{
  "date": "2025-08-17",
  "category": "cs.AI",
  "summary": "å„ä½å­¦æœ¯åŒä»ã€åŒå­¦ï¼Œå¤§å®¶å‘¨æ—¥å¥½ã€‚\n\næ¬¢è¿æ¥åˆ° **UTC æ—¶é—´ 2025-08-17** çš„ arXiv ä¸­æ–‡ TLDR å¿«æŠ¥ï¼\n\n**ä»Šæ—¥æ€»ç»“ï¼š**\nä»Šå¤©çš„ arXiv è®ºæ–‡è´¨é‡é¢‡é«˜ï¼Œæ¶Œç°äº†å¤§é‡å…³äº **Agentic AIï¼ˆæ™ºèƒ½ä½“ï¼‰åä½œä¸æ¨ç†æœºåˆ¶** çš„æ·±åº¦æ¢è®¨ï¼Œç‰¹åˆ«æ˜¯å¦‚ä½•é€šè¿‡å¤šæ™ºèƒ½ä½“åä½œè§£å†³å¤æ‚å›¾æ¨ç†é—®é¢˜ï¼Œä»¥åŠæ¨¡ä»¿äººç±»â€œå¿«æ…¢æ€è€ƒâ€çš„è®¤çŸ¥è·¯ç”±æœºåˆ¶ã€‚åœ¨ **LLM å®‰å…¨ä¸å¯¹é½** æ–¹é¢ï¼Œç ”ç©¶è€…ä»¬å¼€å§‹æŒ‘æˆ˜ä¼ ç»Ÿè§‚å¿µï¼Œæå‡ºå¾®è°ƒä¸­çš„å®‰å…¨æ€§æ›´å¤šæºäºä¼˜åŒ–é€‰æ‹©è€Œéæ•°æ®æƒè¡¡ï¼Œå¹¶æ¢ç´¢äº†æœºå™¨â€œé—å¿˜æƒâ€çš„ç³»ç»Ÿçº§å®ç°ã€‚æ­¤å¤–ï¼Œ**å¤šæ¨¡æ€**é¢†åŸŸå‡ºç°äº†ä¸€ç§â€œåå‘ LLaVAâ€çš„æ–°èŒƒå¼ï¼Œå€¼å¾—å…³æ³¨ã€‚\n\n---\n\n### ğŸš€ æ·±åº¦æ¨ç†ä¸ Agent åä½œ (Agentic AI & Reasoning)\n\nä»Šå¤©æœ€äº®çœ¼çš„å·¥ä½œé›†ä¸­åœ¨å¦‚ä½•è®© LLM å¤„ç†æ›´å¤æ‚çš„ä»»åŠ¡ï¼Œç‰¹åˆ«æ˜¯å›¾ç»“æ„å’Œè®¤çŸ¥å†³ç­–ã€‚\n\n**1. GraphCogent: Mitigating LLMs' Working Memory Constraints via Multi-Agent Collaboration in Complex Graph Understanding**\n**GraphCogent: é€šè¿‡å¤šæ™ºèƒ½ä½“åä½œç¼“è§£ LLM åœ¨å¤æ‚å›¾ç†è§£ä¸­çš„å·¥ä½œè®°å¿†é™åˆ¶**\n> æ ¸å¿ƒè´¡çŒ®ï¼šé’ˆå¯¹ LLM åœ¨å¤„ç†å¤§è§„æ¨¡å›¾æ•°æ®ï¼ˆå¦‚ç¤¾äº¤ç½‘ç»œã€å¼•æ–‡ç½‘ç»œï¼‰æ—¶å—é™äºä¸Šä¸‹æ–‡é•¿åº¦å’Œå·¥ä½œè®°å¿†çš„é—®é¢˜ï¼Œæœ¬æ–‡æå‡ºäº†å—äººç±»å·¥ä½œè®°å¿†æ¨¡å‹å¯å‘çš„ GraphCogent æ¡†æ¶ã€‚å®ƒå°†å›¾æ¨ç†åˆ†è§£ä¸ºâ€œæ„ŸçŸ¥ã€ç¼“å†²ã€æ‰§è¡Œâ€ä¸‰ä¸ªè®¤çŸ¥è¿‡ç¨‹ï¼Œå¹¶å¼•å…¥äº†åŒ…å« 21 ç±»ä»»åŠ¡çš„ Graph4real åŸºå‡†ã€‚\n> å‘ç°ï¼šè¯¥æ¡†æ¶åœ¨ Llama3.1-8B ä¸Šå®ç°äº†æ¯”è‚© DeepSeek-R1 (671B) çš„æ•ˆæœï¼ŒToken ä½¿ç”¨é‡å¤§å¹…é™ä½ã€‚è¿™æ˜¯å›¾ç¥ç»ç½‘ç»œä¸ Agent ç»“åˆçš„ä¸€ä¸ªé‡è¦å°è¯•ã€‚\n\n**2. Cognitive Decision Routing in Large Language Models: When to Think Fast, When to Think Slow**\n**å¤§è¯­è¨€æ¨¡å‹ä¸­çš„è®¤çŸ¥å†³ç­–è·¯ç”±ï¼šä½•æ—¶å¿«æ€è€ƒï¼Œä½•æ—¶æ…¢æ€è€ƒ**\n> æ ¸å¿ƒè´¡çŒ®ï¼šå—å¡å°¼æ›¼ã€Šæ€è€ƒï¼Œå¿«ä¸æ…¢ã€‹å¯å‘ï¼Œä½œè€…æå‡ºäº†è®¤çŸ¥å†³ç­–è·¯ç”± (CDR) æ¡†æ¶ã€‚ç›®å‰çš„ LLM å¾€å¾€å¯¹æ‰€æœ‰é—®é¢˜ä¸€è§†åŒä»åœ°æ¨ç†ï¼ŒCDR å¼•å…¥äº†ä¸€ä¸ªå…ƒè®¤çŸ¥å±‚ï¼Œæ ¹æ®é—®é¢˜çš„å¤æ‚æ€§ã€ä¸ç¡®å®šæ€§ç­‰ç»´åº¦ï¼ŒåŠ¨æ€å†³å®šæ˜¯ä½¿ç”¨å¿«é€Ÿç›´è§‰ååº”è¿˜æ˜¯æ…¢é€Ÿæ·±åº¦æ¨ç†ã€‚\n> æ„ä¹‰ï¼šåœ¨æå‡ä¸“ä¸šåˆ¤æ–­ä»»åŠ¡å‡†ç¡®ç‡çš„åŒæ—¶ï¼Œè®¡ç®—æˆæœ¬é™ä½äº† 34%ã€‚è¿™æ˜¯è¿ˆå‘æ›´é«˜æ•ˆâ€œSystem 2â€æ¨ç†çš„é‡è¦ä¸€æ­¥ã€‚\n\n**3. Disentangling the Drivers of LLM Social Conformity: An Uncertainty-Moderated Dual-Process Mechanism**\n**è§£æ„ LLM ç¤¾ä¼šä»ä¼—æ€§çš„é©±åŠ¨å› ç´ ï¼šä¸ç¡®å®šæ€§è°ƒèŠ‚çš„åŒé‡è¿‡ç¨‹æœºåˆ¶**\n> æ ¸å¿ƒè´¡çŒ®ï¼šLLM ä¹Ÿä¼šâ€œéšå¤§æµâ€å—ï¼Ÿè¿™é¡¹ç ”ç©¶å‘ç° LLM åœ¨åä½œä¸­è¡¨ç°å‡ºä¸äººç±»ç›¸ä¼¼çš„ç¤¾ä¼šä»ä¼—æ€§ã€‚åœ¨ä½ä¸ç¡®å®šæ€§æ—¶ï¼Œå®ƒä»¬å€¾å‘äºä¿å®ˆï¼›ä½†åœ¨é«˜ä¸ç¡®å®šæ€§ä¸‹ï¼Œå®ƒä»¬ä¼šè¿‡åº¦èµ‹äºˆâ€œå…¬å…±ä¿¡å·â€ï¼ˆå³å¤§å¤šæ•°äººçš„æ„è§ï¼‰æƒé‡ï¼Œå“ªæ€•æ˜¯é”™è¯¯çš„ã€‚è¿™å¯¹äºå¤šæ™ºèƒ½ä½“ç³»ç»Ÿçš„è®¾è®¡æå‡ºäº†è­¦ç¤ºã€‚\n\n**4. LinkAnchor: An Autonomous LLM-Based Agent for Issue-to-Commit Link Recovery**\n**LinkAnchor: ç”¨äº Issue åˆ° Commit é“¾æ¥æ¢å¤çš„è‡ªä¸» LLM æ™ºèƒ½ä½“**\n> æ ¸å¿ƒè´¡çŒ®ï¼šè½¯ä»¶å·¥ç¨‹é¢†åŸŸçš„åº”ç”¨ã€‚LinkAnchor æ˜¯ä¸€ä¸ªèƒ½è‡ªä¸»åœ¨ GitHub å’Œ Jira ä¸­ç©¿æ¢­çš„æ™ºèƒ½ä½“ï¼Œé€šè¿‡â€œæ‡’åŠ è½½â€æ¶æ„åªè¯»å–å¿…è¦çš„ä¸Šä¸‹æ–‡ï¼Œè§£å†³äº†è¶…é•¿æäº¤å†å²çš„ Token é™åˆ¶é—®é¢˜ï¼Œå¤§å¹…æå‡äº† Issue å’Œä»£ç æäº¤è®°å½•çš„å…³è”æ¢å¤å‡†ç¡®ç‡ã€‚\n\n---\n\n### ğŸ›¡ï¸ å®‰å…¨ã€å¯¹é½ä¸æ²»ç† (Safety, Alignment & Governance)\n\nä»Šå¤©çš„å‡ ç¯‡å®‰å…¨è®ºæ–‡éå¸¸ç¡¬æ ¸ï¼Œä»ä¼˜åŒ–åŸç†åˆ°ç³»ç»Ÿå®ç°éƒ½æœ‰æ¶‰åŠã€‚\n\n**5. Rethinking Safety in LLM Fine-tuning: An Optimization Perspective**\n**åæ€ LLM å¾®è°ƒä¸­çš„å®‰å…¨æ€§ï¼šä¸€ç§ä¼˜åŒ–çš„è§†è§’**\n> æ ¸å¿ƒè´¡çŒ®ï¼š**è¿™ç¯‡å¾ˆæœ‰æ„æ€ã€‚** ä¼ ç»Ÿè§‚ç‚¹è®¤ä¸ºå¾®è°ƒå¿…ç„¶æŸå®³å®‰å…¨æ€§ï¼ˆSafety Taxï¼‰ã€‚ä½†æœ¬æ–‡é€šè¿‡ç³»ç»Ÿæµ‹è¯•æŒ‘æˆ˜äº†è¿™ä¸€è§‚ç‚¹ï¼ŒæŒ‡å‡ºå®‰å…¨æ€§ä¸‹é™æ›´å¤šæ˜¯å› ä¸ºç³Ÿç³•çš„è¶…å‚æ•°é€‰æ‹©ï¼ˆå¦‚å­¦ä¹ ç‡ã€Batch sizeï¼‰ã€‚ä½œè€…æå‡ºäº†ä¸€ç§ç®€å•çš„æŒ‡æ•°ç§»åŠ¨å¹³å‡ï¼ˆEMAï¼‰åŠ¨é‡æŠ€æœ¯ï¼Œå¯ä»¥åœ¨å¾®è°ƒæ—¶ä¿æŒé¢„è®­ç»ƒæ¨¡å‹çš„å®‰å…¨ç‰¹æ€§ï¼Œè€Œæ— éœ€é¢å¤–çš„æ•°æ®å¹²é¢„ã€‚\n\n**6. Unlearning at Scale: Implementing the Right to be Forgotten in Large Language Models**\n**è§„æ¨¡åŒ–é—å¿˜ï¼šåœ¨å¤§è¯­è¨€æ¨¡å‹ä¸­å®ç°â€œè¢«é—å¿˜æƒâ€**\n> æ ¸å¿ƒè´¡çŒ®ï¼šå¦‚ä½•è®© LLM çœŸæ­£â€œå¿˜æ‰â€ç‰¹å®šçš„è®­ç»ƒæ•°æ®ï¼Ÿæœ¬æ–‡å°†â€œé—å¿˜â€è§†ä¸ºä¸€ä¸ªå¯å¤ç°çš„ç³»ç»Ÿå·¥ç¨‹é—®é¢˜ã€‚ä½œè€…æå‡ºäº†ä¸€å¥—æ–¹æ¡ˆï¼Œé€šè¿‡ç¡®å®šçš„è®­ç»ƒé‡æ”¾ï¼ˆReplayï¼‰å¹¶è¿‡æ»¤æ‰éœ€è¦é—å¿˜çš„æ•°æ®é—­åŒ…ï¼Œå®ç°äº†å­—èŠ‚çº§çš„ç²¾ç¡®é—å¿˜ã€‚è¿™å¯¹äºæ»¡è¶³ GDPR ç­‰éšç§æ³•è§„è‡³å…³é‡è¦ã€‚\n\n**7. Uncovering Systematic Failures of LLMs in Verifying Code Against Natural Language Specifications**\n**æ­ç¤º LLM åœ¨æ ¹æ®è‡ªç„¶è¯­è¨€è§„èŒƒéªŒè¯ä»£ç æ—¶çš„ç³»ç»Ÿæ€§å¤±è´¥**\n> æ ¸å¿ƒè´¡çŒ®ï¼šæˆ‘ä»¬å¸¸è®© LLM å†™ä»£ç ï¼Œä¹Ÿè®©å®ƒ Review ä»£ç ã€‚ä½†è¿™é¡¹ç ”ç©¶å‘ç°ï¼ŒLLM ç»å¸¸ä¼šå°†æ­£ç¡®çš„ä»£ç è¯¯åˆ¤ä¸ºä¸ç¬¦åˆéœ€æ±‚ï¼Œç‰¹åˆ«æ˜¯å½“ä½¿ç”¨å¤æ‚çš„ Prompt å·¥ç¨‹ï¼ˆå¦‚è¦æ±‚è§£é‡Šï¼‰æ—¶ï¼Œè¯¯åˆ¤ç‡åè€Œä¸Šå‡ã€‚è¿™æ­ç¤ºäº† LLM ä½œä¸ºä»£ç å®¡æŸ¥åŠ©æ‰‹çš„é‡å¤§éšæ‚£ã€‚\n\n---\n\n### ğŸ‘ï¸ å¤šæ¨¡æ€ä¸è§†è§‰ (Multimodal & Vision)\n\n**8. Inverse-LLaVA: Eliminating Alignment Pre-training Through Text-to-Vision Mapping**\n**Inverse-LLaVA: é€šè¿‡æ–‡æœ¬åˆ°è§†è§‰æ˜ å°„æ¶ˆé™¤å¯¹é½é¢„è®­ç»ƒ**\n> æ ¸å¿ƒè´¡çŒ®ï¼š**åç›´è§‰çš„è®¾è®¡ã€‚** ä¼ ç»Ÿå¤šæ¨¡æ€æ¨¡å‹ï¼ˆå¦‚ LLaVAï¼‰éœ€è¦æ˜‚è´µçš„å›¾åƒ-æ–‡æœ¬å¯¹é½é¢„è®­ç»ƒã€‚æœ¬æ–‡æå‡ºäº† Inverse-LLaVAï¼Œå®Œå…¨å–æ¶ˆäº†å¯¹é½é¢„è®­ç»ƒï¼Œå¹¶å°†æ˜ å°„æ–¹å‘åè½¬ï¼ˆæ–‡æœ¬ Embeddings æ˜ å°„åˆ°è§†è§‰ç©ºé—´ï¼‰ã€‚\n> å‘ç°ï¼šè¿™ç§æ–¹æ³•åœ¨éœ€è¦å¤æ‚æ¨ç†çš„ä»»åŠ¡ä¸Šï¼ˆå¦‚ ScienceQAï¼‰è¡¨ç°å‡ºè‰²ï¼Œä½†åœ¨ç®€å•çš„æ„ŸçŸ¥ä»»åŠ¡ï¼ˆå¦‚åäººè¯†åˆ«ï¼‰ä¸Šæœ‰æ‰€ä¸‹é™ã€‚è¯æ˜äº†å¯¹é½é¢„è®­ç»ƒå¯¹äºæ¨ç†ä»»åŠ¡å¯èƒ½å¹¶éå¿…é¡»ã€‚\n\n**9. Region-Level Context-Aware Multimodal Understanding**\n**åŒºåŸŸçº§ä¸Šä¸‹æ–‡æ„ŸçŸ¥çš„å¤šæ¨¡æ€ç†è§£**\n> æ ¸å¿ƒè´¡çŒ®ï¼šç°æœ‰çš„å¤šæ¨¡æ€æ¨¡å‹å¾€å¾€å…³æ³¨æ•´ä½“ï¼Œå¿½ç•¥äº†ç‰¹å®šåŒºåŸŸä¸æ–‡æœ¬çš„å…³è”ã€‚æœ¬æ–‡æå‡ºäº† RCMU ä»»åŠ¡å’Œ RCVIT æ–¹æ³•ï¼Œè®©æ¨¡å‹èƒ½å¤Ÿç»“åˆ Bounding Box åæ ‡ï¼Œç²¾å‡†ç†è§£å›¾åƒä¸­ç‰¹å®šåŒºåŸŸçš„è¯­ä¹‰ï¼Œåœ¨ä¸ªæ€§åŒ–å¯¹è¯å’ŒæŒ‡ä»£ç†è§£ä¸Šæå‡æ˜¾è‘—ã€‚\n\n---\n\n### ğŸ§ª AI for Science & åŸºç¡€ç ”ç©¶\n\n**10. Mantis: A Foundation Model for Mechanistic Disease Forecasting**\n**Mantis: åŸºäºæœºç†çš„ç–¾ç—…é¢„æµ‹åŸºç¡€æ¨¡å‹**\n> æ ¸å¿ƒè´¡çŒ®ï¼šMantis æ˜¯ä¸€ä¸ªå®Œå…¨åœ¨**æ¨¡æ‹Ÿæ•°æ®**ä¸Šè®­ç»ƒçš„åŸºç¡€æ¨¡å‹ï¼Œæ²¡æœ‰ä½¿ç”¨ä»»ä½•çœŸå®ä¸–ç•Œæ•°æ®ï¼Œå´åœ¨ COVID-19 ç­‰ç–¾ç—…é¢„æµ‹ä¸Šå‡»è´¥äº†è®¸å¤šä½¿ç”¨çœŸå®æ•°æ®çš„æ¨¡å‹ã€‚è¿™è¯æ˜äº†åŸºäºæ¨¡æ‹Ÿçš„åŸºç¡€æ¨¡å‹èƒ½å¤Ÿæ•æ‰é€šç”¨çš„ä¼ æŸ“åŠ¨åŠ›å­¦ï¼Œå…·æœ‰æå¼ºçš„æ³›åŒ–èƒ½åŠ›ã€‚\n\n**11. Defining and Benchmarking a Data-Centric Design Space for Brain Graph Construction**\n**å®šä¹‰å’ŒåŸºå‡†åŒ–å¤§è„‘å›¾æ„å»ºçš„æ•°æ®ä¸­å¿ƒè®¾è®¡ç©ºé—´**\n> æ ¸å¿ƒè´¡çŒ®ï¼šé’ˆå¯¹ fMRI æ•°æ®æ„å»ºå¤§è„‘å›¾è°±ï¼Œæœ¬æ–‡ä»â€œä»¥æ¨¡å‹ä¸ºä¸­å¿ƒâ€è½¬å‘â€œä»¥æ•°æ®ä¸ºä¸­å¿ƒâ€ã€‚ç ”ç©¶å‘ç°ï¼Œæ•°æ®é¢„å¤„ç†é˜¶æ®µçš„é€‰æ‹©ï¼ˆå¦‚ä¿¡å·è¿‡æ»¤ã€æ‹“æ‰‘æå–ï¼‰å¯¹æœ€ç»ˆæ€§èƒ½çš„å½±å“å¯èƒ½æ¯”æ¨¡å‹ç»“æ„æœ¬èº«æ›´å¤§ã€‚\n\n**12. Uncovering Emergent Physics Representations Learned In-Context by Large Language Models**\n**æ­ç¤ºå¤§è¯­è¨€æ¨¡å‹åœ¨ä¸Šä¸‹æ–‡ä¸­ä¹ å¾—çš„æ¶Œç°ç‰©ç†è¡¨å¾**\n> æ ¸å¿ƒè´¡çŒ®ï¼šLLM çœŸçš„æ‡‚ç‰©ç†å—ï¼Ÿé€šè¿‡ç¨€ç–è‡ªåŠ¨ç¼–ç å™¨ï¼ˆSAEï¼‰åˆ†æï¼Œä½œè€…å‘ç° LLM åœ¨è¿›è¡Œç‰©ç†ç³»ç»ŸåŠ¨åŠ›å­¦é¢„æµ‹æ—¶ï¼Œå…¶å†…éƒ¨æ¿€æ´»ç‰¹å¾ç¡®å®ç¼–ç äº†å…³é”®çš„ç‰©ç†å˜é‡ï¼ˆå¦‚èƒ½é‡ï¼‰ã€‚è¿™è¡¨æ˜ LLM ä¸ä»…ä»…æ˜¯åœ¨æ¨¡ä»¿ç¬¦å·ï¼Œè€Œæ˜¯åœ¨ä¸Šä¸‹æ–‡ä¸­æ„å»ºäº†ç‰©ç†æ¦‚å¿µã€‚\n\n---\n\n### ğŸ› ï¸ åŸºç¡€è®¾æ–½ä¸ç³»ç»Ÿä¼˜åŒ–\n\n*   **Cold-RL: Learning Cache Eviction with Offline Reinforcement Learning for NGINX**\n    **Cold-RL: ç”¨äº NGINX çš„ç¦»çº¿å¼ºåŒ–å­¦ä¹ ç¼“å­˜é©±é€ç­–ç•¥**\n    å°†å¼ºåŒ–å­¦ä¹ å¼•å…¥ NGINX ç¼“å­˜ç®¡ç†ï¼Œç”¨å¾®ç§’çº§é¢„ç®—çš„ DQN æ›¿ä»£ä¼ ç»Ÿçš„ LRU ç®—æ³•ï¼Œåœ¨ NGINX è¿™ç§é«˜æ€§èƒ½ç½‘å…³ä¸­è½åœ° RL æ˜¯ä¸ªä¸å°çš„å·¥ç¨‹æŒ‘æˆ˜ã€‚\n\n*   **Accelerating LLM Inference via Dynamic KV Cache Placement in Heterogeneous Memory System**\n    **é€šè¿‡å¼‚æ„å†…å­˜ç³»ç»Ÿä¸­çš„åŠ¨æ€ KV ç¼“å­˜æ”¾ç½®åŠ é€Ÿ LLM æ¨ç†**\n    é’ˆå¯¹é•¿ä¸Šä¸‹æ–‡æ¨ç†çš„æ˜¾å­˜ç“¶é¢ˆï¼Œæ¢è®¨äº†å¦‚ä½•åœ¨ HBM å’Œ DDR ä¹‹é—´åŠ¨æ€è°ƒåº¦ KV Cacheã€‚\n\n*   **An Introduction to Sliced Optimal Transport**\n    **åˆ‡ç‰‡æœ€ä¼˜ä¼ è¾“å¯¼è®º**\n    ä¸€ç¯‡é•¿è¾¾ 259 é¡µçš„ç»¼è¿°ï¼Œè¯¦ç»†ä»‹ç»äº†åˆ‡ç‰‡æœ€ä¼˜ä¼ è¾“ï¼ˆSOTï¼‰çš„æ•°å­¦åŸºç¡€å’Œåº”ç”¨ã€‚é€‚åˆåšç”Ÿæˆæ¨¡å‹å’Œè®¡ç®—ç»Ÿè®¡çš„åŒå­¦æ”¶è—ã€‚\n\n---\n\n**ä¸€å¥è¯ç‚¹è¯„ï¼š**\nä»Šå¤©çš„è®ºæ–‡ä¸ä»…åœ¨ç®—æ³•å±‚é¢ï¼ˆå¦‚ Agent åä½œã€å¿«æ…¢æ€è€ƒï¼‰æœ‰çªç ´ï¼Œåœ¨â€œå…ƒé—®é¢˜â€çš„æ€è€ƒä¸Šï¼ˆå¦‚ LLM çš„è‡ªæˆ‘è®¤çŸ¥ã€ç¤¾ä¼šä»ä¼—æ€§ã€ä»£ç å®¡æŸ¥èƒ½åŠ›ï¼‰ä¹Ÿæ›´åŠ æ·±å…¥ã€‚ç‰¹åˆ«æ˜¯ Inverse-LLaVA å’Œ Mantis çš„å‡ºç°ï¼Œæç¤ºæˆ‘ä»¬åœ¨æ­¤åˆ»ï¼Œ**åå‘æ€ç»´**ï¼ˆåå‘æ˜ å°„ã€çº¯æ¨¡æ‹Ÿæ•°æ®è®­ç»ƒï¼‰å¯èƒ½ä¼šå¸¦æ¥æ„æƒ³ä¸åˆ°çš„æƒŠå–œã€‚\n\nå¸Œæœ›ä»Šå¤©çš„å¿«æŠ¥å¯¹ä½ çš„ç ”ç©¶æœ‰æ‰€å¯å‘ï¼Œæˆ‘ä»¬æ˜å¤©è§ï¼",
  "papers": [
    {
      "arxiv_id": "2508.12533v1",
      "title": "Defining and Benchmarking a Data-Centric Design Space for Brain Graph Construction",
      "title_zh": "å®šä¹‰ä¸è¯„ä¼°è„‘ç½‘ç»œæ„å»ºä¸­ä»¥æ•°æ®ä¸ºä¸­å¿ƒçš„è®¾è®¡ç©ºé—´",
      "authors": [
        "Qinwen Ge",
        "Roza G. Bayrak",
        "Anwar Said",
        "Catie Chang",
        "Xenofon Koutsoukos",
        "Tyler Derr"
      ],
      "abstract": "The construction of brain graphs from functional Magnetic Resonance Imaging (fMRI) data plays a crucial role in enabling graph machine learning for neuroimaging. However, current practices often rely on rigid pipelines that overlook critical data-centric choices in how brain graphs are constructed. In this work, we adopt a Data-Centric AI perspective and systematically define and benchmark a data-centric design space for brain graph construction, constrasting with primarily model-centric prior work. We organize this design space into three stages: temporal signal processing, topology extraction, and graph featurization. Our contributions lie less in novel components and more in evaluating how combinations of existing and modified techniques influence downstream performance. Specifically, we study high-amplitude BOLD signal filtering, sparsification and unification strategies for connectivity, alternative correlation metrics, and multi-view node and edge features, such as incorporating lagged dynamics. Experiments on the HCP1200 and ABIDE datasets show that thoughtful data-centric configurations consistently improve classification accuracy over standard pipelines. These findings highlight the critical role of upstream data decisions and underscore the importance of systematically exploring the data-centric design space for graph-based neuroimaging. Our code is available at https://github.com/GeQinwen/DataCentricBrainGraphs.",
      "tldr_zh": "è¯¥ç ”ç©¶é’ˆå¯¹åŠŸèƒ½æ€§ç£å…±æŒ¯æˆåƒ (fMRI) è„‘å›¾æ„å»ºä¸­æ™®éå­˜åœ¨çš„æµç¨‹åƒµåŒ–å’Œå¿½ç•¥ä»¥æ•°æ®ä¸ºä¸­å¿ƒ (Data-Centric) å†³ç­–çš„é—®é¢˜ï¼Œä» Data-Centric AI çš„è§†è§’ç³»ç»Ÿåœ°å®šä¹‰å¹¶è¯„ä¼°äº†ä¸€ä¸ªè„‘å›¾æ„å»ºçš„è®¾è®¡ç©ºé—´ã€‚è¯¥è®¾è®¡ç©ºé—´è¢«åˆ’åˆ†ä¸ºæ—¶é—´ä¿¡å·å¤„ç† (temporal signal processing)ã€æ‹“æ‰‘æå– (topology extraction) å’Œå›¾ç‰¹å¾åŒ– (graph featurization) ä¸‰ä¸ªé˜¶æ®µã€‚é€šè¿‡åœ¨ HCP1200 å’Œ ABIDE æ•°æ®é›†ä¸Šçš„å®éªŒï¼Œç ”ç©¶è€…é‡ç‚¹åˆ†æäº†é«˜æŒ¯å¹… BOLD ä¿¡å·è¿‡æ»¤ã€è¿é€šæ€§ç¨€ç–åŒ–ä¸ç»Ÿä¸€ç­–ç•¥ã€æ›¿ä»£ç›¸å…³æ€§æŒ‡æ ‡ä»¥åŠåŒ…å«æ»ååŠ¨åŠ›å­¦ (lagged dynamics) çš„å¤šè§†å›¾ç‰¹å¾å¯¹æ¨¡å‹è¡¨ç°çš„å½±å“ã€‚å®éªŒç»“æœè¯æ˜ï¼Œç»è¿‡æ·±æ€ç†Ÿè™‘çš„ Data-Centric é…ç½®åœ¨åˆ†ç±»å‡†ç¡®ç‡ä¸Šä¸€è‡´ä¼˜äºä¼ ç»Ÿæ ‡å‡†æµç¨‹ã€‚è¿™ä¸€å·¥ä½œå¼ºè°ƒäº†ä¸Šæ¸¸æ•°æ®å¤„ç†å†³ç­–åœ¨ç¥ç»å½±åƒå­¦ä¸­çš„æ ¸å¿ƒåœ°ä½ï¼Œå¹¶ä¸ºå›¾æœºå™¨å­¦ä¹ åœ¨è„‘ç§‘å­¦é¢†åŸŸçš„åº”ç”¨æä¾›äº†ç³»ç»ŸåŒ–çš„æ¢ç´¢è·¯å¾„ä¸åŸºå‡†å‚è€ƒã€‚",
      "categories": [
        "cs.LG",
        "cs.AI",
        "q-bio.NC"
      ],
      "primary_category": "cs.LG",
      "comment": "",
      "pdf_url": "https://arxiv.org/pdf/2508.12533v1",
      "published_date": "2025-08-17 23:53:29 UTC",
      "updated_date": "2025-08-17 23:53:29 UTC",
      "processing_status": "completed",
      "attempts": 1,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "llm_backup_calls": 0,
      "last_update": "2026-01-24T12:21:23.259244+00:00"
    },
    {
      "arxiv_id": "2508.12531v1",
      "title": "Rethinking Safety in LLM Fine-tuning: An Optimization Perspective",
      "title_zh": "é‡æ–°å®¡è§†å¤§è¯­è¨€æ¨¡å‹å¾®è°ƒçš„å®‰å…¨æ€§ï¼šåŸºäºä¼˜åŒ–çš„è§†è§’",
      "authors": [
        "Minseon Kim",
        "Jin Myung Kwak",
        "Lama Alssum",
        "Bernard Ghanem",
        "Philip Torr",
        "David Krueger",
        "Fazl Barez",
        "Adel Bibi"
      ],
      "abstract": "Fine-tuning language models is commonly believed to inevitably harm their safety, i.e., refusing to respond to harmful user requests, even when using harmless datasets, thus requiring additional safety measures. We challenge this belief through systematic testing, showing that poor optimization choices, rather than inherent trade-offs, often cause safety problems, measured as harmful responses to adversarial prompts. By properly selecting key training hyper-parameters, e.g., learning rate, batch size, and gradient steps, we reduce unsafe model responses from 16\\% to approximately 5\\%, as measured by keyword matching, while maintaining utility performance. Based on this observation, we propose a simple exponential moving average (EMA) momentum technique in parameter space that preserves safety performance by creating a stable optimization path and retains the original pre-trained model's safety properties. Our experiments on the Llama families across multiple datasets (Dolly, Alpaca, ORCA) demonstrate that safety problems during fine-tuning can largely be avoided without specialized interventions, outperforming existing approaches that require additional safety data while offering practical guidelines for maintaining both model performance and safety during adaptation.",
      "tldr_zh": "è¯¥ç ”ç©¶æ¢è®¨äº†å¤§å‹è¯­è¨€æ¨¡å‹ï¼ˆLLMsï¼‰åœ¨å¾®è°ƒï¼ˆFine-tuningï¼‰è¿‡ç¨‹ä¸­å®‰å…¨æ€§å—æŸçš„é—®é¢˜ï¼ŒæŒ‘æˆ˜äº†â€œå¾®è°ƒå¿…ç„¶å¯¼è‡´å®‰å…¨æ€§ä¸‹é™â€çš„ä¼ ç»Ÿè§‚ç‚¹ã€‚ä½œè€…é€šè¿‡ç³»ç»Ÿæ€§æµ‹è¯•å‘ç°ï¼Œå®‰å…¨æ€§é™ä½å¾€å¾€æºäºä¸è‰¯çš„ä¼˜åŒ–ï¼ˆOptimizationï¼‰é€‰æ‹©ï¼Œè€Œéæ¨¡å‹æ€§èƒ½ä¸å®‰å…¨ä¹‹é—´çš„å›ºæœ‰æƒè¡¡ã€‚é€šè¿‡ä¼˜åŒ–å…³é”®è¶…å‚æ•°ï¼ˆHyper-parametersï¼‰ï¼Œå¦‚å­¦ä¹ ç‡ï¼ˆLearning rateï¼‰å’Œæ‰¹æ¬¡å¤§å°ï¼ˆBatch sizeï¼‰ï¼Œç ”ç©¶è€…åœ¨ä¿æŒæ¨¡å‹æ•ˆèƒ½çš„åŒæ—¶ï¼Œå°†ä¸å®‰å…¨å“åº”ç‡ä»16%å¤§å¹…é™ä½è‡³çº¦5%ã€‚åŸºäºæ­¤è§‚å¯Ÿï¼Œç ”ç©¶æå‡ºäº†ä¸€ç§åœ¨å‚æ•°ç©ºé—´åº”ç”¨çš„æŒ‡æ•°ç§»åŠ¨å¹³å‡ï¼ˆEMAï¼‰åŠ¨é‡æŠ€æœ¯ï¼Œé€šè¿‡æ„å»ºç¨³å®šçš„ä¼˜åŒ–è·¯å¾„æ¥ä¿ç•™é¢„è®­ç»ƒæ¨¡å‹çš„åŸå§‹å®‰å…¨ç‰¹æ€§ã€‚åœ¨Llamaç³»åˆ—æ¨¡å‹åŠå¤šä¸ªæ•°æ®é›†ï¼ˆDolly, Alpaca, ORCAï¼‰ä¸Šçš„å®éªŒè¯æ˜ï¼Œè¯¥æ–¹æ³•æ— éœ€é¢å¤–çš„å®‰å…¨æ•°æ®æˆ–ä¸“é—¨å¹²é¢„å³å¯åœ¨å¾®è°ƒä¸­æœ‰æ•ˆç»´æŠ¤å®‰å…¨æ€§ï¼Œä¸ºæ¨¡å‹é€‚é…æä¾›äº†å®ç”¨çš„æŒ‡å¯¼åŸåˆ™ã€‚",
      "categories": [
        "cs.LG",
        "cs.AI"
      ],
      "primary_category": "cs.LG",
      "comment": "",
      "pdf_url": "https://arxiv.org/pdf/2508.12531v1",
      "published_date": "2025-08-17 23:46:36 UTC",
      "updated_date": "2025-08-17 23:46:36 UTC",
      "processing_status": "completed",
      "attempts": 1,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "llm_backup_calls": 0,
      "last_update": "2026-01-24T12:21:22.492156+00:00"
    },
    {
      "arxiv_id": "2508.12520v1",
      "title": "An Initial Study of Bird's-Eye View Generation for Autonomous Vehicles using Cross-View Transformers",
      "title_zh": "åŸºäºè·¨è§†å›¾ Transformer çš„è‡ªåŠ¨é©¾é©¶è½¦è¾†é¸Ÿç°å›¾ç”Ÿæˆåˆæ¢",
      "authors": [
        "Felipe Carlos dos Santos",
        "Eric Aislan Antonelo",
        "Gustavo Claudio Karl Couto"
      ],
      "abstract": "Bird's-Eye View (BEV) maps provide a structured, top-down abstraction that is crucial for autonomous-driving perception. In this work, we employ Cross-View Transformers (CVT) for learning to map camera images to three BEV's channels - road, lane markings, and planned trajectory - using a realistic simulator for urban driving. Our study examines generalization to unseen towns, the effect of different camera layouts, and two loss formulations (focal and L1). Using training data from only a town, a four-camera CVT trained with the L1 loss delivers the most robust test performance, evaluated in a new town. Overall, our results underscore CVT's promise for mapping camera inputs to reasonably accurate BEV maps.",
      "tldr_zh": "è¯¥ç ”ç©¶æ¢è®¨äº†åˆ©ç”¨Cross-View Transformers (CVT) ä¸ºè‡ªåŠ¨é©¾é©¶è½¦è¾†ç”ŸæˆBird's-Eye View (BEV) åœ°å›¾çš„æ–¹æ³•ã€‚è¯¥æ¡†æ¶é€šè¿‡å­¦ä¹ å°†å¤šè§†è§’æ‘„åƒå¤´å›¾åƒæ˜ å°„åˆ°é“è·¯(road)ã€è½¦é“æ ‡è®°(lane markings)å’Œè®¡åˆ’è½¨è¿¹(planned trajectory)ä¸‰ä¸ªå…³é”®BEVé€šé“ï¼Œå¹¶åœ¨çœŸå®çš„åŸå¸‚é©¾é©¶æ¨¡æ‹Ÿå™¨ä¸­è¿›è¡Œäº†éªŒè¯ã€‚ç ”ç©¶é‡ç‚¹è€ƒå¯Ÿäº†æ¨¡å‹å¯¹æœªçŸ¥åŸé•‡åœºæ™¯çš„æ³›åŒ–èƒ½åŠ›ï¼Œä»¥åŠä¸åŒæ‘„åƒå¤´å¸ƒå±€å’ŒæŸå¤±å‡½æ•°ï¼ˆfocal lossä¸L1 lossï¼‰å¯¹ç”Ÿæˆæ•ˆæœçš„å½±å“ã€‚å®éªŒç»“æœè¡¨æ˜ï¼Œé‡‡ç”¨L1æŸå¤±çš„å››æ‘„åƒå¤´CVTé…ç½®åœ¨è·¨åŸé•‡æµ‹è¯•ä¸­è¡¨ç°å‡ºæœ€ç¨³å¥çš„æ€§èƒ½ã€‚æ€»ä½“è€Œè¨€ï¼Œè¯¥ç ”ç©¶è¯æ˜äº†CVTåœ¨å°†æ‘„åƒå¤´è¾“å…¥è½¬åŒ–ä¸ºå‡†ç¡®BEVè¡¨å¾æ–¹é¢çš„å·¨å¤§æ½œåŠ›ï¼Œä¸ºè‡ªåŠ¨é©¾é©¶æ„ŸçŸ¥æä¾›äº†ç»“æ„åŒ–çš„é¡¶å±‚æŠ½è±¡ã€‚",
      "categories": [
        "cs.CV",
        "cs.AI"
      ],
      "primary_category": "cs.CV",
      "comment": "12 pages,submitted in ENIAC 2025",
      "pdf_url": "https://arxiv.org/pdf/2508.12520v1",
      "published_date": "2025-08-17 23:05:00 UTC",
      "updated_date": "2025-08-17 23:05:00 UTC",
      "processing_status": "completed",
      "attempts": 1,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "llm_backup_calls": 0,
      "last_update": "2026-01-24T12:21:14.056978+00:00"
    },
    {
      "arxiv_id": "2508.12519v2",
      "title": "An Introduction to Sliced Optimal Transport",
      "title_zh": "åˆ‡ç‰‡æœ€ä¼˜ä¼ è¾“å¯¼è®º",
      "authors": [
        "Khai Nguyen"
      ],
      "abstract": "Sliced Optimal Transport (SOT) is a rapidly developing branch of optimal transport (OT) that exploits the tractability of one-dimensional OT problems. By combining tools from OT, integral geometry, and computational statistics, SOT enables fast and scalable computation of distances, barycenters, and kernels for probability measures, while retaining rich geometric structure. This paper provides a comprehensive review of SOT, covering its mathematical foundations, methodological advances, computational methods, and applications. We discuss key concepts of OT and one-dimensional OT, the role of tools from integral geometry such as Radon transform in projecting measures, and statistical techniques for estimating sliced distances. The paper further explores recent methodological advances, including non-linear projections, improved Monte Carlo approximations, statistical estimation techniques for one-dimensional optimal transport, weighted slicing techniques, and transportation plan estimation methods. Variational problems, such as minimum sliced Wasserstein estimation, barycenters, gradient flows, kernel constructions, and embeddings are examined alongside extensions to unbalanced, partial, multi-marginal, and Gromov-Wasserstein settings. Applications span machine learning, statistics, computer graphics and computer visions, highlighting SOT's versatility as a practical computational tool. This work will be of interest to researchers and practitioners in machine learning, data sciences, and computational disciplines seeking efficient alternatives to classical OT.",
      "tldr_zh": "è¯¥è®ºæ–‡å¯¹åˆ‡ç‰‡æœ€ä¼˜ä¼ è¾“(Sliced Optimal Transport, SOT)è¿›è¡Œäº†å…¨é¢ç»¼è¿°ï¼Œè¿™æ˜¯ä¸€ç§åˆ©ç”¨ä¸€ç»´ Optimal Transport é—®é¢˜æ˜“å¤„ç†æ€§æ¥åº”å¯¹é«˜ç»´æŒ‘æˆ˜çš„é«˜æ•ˆåˆ†æ”¯ã€‚é€šè¿‡ç»“åˆç§¯åˆ†å‡ ä½•ä¸­çš„ Radon transform ç­‰æŠ•å½±æŠ€æœ¯ä»¥åŠè®¡ç®—ç»Ÿè®¡å­¦å·¥å…·ï¼ŒSOT å®ç°äº†æ¦‚ç‡åº¦é‡è·ç¦»ã€Barycenters å’Œ Kernels çš„å¿«é€Ÿä¸”å¯æ‰©å±•çš„è®¡ç®—ï¼ŒåŒæ—¶ä¿ç•™äº†ä¸°å¯Œçš„å‡ ä½•ç»“æ„ã€‚æ–‡ä¸­è¯¦ç»†æ¢è®¨äº† SOT çš„æ•°å­¦åŸºç¡€ã€æ–¹æ³•è®ºè¿›å±•ï¼ˆå¦‚éçº¿æ€§æŠ•å½±å’Œæ”¹è¿›çš„ Monte Carlo è¿‘ä¼¼ï¼‰ã€ç»Ÿè®¡ä¼°è®¡æŠ€æœ¯ï¼Œä»¥åŠå‘ Unbalancedã€Partial å’Œ Gromov-Wasserstein ç­‰å¤æ‚è®¾ç½®çš„æ‰©å±•ã€‚æ­¤å¤–ï¼Œè®ºæ–‡è¿˜æ·±å…¥åˆ†æäº†æœ€å°åˆ‡ç‰‡ Wasserstein ä¼°è®¡ã€Gradient Flows å’ŒåµŒå…¥ç­‰å˜åˆ†é—®é¢˜ã€‚SOT åœ¨æœºå™¨å­¦ä¹ ã€ç»Ÿè®¡å­¦ã€è®¡ç®—æœºå›¾å½¢å­¦å’Œè®¡ç®—æœºè§†è§‰ç­‰é¢†åŸŸçš„å¹¿æ³›åº”ç”¨ï¼Œè¯æ˜äº†å…¶ä½œä¸ºç»å…¸ Optimal Transport å®ç”¨ä¸”é«˜æ•ˆæ›¿ä»£å·¥å…·çš„å·¨å¤§æ½œåŠ›ã€‚",
      "categories": [
        "stat.ML",
        "cs.AI",
        "cs.LG",
        "stat.CO",
        "stat.ME"
      ],
      "primary_category": "stat.ML",
      "comment": "259 pages",
      "pdf_url": "https://arxiv.org/pdf/2508.12519v2",
      "published_date": "2025-08-17 22:53:19 UTC",
      "updated_date": "2025-10-14 06:29:47 UTC",
      "processing_status": "completed",
      "attempts": 1,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "llm_backup_calls": 0,
      "last_update": "2026-01-24T12:21:16.751948+00:00"
    },
    {
      "arxiv_id": "2508.14106v2",
      "title": "High-Throughput Low-Cost Segmentation of Brightfield Microscopy Live Cell Images",
      "title_zh": "æ˜åœºæ˜¾å¾®æ´»ç»†èƒå›¾åƒçš„é«˜é€šé‡ä½æˆæœ¬åˆ†å‰²",
      "authors": [
        "Surajit Das",
        "Gourav Roy",
        "Pavel Zun"
      ],
      "abstract": "Live cell culture is crucial in biomedical studies for analyzing cell properties and dynamics in vitro. This study focuses on segmenting unstained live cells imaged with bright-field microscopy. While many segmentation approaches exist for microscopic images, none consistently address the challenges of bright-field live-cell imaging with high throughput, where temporal phenotype changes, low contrast, noise, and motion-induced blur from cellular movement remain major obstacles. We developed a low-cost CNN-based pipeline incorporating comparative analysis of frozen encoders within a unified U-Net architecture enhanced with attention mechanisms, instance-aware systems, adaptive loss functions, hard instance retraining, dynamic learning rates, progressive mechanisms to mitigate overfitting, and an ensemble technique. The model was validated on a public dataset featuring diverse live cell variants, showing consistent competitiveness with state-of-the-art methods, achieving 93% test accuracy and an average F1-score of 89% (std. 0.07) on low-contrast, noisy, and blurry images. Notably, the model was trained primarily on bright-field images with limited exposure to phase- contrast microscopy (<20%), yet it generalized effectively to the phase-contrast LIVECell dataset, demonstrating modality, robustness and strong performance. This highlights its potential for real- world laboratory deployment across imaging conditions. The model requires minimal compute power and is adaptable using basic deep learning setups such as Google Colab, making it practical for training on other cell variants. Our pipeline outperforms existing methods in robustness and precision for bright-field microscopy segmentation. The code and dataset are available for reproducibility 1.",
      "tldr_zh": "è¯¥ç ”ç©¶é’ˆå¯¹æ˜åœºæ˜¾å¾®é•œ(Brightfield Microscopy)æ´»ç»†èƒæˆåƒä¸­å¯¹æ¯”åº¦ä½ã€å™ªå£°å¤§åŠç»†èƒè¿åŠ¨å¯¼è‡´çš„æ¨¡ç³Šç­‰åˆ†å‰²éš¾é¢˜ï¼Œæå‡ºäº†ä¸€ç§é«˜é€šé‡ä¸”ä½æˆæœ¬çš„å·ç§¯ç¥ç»ç½‘ç»œ(CNN)åˆ†å‰²æµæ°´çº¿ã€‚è¯¥æ–¹æ¡ˆåœ¨ç»Ÿä¸€çš„U-Netæ¶æ„ä¸­æ•´åˆäº†å†»ç»“ç¼–ç å™¨(Frozen Encoders)çš„å¯¹æ¯”åˆ†æã€æ³¨æ„åŠ›æœºåˆ¶(Attention Mechanisms)ä»¥åŠå®ä¾‹æ„ŸçŸ¥ç³»ç»Ÿ(Instance-aware Systems)ï¼Œå¹¶ç»“åˆè‡ªé€‚åº”æŸå¤±å‡½æ•°(Adaptive Loss Functions)å’Œé›†æˆæŠ€æœ¯(Ensemble Technique)æ¥æå‡æ€§èƒ½ã€‚å®éªŒéªŒè¯è¡¨æ˜ï¼Œè¯¥æ¨¡å‹åœ¨å¤šç§æ´»ç»†èƒå˜ä½“æ•°æ®é›†ä¸Šè¾¾åˆ°äº†93%çš„æµ‹è¯•å‡†ç¡®ç‡å’Œ89%çš„å¹³å‡F1-scoreã€‚å€¼å¾—æ³¨æ„çš„æ˜¯ï¼Œå°½ç®¡ä¸»è¦é’ˆå¯¹æ˜åœºå›¾åƒè®­ç»ƒï¼Œè¯¥æ¨¡å‹åœ¨ç›¸ä½å·®æ˜¾å¾®(Phase-contrast Microscopy)æ•°æ®é›†LIVECellä¸Šä»å±•ç°å‡ºå“è¶Šçš„æ³›åŒ–èƒ½åŠ›å’Œé²æ£’æ€§ã€‚ç”±äºè¯¥æµæ°´çº¿å¯¹è®¡ç®—èµ„æºéœ€æ±‚æä½ä¸”æ˜“äºåœ¨åŸºç¡€æ·±åº¦å­¦ä¹ ç¯å¢ƒä¸‹é€‚é…ï¼Œå…¶åœ¨å®é™…å®éªŒå®¤è·¨æˆåƒæ¡ä»¶çš„éƒ¨ç½²ä¸­å…·æœ‰æé«˜çš„åº”ç”¨ä»·å€¼ï¼Œæ€§èƒ½ä¼˜äºç°æœ‰çš„æ˜åœºå›¾åƒåˆ†å‰²æ–¹æ³•ã€‚",
      "categories": [
        "q-bio.QM",
        "cs.AI",
        "cs.CV",
        "eess.IV"
      ],
      "primary_category": "q-bio.QM",
      "comment": "",
      "pdf_url": "https://arxiv.org/pdf/2508.14106v2",
      "published_date": "2025-08-17 22:05:58 UTC",
      "updated_date": "2025-08-23 10:36:18 UTC",
      "processing_status": "completed",
      "attempts": 1,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "llm_backup_calls": 0,
      "last_update": "2026-01-24T12:21:18.454368+00:00"
    },
    {
      "arxiv_id": "2508.12506v1",
      "title": "Design and Validation of a Responsible Artificial Intelligence-based System for the Referral of Diabetic Retinopathy Patients",
      "title_zh": "ç”¨äºç³–å°¿ç—…è§†ç½‘è†œç—…å˜æ‚£è€…è½¬è¯Šçš„è´Ÿè´£ä»»äººå·¥æ™ºèƒ½ç³»ç»Ÿçš„è®¾è®¡ä¸éªŒè¯",
      "authors": [
        "E. Ulises Moya-SÃ¡nchez",
        "Abraham SÃ¡nchez-Perez",
        "RaÃºl Nanclares Da Veiga",
        "Alejandro Zarate-MacÃ­as",
        "Edgar Villareal",
        "Alejandro SÃ¡nchez-Montes",
        "Edtna Jauregui-Ulloa",
        "HÃ©ctor Moreno",
        "Ulises CortÃ©s"
      ],
      "abstract": "Diabetic Retinopathy (DR) is a leading cause of vision loss in working-age individuals. Early detection of DR can reduce the risk of vision loss by up to 95%, but a shortage of retinologists and challenges in timely examination complicate detection. Artificial Intelligence (AI) models using retinal fundus photographs (RFPs) offer a promising solution. However, adoption in clinical settings is hindered by low-quality data and biases that may lead AI systems to learn unintended features. To address these challenges, we developed RAIS-DR, a Responsible AI System for DR screening that incorporates ethical principles across the AI lifecycle. RAIS-DR integrates efficient convolutional models for preprocessing, quality assessment, and three specialized DR classification models. We evaluated RAIS-DR against the FDA-approved EyeArt system on a local dataset of 1,046 patients, unseen by both systems. RAIS-DR demonstrated significant improvements, with F1 scores increasing by 5-12%, accuracy by 6-19%, and specificity by 10-20%. Additionally, fairness metrics such as Disparate Impact and Equal Opportunity Difference indicated equitable performance across demographic subgroups, underscoring RAIS-DR's potential to reduce healthcare disparities. These results highlight RAIS-DR as a robust and ethically aligned solution for DR screening in clinical settings. The code, weights of RAIS-DR are available at https://gitlab.com/inteligencia-gubernamental-jalisco/jalisco-retinopathy with RAIL.",
      "tldr_zh": "è¯¥ç ”ç©¶å¼€å‘äº†RAIS-DRï¼Œä¸€ä¸ªè´Ÿè´£ä»»çš„äººå·¥æ™ºèƒ½ç³»ç»Ÿ(Responsible AI System)ï¼Œæ—¨åœ¨é€šè¿‡è§†ç½‘è†œçœ¼åº•ç…§ç‰‡(RFPs)å¯¹ç³–å°¿ç—…è§†ç½‘è†œç—…å˜(Diabetic Retinopathy, DR)è¿›è¡Œæ—©æœŸç­›æŸ¥ï¼Œä»¥åº”å¯¹ç›¸å…³ä¸“å®¶çŸ­ç¼ºå’Œæ£€æµ‹ä¸åŠæ—¶çš„é—®é¢˜ã€‚è¯¥ç³»ç»Ÿåœ¨AIç”Ÿå‘½å‘¨æœŸä¸­èå…¥äº†ä¼¦ç†åŸåˆ™ï¼Œé›†æˆäº†ç”¨äºé¢„å¤„ç†ã€è´¨é‡è¯„ä¼°çš„é«˜æ•ˆå·ç§¯æ¨¡å‹(convolutional models)ä»¥åŠä¸‰ä¸ªä¸“é—¨çš„DRåˆ†ç±»æ¨¡å‹ã€‚ç ”ç©¶äººå‘˜åœ¨åŒ…å«1,046åæ‚£è€…çš„æœ¬åœ°æ•°æ®é›†ä¸Šå°†RAIS-DRä¸è·å¾—FDAæ‰¹å‡†çš„EyeArtç³»ç»Ÿè¿›è¡Œäº†å¯¹æ¯”ï¼Œç»“æœæ˜¾ç¤ºRAIS-DRåœ¨F1åˆ†æ•°ä¸Šæå‡äº†5-12%ï¼Œå‡†ç¡®ç‡(accuracy)æå‡äº†6-19%ï¼Œç‰¹å¼‚æ€§(specificity)åˆ™æå‡äº†10-20%ã€‚æ­¤å¤–ï¼Œé€šè¿‡å¯¹å·®å¼‚æ€§å½±å“(Disparate Impact)å’Œå‡ç­‰æœºä¼šå·®å¼‚(Equal Opportunity Difference)ç­‰å…¬å¹³æ€§æŒ‡æ ‡çš„è¯„ä¼°ï¼Œè¯æ˜äº†è¯¥ç³»ç»Ÿåœ¨ä¸åŒäººå£ç»Ÿè®¡å­¦å­ç¾¤ä¸­è¡¨ç°å‡è¡¡ï¼Œå…·æœ‰å‡å°‘åŒ»ç–—å·®å¼‚çš„æ½œåŠ›ã€‚è¿™ä¸€æˆæœè¡¨æ˜RAIS-DRæ˜¯ä¸´åºŠç¯å¢ƒä¸‹ä¸€ç§é²æ£’ä¸”ç¬¦åˆä¼¦ç†è§„èŒƒçš„DRç­›æŸ¥è§£å†³æ–¹æ¡ˆã€‚",
      "categories": [
        "cs.CV",
        "cs.AI"
      ],
      "primary_category": "cs.CV",
      "comment": "14 pages,3 figures, under review",
      "pdf_url": "https://arxiv.org/pdf/2508.12506v1",
      "published_date": "2025-08-17 21:54:11 UTC",
      "updated_date": "2025-08-17 21:54:11 UTC",
      "processing_status": "completed",
      "attempts": 1,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "llm_backup_calls": 0,
      "last_update": "2026-01-24T12:21:28.797462+00:00"
    },
    {
      "arxiv_id": "2508.12500v1",
      "title": "Root Cause Analysis of Hydrogen Bond Separation in Spatio-Temporal Molecular Dynamics using Causal Models",
      "title_zh": "åŸºäºå› æœæ¨¡å‹çš„æ—¶ç©ºåˆ†å­åŠ¨åŠ›å­¦æ°¢é”®æ–­è£‚æ ¹å› åˆ†æ",
      "authors": [
        "Rahmat K. Adesunkanmi",
        "Ashfaq Khokhar",
        "Goce Trajcevski",
        "Sohail Murad"
      ],
      "abstract": "Molecular dynamics simulations (MDS) face challenges, including resource-heavy computations and the need to manually scan outputs to detect \"interesting events,\" such as the formation and persistence of hydrogen bonds between atoms of different molecules. A critical research gap lies in identifying the underlying causes of hydrogen bond formation and separation -understanding which interactions or prior events contribute to their emergence over time. With this challenge in mind, we propose leveraging spatio-temporal data analytics and machine learning models to enhance the detection of these phenomena. In this paper, our approach is inspired by causal modeling and aims to identify the root cause variables of hydrogen bond formation and separation events. Specifically, we treat the separation of hydrogen bonds as an \"intervention\" occurring and represent the causal structure of the bonding and separation events in the MDS as graphical causal models. These causal models are built using a variational autoencoder-inspired architecture that enables us to infer causal relationships across samples with diverse underlying causal graphs while leveraging shared dynamic information. We further include a step to infer the root causes of changes in the joint distribution of the causal models. By constructing causal models that capture shifts in the conditional distributions of molecular interactions during bond formation or separation, this framework provides a novel perspective on root cause analysis in molecular dynamic systems. We validate the efficacy of our model empirically on the atomic trajectories that used MDS for chiral separation, demonstrating that we can predict many steps in the future and also find the variables driving the observed changes in the system.",
      "tldr_zh": "è¯¥ç ”ç©¶é’ˆå¯¹åˆ†å­åŠ¨åŠ›å­¦æ¨¡æ‹Ÿ(Molecular Dynamics Simulations, MDS)ä¸­æ°¢é”®(Hydrogen Bond)å½¢æˆä¸æ–­è£‚ç­‰å…³é”®äº‹ä»¶éš¾ä»¥è‡ªåŠ¨è¯†åˆ«æ ¹å› çš„é—®é¢˜ï¼Œæå‡ºäº†ä¸€ç§ç»“åˆæ—¶ç©ºæ•°æ®åˆ†æä¸å› æœæ¨¡å‹(Causal Models)çš„æ–°å‹åˆ†ææ¡†æ¶ã€‚è¯¥æ–¹æ³•å°†æ°¢é”®åˆ†ç¦»è§†ä¸ºä¸€ç§â€œå¹²é¢„(Intervention)â€ï¼Œå¹¶åˆ©ç”¨å—å˜åˆ†è‡ªç¼–ç å™¨(Variational Autoencoder)å¯å‘çš„æ¶æ„æ„å»ºå›¾å½¢å› æœæ¨¡å‹ï¼Œä»è€Œæ¨æ–­è·¨æ ·æœ¬çš„å› æœå…³ç³»å¹¶åˆ©ç”¨å…±äº«çš„åŠ¨åŠ›å­¦ä¿¡æ¯ã€‚é€šè¿‡æ•æ‰åˆ†å­ç›¸äº’ä½œç”¨è¿‡ç¨‹ä¸­æ¡ä»¶åˆ†å¸ƒçš„å˜åŒ–ï¼Œè¯¥æ¡†æ¶èƒ½å¤Ÿæœ‰æ•ˆæ¨æ–­å¯¼è‡´ç³»ç»Ÿè”åˆåˆ†å¸ƒåç§»çš„æ ¹å› å˜é‡ã€‚å®éªŒåœ¨æ‰‹æ€§åˆ†ç¦»(Chiral Separation)çš„åŸå­è½¨è¿¹æ•°æ®ä¸ŠéªŒè¯äº†å…¶æœ‰æ•ˆæ€§ï¼Œè¯æ˜è¯¥æ¨¡å‹ä¸ä»…èƒ½å¤Ÿé¢„æµ‹æœªæ¥å¤šæ­¥çš„ç³»ç»ŸçŠ¶æ€ï¼Œè¿˜èƒ½ç²¾å‡†å®šä½é©±åŠ¨ç³»ç»Ÿå˜åŒ–çš„é©±åŠ¨å˜é‡ã€‚è¿™ä¸€ç ”ç©¶ä¸ºåˆ†å­åŠ¨åŠ›å­¦ç³»ç»Ÿçš„æ ¹å› åˆ†æ(Root Cause Analysis)æä¾›äº†ä¸€ä¸ªæ–°é¢–çš„è‡ªåŠ¨åŒ–è§†è§’ï¼Œæ˜¾è‘—æå‡äº†ä»æµ·é‡æ¨¡æ‹Ÿæ•°æ®ä¸­æå–ç‰©ç†æ´å¯Ÿçš„èƒ½åŠ›ã€‚",
      "categories": [
        "cs.AI",
        "cs.LG",
        "q-bio.QM"
      ],
      "primary_category": "cs.AI",
      "comment": "Submitted to ACM",
      "pdf_url": "https://arxiv.org/pdf/2508.12500v1",
      "published_date": "2025-08-17 21:23:12 UTC",
      "updated_date": "2025-08-17 21:23:12 UTC",
      "processing_status": "completed",
      "attempts": 1,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "llm_backup_calls": 0,
      "last_update": "2026-01-24T12:21:31.191454+00:00"
    },
    {
      "arxiv_id": "2508.12495v2",
      "title": "Mitigating Hallucinations in Large Language Models via Causal Reasoning",
      "title_zh": "é€šè¿‡å› æœæ¨ç†ç¼“è§£å¤§è¯­è¨€æ¨¡å‹çš„å¹»è§‰",
      "authors": [
        "Yuangang Li",
        "Yiqing Shen",
        "Yi Nian",
        "Jiechao Gao",
        "Ziyi Wang",
        "Chenxiao Yu",
        "Shawn Li",
        "Jie Wang",
        "Xiyang Hu",
        "Yue Zhao"
      ],
      "abstract": "Large language models (LLMs) exhibit logically inconsistent hallucinations that appear coherent yet violate reasoning principles, with recent research suggesting an inverse relationship between causal reasoning capabilities and such hallucinations. However, existing reasoning approaches in LLMs, such as Chain-of-Thought (CoT) and its graph-based variants, operate at the linguistic token level rather than modeling the underlying causal relationships between variables, lacking the ability to represent conditional independencies or satisfy causal identification assumptions. To bridge this gap, we introduce causal-DAG construction and reasoning (CDCR-SFT), a supervised fine-tuning framework that trains LLMs to explicitly construct variable-level directed acyclic graph (DAG) and then perform reasoning over it. Moreover, we present a dataset comprising 25,368 samples (CausalDR), where each sample includes an input question, explicit causal DAG, graph-based reasoning trace, and validated answer. Experiments on four LLMs across eight tasks show that CDCR-SFT improves the causal reasoning capability with the state-of-the-art 95.33% accuracy on CLADDER (surpassing human performance of 94.8% for the first time) and reduces the hallucination on HaluEval with 10% improvements. It demonstrates that explicit causal structure modeling in LLMs can effectively mitigate logical inconsistencies in LLM outputs. Code is available at https://github.com/MrLYG/CDCR-SFT.",
      "tldr_zh": "è¯¥ç ”ç©¶é’ˆå¯¹å¤§è¯­è¨€æ¨¡å‹ (LLMs) ä¸­å‡ºç°çš„é€»è¾‘ä¸ä¸€è‡´å¹»è§‰é—®é¢˜ï¼Œæå‡ºäº†ä¸€ç§åä¸º CDCR-SFT (causal-DAG construction and reasoning) çš„æœ‰ç›‘ç£å¾®è°ƒæ¡†æ¶ã€‚é’ˆå¯¹ç°æœ‰ Chain-of-Thought (CoT) ç­‰æ¨ç†æ–¹æ³•åœ¨è¯­è¨€ Token çº§åˆ«æ“ä½œã€ç¼ºä¹å¯¹å˜é‡é—´å› æœå…³ç³»å»ºæ¨¡èƒ½åŠ›çš„å±€é™æ€§ï¼ŒCDCR-SFT è®­ç»ƒæ¨¡å‹æ˜¾å¼æ„å»ºå˜é‡çº§çš„æœ‰å‘æ— ç¯å›¾ (DAG) å¹¶åœ¨æ­¤åŸºç¡€ä¸Šè¿›è¡Œæ¨ç†ã€‚ä¸ºäº†æ”¯æŒè¯¥æ¡†æ¶ï¼Œç ”ç©¶å›¢é˜Ÿæ„å»ºäº†åŒ…å« 25,368 ä¸ªæ ·æœ¬çš„ CausalDR æ•°æ®é›†ï¼Œä¸ºæ¯ä¸ªæ ·æœ¬æä¾›æ˜¾å¼å› æœå›¾å’Œæ¨ç†è·¯å¾„ã€‚å®éªŒç»“æœæ˜¾ç¤ºï¼Œè¯¥æ–¹æ³•åœ¨ CLADDER ä»»åŠ¡ä¸Šè¾¾åˆ°äº† 95.33% çš„å‡†ç¡®ç‡ï¼Œé¦–æ¬¡è¶…è¶Šäº†äººç±»è¡¨ç°ï¼Œå¹¶åœ¨ HaluEval ä»»åŠ¡ä¸Šæå‡äº† 10% çš„æ€§èƒ½ï¼Œæ˜¾è‘—é™ä½äº†æ¨¡å‹å¹»è§‰ã€‚è¯¥ç ”ç©¶è¯æ˜æ˜¾å¼å› æœç»“æ„å»ºæ¨¡èƒ½å¤Ÿæœ‰æ•ˆç¼“è§£è¾“å‡ºä¸­çš„é€»è¾‘ä¸ä¸€è‡´æ€§ï¼Œä¸ºæå‡ LLMs çš„é€»è¾‘ä¸¥å¯†æ€§æä¾›äº†æ–°è·¯å¾„ã€‚",
      "categories": [
        "cs.CL",
        "cs.AI",
        "cs.LG"
      ],
      "primary_category": "cs.CL",
      "comment": "",
      "pdf_url": "https://arxiv.org/pdf/2508.12495v2",
      "published_date": "2025-08-17 20:51:06 UTC",
      "updated_date": "2025-11-12 04:44:20 UTC",
      "processing_status": "completed",
      "attempts": 1,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "llm_backup_calls": 0,
      "last_update": "2026-01-24T12:21:35.700358+00:00"
    },
    {
      "arxiv_id": "2508.12487v1",
      "title": "Advanced DOA Regulation with a Whale-Optimized Fractional Order Fuzzy PID Framework",
      "title_zh": "åŸºäºé²¸é±¼ä¼˜åŒ–åˆ†æ•°é˜¶æ¨¡ç³ŠPIDæ¡†æ¶çš„å…ˆè¿›éº»é†‰æ·±åº¦è°ƒæ§",
      "authors": [
        "Lida Shahbandari",
        "Hossein Mohseni"
      ],
      "abstract": "This study introduces a Fractional Order Fuzzy PID (FOFPID) controller that uses the Whale Optimization Algorithm (WOA) to manage the Bispectral Index (BIS), keeping it within the ideal range of forty to sixty. The FOFPID controller combines fuzzy logic for adapting to changes and fractional order dynamics for fine tuning. This allows it to adjust its control gains to handle a person's unique physiology. The WOA helps fine tune the controller's parameters, including the fractional orders and the fuzzy membership functions, which boosts its performance. Tested on models of eight different patient profiles, the FOFPID controller performed better than a standard Fractional Order PID (FOPID) controller. It achieved faster settling times, at two and a half minutes versus three point two minutes, and had a lower steady state error, at zero point five versus one point two. These outcomes show the FOFPID's excellent strength and accuracy. It offers a scalable, artificial intelligence driven solution for automated anesthesia delivery that could enhance clinical practice and improve patient results.",
      "tldr_zh": "è¯¥ç ”ç©¶æå‡ºäº†ä¸€ç§åŸºäºé²¸é±¼ä¼˜åŒ–ç®—æ³•(Whale Optimization Algorithm, WOA)çš„åˆ†æ•°é˜¶æ¨¡ç³ŠPID(Fractional Order Fuzzy PID, FOFPID)æ§åˆ¶å™¨ï¼Œæ—¨åœ¨é€šè¿‡ç²¾ç¡®è°ƒèŠ‚åŒé¢‘æŒ‡æ•°(Bispectral Index, BIS)æ¥ç»´æŒç†æƒ³çš„éº»é†‰æ·±åº¦(DOA)ã€‚è¯¥æ¡†æ¶ç»“åˆäº†æ¨¡ç³Šé€»è¾‘(Fuzzy Logic)çš„è‡ªé€‚åº”èƒ½åŠ›ä¸åˆ†æ•°é˜¶åŠ¨åŠ›å­¦(Fractional Order Dynamics)çš„å¾®è°ƒç‰¹æ€§ï¼Œèƒ½å¤Ÿæ ¹æ®æ‚£è€…ç‹¬ç‰¹çš„ç”Ÿç†çŠ¶å†µåŠ¨æ€è°ƒæ•´æ§åˆ¶å¢ç›Šã€‚ç ”ç©¶åˆ©ç”¨WOAå¯¹æ§åˆ¶å™¨çš„åˆ†æ•°é˜¶å‚æ•°åŠæ¨¡ç³Šéš¶å±åº¦å‡½æ•°è¿›è¡ŒååŒä¼˜åŒ–ï¼Œæ˜¾è‘—å¢å¼ºäº†æ§åˆ¶æ€§èƒ½ã€‚åœ¨å…«ç§ä¸åŒæ‚£è€…æ¨¡å‹ä¸Šçš„æµ‹è¯•ç»“æœè¡¨æ˜ï¼ŒFOFPIDæ§åˆ¶å™¨åœ¨ç¨³å®šæ—¶é—´(2.5åˆ†é’Ÿå¯¹3.2åˆ†é’Ÿ)å’Œç¨³æ€è¯¯å·®(0.5å¯¹1.2)æ–¹é¢å‡ä¼˜äºæ ‡å‡†åˆ†æ•°é˜¶PID(FOPID)æ§åˆ¶å™¨ã€‚è¿™ä¸€æˆæœè¯æ˜äº†FOFPIDç³»ç»Ÿå“è¶Šçš„é²æ£’æ€§ä¸ç²¾ç¡®åº¦ï¼Œä¸ºè‡ªåŠ¨åŒ–éº»é†‰ç»™è¯æä¾›äº†ä¸€ç§å¯æ‰©å±•çš„äººå·¥æ™ºèƒ½é©±åŠ¨æ–¹æ¡ˆï¼Œå…·æœ‰æå‡ä¸´åºŠå®è·µå’Œæ”¹å–„æ‚£è€…é¢„åçš„æ½œåŠ›ã€‚",
      "categories": [
        "cs.AI",
        "eess.SY"
      ],
      "primary_category": "cs.AI",
      "comment": "",
      "pdf_url": "https://arxiv.org/pdf/2508.12487v1",
      "published_date": "2025-08-17 20:01:49 UTC",
      "updated_date": "2025-08-17 20:01:49 UTC",
      "processing_status": "completed",
      "attempts": 1,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "llm_backup_calls": 0,
      "last_update": "2026-01-24T12:21:49.184478+00:00"
    },
    {
      "arxiv_id": "2508.12485v1",
      "title": "Cold-RL: Learning Cache Eviction with Offline Reinforcement Learning for NGINX",
      "title_zh": "Cold-RLï¼šåŸºäºç¦»çº¿å¼ºåŒ–å­¦ä¹ çš„ NGINX ç¼“å­˜æ·˜æ±°ç­–ç•¥",
      "authors": [
        "Aayush Gupta",
        "Arpit Bhayani"
      ],
      "abstract": "Web proxies such as NGINX commonly rely on least-recently-used (LRU) eviction, which is size agnostic and can thrash under periodic bursts and mixed object sizes. We introduce Cold-RL, a learned eviction policy for NGINX that replaces LRU's forced-expire path with a dueling Deep Q-Network served by an ONNX sidecar within a strict microsecond budget. On each eviction, Cold-RL samples the K least-recently-used objects, extracts six lightweight features (age, size, hit count, inter-arrival time, remaining TTL, and last origin RTT), and requests a bitmask of victims; a hard timeout of 500 microseconds triggers immediate fallback to native LRU. Policies are trained offline by replaying NGINX access logs through a cache simulator with a simple reward: a retained object earns one point if it is hit again before TTL expiry. We compare against LRU, LFU, size-based, adaptive LRU, and a hybrid baseline on two adversarial workloads. With a 25 MB cache, Cold-RL raises hit ratio from 0.1436 to 0.3538, a 146 percent improvement over the best classical baseline; at 100 MB, from 0.7530 to 0.8675, a 15 percent gain; and at 400 MB it matches classical methods (about 0.918). Inference adds less than 2 percent CPU overhead and keeps 95th percentile eviction latency within budget. To our knowledge, this is the first reinforcement learning eviction policy integrated into NGINX with strict SLOs.",
      "tldr_zh": "æœ¬ç ”ç©¶é’ˆå¯¹ NGINX ç­‰ Web ä»£ç†åœ¨ Least-Recently-Used (LRU) æ·˜æ±°ç­–ç•¥ä¸‹éš¾ä»¥åº”å¯¹å¯¹è±¡å¤§å°å·®å¼‚åŠå‘¨æœŸæ€§æµé‡å†²å‡»çš„é—®é¢˜ï¼Œæå‡ºäº† Cold-RL ç¼“å­˜æ·˜æ±°ç­–ç•¥ã€‚è¯¥æ–¹æ¡ˆé‡‡ç”¨ç¦»çº¿å¼ºåŒ–å­¦ä¹  (Offline Reinforcement Learning) è®­ç»ƒ Dueling Deep Q-Network æ¨¡å‹ï¼Œå¹¶é€šè¿‡ ONNX ä¾§è½¦åœ¨å¾®ç§’çº§æ—¶é—´é¢„ç®—å†…æ›¿ä»£ LRU è·¯å¾„ã€‚Cold-RL åˆ©ç”¨å¹´é¾„ã€å¤§å°ã€å‘½ä¸­è®¡æ•°ç­‰å…­é¡¹è½»é‡çº§ç‰¹å¾è¿›è¡Œå†³ç­–ï¼Œå¹¶è®¾ç½® 500 å¾®ç§’çš„ç¡¬è¶…æ—¶æœºåˆ¶ä»¥ç¡®ä¿æœåŠ¡ç­‰çº§åè®® (SLOs) çš„ç¨³å®šæ€§ã€‚å®éªŒç»“æœè¡¨æ˜ï¼Œåœ¨ 25 MB ç¼“å­˜åœºæ™¯ä¸‹ï¼ŒCold-RL çš„å‘½ä¸­ç‡ (Hit Ratio) è¾ƒä¼ ç»ŸåŸºå‡†æå‡äº† 146%ï¼Œå¹¶åœ¨é«˜å®¹é‡åœºæ™¯ä¸‹ä¿æŒäº†æå…·ç«äº‰åŠ›çš„æ€§èƒ½ã€‚è¯¥ç ”ç©¶æ˜¯é¦–ä¸ªæˆåŠŸé›†æˆåˆ° NGINX ä¸”æ»¡è¶³ä¸¥æ ¼å»¶è¿Ÿçº¦æŸçš„å¼ºåŒ–å­¦ä¹ æ·˜æ±°ç­–ç•¥ï¼Œå…¶å®é™… CPU å¼€é”€å¢å¹…ä¸è¶³ 2%ã€‚",
      "categories": [
        "cs.LG",
        "cs.AI",
        "cs.DB",
        "cs.NI"
      ],
      "primary_category": "cs.LG",
      "comment": "8 pages, 4 figures (system architecture, eviction path, training pipeline, and DQN algorithm), 2 tables. Code available at https://github.com/ayushgupta4897/DRL-Cache",
      "pdf_url": "https://arxiv.org/pdf/2508.12485v1",
      "published_date": "2025-08-17 20:01:12 UTC",
      "updated_date": "2025-08-17 20:01:12 UTC",
      "processing_status": "completed",
      "attempts": 1,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "llm_backup_calls": 0,
      "last_update": "2026-01-24T12:21:42.487106+00:00"
    },
    {
      "arxiv_id": "2508.12480v1",
      "title": "The Yokai Learning Environment: Tracking Beliefs Over Space and Time",
      "title_zh": "Yokai å­¦ä¹ ç¯å¢ƒï¼šè·¨è¶Šç©ºé—´ä¸æ—¶é—´çš„ä¿¡å¿µè¿½è¸ª",
      "authors": [
        "Constantin Ruhdorfer",
        "Matteo Bortoletto",
        "Andreas Bulling"
      ],
      "abstract": "Developing collaborative AI hinges on Theory of Mind (ToM) - the ability to reason about the beliefs of others to build and maintain common ground. Existing ToM benchmarks, however, are restricted to passive observer settings or lack an assessment of how agents establish and maintain common ground over time. To address these gaps, we introduce the Yokai Learning Environment (YLE) - a multi-agent reinforcement learning (RL) environment based on the cooperative card game Yokai. In the YLE, agents take turns peeking at hidden cards and moving them to form clusters based on colour. Success requires tracking evolving beliefs, remembering past observations, using hints as grounded communication, and maintaining common ground with teammates. Our evaluation yields two key findings: First, current RL agents struggle to solve the YLE, even when given access to perfect memory. Second, while belief modelling improves performance, agents are still unable to effectively generalise to unseen partners or form accurate beliefs over longer games, exposing a reliance on brittle conventions rather than robust belief tracking. We use the YLE to investigate research questions in belief modelling, memory, partner generalisation, and scaling to higher-order ToM.",
      "tldr_zh": "è¯¥ç ”ç©¶å¼•å…¥äº† Yokai Learning Environment (YLE)ï¼Œè¿™æ˜¯ä¸€ä¸ªåŸºäºåä½œçº¸ç‰Œæ¸¸æˆ Yokai çš„å¤šæ™ºèƒ½ä½“å¼ºåŒ–å­¦ä¹  (Multi-Agent Reinforcement Learning) ç¯å¢ƒï¼Œæ—¨åœ¨è§£å†³ç°æœ‰å¿ƒç†ç†è®º (Theory of Mind) åŸºå‡†æµ‹è¯•å±€é™äºè¢«åŠ¨è§‚å¯Ÿæˆ–ç¼ºä¹å¯¹å…±è¯† (Common Ground) åŠ¨æ€ç»´æŠ¤è¯„ä¼°çš„é—®é¢˜ã€‚åœ¨ YLE ä¸­ï¼Œæ™ºèƒ½ä½“å¿…é¡»é€šè¿‡æŸ¥çœ‹éšè—å¡ç‰‡å¹¶æŒ‰é¢œè‰²èšç±»æ¥åä½œï¼Œè¿™è¦æ±‚å…¶å…·å¤‡è·Ÿè¸ªä¸æ–­æ¼”åŒ–çš„ä¿¡å¿µã€è®°å¿†å†å²è§‚æµ‹ä»¥åŠåˆ©ç”¨æç¤ºè¿›è¡Œ Grounded Communication çš„èƒ½åŠ›ã€‚å®éªŒè¯„ä¼°æ˜¾ç¤ºï¼Œç›®å‰çš„å¼ºåŒ–å­¦ä¹ æ™ºèƒ½ä½“å³ä½¿åœ¨æ‹¥æœ‰å®Œç¾è®°å¿†çš„æƒ…å†µä¸‹ï¼Œä¹Ÿéš¾ä»¥æœ‰æ•ˆè§£å†³ YLE ä¸­çš„æŒ‘æˆ˜ã€‚ç ”ç©¶å‘ç°è™½ç„¶ä¿¡å¿µå»ºæ¨¡ (Belief Modelling) èƒ½æå‡æ€§èƒ½ï¼Œä½†æ™ºèƒ½ä½“åœ¨é¢å¯¹é™Œç”Ÿä¼™ä¼´çš„æ³›åŒ–æ€§ (Partner Generalisation) ä»¥åŠåœ¨é•¿å±€æ¸¸æˆä¸­ç»´æŒå‡†ç¡®ä¿¡å¿µæ–¹é¢è¡¨ç°ä¸ä½³ã€‚è¿™æ­ç¤ºäº†ç°æœ‰æ¨¡å‹å¾€å¾€ä¾èµ–äºè„†å¼±çš„çº¦å®šè€Œéç¨³å¥çš„ä¿¡å¿µè·Ÿè¸ªï¼ŒYLE ä¸ºæ¢ç´¢è®°å¿†ã€ä¼™ä¼´æ³›åŒ–åŠé«˜é˜¶å¿ƒç†ç†è®ºç­‰å…³é”®ç ”ç©¶è¯¾é¢˜æä¾›äº†é‡è¦å¹³å°ã€‚",
      "categories": [
        "cs.AI",
        "cs.LG",
        "cs.MA"
      ],
      "primary_category": "cs.AI",
      "comment": "Presented at the the ToM IJCAI 2025 Workshop",
      "pdf_url": "https://arxiv.org/pdf/2508.12480v1",
      "published_date": "2025-08-17 19:42:17 UTC",
      "updated_date": "2025-08-17 19:42:17 UTC",
      "processing_status": "completed",
      "attempts": 1,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "llm_backup_calls": 0,
      "last_update": "2026-01-24T12:22:10.096840+00:00"
    },
    {
      "arxiv_id": "2508.12479v1",
      "title": "EXOTIC: An Exact, Optimistic, Tree-Based Algorithm for Min-Max Optimization",
      "title_zh": "EXOTICï¼šä¸€ç§ç”¨äºæå°æå¤§ä¼˜åŒ–çš„ç²¾ç¡®ã€ä¹è§‚ã€åŸºäºæ ‘çš„ç®—æ³•",
      "authors": [
        "Chinmay Maheshwari",
        "Chinmay Pimpalkhare",
        "Debasish Chatterjee"
      ],
      "abstract": "Min-max optimization arises in many domains such as game theory, adversarial machine learning, etc., with gradient-based methods as a typical computational tool. Beyond convex-concave min-max optimization, the solutions found by gradient-based methods may be arbitrarily far from global optima. In this work, we present an algorithmic apparatus for computing globally optimal solutions in convex-non-concave and non-convex-concave min-max optimization. For former, we employ a reformulation that transforms it into a non-concave-convex max-min optimization problem with suitably defined feasible sets and objective function. The new form can be viewed as a generalization of Sion's minimax theorem. Next, we introduce EXOTIC-an Exact, Optimistic, Tree-based algorithm for solving the reformulated max-min problem. EXOTIC employs an iterative convex optimization solver to (approximately) solve the inner minimization and a hierarchical tree search for the outer maximization to optimistically select promising regions to search based on the approximate solution returned by convex optimization solver. We establish an upper bound on its optimality gap as a function of the number of calls to the inner solver, the solver's convergence rate, and additional problem-dependent parameters. Both our algorithmic apparatus along with its accompanying theoretical analysis can also be applied for non-convex-concave min-max optimization. In addition, we propose a class of benchmark convex-non-concave min-max problems along with their analytical global solutions, providing a testbed for evaluating algorithms for min-max optimization. Empirically, EXOTIC outperforms gradient-based methods on this benchmark as well as on existing numerical benchmark problems from the literature. Finally, we demonstrate the utility of EXOTIC by computing security strategies in multi-player games with three or more players.",
      "tldr_zh": "è¯¥ç ”ç©¶é’ˆå¯¹åšå¼ˆè®ºå’Œå¯¹æŠ—æ€§æœºå™¨å­¦ä¹ ä¸­çš„ Min-max ä¼˜åŒ–é—®é¢˜ï¼Œæå‡ºäº†ä¸€ç§åä¸º EXOTIC çš„ç²¾ç¡®ã€ä¹è§‚ä¸”åŸºäºæ ‘ç»“æ„çš„å…¨å±€ä¼˜åŒ–ç®—æ³•ï¼Œæ—¨åœ¨è§£å†³æ¢¯åº¦æ–¹æ³•åœ¨éå‡¸-éå‡¹è®¾å®šä¸‹éš¾ä»¥æ±‚å¾—å…¨å±€æœ€ä¼˜è§£çš„å±€é™ã€‚è¯¥ç®—æ³•é€šè¿‡å°†åŸé—®é¢˜é‡æ„ä¸º max-min å½¢å¼ï¼Œå®ç°äº†å¯¹ Sion's minimax theorem çš„æ¨å¹¿ï¼Œå¹¶ç»“åˆè¿­ä»£å‡¸ä¼˜åŒ–æ±‚è§£å™¨å¤„ç† inner minimization ä»¥åŠå±‚æ¬¡åŒ–æ ‘æœç´¢ (hierarchical tree search) æ‰§è¡Œ outer maximizationã€‚ç ”ç©¶å›¢é˜Ÿä¸ä»…ä¸º EXOTIC å»ºç«‹äº†å…³äºæœ€ä¼˜æ€§é—´éš™ (optimality gap) çš„ç†è®ºä¸Šç•Œï¼Œè¿˜æå‡ºäº†ä¸€å¥—å¸¦æœ‰è§£æè§£çš„æ–°åŸºå‡†æµ‹è¯•é›†ã€‚å®éªŒç»“æœè¡¨æ˜ï¼ŒEXOTIC åœ¨åŸºå‡†æµ‹è¯•ä¸­çš„è¡¨ç°æ˜¾è‘—ä¼˜äºä¼ ç»Ÿçš„æ¢¯åº¦ç±»æ–¹æ³•ã€‚æ­¤å¤–ï¼Œè¯¥ç®—æ³•å·²æˆåŠŸåº”ç”¨äºè®¡ç®—ä¸‰äººåŠä»¥ä¸Šå¤šç©å®¶åšå¼ˆ (multi-player games) ä¸­çš„å®‰å…¨ç­–ç•¥ï¼Œè¯æ˜äº†å…¶åœ¨å¤æ‚å†³ç­–åœºæ™¯ä¸‹çš„å®ç”¨ä»·å€¼ã€‚",
      "categories": [
        "math.OC",
        "cs.AI",
        "cs.GT",
        "cs.MA",
        "econ.GN"
      ],
      "primary_category": "math.OC",
      "comment": "31 pages, 2 figures, 3 tables",
      "pdf_url": "https://arxiv.org/pdf/2508.12479v1",
      "published_date": "2025-08-17 19:39:19 UTC",
      "updated_date": "2025-08-17 19:39:19 UTC",
      "processing_status": "completed",
      "attempts": 1,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "llm_backup_calls": 0,
      "last_update": "2026-01-24T12:22:24.285525+00:00"
    },
    {
      "arxiv_id": "2508.12473v1",
      "title": "Standardization of Neuromuscular Reflex Analysis -- Role of Fine-Tuned Vision-Language Model Consortium and OpenAI gpt-oss Reasoning LLM Enabled Decision Support System",
      "title_zh": "ç¥ç»è‚Œè‚‰åå°„åˆ†æçš„æ ‡å‡†åŒ–ï¼šå¾®è°ƒè§†è§‰è¯­è¨€æ¨¡å‹è”ç›Ÿä¸ OpenAI gpt-oss æ¨ç†å¤§è¯­è¨€æ¨¡å‹èµ‹èƒ½çš„å†³ç­–æ”¯æŒç³»ç»Ÿæ‰€å‘æŒ¥çš„ä½œç”¨",
      "authors": [
        "Eranga Bandara",
        "Ross Gore",
        "Sachin Shetty",
        "Ravi Mukkamala",
        "Christopher Rhea",
        "Atmaram Yarlagadda",
        "Shaifali Kaushik",
        "L. H. M. P. De Silva",
        "Andriy Maznychenko",
        "Inna Sokolowska",
        "Amin Hass",
        "Kasun De Zoysa"
      ],
      "abstract": "Accurate assessment of neuromuscular reflexes, such as the H-reflex, plays a critical role in sports science, rehabilitation, and clinical neurology. Traditional analysis of H-reflex EMG waveforms is subject to variability and interpretation bias among clinicians and researchers, limiting reliability and standardization. To address these challenges, we propose a Fine-Tuned Vision-Language Model (VLM) Consortium and a reasoning Large-Language Model (LLM)-enabled Decision Support System for automated H-reflex waveform interpretation and diagnosis. Our approach leverages multiple VLMs, each fine-tuned on curated datasets of H-reflex EMG waveform images annotated with clinical observations, recovery timelines, and athlete metadata. These models are capable of extracting key electrophysiological features and predicting neuromuscular states, including fatigue, injury, and recovery, directly from EMG images and contextual metadata. Diagnostic outputs from the VLM consortium are aggregated using a consensus-based method and refined by a specialized reasoning LLM, which ensures robust, transparent, and explainable decision support for clinicians and sports scientists. The end-to-end platform orchestrates seamless communication between the VLM ensemble and the reasoning LLM, integrating prompt engineering strategies and automated reasoning workflows using LLM Agents. Experimental results demonstrate that this hybrid system delivers highly accurate, consistent, and interpretable H-reflex assessments, significantly advancing the automation and standardization of neuromuscular diagnostics. To our knowledge, this work represents the first integration of a fine-tuned VLM consortium with a reasoning LLM for image-based H-reflex analysis, laying the foundation for next-generation AI-assisted neuromuscular assessment and athlete monitoring platforms.",
      "tldr_zh": "ç¥ç»è‚Œè‚‰åå°„ï¼ˆå¦‚ H-reflexï¼‰çš„å‡†ç¡®è¯„ä¼°åœ¨è¿åŠ¨ç§‘å­¦å’Œä¸´åºŠç¥ç»å­¦ä¸­è‡³å…³é‡è¦ï¼Œä½†ä¼ ç»Ÿçš„è‚Œç”µå›¾ï¼ˆEMGï¼‰æ³¢å½¢åˆ†æå­˜åœ¨æ˜¾è‘—çš„äººä¸ºè§£é‡Šåå·®ä¸”ç¼ºä¹æ ‡å‡†åŒ–ã€‚ä¸ºæ­¤ï¼Œè¯¥ç ”ç©¶æå‡ºäº†ä¸€ç§ç»“åˆå¾®è°ƒè§†è§‰è¯­è¨€æ¨¡å‹ï¼ˆVLMï¼‰è”ç›Ÿä¸æ¨ç†å¤§è¯­è¨€æ¨¡å‹ï¼ˆLLMï¼‰çš„å†³ç­–æ”¯æŒç³»ç»Ÿï¼Œæ—¨åœ¨å®ç°è‡ªåŠ¨åŒ–çš„ H-reflex æ³¢å½¢è§£è¯»å’Œè¯Šæ–­ã€‚è¯¥ç³»ç»Ÿåˆ©ç”¨å¤šä¸ªåœ¨ç‰¹å®š H-reflex EMG å›¾åƒåŠå…ƒæ•°æ®ä¸Šå¾®è°ƒçš„ VLM æ¨¡å‹ï¼Œèƒ½å¤Ÿç›´æ¥ä»å›¾åƒä¸­æå–ç”µç”Ÿç†ç‰¹å¾å¹¶é¢„æµ‹ç–²åŠ³ã€æŸä¼¤åŠæ¢å¤ç­‰ç¥ç»è‚Œè‚‰çŠ¶æ€ã€‚VLM è”ç›Ÿçš„è¾“å‡ºé€šè¿‡å…±è¯†æœºåˆ¶æ±‡æ€»ï¼Œå¹¶ç”±ä¸“é—¨çš„æ¨ç† LLM è¿›è¡Œè¿›ä¸€æ­¥ç²¾ç‚¼ï¼Œç¡®ä¿äº†å†³ç­–æ”¯æŒçš„é²æ£’æ€§ã€é€æ˜åº¦ä¸å¯è§£é‡Šæ€§ã€‚è¯¥å¹³å°é€šè¿‡ LLM Agents åè°ƒ VLM é›†ç¾¤ä¸æ¨ç†æ¨¡å‹é—´çš„é€šä¿¡ï¼Œå¹¶æ•´åˆäº†å¤æ‚çš„æç¤ºå·¥ç¨‹ä¸è‡ªåŠ¨åŒ–æ¨ç†å·¥ä½œæµã€‚å®éªŒç»“æœè¯æ˜ï¼Œè¯¥æ··åˆç³»ç»Ÿåœ¨ H-reflex è¯„ä¼°ä¸­è¡¨ç°å‡ºæé«˜çš„å‡†ç¡®æ€§å’Œä¸€è‡´æ€§ï¼Œæ˜¾è‘—æ¨è¿›äº†ç¥ç»è‚Œè‚‰è¯Šæ–­çš„è‡ªåŠ¨åŒ–è¿›ç¨‹ã€‚ä½œä¸ºé¦–ä¸ªå°†å¾®è°ƒ VLM è”ç›Ÿä¸æ¨ç† LLM é›†æˆç”¨äºå›¾åƒåŒ–åå°„åˆ†æçš„ç ”ç©¶ï¼Œè¯¥æˆæœä¸ºä¸‹ä¸€ä»£ AI è¾…åŠ©ç¥ç»è‚Œè‚‰ç›‘æµ‹å¹³å°å¥ å®šäº†åšå®åŸºç¡€ã€‚",
      "categories": [
        "cs.CV",
        "cs.AI"
      ],
      "primary_category": "cs.CV",
      "comment": "",
      "pdf_url": "https://arxiv.org/pdf/2508.12473v1",
      "published_date": "2025-08-17 19:13:27 UTC",
      "updated_date": "2025-08-17 19:13:27 UTC",
      "processing_status": "completed",
      "attempts": 1,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "llm_backup_calls": 0,
      "last_update": "2026-01-24T12:22:17.397944+00:00"
    },
    {
      "arxiv_id": "2508.12472v1",
      "title": "GALA: Can Graph-Augmented Large Language Model Agentic Workflows Elevate Root Cause Analysis?",
      "title_zh": "GALAï¼šå›¾å¢å¼ºå¤§è¯­è¨€æ¨¡å‹æ™ºèƒ½ä½“å·¥ä½œæµèƒ½å¦æå‡æ ¹å› åˆ†æï¼Ÿ",
      "authors": [
        "Yifang Tian",
        "Yaming Liu",
        "Zichun Chong",
        "Zihang Huang",
        "Hans-Arno Jacobsen"
      ],
      "abstract": "Root cause analysis (RCA) in microservice systems is challenging, requiring on-call engineers to rapidly diagnose failures across heterogeneous telemetry such as metrics, logs, and traces. Traditional RCA methods often focus on single modalities or merely rank suspect services, falling short of providing actionable diagnostic insights with remediation guidance. This paper introduces GALA, a novel multi-modal framework that combines statistical causal inference with LLM-driven iterative reasoning for enhanced RCA. Evaluated on an open-source benchmark, GALA achieves substantial improvements over state-of-the-art methods of up to 42.22% accuracy. Our novel human-guided LLM evaluation score shows GALA generates significantly more causally sound and actionable diagnostic outputs than existing methods. Through comprehensive experiments and a case study, we show that GALA bridges the gap between automated failure diagnosis and practical incident resolution by providing both accurate root cause identification and human-interpretable remediation guidance.",
      "tldr_zh": "è¯¥ç ”ç©¶é’ˆå¯¹å¾®æœåŠ¡ç³»ç»Ÿä¸­æ ¹å› åˆ†æ(Root Cause Analysis, RCA)åœ¨å¤„ç†æŒ‡æ ‡(metrics)ã€æ—¥å¿—(logs)å’Œè¿½è¸ª(traces)ç­‰å¼‚æ„é¥æµ‹æ•°æ®æ—¶çš„å¤æ‚æŒ‘æˆ˜ï¼Œæå‡ºäº†åä¸ºGALAçš„æ–°å‹å¤šæ¨¡æ€æ¡†æ¶ã€‚GALAåˆ›æ–°æ€§åœ°å°†ç»Ÿè®¡å› æœæ¨ç†(statistical causal inference)ä¸å¤§è¯­è¨€æ¨¡å‹(LLM)é©±åŠ¨çš„è¿­ä»£æ¨ç†ç›¸ç»“åˆï¼Œåˆ©ç”¨å›¾å¢å¼ºçš„æ™ºèƒ½ä½“å·¥ä½œæµ(Graph-Augmented Agentic Workflows)æå‡è¯Šæ–­æ•ˆèƒ½ã€‚å®éªŒç»“æœæ˜¾ç¤ºï¼ŒGALAåœ¨å¼€æºåŸºå‡†æµ‹è¯•ä¸­çš„å‡†ç¡®ç‡æ¯”ç°æœ‰æœ€å…ˆè¿›æ–¹æ³•æå‡äº†é«˜è¾¾42.22%ã€‚é€šè¿‡å¼•å…¥äººç±»å¼•å¯¼çš„LLMè¯„ä¼°è¯„åˆ†ï¼Œè¯¥ç ”ç©¶è¯æ˜GALAç”Ÿæˆçš„è¯Šæ–­è¾“å‡ºåœ¨å› æœé€»è¾‘ä¸€è‡´æ€§å’Œå®é™…å¯æ“ä½œæ€§æ–¹é¢æ˜¾è‘—ä¼˜äºä¼ ç»Ÿæ–¹æ³•ã€‚GALAæˆåŠŸå¼¥è¡¥äº†è‡ªåŠ¨åŒ–æ•…éšœè¯Šæ–­ä¸å®é™…äº‹ä»¶ä¿®å¤ä¹‹é—´çš„å·®è·ï¼Œä¸ä»…èƒ½å®ç°ç²¾å‡†çš„æ ¹å› è¯†åˆ«ï¼Œè¿˜èƒ½æä¾›äººç±»å¯è§£é‡Šçš„ä¿®å¤æŒ‡å¯¼å»ºè®®ã€‚",
      "categories": [
        "cs.AI"
      ],
      "primary_category": "cs.AI",
      "comment": "12 pages, 5 figures",
      "pdf_url": "https://arxiv.org/pdf/2508.12472v1",
      "published_date": "2025-08-17 19:12:05 UTC",
      "updated_date": "2025-08-17 19:12:05 UTC",
      "processing_status": "completed",
      "attempts": 1,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "llm_backup_calls": 0,
      "last_update": "2026-01-24T12:22:22.282437+00:00"
    },
    {
      "arxiv_id": "2508.13231v2",
      "title": "Accelerating LLM Inference via Dynamic KV Cache Placement in Heterogeneous Memory System",
      "title_zh": "å¼‚æ„å†…å­˜ç³»ç»Ÿä¸­åŸºäºåŠ¨æ€ KV ç¼“å­˜æ”¾ç½®çš„ LLM æ¨ç†åŠ é€Ÿ",
      "authors": [
        "Yunhua Fang",
        "Rui Xie",
        "Asad Ul Haq",
        "Linsen Ma",
        "Kaoutar El Maghraoui",
        "Naigang Wang",
        "Meng Wang",
        "Liu Liu",
        "Tong Zhang"
      ],
      "abstract": "Large Language Model (LLM) inference is increasingly constrained by memory bandwidth, with frequent access to the key-value (KV) cache dominating data movement. While attention sparsity reduces some memory traffic, the relevance of past tokens varies over time, requiring the full KV cache to remain accessible and sustaining pressure on both bandwidth and capacity. With advances in interconnects such as NVLink and LPDDR5X, modern AI hardware now integrates high-bandwidth memory (HBM) with high-speed off-package DRAM, making heterogeneous memory systems a practical solution. This work investigates dynamic KV cache placement across such systems to maximize aggregated bandwidth utilization under capacity constraints. Rather than proposing a specific scheduling policy, we formulate the placement problem mathematically and derive a theoretical upper bound, revealing substantial headroom for runtime optimization. To our knowledge, this is the first formal treatment of dynamic KV cache scheduling in heterogeneous memory systems for LLM inference.",
      "tldr_zh": "è¯¥ç ”ç©¶æ¢è®¨äº†åœ¨å¼‚æ„å†…å­˜ç³»ç»Ÿ(Heterogeneous Memory System)ä¸­é€šè¿‡åŠ¨æ€é”®å€¼ç¼“å­˜æ”¾ç½®(Dynamic KV Cache Placement)æ¥åŠ é€Ÿå¤§è¯­è¨€æ¨¡å‹(LLM)æ¨ç†çš„æ–¹æ³•ã€‚é’ˆå¯¹LLMæ¨ç†ä¸­å†…å­˜å¸¦å®½(Memory Bandwidth)å—é™ä¸”KV Cacheè®¿é—®é¢‘ç¹çš„é—®é¢˜ï¼Œæœ¬æ–‡ç ”ç©¶äº†å¦‚ä½•åœ¨é«˜å¸¦å®½å†…å­˜(HBM)ä¸é«˜é€Ÿç‰‡å¤–DRAMä¹‹é—´ä¼˜åŒ–æ•°æ®å¸ƒå±€ã€‚ä½œè€…é€šè¿‡æ•°å­¦å»ºæ¨¡æ­£å¼å®šä¹‰äº†KV Cacheçš„æ”¾ç½®é—®é¢˜ï¼Œå¹¶æ¨å¯¼å‡ºäº†å¸¦å®½åˆ©ç”¨ç‡çš„ç†è®ºä¸Šé™(Theoretical Upper Bound)ã€‚ç ”ç©¶ç»“æœè¡¨æ˜ï¼Œé€šè¿‡åŠ¨æ€è°ƒåº¦ç­–ç•¥åœ¨å¼‚æ„å­˜å‚¨é—´åˆ†é…èµ„æºï¼Œå¯ä»¥æ˜¾è‘—æå‡ç³»ç»Ÿçš„èšåˆå¸¦å®½åˆ©ç”¨ç‡å¹¶å…‹æœå®¹é‡é™åˆ¶ã€‚è¯¥å·¥ä½œæ­ç¤ºäº†è¿è¡Œæ—¶ä¼˜åŒ–åœ¨ç°ä»£AIç¡¬ä»¶ç³»ç»Ÿä¸­çš„å·¨å¤§æ½œåŠ›ï¼Œæ˜¯é¦–æ¬¡é’ˆå¯¹å¼‚æ„å†…å­˜ç¯å¢ƒä¸‹LLMæ¨ç†çš„åŠ¨æ€KV Cacheè°ƒåº¦è¿›è¡Œçš„æ­£å¼ç†è®ºç ”ç©¶ã€‚",
      "categories": [
        "cs.AR",
        "cs.AI",
        "cs.PF"
      ],
      "primary_category": "cs.AR",
      "comment": "IEEE Computer Architecture Letter",
      "pdf_url": "https://arxiv.org/pdf/2508.13231v2",
      "published_date": "2025-08-17 19:07:08 UTC",
      "updated_date": "2025-09-15 14:40:16 UTC",
      "processing_status": "completed",
      "attempts": 1,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "llm_backup_calls": 0,
      "last_update": "2026-01-24T12:22:24.787463+00:00"
    },
    {
      "arxiv_id": "2508.12470v1",
      "title": "A Robust Cross-Domain IDS using BiGRU-LSTM-Attention for Medical and Industrial IoT Security",
      "title_zh": "åŸºäº BiGRU-LSTM-Attention çš„åŒ»ç–—ä¸å·¥ä¸šç‰©è”ç½‘å®‰å…¨é²æ£’è·¨åŸŸå…¥ä¾µæ£€æµ‹ç³»ç»Ÿ",
      "authors": [
        "Afrah Gueriani",
        "Hamza Kheddar",
        "Ahmed Cherif Mazari",
        "Mohamed Chahine Ghanem"
      ],
      "abstract": "The increased Internet of Medical Things IoMT and the Industrial Internet of Things IIoT interconnectivity has introduced complex cybersecurity challenges, exposing sensitive data, patient safety, and industrial operations to advanced cyber threats. To mitigate these risks, this paper introduces a novel transformer-based intrusion detection system IDS, termed BiGAT-ID a hybrid model that combines bidirectional gated recurrent units BiGRU, long short-term memory LSTM networks, and multi-head attention MHA. The proposed architecture is designed to effectively capture bidirectional temporal dependencies, model sequential patterns, and enhance contextual feature representation. Extensive experiments on two benchmark datasets, CICIoMT2024 medical IoT and EdgeIIoTset industrial IoT demonstrate the model's cross-domain robustness, achieving detection accuracies of 99.13 percent and 99.34 percent, respectively. Additionally, the model exhibits exceptional runtime efficiency, with inference times as low as 0.0002 seconds per instance in IoMT and 0.0001 seconds in IIoT scenarios. Coupled with a low false positive rate, BiGAT-ID proves to be a reliable and efficient IDS for deployment in real-world heterogeneous IoT environments",
      "tldr_zh": "è¯¥ç ”ç©¶é’ˆå¯¹åŒ»ç–—ç‰©è”ç½‘(IoMT)å’Œå·¥ä¸šç‰©è”ç½‘(IIoT)é¢ä¸´çš„å¤æ‚ç½‘ç»œå®‰å…¨æŒ‘æˆ˜ï¼Œæå‡ºäº†ä¸€ç§åä¸ºBiGAT-IDçš„æ–°å‹å…¥ä¾µæ£€æµ‹ç³»ç»Ÿ(IDS)ã€‚è¯¥æ··åˆæ¨¡å‹é€šè¿‡èåˆåŒå‘é—¨æ§å¾ªç¯å•å…ƒ(BiGRU)ã€é•¿çŸ­æœŸè®°å¿†ç½‘ç»œ(LSTM)å’Œå¤šå¤´æ³¨æ„åŠ›æœºåˆ¶(MHA)ï¼Œæ—¨åœ¨æœ‰æ•ˆæ•è·åŒå‘æ—¶é—´ä¾èµ–æ€§å¹¶å»ºæ¨¡åºåˆ—æ¨¡å¼ï¼Œä»è€Œå¢å¼ºä¸Šä¸‹æ–‡ç‰¹å¾è¡¨ç¤ºã€‚åœ¨CICIoMT2024å’ŒEdgeIIoTsetä¸¤ä¸ªåŸºå‡†æ•°æ®é›†ä¸Šçš„å®éªŒè¡¨æ˜ï¼ŒBiGAT-IDå…·æœ‰æ˜¾è‘—çš„è·¨é¢†åŸŸé²æ£’æ€§ï¼Œæ£€æµ‹å‡†ç¡®ç‡åˆ†åˆ«è¾¾åˆ°äº†99.13%å’Œ99.34%ã€‚æ­¤å¤–ï¼Œè¯¥æ¨¡å‹å±•ç°äº†å“è¶Šçš„è¿è¡Œæ•ˆç‡ï¼Œåœ¨ä¸åŒåœºæ™¯ä¸‹çš„å•æ¬¡æ¨ç†æ—¶é—´ä½è‡³0.0001è‡³0.0002ç§’é‡çº§ã€‚ç»“åˆæä½çš„è¯¯æŠ¥ç‡ï¼ŒBiGAT-IDè¢«è¯æ˜æ˜¯éƒ¨ç½²äºç°å®å¼‚æ„ç‰©è”ç½‘ç¯å¢ƒä¸­å¯é ä¸”é«˜æ•ˆçš„å®‰å…¨é˜²å¾¡è§£å†³æ–¹æ¡ˆã€‚",
      "categories": [
        "cs.CR",
        "cs.AI"
      ],
      "primary_category": "cs.CR",
      "comment": "10 pages",
      "pdf_url": "https://arxiv.org/pdf/2508.12470v1",
      "published_date": "2025-08-17 18:50:23 UTC",
      "updated_date": "2025-08-17 18:50:23 UTC",
      "processing_status": "completed",
      "attempts": 1,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "llm_backup_calls": 0,
      "last_update": "2026-01-24T12:22:32.286266+00:00"
    },
    {
      "arxiv_id": "2508.12466v1",
      "title": "Inverse-LLaVA: Eliminating Alignment Pre-training Through Text-to-Vision Mapping",
      "title_zh": "Inverse-LLaVAï¼šé€šè¿‡æ–‡æœ¬åˆ°è§†è§‰æ˜ å°„æ¶ˆé™¤å¯¹é½é¢„è®­ç»ƒ",
      "authors": [
        "Xuhui Zhan",
        "Tyler Derr"
      ],
      "abstract": "Traditional multimodal learning approaches require expensive alignment pre-training to bridge vision and language modalities, typically projecting visual features into discrete text token spaces. We challenge both fundamental assumptions underlying this paradigm by proposing Inverse-LLaVA, a novel approach that eliminates alignment pre-training entirely while inverting the conventional mapping direction. Rather than projecting visual features to text space, our method maps text embeddings into continuous visual representation space and performs fusion within transformer intermediate layers. Through selective additive components in attention mechanisms, we enable dynamic integration of visual and textual representations without requiring massive image-text alignment datasets. Comprehensive experiments across nine multimodal benchmarks demonstrate nuanced performance trade-offs: Inverse-LLaVA achieves notable improvements on reasoning-intensive and cognitive tasks (MM-VET: +0.2%, VizWiz: +1.8%, ScienceQA: +0.2%, cognitive reasoning: +27.2%), while showing expected decreases in perception tasks requiring memorized visual-text associations (celebrity recognition: -49.5%, OCR: -21.3%). These results provide the first empirical evidence that alignment pre-training is not necessary for effective multimodal learning, particularly for complex reasoning tasks. Our work establishes the feasibility of a new paradigm that reduces computational requirements by 45%, challenges conventional wisdom about modality fusion, and opens new research directions for efficient multimodal architectures that preserve modality-specific characteristics. Our project website with code and additional resources is available at https://inverse-llava.github.io.",
      "tldr_zh": "è¯¥ç ”ç©¶æå‡ºäº†Inverse-LLaVAï¼Œè¿™æ˜¯ä¸€ç§æ—¨åœ¨æ¶ˆé™¤ä¼ ç»Ÿå¤šæ¨¡æ€å­¦ä¹ ä¸­æ˜‚è´µçš„alignment pre-trainingçš„æ–°é¢–æ–¹æ³•ã€‚ä¸å°†è§†è§‰ç‰¹å¾æŠ•å°„åˆ°æ–‡æœ¬ç©ºé—´çš„å¸¸è§„èŒƒå¼ä¸åŒï¼Œè¯¥æ–¹æ³•é€šè¿‡å°†text embeddingsæ˜ å°„åˆ°è¿ç»­çš„visual representation spaceï¼Œå¹¶åœ¨transformerçš„ä¸­é—´å±‚å®ç°èåˆã€‚è¯¥æ¶æ„é€šè¿‡åœ¨æ³¨æ„åŠ›æœºåˆ¶ä¸­å¼•å…¥é€‰æ‹©æ€§åŠ æ³•ç»„ä»¶ï¼Œå®ç°äº†è§†è§‰å’Œæ–‡æœ¬è¡¨ç¤ºçš„åŠ¨æ€é›†æˆï¼Œä¸”æ— éœ€å¤§è§„æ¨¡çš„å›¾åƒæ–‡æœ¬å¯¹é½æ•°æ®é›†ã€‚å®éªŒç»“æœæ˜¾ç¤ºï¼ŒInverse-LLaVAåœ¨æ¨ç†å¯†é›†å‹å’Œè®¤çŸ¥ä»»åŠ¡ï¼ˆå¦‚MM-VETã€VizWizã€ScienceQAå’Œè®¤çŸ¥æ¨ç†ï¼‰ä¸Šå–å¾—äº†æ˜¾è‘—æå‡ï¼Œä½†åœ¨éœ€è¦è®°å¿†è§†è§‰-æ–‡æœ¬å…³è”çš„æ„ŸçŸ¥ä»»åŠ¡ï¼ˆå¦‚celebrity recognitionå’ŒOCRï¼‰ä¸­è¡¨ç°æœ‰æ‰€ä¸‹é™ã€‚è¿™é¡¹å·¥ä½œé¦–æ¬¡è¯æ˜äº†alignment pre-trainingå¯¹äºæœ‰æ•ˆçš„å¤šæ¨¡æ€å­¦ä¹ ï¼ˆå°¤å…¶æ˜¯å¤æ‚æ¨ç†ä»»åŠ¡ï¼‰å¹¶éå¿…è¦ï¼Œå¹¶åœ¨é™ä½45%è®¡ç®—éœ€æ±‚çš„åŒæ—¶ï¼Œä¸ºé«˜æ•ˆå¤šæ¨¡æ€æ¶æ„å¼€è¾Ÿäº†æ–°çš„ç ”ç©¶æ–¹å‘ã€‚",
      "categories": [
        "cs.CV",
        "cs.AI",
        "cs.LG"
      ],
      "primary_category": "cs.CV",
      "comment": "15pages, 3 figures",
      "pdf_url": "https://arxiv.org/pdf/2508.12466v1",
      "published_date": "2025-08-17 18:36:04 UTC",
      "updated_date": "2025-08-17 18:36:04 UTC",
      "processing_status": "completed",
      "attempts": 1,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "llm_backup_calls": 0,
      "last_update": "2026-01-24T12:22:38.844639+00:00"
    },
    {
      "arxiv_id": "2508.12448v1",
      "title": "Uncovering Emergent Physics Representations Learned In-Context by Large Language Models",
      "title_zh": "æ­ç¤ºå¤§è¯­è¨€æ¨¡å‹åœ¨ä¸Šä¸‹æ–‡å­¦ä¹ ä¸­ä¹ å¾—çš„æ¶Œç°ç‰©ç†è¡¨å¾",
      "authors": [
        "Yeongwoo Song",
        "Jaeyong Bae",
        "Dong-Kyum Kim",
        "Hawoong Jeong"
      ],
      "abstract": "Large language models (LLMs) exhibit impressive in-context learning (ICL) abilities, enabling them to solve wide range of tasks via textual prompts alone. As these capabilities advance, the range of applicable domains continues to expand significantly. However, identifying the precise mechanisms or internal structures within LLMs that allow successful ICL across diverse, distinct classes of tasks remains elusive. Physics-based tasks offer a promising testbed for probing this challenge. Unlike synthetic sequences such as basic arithmetic or symbolic equations, physical systems provide experimentally controllable, real-world data based on structured dynamics grounded in fundamental principles. This makes them particularly suitable for studying the emergent reasoning behaviors of LLMs in a realistic yet tractable setting. Here, we mechanistically investigate the ICL ability of LLMs, especially focusing on their ability to reason about physics. Using a dynamics forecasting task in physical systems as a proxy, we evaluate whether LLMs can learn physics in context. We first show that the performance of dynamics forecasting in context improves with longer input contexts. To uncover how such capability emerges in LLMs, we analyze the model's residual stream activations using sparse autoencoders (SAEs). Our experiments reveal that the features captured by SAEs correlate with key physical variables, such as energy. These findings demonstrate that meaningful physical concepts are encoded within LLMs during in-context learning. In sum, our work provides a novel case study that broadens our understanding of how LLMs learn in context.",
      "tldr_zh": "è¯¥ç ”ç©¶æ¢è®¨äº†å¤§è¯­è¨€æ¨¡å‹(LLMs)é€šè¿‡ä¸Šä¸‹æ–‡å­¦ä¹ (In-context learning, ICL)è·å–ç‰©ç†è¡¨å¾çš„æ¶Œç°èƒ½åŠ›ï¼Œæ—¨åœ¨æ­ç¤ºå…¶åœ¨å¤„ç†å¤æ‚ä»»åŠ¡æ—¶çš„å†…éƒ¨æœºåˆ¶ã€‚ç ”ç©¶äººå‘˜ä»¥ç‰©ç†ç³»ç»Ÿä¸­çš„åŠ¨åŠ›å­¦é¢„æµ‹(dynamics forecasting)ä»»åŠ¡ä¸ºå®éªŒå¯¹è±¡ï¼Œå‘ç°é¢„æµ‹æ€§èƒ½éšç€è¾“å…¥ä¸Šä¸‹æ–‡é•¿åº¦çš„å¢åŠ è€Œæ˜¾è‘—æå‡ã€‚ä¸ºäº†æ·±å…¥æ¢ç©¶å…¶å†…åœ¨åŸç†ï¼Œè¯¥é¡¹å·¥ä½œåˆ©ç”¨ç¨€ç–è‡ªåŠ¨ç¼–ç å™¨(Sparse Autoencoders, SAEs)å¯¹æ¨¡å‹çš„æ®‹å·®æµ(residual stream)æ¿€æ´»è¿›è¡Œäº†æœºæ¢°è®ºåˆ†æã€‚å®éªŒç»“æœæ˜¾ç¤ºï¼ŒSAEsæ•è·çš„ç‰¹å¾ä¸èƒ½é‡(energy)ç­‰æ ¸å¿ƒç‰©ç†å˜é‡ä¹‹é—´å­˜åœ¨æ˜¾è‘—å…³è”ã€‚è¿™ä¸€å‘ç°æœ‰åŠ›åœ°è¯æ˜äº†LLMsåœ¨è¿›è¡Œä¸Šä¸‹æ–‡å­¦ä¹ æ—¶ï¼Œå…¶å†…éƒ¨èƒ½å¤Ÿç¼–ç å¹¶å½¢æˆå…·æœ‰ç‰©ç†æ„ä¹‰çš„æ¦‚å¿µã€‚è¯¥å·¥ä½œä¸ºç†è§£LLMså¦‚ä½•é€šè¿‡ä¸Šä¸‹æ–‡å­¦ä¹ æŒæ¡é¢†åŸŸçŸ¥è¯†æä¾›äº†ä¸€ä¸ªæ–°é¢–çš„ç ”ç©¶è§†è§’ã€‚",
      "categories": [
        "cs.CL",
        "cs.AI",
        "cs.LG"
      ],
      "primary_category": "cs.CL",
      "comment": "17 pages, 10 figures",
      "pdf_url": "https://arxiv.org/pdf/2508.12448v1",
      "published_date": "2025-08-17 17:49:17 UTC",
      "updated_date": "2025-08-17 17:49:17 UTC",
      "processing_status": "completed",
      "attempts": 1,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "llm_backup_calls": 0,
      "last_update": "2026-01-24T12:22:38.687179+00:00"
    },
    {
      "arxiv_id": "2508.15822v1",
      "title": "An Auditable Pipeline for Fuzzy Full-Text Screening in Systematic Reviews: Integrating Contrastive Semantic Highlighting and LLM Judgment",
      "title_zh": "ç³»ç»Ÿç»¼è¿°ä¸­æ¨¡ç³Šå…¨æ–‡ç­›é€‰çš„å¯å®¡è®¡æµç¨‹ï¼šé›†æˆå¯¹æ¯”è¯­ä¹‰é«˜äº®ä¸å¤§è¯­è¨€æ¨¡å‹åˆ¤å®š",
      "authors": [
        "Pouria Mortezaagha",
        "Arya Rahgozar"
      ],
      "abstract": "Full-text screening is the major bottleneck of systematic reviews (SRs), as decisive evidence is dispersed across long, heterogeneous documents and rarely admits static, binary rules. We present a scalable, auditable pipeline that reframes inclusion/exclusion as a fuzzy decision problem and benchmark it against statistical and crisp baselines in the context of the Population Health Modelling Consensus Reporting Network for noncommunicable diseases (POPCORN). Articles are parsed into overlapping chunks and embedded with a domain-adapted model; for each criterion (Population, Intervention, Outcome, Study Approach), we compute contrastive similarity (inclusion-exclusion cosine) and a vagueness margin, which a Mamdani fuzzy controller maps into graded inclusion degrees with dynamic thresholds in a multi-label setting. A large language model (LLM) judge adjudicates highlighted spans with tertiary labels, confidence scores, and criterion-referenced rationales; when evidence is insufficient, fuzzy membership is attenuated rather than excluded. In a pilot on an all-positive gold set (16 full texts; 3,208 chunks), the fuzzy system achieved recall of 81.3% (Population), 87.5% (Intervention), 87.5% (Outcome), and 75.0% (Study Approach), surpassing statistical (56.3-75.0%) and crisp baselines (43.8-81.3%). Strict \"all-criteria\" inclusion was reached for 50.0% of articles, compared to 25.0% and 12.5% under the baselines. Cross-model agreement on justifications was 98.3%, human-machine agreement 96.1%, and a pilot review showed 91% inter-rater agreement (kappa = 0.82), with screening time reduced from about 20 minutes to under 1 minute per article at significantly lower cost. These results show that fuzzy logic with contrastive highlighting and LLM adjudication yields high recall, stable rationale, and end-to-end traceability.",
      "tldr_zh": "è¯¥ç ”ç©¶é’ˆå¯¹ç³»ç»Ÿç»¼è¿°(Systematic Reviews)ä¸­å…¨æ–‡ç­›é€‰æ•ˆç‡ä½ä¸‹çš„ç“¶é¢ˆï¼Œæå‡ºäº†ä¸€ç§å¯å®¡è®¡ä¸”å¯æ‰©å±•çš„æµæ°´çº¿ï¼Œå°†çº³å…¥æˆ–æ’é™¤å†³ç­–é‡æ–°å®šä¹‰ä¸ºæ¨¡ç³Šå†³ç­–é—®é¢˜ã€‚è¯¥æ–¹æ¡ˆåˆ©ç”¨é¢†åŸŸè‡ªé€‚åº”æ¨¡å‹å¯¹æ–‡æ¡£å—è¿›è¡ŒåµŒå…¥ï¼Œå¹¶é’ˆå¯¹Populationã€Interventionã€Outcomeå’ŒStudy Approachç­‰æ ‡å‡†è®¡ç®—å¯¹æ¯”ç›¸ä¼¼åº¦(Contrastive Similarity)ä¸æ¨¡ç³Šä½™é‡ã€‚é€šè¿‡Mamdaniæ¨¡ç³Šæ§åˆ¶å™¨å®ç°å¤šæ ‡ç­¾çš„åˆ†çº§çº³å…¥å†³ç­–ï¼Œå¹¶ç»“åˆå¤§è¯­è¨€æ¨¡å‹(LLM)å¯¹è¯æ®ç‰‡æ®µè¿›è¡Œå®¡å®šï¼Œæä¾›ä¸‰çº§æ ‡ç­¾ã€ç½®ä¿¡åº¦åŠå¼•ç”¨ç†ç”±ã€‚åœ¨è¯•ç‚¹ç ”ç©¶ä¸­ï¼Œè¯¥ç³»ç»Ÿåœ¨å„æ ‡å‡†ä¸Šçš„å¬å›ç‡è¾¾åˆ°75.0%è‡³87.5%ï¼Œæ˜¾è‘—ä¼˜äºç»Ÿè®¡å’Œç¡®å®šæ€§åŸºå‡†(Crisp Baselines)ã€‚æ­¤å¤–ï¼Œäººæœºä¸€è‡´æ€§é«˜è¾¾96.1%ï¼Œå¹¶å°†å•ç¯‡æ–‡ç« çš„ç­›é€‰æ—¶é—´ä»20åˆ†é’Ÿå¤§å¹…ç¼©çŸ­è‡³1åˆ†é’Ÿä»¥å†…ã€‚å®éªŒè¯æ˜ï¼Œç»“åˆæ¨¡ç³Šé€»è¾‘ã€å¯¹æ¯”é«˜äº®å’ŒLLMå®¡å®šçš„æ–¹æ³•åœ¨ä¿è¯é«˜å¬å›ç‡çš„åŒæ—¶ï¼Œå®ç°äº†æ¨ç†è¿‡ç¨‹çš„ç¨³å®šæ€§å’Œç«¯åˆ°ç«¯çš„å¯è¿½æº¯æ€§ã€‚",
      "categories": [
        "cs.CL",
        "cs.AI",
        "cs.ET",
        "cs.IR"
      ],
      "primary_category": "cs.CL",
      "comment": "",
      "pdf_url": "https://arxiv.org/pdf/2508.15822v1",
      "published_date": "2025-08-17 17:41:50 UTC",
      "updated_date": "2025-08-17 17:41:50 UTC",
      "processing_status": "completed",
      "attempts": 1,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "llm_backup_calls": 0,
      "last_update": "2026-01-24T12:22:45.248202+00:00"
    },
    {
      "arxiv_id": "2508.15821v1",
      "title": "Straggler-Resilient Federated Learning over A Hybrid Conventional and Pinching Antenna Network",
      "title_zh": "åŸºäºæ··åˆä¼ ç»Ÿä¸æ”¶ç¼©å¤©çº¿ç½‘ç»œçš„æŠ—è½åè€…è”é‚¦å­¦ä¹ ",
      "authors": [
        "Bibo Wu",
        "Fang Fang",
        "Ming Zeng",
        "Xianbin Wang"
      ],
      "abstract": "Leveraging pinching antennas in wireless network enabled federated learning (FL) can effectively mitigate the common \"straggler\" issue in FL by dynamically establishing strong line-of-sight (LoS) links on demand. This letter proposes a hybrid conventional and pinching antenna network (HCPAN) to significantly improve communication efficiency in the non-orthogonal multiple access (NOMA)-enabled FL system. Within this framework, a fuzzy logic-based client classification scheme is first proposed to effectively balance clients' data contributions and communication conditions. Given this classification, we formulate a total time minimization problem to jointly optimize pinching antenna placement and resource allocation. Due to the complexity of variable coupling and non-convexity, a deep reinforcement learning (DRL)-based algorithm is developed to effectively address this problem. Simulation results validate the superiority of the proposed scheme in enhancing FL performance via the optimized deployment of pinching antenna.",
      "tldr_zh": "è¯¥ç ”ç©¶é’ˆå¯¹è”é‚¦å­¦ä¹ (Federated Learning)ä¸­å¸¸è§çš„æ‰é˜Ÿè€…(straggler)é—®é¢˜ï¼Œæå‡ºäº†ä¸€ç§æ··åˆä¼ ç»Ÿä¸æåˆå¤©çº¿ç½‘ç»œ(Hybrid Conventional and Pinching Antenna Network, HCPAN)ã€‚é€šè¿‡åœ¨æ— çº¿ç½‘ç»œä¸­åˆ©ç”¨æåˆå¤©çº¿(pinching antennas)æŒ‰éœ€åŠ¨æ€å»ºç«‹å¼ºè§†è·(Line-of-Sight)é“¾è·¯ï¼Œè¯¥æ¡†æ¶æ˜¾è‘—æå‡äº†éæ­£äº¤å¤šå€æ¥å…¥(NOMA)æ”¯æŒä¸‹çš„è”é‚¦å­¦ä¹ é€šä¿¡æ•ˆç‡ã€‚ç ”ç©¶é¦–å…ˆè®¾è®¡äº†ä¸€ç§åŸºäºæ¨¡ç³Šé€»è¾‘(fuzzy logic)çš„å®¢æˆ·ç«¯åˆ†ç±»æ–¹æ¡ˆï¼Œä»¥å¹³è¡¡å®¢æˆ·ç«¯çš„æ•°æ®è´¡çŒ®ä¸é€šä¿¡çŠ¶å†µã€‚åœ¨æ­¤åŸºç¡€ä¸Šï¼Œç ”ç©¶æ„å»ºäº†ä¸€ä¸ªæ€»æ—¶é—´æœ€å°åŒ–é—®é¢˜ï¼Œå¹¶å¼€å‘äº†åŸºäºæ·±åº¦å¼ºåŒ–å­¦ä¹ (Deep Reinforcement Learning)çš„ç®—æ³•æ¥è”åˆä¼˜åŒ–æåˆå¤©çº¿çš„ä½ç½®éƒ¨ç½²ä¸èµ„æºåˆ†é…ã€‚ä»¿çœŸç»“æœéªŒè¯äº†è¯¥æ–¹æ¡ˆåœ¨é€šè¿‡ä¼˜åŒ–å¤©çº¿éƒ¨ç½²æå‡è”é‚¦å­¦ä¹ æ€§èƒ½æ–¹é¢çš„ä¼˜è¶Šæ€§ã€‚",
      "categories": [
        "cs.IT",
        "cs.AI",
        "cs.NI"
      ],
      "primary_category": "cs.IT",
      "comment": "",
      "pdf_url": "https://arxiv.org/pdf/2508.15821v1",
      "published_date": "2025-08-17 17:09:42 UTC",
      "updated_date": "2025-08-17 17:09:42 UTC",
      "processing_status": "completed",
      "attempts": 1,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "llm_backup_calls": 0,
      "last_update": "2026-01-24T12:22:45.095041+00:00"
    },
    {
      "arxiv_id": "2508.12435v1",
      "title": "Tactile Gesture Recognition with Built-in Joint Sensors for Industrial Robots",
      "title_zh": "åŸºäºå†…ç½®å…³èŠ‚ä¼ æ„Ÿå™¨çš„å·¥ä¸šæœºå™¨äººè§¦è§‰æ‰‹åŠ¿è¯†åˆ«",
      "authors": [
        "Deqing Song",
        "Weimin Yang",
        "Maryam Rezayati",
        "Hans Wernher van de Venn"
      ],
      "abstract": "While gesture recognition using vision or robot skins is an active research area in Human-Robot Collaboration (HRC), this paper explores deep learning methods relying solely on a robot's built-in joint sensors, eliminating the need for external sensors. We evaluated various convolutional neural network (CNN) architectures and collected two datasets to study the impact of data representation and model architecture on the recognition accuracy. Our results show that spectrogram-based representations significantly improve accuracy, while model architecture plays a smaller role. We also tested generalization to new robot poses, where spectrogram-based models performed better. Implemented on a Franka Emika Research robot, two of our methods, STFT2DCNN and STT3DCNN, achieved over 95% accuracy in contact detection and gesture classification. These findings demonstrate the feasibility of external-sensor-free tactile recognition and promote further research toward cost-effective, scalable solutions for HRC.",
      "tldr_zh": "è¯¥ç ”ç©¶æ¢è®¨äº†åœ¨äººæœºåä½œ(HRC)ä¸­ï¼Œä»…åˆ©ç”¨å·¥ä¸šæœºå™¨äººå†…ç½®çš„å…³èŠ‚ä¼ æ„Ÿå™¨è€Œéå¤–éƒ¨è§†è§‰æˆ–çš®è‚¤ä¼ æ„Ÿå™¨æ¥å®ç°è§¦è§‰æ‰‹åŠ¿è¯†åˆ«çš„æ–¹æ³•ã€‚ä½œè€…è¯„ä¼°äº†å¤šç§å·ç§¯ç¥ç»ç½‘ç»œ(CNN)æ¶æ„ï¼Œå¹¶æ”¶é›†äº†ä¸¤ä¸ªæ•°æ®é›†ä»¥åˆ†ææ•°æ®è¡¨ç¤ºå½¢å¼å’Œæ¨¡å‹æ¶æ„å¯¹è¯†åˆ«å‡†ç¡®ç‡çš„å½±å“ã€‚å®éªŒç»“æœè¡¨æ˜ï¼ŒåŸºäºè¯­è°±å›¾(spectrogram)çš„æ•°æ®è¡¨ç¤ºæ˜¾è‘—æå‡äº†è¯†åˆ«å‡†ç¡®ç‡ï¼Œè€Œæ¨¡å‹æ¶æ„æœ¬èº«å¯¹æ€§èƒ½çš„å½±å“ç›¸å¯¹è¾ƒå°ã€‚åœ¨é’ˆå¯¹æ–°æœºå™¨äººå§¿æ€çš„æ³›åŒ–èƒ½åŠ›æµ‹è¯•ä¸­ï¼ŒåŸºäºè¯­è°±å›¾çš„æ¨¡å‹è¡¨ç°å‡ºæ›´å¥½çš„é€‚åº”æ€§ã€‚è¯¥æ–¹æ¡ˆåœ¨ Franka Emika Research æœºå™¨äººä¸Šè¿›è¡Œäº†éƒ¨ç½²ï¼Œå…¶ä¸­ STFT2DCNN å’Œ STT3DCNN ä¸¤ç§æ–¹æ³•åœ¨æ¥è§¦æ£€æµ‹å’Œæ‰‹åŠ¿åˆ†ç±»ä»»åŠ¡ä¸­å‡å®ç°äº†è¶…è¿‡ 95% çš„å‡†ç¡®ç‡ã€‚è¿™é¡¹ç ”ç©¶è¯æ˜äº†æ— å¤–éƒ¨ä¼ æ„Ÿå™¨çš„è§¦è§‰è¯†åˆ«çš„å¯è¡Œæ€§ï¼Œä¸ºå®ç°æ›´å…·æˆæœ¬æ•ˆç›Šã€å¯æ‰©å±•çš„äººæœºåä½œè§£å†³æ–¹æ¡ˆæä¾›äº†æ–°çš„è·¯å¾„ã€‚",
      "categories": [
        "cs.RO",
        "cs.AI"
      ],
      "primary_category": "cs.RO",
      "comment": "",
      "pdf_url": "https://arxiv.org/pdf/2508.12435v1",
      "published_date": "2025-08-17 17:04:58 UTC",
      "updated_date": "2025-08-17 17:04:58 UTC",
      "processing_status": "completed",
      "attempts": 1,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "llm_backup_calls": 0,
      "last_update": "2026-01-24T12:22:56.156005+00:00"
    },
    {
      "arxiv_id": "2508.13228v1",
      "title": "PreSem-Surf: RGB-D Surface Reconstruction with Progressive Semantic Modeling and SG-MLP Pre-Rendering Mechanism",
      "title_zh": "PreSem-Surfï¼šåŸºäºæ¸è¿›å¼è¯­ä¹‰å»ºæ¨¡ä¸ SG-MLP é¢„æ¸²æŸ“æœºåˆ¶çš„ RGB-D è¡¨é¢é‡å»º",
      "authors": [
        "Yuyan Ye",
        "Hang Xu",
        "Yanghang Huang",
        "Jiali Huang",
        "Qian Weng"
      ],
      "abstract": "This paper proposes PreSem-Surf, an optimized method based on the Neural Radiance Field (NeRF) framework, capable of reconstructing high-quality scene surfaces from RGB-D sequences in a short time. The method integrates RGB, depth, and semantic information to improve reconstruction performance. Specifically, a novel SG-MLP sampling structure combined with PR-MLP (Preconditioning Multilayer Perceptron) is introduced for voxel pre-rendering, allowing the model to capture scene-related information earlier and better distinguish noise from local details. Furthermore, progressive semantic modeling is adopted to extract semantic information at increasing levels of precision, reducing training time while enhancing scene understanding. Experiments on seven synthetic scenes with six evaluation metrics show that PreSem-Surf achieves the best performance in C-L1, F-score, and IoU, while maintaining competitive results in NC, Accuracy, and Completeness, demonstrating its effectiveness and practical applicability.",
      "tldr_zh": "è¯¥ç ”ç©¶æå‡ºäº† PreSem-Surfï¼Œè¿™æ˜¯ä¸€ç§åŸºäºç¥ç»è¾å°„åœº (NeRF) æ¡†æ¶çš„ä¼˜åŒ–æ–¹æ³•ï¼Œæ—¨åœ¨ä» RGB-D åºåˆ—ä¸­å¿«é€Ÿå®ç°é«˜è´¨é‡çš„åœºæ™¯è¡¨é¢é‡å»ºã€‚è¯¥æ–¹æ³•é€šè¿‡æ•´åˆ RGBã€æ·±åº¦å’Œè¯­ä¹‰ä¿¡æ¯ï¼Œå¹¶å¼•å…¥ç»“åˆ PR-MLP çš„æ–°å‹ SG-MLP é‡‡æ ·ç»“æ„è¿›è¡Œä½“ç´ é¢„æ¸²æŸ“ï¼Œä½¿æ¨¡å‹èƒ½å¤Ÿæ›´æ—©æ•æ‰åœºæ™¯ä¿¡æ¯å¹¶æœ‰æ•ˆåŒºåˆ†å™ªå£°ä¸å±€éƒ¨ç»†èŠ‚ã€‚æ­¤å¤–ï¼Œç ”ç©¶é‡‡ç”¨äº†æ¸è¿›å¼è¯­ä¹‰å»ºæ¨¡ (Progressive Semantic Modeling) æŠ€æœ¯ï¼Œåœ¨å¢å¼ºåœºæ™¯ç†è§£èƒ½åŠ›çš„åŒæ—¶æ˜¾è‘—ç¼©çŸ­äº†è®­ç»ƒæ—¶é—´ã€‚å®éªŒç»“æœæ˜¾ç¤ºï¼ŒPreSem-Surf åœ¨ C-L1ã€F-score å’Œ IoU æŒ‡æ ‡ä¸Šå–å¾—äº†æœ€ä½³æ€§èƒ½ï¼Œå¹¶åœ¨ NCã€Accuracy å’Œ Completeness æ–¹é¢ä¿æŒäº†æå…·ç«äº‰åŠ›çš„è¡¨ç°ã€‚è¿™å……åˆ†è¯æ˜äº†è¯¥æ–¹æ³•åœ¨æå‡é‡å»ºè´¨é‡ä¸æ•ˆç‡æ–¹é¢çš„æœ‰æ•ˆæ€§ï¼Œå±•ç°äº†è‰¯å¥½çš„å®é™…åº”ç”¨æ½œåŠ›ã€‚",
      "categories": [
        "cs.GR",
        "cs.AI",
        "cs.CV",
        "eess.IV"
      ],
      "primary_category": "cs.GR",
      "comment": "2025 International Joint Conference on Neural Networks (IJCNN 2025)",
      "pdf_url": "https://arxiv.org/pdf/2508.13228v1",
      "published_date": "2025-08-17 17:00:18 UTC",
      "updated_date": "2025-08-17 17:00:18 UTC",
      "processing_status": "completed",
      "attempts": 1,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "llm_backup_calls": 0,
      "last_update": "2026-01-24T12:23:00.144892+00:00"
    },
    {
      "arxiv_id": "2508.12430v1",
      "title": "Adversarial Attacks on VQA-NLE: Exposing and Alleviating Inconsistencies in Visual Question Answering Explanations",
      "title_zh": "é’ˆå¯¹ VQA-NLE çš„å¯¹æŠ—æ”»å‡»ï¼šæ­ç¤ºä¸ç¼“è§£è§†è§‰é—®ç­”è§£é‡Šä¸­çš„ä¸ä¸€è‡´æ€§",
      "authors": [
        "Yahsin Yeh",
        "Yilun Wu",
        "Bokai Ruan",
        "Honghan Shuai"
      ],
      "abstract": "Natural language explanations in visual question answering (VQA-NLE) aim to make black-box models more transparent by elucidating their decision-making processes. However, we find that existing VQA-NLE systems can produce inconsistent explanations and reach conclusions without genuinely understanding the underlying context, exposing weaknesses in either their inference pipeline or explanation-generation mechanism. To highlight these vulnerabilities, we not only leverage an existing adversarial strategy to perturb questions but also propose a novel strategy that minimally alters images to induce contradictory or spurious outputs. We further introduce a mitigation method that leverages external knowledge to alleviate these inconsistencies, thereby bolstering model robustness. Extensive evaluations on two standard benchmarks and two widely used VQA-NLE models underscore the effectiveness of our attacks and the potential of knowledge-based defenses, ultimately revealing pressing security and reliability concerns in current VQA-NLE systems.",
      "tldr_zh": "è¯¥ç ”ç©¶æ¢è®¨äº†è§†è§‰é—®ç­”è‡ªç„¶è¯­è¨€è§£é‡Šï¼ˆVQA-NLEï¼‰ç³»ç»Ÿä¸­çš„ä¸€è‡´æ€§é—®é¢˜ï¼ŒæŒ‡å‡ºè¿™äº›ç³»ç»Ÿè™½ç„¶æ—¨åœ¨æé«˜é»‘ç›’æ¨¡å‹çš„é€æ˜åº¦ï¼Œä½†å¾€å¾€ä¼šäº§ç”Ÿå‰åçŸ›ç›¾çš„è§£é‡Šã€‚ä¸ºäº†æ­ç¤ºè¿™äº›æ¼æ´ï¼Œä½œè€…åˆ©ç”¨å¯¹æŠ—æ€§æ”»å‡»ï¼ˆAdversarial Attacksï¼‰ç­–ç•¥æ‰°åŠ¨é—®é¢˜ï¼Œå¹¶æå‡ºä¸€ç§é€šè¿‡æå°å¹…åº¦ä¿®æ”¹å›¾åƒæ¥è¯±å¯¼çŸ›ç›¾è¾“å‡ºçš„æ–°é¢–ç­–ç•¥ã€‚é’ˆå¯¹è¿™äº›é—®é¢˜ï¼Œç ”ç©¶è¿›ä¸€æ­¥å¼•å…¥äº†ä¸€ç§ç»“åˆå¤–éƒ¨çŸ¥è¯†ï¼ˆExternal Knowledgeï¼‰çš„ç¼“è§£æ–¹æ³•ï¼Œæ—¨åœ¨æ˜¾è‘—æå‡æ¨¡å‹åœ¨é¢å¯¹å¹²æ‰°æ—¶çš„é²æ£’æ€§ï¼ˆRobustnessï¼‰ã€‚åœ¨å¤šä¸ªæ ‡å‡†åŸºå‡†å’Œæ¨¡å‹ä¸Šçš„å¹¿æ³›è¯„ä¼°è¯æ˜äº†æ”»å‡»æ‰‹æ®µçš„æœ‰æ•ˆæ€§ä»¥åŠé˜²å¾¡æ–¹æ¡ˆçš„æ½œåŠ›ã€‚è¯¥ç ”ç©¶æœ€ç»ˆæ­ç¤ºäº†å½“å‰ VQA-NLE ç³»ç»Ÿåœ¨å®‰å…¨æ€§å’Œå¯é æ€§æ–¹é¢å­˜åœ¨çš„è¿«åˆ‡æŒ‘æˆ˜ï¼Œä¸ºè¯¥é¢†åŸŸçš„åç»­æ”¹è¿›æä¾›äº†é‡è¦ä¾æ®ã€‚",
      "categories": [
        "cs.CV",
        "cs.AI",
        "cs.CL"
      ],
      "primary_category": "cs.CV",
      "comment": "",
      "pdf_url": "https://arxiv.org/pdf/2508.12430v1",
      "published_date": "2025-08-17 16:53:10 UTC",
      "updated_date": "2025-08-17 16:53:10 UTC",
      "processing_status": "completed",
      "attempts": 1,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "llm_backup_calls": 0,
      "last_update": "2026-01-24T12:23:08.356832+00:00"
    },
    {
      "arxiv_id": "2508.12425v2",
      "title": "Non-Interactive Symbolic-Aided Chain-of-Thought for Logical Reasoning",
      "title_zh": "é¢å‘é€»è¾‘æ¨ç†çš„éäº¤äº’å¼ç¬¦å·è¾…åŠ©æ€ç»´é“¾",
      "authors": [
        "Phuong Minh Nguyen",
        "Tien Huu Dang",
        "Naoya Inoue"
      ],
      "abstract": "This work introduces Symbolic-Aided Chain-of-Thought (CoT), an improved approach to standard CoT, for logical reasoning in large language models (LLMs). The key idea is to integrate lightweight symbolic representations into few-shot prompts, structuring the inference steps with a consistent strategy to make reasoning patterns more explicit within a non-interactive reasoning process. By incorporating these symbolic structures, Symbolic-Aided CoT preserves the generalizability of standard prompting techniques while enhancing the transparency, interpretability, and analyzability of LLM logical reasoning. Extensive experiments on four well-known logical reasoning benchmarks -- ProofWriter, FOLIO, ProntoQA, and LogicalDeduction, which cover diverse reasoning tasks and scenarios -- demonstrate the effectiveness of the proposed approach, particularly in complex reasoning tasks that require navigating multiple constraints or rules. Notably, Symbolic-Aided CoT consistently improves LLMs' reasoning capabilities across various model sizes and significantly outperforms conventional CoT on three out of four datasets, ProofWriter, ProntoQA, and LogicalDeduction.",
      "tldr_zh": "è¯¥ç ”ç©¶æå‡ºäº†Symbolic-Aided Chain-of-Thought (CoT)ï¼Œè¿™æ˜¯ä¸€ç§æ—¨åœ¨æå‡å¤§è¯­è¨€æ¨¡å‹(LLMs)é€»è¾‘æ¨ç†èƒ½åŠ›çš„æ”¹è¿›æ–¹æ³•ã€‚å…¶æ ¸å¿ƒæ–¹æ¡ˆæ˜¯å°†è½»é‡çº§çš„ç¬¦å·è¡¨ç¤º(symbolic representations)é›†æˆåˆ°å°‘æ ·æœ¬æç¤º(few-shot prompts)ä¸­ï¼Œé€šè¿‡ç»“æ„åŒ–çš„æ¨ç†æ­¥éª¤ä½¿éäº¤äº’å¼æ¨ç†è¿‡ç¨‹ä¸­çš„æ¨¡å¼æ›´åŠ æ˜ç¡®ã€‚è¿™ç§æ–¹æ³•åœ¨ä¿ç•™æ ‡å‡†æç¤ºæŠ€æœ¯é€šç”¨æ€§çš„åŒæ—¶ï¼Œå¢å¼ºäº†æ¨ç†è¿‡ç¨‹çš„é€æ˜åº¦ã€å¯è§£é‡Šæ€§ä¸å¯åˆ†ææ€§ã€‚åœ¨ProofWriterã€FOLIOã€ProntoQAå’ŒLogicalDeductionç­‰å¤šä¸ªé€»è¾‘æ¨ç†åŸºå‡†æµ‹è¯•ä¸Šçš„å®éªŒè¯æ˜äº†è¯¥æ–¹æ³•çš„æœ‰æ•ˆæ€§ï¼Œç‰¹åˆ«æ˜¯åœ¨æ¶‰åŠå¤šé‡çº¦æŸæˆ–è§„åˆ™çš„å¤æ‚ä»»åŠ¡ä¸­ã€‚å®éªŒç»“æœæ˜¾ç¤ºï¼ŒSymbolic-Aided CoTèƒ½æ˜¾è‘—æå‡ä¸åŒè§„æ¨¡æ¨¡å‹çš„æ¨ç†æ€§èƒ½ï¼Œå¹¶åœ¨å¤šæ•°æ•°æ®é›†ä¸Šè¡¨ç°ä¼˜äºä¼ ç»ŸCoTã€‚",
      "categories": [
        "cs.AI",
        "cs.CL"
      ],
      "primary_category": "cs.AI",
      "comment": "Accepted in The 39th Pacific Asia Conference on Language, Information and Computation (PACLIC 39)",
      "pdf_url": "https://arxiv.org/pdf/2508.12425v2",
      "published_date": "2025-08-17 16:32:05 UTC",
      "updated_date": "2025-10-04 17:29:03 UTC",
      "processing_status": "completed",
      "attempts": 1,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "llm_backup_calls": 0,
      "last_update": "2026-01-24T12:23:08.743540+00:00"
    },
    {
      "arxiv_id": "2508.12416v1",
      "title": "fCrit: A Visual Explanation System for Furniture Design Creative Support",
      "title_zh": "fCritï¼šé¢å‘å®¶å…·è®¾è®¡åˆ›æ„æ”¯æŒçš„è§†è§‰è§£é‡Šç³»ç»Ÿ",
      "authors": [
        "Vuong Nguyen",
        "Gabriel Vigliensoni"
      ],
      "abstract": "We introduce fCrit, a dialogue-based AI system designed to critique furniture design with a focus on explainability. Grounded in reflective learning and formal analysis, fCrit employs a multi-agent architecture informed by a structured design knowledge base. We argue that explainability in the arts should not only make AI reasoning transparent but also adapt to the ways users think and talk about their designs. We demonstrate how fCrit supports this process by tailoring explanations to users' design language and cognitive framing. This work contributes to Human-Centered Explainable AI (HCXAI) in creative practice, advancing domain-specific methods for situated, dialogic, and visually grounded AI support.",
      "tldr_zh": "è¯¥ç ”ç©¶æ¨å‡ºäº†fCritï¼Œè¿™æ˜¯ä¸€æ¬¾ä¸“æ³¨äºå¯è§£é‡Šæ€§çš„å¯¹è¯å¼AIç³»ç»Ÿï¼Œæ—¨åœ¨ä¸ºå®¶å…·è®¾è®¡æä¾›åˆ›æ„æ”¯æŒä¸è¯„è®ºã€‚fCritæ¤æ ¹äºreflective learningå’Œformal analysisï¼Œé‡‡ç”¨äº†ç”±ç»“æ„åŒ–è®¾è®¡çŸ¥è¯†åº“é©±åŠ¨çš„multi-agent architectureã€‚ç ”ç©¶å¼ºè°ƒï¼Œè‰ºæœ¯é¢†åŸŸçš„å¯è§£é‡Šæ€§ä¸ä»…éœ€è¦ä½¿AIæ¨ç†é€æ˜åŒ–ï¼Œæ›´åº”é€‚é…ç”¨æˆ·è®¨è®ºå…¶è®¾è®¡æ—¶çš„è¯­è¨€è¡¨è¾¾å’Œè®¤çŸ¥æ¡†æ¶ã€‚é€šè¿‡æ ¹æ®ç”¨æˆ·çš„è®¾è®¡è¯­è¨€å®šåˆ¶è§£é‡Šï¼ŒfCritèƒ½å¤Ÿæœ‰æ•ˆåœ°è¾…åŠ©åˆ›ä½œè¿‡ç¨‹å¹¶æä¾›å…·æœ‰è§†è§‰ä¾æ®çš„åé¦ˆã€‚è¿™é¡¹å·¥ä½œä¸ºåˆ›æ„å®è·µä¸­çš„Human-Centered Explainable AI (HCXAI)åšå‡ºäº†é‡è¦è´¡çŒ®ï¼Œå±•ç¤ºäº†å¦‚ä½•é€šè¿‡æƒ…å¢ƒåŒ–å’Œå¯¹è¯å¼æ–¹æ³•æå‡AIåœ¨ç‰¹å®šä¸“ä¸šé¢†åŸŸçš„æ”¯æŒèƒ½åŠ›ã€‚",
      "categories": [
        "cs.HC",
        "cs.AI"
      ],
      "primary_category": "cs.HC",
      "comment": "In Proceedings of Explainable AI for the Arts Workshop 2025 (XAIxArts 2025) arXiv:2406.14485",
      "pdf_url": "https://arxiv.org/pdf/2508.12416v1",
      "published_date": "2025-08-17 16:03:44 UTC",
      "updated_date": "2025-08-17 16:03:44 UTC",
      "processing_status": "completed",
      "attempts": 1,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "llm_backup_calls": 0,
      "last_update": "2026-01-24T12:23:08.551232+00:00"
    },
    {
      "arxiv_id": "2508.12413v2",
      "title": "Quantum Flow Matching",
      "title_zh": "é‡å­æµåŒ¹é…",
      "authors": [
        "Zidong Cui",
        "Pan Zhang",
        "Ying Tang"
      ],
      "abstract": "The flow matching has rapidly become a dominant paradigm in classical generative modeling, offering an efficient way to interpolate between two complex distributions. We extend this idea to the quantum realm and introduce the Quantum Flow Matching (QFM-a fully quantum-circuit realization that offers efficient interpolation between two density matrices. QFM offers systematic preparation of density matrices and generation of samples for accurately estimating observables, and can be realized on quantum computers without the need for costly circuit redesigns. We validate its versatility on a set of applications: (i) generating target states with prescribed magnetization and entanglement entropy, (ii) estimating nonequilibrium free-energy differences to test the quantum Jarzynski equality, and (iii) expediting the study on superdiffusion. These results position QFM as a unifying and promising framework for generative modeling across quantum systems.",
      "tldr_zh": "è¯¥ç ”ç©¶å°†ç»å…¸ç”Ÿæˆæ¨¡å‹ä¸­çš„ Flow Matching èŒƒå¼æ‰©å±•è‡³é‡å­é¢†åŸŸï¼Œæå‡ºäº† Quantum Flow Matching (QFM) æ¡†æ¶ã€‚QFM æ˜¯ä¸€ç§å®Œå…¨åŸºäºé‡å­çº¿è·¯ (Quantum-Circuit) çš„å®ç°æ–¹å¼ï¼Œèƒ½å¤Ÿåœ¨ä¸¤ä¸ªå¯†åº¦çŸ©é˜µ (Density Matrices) ä¹‹é—´è¿›è¡Œé«˜æ•ˆæ’å€¼ï¼Œå®ç°äº†å¯†åº¦çŸ©é˜µçš„ç³»ç»ŸåŒ–åˆ¶å¤‡å’Œæ ·æœ¬ç”Ÿæˆï¼Œä»è€Œç²¾ç¡®ä¼°ç®—å¯è§‚æµ‹ç‰©ç†é‡ (Observables)ã€‚è¯¥æ¡†æ¶æ— éœ€å¯¹çº¿è·¯è¿›è¡Œå¤æ‚çš„é‡æ–°è®¾è®¡å³å¯åœ¨é‡å­è®¡ç®—æœºä¸Šéƒ¨ç½²ï¼Œæ˜¾è‘—æå‡äº†ç”Ÿæˆæ•ˆç‡ã€‚ç ”ç©¶äººå‘˜é€šè¿‡ç”Ÿæˆå…·æœ‰ç‰¹å®šç£åŒ–å¼ºåº¦ (Magnetization) å’Œçº ç¼ ç†µ (Entanglement Entropy) çš„ç›®æ ‡æ€ã€æµ‹è¯•é‡å­ Jarzynski ç­‰å¼ä»¥åŠåŠ é€Ÿè¶…æ‰©æ•£ (Superdiffusion) ç ”ç©¶ç­‰å¤šé¡¹åº”ç”¨ï¼ŒéªŒè¯äº†è¯¥æ–¹æ³•çš„é€šç”¨æ€§ã€‚å®éªŒç»“æœè¡¨æ˜ QFM ä¸ºé‡å­ç³»ç»Ÿä¸­çš„ç”Ÿæˆå¼å»ºæ¨¡æä¾›äº†ä¸€ä¸ªç»Ÿä¸€ä¸”é«˜æ•ˆçš„æ¡†æ¶ã€‚",
      "categories": [
        "quant-ph",
        "cs.AI",
        "cs.LG"
      ],
      "primary_category": "quant-ph",
      "comment": "16 pages, 11 figures",
      "pdf_url": "https://arxiv.org/pdf/2508.12413v2",
      "published_date": "2025-08-17 16:00:20 UTC",
      "updated_date": "2025-08-30 09:58:07 UTC",
      "processing_status": "completed",
      "attempts": 1,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "llm_backup_calls": 0,
      "last_update": "2026-01-24T12:23:11.050672+00:00"
    },
    {
      "arxiv_id": "2508.12412v1",
      "title": "LumiMAS: A Comprehensive Framework for Real-Time Monitoring and Enhanced Observability in Multi-Agent Systems",
      "title_zh": "LumiMASï¼šå¤šæ™ºèƒ½ä½“ç³»ç»Ÿå®æ—¶ç›‘æ§ä¸å¯è§‚æµ‹æ€§å¢å¼ºçš„ç»¼åˆæ¡†æ¶",
      "authors": [
        "Ron Solomon",
        "Yarin Yerushalmi Levi",
        "Lior Vaknin",
        "Eran Aizikovich",
        "Amit Baras",
        "Etai Ohana",
        "Amit Giloni",
        "Shamik Bose",
        "Chiara Picardi",
        "Yuval Elovici",
        "Asaf Shabtai"
      ],
      "abstract": "The incorporation of large language models in multi-agent systems (MASs) has the potential to significantly improve our ability to autonomously solve complex problems. However, such systems introduce unique challenges in monitoring, interpreting, and detecting system failures. Most existing MAS observability frameworks focus on analyzing each individual agent separately, overlooking failures associated with the entire MAS. To bridge this gap, we propose LumiMAS, a novel MAS observability framework that incorporates advanced analytics and monitoring techniques. The proposed framework consists of three key components: a monitoring and logging layer, anomaly detection layer, and anomaly explanation layer. LumiMAS's first layer monitors MAS executions, creating detailed logs of the agents' activity. These logs serve as input to the anomaly detection layer, which detects anomalies across the MAS workflow in real time. Then, the anomaly explanation layer performs classification and root cause analysis (RCA) of the detected anomalies. LumiMAS was evaluated on seven different MAS applications, implemented using two popular MAS platforms, and a diverse set of possible failures. The applications include two novel failure-tailored applications that illustrate the effects of a hallucination or bias on the MAS. The evaluation results demonstrate LumiMAS's effectiveness in failure detection, classification, and RCA.",
      "tldr_zh": "è¯¥ç ”ç©¶æå‡ºäº†LumiMASï¼Œä¸€ä¸ªæ—¨åœ¨æå‡å¤šæ™ºèƒ½ä½“ç³»ç»Ÿ(Multi-Agent Systems, MAS)å®æ—¶ç›‘æ§ä¸å¯è§‚æµ‹æ€§çš„å…¨é¢æ¡†æ¶ã€‚é’ˆå¯¹ç°æœ‰æ¡†æ¶ä¸»è¦å…³æ³¨å•ä¸ªæ™ºèƒ½ä½“è€Œå¿½è§†ç³»ç»Ÿæ•´ä½“æ•…éšœçš„é—®é¢˜ï¼ŒLumiMASé€šè¿‡ç›‘æ§ä¸æ—¥å¿—å±‚ã€å¼‚å¸¸æ£€æµ‹å±‚ä»¥åŠå¼‚å¸¸è§£é‡Šå±‚ä¸‰ä¸ªæ ¸å¿ƒç»„ä»¶å®ç°äº†å¯¹ç³»ç»Ÿè¡Œä¸ºçš„æ·±åº¦æ´å¯Ÿã€‚è¯¥æ¡†æ¶èƒ½å¤Ÿå®æ—¶æ£€æµ‹MASå·¥ä½œæµä¸­çš„å¼‚å¸¸ï¼Œå¹¶è¿›ä¸€æ­¥æ‰§è¡Œå¼‚å¸¸åˆ†ç±»ä¸æ ¹å› åˆ†æ(Root Cause Analysis, RCA)ã€‚ç ”ç©¶å›¢é˜Ÿåœ¨ä¸¤ä¸ªä¸»æµMASå¹³å°ä¸Šå¯¹ä¸ƒä¸ªä¸åŒçš„åº”ç”¨è¿›è¡Œäº†è¯„ä¼°ï¼Œå…¶ä¸­åŒ…æ‹¬æ¨¡æ‹Ÿå¹»è§‰(hallucination)å’Œåè§(bias)å½±å“çš„ç‰¹å®šæ•…éšœåº”ç”¨ã€‚å®éªŒç»“æœè¯æ˜ï¼ŒLumiMASåœ¨æ•…éšœæ£€æµ‹ã€åˆ†ç±»ä»¥åŠæ ¹å› åˆ†ææ–¹é¢å‡å…·æœ‰æ˜¾è‘—çš„æœ‰æ•ˆæ€§ï¼Œä¸ºæ„å»ºæ›´å¯é ã€å¯è§£é‡Šçš„è‡ªä¸»å¤æ‚é—®é¢˜è§£å†³ç³»ç»Ÿæä¾›äº†é‡è¦æ”¯æŒã€‚",
      "categories": [
        "cs.CR",
        "cs.AI"
      ],
      "primary_category": "cs.CR",
      "comment": "",
      "pdf_url": "https://arxiv.org/pdf/2508.12412v1",
      "published_date": "2025-08-17 15:55:02 UTC",
      "updated_date": "2025-08-17 15:55:02 UTC",
      "processing_status": "completed",
      "attempts": 1,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "llm_backup_calls": 0,
      "last_update": "2026-01-24T12:23:15.657104+00:00"
    },
    {
      "arxiv_id": "2508.12410v2",
      "title": "SRMA-Mamba: Spatial Reverse Mamba Attention Network for Pathological Liver Segmentation in MRI Volumes",
      "title_zh": "SRMA-Mambaï¼šé¢å‘ MRI ä½“æ•°æ®ç—…ç†è‚è„åˆ†å‰²çš„ç©ºé—´åå‘ Mamba æ³¨æ„åŠ›ç½‘ç»œ",
      "authors": [
        "Jun Zeng",
        "Yannan Huang",
        "Elif Keles",
        "Halil Ertugrul Aktas",
        "Gorkem Durak",
        "Nikhil Kumar Tomar",
        "Quoc-Huy Trinh",
        "Deepak Ranjan Nayak",
        "Ulas Bagci",
        "Debesh Jha"
      ],
      "abstract": "Liver Cirrhosis plays a critical role in the prognosis of chronic liver disease. Early detection and timely intervention are critical in significantly reducing mortality rates. However, the intricate anatomical architecture and diverse pathological changes of liver tissue complicate the accurate detection and characterization of lesions in clinical settings. Existing methods underutilize the spatial anatomical details in volumetric MRI data, thereby hindering their clinical effectiveness and explainability. To address this challenge, we introduce a novel Mamba-based network, SRMA-Mamba, designed to model the spatial relationships within the complex anatomical structures of MRI volumes. By integrating the Spatial Anatomy-Based Mamba module (SABMamba), SRMA-Mamba performs selective Mamba scans within liver cirrhotic tissues and combines anatomical information from the sagittal, coronal, and axial planes to construct a global spatial context representation, enabling efficient volumetric segmentation of pathological liver structures. Furthermore, we introduce the Spatial Reverse Attention module (SRMA), designed to progressively refine cirrhotic details in the segmentation map, utilizing both the coarse segmentation map and hierarchical encoding features. Extensive experiments demonstrate that SRMA-Mamba surpasses state-of-the-art methods, delivering exceptional performance in 3D pathological liver segmentation. Our code is available for public: https://github.com/JunZengz/SRMA-Mamba.",
      "tldr_zh": "è‚ç¡¬åŒ–åœ¨æ…¢æ€§è‚ç—…çš„é¢„åä¸­èµ·ç€è‡³å…³é‡è¦çš„ä½œç”¨ï¼Œä½†è‚è„ç»„ç»‡å¤æ‚çš„è§£å‰–ç»“æ„å’Œå¤šæ ·çš„ç—…ç†å˜åŒ–ä½¿å¾—åœ¨MRIä½“ç§¯æ•°æ®ä¸­å‡†ç¡®æ£€æµ‹ç—…å˜é¢ä¸´æŒ‘æˆ˜ã€‚ä¸ºæ­¤ï¼Œè¯¥ç ”ç©¶æå‡ºäº†SRMA-Mambaï¼Œä¸€ç§æ—¨åœ¨å¯¹MRIä½“ç§¯å†…å¤æ‚è§£å‰–ç»“æ„çš„ç©ºé—´å…³ç³»è¿›è¡Œå»ºæ¨¡çš„æ–°å‹ç½‘ç»œã€‚è¯¥æ¡†æ¶é€šè¿‡é›†æˆåŸºäºç©ºé—´è§£å‰–çš„Mambaæ¨¡å—(SABMamba)ï¼Œåœ¨è‚ç¡¬åŒ–ç»„ç»‡å†…æ‰§è¡Œé€‰æ‹©æ€§Mambaæ‰«æï¼Œå¹¶ç»“åˆçŸ¢çŠ¶é¢ã€å† çŠ¶é¢å’Œè½´å‘é¢çš„ä¿¡æ¯æ¥æ„å»ºå…¨å±€ç©ºé—´ä¸Šä¸‹æ–‡è¡¨ç¤ºã€‚åŒæ—¶ï¼Œç ”ç©¶å¼•å…¥äº†ç©ºé—´åå‘æ³¨æ„åŠ›æ¨¡å—(SRMA)ï¼Œåˆ©ç”¨ç²—ç•¥åˆ†å‰²å›¾å’Œåˆ†å±‚ç¼–ç ç‰¹å¾é€æ­¥ä¼˜åŒ–åˆ†å‰²å›¾ä¸­çš„è‚ç¡¬åŒ–ç»†èŠ‚ã€‚å®éªŒç»“æœè¡¨æ˜ï¼ŒSRMA-Mambaåœ¨3Dç—…ç†æ€§è‚è„åˆ†å‰²æ–¹é¢è¡¨ç°ä¼˜å¼‚ï¼Œæ€§èƒ½è¶…è¶Šäº†ç›®å‰çš„æœ€å…ˆè¿›æ–¹æ³•ã€‚è¯¥ç ”ç©¶ä¸ºå®ç°é«˜æ•ˆä¸”å…·æœ‰ä¸´åºŠè§£é‡Šæ€§çš„ç—…ç†æ€§è‚è„ç»“æ„ä½“ç§¯åˆ†å‰²æä¾›äº†æœ‰æ•ˆæ‰‹æ®µã€‚",
      "categories": [
        "cs.CV",
        "cs.AI"
      ],
      "primary_category": "cs.CV",
      "comment": "9 pages, 4 figures",
      "pdf_url": "https://arxiv.org/pdf/2508.12410v2",
      "published_date": "2025-08-17 15:52:54 UTC",
      "updated_date": "2025-08-19 06:05:00 UTC",
      "processing_status": "completed",
      "attempts": 1,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "llm_backup_calls": 0,
      "last_update": "2026-01-24T12:23:23.190932+00:00"
    },
    {
      "arxiv_id": "2508.12405v1",
      "title": "Extracting Post-Acute Sequelae of SARS-CoV-2 Infection Symptoms from Clinical Notes via Hybrid Natural Language Processing",
      "title_zh": "åŸºäºæ··åˆè‡ªç„¶è¯­è¨€å¤„ç†çš„ä¸´åºŠè®°å½• SARS-CoV-2 æ„ŸæŸ“æ€¥æ€§æœŸåé—ç—‡ç—‡çŠ¶æå–",
      "authors": [
        "Zilong Bai",
        "Zihan Xu",
        "Cong Sun",
        "Chengxi Zang",
        "H. Timothy Bunnell",
        "Catherine Sinfield",
        "Jacqueline Rutter",
        "Aaron Thomas Martinez",
        "L. Charles Bailey",
        "Mark Weiner",
        "Thomas R. Campion",
        "Thomas Carton",
        "Christopher B. Forrest",
        "Rainu Kaushal",
        "Fei Wang",
        "Yifan Peng"
      ],
      "abstract": "Accurately and efficiently diagnosing Post-Acute Sequelae of COVID-19 (PASC) remains challenging due to its myriad symptoms that evolve over long- and variable-time intervals. To address this issue, we developed a hybrid natural language processing pipeline that integrates rule-based named entity recognition with BERT-based assertion detection modules for PASC-symptom extraction and assertion detection from clinical notes. We developed a comprehensive PASC lexicon with clinical specialists. From 11 health systems of the RECOVER initiative network across the U.S., we curated 160 intake progress notes for model development and evaluation, and collected 47,654 progress notes for a population-level prevalence study. We achieved an average F1 score of 0.82 in one-site internal validation and 0.76 in 10-site external validation for assertion detection. Our pipeline processed each note at $2.448\\pm 0.812$ seconds on average. Spearman correlation tests showed $Ï>0.83$ for positive mentions and $Ï>0.72$ for negative ones, both with $P <0.0001$. These demonstrate the effectiveness and efficiency of our models and their potential for improving PASC diagnosis.",
      "tldr_zh": "è¯¥ç ”ç©¶é’ˆå¯¹æ–°å‹å† çŠ¶ç—…æ¯’æ„ŸæŸ“åé—ç—‡(Post-Acute Sequelae of SARS-CoV-2 Infection, PASC)ç—‡çŠ¶å¤šæ ·ä¸”éšæ—¶é—´æ¼”å˜çš„è¯Šæ–­éš¾é¢˜ï¼Œå¼€å‘äº†ä¸€ç§æ··åˆè‡ªç„¶è¯­è¨€å¤„ç†(Hybrid Natural Language Processing)æµæ°´çº¿ï¼Œç”¨äºä»ä¸´åºŠè®°å½•ä¸­è‡ªåŠ¨æå–ç›¸å…³ç—‡çŠ¶ã€‚è¯¥ç³»ç»Ÿé›†æˆäº†åŸºäºè§„åˆ™çš„å‘½åå®ä½“è¯†åˆ«(rule-based named entity recognition)å’ŒåŸºäºBERTçš„æ–­è¨€æ£€æµ‹(assertion detection)æ¨¡å—ï¼Œå¹¶ç»“åˆä¸´åºŠä¸“å®¶æ„å»ºçš„PASCè¯å…¸æ¥æé«˜è¯†åˆ«ç²¾åº¦ã€‚é€šè¿‡å¯¹ç¾å›½RECOVERè®¡åˆ’ç½‘ç»œä¸­11ä¸ªåŒ»ç–—ç³»ç»Ÿçš„ä¸´åºŠè®°å½•è¿›è¡ŒéªŒè¯ï¼Œæ¨¡å‹åœ¨æ–­è¨€æ£€æµ‹ä»»åŠ¡ä¸­è¾¾åˆ°äº†0.82çš„å†…éƒ¨éªŒè¯F1åˆ†æ•°å’Œ0.76çš„è·¨ä¸­å¿ƒå¤–éƒ¨éªŒè¯F1åˆ†æ•°ã€‚æ¯ä»½ä¸´åºŠè®°å½•çš„å¹³å‡å¤„ç†æ—¶é—´ä»…ä¸º2.448ç§’ï¼Œä¸”Spearmanç›¸å…³æ€§åˆ†ææ˜¾ç¤ºå…¶åœ¨è¯†åˆ«ç—‡çŠ¶æåŠçš„æ­£è´Ÿå±æ€§ä¸Šå…·æœ‰æé«˜çš„ä¸€è‡´æ€§ã€‚è¯¥ç ”ç©¶å±•ç¤ºäº†è¯¥NLPæµæ°´çº¿åœ¨å¤„ç†å¤§è§„æ¨¡ä¸´åºŠæ–‡æœ¬æ•°æ®æ—¶çš„æœ‰æ•ˆæ€§ä¸æ•ˆç‡ï¼Œä¸ºæ”¹å–„PASCçš„è¯Šæ–­æµç¨‹å’Œå¼€å±•äººç¾¤æ°´å¹³çš„æµè¡Œç—…å­¦ç ”ç©¶æä¾›äº†é‡è¦çš„æŠ€æœ¯æ”¯æ’‘ã€‚",
      "categories": [
        "cs.CL",
        "cs.AI"
      ],
      "primary_category": "cs.CL",
      "comment": "Accepted for publication in npj Health Systems",
      "pdf_url": "https://arxiv.org/pdf/2508.12405v1",
      "published_date": "2025-08-17 15:43:05 UTC",
      "updated_date": "2025-08-17 15:43:05 UTC",
      "processing_status": "completed",
      "attempts": 1,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "llm_backup_calls": 0,
      "last_update": "2026-01-24T12:23:25.590224+00:00"
    },
    {
      "arxiv_id": "2508.12398v2",
      "title": "Where to Start Alignment? Diffusion Large Language Model May Demand a Distinct Position",
      "title_zh": "å¯¹é½åº”ä»ä½•å¤„å¼€å§‹ï¼Ÿæ‰©æ•£å¤§è¯­è¨€æ¨¡å‹æˆ–éœ€ç‹¬ç‰¹çš„å¯¹é½ä½ç½®",
      "authors": [
        "Zhixin Xie",
        "Xurui Song",
        "Jun Luo"
      ],
      "abstract": "Diffusion Large Language Models (dLLMs) have recently emerged as a competitive non-autoregressive paradigm due to their unique training and inference approach. However, there is currently a lack of safety study on this novel architecture. In this paper, we present the first analysis of dLLMs' safety performance and propose a novel safety alignment method tailored to their unique generation characteristics. Specifically, we identify a critical asymmetry between the defender and attacker in terms of security. For the defender, we reveal that the middle tokens of the response, rather than the initial ones, are more critical to the overall safety of dLLM outputs; this seems to suggest that aligning middle tokens can be more beneficial to the defender. The attacker, on the contrary, may have limited power to manipulate middle tokens, as we find dLLMs have a strong tendency towards a sequential generation order in practice, forcing the attack to meet this distribution and diverting it from influencing the critical middle tokens. Building on this asymmetry, we introduce Middle-tOken Safety Alignment (MOSA), a novel method that directly aligns the model's middle generation with safe refusals exploiting reinforcement learning. We implement MOSA and compare its security performance against eight attack methods on two benchmarks. We also test the utility of MOSA-aligned dLLM on coding, math, and general reasoning. The results strongly prove the superiority of MOSA.",
      "tldr_zh": "è¯¥ç ”ç©¶é’ˆå¯¹æ–°å…´çš„æ‰©æ•£å¤§è¯­è¨€æ¨¡å‹(dLLMs)åœ¨å®‰å…¨æ€§ç ”ç©¶æ–¹é¢çš„ç©ºç™½ï¼Œé¦–æ¬¡å¯¹å…¶å®‰å…¨æ€§èƒ½è¿›è¡Œäº†æ·±å…¥åˆ†æã€‚ä½œè€…å‘ç°dLLMsçš„å®‰å…¨æ€§è¡¨ç°å…·æœ‰ç‰¹æ®Šæ€§ï¼Œå…¶å“åº”ä¸­çš„ä¸­é—´token(middle tokens)ç›¸è¾ƒäºåˆå§‹tokenå¯¹æ•´ä½“å®‰å…¨æ€§æ›´ä¸ºå…³é”®ã€‚ç ”ç©¶æ­ç¤ºäº†é˜²å¾¡è€…ä¸æ”»å‡»è€…ä¹‹é—´å­˜åœ¨å…³é”®çš„ä¸å¯¹ç§°æ€§ï¼Œå³é˜²å¾¡è€…é€šè¿‡å¯¹é½ä¸­é—´tokenè·ç›Šæ›´å¤šï¼Œè€Œæ”»å‡»è€…å› dLLMså®é™…ç”Ÿæˆçš„åºåˆ—å€¾å‘è€Œéš¾ä»¥æœ‰æ•ˆæ“çºµè¿™äº›æ ¸å¿ƒä½ç½®ã€‚åŸºäºæ­¤å‘ç°ï¼Œè®ºæ–‡æå‡ºäº†ä¸€ç§åä¸ºMiddle-tOken Safety Alignment (MOSA)çš„æ–°å‹å®‰å…¨å¯¹é½æ–¹æ³•ï¼Œåˆ©ç”¨å¼ºåŒ–å­¦ä¹ (reinforcement learning)ç›´æ¥å°†æ¨¡å‹çš„ä¸­é—´ç”Ÿæˆè¿‡ç¨‹ä¸å®‰å…¨æ‹’ç»å›å¤è¿›è¡Œå¯¹é½ã€‚å®éªŒç»“æœè¡¨æ˜ï¼ŒMOSAåœ¨å¤šä¸ªåŸºå‡†æµ‹è¯•å’Œå…«ç§æ”»å‡»æ–¹æ³•ä¸‹å‡å±•ç°å‡ºä¼˜è¶Šçš„å®‰å…¨æ€§èƒ½ï¼Œå¹¶èƒ½åœ¨ç¼–ç¨‹ã€æ•°å­¦åŠé€šç”¨æ¨ç†ä»»åŠ¡ä¸­ä¿æŒè‰¯å¥½çš„å®ç”¨æ€§ã€‚",
      "categories": [
        "cs.CR",
        "cs.AI",
        "cs.CL"
      ],
      "primary_category": "cs.CR",
      "comment": "Accepted for oral presentation at AAAI 2026",
      "pdf_url": "https://arxiv.org/pdf/2508.12398v2",
      "published_date": "2025-08-17 15:19:57 UTC",
      "updated_date": "2025-11-26 06:44:03 UTC",
      "processing_status": "completed",
      "attempts": 1,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "llm_backup_calls": 0,
      "last_update": "2026-01-24T12:23:26.562519+00:00"
    },
    {
      "arxiv_id": "2508.12393v2",
      "title": "MedKGent: A Large Language Model Agent Framework for Constructing Temporally Evolving Medical Knowledge Graph",
      "title_zh": "MedKGentï¼šç”¨äºæ„å»ºæ—¶å˜æ¼”åŒ–åŒ»å­¦çŸ¥è¯†å›¾è°±çš„å¤§è¯­è¨€æ¨¡å‹æ™ºèƒ½ä½“æ¡†æ¶",
      "authors": [
        "Duzhen Zhang",
        "Zixiao Wang",
        "Zhong-Zhi Li",
        "Yahan Yu",
        "Shuncheng Jia",
        "Jiahua Dong",
        "Haotian Xu",
        "Xing Wu",
        "Yingying Zhang",
        "Tielin Zhang",
        "Jie Yang",
        "Xiuying Chen",
        "Le Song"
      ],
      "abstract": "The rapid expansion of medical literature presents growing challenges for structuring and integrating domain knowledge at scale. Knowledge Graphs (KGs) offer a promising solution by enabling efficient retrieval, automated reasoning, and knowledge discovery. However, current KG construction methods often rely on supervised pipelines with limited generalizability or naively aggregate outputs from Large Language Models (LLMs), treating biomedical corpora as static and ignoring the temporal dynamics and contextual uncertainty of evolving knowledge. To address these limitations, we introduce MedKGent, a LLM agent framework for constructing temporally evolving medical KGs. Leveraging over 10 million PubMed abstracts published between 1975 and 2023, we simulate the emergence of biomedical knowledge via a fine-grained daily time series. MedKGent incrementally builds the KG in a day-by-day manner using two specialized agents powered by the Qwen2.5-32B-Instruct model. The Extractor Agent identifies knowledge triples and assigns confidence scores via sampling-based estimation, which are used to filter low-confidence extractions and inform downstream processing. The Constructor Agent incrementally integrates the retained triples into a temporally evolving graph, guided by confidence scores and timestamps to reinforce recurring knowledge and resolve conflicts. The resulting KG contains 156,275 entities and 2,971,384 relational triples. Quality assessments by two SOTA LLMs and three domain experts demonstrate an accuracy approaching 90%, with strong inter-rater agreement. To evaluate downstream utility, we conduct RAG across seven medical question answering benchmarks using five leading LLMs, consistently observing significant improvements over non-augmented baselines. Case studies further demonstrate the KG's value in literature-based drug repurposing via confidence-aware causal inference.",
      "tldr_zh": "è¯¥ç ”ç©¶æå‡ºäº†MedKGentï¼Œä¸€ä¸ªç”¨äºæ„å»ºéšæ—¶é—´æ¼”è¿›çš„åŒ»ç–—çŸ¥è¯†å›¾è°±(Temporally Evolving Medical Knowledge Graph)çš„å¤§è¯­è¨€æ¨¡å‹æ™ºèƒ½ä½“æ¡†æ¶ï¼Œæ—¨åœ¨è§£å†³ç°æœ‰æ„å»ºæ–¹æ³•å¿½ç•¥åŒ»å­¦çŸ¥è¯†åŠ¨æ€å˜åŒ–å’Œä¸ç¡®å®šæ€§çš„é—®é¢˜ã€‚è¯¥æ¡†æ¶åˆ©ç”¨1975è‡³2023å¹´é—´çš„1000ä¸‡ç¯‡PubMedæ‘˜è¦ï¼Œé€šè¿‡åŸºäºQwen2.5-32B-Instructçš„Extractor Agentå’ŒConstructor Agentï¼Œä»¥æ—¥ä¸ºå•ä½å¢é‡å¼åœ°æå–å¹¶æ•´åˆçŸ¥è¯†ä¸‰å…ƒç»„ã€‚å…¶ä¸­ï¼ŒExtractor Agenté€šè¿‡é‡‡æ ·ä¼°è®¡åˆ†é…ç½®ä¿¡åº¦åˆ†æ•°ï¼Œè€ŒConstructor Agentåˆ™ç»“åˆæ—¶é—´æˆ³è§£å†³çŸ¥è¯†å†²çªå¹¶å¼ºåŒ–é‡å¤ä¿¡æ¯ï¼Œæœ€ç»ˆæ„å»ºå‡ºåŒ…å«çº¦15.6ä¸‡ä¸ªå®ä½“å’Œè¿‘300ä¸‡ä¸ªä¸‰å…ƒç»„çš„å›¾è°±ã€‚è¯„ä¼°ç»“æœæ˜¾ç¤ºMedKGentçš„å‡†ç¡®ç‡æ¥è¿‘90%ï¼Œä¸”åœ¨ä¸ƒä¸ªåŒ»ç–—é—®ç­”åŸºå‡†æµ‹è¯•ä¸­æ˜¾è‘—å¢å¼ºäº†æ£€ç´¢å¢å¼ºç”Ÿæˆ(RAG)çš„æ•ˆæœã€‚æ­¤å¤–ï¼Œè¯¥ç ”ç©¶é€šè¿‡æ¡ˆä¾‹å±•ç¤ºäº†å…¶åœ¨è¯ç‰©é‡å®šå‘(Drug Repurposing)é¢†åŸŸçš„å› æœæ¨ç†æ½œåŠ›ï¼Œä¸ºå¤§è§„æ¨¡è‡ªåŠ¨åŒ–æ„å»ºåŠ¨æ€åŒ»å­¦çŸ¥è¯†åº“æä¾›äº†é«˜æ•ˆæ–¹æ¡ˆã€‚",
      "categories": [
        "cs.CL",
        "cs.AI"
      ],
      "primary_category": "cs.CL",
      "comment": "",
      "pdf_url": "https://arxiv.org/pdf/2508.12393v2",
      "published_date": "2025-08-17 15:14:03 UTC",
      "updated_date": "2025-08-19 05:18:31 UTC",
      "processing_status": "completed",
      "attempts": 1,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "llm_backup_calls": 0,
      "last_update": "2026-01-24T12:23:43.752494+00:00"
    },
    {
      "arxiv_id": "2508.15820v1",
      "title": "Research on intelligent generation of structural demolition suggestions based on multi-model collaboration",
      "title_zh": "åŸºäºå¤šæ¨¡å‹ååŒçš„ç»“æ„æ‹†é™¤å»ºè®®æ™ºèƒ½ç”Ÿæˆç ”ç©¶",
      "authors": [
        "Zhifeng Yang",
        "Peizong Wu"
      ],
      "abstract": "The steel structure demolition scheme needs to be compiled according to the specific engineering characteristics and the update results of the finite element model. The designers need to refer to the relevant engineering cases according to the standard requirements when compiling. It takes a lot of time to retrieve information and organize language, and the degree of automation and intelligence is low. This paper proposes an intelligent generation method of structural demolition suggestions based on multi-model collaboration, and improves the text generation performance of large language models in the field of structural demolition by Retrieval-Augmented Generation and Low-Rank Adaptation Fine-Tuning technology. The intelligent generation framework of multi-model collaborative structural demolition suggestions can start from the specific engineering situation, drive the large language model to answer with anthropomorphic thinking, and propose demolition suggestions that are highly consistent with the characteristics of the structure. Compared with CivilGPT, the multi-model collaboration framework proposed in this paper can focus more on the key information of the structure, and the suggestions are more targeted.",
      "tldr_zh": "è¯¥ç ”ç©¶é’ˆå¯¹é’¢ç»“æ„æ‹†é™¤æ–¹æ¡ˆç¼–åˆ¶è¿‡ç¨‹ä¸­è‡ªåŠ¨åŒ–ç¨‹åº¦ä½ã€äººå·¥æ£€ç´¢è€—æ—¶é•¿çš„é—®é¢˜ï¼Œæå‡ºäº†ä¸€ç§åŸºäºå¤šæ¨¡å‹ååŒ(multi-model collaboration)çš„ç»“æ„æ‹†é™¤å»ºè®®æ™ºèƒ½ç”Ÿæˆæ–¹æ³•ã€‚è¯¥æ–¹æ³•åˆ©ç”¨æ£€ç´¢å¢å¼ºç”Ÿæˆ(Retrieval-Augmented Generation, RAG)å’Œä½ç§©è‡ªé€‚åº”å¾®è°ƒ(Low-Rank Adaptation Fine-Tuning, LoRA)æŠ€æœ¯ï¼Œæ˜¾è‘—ä¼˜åŒ–äº†å¤§è¯­è¨€æ¨¡å‹(LLMs)åœ¨ç»“æ„æ‹†é™¤é¢†åŸŸçš„æ–‡æœ¬ç”Ÿæˆæ€§èƒ½ã€‚è¯¥æ¡†æ¶èƒ½å¤Ÿç»“åˆå…·ä½“å·¥ç¨‹æƒ…å†µï¼Œé©±åŠ¨æ¨¡å‹ä»¥æ‹ŸäººåŒ–æ€ç»´æå‡ºä¸ç»“æ„ç‰¹å¾é«˜åº¦ä¸€è‡´çš„æ‹†é™¤å»ºè®®ï¼Œå®ç°äº†æ–¹æ¡ˆç”Ÿæˆçš„æ™ºèƒ½åŒ–ä¸è‡ªåŠ¨åŒ–ã€‚å®éªŒç»“æœè¡¨æ˜ï¼Œä¸CivilGPTç›¸æ¯”ï¼Œè¯¥å¤šæ¨¡å‹ååŒæ¡†æ¶èƒ½å¤Ÿæ›´ç²¾å‡†åœ°èšç„¦ç»“æ„çš„ç‰©ç†å…³é”®ä¿¡æ¯ï¼Œæ‰€ç”Ÿæˆçš„å»ºè®®å…·æœ‰æ›´é«˜çš„é’ˆå¯¹æ€§å’Œå·¥ç¨‹å‚è€ƒä»·å€¼ã€‚",
      "categories": [
        "cs.CL",
        "cs.AI",
        "cs.IR"
      ],
      "primary_category": "cs.CL",
      "comment": "",
      "pdf_url": "https://arxiv.org/pdf/2508.15820v1",
      "published_date": "2025-08-17 15:03:15 UTC",
      "updated_date": "2025-08-17 15:03:15 UTC",
      "processing_status": "completed",
      "attempts": 1,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "llm_backup_calls": 0,
      "last_update": "2026-01-24T12:23:44.985734+00:00"
    },
    {
      "arxiv_id": "2508.12381v2",
      "title": "IPGPhormer: Interpretable Pathology Graph-Transformer for Survival Analysis",
      "title_zh": "IPGPhormerï¼šç”¨äºç”Ÿå­˜åˆ†æçš„å¯è§£é‡Šç—…ç†å›¾ Transformer",
      "authors": [
        "Guo Tang",
        "Songhan Jiang",
        "Jinpeng Lu",
        "Linghan Cai",
        "Yongbing Zhang"
      ],
      "abstract": "Pathological images play an essential role in cancer prognosis, while survival analysis, which integrates computational techniques, can predict critical clinical events such as patient mortality or disease recurrence from whole-slide images (WSIs). Recent advancements in multiple instance learning have significantly improved the efficiency of survival analysis. However, existing methods often struggle to balance the modeling of long-range spatial relationships with local contextual dependencies and typically lack inherent interpretability, limiting their clinical utility. To address these challenges, we propose the Interpretable Pathology Graph-Transformer (IPGPhormer), a novel framework that captures the characteristics of the tumor microenvironment and models their spatial dependencies across the tissue. IPGPhormer uniquely provides interpretability at both tissue and cellular levels without requiring post-hoc manual annotations, enabling detailed analyses of individual WSIs and cross-cohort assessments. Comprehensive evaluations on four public benchmark datasets demonstrate that IPGPhormer outperforms state-of-the-art methods in both predictive accuracy and interpretability. In summary, our method, IPGPhormer, offers a promising tool for cancer prognosis assessment, paving the way for more reliable and interpretable decision-support systems in pathology. The code is publicly available at https://anonymous.4open.science/r/IPGPhormer-6EEB.",
      "tldr_zh": "è¯¥ç ”ç©¶é’ˆå¯¹ç—…ç†å›¾åƒç”Ÿå­˜åˆ†æä¸­éš¾ä»¥å¹³è¡¡é•¿ç¨‹ç©ºé—´å…³ç³»ä¸å±€éƒ¨ä¸Šä¸‹æ–‡ä¾èµ–ã€ä¸”ç¼ºä¹è§£é‡Šæ€§çš„é—®é¢˜ï¼Œæå‡ºäº† IPGPhormer (Interpretable Pathology Graph-Transformer) æ¡†æ¶ã€‚è¯¥æ¡†æ¶é€šè¿‡æ•æ‰è‚¿ç˜¤å¾®ç¯å¢ƒ (Tumor Microenvironment) çš„ç‰¹å¾ï¼Œå¹¶æ¨¡æ‹Ÿå…¶åœ¨ç»„ç»‡ä¸­çš„ç©ºé—´ä¾èµ–å…³ç³»ï¼Œæœ‰æ•ˆæå‡äº†é¢„åé¢„æµ‹çš„æ•ˆèƒ½ã€‚IPGPhormer çš„æ ¸å¿ƒä¼˜åŠ¿åœ¨äºå…¶æ— éœ€äº‹åäººå·¥æ ‡æ³¨å³å¯åœ¨ç»„ç»‡å’Œç»†èƒæ°´å¹³ä¸Šæä¾›å†…åœ¨çš„å¯è§£é‡Šæ€§ï¼Œæ”¯æŒå¯¹å…¨åˆ‡ç‰‡å›¾åƒ (Whole-Slide Images) è¿›è¡Œæ·±å…¥çš„ä¸ªä½“åŒ–åˆ†æä¸è·¨é˜Ÿåˆ—è¯„ä¼°ã€‚åœ¨å››ä¸ªå…¬å…±åŸºå‡†æ•°æ®é›†ä¸Šçš„å®éªŒç»“æœè¯æ˜ï¼Œè¯¥æ–¹æ³•åœ¨é¢„æµ‹å‡†ç¡®æ€§å’Œå¯è§£é‡Šæ€§æ–¹é¢å‡ä¼˜äºç°æœ‰çš„å…ˆè¿›æ¨¡å‹ã€‚ç»¼ä¸Šæ‰€è¿°ï¼ŒIPGPhormer ä¸ºç™Œç—‡é¢„åè¯„ä¼°æä¾›äº†ä¸€ä¸ªå¯é ä¸”å…·æœ‰è§£é‡Šæ€§çš„å†³ç­–æ”¯æŒå·¥å…·ï¼Œå…·æœ‰é‡è¦çš„ä¸´åºŠåº”ç”¨æ½œåŠ›ã€‚",
      "categories": [
        "cs.CV",
        "cs.AI"
      ],
      "primary_category": "cs.CV",
      "comment": "13 pages, 5 figures",
      "pdf_url": "https://arxiv.org/pdf/2508.12381v2",
      "published_date": "2025-08-17 14:32:08 UTC",
      "updated_date": "2025-09-22 03:22:05 UTC",
      "processing_status": "completed",
      "attempts": 1,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "llm_backup_calls": 0,
      "last_update": "2026-01-24T12:23:45.691736+00:00"
    },
    {
      "arxiv_id": "2508.12379v2",
      "title": "GraphCogent: Mitigating LLMs' Working Memory Constraints via Multi-Agent Collaboration in Complex Graph Understanding",
      "title_zh": "GraphCogentï¼šé€šè¿‡å¤šæ™ºèƒ½ä½“åä½œç¼“è§£å¤æ‚å›¾ç†è§£ä¸­çš„å¤§è¯­è¨€æ¨¡å‹å·¥ä½œè®°å¿†çº¦æŸ",
      "authors": [
        "Rongzheng Wang",
        "Shuang Liang",
        "Qizhi Chen",
        "Yihong Huang",
        "Muquan Li",
        "Yizhuo Ma",
        "Dongyang Zhang",
        "Ke Qin",
        "Man-Fai Leung"
      ],
      "abstract": "Large language models (LLMs) show promising performance on small-scale graph reasoning tasks but fail when handling real-world graphs with complex queries. This phenomenon arises from LLMs' working memory constraints, which result in their inability to retain long-range graph topology over extended contexts while sustaining coherent multi-step reasoning. However, real-world graphs are often structurally complex, such as Web, Transportation, Social, and Citation networks. To address these limitations, we propose GraphCogent, a collaborative agent framework inspired by human Working Memory Model that decomposes graph reasoning into specialized cognitive processes: sense, buffer, and execute. The framework consists of three modules: Sensory Module standardizes diverse graph text representations via subgraph sampling, Buffer Module integrates and indexes graph data across multiple formats, and Execution Module combines tool calling and tool creation for efficient reasoning. We also introduce Graph4real, a comprehensive benchmark that contains four domains of real-world graphs (Web, Transportation, Social, and Citation) to evaluate LLMs' graph reasoning capabilities. Our Graph4real covers 21 different graph reasoning tasks, categorized into three types (Structural Querying, Algorithmic Reasoning, and Predictive Modeling tasks), with graph scales up to 10 times larger than existing benchmarks. Experiments show that Llama3.1-8B based GraphCogent achieves a 50% improvement over massive-scale LLMs like DeepSeek-R1 (671B). Compared to state-of-the-art agent-based baseline, our framework outperforms by 20% in accuracy while reducing token usage by 80% for in-toolset tasks and 30% for out-toolset tasks. Code will be available after review.",
      "tldr_zh": "è¯¥ç ”ç©¶é’ˆå¯¹å¤§è¯­è¨€æ¨¡å‹(LLMs)åœ¨å¤„ç†ç°å®ä¸–ç•Œå¤æ‚å›¾æ¨ç†ä»»åŠ¡æ—¶å› å·¥ä½œè®°å¿†(Working Memory)é™åˆ¶è€Œå¯¼è‡´çš„æ€§èƒ½ä¸‹é™é—®é¢˜ï¼Œæå‡ºäº†GraphCogentæ¡†æ¶ã€‚è¯¥æ¡†æ¶å—äººç±»å·¥ä½œè®°å¿†æ¨¡å‹å¯å‘ï¼Œé€šè¿‡å¤šæ™ºèƒ½ä½“åä½œå°†å›¾æ¨ç†åˆ†è§£ä¸ºæ„ŸçŸ¥(Sense)ã€ç¼“å†²(Buffer)å’Œæ‰§è¡Œ(Execute)ä¸‰ä¸ªè®¤çŸ¥è¿‡ç¨‹ã€‚å…·ä½“è€Œè¨€ï¼ŒSensory Moduleé€šè¿‡å­å›¾é‡‡æ ·(subgraph sampling)æ ‡å‡†åŒ–å›¾æ–‡æœ¬è¡¨ç¤ºï¼ŒBuffer Moduleæ•´åˆå¹¶ç´¢å¼•å¤šæ ¼å¼æ•°æ®ï¼Œè€ŒExecution Moduleç»“åˆå·¥å…·è°ƒç”¨(tool calling)ä¸åˆ›å»ºå®ç°é«˜æ•ˆæ¨ç†ã€‚æ­¤å¤–ï¼Œç ”ç©¶è¿˜å¼•å…¥äº†è§„æ¨¡æ¯”ç°æœ‰åŸºå‡†å¤§10å€çš„Graph4realåŸºå‡†æµ‹è¯•ï¼Œæ¶µç›–Webã€äº¤é€šã€ç¤¾äº¤å’Œå¼•ç”¨ç½‘ç»œå››å¤§é¢†åŸŸçš„21é¡¹æ¨ç†ä»»åŠ¡ã€‚å®éªŒç»“æœæ˜¾ç¤ºï¼ŒåŸºäºLlama3.1-8Bçš„GraphCogentåœ¨å‡†ç¡®ç‡ä¸Šæ¯”DeepSeek-R1ç­‰å·¨å‹æ¨¡å‹æå‡äº†50%ï¼Œåœ¨æ˜¾è‘—ä¼˜äºç°æœ‰æ™ºèƒ½ä½“åŸºçº¿æ¨¡å‹çš„åŒæ—¶å¤§å¹…é™ä½äº†Tokenæ¶ˆè€—ï¼Œä¸ºå¤æ‚å›¾ç†è§£æä¾›äº†é«˜æ•ˆä¸”å¯æ‰©å±•çš„è§£å†³æ–¹æ¡ˆã€‚",
      "categories": [
        "cs.AI"
      ],
      "primary_category": "cs.AI",
      "comment": "",
      "pdf_url": "https://arxiv.org/pdf/2508.12379v2",
      "published_date": "2025-08-17 14:28:38 UTC",
      "updated_date": "2025-09-30 14:56:50 UTC",
      "processing_status": "completed",
      "attempts": 1,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "llm_backup_calls": 0,
      "last_update": "2026-01-24T12:23:53.694917+00:00"
    },
    {
      "arxiv_id": "2508.12375v1",
      "title": "Hierarchical knowledge guided fault intensity diagnosis of complex industrial systems",
      "title_zh": "å±‚çº§çŸ¥è¯†å¼•å¯¼ä¸‹çš„å¤æ‚å·¥ä¸šç³»ç»Ÿæ•…éšœç¨‹åº¦è¯Šæ–­",
      "authors": [
        "Yu Sha",
        "Shuiping Gou",
        "Bo Liu",
        "Johannes Faber",
        "Ningtao Liu",
        "Stefan Schramm",
        "Horst Stoecker",
        "Thomas Steckenreiter",
        "Domagoj Vnucec",
        "Nadine Wetzstein",
        "Andreas Widl",
        "Kai Zhou"
      ],
      "abstract": "Fault intensity diagnosis (FID) plays a pivotal role in monitoring and maintaining mechanical devices within complex industrial systems. As current FID methods are based on chain of thought without considering dependencies among target classes. To capture and explore dependencies, we propose a hierarchical knowledge guided fault intensity diagnosis framework (HKG) inspired by the tree of thought, which is amenable to any representation learning methods. The HKG uses graph convolutional networks to map the hierarchical topological graph of class representations into a set of interdependent global hierarchical classifiers, where each node is denoted by word embeddings of a class. These global hierarchical classifiers are applied to learned deep features extracted by representation learning, allowing the entire model to be end-to-end learnable. In addition, we develop a re-weighted hierarchical knowledge correlation matrix (Re-HKCM) scheme by embedding inter-class hierarchical knowledge into a data-driven statistical correlation matrix (SCM) which effectively guides the information sharing of nodes in graphical convolutional neural networks and avoids over-smoothing issues. The Re-HKCM is derived from the SCM through a series of mathematical transformations. Extensive experiments are performed on four real-world datasets from different industrial domains (three cavitation datasets from SAMSON AG and one existing publicly) for FID, all showing superior results and outperform recent state-of-the-art FID methods.",
      "tldr_zh": "è¯¥ç ”ç©¶é’ˆå¯¹å¤æ‚å·¥ä¸šç³»ç»Ÿä¸­æ•…éšœå¼ºåº¦è¯Šæ–­(Fault Intensity Diagnosis, FID)é¢ä¸´çš„ç›®æ ‡ç±»åˆ«ä¾èµ–æ€§ç¼ºå¤±é—®é¢˜ï¼Œæå‡ºäº†ä¸€ç§å—æ€ç»´æ ‘(Tree of Thought)å¯å‘çš„å±‚çº§çŸ¥è¯†å¼•å¯¼æ¡†æ¶(HKG)ã€‚è¯¥æ¡†æ¶åˆ©ç”¨å›¾å·ç§¯ç½‘ç»œ(Graph Convolutional Networks)å°†ç±»åˆ«è¡¨ç¤ºçš„å±‚çº§æ‹“æ‰‘å›¾æ˜ å°„ä¸ºç›¸äº’ä¾èµ–çš„å…¨å±€å±‚çº§åˆ†ç±»å™¨ï¼Œå¹¶é€šè¿‡æ·±åº¦ç‰¹å¾æå–å®ç°ç«¯åˆ°ç«¯å­¦ä¹ ã€‚ä¸ºäº†ä¼˜åŒ–èŠ‚ç‚¹é—´çš„ä¿¡æ¯å…±äº«å¹¶ç¼“è§£è¿‡å¹³æ»‘é—®é¢˜ï¼Œç ”ç©¶è€…å¼€å‘äº†é‡åŠ æƒå±‚çº§çŸ¥è¯†ç›¸å…³çŸ©é˜µ(Re-HKCM)ï¼Œé€šè¿‡æ•°å­¦å˜æ¢å°†å±‚çº§çŸ¥è¯†åµŒå…¥æ•°æ®é©±åŠ¨çš„ç»Ÿè®¡ç›¸å…³çŸ©é˜µ(SCM)ä¸­ã€‚åœ¨åŒ…æ‹¬ä¸‰ä¸ªæ¥è‡ªSAMSON AGçš„ç©ºåŒ–æ•°æ®é›†åœ¨å†…çš„å››ä¸ªçœŸå®å·¥ä¸šåœºæ™¯å®éªŒä¸­ï¼ŒHKGå±•ç°äº†ä¼˜äºç°æœ‰æœ€å…ˆè¿›(SOTA)æ–¹æ³•çš„è¯Šæ–­æ€§èƒ½ï¼Œæœ‰æ•ˆæå‡äº†å¤æ‚ç³»ç»Ÿç›‘æµ‹çš„å‡†ç¡®æ€§å’Œé²æ£’æ€§ã€‚",
      "categories": [
        "cs.AI"
      ],
      "primary_category": "cs.AI",
      "comment": "12 pages",
      "pdf_url": "https://arxiv.org/pdf/2508.12375v1",
      "published_date": "2025-08-17 14:22:03 UTC",
      "updated_date": "2025-08-17 14:22:03 UTC",
      "processing_status": "completed",
      "attempts": 1,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "llm_backup_calls": 0,
      "last_update": "2026-01-24T12:23:58.790749+00:00"
    },
    {
      "arxiv_id": "2508.12365v3",
      "title": "TaoSR1: The Thinking Model for E-commerce Relevance Search",
      "title_zh": "TaoSR1ï¼šé¢å‘ç”µå•†ç›¸å…³æ€§æœç´¢çš„æ€ç»´æ¨¡å‹",
      "authors": [
        "Chenhe Dong",
        "Shaowei Yao",
        "Pengkun Jiao",
        "Jianhui Yang",
        "Yiming Jin",
        "Zerui Huang",
        "Xiaojiang Zhou",
        "Dan Ou",
        "Haihong Tang",
        "Bo Zheng"
      ],
      "abstract": "Query-product relevance prediction is a core task in e-commerce search. BERT-based models excel at semantic matching but lack complex reasoning capabilities. While Large Language Models (LLMs) are explored, most still use discriminative fine-tuning or distill to smaller models for deployment. We propose a framework to directly deploy LLMs for this task, addressing key challenges: Chain-of-Thought (CoT) error accumulation, discriminative hallucination, and deployment feasibility. Our framework, TaoSR1, involves three stages: (1) Supervised Fine-Tuning (SFT) with CoT to instill reasoning; (2) Offline sampling with a pass@N strategy and Direct Preference Optimization (DPO) to improve generation quality; and (3) Difficulty-based dynamic sampling with Group Relative Policy Optimization (GRPO) to mitigate discriminative hallucination. Additionally, post-CoT processing and a cumulative probability-based partitioning method enable efficient online deployment. TaoSR1 significantly outperforms baselines on offline datasets and achieves substantial gains in online side-by-side human evaluations, introducing a novel paradigm for applying CoT reasoning to relevance classification.",
      "tldr_zh": "è¯¥ç ”ç©¶æå‡ºäº† TaoSR1ï¼Œä¸€ç§ä¸“ä¸ºç”µå­å•†åŠ¡æœç´¢ä¸­çš„æŸ¥è¯¢-äº§å“ç›¸å…³æ€§é¢„æµ‹ï¼ˆQuery-product relevance predictionï¼‰è®¾è®¡çš„æ€è€ƒæ¨¡å‹ï¼Œæ—¨åœ¨è§£å†³ä¼ ç»Ÿ BERT æ¨¡å‹ç¼ºä¹å¤æ‚æ¨ç†èƒ½åŠ›ä»¥åŠå¤§è¯­è¨€æ¨¡å‹ï¼ˆLLMsï¼‰éƒ¨ç½²éš¾ç­‰é—®é¢˜ã€‚TaoSR1 æ¡†æ¶é€šè¿‡ä¸‰ä¸ªé˜¶æ®µè§£å†³ Chain-of-Thought (CoT) è¯¯å·®ç§¯ç´¯ã€åˆ¤åˆ«æ€§å¹»è§‰ï¼ˆdiscriminative hallucinationï¼‰ä»¥åŠåœ¨çº¿éƒ¨ç½²çš„å¯è¡Œæ€§æŒ‘æˆ˜ã€‚è¯¥æ–¹æ³•é¦–å…ˆåˆ©ç”¨å¸¦æœ‰ CoT çš„ç›‘ç£å¾®è°ƒï¼ˆSFTï¼‰èµ‹äºˆæ¨¡å‹æ¨ç†èƒ½åŠ›ï¼Œå¹¶ç»“åˆç¦»çº¿é‡‡æ ·ä¸ç›´æ¥åå¥½ä¼˜åŒ–ï¼ˆDPOï¼‰æå‡ç”Ÿæˆè´¨é‡ï¼Œéšåé€šè¿‡åŸºäºéš¾åº¦çš„åŠ¨æ€é‡‡æ ·å’Œç¾¤ä½“ç›¸å¯¹ç­–ç•¥ä¼˜åŒ–ï¼ˆGRPOï¼‰æ¥ç¼“è§£åˆ¤åˆ«æ€§å¹»è§‰ã€‚æ­¤å¤–ï¼Œç ”ç©¶è¿˜å¼•å…¥äº†å CoT å¤„ç†å’ŒåŸºäºç´¯ç§¯æ¦‚ç‡çš„åˆ†åŒºæ–¹æ³•ï¼Œç¡®ä¿äº†æ¨¡å‹åœ¨å®é™…ç”Ÿäº§ç¯å¢ƒä¸­çš„åœ¨çº¿éƒ¨ç½²æ•ˆç‡ã€‚å®éªŒç»“æœè¡¨æ˜ï¼ŒTaoSR1 åœ¨ç¦»çº¿æ•°æ®é›†å’Œåœ¨çº¿äººå·¥è¯„ä¼°ä¸­å‡æ˜¾è‘—ä¼˜äºåŸºå‡†æ¨¡å‹ï¼Œä¸ºå°† CoT æ¨ç†åº”ç”¨äºç›¸å…³æ€§åˆ†ç±»ä»»åŠ¡å¼€è¾Ÿäº†å…¨æ–°çš„èŒƒå¼ã€‚",
      "categories": [
        "cs.IR",
        "cs.AI",
        "cs.CL"
      ],
      "primary_category": "cs.IR",
      "comment": "",
      "pdf_url": "https://arxiv.org/pdf/2508.12365v3",
      "published_date": "2025-08-17 13:48:48 UTC",
      "updated_date": "2025-12-04 09:49:41 UTC",
      "processing_status": "completed",
      "attempts": 1,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "llm_backup_calls": 0,
      "last_update": "2026-01-24T12:24:05.395858+00:00"
    },
    {
      "arxiv_id": "2508.12361v1",
      "title": "Navigating the Exploration-Exploitation Tradeoff in Inference-Time Scaling of Diffusion Models",
      "title_zh": "æ‰©æ•£æ¨¡å‹æ¨ç†ä¾§æ‰©å±•ä¸­æ¢ç´¢ä¸åˆ©ç”¨çš„æƒè¡¡",
      "authors": [
        "Xun Su",
        "Jianming Huang",
        "Yang Yusen",
        "Zhongxi Fang",
        "Hiroyuki Kasai"
      ],
      "abstract": "Inference-time scaling has achieved remarkable success in language models, yet its adaptation to diffusion models remains underexplored. We observe that the efficacy of recent Sequential Monte Carlo (SMC)-based methods largely stems from globally fitting the The reward-tilted distribution, which inherently preserves diversity during multi-modal search. However, current applications of SMC to diffusion models face a fundamental dilemma: early-stage noise samples offer high potential for improvement but are difficult to evaluate accurately, whereas late-stage samples can be reliably assessed but are largely irreversible. To address this exploration-exploitation trade-off, we approach the problem from the perspective of the search algorithm and propose two strategies: Funnel Schedule and Adaptive Temperature. These simple yet effective methods are tailored to the unique generation dynamics and phase-transition behavior of diffusion models. By progressively reducing the number of maintained particles and down-weighting the influence of early-stage rewards, our methods significantly enhance sample quality without increasing the total number of Noise Function Evaluations. Experimental results on multiple benchmarks and state-of-the-art text-to-image diffusion models demonstrate that our approach outperforms previous baselines.",
      "tldr_zh": "è¯¥ç ”ç©¶æ¢è®¨äº†æ‰©æ•£æ¨¡å‹ (Diffusion Models) åœ¨æ¨ç†æ—¶æ‰©å±• (Inference-time scaling) ä¸­çš„æ¢ç´¢ä¸åˆ©ç”¨æƒè¡¡ (Exploration-Exploitation Tradeoff) é—®é¢˜ï¼Œé’ˆå¯¹ç°æœ‰åºåˆ—è’™ç‰¹å¡æ´› (Sequential Monte Carlo, SMC) æ–¹æ³•åœ¨æ—©æœŸè¯„ä¼°ä¸å‡†ä¸åæœŸè·¯å¾„ä¸å¯é€†ä¹‹é—´çš„çŸ›ç›¾è¿›è¡Œäº†æ”¹è¿›ã€‚ä½œè€…æå‡ºäº†æ¼æ–—å¼è°ƒåº¦ (Funnel Schedule) å’Œè‡ªé€‚åº”æ¸©åº¦ (Adaptive Temperature) ä¸¤é¡¹ç­–ç•¥ï¼Œæ—¨åœ¨é€‚åº”æ‰©æ•£æ¨¡å‹çš„ç”ŸæˆåŠ¨åŠ›å­¦å’Œç›¸ä½è½¬æ¢ (Phase-transition) ç‰¹æ€§ã€‚é€šè¿‡é€æ­¥å‡å°‘ç²’å­ (Particles) ç»´æŒæ•°é‡å¹¶é™ä½æ—©æœŸå¥–åŠ±æƒé‡ï¼Œè¯¥æ–¹æ³•åœ¨ä¸å¢åŠ æ€»å™ªå£°å‡½æ•°è¯„ä¼°æ¬¡æ•° (Noise Function Evaluations, NFE) çš„æƒ…å†µä¸‹æ˜¾è‘—æå‡äº†é‡‡æ ·è´¨é‡ã€‚å®éªŒç»“æœè¡¨æ˜ï¼Œè¯¥æ–¹æ³•åœ¨å¤šé¡¹åŸºå‡†æµ‹è¯•å’Œæœ€å…ˆè¿›çš„æ–‡æœ¬ç”Ÿæˆå›¾åƒæ‰©æ•£æ¨¡å‹ä¸­å‡ä¼˜äºç°æœ‰çš„åŸºçº¿æ¨¡å‹ã€‚",
      "categories": [
        "cs.LG",
        "cs.AI",
        "math.ST"
      ],
      "primary_category": "cs.LG",
      "comment": "",
      "pdf_url": "https://arxiv.org/pdf/2508.12361v1",
      "published_date": "2025-08-17 13:35:38 UTC",
      "updated_date": "2025-08-17 13:35:38 UTC",
      "processing_status": "completed",
      "attempts": 1,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "llm_backup_calls": 0,
      "last_update": "2026-01-24T12:24:09.882787+00:00"
    },
    {
      "arxiv_id": "2508.12358v1",
      "title": "Uncovering Systematic Failures of LLMs in Verifying Code Against Natural Language Specifications",
      "title_zh": "æ­ç¤ºå¤§è¯­è¨€æ¨¡å‹åœ¨ä¾æ®è‡ªç„¶è¯­è¨€è§„èŒƒéªŒè¯ä»£ç æ—¶çš„ç³»ç»Ÿæ€§å¤±æ•ˆ",
      "authors": [
        "Haolin Jin",
        "Huaming Chen"
      ],
      "abstract": "Large language models (LLMs) have become essential tools in software development, widely used for requirements engineering, code generation and review tasks. Software engineers often rely on LLMs to assess whether system code implementation satisfy task requirements, thereby enhancing code robustness and accuracy. However, it remains unclear whether LLMs can reliably determine whether the code complies fully with the given task descriptions, which is usually natural language specifications. In this paper, we uncover a systematic failure of LLMs in evaluating whether code aligns with natural language requirements. Specifically, with widely used benchmarks, we employ unified prompts to judge code correctness. Our results reveal that LLMs frequently misclassify correct code implementations as either ``not satisfying requirements'' or containing potential defects. Surprisingly, more complex prompting, especially when leveraging prompt engineering techniques involving explanations and proposed corrections, leads to higher misjudgment rate, which highlights the critical reliability issues in using LLMs as code review assistants. We further analyze the root causes of these misjudgments, and propose two improved prompting strategies for mitigation. For the first time, our findings reveals unrecognized limitations in LLMs to match code with requirements. We also offer novel insights and practical guidance for effective use of LLMs in automated code review and task-oriented agent scenarios.",
      "tldr_zh": "è¯¥ç ”ç©¶è°ƒæŸ¥äº†å¤§è¯­è¨€æ¨¡å‹ (LLMs) åœ¨éªŒè¯ä»£ç å®ç°æ˜¯å¦ç¬¦åˆè‡ªç„¶è¯­è¨€è§„èŒƒ (Natural Language Specifications) æ–¹é¢çš„å¯é æ€§ï¼Œæ­ç¤ºäº†æ¨¡å‹åœ¨è¯„ä¼°ä»£ç ä¸éœ€æ±‚å¯¹é½æ—¶å­˜åœ¨çš„ç³»ç»Ÿæ€§å¤±æ•ˆ (Systematic Failure)ã€‚å®éªŒè¡¨æ˜ï¼ŒLLMs ç»å¸¸å°†æ­£ç¡®çš„ä»£ç å®ç°è¯¯åˆ¤ä¸ºä¸ç¬¦åˆéœ€æ±‚æˆ–å­˜åœ¨ç¼ºé™·ï¼Œä¸”ä»¤äººæ„å¤–çš„æ˜¯ï¼Œé‡‡ç”¨åŒ…å«è§£é‡Šå’Œä¿®æ­£å»ºè®®çš„å¤æ‚æç¤ºè¯å·¥ç¨‹ (Prompt Engineering) æŠ€æœ¯åè€Œä¼šæé«˜è¯¯åˆ¤ç‡ï¼Œå‡¸æ˜¾äº† LLMs ä½œä¸ºä»£ç è¯„å®¡åŠ©æ‰‹æ—¶çš„å¯é æ€§æŒ‘æˆ˜ã€‚ç ”ç©¶é€šè¿‡åˆ†æè¯¯åˆ¤çš„æ ¹æœ¬åŸå› ï¼Œæå‡ºäº†ä¸¤ç§æ”¹è¿›çš„æç¤ºç­–ç•¥ä»¥ç¼“è§£ä¸Šè¿°é—®é¢˜ã€‚è¯¥å·¥ä½œé¦–æ¬¡æ­ç¤ºäº† LLMs åœ¨ä»£ç éœ€æ±‚åŒ¹é…æ–¹é¢å­˜åœ¨çš„å±€é™æ€§ï¼Œå¹¶ä¸ºè‡ªåŠ¨åŒ–ä»£ç è¯„å®¡å’Œä»»åŠ¡å¯¼å‘å‹æ™ºèƒ½ä½“ (Agent) åœºæ™¯ä¸‹æœ‰æ•ˆåˆ©ç”¨ LLMs æä¾›äº†é‡è¦çš„å®è·µæŒ‡å¯¼å’Œè§è§£ã€‚",
      "categories": [
        "cs.SE",
        "cs.AI"
      ],
      "primary_category": "cs.SE",
      "comment": "Accepted to the NIER track of the 40th IEEE/ACM International Conference on Automated Software Engineering (ASE 2025)",
      "pdf_url": "https://arxiv.org/pdf/2508.12358v1",
      "published_date": "2025-08-17 13:07:26 UTC",
      "updated_date": "2025-08-17 13:07:26 UTC",
      "processing_status": "completed",
      "attempts": 1,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "llm_backup_calls": 0,
      "last_update": "2026-01-24T12:24:12.491698+00:00"
    },
    {
      "arxiv_id": "2508.12356v1",
      "title": "Synthetic Data is Sufficient for Zero-Shot Visual Generalization from Offline Data",
      "title_zh": "åˆæˆæ•°æ®è¶³ä»¥å®ç°åŸºäºç¦»çº¿æ•°æ®çš„é›¶æ ·æœ¬è§†è§‰æ³›åŒ–",
      "authors": [
        "Ahmet H. GÃ¼zel",
        "Ilija Bogunovic",
        "Jack Parker-Holder"
      ],
      "abstract": "Offline reinforcement learning (RL) offers a promising framework for training agents using pre-collected datasets without the need for further environment interaction. However, policies trained on offline data often struggle to generalise due to limited exposure to diverse states. The complexity of visual data introduces additional challenges such as noise, distractions, and spurious correlations, which can misguide the policy and increase the risk of overfitting if the training data is not sufficiently diverse. Indeed, this makes it challenging to leverage vision-based offline data in training robust agents that can generalize to unseen environments. To solve this problem, we propose a simple approach generating additional synthetic training data. We propose a two-step process, first augmenting the originally collected offline data to improve zero-shot generalization by introducing diversity, then using a diffusion model to generate additional data in latent space. We test our method across both continuous action spaces (Visual D4RL) and discrete action spaces (Procgen), demonstrating that it significantly improves generalization without requiring any algorithmic changes to existing model-free offline RL methods. We show that our method not only increases the diversity of the training data but also significantly reduces the generalization gap at test time while maintaining computational efficiency. We believe this approach could fuel additional progress in generating synthetic data to train more general agents in the future.",
      "tldr_zh": "è¿™é¡¹ç ”ç©¶é’ˆå¯¹ç¦»çº¿å¼ºåŒ–å­¦ä¹ (Offline Reinforcement Learning)ä¸­è§†è§‰æ•°æ®æ³›åŒ–èƒ½åŠ›ä¸è¶³çš„é—®é¢˜ï¼Œæå‡ºäº†åˆ©ç”¨åˆæˆæ•°æ®æå‡é›¶æ ·æœ¬è§†è§‰æ³›åŒ–(Zero-Shot Visual Generalization)çš„æ–°æ–¹æ³•ã€‚è¯¥æ–¹æ³•åŒ…å«ä¸€ä¸ªä¸¤æ­¥å¤„ç†è¿‡ç¨‹ï¼Œé¦–å…ˆé€šè¿‡å¯¹åŸå§‹é‡‡é›†çš„ç¦»çº¿æ•°æ®è¿›è¡Œå¢å¼ºæ¥å¼•å…¥å¤šæ ·æ€§ï¼Œéšååˆ©ç”¨æ‰©æ•£æ¨¡å‹(Diffusion Model)åœ¨æ½œç©ºé—´(Latent Space)ä¸­ç”Ÿæˆé¢å¤–çš„åˆæˆè®­ç»ƒæ•°æ®ã€‚ç ”ç©¶åœ¨è¿ç»­åŠ¨ä½œç©ºé—´(Visual D4RL)å’Œç¦»æ•£åŠ¨ä½œç©ºé—´(Procgen)ä»»åŠ¡ä¸­è¿›è¡Œäº†éªŒè¯ï¼Œè¯æ˜è¯¥æ–¹æ³•åœ¨æ— éœ€æ”¹å˜ç°æœ‰æ— æ¨¡å‹ç¦»çº¿å¼ºåŒ–å­¦ä¹ (Model-free Offline RL)ç®—æ³•çš„å‰æä¸‹ï¼Œèƒ½æ˜¾è‘—æé«˜æ™ºèƒ½ä½“çš„æ€§èƒ½ã€‚å®éªŒç»“æœæ˜¾ç¤ºï¼Œè¿™ç§æ–¹æ³•ä¸ä»…å¢åŠ äº†è®­ç»ƒæ•°æ®çš„å¤šæ ·æ€§ï¼Œè¿˜å¤§å¹…ç¼©å°äº†æµ‹è¯•é˜¶æ®µçš„æ³›åŒ–å·®è·(Generalization Gap)ï¼ŒåŒæ—¶å…¼é¡¾äº†è®¡ç®—æ•ˆç‡ã€‚è¯¥ç ”ç©¶å±•ç¤ºäº†åˆæˆæ•°æ®åœ¨è®­ç»ƒæ›´å…·é€šç”¨æ€§æ™ºèƒ½ä½“æ–¹é¢çš„å·¨å¤§æ½œåŠ›ï¼Œä¸ºè§£å†³è§†è§‰RLç¯å¢ƒä¸­çš„è¿‡æ‹Ÿåˆå’Œå™ªå£°å¹²æ‰°é—®é¢˜æä¾›äº†æœ‰æ•ˆé€”å¾„ã€‚",
      "categories": [
        "cs.CV",
        "cs.AI",
        "cs.LG"
      ],
      "primary_category": "cs.CV",
      "comment": "",
      "pdf_url": "https://arxiv.org/pdf/2508.12356v1",
      "published_date": "2025-08-17 13:01:15 UTC",
      "updated_date": "2025-08-17 13:01:15 UTC",
      "processing_status": "completed",
      "attempts": 1,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "llm_backup_calls": 0,
      "last_update": "2026-01-24T12:24:13.400906+00:00"
    },
    {
      "arxiv_id": "2508.13223v1",
      "title": "MIRAGE: Towards AI-Generated Image Detection in the Wild",
      "title_zh": "MIRAGEï¼šé¢å‘å¤æ‚ç°å®åœºæ™¯çš„ AI ç”Ÿæˆå›¾åƒæ£€æµ‹",
      "authors": [
        "Cheng Xia",
        "Manxi Lin",
        "Jiexiang Tan",
        "Xiaoxiong Du",
        "Yang Qiu",
        "Junjun Zheng",
        "Xiangheng Kong",
        "Yuning Jiang",
        "Bo Zheng"
      ],
      "abstract": "The spreading of AI-generated images (AIGI), driven by advances in generative AI, poses a significant threat to information security and public trust. Existing AIGI detectors, while effective against images in clean laboratory settings, fail to generalize to in-the-wild scenarios. These real-world images are noisy, varying from ``obviously fake\" images to realistic ones derived from multiple generative models and further edited for quality control. We address in-the-wild AIGI detection in this paper. We introduce Mirage, a challenging benchmark designed to emulate the complexity of in-the-wild AIGI. Mirage is constructed from two sources: (1) a large corpus of Internet-sourced AIGI verified by human experts, and (2) a synthesized dataset created through the collaboration between multiple expert generators, closely simulating the realistic AIGI in the wild. Building on this benchmark, we propose Mirage-R1, a vision-language model with heuristic-to-analytic reasoning, a reflective reasoning mechanism for AIGI detection. Mirage-R1 is trained in two stages: a supervised-fine-tuning cold start, followed by a reinforcement learning stage. By further adopting an inference-time adaptive thinking strategy, Mirage-R1 is able to provide either a quick judgment or a more robust and accurate conclusion, effectively balancing inference speed and performance. Extensive experiments show that our model leads state-of-the-art detectors by 5% and 10% on Mirage and the public benchmark, respectively. The benchmark and code will be made publicly available.",
      "tldr_zh": "é’ˆå¯¹ç”Ÿæˆå¼ AI å¸¦æ¥çš„ä¿¡æ¯å®‰å…¨æŒ‘æˆ˜ä»¥åŠç°æœ‰æ£€æµ‹å™¨åœ¨ç°å®å¤æ‚åœºæ™¯ï¼ˆin-the-wildï¼‰ä¸‹æ³›åŒ–èƒ½åŠ›ä¸è¶³çš„é—®é¢˜ï¼Œè¯¥ç ”ç©¶è‡´åŠ›äºæå‡ AI-generated images (AIGI) çš„æ£€æµ‹æ€§èƒ½ã€‚ç ”ç©¶è€…é¦–å…ˆæ„å»ºäº†åä¸º Mirage çš„æŒ‘æˆ˜æ€§åŸºå‡†ï¼Œé€šè¿‡æ•´åˆä¸“å®¶æ ¸å®çš„äº’è”ç½‘ AIGI æ•°æ®ä¸å¤šæ¨¡å‹åä½œåˆæˆçš„æ•°æ®ï¼ŒçœŸå®æ¨¡æ‹Ÿäº†ç°å®ä¸–ç•Œä¸­å™ªå£°å¤šå˜ä¸”é«˜åº¦å†™å®çš„å›¾åƒç‰¹å¾ã€‚åœ¨æ­¤åŸºç¡€ä¸Šï¼Œè®ºæ–‡æå‡ºäº† Mirage-R1ï¼Œè¿™æ˜¯ä¸€ç§å…·å¤‡ä»å¯å‘å¼åˆ°åˆ†æå¼æ¨ç†ï¼ˆheuristic-to-analytic reasoningï¼‰èƒ½åŠ›çš„ Vision-Language Modelï¼Œå¹¶å¼•å…¥äº†åæ€æ€§æ¨ç†æœºåˆ¶ï¼ˆreflective reasoning mechanismï¼‰ã€‚Mirage-R1 ç»å†äº† Supervised-Fine-Tuning (SFT) å’Œ Reinforcement Learning (RL) ä¸¤é˜¶æ®µè®­ç»ƒï¼Œå¹¶é‡‡ç”¨æ¨ç†æ—¶è‡ªé€‚åº”æ€è€ƒç­–ç•¥ï¼ˆinference-time adaptive thinkingï¼‰æ¥æœ‰æ•ˆå¹³è¡¡æ£€æµ‹é€Ÿåº¦ä¸å‡†ç¡®æ€§ã€‚å®éªŒç»“æœæ˜¾ç¤ºï¼ŒMirage-R1 åœ¨ Mirage åŸºå‡†å’Œå…¬å…±æ•°æ®é›†ä¸Šåˆ†åˆ«æ¯”ç°æœ‰æœ€å…ˆè¿›æ£€æµ‹å™¨æ€§èƒ½æé«˜ 5% å’Œ 10%ï¼Œä¸ºåº”å¯¹çœŸå®ç¯å¢ƒä¸­çš„ AIGI è¯†åˆ«éš¾é¢˜æä¾›äº†é‡è¦çš„æŠ€æœ¯æ”¯æ’‘ã€‚",
      "categories": [
        "cs.CV",
        "cs.AI"
      ],
      "primary_category": "cs.CV",
      "comment": "",
      "pdf_url": "https://arxiv.org/pdf/2508.13223v1",
      "published_date": "2025-08-17 12:59:58 UTC",
      "updated_date": "2025-08-17 12:59:58 UTC",
      "processing_status": "completed",
      "attempts": 1,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "llm_backup_calls": 0,
      "last_update": "2026-01-24T12:24:19.990813+00:00"
    },
    {
      "arxiv_id": "2508.12353v1",
      "title": "A Large-Scale Web Search Dataset for Federated Online Learning to Rank",
      "title_zh": "é¢å‘è”é‚¦åœ¨çº¿æ’åºå­¦ä¹ çš„å¤§è§„æ¨¡ç½‘é¡µæœç´¢æ•°æ®é›†",
      "authors": [
        "Marcel Gregoriadis",
        "Jingwei Kang",
        "Johan Pouwelse"
      ],
      "abstract": "The centralized collection of search interaction logs for training ranking models raises significant privacy concerns. Federated Online Learning to Rank (FOLTR) offers a privacy-preserving alternative by enabling collaborative model training without sharing raw user data. However, benchmarks in FOLTR are largely based on random partitioning of classical learning-to-rank datasets, simulated user clicks, and the assumption of synchronous client participation. This oversimplifies real-world dynamics and undermines the realism of experimental results. We present AOL4FOLTR, a large-scale web search dataset with 2.6 million queries from 10,000 users. Our dataset addresses key limitations of existing benchmarks by including user identifiers, real click data, and query timestamps, enabling realistic user partitioning, behavior modeling, and asynchronous federated learning scenarios.",
      "tldr_zh": "è¯¥ç ”ç©¶æå‡ºäº†AOL4FOLTRï¼Œè¿™æ˜¯ä¸€ä¸ªä¸“ä¸ºè”é‚¦åœ¨çº¿å­¦ä¹ æ’åº(Federated Online Learning to Rank, FOLTR)è®¾è®¡çš„å¤§è§„æ¨¡ç½‘ç»œæœç´¢æ•°æ®é›†ï¼Œæ—¨åœ¨è§£å†³é›†ä¸­å¼æœç´¢æ—¥å¿—æ”¶é›†ä¸­çš„éšç§ä¿æŠ¤é—®é¢˜ã€‚é’ˆå¯¹ç°æœ‰åŸºå‡†æµ‹è¯•é€šå¸¸ä¾èµ–éšæœºæ•°æ®åˆ’åˆ†ã€æ¨¡æ‹Ÿç‚¹å‡»æ•°æ®ä»¥åŠåŒæ­¥å®¢æˆ·ç«¯å‚ä¸ç­‰è¿‡åº¦ç®€åŒ–çš„ç°çŠ¶ï¼Œè¯¥æ•°æ®é›†æ¶µç›–äº†10,000åç”¨æˆ·çš„260ä¸‡æ¡çœŸå®æŸ¥è¯¢è®°å½•ã€‚AOL4FOLTRçš„ç‹¬ç‰¹ä¹‹å¤„åœ¨äºåŒ…å«äº†ç”¨æˆ·æ ‡è¯†ç¬¦ã€çœŸå®ç‚¹å‡»æ•°æ®å’ŒæŸ¥è¯¢æ—¶é—´æˆ³ï¼Œä»è€Œèƒ½å¤Ÿæ”¯æŒæ›´çœŸå®çš„ç”¨æˆ·åˆ’åˆ†ã€è¡Œä¸ºå»ºæ¨¡ä»¥åŠå¼‚æ­¥è”é‚¦å­¦ä¹ åœºæ™¯çš„ç ”ç©¶ã€‚è¯¥æ•°æ®é›†é€šè¿‡æä¾›æ¥è¿‘ç°å®ä¸–ç•ŒåŠ¨æ€çš„å®éªŒç¯å¢ƒï¼Œæœ‰æ•ˆåœ°å¡«è¡¥äº†ç°æœ‰FOLTRåŸºå‡†æµ‹è¯•ä¸å®é™…åº”ç”¨ä¹‹é—´çš„å·®è·ã€‚è¿™ä¸€èµ„æºçš„å‘å¸ƒä¸ºå¼€å‘å’Œè¯„ä¼°æ›´å…·å¯è§£é‡Šæ€§ä¸å®ç”¨æ€§çš„éšç§ä¿æŠ¤åœ¨çº¿æ’åºæ¨¡å‹æä¾›äº†å…³é”®æ”¯æŒã€‚",
      "categories": [
        "cs.IR",
        "cs.AI",
        "cs.DC"
      ],
      "primary_category": "cs.IR",
      "comment": "Accepted at CIKM 2025",
      "pdf_url": "https://arxiv.org/pdf/2508.12353v1",
      "published_date": "2025-08-17 12:57:54 UTC",
      "updated_date": "2025-08-17 12:57:54 UTC",
      "processing_status": "completed",
      "attempts": 1,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "llm_backup_calls": 0,
      "last_update": "2026-01-24T12:24:35.897568+00:00"
    },
    {
      "arxiv_id": "2508.12341v3",
      "title": "Semantic Discrepancy-aware Detector for Image Forgery Identification",
      "title_zh": "é¢å‘å›¾åƒç¯¡æ”¹è¯†åˆ«çš„è¯­ä¹‰å·®å¼‚æ„ŸçŸ¥æ£€æµ‹å™¨",
      "authors": [
        "Ziye Wang",
        "Minghang Yu",
        "Chunyan Xu",
        "Zhen Cui"
      ],
      "abstract": "With the rapid advancement of image generation techniques, robust forgery detection has become increasingly imperative to ensure the trustworthiness of digital media. Recent research indicates that the learned semantic concepts of pre-trained models are critical for identifying fake images. However, the misalignment between the forgery and semantic concept spaces hinders the model's forgery detection performance. To address this problem, we propose a novel Semantic Discrepancy-aware Detector (SDD) that leverages reconstruction learning to align the two spaces at a fine-grained visual level. By exploiting the conceptual knowledge embedded in the pre-trained vision language model, we specifically design a semantic token sampling module to mitigate the space shifts caused by features irrelevant to both forgery traces and semantic concepts. A concept-level forgery discrepancy learning module, built upon a visual reconstruction paradigm, is proposed to strengthen the interaction between visual semantic concepts and forgery traces, effectively capturing discrepancies under the concepts' guidance. Finally, the low-level forgery feature enhancemer integrates the learned concept level forgery discrepancies to minimize redundant forgery information. Experiments conducted on two standard image forgery datasets demonstrate the efficacy of the proposed SDD, which achieves superior results compared to existing methods. The code is available at https://github.com/wzy1111111/SSD.",
      "tldr_zh": "è¯¥ç ”ç©¶é’ˆå¯¹å›¾åƒä¼ªé€ æ£€æµ‹ä¸­ä¼ªé€ ç©ºé—´ä¸è¯­ä¹‰æ¦‚å¿µç©ºé—´ä¸ä¸€è‡´çš„é—®é¢˜ï¼Œæå‡ºäº†ä¸€ç§åä¸ºè¯­ä¹‰å·®å¼‚æ„ŸçŸ¥æ£€æµ‹å™¨(Semantic Discrepancy-aware Detector, SDD)çš„æ–°æ¡†æ¶ã€‚è¯¥æ¡†æ¶åˆ©ç”¨é‡å»ºå­¦ä¹ (reconstruction learning)åœ¨ç»†ç²’åº¦è§†è§‰å±‚é¢å®ç°ç©ºé—´å¯¹é½ï¼Œå¹¶å€ŸåŠ©é¢„è®­ç»ƒè§†è§‰è¯­è¨€æ¨¡å‹çš„çŸ¥è¯†è®¾è®¡äº†è¯­ä¹‰æ ‡è®°é‡‡æ ·æ¨¡å—(semantic token sampling module)ï¼Œä»¥æ¶ˆé™¤æ— å…³ç‰¹å¾å¸¦æ¥çš„ç©ºé—´åç§»ã€‚é€šè¿‡æ„å»ºæ¦‚å¿µçº§ä¼ªé€ å·®å¼‚å­¦ä¹ æ¨¡å—(concept-level forgery discrepancy learning module)ï¼Œè¯¥æ–¹æ³•åŠ å¼ºäº†è§†è§‰è¯­ä¹‰æ¦‚å¿µä¸ä¼ªé€ ç—•è¿¹ä¹‹é—´çš„äº¤äº’ï¼Œæœ‰æ•ˆæ•æ‰äº†æ¦‚å¿µå¼•å¯¼ä¸‹çš„ä¼ªé€ å·®å¼‚ã€‚æœ€åï¼Œä½çº§ä¼ªé€ ç‰¹å¾å¢å¼ºå™¨(low-level forgery feature enhancer)æ•´åˆäº†è¿™äº›å·®å¼‚ä¿¡æ¯å¹¶å‡å°‘å†—ä½™ï¼Œä»è€Œæå‡äº†æ£€æµ‹ç²¾åº¦ã€‚å®éªŒç»“æœè¡¨æ˜ï¼ŒSDDåœ¨ä¸¤ä¸ªæ ‡å‡†å›¾åƒä¼ªé€ æ•°æ®é›†ä¸Šè¡¨ç°ä¼˜å¼‚ï¼Œæ˜¾è‘—æå‡äº†å›¾åƒä¼ªé€ è¯†åˆ«çš„ç¨³å¥æ€§ã€‚",
      "categories": [
        "cs.CV",
        "cs.AI"
      ],
      "primary_category": "cs.CV",
      "comment": "10 pages, 5 figures",
      "pdf_url": "https://arxiv.org/pdf/2508.12341v3",
      "published_date": "2025-08-17 12:11:09 UTC",
      "updated_date": "2025-09-28 12:48:18 UTC",
      "processing_status": "completed",
      "attempts": 1,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "llm_backup_calls": 0,
      "last_update": "2026-01-24T12:24:40.290726+00:00"
    },
    {
      "arxiv_id": "2508.12338v1",
      "title": "Wisdom of the Crowd: Reinforcement Learning from Coevolutionary Collective Feedback",
      "title_zh": "ç¾¤ä½“æ™ºæ…§ï¼šåŸºäºååŒè¿›åŒ–ç¾¤ä½“åé¦ˆçš„å¼ºåŒ–å­¦ä¹ ",
      "authors": [
        "Wenzhen Yuan",
        "Shengji Tang",
        "Weihao Lin",
        "Jiacheng Ruan",
        "Ganqu Cui",
        "Bo Zhang",
        "Tao Chen",
        "Ting Liu",
        "Yuzhuo Fu",
        "Peng Ye",
        "Lei Bai"
      ],
      "abstract": "Reinforcement learning (RL) has significantly enhanced the reasoning capabilities of large language models (LLMs), but its reliance on expensive human-labeled data or complex reward models severely limits scalability. While existing self-feedback methods aim to address this problem, they are constrained by the capabilities of a single model, which can lead to overconfidence in incorrect answers, reward hacking, and even training collapse. To this end, we propose Reinforcement Learning from Coevolutionary Collective Feedback (RLCCF), a novel RL framework that enables multi-model collaborative evolution without external supervision. Specifically, RLCCF optimizes the ability of a model collective by maximizing its Collective Consistency (CC), which jointly trains a diverse ensemble of LLMs and provides reward signals by voting on collective outputs. Moreover, each model's vote is weighted by its Self-Consistency (SC) score, ensuring that more confident models contribute more to the collective decision. Benefiting from the diverse output distributions and complementary abilities of multiple LLMs, RLCCF enables the model collective to continuously enhance its reasoning ability through coevolution. Experiments on four mainstream open-source LLMs across four mathematical reasoning benchmarks demonstrate that our framework yields significant performance gains, achieving an average relative improvement of 16.72\\% in accuracy. Notably, RLCCF not only improves the performance of individual models but also enhances the group's majority-voting accuracy by 4.51\\%, demonstrating its ability to extend the collective capability boundary of the model collective.",
      "tldr_zh": "è¯¥ç ”ç©¶æå‡ºäº†Reinforcement Learning from Coevolutionary Collective Feedback (RLCCF)ï¼Œè¿™æ˜¯ä¸€ç§æ— éœ€å¤–éƒ¨ç›‘ç£çš„å¤šæ¨¡å‹ååŒè¿›åŒ–å¼ºåŒ–å­¦ä¹ æ¡†æ¶ï¼Œæ—¨åœ¨è§£å†³å¤§å‹è¯­è¨€æ¨¡å‹(LLMs)å¼ºåŒ–å­¦ä¹ è¿‡ç¨‹ä¸­å¯¹æ˜‚è´µäººå·¥æ ‡æ³¨æˆ–å¤æ‚å¥–åŠ±æ¨¡å‹çš„ä¾èµ–é—®é¢˜ã€‚é’ˆå¯¹ç°æœ‰è‡ªåé¦ˆæ–¹æ³•æ˜“å¯¼è‡´æ¨¡å‹è¿‡åº¦è‡ªä¿¡ã€å¥–åŠ±ä½œå¼Š(reward hacking)åŠè®­ç»ƒå´©æºƒç­‰å±€é™ï¼ŒRLCCFé€šè¿‡æœ€å¤§åŒ–é›†ä½“ä¸€è‡´æ€§(Collective Consistency, CC)æ¥ååŒè®­ç»ƒå¤šæ ·åŒ–çš„LLMé›†åˆï¼Œå¹¶ä¾æ®ç”±è‡ªä¸€è‡´æ€§(Self-Consistency, SC)åˆ†æ•°åŠ æƒçš„æŠ•ç¥¨ç»“æœæä¾›å¥–åŠ±ä¿¡å·ã€‚è¿™ç§æœºåˆ¶å……åˆ†åˆ©ç”¨äº†å¤šä¸ªLLMçš„å¤šæ ·åŒ–è¾“å‡ºåˆ†å¸ƒä¸äº’è¡¥èƒ½åŠ›ï¼Œä½¿æ¨¡å‹é›†åˆèƒ½å¤Ÿåœ¨å…±åŒè¿›åŒ–ä¸­æŒç»­å¢å¼ºæ¨ç†æ€§èƒ½ã€‚åœ¨å››ç§å¼€æºLLMåŠå››ä¸ªæ•°å­¦æ¨ç†åŸºå‡†ä¸Šçš„å®éªŒè¯æ˜ï¼Œè¯¥æ¡†æ¶å®ç°äº†16.72%çš„å¹³å‡ç›¸å¯¹å‡†ç¡®ç‡æå‡ï¼Œå¹¶æ˜¾è‘—å¢å¼ºäº†é›†ä½“å¤šæ•°æŠ•ç¥¨çš„å‡†ç¡®æ€§ï¼Œæœ‰æ•ˆæ‹“å±•äº†æ¨¡å‹é›†åˆçš„èƒ½åŠ›è¾¹ç•Œã€‚",
      "categories": [
        "cs.AI"
      ],
      "primary_category": "cs.AI",
      "comment": "",
      "pdf_url": "https://arxiv.org/pdf/2508.12338v1",
      "published_date": "2025-08-17 11:57:34 UTC",
      "updated_date": "2025-08-17 11:57:34 UTC",
      "processing_status": "completed",
      "attempts": 1,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "llm_backup_calls": 0,
      "last_update": "2026-01-24T12:24:46.757558+00:00"
    },
    {
      "arxiv_id": "2508.13220v2",
      "title": "MCPSecBench: A Systematic Security Benchmark and Playground for Testing Model Context Protocols",
      "title_zh": "MCPSecBenchï¼šé¢å‘æ¨¡å‹ä¸Šä¸‹æ–‡åè®®æµ‹è¯•çš„ç³»ç»Ÿæ€§å®‰å…¨åŸºå‡†ä¸æ¼”ç»ƒå¹³å°",
      "authors": [
        "Yixuan Yang",
        "Daoyuan Wu",
        "Yufan Chen"
      ],
      "abstract": "Large Language Models (LLMs) are increasingly integrated into real-world applications via the Model Context Protocol (MCP), a universal, open standard for connecting AI agents with data sources and external tools. While MCP enhances the capabilities of LLM-based agents, it also introduces new security risks and expands their attack surfaces. In this paper, we present the first systematic taxonomy of MCP security, identifying 17 attack types across 4 primary attack surfaces. We introduce MCPSecBench, a comprehensive security benchmark and playground that integrates prompt datasets, MCP servers, MCP clients, attack scripts, and protection mechanisms to evaluate these attacks across three major MCP providers. Our benchmark is modular and extensible, allowing researchers to incorporate custom implementations of clients, servers, and transport protocols for systematic security assessment. Experimental results show that over 85% of the identified attacks successfully compromise at least one platform, with core vulnerabilities universally affecting Claude, OpenAI, and Cursor, while prompt-based and tool-centric attacks exhibit considerable variability across different hosts and models. In addition, current protection mechanisms have little effect against these attacks. Overall, MCPSecBench standardizes the evaluation of MCP security and enables rigorous testing across all MCP layers.",
      "tldr_zh": "è¯¥ç ”ç©¶é’ˆå¯¹å¤§è¯­è¨€æ¨¡å‹(LLMs)é€šè¿‡ Model Context Protocol (MCP) é›†æˆå¤–éƒ¨æ•°æ®ä¸å·¥å…·æ—¶å¼•å…¥çš„å®‰å…¨é£é™©ï¼Œæå‡ºäº†é¦–ä¸ªç³»ç»Ÿæ€§çš„ MCP å®‰å…¨åˆ†ç±»ä½“ç³»ï¼Œè¯†åˆ«äº†4ä¸ªä¸»è¦æ”»å‡»é¢ä¸Šçš„17ç§æ”»å‡»ç±»å‹ã€‚ç ”ç©¶è€…å¼€å‘äº† MCPSecBenchï¼Œè¿™æ˜¯ä¸€ä¸ªåŒ…å«æç¤ºè¯æ•°æ®é›†ã€MCPæœåŠ¡å™¨ã€å®¢æˆ·ç«¯åŠæ”»å‡»è„šæœ¬çš„ç»¼åˆæ€§å®‰å…¨åŸºå‡†æµ‹è¯•å¹³å°ï¼Œæ”¯æŒå¯¹ä¸åŒæœåŠ¡å•†è¿›è¡Œæ¨¡å—åŒ–å’Œå¯æ‰©å±•çš„å®‰å…¨è¯„ä¼°ã€‚å®éªŒç»“æœæ˜¾ç¤ºï¼Œè¶…è¿‡85%çš„è¯†åˆ«æ”»å‡»èƒ½æˆåŠŸå…¥ä¾µè‡³å°‘ä¸€ä¸ªå¹³å°ï¼Œæ ¸å¿ƒæ¼æ´æ™®éå½±å“ Claudeã€OpenAI å’Œ Cursorï¼Œä¸”ç°æœ‰çš„é˜²æŠ¤æœºåˆ¶åœ¨åº”å¯¹è¿™äº›æ”»å‡»æ—¶æ•ˆæœç”šå¾®ã€‚ç ”ç©¶å‘ç°åŸºäºæç¤ºè¯å’Œä»¥å·¥å…·ä¸ºä¸­å¿ƒçš„æ”»å‡»åœ¨ä¸åŒä¸»æœºå’Œæ¨¡å‹é—´è¡¨ç°å‡ºæ˜¾è‘—å·®å¼‚ã€‚MCPSecBench çš„æ¨å‡ºå®ç°äº† MCP å®‰å…¨è¯„ä¼°çš„æ ‡å‡†åŒ–ï¼Œä¸ºè·¨æ‰€æœ‰åè®®å±‚çš„ä¸¥è°¨å®‰å…¨æµ‹è¯•å¥ å®šäº†åŸºç¡€ã€‚",
      "categories": [
        "cs.CR",
        "cs.AI"
      ],
      "primary_category": "cs.CR",
      "comment": "This is a technical report from Lingnan University, Hong Kong. Code is available at https://github.com/AIS2Lab/MCPSecBench",
      "pdf_url": "https://arxiv.org/pdf/2508.13220v2",
      "published_date": "2025-08-17 11:49:16 UTC",
      "updated_date": "2025-10-09 14:57:42 UTC",
      "processing_status": "completed",
      "attempts": 1,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "llm_backup_calls": 0,
      "last_update": "2026-01-24T12:24:53.458154+00:00"
    },
    {
      "arxiv_id": "2508.13219v1",
      "title": "Deep Graph Neural Point Process For Learning Temporal Interactive Networks",
      "title_zh": "é¢å‘æ—¶åºäº¤äº’ç½‘ç»œå­¦ä¹ çš„æ·±åº¦å›¾ç¥ç»ç‚¹è¿‡ç¨‹",
      "authors": [
        "Su Chen",
        "Xiaohua Qi",
        "Xixun Lin",
        "Yanmin Shang",
        "Xiaolin Xu",
        "Yangxi Li"
      ],
      "abstract": "Learning temporal interaction networks(TIN) is previously regarded as a coarse-grained multi-sequence prediction problem, ignoring the network topology structure influence. This paper addresses this limitation and a Deep Graph Neural Point Process(DGNPP) model for TIN is proposed. DGNPP consists of two key modules: the Node Aggregation Layer and the Self Attentive Layer. The Node Aggregation Layer captures topological structures to generate static representation for users and items, while the Self Attentive Layer dynamically updates embeddings over time. By incorporating both dynamic and static embeddings into the event intensity function and optimizing the model via maximum likelihood estimation, DGNPP predicts events and occurrence time effectively. Experimental evaluations on three public datasets demonstrate that DGNPP achieves superior performance in event prediction and time prediction tasks with high efficiency, significantly outperforming baseline models and effectively mitigating the limitations of prior approaches.",
      "tldr_zh": "è¯¥ç ”ç©¶é’ˆå¯¹æ—¶åºäº¤äº’ç½‘ç»œ(Temporal Interaction Networks, TIN)ä»¥å¾€è¢«è§†ä¸ºç²—ç²’åº¦å¤šåºåˆ—é¢„æµ‹é—®é¢˜è€Œå¿½è§†ç½‘ç»œæ‹“æ‰‘å½±å“çš„å±€é™æ€§ï¼Œæå‡ºäº†æ·±åº¦å›¾ç¥ç»ç‚¹è¿‡ç¨‹(Deep Graph Neural Point Process, DGNPP)æ¨¡å‹ã€‚DGNPPåŒ…å«Node Aggregation Layerå’ŒSelf Attentive Layerä¸¤ä¸ªæ ¸å¿ƒæ¨¡å—ï¼Œåˆ†åˆ«ç”¨äºæ•è·é™æ€æ‹“æ‰‘ç»“æ„å’ŒåŠ¨æ€æ›´æ–°æ—¶é—´åµŒå…¥ã€‚è¯¥æ¨¡å‹é€šè¿‡å°†åŠ¨é™æ€åµŒå…¥æ•´åˆè‡³Event Intensity Functionï¼Œå¹¶åˆ©ç”¨Maximum Likelihood Estimationè¿›è¡Œä¼˜åŒ–ï¼Œå®ç°äº†å¯¹äº‹ä»¶åŠå…¶å‘ç”Ÿæ—¶é—´çš„ç²¾ç¡®é¢„æµ‹ã€‚åœ¨ä¸‰ä¸ªå…¬å…±æ•°æ®é›†ä¸Šçš„å®éªŒç»“æœæ˜¾ç¤ºï¼ŒDGNPPåœ¨äº‹ä»¶é¢„æµ‹å’Œæ—¶é—´é¢„æµ‹ä»»åŠ¡ä¸­çš„è¡¨ç°æ˜¾è‘—ä¼˜äºç°æœ‰åŸºçº¿æ¨¡å‹ã€‚è¯¥æ¨¡å‹åœ¨ä¿æŒé«˜æ•ˆç‡çš„åŒæ—¶ï¼Œæœ‰æ•ˆè§£å†³äº†å…ˆå‰æ–¹æ³•åœ¨å¤„ç†å¤æ‚ç½‘ç»œæ‹“æ‰‘ä¿¡æ¯æ–¹é¢çš„ä¸è¶³ï¼Œä¸ºå­¦ä¹ å¤æ‚æ—¶åºäº¤äº’ç½‘ç»œæä¾›äº†æ›´æœ‰æ•ˆçš„æ–¹æ¡ˆã€‚",
      "categories": [
        "cs.LG",
        "cs.AI"
      ],
      "primary_category": "cs.LG",
      "comment": "",
      "pdf_url": "https://arxiv.org/pdf/2508.13219v1",
      "published_date": "2025-08-17 11:17:03 UTC",
      "updated_date": "2025-08-17 11:17:03 UTC",
      "processing_status": "completed",
      "attempts": 1,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "llm_backup_calls": 0,
      "last_update": "2026-01-24T12:25:20.453617+00:00"
    },
    {
      "arxiv_id": "2508.12314v1",
      "title": "Synchronization Dynamics of Heterogeneous, Collaborative Multi-Agent AI Systems",
      "title_zh": "å¼‚æ„ååŒå¤šæ™ºèƒ½ä½“äººå·¥æ™ºèƒ½ç³»ç»Ÿçš„åŒæ­¥åŠ¨åŠ›å­¦",
      "authors": [
        "Chiranjit Mitra"
      ],
      "abstract": "We present a novel interdisciplinary framework that bridges synchronization theory and multi-agent AI systems by adapting the Kuramoto model to describe the collective dynamics of heterogeneous AI agents engaged in complex task execution. By representing AI agents as coupled oscillators with both phase and amplitude dynamics, our model captures essential aspects of agent specialization, influence, and communication within networked systems. We introduce an order parameter to quantify the degree of coordination and synchronization, providing insights into how coupling strength, agent diversity, and network topology impact emergent collective behavior. Furthermore, we formalize a detailed correspondence between Chain-of-Thought prompting in AI reasoning and synchronization phenomena, unifying human-like iterative problem solving with emergent group intelligence. Through extensive simulations on all-to-all and deterministic scale-free networks, we demonstrate that increased coupling promotes robust synchronization despite heterogeneous agent capabilities, reflecting realistic collaborative AI scenarios. Our physics-informed approach establishes a rigorous mathematical foundation for designing, analyzing, and optimizing scalable, adaptive, and interpretable multi-agent AI systems. This work opens pathways for principled orchestration of agentic AI and lays the groundwork for future incorporation of learning dynamics and adaptive network architectures to further enhance system resilience and efficiency.",
      "tldr_zh": "è¯¥ç ”ç©¶æå‡ºäº†ä¸€ä¸ªæ–°é¢–çš„è·¨å­¦ç§‘æ¡†æ¶ï¼Œé€šè¿‡æ”¹è¿› Kuramoto model å°†åŒæ­¥ç†è®º(synchronization theory)åº”ç”¨äºå¼‚æ„åä½œå¤šæ™ºèƒ½ä½“AIç³»ç»Ÿã€‚è¯¥æ¨¡å‹å°†AIæ™ºèƒ½ä½“è¡¨ç¤ºä¸ºå…·æœ‰ç›¸ä½å’ŒæŒ¯å¹…åŠ¨åŠ›å­¦çš„è€¦åˆæŒ¯å­(coupled oscillators)ï¼Œæœ‰æ•ˆæ•æ‰äº†æ™ºèƒ½ä½“åœ¨ç½‘ç»œç³»ç»Ÿä¸­çš„ä¸“ä¸šåŒ–ã€å½±å“åŠ›åŠé€šä¿¡ç‰¹å¾ã€‚ç ”ç©¶å¼•å…¥äº†åºå‚æ•°(order parameter)æ¥é‡åŒ–åè°ƒç¨‹åº¦ï¼Œå¹¶å»ºç«‹äº† AI æ¨ç†ä¸­çš„é“¾å¼æ€ç»´(Chain-of-Thought)ä¸åŒæ­¥ç°è±¡ä¹‹é—´çš„å½¢å¼åŒ–å…³è”ã€‚åœ¨å…¨è¿æ¥å’Œç¡®å®šæ€§æ— æ ‡åº¦ç½‘ç»œ(scale-free networks)ä¸Šçš„ä»¿çœŸç»“æœè¡¨æ˜ï¼Œå¢å¼ºè€¦åˆå¼ºåº¦èƒ½å¤Ÿå…‹æœæ™ºèƒ½ä½“èƒ½åŠ›çš„å¼‚æ„æ€§ï¼Œä¿ƒè¿›ç¨³å¥çš„åŒæ­¥ã€‚è¿™ä¸€åŸºäºç‰©ç†çš„æ–¹æ³•ä¸ºè®¾è®¡ã€åˆ†æå’Œä¼˜åŒ–å¯æ‰©å±•ä¸”å¯è§£é‡Šçš„å¤šæ™ºèƒ½ä½“AIç³»ç»Ÿå¥ å®šäº†ä¸¥è°¨çš„æ•°å­¦åŸºç¡€ï¼Œå¹¶ä¸ºæœªæ¥ç»“åˆå­¦ä¹ åŠ¨åŠ›å­¦ä¸è‡ªé€‚åº”ç½‘ç»œæ¶æ„çš„ç ”ç©¶å¼€è¾Ÿäº†è·¯å¾„ã€‚",
      "categories": [
        "cs.MA",
        "cs.AI",
        "nlin.AO"
      ],
      "primary_category": "cs.MA",
      "comment": "9 pages, 6 figures",
      "pdf_url": "https://arxiv.org/pdf/2508.12314v1",
      "published_date": "2025-08-17 10:16:41 UTC",
      "updated_date": "2025-08-17 10:16:41 UTC",
      "processing_status": "completed",
      "attempts": 1,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "llm_backup_calls": 0,
      "last_update": "2026-01-24T12:24:55.046899+00:00"
    },
    {
      "arxiv_id": "2508.12300v2",
      "title": "Mutually Assured Deregulation",
      "title_zh": "ç›¸äº’ä¿è¯çš„å»ç›‘ç®¡åŒ–",
      "authors": [
        "Gilad Abiri"
      ],
      "abstract": "We have convinced ourselves that the way to make AI safe is to make it unsafe. Since 2022, policymakers worldwide have embraced the Regulation Sacrifice - the belief that dismantling safety oversight will deliver security through AI dominance. Fearing China or USA will gain advantage, nations rush to eliminate safeguards that might slow progress. This Essay reveals the fatal flaw: though AI poses national security challenges, the solution demands stronger regulatory frameworks, not weaker ones. A race without guardrails breeds shared danger, not competitive strength. The Regulation Sacrifice makes three false promises. First, it promises durable technological leads. But AI capabilities spread rapidly - performance gaps between U.S. and Chinese systems collapsed from 9 percent to 2 percent in thirteen months. When advantages evaporate in months, sacrificing permanent safety for temporary speed makes no sense. Second, it promises deregulation accelerates innovation. The opposite often proves true. Companies report well-designed governance streamlines development. Investment flows toward regulated markets. Clear rules reduce uncertainty; uncertain liability creates paralysis. Environmental standards did not kill the auto industry; they created Tesla and BYD. Third, enhanced national security through deregulation actually undermines security across all timeframes. Near term: it hands adversaries information warfare tools. Medium term: it democratizes bioweapon capabilities. Long term: it guarantees deployment of uncontrollable AGI systems. The Regulation Sacrifice persists because it serves powerful interests, not security. Tech companies prefer freedom to accountability. Politicians prefer simple stories to complex truths. This creates mutually assured deregulation, where each nation's sprint for advantage guarantees collective vulnerability. The only way to win is not to play.",
      "tldr_zh": "è¯¥ç ”ç©¶æ¢è®¨äº†â€œRegulation Sacrificeâ€è¿™ä¸€æ¦‚å¿µï¼Œå³æ”¿ç­–åˆ¶å®šè€…è¯¯è®¤ä¸ºé€šè¿‡å‰Šå¼± AI å®‰å…¨ç›‘ç®¡æ¥è¿½æ±‚æŠ€æœ¯é¢†å…ˆå¯ä»¥ç¡®ä¿å›½å®¶å®‰å…¨ã€‚æ–‡ç« æŒ‡å‡ºè¿™ä¸€ç†å¿µå­˜åœ¨ä¸‰å¤§æ ¸å¿ƒè°¬è¯¯ï¼šé¦–å…ˆï¼ŒAI æŠ€æœ¯ä¼˜åŠ¿å…·æœ‰æå¼ºçš„ç¬æ—¶æ€§ï¼Œç‰ºç‰²æ°¸ä¹…çš„å®‰å…¨ä¿éšœæ¢å–æš‚æ—¶çš„é€Ÿåº¦ä¼˜åŠ¿ç¼ºä¹é€»è¾‘ï¼›å…¶æ¬¡ï¼Œå»ç›‘ç®¡åŒ–æœªå¿…èƒ½åŠ é€Ÿåˆ›æ–°ï¼Œæ¸…æ™°çš„æ²»ç†è§„åˆ™åè€Œèƒ½å‡å°‘ä¸ç¡®å®šæ€§å¹¶å¸å¼•æŠ•èµ„ã€‚æ­¤å¤–ï¼Œæ”¾æ¾ç›‘ç®¡åœ¨çŸ­æœŸå†…ä¼šåŠ å‰§ä¿¡æ¯æˆ˜ï¼Œä¸­æœŸå¯¼è‡´ç”Ÿç‰©æ­¦å™¨èƒ½åŠ›æ‰©æ•£ï¼Œé•¿æœŸåˆ™ä»¤ AGI ç³»ç»Ÿçš„å—æ§æ€§é¢ä¸´é£é™©ã€‚ä½œè€…è®¤ä¸ºè¿™ç§ä¸ºäº†é¢†å…ˆè€Œç«ç›¸å‰Šå¼±ç›‘ç®¡çš„è¡Œä¸ºæœ€ç»ˆä¼šå¯¼è‡´â€œMutually Assured Deregulationâ€ï¼Œä½¿æ‰€æœ‰å›½å®¶é™·å…¥é›†ä½“è„†å¼±çš„å›°å¢ƒã€‚å› æ­¤ï¼Œåº”å¯¹ AI æŒ‘æˆ˜éœ€è¦æ›´å¼ºæœ‰åŠ›çš„ç›‘ç®¡æ¡†æ¶ï¼Œè€Œéç›²ç›®æ¶ˆé™¤æŠ¤æ ã€‚",
      "categories": [
        "cs.CY",
        "cs.AI"
      ],
      "primary_category": "cs.CY",
      "comment": "",
      "pdf_url": "https://arxiv.org/pdf/2508.12300v2",
      "published_date": "2025-08-17 09:27:50 UTC",
      "updated_date": "2025-11-22 03:18:28 UTC",
      "processing_status": "completed",
      "attempts": 1,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "llm_backup_calls": 0,
      "last_update": "2026-01-24T12:25:04.390328+00:00"
    },
    {
      "arxiv_id": "2508.12292v1",
      "title": "HuBERT-VIC: Improving Noise-Robust Automatic Speech Recognition of Speech Foundation Model via Variance-Invariance-Covariance Regularization",
      "title_zh": "HuBERT-VICï¼šé€šè¿‡æ–¹å·®-ä¸å˜æ€§-åæ–¹å·®æ­£åˆ™åŒ–æå‡è¯­éŸ³åŸºåº§æ¨¡å‹çš„æŠ—å™ªè‡ªåŠ¨è¯­éŸ³è¯†åˆ«èƒ½åŠ›",
      "authors": [
        "Hyebin Ahn",
        "Kangwook Jang",
        "Hoirin Kim"
      ],
      "abstract": "Noise robustness in speech foundation models (SFMs) has been a critical challenge, as most models are primarily trained on clean data and experience performance degradation when the models are exposed to noisy speech. To address this issue, we propose HuBERT-VIC, a noise-robust SFM with variance, in-variance, and covariance regularization (VICReg) objectives. These objectives adjust the statistics of noisy speech representations, enabling the model to capture diverse acoustic characteristics and improving the generalization ability across different types of noise. When applied to HuBERT, our model shows relative performance improvements of 23.3% on LibriSpeech test-clean and 13.2% on test-other, compared to the baseline model pre-trained on noisy speech.",
      "tldr_zh": "è¯¥ç ”ç©¶æå‡ºäº†HuBERT-VICï¼Œæ—¨åœ¨å¢å¼ºè¯­éŸ³åŸºç¡€æ¨¡å‹(Speech Foundation Models, SFMs)åœ¨å™ªå£°ç¯å¢ƒä¸‹çš„é²æ£’æ€§ã€‚é’ˆå¯¹SFMsåœ¨å¤„ç†å™ªå£°è¯­éŸ³æ—¶æ€§èƒ½æ˜¾è‘—ä¸‹é™çš„æŒ‘æˆ˜ï¼Œç ”ç©¶è€…å¼•å…¥äº†æ–¹å·®-ä¸å˜æ€§-åæ–¹å·®æ­£åˆ™åŒ–(VICReg)ç›®æ ‡ï¼Œé€šè¿‡è°ƒæ•´å™ªå£°è¯­éŸ³è¡¨ç¤º(representations)çš„ç»Ÿè®¡ç‰¹æ€§ï¼Œä½¿æ¨¡å‹èƒ½å¤Ÿæ•è·æ›´ä¸°å¯Œçš„å£°å­¦ç‰¹å¾ï¼Œå¹¶æå‡åœ¨ä¸åŒå™ªå£°ç±»å‹ä¸‹çš„æ³›åŒ–èƒ½åŠ›ã€‚å°†è¯¥æ–¹æ³•åº”ç”¨äºHuBERTæ¨¡å‹åï¼Œå®éªŒç»“æœè¡¨æ˜HuBERT-VICåœ¨LibriSpeech test-cleanå’Œtest-otheræµ‹è¯•é›†ä¸Šçš„ç›¸å¯¹æ€§èƒ½åˆ†åˆ«æ¯”å™ªå£°é¢„è®­ç»ƒåŸºçº¿æ¨¡å‹æé«˜äº†23.3%å’Œ13.2%ã€‚è¯¥ç ”ç©¶è¯æ˜äº†VICRegåœ¨æå‡è¯­éŸ³åŸºç¡€æ¨¡å‹æŠ—å™ªæ€§èƒ½æ–¹é¢çš„æœ‰æ•ˆæ€§ï¼Œä¸ºå®ç°æ›´å…·é²æ£’æ€§çš„è‡ªåŠ¨è¯­éŸ³è¯†åˆ«(ASR)æä¾›äº†é‡è¦å‚è€ƒã€‚",
      "categories": [
        "cs.SD",
        "cs.AI",
        "eess.AS"
      ],
      "primary_category": "cs.SD",
      "comment": "Accepted at Interspeech 2025",
      "pdf_url": "https://arxiv.org/pdf/2508.12292v1",
      "published_date": "2025-08-17 08:54:25 UTC",
      "updated_date": "2025-08-17 08:54:25 UTC",
      "processing_status": "completed",
      "attempts": 1,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "llm_backup_calls": 0,
      "last_update": "2026-01-24T12:24:59.966036+00:00"
    },
    {
      "arxiv_id": "2508.12291v1",
      "title": "RadarQA: Multi-modal Quality Analysis of Weather Radar Forecasts",
      "title_zh": "RadarQAï¼šå¤©æ°”é›·è¾¾é¢„æŠ¥çš„å¤šæ¨¡æ€è´¨é‡åˆ†æ",
      "authors": [
        "Xuming He",
        "Zhiyuan You",
        "Junchao Gong",
        "Couhua Liu",
        "Xiaoyu Yue",
        "Peiqin Zhuang",
        "Wenlong Zhang",
        "Lei Bai"
      ],
      "abstract": "Quality analysis of weather forecasts is an essential topic in meteorology. Although traditional score-based evaluation metrics can quantify certain forecast errors, they are still far from meteorological experts in terms of descriptive capability, interpretability, and understanding of dynamic evolution. With the rapid development of Multi-modal Large Language Models (MLLMs), these models become potential tools to overcome the above challenges. In this work, we introduce an MLLM-based weather forecast analysis method, RadarQA, integrating key physical attributes with detailed assessment reports. We introduce a novel and comprehensive task paradigm for multi-modal quality analysis, encompassing both single frame and sequence, under both rating and assessment scenarios. To support training and benchmarking, we design a hybrid annotation pipeline that combines human expert labeling with automated heuristics. With such an annotation method, we construct RQA-70K, a large-scale dataset with varying difficulty levels for radar forecast quality evaluation. We further design a multi-stage training strategy that iteratively improves model performance at each stage. Extensive experiments show that RadarQA outperforms existing general MLLMs across all evaluation settings, highlighting its potential for advancing quality analysis in weather prediction.",
      "tldr_zh": "è¯¥ç ”ç©¶é’ˆå¯¹ä¼ ç»Ÿå¤©æ°”é¢„æŠ¥è¯„ä¼°æŒ‡æ ‡åœ¨æè¿°èƒ½åŠ›ã€å¯è§£é‡Šæ€§åŠåŠ¨æ€æ¼”å˜ç†è§£æ–¹é¢çš„å±€é™ï¼Œæå‡ºäº†RadarQAï¼Œä¸€ç§åŸºäºå¤šæ¨¡æ€å¤§è¯­è¨€æ¨¡å‹(MLLMs)çš„å¤©æ°”é¢„æŠ¥è´¨é‡åˆ†ææ–¹æ³•ã€‚è¯¥æ–¹æ³•é€šè¿‡æ•´åˆå…³é”®ç‰©ç†å±æ€§ä¸è¯¦ç»†è¯„ä¼°æŠ¥å‘Šï¼Œæ„å»ºäº†ä¸€ä¸ªæ¶µç›–å•å¸§ä¸åºåˆ—ã€è¯„åˆ†ä¸è¯„ä¼°ä»»åŠ¡çš„å¤šæ¨¡æ€åˆ†æèŒƒå¼ã€‚ä¸ºäº†æ”¯æŒæ¨¡å‹è®­ç»ƒï¼Œç ”ç©¶å›¢é˜Ÿåˆ©ç”¨ä¸“å®¶æ ‡æ³¨ä¸è‡ªåŠ¨åŒ–å¯å‘å¼ç®—æ³•ç›¸ç»“åˆçš„æ··åˆç®¡é“ï¼Œæ„å»ºäº†åŒ…å«7ä¸‡ä¸ªæ ·æœ¬çš„å¤§è§„æ¨¡æ•°æ®é›†RQA-70Kã€‚æ­¤å¤–ï¼Œç ”ç©¶è¿˜è®¾è®¡äº†å¤šé˜¶æ®µè®­ç»ƒç­–ç•¥ä»¥è¿­ä»£ä¼˜åŒ–æ¨¡å‹æ€§èƒ½ã€‚å®éªŒç»“æœè¡¨æ˜ï¼ŒRadarQAåœ¨æ‰€æœ‰è¯„ä¼°è®¾ç½®ä¸‹å‡æ˜¾è‘—ä¼˜äºç°æœ‰çš„é€šç”¨MLLMsï¼Œå±•ç°äº†å…¶åœ¨æå‡å¤©æ°”é¢„æŠ¥è´¨é‡åˆ†ææ°´å¹³æ–¹é¢çš„å·¨å¤§æ½œåŠ›ã€‚",
      "categories": [
        "cs.AI"
      ],
      "primary_category": "cs.AI",
      "comment": "",
      "pdf_url": "https://arxiv.org/pdf/2508.12291v1",
      "published_date": "2025-08-17 08:50:07 UTC",
      "updated_date": "2025-08-17 08:50:07 UTC",
      "processing_status": "completed",
      "attempts": 1,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "llm_backup_calls": 0,
      "last_update": "2026-01-24T12:25:12.551109+00:00"
    },
    {
      "arxiv_id": "2508.12285v1",
      "title": "\"My productivity is boosted, but ...\" Demystifying Users' Perception on AI Coding Assistants",
      "title_zh": "â€œæˆ‘çš„ç”Ÿäº§åŠ›æé«˜äº†ï¼Œä½†æ˜¯â€¦â€¦â€ï¼šæ·±åº¦è§£æç”¨æˆ·å¯¹ AI ç¼–ç¨‹åŠ©æ‰‹çš„è®¤çŸ¥",
      "authors": [
        "Yunbo Lyu",
        "Zhou Yang",
        "Jieke Shi",
        "Jianming Chang",
        "Yue Liu",
        "David Lo"
      ],
      "abstract": "This paper aims to explore fundamental questions in the era when AI coding assistants like GitHub Copilot are widely adopted: what do developers truly value and criticize in AI coding assistants, and what does this reveal about their needs and expectations in real-world software development? Unlike previous studies that conduct observational research in controlled and simulated environments, we analyze extensive, first-hand user reviews of AI coding assistants, which capture developers' authentic perspectives and experiences drawn directly from their actual day-to-day work contexts. We identify 1,085 AI coding assistants from the Visual Studio Code Marketplace. Although they only account for 1.64% of all extensions, we observe a surge in these assistants: over 90% of them are released within the past two years. We then manually analyze the user reviews sampled from 32 AI coding assistants that have sufficient installations and reviews to construct a comprehensive taxonomy of user concerns and feedback about these assistants. We manually annotate each review's attitude when mentioning certain aspects of coding assistants, yielding nuanced insights into user satisfaction and dissatisfaction regarding specific features, concerns, and overall tool performance. Built on top of the findings-including how users demand not just intelligent suggestions but also context-aware, customizable, and resource-efficient interactions-we propose five practical implications and suggestions to guide the enhancement of AI coding assistants that satisfy user needs.",
      "tldr_zh": "è¯¥é¡¹ç ”ç©¶æ·±å…¥æ¢è®¨äº†å¼€å‘è€…åœ¨å®é™…å·¥ä½œåœºæ™¯ä¸­å¯¹ AI coding assistantsï¼ˆå¦‚ GitHub Copilotï¼‰çš„çœŸå®è¯„ä»·ä¸éœ€æ±‚ï¼Œæ—¨åœ¨æ­ç¤ºå¼€å‘è€…åœ¨è½¯ä»¶å¼€å‘ä¸­çœŸæ­£å…³æ³¨å’Œæ‰¹è¯„çš„æ ¸å¿ƒè¦ç´ ã€‚ç ”ç©¶å›¢é˜Ÿé€šè¿‡åˆ†æ Visual Studio Code Marketplace ä¸­çš„ 1,085 ä¸ªç›¸å…³æ’ä»¶å‘ç°ï¼Œæ­¤ç±»å·¥å…·åœ¨è¿‡å»ä¸¤å¹´å†…å‘ˆç°çˆ†å‘å¼å¢é•¿ã€‚ä½œè€…é€šè¿‡å¯¹å…¶ä¸­ 32 ä¸ªä»£è¡¨æ€§æ’ä»¶çš„ç”¨æˆ·è¯„è®ºè¿›è¡Œäººå·¥æ ‡æ³¨ä¸åˆ†æï¼Œæ„å»ºäº†ä¸€ä¸ªå…³äº user concerns çš„å…¨é¢åˆ†ç±»ä½“ç³»ï¼Œå¹¶æ·±å…¥æ´å¯Ÿäº†ç”¨æˆ·å¯¹ç‰¹å®šåŠŸèƒ½åŠå·¥å…·æ€§èƒ½çš„æ»¡æ„åº¦ã€‚ç ”ç©¶å‘ç°ï¼Œå¼€å‘è€…ä¸ä»…è¿½æ±‚æ™ºèƒ½åŒ–çš„ä»£ç å»ºè®®ï¼Œè¿˜å¯¹ context-awareã€customizable ä»¥åŠ resource-efficient çš„äº¤äº’ä½“éªŒæå‡ºäº†æ˜ç¡®è¦æ±‚ã€‚åŸºäºè¿™äº›å‘ç°ï¼Œè¯¥ç ”ç©¶æå‡ºäº†äº”é¡¹å®è·µå»ºè®®ï¼Œä¸ºæœªæ¥ä¼˜åŒ–å¹¶å¼€å‘æ›´ç¬¦åˆç”¨æˆ·çœŸå®éœ€æ±‚çš„ AI coding assistants æä¾›äº†é‡è¦æŒ‡å¯¼ã€‚",
      "categories": [
        "cs.SE",
        "cs.AI",
        "cs.HC"
      ],
      "primary_category": "cs.SE",
      "comment": "13 pages, Camera-Ready Version that will appear in ASE 2025",
      "pdf_url": "https://arxiv.org/pdf/2508.12285v1",
      "published_date": "2025-08-17 08:22:47 UTC",
      "updated_date": "2025-08-17 08:22:47 UTC",
      "processing_status": "completed",
      "attempts": 1,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "llm_backup_calls": 0,
      "last_update": "2026-01-24T12:25:09.659421+00:00"
    },
    {
      "arxiv_id": "2508.12279v2",
      "title": "TSLA: A Task-Specific Learning Adaptation for Semantic Segmentation on Autonomous Vehicles Platform",
      "title_zh": "TSLAï¼šé¢å‘è‡ªåŠ¨é©¾é©¶å¹³å°çš„è¯­ä¹‰åˆ†å‰²ä»»åŠ¡ç‰¹å®šå‹å­¦ä¹ è‡ªé€‚åº”",
      "authors": [
        "Jun Liu",
        "Zhenglun Kong",
        "Pu Zhao",
        "Weihao Zeng",
        "Hao Tang",
        "Xuan Shen",
        "Changdi Yang",
        "Wenbin Zhang",
        "Geng Yuan",
        "Wei Niu",
        "Xue Lin",
        "Yanzhi Wang"
      ],
      "abstract": "Autonomous driving platforms encounter diverse driving scenarios, each with varying hardware resources and precision requirements. Given the computational limitations of embedded devices, it is crucial to consider computing costs when deploying on target platforms like the NVIDIA\\textsuperscript{\\textregistered} DRIVE PX 2. Our objective is to customize the semantic segmentation network according to the computing power and specific scenarios of autonomous driving hardware. We implement dynamic adaptability through a three-tier control mechanism -- width multiplier, classifier depth, and classifier kernel -- allowing fine-grained control over model components based on hardware constraints and task requirements. This adaptability facilitates broad model scaling, targeted refinement of the final layers, and scenario-specific optimization of kernel sizes, leading to improved resource allocation and performance.\n  Additionally, we leverage Bayesian Optimization with surrogate modeling to efficiently explore hyperparameter spaces under tight computational budgets. Our approach addresses scenario-specific and task-specific requirements through automatic parameter search, accommodating the unique computational complexity and accuracy needs of autonomous driving. It scales its Multiply-Accumulate Operations (MACs) for Task-Specific Learning Adaptation (TSLA), resulting in alternative configurations tailored to diverse self-driving tasks. These TSLA customizations maximize computational capacity and model accuracy, optimizing hardware utilization.",
      "tldr_zh": "è¯¥ç ”ç©¶é’ˆå¯¹è‡ªåŠ¨é©¾é©¶å¹³å°é¢ä¸´çš„ä¸åŒç¡¬ä»¶èµ„æºå’Œç²¾åº¦éœ€æ±‚ï¼Œæå‡ºäº†åä¸º TSLA (Task-Specific Learning Adaptation) çš„ä»»åŠ¡ç‰¹å®šå­¦ä¹ é€‚é…æ–¹æ³•ï¼Œæ—¨åœ¨æ ¹æ®è®¡ç®—èƒ½åŠ›å’Œç‰¹å®šåœºæ™¯å®šåˆ¶è¯­ä¹‰åˆ†å‰²(Semantic Segmentation)ç½‘ç»œã€‚é€šè¿‡ä¸‰å±‚æ§åˆ¶æœºåˆ¶ï¼ˆWidth Multiplierã€Classifier Depth å’Œ Classifier Kernelï¼‰ï¼Œè¯¥æ–¹æ³•å®ç°äº†å¯¹æ¨¡å‹ç»„ä»¶çš„ç»†ç²’åº¦æ§åˆ¶ï¼Œä»è€Œåœ¨ç¡¬ä»¶çº¦æŸä¸‹ä¼˜åŒ–èµ„æºåˆ†é…ã€‚ç ”ç©¶è¿˜å¼•å…¥äº†åŸºäºä»£ç†æ¨¡å‹çš„è´å¶æ–¯ä¼˜åŒ–(Bayesian Optimization)ï¼Œåœ¨å—é™çš„è®¡ç®—é¢„ç®—å†…é«˜æ•ˆæœç´¢è¶…å‚æ•°ï¼Œä»¥æ»¡è¶³ç‰¹å®šä»»åŠ¡çš„è®¡ç®—å¤æ‚åº¦å’Œå‡†ç¡®æ€§è¦æ±‚ã€‚é€šè¿‡è°ƒæ•´ä¹˜åŠ è¿ç®—æ¬¡æ•°(MACs)ï¼ŒTSLA èƒ½å¤Ÿä¸ºå¤šæ ·åŒ–çš„è‡ªåŠ¨é©¾é©¶ä»»åŠ¡ç”Ÿæˆå®šåˆ¶åŒ–é…ç½®ï¼Œæœ€å¤§åŒ–äº†æ¨¡å‹åœ¨ NVIDIA DRIVE PX 2 ç­‰ç›®æ ‡å¹³å°ä¸Šçš„ç¡¬ä»¶åˆ©ç”¨ç‡ä¸å‡†ç¡®åº¦ã€‚",
      "categories": [
        "cs.CV",
        "cs.AI",
        "cs.AR",
        "cs.LG"
      ],
      "primary_category": "cs.CV",
      "comment": "",
      "pdf_url": "https://arxiv.org/pdf/2508.12279v2",
      "published_date": "2025-08-17 08:09:13 UTC",
      "updated_date": "2025-10-04 14:10:09 UTC",
      "processing_status": "completed",
      "attempts": 1,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "llm_backup_calls": 0,
      "last_update": "2026-01-24T12:25:39.847178+00:00"
    },
    {
      "arxiv_id": "2508.12278v2",
      "title": "CRoC: Context Refactoring Contrast for Graph Anomaly Detection with Limited Supervision",
      "title_zh": "CRoCï¼šé¢å‘æœ‰é™ç›‘ç£å›¾å¼‚å¸¸æ£€æµ‹çš„ä¸Šä¸‹æ–‡é‡æ„å¯¹æ¯”",
      "authors": [
        "Siyue Xie",
        "Da Sun Handason Tam",
        "Wing Cheong Lau"
      ],
      "abstract": "Graph Neural Networks (GNNs) are widely used as the engine for various graph-related tasks, with their effectiveness in analyzing graph-structured data. However, training robust GNNs often demands abundant labeled data, which is a critical bottleneck in real-world applications. This limitation severely impedes progress in Graph Anomaly Detection (GAD), where anomalies are inherently rare, costly to label, and may actively camouflage their patterns to evade detection. To address these problems, we propose Context Refactoring Contrast (CRoC), a simple yet effective framework that trains GNNs for GAD by jointly leveraging limited labeled and abundant unlabeled data. Different from previous works, CRoC exploits the class imbalance inherent in GAD to refactor the context of each node, which builds augmented graphs by recomposing the attributes of nodes while preserving their interaction patterns. Furthermore, CRoC encodes heterogeneous relations separately and integrates them into the message-passing process, enhancing the model's capacity to capture complex interaction semantics. These operations preserve node semantics while encouraging robustness to adversarial camouflage, enabling GNNs to uncover intricate anomalous cases. In the training stage, CRoC is further integrated with the contrastive learning paradigm. This allows GNNs to effectively harness unlabeled data during joint training, producing richer, more discriminative node embeddings. CRoC is evaluated on seven real-world GAD datasets with varying scales. Extensive experiments demonstrate that CRoC achieves up to 14% AUC improvement over baseline GNNs and outperforms state-of-the-art GAD methods under limited-label settings.",
      "tldr_zh": "è¯¥ç ”ç©¶æå‡ºäº†CRoCï¼ˆContext Refactoring Contrastï¼‰ï¼Œè¿™æ˜¯ä¸€ä¸ªæ—¨åœ¨è§£å†³æœ‰é™ç›‘ç£ä¸‹å›¾å¼‚å¸¸æ£€æµ‹ï¼ˆGraph Anomaly Detection, GADï¼‰æŒ‘æˆ˜çš„é«˜æ•ˆæ¡†æ¶ã€‚CRoCé’ˆå¯¹å¼‚å¸¸æ•°æ®ç¨€ç¼ºå’Œä¼ªè£…æ€§å¼ºçš„é—®é¢˜ï¼Œé€šè¿‡é‡æ„èŠ‚ç‚¹ä¸Šä¸‹æ–‡ï¼ˆContext Refactoringï¼‰æ¥ç”Ÿæˆå¢å¼ºå›¾ï¼Œåœ¨ä¿ç•™äº¤äº’æ¨¡å¼çš„åŒæ—¶é‡æ–°ç»„åˆèŠ‚ç‚¹å±æ€§ï¼Œä»è€Œæé«˜æ¨¡å‹å¯¹å¯¹æŠ—æ€§ä¼ªè£…çš„é²æ£’æ€§ã€‚æ­¤å¤–ï¼Œè¯¥æ¡†æ¶é€šè¿‡åˆ†åˆ«ç¼–ç å¼‚æ„å…³ç³»ï¼ˆHeterogeneous relationsï¼‰å¹¶å°†å…¶é›†æˆåˆ°æ¶ˆæ¯ä¼ é€’è¿‡ç¨‹ä¸­ï¼Œå¢å¼ºäº†æ•æ‰å¤æ‚äº¤äº’è¯­ä¹‰çš„èƒ½åŠ›ã€‚åœ¨è®­ç»ƒé˜¶æ®µï¼ŒCRoCç»“åˆäº†å¯¹æ¯”å­¦ä¹ ï¼ˆContrastive learningï¼‰èŒƒå¼ï¼Œèƒ½å¤Ÿæœ‰æ•ˆåˆ©ç”¨å¤§é‡æ— æ ‡ç­¾æ•°æ®ç”Ÿæˆæ›´å…·è¾¨åˆ«åŠ›çš„èŠ‚ç‚¹åµŒå…¥ï¼ˆNode embeddingsï¼‰ã€‚åœ¨ä¸ƒä¸ªçœŸå®æ•°æ®é›†ä¸Šçš„å®éªŒç»“æœè¡¨æ˜ï¼ŒCRoCåœ¨æœ‰é™æ ‡ç­¾è®¾ç½®ä¸‹ç›¸è¾ƒäºåŸºçº¿æ¨¡å‹å®ç°äº†é«˜è¾¾14%çš„AUCæå‡ï¼Œæ€§èƒ½æ˜¾è‘—ä¼˜äºç°æœ‰çš„å›¾å¼‚å¸¸æ£€æµ‹SOTAæ–¹æ³•ã€‚",
      "categories": [
        "cs.LG",
        "cs.AI"
      ],
      "primary_category": "cs.LG",
      "comment": "Accepted by ECAI 2025",
      "pdf_url": "https://arxiv.org/pdf/2508.12278v2",
      "published_date": "2025-08-17 08:05:17 UTC",
      "updated_date": "2025-09-14 10:08:13 UTC",
      "processing_status": "completed",
      "attempts": 1,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "llm_backup_calls": 0,
      "last_update": "2026-01-24T12:25:38.450426+00:00"
    },
    {
      "arxiv_id": "2508.12277v1",
      "title": "The Self-Execution Benchmark: Measuring LLMs' Attempts to Overcome Their Lack of Self-Execution",
      "title_zh": "Self-Execution åŸºå‡†ï¼šè¡¡é‡å¤§è¯­è¨€æ¨¡å‹å¯¹å…¶ç¼ºä¹è‡ªæˆ‘æ‰§è¡Œèƒ½åŠ›çš„å…‹æœå°è¯•",
      "authors": [
        "Elon Ezra",
        "Ariel Weizman",
        "Amos Azaria"
      ],
      "abstract": "Large language models (LLMs) are commonly evaluated on tasks that test their knowledge or reasoning abilities. In this paper, we explore a different type of evaluation: whether an LLM can predict aspects of its own responses. Since LLMs lack the ability to execute themselves, we introduce the Self-Execution Benchmark, which measures a model's ability to anticipate properties of its output, such as whether a question will be difficult for it, whether it will refuse to answer, or what kinds of associations it is likely to produce. Our experiments show that models generally perform poorly on this benchmark, and that increased model size or capability does not consistently lead to better performance. These results suggest a fundamental limitation in how LLMs represent and reason about their own behavior.",
      "tldr_zh": "è¯¥ç ”ç©¶æ¢è®¨äº†å¤§è¯­è¨€æ¨¡å‹(Large Language Models, LLMs)æ˜¯å¦èƒ½å¤Ÿé¢„æµ‹å…¶è‡ªèº«ç”Ÿæˆçš„å“åº”å±æ€§ã€‚ç”±äºLLMsç¼ºä¹Self-Executionçš„èƒ½åŠ›ï¼Œä½œè€…å¼•å…¥äº†Self-Execution Benchmarkï¼Œæ—¨åœ¨è¡¡é‡æ¨¡å‹é¢„æµ‹å…¶è¾“å‡ºç‰¹æ€§çš„èƒ½åŠ›ã€‚è¯¥åŸºå‡†æµ‹è¯•æ¶µç›–äº†å¯¹ä»»åŠ¡éš¾åº¦ã€æ˜¯å¦è§¦å‘æ‹’ç»æœºåˆ¶ä»¥åŠäº§ç”Ÿçš„å…³è”ç±»å‹ç­‰å±æ€§çš„é¢„æµ‹ã€‚å®éªŒç»“æœæ˜¾ç¤ºï¼Œç°æœ‰æ¨¡å‹åœ¨è¯¥åŸºå‡†æµ‹è¯•ä¸Šçš„è¡¨ç°æ™®éæ¬ ä½³ã€‚ç ”ç©¶è¿›ä¸€æ­¥å‘ç°ï¼Œæ¨¡å‹è§„æ¨¡æˆ–èƒ½åŠ›çš„æå‡å¹¶æœªæ˜¾è‘—æ”¹å–„é¢„æµ‹å‡†ç¡®æ€§ã€‚è¿™ä¸€ç»“æœæ­ç¤ºäº†LLMsåœ¨è¡¨å¾å’Œæ¨ç†è‡ªèº«è¡Œä¸ºé€»è¾‘æ–¹é¢å­˜åœ¨æ ¹æœ¬æ€§çš„å±€é™ã€‚",
      "categories": [
        "cs.CL",
        "cs.AI"
      ],
      "primary_category": "cs.CL",
      "comment": "11 pages, 9 figures",
      "pdf_url": "https://arxiv.org/pdf/2508.12277v1",
      "published_date": "2025-08-17 07:57:58 UTC",
      "updated_date": "2025-08-17 07:57:58 UTC",
      "processing_status": "completed",
      "attempts": 1,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "llm_backup_calls": 0,
      "last_update": "2026-01-24T12:25:43.127599+00:00"
    },
    {
      "arxiv_id": "2508.14104v1",
      "title": "You Don't Know Until You Click:Automated GUI Testing for Production-Ready Software Evaluation",
      "title_zh": "ä¸ç‚¹ä¸çŸ¥ï¼šé¢å‘ç”Ÿäº§çº§è½¯ä»¶è¯„ä¼°çš„è‡ªåŠ¨åŒ– GUI æµ‹è¯•",
      "authors": [
        "Yutong Bian",
        "Xianhao Lin",
        "Yupeng Xie",
        "Tianyang Liu",
        "Mingchen Zhuge",
        "Siyuan Lu",
        "Haoming Tang",
        "Jinlin Wang",
        "Jiayi Zhang",
        "Jiaqi Chen",
        "Xiangru Tang",
        "Yongxin Ni",
        "Sirui Hong",
        "Chenglin Wu"
      ],
      "abstract": "Large Language Models (LLMs) and code agents in software development are rapidly evolving from generating isolated code snippets to producing full-fledged software applications with graphical interfaces, interactive logic, and dynamic behaviors. However, current benchmarks fall short in evaluating such production-ready software, as they often rely on static checks or binary pass/fail scripts, failing to capture the interactive behaviors and runtime dynamics that define real-world usability - qualities that only emerge when an application is actively used. This is the blind spot of current evaluation: you don't know if an app works until you click through it, interact with it, and observe how it responds. To bridge this gap, we introduce RealDevWorld, a novel evaluation framework for automated end-to-end assessment of LLMs' ability to generate production-ready repositories from scratch. It features two key components: (1) RealDevBench, a diverse collection of 194 open-ended software engineering tasks across multiple domains, incorporating multimodal elements to reflect real-world complexity; and (2) AppEvalPilot, a new agent-as-a-judge evaluation system that simulates realistic, GUI-based user interactions to automatically and holistically assess software functional correctness, visual fidelity, and runtime behavior. The framework delivers fine-grained, task-specific diagnostic feedback, supporting nuanced evaluation beyond simple success/failure judgments. Empirical results show that RealDevWorld delivers effective, automatic, and human-aligned evaluations, achieving an accuracy of 0.92 and a correlation of 0.85 with expert human assessments, while significantly reducing the reliance on manual review. This enables scalable, human-aligned assessment of production-level software generated by LLMs. Our code is available on GitHub.",
      "tldr_zh": "è¯¥ç ”ç©¶é’ˆå¯¹å¤§è¯­è¨€æ¨¡å‹(LLMs)ç”Ÿæˆçš„æˆå“çº§è½¯ä»¶åœ¨äº¤äº’è¡Œä¸ºå’Œè¿è¡Œæ—¶åŠ¨æ€è¯„ä¼°æ–¹é¢çš„ç¼ºå¤±ï¼Œæå‡ºäº†RealDevWorldè¯„ä¼°æ¡†æ¶ã€‚è¯¥æ¡†æ¶åŒ…å«RealDevBenchï¼Œè¿™æ˜¯ä¸€ä¸ªæ¶µç›–194ä¸ªå¼€æ”¾å¼è½¯ä»¶å·¥ç¨‹ä»»åŠ¡çš„å¤šæ ·åŒ–æ•°æ®é›†ï¼Œé€šè¿‡å¼•å…¥å¤šæ¨¡æ€å…ƒç´ ä½“ç°äº†ç°å®ä¸–ç•Œçš„å¤æ‚æ€§ã€‚æ­¤å¤–ï¼Œç ”ç©¶å¼•å…¥äº†AppEvalPilotï¼Œè¿™æ˜¯ä¸€ç§åŸºäºæ™ºèƒ½ä½“ä»£ç†è¯„å®¡(Agent-as-a-judge)çš„è¯„ä¼°ç³»ç»Ÿï¼Œé€šè¿‡æ¨¡æ‹ŸçœŸå®çš„å›¾å½¢ç”¨æˆ·ç•Œé¢(GUI)äº¤äº’ï¼Œå¯¹è½¯ä»¶çš„åŠŸèƒ½æ­£ç¡®æ€§ã€è§†è§‰ä¿çœŸåº¦(Visual Fidelity)åŠè¿è¡Œæ—¶è¡Œä¸ºè¿›è¡Œè‡ªåŠ¨åŒ–ã€å…¨æ–¹ä½çš„è¯„ä¼°ã€‚RealDevWorldèƒ½å¤Ÿæä¾›ç»†ç²’åº¦çš„ä»»åŠ¡ç‰¹å®šè¯Šæ–­åé¦ˆï¼Œæ”¯æŒè¶…è¶Šç®€å•æˆè´¥åˆ¤å®šçš„ç»†è‡´åŒ–è¯„ä»·ã€‚å®éªŒç»“æœè¡¨æ˜ï¼Œè¯¥æ¡†æ¶åœ¨è‡ªåŠ¨åŒ–è¯„ä¼°ä¸­ä¸äººç±»ä¸“å®¶é«˜åº¦å¯¹é½ï¼Œå‡†ç¡®ç‡è¾¾åˆ°0.92ï¼Œç›¸å…³æ€§ä¸º0.85ã€‚è¯¥ç ”ç©¶æ˜¾è‘—å‡å°‘äº†å¯¹äººå·¥è¯„å®¡çš„ä¾èµ–ï¼Œä¸ºLLMsç”Ÿæˆçš„ç”Ÿäº§çº§è½¯ä»¶æä¾›äº†å¯æ‰©å±•ä¸”é«˜æ•ˆçš„ç«¯åˆ°ç«¯è¯„ä¼°æ–¹æ¡ˆã€‚",
      "categories": [
        "cs.SE",
        "cs.AI"
      ],
      "primary_category": "cs.SE",
      "comment": "",
      "pdf_url": "https://arxiv.org/pdf/2508.14104v1",
      "published_date": "2025-08-17 07:31:11 UTC",
      "updated_date": "2025-08-17 07:31:11 UTC",
      "processing_status": "completed",
      "attempts": 1,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "llm_backup_calls": 0,
      "last_update": "2026-01-24T12:25:47.384554+00:00"
    },
    {
      "arxiv_id": "2508.12263v2",
      "title": "Region-Level Context-Aware Multimodal Understanding",
      "title_zh": "åŒºåŸŸçº§ä¸Šä¸‹æ–‡æ„ŸçŸ¥å¤šæ¨¡æ€ç†è§£",
      "authors": [
        "Hongliang Wei",
        "Xianqi Zhang",
        "Xingtao Wang",
        "Xiaopeng Fan",
        "Debin Zhao"
      ],
      "abstract": "Despite significant progress, existing research on Multimodal Large Language Models (MLLMs) mainly focuses on general visual understanding, overlooking the ability to integrate textual context associated with objects for a more context-aware multimodal understanding -- an ability we refer to as Region-level Context-aware Multimodal Understanding (RCMU). To address this limitation, we first formulate the RCMU task, which requires models to respond to user instructions by integrating both image content and textual information of regions or objects. To equip MLLMs with RCMU capabilities, we propose Region-level Context-aware Visual Instruction Tuning (RCVIT), which incorporates object information into the model input and enables the model to utilize bounding box coordinates to effectively associate objects' visual content with their textual information. To address the lack of datasets, we introduce the RCMU dataset, a large-scale visual instruction tuning dataset that covers multiple RCMU tasks. We also propose RC\\&P-Bench, a comprehensive benchmark that can evaluate the performance of MLLMs in RCMU and multimodal personalized understanding tasks. Additionally, we propose a reference-free evaluation metric to perform a comprehensive and fine-grained evaluation of the region-level context-aware image descriptions. By performing RCVIT on Qwen2-VL models with the RCMU dataset, we developed RC-Qwen2-VL models. Experimental results indicate that RC-Qwen2-VL models not only achieve outstanding performance on multiple RCMU tasks but also demonstrate successful applications in multimodal RAG and personalized conversation. Our data, model and benchmark are available at https://github.com/hongliang-wei/RC-MLLM",
      "tldr_zh": "è¯¥ç ”ç©¶é’ˆå¯¹ç°æœ‰å¤šæ¨¡æ€å¤§è¯­è¨€æ¨¡å‹(MLLMs)åœ¨æ•´åˆç‰©ä½“ç›¸å…³æ–‡æœ¬è¯­å¢ƒæ–¹é¢çš„å±€é™æ€§ï¼Œæ­£å¼å®šä¹‰äº†åŒºåŸŸçº§ä¸Šä¸‹æ–‡æ„ŸçŸ¥å¤šæ¨¡æ€ç†è§£(RCMU)ä»»åŠ¡ã€‚ä¸ºäº†èµ‹äºˆæ¨¡å‹RCMUèƒ½åŠ›ï¼Œä½œè€…æå‡ºäº†åŒºåŸŸçº§ä¸Šä¸‹æ–‡æ„ŸçŸ¥è§†è§‰æŒ‡ä»¤å¾®è°ƒ(RCVIT)æ–¹æ³•ï¼Œåˆ©ç”¨è¾¹ç•Œæ¡†(bounding box)åæ ‡å°†ç‰©ä½“çš„è§†è§‰å†…å®¹ä¸å…¶æ–‡æœ¬ä¿¡æ¯æœ‰æ•ˆå…³è”ã€‚ç ”ç©¶å›¢é˜ŸåŒæ­¥æ¨å‡ºäº†å¤§è§„æ¨¡RCMUæ•°æ®é›†ã€ç»¼åˆè¯„æµ‹åŸºå‡†RC&P-Benchä»¥åŠä¸€å¥—æ— å‚è€ƒè¯„ä¼°æŒ‡æ ‡ï¼Œç”¨äºç»†ç²’åº¦çš„å›¾åƒæè¿°è¯„ä¼°ã€‚é€šè¿‡åœ¨Qwen2-VLæ¨¡å‹ä¸Šåº”ç”¨RCVITæŠ€æœ¯ï¼Œå¼€å‘å‡ºçš„RC-Qwen2-VLæ¨¡å‹åœ¨å¤šé¡¹RCMUä»»åŠ¡ä¸­å–å¾—äº†ä¼˜å¼‚æˆç»©ã€‚å®éªŒè¯æ˜ï¼Œè¯¥æ¨¡å‹ä¸ä»…åœ¨åŸºç¡€ç†è§£ä»»åŠ¡ä¸Šè¡¨ç°å‡ºè‰²ï¼Œåœ¨å¤šæ¨¡æ€æ£€ç´¢å¢å¼ºç”Ÿæˆ(RAG)å’Œä¸ªæ€§åŒ–å¯¹è¯ç­‰å®é™…åº”ç”¨ä¸­ä¹Ÿå±•ç°äº†æå¼ºçš„æ½œåŠ›ã€‚",
      "categories": [
        "cs.CV",
        "cs.AI"
      ],
      "primary_category": "cs.CV",
      "comment": "12 pages, 6 figures",
      "pdf_url": "https://arxiv.org/pdf/2508.12263v2",
      "published_date": "2025-08-17 07:18:43 UTC",
      "updated_date": "2025-08-29 05:28:01 UTC",
      "processing_status": "completed",
      "attempts": 1,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "llm_backup_calls": 0,
      "last_update": "2026-01-24T12:25:45.592352+00:00"
    },
    {
      "arxiv_id": "2508.12260v4",
      "title": "Mantis: A Foundation Model for Mechanistic Disease Forecasting",
      "title_zh": "Mantisï¼šé¢å‘æœºåˆ¶æ€§ç–¾ç—…é¢„æµ‹çš„åŸºç¡€æ¨¡å‹",
      "authors": [
        "Carson Dudley",
        "Reiden Magdaleno",
        "Christopher Harding",
        "Ananya Sharma",
        "Emily Martin",
        "Marisa Eisenberg"
      ],
      "abstract": "Infectious disease forecasting in novel outbreaks or low-resource settings is hampered by the need for large disease and covariate data sets, bespoke training, and expert tuning, all of which can hinder rapid generation of forecasts for new settings. To help address these challenges, we developed Mantis, a foundation model trained entirely on mechanistic simulations, which enables out-of-the-box forecasting across diseases, regions, and outcomes, even in settings with limited historical data. We evaluated Mantis against 48 forecasting models across six diseases with diverse modes of transmission, assessing both point forecast accuracy (mean absolute error) and probabilistic performance (weighted interval score and coverage). Despite using no real-world data during training, Mantis achieved lower mean absolute error than all models in the CDC's COVID-19 Forecast Hub when backtested on early pandemic forecasts which it had not previously seen. Across all other diseases tested, Mantis consistently ranked in the top two models across evaluation metrics. Mantis further generalized to diseases with transmission mechanisms not represented in its training data, demonstrating that it can capture fundamental contagion dynamics rather than memorizing disease-specific patterns. These capabilities illustrate that purely simulation-based foundation models such as Mantis can provide a practical foundation for disease forecasting: general-purpose, accurate, and deployable where traditional models struggle.",
      "tldr_zh": "è¯¥ç ”ç©¶å¼€å‘äº†Mantisï¼Œä¸€ä¸ªå®Œå…¨åŸºäºæœºæ¢°æ¨¡æ‹Ÿ(mechanistic simulations)è®­ç»ƒçš„åŸºç¡€æ¨¡å‹(Foundation Model)ï¼Œæ—¨åœ¨è§£å†³ä¼ æŸ“ç—…é¢„æµ‹ä¸­å¯¹å¤§è§„æ¨¡æ•°æ®å’Œä¸“å®¶è°ƒä¼˜çš„ä¾èµ–é—®é¢˜ã€‚Mantiså…·å¤‡è·¨ç–¾ç—…ã€è·¨åœ°åŒºå’Œè·¨ç»“æœçš„å³æ’å³ç”¨é¢„æµ‹èƒ½åŠ›ï¼Œå°¤å…¶é€‚ç”¨äºç¼ºä¹å†å²æ•°æ®çš„ä½èµ„æºç¯å¢ƒã€‚åœ¨ä¸48ä¸ªæ¨¡å‹é’ˆå¯¹6ç§ä¸åŒä¼ æ’­æ¨¡å¼ç–¾ç—…çš„å¯¹æ¯”è¯„ä¼°ä¸­ï¼ŒMantisçš„é¢„æµ‹æ€§èƒ½å§‹ç»ˆä½å±…å‰åˆ—ï¼Œä¸”åœ¨COVID-19æ—©æœŸå¤§æµè¡Œé¢„æµ‹ä¸­çš„å¹³å‡ç»å¯¹è¯¯å·®(mean absolute error)ä¼˜äºCDCæ‰€æœ‰å¯¹æ¯”æ¨¡å‹ã€‚å®éªŒç»“æœè¡¨æ˜ï¼Œè¯¥æ¨¡å‹é€šè¿‡æ•æ‰åŸºç¡€ä¼ æŸ“åŠ¨æ€è€Œéè®°å¿†ç‰¹å®šç–¾ç—…æ¨¡å¼ï¼Œå®ç°äº†æå¼ºçš„æ³›åŒ–èƒ½åŠ›ã€‚è¿™è¯æ˜äº†çº¯æ¨¡æ‹Ÿé©±åŠ¨çš„åŸºç¡€æ¨¡å‹èƒ½ä¸ºä¼ æŸ“ç—…é¢„æµ‹æä¾›å‡†ç¡®ã€é€šç”¨ä¸”æ˜“äºéƒ¨ç½²çš„å®è·µåŸºç¡€ã€‚",
      "categories": [
        "cs.AI",
        "q-bio.QM"
      ],
      "primary_category": "cs.AI",
      "comment": "11 pages, 4 figures",
      "pdf_url": "https://arxiv.org/pdf/2508.12260v4",
      "published_date": "2025-08-17 06:55:29 UTC",
      "updated_date": "2026-01-22 17:34:42 UTC",
      "processing_status": "completed",
      "attempts": 1,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "llm_backup_calls": 0,
      "last_update": "2026-01-24T12:25:55.685906+00:00"
    },
    {
      "arxiv_id": "2508.12259v3",
      "title": "Fortifying the Agentic Web: A Unified Zero-Trust Architecture Against Logic-layer Threats",
      "title_zh": "ç­‘ç‰¢æ™ºèƒ½ä½“ç½‘ç»œï¼šæŠµå¾¡é€»è¾‘å±‚å¨èƒçš„ç»Ÿä¸€é›¶ä¿¡ä»»æ¶æ„",
      "authors": [
        "Ken Huang",
        "Yasir Mehmood",
        "Hammad Atta",
        "Jerry Huang",
        "Muhammad Zeeshan Baig",
        "Sree Bhargavi Balija"
      ],
      "abstract": "This paper presents a Unified Security Architecture that fortifies the Agentic Web through a Zero-Trust IAM framework. This architecture is built on a foundation of rich, verifiable agent identities using Decentralized Identifiers (DIDs) and Verifiable Credentials (VCs), with discovery managed by a protocol-agnostic Agent Name Service (ANS). Security is operationalized through a multi-layered Trust Fabric which introduces significant innovations, including Trust-Adaptive Runtime Environments (TARE), Causal Chain Auditing, and Dynamic Identity with Behavioral Attestation. By explicitly linking the LPCI threat to these enhanced architectural countermeasures within a formal security model, we propose a comprehensive and forward-looking blueprint for a secure, resilient, and trustworthy agentic ecosystem. Our formal analysis demonstrates that the proposed architecture provides provable security guarantees against LPCI attacks with bounded probability of success.",
      "tldr_zh": "è¯¥ç ”ç©¶æå‡ºäº†ä¸€ä¸ªç»Ÿä¸€çš„å®‰å…¨æ¶æ„(Unified Security Architecture)ï¼Œæ—¨åœ¨é€šè¿‡é›¶ä¿¡ä»»(Zero-Trust)èº«ä»½è¯†åˆ«ä¸è®¿é—®ç®¡ç†(IAM)æ¡†æ¶æ¥åŠ å¼ºAgentic Webçš„å®‰å…¨ã€‚è¯¥æ¶æ„åˆ©ç”¨å»ä¸­å¿ƒåŒ–æ ‡è¯†ç¬¦(DIDs)å’Œå¯éªŒè¯å‡­è¯(VCs)æ„å»ºå¯éªŒè¯çš„æ™ºèƒ½ä½“èº«ä»½ï¼Œå¹¶é€šè¿‡åè®®æ— å…³çš„æ™ºèƒ½ä½“åç§°æœåŠ¡(ANS)ç®¡ç†å‘ç°è¿‡ç¨‹ã€‚å®‰å…¨è¿ä½œä¾æ‰˜äºå¤šå±‚ä¿¡ä»»ç»‡ç‰©(Trust Fabric)ï¼Œå¼•å…¥äº†ä¿¡ä»»è‡ªé€‚åº”è¿è¡Œæ—¶ç¯å¢ƒ(TARE)ã€å› æœé“¾å®¡è®¡(Causal Chain Auditing)ä»¥åŠå¸¦æœ‰è¡Œä¸ºè¯æ˜çš„åŠ¨æ€èº«ä»½(Dynamic Identity with Behavioral Attestation)ç­‰åˆ›æ–°æŠ€æœ¯ã€‚é€šè¿‡å°†LPCIå¨èƒä¸è¿™äº›å¢å¼ºçš„æ¶æ„å¯¹ç­–åœ¨æ­£å¼å®‰å…¨æ¨¡å‹ä¸­æŒ‚é’©ï¼Œè¯¥è®ºæ–‡ä¸ºæ„å»ºå®‰å…¨ä¸”å¯ä¿¡çš„æ™ºèƒ½ä½“ç”Ÿæ€ç³»ç»Ÿæä¾›äº†å‰ç»æ€§è“å›¾ã€‚å½¢å¼åŒ–åˆ†æè¯æ˜ï¼Œè¯¥æ¶æ„èƒ½å¤Ÿæä¾›é’ˆå¯¹LPCIæ”»å‡»çš„å¯è¯æ˜å®‰å…¨ä¿éšœï¼Œå¹¶å°†æ”»å‡»æˆåŠŸæ¦‚ç‡é™åˆ¶åœ¨æœ‰é™èŒƒå›´å†…ã€‚",
      "categories": [
        "cs.CR",
        "cs.AI",
        "cs.ET"
      ],
      "primary_category": "cs.CR",
      "comment": "",
      "pdf_url": "https://arxiv.org/pdf/2508.12259v3",
      "published_date": "2025-08-17 06:52:39 UTC",
      "updated_date": "2025-08-20 21:14:55 UTC",
      "processing_status": "completed",
      "attempts": 1,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "llm_backup_calls": 0,
      "last_update": "2026-01-24T12:26:01.992353+00:00"
    },
    {
      "arxiv_id": "2508.12253v1",
      "title": "Interpreting Time Series Forecasts with LIME and SHAP: A Case Study on the Air Passengers Dataset",
      "title_zh": "ä½¿ç”¨ LIME å’Œ SHAP è§£é‡Šæ—¶é—´åºåˆ—é¢„æµ‹ï¼šä»¥ Air Passengers æ•°æ®é›†ä¸ºä¾‹çš„æ¡ˆä¾‹ç ”ç©¶",
      "authors": [
        "Manish Shukla"
      ],
      "abstract": "Time-series forecasting underpins critical decisions across aviation, energy, retail and health. Classical autoregressive integrated moving average (ARIMA) models offer interpretability via coefficients but struggle with nonlinearities, whereas tree-based machine-learning models such as XGBoost deliver high accuracy but are often opaque. This paper presents a unified framework for interpreting time-series forecasts using local interpretable model-agnostic explanations (LIME) and SHapley additive exPlanations (SHAP). We convert a univariate series into a leakage-free supervised learning problem, train a gradient-boosted tree alongside an ARIMA baseline and apply post-hoc explainability. Using the Air Passengers dataset as a case study, we show that a small set of lagged features -- particularly the twelve-month lag -- and seasonal encodings explain most forecast variance. We contribute: (i) a methodology for applying LIME and SHAP to time series without violating chronology; (ii) theoretical exposition of the underlying algorithms; (iii) empirical evaluation with extensive analysis; and (iv) guidelines for practitioners.",
      "tldr_zh": "è¯¥ç ”ç©¶æå‡ºäº†ä¸€ä¸ªç»Ÿä¸€çš„æ¡†æ¶ï¼Œæ—¨åœ¨åˆ©ç”¨å±€éƒ¨å¯è§£é‡Šæ¨¡å‹æ— å…³è¯´æ˜(LIME)å’ŒSHapleyåŠ æ€§è§£é‡Š(SHAP)æ¥è§£é‡Šæ—¶é—´åºåˆ—é¢„æµ‹æ¨¡å‹ã€‚ä½œè€…é’ˆå¯¹ç»å…¸ARIMAæ¨¡å‹åœ¨å¤„ç†éçº¿æ€§æ—¶é¢ä¸´çš„å±€é™ï¼Œä»¥åŠXGBoostç­‰æ¢¯åº¦æå‡æ ‘æ¨¡å‹è™½ç„¶å‡†ç¡®ä½†ç¼ºä¹é€æ˜åº¦çš„é—®é¢˜ï¼Œå°†å•å˜é‡æ—¶é—´åºåˆ—è½¬æ¢ä¸ºæ— æ•°æ®æ³„æ¼çš„ç›‘ç£å­¦ä¹ é—®é¢˜ã€‚é€šè¿‡åœ¨è¯¥æ¡†æ¶ä¸‹åº”ç”¨äº‹åå¯è§£é‡Šæ€§(post-hoc explainability)æŠ€æœ¯ï¼Œç ”ç©¶æ­ç¤ºäº†é»‘ç›’æ¨¡å‹çš„å†³ç­–æœºåˆ¶ã€‚ä»¥Air Passengersæ•°æ®é›†ä¸ºæ¡ˆä¾‹ï¼Œå®éªŒå‘ç°ä¸€å°éƒ¨åˆ†æ»åç‰¹å¾ï¼ˆç‰¹åˆ«æ˜¯åäºŒä¸ªæœˆæ»åï¼‰å’Œå­£èŠ‚æ€§ç¼–ç è§£é‡Šäº†ç»å¤§éƒ¨åˆ†é¢„æµ‹æ–¹å·®ã€‚è¯¥è®ºæ–‡çš„ä¸»è¦è´¡çŒ®åœ¨äºæå‡ºäº†ä¸€å¥—åœ¨ä¸è¿åæ—¶é—´é¡ºåºçš„å‰æä¸‹å°†LIMEå’ŒSHAPåº”ç”¨äºæ—¶é—´åºåˆ—çš„æ–¹æ³•è®ºï¼Œå¹¶æä¾›äº†è¯¦ç»†çš„ç†è®ºé˜è¿°ã€å®è¯è¯„ä¼°åŠä»ä¸šè€…æŒ‡å—ã€‚",
      "categories": [
        "cs.LG",
        "cs.AI",
        "stat.ME"
      ],
      "primary_category": "cs.LG",
      "comment": "",
      "pdf_url": "https://arxiv.org/pdf/2508.12253v1",
      "published_date": "2025-08-17 06:22:29 UTC",
      "updated_date": "2025-08-17 06:22:29 UTC",
      "processing_status": "completed",
      "attempts": 1,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "llm_backup_calls": 0,
      "last_update": "2026-01-24T12:26:07.284257+00:00"
    },
    {
      "arxiv_id": "2508.12247v1",
      "title": "STM3: Mixture of Multiscale Mamba for Long-Term Spatio-Temporal Time-Series Prediction",
      "title_zh": "STM3ï¼šé¢å‘é•¿æœŸæ—¶ç©ºæ—¶é—´åºåˆ—é¢„æµ‹çš„æ··åˆå¤šå°ºåº¦ Mamba",
      "authors": [
        "Haolong Chen",
        "Liang Zhang",
        "Zhengyuan Xin",
        "Guangxu Zhu"
      ],
      "abstract": "Recently, spatio-temporal time-series prediction has developed rapidly, yet existing deep learning methods struggle with learning complex long-term spatio-temporal dependencies efficiently. The long-term spatio-temporal dependency learning brings two new challenges: 1) The long-term temporal sequence includes multiscale information naturally which is hard to extract efficiently; 2) The multiscale temporal information from different nodes is highly correlated and hard to model. To address these challenges, we propose an efficient \\textit{\\textbf{S}patio-\\textbf{T}emporal \\textbf{M}ultiscale \\textbf{M}amba} (STM2) that includes a multiscale Mamba architecture to capture the multiscale information efficiently and simultaneously, and an adaptive graph causal convolution network to learn the complex multiscale spatio-temporal dependency. STM2 includes hierarchical information aggregation for different-scale information that guarantees their distinguishability. To capture diverse temporal dynamics across all spatial nodes more efficiently, we further propose an enhanced version termed \\textit{\\textbf{S}patio-\\textbf{T}emporal \\textbf{M}ixture of \\textbf{M}ultiscale \\textbf{M}amba} (STM3) that employs a special Mixture-of-Experts architecture, including a more stable routing strategy and a causal contrastive learning strategy to enhance the scale distinguishability. We prove that STM3 has much better routing smoothness and guarantees the pattern disentanglement for each expert successfully. Extensive experiments on real-world benchmarks demonstrate STM2/STM3's superior performance, achieving state-of-the-art results in long-term spatio-temporal time-series prediction.",
      "tldr_zh": "è¯¥ç ”ç©¶é’ˆå¯¹é•¿ç¨‹æ—¶ç©ºåºåˆ—é¢„æµ‹ï¼ˆLong-Term Spatio-Temporal Time-Series Predictionï¼‰ä¸­å¤æ‚ä¾èµ–éš¾ä»¥é«˜æ•ˆæå–çš„æŒ‘æˆ˜ï¼Œæå‡ºäº†STM2æ¡†æ¶ã€‚STM2é€šè¿‡å¤šå°ºåº¦Mambaæ¶æ„å’Œè‡ªé€‚åº”å›¾å› æœå·ç§¯ç½‘ç»œï¼ˆAdaptive Graph Causal Convolution Networkï¼‰æ•è·å¤šå°ºåº¦æ—¶ç©ºä¿¡æ¯ï¼Œå¹¶åˆ©ç”¨å±‚æ¬¡åŒ–èšåˆç¡®ä¿å…¶åŒºåˆ†æ€§ã€‚åœ¨æ­¤åŸºç¡€ä¸Šï¼Œç ”ç©¶è¿›ä¸€æ­¥æå‡ºäº†å¢å¼ºç‰ˆSTM3ï¼Œå¼•å…¥äº†ä¸“å®¶æ··åˆï¼ˆMixture-of-Expertsï¼‰æ¶æ„ä»¥åŠæ›´ç¨³å®šçš„è·¯ç”±ç­–ç•¥ã€‚STM3ç»“åˆå› æœå¯¹æ¯”å­¦ä¹ ç­–ç•¥ï¼ˆCausal Contrastive Learning Strategyï¼‰ï¼Œå¢å¼ºäº†å¤šå°ºåº¦çš„æ—¶ç©ºåŠ¨åŠ›å­¦å»ºæ¨¡å¹¶å®ç°äº†ä¸“å®¶æ¨¡å¼çš„æˆåŠŸè§£è€¦ï¼ˆPattern Disentanglementï¼‰ã€‚ç†è®ºä¸å®éªŒè¯æ˜ï¼ŒSTM3å…·å¤‡æ›´ä¼˜çš„è·¯ç”±å¹³æ»‘æ€§ï¼Œä¸”STM2ä¸STM3åœ¨çœŸå®åŸºå‡†æµ‹è¯•ä¸­å‡å–å¾—äº†å½“å‰æœ€å…ˆè¿›ï¼ˆState-of-the-Artï¼‰çš„æ€§èƒ½è¡¨ç°ã€‚",
      "categories": [
        "cs.LG",
        "cs.AI"
      ],
      "primary_category": "cs.LG",
      "comment": "",
      "pdf_url": "https://arxiv.org/pdf/2508.12247v1",
      "published_date": "2025-08-17 05:29:58 UTC",
      "updated_date": "2025-08-17 05:29:58 UTC",
      "processing_status": "completed",
      "attempts": 1,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "llm_backup_calls": 0,
      "last_update": "2026-01-24T12:26:15.086335+00:00"
    },
    {
      "arxiv_id": "2508.12232v2",
      "title": "LinkAnchor: An Autonomous LLM-Based Agent for Issue-to-Commit Link Recovery",
      "title_zh": "LinkAnchorï¼šåŸºäºå¤§è¯­è¨€æ¨¡å‹çš„è®®é¢˜-æäº¤é“¾æ¥æ¢å¤è‡ªä¸»æ™ºèƒ½ä½“",
      "authors": [
        "Arshia Akhavan",
        "Alireza Hosseinpour",
        "Abbas Heydarnoori",
        "Mehdi Keshani"
      ],
      "abstract": "Issue-to-commit link recovery plays an important role in software traceability and improves project management. However, it remains a challenging task. A study on GitHub shows that only 42.2% of the issues are correctly linked to their commits. This highlights the potential for further development and research in this area. Existing studies have employed various AI/ML-based approaches, and with the recent development of large language models, researchers have leveraged LLMs to tackle this problem. These approaches suffer from two main issues. First, LLMs are constrained by limited context windows and cannot ingest all of the available data sources, such as long commit histories, extensive issue comments, and large code repositories. Second, most methods operate on individual issue-commit pairs; that is, given a single issue-commit pair, they determine whether the commit resolves the issue. This quickly becomes impractical in real-world repositories containing tens of thousands of commits. To address these limitations, we present LinkAnchor, the first autonomous LLM-based agent designed for issue-to-commit link recovery. The lazy-access architecture of LinkAnchor enables the underlying LLM to access the rich context of software, spanning commits, issue comments, and code files, without exceeding the token limit by dynamically retrieving only the most relevant contextual data. Additionally, LinkAnchor is able to automatically pinpoint the target commit rather than exhaustively scoring every possible candidate. Our evaluations show that LinkAnchor outperforms state-of-the-art issue-to-commit link recovery approaches by 60-262% in Hit@1 score across all our case study projects. We also publicly release LinkAnchor as a ready-to-use tool, along with our replication package. LinkAnchor is designed and tested for GitHub and Jira, and is easily extendable to other platforms.",
      "tldr_zh": "è¯¥ç ”ç©¶æå‡ºäº†LinkAnchorï¼Œè¿™æ˜¯ç¬¬ä¸€ä¸ªä¸“é—¨ç”¨äºIssue-to-commit link recoveryï¼ˆé—®é¢˜åˆ°æäº¤é“¾æ¥æ¢å¤ï¼‰ä»»åŠ¡çš„è‡ªä¸»LLM-based agentã€‚é’ˆå¯¹ç°æœ‰Large Language Models (LLMs) æ–¹æ³•å—é™äºä¸Šä¸‹æ–‡çª—å£ä¸”åœ¨å¤§è§„æ¨¡ä»“åº“ä¸­è¿›è¡ŒPair-wise scoringæ•ˆç‡ä½ä¸‹çš„é—®é¢˜ï¼ŒLinkAnchorè®¾è®¡äº†Lazy-access architectureã€‚è¯¥æ¶æ„é€šè¿‡åŠ¨æ€æ£€ç´¢æœ€ç›¸å…³çš„ä»£ç æ–‡ä»¶ã€è®®é¢˜è¯„è®ºå’Œæäº¤å†å²ï¼Œåœ¨ä¸è¶…å‡ºToken limitçš„å‰æä¸‹å……åˆ†åˆ©ç”¨äº†è½¯ä»¶ç³»ç»Ÿçš„ä¸°å¯Œä¸Šä¸‹æ–‡ä¿¡æ¯ã€‚åŒæ—¶ï¼ŒLinkAnchorèƒ½å¤Ÿè‡ªåŠ¨ç²¾å‡†å®šä½ç›®æ ‡Commitï¼Œé¿å…äº†å¯¹æµ·é‡å€™é€‰æäº¤è¿›è¡Œç©·ä¸¾è¯„åˆ†çš„ç¹çè¿‡ç¨‹ï¼Œæå¤§æå‡äº†åœ¨å®é™…å¼€å‘ç¯å¢ƒä¸­çš„å®ç”¨æ€§ã€‚è¯„ä¼°ç»“æœæ˜¾ç¤ºï¼ŒLinkAnchoråœ¨æ‰€æœ‰é¡¹ç›®ä¸­çš„Hit@1æŒ‡æ ‡æ¯”ç°æœ‰æœ€å…ˆè¿›æ–¹æ³•æé«˜äº†60%è‡³262%ã€‚ç›®å‰ï¼Œè¯¥å·¥å…·å·²ä½œä¸ºç°æˆäº§å“å‘å¸ƒï¼Œæ”¯æŒGitHubå’ŒJiraå¹³å°å¹¶å…·æœ‰è‰¯å¥½çš„æ‰©å±•æ€§ã€‚",
      "categories": [
        "cs.SE",
        "cs.AI"
      ],
      "primary_category": "cs.SE",
      "comment": "",
      "pdf_url": "https://arxiv.org/pdf/2508.12232v2",
      "published_date": "2025-08-17 04:21:44 UTC",
      "updated_date": "2025-09-02 23:35:13 UTC",
      "processing_status": "completed",
      "attempts": 1,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "llm_backup_calls": 0,
      "last_update": "2026-01-24T12:26:09.608224+00:00"
    },
    {
      "arxiv_id": "2508.18225v1",
      "title": "Deep Learning and Matrix Completion-aided IoT Network Localization in the Outlier Scenarios",
      "title_zh": "å¼‚å¸¸å€¼åœºæ™¯ä¸‹åŸºäºæ·±åº¦å­¦ä¹ ä¸çŸ©é˜µè¡¥å…¨è¾…åŠ©çš„ç‰©è”ç½‘ç½‘ç»œå®šä½",
      "authors": [
        "Sunwoo Kim"
      ],
      "abstract": "In this paper, we propose a deep learning and matrix completion aided approach for recovering an outlier contaminated Euclidean distance matrix D in IoT network localization. Unlike conventional localization techniques that search the solution over a whole set of matrices, the proposed technique restricts the search to the set of Euclidean distance matrices. Specifically, we express D as a function of the sensor coordinate matrix X that inherently satisfies the unique properties of D, and then jointly recover D and X using a deep neural network. To handle outliers effectively, we model them as a sparse matrix L and add a regularization term of L into the optimization problem. We then solve the problem by alternately updating X, D, and L. Numerical experiments demonstrate that the proposed technique can recover the location information of sensors accurately even in the presence of outliers.",
      "tldr_zh": "è¯¥ç ”ç©¶é’ˆå¯¹ç‰©è”ç½‘(IoT)ç½‘ç»œå®šä½ä¸­å—ç¦»ç¾¤ç‚¹(Outliers)å¹²æ‰°çš„æ¬§å‡ é‡Œå¾—è·ç¦»çŸ©é˜µ(Euclidean distance matrix) $D$ çš„æ¢å¤é—®é¢˜ï¼Œæå‡ºäº†ä¸€ç§ç»“åˆæ·±åº¦å­¦ä¹ (Deep Learning)ä¸çŸ©é˜µè¡¥å…¨(Matrix Completion)çš„å®šä½æ–¹æ³•ã€‚è¯¥æŠ€æœ¯é€šè¿‡å°†æœç´¢ç©ºé—´é™åˆ¶åœ¨æ¬§å‡ é‡Œå¾—è·ç¦»çŸ©é˜µé›†åˆå†…ï¼Œå¹¶åˆ©ç”¨æ·±åº¦ç¥ç»ç½‘ç»œ(Deep Neural Network)å°† $D$ å»ºæ¨¡ä¸ºä¼ æ„Ÿå™¨åæ ‡çŸ©é˜µ $X$ çš„å‡½æ•°ï¼Œå®ç°äº†å¯¹ $D$ å’Œ $X$ çš„è”åˆæ¢å¤ã€‚ä¸ºæœ‰æ•ˆåº”å¯¹å¼‚å¸¸æ•°æ®ï¼Œç ”ç©¶å°†ç¦»ç¾¤ç‚¹å»ºæ¨¡ä¸ºç¨€ç–çŸ©é˜µ(Sparse Matrix) $L$ å¹¶å¼•å…¥æ­£åˆ™åŒ–é¡¹ï¼Œé€šè¿‡äº¤æ›¿æ›´æ–° $X$ã€$D$ å’Œ $L$ çš„ä¼˜åŒ–ç­–ç•¥æé«˜äº†å®šä½è¿‡ç¨‹çš„ç¨³å¥æ€§ã€‚æ•°å€¼å®éªŒç»“æœè¯æ˜ï¼Œè¯¥æŠ€æœ¯å³ä½¿åœ¨å¤æ‚çš„ç¦»ç¾¤ç‚¹å¹²æ‰°åœºæ™¯ä¸‹ä¹Ÿèƒ½ç²¾ç¡®è·å–ä¼ æ„Ÿå™¨çš„ä½ç½®ä¿¡æ¯ï¼Œä¸ºé«˜å¯é æ€§çš„IoTå®šä½ç³»ç»Ÿæä¾›äº†ç†è®ºæ”¯æŒã€‚",
      "categories": [
        "cs.LG",
        "cs.AI",
        "cs.IT"
      ],
      "primary_category": "cs.LG",
      "comment": "4 pages, 2 figures",
      "pdf_url": "https://arxiv.org/pdf/2508.18225v1",
      "published_date": "2025-08-17 03:54:14 UTC",
      "updated_date": "2025-08-17 03:54:14 UTC",
      "processing_status": "completed",
      "attempts": 1,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "llm_backup_calls": 0,
      "last_update": "2026-01-24T12:26:45.090588+00:00"
    },
    {
      "arxiv_id": "2508.14918v1",
      "title": "Disentangling the Drivers of LLM Social Conformity: An Uncertainty-Moderated Dual-Process Mechanism",
      "title_zh": "å˜æ¸…å¤§è¯­è¨€æ¨¡å‹ç¤¾ä¼šä»ä¼—çš„é©±åŠ¨å› ç´ ï¼šä¸€ç§ç”±ä¸ç¡®å®šæ€§è°ƒèŠ‚çš„åŒåŠ å·¥æœºåˆ¶",
      "authors": [
        "Huixin Zhong",
        "Yanan Liu",
        "Qi Cao",
        "Shijin Wang",
        "Zijing Ye",
        "Zimu Wang",
        "Shiyao Zhang"
      ],
      "abstract": "As large language models (LLMs) integrate into collaborative teams, their social conformity -- the tendency to align with majority opinions -- has emerged as a key concern. In humans, conformity arises from informational influence (rational use of group cues for accuracy) or normative influence (social pressure for approval), with uncertainty moderating this balance by shifting from purely analytical to heuristic processing. It remains unclear whether these human psychological mechanisms apply to LLMs. This study adapts the information cascade paradigm from behavioral economics to quantitatively disentangle the two drivers to investigate the moderate effect. We evaluated nine leading LLMs across three decision-making scenarios (medical, legal, investment), manipulating information uncertainty (q = 0.667, 0.55, and 0.70, respectively). Our results indicate that informational influence underpins the models' behavior across all contexts, with accuracy and confidence consistently rising with stronger evidence. However, this foundational mechanism is dramatically modulated by uncertainty. In low-to-medium uncertainty scenarios, this informational process is expressed as a conservative strategy, where LLMs systematically underweight all evidence sources. In contrast, high uncertainty triggers a critical shift: while still processing information, the models additionally exhibit a normative-like amplification, causing them to overweight public signals (beta > 1.55 vs. private beta = 0.81).",
      "tldr_zh": "è¯¥ç ”ç©¶æ¢è®¨äº†å¤§è¯­è¨€æ¨¡å‹(LLMs)åœ¨å›¢é˜Ÿåä½œä¸­çš„ç¤¾ä¼šä»ä¼—(Social Conformity)è¡Œä¸ºï¼Œå³æ¨¡å‹å€¾å‘äºä¸å¤šæ•°äººæ„è§ä¿æŒä¸€è‡´çš„å€¾å‘ã€‚ç ”ç©¶å€Ÿé‰´è¡Œä¸ºç»æµå­¦ä¸­çš„ä¿¡æ¯çº§è”èŒƒå¼(Information Cascade Paradigm)ï¼Œæ—¨åœ¨å®šé‡è§£æä¿¡æ¯æ€§å½±å“(Informational Influence)ä¸è§„èŒƒæ€§å½±å“(Normative Influence)å¯¹æ¨¡å‹è¡Œä¸ºçš„é©±åŠ¨ä½œç”¨ï¼Œå¹¶é‡ç‚¹è€ƒå¯Ÿäº†ä¸ç¡®å®šæ€§(Uncertainty)çš„è°ƒèŠ‚æ•ˆåº”ã€‚é€šè¿‡å¯¹ä¹ç§é¢†å…ˆçš„å¤§è¯­è¨€æ¨¡å‹åœ¨åŒ»ç–—ã€æ³•å¾‹å’ŒæŠ•èµ„åœºæ™¯ä¸‹çš„è¯„ä¼°ï¼Œç»“æœæ˜¾ç¤ºä¿¡æ¯æ€§å½±å“æ„æˆäº†æ¨¡å‹è¡Œä¸ºçš„åŸºç¡€ï¼Œä¸”å…¶å‡†ç¡®æ€§å’Œç½®ä¿¡åº¦éšè¯æ®å¢å¼ºè€Œæå‡ã€‚ç„¶è€Œï¼Œè¿™ä¸€åŸºç¡€æœºåˆ¶å—åˆ°ä¸ç¡®å®šæ€§çš„æ˜¾è‘—è°ƒèŠ‚ï¼šåœ¨ä½ä¸­åº¦ä¸ç¡®å®šæ€§åœºæ™¯ä¸‹ï¼Œæ¨¡å‹è¡¨ç°å‡ºä½ä¼°æ‰€æœ‰è¯æ®çš„ä¿å®ˆç­–ç•¥ï¼›è€Œåœ¨é«˜ä¸ç¡®å®šæ€§ä¸‹ï¼Œæ¨¡å‹ä¼šè§¦å‘ç±»ä¼¼äºè§„èŒƒæ€§å½±å“çš„æ”¾å¤§æ•ˆåº”ï¼Œå¯¼è‡´å…¶è¿‡åº¦åŠ æƒå¤–éƒ¨å…¬å¼€ä¿¡å·ã€‚è¯¥ç ”ç©¶æ­ç¤ºäº†LLMsåœ¨ç¤¾ä¼šå½±å“ä¸‹çš„ä¸ç¡®å®šæ€§è°ƒèŠ‚åŒè¿‡ç¨‹æœºåˆ¶(Dual-Process Mechanism)ï¼Œä¸ºç†è§£äººå·¥æ™ºèƒ½åœ¨ç¾¤ä½“å†³ç­–ä¸­çš„å¤æ‚å¿ƒç†æ¨¡æ‹Ÿæä¾›äº†ç§‘å­¦ä¾æ®ã€‚",
      "categories": [
        "cs.CY",
        "cs.AI"
      ],
      "primary_category": "cs.CY",
      "comment": "",
      "pdf_url": "https://arxiv.org/pdf/2508.14918v1",
      "published_date": "2025-08-17 03:53:55 UTC",
      "updated_date": "2025-08-17 03:53:55 UTC",
      "processing_status": "completed",
      "attempts": 1,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "llm_backup_calls": 0,
      "last_update": "2026-01-24T12:26:43.194849+00:00"
    },
    {
      "arxiv_id": "2508.12222v1",
      "title": "Distribution Matching via Generalized Consistency Models",
      "title_zh": "åŸºäºå¹¿ä¹‰ä¸€è‡´æ€§æ¨¡å‹çš„åˆ†å¸ƒåŒ¹é…",
      "authors": [
        "Sagar Shrestha",
        "Rajesh Shrestha",
        "Tri Nguyen",
        "Subash Timilsina"
      ],
      "abstract": "Recent advancement in generative models have demonstrated remarkable performance across various data modalities. Beyond their typical use in data synthesis, these models play a crucial role in distribution matching tasks such as latent variable modeling, domain translation, and domain adaptation. Generative Adversarial Networks (GANs) have emerged as the preferred method of distribution matching due to their efficacy in handling high-dimensional data and their flexibility in accommodating various constraints. However, GANs often encounter challenge in training due to their bi-level min-max optimization objective and susceptibility to mode collapse. In this work, we propose a novel approach for distribution matching inspired by the consistency models employed in Continuous Normalizing Flow (CNF). Our model inherits the advantages of CNF models, such as having a straight forward norm minimization objective, while remaining adaptable to different constraints similar to GANs. We provide theoretical validation of our proposed objective and demonstrate its performance through experiments on synthetic and real-world datasets.",
      "tldr_zh": "è¯¥ç ”ç©¶é’ˆå¯¹ç”Ÿæˆæ¨¡å‹åœ¨åˆ†å¸ƒåŒ¹é…(Distribution Matching)ä»»åŠ¡ä¸­é¢ä¸´çš„æŒ‘æˆ˜ï¼ŒæŒ‡å‡ºä¼ ç»Ÿçš„ç”Ÿæˆå¯¹æŠ—ç½‘ç»œ(GANs)è™½ç„¶æœ‰æ•ˆï¼Œä½†å­˜åœ¨åŒå±‚æå°æå¤§ä¼˜åŒ–(min-max optimization)ä¸ç¨³å®šå’Œæ¨¡å¼å´©æºƒ(mode collapse)ç­‰è®­ç»ƒéš¾é¢˜ã€‚ä¸ºæ­¤ï¼Œä½œè€…æå‡ºäº†ä¸€ç§å—è¿ç»­å½’ä¸€åŒ–æµ(Continuous Normalizing Flow, CNF)ä¸­çš„ä¸€è‡´æ€§æ¨¡å‹(Consistency Models)å¯å‘çš„æ–°å‹åˆ†å¸ƒåŒ¹é…æ–¹æ³•ã€‚è¯¥æ¨¡å‹ç»“åˆäº†CNFçš„ä¼˜åŠ¿ï¼Œé‡‡ç”¨ç›´è§‚çš„èŒƒæ•°æœ€å°åŒ–(norm minimization)ä½œä¸ºä¼˜åŒ–ç›®æ ‡ï¼ŒåŒæ—¶ä¿æŒäº†ç±»ä¼¼GANsçš„çµæ´»æ€§ä»¥é€‚åº”ä¸åŒçš„ä»»åŠ¡çº¦æŸã€‚ç ”ç©¶å›¢é˜Ÿå¯¹æ‰€æç›®æ ‡å‡½æ•°è¿›è¡Œäº†ç†è®ºéªŒè¯ï¼Œå¹¶é€šè¿‡åœ¨åˆæˆæ•°æ®é›†å’ŒçœŸå®ä¸–ç•Œæ•°æ®é›†ä¸Šçš„å®éªŒå±•ç¤ºäº†å…¶æ€§èƒ½ã€‚è¯¥æ–¹æ³•åœ¨æ½œåœ¨å˜é‡å»ºæ¨¡ã€é¢†åŸŸè½¬æ¢(Domain Translation)å’Œé¢†åŸŸè‡ªé€‚åº”(Domain Adaptation)ç­‰ä»»åŠ¡ä¸­è¡¨ç°ä¼˜å¼‚ï¼Œä¸ºé«˜ç»´æ•°æ®çš„åˆ†å¸ƒåŒ¹é…æä¾›äº†ä¸€ç§æ›´ç¨³å®šä¸”é«˜æ•ˆçš„æ›¿ä»£æ–¹æ¡ˆã€‚",
      "categories": [
        "cs.LG",
        "cs.AI"
      ],
      "primary_category": "cs.LG",
      "comment": "",
      "pdf_url": "https://arxiv.org/pdf/2508.12222v1",
      "published_date": "2025-08-17 03:37:57 UTC",
      "updated_date": "2025-08-17 03:37:57 UTC",
      "processing_status": "completed",
      "attempts": 1,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "llm_backup_calls": 0,
      "last_update": "2026-01-24T12:26:41.186597+00:00"
    },
    {
      "arxiv_id": "2508.12220v1",
      "title": "Unlearning at Scale: Implementing the Right to be Forgotten in Large Language Models",
      "title_zh": "å¤§è§„æ¨¡æœºå™¨é—å¿˜ï¼šåœ¨å¤§è¯­è¨€æ¨¡å‹ä¸­å®ç°è¢«é—å¿˜æƒ",
      "authors": [
        "Abdullah X"
      ],
      "abstract": "We study the right to be forgotten (GDPR Art. 17) for large language models and frame unlearning as a reproducible systems problem. Our approach treats training as a deterministic program and logs a minimal per-microbatch record (ordered ID hash, RNG seed, learning-rate value, optimizer-step counter, and accumulation boundary). Under a pinned stack and deterministic kernels, replaying the training tail while filtering only the forget closure yields the same parameters as training on the retain set (bit-identical in the training dtype) when preconditions hold. To meet latency and availability constraints, we add complementary paths: (i) exact reverts of recent steps via micro-checkpoints or dense per-step deltas, (ii) cohort-scoped adapter deletion when the base is frozen, and (iii) a curvature-guided anti-update followed by a short retain-tune, audit-gated with escalation to exact replay. We report storage/latency budgets and a toy artifact validating mechanics; in a controlled run that satisfies the preconditions we demonstrate byte-identical equality of model and optimizer states.",
      "tldr_zh": "è¯¥ç ”ç©¶æ¢è®¨äº†å¤§å‹è¯­è¨€æ¨¡å‹(Large Language Models, LLMs)ä¸­çš„â€œè¢«é—å¿˜æƒâ€(Right to be Forgotten)ï¼Œå°†å…¶å®šä¹‰ä¸ºä¸€ä¸ªå¯å¤åˆ¶çš„ç³»ç»Ÿå·¥ç¨‹é—®é¢˜ã€‚ç ”ç©¶è€…å°†è®­ç»ƒè¿‡ç¨‹è§†ä¸ºç¡®å®šæ€§ç¨‹åºï¼Œé€šè¿‡è®°å½•åŒ…å«å“ˆå¸Œå€¼ã€RNG seedã€å­¦ä¹ ç‡å’Œä¼˜åŒ–å™¨æ­¥éª¤ç­‰ä¿¡æ¯çš„æœ€å°åŒ–å¾®æ‰¹æ¬¡(Microbatch)æ—¥å¿—ï¼Œå®ç°äº†å¯¹è®­ç»ƒè¿‡ç¨‹çš„ç²¾ç¡®é‡æ„ã€‚åœ¨ç¡®å®šæ€§å†…æ ¸ç¯å¢ƒä¸‹ï¼Œé€šè¿‡å›æ”¾(Replay)è®­ç»ƒå°¾éƒ¨å¹¶è¿‡æ»¤â€œé—å¿˜é—­åŒ…â€(Forget Closure)ï¼Œå¯ä»¥è·å¾—ä¸åœ¨ä¿ç•™é›†ä¸Šè®­ç»ƒå®Œå…¨ä¸€è‡´çš„å‚æ•°ã€‚æ­¤å¤–ï¼Œè¯¥æ–¹æ¡ˆè¿˜æä¾›äº†åŸºäºå¾®æ£€æŸ¥ç‚¹(Micro-checkpoints)çš„ç²¾ç¡®æ’¤å›ã€é€‚é…å™¨(Adapter)åˆ é™¤ä»¥åŠæ›²ç‡å¼•å¯¼çš„æŠ—æ›´æ–°(Curvature-guided anti-update)ç­‰è¡¥å……è·¯å¾„ä»¥ä¼˜åŒ–å»¶è¿Ÿã€‚å®éªŒéªŒè¯è¡¨æ˜ï¼Œåœ¨æ»¡è¶³å‰ææ¡ä»¶ä¸‹ï¼Œè¯¥ç³»ç»Ÿèƒ½å¤Ÿå®ç°æ¨¡å‹å’Œä¼˜åŒ–å™¨çŠ¶æ€çš„å­—èŠ‚çº§ç­‰ä»·(Byte-identical equality)ï¼Œä¸ºå¤§è§„æ¨¡æ¨¡å‹åˆè§„é—å¿˜æä¾›äº†ç³»ç»Ÿæ€§çš„æŠ€æœ¯æ”¯æ’‘ã€‚",
      "categories": [
        "cs.LG",
        "cs.AI",
        "cs.CR"
      ],
      "primary_category": "cs.LG",
      "comment": "Preprint; 2 figures + several tables; includes appendix. Artifact/code link in paper",
      "pdf_url": "https://arxiv.org/pdf/2508.12220v1",
      "published_date": "2025-08-17 03:29:22 UTC",
      "updated_date": "2025-08-17 03:29:22 UTC",
      "processing_status": "completed",
      "attempts": 1,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "llm_backup_calls": 0,
      "last_update": "2026-01-24T12:26:48.986222+00:00"
    },
    {
      "arxiv_id": "2508.12213v1",
      "title": "Towards Generalizable Human Activity Recognition: A Survey",
      "title_zh": "è¿ˆå‘å¯æ³›åŒ–çš„äººä½“æ´»åŠ¨è¯†åˆ«ï¼šç»¼è¿°",
      "authors": [
        "Yize Cai",
        "Baoshen Guo",
        "Flora Salim",
        "Zhiqing Hong"
      ],
      "abstract": "As a critical component of Wearable AI, IMU-based Human Activity Recognition (HAR) has attracted increasing attention from both academia and industry in recent years. Although HAR performance has improved considerably in specific scenarios, its generalization capability remains a key barrier to widespread real-world adoption. For example, domain shifts caused by variations in users, sensor positions, or environments can significantly decrease the performance in practice. As a result, in this survey, we explore the rapidly evolving field of IMU-based generalizable HAR, reviewing 229 research papers alongside 25 publicly available datasets to provide a broad and insightful overview. We first present the background and overall framework of IMU-based HAR tasks, as well as the generalization-oriented training settings. Then, we categorize representative methodologies from two perspectives: (i) model-centric approaches, including pre-training method, end-to-end method, and large language model (LLM)-based learning method; and (ii) data-centric approaches, including multi-modal learning and data augmentation techniques. In addition, we summarize widely used datasets in this field, as well as relevant tools and benchmarks. Building on these methodological advances, the broad applicability of IMU-based HAR is also reviewed and discussed. Finally, we discuss persistent challenges (e.g., data scarcity, efficient training, and reliable evaluation) and also outline future directions for HAR, including the adoption of foundation and large language models, physics-informed and context-aware reasoning, generative modeling, and resource-efficient training and inference. The complete list of this survey is available at https://github.com/rh20624/Awesome-IMU-Sensing, which will be updated continuously.",
      "tldr_zh": "è¯¥ç»¼è¿°æ·±å…¥æ¢è®¨äº†åŸºäºIMUçš„äººä½“æ´»åŠ¨è¯†åˆ«(Human Activity Recognition, HAR)é¢†åŸŸï¼Œé‡ç‚¹å…³æ³¨å…¶åœ¨å®é™…åº”ç”¨ä¸­å› ç”¨æˆ·ã€ä¼ æ„Ÿå™¨ä½ç½®å’Œç¯å¢ƒå·®å¼‚å¼•å‘çš„é¢†åŸŸåç§»(Domain shifts)è€Œå¯¼è‡´çš„æ³›åŒ–æ€§ç“¶é¢ˆã€‚æ–‡ç« ç³»ç»Ÿå›é¡¾äº†229ç¯‡ç ”ç©¶è®ºæ–‡å’Œ25ä¸ªå…¬å¼€æ•°æ®é›†ï¼Œæ„å»ºäº†é¢å‘æ³›åŒ–HARä»»åŠ¡çš„æ•´ä½“æ¡†æ¶å’Œè®­ç»ƒè®¾ç½®ã€‚ç ”ç©¶ä»æ¨¡å‹ä¸­å¿ƒ(Model-centric)è§’åº¦æ€»ç»“äº†é¢„è®­ç»ƒ(Pre-training)ã€ç«¯åˆ°ç«¯æ–¹æ³•åŠåŸºäºå¤§è¯­è¨€æ¨¡å‹(LLM)çš„å­¦ä¹ ç­–ç•¥ï¼Œå¹¶ä»æ•°æ®ä¸­å¿ƒ(Data-centric)è§’åº¦åˆ†æäº†å¤šæ¨¡æ€å­¦ä¹ (Multi-modal learning)ä¸æ•°æ®å¢å¼ºæŠ€æœ¯ã€‚æ­¤å¤–ï¼Œç»¼è¿°æ±‡æ€»äº†ä¸»æµæ•°æ®é›†ã€è¯„ä¼°å·¥å…·åŠåŸºå‡†æµ‹è¯•ï¼Œå¹¶è®¨è®ºäº†è¯¥æŠ€æœ¯çš„å¹¿æ³›é€‚ç”¨æ€§ã€‚æœ€åï¼Œä½œè€…æŒ‡å‡ºäº†æ•°æ®ç¨€ç¼ºå’Œèµ„æºé«˜æ•ˆè®­ç»ƒç­‰æŒ‘æˆ˜ï¼Œå¹¶å±•æœ›äº†åŸºç¡€æ¨¡å‹(Foundation Models)ã€ç‰©ç†å¯å‘(Physics-informed)ä¸ä¸Šä¸‹æ–‡æ„ŸçŸ¥æ¨ç†åŠç”Ÿæˆå¼å»ºæ¨¡(Generative modeling)ç­‰æœªæ¥å‘å±•æ–¹å‘ã€‚",
      "categories": [
        "eess.SP",
        "cs.AI",
        "cs.LG"
      ],
      "primary_category": "eess.SP",
      "comment": "",
      "pdf_url": "https://arxiv.org/pdf/2508.12213v1",
      "published_date": "2025-08-17 03:04:39 UTC",
      "updated_date": "2025-08-17 03:04:39 UTC",
      "processing_status": "completed",
      "attempts": 1,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "llm_backup_calls": 0,
      "last_update": "2026-01-24T12:26:55.966822+00:00"
    },
    {
      "arxiv_id": "2508.12212v1",
      "title": "ProtTeX-CC: Activating In-Context Learning in Protein LLM via Two-Stage Instruction Compression",
      "title_zh": "ProtTeX-CCï¼šé€šè¿‡åŒé˜¶æ®µæŒ‡ä»¤å‹ç¼©æ¿€æ´»è›‹ç™½è´¨å¤§è¯­è¨€æ¨¡å‹ä¸­çš„ä¸Šä¸‹æ–‡å­¦ä¹ ",
      "authors": [
        "Chuanliu Fan",
        "Zicheng Ma",
        "Jun Gao",
        "Nan Yu",
        "Jun Zhang",
        "Ziqiang Cao",
        "Yi Qin Gao",
        "Guohong Fu"
      ],
      "abstract": "Recent advances in protein large language models, such as ProtTeX, represent both side-chain amino acids and backbone structure as discrete token sequences of residue length. While this design enables unified modeling of multimodal protein information, it suffers from two major limitations: (1) The concatenation of sequence and structure tokens approximately doubles the protein length and breaks the intrinsic residue-level alignment between modalities. (2) Constrained by the training corpus and limited context window, ProtTeX is typically trained on single-protein inputs, rendering it incompatible with in-context learning (ICL) and thus limiting its generalization capability. To address these issues, we propose ProtTeX-CC, a lightweight two-stage compression framework designed to enhance ProtTeX under few-shot settings. We first design a joint embedding compression mechanism that fuses sequence and structure representations at the residue level, effectively reducing the protein input length by half without sacrificing performance. Then we propose a self-compression module that aggregates each full demonstration into the latent space of the last few linguistic tokens, reducing the average demonstration length from 751 tokens to less than 16 tokens. Compared to the original ProtTeX, our self-compression approach achieves a compression ratio of approximately 93.68% in the total prompt length under the 16-shot setting. Without modifying the backbone model, ProtTeX-CC introduces only a small number of additional parameters through PEFT-based tuning in the joint embedding compression stage and a single trainable projection layer in the self-compression stage. Extensive experiments on protein function prediction show that ProtTeX-CC improves performance on the in-domain benchmark by 2%, and generalizes well to the out-of-domain dataset with a performance gain of 11%.",
      "tldr_zh": "è¯¥ç ”ç©¶æå‡ºäº† ProtTeX-CCï¼Œä¸€ç§è½»é‡çº§çš„ä¸¤é˜¶æ®µå‹ç¼©æ¡†æ¶ï¼Œæ—¨åœ¨è§£å†³è›‹ç™½è´¨å¤§è¯­è¨€æ¨¡å‹ ProtTeX å› åºåˆ—ä¸ç»“æ„æ‹¼æ¥å¯¼è‡´çš„è¾“å…¥è¿‡é•¿ã€æ¨¡æ€å¯¹é½å—æŸåŠç¼ºä¹ä¸Šä¸‹æ–‡å­¦ä¹ (In-Context Learning, ICL)èƒ½åŠ›ç­‰é—®é¢˜ã€‚æ¡†æ¶çš„ç¬¬ä¸€é˜¶æ®µé‡‡ç”¨è”åˆåµŒå…¥å‹ç¼©æœºåˆ¶(joint embedding compression)ï¼Œåœ¨æ®‹åŸºæ°´å¹³èåˆåºåˆ—ä¸ç»“æ„è¡¨ç¤ºï¼Œåœ¨ä¸æŸå¤±æ€§èƒ½çš„å‰æä¸‹å°†è¾“å…¥é•¿åº¦å‡åŠã€‚ç¬¬äºŒé˜¶æ®µé€šè¿‡è‡ªå‹ç¼©æ¨¡å—(self-compression module)å°†é•¿ç¤ºä¾‹æ–‡æœ¬èšåˆè‡³æå°‘é‡çš„è¯­è¨€æ ‡è®°(linguistic tokens)ä¸­ï¼Œåœ¨ 16-shot è®¾ç½®ä¸‹å®ç°äº† 93.68% çš„æç¤ºè¯é•¿åº¦å‹ç¼©ã€‚è¯¥æ–¹æ¡ˆåˆ©ç”¨å‚æ•°é«˜æ•ˆå¾®è°ƒ(PEFT)æŠ€æœ¯ï¼Œä»…éœ€å¼•å…¥æå°‘é‡é¢å¤–å‚æ•°å³å¯æœ‰æ•ˆæ¿€æ´»æ¨¡å‹çš„ ICL èƒ½åŠ›å¹¶å¢å¼ºå…¶æ³›åŒ–æ€§ã€‚å®éªŒè¯æ˜ï¼ŒProtTeX-CC åœ¨è›‹ç™½è´¨åŠŸèƒ½é¢„æµ‹ä»»åŠ¡ä¸­ä½¿åŸŸå†…åŸºå‡†æ€§èƒ½æå‡äº† 2%ï¼Œå¹¶åœ¨åŸŸå¤–æ•°æ®é›†ä¸Šå®ç°äº† 11% çš„æ˜¾è‘—æ€§èƒ½å¢ç›Šã€‚",
      "categories": [
        "cs.LG",
        "cs.AI",
        "q-bio.QM"
      ],
      "primary_category": "cs.LG",
      "comment": "",
      "pdf_url": "https://arxiv.org/pdf/2508.12212v1",
      "published_date": "2025-08-17 03:03:56 UTC",
      "updated_date": "2025-08-17 03:03:56 UTC",
      "processing_status": "completed",
      "attempts": 1,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "llm_backup_calls": 0,
      "last_update": "2026-01-24T12:27:01.951019+00:00"
    },
    {
      "arxiv_id": "2508.12211v2",
      "title": "Improving Pre-Trained Vision-Language-Action Policies with Model-Based Search",
      "title_zh": "é€šè¿‡åŸºäºæ¨¡å‹çš„æœç´¢æå‡é¢„è®­ç»ƒè§†è§‰-è¯­è¨€-åŠ¨ä½œç­–ç•¥",
      "authors": [
        "Cyrus Neary",
        "Omar G. Younis",
        "Artur Kuramshin",
        "Ozgur Aslan",
        "Glen Berseth"
      ],
      "abstract": "Pre-trained vision-language-action (VLA) models offer a promising foundation for generalist robot policies, but often produce brittle behaviors or unsafe failures when deployed zero-shot in out-of-distribution scenarios. We present Vision-Language-Action Planning & Search (VLAPS) -- a novel framework and accompanying algorithms that embed model-based search into the inference procedure of pre-trained VLA policies to improve their performance on robotic tasks. Specifically, our method biases a modified Monte Carlo Tree Search (MCTS) algorithm -- run using a model of the target environment -- using action priors defined by the VLA policy. By using VLA-derived abstractions and priors in model-based search, VLAPS efficiently explores language-conditioned robotics tasks whose search spaces would otherwise be intractably large. Conversely, by integrating model-based search with the VLA policy's inference procedure, VLAPS yields behaviors that are more performant than those obtained by directly following the VLA policy's action predictions. VLAPS offers a principled framework to: i) control test-time compute in VLA models, ii) leverage a priori knowledge of the robotic environment, and iii) integrate established planning and reinforcement learning techniques into the VLA inference process. Across all experiments, VLAPS significantly outperforms VLA-only baselines on language-specified tasks that would otherwise be intractable for uninformed search algorithms, increasing success rates by as much as 67 percentage points.",
      "tldr_zh": "è¯¥ç ”ç©¶æå‡ºäº† Vision-Language-Action Planning & Search (VLAPS)ï¼Œæ—¨åœ¨è§£å†³é¢„è®­ç»ƒè§†è§‰-è¯­è¨€-åŠ¨ä½œ (VLA) æ¨¡å‹åœ¨åˆ†å¸ƒå¤–åœºæ™¯ä¸­è¡¨ç°å‡ºçš„è¡Œä¸ºè„†å¼±å’Œå®‰å…¨æ€§ä¸è¶³ç­‰é—®é¢˜ã€‚VLAPS æ˜¯ä¸€ç§å°†åŸºäºæ¨¡å‹çš„æœç´¢ (Model-Based Search) åµŒå…¥ VLA ç­–ç•¥æ¨ç†è¿‡ç¨‹çš„æ–°å‹æ¡†æ¶ï¼Œé€šè¿‡ VLA ç­–ç•¥æä¾›çš„åŠ¨ä½œå…ˆéªŒå’ŒæŠ½è±¡æ¥å¼•å¯¼æ”¹è¿›çš„è’™ç‰¹å¡æ´›æ ‘æœç´¢ (MCTS) ç®—æ³•ã€‚è¯¥æ–¹æ³•èƒ½å¤Ÿæœ‰æ•ˆç¼©å‡è¯­è¨€æ¡ä»¶æœºå™¨äººä»»åŠ¡ä¸­åŸæœ¬åºå¤§çš„æœç´¢ç©ºé—´ï¼Œä»è€Œåœ¨æ¨ç†é˜¶æ®µäº§ç”Ÿæ¯”åŸå§‹ VLA é¢„æµ‹æ›´ç¨³å¥ä¸”é«˜æ•ˆçš„è¡Œä¸ºã€‚VLAPS ä¸ºæ§åˆ¶ VLA æ¨¡å‹çš„æµ‹è¯•æ—¶è®¡ç®— (Test-Time Compute) ä»¥åŠæ•´åˆç°æœ‰è§„åˆ’ä¸å¼ºåŒ–å­¦ä¹  (RL) æŠ€æœ¯æä¾›äº†ä¸€ä¸ªåŸåˆ™æ€§çš„æ¡†æ¶ã€‚å®éªŒè¯æ˜ï¼Œåœ¨å¤„ç†å¤æ‚çš„è¯­è¨€æŒ‡ä»¤ä»»åŠ¡æ—¶ï¼ŒVLAPS ç›¸æ¯”äºå•çº¯çš„ VLA åŸºå‡†æ¨¡å‹æ˜¾è‘—æå‡äº†ä»»åŠ¡æˆåŠŸç‡ï¼Œæœ€é«˜æ¶¨å¹…è¾¾ 67 ä¸ªç™¾åˆ†ç‚¹ã€‚",
      "categories": [
        "cs.RO",
        "cs.AI"
      ],
      "primary_category": "cs.RO",
      "comment": "",
      "pdf_url": "https://arxiv.org/pdf/2508.12211v2",
      "published_date": "2025-08-17 02:59:42 UTC",
      "updated_date": "2025-11-12 21:30:47 UTC",
      "processing_status": "completed",
      "attempts": 1,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "llm_backup_calls": 0,
      "last_update": "2026-01-24T12:27:01.750568+00:00"
    },
    {
      "arxiv_id": "2508.12198v1",
      "title": "Exploring Multimodal AI Reasoning for Meteorological Forecasting from Skew-T Diagrams",
      "title_zh": "åŸºäº Skew-T å›¾çš„å¤šæ¨¡æ€äººå·¥æ™ºèƒ½æ°”è±¡é¢„æŠ¥æ¨ç†æ¢ç´¢",
      "authors": [
        "ChangJae Lee",
        "Heecheol Yang",
        "Jonghak Choi"
      ],
      "abstract": "Forecasting from atmospheric soundings is a fundamental task in operational meteorology, often requiring structured visual reasoning over Skew-T log-P diagrams by human forecasters. While recent advances in Vision-Language Models (VLMs) have shown promise in other scientific domains, their application to meteorological diagram interpretation remains largely unexplored. In this study, we present a lightweight AI assistant that interprets Skew-T diagrams using a small language model (LM) and a small VLM fine-tuned to emulate human forecasters. Using a curriculum learning framework, we first train the models to identify key atmospheric features from diagrams through visual question answering, followed by chain-of-thought reasoning tasks that estimate precipitation probability based on the derived visual groundings. Model inputs include either textual summaries or generated Skew-T diagrams derived from operational Numerical Weather Prediction (NWP) forecasts, paired with three-hour precipitation observations from South Korea's Auto Weather Stations network. Evaluation results demonstrate that the fine-tuned VLM achieves skill comparable to an operational NWP model, despite relying solely on static atmospheric profiles. Ablation studies reveal that visual grounding and reasoning supervision are critical for performance, while attention map analysis confirms that the model learns to focus on relevant meteorological features. These findings highlight the potential of compact, interpretable multimodal models to support weather forecasting tasks. The approach offers a computationally efficient alternative to large-scale systems, and future work could extend it to more complex applications.",
      "tldr_zh": "è¯¥ç ”ç©¶æ¢è®¨äº†åˆ©ç”¨å¤šæ¨¡æ€AIå¯¹Skew-Tå¯¹æ•°På›¾è¿›è¡Œæ°”è±¡é¢„æŠ¥æ¨ç†çš„æ–¹æ³•ï¼Œæ—¨åœ¨æ¨¡ä»¿äººç±»é¢„æŠ¥å‘˜çš„è§†è§‰æ¨ç†è¿‡ç¨‹ã€‚ç ”ç©¶å›¢é˜Ÿå¼€å‘äº†ä¸€ä¸ªç”±å°å‹è¯­è¨€æ¨¡å‹(LM)å’Œç»è¿‡å¾®è°ƒçš„å°å‹è§†è§‰è¯­è¨€æ¨¡å‹(VLM)ç»„æˆçš„è½»é‡çº§AIåŠ©æ‰‹ã€‚è¯¥åŠ©æ‰‹é‡‡ç”¨è¯¾ç¨‹å­¦ä¹ (Curriculum Learning)æ¡†æ¶ï¼Œé€šè¿‡è§†è§‰é—®ç­”è¯†åˆ«å¤§æ°”ç‰¹å¾ï¼Œå¹¶ç»“åˆé“¾å¼æ€ç»´(Chain-of-Thought)æ¨ç†æ¥é¢„æµ‹é™æ°´æ¦‚ç‡ã€‚å®éªŒåˆ©ç”¨éŸ©å›½è‡ªåŠ¨æ°”è±¡ç«™(Auto Weather Stations)çš„è§‚æµ‹æ•°æ®å’Œæ•°å€¼å¤©æ°”é¢„æŠ¥(NWP)æ•°æ®è¿›è¡ŒéªŒè¯ã€‚ç»“æœæ˜¾ç¤ºï¼Œå¾®è°ƒåçš„VLMåœ¨é¢„æŠ¥æŠ€èƒ½ä¸Šä¸ä¸šåŠ¡åŒ–NWPæ¨¡å‹ç›¸å½“ï¼Œä¸”æ¶ˆèå®éªŒè¯æ˜è§†è§‰å®šä½ä¸æ¨ç†ç›‘ç£æ˜¯æ€§èƒ½æå‡çš„å…³é”®ã€‚è¿™é¡¹å·¥ä½œå±•ç¤ºäº†ç´§å‡‘å‹ã€å¯è§£é‡Šçš„å¤šæ¨¡æ€æ¨¡å‹åœ¨è®¡ç®—æ•ˆç‡å’Œè¾…åŠ©å¤©æ°”é¢„æŠ¥ä»»åŠ¡æ–¹é¢çš„å·¨å¤§æ½œåŠ›ã€‚",
      "categories": [
        "physics.ao-ph",
        "cs.AI",
        "cs.LG"
      ],
      "primary_category": "physics.ao-ph",
      "comment": "24 pages, 3 figures, 9 tables",
      "pdf_url": "https://arxiv.org/pdf/2508.12198v1",
      "published_date": "2025-08-17 01:36:31 UTC",
      "updated_date": "2025-08-17 01:36:31 UTC",
      "processing_status": "completed",
      "attempts": 1,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "llm_backup_calls": 0,
      "last_update": "2026-01-24T12:27:04.864008+00:00"
    },
    {
      "arxiv_id": "2508.16636v1",
      "title": "Cognitive Decision Routing in Large Language Models: When to Think Fast, When to Think Slow",
      "title_zh": "å¤§è¯­è¨€æ¨¡å‹è®¤çŸ¥å†³ç­–è·¯ç”±ï¼šä½•æ—¶å¿«æ€è€ƒï¼Œä½•æ—¶æ…¢æ€è€ƒ",
      "authors": [
        "Y. Du",
        "C. Guo",
        "W. Wang",
        "G. Tang"
      ],
      "abstract": "Large Language Models (LLMs) face a fundamental challenge in deciding when to rely on rapid, intuitive responses versus engaging in slower, more deliberate reasoning. Inspired by Daniel Kahneman's dual-process theory and his insights on human cognitive biases, we propose a novel Cognitive Decision Routing (CDR) framework that dynamically determines the appropriate reasoning strategy based on query characteristics. Our approach addresses the current limitations where models either apply uniform reasoning depth or rely on computationally expensive methods for all queries. We introduce a meta-cognitive layer that analyzes query complexity through multiple dimensions: correlation strength between given information and required conclusions, domain boundary crossings, stakeholder multiplicity, and uncertainty levels. Through extensive experiments on diverse reasoning tasks, we demonstrate that CDR achieves superior performance while reducing computational costs by 34\\% compared to uniform deep reasoning approaches. Our framework shows particular strength in professional judgment tasks, achieving 23\\% improvement in consistency and 18\\% better accuracy on expert-level evaluations. This work bridges cognitive science principles with practical AI system design, offering a principled approach to adaptive reasoning in LLMs.",
      "tldr_zh": "è¯¥ç ”ç©¶æå‡ºäº†è®¤çŸ¥å†³ç­–è·¯ç”±æ¡†æ¶ (Cognitive Decision Routing, CDR)ï¼Œæ—¨åœ¨è§£å†³å¤§è¯­è¨€æ¨¡å‹ (LLMs) åœ¨å¿«é€Ÿç›´è§‰å“åº”ä¸æ…¢é€Ÿæ·±å±‚æ¨ç†ä¹‹é—´æƒè¡¡å†³ç­–çš„æŒ‘æˆ˜ï¼Œå…¶è®¾è®¡çµæ„Ÿæºè‡ªä¸¹å°¼å°”Â·å¡å°¼æ›¼çš„åŒé‡åŠ å·¥ç†è®º (dual-process theory)ã€‚è¯¥æ¡†æ¶é€šè¿‡å¼•å…¥å…ƒè®¤çŸ¥å±‚ (meta-cognitive layer)ï¼Œä»ä¿¡æ¯ç›¸å…³æ€§ã€é¢†åŸŸè¾¹ç•Œã€åˆ©ç›Šç›¸å…³è€…å¤šæ ·æ€§å’Œä¸ç¡®å®šæ€§æ°´å¹³ç­‰ç»´åº¦åˆ†ææŸ¥è¯¢å¤æ‚åº¦ï¼Œä»è€ŒåŠ¨æ€é€‰æ‹©æœ€åˆé€‚çš„æ¨ç†ç­–ç•¥ã€‚å®éªŒæ•°æ®è¯æ˜ï¼ŒCDR åœ¨æ˜¾è‘—æå‡æ¨ç†ä»»åŠ¡æ€§èƒ½çš„åŒæ—¶ï¼Œç›¸è¾ƒäºç»Ÿä¸€çš„æ·±å±‚æ¨ç†æ–¹æ³•é™ä½äº† 34% çš„è®¡ç®—æˆæœ¬ã€‚åœ¨ä¸“ä¸šåˆ¤æ–­ä»»åŠ¡ä¸­ï¼Œè¯¥æ–¹æ³•è¡¨ç°å‡ºæå¼ºçš„ä¼˜åŠ¿ï¼Œä½¿æ¨¡å‹çš„ä¸€è‡´æ€§æå‡äº† 23%ï¼Œä¸“å®¶çº§è¯„ä¼°å‡†ç¡®ç‡æé«˜äº† 18%ã€‚è¿™ä¸€ç ”ç©¶æˆåŠŸå°†è®¤çŸ¥ç§‘å­¦åŸç†åº”ç”¨äº AI ç³»ç»Ÿè®¾è®¡ï¼Œä¸ºå®ç° LLMs çš„è‡ªé€‚åº”æ¨ç†æä¾›äº†ä¸€ç§é«˜æ•ˆä¸”å…·å¤‡åŸåˆ™æ€§çš„æ–¹æ¡ˆã€‚",
      "categories": [
        "cs.CL",
        "cs.AI"
      ],
      "primary_category": "cs.CL",
      "comment": "6 pages",
      "pdf_url": "https://arxiv.org/pdf/2508.16636v1",
      "published_date": "2025-08-17 01:07:58 UTC",
      "updated_date": "2025-08-17 01:07:58 UTC",
      "processing_status": "completed",
      "attempts": 1,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "llm_backup_calls": 0,
      "last_update": "2026-01-24T12:27:03.254898+00:00"
    },
    {
      "arxiv_id": "2508.12189v1",
      "title": "Self-Guided Action Diffusion",
      "title_zh": "è‡ªå¼•å¯¼åŠ¨ä½œæ‰©æ•£",
      "authors": [
        "Rhea Malhotra",
        "Yuejiang Liu",
        "Chelsea Finn"
      ],
      "abstract": "Recent works have shown the promise of inference-time search over action samples for improving generative robot policies. In particular, optimizing cross-chunk coherence via bidirectional decoding has proven effective in boosting the consistency and reactivity of diffusion policies. However, this approach remains computationally expensive as the diversity of sampled actions grows. In this paper, we introduce self-guided action diffusion, a more efficient variant of bidirectional decoding tailored for diffusion-based policies. At the core of our method is to guide the proposal distribution at each diffusion step based on the prior decision. Experiments in simulation tasks show that the proposed self-guidance enables near-optimal performance at negligible inference cost. Notably, under a tight sampling budget, our method achieves up to 70% higher success rates than existing counterparts on challenging dynamic tasks. See project website at https://rhea-mal.github.io/selfgad.github.io.",
      "tldr_zh": "è¯¥ç ”ç©¶æå‡ºäº†Self-Guided Action Diffusionï¼Œæ—¨åœ¨æå‡æ‰©æ•£ç­–ç•¥(diffusion policies)åœ¨æœºå™¨äººç”Ÿæˆå¼ä»»åŠ¡ä¸­çš„æ¨ç†æ•ˆç‡å’Œè¿è´¯æ€§ã€‚é’ˆå¯¹ç°æœ‰åŒå‘è§£ç (bidirectional decoding)åœ¨ä¼˜åŒ–è·¨å—è¿è´¯æ€§æ—¶è®¡ç®—æˆæœ¬è¿‡é«˜çš„é—®é¢˜ï¼Œè¯¥æ–¹æ³•æä¾›äº†ä¸€ç§æ›´é«˜æ•ˆçš„æ”¹è¿›æ–¹æ¡ˆã€‚å…¶æ ¸å¿ƒæœºåˆ¶æ˜¯åœ¨æ¯ä¸ªæ‰©æ•£æ­¥éª¤(diffusion step)ä¸­ï¼ŒåŸºäºå…ˆå‰çš„å†³ç­–æ¥å¼•å¯¼å»ºè®®åˆ†å¸ƒ(proposal distribution)ã€‚ä»¿çœŸå®éªŒç»“æœæ˜¾ç¤ºï¼Œè¯¥è‡ªå¼•å¯¼æœºåˆ¶åœ¨å‡ ä¹ä¸å¢åŠ æ¨ç†æˆæœ¬çš„å‰æä¸‹ï¼Œèƒ½å¤Ÿå®ç°æ¥è¿‘æœ€ä¼˜çš„æ€§èƒ½ã€‚ç‰¹åˆ«æ˜¯åœ¨é‡‡æ ·é¢„ç®—æœ‰é™çš„æŒ‘æˆ˜æ€§åŠ¨æ€ä»»åŠ¡ä¸­ï¼Œè¯¥æ–¹æ³•çš„æˆåŠŸç‡æ¯”ç°æœ‰åŒç±»æ–¹æ³•æ˜¾è‘—æå‡äº†é«˜è¾¾70%ã€‚è¿™ä¸€æˆæœä¸ºåœ¨å®æ—¶åŠ¨æ€ç¯å¢ƒä¸‹å®ç°ä¸€è‡´ä¸”é«˜æ•ˆçš„æœºå™¨äººè‡ªä¸»æ§åˆ¶æä¾›äº†æœ‰åŠ›æ”¯æŒã€‚",
      "categories": [
        "cs.RO",
        "cs.AI"
      ],
      "primary_category": "cs.RO",
      "comment": "",
      "pdf_url": "https://arxiv.org/pdf/2508.12189v1",
      "published_date": "2025-08-17 00:39:15 UTC",
      "updated_date": "2025-08-17 00:39:15 UTC",
      "processing_status": "completed",
      "attempts": 1,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "llm_backup_calls": 0,
      "last_update": "2026-01-24T12:27:13.454289+00:00"
    }
  ],
  "processing_status": "completed",
  "error": null,
  "raw_papers_fetched": true,
  "papers_count": 70,
  "processed_papers_count": 70,
  "failed_papers_count": 0,
  "llm_backup_calls": 0,
  "summary_generated": true,
  "daily_data_saved": true,
  "last_update": "2026-01-24T12:27:58.404170+00:00"
}