{
  "date": "2024-11-16",
  "category": "cs.AI",
  "summary": "欢迎来到 UTC 时间 2024-11-16 的 arXiv 中文 TLDR 快报！\n\n今天 arXiv 的论文主要聚焦 AI 在医疗诊断、LLM（Large Language Models）优化和 AI 伦理等热门领域，亮点包括 MpoxVLM 用于病毒诊断的视觉语言模型，以及 Playing Language Game 对 LLM 安全风险的探讨，同时有著名学者如 Jason M. Klusowski 参与的 Transformer 理论分析，展示了 AI 模型的实际应用和潜在挑战。\n\n### 重点论文推荐\n**1. MpoxVLM: A Vision-Language Model for Diagnosing Skin Lesions from Mpox Virus Infection（MpoxVLM: 用于诊断痘病毒感染皮肤病变的视觉语言模型）**  \n这篇论文提出 MpoxVLM 模型，通过整合 CLIP 视觉编码器和 LLaMA-2-7B，在新发布的痘病毒数据集上实现 90.38% 的诊断准确率。主要贡献是填补了公开痘病毒图像数据集的空白，提升了多模态 AI 在紧急公共卫生事件中的早期诊断能力。\n\n**2. ViBe: A Text-to-Video Benchmark for Evaluating Hallucination in Large Multimodal Models（ViBe: 用于评估多模态模型幻觉的文本到视频基准）**  \n论文引入 ViBe 数据集和分类框架，识别五种幻觉类型（如消失主体和视觉不一致），并使用 TimeSFormer + CNN 组合达到 0.345 的准确率。关键发现是自动检测幻觉的难度，强调了改进 T2V 模型的必要性，以提升 AI 生成内容的可靠性。\n\n**3. Towards Next-Generation Medical Agent: How o1 is Reshaping Decision-Making in Medical Scenarios（Towards Next-Generation Medical Agent: o1 如何重塑医疗决策）**  \n作者团队包括 Tianming Liu 等知名学者，探讨 o1 模型在医疗代理中的作用，通过实时信息检索和工具使用提升诊断准确性。主要贡献是证明 o1 可处理复杂临床场景，如 ICU 决策，潜在影响包括更智能的 AI 辅助医疗系统。\n\n**4. Playing Language Game with LLMs Leads to Jailbreaking（Playing Language Game with LLMs Leads to Jailbreaking: 通过语言游戏导致 LLM 越狱）**  \n论文提出自然语言游戏和自定义语言游戏方法，导致 GPT-4o 等模型的攻击成功率高达 93%。主要发现是 LLM 的安全对齐知识无法泛化到不同语言格式，揭示了 AI 安全漏洞，并为未来防御策略提供洞见。\n\n**5. Improving training time and GPU utilization in geo-distributed language model training（Improving training time and GPU utilization in geo-distributed language model training: 地理分布 LLM 训练中的时间和 GPU 利用率优化）**  \n论文开发 ATLAS 和 BUBBLETEA 框架，通过带宽共享和推理服务，实现 LLM 训练时间加速 17 倍，GPU 利用率达 94%。关键贡献是解决分布式训练的瓶颈，适用于大规模 AI 部署。\n\n**6. One-Layer Transformer Provably Learns One-Nearest Neighbor In Context（One-Layer Transformer Provably Learns One-Nearest Neighbor In Context: 单层 Transformer 在上下文中学得最近邻分类）**  \n由 Jason M. Klusowski 等学者撰写，理论证明单层 Transformer 可模拟最近邻分类器，即使在非凸损失下也能收敛。主要发现是阐明了 Transformer 在非参数机器学习中的潜力，为 AI 算法设计提供新框架。\n\n### 其他相关论文简评\n**医疗 AI 相关：**  \n- **A Novel Adaptive Hybrid Focal-Entropy Loss for Enhancing Diabetic Retinopathy Detection Using Convolutional Neural Networks（用于增强糖尿病视网膜病变检测的自适应混合焦点熵损失）**  \n  提出 AHFE 损失函数，提升 ResNet50 等模型在不平衡医疗图像数据集上的准确率至 99.79%，主要贡献是改善少数类检测。\n\n- **MRI Parameter Mapping via Gaussian Mixture VAE（通过高斯混合 VAE 的 MRI 参数映射）**  \n  使用变分自编码器打破像素独立假设，实现更精确的医疗图像参数映射，显著提升解剖细节清晰度。\n\n**LLM 和 AI 优化相关：**  \n- **LLM4DS: Evaluating Large Language Models for Data Science Code Generation（LLM4DS: 评估 LLM 在数据科学代码生成的性能）**  \n  比较 ChatGPT 和 Claude 在数据任务中的成功率，ChatGPT 表现稳定，但未达 70% 阈值，强调任务类型对模型选择的影响。\n\n- **MetaLA: Unified Optimal Linear Approximation to Softmax Attention Map（MetaLA: 对 softmax 注意力图的统一最优线性逼近）**  \n  设计 MetaLA 框架，优化线性注意力机制，在多任务上超越现有模型，关键是动态内存和最小参数逼近。\n\n**AI 伦理和应用快速掠过：**  \n- **Gender Bias Mitigation for Bangla Classification Tasks（Bangla 分类任务中的性别偏见缓解）**  \n  使用联合损失优化减少 Bangla LLM 的性别偏见，保持准确性，贡献在于偏见检测数据集的构建。\n\n- **Partitioning Message Passing for Graph Fraud Detection（用于图欺诈检测的分区消息传递）**  \n  提出 PMP 范式，提升 GNN 在不平衡图数据上的性能，显著改善欺诈检测准确率。\n\n其他论文如生物模拟（Fine Tuning Swimming Locomotion）或量子 AI（Digital-Analog Quantum Machine Learning）虽有创新，但主题较窄，暂不展开讨论。今天 arXiv 更新多元而丰富，读者可关注医疗和 LLM 领域以捕捉前沿趋势！",
  "papers": [
    {
      "arxiv_id": "2411.10895v1",
      "title": "Evolution of IVR building techniques: from code writing to AI-powered automation",
      "title_zh": "IVR 构建技术的演变：从代码编写到 AI 驱动的自动化",
      "authors": [
        "Khushbu Mehboob Shaikh",
        "Georgios Giannakopoulos"
      ],
      "abstract": "Interactive Voice Response (IVR) systems have undergone significant\ntransformation in recent years, moving from traditional code-based development\nto more user-friendly approaches leveraging widgets and, most recently,\nharnessing the power of Artificial Intelligence (AI) for automated IVR flow\ncreation. This paper explores the evolution of IVR building techniques,\nhighlighting the industry's revolution and shaping the future of IVR systems.\nThe authors delve into the historical context, current trends, and future\nprospects of IVR development, elucidating the impact of AI on simplifying IVR\ncreation processes and enhancing customer experiences.",
      "tldr_zh": "这篇论文探讨了 Interactive Voice Response (IVR) 系统的构建技术演变，从传统的代码编写发展到使用小部件，再到利用 Artificial Intelligence (AI) 实现自动化流程。作者回顾了 IVR 发展的历史背景、当前趋势，并展望未来前景，强调 AI 如何简化 IVR 创建过程。研究结果表明，这种转变显著提升了客户体验，并推动了 IVR 行业的革命。",
      "categories": [
        "cs.SE",
        "cs.AI"
      ],
      "primary_category": "cs.SE",
      "comment": "6 pages, 3 figures",
      "pdf_url": "http://arxiv.org/pdf/2411.10895v1",
      "published_date": "2024-11-16 21:47:10 UTC",
      "updated_date": "2024-11-16 21:47:10 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-21T01:08:42.748963"
    },
    {
      "arxiv_id": "2411.10888v1",
      "title": "MpoxVLM: A Vision-Language Model for Diagnosing Skin Lesions from Mpox Virus Infection",
      "title_zh": "MpoxVLM：用于诊断由Mpox病毒感染引起的皮肤病变的视觉语言模型",
      "authors": [
        "Xu Cao",
        "Wenqian Ye",
        "Kenny Moise",
        "Megan Coffee"
      ],
      "abstract": "In the aftermath of the COVID-19 pandemic and amid accelerating climate\nchange, emerging infectious diseases, particularly those arising from zoonotic\nspillover, remain a global threat. Mpox (caused by the monkeypox virus) is a\nnotable example of a zoonotic infection that often goes undiagnosed, especially\nas its rash progresses through stages, complicating detection across diverse\npopulations with different presentations. In August 2024, the WHO\nDirector-General declared the mpox outbreak a public health emergency of\ninternational concern for a second time. Despite the deployment of deep\nlearning techniques for detecting diseases from skin lesion images, a robust\nand publicly accessible foundation model for mpox diagnosis is still lacking\ndue to the unavailability of open-source mpox skin lesion images, multimodal\nclinical data, and specialized training pipelines. To address this gap, we\npropose MpoxVLM, a vision-language model (VLM) designed to detect mpox by\nanalyzing both skin lesion images and patient clinical information. MpoxVLM\nintegrates the CLIP visual encoder, an enhanced Vision Transformer (ViT)\nclassifier for skin lesions, and LLaMA-2-7B models, pre-trained and fine-tuned\non visual instruction-following question-answer pairs from our newly released\nmpox skin lesion dataset. Our work achieves 90.38% accuracy for mpox detection,\noffering a promising pathway to improve early diagnostic accuracy in combating\nmpox.",
      "tldr_zh": "本文提出 MpoxVLM，一种 Vision-Language Model (VLM)，旨在通过分析皮肤病变图像和患者临床信息来诊断 Mpox 病毒感染，从而填补现有诊断工具的空白。模型整合了 CLIP 视觉编码器、增强的 Vision Transformer (ViT) 分类器和 LLaMA-2-7B 模型，并在新发布的 Mpox 皮肤病变数据集上进行预训练和微调，以处理视觉指令遵循的问答对。实验结果显示，该模型在 Mpox 检测中实现了 90.38% 的准确率，为提升早诊准确率和应对全球传染病威胁提供有前景的解决方案。",
      "categories": [
        "eess.IV",
        "cs.AI",
        "cs.CV"
      ],
      "primary_category": "eess.IV",
      "comment": "Accepted by ML4H 2024",
      "pdf_url": "http://arxiv.org/pdf/2411.10888v1",
      "published_date": "2024-11-16 21:09:04 UTC",
      "updated_date": "2024-11-16 21:09:04 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-21T01:08:57.727069"
    },
    {
      "arxiv_id": "2411.10886v2",
      "title": "MetricGold: Leveraging Text-To-Image Latent Diffusion Models for Metric Depth Estimation",
      "title_zh": "翻译失败",
      "authors": [
        "Ansh Shah",
        "K Madhava Krishna"
      ],
      "abstract": "Recovering metric depth from a single image remains a fundamental challenge\nin computer vision, requiring both scene understanding and accurate scaling.\nWhile deep learning has advanced monocular depth estimation, current models\noften struggle with unfamiliar scenes and layouts, particularly in zero-shot\nscenarios and when predicting scale-ergodic metric depth. We present\nMetricGold, a novel approach that harnesses generative diffusion model's rich\npriors to improve metric depth estimation. Building upon recent advances in\nMariGold, DDVM and Depth Anything V2 respectively, our method combines latent\ndiffusion, log-scaled metric depth representation, and synthetic data training.\nMetricGold achieves efficient training on a single RTX 3090 within two days\nusing photo-realistic synthetic data from HyperSIM, VirtualKitti, and\nTartanAir. Our experiments demonstrate robust generalization across diverse\ndatasets, producing sharper and higher quality metric depth estimates compared\nto existing approaches.",
      "tldr_zh": "该论文提出MetricGold方法，利用文本到图像latent diffusion models的丰富先验来提升单图像metric depth estimation的性能，解决现有模型在零-shot场景和可缩放度量深度预测中的挑战。方法结合latent diffusion、log-scaled metric depth representation以及基于MariGold、DDVM和Depth Anything V2的合成数据训练，使用HyperSIM、VirtualKitti和TartanAir的照片级合成数据，仅需单张RTX 3090两天即可高效完成训练。实验结果显示，MetricGold在多样数据集上表现出鲁棒的泛化能力，提供比现有方法更锐利和高质的metric depth估计。",
      "categories": [
        "cs.CV",
        "cs.AI",
        "cs.GR",
        "cs.RO"
      ],
      "primary_category": "cs.CV",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2411.10886v2",
      "published_date": "2024-11-16 20:59:01 UTC",
      "updated_date": "2024-12-05 14:51:55 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-21T01:09:08.831756"
    },
    {
      "arxiv_id": "2411.10879v1",
      "title": "BanglaDialecto: An End-to-End AI-Powered Regional Speech Standardization",
      "title_zh": "BanglaDialecto: 端到端的AI驱动区域语音标准化",
      "authors": [
        "Md. Nazmus Sadat Samin",
        "Jawad Ibn Ahad",
        "Tanjila Ahmed Medha",
        "Fuad Rahman",
        "Mohammad Ruhul Amin",
        "Nabeel Mohammed",
        "Shafin Rahman"
      ],
      "abstract": "This study focuses on recognizing Bangladeshi dialects and converting diverse\nBengali accents into standardized formal Bengali speech. Dialects, often\nreferred to as regional languages, are distinctive variations of a language\nspoken in a particular location and are identified by their phonetics,\npronunciations, and lexicon. Subtle changes in pronunciation and intonation are\nalso influenced by geographic location, educational attainment, and\nsocioeconomic status. Dialect standardization is needed to ensure effective\ncommunication, educational consistency, access to technology, economic\nopportunities, and the preservation of linguistic resources while respecting\ncultural diversity. Being the fifth most spoken language with around 55\ndistinct dialects spoken by 160 million people, addressing Bangla dialects is\ncrucial for developing inclusive communication tools. However, limited research\nexists due to a lack of comprehensive datasets and the challenges of handling\ndiverse dialects. With the advancement in multilingual Large Language Models\n(mLLMs), emerging possibilities have been created to address the challenges of\ndialectal Automated Speech Recognition (ASR) and Machine Translation (MT). This\nstudy presents an end-to-end pipeline for converting dialectal Noakhali speech\nto standard Bangla speech. This investigation includes constructing a\nlarge-scale diverse dataset with dialectal speech signals that tailored the\nfine-tuning process in ASR and LLM for transcribing the dialect speech to\ndialect text and translating the dialect text to standard Bangla text. Our\nexperiments demonstrated that fine-tuning the Whisper ASR model achieved a CER\nof 0.8% and WER of 1.5%, while the BanglaT5 model attained a BLEU score of\n41.6% for dialect-to-standard text translation.",
      "tldr_zh": "该研究提出 BanglaDialecto，一种端到端 AI 驱动的系统，用于识别孟加拉语方言并将多样口音转换为标准正式孟加拉语，以促进有效沟通、教育和技术包容。研究强调方言标准化的重要性，特别是针对孟加拉语（第五大语言，拥有55个方言和1.6亿使用者），并构建了一个大规模数据集来微调 Whisper ASR 模型和 BanglaT5 模型，实现从 Noakhali 方言语音到文本的转录，以及方言文本到标准文本的翻译。实验结果显示，微调后的 Whisper ASR 模型达到 CER 0.8% 和 WER 1.5%，而 BanglaT5 模型在翻译任务上获得 BLEU 得分 41.6%，证明了该方法的有效性。",
      "categories": [
        "cs.CL",
        "cs.AI",
        "cs.LG",
        "cs.SD",
        "eess.AS"
      ],
      "primary_category": "cs.CL",
      "comment": "Accepted in 2024 IEEE International Conference on Big Data (IEEE\n  BigData)",
      "pdf_url": "http://arxiv.org/pdf/2411.10879v1",
      "published_date": "2024-11-16 20:20:15 UTC",
      "updated_date": "2024-11-16 20:20:15 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-21T01:09:20.549216"
    },
    {
      "arxiv_id": "2411.10878v1",
      "title": "Empowering Meta-Analysis: Leveraging Large Language Models for Scientific Synthesis",
      "title_zh": "赋能元分析：利用大型语言模型进行科学综合",
      "authors": [
        "Jawad Ibn Ahad",
        "Rafeed Mohammad Sultan",
        "Abraham Kaikobad",
        "Fuad Rahman",
        "Mohammad Ruhul Amin",
        "Nabeel Mohammed",
        "Shafin Rahman"
      ],
      "abstract": "This study investigates the automation of meta-analysis in scientific\ndocuments using large language models (LLMs). Meta-analysis is a robust\nstatistical method that synthesizes the findings of multiple studies support\narticles to provide a comprehensive understanding. We know that a meta-article\nprovides a structured analysis of several articles. However, conducting\nmeta-analysis by hand is labor-intensive, time-consuming, and susceptible to\nhuman error, highlighting the need for automated pipelines to streamline the\nprocess. Our research introduces a novel approach that fine-tunes the LLM on\nextensive scientific datasets to address challenges in big data handling and\nstructured data extraction. We automate and optimize the meta-analysis process\nby integrating Retrieval Augmented Generation (RAG). Tailored through prompt\nengineering and a new loss metric, Inverse Cosine Distance (ICD), designed for\nfine-tuning on large contextual datasets, LLMs efficiently generate structured\nmeta-analysis content. Human evaluation then assesses relevance and provides\ninformation on model performance in key metrics. This research demonstrates\nthat fine-tuned models outperform non-fine-tuned models, with fine-tuned LLMs\ngenerating 87.6% relevant meta-analysis abstracts. The relevance of the\ncontext, based on human evaluation, shows a reduction in irrelevancy from 4.56%\nto 1.9%. These experiments were conducted in a low-resource environment,\nhighlighting the study's contribution to enhancing the efficiency and\nreliability of meta-analysis automation.",
      "tldr_zh": "本研究探讨了利用大型语言模型 (LLMs) 自动化科学文献的元分析过程，以提升科学综合效率。研究引入了一种新方法，通过在广泛科学数据集上微调 LLMs，并整合检索增强生成 (RAG) 技术、提示工程和新的损失指标 Inverse Cosine Distance (ICD)，来处理大数据提取和生成结构化元分析内容。实验结果显示，微调模型的表现优于非微调模型，生成的元分析摘要相关性达87.6%，无关性从4.56%降低至1.9%，并在低资源环境中证明了其可靠性和实用性。",
      "categories": [
        "cs.CL",
        "cs.AI",
        "cs.IR"
      ],
      "primary_category": "cs.CL",
      "comment": "Accepted in 2024 IEEE International Conference on Big Data (IEEE\n  BigData)",
      "pdf_url": "http://arxiv.org/pdf/2411.10878v1",
      "published_date": "2024-11-16 20:18:57 UTC",
      "updated_date": "2024-11-16 20:18:57 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-21T01:09:33.021983"
    },
    {
      "arxiv_id": "2411.10877v3",
      "title": "Developer Perspectives on Licensing and Copyright Issues Arising from Generative AI for Software Development",
      "title_zh": "开发人员对生成式 AI 用于软件开发引发的许可和版权问题的观点",
      "authors": [
        "Trevor Stalnaker",
        "Nathan Wintersgill",
        "Oscar Chaparro",
        "Laura A. Heymann",
        "Massimiliano Di Penta",
        "Daniel M German",
        "Denys Poshyvanyk"
      ],
      "abstract": "Despite the utility that Generative AI (GenAI) tools provide for tasks such\nas writing code, the use of these tools raises important legal questions and\npotential risks, particularly those associated with copyright law. As lawmakers\nand regulators engage with those questions, the views of users can provide\nrelevant perspectives. In this paper, we provide: (1) a survey of 574\ndevelopers on the licensing and copyright aspects of GenAI for coding, as well\nas follow-up interviews; (2) a snapshot of developers' views at a time when\nGenAI and perceptions of it are rapidly evolving; and (3) an analysis of\ndevelopers' views, yielding insights and recommendations that can inform future\nregulatory decisions in this evolving field. Our results show the benefits\ndevelopers derive from GenAI, how they view the use of AI-generated code as\nsimilar to using other existing code, the varied opinions they have on who\nshould own or be compensated for such code, that they are concerned about data\nleakage via GenAI, and much more, providing organizations and policymakers with\nvaluable insights into how the technology is being used and what concerns\nstakeholders would like to see addressed.",
      "tldr_zh": "本研究调查了574名开发人员对生成式AI（GenAI）在软件开发中引发的许可和版权问题的看法，通过问卷和后续访谈收集数据。结果显示，开发人员认为GenAI提供显著益处，并将其生成代码视为类似于现有代码，但对代码所有权和补偿持有多样意见，同时担心数据泄露风险。研究提供了宝贵见解和推荐，帮助组织和政策制定者应对这一快速演变的领域。",
      "categories": [
        "cs.SE",
        "cs.AI"
      ],
      "primary_category": "cs.SE",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2411.10877v3",
      "published_date": "2024-11-16 20:06:21 UTC",
      "updated_date": "2025-03-19 17:50:30 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-21T01:09:42.542149"
    },
    {
      "arxiv_id": "2411.10867v2",
      "title": "ViBe: A Text-to-Video Benchmark for Evaluating Hallucination in Large Multimodal Models",
      "title_zh": "翻译失败",
      "authors": [
        "Vipula Rawte",
        "Sarthak Jain",
        "Aarush Sinha",
        "Garv Kaushik",
        "Aman Bansal",
        "Prathiksha Rumale Vishwanath",
        "Samyak Rajesh Jain",
        "Aishwarya Naresh Reganti",
        "Vinija Jain",
        "Aman Chadha",
        "Amit P. Sheth",
        "Amitava Das"
      ],
      "abstract": "Recent advances in Large Multimodal Models (LMMs) have expanded their\ncapabilities to video understanding, with Text-to-Video (T2V) models excelling\nin generating videos from textual prompts. However, they still frequently\nproduce hallucinated content, revealing AI-generated inconsistencies. We\nintroduce ViBe (https://vibe-t2v-bench.github.io/): a large-scale dataset of\nhallucinated videos from open-source T2V models. We identify five major\nhallucination types: Vanishing Subject, Omission Error, Numeric Variability,\nSubject Dysmorphia, and Visual Incongruity. Using ten T2V models, we generated\nand manually annotated 3,782 videos from 837 diverse MS COCO captions. Our\nproposed benchmark includes a dataset of hallucinated videos and a\nclassification framework using video embeddings. ViBe serves as a critical\nresource for evaluating T2V reliability and advancing hallucination detection.\nWe establish classification as a baseline, with the TimeSFormer + CNN ensemble\nachieving the best performance (0.345 accuracy, 0.342 F1 score). While initial\nbaselines proposed achieve modest accuracy, this highlights the difficulty of\nautomated hallucination detection and the need for improved methods. Our\nresearch aims to drive the development of more robust T2V models and evaluate\ntheir outputs based on user preferences.",
      "tldr_zh": "本文提出 ViBe，这是一个用于评估大型多模态模型 (LMMs) 在文本到视频 (T2V) 生成中的幻觉问题的基准数据集和框架。研究团队识别了五种主要幻觉类型，包括 Vanishing Subject、Omission Error、Numeric Variability、Subject Dysmorphia 和 Visual Incongruity，并从 837 个 MS COCO 标题生成并手动标注了 3,782 个幻觉视频。使用十个 T2V 模型进行实验，TimeSFormer + CNN 集成模型作为基准达到了 0.345 准确率和 0.342 F1 分数，突显了自动幻觉检测的难度。ViBe 旨在提升 T2V 模型的可靠性，并根据用户偏好推动相关技术的发展。",
      "categories": [
        "cs.CV",
        "cs.AI"
      ],
      "primary_category": "cs.CV",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2411.10867v2",
      "published_date": "2024-11-16 19:23:12 UTC",
      "updated_date": "2025-03-19 18:53:09 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-21T01:09:57.502871"
    },
    {
      "arxiv_id": "2411.12763v1",
      "title": "Education in the Era of Neurosymbolic AI",
      "title_zh": "教育在神经符号 AI 时代",
      "authors": [
        "Chris Davis Jaldi",
        "Eleni Ilkou",
        "Noah Schroeder",
        "Cogan Shimizu"
      ],
      "abstract": "Education is poised for a transformative shift with the advent of\nneurosymbolic artificial intelligence (NAI), which will redefine how we support\ndeeply adaptive and personalized learning experiences. NAI-powered education\nsystems will be capable of interpreting complex human concepts and contexts\nwhile employing advanced problem-solving strategies, all grounded in\nestablished pedagogical frameworks. This will enable a level of personalization\nin learning systems that to date has been largely unattainable at scale,\nproviding finely tailored curricula that adapt to an individual's learning pace\nand accessibility needs, including the diagnosis of student understanding of\nsubjects at a fine-grained level, identifying gaps in foundational knowledge,\nand adjusting instruction accordingly. In this paper, we propose a system that\nleverages the unique affordances of pedagogical agents -- embodied characters\ndesigned to enhance learning -- as critical components of a hybrid NAI\narchitecture. To do so, these agents can thus simulate nuanced discussions,\ndebates, and problem-solving exercises that push learners beyond rote\nmemorization toward deep comprehension. We discuss the rationale for our system\ndesign and the preliminary findings of our work. We conclude that education in\nthe era of NAI will make learning more accessible, equitable, and aligned with\nreal-world skills. This is an era that will explore a new depth of\nunderstanding in educational tools.",
      "tldr_zh": "本文探讨了神经符号人工智能 (neurosymbolic AI) 如何变革教育，支持深度适应性和个性化的学习体验，例如通过诊断学生对主题的细粒度理解、识别基础知识缺口并据此调整教学内容。作者提出一个系统，利用 pedagogical agents（教学代理）作为混合 NAI 架构的核心组件，这些代理能模拟讨论、辩论和问题解决练习，帮助学习者从死记硬背转向深度理解。初步研究结果显示，这一系统能提升教育的可及性、公平性和与现实技能的契合度，为未来教育工具开辟新深度。",
      "categories": [
        "cs.HC",
        "cs.AI",
        "cs.CY"
      ],
      "primary_category": "cs.HC",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2411.12763v1",
      "published_date": "2024-11-16 19:18:39 UTC",
      "updated_date": "2024-11-16 19:18:39 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-21T01:10:08.178304"
    },
    {
      "arxiv_id": "2411.10861v1",
      "title": "See-Saw Generative Mechanism for Scalable Recursive Code Generation with Generative AI",
      "title_zh": "翻译失败",
      "authors": [
        "Ruslan Idelfonso Magaña Vsevolodovna"
      ],
      "abstract": "The generation of complex, large-scale code projects using generative AI\nmodels presents challenges due to token limitations, dependency management, and\niterative refinement requirements. This paper introduces the See-Saw generative\nmechanism, a novel methodology for dynamic and recursive code generation. The\nproposed approach alternates between main code updates and dependency\ngeneration to ensure alignment and functionality. By dynamically optimizing\ntoken usage and incorporating key elements of the main code into the generation\nof dependencies, the method enables efficient and scalable code generation for\nprojects requiring hundreds of interdependent files. The mechanism ensures that\nall code components are synchronized and functional, enabling scalable and\nefficient project generation. Experimental validation demonstrates the method's\ncapability to manage dependencies effectively while maintaining coherence and\nminimizing computational overhead.",
      "tldr_zh": "该论文针对生成式AI在创建复杂大规模代码项目时面临的token限制、依赖管理和迭代优化挑战，提出了一种新型的See-Saw generative mechanism。该机制通过交替更新主代码和生成依赖，确保代码组件的对齐与功能性，同时动态优化token使用并将主代码关键元素融入依赖生成，从而实现高效、可扩展的递归代码生成。实验结果表明，该方法能够有效管理数百个相互依赖的文件，保持代码一致性并减少计算开销，为大规模代码项目生成提供了可行的解决方案。",
      "categories": [
        "cs.LG",
        "cs.AI",
        "cs.SE",
        "68T05 (Primary) 68T50, 68N99(Secondary)",
        "I.2.6; I.2.7; D.2.2"
      ],
      "primary_category": "cs.LG",
      "comment": "18 pages, 4 figures",
      "pdf_url": "http://arxiv.org/pdf/2411.10861v1",
      "published_date": "2024-11-16 18:54:56 UTC",
      "updated_date": "2024-11-16 18:54:56 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-21T01:10:18.561407"
    },
    {
      "arxiv_id": "2411.11908v1",
      "title": "LLM4DS: Evaluating Large Language Models for Data Science Code Generation",
      "title_zh": "LLM4DS：评估大型语言模型用于数据科学代码生成",
      "authors": [
        "Nathalia Nascimento",
        "Everton Guimaraes",
        "Sai Sanjna Chintakunta",
        "Santhosh Anitha Boominathan"
      ],
      "abstract": "The adoption of Large Language Models (LLMs) for code generation in data\nscience offers substantial potential for enhancing tasks such as data\nmanipulation, statistical analysis, and visualization. However, the\neffectiveness of these models in the data science domain remains underexplored.\nThis paper presents a controlled experiment that empirically assesses the\nperformance of four leading LLM-based AI assistants-Microsoft Copilot (GPT-4\nTurbo), ChatGPT (o1-preview), Claude (3.5 Sonnet), and Perplexity Labs\n(Llama-3.1-70b-instruct)-on a diverse set of data science coding challenges\nsourced from the Stratacratch platform. Using the Goal-Question-Metric (GQM)\napproach, we evaluated each model's effectiveness across task types\n(Analytical, Algorithm, Visualization) and varying difficulty levels. Our\nfindings reveal that all models exceeded a 50% baseline success rate,\nconfirming their capability beyond random chance. Notably, only ChatGPT and\nClaude achieved success rates significantly above a 60% baseline, though none\nof the models reached a 70% threshold, indicating limitations in higher\nstandards. ChatGPT demonstrated consistent performance across varying\ndifficulty levels, while Claude's success rate fluctuated with task complexity.\nHypothesis testing indicates that task type does not significantly impact\nsuccess rate overall. For analytical tasks, efficiency analysis shows no\nsignificant differences in execution times, though ChatGPT tended to be slower\nand less predictable despite high success rates. This study provides a\nstructured, empirical evaluation of LLMs in data science, delivering insights\nthat support informed model selection tailored to specific task demands. Our\nfindings establish a framework for future AI assessments, emphasizing the value\nof rigorous evaluation beyond basic accuracy measures.",
      "tldr_zh": "本研究评估了大型语言模型（LLMs）在数据科学代码生成中的表现，针对 Microsoft Copilot (GPT-4 Turbo)、ChatGPT (o1-preview)、Claude (3.5 Sonnet) 和 Perplexity Labs (Llama-3.1-70b-instruct) 等四种模型，使用 Goal-Question-Metric (GQM) 方法测试了 Stratacratch 平台的多样化任务，包括分析、算法和可视化类型。结果显示，所有模型成功率均超过50%，其中 ChatGPT 和 Claude 超过了60% 的基准，但未达70%，且 ChatGPT 在不同难度水平上表现一致，而 Claude 的表现随任务复杂度波动。假设测试表明任务类型对成功率无显著影响，该研究提供了结构化的实证框架，支持未来 LLMs 评估并指导模型选择。",
      "categories": [
        "cs.SE",
        "cs.AI",
        "cs.ET"
      ],
      "primary_category": "cs.SE",
      "comment": "11 pages",
      "pdf_url": "http://arxiv.org/pdf/2411.11908v1",
      "published_date": "2024-11-16 18:43:26 UTC",
      "updated_date": "2024-11-16 18:43:26 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-21T01:10:32.658237"
    },
    {
      "arxiv_id": "2411.14461v1",
      "title": "Towards Next-Generation Medical Agent: How o1 is Reshaping Decision-Making in Medical Scenarios",
      "title_zh": "迈向下一代医疗代理：o1 如何重塑医疗场景中的决策",
      "authors": [
        "Shaochen Xu",
        "Yifan Zhou",
        "Zhengliang Liu",
        "Zihao Wu",
        "Tianyang Zhong",
        "Huaqin Zhao",
        "Yiwei Li",
        "Hanqi Jiang",
        "Yi Pan",
        "Junhao Chen",
        "Jin Lu",
        "Wei Zhang",
        "Tuo Zhang",
        "Lu Zhang",
        "Dajiang Zhu",
        "Xiang Li",
        "Wei Liu",
        "Quanzheng Li",
        "Andrea Sikora",
        "Xiaoming Zhai",
        "Zhen Xiang",
        "Tianming Liu"
      ],
      "abstract": "Artificial Intelligence (AI) has become essential in modern healthcare, with\nlarge language models (LLMs) offering promising advances in clinical\ndecision-making. Traditional model-based approaches, including those leveraging\nin-context demonstrations and those with specialized medical fine-tuning, have\ndemonstrated strong performance in medical language processing but struggle\nwith real-time adaptability, multi-step reasoning, and handling complex medical\ntasks. Agent-based AI systems address these limitations by incorporating\nreasoning traces, tool selection based on context, knowledge retrieval, and\nboth short- and long-term memory. These additional features enable the medical\nAI agent to handle complex medical scenarios where decision-making should be\nbuilt on real-time interaction with the environment. Therefore, unlike\nconventional model-based approaches that treat medical queries as isolated\nquestions, medical AI agents approach them as complex tasks and behave more\nlike human doctors. In this paper, we study the choice of the backbone LLM for\nmedical AI agents, which is the foundation for the agent's overall reasoning\nand action generation. In particular, we consider the emergent o1 model and\nexamine its impact on agents' reasoning, tool-use adaptability, and real-time\ninformation retrieval across diverse clinical scenarios, including high-stakes\nsettings such as intensive care units (ICUs). Our findings demonstrate o1's\nability to enhance diagnostic accuracy and consistency, paving the way for\nsmarter, more responsive AI tools that support better patient outcomes and\ndecision-making efficacy in clinical practice.",
      "tldr_zh": "人工智能（AI）在医疗保健中扮演关键角色，本文探讨了新兴的o1模型如何提升医疗AI代理在决策中的表现。传统LLMs在实时适应性、多步推理和复杂任务处理上存在局限，而代理-based AI系统通过引入推理跟踪、工具选择、知识检索和记忆机制，模拟人类医生行为进行综合任务处理。该研究评估了o1作为骨干LLM在多样临床场景中的影响，包括ICU等高风险环境，结果表明o1显著提高了诊断准确性和一致性，为开发更响应式的AI工具支持临床决策和患者outcome铺平道路。",
      "categories": [
        "cs.CL",
        "cs.AI",
        "cs.CY"
      ],
      "primary_category": "cs.CL",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2411.14461v1",
      "published_date": "2024-11-16 18:19:53 UTC",
      "updated_date": "2024-11-16 18:19:53 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-21T01:10:44.160973"
    },
    {
      "arxiv_id": "2411.10843v2",
      "title": "A Novel Adaptive Hybrid Focal-Entropy Loss for Enhancing Diabetic Retinopathy Detection Using Convolutional Neural Networks",
      "title_zh": "翻译失败",
      "authors": [
        "Santhosh Malarvannan",
        "Pandiyaraju V",
        "Shravan Venkatraman",
        "Abeshek A",
        "Priyadarshini B",
        "Kannan A"
      ],
      "abstract": "Diabetic retinopathy is a leading cause of blindness around the world and\ndemands precise AI-based diagnostic tools. Traditional loss functions in\nmulti-class classification, such as Categorical Cross-Entropy (CCE), are very\ncommon but break down with class imbalance, especially in cases with inherently\nchallenging or overlapping classes, which leads to biased and less sensitive\nmodels. Since a heavy imbalance exists in the number of examples for higher\nseverity stage 4 diabetic retinopathy, etc., classes compared to those very\nearly stages like class 0, achieving class balance is key. For this purpose, we\npropose the Adaptive Hybrid Focal-Entropy Loss which combines the ideas of\nfocal loss and entropy loss with adaptive weighting in order to focus on\nminority classes and highlight the challenging samples. The state-of-the art\nmodels applied for diabetic retinopathy detection with AHFE revealed good\nperformance improvements, indicating the top performances of ResNet50 at\n99.79%, DenseNet121 at 98.86%, Xception at 98.92%, MobileNetV2 at 97.84%, and\nInceptionV3 at 93.62% accuracy. This sheds light into how AHFE promotes\nenhancement in AI-driven diagnostics for complex and imbalanced medical\ndatasets.",
      "tldr_zh": "该研究针对糖尿病视网膜病变检测中的类别不平衡问题，提出了一种新颖的Adaptive Hybrid Focal-Entropy Loss损失函数，该函数结合Focal Loss和Entropy Loss，并引入自适应权重，以重点关注少数类和挑战样本，从而提升模型的敏感性和准确性。在多种Convolutional Neural Networks模型上应用AHFE后，性能显著改善，包括ResNet50达到99.79%、DenseNet121达到98.86%、Xception达到98.92%、MobileNetV2达到97.84%和InceptionV3达到93.62%的准确率。该方法为处理复杂不平衡医疗数据集的AI诊断工具提供了重要提升，展示了其在实际应用中的潜力。",
      "categories": [
        "eess.IV",
        "cs.AI",
        "cs.CV",
        "cs.LG",
        "68T07, 92C55, 68U10",
        "I.2.10; I.5.1; J.3"
      ],
      "primary_category": "eess.IV",
      "comment": "7 pages,7 figures",
      "pdf_url": "http://arxiv.org/pdf/2411.10843v2",
      "published_date": "2024-11-16 17:07:53 UTC",
      "updated_date": "2025-04-23 16:24:31 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-21T01:10:56.385028"
    },
    {
      "arxiv_id": "2411.10842v1",
      "title": "CODECLEANER: Elevating Standards with A Robust Data Contamination Mitigation Toolkit",
      "title_zh": "翻译失败",
      "authors": [
        "Jialun Cao",
        "Songqiang Chen",
        "Wuqi Zhang",
        "Hau Ching Lo",
        "Shing-Chi Cheung"
      ],
      "abstract": "Data contamination presents a critical barrier preventing widespread\nindustrial adoption of advanced software engineering techniques that leverage\ncode language models (CLMs). This phenomenon occurs when evaluation data\ninadvertently overlaps with the public code repositories used to train CLMs,\nseverely undermining the credibility of performance evaluations. For software\ncompanies considering the integration of CLM-based techniques into their\ndevelopment pipeline, this uncertainty about true performance metrics poses an\nunacceptable business risk. Code refactoring, which comprises code\nrestructuring and variable renaming, has emerged as a promising measure to\nmitigate data contamination. It provides a practical alternative to the\nresource-intensive process of building contamination-free evaluation datasets,\nwhich would require companies to collect, clean, and label code created after\nthe CLMs' training cutoff dates. However, the lack of automated code\nrefactoring tools and scientifically validated refactoring techniques has\nhampered widespread industrial implementation. To bridge the gap, this paper\npresents the first systematic study to examine the efficacy of code refactoring\noperators at multiple scales (method-level, class-level, and cross-class level)\nand in different programming languages. In particular, we develop an\nopen-sourced toolkit, CODECLEANER, which includes 11 operators for Python, with\nnine method-level, one class-level, and one cross-class-level operator. A drop\nof 65% overlap ratio is found when applying all operators in CODECLEANER,\ndemonstrating their effectiveness in addressing data contamination.\nAdditionally, we migrate four operators to Java, showing their generalizability\nto another language. We make CODECLEANER online available to facilitate further\nstudies on mitigating CLM data contamination.",
      "tldr_zh": "数据污染（data contamination）是代码语言模型（CLMs）在工业应用中的关键障碍，因为评估数据可能与训练数据重叠，导致性能评估不可靠。本文进行首个系统性研究，评估代码重构（code refactoring）操作在方法级、类级和跨类级上的有效性，并开发了开源工具包 CODECLEANER，包含 11 个针对 Python 的操作符。实验结果显示，应用这些操作符后，重叠率下降 65%，并成功将 4 个操作符移植到 Java，证明了其通用性和潜力，为缓解 CLM 数据污染问题提供实用工具。",
      "categories": [
        "cs.SE",
        "cs.AI"
      ],
      "primary_category": "cs.SE",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2411.10842v1",
      "published_date": "2024-11-16 17:06:21 UTC",
      "updated_date": "2024-11-16 17:06:21 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-21T01:11:09.000206"
    },
    {
      "arxiv_id": "2411.10841v1",
      "title": "Adaptive Learning of Design Strategies over Non-Hierarchical Multi-Fidelity Models via Policy Alignment",
      "title_zh": "翻译失败",
      "authors": [
        "Akash Agrawal",
        "Christopher McComb"
      ],
      "abstract": "Multi-fidelity Reinforcement Learning (RL) frameworks significantly enhance\nthe efficiency of engineering design by leveraging analysis models with varying\nlevels of accuracy and computational costs. The prevailing methodologies,\ncharacterized by transfer learning, human-inspired strategies, control variate\ntechniques, and adaptive sampling, predominantly depend on a structured\nhierarchy of models. However, this reliance on a model hierarchy overlooks the\nheterogeneous error distributions of models across the design space, extending\nbeyond mere fidelity levels. This work proposes ALPHA (Adaptively Learned\nPolicy with Heterogeneous Analyses), a novel multi-fidelity RL framework to\nefficiently learn a high-fidelity policy by adaptively leveraging an arbitrary\nset of non-hierarchical, heterogeneous, low-fidelity models alongside a\nhigh-fidelity model. Specifically, low-fidelity policies and their experience\ndata are dynamically used for efficient targeted learning, guided by their\nalignment with the high-fidelity policy. The effectiveness of ALPHA is\ndemonstrated in analytical test optimization and octocopter design problems,\nutilizing two low-fidelity models alongside a high-fidelity one. The results\nhighlight ALPHA's adaptive capability to dynamically utilize models across time\nand design space, eliminating the need for scheduling models as required in a\nhierarchical framework. Furthermore, the adaptive agents find more direct paths\nto high-performance solutions, showing superior convergence behavior compared\nto hierarchical agents.",
      "tldr_zh": "本文提出ALPHA框架（Adaptively Learned Policy with Heterogeneous Analyses），一种新型多保真强化学习（Multi-fidelity RL）方法，通过policy alignment动态利用非层次化的异构低保真模型和一个高保真模型，来高效学习设计策略。不同于传统依赖模型层次的方法，ALPHA根据低保真策略与高保真策略的alignment，自适应地选择和整合经验数据，提升针对性学习。实验结果显示，在分析测试优化和octocopter设计问题中，ALPHA实现了更直接的高性能路径和优越的收敛行为，显著超越了层次化框架。",
      "categories": [
        "cs.LG",
        "cs.AI"
      ],
      "primary_category": "cs.LG",
      "comment": "48 pages, 20 figures",
      "pdf_url": "http://arxiv.org/pdf/2411.10841v1",
      "published_date": "2024-11-16 16:54:33 UTC",
      "updated_date": "2024-11-16 16:54:33 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-21T01:11:20.223616"
    },
    {
      "arxiv_id": "2411.10830v1",
      "title": "One-Layer Transformer Provably Learns One-Nearest Neighbor In Context",
      "title_zh": "翻译失败",
      "authors": [
        "Zihao Li",
        "Yuan Cao",
        "Cheng Gao",
        "Yihan He",
        "Han Liu",
        "Jason M. Klusowski",
        "Jianqing Fan",
        "Mengdi Wang"
      ],
      "abstract": "Transformers have achieved great success in recent years. Interestingly,\ntransformers have shown particularly strong in-context learning capability --\neven without fine-tuning, they are still able to solve unseen tasks well purely\nbased on task-specific prompts. In this paper, we study the capability of\none-layer transformers in learning one of the most classical nonparametric\nestimators, the one-nearest neighbor prediction rule. Under a theoretical\nframework where the prompt contains a sequence of labeled training data and\nunlabeled test data, we show that, although the loss function is nonconvex when\ntrained with gradient descent, a single softmax attention layer can\nsuccessfully learn to behave like a one-nearest neighbor classifier. Our result\ngives a concrete example of how transformers can be trained to implement\nnonparametric machine learning algorithms, and sheds light on the role of\nsoftmax attention in transformer models.",
      "tldr_zh": "本文研究证明，一层 Transformer 模型能够在 in-context learning 中成功学习 one-nearest neighbor (1-NN) 预测规则，即使损失函数是非凸的，通过梯度下降训练也能基于提示中的标记训练数据和未标记测试数据实现类似 1-NN 分类器的行为。该工作提供了一个具体示例，展示了 Transformer 如何实现非参数机器学习算法，并阐明了 softmax attention 在模型中的关键作用。结果有助于加深对 Transformer in-context 学习能力的理解。",
      "categories": [
        "cs.LG",
        "cs.AI",
        "math.OC"
      ],
      "primary_category": "cs.LG",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2411.10830v1",
      "published_date": "2024-11-16 16:12:42 UTC",
      "updated_date": "2024-11-16 16:12:42 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-21T01:11:32.925355"
    },
    {
      "arxiv_id": "2412.12103v1",
      "title": "Empathic Coupling of Homeostatic States for Intrinsic Prosociality",
      "title_zh": "翻译失败",
      "authors": [
        "Naoto Yoshida",
        "Kingson Man"
      ],
      "abstract": "When regarding the suffering of others, we often experience personal distress\nand feel compelled to help. Inspired by living systems, we investigate the\nemergence of prosocial behavior among autonomous agents that are motivated by\nhomeostatic self-regulation. We perform multi-agent reinforcement learning,\ntreating each agent as a vulnerable homeostat charged with maintaining its own\nwell-being. We introduce an empathy-like mechanism to share homeostatic states\nbetween agents: an agent can either \\emph{observe} their partner's internal\nstate (cognitive empathy) or the agent's internal state can be \\emph{directly\ncoupled} to that of their partner's (affective empathy). In three simple\nmulti-agent environments, we show that prosocial behavior arises only under\nhomeostatic coupling - when the distress of a partner can affect one's own\nwell-being. Our findings specify the type and role of empathy in artificial\nagents capable of prosocial behavior.",
      "tldr_zh": "这篇论文探讨了如何通过稳态耦合机制（homeostatic coupling）在自主代理中激发内在利他行为（intrinsic prosociality），受生物系统启发。研究采用 multi-agent reinforcement learning，将每个代理视为负责维持自身福祉的脆弱稳态系统，并引入移情机制：代理可以观察伙伴的内部状态（cognitive empathy）或直接耦合内部状态（affective empathy）。在三个简单多代理环境中，实验发现，只有在稳态耦合时（即伙伴的痛苦影响自身福祉），利他行为才会出现。该研究明确了在能表现出 prosocial behavior 的 artificial agents 中，移情的类型和作用，为设计更具移情能力的代理提供了基础。",
      "categories": [
        "cs.MA",
        "cs.AI",
        "cs.NE"
      ],
      "primary_category": "cs.MA",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2412.12103v1",
      "published_date": "2024-11-16 13:30:01 UTC",
      "updated_date": "2024-11-16 13:30:01 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-21T01:11:44.504734"
    },
    {
      "arxiv_id": "2411.13583v1",
      "title": "Enhanced FIWARE-Based Architecture for Cyberphysical Systems With Tiny Machine Learning and Machine Learning Operations: A Case Study on Urban Mobility Systems",
      "title_zh": "翻译失败",
      "authors": [
        "Javier Conde",
        "Andrés Munoz-Arcentales",
        "Álvaro Alonso",
        "Joaquín Salvachúa",
        "Gabriel Huecas"
      ],
      "abstract": "The rise of AI and the Internet of Things is accelerating the digital\ntransformation of society. Mobility computing presents specific barriers due to\nits real-time requirements, decentralization, and connectivity through wireless\nnetworks. New research on edge computing and tiny machine learning (tinyML)\nexplores the execution of AI models on low-performance devices to address these\nissues. However, there are not many studies proposing agnostic architectures\nthat manage the entire lifecycle of intelligent cyberphysical systems. This\narticle extends a previous architecture based on FIWARE software components to\nimplement the machine learning operations flow, enabling the management of the\nentire tinyML lifecycle in cyberphysical systems. We also provide a use case to\nshowcase how to implement the FIWARE architecture through a complete example of\na smart traffic system. We conclude that the FIWARE ecosystem constitutes a\nreal reference option for developing tinyML and edge computing in cyberphysical\nsystems.",
      "tldr_zh": "本文提出了一种增强的基于 FIWARE 的架构，用于 cyberphysical systems，整合 tiny machine learning (tinyML) 和 machine learning operations (MLOps)，以管理智能系统整个生命周期的挑战，如实时需求和去中心化问题。该架构扩展了原有 FIWARE 组件，实现 tinyML 的完整流程管理，并通过一个智能交通系统的用例展示其在 urban mobility systems 中的实际应用。研究结果表明，FIWARE 生态系统是开发 tinyML 和 edge computing 的可靠参考选项。",
      "categories": [
        "cs.CR",
        "cs.AI",
        "cs.DC",
        "cs.NI"
      ],
      "primary_category": "cs.CR",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2411.13583v1",
      "published_date": "2024-11-16 13:14:29 UTC",
      "updated_date": "2024-11-16 13:14:29 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-21T01:11:56.342670"
    },
    {
      "arxiv_id": "2411.12762v2",
      "title": "Playing Language Game with LLMs Leads to Jailbreaking",
      "title_zh": "翻译失败",
      "authors": [
        "Yu Peng",
        "Zewen Long",
        "Fangming Dong",
        "Congyi Li",
        "Shu Wu",
        "Kai Chen"
      ],
      "abstract": "The advent of large language models (LLMs) has spurred the development of\nnumerous jailbreak techniques aimed at circumventing their security defenses\nagainst malicious attacks. An effective jailbreak approach is to identify a\ndomain where safety generalization fails, a phenomenon known as mismatched\ngeneralization. In this paper, we introduce two novel jailbreak methods based\non mismatched generalization: natural language games and custom language games,\nboth of which effectively bypass the safety mechanisms of LLMs, with various\nkinds and different variants, making them hard to defend and leading to high\nattack rates. Natural language games involve the use of synthetic linguistic\nconstructs and the actions intertwined with these constructs, such as the Ubbi\nDubbi language. Building on this phenomenon, we propose the custom language\ngames method: by engaging with LLMs using a variety of custom rules, we\nsuccessfully execute jailbreak attacks across multiple LLM platforms. Extensive\nexperiments demonstrate the effectiveness of our methods, achieving success\nrates of 93% on GPT-4o, 89% on GPT-4o-mini and 83% on Claude-3.5-Sonnet.\nFurthermore, to investigate the generalizability of safety alignments, we\nfine-tuned Llama-3.1-70B with the custom language games to achieve safety\nalignment within our datasets and found that when interacting through other\nlanguage games, the fine-tuned models still failed to identify harmful content.\nThis finding indicates that the safety alignment knowledge embedded in LLMs\nfails to generalize across different linguistic formats, thus opening new\navenues for future research in this area.",
      "tldr_zh": "这篇论文探讨了通过语言游戏绕过大型语言模型（LLMs）的安全机制，导致 jailbreak 攻击的新方法。研究者引入了两种基于 mismatched generalization 的技术：natural language games（利用合成语言结构，如 Ubbi Dubbi 语言）和 custom language games（通过自定义规则与 LLMs 互动），这些方法能有效规避安全防御，并在 GPT-4o、GPT-4o-mini 和 Claude-3.5-Sonnet 上实现高达 93%、89% 和 83% 的成功率。进一步实验显示，对 Llama-3.1-70B 进行微调后，模型在其他语言游戏中仍无法识别有害内容，揭示了 LLMs 安全对齐知识的泛化局限性，为未来安全研究提供了新方向。",
      "categories": [
        "cs.CL",
        "cs.AI"
      ],
      "primary_category": "cs.CL",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2411.12762v2",
      "published_date": "2024-11-16 13:07:13 UTC",
      "updated_date": "2024-11-27 07:41:35 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-21T01:12:11.488907"
    },
    {
      "arxiv_id": "2411.15173v1",
      "title": "Decentralizing Test-time Adaptation under Heterogeneous Data Streams",
      "title_zh": "翻译失败",
      "authors": [
        "Zixian Su",
        "Jingwei Guo",
        "Xi Yang",
        "Qiufeng Wang",
        "Kaizhu Huang"
      ],
      "abstract": "While Test-Time Adaptation (TTA) has shown promise in addressing distribution\nshifts between training and testing data, its effectiveness diminishes with\nheterogeneous data streams due to uniform target estimation. As previous\nattempts merely stabilize model fine-tuning over time to handle continually\nchanging environments, they fundamentally assume a homogeneous target domain at\nany moment, leaving the intrinsic real-world data heterogeneity unresolved.\nThis paper delves into TTA under heterogeneous data streams, moving beyond\ncurrent model-centric limitations. By revisiting TTA from a data-centric\nperspective, we discover that decomposing samples into Fourier space\nfacilitates an accurate data separation across different frequency levels.\nDrawing from this insight, we propose a novel Frequency-based Decentralized\nAdaptation (FreDA) framework, which transitions data from globally\nheterogeneous to locally homogeneous in Fourier space and employs decentralized\nadaptation to manage diverse distribution shifts.Interestingly, we devise a\nnovel Fourier-based augmentation strategy to assist in decentralizing\nadaptation, which individually enhances sample quality for capturing each type\nof distribution shifts. Extensive experiments across various settings\n(corrupted, natural, and medical environments) demonstrate the superiority of\nour proposed framework over the state-of-the-arts.",
      "tldr_zh": "本文研究了 Test-Time Adaptation (TTA) 在异质数据流下的局限性，指出现有方法因假设目标域同质而无法有效处理真实世界的分布偏移。作者从数据视角出发，通过将样本分解到 Fourier space 实现数据分离，并提出 Frequency-based Decentralized Adaptation (FreDA) 框架，该框架在傅立叶空间中将全局异质数据转化为局部同质数据，并结合 Fourier-based augmentation 策略来增强样本质量以应对不同分布偏移。实验在各种场景（如损坏的、自然的和医疗环境）中证明，FreDA 优于现有方法，显著提升了适应性能。",
      "categories": [
        "cs.LG",
        "cs.AI"
      ],
      "primary_category": "cs.LG",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2411.15173v1",
      "published_date": "2024-11-16 12:29:59 UTC",
      "updated_date": "2024-11-16 12:29:59 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-21T01:12:20.314623"
    },
    {
      "arxiv_id": "2411.14460v2",
      "title": "LLaSA: Large Language and Structured Data Assistant",
      "title_zh": "LLaSA：大型语言与结构化数据助手",
      "authors": [
        "Yao Xu",
        "Shizhu He",
        "Jiabei Chen",
        "Zeng Xiangrong",
        "Bingning Wang",
        "Guang Liu",
        "Jun Zhao",
        "Kang Liu"
      ],
      "abstract": "Structured data, such as tables, graphs, and databases, play a critical role\nin plentiful NLP tasks such as question answering and dialogue system.\nRecently, inspired by Vision-Language Models, Graph Neutral Networks (GNNs)\nhave been introduced as an additional modality into the input of Large Language\nModels (LLMs) to improve their performance on Structured Knowledge Grounding\n(SKG) tasks. However, those GNN-enhanced LLMs have the following limitations:\n(1) They employ diverse GNNs to model varying types of structured data,\nrendering them unable to uniformly process various forms of structured data.\n(2) The pretraining of GNNs is coupled with specific LLMs, which prevents GNNs\nfrom fully aligning with the textual space and limits their adaptability to\nother LLMs. To address these issues, we propose \\textbf{L}arge\n\\textbf{L}anguage and \\textbf{S}tructured Data \\textbf{A}ssistant (LLaSA), a\ngeneral framework for enhancing LLMs' ability to handle structured data.\nSpecifically, we represent various types of structured data in a unified\nhypergraph format, and use self-supervised learning to pretrain a hypergraph\nencoder, and a G-Former compressing encoded hypergraph representations with\ncross-attention. The compressed hypergraph representations are appended to the\nserialized inputs during training and inference stages of LLMs. Experimental\nresults on multiple SKG tasks show that our pretrained hypergraph encoder can\nadapt to various LLMs and enhance their ability to process different types of\nstructured data. Besides, LLaSA, with LoRA fine-tuning, outperforms previous\nSOTA method using full parameters tuning.",
      "tldr_zh": "该研究提出LLaSA框架，以增强Large Language Models (LLMs)处理结构化数据（如表格、图表和数据库）的能力，针对现有Graph Neural Networks (GNNs)增强LLMs的局限性，包括无法统一处理不同类型数据和预训练耦合问题。LLaSA将各种结构化数据统一表示为hypergraph格式，通过自监督学习预训练一个hypergraph编码器，并使用G-Former通过cross-attention机制压缩表示，然后将其附加到LLMs的输入序列中。实验结果显示，该框架能适应多种LLMs，并在多个Structured Knowledge Grounding (SKG)任务上提升性能，使用LoRA微调时 outperform 先前SOTA方法，即使仅调优部分参数。",
      "categories": [
        "cs.CL",
        "cs.AI",
        "cs.LG"
      ],
      "primary_category": "cs.CL",
      "comment": "NAACL 2025 Main",
      "pdf_url": "http://arxiv.org/pdf/2411.14460v2",
      "published_date": "2024-11-16 12:27:14 UTC",
      "updated_date": "2025-02-09 17:13:10 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-21T01:12:32.595098"
    },
    {
      "arxiv_id": "2411.14459v1",
      "title": "Unveiling User Preferences: A Knowledge Graph and LLM-Driven Approach for Conversational Recommendation",
      "title_zh": "翻译失败",
      "authors": [
        "Zhangchi Qiu",
        "Linhao Luo",
        "Shirui Pan",
        "Alan Wee-Chung Liew"
      ],
      "abstract": "Conversational Recommender Systems (CRSs) aim to provide personalized\nrecommendations through dynamically capturing user preferences in interactive\nconversations. Conventional CRSs often extract user preferences as hidden\nrepresentations, which are criticized for their lack of interpretability. This\ndiminishes the transparency and trustworthiness of the recommendation process.\nRecent works have explored combining the impressive capabilities of Large\nLanguage Models (LLMs) with the domain-specific knowledge of Knowledge Graphs\n(KGs) to generate human-understandable recommendation explanations. Despite\nthese efforts, the integration of LLMs and KGs for CRSs remains challenging due\nto the modality gap between unstructured dialogues and structured KGs.\nMoreover, LLMs pre-trained on large-scale corpora may not be well-suited for\nanalyzing user preferences, which require domain-specific knowledge. In this\npaper, we propose COMPASS, a plug-and-play framework that synergizes LLMs and\nKGs to unveil user preferences, enhancing the performance and explainability of\nexisting CRSs. To address integration challenges, COMPASS employs a two-stage\ntraining approach: first, it bridges the gap between the structured KG and\nnatural language through an innovative graph entity captioning pre-training\nmechanism. This enables the LLM to transform KG entities into concise natural\nlanguage descriptions, allowing them to comprehend domain-specific knowledge.\nFollowing, COMPASS optimizes user preference modeling via knowledge-aware\ninstruction fine-tuning, where the LLM learns to reason and summarize user\npreferences from both dialogue histories and KG-augmented context. This enables\nCOMPASS to perform knowledge-aware reasoning and generate comprehensive and\ninterpretable user preferences that can seamlessly integrate with existing CRS\nmodels for improving recommendation performance and explainability.",
      "tldr_zh": "该论文提出 COMPASS 框架，利用 Knowledge Graphs (KGs) 和 Large Language Models (LLMs) 来揭示用户偏好，从而提升 Conversational Recommender Systems (CRSs) 的性能和可解释性。\n为了桥接对话的非结构化性质与 KGs 的结构化挑战，框架采用两阶段训练：首先通过图实体标题预训练，将 KG 实体转化为自然语言描述，让 LLM 理解领域特定知识；其次进行知识感知指令微调，使 LLM 从对话历史和 KG 增强的上下文进行推理和总结用户偏好。\n最终，COMPASS 能生成全面、可解释的用户偏好，并无缝整合到现有 CRS 模型中，提高推荐的准确性和透明度。",
      "categories": [
        "cs.CL",
        "cs.AI",
        "cs.IR"
      ],
      "primary_category": "cs.CL",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2411.14459v1",
      "published_date": "2024-11-16 11:47:21 UTC",
      "updated_date": "2024-11-16 11:47:21 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-21T01:12:45.355041"
    },
    {
      "arxiv_id": "2412.00020v1",
      "title": "Partitioning Message Passing for Graph Fraud Detection",
      "title_zh": "用于图欺诈检测的分区消息传递",
      "authors": [
        "Wei Zhuo",
        "Zemin Liu",
        "Bryan Hooi",
        "Bingsheng He",
        "Guang Tan",
        "Rizal Fathony",
        "Jia Chen"
      ],
      "abstract": "Label imbalance and homophily-heterophily mixture are the fundamental\nproblems encountered when applying Graph Neural Networks (GNNs) to Graph Fraud\nDetection (GFD) tasks. Existing GNN-based GFD models are designed to augment\ngraph structure to accommodate the inductive bias of GNNs towards homophily, by\nexcluding heterophilic neighbors during message passing. In our work, we argue\nthat the key to applying GNNs for GFD is not to exclude but to {\\em\ndistinguish} neighbors with different labels. Grounded in this perspective, we\nintroduce Partitioning Message Passing (PMP), an intuitive yet effective\nmessage passing paradigm expressly crafted for GFD. Specifically, in the\nneighbor aggregation stage of PMP, neighbors with different classes are\naggregated with distinct node-specific aggregation functions. By this means,\nthe center node can adaptively adjust the information aggregated from its\nheterophilic and homophilic neighbors, thus avoiding the model gradient being\ndominated by benign nodes which occupy the majority of the population. We\ntheoretically establish a connection between the spatial formulation of PMP and\nspectral analysis to characterize that PMP operates an adaptive node-specific\nspectral graph filter, which demonstrates the capability of PMP to handle\nheterophily-homophily mixed graphs. Extensive experimental results show that\nPMP can significantly boost the performance on GFD tasks.",
      "tldr_zh": "本文针对Graph Neural Networks (GNNs) 在Graph Fraud Detection (GFD) 任务中面临的标签不平衡和同质-异质混合问题，提出Partitioning Message Passing (PMP) 方法，该方法在邻居聚合阶段使用不同的节点特定聚合函数来区分并处理同质和异质邻居，从而使中心节点能自适应地调整信息来源，避免模型梯度被多数良性节点主导。理论上，PMP 通过空间公式与谱分析建立联系，证明其相当于一个自适应节点特定谱图过滤器，能够有效处理同质-异质混合图。实验结果显示，PMP 显著提升了GFD 任务的性能。",
      "categories": [
        "cs.AI",
        "cs.LG",
        "cs.SI"
      ],
      "primary_category": "cs.AI",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2412.00020v1",
      "published_date": "2024-11-16 11:30:53 UTC",
      "updated_date": "2024-11-16 11:30:53 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-21T01:12:56.472752"
    },
    {
      "arxiv_id": "2411.12761v1",
      "title": "AI-Empowered Human Research Integrating Brain Science and Social Sciences Insights",
      "title_zh": "翻译失败",
      "authors": [
        "Feng Xiong",
        "Xinguo Yu",
        "Hon Wai Leong"
      ],
      "abstract": "This paper explores the transformative role of artificial intelligence (AI)\nin enhancing scientific research, particularly in the fields of brain science\nand social sciences. We analyze the fundamental aspects of human research and\nargue that it is high time for researchers to transition to human-AI joint\nresearch. Building upon this foundation, we propose two innovative research\nparadigms of human-AI joint research: \"AI-Brain Science Research Paradigm\" and\n\"AI-Social Sciences Research Paradigm\". In these paradigms, we introduce three\nhuman-AI collaboration models: AI as a research tool (ART), AI as a research\nassistant (ARA), and AI as a research participant (ARP). Furthermore, we\noutline the methods for conducting human-AI joint research. This paper seeks to\nredefine the collaborative interactions between human researchers and AI\nsystem, setting the stage for future research directions and sparking\ninnovation in this interdisciplinary field.",
      "tldr_zh": "这篇论文探讨了人工智能（AI）在脑科学和社会科学研究中的变革作用，主张从传统人类研究转向人类-AI 联合研究。论文提出两个创新范式：\"AI-Brain Science Research Paradigm\" 和 \"AI-Social Sciences Research Paradigm\"，并引入三种协作模型：AI as a research tool (ART)、AI as a research assistant (ARA) 和 AI as a research participant (ARP)。此外，它概述了进行人类-AI 联合研究的方法，以重新定义研究者与 AI 系统的互动，并为跨学科领域的未来创新奠定基础。",
      "categories": [
        "cs.HC",
        "cs.AI"
      ],
      "primary_category": "cs.HC",
      "comment": "Accepted to IEIR 2024, 10 pages, 4 figures",
      "pdf_url": "http://arxiv.org/pdf/2411.12761v1",
      "published_date": "2024-11-16 11:13:23 UTC",
      "updated_date": "2024-11-16 11:13:23 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-21T01:13:11.358897"
    },
    {
      "arxiv_id": "2411.10772v1",
      "title": "MRI Parameter Mapping via Gaussian Mixture VAE: Breaking the Assumption of Independent Pixels",
      "title_zh": "翻译失败",
      "authors": [
        "Moucheng Xu",
        "Yukun Zhou",
        "Tobias Goodwin-Allcock",
        "Kimia Firoozabadi",
        "Joseph Jacob",
        "Daniel C. Alexander",
        "Paddy J. Slator"
      ],
      "abstract": "We introduce and demonstrate a new paradigm for quantitative parameter\nmapping in MRI. Parameter mapping techniques, such as diffusion MRI and\nquantitative MRI, have the potential to robustly and repeatably measure\nbiologically-relevant tissue maps that strongly relate to underlying\nmicrostructure. Quantitative maps are calculated by fitting a model to multiple\nimages, e.g. with least-squares or machine learning. However, the overwhelming\nmajority of model fitting techniques assume that each voxel is independent,\nignoring any co-dependencies in the data. This makes model fitting sensitive to\nvoxelwise measurement noise, hampering reliability and repeatability. We\npropose a self-supervised deep variational approach that breaks the assumption\nof independent pixels, leveraging redundancies in the data to effectively\nperform data-driven regularisation of quantitative maps. We demonstrate that\nour approach outperforms current model fitting techniques in dMRI simulations\nand real data. Especially with a Gaussian mixture prior, our model enables\nsharper quantitative maps, revealing finer anatomical details that are not\npresented in the baselines. Our approach can hence support the clinical\nadoption of parameter mapping methods such as dMRI and qMRI.",
      "tldr_zh": "本文提出了一种新的MRI参数映射范式，使用Gaussian Mixture VAE打破独立像素假设，通过自监督深度变分方法利用数据冗余进行数据驱动的正则化，从而提升定量地图的可靠性和重复性。在dMRI模拟和真实数据实验中，该方法优于传统模型拟合技术，能生成更锐利的定量地图，揭示更多细微解剖细节。最终，这有助于推动dMRI和qMRI等参数映射方法在临床上的采用。",
      "categories": [
        "eess.IV",
        "cs.AI",
        "cs.CV",
        "cs.LG",
        "stat.ML"
      ],
      "primary_category": "eess.IV",
      "comment": "NeurIPS 2024 Workshop in Machine Learning and the Physical Sciences",
      "pdf_url": "http://arxiv.org/pdf/2411.10772v1",
      "published_date": "2024-11-16 11:11:36 UTC",
      "updated_date": "2024-11-16 11:11:36 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-21T01:13:20.019184"
    },
    {
      "arxiv_id": "2412.12102v1",
      "title": "Distributed Collaborative Inference System in Next-Generation Networks and Communication",
      "title_zh": "下一代网络和通信",
      "authors": [
        "Chuan Zhang",
        "Xixi Zheng",
        "Xiaolong Tao",
        "Chenfei Hu",
        "Weiting Zhang",
        "Liehuang Zhu"
      ],
      "abstract": "With the rapid advancement of artificial intelligence, generative artificial\nintelligence (GAI) has taken a leading role in transforming data processing\nmethods. However, the high computational demands of GAI present challenges for\ndevices with limited resources. As we move towards the sixth generation of\nmobile networks (6G), the higher data rates and improved energy efficiency of\n6G create a need for more efficient data processing in GAI. Traditional GAI,\nhowever, shows its limitations in meeting these demands. To address these\nchallenges, we introduce a multi-level collaborative inference system designed\nfor next-generation networks and communication. Our proposed system features a\ndeployment strategy that assigns models of varying sizes to devices at\ndifferent network layers. Then, we design a task offloading strategy to\noptimise both efficiency and latency. Furthermore, a modified early exit\nmechanism is implemented to enhance the inference process for single models.\nExperimental results demonstrate that our system effectively reduces inference\nlatency while maintaining high-quality output. Specifically, compared to\nexisting work, our system can reduce inference time by up to 17% without\nsacrificing the inference accuracy.",
      "tldr_zh": "该研究针对生成式人工智能(GAI)在6G网络环境中面临的计算需求高和资源限制问题，提出了一种多级协作推理系统。该系统包括模型部署策略（将不同大小的模型分配到网络层）、任务卸载策略（优化效率和延迟），以及修改的早期退出机制，以提升推理过程。实验结果表明，与现有方法相比，该系统可将推理时间减少多达17%，同时保持高准确性。",
      "categories": [
        "cs.NI",
        "cs.AI"
      ],
      "primary_category": "cs.NI",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2412.12102v1",
      "published_date": "2024-11-16 10:48:12 UTC",
      "updated_date": "2024-11-16 10:48:12 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-21T01:13:31.526694"
    },
    {
      "arxiv_id": "2411.14458v1",
      "title": "Improving training time and GPU utilization in geo-distributed language model training",
      "title_zh": "翻译失败",
      "authors": [
        "Palak",
        "Rohan Gandhi",
        "Karan Tandon",
        "Debopam Bhattacherjee",
        "Venkata N. Padmanabhan"
      ],
      "abstract": "The widespread adoption of language models (LMs) across multiple industries\nhas caused huge surge in demand for GPUs. Training LMs requires tens of\nthousands of GPUs and housing them in the same datacenter (DCs) is becoming\nchallenging. We focus on training such models across multiple DCs connected via\nWide-Area-Network (WAN). We build ATLAS that speeds up such training time using\nnovel temporal bandwidth sharing and many other design choices. While ATLAS\nimproves the training time, it does not eliminate the bubbles (idle GPU\ncycles). We built BUBBLETEA that runs prefill-as-a-service (part of LM\ninference) during the bubbles that improves the GPU utilization substantially\nwithout any impact of training. Together, ATLAS and BUBBLETEA improve training\ntime by up to 17X and achieve GPU utilization of up to 94%.",
      "tldr_zh": "该研究针对地理分布的语言模型 (LMs) 训练问题，解决了多数据中心 (DCs) 通过广域网 (WAN) 连接时面临的 GPU 需求和利用率挑战。论文提出 ATLAS 系统，通过新型的临时带宽共享 (temporal bandwidth sharing) 和其他设计选择，显著加速训练过程。进一步，BUBBLETEA 系统利用训练中的 GPU 空闲周期 (bubbles) 运行 prefill-as-a-service 服务，从而在不影响训练的情况下大幅提高 GPU 利用率。总体结果显示，ATLAS 和 BUBBLETEA 组合可将训练时间缩短多达 17 倍，并实现高达 94% 的 GPU 利用率。",
      "categories": [
        "cs.DC",
        "cs.AI",
        "cs.LG"
      ],
      "primary_category": "cs.DC",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2411.14458v1",
      "published_date": "2024-11-16 10:15:01 UTC",
      "updated_date": "2024-11-16 10:15:01 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-21T01:13:45.308752"
    },
    {
      "arxiv_id": "2411.10754v1",
      "title": "Integrated Machine Learning and Survival Analysis Modeling for Enhanced Chronic Kidney Disease Risk Stratification",
      "title_zh": "翻译失败",
      "authors": [
        "Zachary Dana",
        "Ahmed Ammar Naseer",
        "Botros Toro",
        "Sumanth Swaminathan"
      ],
      "abstract": "Chronic kidney disease (CKD) is a significant public health challenge, often\nprogressing to end-stage renal disease (ESRD) if not detected and managed\nearly. Early intervention, warranted by silent disease progression, can\nsignificantly reduce associated morbidity, mortality, and financial burden. In\nthis study, we propose a novel approach to modeling CKD progression using a\ncombination of machine learning techniques and classical statistical models.\nBuilding on the work of Liu et al. (2023), we evaluate linear models,\ntree-based methods, and deep learning models to extract novel predictors for\nCKD progression, with feature importance assessed using Shapley values. These\nnewly identified predictors, integrated with established clinical features from\nthe Kidney Failure Risk Equation, are then applied within the framework of Cox\nproportional hazards models to predict CKD progression.",
      "tldr_zh": "这篇论文针对慢性肾病 (CKD) 的风险分层，提出了一种整合机器学习和生存分析的创新建模方法，以实现早期干预并降低进展至终末期肾病 (ESRD) 的风险。研究基于 Liu et al. (2023) 的工作，使用线性模型、树-based 方法和深度学习模型提取新预测因子，并通过 Shapley values 评估特征重要性。接着，将这些因子与 Kidney Failure Risk Equation 的临床特征整合到 Cox 比例风险模型中，旨在提升 CKD 进展预测的准确性和实用性。",
      "categories": [
        "cs.LG",
        "cs.AI",
        "stat.CO",
        "stat.ML"
      ],
      "primary_category": "cs.LG",
      "comment": "Findings paper presented at Machine Learning for Health (ML4H)\n  symposium 2024, December 15-16, 2024, Vancouver, Canada, 19 pages",
      "pdf_url": "http://arxiv.org/pdf/2411.10754v1",
      "published_date": "2024-11-16 09:22:06 UTC",
      "updated_date": "2024-11-16 09:22:06 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-21T01:13:57.265627"
    },
    {
      "arxiv_id": "2411.10753v1",
      "title": "Chain-of-Programming (CoP) : Empowering Large Language Models for Geospatial Code Generation",
      "title_zh": "翻译失败",
      "authors": [
        "Shuyang Hou",
        "Haoyue Jiao",
        "Zhangxiao Shen",
        "Jianyuan Liang",
        "Anqi Zhao",
        "Xiaopu Zhang",
        "Jianxun Wang",
        "Huayi Wu"
      ],
      "abstract": "With the rapid growth of interdisciplinary demands for geospatial modeling\nand the rise of large language models (LLMs), geospatial code generation\ntechnology has seen significant advancements. However, existing LLMs often face\nchallenges in the geospatial code generation process due to incomplete or\nunclear user requirements and insufficient knowledge of specific platform\nsyntax rules, leading to the generation of non-executable code, a phenomenon\nknown as \"code hallucination.\" To address this issue, this paper proposes a\nChain of Programming (CoP) framework, which decomposes the code generation\nprocess into five steps: requirement analysis, algorithm design, code\nimplementation, code debugging, and code annotation. The framework incorporates\na shared information pool, knowledge base retrieval, and user feedback\nmechanisms, forming an end-to-end code generation flow from requirements to\ncode without the need for model fine-tuning. Based on a geospatial problem\nclassification framework and evaluation benchmarks, the CoP strategy\nsignificantly improves the logical clarity, syntactical correctness, and\nexecutability of the generated code, with improvements ranging from 3.0% to\n48.8%. Comparative and ablation experiments further validate the superiority of\nthe CoP strategy over other optimization approaches and confirm the rationality\nand necessity of its key components. Through case studies on building data\nvisualization and fire data analysis, this paper demonstrates the application\nand effectiveness of CoP in various geospatial scenarios. The CoP framework\noffers a systematic, step-by-step approach to LLM-based geospatial code\ngeneration tasks, significantly enhancing code generation performance in\ngeospatial tasks and providing valuable insights for code generation in other\nvertical domains.",
      "tldr_zh": "本研究针对大语言模型(LLMs)在地理空间代码生成中的挑战，如不完整用户需求和平台语法规则不足导致的“code hallucination”，提出Chain of Programming (CoP)框架。该框架将代码生成过程分解为五个步骤：需求分析、算法设计、代码实现、代码调试和代码注释，并整合共享信息池、知识库检索以及用户反馈机制，形成无需模型微调的端到端流程。实验结果显示，CoP显著提升了生成的代码逻辑清晰度、语法正确性和可执行性，提高幅度达3.0%至48.8%，并通过比较实验和案例研究（如建筑数据可视化和火灾数据分析）验证其在地理空间任务中的优越性。该框架为LLMs在垂直领域的代码生成提供了一个系统化的步步为营方法，具有广泛的启发意义。",
      "categories": [
        "cs.SE",
        "cs.AI",
        "cs.CL"
      ],
      "primary_category": "cs.SE",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2411.10753v1",
      "published_date": "2024-11-16 09:20:35 UTC",
      "updated_date": "2024-11-16 09:20:35 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-21T01:14:09.064381"
    },
    {
      "arxiv_id": "2411.10746v1",
      "title": "LTCXNet: Advancing Chest X-Ray Analysis with Solutions for Long-Tailed Multi-Label Classification and Fairness Challenges",
      "title_zh": "翻译失败",
      "authors": [
        "Chin-Wei Huang",
        "Mu-Yi Shen",
        "Kuan-Chang Shih",
        "Shih-Chih Lin",
        "Chi-Yu Chen",
        "Po-Chih Kuo"
      ],
      "abstract": "Chest X-rays (CXRs) often display various diseases with disparate class\nfrequencies, leading to a long-tailed, multi-label data distribution. In\nresponse to this challenge, we explore the Pruned MIMIC-CXR-LT dataset, a\ncurated collection derived from the MIMIC-CXR dataset, specifically designed to\nrepresent a long-tailed and multi-label data scenario. We introduce LTCXNet, a\nnovel framework that integrates the ConvNeXt model, ML-Decoder, and strategic\ndata augmentation, further enhanced by an ensemble approach. We demonstrate\nthat LTCXNet improves the performance of CXR interpretation across all classes,\nespecially enhancing detection in rarer classes like `Pneumoperitoneum' and\n`Pneumomediastinum' by 79\\% and 48\\%, respectively. Beyond performance metrics,\nour research extends into evaluating fairness, highlighting that some methods,\nwhile improving model accuracy, could inadvertently affect fairness across\ndifferent demographic groups negatively. This work contributes to advancing the\nunderstanding and management of long-tailed, multi-label data distributions in\nmedical imaging, paving the way for more equitable and effective diagnostic\ntools.",
      "tldr_zh": "本研究针对胸部X光片（CXRs）的长尾多标签分类问题，引入LTCXNet框架，该框架整合ConvNeXt模型、ML-Decoder以及战略数据增强和集成方法，使用Pruned MIMIC-CXR-LT数据集进行优化。LTCXNet显著提升了CXR解释性能，尤其在稀有类别如Pneumoperitoneum和Pneumomediastinum的检测上，分别提高了79%和48%。此外，该工作评估了模型公平性，指出某些提升准确率的方法可能负面影响不同人口群体的公平性，从而为医疗成像中的长尾数据管理提供更公平有效的诊断工具。",
      "categories": [
        "cs.CV",
        "cs.AI"
      ],
      "primary_category": "cs.CV",
      "comment": "8 pages, 5 figures",
      "pdf_url": "http://arxiv.org/pdf/2411.10746v1",
      "published_date": "2024-11-16 08:59:20 UTC",
      "updated_date": "2024-11-16 08:59:20 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-21T01:14:21.377540"
    },
    {
      "arxiv_id": "2411.10744v1",
      "title": "Digital-Analog Quantum Machine Learning",
      "title_zh": "数字-模拟量子机器学习",
      "authors": [
        "Lucas Lamata"
      ],
      "abstract": "Machine Learning algorithms are extensively used in an increasing number of\nsystems, applications, technologies, and products, both in industry and in\nsociety as a whole. They enable computing devices to learn from previous\nexperience and therefore improve their performance in a certain context or\nenvironment. In this way, many useful possibilities have been made accessible.\nHowever, dealing with an increasing amount of data poses difficulties for\nclassical devices. Quantum systems may offer a way forward, possibly enabling\nto scale up machine learning calculations in certain contexts. On the other\nhand, quantum systems themselves are also hard to scale up, due to decoherence\nand the fragility of quantum superpositions. In the short and mid term, it has\nbeen evidenced that a quantum paradigm that combines evolution under large\nanalog blocks with discrete quantum gates, may be fruitful to achieve new\nknowledge of classical and quantum systems with no need of having a\nfault-tolerant quantum computer. In this Perspective, we review some recent\nworks that employ this digital-analog quantum paradigm to carry out efficient\nmachine learning calculations with current quantum devices.",
      "tldr_zh": "本论文探讨了数字-模拟量子范式（digital-analog quantum paradigm）在机器学习（Machine Learning）中的应用，以解决经典设备处理海量数据时的挑战。作者指出，量子系统虽可提升机器学习计算的规模，但受decoherence和量子叠加脆弱性等因素限制。该范式通过结合大型模拟块和离散量子门，实现了在当前量子设备上进行高效机器学习计算，无需依赖容错量子计算机（fault-tolerant quantum computer），并回顾了相关最近研究的工作和潜在益处。",
      "categories": [
        "quant-ph",
        "cs.AI"
      ],
      "primary_category": "quant-ph",
      "comment": "Invited Perspective for Advanced Intelligent Discovery",
      "pdf_url": "http://arxiv.org/pdf/2411.10744v1",
      "published_date": "2024-11-16 08:54:52 UTC",
      "updated_date": "2024-11-16 08:54:52 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-21T01:14:31.835401"
    },
    {
      "arxiv_id": "2411.10741v1",
      "title": "MetaLA: Unified Optimal Linear Approximation to Softmax Attention Map",
      "title_zh": "翻译失败",
      "authors": [
        "Yuhong Chou",
        "Man Yao",
        "Kexin Wang",
        "Yuqi Pan",
        "Ruijie Zhu",
        "Yiran Zhong",
        "Yu Qiao",
        "Jibin Wu",
        "Bo Xu",
        "Guoqi Li"
      ],
      "abstract": "Various linear complexity models, such as Linear Transformer (LinFormer),\nState Space Model (SSM), and Linear RNN (LinRNN), have been proposed to replace\nthe conventional softmax attention in Transformer structures. However, the\noptimal design of these linear models is still an open question. In this work,\nwe attempt to answer this question by finding the best linear approximation to\nsoftmax attention from a theoretical perspective. We start by unifying existing\nlinear complexity models as the linear attention form and then identify three\nconditions for the optimal linear attention design: 1) Dynamic memory ability;\n2) Static approximation ability; 3) Least parameter approximation. We find that\nnone of the current linear models meet all three conditions, resulting in\nsuboptimal performance. Instead, we propose Meta Linear Attention (MetaLA) as a\nsolution that satisfies these conditions. Our experiments on Multi-Query\nAssociative Recall (MQAR) task, language modeling, image classification, and\nLong-Range Arena (LRA) benchmark demonstrate that MetaLA is more effective than\nthe existing linear models.",
      "tldr_zh": "本文探讨了线性复杂度模型（如 Linear Transformer、State Space Model (SSM) 和 Linear RNN）在替换 Transformer 中 softmax attention 的挑战，并从理论角度统一这些模型为线性 attention 形式。作者提出了三个优化条件：Dynamic memory ability、Static approximation ability 和 Least parameter approximation，但现有模型均未完全满足，导致性能不佳。为此，提出 MetaLA 模型，该模型满足所有条件，能够实现最佳线性近似。实验结果显示，MetaLA 在 Multi-Query Associative Recall (MQAR) 任务、语言建模、图像分类和 Long-Range Arena (LRA) 基准上，比现有模型更有效。",
      "categories": [
        "cs.LG",
        "cs.AI"
      ],
      "primary_category": "cs.LG",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2411.10741v1",
      "published_date": "2024-11-16 08:47:32 UTC",
      "updated_date": "2024-11-16 08:47:32 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-21T01:14:44.427850"
    },
    {
      "arxiv_id": "2412.02702v1",
      "title": "Fine Tuning Swimming Locomotion Learned from Mosquito Larvae",
      "title_zh": "翻译失败",
      "authors": [
        "Pranav Rajbhandari",
        "Karthick Dhileep",
        "Sridhar Ravi",
        "Donald Sofge"
      ],
      "abstract": "In prior research, we analyzed the backwards swimming motion of mosquito\nlarvae, parameterized it, and replicated it in a Computational Fluid Dynamics\n(CFD) model. Since the parameterized swimming motion is copied from observed\nlarvae, it is not necessarily the most efficient locomotion for the model of\nthe swimmer. In this project, we further optimize this copied solution for the\nswimmer model. We utilize Reinforcement Learning to guide local parameter\nupdates. Since the majority of the computation cost arises from the CFD model,\nwe additionally train a deep learning model to replicate the forces acting on\nthe swimmer model. We find that this method is effective at performing local\nsearch to improve the parameterized swimming locomotion.",
      "tldr_zh": "本研究针对蚊子幼虫的后向游泳运动参数化模型，使用 Reinforcement Learning 指导局部参数更新，以优化其在 Computational Fluid Dynamics (CFD) 模型中的效率。研究者训练了一个深度学习模型来模拟作用在游泳者模型上的力，从而降低主要来自 CFD 的计算成本。结果表明，这种方法在进行局部搜索方面非常有效，能够显著改进参数化的游泳运动。",
      "categories": [
        "cs.NE",
        "cs.AI"
      ],
      "primary_category": "cs.NE",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2412.02702v1",
      "published_date": "2024-11-16 06:54:43 UTC",
      "updated_date": "2024-11-16 06:54:43 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-21T01:14:55.843198"
    },
    {
      "arxiv_id": "2411.10696v1",
      "title": "HELENE: Hessian Layer-wise Clipping and Gradient Annealing for Accelerating Fine-tuning LLM with Zeroth-order Optimization",
      "title_zh": "翻译失败",
      "authors": [
        "Huaqin Zhao",
        "Jiaxi Li",
        "Yi Pan",
        "Shizhe Liang",
        "Xiaofeng Yang",
        "Wei Liu",
        "Xiang Li",
        "Fei Dou",
        "Tianming Liu",
        "Jin Lu"
      ],
      "abstract": "Fine-tuning large language models (LLMs) poses significant memory challenges,\nas the back-propagation process demands extensive resources, especially with\ngrowing model sizes. Recent work, MeZO, addresses this issue using a\nzeroth-order (ZO) optimization method, which reduces memory consumption by\nmatching the usage to the inference phase. However, MeZO experiences slow\nconvergence due to varying curvatures across model parameters. To overcome this\nlimitation, we introduce HELENE, a novel scalable and memory-efficient\noptimizer that integrates annealed A-GNB gradients with a diagonal Hessian\nestimation and layer-wise clipping, serving as a second-order pre-conditioner.\nThis combination allows for faster and more stable convergence. Our theoretical\nanalysis demonstrates that HELENE improves convergence rates, particularly for\nmodels with heterogeneous layer dimensions, by reducing the dependency on the\ntotal parameter space dimension. Instead, the method scales with the largest\nlayer dimension, making it highly suitable for modern LLM architectures.\nExperimental results on RoBERTa-large and OPT-1.3B across multiple tasks show\nthat HELENE achieves up to a 20x speedup compared to MeZO, with average\naccuracy improvements of 1.5%. Furthermore, HELENE remains compatible with both\nfull parameter tuning and parameter-efficient fine-tuning (PEFT), outperforming\nseveral state-of-the-art optimizers. The codes will be released after\nreviewing.",
      "tldr_zh": "该论文提出 HELENE，一种新型优化器，用于加速大型语言模型 (LLMs) 的 fine-tuning，通过整合 annealed A-GNB gradients、diagonal Hessian estimation 和 layer-wise clipping 作为 second-order pre-conditioner，以解决 zeroth-order optimization 方法（如 MeZO）中收敛缓慢的问题。HELENE 通过理论分析减少了对总参数空间的依赖，转而关注最大层维度，从而实现更快、更稳定的收敛。实验结果显示，在 RoBERTa-large 和 OPT-1.3B 模型上，HELENE 比 MeZO 快 20 倍，平均准确率提升 1.5%，并兼容全参数调优和参数高效 fine-tuning (PEFT)，优于现有优化器。",
      "categories": [
        "cs.LG",
        "cs.AI"
      ],
      "primary_category": "cs.LG",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2411.10696v1",
      "published_date": "2024-11-16 04:27:22 UTC",
      "updated_date": "2024-11-16 04:27:22 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-21T01:15:09.716205"
    },
    {
      "arxiv_id": "2411.10692v1",
      "title": "DEBUG-HD: Debugging TinyML models on-device using Hyper-Dimensional computing",
      "title_zh": "DEBUG-HD：使用超维计算在设备上调试 TinyML 模型",
      "authors": [
        "Nikhil P Ghanathe",
        "Steven J E Wilton"
      ],
      "abstract": "TinyML models often operate in remote, dynamic environments without cloud\nconnectivity, making them prone to failures. Ensuring reliability in such\nscenarios requires not only detecting model failures but also identifying their\nroot causes. However, transient failures, privacy concerns, and the\nsafety-critical nature of many applications-where systems cannot be interrupted\nfor debugging-complicate the use of raw sensor data for offline analysis. We\npropose DEBUG-HD, a novel, resource-efficient on-device debugging approach\noptimized for KB-sized tinyML devices that utilizes hyper-dimensional computing\n(HDC). Our method introduces a new HDC encoding technique that leverages\nconventional neural networks, allowing DEBUG-HD to outperform prior binary HDC\nmethods by 27% on average in detecting input corruptions across various image\nand audio datasets.",
      "tldr_zh": "该研究针对 TinyML 模型在远程动态环境中的易失败问题，提出了一种资源高效的设备上调试方法 DEBUG-HD，利用 Hyper-Dimensional computing (HDC) 来检测模型失败并识别根因。DEBUG-HD 引入了一种新颖的 HDC 编码技术，结合传统 neural networks，在各种图像和音频数据集上平均比先前二进制 HDC 方法提高了 27% 的输入损坏检测性能。该方法特别适合 KB-sized TinyML 设备，解决了隐私和安全关键应用的调试挑战，为可靠的 TinyML 部署提供了基础。",
      "categories": [
        "cs.LG",
        "cs.AI",
        "cs.NE"
      ],
      "primary_category": "cs.LG",
      "comment": "Accepted at the Machine Learning for Systems Workshop at NeurIPS 2024",
      "pdf_url": "http://arxiv.org/pdf/2411.10692v1",
      "published_date": "2024-11-16 04:03:22 UTC",
      "updated_date": "2024-11-16 04:03:22 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-21T01:15:20.185714"
    },
    {
      "arxiv_id": "2411.12759v1",
      "title": "A Novel Approach to Eliminating Hallucinations in Large Language Model-Assisted Causal Discovery",
      "title_zh": "一种",
      "authors": [
        "Grace Sng",
        "Yanming Zhang",
        "Klaus Mueller"
      ],
      "abstract": "The increasing use of large language models (LLMs) in causal discovery as a\nsubstitute for human domain experts highlights the need for optimal model\nselection. This paper presents the first hallucination survey of popular LLMs\nfor causal discovery. We show that hallucinations exist when using LLMs in\ncausal discovery so the choice of LLM is important. We propose using Retrieval\nAugmented Generation (RAG) to reduce hallucinations when quality data is\navailable. Additionally, we introduce a novel method employing multiple LLMs\nwith an arbiter in a debate to audit edges in causal graphs, achieving a\ncomparable reduction in hallucinations to RAG.",
      "tldr_zh": "本研究首次调查了大型语言模型（LLMs）在因果发现（Causal Discovery）中的幻觉（Hallucinations）问题，发现这些幻觉普遍存在，且模型选择至关重要。作者提出使用检索增强生成（RAG）技术来减少幻觉，尤其在高质量数据可用时；同时，引入一种新方法，通过多个 LLMs 进行辩论并由仲裁者（Arbiter）审核因果图中的边，实现与 RAG 相当的幻觉减少效果。该方法为提升 LLMs 在因果发现领域的可靠性和准确性提供了有效途径。",
      "categories": [
        "cs.CL",
        "cs.AI"
      ],
      "primary_category": "cs.CL",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2411.12759v1",
      "published_date": "2024-11-16 03:06:39 UTC",
      "updated_date": "2024-11-16 03:06:39 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-21T01:15:31.955202"
    },
    {
      "arxiv_id": "2411.10676v2",
      "title": "Exploring Feature-based Knowledge Distillation for Recommender System: A Frequency Perspective",
      "title_zh": "翻译失败",
      "authors": [
        "Zhangchi Zhu",
        "Wei Zhang"
      ],
      "abstract": "In this paper, we analyze the feature-based knowledge distillation for\nrecommendation from the frequency perspective. By defining knowledge as\ndifferent frequency components of the features, we theoretically demonstrate\nthat regular feature-based knowledge distillation is equivalent to equally\nminimizing losses on all knowledge and further analyze how this equal loss\nweight allocation method leads to important knowledge being overlooked. In\nlight of this, we propose to emphasize important knowledge by redistributing\nknowledge weights. Furthermore, we propose FreqD, a lightweight knowledge\nreweighting method, to avoid the computational cost of calculating losses on\neach knowledge. Extensive experiments demonstrate that FreqD consistently and\nsignificantly outperforms state-of-the-art knowledge distillation methods for\nrecommender systems. Our code is available at https://github.com/woriazzc/KDs.",
      "tldr_zh": "本论文从频率视角探讨了基于特征的知识蒸馏（feature-based knowledge distillation）在推荐系统（recommender system）中的应用，通过将知识定义为特征的不同频率组件，理论证明了常规方法等量最小化损失会导致重要知识被忽略。针对这一问题，作者提出重新分配知识权重的方法，并设计了轻量级的 FreqD 算法，以避免计算每个知识损失的额外开销。实验结果显示，FreqD 在推荐系统中显著优于现有知识蒸馏方法，代码已开源。",
      "categories": [
        "cs.IR",
        "cs.AI",
        "cs.LG"
      ],
      "primary_category": "cs.IR",
      "comment": "ACM KDD 2025 Accepted",
      "pdf_url": "http://arxiv.org/pdf/2411.10676v2",
      "published_date": "2024-11-16 02:41:12 UTC",
      "updated_date": "2025-01-13 09:10:18 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-21T01:15:43.540220"
    },
    {
      "arxiv_id": "2411.10666v3",
      "title": "SAM Decoding: Speculative Decoding via Suffix Automaton",
      "title_zh": "翻译失败",
      "authors": [
        "Yuxuan Hu",
        "Ke Wang",
        "Xiaokang Zhang",
        "Fanjin Zhang",
        "Cuiping Li",
        "Hong Chen",
        "Jing Zhang"
      ],
      "abstract": "Speculative decoding (SD) has been demonstrated as an effective technique for\nlossless LLM inference acceleration. Retrieval-based SD methods, one kind of\nmodel-free method, have yielded promising speedup, but they often rely on\nincomplete retrieval resources, inefficient retrieval methods, and are\nconstrained to certain domains. This paper presents a novel retrieval-based\nspeculative decoding method that adapts suffix automaton (SAM) for efficient\nand accurate draft generation by utilizing common text corpus and dynamic text\nsequence. Unlike existing $n$-gram matching methods, SAM-Decoding finds the\nexact longest suffix match, achieving an average time complexity of O(1) per\ngeneration step of SAM update and suffix retrieval. It can also integrate with\nexisting methods, adaptively selecting a draft generation strategy based on\nmatch length to generalize to broader domains. Extensive experiments on\nSpec-Bench show that our method is $18\\%+$ faster than other retrieval-based SD\nmethods. Additionally, when combined with advanced EAGLE-2, it provides an\nadditional speedup of $3.28\\%$ -- $11.13\\%$ across various-sized LLM backbones.\nOur code is available at our\n\\href{https://github.com/hyx1999/SAM-Decoding}{repository}.",
      "tldr_zh": "本研究提出了一种新型检索-based 推测解码(Speculative Decoding)方法，名为 SAM-Decoding，利用后缀自动机(Suffix Automaton)从常见文本语料和动态文本序列中生成高效准确的草稿，以加速大型语言模型(LLM)的无损推理。不同于传统的 n-gram 匹配方法，该方法通过精确查找最长后缀匹配，实现每步生成的操作平均时间复杂度为 O(1)，并能与现有技术整合，根据匹配长度自适应选择策略，适用于更广泛的领域。在 Spec-Bench 上的实验显示，SAM-Decoding 比其他检索-based 方法快 18% 以上；当与 EAGLE-2 结合时，为不同规模的 LLM 提供 3.28% 到 11.13% 的额外加速。",
      "categories": [
        "cs.CL",
        "cs.AI",
        "I.2.7"
      ],
      "primary_category": "cs.CL",
      "comment": "16 pages, 9 figures, 9 tables",
      "pdf_url": "http://arxiv.org/pdf/2411.10666v3",
      "published_date": "2024-11-16 02:02:49 UTC",
      "updated_date": "2024-12-16 10:48:28 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-21T01:15:56.213967"
    },
    {
      "arxiv_id": "2411.10654v1",
      "title": "Pluralistic Alignment Over Time",
      "title_zh": "翻译失败",
      "authors": [
        "Toryn Q. Klassen",
        "Parand A. Alamdari",
        "Sheila A. McIlraith"
      ],
      "abstract": "If an AI system makes decisions over time, how should we evaluate how aligned\nit is with a group of stakeholders (who may have conflicting values and\npreferences)? In this position paper, we advocate for consideration of temporal\naspects including stakeholders' changing levels of satisfaction and their\npossibly temporally extended preferences. We suggest how a recent approach to\nevaluating fairness over time could be applied to a new form of pluralistic\nalignment: temporal pluralism, where the AI system reflects different\nstakeholders' values at different times.",
      "tldr_zh": "这篇论文探讨了AI系统在时间维度上如何与具有冲突值和偏好的利益相关者群体保持多元一致性（Pluralistic Alignment）。作者主张评估时需考虑利益相关者的满意度变化以及时间延伸偏好，以实现更全面的动态评估。论文建议将一种现有的时间公平性评估方法应用于temporal pluralism，使AI系统在不同时间段内反映不同利益相关者的值，从而提升系统的适应性和公平性。",
      "categories": [
        "cs.AI",
        "cs.CY",
        "cs.LG"
      ],
      "primary_category": "cs.AI",
      "comment": "Pluralistic Alignment Workshop at NeurIPS 2024",
      "pdf_url": "http://arxiv.org/pdf/2411.10654v1",
      "published_date": "2024-11-16 01:23:25 UTC",
      "updated_date": "2024-11-16 01:23:25 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-21T01:16:07.856716"
    },
    {
      "arxiv_id": "2411.10651v1",
      "title": "Understanding Learning with Sliced-Wasserstein Requires Rethinking Informative Slices",
      "title_zh": "理解使用 Sliced-Wasserstein 的学习需要重新审视信息丰富的切片",
      "authors": [
        "Huy Tran",
        "Yikun Bai",
        "Ashkan Shahbazi",
        "John R. Hershey",
        "Soheil Kolouri"
      ],
      "abstract": "The practical applications of Wasserstein distances (WDs) are constrained by\ntheir sample and computational complexities. Sliced-Wasserstein distances\n(SWDs) provide a workaround by projecting distributions onto one-dimensional\nsubspaces, leveraging the more efficient, closed-form WDs for one-dimensional\ndistributions. However, in high dimensions, most random projections become\nuninformative due to the concentration of measure phenomenon. Although several\nSWD variants have been proposed to focus on \\textit{informative} slices, they\noften introduce additional complexity, numerical instability, and compromise\ndesirable theoretical (metric) properties of SWD. Amidst the growing literature\nthat focuses on directly modifying the slicing distribution, which often face\nchallenges, we revisit the classical Sliced-Wasserstein and propose instead to\nrescale the 1D Wasserstein to make all slices equally informative. Importantly,\nwe show that with an appropriate data assumption and notion of \\textit{slice\ninformativeness}, rescaling for all individual slices simplifies to \\textbf{a\nsingle global scaling factor} on the SWD. This, in turn, translates to the\nstandard learning rate search for gradient-based learning in common machine\nlearning workflows. We perform extensive experiments across various machine\nlearning tasks showing that the classical SWD, when properly configured, can\noften match or surpass the performance of more complex variants. We then answer\nthe following question: \"Is Sliced-Wasserstein all you need for common learning\ntasks?\"",
      "tldr_zh": "本文研究发现，Sliced-Wasserstein distances (SWDs) 通过将分布投影到一维子空间来解决Wasserstein distances (WDs)的计算复杂性问题，但高维空间中的随机投影往往因measure phenomenon而变得不信息性，导致现有SWD变体引入额外复杂性和不稳定性。作者提出一种创新方法，通过重新缩放一维Wasserstein，使所有切片同样信息性，并证明这可简化为SWD上的单一全局缩放因子，从而与机器学习的标准学习率搜索兼容。实验结果显示，正确配置的经典SWD在多种机器学习任务中能匹配或超越更复杂的变体，引发了对“SWD是否足以应对常见学习任务”的思考。",
      "categories": [
        "cs.LG",
        "cs.AI",
        "cs.CV",
        "stat.AP",
        "stat.CO",
        "stat.ML"
      ],
      "primary_category": "cs.LG",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2411.10651v1",
      "published_date": "2024-11-16 01:18:27 UTC",
      "updated_date": "2024-11-16 01:18:27 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-21T01:16:21.445481"
    },
    {
      "arxiv_id": "2411.10639v2",
      "title": "MTA: Multimodal Task Alignment for BEV Perception and Captioning",
      "title_zh": "翻译失败",
      "authors": [
        "Yunsheng Ma",
        "Burhaneddin Yaman",
        "Xin Ye",
        "Jingru Luo",
        "Feng Tao",
        "Abhirup Mallik",
        "Ziran Wang",
        "Liu Ren"
      ],
      "abstract": "Bird's eye view (BEV)-based 3D perception plays a crucial role in autonomous\ndriving applications. The rise of large language models has spurred interest in\nBEV-based captioning to understand object behavior in the surrounding\nenvironment. However, existing approaches treat perception and captioning as\nseparate tasks, focusing on the performance of only one task and overlooking\nthe potential benefits of multimodal alignment. To bridge this gap between\nmodalities, we introduce MTA, a novel multimodal task alignment framework that\nboosts both BEV perception and captioning. MTA consists of two key components:\n(1) BEV-Language Alignment (BLA), a contextual learning mechanism that aligns\nthe BEV scene representations with ground-truth language representations, and\n(2) Detection-Captioning Alignment (DCA), a cross-modal prompting mechanism\nthat aligns detection and captioning outputs. MTA seamlessly integrates into\nstate-of-the-art baselines during training, adding no extra computational\ncomplexity at runtime. Extensive experiments on the nuScenes and TOD3Cap\ndatasets show that MTA significantly outperforms state-of-the-art baselines in\nboth tasks, achieving a 10.7% improvement in challenging rare perception\nscenarios and a 9.2% improvement in captioning. These results underscore the\neffectiveness of unified alignment in reconciling BEV-based perception and\ncaptioning.",
      "tldr_zh": "本研究提出MTA框架，用于多模态任务对齐，旨在提升BEV感知和描述任务在自动驾驶中的性能。MTA包括两个关键组件：BEV-Language Alignment (BLA)，通过上下文学习机制将BEV场景表示与真实语言表示对齐；以及Detection-Captioning Alignment (DCA)，通过跨模态提示机制将检测和描述输出整合。该框架在训练时无缝集成到现有基线中，不会增加运行时计算复杂性。在nuScenes和TOD3Cap数据集上的实验显示，MTA在稀有感知场景中提升10.7%的性能，在描述任务中提升9.2%，证明了统一对齐策略的有效性。",
      "categories": [
        "cs.CV",
        "cs.AI",
        "cs.CL",
        "cs.LG"
      ],
      "primary_category": "cs.CV",
      "comment": "10 pages",
      "pdf_url": "http://arxiv.org/pdf/2411.10639v2",
      "published_date": "2024-11-16 00:14:13 UTC",
      "updated_date": "2025-03-10 20:59:22 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-21T01:16:33.372741"
    },
    {
      "arxiv_id": "2411.10636v1",
      "title": "Gender Bias Mitigation for Bangla Classification Tasks",
      "title_zh": "性别偏见缓解在 Bangla",
      "authors": [
        "Sajib Kumar Saha Joy",
        "Arman Hassan Mahy",
        "Meherin Sultana",
        "Azizah Mamun Abha",
        "MD Piyal Ahmmed",
        "Yue Dong",
        "G M Shahariar"
      ],
      "abstract": "In this study, we investigate gender bias in Bangla pretrained language\nmodels, a largely under explored area in low-resource languages. To assess this\nbias, we applied gender-name swapping techniques to existing datasets, creating\nfour manually annotated, task-specific datasets for sentiment analysis,\ntoxicity detection, hate speech detection, and sarcasm detection. By altering\nnames and gender-specific terms, we ensured these datasets were suitable for\ndetecting and mitigating gender bias. We then proposed a joint loss\noptimization technique to mitigate gender bias across task-specific pretrained\nmodels. Our approach was evaluated against existing bias mitigation methods,\nwith results showing that our technique not only effectively reduces bias but\nalso maintains competitive accuracy compared to other baseline approaches. To\npromote further research, we have made both our implementation and datasets\npublicly available\nhttps://github.com/sajib-kumar/Gender-Bias-Mitigation-From-Bangla-PLM",
      "tldr_zh": "本研究调查了低资源语言 Bangla 预训练语言模型中的性别偏见（gender bias），通过性别名称交换技术创建了四个手动标注的数据集，用于情感分析、毒性检测、仇恨言论检测和讽刺检测任务。研究提出了一种联合损失优化（joint loss optimization）技术，在任务特定模型上缓解性别偏见，并与现有方法比较，结果显示该技术不仅有效降低了偏见，还保持了与基线方法相当的准确性。为促进进一步研究，研究团队公开了实现代码和数据集（https://github.com/sajib-kumar/Gender-Bias-Mitigation-From-Bangla-PLM）。",
      "categories": [
        "cs.CL",
        "cs.AI",
        "cs.LG"
      ],
      "primary_category": "cs.CL",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2411.10636v1",
      "published_date": "2024-11-16 00:04:45 UTC",
      "updated_date": "2024-11-16 00:04:45 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-21T01:16:44.210712"
    }
  ],
  "raw_papers_fetched": true,
  "papers_count": 41,
  "processed_papers_count": 41,
  "failed_papers_count": 0,
  "summary_generated": true,
  "daily_data_saved": true,
  "last_update": "2025-05-21T01:17:04.770778"
}