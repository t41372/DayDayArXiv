{
  "date": "2024-09-28",
  "category": "cs.AI",
  "summary": "欢迎来到 UTC 时间 2024-09-28 的 arXiv 中文 TLDR 快报！今天 arXiv 更新了 48 篇论文，主要聚焦 AI 和机器学习领域，包括强化学习、LLM 应用、隐私保护以及医疗 AI 等热门话题，令人印象深刻的是 Brain-JEPA（NeurIPS Spotlight，脑动态建模）和 CLIP-MoE（CLIP 混合专家模型），这些论文展示了 AI 在神经科学和多模态学习中的潜力，同时涉及知名学者如 Juan Helen Zhou 和 Yu Cheng 的工作。\n\n下面，我将挑选并简要讨论最具话题度和影响力的论文，先从 AI 模型、隐私与安全、机器人强化学习等核心领域入手，其他次要论文快速掠过。每篇论文会列出标题（中文 + 英文），并突出核心贡献和发现。\n\n### AI 模型与 LLM 应用\n- **Brain-JEPA：脑动态基础模型使用梯度定位和时空掩码** (Brain-JEPA: Brain Dynamics Foundation Model with Gradient Positioning and Spatiotemporal Masking)  \n  这篇 NeurIPS 2024 Spotlight 论文提出了一种新型脑动态模型，通过梯度定位和时空掩码提升了 fMRI 数据分析性能，实现状态级别的预测精度，并在人口统计和疾病诊断任务中表现出色，显著优于现有模型。\n\n- **CLIP-MoE：使用多样化多重升级构建 CLIP 的混合专家模型** (CLIP-MoE: Towards Building Mixture of Experts for CLIP with Diversified Multiplet Upcycling)  \n  论文引入多样化多重升级策略，从预训练 CLIP 模型高效生成混合专家架构，提升了图像分类和检索任务的性能，显著减少计算开销，是 CLIP 扩展的创新尝试。\n\n- **DOTA：基于分布的测试时适应视觉语言模型** (DOTA: Distributional Test-Time Adaptation of Vision-Language Models)  \n  该方法通过估计测试样本分布并结合贝叶斯定理，实现视觉语言模型（如 CLIP）的鲁棒适应，显著减少测试时遗忘问题，并在图像分类任务中提升准确率。\n\n### 隐私与安全\n- **FairPIVARA：减少和评估基于 CLIP 的多模态模型偏见** (FairPIVARA: Reducing and Assessing Biases in CLIP-Based Multimodal Models)  \n  论文提出 FairPIVARA 方法，通过移除特征嵌入中的偏见维度，减少多模态模型的歧视性高达 98%，并在零样本任务中提升模型平衡性，是 BMVC 2024 研讨会的重要贡献。\n\n- **Subject Data Auditing via Source Inference Attack in Cross-Silo Federated Learning** (Subject Data Auditing via Source Inference Attack in Cross-Silo Federated Learning)  \n  作者开发了 SLSIA 攻击框架，检测联邦学习中主体级隐私泄露，实现了高达 88% 的准确率，并讨论了差分隐私作为防御机制，强调了联邦学习的安全挑战。\n\n### 机器人与强化学习\n- **Spatial Reasoning and Planning for Deep Embodied Agents** (Spatial Reasoning and Planning for Deep Embodied Agents)  \n  这篇牛津大学博士论文的核心贡献是开发 CALVIN 和 SOAP 等算法，提升代理在 3D 环境的规划效率和可转移性，在迷宫和 Minecraft 任务中表现出色。\n\n- **SELP：使用大语言模型生成机器人代理的安全高效任务计划** (SELP: Generating Safe and Efficient Task Plans for Robot Agents with Large Language Models)  \n  论文引入等价投票和约束解码机制，使 LLM 生成的任务计划符合 LTL 逻辑，提升机器人导航和操作的安全率达 20%，是 ICRA 2025 的亮点。\n\n其他论文如药物提取的 INSIGHTBUDDY-AI（使用 LLM 和集成学习提升医疗 NLP）、眼动追踪的 See Where You Read（支持跳跃阅读的系统），以及一些强化学习优化如 Double Actor-Critic，都展示了 AI 在医疗和交互领域的潜力，但细节较常规，故快速掠过。总体而言，今天的更新突显 AI 模型的鲁棒性和应用扩展，值得关注 NeurIPS 和 EMNLP 相关工作。明天的快报见！",
  "papers": [
    {
      "arxiv_id": "2409.19479v1",
      "title": "Spatial Reasoning and Planning for Deep Embodied Agents",
      "title_zh": "深度具身代理的空间推理和规划",
      "authors": [
        "Shu Ishida"
      ],
      "abstract": "Humans can perform complex tasks with long-term objectives by planning,\nreasoning, and forecasting outcomes of actions. For embodied agents to achieve\nsimilar capabilities, they must gain knowledge of the environment transferable\nto novel scenarios with a limited budget of additional trial and error.\nLearning-based approaches, such as deep RL, can discover and take advantage of\ninherent regularities and characteristics of the application domain from data,\nand continuously improve their performances, however at a cost of large amounts\nof training data. This thesis explores the development of data-driven\ntechniques for spatial reasoning and planning tasks, focusing on enhancing\nlearning efficiency, interpretability, and transferability across novel\nscenarios. Four key contributions are made. 1) CALVIN, a differential planner\nthat learns interpretable models of the world for long-term planning. It\nsuccessfully navigated partially observable 3D environments, such as mazes and\nindoor rooms, by learning the rewards and state transitions from expert\ndemonstrations. 2) SOAP, an RL algorithm that discovers options unsupervised\nfor long-horizon tasks. Options segment a task into subtasks and enable\nconsistent execution of the subtask. SOAP showed robust performances on\nhistory-conditional corridor tasks as well as classical benchmarks such as\nAtari. 3) LangProp, a code optimisation framework using LLMs to solve embodied\nagent problems that require reasoning by treating code as learnable policies.\nThe framework successfully generated interpretable code with comparable or\nsuperior performance to human-written experts in the CARLA autonomous driving\nbenchmark. 4) Voggite, an embodied agent with a vision-to-action transformer\nbackend that solves complex tasks in Minecraft. It achieved third place in the\nMineRL BASALT Competition by identifying action triggers to segment tasks into\nmultiple stages.",
      "tldr_zh": "本论文探讨了为深度嵌入式代理开发空间推理和规划技术，旨在通过数据驱动方法提升学习效率、可解释性和在新场景中的转移能力，以减少训练数据需求。论文的主要贡献包括：1) CALVIN，一个微分规划器，从专家演示中学习可解释的世界模型，实现长期规划并在部分可观察的3D环境中导航；2) SOAP，一个无监督强化学习（RL）算法，自动发现选项以分解长视野任务，并在走廊任务和Atari基准上表现出色；3) LangProp，使用大语言模型（LLMs）优化代码框架，将代码视为可学习的策略，在CARLA自动驾驶基准上达到或超过人类专家水平；4) Voggite，一个视觉到行动转换器（vision-to-action transformer）驱动的代理，在Minecraft中解决复杂任务并在MineRL BASALT竞赛中获第三名。这些创新方法证明了嵌入式代理在复杂任务中的潜力，提高了其适应性和可靠性。",
      "categories": [
        "cs.LG",
        "cs.AI"
      ],
      "primary_category": "cs.LG",
      "comment": "DPhil Thesis - Engineering Science, University of Oxford. Original\n  copy available at\n  https://ora.ox.ac.uk/objects/uuid:19489c19-dc5a-464a-831d-bbf887687c41",
      "pdf_url": "http://arxiv.org/pdf/2409.19479v1",
      "published_date": "2024-09-28 23:05:56 UTC",
      "updated_date": "2024-09-28 23:05:56 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-20T04:48:29.428177"
    },
    {
      "arxiv_id": "2409.19474v2",
      "title": "FairPIVARA: Reducing and Assessing Biases in CLIP-Based Multimodal Models",
      "title_zh": "翻译失败",
      "authors": [
        "Diego A. B. Moreira",
        "Alef Iury Ferreira",
        "Jhessica Silva",
        "Gabriel Oliveira dos Santos",
        "Luiz Pereira",
        "João Medrado Gondim",
        "Gustavo Bonil",
        "Helena Maia",
        "Nádia da Silva",
        "Simone Tiemi Hashiguti",
        "Jefersson A. dos Santos",
        "Helio Pedrini",
        "Sandra Avila"
      ],
      "abstract": "Despite significant advancements and pervasive use of vision-language models,\na paucity of studies has addressed their ethical implications. These models\ntypically require extensive training data, often from hastily reviewed text and\nimage datasets, leading to highly imbalanced datasets and ethical concerns.\nAdditionally, models initially trained in English are frequently fine-tuned for\nother languages, such as the CLIP model, which can be expanded with more data\nto enhance capabilities but can add new biases. The CAPIVARA, a CLIP-based\nmodel adapted to Portuguese, has shown strong performance in zero-shot tasks.\nIn this paper, we evaluate four different types of discriminatory practices\nwithin visual-language models and introduce FairPIVARA, a method to reduce them\nby removing the most affected dimensions of feature embeddings. The application\nof FairPIVARA has led to a significant reduction of up to 98% in observed\nbiases while promoting a more balanced word distribution within the model. Our\nmodel and code are available at: https://github.com/hiaac-nlp/FairPIVARA.",
      "tldr_zh": "尽管视觉语言模型如 CLIP 在多模态任务中表现出色，但它们常因数据不平衡和语言扩展（如适应葡萄牙语的 CAPIVARA）而引入偏见，论文评估了四种歧视性实践。研究引入 FairPIVARA 方法，通过移除特征嵌入中最受影响的维度来减少这些偏见。实验结果显示，FairPIVARA 显著降低了偏见高达 98%，并促进了模型中词汇分布的平衡，同时保持了模型性能。该方法及其代码已在 GitHub 上公开可用。",
      "categories": [
        "cs.CV",
        "cs.AI"
      ],
      "primary_category": "cs.CV",
      "comment": "14 pages, 10 figures. Accepted to 35th British Machine Vision\n  Conference (BMVC 2024), Workshop on Privacy, Fairness, Accountability and\n  Transparency in Computer Vision",
      "pdf_url": "http://arxiv.org/pdf/2409.19474v2",
      "published_date": "2024-09-28 22:49:22 UTC",
      "updated_date": "2024-10-05 00:44:32 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-20T04:48:41.002813"
    },
    {
      "arxiv_id": "2410.07216v1",
      "title": "Evaluating Financial Relational Graphs: Interpretation Before Prediction",
      "title_zh": "评估金融关系图：解释在前，预测在后",
      "authors": [
        "Yingjie Niu",
        "Lanxin Lu",
        "Rian Dolphin",
        "Valerio Poti",
        "Ruihai Dong"
      ],
      "abstract": "Accurate and robust stock trend forecasting has been a crucial and\nchallenging task, as stock price changes are influenced by multiple factors.\nGraph neural network-based methods have recently achieved remarkable success in\nthis domain by constructing stock relationship graphs that reflect internal\nfactors and relationships between stocks. However, most of these methods rely\non predefined factors to construct static stock relationship graphs due to the\nlack of suitable datasets, failing to capture the dynamic changes in stock\nrelationships. Moreover, the evaluation of relationship graphs in these methods\nis often tied to the performance of neural network models on downstream tasks,\nleading to confusion and imprecision. To address these issues, we introduce the\nSPNews dataset, collected based on S\\&P 500 Index stocks, to facilitate the\nconstruction of dynamic relationship graphs. Furthermore, we propose a novel\nset of financial relationship graph evaluation methods that are independent of\ndownstream tasks. By using the relationship graph to explain historical\nfinancial phenomena, we assess its validity before constructing a graph neural\nnetwork, ensuring the graph's effectiveness in capturing relevant financial\nrelationships. Experimental results demonstrate that our evaluation methods can\neffectively differentiate between various financial relationship graphs,\nyielding more interpretable results compared to traditional approaches. We make\nour source code publicly available on GitHub to promote reproducibility and\nfurther research in this area.",
      "tldr_zh": "这篇论文针对股票趋势预测的挑战，指出现有基于Graph Neural Network的方法依赖预定义因素构建静态关系图，无法捕捉动态变化，且评估往往与下游任务性能混淆。论文引入SPNews数据集（基于S&P 500指数），以支持动态关系图的构建，并提出独立于下游任务的评估方法，通过解释历史金融现象来验证图的有效性。实验结果显示，该方法能有效区分不同关系图，提供更可解释的结果，并开源代码以促进再现和进一步研究。",
      "categories": [
        "q-fin.ST",
        "cs.AI",
        "cs.LG",
        "I.2.4"
      ],
      "primary_category": "q-fin.ST",
      "comment": "Accepted by 2024 ACM International Conference on AI in Finance",
      "pdf_url": "http://arxiv.org/pdf/2410.07216v1",
      "published_date": "2024-09-28 22:43:00 UTC",
      "updated_date": "2024-09-28 22:43:00 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-20T04:48:52.769991"
    },
    {
      "arxiv_id": "2409.19471v2",
      "title": "SELP: Generating Safe and Efficient Task Plans for Robot Agents with Large Language Models",
      "title_zh": "翻译失败",
      "authors": [
        "Yi Wu",
        "Zikang Xiong",
        "Yiran Hu",
        "Shreyash S. Iyengar",
        "Nan Jiang",
        "Aniket Bera",
        "Lin Tan",
        "Suresh Jagannathan"
      ],
      "abstract": "Despite significant advancements in large language models (LLMs) that enhance\nrobot agents' understanding and execution of natural language (NL) commands,\nensuring the agents adhere to user-specified constraints remains challenging,\nparticularly for complex commands and long-horizon tasks. To address this\nchallenge, we present three key insights, equivalence voting, constrained\ndecoding, and domain-specific fine-tuning, which significantly enhance LLM\nplanners' capability in handling complex tasks. Equivalence voting ensures\nconsistency by generating and sampling multiple Linear Temporal Logic (LTL)\nformulas from NL commands, grouping equivalent LTL formulas, and selecting the\nmajority group of formulas as the final LTL formula. Constrained decoding then\nuses the generated LTL formula to enforce the autoregressive inference of\nplans, ensuring the generated plans conform to the LTL. Domain-specific\nfine-tuning customizes LLMs to produce safe and efficient plans within specific\ntask domains. Our approach, Safe Efficient LLM Planner (SELP), combines these\ninsights to create LLM planners to generate plans adhering to user commands\nwith high confidence. We demonstrate the effectiveness and generalizability of\nSELP across different robot agents and tasks, including drone navigation and\nrobot manipulation. For drone navigation tasks, SELP outperforms\nstate-of-the-art planners by 10.8% in safety rate (i.e., finishing tasks\nconforming to NL commands) and by 19.8% in plan efficiency. For robot\nmanipulation tasks, SELP achieves 20.4% improvement in safety rate. Our\ndatasets for evaluating NL-to-LTL and robot task planning will be released in\ngithub.com/lt-asset/selp.",
      "tldr_zh": "这篇论文提出了 SELP 方法，利用大型语言模型 (LLMs) 为机器人代理生成安全且高效的任务计划，以解决复杂命令和长期任务中遵守用户约束的挑战。SELP 整合了三个关键洞见：Equivalence voting 通过生成并选择多数等价的 Linear Temporal Logic (LTL) 公式确保一致性、Constrained decoding 使用 LTL 公式约束计划生成，以及 Domain-specific fine-tuning 针对特定领域定制模型以提升安全性。实验结果显示，在无人机导航任务中，SELP 比最先进规划器提高了 10.8% 的安全率和 19.8% 的计划效率；在机器人操作任务中，安全率提升了 20.4%。作者将用于评估 NL-to-LTL 和机器人任务规划的数据集发布在 GitHub 上。",
      "categories": [
        "cs.RO",
        "cs.AI",
        "cs.CL",
        "cs.FL"
      ],
      "primary_category": "cs.RO",
      "comment": "This paper has been accepted for presentation at the 2025 IEEE\n  International Conference on Robotics and Automation (ICRA), May 19-23, 2025,\n  Atlanta, USA, and for inclusion in the conference proceeding",
      "pdf_url": "http://arxiv.org/pdf/2409.19471v2",
      "published_date": "2024-09-28 22:33:44 UTC",
      "updated_date": "2025-02-14 02:40:55 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-20T04:49:07.496574"
    },
    {
      "arxiv_id": "2409.19467v2",
      "title": "INSIGHTBUDDY-AI: Medication Extraction and Entity Linking using Large Language Models and Ensemble Learning",
      "title_zh": "INSIGHTBUDDY-AI：使用大型语言模型和集成学习的药物提取与实体链接",
      "authors": [
        "Pablo Romero",
        "Lifeng Han",
        "Goran Nenadic"
      ],
      "abstract": "Medication Extraction and Mining play an important role in healthcare NLP\nresearch due to its practical applications in hospital settings, such as their\nmapping into standard clinical knowledge bases (SNOMED-CT, BNF, etc.). In this\nwork, we investigate state-of-the-art LLMs in text mining tasks on medications\nand their related attributes such as dosage, route, strength, and adverse\neffects. In addition, we explore different ensemble learning methods\n(\\textsc{Stack-Ensemble} and \\textsc{Voting-Ensemble}) to augment the model\nperformances from individual LLMs. Our ensemble learning result demonstrated\nbetter performances than individually fine-tuned base models BERT, RoBERTa,\nRoBERTa-L, BioBERT, BioClinicalBERT, BioMedRoBERTa, ClinicalBERT, and\nPubMedBERT across general and specific domains. Finally, we build up an entity\nlinking function to map extracted medical terminologies into the SNOMED-CT\ncodes and the British National Formulary (BNF) codes, which are further mapped\nto the Dictionary of Medicines and Devices (dm+d), and ICD. Our model's toolkit\nand desktop applications are publicly available (at\n\\url{https://github.com/HECTA-UoM/ensemble-NER}).",
      "tldr_zh": "本研究提出INSIGHTBUDDY-AI框架，利用Large Language Models (LLMs) 和Ensemble Learning（如Stack-Ensemble和Voting-Ensemble）来提取药物相关信息，包括剂量、途径、强度和副作用，并将其映射到标准临床知识库。相比单独微调的基线模型（如BERT、RoBERTa和BioBERT等），集成学习方法在一般和特定领域表现出色，提升了整体性能。最终，该框架还开发了实体链接功能，将提取的医疗术语映射到SNOMED-CT、BHF代码，并进一步连接到Dictionary of Medicines and Devices (dm+d)及ICD，且相关工具包已公开可用（https://github.com/HECTA-UoM/ensemble-NER）。",
      "categories": [
        "cs.CL",
        "cs.AI"
      ],
      "primary_category": "cs.CL",
      "comment": "ongoing work, 24 pages",
      "pdf_url": "http://arxiv.org/pdf/2409.19467v2",
      "published_date": "2024-09-28 22:06:06 UTC",
      "updated_date": "2024-12-27 20:53:02 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-20T04:49:17.161802"
    },
    {
      "arxiv_id": "2409.19454v4",
      "title": "See Where You Read with Eye Gaze Tracking and Large Language Model",
      "title_zh": "翻译失败",
      "authors": [
        "Sikai Yang",
        "Gang Yan",
        "Wan Du"
      ],
      "abstract": "Losing track of reading progress during line switching can be frustrating.\nEye gaze tracking technology offers a potential solution by highlighting read\nparagraphs, aiding users in avoiding wrong line switches. However, the gap\nbetween gaze tracking accuracy (2-3 cm) and text line spacing (3-5 mm) makes\ndirect application impractical. Existing methods leverage the linear reading\npattern but fail during jump reading. This paper presents a reading tracking\nand highlighting system that supports both linear and jump reading. Based on\nexperimental insights from the gaze nature study of 16 users, two gaze error\nmodels are designed to enable both jump reading detection and relocation. The\nsystem further leverages the large language model's contextual perception\ncapability in aiding reading tracking. A reading tracking domain-specific\nline-gaze alignment opportunity is also exploited to enable dynamic and\nfrequent calibration of the gaze results. Controlled experiments demonstrate\nreliable linear reading tracking, as well as 84% accuracy in tracking jump\nreading. Furthermore, real field tests with 18 volunteers demonstrated the\nsystem's effectiveness in tracking and highlighting read paragraphs, improving\nreading efficiency, and enhancing user experience.",
      "tldr_zh": "这篇论文提出了一种结合 Eye Gaze Tracking 和 Large Language Model 的阅读追踪系统，以解决阅读过程中行切换丢失进度的难题，支持线性阅读和跳跃阅读。系统基于对16名用户的眼动研究，设计了两个眼动误差模型，用于检测跳跃阅读并进行重新定位，同时利用 Large Language Model 的上下文感知能力辅助追踪，并实现动态校准。实验结果显示，该系统在线性阅读追踪中表现可靠，跳跃阅读准确率达84%，并在实地测试中提升了阅读效率和用户体验。",
      "categories": [
        "cs.HC",
        "cs.AI",
        "cs.CV",
        "J.5; I.2.7"
      ],
      "primary_category": "cs.HC",
      "comment": "9 pages",
      "pdf_url": "http://arxiv.org/pdf/2409.19454v4",
      "published_date": "2024-09-28 20:40:18 UTC",
      "updated_date": "2024-12-13 04:44:31 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-20T04:49:29.806236"
    },
    {
      "arxiv_id": "2409.19450v2",
      "title": "Secret Use of Large Language Model (LLM)",
      "title_zh": "翻译失败",
      "authors": [
        "Zhiping Zhang",
        "Chenxinran Shen",
        "Bingsheng Yao",
        "Dakuo Wang",
        "Tianshi Li"
      ],
      "abstract": "The advancements of Large Language Models (LLMs) have decentralized the\nresponsibility for the transparency of AI usage. Specifically, LLM users are\nnow encouraged or required to disclose the use of LLM-generated content for\nvaried types of real-world tasks. However, an emerging phenomenon, users'\nsecret use of LLM, raises challenges in ensuring end users adhere to the\ntransparency requirement. Our study used mixed-methods with an exploratory\nsurvey (125 real-world secret use cases reported) and a controlled experiment\namong 300 users to investigate the contexts and causes behind the secret use of\nLLMs. We found that such secretive behavior is often triggered by certain\ntasks, transcending demographic and personality differences among users. Task\ntypes were found to affect users' intentions to use secretive behavior,\nprimarily through influencing perceived external judgment regarding LLM usage.\nOur results yield important insights for future work on designing interventions\nto encourage more transparent disclosure of the use of LLMs or other AI\ntechnologies.",
      "tldr_zh": "该研究探讨了Large Language Model (LLM)用户的秘密使用现象，该行为挑战了AI使用透明度的要求。研究采用混合方法，包括对125个真实案例的探索性调查和涉及300用户的控制实验，分析了秘密使用的上下文和原因。结果发现，这种行为主要由特定任务类型触发，而非用户的人口统计学或个性差异，且任务会通过影响对外部判断的感知来影响秘密意图。该研究为设计干预措施提供了关键见解，以促进LLM或其他AI技术的透明披露。",
      "categories": [
        "cs.HC",
        "cs.AI"
      ],
      "primary_category": "cs.HC",
      "comment": "26 pages, 3 figures, and accepted at CSCW 2025",
      "pdf_url": "http://arxiv.org/pdf/2409.19450v2",
      "published_date": "2024-09-28 20:31:53 UTC",
      "updated_date": "2024-10-19 19:07:45 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-20T04:49:40.713227"
    },
    {
      "arxiv_id": "2409.19448v1",
      "title": "Advanced Clustering Techniques for Speech Signal Enhancement: A Review and Metanalysis of Fuzzy C-Means, K-Means, and Kernel Fuzzy C-Means Methods",
      "title_zh": "高级聚类技术用于",
      "authors": [
        "Abdulhady Abas Abdullah",
        "Aram Mahmood Ahmed",
        "Tarik Rashid",
        "Hadi Veisi",
        "Yassin Hussein Rassul",
        "Bryar Hassan",
        "Polla Fattah",
        "Sabat Abdulhameed Ali",
        "Ahmed S. Shamsaldin"
      ],
      "abstract": "Speech signal processing is a cornerstone of modern communication\ntechnologies, tasked with improving the clarity and comprehensibility of audio\ndata in noisy environments. The primary challenge in this field is the\neffective separation and recognition of speech from background noise, crucial\nfor applications ranging from voice-activated assistants to automated\ntranscription services. The quality of speech recognition directly impacts user\nexperience and accessibility in technology-driven communication. This review\npaper explores advanced clustering techniques, particularly focusing on the\nKernel Fuzzy C-Means (KFCM) method, to address these challenges. Our findings\nindicate that KFCM, compared to traditional methods like K-Means (KM) and Fuzzy\nC-Means (FCM), provides superior performance in handling non-linear and\nnon-stationary noise conditions in speech signals. The most notable outcome of\nthis review is the adaptability of KFCM to various noisy environments, making\nit a robust choice for speech enhancement applications. Additionally, the paper\nidentifies gaps in current methodologies, such as the need for more dynamic\nclustering algorithms that can adapt in real time to changing noise conditions\nwithout compromising speech recognition quality. Key contributions include a\ndetailed comparative analysis of current clustering algorithms and suggestions\nfor further integrating hybrid models that combine KFCM with neural networks to\nenhance speech recognition accuracy. Through this review, we advocate for a\nshift towards more sophisticated, adaptive clustering techniques that can\nsignificantly improve speech enhancement and pave the way for more resilient\nspeech processing systems.",
      "tldr_zh": "这篇综述论文审视了用于语音信号增强的先进聚类技术，重点比较 K-Means、Fuzzy C-Means 和 Kernel Fuzzy C-Means 方法，以应对噪声环境中的语音分离和识别挑战。\n研究发现，Kernel Fuzzy C-Means 在处理非线性、非平稳噪声时表现出优越性能，相比传统方法更具适应性和鲁棒性。\n论文的主要贡献包括详细的算法比较分析，并提出未来方向，如开发实时自适应算法和整合神经网络的混合模型，以提升语音处理系统的整体效能。",
      "categories": [
        "cs.SD",
        "cs.AI",
        "eess.AS"
      ],
      "primary_category": "cs.SD",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2409.19448v1",
      "published_date": "2024-09-28 20:21:05 UTC",
      "updated_date": "2024-09-28 20:21:05 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-20T04:49:52.428085"
    },
    {
      "arxiv_id": "2409.19437v4",
      "title": "Strongly-polynomial time and validation analysis of policy gradient methods",
      "title_zh": "策略梯度方法的强多项式时间和验证分析",
      "authors": [
        "Caleb Ju",
        "Guanghui Lan"
      ],
      "abstract": "This paper proposes a novel termination criterion, termed the advantage gap\nfunction, for finite state and action Markov decision processes (MDP) and\nreinforcement learning (RL). By incorporating this advantage gap function into\nthe design of step size rules and deriving a new linear rate of convergence\nthat is independent of the stationary state distribution of the optimal policy,\nwe demonstrate that policy gradient methods can solve MDPs in\nstrongly-polynomial time. To the best of our knowledge, this is the first time\nthat such strong convergence properties have been established for policy\ngradient methods. Moreover, in the stochastic setting, where only stochastic\nestimates of policy gradients are available, we show that the advantage gap\nfunction provides close approximations of the optimality gap for each\nindividual state and exhibits a sublinear rate of convergence at every state.\nThe advantage gap function can be easily estimated in the stochastic case, and\nwhen coupled with easily computable upper bounds on policy values, they provide\na convenient way to validate the solutions generated by policy gradient\nmethods. Therefore, our developments offer a principled and computable measure\nof optimality for RL, whereas current practice tends to rely on\nalgorithm-to-algorithm or baselines comparisons with no certificate of\noptimality.",
      "tldr_zh": "这篇论文提出了一种新的终止准则——advantage gap function，用于有限状态和动作的Markov decision processes (MDP) 和 reinforcement learning (RL)。通过将该函数整合到步长规则的设计中，论文推导出policy gradient methods 的线性收敛率，该收敛率独立于最优策略的平稳状态分布，从而首次证明了policy gradient methods 可以以strongly-polynomial time 解决MDP。实验结果显示，在随机环境中，advantage gap function 能近似每个状态的optimality gap，并实现子线性收敛率，提供了一个易于计算的验证机制，以评估policy gradient methods 生成的解决方案的可靠性。",
      "categories": [
        "cs.LG",
        "cs.AI",
        "cs.DS",
        "math.OC",
        "49K45, 49M05, 90C05, 90C26, 90C40, 90C46"
      ],
      "primary_category": "cs.LG",
      "comment": "Some fixes to notation",
      "pdf_url": "http://arxiv.org/pdf/2409.19437v4",
      "published_date": "2024-09-28 18:56:48 UTC",
      "updated_date": "2025-02-20 04:57:47 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-20T04:50:05.110874"
    },
    {
      "arxiv_id": "2410.03721v1",
      "title": "Thematic Analysis with Open-Source Generative AI and Machine Learning: A New Method for Inductive Qualitative Codebook Development",
      "title_zh": "翻译失败",
      "authors": [
        "Andrew Katz",
        "Gabriella Coloyan Fleming",
        "Joyce Main"
      ],
      "abstract": "This paper aims to answer one central question: to what extent can\nopen-source generative text models be used in a workflow to approximate\nthematic analysis in social science research? To answer this question, we\npresent the Generative AI-enabled Theme Organization and Structuring (GATOS)\nworkflow, which uses open-source machine learning techniques, natural language\nprocessing tools, and generative text models to facilitate thematic analysis.\nTo establish validity of the method, we present three case studies applying the\nGATOS workflow, leveraging these models and techniques to inductively create\ncodebooks similar to traditional procedures using thematic analysis.\nSpecifically, we investigate the extent to which a workflow comprising\nopen-source models and tools can inductively produce codebooks that approach\nthe known space of themes and sub-themes. To address the challenge of gleaning\ninsights from these texts, we combine open-source generative text models,\nretrieval-augmented generation, and prompt engineering to identify codes and\nthemes in large volumes of text, i.e., generate a qualitative codebook. The\nprocess mimics an inductive coding process that researchers might use in\ntraditional thematic analysis by reading text one unit of analysis at a time,\nconsidering existing codes already in the codebook, and then deciding whether\nor not to generate a new code based on whether the extant codebook provides\nadequate thematic coverage. We demonstrate this workflow using three synthetic\ndatasets from hypothetical organizational research settings: a study of\nteammate feedback in teamwork settings, a study of organizational cultures of\nethical behavior, and a study of employee perspectives about returning to their\noffices after the pandemic. We show that the GATOS workflow is able to identify\nthemes in the text that were used to generate the original synthetic datasets.",
      "tldr_zh": "这篇论文探讨了开源生成式 AI 和机器学习在社会科学研究中的应用，提出了一种名为 GATOS 的工作流，用于辅助主题分析（thematic analysis）的诱导生成定性代码书。\nGATOS 结合自然语言处理工具、检索增强生成（retrieval-augmented generation）和提示工程（prompt engineering），通过逐个分析文本单位并决定是否添加新代码，模仿传统诱导编码过程。\n通过三个合成数据集的案例研究，论文证明该工作流能有效识别出接近原始主题和子主题的代码书，从而为开源工具在定性研究中的使用提供了新方法。",
      "categories": [
        "cs.CL",
        "cs.AI",
        "cs.HC"
      ],
      "primary_category": "cs.CL",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2410.03721v1",
      "published_date": "2024-09-28 18:52:16 UTC",
      "updated_date": "2024-09-28 18:52:16 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-20T04:50:18.555768"
    },
    {
      "arxiv_id": "2409.19433v2",
      "title": "RMLR: Extending Multinomial Logistic Regression into General Geometries",
      "title_zh": "翻译失败",
      "authors": [
        "Ziheng Chen",
        "Yue Song",
        "Rui Wang",
        "Xiaojun Wu",
        "Nicu Sebe"
      ],
      "abstract": "Riemannian neural networks, which extend deep learning techniques to\nRiemannian spaces, have gained significant attention in machine learning. To\nbetter classify the manifold-valued features, researchers have started\nextending Euclidean multinomial logistic regression (MLR) into Riemannian\nmanifolds. However, existing approaches suffer from limited applicability due\nto their strong reliance on specific geometric properties. This paper proposes\na framework for designing Riemannian MLR over general geometries, referred to\nas RMLR. Our framework only requires minimal geometric properties, thus\nexhibiting broad applicability and enabling its use with a wide range of\ngeometries. Specifically, we showcase our framework on the Symmetric Positive\nDefinite (SPD) manifold and special orthogonal group, i.e., the set of rotation\nmatrices. On the SPD manifold, we develop five families of SPD MLRs under five\ntypes of power-deformed metrics. On rotation matrices we propose Lie MLR based\non the popular bi-invariant metric. Extensive experiments on different\nRiemannian backbone networks validate the effectiveness of our framework.",
      "tldr_zh": "本文提出 RMLR 框架，将多项逻辑回归 (MLR) 扩展到一般 Riemannian 几何中，仅需最小几何属性，从而克服现有方法对特定几何依赖的局限性，提升其广泛适用性。具体地，该框架应用于 Symmetric Positive Definite (SPD) 流形，开发了五种基于 power-deformed metrics 的 SPD MLR 家族，以及在特殊正交群（旋转矩阵）上基于 bi-invariant metric 的 Lie MLR。通过在不同 Riemannian 骨干网络上的广泛实验，证明了 RMLR 的有效性。",
      "categories": [
        "cs.LG",
        "cs.AI"
      ],
      "primary_category": "cs.LG",
      "comment": "Accepted to NeurIPS 2024",
      "pdf_url": "http://arxiv.org/pdf/2409.19433v2",
      "published_date": "2024-09-28 18:38:21 UTC",
      "updated_date": "2024-10-02 09:53:48 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-20T04:50:30.267877"
    },
    {
      "arxiv_id": "2409.19432v3",
      "title": "MicroFlow: An Efficient Rust-Based Inference Engine for TinyML",
      "title_zh": "MicroFlow：一种高效的基于 Rust 的 TinyML 推理引擎",
      "authors": [
        "Matteo Carnelos",
        "Francesco Pasti",
        "Nicola Bellotto"
      ],
      "abstract": "In recent years, there has been a significant interest in developing machine\nlearning algorithms on embedded systems. This is particularly relevant for bare\nmetal devices in Internet of Things, Robotics, and Industrial applications that\nface limited memory, processing power, and storage, and which require extreme\nrobustness. To address these constraints, we present MicroFlow, an open-source\nTinyML framework for the deployment of Neural Networks (NNs) on embedded\nsystems using the Rust programming language. The compiler-based inference\nengine of MicroFlow, coupled with Rust's memory safety, makes it suitable for\nTinyML applications in critical environments. The proposed framework enables\nthe successful deployment of NNs on highly resource-constrained devices,\nincluding bare-metal 8-bit microcontrollers with only 2kB of RAM. Furthermore,\nMicroFlow is able to use less Flash and RAM memory than other state-of-the-art\nsolutions for deploying NN reference models (i.e. wake-word and person\ndetection), achieving equally accurate but faster inference compared to\nexisting engines on medium-size NNs, and similar performance on bigger ones.\nThe experimental results prove the efficiency and suitability of MicroFlow for\nthe deployment of TinyML models in critical environments where resources are\nparticularly limited.",
      "tldr_zh": "本论文介绍了 MicroFlow，一种基于 Rust 编程语言的开源 TinyML 框架，旨在高效部署 Neural Networks (NNs) 于资源受限的嵌入式系统，如仅拥有 2kB RAM 的 8-bit 微控制器。MicroFlow 通过编译器-based 推理引擎和 Rust 的内存安全特性，解决了 IoT、机器人和工业应用中的内存、处理能力和存储限制问题。实验结果显示，该框架在部署参考模型（如唤醒词和人物检测）时，使用更少的 Flash 和 RAM 内存，同时实现与现有引擎相当的准确率和更快的推理性能，证明其适用于极端资源约束的关键环境。",
      "categories": [
        "cs.LG",
        "cs.AI"
      ],
      "primary_category": "cs.LG",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2409.19432v3",
      "published_date": "2024-09-28 18:34:27 UTC",
      "updated_date": "2025-01-03 21:45:08 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-20T04:50:41.986747"
    },
    {
      "arxiv_id": "2409.19422v2",
      "title": "Identifiable Shared Component Analysis of Unpaired Multimodal Mixtures",
      "title_zh": "可识别的未配对多模态混合物的共享成分分析",
      "authors": [
        "Subash Timilsina",
        "Sagar Shrestha",
        "Xiao Fu"
      ],
      "abstract": "A core task in multi-modal learning is to integrate information from multiple\nfeature spaces (e.g., text and audio), offering modality-invariant essential\nrepresentations of data. Recent research showed that, classical tools such as\n{\\it canonical correlation analysis} (CCA) provably identify the shared\ncomponents up to minor ambiguities, when samples in each modality are generated\nfrom a linear mixture of shared and private components. Such identifiability\nresults were obtained under the condition that the cross-modality samples are\naligned/paired according to their shared information. This work takes a step\nfurther, investigating shared component identifiability from multi-modal linear\nmixtures where cross-modality samples are unaligned. A distribution divergence\nminimization-based loss is proposed, under which a suite of sufficient\nconditions ensuring identifiability of the shared components are derived. Our\nconditions are based on cross-modality distribution discrepancy\ncharacterization and density-preserving transform removal, which are much\nmilder than existing studies relying on independent component analysis. More\nrelaxed conditions are also provided via adding reasonable structural\nconstraints, motivated by available side information in various applications.\nThe identifiability claims are thoroughly validated using synthetic and\nreal-world data.",
      "tldr_zh": "本论文探讨了未对齐多模态混合数据的共享组件分析，旨在从多个特征空间（如文本和音频）中提取模态不变的本质表示。作者提出了一种基于分布差异最小化的损失函数，并推导出了一系列充分条件来确保共享组件的可识别性，这些条件依赖于跨模态分布差异表征和密度保持变换移除，比传统依赖独立成分分析(ICA)的研究更宽松。通过添加合理的结构约束，进一步放宽了这些条件。实验在合成和真实数据上验证了这些可识别性声明。",
      "categories": [
        "cs.LG",
        "cs.AI",
        "stat.ML"
      ],
      "primary_category": "cs.LG",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2409.19422v2",
      "published_date": "2024-09-28 17:43:17 UTC",
      "updated_date": "2024-10-01 07:04:04 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-20T04:50:53.467732"
    },
    {
      "arxiv_id": "2409.19417v1",
      "title": "Subject Data Auditing via Source Inference Attack in Cross-Silo Federated Learning",
      "title_zh": "在跨孤岛联邦学习中通过来源推断攻击进行主体数据审计",
      "authors": [
        "Jiaxin Li",
        "Marco Arazzi",
        "Antonino Nocera",
        "Mauro Conti"
      ],
      "abstract": "Source Inference Attack (SIA) in Federated Learning (FL) aims to identify\nwhich client used a target data point for local model training. It allows the\ncentral server to audit clients' data usage. In cross-silo FL, a client (silo)\ncollects data from multiple subjects (e.g., individuals, writers, or devices),\nposing a risk of subject information leakage. Subject Membership Inference\nAttack (SMIA) targets this scenario and attempts to infer whether any client\nutilizes data points from a target subject in cross-silo FL. However, existing\nresults on SMIA are limited and based on strong assumptions on the attack\nscenario. Therefore, we propose a Subject-Level Source Inference Attack (SLSIA)\nby removing critical constraints that only one client can use a target data\npoint in SIA and imprecise detection of clients utilizing target subject data\nin SMIA. The attacker, positioned on the server side, controls a target data\nsource and aims to detect all clients using data points from the target\nsubject. Our strategy leverages a binary attack classifier to predict whether\nthe embeddings returned by a local model on test data from the target subject\ninclude unique patterns that indicate a client trains the model with data from\nthat subject. To achieve this, the attacker locally pre-trains models using\ndata derived from the target subject and then leverages them to build a\ntraining set for the binary attack classifier. Our SLSIA significantly\noutperforms previous methods on three datasets. Specifically, SLSIA achieves a\nmaximum average accuracy of 0.88 over 50 target subjects. Analyzing embedding\ndistribution and input feature distance shows that datasets with sparse\nsubjects are more susceptible to our attack. Finally, we propose to defend our\nSLSIA using item-level and subject-level differential privacy mechanisms.",
      "tldr_zh": "该论文探讨了在跨仓库 Federated Learning (FL) 中，通过 Source Inference Attack (SIA) 进行主题数据审计，以检测客户端是否使用了目标主题的数据。研究提出了一种改进的 Subject-Level Source Inference Attack (SLSIA)，该方法使用二元攻击分类器分析本地模型的嵌入，结合预训练模型构建训练集，从而精准识别所有利用目标主题数据的客户端。实验结果显示，SLSIA 在三个数据集上平均准确率高达 0.88，且数据稀疏的主题更容易受攻击；最后，论文建议采用 item-level 和 subject-level differential privacy 机制作为防御策略，以提升数据隐私保护。",
      "categories": [
        "cs.CR",
        "cs.AI"
      ],
      "primary_category": "cs.CR",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2409.19417v1",
      "published_date": "2024-09-28 17:27:34 UTC",
      "updated_date": "2024-09-28 17:27:34 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-20T04:51:06.317270"
    },
    {
      "arxiv_id": "2409.19415v1",
      "title": "Bridging the Gap in Hybrid Decision-Making Systems",
      "title_zh": "翻译失败",
      "authors": [
        "Federico Mazzoni",
        "Roberto Pellungrini",
        "Riccardo Guidotti"
      ],
      "abstract": "We introduce BRIDGET, a novel human-in-the-loop system for hybrid\ndecision-making, aiding the user to label records from an un-labeled dataset,\nattempting to ``bridge the gap'' between the two most popular Hybrid\nDecision-Making paradigms: those featuring the human in a leading position, and\nthe other with a machine making most of the decisions. BRIDGET understands when\neither a machine or a human user should be in charge, dynamically switching\nbetween two statuses. In the different statuses, BRIDGET still fosters the\nhuman-AI interaction, either having a machine learning model assuming skeptical\nstances towards the user and offering them suggestions, or towards itself and\ncalling the user back. We believe our proposal lays the groundwork for future\nsynergistic systems involving a human and a machine decision-makers.",
      "tldr_zh": "该研究引入了BRIDGET，一种新型的人机循环系统，用于混合决策（Hybrid Decision-Making），旨在桥接人类主导和机器主导的两种范式，帮助用户标记未标记数据集。BRIDGET能够动态判断并切换主导权，当机器主导时，它对用户持怀疑态度并提供建议；当人类主导时，它则对自身持怀疑态度并调用用户参与。总体而言，该系统通过增强人机交互，为未来协同决策系统奠定基础。",
      "categories": [
        "cs.AI",
        "cs.HC",
        "68T05, 68W40"
      ],
      "primary_category": "cs.AI",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2409.19415v1",
      "published_date": "2024-09-28 17:14:59 UTC",
      "updated_date": "2024-09-28 17:14:59 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-20T04:51:17.013645"
    },
    {
      "arxiv_id": "2409.19413v1",
      "title": "Membership Privacy Evaluation in Deep Spiking Neural Networks",
      "title_zh": "深度脉冲神经网络中的成员隐私评估",
      "authors": [
        "Jiaxin Li",
        "Gorka Abad",
        "Stjepan Picek",
        "Mauro Conti"
      ],
      "abstract": "Artificial Neural Networks (ANNs), commonly mimicking neurons with non-linear\nfunctions to output floating-point numbers, consistently receive the same\nsignals of a data point during its forward time. Unlike ANNs, Spiking Neural\nNetworks (SNNs) get various input signals in the forward time of a data point\nand simulate neurons in a biologically plausible way, i.e., producing a spike\n(a binary value) if the accumulated membrane potential of a neuron is larger\nthan a threshold. Even though ANNs have achieved remarkable success in multiple\ntasks, e.g., face recognition and object detection, SNNs have recently obtained\nattention due to their low power consumption, fast inference, and event-driven\nproperties. While privacy threats against ANNs are widely explored, much less\nwork has been done on SNNs. For instance, it is well-known that ANNs are\nvulnerable to the Membership Inference Attack (MIA), but whether the same\napplies to SNNs is not explored.\n  In this paper, we evaluate the membership privacy of SNNs by considering\neight MIAs, seven of which are inspired by MIAs against ANNs. Our evaluation\nresults show that SNNs are more vulnerable (maximum 10% higher in terms of\nbalanced attack accuracy) than ANNs when both are trained with neuromorphic\ndatasets (with time dimension). On the other hand, when training ANNs or SNNs\nwith static datasets (without time dimension), the vulnerability depends on the\ndataset used. If we convert ANNs trained with static datasets to SNNs, the\naccuracy of MIAs drops (maximum 11.5% with a reduction of 7.6% on the test\naccuracy of the target model). Next, we explore the impact factors of MIAs on\nSNNs by conducting a hyperparameter study. Finally, we show that the basic data\naugmentation method for static data and two recent data augmentation methods\nfor neuromorphic data can considerably (maximum reduction of 25.7%) decrease\nMIAs' performance on SNNs.",
      "tldr_zh": "本研究评估了深度脉冲神经网络（SNNs）的成员隐私风险，特别针对 Membership Inference Attack (MIA)，通过比较 SNNs 与 Artificial Neural Networks (ANNs) 的易感性。实验结果显示，当使用神经形态数据集时，SNNs 比 ANNs 更易受 MIA 攻击（攻击准确率高出最多 10%），而对于静态数据集，易感性取决于具体数据集；此外，将 ANNs 转换为 SNNs 会降低 MIA 的准确率（最多减少 11.5%，目标模型测试准确率仅降低 7.6%）。论文还通过超参数研究探讨了影响 MIA 的因素，并证明数据增强方法（如基本和神经形态数据增强）能显著降低 SNNs 对 MIA 的脆弱性（最多减少 25.7%）。",
      "categories": [
        "cs.CR",
        "cs.AI"
      ],
      "primary_category": "cs.CR",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2409.19413v1",
      "published_date": "2024-09-28 17:13:04 UTC",
      "updated_date": "2024-09-28 17:13:04 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-20T04:51:30.327819"
    },
    {
      "arxiv_id": "2409.19407v1",
      "title": "Brain-JEPA: Brain Dynamics Foundation Model with Gradient Positioning and Spatiotemporal Masking",
      "title_zh": "翻译失败",
      "authors": [
        "Zijian Dong",
        "Ruilin Li",
        "Yilei Wu",
        "Thuan Tinh Nguyen",
        "Joanna Su Xian Chong",
        "Fang Ji",
        "Nathanael Ren Jie Tong",
        "Christopher Li Hsian Chen",
        "Juan Helen Zhou"
      ],
      "abstract": "We introduce Brain-JEPA, a brain dynamics foundation model with the\nJoint-Embedding Predictive Architecture (JEPA). This pioneering model achieves\nstate-of-the-art performance in demographic prediction, disease\ndiagnosis/prognosis, and trait prediction through fine-tuning. Furthermore, it\nexcels in off-the-shelf evaluations (e.g., linear probing) and demonstrates\nsuperior generalizability across different ethnic groups, surpassing the\nprevious large model for brain activity significantly. Brain-JEPA incorporates\ntwo innovative techniques: Brain Gradient Positioning and Spatiotemporal\nMasking. Brain Gradient Positioning introduces a functional coordinate system\nfor brain functional parcellation, enhancing the positional encoding of\ndifferent Regions of Interest (ROIs). Spatiotemporal Masking, tailored to the\nunique characteristics of fMRI data, addresses the challenge of heterogeneous\ntime-series patches. These methodologies enhance model performance and advance\nour understanding of the neural circuits underlying cognition. Overall,\nBrain-JEPA is paving the way to address pivotal questions of building brain\nfunctional coordinate system and masking brain activity at the AI-neuroscience\ninterface, and setting a potentially new paradigm in brain activity analysis\nthrough downstream adaptation.",
      "tldr_zh": "我们介绍了 Brain-JEPA，这是一个基于 Joint-Embedding Predictive Architecture (JEPA) 的脑动态基础模型，在人口统计预测、疾病诊断/预后以及特征预测任务中，通过微调实现了最先进性能，并在现成评估（如线性探测）中表现出色，同时在不同民族群体间显示出卓越的泛化能力。Brain-JEPA 创新性地引入了 Brain Gradient Positioning 技术，建立功能坐标系统来增强脑功能分区（ROIs）的位置编码，以及 Spatiotemporal Masking 方法，针对 fMRI 数据的异质时间序列片段进行处理，从而提升模型整体表现并加深对认知神经回路的理解。该模型为构建脑功能坐标系统和掩盖脑活动开辟新范式，在 AI-神经科学接口推动脑活动分析的下游应用。",
      "categories": [
        "q-bio.NC",
        "cs.AI",
        "cs.CV"
      ],
      "primary_category": "q-bio.NC",
      "comment": "The first two authors contributed equally. NeurIPS 2024 Spotlight",
      "pdf_url": "http://arxiv.org/pdf/2409.19407v1",
      "published_date": "2024-09-28 17:06:06 UTC",
      "updated_date": "2024-09-28 17:06:06 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-20T04:51:42.269939"
    },
    {
      "arxiv_id": "2409.19390v1",
      "title": "Efficient Federated Intrusion Detection in 5G ecosystem using optimized BERT-based model",
      "title_zh": "翻译失败",
      "authors": [
        "Frederic Adjewa",
        "Moez Esseghir",
        "Leila Merghem-Boulahia"
      ],
      "abstract": "The fifth-generation (5G) offers advanced services, supporting applications\nsuch as intelligent transportation, connected healthcare, and smart cities\nwithin the Internet of Things (IoT). However, these advancements introduce\nsignificant security challenges, with increasingly sophisticated cyber-attacks.\nThis paper proposes a robust intrusion detection system (IDS) using federated\nlearning and large language models (LLMs). The core of our IDS is based on\nBERT, a transformer model adapted to identify malicious network flows. We\nmodified this transformer to optimize performance on edge devices with limited\nresources. Experiments were conducted in both centralized and federated\nlearning contexts. In the centralized setup, the model achieved an inference\naccuracy of 97.79%. In a federated learning context, the model was trained\nacross multiple devices using both IID (Independent and Identically\nDistributed) and non-IID data, based on various scenarios, ensuring data\nprivacy and compliance with regulations. We also leveraged linear quantization\nto compress the model for deployment on edge devices. This reduction resulted\nin a slight decrease of 0.02% in accuracy for a model size reduction of 28.74%.\nThe results underscore the viability of LLMs for deployment in IoT ecosystems,\nhighlighting their ability to operate on devices with constrained computational\nand storage resources.",
      "tldr_zh": "本文提出了一种高效的入侵检测系统(IDS)，针对5G生态系统的网络攻击挑战，利用优化后的BERT模型结合联邦学习(Federated Learning)，以识别恶意网络流量，同时确保数据隐私和资源效率。研究团队修改了BERT模型，使其适用于边缘设备，并通过线性量化压缩模型大小，实现了28.74%的减小，同时准确率仅下降0.02%。实验结果显示，在集中式设置中模型推理准确率达到97.79%，而在联邦学习环境中，使用IID和non-IID数据训练后，系统在IoT生态中表现出色，证明了LLMs在计算资源受限设备上的可行性。",
      "categories": [
        "cs.CR",
        "cs.AI"
      ],
      "primary_category": "cs.CR",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2409.19390v1",
      "published_date": "2024-09-28 15:56:28 UTC",
      "updated_date": "2024-09-28 15:56:28 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-20T04:51:54.833122"
    },
    {
      "arxiv_id": "2409.19389v1",
      "title": "Co-design of a novel CMOS highly parallel, low-power, multi-chip neural network accelerator",
      "title_zh": "新型 CMOS 高度并行、低功耗、多芯片神经网络加速器的协同设计",
      "authors": [
        "W Hokenmaier",
        "R Jurasek",
        "E Bowen",
        "R Granger",
        "D Odom"
      ],
      "abstract": "Why do security cameras, sensors, and siri use cloud servers instead of\non-board computation? The lack of very-low-power, high-performance chips\ngreatly limits the ability to field untethered edge devices. We present the\nNV-1, a new low-power ASIC AI processor that greatly accelerates parallel\nprocessing (> 10X) with dramatic reduction in energy consumption (> 100X), via\nmany parallel combined processor-memory units, i.e., a drastically\nnon-von-Neumann architecture, allowing very large numbers of independent\nprocessing streams without bottlenecks due to typical monolithic memory. The\ncurrent initial prototype fab arises from a successful co-development effort\nbetween algorithm- and software-driven architectural design and VLSI design\nrealities. An innovative communication protocol minimizes power usage, and data\ntransport costs among nodes were vastly reduced by eliminating the address bus,\nthrough local target address matching. Throughout the development process, the\nsoftware and architecture teams were able to innovate alongside the circuit\ndesign team's implementation effort. A digital twin of the proposed hardware\nwas developed early on to ensure that the technical implementation met the\narchitectural specifications, and indeed the predicted performance metrics have\nnow been thoroughly verified in real hardware test data. The resulting device\nis currently being used in a fielded edge sensor application; additional proofs\nof principle are in progress demonstrating the proof on the ground of this new\nreal-world extremely low-power high-performance ASIC device.",
      "tldr_zh": "本论文探讨了边缘设备（如安全摄像头和传感器）依赖云服务器的原因，主要归因于缺乏低功耗高性能芯片。研究团队提出NV-1，一种新型低功耗ASIC AI处理器，通过采用非von-Neumann架构的多并行处理器-内存单元，实现并行处理速度提升超过10倍、能耗降低超过100倍。创新点包括优化通信协议、消除地址总线并使用本地目标地址匹配，以减少数据传输开销；开发过程采用算法、软件和VLSI设计的协同方法，并通过硬件数字孪生验证性能。最终，NV-1已在实际边缘传感器应用中部署，并证明了其在低功耗高性能场景中的实用性。",
      "categories": [
        "cs.DC",
        "cs.AI",
        "cs.AR"
      ],
      "primary_category": "cs.DC",
      "comment": "neural network accelerator, low-power design, instruction set design,\n  parallel processors, digital twin",
      "pdf_url": "http://arxiv.org/pdf/2409.19389v1",
      "published_date": "2024-09-28 15:47:16 UTC",
      "updated_date": "2024-09-28 15:47:16 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-20T04:52:06.339996"
    },
    {
      "arxiv_id": "2409.19379v1",
      "title": "Automated conjecturing in mathematics with \\emph{TxGraffiti}",
      "title_zh": "翻译失败",
      "authors": [
        "Randy Davila"
      ],
      "abstract": "\\emph{TxGraffiti} is a data-driven, heuristic-based computer program\ndeveloped to automate the process of generating conjectures across various\nmathematical domains. Since its creation in 2017, \\emph{TxGraffiti} has\ncontributed to numerous mathematical publications, particularly in graph\ntheory. In this paper, we present the design and core principles of\n\\emph{TxGraffiti}, including its roots in the original \\emph{Graffiti} program,\nwhich pioneered the automation of mathematical conjecturing. We describe the\ndata collection process, the generation of plausible conjectures, and methods\nsuch as the \\emph{Dalmatian} heuristic for filtering out redundant or\ntransitive conjectures. Additionally, we highlight its contributions to the\nmathematical literature and introduce a new web-based interface that allows\nusers to explore conjectures interactively. While we focus on graph theory, the\ntechniques demonstrated extend to other areas of mathematics.",
      "tldr_zh": "这篇论文介绍了\\emph{TxGraffiti}，一个数据驱动的启发式程序，用于自动化数学猜想的生成，特别在图论领域做出了显著贡献。程序基于原始\\emph{Graffiti}程序的设计，涵盖数据收集过程、生成可信猜想的方法，以及\\Dalmatian启发式用于过滤冗余或传递猜想。论文还展示了\\emph{TxGraffiti}对数学文献的实际影响，并推出了一个新的网络界面，支持用户交互式探索猜想；这些技术可扩展到其他数学领域。",
      "categories": [
        "math.CO",
        "cs.AI"
      ],
      "primary_category": "math.CO",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2409.19379v1",
      "published_date": "2024-09-28 15:06:31 UTC",
      "updated_date": "2024-09-28 15:06:31 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-20T04:52:18.533134"
    },
    {
      "arxiv_id": "2409.19375v1",
      "title": "DOTA: Distributional Test-Time Adaptation of Vision-Language Models",
      "title_zh": "翻译失败",
      "authors": [
        "Zongbo Han",
        "Jialong Yang",
        "Junfan Li",
        "Qinghua Hu",
        "Qianli Xu",
        "Mike Zheng Shou",
        "Changqing Zhang"
      ],
      "abstract": "Vision-language foundation models (e.g., CLIP) have shown remarkable\nperformance across a wide range of tasks. However, deploying these models may\nbe unreliable when significant distribution gaps exist between the training and\ntest data. The training-free test-time dynamic adapter (TDA) is a promising\napproach to address this issue by storing representative test samples to guide\nthe classification of subsequent ones. However, TDA only naively maintains a\nlimited number of reference samples in the cache, leading to severe test-time\ncatastrophic forgetting when the cache is updated by dropping samples. In this\npaper, we propose a simple yet effective method for DistributiOnal Test-time\nAdaptation (Dota). Instead of naively memorizing representative test samples,\nDota continually estimates the distributions of test samples, allowing the\nmodel to continually adapt to the deployment environment. The test-time\nposterior probabilities are then computed using the estimated distributions\nbased on Bayes' theorem for adaptation purposes. To further enhance the\nadaptability on the uncertain samples, we introduce a new human-in-the-loop\nparadigm which identifies uncertain samples, collects human-feedback, and\nincorporates it into the Dota framework. Extensive experiments validate that\nDota enables CLIP to continually learn, resulting in a significant improvement\ncompared to current state-of-the-art methods.",
      "tldr_zh": "该研究针对视觉语言模型（如 CLIP）在训练和测试数据分布差距大的场景下性能不稳的问题，提出了 DOTA（Distributional Test-Time Adaptation）方法。DOTA 通过持续估计测试样本的分布，而不是简单维护参考样本，从而避免了传统 TDA 方法中的测试时灾难性遗忘，并利用 Bayes' theorem 计算后验概率以实现模型适应。进一步，该框架引入 human-in-the-loop 范式，识别不确定样本、收集人类反馈并整合到系统中。实验结果显示，DOTA 显著提升了 CLIP 的持续学习能力，比现有最先进方法表现出色。",
      "categories": [
        "cs.LG",
        "cs.AI",
        "cs.CL",
        "cs.CV",
        "cs.HC"
      ],
      "primary_category": "cs.LG",
      "comment": "In submission",
      "pdf_url": "http://arxiv.org/pdf/2409.19375v1",
      "published_date": "2024-09-28 15:03:28 UTC",
      "updated_date": "2024-09-28 15:03:28 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-20T04:52:30.555174"
    },
    {
      "arxiv_id": "2409.19366v1",
      "title": "Mind the Gap: Promoting Missing Modality Brain Tumor Segmentation with Alignment",
      "title_zh": "注意差距：通过对齐促进缺失模态脑肿瘤分割",
      "authors": [
        "Tianyi Liu",
        "Zhaorui Tan",
        "Haochuan Jiang",
        "Xi Yang",
        "Kaizhu Huang"
      ],
      "abstract": "Brain tumor segmentation is often based on multiple magnetic resonance\nimaging (MRI). However, in clinical practice, certain modalities of MRI may be\nmissing, which presents an even more difficult scenario. To cope with this\nchallenge, knowledge distillation has emerged as one promising strategy.\nHowever, recent efforts typically overlook the modality gaps and thus fail to\nlearn invariant feature representations across different modalities. Such\ndrawback consequently leads to limited performance for both teachers and\nstudents. To ameliorate these problems, in this paper, we propose a novel\nparadigm that aligns latent features of involved modalities to a well-defined\ndistribution anchor. As a major contribution, we prove that our novel training\nparadigm ensures a tight evidence lower bound, thus theoretically certifying\nits effectiveness. Extensive experiments on different backbones validate that\nthe proposed paradigm can enable invariant feature representations and produce\na teacher with narrowed modality gaps. This further offers superior guidance\nfor missing modality students, achieving an average improvement of 1.75 on dice\nscore.",
      "tldr_zh": "这篇论文针对脑肿瘤分割中磁共振成像(MRI)模态缺失的问题，提出了一种新训练范式，通过将不同模态的潜在特征对齐到一个定义良好的分布锚点，从而缩小模态间差距并学习不变的特征表示。现有知识蒸馏方法忽略了这些模态差异，导致性能受限，而本文的方法理论上证明了其能确保证据下界紧凑。实验在多种骨干网络上验证了该范式，能为缺失模态的学生模型提供更有效的指导，平均提高 Dice 分数 1.75。",
      "categories": [
        "eess.IV",
        "cs.AI",
        "cs.CV"
      ],
      "primary_category": "eess.IV",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2409.19366v1",
      "published_date": "2024-09-28 14:37:42 UTC",
      "updated_date": "2024-09-28 14:37:42 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-20T04:52:49.878050"
    },
    {
      "arxiv_id": "2409.19365v2",
      "title": "Conditional Image Synthesis with Diffusion Models: A Survey",
      "title_zh": "基于扩散模型的条件图像合成：综述",
      "authors": [
        "Zheyuan Zhan",
        "Defang Chen",
        "Jian-Ping Mei",
        "Zhenghe Zhao",
        "Jiawei Chen",
        "Chun Chen",
        "Siwei Lyu",
        "Can Wang"
      ],
      "abstract": "Conditional image synthesis based on user-specified requirements is a key\ncomponent in creating complex visual content. In recent years, diffusion-based\ngenerative modeling has become a highly effective way for conditional image\nsynthesis, leading to exponential growth in the literature. However, the\ncomplexity of diffusion-based modeling, the wide range of image synthesis\ntasks, and the diversity of conditioning mechanisms present significant\nchallenges for researchers to keep up with rapid developments and understand\nthe core concepts on this topic. In this survey, we categorize existing works\nbased on how conditions are integrated into the two fundamental components of\ndiffusion-based modeling, i.e., the denoising network and the sampling process.\nWe specifically highlight the underlying principles, advantages, and potential\nchallenges of various conditioning approaches in the training, re-purposing,\nand specialization stages to construct a desired denoising network. We also\nsummarize six mainstream conditioning mechanisms in the essential sampling\nprocess. All discussions are centered around popular applications. Finally, we\npinpoint some critical yet still open problems to be solved in the future and\nsuggest some possible solutions. Our reviewed works are itemized at\nhttps://github.com/zju-pi/Awesome-Conditional-Diffusion-Models.",
      "tldr_zh": "这篇调查论文综述了基于扩散模型（diffusion models）的条件图像合成技术，聚焦于如何将用户指定条件整合到模型的核心组件中，包括去噪网络（denoising network）和采样过程（sampling process）。论文对现有文献进行分类，讨论了条件在训练、重用和专业化阶段的原理、优势及挑战，并总结了六种主流条件机制及其在流行应用中的表现。最终，它指出了未来关键问题，如模型复杂性和泛化能力，并提供了GitHub资源以促进进一步研究。",
      "categories": [
        "cs.CV",
        "cs.AI"
      ],
      "primary_category": "cs.CV",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2409.19365v2",
      "published_date": "2024-09-28 14:36:38 UTC",
      "updated_date": "2024-10-03 14:01:03 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-20T04:52:53.618708"
    },
    {
      "arxiv_id": "2409.19363v2",
      "title": "Learning Strategy Representation for Imitation Learning in Multi-Agent Games",
      "title_zh": "多智能体游戏中模仿学习的策略表示学习",
      "authors": [
        "Shiqi Lei",
        "Kanghoon Lee",
        "Linjing Li",
        "Jinkyoo Park"
      ],
      "abstract": "The offline datasets for imitation learning (IL) in multi-agent games\ntypically contain player trajectories exhibiting diverse strategies, which\nnecessitate measures to prevent learning algorithms from acquiring undesirable\nbehaviors. Learning representations for these trajectories is an effective\napproach to depicting the strategies employed by each demonstrator. However,\nexisting learning strategies often require player identification or rely on\nstrong assumptions, which are not appropriate for multi-agent games. Therefore,\nin this paper, we introduce the Strategy Representation for Imitation Learning\n(STRIL) framework, which (1) effectively learns strategy representations in\nmulti-agent games, (2) estimates proposed indicators based on these\nrepresentations, and (3) filters out sub-optimal data using the indicators.\nSTRIL is a plug-in method that can be integrated into existing IL algorithms.\nWe demonstrate the effectiveness of STRIL across competitive multi-agent\nscenarios, including Two-player Pong, Limit Texas Hold'em, and Connect Four.\nOur approach successfully acquires strategy representations and indicators,\nthereby identifying dominant trajectories and significantly enhancing existing\nIL performance across these environments.",
      "tldr_zh": "本研究针对多智能体游戏中的Imitation Learning (IL)问题，提出了一种新的框架STRIL，以处理离线数据集中的策略多样性并避免学习到不良行为。STRIL框架能够有效学习策略表示、基于这些表示估计相关指标，并利用指标过滤出次优数据，从而作为插件方法整合到现有IL算法中。在实验中，该方法在Two-player Pong、Limit Texas Hold'em和Connect Four等竞争性场景中成功识别主导轨迹，并显著提升了IL算法的性能。",
      "categories": [
        "cs.MA",
        "cs.AI",
        "cs.LG"
      ],
      "primary_category": "cs.MA",
      "comment": "13 pages, 7 figures. arXiv admin note: substantial text overlap with\n  arXiv:2402.18617",
      "pdf_url": "http://arxiv.org/pdf/2409.19363v2",
      "published_date": "2024-09-28 14:30:17 UTC",
      "updated_date": "2025-02-14 05:22:03 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-20T04:53:06.205957"
    },
    {
      "arxiv_id": "2409.19362v2",
      "title": "1st Place Solution of Multiview Egocentric Hand Tracking Challenge ECCV2024",
      "title_zh": "翻译失败",
      "authors": [
        "Minqiang Zou",
        "Zhi Lv",
        "Riqiang Jin",
        "Tian Zhan",
        "Mochen Yu",
        "Yao Tang",
        "Jiajun Liang"
      ],
      "abstract": "Multi-view egocentric hand tracking is a challenging task and plays a\ncritical role in VR interaction. In this report, we present a method that uses\nmulti-view input images and camera extrinsic parameters to estimate both hand\nshape and pose. To reduce overfitting to the camera layout, we apply crop\njittering and extrinsic parameter noise augmentation. Additionally, we propose\nan offline neural smoothing post-processing method to further improve the\naccuracy of hand position and pose. Our method achieves 13.92mm MPJPE on the\nUmetrack dataset and 21.66mm MPJPE on the HOT3D dataset.",
      "tldr_zh": "本研究提出了一种多视图 egocentric hand tracking 方法，用于 ECCV2024 挑战赛，采用多视图输入图像和 camera extrinsic parameters 来估计手部形状和姿势。该方法通过 crop jittering 和 extrinsic parameter noise augmentation 技术减少对相机布局的过拟合，并引入离线 neural smoothing 后处理方法进一步提升跟踪准确性。在 Umetrack 数据集上，该方法实现 13.92mm MPJPE，在 HOT3D 数据集上达到 21.66mm MPJPE，最终赢得挑战赛第一名。",
      "categories": [
        "cs.CV",
        "cs.AI"
      ],
      "primary_category": "cs.CV",
      "comment": "Accepted in ECCV2024 workshop",
      "pdf_url": "http://arxiv.org/pdf/2409.19362v2",
      "published_date": "2024-09-28 14:26:32 UTC",
      "updated_date": "2024-10-08 08:18:32 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-20T04:53:17.808049"
    },
    {
      "arxiv_id": "2409.19339v2",
      "title": "Visual Question Decomposition on Multimodal Large Language Models",
      "title_zh": "翻译失败",
      "authors": [
        "Haowei Zhang",
        "Jianzhe Liu",
        "Zhen Han",
        "Shuo Chen",
        "Bailan He",
        "Volker Tresp",
        "Zhiqiang Xu",
        "Jindong Gu"
      ],
      "abstract": "Question decomposition has emerged as an effective strategy for prompting\nLarge Language Models (LLMs) to answer complex questions. However, while\nexisting methods primarily focus on unimodal language models, the question\ndecomposition capability of Multimodal Large Language Models (MLLMs) has yet to\nbe explored. To this end, this paper explores visual question decomposition on\nMLLMs. Specifically, we introduce a systematic evaluation framework including a\ndataset and several evaluation criteria to assess the quality of the decomposed\nsub-questions, revealing that existing MLLMs struggle to produce high-quality\nsub-questions. To address this limitation, we propose a specific finetuning\ndataset, DecoVQA+, for enhancing the model's question decomposition capability.\nAiming at enabling models to perform appropriate selective decomposition, we\npropose an efficient finetuning pipeline. The finetuning pipeline consists of\nour proposed dataset and a training objective for selective decomposition.\nFinetuned MLLMs demonstrate significant improvements in the quality of\nsub-questions and the policy of selective question decomposition. Additionally,\nthe models also achieve higher accuracy with selective decomposition on VQA\nbenchmark datasets.",
      "tldr_zh": "该研究探讨了在多模态大语言模型(MLLMs)上进行视觉问题分解的能力，指出现有方法主要针对单模态模型，而MLLMs在生成高质量子问题方面存在挑战。作者构建了一个系统评估框架，包括数据集和评估标准，以评估子问题的质量，并为此提出DecoVQA+数据集和一个高效的微调管道，该管道通过选择性分解训练目标提升模型的分解策略。实验结果显示，微调后的MLLMs在子问题质量和选择性分解政策上显著改进，并在VQA基准数据集上实现了更高的准确率。",
      "categories": [
        "cs.CL",
        "cs.AI",
        "cs.CV",
        "cs.LG"
      ],
      "primary_category": "cs.CL",
      "comment": "Accepted to EMNLP2024 Findings",
      "pdf_url": "http://arxiv.org/pdf/2409.19339v2",
      "published_date": "2024-09-28 12:49:16 UTC",
      "updated_date": "2024-10-07 12:05:55 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-20T04:53:30.163164"
    },
    {
      "arxiv_id": "2409.19330v1",
      "title": "3D-CT-GPT: Generating 3D Radiology Reports through Integration of Large Vision-Language Models",
      "title_zh": "翻译失败",
      "authors": [
        "Hao Chen",
        "Wei Zhao",
        "Yingli Li",
        "Tianyang Zhong",
        "Yisong Wang",
        "Youlan Shang",
        "Lei Guo",
        "Junwei Han",
        "Tianming Liu",
        "Jun Liu",
        "Tuo Zhang"
      ],
      "abstract": "Medical image analysis is crucial in modern radiological diagnostics,\nespecially given the exponential growth in medical imaging data. The demand for\nautomated report generation systems has become increasingly urgent. While prior\nresearch has mainly focused on using machine learning and multimodal language\nmodels for 2D medical images, the generation of reports for 3D medical images\nhas been less explored due to data scarcity and computational complexities.\nThis paper introduces 3D-CT-GPT, a Visual Question Answering (VQA)-based\nmedical visual language model specifically designed for generating radiology\nreports from 3D CT scans, particularly chest CTs. Extensive experiments on both\npublic and private datasets demonstrate that 3D-CT-GPT significantly\noutperforms existing methods in terms of report accuracy and quality. Although\ncurrent methods are few, including the partially open-source CT2Rep and the\nopen-source M3D, we ensured fair comparison through appropriate data conversion\nand evaluation methodologies. Experimental results indicate that 3D-CT-GPT\nenhances diagnostic accuracy and report coherence, establishing itself as a\nrobust solution for clinical radiology report generation. Future work will\nfocus on expanding the dataset and further optimizing the model to enhance its\nperformance and applicability.",
      "tldr_zh": "该论文针对医疗图像分析中的报告生成需求，引入了 3D-CT-GPT，这是一个基于 Visual Question Answering (VQA) 的医疗视觉语言模型，用于从 3D CT 扫描（尤其是胸部 CT）自动生成放射学报告，以解决数据稀缺和计算复杂性等挑战。相比现有方法如 CT2Rep 和 M3D，3D-CT-GPT 在公共和私有数据集上的实验显示，在报告准确性和质量方面显著提升。未来工作将聚焦于扩展数据集和进一步优化模型，以提高其临床适用性。",
      "categories": [
        "cs.CV",
        "cs.AI"
      ],
      "primary_category": "cs.CV",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2409.19330v1",
      "published_date": "2024-09-28 12:31:07 UTC",
      "updated_date": "2024-09-28 12:31:07 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-20T04:53:42.536882"
    },
    {
      "arxiv_id": "2409.19325v1",
      "title": "A Generalized Model for Multidimensional Intransitivity",
      "title_zh": "多维非传递性的泛化模型",
      "authors": [
        "Jiuding Duan",
        "Jiyi Li",
        "Yukino Baba",
        "Hisashi Kashima"
      ],
      "abstract": "Intransitivity is a critical issue in pairwise preference modeling. It refers\nto the intransitive pairwise preferences between a group of players or objects\nthat potentially form a cyclic preference chain and has been long discussed in\nsocial choice theory in the context of the dominance relationship. However,\nsuch multifaceted intransitivity between players and the corresponding player\nrepresentations in high dimensions is difficult to capture. In this paper, we\npropose a probabilistic model that jointly learns each player's d-dimensional\nrepresentation (d>1) and a dataset-specific metric space that systematically\ncaptures the distance metric in Rd over the embedding space. Interestingly, by\nimposing additional constraints in the metric space, our proposed model\ndegenerates to former models used in intransitive representation learning.\nMoreover, we present an extensive quantitative investigation of the vast\nexistence of intransitive relationships between objects in various real-world\nbenchmark datasets. To our knowledge, this investigation is the first of this\ntype. The predictive performance of our proposed method on different real-world\ndatasets, including social choice, election, and online game datasets, shows\nthat our proposed method outperforms several competing methods in terms of\nprediction accuracy.",
      "tldr_zh": "这篇论文提出一个概率模型，用于处理多维 Intransitivity（非传递性）问题，该模型联合学习每个玩家的 d 维表示（d > 1）和数据集特定的度量空间，以系统捕捉嵌入空间中的距离度量。模型通过施加额外约束，可以退化到现有的非传递性表示学习方法，并首次对各种真实世界基准数据集（如社会选择、选举和在线游戏）进行了广泛定量调查，揭示了 Intransitivity 关系的普遍存在。该方法在预测准确性上超过了多项竞争方法，为配对偏好建模提供了更有效的框架。",
      "categories": [
        "cs.LG",
        "cs.AI",
        "cs.CL",
        "cs.GT",
        "econ.GN",
        "q-fin.EC"
      ],
      "primary_category": "cs.LG",
      "comment": "13 pages, 1 figure",
      "pdf_url": "http://arxiv.org/pdf/2409.19325v1",
      "published_date": "2024-09-28 11:48:34 UTC",
      "updated_date": "2024-09-28 11:48:34 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-20T04:53:54.690299"
    },
    {
      "arxiv_id": "2409.19322v1",
      "title": "Scalable Cloud-Native Pipeline for Efficient 3D Model Reconstruction from Monocular Smartphone Images",
      "title_zh": "可扩展的云原生管道，用于从单目智能手机图像高效重建3D模型",
      "authors": [
        "Potito Aghilar",
        "Vito Walter Anelli",
        "Michelantonio Trizio",
        "Tommaso Di Noia"
      ],
      "abstract": "In recent years, 3D models have gained popularity in various fields,\nincluding entertainment, manufacturing, and simulation. However, manually\ncreating these models can be a time-consuming and resource-intensive process,\nmaking it impractical for large-scale industrial applications. To address this\nissue, researchers are exploiting Artificial Intelligence and Machine Learning\nalgorithms to automatically generate 3D models effortlessly. In this paper, we\npresent a novel cloud-native pipeline that can automatically reconstruct 3D\nmodels from monocular 2D images captured using a smartphone camera. Our goal is\nto provide an efficient and easily-adoptable solution that meets the Industry\n4.0 standards for creating a Digital Twin model, which could enhance personnel\nexpertise through accelerated training. We leverage machine learning models\ndeveloped by NVIDIA Research Labs alongside a custom-designed pose recorder\nwith a unique pose compensation component based on the ARCore framework by\nGoogle. Our solution produces a reusable 3D model, with embedded materials and\ntextures, exportable and customizable in any external 3D modelling software or\n3D engine. Furthermore, the whole workflow is implemented by adopting the\nmicroservices architecture standard, enabling each component of the pipeline to\noperate as a standalone replaceable module.",
      "tldr_zh": "本论文提出了一种可扩展的云原生管道，用于从单目智能手机图像高效重建3D模型，以解决手动创建3D模型耗时且资源密集的问题。该管道利用NVIDIA Research Labs的机器学习模型以及基于Google ARCore的自定义姿态记录器和姿态补偿组件，实现自动生成可重用3D模型，并嵌入材料和纹理，支持导出到外部3D软件。该系统采用微服务架构，使每个组件独立可替换，并符合Industry 4.0标准，促进数字孪生模型的创建和人员培训效率提升。",
      "categories": [
        "cs.CV",
        "cs.AI"
      ],
      "primary_category": "cs.CV",
      "comment": "Preprint",
      "pdf_url": "http://arxiv.org/pdf/2409.19322v1",
      "published_date": "2024-09-28 11:15:26 UTC",
      "updated_date": "2024-09-28 11:15:26 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-20T04:54:16.220602"
    },
    {
      "arxiv_id": "2409.19318v1",
      "title": "Fairness Analysis with Shapley-Owen Effects",
      "title_zh": "翻译失败",
      "authors": [
        "Harald Ruess"
      ],
      "abstract": "We argue that relative importance and its equitable attribution in terms of\nShapley-Owen effects is an appropriate one, and, if we accept a small number of\nreasonable imperatives for equitable attribution, the only way to measure\nfairness. On the other hand, the computation of Shapley-Owen effects can be\nvery demanding. Our main technical result is a spectral decomposition of the\nShapley-Owen effects, which decomposes the computation of these indices into a\nmodel-specific and a model-independent part. The model-independent part is\nprecomputed once and for all, and the model-specific computation of\nShapley-Owen effects is expressed analytically in terms of the coefficients of\nthe model's \\emph{polynomial chaos expansion} (PCE), which can now be reused to\ncompute different Shapley-Owen effects. We also propose an algorithm for\ncomputing precise and sparse truncations of the PCE of the model and the\nspectral decomposition of the Shapley-Owen effects, together with upper bounds\non the accumulated approximation errors. The approximations of both the PCE and\nthe Shapley-Owen effects converge to their true values.",
      "tldr_zh": "本文认为，Shapley-Owen effects 是公平性归因的合适方法，且在满足少量合理要求的情况下，是衡量公平性的唯一方式。作者提出了一种谱分解技术，将 Shapley-Owen effects 的计算分解为模型无关部分（可预计算）和模型特定部分（基于模型的多项式混沌展开，polynomial chaos expansion, PCE），从而提高计算效率。论文还开发了一种算法，用于精确且稀疏地截断 PCE 和 Shapley-Owen effects 的谱分解，并提供误差上界的评估，确保近似值收敛到真实结果。",
      "categories": [
        "cs.AI",
        "cs.GT"
      ],
      "primary_category": "cs.AI",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2409.19318v1",
      "published_date": "2024-09-28 11:05:49 UTC",
      "updated_date": "2024-09-28 11:05:49 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-20T04:54:18.636022"
    },
    {
      "arxiv_id": "2409.19315v2",
      "title": "Analog In-Memory Computing Attention Mechanism for Fast and Energy-Efficient Large Language Models",
      "title_zh": "翻译失败",
      "authors": [
        "Nathan Leroux",
        "Paul-Philipp Manea",
        "Chirag Sudarshan",
        "Jan Finkbeiner",
        "Sebastian Siegel",
        "John Paul Strachan",
        "Emre Neftci"
      ],
      "abstract": "Transformer networks, driven by self-attention, are central to Large Language\nModels. In generative Transformers, self-attention uses cache memory to store\ntoken projections, avoiding recomputation at each time step. However,\nGPU-stored projections must be loaded into SRAM for each new generation step,\ncausing latency and energy bottlenecks.\n  We present a custom self-attention in-memory computing architecture based on\nemerging charge-based memories called gain cells, which can be efficiently\nwritten to store new tokens during sequence generation and enable parallel\nanalog dot-product computation required for self-attention. However, the analog\ngain cell circuits introduce non-idealities and constraints preventing the\ndirect mapping of pre-trained models. To circumvent this problem, we design an\ninitialization algorithm achieving text processing performance comparable to\nGPT-2 without training from scratch. Our architecture respectively reduces\nattention latency and energy consumption by up to two and five orders of\nmagnitude compared to GPUs, marking a significant step toward ultra-fast,\nlow-power generative Transformers.",
      "tldr_zh": "这篇论文提出了一种基于模拟内存计算的自注意力机制，利用新兴的电荷基存储（gain cells），旨在加速大型语言模型的生成过程并显著降低能源消耗，以解决GPU上自注意力机制的延迟和瓶颈问题。该机制支持高效写入新token并实现并行模拟点积计算，但由于模拟电路的非理想性，论文设计了一个初始化算法，使其无需从零训练即可达到与GPT-2相当的文本处理性能。实验结果显示，与GPU相比，该架构将注意力延迟和能源消耗分别减少了两个和五个数量级，为超快速、低功耗的生成式Transformer铺平了道路。",
      "categories": [
        "cs.NE",
        "cs.AI",
        "cs.AR",
        "cs.ET"
      ],
      "primary_category": "cs.NE",
      "comment": "25 pages, 6 figures, 1 table",
      "pdf_url": "http://arxiv.org/pdf/2409.19315v2",
      "published_date": "2024-09-28 11:00:11 UTC",
      "updated_date": "2024-11-25 12:14:33 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-20T04:54:40.873002"
    },
    {
      "arxiv_id": "2409.19310v1",
      "title": "Model X-Ray: Detection of Hidden Malware in AI Model Weights using Few Shot Learning",
      "title_zh": "Model X-Ray：使用少样本学习检测 AI 模型权重中的隐藏恶意软件",
      "authors": [
        "Daniel Gilkarov",
        "Ran Dubin"
      ],
      "abstract": "The potential for exploitation of AI models has increased due to the rapid\nadvancement of Artificial Intelligence (AI) and the widespread use of platforms\nlike Model Zoo for sharing AI models. Attackers can embed malware within AI\nmodels through steganographic techniques, taking advantage of the substantial\nsize of these models to conceal malicious data and use it for nefarious\npurposes, e.g. Remote Code Execution. Ensuring the security of AI models is a\nburgeoning area of research essential for safeguarding the multitude of\norganizations and users relying on AI technologies. This study leverages\nwell-studied image few-shot learning techniques by transferring the AI models\nto the image field using a novel image representation. Applying few-shot\nlearning in this field enables us to create practical models, a feat that\nprevious works lack. Our method addresses critical limitations in\nstate-of-the-art detection techniques that hinder their practicality. This\napproach reduces the required training dataset size from 40000 models to just\n6. Furthermore, our methods consistently detect delicate attacks of up to 25%\nembedding rate and even up to 6% in some cases, while previous works were only\nshown to be effective for a 100%-50% embedding rate. We employ a strict\nevaluation strategy to ensure the trained models are generic concerning various\nfactors. In addition, we show that our trained models successfully detect novel\nspread-spectrum steganography attacks, demonstrating the models' impressive\nrobustness just by learning one type of attack. We open-source our code to\nsupport reproducibility and enhance the research in this new field.",
      "tldr_zh": "本论文提出“Model X-Ray”方法，使用 few-shot learning 技术，通过将 AI 模型转换为图像表示，来检测隐藏在模型权重中的恶意软件（如通过 steganographic techniques 嵌入的远程代码执行威胁）。该方法显著减少训练数据集规模，从 40000 模型降至仅 6 个，同时解决了现有检测技术的局限性，能有效识别低嵌入率攻击（如 6% 到 25%）。实验结果显示，该方法在严格评估策略下表现出色，具有泛化性和鲁棒性，甚至能检测新型 spread-spectrum steganography 攻击。作者开源了代码，以支持研究的可重复性和该领域的进一步发展。",
      "categories": [
        "cs.CR",
        "cs.AI"
      ],
      "primary_category": "cs.CR",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2409.19310v1",
      "published_date": "2024-09-28 10:45:28 UTC",
      "updated_date": "2024-09-28 10:45:28 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-20T04:54:42.946864"
    },
    {
      "arxiv_id": "2409.19308v2",
      "title": "Designing Domain-Specific Large Language Models: The Critical Role of Fine-Tuning in Public Opinion Simulation",
      "title_zh": "翻译失败",
      "authors": [
        "Haocheng Lin"
      ],
      "abstract": "Large language models (LLMs) have transformed natural language processing,\nyet face challenges in specialized tasks such as simulating opinions on\nenvironmental policies. This paper introduces a novel fine-tuning approach that\nintegrates socio-demographic data from the UK Household Longitudinal Study,\nuniquely using profiling factors, such as age, gender, income, education, and\nregion. This method enhances the accuracy and representation of generated\nviews. By emulating diverse synthetic profiles, the fine-tuned models\nsignificantly outperform pre-trained counterparts, achieving measurable\nimprovements in capturing demographic nuances. Evaluation metrics, including\nChi-Squared, Cosine Similarity, Jaccard Index, and KL-divergence, reveal a\nstrong alignment between synthetic and real-world opinions. This work\ndemonstrates the potential of fine-tuned LLMs tailored to societal contexts to\nenable more ethical and precise policy simulations. Its broader implications\ninclude deploying LLMs in domains like healthcare and education, fostering\ninclusive and data-driven decision-making in both research and practice.",
      "tldr_zh": "这篇论文探讨了设计领域特定的大型语言模型（LLMs）的关键策略，强调了微调在模拟公众对环境政策意见时的作用。研究引入了一种新颖的微调方法，整合了英国家庭纵向研究（UK Household Longitudinal Study）中的社会人口数据（如年龄、性别、收入、教育和地区），以提升生成观点的准确性和代表性。结果显示，微调后的模型在捕捉人口统计学细微差别方面显著优于预训练模型，并通过Chi-Squared、Cosine Similarity、Jaccard Index和KL-divergence等评估指标证实了合成意见与真实世界意见的高度一致。该方法不仅提高了政策模拟的伦理性和精确性，还为LLMs在医疗和教育等领域应用提供了潜力，促进包容性决策。",
      "categories": [
        "cs.CL",
        "cs.AI"
      ],
      "primary_category": "cs.CL",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2409.19308v2",
      "published_date": "2024-09-28 10:39:23 UTC",
      "updated_date": "2024-12-07 11:06:45 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-20T04:55:05.489847"
    },
    {
      "arxiv_id": "2409.19306v1",
      "title": "CausalVE: Face Video Privacy Encryption via Causal Video Prediction",
      "title_zh": "CausalVE：通过因果视频预测的面部视频隐私加密",
      "authors": [
        "Yubo Huang",
        "Wenhao Feng",
        "Xin Lai",
        "Zixi Wang",
        "Jingzehua Xu",
        "Shuai Zhang",
        "Hongjie He",
        "Fan Chen"
      ],
      "abstract": "Advanced facial recognition technologies and recommender systems with\ninadequate privacy technologies and policies for facial interactions increase\nconcerns about bioprivacy violations. With the proliferation of video and\nlive-streaming websites, public-face video distribution and interactions pose\ngreater privacy risks. Existing techniques typically address the risk of\nsensitive biometric information leakage through various privacy enhancement\nmethods but pose a higher security risk by corrupting the information to be\nconveyed by the interaction data, or by leaving certain biometric features\nintact that allow an attacker to infer sensitive biometric information from\nthem. To address these shortcomings, in this paper, we propose a neural network\nframework, CausalVE. We obtain cover images by adopting a diffusion model to\nachieve face swapping with face guidance and use the speech sequence features\nand spatiotemporal sequence features of the secret video for dynamic video\ninference and prediction to obtain a cover video with the same number of frames\nas the secret video. In addition, we hide the secret video by using reversible\nneural networks for video hiding so that the video can also disseminate secret\ndata. Numerous experiments prove that our CausalVE has good security in public\nvideo dissemination and outperforms state-of-the-art methods from a\nqualitative, quantitative, and visual point of view.",
      "tldr_zh": "本研究提出 CausalVE 框架，通过因果视频预测（Causal Video Prediction）方法实现面部视频隐私加密，以解决现有技术在保护生物隐私时存在的安全隐患，如交互数据破坏或敏感特征泄露。CausalVE 采用扩散模型（diffusion model）进行面部交换，并利用语音序列特征和时空序列特征进行动态视频预测，生成与原视频帧数相同的覆盖视频，同时通过可逆神经网络隐藏秘密视频。实验结果显示，CausalVE 在公共视频传播中表现出色，在定性、定量和视觉方面优于现有最先进方法，提供更可靠的隐私保护。",
      "categories": [
        "cs.CV",
        "cs.AI"
      ],
      "primary_category": "cs.CV",
      "comment": "Submitted to ICLR 2025",
      "pdf_url": "http://arxiv.org/pdf/2409.19306v1",
      "published_date": "2024-09-28 10:34:22 UTC",
      "updated_date": "2024-09-28 10:34:22 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-20T04:55:05.680149"
    },
    {
      "arxiv_id": "2409.19301v1",
      "title": "Privacy Attack in Federated Learning is Not Easy: An Experimental Study",
      "title_zh": "联邦学习中的隐私攻击并非易事：一个实验研究",
      "authors": [
        "Hangyu Zhu",
        "Liyuan Huang",
        "Zhenping Xie"
      ],
      "abstract": "Federated learning (FL) is an emerging distributed machine learning paradigm\nproposed for privacy preservation. Unlike traditional centralized learning\napproaches, FL enables multiple users to collaboratively train a shared global\nmodel without disclosing their own data, thereby significantly reducing the\npotential risk of privacy leakage. However, recent studies have indicated that\nFL cannot entirely guarantee privacy protection, and attackers may still be\nable to extract users' private data through the communicated model gradients.\nAlthough numerous privacy attack FL algorithms have been developed, most are\ndesigned to reconstruct private data from a single step of calculated\ngradients. It remains uncertain whether these methods are effective in\nrealistic federated environments or if they have other limitations. In this\npaper, we aim to help researchers better understand and evaluate the\neffectiveness of privacy attacks on FL. We analyze and discuss recent research\npapers on this topic and conduct experiments in a real FL environment to\ncompare the performance of various attack methods. Our experimental results\nreveal that none of the existing state-of-the-art privacy attack algorithms can\neffectively breach private client data in realistic FL settings, even in the\nabsence of defense strategies. This suggests that privacy attacks in FL are\nmore challenging than initially anticipated.",
      "tldr_zh": "本研究通过实验评估了联邦学习(FL)中隐私攻击的有效性，分析了现有文献并在真实FL环境中比较了各种攻击方法的性能。结果显示，现有的最先进隐私攻击算法无法成功提取客户端私有数据，即使在没有防御策略的情况下。这表明，FL中的隐私攻击比预期的更具挑战性，为提升FL隐私保护提供了重要启示。",
      "categories": [
        "cs.CR",
        "cs.AI"
      ],
      "primary_category": "cs.CR",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2409.19301v1",
      "published_date": "2024-09-28 10:06:34 UTC",
      "updated_date": "2024-09-28 10:06:34 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-20T04:55:17.773309"
    },
    {
      "arxiv_id": "2409.19300v1",
      "title": "Sustaining model performance for covid-19 detection from dynamic audio data: Development and evaluation of a comprehensive drift-adaptive framework",
      "title_zh": "翻译失败",
      "authors": [
        "Theofanis Ganitidis",
        "Maria Athanasiou",
        "Konstantinos Mitsis",
        "Konstantia Zarkogianni",
        "Konstantina S. Nikita"
      ],
      "abstract": "Background: The COVID-19 pandemic has highlighted the need for robust\ndiagnostic tools capable of detecting the disease from diverse and evolving\ndata sources. Machine learning models, especially convolutional neural networks\n(CNNs), have shown promise. However, the dynamic nature of real-world data can\nlead to model drift, where performance degrades over time as the underlying\ndata distribution changes. Addressing this challenge is crucial to maintaining\naccuracy and reliability in diagnostic applications.\n  Objective: This study aims to develop a framework that monitors model drift\nand employs adaptation mechanisms to mitigate performance fluctuations in\nCOVID-19 detection models trained on dynamic audio data.\n  Methods: Two crowd-sourced COVID-19 audio datasets, COVID-19 Sounds and\nCOSWARA, were used. Each was divided into development and post-development\nperiods. A baseline CNN model was trained and evaluated using cough recordings\nfrom the development period. Maximum mean discrepancy (MMD) was used to detect\nchanges in data distributions and model performance between periods. Upon\ndetecting drift, retraining was triggered to update the baseline model. Two\nadaptation approaches were compared: unsupervised domain adaptation (UDA) and\nactive learning (AL).\n  Results: UDA improved balanced accuracy by up to 22% and 24% for the COVID-19\nSounds and COSWARA datasets, respectively. AL yielded even greater\nimprovements, with increases of up to 30% and 60%, respectively.\n  Conclusions: The proposed framework addresses model drift in COVID-19\ndetection, enabling continuous adaptation to evolving data. This approach\nensures sustained model performance, contributing to robust diagnostic tools\nfor COVID-19 and potentially other infectious diseases.",
      "tldr_zh": "这篇论文开发了一个全面的漂移适应框架，旨在维持基于动态音频数据的 COVID-19 检测模型性能，解决数据分布变化导致的模型漂移问题。方法包括使用 CNN 作为基线模型，通过最大均值差异 (MMD) 检测数据分布变化，并在检测到漂移时采用无监督域适应 (UDA) 或主动学习 (AL) 进行模型更新。实验结果显示，UDA 使平衡准确率提高了最多 24%，而 AL 进一步提升至最多 60%。该框架确保诊断模型的持续可靠性能，为 COVID-19 和其他传染病的检测提供稳健工具。",
      "categories": [
        "cs.SD",
        "cs.AI",
        "eess.AS"
      ],
      "primary_category": "cs.SD",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2409.19300v1",
      "published_date": "2024-09-28 10:06:30 UTC",
      "updated_date": "2024-09-28 10:06:30 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-20T04:55:31.096071"
    },
    {
      "arxiv_id": "2409.19291v2",
      "title": "CLIP-MoE: Towards Building Mixture of Experts for CLIP with Diversified Multiplet Upcycling",
      "title_zh": "翻译失败",
      "authors": [
        "Jihai Zhang",
        "Xiaoye Qu",
        "Tong Zhu",
        "Yu Cheng"
      ],
      "abstract": "In recent years, Contrastive Language-Image Pre-training (CLIP) has become a\ncornerstone in multimodal intelligence. However, recent studies have identified\nthat the information loss in the CLIP encoding process is substantial, and CLIP\ntends to capture only coarse-grained features from the input. This deficiency\nsignificantly limits the ability of a single CLIP model to handle images rich\nin visual detail. In this work, we propose a simple yet effective\nmodel-agnostic strategy, Diversified Multiplet Upcycling (DMU), for CLIP. DMU\nefficiently fine-tunes a series of CLIP models that capture different feature\nspaces, from a dense pre-trained CLIP checkpoint, sharing parameters except for\nthe Feed-Forward Network (FFN). These models can then be transformed into a\nCLIP-MoE with a larger model capacity, leading to significantly enhanced\nperformance with minimal computational overhead. To the best of our knowledge,\nDiversified Multiplet Upcycling is the first approach to introduce sparsely\nactivated MoE into CLIP foundation models. Extensive experiments demonstrate\nthe significant performance of CLIP-MoE across various zero-shot retrieval,\nzero-shot image classification tasks, and downstream Multimodal Large Language\nModel (MLLM) benchmarks by serving as a vision encoder. Furthermore,\nDiversified Multiplet Upcycling enables the conversion of any dense CLIP model\ninto CLIP-MoEs, which can seamlessly replace CLIP in a plug-and-play manner\nwithout requiring further adaptation in downstream frameworks. Through\nDiversified Multiplet Upcycling, we aim to provide valuable insights for future\nresearch on developing more efficient and effective multimodal learning\nsystems.",
      "tldr_zh": "该论文针对 CLIP 模型在多模态智能中存在的显著信息损失和粗粒度特征捕捉问题，提出了一种简单有效的策略——Diversified Multiplet Upcycling (DMU)。DMU 通过从密集预训练 CLIP 模型出发，高效微调多个捕捉不同特征空间的模型，仅调整 Feed-Forward Network (FFN) 参数，并将它们转化为 CLIP-MoE，从而显著提升模型容量。实验结果显示，CLIP-MoE 在零样本检索、图像分类和下游 Multimodal Large Language Model (MLLM) 基准上性能大幅提升，且可无缝替换任何密集 CLIP 模型，提供高效的多模态学习系统见解。",
      "categories": [
        "cs.CV",
        "cs.AI"
      ],
      "primary_category": "cs.CV",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2409.19291v2",
      "published_date": "2024-09-28 09:28:51 UTC",
      "updated_date": "2024-10-02 21:50:58 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-20T04:55:43.441743"
    },
    {
      "arxiv_id": "2410.00051v2",
      "title": "Generalizing Consistency Policy to Visual RL with Prioritized Proximal Experience Regularization",
      "title_zh": "翻译失败",
      "authors": [
        "Haoran Li",
        "Zhennan Jiang",
        "Yuhui Chen",
        "Dongbin Zhao"
      ],
      "abstract": "With high-dimensional state spaces, visual reinforcement learning (RL) faces\nsignificant challenges in exploitation and exploration, resulting in low sample\nefficiency and training stability. As a time-efficient diffusion model,\nalthough consistency models have been validated in online state-based RL, it is\nstill an open question whether it can be extended to visual RL. In this paper,\nwe investigate the impact of non-stationary distribution and the actor-critic\nframework on consistency policy in online RL, and find that consistency policy\nwas unstable during the training, especially in visual RL with the\nhigh-dimensional state space. To this end, we suggest sample-based entropy\nregularization to stabilize the policy training, and propose a consistency\npolicy with prioritized proximal experience regularization (CP3ER) to improve\nsample efficiency. CP3ER achieves new state-of-the-art (SOTA) performance in 21\ntasks across DeepMind control suite and Meta-world. To our knowledge, CP3ER is\nthe first method to apply diffusion/consistency models to visual RL and\ndemonstrates the potential of consistency models in visual RL. More\nvisualization results are available at https://jzndd.github.io/CP3ER-Page/.",
      "tldr_zh": "本研究针对视觉强化学习（visual RL）的低样本效率和训练不稳定问题，探讨了将Consistency Policy扩展到高维状态空间的挑战，并发现其在非平稳分布和actor-critic框架下容易不稳定。为此，提出CP3ER（Consistency Policy with Prioritized Proximal Experience Regularization），通过基于样本的熵正则化和优先级近端经验正则化来稳定策略训练并提升样本效率。实验结果显示，CP3ER在DeepMind control suite和Meta-world的21个任务中达到了新的SOTA性能，并首次证明了扩散/一致性模型在visual RL中的潜力。",
      "categories": [
        "cs.LG",
        "cs.AI",
        "cs.CV"
      ],
      "primary_category": "cs.LG",
      "comment": "Accepted at the Thirty-Eighth Annual Conference on Neural Information\n  Processing Systems (NeurIPS2024)",
      "pdf_url": "http://arxiv.org/pdf/2410.00051v2",
      "published_date": "2024-09-28 09:24:10 UTC",
      "updated_date": "2024-10-29 09:44:15 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-20T04:55:53.862474"
    },
    {
      "arxiv_id": "2409.19279v1",
      "title": "Distributed Optimization via Energy Conservation Laws in Dilated Coordinates",
      "title_zh": "在扩张坐标中通过能量守恒定律实现分布式优化",
      "authors": [
        "Mayank Baranwal",
        "Kushal Chakrabarti"
      ],
      "abstract": "Optimizing problems in a distributed manner is critical for systems involving\nmultiple agents with private data. Despite substantial interest, a unified\nmethod for analyzing the convergence rates of distributed optimization\nalgorithms is lacking. This paper introduces an energy conservation approach\nfor analyzing continuous-time dynamical systems in dilated coordinates. Instead\nof directly analyzing dynamics in the original coordinate system, we establish\na conserved quantity, akin to physical energy, in the dilated coordinate\nsystem. Consequently, convergence rates can be explicitly expressed in terms of\nthe inverse time-dilation factor. Leveraging this generalized approach, we\nformulate a novel second-order distributed accelerated gradient flow with a\nconvergence rate of $O\\left(1/t^{2-\\epsilon}\\right)$ in time $t$ for\n$\\epsilon>0$. We then employ a semi second-order symplectic Euler\ndiscretization to derive a rate-matching algorithm with a convergence rate of\n$O\\left(1/k^{2-\\epsilon}\\right)$ in $k$ iterations. To the best of our\nknowledge, this represents the most favorable convergence rate for any\ndistributed optimization algorithm designed for smooth convex optimization. Its\naccelerated convergence behavior is benchmarked against various\nstate-of-the-art distributed optimization algorithms on practical, large-scale\nproblems.",
      "tldr_zh": "这篇论文提出了一种基于能量守恒定律在扩张坐标(dilated coordinates)中分析分布式优化(distributed optimization)算法的新方法，通过建立守恒量来明确表达收敛率。论文引入了一个新型二阶分布式加速梯度流(second-order distributed accelerated gradient flow)，其在连续时间动力系统中实现了 O(1/t^{2-ε}) 的收敛率。接着，利用半二阶辛欧拉(semi second-order symplectic Euler)离散化方法，开发了相应算法，达到 O(1/k^{2-ε}) 的迭代收敛率，并在实际大规模问题上表现出优于现有算法的性能。",
      "categories": [
        "math.OC",
        "cs.AI",
        "cs.LG",
        "cs.SY",
        "eess.SY",
        "math.DS"
      ],
      "primary_category": "math.OC",
      "comment": "10 pages; (Near) optimal convergence rate",
      "pdf_url": "http://arxiv.org/pdf/2409.19279v1",
      "published_date": "2024-09-28 08:02:43 UTC",
      "updated_date": "2024-09-28 08:02:43 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-20T04:56:08.508681"
    },
    {
      "arxiv_id": "2409.19270v1",
      "title": "OpenSep: Leveraging Large Language Models with Textual Inversion for Open World Audio Separation",
      "title_zh": "翻译失败",
      "authors": [
        "Tanvir Mahmud",
        "Diana Marculescu"
      ],
      "abstract": "Audio separation in real-world scenarios, where mixtures contain a variable\nnumber of sources, presents significant challenges due to limitations of\nexisting models, such as over-separation, under-separation, and dependence on\npredefined training sources. We propose OpenSep, a novel framework that\nleverages large language models (LLMs) for automated audio separation,\neliminating the need for manual intervention and overcoming source limitations.\nOpenSep uses textual inversion to generate captions from audio mixtures with\noff-the-shelf audio captioning models, effectively parsing the sound sources\npresent. It then employs few-shot LLM prompting to extract detailed audio\nproperties of each parsed source, facilitating separation in unseen mixtures.\nAdditionally, we introduce a multi-level extension of the mix-and-separate\ntraining framework to enhance modality alignment by separating single source\nsounds and mixtures simultaneously. Extensive experiments demonstrate OpenSep's\nsuperiority in precisely separating new, unseen, and variable sources in\nchallenging mixtures, outperforming SOTA baseline methods. Code is released at\nhttps://github.com/tanvir-utexas/OpenSep.git",
      "tldr_zh": "本研究提出OpenSep框架，利用Large Language Models (LLMs) 和Textual Inversion，实现开放世界音频分离，解决现有模型在处理变量来源混合时存在的过度分离、不足分离和依赖预定义来源的问题。OpenSep通过现成音频字幕模型生成混合音频的字幕，并采用少样本LLM提示提取每个来源的详细属性，同时引入多级混合和分离训练框架来提升模态对齐。实验结果表明，OpenSep在分离新的、未见和挑战性混合来源方面优于SOTA基线方法，代码已开源于https://github.com/tanvir-utexas/OpenSep.git。",
      "categories": [
        "cs.SD",
        "cs.AI",
        "eess.AS"
      ],
      "primary_category": "cs.SD",
      "comment": "Accepted in EMNLP 2024 Main",
      "pdf_url": "http://arxiv.org/pdf/2409.19270v1",
      "published_date": "2024-09-28 06:59:52 UTC",
      "updated_date": "2024-09-28 06:59:52 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-20T04:56:21.640878"
    },
    {
      "arxiv_id": "2409.19258v1",
      "title": "VecLSTM: Trajectory Data Processing and Management for Activity Recognition through LSTM Vectorization and Database Integration",
      "title_zh": "翻译失败",
      "authors": [
        "Solmaz Seyed Monir",
        "Dongfang Zhao"
      ],
      "abstract": "Activity recognition is a challenging task due to the large scale of\ntrajectory data and the need for prompt and efficient processing. Existing\nmethods have attempted to mitigate this problem by employing traditional LSTM\narchitectures, but these approaches often suffer from inefficiencies in\nprocessing large datasets. In response to this challenge, we propose VecLSTM, a\nnovel framework that enhances the performance and efficiency of LSTM-based\nneural networks. Unlike conventional approaches, VecLSTM incorporates\nvectorization layers, leveraging optimized mathematical operations to process\ninput sequences more efficiently. We have implemented VecLSTM and incorporated\nit into the MySQL database. To evaluate the effectiveness of VecLSTM, we\ncompare its performance against a conventional LSTM model using a dataset\ncomprising 1,467,652 samples with seven unique labels. Experimental results\ndemonstrate superior accuracy and efficiency compared to the state-of-the-art,\nwith VecLSTM achieving a validation accuracy of 85.57\\%, a test accuracy of\n85.47\\%, and a weighted F1-score of 0.86. Furthermore, VecLSTM significantly\nreduces training time, offering a 26.2\\% reduction compared to traditional LSTM\nmodels.",
      "tldr_zh": "本论文针对活动识别中轨迹数据规模大和处理效率低的问题，提出了一种新型框架VecLSTM，通过整合vectorization layers和MySQL数据库，优化LSTM模型的数学操作以提升性能和效率。与传统LSTM方法相比，VecLSTM在包含1,467,652样本的数据集上实现了85.57%的验证准确率、85.47%的测试准确率以及0.86的加权F1-score，同时将训练时间减少26.2%。这项创新为大规模轨迹数据管理提供了更高效的解决方案。",
      "categories": [
        "cs.LG",
        "cs.AI",
        "cs.DB",
        "cs.NE"
      ],
      "primary_category": "cs.LG",
      "comment": "10 pages, 5 figures",
      "pdf_url": "http://arxiv.org/pdf/2409.19258v1",
      "published_date": "2024-09-28 06:22:44 UTC",
      "updated_date": "2024-09-28 06:22:44 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-20T04:56:32.829502"
    },
    {
      "arxiv_id": "2409.19255v2",
      "title": "DENEB: A Hallucination-Robust Automatic Evaluation Metric for Image Captioning",
      "title_zh": "翻译失败",
      "authors": [
        "Kazuki Matsuda",
        "Yuiga Wada",
        "Komei Sugiura"
      ],
      "abstract": "In this work, we address the challenge of developing automatic evaluation\nmetrics for image captioning, with a particular focus on robustness against\nhallucinations. Existing metrics are often inadequate for handling\nhallucinations, primarily due to their limited ability to compare candidate\ncaptions with multifaceted reference captions. To address this shortcoming, we\npropose DENEB, a novel supervised automatic evaluation metric specifically\nrobust against hallucinations. DENEB incorporates the Sim-Vec Transformer, a\nmechanism that processes multiple references simultaneously, thereby\nefficiently capturing the similarity between an image, a candidate caption, and\nreference captions. To train DENEB, we construct the diverse and balanced\nNebula dataset comprising 32,978 images, paired with human judgments provided\nby 805 annotators. We demonstrated that DENEB achieves state-of-the-art\nperformance among existing LLM-free metrics on the FOIL, Composite,\nFlickr8K-Expert, Flickr8K-CF, Nebula, and PASCAL-50S datasets, validating its\neffectiveness and robustness against hallucinations.",
      "tldr_zh": "本研究针对图像字幕评估中幻觉(hallucinations)问题的鲁棒性不足，提出了一种新型监督自动评估指标DENEB，以提升候选字幕与多方面参考字幕的相似性比较。DENEB 整合了Sim-Vec Transformer机制，能够同时处理多个参考字幕，从而准确捕获图像、候选字幕和参考之间的关系；为此，研究者构建了Nebula数据集，包含32,978张图像和805名标注者的人类判断。实验结果显示，DENEB在FOIL、Composite、Flickr8K-Expert等数据集上，超越现有非LLM指标，实现了最先进性能，并验证了其对幻觉的鲁棒性。",
      "categories": [
        "cs.CV",
        "cs.AI",
        "cs.CL"
      ],
      "primary_category": "cs.CV",
      "comment": "ACCV 2024",
      "pdf_url": "http://arxiv.org/pdf/2409.19255v2",
      "published_date": "2024-09-28 06:04:56 UTC",
      "updated_date": "2024-10-24 11:29:41 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-20T04:56:48.677229"
    },
    {
      "arxiv_id": "2409.19247v1",
      "title": "Edit-Constrained Decoding for Sentence Simplification",
      "title_zh": "翻译失败",
      "authors": [
        "Tatsuya Zetsu",
        "Yuki Arase",
        "Tomoyuki Kajiwara"
      ],
      "abstract": "We propose edit operation based lexically constrained decoding for sentence\nsimplification. In sentence simplification, lexical paraphrasing is one of the\nprimary procedures for rewriting complex sentences into simpler\ncorrespondences. While previous studies have confirmed the efficacy of\nlexically constrained decoding on this task, their constraints can be loose and\nmay lead to sub-optimal generation. We address this problem by designing\nconstraints that replicate the edit operations conducted in simplification and\ndefining stricter satisfaction conditions. Our experiments indicate that the\nproposed method consistently outperforms the previous studies on three English\nsimplification corpora commonly used in this task.",
      "tldr_zh": "本文提出了一种基于编辑操作的词汇约束解码（edit operation based lexically constrained decoding）方法，用于句子简化任务，以改进词汇改写的准确性。相比以往研究，该方法设计了更严格的约束条件，模拟简化过程中的编辑操作，从而避免了松散约束导致的 suboptimal 生成。实验结果表明，该方法在三个常用英语简化语料库上 consistently 优于之前的研究。",
      "categories": [
        "cs.CL",
        "cs.AI"
      ],
      "primary_category": "cs.CL",
      "comment": "Accepted by EMNLP2024-Findings",
      "pdf_url": "http://arxiv.org/pdf/2409.19247v1",
      "published_date": "2024-09-28 05:39:50 UTC",
      "updated_date": "2024-09-28 05:39:50 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-20T04:57:06.517896"
    },
    {
      "arxiv_id": "2409.19237v1",
      "title": "The Price of Pessimism for Automated Defense",
      "title_zh": "翻译失败",
      "authors": [
        "Erick Galinkin",
        "Emmanouil Pountourakis",
        "Spiros Mancoridis"
      ],
      "abstract": "The well-worn George Box aphorism ``all models are wrong, but some are\nuseful'' is particularly salient in the cybersecurity domain, where the\nassumptions built into a model can have substantial financial or even national\nsecurity impacts. Computer scientists are often asked to optimize for\nworst-case outcomes, and since security is largely focused on risk mitigation,\npreparing for the worst-case scenario appears rational. In this work, we\ndemonstrate that preparing for the worst case rather than the most probable\ncase may yield suboptimal outcomes for learning agents. Through the lens of\nstochastic Bayesian games, we first explore different attacker knowledge\nmodeling assumptions that impact the usefulness of models to cybersecurity\npractitioners. By considering different models of attacker knowledge about the\nstate of the game and a defender's hidden information, we find that there is a\ncost to the defender for optimizing against the worst case.",
      "tldr_zh": "这篇论文探讨了在自动化防御中，过度优化最坏情况（即“悲观主义”）的代价，强调网络安全领域模型假设可能导致次优结果。作者通过随机贝叶斯游戏(stochastic Bayesian games)的框架，分析了攻击者知识建模假设对防御策略的影响，包括攻击者对游戏状态和防御者隐藏信息的了解。研究发现，防御者专注于最坏情况而非最可能情况，会为学习代理带来额外成本，从而为更有效的安全风险缓解提供重要启示。",
      "categories": [
        "cs.CR",
        "cs.AI"
      ],
      "primary_category": "cs.CR",
      "comment": "Accepted to GameSec 2024",
      "pdf_url": "http://arxiv.org/pdf/2409.19237v1",
      "published_date": "2024-09-28 04:54:23 UTC",
      "updated_date": "2024-09-28 04:54:23 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-20T04:57:09.727443"
    },
    {
      "arxiv_id": "2409.19231v1",
      "title": "Double Actor-Critic with TD Error-Driven Regularization in Reinforcement Learning",
      "title_zh": "翻译失败",
      "authors": [
        "Haohui Chen",
        "Zhiyong Chen",
        "Aoxiang Liu",
        "Wentuo Fang"
      ],
      "abstract": "To obtain better value estimation in reinforcement learning, we propose a\nnovel algorithm based on the double actor-critic framework with temporal\ndifference error-driven regularization, abbreviated as TDDR. TDDR employs\ndouble actors, with each actor paired with a critic, thereby fully leveraging\nthe advantages of double critics. Additionally, TDDR introduces an innovative\ncritic regularization architecture. Compared to classical deterministic policy\ngradient-based algorithms that lack a double actor-critic structure, TDDR\nprovides superior estimation. Moreover, unlike existing algorithms with double\nactor-critic frameworks, TDDR does not introduce any additional\nhyperparameters, significantly simplifying the design and implementation\nprocess. Experiments demonstrate that TDDR exhibits strong competitiveness\ncompared to benchmark algorithms in challenging continuous control tasks.",
      "tldr_zh": "本研究提出了一种新型强化学习算法TDDR（Temporal Difference Error-Driven Regularization），基于双Actor-Critic框架，通过双Actor和双Critic结构充分利用双Critic的优势，并引入创新的Critic正则化架构，以提升价值估计的准确性。与经典的确定性策略梯度算法相比，TDDR提供更优的性能，且不引入额外超参数，简化了设计和实现过程。实验结果显示，在挑战性的连续控制任务中，TDDR与基准算法相比表现出色，具有很强的竞争力。",
      "categories": [
        "cs.LG",
        "cs.AI"
      ],
      "primary_category": "cs.LG",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2409.19231v1",
      "published_date": "2024-09-28 04:22:42 UTC",
      "updated_date": "2024-09-28 04:22:42 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-20T04:57:30.327024"
    },
    {
      "arxiv_id": "2410.00049v2",
      "title": "Epidemiology-Aware Neural ODE with Continuous Disease Transmission Graph",
      "title_zh": "翻译失败",
      "authors": [
        "Guancheng Wan",
        "Zewen Liu",
        "Max S. Y. Lau",
        "B. Aditya Prakash",
        "Wei Jin"
      ],
      "abstract": "Effective epidemic forecasting is critical for public health strategies and\nefficient medical resource allocation, especially in the face of rapidly\nspreading infectious diseases. However, existing deep-learning methods often\noverlook the dynamic nature of epidemics and fail to account for the specific\nmechanisms of disease transmission. In response to these challenges, we\nintroduce an innovative end-to-end framework called Epidemiology-Aware Neural\nODE with Continuous Disease Transmission Graph (EARTH) in this paper. To learn\ncontinuous and regional disease transmission patterns, we first propose EANO,\nwhich seamlessly integrates the neural ODE approach with the epidemic\nmechanism, considering the complex spatial spread process during epidemic\nevolution. Additionally, we introduce GLTG to model global infection trends and\nleverage these signals to guide local transmission dynamically. To accommodate\nboth the global coherence of epidemic trends and the local nuances of epidemic\ntransmission patterns, we build a cross-attention approach to fuse the most\nmeaningful information for forecasting. Through the smooth synergy of both\ncomponents, EARTH offers a more robust and flexible approach to understanding\nand predicting the spread of infectious diseases. Extensive experiments show\nEARTH superior performance in forecasting real-world epidemics compared to\nstate-of-the-art methods. The code will be available at\nhttps://github.com/Emory-Melody/EpiLearn.",
      "tldr_zh": "该论文提出了一种名为 EARTH 的端到端框架，用于改进流行病预测，解决现有深度学习方法忽略疾病传播动态和机制的问题。EARTH 整合了 EANO（Epidemiology-Aware Neural ODE），结合神经 ODE 与流行病机制来学习连续的区域传播模式，并引入 GLTG 来建模全球感染趋势，同时利用跨注意力机制融合全球和本地信息以实现更精确的预测。实验结果显示，EARTH 在真实世界流行病预测任务中优于最先进方法，提供更可靠的公共卫生决策支持。",
      "categories": [
        "cs.LG",
        "cs.AI",
        "cs.SI"
      ],
      "primary_category": "cs.LG",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2410.00049v2",
      "published_date": "2024-09-28 04:07:16 UTC",
      "updated_date": "2024-11-10 05:26:44 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-20T04:57:32.492530"
    },
    {
      "arxiv_id": "2409.19226v1",
      "title": "Learning to Bridge the Gap: Efficient Novelty Recovery with Planning and Reinforcement Learning",
      "title_zh": "翻译失败",
      "authors": [
        "Alicia Li",
        "Nishanth Kumar",
        "Tomás Lozano-Pérez",
        "Leslie Kaelbling"
      ],
      "abstract": "The real world is unpredictable. Therefore, to solve long-horizon\ndecision-making problems with autonomous robots, we must construct agents that\nare capable of adapting to changes in the environment during deployment.\nModel-based planning approaches can enable robots to solve complex,\nlong-horizon tasks in a variety of environments. However, such approaches tend\nto be brittle when deployed into an environment featuring a novel situation\nthat their underlying model does not account for. In this work, we propose to\nlearn a ``bridge policy'' via Reinforcement Learning (RL) to adapt to such\nnovelties. We introduce a simple formulation for such learning, where the RL\nproblem is constructed with a special ``CallPlanner'' action that terminates\nthe bridge policy and hands control of the agent back to the planner. This\nallows the RL policy to learn the set of states in which querying the planner\nand following the returned plan will achieve the goal. We show that this\nformulation enables the agent to rapidly learn by leveraging the planner's\nknowledge to avoid challenging long-horizon exploration caused by sparse\nreward. In experiments across three different simulated domains of varying\ncomplexity, we demonstrate that our approach is able to learn policies that\nadapt to novelty more efficiently than several baselines, including a pure RL\nbaseline. We also demonstrate that the learned bridge policy is generalizable\nin that it can be combined with the planner to enable the agent to solve more\ncomplex tasks with multiple instances of the encountered novelty.",
      "tldr_zh": "这篇论文提出了一种结合规划和 Reinforcement Learning (RL) 的方法，帮助自主机器人适应环境中的新颖性（novelty），以解决长期决策问题。作者引入“bridge policy”通过 RL 学习，并在其中使用“CallPlanner”动作来动态切换控制权给规划器，从而利用规划器的知识避免稀疏奖励导致的复杂探索。实验结果显示，该方法在三个模拟域中比纯 RL 等基线更高效地学习适应策略，并证明了其泛化能力，能处理更复杂的任务。",
      "categories": [
        "cs.RO",
        "cs.AI"
      ],
      "primary_category": "cs.RO",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2409.19226v1",
      "published_date": "2024-09-28 03:41:25 UTC",
      "updated_date": "2024-09-28 03:41:25 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-20T04:57:48.431756"
    },
    {
      "arxiv_id": "2410.12794v2",
      "title": "Disaggregating Embedding Recommendation Systems with FlexEMR",
      "title_zh": "翻译失败",
      "authors": [
        "Yibo Huang",
        "Zhenning Yang",
        "Jiarong Xing",
        "Yi Dai",
        "Yiming Qiu",
        "Dingming Wu",
        "Fan Lai",
        "Ang Chen"
      ],
      "abstract": "Efficiently serving embedding-based recommendation (EMR) models remains a\nsignificant challenge due to their increasingly large memory requirements.\nToday's practice splits the model across many monolithic servers, where a mix\nof GPUs, CPUs, and DRAM is provisioned in fixed proportions. This approach\nleads to suboptimal resource utilization and increased costs. Disaggregating\nembedding operations from neural network inference is a promising solution but\nraises novel networking challenges. In this paper, we discuss the design of\nFlexEMR for optimized EMR disaggregation. FlexEMR proposes two sets of\ntechniques to tackle the networking challenges: Leveraging the temporal and\nspatial locality of embedding lookups to reduce data movement over the network,\nand designing an optimized multi-threaded RDMA engine for concurrent lookup\nsubrequests. We outline the design space for each technique and present initial\nresults from our early prototype.",
      "tldr_zh": "该论文探讨了嵌入式推荐系统（EMR）的内存需求问题，传统方法通过在多服务器上固定分配GPU、CPU和DRAM导致资源利用率低下和成本增加。FlexEMR框架通过将嵌入操作从神经网络推理中分离，提出两种关键技术：利用嵌入查找的temporal and spatial locality来减少网络数据传输，以及设计一个优化的多线程RDMA引擎来处理并发查找子请求。这些技术优化了网络挑战的设计空间，并通过早期原型展示了初步的性能提升潜力。",
      "categories": [
        "cs.IR",
        "cs.AI"
      ],
      "primary_category": "cs.IR",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2410.12794v2",
      "published_date": "2024-09-28 01:58:11 UTC",
      "updated_date": "2024-12-30 19:07:23 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-20T04:57:56.351070"
    },
    {
      "arxiv_id": "2410.12793v1",
      "title": "Environment Scan of Generative AI Infrastructure for Clinical and Translational Science",
      "title_zh": "翻译失败",
      "authors": [
        "Betina Idnay",
        "Zihan Xu",
        "William G. Adams",
        "Mohammad Adibuzzaman",
        "Nicholas R. Anderson",
        "Neil Bahroos",
        "Douglas S. Bell",
        "Cody Bumgardner",
        "Thomas Campion",
        "Mario Castro",
        "James J. Cimino",
        "I. Glenn Cohen",
        "David Dorr",
        "Peter L Elkin",
        "Jungwei W. Fan",
        "Todd Ferris",
        "David J. Foran",
        "David Hanauer",
        "Mike Hogarth",
        "Kun Huang",
        "Jayashree Kalpathy-Cramer",
        "Manoj Kandpal",
        "Niranjan S. Karnik",
        "Avnish Katoch",
        "Albert M. Lai",
        "Christophe G. Lambert",
        "Lang Li",
        "Christopher Lindsell",
        "Jinze Liu",
        "Zhiyong Lu",
        "Yuan Luo",
        "Peter McGarvey",
        "Eneida A. Mendonca",
        "Parsa Mirhaji",
        "Shawn Murphy",
        "John D. Osborne",
        "Ioannis C. Paschalidis",
        "Paul A. Harris",
        "Fred Prior",
        "Nicholas J. Shaheen",
        "Nawar Shara",
        "Ida Sim",
        "Umberto Tachinardi",
        "Lemuel R. Waitman",
        "Rosalind J. Wright",
        "Adrian H. Zai",
        "Kai Zheng",
        "Sandra Soo-Jin Lee",
        "Bradley A. Malin",
        "Karthik Natarajan",
        "W. Nicholson Price II",
        "Rui Zhang",
        "Yiye Zhang",
        "Hua Xu",
        "Jiang Bian",
        "Chunhua Weng",
        "Yifan Peng"
      ],
      "abstract": "This study reports a comprehensive environmental scan of the generative AI\n(GenAI) infrastructure in the national network for clinical and translational\nscience across 36 institutions supported by the Clinical and Translational\nScience Award (CTSA) Program led by the National Center for Advancing\nTranslational Sciences (NCATS) of the National Institutes of Health (NIH) at\nthe United States. With the rapid advancement of GenAI technologies, including\nlarge language models (LLMs), healthcare institutions face unprecedented\nopportunities and challenges. This research explores the current status of\nGenAI integration, focusing on stakeholder roles, governance structures, and\nethical considerations by administering a survey among leaders of health\ninstitutions (i.e., representing academic medical centers and health systems)\nto assess the institutional readiness and approach towards GenAI adoption. Key\nfindings indicate a diverse range of institutional strategies, with most\norganizations in the experimental phase of GenAI deployment. The study\nhighlights significant variations in governance models, with a strong\npreference for centralized decision-making but notable gaps in workforce\ntraining and ethical oversight. Moreover, the results underscore the need for a\nmore coordinated approach to GenAI governance, emphasizing collaboration among\nsenior leaders, clinicians, information technology staff, and researchers. Our\nanalysis also reveals concerns regarding GenAI bias, data security, and\nstakeholder trust, which must be addressed to ensure the ethical and effective\nimplementation of GenAI technologies. This study offers valuable insights into\nthe challenges and opportunities of GenAI integration in healthcare, providing\na roadmap for institutions aiming to leverage GenAI for improved quality of\ncare and operational efficiency.",
      "tldr_zh": "本研究对生成式 AI (GenAI) 基础设施在临床和翻译科学领域的整合进行了全面环境扫描，涵盖了由 NIH 的 Clinical and Translational Science Award (CTSA) 程序支持的 36 个机构。研究通过对健康机构领导者的调查，评估了利益相关者角色、治理结构和伦理考虑，发现大多数组织处于 GenAI 部署的实验阶段，并存在治理模型多样化、劳动力培训不足以及对偏见和数据安全的担忧。总体而言，该研究突出了 GenAI 采用的挑战与机会，并为机构提供路线图，以促进更协调的治理策略，提升护理质量和操作效率。",
      "categories": [
        "cs.CY",
        "cs.AI",
        "cs.HC"
      ],
      "primary_category": "cs.CY",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2410.12793v1",
      "published_date": "2024-09-28 01:53:13 UTC",
      "updated_date": "2024-09-28 01:53:13 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-20T04:58:10.120455"
    }
  ],
  "raw_papers_fetched": true,
  "papers_count": 49,
  "processed_papers_count": 49,
  "failed_papers_count": 0,
  "summary_generated": true,
  "daily_data_saved": true,
  "last_update": "2025-05-20T04:58:24.827642"
}