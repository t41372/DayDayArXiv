{
  "date": "2024-06-04",
  "category": "cs.AI",
  "summary": "欢迎来到 UTC 时间 2024-06-04 的 arXiv 中文 TLDR 快报！  \n\n今天 arXiv 的论文主要聚焦于 AI 模型优化（如大型语言模型的推理和安全）、图像生成与处理、联邦学习和隐私保护等领域，强调了 LLMs 在常识推理和多模态任务中的突破性进展，令人印象深刻的文章包括 ACCORD（用于 LLMs 的多跳常识推理基准）和 PSALM（LLMs 与符号规划器的结合），这些工作展示了 AI 在实际应用中的潜力。  \n\n以下是今日论文的精选摘要，我将相关主题的论文归类讨论，先优先聊重要或话题度高的文章（如 LLMs 创新和多模态模型），对其他次要内容快速掠过。每篇论文标题以中文 + 英文形式列出，焦点放在核心贡献和发现上。  \n\n### LLMs 和常识推理  \n- **ACCORD: Closing the Commonsense Measurability Gap**（ACCORD: 关闭常识可测量性差距）  \n  这篇论文提出 ACCORD 框架和基准，用于拆解 LLMs 的常识基础和推理能力，通过受控的多跳反事实生成基准，测试如 GPT-4o 和 Llama-3 的性能，发现这些模型在复杂推理中快速退化至随机水平，并提供自动生成基准的代码和排行榜，显著提升了 LLMs 评估的量化性。  \n\n- **Language Models can Infer Action Semantics for Symbolic Planners from Environment Feedback**（语言模型能从环境反馈推断符号规划器的动作语义）  \n  作者提出 PSALM 方法，让 LLMs 通过环境反馈学习符号规划器的动作语义，在 7 个环境中实验显示，该方法将计划成功率从 36.4% 提升到 100%，更高效地探索环境，解决了 LLMs 在规划任务中的推理和状态跟踪问题。  \n\n- **Disentangling Logic: The Role of Context in Large Language Model Reasoning Capabilities**（解构逻辑：上下文在大语言模型推理能力中的作用）  \n  这篇工作构建了抽象和情境化逻辑数据集，探讨 LLMs 在命题逻辑推理中的泛化，发现抽象问题无法完全反映真实场景，并提供代码和数据集，支持 LLMs 推理能力的细化分析。  \n\n- **Self-Control of LLM Behaviors by Compressing Suffix Gradient into Prefix Controller**（通过压缩后缀梯度到前缀控制器实现 LLMs 行为的自我控制）  \n  论文引入 SelfControl 方法，使用梯度压缩控制 LLMs 生成过程，实现无监督行为调整，如提升真实性和隐私保护，实验显示在多个任务中性能提升显著（e.g., 毒性减少 8.3%）。  \n\n### 多模态和图像生成  \n- **Parrot: Multilingual Visual Instruction Tuning**（Parrot: 多语言视觉指令微调）  \n  这篇重要工作提出 Parrot 方法，使用混合专家模型微调 LLMs 处理多语言视觉任务，显著提升非英语性能，并在多任务上达到 SOTA，数据集和代码开源。  \n\n- **LADI v2: Multi-label Dataset and Classifiers for Low-Altitude Disaster Imagery**（LADI v2: 用于低空灾害图像的多标签数据集和分类器）  \n  作者发布 LADI v2 数据集（约 10,000 张图像），并提供基线分类器，支持紧急响应中的图像分析，实验证明其在多标签分类中优于现有视觉语言模型。  \n\n- **Reanimating Images using Neural Representations of Dynamic Stimuli**（使用动态刺激的神经表示重现图像）  \n  该论文开发 BrainNRDS 方法，利用视频扩散模型从脑成像数据中解码视觉运动，实现了图像重现和视频解码，展示了脑科学与 AI 的交叉应用潜力。  \n\n- **Flash Diffusion: Accelerating Any Conditional Diffusion Model for Few Steps Image Generation**（Flash Diffusion: 加速任何条件扩散模型的少步图像生成）  \n  工作提出快速蒸馏方法，仅需少量参数训练，即可加速扩散模型图像生成，在 COCO 数据集上达到 SOTA，显著减少计算开销。  \n\n### 联邦学习和隐私保护  \n- **FedMKT: Federated Mutual Knowledge Transfer for Large and Small Language Models**（FedMKT: 用于大和小语言模型的联邦互知识转移）  \n  这篇论文的 FedMKT 框架实现参数高效的联邦学习，允许服务器和客户端模型互传知识，提升小模型性能，实验在多种任务上表现优异。  \n\n- **Adaptive Preference Scaling for Reinforcement Learning with Human Feedback**（自适应偏好缩放用于人类反馈的强化学习）  \n  作者设计自适应损失函数，处理人类反馈的不确定性，提高 RL 策略性能，适用于机器人控制和语言生成，简化了超参数调整。  \n\n### 机器人和控制  \n- **RoboCasa: Large-Scale Simulation of Everyday Tasks for Generalist Robots**（RoboCasa: 用于通用机器人的大规模日常任务模拟）  \n  论文介绍 RoboCasa 模拟框架，支持厨房场景下的机器人任务训练，使用生成 AI 增强数据多样性，实验证明其在模仿学习中提升了机器人泛化能力。  \n\n- **Diagnostic Digital Twin for Anomaly Detection in Floating Offshore Wind Energy**（用于浮动海上风能异常检测的诊断数字孪生）  \n  该工作构建数字孪生模型检测风力涡轮机异常，实现预测性维护，实验显示提前数小时发现故障，提升了海上工程的可持续性。  \n\n### 其他领域（快速掠过）  \n- **Fuzzy Convolution Neural Networks for Tabular Data Classification**（模糊卷积神经网络用于表格数据分类）  \n  提出 FCNN 方法，将表格数据映射为图像进行分类，实验在复杂数据集上优于传统算法，如决策树和 SVM。  \n\n- **Multi-layer Learnable Attention Mask for Multimodal Tasks**（多层可学习注意力掩码用于多模态任务）  \n  引入 LAM 方法优化 Transformer 的注意力机制，提升多模态任务性能，如视频理解。  \n\n- **Adaptive multiple optimal learning factors for neural network training**（神经网络训练的自适应多最优学习因子）  \n  AMOLF 算法动态调整学习因子，提高训练效率，实验优于现有方法。  \n\n- **Story Generation from Visual Inputs: Techniques, Related Tasks, and Challenges**（从视觉输入生成故事：技术、相关任务和挑战）  \n  综述视觉故事生成方法及其挑战，提供数据集和评估指标。  \n\n- **Temporal Graph Rewiring with Expander Graphs**（使用扩展图的重连时序图）  \n  TGR 方法优化时序图神经网络的拓扑，提升预测性能。  \n\n今日论文数量众多，但核心亮点在于 LLMs 的推理增强和多模态应用，这些领域正推动 AI 向更可靠的方向发展。其他如联邦学习和机器人控制的创新，也为实际部署提供了新思路。如果您对特定论文感兴趣，欢迎进一步讨论！",
  "papers": [
    {
      "arxiv_id": "2406.02804v2",
      "title": "ACCORD: Closing the Commonsense Measurability Gap",
      "title_zh": "翻译失败",
      "authors": [
        "François Roewer-Després",
        "Jinyue Feng",
        "Zining Zhu",
        "Frank Rudzicz"
      ],
      "abstract": "We present ACCORD, a framework and benchmark suite for disentangling the\ncommonsense grounding and reasoning abilities of large language models (LLMs)\nthrough controlled, multi-hop counterfactuals. ACCORD introduces formal\nelements to commonsense reasoning to explicitly control and quantify reasoning\ncomplexity beyond the typical 1 or 2 hops. Uniquely, ACCORD can automatically\ngenerate benchmarks of arbitrary reasoning complexity, and so it scales with\nfuture LLM improvements. Benchmarking state-of-the-art LLMs -- including GPT-4o\n(2024-05-13), Llama-3-70B-Instruct, and Mixtral-8x22B-Instruct-v0.1 -- shows\nperformance degrading to random chance with only moderate scaling, leaving\nsubstantial headroom for improvement. We release a leaderboard of the benchmark\nsuite tested in this work, as well as code for automatically generating more\ncomplex benchmarks.",
      "tldr_zh": "本研究提出ACCORD框架和基准测试套件，旨在通过受控多跳反事实(counterfactuals)分离大型语言模型(LLMs)的常识基础和推理能力。ACCORD引入正式元素来控制并量化推理复杂度，超越传统的1或2跳，支持自动生成任意复杂度的基准测试，以适应未来LLMs的改进。实验结果显示，包括GPT-4o、Llama-3-70B-Instruct和Mixtral-8x22B-Instruct等模型的性能在中等复杂度下下降至随机水平，表明仍有巨大提升空间，并发布了排行榜和代码以推动进一步研究。",
      "categories": [
        "cs.AI",
        "cs.CL",
        "cs.LG",
        "I.2.0; I.2.7"
      ],
      "primary_category": "cs.AI",
      "comment": "For leaderboard and dataset download, see\n  https://www.codabench.org/competitions/3160/ For source code, see\n  https://github.com/francois-rd/accord/",
      "pdf_url": "http://arxiv.org/pdf/2406.02804v2",
      "published_date": "2024-06-04 22:08:24 UTC",
      "updated_date": "2025-02-06 19:10:47 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-18T15:50:30.534018"
    },
    {
      "arxiv_id": "2406.02791v2",
      "title": "Language Models can Infer Action Semantics for Symbolic Planners from Environment Feedback",
      "title_zh": "翻译失败",
      "authors": [
        "Wang Zhu",
        "Ishika Singh",
        "Robin Jia",
        "Jesse Thomason"
      ],
      "abstract": "Symbolic planners can discover a sequence of actions from initial to goal\nstates given expert-defined, domain-specific logical action semantics. Large\nLanguage Models (LLMs) can directly generate such sequences, but limitations in\nreasoning and state-tracking often result in plans that are insufficient or\nunexecutable. We propose Predicting Semantics of Actions with Language Models\n(PSALM), which automatically learns action semantics by leveraging the\nstrengths of both symbolic planners and LLMs. PSALM repeatedly proposes and\nexecutes plans, using the LLM to partially generate plans and to infer\ndomain-specific action semantics based on execution outcomes. PSALM maintains a\nbelief over possible action semantics that is iteratively updated until a goal\nstate is reached. Experiments on 7 environments show that when learning just\nfrom one goal, PSALM boosts plan success rate from 36.4% (on Claude-3.5) to\n100%, and explores the environment more efficiently than prior work to infer\nground truth domain action semantics.",
      "tldr_zh": "该研究探讨了大型语言模型 (LLMs) 如何从环境反馈中推断动作语义，以辅助符号规划器 (symbolic planners) 生成从初始状态到目标状态的动作序列。提出 PSALM 方法，该方法结合 LLMs 和符号规划器的优势，通过反复提出、执行计划并基于执行结果迭代更新动作语义信念，最终实现高效学习。实验在 7 个环境中显示，PSALM 将计划成功率从 36.4% (Claude-3.5) 提升至 100%，并比先前工作更高效地推断真实领域动作语义。",
      "categories": [
        "cs.AI",
        "cs.CL",
        "cs.RO"
      ],
      "primary_category": "cs.AI",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2406.02791v2",
      "published_date": "2024-06-04 21:29:56 UTC",
      "updated_date": "2024-11-08 16:50:24 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-18T15:50:39.671911"
    },
    {
      "arxiv_id": "2406.02787v1",
      "title": "Disentangling Logic: The Role of Context in Large Language Model Reasoning Capabilities",
      "title_zh": "翻译失败",
      "authors": [
        "Wenyue Hua",
        "Kaijie Zhu",
        "Lingyao Li",
        "Lizhou Fan",
        "Shuhang Lin",
        "Mingyu Jin",
        "Haochen Xue",
        "Zelong Li",
        "JinDong Wang",
        "Yongfeng Zhang"
      ],
      "abstract": "This study intends to systematically disentangle pure logic reasoning and\ntext understanding by investigating the contrast across abstract and\ncontextualized logical problems from a comprehensive set of domains. We explore\nwhether LLMs demonstrate genuine reasoning capabilities across various domains\nwhen the underlying logical structure remains constant. We focus on two main\nquestions (1) Can abstract logical problems alone accurately benchmark an LLM's\nreasoning ability in real-world scenarios, disentangled from contextual support\nin practical settings? (2) Does fine-tuning LLMs on abstract logic problem\ngeneralize to contextualized logic problems and vice versa? To investigate\nthese questions, we focus on standard propositional logic, specifically\npropositional deductive and abductive logic reasoning. In particular, we\nconstruct instantiated datasets for deductive and abductive reasoning with 4\nlevels of difficulty, encompassing 12 distinct categories or domains based on\nthe categorization of Wikipedia. Our experiments aim to provide insights into\ndisentangling context in logical reasoning and the true reasoning capabilities\nof LLMs and their generalization potential. The code and dataset are available\nat: https://github.com/agiresearch/ContextHub.",
      "tldr_zh": "本研究旨在系统区分大型语言模型（LLMs）的纯逻辑推理与文本理解能力，通过比较抽象和情境化逻辑问题来探索不同领域的推理表现。研究者构建了包含演绎和溯因推理的数据集，涵盖4个难度级别和12个领域（基于Wikipedia分类），并评估抽象逻辑问题是否能准确反映LLMs在真实场景中的推理能力，以及在抽象或情境化问题上微调是否能实现泛化。实验结果提供了对上下文在逻辑推理中作用的洞察，突显了LLMs的真正推理潜力和局限性，并公开了代码和数据集以促进进一步研究。",
      "categories": [
        "cs.CL",
        "cs.AI",
        "cs.LG"
      ],
      "primary_category": "cs.CL",
      "comment": "22 pages, 9 figures",
      "pdf_url": "http://arxiv.org/pdf/2406.02787v1",
      "published_date": "2024-06-04 21:25:06 UTC",
      "updated_date": "2024-06-04 21:25:06 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-18T15:50:50.724999"
    },
    {
      "arxiv_id": "2406.06583v1",
      "title": "Adaptive multiple optimal learning factors for neural network training",
      "title_zh": "翻译失败",
      "authors": [
        "Jeshwanth Challagundla"
      ],
      "abstract": "This thesis presents a novel approach to neural network training that\naddresses the challenge of determining the optimal number of learning factors.\nThe proposed Adaptive Multiple Optimal Learning Factors (AMOLF) algorithm\ndynamically adjusts the number of learning factors based on the error change\nper multiply, leading to improved training efficiency and accuracy. The thesis\nalso introduces techniques for grouping weights based on the curvature of the\nobjective function and for compressing large Hessian matrices. Experimental\nresults demonstrate the superior performance of AMOLF compared to existing\nmethods like OWO-MOLF and Levenberg-Marquardt.",
      "tldr_zh": "本论文提出了一种名为 AMOLF（Adaptive Multiple Optimal Learning Factors）的神经网络训练算法，用于解决确定最优学习因素数量的挑战。该算法通过基于错误变化动态调整学习因素的数量，并引入权重分组（基于目标函数曲率）和压缩 Hessian matrices 的技术，从而提升训练效率和准确性。实验结果显示，AMOLF 比现有方法如 OWO-MOLF 和 Levenberg-Marquardt 在性能上表现出明显优势。",
      "categories": [
        "cs.LG",
        "cs.AI"
      ],
      "primary_category": "cs.LG",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2406.06583v1",
      "published_date": "2024-06-04 21:18:24 UTC",
      "updated_date": "2024-06-04 21:18:24 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-18T15:51:02.110888"
    },
    {
      "arxiv_id": "2406.02780v1",
      "title": "LADI v2: Multi-label Dataset and Classifiers for Low-Altitude Disaster Imagery",
      "title_zh": "LADI v2：低空灾害图像的多标签数据集和分类器",
      "authors": [
        "Samuel Scheele",
        "Katherine Picchione",
        "Jeffrey Liu"
      ],
      "abstract": "ML-based computer vision models are promising tools for supporting emergency\nmanagement operations following natural disasters. Arial photographs taken from\nsmall manned and unmanned aircraft can be available soon after a disaster and\nprovide valuable information from multiple perspectives for situational\nawareness and damage assessment applications. However, emergency managers often\nface challenges finding the most relevant photos among the tens of thousands\nthat may be taken after an incident. While ML-based solutions could enable more\neffective use of aerial photographs, there is still a lack of training data for\nimagery of this type from multiple perspectives and for multiple hazard types.\nTo address this, we present the LADI v2 (Low Altitude Disaster Imagery version\n2) dataset, a curated set of about 10,000 disaster images captured in the\nUnited States by the Civil Air Patrol (CAP) in response to federally-declared\nemergencies (2015-2023) and annotated for multi-label classification by trained\nCAP volunteers. We also provide two pretrained baseline classifiers and compare\ntheir performance to state-of-the-art vision-language models in multi-label\nclassification. The data and code are released publicly to support the\ndevelopment of computer vision models for emergency management research and\napplications.",
      "tldr_zh": "本研究介绍了 LADI v2 数据集，这是一个包含约 10,000 张低空灾害图像的多标签数据集，由美国民用航空巡逻队 (CAP) 在 2015-2023 年响应联邦紧急事件时拍摄并由训练有素的志愿者进行多标签注释。数据集旨在解决紧急管理中从大量航拍照片中筛选相关图像的挑战，支持 situational awareness 和 damage assessment 应用。论文提供了两个预训练基线分类器，并与 state-of-the-art vision-language models 进行了多标签分类性能比较，结果有助于提升计算机视觉模型在紧急管理中的开发和应用。数据和代码已公开发布，以促进相关研究。",
      "categories": [
        "cs.CV",
        "cs.AI",
        "cs.LG",
        "68T45",
        "J.2"
      ],
      "primary_category": "cs.CV",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2406.02780v1",
      "published_date": "2024-06-04 20:51:04 UTC",
      "updated_date": "2024-06-04 20:51:04 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-18T15:51:14.915923"
    },
    {
      "arxiv_id": "2406.02775v1",
      "title": "Diagnostic Digital Twin for Anomaly Detection in Floating Offshore Wind Energy",
      "title_zh": "翻译失败",
      "authors": [
        "Florian Stadtmann",
        "Adil Rasheed"
      ],
      "abstract": "The demand for condition-based and predictive maintenance is rising across\nindustries, especially for remote, high-value, and high-risk assets. In this\narticle, the diagnostic digital twin concept is introduced, discussed, and\nimplemented for a floating offshore turbine. A diagnostic digital twin is a\nvirtual representation of an asset that combines real-time data and models to\nmonitor damage, detect anomalies, and diagnose failures, thereby enabling\ncondition-based and predictive maintenance. By applying diagnostic digital\ntwins to offshore assets, unexpected failures can be alleviated, but the\nimplementation can prove challenging. Here, a diagnostic digital twin is\nimplemented for an operational floating offshore wind turbine. The asset is\nmonitored through measurements. Unsupervised learning methods are employed to\nbuild a normal operation model, detect anomalies, and provide a fault\ndiagnosis. Warnings and diagnoses are sent through text messages, and a more\ndetailed diagnosis can be accessed in a virtual reality interface. The\ndiagnostic digital twin successfully detected an anomaly with high confidence\nhours before a failure occurred. The paper concludes by discussing diagnostic\ndigital twins in the broader context of offshore engineering. The presented\napproach can be generalized to other offshore assets to improve maintenance and\nincrease the lifetime, efficiency, and sustainability of offshore assets.",
      "tldr_zh": "本文引入了diagnostic digital twin概念，这是一种结合实时数据和模型的虚拟表示，用于监控损坏、检测异常和诊断故障，从而实现基于条件的维护和预测性维护。研究将其应用于浮动式海上风力涡轮机，通过unsupervised learning方法构建正常操作模型，并利用测量数据进行异常检测和故障诊断。结果显示，该系统成功提前数小时高置信度检测到一个异常，避免了意外故障。该方法可推广到其他海上资产，提高维护效率、延长寿命、提升可持续性。",
      "categories": [
        "cs.LG",
        "cs.AI",
        "cs.ET",
        "eess.SP"
      ],
      "primary_category": "cs.LG",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2406.02775v1",
      "published_date": "2024-06-04 20:45:20 UTC",
      "updated_date": "2024-06-04 20:45:20 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-18T15:51:27.509468"
    },
    {
      "arxiv_id": "2406.03506v5",
      "title": "Fuzzy Convolution Neural Networks for Tabular Data Classification",
      "title_zh": "模糊卷积神经网络用于表格数据分类",
      "authors": [
        "Arun D. Kulkarni"
      ],
      "abstract": "Recently, convolution neural networks (CNNs) have attracted a great deal of\nattention due to their remarkable performance in various domains, particularly\nin image and text classification tasks. However, their application to tabular\ndata classification remains underexplored. There are many fields such as\nbioinformatics, finance, medicine where nonimage data are prevalent. Adaption\nof CNNs to classify nonimage data remains highly challenging. This paper\ninvestigates the efficacy of CNNs for tabular data classification, aiming to\nbridge the gap between traditional machine learning approaches and deep\nlearning techniques. We propose a novel framework fuzzy convolution neural\nnetwork (FCNN) tailored specifically for tabular data to capture local patterns\nwithin feature vectors. In our approach, we map feature values to fuzzy\nmemberships. The fuzzy membership vectors are converted into images that are\nused to train the CNN model. The trained CNN model is used to classify unknown\nfeature vectors. To validate our approach, we generated six complex noisy data\nsets. We used randomly selected seventy percent samples from each data set for\ntraining and thirty percent for testing. The data sets were also classified\nusing the state-of-the-art machine learning algorithms such as the decision\ntree (DT), support vector machine (SVM), fuzzy neural network (FNN), Bayes\nclassifier, and Random Forest (RF). Experimental results demonstrate that our\nproposed model can effectively learn meaningful representations from tabular\ndata, achieving competitive or superior performance compared to existing\nmethods. Overall, our finding suggests that the proposed FCNN model holds\npromise as a viable alternative for tabular data classification tasks, offering\na fresh prospective and potentially unlocking new opportunities for leveraging\ndeep learning in structured data analysis.",
      "tldr_zh": "该论文探讨了卷积神经网络 (CNNs) 在表格数据分类中的应用，旨在填补传统机器学习与深度学习技术之间的空白。作者提出了一种新型框架 Fuzzy Convolution Neural Networks (FCNN)，通过将特征值映射到模糊成员 (fuzzy memberships) 并转换为图像，从而捕获表格数据中的局部模式，并用于训练 CNN 模型。在六个复杂噪声数据集上的实验中，FCNN 与 Decision Tree (DT)、Support Vector Machine (SVM)、Fuzzy Neural Network (FNN)、Bayes 分类器和 Random Forest (RF) 等算法相比，表现出竞争性或优越的性能。该方法为表格数据分类提供了可行的深度学习替代方案，开辟了结构化数据分析的新机遇。",
      "categories": [
        "cs.LG",
        "cs.AI",
        "I.2.10",
        "I.4.6"
      ],
      "primary_category": "cs.LG",
      "comment": "10 pages, 16 figures, Submitted to IEEE Access",
      "pdf_url": "http://arxiv.org/pdf/2406.03506v5",
      "published_date": "2024-06-04 20:33:35 UTC",
      "updated_date": "2024-10-14 21:21:31 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-18T15:51:39.955750"
    },
    {
      "arxiv_id": "2406.02764v1",
      "title": "Adaptive Preference Scaling for Reinforcement Learning with Human Feedback",
      "title_zh": "用于基于人类反馈的强化学习的自适应偏好缩放",
      "authors": [
        "Ilgee Hong",
        "Zichong Li",
        "Alexander Bukharin",
        "Yixiao Li",
        "Haoming Jiang",
        "Tianbao Yang",
        "Tuo Zhao"
      ],
      "abstract": "Reinforcement learning from human feedback (RLHF) is a prevalent approach to\nalign AI systems with human values by learning rewards from human preference\ndata. Due to various reasons, however, such data typically takes the form of\nrankings over pairs of trajectory segments, which fails to capture the varying\nstrengths of preferences across different pairs. In this paper, we propose a\nnovel adaptive preference loss, underpinned by distributionally robust\noptimization (DRO), designed to address this uncertainty in preference\nstrength. By incorporating an adaptive scaling parameter into the loss for each\npair, our method increases the flexibility of the reward function.\nSpecifically, it assigns small scaling parameters to pairs with ambiguous\npreferences, leading to more comparable rewards, and large scaling parameters\nto those with clear preferences for more distinct rewards. Computationally, our\nproposed loss function is strictly convex and univariate with respect to each\nscaling parameter, enabling its efficient optimization through a simple\nsecond-order algorithm. Our method is versatile and can be readily adapted to\nvarious preference optimization frameworks, including direct preference\noptimization (DPO). Our experiments with robotic control and natural language\ngeneration with large language models (LLMs) show that our method not only\nimproves policy performance but also aligns reward function selection more\nclosely with policy optimization, simplifying the hyperparameter tuning\nprocess.",
      "tldr_zh": "这篇论文针对强化学习从人类反馈（RLHF）中存在的偏好强度不确定性问题，提出了一种基于分布鲁棒优化（DRO）的adaptive preference loss。该方法通过为每个偏好对引入adaptive scaling parameter来增强奖励函数的灵活性：对模糊偏好分配小参数以使奖励更相似，对明确偏好分配大参数以使奖励更不同。实验结果显示，该方法在机器人控制和大型语言模型（LLMs）的自然语言生成任务上显著提升了策略性能，并简化了超参数调优过程。",
      "categories": [
        "cs.LG",
        "cs.AI"
      ],
      "primary_category": "cs.LG",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2406.02764v1",
      "published_date": "2024-06-04 20:33:22 UTC",
      "updated_date": "2024-06-04 20:33:22 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-18T15:51:50.967281"
    },
    {
      "arxiv_id": "2406.03505v1",
      "title": "Dynamic and Adaptive Feature Generation with LLM",
      "title_zh": "翻译失败",
      "authors": [
        "Xinhao Zhang",
        "Jinghan Zhang",
        "Banafsheh Rekabdar",
        "Yuanchun Zhou",
        "Pengfei Wang",
        "Kunpeng Liu"
      ],
      "abstract": "The representation of feature space is a crucial environment where data\npoints get vectorized and embedded for upcoming modeling. Thus the efficacy of\nmachine learning (ML) algorithms is closely related to the quality of feature\nengineering. As one of the most important techniques, feature generation\ntransforms raw data into an optimized feature space conducive to model training\nand further refines the space. Despite the advancements in automated feature\nengineering and feature generation, current methodologies often suffer from\nthree fundamental issues: lack of explainability, limited applicability, and\ninflexible strategy. These shortcomings frequently hinder and limit the\ndeployment of ML models across varied scenarios. Our research introduces a\nnovel approach adopting large language models (LLMs) and feature-generating\nprompts to address these challenges. We propose a dynamic and adaptive feature\ngeneration method that enhances the interpretability of the feature generation\nprocess. Our approach broadens the applicability across various data types and\ntasks and draws advantages over strategic flexibility. A broad range of\nexperiments showcases that our approach is significantly superior to existing\nmethods.",
      "tldr_zh": "本研究探讨了特征生成在机器学习中的关键作用，强调它将原始数据转化为优化特征空间，但现有方法存在缺乏解释性、适用性有限和策略不灵活等问题。作者提出了一种动态和自适应特征生成方法，利用大型语言模型(LLMs)和特征生成提示，提高了过程的解释性，并扩展了其在不同数据类型和任务中的适用性。实验结果表明，该方法在广泛测试中显著优于现有技术。",
      "categories": [
        "cs.LG",
        "cs.AI"
      ],
      "primary_category": "cs.LG",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2406.03505v1",
      "published_date": "2024-06-04 20:32:14 UTC",
      "updated_date": "2024-06-04 20:32:14 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-18T15:52:01.983700"
    },
    {
      "arxiv_id": "2406.02761v1",
      "title": "Multi-layer Learnable Attention Mask for Multimodal Tasks",
      "title_zh": "翻译失败",
      "authors": [
        "Wayner Barrios",
        "SouYoung Jin"
      ],
      "abstract": "While the Self-Attention mechanism in the Transformer model has proven to be\neffective in many domains, we observe that it is less effective in more diverse\nsettings (e.g. multimodality) due to the varying granularity of each token and\nthe high computational demands of lengthy sequences. To address the challenges,\nwe introduce the Learnable Attention Mask (LAM), strategically designed to\nglobally regulate attention maps and prioritize critical tokens within the\nsequence. Leveraging the Self-Attention module in a BERT-like transformer\nnetwork, our approach adeptly captures associations between tokens. The\nextension of the LAM to a multi-layer version accommodates the varied\ninformation aspects embedded at each layer of the Transformer network.\nComprehensive experimental validation on various datasets, such as MADv2,\nQVHighlights, ImageNet 1K, and MSRVTT, demonstrates the efficacy of the LAM,\nexemplifying its ability to enhance model performance while mitigating\nredundant computations. This pioneering approach presents a significant\nadvancement in enhancing the understanding of complex scenarios, such as in\nmovie understanding.",
      "tldr_zh": "该研究发现，Transformer 模型中的 Self-Attention 机制在多模态任务中效果较差，主要由于标记粒度多样和序列计算需求高。为解决此问题，研究提出 Learnable Attention Mask (LAM)，一种可学习注意力掩码，用于全局调节注意力图、优先关键标记，并在 BERT-like Transformer 网络中捕捉标记间的关联；LAM 进一步扩展为多层版本，以适应不同层的信息方面。在 MADv2、QVHighlights、ImageNet 1K 和 MSRVTT 等数据集上的实验验证显示，LAM 显著提升了模型性能，同时减少了冗余计算，尤其在复杂场景如电影理解中。",
      "categories": [
        "cs.CV",
        "cs.AI",
        "cs.LG",
        "cs.MM"
      ],
      "primary_category": "cs.CV",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2406.02761v1",
      "published_date": "2024-06-04 20:28:02 UTC",
      "updated_date": "2024-06-04 20:28:02 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-18T15:52:14.142701"
    },
    {
      "arxiv_id": "2406.02756v1",
      "title": "Aligning Large Language Models via Fine-grained Supervision",
      "title_zh": "翻译失败",
      "authors": [
        "Dehong Xu",
        "Liang Qiu",
        "Minseok Kim",
        "Faisal Ladhak",
        "Jaeyoung Do"
      ],
      "abstract": "Pre-trained large-scale language models (LLMs) excel at producing coherent\narticles, yet their outputs may be untruthful, toxic, or fail to align with\nuser expectations. Current approaches focus on using reinforcement learning\nwith human feedback (RLHF) to improve model alignment, which works by\ntransforming coarse human preferences of LLM outputs into a feedback signal\nthat guides the model learning process. However, because this approach operates\non sequence-level feedback, it lacks the precision to identify the exact parts\nof the output affecting user preferences. To address this gap, we propose a\nmethod to enhance LLM alignment through fine-grained token-level supervision.\nSpecifically, we ask annotators to minimally edit less preferred responses\nwithin the standard reward modeling dataset to make them more favorable,\nensuring changes are made only where necessary while retaining most of the\noriginal content. The refined dataset is used to train a token-level reward\nmodel, which is then used for training our fine-grained Proximal Policy\nOptimization (PPO) model. Our experiment results demonstrate that this approach\ncan achieve up to an absolute improvement of $5.1\\%$ in LLM performance, in\nterms of win rate against the reference model, compared with the traditional\nPPO model.",
      "tldr_zh": "本研究针对预训练的大型语言模型（LLMs）输出可能不真实、有毒或不符合用户期望的问题，提出一种基于细粒度监督的方法来提升模型对齐。不同于传统的强化学习与人类反馈（RLHF）方法，该方法要求标注者对不喜欢的响应进行最小编辑，仅修改必要部分以生成更优数据集，然后训练一个 token-level 奖励模型，并应用于细粒度的 Proximal Policy Optimization (PPO) 模型。实验结果显示，这种方法相较于传统 PPO 模型，提高了 5.1% 的胜率，显著改善了 LLM 的性能和用户满意度。",
      "categories": [
        "cs.CL",
        "cs.AI",
        "cs.LG"
      ],
      "primary_category": "cs.CL",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2406.02756v1",
      "published_date": "2024-06-04 20:21:45 UTC",
      "updated_date": "2024-06-04 20:21:45 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-18T15:52:27.918056"
    },
    {
      "arxiv_id": "2406.02748v1",
      "title": "Story Generation from Visual Inputs: Techniques, Related Tasks, and Challenges",
      "title_zh": "基于视觉输入的故事生成：技术、相关任务和挑战",
      "authors": [
        "Daniel A. P. Oliveira",
        "Eugénio Ribeiro",
        "David Martins de Matos"
      ],
      "abstract": "Creating engaging narratives from visual data is crucial for automated\ndigital media consumption, assistive technologies, and interactive\nentertainment. This survey covers methodologies used in the generation of these\nnarratives, focusing on their principles, strengths, and limitations.\n  The survey also covers tasks related to automatic story generation, such as\nimage and video captioning, and visual question answering, as well as story\ngeneration without visual inputs. These tasks share common challenges with\nvisual story generation and have served as inspiration for the techniques used\nin the field. We analyze the main datasets and evaluation metrics, providing a\ncritical perspective on their limitations.",
      "tldr_zh": "这篇调查论文探讨了从视觉输入生成故事的技术、相关任务及挑战，强调其在自动化数字媒体、辅助技术和互动娱乐中的重要性。论文总结了生成叙述的方法，包括原理、优势和局限性，并讨论了相关任务如 image and video captioning、visual question answering，以及不依赖视觉输入的故事生成，这些任务共享共同挑战并启发了该领域的技术。作者还分析了主要数据集和评估指标，并批判性地指出了它们的局限性，为未来研究提供了参考。",
      "categories": [
        "cs.CV",
        "cs.AI",
        "I.2.7; I.2.10"
      ],
      "primary_category": "cs.CV",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2406.02748v1",
      "published_date": "2024-06-04 20:07:58 UTC",
      "updated_date": "2024-06-04 20:07:58 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-18T15:52:37.754695"
    },
    {
      "arxiv_id": "2406.02723v1",
      "title": "Predicting AI Agent Behavior through Approximation of the Perron-Frobenius Operator",
      "title_zh": "通过 Perron-Frobenius 算子的近似预测 AI 代理行为",
      "authors": [
        "Shiqi Zhang",
        "Darshan Gadginmath",
        "Fabio Pasqualetti"
      ],
      "abstract": "Predicting the behavior of AI-driven agents is particularly challenging\nwithout a preexisting model. In our paper, we address this by treating AI\nagents as nonlinear dynamical systems and adopting a probabilistic perspective\nto predict their statistical behavior using the Perron-Frobenius (PF) operator.\nWe formulate the approximation of the PF operator as an entropy minimization\nproblem, which can be solved by leveraging the Markovian property of the\noperator and decomposing its spectrum. Our data-driven methodology\nsimultaneously approximates the PF operator to perform prediction of the\nevolution of the agents and also predicts the terminal probability density of\nAI agents, such as robotic systems and generative models. We demonstrate the\neffectiveness of our prediction model through extensive experiments on\npractical systems driven by AI algorithms.",
      "tldr_zh": "本研究针对缺乏预先模型的 AI 代理行为预测难题，将 AI 代理视为非线性动态系统，并采用概率视角，通过近似 Perron-Frobenius (PF) 算子来预测其统计行为。方法将 PF 算子的近似表述为熵最小化问题，利用算子的 Markovian 属性和谱分解进行求解，从而实现对代理演化的预测以及终端概率密度的估计。实验在 AI 算法驱动的实际系统（如机器人系统和生成模型）上验证了该方法的有效性，展示了其在预测领域的显著潜力。",
      "categories": [
        "cs.AI"
      ],
      "primary_category": "cs.AI",
      "comment": "12 pages, 4 figures, conference",
      "pdf_url": "http://arxiv.org/pdf/2406.02723v1",
      "published_date": "2024-06-04 19:06:49 UTC",
      "updated_date": "2024-06-04 19:06:49 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-18T15:52:51.643945"
    },
    {
      "arxiv_id": "2406.02721v3",
      "title": "Self-Control of LLM Behaviors by Compressing Suffix Gradient into Prefix Controller",
      "title_zh": "翻译失败",
      "authors": [
        "Min Cai",
        "Yuchen Zhang",
        "Shichang Zhang",
        "Fan Yin",
        "Dan Zhang",
        "Difan Zou",
        "Yisong Yue",
        "Ziniu Hu"
      ],
      "abstract": "We propose SelfControl, an inference-time model control method utilizing\ngradients to control the behavior of large language models (LLMs) without\nexplicit human annotations. Given a desired behavior expressed in a natural\nlanguage suffix string concatenated to the input prompt, SelfControl computes\ngradients of the LLM's self-evaluation of the suffix with respect to its latent\nrepresentations. The gradients are used to directly control the auto-regressive\ngeneration process towards desired behaviors, which eliminates human\nsupervision, achieves precise and transparent control, and offers on-the-fly\nadaptability. To further enhance efficiency, we introduce SelfControl_{Prefix},\na compact module that encapsulates the learned representations from gradients\ninto a SelfControl_{Prefix}, facilitating efficient inference-time control with\nno latency compared to the original model and allowing control for multiple\nbehaviors simultaneously. Our experiments demonstrate SelfControl's efficacy\nacross multiple domains, where it improves over SOTA for 8.3% in\ndetoxification, 3.1% in truthfulness enhancement, 4%~10% in controlling on\nemotion tones, and 48.2% in privacy protection, i.e., completely remove privacy\nleakage issue. Additionally, we demonstrate that SelfControl can be used for\ndata synthesis and to improve reasoning abilities.",
      "tldr_zh": "本文提出 SelfControl，一种无需人工标注的推理时控制方法，通过计算大型语言模型 (LLMs) 对自然语言后缀行为的梯度，来直接引导自回归生成过程，实现精确、透明和实时适应的行为控制。进一步，作者引入 SelfControl_Prefix 模块，将这些梯度表示压缩成紧凑的前缀控制器，支持高效的无延迟推理和同时处理多个行为。实验结果显示，该方法在多个领域表现出色，比最先进技术提升8.3%在解毒、3.1%在真实性增强、4%~10%在情感语气控制，以及48.2%在隐私保护上，并可用于数据合成和提升推理能力。",
      "categories": [
        "cs.CL",
        "cs.AI"
      ],
      "primary_category": "cs.CL",
      "comment": "Website: https://llm-self-control.github.io/",
      "pdf_url": "http://arxiv.org/pdf/2406.02721v3",
      "published_date": "2024-06-04 19:05:10 UTC",
      "updated_date": "2024-10-12 08:30:33 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-18T15:53:03.573972"
    },
    {
      "arxiv_id": "2406.02659v3",
      "title": "Reanimating Images using Neural Representations of Dynamic Stimuli",
      "title_zh": "翻译失败",
      "authors": [
        "Jacob Yeung",
        "Andrew F. Luo",
        "Gabriel Sarch",
        "Margaret M. Henderson",
        "Deva Ramanan",
        "Michael J. Tarr"
      ],
      "abstract": "While computer vision models have made incredible strides in static image\nrecognition, they still do not match human performance in tasks that require\nthe understanding of complex, dynamic motion. This is notably true for\nreal-world scenarios where embodied agents face complex and motion-rich\nenvironments. Our approach, BrainNRDS (Brain-Neural Representations of Dynamic\nStimuli), leverages state-of-the-art video diffusion models to decouple static\nimage representation from motion generation, enabling us to utilize fMRI brain\nactivity for a deeper understanding of human responses to dynamic visual\nstimuli. Conversely, we also demonstrate that information about the brain's\nrepresentation of motion can enhance the prediction of optical flow in\nartificial systems. Our novel approach leads to four main findings: (1) Visual\nmotion, represented as fine-grained, object-level resolution optical flow, can\nbe decoded from brain activity generated by participants viewing video stimuli;\n(2) Video encoders outperform image-based models in predicting video-driven\nbrain activity; (3) Brain-decoded motion signals enable realistic video\nreanimation based only on the initial frame of the video; and (4) We extend\nprior work to achieve full video decoding from video-driven brain activity.\nBrainNRDS advances our understanding of how the brain represents spatial and\ntemporal information in dynamic visual scenes. Our findings demonstrate the\npotential of combining brain imaging with video diffusion models for developing\nmore robust and biologically-inspired computer vision systems. We show\nadditional decoding and encoding examples on this site:\nhttps://brain-nrds.github.io/.",
      "tldr_zh": "这篇论文提出 BrainNRDS 方法，利用视频扩散模型（video diffusion models）和 fMRI 脑活动，分离静态图像表示与运动生成，以提升计算机视觉模型对动态视觉刺激的理解。研究发现，通过脑活动解码精细的光流（optical flow），视频编码器在预测视频驱动脑活动时优于图像模型，并能基于初始帧和脑信号实现真实视频重现。最终，BrainNRDS 扩展了从脑活动到完整视频的解码能力，为开发更鲁棒、生物启发的计算机视觉系统提供了新见解。",
      "categories": [
        "q-bio.NC",
        "cs.AI",
        "cs.CV"
      ],
      "primary_category": "q-bio.NC",
      "comment": "Project Page: https://brain-nrds.github.io",
      "pdf_url": "http://arxiv.org/pdf/2406.02659v3",
      "published_date": "2024-06-04 17:59:49 UTC",
      "updated_date": "2025-03-25 17:59:01 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-18T15:53:15.872875"
    },
    {
      "arxiv_id": "2406.02543v2",
      "title": "To Believe or Not to Believe Your LLM",
      "title_zh": "翻译失败",
      "authors": [
        "Yasin Abbasi Yadkori",
        "Ilja Kuzborskij",
        "András György",
        "Csaba Szepesvári"
      ],
      "abstract": "We explore uncertainty quantification in large language models (LLMs), with\nthe goal to identify when uncertainty in responses given a query is large. We\nsimultaneously consider both epistemic and aleatoric uncertainties, where the\nformer comes from the lack of knowledge about the ground truth (such as about\nfacts or the language), and the latter comes from irreducible randomness (such\nas multiple possible answers). In particular, we derive an\ninformation-theoretic metric that allows to reliably detect when only epistemic\nuncertainty is large, in which case the output of the model is unreliable. This\ncondition can be computed based solely on the output of the model obtained\nsimply by some special iterative prompting based on the previous responses.\nSuch quantification, for instance, allows to detect hallucinations (cases when\nepistemic uncertainty is high) in both single- and multi-answer responses. This\nis in contrast to many standard uncertainty quantification strategies (such as\nthresholding the log-likelihood of a response) where hallucinations in the\nmulti-answer case cannot be detected. We conduct a series of experiments which\ndemonstrate the advantage of our formulation. Further, our investigations shed\nsome light on how the probabilities assigned to a given output by an LLM can be\namplified by iterative prompting, which might be of independent interest.",
      "tldr_zh": "本文探讨大型语言模型(LLMs)的不确定性量化，旨在识别查询响应中不确定性较大的情况，包括认知不确定性(epistemic uncertainty，源于知识缺失)和随机不确定性(aleatoric uncertainty，源于不可约随机性)。他们提出一个基于信息理论的指标，通过简单的迭代提示计算，仅当epistemic uncertainty较高时判断模型输出不可靠，从而有效检测幻觉(hallucinations)在单答案和多答案响应中的出现。实验结果表明，该方法优于传统策略（如阈值化log-likelihood），并揭示了迭代提示如何放大LLM对输出概率的分配，为更可靠的LLM应用提供了新见解。",
      "categories": [
        "cs.LG",
        "cs.AI",
        "cs.CL"
      ],
      "primary_category": "cs.LG",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2406.02543v2",
      "published_date": "2024-06-04 17:58:18 UTC",
      "updated_date": "2024-07-17 15:55:51 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-18T15:53:28.038697"
    },
    {
      "arxiv_id": "2406.02539v2",
      "title": "Parrot: Multilingual Visual Instruction Tuning",
      "title_zh": "Parrot：多语言视觉指令调优",
      "authors": [
        "Hai-Long Sun",
        "Da-Wei Zhou",
        "Yang Li",
        "Shiyin Lu",
        "Chao Yi",
        "Qing-Guo Chen",
        "Zhao Xu",
        "Weihua Luo",
        "Kaifu Zhang",
        "De-Chuan Zhan",
        "Han-Jia Ye"
      ],
      "abstract": "The rapid development of Multimodal Large Language Models (MLLMs) like GPT-4V\nhas marked a significant step towards artificial general intelligence. Existing\nmethods mainly focus on aligning vision encoders with LLMs through supervised\nfine-tuning (SFT) to endow LLMs with multimodal abilities, making MLLMs'\ninherent ability to react to multiple languages progressively deteriorate as\nthe training process evolves. We empirically find that the imbalanced SFT\ndatasets, primarily composed of English-centric image-text pairs, lead to\nsignificantly reduced performance in non-English languages. This is due to the\nfailure of aligning the vision encoder and LLM with multilingual tokens during\nthe SFT process. In this paper, we introduce Parrot, a novel method that\nutilizes textual guidance to drive visual token alignment at the language\nlevel. Parrot makes the visual tokens condition on diverse language inputs and\nuses Mixture-of-Experts (MoE) to promote the alignment of multilingual tokens.\nSpecifically, to enhance non-English visual tokens alignment, we compute the\ncross-attention using the initial visual features and textual embeddings, the\nresult of which is then fed into the MoE router to select the most relevant\nexperts. The selected experts subsequently convert the initial visual tokens\ninto language-specific visual tokens. Moreover, considering the current lack of\nbenchmarks for evaluating multilingual capabilities within the field, we\ncollect and make available a Massive Multilingual Multimodal Benchmark which\nincludes 6 languages, 15 categories, and 12,000 questions, named as MMMB. Our\nmethod not only demonstrates state-of-the-art performance on multilingual\nMMBench and MMMB, but also excels across a broad range of multimodal tasks.\nBoth the source code and the training dataset of Parrot will be made publicly\navailable. Code is available at: https://github.com/AIDC-AI/Parrot.",
      "tldr_zh": "该研究提出Parrot，一种多语言视觉指令微调方法，旨在解决Multimodal Large Language Models (MLLMs)在Supervised Fine-Tuning (SFT)过程中因英语中心数据集导致的非英语性能下降问题。Parrot通过文本指导驱动视觉标记在语言层面的对齐，利用Mixture-of-Experts (MoE)机制计算跨注意力并选择相关专家，将初始视觉标记转换为语言特定的标记，从而提升多语言处理能力。为评估多语言能力，研究者创建了Massive Multilingual Multimodal Benchmark (MMMB)，包括6种语言、15个类别和12,000个问题。实验结果显示，Parrot在多语言MMBench和MMMB上达到state-of-the-art性能，并在广泛的多模态任务中表现出色，代码和数据集已公开可用。",
      "categories": [
        "cs.CV",
        "cs.AI",
        "cs.CL",
        "cs.LG"
      ],
      "primary_category": "cs.CV",
      "comment": "Code is available at: https://github.com/AIDC-AI/Parrot",
      "pdf_url": "http://arxiv.org/pdf/2406.02539v2",
      "published_date": "2024-06-04 17:56:28 UTC",
      "updated_date": "2024-08-11 05:15:46 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-18T15:53:39.655959"
    },
    {
      "arxiv_id": "2406.02534v2",
      "title": "Enhancing predictive imaging biomarker discovery through treatment effect analysis",
      "title_zh": "通过治疗效果分析增强预测性影像生物标志物发现",
      "authors": [
        "Shuhan Xiao",
        "Lukas Klein",
        "Jens Petersen",
        "Philipp Vollmuth",
        "Paul F. Jaeger",
        "Klaus H. Maier-Hein"
      ],
      "abstract": "Identifying predictive covariates, which forecast individual treatment\neffectiveness, is crucial for decision-making across different disciplines such\nas personalized medicine. These covariates, referred to as biomarkers, are\nextracted from pre-treatment data, often within randomized controlled trials,\nand should be distinguished from prognostic biomarkers, which are independent\nof treatment assignment. Our study focuses on discovering predictive imaging\nbiomarkers, specific image features, by leveraging pre-treatment images to\nuncover new causal relationships. Unlike labor-intensive approaches relying on\nhandcrafted features prone to bias, we present a novel task of directly\nlearning predictive features from images. We propose an evaluation protocol to\nassess a model's ability to identify predictive imaging biomarkers and\ndifferentiate them from purely prognostic ones by employing statistical testing\nand a comprehensive analysis of image feature attribution. We explore the\nsuitability of deep learning models originally developed for estimating the\nconditional average treatment effect (CATE) for this task, which have been\nassessed primarily for their precision of CATE estimation while overlooking the\nevaluation of imaging biomarker discovery. Our proof-of-concept analysis\ndemonstrates the feasibility and potential of our approach in discovering and\nvalidating predictive imaging biomarkers from synthetic outcomes and real-world\nimage datasets. Our code is available at\n\\url{https://github.com/MIC-DKFZ/predictive_image_biomarker_analysis}.",
      "tldr_zh": "这篇论文探讨了通过治疗效果分析增强预测性图像生物标记物（predictive imaging biomarkers）的发现，这些标记物能从预治疗图像中预测个体治疗效果，并与预后生物标记物（prognostic biomarkers）区分开来。作者提出一个新任务，直接从图像中学习预测性特征，以克服手工特征方法的偏见和低效，并设计了一个评估协议，使用统计测试和图像特征归因来验证模型的性能。实验结果显示，原本用于估计条件平均治疗效果（CATE）的深度学习模型在这一任务上表现出可行性，并在合成和真实数据集上证明了其潜力；相关代码已在 GitHub 上开源。",
      "categories": [
        "eess.IV",
        "cs.AI",
        "cs.CV",
        "cs.LG"
      ],
      "primary_category": "eess.IV",
      "comment": "Accepted to WACV 2025",
      "pdf_url": "http://arxiv.org/pdf/2406.02534v2",
      "published_date": "2024-06-04 17:54:44 UTC",
      "updated_date": "2024-12-09 15:58:55 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-18T15:53:52.096727"
    },
    {
      "arxiv_id": "2406.02529v2",
      "title": "ReLUs Are Sufficient for Learning Implicit Neural Representations",
      "title_zh": "ReLUs 足以用于学习隐式神经表示",
      "authors": [
        "Joseph Shenouda",
        "Yamin Zhou",
        "Robert D. Nowak"
      ],
      "abstract": "Motivated by the growing theoretical understanding of neural networks that\nemploy the Rectified Linear Unit (ReLU) as their activation function, we\nrevisit the use of ReLU activation functions for learning implicit neural\nrepresentations (INRs). Inspired by second order B-spline wavelets, we\nincorporate a set of simple constraints to the ReLU neurons in each layer of a\ndeep neural network (DNN) to remedy the spectral bias. This in turn enables its\nuse for various INR tasks. Empirically, we demonstrate that, contrary to\npopular belief, one can learn state-of-the-art INRs based on a DNN composed of\nonly ReLU neurons. Next, by leveraging recent theoretical works which\ncharacterize the kinds of functions ReLU neural networks learn, we provide a\nway to quantify the regularity of the learned function. This offers a\nprincipled approach to selecting the hyperparameters in INR architectures. We\nsubstantiate our claims through experiments in signal representation, super\nresolution, and computed tomography, demonstrating the versatility and\neffectiveness of our method. The code for all experiments can be found at\nhttps://github.com/joeshenouda/relu-inrs.",
      "tldr_zh": "本研究证明，Rectified Linear Unit (ReLU) 激活函数足以用于学习 Implicit Neural Representations (INRs)，挑战了传统观点。受二阶 B-spline wavelets 启发，作者在 DNN 的每一层对 ReLU 神经元施加简单约束，以缓解 spectral bias，从而提升 INRs 在各种任务中的性能。实验结果显示，该方法在信号表示、超分辨率和计算机断层扫描等领域实现最先进的表现，并提供量化函数规则性的原理，帮助优化 INR 架构的超参数。总的来说，这为基于 ReLU 的神经网络在表示学习中提供了更可靠和高效的框架。",
      "categories": [
        "eess.IV",
        "cs.AI",
        "cs.CV",
        "cs.LG"
      ],
      "primary_category": "eess.IV",
      "comment": "Accepted to ICML 2024",
      "pdf_url": "http://arxiv.org/pdf/2406.02529v2",
      "published_date": "2024-06-04 17:51:08 UTC",
      "updated_date": "2024-08-01 20:53:09 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-18T15:54:02.799933"
    },
    {
      "arxiv_id": "2406.02657v2",
      "title": "Block Transformer: Global-to-Local Language Modeling for Fast Inference",
      "title_zh": "Block Transformer: 全局到局部语言建模用于快速推理",
      "authors": [
        "Namgyu Ho",
        "Sangmin Bae",
        "Taehyeon Kim",
        "Hyunjik Jo",
        "Yireun Kim",
        "Tal Schuster",
        "Adam Fisch",
        "James Thorne",
        "Se-Young Yun"
      ],
      "abstract": "We introduce the Block Transformer which adopts hierarchical global-to-local\nmodeling to autoregressive transformers to mitigate the inference bottlenecks\nassociated with self-attention. Self-attention requires the key-value (KV)\ncache of all previous sequences to be retrieved from memory at every decoding\nstep to retrieve context information, leading to two primary bottlenecks during\nbatch inference. First, there is a significant delay in obtaining the first\ntoken, as the information of the entire prompt must first be processed to\nprefill the KV cache. Second, computation of subsequent tokens is bottlenecked\nby the high memory I/O demand of fetching the entire KV cache, which grows\nlinearly with sequence length, incurring quadratic memory reads overall. We\ndesign the Block Transformer to strategically mitigate these costs, by\nincorporating coarsity and locality into an integrated global-to-local\narchitecture. At the lower layers, we aggregate tokens into fixed size blocks\nto apply attention across the entire sequence at coarse-grained detail, to\ncapture the global context while minimizing KV cache overhead. At upper layers,\nwe apply attention within each block to decode individual tokens, to model\nfine-grained details with a lightweight local KV cache. We pretrain vanilla and\nBlock Transformers from scratch and demonstrate that Block Transformers reach\n10--20x inference throughput compared to vanilla transformers with equivalent\nperplexity and zero-shot task performance. Code is available at\nhttps://github.com/itsnamgyu/block-transformer.",
      "tldr_zh": "本研究提出 Block Transformer，一种采用分层全局到局部建模的自回归 Transformer 架构，旨在缓解 self-attention 机制在推理过程中的瓶颈问题。具体而言，该模型在较低层通过将 token 聚合为固定大小的块来实现粗粒度全局注意力，捕捉序列整体上下文的同时减少 KV cache 开销；在高层则在每个块内应用局部注意力，以轻量级 KV cache 解码单个 token 的细粒度细节。实验结果显示，从零开始预训练的 Block Transformer 在保持等效 perplexity 和零样本任务性能的前提下，实现 10-20 倍的推理吞吐量，从而显著提升批量推理效率。代码已在 GitHub 上公开。",
      "categories": [
        "cs.CL",
        "cs.AI",
        "cs.LG"
      ],
      "primary_category": "cs.CL",
      "comment": "37 pages, 24 figures, 7 tables",
      "pdf_url": "http://arxiv.org/pdf/2406.02657v2",
      "published_date": "2024-06-04 17:45:26 UTC",
      "updated_date": "2024-11-01 08:52:18 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-18T15:54:15.616537"
    },
    {
      "arxiv_id": "2406.02523v1",
      "title": "RoboCasa: Large-Scale Simulation of Everyday Tasks for Generalist Robots",
      "title_zh": "RoboCasa：大规模模拟日常任务的通用机器人",
      "authors": [
        "Soroush Nasiriany",
        "Abhiram Maddukuri",
        "Lance Zhang",
        "Adeet Parikh",
        "Aaron Lo",
        "Abhishek Joshi",
        "Ajay Mandlekar",
        "Yuke Zhu"
      ],
      "abstract": "Recent advancements in Artificial Intelligence (AI) have largely been\npropelled by scaling. In Robotics, scaling is hindered by the lack of access to\nmassive robot datasets. We advocate using realistic physical simulation as a\nmeans to scale environments, tasks, and datasets for robot learning methods. We\npresent RoboCasa, a large-scale simulation framework for training generalist\nrobots in everyday environments. RoboCasa features realistic and diverse scenes\nfocusing on kitchen environments. We provide thousands of 3D assets across over\n150 object categories and dozens of interactable furniture and appliances. We\nenrich the realism and diversity of our simulation with generative AI tools,\nsuch as object assets from text-to-3D models and environment textures from\ntext-to-image models. We design a set of 100 tasks for systematic evaluation,\nincluding composite tasks generated by the guidance of large language models.\nTo facilitate learning, we provide high-quality human demonstrations and\nintegrate automated trajectory generation methods to substantially enlarge our\ndatasets with minimal human burden. Our experiments show a clear scaling trend\nin using synthetically generated robot data for large-scale imitation learning\nand show great promise in harnessing simulation data in real-world tasks.\nVideos and open-source code are available at https://robocasa.ai/",
      "tldr_zh": "该研究提出RoboCasa，一种大规模模拟框架，用于训练通用机器人处理日常生活任务，通过现实物理模拟解决机器人数据集不足的问题。RoboCasa 包含真实多样的厨房场景、数千个 3D assets 覆盖 150 多个物体类别，以及可交互家具电器，并利用生成 AI 工具如 text-to-3D 和 text-to-image 模型增强模拟的真实性和多样性。该框架设计了 100 个系统任务（包括由 large language models 指导生成的复合任务），并提供高质量人类演示和自动轨迹生成方法来扩展数据集。实验结果显示，使用合成机器人数据进行大规模 imitation learning 表现出明显的规模效应，并展示出在真实世界任务中的巨大潜力。",
      "categories": [
        "cs.RO",
        "cs.AI",
        "cs.LG"
      ],
      "primary_category": "cs.RO",
      "comment": "RSS 2024",
      "pdf_url": "http://arxiv.org/pdf/2406.02523v1",
      "published_date": "2024-06-04 17:41:31 UTC",
      "updated_date": "2024-06-04 17:41:31 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-18T15:54:28.800260"
    },
    {
      "arxiv_id": "2406.02511v1",
      "title": "V-Express: Conditional Dropout for Progressive Training of Portrait Video Generation",
      "title_zh": "翻译失败",
      "authors": [
        "Cong Wang",
        "Kuan Tian",
        "Jun Zhang",
        "Yonghang Guan",
        "Feng Luo",
        "Fei Shen",
        "Zhiwei Jiang",
        "Qing Gu",
        "Xiao Han",
        "Wei Yang"
      ],
      "abstract": "In the field of portrait video generation, the use of single images to\ngenerate portrait videos has become increasingly prevalent. A common approach\ninvolves leveraging generative models to enhance adapters for controlled\ngeneration. However, control signals (e.g., text, audio, reference image, pose,\ndepth map, etc.) can vary in strength. Among these, weaker conditions often\nstruggle to be effective due to interference from stronger conditions, posing a\nchallenge in balancing these conditions. In our work on portrait video\ngeneration, we identified audio signals as particularly weak, often\novershadowed by stronger signals such as facial pose and reference image.\nHowever, direct training with weak signals often leads to difficulties in\nconvergence. To address this, we propose V-Express, a simple method that\nbalances different control signals through the progressive training and the\nconditional dropout operation. Our method gradually enables effective control\nby weak conditions, thereby achieving generation capabilities that\nsimultaneously take into account the facial pose, reference image, and audio.\nThe experimental results demonstrate that our method can effectively generate\nportrait videos controlled by audio. Furthermore, a potential solution is\nprovided for the simultaneous and effective use of conditions of varying\nstrengths.",
      "tldr_zh": "本研究针对肖像视频生成中的控制信号强度不均问题（如音频等弱信号被面部姿势和参考图像等强信号干扰），提出V-Express方法。该方法通过渐进式训练(Progressive Training)和条件Dropout操作来平衡不同控制信号，确保弱信号的有效利用，从而实现同时考虑面部姿势、参考图像和音频的视频生成。实验结果表明，V-Express能有效生成受音频控制的肖像视频，并为处理多种强度条件提供潜在解决方案。",
      "categories": [
        "cs.CV",
        "cs.AI"
      ],
      "primary_category": "cs.CV",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2406.02511v1",
      "published_date": "2024-06-04 17:32:52 UTC",
      "updated_date": "2024-06-04 17:32:52 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-18T15:54:39.808903"
    },
    {
      "arxiv_id": "2406.02507v3",
      "title": "Guiding a Diffusion Model with a Bad Version of Itself",
      "title_zh": "使用其自身的一个较差版本引导扩散模型",
      "authors": [
        "Tero Karras",
        "Miika Aittala",
        "Tuomas Kynkäänniemi",
        "Jaakko Lehtinen",
        "Timo Aila",
        "Samuli Laine"
      ],
      "abstract": "The primary axes of interest in image-generating diffusion models are image\nquality, the amount of variation in the results, and how well the results align\nwith a given condition, e.g., a class label or a text prompt. The popular\nclassifier-free guidance approach uses an unconditional model to guide a\nconditional model, leading to simultaneously better prompt alignment and\nhigher-quality images at the cost of reduced variation. These effects seem\ninherently entangled, and thus hard to control. We make the surprising\nobservation that it is possible to obtain disentangled control over image\nquality without compromising the amount of variation by guiding generation\nusing a smaller, less-trained version of the model itself rather than an\nunconditional model. This leads to significant improvements in ImageNet\ngeneration, setting record FIDs of 1.01 for 64x64 and 1.25 for 512x512, using\npublicly available networks. Furthermore, the method is also applicable to\nunconditional diffusion models, drastically improving their quality.",
      "tldr_zh": "本研究提出了一种新方法，用于指导图像生成扩散模型（diffusion models），通过使用模型自身的较小、训练不足版本（即“坏版本”）来控制图像质量，而不影响生成结果的变异性，从而解决传统 classifier-free guidance 方法中效果纠缠的问题。实验结果显示，该方法在 ImageNet 上显著提升了图像质量，实现了 64x64 分辨率的 FID 1.01 和 512x512 分辨率的 FID 1.25。总之，这种指导技术不仅适用于条件模型，还能大幅改善无条件扩散模型的性能，为生成任务提供更灵活的控制。",
      "categories": [
        "cs.CV",
        "cs.AI",
        "cs.LG",
        "cs.NE",
        "stat.ML"
      ],
      "primary_category": "cs.CV",
      "comment": "NeurIPS 2024",
      "pdf_url": "http://arxiv.org/pdf/2406.02507v3",
      "published_date": "2024-06-04 17:25:59 UTC",
      "updated_date": "2024-12-19 10:43:11 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-18T15:54:54.291186"
    },
    {
      "arxiv_id": "2406.02500v3",
      "title": "Towards Efficient Mixture of Experts: A Holistic Study of Compression Techniques",
      "title_zh": "迈向高效混合专家：压缩技术的整体性研究",
      "authors": [
        "Shwai He",
        "Daize Dong",
        "Liang Ding",
        "Ang Li"
      ],
      "abstract": "Scaling large language models has driven remarkable advancements across\nvarious domains, yet the continual increase in model size presents significant\nchallenges for real-world deployment. The Mixture of Experts (MoE) architecture\noffers a promising solution by dynamically selecting and activating only a\nsubset of experts during inference, thus substantially reducing computational\ncosts while preserving high performance. Despite these benefits, MoE introduces\nnew inefficiencies, such as excessive parameters and communication overhead. In\nthis work, we present a holistic study of compression techniques for Mixture of\nExperts to enhance both efficiency and scalability. While recent efforts have\nfocused on Expert Trimming, which reduces the number of experts, these\napproaches still suffer from considerable communication and computational\ncosts. To address this, we propose more aggressive strategies, such as Layer\nDrop, which removes entire MoE layers, and Block Drop, which eliminates\ntransformer blocks. Surprisingly, these aggressive pruning techniques not only\npreserve model performance but also substantially improve computation and\nmemory efficiency. Furthermore, beyond Expert Trimming, we also introduce\nExpert Slimming, which compresses individual experts to further boost\nperformance and can be seamlessly integrated with Expert Trimming. Extensive\nexperimental results demonstrate the effectiveness of our proposed\nmethods-Layer Drop and Block Drop-along with the comprehensive recipe that\nintegrates Expert Slimming and Expert Trimming, achieving a 6.05x speedup with\n77.1% reduced memory usage while maintaining over 92% of performance on\nMixtral-8x7B. Our code is released at\nhttps://github.com/CASE-Lab-UMD/Unified-MoE-Compression.",
      "tldr_zh": "本研究探讨了 Mixture of Experts (MoE) 架构的压缩技术，以解决大规模语言模型部署中的计算成本和通信开销问题。作者提出了激进策略如 Layer Drop（移除整个MoE层）和 Block Drop（消除transformer块），并引入 Expert Slimming（压缩单个专家）与 Expert Trimming（减少专家数量）的综合方法，这些技术不仅维持了模型性能，还显著提升了效率。实验结果显示，在 Mixtral-8x7B 上，该方法实现了 6.05x 加速、77.1% 内存减少，同时保持了 92% 以上的性能，为高效的 MoE 模型提供了全面优化方案。",
      "categories": [
        "cs.LG",
        "cs.AI"
      ],
      "primary_category": "cs.LG",
      "comment": "Transactions on Machine Learning Research (TMLR)",
      "pdf_url": "http://arxiv.org/pdf/2406.02500v3",
      "published_date": "2024-06-04 17:18:40 UTC",
      "updated_date": "2025-03-17 14:18:42 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-18T15:55:04.904873"
    },
    {
      "arxiv_id": "2406.02497v1",
      "title": "Dropout MPC: An Ensemble Neural MPC Approach for Systems with Learned Dynamics",
      "title_zh": "Dropout MPC：一种针对具有学习动态系统的集成神经 MPC 方法",
      "authors": [
        "Spyridon Syntakas",
        "Kostas Vlachos"
      ],
      "abstract": "Neural networks are lately more and more often being used in the context of\ndata-driven control, as an approximate model of the true system dynamics. Model\nPredictive Control (MPC) adopts this practise leading to neural MPC strategies.\nThis raises a question of whether the trained neural network has converged and\ngeneralized in a way that the learned model encapsulates an accurate\napproximation of the true dynamic model of the system, thus making it a\nreliable choice for model-based control, especially for disturbed and uncertain\nsystems. To tackle that, we propose Dropout MPC, a novel sampling-based\nensemble neural MPC algorithm that employs the Monte-Carlo dropout technique on\nthe learned system model. The closed loop is based on an ensemble of predictive\ncontrollers, that are used simultaneously at each time-step for trajectory\noptimization. Each member of the ensemble influences the control input, based\non a weighted voting scheme, thus by employing different realizations of the\nlearned system dynamics, neural control becomes more reliable by design. An\nadditional strength of the method is that it offers by design a way to estimate\nfuture uncertainty, leading to cautious control. While the method aims in\ngeneral at uncertain systems with complex dynamics, where models derived from\nfirst principles are hard to infer, to showcase the application we utilize data\ngathered in the laboratory from a real mobile manipulator and employ the\nproposed algorithm for the navigation of the robot in simulation.",
      "tldr_zh": "这篇论文针对使用神经网络作为系统动态模型的Model Predictive Control (MPC)问题，提出了Dropout MPC，一种基于采样的集成神经MPC算法。该方法采用Monte-Carlo dropout技术在学习到的系统模型上创建多个预测控制器，通过加权投票方案整合不同动态实现，提高控制的可靠性和鲁棒性，尤其适用于受扰和不确定系统。同时，该方法能自然估计未来不确定性，实现谨慎控制，并在模拟中应用于真实移动机械臂的导航任务中。",
      "categories": [
        "eess.SY",
        "cs.AI",
        "cs.LG",
        "cs.RO",
        "cs.SY"
      ],
      "primary_category": "eess.SY",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2406.02497v1",
      "published_date": "2024-06-04 17:15:25 UTC",
      "updated_date": "2024-06-04 17:15:25 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-18T15:55:16.806097"
    },
    {
      "arxiv_id": "2406.02496v1",
      "title": "Kolmogorov-Arnold Networks for Time Series: Bridging Predictive Power and Interpretability",
      "title_zh": "翻译失败",
      "authors": [
        "Kunpeng Xu",
        "Lifei Chen",
        "Shengrui Wang"
      ],
      "abstract": "Kolmogorov-Arnold Networks (KAN) is a groundbreaking model recently proposed\nby the MIT team, representing a revolutionary approach with the potential to be\na game-changer in the field. This innovative concept has rapidly garnered\nworldwide interest within the AI community. Inspired by the Kolmogorov-Arnold\nrepresentation theorem, KAN utilizes spline-parametrized univariate functions\nin place of traditional linear weights, enabling them to dynamically learn\nactivation patterns and significantly enhancing interpretability. In this\npaper, we explore the application of KAN to time series forecasting and propose\ntwo variants: T-KAN and MT-KAN. T-KAN is designed to detect concept drift\nwithin time series and can explain the nonlinear relationships between\npredictions and previous time steps through symbolic regression, making it\nhighly interpretable in dynamically changing environments. MT-KAN, on the other\nhand, improves predictive performance by effectively uncovering and leveraging\nthe complex relationships among variables in multivariate time series.\nExperiments validate the effectiveness of these approaches, demonstrating that\nT-KAN and MT-KAN significantly outperform traditional methods in time series\nforecasting tasks, not only enhancing predictive accuracy but also improving\nmodel interpretability. This research opens new avenues for adaptive\nforecasting models, highlighting the potential of KAN as a powerful and\ninterpretable tool in predictive analytics.",
      "tldr_zh": "这篇论文探讨了Kolmogorov-Arnold Networks (KAN)，一种基于Kolmogorov-Arnold表示定理的创新模型，使用样条参数化的univariate functions取代传统线性权重，从而动态学习激活模式并提升模型可解释性。论文提出两个针对时间序列预测的变体：T-KAN，用于检测time series中的concept drift，并通过symbolic regression解释预测与先前时间步之间的非线性关系；MT-KAN则通过揭示多变量time series中变量间的复杂关系来提高预测性能。实验结果显示，T-KAN和MT-KAN在时间序列预测任务中显著优于传统方法，不仅提升了预测准确性，还增强了模型的可解释性。该研究为自适应预测模型开辟了新路径，将KAN定位为强大且可解释的预测分析工具。",
      "categories": [
        "cs.LG",
        "cs.AI"
      ],
      "primary_category": "cs.LG",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2406.02496v1",
      "published_date": "2024-06-04 17:14:31 UTC",
      "updated_date": "2024-06-04 17:14:31 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-18T15:55:30.139960"
    },
    {
      "arxiv_id": "2406.02483v1",
      "title": "How Do Neural Spoofing Countermeasures Detect Partially Spoofed Audio?",
      "title_zh": "神经欺",
      "authors": [
        "Tianchi Liu",
        "Lin Zhang",
        "Rohan Kumar Das",
        "Yi Ma",
        "Ruijie Tao",
        "Haizhou Li"
      ],
      "abstract": "Partially manipulating a sentence can greatly change its meaning. Recent work\nshows that countermeasures (CMs) trained on partially spoofed audio can\neffectively detect such spoofing. However, the current understanding of the\ndecision-making process of CMs is limited. We utilize Grad-CAM and introduce a\nquantitative analysis metric to interpret CMs' decisions. We find that CMs\nprioritize the artifacts of transition regions created when concatenating bona\nfide and spoofed audio. This focus differs from that of CMs trained on fully\nspoofed audio, which concentrate on the pattern differences between bona fide\nand spoofed parts. Our further investigation explains the varying nature of\nCMs' focus while making correct or incorrect predictions. These insights\nprovide a basis for the design of CM models and the creation of datasets.\nMoreover, this work lays a foundation of interpretability in the field of\npartial spoofed audio detection that has not been well explored previously.",
      "tldr_zh": "本研究探讨了神经反制措施（CMs）如何检测部分伪造音频，通过引入Grad-CAM和一个定量分析指标来分析CMs的决策过程。研究发现，训练在部分伪造音频上的CMs主要关注拼接真实和伪造音频时产生的过渡区域伪造痕迹，与训练在完全伪造音频上的CMs（其专注于真实和伪造部分的模式差异）存在显著不同。进一步调查揭示了CMs在正确或错误预测时的关注点差异，这些洞见为CM模型设计、数据集创建以及部分伪造音频检测领域的可解释性提供了重要基础。",
      "categories": [
        "eess.AS",
        "cs.AI",
        "cs.SD"
      ],
      "primary_category": "eess.AS",
      "comment": "Accepted at Interspeech 2024",
      "pdf_url": "http://arxiv.org/pdf/2406.02483v1",
      "published_date": "2024-06-04 16:51:42 UTC",
      "updated_date": "2024-06-04 16:51:42 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-18T15:55:41.163791"
    },
    {
      "arxiv_id": "2407.16883v1",
      "title": "A Standardized Machine-readable Dataset Documentation Format for Responsible AI",
      "title_zh": "翻译失败",
      "authors": [
        "Nitisha Jain",
        "Mubashara Akhtar",
        "Joan Giner-Miguelez",
        "Rajat Shinde",
        "Joaquin Vanschoren",
        "Steffen Vogler",
        "Sujata Goswami",
        "Yuhan Rao",
        "Tim Santos",
        "Luis Oala",
        "Michalis Karamousadakis",
        "Manil Maskey",
        "Pierre Marcenac",
        "Costanza Conforti",
        "Michael Kuchnik",
        "Lora Aroyo",
        "Omar Benjelloun",
        "Elena Simperl"
      ],
      "abstract": "Data is critical to advancing AI technologies, yet its quality and\ndocumentation remain significant challenges, leading to adverse downstream\neffects (e.g., potential biases) in AI applications. This paper addresses these\nissues by introducing Croissant-RAI, a machine-readable metadata format\ndesigned to enhance the discoverability, interoperability, and trustworthiness\nof AI datasets. Croissant-RAI extends the Croissant metadata format and builds\nupon existing responsible AI (RAI) documentation frameworks, offering a\nstandardized set of attributes and practices to facilitate community-wide\nadoption. Leveraging established web-publishing practices, such as Schema.org,\nCroissant-RAI enables dataset users to easily find and utilize RAI metadata\nregardless of the platform on which the datasets are published. Furthermore, it\nis seamlessly integrated into major data search engines, repositories, and\nmachine learning frameworks, streamlining the reading and writing of\nresponsible AI metadata within practitioners' existing workflows. Croissant-RAI\nwas developed through a community-led effort. It has been designed to be\nadaptable to evolving documentation requirements and is supported by a Python\nlibrary and a visual editor.",
      "tldr_zh": "该论文针对AI数据集的质量和文档化问题（如潜在偏差），提出Croissant-RAI，这是一个标准化机器可读元数据格式，用于提升数据集的可发现性、互操作性和可信度。Croissant-RAI扩展了Croissant格式，并基于现有的Responsible AI (RAI)文档框架，利用Schema.org等网络发布实践，便于用户在不同平台轻松访问和使用RAI元数据。该格式无缝集成到主要数据搜索引擎、存储库和机器学习框架中，并通过社区主导开发，提供Python库和可视化编辑器支持，以适应不断演变的文档需求。",
      "categories": [
        "cs.IR",
        "cs.AI",
        "cs.CY",
        "cs.DB",
        "cs.LG"
      ],
      "primary_category": "cs.IR",
      "comment": "10 pages, appendix",
      "pdf_url": "http://arxiv.org/pdf/2407.16883v1",
      "published_date": "2024-06-04 16:40:14 UTC",
      "updated_date": "2024-06-04 16:40:14 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-18T15:55:53.611714"
    },
    {
      "arxiv_id": "2406.02654v2",
      "title": "kNN Classification of Malware Data Dependency Graph Features",
      "title_zh": "翻译失败",
      "authors": [
        "John Musgrave",
        "Anca Ralescu"
      ],
      "abstract": "Explainability in classification results are dependent upon the features used\nfor classification. Data dependency graph features representing data movement\nare directly correlated with operational semantics, and subject to fine grained\nanalysis. This study obtains accurate classification from the use of features\ntied to structure and semantics. By training an accurate model using labeled\ndata, this feature representation of semantics is shown to be correlated with\nground truth labels. This was performed using non-parametric learning with a\nnovel feature representation on a large scale dataset, the Kaggle 2015 Malware\ndataset. The features used enable fine grained analysis, increase in\nresolution, and explainable inferences. This allows for the body of the term\nfrequency distribution to be further analyzed and to provide an increase in\nfeature resolution over term frequency features. This method obtains high\naccuracy from analysis of a single instruction, a method that can be repeated\nfor additional instructions to obtain further increases in accuracy. This study\nevaluates the hypothesis that the semantic representation and analysis of\nstructure are able to make accurate predications and are also correlated to\nground truth labels. Additionally, similarity in the metric space can be\ncalculated directly without prior training. Our results provide evidence that\ndata dependency graphs accurately capture both semantic and structural\ninformation for increased explainability in classification results.",
      "tldr_zh": "本研究使用数据依赖图（Data Dependency Graph）特征结合 kNN（k-Nearest Neighbors）分类器，对恶意软件进行分类，旨在通过捕捉数据运动的结构和语义来提升模型的准确性和解释性。实验在 Kaggle 2015 Malware 数据集上采用非参数学习方法，展示了该特征表示与 ground truth 标签的高度相关性，并实现了单指令分析的高分辨率和细粒度分析。结果表明，该方法比传统词频特征更精确，并能直接计算相似性空间，而无需额外训练，从而为可解释的恶意软件分类提供有力证据。",
      "categories": [
        "cs.CR",
        "cs.AI",
        "cs.LG"
      ],
      "primary_category": "cs.CR",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2406.02654v2",
      "published_date": "2024-06-04 16:39:02 UTC",
      "updated_date": "2024-07-06 02:06:49 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-18T15:56:04.826675"
    },
    {
      "arxiv_id": "2406.02653v1",
      "title": "Pancreatic Tumor Segmentation as Anomaly Detection in CT Images Using Denoising Diffusion Models",
      "title_zh": "翻译失败",
      "authors": [
        "Reza Babaei",
        "Samuel Cheng",
        "Theresa Thai",
        "Shangqing Zhao"
      ],
      "abstract": "Despite the advances in medicine, cancer has remained a formidable challenge.\nParticularly in the case of pancreatic tumors, characterized by their diversity\nand late diagnosis, early detection poses a significant challenge crucial for\neffective treatment. The advancement of deep learning techniques, particularly\nsupervised algorithms, has significantly propelled pancreatic tumor detection\nin the medical field. However, supervised deep learning approaches necessitate\nextensive labeled medical images for training, yet acquiring such annotations\nis both limited and costly. Conversely, weakly supervised anomaly detection\nmethods, requiring only image-level annotations, have garnered interest.\nExisting methodologies predominantly hinge on generative adversarial networks\n(GANs) or autoencoder models, which can pose complexity in training and, these\nmodels may face difficulties in accurately preserving fine image details. This\nresearch presents a novel approach to pancreatic tumor detection, employing\nweak supervision anomaly detection through denoising diffusion algorithms. By\nincorporating a deterministic iterative process of adding and removing noise\nalong with classifier guidance, the method enables seamless translation of\nimages between diseased and healthy subjects, resulting in detailed anomaly\nmaps without requiring complex training protocols and segmentation masks. This\nstudy explores denoising diffusion models as a recent advancement over\ntraditional generative models like GANs, contributing to the field of\npancreatic tumor detection. Recognizing the low survival rates of pancreatic\ncancer, this study emphasizes the need for continued research to leverage\ndiffusion models' efficiency in medical segmentation tasks.",
      "tldr_zh": "本研究将胰腺肿瘤分割问题转化为异常检测（anomaly detection），提出一种基于去噪扩散模型（denoising diffusion models）的弱监督方法，以解决传统监督深度学习对大量标注数据的依赖。方法通过确定性迭代过程（添加和移除噪声）结合分类器引导，实现图像在健康和病变状态之间的平滑转换，从而生成详细的异常地图，而无需复杂的训练协议或分割掩码。与GAN或其他生成模型相比，该方法更易于训练并保留细致图像细节。研究强调这种创新方法有助于早期检测胰腺肿瘤，提高癌症治疗效果，并呼吁进一步探索扩散模型在医疗分割任务中的潜力。",
      "categories": [
        "eess.IV",
        "cs.AI",
        "cs.CV",
        "cs.LG"
      ],
      "primary_category": "eess.IV",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2406.02653v1",
      "published_date": "2024-06-04 16:38:11 UTC",
      "updated_date": "2024-06-04 16:38:11 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-18T15:56:16.748013"
    },
    {
      "arxiv_id": "2406.02465v1",
      "title": "An Empirical Study into Clustering of Unseen Datasets with Self-Supervised Encoders",
      "title_zh": "翻译失败",
      "authors": [
        "Scott C. Lowe",
        "Joakim Bruslund Haurum",
        "Sageev Oore",
        "Thomas B. Moeslund",
        "Graham W. Taylor"
      ],
      "abstract": "Can pretrained models generalize to new datasets without any retraining? We\ndeploy pretrained image models on datasets they were not trained for, and\ninvestigate whether their embeddings form meaningful clusters. Our suite of\nbenchmarking experiments use encoders pretrained solely on ImageNet-1k with\neither supervised or self-supervised training techniques, deployed on image\ndatasets that were not seen during training, and clustered with conventional\nclustering algorithms. This evaluation provides new insights into the\nembeddings of self-supervised models, which prioritize different features to\nsupervised models. Supervised encoders typically offer more utility than SSL\nencoders within the training domain, and vice-versa far outside of it, however,\nfine-tuned encoders demonstrate the opposite trend. Clustering provides a way\nto evaluate the utility of self-supervised learned representations orthogonal\nto existing methods such as kNN. Additionally, we find the silhouette score\nwhen measured in a UMAP-reduced space is highly correlated with clustering\nperformance, and can therefore be used as a proxy for clustering performance on\ndata with no ground truth labels. Our code implementation is available at\n\\url{https://github.com/scottclowe/zs-ssl-clustering/}.",
      "tldr_zh": "这篇论文通过实证研究，探讨了在 ImageNet-1k 上预训练的自监督编码器（self-supervised encoders）是否能在未见数据集上形成有意义的聚类，使用常规聚类算法进行评估。研究发现，自监督模型在训练域外优先考虑不同特征，从而比监督模型表现出更高的泛化能力，而微调后的编码器则显示相反趋势。作者还引入轮廓分数（silhouette score）在 UMAP 减少空间中作为聚类性能的代理，提供了一种与 kNN 等现有方法正交的评估方式，并公开了代码实现。",
      "categories": [
        "cs.LG",
        "cs.AI",
        "cs.CV"
      ],
      "primary_category": "cs.LG",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2406.02465v1",
      "published_date": "2024-06-04 16:34:17 UTC",
      "updated_date": "2024-06-04 16:34:17 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-18T15:56:31.079776"
    },
    {
      "arxiv_id": "2406.02464v1",
      "title": "Meta-Learners for Partially-Identified Treatment Effects Across Multiple Environments",
      "title_zh": "针对跨多个环境的部分识别治疗效果的元学习器",
      "authors": [
        "Jonas Schweisthal",
        "Dennis Frauen",
        "Mihaela van der Schaar",
        "Stefan Feuerriegel"
      ],
      "abstract": "Estimating the conditional average treatment effect (CATE) from observational\ndata is relevant for many applications such as personalized medicine. Here, we\nfocus on the widespread setting where the observational data come from multiple\nenvironments, such as different hospitals, physicians, or countries.\nFurthermore, we allow for violations of standard causal assumptions, namely,\noverlap within the environments and unconfoundedness. To this end, we move away\nfrom point identification and focus on partial identification. Specifically, we\nshow that current assumptions from the literature on multiple environments\nallow us to interpret the environment as an instrumental variable (IV). This\nallows us to adapt bounds from the IV literature for partial identification of\nCATE by leveraging treatment assignment mechanisms across environments. Then,\nwe propose different model-agnostic learners (so-called meta-learners) to\nestimate the bounds that can be used in combination with arbitrary machine\nlearning models. We further demonstrate the effectiveness of our meta-learners\nacross various experiments using both simulated and real-world data. Finally,\nwe discuss the applicability of our meta-learners to partial identification in\ninstrumental variable settings, such as randomized controlled trials with\nnon-compliance.",
      "tldr_zh": "该论文探讨了从多环境观察数据中估计条件平均治疗效果（CATE），允许违反标准因果假设（如环境内重叠和无混杂），并转向部分识别（partial identification）。作者将环境视为工具变量（IV），并适应IV文献中的边界方法，利用跨环境治疗分配机制来部分识别CATE。论文提出多种模型无关的学习器（meta-learners），可与任意机器学习模型结合，并通过模拟和真实数据实验证明其有效性。最后，讨论了这些meta-learners在其他IV设置（如有不遵守的随机对照试验）中的适用潜力。",
      "categories": [
        "cs.LG",
        "cs.AI",
        "stat.ML"
      ],
      "primary_category": "cs.LG",
      "comment": "Accepted at ICML 2024",
      "pdf_url": "http://arxiv.org/pdf/2406.02464v1",
      "published_date": "2024-06-04 16:31:43 UTC",
      "updated_date": "2024-06-04 16:31:43 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-18T15:56:40.866411"
    },
    {
      "arxiv_id": "2406.02462v2",
      "title": "Learning Image Priors through Patch-based Diffusion Models for Solving Inverse Problems",
      "title_zh": "通过基于图像块的扩散模型学习图像先验以解决逆问题",
      "authors": [
        "Jason Hu",
        "Bowen Song",
        "Xiaojian Xu",
        "Liyue Shen",
        "Jeffrey A. Fessler"
      ],
      "abstract": "Diffusion models can learn strong image priors from underlying data\ndistribution and use them to solve inverse problems, but the training process\nis computationally expensive and requires lots of data. Such bottlenecks\nprevent most existing works from being feasible for high-dimensional and\nhigh-resolution data such as 3D images. This paper proposes a method to learn\nan efficient data prior for the entire image by training diffusion models only\non patches of images. Specifically, we propose a patch-based position-aware\ndiffusion inverse solver, called PaDIS, where we obtain the score function of\nthe whole image through scores of patches and their positional encoding and\nutilize this as the prior for solving inverse problems. First of all, we show\nthat this diffusion model achieves an improved memory efficiency and data\nefficiency while still maintaining the capability to generate entire images via\npositional encoding. Additionally, the proposed PaDIS model is highly flexible\nand can be plugged in with different diffusion inverse solvers (DIS). We\ndemonstrate that the proposed PaDIS approach enables solving various inverse\nproblems in both natural and medical image domains, including CT\nreconstruction, deblurring, and superresolution, given only patch-based priors.\nNotably, PaDIS outperforms previous DIS methods trained on entire image priors\nin the case of limited training data, demonstrating the data efficiency of our\nproposed approach by learning patch-based prior.",
      "tldr_zh": "本论文提出了一种名为 PaDIS 的方法，通过在图像块（patches）上训练扩散模型（diffusion models），来学习图像先验（image priors）并解决逆问题（inverse problems），从而克服传统方法在计算和数据需求上的瓶颈。PaDIS 利用位置编码（positional encoding）将图像块的得分函数（score function）扩展到整个图像，并与各种扩散逆问题求解器（diffusion inverse solvers）兼容，提高了内存和数据效率。实验显示，该方法在 CT 重建、去模糊和超分辨率等任务上，尤其在训练数据有限时，显著优于基于全图像先验的现有方法。",
      "categories": [
        "cs.CV",
        "cs.AI"
      ],
      "primary_category": "cs.CV",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2406.02462v2",
      "published_date": "2024-06-04 16:30:37 UTC",
      "updated_date": "2024-10-30 23:48:44 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-18T15:56:54.352299"
    },
    {
      "arxiv_id": "2406.02450v1",
      "title": "A Generalized Apprenticeship Learning Framework for Modeling Heterogeneous Student Pedagogical Strategies",
      "title_zh": "翻译失败",
      "authors": [
        "Md Mirajul Islam",
        "Xi Yang",
        "John Hostetter",
        "Adittya Soukarjya Saha",
        "Min Chi"
      ],
      "abstract": "A key challenge in e-learning environments like Intelligent Tutoring Systems\n(ITSs) is to induce effective pedagogical policies efficiently. While Deep\nReinforcement Learning (DRL) often suffers from sample inefficiency and reward\nfunction design difficulty, Apprenticeship Learning(AL) algorithms can overcome\nthem. However, most AL algorithms can not handle heterogeneity as they assume\nall demonstrations are generated with a homogeneous policy driven by a single\nreward function. Still, some AL algorithms which consider heterogeneity, often\ncan not generalize to large continuous state space and only work with discrete\nstates. In this paper, we propose an expectation-maximization(EM)-EDM, a\ngeneral AL framework to induce effective pedagogical policies from given\noptimal or near-optimal demonstrations, which are assumed to be driven by\nheterogeneous reward functions. We compare the effectiveness of the policies\ninduced by our proposed EM-EDM against four AL-based baselines and two policies\ninduced by DRL on two different but related tasks that involve pedagogical\naction prediction. Our overall results showed that, for both tasks, EM-EDM\noutperforms the four AL baselines across all performance metrics and the two\nDRL baselines. This suggests that EM-EDM can effectively model complex student\npedagogical decision-making processes through the ability to manage a large,\ncontinuous state space and adapt to handle diverse and heterogeneous reward\nfunctions with very few given demonstrations.",
      "tldr_zh": "本论文提出了一种通用的Apprenticeship Learning (AL)框架，名为EM-EDM，用于从异构奖励函数驱动的演示中诱导有效的教学策略，以解决电子学习环境如Intelligent Tutoring Systems (ITSs)中策略学习效率低的问题。该框架采用Expectation-Maximization (EM)算法，能够处理大型连续状态空间和异构性，相比传统AL算法更具泛化能力。在实验中，EM-EDM在两个教学行动预测任务上优于四个AL基线和两个Deep Reinforcement Learning (DRL)基线模型，证明其在建模复杂学生教学决策过程方面的高效性，仅需少量演示即可实现出色性能。",
      "categories": [
        "cs.LG",
        "cs.AI"
      ],
      "primary_category": "cs.LG",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2406.02450v1",
      "published_date": "2024-06-04 16:14:55 UTC",
      "updated_date": "2024-06-04 16:14:55 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-18T15:57:06.256040"
    },
    {
      "arxiv_id": "2406.02652v2",
      "title": "RepCNN: Micro-sized, Mighty Models for Wakeword Detection",
      "title_zh": "翻译失败",
      "authors": [
        "Arnav Kundu",
        "Prateeth Nayak",
        "Priyanka Padmanabhan",
        "Devang Naik"
      ],
      "abstract": "Always-on machine learning models require a very low memory and compute\nfootprint. Their restricted parameter count limits the model's capacity to\nlearn, and the effectiveness of the usual training algorithms to find the best\nparameters. Here we show that a small convolutional model can be better trained\nby first refactoring its computation into a larger redundant multi-branched\narchitecture. Then, for inference, we algebraically re-parameterize the trained\nmodel into the single-branched form with fewer parameters for a lower memory\nfootprint and compute cost. Using this technique, we show that our always-on\nwake-word detector model, RepCNN, provides a good trade-off between latency and\naccuracy during inference. RepCNN re-parameterized models are 43% more accurate\nthan a uni-branch convolutional model while having the same runtime. RepCNN\nalso meets the accuracy of complex architectures like BC-ResNet, while having\n2x lesser peak memory usage and 10x faster runtime.",
      "tldr_zh": "该研究提出RepCNN，一种微型高效的卷积模型，用于唤醒词检测，旨在解决总是开启的机器学习模型在内存和计算资源受限时的训练挑战。方法包括先将模型重构为更大的冗余多分支架构进行训练，然后通过代数重参数化转换回单分支形式，以减少推理时的参数数量和计算成本。实验结果显示，RepCNN 比单分支卷积模型准确率提高43%，同时保持相同的运行时间；此外，它达到了BC-ResNet的准确性水平，但峰值内存使用减少2倍，运行速度快10倍。",
      "categories": [
        "eess.AS",
        "cs.AI",
        "cs.LG"
      ],
      "primary_category": "eess.AS",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2406.02652v2",
      "published_date": "2024-06-04 16:14:19 UTC",
      "updated_date": "2024-08-01 22:39:20 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-18T15:57:17.641054"
    },
    {
      "arxiv_id": "2406.02449v1",
      "title": "Representations as Language: An Information-Theoretic Framework for Interpretability",
      "title_zh": "翻译失败",
      "authors": [
        "Henry Conklin",
        "Kenny Smith"
      ],
      "abstract": "Large scale neural models show impressive performance across a wide array of\nlinguistic tasks. Despite this they remain, largely, black-boxes - inducing\nvector-representations of their input that prove difficult to interpret. This\nlimits our ability to understand what they learn, and when the learn it, or\ndescribe what kinds of representations generalise well out of distribution. To\naddress this we introduce a novel approach to interpretability that looks at\nthe mapping a model learns from sentences to representations as a kind of\nlanguage in its own right. In doing so we introduce a set of\ninformation-theoretic measures that quantify how structured a model's\nrepresentations are with respect to its input, and when during training that\nstructure arises. Our measures are fast to compute, grounded in linguistic\ntheory, and can predict which models will generalise best based on their\nrepresentations. We use these measures to describe two distinct phases of\ntraining a transformer: an initial phase of in-distribution learning which\nreduces task loss, then a second stage where representations becoming robust to\nnoise. Generalisation performance begins to increase during this second phase,\ndrawing a link between generalisation and robustness to noise. Finally we look\nat how model size affects the structure of the representational space, showing\nthat larger models ultimately compress their representations more than their\nsmaller counterparts.",
      "tldr_zh": "这篇论文提出了一种基于信息理论（information-theoretic）的框架，将神经模型从句子到表示的映射视为一种语言，从而提升模型的解释性（interpretability）。他们引入了一系列快速计算的信息理论措施，用于量化模型表示的结构化程度，以及这种结构在训练过程中的出现时间，这些措施基于语言理论并能预测模型的泛化性能。研究发现，transformer 模型的训练分为两个阶段：初始的 in-distribution learning 阶段减少任务损失，随后阶段表示变得对噪声更鲁棒，并与泛化性能的提升相关联。最后，论文显示，更大的模型会更有效地压缩表示空间，从而改善整体表现。",
      "categories": [
        "cs.CL",
        "cs.AI"
      ],
      "primary_category": "cs.CL",
      "comment": "6 pages, 3 Figures",
      "pdf_url": "http://arxiv.org/pdf/2406.02449v1",
      "published_date": "2024-06-04 16:14:00 UTC",
      "updated_date": "2024-06-04 16:14:00 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-18T15:57:29.644771"
    },
    {
      "arxiv_id": "2406.06581v3",
      "title": "Order-Independence Without Fine Tuning",
      "title_zh": "无需微调的顺序无关性",
      "authors": [
        "Reid McIlroy-Young",
        "Katrina Brown",
        "Conlan Olson",
        "Linjun Zhang",
        "Cynthia Dwork"
      ],
      "abstract": "The development of generative language models that can create long and\ncoherent textual outputs via autoregression has lead to a proliferation of uses\nand a corresponding sweep of analyses as researches work to determine the\nlimitations of this new paradigm. Unlike humans, these 'Large Language Models'\n(LLMs) are highly sensitive to small changes in their inputs, leading to\nunwanted inconsistency in their behavior. One problematic inconsistency when\nLLMs are used to answer multiple-choice questions or analyze multiple inputs is\norder dependency: the output of an LLM can (and often does) change\nsignificantly when sub-sequences are swapped, despite both orderings being\nsemantically identical. In this paper we present Set-Based Prompting, a\ntechnique that guarantees the output of an LLM will not have order dependence\non a specified set of sub-sequences. We show that this method provably\neliminates order dependency, and that it can be applied to any\ntransformer-based LLM to enable text generation that is unaffected by\nre-orderings. Delving into the implications of our method, we show that,\ndespite our inputs being out of distribution, the impact on expected accuracy\nis small, where the expectation is over the order of uniformly chosen shuffling\nof the candidate responses, and usually significantly less in practice. Thus,\nSet-Based Prompting can be used as a 'dropped-in' method on fully trained\nmodels. Finally, we discuss how our method's success suggests that other strong\nguarantees can be obtained on LLM performance via modifying the input\nrepresentations.",
      "tldr_zh": "本研究探讨了大型语言模型（LLMs）对输入顺序的敏感性问题，该问题会导致在处理多重输入时出现不一致输出，如在多选题分析中交换子序列顺序即会改变结果。论文提出 Set-Based Prompting 技术，该方法通过修改提示方式，确保 LLM 输出对指定子序列的重新排序完全不依赖，且无需对模型进行微调。实验结果显示，这种技术在保持预期准确性（尤其在随机顺序下）的影响很小，通常在实际应用中更具鲁棒性，并暗示可以通过调整输入表示来获得其他 LLM 性能保证。",
      "categories": [
        "cs.CL",
        "cs.AI",
        "cs.LG"
      ],
      "primary_category": "cs.CL",
      "comment": "29 pages, 27 figures, Published in NeurIPS 2024 code\n  https://github.com/reidmcy/set-based-prompting",
      "pdf_url": "http://arxiv.org/pdf/2406.06581v3",
      "published_date": "2024-06-04 16:09:13 UTC",
      "updated_date": "2024-12-09 20:32:47 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-18T15:57:41.049196"
    },
    {
      "arxiv_id": "2406.02443v2",
      "title": "Explainable Deep Learning Analysis for Raga Identification in Indian Art Music",
      "title_zh": "可解释深度学习分析用于印度艺术音乐中的 Raga 识别",
      "authors": [
        "Parampreet Singh",
        "Vipul Arora"
      ],
      "abstract": "Raga identification is an important problem within the domain of Indian Art\nmusic, as Ragas are fundamental to its composition and performance, playing a\ncrucial role in music retrieval, preservation, and education. Few studies that\nhave explored this task employ approaches such as signal processing, Machine\nLearning (ML), and more recently, Deep Learning (DL) based methods. However, a\nkey question remains unanswered in all these works: do these ML/DL methods\nlearn and interpret Ragas in a manner similar to human experts? Besides, a\nsignificant roadblock in this research is the unavailability of an ample supply\nof rich, labeled datasets, which drives these ML/DL-based methods. In this\npaper, firstly we curate a dataset comprising 191 hours of Hindustani Classical\nMusic (HCM) recordings, annotate it for Raga and tonic labels, and train a\nCNN-LSTM model for the task of Automatic Raga Identification (ARI). We achieve\na chunk-wise f1-measure of 0.89 for a subset of 12 Raga classes. Following\nthis, we make one of the first attempts to employ model explainability\ntechniques: SoundLIME and GradCAM++ for Raga identification, to evaluate\nwhether the classifier's predictions align with human understanding of Ragas.\nWe compare the generated explanations with human expert annotations and further\nanalyze individual test examples to understand the role of regions highlighted\nby explanations in making correct or incorrect predictions made by the model.\nOur results demonstrate a significant alignment of the model's understanding\nwith human understanding, and the thorough analysis validates the effectiveness\nof our approach.",
      "tldr_zh": "本研究探讨了印度艺术音乐中 Raga 识别的关键问题，旨在评估机器学习(ML)和深度学习(DL)方法是否与人类专家的理解一致。作者首先整理了一个包含191小时 Hindustani Classical Music (HCM) 录音的数据集，并标注 Raga 和 tonic 标签，训练了一个 CNN-LSTM 模型用于 Automatic Raga Identification (ARI)，在12个 Raga 类上达到0.89的 chunk-wise f1-measure。接着，通过 SoundLIME 和 GradCAM++ 等模型可解释性技术分析模型预测，结果显示模型的理解与人类专家标注高度一致，并通过详细案例验证了方法的有效性。总的来说，该工作为音乐检索、保存和教育提供了可信赖的 DL 框架。",
      "categories": [
        "eess.AS",
        "cs.AI"
      ],
      "primary_category": "eess.AS",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2406.02443v2",
      "published_date": "2024-06-04 16:06:51 UTC",
      "updated_date": "2024-12-21 08:32:18 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-18T15:57:55.216995"
    },
    {
      "arxiv_id": "2406.02651v1",
      "title": "RoutePlacer: An End-to-End Routability-Aware Placer with Graph Neural Network",
      "title_zh": "翻译失败",
      "authors": [
        "Yunbo Hou",
        "Haoran Ye",
        "Yingxue Zhang",
        "Siyuan Xu",
        "Guojie Song"
      ],
      "abstract": "Placement is a critical and challenging step of modern chip design, with\nroutability being an essential indicator of placement quality. Current\nroutability-oriented placers typically apply an iterative two-stage approach,\nwherein the first stage generates a placement solution, and the second stage\nprovides non-differentiable routing results to heuristically improve the\nsolution quality. This method hinders jointly optimizing the routability aspect\nduring placement. To address this problem, this work introduces RoutePlacer, an\nend-to-end routability-aware placement method. It trains RouteGNN, a customized\ngraph neural network, to efficiently and accurately predict routability by\ncapturing and fusing geometric and topological representations of placements.\nWell-trained RouteGNN then serves as a differentiable approximation of\nroutability, enabling end-to-end gradient-based routability optimization. In\naddition, RouteGNN can improve two-stage placers as a plug-and-play alternative\nto external routers. Our experiments on DREAMPlace, an open-source AI4EDA\nplatform, show that RoutePlacer can reduce Total Overflow by up to 16% while\nmaintaining routed wirelength, compared to the state-of-the-art; integrating\nRouteGNN within two-stage placers leads to a 44% reduction in Total Overflow\nwithout compromising wirelength.",
      "tldr_zh": "本研究提出RoutePlacer，一种端到端的、可路由性感知的芯片布局方法，使用Graph Neural Network（RouteGNN）来预测和优化布局的可路由性问题。RouteGNN通过捕捉并融合几何和拓扑表示，作为可微分近似，实现了端到端的梯度-based优化，同时可作为插件集成到传统两阶段布局器中进行改进。在DREAMPlace平台上的实验显示，与最先进方法相比，RoutePlacer可将Total Overflow减少多达16%并保持routed wirelength，而整合RouteGNN后可进一步减少44%的Total Overflow而不影响wirelength。",
      "categories": [
        "cs.LG",
        "cs.AI",
        "cs.NI"
      ],
      "primary_category": "cs.LG",
      "comment": "Accepted at KDD 2024",
      "pdf_url": "http://arxiv.org/pdf/2406.02651v1",
      "published_date": "2024-06-04 15:39:41 UTC",
      "updated_date": "2024-06-04 15:39:41 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-18T15:58:05.533654"
    },
    {
      "arxiv_id": "2406.03403v1",
      "title": "Structure-based Drug Design Benchmark: Do 3D Methods Really Dominate?",
      "title_zh": "基于结构的药物设计基准：三维方法真的主导吗？",
      "authors": [
        "Kangyu Zheng",
        "Yingzhou Lu",
        "Zaixi Zhang",
        "Zhongwei Wan",
        "Yao Ma",
        "Marinka Zitnik",
        "Tianfan Fu"
      ],
      "abstract": "Currently, the field of structure-based drug design is dominated by three\nmain types of algorithms: search-based algorithms, deep generative models, and\nreinforcement learning. While existing works have typically focused on\ncomparing models within a single algorithmic category, cross-algorithm\ncomparisons remain scarce. In this paper, to fill the gap, we establish a\nbenchmark to evaluate the performance of sixteen models across these different\nalgorithmic foundations by assessing the pharmaceutical properties of the\ngenerated molecules and their docking affinities with specified target\nproteins. We highlight the unique advantages of each algorithmic approach and\noffer recommendations for the design of future SBDD models. We emphasize that\n1D/2D ligand-centric drug design methods can be used in SBDD by treating the\ndocking function as a black-box oracle, which is typically neglected. The\nempirical results show that 1D/2D methods achieve competitive performance\ncompared with 3D-based methods that use the 3D structure of the target protein\nexplicitly. Also, AutoGrow4, a 2D molecular graph-based genetic algorithm,\ndominates SBDD in terms of optimization ability. The relevant code is available\nin https://github.com/zkysfls/2024-sbdd-benchmark.",
      "tldr_zh": "本论文建立了一个结构基药物设计(SBDD)基准，用于评估16个模型的性能，包括基于搜索的算法、深度生成模型和强化学习方法，通过比较生成的分子药学特性和对接亲和力。结果显示，1D/2D配体中心方法（如将对接函数视为黑箱预言机）与显式使用目标蛋白3D结构的3D方法竞争力相当，其中AutoGrow4（一个2D分子图基于的遗传算法）在优化能力上表现出色。该基准突出了每种算法的独特优势，并为未来SBDD模型设计提供了具体推荐。",
      "categories": [
        "cs.LG",
        "cs.AI",
        "q-bio.QM"
      ],
      "primary_category": "cs.LG",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2406.03403v1",
      "published_date": "2024-06-04 15:37:14 UTC",
      "updated_date": "2024-06-04 15:37:14 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-18T15:58:20.876750"
    },
    {
      "arxiv_id": "2406.02650v1",
      "title": "By Fair Means or Foul: Quantifying Collusion in a Market Simulation with Deep Reinforcement Learning",
      "title_zh": "翻译失败",
      "authors": [
        "Michael Schlechtinger",
        "Damaris Kosack",
        "Franz Krause",
        "Heiko Paulheim"
      ],
      "abstract": "In the rapidly evolving landscape of eCommerce, Artificial Intelligence (AI)\nbased pricing algorithms, particularly those utilizing Reinforcement Learning\n(RL), are becoming increasingly prevalent. This rise has led to an inextricable\npricing situation with the potential for market collusion. Our research employs\nan experimental oligopoly model of repeated price competition, systematically\nvarying the environment to cover scenarios from basic economic theory to\nsubjective consumer demand preferences. We also introduce a novel demand\nframework that enables the implementation of various demand models, allowing\nfor a weighted blending of different models. In contrast to existing research\nin this domain, we aim to investigate the strategies and emerging pricing\npatterns developed by the agents, which may lead to a collusive outcome.\nFurthermore, we investigate a scenario where agents cannot observe their\ncompetitors' prices. Finally, we provide a comprehensive legal analysis across\nall scenarios. Our findings indicate that RL-based AI agents converge to a\ncollusive state characterized by the charging of supracompetitive prices,\nwithout necessarily requiring inter-agent communication. Implementing\nalternative RL algorithms, altering the number of agents or simulation\nsettings, and restricting the scope of the agents' observation space does not\nsignificantly impact the collusive market outcome behavior.",
      "tldr_zh": "这篇论文使用深度强化学习(Deep Reinforcement Learning)模拟实验性寡头垄断模型，系统地探索AI代理在电子商务定价中的潜在勾结行为，包括从基本经济理论到主观消费者需求偏好的各种场景。研究者引入了一个新型需求框架，支持不同需求模型的加权混合，并调查代理策略及其可能导致的超竞争价格。结果表明，RL代理在无需代理间通信的情况下会收敛到勾结状态，且改变算法、代理数量或观察空间等因素不会显著影响这一行为。论文还提供了全面的法律分析，以评估这些市场动态的合规性。",
      "categories": [
        "cs.LG",
        "cs.AI"
      ],
      "primary_category": "cs.LG",
      "comment": "Preprint for IJCAI 2024",
      "pdf_url": "http://arxiv.org/pdf/2406.02650v1",
      "published_date": "2024-06-04 15:35:08 UTC",
      "updated_date": "2024-06-04 15:35:08 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-18T15:58:34.623913"
    },
    {
      "arxiv_id": "2406.19403v1",
      "title": "Temporal distribution of clusters of investors and their application in prediction with expert advice",
      "title_zh": "投资者集群的时间分布及其在基于专家建议预测中的应用",
      "authors": [
        "Wojciech Wisniewski",
        "Yuri Kalnishkan",
        "David Lindsay",
        "Siân Lindsay"
      ],
      "abstract": "Financial organisations such as brokers face a significant challenge in\nservicing the investment needs of thousands of their traders worldwide. This\ntask is further compounded since individual traders will have their own risk\nappetite and investment goals. Traders may look to capture short-term trends in\nthe market which last only seconds to minutes, or they may have longer-term\nviews which last several days to months. To reduce the complexity of this task,\nclient trades can be clustered. By examining such clusters, we would likely\nobserve many traders following common patterns of investment, but how do these\npatterns vary through time? Knowledge regarding the temporal distributions of\nsuch clusters may help financial institutions manage the overall portfolio of\nrisk that accumulates from underlying trader positions. This study contributes\nto the field by demonstrating that the distribution of clusters derived from\nthe real-world trades of 20k Foreign Exchange (FX) traders (from 2015 to 2017)\nis described in accordance with Ewens' Sampling Distribution. Further, we show\nthat the Aggregating Algorithm (AA), an on-line prediction with expert advice\nalgorithm, can be applied to the aforementioned real-world data in order to\nimprove the returns of portfolios of trader risk. However we found that the AA\n'struggles' when presented with too many trader ``experts'', especially when\nthere are many trades with similar overall patterns. To help overcome this\nchallenge, we have applied and compared the use of Statistically Validated\nNetworks (SVN) with a hierarchical clustering approach on a subset of the data,\ndemonstrating that both approaches can be used to significantly improve results\nof the AA in terms of profitability and smoothness of returns.",
      "tldr_zh": "本研究探讨了投资者集群的时序分布及其在预测以专家建议（prediction with expert advice）中的应用，通过分析20k外汇（FX）交易者从2015到2017年的真实数据，发现这些集群的分布符合Ewens' Sampling Distribution。研究运用Aggregating Algorithm (AA)来优化交易者风险组合的回报，但AA在处理过多专家时表现不佳，导致回报波动。针对这一问题，作者比较了Statistically Validated Networks (SVN)和hierarchical clustering方法，结果显示这些方法能显著提升AA的盈利性和回报平稳性。",
      "categories": [
        "q-fin.ST",
        "cs.AI",
        "cs.CE",
        "cs.LG"
      ],
      "primary_category": "q-fin.ST",
      "comment": "20 pages, technical report",
      "pdf_url": "http://arxiv.org/pdf/2406.19403v1",
      "published_date": "2024-06-04 15:28:06 UTC",
      "updated_date": "2024-06-04 15:28:06 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-18T15:58:48.477989"
    },
    {
      "arxiv_id": "2406.02396v1",
      "title": "The Scandinavian Embedding Benchmarks: Comprehensive Assessment of Multilingual and Monolingual Text Embedding",
      "title_zh": "翻译失败",
      "authors": [
        "Kenneth Enevoldsen",
        "Márton Kardos",
        "Niklas Muennighoff",
        "Kristoffer Laigaard Nielbo"
      ],
      "abstract": "The evaluation of English text embeddings has transitioned from evaluating a\nhandful of datasets to broad coverage across many tasks through benchmarks such\nas MTEB. However, this is not the case for multilingual text embeddings due to\na lack of available benchmarks. To address this problem, we introduce the\nScandinavian Embedding Benchmark (SEB). SEB is a comprehensive framework that\nenables text embedding evaluation for Scandinavian languages across 24 tasks,\n10 subtasks, and 4 task categories. Building on SEB, we evaluate more than 26\nmodels, uncovering significant performance disparities between public and\ncommercial solutions not previously captured by MTEB. We open-source SEB and\nintegrate it with MTEB, thus bridging the text embedding evaluation gap for\nScandinavian languages.",
      "tldr_zh": "该论文引入了Scandinavian Embedding Benchmark (SEB)，一个全面框架，用于评估斯堪的纳维亚语言的多语言和单语言text embedding，目前这类评估因缺乏基准而落后于英语领域。SEB涵盖24个任务、10个子任务和4个任务类别，通过评估26多个模型，揭示了公共和商业解决方案之间未被MTEB捕获的显著性能差异。最终，论文开源SEB并将其与MTEB整合，桥接了斯堪的纳维亚语言text embedding评估的空白，从而提升了多语言嵌入模型的评估标准。",
      "categories": [
        "cs.CL",
        "cs.AI"
      ],
      "primary_category": "cs.CL",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2406.02396v1",
      "published_date": "2024-06-04 15:11:27 UTC",
      "updated_date": "2024-06-04 15:11:27 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-18T15:58:56.834746"
    },
    {
      "arxiv_id": "2406.02394v1",
      "title": "Multiple Choice Questions and Large Languages Models: A Case Study with Fictional Medical Data",
      "title_zh": "翻译失败",
      "authors": [
        "Maxime Griot",
        "Jean Vanderdonckt",
        "Demet Yuksel",
        "Coralie Hemptinne"
      ],
      "abstract": "Large Language Models (LLMs) like ChatGPT demonstrate significant potential\nin the medical field, often evaluated using multiple-choice questions (MCQs)\nsimilar to those found on the USMLE. Despite their prevalence in medical\neducation, MCQs have limitations that might be exacerbated when assessing LLMs.\nTo evaluate the effectiveness of MCQs in assessing the performance of LLMs, we\ndeveloped a fictional medical benchmark focused on a non-existent gland, the\nGlianorex. This approach allowed us to isolate the knowledge of the LLM from\nits test-taking abilities. We used GPT-4 to generate a comprehensive textbook\non the Glianorex in both English and French and developed corresponding\nmultiple-choice questions in both languages. We evaluated various open-source,\nproprietary, and domain-specific LLMs using these questions in a zero-shot\nsetting. The models achieved average scores around 67%, with minor performance\ndifferences between larger and smaller models. Performance was slightly higher\nin English than in French. Fine-tuned medical models showed some improvement\nover their base versions in English but not in French. The uniformly high\nperformance across models suggests that traditional MCQ-based benchmarks may\nnot accurately measure LLMs' clinical knowledge and reasoning abilities,\ninstead highlighting their pattern recognition skills. This study underscores\nthe need for more robust evaluation methods to better assess the true\ncapabilities of LLMs in medical contexts.",
      "tldr_zh": "这篇论文探讨了多选题 (MCQs) 在评估大型语言模型 (LLMs) 性能时的局限性，通过一个虚构医疗基准来研究这一问题。研究者使用 GPT-4 生成关于虚构腺体“Glianorex”的教科书和相应 MCQs（英文和法文），并在零样本设置下测试各种开源、专有和领域特定 LLMs。结果显示，模型平均得分约 67%，英文表现略优于法文，且微调的医疗模型仅在英文中有所改善。这些发现表明，传统 MCQs 基准可能更侧重于 LLMs 的模式识别技能而非实际临床知识和推理能力，呼吁开发更 robust 的评估方法。",
      "categories": [
        "cs.CL",
        "cs.AI",
        "cs.LG"
      ],
      "primary_category": "cs.CL",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2406.02394v1",
      "published_date": "2024-06-04 15:08:56 UTC",
      "updated_date": "2024-06-04 15:08:56 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-18T15:59:12.561629"
    },
    {
      "arxiv_id": "2406.02383v2",
      "title": "Learning to Edit Visual Programs with Self-Supervision",
      "title_zh": "翻译失败",
      "authors": [
        "R. Kenny Jones",
        "Renhao Zhang",
        "Aditya Ganeshan",
        "Daniel Ritchie"
      ],
      "abstract": "We design a system that learns how to edit visual programs. Our edit network\nconsumes a complete input program and a visual target. From this input, we task\nour network with predicting a local edit operation that could be applied to the\ninput program to improve its similarity to the target. In order to apply this\nscheme for domains that lack program annotations, we develop a self-supervised\nlearning approach that integrates this edit network into a bootstrapped\nfinetuning loop along with a network that predicts entire programs in one-shot.\nOur joint finetuning scheme, when coupled with an inference procedure that\ninitializes a population from the one-shot model and evolves members of this\npopulation with the edit network, helps to infer more accurate visual programs.\nOver multiple domains, we experimentally compare our method against the\nalternative of using only the one-shot model, and find that even under equal\nsearch-time budgets, our editing-based paradigm provides significant\nadvantages.",
      "tldr_zh": "这篇论文提出了一种自监督学习系统，用于编辑视觉程序（visual programs）。系统中的编辑网络（edit network）接收输入程序和视觉目标，并预测本地编辑操作以提升程序与目标的相似度；同时，通过引导式微调循环（bootstrapped finetuning loop）将编辑网络与一次性程序预测网络联合训练，实现更准确的程序推断。实验在多个领域表明，与仅使用一次性模型相比，这种基于编辑的范式在相同搜索时间预算下提供了显著优势。",
      "categories": [
        "cs.CV",
        "cs.AI",
        "cs.GR",
        "cs.LG"
      ],
      "primary_category": "cs.CV",
      "comment": "Neurips 2024",
      "pdf_url": "http://arxiv.org/pdf/2406.02383v2",
      "published_date": "2024-06-04 14:59:38 UTC",
      "updated_date": "2024-11-02 01:46:08 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-18T15:59:32.755864"
    },
    {
      "arxiv_id": "2406.02381v2",
      "title": "Kirigami: large convolutional kernels improve deep learning-based RNA secondary structure prediction",
      "title_zh": "翻译失败",
      "authors": [
        "Marc Harary",
        "Chengxin Zhang"
      ],
      "abstract": "We introduce a novel fully convolutional neural network (FCN) architecture\nfor predicting the secondary structure of ribonucleic acid (RNA) molecules.\nInterpreting RNA structures as weighted graphs, we employ deep learning to\nestimate the probability of base pairing between nucleotide residues. Unique to\nour model are its massive 11-pixel kernels, which we argue provide a distinct\nadvantage for FCNs on the specialized domain of RNA secondary structures. On a\nwidely adopted, standardized test set comprised of 1,305 molecules, the\naccuracy of our method exceeds that of current state-of-the-art (SOTA)\nsecondary structure prediction software, achieving a Matthews Correlation\nCoefficient (MCC) over 11-40% higher than that of other leading methods on\noverall structures and 58-400% higher on pseudoknots specifically.",
      "tldr_zh": "本研究引入了Kirigami，一种新型的全卷积神经网络(FCN)架构，用于提升基于深度学习的RNA二级结构预测性能。Kirigami将RNA结构解释为加权图，并采用巨大的11像素内核来估计核苷酸残基之间的配对概率，这在RNA领域提供了显著优势。在一个包含1,305分子的标准测试集上，该方法超过了现有最先进软件，Matthews Correlation Coefficient (MCC)整体提高了11-40%，而对pseudoknots的预测准确性则提高了58-400%。",
      "categories": [
        "q-bio.BM",
        "cs.AI"
      ],
      "primary_category": "q-bio.BM",
      "comment": "-Updated authorship and acknowledgements",
      "pdf_url": "http://arxiv.org/pdf/2406.02381v2",
      "published_date": "2024-06-04 14:58:10 UTC",
      "updated_date": "2024-06-06 14:04:32 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-18T15:59:34.571788"
    },
    {
      "arxiv_id": "2406.02377v2",
      "title": "XRec: Large Language Models for Explainable Recommendation",
      "title_zh": "XRec：大型语言模型用于可解释推荐",
      "authors": [
        "Qiyao Ma",
        "Xubin Ren",
        "Chao Huang"
      ],
      "abstract": "Recommender systems help users navigate information overload by providing\npersonalized recommendations aligned with their preferences. Collaborative\nFiltering (CF) is a widely adopted approach, but while advanced techniques like\ngraph neural networks (GNNs) and self-supervised learning (SSL) have enhanced\nCF models for better user representations, they often lack the ability to\nprovide explanations for the recommended items. Explainable recommendations aim\nto address this gap by offering transparency and insights into the\nrecommendation decision-making process, enhancing users' understanding. This\nwork leverages the language capabilities of Large Language Models (LLMs) to\npush the boundaries of explainable recommender systems. We introduce a\nmodel-agnostic framework called XRec, which enables LLMs to provide\ncomprehensive explanations for user behaviors in recommender systems. By\nintegrating collaborative signals and designing a lightweight collaborative\nadaptor, the framework empowers LLMs to understand complex patterns in\nuser-item interactions and gain a deeper understanding of user preferences. Our\nextensive experiments demonstrate the effectiveness of XRec, showcasing its\nability to generate comprehensive and meaningful explanations that outperform\nbaseline approaches in explainable recommender systems. We open-source our\nmodel implementation at https://github.com/HKUDS/XRec.",
      "tldr_zh": "本研究针对推荐系统（如Collaborative Filtering, CF）在提供个性化推荐的同时缺乏解释性的问题，提出了一种模型无关框架XRec，利用Large Language Models (LLMs)生成全面的用户行为解释。通过整合协作信号（collaborative signals）和设计轻量级协作适配器，XRec使LLMs能够更好地理解用户-物品互动模式和偏好。实验结果表明，XRec生成的解释在全面性和意义性上优于基线方法，并已开源实现（https://github.com/HKUDS/XRec）。",
      "categories": [
        "cs.IR",
        "cs.AI",
        "cs.CL"
      ],
      "primary_category": "cs.IR",
      "comment": "Accepted to EMNLP 2024 Findings",
      "pdf_url": "http://arxiv.org/pdf/2406.02377v2",
      "published_date": "2024-06-04 14:55:14 UTC",
      "updated_date": "2024-09-22 14:50:52 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-18T15:59:46.308986"
    },
    {
      "arxiv_id": "2406.02366v3",
      "title": "Finding NeMo: Localizing Neurons Responsible For Memorization in Diffusion Models",
      "title_zh": "翻译失败",
      "authors": [
        "Dominik Hintersdorf",
        "Lukas Struppek",
        "Kristian Kersting",
        "Adam Dziedzic",
        "Franziska Boenisch"
      ],
      "abstract": "Diffusion models (DMs) produce very detailed and high-quality images. Their\npower results from extensive training on large amounts of data, usually scraped\nfrom the internet without proper attribution or consent from content creators.\nUnfortunately, this practice raises privacy and intellectual property concerns,\nas DMs can memorize and later reproduce their potentially sensitive or\ncopyrighted training images at inference time. Prior efforts prevent this issue\nby either changing the input to the diffusion process, thereby preventing the\nDM from generating memorized samples during inference, or removing the\nmemorized data from training altogether. While those are viable solutions when\nthe DM is developed and deployed in a secure and constantly monitored\nenvironment, they hold the risk of adversaries circumventing the safeguards and\nare not effective when the DM itself is publicly released. To solve the\nproblem, we introduce NeMo, the first method to localize memorization of\nindividual data samples down to the level of neurons in DMs' cross-attention\nlayers. Through our experiments, we make the intriguing finding that in many\ncases, single neurons are responsible for memorizing particular training\nsamples. By deactivating these memorization neurons, we can avoid the\nreplication of training data at inference time, increase the diversity in the\ngenerated outputs, and mitigate the leakage of private and copyrighted data. In\nthis way, our NeMo contributes to a more responsible deployment of DMs.",
      "tldr_zh": "这篇论文针对 Diffusion Models (DMs) 在训练过程中记忆训练数据的隐私和知识产权问题，引入了 NeMo 方法，这是首个将记忆本地化到 DMs 的 cross-attention layers 中的神经元级别。研究发现，在许多情况下，单个神经元负责记忆特定训练样本。通过关闭这些“记忆神经元”，可以有效防止推理时复制训练数据，同时提高生成输出的多样性和减少隐私泄露。该方法为更负责任地部署 DMs 提供了重要途径。",
      "categories": [
        "cs.LG",
        "cs.AI"
      ],
      "primary_category": "cs.LG",
      "comment": "Published as a conference paper at NeurIPS 2024",
      "pdf_url": "http://arxiv.org/pdf/2406.02366v3",
      "published_date": "2024-06-04 14:45:47 UTC",
      "updated_date": "2024-11-04 06:52:09 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-18T16:00:08.189978"
    },
    {
      "arxiv_id": "2406.02362v3",
      "title": "Temporal Graph Rewiring with Expander Graphs",
      "title_zh": "基于扩展",
      "authors": [
        "Katarina Petrović",
        "Shenyang Huang",
        "Farimah Poursafaei",
        "Petar Veličković"
      ],
      "abstract": "Evolving relations in real-world networks are often modelled by temporal\ngraphs. Temporal Graph Neural Networks (TGNNs) emerged to model evolutionary\nbehaviour of such graphs by leveraging the message passing primitive at the\ncore of Graph Neural Networks (GNNs). It is well-known that GNNs are vulnerable\nto several issues directly related to the input graph topology, such as\nunder-reaching and over-squashing - we argue that these issues can often get\nexacerbated in temporal graphs, particularly as the result of stale nodes and\nedges. While graph rewiring techniques have seen frequent usage in GNNs to make\nthe graph topology more favourable for message passing, they have not seen any\nmainstream usage on TGNNs. In this work, we propose Temporal Graph Rewiring\n(TGR), the first approach for graph rewiring on temporal graphs, to the best of\nour knowledge. TGR constructs message passing highways between temporally\ndistant nodes in a continuous-time dynamic graph by utilizing expander graph\npropagation, a prominent framework used for graph rewiring on static graphs\nwhich makes minimal assumptions on the underlying graph structure. On the\nchallenging TGB benchmark, TGR achieves state-of-the-art results on\ntgbl-review, tgbl-coin, tgbl-comment and tgbl-flight datasets at the time of\nwriting. For tgbl-review, TGR has 50.5% improvement in MRR over the base TGN\nmodel and 22.2% improvement over the base TNCN model. The significant\nimprovement over base models demonstrates clear benefits of temporal graph\nrewiring.",
      "tldr_zh": "本研究针对时间图（temporal graphs）中存在的拓扑问题，如 under-reaching 和 over-squashing，提出了一种新的 Temporal Graph Rewiring (TGR) 方法，以改善 Temporal Graph Neural Networks (TGNNs) 的消息传递效率。TGR 通过利用 expander graph propagation 在连续时间动态图中为时间上遥远的节点构建消息传递路径，从而缓解过时节点和边的负面影响。在 TGB 基准测试中，TGR 在 tgbl-review、tgbl-coin、tgbl-comment 和 tgbl-flight 数据集上实现了最先进的结果，例如在 tgbl-review 上，比基线 TGN 模型的 MRR 提高了 50.5%，比 TNCN 模型提高了 22.2%。这项工作证明了时间图重连的显著益处，为处理演化网络提供了新途径。",
      "categories": [
        "cs.LG",
        "cs.AI",
        "cs.SI",
        "stat.ML"
      ],
      "primary_category": "cs.LG",
      "comment": "14 pages, 2 figures",
      "pdf_url": "http://arxiv.org/pdf/2406.02362v3",
      "published_date": "2024-06-04 14:39:51 UTC",
      "updated_date": "2024-10-22 13:43:01 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-18T16:00:12.561614"
    },
    {
      "arxiv_id": "2406.02357v1",
      "title": "The complexity of approximate (coarse) correlated equilibrium for incomplete information games",
      "title_zh": "不完备信息游戏中近似（粗糙）相关均衡的复杂度",
      "authors": [
        "Binghui Peng",
        "Aviad Rubinstein"
      ],
      "abstract": "We study the iteration complexity of decentralized learning of approximate\ncorrelated equilibria in incomplete information games.\n  On the negative side, we prove that in $\\mathit{extensive}$-$\\mathit{form}$\n$\\mathit{games}$, assuming $\\mathsf{PPAD} \\not\\subset\n\\mathsf{TIME}(n^{\\mathsf{polylog}(n)})$, any polynomial-time learning\nalgorithms must take at least $2^{\\log_2^{1-o(1)}(|\\mathcal{I}|)}$ iterations\nto converge to the set of $\\epsilon$-approximate correlated equilibrium, where\n$|\\mathcal{I}|$ is the number of nodes in the game and $\\epsilon > 0$ is an\nabsolute constant. This nearly matches, up to the $o(1)$ term, the algorithms\nof [PR'24, DDFG'24] for learning $\\epsilon$-approximate correlated equilibrium,\nand resolves an open question of Anagnostides, Kalavasis, Sandholm, and\nZampetakis [AKSZ'24]. Our lower bound holds even for the easier solution\nconcept of $\\epsilon$-approximate $\\mathit{coarse}$ correlated equilibrium\n  On the positive side, we give uncoupled dynamics that reach\n$\\epsilon$-approximate correlated equilibria of a $\\mathit{Bayesian}$\n$\\mathit{game}$ in polylogarithmic iterations, without any dependence of the\nnumber of types. This demonstrates a separation between Bayesian games and\nextensive-form games.",
      "tldr_zh": "本研究探讨了在不完全信息游戏中学习近似（粗糙）相关均衡的迭代复杂度。论文证明，在扩展形式游戏（extensive-form games）中，假设 \\(\\mathsf{PPAD} \\not\\subset \\mathsf{TIME}(n^{\\mathsf{polylog}(n)})\\)，任何多项式时间学习算法至少需要 \\(2^{\\log_2^{1-o(1)}|\\mathcal{I}|}\\) 迭代才能收敛到 \\(\\epsilon\\)-approximate correlated equilibrium，这几乎匹配现有算法并解决了 Anagnostides 等人的开放问题；该下界甚至适用于更简单的 \\(\\epsilon\\)-approximate coarse correlated equilibrium。另一方面，论文提出了解耦动态，能够在多项式对数迭代内达到 Bayesian games 的 \\(\\epsilon\\)-approximate correlated equilibria，而不依赖于类型数量，从而展示了 Bayesian games 与 extensive-form games 之间的复杂度分离。该工作为不完全信息游戏的均衡学习提供了重要的理论洞见。",
      "categories": [
        "cs.GT",
        "cs.AI",
        "cs.DS",
        "cs.LG"
      ],
      "primary_category": "cs.GT",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2406.02357v1",
      "published_date": "2024-06-04 14:35:27 UTC",
      "updated_date": "2024-06-04 14:35:27 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-18T16:00:22.972922"
    },
    {
      "arxiv_id": "2406.02356v1",
      "title": "Language Models Do Hard Arithmetic Tasks Easily and Hardly Do Easy Arithmetic Tasks",
      "title_zh": "语言模型轻松完成困难算术任务，却难以完成简单算术任务",
      "authors": [
        "Andrew Gambardella",
        "Yusuke Iwasawa",
        "Yutaka Matsuo"
      ],
      "abstract": "The ability (and inability) of large language models (LLMs) to perform\narithmetic tasks has been the subject of much theoretical and practical debate.\nWe show that LLMs are frequently able to correctly and confidently predict the\nfirst digit of n-digit by m-digit multiplication tasks without using chain of\nthought reasoning, despite these tasks require compounding operations to solve.\nSimultaneously, LLMs in practice often fail to correctly or confidently predict\nthe last digit of an n-digit by m-digit multiplication, a task equivalent to\n1-digit by 1-digit multiplication which can be easily learned or memorized. We\nshow that the latter task can be solved more robustly when the LLM is\nconditioned on all of the correct higher-order digits, which on average\nincreases the confidence of the correct last digit on 5-digit by 5-digit\nmultiplication tasks using Llama 2-13B by over 230% (0.13 to 0.43) and\nMistral-7B by 150% (0.22 to 0.55).",
      "tldr_zh": "本文研究发现，大语言模型(LLMs)在算术任务中表现出矛盾：它们能够轻松且自信地预测n位数乘m位数乘法的第一个数字，而无需chain of thought reasoning，尽管这些任务涉及复杂复合运算；相反，LLMs往往无法正确或自信地预测乘法的最后一个数字，这相当于简单的1位数乘1位数乘法。研究通过实验证明，当LLMs被条件化为知道所有正确的高位数字时，其性能显著提升，例如在5位数乘5位数乘法中，Llama 2-13B的正确最后一个数字信心提高了230%(从0.13到0.43)，Mistral-7B提高了150%(从0.22到0.55)。这一发现揭示了LLMs在算术推理中的局限性，并为改进其鲁棒性提供了新见解。",
      "categories": [
        "cs.LG",
        "cs.AI",
        "cs.CL"
      ],
      "primary_category": "cs.LG",
      "comment": "In Proceedings of the 62nd Annual Meeting of the Association for\n  Computational Linguistics (Volume 2: Short Papers)",
      "pdf_url": "http://arxiv.org/pdf/2406.02356v1",
      "published_date": "2024-06-04 14:34:39 UTC",
      "updated_date": "2024-06-04 14:34:39 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-18T16:00:49.978587"
    },
    {
      "arxiv_id": "2406.02355v1",
      "title": "FedDr+: Stabilizing Dot-regression with Global Feature Distillation for Federated Learning",
      "title_zh": "翻译失败",
      "authors": [
        "Seongyoon Kim",
        "Minchan Jeong",
        "Sungnyun Kim",
        "Sungwoo Cho",
        "Sumyeong Ahn",
        "Se-Young Yun"
      ],
      "abstract": "Federated Learning (FL) has emerged as a pivotal framework for the\ndevelopment of effective global models (global FL) or personalized models\n(personalized FL) across clients with heterogeneous, non-iid data distribution.\nA key challenge in FL is client drift, where data heterogeneity impedes the\naggregation of scattered knowledge. Recent studies have tackled the client\ndrift issue by identifying significant divergence in the last classifier layer.\nTo mitigate this divergence, strategies such as freezing the classifier weights\nand aligning the feature extractor accordingly have proven effective. Although\nthe local alignment between classifier and feature extractor has been studied\nas a crucial factor in FL, we observe that it may lead the model to\noveremphasize the observed classes within each client. Thus, our objectives are\ntwofold: (1) enhancing local alignment while (2) preserving the representation\nof unseen class samples. This approach aims to effectively integrate knowledge\nfrom individual clients, thereby improving performance for both global and\npersonalized FL. To achieve this, we introduce a novel algorithm named FedDr+,\nwhich empowers local model alignment using dot-regression loss. FedDr+ freezes\nthe classifier as a simplex ETF to align the features and improves aggregated\nglobal models by employing a feature distillation mechanism to retain\ninformation about unseen/missing classes. Consequently, we provide empirical\nevidence demonstrating that our algorithm surpasses existing methods that use a\nfrozen classifier to boost alignment across the diverse distribution.",
      "tldr_zh": "本文针对 Federated Learning (FL) 中的客户端漂移问题，提出 FedDr+ 算法，以解决数据异质性导致的模型对齐挑战，同时增强本地对齐并保留未见类别的表示。FedDr+ 通过 dot-regression loss 冻结分类器作为 simplex ETF 来对齐特征提取器，并引入 global feature distillation 机制，以整合散乱的客户端知识并提升模型泛化能力。实验结果表明，FedDr+ 在全球和个性化 FL 任务上超越现有方法，提高了整体性能。",
      "categories": [
        "cs.CV",
        "cs.AI",
        "cs.DC",
        "cs.LG"
      ],
      "primary_category": "cs.CV",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2406.02355v1",
      "published_date": "2024-06-04 14:34:13 UTC",
      "updated_date": "2024-06-04 14:34:13 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-18T16:00:59.683138"
    },
    {
      "arxiv_id": "2406.02350v2",
      "title": "LlamaCare: A Large Medical Language Model for Enhancing Healthcare Knowledge Sharing",
      "title_zh": "LlamaCare：一个大型医疗语言模型，用于增强医疗保健知识共享",
      "authors": [
        "Maojun Sun"
      ],
      "abstract": "Large language models (LLMs) have shown amazing capabilities in knowledge\nmemorization and the present. However, when it comes to domain-specific\nknowledge and downstream tasks like medical, general LLMs are often unable to\ngive precise answers. In addition, when people want LLMs to answer\nclassification questions, they usually go through instruction tuning first.\nHowever, LLMs do not always give a direct index of the categorization after\ninstruction tuning. In this paper, we proposed LlamaCare, a fine-tuned medical\nlanguage model, and Extended Classification Integration(ECI), a module to\nhandle classification problems of LLMs. Our contributions are : (i) We\nfine-tuned a large language model of medical knowledge with very low carbon\nemissions and achieved similar performance with ChatGPT by a 24G GPU. (ii) We\nsolved the problem of redundant categorical answers and improved the\nperformance of LLMs by proposing a new module called Extended Classification\nIntegration. (iii) We released our processed data for one-shot and few-shot\ntraining for some benchmarks such as PubMedQA and USMLE 1-3 step. Our method\nachieves a close performance comparable to some state-of-the-art models with\nthe same quantity of parameters on benchmarks, while being more environmentally\nfriendly by using less GPU computation time. Our models, codes, and datasets\ncan be found at \\url{https://github.com/Stephen-SMJ/LLamaCare}.",
      "tldr_zh": "本论文提出 LlamaCare，一种针对医疗领域的细调大型语言模型（LLMs），旨在提升医疗知识共享并解决通用 LLMs 在领域特定任务中的局限性，如精确回答和分类问题。研究团队引入了 Extended Classification Integration (ECI) 模块，以处理分类任务的冗余答案并提高模型性能，同时使用低碳排放的 24G GPU 实现了与 ChatGPT 相当的性能。贡献包括发布处理后的数据用于 one-shot 和 few-shot 训练（如 PubMedQA 和 USMLE 基准），模型在这些测试中表现接近最先进水平，但更环保，并开源了代码和数据集。",
      "categories": [
        "cs.CL",
        "cs.AI"
      ],
      "primary_category": "cs.CL",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2406.02350v2",
      "published_date": "2024-06-04 14:24:53 UTC",
      "updated_date": "2024-06-05 15:08:42 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-18T16:01:02.900992"
    },
    {
      "arxiv_id": "2406.02349v1",
      "title": "CADE: Cosine Annealing Differential Evolution for Spiking Neural Network",
      "title_zh": "翻译失败",
      "authors": [
        "Runhua Jiang",
        "Guodong Du",
        "Shuyang Yu",
        "Yifei Guo",
        "Sim Kuan Goh",
        "Ho-Kin Tang"
      ],
      "abstract": "Spiking neural networks (SNNs) have gained prominence for their potential in\nneuromorphic computing and energy-efficient artificial intelligence, yet\noptimizing them remains a formidable challenge for gradient-based methods due\nto their discrete, spike-based computation. This paper attempts to tackle the\nchallenges by introducing Cosine Annealing Differential Evolution (CADE),\ndesigned to modulate the mutation factor (F) and crossover rate (CR) of\ndifferential evolution (DE) for the SNN model, i.e., Spiking Element Wise (SEW)\nResNet. Extensive empirical evaluations were conducted to analyze CADE. CADE\nshowed a balance in exploring and exploiting the search space, resulting in\naccelerated convergence and improved accuracy compared to existing\ngradient-based and DE-based methods. Moreover, an initialization method based\non a transfer learning setting was developed, pretraining on a source dataset\n(i.e., CIFAR-10) and fine-tuning the target dataset (i.e., CIFAR-100), to\nimprove population diversity. It was found to further enhance CADE for SNN.\nRemarkably, CADE elevates the performance of the highest accuracy SEW model by\nan additional 0.52 percentage points, underscoring its effectiveness in\nfine-tuning and enhancing SNNs. These findings emphasize the pivotal role of a\nscheduler for F and CR adjustment, especially for DE-based SNN. Source Code on\nGithub: https://github.com/Tank-Jiang/CADE4SNN.",
      "tldr_zh": "本论文提出 CADE（Cosine Annealing Differential Evolution），一种优化算法，用于解决脉冲神经网络（SNN）的优化难题，通过动态调整差分进化（DE）的突变因子（F）和交叉率（CR），并应用于 SEW ResNet 模型，以实现更好的搜索空间探索和利用。\nCADE 与现有梯度-based 和 DE-based 方法相比，展示了加速收敛和提高准确率的优势，并在实验中证明其有效性。\n此外，作者引入了一种基于迁移学习的初始化方法，在 CIFAR-10 上预训练后微调 CIFAR-100，提高了种群多样性，最终使 SEW 模型的最高准确率提升了 0.52%。",
      "categories": [
        "cs.NE",
        "cs.AI",
        "cs.CV"
      ],
      "primary_category": "cs.NE",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2406.02349v1",
      "published_date": "2024-06-04 14:24:35 UTC",
      "updated_date": "2024-06-04 14:24:35 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-18T16:01:15.799851"
    },
    {
      "arxiv_id": "2406.02347v3",
      "title": "Flash Diffusion: Accelerating Any Conditional Diffusion Model for Few Steps Image Generation",
      "title_zh": "翻译失败",
      "authors": [
        "Clément Chadebec",
        "Onur Tasar",
        "Eyal Benaroche",
        "Benjamin Aubin"
      ],
      "abstract": "In this paper, we propose an efficient, fast, and versatile distillation\nmethod to accelerate the generation of pre-trained diffusion models: Flash\nDiffusion. The method reaches state-of-the-art performances in terms of FID and\nCLIP-Score for few steps image generation on the COCO2014 and COCO2017\ndatasets, while requiring only several GPU hours of training and fewer\ntrainable parameters than existing methods. In addition to its efficiency, the\nversatility of the method is also exposed across several tasks such as\ntext-to-image, inpainting, face-swapping, super-resolution and using different\nbackbones such as UNet-based denoisers (SD1.5, SDXL) or DiT (Pixart-$\\alpha$),\nas well as adapters. In all cases, the method allowed to reduce drastically the\nnumber of sampling steps while maintaining very high-quality image generation.\nThe official implementation is available at\nhttps://github.com/gojasper/flash-diffusion.",
      "tldr_zh": "本论文提出了一种高效的蒸馏方法Flash Diffusion，用于加速任意条件扩散模型的图像生成过程，仅需少量采样步骤。该方法在COCO2014和COCO2017数据集上实现了最先进的FID和CLIP-Score性能，同时仅需几个GPU小时的训练和较少的可训练参数。Flash Diffusion的多功能性使其适用于多种任务，如文本到图像、修复、面部交换和超分辨率，并兼容不同骨干网络（如UNet-based denoisers的SD1.5和SDXL，或DiT的Pixart-α）及适配器，在所有场景下显著减少采样步骤的同时保持高质量图像生成。",
      "categories": [
        "cs.CV",
        "cs.AI",
        "cs.LG"
      ],
      "primary_category": "cs.CV",
      "comment": "Accepted to AAAI 2025",
      "pdf_url": "http://arxiv.org/pdf/2406.02347v3",
      "published_date": "2024-06-04 14:23:27 UTC",
      "updated_date": "2024-12-18 10:45:06 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-18T16:01:24.925423"
    },
    {
      "arxiv_id": "2406.02345v2",
      "title": "Progressive Confident Masking Attention Network for Audio-Visual Segmentation",
      "title_zh": "翻译失败",
      "authors": [
        "Yuxuan Wang",
        "Jinchao Zhu",
        "Feng Dong",
        "Shuyue Zhu"
      ],
      "abstract": "Audio and visual signals typically occur simultaneously, and humans possess\nan innate ability to correlate and synchronize information from these two\nmodalities. Recently, a challenging problem known as Audio-Visual Segmentation\n(AVS) has emerged, intending to produce segmentation maps for sounding objects\nwithin a scene. However, the methods proposed so far have not sufficiently\nintegrated audio and visual information, and the computational costs have been\nextremely high. Additionally, the outputs of different stages have not been\nfully utilized. To facilitate this research, we introduce a novel Progressive\nConfident Masking Attention Network (PMCANet). It leverages attention\nmechanisms to uncover the intrinsic correlations between audio signals and\nvisual frames. Furthermore, we design an efficient and effective\ncross-attention module to enhance semantic perception by selecting query\ntokens. This selection is determined through confidence-driven units based on\nthe network's multi-stage predictive outputs. Experiments demonstrate that our\nnetwork outperforms other AVS methods while requiring less computational\nresources. The code is available at: https://github.com/PrettyPlate/PCMANet.",
      "tldr_zh": "本研究针对 Audio-Visual Segmentation (AVS) 任务，提出了一种创新的 Progressive Confident Masking Attention Network (PMCANet)，旨在更好地整合音频和视觉信息，同时降低计算成本。PMCANet 通过 attention mechanisms 揭示音频信号与视觉帧的内在相关性，并设计了一个高效的 cross-attention module，利用基于网络多阶段预测输出的 confidence-driven units 来选择查询 tokens，从而增强语义感知。实验结果显示，该网络在 AVS 任务中优于现有方法，同时需要更少的计算资源，代码已在 GitHub 上公开。",
      "categories": [
        "cs.CV",
        "cs.AI",
        "cs.LG",
        "cs.MM"
      ],
      "primary_category": "cs.CV",
      "comment": "23 pages, 11 figures, submitted to Elsevier Knowledge-Based System",
      "pdf_url": "http://arxiv.org/pdf/2406.02345v2",
      "published_date": "2024-06-04 14:21:41 UTC",
      "updated_date": "2025-02-10 06:05:46 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-18T16:01:35.732297"
    },
    {
      "arxiv_id": "2406.02648v1",
      "title": "Exploring Effects of Hyperdimensional Vectors for Tsetlin Machines",
      "title_zh": "翻译失败",
      "authors": [
        "Vojtech Halenka",
        "Ahmed K. Kadhim",
        "Paul F. A. Clarke",
        "Bimal Bhattarai",
        "Rupsa Saha",
        "Ole-Christoffer Granmo",
        "Lei Jiao",
        "Per-Arne Andersen"
      ],
      "abstract": "Tsetlin machines (TMs) have been successful in several application domains,\noperating with high efficiency on Boolean representations of the input data.\nHowever, Booleanizing complex data structures such as sequences, graphs,\nimages, signal spectra, chemical compounds, and natural language is not\ntrivial. In this paper, we propose a hypervector (HV) based method for\nexpressing arbitrarily large sets of concepts associated with any input data.\nUsing a hyperdimensional space to build vectors drastically expands the\ncapacity and flexibility of the TM. We demonstrate how images, chemical\ncompounds, and natural language text are encoded according to the proposed\nmethod, and how the resulting HV-powered TM can achieve significantly higher\naccuracy and faster learning on well-known benchmarks. Our results open up a\nnew research direction for TMs, namely how to expand and exploit the benefits\nof operating in hyperspace, including new booleanization strategies,\noptimization of TM inference and learning, as well as new TM applications.",
      "tldr_zh": "本研究探讨了在Tsetlin Machines (TMs)中使用Hyperdimensional Vectors (HVs)的方法，以解决TMs在处理复杂数据结构（如序列、图、图像和自然语言）时的布尔化挑战。研究提出了一种基于HV的编码策略，将任意大的概念集映射到超维空间，从而显著提升TMs的容量和灵活性。实验结果显示，该方法在图像、化学化合物和自然语言文本的基准测试中，使HV增强的TMs实现了更高的准确率和更快的学习速度。该工作开辟了TMs在新布尔化策略、推理优化以及超空间应用的新研究方向。",
      "categories": [
        "cs.LG",
        "cs.AI"
      ],
      "primary_category": "cs.LG",
      "comment": "9 pages, 17 figures",
      "pdf_url": "http://arxiv.org/pdf/2406.02648v1",
      "published_date": "2024-06-04 14:16:52 UTC",
      "updated_date": "2024-06-04 14:16:52 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-18T16:01:47.742799"
    },
    {
      "arxiv_id": "2406.02338v1",
      "title": "Linguistic Fingerprint in Transformer Models: How Language Variation Influences Parameter Selection in Irony Detection",
      "title_zh": "翻译失败",
      "authors": [
        "Michele Mastromattei",
        "Fabio Massimo Zanzotto"
      ],
      "abstract": "This paper explores the correlation between linguistic diversity, sentiment\nanalysis and transformer model architectures. We aim to investigate how\ndifferent English variations impact transformer-based models for irony\ndetection. To conduct our study, we used the EPIC corpus to extract five\ndiverse English variation-specific datasets and applied the KEN pruning\nalgorithm on five different architectures. Our results reveal several\nsimilarities between optimal subnetworks, which provide insights into the\nlinguistic variations that share strong resemblances and those that exhibit\ngreater dissimilarities. We discovered that optimal subnetworks across models\nshare at least 60% of their parameters, emphasizing the significance of\nparameter values in capturing and interpreting linguistic variations. This\nstudy highlights the inherent structural similarities between models trained on\ndifferent variants of the same language and also the critical role of parameter\nvalues in capturing these nuances.",
      "tldr_zh": "这篇论文探讨了语言多样性如何影响 Transformer 模型在 irony detection 中的参数选择，特别关注不同英语变体的影响。研究者使用 EPIC corpus 提取五个英语变体特定数据集，并应用 KEN pruning 算法到五个不同架构上进行分析。结果显示，最优子网络之间至少共享 60% 的参数，揭示了某些语言变体间的相似性以及差异性。总体上，这强调了参数值在捕捉和解释语言细微差别中的关键作用。",
      "categories": [
        "cs.CL",
        "cs.AI"
      ],
      "primary_category": "cs.CL",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2406.02338v1",
      "published_date": "2024-06-04 14:09:36 UTC",
      "updated_date": "2024-06-04 14:09:36 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-18T16:02:01.282000"
    },
    {
      "arxiv_id": "2406.06580v1",
      "title": "Break the Chain: Large Language Models Can be Shortcut Reasoners",
      "title_zh": "打破链条：大型语言模型可以是捷径推理者",
      "authors": [
        "Mengru Ding",
        "Hanmeng Liu",
        "Zhizhang Fu",
        "Jian Song",
        "Wenbo Xie",
        "Yue Zhang"
      ],
      "abstract": "Recent advancements in Chain-of-Thought (CoT) reasoning utilize complex\nmodules but are hampered by high token consumption, limited applicability, and\nchallenges in reproducibility. This paper conducts a critical evaluation of CoT\nprompting, extending beyond arithmetic to include complex logical and\ncommonsense reasoning tasks, areas where standard CoT methods fall short. We\npropose the integration of human-like heuristics and shortcuts into language\nmodels (LMs) through \"break the chain\" strategies. These strategies disrupt\ntraditional CoT processes using controlled variables to assess their efficacy.\nAdditionally, we develop innovative zero-shot prompting strategies that\nencourage the use of shortcuts, enabling LMs to quickly exploit reasoning clues\nand bypass detailed procedural steps. Our comprehensive experiments across\nvarious LMs, both commercial and open-source, reveal that LMs maintain\neffective performance with \"break the chain\" strategies. We also introduce\nShortcutQA, a dataset specifically designed to evaluate reasoning through\nshortcuts, compiled from competitive tests optimized for heuristic reasoning\ntasks such as forward/backward reasoning and simplification. Our analysis\nconfirms that ShortcutQA not only poses a robust challenge to LMs but also\nserves as an essential benchmark for enhancing reasoning efficiency in AI.",
      "tldr_zh": "本论文评估了 Chain-of-Thought (CoT) 推理的局限性，如高 token 消耗和适用性问题，并扩展其评估到复杂逻辑和常识推理任务。作者提出 \"break the chain\" 策略，通过整合人类启发式捷径和创新的 zero-shot prompting 方法，允许 Large Language Models (LMs) 快速利用推理线索而非详细步骤。实验结果显示，这种策略在各种商业和开源 LMs 上维持了有效性能，并引入 ShortcutQA 数据集作为评估捷径推理的基准，进一步提升 AI 的推理效率。",
      "categories": [
        "cs.CL",
        "cs.AI"
      ],
      "primary_category": "cs.CL",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2406.06580v1",
      "published_date": "2024-06-04 14:02:53 UTC",
      "updated_date": "2024-06-04 14:02:53 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-18T16:02:15.319440"
    },
    {
      "arxiv_id": "2406.02333v1",
      "title": "Towards Neural Architecture Search for Transfer Learning in 6G Networks",
      "title_zh": "翻译失败",
      "authors": [
        "Adam Orucu",
        "Farnaz Moradi",
        "Masoumeh Ebrahimi",
        "Andreas Johnsson"
      ],
      "abstract": "The future 6G network is envisioned to be AI-native, and as such, ML models\nwill be pervasive in support of optimizing performance, reducing energy\nconsumption, and in coping with increasing complexity and heterogeneity. A key\nchallenge is automating the process of finding optimal model architectures\nsatisfying stringent requirements stemming from varying tasks, dynamicity and\navailable resources in the infrastructure and deployment positions. In this\npaper, we describe and review the state-of-the-art in Neural Architecture\nSearch and Transfer Learning and their applicability in networking. Further, we\nidentify open research challenges and set directions with a specific focus on\nthree main requirements with elements unique to the future network, namely\ncombining NAS and TL, multi-objective search, and tabular data. Finally, we\noutline and discuss both near-term and long-term work ahead.",
      "tldr_zh": "本论文探讨了在6G网络中应用Neural Architecture Search (NAS)来优化Transfer Learning (TL)，以应对AI原生网络的复杂性、异构性和资源限制。作者回顾了NAS和TL的最新进展及其在网络领域的适用性，并识别了关键挑战，包括结合NAS和TL、多目标搜索以及处理tabular data。论文针对6G的独特需求设置了研究方向，并概述了短期和长期工作，以自动化模型架构设计并提升网络性能和能效。",
      "categories": [
        "cs.NI",
        "cs.AI",
        "cs.LG"
      ],
      "primary_category": "cs.NI",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2406.02333v1",
      "published_date": "2024-06-04 14:01:03 UTC",
      "updated_date": "2024-06-04 14:01:03 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-18T16:02:24.646102"
    },
    {
      "arxiv_id": "2406.02325v1",
      "title": "Technical Language Processing for Telecommunications Specifications",
      "title_zh": "针对电信规范的技术语言处理",
      "authors": [
        "Felipe A. Rodriguez Y."
      ],
      "abstract": "Large Language Models (LLMs) are continuously being applied in a more diverse\nset of contexts. At their current state, however, even state-of-the-art LLMs\nsuch as Generative Pre-Trained Transformer 4 (GTP-4) have challenges when\nextracting information from real-world technical documentation without a heavy\npreprocessing. One such area with real-world technical documentation is\ntelecommunications engineering, which could greatly benefit from\ndomain-specific LLMs. The unique format and overall structure of\ntelecommunications internal specifications differs greatly from standard\nEnglish and thus it is evident that the application of out-of-the-box Natural\nLanguage Processing (NLP) tools is not a viable option. In this article, we\noutline the limitations of out-of-the-box NLP tools for processing technical\ninformation generated by telecommunications experts, and expand the concept of\nTechnical Language Processing (TLP) to the telecommunication domain.\nAdditionally, we explore the effect of domain-specific LLMs in the work of\nSpecification Engineers, emphasizing the potential benefits of adopting\ndomain-specific LLMs to speed up the training of experts in different\ntelecommunications fields.",
      "tldr_zh": "该论文探讨了大型语言模型（LLMs）如 GPT-4 在处理电信工程技术文档时的挑战，这些文档的独特格式与标准英语不同，导致现成 Natural Language Processing (NLP) 工具无法有效提取信息。论文扩展了 Technical Language Processing (TLP) 概念，应用于电信领域，以解决这些局限性。研究强调，采用领域特定 LLMs 可以加速规范工程师的培训，并提升电信专家在不同领域的效率和生产力。",
      "categories": [
        "cs.CL",
        "cs.AI"
      ],
      "primary_category": "cs.CL",
      "comment": "Still not published",
      "pdf_url": "http://arxiv.org/pdf/2406.02325v1",
      "published_date": "2024-06-04 13:57:22 UTC",
      "updated_date": "2024-06-04 13:57:22 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-18T16:02:38.753666"
    },
    {
      "arxiv_id": "2406.06579v3",
      "title": "From Redundancy to Relevance: Information Flow in LVLMs Across Reasoning Tasks",
      "title_zh": "翻译失败",
      "authors": [
        "Xiaofeng Zhang",
        "Yihao Quan",
        "Chen Shen",
        "Xiaosong Yuan",
        "Shaotian Yan",
        "Liang Xie",
        "Wenxiao Wang",
        "Chaochen Gu",
        "Hao Tang",
        "Jieping Ye"
      ],
      "abstract": "Large Vision Language Models (LVLMs) achieve great performance on\nvisual-language reasoning tasks, however, the black-box nature of LVLMs hinders\nin-depth research on the reasoning mechanism. As all images need to be\nconverted into image tokens to fit the input format of large language models\n(LLMs) along with natural language prompts, sequential visual representation is\nessential to the performance of LVLMs, and the information flow analysis\napproach can be an effective tool for determining interactions between these\nrepresentations. In this paper, we propose integrating attention analysis with\nLLaVA-CAM, concretely, attention scores highlight relevant regions during\nforward propagation, while LLaVA-CAM captures gradient changes through backward\npropagation, revealing key image features. By exploring the information flow\nfrom the perspective of visual representation contribution, we observe that it\ntends to converge in shallow layers but diversify in deeper layers. To validate\nour analysis, we conduct comprehensive experiments with truncation strategies\nacross various LVLMs for visual question answering and image captioning tasks,\nand experimental results not only verify our hypothesis but also reveal a\nconsistent pattern of information flow convergence in the corresponding layers,\nand the information flow cliff layer will be different due to different\ncontexts. The paper's source code can be accessed from\n\\url{https://github.com/zhangbaijin/From-Redundancy-to-Relevance}",
      "tldr_zh": "这篇论文探讨了 Large Vision Language Models (LVLMs) 在视觉语言推理任务中的信息流机制，提出整合 attention analysis 和 LLaVA-CAM 的方法，通过前向传播突出相关图像区域并后向传播捕获梯度变化，以分析视觉表示的贡献。研究发现，信息流在浅层趋于收敛而在深层趋于多样化，并通过在视觉问答和图像描述任务上的实验验证了这一假设。实验结果还显示，不同上下文会导致信息流悬崖层出现差异，为理解 LVLMs 的推理过程提供了新洞见。",
      "categories": [
        "cs.CL",
        "cs.AI",
        "cs.CV"
      ],
      "primary_category": "cs.CL",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2406.06579v3",
      "published_date": "2024-06-04 13:52:54 UTC",
      "updated_date": "2024-10-17 01:17:25 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-18T16:02:51.592685"
    },
    {
      "arxiv_id": "2406.02322v1",
      "title": "A Survey of Transformer Enabled Time Series Synthesis",
      "title_zh": "翻译失败",
      "authors": [
        "Alexander Sommers",
        "Logan Cummins",
        "Sudip Mittal",
        "Shahram Rahimi",
        "Maria Seale",
        "Joseph Jaboure",
        "Thomas Arnold"
      ],
      "abstract": "Generative AI has received much attention in the image and language domains,\nwith the transformer neural network continuing to dominate the state of the\nart. Application of these models to time series generation is less explored,\nhowever, and is of great utility to machine learning, privacy preservation, and\nexplainability research. The present survey identifies this gap at the\nintersection of the transformer, generative AI, and time series data, and\nreviews works in this sparsely populated subdomain. The reviewed works show\ngreat variety in approach, and have not yet converged on a conclusive answer to\nthe problems the domain poses. GANs, diffusion models, state space models, and\nautoencoders were all encountered alongside or surrounding the transformers\nwhich originally motivated the survey. While too open a domain to offer\nconclusive insights, the works surveyed are quite suggestive, and several\nrecommendations for best practice, and suggestions of valuable future work, are\nprovided.",
      "tldr_zh": "这篇调查论文探讨了Transformer在时间序列合成中的应用，强调生成式AI在图像和语言领域的主导地位，但对时间序列生成的研究相对较少。论文审查了现有作品，发现这些方法多样，包括GANs、diffusion models、state space models和autoencoders等，但尚未形成统一结论。总体而言，该领域仍开放，论文提供了最佳实践推荐和未来研究方向的建议。",
      "categories": [
        "cs.LG",
        "cs.AI"
      ],
      "primary_category": "cs.LG",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2406.02322v1",
      "published_date": "2024-06-04 13:52:42 UTC",
      "updated_date": "2024-06-04 13:52:42 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-18T16:03:01.795214"
    },
    {
      "arxiv_id": "2406.02317v1",
      "title": "Generative Conditional Distributions by Neural (Entropic) Optimal Transport",
      "title_zh": "翻译失败",
      "authors": [
        "Bao Nguyen",
        "Binh Nguyen",
        "Hieu Trung Nguyen",
        "Viet Anh Nguyen"
      ],
      "abstract": "Learning conditional distributions is challenging because the desired outcome\nis not a single distribution but multiple distributions that correspond to\nmultiple instances of the covariates. We introduce a novel neural entropic\noptimal transport method designed to effectively learn generative models of\nconditional distributions, particularly in scenarios characterized by limited\nsample sizes. Our method relies on the minimax training of two neural networks:\na generative network parametrizing the inverse cumulative distribution\nfunctions of the conditional distributions and another network parametrizing\nthe conditional Kantorovich potential. To prevent overfitting, we regularize\nthe objective function by penalizing the Lipschitz constant of the network\noutput. Our experiments on real-world datasets show the effectiveness of our\nalgorithm compared to state-of-the-art conditional distribution learning\ntechniques. Our implementation can be found at\nhttps://github.com/nguyenngocbaocmt02/GENTLE.",
      "tldr_zh": "该论文提出了一种基于Neural (Entropic) Optimal Transport的神经方法，用于有效学习条件分布，尤其适用于样本量有限的场景。该方法通过minimax训练两个神经网络：一个参数化条件分布的逆累积分布函数，另一个参数化条件Kantorovich potential，以生成条件分布模型。为防止过拟合，该方法通过惩罚网络输出的Lipschitz constant来正则化目标函数。实验在真实数据集上证明，该算法比现有条件分布学习技术更有效，并提供了开源实现（https://github.com/nguyenngocbaocmt02/GENTLE）。",
      "categories": [
        "cs.LG",
        "cs.AI",
        "stat.ML"
      ],
      "primary_category": "cs.LG",
      "comment": "15 pages, 8 figures",
      "pdf_url": "http://arxiv.org/pdf/2406.02317v1",
      "published_date": "2024-06-04 13:45:35 UTC",
      "updated_date": "2024-06-04 13:45:35 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-18T16:03:15.236780"
    },
    {
      "arxiv_id": "2406.02315v2",
      "title": "An Independence-promoting Loss for Music Generation with Language Models",
      "title_zh": "翻译失败",
      "authors": [
        "Jean-Marie Lemercier",
        "Simon Rouard",
        "Jade Copet",
        "Yossi Adi",
        "Alexandre Défossez"
      ],
      "abstract": "Music generation schemes using language modeling rely on a vocabulary of\naudio tokens, generally provided as codes in a discrete latent space learnt by\nan auto-encoder. Multi-stage quantizers are often employed to produce these\ntokens, therefore the decoding strategy used for token prediction must be\nadapted to account for multiple codebooks: either it should model the joint\ndistribution over all codebooks, or fit the product of the codebook marginal\ndistributions. Modelling the joint distribution requires a costly increase in\nthe number of auto-regressive steps, while fitting the product of the marginals\nyields an inexact model unless the codebooks are mutually independent. In this\nwork, we introduce an independence-promoting loss to regularize the\nauto-encoder used as the tokenizer in language models for music generation. The\nproposed loss is a proxy for mutual information based on the maximum mean\ndiscrepancy principle, applied in reproducible kernel Hilbert spaces. Our\ncriterion is simple to implement and train, and it is generalizable to other\nmulti-stream codecs. We show that it reduces the statistical dependence between\ncodebooks during auto-encoding. This leads to an increase in the generated\nmusic quality when modelling the product of the marginal distributions, while\ngenerating audio much faster than the joint distribution model.",
      "tldr_zh": "本研究针对使用语言模型进行音乐生成的挑战，提出了一种independence-promoting loss，以减少多阶段量化器中codebooks之间的统计依赖性。该损失函数基于maximum mean discrepancy原理，作为mutual information的代理，用于正则化auto-encoder的tokenizer，使codebooks更趋向独立。实验结果显示，该方法在拟合codebook边际分布乘积时显著提高了生成音乐的质量，同时比建模联合分布更快，实现了高效的音频生成。",
      "categories": [
        "cs.SD",
        "cs.AI",
        "cs.LG",
        "eess.AS"
      ],
      "primary_category": "cs.SD",
      "comment": "Accepted to ICML 2024",
      "pdf_url": "http://arxiv.org/pdf/2406.02315v2",
      "published_date": "2024-06-04 13:44:39 UTC",
      "updated_date": "2024-06-09 17:55:51 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-18T16:03:26.295251"
    },
    {
      "arxiv_id": "2406.06578v1",
      "title": "SMS Spam Detection and Classification to Combat Abuse in Telephone Networks Using Natural Language Processing",
      "title_zh": "翻译失败",
      "authors": [
        "Dare Azeez Oyeyemi",
        "Adebola K. Ojo"
      ],
      "abstract": "In the modern era, mobile phones have become ubiquitous, and Short Message\nService (SMS) has grown to become a multi-million-dollar service due to the\nwidespread adoption of mobile devices and the millions of people who use SMS\ndaily. However, SMS spam has also become a pervasive problem that endangers\nusers' privacy and security through phishing and fraud. Despite numerous spam\nfiltering techniques, there is still a need for a more effective solution to\naddress this problem [1]. This research addresses the pervasive issue of SMS\nspam, which poses threats to users' privacy and security. Despite existing spam\nfiltering techniques, the high false-positive rate persists as a challenge. The\nstudy introduces a novel approach utilizing Natural Language Processing (NLP)\nand machine learning models, particularly BERT (Bidirectional Encoder\nRepresentations from Transformers), for SMS spam detection and classification.\nData preprocessing techniques, such as stop word removal and tokenization, are\napplied, along with feature extraction using BERT. Machine learning models,\nincluding SVM, Logistic Regression, Naive Bayes, Gradient Boosting, and Random\nForest, are integrated with BERT for differentiating spam from ham messages.\nEvaluation results revealed that the Na\\\"ive Bayes classifier + BERT model\nachieves the highest accuracy at 97.31% with the fastest execution time of 0.3\nseconds on the test dataset. This approach demonstrates a notable enhancement\nin spam detection efficiency and a low false-positive rate. The developed model\npresents a valuable solution to combat SMS spam, ensuring faster and more\naccurate detection. This model not only safeguards users' privacy but also\nassists network providers in effectively identifying and blocking SMS spam\nmessages.",
      "tldr_zh": "这篇论文针对SMS垃圾短信对用户隐私和安全的威胁，提出了一种基于Natural Language Processing (NLP)的新方法来检测和分类垃圾短信，以解决现有技术的假阳性率高问题。研究采用数据预处理（如stop word removal和tokenization）、BERT特征提取，并整合多种机器学习模型，包括SVM、Logistic Regression、Naive Bayes、Gradient Boosting和Random Forest。结果表明，Naive Bayes + BERT模型在测试数据集上实现了97.31%的最高准确率，并以0.3秒的执行时间显著提升了检测效率和降低了假阳性率。该方法为保护用户隐私和帮助网络提供商有效阻挡垃圾短信提供了宝贵解决方案。",
      "categories": [
        "cs.CL",
        "cs.AI",
        "cs.LG"
      ],
      "primary_category": "cs.CL",
      "comment": "13 pages, 8 figures, 3 tables",
      "pdf_url": "http://arxiv.org/pdf/2406.06578v1",
      "published_date": "2024-06-04 13:44:36 UTC",
      "updated_date": "2024-06-04 13:44:36 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-18T16:03:50.862677"
    },
    {
      "arxiv_id": "2406.02295v1",
      "title": "How to Explore with Belief: State Entropy Maximization in POMDPs",
      "title_zh": "如何",
      "authors": [
        "Riccardo Zamboni",
        "Duilio Cirino",
        "Marcello Restelli",
        "Mirco Mutti"
      ],
      "abstract": "Recent works have studied *state entropy maximization* in reinforcement\nlearning, in which the agent's objective is to learn a policy inducing high\nentropy over states visitation (Hazan et al., 2019). They typically assume full\nobservability of the state of the system, so that the entropy of the\nobservations is maximized. In practice, the agent may only get *partial*\nobservations, e.g., a robot perceiving the state of a physical space through\nproximity sensors and cameras. A significant mismatch between the entropy over\nobservations and true states of the system can arise in those settings. In this\npaper, we address the problem of entropy maximization over the *true states*\nwith a decision policy conditioned on partial observations *only*. The latter\nis a generalization of POMDPs, which is intractable in general. We develop a\nmemory and computationally efficient *policy gradient* method to address a\nfirst-order relaxation of the objective defined on *belief* states, providing\nvarious formal characterizations of approximation gaps, the optimization\nlandscape, and the *hallucination* problem. This paper aims to generalize state\nentropy maximization to more realistic domains that meet the challenges of\napplications.",
      "tldr_zh": "该论文探讨了在部分可观测马尔可夫决策过程(POMDPs)中，通过信念状态实现状态熵最大化(state entropy maximization)的探索策略，以解决传统方法假设完全可观测状态的局限性。研究提出了一种基于策略梯度(policy gradient)的内存和计算高效方法，对信念状态的松弛目标进行优化，并提供了近似差距、优化景观和幻觉(hallucination)问题的正式表征。总体上，这项工作将状态熵最大化扩展到更现实的领域，如机器人感知环境，帮助提升代理的探索效率和鲁棒性。",
      "categories": [
        "cs.LG",
        "cs.AI"
      ],
      "primary_category": "cs.LG",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2406.02295v1",
      "published_date": "2024-06-04 13:16:34 UTC",
      "updated_date": "2024-06-04 13:16:34 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-18T16:03:53.387021"
    },
    {
      "arxiv_id": "2406.02645v1",
      "title": "Astral: training physics-informed neural networks with error majorants",
      "title_zh": "Astral：使用误差主项训练物理信息神经网络",
      "authors": [
        "Vladimir Fanaskov",
        "Tianchi Yu",
        "Alexander Rudikov",
        "Ivan Oseledets"
      ],
      "abstract": "The primal approach to physics-informed learning is a residual minimization.\nWe argue that residual is, at best, an indirect measure of the error of\napproximate solution and propose to train with error majorant instead. Since\nerror majorant provides a direct upper bound on error, one can reliably\nestimate how close PiNN is to the exact solution and stop the optimization\nprocess when the desired accuracy is reached. We call loss function associated\nwith error majorant $\\textbf{Astral}$: neur$\\textbf{A}$l a\npo$\\textbf{ST}$erio$\\textbf{RI}$ function$\\textbf{A}$l Loss. To compare Astral\nand residual loss functions, we illustrate how error majorants can be derived\nfor various PDEs and conduct experiments with diffusion equations (including\nanisotropic and in the L-shaped domain), convection-diffusion equation,\ntemporal discretization of Maxwell's equation, and magnetostatics problem. The\nresults indicate that Astral loss is competitive to the residual loss,\ntypically leading to faster convergence and lower error (e.g., for Maxwell's\nequations, we observe an order of magnitude better relative error and training\ntime). We also report that the error estimate obtained with Astral loss is\nusually tight enough to be informative, e.g., for a highly anisotropic\nequation, on average, Astral overestimates error by a factor of $1.5$, and for\nconvection-diffusion by a factor of $1.7$.",
      "tldr_zh": "该研究提出了一种名为 Astral 的新方法，用于训练物理信息神经网络 (PiNNs)，以误差上界 (error majorants) 作为损失函数，而不是传统的残差最小化，从而提供对近似解误差的直接上界估计，便于优化过程的可靠控制。作者为各种偏微分方程 (PDEs) 推导了误差上界，并通过实验验证了 Astral 在扩散方程（包括异向性和 L 形域）、对流扩散方程、Maxwell 方程时域离散和磁静力学问题上的性能。结果显示，Astral 损失函数通常比残差损失函数收敛更快、误差更低，例如在 Maxwell 方程上实现了数量级更低的相对误差和更短的训练时间，且其误差估计准确性高，仅平均 overestimated 误差 1.5 到 1.7 倍。",
      "categories": [
        "physics.comp-ph",
        "cs.AI",
        "cs.LG",
        "cs.NA",
        "math.NA"
      ],
      "primary_category": "physics.comp-ph",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2406.02645v1",
      "published_date": "2024-06-04 13:11:49 UTC",
      "updated_date": "2024-06-04 13:11:49 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-18T16:04:03.597931"
    },
    {
      "arxiv_id": "2406.02644v1",
      "title": "Differentially private exact recovery for stochastic block models",
      "title_zh": "随机块模型的差分隐私精确恢复",
      "authors": [
        "Dung Nguyen",
        "Anil Vullikanti"
      ],
      "abstract": "Stochastic block models (SBMs) are a very commonly studied network model for\ncommunity detection algorithms. In the standard form of an SBM, the $n$\nvertices (or nodes) of a graph are generally divided into multiple\npre-determined communities (or clusters). Connections between pairs of vertices\nare generated randomly and independently with pre-defined probabilities, which\ndepend on the communities containing the two nodes. A fundamental problem in\nSBMs is the recovery of the community structure, and sharp\ninformation-theoretic bounds are known for recoverability for many versions of\nSBMs.\n  Our focus here is the recoverability problem in SBMs when the network is\nprivate. Under the edge differential privacy model, we derive conditions for\nexact recoverability in three different versions of SBMs, namely Asymmetric SBM\n(when communities have non-uniform sizes), General Structure SBM (with\noutliers), and Censored SBM (with edge features). Our private algorithms have\npolynomial running time w.r.t. the input graph's size, and match the recovery\nthresholds of the non-private setting when $\\epsilon\\rightarrow\\infty$. In\ncontrast, the previous best results for recoverability in SBMs only hold for\nthe symmetric case (equal size communities), and run in quasi-polynomial time,\nor in polynomial time with recovery thresholds being tight up to some constants\nfrom the non-private settings.",
      "tldr_zh": "本论文研究了在差分隐私（Differentially private）条件下，对随机块模型（Stochastic block models, SBMs）的精确社区恢复问题。针对Asymmetric SBM（社区大小不均匀）、General Structure SBM（包含异常值）和Censored SBM（包含边特征）三种版本，论文提出了多项式时间运行的私有算法，并导出了精确恢复的条件。这些算法在ε→∞时匹配非私有设置的恢复阈值，显著优于现有方法，后者仅适用于对称社区或运行时间较长。总的来说，该工作为隐私保护下的社区检测提供了更高效且鲁棒的解决方案。",
      "categories": [
        "cs.CR",
        "cs.AI",
        "cs.DS"
      ],
      "primary_category": "cs.CR",
      "comment": "Accepted by ICML 2024",
      "pdf_url": "http://arxiv.org/pdf/2406.02644v1",
      "published_date": "2024-06-04 12:38:05 UTC",
      "updated_date": "2024-06-04 12:38:05 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-18T16:04:16.271528"
    },
    {
      "arxiv_id": "2406.02253v1",
      "title": "PuFace: Defending against Facial Cloaking Attacks for Facial Recognition Models",
      "title_zh": "翻译失败",
      "authors": [
        "Jing Wen"
      ],
      "abstract": "The recently proposed facial cloaking attacks add invisible perturbation\n(cloaks) to facial images to protect users from being recognized by\nunauthorized facial recognition models. However, we show that the \"cloaks\" are\nnot robust enough and can be removed from images.\n  This paper introduces PuFace, an image purification system leveraging the\ngeneralization ability of neural networks to diminish the impact of cloaks by\npushing the cloaked images towards the manifold of natural (uncloaked) images\nbefore the training process of facial recognition models. Specifically, we\ndevise a purifier that takes all the training images including both cloaked and\nnatural images as input and generates the purified facial images close to the\nmanifold where natural images lie. To meet the defense goal, we propose to\ntrain the purifier on particularly amplified cloaked images with a loss\nfunction that combines image loss and feature loss. Our empirical experiment\nshows PuFace can effectively defend against two state-of-the-art facial\ncloaking attacks and reduces the attack success rate from 69.84\\% to 7.61\\% on\naverage without degrading the normal accuracy for various facial recognition\nmodels. Moreover, PuFace is a model-agnostic defense mechanism that can be\napplied to any facial recognition model without modifying the model structure.",
      "tldr_zh": "本研究提出 PuFace 系统，用于防御 facial cloaking attacks，这些攻击通过添加不可见扰动来保护用户免于被未经授权的面部识别模型识别。PuFace 利用神经网络的泛化能力，设计一个净化器（purifier）来处理训练图像，将伪装图像推向自然图像的 manifold，通过结合 image loss 和 feature loss 的损失函数进行训练。实验结果显示，PuFace 有效对抗两种最先进攻击，将攻击成功率从 69.84% 降低到 7.61%，同时不降低面部识别模型的正常准确率，且作为 model-agnostic 机制，可应用于任何模型而不需修改结构。",
      "categories": [
        "cs.CV",
        "cs.AI",
        "cs.CR"
      ],
      "primary_category": "cs.CV",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2406.02253v1",
      "published_date": "2024-06-04 12:19:09 UTC",
      "updated_date": "2024-06-04 12:19:09 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-18T16:04:37.682518"
    },
    {
      "arxiv_id": "2406.02251v1",
      "title": "Modeling Emotional Trajectories in Written Stories Utilizing Transformers and Weakly-Supervised Learning",
      "title_zh": "翻译失败",
      "authors": [
        "Lukas Christ",
        "Shahin Amiriparian",
        "Manuel Milling",
        "Ilhan Aslan",
        "Björn W. Schuller"
      ],
      "abstract": "Telling stories is an integral part of human communication which can evoke\nemotions and influence the affective states of the audience. Automatically\nmodeling emotional trajectories in stories has thus attracted considerable\nscholarly interest. However, as most existing works have been limited to\nunsupervised dictionary-based approaches, there is no benchmark for this task.\nWe address this gap by introducing continuous valence and arousal labels for an\nexisting dataset of children's stories originally annotated with discrete\nemotion categories. We collect additional annotations for this data and map the\ncategorical labels to the continuous valence and arousal space. For predicting\nthe thus obtained emotionality signals, we fine-tune a DeBERTa model and\nimprove upon this baseline via a weakly supervised learning approach. The best\nconfiguration achieves a Concordance Correlation Coefficient (CCC) of $.8221$\nfor valence and $.7125$ for arousal on the test set, demonstrating the efficacy\nof our proposed approach. A detailed analysis shows the extent to which the\nresults vary depending on factors such as the author, the individual story, or\nthe section within the story. In addition, we uncover the weaknesses of our\napproach by investigating examples that prove to be difficult to predict.",
      "tldr_zh": "这篇论文探讨了利用Transformers和Weakly-Supervised Learning来建模书面故事中的情感轨迹，旨在捕捉故事如何影响读者的情感状态。研究者为一个现有的儿童故事数据集添加了连续的valence和arousal标签，通过将离散情感类别映射到连续空间，并微调DeBERTa模型结合弱监督学习进行预测。结果显示，最优配置在测试集上达到valence的Concordance Correlation Coefficient (CCC)为0.8221和arousal的0.7125，并通过详细分析揭示了作者、故事部分等因素的影响以及预测的潜在弱点。",
      "categories": [
        "cs.CL",
        "cs.AI"
      ],
      "primary_category": "cs.CL",
      "comment": "Accepted to ACL 2024 Findings. arXiv admin note: text overlap with\n  arXiv:2212.11382",
      "pdf_url": "http://arxiv.org/pdf/2406.02251v1",
      "published_date": "2024-06-04 12:17:16 UTC",
      "updated_date": "2024-06-04 12:17:16 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-18T16:04:52.677684"
    },
    {
      "arxiv_id": "2407.06165v2",
      "title": "Tumor likelihood estimation on MRI prostate data by utilizing k-Space information",
      "title_zh": "利用 k-Space 信息对 MRI 前列腺数据进行肿瘤可能性估计",
      "authors": [
        "M. Rempe",
        "F. Hörst",
        "C. Seibold",
        "B. Hadaschik",
        "M. Schlimbach",
        "J. Egger",
        "K. Kröninger",
        "F. Breuer",
        "M. Blaimer",
        "J. Kleesiek"
      ],
      "abstract": "We present a novel preprocessing and prediction pipeline for the\nclassification of magnetic resonance imaging (MRI) that takes advantage of the\ninformation rich complex valued k-Space. Using a publicly available MRI raw\ndataset with 312 subject and a total of 9508 slices, we show the advantage of\nutilizing the k-Space for better prostate cancer likelihood estimation in\ncomparison to just using the magnitudinal information in the image domain, with\nan AUROC of $86.1\\%\\pm1.8\\%$. Additionally, by using high undersampling rates\nand a simple principal component analysis (PCA) for coil compression, we reduce\nthe time needed for reconstruction by avoiding the time intensive GRAPPA\nreconstruction algorithm. By using digital undersampling for our experiments,\nwe show that scanning and reconstruction time could be reduced. Even with an\nundersampling factor of 16, our approach achieves meaningful results, with an\nAUROC of $71.4\\%\\pm2.9\\%$, using the PCA coil combination and taking into\naccount the k-Space information. With this study, we were able to show the\nfeasibility of preserving phase and k-Space information, with consistent\nresults. Besides preserving valuable information for further diagnostics, this\napproach can work without the time intensive ADC and reconstruction\ncalculations, greatly reducing the post processing, as well as potential\nscanning time, increasing patient comfort and allowing a close to real-time\nprediction.",
      "tldr_zh": "本研究提出了一种新型MRI预处理和预测管道，利用k-Space信息来提升前列腺肿瘤可能性估计的准确性，在包含312个受试者和9508个切片的公开数据集上，实现了86.1%±1.8%的AUROC，比仅使用图像域幅度信息有显著优势。方法通过高欠采样率和PCA线圈压缩，避开了耗时的GRAPPA重建算法，减少了扫描和重建时间，即使在欠采样因子为16时，AUROC仍达71.4%±2.9%。这种方法保留了相位和k-Space信息，提高了患者舒适度，并支持接近实时的诊断预测。",
      "categories": [
        "cs.CV",
        "cs.AI",
        "physics.med-ph"
      ],
      "primary_category": "cs.CV",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2407.06165v2",
      "published_date": "2024-06-04 12:05:20 UTC",
      "updated_date": "2025-04-14 10:28:26 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-18T16:05:05.007600"
    },
    {
      "arxiv_id": "2406.02235v1",
      "title": "Power Mean Estimation in Stochastic Monte-Carlo Tree_Search",
      "title_zh": "在随机蒙特卡罗树搜索中的功率均值估计",
      "authors": [
        "Tuan Dam",
        "Odalric-Ambrym Maillard",
        "Emilie Kaufmann"
      ],
      "abstract": "Monte-Carlo Tree Search (MCTS) is a widely-used strategy for online planning\nthat combines Monte-Carlo sampling with forward tree search. Its success relies\non the Upper Confidence bound for Trees (UCT) algorithm, an extension of the\nUCB method for multi-arm bandits. However, the theoretical foundation of UCT is\nincomplete due to an error in the logarithmic bonus term for action selection,\nleading to the development of Fixed-Depth-MCTS with a polynomial exploration\nbonus to balance exploration and exploitation~\\citep{shah2022journal}. Both UCT\nand Fixed-Depth-MCTS suffer from biased value estimation: the weighted sum\nunderestimates the optimal value, while the maximum valuation overestimates\nit~\\citep{coulom2006efficient}. The power mean estimator offers a balanced\nsolution, lying between the average and maximum values.\nPower-UCT~\\citep{dam2019generalized} incorporates this estimator for more\naccurate value estimates but its theoretical analysis remains incomplete. This\npaper introduces Stochastic-Power-UCT, an MCTS algorithm using the power mean\nestimator and tailored for stochastic MDPs. We analyze its polynomial\nconvergence in estimating root node values and show that it shares the same\nconvergence rate of $\\mathcal{O}(n^{-1/2})$, with $n$ is the number of visited\ntrajectories, as Fixed-Depth-MCTS, with the latter being a special case of the\nformer. Our theoretical results are validated with empirical tests across\nvarious stochastic MDP environments.",
      "tldr_zh": "该论文针对 Monte-Carlo Tree Search (MCTS) 中的价值估计偏见问题，提出了一种新的 Stochastic-Power-UCT 算法，该算法使用 power mean estimator 来平衡探索和利用，并适用于随机 Markov Decision Processes (MDPs)。Stochastic-Power-UCT 的理论分析证明了其多项式收敛性，在估计根节点值时与 Fixed-Depth-MCTS 具有相同的 O(n^{-1/2}) 收敛率，后者是其特例。实验结果通过各种随机 MDP 环境验证了该算法的有效性，提升了 MCTS 的准确性和可靠性。",
      "categories": [
        "cs.AI"
      ],
      "primary_category": "cs.AI",
      "comment": "UAI 2024 conference",
      "pdf_url": "http://arxiv.org/pdf/2406.02235v1",
      "published_date": "2024-06-04 11:56:37 UTC",
      "updated_date": "2024-06-04 11:56:37 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-18T16:05:16.550994"
    },
    {
      "arxiv_id": "2406.02234v2",
      "title": "On the Limitations of Fractal Dimension as a Measure of Generalization",
      "title_zh": "论分形维数作为泛化度量方法的局限性",
      "authors": [
        "Charlie B. Tan",
        "Inés García-Redondo",
        "Qiquan Wang",
        "Michael M. Bronstein",
        "Anthea Monod"
      ],
      "abstract": "Bounding and predicting the generalization gap of overparameterized neural\nnetworks remains a central open problem in theoretical machine learning. There\nis a recent and growing body of literature that proposes the framework of\nfractals to model optimization trajectories of neural networks, motivating\ngeneralization bounds and measures based on the fractal dimension of the\ntrajectory. Notably, the persistent homology dimension has been proposed to\ncorrelate with the generalization gap. This paper performs an empirical\nevaluation of these persistent homology-based generalization measures, with an\nin-depth statistical analysis. Our study reveals confounding effects in the\nobserved correlation between generalization and topological measures due to the\nvariation of hyperparameters. We also observe that fractal dimension fails to\npredict generalization of models trained from poor initializations. We lastly\nreveal the intriguing manifestation of model-wise double descent in these\ntopological generalization measures. Our work forms a basis for a deeper\ninvestigation of the causal relationships between fractal geometry, topological\ndata analysis, and neural network optimization.",
      "tldr_zh": "该论文探讨了分形维数（fractal dimension）作为神经网络泛化度量（generalization measure）的局限性，通过实证评估和统计分析检验了persistent homology dimension与泛化间隙（generalization gap）的相关性。研究发现，这种相关性受超参数变化的混淆影响，且fractal dimension无法有效预测从不良初始化训练的模型的泛化表现。论文还揭示了拓扑泛化度量中出现的模型相关的双重下降现象（model-wise double descent），为进一步调查分形几何、拓扑数据分析（topological data analysis）与神经网络优化之间的因果关系奠定基础。",
      "categories": [
        "cs.LG",
        "cs.AI",
        "math.DS",
        "stat.ML"
      ],
      "primary_category": "cs.LG",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2406.02234v2",
      "published_date": "2024-06-04 11:56:19 UTC",
      "updated_date": "2024-11-01 16:22:33 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-18T16:05:28.814147"
    },
    {
      "arxiv_id": "2406.02224v4",
      "title": "FedMKT: Federated Mutual Knowledge Transfer for Large and Small Language Models",
      "title_zh": "翻译失败",
      "authors": [
        "Tao Fan",
        "Guoqiang Ma",
        "Yan Kang",
        "Hanlin Gu",
        "Yuanfeng Song",
        "Lixin Fan",
        "Kai Chen",
        "Qiang Yang"
      ],
      "abstract": "Recent research in federated large language models (LLMs) has primarily\nfocused on enabling clients to fine-tune their locally deployed homogeneous\nLLMs collaboratively or on transferring knowledge from server-based LLMs to\nsmall language models (SLMs) at downstream clients. However, a significant gap\nremains in the simultaneous mutual enhancement of both the server's LLM and\nclients' SLMs. To bridge this gap, we propose FedMKT, a parameter-efficient\nfederated mutual knowledge transfer framework for large and small language\nmodels. This framework is designed to adaptively transfer knowledge from the\nserver's LLM to clients' SLMs while concurrently enriching the LLM with\nclients' unique domain insights. We facilitate token alignment using minimum\nedit distance (MinED) and then selective mutual knowledge transfer between\nclient-side SLMs and a server-side LLM, aiming to collectively enhance their\nperformance. Through extensive experiments across three distinct scenarios, we\nevaluate the effectiveness of FedMKT using various public LLMs and SLMs on a\nrange of NLP text generation tasks. Empirical results demonstrate that FedMKT\nsimultaneously boosts the performance of both LLMs and SLMs.",
      "tldr_zh": "该研究提出 FedMKT，一种参数高效的联邦互知识转移框架，用于实现服务器端的大型语言模型 (LLMs) 和客户端的小型语言模型 (SLMs) 之间的双向知识增强。框架通过最小编辑距离 (MinED) 进行 token 对齐，并选择性地转移知识，从而允许服务器 LLM 吸收客户端的领域洞见，同时将知识传回客户端 SLMs。在三个不同场景的广泛实验中，FedMKT 在各种 NLP 文本生成任务上证明了其有效性，能够同时提升 LLMs 和 SLMs 的性能。",
      "categories": [
        "cs.CL",
        "cs.AI"
      ],
      "primary_category": "cs.CL",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2406.02224v4",
      "published_date": "2024-06-04 11:36:09 UTC",
      "updated_date": "2024-12-16 16:13:14 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-18T16:05:39.573099"
    },
    {
      "arxiv_id": "2406.02208v1",
      "title": "Why Only Text: Empowering Vision-and-Language Navigation with Multi-modal Prompts",
      "title_zh": "为什么只有文本：使用多模态提示增强视觉与语言导航",
      "authors": [
        "Haodong Hong",
        "Sen Wang",
        "Zi Huang",
        "Qi Wu",
        "Jiajun Liu"
      ],
      "abstract": "Current Vision-and-Language Navigation (VLN) tasks mainly employ textual\ninstructions to guide agents. However, being inherently abstract, the same\ntextual instruction can be associated with different visual signals, causing\nsevere ambiguity and limiting the transfer of prior knowledge in the vision\ndomain from the user to the agent. To fill this gap, we propose\nVision-and-Language Navigation with Multi-modal Prompts (VLN-MP), a novel task\naugmenting traditional VLN by integrating both natural language and images in\ninstructions. VLN-MP not only maintains backward compatibility by effectively\nhandling text-only prompts but also consistently shows advantages with\ndifferent quantities and relevance of visual prompts. Possible forms of visual\nprompts include both exact and similar object images, providing adaptability\nand versatility in diverse navigation scenarios. To evaluate VLN-MP under a\nunified framework, we implement a new benchmark that offers: (1) a\ntraining-free pipeline to transform textual instructions into multi-modal forms\nwith landmark images; (2) diverse datasets with multi-modal instructions for\ndifferent downstream tasks; (3) a novel module designed to process various\nimage prompts for seamless integration with state-of-the-art VLN models.\nExtensive experiments on four VLN benchmarks (R2R, RxR, REVERIE, CVDN) show\nthat incorporating visual prompts significantly boosts navigation performance.\nWhile maintaining efficiency with text-only prompts, VLN-MP enables agents to\nnavigate in the pre-explore setting and outperform text-based models, showing\nits broader applicability.",
      "tldr_zh": "本论文指出，传统的 Vision-and-Language Navigation (VLN) 任务主要依赖文本指令，但这种抽象形式易导致歧义和知识转移问题。作者提出 VLN-MP，一种新任务，通过整合自然语言和图像提示（如精确或相似对象图像）来增强导航代理的鲁棒性，同时保持对纯文本提示的兼容性。VLN-MP 包括一个无训练管道将文本指令转化为多模态形式、多种数据集以及一个专为处理图像提示的模块；实验在 R2R、RxR、REVERIE 和 CVDN 等基准上显示，加入视觉提示显著提升导航性能，并在预探索设置中超越纯文本模型。",
      "categories": [
        "cs.CV",
        "cs.AI",
        "cs.CL"
      ],
      "primary_category": "cs.CV",
      "comment": "IJCAI 2024",
      "pdf_url": "http://arxiv.org/pdf/2406.02208v1",
      "published_date": "2024-06-04 11:06:13 UTC",
      "updated_date": "2024-06-04 11:06:13 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-18T16:05:53.085901"
    },
    {
      "arxiv_id": "2406.02205v1",
      "title": "Query-Enhanced Adaptive Semantic Path Reasoning for Inductive Knowledge Graph Completion",
      "title_zh": "翻译失败",
      "authors": [
        "Kai Sun",
        "Jiapu Wang",
        "Huajie Jiang",
        "Yongli Hu",
        "Baocai Yin"
      ],
      "abstract": "Conventional Knowledge graph completion (KGC) methods aim to infer missing\ninformation in incomplete Knowledge Graphs (KGs) by leveraging existing\ninformation, which struggle to perform effectively in scenarios involving\nemerging entities. Inductive KGC methods can handle the emerging entities and\nrelations in KGs, offering greater dynamic adaptability. While existing\ninductive KGC methods have achieved some success, they also face challenges,\nsuch as susceptibility to noisy structural information during reasoning and\ndifficulty in capturing long-range dependencies in reasoning paths. To address\nthese challenges, this paper proposes the Query-Enhanced Adaptive Semantic Path\nReasoning (QASPR) framework, which simultaneously captures both the structural\nand semantic information of KGs to enhance the inductive KGC task.\nSpecifically, the proposed QASPR employs a query-dependent masking module to\nadaptively mask noisy structural information while retaining important\ninformation closely related to the targets. Additionally, QASPR introduces a\nglobal semantic scoring module that evaluates both the individual contributions\nand the collective impact of nodes along the reasoning path within KGs. The\nexperimental results demonstrate that QASPR achieves state-of-the-art\nperformance.",
      "tldr_zh": "本文针对知识图谱完成（Knowledge Graph Completion, KGC）中新兴实体的挑战，提出了一种归纳式框架Query-Enhanced Adaptive Semantic Path Reasoning (QASPR)，旨在同时捕捉知识图谱的结构和语义信息，以缓解噪声结构干扰和长程依赖问题。QASPR 包括 query-dependent masking module，用于自适应地掩盖无关噪声并保留关键信息，以及 global semantic scoring module，用于评估推理路径中节点的个体和集体贡献。实验结果显示，该框架在归纳式 KGC 任务上达到了 state-of-the-art 性能。",
      "categories": [
        "cs.AI"
      ],
      "primary_category": "cs.AI",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2406.02205v1",
      "published_date": "2024-06-04 11:02:15 UTC",
      "updated_date": "2024-06-04 11:02:15 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-18T16:06:04.604751"
    },
    {
      "arxiv_id": "2406.02204v1",
      "title": "The Deep Latent Space Particle Filter for Real-Time Data Assimilation with Uncertainty Quantification",
      "title_zh": "深度潜在空间粒子滤波器用于实时数据同化伴随不确定性量化",
      "authors": [
        "Nikolaj T. Mücke",
        "Sander M. Bohté",
        "Cornelis W. Oosterlee"
      ],
      "abstract": "In Data Assimilation, observations are fused with simulations to obtain an\naccurate estimate of the state and parameters for a given physical system.\nCombining data with a model, however, while accurately estimating uncertainty,\nis computationally expensive and infeasible to run in real-time for complex\nsystems. Here, we present a novel particle filter methodology, the Deep Latent\nSpace Particle filter or D-LSPF, that uses neural network-based surrogate\nmodels to overcome this computational challenge. The D-LSPF enables filtering\nin the low-dimensional latent space obtained using Wasserstein AEs with\nmodified vision transformer layers for dimensionality reduction and\ntransformers for parameterized latent space time stepping. As we demonstrate on\nthree test cases, including leak localization in multi-phase pipe flow and\nseabed identification for fully nonlinear water waves, the D-LSPF runs orders\nof magnitude faster than a high-fidelity particle filter and 3-5 times faster\nthan alternative methods while being up to an order of magnitude more accurate.\nThe D-LSPF thus enables real-time data assimilation with uncertainty\nquantification for physical systems.",
      "tldr_zh": "这篇论文提出了Deep Latent Space Particle Filter (D-LSPF)，一种新型粒子滤波方法，用于实时数据同化（Data Assimilation），以精确估计物理系统的状态和参数，同时量化不确定性。D-LSPF 利用神经网络-based surrogate models，包括Wasserstein AEs结合modified vision transformer layers进行维度减少，以及transformers进行参数化的潜在空间时间步进，从而显著降低计算开销。在三个测试案例中，如多相管流泄漏定位和非线性水波海底识别，D-LSPF 比高保真粒子滤波器快几个数量级，比替代方法快3-5倍，同时准确率高出一个数量级，实现物理系统的实时数据同化。",
      "categories": [
        "cs.CE",
        "cs.AI",
        "cs.LG"
      ],
      "primary_category": "cs.CE",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2406.02204v1",
      "published_date": "2024-06-04 10:59:54 UTC",
      "updated_date": "2024-06-04 10:59:54 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-18T16:06:17.481919"
    },
    {
      "arxiv_id": "2406.02642v3",
      "title": "E-ICL: Enhancing Fine-Grained Emotion Recognition through the Lens of Prototype Theory",
      "title_zh": "E-ICL：通过原型理论的视角增强细粒度情感识别",
      "authors": [
        "Zhaochun Ren",
        "Zhou Yang",
        "Chenglong Ye",
        "Yufeng Wang",
        "Haizhou Sun",
        "Chao Chen",
        "Xiaofei Zhu",
        "Yunbing Wu",
        "Xiangwen Liao"
      ],
      "abstract": "In-context learning (ICL) achieves remarkable performance in various domains\nsuch as knowledge acquisition, commonsense reasoning, and semantic\nunderstanding. However, its performance significantly deteriorates for emotion\ndetection tasks, especially fine-grained emotion recognition. The underlying\nreasons for this remain unclear. In this paper, we identify the reasons behind\nICL's poor performance from the perspective of prototype theory and propose a\nmethod to address this issue. Specifically, we conduct extensive pilot\nexperiments and find that ICL conforms to the prototype theory on fine-grained\nemotion recognition. Based on this theory, we uncover the following\ndeficiencies in ICL: (1) It relies on prototypes (example-label pairs) that are\nsemantically similar but emotionally inaccurate to predict emotions. (2) It is\nprone to interference from irrelevant categories, affecting the accuracy and\nrobustness of the predictions. To address these issues, we propose an Emotion\nContext Learning method (E-ICL) on fine-grained emotion recognition. E-ICL\nrelies on more emotionally accurate prototypes to predict categories by\nreferring to emotionally similar examples with dynamic labels. Simultaneously,\nE-ICL employs an exclusionary emotion prediction strategy to avoid interference\nfrom irrelevant categories, thereby increasing its accuracy and robustness.\nNote that the entire process is accomplished with the assistance of a\nplug-and-play emotion auxiliary model, without additional training. Experiments\non the fine-grained emotion datasets EDOS, Empathetic-Dialogues,\nEmpatheticIntent, and GoEmotions show that E-ICL achieves superior emotion\nprediction performance. Furthermore, even when the emotion auxiliary model used\nis lower than 10% of the LLMs, E-ICL can still boost the performance of LLMs by\nover 4% on multiple datasets.",
      "tldr_zh": "该论文分析了 In-context Learning (ICL) 在细粒度情感识别（fine-grained emotion recognition）上的表现不佳问题，从 Prototype Theory 的视角揭示其原因，包括依赖语义相似但情感不准确的原型，以及易受无关类别干扰。针对这些缺陷，作者提出 E-ICL 方法，该方法使用更情感准确的原型、动态标签和排除性情感预测策略来提升预测的准确性和鲁棒性，且通过一个即插即用（plug-and-play）的辅助情感模型实现，无需额外训练。在 EDOS、Empathetic-Dialogues、EmpatheticIntent 和 GoEmotions 等数据集上的实验显示，E-ICL 显著提高了大型语言模型（LLMs）的性能，即使辅助模型规模不到 LLMs 的 10%，也能带来超过 4% 的提升。",
      "categories": [
        "cs.LG",
        "cs.AI"
      ],
      "primary_category": "cs.LG",
      "comment": "16 pages, 7 figures, 5 tables",
      "pdf_url": "http://arxiv.org/pdf/2406.02642v3",
      "published_date": "2024-06-04 10:59:43 UTC",
      "updated_date": "2025-01-06 01:52:41 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-18T16:06:27.900766"
    },
    {
      "arxiv_id": "2406.02202v2",
      "title": "No Captions, No Problem: Captionless 3D-CLIP Alignment with Hard Negatives via CLIP Knowledge and LLMs",
      "title_zh": "翻译失败",
      "authors": [
        "Cristian Sbrolli",
        "Matteo Matteucci"
      ],
      "abstract": "In this study, we explore an alternative approach to enhance contrastive\ntext-image-3D alignment in the absence of textual descriptions for 3D objects.\nWe introduce two unsupervised methods, $I2I$ and $(I2L)^2$, which leverage CLIP\nknowledge about textual and 2D data to compute the neural perceived similarity\nbetween two 3D samples. We employ the proposed methods to mine 3D hard\nnegatives, establishing a multimodal contrastive pipeline with hard negative\nweighting via a custom loss function. We train on different configurations of\nthe proposed hard negative mining approach, and we evaluate the accuracy of our\nmodels in 3D classification and on the cross-modal retrieval benchmark, testing\nimage-to-shape and shape-to-image retrieval. Results demonstrate that our\napproach, even without explicit text alignment, achieves comparable or superior\nperformance on zero-shot and standard 3D classification, while significantly\nimproving both image-to-shape and shape-to-image retrieval compared to previous\nmethods.",
      "tldr_zh": "本文提出一种无须文本描述的 3D-CLIP 对齐方法，引入两种无监督技术 I2I 和 (I2L)^2，利用 CLIP 知识和 LLMs 计算 3D 样本的神经感知相似性，以挖掘硬负样本并通过自定义损失函数构建多模态对比管道。实验在不同配置下训练模型，结果显示该方法在零样本和标准 3D 分类任务上达到或优于现有性能，同时显著提升图像到形状和形状到图像的跨模态检索准确性。总的来说，这一方法证明了在缺乏标题的情况下，通过硬负样本加权也能实现有效的 3D-图像对齐。",
      "categories": [
        "cs.CV",
        "cs.AI"
      ],
      "primary_category": "cs.CV",
      "comment": "to be published in BMVC 2024 Proceedings",
      "pdf_url": "http://arxiv.org/pdf/2406.02202v2",
      "published_date": "2024-06-04 10:57:59 UTC",
      "updated_date": "2024-09-09 12:04:27 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-18T16:06:40.770853"
    },
    {
      "arxiv_id": "2406.16908v3",
      "title": "Using Explainable AI for EEG-based Reduced Montage Neonatal Seizure Detection",
      "title_zh": "翻译失败",
      "authors": [
        "Dinuka Sandun Udayantha",
        "Kavindu Weerasinghe",
        "Nima Wickramasinghe",
        "Akila Abeyratne",
        "Kithmin Wickremasinghe",
        "Jithangi Wanigasinghe",
        "Anjula De Silva",
        "Chamira U. S. Edussooriya"
      ],
      "abstract": "The neonatal period is the most vulnerable time for the development of\nseizures. Seizures in the immature brain lead to detrimental consequences,\ntherefore require early diagnosis. The gold-standard for neonatal seizure\ndetection currently relies on continuous video-EEG monitoring; which involves\nrecording multi-channel electroencephalogram (EEG) alongside real-time video\nmonitoring within a neonatal intensive care unit (NICU). However, video-EEG\nmonitoring technology requires clinical expertise and is often limited to\ntechnologically advanced and resourceful settings. Cost-effective new\ntechniques could help the medical fraternity make an accurate diagnosis and\nadvocate treatment without delay. In this work, a novel explainable deep\nlearning model to automate the neonatal seizure detection process with a\nreduced EEG montage is proposed, which employs convolutional nets, graph\nattention layers, and fully connected layers. Beyond its ability to detect\nseizures in real-time with a reduced montage, this model offers the unique\nadvantage of real-time interpretability. By evaluating the performance on the\nZenodo dataset with 10-fold cross-validation, the presented model achieves an\nabsolute improvement of 8.31% and 42.86% in area under curve (AUC) and recall,\nrespectively.",
      "tldr_zh": "本研究针对新生儿癫痫检测的挑战，提出了一种基于Explainable AI的可解释深度学习模型，使用减少的EEG montage（电极配置）来实现自动化实时检测。模型结合了convolutional nets、graph attention layers和fully connected layers，能够提供实时可解释性，帮助早期诊断并减少资源需求。在Zenodo数据集上通过10折交叉验证，该模型在AUC和recall上分别实现了8.31%和42.86%的绝对提升，为临床应用提供了更高效且可信的工具。",
      "categories": [
        "eess.SP",
        "cs.AI",
        "cs.LG"
      ],
      "primary_category": "eess.SP",
      "comment": "Paper is accepted to IEEE International Conference on Systems, Man,\n  and Cybernetics (SMC) 2024. Final Version",
      "pdf_url": "http://arxiv.org/pdf/2406.16908v3",
      "published_date": "2024-06-04 10:53:56 UTC",
      "updated_date": "2024-08-14 11:07:41 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-18T16:06:54.543003"
    },
    {
      "arxiv_id": "2407.13773v1",
      "title": "OpenDataLab: Empowering General Artificial Intelligence with Open Datasets",
      "title_zh": "OpenDataLab：利用开放数据集赋能通用人工智能",
      "authors": [
        "Conghui He",
        "Wei Li",
        "Zhenjiang Jin",
        "Chao Xu",
        "Bin Wang",
        "Dahua Lin"
      ],
      "abstract": "The advancement of artificial intelligence (AI) hinges on the quality and\naccessibility of data, yet the current fragmentation and variability of data\nsources hinder efficient data utilization. The dispersion of data sources and\ndiversity of data formats often lead to inefficiencies in data retrieval and\nprocessing, significantly impeding the progress of AI research and\napplications. To address these challenges, this paper introduces OpenDataLab, a\nplatform designed to bridge the gap between diverse data sources and the need\nfor unified data processing. OpenDataLab integrates a wide range of open-source\nAI datasets and enhances data acquisition efficiency through intelligent\nquerying and high-speed downloading services. The platform employs a\nnext-generation AI Data Set Description Language (DSDL), which standardizes the\nrepresentation of multimodal and multi-format data, improving interoperability\nand reusability. Additionally, OpenDataLab optimizes data processing through\ntools that complement DSDL. By integrating data with unified data descriptions\nand smart data toolchains, OpenDataLab can improve data preparation efficiency\nby 30\\%. We anticipate that OpenDataLab will significantly boost artificial\ngeneral intelligence (AGI) research and facilitate advancements in related AI\nfields. For more detailed information, please visit the platform's official\nwebsite: https://opendatalab.com.",
      "tldr_zh": "该论文指出，AI 进步受限于数据来源的碎片化和格式多样性，导致数据检索和处理效率低下。为解决这一问题，研究团队推出了 OpenDataLab 平台，该平台整合了多种开源 AI 数据集，并通过智能查询、高速下载服务以及新一代 AI 数据集描述语言 (DSDL) 来标准化多模态和多格式数据，从而提升数据互操作性和可重用性。OpenDataLab 还优化了数据处理工具链，提高数据准备效率 30%，预计将显著推动人工通用智能 (AGI) 研究和相关 AI 领域的进展。",
      "categories": [
        "cs.DL",
        "cs.AI"
      ],
      "primary_category": "cs.DL",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2407.13773v1",
      "published_date": "2024-06-04 10:42:01 UTC",
      "updated_date": "2024-06-04 10:42:01 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-18T16:07:06.563884"
    },
    {
      "arxiv_id": "2406.11873v1",
      "title": "Logic-Based Explainability: Past, Present & Future",
      "title_zh": "基于逻辑的可解释性：过去、现在与未来",
      "authors": [
        "Joao Marques-Silva"
      ],
      "abstract": "In recent years, the impact of machine learning (ML) and artificial\nintelligence (AI) in society has been absolutely remarkable. This impact is\nexpected to continue in the foreseeable future. However,the adoption of AI/ML\nis also a cause of grave concern. The operation of the most advances AI/ML\nmodels is often beyond the grasp of human decision makers. As a result,\ndecisions that impact humans may not be understood and may lack rigorous\nvalidation. Explainable AI (XAI) is concerned with providing human\ndecision-makers with understandable explanations for the predictions made by ML\nmodels. As a result, XAI is a cornerstone of trustworthy AI. Despite its\nstrategic importance, most work on XAI lacks rigor, and so its use in high-risk\nor safety-critical domains serves to foster distrust instead of contributing to\nbuild much-needed trust. Logic-based XAI has recently emerged as a rigorous\nalternative to those other non-rigorous methods of XAI. This paper provides a\ntechnical survey of logic-based XAI, its origins, the current topics of\nresearch, and emerging future topics of research. The paper also highlights the\nmany myths that pervade non-rigorous approaches for XAI.",
      "tldr_zh": "这篇论文回顾了可解释AI (XAI) 的发展，强调了AI/ML 模型在社会中的影响及其不透明性导致的信任问题。作者提出逻辑-based XAI 作为一种严谨替代方案，通过技术调查分析其起源、当前研究主题（如提供可理解解释以提升AI可靠性）以及未来方向，同时揭露非严谨XAI 方法的常见误区。该研究为高风险领域构建可信赖AI 提供了重要基础，旨在促进更可靠的决策过程。",
      "categories": [
        "cs.AI"
      ],
      "primary_category": "cs.AI",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2406.11873v1",
      "published_date": "2024-06-04 10:41:55 UTC",
      "updated_date": "2024-06-04 10:41:55 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-18T16:07:18.613793"
    },
    {
      "arxiv_id": "2406.02180v1",
      "title": "On The Statistical Representation Properties Of The Perturb-Softmax And The Perturb-Argmax Probability Distributions",
      "title_zh": "翻译失败",
      "authors": [
        "Hedda Cohen Indelman",
        "Tamir Hazan"
      ],
      "abstract": "The Gumbel-Softmax probability distribution allows learning discrete tokens\nin generative learning, while the Gumbel-Argmax probability distribution is\nuseful in learning discrete structures in discriminative learning. Despite the\nefforts invested in optimizing these probability models, their statistical\nproperties are under-explored. In this work, we investigate their\nrepresentation properties and determine for which families of parameters these\nprobability distributions are complete, i.e., can represent any probability\ndistribution, and minimal, i.e., can represent a probability distribution\nuniquely. We rely on convexity and differentiability to determine these\nstatistical conditions and extend this framework to general probability models,\nsuch as Gaussian-Softmax and Gaussian-Argmax. We experimentally validate the\nqualities of these extensions, which enjoy a faster convergence rate. We\nconclude the analysis by identifying two sets of parameters that satisfy these\nassumptions and thus admit a complete and minimal representation. Our\ncontribution is theoretical with supporting practical evaluation.",
      "tldr_zh": "本论文探讨了 Perturb-Softmax 和 Perturb-Argmax 概率分布的统计表示属性，分析这些分布在生成和判别学习中的应用，并确定其完整性（能表示任何概率分布）和最小性（唯一表示）。作者通过依赖凸性和可微性的框架，扩展这一分析到 Gaussian-Softmax 和 Gaussian-Argmax 等一般概率模型，并通过实验验证这些扩展的更快收敛率。最终，论文识别出满足这些假设的参数集，为概率模型的理论优化提供支持。",
      "categories": [
        "cs.LG",
        "cs.AI",
        "stat.ML"
      ],
      "primary_category": "cs.LG",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2406.02180v1",
      "published_date": "2024-06-04 10:22:12 UTC",
      "updated_date": "2024-06-04 10:22:12 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-18T16:07:31.516762"
    },
    {
      "arxiv_id": "2406.02178v2",
      "title": "Audio Mamba: Selective State Spaces for Self-Supervised Audio Representations",
      "title_zh": "翻译失败",
      "authors": [
        "Sarthak Yadav",
        "Zheng-Hua Tan"
      ],
      "abstract": "Despite its widespread adoption as the prominent neural architecture, the\nTransformer has spurred several independent lines of work to address its\nlimitations. One such approach is selective state space models, which have\ndemonstrated promising results for language modelling. However, their\nfeasibility for learning self-supervised, general-purpose audio representations\nis yet to be investigated. This work proposes Audio Mamba, a selective state\nspace model for learning general-purpose audio representations from randomly\nmasked spectrogram patches through self-supervision. Empirical results on ten\ndiverse audio recognition downstream tasks show that the proposed models,\npretrained on the AudioSet dataset, consistently outperform comparable\nself-supervised audio spectrogram transformer (SSAST) baselines by a\nconsiderable margin and demonstrate better performance in dataset size,\nsequence length and model size comparisons.",
      "tldr_zh": "本文提出 Audio Mamba，一种基于 Selective State Space Models 的框架，用于通过自监督学习从随机 masked 的 spectrogram patches 中学习通用的音频表示，以克服 Transformer 的局限性。模型在 AudioSet 数据集上预训练后，在十个不同的音频识别下游任务上进行评估，结果显示 Audio Mamba 比自监督音频谱图 Transformer (SSAST) 基线模型有显著提升，平均性能优势明显。相比之下，Audio Mamba 在数据集大小、序列长度和模型大小方面表现出更好的鲁棒性和效率。",
      "categories": [
        "cs.SD",
        "cs.AI",
        "eess.AS"
      ],
      "primary_category": "cs.SD",
      "comment": "Accepted at INTERSPEECH 2024",
      "pdf_url": "http://arxiv.org/pdf/2406.02178v2",
      "published_date": "2024-06-04 10:19:14 UTC",
      "updated_date": "2024-06-07 18:41:28 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-18T16:07:41.941087"
    },
    {
      "arxiv_id": "2406.02177v1",
      "title": "One-Shot Federated Learning with Bayesian Pseudocoresets",
      "title_zh": "翻译失败",
      "authors": [
        "Tim d'Hondt",
        "Mykola Pechenizkiy",
        "Robert Peharz"
      ],
      "abstract": "Optimization-based techniques for federated learning (FL) often come with\nprohibitive communication cost, as high dimensional model parameters need to be\ncommunicated repeatedly between server and clients. In this paper, we follow a\nBayesian approach allowing to perform FL with one-shot communication, by\nsolving the global inference problem as a product of local client posteriors.\nFor models with multi-modal likelihoods, such as neural networks, a naive\napplication of this scheme is hampered, since clients will capture different\nposterior modes, causing a destructive collapse of the posterior on the server\nside. Consequently, we explore approximate inference in the function-space\nrepresentation of client posteriors, hence suffering less or not at all from\nmulti-modality. We show that distributed function-space inference is tightly\nrelated to learning Bayesian pseudocoresets and develop a tractable Bayesian FL\nalgorithm on this insight. We show that this approach achieves prediction\nperformance competitive to state-of-the-art while showing a striking reduction\nin communication cost of up to two orders of magnitude. Moreover, due to its\nBayesian nature, our method also delivers well-calibrated uncertainty\nestimates.",
      "tldr_zh": "本论文提出了一种基于 Bayesian Pseudocoresets 的 one-shot Federated Learning 方法，以减少传统优化方法的高通信成本，通过将全局推理问题建模为本地客户端后验的乘积来实现单次通信。针对神经网络等多模态似然模型可能导致后验崩溃的问题，该方法采用函数空间表示的客户端后验近似推理，并将其与学习 Bayesian Pseudocoresets 紧密结合，开发了一个可处理的 Bayesian FL 算法。实验结果显示，该方法在预测性能上与最先进技术相当，同时将通信成本降低多达两个数量级，并提供校准良好的不确定性估计。",
      "categories": [
        "cs.LG",
        "cs.AI",
        "cs.DC",
        "stat.ML"
      ],
      "primary_category": "cs.LG",
      "comment": "10 pages",
      "pdf_url": "http://arxiv.org/pdf/2406.02177v1",
      "published_date": "2024-06-04 10:14:39 UTC",
      "updated_date": "2024-06-04 10:14:39 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-18T16:07:54.265411"
    },
    {
      "arxiv_id": "2407.13105v1",
      "title": "Survey on Plagiarism Detection in Large Language Models: The Impact of ChatGPT and Gemini on Academic Integrity",
      "title_zh": "大语言模型剽窃检测的调查：ChatGPT 和 Gemini 对学术诚信的影响",
      "authors": [
        "Shushanta Pudasaini",
        "Luis Miralles-Pechuán",
        "David Lillis",
        "Marisa Llorens Salvador"
      ],
      "abstract": "The rise of Large Language Models (LLMs) such as ChatGPT and Gemini has posed\nnew challenges for the academic community. With the help of these models,\nstudents can easily complete their assignments and exams, while educators\nstruggle to detect AI-generated content. This has led to a surge in academic\nmisconduct, as students present work generated by LLMs as their own, without\nputting in the effort required for learning. As AI tools become more advanced\nand produce increasingly human-like text, detecting such content becomes more\nchallenging. This development has significantly impacted the academic world,\nwhere many educators are finding it difficult to adapt their assessment methods\nto this challenge.\n  This research first demonstrates how LLMs have increased academic dishonesty,\nand then reviews state-of-the-art solutions for academic plagiarism in detail.\nA survey of datasets, algorithms, tools, and evasion strategies for plagiarism\ndetection has been conducted, focusing on how LLMs and AI-generated content\n(AIGC) detection have affected this area. The survey aims to identify the gaps\nin existing solutions. Lastly, potential long-term solutions are presented to\naddress the issue of academic plagiarism using LLMs based on AI tools and\neducational approaches in an ever-changing world.",
      "tldr_zh": "本研究调查了大型语言模型 (LLMs) 如 ChatGPT 和 Gemini 对学术诚信的影响，强调这些模型导致学术不端行为增加，因为学生易于使用它们生成作业，而教师难以检测 AI-generated content (AIGC)。论文首先分析了 LLMs 如何加剧学术 dishonesty，然后详细审查了现有剽窃检测解决方案，包括数据集、算法、工具和 evasion strategies，并识别了这些方法的不足之处。最后，提出基于 AI 工具和教育方法的潜在长期解决方案，以适应不断变化的学术环境。",
      "categories": [
        "cs.CY",
        "cs.AI",
        "cs.LG"
      ],
      "primary_category": "cs.CY",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2407.13105v1",
      "published_date": "2024-06-04 09:38:03 UTC",
      "updated_date": "2024-06-04 09:38:03 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-18T16:08:07.300067"
    },
    {
      "arxiv_id": "2406.02148v1",
      "title": "Synergetic Event Understanding: A Collaborative Approach to Cross-Document Event Coreference Resolution with Large Language Models",
      "title_zh": "翻译失败",
      "authors": [
        "Qingkai Min",
        "Qipeng Guo",
        "Xiangkun Hu",
        "Songfang Huang",
        "Zheng Zhang",
        "Yue Zhang"
      ],
      "abstract": "Cross-document event coreference resolution (CDECR) involves clustering event\nmentions across multiple documents that refer to the same real-world events.\nExisting approaches utilize fine-tuning of small language models (SLMs) like\nBERT to address the compatibility among the contexts of event mentions.\nHowever, due to the complexity and diversity of contexts, these models are\nprone to learning simple co-occurrences. Recently, large language models (LLMs)\nlike ChatGPT have demonstrated impressive contextual understanding, yet they\nencounter challenges in adapting to specific information extraction (IE) tasks.\nIn this paper, we propose a collaborative approach for CDECR, leveraging the\ncapabilities of both a universally capable LLM and a task-specific SLM. The\ncollaborative strategy begins with the LLM accurately and comprehensively\nsummarizing events through prompting. Then, the SLM refines its learning of\nevent representations based on these insights during fine-tuning. Experimental\nresults demonstrate that our approach surpasses the performance of both the\nlarge and small language models individually, forming a complementary\nadvantage. Across various datasets, our approach achieves state-of-the-art\nperformance, underscoring its effectiveness in diverse scenarios.",
      "tldr_zh": "这篇论文针对跨文档事件共指解析 (CDECR) 提出了一种协作方法，结合大型语言模型 (LLMs) 和小型语言模型 (SLMs) 来识别并聚类多个文档中指代同一真实事件的提及。方法通过提示让 LLMs 准确总结事件内容，然后 SLMs 基于这些总结进行细化学习，以改进事件表示并克服简单共现问题的局限。实验结果表明，该协作策略在各种数据集上超越了单独使用 LLMs 或 SLMs 的表现，实现了最先进性能，并展示了互补优势。",
      "categories": [
        "cs.CL",
        "cs.AI"
      ],
      "primary_category": "cs.CL",
      "comment": "Accepted to ACL-24 Main",
      "pdf_url": "http://arxiv.org/pdf/2406.02148v1",
      "published_date": "2024-06-04 09:35:47 UTC",
      "updated_date": "2024-06-04 09:35:47 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-18T16:08:19.555047"
    },
    {
      "arxiv_id": "2406.02131v4",
      "title": "CondTSF: One-line Plugin of Dataset Condensation for Time Series Forecasting",
      "title_zh": "翻译失败",
      "authors": [
        "Jianrong Ding",
        "Zhanyu Liu",
        "Guanjie Zheng",
        "Haiming Jin",
        "Linghe Kong"
      ],
      "abstract": "Dataset condensation is a newborn technique that generates a small dataset\nthat can be used in training deep neural networks to lower training costs. The\nobjective of dataset condensation is to ensure that the model trained with the\nsynthetic dataset can perform comparably to the model trained with full\ndatasets. However, existing methods predominantly concentrate on classification\ntasks, posing challenges in their adaptation to time series forecasting\n(TS-forecasting). This challenge arises from disparities in the evaluation of\nsynthetic data. In classification, the synthetic data is considered\nwell-distilled if the model trained with the full dataset and the model trained\nwith the synthetic dataset yield identical labels for the same input,\nregardless of variations in output logits distribution. Conversely, in\nTS-forecasting, the effectiveness of synthetic data distillation is determined\nby the distance between predictions of the two models. The synthetic data is\ndeemed well-distilled only when all data points within the predictions are\nsimilar. Consequently, TS-forecasting has a more rigorous evaluation\nmethodology compared to classification. To mitigate this gap, we theoretically\nanalyze the optimization objective of dataset condensation for TS-forecasting\nand propose a new one-line plugin of dataset condensation designated as Dataset\nCondensation for Time Series Forecasting (CondTSF) based on our analysis.\nPlugging CondTSF into previous dataset condensation methods facilitates a\nreduction in the distance between the predictions of the model trained with the\nfull dataset and the model trained with the synthetic dataset, thereby\nenhancing performance. We conduct extensive experiments on eight commonly used\ntime series datasets. CondTSF consistently improves the performance of all\nprevious dataset condensation methods across all datasets, particularly at low\ncondensing ratios.",
      "tldr_zh": "这篇论文针对时间序列预测（Time Series Forecasting）中的数据集浓缩（Dataset Condensation）问题，提出了一种名为CondTSF的一行插件，以解决现有方法在TS-forecasting上的适应性不足。CondTSF通过理论分析优化了浓缩的评估目标，减少了使用合成数据集训练的模型与完整数据集训练的模型之间的预测距离，从而提升整体性能。在八个常用时间序列数据集上的实验显示，CondTSF一致提高了现有方法的准确性，尤其在低浓缩比率下表现突出。",
      "categories": [
        "cs.LG",
        "cs.AI"
      ],
      "primary_category": "cs.LG",
      "comment": "Accepted by NeurIPS 2024, the project can be found at\n  https://github.com/RafaDD/CondTSF",
      "pdf_url": "http://arxiv.org/pdf/2406.02131v4",
      "published_date": "2024-06-04 09:18:20 UTC",
      "updated_date": "2024-10-23 16:05:11 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-18T16:08:31.443886"
    },
    {
      "arxiv_id": "2406.02128v2",
      "title": "Iteration Head: A Mechanistic Study of Chain-of-Thought",
      "title_zh": "翻译失败",
      "authors": [
        "Vivien Cabannes",
        "Charles Arnal",
        "Wassim Bouaziz",
        "Alice Yang",
        "Francois Charton",
        "Julia Kempe"
      ],
      "abstract": "Chain-of-Thought (CoT) reasoning is known to improve Large Language Models\nboth empirically and in terms of theoretical approximation power. However, our\nunderstanding of the inner workings and conditions of apparition of CoT\ncapabilities remains limited. This paper helps fill this gap by demonstrating\nhow CoT reasoning emerges in transformers in a controlled and interpretable\nsetting. In particular, we observe the appearance of a specialized attention\nmechanism dedicated to iterative reasoning, which we coined \"iteration heads\".\nWe track both the emergence and the precise working of these iteration heads\ndown to the attention level, and measure the transferability of the CoT skills\nto which they give rise between tasks.",
      "tldr_zh": "本论文研究了 Chain-of-Thought (CoT) 推理在大型语言模型中的内部机制，通过可控且可解释的实验设置，揭示了 CoT 能力的出现条件。研究发现，transformer 中出现了一种专门的注意力机制，称为 \"iteration heads\"，负责迭代推理，并对其在注意力层面的运作和任务间可转移性进行了详细追踪。该工作增强了对 CoT 推理的理解，提升了模型的理论近似能力和实证性能。",
      "categories": [
        "cs.LG",
        "cs.AI",
        "cs.CL"
      ],
      "primary_category": "cs.LG",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2406.02128v2",
      "published_date": "2024-06-04 09:11:46 UTC",
      "updated_date": "2024-10-28 11:14:54 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-18T16:08:42.706692"
    },
    {
      "arxiv_id": "2406.02126v3",
      "title": "CityLight: A Universal Model for Coordinated Traffic Signal Control in City-scale Heterogeneous Intersections",
      "title_zh": "CityLight：一种用于城市规模异构交叉路口的协调交通信号控制通用模型",
      "authors": [
        "Jinwei Zeng",
        "Chao Yu",
        "Xinyi Yang",
        "Wenxuan Ao",
        "Qianyue Hao",
        "Jian Yuan",
        "Yong Li",
        "Yu Wang",
        "Huazhong Yang"
      ],
      "abstract": "The increasingly severe congestion problem in modern cities strengthens the\nsignificance of developing city-scale traffic signal control (TSC) methods for\ntraffic efficiency enhancement. While reinforcement learning has been widely\nexplored in TSC, most of them still target small-scale optimization and cannot\ndirectly scale to the city level due to unbearable resource demand. Only a few\nof them manage to tackle city-level optimization, namely a thousand-scale\noptimization, by incorporating parameter-sharing mechanisms, but hardly have\nthey fully tackled the heterogeneity of intersections and intricate\nbetween-intersection interactions inherent in real-world city road networks. To\nfill in the gap, we target at the two important challenges in adopting\nparameter-sharing paradigms to solve TSC: inconsistency of inner state\nrepresentations for intersections heterogeneous in configuration, scale, and\norders of available traffic phases; intricacy of impacts from neighborhood\nintersections that have various relative traffic relationships due to\ninconsistent phase orders and diverse relative positioning. Our method,\nCityLight, features a universal representation module that not only aligns the\nstate representations of intersections by reindexing their phases based on\ntheir semantics and designing heterogeneity-preserving observations, but also\nencodes the narrowed relative traffic relation types to project the\nneighborhood intersections onto a uniform relative traffic impact space. We\nfurther attentively fuse neighborhood representations based on their competing\nrelations and incorporate neighborhood-integrated rewards to boost\ncoordination. Extensive experiments with hundreds to tens of thousands of\nintersections validate the surprising effectiveness and generalizability of\nCityLight, with an overall performance gain of 11.68% and a 22.59% improvement\nin transfer scenarios in throughput.",
      "tldr_zh": "该研究针对现代城市交通拥堵问题，提出了一种通用模型CityLight，用于城市规模的协调交通信号控制(TSC)，以处理异构路口和复杂路口间交互的挑战。CityLight 通过参数-sharing机制，设计了一个通用表示模块来对齐路口状态表示，包括基于语义重新索引相位、保留异构性的观察，以及编码相对交通关系以投影邻近路口的统一影响空间；同时，它利用注意力机制融合邻近表示并整合奖励以提升协调。实验在数百到数万个路口的场景中验证了CityLight的有效性，整体吞吐量提高了11.68%，在转移场景中提升了22.59%。",
      "categories": [
        "eess.SY",
        "cs.AI",
        "cs.LG",
        "cs.MA",
        "cs.SY"
      ],
      "primary_category": "eess.SY",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2406.02126v3",
      "published_date": "2024-06-04 09:10:14 UTC",
      "updated_date": "2024-08-29 02:00:25 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-18T16:08:58.620996"
    },
    {
      "arxiv_id": "2406.02638v2",
      "title": "EchoMamba4Rec: Harmonizing Bidirectional State Space Models with Spectral Filtering for Advanced Sequential Recommendation",
      "title_zh": "翻译失败",
      "authors": [
        "Yuda Wang",
        "Xuxin He",
        "Shengxin Zhu"
      ],
      "abstract": "Predicting user preferences and sequential dependencies based on historical\nbehavior is the core goal of sequential recommendation. Although\nattention-based models have shown effectiveness in this field, they often\nstruggle with inference inefficiency due to the quadratic computational\ncomplexity inherent in attention mechanisms, especially with long-range\nbehavior sequences. Drawing inspiration from the recent advancements of state\nspace models (SSMs) in control theory, which provide a robust framework for\nmodeling and controlling dynamic systems, we introduce EchoMamba4Rec. Control\ntheory emphasizes the use of SSMs for managing long-range dependencies and\nmaintaining inferential efficiency through structured state matrices.\nEchoMamba4Rec leverages these control relationships in sequential\nrecommendation and integrates bi-directional processing with frequency-domain\nfiltering to capture complex patterns and dependencies in user interaction data\nmore effectively. Our model benefits from the ability of state space models\n(SSMs) to learn and perform parallel computations, significantly enhancing\ncomputational efficiency and scalability. It features a bi-directional Mamba\nmodule that incorporates both forward and reverse Mamba components, leveraging\ninformation from both past and future interactions. Additionally, a filter\nlayer operates in the frequency domain using learnable Fast Fourier Transform\n(FFT) and learnable filters, followed by an inverse FFT to refine item\nembeddings and reduce noise. We also integrate Gate Linear Units (GLU) to\ndynamically control information flow, enhancing the model's expressiveness and\ntraining stability. Experimental results demonstrate that EchoMamba\nsignificantly outperforms existing models, providing more accurate and\npersonalized recommendations.",
      "tldr_zh": "这篇论文提出 EchoMamba4Rec，一种基于状态空间模型 (SSMs) 的序列推荐框架，旨在解决注意力机制在处理长序列时的二次计算复杂性和效率问题。模型整合双向 Mamba 模块、频域过滤（利用 Fast Fourier Transform (FFT) 和可学习过滤器）以及 Gate Linear Units (GLU)，以有效捕捉用户交互数据的复杂模式和依赖关系，提升计算效率和可扩展性。实验结果显示，EchoMamba4Rec 显著优于现有模型，提供更准确和个性化的推荐。",
      "categories": [
        "cs.LG",
        "cs.AI"
      ],
      "primary_category": "cs.LG",
      "comment": "arXiv admin note: text overlap with arXiv:2403.03900 by other authors",
      "pdf_url": "http://arxiv.org/pdf/2406.02638v2",
      "published_date": "2024-06-04 09:07:58 UTC",
      "updated_date": "2024-06-10 17:22:33 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-18T16:09:08.729162"
    },
    {
      "arxiv_id": "2406.03402v3",
      "title": "Mixed-Precision Federated Learning via Multi-Precision Over-The-Air Aggregation",
      "title_zh": "通过多精度空中聚合的混合精度联邦学习",
      "authors": [
        "Jinsheng Yuan",
        "Zhuangkun Wei",
        "Weisi Guo"
      ],
      "abstract": "Over-the-Air Federated Learning (OTA-FL) is a privacy-preserving distributed\nlearning mechanism, by aggregating updates in the electromagnetic channel\nrather than at the server. A critical research gap in existing OTA-FL research\nis the assumption of homogeneous client computational bit precision. While in\nreal world application, clients with varying hardware resources may exploit\napproximate computing (AxC) to operate at different bit precisions optimized\nfor energy and computational efficiency. And model updates of various\nprecisions amongst clients poses an open challenge for OTA-FL, as it is\nincompatible in the wireless modulation superposition. Here, we propose an\nmixed-precision OTA-FL framework of clients with multiple bit precisions,\ndemonstrating the following innovations: (i) the superior trade-off for both\nserver and clients within the constraints of varying edge computing\ncapabilities, energy efficiency, and learning accuracy requirements comparing\nto homogeneous client bit precision, and (ii) a multi-precision gradient\nmodulation scheme to ensure compatibility with OTA aggregation and eliminate\nthe overheads of precision conversion. Through case study with real world data,\nwe validate our modulation scheme that enables AxC based mixed-precision\nOTA-FL. In comparison to homogeneous standard precision of 32-bit and 16-bit,\nour framework presents more than 10% in 4-bit ultra low precision client\nperformance and over 65%and 13% of energy savings respectively. This\ndemonstrates the great potential of our mixed-precision OTA-FL approach in\nheterogeneous edge computing environments.",
      "tldr_zh": "该论文提出了一种混合精度 Over-The-Air Federated Learning (OTA-FL) 框架，旨在解决客户端位精度不一致的问题，该问题源于真实环境中硬件资源差异导致的近似计算 (AxC)。框架引入多精度梯度调制方案，确保不同精度的模型更新兼容无线调制叠加，并消除精度转换开销，同时在边缘计算能力、能源效率和学习准确性之间实现优越权衡。与同质 32-bit 和 16-bit 精度相比，实验在真实数据上验证了该方法在 4-bit 超低精度客户端的性能提升超过 10%，并分别实现 65% 和 13% 的能源节省，从而展示了其在异构边缘计算环境中的潜力。",
      "categories": [
        "cs.LG",
        "cs.AI"
      ],
      "primary_category": "cs.LG",
      "comment": "Accepted by WCNC 2025",
      "pdf_url": "http://arxiv.org/pdf/2406.03402v3",
      "published_date": "2024-06-04 09:07:45 UTC",
      "updated_date": "2025-02-26 14:21:21 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-18T16:09:22.027055"
    },
    {
      "arxiv_id": "2406.07573v1",
      "title": "Investigating the Potential of Using Large Language Models for Scheduling",
      "title_zh": "探讨使用大型语言模型进行调度的潜力",
      "authors": [
        "Deddy Jobson",
        "Yilin Li"
      ],
      "abstract": "The inaugural ACM International Conference on AI-powered Software introduced\nthe AIware Challenge, prompting researchers to explore AI-driven tools for\noptimizing conference programs through constrained optimization. We investigate\nthe use of Large Language Models (LLMs) for program scheduling, focusing on\nzero-shot learning and integer programming to measure paper similarity. Our\nstudy reveals that LLMs, even under zero-shot settings, create reasonably good\nfirst drafts of conference schedules. When clustering papers, using only titles\nas LLM inputs produces results closer to human categorization than using titles\nand abstracts with TFIDF. The code has been made publicly available.",
      "tldr_zh": "本文研究了使用大型语言模型 (LLMs) 在会议调度中的潜力，聚焦于零样本学习 (zero-shot learning) 和整数规划 (integer programming) 来评估论文相似性。研究发现，即使在零样本设置下，LLMs 也能生成合理的会议时间表初稿。相比使用标题和摘要的 TFIDF 方法，仅使用论文标题作为 LLM 输入的聚类结果更接近人类分类。该代码已公开可用，以促进进一步研究。",
      "categories": [
        "cs.AI",
        "cs.LG"
      ],
      "primary_category": "cs.AI",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2406.07573v1",
      "published_date": "2024-06-04 08:56:56 UTC",
      "updated_date": "2024-06-04 08:56:56 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-18T16:09:33.669144"
    },
    {
      "arxiv_id": "2406.02110v1",
      "title": "UniOQA: A Unified Framework for Knowledge Graph Question Answering with Large Language Models",
      "title_zh": "翻译失败",
      "authors": [
        "Zhuoyang Li",
        "Liran Deng",
        "Hui Liu",
        "Qiaoqiao Liu",
        "Junzhao Du"
      ],
      "abstract": "OwnThink stands as the most extensive Chinese open-domain knowledge graph\nintroduced in recent times. Despite prior attempts in question answering over\nOwnThink (OQA), existing studies have faced limitations in model representation\ncapabilities, posing challenges in further enhancing overall accuracy in\nquestion answering. In this paper, we introduce UniOQA, a unified framework\nthat integrates two complementary parallel workflows. Unlike conventional\napproaches, UniOQA harnesses large language models (LLMs) for precise question\nanswering and incorporates a direct-answer-prediction process as a\ncost-effective complement. Initially, to bolster representation capacity, we\nfine-tune an LLM to translate questions into the Cypher query language (CQL),\ntackling issues associated with restricted semantic understanding and\nhallucinations. Subsequently, we introduce the Entity and Relation Replacement\nalgorithm to ensure the executability of the generated CQL. Concurrently, to\naugment overall accuracy in question answering, we further adapt the\nRetrieval-Augmented Generation (RAG) process to the knowledge graph.\nUltimately, we optimize answer accuracy through a dynamic decision algorithm.\nExperimental findings illustrate that UniOQA notably advances SpCQL Logical\nAccuracy to 21.2% and Execution Accuracy to 54.9%, achieving the new\nstate-of-the-art results on this benchmark. Through ablation experiments, we\ndelve into the superior representation capacity of UniOQA and quantify its\nperformance breakthrough.",
      "tldr_zh": "本论文提出UniOQA，一种统一的框架，用于利用大型语言模型（LLMs）进行知识图谱问答，针对OwnThink数据集的问题回答准确性问题。UniOQA整合了两个互补工作流，包括微调LLMs将问题转化为Cypher query language (CQL)，并通过Entity and Relation Replacement算法确保CQL的可执行性，同时适应Retrieval-Augmented Generation (RAG)过程和动态决策算法来提升整体准确率。实验结果显示，UniOQA在SpCQL Logical Accuracy上达到21.2%、Execution Accuracy上达到54.9%，实现了该基准的新状态-of-the-art表现，并通过消融实验验证了其优越的表示能力。",
      "categories": [
        "cs.CL",
        "cs.AI"
      ],
      "primary_category": "cs.CL",
      "comment": "10 pages, 5 figures",
      "pdf_url": "http://arxiv.org/pdf/2406.02110v1",
      "published_date": "2024-06-04 08:36:39 UTC",
      "updated_date": "2024-06-04 08:36:39 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-18T16:09:45.363082"
    },
    {
      "arxiv_id": "2406.06577v1",
      "title": "RAG-based Crowdsourcing Task Decomposition via Masked Contrastive Learning with Prompts",
      "title_zh": "翻译失败",
      "authors": [
        "Jing Yang",
        "Xiao Wang",
        "Yu Zhao",
        "Yuhang Liu",
        "Fei-Yue Wang"
      ],
      "abstract": "Crowdsourcing is a critical technology in social manufacturing, which\nleverages an extensive and boundless reservoir of human resources to handle a\nwide array of complex tasks. The successful execution of these complex tasks\nrelies on task decomposition (TD) and allocation, with the former being a\nprerequisite for the latter. Recently, pre-trained language models (PLMs)-based\nmethods have garnered significant attention. However, they are constrained to\nhandling straightforward common-sense tasks due to their inherent restrictions\ninvolving limited and difficult-to-update knowledge as well as the presence of\nhallucinations. To address these issues, we propose a retrieval-augmented\ngeneration-based crowdsourcing framework that reimagines TD as event detection\nfrom the perspective of natural language understanding. However, the existing\ndetection methods fail to distinguish differences between event types and\nalways depend on heuristic rules and external semantic analyzing tools.\nTherefore, we present a Prompt-Based Contrastive learning framework for TD\n(PBCT), which incorporates a prompt-based trigger detector to overcome\ndependence. Additionally, trigger-attentive sentinel and masked contrastive\nlearning are introduced to provide varying attention to trigger and contextual\nfeatures according to different event types. Experiment results demonstrate the\ncompetitiveness of our method in both supervised and zero-shot detection. A\ncase study on printed circuit board manufacturing is showcased to validate its\nadaptability to unknown professional domains.",
      "tldr_zh": "本论文提出了一种基于检索增强生成（RAG）的众包任务分解框架，将任务分解（TD）视为事件检测，以解决预训练语言模型（PLMs）在处理复杂任务时存在的知识限制和幻觉（hallucinations）问题。框架引入Prompt-Based Contrastive learning framework for TD (PBCT)，包括prompt-based trigger detector、trigger-attentive sentinel和masked contrastive learning，以区分不同事件类型并减少对启发式规则的依赖。实验结果显示，该方法在监督和零样本检测中表现出色，并在印刷电路板制造的案例研究中验证了其适应未知专业领域的潜力。",
      "categories": [
        "cs.CL",
        "cs.AI"
      ],
      "primary_category": "cs.CL",
      "comment": "13 pages, 9 figures",
      "pdf_url": "http://arxiv.org/pdf/2406.06577v1",
      "published_date": "2024-06-04 08:34:19 UTC",
      "updated_date": "2024-06-04 08:34:19 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-18T16:09:57.714800"
    },
    {
      "arxiv_id": "2406.02105v3",
      "title": "Can Kernel Methods Explain How the Data Affects Neural Collapse?",
      "title_zh": "核方法能解释数据如何影响神经网络崩溃吗？",
      "authors": [
        "Vignesh Kothapalli",
        "Tom Tirer"
      ],
      "abstract": "A vast amount of literature has recently focused on the \"Neural Collapse\"\n(NC) phenomenon, which emerges when training neural network (NN) classifiers\nbeyond the zero training error point. The core component of NC is the decrease\nin the within-class variability of the network's deepest features, dubbed as\nNC1. The theoretical works that study NC are typically based on simplified\nunconstrained features models (UFMs) that mask any effect of the data on the\nextent of collapse. To address this limitation of UFMs, this paper explores the\npossibility of analyzing NC1 using kernels associated with shallow NNs. We\nbegin by formulating an NC1 metric as a function of the kernel. Then, we\nspecialize it to the NN Gaussian Process kernel (NNGP) and the Neural Tangent\nKernel (NTK), associated with wide networks at initialization and during\ngradient-based training with a small learning rate, respectively. As a key\nresult, we show that the NTK does not represent more collapsed features than\nthe NNGP for Gaussian data of arbitrary dimensions. This showcases the\nlimitations of data-independent kernels such as NTK in approximating the NC\nbehavior of NNs. As an alternative to NTK, we then empirically explore a\nrecently proposed data-aware Gaussian Process kernel, which generalizes NNGP to\nmodel feature learning. We show that this kernel yields lower NC1 than NNGP but\nmay not follow the trends of the shallow NN. Our study demonstrates that\nadaptivity to data may allow kernel-based analysis of NC, though further\nadvancements in this area are still needed. A nice byproduct of our study is\nshowing both theoretically and empirically that the choice of nonlinear\nactivation function affects NC1 (with ERF yielding lower values than ReLU). The\ncode is available at: https://github.com/kvignesh1420/shallow_nc1",
      "tldr_zh": "这篇论文探讨了核方法是否能解释数据如何影响神经网络的 Neural Collapse (NC) 现象，特别是 NC1（类内变异性减少）。作者使用 NN Gaussian Process kernel (NNGP) 和 Neural Tangent Kernel (NTK) 来量化 NC1，发现 NTK 在高斯数据上并不比 NNGP 更能表示特征崩溃，从而突显了数据无关核的局限性。作为替代，他们探索了数据感知的 Gaussian Process 核，该核能降低 NC1 但可能不完全遵循浅层神经网络的趋势。研究还证明，非线性激活函数的选择（如 ERF 比 ReLU）会影响 NC1 的程度，并提供了相关代码以供验证。",
      "categories": [
        "cs.LG",
        "cs.AI",
        "cs.IT",
        "math.IT",
        "stat.ML"
      ],
      "primary_category": "cs.LG",
      "comment": "Transactions on Machine Learning Research (TMLR)",
      "pdf_url": "http://arxiv.org/pdf/2406.02105v3",
      "published_date": "2024-06-04 08:33:56 UTC",
      "updated_date": "2025-04-25 06:43:34 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-18T16:10:11.724901"
    },
    {
      "arxiv_id": "2406.02103v1",
      "title": "A Bayesian Approach to Online Planning",
      "title_zh": "贝叶斯方法在在线规划中的应用",
      "authors": [
        "Nir Greshler",
        "David Ben Eli",
        "Carmel Rabinovitz",
        "Gabi Guetta",
        "Liran Gispan",
        "Guy Zohar",
        "Aviv Tamar"
      ],
      "abstract": "The combination of Monte Carlo tree search and neural networks has\nrevolutionized online planning. As neural network approximations are often\nimperfect, we ask whether uncertainty estimates about the network outputs could\nbe used to improve planning. We develop a Bayesian planning approach that\nfacilitates such uncertainty quantification, inspired by classical ideas from\nthe meta-reasoning literature. We propose a Thompson sampling based algorithm\nfor searching the tree of possible actions, for which we prove the first (to\nour knowledge) finite time Bayesian regret bound, and propose an efficient\nimplementation for a restricted family of posterior distributions. In addition\nwe propose a variant of the Bayes-UCB method applied to trees. Empirically, we\ndemonstrate that on the ProcGen Maze and Leaper environments, when the\nuncertainty estimates are accurate but the neural network output is inaccurate,\nour Bayesian approach searches the tree much more effectively. In addition, we\ninvestigate whether popular uncertainty estimation methods are accurate enough\nto yield significant gains in planning. Our code is available at:\nhttps://github.com/nirgreshler/bayesian-online-planning.",
      "tldr_zh": "这篇论文提出了一种Bayesian方法来改进在线规划，通过利用神经网络输出的不确定性估计（如Monte Carlo tree search的扩展），受meta-reasoning文献启发。作者开发了基于Thompson sampling的算法，并首次证明了其有限时间Bayesian regret bound，同时提出了一种Bayes-UCB方法的变体，用于更有效地搜索行动树。在ProcGen Maze和Leaper环境中，实验结果显示，当神经网络输出不准确但不确定性估计准确时，该方法显著提升了规划性能，为实际应用提供了潜在改进。",
      "categories": [
        "cs.AI"
      ],
      "primary_category": "cs.AI",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2406.02103v1",
      "published_date": "2024-06-04 08:33:17 UTC",
      "updated_date": "2024-06-04 08:33:17 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-18T16:10:20.634918"
    },
    {
      "arxiv_id": "2406.02092v1",
      "title": "MaskSR: Masked Language Model for Full-band Speech Restoration",
      "title_zh": "MaskSR：用于全频带语音恢复的掩码语言模型",
      "authors": [
        "Xu Li",
        "Qirui Wang",
        "Xiaoyu Liu"
      ],
      "abstract": "Speech restoration aims at restoring high quality speech in the presence of a\ndiverse set of distortions. Although several deep learning paradigms have been\nstudied for this task, the power of the recently emerging language models has\nnot been fully explored. In this paper, we propose MaskSR, a masked language\nmodel capable of restoring full-band 44.1 kHz speech jointly considering noise,\nreverb, clipping, and low bandwidth. MaskSR works with discrete acoustic tokens\nextracted using a pre-trained neural codec. During training, MaskSR is\noptimized to predict randomly masked tokens extracted from the high quality\ntarget speech, conditioned on the corrupted speech with various distortions.\nDuring inference, MaskSR reconstructs the target speech tokens with efficient\niterative sampling. Extensive experiments show that MaskSR obtains competitive\nresults on both the full-band speech restoration task and also on sub-tasks\ncompared with a wide range of models.",
      "tldr_zh": "这篇论文提出了 MaskSR，一种 Masked Language Model，用于全频带 44.1 kHz 语音恢复，旨在同时处理噪声、混响、剪切和低带宽等失真问题。MaskSR 通过预训练的神经编解码器提取离散声学 tokens，在训练中优化预测随机 masked 的目标语音 tokens，并以损坏语音作为条件；在推理阶段，使用高效的迭代采样重建高质量语音。实验结果表明，MaskSR 在全频带语音恢复任务及子任务上，与多种基准模型相比，取得了竞争性的性能表现。",
      "categories": [
        "cs.SD",
        "cs.AI",
        "cs.LG",
        "eess.AS",
        "eess.SP"
      ],
      "primary_category": "cs.SD",
      "comment": "Accepted by INTERSPEECH 2024. Demo page:\n  https://masksr.github.io/MaskSR/",
      "pdf_url": "http://arxiv.org/pdf/2406.02092v1",
      "published_date": "2024-06-04 08:23:57 UTC",
      "updated_date": "2024-06-04 08:23:57 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-18T16:10:32.877302"
    },
    {
      "arxiv_id": "2406.02090v2",
      "title": "WEIRD ICWSM: How Western, Educated, Industrialized, Rich, and Democratic is Social Computing Research?",
      "title_zh": "翻译失败",
      "authors": [
        "Ali Akbar Septiandri",
        "Marios Constantinides",
        "Daniele Quercia"
      ],
      "abstract": "Much of the research in social computing analyzes data from social media\nplatforms, which may inherently carry biases. An overlooked source of such bias\nis the over-representation of WEIRD (Western, Educated, Industrialized, Rich,\nand Democratic) populations, which might not accurately mirror the global\ndemographic diversity. We evaluated the dependence on WEIRD populations in\nresearch presented at the AAAI ICWSM conference; the only venue whose\nproceedings are fully dedicated to social computing research. We did so by\nanalyzing 494 papers published from 2018 to 2022, which included full research\npapers, dataset papers and posters. After filtering out papers that analyze\nsynthetic datasets or those lacking clear country of origin, we were left with\n420 papers from which 188 participants in a crowdsourcing study with full\nmanual validation extracted data for the WEIRD scores computation. This data\nwas then used to adapt existing WEIRD metrics to be applicable for social media\ndata. We found that 37% of these papers focused solely on data from Western\ncountries. This percentage is significantly less than the percentages observed\nin research from CHI (76%) and FAccT (84%) conferences, suggesting a greater\ndiversity of dataset origins within ICWSM. However, the studies at ICWSM still\npredominantly examine populations from countries that are more Educated,\nIndustrialized, and Rich in comparison to those in FAccT, with a special note\non the 'Democratic' variable reflecting political freedoms and rights. This\npoints out the utility of social media data in shedding light on findings from\ncountries with restricted political freedoms. Based on these insights, we\nrecommend extensions of current \"paper checklists\" to include considerations\nabout the WEIRD bias and call for the community to broaden research inclusivity\nby encouraging the use of diverse datasets from underrepresented regions.",
      "tldr_zh": "本研究评估了社会计算研究中对 WEIRD（Western, Educated, Industrialized, Rich, and Democratic）人口的依赖，通过分析2018-2022年AAAI ICWSM会议的494篇论文（过滤后420篇），并使用众包研究计算WEIRD分数。结果显示，37%的论文仅关注西方国家的数据，比CHI（76%）和FAccT（84%）会议更具多样性，但ICWSM研究仍主要涉及教育、工业化和富裕的国家，并在“Democratic”方面突出政治自由的重要性。研究指出，社会媒体数据有助于探索政治自由受限的国家，并推荐扩展论文检查清单以考虑WEIRD偏差，并鼓励使用来自欠发达地区的多样数据集，以提升研究包容性。",
      "categories": [
        "cs.HC",
        "cs.AI"
      ],
      "primary_category": "cs.HC",
      "comment": "11 pages, 2 figures, 7 tables",
      "pdf_url": "http://arxiv.org/pdf/2406.02090v2",
      "published_date": "2024-06-04 08:17:47 UTC",
      "updated_date": "2024-06-11 13:34:09 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-18T16:10:45.021188"
    },
    {
      "arxiv_id": "2406.18576v1",
      "title": "Negative Prototypes Guided Contrastive Learning for WSOD",
      "title_zh": "负原型引导的对比学习用于 WSOD",
      "authors": [
        "Yu Zhang",
        "Chuang Zhu",
        "Guoqing Yang",
        "Siqi Chen"
      ],
      "abstract": "Weakly Supervised Object Detection (WSOD) with only image-level annotation\nhas recently attracted wide attention. Many existing methods ignore the\ninter-image relationship of instances which share similar characteristics while\ncan certainly be determined not to belong to the same category. Therefore, in\norder to make full use of the weak label, we propose the Negative Prototypes\nGuided Contrastive learning (NPGC) architecture. Firstly, we define Negative\nPrototype as the proposal with the highest confidence score misclassified for\nthe category that does not appear in the label. Unlike other methods that only\nutilize category positive feature, we construct an online updated global\nfeature bank to store both positive prototypes and negative prototypes.\nMeanwhile, we propose a pseudo label sampling module to mine reliable instances\nand discard the easily misclassified instances based on the feature similarity\nwith corresponding prototypes in global feature bank. Finally, we follow the\ncontrastive learning paradigm to optimize the proposal's feature representation\nby attracting same class samples closer and pushing different class samples\naway in the embedding space. Extensive experiments have been conducted on\nVOC07, VOC12 datasets, which shows that our proposed method achieves the\nstate-of-the-art performance.",
      "tldr_zh": "本文提出 Negative Prototypes Guided Contrastive Learning (NPGC) 框架，用于改进 Weakly Supervised Object Detection (WSOD)，通过利用图像级标签来处理实例间关系问题。NPGC 定义 Negative Prototype 为最高置信度错误分类的提案，并构建在线更新的全局特征库存储正负原型，同时引入伪标签采样模块基于特征相似度筛选可靠实例。最终，通过对比学习范式优化提案特征表示，使同类样本靠近、异类样本远离。实验在 VOC07 和 VOC12 数据集上显示，该方法实现了 state-of-the-art 性能。",
      "categories": [
        "cs.CV",
        "cs.AI"
      ],
      "primary_category": "cs.CV",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2406.18576v1",
      "published_date": "2024-06-04 08:16:26 UTC",
      "updated_date": "2024-06-04 08:16:26 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-18T16:10:59.201048"
    },
    {
      "arxiv_id": "2406.02081v2",
      "title": "FightLadder: A Benchmark for Competitive Multi-Agent Reinforcement Learning",
      "title_zh": "FightLadder：竞争性多智能体强化学习的基准",
      "authors": [
        "Wenzhe Li",
        "Zihan Ding",
        "Seth Karten",
        "Chi Jin"
      ],
      "abstract": "Recent advances in reinforcement learning (RL) heavily rely on a variety of\nwell-designed benchmarks, which provide environmental platforms and consistent\ncriteria to evaluate existing and novel algorithms. Specifically, in\nmulti-agent RL (MARL), a plethora of benchmarks based on cooperative games have\nspurred the development of algorithms that improve the scalability of\ncooperative multi-agent systems. However, for the competitive setting, a\nlightweight and open-sourced benchmark with challenging gaming dynamics and\nvisual inputs has not yet been established. In this work, we present\nFightLadder, a real-time fighting game platform, to empower competitive MARL\nresearch. Along with the platform, we provide implementations of\nstate-of-the-art MARL algorithms for competitive games, as well as a set of\nevaluation metrics to characterize the performance and exploitability of\nagents. We demonstrate the feasibility of this platform by training a general\nagent that consistently defeats 12 built-in characters in single-player mode,\nand expose the difficulty of training a non-exploitable agent without human\nknowledge and demonstrations in two-player mode. FightLadder provides\nmeticulously designed environments to address critical challenges in\ncompetitive MARL research, aiming to catalyze a new era of discovery and\nadvancement in the field. Videos and code at\nhttps://sites.google.com/view/fightladder/home.",
      "tldr_zh": "这篇论文引入了FightLadder，一个轻量级开源基准平台，针对竞争性多智能体强化学习(MARL)，以实时格斗游戏为基础，提供视觉输入和挑战性的游戏动态。平台包括MARL算法实现和一组评估指标，用于衡量代理的性能和可利用性。实验结果显示，训练的通用代理在单人模式下能击败12个内置角色，但在两人模式中，难以训练出非可利用代理，而无需依赖人类知识或演示。该基准旨在解决竞争MARL中的关键挑战，推动该领域的创新和发展。",
      "categories": [
        "cs.MA",
        "cs.AI",
        "cs.LG"
      ],
      "primary_category": "cs.MA",
      "comment": "ICML 2024",
      "pdf_url": "http://arxiv.org/pdf/2406.02081v2",
      "published_date": "2024-06-04 08:04:23 UTC",
      "updated_date": "2024-06-24 03:38:46 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-18T16:11:10.877883"
    },
    {
      "arxiv_id": "2406.02080v1",
      "title": "LongSSM: On the Length Extension of State-space Models in Language Modelling",
      "title_zh": "翻译失败",
      "authors": [
        "Shida Wang"
      ],
      "abstract": "In this paper, we investigate the length-extension of state-space models\n(SSMs) in language modeling. Length extension involves training models on short\nsequences and testing them on longer ones. We show that state-space models\ntrained with zero hidden states initialization have difficulty doing length\nextension. We explain this difficulty by pointing out the length extension is\nequivalent to polynomial extrapolation. Based on the theory, we propose a\nsimple yet effective method - changing the hidden states initialization scheme\n- to improve the length extension. Moreover, our method shows that using long\ntraining sequence length is beneficial but not necessary to length extension.\nChanging the hidden state initialization enables the efficient training of\nlong-memory model with a smaller training context length.",
      "tldr_zh": "本研究探讨了状态空间模型 (SSMs) 在语言建模中的长度扩展问题，即在短序列上训练模型后测试其在长序列上的性能。研究发现，使用零隐藏状态初始化的 SSMs 难以实现长度扩展，因为这等同于多项式外推。作者提出了一种简单方法——改变隐藏状态初始化方案——来显著改善这一问题，同时证明使用较长的训练序列虽有益但非必需，从而实现高效训练长记忆模型。实验结果表明，此方法使模型能够在较小训练上下文长度下有效扩展。",
      "categories": [
        "cs.CL",
        "cs.AI",
        "cs.LG",
        "math.DS"
      ],
      "primary_category": "cs.CL",
      "comment": "23 pages",
      "pdf_url": "http://arxiv.org/pdf/2406.02080v1",
      "published_date": "2024-06-04 08:02:39 UTC",
      "updated_date": "2024-06-04 08:02:39 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-18T16:11:22.935979"
    },
    {
      "arxiv_id": "2406.02078v1",
      "title": "A Toolbox for Supporting Research on AI in Water Distribution Networks",
      "title_zh": "翻译失败",
      "authors": [
        "André Artelt",
        "Marios S. Kyriakou",
        "Stelios G. Vrachimis",
        "Demetrios G. Eliades",
        "Barbara Hammer",
        "Marios M. Polycarpou"
      ],
      "abstract": "Drinking water is a vital resource for humanity, and thus, Water Distribution\nNetworks (WDNs) are considered critical infrastructures in modern societies.\nThe operation of WDNs is subject to diverse challenges such as water leakages\nand contamination, cyber/physical attacks, high energy consumption during pump\noperation, etc. With model-based methods reaching their limits due to various\nuncertainty sources, AI methods offer promising solutions to those challenges.\nIn this work, we introduce a Python toolbox for complex scenario modeling \\&\ngeneration such that AI researchers can easily access challenging problems from\nthe drinking water domain. Besides providing a high-level interface for the\neasy generation of hydraulic and water quality scenario data, it also provides\neasy access to popular event detection benchmarks and an environment for\ndeveloping control algorithms.",
      "tldr_zh": "该论文介绍了用于支持AI在水分配网络(Water Distribution Networks, WDNs)研究的一个Python工具箱，旨在解决WDNs面临的挑战，如水漏泄、污染、攻击和高能耗问题，因为传统模型方法受不确定性限制。工具箱提供高水平接口，用于生成水力学和水质场景数据，并易于访问流行的事件检测基准和控制算法开发环境。该工具箱使AI研究者能够轻松处理饮用水领域的复杂问题，从而推动AI在关键基础设施中的应用。",
      "categories": [
        "cs.AI",
        "cs.CE",
        "cs.SY",
        "eess.SY"
      ],
      "primary_category": "cs.AI",
      "comment": "Accepted at the Workshop on Artificial Intelligence for Critical\n  Infrastructure (AI4CI 2024) @ IJCAI'24 , Jeju Island, South Korea",
      "pdf_url": "http://arxiv.org/pdf/2406.02078v1",
      "published_date": "2024-06-04 07:58:19 UTC",
      "updated_date": "2024-06-04 07:58:19 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-18T16:11:37.847744"
    },
    {
      "arxiv_id": "2406.02077v3",
      "title": "Multi-target stain normalization for histology slides",
      "title_zh": "翻译失败",
      "authors": [
        "Desislav Ivanov",
        "Carlo Alberto Barbano",
        "Marco Grangetto"
      ],
      "abstract": "Traditional staining normalization approaches, e.g. Macenko, typically rely\non the choice of a single representative reference image, which may not\nadequately account for the diverse staining patterns of datasets collected in\npractical scenarios. In this study, we introduce a novel approach that\nleverages multiple reference images to enhance robustness against stain\nvariation. Our method is parameter-free and can be adopted in existing\ncomputational pathology pipelines with no significant changes. We evaluate the\neffectiveness of our method through experiments using a deep-learning pipeline\nfor automatic nuclei segmentation on colorectal images. Our results show that\nby leveraging multiple reference images, better results can be achieved when\ngeneralizing to external data, where the staining can widely differ from the\ntraining set.",
      "tldr_zh": "本研究针对传统染色标准化方法（如Macenko）依赖单一参考图像的问题，提出了一种多目标染色标准化方法，使用多个参考图像来提升对染色变异的鲁棒性。该方法无参数设计，便于无缝整合到现有的计算病理学管道中。实验通过深度学习管道在结肠图像的自动nuclei segmentation任务中验证，结果显示，该方法在泛化到外部数据集（染色模式与训练集显著不同时）能显著提高性能。",
      "categories": [
        "eess.IV",
        "cs.AI",
        "cs.CV",
        "68U10",
        "I.4.0"
      ],
      "primary_category": "eess.IV",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2406.02077v3",
      "published_date": "2024-06-04 07:57:34 UTC",
      "updated_date": "2024-06-10 07:49:05 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-18T16:11:47.107891"
    },
    {
      "arxiv_id": "2406.02069v4",
      "title": "PyramidKV: Dynamic KV Cache Compression based on Pyramidal Information Funneling",
      "title_zh": "翻译失败",
      "authors": [
        "Zefan Cai",
        "Yichi Zhang",
        "Bofei Gao",
        "Yuliang Liu",
        "Yucheng Li",
        "Tianyu Liu",
        "Keming Lu",
        "Wayne Xiong",
        "Yue Dong",
        "Junjie Hu",
        "Wen Xiao"
      ],
      "abstract": "In this study, we investigate whether attention-based information flow inside\nlarge language models (LLMs) is aggregated through noticeable patterns for long\ncontext processing. Our observations reveal that LLMs aggregate information\nthrough Pyramidal Information Funneling where attention is scattering widely in\nlower layers, progressively consolidating within specific contexts, and\nultimately focusing on critical tokens (a.k.a massive activation or attention\nsink) in higher layers. Motivated by these insights, we developed PyramidKV, a\nnovel and effective KV cache compression method. This approach dynamically\nadjusts the KV cache size across different layers, allocating more cache in\nlower layers and less in higher ones, diverging from traditional methods that\nmaintain a uniform KV cache size. Our experimental evaluations, utilizing the\nLongBench benchmark, show that PyramidKV matches the performance of models with\na full KV cache while retaining only 12% of the KV cache, thus significantly\nreducing memory usage. In scenarios emphasizing memory efficiency, where only\n0.7% of the KV cache is maintained, PyramidKV surpasses other KV cache\ncompression techniques, achieving up to a 20.5 absolute accuracy improvement on\nTREC dataset. In the Needle-in-a-Haystack experiment, PyramidKV outperforms\ncompeting methods in maintaining long-context comprehension in LLMs; notably,\nretaining just 128 KV cache entries enables the LLAMA-3-70B model to achieve\n100.0 Acc. performance.",
      "tldr_zh": "本研究观察到大型语言模型(LLMs)在处理长上下文时，通过Pyramidal Information Funneling模式聚合信息，即注意力从较低层广泛散射到较高层聚焦关键标记。基于此，提出PyramidKV，一种动态KV cache压缩方法，根据层级调整缓存大小，在较低层分配更多资源以优化信息保留。实验在LongBench基准测试中显示，PyramidKV仅保留12% KV cache时即可匹配完整缓存性能；在TREC数据集上，仅用0.7%缓存就比其他方法提高20.5%的准确率。而在Needle-in-a-Haystack实验中，该方法使LLAMA-3-70B模型仅保留128 KV cache条目即可达到100.0%准确率，显著提升内存效率和长上下文理解能力。",
      "categories": [
        "cs.CL",
        "cs.AI"
      ],
      "primary_category": "cs.CL",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2406.02069v4",
      "published_date": "2024-06-04 07:51:30 UTC",
      "updated_date": "2025-05-15 17:18:12 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-18T16:12:02.505661"
    },
    {
      "arxiv_id": "2406.02061v5",
      "title": "Alice in Wonderland: Simple Tasks Showing Complete Reasoning Breakdown in State-Of-the-Art Large Language Models",
      "title_zh": "翻译失败",
      "authors": [
        "Marianna Nezhurina",
        "Lucia Cipolina-Kun",
        "Mehdi Cherti",
        "Jenia Jitsev"
      ],
      "abstract": "Large Language Models (LLMs) are often described as instances of foundation\nmodels that possess strong generalization obeying scaling laws, and therefore\ntransfer robustly across various conditions in few- or zero-shot manner. Such\nclaims rely on standardized benchmarks that suppose to measure generalization\nand reasoning, where state-of-the-art (SOTA) models score high. We demonstrate\nhere a dramatic breakdown of generalization and basic reasoning of all SOTA\nmodels claiming strong function, including large scale advanced models like\nGPT-4 or Claude 3 Opus, using a simple, short common sense math problem\nformulated in concise natural language, easily solvable by humans (AIW\nproblem). The breakdown is dramatic as it manifests on a simple problem in both\nlow average performance and strong performance fluctuations on natural\nvariations in problem template that do not change either problem structure or\nits difficulty at all. By testing models on further control problems with\nsimilar form, we rule out that breakdown might be rooted in minor low-level\nissues like natural language or numbers parsing. We also observe strong\noverconfidence in the wrong solutions, expressed in form of plausible sounding\nexplanation-like confabulations. Various standard interventions in an attempt\nto get the right solution, like chain-of-thought prompting, or urging the\nmodels to reconsider the wrong solutions again by multi step re-evaluation,\nfail. We use these observations to stimulate re-assessment of the capabilities\nof current generation of LLMs as claimed by standardized benchmarks. Such\nre-assessment also requires common action to create standardized benchmarks\nthat would allow proper detection of such deficits in generalization and\nreasoning that obviously remain undiscovered by current state-of-the-art\nevaluation procedures, where SOTA LLMs manage to score high. Code:\nhttps://github.com/LAION-AI/AIW",
      "tldr_zh": "本文揭示了 State-Of-the-Art Large Language Models (SOTA LLMs)，如 GPT-4 和 Claude 3 Opus，在简单常识数学问题 (AIW 问题) 上出现严重的推理崩溃，尽管它们在标准化基准中表现出色。作者通过测试问题变体和控制问题，排除了语言或数字解析等低级因素，并观察到模型表现出过度自信，提供看似合理的错误解释。标准干预如 Chain-of-Thought 提示无效，导致作者呼吁重新评估 LLMs 的泛化能力，并开发新的基准测试以检测此类缺陷。",
      "categories": [
        "cs.LG",
        "cs.AI",
        "cs.CL"
      ],
      "primary_category": "cs.LG",
      "comment": "v3.0. Control experiments, further AIW problem versions, testing\n  recent reasoning models. Short version appeared at NeurIPS Scientific Methods\n  for Understanding Deep Learning Workshop (SciDL) 2024,\n  https://openreview.net/forum?id=Mkl7dzjYiW",
      "pdf_url": "http://arxiv.org/pdf/2406.02061v5",
      "published_date": "2024-06-04 07:43:33 UTC",
      "updated_date": "2025-03-05 01:58:08 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-18T16:12:14.255314"
    },
    {
      "arxiv_id": "2406.02060v1",
      "title": "I've got the \"Answer\"! Interpretation of LLMs Hidden States in Question Answering",
      "title_zh": "翻译失败",
      "authors": [
        "Valeriya Goloviznina",
        "Evgeny Kotelnikov"
      ],
      "abstract": "Interpretability and explainability of AI are becoming increasingly important\nin light of the rapid development of large language models (LLMs). This paper\ninvestigates the interpretation of LLMs in the context of the knowledge-based\nquestion answering. The main hypothesis of the study is that correct and\nincorrect model behavior can be distinguished at the level of hidden states.\nThe quantized models LLaMA-2-7B-Chat, Mistral-7B, Vicuna-7B and the MuSeRC\nquestion-answering dataset are used to test this hypothesis. The results of the\nanalysis support the proposed hypothesis. We also identify the layers which\nhave a negative effect on the model's behavior. As a prospect of practical\napplication of the hypothesis, we propose to train such \"weak\" layers\nadditionally in order to improve the quality of the task solution.",
      "tldr_zh": "本研究探讨大型语言模型（LLMs）在知识型问答任务中的可解释性，假设正确和错误的模型行为可在隐藏 states 层面区分。研究使用量化模型 LLaMA-2-7B-Chat、Mistral-7B 和 Vicuna-7B 结合 MuSeRC 数据集进行分析，结果支持该假设，并识别出某些 layers 对模型行为有负面影响。作为实际应用前景，论文建议额外训练这些“弱”layers，以提升任务解决质量。",
      "categories": [
        "cs.CL",
        "cs.AI"
      ],
      "primary_category": "cs.CL",
      "comment": "Accepted for NLDB-2024 conference",
      "pdf_url": "http://arxiv.org/pdf/2406.02060v1",
      "published_date": "2024-06-04 07:43:12 UTC",
      "updated_date": "2024-06-04 07:43:12 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-18T16:12:32.302926"
    },
    {
      "arxiv_id": "2406.02057v1",
      "title": "Tabular and Deep Learning for the Whittle Index",
      "title_zh": "翻译失败",
      "authors": [
        "Francisco Robledo Relaño",
        "Vivek Borkar",
        "Urtzi Ayesta",
        "Konstantin Avrachenkov"
      ],
      "abstract": "The Whittle index policy is a heuristic that has shown remarkably good\nperformance (with guaranteed asymptotic optimality) when applied to the class\nof problems known as Restless Multi-Armed Bandit Problems (RMABPs). In this\npaper we present QWI and QWINN, two reinforcement learning algorithms,\nrespectively tabular and deep, to learn the Whittle index for the total\ndiscounted criterion. The key feature is the use of two time-scales, a faster\none to update the state-action Q -values, and a relatively slower one to update\nthe Whittle indices. In our main theoretical result we show that QWI, which is\na tabular implementation, converges to the real Whittle indices. We then\npresent QWINN, an adaptation of QWI algorithm using neural networks to compute\nthe Q -values on the faster time-scale, which is able to extrapolate\ninformation from one state to another and scales naturally to large state-space\nenvironments. For QWINN, we show that all local minima of the Bellman error are\nlocally stable equilibria, which is the first result of its kind for DQN-based\nschemes. Numerical computations show that QWI and QWINN converge faster than\nthe standard Q -learning algorithm, neural-network based approximate Q-learning\nand other state of the art algorithms.",
      "tldr_zh": "本论文提出两种强化学习算法，QWI 和 QWINN，用于学习 Whittle index 在 Restless Multi-Armed Bandit Problems (RMABPs) 中的总折扣标准。QWI 采用表格实现，通过双时间尺度更新状态-动作 Q 值和 Whittle indices，并理论证明其收敛到真实 Whittle indices。QWINN 基于神经网络扩展 QWI，能处理大型状态空间，并证明其 Bellman 误差的所有局部最小值是局部稳定平衡点。实验结果显示，QWI 和 QWINN 比标准 Q-learning 和其他算法收敛更快，提供了一种高效的方法来优化 Whittle index 策略。",
      "categories": [
        "cs.AI",
        "cs.LG"
      ],
      "primary_category": "cs.AI",
      "comment": "ACM Transactions on Modeling and Performance Evaluation of Computing\n  Systems, 2024",
      "pdf_url": "http://arxiv.org/pdf/2406.02057v1",
      "published_date": "2024-06-04 07:41:15 UTC",
      "updated_date": "2024-06-04 07:41:15 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-18T16:12:37.170728"
    },
    {
      "arxiv_id": "2406.02040v2",
      "title": "DFA-GNN: Forward Learning of Graph Neural Networks by Direct Feedback Alignment",
      "title_zh": "翻译失败",
      "authors": [
        "Gongpei Zhao",
        "Tao Wang",
        "Congyan Lang",
        "Yi Jin",
        "Yidong Li",
        "Haibin Ling"
      ],
      "abstract": "Graph neural networks are recognized for their strong performance across\nvarious applications, with the backpropagation algorithm playing a central role\nin the development of most GNN models. However, despite its effectiveness, BP\nhas limitations that challenge its biological plausibility and affect the\nefficiency, scalability and parallelism of training neural networks for\ngraph-based tasks. While several non-BP training algorithms, such as the direct\nfeedback alignment, have been successfully applied to fully-connected and\nconvolutional network components for handling Euclidean data, directly adapting\nthese non-BP frameworks to manage non-Euclidean graph data in GNN models\npresents significant challenges. These challenges primarily arise from the\nviolation of the i.i.d. assumption in graph data and the difficulty in\naccessing prediction errors for all samples (nodes) within the graph. To\novercome these obstacles, in this paper we propose DFA-GNN, a novel forward\nlearning framework tailored for GNNs with a case study of semi-supervised\nlearning. The proposed method breaks the limitations of BP by using a dedicated\nforward training mechanism. Specifically, DFA-GNN extends the principles of DFA\nto adapt to graph data and unique architecture of GNNs, which incorporates the\ninformation of graph topology into the feedback links to accommodate the\nnon-Euclidean characteristics of graph data. Additionally, for semi-supervised\ngraph learning tasks, we developed a pseudo error generator that spreads\nresidual errors from training data to create a pseudo error for each unlabeled\nnode. These pseudo errors are then utilized to train GNNs using DFA. Extensive\nexperiments on 10 public benchmarks reveal that our learning framework\noutperforms not only previous non-BP methods but also the standard BP methods,\nand it exhibits excellent robustness against various types of noise and\nattacks.",
      "tldr_zh": "该论文提出 DFA-GNN，一种基于 Direct Feedback Alignment (DFA) 的前向学习框架，用于训练 Graph Neural Networks (GNNs)，以克服 Backpropagation (BP) 在处理非欧空间图数据时的效率和可扩展性问题。DFA-GNN 通过将图拓扑信息融入反馈链接，并为半监督学习任务开发伪错误生成器，将残差错误传播到未标记节点，从而适应图数据的非独立同分布 (non-i.i.d.) 特性。实验在 10 个公共基准上显示，DFA-GNN 不仅优于传统 BP 和其他非 BP 方法，还表现出色抗噪声和攻击的鲁棒性。",
      "categories": [
        "cs.LG",
        "cs.AI"
      ],
      "primary_category": "cs.LG",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2406.02040v2",
      "published_date": "2024-06-04 07:24:51 UTC",
      "updated_date": "2024-11-05 14:00:37 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-18T16:12:47.043217"
    },
    {
      "arxiv_id": "2406.02035v1",
      "title": "A Unifying Framework for Action-Conditional Self-Predictive Reinforcement Learning",
      "title_zh": "翻译失败",
      "authors": [
        "Khimya Khetarpal",
        "Zhaohan Daniel Guo",
        "Bernardo Avila Pires",
        "Yunhao Tang",
        "Clare Lyle",
        "Mark Rowland",
        "Nicolas Heess",
        "Diana Borsa",
        "Arthur Guez",
        "Will Dabney"
      ],
      "abstract": "Learning a good representation is a crucial challenge for Reinforcement\nLearning (RL) agents. Self-predictive learning provides means to jointly learn\na latent representation and dynamics model by bootstrapping from future latent\nrepresentations (BYOL). Recent work has developed theoretical insights into\nthese algorithms by studying a continuous-time ODE model for self-predictive\nrepresentation learning under the simplifying assumption that the algorithm\ndepends on a fixed policy (BYOL-$\\Pi$); this assumption is at odds with\npractical instantiations of such algorithms, which explicitly condition their\npredictions on future actions. In this work, we take a step towards bridging\nthe gap between theory and practice by analyzing an action-conditional\nself-predictive objective (BYOL-AC) using the ODE framework, characterizing its\nconvergence properties and highlighting important distinctions between the\nlimiting solutions of the BYOL-$\\Pi$ and BYOL-AC dynamics. We show how the two\nrepresentations are related by a variance equation. This connection leads to a\nnovel variance-like action-conditional objective (BYOL-VAR) and its\ncorresponding ODE. We unify the study of all three objectives through two\ncomplementary lenses; a model-based perspective, where each objective is shown\nto be equivalent to a low-rank approximation of certain dynamics, and a\nmodel-free perspective, which establishes relationships between the objectives\nand their respective value, Q-value, and advantage function. Our empirical\ninvestigations, encompassing both linear function approximation and Deep RL\nenvironments, demonstrates that BYOL-AC is better overall in a variety of\ndifferent settings.",
      "tldr_zh": "这篇论文提出一个统一的框架，用于行动条件下的自预测强化学习（RL），扩展了 BYOL 算法到 BYOL-AC，以更好地学习表示和动态模型。作者使用 ODE 框架分析了 BYOL-AC 的收敛特性，揭示了它与 BYOL-Π 的差异，并通过方差方程引入了新的 BYOL-VAR 目标，从模型和无模型视角统一了这些目标的等价性及其与价值函数的关系。实验结果显示，BYOL-AC 在线性函数逼近和深度 RL 环境中表现出色，整体优于基线方法。",
      "categories": [
        "cs.LG",
        "cs.AI"
      ],
      "primary_category": "cs.LG",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2406.02035v1",
      "published_date": "2024-06-04 07:22:12 UTC",
      "updated_date": "2024-06-04 07:22:12 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-18T16:13:12.200017"
    },
    {
      "arxiv_id": "2406.02030v2",
      "title": "Multimodal Reasoning with Multimodal Knowledge Graph",
      "title_zh": "翻译失败",
      "authors": [
        "Junlin Lee",
        "Yequan Wang",
        "Jing Li",
        "Min Zhang"
      ],
      "abstract": "Multimodal reasoning with large language models (LLMs) often suffers from\nhallucinations and the presence of deficient or outdated knowledge within LLMs.\nSome approaches have sought to mitigate these issues by employing textual\nknowledge graphs, but their singular modality of knowledge limits comprehensive\ncross-modal understanding. In this paper, we propose the Multimodal Reasoning\nwith Multimodal Knowledge Graph (MR-MKG) method, which leverages multimodal\nknowledge graphs (MMKGs) to learn rich and semantic knowledge across\nmodalities, significantly enhancing the multimodal reasoning capabilities of\nLLMs. In particular, a relation graph attention network is utilized for\nencoding MMKGs and a cross-modal alignment module is designed for optimizing\nimage-text alignment. A MMKG-grounded dataset is constructed to equip LLMs with\ninitial expertise in multimodal reasoning through pretraining. Remarkably,\nMR-MKG achieves superior performance while training on only a small fraction of\nparameters, approximately 2.25% of the LLM's parameter size. Experimental\nresults on multimodal question answering and multimodal analogy reasoning tasks\ndemonstrate that our MR-MKG method outperforms previous state-of-the-art\nmodels.",
      "tldr_zh": "该论文提出MR-MKG方法，利用多模态知识图谱(MMKGs)来解决大型语言模型(LLMs)在多模态推理中的幻觉问题和知识不足，通过学习跨模态的丰富语义知识来提升LLMs的推理能力。方法包括relation graph attention network用于编码MMKGs，以及cross-modal alignment module来优化图像-文本对齐。研究者构建了一个基于MMKG的训练数据集，通过预训练使LLMs获得多模态推理的专业知识，且仅需训练LLMs参数的2.25%即可实现高效性能。在多模态问答和类比推理任务的实验中，MR-MKG超过了现有最先进模型，证明了其有效性。",
      "categories": [
        "cs.CL",
        "cs.AI"
      ],
      "primary_category": "cs.CL",
      "comment": "Accepted by ACL 2024 (Main Conference)",
      "pdf_url": "http://arxiv.org/pdf/2406.02030v2",
      "published_date": "2024-06-04 07:13:23 UTC",
      "updated_date": "2024-06-05 03:28:01 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-18T16:13:14.220673"
    },
    {
      "arxiv_id": "2406.02027v2",
      "title": "Inference Attacks: A Taxonomy, Survey, and Promising Directions",
      "title_zh": "推断攻击：一个分类法、综述及有前景的方向",
      "authors": [
        "Feng Wu",
        "Lei Cui",
        "Shaowen Yao",
        "Shui Yu"
      ],
      "abstract": "The prosperity of machine learning has also brought people's concerns about\ndata privacy. Among them, inference attacks can implement privacy breaches in\nvarious MLaaS scenarios and model training/prediction phases. Specifically,\ninference attacks can perform privacy inference on undisclosed target training\nsets based on outputs of the target model, including but not limited to\nstatistics, membership, semantics, data representation, etc. For instance,\ninfer whether the target data has the characteristics of AIDS. In addition, the\nrapid development of the machine learning community in recent years, especially\nthe surge of model types and application scenarios, has further stimulated the\ninference attacks' research. Thus, studying inference attacks and analyzing\nthem in depth is urgent and significant. However, there is still a gap in the\nsystematic discussion of inference attacks from taxonomy, global perspective,\nattack, and defense perspectives. This survey provides an in-depth and\ncomprehensive inference of attacks and corresponding countermeasures in\nML-as-a-service based on taxonomy and the latest researches. Without\ncompromising researchers' intuition, we first propose the 3MP taxonomy based on\nthe community research status, trying to normalize the confusing naming system\nof inference attacks. Also, we analyze the pros and cons of each type of\ninference attack, their workflow, countermeasure, and how they interact with\nother attacks. In the end, we point out several promising directions for\nresearchers from a more comprehensive and novel perspective.",
      "tldr_zh": "这篇论文系统地调查了机器学习中的推理攻击（inference attacks），聚焦于其在 ML-as-a-service 场景中的隐私泄露问题，包括统计、成员资格、语义和数据表示等方面的攻击类型。作者提出了 3MP taxonomy 框架，以规范攻击的命名系统，并分析了每种攻击的优缺点、工作流程、防御措施以及与其他攻击的交互关系。最终，论文指出了几个 promising directions，为未来研究提供更全面的视角和创新思路。",
      "categories": [
        "cs.LG",
        "cs.AI",
        "cs.CR",
        "cs.CV"
      ],
      "primary_category": "cs.LG",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2406.02027v2",
      "published_date": "2024-06-04 07:06:06 UTC",
      "updated_date": "2024-06-27 05:47:55 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-18T16:13:23.554694"
    },
    {
      "arxiv_id": "2406.02021v2",
      "title": "FFNet: MetaMixer-based Efficient Convolutional Mixer Design",
      "title_zh": "FFNet: 基于 MetaMixer 的高效卷积混合器设计",
      "authors": [
        "Seokju Yun",
        "Dongheon Lee",
        "Youngmin Ro"
      ],
      "abstract": "Transformer, composed of self-attention and Feed-Forward Network, has\nrevolutionized the landscape of network design across various vision tasks.\nWhile self-attention is extensively explored as a key factor in performance,\nFFN has received little attention. FFN is a versatile operator seamlessly\nintegrated into nearly all AI models to effectively harness rich\nrepresentations. Recent works also show that FFN functions like key-value\nmemories. Thus, akin to the query-key-value mechanism within self-attention,\nFFN can be viewed as a memory network, where the input serves as query and the\ntwo projection weights operate as keys and values, respectively. Based on these\nobservations, we hypothesize that the importance lies in query-key-value\nframework itself for competitive performance. To verify this, we propose\nconverting self-attention into a more FFN-like efficient token mixer with only\nconvolutions while retaining query-key-value framework, namely FFNification.\nSpecifically, FFNification replaces query-key-value interactions with large\nkernel convolutions and adopts GELU activation function instead of softmax. The\nderived token mixer, FFNified attention, serves as key-value memories for\ndetecting locally distributed spatial patterns, and operates in the opposite\ndimension to the ConvNeXt block within each corresponding sub-operation of the\nquery-key-value framework. Building upon the above two modules, we present a\nfamily of Fast-Forward Networks (FFNet). Despite being composed of only simple\noperators, FFNet outperforms sophisticated and highly specialized methods in\neach domain, with notable efficiency gains. These results validate our\nhypothesis, leading us to propose MetaMixer, a general mixer architecture that\ndoes not specify sub-operations within the query-key-value framework.",
      "tldr_zh": "该论文探讨了Transformer模型中Feed-Forward Network (FFN)的作用，将其视为类似query-key-value机制的内存网络，并假设这一框架是性能的关键。为验证此假设，研究提出FFNification方法，使用大内核convolutions替换query-key-value交互，并采用GELU激活函数，构建了高效的token mixer。最终，基于这些模块开发了Fast-Forward Networks (FFNet)系列，该网络仅依赖简单操作器，却在多个视觉任务中超越复杂专业方法，并显著提升效率；此外，论文引入MetaMixer作为通用混合器架构，进一步推广query-key-value框架的应用。",
      "categories": [
        "cs.CV",
        "cs.AI",
        "cs.LG"
      ],
      "primary_category": "cs.CV",
      "comment": "Code: https://github.com/ysj9909/FFNet",
      "pdf_url": "http://arxiv.org/pdf/2406.02021v2",
      "published_date": "2024-06-04 07:00:14 UTC",
      "updated_date": "2025-03-10 05:09:16 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-18T16:13:38.105854"
    },
    {
      "arxiv_id": "2406.02018v2",
      "title": "Why Would You Suggest That? Human Trust in Language Model Responses",
      "title_zh": "翻译失败",
      "authors": [
        "Manasi Sharma",
        "Ho Chit Siu",
        "Rohan Paleja",
        "Jaime D. Peña"
      ],
      "abstract": "The emergence of Large Language Models (LLMs) has revealed a growing need for\nhuman-AI collaboration, especially in creative decision-making scenarios where\ntrust and reliance are paramount. Through human studies and model evaluations\non the open-ended News Headline Generation task from the LaMP benchmark, we\nanalyze how the framing and presence of explanations affect user trust and\nmodel performance. Overall, we provide evidence that adding an explanation in\nthe model response to justify its reasoning significantly increases\nself-reported user trust in the model when the user has the opportunity to\ncompare various responses. Position and faithfulness of these explanations are\nalso important factors. However, these gains disappear when users are shown\nresponses independently, suggesting that humans trust all model responses,\nincluding deceptive ones, equitably when they are shown in isolation. Our\nfindings urge future research to delve deeper into the nuanced evaluation of\ntrust in human-machine teaming systems.",
      "tldr_zh": "本研究探讨了大型语言模型 (LLMs) 在人类-AI 协作中的信任问题，特别是创意决策场景，如 News Headline Generation 任务。研究通过人类实验和模型评估发现，添加解释来证明模型推理能显著提升用户信任，尤其是当用户能比较多个响应时，而解释的位置和真实性（faithfulness）是关键因素。然而，当响应独立呈现时，这种信任提升会消失，用户对所有响应（包括欺骗性 ones）表现出平等信任。该发现呼吁未来研究更深入评估人类-机器团队系统中信任的细微动态。",
      "categories": [
        "cs.CL",
        "cs.AI",
        "cs.HC"
      ],
      "primary_category": "cs.CL",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2406.02018v2",
      "published_date": "2024-06-04 06:57:47 UTC",
      "updated_date": "2024-10-04 16:46:00 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-18T16:13:48.711857"
    },
    {
      "arxiv_id": "2407.11985v1",
      "title": "A Novel Implementation of Marksheet Parser Using PaddleOCR",
      "title_zh": "翻译失败",
      "authors": [
        "Sankalp Bagaria",
        "S Irene",
        "Harikrishnan",
        "Elakia V M"
      ],
      "abstract": "When an applicant files an online application, there is usually a requirement\nto fill the marks in the online form and also upload the marksheet in the\nportal for the verification. A system was built for reading the uploaded\nmarksheet using OCR and automatically filling the rows/ columns in the online\nform. Though there are partial solutions to this problem - implemented using\nPyTesseract - the accuracy is low. Hence, the PaddleOCR was used to build the\nmarksheet parser. Several pre-processing and post-processing steps were also\nperformed. The system was tested and evaluated for seven states. Further work\nis being done and the system is being evaluated for more states and boards of\nIndia.",
      "tldr_zh": "该研究提出了一种新型成绩单解析器，使用 PaddleOCR 技术来自动读取上传的成绩单并填充在线申请表格，解决了传统 PyTesseract 方法的低准确率问题。通过加入预处理和后处理步骤，该系统在七个印度的州进行了测试，并显示出显著的性能提升。未来工作将扩展到更多州和教育委员会，以进一步完善该系统。",
      "categories": [
        "cs.HC",
        "cs.AI"
      ],
      "primary_category": "cs.HC",
      "comment": "5 pages, 1 figure, 1 table",
      "pdf_url": "http://arxiv.org/pdf/2407.11985v1",
      "published_date": "2024-06-04 06:51:03 UTC",
      "updated_date": "2024-06-04 06:51:03 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-18T16:13:59.205508"
    },
    {
      "arxiv_id": "2406.02006v1",
      "title": "ODE-based Learning to Optimize",
      "title_zh": "基于常微分方程的学习优化",
      "authors": [
        "Zhonglin Xie",
        "Wotao Yin",
        "Zaiwen Wen"
      ],
      "abstract": "Recent years have seen a growing interest in understanding acceleration\nmethods through the lens of ordinary differential equations (ODEs). Despite the\ntheoretical advancements, translating the rapid convergence observed in\ncontinuous-time models to discrete-time iterative methods poses significant\nchallenges. In this paper, we present a comprehensive framework integrating the\ninertial systems with Hessian-driven damping equation (ISHD) and learning-based\napproaches for developing optimization methods through a deep synergy of\ntheoretical insights. We first establish the convergence condition for ensuring\nthe convergence of the solution trajectory of ISHD. Then, we show that provided\nthe stability condition, another relaxed requirement on the coefficients of\nISHD, the sequence generated through the explicit Euler discretization of ISHD\nconverges, which gives a large family of practical optimization methods. In\norder to select the best optimization method in this family for certain\nproblems, we introduce the stopping time, the time required for an optimization\nmethod derived from ISHD to achieve a predefined level of suboptimality. Then,\nwe formulate a novel learning to optimize (L2O) problem aimed at minimizing the\nstopping time subject to the convergence and stability condition. To navigate\nthis learning problem, we present an algorithm combining stochastic\noptimization and the penalty method (StoPM). The convergence of StoPM using the\nconservative gradient is proved. Empirical validation of our framework is\nconducted through extensive numerical experiments across a diverse set of\noptimization problems. These experiments showcase the superior performance of\nthe learned optimization methods.",
      "tldr_zh": "本论文提出一个整合惯性系统与Hessian驱动阻尼方程(ISHD)的框架，通过ODEs理论与学习方法相结合，开发优化算法以实现快速收敛。研究者首先建立了ISHD解决方案轨迹的收敛条件，并证明在稳定性条件下，其显式Euler离散化序列收敛，从而生成一系列实用优化方法。为针对特定问题选择最佳方法，他们引入停止时间概念，并制定了一个新的学习到优化(L2O)问题，目标是最小化停止时间，同时满足收敛和稳定性约束。论文还提出StoPM算法（结合随机优化和惩罚方法）来解决此L2O问题，并证明其收敛性；实验结果显示，该框架在多种优化问题上表现出优越性能。",
      "categories": [
        "math.OC",
        "cs.AI"
      ],
      "primary_category": "math.OC",
      "comment": "55 pages, 28 figures",
      "pdf_url": "http://arxiv.org/pdf/2406.02006v1",
      "published_date": "2024-06-04 06:39:45 UTC",
      "updated_date": "2024-06-04 06:39:45 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-18T16:14:15.833593"
    },
    {
      "arxiv_id": "2406.02002v1",
      "title": "Position Debiasing Fine-Tuning for Causal Perception in Long-Term Dialogue",
      "title_zh": "翻译失败",
      "authors": [
        "Shixuan Fan",
        "Wei Wei",
        "Wendi Li",
        "Xian-Ling Mao",
        "Wenfeng Xie",
        "Dangyang Chen"
      ],
      "abstract": "The core of the dialogue system is to generate relevant, informative, and\nhuman-like responses based on extensive dialogue history. Recently, dialogue\ngeneration domain has seen mainstream adoption of large language models (LLMs),\ndue to its powerful capability in generating utterances. However, there is a\nnatural deficiency for such models, that is, inherent position bias, which may\nlead them to pay more attention to the nearby utterances instead of causally\nrelevant ones, resulting in generating irrelevant and generic responses in\nlong-term dialogue. To alleviate such problem, in this paper, we propose a\nnovel method, named Causal Perception long-term Dialogue framework (CPD), which\nemploys perturbation-based causal variable discovery method to extract casually\nrelevant utterances from the dialogue history and enhances model causal\nperception during fine-tuning. Specifically, a local-position awareness method\nis proposed in CPD for inter-sentence position correlation elimination, which\nhelps models extract causally relevant utterances based on perturbations. Then,\na casual-perception fine-tuning strategy is also proposed, to enhance the\ncapability of discovering the causal invariant factors, by differently\nperturbing causally relevant and non-casually relevant ones for response\ngeneration. Experimental results on two datasets prove that our proposed method\ncan effectively alleviate the position bias for multiple LLMs and achieve\nsignificant progress compared with existing baselines.",
      "tldr_zh": "这篇论文针对大语言模型 (LLMs) 在长期对话中存在的固有位置偏差 (position bias) 问题，提出了一种新框架 Causal Perception long-term Dialogue framework (CPD)，旨在帮助模型更关注因果相关的对话而非附近语句，从而生成更相关和信息丰富的响应。CPD 采用基于扰动的因果变量发现方法，从对话历史中提取因果相关语句，并引入本地位置感知方法 (local-position awareness method) 来消除句子间位置相关性。论文还设计了因果感知微调策略 (casual-perception fine-tuning strategy)，通过对因果相关和非相关语句进行不同扰动，增强模型对因果不变因素的识别能力。实验结果显示，该方法在两个数据集上显著缓解了多种 LLMs 的位置偏差，并取得了比现有基线更好的性能。",
      "categories": [
        "cs.CL",
        "cs.AI"
      ],
      "primary_category": "cs.CL",
      "comment": "Accepted to IJCAI 2024",
      "pdf_url": "http://arxiv.org/pdf/2406.02002v1",
      "published_date": "2024-06-04 06:33:13 UTC",
      "updated_date": "2024-06-04 06:33:13 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-18T16:14:27.516180"
    },
    {
      "arxiv_id": "2406.02636v1",
      "title": "Strengthening Network Intrusion Detection in IoT Environments with Self-Supervised Learning and Few Shot Learning",
      "title_zh": "翻译失败",
      "authors": [
        "Safa Ben Atitallah",
        "Maha Driss",
        "Wadii Boulila",
        "Anis Koubaa"
      ],
      "abstract": "The Internet of Things (IoT) has been introduced as a breakthrough technology\nthat integrates intelligence into everyday objects, enabling high levels of\nconnectivity between them. As the IoT networks grow and expand, they become\nmore susceptible to cybersecurity attacks. A significant challenge in current\nintrusion detection systems for IoT includes handling imbalanced datasets where\nlabeled data are scarce, particularly for new and rare types of cyber attacks.\nExisting literature often fails to detect such underrepresented attack classes.\nThis paper introduces a novel intrusion detection approach designed to address\nthese challenges. By integrating Self Supervised Learning (SSL), Few Shot\nLearning (FSL), and Random Forest (RF), our approach excels in learning from\nlimited and imbalanced data and enhancing detection capabilities. The approach\nstarts with a Deep Infomax model trained to extract key features from the\ndataset. These features are then fed into a prototypical network to generate\ndiscriminate embedding. Subsequently, an RF classifier is employed to detect\nand classify potential malware, including a range of attacks that are\nfrequently observed in IoT networks. The proposed approach was evaluated\nthrough two different datasets, MaleVis and WSN-DS, which demonstrate its\nsuperior performance with accuracies of 98.60% and 99.56%, precisions of 98.79%\nand 99.56%, recalls of 98.60% and 99.56%, and F1-scores of 98.63% and 99.56%,\nrespectively.",
      "tldr_zh": "这篇论文针对物联网（IoT）环境中网络入侵检测的挑战，提出了一种新方法来处理数据不平衡和标签稀缺问题，特别是针对 underrepresented attack classes。该方法整合了 Self-Supervised Learning (SSL)、Few Shot Learning (FSL) 和 Random Forest (RF)，首先使用 Deep Infomax 模型提取关键特征，然后通过 prototypical network 生成判别嵌入，最后采用 RF 分类器进行攻击检测。在 MaleVis 和 WSN-DS 数据集上的实验显示，该方法分别达到了 98.60% 和 99.56% 的准确率，以及高精度、召回率和 F1-score，显著提升了入侵检测的性能。",
      "categories": [
        "cs.CR",
        "cs.AI"
      ],
      "primary_category": "cs.CR",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2406.02636v1",
      "published_date": "2024-06-04 06:30:22 UTC",
      "updated_date": "2024-06-04 06:30:22 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-18T16:14:38.119862"
    },
    {
      "arxiv_id": "2406.01996v1",
      "title": "Bayesian Mesh Optimization for Graph Neural Networks to Enhance Engineering Performance Prediction",
      "title_zh": "翻译失败",
      "authors": [
        "Jangseop Park",
        "Namwoo Kang"
      ],
      "abstract": "In engineering design, surrogate models are widely employed to replace\ncomputationally expensive simulations by leveraging design variables and\ngeometric parameters from computer-aided design (CAD) models. However, these\nmodels often lose critical information when simplified to lower dimensions and\nface challenges in parameter definition, especially with the complex 3D shapes\ncommonly found in industrial datasets. To address these limitations, we propose\na Bayesian graph neural network (GNN) framework for a 3D deep-learning-based\nsurrogate model that predicts engineering performance by directly learning\ngeometric features from CAD using mesh representation. Our framework determines\nthe optimal size of mesh elements through Bayesian optimization, resulting in a\nhigh-accuracy surrogate model. Additionally, it effectively handles the\nirregular and complex structures of 3D CADs, which differ significantly from\nthe regular and uniform pixel structures of 2D images typically used in deep\nlearning. Experimental results demonstrate that the quality of the mesh\nsignificantly impacts the prediction accuracy of the surrogate model, with an\noptimally sized mesh achieving superior performance. We compare the performance\nof models based on various 3D representations such as voxel, point cloud, and\ngraph, and evaluate the computational costs of Monte Carlo simulation and\nBayesian optimization methods to find the optimal mesh size. We anticipate that\nour proposed framework has the potential to be applied to mesh-based\nsimulations across various engineering fields, leveraging physics-based\ninformation commonly used in computer-aided engineering.",
      "tldr_zh": "在工程设计中，代理模型常因简化复杂3D形状而丢失关键信息和参数定义挑战，本文提出一种Bayesian GNN框架，使用网格表示从CAD模型直接学习几何特征，以提升工程性能预测准确性。框架通过Bayesian optimization优化网格元素大小，有效处理不规则的3D结构，并与体素、点云和图等表示方法进行了比较。实验结果表明，优化网格显著提高了预测精度，并降低了计算成本。该框架具有潜力应用于各种工程领域的网格模拟中。",
      "categories": [
        "cs.LG",
        "cs.AI",
        "cs.CV",
        "cs.GR"
      ],
      "primary_category": "cs.LG",
      "comment": "17 pages, 8 figures, 3 tables",
      "pdf_url": "http://arxiv.org/pdf/2406.01996v1",
      "published_date": "2024-06-04 06:27:48 UTC",
      "updated_date": "2024-06-04 06:27:48 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-18T16:14:49.568855"
    },
    {
      "arxiv_id": "2406.01988v1",
      "title": "Personalized Topic Selection Model for Topic-Grounded Dialogue",
      "title_zh": "针对主题导向对话的个性化主题选择模型",
      "authors": [
        "Shixuan Fan",
        "Wei Wei",
        "Xiaofei Wen",
        "Xianling Mao",
        "Jixiong Chen",
        "Dangyang Chen"
      ],
      "abstract": "Recently, the topic-grounded dialogue (TGD) system has become increasingly\npopular as its powerful capability to actively guide users to accomplish\nspecific tasks through topic-guided conversations. Most existing works utilize\nside information (\\eg topics or personas) in isolation to enhance the topic\nselection ability. However, due to disregarding the noise within these\nauxiliary information sources and their mutual influence, current models tend\nto predict user-uninteresting and contextually irrelevant topics. To build\nuser-engaging and coherent dialogue agent, we propose a \\textbf{P}ersonalized\ntopic s\\textbf{E}lection model for \\textbf{T}opic-grounded \\textbf{D}ialogue,\nnamed \\textbf{PETD}, which takes account of the interaction of side information\nto selectively aggregate such information for more accurately predicting\nsubsequent topics. Specifically, we evaluate the correlation between global\ntopics and personas and selectively incorporate the global topics aligned with\nuser personas. Furthermore, we propose a contrastive learning based persona\nselector to filter out irrelevant personas under the constraint of lacking\npertinent persona annotations. Throughout the selection and generation, diverse\nrelevant side information is considered. Extensive experiments demonstrate that\nour proposed method can generate engaging and diverse responses, outperforming\nstate-of-the-art baselines across various evaluation metrics.",
      "tldr_zh": "本研究针对主题导向对话（Topic-Grounded Dialogue, TGD）系统提出了一种个性化主题选择模型PETD，以解决现有方法忽略辅助信息（如主题和人物设定）中的噪声和相互影响，导致对话主题不吸引人或不相关的问题。PETD 通过评估全局主题与用户人物设定的相关性，选择性地整合一致的辅助信息，并引入基于对比学习（contrastive learning）的人物选择器来过滤无关人物设定，从而生成更连贯和多样化的对话。实验结果显示，PETD 在各种评估指标上优于现有基线模型，能显著提升用户参与度和对话质量。",
      "categories": [
        "cs.CL",
        "cs.AI"
      ],
      "primary_category": "cs.CL",
      "comment": "Accepted to ACL 2024 Findings",
      "pdf_url": "http://arxiv.org/pdf/2406.01988v1",
      "published_date": "2024-06-04 06:09:49 UTC",
      "updated_date": "2024-06-04 06:09:49 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-18T16:15:03.069959"
    },
    {
      "arxiv_id": "2406.01981v2",
      "title": "Zyda: A 1.3T Dataset for Open Language Modeling",
      "title_zh": "翻译失败",
      "authors": [
        "Yury Tokpanov",
        "Beren Millidge",
        "Paolo Glorioso",
        "Jonathan Pilault",
        "Adam Ibrahim",
        "James Whittington",
        "Quentin Anthony"
      ],
      "abstract": "The size of large language models (LLMs) has scaled dramatically in recent\nyears and their computational and data requirements have surged\ncorrespondingly. State-of-the-art language models, even at relatively smaller\nsizes, typically require training on at least a trillion tokens. This rapid\nadvancement has eclipsed the growth of open-source datasets available for\nlarge-scale LLM pretraining. In this paper, we introduce Zyda (Zyphra Dataset),\na dataset under a permissive license comprising 1.3 trillion tokens, assembled\nby integrating several major respected open-source datasets into a single,\nhigh-quality corpus. We apply rigorous filtering and deduplication processes,\nboth within and across datasets, to maintain and enhance the quality derived\nfrom the original datasets. Our evaluations show that Zyda not only competes\nfavorably with other open datasets like Dolma, FineWeb, and RefinedWeb, but\nalso substantially improves the performance of comparable models from the\nPythia suite. Our rigorous data processing methods significantly enhance Zyda's\neffectiveness, outperforming even the best of its constituent datasets when\nused independently.",
      "tldr_zh": "本文介绍了 Zyda，一个包含 1.3 万亿 tokens 的开源数据集，旨在满足大型语言模型 (LLMs) 预训练的庞大数据需求。Zyda 通过整合多个主要开源数据集，并应用严格的过滤和去重处理，确保了数据集的高质量和有效性。评估结果显示，Zyda 在性能上优于 Dolma、FineWeb 和 RefinedWeb 等数据集，并显著提升了 Pythia 系列模型的表现，即使单独使用也超过了其组成部分。",
      "categories": [
        "cs.CL",
        "cs.AI"
      ],
      "primary_category": "cs.CL",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2406.01981v2",
      "published_date": "2024-06-04 05:47:17 UTC",
      "updated_date": "2024-09-03 19:11:11 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-18T16:15:14.847821"
    },
    {
      "arxiv_id": "2406.02635v2",
      "title": "Evidentially Calibrated Source-Free Time-Series Domain Adaptation with Temporal Imputation",
      "title_zh": "翻译失败",
      "authors": [
        "Mohamed Ragab",
        "Peiliang Gong",
        "Emadeldeen Eldele",
        "Wenyu Zhang",
        "Min Wu",
        "Chuan-Sheng Foo",
        "Daoqiang Zhang",
        "Xiaoli Li",
        "Zhenghua Chen"
      ],
      "abstract": "Source-free domain adaptation (SFDA) aims to adapt a model pre-trained on a\nlabeled source domain to an unlabeled target domain without access to source\ndata, preserving the source domain's privacy. While SFDA is prevalent in\ncomputer vision, it remains largely unexplored in time series analysis.\nExisting SFDA methods, designed for visual data, struggle to capture the\ninherent temporal dynamics of time series, hindering adaptation performance.\nThis paper proposes MAsk And imPUte (MAPU), a novel and effective approach for\ntime series SFDA. MAPU addresses the critical challenge of temporal consistency\nby introducing a novel temporal imputation task. This task involves randomly\nmasking time series signals and leveraging a dedicated temporal imputer to\nrecover the original signal within the learned embedding space, bypassing the\ncomplexities of noisy raw data. Notably, MAPU is the first method to explicitly\naddress temporal consistency in the context of time series SFDA. Additionally,\nit offers seamless integration with existing SFDA methods, providing greater\nflexibility. We further introduce E-MAPU, which incorporates evidential\nuncertainty estimation to address the overconfidence issue inherent in softmax\npredictions. To achieve that, we leverage evidential deep learning to obtain a\nbetter-calibrated pre-trained model and adapt the target encoder to map\nout-of-support target samples to a new feature representation closer to the\nsource domain's support. This fosters better alignment, ultimately enhancing\nadaptation performance. Extensive experiments on five real-world time series\ndatasets demonstrate that both MAPU and E-MAPU achieve significant performance\ngains compared to existing methods. These results highlight the effectiveness\nof our proposed approaches for tackling various time series domain adaptation\nproblems.",
      "tldr_zh": "本论文探讨了Source-Free Domain Adaptation (SFDA)在时间序列分析中的应用，针对现有方法无法捕捉时间序列的temporal dynamics问题，提出了一种新颖方法MAsk And imPUte (MAPU)。MAPU通过引入temporal imputation任务，即随机masking时间序列信号并在embedding space中使用temporal imputer恢复原始信号，从而提升temporal consistency，并能无缝整合现有SFDA方法。进一步，E-MAPU整合evidential uncertainty estimation和evidential deep learning，改进模型校准并调整目标编码器，使目标样本更接近源域，支持。实验在五个真实世界时间序列数据集上显示，MAPU和E-MAPU相较现有方法实现了显著性能提升，证明了其在时间序列域适配问题上的有效性。",
      "categories": [
        "cs.LG",
        "cs.AI"
      ],
      "primary_category": "cs.LG",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2406.02635v2",
      "published_date": "2024-06-04 05:36:29 UTC",
      "updated_date": "2024-06-13 03:08:23 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-18T16:15:28.203882"
    },
    {
      "arxiv_id": "2406.01970v1",
      "title": "The Crystal Ball Hypothesis in diffusion models: Anticipating object positions from initial noise",
      "title_zh": "翻译失败",
      "authors": [
        "Yuanhao Ban",
        "Ruochen Wang",
        "Tianyi Zhou",
        "Boqing Gong",
        "Cho-Jui Hsieh",
        "Minhao Cheng"
      ],
      "abstract": "Diffusion models have achieved remarkable success in text-to-image generation\ntasks; however, the role of initial noise has been rarely explored. In this\nstudy, we identify specific regions within the initial noise image, termed\ntrigger patches, that play a key role for object generation in the resulting\nimages. Notably, these patches are ``universal'' and can be generalized across\nvarious positions, seeds, and prompts. To be specific, extracting these patches\nfrom one noise and injecting them into another noise leads to object generation\nin targeted areas. We identify these patches by analyzing the dispersion of\nobject bounding boxes across generated images, leading to the development of a\nposterior analysis technique. Furthermore, we create a dataset consisting of\nGaussian noises labeled with bounding boxes corresponding to the objects\nappearing in the generated images and train a detector that identifies these\npatches from the initial noise. To explain the formation of these patches, we\nreveal that they are outliers in Gaussian noise, and follow distinct\ndistributions through two-sample tests. Finally, we find the misalignment\nbetween prompts and the trigger patch patterns can result in unsuccessful image\ngenerations. The study proposes a reject-sampling strategy to obtain optimal\nnoise, aiming to improve prompt adherence and positional diversity in image\ngeneration.",
      "tldr_zh": "本文研究了扩散模型中初始噪声的作用，提出“Crystal Ball Hypothesis”，即通过识别初始噪声图像中的特定区域（trigger patches）来预测和控制生成图像中对象的位置。这些 patches 被证明是高斯噪声中的异常值，能泛化到不同位置、种子和提示，并通过边界框分析、数据集构建和检测器训练来识别和利用。研究发现，提示与 patches 模式的不匹配会导致生成失败，因此引入拒绝采样策略，以提升图像生成的提示遵守性和位置多样性。总体上，该方法为改进文本到图像任务提供了新见解。",
      "categories": [
        "cs.CV",
        "cs.AI"
      ],
      "primary_category": "cs.CV",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2406.01970v1",
      "published_date": "2024-06-04 05:06:00 UTC",
      "updated_date": "2024-06-04 05:06:00 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-18T16:15:40.801015"
    },
    {
      "arxiv_id": "2406.01968v1",
      "title": "Cross-Embodiment Robot Manipulation Skill Transfer using Latent Space Alignment",
      "title_zh": "利用潜在空间对齐的跨实体机器人操控技能转移",
      "authors": [
        "Tianyu Wang",
        "Dwait Bhatt",
        "Xiaolong Wang",
        "Nikolay Atanasov"
      ],
      "abstract": "This paper focuses on transferring control policies between robot\nmanipulators with different morphology. While reinforcement learning (RL)\nmethods have shown successful results in robot manipulation tasks, transferring\na trained policy from simulation to a real robot or deploying it on a robot\nwith different states, actions, or kinematics is challenging. To achieve\ncross-embodiment policy transfer, our key insight is to project the state and\naction spaces of the source and target robots to a common latent space\nrepresentation. We first introduce encoders and decoders to associate the\nstates and actions of the source robot with a latent space. The encoders,\ndecoders, and a latent space control policy are trained simultaneously using\nloss functions measuring task performance, latent dynamics consistency, and\nencoder-decoder ability to reconstruct the original states and actions. To\ntransfer the learned control policy, we only need to train target encoders and\ndecoders that align a new target domain to the latent space. We use generative\nadversarial training with cycle consistency and latent dynamics losses without\naccess to the task reward or reward tuning in the target domain. We demonstrate\nsim-to-sim and sim-to-real manipulation policy transfer with source and target\nrobots of different states, actions, and embodiments. The source code is\navailable at\n\\url{https://github.com/ExistentialRobotics/cross_embodiment_transfer}.",
      "tldr_zh": "本文提出了一种基于潜在空间对齐(Latent Space Alignment)的跨形态机器人操纵技能转移方法，旨在解决强化学习(RL)策略从模拟环境到真实机器人或不同状态/动作/运动学机器人的转移挑战。核心方法包括训练编码器(encoders)和解码器(decoders)将源和目标机器人的状态与动作投影到共同的潜在空间(latent space)，并通过生成对抗训练(generative adversarial training)、循环一致性(cycle consistency)和潜在动态损失(latent dynamics losses)实现转移，而无需目标域的任务奖励。实验验证了该方法在模拟到模拟(sim-to-sim)和模拟到真实(sim-to-real)场景中的有效性，成功处理不同机器人形态的操纵任务。",
      "categories": [
        "cs.RO",
        "cs.AI"
      ],
      "primary_category": "cs.RO",
      "comment": "8 pages, 9 figures",
      "pdf_url": "http://arxiv.org/pdf/2406.01968v1",
      "published_date": "2024-06-04 05:00:24 UTC",
      "updated_date": "2024-06-04 05:00:24 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-18T16:15:53.385001"
    },
    {
      "arxiv_id": "2406.01967v1",
      "title": "DrEureka: Language Model Guided Sim-To-Real Transfer",
      "title_zh": "翻译失败",
      "authors": [
        "Yecheng Jason Ma",
        "William Liang",
        "Hung-Ju Wang",
        "Sam Wang",
        "Yuke Zhu",
        "Linxi Fan",
        "Osbert Bastani",
        "Dinesh Jayaraman"
      ],
      "abstract": "Transferring policies learned in simulation to the real world is a promising\nstrategy for acquiring robot skills at scale. However, sim-to-real approaches\ntypically rely on manual design and tuning of the task reward function as well\nas the simulation physics parameters, rendering the process slow and\nhuman-labor intensive. In this paper, we investigate using Large Language\nModels (LLMs) to automate and accelerate sim-to-real design. Our LLM-guided\nsim-to-real approach, DrEureka, requires only the physics simulation for the\ntarget task and automatically constructs suitable reward functions and domain\nrandomization distributions to support real-world transfer. We first\ndemonstrate that our approach can discover sim-to-real configurations that are\ncompetitive with existing human-designed ones on quadruped locomotion and\ndexterous manipulation tasks. Then, we showcase that our approach is capable of\nsolving novel robot tasks, such as quadruped balancing and walking atop a yoga\nball, without iterative manual design.",
      "tldr_zh": "该论文提出DrEureka，一种由大型语言模型(LLMs)引导的sim-to-real转移方法，旨在自动化机器人技能从模拟环境向真实世界的迁移过程，避免传统方法的手动设计和调优。DrEureka仅需目标任务的物理模拟，就能自动构建合适的任务奖励函数和domain randomization分布，以提升转移效果。实验结果显示，该方法在四足机器人运动和灵巧操作任务上达到与人工设计相当的性能，并成功处理新颖任务，如四足机器人平衡和在瑜伽球上行走，而无需迭代手动干预。",
      "categories": [
        "cs.RO",
        "cs.AI",
        "cs.LG"
      ],
      "primary_category": "cs.RO",
      "comment": "Robotics: Science and Systems (RSS) 2024. Project website and\n  open-source code: https://eureka-research.github.io/dr-eureka/",
      "pdf_url": "http://arxiv.org/pdf/2406.01967v1",
      "published_date": "2024-06-04 04:53:05 UTC",
      "updated_date": "2024-06-04 04:53:05 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-18T16:16:03.472928"
    },
    {
      "arxiv_id": "2406.03404v1",
      "title": "ST-DPGAN: A Privacy-preserving Framework for Spatiotemporal Data Generation",
      "title_zh": "翻译失败",
      "authors": [
        "Wei Shao",
        "Rongyi Zhu",
        "Cai Yang",
        "Chandra Thapa",
        "Muhammad Ejaz Ahmed",
        "Seyit Camtepe",
        "Rui Zhang",
        "DuYong Kim",
        "Hamid Menouar",
        "Flora D. Salim"
      ],
      "abstract": "Spatiotemporal data is prevalent in a wide range of edge devices, such as\nthose used in personal communication and financial transactions. Recent\nadvancements have sparked a growing interest in integrating spatiotemporal\nanalysis with large-scale language models. However, spatiotemporal data often\ncontains sensitive information, making it unsuitable for open third-party\naccess. To address this challenge, we propose a Graph-GAN-based model for\ngenerating privacy-protected spatiotemporal data. Our approach incorporates\nspatial and temporal attention blocks in the discriminator and a spatiotemporal\ndeconvolution structure in the generator. These enhancements enable efficient\ntraining under Gaussian noise to achieve differential privacy. Extensive\nexperiments conducted on three real-world spatiotemporal datasets validate the\nefficacy of our model. Our method provides a privacy guarantee while\nmaintaining the data utility. The prediction model trained on our generated\ndata maintains a competitive performance compared to the model trained on the\noriginal data.",
      "tldr_zh": "该论文提出了 ST-DPGAN，一种基于 Graph-GAN 的隐私保护框架，用于生成时空数据，以解决数据敏感性问题。该框架在鉴别器中整合了空间和时间注意力块，在生成器中采用了时空反卷积结构，并通过高斯噪声实现差分隐私，确保高效训练。在三个真实世界数据集上的广泛实验验证了该方法的有效性，它在提供隐私保证的同时，保持了数据效用，且使用生成数据训练的预测模型性能与原始数据训练的模型相当。",
      "categories": [
        "cs.LG",
        "cs.AI",
        "cs.CR"
      ],
      "primary_category": "cs.LG",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2406.03404v1",
      "published_date": "2024-06-04 04:43:54 UTC",
      "updated_date": "2024-06-04 04:43:54 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-18T16:16:15.677119"
    },
    {
      "arxiv_id": "2406.01960v1",
      "title": "Certifiably Byzantine-Robust Federated Conformal Prediction",
      "title_zh": "翻译失败",
      "authors": [
        "Mintong Kang",
        "Zhen Lin",
        "Jimeng Sun",
        "Cao Xiao",
        "Bo Li"
      ],
      "abstract": "Conformal prediction has shown impressive capacity in constructing\nstatistically rigorous prediction sets for machine learning models with\nexchangeable data samples. The siloed datasets, coupled with the escalating\nprivacy concerns related to local data sharing, have inspired recent\ninnovations extending conformal prediction into federated environments with\ndistributed data samples. However, this framework for distributed uncertainty\nquantification is susceptible to Byzantine failures. A minor subset of\nmalicious clients can significantly compromise the practicality of coverage\nguarantees. To address this vulnerability, we introduce a novel framework\nRob-FCP, which executes robust federated conformal prediction, effectively\ncountering malicious clients capable of reporting arbitrary statistics with the\nconformal calibration process. We theoretically provide the conformal coverage\nbound of Rob-FCP in the Byzantine setting and show that the coverage of Rob-FCP\nis asymptotically close to the desired coverage level. We also propose a\nmalicious client number estimator to tackle a more challenging setting where\nthe number of malicious clients is unknown to the defender and theoretically\nshows its effectiveness. We empirically demonstrate the robustness of Rob-FCP\nagainst diverse proportions of malicious clients under a variety of Byzantine\nattacks on five standard benchmark and real-world healthcare datasets.",
      "tldr_zh": "本论文提出了一种鲁棒的联邦共形预测框架Rob-FCP，以应对联邦环境中拜占庭故障（Byzantine failures）对预测集覆盖保证的破坏，该框架能有效抵抗报告任意统计的恶意客户端。理论上，Rob-FCP在拜占庭设置下提供了共形覆盖边界，并证明其渐近接近期望覆盖水平；此外，还引入了恶意客户端数量估计器，用于未知恶意客户端数量的场景，并证明其有效性。实验结果显示，在五个标准基准和真实医疗数据集上，Rob-FCP对不同比例的恶意客户端和各种Byzantine攻击表现出强鲁棒性。",
      "categories": [
        "cs.LG",
        "cs.AI"
      ],
      "primary_category": "cs.LG",
      "comment": "Accepted to ICML 2024",
      "pdf_url": "http://arxiv.org/pdf/2406.01960v1",
      "published_date": "2024-06-04 04:43:30 UTC",
      "updated_date": "2024-06-04 04:43:30 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-18T16:16:27.503646"
    },
    {
      "arxiv_id": "2406.06576v4",
      "title": "OccamLLM: Fast and Exact Language Model Arithmetic in a Single Step",
      "title_zh": "翻译失败",
      "authors": [
        "Owen Dugan",
        "Donato Manuel Jimenez Beneto",
        "Charlotte Loh",
        "Zhuo Chen",
        "Rumen Dangovski",
        "Marin Soljačić"
      ],
      "abstract": "Despite significant advancements in text generation and reasoning, Large\nLanguage Models (LLMs) still face challenges in accurately performing complex\narithmetic operations. Language model systems often enable LLMs to generate\ncode for arithmetic operations to achieve accurate calculations. However, this\napproach compromises speed and security, and fine-tuning risks the language\nmodel losing prior capabilities. We propose a framework that enables exact\narithmetic in a single autoregressive step, providing faster, more secure, and\nmore interpretable LLM systems with arithmetic capabilities. We use the hidden\nstates of a LLM to control a symbolic architecture that performs arithmetic.\nOur implementation using Llama 3 with OccamNet as a symbolic model (OccamLlama)\nachieves 100\\% accuracy on single arithmetic operations\n($+,-,\\times,\\div,\\sin{},\\cos{},\\log{},\\exp{},\\sqrt{}$), outperforming GPT 4o\nwith and without a code interpreter. Furthermore, OccamLlama outperforms GPT 4o\nwith and without a code interpreter on average across a range of mathematical\nproblem solving benchmarks, demonstrating that OccamLLMs can excel in\narithmetic tasks, even surpassing much larger models. We will make our code\npublic shortly.",
      "tldr_zh": "该研究提出OccamLLM框架，旨在让Large Language Models (LLMs) 在单步自回归过程中实现快速且精确的算术运算，从而解决传统方法（如生成代码）在速度、安全性和模型能力上的缺陷。框架利用LLM的隐藏状态来控制一个符号架构（symbolic architecture），例如通过Llama 3结合OccamNet构建的OccamLlama系统。实验结果显示，OccamLlama在单次算术操作（如+、-、×、÷、sin、cos、log、exp、√）上达到100%准确率，并整体优于GPT-4o（有无代码解释器），甚至在多种数学问题解决基准上超越更大模型。",
      "categories": [
        "cs.CL",
        "cs.AI",
        "cs.LG"
      ],
      "primary_category": "cs.CL",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2406.06576v4",
      "published_date": "2024-06-04 04:17:40 UTC",
      "updated_date": "2024-09-03 02:11:01 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-18T16:16:39.964733"
    },
    {
      "arxiv_id": "2406.01952v1",
      "title": "Improving Generalization in Aerial and Terrestrial Mobile Robots Control Through Delayed Policy Learning",
      "title_zh": "翻译失败",
      "authors": [
        "Ricardo B. Grando",
        "Raul Steinmetz",
        "Victor A. Kich",
        "Alisson H. Kolling",
        "Pablo M. Furik",
        "Junior C. de Jesus",
        "Bruna V. Guterres",
        "Daniel T. Gamarra",
        "Rodrigo S. Guerra",
        "Paulo L. J. Drews-Jr"
      ],
      "abstract": "Deep Reinforcement Learning (DRL) has emerged as a promising approach to\nenhancing motion control and decision-making through a wide range of robotic\napplications. While prior research has demonstrated the efficacy of DRL\nalgorithms in facilitating autonomous mapless navigation for aerial and\nterrestrial mobile robots, these methods often grapple with poor generalization\nwhen faced with unknown tasks and environments. This paper explores the impact\nof the Delayed Policy Updates (DPU) technique on fostering generalization to\nnew situations, and bolstering the overall performance of agents. Our analysis\nof DPU in aerial and terrestrial mobile robots reveals that this technique\nsignificantly curtails the lack of generalization and accelerates the learning\nprocess for agents, enhancing their efficiency across diverse tasks and unknown\nscenarios.",
      "tldr_zh": "本研究探讨了深度强化学习 (DRL) 在空中和地面移动机器人控制中的应用问题，指出现有方法在面对未知任务和环境时存在泛化能力不足的挑战。论文引入Delayed Policy Updates (DPU) 技术，通过延迟策略更新来提升代理的泛化性能并加速学习过程。实验结果显示，DPU 显著改善了机器人在多样任务和未知场景中的效率和表现。",
      "categories": [
        "cs.RO",
        "cs.AI"
      ],
      "primary_category": "cs.RO",
      "comment": "IEEE 20th International Conference on Automation Science and\n  Engineering (CASE)",
      "pdf_url": "http://arxiv.org/pdf/2406.01952v1",
      "published_date": "2024-06-04 04:16:38 UTC",
      "updated_date": "2024-06-04 04:16:38 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-18T16:16:50.306867"
    },
    {
      "arxiv_id": "2406.02633v1",
      "title": "Edit Distance Robust Watermarks for Language Models",
      "title_zh": "翻译失败",
      "authors": [
        "Noah Golowich",
        "Ankur Moitra"
      ],
      "abstract": "Motivated by the problem of detecting AI-generated text, we consider the\nproblem of watermarking the output of language models with provable guarantees.\nWe aim for watermarks which satisfy: (a) undetectability, a cryptographic\nnotion introduced by Christ, Gunn & Zamir (2024) which stipulates that it is\ncomputationally hard to distinguish watermarked language model outputs from the\nmodel's actual output distribution; and (b) robustness to channels which\nintroduce a constant fraction of adversarial insertions, substitutions, and\ndeletions to the watermarked text. Earlier schemes could only handle stochastic\nsubstitutions and deletions, and thus we are aiming for a more natural and\nappealing robustness guarantee that holds with respect to edit distance.\n  Our main result is a watermarking scheme which achieves both undetectability\nand robustness to edits when the alphabet size for the language model is\nallowed to grow as a polynomial in the security parameter. To derive such a\nscheme, we follow an approach introduced by Christ & Gunn (2024), which\nproceeds via first constructing pseudorandom codes satisfying undetectability\nand robustness properties analogous to those above; our key idea is to handle\nadversarial insertions and deletions by interpreting the symbols as indices\ninto the codeword, which we call indexing pseudorandom codes. Additionally, our\ncodes rely on weaker computational assumptions than used in previous work. Then\nwe show that there is a generic transformation from such codes over large\nalphabets to watermarking schemes for arbitrary language models.",
      "tldr_zh": "这篇论文针对检测 AI 生成文本的问题，提出了一种对编辑距离(edit distance)鲁棒的水印方案(edit distance robust watermarks)，旨在实现 undetectability（即水印文本难以与语言模型的实际输出分布区分）和对插入、替换、删除等编辑的鲁棒性。研究方法基于 pseudorandom codes，通过引入 indexing pseudorandom codes 来处理 adversarial edits，并依赖更弱的计算假设，在字母表大小作为安全参数的多项式增长时构建该方案。随后，论文展示了从这些代码到任意语言模型水印方案的通用转换，显著提升了水印的实用性和可靠性。",
      "categories": [
        "cs.CR",
        "cs.AI",
        "cs.LG"
      ],
      "primary_category": "cs.CR",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2406.02633v1",
      "published_date": "2024-06-04 04:03:17 UTC",
      "updated_date": "2024-06-04 04:03:17 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-18T16:17:05.743754"
    },
    {
      "arxiv_id": "2406.01950v1",
      "title": "A Comparative Study of Sampling Methods with Cross-Validation in the FedHome Framework",
      "title_zh": "翻译失败",
      "authors": [
        "Arash Ahmadi",
        "Sarah S. Sharif",
        "Yaser M. Banad"
      ],
      "abstract": "This paper presents a comparative study of sampling methods within the\nFedHome framework, designed for personalized in-home health monitoring. FedHome\nleverages federated learning (FL) and generative convolutional autoencoders\n(GCAE) to train models on decentralized edge devices while prioritizing data\nprivacy. A notable challenge in this domain is the class imbalance in health\ndata, where critical events such as falls are underrepresented, adversely\naffecting model performance. To address this, the research evaluates six\noversampling techniques using Stratified K-fold cross-validation: SMOTE,\nBorderline-SMOTE, Random OverSampler, SMOTE-Tomek, SVM-SMOTE, and SMOTE-ENN.\nThese methods are tested on FedHome's public implementation over 200 training\nrounds with and without stratified K-fold cross-validation. The findings\nindicate that SMOTE-ENN achieves the most consistent test accuracy, with a\nstandard deviation range of 0.0167-0.0176, demonstrating stable performance\ncompared to other samplers. In contrast, SMOTE and SVM-SMOTE exhibit higher\nvariability in performance, as reflected by their wider standard deviation\nranges of 0.0157-0.0180 and 0.0155-0.0180, respectively. Similarly, the Random\nOverSampler method shows a significant deviation range of 0.0155-0.0176.\nSMOTE-Tomek, with a deviation range of 0.0160-0.0175, also shows greater\nstability but not as much as SMOTE-ENN. This finding highlights the potential\nof SMOTE-ENN to enhance the reliability and accuracy of personalized health\nmonitoring systems within the FedHome framework.",
      "tldr_zh": "本研究在 FedHome 框架中比较了六种过采样技术，用于解决个性化家庭健康监测中健康数据类别不平衡问题，该框架基于 Federated Learning (FL) 和 Generative Convolutional Autoencoders (GCAE)，以优先保护数据隐私。研究采用 Stratified K-fold cross-validation 对 SMOTE、Borderline-SMOTE、Random OverSampler、SMOTE-Tomek、SVM-SMOTE 和 SMOTE-ENN 等方法进行了评估，共进行 200 轮训练。结果显示，SMOTE-ENN 表现出最稳定的测试准确率（标准差范围 0.0167-0.0176），而其他方法如 SMOTE 和 SVM-SMOTE 则显示出更高的性能变异性，这突出了 SMOTE-ENN 在提升 FedHome 框架中健康监测系统可靠性和准确性的潜力。",
      "categories": [
        "cs.LG",
        "cs.AI",
        "cs.CY"
      ],
      "primary_category": "cs.LG",
      "comment": "11 Figures",
      "pdf_url": "http://arxiv.org/pdf/2406.01950v1",
      "published_date": "2024-06-04 04:03:07 UTC",
      "updated_date": "2024-06-04 04:03:07 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-18T16:17:17.641980"
    },
    {
      "arxiv_id": "2406.01943v1",
      "title": "Enhancing Trust in LLMs: Algorithms for Comparing and Interpreting LLMs",
      "title_zh": "增强对 LLMs 的信任：用于比较和解释 LLMs 的算法",
      "authors": [
        "Nik Bear Brown"
      ],
      "abstract": "This paper surveys evaluation techniques to enhance the trustworthiness and\nunderstanding of Large Language Models (LLMs). As reliance on LLMs grows,\nensuring their reliability, fairness, and transparency is crucial. We explore\nalgorithmic methods and metrics to assess LLM performance, identify weaknesses,\nand guide development towards more trustworthy applications. Key evaluation\nmetrics include Perplexity Measurement, NLP metrics (BLEU, ROUGE, METEOR,\nBERTScore, GLEU, Word Error Rate, Character Error Rate), Zero-Shot and Few-Shot\nLearning Performance, Transfer Learning Evaluation, Adversarial Testing, and\nFairness and Bias Evaluation. We introduce innovative approaches like LLMMaps\nfor stratified evaluation, Benchmarking and Leaderboards for competitive\nassessment, Stratified Analysis for in-depth understanding, Visualization of\nBlooms Taxonomy for cognitive level accuracy distribution, Hallucination Score\nfor quantifying inaccuracies, Knowledge Stratification Strategy for\nhierarchical analysis, and Machine Learning Models for Hierarchy Generation.\nHuman Evaluation is highlighted for capturing nuances that automated metrics\nmay miss. These techniques form a framework for evaluating LLMs, aiming to\nenhance transparency, guide development, and establish user trust. Future\npapers will describe metric visualization and demonstrate each approach on\npractical examples.",
      "tldr_zh": "这篇论文调查了评估大型语言模型 (LLMs) 的技术，以提升其可信度、可靠性和透明度，通过算法方法和指标如 Perplexity Measurement、NLP 指标 (如 BLEU、ROUGE、METEOR 和 BERTScore) 以及 Adversarial Testing 和 Fairness and Bias Evaluation 来识别弱点并指导开发。论文引入创新方法，包括 LLMMaps 用于分层评估、Hallucination Score 用于量化不准确性、Visualization of Blooms Taxonomy 用于分析认知水平准确性分布，以及 Human Evaluation 以捕捉自动化指标可能忽略的细微差别。这些技术构建了一个全面评估框架，帮助增强 LLMs 的透明度、优化模型开发并建立用户信任，为未来指标可视化和实际应用示例奠定基础。",
      "categories": [
        "cs.CL",
        "cs.AI",
        "2020: 68T50, 68Q25",
        "I.2.7; F.2.2"
      ],
      "primary_category": "cs.CL",
      "comment": "An extensive survey of the literature specifying algorithms and\n  techniques enhancing the trustworthiness and understanding of Large Language\n  Models (LLMs)",
      "pdf_url": "http://arxiv.org/pdf/2406.01943v1",
      "published_date": "2024-06-04 03:54:53 UTC",
      "updated_date": "2024-06-04 03:54:53 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-18T16:17:30.564762"
    },
    {
      "arxiv_id": "2407.16881v1",
      "title": "Comparative Analysis Vision of Worldwide AI Courses",
      "title_zh": "翻译失败",
      "authors": [
        "Jianing Xia",
        "Man Li",
        "Jianxin Li"
      ],
      "abstract": "This research investigates the curriculum structures of undergraduate\nArtificial Intelligence (AI) education across universities worldwide. By\nexamining the curricula of leading universities, the research seeks to\ncontribute to a deeper understanding of AI education on a global scale,\nfacilitating the alignment of educational practices with the evolving needs of\nthe AI landscape. This research delves into the diverse course structures of\nleading universities, exploring contemporary trends and priorities to reveal\nthe nuanced approaches in AI education. It also investigates the core AI topics\nand learning contents frequently taught, comparing them with the CS2023\ncurriculum guidance to identify convergence and divergence. Additionally, it\nexamines how universities across different countries approach AI education,\nanalyzing educational objectives, priorities, potential careers, and\nmethodologies to understand the global landscape and implications of AI\npedagogy.",
      "tldr_zh": "这项研究对全球大学本科人工智能 (AI) 教育的课程结构进行比较分析，旨在加深对全球 AI 教育的理解，并帮助教育实践适应 AI 领域的动态需求。通过考察领先大学的课程结构，该研究探讨了当代趋势、优先事项以及核心 AI 主题的学习内容，并与 CS2023 课程指导进行对比，以识别一致性和差异。此外，研究分析了不同国家在 AI 教育中的目标、优先事项、潜在职业路径和方法论，揭示了全球 AI 教学景观的多样性和启示。",
      "categories": [
        "cs.CY",
        "cs.AI"
      ],
      "primary_category": "cs.CY",
      "comment": "9 pages, 6 figures",
      "pdf_url": "http://arxiv.org/pdf/2407.16881v1",
      "published_date": "2024-06-04 03:53:57 UTC",
      "updated_date": "2024-06-04 03:53:57 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-18T16:17:39.185098"
    },
    {
      "arxiv_id": "2406.01939v2",
      "title": "Speeding up Policy Simulation in Supply Chain RL",
      "title_zh": "翻译失败",
      "authors": [
        "Vivek Farias",
        "Joren Gijsbrechts",
        "Aryan Khojandi",
        "Tianyi Peng",
        "Andrew Zheng"
      ],
      "abstract": "Simulating a single trajectory of a dynamical system under some\nstate-dependent policy is a core bottleneck in policy optimization (PO)\nalgorithms. The many inherently serial policy evaluations that must be\nperformed in a single simulation constitute the bulk of this bottleneck. In\napplying PO to supply chain optimization (SCO) problems, simulating a single\nsample path corresponding to one month of a supply chain can take several\nhours. We present an iterative algorithm to accelerate policy simulation,\ndubbed Picard Iteration. This scheme carefully assigns policy evaluation tasks\nto independent processes. Within an iteration, any given process evaluates the\npolicy only on its assigned tasks while assuming a certain \"cached\" evaluation\nfor other tasks; the cache is updated at the end of the iteration. Implemented\non GPUs, this scheme admits batched evaluation of the policy across a single\ntrajectory. We prove that the structure afforded by many SCO problems allows\nconvergence in a small number of iterations independent of the horizon. We\ndemonstrate practical speedups of 400x on large-scale SCO problems even with a\nsingle GPU, and also demonstrate practical efficacy in other RL environments.",
      "tldr_zh": "在供应链强化学习（Supply Chain RL）中，策略模拟是策略优化（PO）算法的主要瓶颈，尤其是SCO问题可能需要数小时模拟一个样本路径。本文提出Picard Iteration算法，通过将策略评估任务分配到独立进程、使用缓存更新以及在GPU上实现批量评估，来加速模拟过程。该算法利用SCO问题的结构证明了在小迭代次数内收敛，且实验在大型SCO问题上实现了400倍速度提升，并在其他RL环境中表现出实际有效性。",
      "categories": [
        "cs.AI",
        "cs.DC",
        "cs.LG"
      ],
      "primary_category": "cs.AI",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2406.01939v2",
      "published_date": "2024-06-04 03:48:08 UTC",
      "updated_date": "2025-02-15 18:09:50 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-18T16:17:52.252400"
    },
    {
      "arxiv_id": "2406.01929v1",
      "title": "Fast networked data selection via distributed smoothed quantile estimation",
      "title_zh": "翻译失败",
      "authors": [
        "Xu Zhang",
        "Marcos M. Vasconcelos"
      ],
      "abstract": "Collecting the most informative data from a large dataset distributed over a\nnetwork is a fundamental problem in many fields, including control, signal\nprocessing and machine learning. In this paper, we establish a connection\nbetween selecting the most informative data and finding the top-$k$ elements of\na multiset. The top-$k$ selection in a network can be formulated as a\ndistributed nonsmooth convex optimization problem known as quantile estimation.\nUnfortunately, the lack of smoothness in the local objective functions leads to\nextremely slow convergence and poor scalability with respect to the network\nsize. To overcome the deficiency, we propose an accelerated method that employs\nsmoothing techniques. Leveraging the piecewise linearity of the local objective\nfunctions in quantile estimation, we characterize the iteration complexity\nrequired to achieve top-$k$ selection, a challenging task due to the lack of\nstrong convexity. Several numerical results are provided to validate the\neffectiveness of the algorithm and the correctness of the theory.",
      "tldr_zh": "本研究解决了从网络中分布式数据集选择最信息量数据的问题，将其等效为 top-k 元素选择，并表述为分布式非平滑凸优化问题（quantile estimation）。为了克服现有方法的慢收敛和可扩展性差问题，作者提出了一种加速算法，使用平滑技术（smoothed quantile estimation）来优化迭代过程。论文分析了算法的迭代复杂度，并通过数值实验验证了其有效性和理论正确性。",
      "categories": [
        "eess.SY",
        "cs.AI",
        "cs.SY"
      ],
      "primary_category": "eess.SY",
      "comment": "Submitted to the IEEE Transactions on Automatic Control",
      "pdf_url": "http://arxiv.org/pdf/2406.01929v1",
      "published_date": "2024-06-04 03:26:15 UTC",
      "updated_date": "2024-06-04 03:26:15 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-18T16:18:02.487833"
    },
    {
      "arxiv_id": "2406.18574v1",
      "title": "Unsupervised Few-Shot Continual Learning for Remote Sensing Image Scene Classification",
      "title_zh": "翻译失败",
      "authors": [
        "Muhammad Anwar Ma'sum",
        "Mahardhika Pratama",
        "Ramasamy Savitha",
        "Lin Liu",
        "Habibullah",
        "Ryszard Kowalczyk"
      ],
      "abstract": "A continual learning (CL) model is desired for remote sensing image analysis\nbecause of varying camera parameters, spectral ranges, resolutions, etc. There\nexist some recent initiatives to develop CL techniques in this domain but they\nstill depend on massive labelled samples which do not fully fit remote sensing\napplications because ground truths are often obtained via field-based surveys.\nThis paper addresses this problem with a proposal of unsupervised flat-wide\nlearning approach (UNISA) for unsupervised few-shot continual learning\napproaches of remote sensing image scene classifications which do not depend on\nany labelled samples for its model updates. UNISA is developed from the idea of\nprototype scattering and positive sampling for learning representations while\nthe catastrophic forgetting problem is tackled with the flat-wide learning\napproach combined with a ball generator to address the data scarcity problem.\nOur numerical study with remote sensing image scene datasets and a\nhyperspectral dataset confirms the advantages of our solution. Source codes of\nUNISA are shared publicly in \\url{https://github.com/anwarmaxsum/UNISA} to\nallow convenient future studies and reproductions of our numerical results.",
      "tldr_zh": "本文提出 UNISA，一种无监督少样本持续学习(Unsupervised Few-Shot Continual Learning)方法，用于遥感图像场景分类，以解决现有持续学习(CL)模型对大量标记样本的依赖问题。UNISA 通过原型散射和正采样来学习表示，并结合 flat-wide 学习方法及球生成器，缓解灾难性遗忘和数据稀缺挑战。实验在遥感图像场景数据集和高光谱数据集上验证了方法的优势，并公开了源代码（https://github.com/anwarmaxsum/UNISA），便于后续研究和复现。",
      "categories": [
        "cs.CV",
        "cs.AI",
        "cs.LG"
      ],
      "primary_category": "cs.CV",
      "comment": "Under Review for Publication in IEEE TGRS",
      "pdf_url": "http://arxiv.org/pdf/2406.18574v1",
      "published_date": "2024-06-04 03:06:41 UTC",
      "updated_date": "2024-06-04 03:06:41 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-18T16:18:17.096882"
    },
    {
      "arxiv_id": "2406.01920v1",
      "title": "CODE: Contrasting Self-generated Description to Combat Hallucination in Large Multi-modal Models",
      "title_zh": "翻译失败",
      "authors": [
        "Junho Kim",
        "Hyunjun Kim",
        "Yeonju Kim",
        "Yong Man Ro"
      ],
      "abstract": "Large Multi-modal Models (LMMs) have recently demonstrated remarkable\nabilities in visual context understanding and coherent response generation.\nHowever, alongside these advancements, the issue of hallucinations has emerged\nas a significant challenge, producing erroneous responses that are unrelated to\nthe visual contents. In this paper, we introduce a novel contrastive-based\ndecoding method, COuntering DEscription Contrastive Decoding (CODE), which\nleverages self-generated descriptions as contrasting references during the\ndecoding phase of LMMs to address hallucination issues. CODE utilizes the\ncomprehensive descriptions from model itself as visual counterpart to correct\nand improve response alignment with actual visual content. By dynamically\nadjusting the information flow and distribution of next-token predictions in\nthe LMM's vocabulary, CODE enhances the coherence and informativeness of\ngenerated responses. Extensive experiments demonstrate that our method\nsignificantly reduces hallucinations and improves cross-modal consistency\nacross various benchmarks and cutting-edge LMMs. Our method provides a simple\nyet effective decoding strategy that can be integrated to existing LMM\nframeworks without additional training.",
      "tldr_zh": "本研究针对Large Multi-modal Models (LMMs) 在视觉理解中存在的hallucination问题，即生成与视觉内容无关的错误响应，提出了一种新型对比解码方法CODE (COuntering DEscription Contrastive Decoding)。CODE利用模型自身生成的描述作为对比参考，在解码阶段动态调整信息流和下一个token的预测分布，从而提升响应的连贯性和与实际视觉内容的对齐。实验结果显示，该方法显著减少了hallucination，提高了跨模态一致性，并在多种基准和LMMs上表现出色，且无需额外训练即可集成到现有框架中。",
      "categories": [
        "cs.CV",
        "cs.AI"
      ],
      "primary_category": "cs.CV",
      "comment": "Project page: https://ivy-lvlm.github.io/CODE/",
      "pdf_url": "http://arxiv.org/pdf/2406.01920v1",
      "published_date": "2024-06-04 03:04:21 UTC",
      "updated_date": "2024-06-04 03:04:21 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-18T16:18:27.693758"
    },
    {
      "arxiv_id": "2406.01917v1",
      "title": "GOMAA-Geo: GOal Modality Agnostic Active Geo-localization",
      "title_zh": "GOMAA-Geo：目标模态无关主动地理定位",
      "authors": [
        "Anindya Sarkar",
        "Srikumar Sastry",
        "Aleksis Pirinen",
        "Chongjie Zhang",
        "Nathan Jacobs",
        "Yevgeniy Vorobeychik"
      ],
      "abstract": "We consider the task of active geo-localization (AGL) in which an agent uses\na sequence of visual cues observed during aerial navigation to find a target\nspecified through multiple possible modalities. This could emulate a UAV\ninvolved in a search-and-rescue operation navigating through an area, observing\na stream of aerial images as it goes. The AGL task is associated with two\nimportant challenges. Firstly, an agent must deal with a goal specification in\none of multiple modalities (e.g., through a natural language description) while\nthe search cues are provided in other modalities (aerial imagery). The second\nchallenge is limited localization time (e.g., limited battery life, urgency) so\nthat the goal must be localized as efficiently as possible, i.e. the agent must\neffectively leverage its sequentially observed aerial views when searching for\nthe goal. To address these challenges, we propose GOMAA-Geo - a goal modality\nagnostic active geo-localization agent - for zero-shot generalization between\ndifferent goal modalities. Our approach combines cross-modality contrastive\nlearning to align representations across modalities with supervised foundation\nmodel pretraining and reinforcement learning to obtain highly effective\nnavigation and localization policies. Through extensive evaluations, we show\nthat GOMAA-Geo outperforms alternative learnable approaches and that it\ngeneralizes across datasets - e.g., to disaster-hit areas without seeing a\nsingle disaster scenario during training - and goal modalities - e.g., to\nground-level imagery or textual descriptions, despite only being trained with\ngoals specified as aerial views. Code and models are publicly available at\nhttps://github.com/mvrl/GOMAA-Geo/tree/main.",
      "tldr_zh": "本研究探讨了主动地理定位（Active Geo-localization, AGL）任务，其中代理需利用空中导航中的视觉线索，定位通过多种模态（如自然语言描述）指定的目标，同时应对目标模态差异和定位时间限制的挑战。论文提出 GOMAA-Geo 框架，该框架采用跨模态对比学习（cross-modality contrastive learning）对齐不同模态表示，并结合监督基础模型预训练和强化学习（reinforcement learning）来优化导航和定位策略，实现零样本泛化。实验结果显示，GOMAA-Geo 优于其他方法，并在不同数据集和目标模态（如地面图像或文本）上表现出色，即使训练时仅使用空中视图。",
      "categories": [
        "cs.CV",
        "cs.AI"
      ],
      "primary_category": "cs.CV",
      "comment": "23 pages, 17 figures",
      "pdf_url": "http://arxiv.org/pdf/2406.01917v1",
      "published_date": "2024-06-04 02:59:36 UTC",
      "updated_date": "2024-06-04 02:59:36 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-18T16:18:41.297884"
    },
    {
      "arxiv_id": "2406.01914v2",
      "title": "HPE-CogVLM: Advancing Vision Language Models with a Head Pose Grounding Task",
      "title_zh": "翻译失败",
      "authors": [
        "Yu Tian",
        "Tianqi Shao",
        "Tsukasa Demizu",
        "Xuyang Wu",
        "Hsin-Tai Wu"
      ],
      "abstract": "Head pose estimation (HPE) requires a sophisticated understanding of 3D\nspatial relationships to generate precise yaw, pitch, and roll angles. Previous\nHPE models, primarily CNN-based, rely on cropped close-up human head images as\ninputs and often lack robustness in real-world scenario. Vision Language Models\n(VLMs) can analyze entire images while focusing on specific objects through\ntheir attention mechanisms. In this paper, we propose a novel framework to\nimprove the HPE accuracy by leveraging the object detection grounding\ncapability of a VLM, referred to as CogVLM. We empirically find that directly\nLoRA fine-tuning of this VLM for the HPE task fails to achieve desirable HPE\naccuracy, while some model merging methods can improve accuracy but frequently\nproduce blended invalid response formats, struggling to handle both object\ndetection and HPE tasks simultaneously. To integrate HPE capability into CogVLM\neffectively, we develop a novel LoRA layer-based model merging method. This\nmerging approach applies a high cosine similarity threshold and a\nwinner-takes-all layer selection strategy, aligning attention to the HPE task\nwhile preserving original object detection knowledge. It successfully resolves\nissues with blended invalid response formats and improves accuracy. Results\nshow that our HPE-CogVLM achieves a 31.5\\% reduction in Mean Absolute Error\nover the current state-of-the-art CNN model, 6DRepNet, in cross-dataset\nevaluation. Furthermore, HPE-CogVLM outperforms both directly LoRA fine-tuned\nand task arithmetic-based merged VLMs across all HPE metrics.",
      "tldr_zh": "本研究针对头部姿态估计（HPE）任务的准确性和鲁棒性问题，提出了一种新型框架HPE-CogVLM，利用视觉语言模型（VLMs）如CogVLM的物体检测grounding能力。研究发现，直接LoRA fine-tuning无法有效提升HPE准确性，因此开发了一种基于LoRA层的模型合并方法，采用高余弦相似度阈值和winner-takes-all层选择策略，以整合HPE功能，同时保留原有物体检测知识并避免无效响应格式。结果显示，HPE-CogVLM在跨数据集评估中，比当前最先进的CNN模型6DRepNet降低了31.5%的Mean Absolute Error，并在所有HPE指标上优于直接fine-tuned或任务算术-based合并的VLMs。",
      "categories": [
        "cs.CV",
        "cs.AI",
        "cs.CL"
      ],
      "primary_category": "cs.CV",
      "comment": "This work has been submitted to the IEEE for possible publication",
      "pdf_url": "http://arxiv.org/pdf/2406.01914v2",
      "published_date": "2024-06-04 02:51:26 UTC",
      "updated_date": "2024-11-08 17:33:31 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-18T16:18:52.387239"
    },
    {
      "arxiv_id": "2406.01913v1",
      "title": "Generating Synthetic Net Load Data with Physics-informed Diffusion Model",
      "title_zh": "使用物理信息驱动扩散模型生成合成净负荷数据",
      "authors": [
        "Shaorong Zhang",
        "Yuanbin Cheng",
        "Nanpeng Yu"
      ],
      "abstract": "This paper presents a novel physics-informed diffusion model for generating\nsynthetic net load data, addressing the challenges of data scarcity and privacy\nconcerns. The proposed framework embeds physical models within denoising\nnetworks, offering a versatile approach that can be readily generalized to\nunforeseen scenarios. A conditional denoising neural network is designed to\njointly train the parameters of the transition kernel of the diffusion model\nand the parameters of the physics-informed function. Utilizing the real-world\nsmart meter data from Pecan Street, we validate the proposed method and conduct\na thorough numerical study comparing its performance with state-of-the-art\ngenerative models, including generative adversarial networks, variational\nautoencoders, normalizing flows, and a well calibrated baseline diffusion\nmodel. A comprehensive set of evaluation metrics is used to assess the accuracy\nand diversity of the generated synthetic net load data. The numerical study\nresults demonstrate that the proposed physics-informed diffusion model\noutperforms state-of-the-art models across all quantitative metrics, yielding\nat least 20% improvement.",
      "tldr_zh": "本论文提出了一种physics-informed diffusion model，用于生成合成净负载数据，以解决数据稀缺和隐私问题。该模型将物理模型嵌入去噪网络中，并设计了一个conditional denoising neural network来联合训练扩散模型的过渡核参数和物理信息函数参数，从而提升泛化能力。利用Pecan Street的真实智能电表数据进行验证，并与generative adversarial networks (GAN)、variational autoencoders (VAE)、normalizing flows以及基准扩散模型进行比较。结果显示，该方法在所有量化指标上优于现有模型，至少提高了20%。",
      "categories": [
        "cs.LG",
        "cs.AI"
      ],
      "primary_category": "cs.LG",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2406.01913v1",
      "published_date": "2024-06-04 02:50:19 UTC",
      "updated_date": "2024-06-04 02:50:19 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-18T16:19:06.979081"
    },
    {
      "arxiv_id": "2407.11984v1",
      "title": "Mimetic Poet",
      "title_zh": "翻译失败",
      "authors": [
        "Jon McCormack",
        "Elliott Wilson",
        "Nina Rajcic",
        "Maria Teresa Llano"
      ],
      "abstract": "This paper presents the design and initial assessment of a novel device that\nuses generative AI to facilitate creative ideation, inspiration, and reflective\nthought. Inspired by magnetic poetry, which was originally designed to help\novercome writer's block, the device allows participants to compose short poetic\ntexts from a limited vocabulary by physically placing words on the device's\nsurface. Upon composing the text, the system employs a large language model\n(LLM) to generate a response, displayed on an e-ink screen. We explored various\nstrategies for internally sequencing prompts to foster creative thinking,\nincluding analogy, allegorical interpretations, and ideation. We installed the\ndevice in our research laboratory for two weeks and held a focus group at the\nconclusion to evaluate the design. The design choice to limit interactions with\nthe LLM to poetic text, coupled with the tactile experience of assembling the\npoem, fostered a deeper and more enjoyable engagement with the LLM compared to\ntraditional chatbot or screen-based interactions. This approach gives users the\nopportunity to reflect on the AI-generated responses in a manner conducive to\ncreative thought.",
      "tldr_zh": "这篇论文介绍了 Mimetic Poet，一种新型设备，利用 generative AI 促进创意构想、灵感和反思性思考，灵感来源于 magnetic poetry 以克服写作障碍。设备允许用户通过物理放置单词在表面组成短诗，然后由 large language model (LLM) 生成响应，包括 analogy、allegorical interpretations 和 ideation 等策略，并在 e-ink 屏幕上显示。实验结果显示，这种限制互动为诗意文本并结合触觉体验的设计，比传统聊天机器人或屏幕互动更能提升用户参与度，并为创意思考提供更有利的反思机会。",
      "categories": [
        "cs.HC",
        "cs.AI",
        "cs.CL",
        "I.2; J.5"
      ],
      "primary_category": "cs.HC",
      "comment": "Paper accepted at the International Conference on Computational\n  Creativity, (ICCC 2024), J\\\"onk\\\"oping, Sweden",
      "pdf_url": "http://arxiv.org/pdf/2407.11984v1",
      "published_date": "2024-06-04 02:50:15 UTC",
      "updated_date": "2024-06-04 02:50:15 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-18T16:19:18.840071"
    },
    {
      "arxiv_id": "2406.01893v2",
      "title": "Large Language Model-Enabled Multi-Agent Manufacturing Systems",
      "title_zh": "翻译失败",
      "authors": [
        "Jonghan Lim",
        "Birgit Vogel-Heuser",
        "Ilya Kovalenko"
      ],
      "abstract": "Traditional manufacturing faces challenges adapting to dynamic environments\nand quickly responding to manufacturing changes. The use of multi-agent systems\nhas improved adaptability and coordination but requires further advancements in\nrapid human instruction comprehension, operational adaptability, and\ncoordination through natural language integration. Large language models like\nGPT-3.5 and GPT-4 enhance multi-agent manufacturing systems by enabling agents\nto communicate in natural language and interpret human instructions for\ndecision-making. This research introduces a novel framework where large\nlanguage models enhance the capabilities of agents in manufacturing, making\nthem more adaptable, and capable of processing context-specific instructions. A\ncase study demonstrates the practical application of this framework, showing\nhow agents can effectively communicate, understand tasks, and execute\nmanufacturing processes, including precise G-code allocation among agents. The\nfindings highlight the importance of continuous large language model\nintegration into multi-agent manufacturing systems and the development of\nsophisticated agent communication protocols for a more flexible manufacturing\nsystem.",
      "tldr_zh": "本研究探讨了传统制造系统在动态环境中的适应性和响应能力不足问题，并提出一种利用 Large Language Models（如 GPT-3.5 和 GPT-4）增强多智能体制造系统的创新框架。该框架使智能体能够通过自然语言进行沟通、快速理解人类指令，并实现更强的操作适应性和决策能力。案例研究展示了该系统在任务执行中的实际应用，包括智能体间的有效协作和精确 G-code 分配，结果表明这种整合显著提高了制造系统的灵活性，并强调了持续开发高级通信协议的重要性。",
      "categories": [
        "cs.MA",
        "cs.AI"
      ],
      "primary_category": "cs.MA",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2406.01893v2",
      "published_date": "2024-06-04 01:57:37 UTC",
      "updated_date": "2024-06-21 14:54:46 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-18T16:19:30.323943"
    },
    {
      "arxiv_id": "2406.01882v2",
      "title": "HoneyGPT: Breaking the Trilemma in Terminal Honeypots with Large Language Model",
      "title_zh": "翻译失败",
      "authors": [
        "Ziyang Wang",
        "Jianzhou You",
        "Haining Wang",
        "Tianwei Yuan",
        "Shichao Lv",
        "Yang Wang",
        "Limin Sun"
      ],
      "abstract": "Honeypots, as a strategic cyber-deception mechanism designed to emulate\nauthentic interactions and bait unauthorized entities, often struggle with\nbalancing flexibility, interaction depth, and deception. They typically fail to\nadapt to evolving attacker tactics, with limited engagement and information\ngathering. Fortunately, the emergent capabilities of large language models and\ninnovative prompt-based engineering offer a transformative shift in honeypot\ntechnologies. This paper introduces HoneyGPT, a pioneering shell honeypot\narchitecture based on ChatGPT, characterized by its cost-effectiveness and\nproactive engagement. In particular, we propose a structured prompt engineering\nframework that incorporates chain-of-thought tactics to improve long-term\nmemory and robust security analytics, enhancing deception and engagement. Our\nevaluation of HoneyGPT comprises a baseline comparison based on a collected\ndataset and a three-month field evaluation. The baseline comparison\ndemonstrates HoneyGPT's remarkable ability to strike a balance among\nflexibility, interaction depth, and deceptive capability. The field evaluation\nfurther validates HoneyGPT's superior performance in engaging attackers more\ndeeply and capturing a wider array of novel attack vectors.",
      "tldr_zh": "本文提出 HoneyGPT，一种基于 Large Language Model（如 ChatGPT）的 shell honeypot 架构，旨在打破 Honeypots 在灵活性、交互深度和欺骗性方面的三重困境。HoneyGPT 通过结构化的 prompt engineering 框架和 chain-of-thought 策略，提升了长期记忆、安全分析和主动参与能力。实验评估，包括基线比较和为期三个月的现场测试，证明 HoneyGPT 显著改善了攻击者互动深度，并成功捕获更多新型攻击向量。",
      "categories": [
        "cs.CR",
        "cs.AI",
        "cs.ET",
        "cs.SE"
      ],
      "primary_category": "cs.CR",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2406.01882v2",
      "published_date": "2024-06-04 01:31:20 UTC",
      "updated_date": "2025-02-15 10:06:51 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-18T16:19:42.246650"
    },
    {
      "arxiv_id": "2406.02630v2",
      "title": "AI Agents Under Threat: A Survey of Key Security Challenges and Future Pathways",
      "title_zh": "翻译失败",
      "authors": [
        "Zehang Deng",
        "Yongjian Guo",
        "Changzhou Han",
        "Wanlun Ma",
        "Junwu Xiong",
        "Sheng Wen",
        "Yang Xiang"
      ],
      "abstract": "An Artificial Intelligence (AI) agent is a software entity that autonomously\nperforms tasks or makes decisions based on pre-defined objectives and data\ninputs. AI agents, capable of perceiving user inputs, reasoning and planning\ntasks, and executing actions, have seen remarkable advancements in algorithm\ndevelopment and task performance. However, the security challenges they pose\nremain under-explored and unresolved. This survey delves into the emerging\nsecurity threats faced by AI agents, categorizing them into four critical\nknowledge gaps: unpredictability of multi-step user inputs, complexity in\ninternal executions, variability of operational environments, and interactions\nwith untrusted external entities. By systematically reviewing these threats,\nthis paper highlights both the progress made and the existing limitations in\nsafeguarding AI agents. The insights provided aim to inspire further research\ninto addressing the security threats associated with AI agents, thereby\nfostering the development of more robust and secure AI agent applications.",
      "tldr_zh": "本调查论文审视了AI agents的安全挑战，系统地将威胁分类为四个关键知识空白：unpredictability of multi-step user inputs、complexity in internal executions、variability of operational environments，以及interactions with untrusted external entities。通过回顾现有进展和限制，该研究突出了AI agents在算法发展和任务执行方面的成就，同时强调了尚未解决的问题，以激励未来研究，推动更稳健、安全的AI应用发展。",
      "categories": [
        "cs.CR",
        "cs.AI"
      ],
      "primary_category": "cs.CR",
      "comment": "Submitted to ACM Computing Survey",
      "pdf_url": "http://arxiv.org/pdf/2406.02630v2",
      "published_date": "2024-06-04 01:22:31 UTC",
      "updated_date": "2024-09-06 01:31:22 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-18T16:19:53.811253"
    },
    {
      "arxiv_id": "2406.01876v1",
      "title": "GRAM: Generative Retrieval Augmented Matching of Data Schemas in the Context of Data Security",
      "title_zh": "翻译失败",
      "authors": [
        "Xuanqing Liu",
        "Luyang Kong",
        "Runhui Wang",
        "Patrick Song",
        "Austin Nevins",
        "Henrik Johnson",
        "Nimish Amlathe",
        "Davor Golac"
      ],
      "abstract": "Schema matching constitutes a pivotal phase in the data ingestion process for\ncontemporary database systems. Its objective is to discern pairwise\nsimilarities between two sets of attributes, each associated with a distinct\ndata table. This challenge emerges at the initial stages of data analytics,\nsuch as when incorporating a third-party table into existing databases to\ninform business insights. Given its significance in the realm of database\nsystems, schema matching has been under investigation since the 2000s. This\nstudy revisits this foundational problem within the context of large language\nmodels. Adhering to increasingly stringent data security policies, our focus\nlies on the zero-shot and few-shot scenarios: the model should analyze only a\nminimal amount of customer data to execute the matching task, contrasting with\nthe conventional approach of scrutinizing the entire data table. We emphasize\nthat the zero-shot or few-shot assumption is imperative to safeguard the\nidentity and privacy of customer data, even at the potential cost of accuracy.\nThe capability to accurately match attributes under such stringent requirements\ndistinguishes our work from previous literature in this domain.",
      "tldr_zh": "该论文提出 GRAM 框架，即 Generative Retrieval Augmented Matching，用于在数据安全背景下处理 schema matching 问题，该任务旨在识别两个数据表属性之间的相似性，以支持数据分析如整合第三方表。不同于传统方法，GRAM 专注于 zero-shot 和 few-shot 场景，仅使用最小量客户数据进行匹配，从而优先保障数据隐私和身份安全，即使可能牺牲部分准确性。该方法在大型语言模型的背景下重新审视这一经典问题，为符合严格数据安全政策的数据管理系统提供了创新解决方案。",
      "categories": [
        "cs.DB",
        "cs.AI",
        "cs.CL",
        "cs.IR",
        "cs.LG"
      ],
      "primary_category": "cs.DB",
      "comment": "KDD 2024 Camera Ready; 11 pages, 8 figures",
      "pdf_url": "http://arxiv.org/pdf/2406.01876v1",
      "published_date": "2024-06-04 01:08:00 UTC",
      "updated_date": "2024-06-04 01:08:00 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-18T16:20:06.435182"
    },
    {
      "arxiv_id": "2406.01869v1",
      "title": "Fruit Classification System with Deep Learning and Neural Architecture Search",
      "title_zh": "基于深度学习和神经架构搜索的水果分类系统",
      "authors": [
        "Christine Dewi",
        "Dhananjay Thiruvady",
        "Nayyar Zaidi"
      ],
      "abstract": "The fruit identification process involves analyzing and categorizing\ndifferent types of fruits based on their visual characteristics. This activity\ncan be achieved using a range of methodologies, encompassing manual\nexamination, conventional computer vision methodologies, and more sophisticated\nmethodologies employing machine learning and deep learning. Our study\nidentified a total of 15 distinct categories of fruit, consisting of class\nAvocado, Banana, Cherry, Apple Braeburn, Apple golden 1, Apricot, Grape, Kiwi,\nMango, Orange, Papaya, Peach, Pineapple, Pomegranate and Strawberry. Neural\nArchitecture Search (NAS) is a technological advancement employed within the\nrealm of deep learning and artificial intelligence, to automate conceptualizing\nand refining neural network topologies. NAS aims to identify neural network\nstructures that are highly suitable for tasks, such as the detection of fruits.\nOur suggested model with 99.98% mAP increased the detection performance of the\npreceding research study that used Fruit datasets. In addition, after the\ncompletion of the study, a comparative analysis was carried out to assess the\nfindings in conjunction with those of another research that is connected to the\ntopic. When compared to the findings of earlier studies, the detector that was\nproposed exhibited higher performance in terms of both its accuracy and its\nprecision.",
      "tldr_zh": "本研究提出了一种基于深度学习和 Neural Architecture Search (NAS) 的水果分类系统，用于分析和识别15种水果类别，包括Avocado、Banan、Cherry、Apple Braeburn等。  \n该系统利用NAS自动优化神经网络架构，提升了水果检测的效率和准确性，在Fruit数据集上实现了99.98%的mAP。  \n与其他相关研究相比，该模型在准确性和精确性方面表现出显著提升，为水果识别任务提供了更先进的解决方案。",
      "categories": [
        "cs.CV",
        "cs.AI",
        "I.2; I.4"
      ],
      "primary_category": "cs.CV",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2406.01869v1",
      "published_date": "2024-06-04 00:41:47 UTC",
      "updated_date": "2024-06-04 00:41:47 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-18T16:20:18.766984"
    },
    {
      "arxiv_id": "2406.01855v1",
      "title": "TruthEval: A Dataset to Evaluate LLM Truthfulness and Reliability",
      "title_zh": "翻译失败",
      "authors": [
        "Aisha Khatun",
        "Daniel G. Brown"
      ],
      "abstract": "Large Language Model (LLM) evaluation is currently one of the most important\nareas of research, with existing benchmarks proving to be insufficient and not\ncompletely representative of LLMs' various capabilities. We present a curated\ncollection of challenging statements on sensitive topics for LLM benchmarking\ncalled TruthEval. These statements were curated by hand and contain known truth\nvalues. The categories were chosen to distinguish LLMs' abilities from their\nstochastic nature. We perform some initial analyses using this dataset and find\nseveral instances of LLMs failing in simple tasks showing their inability to\nunderstand simple questions.",
      "tldr_zh": "本研究引入了TruthEval数据集，用于评估大型语言模型(LLM)的真实性和可靠性，以弥补现有基准测试的不足。该数据集由手工策划的挑战性陈述组成，这些陈述针对敏感话题并具有已知真实值，类别设计旨在区分LLM的能力与其随机性特征。通过初步分析，研究者发现LLM在简单任务中表现出失败，暴露了其理解基本问题的局限性。",
      "categories": [
        "cs.CL",
        "cs.AI"
      ],
      "primary_category": "cs.CL",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2406.01855v1",
      "published_date": "2024-06-04 00:01:35 UTC",
      "updated_date": "2024-06-04 00:01:35 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-18T16:20:28.554719"
    }
  ],
  "raw_papers_fetched": true,
  "papers_count": 148,
  "processed_papers_count": 148,
  "failed_papers_count": 0,
  "summary_generated": true,
  "daily_data_saved": true,
  "last_update": "2025-05-18T16:20:59.977724"
}