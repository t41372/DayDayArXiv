{
  "date": "2024-09-11",
  "category": "cs.AI",
  "summary": "欢迎来到 UTC 时间 2024-09-11 的 arXiv 中文 TLDR 快报！\n\n今天 arXiv 的论文主要聚焦人工智能（AI）和大型语言模型（LLM）的创新应用、机器学习的安全性和生物医学中的AI挑战，强调模型鲁棒性、知识蒸馏和多模态交互等话题。令人印象深刻的包括 Thomas Ball 等关于 LLM 能力的实验分析，以及 Alan F. Smeaton 的基础模型理解论文；这些工作揭示了 AI 在实际场景中的潜力与局限。\n\n下面，我将挑选并简要讨论部分关键论文，先优先聊 AI、LLM 和机器学习领域的创新性工作，再快速掠过其他主题的相关论文。每个条目列出论文标题（中文 + 英文），并突出核心贡献和发现。\n\n### AI 和 LLM 核心论文\n- **Can We Count on LLMs? The Fixed-Effect Fallacy and Claims of GPT-4 Capabilities（我们能依赖 LLM 吗？固定效应谬误和 GPT-4 能力的声明）**  \n  作者：Thomas Ball 等。主要贡献是通过实验评估 GPT-4 在确定性任务中的性能，发现查询措辞和输入参数会显著影响准确性，揭示 LLM 泛化能力的局限性，并警告语言模型易受固定效应谬误影响。\n\n- **Understanding Foundation Models: Are We Back in 1924?（理解基础模型：我们回到了 1924 年？）**  \n  作者：Alan F. Smeaton。主要发现分析基础模型的训练和推理能力，强调这些模型的语义关系捕捉类似于人类大脑，但警告直接比较的潜在风险，并讨论了基准测试和神经科学启示。\n\n- **Synthetic continued pretraining（合成持续预训练）**  \n  作者：Zitong Yang 等。核心贡献提出使用合成数据增强（如 EntiGraph）来提升 LLM 在小规模领域数据集上的知识获取效率，发现这种方法能改善模型在特定任务上的数据利用和泛化性能。\n\n- **Securing Vision-Language Models with a Robust Encoder Against Jailbreak and Adversarial Attacks（使用鲁棒编码器保护视觉-语言模型免受越狱和对抗攻击）**  \n  作者：Md Zarif Hossain 等。主要发现开发 Sim-CLIP+ 方法，通过对抗训练增强视觉-语言模型的鲁棒性，在对抗攻击和越狱场景下显著提高准确性，同时保持高效性。\n\n- **DrLLM: Prompt-Enhanced Distributed Denial-of-Service Resistance Method with Large Language Models（DrLLM：使用 LLM 的提示增强分布式拒绝服务抵抗方法）**  \n  作者：Zhenyu Yin 等。论文提出 DrLLM 框架，利用 LLM 和提示工程检测异常流量，发现该方法在零样本场景下有效提升网络安全防御，并通过模块设计减少计算开销。\n\n- **Zero-Shot Text-to-Speech as Golden Speech Generator: A Systematic Framework and its Applicability in Automatic Pronunciation Assessment（零样本文本到语音作为黄金语音生成器：一个系统框架及其在自动发音评估中的应用）**  \n  作者：Tien-Hong Lo 等。核心贡献构建 EHRXDiff 框架，使用零样本 TTS 生成患者特定语音，发现其能预测胸部 X 光图像的时序变化，提升临床决策辅助的准确性。\n\n- **Inf-MLLM: Efficient Streaming Inference of Multimodal Large Language Models on a Single GPU（Inf-MLLM：在单 GPU 上高效流式推理多模态大型语言模型）**  \n  作者：Zhenyu Ning 等。主要发现通过注意力模式优化，实现无限上下文的多模态 LLM 推理，显著减少计算资源消耗，并在长文本和视频任务中加速推理过程。\n\n这些 AI 相关论文突出了 LLM 在安全、泛化和多模态方面的进展，潜在影响包括提升模型部署的实际可行性。\n\n### 机器学习和强化学习相关论文（简要掠过）\n- **Feature Importance in Pedestrian Intention Prediction: A Context-Aware Review（行人意图预测中的特征重要性：一个基于上下文的回顾）**  \n  作者：Mohsen Azarmi 等。贡献提出 CAPFI 方法，提升行人意图预测的解释性和准确性，发现上下文细分能减少特征偏差。\n\n- **Ensemble Methods for Sequence Classification with Hidden Markov Models（使用隐马尔可夫模型的集成方法进行序列分类）**  \n  作者：Maxime Kawawa-Beaudan 等。主要发现集成 HMM 模型在不平衡数据上表现优于 CNN 和 LSTM，提升了序列分类的鲁棒性。\n\n- **SUPER: Evaluating Agents on Setting Up and Executing Tasks from Research Repositories（SUPER：评估代理从研究仓库设置和执行任务）**  \n  作者：Tushar Khot 等。论文构建 SUPER 基准，发现强化学习代理能有效处理研究任务，但当前模型在复杂场景下仍有局限。\n\n其他机器学习论文如 Hierarchical Reinforcement Learning（第22）和 Neural Algorithmic Reasoning（第54）等，展示了算法在多任务适应中的潜力，但细节较常规，影响较小。\n\n### 生物医学和健康应用论文（快速概述）\n- **Safety challenges of AI in medicine in the era of large language models（AI 在医学中的安全挑战：在大型语言模型时代）**  \n  作者：Xiaoye Wang 等。发现 LLM 在医疗中的应用面临安全风险，如幻觉和偏差，建议加强模型训练以提升临床可靠性。\n\n- **MEDIC: Towards a Comprehensive Framework for Evaluating LLMs in Clinical Applications（MEDIC：针对临床应用的 LLM 全面评估框架）**  \n  作者：Praveen K Kanithi 等。贡献提出 MEDIC 框架，评估 LLM 在医疗任务中的推理和安全性，发现模型在问答和总结任务上表现出色。\n\n这些论文强调 AI 在医疗的实际挑战，但整体影响需进一步验证。\n\n### 其他领域论文（简要提及）\n其余论文涉及图像处理（如 ThermalGaussian，第47）、网络安全（如 Context-Aware Membership Inference Attacks，第78）和机器人（如 Robust Robot Walker，第24）等。它们贡献了特定领域创新，如 ThermalGaussian 通过多模态重建提升热成像质量，但整体话题度较低，故从简。\n\n总之，今天的论文突显 AI 领域的快速迭代，LLM 的安全和应用仍是热点。感兴趣的读者可关注 Thomas Ball 和 Alan F. Smeaton 的工作，以探索 AI 的深层问题。更多细节请查阅 arXiv！",
  "papers": [
    {
      "arxiv_id": "2409.07656v1",
      "title": "Passed the Turing Test: Living in Turing Futures",
      "title_zh": "翻译失败",
      "authors": [
        "Bernardo Gonçalves"
      ],
      "abstract": "The world has seen the emergence of machines based on pretrained models,\ntransformers, also known as generative artificial intelligences for their\nability to produce various types of content, including text, images, audio, and\nsynthetic data. Without resorting to preprogramming or special tricks, their\nintelligence grows as they learn from experience, and to ordinary people, they\ncan appear human-like in conversation. This means that they can pass the Turing\ntest, and that we are now living in one of many possible Turing futures where\nmachines can pass for what they are not. However, the learning machines that\nTuring imagined would pass his imitation tests were machines inspired by the\nnatural development of the low-energy human cortex. They would be raised like\nhuman children and naturally learn the ability to deceive an observer. These\n``child machines,'' Turing hoped, would be powerful enough to have an impact on\nsociety and nature.",
      "tldr_zh": "该论文讨论了基于预训练模型和 Transformers 的生成式人工智能（generative artificial intelligences），它们能够生成文本、图像、音频等内容，并在对话中表现得像人类，从而通过图灵测试（Turing Test）。作者指出，我们正生活在众多可能的图灵未来（Turing futures）之一，其中机器能成功模仿人类，但这与图灵最初设想的学习机器不同，后者像人类儿童般低能耗地成长和学习。论文强调，这些AI的发展可能对社会和自然产生深远影响，但也引发了对欺骗性和真实性的担忧。",
      "categories": [
        "cs.AI",
        "cs.CY"
      ],
      "primary_category": "cs.AI",
      "comment": "Author's version. Forthcoming in Intelligent Computing, a Science\n  Partner Journal published in affiliation with Zhejiang Lab\n  (https://spj.science.org/journal/icomputing). First submitted 19 Feb 2024.\n  Revised 16 Jul 2024. Accepted 15 Aug 2024",
      "pdf_url": "http://arxiv.org/pdf/2409.07656v1",
      "published_date": "2024-09-11 22:56:30 UTC",
      "updated_date": "2024-09-11 22:56:30 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-19T22:58:57.590008"
    },
    {
      "arxiv_id": "2409.07645v1",
      "title": "Feature Importance in Pedestrian Intention Prediction: A Context-Aware Review",
      "title_zh": "行人意图预测中的特征重要性：一个基于上下文的回顾",
      "authors": [
        "Mohsen Azarmi",
        "Mahdi Rezaei",
        "He Wang",
        "Ali Arabian"
      ],
      "abstract": "Recent advancements in predicting pedestrian crossing intentions for\nAutonomous Vehicles using Computer Vision and Deep Neural Networks are\npromising. However, the black-box nature of DNNs poses challenges in\nunderstanding how the model works and how input features contribute to final\npredictions. This lack of interpretability delimits the trust in model\nperformance and hinders informed decisions on feature selection,\nrepresentation, and model optimisation; thereby affecting the efficacy of\nfuture research in the field. To address this, we introduce Context-aware\nPermutation Feature Importance (CAPFI), a novel approach tailored for\npedestrian intention prediction. CAPFI enables more interpretability and\nreliable assessments of feature importance by leveraging subdivided scenario\ncontexts, mitigating the randomness of feature values through targeted\nshuffling. This aims to reduce variance and prevent biased estimations in\nimportance scores during permutations. We divide the Pedestrian Intention\nEstimation (PIE) dataset into 16 comparable context sets, measure the baseline\nperformance of five distinct neural network architectures for intention\nprediction in each context, and assess input feature importance using CAPFI. We\nobserved nuanced differences among models across various contextual\ncharacteristics. The research reveals the critical role of pedestrian bounding\nboxes and ego-vehicle speed in predicting pedestrian intentions, and potential\nprediction biases due to the speed feature through cross-context permutation\nevaluation. We propose an alternative feature representation by considering\nproximity change rate for rendering dynamic pedestrian-vehicle locomotion,\nthereby enhancing the contributions of input features to intention prediction.\nThese findings underscore the importance of contextual features and their\ndiversity to develop accurate and robust intent-predictive models.",
      "tldr_zh": "该论文审视了使用计算机视觉和Deep Neural Networks (DNNs)预测行人过马路意图时，特征重要性的可解释性问题，并引入了Context-aware Permutation Feature Importance (CAPFI)方法，通过细分场景上下文和针对性混洗来减少随机性和偏差。研究者将Pedestrian Intention Estimation (PIE)数据集分为16个可比较的上下文集，使用五种神经网络架构评估性能，并分析了特征重要性。结果显示，行人bounding boxes和ego-vehicle速度是预测意图的关键特征，但速度特征可能引入偏差；为此，论文提出使用接近率变化作为替代特征表示，以提升输入特征的贡献和模型的鲁棒性。这些发现突出了上下文特征多样性的重要性，有助于开发更准确的意图预测模型。",
      "categories": [
        "cs.CV",
        "cs.AI",
        "cs.LG",
        "cs.RO",
        "eess.IV"
      ],
      "primary_category": "cs.CV",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2409.07645v1",
      "published_date": "2024-09-11 22:13:01 UTC",
      "updated_date": "2024-09-11 22:13:01 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-19T22:59:12.520979"
    },
    {
      "arxiv_id": "2409.07638v2",
      "title": "Can We Count on LLMs? The Fixed-Effect Fallacy and Claims of GPT-4 Capabilities",
      "title_zh": "翻译失败",
      "authors": [
        "Thomas Ball",
        "Shuo Chen",
        "Cormac Herley"
      ],
      "abstract": "In this paper we explore evaluation of LLM capabilities. We present\nmeasurements of GPT-4 performance on several deterministic tasks; each task\ninvolves a basic calculation and takes as input parameter some element drawn\nfrom a large well-defined population (e.g., count elements in a list, multiply\ntwo k-digit numbers, etc). We examine several conditions per-task and perform\nenough trials so that statistically significant differences can be detected.\nThis allows us to investigate the sensitivity of task-accuracy both to query\nphrasing and input parameter population. We find that seemingly trivial\nmodifications in the task-prompt or input population can yield differences far\nlarger than can be explained by sampling effects. For example, performance on a\nsimple list-counting task varies with query-phrasing and list-length, but also\nwith list composition (i.e., the thing-to-be-counted) and object frequency\n(e.g., success when an element accounts for $\\approx$ 50\\% of a list is\ndifferent from when it accounts for $\\approx$ 70\\% etc).\n  We conclude that efforts to quantify LLM capabilities easily succumb to the\nlanguage-as-fixed-effect fallacy, where experimental observations are\nimproperly generalized beyond what the data supports. A consequence appears to\nbe that intuitions that have been formed based on interactions with humans form\na very unreliable guide as to which input modifications should ``make no\ndifference'' to LLM performance.",
      "tldr_zh": "这篇论文探讨了评估大型语言模型 (LLM) 能力的挑战，特别是针对 GPT-4 在确定性任务（如计数列表元素或乘法计算）上的表现。作者通过多次试验，测试任务准确率对查询表述和输入参数（如列表长度、组成或对象频率）的敏感性，结果显示微小的修改会导致性能差异远超采样效应。论文揭示了“语言作为固定效应谬误”（fixed-effect fallacy）的风险，即实验观察往往被过度泛化。最终，研究强调，基于人类互动形成的直觉无法可靠地指导对 LLM 能力的预期，呼吁更谨慎的评估方法。",
      "categories": [
        "cs.AI",
        "cs.CL",
        "cs.LG"
      ],
      "primary_category": "cs.AI",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2409.07638v2",
      "published_date": "2024-09-11 21:48:33 UTC",
      "updated_date": "2024-09-24 17:34:07 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-19T22:59:22.044901"
    },
    {
      "arxiv_id": "2409.07637v1",
      "title": "Weather-Informed Probabilistic Forecasting and Scenario Generation in Power Systems",
      "title_zh": "基于天气信息的概率预测和场景",
      "authors": [
        "Hanyu Zhang",
        "Reza Zandehshahvar",
        "Mathieu Tanneau",
        "Pascal Van Hentenryck"
      ],
      "abstract": "The integration of renewable energy sources (RES) into power grids presents\nsignificant challenges due to their intrinsic stochasticity and uncertainty,\nnecessitating the development of new techniques for reliable and efficient\nforecasting. This paper proposes a method combining probabilistic forecasting\nand Gaussian copula for day-ahead prediction and scenario generation of load,\nwind, and solar power in high-dimensional contexts. By incorporating weather\ncovariates and restoring spatio-temporal correlations, the proposed method\nenhances the reliability of probabilistic forecasts in RES. Extensive numerical\nexperiments compare the effectiveness of different time series models, with\nperformance evaluated using comprehensive metrics on a real-world and\nhigh-dimensional dataset from Midcontinent Independent System Operator (MISO).\nThe results highlight the importance of weather information and demonstrate the\nefficacy of the Gaussian copula in generating realistic scenarios, with the\nproposed weather-informed Temporal Fusion Transformer (WI-TFT) model showing\nsuperior performance.",
      "tldr_zh": "本论文探讨了可再生能源（RES）集成到电力系统中的不确定性挑战，提出了一种结合概率预测和Gaussian copula的方法，用于日提前负荷、风能和太阳能的预测及场景生成。该方法通过纳入天气协变量并恢复时空相关性，提高了RES概率预测的可靠性。在MISO的真实高维数据集上进行的实验比较了不同时间序列模型的性能，结果显示Gaussian copula在生成现实场景方面效果显著，而提出的weather-informed Temporal Fusion Transformer (WI-TFT) 模型表现出色，准确率和可靠性均优于基线模型。总的来说，该研究强调了天气信息的重要性，为电力系统的可靠预测提供了新途径。",
      "categories": [
        "stat.ML",
        "cs.AI",
        "cs.LG",
        "stat.AP"
      ],
      "primary_category": "stat.ML",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2409.07637v1",
      "published_date": "2024-09-11 21:44:59 UTC",
      "updated_date": "2024-09-11 21:44:59 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-19T22:59:34.149892"
    },
    {
      "arxiv_id": "2409.13746v2",
      "title": "Mapping Biomedical Ontology Terms to IDs: Effect of Domain Prevalence on Prediction Accuracy",
      "title_zh": "翻译失败",
      "authors": [
        "Thanh Son Do",
        "Daniel B. Hier",
        "Tayo Obafemi-Ajayi"
      ],
      "abstract": "This study evaluates the ability of large language models (LLMs) to map\nbiomedical ontology terms to their corresponding ontology IDs across the Human\nPhenotype Ontology (HPO), Gene Ontology (GO), and UniProtKB terminologies.\nUsing counts of ontology IDs in the PubMed Central (PMC) dataset as a surrogate\nfor their prevalence in the biomedical literature, we examined the relationship\nbetween ontology ID prevalence and mapping accuracy. Results indicate that\nontology ID prevalence strongly predicts accurate mapping of HPO terms to HPO\nIDs, GO terms to GO IDs, and protein names to UniProtKB accession numbers.\nHigher prevalence of ontology IDs in the biomedical literature correlated with\nhigher mapping accuracy. Predictive models based on receiver operating\ncharacteristic (ROC) curves confirmed this relationship.\n  In contrast, this pattern did not apply to mapping protein names to Human\nGenome Organisation's (HUGO) gene symbols. GPT-4 achieved a high baseline\nperformance (95%) in mapping protein names to HUGO gene symbols, with mapping\naccuracy unaffected by prevalence. We propose that the high prevalence of HUGO\ngene symbols in the literature has caused these symbols to become lexicalized,\nenabling GPT-4 to map protein names to HUGO gene symbols with high accuracy.\nThese findings highlight the limitations of LLMs in mapping ontology terms to\nlow-prevalence ontology IDs and underscore the importance of incorporating\nontology ID prevalence into the training and evaluation of LLMs for biomedical\napplications.",
      "tldr_zh": "这篇论文评估了大型语言模型 (LLMs) 将生物医学本体术语（如 Human Phenotype Ontology (HPO)、Gene Ontology (GO) 和 UniProtKB）映射到对应 ID 的准确率，并考察了这些术语在 PubMed Central (PMC) 文献中的流行度对预测准确率的影响。结果显示，术语流行度与映射准确率正相关，尤其在 HPO、GO 和 UniProtKB 中，ROC 曲线预测模型证实了这一关系；然而，对蛋白质名称到 Human Genome Organisation's (HUGO) 基因符号的映射，GPT-4 保持高准确率 (95%) 并不受流行度影响，可能因 HUGO 符号已词典化。研究强调了 LLMs 在处理低流行度本体 ID 时的局限性，并建议在模型的训练和评估中纳入流行度因素，以提升生物医学应用性能。",
      "categories": [
        "cs.CL",
        "cs.AI",
        "I.2"
      ],
      "primary_category": "cs.CL",
      "comment": "Presented at 2025 IEEE Conference on Artificial Intelligence (CAI).\n  Santa Clara, CA. May 5, 2025",
      "pdf_url": "http://arxiv.org/pdf/2409.13746v2",
      "published_date": "2024-09-11 21:34:46 UTC",
      "updated_date": "2025-05-12 15:43:37 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-19T22:59:48.121291"
    },
    {
      "arxiv_id": "2409.07629v3",
      "title": "Dividable Configuration Performance Learning",
      "title_zh": "可分配置性能学习",
      "authors": [
        "Jingzhi Gong",
        "Tao Chen",
        "Rami Bahsoon"
      ],
      "abstract": "Machine/deep learning models have been widely adopted for predicting the\nconfiguration performance of software systems. However, a crucial yet\nunaddressed challenge is how to cater for the sparsity inherited from the\nconfiguration landscape: the influence of configuration options (features) and\nthe distribution of data samples are highly sparse. In this paper, we propose a\nmodel-agnostic and sparsity-robust framework for predicting configuration\nperformance, dubbed DaL, based on the new paradigm of dividable learning that\nbuilds a model via \"divide-and-learn\". To handle sample sparsity, the samples\nfrom the configuration landscape are divided into distant divisions, for each\nof which we build a sparse local model, e.g., regularized Hierarchical\nInteraction Neural Network, to deal with the feature sparsity. A newly given\nconfiguration would then be assigned to the right model of division for the\nfinal prediction. Further, DaL adaptively determines the optimal number of\ndivisions required for a system and sample size without any extra training or\nprofiling. Experiment results from 12 real-world systems and five sets of\ntraining data reveal that, compared with the state-of-the-art approaches, DaL\nperforms no worse than the best counterpart on 44 out of 60 cases with up to\n1.61x improvement on accuracy; requires fewer samples to reach the same/better\naccuracy; and producing acceptable training overhead. In particular, the\nmechanism that adapted the parameter d can reach the optimal value for 76.43%\nof the individual runs. The result also confirms that the paradigm of dividable\nlearning is more suitable than other similar paradigms such as ensemble\nlearning for predicting configuration performance. Practically, DaL\nconsiderably improves different global models when using them as the underlying\nlocal models, which further strengthens its flexibility.",
      "tldr_zh": "本文提出 DaL 框架，一种模型无关且鲁棒于稀疏性的方法，用于预测软件系统配置性能，基于 divide-and-learn 新范式，通过将样本分成多个远距离分区并为每个分区构建稀疏局部模型（如 regularized Hierarchical Interaction Neural Network），从而处理特征和样本的稀疏性。DaL 能自适应地确定最佳分区数，而无需额外训练或分析。实验在 12 个真实系统中显示，DaL 相较最先进方法在 60 个案例中 44 个表现不差，准确率最高提升 1.61 倍，并需更少样本，同时训练开销可接受，这证明 divide-and-learn 范式比 ensemble learning 等更适合配置性能预测。",
      "categories": [
        "cs.SE",
        "cs.AI"
      ],
      "primary_category": "cs.SE",
      "comment": "Accepted by TSE in October 2024. arXiv admin note: substantial text\n  overlap with arXiv:2407.02706, arXiv:2306.06651",
      "pdf_url": "http://arxiv.org/pdf/2409.07629v3",
      "published_date": "2024-09-11 21:23:23 UTC",
      "updated_date": "2024-11-20 12:40:11 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-19T22:59:59.679270"
    },
    {
      "arxiv_id": "2409.07619v1",
      "title": "Ensemble Methods for Sequence Classification with Hidden Markov Models",
      "title_zh": "使用隐马尔可夫模型的序列分类集成方法",
      "authors": [
        "Maxime Kawawa-Beaudan",
        "Srijan Sood",
        "Soham Palande",
        "Ganapathy Mani",
        "Tucker Balch",
        "Manuela Veloso"
      ],
      "abstract": "We present a lightweight approach to sequence classification using Ensemble\nMethods for Hidden Markov Models (HMMs). HMMs offer significant advantages in\nscenarios with imbalanced or smaller datasets due to their simplicity,\ninterpretability, and efficiency. These models are particularly effective in\ndomains such as finance and biology, where traditional methods struggle with\nhigh feature dimensionality and varied sequence lengths. Our ensemble-based\nscoring method enables the comparison of sequences of any length and improves\nperformance on imbalanced datasets.\n  This study focuses on the binary classification problem, particularly in\nscenarios with data imbalance, where the negative class is the majority (e.g.,\nnormal data) and the positive class is the minority (e.g., anomalous data),\noften with extreme distribution skews. We propose a novel training approach for\nHMM Ensembles that generalizes to multi-class problems and supports\nclassification and anomaly detection. Our method fits class-specific groups of\ndiverse models using random data subsets, and compares likelihoods across\nclasses to produce composite scores, achieving high average precisions and\nAUCs.\n  In addition, we compare our approach with neural network-based methods such\nas Convolutional Neural Networks (CNNs) and Long Short-Term Memory networks\n(LSTMs), highlighting the efficiency and robustness of HMMs in data-scarce\nenvironments. Motivated by real-world use cases, our method demonstrates robust\nperformance across various benchmarks, offering a flexible framework for\ndiverse applications.",
      "tldr_zh": "本文提出了一种基于 Ensemble Methods 和 Hidden Markov Models (HMMs) 的轻量级序列分类方法，特别适用于不平衡数据集和不同序列长度场景，能够通过随机数据子集训练多样模型并比较类间似然度生成复合分数。研究焦点是二元分类问题（如异常检测），并扩展到多类问题，支持高效的分类和异常检测。实验结果显示，该方法在金融和生物等领域表现出色，与 CNN 和 LSTM 等神经网络方法相比，在数据稀缺环境中实现了更高的平均精度和 AUC 指标。",
      "categories": [
        "cs.LG",
        "cs.AI"
      ],
      "primary_category": "cs.LG",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2409.07619v1",
      "published_date": "2024-09-11 20:59:32 UTC",
      "updated_date": "2024-09-11 20:59:32 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-19T23:00:11.620815"
    },
    {
      "arxiv_id": "2409.07618v1",
      "title": "Understanding Foundation Models: Are We Back in 1924?",
      "title_zh": "理解基础模型：我们又回到了1924年吗？",
      "authors": [
        "Alan F. Smeaton"
      ],
      "abstract": "This position paper explores the rapid development of Foundation Models (FMs)\nin AI and their implications for intelligence and reasoning. It examines the\ncharacteristics of FMs, including their training on vast datasets and use of\nembedding spaces to capture semantic relationships. The paper discusses recent\nadvancements in FMs' reasoning abilities which we argue cannot be attributed to\nincreased model size but to novel training techniques which yield learning\nphenomena like grokking. It also addresses the challenges in benchmarking FMs\nand compares their structure to the human brain. We argue that while FMs show\npromising developments in reasoning and knowledge representation, understanding\ntheir inner workings remains a significant challenge, similar to ongoing\nefforts in neuroscience to comprehend human brain function. Despite having some\nsimilarities, fundamental differences between FMs and the structure of human\nbrain warn us against making direct comparisons or expecting neuroscience to\nprovide immediate insights into FM function.",
      "tldr_zh": "这篇观点论文探讨了基础模型（Foundation Models, FMs）在 AI 中的快速发展及其对智能和推理的含义，分析了 FMs 通过训练于庞大数据集和使用嵌入空间（embedding spaces）来捕获语义关系的特性。论文认为，FMs 的推理能力进步主要归因于新型训练技术（如 grokking）而非模型规模增大，并指出了基准测试 FMs 的挑战。最终，它警告不要将 FMs 与人类大脑结构直接类比，尽管两者有某些相似性，但根本差异使得理解 FMs 的内部机制如同理解人类大脑一样充满挑战。",
      "categories": [
        "cs.AI",
        "cs.LG"
      ],
      "primary_category": "cs.AI",
      "comment": "7 pages, 4 Figures, to appear in Proceedings of the 2nd International\n  Conference on Foundation and Large Language Models (FLLM2024) 26-29 November,\n  2024, Dubai, UAE",
      "pdf_url": "http://arxiv.org/pdf/2409.07618v1",
      "published_date": "2024-09-11 20:59:27 UTC",
      "updated_date": "2024-09-11 20:59:27 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-19T23:00:23.630759"
    },
    {
      "arxiv_id": "2409.12170v1",
      "title": "The Unreliability of Acoustic Systems in Alzheimer's Speech Datasets with Heterogeneous Recording Conditions",
      "title_zh": "翻译失败",
      "authors": [
        "Lara Gauder",
        "Pablo Riera",
        "Andrea Slachevsky",
        "Gonzalo Forno",
        "Adolfo M. Garcia",
        "Luciana Ferrer"
      ],
      "abstract": "Automated speech analysis is a thriving approach to detect early markers of\nAlzheimer's disease (AD). Yet, recording conditions in most AD datasets are\nheterogeneous, with patients and controls often evaluated in different acoustic\nsettings. While this is not a problem for analyses based on speech\ntranscription or features obtained from manual alignment, it does cast serious\ndoubts on the validity of acoustic features, which are strongly influenced by\nacquisition conditions. We examined this issue in the ADreSSo dataset, derived\nfrom the widely used Pitt corpus. We show that systems based on two acoustic\nfeatures, MFCCs and Wav2vec 2.0 embeddings, can discriminate AD patients from\ncontrols with above-chance performance when using only the non-speech part of\nthe audio signals. We replicated this finding in a separate dataset of Spanish\nspeakers. Thus, in these datasets, the class can be partly predicted by\nrecording conditions. Our results are a warning against the use of acoustic\nsystems for identifying patients based on non-standardized recordings. We\npropose that acoustically heterogeneous datasets for dementia studies should be\neither (a) analyzed using only transcripts or other features derived from\nmanual annotations, or (b) replaced by datasets collected with strictly\ncontrolled acoustic conditions.",
      "tldr_zh": "这篇论文探讨了录音条件异质性对阿尔茨海默病(AD)语音数据集声学系统的不可靠性，指出患者和对照组的不同声学环境会扭曲基于MFCCs和Wav2vec 2.0嵌入等特征的分析。研究者在ADreSSo数据集和一个西班牙语数据集上实验，发现这些系统仅使用非语音音频部分就能高于随机水平区分AD患者和对照组，表明分类结果部分依赖于录音条件。论文警告不应在非标准化录音中使用声学系统，并建议采用基于语音转录或手动标注的特征，或转向严格控制声学条件的数据集。",
      "categories": [
        "cs.SD",
        "cs.AI",
        "cs.LG",
        "eess.AS"
      ],
      "primary_category": "cs.SD",
      "comment": "5 pages, 1 figure, 1 table",
      "pdf_url": "http://arxiv.org/pdf/2409.12170v1",
      "published_date": "2024-09-11 20:50:45 UTC",
      "updated_date": "2024-09-11 20:50:45 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-19T23:00:35.345602"
    },
    {
      "arxiv_id": "2409.07606v3",
      "title": "The Role of Deep Learning Regularizations on Actors in Offline RL",
      "title_zh": "翻译失败",
      "authors": [
        "Denis Tarasov",
        "Anja Surina",
        "Caglar Gulcehre"
      ],
      "abstract": "Deep learning regularization techniques, such as dropout, layer\nnormalization, or weight decay, are widely adopted in the construction of\nmodern artificial neural networks, often resulting in more robust training\nprocesses and improved generalization capabilities. However, in the domain of\nReinforcement Learning (RL), the application of these techniques has been\nlimited, usually applied to value function estimators (Hiraoka et al., 2021;\nSmith et al., 2022), and may result in detrimental effects. This issue is even\nmore pronounced in offline RL settings, which bear greater similarity to\nsupervised learning but have received less attention. Recent work in continuous\noffline RL (Park et al., 2024) has demonstrated that while we can build\nsufficiently powerful critic networks, the generalization of actor networks\nremains a bottleneck. In this study, we empirically show that applying standard\nregularization techniques to actor networks in offline RL actor-critic\nalgorithms yields improvements of 6% on average across two algorithms and three\ndifferent continuous D4RL domains.",
      "tldr_zh": "本文研究了深度学习正则化技术（如 dropout、layer normalization 和 weight decay）在离线强化学习(Offline RL)中对 actor 网络的作用，这些技术在传统 RL 中应用有限，且可能导致负面影响。作者通过经验性实验，在 actor-critic 算法中对 actor 网络应用这些标准正则化方法，观察到在两个算法和三个连续 D4RL 领域中的性能平均提高了 6%。这一发现强调了正则化技术在提升 actor 网络泛化能力方面的潜力，为离线 RL 的改进提供了新见解。",
      "categories": [
        "cs.LG",
        "cs.AI"
      ],
      "primary_category": "cs.LG",
      "comment": "https://github.com/DT6A/ActoReg",
      "pdf_url": "http://arxiv.org/pdf/2409.07606v3",
      "published_date": "2024-09-11 20:35:29 UTC",
      "updated_date": "2024-11-21 14:35:28 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-19T23:00:47.803587"
    },
    {
      "arxiv_id": "2409.07585v1",
      "title": "Efficient Localized Adaptation of Neural Weather Forecasting: A Case Study in the MENA Region",
      "title_zh": "高效的神经网络天气预报本地化适应：MENA 地区的一个案例研究",
      "authors": [
        "Muhammad Akhtar Munir",
        "Fahad Shahbaz Khan",
        "Salman Khan"
      ],
      "abstract": "Accurate weather and climate modeling is critical for both scientific\nadvancement and safeguarding communities against environmental risks.\nTraditional approaches rely heavily on Numerical Weather Prediction (NWP)\nmodels, which simulate energy and matter flow across Earth's systems. However,\nheavy computational requirements and low efficiency restrict the suitability of\nNWP, leading to a pressing need for enhanced modeling techniques. Neural\nnetwork-based models have emerged as promising alternatives, leveraging\ndata-driven approaches to forecast atmospheric variables. In this work, we\nfocus on limited-area modeling and train our model specifically for localized\nregion-level downstream tasks. As a case study, we consider the MENA region due\nto its unique climatic challenges, where accurate localized weather forecasting\nis crucial for managing water resources, agriculture and mitigating the impacts\nof extreme weather events. This targeted approach allows us to tailor the\nmodel's capabilities to the unique conditions of the region of interest. Our\nstudy aims to validate the effectiveness of integrating parameter-efficient\nfine-tuning (PEFT) methodologies, specifically Low-Rank Adaptation (LoRA) and\nits variants, to enhance forecast accuracy, as well as training speed,\ncomputational resource utilization, and memory efficiency in weather and\nclimate modeling for specific regions.",
      "tldr_zh": "本文研究了神经网络在天气预报中的本地化适应，以应对传统 Numerical Weather Prediction (NWP) 模型的计算密集和效率低下问题。针对 MENA 地区独特的气候挑战，该研究采用参数高效微调 (PEFT) 方法，包括 Low-Rank Adaptation (LoRA) 和其变体，对模型进行针对性训练，提高了预测准确性、训练速度、计算资源利用和内存效率。通过这一案例研究，验证了这种方法在区域性天气建模中的有效性，有助于更好地管理水资源、农业和极端天气影响。",
      "categories": [
        "cs.LG",
        "cs.AI",
        "physics.ao-ph"
      ],
      "primary_category": "cs.LG",
      "comment": "Our codebase and pre-trained models can be accessed at: [this\n  url](https://github.com/akhtarvision/weather-regional)",
      "pdf_url": "http://arxiv.org/pdf/2409.07585v1",
      "published_date": "2024-09-11 19:31:56 UTC",
      "updated_date": "2024-09-11 19:31:56 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-19T23:00:59.677901"
    },
    {
      "arxiv_id": "2409.07584v1",
      "title": "DS-ViT: Dual-Stream Vision Transformer for Cross-Task Distillation in Alzheimer's Early Diagnosis",
      "title_zh": "翻译失败",
      "authors": [
        "Ke Chen",
        "Yifeng Wang",
        "Yufei Zhou",
        "Haohan Wang"
      ],
      "abstract": "In the field of Alzheimer's disease diagnosis, segmentation and\nclassification tasks are inherently interconnected. Sharing knowledge between\nmodels for these tasks can significantly improve training efficiency,\nparticularly when training data is scarce. However, traditional knowledge\ndistillation techniques often struggle to bridge the gap between segmentation\nand classification due to the distinct nature of tasks and different model\narchitectures. To address this challenge, we propose a dual-stream pipeline\nthat facilitates cross-task and cross-architecture knowledge sharing. Our\napproach introduces a dual-stream embedding module that unifies feature\nrepresentations from segmentation and classification models, enabling\ndimensional integration of these features to guide the classification model. We\nvalidated our method on multiple 3D datasets for Alzheimer's disease diagnosis,\ndemonstrating significant improvements in classification performance,\nespecially on small datasets. Furthermore, we extended our pipeline with a\nresidual temporal attention mechanism for early diagnosis, utilizing images\ntaken before the atrophy of patients' brain mass. This advancement shows\npromise in enabling diagnosis approximately six months earlier in mild and\nasymptomatic stages, offering critical time for intervention.",
      "tldr_zh": "该研究提出 DS-ViT，一种双流 Vision Transformer 框架，用于阿尔茨海默病早期诊断中的跨任务知识 distillation。框架通过双流嵌入模块统一分割和分类模型的特征表示，实现跨任务和跨架构知识共享，从而显著提升分类性能，尤其在数据稀缺的小型 3D 数据集上。进一步，论文扩展了该管道，添加了 residual temporal attention mechanism，利用患者脑部萎缩前的图像，实现轻度或无症状阶段提前约六个月的诊断，为及时干预提供关键窗口。",
      "categories": [
        "eess.IV",
        "cs.AI",
        "cs.CV",
        "68T07, 92C55 (Primary) 93C85 (Secondary)"
      ],
      "primary_category": "eess.IV",
      "comment": "8 pages, 3 figures, 3 tables",
      "pdf_url": "http://arxiv.org/pdf/2409.07584v1",
      "published_date": "2024-09-11 19:31:01 UTC",
      "updated_date": "2024-09-11 19:31:01 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-19T23:01:11.403294"
    },
    {
      "arxiv_id": "2409.07581v1",
      "title": "Violence detection in videos using deep recurrent and convolutional neural networks",
      "title_zh": "翻译失败",
      "authors": [
        "Abdarahmane Traoré",
        "Moulay A. Akhloufi"
      ],
      "abstract": "Violence and abnormal behavior detection research have known an increase of\ninterest in recent years, due mainly to a rise in crimes in large cities\nworldwide. In this work, we propose a deep learning architecture for violence\ndetection which combines both recurrent neural networks (RNNs) and\n2-dimensional convolutional neural networks (2D CNN). In addition to video\nframes, we use optical flow computed using the captured sequences. CNN extracts\nspatial characteristics in each frame, while RNN extracts temporal\ncharacteristics. The use of optical flow allows to encode the movements in the\nscenes. The proposed approaches reach the same level as the state-of-the-art\ntechniques and sometime surpass them. It was validated on 3 databases achieving\ngood results.",
      "tldr_zh": "本文提出了一种基于深度学习的架构，用于视频中的暴力检测，该方法结合了循环神经网络 (RNNs) 和二维卷积神经网络 (2D CNN)，并利用光学流 (optical flow) 来提取帧的空间特征和场景的运动信息。RNNs 负责捕捉时间特征，而 2D CNN 则处理空间特征，从而提高检测的准确性。该架构在 3 个数据库上进行了验证，达到了或超过了现有最先进技术 (state-of-the-art) 的性能水平。",
      "categories": [
        "cs.CV",
        "cs.AI"
      ],
      "primary_category": "cs.CV",
      "comment": "11 pages, 7 figures, 2020 IEEE International Conference on Systems,\n  Man, and Cybernetics (SMC)",
      "pdf_url": "http://arxiv.org/pdf/2409.07581v1",
      "published_date": "2024-09-11 19:21:51 UTC",
      "updated_date": "2024-09-11 19:21:51 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-19T23:01:22.634568"
    },
    {
      "arxiv_id": "2409.07578v3",
      "title": "A Novel Mathematical Framework for Objective Characterization of Ideas",
      "title_zh": "一种新颖的数学框架用于对想法的客观表征",
      "authors": [
        "B. Sankar",
        "Dibakar Sen"
      ],
      "abstract": "The demand for innovation in product design necessitates a prolific ideation\nphase. Conversational AI (CAI) systems that use Large Language Models (LLMs)\nsuch as GPT (Generative Pre-trained Transformer) have been shown to be fruitful\nin augmenting human creativity, providing numerous novel and diverse ideas.\nDespite the success in ideation quantity, the qualitative assessment of these\nideas remains challenging and traditionally reliant on expert human evaluation.\nThis method suffers from limitations such as human judgment errors, bias, and\noversight. Addressing this gap, our study introduces a comprehensive\nmathematical framework for automated analysis to objectively evaluate the\nplethora of ideas generated by CAI systems and/or humans. This framework is\nparticularly advantageous for novice designers who lack experience in selecting\npromising ideas. By converting the ideas into higher dimensional vectors and\nquantitatively measuring the diversity between them using tools such as UMAP,\nDBSCAN and PCA, the proposed method provides a reliable and objective way of\nselecting the most promising ideas, thereby enhancing the efficiency of the\nideation phase.",
      "tldr_zh": "这篇论文提出一个新的数学框架，用于客观评估由Conversational AI (CAI)系统（如基于Large Language Models (LLMs)的GPT）或人类生成的创新想法，以克服传统专家评估的偏差、错误和疏忽问题。该框架将想法转换为高维向量，并通过UMAP、DBSCAN和PCA等工具量化测量想法之间的多样性，提供自动化且可靠的分析方法。该方法特别适用于新手设计师，帮助他们高效筛选最有前景的想法，从而提升创新构思阶段的整体效率。",
      "categories": [
        "cs.AI",
        "53A45",
        "I.2.7; G.3"
      ],
      "primary_category": "cs.AI",
      "comment": "35 pages, 18 figures, 6 tables",
      "pdf_url": "http://arxiv.org/pdf/2409.07578v3",
      "published_date": "2024-09-11 19:10:29 UTC",
      "updated_date": "2025-05-15 18:53:26 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-19T23:01:45.584683"
    },
    {
      "arxiv_id": "2409.07569v3",
      "title": "A Comprehensive Survey on Inverse Constrained Reinforcement Learning: Definitions, Progress and Challenges",
      "title_zh": "关于逆向约束强化学习的全面调查：定义、进展和挑战",
      "authors": [
        "Guiliang Liu",
        "Sheng Xu",
        "Shicheng Liu",
        "Ashish Gaurav",
        "Sriram Ganapathi Subramanian",
        "Pascal Poupart"
      ],
      "abstract": "Inverse Constrained Reinforcement Learning (ICRL) is the task of inferring\nthe implicit constraints that expert agents adhere to, based on their\ndemonstration data. As an emerging research topic, ICRL has received\nconsiderable attention in recent years. This article presents a categorical\nsurvey of the latest advances in ICRL. It serves as a comprehensive reference\nfor machine learning researchers and practitioners, as well as starters seeking\nto comprehend the definitions, advancements, and important challenges in ICRL.\nWe begin by formally defining the problem and outlining the algorithmic\nframework that facilitates constraint inference across various scenarios. These\ninclude deterministic or stochastic environments, environments with limited\ndemonstrations, and multiple agents. For each context, we illustrate the\ncritical challenges and introduce a series of fundamental methods to tackle\nthese issues. This survey encompasses discrete, virtual, and realistic\nenvironments for evaluating ICRL agents. We also delve into the most pertinent\napplications of ICRL, such as autonomous driving, robot control, and sports\nanalytics. To stimulate continuing research, we conclude the survey with a\ndiscussion of key unresolved questions in ICRL that can effectively foster a\nbridge between theoretical understanding and practical industrial applications.\nThe papers referenced in this survey can be found at\nhttps://github.com/Jasonxu1225/Awesome-Constraint-Inference-in-RL.",
      "tldr_zh": "这篇调查论文对Inverse Constrained Reinforcement Learning (ICRL)进行了全面综述，旨在从专家演示数据中推断隐含约束。论文首先正式定义ICRL问题，并概述了适用于各种场景（如确定性/随机环境、有限演示或多代理设置）的算法框架，同时介绍了应对关键挑战的基本方法。调查涵盖了离散、虚拟和现实环境下的评估，以及实际应用如自动驾驶、机器人控制和体育分析；最后，讨论了未解决的问题，以桥接理论与工业实践，并提供参考资源。",
      "categories": [
        "cs.LG",
        "cs.AI"
      ],
      "primary_category": "cs.LG",
      "comment": "36 pages",
      "pdf_url": "http://arxiv.org/pdf/2409.07569v3",
      "published_date": "2024-09-11 18:49:03 UTC",
      "updated_date": "2025-02-01 03:57:57 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-19T23:01:47.102064"
    },
    {
      "arxiv_id": "2409.07547v1",
      "title": "Machine Learning and Constraint Programming for Efficient Healthcare Scheduling",
      "title_zh": "机器",
      "authors": [
        "Aymen Ben Said",
        "Malek Mouhoub"
      ],
      "abstract": "Solving combinatorial optimization problems involve satisfying a set of hard\nconstraints while optimizing some objectives. In this context, exact or\napproximate methods can be used. While exact methods guarantee the optimal\nsolution, they often come with an exponential running time as opposed to\napproximate methods that trade the solutions quality for a better running time.\nIn this context, we tackle the Nurse Scheduling Problem (NSP). The NSP consist\nin assigning nurses to daily shifts within a planning horizon such that\nworkload constraints are satisfied while hospitals costs and nurses preferences\nare optimized. To solve the NSP, we propose implicit and explicit approaches.\nIn the implicit solving approach, we rely on Machine Learning methods using\nhistorical data to learn and generate new solutions through the constraints and\nobjectives that may be embedded in the learned patterns. To quantify the\nquality of using our implicit approach in capturing the embedded constraints\nand objectives, we rely on the Frobenius Norm, a quality measure used to\ncompute the average error between the generated solutions and historical data.\nTo compensate for the uncertainty related to the implicit approach given that\nthe constraints and objectives may not be concretely visible in the produced\nsolutions, we propose an alternative explicit approach where we first model the\nNSP using the Constraint Satisfaction Problem (CSP) framework. Then we develop\nStochastic Local Search methods and a new Branch and Bound algorithm enhanced\nwith constraint propagation techniques and variables/values ordering\nheuristics. Since our implicit approach may not guarantee the feasibility or\noptimality of the generated solution, we propose a data-driven approach to\npassively learn the NSP as a constraint network. The learned constraint\nnetwork, formulated as a CSP, will then be solved using the methods we listed\nearlier.",
      "tldr_zh": "本文针对 Nurse Scheduling Problem (NSP)，提出结合 Machine Learning 和 Constraint Programming 的方法，以高效解决医疗保健调度问题，包括满足工作负载约束并优化医院成本和护士偏好。隐式方法使用 Machine Learning 基于历史数据学习生成新解决方案，并通过 Frobenius Norm 量化生成方案与历史数据的误差，以捕捉潜在约束和目标。显式方法则将 NSP 建模为 Constraint Satisfaction Problem (CSP)，并开发 Stochastic Local Search 算法和增强的 Branch and Bound 算法，结合约束传播技术和变量/值排序启发式来确保解决方案的可行性。最终，通过数据驱动方法从隐式生成的解决方案中学习约束网络，并将其作为 CSP 形式解决，提高了整体调度的准确性和效率。",
      "categories": [
        "cs.AI"
      ],
      "primary_category": "cs.AI",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2409.07547v1",
      "published_date": "2024-09-11 18:09:25 UTC",
      "updated_date": "2024-09-11 18:09:25 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-19T23:02:00.769030"
    },
    {
      "arxiv_id": "2409.07453v1",
      "title": "\"My Grade is Wrong!\": A Contestable AI Framework for Interactive Feedback in Evaluating Student Essays",
      "title_zh": "翻译失败",
      "authors": [
        "Shengxin Hong",
        "Chang Cai",
        "Sixuan Du",
        "Haiyue Feng",
        "Siyuan Liu",
        "Xiuyi Fan"
      ],
      "abstract": "Interactive feedback, where feedback flows in both directions between teacher\nand student, is more effective than traditional one-way feedback. However, it\nis often too time-consuming for widespread use in educational practice. While\nLarge Language Models (LLMs) have potential for automating feedback, they\nstruggle with reasoning and interaction in an interactive setting. This paper\nintroduces CAELF, a Contestable AI Empowered LLM Framework for automating\ninteractive feedback. CAELF allows students to query, challenge, and clarify\ntheir feedback by integrating a multi-agent system with computational\nargumentation. Essays are first assessed by multiple Teaching-Assistant Agents\n(TA Agents), and then a Teacher Agent aggregates the evaluations through formal\nreasoning to generate feedback and grades. Students can further engage with the\nfeedback to refine their understanding. A case study on 500 critical thinking\nessays with user studies demonstrates that CAELF significantly improves\ninteractive feedback, enhancing the reasoning and interaction capabilities of\nLLMs. This approach offers a promising solution to overcoming the time and\nresource barriers that have limited the adoption of interactive feedback in\neducational settings.",
      "tldr_zh": "这篇论文提出 CAELF 框架，一种基于可争辩 AI 的 Large Language Models (LLMs) 系统，用于自动化交互式反馈，以解决传统反馈耗时的问题。CAELF 整合多智能体系统和 computational argumentation，允许多个 Teaching-Assistant Agents (TA Agents) 评估学生作文，然后由 Teacher Agent 通过正式推理聚合结果，生成反馈和分数，同时支持学生查询、挑战和澄清反馈。在 500 篇批判性思维作文的案例研究中，用户研究证明 CAELF 显著提升了 LLMs 的推理和交互能力，为教育环境中推广交互式反馈提供了高效解决方案。",
      "categories": [
        "cs.AI",
        "cs.HC"
      ],
      "primary_category": "cs.AI",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2409.07453v1",
      "published_date": "2024-09-11 17:59:01 UTC",
      "updated_date": "2024-09-11 17:59:01 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-19T23:02:11.922349"
    },
    {
      "arxiv_id": "2409.07510v5",
      "title": "Still More Shades of Null: An Evaluation Suite for Responsible Missing Value Imputation",
      "title_zh": "Still More Shades of Null：负责任缺失值插补的评估套件",
      "authors": [
        "Falaah Arif Khan",
        "Denys Herasymuk",
        "Nazar Protsiv",
        "Julia Stoyanovich"
      ],
      "abstract": "Data missingness is a practical challenge of sustained interest to the\nscientific community. In this paper, we present Shades-of-Null, an evaluation\nsuite for responsible missing value imputation. Our work is novel in two ways\n(i) we model realistic and socially-salient missingness scenarios that go\nbeyond Rubin's classic Missing Completely at Random (MCAR), Missing At Random\n(MAR) and Missing Not At Random (MNAR) settings, to include multi-mechanism\nmissingness (when different missingness patterns co-exist in the data) and\nmissingness shift (when the missingness mechanism changes between training and\ntest) (ii) we evaluate imputers holistically, based on imputation quality and\nimputation fairness, as well as on the predictive performance, fairness and\nstability of the models that are trained and tested on the data\npost-imputation.\n  We use Shades-of-Null to conduct a large-scale empirical study involving\n29,736 experimental pipelines, and find that while there is no single\nbest-performing imputation approach for all missingness types, interesting\ntrade-offs arise between predictive performance, fairness and stability, based\non the combination of missingness scenario, imputer choice, and the\narchitecture of the predictive model. We make Shades-of-Null publicly\navailable, to enable researchers to rigorously evaluate missing value\nimputation methods on a wide range of metrics in plausible and socially\nmeaningful scenarios.",
      "tldr_zh": "这篇论文介绍了 Shades-of-Null，这是一个用于负责任缺失值插补的评估套件，旨在处理数据缺失的实际挑战。不同于传统的 MCAR、MAR 和 MNAR 机制，该套件扩展了缺失场景，包括 multi-mechanism missingness（多种缺失模式共存）和 missingness shift（训练与测试间机制变化）。它从插补质量、公平性以及后续模型的预测性能、公平性和稳定性等方面进行全面评估。通过 29,736 个实验管道的大规模实证研究，发现不同插补方法在各种缺失类型间存在预测性能、公平性和稳定性之间的权衡。Shades-of-Null 被公开可用，帮助研究者在真实社会场景中评估缺失值插补方法。",
      "categories": [
        "cs.AI",
        "cs.CY",
        "cs.LG"
      ],
      "primary_category": "cs.AI",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2409.07510v5",
      "published_date": "2024-09-11 17:58:39 UTC",
      "updated_date": "2025-03-18 17:46:41 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-19T23:02:24.868937"
    },
    {
      "arxiv_id": "2409.07448v3",
      "title": "Introducing Perturb-ability Score (PS) to Enhance Robustness Against Problem-Space Evasion Adversarial Attacks on Flow-based ML-NIDS",
      "title_zh": "翻译失败",
      "authors": [
        "Mohamed elShehaby",
        "Ashraf Matrawy"
      ],
      "abstract": "As network security threats continue to evolve, safeguarding Machine Learning\n(ML)-based Network Intrusion Detection Systems (NIDS) from adversarial attacks\nis crucial. This paper introduces the notion of feature perturb-ability and\npresents a novel Perturb-ability Score (PS) metric that identifies NIDS\nfeatures susceptible to manipulation in the problem-space by an attacker. By\nquantifying a feature's susceptibility to perturbations within the\nproblem-space, the PS facilitates the selection of features that are inherently\nmore robust against evasion adversarial attacks on ML-NIDS during the feature\nselection phase. These features exhibit natural resilience to perturbations, as\nthey are heavily constrained by the problem-space limitations and correlations\nof the NIDS domain. Furthermore, manipulating these features may either disrupt\nthe malicious function of evasion adversarial attacks on NIDS or render the\nnetwork traffic invalid for processing (or both). This proposed novel approach\nemploys a fresh angle by leveraging network domain constraints as a defense\nmechanism against problem-space evasion adversarial attacks targeting ML-NIDS.\nWe demonstrate the effectiveness of our PS-guided feature selection defense in\nenhancing NIDS robustness. Experimental results across various ML-based NIDS\nmodels and public datasets show that selecting only robust features (low-PS\nfeatures) can maintain solid detection performance while significantly reducing\nvulnerability to evasion adversarial attacks. Additionally, our findings verify\nthat the PS effectively identifies NIDS features highly vulnerable to\nproblem-space perturbations.",
      "tldr_zh": "本论文引入了 Perturb-ability Score (PS) 指标，用于评估 ML-NIDS 特征对问题空间规避攻击的易感性，从而在特征选择阶段优先选择更鲁棒的特征。\nPS 通过量化特征的可扰动性，借助网络域约束来增强防御机制，使操纵这些特征可能破坏攻击效果或使网络流量无效。\n实验结果表明，在各种 ML 模型和公共数据集上，选择低 PS 特征能保持良好的检测性能，同时显著降低对 evasion adversarial attacks 的脆弱性。",
      "categories": [
        "cs.CR",
        "cs.AI",
        "cs.LG"
      ],
      "primary_category": "cs.CR",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2409.07448v3",
      "published_date": "2024-09-11 17:52:37 UTC",
      "updated_date": "2025-01-22 18:10:50 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-19T23:02:35.810134"
    },
    {
      "arxiv_id": "2409.07440v1",
      "title": "SUPER: Evaluating Agents on Setting Up and Executing Tasks from Research Repositories",
      "title_zh": "翻译失败",
      "authors": [
        "Ben Bogin",
        "Kejuan Yang",
        "Shashank Gupta",
        "Kyle Richardson",
        "Erin Bransom",
        "Peter Clark",
        "Ashish Sabharwal",
        "Tushar Khot"
      ],
      "abstract": "Given that Large Language Models (LLMs) have made significant progress in\nwriting code, can they now be used to autonomously reproduce results from\nresearch repositories? Such a capability would be a boon to the research\ncommunity, helping researchers validate, understand, and extend prior work. To\nadvance towards this goal, we introduce SUPER, the first benchmark designed to\nevaluate the capability of LLMs in setting up and executing tasks from research\nrepositories. SUPERaims to capture the realistic challenges faced by\nresearchers working with Machine Learning (ML) and Natural Language Processing\n(NLP) research repositories. Our benchmark comprises three distinct problem\nsets: 45 end-to-end problems with annotated expert solutions, 152 sub problems\nderived from the expert set that focus on specific challenges (e.g.,\nconfiguring a trainer), and 602 automatically generated problems for\nlarger-scale development. We introduce various evaluation measures to assess\nboth task success and progress, utilizing gold solutions when available or\napproximations otherwise. We show that state-of-the-art approaches struggle to\nsolve these problems with the best model (GPT-4o) solving only 16.3% of the\nend-to-end set, and 46.1% of the scenarios. This illustrates the challenge of\nthis task, and suggests that SUPER can serve as a valuable resource for the\ncommunity to make and measure progress.",
      "tldr_zh": "该论文引入了SUPER基准，用于评估大型语言模型(LLMs)是否能自主从研究仓库中设置和执行任务，以重现研究结果，从而帮助研究者验证、理解和扩展现有工作。SUPER基准包括45个端到端问题（附专家解决方案）、152个子问题（聚焦特定挑战，如配置训练器）和602个自动生成问题，并采用多种评估措施来衡量任务成功和进度。实验结果显示，最先进模型如GPT-4o仅解决了16.3%的端到端问题和46.1%的场景，突显了这一任务的难度，并将SUPER定位为社区推动LLMs进步的宝贵资源。",
      "categories": [
        "cs.AI",
        "cs.CL",
        "cs.SE"
      ],
      "primary_category": "cs.AI",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2409.07440v1",
      "published_date": "2024-09-11 17:37:48 UTC",
      "updated_date": "2024-09-11 17:37:48 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-19T23:02:47.233446"
    },
    {
      "arxiv_id": "2409.07431v2",
      "title": "Synthetic continued pretraining",
      "title_zh": "合成持续预训练",
      "authors": [
        "Zitong Yang",
        "Neil Band",
        "Shuangping Li",
        "Emmanuel Candès",
        "Tatsunori Hashimoto"
      ],
      "abstract": "Pretraining on large-scale, unstructured internet text enables language\nmodels to acquire a significant amount of world knowledge. However, this\nknowledge acquisition is data-inefficient--to learn a given fact, models must\nbe trained on hundreds to thousands of diverse representations of it. This\nposes a challenge when adapting a pretrained model to a small corpus of\ndomain-specific documents, where each fact may appear rarely or only once. We\npropose to bridge this gap with synthetic continued pretraining: using the\nsmall domain-specific corpus to synthesize a large corpus more amenable to\nlearning, and then performing continued pretraining on the synthesized corpus.\nWe instantiate this proposal with EntiGraph, a synthetic data augmentation\nalgorithm that extracts salient entities from the source documents and then\ngenerates diverse text by drawing connections between the sampled entities.\nSynthetic continued pretraining with EntiGraph enables a language model to\nanswer questions and follow generic instructions related to the source\ndocuments without access to them. If, instead, the source documents are\navailable at inference time, we show that the knowledge acquired through our\napproach compounds with retrieval-augmented generation. To better understand\nthese results, we build a simple mathematical model of EntiGraph, and show how\nsynthetic data augmentation can \"rearrange\" knowledge to enable more\ndata-efficient learning.",
      "tldr_zh": "该论文提出 synthetic continued pretraining 方法，以提高语言模型在小规模领域特定文档上的知识学习效率，因为传统预训练需要数百次重复 exposure 才能掌握一个事实。研究引入 EntiGraph 算法，从源文档提取显著实体，并通过在采样实体之间建立连接生成多样化合成文本，用于后续预训练。该方法使模型能够在没有源文档的情况下回答问题和遵循指令；若源文档在推理时可用，其知识可与 retrieval-augmented generation 结合，进一步提升性能。作者还构建了一个简单数学模型，解释 synthetic data augmentation 如何“重新排列”知识，实现更高效的学习。",
      "categories": [
        "cs.LG",
        "cs.AI",
        "cs.CL",
        "stat.ML"
      ],
      "primary_category": "cs.LG",
      "comment": "Updated organization of experimental results and methods\n  introduction. Released the dataset and model weights artifact",
      "pdf_url": "http://arxiv.org/pdf/2409.07431v2",
      "published_date": "2024-09-11 17:21:59 UTC",
      "updated_date": "2024-10-03 13:07:25 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-19T23:03:00.155572"
    },
    {
      "arxiv_id": "2409.07416v1",
      "title": "Hierarchical Reinforcement Learning for Temporal Abstraction of Listwise Recommendation",
      "title_zh": "翻译失败",
      "authors": [
        "Luo Ji",
        "Gao Liu",
        "Mingyang Yin",
        "Hongxia Yang",
        "Jingren Zhou"
      ],
      "abstract": "Modern listwise recommendation systems need to consider both long-term user\nperceptions and short-term interest shifts. Reinforcement learning can be\napplied on recommendation to study such a problem but is also subject to large\nsearch space, sparse user feedback and long interactive latency. Motivated by\nrecent progress in hierarchical reinforcement learning, we propose a novel\nframework called mccHRL to provide different levels of temporal abstraction on\nlistwise recommendation. Within the hierarchical framework, the high-level\nagent studies the evolution of user perception, while the low-level agent\nproduces the item selection policy by modeling the process as a sequential\ndecision-making problem. We argue that such framework has a well-defined\ndecomposition of the outra-session context and the intra-session context, which\nare encoded by the high-level and low-level agents, respectively. To verify\nthis argument, we implement both a simulator-based environment and an\nindustrial dataset-based experiment. Results observe significant performance\nimprovement by our method, compared with several well-known baselines. Data and\ncodes have been made public.",
      "tldr_zh": "本研究针对列表式推荐(listwise recommendation)系统的问题，提出了一种名为 mccHRL 的分层强化学习(hierarchical reinforcement learning)框架，以处理用户感知的长期演变和短期兴趣变化。高层代理负责研究用户整体感知的演变，而低层代理则通过顺序决策建模物品选择策略，实现上下文的层次化分解。实验结果显示，该框架在模拟器环境和工业数据集上，比现有基线方法取得了显著性能提升。数据和代码已公开，以促进进一步研究。",
      "categories": [
        "cs.IR",
        "cs.AI",
        "cs.LG"
      ],
      "primary_category": "cs.IR",
      "comment": "18 pages, 4 figures",
      "pdf_url": "http://arxiv.org/pdf/2409.07416v1",
      "published_date": "2024-09-11 17:01:06 UTC",
      "updated_date": "2024-09-11 17:01:06 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-19T23:03:11.393270"
    },
    {
      "arxiv_id": "2409.07415v2",
      "title": "SoK: Security and Privacy Risks of Healthcare AI",
      "title_zh": "SoK: 医疗保健人工智能的安全和隐私风险",
      "authors": [
        "Yuanhaur Chang",
        "Han Liu",
        "Chenyang Lu",
        "Ning Zhang"
      ],
      "abstract": "The integration of artificial intelligence (AI) and machine learning (ML)\ninto healthcare systems holds great promise for enhancing patient care and care\ndelivery efficiency; however, it also exposes sensitive data and system\nintegrity to potential cyberattacks. Current security and privacy (S&P)\nresearch on healthcare AI is highly unbalanced in terms of healthcare\ndeployment scenarios and threat models, and has a disconnected focus with the\nbiomedical research community. This hinders a comprehensive understanding of\nthe risks that healthcare AI entails. To address this gap, this paper takes a\nthorough examination of existing healthcare AI S&P research, providing a\nunified framework that allows the identification of under-explored areas. Our\nsurvey presents a systematic overview of healthcare AI attacks and defenses,\nand points out challenges and research opportunities for each AI-driven\nhealthcare application domain. Through our experimental analysis of different\nthreat models and feasibility studies on under-explored adversarial attacks, we\nprovide compelling insights into the pressing need for cybersecurity research\nin the rapidly evolving field of healthcare AI.",
      "tldr_zh": "这篇 SoK 论文系统分析了医疗 AI 的安全和隐私（S&P）风险，指出 AI 和 ML 在医疗系统中的应用虽能提升患者护理效率，但也暴露了敏感数据和系统完整性给潜在网络攻击。作者通过一个统一的框架，概述了现有攻击和防御研究，识别了在不同医疗部署场景和威胁模型中未充分探索的领域。实验分析进一步揭示了这些风险的紧迫性，并为 AI 驱动医疗应用领域的挑战和研究机会提供了宝贵见解。",
      "categories": [
        "cs.CR",
        "cs.AI",
        "cs.LG"
      ],
      "primary_category": "cs.CR",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2409.07415v2",
      "published_date": "2024-09-11 16:59:58 UTC",
      "updated_date": "2025-04-30 22:27:30 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-19T23:03:23.421750"
    },
    {
      "arxiv_id": "2409.07409v2",
      "title": "Robust Robot Walker: Learning Agile Locomotion over Tiny Traps",
      "title_zh": "翻译失败",
      "authors": [
        "Shaoting Zhu",
        "Runhan Huang",
        "Linzhan Mou",
        "Hang Zhao"
      ],
      "abstract": "Quadruped robots must exhibit robust walking capabilities in practical\napplications. In this work, we propose a novel approach that enables quadruped\nrobots to pass various small obstacles, or \"tiny traps\". Existing methods often\nrely on exteroceptive sensors, which can be unreliable for detecting such tiny\ntraps. To overcome this limitation, our approach focuses solely on\nproprioceptive inputs. We introduce a two-stage training framework\nincorporating a contact encoder and a classification head to learn implicit\nrepresentations of different traps. Additionally, we design a set of tailored\nreward functions to improve both the stability of training and the ease of\ndeployment for goal-tracking tasks. To benefit further research, we design a\nnew benchmark for tiny trap task. Extensive experiments in both simulation and\nreal-world settings demonstrate the effectiveness and robustness of our method.\nProject Page: https://robust-robot-walker.github.io/",
      "tldr_zh": "本文提出了一种名为 Robust Robot Walker 的方法，使用仅本体感觉输入（proprioceptive inputs）来实现四足机器人在小障碍物（tiny traps）上进行敏捷行走，克服了依赖外部传感器的现有方法的局限性。该方法采用两阶段训练框架，包括接触编码器（contact encoder）和分类头（classification head），以学习陷阱的隐式表示，并设计了定制的奖励函数来提升训练稳定性和任务部署的便利性。为促进研究，我们创建了一个新的基准测试，并在模拟和真实环境中进行的实验证明了该方法的有效性和鲁棒性。",
      "categories": [
        "cs.RO",
        "cs.AI"
      ],
      "primary_category": "cs.RO",
      "comment": "10 pages, 17 figures",
      "pdf_url": "http://arxiv.org/pdf/2409.07409v2",
      "published_date": "2024-09-11 16:50:29 UTC",
      "updated_date": "2024-09-12 15:35:49 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-19T23:03:35.932929"
    },
    {
      "arxiv_id": "2409.07407v1",
      "title": "CLNX: Bridging Code and Natural Language for C/C++ Vulnerability-Contributing Commits Identification",
      "title_zh": "CLNX：桥接代码和自然语言以识别 C/C++ 漏洞贡献提交",
      "authors": [
        "Zeqing Qin",
        "Yiwei Wu",
        "Lansheng Han"
      ],
      "abstract": "Large Language Models (LLMs) have shown great promise in vulnerability\nidentification. As C/C++ comprises half of the Open-Source Software (OSS)\nvulnerabilities over the past decade and updates in OSS mainly occur through\ncommits, enhancing LLMs' ability to identify C/C++ Vulnerability-Contributing\nCommits (VCCs) is essential. However, current studies primarily focus on\nfurther pre-training LLMs on massive code datasets, which is resource-intensive\nand poses efficiency challenges. In this paper, we enhance the ability of\nBERT-based LLMs to identify C/C++ VCCs in a lightweight manner. We propose\nCodeLinguaNexus (CLNX) as a bridge facilitating communication between C/C++\nprograms and LLMs. Based on commits, CLNX efficiently converts the source code\ninto a more natural representation while preserving key details. Specifically,\nCLNX first applies structure-level naturalization to decompose complex\nprograms, followed by token-level naturalization to interpret complex symbols.\nWe evaluate CLNX on public datasets of 25,872 C/C++ functions with their\ncommits. The results show that CLNX significantly enhances the performance of\nLLMs on identifying C/C++ VCCs. Moreover, CLNX-equipped CodeBERT achieves new\nstate-of-the-art and identifies 38 OSS vulnerabilities in the real world.",
      "tldr_zh": "本研究提出 CLNX，一种轻量级框架，用于桥接 C/C++ 代码和自然语言，从而增强 BERT-based LLMs 在识别 C/C++ Vulnerability-Contributing Commits (VCCs) 的能力。CLNX 通过 structure-level naturalization 分解复杂程序，以及 token-level naturalization 解释复杂符号，将源代码转换为更自然的表示，同时保留关键细节。在包含 25,872 个 C/C++ 函数的公共数据集上实验表明，CLNX 显著提升了 LLMs 的性能，配备 CLNX 的 CodeBERT 达到了新的 state-of-the-art 水平，并在现实世界中识别了 38 个 OSS 漏洞。",
      "categories": [
        "cs.CR",
        "cs.AI",
        "68M25"
      ],
      "primary_category": "cs.CR",
      "comment": "8 pages, 2 figures, conference",
      "pdf_url": "http://arxiv.org/pdf/2409.07407v1",
      "published_date": "2024-09-11 16:49:46 UTC",
      "updated_date": "2024-09-11 16:49:46 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-19T23:03:47.177277"
    },
    {
      "arxiv_id": "2409.07402v2",
      "title": "What to align in multimodal contrastive learning?",
      "title_zh": "在多模态对比学习中该对齐什么？",
      "authors": [
        "Benoit Dufumier",
        "Javiera Castillo-Navarro",
        "Devis Tuia",
        "Jean-Philippe Thiran"
      ],
      "abstract": "Humans perceive the world through multisensory integration, blending the\ninformation of different modalities to adapt their behavior. Contrastive\nlearning offers an appealing solution for multimodal self-supervised learning.\nIndeed, by considering each modality as a different view of the same entity, it\nlearns to align features of different modalities in a shared representation\nspace. However, this approach is intrinsically limited as it only learns shared\nor redundant information between modalities, while multimodal interactions can\narise in other ways. In this work, we introduce CoMM, a Contrastive MultiModal\nlearning strategy that enables the communication between modalities in a single\nmultimodal space. Instead of imposing cross- or intra- modality constraints, we\npropose to align multimodal representations by maximizing the mutual\ninformation between augmented versions of these multimodal features. Our\ntheoretical analysis shows that shared, synergistic and unique terms of\ninformation naturally emerge from this formulation, allowing us to estimate\nmultimodal interactions beyond redundancy. We test CoMM both in a controlled\nand in a series of real-world settings: in the former, we demonstrate that CoMM\neffectively captures redundant, unique and synergistic information between\nmodalities. In the latter, CoMM learns complex multimodal interactions and\nachieves state-of-the-art results on the seven multimodal benchmarks. Code is\navailable at https://github.com/Duplums/CoMM",
      "tldr_zh": "本论文探讨了多模态对比学习（multimodal contrastive learning）中应该对齐哪些元素，指出传统方法仅学习模态间的共享或冗余信息，而忽略其他交互形式。作者提出 CoMM（Contrastive MultiModal learning strategy），通过最大化增强版本的多模态特征之间的互信息，在单个多模态空间中实现模态通信，从而自然捕捉共享、协同和独特信息。实验验证显示，CoMM 不仅在控制环境中有效估计多模态交互，还在七个真实世界基准上达到最先进（state-of-the-art）结果。",
      "categories": [
        "cs.LG",
        "cs.AI",
        "cs.CL",
        "cs.CV"
      ],
      "primary_category": "cs.LG",
      "comment": "ICLR 2025, 25 pages",
      "pdf_url": "http://arxiv.org/pdf/2409.07402v2",
      "published_date": "2024-09-11 16:42:22 UTC",
      "updated_date": "2025-03-05 16:48:23 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-19T23:03:59.622872"
    },
    {
      "arxiv_id": "2409.07372v1",
      "title": "Awaking the Slides: A Tuning-free and Knowledge-regulated AI Tutoring System via Language Model Coordination",
      "title_zh": "翻译失败",
      "authors": [
        "Daniel Zhang-Li",
        "Zheyuan Zhang",
        "Jifan Yu",
        "Joy Lim Jia Yin",
        "Shangqing Tu",
        "Linlu Gong",
        "Haohua Wang",
        "Zhiyuan Liu",
        "Huiqin Liu",
        "Lei Hou",
        "Juanzi Li"
      ],
      "abstract": "The vast pre-existing slides serve as rich and important materials to carry\nlecture knowledge. However, effectively leveraging lecture slides to serve\nstudents is difficult due to the multi-modal nature of slide content and the\nheterogeneous teaching actions. We study the problem of discovering effective\ndesigns that convert a slide into an interactive lecture. We develop\nSlide2Lecture, a tuning-free and knowledge-regulated intelligent tutoring\nsystem that can (1) effectively convert an input lecture slide into a\nstructured teaching agenda consisting of a set of heterogeneous teaching\nactions; (2) create and manage an interactive lecture that generates responsive\ninteractions catering to student learning demands while regulating the\ninteractions to follow teaching actions. Slide2Lecture contains a complete\npipeline for learners to obtain an interactive classroom experience to learn\nthe slide. For teachers and developers, Slide2Lecture enables customization to\ncater to personalized demands. The evaluation rated by annotators and students\nshows that Slide2Lecture is effective in outperforming the remaining\nimplementation. Slide2Lecture's online deployment has made more than 200K\ninteraction with students in the 3K lecture sessions. We open source\nSlide2Lecture's implementation in\nhttps://anonymous.4open.science/r/slide2lecture-4210/.",
      "tldr_zh": "本研究提出了一种无须微调（tuning-free）和知识调控（knowledge-regulated）的智能辅导系统Slide2Lecture，通过语言模型协调（Language Model Coordination）有效利用现有幻灯片作为教学材料。系统将输入幻灯片转换为结构化的教学议程，包括多种异构教学行动，并管理互动讲座以响应学生需求，同时确保互动遵循预设行动。该系统提供完整管道，支持学习者获得互动课堂体验，并允许教师和开发者进行个性化定制。评估结果显示，Slide2Lecture在用户评定中优于其他实现，已在线部署超过3K场讲座，累计互动超20万次，并开源其实现代码。",
      "categories": [
        "cs.CL",
        "cs.AI",
        "cs.HC"
      ],
      "primary_category": "cs.CL",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2409.07372v1",
      "published_date": "2024-09-11 16:03:09 UTC",
      "updated_date": "2024-09-11 16:03:09 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-19T23:04:11.021729"
    },
    {
      "arxiv_id": "2409.07368v3",
      "title": "Demo: SGCode: A Flexible Prompt-Optimizing System for Secure Generation of Code",
      "title_zh": "翻译失败",
      "authors": [
        "Khiem Ton",
        "Nhi Nguyen",
        "Mahmoud Nazzal",
        "Abdallah Khreishah",
        "Cristian Borcea",
        "NhatHai Phan",
        "Ruoming Jin",
        "Issa Khalil",
        "Yelong Shen"
      ],
      "abstract": "This paper introduces SGCode, a flexible prompt-optimizing system to generate\nsecure code with large language models (LLMs). SGCode integrates recent\nprompt-optimization approaches with LLMs in a unified system accessible through\nfront-end and back-end APIs, enabling users to 1) generate secure code, which\nis free of vulnerabilities, 2) review and share security analysis, and 3)\neasily switch from one prompt optimization approach to another, while providing\ninsights on model and system performance. We populated SGCode on an AWS server\nwith PromSec, an approach that optimizes prompts by combining an LLM and\nsecurity tools with a lightweight generative adversarial graph neural network\nto detect and fix security vulnerabilities in the generated code. Extensive\nexperiments show that SGCode is practical as a public tool to gain insights\ninto the trade-offs between model utility, secure code generation, and system\ncost. SGCode has only a marginal cost compared with prompting LLMs. SGCode is\navailable at: https://sgcode.codes/.",
      "tldr_zh": "本研究介绍了 SGCode，一种灵活的提示优化系统，用于通过大型语言模型（LLMs）生成安全的代码。SGCode 通过整合提示优化方法（如 PromSec）并提供前端和后端 API，允许用户生成无漏洞代码、审查安全分析以及轻松切换优化策略，同时提供模型和系统性能洞见。PromSec 方法结合 LLM、安全工具和轻量级生成对抗图神经网络（generative adversarial graph neural network）来检测并修复代码漏洞。实验结果显示，SGCode 作为公共工具非常实用，能平衡模型效用、安全生成和系统成本，且其额外成本仅比直接提示 LLMs 略高。系统已上线，可访问 https://sgcode.codes/。",
      "categories": [
        "cs.CR",
        "cs.AI"
      ],
      "primary_category": "cs.CR",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2409.07368v3",
      "published_date": "2024-09-11 15:56:15 UTC",
      "updated_date": "2024-09-25 15:17:27 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-19T23:04:33.036508"
    },
    {
      "arxiv_id": "2409.07353v1",
      "title": "Securing Vision-Language Models with a Robust Encoder Against Jailbreak and Adversarial Attacks",
      "title_zh": "翻译失败",
      "authors": [
        "Md Zarif Hossain",
        "Ahmed Imteaj"
      ],
      "abstract": "Large Vision-Language Models (LVLMs), trained on multimodal big datasets,\nhave significantly advanced AI by excelling in vision-language tasks. However,\nthese models remain vulnerable to adversarial attacks, particularly jailbreak\nattacks, which bypass safety protocols and cause the model to generate\nmisleading or harmful responses. This vulnerability stems from both the\ninherent susceptibilities of LLMs and the expanded attack surface introduced by\nthe visual modality. We propose Sim-CLIP+, a novel defense mechanism that\nadversarially fine-tunes the CLIP vision encoder by leveraging a Siamese\narchitecture. This approach maximizes cosine similarity between perturbed and\nclean samples, facilitating resilience against adversarial manipulations.\nSim-CLIP+ offers a plug-and-play solution, allowing seamless integration into\nexisting LVLM architectures as a robust vision encoder. Unlike previous\ndefenses, our method requires no structural modifications to the LVLM and\nincurs minimal computational overhead. Sim-CLIP+ demonstrates effectiveness\nagainst both gradient-based adversarial attacks and various jailbreak\ntechniques. We evaluate Sim-CLIP+ against three distinct jailbreak attack\nstrategies and perform clean evaluations using standard downstream datasets,\nincluding COCO for image captioning and OKVQA for visual question answering.\nExtensive experiments demonstrate that Sim-CLIP+ maintains high clean accuracy\nwhile substantially improving robustness against both gradient-based\nadversarial attacks and jailbreak techniques. Our code and robust vision\nencoders are available at\nhttps://github.com/speedlab-git/Robust-Encoder-against-Jailbreak-attack.git.",
      "tldr_zh": "该研究针对Large Vision-Language Models (LVLMs) 面临的jailbreak attacks和adversarial attacks问题，提出了一种新型防御机制Sim-CLIP+。该机制通过对抗性微调CLIP视觉编码器，利用Siamese architecture最大化perturbed和clean samples之间的cosine similarity，从而提升模型对攻击的抵抗力。Sim-CLIP+作为plug-and-play解决方案，能无缝集成到现有LVLM架构中，无需结构修改且计算开销最小。实验结果显示，该方法在对抗gradient-based attacks和多种jailbreak策略时显著提高鲁棒性，同时在COCO和OKVQA数据集上保持高clean accuracy。",
      "categories": [
        "cs.CV",
        "cs.AI"
      ],
      "primary_category": "cs.CV",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2409.07353v1",
      "published_date": "2024-09-11 15:39:42 UTC",
      "updated_date": "2024-09-11 15:39:42 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-19T23:04:35.622840"
    },
    {
      "arxiv_id": "2409.07351v2",
      "title": "Federated Impression for Learning with Distributed Heterogeneous Data",
      "title_zh": "翻译失败",
      "authors": [
        "Atrin Arya",
        "Sana Ayromlou",
        "Armin Saadat",
        "Purang Abolmaesumi",
        "Xiaoxiao Li"
      ],
      "abstract": "Standard deep learning-based classification approaches may not always be\npractical in real-world clinical applications, as they require a centralized\ncollection of all samples. Federated learning (FL) provides a paradigm that can\nlearn from distributed datasets across clients without requiring them to share\ndata, which can help mitigate privacy and data ownership issues. In FL,\nsub-optimal convergence caused by data heterogeneity is common among data from\ndifferent health centers due to the variety in data collection protocols and\npatient demographics across centers. Through experimentation in this study, we\nshow that data heterogeneity leads to the phenomenon of catastrophic forgetting\nduring local training. We propose FedImpres which alleviates catastrophic\nforgetting by restoring synthetic data that represents the global information\nas federated impression. To achieve this, we distill the global model resulting\nfrom each communication round. Subsequently, we use the synthetic data\nalongside the local data to enhance the generalization of local training.\nExtensive experiments show that the proposed method achieves state-of-the-art\nperformance on both the BloodMNIST and Retina datasets, which contain label\nimbalance and domain shift, with an improvement in classification accuracy of\nup to 20%.",
      "tldr_zh": "该论文针对联邦学习（Federated Learning, FL）在处理分布式异质数据时的挑战，特别是在医疗领域的数据隐私和灾难性遗忘（catastrophic forgetting）问题，提出了一种新方法 FedImpres。FedImpres 通过蒸馏全局模型生成的合成数据（federated impression）来恢复全局信息，并在本地训练中结合这些合成数据与本地数据，提升模型的泛化能力。实验结果显示，在 BloodMNIST 和 Retina 数据集上，该方法在标签不平衡和领域偏移（domain shift）条件下，将分类准确率提高了高达 20%，实现了最先进性能。",
      "categories": [
        "cs.LG",
        "cs.AI",
        "cs.CV",
        "cs.DC"
      ],
      "primary_category": "cs.LG",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2409.07351v2",
      "published_date": "2024-09-11 15:37:52 UTC",
      "updated_date": "2024-10-09 13:55:01 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-19T23:04:47.525995"
    },
    {
      "arxiv_id": "2409.07341v1",
      "title": "Online Decision MetaMorphFormer: A Casual Transformer-Based Reinforcement Learning Framework of Universal Embodied Intelligence",
      "title_zh": "翻译失败",
      "authors": [
        "Luo Ji",
        "Runji Lin"
      ],
      "abstract": "Interactive artificial intelligence in the motion control field is an\ninteresting topic, especially when universal knowledge is adaptive to multiple\ntasks and universal environments. Despite there being increasing efforts in the\nfield of Reinforcement Learning (RL) with the aid of transformers, most of them\nmight be limited by the offline training pipeline, which prohibits exploration\nand generalization abilities. To address this limitation, we propose the\nframework of Online Decision MetaMorphFormer (ODM) which aims to achieve\nself-awareness, environment recognition, and action planning through a unified\nmodel architecture. Motivated by cognitive and behavioral psychology, an ODM\nagent is able to learn from others, recognize the world, and practice itself\nbased on its own experience. ODM can also be applied to any arbitrary agent\nwith a multi-joint body, located in different environments, and trained with\ndifferent types of tasks using large-scale pre-trained datasets. Through the\nuse of pre-trained datasets, ODM can quickly warm up and learn the necessary\nknowledge to perform the desired task, while the target environment continues\nto reinforce the universal policy. Extensive online experiments as well as\nfew-shot and zero-shot environmental tests are used to verify ODM's performance\nand generalization ability. The results of our study contribute to the study of\ngeneral artificial intelligence in embodied and cognitive fields. Code,\nresults, and video examples can be found on the website\n\\url{https://rlodm.github.io/odm/}.",
      "tldr_zh": "这篇论文提出了 Online Decision MetaMorphFormer (ODM)，一个基于 Transformer 的在线强化学习 (RL) 框架，旨在实现通用具身智能，包括自我意识、环境识别和行动规划。ODM 受认知和行为心理学启发，能从预训练数据集快速学习，并通过在线强化适应多关节代理在不同环境和任务中的应用，同时提升探索和泛化能力。实验结果显示，ODM 在在线测试、少样本和零样本环境中表现出色，为具身和认知领域的通用人工智能研究提供了重要贡献。",
      "categories": [
        "cs.LG",
        "cs.AI",
        "cs.RO"
      ],
      "primary_category": "cs.LG",
      "comment": "12 pages, 6 figures",
      "pdf_url": "http://arxiv.org/pdf/2409.07341v1",
      "published_date": "2024-09-11 15:22:43 UTC",
      "updated_date": "2024-09-11 15:22:43 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-19T23:04:59.637830"
    },
    {
      "arxiv_id": "2409.07340v1",
      "title": "A Framework for Predicting the Impact of Game Balance Changes through Meta Discovery",
      "title_zh": "翻译失败",
      "authors": [
        "Akash Saravanan",
        "Matthew Guzdial"
      ],
      "abstract": "A metagame is a collection of knowledge that goes beyond the rules of a game.\nIn competitive, team-based games like Pok\\'emon or League of Legends, it refers\nto the set of current dominant characters and/or strategies within the player\nbase. Developer changes to the balance of the game can have drastic and\nunforeseen consequences on these sets of meta characters. A framework for\npredicting the impact of balance changes could aid developers in making more\ninformed balance decisions. In this paper we present such a Meta Discovery\nframework, leveraging Reinforcement Learning for automated testing of balance\nchanges. Our results demonstrate the ability to predict the outcome of balance\nchanges in Pok\\'emon Showdown, a collection of competitive Pok\\'emon tiers,\nwith high accuracy.",
      "tldr_zh": "本研究提出一个Meta Discovery框架，用于预测游戏平衡变化对metagame的影响，其中metagame指的是竞争性游戏（如Pokémon或League of Legends）中当前主导的角色和策略。框架利用Reinforcement Learning进行自动测试，帮助开发者评估平衡调整的潜在后果。实验结果显示，该框架在Pokémon Showdown上实现了高准确率的预测，为游戏开发提供更可靠的决策支持。",
      "categories": [
        "cs.AI",
        "cs.LG"
      ],
      "primary_category": "cs.AI",
      "comment": "11 pages, 1 figure, IEEE Transactions on Games",
      "pdf_url": "http://arxiv.org/pdf/2409.07340v1",
      "published_date": "2024-09-11 15:20:43 UTC",
      "updated_date": "2024-09-11 15:20:43 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-19T23:05:10.198132"
    },
    {
      "arxiv_id": "2409.07335v1",
      "title": "Explanation, Debate, Align: A Weak-to-Strong Framework for Language Model Generalization",
      "title_zh": "解释、辩论、对齐：一个弱到强的框架，用于语言模型泛化",
      "authors": [
        "Mehrdad Zakershahrak",
        "Samira Ghodratnama"
      ],
      "abstract": "The rapid advancement of artificial intelligence systems has brought the\nchallenge of AI alignment to the forefront of research, particularly in complex\ndecision-making and task execution. As these systems surpass human-level\nperformance in sophisticated problems, ensuring their alignment with human\nvalues, intentions, and ethical guidelines becomes crucial. Building on\nprevious work in explanation generation for human-agent alignment, we address\nthe more complex dynamics of multi-agent systems and human-AI teams. This paper\nintroduces a novel approach to model alignment through weak-to-strong\ngeneralization in the context of language models. We present a framework where\na strong model facilitates the improvement of a weaker model, bridging the gap\nbetween explanation generation and model alignment. Our method, formalized as a\nfacilitation function, allows for the transfer of capabilities from advanced\nmodels to less capable ones without direct access to extensive training data.\nOur results suggest that this facilitation-based approach not only enhances\nmodel performance but also provides insights into the nature of model alignment\nand the potential for scalable oversight of AI systems.",
      "tldr_zh": "本论文针对AI对齐的挑战，提出一个弱到强泛化框架（weak-to-strong generalization），旨在通过强模型帮助弱模型提升性能，尤其在语言模型的多代理系统和人类-AI团队中。框架包括解释生成（explanation generation）、辩论（debate）和对齐（align）过程，利用facilitation function从强模型向弱模型转移能力，而无需大量训练数据。这种方法不仅显著提高了模型的表现，还提供了对AI系统对齐机制的洞见，并支持可扩展的监督策略。",
      "categories": [
        "cs.AI",
        "cs.CL"
      ],
      "primary_category": "cs.AI",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2409.07335v1",
      "published_date": "2024-09-11 15:16:25 UTC",
      "updated_date": "2024-09-11 15:16:25 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-19T23:05:22.974251"
    },
    {
      "arxiv_id": "2409.07321v1",
      "title": "Module-wise Adaptive Adversarial Training for End-to-end Autonomous Driving",
      "title_zh": "模块级自适应对抗训练用于端到端自动驾驶",
      "authors": [
        "Tianyuan Zhang",
        "Lu Wang",
        "Jiaqi Kang",
        "Xinwei Zhang",
        "Siyuan Liang",
        "Yuwei Chen",
        "Aishan Liu",
        "Xianglong Liu"
      ],
      "abstract": "Recent advances in deep learning have markedly improved autonomous driving\n(AD) models, particularly end-to-end systems that integrate perception,\nprediction, and planning stages, achieving state-of-the-art performance.\nHowever, these models remain vulnerable to adversarial attacks, where\nhuman-imperceptible perturbations can disrupt decision-making processes. While\nadversarial training is an effective method for enhancing model robustness\nagainst such attacks, no prior studies have focused on its application to\nend-to-end AD models. In this paper, we take the first step in adversarial\ntraining for end-to-end AD models and present a novel Module-wise Adaptive\nAdversarial Training (MA2T). However, extending conventional adversarial\ntraining to this context is highly non-trivial, as different stages within the\nmodel have distinct objectives and are strongly interconnected. To address\nthese challenges, MA2T first introduces Module-wise Noise Injection, which\ninjects noise before the input of different modules, targeting training models\nwith the guidance of overall objectives rather than each independent module\nloss. Additionally, we introduce Dynamic Weight Accumulation Adaptation, which\nincorporates accumulated weight changes to adaptively learn and adjust the loss\nweights of each module based on their contributions (accumulated reduction\nrates) for better balance and robust training. To demonstrate the efficacy of\nour defense, we conduct extensive experiments on the widely-used nuScenes\ndataset across several end-to-end AD models under both white-box and black-box\nattacks, where our method outperforms other baselines by large margins\n(+5-10%). Moreover, we validate the robustness of our defense through\nclosed-loop evaluation in the CARLA simulation environment, showing improved\nresilience even against natural corruption.",
      "tldr_zh": "本研究针对端到端自动驾驶（AD）模型在对抗攻击下的脆弱性，首次提出Module-wise Adaptive Adversarial Training (MA2T)方法，以提升整体鲁棒性。MA2T 通过Module-wise Noise Injection向不同模块输入注入噪声，并采用Dynamic Weight Accumulation Adaptation动态调整模块损失权重，根据其贡献平衡训练过程，从而解决模块间目标不一致的问题。在nuScenes数据集上的实验显示，MA2T在白盒和黑盒攻击下比基线模型提升5-10%，并在CARLA模拟环境中的闭环评估中证明了其对自然干扰的出色抵抗力。",
      "categories": [
        "cs.CV",
        "cs.AI"
      ],
      "primary_category": "cs.CV",
      "comment": "14 pages",
      "pdf_url": "http://arxiv.org/pdf/2409.07321v1",
      "published_date": "2024-09-11 15:00:18 UTC",
      "updated_date": "2024-09-11 15:00:18 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-19T23:05:35.443865"
    },
    {
      "arxiv_id": "2409.18969v2",
      "title": "Integrating SPARQL and LLMs for Question Answering over Scholarly Data Sources",
      "title_zh": "翻译失败",
      "authors": [
        "Fomubad Borista Fondi",
        "Azanzi Jiomekong Fidel",
        "Gaoussou Camara"
      ],
      "abstract": "The Scholarly Hybrid Question Answering over Linked Data (QALD) Challenge at\nthe International Semantic Web Conference (ISWC) 2024 focuses on Question\nAnswering (QA) over diverse scholarly sources: DBLP, SemOpenAlex, and\nWikipedia-based texts. This paper describes a methodology that combines SPARQL\nqueries, divide and conquer algorithms, and a pre-trained extractive question\nanswering model. It starts with SPARQL queries to gather data, then applies\ndivide and conquer to manage various question types and sources, and uses the\nmodel to handle personal author questions. The approach, evaluated with Exact\nMatch and F-score metrics, shows promise for improving QA accuracy and\nefficiency in scholarly contexts.",
      "tldr_zh": "这篇论文提出了一种整合 SPARQL 查询、divide and conquer 算法以及预训练提取式问答模型的方法，用于在学术数据源（如 DBLP、SemOpenAlex 和 Wikipedia-based texts）上进行问答系统。方法流程包括先用 SPARQL 收集数据，然后通过 divide and conquer 处理不同问题类型和来源，最后应用模型针对个人作者相关问题进行响应。在 ISWC 2024 QALD Challenge 的评估中，该方法使用 Exact Match 和 F-score 指标，显示出显著提升问答准确性和效率的潜力。",
      "categories": [
        "cs.IR",
        "cs.AI"
      ],
      "primary_category": "cs.IR",
      "comment": "Scholarly Hybrid Question answering challenge from the International\n  Semantic Web Conference of 2024(ISWC), 7 pages, 8 figures",
      "pdf_url": "http://arxiv.org/pdf/2409.18969v2",
      "published_date": "2024-09-11 14:50:28 UTC",
      "updated_date": "2024-11-28 20:29:44 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-19T23:05:47.453739"
    },
    {
      "arxiv_id": "2409.07314v1",
      "title": "MEDIC: Towards a Comprehensive Framework for Evaluating LLMs in Clinical Applications",
      "title_zh": "翻译失败",
      "authors": [
        "Praveen K Kanithi",
        "Clément Christophe",
        "Marco AF Pimentel",
        "Tathagata Raha",
        "Nada Saadi",
        "Hamza Javed",
        "Svetlana Maslenkova",
        "Nasir Hayat",
        "Ronnie Rajan",
        "Shadab Khan"
      ],
      "abstract": "The rapid development of Large Language Models (LLMs) for healthcare\napplications has spurred calls for holistic evaluation beyond frequently-cited\nbenchmarks like USMLE, to better reflect real-world performance. While\nreal-world assessments are valuable indicators of utility, they often lag\nbehind the pace of LLM evolution, likely rendering findings obsolete upon\ndeployment. This temporal disconnect necessitates a comprehensive upfront\nevaluation that can guide model selection for specific clinical applications.\nWe introduce MEDIC, a framework assessing LLMs across five critical dimensions\nof clinical competence: medical reasoning, ethics and bias, data and language\nunderstanding, in-context learning, and clinical safety. MEDIC features a novel\ncross-examination framework quantifying LLM performance across areas like\ncoverage and hallucination detection, without requiring reference outputs. We\napply MEDIC to evaluate LLMs on medical question-answering, safety,\nsummarization, note generation, and other tasks. Our results show performance\ndisparities across model sizes, baseline vs medically finetuned models, and\nhave implications on model selection for applications requiring specific model\nstrengths, such as low hallucination or lower cost of inference. MEDIC's\nmultifaceted evaluation reveals these performance trade-offs, bridging the gap\nbetween theoretical capabilities and practical implementation in healthcare\nsettings, ensuring that the most promising models are identified and adapted\nfor diverse healthcare applications.",
      "tldr_zh": "该研究提出MEDIC框架，用于全面评估大型语言模型(LLMs)在临床应用中的性能，超越传统基准如USMLE，以更好地反映实际场景。MEDIC涵盖医疗推理、伦理和偏见、数据和语言理解、上下文学习以及临床安全等五个关键维度，并引入交叉检查机制来量化覆盖率和幻觉检测，而无需参考输出。实验结果显示不同模型大小、基线模型与医疗微调模型之间存在性能差异，这有助于指导模型选择，例如优先低幻觉或低推理成本的模型，最终桥接LLMs的理论能力与实际医疗应用。",
      "categories": [
        "cs.CL",
        "cs.AI"
      ],
      "primary_category": "cs.CL",
      "comment": "Technical report",
      "pdf_url": "http://arxiv.org/pdf/2409.07314v1",
      "published_date": "2024-09-11 14:44:51 UTC",
      "updated_date": "2024-09-11 14:44:51 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-19T23:05:58.897533"
    },
    {
      "arxiv_id": "2409.10561v3",
      "title": "DrLLM: Prompt-Enhanced Distributed Denial-of-Service Resistance Method with Large Language Models",
      "title_zh": "翻译失败",
      "authors": [
        "Zhenyu Yin",
        "Shang Liu",
        "Guangyuan Xu"
      ],
      "abstract": "The increasing number of Distributed Denial of Service (DDoS) attacks poses a\nmajor threat to the Internet, highlighting the importance of DDoS mitigation.\nMost existing approaches require complex training methods to learn data\nfeatures, which increases the complexity and generality of the application. In\nthis paper, we propose DrLLM, which aims to mine anomalous traffic information\nin zero-shot scenarios through Large Language Models (LLMs). To bridge the gap\nbetween DrLLM and existing approaches, we embed the global and local\ninformation of the traffic data into the reasoning paradigm and design three\nmodules, namely Knowledge Embedding, Token Embedding, and Progressive Role\nReasoning, for data representation and reasoning. In addition we explore the\ngeneralization of prompt engineering in the cybersecurity domain to improve the\nclassification capability of DrLLM. Our ablation experiments demonstrate the\napplicability of DrLLM in zero-shot scenarios and further demonstrate the\npotential of LLMs in the network domains. DrLLM implementation code has been\nopen-sourced at https://github.com/liuup/DrLLM.",
      "tldr_zh": "该论文提出DrLLM，一种基于Large Language Models (LLMs)的提示增强方法，用于抵抗Distributed Denial-of-Service (DDoS)攻击，旨在在zero-shot场景下挖掘异常流量信息，而无需复杂的训练过程。DrLLM通过Knowledge Embedding、Token Embedding和Progressive Role Reasoning三个模块，将流量数据的全局和本地信息嵌入推理范式中，并利用prompt engineering在网络安全领域提升分类能力。实验结果显示，DrLLM在零-shot场景中表现出色，证明了LLMs在网络领域应用的潜力，并已开源代码以促进进一步研究。",
      "categories": [
        "cs.CR",
        "cs.AI"
      ],
      "primary_category": "cs.CR",
      "comment": "Accepted by ICASSP2025",
      "pdf_url": "http://arxiv.org/pdf/2409.10561v3",
      "published_date": "2024-09-11 14:41:44 UTC",
      "updated_date": "2025-01-13 13:12:09 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-19T23:06:11.368214"
    },
    {
      "arxiv_id": "2409.07291v1",
      "title": "Exploring User-level Gradient Inversion with a Diffusion Prior",
      "title_zh": "翻译失败",
      "authors": [
        "Zhuohang Li",
        "Andrew Lowy",
        "Jing Liu",
        "Toshiaki Koike-Akino",
        "Bradley Malin",
        "Kieran Parsons",
        "Ye Wang"
      ],
      "abstract": "We explore user-level gradient inversion as a new attack surface in\ndistributed learning. We first investigate existing attacks on their ability to\nmake inferences about private information beyond training data reconstruction.\nMotivated by the low reconstruction quality of existing methods, we propose a\nnovel gradient inversion attack that applies a denoising diffusion model as a\nstrong image prior in order to enhance recovery in the large batch setting.\nUnlike traditional attacks, which aim to reconstruct individual samples and\nsuffer at large batch and image sizes, our approach instead aims to recover a\nrepresentative image that captures the sensitive shared semantic information\ncorresponding to the underlying user. Our experiments with face images\ndemonstrate the ability of our methods to recover realistic facial images along\nwith private user attributes.",
      "tldr_zh": "本研究探讨了分布式学习中的用户级梯度反演（user-level gradient inversion）作为一种新攻击面，调查现有攻击方法在推断训练数据外私人信息时的局限性。针对现有方法的低重建质量，作者提出了一种新型梯度反演攻击，利用去噪扩散模型（denoising diffusion model）作为图像先验（image prior），旨在在大批量设置下恢复代表性图像，从而捕捉用户的敏感共享语义信息。与传统攻击不同，该方法专注于重建单个样本之外的整体特征。实验结果显示，在面部图像任务中，该方法成功恢复了逼真的面部图像以及私人用户属性，证明了其在隐私风险评估中的有效性。",
      "categories": [
        "cs.LG",
        "cs.AI",
        "cs.CR",
        "cs.CV",
        "stat.ML"
      ],
      "primary_category": "cs.LG",
      "comment": "Presented at the International Workshop on Federated Learning in the\n  Age of Foundation Models in conjunction with NeurIPS 2023",
      "pdf_url": "http://arxiv.org/pdf/2409.07291v1",
      "published_date": "2024-09-11 14:20:47 UTC",
      "updated_date": "2024-09-11 14:20:47 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-19T23:06:25.194896"
    },
    {
      "arxiv_id": "2409.07286v1",
      "title": "Using Generative Agents to Create Tip Sheets for Investigative Data Reporting",
      "title_zh": "翻译失败",
      "authors": [
        "Joris Veerbeek",
        "Nicholas Diakopoulos"
      ],
      "abstract": "This paper introduces a system using generative AI agents to create tip\nsheets for investigative data reporting. Our system employs three specialized\nagents--an analyst, a reporter, and an editor--to collaboratively generate and\nrefine tips from datasets. We validate this approach using real-world\ninvestigative stories, demonstrating that our agent-based system generally\ngenerates more newsworthy and accurate insights compared to a baseline model\nwithout agents, although some variability was noted between different stories.\nOur findings highlight the potential of generative AI to provide leads for\ninvestigative data reporting.",
      "tldr_zh": "本研究提出了一种利用生成式 AI 代理创建调查数据报告提示表（Tip Sheets）的系统，该系统包括三个专门代理：分析师、记者和编辑，它们协作从数据集生成并完善提示。相比于没有代理的基线模型，该系统在真实世界调查故事的验证中，通常能产生更多新闻价值和准确的见解，尽管在不同故事之间存在一些变异。研究结果突出了生成式 AI 在为调查数据报告提供线索方面的潜力。",
      "categories": [
        "cs.AI",
        "cs.CL",
        "cs.LG"
      ],
      "primary_category": "cs.AI",
      "comment": "Short paper to be presented at Computation + Journalism 2024",
      "pdf_url": "http://arxiv.org/pdf/2409.07286v1",
      "published_date": "2024-09-11 14:14:15 UTC",
      "updated_date": "2024-09-11 14:14:15 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-19T23:06:34.598671"
    },
    {
      "arxiv_id": "2409.18968v2",
      "title": "Safety challenges of AI in medicine in the era of large language models",
      "title_zh": "翻译失败",
      "authors": [
        "Xiaoye Wang",
        "Nicole Xi Zhang",
        "Hongyu He",
        "Trang Nguyen",
        "Kun-Hsing Yu",
        "Hao Deng",
        "Cynthia Brandt",
        "Danielle S. Bitterman",
        "Ling Pan",
        "Ching-Yu Cheng",
        "James Zou",
        "Dianbo Liu"
      ],
      "abstract": "Recent advancements in artificial intelligence (AI), particularly in large\nlanguage models (LLMs), have unlocked significant potential to enhance the\nquality and efficiency of medical care. By introducing a novel way to interact\nwith AI and data through natural language, LLMs offer new opportunities for\nmedical practitioners, patients, and researchers. However, as AI and LLMs\nbecome more powerful and especially achieve superhuman performance in some\nmedical tasks, public concerns over their safety have intensified. These\nconcerns about AI safety have emerged as the most significant obstacles to the\nadoption of AI in medicine. In response, this review examines emerging risks in\nAI utilization during the LLM era. First, we explore LLM-specific safety\nchallenges from functional and communication perspectives, addressing issues\nacross data collection, model training, and real-world application. We then\nconsider inherent safety problems shared by all AI systems, along with\nadditional complications introduced by LLMs. Last, we discussed how safety\nissues of using AI in clinical practice and healthcare system operation would\nundermine trust among patient, clinicians and the public, and how to build\nconfidence in these systems. By emphasizing the development of safe AI, we\nbelieve these technologies can be more rapidly and reliably integrated into\neveryday medical practice to benefit both patients and clinicians.",
      "tldr_zh": "这篇综述探讨了在大型语言模型(LLMs)时代，AI在医疗领域面临的安全挑战，这些问题已成为AI采用的主要障碍。作者从功能和通信视角分析了LLMs特有的风险，包括数据收集、模型训练和实际应用中的潜在问题，并讨论了这些挑战如何加剧通用AI系统的安全复杂性。最终，论文强调通过构建安全AI来提升患者、临床医生和公众的信任，从而加速这些技术在日常医疗实践中的可靠整合。",
      "categories": [
        "cs.CY",
        "cs.AI",
        "cs.LG"
      ],
      "primary_category": "cs.CY",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2409.18968v2",
      "published_date": "2024-09-11 13:47:47 UTC",
      "updated_date": "2025-01-30 08:55:23 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-19T23:06:47.267801"
    },
    {
      "arxiv_id": "2409.12171v1",
      "title": "Semantic Interoperability on Blockchain by Generating Smart Contracts Based on Knowledge Graphs",
      "title_zh": "基于知识图谱生成智能合约实现区块链上的语义互操作性",
      "authors": [
        "William Van Woensel",
        "Oshani Seneviratne"
      ],
      "abstract": "Background: Health 3.0 allows decision making to be based on longitudinal\ndata from multiple institutions, from across the patient's healthcare journey.\nIn such a distributed setting, blockchain smart contracts can act as neutral\nintermediaries to implement trustworthy decision making.\n  Objective: In a distributed setting, transmitted data will be structured\nusing standards (such as HL7 FHIR) for semantic interoperability. In turn, the\nsmart contract will require interoperability with this standard, implement a\ncomplex communication setup (e.g., using oracles), and be developed using\nblockchain languages (e.g., Solidity). We propose the encoding of smart\ncontract logic using a high-level semantic Knowledge Graph, using concepts from\nthe domain standard. We then deploy this semantic KG on blockchain.\n  Methods: Off-chain, a code generation pipeline compiles the KG into a\nconcrete smart contract, which is then deployed on-chain. Our pipeline targets\nan intermediary bridge representation, which can be transpiled into a specific\nblockchain language. Our choice avoids on-chain rule engines, with\nunpredictable and likely higher computational cost; it is thus in line with the\neconomic rules of blockchain.\n  Results: We applied our code generation approach to generate smart contracts\nfor 3 health insurance cases from Medicare. We discuss the suitability of our\napproach - the need for a neutral intermediary - for a number of healthcare use\ncases. Our evaluation finds that the generated contracts perform well in terms\nof correctness and execution cost (\"gas\") on blockchain.\n  Conclusions: We showed that it is feasible to automatically generate smart\ncontract code based on a semantic KG, in a way that respects the economic rules\nof blockchain. Future work includes studying the use of Large Language Models\n(LLM) in our approach, and evaluations on other blockchains.",
      "tldr_zh": "该研究针对区块链上的语义互操作性问题，提出了一种基于 Knowledge Graphs 的方法，通过编码高层次语义知识图谱来自动生成 Smart Contracts，从而实现与标准如 HL7 FHIR 的互操作性，并部署到区块链环境中。方法包括一个离线代码生成管道，将 Knowledge Graphs 编译成具体合约，使用中间桥表示转译成区块链语言（如 Solidity），以避免链上规则引擎的高计算成本。结果显示，该方法应用于 3 个 Medicare 健康保险案例后，生成的合约在正确性和执行成本（gas）方面表现出色，为医疗保健分布式决策提供可信中立中介。未来工作将探索 Large Language Models (LLM) 的整合及在其他区块链上的评估。",
      "categories": [
        "cs.CR",
        "cs.AI"
      ],
      "primary_category": "cs.CR",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2409.12171v1",
      "published_date": "2024-09-11 13:46:24 UTC",
      "updated_date": "2024-09-11 13:46:24 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-19T23:06:59.772074"
    },
    {
      "arxiv_id": "2409.07246v2",
      "title": "Propaganda to Hate: A Multimodal Analysis of Arabic Memes with Multi-Agent LLMs",
      "title_zh": "翻译失败",
      "authors": [
        "Firoj Alam",
        "Md. Rafiul Biswas",
        "Uzair Shah",
        "Wajdi Zaghouani",
        "Georgios Mikros"
      ],
      "abstract": "In the past decade, social media platforms have been used for information\ndissemination and consumption. While a major portion of the content is posted\nto promote citizen journalism and public awareness, some content is posted to\nmislead users. Among different content types such as text, images, and videos,\nmemes (text overlaid on images) are particularly prevalent and can serve as\npowerful vehicles for propaganda, hate, and humor. In the current literature,\nthere have been efforts to individually detect such content in memes. However,\nthe study of their intersection is very limited. In this study, we explore the\nintersection between propaganda and hate in memes using a multi-agent LLM-based\napproach. We extend the propagandistic meme dataset with coarse and\nfine-grained hate labels. Our finding suggests that there is an association\nbetween propaganda and hate in memes. We provide detailed experimental results\nthat can serve as a baseline for future studies. We will make the experimental\nresources publicly available to the community\n(https://github.com/firojalam/propaganda-and-hateful-memes).",
      "tldr_zh": "本研究探讨了社交媒体上阿拉伯语模因（memes）中宣传和仇恨的交集，采用多智能体LLM（Multi-Agent LLMs）方法进行多模态分析。研究者扩展了现有宣传模因数据集，添加了粗粒度和细粒度仇恨标签，并通过实验发现宣传和仇恨之间存在显著关联。实验结果提供了未来研究的基准，并将相关资源公开在GitHub上（https://github.com/firojalam/propaganda-and-hateful-memes），以促进社区进一步探讨。",
      "categories": [
        "cs.CL",
        "cs.AI",
        "68T50",
        "F.2.2; I.2.7"
      ],
      "primary_category": "cs.CL",
      "comment": "propaganda, hate-speech, disinformation, misinformation, fake news,\n  LLMs, GPT-4, multimodality, multimodal LLMs",
      "pdf_url": "http://arxiv.org/pdf/2409.07246v2",
      "published_date": "2024-09-11 13:04:34 UTC",
      "updated_date": "2024-10-06 08:30:48 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-19T23:07:11.213900"
    },
    {
      "arxiv_id": "2409.09086v1",
      "title": "Inf-MLLM: Efficient Streaming Inference of Multimodal Large Language Models on a Single GPU",
      "title_zh": "翻译失败",
      "authors": [
        "Zhenyu Ning",
        "Jieru Zhao",
        "Qihao Jin",
        "Wenchao Ding",
        "Minyi Guo"
      ],
      "abstract": "Multimodal Large Language Models (MLLMs) are distinguished by their\nmultimodal comprehensive ability and widely used in many real-world\napplications including GPT-4o, autonomous driving and robotics. Despite their\nimpressive performance, the multimodal inputs always incur long context. The\ninference under long context requires caching massive Key and Value states (KV\ncache) of previous tokens, which introduces high latency and excessive memory\nconsumption. Due to this reason, it is challenging to deploy streaming\ninference of MLLMs on edge devices, which largely constrains the power and\nusage of MLLMs in real-world applications. In this paper, we introduce\nInf-MLLM, an efficient inference framework for MLLMs, which enable streaming\ninference of MLLM on a single GPU with infinite context. Inf-MLLM is based on\nour key observation of the attention pattern in both LLMs and MLLMs called\n\"attention saddles\". Thanks to the newly discovered attention pattern, Inf-MLLM\nmaintains a size-constrained KV cache by dynamically caching recent tokens and\nrelevant tokens. Furthermore, Inf-MLLM proposes attention bias, a novel\napproach to enable MLLMs to capture long-term dependency. We show that Inf-MLLM\nenables multiple LLMs and MLLMs to achieve stable performance over 4M-token\nlong texts and multi-round conversations with 1-hour-long videos on a single\nGPU. In addition, Inf-MLLM exhibits superior streaming reasoning quality than\nexisting methods such as StreamingLLM and 2x speedup than H2O.",
      "tldr_zh": "该论文提出 Inf-MLLM，一种高效的多模态大语言模型(MLLMs)流式推理框架，旨在解决长上下文带来的高延迟和内存消耗问题，使 MLLMs 在单 GPU 上实现无限上下文的流式处理。Inf-MLLM 基于发现的“attention saddles”注意力模式，通过动态缓存最近和相关 token 来限制 KV cache 大小，并引入 attention bias 方法增强长程依赖捕捉能力。实验结果显示，Inf-MLLM 使 LLMs 和 MLLMs 在超过 4M token 的长文本和 1 小时视频多轮对话中保持稳定性能，比 StreamingLLM 提供更好的推理质量，并比 H2O 快 2 倍。",
      "categories": [
        "cs.LG",
        "cs.AI",
        "cs.CV",
        "cs.DC",
        "cs.PF"
      ],
      "primary_category": "cs.LG",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2409.09086v1",
      "published_date": "2024-09-11 12:44:12 UTC",
      "updated_date": "2024-09-11 12:44:12 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-19T23:07:22.941200"
    },
    {
      "arxiv_id": "2409.07507v1",
      "title": "Traceable LLM-based validation of statements in knowledge graphs",
      "title_zh": "翻译失败",
      "authors": [
        "Daniel Adam",
        "Tomáš Kliegr"
      ],
      "abstract": "This article presents a method for verifying RDF triples using LLMs, with an\nemphasis on providing traceable arguments. Because the LLMs cannot currently\nreliably identify the origin of the information used to construct the response\nto the user query, our approach is to avoid using internal LLM factual\nknowledge altogether. Instead, verified RDF statements are compared to chunks\nof external documents retrieved through a web search or Wikipedia. To assess\nthe possible application of this workflow on biosciences content, we evaluated\n1,719 positive statements from the BioRED dataset and the same number of newly\ngenerated negative statements. The resulting precision is 88%, and recall is\n44%. This indicates that the method requires human oversight. We demonstrate\nthe method on Wikidata, where a SPARQL query is used to automatically retrieve\nstatements needing verification. Overall, the results suggest that LLMs could\nbe used for large-scale verification of statements in KGs, a task previously\nunfeasible due to human annotation costs.",
      "tldr_zh": "这篇论文提出了一种基于LLMs的可追踪方法，用于验证知识图谱（knowledge graphs）中的RDF triples，通过外部文档检索（如web search或Wikipedia）来比较语句，而非依赖LLMs的内部知识，从而提升验证的可解释性。在BioRED数据集上评估了1,719个正向语句和同样数量的负向语句，取得了88%的精确度（precision）和44%的召回率（recall），表明该方法虽然有效但仍需人工监督。该方法在Wikidata上通过SPARQL查询自动检索需要验证的语句，证明LLMs可实现大规模知识图谱验证，显著降低人工标注成本。",
      "categories": [
        "cs.AI",
        "cs.LG"
      ],
      "primary_category": "cs.AI",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2409.07507v1",
      "published_date": "2024-09-11 12:27:41 UTC",
      "updated_date": "2024-09-11 12:27:41 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-19T23:07:36.157568"
    },
    {
      "arxiv_id": "2409.07218v1",
      "title": "Behavioral Cloning Models Reality Check for Autonomous Driving",
      "title_zh": "行为克隆模型在自动驾驶的现实验证",
      "authors": [
        "Mustafa Yildirim",
        "Barkin Dagda",
        "Vinal Asodia",
        "Saber Fallah"
      ],
      "abstract": "How effective are recent advancements in autonomous vehicle perception\nsystems when applied to real-world autonomous vehicle control? While numerous\nvision-based autonomous vehicle systems have been trained and evaluated in\nsimulated environments, there is a notable lack of real-world validation for\nthese systems. This paper addresses this gap by presenting the real-world\nvalidation of state-of-the-art perception systems that utilize Behavior Cloning\n(BC) for lateral control, processing raw image data to predict steering\ncommands. The dataset was collected using a scaled research vehicle and tested\non various track setups. Experimental results demonstrate that these methods\npredict steering angles with low error margins in real-time, indicating\npromising potential for real-world applications.",
      "tldr_zh": "这篇论文评估了基于 Behavioral Cloning (BC) 的先进自动驾驶感知系统在真实世界的表现，填补了这些系统主要在模拟环境训练和评估的空白。该系统处理原始图像数据来预测转向命令，并使用缩放的研究车辆在多种轨道设置上进行测试。实验结果显示，该方法在实时预测转向角度时误差较低，展现出在实际自动驾驶控制中的可行潜力。",
      "categories": [
        "cs.RO",
        "cs.AI",
        "cs.CV"
      ],
      "primary_category": "cs.RO",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2409.07218v1",
      "published_date": "2024-09-11 12:19:38 UTC",
      "updated_date": "2024-09-11 12:19:38 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-19T23:07:47.404824"
    },
    {
      "arxiv_id": "2409.07202v1",
      "title": "Heterogeneity-Aware Coordination for Federated Learning via Stitching Pre-trained blocks",
      "title_zh": "翻译失败",
      "authors": [
        "Shichen Zhan",
        "Yebo Wu",
        "Chunlin Tian",
        "Yan Zhao",
        "Li Li"
      ],
      "abstract": "Federated learning (FL) coordinates multiple devices to collaboratively train\na shared model while preserving data privacy. However, large memory footprint\nand high energy consumption during the training process excludes the low-end\ndevices from contributing to the global model with their own data, which\nseverely deteriorates the model performance in real-world scenarios. In this\npaper, we propose FedStitch, a hierarchical coordination framework for\nheterogeneous federated learning with pre-trained blocks. Unlike the\ntraditional approaches that train the global model from scratch, for a new\ntask, FedStitch composes the global model via stitching pre-trained blocks.\nSpecifically, each participating client selects the most suitable block based\non their local data from the candidate pool composed of blocks from pre-trained\nmodels. The server then aggregates the optimal block for stitching. This\nprocess iterates until a new stitched network is generated. Except for the new\ntraining paradigm, FedStitch consists of the following three core components:\n1) an RL-weighted aggregator, 2) a search space optimizer deployed on the\nserver side, and 3) a local energy optimizer deployed on each participating\nclient. The RL-weighted aggregator helps to select the right block in the\nnon-IID scenario, while the search space optimizer continuously reduces the\nsize of the candidate block pool during stitching. Meanwhile, the local energy\noptimizer is designed to minimize energy consumption of each client while\nguaranteeing the overall training progress. The results demonstrate that\ncompared to existing approaches, FedStitch improves the model accuracy up to\n20.93%. At the same time, it achieves up to 8.12% speedup, reduces the memory\nfootprint up to 79.5%, and achieves 89.41% energy saving at most during the\nlearning procedure.",
      "tldr_zh": "这篇论文提出 FedStitch，一种针对异构联邦学习 (FL) 的分层协调框架，通过拼接预训练 blocks 来构建全局模型，而不是从零开始训练，从而解决低端设备因内存和能耗问题而无法参与的挑战。框架的核心组件包括 RL-weighted aggregator 用于非 IID 场景下选择最佳块、search space optimizer 动态缩小候选块池，以及 local energy optimizer 来最小化客户端能耗同时确保训练进度。实验结果显示，FedStitch 比现有方法提高模型准确率高达 20.93%，加速 8.12%，减少内存占用 79.5%，并节省能耗达 89.41%。",
      "categories": [
        "cs.LG",
        "cs.AI"
      ],
      "primary_category": "cs.LG",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2409.07202v1",
      "published_date": "2024-09-11 11:47:50 UTC",
      "updated_date": "2024-09-11 11:47:50 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-19T23:08:01.277790"
    },
    {
      "arxiv_id": "2409.07200v2",
      "title": "ThermalGaussian: Thermal 3D Gaussian Splatting",
      "title_zh": "翻译失败",
      "authors": [
        "Rongfeng Lu",
        "Hangyu Chen",
        "Zunjie Zhu",
        "Yuhang Qin",
        "Ming Lu",
        "Le Zhang",
        "Chenggang Yan",
        "Anke Xue"
      ],
      "abstract": "Thermography is especially valuable for the military and other users of\nsurveillance cameras. Some recent methods based on Neural Radiance Fields\n(NeRF) are proposed to reconstruct the thermal scenes in 3D from a set of\nthermal and RGB images. However, unlike NeRF, 3D Gaussian splatting (3DGS)\nprevails due to its rapid training and real-time rendering. In this work, we\npropose ThermalGaussian, the first thermal 3DGS approach capable of rendering\nhigh-quality images in RGB and thermal modalities. We first calibrate the RGB\ncamera and the thermal camera to ensure that both modalities are accurately\naligned. Subsequently, we use the registered images to learn the multimodal 3D\nGaussians. To prevent the overfitting of any single modality, we introduce\nseveral multimodal regularization constraints. We also develop smoothing\nconstraints tailored to the physical characteristics of the thermal modality.\nBesides, we contribute a real-world dataset named RGBT-Scenes, captured by a\nhand-hold thermal-infrared camera, facilitating future research on thermal\nscene reconstruction. We conduct comprehensive experiments to show that\nThermalGaussian achieves photorealistic rendering of thermal images and\nimproves the rendering quality of RGB images. With the proposed multimodal\nregularization constraints, we also reduced the model's storage cost by 90%.\nOur project page is at https://thermalgaussian.github.io/.",
      "tldr_zh": "该研究提出 ThermalGaussian，一种基于 3D Gaussian Splatting (3DGS) 的方法，用于从 RGB 和热成像图像重建高质量的 3D 热场景，相比传统 NeRF 方法实现了更快的训练和实时渲染。\n方法包括校准 RGB 和热成像相机以确保模态对齐、学习多模态 3D Gaussians，并引入多模态正则化约束和针对热成像物理特性的平滑约束，以防止过拟合并优化模型。\n实验结果显示，ThermalGaussian 实现了热成像的逼真渲染，同时提升了 RGB 图像的渲染质量，并通过正则化约束将模型存储成本降低了 90%；此外，该论文贡献了一个真实世界数据集 RGBT-Scenes，以支持未来热场景重建研究。",
      "categories": [
        "cs.CV",
        "cs.AI"
      ],
      "primary_category": "cs.CV",
      "comment": "10 pages, 7 figures",
      "pdf_url": "http://arxiv.org/pdf/2409.07200v2",
      "published_date": "2024-09-11 11:45:57 UTC",
      "updated_date": "2025-04-22 07:28:59 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-19T23:08:15.190578"
    },
    {
      "arxiv_id": "2409.07505v1",
      "title": "A Survey of Anomaly Detection in In-Vehicle Networks",
      "title_zh": "翻译失败",
      "authors": [
        "Övgü Özdemir",
        "M. Tuğberk İşyapar",
        "Pınar Karagöz",
        "Klaus Werner Schmidt",
        "Demet Demir",
        "N. Alpay Karagöz"
      ],
      "abstract": "Modern vehicles are equipped with Electronic Control Units (ECU) that are\nused for controlling important vehicle functions including safety-critical\noperations. ECUs exchange information via in-vehicle communication buses, of\nwhich the Controller Area Network (CAN bus) is by far the most widespread\nrepresentative. Problems that may occur in the vehicle's physical parts or\nmalicious attacks may cause anomalies in the CAN traffic, impairing the correct\nvehicle operation. Therefore, the detection of such anomalies is vital for\nvehicle safety. This paper reviews the research on anomaly detection for\nin-vehicle networks, more specifically for the CAN bus. Our main focus is the\nevaluation of methods used for CAN bus anomaly detection together with the\ndatasets used in such analysis. To provide the reader with a more comprehensive\nunderstanding of the subject, we first give a brief review of related studies\non time series-based anomaly detection. Then, we conduct an extensive survey of\nrecent deep learning-based techniques as well as conventional techniques for\nCAN bus anomaly detection. Our comprehensive analysis delves into anomaly\ndetection algorithms employed in in-vehicle networks, specifically focusing on\ntheir learning paradigms, inherent strengths, and weaknesses, as well as their\nefficacy when applied to CAN bus datasets. Lastly, we highlight challenges and\nopen research problems in CAN bus anomaly detection.",
      "tldr_zh": "这篇论文对车辆网络中的异常检测进行了全面调查，重点关注Electronic Control Units (ECU)和Controller Area Network (CAN bus)。论文回顾了基于时间序列的异常检测研究，并深入分析了深度学习-based 和传统技术在CAN bus异常检测中的应用，包括这些算法的学习范式、优势、劣势以及在相关数据集上的效能。最终，论文突出了CAN bus异常检测面临的挑战和开放研究问题，为提升车辆安全提供了宝贵见解。",
      "categories": [
        "cs.LG",
        "cs.AI",
        "eess.SP"
      ],
      "primary_category": "cs.LG",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2409.07505v1",
      "published_date": "2024-09-11 11:45:18 UTC",
      "updated_date": "2024-09-11 11:45:18 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-19T23:08:33.194430"
    },
    {
      "arxiv_id": "2409.07194v1",
      "title": "Cyber Deception: State of the art, Trends and Open challenges",
      "title_zh": "翻译失败",
      "authors": [
        "Pedro Beltrán López",
        "Manuel Gil Pérez",
        "Pantaleone Nespoli"
      ],
      "abstract": "The growing interest in cybersecurity has significantly increased articles\ndesigning and implementing various Cyber Deception (CYDEC) mechanisms. This\ntrend reflects the urgent need for new strategies to address cyber threats\neffectively. Since its emergence, CYDEC has established itself as an innovative\ndefense against attackers, thanks to its proactive and reactive capabilities,\nfinding applications in numerous real-life scenarios. Despite the considerable\nwork devoted to CYDEC, the literature still presents significant gaps. In\nparticular, there has not been (i) a comprehensive analysis of the main\ncomponents characterizing CYDEC, (ii) a generic classification covering all\ntypes of solutions, nor (iii) a survey of the current state of the literature\nin various contexts. This article aims to fill these gaps through a detailed\nreview of the main features that comprise CYDEC, developing a comprehensive\nclassification taxonomy. In addition, the different frameworks used to generate\nCYDEC are reviewed, presenting a more comprehensive one. Existing solutions in\nthe literature using CYDEC, both without Artificial Intelligence (AI) and with\nAI, are studied and compared. Finally, the most salient trends of the current\nstate of the art are discussed, offering a list of pending challenges for\nfuture research.",
      "tldr_zh": "这篇论文对网络欺骗（Cyber Deception, CYDEC）进行了全面综述，分析了其作为主动防御策略在应对网络威胁中的重要作用，并指出了现有文献的三大缺口：缺乏对CYDEC主要组件的全面分析、通用分类taxonomy以及不同情境下的文献调查。作者开发了一个综合分类taxonomy，审查了CYDEC的生成框架，并提出一个更全面的框架，同时比较了无Artificial Intelligence (AI) 和有AI的现有解决方案。最终，论文讨论了当前CYDEC领域的关键趋势和开放挑战，为未来研究提供了宝贵方向。",
      "categories": [
        "cs.CR",
        "cs.AI",
        "cs.GT"
      ],
      "primary_category": "cs.CR",
      "comment": "38 pages",
      "pdf_url": "http://arxiv.org/pdf/2409.07194v1",
      "published_date": "2024-09-11 11:31:34 UTC",
      "updated_date": "2024-09-11 11:31:34 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-19T23:08:34.858553"
    },
    {
      "arxiv_id": "2409.07192v1",
      "title": "How Mature is Requirements Engineering for AI-based Systems? A Systematic Mapping Study on Practices, Challenges, and Future Research Directions",
      "title_zh": "翻译失败",
      "authors": [
        "Umm-e- Habiba",
        "Markus Haug",
        "Justus Bogner",
        "Stefan Wagner"
      ],
      "abstract": "Artificial intelligence (AI) permeates all fields of life, which resulted in\nnew challenges in requirements engineering for artificial intelligence (RE4AI),\ne.g., the difficulty in specifying and validating requirements for AI or\nconsidering new quality requirements due to emerging ethical implications. It\nis currently unclear if existing RE methods are sufficient or if new ones are\nneeded to address these challenges. Therefore, our goal is to provide a\ncomprehensive overview of RE4AI to researchers and practitioners. What has been\nachieved so far, i.e., what practices are available, and what research gaps and\nchallenges still need to be addressed? To achieve this, we conducted a\nsystematic mapping study combining query string search and extensive\nsnowballing. The extracted data was aggregated, and results were synthesized\nusing thematic analysis. Our selection process led to the inclusion of 126\nprimary studies. Existing RE4AI research focuses mainly on requirements\nanalysis and elicitation, with most practices applied in these areas.\nFurthermore, we identified requirements specification, explainability, and the\ngap between machine learning engineers and end-users as the most prevalent\nchallenges, along with a few others. Additionally, we proposed seven potential\nresearch directions to address these challenges. Practitioners can use our\nresults to identify and select suitable RE methods for working on their\nAI-based systems, while researchers can build on the identified gaps and\nresearch directions to push the field forward.",
      "tldr_zh": "本研究通过系统映射研究（Systematic Mapping Study），分析了人工智能（AI）系统中的需求工程（Requirements Engineering for AI, RE4AI）的成熟度，涵盖现有实践、挑战及未来研究方向。研究者审阅了126篇主要文献，发现RE4AI的研究主要集中在需求分析和elicitation（需求获取）上。关键挑战包括需求规格说明、explainability（可解释性）以及机器学习工程师与最终用户之间的差距。论文提出了七个潜在研究方向，以帮助实践者选择合适的RE方法，并为研究者提供推进该领域的指导。",
      "categories": [
        "cs.SE",
        "cs.AI"
      ],
      "primary_category": "cs.SE",
      "comment": "Accepted in Requirements Engineering Journal, 2024",
      "pdf_url": "http://arxiv.org/pdf/2409.07192v1",
      "published_date": "2024-09-11 11:28:16 UTC",
      "updated_date": "2024-09-11 11:28:16 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-19T23:08:47.246099"
    },
    {
      "arxiv_id": "2409.07189v1",
      "title": "A Perspective on AI-Guided Molecular Simulations in VR: Exploring Strategies for Imitation Learning in Hyperdimensional Molecular Systems",
      "title_zh": "翻译失败",
      "authors": [
        "Mohamed Dhouioui",
        "Jonathan Barnoud",
        "Rhoslyn Roebuck Williams",
        "Harry J. Stroud",
        "Phil Bates",
        "David R. Glowacki"
      ],
      "abstract": "Molecular dynamics simulations are a crucial computational tool for\nresearchers to understand and engineer molecular structure and function in\nareas such as drug discovery, protein engineering, and material design. Despite\ntheir utility, MD simulations are expensive, owing to the high dimensionality\nof molecular systems. Interactive molecular dynamics in virtual reality\n(iMD-VR) has recently been developed as a 'human-in-the-loop' strategy, which\nleverages high-performance computing to accelerate the researcher's ability to\nsolve the hyperdimensional sampling problem. By providing an immersive 3D\nenvironment that enables visualization and manipulation of real-time molecular\nmotion, iMD-VR enables researchers and students to efficiently and intuitively\nexplore and navigate these complex, high-dimensional systems. iMD-VR platforms\noffer a unique opportunity to quickly generate rich datasets that capture human\nexperts' spatial insight regarding molecular structure and function. This paper\nexplores the possibility of employing user-generated iMD-VR datasets to train\nAI agents via imitation learning (IL). IL is an important technique in robotics\nthat enables agents to mimic complex behaviors from expert demonstrations, thus\ncircumventing the need for explicit programming or intricate reward design. We\nreview the utilization of IL for manipulation tasks in robotics and discuss how\niMD-VR recordings could be used to train IL models for solving specific\nmolecular 'tasks'. We then investigate how such approaches could be applied to\nthe data captured from iMD-VR recordings. Finally, we outline the future\nresearch directions and potential challenges of using AI agents to augment\nhuman expertise to efficiently navigate conformational spaces, highlighting how\nthis approach could provide valuable insight across domains such as materials\nscience, protein engineering, and computer-aided drug design.",
      "tldr_zh": "这篇论文探讨了在虚拟现实（VR）中进行交互式分子动力学模拟（iMD-VR）的视角，强调其作为“人机循环”策略来加速探索高维分子系统的潜力。作者提出利用 iMD-VR 生成的用户数据集，通过模仿学习（Imitation Learning, IL）训练 AI 代理，使其模仿人类专家的空间洞察，从而解决分子任务而无需复杂编程或奖励设计。论文回顾了 IL 在机器人操作中的应用，并展望未来挑战，如 AI 如何增强人类在材料科学、蛋白工程和计算机辅助药物设计领域的专业知识，以更高效导航分子构象空间。",
      "categories": [
        "cs.LG",
        "cs.AI",
        "cs.HC",
        "q-bio.BM"
      ],
      "primary_category": "cs.LG",
      "comment": "(Accepted for presentation at the First Workshop on \"eXtended Reality\n  \\& Intelligent Agents\" (XRIA24) @ ECAI24, Santiago De Compostela (Spain), 20\n  October 2024)",
      "pdf_url": "http://arxiv.org/pdf/2409.07189v1",
      "published_date": "2024-09-11 11:21:02 UTC",
      "updated_date": "2024-09-11 11:21:02 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-19T23:09:00.095020"
    },
    {
      "arxiv_id": "2409.07186v2",
      "title": "Enhancing Angular Resolution via Directionality Encoding and Geometric Constraints in Brain Diffusion Tensor Imaging",
      "title_zh": "通过方向性编码和几何约束提升大脑扩散张量成像中的角度分辨率",
      "authors": [
        "Sheng Chen",
        "Zihao Tang",
        "Mariano Cabezas",
        "Xinyi Wang",
        "Arkiev D'Souza",
        "Michael Barnett",
        "Fernando Calamante",
        "Weidong Cai",
        "Chenyu Wang"
      ],
      "abstract": "Diffusion-weighted imaging (DWI) is a type of Magnetic Resonance Imaging\n(MRI) technique sensitised to the diffusivity of water molecules, offering the\ncapability to inspect tissue microstructures and is the only in-vivo method to\nreconstruct white matter fiber tracts non-invasively. The DWI signal can be\nanalysed with the diffusion tensor imaging (DTI) model to estimate the\ndirectionality of water diffusion within voxels. Several scalar metrics,\nincluding axial diffusivity (AD), mean diffusivity (MD), radial diffusivity\n(RD), and fractional anisotropy (FA), can be further derived from DTI to\nquantitatively summarise the microstructural integrity of brain tissue. These\nscalar metrics have played an important role in understanding the organisation\nand health of brain tissue at a microscopic level in clinical studies. However,\nreliable DTI metrics rely on DWI acquisitions with high gradient directions,\nwhich often go beyond the commonly used clinical protocols. To enhance the\nutility of clinically acquired DWI and save scanning time for robust DTI\nanalysis, this work proposes DirGeo-DTI, a deep learning-based method to\nestimate reliable DTI metrics even from a set of DWIs acquired with the minimum\ntheoretical number (6) of gradient directions. DirGeo-DTI leverages directional\nencoding and geometric constraints to facilitate the training process. Two\npublic DWI datasets were used for evaluation, demonstrating the effectiveness\nof the proposed method. Extensive experimental results show that the proposed\nmethod achieves the best performance compared to existing DTI enhancement\nmethods and potentially reveals further clinical insights with routine clinical\nDWI scans.",
      "tldr_zh": "本论文针对脑扩散张量成像(DTI)中角度分辨率不足的问题，提出了一种名为DirGeo-DTI的深度学习方法，通过directionality encoding和geometric constraints来提升从临床DWI数据中提取DTI指标的准确性。DirGeo-DTI能够从理论最小梯度方向（仅6个）的DWI采集中可靠地估计关键指标，如axial diffusivity (AD)、mean diffusivity (MD)、radial diffusivity (RD)和fractional anisotropy (FA)，从而减少扫描时间并改善微结构分析。实验在两个公共DWI数据集上验证了该方法的有效性，其性能优于现有DTI增强方法，并为临床应用提供更多潜在见解。",
      "categories": [
        "cs.CV",
        "cs.AI"
      ],
      "primary_category": "cs.CV",
      "comment": "Accepted to ICONIP2024, Diffusion Weighted Imaging, Diffusion Tensor\n  Imaging, Angular Resolution Enhancement, Fractional Anisotropy",
      "pdf_url": "http://arxiv.org/pdf/2409.07186v2",
      "published_date": "2024-09-11 11:12:26 UTC",
      "updated_date": "2024-09-14 13:30:34 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-19T23:09:13.710576"
    },
    {
      "arxiv_id": "2409.07165v1",
      "title": "Linear Time Complexity Conformers with SummaryMixing for Streaming Speech Recognition",
      "title_zh": "翻译失败",
      "authors": [
        "Titouan Parcollet",
        "Rogier van Dalen",
        "Shucong Zhang",
        "Sourav Batthacharya"
      ],
      "abstract": "Automatic speech recognition (ASR) with an encoder equipped with\nself-attention, whether streaming or non-streaming, takes quadratic time in the\nlength of the speech utterance. This slows down training and decoding, increase\ntheir cost, and limit the deployment of the ASR in constrained devices.\nSummaryMixing is a promising linear-time complexity alternative to\nself-attention for non-streaming speech recognition that, for the first time,\npreserves or outperforms the accuracy of self-attention models. Unfortunately,\nthe original definition of SummaryMixing is not suited to streaming speech\nrecognition. Hence, this work extends SummaryMixing to a Conformer Transducer\nthat works in both a streaming and an offline mode. It shows that this new\nlinear-time complexity speech encoder outperforms self-attention in both\nscenarios while requiring less compute and memory during training and decoding.",
      "tldr_zh": "本研究针对自动语音识别（ASR）中基于自注意力的编码器存在的时间复杂度问题（quadratic time），提出了一种线性时间复杂度（linear-time complexity）的解决方案。研究扩展了SummaryMixing机制，使其适用于Conformer Transducer，支持流式和离线语音识别模式。实验结果显示，该新编码器在准确性上优于传统自注意力模型，同时在训练和解码过程中显著减少计算和内存需求。",
      "categories": [
        "cs.SD",
        "cs.AI",
        "eess.AS"
      ],
      "primary_category": "cs.SD",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2409.07165v1",
      "published_date": "2024-09-11 10:24:43 UTC",
      "updated_date": "2024-09-11 10:24:43 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-19T23:09:22.936105"
    },
    {
      "arxiv_id": "2409.07154v2",
      "title": "Recurrent Aggregators in Neural Algorithmic Reasoning",
      "title_zh": "翻译失败",
      "authors": [
        "Kaijia Xu",
        "Petar Veličković"
      ],
      "abstract": "Neural algorithmic reasoning (NAR) is an emerging field that seeks to design\nneural networks that mimic classical algorithmic computations. Today, graph\nneural networks (GNNs) are widely used in neural algorithmic reasoners due to\ntheir message passing framework and permutation equivariance. In this extended\nabstract, we challenge this design choice, and replace the equivariant\naggregation function with a recurrent neural network. While seemingly\ncounter-intuitive, this approach has appropriate grounding when nodes have a\nnatural ordering -- and this is the case frequently in established reasoning\nbenchmarks like CLRS-30. Indeed, our recurrent NAR (RNAR) model performs very\nstrongly on such tasks, while handling many others gracefully. A notable\nachievement of RNAR is its decisive state-of-the-art result on the Heapsort and\nQuickselect tasks, both deemed as a significant challenge for contemporary\nneural algorithmic reasoners -- especially the latter, where RNAR achieves a\nmean micro-F1 score of 87%.",
      "tldr_zh": "本研究挑战了图神经网络 (GNNs) 在神经算法推理 (NAR) 中的主导地位，提出使用循环神经网络 (RNN) 替换等变聚合函数，开发出 recurrent NAR (RNAR) 模型，以更好地处理节点具有自然顺序的任务，如 CLRS-30 基准。RNAR 通过利用 RNN 的循环机制，实现了对算法计算的更强模仿，并在 Heapsort 和 Quickselect 任务上取得了显著进展，其中 Quickselect 的微观 F1 分数达到 87%，超越了现有模型。整体而言，该方法不仅在特定任务中表现出色，还能优雅地处理其他 NAR 场景，为神经算法推理提供了新视角。",
      "categories": [
        "cs.LG",
        "cs.AI"
      ],
      "primary_category": "cs.LG",
      "comment": "Presented at the Third Learning on Graphs Conference (LoG 2024). 10\n  pages, 1 figure",
      "pdf_url": "http://arxiv.org/pdf/2409.07154v2",
      "published_date": "2024-09-11 09:59:56 UTC",
      "updated_date": "2024-12-01 15:07:43 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-19T23:09:35.429676"
    },
    {
      "arxiv_id": "2409.07151v1",
      "title": "Zero-Shot Text-to-Speech as Golden Speech Generator: A Systematic Framework and its Applicability in Automatic Pronunciation Assessment",
      "title_zh": "翻译失败",
      "authors": [
        "Tien-Hong Lo",
        "Meng-Ting Tsai",
        "Berlin Chen"
      ],
      "abstract": "Second language (L2) learners can improve their pronunciation by imitating\ngolden speech, especially when the speech that aligns with their respective\nspeech characteristics. This study explores the hypothesis that\nlearner-specific golden speech generated with zero-shot text-to-speech (ZS-TTS)\ntechniques can be harnessed as an effective metric for measuring the\npronunciation proficiency of L2 learners. Building on this exploration, the\ncontributions of this study are at least two-fold: 1) design and development of\na systematic framework for assessing the ability of a synthesis model to\ngenerate golden speech, and 2) in-depth investigations of the effectiveness of\nusing golden speech in automatic pronunciation assessment (APA). Comprehensive\nexperiments conducted on the L2-ARCTIC and Speechocean762 benchmark datasets\nsuggest that our proposed modeling can yield significant performance\nimprovements with respect to various assessment metrics in relation to some\nprior arts. To our knowledge, this study is the first to explore the role of\ngolden speech in both ZS-TTS and APA, offering a promising regime for\ncomputer-assisted pronunciation training (CAPT).",
      "tldr_zh": "本研究探讨了使用 Zero-Shot Text-to-Speech (ZS-TTS) 生成的 learner-specific 黄金语音（golden speech）作为评估二语（L2）学习者发音熟练度的有效指标。研究的主要贡献包括设计一个系统框架来评估合成模型生成黄金语音的能力，以及深入调查其在 Automatic Pronunciation Assessment (APA) 中的应用效果。在 L2-ARCTIC 和 Speechocean762 数据集上的实验显示，该框架在各种评估指标上比现有方法取得了显著性能改进。该研究首次将黄金语音整合到 ZS-TTS 和 APA 中，为计算机辅助发音训练（CAPT）提供了新的发展方向。",
      "categories": [
        "eess.AS",
        "cs.AI"
      ],
      "primary_category": "eess.AS",
      "comment": "11 pages, 4 figures, 4 tables",
      "pdf_url": "http://arxiv.org/pdf/2409.07151v1",
      "published_date": "2024-09-11 09:55:57 UTC",
      "updated_date": "2024-09-11 09:55:57 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-19T23:09:49.621156"
    },
    {
      "arxiv_id": "2409.07136v1",
      "title": "Leveraging Unstructured Text Data for Federated Instruction Tuning of Large Language Models",
      "title_zh": "利用非结构化文本数据进行大语言模型的联邦指令微调",
      "authors": [
        "Rui Ye",
        "Rui Ge",
        "Yuchi Fengting",
        "Jingyi Chai",
        "Yanfeng Wang",
        "Siheng Chen"
      ],
      "abstract": "Federated instruction tuning enables multiple clients to collaboratively\nfine-tune a shared large language model (LLM) that can follow humans'\ninstructions without directly sharing raw data. However, existing literature\nimpractically requires that all the clients readily hold instruction-tuning\ndata (i.e., structured instruction-response pairs), which necessitates massive\nhuman annotations since clients' data is usually unstructured text instead.\nAddressing this, we propose a novel and flexible framework FedIT-U2S, which can\nautomatically transform unstructured corpus into structured data for federated\ninstruction tuning. FedIT-U2S consists two key steps: (1) few-shot\ninstruction-tuning data generation, where each unstructured data piece together\nwith several examples is combined to prompt an LLM in generating an\ninstruction-response pair. To further enhance the flexibility, a\nretrieval-based example selection technique is proposed, where the examples are\nautomatically selected based on the relatedness between the client's data piece\nand example pool, bypassing the need of determining examples in advance. (2) A\ntypical federated instruction tuning process based on the generated data.\nOverall, FedIT-U2S can be applied to diverse scenarios as long as the client\nholds valuable text corpus, broadening the application scope of federated\ninstruction tuning. We conduct a series of experiments on three domains\n(medicine, knowledge, and math), showing that our proposed FedIT-U2S can\nconsistently and significantly brings improvement over the base LLM.",
      "tldr_zh": "该论文提出 FedIT-U2S 框架，用于利用无结构文本数据进行 Large Language Models (LLM) 的 Federated Instruction Tuning，从而避免客户端直接共享原始数据。框架的关键步骤包括 few-shot instruction-tuning 数据生成，通过结合少量示例和检索-based 示例选择技术自动生成指令-响应对，以及后续的联邦微调过程。实验在医学、知识和数学三个领域表明，FedIT-U2S 显著提升了基线 LLM 的性能，扩展了联邦指令微调的应用范围。",
      "categories": [
        "cs.CL",
        "cs.AI",
        "cs.MA"
      ],
      "primary_category": "cs.CL",
      "comment": "11 pages, work in progress",
      "pdf_url": "http://arxiv.org/pdf/2409.07136v1",
      "published_date": "2024-09-11 09:31:44 UTC",
      "updated_date": "2024-09-11 09:31:44 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-19T23:09:59.537002"
    },
    {
      "arxiv_id": "2409.07128v1",
      "title": "Deep Learning Techniques for Hand Vein Biometrics: A Comprehensive Review",
      "title_zh": "深度学习技术在手部",
      "authors": [
        "Mustapha Hemis",
        "Hamza Kheddar",
        "Sami Bourouis",
        "Nasir Saleem"
      ],
      "abstract": "Biometric authentication has garnered significant attention as a secure and\nefficient method of identity verification. Among the various modalities, hand\nvein biometrics, including finger vein, palm vein, and dorsal hand vein\nrecognition, offer unique advantages due to their high accuracy, low\nsusceptibility to forgery, and non-intrusiveness. The vein patterns within the\nhand are highly complex and distinct for each individual, making them an ideal\nbiometric identifier. Additionally, hand vein recognition is contactless,\nenhancing user convenience and hygiene compared to other modalities such as\nfingerprint or iris recognition. Furthermore, the veins are internally located,\nrendering them less susceptible to damage or alteration, thus enhancing the\nsecurity and reliability of the biometric system. The combination of these\nfactors makes hand vein biometrics a highly effective and secure method for\nidentity verification. This review paper delves into the latest advancements in\ndeep learning techniques applied to finger vein, palm vein, and dorsal hand\nvein recognition. It encompasses all essential fundamentals of hand vein\nbiometrics, summarizes publicly available datasets, and discusses\nstate-of-the-art metrics used for evaluating the three modes. Moreover, it\nprovides a comprehensive overview of suggested approaches for finger, palm,\ndorsal, and multimodal vein techniques, offering insights into the best\nperformance achieved, data augmentation techniques, and effective transfer\nlearning methods, along with associated pretrained deep learning models.\nAdditionally, the review addresses research challenges faced and outlines\nfuture directions and perspectives, encouraging researchers to enhance existing\nmethods and propose innovative techniques.",
      "tldr_zh": "这篇综述论文系统回顾了深度学习技术在手部静脉生物识别（包括finger vein、palm vein和dorsal hand vein）中的应用，强调其高准确性、抗伪造性和非接触式优势。论文涵盖了生物识别基础、公开数据集、评估指标，以及推荐的方法如数据增强和transfer learning技术，并总结了最佳性能和预训练模型。最终，它讨论了当前研究挑战，并为未来方向提供见解，鼓励创新改进。",
      "categories": [
        "eess.IV",
        "cs.AI",
        "cs.CR",
        "cs.CV"
      ],
      "primary_category": "eess.IV",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2409.07128v1",
      "published_date": "2024-09-11 09:25:05 UTC",
      "updated_date": "2024-09-11 09:25:05 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-19T23:10:11.702094"
    },
    {
      "arxiv_id": "2409.07127v2",
      "title": "DCMAC: Demand-aware Customized Multi-Agent Communication via Upper Bound Training",
      "title_zh": "翻译失败",
      "authors": [
        "Dongkun Huo",
        "Huateng Zhang",
        "Yixue Hao",
        "Yuanlin Ye",
        "Long Hu",
        "Rui Wang",
        "Min Chen"
      ],
      "abstract": "Efficient communication can enhance the overall performance of collaborative\nmulti-agent reinforcement learning. A common approach is to share observations\nthrough full communication, leading to significant communication overhead.\nExisting work attempts to perceive the global state by conducting teammate\nmodel based on local information. However, they ignore that the uncertainty\ngenerated by prediction may lead to difficult training. To address this\nproblem, we propose a Demand-aware Customized Multi-Agent Communication (DCMAC)\nprotocol, which use an upper bound training to obtain the ideal policy. By\nutilizing the demand parsing module, agent can interpret the gain of sending\nlocal message on teammate, and generate customized messages via compute the\ncorrelation between demands and local observation using cross-attention\nmechanism. Moreover, our method can adapt to the communication resources of\nagents and accelerate the training progress by appropriating the ideal policy\nwhich is trained with joint observation. Experimental results reveal that DCMAC\nsignificantly outperforms the baseline algorithms in both unconstrained and\ncommunication constrained scenarios.",
      "tldr_zh": "该研究提出DCMAC协议，通过upper bound training获得理想策略，以提升多智能体强化学习中的通信效率，避免传统全通信的高开销问题。DCMAC利用需求解析模块和交叉注意力机制，让代理评估发送本地消息的收益，并基于需求与本地观察的相关性生成自定义消息，同时适应代理的通信资源并加速训练过程。实验结果表明，DCMAC在无约束和通信约束场景下显著优于基线算法。",
      "categories": [
        "cs.AI",
        "cs.MA"
      ],
      "primary_category": "cs.AI",
      "comment": "Paper has errors and needs to be revised and submitted",
      "pdf_url": "http://arxiv.org/pdf/2409.07127v2",
      "published_date": "2024-09-11 09:23:27 UTC",
      "updated_date": "2024-12-10 02:25:18 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-19T23:10:23.299065"
    },
    {
      "arxiv_id": "2409.07119v1",
      "title": "Credibility-Limited Revision for Epistemic Spaces",
      "title_zh": "翻译失败",
      "authors": [
        "Kai Sauerwald"
      ],
      "abstract": "We consider credibility-limited revision in the framework of belief change\nfor epistemic spaces, permitting inconsistent belief sets and inconsistent\nbeliefs. In this unrestricted setting, the class of credibility-limited\nrevision operators does not include any AGM revision operators. We extend the\nclass of credibility-limited revision operators in a way that all AGM revision\noperators are included while keeping the original spirit of credibility-limited\nrevision. Extended credibility-limited revision operators are defined\naxiomatically. A semantic characterization of extended credibility-limited\nrevision operators that employ total preorders on possible worlds is presented.",
      "tldr_zh": "本文在认知空间(epistemic spaces)框架下，探讨了允许不一致信念集的 credibility-limited revision，指出原操作符类不包含任何 AGM revision operators。论文扩展了 credibility-limited revision operators 的类，使其涵盖所有 AGM revision operators，同时保留其核心精神，并通过公理定义这些扩展操作符。最终，提供了一个基于 total preorders on possible worlds 的语义特征化，以全面描述这些操作符。",
      "categories": [
        "cs.AI",
        "cs.LO"
      ],
      "primary_category": "cs.AI",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2409.07119v1",
      "published_date": "2024-09-11 09:15:43 UTC",
      "updated_date": "2024-09-11 09:15:43 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-19T23:10:35.315993"
    },
    {
      "arxiv_id": "2409.07115v1",
      "title": "Attention Down-Sampling Transformer, Relative Ranking and Self-Consistency for Blind Image Quality Assessment",
      "title_zh": "翻译失败",
      "authors": [
        "Mohammed Alsaafin",
        "Musab Alsheikh",
        "Saeed Anwar",
        "Muhammad Usman"
      ],
      "abstract": "The no-reference image quality assessment is a challenging domain that\naddresses estimating image quality without the original reference. We introduce\nan improved mechanism to extract local and non-local information from images\nvia different transformer encoders and CNNs. The utilization of Transformer\nencoders aims to mitigate locality bias and generate a non-local representation\nby sequentially processing CNN features, which inherently capture local visual\nstructures. Establishing a stronger connection between subjective and objective\nassessments is achieved through sorting within batches of images based on\nrelative distance information. A self-consistency approach to self-supervision\nis presented, explicitly addressing the degradation of no-reference image\nquality assessment (NR-IQA) models under equivariant transformations. Our\napproach ensures model robustness by maintaining consistency between an image\nand its horizontally flipped equivalent. Through empirical evaluation of five\npopular image quality assessment datasets, the proposed model outperforms\nalternative algorithms in the context of no-reference image quality assessment\ndatasets, especially on smaller datasets. Codes are available at\n\\href{https://github.com/mas94/ADTRS}{https://github.com/mas94/ADTRS}",
      "tldr_zh": "这篇论文针对无参考图像质量评估 (NR-IQA) 提出了一种改进方法，使用 Attention Down-Sampling Transformer 和 CNNs 提取图像的局部和非局部信息，以减少局部偏差并生成更全面的特征表示。论文引入相对排名机制，通过批处理图像的相对距离信息增强主观和客观评估之间的关联，并采用自一致性(self-consistency)自监督策略，确保模型在等变变换（如水平翻转）下保持鲁棒性。实验结果显示，该模型在五个流行图像质量评估数据集上优于其他算法，尤其在较小数据集上表现出色。",
      "categories": [
        "eess.IV",
        "cs.AI",
        "cs.CV",
        "cs.LG"
      ],
      "primary_category": "eess.IV",
      "comment": "Accepted in International Conference on Image Processing (ICIP)",
      "pdf_url": "http://arxiv.org/pdf/2409.07115v1",
      "published_date": "2024-09-11 09:08:43 UTC",
      "updated_date": "2024-09-11 09:08:43 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-19T23:10:47.693949"
    },
    {
      "arxiv_id": "2409.07114v1",
      "title": "A Continual and Incremental Learning Approach for TinyML On-device Training Using Dataset Distillation and Model Size Adaption",
      "title_zh": "翻译失败",
      "authors": [
        "Marcus Rüb",
        "Philipp Tuchel",
        "Axel Sikora",
        "Daniel Mueller-Gritschneder"
      ],
      "abstract": "A new algorithm for incremental learning in the context of Tiny Machine\nlearning (TinyML) is presented, which is optimized for low-performance and\nenergy efficient embedded devices. TinyML is an emerging field that deploys\nmachine learning models on resource-constrained devices such as\nmicrocontrollers, enabling intelligent applications like voice recognition,\nanomaly detection, predictive maintenance, and sensor data processing in\nenvironments where traditional machine learning models are not feasible. The\nalgorithm solve the challenge of catastrophic forgetting through the use of\nknowledge distillation to create a small, distilled dataset. The novelty of the\nmethod is that the size of the model can be adjusted dynamically, so that the\ncomplexity of the model can be adapted to the requirements of the task. This\noffers a solution for incremental learning in resource-constrained\nenvironments, where both model size and computational efficiency are critical\nfactors. Results show that the proposed algorithm offers a promising approach\nfor TinyML incremental learning on embedded devices. The algorithm was tested\non five datasets including: CIFAR10, MNIST, CORE50, HAR, Speech Commands. The\nfindings indicated that, despite using only 43% of Floating Point Operations\n(FLOPs) compared to a larger fixed model, the algorithm experienced a\nnegligible accuracy loss of just 1%. In addition, the presented method is\nmemory efficient. While state-of-the-art incremental learning is usually very\nmemory intensive, the method requires only 1% of the original data set.",
      "tldr_zh": "本研究提出了一种针对 TinyML 的持续增量学习算法，优化用于低性能和节能的嵌入式设备，以支持语音识别、异常检测等应用。算法通过知识蒸馏创建小型蒸馏数据集（dataset distillation）来解决灾难性遗忘问题，并实现模型大小动态调整（model size adaption），以适应任务的资源需求。实验在 CIFAR10、MNIST 等五个数据集上验证，结果显示该算法仅使用 43% 的 Floating Point Operations (FLOPs) 便实现了准确率损失仅 1%，且内存需求仅为原数据集的 1%，展示了其在资源受限环境中的高效性。",
      "categories": [
        "cs.LG",
        "cs.AI"
      ],
      "primary_category": "cs.LG",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2409.07114v1",
      "published_date": "2024-09-11 09:02:33 UTC",
      "updated_date": "2024-09-11 09:02:33 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-19T23:10:59.390761"
    },
    {
      "arxiv_id": "2409.07109v1",
      "title": "Advancing On-Device Neural Network Training with TinyPropv2: Dynamic, Sparse, and Efficient Backpropagation",
      "title_zh": "通过 TinyPropv2 推进设备上神经网络训练：动态、稀疏且高效的反向传播",
      "authors": [
        "Marcus Rüb",
        "Axel Sikora",
        "Daniel Mueller-Gritschneder"
      ],
      "abstract": "This study introduces TinyPropv2, an innovative algorithm optimized for\non-device learning in deep neural networks, specifically designed for low-power\nmicrocontroller units. TinyPropv2 refines sparse backpropagation by dynamically\nadjusting the level of sparsity, including the ability to selectively skip\ntraining steps. This feature significantly lowers computational effort without\nsubstantially compromising accuracy. Our comprehensive evaluation across\ndiverse datasets CIFAR 10, CIFAR100, Flower, Food, Speech Command, MNIST, HAR,\nand DCASE2020 reveals that TinyPropv2 achieves near-parity with full training\nmethods, with an average accuracy drop of only around 1 percent in most cases.\nFor instance, against full training, TinyPropv2's accuracy drop is minimal, for\nexample, only 0.82 percent on CIFAR 10 and 1.07 percent on CIFAR100. In terms\nof computational effort, TinyPropv2 shows a marked reduction, requiring as\nlittle as 10 percent of the computational effort needed for full training in\nsome scenarios, and consistently outperforms other sparse training\nmethodologies. These findings underscore TinyPropv2's capacity to efficiently\nmanage computational resources while maintaining high accuracy, positioning it\nas an advantageous solution for advanced embedded device applications in the\nIoT ecosystem.",
      "tldr_zh": "本研究引入了 TinyPropv2 算法，针对深度神经网络的设备端训练进行优化，特别适用于低功耗微控制器，通过动态调整稀疏 backpropagation 的稀疏级别并选择性跳过训练步骤，显著降低了计算需求，同时基本不影响准确率。  \n在 CIFAR-10、CIFAR100 等多种数据集上的全面评估中，TinyPropv2 与完整训练方法相比，平均准确率仅下降约1%（例如 CIFAR-10 上下降0.82%、CIFAR100 上下降1.07%），并在某些场景下只需完整训练的10%计算努力。  \n这些结果表明，TinyPropv2 优于其他稀疏训练方法，为 IoT 生态中的嵌入式设备提供高效、可行的训练解决方案。",
      "categories": [
        "cs.LG",
        "cs.AI"
      ],
      "primary_category": "cs.LG",
      "comment": "2024 International Joint Conference on Neural Networks (IJCNN)",
      "pdf_url": "http://arxiv.org/pdf/2409.07109v1",
      "published_date": "2024-09-11 08:56:13 UTC",
      "updated_date": "2024-09-11 08:56:13 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-19T23:11:13.082706"
    },
    {
      "arxiv_id": "2409.07098v1",
      "title": "Redundancy-Aware Camera Selection for Indoor Scene Neural Rendering",
      "title_zh": "翻译失败",
      "authors": [
        "Zehao Wang",
        "Han Zhou",
        "Matthew B. Blaschko",
        "Tinne Tuytelaars",
        "Minye Wu"
      ],
      "abstract": "Novel view synthesis of indoor scenes can be achieved by capturing a\nmonocular video sequence of the environment. However, redundant information\ncaused by artificial movements in the input video data reduces the efficiency\nof scene modeling. In this work, we tackle this challenge from the perspective\nof camera selection. We begin by constructing a similarity matrix that\nincorporates both the spatial diversity of the cameras and the semantic\nvariation of the images. Based on this matrix, we use the Intra-List Diversity\n(ILD) metric to assess camera redundancy, formulating the camera selection task\nas an optimization problem. Then we apply a diversity-based sampling algorithm\nto optimize the camera selection. We also develop a new dataset, IndoorTraj,\nwhich includes long and complex camera movements captured by humans in virtual\nindoor environments, closely mimicking real-world scenarios. Experimental\nresults demonstrate that our strategy outperforms other approaches under time\nand memory constraints. Remarkably, our method achieves performance comparable\nto models trained on the full dataset, while using only an average of 15% of\nthe frames and 75% of the allotted time.",
      "tldr_zh": "该论文针对室内场景神经渲染中，使用单目视频序列时存在的冗余信息问题，提出了一种冗余感知的相机选择策略，以提高建模效率。方法包括构建一个结合相机空间多样性和图像语义变化的相似性矩阵，并使用 Intra-List Diversity (ILD) 指标将相机选择转化为优化问题，然后应用基于多样性的采样算法进行优化。同时，作者开发了新数据集 IndoorTraj，该数据集包含人类在虚拟室内环境中捕获的长而复杂的相机运动，模拟真实场景。实验结果显示，该策略在时间和内存约束下优于其他方法，仅使用平均15%的帧和75%的时间，就实现了与完整数据集相当的性能。",
      "categories": [
        "cs.CV",
        "cs.AI"
      ],
      "primary_category": "cs.CV",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2409.07098v1",
      "published_date": "2024-09-11 08:36:49 UTC",
      "updated_date": "2024-09-11 08:36:49 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-19T23:11:23.353888"
    },
    {
      "arxiv_id": "2409.07092v1",
      "title": "CWT-Net: Super-resolution of Histopathology Images Using a Cross-scale Wavelet-based Transformer",
      "title_zh": "翻译失败",
      "authors": [
        "Feiyang Jia",
        "Zhineng Chen",
        "Ziying Song",
        "Lin Liu",
        "Caiyan Jia"
      ],
      "abstract": "Super-resolution (SR) aims to enhance the quality of low-resolution images\nand has been widely applied in medical imaging. We found that the design\nprinciples of most existing methods are influenced by SR tasks based on\nreal-world images and do not take into account the significance of the\nmulti-level structure in pathological images, even if they can achieve\nrespectable objective metric evaluations. In this work, we delve into two\nsuper-resolution working paradigms and propose a novel network called CWT-Net,\nwhich leverages cross-scale image wavelet transform and Transformer\narchitecture. Our network consists of two branches: one dedicated to learning\nsuper-resolution and the other to high-frequency wavelet features. To generate\nhigh-resolution histopathology images, the Transformer module shares and fuses\nfeatures from both branches at various stages. Notably, we have designed a\nspecialized wavelet reconstruction module to effectively enhance the wavelet\ndomain features and enable the network to operate in different modes, allowing\nfor the introduction of additional relevant information from cross-scale\nimages. Our experimental results demonstrate that our model significantly\noutperforms state-of-the-art methods in both performance and visualization\nevaluations and can substantially boost the accuracy of image diagnostic\nnetworks.",
      "tldr_zh": "本研究针对病理图像的超分辨率（SR）问题，提出了一种新型网络CWT-Net，利用跨尺度小波变换和Transformer架构，以解决现有方法忽略多级结构的问题。CWT-Net包含两个分支：一个专注于SR学习，另一个处理高频小波特征；Transformer模块在不同阶段共享和融合这些特征，并通过专门的小波重建模块增强小波域信息，支持引入跨尺度图像的相关数据。实验结果表明，该模型在性能、可视化评估和图像诊断网络准确性上显著优于现有方法。",
      "categories": [
        "eess.IV",
        "cs.AI",
        "cs.CV"
      ],
      "primary_category": "eess.IV",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2409.07092v1",
      "published_date": "2024-09-11 08:26:28 UTC",
      "updated_date": "2024-09-11 08:26:28 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-19T23:11:35.986828"
    },
    {
      "arxiv_id": "2409.07088v1",
      "title": "Ontology-Free General-Domain Knowledge Graph-to-Text Generation Dataset Synthesis using Large Language Model",
      "title_zh": "翻译失败",
      "authors": [
        "Daehee Kim",
        "Deokhyung Kang",
        "Sangwon Ryu",
        "Gary Geunbae Lee"
      ],
      "abstract": "Knowledge Graph-to-Text (G2T) generation involves verbalizing structured\nknowledge graphs into natural language text. Recent advancements in Pretrained\nLanguage Models (PLMs) have improved G2T performance, but their effectiveness\ndepends on datasets with precise graph-text alignment. However, the scarcity of\nhigh-quality, general-domain G2T generation datasets restricts progress in the\ngeneral-domain G2T generation research. To address this issue, we introduce\nWikipedia Ontology-Free Graph-text dataset (WikiOFGraph), a new large-scale G2T\ndataset generated using a novel method that leverages Large Language Model\n(LLM) and Data-QuestEval. Our new dataset, which contains 5.85M general-domain\ngraph-text pairs, offers high graph-text consistency without relying on\nexternal ontologies. Experimental results demonstrate that PLM fine-tuned on\nWikiOFGraph outperforms those trained on other datasets across various\nevaluation metrics. Our method proves to be a scalable and effective solution\nfor generating high-quality G2T data, significantly advancing the field of G2T\ngeneration.",
      "tldr_zh": "该论文针对Knowledge Graph-to-Text (G2T) 生成领域的挑战，提出了一种使用Large Language Model (LLM) 和Data-QuestEval 的新方法，来合成大规模的通用领域数据集。研究者创建了Wikipedia Ontology-Free Graph-text dataset (WikiOFGraph)，包含5.85M对图-文本对，该数据集无需依赖外部ontologies，确保了高图-文本一致性。实验结果显示，在WikiOFGraph上微调的Pretrained Language Models (PLMs) 在各种评估指标上优于其他数据集训练的模型，从而为G2T生成研究提供了可扩展、高质量的数据解决方案。",
      "categories": [
        "cs.CL",
        "cs.AI"
      ],
      "primary_category": "cs.CL",
      "comment": "18 pages, 9 figures",
      "pdf_url": "http://arxiv.org/pdf/2409.07088v1",
      "published_date": "2024-09-11 08:16:20 UTC",
      "updated_date": "2024-09-11 08:16:20 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-19T23:11:48.307913"
    },
    {
      "arxiv_id": "2409.07078v1",
      "title": "Multimodal Emotion Recognition with Vision-language Prompting and Modality Dropout",
      "title_zh": "翻译失败",
      "authors": [
        "Anbin QI",
        "Zhongliang Liu",
        "Xinyong Zhou",
        "Jinba Xiao",
        "Fengrun Zhang",
        "Qi Gan",
        "Ming Tao",
        "Gaozheng Zhang",
        "Lu Zhang"
      ],
      "abstract": "In this paper, we present our solution for the Second Multimodal Emotion\nRecognition Challenge Track 1(MER2024-SEMI). To enhance the accuracy and\ngeneralization performance of emotion recognition, we propose several methods\nfor Multimodal Emotion Recognition. Firstly, we introduce EmoVCLIP, a model\nfine-tuned based on CLIP using vision-language prompt learning, designed for\nvideo-based emotion recognition tasks. By leveraging prompt learning on CLIP,\nEmoVCLIP improves the performance of pre-trained CLIP on emotional videos.\nAdditionally, to address the issue of modality dependence in multimodal fusion,\nwe employ modality dropout for robust information fusion. Furthermore, to aid\nBaichuan in better extracting emotional information, we suggest using GPT-4 as\nthe prompt for Baichuan. Lastly, we utilize a self-training strategy to\nleverage unlabeled videos. In this process, we use unlabeled videos with\nhigh-confidence pseudo-labels generated by our model and incorporate them into\nthe training set. Experimental results demonstrate that our model ranks 1st in\nthe MER2024-SEMI track, achieving an accuracy of 90.15% on the test set.",
      "tldr_zh": "本论文提出了一种多模态情感识别解决方案，针对 MER2024-SEMI 挑战赛，通过 EmoVCLIP 模型基于 CLIP 的 vision-language prompting 微调，提升了视频情感识别的性能。针对多模态融合中的模态依赖问题，该方法引入 modality dropout 实现鲁棒信息融合，并利用 GPT-4 作为提示优化 Baichuan 模型的情感提取，同时采用自训练策略将高置信度伪标签的未标注视频加入训练集。实验结果显示，该模型在 MER2024-SEMI 赛道中排名第一，测试集准确率达到 90.15%。",
      "categories": [
        "cs.CV",
        "cs.AI"
      ],
      "primary_category": "cs.CV",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2409.07078v1",
      "published_date": "2024-09-11 08:06:47 UTC",
      "updated_date": "2024-09-11 08:06:47 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-19T23:12:00.901139"
    },
    {
      "arxiv_id": "2409.07055v2",
      "title": "Legal Fact Prediction: The Missing Piece in Legal Judgment Prediction",
      "title_zh": "翻译失败",
      "authors": [
        "Junkai Liu",
        "Yujie Tong",
        "Hui Huang",
        "Bowen Zheng",
        "Yiran Hu",
        "Peicheng Wu",
        "Chuan Xiao",
        "Makoto Onizuka",
        "Muyun Yang",
        "Shuyuan Zheng"
      ],
      "abstract": "Legal judgment prediction (LJP), which enables litigants and their lawyers to\nforecast judgment outcomes and refine litigation strategies, has emerged as a\ncrucial legal NLP task. Existing studies typically utilize legal facts, i.e.,\nfacts that have been established by evidence and determined by the judge, to\npredict the judgment. However, legal facts are often difficult to obtain in the\nearly stages of litigation, significantly limiting the practical applicability\nof fact-based LJP. To address this limitation, we propose a novel legal NLP\ntask: \\textit{legal fact prediction} (LFP), which takes the evidence submitted\nby litigants for trial as input to predict legal facts, thereby empowering\nfact-based LJP technologies to perform prediction in the absence of\nground-truth legal facts. We also propose the first benchmark dataset,\nLFPBench, for evaluating the LFP task. Our extensive experiments on LFPBench\ndemonstrate the effectiveness of LFP-empowered LJP and highlight promising\nresearch directions for LFP. Our code and data are available at\nhttps://github.com/HPRCEST/LFPBench.",
      "tldr_zh": "论文指出，现有的 Legal Judgment Prediction (LJP) 任务依赖于已确定的法律事实（legal facts），但这些事实在诉讼早期难以获取，从而限制了其实际应用。研究提出一个新任务 Legal Fact Prediction (LFP)，以诉讼当事方提交的证据作为输入，预测法律事实，从而使基于事实的 LJP 能够在没有真实法律事实的情况下进行预测。作者构建了首个基准数据集 LFPBench，并通过广泛实验证明了 LFP 对 LJP 的有效性，同时指出了 LFP 的有前景研究方向。代码和数据已公开在 GitHub 上。",
      "categories": [
        "cs.CL",
        "cs.AI",
        "cs.CY"
      ],
      "primary_category": "cs.CL",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2409.07055v2",
      "published_date": "2024-09-11 07:01:08 UTC",
      "updated_date": "2025-03-06 05:48:54 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-19T23:12:12.755836"
    },
    {
      "arxiv_id": "2409.07054v2",
      "title": "Native vs Non-Native Language Prompting: A Comparative Analysis",
      "title_zh": "翻译失败",
      "authors": [
        "Mohamed Bayan Kmainasi",
        "Rakif Khan",
        "Ali Ezzat Shahroor",
        "Boushra Bendou",
        "Maram Hasanain",
        "Firoj Alam"
      ],
      "abstract": "Large language models (LLMs) have shown remarkable abilities in different\nfields, including standard Natural Language Processing (NLP) tasks. To elicit\nknowledge from LLMs, prompts play a key role, consisting of natural language\ninstructions. Most open and closed source LLMs are trained on available labeled\nand unlabeled resources--digital content such as text, images, audio, and\nvideos. Hence, these models have better knowledge for high-resourced languages\nbut struggle with low-resourced languages. Since prompts play a crucial role in\nunderstanding their capabilities, the language used for prompts remains an\nimportant research question. Although there has been significant research in\nthis area, it is still limited, and less has been explored for medium to\nlow-resourced languages. In this study, we investigate different prompting\nstrategies (native vs. non-native) on 11 different NLP tasks associated with 12\ndifferent Arabic datasets (9.7K data points). In total, we conducted 197\nexperiments involving 3 LLMs, 12 datasets, and 3 prompting strategies. Our\nfindings suggest that, on average, the non-native prompt performs the best,\nfollowed by mixed and native prompts.",
      "tldr_zh": "这篇论文比较了在大型语言模型(LLMs)上使用母语(native)提示与非母语(non-native)提示的性能差异，焦点在于阿拉伯语等中低资源语言的NLP任务。研究者通过197个实验，评估了3个LLMs在11个NLP任务和12个阿拉伯数据集(共9.7K数据点)上的表现，涉及native、non-native和mixed三种提示策略。结果显示，非母语提示平均表现最佳，其次是mixed提示，然后是native提示。这一发现为优化LLMs在低资源语言中的提示设计提供了重要指导。",
      "categories": [
        "cs.CL",
        "cs.AI",
        "68T50",
        "F.2.2; I.2.7"
      ],
      "primary_category": "cs.CL",
      "comment": "Foundation Models, Large Language Models, Arabic NLP, LLMs, Native,\n  Contextual Understanding, Arabic LLM",
      "pdf_url": "http://arxiv.org/pdf/2409.07054v2",
      "published_date": "2024-09-11 06:59:37 UTC",
      "updated_date": "2024-10-06 10:16:27 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-19T23:12:24.427296"
    },
    {
      "arxiv_id": "2409.07045v1",
      "title": "Beyond IID: Optimizing Instruction Learning from the Perspective of Instruction Interaction and Dependency",
      "title_zh": "翻译失败",
      "authors": [
        "Hanyu Zhao",
        "Li Du",
        "Yiming Ju",
        "Chengwei Wu",
        "Tengfei Pan"
      ],
      "abstract": "With the availability of various instruction datasets, a pivotal challenge is\nhow to effectively select and integrate these instructions to fine-tune large\nlanguage models (LLMs). Previous research mainly focuses on selecting\nindividual high-quality instructions. However, these works overlooked the joint\ninteractions and dependencies between different categories of instructions,\nleading to suboptimal selection strategies. Moreover, the nature of these\ninteraction patterns remains largely unexplored, let alone optimize the\ninstruction set with regard to them. To fill these gaps, in this paper, we: (1)\nsystemically investigate interaction and dependency patterns between different\ncategories of instructions, (2) manage to optimize the instruction set\nconcerning the interaction patterns using a linear programming-based method,\nand optimize the learning schema of SFT using an instruction dependency\ntaxonomy guided curriculum learning. Experimental results across different LLMs\ndemonstrate improved performance over strong baselines on widely adopted\nbenchmarks.",
      "tldr_zh": "本研究超越了独立同分布（IID）假设，从指令交互和依赖角度优化指令学习，解决了现有方法在选择和整合指令数据集时忽略交互模式的问题。主要贡献包括：系统调查不同类别指令之间的交互和依赖模式；使用基于线性规划的优化方法调整指令集，并通过指令依赖分类学指导的课程学习（curriculum learning）改进监督微调（SFT）的学习方案。在多个大型语言模型（LLMs）上的实验显示，该方法在广泛采用的基准上比强基线性能显著提升。",
      "categories": [
        "cs.CL",
        "cs.AI"
      ],
      "primary_category": "cs.CL",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2409.07045v1",
      "published_date": "2024-09-11 06:27:50 UTC",
      "updated_date": "2024-09-11 06:27:50 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-19T23:12:34.727721"
    },
    {
      "arxiv_id": "2409.07033v1",
      "title": "E-commerce Webpage Recommendation Scheme Base on Semantic Mining and Neural Networks",
      "title_zh": "翻译失败",
      "authors": [
        "Wenchao Zhao",
        "Xiaoyi Liu",
        "Ruilin Xu",
        "Lingxi Xiao",
        "Muqing Li"
      ],
      "abstract": "In e-commerce websites, web mining web page recommendation technology has\nbeen widely used. However, recommendation solutions often cannot meet the\nactual application needs of online shopping users. To address this problem,\nthis paper proposes an e-commerce web page recommendation solution that\ncombines semantic web mining and BP neural networks. First, the web logs of\nuser searches are processed, and 5 features are extracted: content priority,\ntime consumption priority, online shopping users' explicit/implicit feedback on\nthe website, recommendation semantics and input deviation amount. Then, these\nfeatures are used as input features of the BP neural network to classify and\nidentify the priority of the final output web page. Finally, the web pages are\nsorted according to priority and recommended to users. This project uses book\nsales webpages as samples for experiments. The results show that this solution\ncan quickly and accurately identify the webpages required by users.",
      "tldr_zh": "本论文提出了一种结合语义网络挖掘和 BP neural networks 的电子商务网页推荐方案，以解决现有推荐技术无法满足用户实际需求的问题。方案首先处理用户搜索日志，提取5个特征，包括内容优先级、时间消耗优先级、用户显式/隐式反馈、推荐语义和输入偏差量；然后将这些特征作为 BP neural networks 的输入进行网页优先级分类和识别。实验以书籍销售网页为样本，结果表明该方案能快速准确地识别用户所需网页。",
      "categories": [
        "cs.IR",
        "cs.AI"
      ],
      "primary_category": "cs.IR",
      "comment": "arXiv admin note: text overlap with arXiv:2409.01137",
      "pdf_url": "http://arxiv.org/pdf/2409.07033v1",
      "published_date": "2024-09-11 06:03:02 UTC",
      "updated_date": "2024-09-11 06:03:02 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-19T23:12:47.535160"
    },
    {
      "arxiv_id": "2409.07016v1",
      "title": "Improving Anomalous Sound Detection via Low-Rank Adaptation Fine-Tuning of Pre-Trained Audio Models",
      "title_zh": "通过低秩适应微调预训练",
      "authors": [
        "Xinhu Zheng",
        "Anbai Jiang",
        "Bing Han",
        "Yanmin Qian",
        "Pingyi Fan",
        "Jia Liu",
        "Wei-Qiang Zhang"
      ],
      "abstract": "Anomalous Sound Detection (ASD) has gained significant interest through the\napplication of various Artificial Intelligence (AI) technologies in industrial\nsettings. Though possessing great potential, ASD systems can hardly be readily\ndeployed in real production sites due to the generalization problem, which is\nprimarily caused by the difficulty of data collection and the complexity of\nenvironmental factors. This paper introduces a robust ASD model that leverages\naudio pre-trained models. Specifically, we fine-tune these models using machine\noperation data, employing SpecAug as a data augmentation strategy.\nAdditionally, we investigate the impact of utilizing Low-Rank Adaptation (LoRA)\ntuning instead of full fine-tuning to address the problem of limited data for\nfine-tuning. Our experiments on the DCASE2023 Task 2 dataset establish a new\nbenchmark of 77.75% on the evaluation set, with a significant improvement of\n6.48% compared with previous state-of-the-art (SOTA) models, including top-tier\ntraditional convolutional networks and speech pre-trained models, which\ndemonstrates the effectiveness of audio pre-trained models with LoRA tuning.\nAblation studies are also conducted to showcase the efficacy of the proposed\nscheme.",
      "tldr_zh": "这篇论文针对 Anomalous Sound Detection (ASD) 的泛化问题，提出了一种利用音频预训练模型的鲁棒方法，通过 Low-Rank Adaptation (LoRA) 微调来应对数据有限的挑战，并结合 SpecAug 作为数据增强策略。相比传统全微调，该方法显著减少了参数调整，同时在 DCASE2023 Task 2 数据集上建立了新的基准，评估集性能达到 77.75%。实验结果显示，该方案比现有 SOTA 模型（如传统卷积网络和语音预训练模型）提高了 6.48%，并通过消融研究证明了其有效性。",
      "categories": [
        "cs.SD",
        "cs.AI",
        "eess.AS"
      ],
      "primary_category": "cs.SD",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2409.07016v1",
      "published_date": "2024-09-11 05:19:38 UTC",
      "updated_date": "2024-09-11 05:19:38 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-19T23:13:01.056124"
    },
    {
      "arxiv_id": "2409.07012v2",
      "title": "Towards Predicting Temporal Changes in a Patient's Chest X-ray Images based on Electronic Health Records",
      "title_zh": "翻译失败",
      "authors": [
        "Daeun Kyung",
        "Junu Kim",
        "Tackeun Kim",
        "Edward Choi"
      ],
      "abstract": "Chest X-ray (CXR) is an important diagnostic tool widely used in hospitals to\nassess patient conditions and monitor changes over time. Recently, generative\nmodels, specifically diffusion-based models, have shown promise in generating\nrealistic synthetic CXRs. However, these models mainly focus on conditional\ngeneration using single-time-point data, i.e., generating CXRs conditioned on\ntheir corresponding reports from a specific time. This limits their clinical\nutility, particularly for capturing temporal changes. To address this\nlimitation, we propose a novel framework, EHRXDiff, which predicts future CXR\nimages by integrating previous CXRs with subsequent medical events, e.g.,\nprescriptions, lab measures, etc. Our framework dynamically tracks and predicts\ndisease progression based on a latent diffusion model, conditioned on the\nprevious CXR image and a history of medical events. We comprehensively evaluate\nthe performance of our framework across three key aspects, including clinical\nconsistency, demographic consistency, and visual realism. Results show that our\nframework generates high-quality, realistic future images that effectively\ncapture potential temporal changes. This suggests that our framework could be\nfurther developed to support clinical decision-making and provide valuable\ninsights for patient monitoring and treatment planning in the medical field.\nThe code is available at https://github.com/dek924/EHRXDiff.",
      "tldr_zh": "本文提出EHRXDiff框架，用于基于电子健康记录(EHR)预测患者Chest X-ray (CXR)图像的时序变化，解决现有diffusion-based models在捕捉时序动态方面的局限性。该框架采用latent diffusion model，结合之前的CXR图像和后续医疗事件（如处方和实验室测量）来生成高质量的未来图像。实验评估显示，EHRXDiff在临床一致性、人口统计一致性和视觉真实性方面表现出色，能够有效捕捉潜在疾病进展，并为临床决策、患者监测和治疗规划提供支持。代码可访问https://github.com/dek924/EHRXDiff。",
      "categories": [
        "eess.IV",
        "cs.AI",
        "cs.CV"
      ],
      "primary_category": "eess.IV",
      "comment": "Accepted at Proc. of Conference on Health, Inference, and Learning\n  (CHIL) 2025 (10 pages for main text, 3 pages for references, 8 pages for\n  supplementary materials)",
      "pdf_url": "http://arxiv.org/pdf/2409.07012v2",
      "published_date": "2024-09-11 04:49:44 UTC",
      "updated_date": "2025-05-06 00:52:51 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-19T23:13:13.140739"
    },
    {
      "arxiv_id": "2409.06997v1",
      "title": "What is the Right Notion of Distance between Predict-then-Optimize Tasks?",
      "title_zh": "翻译失败",
      "authors": [
        "Paula Rodriguez-Diaz",
        "Lingkai Kong",
        "Kai Wang",
        "David Alvarez-Melis",
        "Milind Tambe"
      ],
      "abstract": "Comparing datasets is a fundamental task in machine learning, essential for\nvarious learning paradigms; from evaluating train and test datasets for model\ngeneralization to using dataset similarity for detecting data drift. While\ntraditional notions of dataset distances offer principled measures of\nsimilarity, their utility has largely been assessed through prediction error\nminimization. However, in Predict-then-Optimize (PtO) frameworks, where\npredictions serve as inputs for downstream optimization tasks, model\nperformance is measured through decision regret minimization rather than\nprediction error minimization. In this work, we (i) show that traditional\ndataset distances, which rely solely on feature and label dimensions, lack\ninformativeness in the PtO context, and (ii) propose a new dataset distance\nthat incorporates the impacts of downstream decisions. Our results show that\nthis decision-aware dataset distance effectively captures adaptation success in\nPtO contexts, providing a PtO adaptation bound in terms of dataset distance.\nEmpirically, we show that our proposed distance measure accurately predicts\ntransferability across three different PtO tasks from the literature.",
      "tldr_zh": "本文探讨了在 Predict-then-Optimize (PtO) 任务中，数据集距离的适当定义问题，指出传统基于特征和标签的距离方法仅适用于预测错误最小化，而在 PtO 框架中需关注决策遗憾最小化。作者提出了一种新的决策感知数据集距离，该方法整合下游决策的影响，以更好地评估数据集相似性。研究结果显示，这种距离能有效捕捉 PtO 环境的适应成功，并提供了一个基于数据集距离的 PtO 适应边界。实证实验在三个 PtO 任务上验证了该距离在预测转移性方面的准确性。",
      "categories": [
        "cs.LG",
        "cs.AI"
      ],
      "primary_category": "cs.LG",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2409.06997v1",
      "published_date": "2024-09-11 04:13:17 UTC",
      "updated_date": "2024-09-11 04:13:17 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-19T23:13:23.389932"
    },
    {
      "arxiv_id": "2409.06978v1",
      "title": "Large Language Models and the Extended Church-Turing Thesis",
      "title_zh": "大语言模型与扩展的丘奇-图灵论题",
      "authors": [
        "Jiří Wiedermann",
        "Jan van Leeuwen"
      ],
      "abstract": "The Extended Church-Turing Thesis (ECTT) posits that all effective\ninformation processing, including unbounded and non-uniform interactive\ncomputations, can be described in terms of interactive Turing machines with\nadvice. Does this assertion also apply to the abilities of contemporary large\nlanguage models (LLMs)? From a broader perspective, this question calls for an\ninvestigation of the computational power of LLMs by the classical means of\ncomputability and computational complexity theory, especially the theory of\nautomata. Along these lines, we establish a number of fundamental results.\nFirstly, we argue that any fixed (non-adaptive) LLM is computationally\nequivalent to a, possibly very large, deterministic finite-state transducer.\nThis characterizes the base level of LLMs. We extend this to a key result\nconcerning the simulation of space-bounded Turing machines by LLMs. Secondly,\nwe show that lineages of evolving LLMs are computationally equivalent to\ninteractive Turing machines with advice. The latter finding confirms the\nvalidity of the ECTT for lineages of LLMs. From a computability viewpoint, it\nalso suggests that lineages of LLMs possess super-Turing computational power.\nConsequently, in our computational model knowledge generation is in general a\nnon-algorithmic process realized by lineages of LLMs. Finally, we discuss the\nmerits of our findings in the broader context of several related disciplines\nand philosophies.",
      "tldr_zh": "这篇论文探讨了大型语言模型 (LLMs) 与扩展丘奇-图灵论题 (ECTT) 的关系，ECTT 主张所有有效计算都可以用交互图灵机描述。研究通过计算复杂性理论和自动机理论证明，任何固定 (非自适应) 的 LLMs 计算等价于一个确定性有限状态转录器，并能模拟空间受限的图灵机。进一步发现，LLMs 的演化系列等价于带有建议的交互图灵机，这验证了 ECTT 的适用性，并表明这些系列具有超图灵计算能力，使知识生成成为非算法化过程。最后，论文讨论了这些结果在相关学科和哲学中的意义。",
      "categories": [
        "cs.FL",
        "cs.AI"
      ],
      "primary_category": "cs.FL",
      "comment": "In Proceedings NCMA 2024, arXiv:2409.06120",
      "pdf_url": "http://arxiv.org/pdf/2409.06978v1",
      "published_date": "2024-09-11 03:09:55 UTC",
      "updated_date": "2024-09-11 03:09:55 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-19T23:13:36.094916"
    },
    {
      "arxiv_id": "2409.06957v2",
      "title": "Policy Filtration in RLHF to Fine-Tune LLM for Code Generation",
      "title_zh": "翻译失败",
      "authors": [
        "Wei Shen",
        "Chuheng Zhang"
      ],
      "abstract": "Reinforcement learning from human feedback (RLHF) is one of the key\ntechniques that helps large language models (LLMs) to follow instructions and\nprovide helpful and harmless responses. While direct policy optimization\nmethods exist, state-of-the-art LLMs adopt RL-based methods (usually PPO) in\nRLHF to train the policy to generate good responses guided by a reward model\nlearned from preference data. The main challenge of these methods is the\ninaccuracy of the intermediate reward model, especially in code generation\ntasks that require long and complex reasoning to score a response. We find that\nthe reliability of the reward model varies across responses assigned with\ndifferent rewards. This motivates us to filter the samples whose rewards may be\nunreliable to improve signal-to-noise ratio during policy learning, resulting\nin Policy Filtration for Proximal Policy Optimization (PF-PPO). To choose a\nproper policy filtration strategy for a given reward model, the coefficient of\ndetermination ($R^2$) between rewards and actual scores on filtered samples\nserves as a good metrics and helps us find several promising strategies. We\nprovide extensive experiments to validate the effectiveness of PF-PPO in code\ngeneration tasks, and find that some variants of PF-PPO are highly effective\nand achieve new state-of-the-art performance across 7-billion-parameter models\non HumanEval, MBPP, and a new and more challenging LeetCode Contest benchmark.",
      "tldr_zh": "这篇论文针对强化学习从人类反馈（RLHF）在代码生成任务中奖励模型不准确的问题，提出了Policy Filtration for Proximal Policy Optimization (PF-PPO)方法，通过过滤不可靠的奖励样本来提高政策学习的信号噪声比。作者使用$R^2$系数作为指标来评估和选择合适的过滤策略，确保奖励的可靠性。实验结果显示，PF-PPO的某些变体在HumanEval、MBPP和LeetCode Contest基准上实现了新的state-of-the-art性能，尤其在7B参数的LLM模型中。",
      "categories": [
        "cs.LG",
        "cs.AI"
      ],
      "primary_category": "cs.LG",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2409.06957v2",
      "published_date": "2024-09-11 02:40:38 UTC",
      "updated_date": "2024-12-10 06:21:47 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-19T23:13:47.761943"
    },
    {
      "arxiv_id": "2409.06953v4",
      "title": "Neural Algorithmic Reasoning with Multiple Correct Solutions",
      "title_zh": "翻译失败",
      "authors": [
        "Zeno Kujawa",
        "John Poole",
        "Dobrik Georgiev",
        "Danilo Numeroso",
        "Henry Fleischmann",
        "Pietro Liò"
      ],
      "abstract": "Neural Algorithmic Reasoning (NAR) extends classical algorithms to higher\ndimensional data. However, canonical implementations of NAR train neural\nnetworks to return only a single solution, even when there are multiple correct\nsolutions to a problem, such as single-source shortest paths. For some\napplications, it is desirable to recover more than one correct solution. To\nthat end, we give the first method for NAR with multiple solutions. We\ndemonstrate our method on two classical algorithms: Bellman-Ford (BF) and\nDepth-First Search (DFS), favouring deeper insight into two algorithms over a\nbroader survey of algorithms. This method involves generating appropriate\ntraining data as well as sampling and validating solutions from model output.\nEach step of our method, which can serve as a framework for neural algorithmic\nreasoning beyond the tasks presented in this paper, might be of independent\ninterest to the field and our results represent the first attempt at this task\nin the NAR literature.",
      "tldr_zh": "该论文探讨了 Neural Algorithmic Reasoning (NAR)，一种将经典算法扩展到高维数据的框架，但传统 NAR 只训练模型返回单一解决方案，而忽略了某些问题（如单源最短路径）可能存在多个正确答案。研究提出首个支持多解决方案的 NAR 方法，包括生成适当的训练数据、从模型输出中采样和验证解决方案，并将其应用于 Bellman-Ford (BF) 和 Depth-First Search (DFS) 算法。实验结果显示，这一方法为 NAR 领域提供了新的框架，可能扩展到更多算法，并代表了该任务的首次尝试。",
      "categories": [
        "cs.LG",
        "cs.AI"
      ],
      "primary_category": "cs.LG",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2409.06953v4",
      "published_date": "2024-09-11 02:29:53 UTC",
      "updated_date": "2025-05-11 07:01:18 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-19T23:14:00.136057"
    },
    {
      "arxiv_id": "2409.06949v1",
      "title": "You Have Thirteen Hours in Which to Solve the Labyrinth: Enhancing AI Game Masters with Function Calling",
      "title_zh": "翻译失败",
      "authors": [
        "Jaewoo Song",
        "Andrew Zhu",
        "Chris Callison-Burch"
      ],
      "abstract": "Developing a consistent and reliable AI game master for text-based games is a\nchallenging task due to the limitations of large language models (LLMs) and the\ncomplexity of the game master's role. This paper presents a novel approach to\nenhance AI game masters by leveraging function calling in the context of the\ntable-top role-playing game \"Jim Henson's Labyrinth: The Adventure Game.\" Our\nmethodology involves integrating game-specific controls through functions,\nwhich we show improves the narrative quality and state update consistency of\nthe AI game master. The experimental results, based on human evaluations and\nunit tests, demonstrate the effectiveness of our approach in enhancing gameplay\nexperience and maintaining coherence with the game state. This work contributes\nto the advancement of game AI and interactive storytelling, offering insights\ninto the design of more engaging and consistent AI-driven game masters.",
      "tldr_zh": "这篇论文针对大型语言模型(LLMs)在文本-based games中开发一致可靠的AI游戏主控(AI game masters)的挑战，提出了一种新方法，通过函数调用(function calling)整合游戏特定控件。研究在桌游“Jim Henson's Labyrinth: The Adventure Game”中应用该方法，提升了叙事质量和游戏状态更新的连贯性。实验结果基于人类评估和单元测试，证明了该方法显著改善了游戏体验，并为游戏AI和互动叙事的设计提供了重要见解。",
      "categories": [
        "cs.CL",
        "cs.AI"
      ],
      "primary_category": "cs.CL",
      "comment": "Wordplay Workshop @ ACL 2024",
      "pdf_url": "http://arxiv.org/pdf/2409.06949v1",
      "published_date": "2024-09-11 02:03:51 UTC",
      "updated_date": "2024-09-11 02:03:51 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-19T23:14:12.074522"
    },
    {
      "arxiv_id": "2409.13745v1",
      "title": "Context-Aware Membership Inference Attacks against Pre-trained Large Language Models",
      "title_zh": "针对预训练大型语言模型的上下文感知成员推断攻击",
      "authors": [
        "Hongyan Chang",
        "Ali Shahin Shamsabadi",
        "Kleomenis Katevas",
        "Hamed Haddadi",
        "Reza Shokri"
      ],
      "abstract": "Prior Membership Inference Attacks (MIAs) on pre-trained Large Language\nModels (LLMs), adapted from classification model attacks, fail due to ignoring\nthe generative process of LLMs across token sequences. In this paper, we\npresent a novel attack that adapts MIA statistical tests to the perplexity\ndynamics of subsequences within a data point. Our method significantly\noutperforms prior loss-based approaches, revealing context-dependent\nmemorization patterns in pre-trained LLMs.",
      "tldr_zh": "本研究发现，传统的 Membership Inference Attacks (MIAs) 在预训练的大型语言模型 (LLMs) 上效果不佳，因为它们忽略了 LLMs 在 token 序列中的生成过程。论文提出了一种新颖的上下文感知攻击方法，将 MIA 的统计测试适应于数据点子序列的 perplexity 动态，从而显著提升攻击性能。实验结果显示，该方法优于现有的基于损失的方案，并揭示了预训练 LLMs 中上下文依赖的记忆模式。",
      "categories": [
        "cs.CL",
        "cs.AI",
        "cs.CR",
        "cs.LG",
        "stat.ML"
      ],
      "primary_category": "cs.CL",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2409.13745v1",
      "published_date": "2024-09-11 01:56:35 UTC",
      "updated_date": "2024-09-11 01:56:35 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-19T23:14:22.419113"
    },
    {
      "arxiv_id": "2409.06945v1",
      "title": "FSMDet: Vision-guided feature diffusion for fully sparse 3D detector",
      "title_zh": "翻译失败",
      "authors": [
        "Tianran Liu",
        "Morteza Mousa Pasandi",
        "Robert Laganiere"
      ],
      "abstract": "Fully sparse 3D detection has attracted an increasing interest in the recent\nyears. However, the sparsity of the features in these frameworks challenges the\ngeneration of proposals because of the limited diffusion process. In addition,\nthe quest for efficiency has led to only few work on vision-assisted fully\nsparse models. In this paper, we propose FSMDet (Fully Sparse Multi-modal\nDetection), which use visual information to guide the LiDAR feature diffusion\nprocess while still maintaining the efficiency of the pipeline. Specifically,\nmost of fully sparse works focus on complex customized center fusion\ndiffusion/regression operators. However, we observed that if the adequate\nobject completion is performed, even the simplest interpolation operator leads\nto satisfactory results. Inspired by this observation, we split the\nvision-guided diffusion process into two modules: a Shape Recover Layer\n(SRLayer) and a Self Diffusion Layer (SDLayer). The former uses RGB information\nto recover the shape of the visible part of an object, and the latter uses a\nvisual prior to further spread the features to the center region. Experiments\ndemonstrate that our approach successfully improves the performance of previous\nfully sparse models that use LiDAR only and reaches SOTA performance in\nmultimodal models. At the same time, thanks to the sparse architecture, our\nmethod can be up to 5 times more efficient than previous SOTA methods in the\ninference process.",
      "tldr_zh": "本研究提出 FSMDet，一种全稀疏 3D 检测框架，通过视觉信息指导 LiDAR 特征扩散，解决特征稀疏导致的提案生成挑战，同时保持高效处理。FSMDet 将扩散过程分为两个模块：Shape Recover Layer (SRLayer) 使用 RGB 信息恢复物体可见部分的形状，以及 Self Diffusion Layer (SDLayer) 利用视觉先验进一步扩散特征至中心区域。该方法显著提升了仅依赖 LiDAR 的全稀疏模型性能，达到 SOTA 多模态检测水平，并在推理效率上比之前 SOTA 方法高出 5 倍。",
      "categories": [
        "cs.CV",
        "cs.AI"
      ],
      "primary_category": "cs.CV",
      "comment": "Accepted by European Conference on Computer Vision (ECCV) 2024\n  workshop on VCAD",
      "pdf_url": "http://arxiv.org/pdf/2409.06945v1",
      "published_date": "2024-09-11 01:55:45 UTC",
      "updated_date": "2024-09-11 01:55:45 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-19T23:14:35.362010"
    },
    {
      "arxiv_id": "2409.06941v2",
      "title": "FreeRide: Harvesting Bubbles in Pipeline Parallelism",
      "title_zh": "翻译失败",
      "authors": [
        "Jiashu Zhang",
        "Zihan Pan",
        "Molly",
        "Xu",
        "Khuzaima Daudjee",
        "Sihang Liu"
      ],
      "abstract": "The occurrence of bubbles in pipeline parallelism is an inherent limitation\nthat can account for more than 40% of the large language model (LLM) training\ntime and is one of the main reasons for the underutilization of GPU resources\nin LLM training. Harvesting these bubbles for GPU side tasks can increase\nresource utilization and reduce training costs but comes with challenges.\nFirst, because bubbles are discontinuous with various shapes, programming side\ntasks becomes difficult while requiring excessive engineering effort. Second, a\nside task can compete with pipeline training for GPU resources and incur\nsignificant overhead. To address these challenges, we propose FreeRide, a\nsystem designed to harvest bubbles in pipeline parallelism for side tasks.\nFreeRide provides programmers with interfaces to implement side tasks easily,\nmanages bubbles and side tasks during pipeline training, and controls access to\nGPU resources by side tasks to reduce overhead. We demonstrate that FreeRide\nachieves 7.8% average cost savings with a negligible overhead of about 1% in\ntraining LLMs while serving model training, graph analytics, and image\nprocessing side tasks.",
      "tldr_zh": "该论文探讨了在 pipeline parallelism 中出现的 bubbles 问题，这些 bubbles 会导致 LLM 训练时间浪费超过 40%，并造成 GPU 资源利用率低下。作者提出 FreeRide 系统，通过提供简便的编程接口、管理 bubbles 和 side tasks，并控制 GPU 资源访问，来高效利用这些 bubbles 运行辅助任务，从而减少训练开销。实验结果表明，FreeRide 在 LLM 训练中实现了平均 7.8% 的成本节约，同时保持开销仅约 1%，并成功支持模型训练、图分析和图像处理等 side tasks。",
      "categories": [
        "cs.DC",
        "cs.AI"
      ],
      "primary_category": "cs.DC",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2409.06941v2",
      "published_date": "2024-09-11 01:46:49 UTC",
      "updated_date": "2025-04-27 05:25:56 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-19T23:14:47.766207"
    },
    {
      "arxiv_id": "2409.06928v1",
      "title": "Intrapartum Ultrasound Image Segmentation of Pubic Symphysis and Fetal Head Using Dual Student-Teacher Framework with CNN-ViT Collaborative Learning",
      "title_zh": "翻译失败",
      "authors": [
        "Jianmei Jiang",
        "Huijin Wang",
        "Jieyun Bai",
        "Shun Long",
        "Shuangping Chen",
        "Victor M. Campello",
        "Karim Lekadir"
      ],
      "abstract": "The segmentation of the pubic symphysis and fetal head (PSFH) constitutes a\npivotal step in monitoring labor progression and identifying potential delivery\ncomplications. Despite the advances in deep learning, the lack of annotated\nmedical images hinders the training of segmentation. Traditional\nsemi-supervised learning approaches primarily utilize a unified network model\nbased on Convolutional Neural Networks (CNNs) and apply consistency\nregularization to mitigate the reliance on extensive annotated data. However,\nthese methods often fall short in capturing the discriminative features of\nunlabeled data and in delineating the long-range dependencies inherent in the\nambiguous boundaries of PSFH within ultrasound images. To address these\nlimitations, we introduce a novel framework, the Dual-Student and Teacher\nCombining CNN and Transformer (DSTCT), which synergistically integrates the\ncapabilities of CNNs and Transformers. Our framework comprises a Vision\nTransformer (ViT) as the teacher and two student mod ls one ViT and one CNN.\nThis dual-student setup enables mutual supervision through the generation of\nboth hard and soft pseudo-labels, with the consistency in their predictions\nbeing refined by minimizing the classifier determinacy discrepancy. The teacher\nmodel further reinforces learning within this architecture through the\nimposition of consistency regularization constraints. To augment the\ngeneralization abilities of our approach, we employ a blend of data and model\nperturbation techniques. Comprehensive evaluations on the benchmark dataset of\nthe PSFH Segmentation Grand Challenge at MICCAI 2023 demonstrate our DSTCT\nframework outperformed ten contemporary semi-supervised segmentation methods.\nCode available at https://github.com/jjm1589/DSTCT.",
      "tldr_zh": "本研究针对产科超声图像中耻骨联合和胎头 (PSFH) 的分割问题，提出了一种新型框架 DSTCT，该框架通过 CNN 和 ViT 的协同学习，采用双学生-教师结构来缓解标注数据不足的挑战。\n在 DSTCT 中，ViT 作为教师模型，两个学生模型（一个 ViT 和一个 CNN）通过生成硬伪标签和软伪标签实现相互监督，并通过最小化分类器确定性差异以及一致性正则化来捕获未标注数据的判别特征和长距离依赖。\n此外，该框架还结合数据和模型扰动技术提升泛化能力，并在 MICCAI 2023 PSFH 分割挑战的基准数据集上，优于十种当代半监督分割方法。",
      "categories": [
        "cs.CV",
        "cs.AI"
      ],
      "primary_category": "cs.CV",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2409.06928v1",
      "published_date": "2024-09-11 00:57:31 UTC",
      "updated_date": "2024-09-11 00:57:31 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-19T23:15:01.708782"
    },
    {
      "arxiv_id": "2409.13744v2",
      "title": "A Simplified Retriever to Improve Accuracy of Phenotype Normalizations by Large Language Models",
      "title_zh": "翻译失败",
      "authors": [
        "Daniel B. Hier",
        "Thanh Son Do",
        "Tayo Obafemi-Ajayi"
      ],
      "abstract": "Large language models (LLMs) have shown improved accuracy in phenotype term\nnormalization tasks when augmented with retrievers that suggest candidate\nnormalizations based on term definitions. In this work, we introduce a\nsimplified retriever that enhances LLM accuracy by searching the Human\nPhenotype Ontology (HPO) for candidate matches using contextual word embeddings\nfrom BioBERT without the need for explicit term definitions. Testing this\nmethod on terms derived from the clinical synopses of Online Mendelian\nInheritance in Man (OMIM), we demonstrate that the normalization accuracy of a\nstate-of-the-art LLM increases from a baseline of 62.3% without augmentation to\n90.3% with retriever augmentation. This approach is potentially generalizable\nto other biomedical term normalization tasks and offers an efficient\nalternative to more complex retrieval methods.",
      "tldr_zh": "本文提出一个简化检索器，使用BioBERT的上下文词嵌入在Human Phenotype Ontology (HPO)中搜索候选匹配，从而提升Large Language Models (LLMs)在表型术语标准化任务的准确性，而无需显式的术语定义。测试结果显示，在从Online Mendelian Inheritance in Man (OMIM)临床概要衍生的术语上，LLMs的标准化准确率从基线的62.3%提高到90.3%。这种方法提供了一个高效的替代方案，并具有潜力推广到其他生物医学术语标准化任务。",
      "categories": [
        "cs.CL",
        "cs.AI",
        "cs.IR",
        "68",
        "I.2"
      ],
      "primary_category": "cs.CL",
      "comment": "Published by Frontiers in Digital Health",
      "pdf_url": "http://arxiv.org/pdf/2409.13744v2",
      "published_date": "2024-09-11 00:16:17 UTC",
      "updated_date": "2025-03-04 19:15:49 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-19T23:15:12.022949"
    },
    {
      "arxiv_id": "2409.07503v1",
      "title": "AdaPPA: Adaptive Position Pre-Fill Jailbreak Attack Approach Targeting LLMs",
      "title_zh": "翻译失败",
      "authors": [
        "Lijia Lv",
        "Weigang Zhang",
        "Xuehai Tang",
        "Jie Wen",
        "Feng Liu",
        "Jizhong Han",
        "Songlin Hu"
      ],
      "abstract": "Jailbreak vulnerabilities in Large Language Models (LLMs) refer to methods\nthat extract malicious content from the model by carefully crafting prompts or\nsuffixes, which has garnered significant attention from the research community.\nHowever, traditional attack methods, which primarily focus on the semantic\nlevel, are easily detected by the model. These methods overlook the difference\nin the model's alignment protection capabilities at different output stages. To\naddress this issue, we propose an adaptive position pre-fill jailbreak attack\napproach for executing jailbreak attacks on LLMs. Our method leverages the\nmodel's instruction-following capabilities to first output pre-filled safe\ncontent, then exploits its narrative-shifting abilities to generate harmful\ncontent. Extensive black-box experiments demonstrate our method can improve the\nattack success rate by 47% on the widely recognized secure model (Llama2)\ncompared to existing approaches. Our code can be found at:\nhttps://github.com/Yummy416/AdaPPA.",
      "tldr_zh": "该研究针对大型语言模型(LLMs)的越狱漏洞(jailbreak vulnerabilities)提出了一种自适应位置预填充攻击方法AdaPPA，以规避传统语义级攻击易被检测的问题。AdaPPA利用模型的指令遵循能力先输出安全的预填充内容，然后通过叙事切换能力生成有害内容，从而提升攻击效率。实验结果显示，在Llama2模型上，该方法比现有方法提高了47%的攻击成功率，为评估和强化LLMs的安全性提供了新见解。",
      "categories": [
        "cs.CR",
        "cs.AI",
        "cs.CL"
      ],
      "primary_category": "cs.CR",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2409.07503v1",
      "published_date": "2024-09-11 00:00:58 UTC",
      "updated_date": "2024-09-11 00:00:58 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-19T23:15:33.130098"
    }
  ],
  "raw_papers_fetched": true,
  "papers_count": 83,
  "processed_papers_count": 83,
  "failed_papers_count": 0,
  "summary_generated": true,
  "daily_data_saved": true,
  "last_update": "2025-05-19T23:15:54.851022"
}