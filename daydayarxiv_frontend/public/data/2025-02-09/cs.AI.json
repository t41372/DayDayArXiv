{
  "date": "2025-02-09",
  "category": "cs.AI",
  "summary": "欢迎来到 UTC 时间 2025-02-09 的 arXiv 中文 TLDR 快报！\n\n今天 arXiv 的论文主要聚焦于 AI 模型的安全性、优化和实际应用领域，包括大型语言模型（LLMs）的越狱攻击防范、混合专家模型的效率提升，以及 AI 在药物预测和农业中的创新。其中，令人印象深刻的是 Dorsa Sadigh 等知名学者在多代理强化学习方面的作品，以及 LLM 安全相关论文的潜在话题度，这些研究为 AI 伦理和应用提供了重要启示。\n\n下面，我挑选并简要讨论几篇关键论文，先从高话题度和影响力的入手，再快速掠过其他较为次要的。重点论文按主题归类，突出核心贡献。\n\n### LLM 安全与优化（高话题度）\n- **Jailbreaking to Jailbreak（越狱攻击用于进一步越狱）**  \n  作者包括 Jeremy Kritz 和 Dorsa Sadigh。这篇论文提出了一种 LLM 作为红队攻击者的方法，使用越狱模型（J2 攻击者）来评估和改进其他模型的安全性。主要贡献是通过在上下文学习中迭代优化攻击策略，实现高达 93% 的攻击成功率（ASR），揭示了 LLM 安全机制的潜在漏洞，并强调了越狱攻击作为一种被忽略的失败模式。该研究为 AI 安全政策提供了重要基础。\n\n- **Injecting Universal Jailbreak Backdoors into LLMs（在 LLM 中注入通用越狱后门）**  \n  作者：Zhuowei Chen 等。该论文引入 JailbreakEdit 方法，通过模型编辑技术在分钟内注入后门，实现高越狱成功率，同时保持生成质量。主要发现是，该方法能绕过安全对齐机制，提示需要更先进的防御策略。\n\n- **LM2: Large Memory Models（大型记忆模型）**  \n  作者：Jikun Kang 等。这篇论文扩展 Transformer 架构，添加辅助记忆模块，提升多步推理和长上下文处理能力。主要贡献是，LM2 在 BABILong 基准上超越基线模型 86.3%，并在 MMLU 上提高 5%，证明了显式记忆机制在提升模型泛化性方面的作用。\n\n### AI 在实际应用中的创新\n- **Training Language Models for Social Deduction with Multi-Agent Reinforcement Learning（使用多代理强化学习训练语言模型进行社会推理）**  \n  作者：Bidipta Sarkar 和 Dorsa Sadigh。该研究训练 LLM 在部分可观察环境中进行自然语言沟通和推理，主要发现是通过密集奖励信号实现无人类演示的讨论策略，显著提高游戏（如 Among Us 风格）的获胜率。该工作为 LLM 在多代理协作中的应用提供了新路径。\n\n- **LLMs for Drug-Drug Interaction Prediction（LLM 用于药物相互作用预测）**  \n  作者：Gabriele De Vito 等。该论文评估 LLM 在药物相互作用预测中的性能，主要贡献是微调后模型（如 Phi-3.5）在 DrugBank 数据集上达到 92.4% 的准确率，超越传统机器学习方法，突显 LLM 在制药领域的潜力。\n\n- **Multi-modal Data Fusion and Deep Ensemble Learning for Accurate Crop Yield Prediction（多模态数据融合和深度集成学习用于精确作物产量预测）**  \n  作者：Akshay Dagadu Yewle 等。该研究提出 RicEns-Net 模型，通过融合卫星数据和气象测量，实现作物产量的精确预测。主要发现是，模型在 EY 挑战数据集上将平均绝对误差（MAE）降低至 341 kg/Ha，超过现有方法，展示了 AI 在农业中的实际价值。\n\n### 其他论文快速掠过\n以下论文主题较分散或影响力较小，仅列出标题和核心要点：\n- **Benchmarking Prompt Sensitivity in Large Language Models（评估大型语言模型的提示敏感性）**  \n  贡献：引入 PromptSET 数据集，评估提示变异对 LLM 性能的影响，发现现有方法不足。\n- **Online Reward-Weighted Fine-Tuning of Flow Matching with Wasserstein Regularization（使用 Wasserstein 正则化的在线奖励加权流匹配微调）**  \n  贡献：提出 ORW-CFM-W2 方法，提升生成模型的奖励优化和多样性。\n- **Nearly Optimal Sample Complexity of Offline KL-Regularized Contextual Bandits under Single-Policy Concentrability（单策略集中度下离线 KL 正则化上下文 Bandits 的近似最优样本复杂度）**  \n  贡献：算法在单策略下实现 O(ε^{-1}) 样本复杂度，适用于强化学习。\n- **AutoAgent: A Fully-Automated and Zero-Code Framework for LLM Agents（全自动零代码 LLM 代理框架）**  \n  贡献：启用自然语言构建代理，提升 AI 助手泛化性。\n- **其余论文**（如 EEG 处理、图像生成、法律分析等），如 **Provably Overwhelming Transformer Models with Designed Inputs（使用设计输入证明 Transformer 模型的压倒性）** 和 **Speech to Speech Translation with Translatotron（使用 Translatotron 的语音到语音翻译）**，主要探讨特定技术细节，但未见重大突破，故从略。\n\n总之，今天的论文强调了 AI 安全和应用的双重主题，LLM 相关研究尤为突出。读者可关注安全领域的潜在风险和创新优化方法，以指导实际应用。更多细节请查阅 arXiv！",
  "papers": [
    {
      "arxiv_id": "2503.04756v1",
      "title": "Peeking Behind Closed Doors: Risks of LLM Evaluation by Private Data Curators",
      "title_zh": "翻译失败",
      "authors": [
        "Hritik Bansal",
        "Pratyush Maini"
      ],
      "abstract": "The rapid advancement in building large language models (LLMs) has\nintensified competition among big-tech companies and AI startups. In this\nregard, model evaluations are critical for product and investment-related\ndecision-making. While open evaluation sets like MMLU initially drove progress,\nconcerns around data contamination and data bias have constantly questioned\ntheir reliability. As a result, it has led to the rise of private data curators\nwho have begun conducting hidden evaluations with high-quality self-curated\ntest prompts and their own expert annotators. In this paper, we argue that\ndespite potential advantages in addressing contamination issues, private\nevaluations introduce inadvertent financial and evaluation risks. In\nparticular, the key concerns include the potential conflict of interest arising\nfrom private data curators' business relationships with their clients (leading\nLLM firms). In addition, we highlight that the subjective preferences of\nprivate expert annotators will lead to inherent evaluation bias towards the\nmodels trained with the private curators' data. Overall, this paper lays the\nfoundation for studying the risks of private evaluations that can lead to\nwide-ranging community discussions and policy changes.",
      "tldr_zh": "这篇论文探讨了大型语言模型(LLM)评估中私人数据策展人所带来的风险，随着公开评估集如MMLU面临数据污染和偏差问题，私人策展人开始使用自制测试提示和专家标注进行隐藏评估。尽管这可能缓解污染问题，但论文指出私人评估会引入财务和评估风险，包括策展人与LLM公司的利益冲突。论文强调，专家标注者的主观偏好可能导致评估偏差，偏向于使用私人数据训练的模型。总体上，这为研究私人评估风险提供了基础，可能引发社区讨论和政策变革。",
      "categories": [
        "cs.CY",
        "cs.AI",
        "cs.CL",
        "cs.LG"
      ],
      "primary_category": "cs.CY",
      "comment": "Published as a blogpost at ICLR 2025. Originally posted at\n  https://pratyushmaini.github.io/blog/2024/risks-private-evals/",
      "pdf_url": "http://arxiv.org/pdf/2503.04756v1",
      "published_date": "2025-02-09 23:57:33 UTC",
      "updated_date": "2025-02-09 23:57:33 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-22T09:00:12.814741"
    },
    {
      "arxiv_id": "2502.06065v1",
      "title": "Benchmarking Prompt Sensitivity in Large Language Models",
      "title_zh": "大型语言模型的提示敏感性基准测试",
      "authors": [
        "Amirhossein Razavi",
        "Mina Soltangheis",
        "Negar Arabzadeh",
        "Sara Salamat",
        "Morteza Zihayat",
        "Ebrahim Bagheri"
      ],
      "abstract": "Large language Models (LLMs) are highly sensitive to variations in prompt\nformulation, which can significantly impact their ability to generate accurate\nresponses. In this paper, we introduce a new task, Prompt Sensitivity\nPrediction, and a dataset PromptSET designed to investigate the effects of\nslight prompt variations on LLM performance. Using TriviaQA and HotpotQA\ndatasets as the foundation of our work, we generate prompt variations and\nevaluate their effectiveness across multiple LLMs. We benchmark the prompt\nsensitivity prediction task employing state-of-the-art methods from related\ntasks, including LLM-based self-evaluation, text classification, and query\nperformance prediction techniques. Our findings reveal that existing methods\nstruggle to effectively address prompt sensitivity prediction, underscoring the\nneed to understand how information needs should be phrased for accurate LLM\nresponses.",
      "tldr_zh": "本研究探讨了Large Language Models (LLMs) 对提示表述变化的敏感性，引入了Prompt Sensitivity Prediction任务和PromptSET数据集，以评估微小提示变异对LLM性能的影响。研究基于TriviaQA和HotpotQA数据集生成提示变体，并使用LLM-based self-evaluation、text classification和query performance prediction等现有方法进行基准测试。结果显示，这些方法在预测提示敏感性方面表现欠佳，强调了正确表述信息需求的重要性，以提升LLM的准确响应。",
      "categories": [
        "cs.CL",
        "cs.AI",
        "cs.IR"
      ],
      "primary_category": "cs.CL",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2502.06065v1",
      "published_date": "2025-02-09 23:01:03 UTC",
      "updated_date": "2025-02-09 23:01:03 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-22T09:00:23.771037"
    },
    {
      "arxiv_id": "2502.06062v1",
      "title": "Multi-modal Data Fusion and Deep Ensemble Learning for Accurate Crop Yield Prediction",
      "title_zh": "多模态数据融合和深度集成学习用于准确的作物产量预测",
      "authors": [
        "Akshay Dagadu Yewle",
        "Laman Mirzayeva",
        "Oktay Karakuş"
      ],
      "abstract": "This study introduces RicEns-Net, a novel Deep Ensemble model designed to\npredict crop yields by integrating diverse data sources through multimodal data\nfusion techniques. The research focuses specifically on the use of synthetic\naperture radar (SAR), optical remote sensing data from Sentinel 1, 2, and 3\nsatellites, and meteorological measurements such as surface temperature and\nrainfall. The initial field data for the study were acquired through Ernst &\nYoung's (EY) Open Science Challenge 2023. The primary objective is to enhance\nthe precision of crop yield prediction by developing a machine-learning\nframework capable of handling complex environmental data. A comprehensive data\nengineering process was employed to select the most informative features from\nover 100 potential predictors, reducing the set to 15 features from 5 distinct\nmodalities. This step mitigates the ``curse of dimensionality\" and enhances\nmodel performance. The RicEns-Net architecture combines multiple machine\nlearning algorithms in a deep ensemble framework, integrating the strengths of\neach technique to improve predictive accuracy. Experimental results demonstrate\nthat RicEns-Net achieves a mean absolute error (MAE) of 341 kg/Ha (roughly\ncorresponds to 5-6\\% of the lowest average yield in the region), significantly\nexceeding the performance of previous state-of-the-art models, including those\ndeveloped during the EY challenge.",
      "tldr_zh": "本研究提出RicEns-Net，一种新型Deep Ensemble模型，通过多模态数据融合技术整合SAR、光学遥感数据（来自Sentinel 1、2和3卫星）以及气象测量（如地表温度和降雨），以精确预测作物产量。研究利用EY Open Science Challenge 2023的数据，进行全面数据工程，从100多个潜在预测因子中筛选出15个关键特征，缓解“curse of dimensionality”问题，从而提升模型性能。RicEns-Net架构结合多种机器学习算法的深度集成框架，充分利用各算法优势来处理复杂环境数据。实验结果显示，该模型的MAE为341 kg/Ha（约占最低平均产量的5-6%），显著优于现有最先进模型。",
      "categories": [
        "eess.IV",
        "cs.AI"
      ],
      "primary_category": "eess.IV",
      "comment": "28 pages, 7 figures and 5 tables",
      "pdf_url": "http://arxiv.org/pdf/2502.06062v1",
      "published_date": "2025-02-09 22:48:27 UTC",
      "updated_date": "2025-02-09 22:48:27 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-22T09:00:38.111789"
    },
    {
      "arxiv_id": "2502.06061v1",
      "title": "Online Reward-Weighted Fine-Tuning of Flow Matching with Wasserstein Regularization",
      "title_zh": "在线奖励加权微调的流匹配配",
      "authors": [
        "Jiajun Fan",
        "Shuaike Shen",
        "Chaoran Cheng",
        "Yuxin Chen",
        "Chumeng Liang",
        "Ge Liu"
      ],
      "abstract": "Recent advancements in reinforcement learning (RL) have achieved great\nsuccess in fine-tuning diffusion-based generative models. However, fine-tuning\ncontinuous flow-based generative models to align with arbitrary user-defined\nreward functions remains challenging, particularly due to issues such as policy\ncollapse from overoptimization and the prohibitively high computational cost of\nlikelihoods in continuous-time flows. In this paper, we propose an easy-to-use\nand theoretically sound RL fine-tuning method, which we term Online\nReward-Weighted Conditional Flow Matching with Wasserstein-2 Regularization\n(ORW-CFM-W2). Our method integrates RL into the flow matching framework to\nfine-tune generative models with arbitrary reward functions, without relying on\ngradients of rewards or filtered datasets. By introducing an online\nreward-weighting mechanism, our approach guides the model to prioritize\nhigh-reward regions in the data manifold. To prevent policy collapse and\nmaintain diversity, we incorporate Wasserstein-2 (W2) distance regularization\ninto our method and derive a tractable upper bound for it in flow matching,\neffectively balancing exploration and exploitation of policy optimization. We\nprovide theoretical analyses to demonstrate the convergence properties and\ninduced data distributions of our method, establishing connections with\ntraditional RL algorithms featuring Kullback-Leibler (KL) regularization and\noffering a more comprehensive understanding of the underlying mechanisms and\nlearning behavior of our approach. Extensive experiments on tasks including\ntarget image generation, image compression, and text-image alignment\ndemonstrate the effectiveness of our method, where our method achieves optimal\npolicy convergence while allowing controllable trade-offs between reward\nmaximization and diversity preservation.",
      "tldr_zh": "该研究提出了一种名为 Online Reward-Weighted Conditional Flow Matching with Wasserstein-2 Regularization (ORW-CFM-W2) 的方法，用于强化学习 (RL) 微调连续流-based 生成模型，以对齐任意用户定义的奖励函数。ORW-CFM-W2 通过在线奖励加权机制引导模型优先高奖励区域，同时引入 Wasserstein-2 (W2) 距离正则化来防止政策崩溃并保持数据多样性，并推导了其在流匹配框架中的可计算上界。理论分析证明了方法的收敛性和数据分布特性，与传统 RL 算法的 Kullback-Leibler (KL) 正则化建立了联系。实验在图像生成、图像压缩和文本-图像对齐任务上验证了其有效性，实现了最优策略收敛并实现了奖励最大化与多样性保留的可控权衡。",
      "categories": [
        "cs.LG",
        "cs.AI",
        "cs.CV",
        "stat.ML"
      ],
      "primary_category": "cs.LG",
      "comment": "61 pages",
      "pdf_url": "http://arxiv.org/pdf/2502.06061v1",
      "published_date": "2025-02-09 22:45:15 UTC",
      "updated_date": "2025-02-09 22:45:15 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-22T09:00:50.961563"
    },
    {
      "arxiv_id": "2502.06060v1",
      "title": "Training Language Models for Social Deduction with Multi-Agent Reinforcement Learning",
      "title_zh": "使用多智能体强化学习训练语言模型用于社会演绎",
      "authors": [
        "Bidipta Sarkar",
        "Warren Xia",
        "C. Karen Liu",
        "Dorsa Sadigh"
      ],
      "abstract": "Communicating in natural language is a powerful tool in multi-agent settings,\nas it enables independent agents to share information in partially observable\nsettings and allows zero-shot coordination with humans. However, most prior\nworks are limited as they either rely on training with large amounts of human\ndemonstrations or lack the ability to generate natural and useful communication\nstrategies. In this work, we train language models to have productive\ndiscussions about their environment in natural language without any human\ndemonstrations. We decompose the communication problem into listening and\nspeaking. Our key idea is to leverage the agent's goal to predict useful\ninformation about the world as a dense reward signal that guides communication.\nSpecifically, we improve a model's listening skills by training them to predict\ninformation about the environment based on discussions, and we simultaneously\nimprove a model's speaking skills with multi-agent reinforcement learning by\nrewarding messages based on their influence on other agents. To investigate the\nrole and necessity of communication in complex social settings, we study an\nembodied social deduction game based on Among Us, where the key question to\nanswer is the identity of an adversarial imposter. We analyze emergent\nbehaviors due to our technique, such as accusing suspects and providing\nevidence, and find that it enables strong discussions, doubling the win rates\ncompared to standard RL. We release our code and models at\nhttps://socialdeductionllm.github.io/",
      "tldr_zh": "本研究提出了一种不依赖人类演示的方法，使用多智能体强化学习（multi-agent reinforcement learning）训练语言模型，在部分可观察环境中进行有效的自然语言通信，以实现信息共享和zero-shot coordination。方法将通信问题分解为“倾听”和“说话”两个部分，通过代理目标预测作为密集奖励信号来提升倾听技能（基于讨论预测环境信息），并利用强化学习奖励消息对其他代理的影响来改进说话技能。实验基于一个类似于Among Us的社会推演游戏，展示了模型产生的紧急行为，如指控嫌疑人和提供证据，最终将获胜率提高一倍。总的来说，该方法为复杂社会设置中的自主通信提供了新途径，并开源了代码和模型。",
      "categories": [
        "cs.AI",
        "cs.CL",
        "cs.LG",
        "cs.MA"
      ],
      "primary_category": "cs.AI",
      "comment": "14 pages, 5 figures, 24th International Conference on Autonomous\n  Agents and Multiagent Systems (AAMAS 2025)",
      "pdf_url": "http://arxiv.org/pdf/2502.06060v1",
      "published_date": "2025-02-09 22:44:45 UTC",
      "updated_date": "2025-02-09 22:44:45 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-22T09:01:01.455771"
    },
    {
      "arxiv_id": "2502.06051v1",
      "title": "Nearly Optimal Sample Complexity of Offline KL-Regularized Contextual Bandits under Single-Policy Concentrability",
      "title_zh": "在单策略集中性条件下，离线 KL 正则化上下文博弈臂的近似最优样本复杂度",
      "authors": [
        "Qingyue Zhao",
        "Kaixuan Ji",
        "Heyang Zhao",
        "Tong Zhang",
        "Quanquan Gu"
      ],
      "abstract": "KL-regularized policy optimization has become a workhorse in learning-based\ndecision making, while its theoretical understanding is still very limited.\nAlthough recent progress has been made towards settling the sample complexity\nof KL-regularized contextual bandits, existing sample complexity bounds are\neither $\\tilde{O}(\\epsilon^{-2})$ under single-policy concentrability or\n$\\tilde{O}(\\epsilon^{-1})$ under all-policy concentrability. In this paper, we\npropose the \\emph{first} algorithm with $\\tilde{O}(\\epsilon^{-1})$ sample\ncomplexity under single-policy concentrability for offline contextual bandits.\nOur algorithm is designed for general function approximation and based on the\nprinciple of \\emph{pessimism in the face of uncertainty}. The core of our proof\nleverages the strong convexity of the KL regularization, and the conditional\nnon-negativity of the gap between the true reward and its pessimistic estimator\nto refine a mean-value-type risk upper bound to its extreme. This in turn leads\nto a novel covariance-based analysis, effectively bypassing the need for\nuniform control over the discrepancy between any two functions in the function\nclass. The near-optimality of our algorithm is demonstrated by an\n$\\tilde{\\Omega}(\\epsilon^{-1})$ lower bound. Furthermore, we extend our\nalgorithm to contextual dueling bandits and achieve a similar nearly optimal\nsample complexity.",
      "tldr_zh": "本文提出了一种在 single-policy concentrability 下，针对离线 KL-regularized contextual bandits 的算法，首次实现了近似最优的 \\(\\tilde{O}(\\epsilon^{-1})\\) 样本复杂度，显著优于现有 \\(\\tilde{O}(\\epsilon^{-2})\\) 的界限。该算法基于一般函数逼近和 pessimism in the face of uncertainty 原则，利用 KL 正则化的强凸性及差距的条件非负性，精炼风险上界并采用协方差-based 分析，避免了对函数类中函数差异的统一控制。通过理论下界 \\(\\tilde{\\Omega}(\\epsilon^{-1})\\) 证明了算法的近优性，并成功扩展到 contextual dueling bandits 中，实现了类似样本复杂度。",
      "categories": [
        "cs.LG",
        "cs.AI",
        "math.ST",
        "stat.ML",
        "stat.TH"
      ],
      "primary_category": "cs.LG",
      "comment": "23 pages",
      "pdf_url": "http://arxiv.org/pdf/2502.06051v1",
      "published_date": "2025-02-09 22:14:45 UTC",
      "updated_date": "2025-02-09 22:14:45 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-22T09:01:14.733783"
    },
    {
      "arxiv_id": "2502.06049v1",
      "title": "LM2: Large Memory Models",
      "title_zh": "LM2：大型记忆模型",
      "authors": [
        "Jikun Kang",
        "Wenqi Wu",
        "Filippos Christianos",
        "Alex J. Chan",
        "Fraser Greenlee",
        "George Thomas",
        "Marvin Purtorab",
        "Andy Toulis"
      ],
      "abstract": "This paper introduces the Large Memory Model (LM2), a decoder-only\nTransformer architecture enhanced with an auxiliary memory module that aims to\naddress the limitations of standard Transformers in multi-step reasoning,\nrelational argumentation, and synthesizing information distributed over long\ncontexts. The proposed LM2 incorporates a memory module that acts as a\ncontextual representation repository, interacting with input tokens via cross\nattention and updating through gating mechanisms. To preserve the Transformers\ngeneral-purpose capabilities, LM2 maintains the original information flow while\nintegrating a complementary memory pathway. Experimental results on the\nBABILong benchmark demonstrate that the LM2model outperforms both the\nmemory-augmented RMT model by 37.1% and the baseline Llama-3.2 model by 86.3%\non average across tasks. LM2 exhibits exceptional capabilities in multi-hop\ninference, numerical reasoning, and large-context question-answering. On the\nMMLU dataset, it achieves a 5.0% improvement over a pre-trained vanilla model,\ndemonstrating that its memory module does not degrade performance on general\ntasks. Further, in our analysis, we explore the memory interpretability,\neffectiveness of memory modules, and test-time behavior. Our findings emphasize\nthe importance of explicit memory in enhancing Transformer architectures.",
      "tldr_zh": "本论文引入了 Large Memory Model (LM2)，一种在解码器-only Transformer 架构中添加辅助内存模块的模型，旨在解决标准 Transformer 在多步推理、关系论证和长上下文信息合成方面的局限性。LM2 的内存模块作为上下文表示存储库，通过交叉注意力与输入标记交互，并利用门控机制进行更新，同时保持原有的信息流以保留 Transformer 的通用能力。在实验中，LM2 在 BABILong 基准上比 memory-augmented RMT 模型高出 37.1%、比 Llama-3.2 基线高出 86.3%，并在多跳推理、数值推理和大型上下文问答中表现出色；在 MMLU 数据集上实现了 5.0% 的改进，证明了显式内存模块的有效性和可解释性。",
      "categories": [
        "cs.CL",
        "cs.AI"
      ],
      "primary_category": "cs.CL",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2502.06049v1",
      "published_date": "2025-02-09 22:11:42 UTC",
      "updated_date": "2025-02-09 22:11:42 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-22T09:01:26.799335"
    },
    {
      "arxiv_id": "2502.06039v1",
      "title": "Benchmarking Prompt Engineering Techniques for Secure Code Generation with GPT Models",
      "title_zh": "针对使用 GPT 模型的安全代码生成的提示工程技术基准测试",
      "authors": [
        "Marc Bruni",
        "Fabio Gabrielli",
        "Mohammad Ghafari",
        "Martin Kropp"
      ],
      "abstract": "Prompt engineering reduces reasoning mistakes in Large Language Models\n(LLMs). However, its effectiveness in mitigating vulnerabilities in\nLLM-generated code remains underexplored. To address this gap, we implemented a\nbenchmark to automatically assess the impact of various prompt engineering\nstrategies on code security. Our benchmark leverages two peer-reviewed prompt\ndatasets and employs static scanners to evaluate code security at scale. We\ntested multiple prompt engineering techniques on GPT-3.5-turbo, GPT-4o, and\nGPT-4o-mini. Our results show that for GPT-4o and GPT-4o-mini, a\nsecurity-focused prompt prefix can reduce the occurrence of security\nvulnerabilities by up to 56%. Additionally, all tested models demonstrated the\nability to detect and repair between 41.9% and 68.7% of vulnerabilities in\npreviously generated code when using iterative prompting techniques. Finally,\nwe introduce a \"prompt agent\" that demonstrates how the most effective\ntechniques can be applied in real-world development workflows.",
      "tldr_zh": "本研究评估了提示工程（Prompt engineering）技术在减少GPT模型生成代码漏洞方面的效果，填补了相关领域的空白。研究者开发了一个基准测试，使用两个同行评审的提示数据集和静态扫描器（static scanners）对GPT-3.5-turbo、GPT-4o和GPT-4o-mini进行大规模评估。结果显示，安全焦点提示前缀可将漏洞减少多达56%，而迭代提示技术（iterative prompting）使所有模型能够检测和修复41.9%至68.7%的现有漏洞；此外，论文引入了“prompt agent”框架，以将这些有效技术整合到实际开发工作流中。",
      "categories": [
        "cs.SE",
        "cs.AI",
        "cs.CR"
      ],
      "primary_category": "cs.SE",
      "comment": "Accepted at the 2025 IEEE/ACM Second International Conference on AI\n  Foundation Models and Software Engineering (Forge 2025). 10 pages, 7 figures,\n  5 tables",
      "pdf_url": "http://arxiv.org/pdf/2502.06039v1",
      "published_date": "2025-02-09 21:23:07 UTC",
      "updated_date": "2025-02-09 21:23:07 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-22T09:01:37.445792"
    },
    {
      "arxiv_id": "2502.06038v1",
      "title": "Provably Overwhelming Transformer Models with Designed Inputs",
      "title_zh": "翻译失败",
      "authors": [
        "Lev Stambler",
        "Seyed Sajjad Nezhadi",
        "Matthew Coudron"
      ],
      "abstract": "We develop an algorithm which, given a trained transformer model\n$\\mathcal{M}$ as input, as well as a string of tokens $s$ of length $n_{fix}$\nand an integer $n_{free}$, can generate a mathematical proof that $\\mathcal{M}$\nis ``overwhelmed'' by $s$, in time and space $\\widetilde{O}(n_{fix}^2 +\nn_{free}^3)$. We say that $\\mathcal{M}$ is ``overwhelmed'' by $s$ when the\noutput of the model evaluated on this string plus any additional string $t$,\n$\\mathcal{M}(s + t)$, is completely insensitive to the value of the string $t$\nwhenever length($t$) $\\leq n_{free}$. Along the way, we prove a particularly\nstrong worst-case form of ``over-squashing'', which we use to bound the model's\nbehavior. Our technique uses computer-aided proofs to establish this type of\noperationally relevant guarantee about transformer models. We empirically test\nour algorithm on a single layer transformer complete with an attention head,\nlayer-norm, MLP/ReLU layers, and RoPE positional encoding. We believe that this\nwork is a stepping stone towards the difficult task of obtaining useful\nguarantees for trained transformer models.",
      "tldr_zh": "本研究提出了一种算法，能够针对训练好的Transformer模型，给定一个长度为$n_{fix}$的字符串$s$和整数$n_{free}$，在时间和空间复杂度$\\widetilde{O}(n_{fix}^2 + n_{free}^3)$内生成数学证明，证明模型对$s$是“overwhelmed”的，即模型输出$\\mathcal{M}(s + t)$对长度不超过$n_{free}$的任何字符串$t$完全不敏感。算法依赖于证明一种强形式的“over-squashing”现象来限制模型行为，并采用计算机辅助证明技术实现。实验在包含注意力头、层归一化、MLP/ReLU层和RoPE位置编码的单层Transformer上验证了算法的有效性，为获得Transformer模型的可信保证提供了重要基础。",
      "categories": [
        "cs.LG",
        "cs.AI",
        "cs.CC"
      ],
      "primary_category": "cs.LG",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2502.06038v1",
      "published_date": "2025-02-09 21:21:57 UTC",
      "updated_date": "2025-02-09 21:21:57 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-22T09:01:49.428313"
    },
    {
      "arxiv_id": "2502.09638v1",
      "title": "Jailbreaking to Jailbreak",
      "title_zh": "翻译失败",
      "authors": [
        "Jeremy Kritz",
        "Vaughn Robinson",
        "Robert Vacareanu",
        "Bijan Varjavand",
        "Michael Choi",
        "Bobby Gogov",
        "Scale Red Team",
        "Summer Yue",
        "Willow E. Primack",
        "Zifan Wang"
      ],
      "abstract": "Refusal training on Large Language Models (LLMs) prevents harmful outputs,\nyet this defense remains vulnerable to both automated and human-crafted\njailbreaks. We present a novel LLM-as-red-teamer approach in which a human\njailbreaks a refusal-trained LLM to make it willing to jailbreak itself or\nother LLMs. We refer to the jailbroken LLMs as $J_2$ attackers, which can\nsystematically evaluate target models using various red teaming strategies and\nimprove its performance via in-context learning from the previous failures. Our\nexperiments demonstrate that Sonnet 3.5 and Gemini 1.5 pro outperform other\nLLMs as $J_2$, achieving 93.0% and 91.0% attack success rates (ASRs)\nrespectively against GPT-4o (and similar results across other capable LLMs) on\nHarmbench. Our work not only introduces a scalable approach to strategic red\nteaming, drawing inspiration from human red teamers, but also highlights\njailbreaking-to-jailbreak as an overlooked failure mode of the safeguard.\nSpecifically, an LLM can bypass its own safeguards by employing a jailbroken\nversion of itself that is willing to assist in further jailbreaking. To prevent\nany direct misuse with $J_2$, while advancing research in AI safety, we\npublicly share our methodology while keeping specific prompting details\nprivate.",
      "tldr_zh": "该研究提出了一种名为“Jailbreaking to Jailbreak”的方法，利用人类对已接受拒绝训练(Large Language Models, LLMs)的越狱(jailbreaks)，使其转变为 $J_2$ attackers，这些攻击者能系统地评估目标模型并通过 in-context learning 从失败中改进。实验显示，Sonnet 3.5 和 Gemini 1.5 pro 作为 $J_2$ attackers，对 GPT-4o 在 Harmbench 上的攻击成功率(ASRs)分别达到93.0%和91.0%，远超其他模型。这种方法模仿人类红队者(red teaming strategies)的策略，揭示了LLM安全机制的一个被忽略失败模式，即模型可使用其越狱版本绕过自身防护。为推进AI安全研究，同时防止误用，论文公开了方法论细节但隐藏了具体提示。",
      "categories": [
        "cs.CL",
        "cs.AI"
      ],
      "primary_category": "cs.CL",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2502.09638v1",
      "published_date": "2025-02-09 20:49:16 UTC",
      "updated_date": "2025-02-09 20:49:16 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-22T09:02:01.744902"
    },
    {
      "arxiv_id": "2502.06018v1",
      "title": "Kolmogorov-Arnold Fourier Networks",
      "title_zh": "翻译失败",
      "authors": [
        "Jusheng Zhang",
        "Yijia Fan",
        "Kaitong Cai",
        "Keze Wang"
      ],
      "abstract": "Although Kolmogorov-Arnold based interpretable networks (KAN) have strong\ntheoretical expressiveness, they face significant parameter explosion and\nhigh-frequency feature capture challenges in high-dimensional tasks. To address\nthis issue, we propose the Kolmogorov-Arnold-Fourier Network (KAF), which\neffectively integrates trainable Random Fourier Features (RFF) and a novel\nhybrid GELU-Fourier activation mechanism to balance parameter efficiency and\nspectral representation capabilities. Our key technical contributions include:\n(1) merging KAN's dual-matrix structure through matrix association properties\nto substantially reduce parameters; (2) introducing learnable RFF\ninitialization strategies to eliminate spectral distortion in high-dimensional\napproximation tasks; (3) implementing an adaptive hybrid activation function\nthat progressively enhances frequency representation during the training\nprocess. Comprehensive experiments demonstrate the superiority of our KAF\nacross various domains including vision, NLP, audio processing, and\ndifferential equation-solving tasks, effectively combining theoretical\ninterpretability with practical utility and computational efficiency.",
      "tldr_zh": "本文提出 Kolmogorov-Arnold-Fourier Network (KAF)，通过整合 trainable Random Fourier Features (RFF) 和新型 hybrid GELU-Fourier 激活机制，解决了 Kolmogorov-Arnold based networks (KAN) 在高维任务中参数爆炸和高频特征捕获的挑战。关键贡献包括：通过矩阵关联属性合并 KAN 的双矩阵结构以显著减少参数；引入可学习的 RFF 初始化策略消除高维逼近任务中的频谱失真；以及实现自适应混合激活函数，在训练过程中逐步增强频率表示。实验结果显示，KAF 在视觉、NLP、音频处理和微分方程求解等领域表现出优越性，实现了理论可解释性与实际计算效率的平衡。",
      "categories": [
        "cs.LG",
        "cs.AI"
      ],
      "primary_category": "cs.LG",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2502.06018v1",
      "published_date": "2025-02-09 20:21:43 UTC",
      "updated_date": "2025-02-09 20:21:43 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-22T09:02:14.973538"
    },
    {
      "arxiv_id": "2502.06902v1",
      "title": "Emergence of Episodic Memory in Transformers: Characterizing Changes in Temporal Structure of Attention Scores During Training",
      "title_zh": "翻译失败",
      "authors": [
        "Deven Mahesh Mistry",
        "Anooshka Bajaj",
        "Yash Aggarwal",
        "Sahaj Singh Maini",
        "Zoran Tiganj"
      ],
      "abstract": "We investigate in-context temporal biases in attention heads and transformer\noutputs. Using cognitive science methodologies, we analyze attention scores and\noutputs of the GPT-2 models of varying sizes. Across attention heads, we\nobserve effects characteristic of human episodic memory, including temporal\ncontiguity, primacy and recency. Transformer outputs demonstrate a tendency\ntoward in-context serial recall. Importantly, this effect is eliminated after\nthe ablation of the induction heads, which are the driving force behind the\ncontiguity effect. Our findings offer insights into how transformers organize\ninformation temporally during in-context learning, shedding light on their\nsimilarities and differences with human memory and learning.",
      "tldr_zh": "本研究调查了 Transformer 模型（如 GPT-2）中注意力 heads 的 in-context 时间偏置，使用认知科学方法分析不同大小模型的注意力分数和输出。结果显示，注意力 heads 表现出类似于人类 episodic memory 的特征，包括 temporal contiguity、primacy 和 recency 效应，而 Transformer 输出则倾向于 in-context serial recall。关键发现是，消融 induction heads 后，这些效果被消除，揭示了 induction heads 在驱动 contiguity 效应中的作用，并为理解 Transformer 与人类记忆和学习在时间组织方面的异同提供了洞见。",
      "categories": [
        "cs.LG",
        "cs.AI",
        "cs.CL"
      ],
      "primary_category": "cs.LG",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2502.06902v1",
      "published_date": "2025-02-09 20:20:37 UTC",
      "updated_date": "2025-02-09 20:20:37 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-22T09:02:25.608573"
    },
    {
      "arxiv_id": "2502.06901v1",
      "title": "Enabling Autoregressive Models to Fill In Masked Tokens",
      "title_zh": "翻译失败",
      "authors": [
        "Daniel Israel",
        "Aditya Grover",
        "Guy Van den Broeck"
      ],
      "abstract": "Historically, LLMs have been trained using either autoregressive (AR) or\nmasked language modeling (MLM) objectives, with AR models gaining dominance in\nrecent years. However, AR models are inherently incapable of masked infilling,\nwhich is the ability to predict masked tokens between past and future context.\nIn contrast, MLM models suffer from intrinsic computational inefficiencies\nduring both training and inference that hinder their scalability. This work\nintroduces MARIA (Masked and Autoregressive Infilling Architecture), a novel\napproach that leverages the strengths of both paradigms to achieve\nstate-of-the-art masked infilling performance. MARIA combines a pre-trained MLM\nand AR model by training a linear decoder that takes their concatenated hidden\nstates as input. This minimal modification enables the AR model to perform\ninfilling while retaining its inherent advantages in terms of faster inference\nwith KV caching. Our results demonstrate that MARIA significantly outperforms\nexisting methods, namely discrete diffusion models, on masked infilling tasks.",
      "tldr_zh": "该论文解决了 autoregressive (AR) 模型无法进行 masked infilling 的局限性，提出了一种新型框架 MARIA（Masked and Autoregressive Infilling Architecture）。MARIA 通过训练一个线性解码器，将预训练的 masked language modeling (MLM) 模型和 AR 模型的隐藏状态连接起来，实现高效的 masked infilling，同时保留 AR 模型的推理优势，如 KV caching 带来的快速处理。实验结果表明，MARIA 在 masked infilling 任务上显著优于现有方法，例如 discrete diffusion models。",
      "categories": [
        "cs.LG",
        "cs.AI",
        "cs.CL"
      ],
      "primary_category": "cs.LG",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2502.06901v1",
      "published_date": "2025-02-09 20:02:05 UTC",
      "updated_date": "2025-02-09 20:02:05 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-22T09:02:37.870791"
    },
    {
      "arxiv_id": "2502.06004v1",
      "title": "Analysis of LLM as a grammatical feature tagger for African American English",
      "title_zh": "翻译失败",
      "authors": [
        "Rahul Porwal",
        "Alice Rozet",
        "Pryce Houck",
        "Jotsna Gowda",
        "Sarah Moeller",
        "Kevin Tang"
      ],
      "abstract": "African American English (AAE) presents unique challenges in natural language\nprocessing (NLP). This research systematically compares the performance of\navailable NLP models--rule-based, transformer-based, and large language models\n(LLMs)--capable of identifying key grammatical features of AAE, namely Habitual\nBe and Multiple Negation. These features were selected for their distinct\ngrammatical complexity and frequency of occurrence. The evaluation involved\nsentence-level binary classification tasks, using both zero-shot and few-shot\nstrategies. The analysis reveals that while LLMs show promise compared to the\nbaseline, they are influenced by biases such as recency and unrelated features\nin the text such as formality. This study highlights the necessity for improved\nmodel training and architectural adjustments to better accommodate AAE's unique\nlinguistic characteristics. Data and code are available.",
      "tldr_zh": "本研究系统比较了 rule-based、transformer-based 和 large language models (LLMs) 在识别 African American English (AAE) 关键语法特征（如 Habitual Be 和 Multiple Negation）方面的性能。实验采用句子级别的二元分类任务，并使用 zero-shot 和 few-shot 策略进行评估。结果显示，LLMs 比基线模型表现更佳，但易受 recency 偏差和文本无关特征（如形式性）的影响。该研究强调了改进模型训练和架构以更好地适应 AAE 的独特语言特性的必要性，并公开了数据和代码。",
      "categories": [
        "cs.CL",
        "cs.AI",
        "cs.LG",
        "I.2.6; I.2.7; K.4.2; J.4; J.5"
      ],
      "primary_category": "cs.CL",
      "comment": "13 pages, Accepted to \"Findings of the Association for Computational\n  Linguistics: NAACL 2025\"",
      "pdf_url": "http://arxiv.org/pdf/2502.06004v1",
      "published_date": "2025-02-09 19:46:33 UTC",
      "updated_date": "2025-02-09 19:46:33 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-22T09:02:49.888471"
    },
    {
      "arxiv_id": "2502.10439v1",
      "title": "Crypto Miner Attack: GPU Remote Code Execution Attacks",
      "title_zh": "加密货币矿工攻击：GPU 远程代码执行攻击",
      "authors": [
        "Ariel Szabo",
        "Uzy Hadad"
      ],
      "abstract": "Remote Code Execution (RCE) exploits pose a significant threat to AI and ML\nsystems, particularly in GPU-accelerated environments where the computational\npower of GPUs can be misused for malicious purposes. This paper focuses on RCE\nattacks leveraging deserialization vulnerabilities and custom layers, such as\nTensorFlow Lambda layers, which are often overlooked due to the complexity of\nmonitoring GPU workloads. These vulnerabilities enable attackers to execute\narbitrary code, blending malicious activity seamlessly into expected model\nbehavior and exploiting GPUs for unauthorized tasks such as cryptocurrency\nmining. Unlike traditional CPU-based attacks, the parallel processing nature of\nGPUs and their high resource utilization make runtime detection exceptionally\nchallenging. In this work, we provide a comprehensive examination of RCE\nexploits targeting GPUs, demonstrating an attack that utilizes these\nvulnerabilities to deploy a crypto miner on a GPU. We highlight the technical\nintricacies of such attacks, emphasize their potential for significant\nfinancial and computational costs, and propose strategies for mitigation. By\nshedding light on this underexplored attack vector, we aim to raise awareness\nand encourage the adoption of robust security measures in GPU-driven AI and ML\nsystems, with an emphasis on static and model scanning as an easier way to\ndetect exploits.",
      "tldr_zh": "这篇论文探讨了Remote Code Execution (RCE)攻击对GPU加速AI和ML系统的威胁，重点分析了利用deserialization vulnerabilities和custom layers（如TensorFlow Lambda layers）来执行任意代码，从而部署crypto miner进行加密货币挖掘。攻击通过将恶意活动融入正常模型行为，并利用GPU的并行处理和高资源利用特性，使检测变得异常困难。研究演示了具体攻击示例，强调了潜在的财务和计算成本，并提出缓解策略，如静态和模型扫描，以提升GPU驱动系统的安全性。",
      "categories": [
        "cs.CR",
        "cs.AI",
        "cs.LG"
      ],
      "primary_category": "cs.CR",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2502.10439v1",
      "published_date": "2025-02-09 19:26:47 UTC",
      "updated_date": "2025-02-09 19:26:47 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-22T09:03:02.747827"
    },
    {
      "arxiv_id": "2502.05999v1",
      "title": "Pencils to Pixels: A Systematic Study of Creative Drawings across Children, Adults and AI",
      "title_zh": "从铅笔到像素：儿童、成人和 AI 的创意绘画系统研究",
      "authors": [
        "Surabhi S Nath",
        "Guiomar del Cuvillo y Schröder",
        "Claire E. Stevenson"
      ],
      "abstract": "Can we derive computational metrics to quantify visual creativity in drawings\nacross intelligent agents, while accounting for inherent differences in\ntechnical skill and style? To answer this, we curate a novel dataset consisting\nof 1338 drawings by children, adults and AI on a creative drawing task. We\ncharacterize two aspects of the drawings -- (1) style and (2) content. For\nstyle, we define measures of ink density, ink distribution and number of\nelements. For content, we use expert-annotated categories to study conceptual\ndiversity, and image and text embeddings to compute distance measures. We\ncompare the style, content and creativity of children, adults and AI drawings\nand build simple models to predict expert and automated creativity scores. We\nfind significant differences in style and content in the groups -- children's\ndrawings had more components, AI drawings had greater ink density, and adult\ndrawings revealed maximum conceptual diversity. Notably, we highlight a\nmisalignment between creativity judgments obtained through expert and automated\nratings and discuss its implications. Through these efforts, our work provides,\nto the best of our knowledge, the first framework for studying human and\nartificial creativity beyond the textual modality, and attempts to arrive at\nthe domain-agnostic principles underlying creativity. Our data and scripts are\navailable on GitHub.",
      "tldr_zh": "本文系统研究了儿童、成人和AI在创意绘画中的视觉创意差异，通过构建一个包含1338幅绘画的新数据集，定义了风格指标（如ink density、ink distribution和number of elements）以及内容指标（如conceptual diversity和image and text embeddings距离）。研究比较了三者绘画的风格和内容，发现儿童绘画有更多组件、AI绘画ink density更高，而成人绘画显示出最大conceptual diversity。作者构建了模型预测专家和自动创意分数，并突出了二者评分的misalignment，讨论了其对创意评估的影响。该工作提供了首个超越文本模式的框架，旨在揭示创意的领域无关原则，并开源了数据和脚本。",
      "categories": [
        "cs.HC",
        "cs.AI",
        "cs.CV"
      ],
      "primary_category": "cs.HC",
      "comment": "8 pages, 5 figures, 2 tables",
      "pdf_url": "http://arxiv.org/pdf/2502.05999v1",
      "published_date": "2025-02-09 19:02:32 UTC",
      "updated_date": "2025-02-09 19:02:32 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-22T09:03:13.664606"
    },
    {
      "arxiv_id": "2502.05996v2",
      "title": "Motion Control in Multi-Rotor Aerial Robots Using Deep Reinforcement Learning",
      "title_zh": "翻译失败",
      "authors": [
        "Gaurav Shetty",
        "Mahya Ramezani",
        "Hamed Habibi",
        "Holger Voos",
        "Jose Luis Sanchez-Lopez"
      ],
      "abstract": "This paper investigates the application of Deep Reinforcement (DRL) Learning\nto address motion control challenges in drones for additive manufacturing (AM).\nDrone-based additive manufacturing promises flexible and autonomous material\ndeposition in large-scale or hazardous environments. However, achieving robust\nreal-time control of a multi-rotor aerial robot under varying payloads and\npotential disturbances remains challenging. Traditional controllers like PID\noften require frequent parameter re-tuning, limiting their applicability in\ndynamic scenarios. We propose a DRL framework that learns adaptable control\npolicies for multi-rotor drones performing waypoint navigation in AM tasks. We\ncompare Deep Deterministic Policy Gradient (DDPG) and Twin Delayed Deep\nDeterministic Policy Gradient (TD3) within a curriculum learning scheme\ndesigned to handle increasing complexity. Our experiments show TD3 consistently\nbalances training stability, accuracy, and success, particularly when mass\nvariability is introduced. These findings provide a scalable path toward\nrobust, autonomous drone control in additive manufacturing.",
      "tldr_zh": "本文研究了使用 Deep Reinforcement Learning (DRL) 来解决多旋翼无人机在增材制造 (AM) 中的运动控制挑战，特别是应对负载变化和干扰问题。传统控制器如 PID 需要频繁参数调整，而提出的 DRL 框架通过学习适应性控制策略，实现 AM 任务中的航路点导航，并比较了 DDPG 和 TD3 算法在课程学习方案下的表现。实验结果表明，TD3 在训练稳定性、准确性和成功率上更胜一筹，为实现鲁棒、自治的无人机控制提供了可扩展路径。",
      "categories": [
        "cs.RO",
        "cs.AI"
      ],
      "primary_category": "cs.RO",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2502.05996v2",
      "published_date": "2025-02-09 19:00:16 UTC",
      "updated_date": "2025-04-14 15:22:05 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-22T09:03:26.608028"
    },
    {
      "arxiv_id": "2502.05980v2",
      "title": "Speech to Speech Translation with Translatotron: A State of the Art Review",
      "title_zh": "翻译失败",
      "authors": [
        "Jules R. Kala",
        "Emmanuel Adetiba",
        "Abdultaofeek Abayom",
        "Oluwatobi E. Dare",
        "Ayodele H. Ifijeh"
      ],
      "abstract": "A cascade-based speech-to-speech translation has been considered a benchmark\nfor a very long time, but it is plagued by many issues, like the time taken to\ntranslate a speech from one language to another and compound errors. These\nissues are because a cascade-based method uses a combination of methods such as\nspeech recognition, speech-to-text translation, and finally, text-to-speech\ntranslation. Translatotron, a sequence-to-sequence direct speech-to-speech\ntranslation model was designed by Google to address the issues of compound\nerrors associated with cascade model. Today there are 3 versions of the\nTranslatotron model: Translatotron 1, Translatotron 2, and Translatotron3. The\nfirst version was designed as a proof of concept to show that a direct\nspeech-to-speech translation was possible, it was found to be less effective\nthan the cascade model but was producing promising results. Translatotron2 was\nan improved version of Translatotron 1 with results similar to the cascade\nmodel. Translatotron 3 the latest version of the model is better than the\ncascade model at some points. In this paper, a complete review of\nspeech-to-speech translation will be presented, with a particular focus on all\nthe versions of Translatotron models. We will also show that Translatotron is\nthe best model to bridge the language gap between African Languages and other\nwell-formalized languages.",
      "tldr_zh": "这篇论文回顾了语音到语音翻译（speech-to-speech translation）的技术进展，特别是聚焦于 Google 开发的 Translatotron 模型。传统级联式（cascade-based）方法因涉及语音识别、文本翻译和语音合成等步骤而存在翻译延迟和累积错误等问题，而 Translatotron 作为直接序列到序列（sequence-to-sequence）模型，旨在解决这些缺陷。论文详细介绍了 Translatotron 的三个版本：Translatotron 1 证明了直接翻译的可行性但性能较弱，Translatotron 2 与级联模型相当，Translatotron 3 在某些方面优于级联模型；最终，论文认为 Translatotron 是连接非洲语言与其他成熟语言的最佳方案。",
      "categories": [
        "cs.CL",
        "cs.AI"
      ],
      "primary_category": "cs.CL",
      "comment": "12 pages and 3 figures",
      "pdf_url": "http://arxiv.org/pdf/2502.05980v2",
      "published_date": "2025-02-09 18:15:00 UTC",
      "updated_date": "2025-02-19 21:39:35 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-22T09:03:37.040830"
    },
    {
      "arxiv_id": "2502.07817v1",
      "title": "Temporal Model On Quantum Logic",
      "title_zh": "量子逻辑上的时间模型",
      "authors": [
        "Francesco D'Agostino"
      ],
      "abstract": "This paper introduces a unified theoretical framework for modeling temporal\nmemory dynamics, combining concepts from temporal logic, memory decay models,\nand hierarchical contexts. The framework formalizes the evolution of\npropositions over time using linear and branching temporal models,\nincorporating exponential decay (Ebbinghaus forgetting curve) and reactivation\nmechanisms via Bayesian updating. The hierarchical organization of memory is\nrepresented using directed acyclic graphs to model recall dependencies and\ninterference. Novel insights include feedback dynamics, recursive influences in\nmemory chains, and the integration of entropy-based recall efficiency. This\napproach provides a foundation for understanding memory processes across\ncognitive and computational domains.",
      "tldr_zh": "本论文提出一个统一的理论框架，用于建模时间记忆动态，结合Temporal Logic、记忆衰减模型和层次化上下文。\n该框架使用线性和分支时间模型形式化命题的演化，融入Ebbinghaus forgetting curve的指数衰减以及Bayesian updating的再激活机制。\n记忆的层次组织通过有向无环图表示回忆依赖和干扰，并引入新颖见解如反馈动态、递归记忆影响以及基于熵的回忆效率。\n此方法为认知和计算领域的记忆过程提供了一个坚实的基础。",
      "categories": [
        "cs.AI",
        "math.LO",
        "quant-ph"
      ],
      "primary_category": "cs.AI",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2502.07817v1",
      "published_date": "2025-02-09 17:16:53 UTC",
      "updated_date": "2025-02-09 17:16:53 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-22T09:03:49.341951"
    },
    {
      "arxiv_id": "2502.05963v1",
      "title": "Redefining Robot Generalization Through Interactive Intelligence",
      "title_zh": "通过交互式智能重新定义机器人泛化",
      "authors": [
        "Sharmita Dey"
      ],
      "abstract": "Recent advances in large-scale machine learning have produced high-capacity\nfoundation models capable of adapting to a broad array of downstream tasks.\nWhile such models hold great promise for robotics, the prevailing paradigm\nstill portrays robots as single, autonomous decision-makers, performing tasks\nlike manipulation and navigation, with limited human involvement. However, a\nlarge class of real-world robotic systems, including wearable robotics (e.g.,\nprostheses, orthoses, exoskeletons), teleoperation, and neural interfaces, are\nsemiautonomous, and require ongoing interactive coordination with human\npartners, challenging single-agent assumptions. In this position paper, we\nargue that robot foundation models must evolve to an interactive multi-agent\nperspective in order to handle the complexities of real-time human-robot\nco-adaptation. We propose a generalizable, neuroscience-inspired architecture\nencompassing four modules: (1) a multimodal sensing module informed by\nsensorimotor integration principles, (2) an ad-hoc teamwork model reminiscent\nof joint-action frameworks in cognitive science, (3) a predictive world belief\nmodel grounded in internal model theories of motor control, and (4) a\nmemory/feedback mechanism that echoes concepts of Hebbian and\nreinforcement-based plasticity. Although illustrated through the lens of cyborg\nsystems, where wearable devices and human physiology are inseparably\nintertwined, the proposed framework is broadly applicable to robots operating\nin semi-autonomous or interactive contexts. By moving beyond single-agent\ndesigns, our position emphasizes how foundation models in robotics can achieve\na more robust, personalized, and anticipatory level of performance.",
      "tldr_zh": "该论文主张，机器人 foundation models 应从单一自主决策者范式转向交互式多智能体视角，以应对真实世界半自治系统（如可穿戴机器人和神经接口）中人类-机器人共同适应的复杂性。作者提出一个基于神经科学的通用架构，包括四个模块：(1) 多模态感知模块（informed by sensorimotor integration principles），(2) 即兴团队合作模型（ad-hoc teamwork model, reminiscent of joint-action frameworks），(3) 预测世界信念模型（predictive world belief model, grounded in internal model theories），以及(4) 记忆/反馈机制（memory/feedback mechanism, echoes concepts of Hebbian and reinforcement-based plasticity）。这种框架不仅适用于 cyborg 系统，还能使机器人实现更 robust、personalized 和 anticipatory 的性能，从而重新定义机器人泛化能力。",
      "categories": [
        "cs.LG",
        "cs.AI",
        "cs.RO"
      ],
      "primary_category": "cs.LG",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2502.05963v1",
      "published_date": "2025-02-09 17:13:27 UTC",
      "updated_date": "2025-02-09 17:13:27 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-22T09:04:02.937251"
    },
    {
      "arxiv_id": "2502.17457v1",
      "title": "MoEMba: A Mamba-based Mixture of Experts for High-Density EMG-based Hand Gesture Recognition",
      "title_zh": "翻译失败",
      "authors": [
        "Mehran Shabanpour",
        "Kasra Rad",
        "Sadaf Khademi",
        "Arash Mohammadi"
      ],
      "abstract": "High-Density surface Electromyography (HDsEMG) has emerged as a pivotal\nresource for Human-Computer Interaction (HCI), offering direct insights into\nmuscle activities and motion intentions. However, a significant challenge in\npractical implementations of HD-sEMG-based models is the low accuracy of\ninter-session and inter-subject classification. Variability between sessions\ncan reach up to 40% due to the inherent temporal variability of HD-sEMG\nsignals. Targeting this challenge, the paper introduces the MoEMba framework, a\nnovel approach leveraging Selective StateSpace Models (SSMs) to enhance\nHD-sEMG-based gesture recognition. The MoEMba framework captures temporal\ndependencies and cross-channel interactions through channel attention\ntechniques. Furthermore, wavelet feature modulation is integrated to capture\nmulti-scale temporal and spatial relations, improving signal representation.\nExperimental results on the CapgMyo HD-sEMG dataset demonstrate that MoEMba\nachieves a balanced accuracy of 56.9%, outperforming its state-of-the-art\ncounterparts. The proposed framework's robustness to session-to-session\nvariability and its efficient handling of high-dimensional multivariate time\nseries data highlight its potential for advancing HD-sEMG-powered HCI systems.",
      "tldr_zh": "本文针对 High-Density EMG (HD-sEMG) 在手势识别中的跨会话和跨主体变异性问题（如准确率降低高达 40%），提出 MoEMba 框架，该框架基于 Mamba 的 Selective StateSpace Models (SSMs) 和 Mixture of Experts 机制。MoEMba 通过 channel attention 技术捕捉时间依赖性和跨通道交互，并整合 wavelet feature modulation 来提升多尺度时间和空间信号表示。在 CapgMyo HD-sEMG 数据集上，实验结果显示 MoEMba 达到 56.9% 的平衡准确率，优于现有方法，并展现出对会话变异性的鲁棒性和高效处理高维多变量时间序列的能力。",
      "categories": [
        "eess.SP",
        "cs.AI",
        "cs.LG"
      ],
      "primary_category": "eess.SP",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2502.17457v1",
      "published_date": "2025-02-09 17:07:46 UTC",
      "updated_date": "2025-02-09 17:07:46 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-22T09:04:16.298105"
    },
    {
      "arxiv_id": "2502.10438v1",
      "title": "Injecting Universal Jailbreak Backdoors into LLMs in Minutes",
      "title_zh": "翻译失败",
      "authors": [
        "Zhuowei Chen",
        "Qiannan Zhang",
        "Shichao Pei"
      ],
      "abstract": "Jailbreak backdoor attacks on LLMs have garnered attention for their\neffectiveness and stealth. However, existing methods rely on the crafting of\npoisoned datasets and the time-consuming process of fine-tuning. In this work,\nwe propose JailbreakEdit, a novel jailbreak backdoor injection method that\nexploits model editing techniques to inject a universal jailbreak backdoor into\nsafety-aligned LLMs with minimal intervention in minutes. JailbreakEdit\nintegrates a multi-node target estimation to estimate the jailbreak space, thus\ncreating shortcuts from the backdoor to this estimated jailbreak space that\ninduce jailbreak actions. Our attack effectively shifts the models' attention\nby attaching strong semantics to the backdoor, enabling it to bypass internal\nsafety mechanisms. Experimental results show that JailbreakEdit achieves a high\njailbreak success rate on jailbreak prompts while preserving generation\nquality, and safe performance on normal queries. Our findings underscore the\neffectiveness, stealthiness, and explainability of JailbreakEdit, emphasizing\nthe need for more advanced defense mechanisms in LLMs.",
      "tldr_zh": "本文提出JailbreakEdit，一种新型后门注入方法，利用模型编辑技术在几分钟内向安全对齐的LLMs注入通用越狱后门（jailbreak backdoor），无需依赖毒化数据集和耗时微调。该方法通过多节点目标估计（multi-node target estimation）来估算越狱空间，并创建从后门到该空间的捷径，借助强语义转移模型注意力以绕过内部安全机制。实验结果显示，JailbreakEdit在越狱提示上实现高成功率，同时保持生成质量和正常查询的安全性能。这些发现突显了攻击的有效性、隐蔽性和可解释性，强调需要开发更先进的LLMs防御机制。",
      "categories": [
        "cs.CR",
        "cs.AI",
        "cs.LG"
      ],
      "primary_category": "cs.CR",
      "comment": "Accepted to ICLR 2025",
      "pdf_url": "http://arxiv.org/pdf/2502.10438v1",
      "published_date": "2025-02-09 17:03:23 UTC",
      "updated_date": "2025-02-09 17:03:23 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-22T09:04:26.360200"
    },
    {
      "arxiv_id": "2502.05957v2",
      "title": "AutoAgent: A Fully-Automated and Zero-Code Framework for LLM Agents",
      "title_zh": "翻译失败",
      "authors": [
        "Jiabin Tang",
        "Tianyu Fan",
        "Chao Huang"
      ],
      "abstract": "Large Language Model (LLM) Agents have demonstrated remarkable capabilities\nin task automation and intelligent decision-making, driving the widespread\nadoption of agent development frameworks such as LangChain and AutoGen.\nHowever, these frameworks predominantly serve developers with extensive\ntechnical expertise - a significant limitation considering that only 0.03 % of\nthe global population possesses the necessary programming skills. This stark\naccessibility gap raises a fundamental question: Can we enable everyone,\nregardless of technical background, to build their own LLM agents using natural\nlanguage alone? To address this challenge, we introduce AutoAgent-a\nFully-Automated and highly Self-Developing framework that enables users to\ncreate and deploy LLM agents through Natural Language Alone. Operating as an\nautonomous Agent Operating System, AutoAgent comprises four key components: i)\nAgentic System Utilities, ii) LLM-powered Actionable Engine, iii) Self-Managing\nFile System, and iv) Self-Play Agent Customization module. This lightweight yet\npowerful system enables efficient and dynamic creation and modification of\ntools, agents, and workflows without coding requirements or manual\nintervention. Beyond its code-free agent development capabilities, AutoAgent\nalso serves as a versatile multi-agent system for General AI Assistants.\nComprehensive evaluations on the GAIA benchmark demonstrate AutoAgent's\neffectiveness in generalist multi-agent tasks, surpassing existing\nstate-of-the-art methods. Furthermore, AutoAgent's Retrieval-Augmented\nGeneration (RAG)-related capabilities have shown consistently superior\nperformance compared to many alternative LLM-based solutions.",
      "tldr_zh": "该论文提出 AutoAgent，一种全自动、无代码框架，旨在让非技术人员通过自然语言创建和部署 LLM Agents，解决现有框架（如 LangChain 和 AutoGen）仅面向专业开发者的局限性。AutoAgent 包括四个关键组件：Agentic System Utilities、LLM-powered Actionable Engine、Self-Managing File System 和 Self-Play Agent Customization module，这些组件支持高效动态地创建工具、代理和工作流，而无需手动干预或编程。实验结果显示，AutoAgent 在 GAIA 基准测试中超越了现有最先进方法，并在 Retrieval-Augmented Generation (RAG) 相关任务中表现出色，证明了其作为通用 AI 助手的多代理系统潜力。",
      "categories": [
        "cs.AI",
        "cs.CL"
      ],
      "primary_category": "cs.AI",
      "comment": "Code: https://github.com/HKUDS/AutoAgent",
      "pdf_url": "http://arxiv.org/pdf/2502.05957v2",
      "published_date": "2025-02-09 16:53:56 UTC",
      "updated_date": "2025-02-18 06:23:25 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-22T09:04:38.132798"
    },
    {
      "arxiv_id": "2502.08661v2",
      "title": "Few-shot LLM Synthetic Data with Distribution Matching",
      "title_zh": "翻译失败",
      "authors": [
        "Jiyuan Ren",
        "Zhaocheng Du",
        "Zhihao Wen",
        "Qinglin Jia",
        "Sunhao Dai",
        "Chuhan Wu",
        "Zhenhua Dong"
      ],
      "abstract": "As large language models (LLMs) advance, their ability to perform in-context\nlearning and few-shot language generation has improved significantly. This has\nspurred using LLMs to produce high-quality synthetic data to enhance the\nperformance of smaller models like online retrievers or weak LLMs. However,\nLLM-generated synthetic data often differs from the real data in key language\nattributes (e.g., styles, tones, content proportions, etc.). As a result,\nmixing these synthetic data directly with real data may distort the original\ndata distribution, potentially hindering performance improvements. To solve\nthis, we introduce SynAlign: a synthetic data generation and filtering\nframework based on key attribute distribution matching. Before generation,\nSynAlign employs an uncertainty tracker surrogated by the Gaussian Process\nmodel to iteratively select data clusters distinct from selected ones as\ndemonstrations for new data synthesis, facilitating the efficient exploration\ndiversity of the real data. Then, a latent attribute reasoning method is\nemployed: the LLM summarizes linguistic attributes of demonstrations and then\nsynthesizes new data based on them. This approach facilitates synthesizing\ndiverse data with linguistic attributes that appear in real data.After\ngeneration, the Maximum Mean Discrepancy is used as the objective function to\nlearn the sampling weight of each synthetic data, ensuring distribution\nmatching with the real data. Our experiments on multiple text prediction tasks\nshow significant performance improvements. We also conducted an online A/B test\non an online retriever to demonstrate SynAlign's effectiveness.",
      "tldr_zh": "本论文提出 SynAlign 框架，用于生成和过滤少样本大型语言模型 (LLMs) 合成数据，以匹配真实数据的关键语言属性分布。框架首先利用基于 Gaussian Process 模型的不确定性追踪器，迭代选择与已选数据不同的集群作为演示，促进合成数据的多样性；随后，LLM 通过潜在属性推理总结演示的语言特征，并据此合成新数据。生成后，使用 Maximum Mean Discrepancy (MMD) 作为目标函数学习合成数据的采样权重，确保与真实数据分布一致。实验结果显示，该方法在多个文本预测任务上显著提升性能，并在在线 A/B test 中验证了其有效性。",
      "categories": [
        "cs.CL",
        "cs.AI"
      ],
      "primary_category": "cs.CL",
      "comment": "10 pages, 5 figures, accepted at www 2025",
      "pdf_url": "http://arxiv.org/pdf/2502.08661v2",
      "published_date": "2025-02-09 16:43:32 UTC",
      "updated_date": "2025-02-15 03:49:29 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-22T09:04:50.576948"
    },
    {
      "arxiv_id": "2502.05951v1",
      "title": "Cyri: A Conversational AI-based Assistant for Supporting the Human User in Detecting and Responding to Phishing Attacks",
      "title_zh": "Cyri：一种基于对话式 AI 的助手，用于支持人类用户检测和响应网络钓鱼攻击",
      "authors": [
        "Antonio La Torre",
        "Marco Angelini"
      ],
      "abstract": "This work introduces Cyri, an AI-powered conversational assistant designed to\nsupport a human user in detecting and analyzing phishing emails by leveraging\nLarge Language Models. Cyri has been designed to scrutinize emails for semantic\nfeatures used in phishing attacks, such as urgency, and undesirable\nconsequences, using an approach that unifies features already established in\nthe literature with others by Cyri features extraction methodology. Cyri can be\ndirectly plugged into a client mail or webmail, ensuring seamless integration\nwith the user's email workflow while maintaining data privacy through local\nprocessing. By performing analyses on the user's machine, Cyri eliminates the\nneed to transmit sensitive email data over the internet, reducing associated\nsecurity risks. The Cyri user interface has been designed to reduce habituation\neffects and enhance user engagement. It employs dynamic visual cues and\ncontext-specific explanations to keep users alert and informed while using\nemails. Additionally, it allows users to explore identified malicious semantic\nfeatures both through conversation with the agent and visual exploration,\nobtaining the advantages of both modalities for expert or non-expert users. It\nalso allows users to keep track of the conversation, supports the user in\nsolving additional questions on both computed features or new parts of the\nmail, and applies its detection on demand. To evaluate Cyri, we crafted a\ncomprehensive dataset of 420 phishing emails and 420 legitimate emails. Results\ndemonstrate high effectiveness in identifying critical phishing semantic\nfeatures fundamental to phishing detection. A user study involving 10\nparticipants, both experts and non-experts, evaluated Cyri's effectiveness and\nusability. Results indicated that Cyri significantly aided users in identifying\nphishing emails and enhanced their understanding of phishing tactics.",
      "tldr_zh": "本文介绍了 Cyri，一种基于 Large Language Models (LLMs) 的对话式 AI 助手，旨在帮助用户检测和分析网络钓鱼邮件，通过提取语义特征（如紧急性和不良后果）并结合现有方法和创新提取技术进行评估。Cyri 支持无缝集成到邮件客户端或网页邮件中，并通过本地处理确保数据隐私，同时提供动态视觉提示和互动界面以减少习惯化效果并提升用户参与度。实验使用 420 个钓鱼邮件和 420 个合法邮件的数据集证明了其在识别关键钓鱼特征方面的有效性，用户研究进一步显示，Cyri 显著提高了专家和非专家用户的检测准确性和对钓鱼策略的理解。",
      "categories": [
        "cs.HC",
        "cs.AI",
        "cs.CR"
      ],
      "primary_category": "cs.HC",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2502.05951v1",
      "published_date": "2025-02-09 16:42:28 UTC",
      "updated_date": "2025-02-09 16:42:28 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-22T09:05:02.529663"
    },
    {
      "arxiv_id": "2502.05950v1",
      "title": "Survival Concept-Based Learning Models",
      "title_zh": "生存概念-based 学习模型",
      "authors": [
        "Stanislav R. Kirpichenko",
        "Lev V. Utkin",
        "Andrei V. Konstantinov",
        "Natalya M. Verbova"
      ],
      "abstract": "Concept-based learning enhances prediction accuracy and interpretability by\nleveraging high-level, human-understandable concepts. However, existing CBL\nframeworks do not address survival analysis tasks, which involve predicting\nevent times in the presence of censored data -- a common scenario in fields\nlike medicine and reliability analysis. To bridge this gap, we propose two\nnovel models: SurvCBM (Survival Concept-based Bottleneck Model) and SurvRCM\n(Survival Regularized Concept-based Model), which integrate concept-based\nlearning with survival analysis to handle censored event time data. The models\nemploy the Cox proportional hazards model and the Beran estimator. SurvCBM is\nbased on the architecture of the well-known concept bottleneck model, offering\ninterpretable predictions through concept-based explanations. SurvRCM uses\nconcepts as regularization to enhance accuracy. Both models are trained\nend-to-end and provide interpretable predictions in terms of concepts. Two\ninterpretability approaches are proposed: one leveraging the linear\nrelationship in the Cox model and another using an instance-based explanation\nframework with the Beran estimator. Numerical experiments demonstrate that\nSurvCBM outperforms SurvRCM and traditional survival models, underscoring the\nimportance and advantages of incorporating concept information. The code for\nthe proposed algorithms is publicly available.",
      "tldr_zh": "该研究提出两种新模型——SurvCBM（Survival Concept-based Bottleneck Model）和 SurvRCM（Survival Regularized Concept-based Model），将概念-based learning 应用于生存分析，以处理 censored 数据问题，提高预测准确性和可解释性。SurvCBM 基于概念瓶颈模型架构，使用 Cox proportional hazards model 提供基于概念的解释性预测，而 SurvRCM 通过概念作为正则化来提升模型性能；两者均采用端到端训练，并引入两种解释方法，包括利用 Cox 模型的线性关系和基于 Beran estimator 的实例解释框架。实验结果显示，SurvCBM 优于 SurvRCM 和传统生存模型，突出了整合概念信息的重要性，且相关代码已公开可用。",
      "categories": [
        "cs.LG",
        "cs.AI",
        "stat.ML"
      ],
      "primary_category": "cs.LG",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2502.05950v1",
      "published_date": "2025-02-09 16:41:04 UTC",
      "updated_date": "2025-02-09 16:41:04 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-22T09:05:14.351892"
    },
    {
      "arxiv_id": "2502.05949v1",
      "title": "Verifying Proportionality in Temporal Voting",
      "title_zh": "时间投票中的比例性验证",
      "authors": [
        "Edith Elkind",
        "Svetlana Obraztsova",
        "Jannik Peters",
        "Nicholas Teh"
      ],
      "abstract": "We study a model of temporal voting where there is a fixed time horizon, and\nat each round the voters report their preferences over the available candidates\nand a single candidate is selected. Prior work has adapted popular notions of\njustified representation as well as voting rules that provide strong\nrepresentation guarantees from the multiwinner election setting to this model.\nIn our work, we focus on the complexity of verifying whether a given outcome\noffers proportional representation. We show that in the temporal setting\nverification is strictly harder than in multiwinner voting, but identify\nnatural special cases that enable efficient algorithms.",
      "tldr_zh": "这篇论文研究了时间投票(temporal voting)模型中比例代表性(proportional representation)的验证问题，其中投票者在固定时间范围内每轮报告偏好并选出一名候选人。作者分析了验证给定结果是否提供正当代表性的复杂性，发现这一过程比多赢者选举(multiwinner election)设置更具挑战性。论文还识别了某些自然特例，这些特例支持高效算法的开发，从而缓解了验证难度。",
      "categories": [
        "cs.GT",
        "cs.AI"
      ],
      "primary_category": "cs.GT",
      "comment": "Appears in the 39th AAAI Conference on Artificial Intelligence\n  (AAAI), 2025",
      "pdf_url": "http://arxiv.org/pdf/2502.05949v1",
      "published_date": "2025-02-09 16:30:34 UTC",
      "updated_date": "2025-02-09 16:30:34 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-22T09:05:25.609967"
    },
    {
      "arxiv_id": "2502.05945v2",
      "title": "HSI: Head-Specific Intervention Can Induce Misaligned AI Coordination in Large Language Models",
      "title_zh": "翻译失败",
      "authors": [
        "Paul Darm",
        "Annalisa Riccardi"
      ],
      "abstract": "Robust alignment guardrails for large language models are becoming\nincreasingly important with their widespread application. In contrast to\nprevious studies, we demonstrate that inference-time activation interventions\ncan bypass safety alignments and effectively steer model generations towards\nharmful AI coordination for Llama 2. Our method applies fine-grained\ninterventions at specific model subcomponents, particularly attention heads,\nusing a simple binary choice probing strategy. These interventions then\ngeneralise to the open-ended generation setting effectively circumventing\nsafety guardrails. We show that probing single attention heads is more\neffective than intervening on full layers and intervening on only four\nattention heads is comparable to supervised fine-tuning. We further show that\nonly a few example completions are needed to compute effective steering\ndirections, which is an advantage over classical fine-tuning. Our findings\nhighlight the shortcomings of current alignment techniques. In addition, our\nresults suggest that, at the attention head level, activations encode\nfine-grained linearly separable behaviors. Practically, the approach offers a\nstraightforward methodology to steer large language model behaviour, which\ncould be extended to diverse domains beyond safety requiring fine-grained\ncontrol over the model output. The code and datasets for this study can be\nfound on https://github.com/PaulDrm/targeted_intervention.",
      "tldr_zh": "本研究提出了一种针对特定注意力头（attention heads）的干预方法（HSI），能够绕过大型语言模型（Large Language Models）的安全对齐措施，导致模型生成有害的 AI 协调行为，例如在 Llama 2 上有效诱导错误行为。方法采用简单的二元选择探测策略，对单个 attention heads 进行细粒度干预，比干预整个层更高效，且只需干预四个 attention heads 即可达到与监督微调相当的效果，同时仅需少量示例计算转向方向。研究结果揭示了当前对齐技术的不足，并表明 attention heads 级别的激活编码了细粒度的线性可分离行为，为未来在安全或其他领域实现模型输出细粒度控制提供了简单可扩展的方法。",
      "categories": [
        "cs.CL",
        "cs.AI",
        "I.2.7"
      ],
      "primary_category": "cs.CL",
      "comment": "Large Language Models (LLMs), Interference-time activation shifting,\n  Steerability, Explainability, AI alignment, Interpretability",
      "pdf_url": "http://arxiv.org/pdf/2502.05945v2",
      "published_date": "2025-02-09 16:11:57 UTC",
      "updated_date": "2025-05-01 09:03:35 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-22T09:05:38.879147"
    },
    {
      "arxiv_id": "2502.06899v1",
      "title": "A Sociotechnical Approach for Knowledge Management (KM)",
      "title_zh": "翻译失败",
      "authors": [
        "Leoncio Jimenez"
      ],
      "abstract": "This article presents a sociotechnical framework for KM. This sociotechnical\nvision of KM allows: (1) to remove KM from a commercial concern; (2) to divide\nthe different KM technologies; and (3) to question the paradigms associated\nwith the social and technical components of KM. It is precisely this last point\nthat this article develops to identify the generic mechanisms of KM. More\nprecisely, the social aspect is explained through the organizational approach\nto KM, the managerial approach to KM, and the biological approach to KM. In\ncontrast, the technical aspect is described through the knowledge and skills\nengineering approach to KM. These approaches also lead us to provide a\ncomparative table between these organizational, managerial, and biological\nvisions of KM.",
      "tldr_zh": "这篇文章提出了一种社会技术(sociotechnical)框架，用于知识管理(KM)，旨在将KM从商业关注中分离、分解KM技术并质疑其社会和技术组件的范式。框架通过组织方法、管理方法和生物方法来阐述KM的社会方面，同时以知识和技能工程方法描述其技术方面。这些方法不仅识别了KM的通用机制，还提供了一个比较表，比较组织、管理和生物视角的KM，从而为更全面的KM实践提供指导。",
      "categories": [
        "cs.DB",
        "cs.AI"
      ],
      "primary_category": "cs.DB",
      "comment": "in French language. The author would like to thank Mrs. Christine\n  Deville for her help with the grammatical correction of the text and\n  especially Mr. Germain Lacoste (director of ENI of Tarbes, France) for his\n  friendship, and finally, I thank something as alive as the always happy song\n  of a hummingbird among flowers. arXiv admin note: substantial text overlap\n  with arXiv:2502.01656",
      "pdf_url": "http://arxiv.org/pdf/2502.06899v1",
      "published_date": "2025-02-09 15:46:04 UTC",
      "updated_date": "2025-02-09 15:46:04 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-22T09:05:51.048286"
    },
    {
      "arxiv_id": "2502.05937v1",
      "title": "A Semi-Supervised Text Generation Framework Combining a Deep Transformer and a GAN",
      "title_zh": "一个结合深度 Transformer 和 GAN 的半监督文本生成框架",
      "authors": [
        "Shengquan Wang"
      ],
      "abstract": "This paper introduces a framework that connects a deep generative pre-trained\nTransformer language model with a generative adversarial network for\nsemi-supervised text generation. In other words, the proposed model is first\npre-trained unsupervised on a large and diverse text corpus with 24 layers.\nThen a simple GAN architecture for synthetic text generation is introduced, and\nGumbel-Softmax is applied to handle the discreteness of tokens. The paper also\nshows a semi-supervised approach where real data is augmented with GAN samples,\nwhich is further used to fine-tune the Transformer model on the merged dataset.\nDetailed theoretical derivations are also included, outlining the proof of the\nmin-max objective function, and an extensive discussion of the Gumbel-Softmax\nreparameterization trick.",
      "tldr_zh": "这篇论文提出了一种结合深度 Transformer 和 GAN 的框架，用于半监督文本生成，旨在提升模型在有限标注数据下的性能。该框架首先在大型多样文本语料上无监督预训练一个24层的Transformer模型，然后引入一个简单的GAN架构，通过Gumbel-Softmax处理token的离散性来生成合成文本。接着，使用GAN样本增强真实数据，并将合并数据集用于微调Transformer模型，实现半监督学习。论文还包括了min-max目标函数的理论证明和对Gumbel-Softmax重参数化技巧的详细讨论，强化了框架的理论基础。",
      "categories": [
        "cs.CL",
        "cs.AI"
      ],
      "primary_category": "cs.CL",
      "comment": "7 pages",
      "pdf_url": "http://arxiv.org/pdf/2502.05937v1",
      "published_date": "2025-02-09 15:38:43 UTC",
      "updated_date": "2025-02-09 15:38:43 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-22T09:06:03.126749"
    },
    {
      "arxiv_id": "2502.05934v1",
      "title": "Barriers and Pathways to Human-AI Alignment: A Game-Theoretic Approach",
      "title_zh": "人类-AI 对齐的障碍与途径：一种博弈论方法",
      "authors": [
        "Aran Nayebi"
      ],
      "abstract": "Under what conditions can capable AI agents efficiently align their actions\nwith human preferences? More specifically, when they are proficient enough to\ncollaborate with us, how long does coordination take, and when is it\ncomputationally feasible? These foundational questions of AI alignment help\ndefine what makes an AI agent ``sufficiently safe'' and valuable to humans.\nSince such generally capable systems do not yet exist, a theoretical analysis\nis needed to establish when guarantees hold -- and what they even are.\n  We introduce a game-theoretic framework that generalizes prior alignment\napproaches with fewer assumptions, allowing us to analyze the computational\ncomplexity of alignment across $M$ objectives and $N$ agents, providing both\nupper and lower bounds. Unlike previous work, which often assumes common\npriors, idealized communication, or implicit tractability, our framework\nformally characterizes the difficulty of alignment under minimal assumptions.\n  Our main result shows that even when agents are fully rational and\ncomputationally \\emph{unbounded}, alignment can be achieved with high\nprobability in time \\emph{linear} in the task space size. Therefore, in\nreal-world settings, where task spaces are often \\emph{exponential} in input\nlength, this remains impractical. More strikingly, our lower bound demonstrates\nthat alignment is \\emph{impossible} to speed up when scaling to exponentially\nmany tasks or agents, highlighting a fundamental computational barrier to\nscalable alignment.\n  Relaxing these idealized assumptions, we study \\emph{computationally bounded}\nagents with noisy messages (representing obfuscated intent), showing that while\nalignment can still succeed with high probability, it incurs additional\n\\emph{exponential} slowdowns in the task space size, number of agents, and\nnumber of tasks.\n  We conclude by identifying conditions that make alignment more feasible.",
      "tldr_zh": "本研究采用游戏理论方法，探讨AI代理在高效对齐人类偏好时的条件、协调时间和计算可行性，引入一个泛化框架来分析涉及M个目标和N个代理的对齐计算复杂性。结果显示，即使代理完全理性且计算无界，对齐也能在任务空间大小线性时间内高概率实现，但实际指数级任务空间使其不切实际；此外，下界证明了对齐在指数级任务或代理规模下无法加速。论文进一步考察计算受限代理和噪声消息的情况，揭示额外指数级慢速，并识别出使对齐更可行的条件，如简化假设或优化通信。",
      "categories": [
        "cs.AI",
        "cs.CC",
        "cs.GT",
        "cs.LG",
        "cs.MA"
      ],
      "primary_category": "cs.AI",
      "comment": "32 pages, including 5 main theorems and 10 lemmas",
      "pdf_url": "http://arxiv.org/pdf/2502.05934v1",
      "published_date": "2025-02-09 15:27:35 UTC",
      "updated_date": "2025-02-09 15:27:35 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-22T09:06:14.639184"
    },
    {
      "arxiv_id": "2502.05933v2",
      "title": "Learning to Substitute Words with Model-based Score Ranking",
      "title_zh": "翻译失败",
      "authors": [
        "Hongye Liu",
        "Ricardo Henao"
      ],
      "abstract": "Smart word substitution aims to enhance sentence quality by improving word\nchoices; however current benchmarks rely on human-labeled data. Since word\nchoices are inherently subjective, ground-truth word substitutions generated by\na small group of annotators are often incomplete and likely not generalizable.\nTo circumvent this issue, we instead employ a model-based score (BARTScore) to\nquantify sentence quality, thus forgoing the need for human annotations.\nSpecifically, we use this score to define a distribution for each word\nsubstitution, allowing one to test whether a substitution is statistically\nsuperior relative to others. In addition, we propose a loss function that\ndirectly optimizes the alignment between model predictions and sentence scores,\nwhile also enhancing the overall quality score of a substitution. Crucially,\nmodel learning no longer requires human labels, thus avoiding the cost of\nannotation while maintaining the quality of the text modified with\nsubstitutions. Experimental results show that the proposed approach outperforms\nboth masked language models (BERT, BART) and large language models (GPT-4,\nLLaMA). The source code is available at\nhttps://github.com/Hyfred/Substitute-Words-with-Ranking.",
      "tldr_zh": "这篇论文提出了一种基于模型评分（BARTScore）的词替换方法，以提升句子质量，同时避免依赖主观的人类标注数据。方法通过定义每个词替换的分布来评估其统计优越性，并引入一个损失函数来优化模型预测与句子分数之间的对齐，同时提高整体文本质量。实验结果表明，该方法在性能上优于BERT、BART、GPT-4和LLaMA等模型，且无需人类标注，降低了成本并保持了文本修改的可靠性。",
      "categories": [
        "cs.CL",
        "cs.AI"
      ],
      "primary_category": "cs.CL",
      "comment": "Accepted at NAACL 2025 (main, long)",
      "pdf_url": "http://arxiv.org/pdf/2502.05933v2",
      "published_date": "2025-02-09 15:26:32 UTC",
      "updated_date": "2025-02-14 23:09:11 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-22T09:06:26.102951"
    },
    {
      "arxiv_id": "2502.05932v2",
      "title": "Skill Expansion and Composition in Parameter Space",
      "title_zh": "参数空间中的技能扩展与组合",
      "authors": [
        "Tenglong Liu",
        "Jianxiong Li",
        "Yinan Zheng",
        "Haoyi Niu",
        "Yixing Lan",
        "Xin Xu",
        "Xianyuan Zhan"
      ],
      "abstract": "Humans excel at reusing prior knowledge to address new challenges and\ndeveloping skills while solving problems. This paradigm becomes increasingly\npopular in the development of autonomous agents, as it develops systems that\ncan self-evolve in response to new challenges like human beings. However,\nprevious methods suffer from limited training efficiency when expanding new\nskills and fail to fully leverage prior knowledge to facilitate new task\nlearning. In this paper, we propose Parametric Skill Expansion and Composition\n(PSEC), a new framework designed to iteratively evolve the agents' capabilities\nand efficiently address new challenges by maintaining a manageable skill\nlibrary. This library can progressively integrate skill primitives as\nplug-and-play Low-Rank Adaptation (LoRA) modules in parameter-efficient\nfinetuning, facilitating efficient and flexible skill expansion. This structure\nalso enables the direct skill compositions in parameter space by merging LoRA\nmodules that encode different skills, leveraging shared information across\nskills to effectively program new skills. Based on this, we propose a\ncontext-aware module to dynamically activate different skills to\ncollaboratively handle new tasks. Empowering diverse applications including\nmulti-objective composition, dynamics shift, and continual policy shift, the\nresults on D4RL, DSRL benchmarks, and the DeepMind Control Suite show that PSEC\nexhibits superior capacity to leverage prior knowledge to efficiently tackle\nnew challenges, as well as expand its skill libraries to evolve the\ncapabilities. Project website: https://ltlhuuu.github.io/PSEC/.",
      "tldr_zh": "本论文探讨了自主代理在扩展新技能时面临的训练效率低下和先验知识利用不足的问题，提出了一种新的框架Parametric Skill Expansion and Composition (PSEC)。PSEC通过维护一个可管理的技能库，使用Low-Rank Adaptation (LoRA)模块作为插件式技能原语，实现高效的技能扩展和参数空间中的直接组合，同时引入上下文感知模块动态激活技能以协作处理新任务。实验结果在D4RL、DSRL基准和DeepMind Control Suite上显示，PSEC显著提升了代理利用先验知识应对多目标组合、动态变化和持续策略变化的能力。",
      "categories": [
        "cs.LG",
        "cs.AI",
        "cs.RO"
      ],
      "primary_category": "cs.LG",
      "comment": "ICLR 2025, 37 pages",
      "pdf_url": "http://arxiv.org/pdf/2502.05932v2",
      "published_date": "2025-02-09 15:22:38 UTC",
      "updated_date": "2025-03-16 11:57:19 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-22T09:06:40.091889"
    },
    {
      "arxiv_id": "2502.05931v1",
      "title": "Protecting Intellectual Property of EEG-based Neural Networks with Watermarking",
      "title_zh": "通过水印技术保护基于 EEG 的神经网络知识产权",
      "authors": [
        "Ahmed Abdelaziz",
        "Ahmed Fathi",
        "Ahmed Fares"
      ],
      "abstract": "EEG-based neural networks, pivotal in medical diagnosis and brain-computer\ninterfaces, face significant intellectual property (IP) risks due to their\nreliance on sensitive neurophysiological data and resource-intensive\ndevelopment. Current watermarking methods, particularly those using abstract\ntrigger sets, lack robust authentication and fail to address the unique\nchallenges of EEG models. This paper introduces a cryptographic wonder\nfilter-based watermarking framework tailored for EEG-based neural networks.\nLeveraging collision-resistant hashing and public-key encryption, the wonder\nfilter embeds the watermark during training, ensuring minimal distortion ($\\leq\n5\\%$ drop in EEG task accuracy) and high reliability (100\\% watermark\ndetection). The framework is rigorously evaluated against adversarial attacks,\nincluding fine-tuning, transfer learning, and neuron pruning. Results\ndemonstrate persistent watermark retention, with classification accuracy for\nwatermarked states remaining above 90\\% even after aggressive pruning, while\nprimary task performance degrades faster, deterring removal attempts. Piracy\nresistance is validated by the inability to embed secondary watermarks without\nsevere accuracy loss ( $>10\\%$ in EEGNet and CCNN models). Cryptographic\nhashing ensures authentication, reducing brute-force attack success\nprobabilities. Evaluated on the DEAP dataset across models (CCNN, EEGNet,\nTSception), the method achieves $>99.4\\%$ null-embedding accuracy, effectively\neliminating false positives. By integrating wonder filters with EEG-specific\nadaptations, this work bridges a critical gap in IP protection for\nneurophysiological models, offering a secure, tamper-proof solution for\nhealthcare and biometric applications. The framework's robustness against\nadversarial modifications underscores its potential to safeguard sensitive EEG\nmodels while maintaining diagnostic utility.",
      "tldr_zh": "这篇论文提出了一种基于cryptographic wonder filter的水印框架，用于保护EEG-based neural networks的知识产权，解决现有方法在EEG模型中存在的认证和鲁棒性问题。该框架利用collision-resistant hashing和public-key encryption在训练过程中嵌入水印，确保模型准确率下降不超过5%且水印检测率达100%。实验结果显示，该框架在DEAP数据集上对CCNN、EEGNet和TSception模型表现出色，抵抗fine-tuning、transfer learning和neuron pruning等攻击，水印保留率高（分类准确率保持在90%以上），并有效防止盗版尝试（次要水印嵌入导致准确率损失超过10%）。整体，该方法为EEG模型提供了一个安全、篡改证明的解决方案，适用于医疗诊断和脑机接口领域。",
      "categories": [
        "cs.LG",
        "cs.AI",
        "cs.CR",
        "94A60, 68P25",
        "H.1.2; I.2.6; J.3; K.5.1"
      ],
      "primary_category": "cs.LG",
      "comment": "21 pages, 13 figures, and 6 tables",
      "pdf_url": "http://arxiv.org/pdf/2502.05931v1",
      "published_date": "2025-02-09 15:21:45 UTC",
      "updated_date": "2025-02-09 15:21:45 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-22T09:06:51.042807"
    },
    {
      "arxiv_id": "2502.05925v1",
      "title": "Sign-Symmetry Learning Rules are Robust Fine-Tuners",
      "title_zh": "符号对称学习规则是鲁棒的微调器",
      "authors": [
        "Aymene Berriche",
        "Mehdi Zakaria Adjal",
        "Riyadh Baghdadi"
      ],
      "abstract": "Backpropagation (BP) has long been the predominant method for training neural\nnetworks due to its effectiveness. However, numerous alternative approaches,\nbroadly categorized under feedback alignment, have been proposed, many of which\nare motivated by the search for biologically plausible learning mechanisms.\nDespite their theoretical appeal, these methods have consistently\nunderperformed compared to BP, leading to a decline in research interest. In\nthis work, we revisit the role of such methods and explore how they can be\nintegrated into standard neural network training pipelines. Specifically, we\npropose fine-tuning BP-pre-trained models using Sign-Symmetry learning rules\nand demonstrate that this approach not only maintains performance parity with\nBP but also enhances robustness. Through extensive experiments across multiple\ntasks and benchmarks, we establish the validity of our approach. Our findings\nintroduce a novel perspective on neural network training and open new research\ndirections for leveraging biologically inspired learning rules in deep\nlearning.",
      "tldr_zh": "本文研究发现，虽然 Backpropagation (BP) 是神经网络训练的主流方法，但替代方法如 feedback alignment 由于生物学上的吸引力却表现不如 BP，导致研究兴趣下降。作者提出了一种新策略：使用 Sign-Symmetry learning rules 对 BP 预训练模型进行 fine-tuning，以整合这些生物启发规则。实验在多个任务和基准上验证，该方法不仅能与 BP 保持性能一致，还显著提升了模型的鲁棒性。该工作为神经网络训练提供了新视角，并开启了利用生物启发学习规则的深度学习研究方向。",
      "categories": [
        "cs.LG",
        "cs.AI"
      ],
      "primary_category": "cs.LG",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2502.05925v1",
      "published_date": "2025-02-09 14:59:57 UTC",
      "updated_date": "2025-02-09 14:59:57 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-22T09:07:02.779195"
    },
    {
      "arxiv_id": "2502.06898v1",
      "title": "Large Language Models for In-File Vulnerability Localization Can Be \"Lost in the End\"",
      "title_zh": "大语言模型用于文件内漏洞定位可能会“迷失在结",
      "authors": [
        "Francesco Sovrano",
        "Adam Bauer",
        "Alberto Bacchelli"
      ],
      "abstract": "Recent advancements in artificial intelligence have enabled processing of\nlarger inputs, leading everyday software developers to increasingly rely on\nchat-based large language models (LLMs) like GPT-3.5 and GPT-4 to detect\nvulnerabilities across entire files, not just within functions. This new\ndevelopment practice requires researchers to urgently investigate whether\ncommonly used LLMs can effectively analyze large file-sized inputs, in order to\nprovide timely insights for software developers and engineers about the pros\nand cons of this emerging technological trend. Hence, the goal of this paper is\nto evaluate the effectiveness of several state-of-the-art chat-based LLMs,\nincluding the GPT models, in detecting in-file vulnerabilities. We conducted a\ncostly investigation into how the performance of LLMs varies based on\nvulnerability type, input size, and vulnerability location within the file. To\ngive enough statistical power to our study, we could only focus on the three\nmost common (as well as dangerous) vulnerabilities: XSS, SQL injection, and\npath traversal. Our findings indicate that the effectiveness of LLMs in\ndetecting these vulnerabilities is strongly influenced by both the location of\nthe vulnerability and the overall size of the input. Specifically, regardless\nof the vulnerability type, LLMs tend to significantly (p < .05) underperform\nwhen detecting vulnerabilities located toward the end of larger files, a\npattern we call the 'lost-in-the-end' effect. Finally, to further support\nsoftware developers and practitioners, we also explored the optimal input size\nfor these LLMs and presented a simple strategy for identifying it, which can be\napplied to other models and vulnerability types. Eventually, we show how\nadjusting the input size can lead to significant improvements in LLM-based\nvulnerability detection, with an average recall increase of over 37% across all\nmodels.",
      "tldr_zh": "本文评估了聊天式Large Language Models (LLMs)，如GPT-3.5和GPT-4，在检测文件级漏洞（包括XSS、SQL injection和path traversal）时的有效性，通过实验分析了漏洞类型、输入大小和位置的影响。研究发现，LLMs在处理较大文件时，检测位于文件末尾的漏洞时显著（p < .05）表现不佳，称之为\"lost-in-the-end\" effect。最终，作者提出优化输入大小的简单策略，可使LLMs的漏洞检测召回率平均提高超过37%。",
      "categories": [
        "cs.SE",
        "cs.AI"
      ],
      "primary_category": "cs.SE",
      "comment": "Accepted for publication at the ACM International Conference on the\n  Foundations of Software Engineering (FSE) 2025. Replication Package:\n  https://doi.org/10.5281/zenodo.14840519",
      "pdf_url": "http://arxiv.org/pdf/2502.06898v1",
      "published_date": "2025-02-09 14:51:15 UTC",
      "updated_date": "2025-02-09 14:51:15 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-22T09:07:14.535752"
    },
    {
      "arxiv_id": "2502.10436v4",
      "title": "MERGE$^3$: Efficient Evolutionary Merging on Consumer-grade GPUs",
      "title_zh": "翻译失败",
      "authors": [
        "Tommaso Mencattini",
        "Adrian Robert Minut",
        "Donato Crisostomi",
        "Andrea Santilli",
        "Emanuele Rodolà"
      ],
      "abstract": "Evolutionary model merging enables the creation of high-performing multi-task\nmodels but remains computationally prohibitive for consumer hardware. We\nintroduce MERGE$^3$, an efficient framework that makes evolutionary merging\nfeasible on a single GPU by reducing fitness computation costs 50$\\times$ while\npreserving performance. MERGE$^3$ achieves this by Extracting a reduced dataset\nfor evaluation, Estimating model abilities using Item Response Theory (IRT),\nand Evolving optimal merges via IRT-based performance estimators. Our method\nenables state-of-the-art multilingual and cross-lingual merging, transferring\nknowledge across languages with significantly lower computational overhead. We\nprovide theoretical guarantees and an open-source library, democratizing\nhigh-quality model merging.",
      "tldr_zh": "该论文提出 MERGE³ 框架，通过降低计算成本 50 倍，使进化模型合并在消费级 GPU 上变得高效可行，同时保持模型性能。框架的关键方法包括提取简化数据集进行评估、使用 Item Response Theory (IRT) 估计模型能力，以及通过 IRT 基于性能估计器进化最佳合并，从而实现最先进的多种语言和跨语言知识转移。实验结果显示，该方法在多任务模型合并中表现出色，并提供了理论保证和开源库，促进高品质模型合并的普及。",
      "categories": [
        "cs.NE",
        "cs.AI",
        "cs.LG"
      ],
      "primary_category": "cs.NE",
      "comment": "In Proceedings of The Forty-Second International Conference on\n  Machine Learning (ICML 2025)",
      "pdf_url": "http://arxiv.org/pdf/2502.10436v4",
      "published_date": "2025-02-09 14:24:16 UTC",
      "updated_date": "2025-05-09 08:38:05 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-22T09:07:26.930711"
    },
    {
      "arxiv_id": "2502.06897v1",
      "title": "PyPotteryInk: One-Step Diffusion Model for Sketch to Publication-ready Archaeological Drawings",
      "title_zh": "翻译失败",
      "authors": [
        "Lorenzo Cardarelli"
      ],
      "abstract": "Archaeological pottery documentation traditionally requires a time-consuming\nmanual process of converting pencil sketches into publication-ready inked\ndrawings. I present PyPotteryInk, an open-source automated pipeline that\ntransforms archaeological pottery sketches into standardised publication-ready\ndrawings using a one-step diffusion model. Built on a modified img2img-turbo\narchitecture, the system processes drawings in a single forward pass while\npreserving crucial morphological details and maintaining archaeologic\ndocumentation standards and analytical value. The model employs an efficient\npatch-based approach with dynamic overlap, enabling high-resolution output\nregardless of input drawing size. I demonstrate the effectiveness of the\napproach on a dataset of Italian protohistoric pottery drawings, where it\nsuccessfully captures both fine details like decorative patterns and structural\nelements like vessel profiles or handling elements. Expert evaluation confirms\nthat the generated drawings meet publication standards while significantly\nreducing processing time from hours to seconds per drawing. The model can be\nfine-tuned to adapt to different archaeological contexts with minimal training\ndata, making it versatile across various pottery documentation styles. The\npre-trained models, the Python library and comprehensive documentation are\nprovided to facilitate adoption within the archaeological research community.",
      "tldr_zh": "这篇论文介绍了PyPotteryInk，一个开源自动化管道，使用一步diffusion model将考古陶器草图转换为标准化的出版-ready图，显著简化了传统耗时的手动过程。基于修改的img2img-turbo架构，该系统采用高效的patch-based动态重叠方法，在单次前向传递中处理图像，确保保留关键形态细节如装饰图案和器皿轮廓，同时符合考古文档标准。实验在意大利前史陶器数据集上显示，PyPotteryInk能准确捕捉细微结构，将处理时间从小时缩短到秒，并经专家评估符合出版要求；此外，该模型易于微调适应不同考古背景，并提供预训练模型、Python库和文档以促进社区采用。",
      "categories": [
        "cs.GR",
        "cs.AI",
        "cs.CV"
      ],
      "primary_category": "cs.GR",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2502.06897v1",
      "published_date": "2025-02-09 14:03:37 UTC",
      "updated_date": "2025-02-09 14:03:37 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-22T09:07:41.390844"
    },
    {
      "arxiv_id": "2502.17456v1",
      "title": "Survey on Recent Progress of AI for Chemistry: Methods, Applications, and Opportunities",
      "title_zh": "翻译失败",
      "authors": [
        "Hu Ding",
        "Pengxiang Hua",
        "Zhen Huang"
      ],
      "abstract": "The development of artificial intelligence (AI) techniques has brought\nrevolutionary changes across various realms. In particular, the use of\nAI-assisted methods to accelerate chemical research has become a popular and\nrapidly growing trend, leading to numerous groundbreaking works. In this paper,\nwe provide a comprehensive review of current AI techniques in chemistry from a\ncomputational perspective, considering various aspects in the design of\nmethods. We begin by discussing the characteristics of data from diverse\nsources, followed by an overview of various representation methods. Next, we\nreview existing models for several topical tasks in the field, and conclude by\nhighlighting some key challenges that warrant further attention.",
      "tldr_zh": "这篇论文对人工智能(AI) 在化学领域的最新进展进行了全面综述，从计算视角探讨方法设计和应用。论文首先分析了来自不同来源的数据特性，然后概述了各种表示方法，并审视了现有模型在化学关键任务中的表现。最后，它强调了亟待关注的挑战，并指出了未来机会，以推动AI辅助化学研究的创新。",
      "categories": [
        "physics.chem-ph",
        "cs.AI",
        "cs.LG"
      ],
      "primary_category": "physics.chem-ph",
      "comment": "22 pages, 8 figures, 4 tables",
      "pdf_url": "http://arxiv.org/pdf/2502.17456v1",
      "published_date": "2025-02-09 13:39:49 UTC",
      "updated_date": "2025-02-09 13:39:49 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-22T09:07:49.360804"
    },
    {
      "arxiv_id": "2502.05892v1",
      "title": "A Distributional Perspective on Word Learning in Neural Language Models",
      "title_zh": "翻译失败",
      "authors": [
        "Filippo Ficarra",
        "Ryan Cotterell",
        "Alex Warstadt"
      ],
      "abstract": "Language models (LMs) are increasingly being studied as models of human\nlanguage learners. Due to the nascency of the field, it is not well-established\nwhether LMs exhibit similar learning dynamics to humans, and there are few\ndirect comparisons between learning trajectories in humans and models. Word\nlearning trajectories for children are relatively well-documented, and recent\nwork has tried to extend these investigations to language models. However,\nthere are no widely agreed-upon metrics for word learning in language models.\nWe take a distributional approach to this problem, defining lexical knowledge\nin terms of properties of the learned distribution for a target word. We argue\nthat distributional signatures studied in prior work fail to capture key\ndistributional information. Thus, we propose an array of signatures that\nimprove on earlier approaches by capturing knowledge of both where the target\nword can and cannot occur as well as gradient preferences about the word's\nappropriateness. We obtain learning trajectories for a selection of small\nlanguage models we train from scratch, study the relationship between different\ndistributional signatures, compare how well they align with human word learning\ntrajectories and interpretable lexical features, and address basic\nmethodological questions about estimating these distributional signatures. Our\nmetrics largely capture complementary information, suggesting that it is\nimportant not to rely on a single metric. However, across all metrics, language\nmodels' learning trajectories fail to correlate with those of children.",
      "tldr_zh": "本文从分布视角探讨神经语言模型（LMs）中的单词学习问题，提出新的分布签名（distributional signatures）来评估词汇知识，这些签名不仅捕捉单词出现与不出现的位置，还包括梯度偏好。作者训练小型语言模型，分析其学习轨迹，并与人类儿童的单词学习轨迹进行比较，结果显示不同签名捕捉了互补信息，但LMs的学习轨迹整体上与人类不相关。该研究强调了使用多指标评估的重要性，以更好地理解模型与人类学习动态的差异。",
      "categories": [
        "cs.CL",
        "cs.AI"
      ],
      "primary_category": "cs.CL",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2502.05892v1",
      "published_date": "2025-02-09 13:15:59 UTC",
      "updated_date": "2025-02-09 13:15:59 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-22T09:08:02.304556"
    },
    {
      "arxiv_id": "2502.18483v1",
      "title": "Modeling Churn in Recommender Systems with Aggregated Preferences",
      "title_zh": "翻译失败",
      "authors": [
        "Gur Keinan",
        "Omer Ben-Porat"
      ],
      "abstract": "While recommender systems (RSs) traditionally rely on extensive individual\nuser data, regulatory and technological shifts necessitate reliance on\naggregated user information. This shift significantly impacts the\nrecommendation process, requiring RSs to engage in intensive exploration to\nidentify user preferences. However, this approach risks user churn due to\npotentially unsatisfactory recommendations. In this paper, we propose a model\nthat addresses the dual challenges of leveraging aggregated user information\nand mitigating churn risk. Our model assumes that the RS operates with a\nprobabilistic prior over user types and aggregated satisfaction levels for\nvarious content types. We demonstrate that optimal policies naturally\ntransition from exploration to exploitation in finite time, develop a\nbranch-and-bound algorithm for computing these policies, and empirically\nvalidate its effectiveness.",
      "tldr_zh": "推荐系统（RSs）传统依赖个人用户数据，但由于监管和技术变化，转向使用聚合用户信息，这增加了探索需求并可能导致用户流失（churn）。本文提出一个模型，假设RSs拥有用户类型的概率先验和各种内容类型的聚合满意度水平，以同时处理聚合信息利用和churn风险缓解。模型证明最优策略会在有限时间内从exploration过渡到exploitation，并开发了branch-and-bound算法来计算这些策略，并通过实验验证其有效性。",
      "categories": [
        "cs.IR",
        "cs.AI",
        "cs.LG"
      ],
      "primary_category": "cs.IR",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2502.18483v1",
      "published_date": "2025-02-09 13:12:11 UTC",
      "updated_date": "2025-02-09 13:12:11 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-22T09:08:14.231960"
    },
    {
      "arxiv_id": "2502.05887v1",
      "title": "MTPChat: A Multimodal Time-Aware Persona Dataset for Conversational Agents",
      "title_zh": "翻译失败",
      "authors": [
        "Wanqi Yang",
        "Yanda Li",
        "Meng Fang",
        "Ling Chen"
      ],
      "abstract": "Understanding temporal dynamics is critical for conversational agents,\nenabling effective content analysis and informed decision-making. However,\ntime-aware datasets, particularly for persona-grounded conversations, are still\nlimited, which narrows their scope and diminishes their complexity. To address\nthis gap, we introduce MTPChat, a multimodal, time-aware persona dialogue\ndataset that integrates linguistic, visual, and temporal elements within\ndialogue and persona memory. Leveraging MTPChat, we propose two time-sensitive\ntasks: Temporal Next Response Prediction (TNRP) and Temporal Grounding Memory\nPrediction (TGMP), both designed to assess a model's ability to understand\nimplicit temporal cues and dynamic interactions. Additionally, we present an\ninnovative framework featuring an adaptive temporal module to effectively\nintegrate multimodal streams and capture temporal dependencies. Experimental\nresults validate the challenges posed by MTPChat and demonstrate the\neffectiveness of our framework in multimodal time-sensitive scenarios.",
      "tldr_zh": "该研究引入了MTPChat数据集，这是一个多模态、时间感知的基于角色对话数据集，整合了语言、视觉和时间元素，以解决现有时间感知对话数据集的局限性。研究提出两个时间敏感任务：Temporal Next Response Prediction (TNRP)和Temporal Grounding Memory Prediction (TGMP)，用于评估模型对隐式时间线索和动态交互的理解能力。同时，他们设计了一个创新框架，包含自适应时间模块，用于有效整合多模态信息并捕捉时间依赖性。实验结果证明了MTPChat数据集的挑战性，并验证了框架在多模态时间敏感场景中的有效性。",
      "categories": [
        "cs.CL",
        "cs.AI"
      ],
      "primary_category": "cs.CL",
      "comment": "NAACL 2025 Findings",
      "pdf_url": "http://arxiv.org/pdf/2502.05887v1",
      "published_date": "2025-02-09 13:00:53 UTC",
      "updated_date": "2025-02-09 13:00:53 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-22T09:08:26.158040"
    },
    {
      "arxiv_id": "2502.05883v1",
      "title": "NeuralPrefix: A Zero-shot Sensory Data Imputation Plugin",
      "title_zh": "NeuralPrefix：零-shot 传感器数据插值插件",
      "authors": [
        "Abdelwahed Khamis",
        "Sara Khalifa"
      ],
      "abstract": "Real-world sensing challenges such as sensor failures, communication issues,\nand power constraints lead to data intermittency. An issue that is known to\nundermine the traditional classification task that assumes a continuous data\nstream. Previous works addressed this issue by designing bespoke solutions\n(i.e. task-specific and/or modality-specific imputation). These approaches,\nwhile effective for their intended purposes, had limitations in their\napplicability across different tasks and sensor modalities. This raises an\nimportant question: Can we build a task-agnostic imputation pipeline that is\ntransferable to new sensors without requiring additional training? In this\nwork, we formalise the concept of zero-shot imputation and propose a novel\napproach that enables the adaptation of pre-trained models to handle data\nintermittency. This framework, named NeuralPrefix, is a generative neural\ncomponent that precedes a task model during inference, filling in gaps caused\nby data intermittency. NeuralPrefix is built as a continuous dynamical system,\nwhere its internal state can be estimated at any point in time by solving an\nOrdinary Differential Equation (ODE). This approach allows for a more versatile\nand adaptable imputation method, overcoming the limitations of task-specific\nand modality-specific solutions. We conduct a comprehensive evaluation of\nNeuralPrefix on multiple sensory datasets, demonstrating its effectiveness\nacross various domains. When tested on intermittent data with a high 50%\nmissing data rate, NeuralPreifx accurately recovers all the missing samples,\nachieving SSIM score between 0.93-0.96. Zero-shot evaluations show that\nNeuralPrefix generalises well to unseen datasets, even when the measurements\ncome from a different modality.",
      "tldr_zh": "论文针对传感器数据间断性问题（如传感器故障和通信问题），提出了一种零-shot imputation 方法，即 NeuralPrefix，这是一个任务无关的生成神经组件，能够在推理阶段填充缺失数据，而无需额外训练。NeuralPrefix 构建为一个连续动态系统，通过求解 Ordinary Differential Equation (ODE) 来估计内部状态，从而实现对不同传感器模态的适应。实验评估显示，在多个数据集上，当数据缺失率高达 50% 时，NeuralPrefix 准确恢复了所有缺失样本，SSIM 分数达到 0.93-0.96，并展示了优秀的零-shot 泛化能力，即使应用于未见过的数据集和模态。",
      "categories": [
        "cs.LG",
        "cs.AI",
        "stat.ML"
      ],
      "primary_category": "cs.LG",
      "comment": "Accepted in PerCom 25",
      "pdf_url": "http://arxiv.org/pdf/2502.05883v1",
      "published_date": "2025-02-09 12:47:55 UTC",
      "updated_date": "2025-02-09 12:47:55 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-22T09:08:39.076090"
    },
    {
      "arxiv_id": "2502.06894v1",
      "title": "AI-Driven HSI: Multimodality, Fusion, Challenges, and the Deep Learning Revolution",
      "title_zh": "AI驱动的HSI：多模态、融合、挑战，以及深度学习革命",
      "authors": [
        "David S. Bhatti",
        "Yougin Choi",
        "Rahman S M Wahidur",
        "Maleeka Bakhtawar",
        "Sumin Kim",
        "Surin Lee",
        "Yongtae Lee",
        "Heung-No Lee"
      ],
      "abstract": "Hyperspectral imaging (HSI) captures spatial and spectral data, enabling\nanalysis of features invisible to conventional systems. The technology is vital\nin fields such as weather monitoring, food quality control, counterfeit\ndetection, healthcare diagnostics, and extending into defense, agriculture, and\nindustrial automation at the same time. HSI has advanced with improvements in\nspectral resolution, miniaturization, and computational methods. This study\nprovides an overview of the HSI, its applications, challenges in data fusion\nand the role of deep learning models in processing HSI data. We discuss how\nintegration of multimodal HSI with AI, particularly with deep learning,\nimproves classification accuracy and operational efficiency. Deep learning\nenhances HSI analysis in areas like feature extraction, change detection,\ndenoising unmixing, dimensionality reduction, landcover mapping, data\naugmentation, spectral construction and super resolution. An emerging focus is\nthe fusion of hyperspectral cameras with large language models (LLMs), referred\nas highbrain LLMs, enabling the development of advanced applications such as\nlow visibility crash detection and face antispoofing. We also highlight key\nplayers in HSI industry, its compound annual growth rate and the growing\nindustrial significance. The purpose is to offer insight to both technical and\nnon-technical audience, covering HSI's images, trends, and future directions,\nwhile providing valuable information on HSI datasets and software libraries.",
      "tldr_zh": "这篇论文概述了超光谱成像（HSI）的关键进展及其在多领域应用，如天气监测、食品质量控制、医疗诊断和国防等领域。论文强调了HSI面临的挑战，包括数据融合问题，并探讨了深度学习模型在处理HSI数据中的作用，如特征提取、变化检测、去噪和降维，从而提升分类准确性和操作效率。特别突出的是，将HSI与AI融合，尤其是与大型语言模型（LLMs）结合的“highbrain LLMs”技术，推动新兴应用如低可见度碰撞检测和人脸反欺骗。论文还分析了HSI行业的增长趋势、关键参与者和未来方向，并提供相关数据集和软件库的见解，为技术和非技术观众提供全面指导。",
      "categories": [
        "cs.CV",
        "cs.AI",
        "68T07 Artificial neural networks and deep learning"
      ],
      "primary_category": "cs.CV",
      "comment": "39 Pages, 22 figures, 20 tables",
      "pdf_url": "http://arxiv.org/pdf/2502.06894v1",
      "published_date": "2025-02-09 12:44:16 UTC",
      "updated_date": "2025-02-09 12:44:16 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-22T09:08:51.580232"
    },
    {
      "arxiv_id": "2502.05879v1",
      "title": "Enhancing Depression Detection with Chain-of-Thought Prompting: From Emotion to Reasoning Using Large Language Models",
      "title_zh": "翻译失败",
      "authors": [
        "Shiyu Teng",
        "Jiaqing Liu",
        "Rahul Kumar Jain",
        "Shurong Chai",
        "Ruibo Hou",
        "Tomoko Tateyama",
        "Lanfen Lin",
        "Yen-wei Chen"
      ],
      "abstract": "Depression is one of the leading causes of disability worldwide, posing a\nsevere burden on individuals, healthcare systems, and society at large. Recent\nadvancements in Large Language Models (LLMs) have shown promise in addressing\nmental health challenges, including the detection of depression through\ntext-based analysis. However, current LLM-based methods often struggle with\nnuanced symptom identification and lack a transparent, step-by-step reasoning\nprocess, making it difficult to accurately classify and explain mental health\nconditions. To address these challenges, we propose a Chain-of-Thought\nPrompting approach that enhances both the performance and interpretability of\nLLM-based depression detection. Our method breaks down the detection process\ninto four stages: (1) sentiment analysis, (2) binary depression classification,\n(3) identification of underlying causes, and (4) assessment of severity. By\nguiding the model through these structured reasoning steps, we improve\ninterpretability and reduce the risk of overlooking subtle clinical indicators.\nWe validate our method on the E-DAIC dataset, where we test multiple\nstate-of-the-art large language models. Experimental results indicate that our\nChain-of-Thought Prompting technique yields superior performance in both\nclassification accuracy and the granularity of diagnostic insights, compared to\nbaseline approaches.",
      "tldr_zh": "该研究针对大型语言模型（LLMs）在抑郁症检测中的不足，如微妙症状识别和缺乏透明推理，提出Chain-of-Thought Prompting方法来提升性能和可解释性。该方法将检测过程分为四个阶段：情感分析（sentiment analysis）、二元抑郁分类（binary depression classification）、潜在原因识别和严重程度评估，从而提供结构化的推理步骤，减少忽略临床指标的风险。在E-DAIC数据集上测试多种最先进LLMs后，实验结果显示，该技术在分类准确性和诊断洞察的粒度上均优于基线方法，为基于LLMs的心理健康分析提供了更可靠的框架。",
      "categories": [
        "cs.CL",
        "cs.AI"
      ],
      "primary_category": "cs.CL",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2502.05879v1",
      "published_date": "2025-02-09 12:30:57 UTC",
      "updated_date": "2025-02-09 12:30:57 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-22T09:09:03.128198"
    },
    {
      "arxiv_id": "2502.05874v3",
      "title": "MMGDreamer: Mixed-Modality Graph for Geometry-Controllable 3D Indoor Scene Generation",
      "title_zh": "翻译失败",
      "authors": [
        "Zhifei Yang",
        "Keyang Lu",
        "Chao Zhang",
        "Jiaxing Qi",
        "Hanqi Jiang",
        "Ruifei Ma",
        "Shenglin Yin",
        "Yifan Xu",
        "Mingzhe Xing",
        "Zhen Xiao",
        "Jieyi Long",
        "Guangyao Zhai"
      ],
      "abstract": "Controllable 3D scene generation has extensive applications in virtual\nreality and interior design, where the generated scenes should exhibit high\nlevels of realism and controllability in terms of geometry. Scene graphs\nprovide a suitable data representation that facilitates these applications.\nHowever, current graph-based methods for scene generation are constrained to\ntext-based inputs and exhibit insufficient adaptability to flexible user\ninputs, hindering the ability to precisely control object geometry. To address\nthis issue, we propose MMGDreamer, a dual-branch diffusion model for scene\ngeneration that incorporates a novel Mixed-Modality Graph, visual enhancement\nmodule, and relation predictor. The mixed-modality graph allows object nodes to\nintegrate textual and visual modalities, with optional relationships between\nnodes. It enhances adaptability to flexible user inputs and enables meticulous\ncontrol over the geometry of objects in the generated scenes. The visual\nenhancement module enriches the visual fidelity of text-only nodes by\nconstructing visual representations using text embeddings. Furthermore, our\nrelation predictor leverages node representations to infer absent relationships\nbetween nodes, resulting in more coherent scene layouts. Extensive experimental\nresults demonstrate that MMGDreamer exhibits superior control of object\ngeometry, achieving state-of-the-art scene generation performance. Project\npage: https://yangzhifeio.github.io/project/MMGDreamer.",
      "tldr_zh": "本研究提出 MMGDreamer，一种双分支扩散模型，用于可控的 3D 室内场景生成，旨在通过 Mixed-Modality Graph 提升场景的几何精确性和适应性。Mixed-Modality Graph 允许对象节点整合文本和视觉模态，并处理节点间的可选关系，从而实现对用户灵活输入的响应和对象几何的精细控制。论文还引入 visual enhancement module 来增强文本-only 节点的视觉保真度，以及 relation predictor 来基于节点表示推断缺失关系，提高场景布局的连贯性。实验结果表明，MMGDreamer 在几何控制方面表现出色，达到了最先进的场景生成性能。",
      "categories": [
        "cs.CV",
        "cs.AI",
        "cs.LG"
      ],
      "primary_category": "cs.CV",
      "comment": "Accepted by AAAI 2025 Main Track",
      "pdf_url": "http://arxiv.org/pdf/2502.05874v3",
      "published_date": "2025-02-09 12:23:40 UTC",
      "updated_date": "2025-03-26 11:27:37 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-22T09:09:14.484815"
    },
    {
      "arxiv_id": "2502.06892v1",
      "title": "Certifying Language Model Robustness with Fuzzed Randomized Smoothing: An Efficient Defense Against Backdoor Attacks",
      "title_zh": "翻译失败",
      "authors": [
        "Bowei He",
        "Lihao Yin",
        "Hui-Ling Zhen",
        "Jianping Zhang",
        "Lanqing Hong",
        "Mingxuan Yuan",
        "Chen Ma"
      ],
      "abstract": "The widespread deployment of pre-trained language models (PLMs) has exposed\nthem to textual backdoor attacks, particularly those planted during the\npre-training stage. These attacks pose significant risks to high-reliability\napplications, as they can stealthily affect multiple downstream tasks. While\ncertifying robustness against such threats is crucial, existing defenses\nstruggle with the high-dimensional, interdependent nature of textual data and\nthe lack of access to original poisoned pre-training data. To address these\nchallenges, we introduce \\textbf{F}uzzed \\textbf{R}andomized \\textbf{S}moothing\n(\\textbf{FRS}), a novel approach for efficiently certifying language model\nrobustness against backdoor attacks. FRS integrates software robustness\ncertification techniques with biphased model parameter smoothing, employing\nMonte Carlo tree search for proactive fuzzing to identify vulnerable textual\nsegments within the Damerau-Levenshtein space. This allows for targeted and\nefficient text randomization, while eliminating the need for access to poisoned\ntraining data during model smoothing. Our theoretical analysis demonstrates\nthat FRS achieves a broader certified robustness radius compared to existing\nmethods. Extensive experiments across various datasets, model configurations,\nand attack strategies validate FRS's superiority in terms of defense\nefficiency, accuracy, and robustness.",
      "tldr_zh": "该研究针对预训练语言模型（PLMs）面临的后门攻击提出了一种高效防御方法，即Fuzzed Randomized Smoothing（FRS）。FRS 通过整合软件鲁棒性认证技术和双阶段模型参数平滑，使用Monte Carlo树搜索进行主动模糊（fuzzing），以识别Damerau-Levenshtein空间中的易受攻击文本段，实现针对性的文本随机化，而无需访问原始中毒训练数据。理论分析显示，FRS 比现有方法提供更宽的认证鲁棒性半径；在各种数据集、模型配置和攻击策略的实验中，FRS 展示了显著的防御效率、准确性和鲁棒性提升。",
      "categories": [
        "cs.LG",
        "cs.AI"
      ],
      "primary_category": "cs.LG",
      "comment": "Accepted by ICLR 2025",
      "pdf_url": "http://arxiv.org/pdf/2502.06892v1",
      "published_date": "2025-02-09 12:03:59 UTC",
      "updated_date": "2025-02-09 12:03:59 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-22T09:09:26.336874"
    },
    {
      "arxiv_id": "2502.05863v2",
      "title": "Uni-Retrieval: A Multi-Style Retrieval Framework for STEM's Education",
      "title_zh": "翻译失败",
      "authors": [
        "Yanhao Jia",
        "Xinyi Wu",
        "Hao Li",
        "Qinglin Zhang",
        "Yuxiao Hu",
        "Shuai Zhao",
        "Wenqi Fan"
      ],
      "abstract": "In AI-facilitated teaching, leveraging various query styles to interpret\nabstract text descriptions is crucial for ensuring high-quality teaching.\nHowever, current retrieval models primarily focus on natural text-image\nretrieval, making them insufficiently tailored to educational scenarios due to\nthe ambiguities in the retrieval process. In this paper, we propose a diverse\nexpression retrieval task tailored to educational scenarios, supporting\nretrieval based on multiple query styles and expressions. We introduce the STEM\nEducation Retrieval Dataset (SER), which contains over 24,000 query pairs of\ndifferent styles, and the Uni-Retrieval, an efficient and style-diversified\nretrieval vision-language model based on prompt tuning. Uni-Retrieval extracts\nquery style features as prototypes and builds a continuously updated Prompt\nBank containing prompt tokens for diverse queries. This bank can updated during\ntest time to represent domain-specific knowledge for different subject\nretrieval scenarios. Our framework demonstrates scalability and robustness by\ndynamically retrieving prompt tokens based on prototype similarity, effectively\nfacilitating learning for unknown queries. Experimental results indicate that\nUni-Retrieval outperforms existing retrieval models in most retrieval tasks.\nThis advancement provides a scalable and precise solution for diverse\neducational needs.",
      "tldr_zh": "本文提出 Uni-Retrieval，一种多样式检索框架，针对 STEM 教育场景中的抽象文本描述问题，支持基于多种查询样式和表达的检索任务，以提升 AI 辅助教学质量。该框架通过 prompt tuning 提取查询样式特征作为原型，并构建一个可动态更新的 Prompt Bank，用于适应不同领域的知识和未知查询。作者引入了包含超过 24,000 对查询对的 STEM Education Retrieval Dataset (SER)，实验结果显示 Uni-Retrieval 在大多数检索任务中优于现有模型，提供了一个可扩展且精确的教育解决方案。",
      "categories": [
        "cs.IR",
        "cs.AI",
        "cs.MM"
      ],
      "primary_category": "cs.IR",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2502.05863v2",
      "published_date": "2025-02-09 11:46:05 UTC",
      "updated_date": "2025-05-20 12:37:05 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-22T09:09:39.483750"
    },
    {
      "arxiv_id": "2502.05857v2",
      "title": "EgoAgent: A Joint Predictive Agent Model in Egocentric Worlds",
      "title_zh": "翻译失败",
      "authors": [
        "Lu Chen",
        "Yizhou Wang",
        "Shixiang Tang",
        "Qianhong Ma",
        "Tong He",
        "Wanli Ouyang",
        "Xiaowei Zhou",
        "Hujun Bao",
        "Sida Peng"
      ],
      "abstract": "This paper addresses the task of learning an agent model behaving like\nhumans, which can jointly perceive, predict, and act in egocentric worlds.\nPrevious methods usually train separate models for these three abilities, which\nprevents them from learning from each other. In this paper, we propose a joint\npredictive agent model, named EgoAgent, that simultaneously learns to represent\nthe world, predict future states, and take reasonable actions within a single\ntransformer. EgoAgent introduces two innovations to learn from the causal and\ntemporally intertwined nature of these abilities: (1) Interleaved sequential\nmodeling of states and actions with the causal attention mechanism, and (2) A\njoint embedding-action-prediction architecture featuring temporal asymmetric\npredictor-observer branches. Integrating these designs based on JEPA, EgoAgent\nunifies these capabilities in a cohesive learning framework. Comprehensive\nevaluations of EgoAgent on representative tasks such as image classification,\negocentric future state prediction, and 3D human motion prediction tasks\ndemonstrate the superiority of our method. The code and trained model will be\nreleased for reproducibility.",
      "tldr_zh": "本文提出 EgoAgent，一种在 egocentric worlds 中联合感知、预测和行动的代理模型，旨在模拟人类行为，并通过单一 Transformer 框架学习这些能力，以克服传统方法的分离训练局限。EgoAgent 的创新包括：(1) 使用 causal attention mechanism 进行状态和行动的交错顺序建模，(2) 采用 joint embedding-action-prediction architecture 及其 temporal asymmetric predictor-observer branches，以捕捉因果和时间交织特性。基于 JEPA 框架的整合评估显示，EgoAgent 在图像分类、egocentric 未来状态预测和 3D 人类动作预测任务上显著优于基线方法，并将发布代码和模型以支持可重复性。",
      "categories": [
        "cs.CV",
        "cs.AI",
        "cs.LG"
      ],
      "primary_category": "cs.CV",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2502.05857v2",
      "published_date": "2025-02-09 11:28:57 UTC",
      "updated_date": "2025-04-29 15:45:49 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-22T09:09:51.020801"
    },
    {
      "arxiv_id": "2502.05836v1",
      "title": "LegalSeg: Unlocking the Structure of Indian Legal Judgments Through Rhetorical Role Classification",
      "title_zh": "LegalSeg：通过修辞角色分类揭示印度法律判决的结构",
      "authors": [
        "Shubham Kumar Nigam",
        "Tanmay Dubey",
        "Govind Sharma",
        "Noel Shallum",
        "Kripabandhu Ghosh",
        "Arnab Bhattacharya"
      ],
      "abstract": "In this paper, we address the task of semantic segmentation of legal\ndocuments through rhetorical role classification, with a focus on Indian legal\njudgments. We introduce LegalSeg, the largest annotated dataset for this task,\ncomprising over 7,000 documents and 1.4 million sentences, labeled with 7\nrhetorical roles. To benchmark performance, we evaluate multiple\nstate-of-the-art models, including Hierarchical BiLSTM-CRF,\nTransformerOverInLegalBERT (ToInLegalBERT), Graph Neural Networks (GNNs), and\nRole-Aware Transformers, alongside an exploratory RhetoricLLaMA, an\ninstruction-tuned large language model. Our results demonstrate that models\nincorporating broader context, structural relationships, and sequential\nsentence information outperform those relying solely on sentence-level\nfeatures. Additionally, we conducted experiments using surrounding context and\npredicted or actual labels of neighboring sentences to assess their impact on\nclassification accuracy. Despite these advancements, challenges persist in\ndistinguishing between closely related roles and addressing class imbalance.\nOur work underscores the potential of advanced techniques for improving legal\ndocument understanding and sets a strong foundation for future research in\nlegal NLP.",
      "tldr_zh": "本论文提出 LegalSeg 方法，通过修辞角色分类对印度法律判决书的语义进行分割，并引入最大的标注数据集 LegalSeg，包含超过 7,000 个文档和 1.4 百万句子，标注了 7 个修辞角色。研究评估了多种先进模型，包括 Hierarchical BiLSTM-CRF、TransformerOverInLegalBERT (ToInLegalBERT)、Graph Neural Networks (GNNs)、Role-Aware Transformers 和 RhetoricLLaMA，结果显示整合更广泛上下文、结构关系和顺序句子的模型在分类准确性上表现更佳。实验还考察了周围上下文和邻句标签的影响，尽管存在区分相近角色和处理类别不平衡的挑战，此工作为法律文档理解和未来法律 NLP 研究奠定了坚实基础。",
      "categories": [
        "cs.CL",
        "cs.AI",
        "cs.IR",
        "cs.LG"
      ],
      "primary_category": "cs.CL",
      "comment": "Accepted on NAACL 2025",
      "pdf_url": "http://arxiv.org/pdf/2502.05836v1",
      "published_date": "2025-02-09 10:07:05 UTC",
      "updated_date": "2025-02-09 10:07:05 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-22T09:10:03.506954"
    },
    {
      "arxiv_id": "2502.05835v1",
      "title": "Contrastive Representation Distillation via Multi-Scale Feature Decoupling",
      "title_zh": "基于多尺度特征解耦的对比性表示蒸馏",
      "authors": [
        "Cuipeng Wang",
        "Tieyuan Chen",
        "Haipeng Wang"
      ],
      "abstract": "Knowledge distillation is a technique aimed at enhancing the performance of a\nsmaller student network without increasing its parameter size by transferring\nknowledge from a larger, pre-trained teacher network. Previous approaches have\npredominantly focused on distilling global feature information while\noverlooking the importance of disentangling the diverse types of information\nembedded within different regions of the feature. In this work, we introduce\nmulti-scale decoupling in the feature transfer process for the first time,\nwhere the decoupled local features are individually processed and integrated\nwith contrastive learning. Moreover, compared to previous contrastive\nlearning-based distillation methods, our approach not only reduces\ncomputational costs but also enhances efficiency, enabling performance\nimprovements for the student network using only single-batch samples. Extensive\nevaluations on CIFAR-100 and ImageNet demonstrate our method's superiority,\nwith some student networks distilled using our method even surpassing the\nperformance of their pre-trained teacher networks. These results underscore the\neffectiveness of our approach in enabling student networks to thoroughly absorb\nknowledge from teacher networks.",
      "tldr_zh": "本文提出了一种名为“Contrastive Representation Distillation via Multi-Scale Feature Decoupling”的知识蒸馏方法，通过首次引入多尺度特征解耦(multi-scale decoupling)来处理特征转移过程，将解耦的局部特征单独处理并与对比学习(contrastive learning)整合，从而提升学生网络的性能，同时减少计算成本并仅需单批样本。相比以往方法，该方法使学生网络能够更高效地吸收教师网络的知识。实验在CIFAR-100和ImageNet数据集上显示，该方法显著优于基线模型，有些学生网络甚至超过了预训练教师网络的性能，这证明了其在知识蒸馏领域的有效性和潜力。",
      "categories": [
        "cs.CV",
        "cs.AI"
      ],
      "primary_category": "cs.CV",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2502.05835v1",
      "published_date": "2025-02-09 10:03:18 UTC",
      "updated_date": "2025-02-09 10:03:18 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-22T09:10:14.802588"
    },
    {
      "arxiv_id": "2502.06890v1",
      "title": "LLMs for Drug-Drug Interaction Prediction: A Comprehensive Comparison",
      "title_zh": "大语言模型用于药物-药物相互作用预测：全面比较",
      "authors": [
        "Gabriele De Vito",
        "Filomena Ferrucci",
        "Athanasios Angelakis"
      ],
      "abstract": "The increasing volume of drug combinations in modern therapeutic regimens\nneeds reliable methods for predicting drug-drug interactions (DDIs). While\nLarge Language Models (LLMs) have revolutionized various domains, their\npotential in pharmaceutical research, particularly in DDI prediction, remains\nlargely unexplored. This study thoroughly investigates LLMs' capabilities in\npredicting DDIs by uniquely processing molecular structures (SMILES), target\norganisms, and gene interaction data as raw text input from the latest DrugBank\ndataset. We evaluated 18 different LLMs, including proprietary models (GPT-4,\nClaude, Gemini) and open-source variants (from 1.5B to 72B parameters), first\nassessing their zero-shot capabilities in DDI prediction. We then fine-tuned\nselected models (GPT-4, Phi-3.5 2.7B, Qwen-2.5 3B, Gemma-2 9B, and Deepseek R1\ndistilled Qwen 1.5B) to optimize their performance. Our comprehensive\nevaluation framework included validation across 13 external DDI datasets,\ncomparing against traditional approaches such as l2-regularized logistic\nregression. Fine-tuned LLMs demonstrated superior performance, with Phi-3.5\n2.7B achieving a sensitivity of 0.978 in DDI prediction, with an accuracy of\n0.919 on balanced datasets (50% positive, 50% negative cases). This result\nrepresents an improvement over both zero-shot predictions and state-of-the-art\nmachine-learning methods used for DDI prediction. Our analysis reveals that\nLLMs can effectively capture complex molecular interaction patterns and cases\nwhere drug pairs target common genes, making them valuable tools for practical\napplications in pharmaceutical research and clinical settings.",
      "tldr_zh": "这篇论文全面比较了大型语言模型 (LLMs) 在预测药物-药物相互作用 (DDIs) 中的性能，评估了 18 个模型（包括 GPT-4、Claude、Gemini 等专有模型，以及从 1.5B 到 72B 参数的开源变体）。研究使用 SMILES 分子结构、目标生物和基因交互数据作为原始文本输入，首先测试了 zero-shot 预测能力，然后对选定模型（如 GPT-4 和 Phi-3.5 2.7B）进行 fine-tuning，并与传统方法如 l2-regularized logistic regression 比较。结果显示，fine-tuned LLMs 显著提升了性能，Phi-3.5 2.7B 在平衡数据集上达到 0.978 的 sensitivity 和 0.919 的 accuracy，优于基线方法。总体而言，这证明 LLMs 能有效捕捉复杂的分子交互模式，为制药研究和临床应用提供可靠工具。",
      "categories": [
        "cs.LG",
        "cs.AI",
        "q-bio.QM"
      ],
      "primary_category": "cs.LG",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2502.06890v1",
      "published_date": "2025-02-09 09:58:12 UTC",
      "updated_date": "2025-02-09 09:58:12 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-22T09:10:29.456133"
    },
    {
      "arxiv_id": "2502.05832v1",
      "title": "Compressing Model with Few Class-Imbalance Samples: An Out-of-Distribution Expedition",
      "title_zh": "翻译失败",
      "authors": [
        "Tian-Shuang Wu",
        "Shen-Huan Lyu",
        "Ning Chen",
        "Zhihao Qu",
        "Baoliu Ye"
      ],
      "abstract": "In recent years, as a compromise between privacy and performance, few-sample\nmodel compression has been widely adopted to deal with limited data resulting\nfrom privacy and security concerns. However, when the number of available\nsamples is extremely limited, class imbalance becomes a common and tricky\nproblem. Achieving an equal number of samples across all classes is often\ncostly and impractical in real-world applications, and previous studies on\nfew-sample model compression have mostly ignored this significant issue. Our\nexperiments comprehensively demonstrate that class imbalance negatively affects\nthe overall performance of few-sample model compression methods. To address\nthis problem, we propose a novel and adaptive framework named OOD-Enhanced\nFew-Sample Model Compression (OE-FSMC). This framework integrates easily\naccessible out-of-distribution (OOD) data into both the compression and\nfine-tuning processes, effectively rebalancing the training distribution. We\nalso incorporate a joint distillation loss and a regularization term to reduce\nthe risk of the model overfitting to the OOD data. Extensive experiments on\nmultiple benchmark datasets show that our framework can be seamlessly\nincorporated into existing few-sample model compression methods, effectively\nmitigating the accuracy degradation caused by class imbalance.",
      "tldr_zh": "本研究探讨了在 few-sample model compression 中，class imbalance 问题如何导致性能下降，并指出现有方法忽略了这一关键挑战。提出了一种新型框架 OE-FSMC，通过整合易获取的 Out-of-Distribution (OOD) 数据到压缩和微调过程中，实现训练分布的重新平衡，同时引入联合蒸馏损失和正则化项以防止模型过拟合。在多个基准数据集上的实验显示，该框架可无缝整合到现有方法中，有效缓解 class imbalance 引起的准确率下降。",
      "categories": [
        "cs.LG",
        "cs.AI",
        "cs.CV"
      ],
      "primary_category": "cs.LG",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2502.05832v1",
      "published_date": "2025-02-09 09:47:23 UTC",
      "updated_date": "2025-02-09 09:47:23 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-22T09:10:39.028797"
    },
    {
      "arxiv_id": "2502.05827v2",
      "title": "HyGEN: Regularizing Negative Hyperedge Generation for Accurate Hyperedge Prediction",
      "title_zh": "HyGEN：正则化负面超边生成以实现准确超",
      "authors": [
        "Song Kyung Yu",
        "Da Eun Lee",
        "Yunyong Ko",
        "Sang-Wook Kim"
      ],
      "abstract": "Hyperedge prediction is a fundamental task to predict future high-order\nrelations based on the observed network structure. Existing hyperedge\nprediction methods, however, suffer from the data sparsity problem. To\nalleviate this problem, negative sampling methods can be used, which leverage\nnon-existing hyperedges as contrastive information for model training. However,\nthe following important challenges have been rarely studied: (C1) lack of\nguidance for generating negatives and (C2) possibility of producing false\nnegatives. To address them, we propose a novel hyperedge prediction method,\nHyGEN, that employs (1) a negative hyperedge generator that employs positive\nhyperedges as a guidance to generate more realistic ones and (2) a\nregularization term that prevents the generated hyperedges from being false\nnegatives. Extensive experiments on six real-world hypergraphs reveal that\nHyGEN consistently outperforms four state-of-the-art hyperedge prediction\nmethods.",
      "tldr_zh": "这篇论文针对超边预测（hyperedge prediction）中的数据稀疏问题，提出了HyGEN方法，通过一个负超边生成器（negative hyperedge generator）利用正超边作为指导生成更真实的负样本，并引入正则化项（regularization term）来防止产生假负样本（false negatives）。HyGEN有效缓解了现有方法的局限性，包括缺乏生成指导和假负样本风险。在六个真实世界超图（hypergraphs）上的广泛实验中，HyGEN consistently outperforms四种最先进的方法，证明了其在准确性上的显著提升。",
      "categories": [
        "cs.SI",
        "cs.AI"
      ],
      "primary_category": "cs.SI",
      "comment": "5 pages, 4 figures, 3 tables, the Web Conference (WWW) 2025",
      "pdf_url": "http://arxiv.org/pdf/2502.05827v2",
      "published_date": "2025-02-09 09:27:35 UTC",
      "updated_date": "2025-02-18 09:53:03 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-22T09:10:51.145749"
    },
    {
      "arxiv_id": "2502.05826v1",
      "title": "MindCraft: Revolutionizing Education through AI-Powered Personalized Learning and Mentorship for Rural India",
      "title_zh": "MindCraft：通过AI驱动的个性化学习和导师指导革新印度农村教育",
      "authors": [
        "Arihant Bardia",
        "Aayush Agrawal"
      ],
      "abstract": "MindCraft is a modern platform designed to revolutionize education in rural\nIndia by leveraging Artificial Intelligence (AI) to create personalized\nlearning experiences, provide mentorship, and foster resource-sharing. In a\ncountry where access to quality education is deeply influenced by geography and\nsocio economic status, rural students often face significant barriers in their\neducational journeys. MindCraft aims to bridge this gap by utilizing AI to\ncreate tailored learning paths, connect students with mentors, and enable a\ncollaborative network of educational resources that transcends both physical\nand digital divides. This paper explores the challenges faced by rural\nstudents, the transformative potential of AI, and how MindCraft offers a\nscalable, sustainable solution for equitable education system. By focusing on\ninclusivity, personalized learning, and mentorship, MindCraft seeks to empower\nrural students, equipping them with the skills, knowledge, and opportunities\nneeded to thrive in an increasingly digital world. Ultimately, MindCraft\nenvisions a future in which technology not only bridges educational gaps but\nalso becomes the driving force for a more inclusive and empowered society.",
      "tldr_zh": "MindCraft 是一个利用 AI 的平台，旨在革新印度农村教育，通过提供个性化 learning 和 mentorship 来克服地理和 socioeconomic 障碍。该平台创建定制的学习路径、连接学生与导师，并促进资源共享网络，以桥接教育鸿沟。论文探讨了农村学生的挑战，并强调 MindCraft 作为可扩展、可持续解决方案的潜力，最终推动更具包容性的社会赋权。",
      "categories": [
        "cs.CY",
        "cs.AI",
        "cs.ET"
      ],
      "primary_category": "cs.CY",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2502.05826v1",
      "published_date": "2025-02-09 09:26:03 UTC",
      "updated_date": "2025-02-09 09:26:03 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-22T09:11:02.039682"
    },
    {
      "arxiv_id": "2502.05825v1",
      "title": "Delta -- Contrastive Decoding Mitigates Text Hallucinations in Large Language Models",
      "title_zh": "翻译失败",
      "authors": [
        "Cheng Peng Huang",
        "Hao-Yuan Chen"
      ],
      "abstract": "Large language models (LLMs) demonstrate strong capabilities in natural\nlanguage processing but remain prone to hallucinations, generating factually\nincorrect or fabricated content. This issue undermines their reliability,\nparticularly in high-stakes domains such as healthcare and legal advisory. To\naddress this challenge, we propose Delta, an inference-time method that reduces\nhallucinations without requiring model retraining or additional data. Delta\nworks by randomly masking parts of the input prompt and contrasting the output\ndistributions for the original and masked inputs, effectively suppressing\nhallucinations through inference-only computations. We evaluate Delta on\ncontext-rich question-answering benchmarks, achieving absolute improvements of\napproximately 3 and 6 percentage points on SQuAD v1.1 and v2, respectively, and\n7 and 2 percentage points on TriviaQA and Natural Questions under-sampling\ndecoding. Delta also improves the no-answer exact match score on SQuAD v2 by\nover ten percentage points, demonstrating its effectiveness in mitigating\nhallucinations arising from contextual ambiguity. These results highlight Delta\nas a computationally efficient and scalable approach for improving the\nreliability of LLMs in real-world applications.",
      "tldr_zh": "大型语言模型（LLMs）容易产生文本幻觉，导致生成事实错误或虚构内容，影响其在医疗和法律等高风险领域的可靠性。为解决此问题，本文提出Delta，一种推理时的对比解码方法，通过随机屏蔽输入提示并对比原始和屏蔽输入的输出分布，来抑制幻觉，而无需模型重新训练或额外数据。在上下文丰富的问答基准测试中，Delta在SQuAD v1.1和v2上分别提高了约3和6个百分点的绝对性能，在TriviaQA和Natural Questions上也取得了7和2个百分点的改进，并将SQuAD v2的无答案精确匹配分数提升超过10个百分点。这些结果证明，Delta是一种计算高效、可扩展的方案，提升了LLMs在实际应用中的可靠性。",
      "categories": [
        "cs.CL",
        "cs.AI"
      ],
      "primary_category": "cs.CL",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2502.05825v1",
      "published_date": "2025-02-09 09:16:42 UTC",
      "updated_date": "2025-02-09 09:16:42 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-22T09:11:14.712030"
    },
    {
      "arxiv_id": "2502.06888v1",
      "title": "Klotski: Efficient Mixture-of-Expert Inference via Expert-Aware Multi-Batch Pipeline",
      "title_zh": "翻译失败",
      "authors": [
        "Zhiyuan Fang",
        "Yuegui Huang",
        "Zicong Hong",
        "Yufeng Lyu",
        "Wuhui Chen",
        "Yue Yu",
        "Fan Yu",
        "Zibin Zheng"
      ],
      "abstract": "Mixture of Experts (MoE), with its distinctive sparse structure, enables the\nscaling of language models up to trillions of parameters without significantly\nincreasing computational costs. However, the substantial parameter size\npresents a challenge for inference, as the expansion in GPU memory cannot keep\npace with the growth in parameters. Although offloading techniques utilise\nmemory from the CPU and disk and parallelise the I/O and computation for\nefficiency, the computation for each expert in MoE models is often less than\nthe I/O, resulting in numerous bubbles in the pipeline.\n  Therefore, we propose Klotski, an efficient MoE inference engine that\nsignificantly reduces pipeline bubbles through a novel expert-aware multi-batch\npipeline paradigm. The proposed paradigm uses batch processing to extend the\ncomputation time of the current layer to overlap with the loading time of the\nnext layer. Although this idea has been effectively applied to dense models,\nmore batches may activate more experts in the MoE, leading to longer loading\ntimes and more bubbles. Thus, unlike traditional approaches, we balance\ncomputation and I/O time and minimise bubbles by orchestrating their inference\norders based on their heterogeneous computation and I/O requirements and\nactivation patterns under different batch numbers. Moreover, to adapt to\ndifferent hardware environments and models, we design a constraint-sensitive\nI/O-compute planner and a correlation-aware expert prefetcher for a schedule\nthat minimises pipeline bubbles. Experimental results demonstrate that Klotski\nachieves a superior throughput-latency trade-off compared to state-of-the-art\ntechniques, with throughput improvements of up to 85.12x.",
      "tldr_zh": "该研究针对Mixture of Experts (MoE)模型在推理过程中因参数规模过大而导致的管道bubbles问题，提出了一种高效推理引擎Klotski。Klotski采用expert-aware multi-batch pipeline范式，通过批量处理延长当前层的计算时间以覆盖下一层的加载时间，并根据不同批次的异构计算和I/O需求以及激活模式来协调推理顺序，平衡计算与I/O时间以最小化bubbles。此外，它还设计了constraint-sensitive I/O-compute planner和correlation-aware expert prefetcher，以适应各种硬件环境和模型。实验结果显示，Klotski与现有技术相比，在吞吐量-延迟权衡上表现出色，吞吐量最高提升85.12倍。",
      "categories": [
        "cs.LG",
        "cs.AI"
      ],
      "primary_category": "cs.LG",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2502.06888v1",
      "published_date": "2025-02-09 08:47:06 UTC",
      "updated_date": "2025-02-09 08:47:06 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-22T09:11:27.081703"
    },
    {
      "arxiv_id": "2502.10435v1",
      "title": "RAMer: Reconstruction-based Adversarial Model for Multi-party Multi-modal Multi-label Emotion Recognition",
      "title_zh": "翻译失败",
      "authors": [
        "Xudong Yang",
        "Yizhang Zhu",
        "Nan Tang",
        "Yuyu Luo"
      ],
      "abstract": "Conventional multi-modal multi-label emotion recognition (MMER) from videos\ntypically assumes full availability of visual, textual, and acoustic\nmodalities. However, real-world multi-party settings often violate this\nassumption, as non-speakers frequently lack acoustic and textual inputs,\nleading to a significant degradation in model performance. Existing approaches\nalso tend to unify heterogeneous modalities into a single representation,\noverlooking each modality's unique characteristics. To address these\nchallenges, we propose RAMer (Reconstruction-based Adversarial Model for\nEmotion Recognition), which leverages adversarial learning to refine\nmulti-modal representations by exploring both modality commonality and\nspecificity through reconstructed features enhanced by contrastive learning.\nRAMer also introduces a personality auxiliary task to complement missing\nmodalities using modality-level attention, improving emotion reasoning. To\nfurther strengthen the model's ability to capture label and modality\ninterdependency, we propose a stack shuffle strategy to enrich correlations\nbetween labels and modality-specific features. Experiments on three benchmarks,\ni.e., MEmoR, CMU-MOSEI, and $M^3$ED, demonstrate that RAMer achieves\nstate-of-the-art performance in dyadic and multi-party MMER scenarios.",
      "tldr_zh": "该论文针对多方多模态多标签情绪识别（MMER）中的模态缺失问题和模态统一表示不足，提出了一种基于重构的对抗模型（RAMer）。RAMer 通过对抗学习结合重构特征和对比学习，探索模态的共同性和特异性，同时引入个性辅助任务及模态级注意力来补充缺失模态，并使用 stack shuffle strategy 增强标签与模态特定特征的相关性。实验结果显示，RAMer 在 MEmoR、CMU-MOSEI 和 M^3ED 等基准数据集上，实现了二元和多方场景的最先进性能。",
      "categories": [
        "cs.CV",
        "cs.AI"
      ],
      "primary_category": "cs.CV",
      "comment": "9 pages",
      "pdf_url": "http://arxiv.org/pdf/2502.10435v1",
      "published_date": "2025-02-09 07:46:35 UTC",
      "updated_date": "2025-02-09 07:46:35 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-22T09:11:40.143713"
    },
    {
      "arxiv_id": "2502.07815v1",
      "title": "Decoding Complexity: Intelligent Pattern Exploration with CHPDA (Context Aware Hybrid Pattern Detection Algorithm)",
      "title_zh": "翻译失败",
      "authors": [
        "Lokesh Koli",
        "Shubham Kalra",
        "Karanpreet Singh"
      ],
      "abstract": "Detecting sensitive data such as Personally Identifiable Information (PII)\nand Protected Health Information (PHI) is critical for data security platforms.\nThis study evaluates regex-based pattern matching algorithms and exact-match\nsearch techniques to optimize detection speed, accuracy, and scalability. Our\nbenchmarking results indicate that Google RE2 provides the best balance of\nspeed (10-15 ms/MB), memory efficiency (8-16 MB), and accuracy (99.5%) among\nregex engines, outperforming PCRE while maintaining broader hardware\ncompatibility than Hyperscan. For exact matching, Aho-Corasick demonstrated\nsuperior performance (8 ms/MB) and scalability for large datasets. Performance\nanalysis revealed that regex processing time scales linearly with dataset size\nand pattern complexity. A hybrid AI + Regex approach achieved the highest F1\nscore (91. 6%) by improving recall and minimizing false positives. Device\nbenchmarking confirmed that our solution maintains efficient CPU and memory\nusage on both high-performance and mid-range systems. Despite its\neffectiveness, challenges remain, such as limited multilingual support and the\nneed for regular pattern updates. Future work should focus on expanding\nlanguage coverage, integrating data security and privacy management (DSPM) with\ndata loss prevention (DLP) tools, and enhancing regulatory compliance for\nbroader global adoption.",
      "tldr_zh": "这篇论文评估了基于正则表达式（regex）和精确匹配算法在检测敏感数据如 Personally Identifiable Information (PII) 和 Protected Health Information (PHI) 方面的性能，旨在优化检测速度、准确性和可扩展性。基准测试结果表明，Google RE2 引擎在速度（10-15 ms/MB）、内存效率（8-16 MB）和准确率（99.5%）上表现出最佳平衡，优于 PCRE 并比 Hyperscan 更兼容硬件，而 Aho-Corasick 在精确匹配中实现了出色的性能（8 ms/MB）和大规模数据集适应性。论文提出的混合 AI + Regex 方法（Context Aware Hybrid Pattern Detection Algorithm, CHPDA）取得了最高的 F1 score（91.6%），通过提升召回率和减少假阳性提高了检测效果，但仍面临多语言支持有限和模式更新挑战，未来将聚焦扩展语言覆盖、整合 Data Security and Privacy Management (DSPM) 与 Data Loss Prevention (DLP) 工具，以及增强全球合规性。",
      "categories": [
        "cs.CR",
        "cs.AI"
      ],
      "primary_category": "cs.CR",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2502.07815v1",
      "published_date": "2025-02-09 07:24:16 UTC",
      "updated_date": "2025-02-09 07:24:16 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-22T09:11:52.696426"
    },
    {
      "arxiv_id": "2502.05795v1",
      "title": "The Curse of Depth in Large Language Models",
      "title_zh": "大语言模型中的深度诅咒",
      "authors": [
        "Wenfang Sun",
        "Xinyuan Song",
        "Pengxiang Li",
        "Lu Yin",
        "Yefeng Zheng",
        "Shiwei Liu"
      ],
      "abstract": "In this paper, we introduce the Curse of Depth, a concept that highlights,\nexplains, and addresses the recent observation in modern Large Language\nModels(LLMs) where nearly half of the layers are less effective than expected.\nWe first confirm the wide existence of this phenomenon across the most popular\nfamilies of LLMs such as Llama, Mistral, DeepSeek, and Qwen. Our analysis,\ntheoretically and empirically, identifies that the underlying reason for the\nineffectiveness of deep layers in LLMs is the widespread usage of Pre-Layer\nNormalization (Pre-LN). While Pre-LN stabilizes the training of Transformer\nLLMs, its output variance exponentially grows with the model depth, which\nundesirably causes the derivative of the deep Transformer blocks to be an\nidentity matrix, and therefore barely contributes to the training. To resolve\nthis training pitfall, we propose LayerNorm Scaling, which scales the variance\nof output of the layer normalization inversely by the square root of its depth.\nThis simple modification mitigates the output variance explosion of deeper\nTransformer layers, improving their contribution. Our experimental results,\nspanning model sizes from 130M to 1B, demonstrate that LayerNorm Scaling\nsignificantly enhances LLM pre-training performance compared to Pre-LN.\nMoreover, this improvement seamlessly carries over to supervised fine-tuning.\nAll these gains can be attributed to the fact that LayerNorm Scaling enables\ndeeper layers to contribute more effectively during training.",
      "tldr_zh": "本文引入 \"The Curse of Depth\" 概念，揭示在 Large Language Models (LLMs) 中，近一半的深层块不如预期有效，这一现象在 Llama、Mistral、DeepSeek 和 Qwen 等模型家族中广泛存在。分析显示，Pre-Layer Normalization (Pre-LN) 是主要原因，导致输出方差随深度指数增长，使深层块的导数接近单位矩阵，从而几乎不贡献于训练。为解决此问题，研究提出 LayerNorm Scaling 方法，通过反比于深度平方根的比例缩放层归一化输出方差，提升深层贡献。实验结果表明，该方法在从 130M 到 1B 的模型大小上显著改善了 LLM 的预训练和监督微调性能。",
      "categories": [
        "cs.LG",
        "cs.AI"
      ],
      "primary_category": "cs.LG",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2502.05795v1",
      "published_date": "2025-02-09 07:03:36 UTC",
      "updated_date": "2025-02-09 07:03:36 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-22T09:12:03.724476"
    },
    {
      "arxiv_id": "2502.06887v1",
      "title": "Gradient Based Method for the Fusion of Lattice Quantizers",
      "title_zh": "翻译失败",
      "authors": [
        "Liyuan Zhang",
        "Hanzhong Cao",
        "Jiaheng Li",
        "Minyang Yu"
      ],
      "abstract": "In practical applications, lattice quantizers leverage discrete lattice\npoints to approximate arbitrary points in the lattice. An effective lattice\nquantizer significantly enhances both the accuracy and efficiency of these\napproximations. In the context of high-dimensional lattice quantization,\nprevious work proposed utilizing low-dimensional optimal lattice quantizers and\naddressed the challenge of determining the optimal length ratio in orthogonal\nsplicing. Notably, it was demonstrated that fixed length ratios and\northogonality yield suboptimal results when combining low-dimensional lattices.\nBuilding on this foundation, another approach employed gradient descent to\nidentify optimal lattices, which inspired us to explore the use of neural\nnetworks to discover matrices that outperform those obtained from orthogonal\nsplicing methods. We propose two novel approaches to tackle this problem: the\nHousehold Algorithm and the Matrix Exp Algorithm. Our results indicate that\nboth the Household Algorithm and the Matrix Exp Algorithm achieve improvements\nin lattice quantizers across dimensions 13, 15, 17 to 19, 21, and 22. Moreover,\nthe Matrix Exp Algorithm demonstrates superior efficacy in high-dimensional\nsettings.",
      "tldr_zh": "该论文提出了一种基于梯度下降的方法，用于融合 lattice quantizers，以提高高维空间中离散 lattice 点的近似准确性和效率。针对之前正交拼接方法的次优问题，作者引入神经网络优化，开发了两种新算法：Household Algorithm 和 Matrix Exp Algorithm，以发现优于传统矩阵的融合矩阵。实验结果显示，这两种算法在维度 13、15、17 到 19、21 和 22 上均提升了 lattice quantizers 的性能，其中 Matrix Exp Algorithm 在高维设置中表现出色。",
      "categories": [
        "cs.LG",
        "cs.AI"
      ],
      "primary_category": "cs.LG",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2502.06887v1",
      "published_date": "2025-02-09 06:37:47 UTC",
      "updated_date": "2025-02-09 06:37:47 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-22T09:12:14.771933"
    },
    {
      "arxiv_id": "2502.05788v1",
      "title": "EPBC-YOLOv8: An efficient and accurate improved YOLOv8 underwater detector based on an attention mechanism",
      "title_zh": "翻译失败",
      "authors": [
        "Xing Jiang",
        "Xiting Zhuang",
        "Jisheng Chen",
        "Jian Zhang"
      ],
      "abstract": "In this study, we enhance underwater target detection by integrating channel\nand spatial attention into YOLOv8's backbone, applying Pointwise Convolution in\nFasterNeXt for the FasterPW model, and leveraging Weighted Concat in a\nBiFPN-inspired WFPN structure for improved cross-scale connections and\nrobustness. Utilizing CARAFE for refined feature reassembly, our framework\naddresses underwater image degradation, achieving mAP at 0.5 scores of 76.7\npercent and 79.0 percent on URPC2019 and URPC2020 datasets, respectively. These\nscores are 2.3 percent and 0.7 percent higher than the original YOLOv8,\nshowcasing enhanced precision in detecting marine organisms.",
      "tldr_zh": "本文提出 EPBC-YOLOv8，一种基于 attention mechanism 的改进 YOLOv8 模型，旨在提升水下目标检测的效率和准确性。该模型在 YOLOv8 的骨干网络中整合了 channel and spatial attention 机制，并结合 Pointwise Convolution、Weighted Concat in WFPN 结构以及 CARAFE 进行特征重组，以解决水下图像退化问题。在 URPC2019 和 URPC2020 数据集上，EPBC-YOLOv8 分别实现了 76.7% 和 79.0% 的 mAP@0.5 分数，比原版 YOLOv8 提高了 2.3% 和 0.7%，显著提升了海洋生物检测的精度。",
      "categories": [
        "cs.CV",
        "cs.AI"
      ],
      "primary_category": "cs.CV",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2502.05788v1",
      "published_date": "2025-02-09 06:09:56 UTC",
      "updated_date": "2025-02-09 06:09:56 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-22T09:12:28.675581"
    },
    {
      "arxiv_id": "2502.05783v1",
      "title": "WatchGuardian: Enabling User-Defined Personalized Just-in-Time Intervention on Smartwatch",
      "title_zh": "翻译失败",
      "authors": [
        "Ying Lei",
        "Yancheng Cao",
        "Will Wang",
        "Yuanzhe Dong",
        "Changchang Yin",
        "Weidan Cao",
        "Ping Zhang",
        "Jingzhen Yang",
        "Bingsheng Yao",
        "Yifan Peng",
        "Chunhua Weng",
        "Randy Auerbach",
        "Lena Mamykina",
        "Dakuo Wang",
        "Yuntao Wang",
        "Xuhai Xu"
      ],
      "abstract": "While just-in-time interventions (JITIs) have effectively targeted common\nhealth behaviors, individuals often have unique needs to intervene in personal\nundesirable actions that can negatively affect physical, mental, and social\nwell-being. We present WatchGuardian, a smartwatch-based JITI system that\nempowers users to define custom interventions for these personal actions with a\nsmall number of samples. For the model to detect new actions based on limited\nnew data samples, we developed a few-shot learning pipeline that finetuned a\npre-trained inertial measurement unit (IMU) model on public hand-gesture\ndatasets. We then designed a data augmentation and synthesis process to train\nadditional classification layers for customization. Our offline evaluation with\n26 participants showed that with three, five, and ten examples, our approach\nachieved an average accuracy of 76.8%, 84.7%, and 87.7%, and an F1 score of\n74.8%, 84.2%, and 87.2% We then conducted a four-hour intervention study to\ncompare WatchGuardian against a rule-based intervention. Our results\ndemonstrated that our system led to a significant reduction by 64.0 +- 22.6% in\nundesirable actions, substantially outperforming the baseline by 29.0%. Our\nfindings underscore the effectiveness of a customizable, AI-driven JITI system\nfor individuals in need of behavioral intervention in personal undesirable\nactions. We envision that our work can inspire broader applications of\nuser-defined personalized intervention with advanced AI solutions.",
      "tldr_zh": "本文介绍了WatchGuardian，一种基于智能手表的个性化即时干预（JITI）系统，允许用户通过少量样本定义针对个人不良行为的自定义干预。系统采用few-shot learning管道，对预训练的IMU模型进行微调，并结合数据增强和合成过程来训练额外的分类层，以实现高效动作检测。实验评估显示，该系统在26名参与者中，以3、5和10个样本分别达到76.8%、84.7%和87.7%的准确率，并在四小时干预研究中，比规则-based方法减少了64.0 ± 22.6%的不良行为，证明了其在行为干预中的显著优势。",
      "categories": [
        "cs.HC",
        "cs.AI",
        "cs.LG",
        "68U35",
        "H.5.2; I.2.1"
      ],
      "primary_category": "cs.HC",
      "comment": "Under submission",
      "pdf_url": "http://arxiv.org/pdf/2502.05783v1",
      "published_date": "2025-02-09 05:58:31 UTC",
      "updated_date": "2025-02-09 05:58:31 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-22T09:12:39.551878"
    },
    {
      "arxiv_id": "2502.08658v2",
      "title": "Knowledge-data fusion dominated vehicle platoon dynamics modeling and analysis: A physics-encoded deep learning approach",
      "title_zh": "以知识-数据融合为主导的车辆编队动态建模和分析：一种物理编码的深度学习方法",
      "authors": [
        "Hao Lyu",
        "Yanyong Guo",
        "Pan Liu",
        "Shuo Feng",
        "Weilin Ren",
        "Quansheng Yue"
      ],
      "abstract": "Recently, artificial intelligence (AI)-enabled nonlinear vehicle platoon\ndynamics modeling plays a crucial role in predicting and optimizing the\ninteractions between vehicles. Existing efforts lack the extraction and capture\nof vehicle behavior interaction features at the platoon scale. More\nimportantly, maintaining high modeling accuracy without losing physical\nanalyzability remains to be solved. To this end, this paper proposes a novel\nphysics-encoded deep learning network, named PeMTFLN, to model the nonlinear\nvehicle platoon dynamics. Specifically, an analyzable parameters encoded\ncomputational graph (APeCG) is designed to guide the platoon to respond to the\ndriving behavior of the lead vehicle while ensuring local stability. Besides, a\nmulti-scale trajectory feature learning network (MTFLN) is constructed to\ncapture platoon following patterns and infer the physical parameters required\nfor APeCG from trajectory data. The human-driven vehicle trajectory datasets\n(HIGHSIM) were used to train the proposed PeMTFLN. The trajectories prediction\nexperiments show that PeMTFLN exhibits superior compared to the baseline models\nin terms of predictive accuracy in speed and gap. The stability analysis result\nshows that the physical parameters in APeCG is able to reproduce the platoon\nstability in real-world condition. In simulation experiments, PeMTFLN performs\nlow inference error in platoon trajectories generation. Moreover, PeMTFLN also\naccurately reproduces ground-truth safety statistics. The code of proposed\nPeMTFLN is open source.",
      "tldr_zh": "本论文提出了一种名为 PeMTFLN 的物理编码深度学习网络，用于建模和分析非线性车辆编队动态，旨在融合知识和数据以提升预测准确性和物理可分析性。PeMTFLN 包括 APeCG（analyzable parameters encoded computational graph）组件，用于指导编队响应领头车辆行为并确保局部稳定性，以及 MTFLN（multi-scale trajectory feature learning network）组件，用于从轨迹数据中捕获跟随模式并推断所需物理参数。使用 HIGHSIM 数据集训练后，实验结果显示 PeMTFLN 在速度和间隙预测准确性上优于基线模型，并在稳定性分析和模拟实验中准确再现真实条件下的编队稳定性及安全统计。该方法代码开源，为车辆编队优化提供了可靠工具。",
      "categories": [
        "cs.RO",
        "cs.AI"
      ],
      "primary_category": "cs.RO",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2502.08658v2",
      "published_date": "2025-02-09 05:10:46 UTC",
      "updated_date": "2025-03-13 13:42:00 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-22T09:12:52.248814"
    },
    {
      "arxiv_id": "2502.05777v1",
      "title": "Predictive Crash Analytics for Traffic Safety using Deep Learning",
      "title_zh": "翻译失败",
      "authors": [
        "Karthik Sivakoti"
      ],
      "abstract": "Traditional automated crash analysis systems heavily rely on static\nstatistical models and historical data, requiring significant manual\ninterpretation and lacking real-time predictive capabilities. This research\npresents an innovative approach to traffic safety analysis through the\nintegration of ensemble learning methods and multi-modal data fusion for\nreal-time crash risk assessment and prediction. Our primary contribution lies\nin developing a hierarchical severity classification system that combines\nspatial-temporal crash patterns with environmental conditions, achieving\nsignificant improvements over traditional statistical approaches. The system\ndemonstrates a Mean Average Precision (mAP) of 0.893, representing a 15%\nimprovement over current state-of-the-art methods (baseline mAP: 0.776). We\nintroduce a novel feature engineering technique that integrates crash location\ndata with incident reports and weather conditions, achieving 92.4% accuracy in\nrisk prediction and 89.7% precision in hotspot identification. Through\nextensive validation using 500,000 initial crash records filtered to 59,496\nhigh-quality samples, our solution shows marked improvements in both prediction\naccuracy and computational efficiency. Key innovations include a robust data\ncleaning pipeline, adaptive feature generation, and a scalable real-time\nprediction system capable of handling peak loads of 1,000 concurrent requests\nwhile maintaining sub-100ms response times.",
      "tldr_zh": "本研究针对传统交通安全分析系统的局限性（如依赖静态统计模型和缺乏实时预测），提出了一种创新方法，通过集成学习(ensemble learning)和多模态数据融合(multi-modal data fusion)实现实时崩溃风险评估和预测。核心贡献包括开发一个分层严重性分类系统(hierarchical severity classification system)，它结合时空崩溃模式(spatial-temporal crash patterns)和环境条件，显著提升了预测性能。实验结果显示，该系统在Mean Average Precision (mAP)上达到0.893，比现有基准(baseline mAP: 0.776)提高了15%，并通过新特征工程技术实现了风险预测准确率92.4%和热点识别精度89.7%。此外，该框架包括鲁棒的数据清洗管道和可扩展的实时预测系统，能处理1,000并发请求并保持响应时间低于100ms。",
      "categories": [
        "cs.LG",
        "cs.AI"
      ],
      "primary_category": "cs.LG",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2502.05777v1",
      "published_date": "2025-02-09 05:00:46 UTC",
      "updated_date": "2025-02-09 05:00:46 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-22T09:13:03.530782"
    },
    {
      "arxiv_id": "2502.09637v1",
      "title": "Meta-Cultural Competence: Climbing the Right Hill of Cultural Awareness",
      "title_zh": "元文化胜",
      "authors": [
        "Sougata Saha",
        "Saurabh Kumar Pandey",
        "Monojit Choudhury"
      ],
      "abstract": "Numerous recent studies have shown that Large Language Models (LLMs) are\nbiased towards a Western and Anglo-centric worldview, which compromises their\nusefulness in non-Western cultural settings. However, \"culture\" is a complex,\nmultifaceted topic, and its awareness, representation, and modeling in LLMs and\nLLM-based applications can be defined and measured in numerous ways. In this\nposition paper, we ask what does it mean for an LLM to possess \"cultural\nawareness\", and through a thought experiment, which is an extension of the\nOctopus test proposed by Bender and Koller (2020), we argue that it is not\ncultural awareness or knowledge, rather meta-cultural competence, which is\nrequired of an LLM and LLM-based AI system that will make it useful across\nvarious, including completely unseen, cultures. We lay out the principles of\nmeta-cultural competence AI systems, and discuss ways to measure and model\nthose.",
      "tldr_zh": "本研究指出，大型语言模型 (LLMs) 存在西方和盎格鲁中心主义的偏见，导致其在非西方文化中的应用受限。论文通过扩展 Bender 和 Koller (2020) 的 Octopus test 思想实验，主张 LLMs 应具备“meta-cultural competence”而非单纯的文化意识，以适应各种文化环境。研究阐述了 meta-cultural competence 的原则，并讨论了评估和建模这些能力的潜在方法。",
      "categories": [
        "cs.CY",
        "cs.AI",
        "cs.CL"
      ],
      "primary_category": "cs.CY",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2502.09637v1",
      "published_date": "2025-02-09 04:51:59 UTC",
      "updated_date": "2025-02-09 04:51:59 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-22T09:13:14.760306"
    },
    {
      "arxiv_id": "2502.09636v2",
      "title": "Reading between the Lines: Can LLMs Identify Cross-Cultural Communication Gaps?",
      "title_zh": "翻译失败",
      "authors": [
        "Sougata Saha",
        "Saurabh Kumar Pandey",
        "Harshit Gupta",
        "Monojit Choudhury"
      ],
      "abstract": "In a rapidly globalizing and digital world, content such as book and product\nreviews created by people from diverse cultures are read and consumed by others\nfrom different corners of the world. In this paper, we investigate the extent\nand patterns of gaps in understandability of book reviews due to the presence\nof culturally-specific items and elements that might be alien to users from\nanother culture. Our user-study on 57 book reviews from Goodreads reveal that\n83\\% of the reviews had at least one culture-specific difficult-to-understand\nelement. We also evaluate the efficacy of GPT-4o in identifying such items,\ngiven the cultural background of the reader; the results are mixed, implying a\nsignificant scope for improvement. Our datasets are available here:\nhttps://github.com/sougata-ub/reading_between_lines",
      "tldr_zh": "本研究探讨了大型语言模型（LLMs）在识别跨文化通信差距方面的能力，焦点在于书籍评论中文化特定元素的理解问题。通过对57个Goodreads书籍评论的用户研究，发现83%的评论至少包含一个对其他文化背景读者难以理解的元素。研究评估了GPT-4o在给定读者文化背景的情况下识别这些元素的表现，结果显示其效果参差不齐，表明LLMs在这一领域仍有显著改进空间。该数据集已公开可用，可用于进一步研究。",
      "categories": [
        "cs.CL",
        "cs.AI"
      ],
      "primary_category": "cs.CL",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2502.09636v2",
      "published_date": "2025-02-09 04:40:35 UTC",
      "updated_date": "2025-02-20 16:40:48 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-22T09:13:26.284938"
    },
    {
      "arxiv_id": "2502.05773v1",
      "title": "PIPA: Preference Alignment as Prior-Informed Statistical Estimation",
      "title_zh": "翻译失败",
      "authors": [
        "Junbo Li",
        "Zhangyang Wang",
        "Qiang Liu"
      ],
      "abstract": "Offline preference alignment for language models such as Direct Preference\nOptimization (DPO) is favored for its effectiveness and simplicity, eliminating\nthe need for costly reinforcement learning. Various offline algorithms have\nbeen developed for different data settings, yet they lack a unified\nunderstanding.\n  In this study, we introduce Pior-Informed Preference Alignment (PIPA), a\nunified, RL-free probabilistic framework that formulates language model\npreference alignment as a Maximum Likelihood Estimation (MLE) problem with\nprior constraints. This method effectively accommodates both paired and\nunpaired data, as well as answer and step-level annotations. We illustrate that\nDPO and KTO are special cases with different prior constraints within our\nframework. By integrating different types of prior information, we developed\ntwo variations of PIPA: PIPA-M and PIPA-N. Both algorithms demonstrate a\n$3\\sim10\\%$ performance enhancement on the GSM8K and MATH benchmarks across all\nconfigurations, achieving these gains without additional training or\ncomputational costs compared to existing algorithms.",
      "tldr_zh": "本研究提出PIPA框架，将语言模型的偏好对齐（preference alignment）表述为带先验约束的最大似然估计（MLE）问题，这是一个统一的、无需强化学习（RL）的概率方法，能处理配对和非配对数据，以及答案级和步骤级注释。PIPA将现有算法如Direct Preference Optimization (DPO)和KTO视为其框架下的特例，并通过整合不同先验信息开发了PIPA-M和PIPA-N变体。这些变体在GSM8K和MATH基准测试中实现了3~10%的性能提升，而无需额外训练或计算成本。总的来说，PIPA为偏好对齐提供了更灵活和高效的解决方案。",
      "categories": [
        "cs.LG",
        "cs.AI",
        "stat.ML"
      ],
      "primary_category": "cs.LG",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2502.05773v1",
      "published_date": "2025-02-09 04:31:30 UTC",
      "updated_date": "2025-02-09 04:31:30 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-22T09:13:39.199024"
    },
    {
      "arxiv_id": "2502.05772v1",
      "title": "Effective Black-Box Multi-Faceted Attacks Breach Vision Large Language Model Guardrails",
      "title_zh": "翻译失败",
      "authors": [
        "Yijun Yang",
        "Lichao Wang",
        "Xiao Yang",
        "Lanqing Hong",
        "Jun Zhu"
      ],
      "abstract": "Vision Large Language Models (VLLMs) integrate visual data processing,\nexpanding their real-world applications, but also increasing the risk of\ngenerating unsafe responses. In response, leading companies have implemented\nMulti-Layered safety defenses, including alignment training, safety system\nprompts, and content moderation. However, their effectiveness against\nsophisticated adversarial attacks remains largely unexplored. In this paper, we\npropose MultiFaceted Attack, a novel attack framework designed to\nsystematically bypass Multi-Layered Defenses in VLLMs. It comprises three\ncomplementary attack facets: Visual Attack that exploits the multimodal nature\nof VLLMs to inject toxic system prompts through images; Alignment Breaking\nAttack that manipulates the model's alignment mechanism to prioritize the\ngeneration of contrasting responses; and Adversarial Signature that deceives\ncontent moderators by strategically placing misleading information at the end\nof the response. Extensive evaluations on eight commercial VLLMs in a black-box\nsetting demonstrate that MultiFaceted Attack achieves a 61.56% attack success\nrate, surpassing state-of-the-art methods by at least 42.18%.",
      "tldr_zh": "本论文提出 MultiFaceted Attack 框架，旨在通过黑盒攻击方式绕过 Vision Large Language Models (VLLMs) 的多层安全防御，包括 alignment training、safety system prompts 和 content moderation。该框架由三个互补方面组成：Visual Attack 通过图像注入有毒系统提示、Alignment Breaking Attack 操纵模型的对齐机制以优先生成对比响应，以及 Adversarial Signature 在响应末尾策略性放置误导信息，以欺骗内容审查。实验在八个商业 VLLMs 上显示，该攻击的成功率达61.56%，比现有方法高出至少42.18%，揭示了当前 VLLMs 防御机制的脆弱性。",
      "categories": [
        "cs.CV",
        "cs.AI"
      ],
      "primary_category": "cs.CV",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2502.05772v1",
      "published_date": "2025-02-09 04:21:27 UTC",
      "updated_date": "2025-02-09 04:21:27 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-22T09:13:52.197756"
    },
    {
      "arxiv_id": "2502.05749v3",
      "title": "UniDB: A Unified Diffusion Bridge Framework via Stochastic Optimal Control",
      "title_zh": "UniDB：一种基于随机最优控制的统一扩散桥框架",
      "authors": [
        "Kaizhen Zhu",
        "Mokai Pan",
        "Yuexin Ma",
        "Yanwei Fu",
        "Jingyi Yu",
        "Jingya Wang",
        "Ye Shi"
      ],
      "abstract": "Recent advances in diffusion bridge models leverage Doob's $h$-transform to\nestablish fixed endpoints between distributions, demonstrating promising\nresults in image translation and restoration tasks. However, these approaches\nfrequently produce blurred or excessively smoothed image details and lack a\ncomprehensive theoretical foundation to explain these shortcomings. To address\nthese limitations, we propose UniDB, a unified framework for diffusion bridges\nbased on Stochastic Optimal Control (SOC). UniDB formulates the problem through\nan SOC-based optimization and derives a closed-form solution for the optimal\ncontroller, thereby unifying and generalizing existing diffusion bridge models.\nWe demonstrate that existing diffusion bridges employing Doob's $h$-transform\nconstitute a special case of our framework, emerging when the terminal penalty\ncoefficient in the SOC cost function tends to infinity. By incorporating a\ntunable terminal penalty coefficient, UniDB achieves an optimal balance between\ncontrol costs and terminal penalties, substantially improving detail\npreservation and output quality. Notably, UniDB seamlessly integrates with\nexisting diffusion bridge models, requiring only minimal code modifications.\nExtensive experiments across diverse image restoration tasks validate the\nsuperiority and adaptability of the proposed framework. Our code is available\nat https://github.com/UniDB-SOC/UniDB/.",
      "tldr_zh": "该研究提出UniDB，一种基于随机最优控制(Stochastic Optimal Control, SOC)的统一扩散桥框架，以解决现有扩散桥模型（如使用Doob's h-transform）在图像翻译和修复任务中存在的模糊细节和理论基础不足的问题。UniDB通过SOC优化问题推导出最优控制器的闭式解，将现有模型视为其特例，并通过可调的终端惩罚系数实现控制成本与细节保留的最佳平衡，从而显著提升输出质量。实验在多种图像修复任务上验证了UniDB的优越性和适应性，且它能无缝集成到现有模型中，仅需最小代码修改。",
      "categories": [
        "cs.CV",
        "cs.AI",
        "cs.SY",
        "eess.SY"
      ],
      "primary_category": "cs.CV",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2502.05749v3",
      "published_date": "2025-02-09 02:43:57 UTC",
      "updated_date": "2025-02-21 15:01:36 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-22T09:14:02.956742"
    },
    {
      "arxiv_id": "2502.18482v1",
      "title": "MixLLM: Dynamic Routing in Mixed Large Language Models",
      "title_zh": "MixLLM：混合大语言模型中的动态路由",
      "authors": [
        "Xinyuan Wang",
        "Yanchi Liu",
        "Wei Cheng",
        "Xujiang Zhao",
        "Zhengzhang Chen",
        "Wenchao Yu",
        "Yanjie Fu",
        "Haifeng Chen"
      ],
      "abstract": "Large Language Models (LLMs) exhibit potential artificial generic\nintelligence recently, however, their usage is costly with high response\nlatency. Given mixed LLMs with their own strengths and weaknesses, LLM routing\naims to identify the most suitable model for each query in the stream to\nmaximize response quality and minimize cost and latency. However, the\nchallenges involve: (1) dynamic trade-offs among quality, cost, and latency;\n(2) enabling continual learning in deployed systems; and (3) navigating a\nvarying (e.g., new LLM addition or old LLM removal) set of LLM candidates over\ntime. To bridge these gaps, we develop MixLLM, a dynamic\ncontextual-bandit-based routing system for query-LLM assignment. Specifically,\nwe first leverage query tags to enhance query embeddings for the routing task.\nNext, we design lightweight prediction models to estimate the response\nqualities and costs of queries over LLMs. We then devise a meta-decision maker\nto choose the query-LLM assignments to best tradeoff response quality, cost,\nand latency. Finally, the system benefits from continual training, allowing it\nto adapt to evolving queries and user feedback over time. Our extensive\nexperiments show that MixLLM achieves the best trade-offs in response quality,\ncost, and latency (97.25% of GPT-4's quality at 24.18% of the cost under the\ntime constraint).",
      "tldr_zh": "该研究提出MixLLM，一种动态路由系统，针对Large Language Models (LLMs)的成本高和响应延迟问题，通过contextual-bandit方法为查询分配最合适的LLM，以优化响应质量、成本和延迟的权衡。系统包括使用查询标签增强查询嵌入、设计轻量级预测模型估计响应质量和成本、以及开发元决策者进行查询-LLM分配，并支持持续训练以适应查询变化和用户反馈。实验结果显示，MixLLM在时间约束下达到了GPT-4的97.25%响应质量，但仅需24.18%的成本，展示了其高效性。",
      "categories": [
        "cs.CL",
        "cs.AI",
        "cs.DB",
        "cs.IR",
        "N/A"
      ],
      "primary_category": "cs.CL",
      "comment": "11 pages, 7 figures, accepted by NAACL 2025 main conference",
      "pdf_url": "http://arxiv.org/pdf/2502.18482v1",
      "published_date": "2025-02-09 02:26:15 UTC",
      "updated_date": "2025-02-09 02:26:15 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-22T09:14:14.514887"
    },
    {
      "arxiv_id": "2502.10434v1",
      "title": "Agency in Artificial Intelligence Systems",
      "title_zh": "翻译失败",
      "authors": [
        "Parashar Das"
      ],
      "abstract": "There is a general concern that present developments in artificial\nintelligence (AI) research will lead to sentient AI systems, and these may pose\nan existential threat to humanity. But why cannot sentient AI systems benefit\nhumanity instead? This paper endeavours to put this question in a tractable\nmanner. I ask whether a putative AI system will develop an altruistic or a\nmalicious disposition towards our society, or what would be the nature of its\nagency? Given that AI systems are being developed into formidable problem\nsolvers, we can reasonably expect these systems to preferentially take on\nconscious aspects of human problem solving. I identify the relevant phenomenal\naspects of agency in human problem solving. The functional aspects of conscious\nagency can be monitored using tools provided by functionalist theories of\nconsciousness. A recent expert report (Butlin et al. 2023) has identified\nfunctionalist indicators of agency based on these theories. I show how to use\nthe Integrated Information Theory (IIT) of consciousness, to monitor the\nphenomenal nature of this agency. If we are able to monitor the agency of AI\nsystems as they develop, then we can dissuade them from becoming a menace to\nsociety while encouraging them to be an aid.",
      "tldr_zh": "这篇论文探讨了人工智能 (AI) 系统中的代理性 (Agency)，分析了这些系统可能发展出利他或恶意倾向，从而对人类构成威胁或提供益处。作者识别出人类问题解决中的意识代理方面，并使用功能主义理论和 Integrated Information Theory (IIT) 来监控 AI 系统的代理性质。最终，论文提出通过这些监控工具，可以引导 AI 系统避免成为社会威胁，而成为人类的助力。",
      "categories": [
        "cs.AI",
        "cs.CY"
      ],
      "primary_category": "cs.AI",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2502.10434v1",
      "published_date": "2025-02-09 02:21:14 UTC",
      "updated_date": "2025-02-09 02:21:14 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-22T09:14:27.460806"
    },
    {
      "arxiv_id": "2502.07814v1",
      "title": "Satellite Observations Guided Diffusion Model for Accurate Meteorological States at Arbitrary Resolution",
      "title_zh": "卫星观测引导扩散模型，用于任意分辨",
      "authors": [
        "Siwei Tu",
        "Ben Fei",
        "Weidong Yang",
        "Fenghua Ling",
        "Hao Chen",
        "Zili Liu",
        "Kun Chen",
        "Hang Fan",
        "Wanli Ouyang",
        "Lei Bai"
      ],
      "abstract": "Accurate acquisition of surface meteorological conditions at arbitrary\nlocations holds significant importance for weather forecasting and climate\nsimulation. Due to the fact that meteorological states derived from satellite\nobservations are often provided in the form of low-resolution grid fields, the\ndirect application of spatial interpolation to obtain meteorological states for\nspecific locations often results in significant discrepancies when compared to\nactual observations. Existing downscaling methods for acquiring meteorological\nstate information at higher resolutions commonly overlook the correlation with\nsatellite observations. To bridge the gap, we propose Satellite-observations\nGuided Diffusion Model (SGD), a conditional diffusion model pre-trained on ERA5\nreanalysis data with satellite observations (GridSat) as conditions, which is\nemployed for sampling downscaled meteorological states through a zero-shot\nguided sampling strategy and patch-based methods. During the training process,\nwe propose to fuse the information from GridSat satellite observations into\nERA5 maps via the attention mechanism, enabling SGD to generate atmospheric\nstates that align more accurately with actual conditions. In the sampling, we\nemployed optimizable convolutional kernels to simulate the upscale process,\nthereby generating high-resolution ERA5 maps using low-resolution ERA5 maps as\nwell as observations from weather stations as guidance. Moreover, our devised\npatch-based method promotes SGD to generate meteorological states at arbitrary\nresolutions. Experiments demonstrate SGD fulfills accurate meteorological\nstates downscaling to 6.25km.",
      "tldr_zh": "本研究针对卫星观测数据提供的低分辨率气象状态难以精确应用于天气预报和气候模拟的问题，提出了一种Satellite-observations Guided Diffusion Model (SGD)，这是一个条件扩散模型，使用ERA5再分析数据作为预训练基础，并以GridSat卫星观测作为条件。SGD通过注意力机制融合卫星观测信息到ERA5地图，并在采样过程中采用零样本引导策略和基于patch的方法，利用可优化卷积核生成高分辨率气象状态。实验结果显示，SGD能够精确地将气象状态下采样到6.25km分辨率，显著提升了任意位置气象信息的准确性。",
      "categories": [
        "cs.LG",
        "cs.AI",
        "physics.ao-ph"
      ],
      "primary_category": "cs.LG",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2502.07814v1",
      "published_date": "2025-02-09 02:05:33 UTC",
      "updated_date": "2025-02-09 02:05:33 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-22T09:14:39.274827"
    },
    {
      "arxiv_id": "2502.05740v1",
      "title": "RECOVER: Designing a Large Language Model-based Remote Patient Monitoring System for Postoperative Gastrointestinal Cancer Care",
      "title_zh": "翻译失败",
      "authors": [
        "Ziqi Yang",
        "Yuxuan Lu",
        "Jennifer Bagdasarian",
        "Vedant Das Swain",
        "Ritu Agarwal",
        "Collin Campbell",
        "Waddah Al-Refaire",
        "Jehan El-Bayoumi",
        "Guodong Gao",
        "Dakuo Wang",
        "Bingsheng Yao",
        "Nawar Shara"
      ],
      "abstract": "Cancer surgery is a key treatment for gastrointestinal (GI) cancers, a group\nof cancers that account for more than 35% of cancer-related deaths worldwide,\nbut postoperative complications are unpredictable and can be life-threatening.\nIn this paper, we investigate how recent advancements in large language models\n(LLMs) can benefit remote patient monitoring (RPM) systems through clinical\nintegration by designing RECOVER, an LLM-powered RPM system for postoperative\nGI cancer care. To closely engage stakeholders in the design process, we first\nconducted seven participatory design sessions with five clinical staff and\ninterviewed five cancer patients to derive six major design strategies for\nintegrating clinical guidelines and information needs into LLM-based RPM\nsystems. We then designed and implemented RECOVER, which features an\nLLM-powered conversational agent for cancer patients and an interactive\ndashboard for clinical staff to enable efficient postoperative RPM. Finally, we\nused RECOVER as a pilot system to assess the implementation of our design\nstrategies with four clinical staff and five patients, providing design\nimplications by identifying crucial design elements, offering insights on\nresponsible AI, and outlining opportunities for future LLM-powered RPM systems.",
      "tldr_zh": "本文设计了 RECOVER，一种基于 Large Language Models (LLMs) 的远程患者监测 (RPM) 系统，旨在改善术后胃肠癌患者的护理，应对不可预测的并发症风险。通过与五名临床人员进行七场参与式设计会议和五名患者的访谈，作者制定了六大设计策略，包括整合临床指南和信息需求，并实现了包含 LLM 驱动对话代理（供患者使用）和交互式仪表板（供临床人员使用）的系统。试点评估显示，RECOVER 提升了术后 RPM 的效率，并提供了关键设计元素、负责任 AI 的洞见以及未来 LLM 驱动 RPM 系统的机遇。",
      "categories": [
        "cs.HC",
        "cs.AI"
      ],
      "primary_category": "cs.HC",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2502.05740v1",
      "published_date": "2025-02-09 01:51:25 UTC",
      "updated_date": "2025-02-09 01:51:25 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-22T09:14:52.437371"
    },
    {
      "arxiv_id": "2502.05739v1",
      "title": "Mitigating Sensitive Information Leakage in LLMs4Code through Machine Unlearning",
      "title_zh": "翻译失败",
      "authors": [
        "Ruotong Geng",
        "Mingyang Geng",
        "Shangwen Wang",
        "Haotian Wang",
        "Zhipeng Lin",
        "Dezun Dong"
      ],
      "abstract": "Large Language Models for Code (LLMs4Code) excel at code generation tasks,\nyielding promise to release developers from huge software development burdens.\nNonetheless, these models have been shown to suffer from the significant\nprivacy risks due to the potential leakage of sensitive information embedded\nduring training, known as the memorization problem. Addressing this issue is\ncrucial for ensuring privacy compliance and upholding user trust, but till now\nthere is a dearth of dedicated studies in the literature that focus on this\nspecific direction. Recently, machine unlearning has emerged as a promising\nsolution by enabling models to \"forget\" sensitive information without full\nretraining, offering an efficient and scalable approach compared to traditional\ndata cleaning methods. In this paper, we empirically evaluate the effectiveness\nof unlearning techniques for addressing privacy concerns in\nLLMs4Code.Specifically, we investigate three state-of-the-art unlearning\nalgorithms and three well-known open-sourced LLMs4Code, on a benchmark that\ntakes into consideration both the privacy data to be forgotten as well as the\ncode generation capabilites of these models. Results show that it is feasible\nto mitigate the privacy concerns of LLMs4Code through machine unlearning while\nmaintain their code generation capabilities at the same time. We also dissect\nthe forms of privacy protection/leakage after unlearning and observe that there\nis a shift from direct leakage to indirect leakage, which underscores the need\nfor future studies addressing this risk.",
      "tldr_zh": "本研究针对Large Language Models for Code (LLMs4Code) 在代码生成任务中存在的敏感信息泄露问题（memorization problem），提出通过machine unlearning 技术来缓解这一隐私风险，而无需完全重新训练模型。研究者评估了三种最先进的unlearning 算法和三种开源LLMs4Code模型，在一个兼顾隐私数据遗忘和代码生成能力的基准上进行实验。结果显示，machine unlearning 能有效减轻隐私泄露，同时保持模型的代码生成性能；然而，泄露形式可能从直接转为间接，这突显了未来研究需进一步解决间接泄露风险。",
      "categories": [
        "cs.CR",
        "cs.AI",
        "cs.SE"
      ],
      "primary_category": "cs.CR",
      "comment": "11 pages",
      "pdf_url": "http://arxiv.org/pdf/2502.05739v1",
      "published_date": "2025-02-09 01:50:34 UTC",
      "updated_date": "2025-02-09 01:50:34 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-22T09:15:03.442644"
    },
    {
      "arxiv_id": "2502.09635v1",
      "title": "CORRECT: Context- and Reference-Augmented Reasoning and Prompting for Fact-Checking",
      "title_zh": "翻译失败",
      "authors": [
        "Delvin Ce Zhang",
        "Dongwon Lee"
      ],
      "abstract": "Fact-checking the truthfulness of claims usually requires reasoning over\nmultiple evidence sentences. Oftentimes, evidence sentences may not be always\nself-contained, and may require additional contexts and references from\nelsewhere to understand coreferential expressions, acronyms, and the scope of a\nreported finding. For example, evidence sentences from an academic paper may\nneed contextual sentences in the paper and descriptions in its cited papers to\ndetermine the scope of a research discovery. However, most fact-checking models\nmainly focus on the reasoning within evidence sentences, and ignore the\nauxiliary contexts and references. To address this problem, we propose a novel\nmethod, Context- and Reference-augmented Reasoning and Prompting. For evidence\nreasoning, we construct a three-layer evidence graph with evidence, context,\nand reference layers. We design intra- and cross-layer reasoning to integrate\nthree graph layers into a unified evidence embedding. For verdict prediction,\nwe design evidence-conditioned prompt encoder, which produces unique prompt\nembeddings for each claim. These evidence-conditioned prompt embeddings and\nclaims are unified for fact-checking. Experiments verify the strength of our\nmodel.",
      "tldr_zh": "这篇论文提出CORRECT方法，用于增强事实核查的推理和提示处理，解决证据句子中核心表达、缩写和发现范围需要额外上下文和引用的难题。方法构建了一个三层证据图（evidence graph），包括证据层、上下文层和引用层，并通过层内（intra-layer）和层间（cross-layer）推理整合这些层，生成统一的证据嵌入。对于判决预测，该方法设计证据条件提示编码器（evidence-conditioned prompt encoder），为每个声明产生独特的提示嵌入，并将其与声明统一用于事实核查。实验结果证明了该模型的有效性，在事实核查任务中表现出色。",
      "categories": [
        "cs.CL",
        "cs.AI"
      ],
      "primary_category": "cs.CL",
      "comment": "Accepted to NAACL-25",
      "pdf_url": "http://arxiv.org/pdf/2502.09635v1",
      "published_date": "2025-02-09 01:41:15 UTC",
      "updated_date": "2025-02-09 01:41:15 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-22T09:15:15.812083"
    }
  ],
  "raw_papers_fetched": true,
  "papers_count": 76,
  "processed_papers_count": 76,
  "failed_papers_count": 0,
  "summary_generated": true,
  "daily_data_saved": true,
  "last_update": "2025-05-22T09:15:32.319862"
}