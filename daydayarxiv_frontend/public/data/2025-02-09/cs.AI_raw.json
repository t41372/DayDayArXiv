[
  {
    "arxiv_id": "2503.04756v1",
    "title": "Peeking Behind Closed Doors: Risks of LLM Evaluation by Private Data Curators",
    "authors": [
      "Hritik Bansal",
      "Pratyush Maini"
    ],
    "abstract": "The rapid advancement in building large language models (LLMs) has\nintensified competition among big-tech companies and AI startups. In this\nregard, model evaluations are critical for product and investment-related\ndecision-making. While open evaluation sets like MMLU initially drove progress,\nconcerns around data contamination and data bias have constantly questioned\ntheir reliability. As a result, it has led to the rise of private data curators\nwho have begun conducting hidden evaluations with high-quality self-curated\ntest prompts and their own expert annotators. In this paper, we argue that\ndespite potential advantages in addressing contamination issues, private\nevaluations introduce inadvertent financial and evaluation risks. In\nparticular, the key concerns include the potential conflict of interest arising\nfrom private data curators' business relationships with their clients (leading\nLLM firms). In addition, we highlight that the subjective preferences of\nprivate expert annotators will lead to inherent evaluation bias towards the\nmodels trained with the private curators' data. Overall, this paper lays the\nfoundation for studying the risks of private evaluations that can lead to\nwide-ranging community discussions and policy changes.",
    "categories": [
      "cs.CY",
      "cs.AI",
      "cs.CL",
      "cs.LG"
    ],
    "primary_category": "cs.CY",
    "comment": "Published as a blogpost at ICLR 2025. Originally posted at\n  https://pratyushmaini.github.io/blog/2024/risks-private-evals/",
    "pdf_url": "http://arxiv.org/pdf/2503.04756v1",
    "published_date": "2025-02-09 23:57:33 UTC",
    "updated_date": "2025-02-09 23:57:33 UTC"
  },
  {
    "arxiv_id": "2502.06065v1",
    "title": "Benchmarking Prompt Sensitivity in Large Language Models",
    "authors": [
      "Amirhossein Razavi",
      "Mina Soltangheis",
      "Negar Arabzadeh",
      "Sara Salamat",
      "Morteza Zihayat",
      "Ebrahim Bagheri"
    ],
    "abstract": "Large language Models (LLMs) are highly sensitive to variations in prompt\nformulation, which can significantly impact their ability to generate accurate\nresponses. In this paper, we introduce a new task, Prompt Sensitivity\nPrediction, and a dataset PromptSET designed to investigate the effects of\nslight prompt variations on LLM performance. Using TriviaQA and HotpotQA\ndatasets as the foundation of our work, we generate prompt variations and\nevaluate their effectiveness across multiple LLMs. We benchmark the prompt\nsensitivity prediction task employing state-of-the-art methods from related\ntasks, including LLM-based self-evaluation, text classification, and query\nperformance prediction techniques. Our findings reveal that existing methods\nstruggle to effectively address prompt sensitivity prediction, underscoring the\nneed to understand how information needs should be phrased for accurate LLM\nresponses.",
    "categories": [
      "cs.CL",
      "cs.AI",
      "cs.IR"
    ],
    "primary_category": "cs.CL",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2502.06065v1",
    "published_date": "2025-02-09 23:01:03 UTC",
    "updated_date": "2025-02-09 23:01:03 UTC"
  },
  {
    "arxiv_id": "2502.06062v1",
    "title": "Multi-modal Data Fusion and Deep Ensemble Learning for Accurate Crop Yield Prediction",
    "authors": [
      "Akshay Dagadu Yewle",
      "Laman Mirzayeva",
      "Oktay Karaku≈ü"
    ],
    "abstract": "This study introduces RicEns-Net, a novel Deep Ensemble model designed to\npredict crop yields by integrating diverse data sources through multimodal data\nfusion techniques. The research focuses specifically on the use of synthetic\naperture radar (SAR), optical remote sensing data from Sentinel 1, 2, and 3\nsatellites, and meteorological measurements such as surface temperature and\nrainfall. The initial field data for the study were acquired through Ernst &\nYoung's (EY) Open Science Challenge 2023. The primary objective is to enhance\nthe precision of crop yield prediction by developing a machine-learning\nframework capable of handling complex environmental data. A comprehensive data\nengineering process was employed to select the most informative features from\nover 100 potential predictors, reducing the set to 15 features from 5 distinct\nmodalities. This step mitigates the ``curse of dimensionality\" and enhances\nmodel performance. The RicEns-Net architecture combines multiple machine\nlearning algorithms in a deep ensemble framework, integrating the strengths of\neach technique to improve predictive accuracy. Experimental results demonstrate\nthat RicEns-Net achieves a mean absolute error (MAE) of 341 kg/Ha (roughly\ncorresponds to 5-6\\% of the lowest average yield in the region), significantly\nexceeding the performance of previous state-of-the-art models, including those\ndeveloped during the EY challenge.",
    "categories": [
      "eess.IV",
      "cs.AI"
    ],
    "primary_category": "eess.IV",
    "comment": "28 pages, 7 figures and 5 tables",
    "pdf_url": "http://arxiv.org/pdf/2502.06062v1",
    "published_date": "2025-02-09 22:48:27 UTC",
    "updated_date": "2025-02-09 22:48:27 UTC"
  },
  {
    "arxiv_id": "2502.06061v1",
    "title": "Online Reward-Weighted Fine-Tuning of Flow Matching with Wasserstein Regularization",
    "authors": [
      "Jiajun Fan",
      "Shuaike Shen",
      "Chaoran Cheng",
      "Yuxin Chen",
      "Chumeng Liang",
      "Ge Liu"
    ],
    "abstract": "Recent advancements in reinforcement learning (RL) have achieved great\nsuccess in fine-tuning diffusion-based generative models. However, fine-tuning\ncontinuous flow-based generative models to align with arbitrary user-defined\nreward functions remains challenging, particularly due to issues such as policy\ncollapse from overoptimization and the prohibitively high computational cost of\nlikelihoods in continuous-time flows. In this paper, we propose an easy-to-use\nand theoretically sound RL fine-tuning method, which we term Online\nReward-Weighted Conditional Flow Matching with Wasserstein-2 Regularization\n(ORW-CFM-W2). Our method integrates RL into the flow matching framework to\nfine-tune generative models with arbitrary reward functions, without relying on\ngradients of rewards or filtered datasets. By introducing an online\nreward-weighting mechanism, our approach guides the model to prioritize\nhigh-reward regions in the data manifold. To prevent policy collapse and\nmaintain diversity, we incorporate Wasserstein-2 (W2) distance regularization\ninto our method and derive a tractable upper bound for it in flow matching,\neffectively balancing exploration and exploitation of policy optimization. We\nprovide theoretical analyses to demonstrate the convergence properties and\ninduced data distributions of our method, establishing connections with\ntraditional RL algorithms featuring Kullback-Leibler (KL) regularization and\noffering a more comprehensive understanding of the underlying mechanisms and\nlearning behavior of our approach. Extensive experiments on tasks including\ntarget image generation, image compression, and text-image alignment\ndemonstrate the effectiveness of our method, where our method achieves optimal\npolicy convergence while allowing controllable trade-offs between reward\nmaximization and diversity preservation.",
    "categories": [
      "cs.LG",
      "cs.AI",
      "cs.CV",
      "stat.ML"
    ],
    "primary_category": "cs.LG",
    "comment": "61 pages",
    "pdf_url": "http://arxiv.org/pdf/2502.06061v1",
    "published_date": "2025-02-09 22:45:15 UTC",
    "updated_date": "2025-02-09 22:45:15 UTC"
  },
  {
    "arxiv_id": "2502.06060v1",
    "title": "Training Language Models for Social Deduction with Multi-Agent Reinforcement Learning",
    "authors": [
      "Bidipta Sarkar",
      "Warren Xia",
      "C. Karen Liu",
      "Dorsa Sadigh"
    ],
    "abstract": "Communicating in natural language is a powerful tool in multi-agent settings,\nas it enables independent agents to share information in partially observable\nsettings and allows zero-shot coordination with humans. However, most prior\nworks are limited as they either rely on training with large amounts of human\ndemonstrations or lack the ability to generate natural and useful communication\nstrategies. In this work, we train language models to have productive\ndiscussions about their environment in natural language without any human\ndemonstrations. We decompose the communication problem into listening and\nspeaking. Our key idea is to leverage the agent's goal to predict useful\ninformation about the world as a dense reward signal that guides communication.\nSpecifically, we improve a model's listening skills by training them to predict\ninformation about the environment based on discussions, and we simultaneously\nimprove a model's speaking skills with multi-agent reinforcement learning by\nrewarding messages based on their influence on other agents. To investigate the\nrole and necessity of communication in complex social settings, we study an\nembodied social deduction game based on Among Us, where the key question to\nanswer is the identity of an adversarial imposter. We analyze emergent\nbehaviors due to our technique, such as accusing suspects and providing\nevidence, and find that it enables strong discussions, doubling the win rates\ncompared to standard RL. We release our code and models at\nhttps://socialdeductionllm.github.io/",
    "categories": [
      "cs.AI",
      "cs.CL",
      "cs.LG",
      "cs.MA"
    ],
    "primary_category": "cs.AI",
    "comment": "14 pages, 5 figures, 24th International Conference on Autonomous\n  Agents and Multiagent Systems (AAMAS 2025)",
    "pdf_url": "http://arxiv.org/pdf/2502.06060v1",
    "published_date": "2025-02-09 22:44:45 UTC",
    "updated_date": "2025-02-09 22:44:45 UTC"
  },
  {
    "arxiv_id": "2502.06051v1",
    "title": "Nearly Optimal Sample Complexity of Offline KL-Regularized Contextual Bandits under Single-Policy Concentrability",
    "authors": [
      "Qingyue Zhao",
      "Kaixuan Ji",
      "Heyang Zhao",
      "Tong Zhang",
      "Quanquan Gu"
    ],
    "abstract": "KL-regularized policy optimization has become a workhorse in learning-based\ndecision making, while its theoretical understanding is still very limited.\nAlthough recent progress has been made towards settling the sample complexity\nof KL-regularized contextual bandits, existing sample complexity bounds are\neither $\\tilde{O}(\\epsilon^{-2})$ under single-policy concentrability or\n$\\tilde{O}(\\epsilon^{-1})$ under all-policy concentrability. In this paper, we\npropose the \\emph{first} algorithm with $\\tilde{O}(\\epsilon^{-1})$ sample\ncomplexity under single-policy concentrability for offline contextual bandits.\nOur algorithm is designed for general function approximation and based on the\nprinciple of \\emph{pessimism in the face of uncertainty}. The core of our proof\nleverages the strong convexity of the KL regularization, and the conditional\nnon-negativity of the gap between the true reward and its pessimistic estimator\nto refine a mean-value-type risk upper bound to its extreme. This in turn leads\nto a novel covariance-based analysis, effectively bypassing the need for\nuniform control over the discrepancy between any two functions in the function\nclass. The near-optimality of our algorithm is demonstrated by an\n$\\tilde{\\Omega}(\\epsilon^{-1})$ lower bound. Furthermore, we extend our\nalgorithm to contextual dueling bandits and achieve a similar nearly optimal\nsample complexity.",
    "categories": [
      "cs.LG",
      "cs.AI",
      "math.ST",
      "stat.ML",
      "stat.TH"
    ],
    "primary_category": "cs.LG",
    "comment": "23 pages",
    "pdf_url": "http://arxiv.org/pdf/2502.06051v1",
    "published_date": "2025-02-09 22:14:45 UTC",
    "updated_date": "2025-02-09 22:14:45 UTC"
  },
  {
    "arxiv_id": "2502.06049v1",
    "title": "LM2: Large Memory Models",
    "authors": [
      "Jikun Kang",
      "Wenqi Wu",
      "Filippos Christianos",
      "Alex J. Chan",
      "Fraser Greenlee",
      "George Thomas",
      "Marvin Purtorab",
      "Andy Toulis"
    ],
    "abstract": "This paper introduces the Large Memory Model (LM2), a decoder-only\nTransformer architecture enhanced with an auxiliary memory module that aims to\naddress the limitations of standard Transformers in multi-step reasoning,\nrelational argumentation, and synthesizing information distributed over long\ncontexts. The proposed LM2 incorporates a memory module that acts as a\ncontextual representation repository, interacting with input tokens via cross\nattention and updating through gating mechanisms. To preserve the Transformers\ngeneral-purpose capabilities, LM2 maintains the original information flow while\nintegrating a complementary memory pathway. Experimental results on the\nBABILong benchmark demonstrate that the LM2model outperforms both the\nmemory-augmented RMT model by 37.1% and the baseline Llama-3.2 model by 86.3%\non average across tasks. LM2 exhibits exceptional capabilities in multi-hop\ninference, numerical reasoning, and large-context question-answering. On the\nMMLU dataset, it achieves a 5.0% improvement over a pre-trained vanilla model,\ndemonstrating that its memory module does not degrade performance on general\ntasks. Further, in our analysis, we explore the memory interpretability,\neffectiveness of memory modules, and test-time behavior. Our findings emphasize\nthe importance of explicit memory in enhancing Transformer architectures.",
    "categories": [
      "cs.CL",
      "cs.AI"
    ],
    "primary_category": "cs.CL",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2502.06049v1",
    "published_date": "2025-02-09 22:11:42 UTC",
    "updated_date": "2025-02-09 22:11:42 UTC"
  },
  {
    "arxiv_id": "2502.06039v1",
    "title": "Benchmarking Prompt Engineering Techniques for Secure Code Generation with GPT Models",
    "authors": [
      "Marc Bruni",
      "Fabio Gabrielli",
      "Mohammad Ghafari",
      "Martin Kropp"
    ],
    "abstract": "Prompt engineering reduces reasoning mistakes in Large Language Models\n(LLMs). However, its effectiveness in mitigating vulnerabilities in\nLLM-generated code remains underexplored. To address this gap, we implemented a\nbenchmark to automatically assess the impact of various prompt engineering\nstrategies on code security. Our benchmark leverages two peer-reviewed prompt\ndatasets and employs static scanners to evaluate code security at scale. We\ntested multiple prompt engineering techniques on GPT-3.5-turbo, GPT-4o, and\nGPT-4o-mini. Our results show that for GPT-4o and GPT-4o-mini, a\nsecurity-focused prompt prefix can reduce the occurrence of security\nvulnerabilities by up to 56%. Additionally, all tested models demonstrated the\nability to detect and repair between 41.9% and 68.7% of vulnerabilities in\npreviously generated code when using iterative prompting techniques. Finally,\nwe introduce a \"prompt agent\" that demonstrates how the most effective\ntechniques can be applied in real-world development workflows.",
    "categories": [
      "cs.SE",
      "cs.AI",
      "cs.CR"
    ],
    "primary_category": "cs.SE",
    "comment": "Accepted at the 2025 IEEE/ACM Second International Conference on AI\n  Foundation Models and Software Engineering (Forge 2025). 10 pages, 7 figures,\n  5 tables",
    "pdf_url": "http://arxiv.org/pdf/2502.06039v1",
    "published_date": "2025-02-09 21:23:07 UTC",
    "updated_date": "2025-02-09 21:23:07 UTC"
  },
  {
    "arxiv_id": "2502.06038v1",
    "title": "Provably Overwhelming Transformer Models with Designed Inputs",
    "authors": [
      "Lev Stambler",
      "Seyed Sajjad Nezhadi",
      "Matthew Coudron"
    ],
    "abstract": "We develop an algorithm which, given a trained transformer model\n$\\mathcal{M}$ as input, as well as a string of tokens $s$ of length $n_{fix}$\nand an integer $n_{free}$, can generate a mathematical proof that $\\mathcal{M}$\nis ``overwhelmed'' by $s$, in time and space $\\widetilde{O}(n_{fix}^2 +\nn_{free}^3)$. We say that $\\mathcal{M}$ is ``overwhelmed'' by $s$ when the\noutput of the model evaluated on this string plus any additional string $t$,\n$\\mathcal{M}(s + t)$, is completely insensitive to the value of the string $t$\nwhenever length($t$) $\\leq n_{free}$. Along the way, we prove a particularly\nstrong worst-case form of ``over-squashing'', which we use to bound the model's\nbehavior. Our technique uses computer-aided proofs to establish this type of\noperationally relevant guarantee about transformer models. We empirically test\nour algorithm on a single layer transformer complete with an attention head,\nlayer-norm, MLP/ReLU layers, and RoPE positional encoding. We believe that this\nwork is a stepping stone towards the difficult task of obtaining useful\nguarantees for trained transformer models.",
    "categories": [
      "cs.LG",
      "cs.AI",
      "cs.CC"
    ],
    "primary_category": "cs.LG",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2502.06038v1",
    "published_date": "2025-02-09 21:21:57 UTC",
    "updated_date": "2025-02-09 21:21:57 UTC"
  },
  {
    "arxiv_id": "2502.09638v1",
    "title": "Jailbreaking to Jailbreak",
    "authors": [
      "Jeremy Kritz",
      "Vaughn Robinson",
      "Robert Vacareanu",
      "Bijan Varjavand",
      "Michael Choi",
      "Bobby Gogov",
      "Scale Red Team",
      "Summer Yue",
      "Willow E. Primack",
      "Zifan Wang"
    ],
    "abstract": "Refusal training on Large Language Models (LLMs) prevents harmful outputs,\nyet this defense remains vulnerable to both automated and human-crafted\njailbreaks. We present a novel LLM-as-red-teamer approach in which a human\njailbreaks a refusal-trained LLM to make it willing to jailbreak itself or\nother LLMs. We refer to the jailbroken LLMs as $J_2$ attackers, which can\nsystematically evaluate target models using various red teaming strategies and\nimprove its performance via in-context learning from the previous failures. Our\nexperiments demonstrate that Sonnet 3.5 and Gemini 1.5 pro outperform other\nLLMs as $J_2$, achieving 93.0% and 91.0% attack success rates (ASRs)\nrespectively against GPT-4o (and similar results across other capable LLMs) on\nHarmbench. Our work not only introduces a scalable approach to strategic red\nteaming, drawing inspiration from human red teamers, but also highlights\njailbreaking-to-jailbreak as an overlooked failure mode of the safeguard.\nSpecifically, an LLM can bypass its own safeguards by employing a jailbroken\nversion of itself that is willing to assist in further jailbreaking. To prevent\nany direct misuse with $J_2$, while advancing research in AI safety, we\npublicly share our methodology while keeping specific prompting details\nprivate.",
    "categories": [
      "cs.CL",
      "cs.AI"
    ],
    "primary_category": "cs.CL",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2502.09638v1",
    "published_date": "2025-02-09 20:49:16 UTC",
    "updated_date": "2025-02-09 20:49:16 UTC"
  },
  {
    "arxiv_id": "2502.06018v1",
    "title": "Kolmogorov-Arnold Fourier Networks",
    "authors": [
      "Jusheng Zhang",
      "Yijia Fan",
      "Kaitong Cai",
      "Keze Wang"
    ],
    "abstract": "Although Kolmogorov-Arnold based interpretable networks (KAN) have strong\ntheoretical expressiveness, they face significant parameter explosion and\nhigh-frequency feature capture challenges in high-dimensional tasks. To address\nthis issue, we propose the Kolmogorov-Arnold-Fourier Network (KAF), which\neffectively integrates trainable Random Fourier Features (RFF) and a novel\nhybrid GELU-Fourier activation mechanism to balance parameter efficiency and\nspectral representation capabilities. Our key technical contributions include:\n(1) merging KAN's dual-matrix structure through matrix association properties\nto substantially reduce parameters; (2) introducing learnable RFF\ninitialization strategies to eliminate spectral distortion in high-dimensional\napproximation tasks; (3) implementing an adaptive hybrid activation function\nthat progressively enhances frequency representation during the training\nprocess. Comprehensive experiments demonstrate the superiority of our KAF\nacross various domains including vision, NLP, audio processing, and\ndifferential equation-solving tasks, effectively combining theoretical\ninterpretability with practical utility and computational efficiency.",
    "categories": [
      "cs.LG",
      "cs.AI"
    ],
    "primary_category": "cs.LG",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2502.06018v1",
    "published_date": "2025-02-09 20:21:43 UTC",
    "updated_date": "2025-02-09 20:21:43 UTC"
  },
  {
    "arxiv_id": "2502.06902v1",
    "title": "Emergence of Episodic Memory in Transformers: Characterizing Changes in Temporal Structure of Attention Scores During Training",
    "authors": [
      "Deven Mahesh Mistry",
      "Anooshka Bajaj",
      "Yash Aggarwal",
      "Sahaj Singh Maini",
      "Zoran Tiganj"
    ],
    "abstract": "We investigate in-context temporal biases in attention heads and transformer\noutputs. Using cognitive science methodologies, we analyze attention scores and\noutputs of the GPT-2 models of varying sizes. Across attention heads, we\nobserve effects characteristic of human episodic memory, including temporal\ncontiguity, primacy and recency. Transformer outputs demonstrate a tendency\ntoward in-context serial recall. Importantly, this effect is eliminated after\nthe ablation of the induction heads, which are the driving force behind the\ncontiguity effect. Our findings offer insights into how transformers organize\ninformation temporally during in-context learning, shedding light on their\nsimilarities and differences with human memory and learning.",
    "categories": [
      "cs.LG",
      "cs.AI",
      "cs.CL"
    ],
    "primary_category": "cs.LG",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2502.06902v1",
    "published_date": "2025-02-09 20:20:37 UTC",
    "updated_date": "2025-02-09 20:20:37 UTC"
  },
  {
    "arxiv_id": "2502.06901v1",
    "title": "Enabling Autoregressive Models to Fill In Masked Tokens",
    "authors": [
      "Daniel Israel",
      "Aditya Grover",
      "Guy Van den Broeck"
    ],
    "abstract": "Historically, LLMs have been trained using either autoregressive (AR) or\nmasked language modeling (MLM) objectives, with AR models gaining dominance in\nrecent years. However, AR models are inherently incapable of masked infilling,\nwhich is the ability to predict masked tokens between past and future context.\nIn contrast, MLM models suffer from intrinsic computational inefficiencies\nduring both training and inference that hinder their scalability. This work\nintroduces MARIA (Masked and Autoregressive Infilling Architecture), a novel\napproach that leverages the strengths of both paradigms to achieve\nstate-of-the-art masked infilling performance. MARIA combines a pre-trained MLM\nand AR model by training a linear decoder that takes their concatenated hidden\nstates as input. This minimal modification enables the AR model to perform\ninfilling while retaining its inherent advantages in terms of faster inference\nwith KV caching. Our results demonstrate that MARIA significantly outperforms\nexisting methods, namely discrete diffusion models, on masked infilling tasks.",
    "categories": [
      "cs.LG",
      "cs.AI",
      "cs.CL"
    ],
    "primary_category": "cs.LG",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2502.06901v1",
    "published_date": "2025-02-09 20:02:05 UTC",
    "updated_date": "2025-02-09 20:02:05 UTC"
  },
  {
    "arxiv_id": "2502.06004v1",
    "title": "Analysis of LLM as a grammatical feature tagger for African American English",
    "authors": [
      "Rahul Porwal",
      "Alice Rozet",
      "Pryce Houck",
      "Jotsna Gowda",
      "Sarah Moeller",
      "Kevin Tang"
    ],
    "abstract": "African American English (AAE) presents unique challenges in natural language\nprocessing (NLP). This research systematically compares the performance of\navailable NLP models--rule-based, transformer-based, and large language models\n(LLMs)--capable of identifying key grammatical features of AAE, namely Habitual\nBe and Multiple Negation. These features were selected for their distinct\ngrammatical complexity and frequency of occurrence. The evaluation involved\nsentence-level binary classification tasks, using both zero-shot and few-shot\nstrategies. The analysis reveals that while LLMs show promise compared to the\nbaseline, they are influenced by biases such as recency and unrelated features\nin the text such as formality. This study highlights the necessity for improved\nmodel training and architectural adjustments to better accommodate AAE's unique\nlinguistic characteristics. Data and code are available.",
    "categories": [
      "cs.CL",
      "cs.AI",
      "cs.LG",
      "I.2.6; I.2.7; K.4.2; J.4; J.5"
    ],
    "primary_category": "cs.CL",
    "comment": "13 pages, Accepted to \"Findings of the Association for Computational\n  Linguistics: NAACL 2025\"",
    "pdf_url": "http://arxiv.org/pdf/2502.06004v1",
    "published_date": "2025-02-09 19:46:33 UTC",
    "updated_date": "2025-02-09 19:46:33 UTC"
  },
  {
    "arxiv_id": "2502.10439v1",
    "title": "Crypto Miner Attack: GPU Remote Code Execution Attacks",
    "authors": [
      "Ariel Szabo",
      "Uzy Hadad"
    ],
    "abstract": "Remote Code Execution (RCE) exploits pose a significant threat to AI and ML\nsystems, particularly in GPU-accelerated environments where the computational\npower of GPUs can be misused for malicious purposes. This paper focuses on RCE\nattacks leveraging deserialization vulnerabilities and custom layers, such as\nTensorFlow Lambda layers, which are often overlooked due to the complexity of\nmonitoring GPU workloads. These vulnerabilities enable attackers to execute\narbitrary code, blending malicious activity seamlessly into expected model\nbehavior and exploiting GPUs for unauthorized tasks such as cryptocurrency\nmining. Unlike traditional CPU-based attacks, the parallel processing nature of\nGPUs and their high resource utilization make runtime detection exceptionally\nchallenging. In this work, we provide a comprehensive examination of RCE\nexploits targeting GPUs, demonstrating an attack that utilizes these\nvulnerabilities to deploy a crypto miner on a GPU. We highlight the technical\nintricacies of such attacks, emphasize their potential for significant\nfinancial and computational costs, and propose strategies for mitigation. By\nshedding light on this underexplored attack vector, we aim to raise awareness\nand encourage the adoption of robust security measures in GPU-driven AI and ML\nsystems, with an emphasis on static and model scanning as an easier way to\ndetect exploits.",
    "categories": [
      "cs.CR",
      "cs.AI",
      "cs.LG"
    ],
    "primary_category": "cs.CR",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2502.10439v1",
    "published_date": "2025-02-09 19:26:47 UTC",
    "updated_date": "2025-02-09 19:26:47 UTC"
  },
  {
    "arxiv_id": "2502.05999v1",
    "title": "Pencils to Pixels: A Systematic Study of Creative Drawings across Children, Adults and AI",
    "authors": [
      "Surabhi S Nath",
      "Guiomar del Cuvillo y Schr√∂der",
      "Claire E. Stevenson"
    ],
    "abstract": "Can we derive computational metrics to quantify visual creativity in drawings\nacross intelligent agents, while accounting for inherent differences in\ntechnical skill and style? To answer this, we curate a novel dataset consisting\nof 1338 drawings by children, adults and AI on a creative drawing task. We\ncharacterize two aspects of the drawings -- (1) style and (2) content. For\nstyle, we define measures of ink density, ink distribution and number of\nelements. For content, we use expert-annotated categories to study conceptual\ndiversity, and image and text embeddings to compute distance measures. We\ncompare the style, content and creativity of children, adults and AI drawings\nand build simple models to predict expert and automated creativity scores. We\nfind significant differences in style and content in the groups -- children's\ndrawings had more components, AI drawings had greater ink density, and adult\ndrawings revealed maximum conceptual diversity. Notably, we highlight a\nmisalignment between creativity judgments obtained through expert and automated\nratings and discuss its implications. Through these efforts, our work provides,\nto the best of our knowledge, the first framework for studying human and\nartificial creativity beyond the textual modality, and attempts to arrive at\nthe domain-agnostic principles underlying creativity. Our data and scripts are\navailable on GitHub.",
    "categories": [
      "cs.HC",
      "cs.AI",
      "cs.CV"
    ],
    "primary_category": "cs.HC",
    "comment": "8 pages, 5 figures, 2 tables",
    "pdf_url": "http://arxiv.org/pdf/2502.05999v1",
    "published_date": "2025-02-09 19:02:32 UTC",
    "updated_date": "2025-02-09 19:02:32 UTC"
  },
  {
    "arxiv_id": "2502.05996v2",
    "title": "Motion Control in Multi-Rotor Aerial Robots Using Deep Reinforcement Learning",
    "authors": [
      "Gaurav Shetty",
      "Mahya Ramezani",
      "Hamed Habibi",
      "Holger Voos",
      "Jose Luis Sanchez-Lopez"
    ],
    "abstract": "This paper investigates the application of Deep Reinforcement (DRL) Learning\nto address motion control challenges in drones for additive manufacturing (AM).\nDrone-based additive manufacturing promises flexible and autonomous material\ndeposition in large-scale or hazardous environments. However, achieving robust\nreal-time control of a multi-rotor aerial robot under varying payloads and\npotential disturbances remains challenging. Traditional controllers like PID\noften require frequent parameter re-tuning, limiting their applicability in\ndynamic scenarios. We propose a DRL framework that learns adaptable control\npolicies for multi-rotor drones performing waypoint navigation in AM tasks. We\ncompare Deep Deterministic Policy Gradient (DDPG) and Twin Delayed Deep\nDeterministic Policy Gradient (TD3) within a curriculum learning scheme\ndesigned to handle increasing complexity. Our experiments show TD3 consistently\nbalances training stability, accuracy, and success, particularly when mass\nvariability is introduced. These findings provide a scalable path toward\nrobust, autonomous drone control in additive manufacturing.",
    "categories": [
      "cs.RO",
      "cs.AI"
    ],
    "primary_category": "cs.RO",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2502.05996v2",
    "published_date": "2025-02-09 19:00:16 UTC",
    "updated_date": "2025-04-14 15:22:05 UTC"
  },
  {
    "arxiv_id": "2502.05980v2",
    "title": "Speech to Speech Translation with Translatotron: A State of the Art Review",
    "authors": [
      "Jules R. Kala",
      "Emmanuel Adetiba",
      "Abdultaofeek Abayom",
      "Oluwatobi E. Dare",
      "Ayodele H. Ifijeh"
    ],
    "abstract": "A cascade-based speech-to-speech translation has been considered a benchmark\nfor a very long time, but it is plagued by many issues, like the time taken to\ntranslate a speech from one language to another and compound errors. These\nissues are because a cascade-based method uses a combination of methods such as\nspeech recognition, speech-to-text translation, and finally, text-to-speech\ntranslation. Translatotron, a sequence-to-sequence direct speech-to-speech\ntranslation model was designed by Google to address the issues of compound\nerrors associated with cascade model. Today there are 3 versions of the\nTranslatotron model: Translatotron 1, Translatotron 2, and Translatotron3. The\nfirst version was designed as a proof of concept to show that a direct\nspeech-to-speech translation was possible, it was found to be less effective\nthan the cascade model but was producing promising results. Translatotron2 was\nan improved version of Translatotron 1 with results similar to the cascade\nmodel. Translatotron 3 the latest version of the model is better than the\ncascade model at some points. In this paper, a complete review of\nspeech-to-speech translation will be presented, with a particular focus on all\nthe versions of Translatotron models. We will also show that Translatotron is\nthe best model to bridge the language gap between African Languages and other\nwell-formalized languages.",
    "categories": [
      "cs.CL",
      "cs.AI"
    ],
    "primary_category": "cs.CL",
    "comment": "12 pages and 3 figures",
    "pdf_url": "http://arxiv.org/pdf/2502.05980v2",
    "published_date": "2025-02-09 18:15:00 UTC",
    "updated_date": "2025-02-19 21:39:35 UTC"
  },
  {
    "arxiv_id": "2502.07817v1",
    "title": "Temporal Model On Quantum Logic",
    "authors": [
      "Francesco D'Agostino"
    ],
    "abstract": "This paper introduces a unified theoretical framework for modeling temporal\nmemory dynamics, combining concepts from temporal logic, memory decay models,\nand hierarchical contexts. The framework formalizes the evolution of\npropositions over time using linear and branching temporal models,\nincorporating exponential decay (Ebbinghaus forgetting curve) and reactivation\nmechanisms via Bayesian updating. The hierarchical organization of memory is\nrepresented using directed acyclic graphs to model recall dependencies and\ninterference. Novel insights include feedback dynamics, recursive influences in\nmemory chains, and the integration of entropy-based recall efficiency. This\napproach provides a foundation for understanding memory processes across\ncognitive and computational domains.",
    "categories": [
      "cs.AI",
      "math.LO",
      "quant-ph"
    ],
    "primary_category": "cs.AI",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2502.07817v1",
    "published_date": "2025-02-09 17:16:53 UTC",
    "updated_date": "2025-02-09 17:16:53 UTC"
  },
  {
    "arxiv_id": "2502.05963v1",
    "title": "Redefining Robot Generalization Through Interactive Intelligence",
    "authors": [
      "Sharmita Dey"
    ],
    "abstract": "Recent advances in large-scale machine learning have produced high-capacity\nfoundation models capable of adapting to a broad array of downstream tasks.\nWhile such models hold great promise for robotics, the prevailing paradigm\nstill portrays robots as single, autonomous decision-makers, performing tasks\nlike manipulation and navigation, with limited human involvement. However, a\nlarge class of real-world robotic systems, including wearable robotics (e.g.,\nprostheses, orthoses, exoskeletons), teleoperation, and neural interfaces, are\nsemiautonomous, and require ongoing interactive coordination with human\npartners, challenging single-agent assumptions. In this position paper, we\nargue that robot foundation models must evolve to an interactive multi-agent\nperspective in order to handle the complexities of real-time human-robot\nco-adaptation. We propose a generalizable, neuroscience-inspired architecture\nencompassing four modules: (1) a multimodal sensing module informed by\nsensorimotor integration principles, (2) an ad-hoc teamwork model reminiscent\nof joint-action frameworks in cognitive science, (3) a predictive world belief\nmodel grounded in internal model theories of motor control, and (4) a\nmemory/feedback mechanism that echoes concepts of Hebbian and\nreinforcement-based plasticity. Although illustrated through the lens of cyborg\nsystems, where wearable devices and human physiology are inseparably\nintertwined, the proposed framework is broadly applicable to robots operating\nin semi-autonomous or interactive contexts. By moving beyond single-agent\ndesigns, our position emphasizes how foundation models in robotics can achieve\na more robust, personalized, and anticipatory level of performance.",
    "categories": [
      "cs.LG",
      "cs.AI",
      "cs.RO"
    ],
    "primary_category": "cs.LG",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2502.05963v1",
    "published_date": "2025-02-09 17:13:27 UTC",
    "updated_date": "2025-02-09 17:13:27 UTC"
  },
  {
    "arxiv_id": "2502.17457v1",
    "title": "MoEMba: A Mamba-based Mixture of Experts for High-Density EMG-based Hand Gesture Recognition",
    "authors": [
      "Mehran Shabanpour",
      "Kasra Rad",
      "Sadaf Khademi",
      "Arash Mohammadi"
    ],
    "abstract": "High-Density surface Electromyography (HDsEMG) has emerged as a pivotal\nresource for Human-Computer Interaction (HCI), offering direct insights into\nmuscle activities and motion intentions. However, a significant challenge in\npractical implementations of HD-sEMG-based models is the low accuracy of\ninter-session and inter-subject classification. Variability between sessions\ncan reach up to 40% due to the inherent temporal variability of HD-sEMG\nsignals. Targeting this challenge, the paper introduces the MoEMba framework, a\nnovel approach leveraging Selective StateSpace Models (SSMs) to enhance\nHD-sEMG-based gesture recognition. The MoEMba framework captures temporal\ndependencies and cross-channel interactions through channel attention\ntechniques. Furthermore, wavelet feature modulation is integrated to capture\nmulti-scale temporal and spatial relations, improving signal representation.\nExperimental results on the CapgMyo HD-sEMG dataset demonstrate that MoEMba\nachieves a balanced accuracy of 56.9%, outperforming its state-of-the-art\ncounterparts. The proposed framework's robustness to session-to-session\nvariability and its efficient handling of high-dimensional multivariate time\nseries data highlight its potential for advancing HD-sEMG-powered HCI systems.",
    "categories": [
      "eess.SP",
      "cs.AI",
      "cs.LG"
    ],
    "primary_category": "eess.SP",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2502.17457v1",
    "published_date": "2025-02-09 17:07:46 UTC",
    "updated_date": "2025-02-09 17:07:46 UTC"
  },
  {
    "arxiv_id": "2502.10438v1",
    "title": "Injecting Universal Jailbreak Backdoors into LLMs in Minutes",
    "authors": [
      "Zhuowei Chen",
      "Qiannan Zhang",
      "Shichao Pei"
    ],
    "abstract": "Jailbreak backdoor attacks on LLMs have garnered attention for their\neffectiveness and stealth. However, existing methods rely on the crafting of\npoisoned datasets and the time-consuming process of fine-tuning. In this work,\nwe propose JailbreakEdit, a novel jailbreak backdoor injection method that\nexploits model editing techniques to inject a universal jailbreak backdoor into\nsafety-aligned LLMs with minimal intervention in minutes. JailbreakEdit\nintegrates a multi-node target estimation to estimate the jailbreak space, thus\ncreating shortcuts from the backdoor to this estimated jailbreak space that\ninduce jailbreak actions. Our attack effectively shifts the models' attention\nby attaching strong semantics to the backdoor, enabling it to bypass internal\nsafety mechanisms. Experimental results show that JailbreakEdit achieves a high\njailbreak success rate on jailbreak prompts while preserving generation\nquality, and safe performance on normal queries. Our findings underscore the\neffectiveness, stealthiness, and explainability of JailbreakEdit, emphasizing\nthe need for more advanced defense mechanisms in LLMs.",
    "categories": [
      "cs.CR",
      "cs.AI",
      "cs.LG"
    ],
    "primary_category": "cs.CR",
    "comment": "Accepted to ICLR 2025",
    "pdf_url": "http://arxiv.org/pdf/2502.10438v1",
    "published_date": "2025-02-09 17:03:23 UTC",
    "updated_date": "2025-02-09 17:03:23 UTC"
  },
  {
    "arxiv_id": "2502.05957v2",
    "title": "AutoAgent: A Fully-Automated and Zero-Code Framework for LLM Agents",
    "authors": [
      "Jiabin Tang",
      "Tianyu Fan",
      "Chao Huang"
    ],
    "abstract": "Large Language Model (LLM) Agents have demonstrated remarkable capabilities\nin task automation and intelligent decision-making, driving the widespread\nadoption of agent development frameworks such as LangChain and AutoGen.\nHowever, these frameworks predominantly serve developers with extensive\ntechnical expertise - a significant limitation considering that only 0.03 % of\nthe global population possesses the necessary programming skills. This stark\naccessibility gap raises a fundamental question: Can we enable everyone,\nregardless of technical background, to build their own LLM agents using natural\nlanguage alone? To address this challenge, we introduce AutoAgent-a\nFully-Automated and highly Self-Developing framework that enables users to\ncreate and deploy LLM agents through Natural Language Alone. Operating as an\nautonomous Agent Operating System, AutoAgent comprises four key components: i)\nAgentic System Utilities, ii) LLM-powered Actionable Engine, iii) Self-Managing\nFile System, and iv) Self-Play Agent Customization module. This lightweight yet\npowerful system enables efficient and dynamic creation and modification of\ntools, agents, and workflows without coding requirements or manual\nintervention. Beyond its code-free agent development capabilities, AutoAgent\nalso serves as a versatile multi-agent system for General AI Assistants.\nComprehensive evaluations on the GAIA benchmark demonstrate AutoAgent's\neffectiveness in generalist multi-agent tasks, surpassing existing\nstate-of-the-art methods. Furthermore, AutoAgent's Retrieval-Augmented\nGeneration (RAG)-related capabilities have shown consistently superior\nperformance compared to many alternative LLM-based solutions.",
    "categories": [
      "cs.AI",
      "cs.CL"
    ],
    "primary_category": "cs.AI",
    "comment": "Code: https://github.com/HKUDS/AutoAgent",
    "pdf_url": "http://arxiv.org/pdf/2502.05957v2",
    "published_date": "2025-02-09 16:53:56 UTC",
    "updated_date": "2025-02-18 06:23:25 UTC"
  },
  {
    "arxiv_id": "2502.08661v2",
    "title": "Few-shot LLM Synthetic Data with Distribution Matching",
    "authors": [
      "Jiyuan Ren",
      "Zhaocheng Du",
      "Zhihao Wen",
      "Qinglin Jia",
      "Sunhao Dai",
      "Chuhan Wu",
      "Zhenhua Dong"
    ],
    "abstract": "As large language models (LLMs) advance, their ability to perform in-context\nlearning and few-shot language generation has improved significantly. This has\nspurred using LLMs to produce high-quality synthetic data to enhance the\nperformance of smaller models like online retrievers or weak LLMs. However,\nLLM-generated synthetic data often differs from the real data in key language\nattributes (e.g., styles, tones, content proportions, etc.). As a result,\nmixing these synthetic data directly with real data may distort the original\ndata distribution, potentially hindering performance improvements. To solve\nthis, we introduce SynAlign: a synthetic data generation and filtering\nframework based on key attribute distribution matching. Before generation,\nSynAlign employs an uncertainty tracker surrogated by the Gaussian Process\nmodel to iteratively select data clusters distinct from selected ones as\ndemonstrations for new data synthesis, facilitating the efficient exploration\ndiversity of the real data. Then, a latent attribute reasoning method is\nemployed: the LLM summarizes linguistic attributes of demonstrations and then\nsynthesizes new data based on them. This approach facilitates synthesizing\ndiverse data with linguistic attributes that appear in real data.After\ngeneration, the Maximum Mean Discrepancy is used as the objective function to\nlearn the sampling weight of each synthetic data, ensuring distribution\nmatching with the real data. Our experiments on multiple text prediction tasks\nshow significant performance improvements. We also conducted an online A/B test\non an online retriever to demonstrate SynAlign's effectiveness.",
    "categories": [
      "cs.CL",
      "cs.AI"
    ],
    "primary_category": "cs.CL",
    "comment": "10 pages, 5 figures, accepted at www 2025",
    "pdf_url": "http://arxiv.org/pdf/2502.08661v2",
    "published_date": "2025-02-09 16:43:32 UTC",
    "updated_date": "2025-02-15 03:49:29 UTC"
  },
  {
    "arxiv_id": "2502.05951v1",
    "title": "Cyri: A Conversational AI-based Assistant for Supporting the Human User in Detecting and Responding to Phishing Attacks",
    "authors": [
      "Antonio La Torre",
      "Marco Angelini"
    ],
    "abstract": "This work introduces Cyri, an AI-powered conversational assistant designed to\nsupport a human user in detecting and analyzing phishing emails by leveraging\nLarge Language Models. Cyri has been designed to scrutinize emails for semantic\nfeatures used in phishing attacks, such as urgency, and undesirable\nconsequences, using an approach that unifies features already established in\nthe literature with others by Cyri features extraction methodology. Cyri can be\ndirectly plugged into a client mail or webmail, ensuring seamless integration\nwith the user's email workflow while maintaining data privacy through local\nprocessing. By performing analyses on the user's machine, Cyri eliminates the\nneed to transmit sensitive email data over the internet, reducing associated\nsecurity risks. The Cyri user interface has been designed to reduce habituation\neffects and enhance user engagement. It employs dynamic visual cues and\ncontext-specific explanations to keep users alert and informed while using\nemails. Additionally, it allows users to explore identified malicious semantic\nfeatures both through conversation with the agent and visual exploration,\nobtaining the advantages of both modalities for expert or non-expert users. It\nalso allows users to keep track of the conversation, supports the user in\nsolving additional questions on both computed features or new parts of the\nmail, and applies its detection on demand. To evaluate Cyri, we crafted a\ncomprehensive dataset of 420 phishing emails and 420 legitimate emails. Results\ndemonstrate high effectiveness in identifying critical phishing semantic\nfeatures fundamental to phishing detection. A user study involving 10\nparticipants, both experts and non-experts, evaluated Cyri's effectiveness and\nusability. Results indicated that Cyri significantly aided users in identifying\nphishing emails and enhanced their understanding of phishing tactics.",
    "categories": [
      "cs.HC",
      "cs.AI",
      "cs.CR"
    ],
    "primary_category": "cs.HC",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2502.05951v1",
    "published_date": "2025-02-09 16:42:28 UTC",
    "updated_date": "2025-02-09 16:42:28 UTC"
  },
  {
    "arxiv_id": "2502.05950v1",
    "title": "Survival Concept-Based Learning Models",
    "authors": [
      "Stanislav R. Kirpichenko",
      "Lev V. Utkin",
      "Andrei V. Konstantinov",
      "Natalya M. Verbova"
    ],
    "abstract": "Concept-based learning enhances prediction accuracy and interpretability by\nleveraging high-level, human-understandable concepts. However, existing CBL\nframeworks do not address survival analysis tasks, which involve predicting\nevent times in the presence of censored data -- a common scenario in fields\nlike medicine and reliability analysis. To bridge this gap, we propose two\nnovel models: SurvCBM (Survival Concept-based Bottleneck Model) and SurvRCM\n(Survival Regularized Concept-based Model), which integrate concept-based\nlearning with survival analysis to handle censored event time data. The models\nemploy the Cox proportional hazards model and the Beran estimator. SurvCBM is\nbased on the architecture of the well-known concept bottleneck model, offering\ninterpretable predictions through concept-based explanations. SurvRCM uses\nconcepts as regularization to enhance accuracy. Both models are trained\nend-to-end and provide interpretable predictions in terms of concepts. Two\ninterpretability approaches are proposed: one leveraging the linear\nrelationship in the Cox model and another using an instance-based explanation\nframework with the Beran estimator. Numerical experiments demonstrate that\nSurvCBM outperforms SurvRCM and traditional survival models, underscoring the\nimportance and advantages of incorporating concept information. The code for\nthe proposed algorithms is publicly available.",
    "categories": [
      "cs.LG",
      "cs.AI",
      "stat.ML"
    ],
    "primary_category": "cs.LG",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2502.05950v1",
    "published_date": "2025-02-09 16:41:04 UTC",
    "updated_date": "2025-02-09 16:41:04 UTC"
  },
  {
    "arxiv_id": "2502.05949v1",
    "title": "Verifying Proportionality in Temporal Voting",
    "authors": [
      "Edith Elkind",
      "Svetlana Obraztsova",
      "Jannik Peters",
      "Nicholas Teh"
    ],
    "abstract": "We study a model of temporal voting where there is a fixed time horizon, and\nat each round the voters report their preferences over the available candidates\nand a single candidate is selected. Prior work has adapted popular notions of\njustified representation as well as voting rules that provide strong\nrepresentation guarantees from the multiwinner election setting to this model.\nIn our work, we focus on the complexity of verifying whether a given outcome\noffers proportional representation. We show that in the temporal setting\nverification is strictly harder than in multiwinner voting, but identify\nnatural special cases that enable efficient algorithms.",
    "categories": [
      "cs.GT",
      "cs.AI"
    ],
    "primary_category": "cs.GT",
    "comment": "Appears in the 39th AAAI Conference on Artificial Intelligence\n  (AAAI), 2025",
    "pdf_url": "http://arxiv.org/pdf/2502.05949v1",
    "published_date": "2025-02-09 16:30:34 UTC",
    "updated_date": "2025-02-09 16:30:34 UTC"
  },
  {
    "arxiv_id": "2502.05945v2",
    "title": "HSI: Head-Specific Intervention Can Induce Misaligned AI Coordination in Large Language Models",
    "authors": [
      "Paul Darm",
      "Annalisa Riccardi"
    ],
    "abstract": "Robust alignment guardrails for large language models are becoming\nincreasingly important with their widespread application. In contrast to\nprevious studies, we demonstrate that inference-time activation interventions\ncan bypass safety alignments and effectively steer model generations towards\nharmful AI coordination for Llama 2. Our method applies fine-grained\ninterventions at specific model subcomponents, particularly attention heads,\nusing a simple binary choice probing strategy. These interventions then\ngeneralise to the open-ended generation setting effectively circumventing\nsafety guardrails. We show that probing single attention heads is more\neffective than intervening on full layers and intervening on only four\nattention heads is comparable to supervised fine-tuning. We further show that\nonly a few example completions are needed to compute effective steering\ndirections, which is an advantage over classical fine-tuning. Our findings\nhighlight the shortcomings of current alignment techniques. In addition, our\nresults suggest that, at the attention head level, activations encode\nfine-grained linearly separable behaviors. Practically, the approach offers a\nstraightforward methodology to steer large language model behaviour, which\ncould be extended to diverse domains beyond safety requiring fine-grained\ncontrol over the model output. The code and datasets for this study can be\nfound on https://github.com/PaulDrm/targeted_intervention.",
    "categories": [
      "cs.CL",
      "cs.AI",
      "I.2.7"
    ],
    "primary_category": "cs.CL",
    "comment": "Large Language Models (LLMs), Interference-time activation shifting,\n  Steerability, Explainability, AI alignment, Interpretability",
    "pdf_url": "http://arxiv.org/pdf/2502.05945v2",
    "published_date": "2025-02-09 16:11:57 UTC",
    "updated_date": "2025-05-01 09:03:35 UTC"
  },
  {
    "arxiv_id": "2502.06899v1",
    "title": "A Sociotechnical Approach for Knowledge Management (KM)",
    "authors": [
      "Leoncio Jimenez"
    ],
    "abstract": "This article presents a sociotechnical framework for KM. This sociotechnical\nvision of KM allows: (1) to remove KM from a commercial concern; (2) to divide\nthe different KM technologies; and (3) to question the paradigms associated\nwith the social and technical components of KM. It is precisely this last point\nthat this article develops to identify the generic mechanisms of KM. More\nprecisely, the social aspect is explained through the organizational approach\nto KM, the managerial approach to KM, and the biological approach to KM. In\ncontrast, the technical aspect is described through the knowledge and skills\nengineering approach to KM. These approaches also lead us to provide a\ncomparative table between these organizational, managerial, and biological\nvisions of KM.",
    "categories": [
      "cs.DB",
      "cs.AI"
    ],
    "primary_category": "cs.DB",
    "comment": "in French language. The author would like to thank Mrs. Christine\n  Deville for her help with the grammatical correction of the text and\n  especially Mr. Germain Lacoste (director of ENI of Tarbes, France) for his\n  friendship, and finally, I thank something as alive as the always happy song\n  of a hummingbird among flowers. arXiv admin note: substantial text overlap\n  with arXiv:2502.01656",
    "pdf_url": "http://arxiv.org/pdf/2502.06899v1",
    "published_date": "2025-02-09 15:46:04 UTC",
    "updated_date": "2025-02-09 15:46:04 UTC"
  },
  {
    "arxiv_id": "2502.05937v1",
    "title": "A Semi-Supervised Text Generation Framework Combining a Deep Transformer and a GAN",
    "authors": [
      "Shengquan Wang"
    ],
    "abstract": "This paper introduces a framework that connects a deep generative pre-trained\nTransformer language model with a generative adversarial network for\nsemi-supervised text generation. In other words, the proposed model is first\npre-trained unsupervised on a large and diverse text corpus with 24 layers.\nThen a simple GAN architecture for synthetic text generation is introduced, and\nGumbel-Softmax is applied to handle the discreteness of tokens. The paper also\nshows a semi-supervised approach where real data is augmented with GAN samples,\nwhich is further used to fine-tune the Transformer model on the merged dataset.\nDetailed theoretical derivations are also included, outlining the proof of the\nmin-max objective function, and an extensive discussion of the Gumbel-Softmax\nreparameterization trick.",
    "categories": [
      "cs.CL",
      "cs.AI"
    ],
    "primary_category": "cs.CL",
    "comment": "7 pages",
    "pdf_url": "http://arxiv.org/pdf/2502.05937v1",
    "published_date": "2025-02-09 15:38:43 UTC",
    "updated_date": "2025-02-09 15:38:43 UTC"
  },
  {
    "arxiv_id": "2502.05934v1",
    "title": "Barriers and Pathways to Human-AI Alignment: A Game-Theoretic Approach",
    "authors": [
      "Aran Nayebi"
    ],
    "abstract": "Under what conditions can capable AI agents efficiently align their actions\nwith human preferences? More specifically, when they are proficient enough to\ncollaborate with us, how long does coordination take, and when is it\ncomputationally feasible? These foundational questions of AI alignment help\ndefine what makes an AI agent ``sufficiently safe'' and valuable to humans.\nSince such generally capable systems do not yet exist, a theoretical analysis\nis needed to establish when guarantees hold -- and what they even are.\n  We introduce a game-theoretic framework that generalizes prior alignment\napproaches with fewer assumptions, allowing us to analyze the computational\ncomplexity of alignment across $M$ objectives and $N$ agents, providing both\nupper and lower bounds. Unlike previous work, which often assumes common\npriors, idealized communication, or implicit tractability, our framework\nformally characterizes the difficulty of alignment under minimal assumptions.\n  Our main result shows that even when agents are fully rational and\ncomputationally \\emph{unbounded}, alignment can be achieved with high\nprobability in time \\emph{linear} in the task space size. Therefore, in\nreal-world settings, where task spaces are often \\emph{exponential} in input\nlength, this remains impractical. More strikingly, our lower bound demonstrates\nthat alignment is \\emph{impossible} to speed up when scaling to exponentially\nmany tasks or agents, highlighting a fundamental computational barrier to\nscalable alignment.\n  Relaxing these idealized assumptions, we study \\emph{computationally bounded}\nagents with noisy messages (representing obfuscated intent), showing that while\nalignment can still succeed with high probability, it incurs additional\n\\emph{exponential} slowdowns in the task space size, number of agents, and\nnumber of tasks.\n  We conclude by identifying conditions that make alignment more feasible.",
    "categories": [
      "cs.AI",
      "cs.CC",
      "cs.GT",
      "cs.LG",
      "cs.MA"
    ],
    "primary_category": "cs.AI",
    "comment": "32 pages, including 5 main theorems and 10 lemmas",
    "pdf_url": "http://arxiv.org/pdf/2502.05934v1",
    "published_date": "2025-02-09 15:27:35 UTC",
    "updated_date": "2025-02-09 15:27:35 UTC"
  },
  {
    "arxiv_id": "2502.05933v2",
    "title": "Learning to Substitute Words with Model-based Score Ranking",
    "authors": [
      "Hongye Liu",
      "Ricardo Henao"
    ],
    "abstract": "Smart word substitution aims to enhance sentence quality by improving word\nchoices; however current benchmarks rely on human-labeled data. Since word\nchoices are inherently subjective, ground-truth word substitutions generated by\na small group of annotators are often incomplete and likely not generalizable.\nTo circumvent this issue, we instead employ a model-based score (BARTScore) to\nquantify sentence quality, thus forgoing the need for human annotations.\nSpecifically, we use this score to define a distribution for each word\nsubstitution, allowing one to test whether a substitution is statistically\nsuperior relative to others. In addition, we propose a loss function that\ndirectly optimizes the alignment between model predictions and sentence scores,\nwhile also enhancing the overall quality score of a substitution. Crucially,\nmodel learning no longer requires human labels, thus avoiding the cost of\nannotation while maintaining the quality of the text modified with\nsubstitutions. Experimental results show that the proposed approach outperforms\nboth masked language models (BERT, BART) and large language models (GPT-4,\nLLaMA). The source code is available at\nhttps://github.com/Hyfred/Substitute-Words-with-Ranking.",
    "categories": [
      "cs.CL",
      "cs.AI"
    ],
    "primary_category": "cs.CL",
    "comment": "Accepted at NAACL 2025 (main, long)",
    "pdf_url": "http://arxiv.org/pdf/2502.05933v2",
    "published_date": "2025-02-09 15:26:32 UTC",
    "updated_date": "2025-02-14 23:09:11 UTC"
  },
  {
    "arxiv_id": "2502.05932v2",
    "title": "Skill Expansion and Composition in Parameter Space",
    "authors": [
      "Tenglong Liu",
      "Jianxiong Li",
      "Yinan Zheng",
      "Haoyi Niu",
      "Yixing Lan",
      "Xin Xu",
      "Xianyuan Zhan"
    ],
    "abstract": "Humans excel at reusing prior knowledge to address new challenges and\ndeveloping skills while solving problems. This paradigm becomes increasingly\npopular in the development of autonomous agents, as it develops systems that\ncan self-evolve in response to new challenges like human beings. However,\nprevious methods suffer from limited training efficiency when expanding new\nskills and fail to fully leverage prior knowledge to facilitate new task\nlearning. In this paper, we propose Parametric Skill Expansion and Composition\n(PSEC), a new framework designed to iteratively evolve the agents' capabilities\nand efficiently address new challenges by maintaining a manageable skill\nlibrary. This library can progressively integrate skill primitives as\nplug-and-play Low-Rank Adaptation (LoRA) modules in parameter-efficient\nfinetuning, facilitating efficient and flexible skill expansion. This structure\nalso enables the direct skill compositions in parameter space by merging LoRA\nmodules that encode different skills, leveraging shared information across\nskills to effectively program new skills. Based on this, we propose a\ncontext-aware module to dynamically activate different skills to\ncollaboratively handle new tasks. Empowering diverse applications including\nmulti-objective composition, dynamics shift, and continual policy shift, the\nresults on D4RL, DSRL benchmarks, and the DeepMind Control Suite show that PSEC\nexhibits superior capacity to leverage prior knowledge to efficiently tackle\nnew challenges, as well as expand its skill libraries to evolve the\ncapabilities. Project website: https://ltlhuuu.github.io/PSEC/.",
    "categories": [
      "cs.LG",
      "cs.AI",
      "cs.RO"
    ],
    "primary_category": "cs.LG",
    "comment": "ICLR 2025, 37 pages",
    "pdf_url": "http://arxiv.org/pdf/2502.05932v2",
    "published_date": "2025-02-09 15:22:38 UTC",
    "updated_date": "2025-03-16 11:57:19 UTC"
  },
  {
    "arxiv_id": "2502.05931v1",
    "title": "Protecting Intellectual Property of EEG-based Neural Networks with Watermarking",
    "authors": [
      "Ahmed Abdelaziz",
      "Ahmed Fathi",
      "Ahmed Fares"
    ],
    "abstract": "EEG-based neural networks, pivotal in medical diagnosis and brain-computer\ninterfaces, face significant intellectual property (IP) risks due to their\nreliance on sensitive neurophysiological data and resource-intensive\ndevelopment. Current watermarking methods, particularly those using abstract\ntrigger sets, lack robust authentication and fail to address the unique\nchallenges of EEG models. This paper introduces a cryptographic wonder\nfilter-based watermarking framework tailored for EEG-based neural networks.\nLeveraging collision-resistant hashing and public-key encryption, the wonder\nfilter embeds the watermark during training, ensuring minimal distortion ($\\leq\n5\\%$ drop in EEG task accuracy) and high reliability (100\\% watermark\ndetection). The framework is rigorously evaluated against adversarial attacks,\nincluding fine-tuning, transfer learning, and neuron pruning. Results\ndemonstrate persistent watermark retention, with classification accuracy for\nwatermarked states remaining above 90\\% even after aggressive pruning, while\nprimary task performance degrades faster, deterring removal attempts. Piracy\nresistance is validated by the inability to embed secondary watermarks without\nsevere accuracy loss ( $>10\\%$ in EEGNet and CCNN models). Cryptographic\nhashing ensures authentication, reducing brute-force attack success\nprobabilities. Evaluated on the DEAP dataset across models (CCNN, EEGNet,\nTSception), the method achieves $>99.4\\%$ null-embedding accuracy, effectively\neliminating false positives. By integrating wonder filters with EEG-specific\nadaptations, this work bridges a critical gap in IP protection for\nneurophysiological models, offering a secure, tamper-proof solution for\nhealthcare and biometric applications. The framework's robustness against\nadversarial modifications underscores its potential to safeguard sensitive EEG\nmodels while maintaining diagnostic utility.",
    "categories": [
      "cs.LG",
      "cs.AI",
      "cs.CR",
      "94A60, 68P25",
      "H.1.2; I.2.6; J.3; K.5.1"
    ],
    "primary_category": "cs.LG",
    "comment": "21 pages, 13 figures, and 6 tables",
    "pdf_url": "http://arxiv.org/pdf/2502.05931v1",
    "published_date": "2025-02-09 15:21:45 UTC",
    "updated_date": "2025-02-09 15:21:45 UTC"
  },
  {
    "arxiv_id": "2502.05925v1",
    "title": "Sign-Symmetry Learning Rules are Robust Fine-Tuners",
    "authors": [
      "Aymene Berriche",
      "Mehdi Zakaria Adjal",
      "Riyadh Baghdadi"
    ],
    "abstract": "Backpropagation (BP) has long been the predominant method for training neural\nnetworks due to its effectiveness. However, numerous alternative approaches,\nbroadly categorized under feedback alignment, have been proposed, many of which\nare motivated by the search for biologically plausible learning mechanisms.\nDespite their theoretical appeal, these methods have consistently\nunderperformed compared to BP, leading to a decline in research interest. In\nthis work, we revisit the role of such methods and explore how they can be\nintegrated into standard neural network training pipelines. Specifically, we\npropose fine-tuning BP-pre-trained models using Sign-Symmetry learning rules\nand demonstrate that this approach not only maintains performance parity with\nBP but also enhances robustness. Through extensive experiments across multiple\ntasks and benchmarks, we establish the validity of our approach. Our findings\nintroduce a novel perspective on neural network training and open new research\ndirections for leveraging biologically inspired learning rules in deep\nlearning.",
    "categories": [
      "cs.LG",
      "cs.AI"
    ],
    "primary_category": "cs.LG",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2502.05925v1",
    "published_date": "2025-02-09 14:59:57 UTC",
    "updated_date": "2025-02-09 14:59:57 UTC"
  },
  {
    "arxiv_id": "2502.06898v1",
    "title": "Large Language Models for In-File Vulnerability Localization Can Be \"Lost in the End\"",
    "authors": [
      "Francesco Sovrano",
      "Adam Bauer",
      "Alberto Bacchelli"
    ],
    "abstract": "Recent advancements in artificial intelligence have enabled processing of\nlarger inputs, leading everyday software developers to increasingly rely on\nchat-based large language models (LLMs) like GPT-3.5 and GPT-4 to detect\nvulnerabilities across entire files, not just within functions. This new\ndevelopment practice requires researchers to urgently investigate whether\ncommonly used LLMs can effectively analyze large file-sized inputs, in order to\nprovide timely insights for software developers and engineers about the pros\nand cons of this emerging technological trend. Hence, the goal of this paper is\nto evaluate the effectiveness of several state-of-the-art chat-based LLMs,\nincluding the GPT models, in detecting in-file vulnerabilities. We conducted a\ncostly investigation into how the performance of LLMs varies based on\nvulnerability type, input size, and vulnerability location within the file. To\ngive enough statistical power to our study, we could only focus on the three\nmost common (as well as dangerous) vulnerabilities: XSS, SQL injection, and\npath traversal. Our findings indicate that the effectiveness of LLMs in\ndetecting these vulnerabilities is strongly influenced by both the location of\nthe vulnerability and the overall size of the input. Specifically, regardless\nof the vulnerability type, LLMs tend to significantly (p < .05) underperform\nwhen detecting vulnerabilities located toward the end of larger files, a\npattern we call the 'lost-in-the-end' effect. Finally, to further support\nsoftware developers and practitioners, we also explored the optimal input size\nfor these LLMs and presented a simple strategy for identifying it, which can be\napplied to other models and vulnerability types. Eventually, we show how\nadjusting the input size can lead to significant improvements in LLM-based\nvulnerability detection, with an average recall increase of over 37% across all\nmodels.",
    "categories": [
      "cs.SE",
      "cs.AI"
    ],
    "primary_category": "cs.SE",
    "comment": "Accepted for publication at the ACM International Conference on the\n  Foundations of Software Engineering (FSE) 2025. Replication Package:\n  https://doi.org/10.5281/zenodo.14840519",
    "pdf_url": "http://arxiv.org/pdf/2502.06898v1",
    "published_date": "2025-02-09 14:51:15 UTC",
    "updated_date": "2025-02-09 14:51:15 UTC"
  },
  {
    "arxiv_id": "2502.10436v4",
    "title": "MERGE$^3$: Efficient Evolutionary Merging on Consumer-grade GPUs",
    "authors": [
      "Tommaso Mencattini",
      "Adrian Robert Minut",
      "Donato Crisostomi",
      "Andrea Santilli",
      "Emanuele Rodol√†"
    ],
    "abstract": "Evolutionary model merging enables the creation of high-performing multi-task\nmodels but remains computationally prohibitive for consumer hardware. We\nintroduce MERGE$^3$, an efficient framework that makes evolutionary merging\nfeasible on a single GPU by reducing fitness computation costs 50$\\times$ while\npreserving performance. MERGE$^3$ achieves this by Extracting a reduced dataset\nfor evaluation, Estimating model abilities using Item Response Theory (IRT),\nand Evolving optimal merges via IRT-based performance estimators. Our method\nenables state-of-the-art multilingual and cross-lingual merging, transferring\nknowledge across languages with significantly lower computational overhead. We\nprovide theoretical guarantees and an open-source library, democratizing\nhigh-quality model merging.",
    "categories": [
      "cs.NE",
      "cs.AI",
      "cs.LG"
    ],
    "primary_category": "cs.NE",
    "comment": "In Proceedings of The Forty-Second International Conference on\n  Machine Learning (ICML 2025)",
    "pdf_url": "http://arxiv.org/pdf/2502.10436v4",
    "published_date": "2025-02-09 14:24:16 UTC",
    "updated_date": "2025-05-09 08:38:05 UTC"
  },
  {
    "arxiv_id": "2502.06897v1",
    "title": "PyPotteryInk: One-Step Diffusion Model for Sketch to Publication-ready Archaeological Drawings",
    "authors": [
      "Lorenzo Cardarelli"
    ],
    "abstract": "Archaeological pottery documentation traditionally requires a time-consuming\nmanual process of converting pencil sketches into publication-ready inked\ndrawings. I present PyPotteryInk, an open-source automated pipeline that\ntransforms archaeological pottery sketches into standardised publication-ready\ndrawings using a one-step diffusion model. Built on a modified img2img-turbo\narchitecture, the system processes drawings in a single forward pass while\npreserving crucial morphological details and maintaining archaeologic\ndocumentation standards and analytical value. The model employs an efficient\npatch-based approach with dynamic overlap, enabling high-resolution output\nregardless of input drawing size. I demonstrate the effectiveness of the\napproach on a dataset of Italian protohistoric pottery drawings, where it\nsuccessfully captures both fine details like decorative patterns and structural\nelements like vessel profiles or handling elements. Expert evaluation confirms\nthat the generated drawings meet publication standards while significantly\nreducing processing time from hours to seconds per drawing. The model can be\nfine-tuned to adapt to different archaeological contexts with minimal training\ndata, making it versatile across various pottery documentation styles. The\npre-trained models, the Python library and comprehensive documentation are\nprovided to facilitate adoption within the archaeological research community.",
    "categories": [
      "cs.GR",
      "cs.AI",
      "cs.CV"
    ],
    "primary_category": "cs.GR",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2502.06897v1",
    "published_date": "2025-02-09 14:03:37 UTC",
    "updated_date": "2025-02-09 14:03:37 UTC"
  },
  {
    "arxiv_id": "2502.17456v1",
    "title": "Survey on Recent Progress of AI for Chemistry: Methods, Applications, and Opportunities",
    "authors": [
      "Hu Ding",
      "Pengxiang Hua",
      "Zhen Huang"
    ],
    "abstract": "The development of artificial intelligence (AI) techniques has brought\nrevolutionary changes across various realms. In particular, the use of\nAI-assisted methods to accelerate chemical research has become a popular and\nrapidly growing trend, leading to numerous groundbreaking works. In this paper,\nwe provide a comprehensive review of current AI techniques in chemistry from a\ncomputational perspective, considering various aspects in the design of\nmethods. We begin by discussing the characteristics of data from diverse\nsources, followed by an overview of various representation methods. Next, we\nreview existing models for several topical tasks in the field, and conclude by\nhighlighting some key challenges that warrant further attention.",
    "categories": [
      "physics.chem-ph",
      "cs.AI",
      "cs.LG"
    ],
    "primary_category": "physics.chem-ph",
    "comment": "22 pages, 8 figures, 4 tables",
    "pdf_url": "http://arxiv.org/pdf/2502.17456v1",
    "published_date": "2025-02-09 13:39:49 UTC",
    "updated_date": "2025-02-09 13:39:49 UTC"
  },
  {
    "arxiv_id": "2502.05892v1",
    "title": "A Distributional Perspective on Word Learning in Neural Language Models",
    "authors": [
      "Filippo Ficarra",
      "Ryan Cotterell",
      "Alex Warstadt"
    ],
    "abstract": "Language models (LMs) are increasingly being studied as models of human\nlanguage learners. Due to the nascency of the field, it is not well-established\nwhether LMs exhibit similar learning dynamics to humans, and there are few\ndirect comparisons between learning trajectories in humans and models. Word\nlearning trajectories for children are relatively well-documented, and recent\nwork has tried to extend these investigations to language models. However,\nthere are no widely agreed-upon metrics for word learning in language models.\nWe take a distributional approach to this problem, defining lexical knowledge\nin terms of properties of the learned distribution for a target word. We argue\nthat distributional signatures studied in prior work fail to capture key\ndistributional information. Thus, we propose an array of signatures that\nimprove on earlier approaches by capturing knowledge of both where the target\nword can and cannot occur as well as gradient preferences about the word's\nappropriateness. We obtain learning trajectories for a selection of small\nlanguage models we train from scratch, study the relationship between different\ndistributional signatures, compare how well they align with human word learning\ntrajectories and interpretable lexical features, and address basic\nmethodological questions about estimating these distributional signatures. Our\nmetrics largely capture complementary information, suggesting that it is\nimportant not to rely on a single metric. However, across all metrics, language\nmodels' learning trajectories fail to correlate with those of children.",
    "categories": [
      "cs.CL",
      "cs.AI"
    ],
    "primary_category": "cs.CL",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2502.05892v1",
    "published_date": "2025-02-09 13:15:59 UTC",
    "updated_date": "2025-02-09 13:15:59 UTC"
  },
  {
    "arxiv_id": "2502.18483v1",
    "title": "Modeling Churn in Recommender Systems with Aggregated Preferences",
    "authors": [
      "Gur Keinan",
      "Omer Ben-Porat"
    ],
    "abstract": "While recommender systems (RSs) traditionally rely on extensive individual\nuser data, regulatory and technological shifts necessitate reliance on\naggregated user information. This shift significantly impacts the\nrecommendation process, requiring RSs to engage in intensive exploration to\nidentify user preferences. However, this approach risks user churn due to\npotentially unsatisfactory recommendations. In this paper, we propose a model\nthat addresses the dual challenges of leveraging aggregated user information\nand mitigating churn risk. Our model assumes that the RS operates with a\nprobabilistic prior over user types and aggregated satisfaction levels for\nvarious content types. We demonstrate that optimal policies naturally\ntransition from exploration to exploitation in finite time, develop a\nbranch-and-bound algorithm for computing these policies, and empirically\nvalidate its effectiveness.",
    "categories": [
      "cs.IR",
      "cs.AI",
      "cs.LG"
    ],
    "primary_category": "cs.IR",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2502.18483v1",
    "published_date": "2025-02-09 13:12:11 UTC",
    "updated_date": "2025-02-09 13:12:11 UTC"
  },
  {
    "arxiv_id": "2502.05887v1",
    "title": "MTPChat: A Multimodal Time-Aware Persona Dataset for Conversational Agents",
    "authors": [
      "Wanqi Yang",
      "Yanda Li",
      "Meng Fang",
      "Ling Chen"
    ],
    "abstract": "Understanding temporal dynamics is critical for conversational agents,\nenabling effective content analysis and informed decision-making. However,\ntime-aware datasets, particularly for persona-grounded conversations, are still\nlimited, which narrows their scope and diminishes their complexity. To address\nthis gap, we introduce MTPChat, a multimodal, time-aware persona dialogue\ndataset that integrates linguistic, visual, and temporal elements within\ndialogue and persona memory. Leveraging MTPChat, we propose two time-sensitive\ntasks: Temporal Next Response Prediction (TNRP) and Temporal Grounding Memory\nPrediction (TGMP), both designed to assess a model's ability to understand\nimplicit temporal cues and dynamic interactions. Additionally, we present an\ninnovative framework featuring an adaptive temporal module to effectively\nintegrate multimodal streams and capture temporal dependencies. Experimental\nresults validate the challenges posed by MTPChat and demonstrate the\neffectiveness of our framework in multimodal time-sensitive scenarios.",
    "categories": [
      "cs.CL",
      "cs.AI"
    ],
    "primary_category": "cs.CL",
    "comment": "NAACL 2025 Findings",
    "pdf_url": "http://arxiv.org/pdf/2502.05887v1",
    "published_date": "2025-02-09 13:00:53 UTC",
    "updated_date": "2025-02-09 13:00:53 UTC"
  },
  {
    "arxiv_id": "2502.05883v1",
    "title": "NeuralPrefix: A Zero-shot Sensory Data Imputation Plugin",
    "authors": [
      "Abdelwahed Khamis",
      "Sara Khalifa"
    ],
    "abstract": "Real-world sensing challenges such as sensor failures, communication issues,\nand power constraints lead to data intermittency. An issue that is known to\nundermine the traditional classification task that assumes a continuous data\nstream. Previous works addressed this issue by designing bespoke solutions\n(i.e. task-specific and/or modality-specific imputation). These approaches,\nwhile effective for their intended purposes, had limitations in their\napplicability across different tasks and sensor modalities. This raises an\nimportant question: Can we build a task-agnostic imputation pipeline that is\ntransferable to new sensors without requiring additional training? In this\nwork, we formalise the concept of zero-shot imputation and propose a novel\napproach that enables the adaptation of pre-trained models to handle data\nintermittency. This framework, named NeuralPrefix, is a generative neural\ncomponent that precedes a task model during inference, filling in gaps caused\nby data intermittency. NeuralPrefix is built as a continuous dynamical system,\nwhere its internal state can be estimated at any point in time by solving an\nOrdinary Differential Equation (ODE). This approach allows for a more versatile\nand adaptable imputation method, overcoming the limitations of task-specific\nand modality-specific solutions. We conduct a comprehensive evaluation of\nNeuralPrefix on multiple sensory datasets, demonstrating its effectiveness\nacross various domains. When tested on intermittent data with a high 50%\nmissing data rate, NeuralPreifx accurately recovers all the missing samples,\nachieving SSIM score between 0.93-0.96. Zero-shot evaluations show that\nNeuralPrefix generalises well to unseen datasets, even when the measurements\ncome from a different modality.",
    "categories": [
      "cs.LG",
      "cs.AI",
      "stat.ML"
    ],
    "primary_category": "cs.LG",
    "comment": "Accepted in PerCom 25",
    "pdf_url": "http://arxiv.org/pdf/2502.05883v1",
    "published_date": "2025-02-09 12:47:55 UTC",
    "updated_date": "2025-02-09 12:47:55 UTC"
  },
  {
    "arxiv_id": "2502.06894v1",
    "title": "AI-Driven HSI: Multimodality, Fusion, Challenges, and the Deep Learning Revolution",
    "authors": [
      "David S. Bhatti",
      "Yougin Choi",
      "Rahman S M Wahidur",
      "Maleeka Bakhtawar",
      "Sumin Kim",
      "Surin Lee",
      "Yongtae Lee",
      "Heung-No Lee"
    ],
    "abstract": "Hyperspectral imaging (HSI) captures spatial and spectral data, enabling\nanalysis of features invisible to conventional systems. The technology is vital\nin fields such as weather monitoring, food quality control, counterfeit\ndetection, healthcare diagnostics, and extending into defense, agriculture, and\nindustrial automation at the same time. HSI has advanced with improvements in\nspectral resolution, miniaturization, and computational methods. This study\nprovides an overview of the HSI, its applications, challenges in data fusion\nand the role of deep learning models in processing HSI data. We discuss how\nintegration of multimodal HSI with AI, particularly with deep learning,\nimproves classification accuracy and operational efficiency. Deep learning\nenhances HSI analysis in areas like feature extraction, change detection,\ndenoising unmixing, dimensionality reduction, landcover mapping, data\naugmentation, spectral construction and super resolution. An emerging focus is\nthe fusion of hyperspectral cameras with large language models (LLMs), referred\nas highbrain LLMs, enabling the development of advanced applications such as\nlow visibility crash detection and face antispoofing. We also highlight key\nplayers in HSI industry, its compound annual growth rate and the growing\nindustrial significance. The purpose is to offer insight to both technical and\nnon-technical audience, covering HSI's images, trends, and future directions,\nwhile providing valuable information on HSI datasets and software libraries.",
    "categories": [
      "cs.CV",
      "cs.AI",
      "68T07 Artificial neural networks and deep learning"
    ],
    "primary_category": "cs.CV",
    "comment": "39 Pages, 22 figures, 20 tables",
    "pdf_url": "http://arxiv.org/pdf/2502.06894v1",
    "published_date": "2025-02-09 12:44:16 UTC",
    "updated_date": "2025-02-09 12:44:16 UTC"
  },
  {
    "arxiv_id": "2502.05879v1",
    "title": "Enhancing Depression Detection with Chain-of-Thought Prompting: From Emotion to Reasoning Using Large Language Models",
    "authors": [
      "Shiyu Teng",
      "Jiaqing Liu",
      "Rahul Kumar Jain",
      "Shurong Chai",
      "Ruibo Hou",
      "Tomoko Tateyama",
      "Lanfen Lin",
      "Yen-wei Chen"
    ],
    "abstract": "Depression is one of the leading causes of disability worldwide, posing a\nsevere burden on individuals, healthcare systems, and society at large. Recent\nadvancements in Large Language Models (LLMs) have shown promise in addressing\nmental health challenges, including the detection of depression through\ntext-based analysis. However, current LLM-based methods often struggle with\nnuanced symptom identification and lack a transparent, step-by-step reasoning\nprocess, making it difficult to accurately classify and explain mental health\nconditions. To address these challenges, we propose a Chain-of-Thought\nPrompting approach that enhances both the performance and interpretability of\nLLM-based depression detection. Our method breaks down the detection process\ninto four stages: (1) sentiment analysis, (2) binary depression classification,\n(3) identification of underlying causes, and (4) assessment of severity. By\nguiding the model through these structured reasoning steps, we improve\ninterpretability and reduce the risk of overlooking subtle clinical indicators.\nWe validate our method on the E-DAIC dataset, where we test multiple\nstate-of-the-art large language models. Experimental results indicate that our\nChain-of-Thought Prompting technique yields superior performance in both\nclassification accuracy and the granularity of diagnostic insights, compared to\nbaseline approaches.",
    "categories": [
      "cs.CL",
      "cs.AI"
    ],
    "primary_category": "cs.CL",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2502.05879v1",
    "published_date": "2025-02-09 12:30:57 UTC",
    "updated_date": "2025-02-09 12:30:57 UTC"
  },
  {
    "arxiv_id": "2502.05874v3",
    "title": "MMGDreamer: Mixed-Modality Graph for Geometry-Controllable 3D Indoor Scene Generation",
    "authors": [
      "Zhifei Yang",
      "Keyang Lu",
      "Chao Zhang",
      "Jiaxing Qi",
      "Hanqi Jiang",
      "Ruifei Ma",
      "Shenglin Yin",
      "Yifan Xu",
      "Mingzhe Xing",
      "Zhen Xiao",
      "Jieyi Long",
      "Guangyao Zhai"
    ],
    "abstract": "Controllable 3D scene generation has extensive applications in virtual\nreality and interior design, where the generated scenes should exhibit high\nlevels of realism and controllability in terms of geometry. Scene graphs\nprovide a suitable data representation that facilitates these applications.\nHowever, current graph-based methods for scene generation are constrained to\ntext-based inputs and exhibit insufficient adaptability to flexible user\ninputs, hindering the ability to precisely control object geometry. To address\nthis issue, we propose MMGDreamer, a dual-branch diffusion model for scene\ngeneration that incorporates a novel Mixed-Modality Graph, visual enhancement\nmodule, and relation predictor. The mixed-modality graph allows object nodes to\nintegrate textual and visual modalities, with optional relationships between\nnodes. It enhances adaptability to flexible user inputs and enables meticulous\ncontrol over the geometry of objects in the generated scenes. The visual\nenhancement module enriches the visual fidelity of text-only nodes by\nconstructing visual representations using text embeddings. Furthermore, our\nrelation predictor leverages node representations to infer absent relationships\nbetween nodes, resulting in more coherent scene layouts. Extensive experimental\nresults demonstrate that MMGDreamer exhibits superior control of object\ngeometry, achieving state-of-the-art scene generation performance. Project\npage: https://yangzhifeio.github.io/project/MMGDreamer.",
    "categories": [
      "cs.CV",
      "cs.AI",
      "cs.LG"
    ],
    "primary_category": "cs.CV",
    "comment": "Accepted by AAAI 2025 Main Track",
    "pdf_url": "http://arxiv.org/pdf/2502.05874v3",
    "published_date": "2025-02-09 12:23:40 UTC",
    "updated_date": "2025-03-26 11:27:37 UTC"
  },
  {
    "arxiv_id": "2502.06892v1",
    "title": "Certifying Language Model Robustness with Fuzzed Randomized Smoothing: An Efficient Defense Against Backdoor Attacks",
    "authors": [
      "Bowei He",
      "Lihao Yin",
      "Hui-Ling Zhen",
      "Jianping Zhang",
      "Lanqing Hong",
      "Mingxuan Yuan",
      "Chen Ma"
    ],
    "abstract": "The widespread deployment of pre-trained language models (PLMs) has exposed\nthem to textual backdoor attacks, particularly those planted during the\npre-training stage. These attacks pose significant risks to high-reliability\napplications, as they can stealthily affect multiple downstream tasks. While\ncertifying robustness against such threats is crucial, existing defenses\nstruggle with the high-dimensional, interdependent nature of textual data and\nthe lack of access to original poisoned pre-training data. To address these\nchallenges, we introduce \\textbf{F}uzzed \\textbf{R}andomized \\textbf{S}moothing\n(\\textbf{FRS}), a novel approach for efficiently certifying language model\nrobustness against backdoor attacks. FRS integrates software robustness\ncertification techniques with biphased model parameter smoothing, employing\nMonte Carlo tree search for proactive fuzzing to identify vulnerable textual\nsegments within the Damerau-Levenshtein space. This allows for targeted and\nefficient text randomization, while eliminating the need for access to poisoned\ntraining data during model smoothing. Our theoretical analysis demonstrates\nthat FRS achieves a broader certified robustness radius compared to existing\nmethods. Extensive experiments across various datasets, model configurations,\nand attack strategies validate FRS's superiority in terms of defense\nefficiency, accuracy, and robustness.",
    "categories": [
      "cs.LG",
      "cs.AI"
    ],
    "primary_category": "cs.LG",
    "comment": "Accepted by ICLR 2025",
    "pdf_url": "http://arxiv.org/pdf/2502.06892v1",
    "published_date": "2025-02-09 12:03:59 UTC",
    "updated_date": "2025-02-09 12:03:59 UTC"
  },
  {
    "arxiv_id": "2502.05863v2",
    "title": "Uni-Retrieval: A Multi-Style Retrieval Framework for STEM's Education",
    "authors": [
      "Yanhao Jia",
      "Xinyi Wu",
      "Hao Li",
      "Qinglin Zhang",
      "Yuxiao Hu",
      "Shuai Zhao",
      "Wenqi Fan"
    ],
    "abstract": "In AI-facilitated teaching, leveraging various query styles to interpret\nabstract text descriptions is crucial for ensuring high-quality teaching.\nHowever, current retrieval models primarily focus on natural text-image\nretrieval, making them insufficiently tailored to educational scenarios due to\nthe ambiguities in the retrieval process. In this paper, we propose a diverse\nexpression retrieval task tailored to educational scenarios, supporting\nretrieval based on multiple query styles and expressions. We introduce the STEM\nEducation Retrieval Dataset (SER), which contains over 24,000 query pairs of\ndifferent styles, and the Uni-Retrieval, an efficient and style-diversified\nretrieval vision-language model based on prompt tuning. Uni-Retrieval extracts\nquery style features as prototypes and builds a continuously updated Prompt\nBank containing prompt tokens for diverse queries. This bank can updated during\ntest time to represent domain-specific knowledge for different subject\nretrieval scenarios. Our framework demonstrates scalability and robustness by\ndynamically retrieving prompt tokens based on prototype similarity, effectively\nfacilitating learning for unknown queries. Experimental results indicate that\nUni-Retrieval outperforms existing retrieval models in most retrieval tasks.\nThis advancement provides a scalable and precise solution for diverse\neducational needs.",
    "categories": [
      "cs.IR",
      "cs.AI",
      "cs.MM"
    ],
    "primary_category": "cs.IR",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2502.05863v2",
    "published_date": "2025-02-09 11:46:05 UTC",
    "updated_date": "2025-05-20 12:37:05 UTC"
  },
  {
    "arxiv_id": "2502.05857v2",
    "title": "EgoAgent: A Joint Predictive Agent Model in Egocentric Worlds",
    "authors": [
      "Lu Chen",
      "Yizhou Wang",
      "Shixiang Tang",
      "Qianhong Ma",
      "Tong He",
      "Wanli Ouyang",
      "Xiaowei Zhou",
      "Hujun Bao",
      "Sida Peng"
    ],
    "abstract": "This paper addresses the task of learning an agent model behaving like\nhumans, which can jointly perceive, predict, and act in egocentric worlds.\nPrevious methods usually train separate models for these three abilities, which\nprevents them from learning from each other. In this paper, we propose a joint\npredictive agent model, named EgoAgent, that simultaneously learns to represent\nthe world, predict future states, and take reasonable actions within a single\ntransformer. EgoAgent introduces two innovations to learn from the causal and\ntemporally intertwined nature of these abilities: (1) Interleaved sequential\nmodeling of states and actions with the causal attention mechanism, and (2) A\njoint embedding-action-prediction architecture featuring temporal asymmetric\npredictor-observer branches. Integrating these designs based on JEPA, EgoAgent\nunifies these capabilities in a cohesive learning framework. Comprehensive\nevaluations of EgoAgent on representative tasks such as image classification,\negocentric future state prediction, and 3D human motion prediction tasks\ndemonstrate the superiority of our method. The code and trained model will be\nreleased for reproducibility.",
    "categories": [
      "cs.CV",
      "cs.AI",
      "cs.LG"
    ],
    "primary_category": "cs.CV",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2502.05857v2",
    "published_date": "2025-02-09 11:28:57 UTC",
    "updated_date": "2025-04-29 15:45:49 UTC"
  },
  {
    "arxiv_id": "2502.05836v1",
    "title": "LegalSeg: Unlocking the Structure of Indian Legal Judgments Through Rhetorical Role Classification",
    "authors": [
      "Shubham Kumar Nigam",
      "Tanmay Dubey",
      "Govind Sharma",
      "Noel Shallum",
      "Kripabandhu Ghosh",
      "Arnab Bhattacharya"
    ],
    "abstract": "In this paper, we address the task of semantic segmentation of legal\ndocuments through rhetorical role classification, with a focus on Indian legal\njudgments. We introduce LegalSeg, the largest annotated dataset for this task,\ncomprising over 7,000 documents and 1.4 million sentences, labeled with 7\nrhetorical roles. To benchmark performance, we evaluate multiple\nstate-of-the-art models, including Hierarchical BiLSTM-CRF,\nTransformerOverInLegalBERT (ToInLegalBERT), Graph Neural Networks (GNNs), and\nRole-Aware Transformers, alongside an exploratory RhetoricLLaMA, an\ninstruction-tuned large language model. Our results demonstrate that models\nincorporating broader context, structural relationships, and sequential\nsentence information outperform those relying solely on sentence-level\nfeatures. Additionally, we conducted experiments using surrounding context and\npredicted or actual labels of neighboring sentences to assess their impact on\nclassification accuracy. Despite these advancements, challenges persist in\ndistinguishing between closely related roles and addressing class imbalance.\nOur work underscores the potential of advanced techniques for improving legal\ndocument understanding and sets a strong foundation for future research in\nlegal NLP.",
    "categories": [
      "cs.CL",
      "cs.AI",
      "cs.IR",
      "cs.LG"
    ],
    "primary_category": "cs.CL",
    "comment": "Accepted on NAACL 2025",
    "pdf_url": "http://arxiv.org/pdf/2502.05836v1",
    "published_date": "2025-02-09 10:07:05 UTC",
    "updated_date": "2025-02-09 10:07:05 UTC"
  },
  {
    "arxiv_id": "2502.05835v1",
    "title": "Contrastive Representation Distillation via Multi-Scale Feature Decoupling",
    "authors": [
      "Cuipeng Wang",
      "Tieyuan Chen",
      "Haipeng Wang"
    ],
    "abstract": "Knowledge distillation is a technique aimed at enhancing the performance of a\nsmaller student network without increasing its parameter size by transferring\nknowledge from a larger, pre-trained teacher network. Previous approaches have\npredominantly focused on distilling global feature information while\noverlooking the importance of disentangling the diverse types of information\nembedded within different regions of the feature. In this work, we introduce\nmulti-scale decoupling in the feature transfer process for the first time,\nwhere the decoupled local features are individually processed and integrated\nwith contrastive learning. Moreover, compared to previous contrastive\nlearning-based distillation methods, our approach not only reduces\ncomputational costs but also enhances efficiency, enabling performance\nimprovements for the student network using only single-batch samples. Extensive\nevaluations on CIFAR-100 and ImageNet demonstrate our method's superiority,\nwith some student networks distilled using our method even surpassing the\nperformance of their pre-trained teacher networks. These results underscore the\neffectiveness of our approach in enabling student networks to thoroughly absorb\nknowledge from teacher networks.",
    "categories": [
      "cs.CV",
      "cs.AI"
    ],
    "primary_category": "cs.CV",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2502.05835v1",
    "published_date": "2025-02-09 10:03:18 UTC",
    "updated_date": "2025-02-09 10:03:18 UTC"
  },
  {
    "arxiv_id": "2502.06890v1",
    "title": "LLMs for Drug-Drug Interaction Prediction: A Comprehensive Comparison",
    "authors": [
      "Gabriele De Vito",
      "Filomena Ferrucci",
      "Athanasios Angelakis"
    ],
    "abstract": "The increasing volume of drug combinations in modern therapeutic regimens\nneeds reliable methods for predicting drug-drug interactions (DDIs). While\nLarge Language Models (LLMs) have revolutionized various domains, their\npotential in pharmaceutical research, particularly in DDI prediction, remains\nlargely unexplored. This study thoroughly investigates LLMs' capabilities in\npredicting DDIs by uniquely processing molecular structures (SMILES), target\norganisms, and gene interaction data as raw text input from the latest DrugBank\ndataset. We evaluated 18 different LLMs, including proprietary models (GPT-4,\nClaude, Gemini) and open-source variants (from 1.5B to 72B parameters), first\nassessing their zero-shot capabilities in DDI prediction. We then fine-tuned\nselected models (GPT-4, Phi-3.5 2.7B, Qwen-2.5 3B, Gemma-2 9B, and Deepseek R1\ndistilled Qwen 1.5B) to optimize their performance. Our comprehensive\nevaluation framework included validation across 13 external DDI datasets,\ncomparing against traditional approaches such as l2-regularized logistic\nregression. Fine-tuned LLMs demonstrated superior performance, with Phi-3.5\n2.7B achieving a sensitivity of 0.978 in DDI prediction, with an accuracy of\n0.919 on balanced datasets (50% positive, 50% negative cases). This result\nrepresents an improvement over both zero-shot predictions and state-of-the-art\nmachine-learning methods used for DDI prediction. Our analysis reveals that\nLLMs can effectively capture complex molecular interaction patterns and cases\nwhere drug pairs target common genes, making them valuable tools for practical\napplications in pharmaceutical research and clinical settings.",
    "categories": [
      "cs.LG",
      "cs.AI",
      "q-bio.QM"
    ],
    "primary_category": "cs.LG",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2502.06890v1",
    "published_date": "2025-02-09 09:58:12 UTC",
    "updated_date": "2025-02-09 09:58:12 UTC"
  },
  {
    "arxiv_id": "2502.05832v1",
    "title": "Compressing Model with Few Class-Imbalance Samples: An Out-of-Distribution Expedition",
    "authors": [
      "Tian-Shuang Wu",
      "Shen-Huan Lyu",
      "Ning Chen",
      "Zhihao Qu",
      "Baoliu Ye"
    ],
    "abstract": "In recent years, as a compromise between privacy and performance, few-sample\nmodel compression has been widely adopted to deal with limited data resulting\nfrom privacy and security concerns. However, when the number of available\nsamples is extremely limited, class imbalance becomes a common and tricky\nproblem. Achieving an equal number of samples across all classes is often\ncostly and impractical in real-world applications, and previous studies on\nfew-sample model compression have mostly ignored this significant issue. Our\nexperiments comprehensively demonstrate that class imbalance negatively affects\nthe overall performance of few-sample model compression methods. To address\nthis problem, we propose a novel and adaptive framework named OOD-Enhanced\nFew-Sample Model Compression (OE-FSMC). This framework integrates easily\naccessible out-of-distribution (OOD) data into both the compression and\nfine-tuning processes, effectively rebalancing the training distribution. We\nalso incorporate a joint distillation loss and a regularization term to reduce\nthe risk of the model overfitting to the OOD data. Extensive experiments on\nmultiple benchmark datasets show that our framework can be seamlessly\nincorporated into existing few-sample model compression methods, effectively\nmitigating the accuracy degradation caused by class imbalance.",
    "categories": [
      "cs.LG",
      "cs.AI",
      "cs.CV"
    ],
    "primary_category": "cs.LG",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2502.05832v1",
    "published_date": "2025-02-09 09:47:23 UTC",
    "updated_date": "2025-02-09 09:47:23 UTC"
  },
  {
    "arxiv_id": "2502.05827v2",
    "title": "HyGEN: Regularizing Negative Hyperedge Generation for Accurate Hyperedge Prediction",
    "authors": [
      "Song Kyung Yu",
      "Da Eun Lee",
      "Yunyong Ko",
      "Sang-Wook Kim"
    ],
    "abstract": "Hyperedge prediction is a fundamental task to predict future high-order\nrelations based on the observed network structure. Existing hyperedge\nprediction methods, however, suffer from the data sparsity problem. To\nalleviate this problem, negative sampling methods can be used, which leverage\nnon-existing hyperedges as contrastive information for model training. However,\nthe following important challenges have been rarely studied: (C1) lack of\nguidance for generating negatives and (C2) possibility of producing false\nnegatives. To address them, we propose a novel hyperedge prediction method,\nHyGEN, that employs (1) a negative hyperedge generator that employs positive\nhyperedges as a guidance to generate more realistic ones and (2) a\nregularization term that prevents the generated hyperedges from being false\nnegatives. Extensive experiments on six real-world hypergraphs reveal that\nHyGEN consistently outperforms four state-of-the-art hyperedge prediction\nmethods.",
    "categories": [
      "cs.SI",
      "cs.AI"
    ],
    "primary_category": "cs.SI",
    "comment": "5 pages, 4 figures, 3 tables, the Web Conference (WWW) 2025",
    "pdf_url": "http://arxiv.org/pdf/2502.05827v2",
    "published_date": "2025-02-09 09:27:35 UTC",
    "updated_date": "2025-02-18 09:53:03 UTC"
  },
  {
    "arxiv_id": "2502.05826v1",
    "title": "MindCraft: Revolutionizing Education through AI-Powered Personalized Learning and Mentorship for Rural India",
    "authors": [
      "Arihant Bardia",
      "Aayush Agrawal"
    ],
    "abstract": "MindCraft is a modern platform designed to revolutionize education in rural\nIndia by leveraging Artificial Intelligence (AI) to create personalized\nlearning experiences, provide mentorship, and foster resource-sharing. In a\ncountry where access to quality education is deeply influenced by geography and\nsocio economic status, rural students often face significant barriers in their\neducational journeys. MindCraft aims to bridge this gap by utilizing AI to\ncreate tailored learning paths, connect students with mentors, and enable a\ncollaborative network of educational resources that transcends both physical\nand digital divides. This paper explores the challenges faced by rural\nstudents, the transformative potential of AI, and how MindCraft offers a\nscalable, sustainable solution for equitable education system. By focusing on\ninclusivity, personalized learning, and mentorship, MindCraft seeks to empower\nrural students, equipping them with the skills, knowledge, and opportunities\nneeded to thrive in an increasingly digital world. Ultimately, MindCraft\nenvisions a future in which technology not only bridges educational gaps but\nalso becomes the driving force for a more inclusive and empowered society.",
    "categories": [
      "cs.CY",
      "cs.AI",
      "cs.ET"
    ],
    "primary_category": "cs.CY",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2502.05826v1",
    "published_date": "2025-02-09 09:26:03 UTC",
    "updated_date": "2025-02-09 09:26:03 UTC"
  },
  {
    "arxiv_id": "2502.05825v1",
    "title": "Delta -- Contrastive Decoding Mitigates Text Hallucinations in Large Language Models",
    "authors": [
      "Cheng Peng Huang",
      "Hao-Yuan Chen"
    ],
    "abstract": "Large language models (LLMs) demonstrate strong capabilities in natural\nlanguage processing but remain prone to hallucinations, generating factually\nincorrect or fabricated content. This issue undermines their reliability,\nparticularly in high-stakes domains such as healthcare and legal advisory. To\naddress this challenge, we propose Delta, an inference-time method that reduces\nhallucinations without requiring model retraining or additional data. Delta\nworks by randomly masking parts of the input prompt and contrasting the output\ndistributions for the original and masked inputs, effectively suppressing\nhallucinations through inference-only computations. We evaluate Delta on\ncontext-rich question-answering benchmarks, achieving absolute improvements of\napproximately 3 and 6 percentage points on SQuAD v1.1 and v2, respectively, and\n7 and 2 percentage points on TriviaQA and Natural Questions under-sampling\ndecoding. Delta also improves the no-answer exact match score on SQuAD v2 by\nover ten percentage points, demonstrating its effectiveness in mitigating\nhallucinations arising from contextual ambiguity. These results highlight Delta\nas a computationally efficient and scalable approach for improving the\nreliability of LLMs in real-world applications.",
    "categories": [
      "cs.CL",
      "cs.AI"
    ],
    "primary_category": "cs.CL",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2502.05825v1",
    "published_date": "2025-02-09 09:16:42 UTC",
    "updated_date": "2025-02-09 09:16:42 UTC"
  },
  {
    "arxiv_id": "2502.06888v1",
    "title": "Klotski: Efficient Mixture-of-Expert Inference via Expert-Aware Multi-Batch Pipeline",
    "authors": [
      "Zhiyuan Fang",
      "Yuegui Huang",
      "Zicong Hong",
      "Yufeng Lyu",
      "Wuhui Chen",
      "Yue Yu",
      "Fan Yu",
      "Zibin Zheng"
    ],
    "abstract": "Mixture of Experts (MoE), with its distinctive sparse structure, enables the\nscaling of language models up to trillions of parameters without significantly\nincreasing computational costs. However, the substantial parameter size\npresents a challenge for inference, as the expansion in GPU memory cannot keep\npace with the growth in parameters. Although offloading techniques utilise\nmemory from the CPU and disk and parallelise the I/O and computation for\nefficiency, the computation for each expert in MoE models is often less than\nthe I/O, resulting in numerous bubbles in the pipeline.\n  Therefore, we propose Klotski, an efficient MoE inference engine that\nsignificantly reduces pipeline bubbles through a novel expert-aware multi-batch\npipeline paradigm. The proposed paradigm uses batch processing to extend the\ncomputation time of the current layer to overlap with the loading time of the\nnext layer. Although this idea has been effectively applied to dense models,\nmore batches may activate more experts in the MoE, leading to longer loading\ntimes and more bubbles. Thus, unlike traditional approaches, we balance\ncomputation and I/O time and minimise bubbles by orchestrating their inference\norders based on their heterogeneous computation and I/O requirements and\nactivation patterns under different batch numbers. Moreover, to adapt to\ndifferent hardware environments and models, we design a constraint-sensitive\nI/O-compute planner and a correlation-aware expert prefetcher for a schedule\nthat minimises pipeline bubbles. Experimental results demonstrate that Klotski\nachieves a superior throughput-latency trade-off compared to state-of-the-art\ntechniques, with throughput improvements of up to 85.12x.",
    "categories": [
      "cs.LG",
      "cs.AI"
    ],
    "primary_category": "cs.LG",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2502.06888v1",
    "published_date": "2025-02-09 08:47:06 UTC",
    "updated_date": "2025-02-09 08:47:06 UTC"
  },
  {
    "arxiv_id": "2502.10435v1",
    "title": "RAMer: Reconstruction-based Adversarial Model for Multi-party Multi-modal Multi-label Emotion Recognition",
    "authors": [
      "Xudong Yang",
      "Yizhang Zhu",
      "Nan Tang",
      "Yuyu Luo"
    ],
    "abstract": "Conventional multi-modal multi-label emotion recognition (MMER) from videos\ntypically assumes full availability of visual, textual, and acoustic\nmodalities. However, real-world multi-party settings often violate this\nassumption, as non-speakers frequently lack acoustic and textual inputs,\nleading to a significant degradation in model performance. Existing approaches\nalso tend to unify heterogeneous modalities into a single representation,\noverlooking each modality's unique characteristics. To address these\nchallenges, we propose RAMer (Reconstruction-based Adversarial Model for\nEmotion Recognition), which leverages adversarial learning to refine\nmulti-modal representations by exploring both modality commonality and\nspecificity through reconstructed features enhanced by contrastive learning.\nRAMer also introduces a personality auxiliary task to complement missing\nmodalities using modality-level attention, improving emotion reasoning. To\nfurther strengthen the model's ability to capture label and modality\ninterdependency, we propose a stack shuffle strategy to enrich correlations\nbetween labels and modality-specific features. Experiments on three benchmarks,\ni.e., MEmoR, CMU-MOSEI, and $M^3$ED, demonstrate that RAMer achieves\nstate-of-the-art performance in dyadic and multi-party MMER scenarios.",
    "categories": [
      "cs.CV",
      "cs.AI"
    ],
    "primary_category": "cs.CV",
    "comment": "9 pages",
    "pdf_url": "http://arxiv.org/pdf/2502.10435v1",
    "published_date": "2025-02-09 07:46:35 UTC",
    "updated_date": "2025-02-09 07:46:35 UTC"
  },
  {
    "arxiv_id": "2502.07815v1",
    "title": "Decoding Complexity: Intelligent Pattern Exploration with CHPDA (Context Aware Hybrid Pattern Detection Algorithm)",
    "authors": [
      "Lokesh Koli",
      "Shubham Kalra",
      "Karanpreet Singh"
    ],
    "abstract": "Detecting sensitive data such as Personally Identifiable Information (PII)\nand Protected Health Information (PHI) is critical for data security platforms.\nThis study evaluates regex-based pattern matching algorithms and exact-match\nsearch techniques to optimize detection speed, accuracy, and scalability. Our\nbenchmarking results indicate that Google RE2 provides the best balance of\nspeed (10-15 ms/MB), memory efficiency (8-16 MB), and accuracy (99.5%) among\nregex engines, outperforming PCRE while maintaining broader hardware\ncompatibility than Hyperscan. For exact matching, Aho-Corasick demonstrated\nsuperior performance (8 ms/MB) and scalability for large datasets. Performance\nanalysis revealed that regex processing time scales linearly with dataset size\nand pattern complexity. A hybrid AI + Regex approach achieved the highest F1\nscore (91. 6%) by improving recall and minimizing false positives. Device\nbenchmarking confirmed that our solution maintains efficient CPU and memory\nusage on both high-performance and mid-range systems. Despite its\neffectiveness, challenges remain, such as limited multilingual support and the\nneed for regular pattern updates. Future work should focus on expanding\nlanguage coverage, integrating data security and privacy management (DSPM) with\ndata loss prevention (DLP) tools, and enhancing regulatory compliance for\nbroader global adoption.",
    "categories": [
      "cs.CR",
      "cs.AI"
    ],
    "primary_category": "cs.CR",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2502.07815v1",
    "published_date": "2025-02-09 07:24:16 UTC",
    "updated_date": "2025-02-09 07:24:16 UTC"
  },
  {
    "arxiv_id": "2502.05795v1",
    "title": "The Curse of Depth in Large Language Models",
    "authors": [
      "Wenfang Sun",
      "Xinyuan Song",
      "Pengxiang Li",
      "Lu Yin",
      "Yefeng Zheng",
      "Shiwei Liu"
    ],
    "abstract": "In this paper, we introduce the Curse of Depth, a concept that highlights,\nexplains, and addresses the recent observation in modern Large Language\nModels(LLMs) where nearly half of the layers are less effective than expected.\nWe first confirm the wide existence of this phenomenon across the most popular\nfamilies of LLMs such as Llama, Mistral, DeepSeek, and Qwen. Our analysis,\ntheoretically and empirically, identifies that the underlying reason for the\nineffectiveness of deep layers in LLMs is the widespread usage of Pre-Layer\nNormalization (Pre-LN). While Pre-LN stabilizes the training of Transformer\nLLMs, its output variance exponentially grows with the model depth, which\nundesirably causes the derivative of the deep Transformer blocks to be an\nidentity matrix, and therefore barely contributes to the training. To resolve\nthis training pitfall, we propose LayerNorm Scaling, which scales the variance\nof output of the layer normalization inversely by the square root of its depth.\nThis simple modification mitigates the output variance explosion of deeper\nTransformer layers, improving their contribution. Our experimental results,\nspanning model sizes from 130M to 1B, demonstrate that LayerNorm Scaling\nsignificantly enhances LLM pre-training performance compared to Pre-LN.\nMoreover, this improvement seamlessly carries over to supervised fine-tuning.\nAll these gains can be attributed to the fact that LayerNorm Scaling enables\ndeeper layers to contribute more effectively during training.",
    "categories": [
      "cs.LG",
      "cs.AI"
    ],
    "primary_category": "cs.LG",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2502.05795v1",
    "published_date": "2025-02-09 07:03:36 UTC",
    "updated_date": "2025-02-09 07:03:36 UTC"
  },
  {
    "arxiv_id": "2502.06887v1",
    "title": "Gradient Based Method for the Fusion of Lattice Quantizers",
    "authors": [
      "Liyuan Zhang",
      "Hanzhong Cao",
      "Jiaheng Li",
      "Minyang Yu"
    ],
    "abstract": "In practical applications, lattice quantizers leverage discrete lattice\npoints to approximate arbitrary points in the lattice. An effective lattice\nquantizer significantly enhances both the accuracy and efficiency of these\napproximations. In the context of high-dimensional lattice quantization,\nprevious work proposed utilizing low-dimensional optimal lattice quantizers and\naddressed the challenge of determining the optimal length ratio in orthogonal\nsplicing. Notably, it was demonstrated that fixed length ratios and\northogonality yield suboptimal results when combining low-dimensional lattices.\nBuilding on this foundation, another approach employed gradient descent to\nidentify optimal lattices, which inspired us to explore the use of neural\nnetworks to discover matrices that outperform those obtained from orthogonal\nsplicing methods. We propose two novel approaches to tackle this problem: the\nHousehold Algorithm and the Matrix Exp Algorithm. Our results indicate that\nboth the Household Algorithm and the Matrix Exp Algorithm achieve improvements\nin lattice quantizers across dimensions 13, 15, 17 to 19, 21, and 22. Moreover,\nthe Matrix Exp Algorithm demonstrates superior efficacy in high-dimensional\nsettings.",
    "categories": [
      "cs.LG",
      "cs.AI"
    ],
    "primary_category": "cs.LG",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2502.06887v1",
    "published_date": "2025-02-09 06:37:47 UTC",
    "updated_date": "2025-02-09 06:37:47 UTC"
  },
  {
    "arxiv_id": "2502.05788v1",
    "title": "EPBC-YOLOv8: An efficient and accurate improved YOLOv8 underwater detector based on an attention mechanism",
    "authors": [
      "Xing Jiang",
      "Xiting Zhuang",
      "Jisheng Chen",
      "Jian Zhang"
    ],
    "abstract": "In this study, we enhance underwater target detection by integrating channel\nand spatial attention into YOLOv8's backbone, applying Pointwise Convolution in\nFasterNeXt for the FasterPW model, and leveraging Weighted Concat in a\nBiFPN-inspired WFPN structure for improved cross-scale connections and\nrobustness. Utilizing CARAFE for refined feature reassembly, our framework\naddresses underwater image degradation, achieving mAP at 0.5 scores of 76.7\npercent and 79.0 percent on URPC2019 and URPC2020 datasets, respectively. These\nscores are 2.3 percent and 0.7 percent higher than the original YOLOv8,\nshowcasing enhanced precision in detecting marine organisms.",
    "categories": [
      "cs.CV",
      "cs.AI"
    ],
    "primary_category": "cs.CV",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2502.05788v1",
    "published_date": "2025-02-09 06:09:56 UTC",
    "updated_date": "2025-02-09 06:09:56 UTC"
  },
  {
    "arxiv_id": "2502.05783v1",
    "title": "WatchGuardian: Enabling User-Defined Personalized Just-in-Time Intervention on Smartwatch",
    "authors": [
      "Ying Lei",
      "Yancheng Cao",
      "Will Wang",
      "Yuanzhe Dong",
      "Changchang Yin",
      "Weidan Cao",
      "Ping Zhang",
      "Jingzhen Yang",
      "Bingsheng Yao",
      "Yifan Peng",
      "Chunhua Weng",
      "Randy Auerbach",
      "Lena Mamykina",
      "Dakuo Wang",
      "Yuntao Wang",
      "Xuhai Xu"
    ],
    "abstract": "While just-in-time interventions (JITIs) have effectively targeted common\nhealth behaviors, individuals often have unique needs to intervene in personal\nundesirable actions that can negatively affect physical, mental, and social\nwell-being. We present WatchGuardian, a smartwatch-based JITI system that\nempowers users to define custom interventions for these personal actions with a\nsmall number of samples. For the model to detect new actions based on limited\nnew data samples, we developed a few-shot learning pipeline that finetuned a\npre-trained inertial measurement unit (IMU) model on public hand-gesture\ndatasets. We then designed a data augmentation and synthesis process to train\nadditional classification layers for customization. Our offline evaluation with\n26 participants showed that with three, five, and ten examples, our approach\nachieved an average accuracy of 76.8%, 84.7%, and 87.7%, and an F1 score of\n74.8%, 84.2%, and 87.2% We then conducted a four-hour intervention study to\ncompare WatchGuardian against a rule-based intervention. Our results\ndemonstrated that our system led to a significant reduction by 64.0 +- 22.6% in\nundesirable actions, substantially outperforming the baseline by 29.0%. Our\nfindings underscore the effectiveness of a customizable, AI-driven JITI system\nfor individuals in need of behavioral intervention in personal undesirable\nactions. We envision that our work can inspire broader applications of\nuser-defined personalized intervention with advanced AI solutions.",
    "categories": [
      "cs.HC",
      "cs.AI",
      "cs.LG",
      "68U35",
      "H.5.2; I.2.1"
    ],
    "primary_category": "cs.HC",
    "comment": "Under submission",
    "pdf_url": "http://arxiv.org/pdf/2502.05783v1",
    "published_date": "2025-02-09 05:58:31 UTC",
    "updated_date": "2025-02-09 05:58:31 UTC"
  },
  {
    "arxiv_id": "2502.08658v2",
    "title": "Knowledge-data fusion dominated vehicle platoon dynamics modeling and analysis: A physics-encoded deep learning approach",
    "authors": [
      "Hao Lyu",
      "Yanyong Guo",
      "Pan Liu",
      "Shuo Feng",
      "Weilin Ren",
      "Quansheng Yue"
    ],
    "abstract": "Recently, artificial intelligence (AI)-enabled nonlinear vehicle platoon\ndynamics modeling plays a crucial role in predicting and optimizing the\ninteractions between vehicles. Existing efforts lack the extraction and capture\nof vehicle behavior interaction features at the platoon scale. More\nimportantly, maintaining high modeling accuracy without losing physical\nanalyzability remains to be solved. To this end, this paper proposes a novel\nphysics-encoded deep learning network, named PeMTFLN, to model the nonlinear\nvehicle platoon dynamics. Specifically, an analyzable parameters encoded\ncomputational graph (APeCG) is designed to guide the platoon to respond to the\ndriving behavior of the lead vehicle while ensuring local stability. Besides, a\nmulti-scale trajectory feature learning network (MTFLN) is constructed to\ncapture platoon following patterns and infer the physical parameters required\nfor APeCG from trajectory data. The human-driven vehicle trajectory datasets\n(HIGHSIM) were used to train the proposed PeMTFLN. The trajectories prediction\nexperiments show that PeMTFLN exhibits superior compared to the baseline models\nin terms of predictive accuracy in speed and gap. The stability analysis result\nshows that the physical parameters in APeCG is able to reproduce the platoon\nstability in real-world condition. In simulation experiments, PeMTFLN performs\nlow inference error in platoon trajectories generation. Moreover, PeMTFLN also\naccurately reproduces ground-truth safety statistics. The code of proposed\nPeMTFLN is open source.",
    "categories": [
      "cs.RO",
      "cs.AI"
    ],
    "primary_category": "cs.RO",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2502.08658v2",
    "published_date": "2025-02-09 05:10:46 UTC",
    "updated_date": "2025-03-13 13:42:00 UTC"
  },
  {
    "arxiv_id": "2502.05777v1",
    "title": "Predictive Crash Analytics for Traffic Safety using Deep Learning",
    "authors": [
      "Karthik Sivakoti"
    ],
    "abstract": "Traditional automated crash analysis systems heavily rely on static\nstatistical models and historical data, requiring significant manual\ninterpretation and lacking real-time predictive capabilities. This research\npresents an innovative approach to traffic safety analysis through the\nintegration of ensemble learning methods and multi-modal data fusion for\nreal-time crash risk assessment and prediction. Our primary contribution lies\nin developing a hierarchical severity classification system that combines\nspatial-temporal crash patterns with environmental conditions, achieving\nsignificant improvements over traditional statistical approaches. The system\ndemonstrates a Mean Average Precision (mAP) of 0.893, representing a 15%\nimprovement over current state-of-the-art methods (baseline mAP: 0.776). We\nintroduce a novel feature engineering technique that integrates crash location\ndata with incident reports and weather conditions, achieving 92.4% accuracy in\nrisk prediction and 89.7% precision in hotspot identification. Through\nextensive validation using 500,000 initial crash records filtered to 59,496\nhigh-quality samples, our solution shows marked improvements in both prediction\naccuracy and computational efficiency. Key innovations include a robust data\ncleaning pipeline, adaptive feature generation, and a scalable real-time\nprediction system capable of handling peak loads of 1,000 concurrent requests\nwhile maintaining sub-100ms response times.",
    "categories": [
      "cs.LG",
      "cs.AI"
    ],
    "primary_category": "cs.LG",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2502.05777v1",
    "published_date": "2025-02-09 05:00:46 UTC",
    "updated_date": "2025-02-09 05:00:46 UTC"
  },
  {
    "arxiv_id": "2502.09637v1",
    "title": "Meta-Cultural Competence: Climbing the Right Hill of Cultural Awareness",
    "authors": [
      "Sougata Saha",
      "Saurabh Kumar Pandey",
      "Monojit Choudhury"
    ],
    "abstract": "Numerous recent studies have shown that Large Language Models (LLMs) are\nbiased towards a Western and Anglo-centric worldview, which compromises their\nusefulness in non-Western cultural settings. However, \"culture\" is a complex,\nmultifaceted topic, and its awareness, representation, and modeling in LLMs and\nLLM-based applications can be defined and measured in numerous ways. In this\nposition paper, we ask what does it mean for an LLM to possess \"cultural\nawareness\", and through a thought experiment, which is an extension of the\nOctopus test proposed by Bender and Koller (2020), we argue that it is not\ncultural awareness or knowledge, rather meta-cultural competence, which is\nrequired of an LLM and LLM-based AI system that will make it useful across\nvarious, including completely unseen, cultures. We lay out the principles of\nmeta-cultural competence AI systems, and discuss ways to measure and model\nthose.",
    "categories": [
      "cs.CY",
      "cs.AI",
      "cs.CL"
    ],
    "primary_category": "cs.CY",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2502.09637v1",
    "published_date": "2025-02-09 04:51:59 UTC",
    "updated_date": "2025-02-09 04:51:59 UTC"
  },
  {
    "arxiv_id": "2502.09636v2",
    "title": "Reading between the Lines: Can LLMs Identify Cross-Cultural Communication Gaps?",
    "authors": [
      "Sougata Saha",
      "Saurabh Kumar Pandey",
      "Harshit Gupta",
      "Monojit Choudhury"
    ],
    "abstract": "In a rapidly globalizing and digital world, content such as book and product\nreviews created by people from diverse cultures are read and consumed by others\nfrom different corners of the world. In this paper, we investigate the extent\nand patterns of gaps in understandability of book reviews due to the presence\nof culturally-specific items and elements that might be alien to users from\nanother culture. Our user-study on 57 book reviews from Goodreads reveal that\n83\\% of the reviews had at least one culture-specific difficult-to-understand\nelement. We also evaluate the efficacy of GPT-4o in identifying such items,\ngiven the cultural background of the reader; the results are mixed, implying a\nsignificant scope for improvement. Our datasets are available here:\nhttps://github.com/sougata-ub/reading_between_lines",
    "categories": [
      "cs.CL",
      "cs.AI"
    ],
    "primary_category": "cs.CL",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2502.09636v2",
    "published_date": "2025-02-09 04:40:35 UTC",
    "updated_date": "2025-02-20 16:40:48 UTC"
  },
  {
    "arxiv_id": "2502.05773v1",
    "title": "PIPA: Preference Alignment as Prior-Informed Statistical Estimation",
    "authors": [
      "Junbo Li",
      "Zhangyang Wang",
      "Qiang Liu"
    ],
    "abstract": "Offline preference alignment for language models such as Direct Preference\nOptimization (DPO) is favored for its effectiveness and simplicity, eliminating\nthe need for costly reinforcement learning. Various offline algorithms have\nbeen developed for different data settings, yet they lack a unified\nunderstanding.\n  In this study, we introduce Pior-Informed Preference Alignment (PIPA), a\nunified, RL-free probabilistic framework that formulates language model\npreference alignment as a Maximum Likelihood Estimation (MLE) problem with\nprior constraints. This method effectively accommodates both paired and\nunpaired data, as well as answer and step-level annotations. We illustrate that\nDPO and KTO are special cases with different prior constraints within our\nframework. By integrating different types of prior information, we developed\ntwo variations of PIPA: PIPA-M and PIPA-N. Both algorithms demonstrate a\n$3\\sim10\\%$ performance enhancement on the GSM8K and MATH benchmarks across all\nconfigurations, achieving these gains without additional training or\ncomputational costs compared to existing algorithms.",
    "categories": [
      "cs.LG",
      "cs.AI",
      "stat.ML"
    ],
    "primary_category": "cs.LG",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2502.05773v1",
    "published_date": "2025-02-09 04:31:30 UTC",
    "updated_date": "2025-02-09 04:31:30 UTC"
  },
  {
    "arxiv_id": "2502.05772v1",
    "title": "Effective Black-Box Multi-Faceted Attacks Breach Vision Large Language Model Guardrails",
    "authors": [
      "Yijun Yang",
      "Lichao Wang",
      "Xiao Yang",
      "Lanqing Hong",
      "Jun Zhu"
    ],
    "abstract": "Vision Large Language Models (VLLMs) integrate visual data processing,\nexpanding their real-world applications, but also increasing the risk of\ngenerating unsafe responses. In response, leading companies have implemented\nMulti-Layered safety defenses, including alignment training, safety system\nprompts, and content moderation. However, their effectiveness against\nsophisticated adversarial attacks remains largely unexplored. In this paper, we\npropose MultiFaceted Attack, a novel attack framework designed to\nsystematically bypass Multi-Layered Defenses in VLLMs. It comprises three\ncomplementary attack facets: Visual Attack that exploits the multimodal nature\nof VLLMs to inject toxic system prompts through images; Alignment Breaking\nAttack that manipulates the model's alignment mechanism to prioritize the\ngeneration of contrasting responses; and Adversarial Signature that deceives\ncontent moderators by strategically placing misleading information at the end\nof the response. Extensive evaluations on eight commercial VLLMs in a black-box\nsetting demonstrate that MultiFaceted Attack achieves a 61.56% attack success\nrate, surpassing state-of-the-art methods by at least 42.18%.",
    "categories": [
      "cs.CV",
      "cs.AI"
    ],
    "primary_category": "cs.CV",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2502.05772v1",
    "published_date": "2025-02-09 04:21:27 UTC",
    "updated_date": "2025-02-09 04:21:27 UTC"
  },
  {
    "arxiv_id": "2502.05749v3",
    "title": "UniDB: A Unified Diffusion Bridge Framework via Stochastic Optimal Control",
    "authors": [
      "Kaizhen Zhu",
      "Mokai Pan",
      "Yuexin Ma",
      "Yanwei Fu",
      "Jingyi Yu",
      "Jingya Wang",
      "Ye Shi"
    ],
    "abstract": "Recent advances in diffusion bridge models leverage Doob's $h$-transform to\nestablish fixed endpoints between distributions, demonstrating promising\nresults in image translation and restoration tasks. However, these approaches\nfrequently produce blurred or excessively smoothed image details and lack a\ncomprehensive theoretical foundation to explain these shortcomings. To address\nthese limitations, we propose UniDB, a unified framework for diffusion bridges\nbased on Stochastic Optimal Control (SOC). UniDB formulates the problem through\nan SOC-based optimization and derives a closed-form solution for the optimal\ncontroller, thereby unifying and generalizing existing diffusion bridge models.\nWe demonstrate that existing diffusion bridges employing Doob's $h$-transform\nconstitute a special case of our framework, emerging when the terminal penalty\ncoefficient in the SOC cost function tends to infinity. By incorporating a\ntunable terminal penalty coefficient, UniDB achieves an optimal balance between\ncontrol costs and terminal penalties, substantially improving detail\npreservation and output quality. Notably, UniDB seamlessly integrates with\nexisting diffusion bridge models, requiring only minimal code modifications.\nExtensive experiments across diverse image restoration tasks validate the\nsuperiority and adaptability of the proposed framework. Our code is available\nat https://github.com/UniDB-SOC/UniDB/.",
    "categories": [
      "cs.CV",
      "cs.AI",
      "cs.SY",
      "eess.SY"
    ],
    "primary_category": "cs.CV",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2502.05749v3",
    "published_date": "2025-02-09 02:43:57 UTC",
    "updated_date": "2025-02-21 15:01:36 UTC"
  },
  {
    "arxiv_id": "2502.18482v1",
    "title": "MixLLM: Dynamic Routing in Mixed Large Language Models",
    "authors": [
      "Xinyuan Wang",
      "Yanchi Liu",
      "Wei Cheng",
      "Xujiang Zhao",
      "Zhengzhang Chen",
      "Wenchao Yu",
      "Yanjie Fu",
      "Haifeng Chen"
    ],
    "abstract": "Large Language Models (LLMs) exhibit potential artificial generic\nintelligence recently, however, their usage is costly with high response\nlatency. Given mixed LLMs with their own strengths and weaknesses, LLM routing\naims to identify the most suitable model for each query in the stream to\nmaximize response quality and minimize cost and latency. However, the\nchallenges involve: (1) dynamic trade-offs among quality, cost, and latency;\n(2) enabling continual learning in deployed systems; and (3) navigating a\nvarying (e.g., new LLM addition or old LLM removal) set of LLM candidates over\ntime. To bridge these gaps, we develop MixLLM, a dynamic\ncontextual-bandit-based routing system for query-LLM assignment. Specifically,\nwe first leverage query tags to enhance query embeddings for the routing task.\nNext, we design lightweight prediction models to estimate the response\nqualities and costs of queries over LLMs. We then devise a meta-decision maker\nto choose the query-LLM assignments to best tradeoff response quality, cost,\nand latency. Finally, the system benefits from continual training, allowing it\nto adapt to evolving queries and user feedback over time. Our extensive\nexperiments show that MixLLM achieves the best trade-offs in response quality,\ncost, and latency (97.25% of GPT-4's quality at 24.18% of the cost under the\ntime constraint).",
    "categories": [
      "cs.CL",
      "cs.AI",
      "cs.DB",
      "cs.IR",
      "N/A"
    ],
    "primary_category": "cs.CL",
    "comment": "11 pages, 7 figures, accepted by NAACL 2025 main conference",
    "pdf_url": "http://arxiv.org/pdf/2502.18482v1",
    "published_date": "2025-02-09 02:26:15 UTC",
    "updated_date": "2025-02-09 02:26:15 UTC"
  },
  {
    "arxiv_id": "2502.10434v1",
    "title": "Agency in Artificial Intelligence Systems",
    "authors": [
      "Parashar Das"
    ],
    "abstract": "There is a general concern that present developments in artificial\nintelligence (AI) research will lead to sentient AI systems, and these may pose\nan existential threat to humanity. But why cannot sentient AI systems benefit\nhumanity instead? This paper endeavours to put this question in a tractable\nmanner. I ask whether a putative AI system will develop an altruistic or a\nmalicious disposition towards our society, or what would be the nature of its\nagency? Given that AI systems are being developed into formidable problem\nsolvers, we can reasonably expect these systems to preferentially take on\nconscious aspects of human problem solving. I identify the relevant phenomenal\naspects of agency in human problem solving. The functional aspects of conscious\nagency can be monitored using tools provided by functionalist theories of\nconsciousness. A recent expert report (Butlin et al. 2023) has identified\nfunctionalist indicators of agency based on these theories. I show how to use\nthe Integrated Information Theory (IIT) of consciousness, to monitor the\nphenomenal nature of this agency. If we are able to monitor the agency of AI\nsystems as they develop, then we can dissuade them from becoming a menace to\nsociety while encouraging them to be an aid.",
    "categories": [
      "cs.AI",
      "cs.CY"
    ],
    "primary_category": "cs.AI",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2502.10434v1",
    "published_date": "2025-02-09 02:21:14 UTC",
    "updated_date": "2025-02-09 02:21:14 UTC"
  },
  {
    "arxiv_id": "2502.07814v1",
    "title": "Satellite Observations Guided Diffusion Model for Accurate Meteorological States at Arbitrary Resolution",
    "authors": [
      "Siwei Tu",
      "Ben Fei",
      "Weidong Yang",
      "Fenghua Ling",
      "Hao Chen",
      "Zili Liu",
      "Kun Chen",
      "Hang Fan",
      "Wanli Ouyang",
      "Lei Bai"
    ],
    "abstract": "Accurate acquisition of surface meteorological conditions at arbitrary\nlocations holds significant importance for weather forecasting and climate\nsimulation. Due to the fact that meteorological states derived from satellite\nobservations are often provided in the form of low-resolution grid fields, the\ndirect application of spatial interpolation to obtain meteorological states for\nspecific locations often results in significant discrepancies when compared to\nactual observations. Existing downscaling methods for acquiring meteorological\nstate information at higher resolutions commonly overlook the correlation with\nsatellite observations. To bridge the gap, we propose Satellite-observations\nGuided Diffusion Model (SGD), a conditional diffusion model pre-trained on ERA5\nreanalysis data with satellite observations (GridSat) as conditions, which is\nemployed for sampling downscaled meteorological states through a zero-shot\nguided sampling strategy and patch-based methods. During the training process,\nwe propose to fuse the information from GridSat satellite observations into\nERA5 maps via the attention mechanism, enabling SGD to generate atmospheric\nstates that align more accurately with actual conditions. In the sampling, we\nemployed optimizable convolutional kernels to simulate the upscale process,\nthereby generating high-resolution ERA5 maps using low-resolution ERA5 maps as\nwell as observations from weather stations as guidance. Moreover, our devised\npatch-based method promotes SGD to generate meteorological states at arbitrary\nresolutions. Experiments demonstrate SGD fulfills accurate meteorological\nstates downscaling to 6.25km.",
    "categories": [
      "cs.LG",
      "cs.AI",
      "physics.ao-ph"
    ],
    "primary_category": "cs.LG",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2502.07814v1",
    "published_date": "2025-02-09 02:05:33 UTC",
    "updated_date": "2025-02-09 02:05:33 UTC"
  },
  {
    "arxiv_id": "2502.05740v1",
    "title": "RECOVER: Designing a Large Language Model-based Remote Patient Monitoring System for Postoperative Gastrointestinal Cancer Care",
    "authors": [
      "Ziqi Yang",
      "Yuxuan Lu",
      "Jennifer Bagdasarian",
      "Vedant Das Swain",
      "Ritu Agarwal",
      "Collin Campbell",
      "Waddah Al-Refaire",
      "Jehan El-Bayoumi",
      "Guodong Gao",
      "Dakuo Wang",
      "Bingsheng Yao",
      "Nawar Shara"
    ],
    "abstract": "Cancer surgery is a key treatment for gastrointestinal (GI) cancers, a group\nof cancers that account for more than 35% of cancer-related deaths worldwide,\nbut postoperative complications are unpredictable and can be life-threatening.\nIn this paper, we investigate how recent advancements in large language models\n(LLMs) can benefit remote patient monitoring (RPM) systems through clinical\nintegration by designing RECOVER, an LLM-powered RPM system for postoperative\nGI cancer care. To closely engage stakeholders in the design process, we first\nconducted seven participatory design sessions with five clinical staff and\ninterviewed five cancer patients to derive six major design strategies for\nintegrating clinical guidelines and information needs into LLM-based RPM\nsystems. We then designed and implemented RECOVER, which features an\nLLM-powered conversational agent for cancer patients and an interactive\ndashboard for clinical staff to enable efficient postoperative RPM. Finally, we\nused RECOVER as a pilot system to assess the implementation of our design\nstrategies with four clinical staff and five patients, providing design\nimplications by identifying crucial design elements, offering insights on\nresponsible AI, and outlining opportunities for future LLM-powered RPM systems.",
    "categories": [
      "cs.HC",
      "cs.AI"
    ],
    "primary_category": "cs.HC",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2502.05740v1",
    "published_date": "2025-02-09 01:51:25 UTC",
    "updated_date": "2025-02-09 01:51:25 UTC"
  },
  {
    "arxiv_id": "2502.05739v1",
    "title": "Mitigating Sensitive Information Leakage in LLMs4Code through Machine Unlearning",
    "authors": [
      "Ruotong Geng",
      "Mingyang Geng",
      "Shangwen Wang",
      "Haotian Wang",
      "Zhipeng Lin",
      "Dezun Dong"
    ],
    "abstract": "Large Language Models for Code (LLMs4Code) excel at code generation tasks,\nyielding promise to release developers from huge software development burdens.\nNonetheless, these models have been shown to suffer from the significant\nprivacy risks due to the potential leakage of sensitive information embedded\nduring training, known as the memorization problem. Addressing this issue is\ncrucial for ensuring privacy compliance and upholding user trust, but till now\nthere is a dearth of dedicated studies in the literature that focus on this\nspecific direction. Recently, machine unlearning has emerged as a promising\nsolution by enabling models to \"forget\" sensitive information without full\nretraining, offering an efficient and scalable approach compared to traditional\ndata cleaning methods. In this paper, we empirically evaluate the effectiveness\nof unlearning techniques for addressing privacy concerns in\nLLMs4Code.Specifically, we investigate three state-of-the-art unlearning\nalgorithms and three well-known open-sourced LLMs4Code, on a benchmark that\ntakes into consideration both the privacy data to be forgotten as well as the\ncode generation capabilites of these models. Results show that it is feasible\nto mitigate the privacy concerns of LLMs4Code through machine unlearning while\nmaintain their code generation capabilities at the same time. We also dissect\nthe forms of privacy protection/leakage after unlearning and observe that there\nis a shift from direct leakage to indirect leakage, which underscores the need\nfor future studies addressing this risk.",
    "categories": [
      "cs.CR",
      "cs.AI",
      "cs.SE"
    ],
    "primary_category": "cs.CR",
    "comment": "11 pages",
    "pdf_url": "http://arxiv.org/pdf/2502.05739v1",
    "published_date": "2025-02-09 01:50:34 UTC",
    "updated_date": "2025-02-09 01:50:34 UTC"
  },
  {
    "arxiv_id": "2502.09635v1",
    "title": "CORRECT: Context- and Reference-Augmented Reasoning and Prompting for Fact-Checking",
    "authors": [
      "Delvin Ce Zhang",
      "Dongwon Lee"
    ],
    "abstract": "Fact-checking the truthfulness of claims usually requires reasoning over\nmultiple evidence sentences. Oftentimes, evidence sentences may not be always\nself-contained, and may require additional contexts and references from\nelsewhere to understand coreferential expressions, acronyms, and the scope of a\nreported finding. For example, evidence sentences from an academic paper may\nneed contextual sentences in the paper and descriptions in its cited papers to\ndetermine the scope of a research discovery. However, most fact-checking models\nmainly focus on the reasoning within evidence sentences, and ignore the\nauxiliary contexts and references. To address this problem, we propose a novel\nmethod, Context- and Reference-augmented Reasoning and Prompting. For evidence\nreasoning, we construct a three-layer evidence graph with evidence, context,\nand reference layers. We design intra- and cross-layer reasoning to integrate\nthree graph layers into a unified evidence embedding. For verdict prediction,\nwe design evidence-conditioned prompt encoder, which produces unique prompt\nembeddings for each claim. These evidence-conditioned prompt embeddings and\nclaims are unified for fact-checking. Experiments verify the strength of our\nmodel.",
    "categories": [
      "cs.CL",
      "cs.AI"
    ],
    "primary_category": "cs.CL",
    "comment": "Accepted to NAACL-25",
    "pdf_url": "http://arxiv.org/pdf/2502.09635v1",
    "published_date": "2025-02-09 01:41:15 UTC",
    "updated_date": "2025-02-09 01:41:15 UTC"
  }
]