{
  "date": "2025-03-30",
  "category": "cs.AI",
  "summary": "欢迎来到 UTC 时间 2025-03-30 的 arXiv 中文 TLDR 快报！\n\n今天 arXiv 的论文主要聚焦 AI 领域，特别是大型语言模型（LLMs）的应用、强化学习和多模态模型的创新，强调模型鲁棒性、解释性和实际部署；重点包括 Distill-C 在 NL2SQL 任务上的高效优化、Graph-Eq 的方程发现框架，以及 Elias Bareinboim 等知名学者的因果推理工作；令人印象深刻的文章有 Distill-C 和 Interpretable Machine Learning in Physics，它们展示了 AI 在行业应用和物理领域的潜力。\n\n下面，我挑选并简要讨论了今天最重要和话题性的论文，先从 AI 核心创新入手，再聊相关应用。其他论文（如一些纯理论综述或小众领域）快速掠过，仅提关键点，以控制篇幅。\n\n1. **Distill-C: Enhanced NL2SQL via Distilled Customization with LLMs**（中文：通过蒸馏定制增强 NL2SQL 的方法）  \n   这篇论文提出 Distill-C 框架，利用大型教师模型生成高质量合成数据，微调小型开源模型，实现 NL2SQL 任务的性能提升；在多个基准测试中，执行准确率平均提高 36%，并在内部基准上提升 22.6%，为高效部署提供低计算成本的解决方案。\n\n2. **EAP4EMSIG - Enhancing Event-Driven Microscopy for Microfluidic Single-Cell Analysis**（中文：增强事件驱动显微镜用于微流控单细胞分析）  \n   论文引入深度学习自动对焦和实时分割方法，Mean Absolute Error 达 0.0226 微米，Cellpose 3 模型的 Panoptic Quality 为 93.58%；这为高通量实验提供实时洞察，显著改善微生物细胞工厂的数据分析。\n\n3. **Beyond Detection: Designing AI-Resilient Assessments with Automated Feedback Tool to Foster Critical Thinking**（中文：超越检测：设计 AI 抗性评估工具以促进批判性思维）  \n   作者提出基于 Bloom 分类和 NLP（如 GPT-3.5 Turbo）的工具，评估任务的 AI 可解性，帮助教育者创建更具挑战性的评估；这避免了 AI 生成文本的检测局限，推动高等教育中批判性思维的培养。\n\n4. **Multi-Stakeholder Disaster Insights from Social Media Using Large Language Models**（中文：使用大型语言模型从社交媒体获取多利益相关者灾害洞察）  \n   该方法结合 BERT 分类和 ChatGPT 生成报告，从社交媒体数据中提取灾害洞见，提高救灾协调；在定量指标上优于标准方法，为媒体、警察和急救服务提供定制化报告。\n\n5. **Graph-Eq: Discovering Mathematical Equations using Graph Generative Models**（中文：使用图生成模型发现数学方程）  \n   论文开发 Graph-EQ 框架，通过条件变分自编码器学习方程的潜在表示，并用 Bayesian 优化探索数据集；它成功在 20 个数据集上发现 ground-truth 方程，展示了图神经网络在高效方程发现中的潜力。\n\n6. **Interpretable Machine Learning in Physics: A Review**（中文：物理学中的可解释机器学习：综述）  \n   作者（如 Ziming Liu）审视机器学习在物理中的可解释性，分类不同解释方面，并讨论哲学含义；这篇综述强调可解释模型在科学发现中的作用，提升人类-AI 协作。\n\n7. **Partial Transportability for Domain Generalization**（中文：部分可移植性用于领域泛化）  \n   Elias Bareinboim 等提出新方法，使用因果图和神经因果模型界定目标分布的泛化误差；在实际实验中，该技术提供一致的边界估计，推进 AI 在未知域中的鲁棒应用。\n\n8. **GenVP: Generating Visual Puzzles with Contrastive Hierarchical VAEs**（中文：使用对比分层 VAEs 生成视觉谜题）  \n   论文的 GenVP 框架生成 Raven's Progressive Matrices 谜题，实现 SOTA 的求解准确性和 OOD 泛化；它捕捉抽象规则与视觉属性的关系，适用于高级视觉推理任务。\n\n9. **CrossWordBench: Evaluating the Reasoning Capabilities of LLMs and LVLMs with Controllable Puzzle Generation**（中文：使用可控谜题生成评估 LLMs 和 LVLMs 的推理能力）  \n   该基准通过填字游戏评估 LLMs 的多模态推理，揭示它们在文本-视觉约束下的局限；实验显示，推理模型在交叉字母约束下性能提升，但 LVLMs 仍面临网格解析挑战。\n\n10. **DASH: Detection and Assessment of Systematic Hallucinations of VLMs**（中文：检测和评估视觉语言模型的系统性幻觉）  \n   论文的 DASH 管道优化图像检索以识别 VLMs 的幻觉，在 950k 图像上找到 19k 集群；这为减轻对象幻觉提供新方法，并证明微调能提升模型鲁棒性。\n\n其他论文，如量子 NLP 或特定领域如药物交互预测（Addressing Model Overcomplexity），快速掠过：它们提供基础综述或方法优化，但影响较小，仅在特定子领域有应用价值。例如，A Survey on Unlearnable Data 讨论数据隐私保护，但未有突破性贡献；BiPVL-Seg 在医疗图像分割中引入视觉-语言融合，提升多类分割性能，但整体影响力不如上述 AI 核心论文。\n\n总之，今天的 arXiv 突显 AI 模型的实用性和挑战，期待这些创新推动更可靠的 AI 系统。明天见！",
  "papers": [
    {
      "arxiv_id": "2504.00048v1",
      "title": "Distill-C: Enhanced NL2SQL via Distilled Customization with LLMs",
      "title_zh": "翻译失败",
      "authors": [
        "Cong Duy Vu Hoang",
        "Gioacchino Tangari",
        "Clemence Lanfranchi",
        "Dalu Guo",
        "Paul Cayet",
        "Steve Siu",
        "Don Dharmasiri",
        "Yuan-Fang Li",
        "Long Duong",
        "Damien Hilloulin",
        "Rhicheek Patra",
        "Sungpack Hong",
        "Hassan Chafi"
      ],
      "abstract": "The growing adoption of large language models (LLMs) in business applications\nhas amplified interest in Natural Language to SQL (NL2SQL) solutions, in which\nthere is competing demand for high performance and efficiency. Domain- and\ncustomer-specific requirements further complicate the problem. To address this\nconundrum, we introduce Distill-C, a distilled customization framework tailored\nfor NL2SQL tasks. Distill-C utilizes large teacher LLMs to produce high-quality\nsynthetic data through a robust and scalable pipeline. Finetuning smaller and\nopen-source LLMs on this synthesized data enables them to rival or outperform\nteacher models an order of magnitude larger. Evaluated on multiple challenging\nbenchmarks, Distill-C achieves an average improvement of 36% in execution\naccuracy compared to the base models from three distinct LLM families.\nAdditionally, on three internal customer benchmarks, Distill-C demonstrates a\n22.6% performance improvement over the base models. Our results demonstrate\nthat Distill-C is an effective, high-performing and generalizable approach for\ndeploying lightweight yet powerful NL2SQL models, delivering exceptional\naccuracies while maintaining low computational cost.",
      "tldr_zh": "该研究提出了一种名为 Distill-C 的蒸馏定制框架，用于提升自然语言到 SQL（NL2SQL）任务的性能和效率。该框架利用大型教师 LLMs 生成高质量的合成数据，通过一个稳健可扩展的管道来微调更小、更开源的 LLMs，使其性能可媲美或超越比自身大一个数量级的模型。在多个挑战性基准测试中，Distill-C 平均提高了 36% 的执行准确率，并在三个内部客户基准上实现了 22.6% 的性能提升。该方法为部署轻量级、高准确率的 NL2SQL 模型提供了高效且通用化的解决方案，同时降低了计算成本。",
      "categories": [
        "cs.CL",
        "cs.AI"
      ],
      "primary_category": "cs.CL",
      "comment": "Preprint, accepted at NAACL 2025 (Industry Track)",
      "pdf_url": "http://arxiv.org/pdf/2504.00048v1",
      "published_date": "2025-03-30 23:23:21 UTC",
      "updated_date": "2025-03-30 23:23:21 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-24T07:32:25.035969"
    },
    {
      "arxiv_id": "2504.00047v1",
      "title": "EAP4EMSIG -- Enhancing Event-Driven Microscopy for Microfluidic Single-Cell Analysis",
      "title_zh": "翻译失败",
      "authors": [
        "Nils Friederich",
        "Angelo Jovin Yamachui Sitcheu",
        "Annika Nassal",
        "Erenus Yildiz",
        "Matthias Pesch",
        "Maximilian Beichter",
        "Lukas Scholtes",
        "Bahar Akbaba",
        "Thomas Lautenschlager",
        "Oliver Neumann",
        "Dietrich Kohlheyer",
        "Hanno Scharr",
        "Johannes Seiffarth",
        "Katharina Nöh",
        "Ralf Mikut"
      ],
      "abstract": "Microfluidic Live-Cell Imaging yields data on microbial cell factories.\nHowever, continuous acquisition is challenging as high-throughput experiments\noften lack realtime insights, delaying responses to stochastic events. We\nintroduce three components in the Experiment Automation Pipeline for\nEvent-Driven Microscopy to Smart Microfluidic Single-Cell Analysis: a fast,\naccurate Deep Learning autofocusing method predicting the focus offset, an\nevaluation of real-time segmentation methods and a realtime data analysis\ndashboard. Our autofocusing achieves a Mean Absolute Error of 0.0226\\textmu m\nwith inference times below 50~ms. Among eleven Deep Learning segmentation\nmethods, Cellpose~3 reached a Panoptic Quality of 93.58\\%, while a\ndistance-based method is fastest (121~ms, Panoptic Quality 93.02\\%). All six\nDeep Learning Foundation Models were unsuitable for real-time segmentation.",
      "tldr_zh": "该研究针对微流控活细胞成像中高通量实验缺乏实时洞察的问题，提出EAP4EMSIG框架，以提升事件驱动显微镜在单细胞分析中的性能。该框架包括三个关键组件：一个快速深度学习自动对焦方法（Mean Absolute Error为0.0226 μm，推理时间低于50 ms）、实时分割方法的评估（Cellpose 3达到Panoptic Quality 93.58%，而距离-based方法最快，121 ms且Panoptic Quality 93.02%），以及实时数据分析仪表板。实验结果表明，所有六种Deep Learning Foundation Models不适合实时分割，从而为智能微流控单细胞分析提供了更高效的工具。",
      "categories": [
        "q-bio.QM",
        "cs.AI",
        "cs.CV"
      ],
      "primary_category": "q-bio.QM",
      "comment": "Submitted to: at - Automatisierungstechnik",
      "pdf_url": "http://arxiv.org/pdf/2504.00047v1",
      "published_date": "2025-03-30 23:16:23 UTC",
      "updated_date": "2025-03-30 23:16:23 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-24T07:32:37.594873"
    },
    {
      "arxiv_id": "2503.23622v1",
      "title": "Beyond Detection: Designing AI-Resilient Assessments with Automated Feedback Tool to Foster Critical Thinking",
      "title_zh": "翻译失败",
      "authors": [
        "Muhammad Sajjad Akbar"
      ],
      "abstract": "The growing use of generative AI tools like ChatGPT has raised urgent\nconcerns about their impact on student learning, particularly the potential\nerosion of critical thinking and creativity. As students increasingly turn to\nthese tools to complete assessments, foundational cognitive skills are at risk\nof being bypassed, challenging the integrity of higher education and the\nauthenticity of student work. Existing AI-generated text detection tools are\ninadequate; they produce unreliable outputs and are prone to both false\npositives and false negatives, especially when students apply paraphrasing,\ntranslation, or rewording. These systems rely on shallow statistical patterns\nrather than true contextual or semantic understanding, making them unsuitable\nas definitive indicators of AI misuse. In response, this research proposes a\nproactive, AI-resilient solution based on assessment design rather than\ndetection. It introduces a web-based Python tool that integrates Bloom's\nTaxonomy with advanced natural language processing techniques including GPT-3.5\nTurbo, BERT-based semantic similarity, and TF-IDF metrics to evaluate the\nAI-solvability of assessment tasks. By analyzing surface-level and semantic\nfeatures, the tool helps educators determine whether a task targets lower-order\nthinking such as recall and summarization or higher-order skills such as\nanalysis, evaluation, and creation, which are more resistant to AI automation.\nThis framework empowers educators to design cognitively demanding, AI-resistant\nassessments that promote originality, critical thinking, and fairness. It\noffers a sustainable, pedagogically sound strategy to foster authentic learning\nand uphold academic standards in the age of AI.",
      "tldr_zh": "这篇论文讨论了生成式 AI（如 ChatGPT）对学生学习的影响，特别是对批判性思考和创造力的潜在侵蚀，并指出现有 AI 生成文本检测工具（如基于浅层统计模式的系统）不可靠，易产生误报或漏报。论文提出一种主动的 AI-resilient 评估设计解决方案，引入一个基于网络的 Python 工具，该工具整合 Bloom's Taxonomy 与高级 NLP 技术（如 GPT-3.5 Turbo、BERT-based semantic similarity 和 TF-IDF 指标），用于分析任务的表面和语义特征。工具帮助教育者评估任务是否针对高阶认知技能（如分析、评价和创造），从而设计出更具挑战性和 AI 抵抗性的评估，促进学生的原创性、批判性思考和公平学习。最终，该框架为 AI 时代的高等教育提供了一个可持续的策略，以维护学术标准和真实性。",
      "categories": [
        "cs.CY",
        "cs.AI"
      ],
      "primary_category": "cs.CY",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2503.23622v1",
      "published_date": "2025-03-30 23:13:00 UTC",
      "updated_date": "2025-03-30 23:13:00 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-24T07:32:49.692072"
    },
    {
      "arxiv_id": "2504.00046v2",
      "title": "Multi-Stakeholder Disaster Insights from Social Media Using Large Language Models",
      "title_zh": "利用大语言模型从社交媒体获取多利益相关者灾害洞察",
      "authors": [
        "Loris Belcastro",
        "Cristian Cosentino",
        "Fabrizio Marozzo",
        "Merve Gündüz-Cüre",
        "Sule Öztürk-Birim"
      ],
      "abstract": "In recent years, social media has emerged as a primary channel for users to\npromptly share feedback and issues during disasters and emergencies, playing a\nkey role in crisis management. While significant progress has been made in\ncollecting and analyzing social media content, there remains a pressing need to\nenhance the automation, aggregation, and customization of this data to deliver\nactionable insights tailored to diverse stakeholders, including the press,\npolice, EMS, and firefighters. This effort is essential for improving the\ncoordination of activities such as relief efforts, resource distribution, and\nmedia communication. This paper presents a methodology that leverages the\ncapabilities of LLMs to enhance disaster response and management. Our approach\ncombines classification techniques with generative AI to bridge the gap between\nraw user feedback and stakeholder-specific reports. Social media posts shared\nduring catastrophic events are analyzed with a focus on user-reported issues,\nservice interruptions, and encountered challenges. We employ full-spectrum\nLLMs, using analytical models like BERT for precise, multi-dimensional\nclassification of content type, sentiment, emotion, geolocation, and topic.\nGenerative models such as ChatGPT are then used to produce human-readable,\ninformative reports tailored to distinct audiences, synthesizing insights\nderived from detailed classifications. We compare standard approaches, which\nanalyze posts directly using prompts in ChatGPT, to our advanced method, which\nincorporates multi-dimensional classification, sub-event selection, and\ntailored report generation. Our methodology demonstrates superior performance\nin both quantitative metrics, such as text coherence scores and latent\nrepresentations, and qualitative assessments by automated tools and field\nexperts, delivering precise insights for diverse disaster response\nstakeholders.",
      "tldr_zh": "该研究提出了一种利用大型语言模型（LLMs）的方法，从社交媒体数据中提取多利益相关者（如媒体、警察、EMS和消防员）专属的灾害洞见，以提升危机管理和资源协调。方法结合分类模型如BERT进行多维度分析（包括内容类型、情感、情绪、地理位置和主题），并使用生成模型如ChatGPT合成人性化的定制报告。相比直接使用ChatGPT的标准方法，该框架通过子事件选择和报告生成，显著提高了文本连贯性、潜在表示等定量指标，并在定性和专家评估中表现出色，提供更精确的灾害响应洞见。",
      "categories": [
        "cs.CL",
        "cs.AI",
        "cs.ET",
        "cs.SI"
      ],
      "primary_category": "cs.CL",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2504.00046v2",
      "published_date": "2025-03-30 22:53:52 UTC",
      "updated_date": "2025-04-17 11:29:06 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-24T07:33:01.082038"
    },
    {
      "arxiv_id": "2503.23617v1",
      "title": "Graph-Eq: Discovering Mathematical Equations using Graph Generative Models",
      "title_zh": "Graph-Eq: 使用图生成模型发现数学方程",
      "authors": [
        "Nisal Ranasinghe",
        "Damith Senanayake",
        "Saman Halgamuge"
      ],
      "abstract": "The ability to discover meaningful, accurate, and concise mathematical\nequations that describe datasets is valuable across various domains. Equations\noffer explicit relationships between variables, enabling deeper insights into\nunderlying data patterns. Most existing equation discovery methods rely on\ngenetic programming, which iteratively searches the equation space but is often\nslow and prone to overfitting. By representing equations as directed acyclic\ngraphs, we leverage the use of graph neural networks to learn the underlying\nsemantics of equations, and generate new, previously unseen equations. Although\ngraph generative models have been shown to be successful in discovering new\ntypes of graphs in many fields, there application in discovering equations\nremains largely unexplored. In this work, we propose Graph-EQ, a deep graph\ngenerative model designed for efficient equation discovery. Graph-EQ uses a\nconditional variational autoencoder (CVAE) to learn a rich latent\nrepresentation of the equation space by training it on a large corpus of\nequations in an unsupervised manner. Instead of directly searching the equation\nspace, we employ Bayesian optimization to efficiently explore this learned\nlatent space. We show that the encoder-decoder architecture of Graph-Eq is able\nto accurately reconstruct input equations. Moreover, we show that the learned\nlatent representation can be sampled and decoded into valid equations,\nincluding new and previously unseen equations in the training data. Finally, we\nassess Graph-Eq's ability to discover equations that best fit a dataset by\nexploring the latent space using Bayesian optimization. Latent space\nexploration is done on 20 dataset with known ground-truth equations, and\nGraph-Eq is shown to successfully discover the grountruth equation in the\nmajority of datasets.",
      "tldr_zh": "该论文提出 Graph-EQ，一种基于图生成模型的框架，用于发现描述数据集的数学方程，以克服现有 genetic programming 方法的低效性和过拟合问题。Graph-EQ 将方程表示为 directed acyclic graphs，并利用条件变分自编码器 (CVAE) 在大型方程语料上进行无监督训练，学习方程空间的潜在表示，然后通过 Bayesian optimization 高效探索该空间。实验结果显示，Graph-EQ 能准确重建输入方程、生成新颖的未见方程，并在 20 个数据集上成功发现 ground-truth 方程。",
      "categories": [
        "cs.LG",
        "cs.AI",
        "I.2"
      ],
      "primary_category": "cs.LG",
      "comment": "8 pages, 4 figures",
      "pdf_url": "http://arxiv.org/pdf/2503.23617v1",
      "published_date": "2025-03-30 22:47:57 UTC",
      "updated_date": "2025-03-30 22:47:57 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-24T07:33:14.053489"
    },
    {
      "arxiv_id": "2503.23616v1",
      "title": "Interpretable Machine Learning in Physics: A Review",
      "title_zh": "物理学中的可解释机器学习：综述",
      "authors": [
        "Sebastian Johann Wetzel",
        "Seungwoong Ha",
        "Raban Iten",
        "Miriam Klopotek",
        "Ziming Liu"
      ],
      "abstract": "Machine learning is increasingly transforming various scientific fields,\nenabled by advancements in computational power and access to large data sets\nfrom experiments and simulations. As artificial intelligence (AI) continues to\ngrow in capability, these algorithms will enable many scientific discoveries\nbeyond human capabilities. Since the primary goal of science is to understand\nthe world around us, fully leveraging machine learning in scientific discovery\nrequires models that are interpretable -- allowing experts to comprehend the\nconcepts underlying machine-learned predictions. Successful interpretations\nincrease trust in black-box methods, help reduce errors, allow for the\nimprovement of the underlying models, enhance human-AI collaboration, and\nultimately enable fully automated scientific discoveries that remain\nunderstandable to human scientists. This review examines the role of\ninterpretability in machine learning applied to physics. We categorize\ndifferent aspects of interpretability, discuss machine learning models in terms\nof both interpretability and performance, and explore the philosophical\nimplications of interpretability in scientific inquiry. Additionally, we\nhighlight recent advances in interpretable machine learning across many\nsubfields of physics. By bridging boundaries between disciplines -- each with\nits own unique insights and challenges -- we aim to establish interpretable\nmachine learning as a core research focus in science.",
      "tldr_zh": "这篇综述论文探讨了可解释机器学习（interpretable machine learning）在物理学中的作用，强调其在科学发现中的必要性，以提升对黑盒模型的信任、减少错误并促进人类-AI 协作。作者分类了可解释性的不同方面，比较了机器学习模型在性能和可解释性之间的权衡，并分析了其在科学探究中的哲学含义，同时回顾了物理学子领域（如粒子物理和量子力学）的最新进展。最终，该论文旨在将可解释机器学习确立为核心科学研究焦点，推动跨学科融合以实现可理解的自动化发现。",
      "categories": [
        "physics.comp-ph",
        "cs.AI",
        "cs.LG"
      ],
      "primary_category": "physics.comp-ph",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2503.23616v1",
      "published_date": "2025-03-30 22:44:40 UTC",
      "updated_date": "2025-03-30 22:44:40 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-24T07:33:25.226215"
    },
    {
      "arxiv_id": "2503.23615v1",
      "title": "An Organizationally-Oriented Approach to Enhancing Explainability and Control in Multi-Agent Reinforcement Learning",
      "title_zh": "翻译失败",
      "authors": [
        "Julien Soulé",
        "Jean-Paul Jamont",
        "Michel Occello",
        "Louis-Marie Traonouez",
        "Paul Théron"
      ],
      "abstract": "Multi-Agent Reinforcement Learning can lead to the development of\ncollaborative agent behaviors that show similarities with organizational\nconcepts. Pushing forward this perspective, we introduce a novel framework that\nexplicitly incorporates organizational roles and goals from the\n$\\mathcal{M}OISE^+$ model into the MARL process, guiding agents to satisfy\ncorresponding organizational constraints. By structuring training with roles\nand goals, we aim to enhance both the explainability and control of agent\nbehaviors at the organizational level, whereas much of the literature primarily\nfocuses on individual agents. Additionally, our framework includes a\npost-training analysis method to infer implicit roles and goals, offering\ninsights into emergent agent behaviors. This framework has been applied across\nvarious MARL environments and algorithms, demonstrating coherence between\npredefined organizational specifications and those inferred from trained\nagents.",
      "tldr_zh": "该论文提出了一种以组织为导向的框架，将 $\\mathcal{M}OISE^+$ 模型中的组织角色和目标显式整合到多智能体强化学习（MARL）中，以提升代理行为的解释性和控制性。该框架通过结构化训练指导代理满足组织约束，同时引入后训练分析方法来推断隐含角色和目标，从而提供对涌现行为的洞见。在各种 MARL 环境和算法中应用后，该框架展示了预定义组织规范与训练代理推断结果的高度一致性。",
      "categories": [
        "cs.AI",
        "cs.LG"
      ],
      "primary_category": "cs.AI",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2503.23615v1",
      "published_date": "2025-03-30 22:43:01 UTC",
      "updated_date": "2025-03-30 22:43:01 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-24T07:33:37.250039"
    },
    {
      "arxiv_id": "2503.23605v1",
      "title": "Partial Transportability for Domain Generalization",
      "title_zh": "翻译失败",
      "authors": [
        "Kasra Jalaldoust",
        "Alexis Bellot",
        "Elias Bareinboim"
      ],
      "abstract": "A fundamental task in AI is providing performance guarantees for predictions\nmade in unseen domains. In practice, there can be substantial uncertainty about\nthe distribution of new data, and corresponding variability in the performance\nof existing predictors. Building on the theory of partial identification and\ntransportability, this paper introduces new results for bounding the value of a\nfunctional of the target distribution, such as the generalization error of a\nclassifier, given data from source domains and assumptions about the data\ngenerating mechanisms, encoded in causal diagrams. Our contribution is to\nprovide the first general estimation technique for transportability problems,\nadapting existing parameterization schemes such Neural Causal Models to encode\nthe structural constraints necessary for cross-population inference. We\ndemonstrate the expressiveness and consistency of this procedure and further\npropose a gradient-based optimization scheme for making scalable inferences in\npractice. Our results are corroborated with experiments.",
      "tldr_zh": "本论文针对AI领域中为未见域预测提供性能保证的问题，引入了Partial Transportability方法，用于在给定源域数据和因果图编码的数据生成机制假设下，界定目标分布的功能（如分类器的泛化错误）。该方法基于部分识别和transportability理论，开发了第一个通用估计技术，通过Neural Causal Models编码结构约束，实现跨群体推理。研究证明了该过程的表达性和一致性，并提出基于梯度的优化方案以提升实际可扩展性，结果通过实验得到验证。",
      "categories": [
        "cs.LG",
        "cs.AI",
        "stat.ML"
      ],
      "primary_category": "cs.LG",
      "comment": "causalai.net/r88.pdf",
      "pdf_url": "http://arxiv.org/pdf/2503.23605v1",
      "published_date": "2025-03-30 22:06:37 UTC",
      "updated_date": "2025-03-30 22:06:37 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-24T07:33:49.045116"
    },
    {
      "arxiv_id": "2503.23598v1",
      "title": "GenVP: Generating Visual Puzzles with Contrastive Hierarchical VAEs",
      "title_zh": "GenVP：使用对比层次 VAEs 生成视觉谜题",
      "authors": [
        "Kalliopi Basioti",
        "Pritish Sahu",
        "Qingze Tony Liu",
        "Zihao Xu",
        "Hao Wang",
        "Vladimir Pavlovic"
      ],
      "abstract": "Raven's Progressive Matrices (RPMs) is an established benchmark to examine\nthe ability to perform high-level abstract visual reasoning (AVR). Despite the\ncurrent success of algorithms that solve this task, humans can generalize\nbeyond a given puzzle and create new puzzles given a set of rules, whereas\nmachines remain locked in solving a fixed puzzle from a curated choice list. We\npropose Generative Visual Puzzles (GenVP), a framework to model the entire RPM\ngeneration process, a substantially more challenging task. Our model's\ncapability spans from generating multiple solutions for one specific problem\nprompt to creating complete new puzzles out of the desired set of rules.\nExperiments on five different datasets indicate that GenVP achieves\nstate-of-the-art (SOTA) performance both in puzzle-solving accuracy and\nout-of-distribution (OOD) generalization in 22 OOD scenarios. Compared to SOTA\ngenerative approaches, which struggle to solve RPMs when the feasible solution\nspace increases, GenVP efficiently generalizes to these challenging setups.\nMoreover, our model demonstrates the ability to produce a wide range of\ncomplete RPMs given a set of abstract rules by effectively capturing the\nrelationships between abstract rules and visual object properties.",
      "tldr_zh": "本研究针对 Raven's Progressive Matrices (RPMs) 测试高级抽象视觉推理 (AVR) 的能力，提出 GenVP 框架，利用 Contrastive Hierarchical VAEs 生成视觉谜题，这比传统解决固定谜题更具挑战性。GenVP 模型能够为特定问题生成多个解决方案，并基于抽象规则创建全新的 RPMs，通过捕捉规则与视觉对象属性的关系实现高效生成。在五个数据集上的实验显示，GenVP 达到 state-of-the-art (SOTA) 性能，在谜题解决准确性和 out-of-distribution (OOD) 泛化方面表现出色，尤其在 22 个 OOD 场景中超越其他生成方法。",
      "categories": [
        "cs.AI",
        "cs.CV"
      ],
      "primary_category": "cs.AI",
      "comment": "Accepted to ICLR 2025",
      "pdf_url": "http://arxiv.org/pdf/2503.23598v1",
      "published_date": "2025-03-30 21:35:26 UTC",
      "updated_date": "2025-03-30 21:35:26 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-24T07:34:01.743230"
    },
    {
      "arxiv_id": "2504.00043v1",
      "title": "CrossWordBench: Evaluating the Reasoning Capabilities of LLMs and LVLMs with Controllable Puzzle Generation",
      "title_zh": "翻译失败",
      "authors": [
        "Jixuan Leng",
        "Chengsong Huang",
        "Langlin Huang",
        "Bill Yuchen Lin",
        "William W. Cohen",
        "Haohan Wang",
        "Jiaxin Huang"
      ],
      "abstract": "Existing reasoning evaluation frameworks for Large Language Models (LLMs) and\nLarge Vision-Language Models (LVLMs) predominantly either assess text-based\nreasoning or vision-language understanding capabilities, with limited dynamic\ninterplay between textual and visual constraints. To address this limitation,\nwe introduce CrossWordBench, a benchmark designed to evaluate the reasoning\ncapabilities of both LLMs and LVLMs through the medium of crossword puzzles-a\ntask requiring multimodal adherence to semantic constraints from text-based\nclues and intersectional constraints from visual grid structures.\nCrossWordBench leverages a controllable puzzle generation framework that\nproduces puzzles in multiple formats (text and image) and offers different\nevaluation strategies ranging from direct puzzle solving to interactive modes.\nOur extensive evaluation of over 20 models reveals that reasoning LLMs\noutperform non-reasoning models substantially by effectively leveraging\ncrossing-letter constraints. We further demonstrate that LVLMs struggle with\nthe task, showing a strong correlation between their puzzle-solving performance\nand grid-parsing accuracy. Our findings offer insights into the limitations of\nthe reasoning capabilities of current LLMs and LVLMs, and provide an effective\napproach for creating multimodal constrained tasks for future evaluations.",
      "tldr_zh": "本文提出 CrossWordBench 基准，用于评估 Large Language Models (LLMs) 和 Large Vision-Language Models (LVLMs) 的推理能力，通过可控填字游戏生成框架整合文本线索和视觉网格的语义约束，实现文本与视觉动态互动。框架支持多种格式（如文本和图像）和评估策略，包括直接解决和交互模式，对超过20个模型进行评估，结果显示推理型LLMs显著优于非推理型模型，因为它们有效利用交叉字母约束，而LVLMs的表现受网格解析准确性影响较大。该研究揭示了当前模型的推理局限性，并为创建多模态约束任务提供有效评估方法。",
      "categories": [
        "cs.CL",
        "cs.AI",
        "cs.CV"
      ],
      "primary_category": "cs.CL",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2504.00043v1",
      "published_date": "2025-03-30 20:03:36 UTC",
      "updated_date": "2025-03-30 20:03:36 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-24T07:34:13.410181"
    },
    {
      "arxiv_id": "2503.23573v1",
      "title": "DASH: Detection and Assessment of Systematic Hallucinations of VLMs",
      "title_zh": "翻译失败",
      "authors": [
        "Maximilian Augustin",
        "Yannic Neuhaus",
        "Matthias Hein"
      ],
      "abstract": "Vision-language models (VLMs) are prone to object hallucinations, where they\nerroneously indicate the presenceof certain objects in an image. Existing\nbenchmarks quantify hallucinations using relatively small, labeled datasets.\nHowever, this approach is i) insufficient to assess hallucinations that arise\nin open-world settings, where VLMs are widely used, and ii) inadequate for\ndetecting systematic errors in VLMs. We propose DASH (Detection and Assessment\nof Systematic Hallucinations), an automatic, large-scale pipeline designed to\nidentify systematic hallucinations of VLMs on real-world images in an\nopen-world setting. A key component is DASH-OPT for image-based retrieval,\nwhere we optimize over the ''natural image manifold'' to generate images that\nmislead the VLM. The output of DASH consists of clusters of real and\nsemantically similar images for which the VLM hallucinates an object. We apply\nDASH to PaliGemma and two LLaVA-NeXT models across 380 object classes and, in\ntotal, find more than 19k clusters with 950k images. We study the transfer of\nthe identified systematic hallucinations to other VLMs and show that\nfine-tuning PaliGemma with the model-specific images obtained with DASH\nmitigates object hallucinations. Code and data are available at\nhttps://YanNeu.github.io/DASH.",
      "tldr_zh": "本研究提出DASH（Detection and Assessment of Systematic Hallucinations），一个自动的大型管道，用于检测和评估视觉语言模型（VLMs）在真实世界图像中的系统性物体幻觉问题。DASH通过其关键组件DASH-OPT优化“自然图像流形”生成误导VLMs的图像，并输出VLMs幻觉物体的语义相似图像集群。研究者在PaliGemma和两个LLaVA-NeXT模型上应用DASH，覆盖380个物体类别，识别出超过19k个集群和950k图像，并证明这些系统性幻觉可在其他VLMs间转移。最终，实验显示，使用DASH获得的模型特定图像对PaliGemma进行微调可有效缓解物体幻觉，为VLMs的鲁棒性改进提供了新途径。",
      "categories": [
        "cs.CV",
        "cs.AI",
        "cs.LG"
      ],
      "primary_category": "cs.CV",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2503.23573v1",
      "published_date": "2025-03-30 19:45:09 UTC",
      "updated_date": "2025-03-30 19:45:09 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-24T07:34:25.694322"
    },
    {
      "arxiv_id": "2504.00040v1",
      "title": "Quantum Methods for Managing Ambiguity in Natural Language Processing",
      "title_zh": "量子方法用于管理自然语言处理中的模糊性",
      "authors": [
        "Jurek Eisinger",
        "Ward Gauderis",
        "Lin de Huybrecht",
        "Geraint A. Wiggins"
      ],
      "abstract": "The Categorical Compositional Distributional (DisCoCat) framework models\nmeaning in natural language using the mathematical framework of quantum theory,\nexpressed as formal diagrams. DisCoCat diagrams can be associated with tensor\nnetworks and quantum circuits. DisCoCat diagrams have been connected to density\nmatrices in various contexts in Quantum Natural Language Processing (QNLP).\nPrevious use of density matrices in QNLP entails modelling ambiguous words as\nprobability distributions over more basic words (the word \\texttt{queen}, e.g.,\nmight mean the reigning queen or the chess piece). In this article, we\ninvestigate using probability distributions over processes to account for\nsyntactic ambiguity in sentences. The meanings of these sentences are\nrepresented by density matrices. We show how to create probability\ndistributions on quantum circuits that represent the meanings of sentences and\nexplain how this approach generalises tasks from the literature. We conduct an\nexperiment to validate the proposed theory.",
      "tldr_zh": "本研究探讨了量子方法在处理自然语言处理(Natural Language Processing)中的歧义问题，基于Categorical Compositional Distributional (DisCoCat)框架，将语言含义建模为量子理论的形式化图表，并与张量网络和量子电路相关联。不同于以往将歧义词建模为对基本词的概率分布，本文提出使用对过程的概率分布来管理句子的句法歧义，并通过密度矩阵(density matrices)表示句子含义，同时展示了如何在量子电路(quantum circuits)中创建这些分布，以推广Quantum Natural Language Processing (QNLP)中的现有任务。研究通过实验验证了这一理论的有效性，为歧义管理提供了新视角。",
      "categories": [
        "cs.CL",
        "cs.AI",
        "quant-ph",
        "I.2"
      ],
      "primary_category": "cs.CL",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2504.00040v1",
      "published_date": "2025-03-30 19:10:37 UTC",
      "updated_date": "2025-03-30 19:10:37 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-24T07:34:36.922651"
    },
    {
      "arxiv_id": "2503.23550v1",
      "title": "Addressing Model Overcomplexity in Drug-Drug Interaction Prediction With Molecular Fingerprints",
      "title_zh": "利用分子指纹解决药物-药物相互作用预测中的模型过复杂性",
      "authors": [
        "Manel Gil-Sorribes",
        "Alexis Molina"
      ],
      "abstract": "Accurately predicting drug-drug interactions (DDIs) is crucial for\npharmaceutical research and clinical safety. Recent deep learning models often\nsuffer from high computational costs and limited generalization across\ndatasets. In this study, we investigate a simpler yet effective approach using\nmolecular representations such as Morgan fingerprints (MFPS), graph-based\nembeddings from graph convolutional networks (GCNs), and transformer-derived\nembeddings from MoLFormer integrated into a straightforward neural network. We\nbenchmark our implementation on DrugBank DDI splits and a drug-drug affinity\n(DDA) dataset from the Food and Drug Administration. MFPS along with MoLFormer\nand GCN representations achieve competitive performance across tasks, even in\nthe more challenging leak-proof split, highlighting the sufficiency of simple\nmolecular representations. Moreover, we are able to identify key molecular\nmotifs and structural patterns relevant to drug interactions via gradient-based\nanalyses using the representations under study. Despite these results, dataset\nlimitations such as insufficient chemical diversity, limited dataset size, and\ninconsistent labeling impact robust evaluation and challenge the need for more\ncomplex approaches. Our work provides a meaningful baseline and emphasizes the\nneed for better dataset curation and progressive complexity scaling.",
      "tldr_zh": "本研究针对药物-药物相互作用 (DDIs) 预测中的模型过复杂问题，提出使用简单分子表示如 Morgan fingerprints (MFPS)、来自 graph convolutional networks (GCNs) 的图-based embeddings 和 MoLFormer 的 transformer-derived embeddings，整合到一个直观的神经网络中进行预测。实验在 DrugBank DDI splits 和 FDA 的 DDA 数据集上进行基准测试，结果显示这些表示在各种任务中表现出色，甚至在 challenging 的 leak-proof split 中也实现竞争性能，并通过梯度-based 分析识别了与药物相互作用相关的关键分子基序和结构模式。尽管数据集存在化学多样性不足、规模有限和标签不一致等问题，该工作提供了一个有意义的基准，强调了改进数据集整理和渐进复杂性scaling的需求。",
      "categories": [
        "q-bio.BM",
        "cs.AI",
        "cs.LG"
      ],
      "primary_category": "q-bio.BM",
      "comment": "Accepted to the GEM Workshop at ICLR 2025",
      "pdf_url": "http://arxiv.org/pdf/2503.23550v1",
      "published_date": "2025-03-30 18:27:01 UTC",
      "updated_date": "2025-03-30 18:27:01 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-24T07:34:50.534685"
    },
    {
      "arxiv_id": "2503.23536v2",
      "title": "A Survey on Unlearnable Data",
      "title_zh": "翻译失败",
      "authors": [
        "Jiahao Li",
        "Yiqiang Chen",
        "Yunbing Xing",
        "Yang Gu",
        "Xiangyuan Lan"
      ],
      "abstract": "Unlearnable data (ULD) has emerged as an innovative defense technique to\nprevent machine learning models from learning meaningful patterns from specific\ndata, thus protecting data privacy and security. By introducing perturbations\nto the training data, ULD degrades model performance, making it difficult for\nunauthorized models to extract useful representations. Despite the growing\nsignificance of ULD, existing surveys predominantly focus on related fields,\nsuch as adversarial attacks and machine unlearning, with little attention given\nto ULD as an independent area of study. This survey fills that gap by offering\na comprehensive review of ULD, examining unlearnable data generation methods,\npublic benchmarks, evaluation metrics, theoretical foundations and practical\napplications. We compare and contrast different ULD approaches, analyzing their\nstrengths, limitations, and trade-offs related to unlearnability,\nimperceptibility, efficiency and robustness. Moreover, we discuss key\nchallenges, such as balancing perturbation imperceptibility with model\ndegradation and the computational complexity of ULD generation. Finally, we\nhighlight promising future research directions to advance the effectiveness and\napplicability of ULD, underscoring its potential to become a crucial tool in\nthe evolving landscape of data protection in machine learning.",
      "tldr_zh": "这篇论文对Unlearnable Data (ULD)进行了全面调查，ULD是一种通过在训练数据中引入扰动来防止机器学习模型学习有意义模式的技术，从而保护数据隐私和安全。论文审查了ULD的生成方法、公共基准、评估指标、理论基础以及实际应用，并比较了不同方法的优势、局限性及权衡，包括unlearnability、imperceptibility、efficiency和robustness。作者讨论了关键挑战，如平衡扰动的不易察觉性与模型性能退化，以及ULD生成的计算复杂度。最后，论文强调了ULD在数据保护中的潜力，并提出了未来研究方向以提升其有效性和适用性。",
      "categories": [
        "cs.LG",
        "cs.AI"
      ],
      "primary_category": "cs.LG",
      "comment": "31 pages, 3 figures, Code in\n  https://github.com/LiJiahao-Alex/Awesome-UnLearnable-Data",
      "pdf_url": "http://arxiv.org/pdf/2503.23536v2",
      "published_date": "2025-03-30 17:41:30 UTC",
      "updated_date": "2025-04-01 16:42:45 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-24T07:35:02.373639"
    },
    {
      "arxiv_id": "2503.23534v1",
      "title": "BiPVL-Seg: Bidirectional Progressive Vision-Language Fusion with Global-Local Alignment for Medical Image Segmentation",
      "title_zh": "翻译失败",
      "authors": [
        "Rafi Ibn Sultan",
        "Hui Zhu",
        "Chengyin Li",
        "Dongxiao Zhu"
      ],
      "abstract": "Medical image segmentation typically relies solely on visual data,\noverlooking the rich textual information clinicians use for diagnosis.\nVision-language models attempt to bridge this gap, but existing approaches\noften process visual and textual features independently, resulting in weak\ncross-modal alignment. Simple fusion techniques fail due to the inherent\ndifferences between spatial visual features and sequential text embeddings.\nAdditionally, medical terminology deviates from general language, limiting the\neffectiveness of off-the-shelf text encoders and further hindering\nvision-language alignment. We propose BiPVL-Seg, an end-to-end framework that\nintegrates vision-language fusion and embedding alignment through architectural\nand training innovations, where both components reinforce each other to enhance\nmedical image segmentation. BiPVL-Seg introduces bidirectional progressive\nfusion in the architecture, which facilitates stage-wise information exchange\nbetween vision and text encoders. Additionally, it incorporates global-local\ncontrastive alignment, a training objective that enhances the text encoder's\ncomprehension by aligning text and vision embeddings at both class and concept\nlevels. Extensive experiments on diverse medical imaging benchmarks across CT\nand MR modalities demonstrate BiPVL-Seg's superior performance when compared\nwith state-of-the-art methods in complex multi-class segmentation. Source code\nis available in this GitHub repository.",
      "tldr_zh": "该论文指出，传统医疗图像分割仅依赖视觉数据，而忽略了临床文本信息，导致现有视觉语言模型在跨模态对齐上存在弱点。作者提出BiPVL-Seg框架，一个端到端系统，通过双向渐进融合(bidirectional progressive fusion)实现视觉和文本编码器之间的阶段性信息交换，并引入全局-局部对比对齐(global-local contrastive alignment)训练目标，在类和概念级别对齐文本和视觉嵌入，从而提升医疗图像分割性能。在CT和MR模态的多类分割基准上，BiPVL-Seg比最先进方法表现出色，提供开源代码以促进进一步研究。",
      "categories": [
        "cs.CV",
        "cs.AI"
      ],
      "primary_category": "cs.CV",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2503.23534v1",
      "published_date": "2025-03-30 17:34:39 UTC",
      "updated_date": "2025-03-30 17:34:39 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-24T07:35:13.505221"
    },
    {
      "arxiv_id": "2503.23514v1",
      "title": "If an LLM Were a Character, Would It Know Its Own Story? Evaluating Lifelong Learning in LLMs",
      "title_zh": "翻译失败",
      "authors": [
        "Siqi Fan",
        "Xiusheng Huang",
        "Yiqun Yao",
        "Xuezhi Fang",
        "Kang Liu",
        "Peng Han",
        "Shuo Shang",
        "Aixin Sun",
        "Yequan Wang"
      ],
      "abstract": "Large language models (LLMs) can carry out human-like dialogue, but unlike\nhumans, they are stateless due to the superposition property. However, during\nmulti-turn, multi-agent interactions, LLMs begin to exhibit consistent,\ncharacter-like behaviors, hinting at a form of emergent lifelong learning.\nDespite this, existing benchmarks often fail to capture these dynamics,\nprimarily focusing on static, open-ended evaluations. To address this gap, we\nintroduce LIFESTATE-BENCH, a benchmark designed to assess lifelong learning in\nLLMs. It features two episodic datasets: Hamlet and a synthetic script\ncollection, rich in narrative structure and character interactions. Our fact\nchecking evaluation probes models' self-awareness, episodic memory retrieval,\nand relationship tracking, across both parametric and non-parametric\napproaches. Experiments on models like Llama3.1-8B, GPT-4-turbo, and DeepSeek\nR1, we demonstrate that nonparametric methods significantly outperform\nparametric ones in managing stateful learning. However, all models exhibit\nchallenges with catastrophic forgetting as interactions extend, highlighting\nthe need for further advancements in lifelong learning.",
      "tldr_zh": "本研究评估大型语言模型（LLMs）在多轮、多代理互动中的终身学习（lifelong learning）能力，探讨它们是否能像角色般保持一致行为和记忆。论文引入 LIFESTATE-BENCH 基准，利用 Hamlet 和合成脚本数据集进行事实检查评估，测试模型的自我意识、情节记忆检索（episodic memory retrieval）和关系跟踪。实验结果显示，非参数方法（nonparametric methods）在处理有状态学习方面显著优于参数方法（parametric approaches），但所有测试模型（如 Llama3.1-8B 和 GPT-4-turbo）均面临互动延长时的灾难性遗忘（catastrophic forgetting），强调了提升终身学习机制的必要性。",
      "categories": [
        "cs.CL",
        "cs.AI"
      ],
      "primary_category": "cs.CL",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2503.23514v1",
      "published_date": "2025-03-30 16:50:57 UTC",
      "updated_date": "2025-03-30 16:50:57 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-24T07:35:25.339811"
    },
    {
      "arxiv_id": "2503.23511v1",
      "title": "Buffer is All You Need: Defending Federated Learning against Backdoor Attacks under Non-iids via Buffering",
      "title_zh": "翻译失败",
      "authors": [
        "Xingyu Lyu",
        "Ning Wang",
        "Yang Xiao",
        "Shixiong Li",
        "Tao Li",
        "Danjue Chen",
        "Yimin Chen"
      ],
      "abstract": "Federated Learning (FL) is a popular paradigm enabling clients to jointly\ntrain a global model without sharing raw data. However, FL is known to be\nvulnerable towards backdoor attacks due to its distributed nature. As\nparticipants, attackers can upload model updates that effectively compromise\nFL. What's worse, existing defenses are mostly designed under\nindependent-and-identically-distributed (iid) settings, hence neglecting the\nfundamental non-iid characteristic of FL. Here we propose FLBuff for tackling\nbackdoor attacks even under non-iids. The main challenge for such defenses is\nthat non-iids bring benign and malicious updates closer, hence harder to\nseparate. FLBuff is inspired by our insight that non-iids can be modeled as\nomni-directional expansion in representation space while backdoor attacks as\nuni-directional. This leads to the key design of FLBuff, i.e., a\nsupervised-contrastive-learning model extracting penultimate-layer\nrepresentations to create a large in-between buffer layer. Comprehensive\nevaluations demonstrate that FLBuff consistently outperforms state-of-the-art\ndefenses.",
      "tldr_zh": "本研究针对联邦学习(FL)中后门攻击的脆弱性，提出了一种名为FLBuff的防御方法，专门处理非独立同分布(non-iids)场景下良性和恶意更新难以区分的挑战。该方法基于一个关键洞见，将non-iids建模为表示空间中的全向扩展，而后门攻击视为单向扩展，并使用监督对比学习模型提取倒数第二层的表示来创建大型缓冲层。实验评估显示，FLBuff在多种设置下均优于现有最先进防御。",
      "categories": [
        "cs.CR",
        "cs.AI"
      ],
      "primary_category": "cs.CR",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2503.23511v1",
      "published_date": "2025-03-30 16:46:14 UTC",
      "updated_date": "2025-03-30 16:46:14 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-24T07:35:37.503008"
    },
    {
      "arxiv_id": "2503.23502v1",
      "title": "Boosting Omnidirectional Stereo Matching with a Pre-trained Depth Foundation Model",
      "title_zh": "利用预训练深度基础模型提升全向立体匹配",
      "authors": [
        "Jannik Endres",
        "Oliver Hahn",
        "Charles Corbière",
        "Simone Schaub-Meyer",
        "Stefan Roth",
        "Alexandre Alahi"
      ],
      "abstract": "Omnidirectional depth perception is essential for mobile robotics\napplications that require scene understanding across a full 360{\\deg} field of\nview. Camera-based setups offer a cost-effective option by using stereo depth\nestimation to generate dense, high-resolution depth maps without relying on\nexpensive active sensing. However, existing omnidirectional stereo matching\napproaches achieve only limited depth accuracy across diverse environments,\ndepth ranges, and lighting conditions, due to the scarcity of real-world data.\nWe present DFI-OmniStereo, a novel omnidirectional stereo matching method that\nleverages a large-scale pre-trained foundation model for relative monocular\ndepth estimation within an iterative optimization-based stereo matching\narchitecture. We introduce a dedicated two-stage training strategy to utilize\nthe relative monocular depth features for our omnidirectional stereo matching\nbefore scale-invariant fine-tuning. DFI-OmniStereo achieves state-of-the-art\nresults on the real-world Helvipad dataset, reducing disparity MAE by\napproximately 16% compared to the previous best omnidirectional stereo method.",
      "tldr_zh": "该论文针对全向立体匹配（Omnidirectional Stereo Matching）在移动机器人应用中的准确性问题，提出了一种新方法DFI-OmniStereo，利用预训练的Depth Foundation Model进行相对单目深度估计（Relative Monocular Depth Estimation），并整合到迭代优化架构中。方法包括一个专用的两阶段训练策略，先利用单目深度特征进行全向立体匹配，然后进行尺度不变的微调。实验结果显示，在真实世界Helvipad数据集上，DFI-OmniStereo实现了State-of-the-Art性能，将视差均方误差（Disparity MAE）比之前最佳方法降低了约16%。",
      "categories": [
        "cs.CV",
        "cs.AI",
        "cs.LG",
        "cs.RO"
      ],
      "primary_category": "cs.CV",
      "comment": "Project page: https://vita-epfl.github.io/DFI-OmniStereo-website/",
      "pdf_url": "http://arxiv.org/pdf/2503.23502v1",
      "published_date": "2025-03-30 16:24:22 UTC",
      "updated_date": "2025-03-30 16:24:22 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-24T07:35:51.264176"
    },
    {
      "arxiv_id": "2504.00038v1",
      "title": "Revisiting the Relationship between Adversarial and Clean Training: Why Clean Training Can Make Adversarial Training Better",
      "title_zh": "重新审视对抗训练和干净训练之间的关系：为什么干净训练能使对抗训练更好",
      "authors": [
        "MingWei Zhou",
        "Xiaobing Pei"
      ],
      "abstract": "Adversarial training (AT) is an effective technique for enhancing adversarial\nrobustness, but it usually comes at the cost of a decline in generalization\nability. Recent studies have attempted to use clean training to assist\nadversarial training, yet there are contradictions among the conclusions. We\ncomprehensively summarize the representative strategies and, with a focus on\nthe multi - view hypothesis, provide a unified explanation for the\ncontradictory phenomena among different studies. In addition, we conduct an in\n- depth analysis of the knowledge combinations transferred from clean - trained\nmodels to adversarially - trained models in previous studies, and find that\nthey can be divided into two categories: reducing the learning difficulty and\nproviding correct guidance. Based on this finding, we propose a new idea of\nleveraging clean training to further improve the performance of advanced AT\nmethods.We reveal that the problem of generalization degradation faced by AT\npartly stems from the difficulty of adversarial training in learning certain\nsample features, and this problem can be alleviated by making full use of clean\ntraining.",
      "tldr_zh": "这篇论文重新审视了对抗训练(AT)和清洁训练的关系，解释了为什么清洁训练能提升AT的性能，因为AT虽然提高了对抗鲁棒性，但往往会降低泛化能力。作者总结了代表性策略，通过多视图假设提供统一解释，并将从清洁训练模型转移到AT模型的知识分为两类：减少学习难度和提供正确指导。最终，他们提出新方法充分利用清洁训练来缓解AT在学习样本特征方面的困难，从而改善其整体表现。",
      "categories": [
        "cs.LG",
        "cs.AI"
      ],
      "primary_category": "cs.LG",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2504.00038v1",
      "published_date": "2025-03-30 15:58:41 UTC",
      "updated_date": "2025-03-30 15:58:41 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-24T07:36:01.416895"
    },
    {
      "arxiv_id": "2503.23491v1",
      "title": "POINT$^{2}$: A Polymer Informatics Training and Testing Database",
      "title_zh": "翻译失败",
      "authors": [
        "Jiaxin Xu",
        "Gang Liu",
        "Ruilan Guo",
        "Meng Jiang",
        "Tengfei Luo"
      ],
      "abstract": "The advancement of polymer informatics has been significantly propelled by\nthe integration of machine learning (ML) techniques, enabling the rapid\nprediction of polymer properties and expediting the discovery of\nhigh-performance polymeric materials. However, the field lacks a standardized\nworkflow that encompasses prediction accuracy, uncertainty quantification, ML\ninterpretability, and polymer synthesizability. In this study, we introduce\nPOINT$^{2}$ (POlymer INformatics Training and Testing), a comprehensive\nbenchmark database and protocol designed to address these critical challenges.\nLeveraging the existing labeled datasets and the unlabeled PI1M dataset, a\ncollection of approximately one million virtual polymers generated via a\nrecurrent neural network trained on the realistic polymers, we develop an\nensemble of ML models, including Quantile Random Forests, Multilayer\nPerceptrons with dropout, Graph Neural Networks, and pretrained large language\nmodels. These models are coupled with diverse polymer representations such as\nMorgan, MACCS, RDKit, Topological, Atom Pair fingerprints, and graph-based\ndescriptors to achieve property predictions, uncertainty estimations, model\ninterpretability, and template-based polymerization synthesizability across a\nspectrum of properties, including gas permeability, thermal conductivity, glass\ntransition temperature, melting temperature, fractional free volume, and\ndensity. The POINT$^{2}$ database can serve as a valuable resource for the\npolymer informatics community for polymer discovery and optimization.",
      "tldr_zh": "该研究引入了POINT²（POlymer INformatics Training and Testing），一个全面的基准数据库和协议，旨在标准化聚合物信息学工作流程，包括预测准确性、不确定性量化、Machine Learning (ML) 可解释性和聚合物合成可能性。研究利用现有标记数据集和PI1M数据集（约一百万虚拟聚合物）开发了多种ML模型的集成，如Quantile Random Forests、Multilayer Perceptrons with dropout、Graph Neural Networks和预训练的大型语言模型，并结合Morgan、MACCS、RDKit等聚合物表示进行属性预测。POINT²支持对气体渗透性、热导率、玻璃化转变温度等属性的预测、不确定性估计、模型可解释性和基于模板的合成评估，为聚合物信息学社区提供宝贵资源，促进聚合物发现和优化。",
      "categories": [
        "cond-mat.mtrl-sci",
        "cs.AI",
        "cs.LG"
      ],
      "primary_category": "cond-mat.mtrl-sci",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2503.23491v1",
      "published_date": "2025-03-30 15:46:01 UTC",
      "updated_date": "2025-03-30 15:46:01 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-24T07:36:13.802003"
    },
    {
      "arxiv_id": "2503.23487v1",
      "title": "Benchmarking Systematic Relational Reasoning with Large Language and Reasoning Models",
      "title_zh": "基于大型语言和推理模型的系统化关系推理基准测试",
      "authors": [
        "Irtaza Khalid",
        "Amir Masoud Nourollah",
        "Steven Schockaert"
      ],
      "abstract": "Large Language Models (LLMs) have been found to struggle with systematic\nreasoning. Even on tasks where they appear to perform well, their performance\noften depends on shortcuts, rather than on genuine reasoning abilities, leading\nthem to collapse on out-of-distribution examples. Post-training strategies\nbased on reinforcement learning and chain-of-thought prompting have recently\nbeen hailed as a step change. However, little is still known about the\npotential of the resulting ``Large Reasoning Models'' (LRMs) beyond problem\nsolving in mathematics and programming, where finding genuine\nout-of-distribution problems can be difficult. In this paper, we focus on tasks\nthat require systematic reasoning about relational compositions, especially for\nqualitative spatial and temporal reasoning. These tasks allow us to control the\ndifficulty of problem instances, and measure in a precise way to what extent\nmodels can generalise. We find that that the considered LLMs and LRMs overall\nperform poorly overall, albeit better than random chance.",
      "tldr_zh": "这篇论文评估了 Large Language Models (LLMs) 和 Large Reasoning Models (LRMs) 在系统性关系推理任务上的性能，发现这些模型往往依赖捷径而非真正的推理能力，导致在分布外样本上表现崩坏。研究聚焦于定性空间和时间推理任务，这些任务允许精确控制难度并测量模型的泛化能力。结果显示，所测试的 LLMs 和 LRMs 整体表现较差，但仍优于随机猜测，为后训练策略如强化学习和 chain-of-thought prompting 的局限性提供了重要基准。",
      "categories": [
        "cs.AI",
        "cs.CL",
        "cs.LG"
      ],
      "primary_category": "cs.AI",
      "comment": "Submitted to ACL 2025",
      "pdf_url": "http://arxiv.org/pdf/2503.23487v1",
      "published_date": "2025-03-30 15:41:55 UTC",
      "updated_date": "2025-03-30 15:41:55 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-24T07:36:25.266957"
    },
    {
      "arxiv_id": "2503.23486v1",
      "title": "A Systematic Decade Review of Trip Route Planning with Travel Time Estimation based on User Preferences and Behavior",
      "title_zh": "基于用户偏好和行为的旅行路线规划与旅行时间估计的系统十年回顾",
      "authors": [
        "Nikil Jayasuriya",
        "Deshan Sumanathilaka"
      ],
      "abstract": "This paper systematically explores the advancements in adaptive trip route\nplanning and travel time estimation (TTE) through Artificial Intelligence (AI).\nWith the increasing complexity of urban transportation systems, traditional\nnavigation methods often struggle to accommodate dynamic user preferences,\nreal-time traffic conditions, and scalability requirements. This study explores\nthe contributions of established AI techniques, including Machine Learning\n(ML), Reinforcement Learning (RL), and Graph Neural Networks (GNNs), alongside\nemerging methodologies like Meta-Learning, Explainable AI (XAI), Generative AI,\nand Federated Learning. In addition to highlighting these innovations, the\npaper identifies critical challenges such as ethical concerns, computational\nscalability, and effective data integration, which must be addressed to advance\nthe field. The paper concludes with recommendations for leveraging AI to build\nefficient, transparent, and sustainable navigation systems.",
      "tldr_zh": "这篇论文系统回顾了过去十年基于用户偏好和行为的旅行路线规划及旅行时间估计（TTE）的进展，强调了Artificial Intelligence (AI)在处理动态用户需求和实时交通条件方面的作用。论文探讨了多种AI技术，包括Machine Learning (ML)、Reinforcement Learning (RL)、Graph Neural Networks (GNNs)，以及新兴方法如Meta-Learning、Explainable AI (XAI)、Generative AI和Federated Learning，这些创新有助于提升导航系统的可伸缩性和适应性。研究同时指出了关键挑战，例如伦理问题、计算可伸缩性和数据整合问题。最终，论文提出建议，利用AI构建高效、透明和可持续的导航系统。",
      "categories": [
        "cs.AI"
      ],
      "primary_category": "cs.AI",
      "comment": "6 pages, 2 figures, 1 table",
      "pdf_url": "http://arxiv.org/pdf/2503.23486v1",
      "published_date": "2025-03-30 15:41:44 UTC",
      "updated_date": "2025-03-30 15:41:44 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-24T07:36:38.344473"
    },
    {
      "arxiv_id": "2503.23483v1",
      "title": "Order Independence With Finetuning",
      "title_zh": "通过微调实现的",
      "authors": [
        "Katrina Brown",
        "Reid McIlroy"
      ],
      "abstract": "Large language models (LLMs) demonstrate remarkable performance on many NLP\ntasks, yet often exhibit order dependence: simply reordering semantically\nidentical tokens (e.g., answer choices in multiple-choice questions) can lead\nto inconsistent predictions. Recent work proposes Set-Based Prompting (SBP) as\na way to remove order information from designated token subsets, thereby\nmitigating positional biases. However, applying SBP on base models induces an\nout-of-distribution input format, which can degrade in-distribution\nperformance. We introduce a fine-tuning strategy that integrates SBP into the\ntraining process, \"pulling\" these set-formatted prompts closer to the model's\ntraining manifold. We show that SBP can be incorporated into a model via\nfine-tuning. Our experiments on in-distribution (MMLU) and out-of-distribution\n(CSQA, ARC Challenge) multiple-choice tasks show that SBP fine-tuning\nsignificantly improves accuracy and robustness to answer-order permutations,\nall while preserving broader language modeling capabilities. We discuss the\nbroader implications of order-invariant modeling and outline future directions\nfor building fairer, more consistent LLMs.",
      "tldr_zh": "大语言模型(LLMs)常因顺序依赖问题而导致预测不一致，例如重新排列答案选项会影响多选任务的准确性，本文提出一种微调策略，将Set-Based Prompting (SBP)整合到训练过程中，以减少输入格式的分布偏移。实验结果显示，在MMLU、CSQA和ARC Challenge等任务上，SBP微调显著提升了准确率和对答案顺序置换的鲁棒性，同时保持了模型的整体语言建模能力。该研究讨论了顺序不变建模的更广泛含义，并为构建更公平、更一致的LLMs提供了未来方向。",
      "categories": [
        "cs.CL",
        "cs.AI",
        "cs.LG"
      ],
      "primary_category": "cs.CL",
      "comment": "Published as a Bi-Align workshop paper at ICLR 2025",
      "pdf_url": "http://arxiv.org/pdf/2503.23483v1",
      "published_date": "2025-03-30 15:38:43 UTC",
      "updated_date": "2025-03-30 15:38:43 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-24T07:36:51.692190"
    },
    {
      "arxiv_id": "2504.00037v1",
      "title": "ViT-Linearizer: Distilling Quadratic Knowledge into Linear-Time Vision Models",
      "title_zh": "翻译失败",
      "authors": [
        "Guoyizhe Wei",
        "Rama Chellappa"
      ],
      "abstract": "Vision Transformers (ViTs) have delivered remarkable progress through global\nself-attention, yet their quadratic complexity can become prohibitive for\nhigh-resolution inputs. In this work, we present ViT-Linearizer, a\ncross-architecture distillation framework that transfers rich ViT\nrepresentations into a linear-time, recurrent-style model. Our approach\nleverages 1) activation matching, an intermediate constraint that encourages\nstudent to align its token-wise dependencies with those produced by the\nteacher, and 2) masked prediction, a contextual reconstruction objective that\nrequires the student to predict the teacher's representations for unseen\n(masked) tokens, to effectively distill the quadratic self-attention knowledge\ninto the student while maintaining efficient complexity. Empirically, our\nmethod provides notable speedups particularly for high-resolution tasks,\nsignificantly addressing the hardware challenges in inference. Additionally, it\nalso elevates Mamba-based architectures' performance on standard vision\nbenchmarks, achieving a competitive 84.3% top-1 accuracy on ImageNet with a\nbase-sized model. Our results underscore the good potential of RNN-based\nsolutions for large-scale visual tasks, bridging the gap between theoretical\nefficiency and real-world practice.",
      "tldr_zh": "该论文提出 ViT-Linearizer，一种跨架构蒸馏框架，用于将 Vision Transformers (ViTs) 的二次复杂度知识转移到线性时间的循环式模型中，以解决高分辨率输入的计算挑战。框架采用 activation matching 和 masked prediction 两种技术，确保学生模型在 token-wise 依赖和上下文重建上与教师模型保持一致，从而高效地蒸馏自注意力知识。实验结果显示，该方法显著加速高分辨率任务的推理，并提升 Mamba-based 架构的性能，在 ImageNet 上实现 84.3% top-1 准确率，证明了 RNN-based 解决方案在大型视觉任务中的实际潜力。",
      "categories": [
        "cs.CV",
        "cs.AI"
      ],
      "primary_category": "cs.CV",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2504.00037v1",
      "published_date": "2025-03-30 15:35:24 UTC",
      "updated_date": "2025-03-30 15:35:24 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-24T07:37:03.185008"
    },
    {
      "arxiv_id": "2503.23478v1",
      "title": "Handling Delay in Real-Time Reinforcement Learning",
      "title_zh": "实时强化学习中的延迟处理",
      "authors": [
        "Ivan Anokhin",
        "Rishav Rishav",
        "Matthew Riemer",
        "Stephen Chung",
        "Irina Rish",
        "Samira Ebrahimi Kahou"
      ],
      "abstract": "Real-time reinforcement learning (RL) introduces several challenges. First,\npolicies are constrained to a fixed number of actions per second due to\nhardware limitations. Second, the environment may change while the network is\nstill computing an action, leading to observational delay. The first issue can\npartly be addressed with pipelining, leading to higher throughput and\npotentially better policies. However, the second issue remains: if each neuron\noperates in parallel with an execution time of $\\tau$, an $N$-layer\nfeed-forward network experiences observation delay of $\\tau N$. Reducing the\nnumber of layers can decrease this delay, but at the cost of the network's\nexpressivity. In this work, we explore the trade-off between minimizing delay\nand network's expressivity. We present a theoretically motivated solution that\nleverages temporal skip connections combined with history-augmented\nobservations. We evaluate several architectures and show that those\nincorporating temporal skip connections achieve strong performance across\nvarious neuron execution times, reinforcement learning algorithms, and\nenvironments, including four Mujoco tasks and all MinAtar games. Moreover, we\ndemonstrate parallel neuron computation can accelerate inference by 6-350% on\nstandard hardware. Our investigation into temporal skip connections and\nparallel computations paves the way for more efficient RL agents in real-time\nsetting.",
      "tldr_zh": "该论文探讨了实时强化学习（RL）中的延迟挑战，包括硬件限制导致的固定动作频率和环境变化引起的观察延迟。作者提出了一种理论驱动的解决方案，利用 temporal skip connections 和 history-augmented observations 来平衡延迟最小化和网络表达能力（expressivity）。实验结果显示，这种架构在各种神经元执行时间、RL 算法和环境中（如 Mujoco 任务和 MinAtar 游戏）表现出强性能，并通过并行神经元计算加速推理 6-350%。总体上，该工作为实时设置下的高效 RL 代理铺平了道路。",
      "categories": [
        "cs.LG",
        "cs.AI",
        "cs.RO"
      ],
      "primary_category": "cs.LG",
      "comment": "Accepted at ICLR 2025. Code available at\n  https://github.com/avecplezir/realtime-agent",
      "pdf_url": "http://arxiv.org/pdf/2503.23478v1",
      "published_date": "2025-03-30 15:30:27 UTC",
      "updated_date": "2025-03-30 15:30:27 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-24T07:37:13.792465"
    },
    {
      "arxiv_id": "2504.13186v1",
      "title": "Advanced Deep Learning and Large Language Models: Comprehensive Insights for Cancer Detection",
      "title_zh": "高级深度学习和大语言模型：癌症检测的全面见解",
      "authors": [
        "Yassine Habchi",
        "Hamza Kheddar",
        "Yassine Himeur",
        "Adel Belouchrani",
        "Erchin Serpedin",
        "Fouad Khelifi",
        "Muhammad E. H. Chowdhury"
      ],
      "abstract": "The rapid advancement of deep learning (DL) has transformed healthcare,\nparticularly in cancer detection and diagnosis. DL surpasses traditional\nmachine learning and human accuracy, making it a critical tool for identifying\ndiseases. Despite numerous reviews on DL in healthcare, a comprehensive\nanalysis of its role in cancer detection remains limited. Existing studies\nfocus on specific aspects, leaving gaps in understanding its broader impact.\nThis paper addresses these gaps by reviewing advanced DL techniques, including\ntransfer learning (TL), reinforcement learning (RL), federated learning (FL),\nTransformers, and large language models (LLMs). These approaches enhance\naccuracy, tackle data scarcity, and enable decentralized learning while\nmaintaining data privacy. TL adapts pre-trained models to new datasets,\nimproving performance with limited labeled data. RL optimizes diagnostic\npathways and treatment strategies, while FL fosters collaborative model\ndevelopment without sharing sensitive data. Transformers and LLMs,\ntraditionally used in natural language processing, are now applied to medical\ndata for improved interpretability. Additionally, this review examines these\ntechniques' efficiency in cancer diagnosis, addresses challenges like data\nimbalance, and proposes solutions. It serves as a resource for researchers and\npractitioners, providing insights into current trends and guiding future\nresearch in advanced DL for cancer detection.",
      "tldr_zh": "这篇论文全面审视了深度学习(DL)在癌症检测中的应用，超越了传统机器学习和人类准确性，并填补了现有研究的空白。论文分析了高级DL技术，包括转移学习(TL)、强化学习(RL)、联邦学习(FL)、Transformer和大型语言模型(LLMs)，这些方法提升了诊断准确性、解决了数据稀缺问题，并通过去中心化学习保护数据隐私。最终，它探讨了这些技术在癌症诊断中的效率、挑战（如数据不平衡）及解决方案，为研究者和从业者提供资源和未来研究指导。",
      "categories": [
        "eess.IV",
        "cs.AI",
        "cs.CV",
        "cs.LG"
      ],
      "primary_category": "eess.IV",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2504.13186v1",
      "published_date": "2025-03-30 15:17:40 UTC",
      "updated_date": "2025-03-30 15:17:40 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-24T07:37:25.396468"
    },
    {
      "arxiv_id": "2503.23466v1",
      "title": "Codehacks: A Dataset of Adversarial Tests for Competitive Programming Problems Obtained from Codeforces",
      "title_zh": "翻译失败",
      "authors": [
        "Max Hort",
        "Leon Moonen"
      ],
      "abstract": "Software is used in critical applications in our day-to-day life and it is\nimportant to ensure its correctness. One popular approach to assess correctness\nis to evaluate software on tests. If a test fails, it indicates a fault in the\nsoftware under test; if all tests pass correctly, one may assume that the\nsoftware is correct. However, the reliability of these results depends on the\ntest suite considered, and there is a risk of false negatives (i.e. software\nthat passes all available tests but contains bugs because some cases are not\ntested). Therefore, it is important to consider error-inducing test cases when\nevaluating software.\n  To support data-driven creation of such a test-suite, which is especially of\ninterest for testing software synthesized from large language models, we curate\na dataset (Codehacks) of programming problems together with corresponding\nerror-inducing test cases (i.e., \"hacks\"). This dataset is collected from the\nwild, in particular, from the Codeforces online judge platform. The dataset\ncomprises 288,617 hacks for 5,578 programming problems, each with a natural\nlanguage description, as well as the source code for 2,196 submitted solutions\nto these problems that can be broken with their corresponding hacks.\n  Keywords: competitive programming, language model, dataset",
      "tldr_zh": "该论文介绍了Codehacks数据集，该数据集从Codeforces在线评判平台收集了288,617个对抗性测试用例（adversarial tests），用于识别软件中的隐藏bug，特别是针对competitive programming问题。数据集涵盖5,578个编程问题，每个问题附有自然语言描述，以及2,196个可被这些测试用例打破的源代码（submitted solutions）。这项工作旨在支持数据驱动的测试套件创建，尤其有助于评估由大型语言模型(language model)合成的软件的正确性。",
      "categories": [
        "cs.SE",
        "cs.AI",
        "cs.CL",
        "cs.LG"
      ],
      "primary_category": "cs.SE",
      "comment": "Accepted for publication at the 18th IEEE International Conference on\n  Software Testing, Verification and Validation (ICST 2025)",
      "pdf_url": "http://arxiv.org/pdf/2503.23466v1",
      "published_date": "2025-03-30 14:50:03 UTC",
      "updated_date": "2025-03-30 14:50:03 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-24T07:37:38.013154"
    },
    {
      "arxiv_id": "2504.01985v1",
      "title": "Multi-Dimensional AGV Path Planning in 3D Warehouses Using Ant Colony Optimization and Advanced Neural Networks",
      "title_zh": "翻译失败",
      "authors": [
        "Bo Zhang",
        "Xiubo Liang",
        "Wei Song",
        "Yulu Chen"
      ],
      "abstract": "Within modern warehouse scenarios, the rapid expansion of e-commerce and\nincreasingly complex, multi-level storage environments have exposed the\nlimitations of traditional AGV (Automated Guided Vehicle) path planning\nmethods--often reliant on static 2D models and expert-tuned heuristics that\nstruggle to handle dynamic traffic and congestion. Addressing these\nlimitations, this paper introduces a novel AGV path planning approach for 3D\nwarehouse environments that leverages a hybrid framework combining ACO (Ant\nColony Optimization) with deep learning models, called NAHACO (Neural Adaptive\nHeuristic Ant Colony Optimization). NAHACO integrates three key innovations:\nfirst, an innovative heuristic algorithm for 3D warehouse cargo modeling using\nmultidimensional tensors, which addresses the challenge of achieving superior\nheuristic accuracy; second, integration of a congestion-aware loss function\nwithin the ACO framework to adjust path costs based on traffic and capacity\nconstraints, called CARL (Congestion-Aware Reinforce Loss), enabling dynamic\nheuristic calibration for optimizing ACO-based path planning; and third, an\nadaptive attention mechanism that captures multi-scale spatial features,\nthereby addressing dynamic heuristic calibration for further optimization of\nACO-based path planning and AGV navigation. NAHACO significantly boosts path\nplanning efficiency, yielding faster computation times and superior performance\nover both vanilla and state-of-the-art methods, while automatically adapting to\nwarehouse constraints for real-time optimization. NAHACO outperforms\nstate-of-the-art methods, lowering the total cost by up to 24.7% on TSP\nbenchmarks. In warehouse tests, NAHACO cuts cost by up to 41.5% and congestion\nby up to 56.1% compared to previous methods.",
      "tldr_zh": "这篇论文针对传统AGV路径规划在3D仓库环境中处理动态交通和拥堵的局限性，提出了一种创新框架NAHACO，将Ant Colony Optimization (ACO)与深度学习模型结合。NAHACO的关键创新包括使用多维张量建模仓库货物、集成Congestion-Aware Reinforce Loss (CARL)来动态调整路径成本以应对容量约束，以及适应性注意力机制捕捉多尺度空间特征，从而优化AGV导航。实验结果显示，NAHACO在TSP基准测试中降低了总成本高达24.7%，而在实际仓库测试中，成本降低了41.5%、拥堵降低了56.1%，显著优于现有方法。",
      "categories": [
        "cs.RO",
        "cs.AI"
      ],
      "primary_category": "cs.RO",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2504.01985v1",
      "published_date": "2025-03-30 14:09:21 UTC",
      "updated_date": "2025-03-30 14:09:21 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-24T07:37:50.136329"
    },
    {
      "arxiv_id": "2503.23448v1",
      "title": "Semantic-Preserving Transformations as Mutation Operators: A Study on Their Effectiveness in Defect Detection",
      "title_zh": "语义保持变换作为变异算子：对其在缺陷检测中的有效性研究",
      "authors": [
        "Max Hort",
        "Linas Vidziunas",
        "Leon Moonen"
      ],
      "abstract": "Recent advances in defect detection use language models. Existing works\nenhanced the training data to improve the models' robustness when applied to\nsemantically identical code (i.e., predictions should be the same). However,\nthe use of semantically identical code has not been considered for improving\nthe tools during their application - a concept closely related to metamorphic\ntesting.\n  The goal of our study is to determine whether we can use semantic-preserving\ntransformations, analogue to mutation operators, to improve the performance of\ndefect detection tools in the testing stage. We first collect existing\npublications which implemented semantic-preserving transformations and share\ntheir implementation, such that we can reuse them. We empirically study the\neffectiveness of three different ensemble strategies for enhancing defect\ndetection tools. We apply the collected transformations on the Devign dataset,\nconsidering vulnerabilities as a type of defect, and two fine-tuned large\nlanguage models for defect detection (VulBERTa, PLBART). We found 28\npublications with 94 different transformations.\n  We choose to implement 39 transformations from four of the publications, but\na manual check revealed that 23 out 39 transformations change code semantics.\nUsing the 16 remaining, correct transformations and three ensemble strategies,\nwe were not able to increase the accuracy of the defect detection models. Our\nresults show that reusing shared semantic-preserving transformation is\ndifficult, sometimes even causing wrongful changes to the semantics.\n  Keywords: defect detection, language model, semantic-preserving\ntransformation, ensemble",
      "tldr_zh": "本研究探讨了语义保持转换（semantic-preserving transformations）作为突变算子（mutation operators）在缺陷检测（defect detection）工具测试阶段的有效性，旨在通过类似形变测试的方法增强工具性能。研究者收集了28个出版物中的94个转换，并选择了39个进行实施，但手动检查发现23个会改变代码语义，最终仅使用16个正确的转换在Devign数据集上测试三种ensemble策略，并应用于VulBERTa和PLBART模型。结果显示，这些转换未能提高模型的准确率，并揭示了重用共享转换的困难，可能导致错误的语义改变。该研究强调了在缺陷检测中使用语义保持转换的潜在挑战，为未来改进提供了重要见解。",
      "categories": [
        "cs.SE",
        "cs.AI",
        "cs.CL",
        "cs.LG"
      ],
      "primary_category": "cs.SE",
      "comment": "Accepted for publication in Mutation 2025 at the 18th IEEE\n  International Conference on Software Testing, Verification and Validation\n  (ICST 2025)",
      "pdf_url": "http://arxiv.org/pdf/2503.23448v1",
      "published_date": "2025-03-30 14:00:22 UTC",
      "updated_date": "2025-03-30 14:00:22 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-24T07:38:02.881562"
    },
    {
      "arxiv_id": "2503.23439v1",
      "title": "Speculative End-Turn Detector for Efficient Speech Chatbot Assistant",
      "title_zh": "翻译失败",
      "authors": [
        "Hyunjong Ok",
        "Suho Yoo",
        "Jaeho Lee"
      ],
      "abstract": "Spoken dialogue systems powered by large language models have demonstrated\nremarkable abilities in understanding human speech and generating appropriate\nspoken responses. However, these systems struggle with end-turn detection (ETD)\n-- the ability to distinguish between user turn completion and hesitation. This\nlimitation often leads to premature or delayed responses, disrupting the flow\nof spoken conversations. In this paper, we introduce the ETD Dataset, the first\npublic dataset for end-turn detection. The ETD dataset consists of both\nsynthetic speech data generated with text-to-speech models and real-world\nspeech data collected from web sources. We also propose SpeculativeETD, a novel\ncollaborative inference framework that balances efficiency and accuracy to\nimprove real-time ETD in resource-constrained environments. Our approach\njointly employs a lightweight GRU-based model, which rapidly detects the\nnon-speaking units in real-time on local devices, and a high-performance\nWav2vec-based model running on the server to make a more challenging\nclassification of distinguishing turn ends from mere pauses. Experiments\ndemonstrate that the proposed SpeculativeETD significantly improves ETD\naccuracy while keeping the required computations low. Datasets and code will be\navailable after the review.",
      "tldr_zh": "这篇论文针对基于大型语言模型的口语对话系统在端转检测(ETD)上的挑战（如区分用户转结束和犹豫，导致响应不及时）进行了研究。作者引入了ETD Dataset，这是首个公开数据集，包含合成语音数据（使用文本到语音模型生成）和真实世界语音数据。论文提出了SpeculativeETD框架，一种协作推理方法，结合轻量级的GRU-based模型在本地设备上实时检测非说话单位，以及高性能的Wav2vec-based模型在服务器上进行更精确的分类。实验结果表明，SpeculativeETD显著提高了ETD准确性，同时保持了低计算需求，数据集和代码将在审阅后公开。",
      "categories": [
        "cs.CL",
        "cs.AI",
        "cs.LG",
        "cs.SD",
        "eess.AS"
      ],
      "primary_category": "cs.CL",
      "comment": "Preprint",
      "pdf_url": "http://arxiv.org/pdf/2503.23439v1",
      "published_date": "2025-03-30 13:34:23 UTC",
      "updated_date": "2025-03-30 13:34:23 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-24T07:38:13.941050"
    },
    {
      "arxiv_id": "2504.00036v1",
      "title": "Improving Diseases Predictions Utilizing External Bio-Banks",
      "title_zh": "利用外部生物银行改善疾病预测",
      "authors": [
        "Hido Pinto",
        "Eran Segal"
      ],
      "abstract": "Machine learning has been successfully used in critical domains, such as\nmedicine. However, extracting meaningful insights from biomedical data is often\nconstrained by the lack of their available disease labels. In this research, we\ndemonstrate how machine learning can be leveraged to enhance explainability and\nuncover biologically meaningful associations, even when predictive improvements\nin disease modeling are limited. We train LightGBM models from scratch on our\ndataset (10K) to impute metabolomics features and apply them to the UK Biobank\n(UKBB) for downstream analysis. The imputed metabolomics features are then used\nin survival analysis to assess their impact on disease-related risk factors. As\na result, our approach successfully identified biologically relevant\nconnections that were not previously known to the predictive models.\nAdditionally, we applied a genome-wide association study (GWAS) on key\nmetabolomics features, revealing a link between vascular dementia and smoking.\nAlthough being a well-established epidemiological relationship, this link was\nnot embedded in the model's training data, which validated the method's ability\nto extract meaningful signals. Furthermore, by integrating survival models as\ninputs in the 10K data, we uncovered associations between metabolic substances\nand obesity, demonstrating the ability to infer disease risk for future\npatients without requiring direct outcome labels. These findings highlight the\npotential of leveraging external bio-banks to extract valuable biomedical\ninsights, even in data-limited scenarios. Our results demonstrate that machine\nlearning models trained on smaller datasets can still be used to uncover real\nbiological associations when carefully integrated with survival analysis and\ngenetic studies.",
      "tldr_zh": "本文研究了如何利用外部生物银行（如 UK Biobank）提升疾病预测的解释性和生物学关联发现，即使预测模型的改进有限。作者训练 LightGBM 模型在 10K 数据集上推断代谢组学特征，并将其应用于 UK Biobank 进行生存分析和 genome-wide association study (GWAS)，从而识别出新的生物学联系，如血管性痴呆与吸烟的关联，以及代谢物质与肥胖的风险因素。结果表明，这种方法能在数据有限的场景下，通过整合生存模型，推断未来患者的疾病风险，并证明机器学习在提取有价值生物医学洞见的潜力。",
      "categories": [
        "q-bio.QM",
        "cs.AI",
        "cs.LG"
      ],
      "primary_category": "q-bio.QM",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2504.00036v1",
      "published_date": "2025-03-30 13:05:20 UTC",
      "updated_date": "2025-03-30 13:05:20 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-24T07:38:25.347380"
    },
    {
      "arxiv_id": "2503.23424v1",
      "title": "What Makes an Evaluation Useful? Common Pitfalls and Best Practices",
      "title_zh": "翻译失败",
      "authors": [
        "Gil Gekker",
        "Meirav Segal",
        "Dan Lahav",
        "Omer Nevo"
      ],
      "abstract": "Following the rapid increase in Artificial Intelligence (AI) capabilities in\nrecent years, the AI community has voiced concerns regarding possible safety\nrisks. To support decision-making on the safe use and development of AI\nsystems, there is a growing need for high-quality evaluations of dangerous\nmodel capabilities. While several attempts to provide such evaluations have\nbeen made, a clear definition of what constitutes a \"good evaluation\" has yet\nto be agreed upon. In this practitioners' perspective paper, we present a set\nof best practices for safety evaluations, drawing on prior work in model\nevaluation and illustrated through cybersecurity examples. We first discuss the\nsteps of the initial thought process, which connects threat modeling to\nevaluation design. Then, we provide the characteristics and parameters that\nmake an evaluation useful. Finally, we address additional considerations as we\nmove from building specific evaluations to building a full and comprehensive\nevaluation suite.",
      "tldr_zh": "这篇论文探讨了什么使评估（evaluation）有用，特别是针对 AI 安全风险的评估，强调了高质量评估在支持 AI 系统安全决策中的重要性。作者基于先前的模型评估工作，通过网络安全示例，概述了从威胁建模（threat modeling）到评估设计的初始思考过程，以及评估的有用特征、参数和常见陷阱。最终，论文提供最佳实践建议，包括构建全面评估套件（evaluation suite）的额外考虑，以提升 AI 开发的可靠性和安全性。",
      "categories": [
        "cs.LG",
        "cs.AI",
        "cs.CL",
        "cs.CR",
        "cs.CY"
      ],
      "primary_category": "cs.LG",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2503.23424v1",
      "published_date": "2025-03-30 12:51:47 UTC",
      "updated_date": "2025-03-30 12:51:47 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-24T07:38:36.612408"
    },
    {
      "arxiv_id": "2504.08758v1",
      "title": "Hyper-RAG: Combating LLM Hallucinations using Hypergraph-Driven Retrieval-Augmented Generation",
      "title_zh": "翻译失败",
      "authors": [
        "Yifan Feng",
        "Hao Hu",
        "Xingliang Hou",
        "Shiquan Liu",
        "Shihui Ying",
        "Shaoyi Du",
        "Han Hu",
        "Yue Gao"
      ],
      "abstract": "Large language models (LLMs) have transformed various sectors, including\neducation, finance, and medicine, by enhancing content generation and\ndecision-making processes. However, their integration into the medical field is\ncautious due to hallucinations, instances where generated content deviates from\nfactual accuracy, potentially leading to adverse outcomes. To address this, we\nintroduce Hyper-RAG, a hypergraph-driven Retrieval-Augmented Generation method\nthat comprehensively captures both pairwise and beyond-pairwise correlations in\ndomain-specific knowledge, thereby mitigating hallucinations. Experiments on\nthe NeurologyCrop dataset with six prominent LLMs demonstrated that Hyper-RAG\nimproves accuracy by an average of 12.3% over direct LLM use and outperforms\nGraph RAG and Light RAG by 6.3% and 6.0%, respectively. Additionally, Hyper-RAG\nmaintained stable performance with increasing query complexity, unlike existing\nmethods which declined. Further validation across nine diverse datasets showed\na 35.5% performance improvement over Light RAG using a selection-based\nassessment. The lightweight variant, Hyper-RAG-Lite, achieved twice the\nretrieval speed and a 3.3% performance boost compared with Light RAG. These\nresults confirm Hyper-RAG's effectiveness in enhancing LLM reliability and\nreducing hallucinations, making it a robust solution for high-stakes\napplications like medical diagnostics.",
      "tldr_zh": "该研究提出Hyper-RAG，一种基于超图驱动的检索增强生成（Retrieval-Augmented Generation）方法，用于减少大型语言模型（LLMs）的幻觉问题，通过捕捉领域知识中的成对和超越成对相关性，提升生成内容的准确性。实验在NeurologyCrop数据集上显示，Hyper-RAG与六种主要LLMs结合时，比直接使用LLMs提高了12.3%的准确率，并分别超过Graph RAG和Light RAG 6.3%和6.0%；在九个多样数据集上，它比Light RAG提升了35.5%的性能，且在查询复杂度增加时保持稳定。轻量版Hyper-RAG-Lite进一步实现了检索速度提高两倍和3.3%的性能提升，使其成为高风险应用如医疗诊断的可靠解决方案。",
      "categories": [
        "cs.IR",
        "cs.AI"
      ],
      "primary_category": "cs.IR",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2504.08758v1",
      "published_date": "2025-03-30 12:39:14 UTC",
      "updated_date": "2025-03-30 12:39:14 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-24T07:38:49.405312"
    },
    {
      "arxiv_id": "2503.23415v1",
      "title": "An Analysis of Decoding Methods for LLM-based Agents for Faithful Multi-Hop Question Answering",
      "title_zh": "翻译失败",
      "authors": [
        "Alexander Murphy",
        "Mohd Sanad Zaki Rizvi",
        "Aden Haussmann",
        "Ping Nie",
        "Guifu Liu",
        "Aryo Pradipta Gema",
        "Pasquale Minervini"
      ],
      "abstract": "Large Language Models (LLMs) frequently produce factually inaccurate outputs\n- a phenomenon known as hallucination - which limits their accuracy in\nknowledge-intensive NLP tasks. Retrieval-augmented generation and agentic\nframeworks such as Reasoning and Acting (ReAct) can address this issue by\ngiving the model access to external knowledge. However, LLMs often fail to\nremain faithful to retrieved information. Mitigating this is critical,\nespecially if LLMs are required to reason about the retrieved information.\nRecent research has explored training-free decoding strategies to improve the\nfaithfulness of model generations. We present a systematic analysis of how the\ncombination of the ReAct framework and decoding strategies (i.e., DeCoRe, DoLa,\nand CAD) can influence the faithfulness of LLM-generated answers. Our results\nshow that combining an agentic framework for knowledge retrieval with decoding\nmethods that enhance faithfulness can increase accuracy on the downstream\nMulti-Hop Question Answering tasks. For example, we observe an F1 increase from\n19.5 to 32.6 on HotpotQA when using ReAct and DoLa.",
      "tldr_zh": "这篇论文分析了解码方法如何提升LLM-based Agents在多跳问答任务中的忠实度，针对LLMs常见的hallination问题。研究结合了ReAct框架与训练-free解码策略（如DeCoRe、DoLa和CAD），通过检索增强生成（Retrieval-augmented generation）来确保模型对外部知识的忠实响应。结果显示，这种组合显著提高了下游Multi-Hop Question Answering任务的准确性，例如在HotpotQA上，F1分数从19.5增加到32.6。",
      "categories": [
        "cs.CL",
        "cs.AI"
      ],
      "primary_category": "cs.CL",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2503.23415v1",
      "published_date": "2025-03-30 12:18:21 UTC",
      "updated_date": "2025-03-30 12:18:21 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-24T07:39:02.800225"
    },
    {
      "arxiv_id": "2503.23414v1",
      "title": "From Content Creation to Citation Inflation: A GenAI Case Study",
      "title_zh": "从内容创建到引用膨胀：一个 GenAI 案例研究",
      "authors": [
        "Haitham S. Al-Sinani",
        "Chris J. Mitchell"
      ],
      "abstract": "This paper investigates the presence and impact of questionable, AI-generated\nacademic papers on widely used preprint repositories, with a focus on their\nrole in citation manipulation. Motivated by suspicious patterns observed in\npublications related to our ongoing research on GenAI-enhanced cybersecurity,\nwe identify clusters of questionable papers and profiles. These papers\nfrequently exhibit minimal technical content, repetitive structure,\nunverifiable authorship, and mutually reinforcing citation patterns among a\nrecurring set of authors. To assess the feasibility and implications of such\npractices, we conduct a controlled experiment: generating a fake paper using\nGenAI, embedding citations to suspected questionable publications, and\nuploading it to one such repository (ResearchGate). Our findings demonstrate\nthat such papers can bypass platform checks, remain publicly accessible, and\ncontribute to inflating citation metrics like the H-index and i10-index. We\npresent a detailed analysis of the mechanisms involved, highlight systemic\nweaknesses in content moderation, and offer recommendations for improving\nplatform accountability and preserving academic integrity in the age of GenAI.",
      "tldr_zh": "这篇论文探讨了GenAI生成的学术论文在预印本仓库（如ResearchGate）中的问题，焦点在于它们如何被用于引用操纵，包括内容稀少、结构重复和相互引用模式。研究者通过观察可疑论文集群并进行控制实验——使用GenAI生成一篇假论文并嵌入可疑引文上传——证明这些论文能绕过平台审核，进而膨胀引用指标如H-index和i10-index。论文分析了这些机制的系统性弱点，并提出改进内容审核措施，以维护GenAI时代下的学术诚信。",
      "categories": [
        "cs.DL",
        "cs.AI",
        "cs.CR"
      ],
      "primary_category": "cs.DL",
      "comment": "20 pages",
      "pdf_url": "http://arxiv.org/pdf/2503.23414v1",
      "published_date": "2025-03-30 12:17:26 UTC",
      "updated_date": "2025-03-30 12:17:26 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-24T07:39:13.579539"
    },
    {
      "arxiv_id": "2503.23407v1",
      "title": "GMapLatent: Geometric Mapping in Latent Space",
      "title_zh": "GMapLatent：潜在空间中的几何映射",
      "authors": [
        "Wei Zeng",
        "Xuebin Chang",
        "Jianghao Su",
        "Xiang Gu",
        "Jian Sun",
        "Zongben Xu"
      ],
      "abstract": "Cross-domain generative models based on encoder-decoder AI architectures have\nattracted much attention in generating realistic images, where domain alignment\nis crucial for generation accuracy. Domain alignment methods usually deal\ndirectly with the initial distribution; however, mismatched or mixed clusters\ncan lead to mode collapse and mixture problems in the decoder, compromising\nmodel generalization capabilities. In this work, we innovate a cross-domain\nalignment and generation model that introduces a canonical latent space\nrepresentation based on geometric mapping to align the cross-domain latent\nspaces in a rigorous and precise manner, thus avoiding mode collapse and\nmixture in the encoder-decoder generation architectures. We name this model\nGMapLatent. The core of the method is to seamlessly align latent spaces with\nstrict cluster correspondence constraints using the canonical parameterizations\nof cluster-decorated latent spaces. We first (1) transform the latent space to\na canonical parameter domain by composing barycenter translation, optimal\ntransport merging and constrained harmonic mapping, and then (2) compute\ngeometric registration with cluster constraints over the canonical parameter\ndomains. This process realizes a bijective (one-to-one and onto) mapping\nbetween newly transformed latent spaces and generates a precise alignment of\ncluster pairs. Cross-domain generation is then achieved through the aligned\nlatent spaces embedded in the encoder-decoder pipeline. Experiments on\ngray-scale and color images validate the efficiency, efficacy and applicability\nof GMapLatent, and demonstrate that the proposed model has superior performance\nover existing models.",
      "tldr_zh": "本文提出 GMapLatent 模型，通过 geometric mapping 在 latent space 中实现跨域对齐和生成，旨在解决传统编码器-解码器架构中因初始分布失配导致的模式崩溃和混合问题。核心方法包括将潜在空间转换为规范参数域（利用 barycenter translation、optimal transport merging 和 constrained harmonic mapping），并在该域上进行几何配准以确保严格的聚类对应约束，从而实现双射映射和精确对齐。实验结果显示，在灰度和彩色图像任务上，GMapLatent 比现有模型表现出更高的效率、有效性和泛化性能。",
      "categories": [
        "cs.CV",
        "cs.AI"
      ],
      "primary_category": "cs.CV",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2503.23407v1",
      "published_date": "2025-03-30 12:02:36 UTC",
      "updated_date": "2025-03-30 12:02:36 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-24T07:39:27.341231"
    },
    {
      "arxiv_id": "2503.23402v1",
      "title": "Diffusion Meets Few-shot Class Incremental Learning",
      "title_zh": "翻译失败",
      "authors": [
        "Junsu Kim",
        "Yunhoe Ku",
        "Dongyoon Han",
        "Seungryul Baek"
      ],
      "abstract": "Few-shot class-incremental learning (FSCIL) is challenging due to extremely\nlimited training data; while aiming to reduce catastrophic forgetting and learn\nnew information. We propose Diffusion-FSCIL, a novel approach that employs a\ntext-to-image diffusion model as a frozen backbone. Our conjecture is that\nFSCIL can be tackled using a large generative model's capabilities benefiting\nfrom 1) generation ability via large-scale pre-training; 2) multi-scale\nrepresentation; 3) representational flexibility through the text encoder. To\nmaximize the representation capability, we propose to extract multiple\ncomplementary diffusion features to play roles as latent replay with slight\nsupport from feature distillation for preventing generative biases. Our\nframework realizes efficiency through 1) using a frozen backbone; 2) minimal\ntrainable components; 3) batch processing of multiple feature extractions.\nExtensive experiments on CUB-200, miniImageNet, and CIFAR-100 show that\nDiffusion-FSCIL surpasses state-of-the-art methods, preserving performance on\npreviously learned classes and adapting effectively to new ones.",
      "tldr_zh": "该研究提出Diffusion-FSCIL方法，利用冻结的文本到图像扩散模型作为骨干，旨在解决Few-shot class-incremental learning (FSCIL)中的数据有限问题，同时减少灾难性遗忘并提升新信息学习。方法通过提取多个互补的扩散特征作为潜在重放（latent replay），并结合特征蒸馏（feature distillation）来防止生成偏差，同时实现高效计算，如使用最小可训练组件和批量处理。实验结果显示，在CUB-200、miniImageNet和CIFAR-100数据集上，Diffusion-FSCIL超越了现有最先进方法，在保持先前类性能的同时有效适应新类。",
      "categories": [
        "cs.CV",
        "cs.AI"
      ],
      "primary_category": "cs.CV",
      "comment": "pre-print",
      "pdf_url": "http://arxiv.org/pdf/2503.23402v1",
      "published_date": "2025-03-30 11:20:08 UTC",
      "updated_date": "2025-03-30 11:20:08 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-24T07:39:38.353688"
    },
    {
      "arxiv_id": "2503.23395v1",
      "title": "Scaling Auditory Cognition via Test-Time Compute in Audio Language Models",
      "title_zh": "翻译失败",
      "authors": [
        "Ting Dang",
        "Yan Gao",
        "Hong Jia"
      ],
      "abstract": "Large language models (LLMs) have shown exceptional versatility in natural\nlanguage processing, prompting recent efforts to extend their multimodal\ncapabilities to speech processing through the development of audio large\nlanguage models (Audio LLMs). While Audio LLMs excel in tasks such as speech\nrecognition and synthesis, it remains unclear how they perform when faced with\nthe auditory cognitive challenges posed by real-world environments, such as\naudio comprehension and listening recall, particularly in the presence of\nbackground noise or overlapping speech. Unlike text-based LLMs, which have\naccess to vast amounts of text data for pre-training, retraining Audio LLMs\nwith diverse auditory cognitive scenes is difficult due to the limited datasets\nthat simulate real-world auditory cognitive scenarios and the challenge of\nacquiring auditory cognitive labels for training. While test-time compute (TTC)\nmethods have been shown to enhance the capabilities of text-based LLMs during\ninference, a key challenge lies in designing these TTC methods to improve the\nauditory capabilities of Audio LLMs. This study aims to address these two\nresearch gaps by: i) exploring the auditory cognitive capabilities of Audio\nLLMs, and ii) enhancing their capabilities using TTC approaches. We have\ninvestigated five different Audio LLMs for auditory cognition using a\n\\textit{self-collected} database and have proposed five TTC approaches to\nenhance auditory cognitive capabilities during inference. Our findings reveal\nthat Audio LLMs performance decreases in more challenging auditory cognitive\ntasks. The proposed TTC approaches significantly enhance cognitive auditory\ncapabilities, advancing the development of more adaptable and resilient Audio\nLLMs for practical applications such as assistive listening devices,\nvoice-based AI assistants, and communication technologies.",
      "tldr_zh": "本文研究了 Audio LLMs 在真实听觉认知任务（如音频理解和回忆，尤其在背景噪声或重叠语音环境下）的性能，发现这些模型在复杂场景下表现下降。作者使用自收集数据库评估了五种 Audio LLMs，并提出五种 Test-Time Compute (TTC) 方法来提升其推理阶段的听觉认知能力。实验结果显示，TTC 方法显著改善了模型的适应性和鲁棒性，为 Audio LLMs 在实际应用中的发展提供了新途径，例如助听设备、语音 AI 助手和通信技术。",
      "categories": [
        "cs.SD",
        "cs.AI",
        "eess.AS"
      ],
      "primary_category": "cs.SD",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2503.23395v1",
      "published_date": "2025-03-30 11:04:18 UTC",
      "updated_date": "2025-03-30 11:04:18 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-24T07:39:50.204250"
    },
    {
      "arxiv_id": "2503.23394v1",
      "title": "Spatiotemporal Learning of Brain Dynamics from fMRI Using Frequency-Specific Multi-Band Attention for Cognitive and Psychiatric Applications",
      "title_zh": "翻译失败",
      "authors": [
        "Sangyoon Bae",
        "Junbeom Kwon",
        "Shinjae Yoo",
        "Jiook Cha"
      ],
      "abstract": "Understanding how the brain's complex nonlinear dynamics give rise to\nadaptive cognition and behavior is a central challenge in neuroscience. These\ndynamics exhibit scale-free and multifractal properties, influencing the\nreconfiguration of neural networks. However, conventional neuroimaging models\nare constrained by linear and stationary assumptions, limiting their ability to\ncapture these processes. Transformer-based architectures, known for capturing\nlong-range dependencies, align well with the brain's hierarchical and temporal\norganization. We introduce Multi-Band Brain Net (MBBN), a transformer-based\nframework that models frequency-specific spatiotemporal brain dynamics from\nfMRI by integrating scale-free network principles with frequency-resolved\nmulti-band self-attention. Trained on three large-scale neuroimaging cohorts\n(UK Biobank, ABCD, ABIDE) totaling 45,951 individuals, MBBN reveals previously\nundetectable frequency-dependent network interactions, shedding light on\nconnectivity disruptions in psychiatric conditions (ADHD, ASD, depression).\nThis validation shows robust generalizability and highlights core neural\nprinciples conserved across populations. MBBN achieves up to 30.59% higher\npredictive accuracy than state-of-the-art methods, demonstrating the advantage\nof frequency-informed spatiotemporal modeling in capturing latent neural\ncomputations. MBBN's interpretability uncovers novel frequency-specific\nbiomarkers for neurodevelopmental disorders, providing insights into the\nhierarchical organization of brain function. By offering an interpretable\nframework for spatiotemporal learning, MBBN provides insights into how neural\ncomputations underpin cognitive function and psychiatric vulnerability, with\nimplications for brain decoding, cognitive neuroscience, and precision\npsychiatry.",
      "tldr_zh": "这篇论文介绍了 Multi-Band Brain Net (MBBN)，一个基于 Transformer 的框架，用于从 fMRI 数据中学习频率特定的时空脑动态，旨在克服传统神经影像模型的线性静态限制。MBBN 通过整合 scale-free 网络原则和 frequency-resolved multi-band self-attention 机制，分析大脑的非线性动态，并在 UK Biobank、ABCD 和 ABIDE 等三个大型队列（共 45,951 个个体）上进行训练。研究揭示了先前未检测到的频率依赖网络互动，阐明 ADHD、ASD 和抑郁症等精神疾病的连接中断，并实现比最先进方法高出 30.59% 的预测准确率。该框架的解释性优势还发现了新的频率特定生物标志物，为脑解码、认知神经科学和精确精神病学提供了重要洞见。",
      "categories": [
        "q-bio.NC",
        "cs.AI"
      ],
      "primary_category": "q-bio.NC",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2503.23394v1",
      "published_date": "2025-03-30 10:56:50 UTC",
      "updated_date": "2025-03-30 10:56:50 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-24T07:40:03.553063"
    },
    {
      "arxiv_id": "2503.23390v1",
      "title": "Pareto Continual Learning: Preference-Conditioned Learning and Adaption for Dynamic Stability-Plasticity Trade-off",
      "title_zh": "翻译失败",
      "authors": [
        "Song Lai",
        "Zhe Zhao",
        "Fei Zhu",
        "Xi Lin",
        "Qingfu Zhang",
        "Gaofeng Meng"
      ],
      "abstract": "Continual learning aims to learn multiple tasks sequentially. A key challenge\nin continual learning is balancing between two objectives: retaining knowledge\nfrom old tasks (stability) and adapting to new tasks (plasticity). Experience\nreplay methods, which store and replay past data alongside new data, have\nbecome a widely adopted approach to mitigate catastrophic forgetting. However,\nthese methods neglect the dynamic nature of the stability-plasticity trade-off\nand aim to find a fixed and unchanging balance, resulting in suboptimal\nadaptation during training and inference. In this paper, we propose Pareto\nContinual Learning (ParetoCL), a novel framework that reformulates the\nstability-plasticity trade-off in continual learning as a multi-objective\noptimization (MOO) problem. ParetoCL introduces a preference-conditioned model\nto efficiently learn a set of Pareto optimal solutions representing different\ntrade-offs and enables dynamic adaptation during inference. From a\ngeneralization perspective, ParetoCL can be seen as an objective augmentation\napproach that learns from different objective combinations of stability and\nplasticity. Extensive experiments across multiple datasets and settings\ndemonstrate that ParetoCL outperforms state-of-the-art methods and adapts to\ndiverse continual learning scenarios.",
      "tldr_zh": "本论文提出 Pareto Continual Learning (ParetoCL) 框架，将持续学习中的稳定性（retaining knowledge from old tasks）和可塑性（adapting to new tasks）的权衡重新表述为多目标优化 (MOO) 问题，以解决现有方法忽略动态权衡导致的次优问题。ParetoCL 引入偏好条件模型，学习一组 Pareto 最优解，实现推理时的动态适应，并从泛化角度视其为目标增强方法。实验结果显示，该框架在多个数据集和设置中优于最先进方法，并能有效适应多样持续学习场景。",
      "categories": [
        "cs.LG",
        "cs.AI"
      ],
      "primary_category": "cs.LG",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2503.23390v1",
      "published_date": "2025-03-30 10:38:36 UTC",
      "updated_date": "2025-03-30 10:38:36 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-24T07:40:13.750944"
    },
    {
      "arxiv_id": "2503.23388v1",
      "title": "COSMIC: Clique-Oriented Semantic Multi-space Integration for Robust CLIP Test-Time Adaptation",
      "title_zh": "翻译失败",
      "authors": [
        "Fanding Huang",
        "Jingyan Jiang",
        "Qinting Jiang",
        "Hebei Li",
        "Faisal Nadeem Khan",
        "Zhi Wang"
      ],
      "abstract": "Recent vision-language models (VLMs) face significant challenges in test-time\nadaptation to novel domains. While cache-based methods show promise by\nleveraging historical information, they struggle with both caching unreliable\nfeature-label pairs and indiscriminately using single-class information during\nquerying, significantly compromising adaptation accuracy. To address these\nlimitations, we propose COSMIC (Clique-Oriented Semantic Multi-space\nIntegration for CLIP), a robust test-time adaptation framework that enhances\nadaptability through multi-granular, cross-modal semantic caching and\ngraph-based querying mechanisms. Our framework introduces two key innovations:\nDual Semantics Graph (DSG) and Clique Guided Hyper-class (CGH). The Dual\nSemantics Graph constructs complementary semantic spaces by incorporating\ntextual features, coarse-grained CLIP features, and fine-grained DINOv2\nfeatures to capture rich semantic relationships. Building upon these dual\ngraphs, the Clique Guided Hyper-class component leverages structured class\nrelationships to enhance prediction robustness through correlated class\nselection. Extensive experiments demonstrate COSMIC's superior performance\nacross multiple benchmarks, achieving significant improvements over\nstate-of-the-art methods: 15.81% gain on out-of-distribution tasks and 5.33% on\ncross-domain generation with CLIP RN-50. Code is available at\ngithub.com/hf618/COSMIC.",
      "tldr_zh": "该研究提出 COSMIC 框架，用于提升视觉语言模型 (VLMs) 在测试时适应新领域的鲁棒性，通过多粒度跨模态语义缓存和基于图的查询机制解决现有缓存方法的问题，如不可靠特征-标签对和单类信息滥用。  \nCOSMIC 的关键创新包括 Dual Semantics Graph (DSG)，它整合文本特征、粗粒度 CLIP 特征和细粒度 DINOv2 特征来构建互补语义空间；以及 Clique Guided Hyper-class (CGH)，利用结构化类关系进行相关类选择以增强预测准确性。  \n实验结果显示，COSMIC 在多个基准上显著优于现有方法，在分布外任务上提升 15.81%，在跨域生成任务上提升 5.33%（基于 CLIP RN-50），并提供开源代码以支持进一步验证。",
      "categories": [
        "cs.CV",
        "cs.AI",
        "cs.LG",
        "cs.MM"
      ],
      "primary_category": "cs.CV",
      "comment": "Accepted to CVPR 2025",
      "pdf_url": "http://arxiv.org/pdf/2503.23388v1",
      "published_date": "2025-03-30 10:34:45 UTC",
      "updated_date": "2025-03-30 10:34:45 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-24T07:40:26.604980"
    },
    {
      "arxiv_id": "2503.23379v1",
      "title": "KernelDNA: Dynamic Kernel Sharing via Decoupled Naive Adapters",
      "title_zh": "翻译失败",
      "authors": [
        "Haiduo Huang",
        "Yadong Zhang",
        "Pengju Ren"
      ],
      "abstract": "Dynamic convolution enhances model capacity by adaptively combining multiple\nkernels, yet faces critical trade-offs: prior works either (1) incur\nsignificant parameter overhead by scaling kernel numbers linearly, (2)\ncompromise inference speed through complex kernel interactions, or (3) struggle\nto jointly optimize dynamic attention and static kernels. We also observe that\npre-trained Convolutional Neural Networks (CNNs) exhibit inter-layer redundancy\nakin to that in Large Language Models (LLMs). Specifically, dense convolutional\nlayers can be efficiently replaced by derived ``child\" layers generated from a\nshared ``parent\" convolutional kernel through an adapter.\n  To address these limitations and implement the weight-sharing mechanism, we\npropose a lightweight convolution kernel plug-in, named KernelDNA. It decouples\nkernel adaptation into input-dependent dynamic routing and pre-trained static\nmodulation, ensuring both parameter efficiency and hardware-friendly inference.\nUnlike existing dynamic convolutions that expand parameters via multi-kernel\nensembles, our method leverages cross-layer weight sharing and adapter-based\nmodulation, enabling dynamic kernel specialization without altering the\nstandard convolution structure. This design preserves the native computational\nefficiency of standard convolutions while enhancing representation power\nthrough input-adaptive kernel adjustments. Experiments on image classification\nand dense prediction tasks demonstrate that KernelDNA achieves state-of-the-art\naccuracy-efficiency balance among dynamic convolution variants. Our codes are\navailable at https://github.com/haiduo/KernelDNA.",
      "tldr_zh": "这篇论文针对动态卷积(dynamic convolution)的参数开销、推理速度和优化挑战，提出了 KernelDNA，一种轻量级卷积内核插件，通过解耦 naive adapters 实现输入相关的动态路由和预训练的静态调制。KernelDNA 利用跨层权重共享和适配器-based 调制，使动态内核专业化而不改变标准卷积结构，从而保持计算效率并增强表示能力。与现有方法不同，该框架避免了多内核集成带来的参数膨胀。实验结果显示，KernelDNA 在图像分类和密集预测任务上达到了最先进的准确性-效率平衡。",
      "categories": [
        "cs.CV",
        "cs.AI",
        "cs.LG"
      ],
      "primary_category": "cs.CV",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2503.23379v1",
      "published_date": "2025-03-30 09:54:07 UTC",
      "updated_date": "2025-03-30 09:54:07 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-24T07:40:38.671942"
    },
    {
      "arxiv_id": "2503.23377v1",
      "title": "JavisDiT: Joint Audio-Video Diffusion Transformer with Hierarchical Spatio-Temporal Prior Synchronization",
      "title_zh": "JavisDiT：联合音频-视频扩散Transformer，带有层次空间-时间先验同步",
      "authors": [
        "Kai Liu",
        "Wei Li",
        "Lai Chen",
        "Shengqiong Wu",
        "Yanhao Zheng",
        "Jiayi Ji",
        "Fan Zhou",
        "Rongxin Jiang",
        "Jiebo Luo",
        "Hao Fei",
        "Tat-Seng Chua"
      ],
      "abstract": "This paper introduces JavisDiT, a novel Joint Audio-Video Diffusion\nTransformer designed for synchronized audio-video generation (JAVG). Built upon\nthe powerful Diffusion Transformer (DiT) architecture, JavisDiT is able to\ngenerate high-quality audio and video content simultaneously from open-ended\nuser prompts. To ensure optimal synchronization, we introduce a fine-grained\nspatio-temporal alignment mechanism through a Hierarchical Spatial-Temporal\nSynchronized Prior (HiST-Sypo) Estimator. This module extracts both global and\nfine-grained spatio-temporal priors, guiding the synchronization between the\nvisual and auditory components. Furthermore, we propose a new benchmark,\nJavisBench, consisting of 10,140 high-quality text-captioned sounding videos\nspanning diverse scenes and complex real-world scenarios. Further, we\nspecifically devise a robust metric for evaluating the synchronization between\ngenerated audio-video pairs in real-world complex content. Experimental results\ndemonstrate that JavisDiT significantly outperforms existing methods by\nensuring both high-quality generation and precise synchronization, setting a\nnew standard for JAVG tasks. Our code, model, and dataset will be made publicly\navailable at https://javisdit.github.io/.",
      "tldr_zh": "本文提出 JavisDiT，一种基于 Diffusion Transformer (DiT) 的联合音频-视频生成模型，能够从开放式用户提示同步生成高质量音频和视频。核心创新是引入 Hierarchical Spatial-Temporal Synchronized Prior (HiST-Sypo) Estimator，该模块通过提取全局和细粒度的时空先验，确保视觉和听觉组件的精确对齐。作者还构建了新基准 JavisBench（包含10,140个多样化视频）和一个鲁棒的同步评估指标，实验结果显示 JavisDiT 在音频-视频生成任务中显著优于现有方法，提供更高生成质量和同步精度。模型、代码和数据集将在 https://javisdit.github.io/ 公开。",
      "categories": [
        "cs.CV",
        "cs.AI",
        "cs.SD",
        "eess.AS"
      ],
      "primary_category": "cs.CV",
      "comment": "Work in progress. Homepage: https://javisdit.github.io/",
      "pdf_url": "http://arxiv.org/pdf/2503.23377v1",
      "published_date": "2025-03-30 09:40:42 UTC",
      "updated_date": "2025-03-30 09:40:42 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-24T07:40:50.792461"
    },
    {
      "arxiv_id": "2504.03721v1",
      "title": "A Hybrid Reinforcement Learning Framework for Hard Latency Constrained Resource Scheduling",
      "title_zh": "一种用于硬延迟约束资源调度的混合强化学习框架",
      "authors": [
        "Luyuan Zhang",
        "An Liu",
        "Kexuan Wang"
      ],
      "abstract": "In the forthcoming 6G era, extend reality (XR) has been regarded as an\nemerging application for ultra-reliable and low latency communications (URLLC)\nwith new traffic characteristics and more stringent requirements. In addition\nto the quasi-periodical traffic in XR, burst traffic with both large frame size\nand random arrivals in some real world low latency communication scenarios has\nbecome the leading cause of network congestion or even collapse, and there\nstill lacks an efficient algorithm for the resource scheduling problem under\nburst traffic with hard latency constraints. We propose a novel hybrid\nreinforcement learning framework for resource scheduling with hard latency\nconstraints (HRL-RSHLC), which reuses polices from both old policies learned\nunder other similar environments and domain-knowledge-based (DK) policies\nconstructed using expert knowledge to improve the performance. The joint\noptimization of the policy reuse probabilities and new policy is formulated as\nan Markov Decision Problem (MDP), which maximizes the hard-latency constrained\neffective throughput (HLC-ET) of users. We prove that the proposed HRL-RSHLC\ncan converge to KKT points with an arbitrary initial point. Simulations show\nthat HRL-RSHLC can achieve superior performance with faster convergence speed\ncompared to baseline algorithms.",
      "tldr_zh": "本研究针对6G时代扩展现实(XR)应用中突发流量导致的网络拥塞问题，提出了一种混合强化学习框架HRL-RSHLC，用于处理硬延迟约束下的资源调度。该框架通过重用旧策略和基于领域知识(DK)策略，优化策略重用概率和新策略的联合，形成一个Markov Decision Problem (MDP)，以最大化硬延迟约束有效吞吐量(HLC-ET)。研究证明，HRL-RSHLC可以从任意初始点收敛到KKT点，且模拟结果显示其比基线算法具有更优性能和更快收敛速度。",
      "categories": [
        "cs.NI",
        "cs.AI"
      ],
      "primary_category": "cs.NI",
      "comment": "13 pages, 8 figures",
      "pdf_url": "http://arxiv.org/pdf/2504.03721v1",
      "published_date": "2025-03-30 09:39:13 UTC",
      "updated_date": "2025-03-30 09:39:13 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-24T07:41:02.448833"
    },
    {
      "arxiv_id": "2503.23371v1",
      "title": "FeRG-LLM : Feature Engineering by Reason Generation Large Language Models",
      "title_zh": "翻译失败",
      "authors": [
        "Jeonghyun Ko",
        "Gyeongyun Park",
        "Donghoon Lee",
        "Kyunam Lee"
      ],
      "abstract": "One of the key tasks in machine learning for tabular data is feature\nengineering. Although it is vital for improving the performance of models, it\ndemands considerable human expertise and deep domain knowledge, making it\nlabor-intensive endeavor. To address this issue, we propose a novel framework,\n\\textbf{FeRG-LLM} (\\textbf{Fe}ature engineering by \\textbf{R}eason\n\\textbf{G}eneration \\textbf{L}arge \\textbf{L}anguage \\textbf{M}odels), a large\nlanguage model designed to automatically perform feature engineering at an\n8-billion-parameter scale. We have constructed two-stage conversational\ndialogues that enable language models to analyze machine learning tasks and\ndiscovering new features, exhibiting their Chain-of-Thought (CoT) capabilities.\nWe use these dialogues to fine-tune Llama 3.1 8B model and integrate Direct\nPreference Optimization (DPO) to receive feedback improving quality of new\nfeatures and the model's performance. Our experiments show that FeRG-LLM\nperforms comparably to or better than Llama 3.1 70B on most datasets, while\nusing fewer resources and achieving reduced inference time. It outperforms\nother studies in classification tasks and performs well in regression tasks.\nMoreover, since it does not rely on cloud-hosted LLMs like GPT-4 with extra API\ncosts when generating features, it can be deployed locally, addressing security\nconcerns.",
      "tldr_zh": "本文提出 FeRG-LLM 框架，这是一个基于大型语言模型的自动特征工程系统，旨在减少手动特征工程的劳动强度，通过两阶段对话和 Chain-of-Thought (CoT) 能力来分析机器学习任务并生成新特征，并使用 Direct Preference Optimization (DPO) 微调 Llama 3.1 8B 模型以提升性能。实验结果表明，FeRG-LLM 在大多数数据集上与 Llama 3.1 70B 相当或表现更好，尤其在分类任务中优于其他研究，同时在回归任务中表现出色，且资源消耗更低、推理时间缩短。相比依赖云服务的模型，FeRG-LLM 支持本地部署，降低了 API 成本和安全风险。",
      "categories": [
        "cs.CL",
        "cs.AI"
      ],
      "primary_category": "cs.CL",
      "comment": "Accepted to NAACL 2025 Findings",
      "pdf_url": "http://arxiv.org/pdf/2503.23371v1",
      "published_date": "2025-03-30 09:07:21 UTC",
      "updated_date": "2025-03-30 09:07:21 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-24T07:41:16.934513"
    },
    {
      "arxiv_id": "2503.23368v3",
      "title": "VLIPP: Towards Physically Plausible Video Generation with Vision and Language Informed Physical Prior",
      "title_zh": "翻译失败",
      "authors": [
        "Xindi Yang",
        "Baolu Li",
        "Yiming Zhang",
        "Zhenfei Yin",
        "Lei Bai",
        "Liqian Ma",
        "Zhiyong Wang",
        "Jianfei Cai",
        "Tien-Tsin Wong",
        "Huchuan Lu",
        "Xu Jia"
      ],
      "abstract": "Video diffusion models (VDMs) have advanced significantly in recent years,\nenabling the generation of highly realistic videos and drawing the attention of\nthe community in their potential as world simulators. However, despite their\ncapabilities, VDMs often fail to produce physically plausible videos due to an\ninherent lack of understanding of physics, resulting in incorrect dynamics and\nevent sequences. To address this limitation, we propose a novel two-stage\nimage-to-video generation framework that explicitly incorporates physics with\nvision and language informed physical prior. In the first stage, we employ a\nVision Language Model (VLM) as a coarse-grained motion planner, integrating\nchain-of-thought and physics-aware reasoning to predict a rough motion\ntrajectories/changes that approximate real-world physical dynamics while\nensuring the inter-frame consistency. In the second stage, we use the predicted\nmotion trajectories/changes to guide the video generation of a VDM. As the\npredicted motion trajectories/changes are rough, noise is added during\ninference to provide freedom to the VDM in generating motion with more fine\ndetails. Extensive experimental results demonstrate that our framework can\nproduce physically plausible motion, and comparative evaluations highlight the\nnotable superiority of our approach over existing methods. More video results\nare available on our Project Page:\nhttps://madaoer.github.io/projects/physically_plausible_video_generation.",
      "tldr_zh": "该论文提出 VLIPP 框架，一种两阶段图像到视频生成方法，旨在解决 Video Diffusion Models (VDMs) 在物理合理性方面的不足，通过整合 Vision Language Model (VLM) 和语言信息来指导物理动态生成。在第一阶段，VLM 作为粗粒度运动规划器，利用 chain-of-thought 和 physics-aware reasoning 预测粗略的运动轨迹，确保帧间一致性和真实物理效果；在第二阶段，这些轨迹指导 VDM 生成视频，同时添加噪声以实现更细致的细节。实验结果显示，VLIPP 生成的视频在物理可信度上显著优于现有方法，为更真实的视频模拟提供了新途径。",
      "categories": [
        "cs.CV",
        "cs.AI"
      ],
      "primary_category": "cs.CV",
      "comment": "18 pages, 11 figures",
      "pdf_url": "http://arxiv.org/pdf/2503.23368v3",
      "published_date": "2025-03-30 09:03:09 UTC",
      "updated_date": "2025-04-04 07:23:21 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-24T07:41:26.017483"
    },
    {
      "arxiv_id": "2503.23363v1",
      "title": "Large Language Models Are Better Logical Fallacy Reasoners with Counterargument, Explanation, and Goal-Aware Prompt Formulation",
      "title_zh": "翻译失败",
      "authors": [
        "Jiwon Jeong",
        "Hyeju Jang",
        "Hogun Park"
      ],
      "abstract": "The advancement of Large Language Models (LLMs) has greatly improved our\nability to process complex language. However, accurately detecting logical\nfallacies remains a significant challenge. This study presents a novel and\neffective prompt formulation approach for logical fallacy detection, applicable\nin both supervised (fine-tuned) and unsupervised (zero-shot) settings. Our\nmethod enriches input text incorporating implicit contextual information --\ncounterarguments, explanations, and goals -- which we query for validity within\nthe context of the argument. We then rank these queries based on confidence\nscores to inform classification. We evaluate our approach across multiple\ndatasets from 5 domains, covering 29 distinct fallacy types, using models from\nthe GPT and LLaMA series. The results show substantial improvements over\nstate-of-the-art models, with F1 score increases of up to 0.60 in zero-shot\nsettings and up to 0.45 in fine-tuned models. Extensive analyses further\nillustrate why and how our method excels.",
      "tldr_zh": "本研究提出了一种新型提示制定方法，以提升大语言模型（LLMs）在逻辑谬误检测方面的性能，该方法通过整合反驳（counterarguments）、解释（explanations）和目标（goals）来丰富输入文本，并在上下文中查询其有效性，然后基于置信度评分进行排名和分类，支持监督（fine-tuned）和无监督（zero-shot）设置。实验在涵盖5个领域的多个数据集上评估了29种逻辑谬误类型，使用GPT和LLaMA系列模型，结果显示F1分数在zero-shot设置中提升高达0.60，在fine-tuned设置中提升高达0.45，显著优于现有最先进模型。进一步分析揭示了该方法在为什么和如何提升性能方面的机制，为LLMs在复杂语言处理中的应用提供了新见解。",
      "categories": [
        "cs.AI",
        "cs.CL",
        "cs.LG"
      ],
      "primary_category": "cs.AI",
      "comment": "Accepted to NAACL 2025 Findings",
      "pdf_url": "http://arxiv.org/pdf/2503.23363v1",
      "published_date": "2025-03-30 08:41:09 UTC",
      "updated_date": "2025-03-30 08:41:09 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-24T07:41:37.574041"
    },
    {
      "arxiv_id": "2503.23362v2",
      "title": "Mixture of Routers",
      "title_zh": "翻译失败",
      "authors": [
        "Jia-Chen Zhang",
        "Yu-Jie Xiong",
        "Xi-He Qiu",
        "Chun-Ming Xia",
        "Fei Dai"
      ],
      "abstract": "Supervised fine-tuning (SFT) is a milestone in aligning large language models\nwith human instructions and adapting them to downstream tasks. In particular,\nLow-Rank Adaptation (LoRA) has gained widespread attention due to its parameter\nefficiency. However, its impact on improving the performance of large models\nremains limited. Recent studies suggest that combining LoRA with\nMixture-of-Experts (MoE) can significantly enhance fine-tuning performance. MoE\nadapts to the diversity and complexity of datasets by dynamically selecting the\nmost suitable experts, thereby improving task accuracy and efficiency. Despite\nimpressive results, recent studies reveal issues in the MoE routing mechanism,\nsuch as incorrect assignments and imbalanced expert allocation. Inspired by the\nprinciples of Redundancy and Fault Tolerance Theory. We innovatively integrate\nthe concept of Mixture of Experts into the routing mechanism and propose an\nefficient fine-tuning method called Mixture of Routers (MoR). It employs\nmultiple sub-routers for joint selection and uses a learnable main router to\ndetermine the weights of the sub-routers. The results show that MoR outperforms\nbaseline models on most tasks, achieving an average performance improvement of\n1%. MoR can serve as a plug-and-play, parameter-efficient fine-tuning method\nsuitable for a wide range of applications. Our code is available here:\nhttps://anonymous.4open.science/r/MoR-DFC6.",
      "tldr_zh": "该论文针对Supervised Fine-Tuning (SFT)中的性能限制，提出Mixture of Routers (MoR)方法，以解决Mixture-of-Experts (MoE)的routing机制问题，如分配错误和专家不平衡。MoR创新地将MoE概念融入routing中，使用多个sub-routers进行联合选择，并由一个learnable main router分配权重，从而提升模型的适应性和效率。实验结果显示，MoR在大多数任务上优于基线模型，平均性能提升1%，并作为一种plug-and-play、参数高效的fine-tuning方法，适用于广泛应用。",
      "categories": [
        "cs.CL",
        "cs.AI"
      ],
      "primary_category": "cs.CL",
      "comment": "10 pages,4 figures",
      "pdf_url": "http://arxiv.org/pdf/2503.23362v2",
      "published_date": "2025-03-30 08:39:09 UTC",
      "updated_date": "2025-05-16 14:18:06 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-24T07:41:51.136931"
    },
    {
      "arxiv_id": "2504.00035v1",
      "title": "MiZero: The Shadowy Defender Against Text Style Infringements",
      "title_zh": "翻译失败",
      "authors": [
        "Ziwei Zhang",
        "Juan Wen",
        "Wanli Peng",
        "Zhengxian Wu",
        "Yinghan Zhou",
        "Yiming Xue"
      ],
      "abstract": "In-Context Learning (ICL) and efficient fine-tuning methods significantly\nenhanced the efficiency of applying Large Language Models (LLMs) to downstream\ntasks. However, they also raise concerns about the imitation and infringement\nof personal creative data. Current methods for data copyright protection\nprimarily focuses on content security but lacks effectiveness in protecting the\ncopyrights of text styles. In this paper, we introduce a novel implicit\nzero-watermarking scheme, namely MiZero. This scheme establishes a precise\nwatermark domain to protect the copyrighted style, surpassing traditional\nwatermarking methods that distort the style characteristics. Specifically, we\nemploy LLMs to extract condensed-lists utilizing the designed instance\ndelimitation mechanism. These lists guide MiZero in generating the watermark.\nExtensive experiments demonstrate that MiZero effectively verifies text style\ncopyright ownership against AI imitation.",
      "tldr_zh": "这篇论文针对In-Context Learning (ICL)和高效微调方法导致的文本风格侵权问题，提出了一种新型隐式zero-watermarking scheme，名为MiZero。MiZero通过建立精确的水印域，使用Large Language Models (LLMs)提取浓缩列表并结合设计的instance delimitation mechanism生成水印，从而保护文本风格版权而不扭曲其特征。实验结果显示，MiZero有效地验证了文本风格的版权所有权，能够对抗AI模仿。",
      "categories": [
        "cs.CR",
        "cs.AI"
      ],
      "primary_category": "cs.CR",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2504.00035v1",
      "published_date": "2025-03-30 08:19:12 UTC",
      "updated_date": "2025-03-30 08:19:12 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-24T07:42:01.741844"
    },
    {
      "arxiv_id": "2503.23353v1",
      "title": "Object Isolated Attention for Consistent Story Visualization",
      "title_zh": "翻译失败",
      "authors": [
        "Xiangyang Luo",
        "Junhao Cheng",
        "Yifan Xie",
        "Xin Zhang",
        "Tao Feng",
        "Zhou Liu",
        "Fei Ma",
        "Fei Yu"
      ],
      "abstract": "Open-ended story visualization is a challenging task that involves generating\ncoherent image sequences from a given storyline. One of the main difficulties\nis maintaining character consistency while creating natural and contextually\nfitting scenes--an area where many existing methods struggle. In this paper, we\npropose an enhanced Transformer module that uses separate self attention and\ncross attention mechanisms, leveraging prior knowledge from pre-trained\ndiffusion models to ensure logical scene creation. The isolated self attention\nmechanism improves character consistency by refining attention maps to reduce\nfocus on irrelevant areas and highlight key features of the same character.\nMeanwhile, the isolated cross attention mechanism independently processes each\ncharacter's features, avoiding feature fusion and further strengthening\nconsistency. Notably, our method is training-free, allowing the continuous\ngeneration of new characters and storylines without re-tuning. Both qualitative\nand quantitative evaluations show that our approach outperforms current\nmethods, demonstrating its effectiveness.",
      "tldr_zh": "本文针对开放式故事可视化（Open-ended story visualization）中的人物一致性挑战，提出了一种增强的 Transformer 模块，使用隔离自注意力（isolated self attention）和隔离交叉注意力（isolated cross attention）机制。隔离自注意力通过精炼注意力图，减少对无关区域的关注并突出关键人物特征；隔离交叉注意力则独立处理每个人物的特征，避免特征融合，从而提升整体一致性。该方法利用预训练扩散模型（pre-trained diffusion models）的先验知识，且为训练-free设计，允许灵活生成新人物和故事线。定性和定量评估显示，该方法在表现上优于现有技术，证明了其有效性。",
      "categories": [
        "cs.CV",
        "cs.AI"
      ],
      "primary_category": "cs.CV",
      "comment": "6 pages, 4 figures",
      "pdf_url": "http://arxiv.org/pdf/2503.23353v1",
      "published_date": "2025-03-30 08:16:52 UTC",
      "updated_date": "2025-03-30 08:16:52 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-24T07:42:14.773797"
    },
    {
      "arxiv_id": "2503.23350v2",
      "title": "A Survey of WebAgents: Towards Next-Generation AI Agents for Web Automation with Large Foundation Models",
      "title_zh": "翻译失败",
      "authors": [
        "Liangbo Ning",
        "Ziran Liang",
        "Zhuohang Jiang",
        "Haohao Qu",
        "Yujuan Ding",
        "Wenqi Fan",
        "Xiao-yong Wei",
        "Shanru Lin",
        "Hui Liu",
        "Philip S. Yu",
        "Qing Li"
      ],
      "abstract": "With the advancement of web techniques, they have significantly\nrevolutionized various aspects of people's lives. Despite the importance of the\nweb, many tasks performed on it are repetitive and time-consuming, negatively\nimpacting overall quality of life. To efficiently handle these tedious daily\ntasks, one of the most promising approaches is to advance autonomous agents\nbased on Artificial Intelligence (AI) techniques, referred to as AI Agents, as\nthey can operate continuously without fatigue or performance degradation. In\nthe context of the web, leveraging AI Agents -- termed WebAgents -- to\nautomatically assist people in handling tedious daily tasks can dramatically\nenhance productivity and efficiency. Recently, Large Foundation Models (LFMs)\ncontaining billions of parameters have exhibited human-like language\nunderstanding and reasoning capabilities, showing proficiency in performing\nvarious complex tasks. This naturally raises the question: `Can LFMs be\nutilized to develop powerful AI Agents that automatically handle web tasks,\nproviding significant convenience to users?' To fully explore the potential of\nLFMs, extensive research has emerged on WebAgents designed to complete daily\nweb tasks according to user instructions, significantly enhancing the\nconvenience of daily human life. In this survey, we comprehensively review\nexisting research studies on WebAgents across three key aspects: architectures,\ntraining, and trustworthiness. Additionally, several promising directions for\nfuture research are explored to provide deeper insights.",
      "tldr_zh": "这篇调查论文探讨了WebAgents的发展前景，这些基于Large Foundation Models (LFMs)的AI代理旨在自动化处理日常网络任务，提高用户效率和生活质量。论文回顾了现有WebAgents的研究，包括架构设计、训练方法和可信度评估，强调LFMs的人类级语言理解和推理能力在处理重复性网络任务中的潜力。通过综合分析，论文总结了WebAgents的关键挑战与优势，并提出了未来研究方向，如进一步提升代理的自主性和可靠性。",
      "categories": [
        "cs.AI"
      ],
      "primary_category": "cs.AI",
      "comment": "Accepted by KDD 2025;",
      "pdf_url": "http://arxiv.org/pdf/2503.23350v2",
      "published_date": "2025-03-30 08:15:44 UTC",
      "updated_date": "2025-05-10 09:20:29 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-24T07:42:24.510697"
    },
    {
      "arxiv_id": "2503.23339v2",
      "title": "A Scalable Framework for Evaluating Health Language Models",
      "title_zh": "翻译失败",
      "authors": [
        "Neil Mallinar",
        "A. Ali Heydari",
        "Xin Liu",
        "Anthony Z. Faranesh",
        "Brent Winslow",
        "Nova Hammerquist",
        "Benjamin Graef",
        "Cathy Speed",
        "Mark Malhotra",
        "Shwetak Patel",
        "Javier L. Prieto",
        "Daniel McDuff",
        "Ahmed A. Metwally"
      ],
      "abstract": "Large language models (LLMs) have emerged as powerful tools for analyzing\ncomplex datasets. Recent studies demonstrate their potential to generate\nuseful, personalized responses when provided with patient-specific health\ninformation that encompasses lifestyle, biomarkers, and context. As LLM-driven\nhealth applications are increasingly adopted, rigorous and efficient one-sided\nevaluation methodologies are crucial to ensure response quality across multiple\ndimensions, including accuracy, personalization and safety. Current evaluation\npractices for open-ended text responses heavily rely on human experts. This\napproach introduces human factors and is often cost-prohibitive,\nlabor-intensive, and hinders scalability, especially in complex domains like\nhealthcare where response assessment necessitates domain expertise and\nconsiders multifaceted patient data. In this work, we introduce Adaptive\nPrecise Boolean rubrics: an evaluation framework that streamlines human and\nautomated evaluation of open-ended questions by identifying gaps in model\nresponses using a minimal set of targeted rubrics questions. Our approach is\nbased on recent work in more general evaluation settings that contrasts a\nsmaller set of complex evaluation targets with a larger set of more precise,\ngranular targets answerable with simple boolean responses. We validate this\napproach in metabolic health, a domain encompassing diabetes, cardiovascular\ndisease, and obesity. Our results demonstrate that Adaptive Precise Boolean\nrubrics yield higher inter-rater agreement among expert and non-expert human\nevaluators, and in automated assessments, compared to traditional Likert\nscales, while requiring approximately half the evaluation time of Likert-based\nmethods. This enhanced efficiency, particularly in automated evaluation and\nnon-expert contributions, paves the way for more extensive and cost-effective\nevaluation of LLMs in health.",
      "tldr_zh": "这篇论文提出了一种可扩展框架 Adaptive Precise Boolean rubrics，用于评估 Large Language Models (LLMs) 在健康领域的响应质量，包括准确性、个性化性和安全性，以解决传统依赖人类专家的评估方法存在的成本高和效率低问题。该框架通过使用一组最小化的精确布尔问题来识别模型响应的差距，从而简化人类和自动化评估过程，并在代谢健康领域（如糖尿病、心血管疾病和肥胖）进行了验证。实验结果显示，与传统的 Likert scales 相比，这种方法提高了评委间的一致性，并将评估时间减少约一半，促进了更高效、成本有效的 LLM 健康应用评估。",
      "categories": [
        "cs.AI",
        "cs.CL",
        "cs.HC"
      ],
      "primary_category": "cs.AI",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2503.23339v2",
      "published_date": "2025-03-30 06:47:57 UTC",
      "updated_date": "2025-04-01 21:17:55 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-24T07:42:38.735204"
    },
    {
      "arxiv_id": "2504.01034v1",
      "title": "Artificial intelligence and democracy: Towards digital authoritarianism or a democratic upgrade?",
      "title_zh": "人工智能与民主：走向数字威权主义还是民主升级？",
      "authors": [
        "Fereniki Panagopoulou"
      ],
      "abstract": "Do robots vote? Do machines make decisions instead of us? No, (at least not\nyet), but this is something that could happen. The impact of Artificial\nIntelligence (AI) on democracy is a complex issue that requires thorough\nresearch and careful regulation. At the most important level, that of the\nelectoral process, it is noted that it is not determined by the AI, but it is\ngreatly impacted by its multiple applications. New types of online campaigns,\ndriven by AI applications, are replacing traditional ones. The potential for\nmanipulating voters and indirectly influencing the electoral outcome should not\nbe underestimated. Certainly, instances of voter manipulation are not absent\nfrom traditional political campaigns, with the only difference being that\ndigital manipulation is often carried out without our knowledge, e.g. by\nmonitoring our behavior on social media. Nevertheless, we should not overlook\nthe positive impact that AI has in the upgrading of democratic institutions by\nproviding a forum for participation in decision-making. In this context, as a\nfirst step, we look into the potential jeopardization of democratic processes\nposed by the use of AI tools. Secondly, we consider the possibility of\nstrengthening democratic processes by using AI, as well as the democratization\nof AI itself through the possibilities it offers. And thirdly, the impact of AI\non the representative system is also discussed. The paper is concluded with\nrecommendations and conclusions.",
      "tldr_zh": "本论文探讨了Artificial Intelligence (AI) 对民主的影响，分析其可能导致数字威权主义（如通过AI驱动的在线竞选操纵选民和间接影响选举结果）或促进民主升级（如提供决策参与论坛和加强民主机构）。研究指出，AI的负面作用包括隐蔽的数字操纵，而正面作用则在于提升公众参与和AI自身的民主化进程。最终，论文评估了AI对代表制的冲击，并提出监管建议以平衡其风险和益处。",
      "categories": [
        "cs.CY",
        "cs.AI",
        "cs.LG"
      ],
      "primary_category": "cs.CY",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2504.01034v1",
      "published_date": "2025-03-30 06:43:54 UTC",
      "updated_date": "2025-03-30 06:43:54 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-24T07:42:49.492902"
    },
    {
      "arxiv_id": "2503.23333v1",
      "title": "Beyond Unimodal Boundaries: Generative Recommendation with Multimodal Semantics",
      "title_zh": "超越单模态边界：基于多模态语义的生成式推荐",
      "authors": [
        "Jing Zhu",
        "Mingxuan Ju",
        "Yozen Liu",
        "Danai Koutra",
        "Neil Shah",
        "Tong Zhao"
      ],
      "abstract": "Generative recommendation (GR) has become a powerful paradigm in\nrecommendation systems that implicitly links modality and semantics to item\nrepresentation, in contrast to previous methods that relied on non-semantic\nitem identifiers in autoregressive models. However, previous research has\npredominantly treated modalities in isolation, typically assuming item content\nis unimodal (usually text). We argue that this is a significant limitation\ngiven the rich, multimodal nature of real-world data and the potential\nsensitivity of GR models to modality choices and usage. Our work aims to\nexplore the critical problem of Multimodal Generative Recommendation (MGR),\nhighlighting the importance of modality choices in GR nframeworks. We reveal\nthat GR models are particularly sensitive to different modalities and examine\nthe challenges in achieving effective GR when multiple modalities are\navailable. By evaluating design strategies for effectively leveraging multiple\nmodalities, we identify key challenges and introduce MGR-LF++, an enhanced late\nfusion framework that employs contrastive modality alignment and special tokens\nto denote different modalities, achieving a performance improvement of over 20%\ncompared to single-modality alternatives.",
      "tldr_zh": "本文指出，生成式推荐 (GR) 系统虽能隐式链接模态和语义，但以往研究多局限于单一模态（如文本），忽略了真实世界数据的多模态特性，从而导致模型对模态选择高度敏感。论文探讨多模态生成式推荐 (MGR)，分析了整合多种模态的挑战，并提出 MGR-LF++ 框架，该框架采用对比模态对齐和特殊标记来实现晚融合，提升多模态信息的利用效率。实验结果显示，MGR-LF++ 相较单一模态方法性能提升超过 20%，为更全面的推荐系统设计提供了新路径。",
      "categories": [
        "cs.IR",
        "cs.AI",
        "cs.CL",
        "cs.CV"
      ],
      "primary_category": "cs.IR",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2503.23333v1",
      "published_date": "2025-03-30 06:24:43 UTC",
      "updated_date": "2025-03-30 06:24:43 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-24T07:43:02.619357"
    },
    {
      "arxiv_id": "2503.23329v1",
      "title": "A Multi-Agent Framework with Automated Decision Rule Optimization for Cross-Domain Misinformation Detection",
      "title_zh": "带有自动决策规则优化的多智能体框架，用于跨领域虚假信息检测",
      "authors": [
        "Hui Li",
        "Ante Wang",
        "kunquan li",
        "Zhihao Wang",
        "Liang Zhang",
        "Delai Qiu",
        "Qingsong Liu",
        "Jinsong Su"
      ],
      "abstract": "Misinformation spans various domains, but detection methods trained on\nspecific domains often perform poorly when applied to others. With the rapid\ndevelopment of Large Language Models (LLMs), researchers have begun to utilize\nLLMs for cross-domain misinformation detection. However, existing LLM-based\nmethods often fail to adequately analyze news in the target domain, limiting\ntheir detection capabilities. More importantly, these methods typically rely on\nmanually designed decision rules, which are limited by domain knowledge and\nexpert experience, thus limiting the generalizability of decision rules to\ndifferent domains. To address these issues, we propose a MultiAgent Framework\nfor cross-domain misinformation detection with Automated Decision Rule\nOptimization (MARO). Under this framework, we first employs multiple expert\nagents to analyze target-domain news. Subsequently, we introduce a\nquestion-reflection mechanism that guides expert agents to facilitate\nhigherquality analysis. Furthermore, we propose a decision rule optimization\napproach based on carefully-designed cross-domain validation tasks to\niteratively enhance the effectiveness of decision rules in different domains.\nExperimental results and in-depth analysis on commonlyused datasets demonstrate\nthat MARO achieves significant improvements over existing methods.",
      "tldr_zh": "该研究针对跨领域错误信息检测的挑战，提出了一种Multi-Agent Framework with Automated Decision Rule Optimization (MARO)，以解决现有Large Language Models (LLMs)方法在分析目标领域新闻时存在的局限性，以及依赖手动决策规则导致的泛化性问题。MARO框架通过部署多个专家代理进行新闻分析，并引入question-reflection机制来提升分析质量，同时采用基于跨领域验证任务的优化方法来迭代改进决策规则。实验结果显示，该框架在常用数据集上显著优于现有方法，证明了其在提升跨领域检测性能方面的有效性。",
      "categories": [
        "cs.AI"
      ],
      "primary_category": "cs.AI",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2503.23329v1",
      "published_date": "2025-03-30 06:08:33 UTC",
      "updated_date": "2025-03-30 06:08:33 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-24T07:43:13.906090"
    },
    {
      "arxiv_id": "2503.23326v2",
      "title": "Exploring Explainable Multi-player MCTS-minimax Hybrids in Board Game Using Process Mining",
      "title_zh": "翻译失败",
      "authors": [
        "Yiyu Qian",
        "Tim Miller",
        "Zheng Qian",
        "Liyuan Zhao"
      ],
      "abstract": "Monte-Carlo Tree Search (MCTS) is a family of sampling-based search\nalgorithms widely used for online planning in sequential decision-making\ndomains and at the heart of many recent advances in artificial intelligence.\nUnderstanding the behavior of MCTS agents is difficult for developers and users\ndue to the frequently large and complex search trees that result from the\nsimulation of many possible futures, their evaluations, and their\nrelationships. This paper presents our ongoing investigation into potential\nexplanations for the decision-making and behavior of MCTS. A weakness of MCTS\nis that it constructs a highly selective tree and, as a result, can miss\ncrucial moves and fall into tactical traps. Full-width minimax search\nconstitutes the solution. We integrate shallow minimax search into the rollout\nphase of multi-player MCTS and use process mining technique to explain agents'\nstrategies in 3v3 checkers.",
      "tldr_zh": "这篇论文探讨了如何使用过程挖掘技术来解释多玩家MCTS（Monte-Carlo Tree Search）和minimax混合算法在棋盘游戏中的决策行为，以解决MCTS构建高度选择性搜索树而可能错过关键动作的弱点。研究者将浅层minimax搜索整合到MCTS的rollout阶段，增强算法在多玩家环境下的策略分析。实验在3v3跳棋游戏中验证了这一方法，提高了代理行为的透明度和理解性。",
      "categories": [
        "cs.AI"
      ],
      "primary_category": "cs.AI",
      "comment": "38 pages, AAAI 2025 PRL",
      "pdf_url": "http://arxiv.org/pdf/2503.23326v2",
      "published_date": "2025-03-30 05:48:53 UTC",
      "updated_date": "2025-05-20 14:09:58 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-24T07:43:26.036472"
    },
    {
      "arxiv_id": "2503.23315v1",
      "title": "AI Agents in Engineering Design: A Multi-Agent Framework for Aesthetic and Aerodynamic Car Design",
      "title_zh": "翻译失败",
      "authors": [
        "Mohamed Elrefaie",
        "Janet Qian",
        "Raina Wu",
        "Qian Chen",
        "Angela Dai",
        "Faez Ahmed"
      ],
      "abstract": "We introduce the concept of \"Design Agents\" for engineering applications,\nparticularly focusing on the automotive design process, while emphasizing that\nour approach can be readily extended to other engineering and design domains.\nOur framework integrates AI-driven design agents into the traditional\nengineering workflow, demonstrating how these specialized computational agents\ninteract seamlessly with engineers and designers to augment creativity, enhance\nefficiency, and significantly accelerate the overall design cycle. By\nautomating and streamlining tasks traditionally performed manually, such as\nconceptual sketching, styling enhancements, 3D shape retrieval and generative\nmodeling, computational fluid dynamics (CFD) meshing, and aerodynamic\nsimulations, our approach reduces certain aspects of the conventional workflow\nfrom weeks and days down to minutes. These agents leverage state-of-the-art\nvision-language models (VLMs), large language models (LLMs), and geometric deep\nlearning techniques, providing rapid iteration and comprehensive design\nexploration capabilities. We ground our methodology in industry-standard\nbenchmarks, encompassing a wide variety of conventional automotive designs, and\nutilize high-fidelity aerodynamic simulations to ensure practical and\napplicable outcomes. Furthermore, we present design agents that can swiftly and\naccurately predict simulation outcomes, empowering engineers and designers to\nengage in more informed design optimization and exploration. This research\nunderscores the transformative potential of integrating advanced generative AI\ntechniques into complex engineering tasks, paving the way for broader adoption\nand innovation across multiple engineering disciplines.",
      "tldr_zh": "这篇论文引入了“Design Agents”的概念，提出一个多代理框架，用于汽车设计领域，专注于美学和空气动力学优化，同时可扩展到其他工程领域。该框架将 AI 驱动的代理集成到传统工程流程中，利用 VLMs、LLMs 和几何深度学习技术自动化任务，如概念草图、3D 形状检索、CFD 网格和空气动力学模拟，从而将设计周期从数周或数天缩短到几分钟。实验基于行业标准基准和高保真模拟，展示了代理在预测模拟结果和提升设计探索方面的能力，最终强调了生成 AI 在工程创新中的变革潜力。",
      "categories": [
        "cs.AI",
        "cs.CE",
        "cs.LG"
      ],
      "primary_category": "cs.AI",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2503.23315v1",
      "published_date": "2025-03-30 04:57:17 UTC",
      "updated_date": "2025-03-30 04:57:17 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-24T07:43:38.692036"
    },
    {
      "arxiv_id": "2503.23314v1",
      "title": "SPIO: Ensemble and Selective Strategies via LLM-Based Multi-Agent Planning in Automated Data Science",
      "title_zh": "翻译失败",
      "authors": [
        "Wonduk Seo",
        "Juhyeon Lee",
        "Yi Bu"
      ],
      "abstract": "Large Language Models (LLMs) have revolutionized automated data analytics and\nmachine learning by enabling dynamic reasoning and adaptability. While recent\napproaches have advanced multi-stage pipelines through multi-agent systems,\nthey typically rely on rigid, single-path workflows that limit the exploration\nand integration of diverse strategies, often resulting in suboptimal\npredictions. To address these challenges, we propose SPIO (Sequential Plan\nIntegration and Optimization), a novel framework that leverages LLM-driven\ndecision-making to orchestrate multi-agent planning across four key modules:\ndata preprocessing, feature engineering, modeling, and hyperparameter tuning.\nIn each module, dedicated planning agents independently generate candidate\nstrategies that cascade into subsequent stages, fostering comprehensive\nexploration. A plan optimization agent refines these strategies by suggesting\nseveral optimized plans. We further introduce two variants: SPIO-S, which\nselects a single best solution path as determined by the LLM, and SPIO-E, which\nselects the top k candidate plans and ensembles them to maximize predictive\nperformance. Extensive experiments on Kaggle and OpenML datasets demonstrate\nthat SPIO significantly outperforms state-of-the-art methods, providing a\nrobust and scalable solution for automated data science task.",
      "tldr_zh": "本研究提出SPIO框架，利用LLM驱动的多代理规划来解决自动化数据科学中刚性工作流导致的策略探索不足问题。SPIO包括四个关键模块——数据预处理、特征工程、建模和超参数调整——其中专用规划代理生成候选策略，并由优化代理精炼这些策略。框架提供两种变体：SPIO-S选择LLM确定的最佳单一路径，SPIO-E则集成顶尖候选计划以提升预测性能。在Kaggle和OpenML数据集上的广泛实验显示，SPIO显著优于现有方法，提供了一个鲁棒且可扩展的自动化数据科学解决方案。",
      "categories": [
        "cs.AI",
        "cs.CL",
        "cs.LG",
        "cs.MA"
      ],
      "primary_category": "cs.AI",
      "comment": "Under Review",
      "pdf_url": "http://arxiv.org/pdf/2503.23314v1",
      "published_date": "2025-03-30 04:45:32 UTC",
      "updated_date": "2025-03-30 04:45:32 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-24T07:43:50.745199"
    },
    {
      "arxiv_id": "2503.23312v1",
      "title": "LaViC: Adapting Large Vision-Language Models to Visually-Aware Conversational Recommendation",
      "title_zh": "翻译失败",
      "authors": [
        "Hyunsik Jeon",
        "Satoshi Koide",
        "Yu Wang",
        "Zhankui He",
        "Julian McAuley"
      ],
      "abstract": "Conversational recommender systems engage users in dialogues to refine their\nneeds and provide more personalized suggestions. Although textual information\nsuffices for many domains, visually driven categories such as fashion or home\ndecor potentially require detailed visual information related to color, style,\nor design. To address this challenge, we propose LaViC (Large Vision-Language\nConversational Recommendation Framework), a novel approach that integrates\ncompact image representations into dialogue-based recommendation systems. LaViC\nleverages a large vision-language model in a two-stage process: (1) visual\nknowledge self-distillation, which condenses product images from hundreds of\ntokens into a small set of visual tokens in a self-distillation manner,\nsignificantly reducing computational overhead, and (2) recommendation prompt\ntuning, which enables the model to incorporate both dialogue context and\ndistilled visual tokens, providing a unified mechanism for capturing textual\nand visual features. To support rigorous evaluation of visually-aware\nconversational recommendation, we construct a new dataset by aligning Reddit\nconversations with Amazon product listings across multiple visually oriented\ncategories (e.g., fashion, beauty, and home). This dataset covers realistic\nuser queries and product appearances in domains where visual details are\ncrucial. Extensive experiments demonstrate that LaViC significantly outperforms\ntext-only conversational recommendation methods and open-source vision-language\nbaselines. Moreover, LaViC achieves competitive or superior accuracy compared\nto prominent proprietary baselines (e.g., GPT-3.5-turbo, GPT-4o-mini, and\nGPT-4o), demonstrating the necessity of explicitly using visual data for\ncapturing product attributes and showing the effectiveness of our\nvision-language integration. Our code and dataset are available at\nhttps://github.com/jeon185/LaViC.",
      "tldr_zh": "这篇论文提出了 LaViC 框架，将大型视觉语言模型（Large Vision-Language Models）适应于视觉感知的对话推荐系统，以解决传统文本依赖方法在时尚、美妆等视觉驱动领域（如颜色、风格）的局限性。LaViC 通过两阶段过程实现：（1）视觉知识自蒸馏，将产品图像从数百个标记浓缩成少量视觉标记，减少计算开销；（2）推荐提示调整，融合对话上下文和蒸馏视觉标记，统一捕捉文本与视觉特征。为评估该框架，作者构建了一个新数据集，将 Reddit 对话与 Amazon 产品列表对齐。实验结果表明，LaViC 显著优于纯文本方法和开源视觉语言基线，甚至与 GPT-3.5-turbo、GPT-4o-mini 和 GPT-4o 等专有模型相当或更优，突显了显式使用视觉数据的必要性和框架的有效性。",
      "categories": [
        "cs.AI",
        "cs.CV"
      ],
      "primary_category": "cs.AI",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2503.23312v1",
      "published_date": "2025-03-30 04:44:13 UTC",
      "updated_date": "2025-03-30 04:44:13 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-24T07:44:03.460837"
    },
    {
      "arxiv_id": "2503.23303v1",
      "title": "SalesRLAgent: A Reinforcement Learning Approach for Real-Time Sales Conversion Prediction and Optimization",
      "title_zh": "SalesRLAgent：一种强化学习方法用于实时销售转化预测和优化",
      "authors": [
        "Nandakishor M"
      ],
      "abstract": "Current approaches to sales conversation analysis and conversion prediction\ntypically rely on Large Language Models (LLMs) combined with basic retrieval\naugmented generation (RAG). These systems, while capable of answering\nquestions, fail to accurately predict conversion probability or provide\nstrategic guidance in real time. In this paper, we present SalesRLAgent, a\nnovel framework leveraging specialized reinforcement learning to predict\nconversion probability throughout sales conversations. Unlike systems from\nKapa.ai, Mendable, Inkeep, and others that primarily use off-the-shelf LLMs for\ncontent generation, our approach treats conversion prediction as a sequential\ndecision problem, training on synthetic data generated using GPT-4O to develop\na specialized probability estimation model. Our system incorporates Azure\nOpenAI embeddings (3072 dimensions), turn-by-turn state tracking, and\nmeta-learning capabilities to understand its own knowledge boundaries.\nEvaluations demonstrate that SalesRLAgent achieves 96.7% accuracy in conversion\nprediction, outperforming LLM-only approaches by 34.7% while offering\nsignificantly faster inference (85ms vs 3450ms for GPT-4). Furthermore,\nintegration with existing sales platforms shows a 43.2% increase in conversion\nrates when representatives utilize our system's real-time guidance.\nSalesRLAgent represents a fundamental shift from content generation to\nstrategic sales intelligence, providing moment-by-moment conversion probability\nestimation with actionable insights for sales professionals.",
      "tldr_zh": "本文提出 SalesRLAgent，一种基于 Reinforcement Learning 的框架，用于实时销售对话中的转换概率预测和优化，与传统依赖 Large Language Models (LLMs) 和基本 Retrieval Augmented Generation (RAG) 的系统相比，它将转换预测视为顺序决策问题，并使用 GPT-4O 生成的合成数据进行训练。框架整合了 Azure OpenAI embeddings (3072 维度)、逐轮状态跟踪和 meta-learning 能力，以提供更准确的概率估计和实时指导。实验评估显示，SalesRLAgent 在转换预测中达到 96.7% 的准确率，比 LLM-only 方法高出 34.7%，并将推理时间缩短至 85ms。实际应用中，该系统与销售平台整合后，提高了 43.2% 的转换率，推动了从内容生成向战略销售智能的转变。",
      "categories": [
        "cs.LG",
        "cs.AI"
      ],
      "primary_category": "cs.LG",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2503.23303v1",
      "published_date": "2025-03-30 03:56:26 UTC",
      "updated_date": "2025-03-30 03:56:26 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-24T07:44:16.475560"
    },
    {
      "arxiv_id": "2503.23299v1",
      "title": "GRASP: Municipal Budget AI Chatbots for Enhancing Civic Engagement",
      "title_zh": "GRASP：用于增强公民参与的市政预算 AI 聊天机器人",
      "authors": [
        "Jerry Xu",
        "Justin Wang",
        "Joley Leung",
        "Jasmine Gu"
      ],
      "abstract": "There are a growing number of AI applications, but none tailored specifically\nto help residents answer their questions about municipal budget, a topic most\nare interested in but few have a solid comprehension of. In this research\npaper, we propose GRASP, a custom AI chatbot framework which stands for\nGeneration with Retrieval and Action System for Prompts. GRASP provides more\ntruthful and grounded responses to user budget queries than traditional\ninformation retrieval systems like general Large Language Models (LLMs) or web\nsearches. These improvements come from the novel combination of a\nRetrieval-Augmented Generation (RAG) framework (\"Generation with Retrieval\")\nand an agentic workflow (\"Action System\"), as well as prompt engineering\ntechniques, the incorporation of municipal budget domain knowledge, and\ncollaboration with local town officials to ensure response truthfulness. During\ntesting, we found that our GRASP chatbot provided precise and accurate\nresponses for local municipal budget queries 78% of the time, while GPT-4o and\nGemini were only accurate 60% and 35% of the time, respectively. GRASP chatbots\ngreatly reduce the time and effort needed for the general public to get an\nintuitive and correct understanding of their town's budget, thus fostering\ngreater communal discourse, improving government transparency, and allowing\ncitizens to make more informed decisions.",
      "tldr_zh": "本研究提出 GRASP 框架，这是一个名为 Generation with Retrieval and Action System for Prompts 的自定义 AI 聊天机器人，旨在帮助居民更准确地回答市政预算相关问题，从而提升公民参与。GRASP 通过结合 Retrieval-Augmented Generation (RAG) 框架、agentic workflow、prompt engineering 技术，以及融入市政预算领域知识和与当地官员的合作，确保响应更真实和可靠。实验结果显示，GRASP 在处理本地市政预算查询时准确率达 78%，显著高于 GPT-4o 的 60% 和 Gemini 的 35%。该框架减少了公众获取信息的努力，促进政府透明度和社区对话，推动更知情的公民决策。",
      "categories": [
        "cs.AI"
      ],
      "primary_category": "cs.AI",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2503.23299v1",
      "published_date": "2025-03-30 03:46:06 UTC",
      "updated_date": "2025-03-30 03:46:06 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-24T07:44:27.861490"
    },
    {
      "arxiv_id": "2503.23288v1",
      "title": "Two Heads Are Better than One: Model-Weight and Latent-Space Analysis for Federated Learning on Non-iid Data against Poisoning Attacks",
      "title_zh": "翻译失败",
      "authors": [
        "Xingyu Lyu",
        "Ning Wang",
        "Yang Xiao",
        "Shixiong Li",
        "Tao Li",
        "Danjue Chen",
        "Yimin Chen"
      ],
      "abstract": "Federated Learning is a popular paradigm that enables remote clients to\njointly train a global model without sharing their raw data. However, FL has\nbeen shown to be vulnerable towards model poisoning attacks due to its\ndistributed nature. Particularly, attackers acting as participants can upload\narbitrary model updates that effectively compromise the global model of FL.\nWhile extensive research has been focusing on fighting against these attacks,\nwe find that most of them assume data at remote clients are under iid while in\npractice they are inevitably non-iid. Our benchmark evaluations reveal that\nexisting defenses generally fail to live up to their reputation when applied to\nvarious non-iid scenarios. In this paper, we propose a novel approach,\nGeminiGuard, that aims to address such a significant gap. We design GeminiGuard\nto be lightweight, versatile, and unsupervised so that it aligns well with the\npractical requirements of deploying such defenses. The key challenge from\nnon-iids is that they make benign model updates look more similar to malicious\nones. GeminiGuard is mainly built on two fundamental observations: (1) existing\ndefenses based on either model-weight analysis or latent-space analysis face\nlimitations in covering different MPAs and non-iid scenarios, and (2)\nmodel-weight and latent-space analysis are sufficiently different yet\npotentially complementary methods as MPA defenses. We hence incorporate a novel\nmodel-weight analysis component as well as a custom latent-space analysis\ncomponent in GeminiGuard, aiming to further enhance its defense performance. We\nconduct extensive experiments to evaluate our defense across various settings,\ndemonstrating its effectiveness in countering multiple types of untargeted and\ntargeted MPAs, including adaptive ones. Our comprehensive evaluations show that\nGeminiGuard consistently outperforms SOTA defenses under various settings.",
      "tldr_zh": "这篇论文探讨了Federated Learning在非独立同分布(non-iid)数据上的脆弱性，特别是针对模型投毒攻击(model poisoning attacks)的防御问题。现有防御方法假设数据为iid，导致在实际非iid场景中表现不佳。论文提出了一种新型轻量级、无监督防御框架GeminiGuard，通过结合模型权重分析(model-weight analysis)和自定义潜在空间分析(latent-space analysis)组件，利用二者的互补性来提升防御效果。实验结果显示，GeminiGuard在多种无针对性(untargeted)和有针对性(targeted)MPAs攻击下，包括自适应攻击，均优于现有最先进(SOTA)防御方法。",
      "categories": [
        "cs.LG",
        "cs.AI"
      ],
      "primary_category": "cs.LG",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2503.23288v1",
      "published_date": "2025-03-30 02:56:05 UTC",
      "updated_date": "2025-03-30 02:56:05 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-24T07:44:40.046994"
    },
    {
      "arxiv_id": "2503.23281v1",
      "title": "Extracting Patient History from Clinical Text: A Comparative Study of Clinical Large Language Models",
      "title_zh": "翻译失败",
      "authors": [
        "Hieu Nghiem",
        "Tuan-Dung Le",
        "Suhao Chen",
        "Thanh Thieu",
        "Andrew Gin",
        "Ellie Phuong Nguyen",
        "Dursun Delen",
        "Johnson Thomas",
        "Jivan Lamichhane",
        "Zhuqi Miao"
      ],
      "abstract": "Extracting medical history entities (MHEs) related to a patient's chief\ncomplaint (CC), history of present illness (HPI), and past, family, and social\nhistory (PFSH) helps structure free-text clinical notes into standardized EHRs,\nstreamlining downstream tasks like continuity of care, medical coding, and\nquality metrics. Fine-tuned clinical large language models (cLLMs) can assist\nin this process while ensuring the protection of sensitive data via on-premises\ndeployment. This study evaluates the performance of cLLMs in recognizing\nCC/HPI/PFSH-related MHEs and examines how note characteristics impact model\naccuracy. We annotated 1,449 MHEs across 61 outpatient-related clinical notes\nfrom the MTSamples repository. To recognize these entities, we fine-tuned seven\nstate-of-the-art cLLMs. Additionally, we assessed the models' performance when\nenhanced by integrating, problems, tests, treatments, and other basic medical\nentities (BMEs). We compared the performance of these models against GPT-4o in\na zero-shot setting. To further understand the textual characteristics\naffecting model accuracy, we conducted an error analysis focused on note\nlength, entity length, and segmentation. The cLLMs showed potential in reducing\nthe time required for extracting MHEs by over 20%. However, detecting many\ntypes of MHEs remained challenging due to their polysemous nature and the\nfrequent involvement of non-medical vocabulary. Fine-tuned GatorTron and\nGatorTronS, two of the most extensively trained cLLMs, demonstrated the highest\nperformance. Integrating pre-identified BME information improved model\nperformance for certain entities. Regarding the impact of textual\ncharacteristics on model performance, we found that longer entities were harder\nto identify, note length did not correlate with a higher error rate, and\nwell-organized segments with headings are beneficial for the extraction.",
      "tldr_zh": "这篇论文比较了临床大语言模型(cLLMs)在提取患者病史实体(MHEs)方面的性能，包括首席抱怨(CC)、现病史(HPI)和既往、家族、社会史(PFSH)，以结构化临床笔记并支持后续医疗任务。研究者微调了七个cLLMs模型，并与GPT-4o进行零样本比较，实验基于标注的1,449个MHEs，发现GatorTron和GatorTronS表现出色，能将提取时间减少超过20%，而整合基本医疗实体(BMEs)进一步提升了某些实体的识别准确性。分析显示，较长实体更难检测，笔记长度与错误率无关，但有标题的段落有助于提取效果。",
      "categories": [
        "cs.CL",
        "cs.AI",
        "cs.LG"
      ],
      "primary_category": "cs.CL",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2503.23281v1",
      "published_date": "2025-03-30 02:00:56 UTC",
      "updated_date": "2025-03-30 02:00:56 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-24T07:44:52.950312"
    },
    {
      "arxiv_id": "2503.23278v2",
      "title": "Model Context Protocol (MCP): Landscape, Security Threats, and Future Research Directions",
      "title_zh": "Model Context Protocol (MCP)：现状、安全威胁和未来研究方向",
      "authors": [
        "Xinyi Hou",
        "Yanjie Zhao",
        "Shenao Wang",
        "Haoyu Wang"
      ],
      "abstract": "The Model Context Protocol (MCP) is a standardized interface designed to\nenable seamless interaction between AI models and external tools and resources,\nbreaking down data silos and facilitating interoperability across diverse\nsystems. This paper provides a comprehensive overview of MCP, focusing on its\ncore components, workflow, and the lifecycle of MCP servers, which consists of\nthree key phases: creation, operation, and update. We analyze the security and\nprivacy risks associated with each phase and propose strategies to mitigate\npotential threats. The paper also examines the current MCP landscape, including\nits adoption by industry leaders and various use cases, as well as the tools\nand platforms supporting its integration. We explore future directions for MCP,\nhighlighting the challenges and opportunities that will influence its adoption\nand evolution within the broader AI ecosystem. Finally, we offer\nrecommendations for MCP stakeholders to ensure its secure and sustainable\ndevelopment as the AI landscape continues to evolve.",
      "tldr_zh": "这篇论文介绍了 Model Context Protocol (MCP)，一个标准化接口，用于实现 AI 模型与外部工具和资源的无缝交互，从而打破数据孤岛并提升系统互操作性。论文详细概述了 MCP 的核心组件、工作流及其生命周期（包括创建、操作和更新阶段），并分析了每个阶段的安全和隐私风险，同时提出缓解策略。最终，论文探讨了 MCP 的当前景观、行业采用情况以及未来研究方向，强调了挑战与机会，并为利益相关者提供确保其安全可持续发展的建议。",
      "categories": [
        "cs.CR",
        "cs.AI"
      ],
      "primary_category": "cs.CR",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2503.23278v2",
      "published_date": "2025-03-30 01:58:22 UTC",
      "updated_date": "2025-04-06 13:32:33 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-24T07:45:04.000164"
    },
    {
      "arxiv_id": "2503.23275v1",
      "title": "Improved Ear Verification with Vision Transformers and Overlapping Patches",
      "title_zh": "翻译失败",
      "authors": [
        "Deeksha Arun",
        "Kagan Ozturk",
        "Kevin W. Bowyer",
        "Patrick Flynn"
      ],
      "abstract": "Ear recognition has emerged as a promising biometric modality due to the\nrelative stability in appearance during adulthood. Although Vision Transformers\n(ViTs) have been widely used in image recognition tasks, their efficiency in\near recognition has been hampered by a lack of attention to overlapping\npatches, which is crucial for capturing intricate ear features. In this study,\nwe evaluate ViT-Tiny (ViT-T), ViT-Small (ViT-S), ViT-Base (ViT-B) and ViT-Large\n(ViT-L) configurations on a diverse set of datasets (OPIB, AWE, WPUT, and\nEarVN1.0), using an overlapping patch selection strategy. Results demonstrate\nthe critical importance of overlapping patches, yielding superior performance\nin 44 of 48 experiments in a structured study. Moreover, upon comparing the\nresults of the overlapping patches with the non-overlapping configurations, the\nincrease is significant, reaching up to 10% for the EarVN1.0 dataset. In terms\nof model performance, the ViT-T model consistently outperformed the ViT-S,\nViT-B, and ViT-L models on the AWE, WPUT, and EarVN1.0 datasets. The highest\nscores were achieved in a configuration with a patch size of 28x28 and a stride\nof 14 pixels. This patch-stride configuration represents 25% of the normalized\nimage area (112x112 pixels) for the patch size and 12.5% of the row or column\nsize for the stride. This study confirms that transformer architectures with\noverlapping patch selection can serve as an efficient and high-performing\noption for ear-based biometric recognition tasks in verification scenarios.",
      "tldr_zh": "本文研究了使用 Vision Transformers (ViTs) 改进耳部验证的性能，重点强调了重叠补丁在捕捉耳部精细特征中的关键作用。研究者评估了 ViT-Tiny (ViT-T)、ViT-Small (ViT-S)、ViT-Base (ViT-B) 和 ViT-Large (ViT-L) 模型，在 OPIB、AWE、WPUT 和 EarVN1.0 数据集上采用重叠补丁策略进行实验。结果显示，重叠补丁在 48 个实验中占优于 44 个，与非重叠配置相比，性能提升显著，最多达 10%（特别是在 EarVN1.0 数据集上）。此外，ViT-T 模型在 AWE、WPUT 和 EarVN1.0 数据集上 consistently 优于其他模型，最佳配置为补丁大小 28x28 和步幅 14 像素，证明了这种方法在耳部生物特征识别任务中的高效性。",
      "categories": [
        "cs.CV",
        "cs.AI"
      ],
      "primary_category": "cs.CV",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2503.23275v1",
      "published_date": "2025-03-30 01:50:21 UTC",
      "updated_date": "2025-03-30 01:50:21 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-24T07:45:18.339141"
    },
    {
      "arxiv_id": "2503.23271v1",
      "title": "Learning Coordinated Bimanual Manipulation Policies using State Diffusion and Inverse Dynamics Models",
      "title_zh": "利用状态扩散和逆动力学模型学习协调双臂操作策略",
      "authors": [
        "Haonan Chen",
        "Jiaming Xu",
        "Lily Sheng",
        "Tianchen Ji",
        "Shuijing Liu",
        "Yunzhu Li",
        "Katherine Driggs-Campbell"
      ],
      "abstract": "When performing tasks like laundry, humans naturally coordinate both hands to\nmanipulate objects and anticipate how their actions will change the state of\nthe clothes. However, achieving such coordination in robotics remains\nchallenging due to the need to model object movement, predict future states,\nand generate precise bimanual actions. In this work, we address these\nchallenges by infusing the predictive nature of human manipulation strategies\ninto robot imitation learning. Specifically, we disentangle task-related state\ntransitions from agent-specific inverse dynamics modeling to enable effective\nbimanual coordination. Using a demonstration dataset, we train a diffusion\nmodel to predict future states given historical observations, envisioning how\nthe scene evolves. Then, we use an inverse dynamics model to compute robot\nactions that achieve the predicted states. Our key insight is that modeling\nobject movement can help learning policies for bimanual coordination\nmanipulation tasks. Evaluating our framework across diverse simulation and\nreal-world manipulation setups, including multimodal goal configurations,\nbimanual manipulation, deformable objects, and multi-object setups, we find\nthat it consistently outperforms state-of-the-art state-to-action mapping\npolicies. Our method demonstrates a remarkable capacity to navigate multimodal\ngoal configurations and action distributions, maintain stability across\ndifferent control modes, and synthesize a broader range of behaviors than those\npresent in the demonstration dataset.",
      "tldr_zh": "本文提出了一种学习协调双臂操纵策略的方法，通过状态扩散模型（state diffusion model）预测未来状态，并结合逆向动态模型（inverse dynamics model）计算机器人动作，以实现有效的双臂协调和物体运动建模。研究从演示数据集入手，将任务相关的状态转换与代理特定建模分离，解决了机器人模仿学习中的挑战。实验结果显示，该框架在模拟和真实世界设置中，包括多模态目标配置、可变形物体和多物体任务上，显著优于现有状态到动作映射策略，能处理复杂场景并生成超出演示数据的行为范围。",
      "categories": [
        "cs.RO",
        "cs.AI"
      ],
      "primary_category": "cs.RO",
      "comment": "Project Page: https://haonan16.github.io/coord_bimanual_page/. 12\n  pages, 12 figures, Accepted at ICRA 2025",
      "pdf_url": "http://arxiv.org/pdf/2503.23271v1",
      "published_date": "2025-03-30 01:25:35 UTC",
      "updated_date": "2025-03-30 01:25:35 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-24T07:45:28.184933"
    },
    {
      "arxiv_id": "2503.23270v1",
      "title": "Localized Graph-Based Neural Dynamics Models for Terrain Manipulation",
      "title_zh": "局域化的基于图的神经动力学模型用于地形操控",
      "authors": [
        "Chaoqi Liu",
        "Yunzhu Li",
        "Kris Hauser"
      ],
      "abstract": "Predictive models can be particularly helpful for robots to effectively\nmanipulate terrains in construction sites and extraterrestrial surfaces.\nHowever, terrain state representations become extremely high-dimensional\nespecially to capture fine-resolution details and when depth is unknown or\nunbounded. This paper introduces a learning-based approach for terrain dynamics\nmodeling and manipulation, leveraging the Graph-based Neural Dynamics (GBND)\nframework to represent terrain deformation as motion of a graph of particles.\nBased on the principle that the moving portion of a terrain is usually\nlocalized, our approach builds a large terrain graph (potentially millions of\nparticles) but only identifies a very small active subgraph (hundreds of\nparticles) for predicting the outcomes of robot-terrain interaction. To\nminimize the size of the active subgraph we introduce a learning-based approach\nthat identifies a small region of interest (RoI) based on the robot's control\ninputs and the current scene. We also introduce a novel domain boundary feature\nencoding that allows GBNDs to perform accurate dynamics prediction in the RoI\ninterior while avoiding particle penetration through RoI boundaries. Our\nproposed method is both orders of magnitude faster than naive GBND and it\nachieves better overall prediction accuracy. We further evaluated our framework\non excavation and shaping tasks on terrain with different granularity.",
      "tldr_zh": "这篇论文提出了一种基于 Graph-based Neural Dynamics (GBND) 的方法，用于机器人高效操纵地形，如建筑工地或外星表面，以应对高维地形表示的挑战。方法将地形变形建模为粒子图的运动，但通过学习-based 区域识别 (RoI) 技术，仅激活一个小型活跃子图 (数百粒子) 来预测机器人-地形互动，同时引入领域边界特征编码以防止粒子穿透边界。结果显示，该方法比传统 GBND 快几个数量级，并实现了更高的预测准确性，在不同粒度的挖掘和塑造任务中表现出色。",
      "categories": [
        "cs.RO",
        "cs.AI",
        "cs.LG"
      ],
      "primary_category": "cs.RO",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2503.23270v1",
      "published_date": "2025-03-30 01:24:10 UTC",
      "updated_date": "2025-03-30 01:24:10 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-24T07:45:40.032125"
    }
  ],
  "raw_papers_fetched": true,
  "papers_count": 67,
  "processed_papers_count": 67,
  "failed_papers_count": 0,
  "summary_generated": true,
  "daily_data_saved": true,
  "last_update": "2025-05-24T07:45:58.627719"
}