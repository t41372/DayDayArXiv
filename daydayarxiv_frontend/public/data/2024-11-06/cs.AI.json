{
  "date": "2024-11-06",
  "category": "cs.AI",
  "summary": "欢迎来到 UTC 时间 2024-11-06 的 arXiv 中文 TLDR 快报！今天 arXiv 的论文主要聚焦于 AI 模型优化、LLM（大型语言模型）的推理与安全、医疗图像分析、多模态学习和强化学习等领域，其中令人印象深刻的包括 NeurIPS 接受的 DiMSUM（用于图像生成）和 LaTRO（提升 LLM 推理能力）的创新工作，以及 Salesforce 团队的 LLM 自提升研究；这些论文展示了 AI 在实际应用中的潜力，如医疗诊断和机器人导航。\n\n下面，我将逐一简要概述今天的论文，先优先讨论那些重要、创新性强或有话题度的文章（如 LLM 优化、医疗 AI 和强化学习），然后快速掠过其他较常规或小众的论文。每个条目包括论文标题（中文 + 英文）和核心贡献，保留关键学术术语。\n\n### 重点论文讨论\n\n**LLM 推理与优化（Language Models and Reasoning）**  \n这些论文探讨了 LLM 的推理能力提升和安全问题，相关工作显示了 LLM 在复杂任务中的潜力。  \n- **Language Models are Hidden Reasoners: Unlocking Latent Reasoning Capabilities via Self-Rewarding（语言模型是隐藏的推理器：通过自奖励解锁潜在推理能力）**  \n  作者：Haolin Chen 等（Salesforce 团队）。主要贡献：提出 LaTRO 框架，使用变分方法优化 LLM 的推理过程，实现自提升；在 GSM8K 和 ARC-Challenge 数据集上，零样本准确率平均提升 12.5%，无需外部反馈，展示了 LLM 潜在能力的解锁。  \n- **Self-Consistency Preference Optimization（自一致性偏好优化）**  \n  作者：Archiki Prasad 等。主要贡献：引入 ScPO 方法，通过多次采样优化 LLM 的推理一致性；在 GSM8K 上，Llama-3 8B 模型的准确率超过 Llama-3 70B，证明了无监督优化的有效性，适用于复杂推理任务。  \n- **How Transformers Solve Propositional Logic Problems: A Mechanistic Analysis（Transformer 如何解决命题逻辑问题：一种机制分析）**  \n  作者：Guan Zhe Hong 等。主要贡献：分析 Transformer 在逻辑推理中的内部机制，识别注意力头的“规划”和“推理”作用；实验揭示 Mistral-7B 和 Gemma-2-9B 的相似策略，提供可解释性洞见。  \n这些工作突出了 LLM 的自优化潜力，相关发现可能推动 AI 安全和高效应用，但需注意泛化性。\n\n**医疗 AI 与图像处理（Medical AI and Image Analysis）**  \n医疗相关论文占比高，聚焦 AI 在诊断中的实际价值，一些工作如 Touchstone Benchmark 强调基准测试的必要性。  \n- **Touchstone Benchmark: Are We on the Right Way for Evaluating AI Algorithms for Medical Segmentation?（Touchstone 基准：我们是否在正确评估医疗分割 AI 算法？）**  \n  作者：Pedro R. A. S. Bassi 等（多机构合作）。主要贡献：提出大规模基准 Touchstone，包含 5,903 张测试 CT 扫描，评估 19 个 AI 算法；结果显示多模态模型在腹部器官分割上优于单模态，强调真实场景评估的重要性。  \n- **Medical Adaptation of Large Language and Vision-Language Models: Are We Making Progress?（大型语言和视觉语言模型的医疗适应：我们有进步吗？）**  \n  作者：Daniel P. Jeong 等。主要贡献：评估医疗 LLM 和 VLM 的适应性，发现预训练模型在医学问答上表现优于微调模型，提升了 6.2% AUC，质疑现有基准的可靠性。  \n- **Generating Synthetic Electronic Health Record (EHR) Data: A Review with Benchmarking（生成合成电子健康记录数据：综述与基准测试）**  \n  作者：Xingran Chen 等。主要贡献：综述 EHR 数据生成方法，并提供 SynthEHRella 工具包；GAN-based 方法在 MIMIC-III/IV 数据集上提升了保真度和隐私保护，指导实际应用。  \n这些论文推动了医疗 AI 的可信度和效率，但快速掠过如 Improving Radiology Report Conciseness（改进放射学报告简洁性）等较具体的工作，仅提其使用本地 LLM 提升报告结构的贡献。\n\n**多模态学习与图像生成（Multimodal Learning and Image Generation）**  \n这些创新工作扩展了 AI 在视觉任务中的应用，NeurIPS 接受的论文尤为突出。  \n- **DiMSUM: Diffusion Mamba -- A Scalable and Unified Spatial-Frequency Method for Image Generation（DiMSUM：扩散 Mamba -- 一种可扩展的统一空间-频率图像生成方法）**  \n  作者：Hao Phung 等（NeurIPS 2024 接受）。主要贡献：提出结合小波变换和 Mamba 的框架，提升图像生成质量；在图像基准上超越 DiT 和 DIFFUSSM，提供更高效的全局关系捕捉。  \n- **Equivariant Graph Network Approximations of High-Degree Polynomials for Force Field Prediction（等变图神经网络的高阶多项式逼近用于力场预测）**  \n  作者：Zhao Xu 等。主要贡献：开发 PACE 模型，使用原子簇扩展逼近 SE(3) 等变多项式，提升分子动力学模拟的准确性；在基准上达到 SOTA 性能。  \n快速掠过如 WiFlexFormer（高效 WiFi 感知）和 Object Recognition in Human Computer Interaction（物体识别比较），它们分别优化了 WiFi 感知和 HCI 性能，但影响较小。\n\n**强化学习与机器人（Reinforcement Learning and Robotics）**  \n这些论文展示了 RL 在实际场景中的应用潜力。  \n- **Learning Generalizable Policy for Obstacle-Aware Autonomous Drone Racing（学习可泛化策略用于障碍感知自主无人机竞速）**  \n  作者：Yueqian Liu。主要贡献：使用深度强化学习和领域随机化训练无人机策略，实现 70 km/h 速度的泛化导航；代码开源，适用于复杂环境。  \n- **Quantum Diffusion Models for Few-Shot Learning（量子扩散模型用于少样本学习）**  \n  作者：Ruhan Wang 等。主要贡献：提出三框架（LGGI、LGDI、LGNAI）结合量子扩散模型，提升少样本任务性能，超越现有 QML 方法。  \n其他如 Adaptive Consensus Gradients Aggregation（分布式训练优化）和 RTify（AI 与人类决策对齐），快速提及它们分别提升了训练效率和鲁棒性。\n\n### 其他论文快速掠过\n剩余论文较多，且部分主题较小众或初步，这里仅简要列出标题和关键点，不做深入讨论：  \n- **Harmful YouTube Video Detection: A Taxonomy of Online Harm and MLLMs as Alternative Annotators（有害 YouTube 视频检测：在线危害分类和多模态 LLM 作为替代标注器）**  \n  贡献：开发在线危害分类法，使用 GPT-4-Turbo 提升检测准确性。  \n- **A Multilingual Sentiment Lexicon for Low-Resource Language Translation（多语言情感词典用于低资源语言翻译）**  \n  贡献：构建多语言词典，提升低资源语言的情感分析精度。  \n- **Improving Bilingual Capabilities of Language Models（提升语言模型的双语能力）**  \n  贡献：微调 MLLM 支持双语学习分析，适用于教育场景。  \n- **A Random-Key Optimizer for Combinatorial Optimization（随机密钥优化器用于组合优化）**  \n  贡献：提出 RKO 框架，应用于 NP-hard 问题。  \n- **Robust Real-Time Mortality Prediction（鲁棒实时死亡率预测）**  \n  贡献：使用时序差分学习提升 ICU 预测准确性。  \n其他如 PhDGPT（LLM 心理建模）、Fed-EC（联邦学习导航）和 Bio-xLSTM（生物序列建模）等，均有特定领域创新，但非主流话题，故从简。\n\n总之，今天的 arXiv 论文强调 AI 的实用性和优化，LLM 推理和医疗应用是亮点。读者可关注 LaTRO 和 DiMSUM 等工作，以探索 AI 的前沿进展。明天见！",
  "papers": [
    {
      "arxiv_id": "2411.04324v1",
      "title": "Gradient Boosting Trees and Large Language Models for Tabular Data Few-Shot Learning",
      "title_zh": "翻译失败",
      "authors": [
        "Carlos Huertas"
      ],
      "abstract": "Large Language Models (LLM) have brought numerous of new applications to\nMachine Learning (ML). In the context of tabular data (TD), recent studies show\nthat TabLLM is a very powerful mechanism for few-shot-learning (FSL)\napplications, even if gradient boosting decisions trees (GBDT) have\nhistorically dominated the TD field. In this work we demonstrate that although\nLLMs are a viable alternative, the evidence suggests that baselines used to\ngauge performance can be improved. We replicated public benchmarks and our\nmethodology improves LightGBM by 290%, this is mainly driven by forcing node\nsplitting with few samples, a critical step in FSL with GBDT. Our results show\nan advantage to TabLLM for 8 or fewer shots, but as the number of samples\nincreases GBDT provides competitive performance at a fraction of runtime. For\nother real-life applications with vast number of samples, we found FSL still\nuseful to improve model diversity, and when combined with ExtraTrees it\nprovides strong resilience to overfitting, our proposal was validated in a ML\ncompetition setting ranking first place.",
      "tldr_zh": "本论文探讨了 Large Language Models (LLM) 和 gradient boosting decisions trees (GBDT) 在表格数据 few-shot learning (FSL) 中的性能，比较了二者在不同样本量下的优势。作者改进 GBDT 方法（如 LightGBM），通过强制节点分裂等技术，使其性能提升 290%，并发现当样本数为 8 或更少时 TabLLM 更具竞争力，而在大样本场景下 GBDT 提供更高效的运行。最终，结合 ExtraTrees 的 FSL 策略提高了模型多样性和抗过拟合能力，并在 ML 竞赛中取得第一名。",
      "categories": [
        "cs.LG",
        "cs.AI",
        "I.2"
      ],
      "primary_category": "cs.LG",
      "comment": "FedCSIS 2024 - Data Mining Competition - 1st Place Winner",
      "pdf_url": "http://arxiv.org/pdf/2411.04324v1",
      "published_date": "2024-11-06 23:54:09 UTC",
      "updated_date": "2024-11-06 23:54:09 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-20T21:50:30.983845"
    },
    {
      "arxiv_id": "2411.05854v1",
      "title": "Harmful YouTube Video Detection: A Taxonomy of Online Harm and MLLMs as Alternative Annotators",
      "title_zh": "翻译失败",
      "authors": [
        "Claire Wonjeong Jo",
        "Miki Wesołowska",
        "Magdalena Wojcieszak"
      ],
      "abstract": "Short video platforms, such as YouTube, Instagram, or TikTok, are used by\nbillions of users globally. These platforms expose users to harmful content,\nranging from clickbait or physical harms to misinformation or online hate. Yet,\ndetecting harmful videos remains challenging due to an inconsistent\nunderstanding of what constitutes harm and limited resources and mental tolls\ninvolved in human annotation. As such, this study advances measures and methods\nto detect harm in video content. First, we develop a comprehensive taxonomy for\nonline harm on video platforms, categorizing it into six categories:\nInformation, Hate and harassment, Addictive, Clickbait, Sexual, and Physical\nharms. Next, we establish multimodal large language models as reliable\nannotators of harmful videos. We analyze 19,422 YouTube videos using 14 image\nframes, 1 thumbnail, and text metadata, comparing the accuracy of crowdworkers\n(Mturk) and GPT-4-Turbo with domain expert annotations serving as the gold\nstandard. Our results demonstrate that GPT-4-Turbo outperforms crowdworkers in\nboth binary classification (harmful vs. harmless) and multi-label harm\ncategorization tasks. Methodologically, this study extends the application of\nLLMs to multi-label and multi-modal contexts beyond text annotation and binary\nclassification. Practically, our study contributes to online harm mitigation by\nguiding the definitions and identification of harmful content on video\nplatforms.",
      "tldr_zh": "本研究针对短视频平台（如YouTube）上的有害内容检测问题，开发了一个全面的在线有害分类taxonomy，将有害内容分为六类：Information、Hate and harassment、Addictive、Clickbait、Sexual 和 Physical harms，以解决有害定义不一致和人力标注资源有限的挑战。研究利用多模态大型语言模型(MLLMs)作为替代标注者，分析了19,422个YouTube视频的图像帧、缩略图和文本元数据，并将GPT-4-Turbo与众包工作者(Mturk)进行比较，结果显示GPT-4-Turbo在二元分类(有害 vs. 无害)和多标签分类任务中均优于Mturk。方法论上，该研究扩展了LLMs在多模态和多标签上下文的应用，实际贡献在于为视频平台的在线有害内容识别和缓解提供指导。",
      "categories": [
        "cs.MM",
        "cs.AI",
        "cs.CV",
        "cs.CY"
      ],
      "primary_category": "cs.MM",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2411.05854v1",
      "published_date": "2024-11-06 23:48:30 UTC",
      "updated_date": "2024-11-06 23:48:30 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-20T21:50:42.669063"
    },
    {
      "arxiv_id": "2411.04316v1",
      "title": "A Multilingual Sentiment Lexicon for Low-Resource Language Translation using Large Languages Models and Explainable AI",
      "title_zh": "翻译失败",
      "authors": [
        "Melusi Malinga",
        "Isaac Lupanda",
        "Mike Wa Nkongolo",
        "Phil van Deventer"
      ],
      "abstract": "South Africa and the Democratic Republic of Congo (DRC) present a complex\nlinguistic landscape with languages such as Zulu, Sepedi, Afrikaans, French,\nEnglish, and Tshiluba (Ciluba), which creates unique challenges for AI-driven\ntranslation and sentiment analysis systems due to a lack of accurately labeled\ndata. This study seeks to address these challenges by developing a multilingual\nlexicon designed for French and Tshiluba, now expanded to include translations\nin English, Afrikaans, Sepedi, and Zulu. The lexicon enhances cultural\nrelevance in sentiment classification by integrating language-specific\nsentiment scores. A comprehensive testing corpus is created to support\ntranslation and sentiment analysis tasks, with machine learning models such as\nRandom Forest, Support Vector Machine (SVM), Decision Trees, and Gaussian Naive\nBayes (GNB) trained to predict sentiment across low resource languages (LRLs).\nAmong them, the Random Forest model performed particularly well, capturing\nsentiment polarity and handling language-specific nuances effectively.\nFurthermore, Bidirectional Encoder Representations from Transformers (BERT), a\nLarge Language Model (LLM), is applied to predict context-based sentiment with\nhigh accuracy, achieving 99% accuracy and 98% precision, outperforming other\nmodels. The BERT predictions were clarified using Explainable AI (XAI),\nimproving transparency and fostering confidence in sentiment classification.\nOverall, findings demonstrate that the proposed lexicon and machine learning\nmodels significantly enhance translation and sentiment analysis for LRLs in\nSouth Africa and the DRC, laying a foundation for future AI models that support\nunderrepresented languages, with applications across education, governance, and\nbusiness in multilingual contexts.",
      "tldr_zh": "这篇论文针对南非和刚果（DRC）的低资源语言（Low-Resource Languages, LRLs）如 Zulu、Sepedi、Afrikaans、French 和 Tshiluba，开发了一个多语言情感词典（Multilingual Sentiment Lexicon），整合语言特定情感分数以提升情感分类的文化相关性。研究方法包括创建测试语料库，并训练机器学习模型如 Random Forest、SVM、Decision Trees 和 Gaussian Naive Bayes (GNB)，其中 Random Forest 在处理语言细微差异方面表现突出，同时使用 Large Language Models 如 BERT 实现基于上下文的情感预测，达到 99% 准确率和 98% 精确度。Explainable AI (XAI) 被应用来解释 BERT 的预测，提高模型透明度和可信度。总体上，该工作显著改善了 LRLs 的翻译和情感分析，为教育、治理和商业等领域的多语言 AI 应用提供了坚实基础。",
      "categories": [
        "cs.CL",
        "cs.AI",
        "cs.LG"
      ],
      "primary_category": "cs.CL",
      "comment": "This work is part of a PhD proposal in Information Technology at the\n  University of Pretoria, supervised by Dr. Mike Wa Nkongolo and co-supervised\n  by Dr. Phil van Deventer, under the Low-Resource Language Processing Lab in\n  the Department of Informatics",
      "pdf_url": "http://arxiv.org/pdf/2411.04316v1",
      "published_date": "2024-11-06 23:41:18 UTC",
      "updated_date": "2024-11-06 23:41:18 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-20T21:50:56.028530"
    },
    {
      "arxiv_id": "2411.04308v1",
      "title": "Improving Bilingual Capabilities of Language Models to Support Diverse Linguistic Practices in Education",
      "title_zh": "提升语言模型的双语能力以支持教育中的多样语言实践",
      "authors": [
        "Anand Syamkumar",
        "Nora Tseng",
        "Kaycie Barron",
        "Shanglin Yang",
        "Shamya Karumbaiah",
        "Rheeya Uppal",
        "Junjie Hu"
      ],
      "abstract": "Large language models (LLMs) offer promise in generating educational content,\nproviding instructor feedback, and reducing teacher workload on assessments.\nWhile prior studies have focused on studying LLM-powered learning analytics,\nlimited research has examined how effective LLMs are in a bilingual context. In\nthis paper, we study the effectiveness of multilingual large language models\n(MLLMs) across monolingual (English-only, Spanish-only) and bilingual\n(Spanglish) student writing. We present a learning analytics use case that\ndetails LLM performance in assessing acceptable and unacceptable explanations\nof Science and Social Science concepts. Our findings reveal a significant bias\nin the grading performance of pre-trained models for bilingual writing compared\nto English-only and Spanish-only writing. Following this, we fine-tune\nopen-source MLLMs including Llama 3.1 and Mistral NeMo using synthetic datasets\ngenerated in English, Spanish, and Spanglish. Our experiments indicate that the\nmodels perform significantly better for all three languages after fine-tuning\nwith bilingual data. This study highlights the potential of enhancing MLLM\neffectiveness to support authentic language practices amongst bilingual\nlearners. It also aims to illustrate the value of incorporating non-English\nlanguages into the design and implementation of language models in education.",
      "tldr_zh": "本研究探讨了多语言大语言模型 (MLLMs) 在教育中的双语应用效果，特别针对英语-only、西班牙语-only 和双语 (Spanglish) 学生写作进行评估，发现预训练模型在评分双语写作时存在显著偏差。研究者使用合成数据集对开源 MLLMs（如 Llama 3.1 和 Mistral NeMo）进行微调，涵盖英语、西班牙语和 Spanglish，以改善模型对科学和社会科学概念解释的评估能力。实验结果显示，微调后模型在三种语言上的表现显著提升，这突显了增强 MLLMs 的潜力，以支持双语学习者的真实语言实践并推动教育中非英语语言的整合。",
      "categories": [
        "cs.CL",
        "cs.AI"
      ],
      "primary_category": "cs.CL",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2411.04308v1",
      "published_date": "2024-11-06 23:16:25 UTC",
      "updated_date": "2024-11-06 23:16:25 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-20T21:51:05.387410"
    },
    {
      "arxiv_id": "2411.04293v2",
      "title": "A Random-Key Optimizer for Combinatorial Optimization",
      "title_zh": "翻译失败",
      "authors": [
        "Antonio A. Chaves",
        "Mauricio G. C. Resende",
        "Martin J. A. Schuetz",
        "J. Kyle Brubaker",
        "Helmut G. Katzgraber",
        "Edilson F. de Arruda",
        "Ricardo M. A. Silva"
      ],
      "abstract": "This paper presents the Random-Key Optimizer (RKO), a versatile and efficient\nstochastic local search method tailored for combinatorial optimization\nproblems. Using the random-key concept, RKO encodes solutions as vectors of\nrandom keys that are subsequently decoded into feasible solutions via\nproblem-specific decoders. The RKO framework is able to combine a plethora of\nclassic metaheuristics, each capable of operating independently or in parallel,\nwith solution sharing facilitated through an elite solution pool. This modular\napproach allows for the adaptation of various metaheuristics, including\nsimulated annealing, iterated local search, and greedy randomized adaptive\nsearch procedures, among others. The efficacy of the RKO framework, implemented\nin C++, is demonstrated through its application to three NP-hard combinatorial\noptimization problems: the alpha-neighborhood p-median problem, the tree of\nhubs location problem, and the node-capacitated graph partitioning problem. The\nresults highlight the framework's ability to produce high-quality solutions\nacross diverse problem domains, underscoring its potential as a robust tool for\ncombinatorial optimization.",
      "tldr_zh": "本论文提出了一种多功能随机局部搜索方法——Random-Key Optimizer (RKO)，专门用于解决组合优化问题。RKO 通过 random-key 概念将解决方案编码为随机键向量，并利用问题特定的解码器转换为可行方案，同时支持多种经典元启发式算法（如 simulated annealing、iterated local search 和 greedy randomized adaptive search procedures）的独立或并行组合，并通过精英解决方案池实现方案共享。实验结果显示，该框架在三个 NP-hard 问题（alpha-neighborhood p-median problem、tree of hubs location problem 和 node-capacitated graph partitioning problem）上产生了高质量解决方案，证明了其在组合优化领域的鲁棒性和潜力。",
      "categories": [
        "cs.AI",
        "cond-mat.dis-nn",
        "cs.NE",
        "math.OC",
        "90-02, 90B40, 90C27",
        "G.1.6; G.2.1; I.2.8"
      ],
      "primary_category": "cs.AI",
      "comment": "54 pages, 16 figures, 8 tables",
      "pdf_url": "http://arxiv.org/pdf/2411.04293v2",
      "published_date": "2024-11-06 22:23:29 UTC",
      "updated_date": "2024-11-15 22:04:15 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-20T21:51:17.343088"
    },
    {
      "arxiv_id": "2411.04285v1",
      "title": "Robust Real-Time Mortality Prediction in the Intensive Care Unit using Temporal Difference Learning",
      "title_zh": "翻译失败",
      "authors": [
        "Thomas Frost",
        "Kezhi Li",
        "Steve Harris"
      ],
      "abstract": "The task of predicting long-term patient outcomes using supervised machine\nlearning is a challenging one, in part because of the high variance of each\npatient's trajectory, which can result in the model over-fitting to the\ntraining data. Temporal difference (TD) learning, a common reinforcement\nlearning technique, may reduce variance by generalising learning to the pattern\nof state transitions rather than terminal outcomes. However, in healthcare this\nmethod requires several strong assumptions about patient states, and there\nappears to be limited literature evaluating the performance of TD learning\nagainst traditional supervised learning methods for long-term health outcome\nprediction tasks. In this study, we define a framework for applying TD learning\nto real-time irregularly sampled time series data using a Semi-Markov Reward\nProcess. We evaluate the model framework in predicting intensive care mortality\nand show that TD learning under this framework can result in improved model\nrobustness compared to standard supervised learning methods. and that this\nrobustness is maintained even when validated on external datasets. This\napproach may offer a more reliable method when learning to predict patient\noutcomes using high-variance irregular time series data.",
      "tldr_zh": "这篇论文探讨了使用 Temporal Difference Learning 来预测重症监护病房 (ICU) 的实时死亡率问题，以解决监督机器学习在处理患者轨迹高变异性时容易过拟合的挑战。研究提出一个框架，将 TD Learning 应用于不规则采样时间序列数据，通过 Semi-Markov Reward Process 建模状态转换模式。实验结果表明，该框架比传统监督学习方法更鲁棒，即使在外部数据集上验证，也能维持性能优势，从而为预测高变异患者结果提供更可靠的方案。",
      "categories": [
        "cs.LG",
        "cs.AI"
      ],
      "primary_category": "cs.LG",
      "comment": "To be published in the Proceedings of the 4th Machine Learning for\n  Health symposium, Proceedings of Machine Learning Research (PMLR)",
      "pdf_url": "http://arxiv.org/pdf/2411.04285v1",
      "published_date": "2024-11-06 22:11:20 UTC",
      "updated_date": "2024-11-06 22:11:20 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-20T21:51:29.857138"
    },
    {
      "arxiv_id": "2411.04282v2",
      "title": "Language Models are Hidden Reasoners: Unlocking Latent Reasoning Capabilities via Self-Rewarding",
      "title_zh": "语言模型是隐藏的推理者：通过自我奖励解锁潜在推理能力",
      "authors": [
        "Haolin Chen",
        "Yihao Feng",
        "Zuxin Liu",
        "Weiran Yao",
        "Akshara Prabhakar",
        "Shelby Heinecke",
        "Ricky Ho",
        "Phil Mui",
        "Silvio Savarese",
        "Caiming Xiong",
        "Huan Wang"
      ],
      "abstract": "Large language models (LLMs) have shown impressive capabilities, but still\nstruggle with complex reasoning tasks requiring multiple steps. While\nprompt-based methods like Chain-of-Thought (CoT) can improve LLM reasoning at\ninference time, optimizing reasoning capabilities during training remains\nchallenging. We introduce LaTent Reasoning Optimization (LaTRO), a principled\nframework that formulates reasoning as sampling from a latent distribution and\noptimizes it via variational approaches. LaTRO enables LLMs to concurrently\nimprove both their reasoning process and ability to evaluate reasoning quality,\nwithout requiring external feedback or reward models. We validate LaTRO through\nexperiments on GSM8K and ARC-Challenge datasets using multiple model\narchitectures. On GSM8K, LaTRO improves zero-shot accuracy by an average of\n12.5% over base models and 9.6% over supervised fine-tuning across\nPhi-3.5-mini, Mistral-7B, and Llama-3.1-8B. Our findings suggest that\npre-trained LLMs possess latent reasoning capabilities that can be unlocked and\nenhanced through our proposed optimization approach in a self-improvement\nmanner. The code of LaTRO is available at\n\\url{https://github.com/SalesforceAIResearch/LaTRO}.",
      "tldr_zh": "该研究发现大型语言模型（LLMs）在多步复杂推理任务上表现不佳，并提出 LaTRO（LaTent Reasoning Optimization）框架，将推理视为从潜在分布中采样，并通过变分方法优化推理过程和质量评估，而无需外部反馈或奖励模型。LaTRO 让 LLMs 在训练中实现自提升，实验在 GSM8K 和 ARC-Challenge 数据集上验证，使用 Phi-3.5-mini、Mistral-7B 和 Llama-3.1-8B 模型，结果显示 GSM8K 的零样本准确率平均比基线模型提高 12.5%，比监督微调高 9.6%。这些发现证明，预训练 LLMs 拥有隐藏的推理能力，可通过该框架解锁和增强。",
      "categories": [
        "cs.AI",
        "cs.CL",
        "cs.LG",
        "stat.ML",
        "I.2.7"
      ],
      "primary_category": "cs.AI",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2411.04282v2",
      "published_date": "2024-11-06 22:02:30 UTC",
      "updated_date": "2024-11-21 20:29:09 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-20T21:51:44.105033"
    },
    {
      "arxiv_id": "2411.04281v1",
      "title": "Generating Synthetic Electronic Health Record (EHR) Data: A Review with Benchmarking",
      "title_zh": "翻译失败",
      "authors": [
        "Xingran Chen",
        "Zhenke Wu",
        "Xu Shi",
        "Hyunghoon Cho",
        "Bhramar Mukherjee"
      ],
      "abstract": "We conduct a scoping review of existing approaches for synthetic EHR data\ngeneration, and benchmark major methods with proposed open-source software to\noffer recommendations for practitioners. We search three academic databases for\nour scoping review. Methods are benchmarked on open-source EHR datasets,\nMIMIC-III/IV. Seven existing methods covering major categories and two baseline\nmethods are implemented and compared. Evaluation metrics concern data fidelity,\ndownstream utility, privacy protection, and computational cost. 42 studies are\nidentified and classified into five categories. Seven open-source methods\ncovering all categories are selected, trained on MIMIC-III, and evaluated on\nMIMIC-III or MIMIC-IV for transportability considerations. Among them,\nGAN-based methods demonstrate competitive performance in fidelity and utility\non MIMIC-III; rule-based methods excel in privacy protection. Similar findings\nare observed on MIMIC-IV, except that GAN-based methods further outperform the\nbaseline methods in preserving fidelity. A Python package, ``SynthEHRella'', is\nprovided to integrate various choices of approaches and evaluation metrics,\nenabling more streamlined exploration and evaluation of multiple methods. We\nfound that method choice is governed by the relative importance of the\nevaluation metrics in downstream use cases. We provide a decision tree to guide\nthe choice among the benchmarked methods. Based on the decision tree, GAN-based\nmethods excel when distributional shifts exist between the training and testing\npopulations. Otherwise, CorGAN and MedGAN are most suitable for association\nmodeling and predictive modeling, respectively. Future research should\nprioritize enhancing fidelity of the synthetic data while controlling privacy\nexposure, and comprehensive benchmarking of longitudinal or conditional\ngeneration methods.",
      "tldr_zh": "本综述论文审视了合成电子健康记录 (EHR) 数据生成的方法，并通过基准测试提供实用建议。研究者从三个学术数据库中识别了42个研究，并将它们分类为五类，然后在MIMIC-III/IV数据集上评估七种开源方法，包括GAN-based和rule-based方法，指标涵盖数据保真度(fidelity)、下游实用性(utility)、隐私保护和计算成本。结果显示，GAN-based方法在MIMIC-III上表现出色，尤其在保真度和实用性方面，而rule-based方法在隐私保护上领先；在MIMIC-IV上，GAN-based方法进一步提升了保真度表现。论文提供了Python包SynthEHRella和一个决策树，帮助从业者根据用例（如分布偏移情况）选择合适方法，并建议未来研究重点提升合成数据的保真度同时强化隐私控制。",
      "categories": [
        "cs.LG",
        "cs.AI",
        "stat.ML"
      ],
      "primary_category": "cs.LG",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2411.04281v1",
      "published_date": "2024-11-06 21:59:19 UTC",
      "updated_date": "2024-11-06 21:59:19 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-20T21:51:54.224958"
    },
    {
      "arxiv_id": "2411.04280v1",
      "title": "Bayesian Inference in Recurrent Explicit Duration Switching Linear Dynamical Systems",
      "title_zh": "翻译失败",
      "authors": [
        "Mikołaj Słupiński",
        "Piotr Lipiński"
      ],
      "abstract": "In this paper, we propose a novel model called Recurrent Explicit Duration\nSwitching Linear Dynamical Systems (REDSLDS) that incorporates recurrent\nexplicit duration variables into the rSLDS model. We also propose an inference\nand learning scheme that involves the use of P\\'olya-gamma augmentation. We\ndemonstrate the improved segmentation capabilities of our model on three\nbenchmark datasets, including two quantitative datasets and one qualitative\ndataset.",
      "tldr_zh": "这篇论文提出了一个名为Recurrent Explicit Duration Switching Linear Dynamical Systems (REDSLDS)的创新模型，将recurrent explicit duration variables整合到rSLDS模型中，以提升动态系统的建模能力。作者开发了一种基于Pólya-gamma augmentation的推理和学习方案，用于处理模型参数的贝叶斯推断。实验结果显示，该模型在三个基准数据集（包括两个定量数据集和一个定性数据集）上实现了改进的分割性能。",
      "categories": [
        "cs.LG",
        "cs.AI",
        "math.DS",
        "stat.ML"
      ],
      "primary_category": "cs.LG",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2411.04280v1",
      "published_date": "2024-11-06 21:58:24 UTC",
      "updated_date": "2024-11-06 21:58:24 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-20T21:52:04.410281"
    },
    {
      "arxiv_id": "2411.04278v1",
      "title": "The Recurrent Sticky Hierarchical Dirichlet Process Hidden Markov Model",
      "title_zh": "翻译失败",
      "authors": [
        "Mikołaj Słupiński",
        "Piotr Lipiński"
      ],
      "abstract": "The Hierarchical Dirichlet Process Hidden Markov Model (HDP-HMM) is a natural\nBayesian nonparametric extension of the classical Hidden Markov Model for\nlearning from (spatio-)temporal data. A sticky HDP-HMM has been proposed to\nstrengthen the self-persistence probability in the HDP-HMM. Then, disentangled\nsticky HDP-HMM has been proposed to disentangle the strength of the\nself-persistence prior and transition prior. However, the sticky HDP-HMM\nassumes that the self-persistence probability is stationary, limiting its\nexpressiveness. Here, we build on previous work on sticky HDP-HMM and\ndisentangled sticky HDP-HMM, developing a more general model: the recurrent\nsticky HDP-HMM (RS-HDP-HMM). We develop a novel Gibbs sampling strategy for\nefficient inference in this model. We show that RS-HDP-HMM outperforms\ndisentangled sticky HDP-HMM, sticky HDP-HMM, and HDP-HMM in both synthetic and\nreal data segmentation.",
      "tldr_zh": "该研究提出了Recurrent Sticky Hierarchical Dirichlet Process Hidden Markov Model (RS-HDP-HMM)，一种扩展HDP-HMM的Bayesian非参数模型，解决了现有sticky HDP-HMM中自持久概率静态假设的局限性，同时构建在disentangled sticky HDP-HMM的基础上增强模型的表达能力。研究团队开发了新型Gibbs sampling策略，以实现该模型的高效推理。实验结果显示，RS-HDP-HMM在合成和真实数据分割任务中，性能优于disentangled sticky HDP-HMM、sticky HDP-HMM和HDP-HMM。",
      "categories": [
        "cs.LG",
        "cs.AI",
        "math.DS",
        "stat.ML"
      ],
      "primary_category": "cs.LG",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2411.04278v1",
      "published_date": "2024-11-06 21:49:20 UTC",
      "updated_date": "2024-11-06 21:49:20 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-20T21:52:16.530768"
    },
    {
      "arxiv_id": "2411.04265v1",
      "title": "Graph neural networks and non-commuting operators",
      "title_zh": "翻译失败",
      "authors": [
        "Mauricio Velasco",
        "Kaiying O'Hare",
        "Bernardo Rychtenberg",
        "Soledad Villar"
      ],
      "abstract": "Graph neural networks (GNNs) provide state-of-the-art results in a wide\nvariety of tasks which typically involve predicting features at the vertices of\na graph. They are built from layers of graph convolutions which serve as a\npowerful inductive bias for describing the flow of information among the\nvertices. Often, more than one data modality is available. This work considers\na setting in which several graphs have the same vertex set and a common\nvertex-level learning task. This generalizes standard GNN models to GNNs with\nseveral graph operators that do not commute. We may call this model graph-tuple\nneural networks (GtNN).\n  In this work, we develop the mathematical theory to address the stability and\ntransferability of GtNNs using properties of non-commuting non-expansive\noperators. We develop a limit theory of graphon-tuple neural networks and use\nit to prove a universal transferability theorem that guarantees that all\ngraph-tuple neural networks are transferable on convergent graph-tuple\nsequences. In particular, there is no non-transferable energy under the\nconvergence we consider here. Our theoretical results extend well-known\ntransferability theorems for GNNs to the case of several simultaneous graphs\n(GtNNs) and provide a strict improvement on what is currently known even in the\nGNN case.\n  We illustrate our theoretical results with simple experiments on synthetic\nand real-world data. To this end, we derive a training procedure that provably\nenforces the stability of the resulting model.",
      "tldr_zh": "本研究扩展了图神经网络 (GNNs)，提出图元组神经网络 (GtNNs) 来处理多个共享顶点集但操作符不交换 (non-commuting) 的图结构，从而提升多模态数据的顶点级学习任务。研究开发了基于非交换非扩张算子 (non-commuting non-expansive operators) 的数学理论，分析了 GtNNs 的稳定性 (stability) 和可转移性 (transferability)，并建立了 graphon-tuple neural networks 的极限理论，以证明 GtNNs 在收敛图元组序列上的普遍可转移性定理。实验通过合成和真实数据验证了这些理论结果，并提供了一个确保模型稳定的训练过程，显著改进了现有 GNNs 的可转移性性能。",
      "categories": [
        "stat.ML",
        "cs.AI",
        "cs.LG"
      ],
      "primary_category": "stat.ML",
      "comment": "NeurIPS 2024",
      "pdf_url": "http://arxiv.org/pdf/2411.04265v1",
      "published_date": "2024-11-06 21:17:14 UTC",
      "updated_date": "2024-11-06 21:17:14 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-20T21:52:29.265764"
    },
    {
      "arxiv_id": "2411.04263v1",
      "title": "Object Recognition in Human Computer Interaction:- A Comparative Analysis",
      "title_zh": "翻译失败",
      "authors": [
        "Kaushik Ranade",
        "Tanmay Khule",
        "Riddhi More"
      ],
      "abstract": "Human-computer interaction (HCI) has been a widely researched area for many\nyears, with continuous advancements in technology leading to the development of\nnew techniques that change the way we interact with computers. With the recent\nadvent of powerful computers, we recognize human actions and interact\naccordingly, thus revolutionizing the way we interact with computers. The\npurpose of this paper is to provide a comparative analysis of various\nalgorithms used for recognizing user faces and gestures in the context of\ncomputer vision and HCI. This study aims to explore and evaluate the\nperformance of different algorithms in terms of accuracy, robustness, and\nefficiency. This study aims to provide a comprehensive analysis of algorithms\nfor face and gesture recognition in the context of computer vision and HCI,\nwith the goal of improving the design and development of interactive systems\nthat are more intuitive, efficient, and user-friendly.",
      "tldr_zh": "这篇论文对 Human-Computer Interaction (HCI) 中的对象识别算法进行了比较分析，重点评估人脸和手势识别技术在计算机视觉领域的应用。研究比较了多种算法的性能，包括准确性、鲁棒性和效率，旨在探索这些算法的优势和局限性。最终，该分析为设计更直观、高效和用户友好的交互系统提供了宝贵见解。",
      "categories": [
        "cs.HC",
        "cs.AI",
        "cs.CV",
        "cs.LG"
      ],
      "primary_category": "cs.HC",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2411.04263v1",
      "published_date": "2024-11-06 21:16:02 UTC",
      "updated_date": "2024-11-06 21:16:02 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-20T21:52:40.135208"
    },
    {
      "arxiv_id": "2411.04246v1",
      "title": "Learning Generalizable Policy for Obstacle-Aware Autonomous Drone Racing",
      "title_zh": "翻译失败",
      "authors": [
        "Yueqian Liu"
      ],
      "abstract": "Autonomous drone racing has gained attention for its potential to push the\nboundaries of drone navigation technologies. While much of the existing\nresearch focuses on racing in obstacle-free environments, few studies have\naddressed the complexities of obstacle-aware racing, and approaches presented\nin these studies often suffer from overfitting, with learned policies\ngeneralizing poorly to new environments. This work addresses the challenge of\ndeveloping a generalizable obstacle-aware drone racing policy using deep\nreinforcement learning. We propose applying domain randomization on racing\ntracks and obstacle configurations before every rollout, combined with parallel\nexperience collection in randomized environments to achieve the goal. The\nproposed randomization strategy is shown to be effective through simulated\nexperiments where drones reach speeds of up to 70 km/h, racing in unseen\ncluttered environments. This study serves as a stepping stone toward learning\nrobust policies for obstacle-aware drone racing and general-purpose drone\nnavigation in cluttered environments. Code is available at\nhttps://github.com/ErcBunny/IsaacGymEnvs.",
      "tldr_zh": "本研究针对自主无人机竞速中的障碍物感知问题，提出一种基于深度强化学习（deep reinforcement learning）的可泛化策略，以解决现有方法易过拟合和泛化性差的挑战。方法包括对赛道和障碍物配置进行领域随机化（domain randomization），并在随机化环境中并行收集经验，从而提升策略的鲁棒性。通过模拟实验，无人机在未知杂乱环境中达到最高70 km/h的速度，证明了该策略的有效性。该工作为障碍物感知无人机竞速和一般用途的杂乱环境导航提供了重要基础。",
      "categories": [
        "cs.RO",
        "cs.AI"
      ],
      "primary_category": "cs.RO",
      "comment": "10 pages, 11 figures. This preprint is part of the author's M.Sc.\n  thesis supervised by Ir. Hang Yu and Dr. Ir. Christophe De Wagter, at MAVLab\n  TU Delft. Full thesis is available at https://repository.tudelft.nl",
      "pdf_url": "http://arxiv.org/pdf/2411.04246v1",
      "published_date": "2024-11-06 20:25:43 UTC",
      "updated_date": "2024-11-06 20:25:43 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-20T21:52:53.555545"
    },
    {
      "arxiv_id": "2411.10473v1",
      "title": "PhDGPT: Introducing a psychometric and linguistic dataset about how large language models perceive graduate students and professors in psychology",
      "title_zh": "PhDGPT：介绍一个关于大型语言模型如何感知心理学研究生和教授的心理测量与语言学数据集",
      "authors": [
        "Edoardo Sebastiano De Duro",
        "Enrique Taietta",
        "Riccardo Improta",
        "Massimo Stella"
      ],
      "abstract": "Machine psychology aims to reconstruct the mindset of Large Language Models\n(LLMs), i.e. how these artificial intelligences perceive and associate ideas.\nThis work introduces PhDGPT, a prompting framework and synthetic dataset that\nencapsulates the machine psychology of PhD researchers and professors as\nperceived by OpenAI's GPT-3.5. The dataset consists of 756,000 datapoints,\ncounting 300 iterations repeated across 15 academic events, 2 biological\ngenders, 2 career levels and 42 unique item responses of the Depression,\nAnxiety, and Stress Scale (DASS-42). PhDGPT integrates these psychometric\nscores with their explanations in plain language. This synergy of scores and\ntexts offers a dual, comprehensive perspective on the emotional well-being of\nsimulated academics, e.g. male/female PhD students or professors. By combining\nnetwork psychometrics and psycholinguistic dimensions, this study identifies\nseveral similarities and distinctions between human and LLM data. The\npsychometric networks of simulated male professors do not differ between\nphysical and emotional anxiety subscales, unlike humans. Other LLMs'\npersonification can reconstruct human DASS factors with a purity up to 80%.\nFurthemore, LLM-generated personifications across different scenarios are found\nto elicit explanations lower in concreteness and imageability in items coding\nfor anxiety, in agreement with past studies about human psychology. Our\nfindings indicate an advanced yet incomplete ability for LLMs to reproduce the\ncomplexity of human psychometric data, unveiling convenient advantages and\nlimitations in using LLMs to replace human participants. PhDGPT also\nintriguingly capture the ability for LLMs to adapt and change language patterns\naccording to prompted mental distress contextual features, opening new\nquantitative opportunities for assessing the machine psychology of these\nartificial intelligences.",
      "tldr_zh": "本研究引入了PhDGPT，这是一个提示框架和合成数据集，用于探索Large Language Models (LLMs) 如GPT-3.5如何感知心理学领域的博士生和教授的心理状态。数据集包含756,000个数据点，基于Depression, Anxiety, and Stress Scale (DASS-42) 的42个项目，涵盖15个学术事件、2个生物性别和2个职业水平，并结合了心理测量分数及其语言解释。研究通过network psychometrics和psycholinguistic dimensions分析，发现LLMs在模拟人类心理数据时表现出某些相似性（如焦虑解释的具象性和形象性较低），但也存在差异（如模拟男性教授的网络不区分身体和情感焦虑）。总体而言，PhDGPT揭示了LLMs在重现人类心理复杂性的先进能力及其局限性，为评估机器心理学提供了新途径。",
      "categories": [
        "cs.HC",
        "cs.AI",
        "cs.CL",
        "cs.CY"
      ],
      "primary_category": "cs.HC",
      "comment": "20 pages, 8 figures. Edoardo Sebastiano De Duro and Enrique Taietta\n  equally contributed to this work",
      "pdf_url": "http://arxiv.org/pdf/2411.10473v1",
      "published_date": "2024-11-06 20:04:20 UTC",
      "updated_date": "2024-11-06 20:04:20 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-20T21:53:05.660286"
    },
    {
      "arxiv_id": "2411.04224v1",
      "title": "WiFlexFormer: Efficient WiFi-Based Person-Centric Sensing",
      "title_zh": "WiFlexFormer：高效的基于WiFi的以人为中心的感知",
      "authors": [
        "Julian Strohmayer",
        "Matthias Wödlinger",
        "Martin Kampel"
      ],
      "abstract": "We propose WiFlexFormer, a highly efficient Transformer-based architecture\ndesigned for WiFi Channel State Information (CSI)-based person-centric sensing.\nWe benchmark WiFlexFormer against state-of-the-art vision and specialized\narchitectures for processing radio frequency data and demonstrate that it\nachieves comparable Human Activity Recognition (HAR) performance while offering\na significantly lower parameter count and faster inference times. With an\ninference time of just 10 ms on an Nvidia Jetson Orin Nano, WiFlexFormer is\noptimized for real-time inference. Additionally, its low parameter count\ncontributes to improved cross-domain generalization, where it often outperforms\nlarger models. Our comprehensive evaluation shows that WiFlexFormer is a\npotential solution for efficient, scalable WiFi-based sensing applications. The\nPyTorch implementation of WiFlexFormer is publicly available at:\nhttps://github.com/StrohmayerJ/WiFlexFormer.",
      "tldr_zh": "本研究提出 WiFlexFormer，一种基于 Transformer 的高效架构，用于 WiFi Channel State Information (CSI) 的基于个人的感知系统。相比于最先进的视觉和射频数据处理模型，WiFlexFormer 在 Human Activity Recognition (HAR) 性能上相当，但参数量更低，推理时间仅 10 ms（在 Nvidia Jetson Orin Nano 上），从而实现实时推理并提升跨域泛化能力。实验结果显示，该模型往往优于更大模型，并为高效、可扩展的 WiFi 感知应用提供潜在解决方案；其 PyTorch 实现已在 GitHub 上开源。",
      "categories": [
        "cs.CV",
        "cs.AI",
        "cs.ET",
        "cs.LG"
      ],
      "primary_category": "cs.CV",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2411.04224v1",
      "published_date": "2024-11-06 19:44:36 UTC",
      "updated_date": "2024-11-06 19:44:36 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-20T21:53:16.961296"
    },
    {
      "arxiv_id": "2411.04219v1",
      "title": "Equivariant Graph Network Approximations of High-Degree Polynomials for Force Field Prediction",
      "title_zh": "等",
      "authors": [
        "Zhao Xu",
        "Haiyang Yu",
        "Montgomery Bohde",
        "Shuiwang Ji"
      ],
      "abstract": "Recent advancements in equivariant deep models have shown promise in\naccurately predicting atomic potentials and force fields in molecular dynamics\nsimulations. Using spherical harmonics (SH) and tensor products (TP), these\nequivariant networks gain enhanced physical understanding, like symmetries and\nmany-body interactions. Beyond encoding physical insights, SH and TP are also\ncrucial to represent equivariant polynomial functions. In this work, we analyze\nthe equivariant polynomial functions for the equivariant architecture, and\nintroduce a novel equivariant network, named PACE. The proposed PACE utilizes\nedge booster and the Atomic Cluster Expansion (ACE) technique to approximate a\ngreater number of $SE(3) \\times S_n$ equivariant polynomial functions with\nenhanced degrees. As experimented in commonly used benchmarks, PACE\ndemonstrates state-of-the-art performance in predicting atomic energy and force\nfields, with robust generalization capability across various geometric\ndistributions under molecular dynamics (MD) across different temperature\nconditions. Our code is publicly available as part of the AIRS library\nhttps://github.com/divelab/AIRS/.",
      "tldr_zh": "本论文探讨了等变图网络在预测分子动力学中的高阶多项式逼近，用于原子势和力场预测，强调 spherical harmonics (SH) 和 tensor products (TP) 在编码物理洞察和表示等变多项式函数中的作用。研究引入了新型网络 PACE，通过 edge booster 和 Atomic Cluster Expansion (ACE) 技术，实现了对更高阶 $SE(3) \\times S_n$ 等变多项式函数的精确逼近。实验结果显示，PACE 在常用基准测试中取得了 state-of-the-art 性能，并在不同温度条件下的分子动力学 (MD) 中展现出强大的泛化能力和鲁棒性。",
      "categories": [
        "cs.LG",
        "cs.AI"
      ],
      "primary_category": "cs.LG",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2411.04219v1",
      "published_date": "2024-11-06 19:34:40 UTC",
      "updated_date": "2024-11-06 19:34:40 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-20T21:53:31.081658"
    },
    {
      "arxiv_id": "2411.04217v1",
      "title": "Quantum Diffusion Models for Few-Shot Learning",
      "title_zh": "翻译失败",
      "authors": [
        "Ruhan Wang",
        "Ye Wang",
        "Jing Liu",
        "Toshiaki Koike-Akino"
      ],
      "abstract": "Modern quantum machine learning (QML) methods involve the variational\noptimization of parameterized quantum circuits on training datasets, followed\nby predictions on testing datasets. Most state-of-the-art QML algorithms\ncurrently lack practical advantages due to their limited learning capabilities,\nespecially in few-shot learning tasks. In this work, we propose three new\nframeworks employing quantum diffusion model (QDM) as a solution for the\nfew-shot learning: label-guided generation inference (LGGI); label-guided\ndenoising inference (LGDI); and label-guided noise addition inference (LGNAI).\nExperimental results demonstrate that our proposed algorithms significantly\noutperform existing methods.",
      "tldr_zh": "该论文探讨了量子机器学习（QML）在少样本学习（Few-Shot Learning）任务中的局限性，提出三种基于量子扩散模型（QDM）的新框架作为解决方案，包括标签引导生成推理（LGGI）、标签引导去噪推理（LGDI）和标签引导噪声添加推理（LGNAI）。这些框架通过结合标签引导机制来提升模型的泛化能力，针对训练数据有限的场景进行优化。实验结果表明，所提算法在性能上显著优于现有QML方法，为少样本学习提供了更有效的量子方法。",
      "categories": [
        "cs.LG",
        "cs.AI"
      ],
      "primary_category": "cs.LG",
      "comment": "10 pages",
      "pdf_url": "http://arxiv.org/pdf/2411.04217v1",
      "published_date": "2024-11-06 19:25:06 UTC",
      "updated_date": "2024-11-06 19:25:06 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-20T21:53:40.777843"
    },
    {
      "arxiv_id": "2411.05042v1",
      "title": "Improving Radiology Report Conciseness and Structure via Local Large Language Models",
      "title_zh": "通过本地大型语言模型改善放射学报告的简洁性和结构",
      "authors": [
        "Iryna Hartsock",
        "Cyrillo Araujo",
        "Les Folio",
        "Ghulam Rasool"
      ],
      "abstract": "In this study, we aim to enhance radiology reporting by improving both the\nconciseness and structured organization of findings (also referred to as\ntemplating), specifically by organizing information according to anatomical\nregions. This structured approach allows physicians to locate relevant\ninformation quickly, increasing the report's utility. We utilize Large Language\nModels (LLMs) such as Mixtral, Mistral, and Llama to generate concise,\nwell-structured reports. Among these, we primarily focus on the Mixtral model\ndue to its superior adherence to specific formatting requirements compared to\nother models. To maintain data security and privacy, we run these LLMs locally\nbehind our institution's firewall. We leverage the LangChain framework and\napply five distinct prompting strategies to enforce a consistent structure in\nradiology reports, aiming to eliminate extraneous language and achieve a high\nlevel of conciseness. We also introduce a novel metric, the Conciseness\nPercentage (CP) score, to evaluate report brevity. Our dataset comprises 814\nradiology reports authored by seven board-certified body radiologists at our\ncancer center. In evaluating the different prompting methods, we discovered\nthat the most effective approach for generating concise, well-structured\nreports involves first instructing the LLM to condense the report, followed by\na prompt to structure the content according to specific guidelines. We assessed\nall prompting strategies based on their ability to handle formatting issues,\nreduce report length, and adhere to formatting instructions. Our findings\ndemonstrate that open-source, locally deployed LLMs can significantly improve\nradiology report conciseness and structure while conforming to specified\nformatting standards.",
      "tldr_zh": "本研究旨在通过本地部署的 Large Language Models (LLMs) 如 Mixtral，提升放射学报告的简洁性和结构化组织（如按解剖区域排列），以帮助医生快速定位信息。研究团队使用 LangChain 框架和五种提示策略，其中先指令 LLM 浓缩报告再结构化的方法表现最佳，并引入 Conciseness Percentage (CP) score 作为评估简洁度的全新指标。实验基于 814 份真实放射学报告显示，这种方法显著减少了报告长度、消除了多余语言，并确保了数据安全和格式遵守。",
      "categories": [
        "cs.CL",
        "cs.AI"
      ],
      "primary_category": "cs.CL",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2411.05042v1",
      "published_date": "2024-11-06 19:00:57 UTC",
      "updated_date": "2024-11-06 19:00:57 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-20T21:53:54.282511"
    },
    {
      "arxiv_id": "2411.04168v4",
      "title": "DiMSUM: Diffusion Mamba -- A Scalable and Unified Spatial-Frequency Method for Image Generation",
      "title_zh": "翻译失败",
      "authors": [
        "Hao Phung",
        "Quan Dao",
        "Trung Dao",
        "Hoang Phan",
        "Dimitris Metaxas",
        "Anh Tran"
      ],
      "abstract": "We introduce a novel state-space architecture for diffusion models,\neffectively harnessing spatial and frequency information to enhance the\ninductive bias towards local features in input images for image generation\ntasks. While state-space networks, including Mamba, a revolutionary advancement\nin recurrent neural networks, typically scan input sequences from left to\nright, they face difficulties in designing effective scanning strategies,\nespecially in the processing of image data. Our method demonstrates that\nintegrating wavelet transformation into Mamba enhances the local structure\nawareness of visual inputs and better captures long-range relations of\nfrequencies by disentangling them into wavelet subbands, representing both low-\nand high-frequency components. These wavelet-based outputs are then processed\nand seamlessly fused with the original Mamba outputs through a cross-attention\nfusion layer, combining both spatial and frequency information to optimize the\norder awareness of state-space models which is essential for the details and\noverall quality of image generation. Besides, we introduce a globally-shared\ntransformer to supercharge the performance of Mamba, harnessing its exceptional\npower to capture global relationships. Through extensive experiments on\nstandard benchmarks, our method demonstrates superior results compared to DiT\nand DIFFUSSM, achieving faster training convergence and delivering high-quality\noutputs. The codes and pretrained models are released at\nhttps://github.com/VinAIResearch/DiMSUM.git.",
      "tldr_zh": "我们提出 DiMSUM，一种基于 state-space architecture 的扩散模型方法，通过整合 wavelet transformation 到 Mamba 中，增强图像生成任务中对局部特征的归纳偏差（inductive bias），并通过分离 wavelet subbands 捕获低频和高频关系。 该方法将小波输出与原始 Mamba 输出通过 cross-attention fusion layer 融合，并引入 globally-shared transformer 来捕捉全局关系，从而优化空间和频率信息的处理。 实验结果显示，DiMSUM 在标准基准上优于 DiT 和 DIFFUSSM，实现了更快训练收敛和更高输出质量。",
      "categories": [
        "cs.CV",
        "cs.AI"
      ],
      "primary_category": "cs.CV",
      "comment": "Accepted to NeurIPS 2024. Project page:\n  https://vinairesearch.github.io/DiMSUM/",
      "pdf_url": "http://arxiv.org/pdf/2411.04168v4",
      "published_date": "2024-11-06 18:59:17 UTC",
      "updated_date": "2025-04-10 23:29:21 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-20T21:54:06.109547"
    },
    {
      "arxiv_id": "2411.05040v1",
      "title": "Bottom-Up and Top-Down Analysis of Values, Agendas, and Observations in Corpora and LLMs",
      "title_zh": "翻译失败",
      "authors": [
        "Scott E. Friedman",
        "Noam Benkler",
        "Drisana Mosaphir",
        "Jeffrey Rye",
        "Sonja M. Schmer-Galunder",
        "Micah Goldwater",
        "Matthew McLure",
        "Ruta Wheelock",
        "Jeremy Gottlieb",
        "Robert P. Goldman",
        "Christopher Miller"
      ],
      "abstract": "Large language models (LLMs) generate diverse, situated, persuasive texts\nfrom a plurality of potential perspectives, influenced heavily by their prompts\nand training data. As part of LLM adoption, we seek to characterize - and\nideally, manage - the socio-cultural values that they express, for reasons of\nsafety, accuracy, inclusion, and cultural fidelity. We present a validated\napproach to automatically (1) extracting heterogeneous latent value\npropositions from texts, (2) assessing resonance and conflict of values with\ntexts, and (3) combining these operations to characterize the pluralistic value\nalignment of human-sourced and LLM-sourced textual data.",
      "tldr_zh": "这篇论文探讨了大型语言模型（LLMs）在生成文本时所表达的社会文化价值观，并提出了一种 Bottom-Up and Top-Down 分析方法来表征和管理这些价值观，以提升安全、准确、包容性和文化忠实性。方法包括自动提取文本中的异构潜在价值命题（heterogeneous latent value propositions）、评估文本与这些价值的共鸣和冲突（resonance and conflict），以及整合这些操作来分析人类来源和 LLM 来源文本的多样性价值对齐（pluralistic value alignment）。该方法经验证后，可帮助更好地理解和控制 LLMs 的价值观表达。",
      "categories": [
        "cs.CL",
        "cs.AI"
      ],
      "primary_category": "cs.CL",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2411.05040v1",
      "published_date": "2024-11-06 18:51:04 UTC",
      "updated_date": "2024-11-06 18:51:04 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-20T21:54:19.432278"
    },
    {
      "arxiv_id": "2411.04118v2",
      "title": "Medical Adaptation of Large Language and Vision-Language Models: Are We Making Progress?",
      "title_zh": "大语言模型和视觉语言模型的医学适应：我们正在取得进展吗？",
      "authors": [
        "Daniel P. Jeong",
        "Saurabh Garg",
        "Zachary C. Lipton",
        "Michael Oberst"
      ],
      "abstract": "Several recent works seek to develop foundation models specifically for\nmedical applications, adapting general-purpose large language models (LLMs) and\nvision-language models (VLMs) via continued pretraining on publicly available\nbiomedical corpora. These works typically claim that such domain-adaptive\npretraining (DAPT) improves performance on downstream medical tasks, such as\nanswering medical licensing exam questions. In this paper, we compare seven\npublic \"medical\" LLMs and two VLMs against their corresponding base models,\narriving at a different conclusion: all medical VLMs and nearly all medical\nLLMs fail to consistently improve over their base models in the zero-/few-shot\nprompting regime for medical question-answering (QA) tasks. For instance,\nacross the tasks and model pairs we consider in the 3-shot setting, medical\nLLMs only outperform their base models in 12.1% of cases, reach a (statistical)\ntie in 49.8% of cases, and are significantly worse than their base models in\nthe remaining 38.2% of cases. Our conclusions are based on (i) comparing each\nmedical model head-to-head, directly against the corresponding base model; (ii)\noptimizing the prompts for each model separately; and (iii) accounting for\nstatistical uncertainty in comparisons. While these basic practices are not\nconsistently adopted in the literature, our ablations show that they\nsubstantially impact conclusions. Our findings suggest that state-of-the-art\ngeneral-domain models may already exhibit strong medical knowledge and\nreasoning capabilities, and offer recommendations to strengthen the conclusions\nof future studies.",
      "tldr_zh": "这篇论文质疑了通过领域适应预训练(DAPT)在生物医学语料上继续预训练大型语言模型(LLMs)和视觉语言模型(VLMs)是否能提升其在医学任务上的表现。研究者对比了七个公共医学LLMs和两个VLMs与其对应的基础模型，在零样本/少样本提示下的医学问答(QA)任务中进行评估，发现几乎所有医学VLMs和LLMs未能一致优于基础模型，例如在3-shot设置下，医学LLMs仅在12.1%的案例中表现更好。论文强调，通过为每个模型优化提示并考虑统计不确定性，这些结论与文献中常见做法不同，并建议最先进的通用模型可能已具备强大医学知识和推理能力，未来研究应加强比较方法以得出更可靠的结果。",
      "categories": [
        "cs.CL",
        "cs.AI",
        "cs.LG"
      ],
      "primary_category": "cs.CL",
      "comment": "This version was published at EMNLP 2024 Main Conference as a Long\n  Paper (Oral). See the extended version (arXiv:2411.08870) for additional\n  results on QA tasks based on clinical notes and evaluations in the supervised\n  fine-tuning regime",
      "pdf_url": "http://arxiv.org/pdf/2411.04118v2",
      "published_date": "2024-11-06 18:51:02 UTC",
      "updated_date": "2024-11-19 20:51:58 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-20T21:54:32.262065"
    },
    {
      "arxiv_id": "2411.04112v1",
      "title": "Fed-EC: Bandwidth-Efficient Clustering-Based Federated Learning For Autonomous Visual Robot Navigation",
      "title_zh": "翻译失败",
      "authors": [
        "Shreya Gummadi",
        "Mateus V. Gasparino",
        "Deepak Vasisht",
        "Girish Chowdhary"
      ],
      "abstract": "Centralized learning requires data to be aggregated at a central server,\nwhich poses significant challenges in terms of data privacy and bandwidth\nconsumption. Federated learning presents a compelling alternative, however,\nvanilla federated learning methods deployed in robotics aim to learn a single\nglobal model across robots that works ideally for all. But in practice one\nmodel may not be well suited for robots deployed in various environments. This\npaper proposes Federated-EmbedCluster (Fed-EC), a clustering-based federated\nlearning framework that is deployed with vision based autonomous robot\nnavigation in diverse outdoor environments. The framework addresses the key\nfederated learning challenge of deteriorating model performance of a single\nglobal model due to the presence of non-IID data across real-world robots.\nExtensive real-world experiments validate that Fed-EC reduces the communication\nsize by 23x for each robot while matching the performance of centralized\nlearning for goal-oriented navigation and outperforms local learning. Fed-EC\ncan transfer previously learnt models to new robots that join the cluster.",
      "tldr_zh": "该论文提出Fed-EC，一种基于聚类的联邦学习框架，旨在解决传统联邦学习在视觉自主机器人导航中的问题，特别是非-IID数据导致的单一全局模型性能下降，以及数据隐私和带宽消耗挑战。Fed-EC通过聚类方法允许机器人根据多样化户外环境学习本地化模型，同时显著减少通信大小。实验结果显示，Fed-EC将每台机器人的通信量降低23倍，其导航性能与集中式学习相当，并优于本地学习，还支持将已学模型转移到新加入的机器人。",
      "categories": [
        "cs.RO",
        "cs.AI",
        "cs.CV",
        "cs.DC"
      ],
      "primary_category": "cs.RO",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2411.04112v1",
      "published_date": "2024-11-06 18:44:09 UTC",
      "updated_date": "2024-11-06 18:44:09 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-20T21:54:42.674946"
    },
    {
      "arxiv_id": "2411.15147v1",
      "title": "Delegating Responsibilities to Intelligent Autonomous Systems: Challenges and Benefits",
      "title_zh": "将责任委派给智能自治系统：挑战与益处",
      "authors": [
        "Gordana Dodig-Crnkovic",
        "Gianfranco Basti",
        "Tobias Holstein"
      ],
      "abstract": "As AI systems increasingly operate with autonomy and adaptability, the\ntraditional boundaries of moral responsibility in techno-social systems are\nbeing challenged. This paper explores the evolving discourse on the delegation\nof responsibilities to intelligent autonomous agents and the ethical\nimplications of such practices. Synthesizing recent developments in AI ethics,\nincluding concepts of distributed responsibility and ethical AI by design, the\npaper proposes a functionalist perspective as a framework. This perspective\nviews moral responsibility not as an individual trait but as a role within a\nsocio-technical system, distributed among human and artificial agents. As an\nexample of 'AI ethical by design,' we present Basti and Vitiello's\nimplementation. They suggest that AI can act as artificial moral agents by\nlearning ethical guidelines and using Deontic Higher-Order Logic to assess\ndecisions ethically. Motivated by the possible speed and scale beyond human\nsupervision and ethical implications, the paper argues for 'AI ethical by\ndesign', while acknowledging the distributed, shared, and dynamic nature of\nresponsibility. This functionalist approach offers a practical framework for\nnavigating the complexities of AI ethics in a rapidly evolving technological\nlandscape.",
      "tldr_zh": "这篇论文探讨了将责任委托给智能自主系统的挑战与益处，强调了AI伦理中道德责任的演变，包括distributed responsibility和ethical AI by design等概念。作者提出functionalist perspective框架，将道德责任视为社会技术系统中的分布式角色，由人类和人工智能代理共同承担。作为示例，论文引用Basti和Vitiello的实现，让AI作为artificial moral agents通过Deontic Higher-Order Logic学习伦理准则并评估决策。最终，该框架主张“AI ethical by design”，提供了一个实用方法来应对AI伦理的动态复杂性。",
      "categories": [
        "cs.CY",
        "cs.AI",
        "K. Computing Milieux K.4 COMPUTERS AND SOCIETY K.4.1 Public Policy\n  Issues. Ethics"
      ],
      "primary_category": "cs.CY",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2411.15147v1",
      "published_date": "2024-11-06 18:40:38 UTC",
      "updated_date": "2024-11-06 18:40:38 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-20T21:54:54.716951"
    },
    {
      "arxiv_id": "2411.04165v1",
      "title": "Bio-xLSTM: Generative modeling, representation and in-context learning of biological and chemical sequences",
      "title_zh": "翻译失败",
      "authors": [
        "Niklas Schmidinger",
        "Lisa Schneckenreiter",
        "Philipp Seidl",
        "Johannes Schimunek",
        "Pieter-Jan Hoedt",
        "Johannes Brandstetter",
        "Andreas Mayr",
        "Sohvi Luukkonen",
        "Sepp Hochreiter",
        "Günter Klambauer"
      ],
      "abstract": "Language models for biological and chemical sequences enable crucial\napplications such as drug discovery, protein engineering, and precision\nmedicine. Currently, these language models are predominantly based on\nTransformer architectures. While Transformers have yielded impressive results,\ntheir quadratic runtime dependency on the sequence length complicates their use\nfor long genomic sequences and in-context learning on proteins and chemical\nsequences. Recently, the recurrent xLSTM architecture has been shown to perform\nfavorably compared to Transformers and modern state-space model (SSM)\narchitectures in the natural language domain. Similar to SSMs, xLSTMs have a\nlinear runtime dependency on the sequence length and allow for constant-memory\ndecoding at inference time, which makes them prime candidates for modeling\nlong-range dependencies in biological and chemical sequences. In this work, we\ntailor xLSTM towards these domains and propose a suite of architectural\nvariants called Bio-xLSTM. Extensive experiments in three large domains,\ngenomics, proteins, and chemistry, were performed to assess xLSTM's ability to\nmodel biological and chemical sequences. The results show that models based on\nBio-xLSTM a) can serve as proficient generative models for DNA, protein, and\nchemical sequences, b) learn rich representations for those modalities, and c)\ncan perform in-context learning for proteins and small molecules.",
      "tldr_zh": "本研究提出 Bio-xLSTM，一种针对生物和化学序列的架构变体，旨在解决基于 Transformer 模型的语言模型在处理长序列时的二次方时间复杂度问题。Bio-xLSTM 基于 xLSTM 框架，优化了线性时间依赖性和常量内存解码能力，以更好地捕捉基因组、蛋白质和化学序列的长程依赖关系。通过在三大领域的广泛实验，结果表明 Bio-xLSTM 能够作为高效的生成模型，学习丰富的序列表示，并支持蛋白质和小分子的 in-context learning。总的来说，该方法为药物发现、蛋白工程和精准医学等应用提供了更具优势的工具。",
      "categories": [
        "q-bio.BM",
        "cs.AI",
        "cs.LG"
      ],
      "primary_category": "q-bio.BM",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2411.04165v1",
      "published_date": "2024-11-06 18:36:48 UTC",
      "updated_date": "2024-11-06 18:36:48 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-20T21:55:07.358735"
    },
    {
      "arxiv_id": "2411.04109v2",
      "title": "Self-Consistency Preference Optimization",
      "title_zh": "自我一致性偏好优化",
      "authors": [
        "Archiki Prasad",
        "Weizhe Yuan",
        "Richard Yuanzhe Pang",
        "Jing Xu",
        "Maryam Fazel-Zarandi",
        "Mohit Bansal",
        "Sainbayar Sukhbaatar",
        "Jason Weston",
        "Jane Yu"
      ],
      "abstract": "Self-alignment, whereby models learn to improve themselves without human\nannotation, is a rapidly growing research area. However, existing techniques\noften fail to improve complex reasoning tasks due to the difficulty of\nassigning correct rewards. An orthogonal approach that is known to improve\ncorrectness is self-consistency, a method applied at inference time based on\nmultiple sampling in order to find the most consistent answer. In this work, we\nextend the self-consistency concept to help train models. We thus introduce\nself-consistency preference optimization (ScPO), which iteratively trains\nconsistent answers to be preferred over inconsistent ones on unsupervised new\nproblems. We show ScPO leads to large improvements over conventional reward\nmodel training on reasoning tasks such as GSM8K and MATH, closing the gap with\nsupervised training with gold answers or preferences, and that combining ScPO\nwith standard supervised learning improves results even further. On ZebraLogic,\nScPO finetunes Llama-3 8B to be superior to Llama-3 70B, Gemma-2 27B, and\nClaude-3 Haiku.",
      "tldr_zh": "该研究提出了 Self-Consistency Preference Optimization (ScPO)，一种无需人类标注的自对齐方法，通过扩展 self-consistency 概念在训练阶段优先选择一致答案，从而改善模型在复杂推理任务上的性能。ScPO 通过迭代训练模型在无监督新问题上偏好一致的响应，显著提升了 GSM8K 和 MATH 等任务的表现，缩小了与使用金标准答案或偏好的监督训练的差距。结合标准监督学习后，效果进一步增强；在 ZebraLogic 上，ScPO 微调的 Llama-3 8B 模型超过了 Llama-3 70B、Gemma-2 27B 和 Claude-3 Haiku。",
      "categories": [
        "cs.CL",
        "cs.AI",
        "cs.LG"
      ],
      "primary_category": "cs.CL",
      "comment": "16 pages, 3 figures",
      "pdf_url": "http://arxiv.org/pdf/2411.04109v2",
      "published_date": "2024-11-06 18:36:22 UTC",
      "updated_date": "2024-11-07 23:41:00 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-20T21:55:19.784775"
    },
    {
      "arxiv_id": "2411.04105v3",
      "title": "How Transformers Solve Propositional Logic Problems: A Mechanistic Analysis",
      "title_zh": "翻译失败",
      "authors": [
        "Guan Zhe Hong",
        "Nishanth Dikkala",
        "Enming Luo",
        "Cyrus Rashtchian",
        "Xin Wang",
        "Rina Panigrahy"
      ],
      "abstract": "Large language models (LLMs) have shown amazing performance on tasks that\nrequire planning and reasoning. Motivated by this, we investigate the internal\nmechanisms that underpin a network's ability to perform complex logical\nreasoning. We first construct a synthetic propositional logic problem that\nserves as a concrete test-bed for network training and evaluation. Crucially,\nthis problem demands nontrivial planning to solve. We perform our study on two\nfronts. First, we pursue an understanding of precisely how a three-layer\ntransformer, trained from scratch and attains perfect test accuracy, solves\nthis problem. We are able to identify certain \"planning\" and \"reasoning\"\nmechanisms in the network that necessitate cooperation between the attention\nblocks to implement the desired logic. Second, we study how pretrained LLMs,\nnamely Mistral-7B and Gemma-2-9B, solve this problem. We characterize their\nreasoning circuits through causal intervention experiments, providing necessity\nand sufficiency evidence for the circuits. We find evidence suggesting that the\ntwo models' latent reasoning strategies are surprisingly similar, and\nhuman-like. Overall, our work systemically uncovers novel aspects of small and\nlarge transformers, and continues the study of how they plan and reason.",
      "tldr_zh": "本研究调查了Transformer模型如何解决命题逻辑（propositional logic）问题，通过构建一个需要非平凡规划的合成问题作为测试平台。首先，分析了从零训练的三层Transformer，发现其内部机制涉及注意块（attention blocks）之间的合作，以实现“规划”和“推理”功能。其次，通过因果干预实验（causal intervention experiments）表征预训练LLMs（如Mistral-7B和Gemma-2-9B）的推理电路，结果显示这些模型的策略相似且类似人类。最后，该工作揭示了小型和大型Transformer在规划和推理方面的机制，为理解语言模型的内部行为提供了系统性洞见。",
      "categories": [
        "cs.LG",
        "cs.AI",
        "cs.CL"
      ],
      "primary_category": "cs.LG",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2411.04105v3",
      "published_date": "2024-11-06 18:35:32 UTC",
      "updated_date": "2024-12-09 16:36:34 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-20T21:55:30.577012"
    },
    {
      "arxiv_id": "2411.04097v1",
      "title": "RaVL: Discovering and Mitigating Spurious Correlations in Fine-Tuned Vision-Language Models",
      "title_zh": "RaVL：在微调的视觉语言模型中发现与缓解虚假相关性",
      "authors": [
        "Maya Varma",
        "Jean-Benoit Delbrouck",
        "Zhihong Chen",
        "Akshay Chaudhari",
        "Curtis Langlotz"
      ],
      "abstract": "Fine-tuned vision-language models (VLMs) often capture spurious correlations\nbetween image features and textual attributes, resulting in degraded zero-shot\nperformance at test time. Existing approaches for addressing spurious\ncorrelations (i) primarily operate at the global image-level rather than\nintervening directly on fine-grained image features and (ii) are predominantly\ndesigned for unimodal settings. In this work, we present RaVL, which takes a\nfine-grained perspective on VLM robustness by discovering and mitigating\nspurious correlations using local image features rather than operating at the\nglobal image level. Given a fine-tuned VLM, RaVL first discovers spurious\ncorrelations by leveraging a region-level clustering approach to identify\nprecise image features contributing to zero-shot classification errors. Then,\nRaVL mitigates the identified spurious correlation with a novel region-aware\nloss function that enables the VLM to focus on relevant regions and ignore\nspurious relationships during fine-tuning. We evaluate RaVL on 654 VLMs with\nvarious model architectures, data domains, and learned spurious correlations.\nOur results show that RaVL accurately discovers (191% improvement over the\nclosest baseline) and mitigates (8.2% improvement on worst-group image\nclassification accuracy) spurious correlations. Qualitative evaluations on\ngeneral-domain and medical-domain VLMs confirm our findings.",
      "tldr_zh": "该研究提出RaVL框架，用于发现和缓解fine-tuned Vision-Language Models (VLMs)中的虚假相关性(spurious correlations)，以提升零样本(zero-shot)性能。RaVL通过区域级聚类方法识别导致分类错误的精确图像特征，从而发现虚假相关性；随后，使用新型区域感知损失函数(region-aware loss)引导VLM在微调时关注相关区域并忽略虚假关系。实验在654个不同架构和数据域的VLM上显示，RaVL的发现准确率比基线提升191%，并在最差组图像分类准确率上改善8.2%，在通用域和医疗域的定性评估中得到验证。",
      "categories": [
        "cs.CV",
        "cs.AI"
      ],
      "primary_category": "cs.CV",
      "comment": "NeurIPS 2024",
      "pdf_url": "http://arxiv.org/pdf/2411.04097v1",
      "published_date": "2024-11-06 18:25:00 UTC",
      "updated_date": "2024-11-06 18:25:00 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-20T21:55:43.530189"
    },
    {
      "arxiv_id": "2411.13559v1",
      "title": "Composing Ensembles of Instrument-Model Pairs for Optimizing Profitability in Algorithmic Trading",
      "title_zh": "翻译失败",
      "authors": [
        "Sahand Hassanizorgabad"
      ],
      "abstract": "Financial markets are nonlinear with complexity, where different types of\nassets are traded between buyers and sellers, each having a view to maximize\ntheir Return on Investment (ROI). Forecasting market trends is a challenging\ntask since various factors like stock-specific news, company profiles, public\nsentiments, and global economic conditions influence them. This paper describes\na daily price directional predictive system of financial instruments,\naddressing the difficulty of predicting short-term price movements. This paper\nwill introduce the development of a novel trading system methodology by\nproposing a two-layer Composing Ensembles architecture, optimized through grid\nsearch, to predict whether the price will rise or fall the next day. This\nstrategy was back-tested on a wide range of financial instruments and time\nframes, demonstrating an improvement of 20% over the benchmark, representing a\nstandard investment strategy.",
      "tldr_zh": "这篇论文针对算法交易中的盈利优化，提出了一种基于 Instrument-Model Pairs 的两层 Composing Ensembles 架构，用于预测金融工具的每日价格方向。方法通过网格搜索优化来处理市场复杂性，如股票新闻、公众情绪和全球经济因素的影响，确保更准确的短期价格运动预测。在广泛的金融工具和时间框架上回测，该策略比基准投资策略提高了20%的表现，为提升 Return on Investment (ROI) 提供了新途径。",
      "categories": [
        "q-fin.TR",
        "cs.AI",
        "cs.LG"
      ],
      "primary_category": "q-fin.TR",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2411.13559v1",
      "published_date": "2024-11-06 18:17:26 UTC",
      "updated_date": "2024-11-06 18:17:26 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-20T21:55:54.768642"
    },
    {
      "arxiv_id": "2411.04090v2",
      "title": "A Collaborative Content Moderation Framework for Toxicity Detection based on Conformalized Estimates of Annotation Disagreement",
      "title_zh": "翻译失败",
      "authors": [
        "Guillermo Villate-Castillo",
        "Javier Del Ser",
        "Borja Sanz"
      ],
      "abstract": "Content moderation typically combines the efforts of human moderators and\nmachine learning models. However, these systems often rely on data where\nsignificant disagreement occurs during moderation, reflecting the subjective\nnature of toxicity perception. Rather than dismissing this disagreement as\nnoise, we interpret it as a valuable signal that highlights the inherent\nambiguity of the content,an insight missed when only the majority label is\nconsidered. In this work, we introduce a novel content moderation framework\nthat emphasizes the importance of capturing annotation disagreement. Our\napproach uses multitask learning, where toxicity classification serves as the\nprimary task and annotation disagreement is addressed as an auxiliary task.\nAdditionally, we leverage uncertainty estimation techniques, specifically\nConformal Prediction, to account for both the ambiguity in comment annotations\nand the model's inherent uncertainty in predicting toxicity and\ndisagreement.The framework also allows moderators to adjust thresholds for\nannotation disagreement, offering flexibility in determining when ambiguity\nshould trigger a review. We demonstrate that our joint approach enhances model\nperformance, calibration, and uncertainty estimation, while offering greater\nparameter efficiency and improving the review process in comparison to\nsingle-task methods.",
      "tldr_zh": "本研究提出了一种协作内容审核框架，用于毒性检测，强调利用标注分歧（annotation disagreement）作为内容的固有模糊性信号，而不是将其视为噪音。该框架采用多任务学习（multitask learning），以毒性分类（toxicity classification）为主任务，并将标注分歧作为辅助任务，同时结合 Conformal Prediction 的不确定性估计技术，来处理注释模糊性和模型预测的不确定性。框架允许审核员调整分歧阈值，提供灵活性，以优化审核流程。实验结果显示，该方法提高了模型性能、校准和不确定性估计，并比单任务方法更参数高效，从而提升了整体内容审核的有效性。",
      "categories": [
        "cs.CL",
        "cs.AI",
        "cs.HC",
        "68T50 (Primary) 68T37 (Secondary)",
        "I.2.7; I.2.1"
      ],
      "primary_category": "cs.CL",
      "comment": "35 pages, 1 figure",
      "pdf_url": "http://arxiv.org/pdf/2411.04090v2",
      "published_date": "2024-11-06 18:08:57 UTC",
      "updated_date": "2024-11-07 07:12:45 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-20T21:56:06.839881"
    },
    {
      "arxiv_id": "2411.05039v2",
      "title": "YouTube Comments Decoded: Leveraging LLMs for Low Resource Language Classification",
      "title_zh": "翻译失败",
      "authors": [
        "Aniket Deroy",
        "Subhankar Maity"
      ],
      "abstract": "Sarcasm detection is a significant challenge in sentiment analysis,\nparticularly due to its nature of conveying opinions where the intended meaning\ndeviates from the literal expression. This challenge is heightened in social\nmedia contexts where code-mixing, especially in Dravidian languages, is\nprevalent. Code-mixing involves the blending of multiple languages within a\nsingle utterance, often with non-native scripts, complicating the task for\nsystems trained on monolingual data. This shared task introduces a novel gold\nstandard corpus designed for sarcasm and sentiment detection within code-mixed\ntexts, specifically in Tamil-English and Malayalam-English languages. The\nprimary objective of this task is to identify sarcasm and sentiment polarity\nwithin a code-mixed dataset of Tamil-English and Malayalam-English comments and\nposts collected from social media platforms. Each comment or post is annotated\nat the message level for sentiment polarity, with particular attention to the\nchallenges posed by class imbalance, reflecting real-world scenarios.In this\nwork, we experiment with state-of-the-art large language models like GPT-3.5\nTurbo via prompting to classify comments into sarcastic or non-sarcastic\ncategories. We obtained a macro-F1 score of 0.61 for Tamil language. We\nobtained a macro-F1 score of 0.50 for Malayalam language.",
      "tldr_zh": "这篇论文探讨了在社交媒体评论中检测 sarcasm（讽刺）的挑战，特别是针对 Tamil-English 和 Malayalam-English 的 code-mixing（代码混合）文本，这些文本常涉及类 imbalance（类不平衡）。作者利用大型语言模型（LLMs）如 GPT-3.5 Turbo 通过 prompting（提示）方法，对评论进行 sarcasm 和 sentiment polarity（情感极性）分类。实验结果显示，Tamil 语言的 macro-F1 score 为 0.61，Malayalam 为 0.50，并引入了一个新的 gold standard corpus（金标准语料库）来支持此类低资源语言任务。",
      "categories": [
        "cs.CL",
        "cs.AI"
      ],
      "primary_category": "cs.CL",
      "comment": "Updated and Final Version",
      "pdf_url": "http://arxiv.org/pdf/2411.05039v2",
      "published_date": "2024-11-06 17:58:01 UTC",
      "updated_date": "2025-03-13 16:17:21 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-20T21:56:19.596148"
    },
    {
      "arxiv_id": "2411.04075v1",
      "title": "M3SciQA: A Multi-Modal Multi-Document Scientific QA Benchmark for Evaluating Foundation Models",
      "title_zh": "翻译失败",
      "authors": [
        "Chuhan Li",
        "Ziyao Shangguan",
        "Yilun Zhao",
        "Deyuan Li",
        "Yixin Liu",
        "Arman Cohan"
      ],
      "abstract": "Existing benchmarks for evaluating foundation models mainly focus on\nsingle-document, text-only tasks. However, they often fail to fully capture the\ncomplexity of research workflows, which typically involve interpreting\nnon-textual data and gathering information across multiple documents. To\naddress this gap, we introduce M3SciQA, a multi-modal, multi-document\nscientific question answering benchmark designed for a more comprehensive\nevaluation of foundation models. M3SciQA consists of 1,452 expert-annotated\nquestions spanning 70 natural language processing paper clusters, where each\ncluster represents a primary paper along with all its cited documents,\nmirroring the workflow of comprehending a single paper by requiring multi-modal\nand multi-document data. With M3SciQA, we conduct a comprehensive evaluation of\n18 foundation models. Our results indicate that current foundation models still\nsignificantly underperform compared to human experts in multi-modal information\nretrieval and in reasoning across multiple scientific documents. Additionally,\nwe explore the implications of these findings for the future advancement of\napplying foundation models in multi-modal scientific literature analysis.",
      "tldr_zh": "该研究指出了现有评估基础模型的基准主要局限于单文档纯文本任务，无法捕捉研究工作流的复杂性，如解释非文本数据和跨文档信息收集。为此，引入了M3SciQA，一个多模态(Multi-Modal)和多文档(Multi-Document)科学问答(Scientific QA)基准，包含1,452个专家标注的问题，覆盖70个自然语言处理论文集群，每个集群模拟真实研究工作流。研究评估了18个基础模型，发现这些模型在多模态信息检索和跨多个科学文档推理方面远低于人类专家水平。最后，该工作探讨了这些发现对未来应用基础模型于多模态科学文献分析的启示。",
      "categories": [
        "cs.CL",
        "cs.AI"
      ],
      "primary_category": "cs.CL",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2411.04075v1",
      "published_date": "2024-11-06 17:52:01 UTC",
      "updated_date": "2024-11-06 17:52:01 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-20T21:56:31.206207"
    },
    {
      "arxiv_id": "2411.05849v1",
      "title": "Input-Driven Dynamics for Robust Memory Retrieval in Hopfield Networks",
      "title_zh": "翻译失败",
      "authors": [
        "Simone Betteti",
        "Giacomo Baggio",
        "Francesco Bullo",
        "Sandro Zampieri"
      ],
      "abstract": "The Hopfield model provides a mathematically idealized yet insightful\nframework for understanding the mechanisms of memory storage and retrieval in\nthe human brain. This model has inspired four decades of extensive research on\nlearning and retrieval dynamics, capacity estimates, and sequential transitions\namong memories. Notably, the role and impact of external inputs has been\nlargely underexplored, from their effects on neural dynamics to how they\nfacilitate effective memory retrieval. To bridge this gap, we propose a novel\ndynamical system framework in which the external input directly influences the\nneural synapses and shapes the energy landscape of the Hopfield model. This\nplasticity-based mechanism provides a clear energetic interpretation of the\nmemory retrieval process and proves effective at correctly classifying highly\nmixed inputs. Furthermore, we integrate this model within the framework of\nmodern Hopfield architectures, using this connection to elucidate how current\nand past information are combined during the retrieval process. Finally, we\nembed both the classic and the new model in an environment disrupted by noise\nand compare their robustness during memory retrieval.",
      "tldr_zh": "本文研究了 Hopfield Networks 在记忆存储和检索中的机制，强调外部输入的作用，该领域此前未被充分探索。作者提出一个新动态系统框架，其中外部输入直接影响神经突触并塑造能量景观，提供记忆检索过程的能量解释，并有效分类高度混合的输入。该框架整合到现代 Hopfield 架构中，阐释当前和过去信息如何结合。最后，实验在噪声环境下比较新模型与经典模型，证明新模型在记忆检索的鲁棒性上表现出色。",
      "categories": [
        "q-bio.NC",
        "cond-mat.stat-mech",
        "cs.AI",
        "cs.LG",
        "math.DS",
        "37N25 (Primary) 37C75, 34D45 (Secondary)",
        "I.5.1; I.2.11"
      ],
      "primary_category": "q-bio.NC",
      "comment": "24 pages, 15 figures",
      "pdf_url": "http://arxiv.org/pdf/2411.05849v1",
      "published_date": "2024-11-06 17:24:25 UTC",
      "updated_date": "2024-11-06 17:24:25 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-20T21:56:43.112931"
    },
    {
      "arxiv_id": "2411.04034v1",
      "title": "Non-Stationary Learning of Neural Networks with Automatic Soft Parameter Reset",
      "title_zh": "翻译失败",
      "authors": [
        "Alexandre Galashov",
        "Michalis K. Titsias",
        "András György",
        "Clare Lyle",
        "Razvan Pascanu",
        "Yee Whye Teh",
        "Maneesh Sahani"
      ],
      "abstract": "Neural networks are traditionally trained under the assumption that data come\nfrom a stationary distribution. However, settings which violate this assumption\nare becoming more popular; examples include supervised learning under\ndistributional shifts, reinforcement learning, continual learning and\nnon-stationary contextual bandits. In this work we introduce a novel learning\napproach that automatically models and adapts to non-stationarity, via an\nOrnstein-Uhlenbeck process with an adaptive drift parameter. The adaptive drift\ntends to draw the parameters towards the initialisation distribution, so the\napproach can be understood as a form of soft parameter reset. We show\nempirically that our approach performs well in non-stationary supervised and\noff-policy reinforcement learning settings.",
      "tldr_zh": "该研究挑战了传统神经网络假设数据来自平稳分布的局限性，提出了一种自动适应非平稳性的学习方法，使用Ornstein-Uhlenbeck过程并引入自适应漂移参数，以实现软参数重置（soft parameter reset）。这种方法通过将参数趋向初始分布来建模数据非平稳性，适用于场景如分布偏移、强化学习和持续学习。实验验证显示，该方法在非平稳的监督学习和离策略强化学习设置中表现出色，显著提升了模型性能。",
      "categories": [
        "cs.LG",
        "cs.AI"
      ],
      "primary_category": "cs.LG",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2411.04034v1",
      "published_date": "2024-11-06 16:32:40 UTC",
      "updated_date": "2024-11-06 16:32:40 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-20T21:56:54.933701"
    },
    {
      "arxiv_id": "2411.05037v1",
      "title": "Towards Interpreting Language Models: A Case Study in Multi-Hop Reasoning",
      "title_zh": "翻译失败",
      "authors": [
        "Mansi Sakarvadia"
      ],
      "abstract": "Answering multi-hop reasoning questions requires retrieving and synthesizing\ninformation from diverse sources. Language models (LMs) struggle to perform\nsuch reasoning consistently. We propose an approach to pinpoint and rectify\nmulti-hop reasoning failures through targeted memory injections on LM attention\nheads. First, we analyze the per-layer activations of GPT-2 models in response\nto single- and multi-hop prompts. We then propose a mechanism that allows users\nto inject relevant prompt-specific information, which we refer to as\n\"memories,\" at critical LM locations during inference. By thus enabling the LM\nto incorporate additional relevant information during inference, we enhance the\nquality of multi-hop prompt completions. We empirically show that a simple,\nefficient, and targeted memory injection into a key attention layer often\nincreases the probability of the desired next token in multi-hop tasks, by up\nto 424%. We observe that small subsets of attention heads can significantly\nimpact the model prediction during multi-hop reasoning. To more faithfully\ninterpret these heads, we develop Attention Lens: an open source tool that\ntranslates the outputs of attention heads into vocabulary tokens via learned\ntransformations called lenses. We demonstrate the use of lenses to reveal how a\nmodel arrives at its answer and use them to localize sources of model failures\nsuch as in the case of biased and malicious language generation.",
      "tldr_zh": "本研究探讨了语言模型（LMs）在多跳推理（multi-hop reasoning）中的局限性，并提出一种通过针对性内存注入（memory injections）来识别和修复推理失败的方法。研究者分析了GPT-2模型的层激活响应，并设计机制在推理过程中向关键注意力层注入相关提示特定信息（memories），从而提升多跳任务的完成质量。实验结果显示，这种注入可将正确下一标记的概率提高多达424%，并证明小部分注意力头能显著影响模型预测。为更好地解释模型行为，他们开发了Attention Lens工具，该工具通过学习转换（lenses）将注意力头的输出转化为词汇标记，帮助定位模型失败来源，如偏见和恶意生成。",
      "categories": [
        "cs.CL",
        "cs.AI",
        "cs.LG"
      ],
      "primary_category": "cs.CL",
      "comment": "University of Chicago, Computer Science, Master of Science\n  Dissertation",
      "pdf_url": "http://arxiv.org/pdf/2411.05037v1",
      "published_date": "2024-11-06 16:30:26 UTC",
      "updated_date": "2024-11-06 16:30:26 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-20T21:57:07.218372"
    },
    {
      "arxiv_id": "2411.05847v2",
      "title": "Federated Data-Driven Kalman Filtering for State Estimation",
      "title_zh": "翻译失败",
      "authors": [
        "Nikos Piperigkos",
        "Alexandros Gkillas",
        "Christos Anagnostopoulos",
        "Aris S. Lalos"
      ],
      "abstract": "This paper proposes a novel localization framework based on collaborative\ntraining or federated learning paradigm, for highly accurate localization of\nautonomous vehicles. More specifically, we build on the standard approach of\nKalmanNet, a recurrent neural network aiming to estimate the underlying system\nuncertainty of traditional Extended Kalman Filtering, and reformulate it by the\nadapt-then-combine concept to FedKalmanNet. The latter is trained in a\ndistributed manner by a group of vehicles (or clients), with local training\ndatasets consisting of vehicular location and velocity measurements, through a\nglobal server aggregation operation. The FedKalmanNet is then used by each\nvehicle to localize itself, by estimating the associated system uncertainty\nmatrices (i.e, Kalman gain). Our aim is to actually demonstrate the benefits of\ncollaborative training for state estimation in autonomous driving, over\ncollaborative decision-making which requires rich V2X communication resources\nfor measurement exchange and sensor fusion under real-time constraints. An\nextensive experimental and evaluation study conducted in CARLA autonomous\ndriving simulator highlights the superior performance of FedKalmanNet over\nstate-of-the-art collaborative decision-making approaches, in localizing\nvehicles without the need of real-time V2X communication.",
      "tldr_zh": "本论文提出了一种基于联邦学习（Federated Learning）的FedKalmanNet框架，用于提升自动驾驶车辆的定位准确性。该框架改进了KalmanNet（一种用于估计传统Extended Kalman Filtering系统不确定性的循环神经网络），通过adapt-then-combine概念实现分布式训练，由车辆（客户端）使用本地位置和速度测量数据，并在全局服务器上聚合。相比于需要实时V2X通信的协作决策方法，FedKalmanNet在CARLA模拟器实验中表现出色，提高了定位性能，并无需实时通信资源。总的来说，该方法为状态估计提供了高效的协作训练方案，展示了其在自主驾驶领域的潜在优势。",
      "categories": [
        "cs.RO",
        "cs.AI"
      ],
      "primary_category": "cs.RO",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2411.05847v2",
      "published_date": "2024-11-06 16:18:33 UTC",
      "updated_date": "2025-02-13 10:23:56 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-20T21:57:19.028770"
    },
    {
      "arxiv_id": "2411.04011v2",
      "title": "Predicting and Publishing Accurate Imbalance Prices Using Monte Carlo Tree Search",
      "title_zh": "利用蒙特卡洛树搜索预测和发布准确的失衡价格",
      "authors": [
        "Fabio Pavirani",
        "Jonas Van Gompel",
        "Seyed Soroush Karimi Madahi",
        "Bert Claessens",
        "Chris Develder"
      ],
      "abstract": "The growing reliance on renewable energy sources, particularly solar and\nwind, has introduced challenges due to their uncontrollable production. This\ncomplicates maintaining the electrical grid balance, prompting some\ntransmission system operators in Western Europe to implement imbalance tariffs\nthat penalize unsustainable power deviations. These tariffs create an implicit\ndemand response framework to mitigate grid instability. Yet, several challenges\nlimit active participation. In Belgium, for example, imbalance prices are only\ncalculated at the end of each 15-minute settlement period, creating high risk\ndue to price uncertainty. This risk is further amplified by the inherent\nvolatility of imbalance prices, discouraging participation. Although\ntransmission system operators provide minute-based price predictions, the\nsystem imbalance volatility makes accurate price predictions challenging to\nobtain and requires sophisticated techniques. Moreover, publishing price\nestimates can prompt participants to adjust their schedules, potentially\naffecting the system balance and the final price, adding further complexity. To\naddress these challenges, we propose a Monte Carlo Tree Search method that\npublishes accurate imbalance prices while accounting for potential response\nactions. Our approach models the system dynamics using a neural network\nforecaster and a cluster of virtual batteries controlled by reinforcement\nlearning agents. Compared to Belgium's current publication method, our\ntechnique improves price accuracy by 20.4% under ideal conditions and by 12.8%\nin more realistic scenarios. This research addresses an unexplored, yet crucial\nproblem, positioning this paper as a pioneering work in analyzing the potential\nof more advanced imbalance price publishing techniques.",
      "tldr_zh": "本研究针对可再生能源波动导致的电网不平衡问题，提出一种使用 Monte Carlo Tree Search (MCTS) 方法来预测和发布准确的不平衡价格，同时考虑参与者的响应行动，以缓解价格不确定性和波动风险。  \n该方法结合神经网络 forecaster 和由强化学习 agents 控制的虚拟电池集群来模拟系统动态，确保预测的鲁棒性。  \n实验结果显示，与比利时的当前发布方法相比，价格准确性在理想条件下提升 20.4%，在更现实场景下提升 12.8%，这为更先进的电网管理技术提供了开创性贡献。",
      "categories": [
        "eess.SY",
        "cs.AI",
        "cs.LG",
        "cs.SY"
      ],
      "primary_category": "eess.SY",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2411.04011v2",
      "published_date": "2024-11-06 15:49:28 UTC",
      "updated_date": "2025-04-17 10:30:26 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-20T21:57:31.684256"
    },
    {
      "arxiv_id": "2411.04008v1",
      "title": "Aligning Characteristic Descriptors with Images for Human-Expert-like Explainability",
      "title_zh": "翻译失败",
      "authors": [
        "Bharat Chandra Yalavarthi",
        "Nalini Ratha"
      ],
      "abstract": "In mission-critical domains such as law enforcement and medical diagnosis,\nthe ability to explain and interpret the outputs of deep learning models is\ncrucial for ensuring user trust and supporting informed decision-making.\nDespite advancements in explainability, existing methods often fall short in\nproviding explanations that mirror the depth and clarity of those given by\nhuman experts. Such expert-level explanations are essential for the dependable\napplication of deep learning models in law enforcement and medical contexts.\nAdditionally, we recognize that most explanations in real-world scenarios are\ncommunicated primarily through natural language. Addressing these needs, we\npropose a novel approach that utilizes characteristic descriptors to explain\nmodel decisions by identifying their presence in images, thereby generating\nexpert-like explanations. Our method incorporates a concept bottleneck layer\nwithin the model architecture, which calculates the similarity between image\nand descriptor encodings to deliver inherent and faithful explanations. Through\nexperiments in face recognition and chest X-ray diagnosis, we demonstrate that\nour approach offers a significant contrast over existing techniques, which are\noften limited to the use of saliency maps. We believe our approach represents a\nsignificant step toward making deep learning systems more accountable,\ntransparent, and trustworthy in the critical domains of face recognition and\nmedical diagnosis.",
      "tldr_zh": "在执法和医疗诊断等关键领域，为提升深度学习模型的可解释性，本文提出一种新方法，利用characteristic descriptors来识别图像中的特征，从而生成类似于人类专家的自然语言解释。  \n该方法在模型架构中引入concept bottleneck layer，通过计算图像和描述符编码之间的相似性，提供固有且可靠的解释决策过程。  \n实验结果显示，在面部识别和胸部X光诊断任务上，该方法显著优于传统的显著性地图技术，提高了模型的透明度、可信度和实际应用价值。",
      "categories": [
        "cs.CV",
        "cs.AI"
      ],
      "primary_category": "cs.CV",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2411.04008v1",
      "published_date": "2024-11-06 15:47:18 UTC",
      "updated_date": "2024-11-06 15:47:18 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-20T21:57:43.463718"
    },
    {
      "arxiv_id": "2411.04723v2",
      "title": "Exploring the Stability Gap in Continual Learning: The Role of the Classification Head",
      "title_zh": "探索持续学习中的稳定性差距：分类头的作用",
      "authors": [
        "Wojciech Łapacz",
        "Daniel Marczak",
        "Filip Szatkowski",
        "Tomasz Trzciński"
      ],
      "abstract": "Continual learning (CL) has emerged as a critical area in machine learning,\nenabling neural networks to learn from evolving data distributions while\nmitigating catastrophic forgetting. However, recent research has identified the\nstability gap -- a phenomenon where models initially lose performance on\npreviously learned tasks before partially recovering during training. Such\nlearning dynamics are contradictory to the intuitive understanding of stability\nin continual learning where one would expect the performance to degrade\ngradually instead of rapidly decreasing and then partially recovering later. To\nbetter understand and alleviate the stability gap, we investigate it at\ndifferent levels of the neural network architecture, particularly focusing on\nthe role of the classification head. We introduce the nearest-mean classifier\n(NMC) as a tool to attribute the influence of the backbone and the\nclassification head on the stability gap. Our experiments demonstrate that NMC\nnot only improves final performance, but also significantly enhances training\nstability across various continual learning benchmarks, including CIFAR100,\nImageNet100, CUB-200, and FGVC Aircrafts. Moreover, we find that NMC also\nreduces task-recency bias. Our analysis provides new insights into the\nstability gap and suggests that the primary contributor to this phenomenon is\nthe linear head, rather than the insufficient representation learning.",
      "tldr_zh": "这篇论文探讨了持续学习（CL）中的稳定性差距现象，即模型在训练过程中先快速下降后部分恢复先前任务的性能，这与预期渐进式退化相悖。作者引入了最近邻均值分类器（NMC）作为工具，分析神经网络架构中主干网络和分类头对稳定性差距的影响。实验在 CIFAR100、ImageNet100 等基准上表明，NMC 不仅提升了最终性能和训练稳定性，还减少了任务最近偏差；研究发现，稳定性差距的主要原因在于线性分类头，而非表示学习不足。",
      "categories": [
        "cs.LG",
        "cs.AI",
        "cs.CV"
      ],
      "primary_category": "cs.LG",
      "comment": "Accepted at WACV 2025",
      "pdf_url": "http://arxiv.org/pdf/2411.04723v2",
      "published_date": "2024-11-06 15:45:01 UTC",
      "updated_date": "2024-11-25 10:09:05 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-20T21:57:55.478061"
    },
    {
      "arxiv_id": "2411.04006v1",
      "title": "Select2Plan: Training-Free ICL-Based Planning through VQA and Memory Retrieval",
      "title_zh": "翻译失败",
      "authors": [
        "Davide Buoso",
        "Luke Robinson",
        "Giuseppe Averta",
        "Philip Torr",
        "Tim Franzmeyer",
        "Daniele De Martini"
      ],
      "abstract": "This study explores the potential of off-the-shelf Vision-Language Models\n(VLMs) for high-level robot planning in the context of autonomous navigation.\nIndeed, while most of existing learning-based approaches for path planning\nrequire extensive task-specific training/fine-tuning, we demonstrate how such\ntraining can be avoided for most practical cases. To do this, we introduce\nSelect2Plan (S2P), a novel training-free framework for high-level robot\nplanning which completely eliminates the need for fine-tuning or specialised\ntraining. By leveraging structured Visual Question-Answering (VQA) and\nIn-Context Learning (ICL), our approach drastically reduces the need for data\ncollection, requiring a fraction of the task-specific data typically used by\ntrained models, or even relying only on online data. Our method facilitates the\neffective use of a generally trained VLM in a flexible and cost-efficient way,\nand does not require additional sensing except for a simple monocular camera.\nWe demonstrate its adaptability across various scene types, context sources,\nand sensing setups. We evaluate our approach in two distinct scenarios:\ntraditional First-Person View (FPV) and infrastructure-driven Third-Person View\n(TPV) navigation, demonstrating the flexibility and simplicity of our method.\nOur technique significantly enhances the navigational capabilities of a\nbaseline VLM of approximately 50% in TPV scenario, and is comparable to trained\nmodels in the FPV one, with as few as 20 demonstrations.",
      "tldr_zh": "本研究提出Select2Plan (S2P)，一个无需训练的框架，利用Visual Question-Answering (VQA)和In-Context Learning (ICL)来实现高水平机器人规划，尤其在自主导航领域。S2P通过结构化VQA和记忆检索，显著减少数据需求，仅需少量演示或在线数据，并仅依赖单目摄像头进行感知。实验结果显示，该方法在Third-Person View (TPV)场景中比基线Vision-Language Models (VLMs)提升约50%的导航能力，在First-Person View (FPV)场景中与训练模型相当，仅需20个演示，展示了其灵活性和高效性。",
      "categories": [
        "cs.RO",
        "cs.AI"
      ],
      "primary_category": "cs.RO",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2411.04006v1",
      "published_date": "2024-11-06 15:44:59 UTC",
      "updated_date": "2024-11-06 15:44:59 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-20T21:58:07.154089"
    },
    {
      "arxiv_id": "2411.03999v1",
      "title": "ParaGAN: A Scalable Distributed Training Framework for Generative Adversarial Networks",
      "title_zh": "翻译失败",
      "authors": [
        "Ziji Shi",
        "Jialin Li",
        "Yang You"
      ],
      "abstract": "Recent advances in Generative Artificial Intelligence have fueled numerous\napplications, particularly those involving Generative Adversarial Networks\n(GANs), which are essential for synthesizing realistic photos and videos.\nHowever, efficiently training GANs remains a critical challenge due to their\ncomputationally intensive and numerically unstable nature. Existing methods\noften require days or even weeks for training, posing significant resource and\ntime constraints.\n  In this work, we introduce ParaGAN, a scalable distributed GAN training\nframework that leverages asynchronous training and an asymmetric optimization\npolicy to accelerate GAN training. ParaGAN employs a congestion-aware data\npipeline and hardware-aware layout transformation to enhance accelerator\nutilization, resulting in over 30% improvements in throughput. With ParaGAN, we\nreduce the training time of BigGAN from 15 days to 14 hours while achieving 91%\nscaling efficiency. Additionally, ParaGAN enables unprecedented high-resolution\nimage generation using BigGAN.",
      "tldr_zh": "该论文介绍了ParaGAN，一种可扩展的分布式训练框架，旨在解决Generative Adversarial Networks (GANs)训练过程中计算密集和不稳定的问题。\nParaGAN采用异步训练、不对称优化策略、拥塞感知数据管道和硬件感知布局转换，提高加速器利用率并提升吞吐量超过30%。\n实验结果显示，使用ParaGAN可以将BigGAN的训练时间从15天缩短到14小时，达到91%的缩放效率，并实现高分辨率图像生成。",
      "categories": [
        "cs.DC",
        "cs.AI"
      ],
      "primary_category": "cs.DC",
      "comment": "Accepted at ACM Symposium on Cloud Computing (SoCC) 2024",
      "pdf_url": "http://arxiv.org/pdf/2411.03999v1",
      "published_date": "2024-11-06 15:40:46 UTC",
      "updated_date": "2024-11-06 15:40:46 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-20T21:58:18.832993"
    },
    {
      "arxiv_id": "2411.03996v1",
      "title": "Towards Resource-Efficient Federated Learning in Industrial IoT for Multivariate Time Series Analysis",
      "title_zh": "翻译失败",
      "authors": [
        "Alexandros Gkillas",
        "Aris Lalos"
      ],
      "abstract": "Anomaly and missing data constitute a thorny problem in industrial\napplications. In recent years, deep learning enabled anomaly detection has\nemerged as a critical direction, however the improved detection accuracy is\nachieved with the utilization of large neural networks, increasing their\nstorage and computational cost. Moreover, the data collected in edge devices\ncontain user privacy, introducing challenges that can be successfully addressed\nby the privacy-preserving distributed paradigm, known as federated learning\n(FL). This framework allows edge devices to train and exchange models\nincreasing also the communication cost. Thus, to deal with the increased\ncommunication, processing and storage challenges of the FL based deep anomaly\ndetection NN pruning is expected to have significant benefits towards reducing\nthe processing, storage and communication complexity. With this focus, a novel\ncompression-based optimization problem is proposed at the server-side of a FL\nparadigm that fusses the received local models broadcast and performs pruning\ngenerating a more compressed model. Experiments in the context of anomaly\ndetection and missing value imputation demonstrate that the proposed FL\nscenario along with the proposed compressed-based method are able to achieve\nhigh compression rates (more than $99.7\\%$) with negligible performance losses\n(less than $1.18\\%$ ) as compared to the centralized solutions.",
      "tldr_zh": "本研究针对工业 IoT 中的多变量时间序列分析，解决异常检测和缺失数据问题，同时考虑资源效率和用户隐私。论文提出一种基于联邦学习 (FL) 的框架，在服务器端设计一个新的压缩优化问题，通过神经网络修剪 (NN pruning) 融合本地模型并进行广播，以减少处理、存储和通信成本。实验结果显示，该方法在异常检测和缺失值插补任务上实现了超过 99.7% 的压缩率，同时性能损失不到 1.18%，与集中式解决方案相当。",
      "categories": [
        "cs.LG",
        "cs.AI",
        "eess.SP"
      ],
      "primary_category": "cs.LG",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2411.03996v1",
      "published_date": "2024-11-06 15:38:31 UTC",
      "updated_date": "2024-11-06 15:38:31 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-20T21:58:30.904911"
    },
    {
      "arxiv_id": "2411.05844v2",
      "title": "LEGO-GraphRAG: Modularizing Graph-based Retrieval-Augmented Generation for Design Space Exploration",
      "title_zh": "翻译失败",
      "authors": [
        "Yukun Cao",
        "Zengyi Gao",
        "Zhiyang Li",
        "Xike Xie",
        "Kevin Zhou",
        "Jianliang Xu"
      ],
      "abstract": "GraphRAG integrates (knowledge) graphs with large language models (LLMs) to\nimprove reasoning accuracy and contextual relevance. Despite its promising\napplications and strong relevance to multiple research communities, such as\ndatabases and natural language processing, GraphRAG currently lacks modular\nworkflow analysis, systematic solution frameworks, and insightful empirical\nstudies. To bridge these gaps, we propose LEGO-GraphRAG, a modular framework\nthat enables: 1) fine-grained decomposition of the GraphRAG workflow, 2)\nsystematic classification of existing techniques and implemented GraphRAG\ninstances, and 3) creation of new GraphRAG instances. Our framework facilitates\ncomprehensive empirical studies of GraphRAG on large-scale real-world graphs\nand diverse query sets, revealing insights into balancing reasoning quality,\nruntime efficiency, and token or GPU cost, that are essential for building\nadvanced GraphRAG systems.",
      "tldr_zh": "该论文提出LEGO-GraphRAG框架，用于模块化基于图谱的检索增强生成(GraphRAG)系统，以提升设计空间探索中的推理准确性和上下文相关性。框架通过细粒度分解GraphRAG工作流、系统分类现有技术和创建新实例，填补了GraphRAG在模块化分析、解决方案框架和实证研究方面的空白。在大型真实世界图谱和多样查询集上的实证研究揭示了如何平衡推理质量、运行时效率以及token或GPU成本，这对构建高级GraphRAG系统至关重要。",
      "categories": [
        "cs.AI",
        "cs.CL",
        "cs.DB"
      ],
      "primary_category": "cs.AI",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2411.05844v2",
      "published_date": "2024-11-06 15:32:28 UTC",
      "updated_date": "2025-01-17 05:33:54 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-20T21:58:43.629709"
    },
    {
      "arxiv_id": "2411.03964v1",
      "title": "What Really is Commonsense Knowledge?",
      "title_zh": "翻译失败",
      "authors": [
        "Quyet V. Do",
        "Junze Li",
        "Tung-Duong Vuong",
        "Zhaowei Wang",
        "Yangqiu Song",
        "Xiaojuan Ma"
      ],
      "abstract": "Commonsense datasets have been well developed in Natural Language Processing,\nmainly through crowdsource human annotation. However, there are debates on the\ngenuineness of commonsense reasoning benchmarks. In specific, a significant\nportion of instances in some commonsense benchmarks do not concern commonsense\nknowledge. That problem would undermine the measurement of the true commonsense\nreasoning ability of evaluated models. It is also suggested that the problem\noriginated from a blurry concept of commonsense knowledge, as distinguished\nfrom other types of knowledge. To demystify all of the above claims, in this\nstudy, we survey existing definitions of commonsense knowledge, ground into the\nthree frameworks for defining concepts, and consolidate them into a\nmulti-framework unified definition of commonsense knowledge (so-called\nconsolidated definition). We then use the consolidated definition for\nannotations and experiments on the CommonsenseQA and CommonsenseQA 2.0 datasets\nto examine the above claims. Our study shows that there exists a large portion\nof non-commonsense-knowledge instances in the two datasets, and a large\nperformance gap on these two subsets where Large Language Models (LLMs) perform\nworse on commonsense-knowledge instances.",
      "tldr_zh": "本研究探讨了常识知识（commonsense knowledge）的真实定义问题，调查现有定义并将其整合到三个框架中，提出一个统一的整合定义（consolidated definition），以区分常识知识与其他知识类型。研究者随后使用这一定义对 CommonsenseQA 和 CommonsenseQA 2.0 数据集进行标注和实验，结果显示这些数据集中有大量实例不涉及真正的常识知识。实验进一步揭示，大型语言模型（LLMs）在常识知识子集上的表现明显更差，这突显了当前基准测试在评估模型常识推理能力方面的局限性。",
      "categories": [
        "cs.CL",
        "cs.AI"
      ],
      "primary_category": "cs.CL",
      "comment": "Code and data will be released together with the next version of the\n  paper",
      "pdf_url": "http://arxiv.org/pdf/2411.03964v1",
      "published_date": "2024-11-06 14:54:19 UTC",
      "updated_date": "2024-11-06 14:54:19 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-20T21:58:54.828135"
    },
    {
      "arxiv_id": "2411.03959v1",
      "title": "Energy Score-based Pseudo-Label Filtering and Adaptive Loss for Imbalanced Semi-supervised SAR target recognition",
      "title_zh": "翻译失败",
      "authors": [
        "Xinzheng Zhang",
        "Yuqing Luo",
        "Guopeng Li"
      ],
      "abstract": "Automatic target recognition (ATR) is an important use case for synthetic\naperture radar (SAR) image interpretation. Recent years have seen significant\nadvancements in SAR ATR technology based on semi-supervised learning. However,\nexisting semi-supervised SAR ATR algorithms show low recognition accuracy in\nthe case of class imbalance. This work offers a non-balanced semi-supervised\nSAR target recognition approach using dynamic energy scores and adaptive loss.\nFirst, an energy score-based method is developed to dynamically select\nunlabeled samples near to the training distribution as pseudo-labels during\ntraining, assuring pseudo-label reliability in long-tailed distribution\ncircumstances. Secondly, loss functions suitable for class imbalances are\nproposed, including adaptive margin perception loss and adaptive hard triplet\nloss, the former offsets inter-class confusion of classifiers, alleviating the\nimbalance issue inherent in pseudo-label generation. The latter effectively\ntackles the model's preference for the majority class by focusing on complex\ndifficult samples during training. Experimental results on extremely imbalanced\nSAR datasets demonstrate that the proposed method performs well under the dual\nconstraints of scarce labels and data imbalance, effectively overcoming the\nmodel bias caused by data imbalance and achieving high-precision target\nrecognition.",
      "tldr_zh": "这篇论文针对类别不平衡的半监督 SAR 目标识别（ATR）问题，提出了一种基于能量分数（energy score）的伪标签过滤方法和自适应损失函数，以提高模型性能。具体方法包括动态选择接近训练分布的无标签样本作为伪标签，确保在长尾分布下伪标签的可靠性；同时引入自适应边缘感知损失（adaptive margin perception loss）和自适应硬三元组损失（adaptive hard triplet loss），分别缓解分类器混淆和模型对多数类的偏好。实验结果显示，该方法在极端不平衡的 SAR 数据集上表现优异，有效克服标签稀缺和数据不平衡的双重挑战，实现高精度目标识别。",
      "categories": [
        "cs.CV",
        "cs.AI"
      ],
      "primary_category": "cs.CV",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2411.03959v1",
      "published_date": "2024-11-06 14:45:16 UTC",
      "updated_date": "2024-11-06 14:45:16 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-20T21:59:08.199880"
    },
    {
      "arxiv_id": "2411.05034v1",
      "title": "Mitigating Privacy Risks in LLM Embeddings from Embedding Inversion",
      "title_zh": "翻译失败",
      "authors": [
        "Tiantian Liu",
        "Hongwei Yao",
        "Tong Wu",
        "Zhan Qin",
        "Feng Lin",
        "Kui Ren",
        "Chun Chen"
      ],
      "abstract": "Embeddings have become a cornerstone in the functionality of large language\nmodels (LLMs) due to their ability to transform text data into rich, dense\nnumerical representations that capture semantic and syntactic properties. These\nembedding vector databases serve as the long-term memory of LLMs, enabling\nefficient handling of a wide range of natural language processing tasks.\nHowever, the surge in popularity of embedding vector databases in LLMs has been\naccompanied by significant concerns about privacy leakage. Embedding vector\ndatabases are particularly vulnerable to embedding inversion attacks, where\nadversaries can exploit the embeddings to reverse-engineer and extract\nsensitive information from the original text data. Existing defense mechanisms\nhave shown limitations, often struggling to balance security with the\nperformance of downstream tasks. To address these challenges, we introduce\nEguard, a novel defense mechanism designed to mitigate embedding inversion\nattacks. Eguard employs a transformer-based projection network and text mutual\ninformation optimization to safeguard embeddings while preserving the utility\nof LLMs. Our approach significantly reduces privacy risks, protecting over 95%\nof tokens from inversion while maintaining high performance across downstream\ntasks consistent with original embeddings.",
      "tldr_zh": "本研究探讨了大型语言模型(LLM)中嵌入(embeddings)的隐私风险，特别是embedding inversion attacks可能导致敏感信息泄露的问题。针对现有防御机制的安全性与性能平衡不足，该论文提出Eguard，一种新型防御机制，利用transformer-based projection network和text mutual information optimization来保护嵌入，同时保留LLM的实用性。实验结果显示，Eguard能够保护95%以上的tokens免于逆向攻击，并在下游任务中维持与原embeddings一致的高性能，从而有效缓解隐私泄露风险。",
      "categories": [
        "cs.CR",
        "cs.AI",
        "cs.CL"
      ],
      "primary_category": "cs.CR",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2411.05034v1",
      "published_date": "2024-11-06 14:42:41 UTC",
      "updated_date": "2024-11-06 14:42:41 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-20T21:59:18.712927"
    },
    {
      "arxiv_id": "2411.03957v1",
      "title": "Fine-Grained Guidance for Retrievers: Leveraging LLMs' Feedback in Retrieval-Augmented Generation",
      "title_zh": "翻译失败",
      "authors": [
        "Yuhang Liu",
        "Xueyu Hu",
        "Shengyu Zhang",
        "Jingyuan Chen",
        "Fan Wu",
        "Fei Wu"
      ],
      "abstract": "Retrieval-Augmented Generation (RAG) has proven to be an effective method for\nmitigating hallucination issues inherent in large language models (LLMs).\nPrevious approaches typically train retrievers based on semantic similarity,\nlacking optimization for RAG. More recent works have proposed aligning\nretrievers with the preference signals of LLMs. However, these preference\nsignals are often difficult for dense retrievers, which typically have weaker\nlanguage capabilities, to understand and learn effectively. Drawing inspiration\nfrom pedagogical theories like Guided Discovery Learning, we propose a novel\nframework, FiGRet (Fine-grained Guidance for Retrievers), which leverages the\nlanguage capabilities of LLMs to construct examples from a more granular,\ninformation-centric perspective to guide the learning of retrievers.\nSpecifically, our method utilizes LLMs to construct easy-to-understand examples\nfrom samples where the retriever performs poorly, focusing on three learning\nobjectives highly relevant to the RAG scenario: relevance, comprehensiveness,\nand purity. These examples serve as scaffolding to ultimately align the\nretriever with the LLM's preferences. Furthermore, we employ a dual curriculum\nlearning strategy and leverage the reciprocal feedback between LLM and\nretriever to further enhance the performance of the RAG system. A series of\nexperiments demonstrate that our proposed framework enhances the performance of\nRAG systems equipped with different retrievers and is applicable to various\nLLMs.",
      "tldr_zh": "本文提出 FiGRet 框架，利用 LLMs 的语言能力从细粒度的信息中心视角构建例子，指导检索器的学习，以优化 Retrieval-Augmented Generation (RAG) 系统。方法聚焦于三个关键学习目标：相关性(relevance)、全面性(comprehensiveness)和纯度(purity)，并结合双重课程学习(dual curriculum learning)策略及 LLMs 与检索器之间的互惠反馈。实验结果表明，该框架显著提升了配备不同检索器的 RAG 系统性能，并适用于各种 LLMs。",
      "categories": [
        "cs.IR",
        "cs.AI"
      ],
      "primary_category": "cs.IR",
      "comment": "13 pages, 4 figures",
      "pdf_url": "http://arxiv.org/pdf/2411.03957v1",
      "published_date": "2024-11-06 14:42:39 UTC",
      "updated_date": "2024-11-06 14:42:39 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-20T21:59:31.917837"
    },
    {
      "arxiv_id": "2411.03948v2",
      "title": "Long-Form Text-to-Music Generation with Adaptive Prompts: A Case of Study in Tabletop Role-Playing Games Soundtracks",
      "title_zh": "翻译失败",
      "authors": [
        "Felipe Marra",
        "Lucas N. Ferreira"
      ],
      "abstract": "This paper investigates the capabilities of text-to-audio music generation\nmodels in producing long-form music with prompts that change over time,\nfocusing on soundtrack generation for Tabletop Role-Playing Games (TRPGs). We\nintroduce Babel Bardo, a system that uses Large Language Models (LLMs) to\ntransform speech transcriptions into music descriptions for controlling a\ntext-to-music model. Four versions of Babel Bardo were compared in two TRPG\ncampaigns: a baseline using direct speech transcriptions, and three LLM-based\nversions with varying approaches to music description generation. Evaluations\nconsidered audio quality, story alignment, and transition smoothness. Results\nindicate that detailed music descriptions improve audio quality while\nmaintaining consistency across consecutive descriptions enhances story\nalignment and transition smoothness.",
      "tldr_zh": "这篇论文探讨了文本到音乐生成模型在产生长形式音乐的能力，焦点在于使用适应性提示生成桌面角色扮演游戏 (TRPGs) 原声带。我们引入了 Babel Bardo 系统，该系统利用大型语言模型 (LLMs) 将语音转录转化为音乐描述，以控制文本到音乐模型，并在两个 TRPG 战役中比较了四个版本，包括一个基线和三种基于 LLM 的变体。结果表明，详细的音乐描述提高了音频质量，同时保持描述一致性增强了故事一致性 (story alignment) 和过渡平滑性 (transition smoothness)。",
      "categories": [
        "cs.SD",
        "cs.AI",
        "cs.MM",
        "cs.NE",
        "eess.AS"
      ],
      "primary_category": "cs.SD",
      "comment": "Paper accepted at the LAMIR 2024 workshop",
      "pdf_url": "http://arxiv.org/pdf/2411.03948v2",
      "published_date": "2024-11-06 14:29:49 UTC",
      "updated_date": "2025-01-22 13:35:26 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-20T21:59:43.441783"
    },
    {
      "arxiv_id": "2411.03945v1",
      "title": "Can Custom Models Learn In-Context? An Exploration of Hybrid Architecture Performance on In-Context Learning Tasks",
      "title_zh": "翻译失败",
      "authors": [
        "Ryan Campbell",
        "Nelson Lojo",
        "Kesava Viswanadha",
        "Christoffer Grondal Tryggestad",
        "Derrick Han Sun",
        "Sriteja Vijapurapu",
        "August Rolfsen",
        "Anant Sahai"
      ],
      "abstract": "In-Context Learning (ICL) is a phenomenon where task learning occurs through\na prompt sequence without the necessity of parameter updates. ICL in\nMulti-Headed Attention (MHA) with absolute positional embedding has been the\nfocus of more study than other sequence model varieties. We examine\nimplications of architectural differences between GPT-2 and LLaMa as well as\nLlaMa and Mamba. We extend work done by Garg et al. (2022) and Park et al.\n(2024) to GPT-2/LLaMa hybrid and LLaMa/Mamba hybrid models - examining the\ninterplay between sequence transformation blocks and regressive performance\nin-context. We note that certain architectural changes cause degraded training\nefficiency/ICL accuracy by converging to suboptimal predictors or converging\nslower. We also find certain hybrids showing optimistic performance\nimprovements, informing potential future ICL-focused architecture\nmodifications. Additionally, we propose the \"ICL regression score\", a scalar\nmetric describing a model's whole performance on a specific task. Compute\nlimitations impose restrictions on our architecture-space, training duration,\nnumber of training runs, function class complexity, and benchmark complexity.\nTo foster reproducible and extensible research, we provide a typed, modular,\nand extensible Python package on which we run all experiments.",
      "tldr_zh": "本研究探讨了自定义混合模型（如GPT-2/LLaMa和LLaMa/Mamba混合架构）在In-Context Learning (ICL)任务中的性能，扩展了Garg et al. (2022)和Park et al. (2024)的相关工作，通过分析序列转换块与ICL回归性能的相互作用。结果显示，某些架构变化会导致训练效率和ICL准确率下降，因为模型可能收敛到次优预测器或收敛更慢，但部分混合模型表现出性能提升，为未来的ICL优化提供指导。该研究还提出“ICL regression score”作为评估模型整体性能的标量指标，并提供了一个可重现的模块化Python包以支持进一步研究。",
      "categories": [
        "cs.LG",
        "cs.AI"
      ],
      "primary_category": "cs.LG",
      "comment": "18 pages, 16 figures",
      "pdf_url": "http://arxiv.org/pdf/2411.03945v1",
      "published_date": "2024-11-06 14:25:05 UTC",
      "updated_date": "2024-11-06 14:25:05 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-20T21:59:56.162774"
    },
    {
      "arxiv_id": "2411.03941v1",
      "title": "Fine-tuning -- a Transfer Learning approach",
      "title_zh": "微调——一种迁移学习方法",
      "authors": [
        "Joseph Arul Raj",
        "Linglong Qian",
        "Zina Ibrahim"
      ],
      "abstract": "Secondary research use of Electronic Health Records (EHRs) is often hampered\nby the abundance of missing data in this valuable resource. Missingness in EHRs\noccurs naturally as a result of the data recording practices during routine\nclinical care, but handling it is crucial to the precision of medical analysis\nand the decision-making that follows. The literature contains a variety of\nimputation methodologies based on deep neural networks. Those aim to overcome\nthe dynamic, heterogeneous and multivariate missingness patterns of EHRs, which\ncannot be handled by classical and statistical imputation methods. However, all\nexisting deep imputation methods rely on end-to-end pipelines that incorporate\nboth imputation and downstream analyses, e.g. classification. This coupling\nmakes it difficult to assess the quality of imputation and takes away the\nflexibility of re-using the imputer for a different task. Furthermore, most\nend-to-end deep architectures tend to use complex networks to perform the\ndownstream task, in addition to the already sophisticated deep imputation\nnetwork. We, therefore ask if the high performance reported in the literature\nis due to the imputer or the classifier and further ask if an optimised\nstate-of-the-art imputer is used, a simpler classifier can achieve comparable\nperformance. This paper explores the development of a modular, deep\nlearning-based imputation and classification pipeline, specifically built to\nleverage the capabilities of state-of-the-art imputation models for downstream\nclassification tasks. Such a modular approach enables a) objective assessment\nof the quality of the imputer and classifier independently, and b) enables the\nexploration of the performance of simpler classification architectures using an\noptimised imputer.",
      "tldr_zh": "这篇论文探讨了电子健康记录（EHRs）中缺失数据的问题，指出现有深度神经网络插值方法将插值和下游任务（如分类）耦合，导致难以评估插值质量和缺乏灵活性。作者提出了一种模块化的深度学习管道，基于转移学习（Fine-tuning）的理念，利用最先进的插值模型独立处理缺失数据，然后应用于下游分类任务。这种方法允许客观评估插值器和分类器的性能，并探索使用优化插值器时，简单分类架构是否能实现可比性能。最终，该框架提升了插值过程的复用性和整体分析效率。",
      "categories": [
        "cs.LG",
        "cs.AI"
      ],
      "primary_category": "cs.LG",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2411.03941v1",
      "published_date": "2024-11-06 14:18:23 UTC",
      "updated_date": "2024-11-06 14:18:23 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-20T22:00:08.120007"
    },
    {
      "arxiv_id": "2411.03934v1",
      "title": "Interactions Across Blocks in Post-Training Quantization of Large Language Models",
      "title_zh": "后训练量化中大型语言模型的块间交互",
      "authors": [
        "Khasmamad Shabanovi",
        "Lukas Wiest",
        "Vladimir Golkov",
        "Daniel Cremers",
        "Thomas Pfeil"
      ],
      "abstract": "Post-training quantization is widely employed to reduce the computational\ndemands of neural networks. Typically, individual substructures, such as layers\nor blocks of layers, are quantized with the objective of minimizing\nquantization errors in their pre-activations by fine-tuning the corresponding\nweights. Deriving this local objective from the global objective of minimizing\ntask loss involves two key simplifications: assuming substructures are mutually\nindependent and ignoring the knowledge of subsequent substructures as well as\nthe task loss. In this work, we assess the effects of these simplifications on\nweight-only quantization of large language models. We introduce two multi-block\nfine-tuning strategies and compare them against the baseline of fine-tuning\nsingle transformer blocks. The first captures correlations of weights across\nblocks by jointly optimizing multiple quantized blocks. The second incorporates\nknowledge of subsequent blocks by minimizing the error in downstream\npre-activations rather than focusing solely on the quantized block. Our\nfindings indicate that the effectiveness of these methods depends on the\nspecific network model, with no impact on some models but demonstrating\nsignificant benefits for others.",
      "tldr_zh": "本文研究了后训练量化（Post-Training Quantization）在大型语言模型（Large Language Models）中的子结构量化问题，评估了传统方法中假设子结构相互独立并忽略后续子结构和任务损失的简化影响。研究者提出两种多块微调策略：第一种通过联合优化多个Transformer块来捕捉块间权重相关性；第二种通过最小化下游预激活错误来纳入后续块的知识。结果表明，这些策略的有效性取决于具体网络模型，在某些模型上无显著影响，但在其他模型上显示出明显改进。",
      "categories": [
        "cs.LG",
        "cs.AI",
        "cs.CL"
      ],
      "primary_category": "cs.LG",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2411.03934v1",
      "published_date": "2024-11-06 14:11:39 UTC",
      "updated_date": "2024-11-06 14:11:39 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-20T22:01:37.530637"
    },
    {
      "arxiv_id": "2411.04159v1",
      "title": "Cooperation and Personalization on a Seesaw: Choice-based FL for Safe Cooperation in Wireless Networks",
      "title_zh": "翻译失败",
      "authors": [
        "Han Zhang",
        "Medhat Elsayed",
        "Majid Bavand",
        "Raimundas Gaigalas",
        "Yigit Ozcan",
        "Melike Erol-Kantarci"
      ],
      "abstract": "Federated learning (FL) is an innovative distributed artificial intelligence\n(AI) technique. It has been used for interdisciplinary studies in different\nfields such as healthcare, marketing and finance. However the application of FL\nin wireless networks is still in its infancy. In this work, we first overview\nbenefits and concerns when applying FL to wireless networks. Next, we provide a\nnew perspective on existing personalized FL frameworks by analyzing the\nrelationship between cooperation and personalization in these frameworks.\nAdditionally, we discuss the possibility of tuning the cooperation level with a\nchoice-based approach. Our choice-based FL approach is a flexible and safe FL\nframework that allows participants to lower the level of cooperation when they\nfeel unsafe or unable to benefit from the cooperation. In this way, the\nchoice-based FL framework aims to address the safety and fairness concerns in\nFL and protect participants from malicious attacks.",
      "tldr_zh": "该论文探讨了联邦学习（Federated Learning, FL）在无线网络中的应用，概述了其潜在益处（如分布式AI的创新性）和担忧（如安全风险）。作者分析了现有个性化FL框架中合作与个性化的权衡关系，并提出了一种基于选择的FL方法（choice-based FL），允许参与者根据自身安全性和受益程度灵活调整合作水平。最终，该框架旨在提升FL的安全性和公平性，保护参与者免受恶意攻击，从而为无线网络中的FL应用提供更可靠的解决方案。",
      "categories": [
        "cs.NI",
        "cs.AI",
        "cs.DC",
        "cs.LG"
      ],
      "primary_category": "cs.NI",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2411.04159v1",
      "published_date": "2024-11-06 14:09:47 UTC",
      "updated_date": "2024-11-06 14:09:47 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-20T22:01:48.132777"
    },
    {
      "arxiv_id": "2411.03906v2",
      "title": "Lexicalization Is All You Need: Examining the Impact of Lexical Knowledge in a Compositional QALD System",
      "title_zh": "词汇化就是你所需要的全部：考察词汇知识在组合式 QALD 系统中的影响",
      "authors": [
        "David Maria Schmidt",
        "Mohammad Fazleh Elahi",
        "Philipp Cimiano"
      ],
      "abstract": "In this paper, we examine the impact of lexicalization on Question Answering\nover Linked Data (QALD). It is well known that one of the key challenges in\ninterpreting natural language questions with respect to SPARQL lies in bridging\nthe lexical gap, that is mapping the words in the query to the correct\nvocabulary elements. We argue in this paper that lexicalization, that is\nexplicit knowledge about the potential interpretations of a word with respect\nto the given vocabulary, significantly eases the task and increases the\nperformance of QA systems. Towards this goal, we present a compositional QA\nsystem that can leverage explicit lexical knowledge in a compositional manner\nto infer the meaning of a question in terms of a SPARQL query. We show that\nsuch a system, given lexical knowledge, has a performance well beyond current\nQA systems, achieving up to a $35.8\\%$ increase in the micro $F_1$ score\ncompared to the best QA system on QALD-9. This shows the importance and\npotential of including explicit lexical knowledge. In contrast, we show that\nLLMs have limited abilities to exploit lexical knowledge, with only marginal\nimprovements compared to a version without lexical knowledge. This shows that\nLLMs have no ability to compositionally interpret a question on the basis of\nthe meaning of its parts, a key feature of compositional approaches. Taken\ntogether, our work shows new avenues for QALD research, emphasizing the\nimportance of lexicalization and compositionality.",
      "tldr_zh": "本文探讨了在 Question Answering over Linked Data (QALD) 系统中的 lexicalization（词汇化）对性能的影响，强调显式 lexical knowledge（词汇知识）能有效桥接词汇差距并提升问题解释能力。作者提出一个 compositional QA system（组合式 QA 系统），通过整合词汇知识来组合式推断自然语言问题并生成对应的 SPARQL 查询。实验结果显示，该系统在 QALD-9 数据集上比最佳现有系统提高了 35.8% 的 micro F1 分数。相比之下，大型语言模型（LLMs）在利用词汇知识时仅获得微小改善，暴露了其缺乏组合式解释能力。该研究突出了 lexicalization 和 compositionality（组合性）的重要性，为 QALD 领域开辟新研究路径。",
      "categories": [
        "cs.AI",
        "cs.CL",
        "cs.IR"
      ],
      "primary_category": "cs.AI",
      "comment": "24th International Conference on Knowledge Engineering and Knowledge\n  Management (EKAW 2024), November 26-28, 2024, Amsterdam, The Netherlands",
      "pdf_url": "http://arxiv.org/pdf/2411.03906v2",
      "published_date": "2024-11-06 13:37:28 UTC",
      "updated_date": "2024-12-05 12:56:40 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-20T22:02:02.655138"
    },
    {
      "arxiv_id": "2411.03885v1",
      "title": "Disability data futures: Achievable imaginaries for AI and disability data justice",
      "title_zh": "翻译失败",
      "authors": [
        "Denis Newman-Griffis",
        "Bonnielin Swenor",
        "Rupa Valdez",
        "Gillian Mason"
      ],
      "abstract": "Data are the medium through which individuals' identities and experiences are\nfiltered in contemporary states and systems, and AI is increasingly the layer\nmediating between people, data, and decisions. The history of data and AI is\noften one of disability exclusion, oppression, and the reduction of disabled\nexperience; left unchallenged, the current proliferation of AI and data systems\nthus risks further automating ableism behind the veneer of algorithmic\nneutrality. However, exclusionary histories do not preclude inclusive futures,\nand disability-led visions can chart new paths for collective action to achieve\nfutures founded in disability justice. This chapter brings together four\nacademics and disability advocates working at the nexus of disability, data,\nand AI, to describe achievable imaginaries for artificial intelligence and\ndisability data justice. Reflecting diverse contexts, disciplinary\nperspectives, and personal experiences, we draw out the shape, actors, and\ngoals of imagined future systems where data and AI support movement towards\ndisability justice.",
      "tldr_zh": "本研究探讨了数据和AI在当代社会中如何过滤个体身份和经历，但历史中数据和AI往往导致残疾群体的排斥、压迫和经历简化，从而可能在算法中自动化歧视。作者汇集了四位在残疾、数据和AI交叉领域的学者和倡导者，基于多样化的背景和经验，提出可实现的可想象未来愿景。研究强调通过残疾主导的集体行动，设计数据和AI系统来支持向disability justice（残疾公正）迈进，确保这些系统促进包容而非强化ableism（能力主义）。这为实现AI和数据在残疾公正中的积极作用提供了可行的路径。",
      "categories": [
        "cs.HC",
        "cs.AI"
      ],
      "primary_category": "cs.HC",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2411.03885v1",
      "published_date": "2024-11-06 13:04:29 UTC",
      "updated_date": "2024-11-06 13:04:29 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-20T22:02:12.357809"
    },
    {
      "arxiv_id": "2411.03884v3",
      "title": "Polynomial Composition Activations: Unleashing the Dynamics of Large Language Models",
      "title_zh": "翻译失败",
      "authors": [
        "Zhijian Zhuo",
        "Ya Wang",
        "Yutao Zeng",
        "Xiaoqing Li",
        "Xun Zhou",
        "Jinwen Ma"
      ],
      "abstract": "Transformers have found extensive applications across various domains due to\nthe powerful fitting capabilities. This success can be partially attributed to\ntheir inherent nonlinearity. Thus, in addition to the ReLU function employed in\nthe original transformer architecture, researchers have explored alternative\nmodules such as GeLU and SwishGLU to enhance nonlinearity and thereby augment\nrepresentational capacity. In this paper, we propose a novel category of\npolynomial composition activations (PolyCom), designed to optimize the dynamics\nof transformers. Theoretically, we provide a comprehensive mathematical\nanalysis of PolyCom, highlighting its enhanced expressivity and efficacy\nrelative to other activation functions. Notably, we demonstrate that networks\nincorporating PolyCom achieve the $\\textbf{optimal approximation rate}$,\nindicating that PolyCom networks require minimal parameters to approximate\ngeneral smooth functions in Sobolev spaces. We conduct empirical experiments on\nthe pre-training configurations of large language models (LLMs), including both\ndense and sparse architectures. By substituting conventional activation\nfunctions with PolyCom, we enable LLMs to capture higher-order interactions\nwithin the data, thus improving performance metrics in terms of accuracy and\nconvergence rates. Extensive experimental results demonstrate the effectiveness\nof our method, showing substantial improvements over other activation\nfunctions. Code is available at https://github.com/BryceZhuo/PolyCom.",
      "tldr_zh": "本论文提出了一种新型激活函数——Polynomial Composition Activations (PolyCom)，旨在优化Transformer模型的动态性能，以提升大型语言模型（LLMs）的表示能力。理论分析显示，PolyCom 相比 ReLU、GeLU 和 SwishGLU 等函数，具有更强的表达性和最优逼近率，能够使用更少的参数逼近 Sobolev 空间中的光滑函数。实验结果表明，在 LLMs 的预训练中，使用 PolyCom 替换传统激活函数后，模型在密集和稀疏架构上实现了更高的准确性和更快收敛率，并展示了显著的性能提升。",
      "categories": [
        "cs.CL",
        "cs.AI",
        "cs.LG"
      ],
      "primary_category": "cs.CL",
      "comment": "Accepted by ICLR 2025",
      "pdf_url": "http://arxiv.org/pdf/2411.03884v3",
      "published_date": "2024-11-06 13:00:34 UTC",
      "updated_date": "2025-03-20 09:46:11 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-20T22:02:25.847573"
    },
    {
      "arxiv_id": "2411.03883v3",
      "title": "MEG: Medical Knowledge-Augmented Large Language Models for Question Answering",
      "title_zh": "翻译失败",
      "authors": [
        "Laura Cabello",
        "Carmen Martin-Turrero",
        "Uchenna Akujuobi",
        "Anders Søgaard",
        "Carlos Bobed"
      ],
      "abstract": "Question answering is a natural language understanding task that involves\nreasoning over both explicit context, and unstated relevant domain knowledge.\nDespite the high cost of training, large language models (LLMs) -- the backbone\nof most modern question-answering systems -- still struggle to reliably capture\nthe nuanced relationships between concepts that are crucial for reasoning in\nspecialized fields like medicine. In this work, we present MEG, a\nparameter-efficient approach for medical knowledge-augmented LLMs. MEG uses a\nlightweight mapping network to incorporate knowledge graph embeddings into the\nLLM, enabling it to leverage external knowledge in a cost-effective way. We\nevaluate our method on four popular medical multiple-choice datasets and show\nthat LLMs i) can effectively interpret knowledge graph embeddings and ii) gain\nsignificant advantages from the factual grounding these embeddings provide. MEG\nattains an average of +6.7% and +9.9% accuracy over specialized models like\nBioMistral-7B and MediTron-7B, respectively. Finally, we show that MEG's\nperformance remains robust to the choice of graph encoder.",
      "tldr_zh": "本研究提出MEG，一种参数高效的方法，用于在Large Language Models (LLMs)中整合医疗知识图嵌入(knowledge graph embeddings)，以提升医学问答任务的性能。MEG通过一个轻量级映射网络，将外部知识融入LLMs，帮助模型更好地捕捉概念间的细微关系，并在四个医疗多选数据集上进行评估。结果显示，MEG比BioMistral-7B和MediTron-7B等专业模型分别提高了平均6.7%和9.9%的准确率，且其性能对图编码器的选择具有鲁棒性。总的来说，该方法为LLMs提供事实基础，提高了在专业领域如医学的推理能力。",
      "categories": [
        "cs.CL",
        "cs.AI",
        "cs.LG"
      ],
      "primary_category": "cs.CL",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2411.03883v3",
      "published_date": "2024-11-06 12:57:58 UTC",
      "updated_date": "2025-04-22 19:33:54 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-20T22:02:37.441188"
    },
    {
      "arxiv_id": "2411.03866v2",
      "title": "Performance evaluation of SLAM-ASR: The Good, the Bad, the Ugly, and the Way Forward",
      "title_zh": "翻译失败",
      "authors": [
        "Shashi Kumar",
        "Iuliia Thorbecke",
        "Sergio Burdisso",
        "Esaú Villatoro-Tello",
        "Manjunath K E",
        "Kadri Hacioğlu",
        "Pradeep Rangappa",
        "Petr Motlicek",
        "Aravind Ganapathiraju",
        "Andreas Stolcke"
      ],
      "abstract": "Recent research has demonstrated that training a linear connector between\nspeech foundation encoders and large language models (LLMs) enables this\narchitecture to achieve strong ASR capabilities. Despite the impressive\nresults, it remains unclear whether these simple approaches are robust enough\nacross different scenarios and speech conditions, such as domain shifts and\nspeech perturbations. In this paper, we address these questions by conducting\nvarious ablation experiments using a recent and widely adopted approach called\nSLAM-ASR. We present novel empirical findings that offer insights on how to\neffectively utilize the SLAM-ASR architecture across a wide range of settings.\nOur main findings indicate that SLAM-ASR exhibits poor performance in\ncross-domain evaluation settings. Additionally, speech perturbations on\nin-domain data, such as changes in speech rate or additive noise, can\nsignificantly degrade performance. Our findings offer critical insights for\nfine-tuning and configuring robust LLM-based ASR models, tailored to different\ndata characteristics and computational resources.",
      "tldr_zh": "这篇论文评估了 SLAM-ASR 架构的性能，该架构通过线性连接器将语音基础编码器和大型语言模型 (LLMs) 结合，以实现强有力的自动语音识别 (ASR) 能力。研究者通过各种消融实验，检验了 SLAM-ASR 在领域转移和语音扰动（如语速变化或添加噪声）等场景下的鲁棒性，发现其在跨领域评估中表现不佳，且这些扰动会显著降低模型性能。最终，论文提供了关键见解，包括针对不同数据特性和计算资源的微调策略，以提升 LLM-based ASR 模型的可靠性和适用性。",
      "categories": [
        "cs.CL",
        "cs.AI",
        "cs.SD",
        "eess.AS"
      ],
      "primary_category": "cs.CL",
      "comment": "Accepted in ICASSP 2025 SALMA Workshop",
      "pdf_url": "http://arxiv.org/pdf/2411.03866v2",
      "published_date": "2024-11-06 12:22:04 UTC",
      "updated_date": "2025-01-22 09:48:34 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-20T22:04:28.604641"
    },
    {
      "arxiv_id": "2411.03865v5",
      "title": "AdaSociety: An Adaptive Environment with Social Structures for Multi-Agent Decision-Making",
      "title_zh": "翻译失败",
      "authors": [
        "Yizhe Huang",
        "Xingbo Wang",
        "Hao Liu",
        "Fanqi Kong",
        "Aoyang Qin",
        "Min Tang",
        "Song-Chun Zhu",
        "Mingjie Bi",
        "Siyuan Qi",
        "Xue Feng"
      ],
      "abstract": "Traditional interactive environments limit agents' intelligence growth with\nfixed tasks. Recently, single-agent environments address this by generating new\ntasks based on agent actions, enhancing task diversity. We consider the\ndecision-making problem in multi-agent settings, where tasks are further\ninfluenced by social connections, affecting rewards and information access.\nHowever, existing multi-agent environments lack a combination of adaptive\nphysical surroundings and social connections, hindering the learning of\nintelligent behaviors. To address this, we introduce AdaSociety, a customizable\nmulti-agent environment featuring expanding state and action spaces, alongside\nexplicit and alterable social structures. As agents progress, the environment\nadaptively generates new tasks with social structures for agents to undertake.\nIn AdaSociety, we develop three mini-games showcasing distinct social\nstructures and tasks. Initial results demonstrate that specific social\nstructures can promote both individual and collective benefits, though current\nreinforcement learning and LLM-based algorithms show limited effectiveness in\nleveraging social structures to enhance performance. Overall, AdaSociety serves\nas a valuable research platform for exploring intelligence in diverse physical\nand social settings. The code is available at\nhttps://github.com/bigai-ai/AdaSociety.",
      "tldr_zh": "本文提出 AdaSociety，一种自适应多代理环境，结合扩展的状态和动作空间以及显式可变的社交结构，以解决传统多代理决策问题中任务固定和社交影响缺失的局限。环境通过代理行为动态生成新任务，并融入社会连接来影响奖励和信息访问；在三个迷你游戏中，实验结果显示特定社交结构能促进个体和集体利益，但现有强化学习和LLM-based算法在利用这些结构提升性能方面效果有限。总体上，AdaSociety 作为研究平台，有助于探索多代理智能在多样物理和社会设置中的决策优化，并提供开源代码支持。",
      "categories": [
        "cs.MA",
        "cs.AI",
        "cs.GT",
        "cs.LG",
        "cs.SI"
      ],
      "primary_category": "cs.MA",
      "comment": "Accepted at NeurIPS D&B 2024",
      "pdf_url": "http://arxiv.org/pdf/2411.03865v5",
      "published_date": "2024-11-06 12:19:01 UTC",
      "updated_date": "2025-01-29 12:52:53 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-20T22:03:01.704461"
    },
    {
      "arxiv_id": "2411.03862v2",
      "title": "ROBIN: Robust and Invisible Watermarks for Diffusion Models with Adversarial Optimization",
      "title_zh": "翻译失败",
      "authors": [
        "Huayang Huang",
        "Yu Wu",
        "Qian Wang"
      ],
      "abstract": "Watermarking generative content serves as a vital tool for authentication,\nownership protection, and mitigation of potential misuse. Existing watermarking\nmethods face the challenge of balancing robustness and concealment. They\nempirically inject a watermark that is both invisible and robust and passively\nachieve concealment by limiting the strength of the watermark, thus reducing\nthe robustness. In this paper, we propose to explicitly introduce a watermark\nhiding process to actively achieve concealment, thus allowing the embedding of\nstronger watermarks. To be specific, we implant a robust watermark in an\nintermediate diffusion state and then guide the model to hide the watermark in\nthe final generated image. We employ an adversarial optimization algorithm to\nproduce the optimal hiding prompt guiding signal for each watermark. The prompt\nembedding is optimized to minimize artifacts in the generated image, while the\nwatermark is optimized to achieve maximum strength. The watermark can be\nverified by reversing the generation process. Experiments on various diffusion\nmodels demonstrate the watermark remains verifiable even under significant\nimage tampering and shows superior invisibility compared to other\nstate-of-the-art robust watermarking methods. Code is available at\nhttps://github.com/Hannah1102/ROBIN.",
      "tldr_zh": "这篇论文提出了 ROBIN 框架，一种用于扩散模型的鲁棒且隐蔽水印方法，通过对抗优化算法（adversarial optimization）显式引入水印隐藏过程，以平衡水印强度和隐蔽性。具体而言，ROBIN 在扩散模型的中间状态植入鲁棒水印，然后优化隐藏提示来最小化生成图像中的伪影，同时最大化水印强度，水印可通过逆转生成过程进行验证。实验结果显示，该方法在各种扩散模型上表现出色，即使图像遭受显著篡改，水印仍可被验证，且隐蔽性优于现有最先进鲁棒水印技术。",
      "categories": [
        "cs.CV",
        "cs.AI",
        "cs.CR"
      ],
      "primary_category": "cs.CV",
      "comment": "Accept to NeurIPS 2024",
      "pdf_url": "http://arxiv.org/pdf/2411.03862v2",
      "published_date": "2024-11-06 12:14:23 UTC",
      "updated_date": "2025-04-03 03:11:31 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-20T22:03:14.291991"
    },
    {
      "arxiv_id": "2411.03859v2",
      "title": "UniTraj: Learning a Universal Trajectory Foundation Model from Billion-Scale Worldwide Traces",
      "title_zh": "翻译失败",
      "authors": [
        "Yuanshao Zhu",
        "James Jianqiao Yu",
        "Xiangyu Zhao",
        "Xuetao Wei",
        "Yuxuan Liang"
      ],
      "abstract": "Human trajectory modeling is essential for deciphering movement patterns and\nsupporting advanced applications across various domains. However, existing\nmethods are often tailored to specific tasks and regions, resulting in\nlimitations related to task specificity, regional dependency, and data quality\nsensitivity. Addressing these challenges requires a universal human trajectory\nfoundation model capable of generalizing and scaling across diverse tasks and\ngeographic contexts. To this end, we propose UniTraj, a Universal human\nTrajectory foundation model that is task-adaptive, region-independent, and\nhighly generalizable. To further enhance performance, we construct WorldTrace,\nthe first large-scale, high-quality, globally distributed dataset sourced from\nopen web platforms, encompassing 2.45 million trajectories with billions of\npoints across 70 countries. Through multiple resampling and masking strategies\ndesigned for pre-training, UniTraj effectively overcomes geographic and task\nconstraints, adapting to heterogeneous data quality. Extensive experiments\nacross multiple trajectory analysis tasks and real-world datasets demonstrate\nthat UniTraj consistently outperforms existing approaches in terms of\nscalability and adaptability. These results underscore the potential of UniTraj\nas a versatile, robust solution for a wide range of trajectory analysis\napplications, with WorldTrace serving as an ideal but non-exclusive foundation\nfor training.",
      "tldr_zh": "该研究针对现有人类轨迹建模方法的任务特定性、区域依赖性和数据质量敏感性等问题，提出UniTraj，一种通用轨迹基础模型（trajectory foundation model），该模型具有任务自适应、区域独立和高泛化能力。研究者构建了WorldTrace数据集，这是首个大规模、高质量的全球分布数据集，包含2.45百万轨迹和数十亿点，覆盖70个国家，并通过多种重采样和掩码策略进行预训练，以克服地理和任务约束。在多个轨迹分析任务和真实数据集上的实验表明，UniTraj在可扩展性和适应性方面均优于现有方法，为广泛的轨迹应用提供了一个鲁棒解决方案。",
      "categories": [
        "cs.ET",
        "cs.AI",
        "cs.LG",
        "cs.SI",
        "physics.soc-ph"
      ],
      "primary_category": "cs.ET",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2411.03859v2",
      "published_date": "2024-11-06 12:06:43 UTC",
      "updated_date": "2024-11-16 06:53:43 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-20T22:04:28.276843"
    },
    {
      "arxiv_id": "2411.03855v3",
      "title": "MambaPEFT: Exploring Parameter-Efficient Fine-Tuning for Mamba",
      "title_zh": "MambaPEFT：探索 Mamba 的参数高效微调",
      "authors": [
        "Masakazu Yoshimura",
        "Teruaki Hayashi",
        "Yota Maeda"
      ],
      "abstract": "An ecosystem of Transformer-based models has been established by building\nlarge models with extensive data. Parameter-efficient fine-tuning (PEFT) is a\ncrucial technology for deploying these models to downstream tasks with minimal\ncost while achieving effective performance. Recently, Mamba, a State Space\nModel (SSM)-based model, has attracted attention as a potential alternative to\nTransformers. While many large-scale Mamba-based models have been proposed,\nefficiently adapting pre-trained Mamba-based models to downstream tasks remains\nunexplored. In this paper, we conduct an exploratory analysis of PEFT methods\nfor Mamba. We investigate the effectiveness of existing PEFT methods for\nTransformers when applied to Mamba. We also modify these methods to better\nalign with the Mamba architecture. Additionally, we propose new Mamba-specific\nPEFT methods that leverage the distinctive structure of Mamba. Our experiments\nindicate that PEFT performs more effectively for Mamba than Transformers.\nLastly, we demonstrate how to effectively combine multiple PEFT methods and\nprovide a framework that outperforms previous works. To ensure reproducibility,\nwe will release the code after publication.",
      "tldr_zh": "本论文探讨了参数高效微调 (PEFT) 在 Mamba 模型上的应用，Mamba 是一种基于 State Space Model (SSM) 的潜在 Transformer 替代方案，以高效适应下游任务。研究团队评估了现有 PEFT 方法在 Mamba 上的有效性，并对其进行了修改以匹配 Mamba 的独特架构，同时提出了新的 Mamba-specific PEFT 方法。实验结果显示，PEFT 在 Mamba 上比在 Transformer 上表现更优越，且通过组合多种 PEFT 方法，构建了一个超越先前作品的框架。该框架的代码将发布以确保可重复性。",
      "categories": [
        "cs.CL",
        "cs.AI",
        "cs.CV",
        "cs.LG"
      ],
      "primary_category": "cs.CL",
      "comment": "Accepted to ICLR2025",
      "pdf_url": "http://arxiv.org/pdf/2411.03855v3",
      "published_date": "2024-11-06 11:57:55 UTC",
      "updated_date": "2025-04-01 08:41:31 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-20T22:03:37.991073"
    },
    {
      "arxiv_id": "2411.03847v1",
      "title": "A Novel Access Control and Privacy-Enhancing Approach for Models in Edge Computing",
      "title_zh": "一种针对边缘计算中模型的访问控制和隐私增强方法",
      "authors": [
        "Peihao Li"
      ],
      "abstract": "With the widespread adoption of edge computing technologies and the\nincreasing prevalence of deep learning models in these environments, the\nsecurity risks and privacy threats to models and data have grown more acute.\nAttackers can exploit various techniques to illegally obtain models or misuse\ndata, leading to serious issues such as intellectual property infringement and\nprivacy breaches. Existing model access control technologies primarily rely on\ntraditional encryption and authentication methods; however, these approaches\nexhibit significant limitations in terms of flexibility and adaptability in\ndynamic environments. Although there have been advancements in model\nwatermarking techniques for marking model ownership, they remain limited in\ntheir ability to proactively protect intellectual property and prevent\nunauthorized access. To address these challenges, we propose a novel model\naccess control method tailored for edge computing environments. This method\nleverages image style as a licensing mechanism, embedding style recognition\ninto the model's operational framework to enable intrinsic access control.\nConsequently, models deployed on edge platforms are designed to correctly infer\nonly on license data with specific style, rendering them ineffective on any\nother data. By restricting the input data to the edge model, this approach not\nonly prevents attackers from gaining unauthorized access to the model but also\nenhances the privacy of data on terminal devices. We conducted extensive\nexperiments on benchmark datasets, including MNIST, CIFAR-10, and FACESCRUB,\nand the results demonstrate that our method effectively prevents unauthorized\naccess to the model while maintaining accuracy. Additionally, the model shows\nstrong resistance against attacks such as forged licenses and fine-tuning.\nThese results underscore the method's usability, security, and robustness.",
      "tldr_zh": "本研究针对边缘计算环境中深度学习模型的安全风险和隐私威胁，提出了一种新型访问控制方法，该方法使用图像风格作为许可机制，将风格识别嵌入模型框架中，使模型仅对特定风格的许可数据进行正确推理，从而防止未授权访问。\n这种方法通过限制输入数据，不仅保护模型知识产权，还提升了终端设备的数据隐私。\n实验在MNIST、CIFAR-10和FACESCRUB基准数据集上验证了其有效性，模型准确性保持不变，并显示出对伪造许可和微调攻击的强抵抗力。",
      "categories": [
        "cs.CR",
        "cs.AI"
      ],
      "primary_category": "cs.CR",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2411.03847v1",
      "published_date": "2024-11-06 11:37:30 UTC",
      "updated_date": "2024-11-06 11:37:30 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-20T22:04:40.186591"
    },
    {
      "arxiv_id": "2411.03845v2",
      "title": "Reconsidering the Performance of GAE in Link Prediction",
      "title_zh": "翻译失败",
      "authors": [
        "Weishuo Ma",
        "Yanbo Wang",
        "Xiyuan Wang",
        "Muhan Zhang"
      ],
      "abstract": "Various graph neural networks (GNNs) with advanced training techniques and\nmodel designs have been proposed for link prediction tasks. However, outdated\nbaseline models may lead to an overestimation of the benefits provided by these\nnovel approaches. To address this, we systematically investigate the potential\nof Graph Autoencoders (GAE) by meticulously tuning hyperparameters and\nutilizing the trick of orthogonal embedding and linear propagation. Our\nfindings reveal that a well-optimized GAE can match the performance of more\ncomplex models while offering greater computational efficiency.",
      "tldr_zh": "该研究重新审视了图自编码器(GAE)在链接预测任务中的性能，指出过时的基线模型可能导致新方法优势被高估。研究者通过系统优化GAE，包括微调超参数、应用正交嵌入(orthogonal embedding)和线性传播(linear propagation)技巧，来提升其表现。结果显示，优化后的GAE能够与更复杂的图神经网络(GNNs)模型匹敌，同时提供更高的计算效率，这为链接预测任务提供了更高效的解决方案。",
      "categories": [
        "cs.LG",
        "cs.AI"
      ],
      "primary_category": "cs.LG",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2411.03845v2",
      "published_date": "2024-11-06 11:29:47 UTC",
      "updated_date": "2025-02-24 06:04:27 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-20T22:04:50.907809"
    },
    {
      "arxiv_id": "2411.03823v2",
      "title": "Both Text and Images Leaked! A Systematic Analysis of Multimodal LLM Data Contamination",
      "title_zh": "翻译失败",
      "authors": [
        "Dingjie Song",
        "Sicheng Lai",
        "Shunian Chen",
        "Lichao Sun",
        "Benyou Wang"
      ],
      "abstract": "The rapid progression of multimodal large language models (MLLMs) has\ndemonstrated superior performance on various multimodal benchmarks. However,\nthe issue of data contamination during training creates challenges in\nperformance evaluation and comparison. While numerous methods exist for\ndetecting models' contamination in large language models (LLMs), they are less\neffective for MLLMs due to their various modalities and multiple training\nphases. In this study, we introduce a multimodal data contamination detection\nframework, MM-Detect, designed for MLLMs. Our experimental results indicate\nthat MM-Detect is quite effective and sensitive in identifying varying degrees\nof contamination, and can highlight significant performance improvements due to\nthe leakage of multimodal benchmark training sets. Furthermore, we explore\nwhether the contamination originates from the base LLMs used by MLLMs or the\nmultimodal training phase, providing new insights into the stages at which\ncontamination may be introduced.",
      "tldr_zh": "该研究系统分析了多模态大型语言模型（MLLMs）的训练数据污染问题，指出现有检测方法对LLMs有效，但因MLLMs的多模态和多阶段训练而失效。研究者引入了MM-Detect框架，该框架针对MLLMs设计，能敏感地识别不同程度的污染并突出基准训练集泄露导致的性能提升。通过实验，MM-Detect证明了其有效性，并探讨了污染可能源于基础LLMs或多模态训练阶段，提供新的见解以改进模型评估。",
      "categories": [
        "cs.CV",
        "cs.AI",
        "cs.CL",
        "cs.MM"
      ],
      "primary_category": "cs.CV",
      "comment": "Code Available: https://github.com/MLLM-Data-Contamination/MM-Detect",
      "pdf_url": "http://arxiv.org/pdf/2411.03823v2",
      "published_date": "2024-11-06 10:44:15 UTC",
      "updated_date": "2025-02-17 18:29:13 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-20T22:05:03.364938"
    },
    {
      "arxiv_id": "2411.03820v1",
      "title": "Beyond The Rainbow: High Performance Deep Reinforcement Learning On A Desktop PC",
      "title_zh": "翻译失败",
      "authors": [
        "Tyler Clark",
        "Mark Towers",
        "Christine Evers",
        "Jonathon Hare"
      ],
      "abstract": "Rainbow Deep Q-Network (DQN) demonstrated combining multiple independent\nenhancements could significantly boost a reinforcement learning (RL) agent's\nperformance. In this paper, we present \"Beyond The Rainbow\" (BTR), a novel\nalgorithm that integrates six improvements from across the RL literature to\nRainbow DQN, establishing a new state-of-the-art for RL using a desktop PC,\nwith a human-normalized interquartile mean (IQM) of 7.4 on atari-60. Beyond\nAtari, we demonstrate BTR's capability to handle complex 3D games, successfully\ntraining agents to play Super Mario Galaxy, Mario Kart, and Mortal Kombat with\nminimal algorithmic changes. Designing BTR with computational efficiency in\nmind, agents can be trained using a desktop PC on 200 million Atari frames\nwithin 12 hours. Additionally, we conduct detailed ablation studies of each\ncomponent, analzying the performance and impact using numerous measures.",
      "tldr_zh": "该论文提出了 Beyond The Rainbow (BTR) 算法，将六个强化学习 (RL) 文献中的改进整合到 Rainbow DQN 中，显著提升了 RL 代理的性能。\nBTR 在 Atari-60 上达到了新的 state-of-the-art 水平，人性化标准化四分位均值 (IQM) 为 7.4。\n此外，该算法成功扩展到复杂 3D 游戏，如 Super Mario Galaxy、Mario Kart 和 Mortal Kombat，仅需最小修改，并通过桌面 PC 在 12 小时内训练 2 亿 Atari 帧，展示了高效计算能力。\n论文还进行了详细的消融研究，分析了每个组件对性能的影响。",
      "categories": [
        "cs.AI",
        "cs.LG"
      ],
      "primary_category": "cs.AI",
      "comment": "9 main pages, 26 total. Currently under review at ICLR",
      "pdf_url": "http://arxiv.org/pdf/2411.03820v1",
      "published_date": "2024-11-06 10:42:04 UTC",
      "updated_date": "2024-11-06 10:42:04 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-20T22:07:07.623246"
    },
    {
      "arxiv_id": "2411.03817v3",
      "title": "From Novice to Expert: LLM Agent Policy Optimization via Step-wise Reinforcement Learning",
      "title_zh": "翻译失败",
      "authors": [
        "Zhirui Deng",
        "Zhicheng Dou",
        "Yutao Zhu",
        "Ji-Rong Wen",
        "Ruibin Xiong",
        "Mang Wang",
        "Weipeng Chen"
      ],
      "abstract": "The outstanding capabilities of large language models (LLMs) render them a\ncrucial component in various autonomous agent systems. While traditional\nmethods depend on the inherent knowledge of LLMs without fine-tuning, more\nrecent approaches have shifted toward the reinforcement learning strategy to\nfurther enhance agents' ability to solve complex interactive tasks with\nenvironments and tools. However, previous approaches are constrained by the\nsparse reward issue, where existing datasets solely provide a final scalar\nreward for each multi-step reasoning chain, potentially leading to\nineffectiveness and inefficiency in policy learning. In this paper, we\nintroduce StepAgent, which utilizes step-wise reward to optimize the agent's\nreinforcement learning process. Inheriting the spirit of novice-to-expert\ntheory, we first compare the actions of the expert and the agent to\nautomatically generate intermediate rewards for fine-grained optimization.\nAdditionally, we propose implicit-reward and inverse reinforcement learning\ntechniques to facilitate agent reflection and policy adjustment. Further\ntheoretical analysis demonstrates that the action distribution of the agent can\nconverge toward the expert action distribution over multiple training cycles.\nExperimental results across various datasets indicate that StepAgent\noutperforms existing baseline methods.",
      "tldr_zh": "这篇论文提出 StepAgent，一种基于步进式奖励(step-wise reward)的强化学习方法，用于优化大型语言模型(LLM)代理的政策，使其从新手逐步提升到专家水平，以解决传统方法中稀疏奖励问题导致的学习低效问题。StepAgent 通过比较专家和代理的动作自动生成中间奖励，并结合隐式奖励(implicit-reward)和逆强化学习(inverse reinforcement learning)技术，促进代理的反思和策略调整。理论分析表明，代理的动作分布可在多次训练中收敛于专家分布，实验结果显示 StepAgent 在多种数据集上优于现有基线方法。",
      "categories": [
        "cs.AI",
        "cs.CL",
        "cs.HC",
        "cs.RO"
      ],
      "primary_category": "cs.AI",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2411.03817v3",
      "published_date": "2024-11-06 10:35:11 UTC",
      "updated_date": "2024-12-09 09:20:11 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-20T22:07:06.929897"
    },
    {
      "arxiv_id": "2411.03814v2",
      "title": "MRJ-Agent: An Effective Jailbreak Agent for Multi-Round Dialogue",
      "title_zh": "MRJ-Agent：用于多轮对话的有效越狱代理",
      "authors": [
        "Fengxiang Wang",
        "Ranjie Duan",
        "Peng Xiao",
        "Xiaojun Jia",
        "Shiji Zhao",
        "Cheng Wei",
        "YueFeng Chen",
        "Chongwen Wang",
        "Jialing Tao",
        "Hang Su",
        "Jun Zhu",
        "Hui Xue"
      ],
      "abstract": "Large Language Models (LLMs) demonstrate outstanding performance in their\nreservoir of knowledge and understanding capabilities, but they have also been\nshown to be prone to illegal or unethical reactions when subjected to jailbreak\nattacks. To ensure their responsible deployment in critical applications, it is\ncrucial to understand the safety capabilities and vulnerabilities of LLMs.\nPrevious works mainly focus on jailbreak in single-round dialogue, overlooking\nthe potential jailbreak risks in multi-round dialogues, which are a vital way\nhumans interact with and extract information from LLMs. Some studies have\nincreasingly concentrated on the risks associated with jailbreak in multi-round\ndialogues. These efforts typically involve the use of manually crafted\ntemplates or prompt engineering techniques. However, due to the inherent\ncomplexity of multi-round dialogues, their jailbreak performance is limited. To\nsolve this problem, we propose a novel multi-round dialogue jailbreaking agent,\nemphasizing the importance of stealthiness in identifying and mitigating\npotential threats to human values posed by LLMs. We propose a risk\ndecomposition strategy that distributes risks across multiple rounds of queries\nand utilizes psychological strategies to enhance attack strength. Extensive\nexperiments show that our proposed method surpasses other attack methods and\nachieves state-of-the-art attack success rate. We will make the corresponding\ncode and dataset available for future research. The code will be released soon.",
      "tldr_zh": "本研究探讨了大语言模型(LLMs)在多轮对话中面临的jailbreak攻击风险，这些攻击可能导致非法或不道德的响应，而现有方法主要依赖手动模板或提示工程，效果有限。论文提出MRJ-Agent，一种新型多轮对话jailbreaking代理，通过风险分解策略将风险分布到多个查询轮次，并结合心理策略增强攻击的隐蔽性和强度。实验结果显示，该方法在攻击成功率上超越了其他方法，达到了最先进的水平，并计划发布相关代码和数据集以支持未来研究。",
      "categories": [
        "cs.AI",
        "cs.CL",
        "cs.CR"
      ],
      "primary_category": "cs.AI",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2411.03814v2",
      "published_date": "2024-11-06 10:32:09 UTC",
      "updated_date": "2025-01-07 07:46:16 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-20T22:05:40.005821"
    },
    {
      "arxiv_id": "2411.04156v1",
      "title": "Crystal: Illuminating LLM Abilities on Language and Code",
      "title_zh": "Crystal：揭示大语言模型在语言和代码方面的能力",
      "authors": [
        "Tianhua Tao",
        "Junbo Li",
        "Bowen Tan",
        "Hongyi Wang",
        "William Marshall",
        "Bhargav M Kanakiya",
        "Joel Hestness",
        "Natalia Vassilieva",
        "Zhiqiang Shen",
        "Eric P. Xing",
        "Zhengzhong Liu"
      ],
      "abstract": "Large Language Models (LLMs) specializing in code generation (which are also\noften referred to as code LLMs), e.g., StarCoder and Code Llama, play\nincreasingly critical roles in various software development scenarios. It is\nalso crucial for code LLMs to possess both code generation and natural language\nabilities for many specific applications, such as code snippet retrieval using\nnatural language or code explanations. The intricate interaction between\nacquiring language and coding skills complicates the development of strong code\nLLMs. Furthermore, there is a lack of thorough prior studies on the LLM\npretraining strategy that mixes code and natural language. In this work, we\npropose a pretraining strategy to enhance the integration of natural language\nand coding capabilities within a single LLM. Specifically, it includes two\nphases of training with appropriately adjusted code/language ratios. The\nresulting model, Crystal, demonstrates remarkable capabilities in both domains.\nSpecifically, it has natural language and coding performance comparable to that\nof Llama 2 and Code Llama, respectively. Crystal exhibits better data\nefficiency, using 1.4 trillion tokens compared to the more than 2 trillion\ntokens used by Llama 2 and Code Llama. We verify our pretraining strategy by\nanalyzing the training process and observe consistent improvements in most\nbenchmarks. We also adopted a typical application adaptation phase with a\ncode-centric data mixture, only to find that it did not lead to enhanced\nperformance or training efficiency, underlining the importance of a carefully\ndesigned data recipe. To foster research within the community, we commit to\nopen-sourcing every detail of the pretraining, including our training datasets,\ncode, loggings and 136 checkpoints throughout the training.",
      "tldr_zh": "这篇论文提出了一种预训练策略，用于提升 Large Language Models (LLMs) 在代码生成和自然语言处理方面的能力，针对如 StarCoder 和 Code Llama 等模型的局限性。策略包括两个训练阶段，通过调整代码/语言数据比例，开发出 Crystal 模型，该模型在自然语言性能上与 Llama 2 相当，在代码性能上与 Code Llama 相当，且仅使用 1.4 万亿 tokens，显示出更高的数据效率。实验分析验证了该策略的有效性，并强调了精心设计的数据混合配方的关键作用；作者承诺开源所有训练细节，包括数据集、代码和检查点，以推动社区研究。",
      "categories": [
        "cs.SE",
        "cs.AI",
        "cs.CL"
      ],
      "primary_category": "cs.SE",
      "comment": "Published as a conference paper at COLM 2024",
      "pdf_url": "http://arxiv.org/pdf/2411.04156v1",
      "published_date": "2024-11-06 10:28:46 UTC",
      "updated_date": "2024-11-06 10:28:46 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-20T22:05:52.446936"
    },
    {
      "arxiv_id": "2411.03807v3",
      "title": "GS2Pose: Two-stage 6D Object Pose Estimation Guided by Gaussian Splatting",
      "title_zh": "翻译失败",
      "authors": [
        "Jilan Mei",
        "Junbo Li",
        "Cai Meng"
      ],
      "abstract": "This paper proposes a new method for accurate and robust 6D pose estimation\nof novel objects, named GS2Pose. By introducing 3D Gaussian splatting, GS2Pose\ncan utilize the reconstruction results without requiring a high-quality CAD\nmodel, which means it only requires segmented RGBD images as input.\nSpecifically, GS2Pose employs a two-stage structure consisting of coarse\nestimation followed by refined estimation. In the coarse stage, a lightweight\nU-Net network with a polarization attention mechanism, called Pose-Net, is\ndesigned. By using the 3DGS model for supervised training, Pose-Net can\ngenerate NOCS images to compute a coarse pose. In the refinement stage, GS2Pose\nformulates a pose regression algorithm following the idea of reprojection or\nBundle Adjustment (BA), referred to as GS-Refiner. By leveraging Lie algebra to\nextend 3DGS, GS-Refiner obtains a pose-differentiable rendering pipeline that\nrefines the coarse pose by comparing the input images with the rendered images.\nGS-Refiner also selectively updates parameters in the 3DGS model to achieve\nenvironmental adaptation, thereby enhancing the algorithm's robustness and\nflexibility to illuminative variation, occlusion, and other challenging\ndisruptive factors. GS2Pose was evaluated through experiments conducted on the\nLineMod dataset, where it was compared with similar algorithms, yielding highly\ncompetitive results. The code for GS2Pose will soon be released on GitHub.",
      "tldr_zh": "该论文提出了一种名为 GS2Pose 的新方法，用于准确和鲁棒的 6D Object Pose Estimation，仅需分段 RGBD 图像作为输入，通过 3D Gaussian Splatting 利用重建结果，而非依赖高质量 CAD 模型。方法采用两阶段结构：粗略阶段使用轻量级 U-Net 网络（Pose-Net）带极化注意力机制生成 NOCS 图像计算初估位姿；精炼阶段则通过 GS-Refiner 算法，基于重投影或 Bundle Adjustment (BA) 原理，并利用 Lie 代数扩展 3DGS，实现位姿可微渲染并选择性更新模型参数，以提升对光照变化、遮挡等干扰的适应性。在 LineMod 数据集上的实验显示，GS2Pose 与类似算法相比取得了高度竞争的结果，代码即将开源。",
      "categories": [
        "cs.CV",
        "cs.AI"
      ],
      "primary_category": "cs.CV",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2411.03807v3",
      "published_date": "2024-11-06 10:07:46 UTC",
      "updated_date": "2024-11-08 03:02:02 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-20T22:06:05.582559"
    },
    {
      "arxiv_id": "2411.03799v1",
      "title": "Overcoming label shift in targeted federated learning",
      "title_zh": "在针对性联邦学习中克服标签偏移",
      "authors": [
        "Edvin Listo Zec",
        "Adam Breitholtz",
        "Fredrik D. Johansson"
      ],
      "abstract": "Federated learning enables multiple actors to collaboratively train models\nwithout sharing private data. This unlocks the potential for scaling machine\nlearning to diverse applications. Existing algorithms for this task are\nwell-justified when clients and the intended target domain share the same\ndistribution of features and labels, but this assumption is often violated in\nreal-world scenarios. One common violation is label shift, where the label\ndistributions differ across clients or between clients and the target domain,\nwhich can significantly degrade model performance. To address this problem, we\npropose FedPALS, a novel model aggregation scheme that adapts to label shifts\nby leveraging knowledge of the target label distribution at the central server.\nOur approach ensures unbiased updates under stochastic gradient descent,\nensuring robust generalization across clients with diverse, label-shifted data.\nExtensive experiments on image classification demonstrate that FedPALS\nconsistently outperforms standard baselines by aligning model aggregation with\nthe target domain. Our findings reveal that conventional federated learning\nmethods suffer severely in cases of extreme client sparsity, highlighting the\ncritical need for target-aware aggregation. FedPALS offers a principled and\npractical solution to mitigate label distribution mismatch, ensuring models\ntrained in federated settings can generalize effectively to label-shifted\ntarget domains.",
      "tldr_zh": "联邦学习（Federated Learning）在实际应用中常面临标签偏移（label shift）问题，导致模型性能显著下降，因为客户端和目标域的标签分布不一致。论文提出 FedPALS，一种新型模型聚合方案，通过在中央服务器利用目标标签分布的知识来适应标签偏移，确保在随机梯度下降（stochastic gradient descent）下的更新无偏，并提升模型的鲁棒泛化能力。在图像分类实验中，FedPALS 比传统基线方法性能提升明显，尤其在极端客户端稀疏场景下，证明了目标感知聚合的必要性和有效性。",
      "categories": [
        "cs.LG",
        "cs.AI"
      ],
      "primary_category": "cs.LG",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2411.03799v1",
      "published_date": "2024-11-06 09:52:45 UTC",
      "updated_date": "2024-11-06 09:52:45 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-20T22:06:18.014420"
    },
    {
      "arxiv_id": "2411.03795v4",
      "title": "VQA$^2$: Visual Question Answering for Video Quality Assessment",
      "title_zh": "翻译失败",
      "authors": [
        "Ziheng Jia",
        "Zicheng Zhang",
        "Jiaying Qian",
        "Haoning Wu",
        "Wei Sun",
        "Chunyi Li",
        "Xiaohong Liu",
        "Weisi Lin",
        "Guangtao Zhai",
        "Xiongkuo Min"
      ],
      "abstract": "The advent and proliferation of large multi-modal models (LMMs) have\nintroduced new paradigms to computer vision, transforming various tasks into a\nunified visual question answering framework. Video Quality Assessment (VQA), a\nclassic field in low-level visual perception, focused initially on quantitative\nvideo quality scoring. However, driven by advances in LMMs, it is now\nprogressing toward more holistic visual quality understanding tasks. Recent\nstudies in the image domain have demonstrated that Visual Question Answering\n(VQA) can markedly enhance low-level visual quality evaluation. Nevertheless,\nrelated work has not been explored in the video domain, leaving substantial\nroom for improvement. To address this gap, we introduce the VQA2 Instruction\nDataset - the first visual question answering instruction dataset that focuses\non video quality assessment. This dataset consists of 3 subsets and covers\nvarious video types, containing 157,755 instruction question-answer pairs.\nThen, leveraging this foundation, we present the VQA2 series models. The VQA2\nseries models interleave visual and motion tokens to enhance the perception of\nspatial-temporal quality details in videos. We conduct extensive experiments on\nvideo quality scoring and understanding tasks, and results demonstrate that the\nVQA2series models achieve excellent performance in both tasks. Notably, our\nfinal model, the VQA2-Assistant, exceeds the renowned GPT-4o in visual quality\nunderstanding tasks while maintaining strong competitiveness in quality scoring\ntasks. Our work provides a foundation and feasible approach for integrating\nlow-level video quality assessment and understanding with LMMs.",
      "tldr_zh": "本文提出 VQA² 框架，将视觉问答（VQA）应用于视频质量评估（VQA），以弥补该领域在大型多模态模型（LMMs）下的空白。研究团队构建了 VQA² Instruction Dataset，这是首个专注于视频质量评估的指令数据集，包含 157,755 个问题-答案对，覆盖多种视频类型。VQA² 系列模型通过交错视觉和运动标记来提升视频的时空质量感知，在质量评分和理解任务上表现出色。特别地，VQA²-Assistant 模型在视觉质量理解任务中超过了 GPT-4o，为将低级视频质量评估与 LMMs 整合提供了可行基础。",
      "categories": [
        "cs.CV",
        "cs.AI"
      ],
      "primary_category": "cs.CV",
      "comment": "23 pages 12 figures",
      "pdf_url": "http://arxiv.org/pdf/2411.03795v4",
      "published_date": "2024-11-06 09:39:52 UTC",
      "updated_date": "2024-12-02 12:09:39 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-20T22:06:28.680372"
    },
    {
      "arxiv_id": "2411.03782v1",
      "title": "Navigating the landscape of multimodal AI in medicine: a scoping review on technical challenges and clinical applications",
      "title_zh": "翻译失败",
      "authors": [
        "Daan Schouten",
        "Giulia Nicoletti",
        "Bas Dille",
        "Catherine Chia",
        "Pierpaolo Vendittelli",
        "Megan Schuurmans",
        "Geert Litjens",
        "Nadieh Khalili"
      ],
      "abstract": "Recent technological advances in healthcare have led to unprecedented growth\nin patient data quantity and diversity. While artificial intelligence (AI)\nmodels have shown promising results in analyzing individual data modalities,\nthere is increasing recognition that models integrating multiple complementary\ndata sources, so-called multimodal AI, could enhance clinical decision-making.\nThis scoping review examines the landscape of deep learning-based multimodal AI\napplications across the medical domain, analyzing 432 papers published between\n2018 and 2024. We provide an extensive overview of multimodal AI development\nacross different medical disciplines, examining various architectural\napproaches, fusion strategies, and common application areas. Our analysis\nreveals that multimodal AI models consistently outperform their unimodal\ncounterparts, with an average improvement of 6.2 percentage points in AUC.\nHowever, several challenges persist, including cross-departmental coordination,\nheterogeneous data characteristics, and incomplete datasets. We critically\nassess the technical and practical challenges in developing multimodal AI\nsystems and discuss potential strategies for their clinical implementation,\nincluding a brief overview of commercially available multimodal AI models for\nclinical decision-making. Additionally, we identify key factors driving\nmultimodal AI development and propose recommendations to accelerate the field's\nmaturation. This review provides researchers and clinicians with a thorough\nunderstanding of the current state, challenges, and future directions of\nmultimodal AI in medicine.",
      "tldr_zh": "这篇综述分析了2018-2024年间432篇论文，探讨了多模态AI（multimodal AI）在医疗领域的应用和技术挑战，涵盖不同医疗学科的架构方法、融合策略和临床决策场景。研究发现，多模态AI模型相较于单模态模型平均提升6.2个百分点AUC性能，但面临跨部门协调、数据异质性和不完整数据集等挑战。作者评估了这些技术难题，并提出实施策略、驱动因素及推荐，以加速多模态AI在临床决策中的成熟和发展。",
      "categories": [
        "cs.AI",
        "cs.CY",
        "cs.LG"
      ],
      "primary_category": "cs.AI",
      "comment": "28 pages",
      "pdf_url": "http://arxiv.org/pdf/2411.03782v1",
      "published_date": "2024-11-06 09:18:05 UTC",
      "updated_date": "2024-11-06 09:18:05 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-20T22:07:18.517608"
    },
    {
      "arxiv_id": "2411.15144v3",
      "title": "Physically Parameterized Differentiable MUSIC for DoA Estimation with Uncalibrated Arrays",
      "title_zh": "翻译失败",
      "authors": [
        "Baptiste Chatelier",
        "José Miguel Mateos-Ramos",
        "Vincent Corlay",
        "Christian Häger",
        "Matthieu Crussière",
        "Henk Wymeersch",
        "Luc Le Magoarou"
      ],
      "abstract": "Direction of arrival (DoA) estimation is a common sensing problem in radar,\nsonar, audio, and wireless communication systems. It has gained renewed\nimportance with the advent of the integrated sensing and communication\nparadigm. To fully exploit the potential of such sensing systems, it is crucial\nto take into account potential hardware impairments that can negatively impact\nthe obtained performance. This study introduces a joint DoA estimation and\nhardware impairment learning scheme following a model-based approach.\nSpecifically, a differentiable version of the multiple signal classification\n(MUSIC) algorithm is derived, allowing efficient learning of the considered\nimpairments. The proposed approach supports both supervised and unsupervised\nlearning strategies, showcasing its practical potential. Simulation results\nindicate that the proposed method successfully learns significant inaccuracies\nin both antenna locations and complex gains. Additionally, the proposed method\noutperforms the classical MUSIC algorithm in the DoA estimation task.",
      "tldr_zh": "这篇论文提出了一种物理参数化的可微分 MUSIC 算法，用于未校准阵列的 DoA 估计，同时学习硬件缺陷，以应对雷达、声纳和无线通信系统中的性能影响问题。该算法通过模型-based方法实现联合 DoA 估计和硬件损伤学习，支持监督和无监督策略，允许高效优化天线位置和复杂增益的不准确性。模拟结果显示，该方法在 DoA 估计任务中优于经典 MUSIC 算法，提升了整体性能。",
      "categories": [
        "eess.SP",
        "cs.AI",
        "cs.IT",
        "cs.LG",
        "math.IT"
      ],
      "primary_category": "eess.SP",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2411.15144v3",
      "published_date": "2024-11-06 09:14:26 UTC",
      "updated_date": "2025-03-20 09:20:09 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-20T22:07:30.922966"
    },
    {
      "arxiv_id": "2411.03769v1",
      "title": "No Culture Left Behind: ArtELingo-28, a Benchmark of WikiArt with Captions in 28 Languages",
      "title_zh": "翻译失败",
      "authors": [
        "Youssef Mohamed",
        "Runjia Li",
        "Ibrahim Said Ahmad",
        "Kilichbek Haydarov",
        "Philip Torr",
        "Kenneth Ward Church",
        "Mohamed Elhoseiny"
      ],
      "abstract": "Research in vision and language has made considerable progress thanks to\nbenchmarks such as COCO. COCO captions focused on unambiguous facts in English;\nArtEmis introduced subjective emotions and ArtELingo introduced some\nmultilinguality (Chinese and Arabic). However we believe there should be more\nmultilinguality. Hence, we present ArtELingo-28, a vision-language benchmark\nthat spans $\\textbf{28}$ languages and encompasses approximately\n$\\textbf{200,000}$ annotations ($\\textbf{140}$ annotations per image).\nTraditionally, vision research focused on unambiguous class labels, whereas\nArtELingo-28 emphasizes diversity of opinions over languages and cultures. The\nchallenge is to build machine learning systems that assign emotional captions\nto images. Baseline results will be presented for three novel conditions:\nZero-Shot, Few-Shot and One-vs-All Zero-Shot. We find that cross-lingual\ntransfer is more successful for culturally-related languages. Data and code are\nprovided at www.artelingo.org.",
      "tldr_zh": "本研究提出ArtELingo-28，一个基于WikiArt的视觉语言基准数据集，涵盖28种语言和约200,000个图像注释（每张图像140个），强调跨文化意见多样性和情感描述，而非传统的事实标签。相比以往基准如COCO和ArtELingo，该数据集促进多语言研究，挑战机器学习系统为图像生成情感标题。实验评估了Zero-Shot、Few-Shot和One-vs-All Zero-Shot条件，发现跨语言转移在文化相关语言中更成功；数据和代码已在www.artelingo.org提供。",
      "categories": [
        "cs.CL",
        "cs.AI",
        "cs.CY",
        "cs.LG"
      ],
      "primary_category": "cs.CL",
      "comment": "9 pages, Accepted at EMNLP 24, for more details see www.artelingo.org",
      "pdf_url": "http://arxiv.org/pdf/2411.03769v1",
      "published_date": "2024-11-06 09:05:17 UTC",
      "updated_date": "2024-11-06 09:05:17 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-20T22:07:42.166288"
    },
    {
      "arxiv_id": "2411.03766v3",
      "title": "Number Cookbook: Number Understanding of Language Models and How to Improve It",
      "title_zh": "数字食谱：语言模型的数字理解以及如何改进它",
      "authors": [
        "Haotong Yang",
        "Yi Hu",
        "Shijia Kang",
        "Zhouchen Lin",
        "Muhan Zhang"
      ],
      "abstract": "Large language models (LLMs) can solve an increasing number of complex\nreasoning tasks while making surprising mistakes in basic numerical\nunderstanding and processing (such as 9.11 > 9.9). The latter ability is\nessential for tackling complex arithmetic and mathematical problems and serves\nas a foundation for most reasoning tasks, but previous work paid little\nattention to it or only discussed several restricted tasks (like integer\naddition). In this paper, we comprehensively investigate the numerical\nunderstanding and processing ability (NUPA) of LLMs. Firstly, we introduce a\nbenchmark covering four common numerical representations and 17 distinct\nnumerical tasks in four major categories, resulting in 41 meaningful\ncombinations in total. These tasks are derived from primary and secondary\neducation curricula, encompassing nearly all everyday numerical understanding\nand processing scenarios, and the rules of these tasks are very simple and\nclear. Through the benchmark, we find that current LLMs fail frequently in many\nof the tasks. To study the problem, we train small models with existing and\npotential techniques for enhancing NUPA (such as tokenizers, PEs, and number\nformats), comprehensively evaluating their effectiveness using our testbed. We\nalso finetune practical-scale LLMs on our proposed NUPA tasks and find that 1)\nnaive finetuning can improve NUPA a lot on many but not all tasks, and 2)\nsurprisingly, techniques designed to enhance NUPA prove ineffective for\nfinetuning pretrained models. We further explore the impact of chain-of-thought\ntechniques on NUPA. Our work provides a more detailed and comprehensive\nunderstanding of NUPA in LLMs. Our benchmark and code are released at\nhttps://github.com/GraphPKU/number_cookbook.",
      "tldr_zh": "本研究探讨了大型语言模型（LLMs）在数字理解和处理能力（NUPA）上的不足，例如错误判断9.11 > 9.9，尽管它们在复杂推理任务上表现出色。论文引入了一个基准，涵盖四种数字表示和17个任务（总计41个组合），这些任务基于初高中教育场景，评估LLMs在日常数字处理中的表现，结果显示当前模型在许多任务中频繁失败。为提升NUPA，研究者训练小模型并测试现有技术（如tokenizers、PEs和number formats），并通过微调实际规模LLMs发现，简单微调能显著改善部分任务，但特定增强技术在微调预训练模型时无效；此外，chain-of-thought技术的影响也被进一步探讨。该工作提供了对LLMs数字理解的全面洞察，并公开了基准和代码。",
      "categories": [
        "cs.CL",
        "cs.AI"
      ],
      "primary_category": "cs.CL",
      "comment": "ICLR 2025 poster",
      "pdf_url": "http://arxiv.org/pdf/2411.03766v3",
      "published_date": "2024-11-06 08:59:44 UTC",
      "updated_date": "2025-03-05 09:52:30 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-20T22:09:46.637774"
    },
    {
      "arxiv_id": "2411.03758v1",
      "title": "Sub-DM:Subspace Diffusion Model with Orthogonal Decomposition for MRI Reconstruction",
      "title_zh": "翻译失败",
      "authors": [
        "Yu Guan",
        "Qinrong Cai",
        "Wei Li",
        "Qiuyun Fan",
        "Dong Liang",
        "Qiegen Liu"
      ],
      "abstract": "Diffusion model-based approaches recently achieved re-markable success in MRI\nreconstruction, but integration into clinical routine remains challenging due\nto its time-consuming convergence. This phenomenon is partic-ularly notable\nwhen directly apply conventional diffusion process to k-space data without\nconsidering the inherent properties of k-space sampling, limiting k-space\nlearning efficiency and image reconstruction quality. To tackle these\nchallenges, we introduce subspace diffusion model with orthogonal\ndecomposition, a method (referred to as Sub-DM) that restrict the diffusion\nprocess via projections onto subspace as the k-space data distribution evolves\ntoward noise. Particularly, the subspace diffusion model circumvents the\ninference challenges posed by the com-plex and high-dimensional characteristics\nof k-space data, so the highly compact subspace ensures that diffusion process\nrequires only a few simple iterations to produce accurate prior information.\nFurthermore, the orthogonal decomposition strategy based on wavelet transform\nhin-ders the information loss during the migration of the vanilla diffusion\nprocess to the subspace. Considering the strate-gy is approximately reversible,\nsuch that the entire pro-cess can be reversed. As a result, it allows the\ndiffusion processes in different spaces to refine models through a mutual\nfeedback mechanism, enabling the learning of ac-curate prior even when dealing\nwith complex k-space data. Comprehensive experiments on different datasets\nclearly demonstrate that the superiority of Sub-DM against state of-the-art\nmethods in terms of reconstruction speed and quality.",
      "tldr_zh": "本研究提出 Sub-DM，一种基于子空间扩散模型和正交分解的方法，用于 MRI 重建，以解决传统 Diffusion Model 在处理 k-space 数据时存在的收敛时间长和效率低的问题。\nSub-DM 通过将扩散过程投影到子空间，并利用小波变换的正交分解策略，限制数据分布演化并防止信息丢失，同时实现可逆反馈机制，提升对复杂 k-space 数据的学习效率。\n实验在不同数据集上表明，Sub-DM 在重建速度和质量方面均优于最先进方法。",
      "categories": [
        "eess.IV",
        "cs.AI",
        "cs.CV"
      ],
      "primary_category": "eess.IV",
      "comment": "10 pages, 11 figures",
      "pdf_url": "http://arxiv.org/pdf/2411.03758v1",
      "published_date": "2024-11-06 08:33:07 UTC",
      "updated_date": "2024-11-06 08:33:07 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-20T22:08:07.309821"
    },
    {
      "arxiv_id": "2411.03755v3",
      "title": "Content-Style Learning from Unaligned Domains: Identifiability under Unknown Latent Dimensions",
      "title_zh": "翻译失败",
      "authors": [
        "Sagar Shrestha",
        "Xiao Fu"
      ],
      "abstract": "Understanding identifiability of latent content and style variables from\nunaligned multi-domain data is essential for tasks such as domain translation\nand data generation. Existing works on content-style identification were often\ndeveloped under somewhat stringent conditions, e.g., that all latent components\nare mutually independent and that the dimensions of the content and style\nvariables are known. We introduce a new analytical framework via cross-domain\n\\textit{latent distribution matching} (LDM), which establishes content-style\nidentifiability under substantially more relaxed conditions. Specifically, we\nshow that restrictive assumptions such as component-wise independence of the\nlatent variables can be removed. Most notably, we prove that prior knowledge of\nthe content and style dimensions is not necessary for ensuring identifiability,\nif sparsity constraints are properly imposed onto the learned latent\nrepresentations. Bypassing the knowledge of the exact latent dimension has been\na longstanding aspiration in unsupervised representation learning -- our\nanalysis is the first to underpin its theoretical and practical viability. On\nthe implementation side, we recast the LDM formulation into a regularized\nmulti-domain GAN loss with coupled latent variables. We show that the\nreformulation is equivalent to LDM under mild conditions -- yet requiring\nconsiderably less computational resource. Experiments corroborate with our\ntheoretical claims.",
      "tldr_zh": "本研究探讨了从未对齐的多域数据中识别潜在内容和风格变量的标识性问题，引入了跨域潜在分布匹配 (LDM) 框架，以更宽松的条件实现内容-风格标识性。LDM 框架去除潜在变量的组件独立性假设，并证明无需事先知道内容和风格变量的维度，只需施加适当的稀疏性约束即可确保标识性。该方法通过将 LDM 转化为正则化多域 GAN 损失的实现形式，提高了计算效率，实验结果验证了其理论可行性。",
      "categories": [
        "cs.LG",
        "cs.AI"
      ],
      "primary_category": "cs.LG",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2411.03755v3",
      "published_date": "2024-11-06 08:30:23 UTC",
      "updated_date": "2025-03-01 23:02:28 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-20T22:08:18.761040"
    },
    {
      "arxiv_id": "2411.03746v1",
      "title": "Optimal Defenses Against Gradient Reconstruction Attacks",
      "title_zh": "翻译失败",
      "authors": [
        "Yuxiao Chen",
        "Gamze Gürsoy",
        "Qi Lei"
      ],
      "abstract": "Federated Learning (FL) is designed to prevent data leakage through\ncollaborative model training without centralized data storage. However, it\nremains vulnerable to gradient reconstruction attacks that recover original\ntraining data from shared gradients. To optimize the trade-off between data\nleakage and utility loss, we first derive a theoretical lower bound of\nreconstruction error (among all attackers) for the two standard methods: adding\nnoise, and gradient pruning. We then customize these two defenses to be\nparameter- and model-specific and achieve the optimal trade-off between our\nobtained reconstruction lower bound and model utility. Experimental results\nvalidate that our methods outperform Gradient Noise and Gradient Pruning by\nprotecting the training data better while also achieving better utility.",
      "tldr_zh": "本文针对 Federated Learning (FL) 中 gradient reconstruction attacks 的数据泄漏风险，推导了 adding noise 和 gradient pruning 两种标准防御方法的理论 reconstruction error 下界，并将这些方法定制化为 parameter- and model-specific 的形式，以优化 reconstruction lower bound 与 model utility 之间的权衡。研究通过理论分析和实验验证，展示了定制防御的优越性。结果表明，该方法在保护训练数据方面比 Gradient Noise 和 Gradient Pruning 更有效，同时实现了更高的模型效用。",
      "categories": [
        "cs.LG",
        "cs.AI",
        "cs.CR",
        "stat.ML"
      ],
      "primary_category": "cs.LG",
      "comment": "The code for this project is available at\n  https://github.com/cyx78/Optimal_Defenses_Against_Gradient_Reconstruction_Attacks",
      "pdf_url": "http://arxiv.org/pdf/2411.03746v1",
      "published_date": "2024-11-06 08:22:20 UTC",
      "updated_date": "2024-11-06 08:22:20 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-20T22:08:30.928965"
    },
    {
      "arxiv_id": "2411.03743v1",
      "title": "Automating Exploratory Proteomics Research via Language Models",
      "title_zh": "利用语言模型自动化探索性蛋白质组学研究",
      "authors": [
        "Ning Ding",
        "Shang Qu",
        "Linhai Xie",
        "Yifei Li",
        "Zaoqu Liu",
        "Kaiyan Zhang",
        "Yibai Xiong",
        "Yuxin Zuo",
        "Zhangren Chen",
        "Ermo Hua",
        "Xingtai Lv",
        "Youbang Sun",
        "Yang Li",
        "Dong Li",
        "Fuchu He",
        "Bowen Zhou"
      ],
      "abstract": "With the development of artificial intelligence, its contribution to science\nis evolving from simulating a complex problem to automating entire research\nprocesses and producing novel discoveries. Achieving this advancement requires\nboth specialized general models grounded in real-world scientific data and\niterative, exploratory frameworks that mirror human scientific methodologies.\nIn this paper, we present PROTEUS, a fully automated system for scientific\ndiscovery from raw proteomics data. PROTEUS uses large language models (LLMs)\nto perform hierarchical planning, execute specialized bioinformatics tools, and\niteratively refine analysis workflows to generate high-quality scientific\nhypotheses. The system takes proteomics datasets as input and produces a\ncomprehensive set of research objectives, analysis results, and novel\nbiological hypotheses without human intervention. We evaluated PROTEUS on 12\nproteomics datasets collected from various biological samples (e.g. immune\ncells, tumors) and different sample types (single-cell and bulk), generating\n191 scientific hypotheses. These were assessed using both automatic LLM-based\nscoring on 5 metrics and detailed reviews from human experts. Results\ndemonstrate that PROTEUS consistently produces reliable, logically coherent\nresults that align well with existing literature while also proposing novel,\nevaluable hypotheses. The system's flexible architecture facilitates seamless\nintegration of diverse analysis tools and adaptation to different proteomics\ndata types. By automating complex proteomics analysis workflows and hypothesis\ngeneration, PROTEUS has the potential to considerably accelerate the pace of\nscientific discovery in proteomics research, enabling researchers to\nefficiently explore large-scale datasets and uncover biological insights.",
      "tldr_zh": "这篇论文介绍了 PROTEUS 系统，一种利用大型语言模型 (LLMs) 自动化的框架，用于从原始蛋白质组学数据中进行探索性研究，包括分层规划、执行生物信息学工具和迭代优化分析流程。系统输入蛋白质组学数据集，输出全面的研究目标、分析结果和新型生物学假设，并在 12 个数据集上生成了 191 个可靠假设，这些假设经 LLM 评分和人类专家评估显示逻辑一致且与现有文献相符。PROTEUS 的灵活架构便于整合多种工具和适应不同数据类型，从而加速蛋白质组学领域的科学发现和生物洞见。",
      "categories": [
        "cs.AI",
        "q-bio.QM"
      ],
      "primary_category": "cs.AI",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2411.03743v1",
      "published_date": "2024-11-06 08:16:56 UTC",
      "updated_date": "2024-11-06 08:16:56 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-20T22:09:48.226817"
    },
    {
      "arxiv_id": "2411.03742v1",
      "title": "Adaptive Consensus Gradients Aggregation for Scaled Distributed Training",
      "title_zh": "自适应共识梯度聚合用于大规模分布式训练",
      "authors": [
        "Yoni Choukroun",
        "Shlomi Azoulay",
        "Pavel Kisilev"
      ],
      "abstract": "Distributed machine learning has recently become a critical paradigm for\ntraining large models on vast datasets. We examine the stochastic optimization\nproblem for deep learning within synchronous parallel computing environments\nunder communication constraints. While averaging distributed gradients is the\nmost widely used method for gradient estimation, whether this is the optimal\nstrategy remains an open question. In this work, we analyze the distributed\ngradient aggregation process through the lens of subspace optimization. By\nformulating the aggregation problem as an objective-aware subspace optimization\nproblem, we derive an efficient weighting scheme for gradients, guided by\nsubspace coefficients. We further introduce subspace momentum to accelerate\nconvergence while maintaining statistical unbiasedness in the aggregation. Our\nmethod demonstrates improved performance over the ubiquitous gradient averaging\non multiple MLPerf tasks while remaining extremely efficient in both\ncommunicational and computational complexity.",
      "tldr_zh": "本论文探讨分布式机器学习中梯度聚合的优化问题，针对同步并行计算环境下的通信约束，将梯度聚合视为子空间优化问题，并提出一种基于子空间系数的自适应加权方案和子空间动量方法，以加速收敛同时保持统计无偏性。该方法在多个 MLPerf 任务上比传统的梯度 averaging 表现出显著性能提升，通信和计算复杂度保持高效。",
      "categories": [
        "cs.LG",
        "cs.AI",
        "cs.DC"
      ],
      "primary_category": "cs.LG",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2411.03742v1",
      "published_date": "2024-11-06 08:16:39 UTC",
      "updated_date": "2024-11-06 08:16:39 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-20T22:08:54.695137"
    },
    {
      "arxiv_id": "2411.04151v1",
      "title": "UnityGraph: Unified Learning of Spatio-temporal features for Multi-person Motion Prediction",
      "title_zh": "UnityGraph：用于多人运动预测的时空特征统一学习",
      "authors": [
        "Kehua Qu",
        "Rui Ding",
        "Jin Tang"
      ],
      "abstract": "Multi-person motion prediction is a complex and emerging field with\nsignificant real-world applications. Current state-of-the-art methods typically\nadopt dual-path networks to separately modeling spatial features and temporal\nfeatures. However, the uncertain compatibility of the two networks brings a\nchallenge for spatio-temporal features fusion and violate the spatio-temporal\ncoherence and coupling of human motions by nature. To address this issue, we\npropose a novel graph structure, UnityGraph, which treats spatio-temporal\nfeatures as a whole, enhancing model coherence and coupling.spatio-temporal\nfeatures as a whole, enhancing model coherence and coupling. Specifically,\nUnityGraph is a hypervariate graph based network. The flexibility of the\nhypergraph allows us to consider the observed motions as graph nodes. We then\nleverage hyperedges to bridge these nodes for exploring spatio-temporal\nfeatures. This perspective considers spatio-temporal dynamics unitedly and\nreformulates multi-person motion prediction into a problem on a single graph.\nLeveraging the dynamic message passing based on this hypergraph, our model\ndynamically learns from both types of relations to generate targeted messages\nthat reflect the relevance among nodes. Extensive experiments on several\ndatasets demonstrates that our method achieves state-of-the-art performance,\nconfirming its effectiveness and innovative design.",
      "tldr_zh": "本研究针对多人物运动预测中的问题，指出现有方法采用双路径网络分别处理 spatio-temporal features，导致特征融合兼容性差，并违反了人类运动的内在连贯性和耦合性。为解决此问题，论文提出 UnityGraph，一种基于 hypervariate graph 的网络，将 spatio-temporal features 作为一个整体处理，通过 hyperedges 连接观察到的运动节点，并利用动态消息传递学习节点相关性。实验结果显示，该方法在多个数据集上达到了 state-of-the-art 性能，证明了其统一学习框架的有效性和创新性。",
      "categories": [
        "cs.CV",
        "cs.AI"
      ],
      "primary_category": "cs.CV",
      "comment": "13pages, 12 figures. arXiv admin note: text overlap with\n  arXiv:2411.03729",
      "pdf_url": "http://arxiv.org/pdf/2411.04151v1",
      "published_date": "2024-11-06 08:05:36 UTC",
      "updated_date": "2024-11-06 08:05:36 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-20T22:09:06.875999"
    },
    {
      "arxiv_id": "2411.03729v1",
      "title": "Relation Learning and Aggregate-attention for Multi-person Motion Prediction",
      "title_zh": "翻译失败",
      "authors": [
        "Kehua Qu",
        "Rui Ding",
        "Jin Tang"
      ],
      "abstract": "Multi-person motion prediction is an emerging and intricate task with broad\nreal-world applications. Unlike single person motion prediction, it considers\nnot just the skeleton structures or human trajectories but also the\ninteractions between others. Previous methods use various networks to achieve\nimpressive predictions but often overlook that the joints relations within an\nindividual (intra-relation) and interactions among groups (inter-relation) are\ndistinct types of representations. These methods often lack explicit\nrepresentation of inter&intra-relations, and inevitably introduce undesired\ndependencies. To address this issue, we introduce a new collaborative framework\nfor multi-person motion prediction that explicitly modeling these relations:a\nGCN-based network for intra-relations and a novel reasoning network for\ninter-relations.Moreover, we propose a novel plug-and-play aggregation module\ncalled the Interaction Aggregation Module (IAM), which employs an\naggregate-attention mechanism to seamlessly integrate these relations.\nExperiments indicate that the module can also be applied to other dual-path\nmodels. Extensive experiments on the 3DPW, 3DPW-RC, CMU-Mocap, MuPoTS-3D, as\nwell as synthesized datasets Mix1 & Mix2 (9 to 15 persons), demonstrate that\nour method achieves state-of-the-art performance.",
      "tldr_zh": "本研究针对多人物体运动预测（Multi-person Motion Prediction）问题，提出了一种新框架，通过显式建模个体内部关节关系（intra-relations）和群体间互动关系（inter-relations）来解决现有方法忽略这些关系的局限。框架包括一个 GCN-based 网络处理 intra-relations，以及一个新型推理网络处理 inter-relations；此外，引入了 Interaction Aggregation Module (IAM)，利用 aggregate-attention 机制无缝整合这些关系，使其可作为 plug-and-play 模块应用于其他 dual-path 模型。实验在 3DPW、3DPW-RC、CMU-Mocap、MuPoTS-3D 以及合成数据集 Mix1 和 Mix2 上显示，该方法实现了 state-of-the-art 性能，显著提升了预测准确性。",
      "categories": [
        "cs.CV",
        "cs.AI"
      ],
      "primary_category": "cs.CV",
      "comment": "Submitted to IEEE Transactions on Multimedia",
      "pdf_url": "http://arxiv.org/pdf/2411.03729v1",
      "published_date": "2024-11-06 07:48:30 UTC",
      "updated_date": "2024-11-06 07:48:30 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-20T22:09:59.341316"
    },
    {
      "arxiv_id": "2411.03726v1",
      "title": "PropNEAT -- Efficient GPU-Compatible Backpropagation over NeuroEvolutionary Augmenting Topology Networks",
      "title_zh": "翻译失败",
      "authors": [
        "Michael Merry",
        "Patricia Riddle",
        "Jim Warren"
      ],
      "abstract": "We introduce PropNEAT, a fast backpropagation implementation of NEAT that\nuses a bidirectional mapping of the genome graph to a layer-based architecture\nthat preserves the NEAT genomes whilst enabling efficient GPU backpropagation.\nWe test PropNEAT on 58 binary classification datasets from the Penn Machine\nLearning Benchmarks database, comparing the performance against logistic\nregression, dense neural networks and random forests, as well as a densely\nretrained variant of the final PropNEAT model. PropNEAT had the second best\noverall performance, behind Random Forest, though the difference between the\nmodels was not statistically significant apart from between Random Forest in\ncomparison with logistic regression and the PropNEAT retrain models. PropNEAT\nwas substantially faster than a naive backpropagation method, and both were\nsubstantially faster and had better performance than the original NEAT\nimplementation. We demonstrate that the per-epoch training time for PropNEAT\nscales linearly with network depth, and is efficient on GPU implementations for\nbackpropagation. This implementation could be extended to support reinforcement\nlearning or convolutional networks, and is able to find sparser and smaller\nnetworks with potential for applications in low-power contexts.",
      "tldr_zh": "该研究引入了 PropNEAT，一种高效的 NEAT（NeuroEvolutionary Augmenting Topology）变体，通过双向映射将基因组图转换为层-based 架构，支持 GPU 兼容的 backpropagation，同时保留原始基因组。PropNEAT 在 58 个二元分类数据集上进行测试，与 logistic regression、dense neural networks 和 Random Forest 相比，其整体性能排名第二，仅次于 Random Forest，且训练速度远超 naive backpropagation 方法和原始 NEAT 实现。实验结果显示，PropNEAT 的每轮训练时间与网络深度线性 scaling，并能生成更稀疏、更小的网络，适用于低功耗场景，并可扩展到 reinforcement learning 或 convolutional networks。",
      "categories": [
        "cs.LG",
        "cs.AI",
        "cs.NE"
      ],
      "primary_category": "cs.LG",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2411.03726v1",
      "published_date": "2024-11-06 07:44:14 UTC",
      "updated_date": "2024-11-06 07:44:14 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-20T22:10:11.656836"
    },
    {
      "arxiv_id": "2411.03709v1",
      "title": "AutoGameUI: Constructing High-Fidelity Game UIs via Multimodal Learning and Interactive Web-Based Tool",
      "title_zh": "翻译失败",
      "authors": [
        "Zhongliang Tang",
        "Mengchen Tan",
        "Fei Xia",
        "Qingrong Cheng",
        "Hao Jiang",
        "Yongxiang Zhang"
      ],
      "abstract": "We introduce an innovative system, AutoGameUI, for efficiently constructing\ncohesive user interfaces in game development. Our system is the first to\naddress the coherence issue arising from integrating inconsistent UI and UX\ndesigns, typically leading to mismatches and inefficiencies. We propose a\ntwo-stage multimodal learning pipeline to obtain comprehensive representations\nof both UI and UX designs, and to establish their correspondences. Through the\ncorrespondences, a cohesive user interface is automatically constructed from\npairwise designs. To achieve high-fidelity effects, we introduce a universal\ndata protocol for precise design descriptions and cross-platform applications.\nWe also develop an interactive web-based tool for game developers to facilitate\nthe use of our system. We create a game UI dataset from actual game projects\nand combine it with a public dataset for training and evaluation. Our\nexperimental results demonstrate the effectiveness of our system in maintaining\ncoherence between the constructed interfaces and the original designs.",
      "tldr_zh": "我们引入 AutoGameUI 系统，这是首个针对游戏开发中 UI 和 UX 设计不一致导致连贯性问题的解决方案，通过多模态学习的多阶段管道获取设计表示并建立对应关系，从而自动构建高保真用户界面。系统还引入通用数据协议以支持精确设计描述和跨平台应用，并开发交互式 Web-Based Tool 供游戏开发者使用。我们创建了自定义游戏 UI 数据集并结合公共数据集进行训练和评估，实验结果显示 AutoGameUI 显著提高了界面与原设计的连贯性。",
      "categories": [
        "cs.HC",
        "cs.AI"
      ],
      "primary_category": "cs.HC",
      "comment": "27 pages",
      "pdf_url": "http://arxiv.org/pdf/2411.03709v1",
      "published_date": "2024-11-06 07:16:54 UTC",
      "updated_date": "2024-11-06 07:16:54 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-20T22:10:23.168021"
    },
    {
      "arxiv_id": "2411.03707v1",
      "title": "Fine-Tuning Vision-Language Model for Automated Engineering Drawing Information Extraction",
      "title_zh": "翻译失败",
      "authors": [
        "Muhammad Tayyab Khan",
        "Lequn Chen",
        "Ye Han Ng",
        "Wenhe Feng",
        "Nicholas Yew Jin Tan",
        "Seung Ki Moon"
      ],
      "abstract": "Geometric Dimensioning and Tolerancing (GD&T) plays a critical role in\nmanufacturing by defining acceptable variations in part features to ensure\ncomponent quality and functionality. However, extracting GD&T information from\n2D engineering drawings is a time-consuming and labor-intensive task, often\nrelying on manual efforts or semi-automated tools. To address these challenges,\nthis study proposes an automated and computationally efficient GD&T extraction\nmethod by fine-tuning Florence-2, an open-source vision-language model (VLM).\nThe model is trained on a dataset of 400 drawings with ground truth annotations\nprovided by domain experts. For comparison, two state-of-the-art closed-source\nVLMs, GPT-4o and Claude-3.5-Sonnet, are evaluated on the same dataset. All\nmodels are assessed using precision, recall, F1-score, and hallucination\nmetrics. Due to the computational cost and impracticality of fine-tuning large\nclosed-source VLMs for domain-specific tasks, GPT-4o and Claude-3.5-Sonnet are\nevaluated in a zero-shot setting. In contrast, Florence-2, a smaller model with\n0.23 billion parameters, is optimized through full-parameter fine-tuning across\nthree distinct experiments, each utilizing datasets augmented to different\nlevels. The results show that Florence-2 achieves a 29.95% increase in\nprecision, a 37.75% increase in recall, a 52.40% improvement in F1-score, and a\n43.15% reduction in hallucination rate compared to the best-performing\nclosed-source model. These findings highlight the effectiveness of fine-tuning\nsmaller, open-source VLMs like Florence-2, offering a practical and efficient\nsolution for automated GD&T extraction to support downstream manufacturing\ntasks.",
      "tldr_zh": "本研究针对工程图纸中 Geometric Dimensioning and Tolerancing (GD&T) 信息的提取问题，提出了一种自动化方法，通过微调开源视觉语言模型 (VLM) Florence-2，利用包含400张专家标注图纸的数据集进行训练。相比于在零样本设置下评估的闭源模型 GPT-4o 和 Claude-3.5-Sonnet，Florence-2 在三个不同增强数据集实验中实现了精度提高29.95%、召回率提高37.75%、F1-score 改善52.40%，并将 hallucination rate 降低了43.15%。这些结果突显了微调小型开源 VLM 的高效性和实用性，为下游制造任务提供可靠的自动化提取解决方案。",
      "categories": [
        "cs.CV",
        "cs.AI"
      ],
      "primary_category": "cs.CV",
      "comment": "Paper has been submitted to the 9th International Conference on\n  Innovation in Artificial Intelligence (ICIAI 2025)",
      "pdf_url": "http://arxiv.org/pdf/2411.03707v1",
      "published_date": "2024-11-06 07:11:15 UTC",
      "updated_date": "2024-11-06 07:11:15 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-20T22:10:36.355629"
    },
    {
      "arxiv_id": "2411.05029v1",
      "title": "Ultrasound-Based AI for COVID-19 Detection: A Comprehensive Review of Public and Private Lung Ultrasound Datasets and Studies",
      "title_zh": "基于超声波的人工智能用于 COVID-19 检测：公共和私有肺部超声数据集及研究的全面综述",
      "authors": [
        "Abrar Morshed",
        "Abdulla Al Shihab",
        "Md Abrar Jahin",
        "Md Jaber Al Nahian",
        "Md Murad Hossain Sarker",
        "Md Sharjis Ibne Wadud",
        "Mohammad Istiaq Uddin",
        "Muntequa Imtiaz Siraji",
        "Nafisa Anjum",
        "Sumiya Rajjab Shristy",
        "Tanvin Rahman",
        "Mahmuda Khatun",
        "Md Rubel Dewan",
        "Mosaddeq Hossain",
        "Razia Sultana",
        "Ripel Chakma",
        "Sonet Barua Emon",
        "Towhidul Islam",
        "Mohammad Arafat Hussain"
      ],
      "abstract": "The COVID-19 pandemic has affected millions of people globally, with\nrespiratory organs being strongly affected in individuals with comorbidities.\nMedical imaging-based diagnosis and prognosis have become increasingly popular\nin clinical settings for detecting COVID-19 lung infections. Among various\nmedical imaging modalities, ultrasound stands out as a low-cost, mobile, and\nradiation-safe imaging technology. In this comprehensive review, we focus on\nAI-driven studies utilizing lung ultrasound (LUS) for COVID-19 detection and\nanalysis. We provide a detailed overview of both publicly available and private\nLUS datasets and categorize the AI studies according to the dataset they used.\nAdditionally, we systematically analyzed and tabulated the studies across\nvarious dimensions, including data preprocessing methods, AI models,\ncross-validation techniques, and evaluation metrics. In total, we reviewed 60\narticles, 41 of which utilized public datasets, while the remaining employed\nprivate data. Our findings suggest that ultrasound-based AI studies for\nCOVID-19 detection have great potential for clinical use, especially for\nchildren and pregnant women. Our review also provides a useful summary for\nfuture researchers and clinicians who may be interested in the field.",
      "tldr_zh": "这篇综述论文回顾了基于肺超声（Lung Ultrasound, LUS）的AI技术在COVID-19检测中的应用，详细概述了公开和私有LUS数据集，并对60篇相关研究进行了分类分析，包括数据预处理方法、AI模型、交叉验证技术和评估指标。研究发现，其中41篇使用了公开数据集，这些AI驱动方法显示出巨大的临床潜力，尤其适合儿童和孕妇群体。总体而言，该论文为未来研究者和临床医生提供了宝贵的总结和指导方向。",
      "categories": [
        "cs.CV",
        "cs.AI"
      ],
      "primary_category": "cs.CV",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2411.05029v1",
      "published_date": "2024-11-06 06:59:41 UTC",
      "updated_date": "2024-11-06 06:59:41 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-20T22:10:46.897577"
    },
    {
      "arxiv_id": "2411.03687v1",
      "title": "Beyond Model Adaptation at Test Time: A Survey",
      "title_zh": "超越测试时模型适应：一个综述",
      "authors": [
        "Zehao Xiao",
        "Cees G. M. Snoek"
      ],
      "abstract": "Machine learning algorithms have achieved remarkable success across various\ndisciplines, use cases and applications, under the prevailing assumption that\ntraining and test samples are drawn from the same distribution. Consequently,\nthese algorithms struggle and become brittle even when samples in the test\ndistribution start to deviate from the ones observed during training. Domain\nadaptation and domain generalization have been studied extensively as\napproaches to address distribution shifts across test and train domains, but\neach has its limitations. Test-time adaptation, a recently emerging learning\nparadigm, combines the benefits of domain adaptation and domain generalization\nby training models only on source data and adapting them to target data during\ntest-time inference. In this survey, we provide a comprehensive and systematic\nreview on test-time adaptation, covering more than 400 recent papers. We\nstructure our review by categorizing existing methods into five distinct\ncategories based on what component of the method is adjusted for test-time\nadaptation: the model, the inference, the normalization, the sample, or the\nprompt, providing detailed analysis of each. We further discuss the various\npreparation and adaptation settings for methods within these categories,\noffering deeper insights into the effective deployment for the evaluation of\ndistribution shifts and their real-world application in understanding images,\nvideo and 3D, as well as modalities beyond vision. We close the survey with an\noutlook on emerging research opportunities for test-time adaptation.",
      "tldr_zh": "这篇调查论文探讨了机器学习模型在训练和测试分布偏移时的挑战，超越了传统领域适应（domain adaptation）和领域泛化（domain generalization）的局限性。论文对测试时适应（test-time adaptation）进行了系统回顾，涵盖超过400篇相关文献，并将方法分类为五类：模型调整、推理调整、归一化调整、样本调整或提示调整，同时分析了其准备和适应设置。最终，论文讨论了这些方法在图像、视频、3D 等领域的实际应用，并展望了测试时适应的未来研究机会。",
      "categories": [
        "cs.LG",
        "cs.AI"
      ],
      "primary_category": "cs.LG",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2411.03687v1",
      "published_date": "2024-11-06 06:13:57 UTC",
      "updated_date": "2024-11-06 06:13:57 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-20T22:10:59.218943"
    },
    {
      "arxiv_id": "2411.03675v2",
      "title": "QUILL: Quotation Generation Enhancement of Large Language Models",
      "title_zh": "翻译失败",
      "authors": [
        "Jin Xiao",
        "Bowei Zhang",
        "Qianyu He",
        "Jiaqing Liang",
        "Feng Wei",
        "Jinglei Chen",
        "Zujie Liang",
        "Deqing Yang",
        "Yanghua Xiao"
      ],
      "abstract": "While Large language models (LLMs) have become excellent writing assistants,\nthey still struggle with quotation generation. This is because they either\nhallucinate when providing factual quotations or fail to provide quotes that\nexceed human expectations. To bridge the gap, we systematically study how to\nevaluate and improve LLMs' performance in quotation generation tasks. We first\nestablish a holistic and automatic evaluation system for quotation generation\ntask, which consists of five criteria each with corresponding automatic metric.\nTo improve the LLMs' quotation generation abilities, we construct a bilingual\nknowledge base that is broad in scope and rich in dimensions, containing up to\n32,022 quotes. Moreover, guided by our critiria, we further design a\nquotation-specific metric to rerank the retrieved quotations from the knowledge\nbase. Extensive experiments show that our metrics strongly correlate with human\npreferences. Existing LLMs struggle to generate desired quotes, but our\nquotation knowledge base and reranking metric help narrow this gap. Our dataset\nand code are publicly available at https://github.com/GraceXiaoo/QUILL.",
      "tldr_zh": "该论文研究了如何提升大型语言模型（LLMs）在引用生成（quotation generation）方面的性能，解决其幻觉（hallucinate）和无法超出人类预期的缺陷。首先，他们建立了全面的自动评估系统，包括五个标准和相应指标，并构建了一个范围广泛的双语知识库，包含多达32,022条引用。其次，通过设计基于标准的特定指标来重新排名检索的引用，实验证明这些方法与人类偏好高度相关，有效缩小了LLMs的生成差距。数据集和代码已在GitHub上公开。",
      "categories": [
        "cs.CL",
        "cs.AI"
      ],
      "primary_category": "cs.CL",
      "comment": "17 pages, 6 figures",
      "pdf_url": "http://arxiv.org/pdf/2411.03675v2",
      "published_date": "2024-11-06 05:24:09 UTC",
      "updated_date": "2025-02-20 07:29:42 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-20T22:11:11.172816"
    },
    {
      "arxiv_id": "2411.03672v2",
      "title": "MetaSSC: Enhancing 3D Semantic Scene Completion for Autonomous Driving through Meta-Learning and Long-sequence Modeling",
      "title_zh": "MetaSSC：通过元学习和长序列建模增强自动驾驶的3D语义场景补全",
      "authors": [
        "Yansong Qu",
        "Zixuan Xu",
        "Zilin Huang",
        "Zihao Sheng",
        "Tiantian Chen",
        "Sikai Chen"
      ],
      "abstract": "Semantic scene completion (SSC) is essential for achieving comprehensive\nperception in autonomous driving systems. However, existing SSC methods often\noverlook the high deployment costs in real-world applications. Traditional\narchitectures, such as 3D Convolutional Neural Networks (3D CNNs) and\nself-attention mechanisms, face challenges in efficiently capturing long-range\ndependencies within 3D voxel grids, limiting their effectiveness. To address\nthese issues, we introduce MetaSSC, a novel meta-learning-based framework for\nSSC that leverages deformable convolution, large-kernel attention, and the\nMamba (D-LKA-M) model. Our approach begins with a voxel-based semantic\nsegmentation (SS) pretraining task, aimed at exploring the semantics and\ngeometry of incomplete regions while acquiring transferable meta-knowledge.\nUsing simulated cooperative perception datasets, we supervise the perception\ntraining of a single vehicle using aggregated sensor data from multiple nearby\nconnected autonomous vehicles (CAVs), generating richer and more comprehensive\nlabels. This meta-knowledge is then adapted to the target domain through a\ndual-phase training strategy that does not add extra model parameters, enabling\nefficient deployment. To further enhance the model's capability in capturing\nlong-sequence relationships within 3D voxel grids, we integrate Mamba blocks\nwith deformable convolution and large-kernel attention into the backbone\nnetwork. Extensive experiments demonstrate that MetaSSC achieves\nstate-of-the-art performance, significantly outperforming competing models\nwhile also reducing deployment costs.",
      "tldr_zh": "本研究提出 MetaSSC，一种基于 meta-learning 的框架，用于提升自动驾驶中的 3D Semantic Scene Completion (SSC)，以解决现有方法在捕获 3D 体素网格长程依赖和部署成本方面的挑战。该框架先通过 voxel-based semantic segmentation (SS) 预训练获取可转移的 meta-knowledge，并利用模拟合作感知数据集从多个连接的自动车辆 (CAVs) 的聚合传感器数据监督训练，然后整合 deformable convolution、大内核 attention 和 Mamba 模型来增强长序列建模能力。最终，MetaSSC 在实验中实现了最先进性能，大幅超越竞争模型，同时显著降低了部署成本。",
      "categories": [
        "cs.CV",
        "cs.AI"
      ],
      "primary_category": "cs.CV",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2411.03672v2",
      "published_date": "2024-11-06 05:11:25 UTC",
      "updated_date": "2025-02-19 17:21:53 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-20T22:11:24.232743"
    },
    {
      "arxiv_id": "2411.03670v2",
      "title": "Touchstone Benchmark: Are We on the Right Way for Evaluating AI Algorithms for Medical Segmentation?",
      "title_zh": "翻译失败",
      "authors": [
        "Pedro R. A. S. Bassi",
        "Wenxuan Li",
        "Yucheng Tang",
        "Fabian Isensee",
        "Zifu Wang",
        "Jieneng Chen",
        "Yu-Cheng Chou",
        "Yannick Kirchhoff",
        "Maximilian Rokuss",
        "Ziyan Huang",
        "Jin Ye",
        "Junjun He",
        "Tassilo Wald",
        "Constantin Ulrich",
        "Michael Baumgartner",
        "Saikat Roy",
        "Klaus H. Maier-Hein",
        "Paul Jaeger",
        "Yiwen Ye",
        "Yutong Xie",
        "Jianpeng Zhang",
        "Ziyang Chen",
        "Yong Xia",
        "Zhaohu Xing",
        "Lei Zhu",
        "Yousef Sadegheih",
        "Afshin Bozorgpour",
        "Pratibha Kumari",
        "Reza Azad",
        "Dorit Merhof",
        "Pengcheng Shi",
        "Ting Ma",
        "Yuxin Du",
        "Fan Bai",
        "Tiejun Huang",
        "Bo Zhao",
        "Haonan Wang",
        "Xiaomeng Li",
        "Hanxue Gu",
        "Haoyu Dong",
        "Jichen Yang",
        "Maciej A. Mazurowski",
        "Saumya Gupta",
        "Linshan Wu",
        "Jiaxin Zhuang",
        "Hao Chen",
        "Holger Roth",
        "Daguang Xu",
        "Matthew B. Blaschko",
        "Sergio Decherchi",
        "Andrea Cavalli",
        "Alan L. Yuille",
        "Zongwei Zhou"
      ],
      "abstract": "How can we test AI performance? This question seems trivial, but it isn't.\nStandard benchmarks often have problems such as in-distribution and small-size\ntest sets, oversimplified metrics, unfair comparisons, and short-term outcome\npressure. As a consequence, good performance on standard benchmarks does not\nguarantee success in real-world scenarios. To address these problems, we\npresent Touchstone, a large-scale collaborative segmentation benchmark of 9\ntypes of abdominal organs. This benchmark is based on 5,195 training CT scans\nfrom 76 hospitals around the world and 5,903 testing CT scans from 11\nadditional hospitals. This diverse test set enhances the statistical\nsignificance of benchmark results and rigorously evaluates AI algorithms across\nvarious out-of-distribution scenarios. We invited 14 inventors of 19 AI\nalgorithms to train their algorithms, while our team, as a third party,\nindependently evaluated these algorithms on three test sets. In addition, we\nalso evaluated pre-existing AI frameworks--which, differing from algorithms,\nare more flexible and can support different algorithms--including MONAI from\nNVIDIA, nnU-Net from DKFZ, and numerous other open-source frameworks. We are\ncommitted to expanding this benchmark to encourage more innovation of AI\nalgorithms for the medical domain.",
      "tldr_zh": "该论文批评了现有AI算法医疗分割基准的问题，包括测试集分布不均、规模小、指标简化、不公平比较及短期结果压力，导致基准表现无法反映真实场景。作者提出Touchstone基准，这是一个大规模协作分割基准，涵盖9种腹部器官，基于5,195个训练CT扫描（来自76个医院）和5,903个测试CT扫描（来自11个额外医院），以提升统计意义和out-of-distribution场景评估。研究邀请14个发明者训练19个AI算法，并由第三方团队独立评估这些算法及预存框架如MONAI和nnU-Net，旨在推动医疗AI创新并计划扩展基准。",
      "categories": [
        "cs.CV",
        "cs.AI"
      ],
      "primary_category": "cs.CV",
      "comment": "Accepted to NeurIPS-2024",
      "pdf_url": "http://arxiv.org/pdf/2411.03670v2",
      "published_date": "2024-11-06 05:09:34 UTC",
      "updated_date": "2025-01-20 02:44:19 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-20T22:11:35.349842"
    },
    {
      "arxiv_id": "2411.03665v1",
      "title": "Evaluating Moral Beliefs across LLMs through a Pluralistic Framework",
      "title_zh": "翻译失败",
      "authors": [
        "Xuelin Liu",
        "Yanfei Zhu",
        "Shucheng Zhu",
        "Pengyuan Liu",
        "Ying Liu",
        "Dong Yu"
      ],
      "abstract": "Proper moral beliefs are fundamental for language models, yet assessing these\nbeliefs poses a significant challenge. This study introduces a novel\nthree-module framework to evaluate the moral beliefs of four prominent large\nlanguage models. Initially, we constructed a dataset containing 472 moral\nchoice scenarios in Chinese, derived from moral words. The decision-making\nprocess of the models in these scenarios reveals their moral principle\npreferences. By ranking these moral choices, we discern the varying moral\nbeliefs held by different language models. Additionally, through moral debates,\nwe investigate the firmness of these models to their moral choices. Our\nfindings indicate that English language models, namely ChatGPT and Gemini,\nclosely mirror moral decisions of the sample of Chinese university students,\ndemonstrating strong adherence to their choices and a preference for\nindividualistic moral beliefs. In contrast, Chinese models such as Ernie and\nChatGLM lean towards collectivist moral beliefs, exhibiting ambiguity in their\nmoral choices and debates. This study also uncovers gender bias embedded within\nthe moral beliefs of all examined language models. Our methodology offers an\ninnovative means to assess moral beliefs in both artificial and human\nintelligence, facilitating a comparison of moral values across different\ncultures.",
      "tldr_zh": "本研究提出一个三模块框架，用于评估ChatGPT、Gemini、Ernie和ChatGLM等LLMs的道德信念，通过构建一个包含472个中文道德选择场景的数据集来揭示模型的道德原则偏好和决策排名。实验涉及模型在这些场景中的决策分析和道德辩论，显示ChatGPT和Gemini更接近中国大学生的个人主义道德信念，并表现出更强的选择坚持性，而Ernie和ChatGLM则偏向集体主义信念且在辩论中更模糊。所有模型均存在性别偏见，这一框架为比较不同文化中人工和人类智能的道德价值观提供了创新评估方法。",
      "categories": [
        "cs.CL",
        "cs.AI"
      ],
      "primary_category": "cs.CL",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2411.03665v1",
      "published_date": "2024-11-06 04:52:38 UTC",
      "updated_date": "2024-11-06 04:52:38 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-20T22:11:47.848969"
    },
    {
      "arxiv_id": "2411.03656v1",
      "title": "Requirements Engineering for Older Adult Digital Health Software: A Systematic Literature Review",
      "title_zh": "老年人群数字健康软件的需求工程：系统文献综述",
      "authors": [
        "Yuqing Xiao",
        "John Grundy",
        "Anuradha Madugalla"
      ],
      "abstract": "Growth of the older adult population has led to an increasing interest in\ntechnology-supported aged care. However, the area has some challenges such as a\nlack of caregivers and limitations in understanding the emotional, social,\nphysical, and mental well-being needs of seniors. Furthermore, there is a gap\nin the understanding between developers and ageing people of their\nrequirements. Digital health can be important in supporting older adults\nwellbeing, emotional requirements, and social needs. Requirements Engineering\n(RE) is a major software engineering field, which can help to identify, elicit\nand prioritize the requirements of stakeholders and ensure that the systems\nmeet standards for performance, reliability, and usability. We carried out a\nsystematic review of the literature on RE for older adult digital health\nsoftware. This was necessary to show the representatives of the current stage\nof understanding the needs of older adults in aged care digital health. Using\nestablished guidelines outlined by the Kitchenham method, the PRISMA and the\nPICO guideline, we developed a protocol, followed by the systematic exploration\nof eight databases. This resulted in 69 primary studies of high relevance,\nwhich were subsequently subjected to data extraction, synthesis, and reporting.\nWe highlight key RE processes in digital health software for ageing people. It\nexplored the utilization of technology for older user well-being and care, and\nthe evaluations of such solutions. The review also identified key limitations\nfound in existing primary studies that inspire future research opportunities.\nThe results indicate that requirement gathering and understanding have a\nsignificant variation between different studies. The differences are in the\nquality, depth, and techniques adopted for requirement gathering and these\ndifferences are largely due to uneven adoption of RE methods.",
      "tldr_zh": "这篇论文通过系统文献综述探讨了Requirements Engineering (RE) 在老年数字健康软件中的应用，旨在解决老年人群的福祉需求与开发人员理解差距的问题。研究采用Kitchenham 方法、PRISMA 和 PICO 指南，从八个数据库中筛选出69篇相关研究，进行数据提取和合成，突出了RE 进程的关键点，如需求识别、优先级设定和系统可用性评估。结果显示，不同研究在需求收集的质量、深度和所用技术上存在显著差异，主要源于RE 方法采用的不均匀，这为未来优化老年健康技术提供了重要研究机会。",
      "categories": [
        "cs.SE",
        "cs.AI",
        "cs.HC",
        "cs.LG"
      ],
      "primary_category": "cs.SE",
      "comment": "arxiv version of SLR on RE for Older Adult Digital Health Software",
      "pdf_url": "http://arxiv.org/pdf/2411.03656v1",
      "published_date": "2024-11-06 04:35:39 UTC",
      "updated_date": "2024-11-06 04:35:39 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-20T22:11:59.860263"
    },
    {
      "arxiv_id": "2411.05832v1",
      "title": "Diversify, Contextualize, and Adapt: Efficient Entropy Modeling for Neural Image Codec",
      "title_zh": "翻译失败",
      "authors": [
        "Jun-Hyuk Kim",
        "Seungeon Kim",
        "Won-Hee Lee",
        "Dokwan Oh"
      ],
      "abstract": "Designing a fast and effective entropy model is challenging but essential for\npractical application of neural codecs. Beyond spatial autoregressive entropy\nmodels, more efficient backward adaptation-based entropy models have been\nrecently developed. They not only reduce decoding time by using smaller number\nof modeling steps but also maintain or even improve rate--distortion\nperformance by leveraging more diverse contexts for backward adaptation.\nDespite their significant progress, we argue that their performance has been\nlimited by the simple adoption of the design convention for forward adaptation:\nusing only a single type of hyper latent representation, which does not provide\nsufficient contextual information, especially in the first modeling step. In\nthis paper, we propose a simple yet effective entropy modeling framework that\nleverages sufficient contexts for forward adaptation without compromising on\nbit-rate. Specifically, we introduce a strategy of diversifying hyper latent\nrepresentations for forward adaptation, i.e., using two additional types of\ncontexts along with the existing single type of context. In addition, we\npresent a method to effectively use the diverse contexts for contextualizing\nthe current elements to be encoded/decoded. By addressing the limitation of the\nprevious approach, our proposed framework leads to significant performance\nimprovements. Experimental results on popular datasets show that our proposed\nframework consistently improves rate--distortion performance across various\nbit-rate regions, e.g., 3.73% BD-rate gain over the state-of-the-art baseline\non the Kodak dataset.",
      "tldr_zh": "该论文针对神经图像编解码器的熵模型设计挑战，提出了一种高效框架，以解决现有后向适应（backward adaptation）方法因仅使用单一类型超潜表示（hyper latent representation）而导致的上下文信息不足问题。框架通过多样化超潜表示策略（即引入两种额外上下文类型）并优化上下文化方法，为前向适应（forward adaptation）提供更丰富的上下文，同时不增加比特率。实验结果显示，该框架在流行数据集上显著提升了率失真性能，例如在 Kodak 数据集上比最先进基线实现了 3.73% 的 BD-rate gain。",
      "categories": [
        "cs.CV",
        "cs.AI",
        "cs.MM"
      ],
      "primary_category": "cs.CV",
      "comment": "NeurIPS 2024",
      "pdf_url": "http://arxiv.org/pdf/2411.05832v1",
      "published_date": "2024-11-06 04:30:04 UTC",
      "updated_date": "2024-11-06 04:30:04 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-20T22:12:12.427095"
    },
    {
      "arxiv_id": "2411.05831v1",
      "title": "To Ask or Not to Ask? Detecting Absence of Information in Vision and Language Navigation",
      "title_zh": "问还是不问？检测视觉和语言导航中的信息缺失",
      "authors": [
        "Savitha Sam Abraham",
        "Sourav Garg",
        "Feras Dayoub"
      ],
      "abstract": "Recent research in Vision Language Navigation (VLN) has overlooked the\ndevelopment of agents' inquisitive abilities, which allow them to ask\nclarifying questions when instructions are incomplete. This paper addresses how\nagents can recognize \"when\" they lack sufficient information, without focusing\non \"what\" is missing, particularly in VLN tasks with vague instructions.\nEquipping agents with this ability enhances efficiency by reducing potential\ndigressions and seeking timely assistance. The challenge in identifying such\nuncertain points is balancing between being overly cautious (high recall) and\noverly confident (high precision). We propose an attention-based\ninstruction-vagueness estimation module that learns associations between\ninstructions and the agent's trajectory. By leveraging instruction-to-path\nalignment information during training, the module's vagueness estimation\nperformance improves by around 52% in terms of precision-recall balance. In our\nablative experiments, we also demonstrate the effectiveness of incorporating\nthis additional instruction-to-path attention network alongside the cross-modal\nattention networks within the navigator module. Our results show that the\nattention scores from the instruction-to-path attention network serve as better\nindicators for estimating vagueness.",
      "tldr_zh": "本研究探讨了Vision Language Navigation (VLN)中代理如何检测指令的不完整性，以提升其询问能力，从而避免因模糊指令导致的路径偏差。论文提出一个基于注意力的instruction-vagueness estimation模块，通过学习指令与代理轨迹之间的关联，利用instruction-to-path alignment信息进行训练，使模块的精确-召回平衡性能提升约52%。实验结果表明，该模块与导航模块的跨模态注意网络结合后，能更准确地识别指令模糊性，并证明了其在提高VLN代理效率方面的有效性。",
      "categories": [
        "cs.AI",
        "cs.CV"
      ],
      "primary_category": "cs.AI",
      "comment": "Accepted at WACV 2025",
      "pdf_url": "http://arxiv.org/pdf/2411.05831v1",
      "published_date": "2024-11-06 04:21:15 UTC",
      "updated_date": "2024-11-06 04:21:15 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-20T22:12:22.832301"
    },
    {
      "arxiv_id": "2411.03651v1",
      "title": "Policy Aggregation",
      "title_zh": "策略聚合",
      "authors": [
        "Parand A. Alamdari",
        "Soroush Ebadian",
        "Ariel D. Procaccia"
      ],
      "abstract": "We consider the challenge of AI value alignment with multiple individuals\nthat have different reward functions and optimal policies in an underlying\nMarkov decision process. We formalize this problem as one of policy\naggregation, where the goal is to identify a desirable collective policy. We\nargue that an approach informed by social choice theory is especially suitable.\nOur key insight is that social choice methods can be reinterpreted by\nidentifying ordinal preferences with volumes of subsets of the state-action\noccupancy polytope. Building on this insight, we demonstrate that a variety of\nmethods--including approval voting, Borda count, the proportional veto core,\nand quantile fairness--can be practically applied to policy aggregation.",
      "tldr_zh": "该论文探讨了AI价值对齐（AI value alignment）问题，即在Markov决策过程（Markov decision process）中，如何为具有不同奖励函数和最优策略的多个个体聚合一个理想的集体策略（policy aggregation）。作者提出使用社会选择理论（social choice theory）作为指导框架，将序数偏好重新解释为状态-动作占用多面体（state-action occupancy polytope）子集的体积，从而实现策略聚合。实验结果显示，这种方法可以实际应用于多种机制，包括approval voting、Borda count、proportional veto core和quantile fairness，提供了一种可行的多代理人决策解决方案。",
      "categories": [
        "cs.AI",
        "cs.GT",
        "cs.LG"
      ],
      "primary_category": "cs.AI",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2411.03651v1",
      "published_date": "2024-11-06 04:19:50 UTC",
      "updated_date": "2024-11-06 04:19:50 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-20T22:12:36.730400"
    },
    {
      "arxiv_id": "2411.03644v2",
      "title": "Deploying Multi-task Online Server with Large Language Model",
      "title_zh": "翻译失败",
      "authors": [
        "Yincen Qu",
        "Chao Ma",
        "Xiangying Dai",
        "Hui Zhou",
        "Yiting Wu",
        "Hengyue Liu"
      ],
      "abstract": "In the industry, numerous tasks are deployed online. Traditional approaches\noften tackle each task separately by its own network, which leads to excessive\ncosts for developing and scaling models, especially in the context of large\nlanguage models. Although multi-task methods can save costs through parameter\nsharing, they often struggle to outperform single-task methods in real-world\napplications. To tackle these challenges, we present a three-stage multi-task\nlearning framework for large language models. It involves task filtering,\nfollowed by fine-tuning on high-resource tasks, and finally fine-tuning on all\ntasks. We conducted comprehensive experiments in single-task and multi-task\nsettings. Our approach, exemplified on different benchmarks, demonstrates that\nit is able to achieve performance comparable to the single-task method while\nreducing up to 90.9\\% of its overhead.",
      "tldr_zh": "本研究针对在线部署多任务时，传统单任务网络的高开发和扩展成本问题，提出了一种三阶段多任务学习框架，适用于Large Language Models。该框架包括任务过滤、首先在高资源任务上微调、然后在所有任务上微调，从而实现参数共享并提升效率。在不同基准的实验中，该方法达到了与单任务方法相当的性能，同时减少了高达90.9%的开销。",
      "categories": [
        "cs.CL",
        "cs.AI"
      ],
      "primary_category": "cs.CL",
      "comment": "Accepted by COLING 2025 Industry Track",
      "pdf_url": "http://arxiv.org/pdf/2411.03644v2",
      "published_date": "2024-11-06 03:48:41 UTC",
      "updated_date": "2024-11-07 02:44:34 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-20T22:12:48.071980"
    },
    {
      "arxiv_id": "2411.03638v1",
      "title": "Adaptive Stereo Depth Estimation with Multi-Spectral Images Across All Lighting Conditions",
      "title_zh": "翻译失败",
      "authors": [
        "Zihan Qin",
        "Jialei Xu",
        "Wenbo Zhao",
        "Junjun Jiang",
        "Xianming Liu"
      ],
      "abstract": "Depth estimation under adverse conditions remains a significant challenge.\nRecently, multi-spectral depth estimation, which integrates both visible light\nand thermal images, has shown promise in addressing this issue. However,\nexisting algorithms struggle with precise pixel-level feature matching,\nlimiting their ability to fully exploit geometric constraints across different\nspectra. To address this, we propose a novel framework incorporating stereo\ndepth estimation to enforce accurate geometric constraints. In particular, we\ntreat the visible light and thermal images as a stereo pair and utilize a\nCross-modal Feature Matching (CFM) Module to construct a cost volume for\npixel-level matching. To mitigate the effects of poor lighting on stereo\nmatching, we introduce Degradation Masking, which leverages robust monocular\nthermal depth estimation in degraded regions. Our method achieves\nstate-of-the-art (SOTA) performance on the Multi-Spectral Stereo (MS2) dataset,\nwith qualitative evaluations demonstrating high-quality depth maps under\nvarying lighting conditions.",
      "tldr_zh": "这篇论文针对多光谱图像在各种照明条件下的深度估计挑战，提出了一种自适应立体深度估计框架，以解决现有算法在像素级特征匹配和几何约束利用上的不足。该框架将可见光和热成像图像视为立体对，利用 Cross-modal Feature Matching (CFM) Module 构建成本体积进行精确匹配，并引入 Degradation Masking 技术，通过稳健的单目热成像深度估计来处理退化区域。实验结果表明，该方法在 Multi-Spectral Stereo (MS2) 数据集上达到了 SOTA 性能，并在定性评估中展示了高质量的深度图。",
      "categories": [
        "cs.CV",
        "cs.AI"
      ],
      "primary_category": "cs.CV",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2411.03638v1",
      "published_date": "2024-11-06 03:30:46 UTC",
      "updated_date": "2024-11-06 03:30:46 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-20T22:13:00.123121"
    },
    {
      "arxiv_id": "2411.03630v2",
      "title": "RTify: Aligning Deep Neural Networks with Human Behavioral Decisions",
      "title_zh": "翻译失败",
      "authors": [
        "Yu-Ang Cheng",
        "Ivan Felipe Rodriguez",
        "Sixuan Chen",
        "Kohitij Kar",
        "Takeo Watanabe",
        "Thomas Serre"
      ],
      "abstract": "Current neural network models of primate vision focus on replicating overall\nlevels of behavioral accuracy, often neglecting perceptual decisions' rich,\ndynamic nature. Here, we introduce a novel computational framework to model the\ndynamics of human behavioral choices by learning to align the temporal dynamics\nof a recurrent neural network (RNN) to human reaction times (RTs). We describe\nan approximation that allows us to constrain the number of time steps an RNN\ntakes to solve a task with human RTs. The approach is extensively evaluated\nagainst various psychophysics experiments. We also show that the approximation\ncan be used to optimize an \"ideal-observer\" RNN model to achieve an optimal\ntradeoff between speed and accuracy without human data. The resulting model is\nfound to account well for human RT data. Finally, we use the approximation to\ntrain a deep learning implementation of the popular Wong-Wang decision-making\nmodel. The model is integrated with a convolutional neural network (CNN) model\nof visual processing and evaluated using both artificial and natural image\nstimuli. Overall, we present a novel framework that helps align current vision\nmodels with human behavior, bringing us closer to an integrated model of human\nvision.",
      "tldr_zh": "该研究引入了 RTify 框架，通过学习将循环神经网络 (RNN) 的时间动态与人类反应时间 (RTs) 对齐，从而更好地模拟人类感知决策的动态过程。框架采用一种近似方法来约束 RNN 在任务中的时间步骤，以匹配人类 RTs，并对各种心理物理实验进行了广泛评估。结果显示，该方法能优化“理想观察者”RNN 模型，实现速度和准确性的最佳权衡，并成功解释人类 RT 数据。此外，研究将该框架应用于训练 Wong-Wang 决策模型与卷积神经网络 (CNN) 视觉处理模型的整合，使用人工和自然图像刺激进行测试，最终推动了视觉模型与人类行为的对齐，迈向集成人类视觉模型。",
      "categories": [
        "cs.AI",
        "q-bio.NC"
      ],
      "primary_category": "cs.AI",
      "comment": "Published at NeurIPS 2024",
      "pdf_url": "http://arxiv.org/pdf/2411.03630v2",
      "published_date": "2024-11-06 03:04:05 UTC",
      "updated_date": "2024-12-26 09:11:08 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-20T22:13:13.219935"
    },
    {
      "arxiv_id": "2411.03628v1",
      "title": "StreamingBench: Assessing the Gap for MLLMs to Achieve Streaming Video Understanding",
      "title_zh": "翻译失败",
      "authors": [
        "Junming Lin",
        "Zheng Fang",
        "Chi Chen",
        "Zihao Wan",
        "Fuwen Luo",
        "Peng Li",
        "Yang Liu",
        "Maosong Sun"
      ],
      "abstract": "The rapid development of Multimodal Large Language Models (MLLMs) has\nexpanded their capabilities from image comprehension to video understanding.\nHowever, most of these MLLMs focus primarily on offline video comprehension,\nnecessitating extensive processing of all video frames before any queries can\nbe made. This presents a significant gap compared to the human ability to\nwatch, listen, think, and respond to streaming inputs in real time,\nhighlighting the limitations of current MLLMs. In this paper, we introduce\nStreamingBench, the first comprehensive benchmark designed to evaluate the\nstreaming video understanding capabilities of MLLMs. StreamingBench assesses\nthree core aspects of streaming video understanding: (1) real-time visual\nunderstanding, (2) omni-source understanding, and (3) contextual understanding.\nThe benchmark consists of 18 tasks, featuring 900 videos and 4,500\nhuman-curated QA pairs. Each video features five questions presented at\ndifferent time points to simulate a continuous streaming scenario. We conduct\nexperiments on StreamingBench with 13 open-source and proprietary MLLMs and\nfind that even the most advanced proprietary MLLMs like Gemini 1.5 Pro and\nGPT-4o perform significantly below human-level streaming video understanding\ncapabilities. We hope our work can facilitate further advancements for MLLMs,\nempowering them to approach human-level video comprehension and interaction in\nmore realistic scenarios.",
      "tldr_zh": "该研究指出了多模态大语言模型(MLLMs)在视频理解方面的局限性，即它们主要依赖离线处理所有帧，无法实现像人类一样实时响应流媒体输入。论文引入了StreamingBench，这是第一个全面基准，用于评估MLLMs的流媒体视频理解能力，包括实时视觉理解、全源理解和上下文理解三个核心方面，并包含18个任务、900个视频和4,500个人工策划的QA对。实验结果显示，13个开源和专有MLLMs（如Gemini 1.5 Pro和GPT-4o）的性能远低于人类水平，准确率存在显著差距。该工作旨在推动MLLMs的进一步发展，实现更接近人类水平的视频理解和交互。",
      "categories": [
        "cs.CV",
        "cs.AI"
      ],
      "primary_category": "cs.CV",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2411.03628v1",
      "published_date": "2024-11-06 02:50:30 UTC",
      "updated_date": "2024-11-06 02:50:30 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-20T22:13:24.272797"
    },
    {
      "arxiv_id": "2411.03622v2",
      "title": "Fully Hyperbolic Rotation for Knowledge Graph Embedding",
      "title_zh": "完全双曲旋转用于知识图谱嵌入",
      "authors": [
        "Qiuyu Liang",
        "Weihua Wang",
        "Feilong Bao",
        "Guanglai Gao"
      ],
      "abstract": "Hyperbolic rotation is commonly used to effectively model knowledge graphs\nand their inherent hierarchies. However, existing hyperbolic rotation models\nrely on logarithmic and exponential mappings for feature transformation. These\nmodels only project data features into hyperbolic space for rotation, limiting\ntheir ability to fully exploit the hyperbolic space. To address this problem,\nwe propose a novel fully hyperbolic model designed for knowledge graph\nembedding. Instead of feature mappings, we define the model directly in\nhyperbolic space with the Lorentz model. Our model considers each relation in\nknowledge graphs as a Lorentz rotation from the head entity to the tail entity.\nWe adopt the Lorentzian version distance as the scoring function for measuring\nthe plausibility of triplets. Extensive results on standard knowledge graph\ncompletion benchmarks demonstrated that our model achieves competitive results\nwith fewer parameters. In addition, our model get the state-of-the-art\nperformance on datasets of CoDEx-s and CoDEx-m, which are more diverse and\nchallenging than before. Our code is available at\nhttps://github.com/llqy123/FHRE.",
      "tldr_zh": "本研究针对现有超曲空间旋转模型的局限性，提出了一种全新的Fully Hyperbolic模型，用于知识图谱嵌入。该模型直接在Lorentz模型的超曲空间中定义，将每个知识图谱关系视为从head entity到tail entity的Lorentz rotation，并使用Lorentzian version distance作为评分函数来评估三元组的合理性。实验结果显示，该模型在标准知识图谱完成基准上取得了竞争性性能，同时参数更少，并在更具挑战性的CoDEx-s和CoDEx-m数据集上达到了state-of-the-art水平。",
      "categories": [
        "cs.AI",
        "cs.LG"
      ],
      "primary_category": "cs.AI",
      "comment": "Accepted by ECAI 2024",
      "pdf_url": "http://arxiv.org/pdf/2411.03622v2",
      "published_date": "2024-11-06 02:41:26 UTC",
      "updated_date": "2024-11-07 03:26:58 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-20T22:13:35.269795"
    },
    {
      "arxiv_id": "2411.03618v1",
      "title": "Cross Feature Fusion of Fundus Image and Generated Lesion Map for Referable Diabetic Retinopathy Classification",
      "title_zh": "翻译失败",
      "authors": [
        "Dahyun Mok",
        "Junghyun Bum",
        "Le Duc Tai",
        "Hyunseung Choo"
      ],
      "abstract": "Diabetic Retinopathy (DR) is a primary cause of blindness, necessitating\nearly detection and diagnosis. This paper focuses on referable DR\nclassification to enhance the applicability of the proposed method in clinical\npractice. We develop an advanced cross-learning DR classification method\nleveraging transfer learning and cross-attention mechanisms. The proposed\nmethod employs the Swin U-Net architecture to segment lesion maps from DR\nfundus images. The Swin U-Net segmentation model, enriched with DR lesion\ninsights, is transferred to generate a lesion map. Both the fundus image and\nits segmented lesion map are used as complementary inputs for the\nclassification model. A cross-attention mechanism is deployed to improve the\nmodel's ability to capture fine-grained details from the input pairs. Our\nexperiments, utilizing two public datasets, FGADR and EyePACS, demonstrate a\nsuperior accuracy of 94.6%, surpassing current state-of-the-art methods by\n4.4%. To this end, we aim for the proposed method to be seamlessly integrated\ninto clinical workflows, enhancing accuracy and efficiency in identifying\nreferable DR.",
      "tldr_zh": "本论文针对Diabetic Retinopathy (DR) 作为主要致盲原因的问题，提出了一种先进的跨学习分类方法，利用转移学习和cross-attention机制来提升可参考DR的诊断准确性。方法采用Swin U-Net架构从眼底图像中分割生成病变地图，并将该地图与原始图像作为互补输入，通过cross-attention机制捕捉细粒度细节。实验在FGADR和EyePACS两个公共数据集上实现了94.6%的准确率，比现有最先进方法高4.4%，有望无缝整合到临床工作流程中以提高诊断效率。",
      "categories": [
        "eess.IV",
        "cs.AI",
        "cs.CV"
      ],
      "primary_category": "eess.IV",
      "comment": "ACCV 2024 accepted",
      "pdf_url": "http://arxiv.org/pdf/2411.03618v1",
      "published_date": "2024-11-06 02:23:38 UTC",
      "updated_date": "2024-11-06 02:23:38 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-20T22:13:48.773934"
    },
    {
      "arxiv_id": "2411.03588v1",
      "title": "An Experimental Study on Decomposition-Based Deep Ensemble Learning for Traffic Flow Forecasting",
      "title_zh": "基于分解的深度集成学习在交通流量预测中的实验研究",
      "authors": [
        "Qiyuan Zhu",
        "A. K. Qin",
        "Hussein Dia",
        "Adriana-Simona Mihaita",
        "Hanna Grzybowska"
      ],
      "abstract": "Traffic flow forecasting is a crucial task in intelligent transport systems.\nDeep learning offers an effective solution, capturing complex patterns in\ntime-series traffic flow data to enable the accurate prediction. However, deep\nlearning models are prone to overfitting the intricate details of flow data,\nleading to poor generalisation. Recent studies suggest that decomposition-based\ndeep ensemble learning methods may address this issue by breaking down a time\nseries into multiple simpler signals, upon which deep learning models are built\nand ensembled to generate the final prediction. However, few studies have\ncompared the performance of decomposition-based ensemble methods with\nnon-decomposition-based ones which directly utilise raw time-series data. This\nwork compares several decomposition-based and non-decomposition-based deep\nensemble learning methods. Experimental results on three traffic datasets\ndemonstrate the superiority of decomposition-based ensemble methods, while also\nrevealing their sensitivity to aggregation strategies and forecasting horizons.",
      "tldr_zh": "这篇论文通过实验研究了基于分解的深度集成学习（decomposition-based deep ensemble learning）在交通流量预测中的应用，以解决深度学习模型容易过拟合复杂时间序列数据的问题。研究方法包括将时间序列分解成多个简单信号，然后构建和集成深度学习模型，与直接使用原始数据的非分解方法进行比较。实验结果显示，在三个交通数据集上，基于分解的集成方法表现出显著优越性，但对聚合策略和预测时段（forecasting horizons）高度敏感。",
      "categories": [
        "cs.LG",
        "cs.AI",
        "cs.NE"
      ],
      "primary_category": "cs.LG",
      "comment": "This work has been accepted by the 2024 Australasian Joint Conference\n  on Artificial Intelligence (AJCAI 2024)",
      "pdf_url": "http://arxiv.org/pdf/2411.03588v1",
      "published_date": "2024-11-06 01:00:17 UTC",
      "updated_date": "2024-11-06 01:00:17 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-20T22:14:00.044061"
    },
    {
      "arxiv_id": "2411.03576v1",
      "title": "Hybrid Attention for Robust RGB-T Pedestrian Detection in Real-World Conditions",
      "title_zh": "翻译失败",
      "authors": [
        "Arunkumar Rathinam",
        "Leo Pauly",
        "Abd El Rahman Shabayek",
        "Wassim Rharbaoui",
        "Anis Kacem",
        "Vincent Gaudillière",
        "Djamila Aouada"
      ],
      "abstract": "Multispectral pedestrian detection has gained significant attention in recent\nyears, particularly in autonomous driving applications. To address the\nchallenges posed by adversarial illumination conditions, the combination of\nthermal and visible images has demonstrated its advantages. However, existing\nfusion methods rely on the critical assumption that the RGB-Thermal (RGB-T)\nimage pairs are fully overlapping. These assumptions often do not hold in\nreal-world applications, where only partial overlap between images can occur\ndue to sensors configuration. Moreover, sensor failure can cause loss of\ninformation in one modality. In this paper, we propose a novel module called\nthe Hybrid Attention (HA) mechanism as our main contribution to mitigate\nperformance degradation caused by partial overlap and sensor failure, i.e. when\nat least part of the scene is acquired by only one sensor. We propose an\nimproved RGB-T fusion algorithm, robust against partial overlap and sensor\nfailure encountered during inference in real-world applications. We also\nleverage a mobile-friendly backbone to cope with resource constraints in\nembedded systems. We conducted experiments by simulating various partial\noverlap and sensor failure scenarios to evaluate the performance of our\nproposed method. The results demonstrate that our approach outperforms\nstate-of-the-art methods, showcasing its superiority in handling real-world\nchallenges.",
      "tldr_zh": "该论文针对 RGB-T 行人检测中的现实挑战，如图像部分重叠和传感器故障，提出了一种新型 Hybrid Attention (HA) 机制，以缓解性能下降问题。HA 机制改进了 RGB-T 融合算法，使其在不完全重叠或单一传感器场景下更具鲁棒性，同时采用了移动友好型 backbone 以适应嵌入式系统的资源限制。通过模拟各种部分重叠和传感器故障场景的实验，结果表明该方法优于现有状态方法，在真实世界条件下显著提升了检测性能。",
      "categories": [
        "cs.CV",
        "cs.AI"
      ],
      "primary_category": "cs.CV",
      "comment": "Accepted for publication in IEEE Robotics and Automation Letters,\n  October 2024",
      "pdf_url": "http://arxiv.org/pdf/2411.03576v1",
      "published_date": "2024-11-06 00:34:26 UTC",
      "updated_date": "2024-11-06 00:34:26 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-20T22:14:11.830836"
    },
    {
      "arxiv_id": "2411.03569v1",
      "title": "Towards Personalized Federated Learning via Comprehensive Knowledge Distillation",
      "title_zh": "翻译失败",
      "authors": [
        "Pengju Wang",
        "Bochao Liu",
        "Weijia Guo",
        "Yong Li",
        "Shiming Ge"
      ],
      "abstract": "Federated learning is a distributed machine learning paradigm designed to\nprotect data privacy. However, data heterogeneity across various clients\nresults in catastrophic forgetting, where the model rapidly forgets previous\nknowledge while acquiring new knowledge. To address this challenge,\npersonalized federated learning has emerged to customize a personalized model\nfor each client. However, the inherent limitation of this mechanism is its\nexcessive focus on personalization, potentially hindering the generalization of\nthose models. In this paper, we present a novel personalized federated learning\nmethod that uses global and historical models as teachers and the local model\nas the student to facilitate comprehensive knowledge distillation. The\nhistorical model represents the local model from the last round of client\ntraining, containing historical personalized knowledge, while the global model\nrepresents the aggregated model from the last round of server aggregation,\ncontaining global generalized knowledge. By applying knowledge distillation, we\neffectively transfer global generalized knowledge and historical personalized\nknowledge to the local model, thus mitigating catastrophic forgetting and\nenhancing the general performance of personalized models. Extensive\nexperimental results demonstrate the significant advantages of our method.",
      "tldr_zh": "本论文针对联邦学习（Federated Learning）中数据异质性导致的灾难性遗忘（Catastrophic Forgetting）问题，提出了一种新型个性化联邦学习（Personalized Federated Learning）方法。方法使用全局模型（包含全局泛化知识）和历史模型（包含历史个性化知识）作为教师，对局部模型作为学生进行全面知识蒸馏（Knowledge Distillation），从而有效转移知识、缓解遗忘并提升模型的泛化性能。实验结果显示，该方法在多个场景下表现出显著优势，改善了个性化模型的整体表现。",
      "categories": [
        "cs.LG",
        "cs.AI",
        "cs.CR",
        "cs.CV"
      ],
      "primary_category": "cs.LG",
      "comment": "Accepted by IEEE SMC 2024",
      "pdf_url": "http://arxiv.org/pdf/2411.03569v1",
      "published_date": "2024-11-06 00:17:36 UTC",
      "updated_date": "2024-11-06 00:17:36 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-20T22:14:23.687620"
    }
  ],
  "raw_papers_fetched": true,
  "papers_count": 103,
  "processed_papers_count": 103,
  "failed_papers_count": 0,
  "summary_generated": true,
  "daily_data_saved": true,
  "last_update": "2025-05-20T22:14:46.159040"
}