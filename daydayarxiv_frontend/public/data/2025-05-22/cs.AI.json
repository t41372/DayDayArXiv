{
  "date": "2025-05-22",
  "category": "cs.AI",
  "summary": "欢迎来到 UTC 时间 2025-05-22 的 arXiv 中文 TLDR 快报！今天 arXiv 的论文主要聚焦于 AI 模型的推理能力、强化学习、多模态理解和安全应用等领域，亮点包括强化学习在视觉生成和多代理系统中的创新，以及知名学者如 Hongsheng Li 和 Philipp Krähenbühl 的多篇高质量工作，这些论文为 LLM 和视觉语言模型的实际应用提供了新思路。\n\n下面，我挑选并简要讨论了今天更具影响力和话题度的论文（约 15 篇），优先关注 AI 推理、强化学习和多模态领域的突破性贡献，其他次要论文（如特定领域的生物或物理模型）则快速掠过，只提核心点。相关论文已按主题归类，便于阅读。\n\n### 强化学习与推理增强\n- **GoT-R1: Unleashing Reasoning Capability of MLLM for Visual Generation with Reinforcement Learning**（中文：通过强化学习释放多模态语言模型的视觉生成推理能力）  \n  这篇论文提出 GoT-R1 框架，使用强化学习提升多模态模型在处理复杂文本提示（如多对象空间关系）的生成能力。主要贡献是通过双阶段奖励机制评估语义和空间准确性，在 T2I-CompBench 基准上显著改善生成质量，展示了强化学习在视觉领域的潜力。\n\n- **Delving into RL for Image Generation with CoT: A Study on DPO vs. GRPO**（中文：探索链式思维中的强化学习：DPO 与 GRPO 在图像生成中的比较）  \n  作者 Chengzhuo Tong 和 Hongsheng Li 团队比较了 DPO 和 GRPO 算法在图像生成中的性能，强调了奖励模型泛化对算法效果的关键影响。发现 GRPO 在领域内表现更优，并通过实验验证了扩展策略的鲁棒性。\n\n- **Interactive Post-Training for Vision-Language-Action Models**（中文：视觉-语言-动作模型的交互式后训练）  \n  论文引入 RIPT-VLA 方法，通过强化学习后训练 VLA 模型，仅需稀疏奖励即可提升性能。主要发现：在轻量模型上成功率提升 21.2%，并在低数据场景下实现 97% 成功率，展示了高效交互训练的应用价值。\n\n- **R1-Searcher++: Incentivizing the Dynamic Knowledge Acquisition of LLMs via Reinforcement Learning**（中文：通过强化学习激励 LLM 的动态知识获取）  \n  该工作扩展了 R1-Searcher 框架，采用两阶段训练（SFT 和 RL）来提升 LLM 的内部和外部知识整合。贡献在于引入奖励机制减少幻觉问题，并在实验中超越现有 RAG 方法。\n\n- **AceReason-Nemotron: Advancing Math and Code Reasoning through Reinforcement Learning**（中文：通过强化学习提升数学和代码推理的 Nemotron 模型）  \n  论文提出一种强化学习策略，先在数学任务上训练再扩展到代码，显著提升了小规模模型的推理能力。主要发现：在 GSM8K 等基准上，准确率提升 14.6%，证明了 RL 在高效模型训练中的优势。\n\n- **Tool-Star: Empowering LLM-Brained Multi-Tool Reasoner via Reinforcement Learning**（中文：通过强化学习增强多工具推理的 LLM 代理）  \n  作者 Guannan Liang 团队设计了 Tool-Star 框架，使用 RL 优化多工具协作。关键贡献是构建可扩展的数据合成管道，并在实验中减少了 58.6% 的计算开销，同时提升推理准确性。\n\n### 多模态与视觉理解\n- **Let Androids Dream of Electric Sheep: A Human-like Image Implication Understanding and Reasoning Framework**（中文：让机器人做电子羊梦：图像隐喻理解和推理框架）  \n  论文提出 LAD 框架，通过三阶段过程（感知、搜索、推理）处理图像隐喻。发现它在英语和中文基准上超越 15+ 多模态模型，展示了人类认知式多模态推理的应用潜力。\n\n- **SpatialScore: Towards Unified Evaluation for Multimodal Spatial Understanding**（中文：面向多模态空间理解的统一评估框架）  \n  作者 Weidi Xie 团队构建了 SpatialScore 基准，评估多模态模型的空间感知能力。贡献在于整合 12 个数据集并提出 SpatialAgent 系统，揭示了模型在 3D 空间任务中的挑战。\n\n- **Fact-R1: Towards Explainable Video Misinformation Detection with Deep Reasoning**（中文：通过深度推理实现可解释视频错误信息检测）  \n  这篇论文引入 Fact-R1 框架，使用强化学习和三阶段训练检测视频错误信息。关键发现：在多基准上提升了 10% 的准确率，并提供了可解释的推理路径。\n\n### 代理系统与基准测试\n- **X-MAS: Towards Building Multi-Agent Systems with Heterogeneous LLMs**（中文：构建异构 LLM 多代理系统的框架）  \n  作者 Rui Ye 团队探索了异构 LLM 代理系统，构建了 X-MAS-Bench 基准。发现混合代理配置可提升 47% 的性能，强调了多样性在协作系统中的作用。\n\n- **MASLab: A Unified and Comprehensive Codebase for LLM-based Multi-Agent Systems**（中文：LLM 多代理系统的统一代码库）  \n  这篇论文发布 MASLab 框架，整合 20+ 多代理方法。贡献在于提供统一环境和基准，促进公平比较和扩展。\n\n- **NovelSeek: When Agent Becomes the Scientist**（中文：当代理成为科学家：自主科学研究的闭环系统）  \n  作者 Lei Bai 团队提出 NovelSeek 框架，支持跨领域科学任务。发现它在反应预测等任务中提升 7.8% 的准确率，展示了代理在科研中的潜力。\n\n- **DriveMoE: Mixture-of-Experts for Vision-Language-Action Model in End-to-End Autonomous Driving**（中文：混合专家的视觉-语言-动作模型在端到端自动驾驶中的应用）  \n  论文设计了 DriveMoE 系统，使用混合专家提升自动驾驶性能。关键发现：在 CARLA 基准上成功率提升 10%，证明了视觉和动作专家的协同效果。\n\n其他论文，如那些聚焦特定领域（如 PDE 建模或语音增强），虽有技术贡献但影响力较小，我仅快速提及：\n- **Guided Diffusion Sampling on Function Spaces with Applications to PDEs**（中文：函数空间中的引导扩散采样及其在 PDE 上的应用）提出 FunDPS 方法，提升 PDE 任务的准确性 32%。\n- **PAEFF: Precise Alignment and Enhanced Gated Feature Fusion for Face-Voice Association**（中文：人脸-语音关联的精确对齐和增强特征融合）在语音任务中提升关联性能，已被 Interspeech 接受。\n- 其余如量子优化或生物基准论文（如 Beyond Correlation: Towards Causal Large Language Model Agents），虽有创新但非主流话题，故不展开。\n\n总之，今天的论文突显了 AI 模型在推理和多模态上的进展，强化学习框架如 GoT-R1 和 Tool-Star 值得关注，能为实际应用带来高效优化。未来几天，继续追踪这些领域的动态！",
  "papers": [
    {
      "arxiv_id": "2505.17022v1",
      "title": "GoT-R1: Unleashing Reasoning Capability of MLLM for Visual Generation with Reinforcement Learning",
      "title_zh": "翻译失败",
      "authors": [
        "Chengqi Duan",
        "Rongyao Fang",
        "Yuqing Wang",
        "Kun Wang",
        "Linjiang Huang",
        "Xingyu Zeng",
        "Hongsheng Li",
        "Xihui Liu"
      ],
      "abstract": "Visual generation models have made remarkable progress in creating realistic\nimages from text prompts, yet struggle with complex prompts that specify\nmultiple objects with precise spatial relationships and attributes. Effective\nhandling of such prompts requires explicit reasoning about the semantic content\nand spatial layout. We present GoT-R1, a framework that applies reinforcement\nlearning to enhance semantic-spatial reasoning in visual generation. Building\nupon the Generation Chain-of-Thought approach, GoT-R1 enables models to\nautonomously discover effective reasoning strategies beyond predefined\ntemplates through carefully designed reinforcement learning. To achieve this,\nwe propose a dual-stage multi-dimensional reward framework that leverages MLLMs\nto evaluate both the reasoning process and final output, enabling effective\nsupervision across the entire generation pipeline. The reward system assesses\nsemantic alignment, spatial accuracy, and visual quality in a unified approach.\nExperimental results demonstrate significant improvements on T2I-CompBench\nbenchmark, particularly in compositional tasks involving precise spatial\nrelationships and attribute binding. GoT-R1 advances the state-of-the-art in\nimage generation by successfully transferring sophisticated reasoning\ncapabilities to the visual generation domain. To facilitate future research, we\nmake our code and pretrained models publicly available at\nhttps://github.com/gogoduan/GoT-R1.",
      "tldr_zh": "该论文提出 GoT-R1 框架，利用 Reinforcement Learning 增强多模态大型语言模型(MLLMs)在视觉生成中的语义-空间推理能力，以应对复杂文本提示（如多个对象、精确空间关系和属性）的挑战。框架基于 Chain-of-Thought 方法，允许模型自主发现有效的推理策略，并引入双阶段多维度奖励系统，通过 MLLMs 评估推理过程和最终输出的语义对齐、空间准确性及视觉质量。实验在 T2I-CompBench 基准上显示，GoT-R1 在组合任务中显著提升了生成性能，超越了现有状态-of-the-art。作者公开了代码和预训练模型，以促进未来研究。",
      "categories": [
        "cs.CV",
        "cs.AI",
        "cs.CL",
        "cs.LG",
        "cs.MM"
      ],
      "primary_category": "cs.CV",
      "comment": "Github page refer to: https://github.com/gogoduan/GoT-R1",
      "pdf_url": "http://arxiv.org/pdf/2505.17022v1",
      "published_date": "2025-05-22 17:59:58 UTC",
      "updated_date": "2025-05-22 17:59:58 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-25T03:07:33.580123"
    },
    {
      "arxiv_id": "2505.17019v1",
      "title": "Let Androids Dream of Electric Sheep: A Human-like Image Implication Understanding and Reasoning Framework",
      "title_zh": "翻译失败",
      "authors": [
        "Chenhao Zhang",
        "Yazhe Niu"
      ],
      "abstract": "Metaphorical comprehension in images remains a critical challenge for AI\nsystems, as existing models struggle to grasp the nuanced cultural, emotional,\nand contextual implications embedded in visual content. While multimodal large\nlanguage models (MLLMs) excel in basic Visual Question Answer (VQA) tasks, they\nstruggle with a fundamental limitation on image implication tasks: contextual\ngaps that obscure the relationships between different visual elements and their\nabstract meanings. Inspired by the human cognitive process, we propose Let\nAndroids Dream (LAD), a novel framework for image implication understanding and\nreasoning. LAD addresses contextual missing through the three-stage framework:\n(1) Perception: converting visual information into rich and multi-level textual\nrepresentations, (2) Search: iteratively searching and integrating cross-domain\nknowledge to resolve ambiguity, and (3) Reasoning: generating context-alignment\nimage implication via explicit reasoning. Our framework with the lightweight\nGPT-4o-mini model achieves SOTA performance compared to 15+ MLLMs on English\nimage implication benchmark and a huge improvement on Chinese benchmark,\nperforming comparable with the GPT-4o model on Multiple-Choice Question (MCQ)\nand outperforms 36.7% on Open-Style Question (OSQ). Additionally, our work\nprovides new insights into how AI can more effectively interpret image\nimplications, advancing the field of vision-language reasoning and human-AI\ninteraction. Our project is publicly available at\nhttps://github.com/MING-ZCH/Let-Androids-Dream-of-Electric-Sheep.",
      "tldr_zh": "本研究针对AI在图像隐喻理解中的挑战，提出Let Androids Dream (LAD)框架，以模拟人类认知过程解决Multimodal Large Language Models (MLLMs)在Visual Question Answer (VQA)任务中的上下文差距问题。该框架包括三个阶段：Perception（将视觉信息转换为多级文本表示）、Search（迭代搜索跨领域知识以消除歧义），以及Reasoning（通过显式推理生成与上下文对齐的图像隐喻）。实验结果显示，使用轻量级GPT-4o-mini模型的LAD在英语和中文图像隐喻基准上达到State-of-the-Art (SOTA)性能，与GPT-4o在Multiple-Choice Question (MCQ)上相当，并在Open-Style Question (OSQ)上提升36.7%，从而为视觉语言推理和人类-AI交互提供了新见解。",
      "categories": [
        "cs.CV",
        "cs.AI",
        "cs.CY"
      ],
      "primary_category": "cs.CV",
      "comment": "16 pages, 9 figures. Code & Dataset:\n  https://github.com/MING-ZCH/Let-Androids-Dream-of-Electric-Sheep",
      "pdf_url": "http://arxiv.org/pdf/2505.17019v1",
      "published_date": "2025-05-22 17:59:53 UTC",
      "updated_date": "2025-05-22 17:59:53 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-25T03:07:46.253442"
    },
    {
      "arxiv_id": "2505.17017v1",
      "title": "Delving into RL for Image Generation with CoT: A Study on DPO vs. GRPO",
      "title_zh": "翻译失败",
      "authors": [
        "Chengzhuo Tong",
        "Ziyu Guo",
        "Renrui Zhang",
        "Wenyu Shan",
        "Xinyu Wei",
        "Zhenghao Xing",
        "Hongsheng Li",
        "Pheng-Ann Heng"
      ],
      "abstract": "Recent advancements underscore the significant role of Reinforcement Learning\n(RL) in enhancing the Chain-of-Thought (CoT) reasoning capabilities of large\nlanguage models (LLMs). Two prominent RL algorithms, Direct Preference\nOptimization (DPO) and Group Relative Policy Optimization (GRPO), are central\nto these developments, showcasing different pros and cons. Autoregressive image\ngeneration, also interpretable as a sequential CoT reasoning process, presents\nunique challenges distinct from LLM-based CoT reasoning. These encompass\nensuring text-image consistency, improving image aesthetic quality, and\ndesigning sophisticated reward models, rather than relying on simpler\nrule-based rewards. While recent efforts have extended RL to this domain, these\nexplorations typically lack an in-depth analysis of the domain-specific\nchallenges and the characteristics of different RL strategies. To bridge this\ngap, we provide the first comprehensive investigation of the GRPO and DPO\nalgorithms in autoregressive image generation, evaluating their in-domain\nperformance and out-of-domain generalization, while scrutinizing the impact of\ndifferent reward models on their respective capabilities. Our findings reveal\nthat GRPO and DPO exhibit distinct advantages, and crucially, that reward\nmodels possessing stronger intrinsic generalization capabilities potentially\nenhance the generalization potential of the applied RL algorithms. Furthermore,\nwe systematically explore three prevalent scaling strategies to enhance both\ntheir in-domain and out-of-domain proficiency, deriving unique insights into\nefficiently scaling performance for each paradigm. We hope our study paves a\nnew path for inspiring future work on developing more effective RL algorithms\nto achieve robust CoT reasoning in the realm of autoregressive image\ngeneration. Code is released at\nhttps://github.com/ZiyuGuo99/Image-Generation-CoT",
      "tldr_zh": "本研究探讨了强化学习(RL)算法 Direct Preference Optimization (DPO) 与 Group Relative Policy Optimization (GRPO) 在链式思维(CoT)推理下的 autoregressive 图像生成中的应用，针对文本-图像一致性、图像美学质量和复杂奖励模型设计等独特挑战进行首次全面分析。\n通过评估两者的领域内性能、领域外泛化能力及奖励模型的影响，研究发现 GRPO 和 DPO 各具优势，且奖励模型的内在泛化能力可显著提升 RL 算法的泛化潜力。\n此外，系统探索了三种缩放策略，以优化两算法的性能，提供针对图像生成 CoT 推理的宝贵见解。\n这项工作旨在为开发更有效的 RL 算法，推动 autoregressive 图像生成领域的稳健进步。",
      "categories": [
        "cs.CV",
        "cs.AI",
        "cs.CL",
        "cs.LG"
      ],
      "primary_category": "cs.CV",
      "comment": "Code is released at https://github.com/ZiyuGuo99/Image-Generation-CoT",
      "pdf_url": "http://arxiv.org/pdf/2505.17017v1",
      "published_date": "2025-05-22 17:59:49 UTC",
      "updated_date": "2025-05-22 17:59:49 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-25T03:07:58.179187"
    },
    {
      "arxiv_id": "2505.17016v1",
      "title": "Interactive Post-Training for Vision-Language-Action Models",
      "title_zh": "翻译失败",
      "authors": [
        "Shuhan Tan",
        "Kairan Dou",
        "Yue Zhao",
        "Philipp Krähenbühl"
      ],
      "abstract": "We introduce RIPT-VLA, a simple and scalable reinforcement-learning-based\ninteractive post-training paradigm that fine-tunes pretrained\nVision-Language-Action (VLA) models using only sparse binary success rewards.\nExisting VLA training pipelines rely heavily on offline expert demonstration\ndata and supervised imitation, limiting their ability to adapt to new tasks and\nenvironments under low-data regimes. RIPT-VLA addresses this by enabling\ninteractive post-training with a stable policy optimization algorithm based on\ndynamic rollout sampling and leave-one-out advantage estimation.\n  RIPT-VLA has the following characteristics. First, it applies to various VLA\nmodels, resulting in an improvement on the lightweight QueST model by 21.2%,\nand the 7B OpenVLA-OFT model to an unprecedented 97.5% success rate. Second, it\nis computationally efficient and data-efficient: with only one demonstration,\nRIPT-VLA enables an unworkable SFT model (4%) to succeed with a 97% success\nrate within 15 iterations. Furthermore, we demonstrate that the policy learned\nby RIPT-VLA generalizes across different tasks and scenarios and is robust to\nthe initial state context. These results highlight RIPT-VLA as a practical and\neffective paradigm for post-training VLA models through minimal supervision.",
      "tldr_zh": "本文提出 RIPT-VLA，一种基于强化学习的交互式后训练范式，用于微调预训练的 Vision-Language-Action (VLA) 模型，仅依赖稀疏的二元成功奖励，以解决现有 VLA 模型在低数据环境下适应新任务的局限性。该方法采用动态 rollout sampling 和 leave-one-out advantage estimation 的稳定策略优化算法，提升模型的交互学习能力。实验结果显示，RIPT-VLA 将轻量级 QueST 模型提高了 21.2%，并将 7B OpenVLA-OFT 模型的成功率提升至 97.5%。此外，该方法数据高效，仅需一个演示即可使 SFT 模型在 15 次迭代内从 4% 成功率提升到 97%，并展现出在不同任务和场景中的良好泛化性和对初始状态的鲁棒性。",
      "categories": [
        "cs.LG",
        "cs.AI",
        "cs.CV",
        "cs.RO"
      ],
      "primary_category": "cs.LG",
      "comment": "Project page: https://ariostgx.github.io/ript_vla/",
      "pdf_url": "http://arxiv.org/pdf/2505.17016v1",
      "published_date": "2025-05-22 17:59:45 UTC",
      "updated_date": "2025-05-22 17:59:45 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-25T03:08:11.316243"
    },
    {
      "arxiv_id": "2505.17012v1",
      "title": "SpatialScore: Towards Unified Evaluation for Multimodal Spatial Understanding",
      "title_zh": "SpatialScore：面向多模态空间理解的统一评估",
      "authors": [
        "Haoning Wu",
        "Xiao Huang",
        "Yaohui Chen",
        "Ya Zhang",
        "Yanfeng Wang",
        "Weidi Xie"
      ],
      "abstract": "Multimodal large language models (MLLMs) have achieved impressive success in\nquestion-answering tasks, yet their capabilities for spatial understanding are\nless explored. This work investigates a critical question: do existing MLLMs\npossess 3D spatial perception and understanding abilities? Concretely, we make\nthe following contributions in this paper: (i) we introduce VGBench, a\nbenchmark specifically designed to assess MLLMs for visual geometry perception,\ne.g., camera pose and motion estimation; (ii) we propose SpatialScore, the most\ncomprehensive and diverse multimodal spatial understanding benchmark to date,\nintegrating VGBench with relevant data from the other 11 existing datasets.\nThis benchmark comprises 28K samples across various spatial understanding\ntasks, modalities, and QA formats, along with a carefully curated challenging\nsubset, SpatialScore-Hard; (iii) we develop SpatialAgent, a novel multi-agent\nsystem incorporating 9 specialized tools for spatial understanding, supporting\nboth Plan-Execute and ReAct reasoning paradigms; (iv) we conduct extensive\nevaluations to reveal persistent challenges in spatial reasoning while\ndemonstrating the effectiveness of SpatialAgent. We believe SpatialScore will\noffer valuable insights and serve as a rigorous benchmark for the next\nevolution of MLLMs.",
      "tldr_zh": "这篇论文探讨了多模态大语言模型 (MLLMs) 在空间理解方面的能力，针对其 3D 空间感知的不足，提出了统一的评估框架。研究的主要贡献包括引入 VGBench 基准用于评估视觉几何感知（如相机位姿和运动估计）、构建 SpatialScore 基准（整合 11 个数据集，共 28K 样本，包括挑战子集 SpatialScore-Hard），以及开发 SpatialAgent 多智能体系统，该系统整合 9 个专用工具，支持 Plan-Execute 和 ReAct 推理范式。通过广泛实验，论文揭示了 MLLMs 在空间推理中的持续挑战，并证明了 SpatialAgent 的有效性，为未来 MLLMs 发展提供了宝贵基准。",
      "categories": [
        "cs.CV",
        "cs.AI"
      ],
      "primary_category": "cs.CV",
      "comment": "Technical Report; Project Page:\n  https://haoningwu3639.github.io/SpatialScore",
      "pdf_url": "http://arxiv.org/pdf/2505.17012v1",
      "published_date": "2025-05-22 17:59:03 UTC",
      "updated_date": "2025-05-22 17:59:03 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-25T03:08:22.683832"
    },
    {
      "arxiv_id": "2505.17010v1",
      "title": "Understanding Prompt Tuning and In-Context Learning via Meta-Learning",
      "title_zh": "翻译失败",
      "authors": [
        "Tim Genewein",
        "Kevin Wenliang Li",
        "Jordi Grau-Moya",
        "Anian Ruoss",
        "Laurent Orseau",
        "Marcus Hutter"
      ],
      "abstract": "Prompting is one of the main ways to adapt a pretrained model to target\ntasks. Besides manually constructing prompts, many prompt optimization methods\nhave been proposed in the literature. Method development is mainly empirically\ndriven, with less emphasis on a conceptual understanding of prompting. In this\npaper we discuss how optimal prompting can be understood through a Bayesian\nview, which also implies some fundamental limitations of prompting that can\nonly be overcome by tuning weights. The paper explains in detail how\nmeta-trained neural networks behave as Bayesian predictors over the pretraining\ndistribution, whose hallmark feature is rapid in-context adaptation. Optimal\nprompting can be studied formally as conditioning these Bayesian predictors,\nyielding criteria for target tasks where optimal prompting is and is not\npossible. We support the theory with educational experiments on LSTMs and\nTransformers, where we compare different versions of prefix-tuning and\ndifferent weight-tuning methods. We also confirm that soft prefixes, which are\nsequences of real-valued vectors outside the token alphabet, can lead to very\neffective prompts for trained and even untrained networks by manipulating\nactivations in ways that are not achievable by hard tokens. This adds an\nimportant mechanistic aspect beyond the conceptual Bayesian theory.",
      "tldr_zh": "本文通过 Bayesian 视角分析 Prompt Tuning 和 In-Context Learning 的机制，解释 meta-trained 神经网络如何作为 Bayesian 预测器，支持快速适应预训练分布。作者探讨了最优提示的条件及其局限性，指出这些限制仅能通过调整权重来克服，并通过实验比较不同版本的 Prefix-Tuning 和 Weight-Tuning 方法。研究发现，Soft Prefixes 能通过操纵激活值创建高效提示，即使在未经训练的网络上，从而为提示优化提供重要机制洞见。",
      "categories": [
        "cs.LG",
        "cs.AI",
        "stat.ML"
      ],
      "primary_category": "cs.LG",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2505.17010v1",
      "published_date": "2025-05-22 17:58:53 UTC",
      "updated_date": "2025-05-22 17:58:53 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-25T03:08:32.719821"
    },
    {
      "arxiv_id": "2505.17005v1",
      "title": "R1-Searcher++: Incentivizing the Dynamic Knowledge Acquisition of LLMs via Reinforcement Learning",
      "title_zh": "翻译失败",
      "authors": [
        "Huatong Song",
        "Jinhao Jiang",
        "Wenqing Tian",
        "Zhipeng Chen",
        "Yuhuan Wu",
        "Jiahao Zhao",
        "Yingqian Min",
        "Wayne Xin Zhao",
        "Lei Fang",
        "Ji-Rong Wen"
      ],
      "abstract": "Large Language Models (LLMs) are powerful but prone to hallucinations due to\nstatic knowledge. Retrieval-Augmented Generation (RAG) helps by injecting\nexternal information, but current methods often are costly, generalize poorly,\nor ignore the internal knowledge of the model. In this paper, we introduce\nR1-Searcher++, a novel framework designed to train LLMs to adaptively leverage\nboth internal and external knowledge sources. R1-Searcher++ employs a two-stage\ntraining strategy: an initial SFT Cold-start phase for preliminary format\nlearning, followed by RL for Dynamic Knowledge Acquisition. The RL stage uses\noutcome-supervision to encourage exploration, incorporates a reward mechanism\nfor internal knowledge utilization, and integrates a memorization mechanism to\ncontinuously assimilate retrieved information, thereby enriching the model's\ninternal knowledge. By leveraging internal knowledge and external search\nengine, the model continuously improves its capabilities, enabling efficient\nretrieval-augmented reasoning. Our experiments demonstrate that R1-Searcher++\noutperforms previous RAG and reasoning methods and achieves efficient\nretrieval. The code is available at\nhttps://github.com/RUCAIBox/R1-Searcher-plus.",
      "tldr_zh": "该研究提出 R1-Searcher++ 框架，通过强化学习（RL）激励大型语言模型（LLMs）动态获取知识，解决 LLMs 静态知识导致的幻觉问题，并克服现有 Retrieval-Augmented Generation (RAG) 方法的成本高和泛化差等问题。框架采用两阶段训练策略：先进行 SFT Cold-start 阶段以初步学习格式，然后通过 RL for Dynamic Knowledge Acquisition 阶段，使用 outcome-supervision 鼓励探索、奖励机制促进内部知识利用，以及 memorization 机制吸收外部信息以丰富模型知识。实验结果显示，R1-Searcher++ 在检索增强推理任务中优于现有 RAG 和推理方法，实现高效检索，并开源代码以便进一步应用。",
      "categories": [
        "cs.CL",
        "cs.AI",
        "cs.IR"
      ],
      "primary_category": "cs.CL",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2505.17005v1",
      "published_date": "2025-05-22 17:58:26 UTC",
      "updated_date": "2025-05-22 17:58:26 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-25T03:08:45.052378"
    },
    {
      "arxiv_id": "2505.17004v1",
      "title": "Guided Diffusion Sampling on Function Spaces with Applications to PDEs",
      "title_zh": "函数空间上的引导扩散采样及其偏微分方程应用",
      "authors": [
        "Jiachen Yao",
        "Abbas Mammadov",
        "Julius Berner",
        "Gavin Kerrigan",
        "Jong Chul Ye",
        "Kamyar Azizzadenesheli",
        "Anima Anandkumar"
      ],
      "abstract": "We propose a general framework for conditional sampling in PDE-based inverse\nproblems, targeting the recovery of whole solutions from extremely sparse or\nnoisy measurements. This is accomplished by a function-space diffusion model\nand plug-and-play guidance for conditioning. Our method first trains an\nunconditional discretization-agnostic denoising model using neural operator\narchitectures. At inference, we refine the samples to satisfy sparse\nobservation data via a gradient-based guidance mechanism. Through rigorous\nmathematical analysis, we extend Tweedie's formula to infinite-dimensional\nHilbert spaces, providing the theoretical foundation for our posterior sampling\napproach. Our method (FunDPS) accurately captures posterior distributions in\nfunction spaces under minimal supervision and severe data scarcity. Across five\nPDE tasks with only 3% observation, our method achieves an average 32% accuracy\nimprovement over state-of-the-art fixed-resolution diffusion baselines while\nreducing sampling steps by 4x. Furthermore, multi-resolution fine-tuning\nensures strong cross-resolution generalizability. To the best of our knowledge,\nthis is the first diffusion-based framework to operate independently of\ndiscretization, offering a practical and flexible solution for forward and\ninverse problems in the context of PDEs. Code is available at\nhttps://github.com/neuraloperator/FunDPS",
      "tldr_zh": "该研究提出了一种名为 FunDPS 的框架，用于基于 PDEs（偏微分方程）的逆问题中，从稀疏或噪声数据恢复完整解，通过函数空间扩散模型和即插即用指导机制实现条件采样。方法首先训练一个无条件、离散化无关的去噪模型，利用神经算子架构，并在推理阶段通过基于梯度的指导细化样本，同时通过扩展 Tweedie's formula 到无限维 Hilbert 空间提供理论支撑。在五个 PDE 任务中，仅使用 3% 的观测数据，FunDPS 比现有扩散基线平均提高 32% 的准确率，并将采样步骤减少 4 倍，同时实现多分辨率泛化，成为首个独立于离散化的扩散框架，为 PDEs 的正向和逆问题提供灵活解决方案。",
      "categories": [
        "cs.LG",
        "cs.AI",
        "cs.NA",
        "math.NA",
        "stat.ML"
      ],
      "primary_category": "cs.LG",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2505.17004v1",
      "published_date": "2025-05-22 17:58:12 UTC",
      "updated_date": "2025-05-22 17:58:12 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-25T03:08:57.845172"
    },
    {
      "arxiv_id": "2505.17002v1",
      "title": "PAEFF: Precise Alignment and Enhanced Gated Feature Fusion for Face-Voice Association",
      "title_zh": "PAEFF：精确对齐和增强门控特征融合用于人脸-语音关联",
      "authors": [
        "Abdul Hannan",
        "Muhammad Arslan Manzoor",
        "Shah Nawaz",
        "Muhammad Irzam Liaqat",
        "Markus Schedl",
        "Mubashir Noman"
      ],
      "abstract": "We study the task of learning association between faces and voices, which is\ngaining interest in the multimodal community lately. These methods suffer from\nthe deliberate crafting of negative mining procedures as well as the reliance\non the distant margin parameter. These issues are addressed by learning a joint\nembedding space in which orthogonality constraints are applied to the fused\nembeddings of faces and voices. However, embedding spaces of faces and voices\npossess different characteristics and require spaces to be aligned before\nfusing them. To this end, we propose a method that accurately aligns the\nembedding spaces and fuses them with an enhanced gated fusion thereby improving\nthe performance of face-voice association. Extensive experiments on the\nVoxCeleb dataset reveals the merits of the proposed approach.",
      "tldr_zh": "本文研究面部和声音关联（face-voice association）的任务，提出PAEFF方法，通过精确对齐（Precise Alignment）面部和声音的嵌入空间（embedding spaces），并采用增强的门控特征融合（Enhanced Gated Feature Fusion）来解决现有方法的负样本挖掘和边距参数依赖问题。相比传统方法，该框架在联合嵌入空间中应用正交约束，提高了关联性能。在VoxCeleb数据集上的广泛实验显示，该方法显著提升了整体表现。",
      "categories": [
        "cs.CV",
        "cs.AI"
      ],
      "primary_category": "cs.CV",
      "comment": "Accepted at InterSpeech 2025",
      "pdf_url": "http://arxiv.org/pdf/2505.17002v1",
      "published_date": "2025-05-22 17:57:55 UTC",
      "updated_date": "2025-05-22 17:57:55 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-25T03:09:08.361292"
    },
    {
      "arxiv_id": "2505.16998v1",
      "title": "Do Large Language Models Excel in Complex Logical Reasoning with Formal Language?",
      "title_zh": "大型语言模型是否在复杂逻辑推理中使用形式语言方面表现出色？",
      "authors": [
        "Jin Jiang",
        "Jianing Wang",
        "Yuchen Yan",
        "Yang Liu",
        "Jianhua Zhu",
        "Mengdi Zhang",
        "Xunliang Cai",
        "Liangcai Gao"
      ],
      "abstract": "Large Language Models (LLMs) have been shown to achieve breakthrough\nperformance on complex logical reasoning tasks. Nevertheless, most existing\nresearch focuses on employing formal language to guide LLMs to derive reliable\nreasoning paths, while systematic evaluations of these capabilities are still\nlimited. In this paper, we aim to conduct a comprehensive evaluation of LLMs\nacross various logical reasoning problems utilizing formal languages. From the\nperspective of three dimensions, i.e., spectrum of LLMs, taxonomy of tasks, and\nformat of trajectories, our key findings are: 1) Thinking models significantly\noutperform Instruct models, especially when formal language is employed; 2) All\nLLMs exhibit limitations in inductive reasoning capability, irrespective of\nwhether they use a formal language; 3) Data with PoT format achieves the best\ngeneralization performance across other languages. Additionally, we also curate\nthe formal-relative training data to further enhance the small language models,\nand the experimental results indicate that a simple rejected fine-tuning method\ncan better enable LLMs to generalize across formal languages and achieve the\nbest overall performance. Our codes and reports are available at\nhttps://github.com/jiangjin1999/FormalEval.",
      "tldr_zh": "本研究评估了大型语言模型（LLMs）在利用形式语言进行复杂逻辑推理方面的性能，通过从LLMs谱系、任务分类和轨迹格式三个维度进行全面评估。关键发现包括：Thinking models显著优于Instruct models，尤其在使用形式语言时；所有LLMs在inductive reasoning能力上存在局限性；PoT格式的数据在泛化性能上表现出最佳效果。此外，论文通过整理形式语言相关训练数据并采用rejected fine-tuning方法，提升了小语言模型在形式语言上的泛化能力，并实现了整体最佳性能。",
      "categories": [
        "cs.CL",
        "cs.AI"
      ],
      "primary_category": "cs.CL",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2505.16998v1",
      "published_date": "2025-05-22 17:57:23 UTC",
      "updated_date": "2025-05-22 17:57:23 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-25T03:09:21.588265"
    },
    {
      "arxiv_id": "2505.16997v1",
      "title": "X-MAS: Towards Building Multi-Agent Systems with Heterogeneous LLMs",
      "title_zh": "翻译失败",
      "authors": [
        "Rui Ye",
        "Xiangrui Liu",
        "Qimin Wu",
        "Xianghe Pang",
        "Zhenfei Yin",
        "Lei Bai",
        "Siheng Chen"
      ],
      "abstract": "LLM-based multi-agent systems (MAS) extend the capabilities of single LLMs by\nenabling cooperation among multiple specialized agents. However, most existing\nMAS frameworks rely on a single LLM to drive all agents, constraining the\nsystem's intelligence to the limit of that model. This paper explores the\nparadigm of heterogeneous LLM-driven MAS (X-MAS), where agents are powered by\ndiverse LLMs, elevating the system's potential to the collective intelligence\nof diverse LLMs. We introduce X-MAS-Bench, a comprehensive testbed designed to\nevaluate the performance of various LLMs across different domains and\nMAS-related functions. As an extensive empirical study, we assess 27 LLMs\nacross 5 domains (encompassing 21 test sets) and 5 functions, conducting over\n1.7 million evaluations to identify optimal model selections for each\ndomain-function combination. Building on these findings, we demonstrate that\ntransitioning from homogeneous to heterogeneous LLM-driven MAS can\nsignificantly enhance system performance without requiring structural redesign.\nSpecifically, in a chatbot-only MAS scenario, the heterogeneous configuration\nyields up to 8.4\\% performance improvement on the MATH dataset. In a mixed\nchatbot-reasoner scenario, the heterogeneous MAS could achieve a remarkable\n47\\% performance boost on the AIME dataset. Our results underscore the\ntransformative potential of heterogeneous LLMs in MAS, highlighting a promising\navenue for advancing scalable, collaborative AI systems.",
      "tldr_zh": "本论文提出X-MAS框架，旨在通过使用异构LLMs（不同的大型语言模型）构建多智能体系统（MAS），超越单一LLM的限制，提升系统的整体智能。研究引入X-MAS-Bench测试平台，对27个LLMs在5个领域（涵盖21个测试集）和5个功能的性能进行了超过170万次的评估，以识别最佳模型组合。结果显示，采用异构LLMs的MAS无需结构重设计即可显著提升性能，例如在chatbot-only场景中，MATH数据集上提升8.4%，而在混合chatbot-reasoner场景中，AIME数据集上提升47%。这一方法突显了异构LLMs在推进可扩展协作AI系统方面的变革潜力。",
      "categories": [
        "cs.AI",
        "cs.CL",
        "cs.MA"
      ],
      "primary_category": "cs.AI",
      "comment": "19 pages, 5 figures",
      "pdf_url": "http://arxiv.org/pdf/2505.16997v1",
      "published_date": "2025-05-22 17:56:39 UTC",
      "updated_date": "2025-05-22 17:56:39 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-25T03:09:34.469109"
    },
    {
      "arxiv_id": "2505.16994v1",
      "title": "$\\text{R}^2\\text{ec}$: Towards Large Recommender Models with Reasoning",
      "title_zh": "翻译失败",
      "authors": [
        "Runyang You",
        "Yongqi Li",
        "Xinyu Lin",
        "Xin Zhang",
        "Wenjie Wang",
        "Wenjie Li",
        "Liqiang Nie"
      ],
      "abstract": "Large recommender models have extended LLMs as powerful recommenders via\nencoding or item generation, and recent breakthroughs in LLM reasoning\nsynchronously motivate the exploration of reasoning in recommendation. Current\nstudies usually position LLMs as external reasoning modules to yield auxiliary\nthought for augmenting conventional recommendation pipelines. However, such\ndecoupled designs are limited in significant resource cost and suboptimal joint\noptimization. To address these issues, we propose \\name, a unified large\nrecommender model with intrinsic reasoning capabilities. Initially, we\nreconceptualize the model architecture to facilitate interleaved reasoning and\nrecommendation in the autoregressive process. Subsequently, we propose RecPO, a\ncorresponding reinforcement learning framework that optimizes \\name\\ both the\nreasoning and recommendation capabilities simultaneously in a single policy\nupdate; RecPO introduces a fused reward scheme that solely leverages\nrecommendation labels to simulate the reasoning capability, eliminating\ndependency on specialized reasoning annotations. Experiments on three datasets\nwith various baselines verify the effectiveness of \\name, showing relative\nimprovements of 68.67\\% in Hit@5 and 45.21\\% in NDCG@20. Code available at\nhttps://github.com/YRYangang/RRec.",
      "tldr_zh": "本论文提出 $\\text{R}^2\\text{ec}$，一个统一的推荐模型，旨在赋予大型推荐系统内在的推理能力，以克服当前依赖外部 LLMs 作为推理模块的资源消耗和优化不足问题。该模型通过重新设计架构，支持 autoregressive 过程中的交错推理和推荐操作，实现更高效的整合。论文同时引入 RecPO 强化学习框架，使用融合奖励方案仅基于推荐标签来同时优化推理和推荐能力，避免了对专门推理注解的依赖。在三个数据集上的实验验证了 $\\text{R}^2\\text{ec}$ 的有效性，比基线模型提升了 68.67% 的 Hit@5 和 45.21% 的 NDCG@20。",
      "categories": [
        "cs.IR",
        "cs.AI",
        "cs.CL"
      ],
      "primary_category": "cs.IR",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2505.16994v1",
      "published_date": "2025-05-22 17:55:43 UTC",
      "updated_date": "2025-05-22 17:55:43 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-25T03:09:45.924659"
    },
    {
      "arxiv_id": "2505.16988v1",
      "title": "MASLab: A Unified and Comprehensive Codebase for LLM-based Multi-Agent Systems",
      "title_zh": "翻译失败",
      "authors": [
        "Rui Ye",
        "Keduan Huang",
        "Qimin Wu",
        "Yuzhu Cai",
        "Tian Jin",
        "Xianghe Pang",
        "Xiangrui Liu",
        "Jiaqi Su",
        "Chen Qian",
        "Bohan Tang",
        "Kaiqu Liang",
        "Jiaao Chen",
        "Yue Hu",
        "Zhenfei Yin",
        "Rongye Shi",
        "Bo An",
        "Yang Gao",
        "Wenjun Wu",
        "Lei Bai",
        "Siheng Chen"
      ],
      "abstract": "LLM-based multi-agent systems (MAS) have demonstrated significant potential\nin enhancing single LLMs to address complex and diverse tasks in practical\napplications. Despite considerable advancements, the field lacks a unified\ncodebase that consolidates existing methods, resulting in redundant\nre-implementation efforts, unfair comparisons, and high entry barriers for\nresearchers. To address these challenges, we introduce MASLab, a unified,\ncomprehensive, and research-friendly codebase for LLM-based MAS. (1) MASLab\nintegrates over 20 established methods across multiple domains, each rigorously\nvalidated by comparing step-by-step outputs with its official implementation.\n(2) MASLab provides a unified environment with various benchmarks for fair\ncomparisons among methods, ensuring consistent inputs and standardized\nevaluation protocols. (3) MASLab implements methods within a shared streamlined\nstructure, lowering the barriers for understanding and extension. Building on\nMASLab, we conduct extensive experiments covering 10+ benchmarks and 8 models,\noffering researchers a clear and comprehensive view of the current landscape of\nMAS methods. MASLab will continue to evolve, tracking the latest developments\nin the field, and invite contributions from the broader open-source community.",
      "tldr_zh": "该研究针对LLM-based multi-agent systems (MAS)领域的碎片化问题，提出MASLab，这是一个统一的、全面的代码库，旨在整合20多个现有方法并进行严格验证，以避免重复实现和不公平比较。MASLab提供了一个标准化的基准环境，支持公平比较和方法扩展，降低了研究者的入门门槛。通过覆盖10+基准和8个模型的大规模实验，该代码库展示了MAS方法的当前景观，并计划持续更新并欢迎社区贡献。",
      "categories": [
        "cs.CL",
        "cs.AI",
        "cs.MA"
      ],
      "primary_category": "cs.CL",
      "comment": "18 pages, 11 figures",
      "pdf_url": "http://arxiv.org/pdf/2505.16988v1",
      "published_date": "2025-05-22 17:54:38 UTC",
      "updated_date": "2025-05-22 17:54:38 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-25T03:09:55.990892"
    },
    {
      "arxiv_id": "2505.16986v1",
      "title": "T1: A Tool-Oriented Conversational Dataset for Multi-Turn Agentic Planning",
      "title_zh": "翻译失败",
      "authors": [
        "Amartya Chakraborty",
        "Paresh Dashore",
        "Nadia Bathaee",
        "Anmol Jain",
        "Anirban Das",
        "Shi-Xiong Zhang",
        "Sambit Sahu",
        "Milind Naphade",
        "Genta Indra Winata"
      ],
      "abstract": "Large Language Models (LLMs) have demonstrated impressive capabilities as\nintelligent agents capable of solving complex problems. However, effective\nplanning in scenarios involving dependencies between API or tool\ncalls-particularly in multi-turn conversations-remains a significant challenge.\nTo address this, we introduce T1, a tool-augmented, multi-domain, multi-turn\nconversational dataset specifically designed to capture and manage inter-tool\ndependencies across diverse domains. T1 enables rigorous evaluation of agents'\nability to coordinate tool use across nine distinct domains (4 single domain\nand 5 multi-domain) with the help of an integrated caching mechanism for both\nshort- and long-term memory, while supporting dynamic replanning-such as\ndeciding whether to recompute or reuse cached results. Beyond facilitating\nresearch on tool use and planning, T1 also serves as a benchmark for evaluating\nthe performance of open-source language models. We present results powered by\nT1-Agent, highlighting their ability to plan and reason in complex,\ntool-dependent scenarios.",
      "tldr_zh": "本研究引入了 T1 数据集，这是一个工具增强的多领域多轮对话数据集，旨在解决大型语言模型 (LLMs) 在处理 API 或工具调用依赖性的多轮对话规划挑战。T1 设计捕捉和管理跨九个领域的工具间依赖（包括4个单领域和5个多领域），并集成缓存机制支持短期和长期记忆以及动态重新规划，如决定是否重用结果。实验结果展示了 T1-Agent 在复杂工具依赖场景中的出色规划和推理能力，并为评估开源语言模型的性能提供了一个可靠基准。",
      "categories": [
        "cs.CL",
        "cs.AI"
      ],
      "primary_category": "cs.CL",
      "comment": "Preprint",
      "pdf_url": "http://arxiv.org/pdf/2505.16986v1",
      "published_date": "2025-05-22 17:54:32 UTC",
      "updated_date": "2025-05-22 17:54:32 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-25T03:10:09.421834"
    },
    {
      "arxiv_id": "2505.16985v1",
      "title": "Extremely Simple Multimodal Outlier Synthesis for Out-of-Distribution Detection and Segmentation",
      "title_zh": "极其简单的多模态异常合成用于分布外检测和分割",
      "authors": [
        "Moru Liu",
        "Hao Dong",
        "Jessica Kelly",
        "Olga Fink",
        "Mario Trapp"
      ],
      "abstract": "Out-of-distribution (OOD) detection and segmentation are crucial for\ndeploying machine learning models in safety-critical applications such as\nautonomous driving and robot-assisted surgery. While prior research has\nprimarily focused on unimodal image data, real-world applications are\ninherently multimodal, requiring the integration of multiple modalities for\nimproved OOD detection. A key challenge is the lack of supervision signals from\nunknown data, leading to overconfident predictions on OOD samples. To address\nthis challenge, we propose Feature Mixing, an extremely simple and fast method\nfor multimodal outlier synthesis with theoretical support, which can be further\noptimized to help the model better distinguish between in-distribution (ID) and\nOOD data. Feature Mixing is modality-agnostic and applicable to various\nmodality combinations. Additionally, we introduce CARLA-OOD, a novel multimodal\ndataset for OOD segmentation, featuring synthetic OOD objects across diverse\nscenes and weather conditions. Extensive experiments on SemanticKITTI,\nnuScenes, CARLA-OOD datasets, and the MultiOOD benchmark demonstrate that\nFeature Mixing achieves state-of-the-art performance with a $10 \\times$ to $370\n\\times$ speedup. Our source code and dataset will be available at\nhttps://github.com/mona4399/FeatureMixing.",
      "tldr_zh": "该研究针对多模态场景中的 Out-of-Distribution (OOD) 检测和分割问题，提出了一种极其简单且快速的方法 Feature Mixing，用于合成异常样本，以解决模型对未知数据过自信的挑战。该方法基于理论支持，能够优化模型更好地区分 in-distribution (ID) 和 OOD 数据，且适用于各种模态组合。研究者还引入了新的多模态数据集 CARLA-OOD，包含多样场景和天气条件下的合成 OOD 对象，以支持 OOD 分割任务。在 SemanticKITTI、nuScenes、CARLA-OOD 和 MultiOOD benchmark 等数据集上的实验显示，Feature Mixing 实现了最先进性能，并带来 10 倍到 370 倍的速度提升。",
      "categories": [
        "cs.CV",
        "cs.AI",
        "cs.LG",
        "cs.RO"
      ],
      "primary_category": "cs.CV",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2505.16985v1",
      "published_date": "2025-05-22 17:54:30 UTC",
      "updated_date": "2025-05-22 17:54:30 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-25T03:10:21.919381"
    },
    {
      "arxiv_id": "2505.16982v1",
      "title": "Beyond Correlation: Towards Causal Large Language Model Agents in Biomedicine",
      "title_zh": "超越相关性：朝向生物医学中的因果大语言模型智能体",
      "authors": [
        "Adib Bazgir",
        "Amir Habibdoust Lafmajani",
        "Yuwen Zhang"
      ],
      "abstract": "Large Language Models (LLMs) show promise in biomedicine but lack true causal\nunderstanding, relying instead on correlations. This paper envisions causal LLM\nagents that integrate multimodal data (text, images, genomics, etc.) and\nperform intervention-based reasoning to infer cause-and-effect. Addressing this\nrequires overcoming key challenges: designing safe, controllable agentic\nframeworks; developing rigorous benchmarks for causal evaluation; integrating\nheterogeneous data sources; and synergistically combining LLMs with structured\nknowledge (KGs) and formal causal inference tools. Such agents could unlock\ntransformative opportunities, including accelerating drug discovery through\nautomated hypothesis generation and simulation, enabling personalized medicine\nthrough patient-specific causal models. This research agenda aims to foster\ninterdisciplinary efforts, bridging causal concepts and foundation models to\ndevelop reliable AI partners for biomedical progress.",
      "tldr_zh": "这篇论文指出，大型语言模型（LLMs）在生物医学领域虽有潜力，但仅依赖相关性而缺乏真正的因果理解。论文提出开发因果 LLM 代理，通过整合多模态数据（如文本、图像和基因组数据）以及基于干预的推理，来实现因果关系的推断。关键挑战包括设计安全可控的代理框架、建立严格的因果评估基准、整合异构数据源，以及将 LLMs 与结构化知识（KGs）和正式因果推理工具相结合。这种创新有望加速药物发现（如自动假设生成和模拟）和个性化医学（如患者特定因果模型），并推动跨学科努力，桥接因果概念与基础模型，为生物医学进步提供可靠的 AI 伙伴。",
      "categories": [
        "cs.AI",
        "physics.med-ph"
      ],
      "primary_category": "cs.AI",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2505.16982v1",
      "published_date": "2025-05-22 17:52:59 UTC",
      "updated_date": "2025-05-22 17:52:59 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-25T03:10:33.346194"
    },
    {
      "arxiv_id": "2505.16979v1",
      "title": "Know the Ropes: A Heuristic Strategy for LLM-based Multi-Agent System Design",
      "title_zh": "翻译失败",
      "authors": [
        "Zhenkun Li",
        "Lingyao Li",
        "Shuhang Lin",
        "Yongfeng Zhang"
      ],
      "abstract": "Single-agent LLMs hit hard limits--finite context, role overload, and brittle\ndomain transfer. Conventional multi-agent fixes soften those edges yet expose\nfresh pains: ill-posed decompositions, fuzzy contracts, and verification\noverhead that blunts the gains. We therefore present Know-The-Ropes (KtR), a\nframework that converts domain priors into an algorithmic blueprint hierarchy,\nin which tasks are recursively split into typed, controller-mediated subtasks,\neach solved zero-shot or with the lightest viable boost (e.g.,\nchain-of-thought, micro-tune, self-check). Grounded in the No-Free-Lunch\ntheorem, KtR trades the chase for a universal prompt for disciplined\ndecomposition. On the Knapsack problem (3-8 items), three GPT-4o-mini agents\nraise accuracy from 3% zero-shot to 95% on size-5 instances after patching a\nsingle bottleneck agent. On the tougher Task-Assignment problem (6-15 jobs), a\nsix-agent o3-mini blueprint hits 100% up to size 10 and 84% on sizes 13-15,\nversus 11% zero-shot. Algorithm-aware decomposition plus targeted augmentation\nthus turns modest models into reliable collaborators--no ever-larger monoliths\nrequired.",
      "tldr_zh": "这篇论文提出了 Know the Ropes (KtR) 框架，一种启发式策略，用于设计基于 LLM 的 Multi-Agent System，以解决单代理 LLM 的局限性，如有限上下文、角色过载和领域转移脆弱问题。KtR 通过将领域先验转换为算法蓝图层次结构，递归地将任务拆分为类型化子任务，由控制器中介，并采用零样本解决或轻量级增强（如 Chain-of-Thought、微调和自检查）。实验显示，在 Knapsack 问题（3-8 项）上，三代理 GPT-4o-mini 的准确率从 3% 零样本提升至 95%（大小 5 实例），而在 Task-Assignment 问题（6-15 作业）上，六代理 o3-mini 达到 100% 准确率直到大小 10，并保持 84% 在大小 13-15。基于 No-Free-Lunch 定理，该框架证明了算法感知分解和针对性增强能将中等模型转化为可靠的协作者，无需依赖更大的单体模型。",
      "categories": [
        "cs.AI",
        "cs.MA"
      ],
      "primary_category": "cs.AI",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2505.16979v1",
      "published_date": "2025-05-22 17:52:33 UTC",
      "updated_date": "2025-05-22 17:52:33 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-25T03:10:47.520220"
    },
    {
      "arxiv_id": "2505.16978v1",
      "title": "HyGenar: An LLM-Driven Hybrid Genetic Algorithm for Few-Shot Grammar Generation",
      "title_zh": "翻译失败",
      "authors": [
        "Weizhi Tang",
        "Yixuan Li",
        "Chris Sypherd",
        "Elizabeth Polgreen",
        "Vaishak Belle"
      ],
      "abstract": "Grammar plays a critical role in natural language processing and text/code\ngeneration by enabling the definition of syntax, the creation of parsers, and\nguiding structured outputs. Although large language models (LLMs) demonstrate\nimpressive capabilities across domains, their ability to infer and generate\ngrammars has not yet been thoroughly explored. In this paper, we aim to study\nand improve the ability of LLMs for few-shot grammar generation, where grammars\nare inferred from sets of a small number of positive and negative examples and\ngenerated in Backus-Naur Form. To explore this, we introduced a novel dataset\ncomprising 540 structured grammar generation challenges, devised 6 metrics, and\nevaluated 8 various LLMs against it. Our findings reveal that existing LLMs\nperform sub-optimally in grammar generation. To address this, we propose an\nLLM-driven hybrid genetic algorithm, namely HyGenar, to optimize grammar\ngeneration. HyGenar achieves substantial improvements in both the syntactic and\nsemantic correctness of generated grammars across LLMs.",
      "tldr_zh": "该论文探讨了大型语言模型 (LLMs) 在少样本 (few-shot) 语法生成中的能力，发现现有模型在推断和生成 Backus-Naur Form 语法方面表现 suboptimal。研究者引入了一个包含 540 个结构化挑战的 dataset，并设计了 6 个 metrics 来评估 8 个不同 LLMs。针对这些问题，他们提出了 HyGenar，一种 LLM 驱动的混合遗传算法 (Hybrid Genetic Algorithm)，通过优化过程显著提高了生成的语法在 syntactic 和 semantic 正确性方面的性能。",
      "categories": [
        "cs.AI",
        "cs.PL"
      ],
      "primary_category": "cs.AI",
      "comment": "Accepted to ACL 2025 Findings. Code available at\n  https://github.com/RutaTang/HyGenar",
      "pdf_url": "http://arxiv.org/pdf/2505.16978v1",
      "published_date": "2025-05-22 17:52:31 UTC",
      "updated_date": "2025-05-22 17:52:31 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-25T03:10:56.986463"
    },
    {
      "arxiv_id": "2505.16968v1",
      "title": "CASS: Nvidia to AMD Transpilation with Data, Models, and Benchmark",
      "title_zh": "翻译失败",
      "authors": [
        "Ahmed Heakl",
        "Sarim Hashmi",
        "Gustavo Bertolo Stahl",
        "Seung Hun Eddie Han",
        "Salman Khan",
        "Abdulrahman Mahmoud"
      ],
      "abstract": "We introduce \\texttt{CASS}, the first large-scale dataset and model suite for\ncross-architecture GPU code transpilation, targeting both source-level\n(CUDA~$\\leftrightarrow$~HIP) and assembly-level (Nvidia\nSASS~$\\leftrightarrow$~AMD RDNA3) translation. The dataset comprises 70k\nverified code pairs across host and device, addressing a critical gap in\nlow-level GPU code portability. Leveraging this resource, we train the\n\\texttt{CASS} family of domain-specific language models, achieving 95\\% source\ntranslation accuracy and 37.5\\% assembly translation accuracy, substantially\noutperforming commercial baselines such as GPT-4o, Claude, and Hipify. Our\ngenerated code matches native performance in over 85\\% of test cases,\npreserving runtime and memory behavior. To support rigorous evaluation, we\nintroduce \\texttt{CASS-Bench}, a curated benchmark spanning 16 GPU domains with\nground-truth execution. All data, models, and evaluation tools are released as\nopen source to foster progress in GPU compiler tooling, binary compatibility,\nand LLM-guided hardware translation. Dataset and benchmark are on\n\\href{https://huggingface.co/datasets/MBZUAI/cass}{\\textcolor{blue}{HuggingFace}},\nwith code at\n\\href{https://github.com/GustavoStahl/CASS}{\\textcolor{blue}{GitHub}}.",
      "tldr_zh": "该研究引入了 CASS，这是一个首创的大规模数据集和模型套件，用于跨架构 GPU 代码转译，包括源代码级别 (CUDA ↔ HIP) 和汇编级别 (Nvidia SASS ↔ AMD RDNA3)，包含 70k 个验证代码对，以解决 GPU 代码可移植性问题。利用该数据集，研究者训练了 CASS 系列领域特定语言模型，实现了 95% 的源代码转译准确率和 37.5% 的汇编转译准确率，大幅超越商业基线如 GPT-4o 和 Claude。生成的代码在 85% 的测试案例中匹配原生性能，并保留运行时和内存行为；此外，研究团队发布了 CASS-Bench 基准（覆盖 16 个 GPU 领域）和所有数据、模型及工具作为开源，促进 GPU 编译工具和硬件转译的进步。",
      "categories": [
        "cs.AR",
        "cs.AI",
        "cs.CL",
        "cs.LG",
        "cs.PL"
      ],
      "primary_category": "cs.AR",
      "comment": "20 pages, 11 figures, 5 tables",
      "pdf_url": "http://arxiv.org/pdf/2505.16968v1",
      "published_date": "2025-05-22 17:48:53 UTC",
      "updated_date": "2025-05-22 17:48:53 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-25T03:11:10.695991"
    },
    {
      "arxiv_id": "2505.16967v1",
      "title": "Fixing Data That Hurts Performance: Cascading LLMs to Relabel Hard Negatives for Robust Information Retrieval",
      "title_zh": "翻译失败",
      "authors": [
        "Nandan Thakur",
        "Crystina Zhang",
        "Xueguang Ma",
        "Jimmy Lin"
      ],
      "abstract": "Training robust retrieval and reranker models typically relies on large-scale\nretrieval datasets; for example, the BGE collection contains 1.6 million\nquery-passage pairs sourced from various data sources. However, we find that\ncertain datasets can negatively impact model effectiveness -- pruning 8 out of\n15 datasets from the BGE collection reduces the training set size by\n2.35$\\times$ and increases nDCG@10 on BEIR by 1.0 point. This motivates a\ndeeper examination of training data quality, with a particular focus on \"false\nnegatives\", where relevant passages are incorrectly labeled as irrelevant. We\npropose a simple, cost-effective approach using cascading LLM prompts to\nidentify and relabel hard negatives. Experimental results show that relabeling\nfalse negatives with true positives improves both E5 (base) and Qwen2.5-7B\nretrieval models by 0.7-1.4 nDCG@10 on BEIR and by 1.7-1.8 nDCG@10 on zero-shot\nAIR-Bench evaluation. Similar gains are observed for rerankers fine-tuned on\nthe relabeled data, such as Qwen2.5-3B on BEIR. The reliability of the\ncascading design is further supported by human annotation results, where we\nfind judgment by GPT-4o shows much higher agreement with humans than\nGPT-4o-mini.",
      "tldr_zh": "该研究发现，训练 robust retrieval 和 reranker 模型的大规模数据集（如 BGE 集合）中，某些子集会因“false negatives”（假负例）问题而降低模型性能，例如去除部分数据集后，nDCG@10 在 BEIR 上提升 1.0 点。作者提出一种简单、成本有效的解决方案：使用 cascading LLM prompts 来识别和 relabel hard negatives，从而将错误标记的无关段落修正为相关正例。实验结果显示，这种方法使 E5 (base) 和 Qwen2.5-7B 模型在 BEIR 上的 nDCG@10 提高 0.7-1.4 点，在 zero-shot AIR-Bench 上提高 1.7-1.8 点；rerankers 如 Qwen2.5-3B 也获得类似提升，且该 cascading design 的可靠性经人类标注验证，与 GPT-4o 的判断一致性更高。",
      "categories": [
        "cs.IR",
        "cs.AI",
        "cs.CL"
      ],
      "primary_category": "cs.IR",
      "comment": "Code is available at https://github.com/castorini/rlhn & datasets are\n  available at https://huggingface.co/rlhn",
      "pdf_url": "http://arxiv.org/pdf/2505.16967v1",
      "published_date": "2025-05-22 17:47:57 UTC",
      "updated_date": "2025-05-22 17:47:57 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-25T03:11:23.602032"
    },
    {
      "arxiv_id": "2505.16965v1",
      "title": "BP-Seg: A graphical model approach to unsupervised and non-contiguous text segmentation using belief propagation",
      "title_zh": "翻译失败",
      "authors": [
        "Fengyi Li",
        "Kayhan Behdin",
        "Natesh Pillai",
        "Xiaofeng Wang",
        "Zhipeng Wang",
        "Ercan Yildiz"
      ],
      "abstract": "Text segmentation based on the semantic meaning of sentences is a fundamental\ntask with broad utility in many downstream applications. In this paper, we\npropose a graphical model-based unsupervised learning approach, named BP-Seg\nfor efficient text segmentation. Our method not only considers local coherence,\ncapturing the intuition that adjacent sentences are often more related, but\nalso effectively groups sentences that are distant in the text yet semantically\nsimilar. This is achieved through belief propagation on the carefully\nconstructed graphical models. Experimental results on both an illustrative\nexample and a dataset with long-form documents demonstrate that our method\nperforms favorably compared to competing approaches.",
      "tldr_zh": "本研究提出了一种基于图形模型(graphical model)的无监督学习方法BP-Seg，用于文本分割任务。该方法不仅考虑局部连贯性（即相邻句子的相关性），还能够有效识别文本中非连续但语义相似的句子，通过在精心构建的图形模型上应用belief propagation实现分组。实验结果显示，BP-Seg在示例数据集和长文档数据集上表现出色，比现有竞争方法性能更优。",
      "categories": [
        "cs.CL",
        "cs.AI",
        "cs.LG"
      ],
      "primary_category": "cs.CL",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2505.16965v1",
      "published_date": "2025-05-22 17:46:23 UTC",
      "updated_date": "2025-05-22 17:46:23 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-25T03:11:33.968286"
    },
    {
      "arxiv_id": "2505.16957v1",
      "title": "Invisible Prompts, Visible Threats: Malicious Font Injection in External Resources for Large Language Models",
      "title_zh": "翻译失败",
      "authors": [
        "Junjie Xiong",
        "Changjia Zhu",
        "Shuhang Lin",
        "Chong Zhang",
        "Yongfeng Zhang",
        "Yao Liu",
        "Lingyao Li"
      ],
      "abstract": "Large Language Models (LLMs) are increasingly equipped with capabilities of\nreal-time web search and integrated with protocols like Model Context Protocol\n(MCP). This extension could introduce new security vulnerabilities. We present\na systematic investigation of LLM vulnerabilities to hidden adversarial prompts\nthrough malicious font injection in external resources like webpages, where\nattackers manipulate code-to-glyph mapping to inject deceptive content which\nare invisible to users. We evaluate two critical attack scenarios: (1)\n\"malicious content relay\" and (2) \"sensitive data leakage\" through MCP-enabled\ntools. Our experiments reveal that indirect prompts with injected malicious\nfont can bypass LLM safety mechanisms through external resources, achieving\nvarying success rates based on data sensitivity and prompt design. Our research\nunderscores the urgent need for enhanced security measures in LLM deployments\nwhen processing external content.",
      "tldr_zh": "该研究揭示了大语言模型 (LLMs) 在处理外部资源时的新安全漏洞，通过恶意字体注入攻击来创建对用户不可见的隐藏对抗性提示。攻击者操纵代码到字形的映射，在网页等外部资源中注入欺骗性内容，导致“malicious content relay”（恶意内容中继）和“sensitive data leakage”（敏感数据泄露）等场景。实验评估了这些攻击在MCP (Model Context Protocol) 启用的工具中的效果，发现间接提示能绕过LLMs的安全机制，成功率因数据敏感性和提示设计而异。该工作强调了在LLMs部署中处理外部内容时急需增强安全措施，以防范此类威胁。",
      "categories": [
        "cs.CR",
        "cs.AI"
      ],
      "primary_category": "cs.CR",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2505.16957v1",
      "published_date": "2025-05-22 17:36:33 UTC",
      "updated_date": "2025-05-22 17:36:33 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-25T03:11:47.400041"
    },
    {
      "arxiv_id": "2505.16950v1",
      "title": "Bottlenecked Transformers: Periodic KV Cache Abstraction for Generalised Reasoning",
      "title_zh": "翻译失败",
      "authors": [
        "Adnan Oomerjee",
        "Zafeirios Fountas",
        "Zhongwei Yu",
        "Haitham Bou-Ammar",
        "Jun Wang"
      ],
      "abstract": "Despite their impressive capabilities, Large Language Models struggle with\ngeneralisation beyond their training distribution, often exhibiting\nsophisticated pattern interpolation rather than true abstract reasoning\n(extrapolation). In this work, we approach this limitation through the lens of\nInformation Bottleneck (IB) theory, which posits that model generalisation\nemerges from an optimal balance between input compression and retention of\npredictive information in latent representations. We prove using IB theory that\ndecoder-only Transformers are inherently constrained in their ability to form\ntask-optimal sequence representations. We then use this result to demonstrate\nthat periodic global transformation of the internal sequence-level\nrepresentations (KV cache) is a necessary computational step for improving\nTransformer generalisation in reasoning tasks. Based on these theoretical\ninsights, we propose a modification to the Transformer architecture, in the\nform of an additional module that globally rewrites the KV cache at periodic\nintervals, shifting its capacity away from memorising input prefixes and toward\nencoding features most useful for predicting future tokens. Our model delivers\nsubstantial gains on mathematical reasoning benchmarks, outperforming both\nvanilla Transformers with up to 3.5x more parameters, as well as\nheuristic-driven pruning mechanisms for cache compression. Our approach can be\nseen as a principled generalisation of existing KV-cache compression methods;\nwhereas such methods focus solely on compressing input representations, they\noften do so at the expense of retaining predictive information, and thus their\ncapabilities are inherently bounded by those of an unconstrained model. This\nestablishes a principled framework to manipulate Transformer memory using\ninformation theory, addressing fundamental reasoning limitations that scaling\nalone cannot overcome.",
      "tldr_zh": "本研究基于 Information Bottleneck (IB) 理论，揭示了 decoder-only Transformers 在泛化能力上的限制，即它们更倾向于模式插值而非真正的抽象推理。作者证明，通过周期性地全局转换内部序列级表示（KV cache），可以优化模型从记忆输入前缀转向编码对未来 token 有用的特征，从而提升 Transformer 在推理任务中的泛化性能。实验结果显示，该改进架构在数学推理基准上显著超越参数多 3.5 倍的普通 Transformers，以及现有的 KV-cache 压缩方法，提供了一个信息理论框架来解决模型的根本性推理局限。",
      "categories": [
        "cs.LG",
        "cs.AI",
        "cs.IT",
        "math.IT"
      ],
      "primary_category": "cs.LG",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2505.16950v1",
      "published_date": "2025-05-22 17:33:49 UTC",
      "updated_date": "2025-05-22 17:33:49 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-25T03:11:59.296995"
    },
    {
      "arxiv_id": "2505.16947v1",
      "title": "MixAT: Combining Continuous and Discrete Adversarial Training for LLMs",
      "title_zh": "翻译失败",
      "authors": [
        "Csaba Dékány",
        "Stefan Balauca",
        "Robin Staab",
        "Dimitar I. Dimitrov",
        "Martin Vechev"
      ],
      "abstract": "Despite recent efforts in Large Language Models (LLMs) safety and alignment,\ncurrent adversarial attacks on frontier LLMs are still able to force harmful\ngenerations consistently. Although adversarial training has been widely studied\nand shown to significantly improve the robustness of traditional machine\nlearning models, its strengths and weaknesses in the context of LLMs are less\nunderstood. Specifically, while existing discrete adversarial attacks are\neffective at producing harmful content, training LLMs with concrete adversarial\nprompts is often computationally expensive, leading to reliance on continuous\nrelaxations. As these relaxations do not correspond to discrete input tokens,\nsuch latent training methods often leave models vulnerable to a diverse set of\ndiscrete attacks. In this work, we aim to bridge this gap by introducing MixAT,\na novel method that combines stronger discrete and faster continuous attacks\nduring training. We rigorously evaluate MixAT across a wide spectrum of\nstate-of-the-art attacks, proposing the At Least One Attack Success Rate\n(ALO-ASR) metric to capture the worst-case vulnerability of models. We show\nMixAT achieves substantially better robustness (ALO-ASR < 20%) compared to\nprior defenses (ALO-ASR > 50%), while maintaining a runtime comparable to\nmethods based on continuous relaxations. We further analyze MixAT in realistic\ndeployment settings, exploring how chat templates, quantization, low-rank\nadapters, and temperature affect both adversarial training and evaluation,\nrevealing additional blind spots in current methodologies. Our results\ndemonstrate that MixAT's discrete-continuous defense offers a principled and\nsuperior robustness-accuracy tradeoff with minimal computational overhead,\nhighlighting its promise for building safer LLMs. We provide our code and\nmodels at https://github.com/insait-institute/MixAT.",
      "tldr_zh": "本论文提出 MixAT，一种结合连续和离散对抗训练的方法，旨在提升大型语言模型(LLMs)对攻击的鲁棒性，以解决现有防御在处理离散攻击时的脆弱性。MixAT 通过同时利用更有效的离散攻击和更高效的连续攻击进行训练，使用 At Least One Attack Success Rate (ALO-ASR) 指标评估，结果显示其鲁棒性显著提高（ALO-ASR < 20%），远优于现有方法（ALO-ASR > 50%），并保持了与连续方法相当的运行时效率。该方法还分析了聊天模板、量化、低秩适配器和温度等实际部署因素的影响，提供了一个更好的鲁棒性-准确性权衡，并开源了代码和模型。",
      "categories": [
        "cs.LG",
        "cs.AI",
        "I.2.7; K.4.1"
      ],
      "primary_category": "cs.LG",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2505.16947v1",
      "published_date": "2025-05-22 17:32:50 UTC",
      "updated_date": "2025-05-22 17:32:50 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-25T03:12:12.065638"
    },
    {
      "arxiv_id": "2505.16944v1",
      "title": "AGENTIF: Benchmarking Instruction Following of Large Language Models in Agentic Scenarios",
      "title_zh": "AGENTIF：大语言模型在智能体场景中的指令遵循基准测试",
      "authors": [
        "Yunjia Qi",
        "Hao Peng",
        "Xiaozhi Wang",
        "Amy Xin",
        "Youfeng Liu",
        "Bin Xu",
        "Lei Hou",
        "Juanzi Li"
      ],
      "abstract": "Large Language Models (LLMs) have demonstrated advanced capabilities in\nreal-world agentic applications. Growing research efforts aim to develop\nLLM-based agents to address practical demands, introducing a new challenge:\nagentic scenarios often involve lengthy instructions with complex constraints,\nsuch as extended system prompts and detailed tool specifications. While\nadherence to such instructions is crucial for agentic applications, whether\nLLMs can reliably follow them remains underexplored. In this paper, we\nintroduce AgentIF, the first benchmark for systematically evaluating LLM\ninstruction following ability in agentic scenarios. AgentIF features three key\ncharacteristics: (1) Realistic, constructed from 50 real-world agentic\napplications. (2) Long, averaging 1,723 words with a maximum of 15,630 words.\n(3) Complex, averaging 11.9 constraints per instruction, covering diverse\nconstraint types, such as tool specifications and condition constraints. To\nconstruct AgentIF, we collect 707 human-annotated instructions across 50\nagentic tasks from industrial application agents and open-source agentic\nsystems. For each instruction, we annotate the associated constraints and\ncorresponding evaluation metrics, including code-based evaluation, LLM-based\nevaluation, and hybrid code-LLM evaluation. We use AgentIF to systematically\nevaluate existing advanced LLMs. We observe that current models generally\nperform poorly, especially in handling complex constraint structures and tool\nspecifications. We further conduct error analysis and analytical experiments on\ninstruction length and meta constraints, providing some findings about the\nfailure modes of existing LLMs. We have released the code and data to\nfacilitate future research.",
      "tldr_zh": "本论文引入了AGENTIF，这是一个首个系统基准，用于评估大型语言模型(LLMs)在代理(agentic)场景中的指令遵循能力。AGENTIF基于50个真实世界代理应用构建，指令平均长达1723词（最长15630词），并包含平均11.9个复杂约束，如工具规格和条件约束。研究团队收集了707条人类标注指令，并设计了代码-based、LLM-based和混合评估指标来量化模型表现。实验结果显示，现有LLMs在处理复杂约束结构和工具规格时表现较差，通过错误分析和实验，进一步揭示了指令长度和元约束对模型失败的影响，并发布了代码和数据以支持未来研究。",
      "categories": [
        "cs.AI",
        "cs.CL"
      ],
      "primary_category": "cs.AI",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2505.16944v1",
      "published_date": "2025-05-22 17:31:10 UTC",
      "updated_date": "2025-05-22 17:31:10 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-25T03:12:23.411174"
    },
    {
      "arxiv_id": "2505.16941v1",
      "title": "FoMoH: A clinically meaningful foundation model evaluation for structured electronic health records",
      "title_zh": "翻译失败",
      "authors": [
        "Chao Pang",
        "Vincent Jeanselme",
        "Young Sang Choi",
        "Xinzhuo Jiang",
        "Zilin Jing",
        "Aparajita Kashyap",
        "Yuta Kobayashi",
        "Yanwei Li",
        "Florent Pollet",
        "Karthik Natarajan",
        "Shalmali Joshi"
      ],
      "abstract": "Foundation models hold significant promise in healthcare, given their\ncapacity to extract meaningful representations independent of downstream tasks.\nThis property has enabled state-of-the-art performance across several clinical\napplications trained on structured electronic health record (EHR) data, even in\nsettings with limited labeled data, a prevalent challenge in healthcare.\nHowever, there is little consensus on these models' potential for clinical\nutility due to the lack of desiderata of comprehensive and meaningful tasks and\nsufficiently diverse evaluations to characterize the benefit over conventional\nsupervised learning. To address this gap, we propose a suite of clinically\nmeaningful tasks spanning patient outcomes, early prediction of acute and\nchronic conditions, including desiderata for robust evaluations. We evaluate\nstate-of-the-art foundation models on EHR data consisting of 5 million patients\nfrom Columbia University Irving Medical Center (CUMC), a large urban academic\nmedical center in New York City, across 14 clinically relevant tasks. We\nmeasure overall accuracy, calibration, and subpopulation performance to surface\ntradeoffs based on the choice of pre-training, tokenization, and data\nrepresentation strategies. Our study aims to advance the empirical evaluation\nof structured EHR foundation models and guide the development of future\nhealthcare foundation models.",
      "tldr_zh": "本研究提出FoMoH框架，用于评估foundation models在结构化电子健康记录(EHR)中的临床效用，旨在解决现有模型缺乏全面任务和多样评估的问题。研究设计了一系列临床意义任务，包括患者结果预测、急性和慢性疾病的早期识别，并制定了稳健评估标准，如准确率、校准和子群性能。基于纽约市哥伦比亚大学欧文医学中心(CUMC)的5百万患者数据，评估了14个任务，结果揭示了预训练、标记化和数据表示策略的权衡，从而指导未来healthcare foundation models的开发。",
      "categories": [
        "cs.LG",
        "cs.AI"
      ],
      "primary_category": "cs.LG",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2505.16941v1",
      "published_date": "2025-05-22 17:29:52 UTC",
      "updated_date": "2025-05-22 17:29:52 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-25T03:12:35.182676"
    },
    {
      "arxiv_id": "2505.16938v1",
      "title": "NovelSeek: When Agent Becomes the Scientist -- Building Closed-Loop System from Hypothesis to Verification",
      "title_zh": "翻译失败",
      "authors": [
        "NovelSeek Team",
        "Bo Zhang",
        "Shiyang Feng",
        "Xiangchao Yan",
        "Jiakang Yuan",
        "Zhiyin Yu",
        "Xiaohan He",
        "Songtao Huang",
        "Shaowei Hou",
        "Zheng Nie",
        "Zhilong Wang",
        "Jinyao Liu",
        "Runmin Ma",
        "Tianshuo Peng",
        "Peng Ye",
        "Dongzhan Zhou",
        "Shufei Zhang",
        "Xiaosong Wang",
        "Yilan Zhang",
        "Meng Li",
        "Zhongying Tu",
        "Xiangyu Yue",
        "Wangli Ouyang",
        "Bowen Zhou",
        "Lei Bai"
      ],
      "abstract": "Artificial Intelligence (AI) is accelerating the transformation of scientific\nresearch paradigms, not only enhancing research efficiency but also driving\ninnovation. We introduce NovelSeek, a unified closed-loop multi-agent framework\nto conduct Autonomous Scientific Research (ASR) across various scientific\nresearch fields, enabling researchers to tackle complicated problems in these\nfields with unprecedented speed and precision. NovelSeek highlights three key\nadvantages: 1) Scalability: NovelSeek has demonstrated its versatility across\n12 scientific research tasks, capable of generating innovative ideas to enhance\nthe performance of baseline code. 2) Interactivity: NovelSeek provides an\ninterface for human expert feedback and multi-agent interaction in automated\nend-to-end processes, allowing for the seamless integration of domain expert\nknowledge. 3) Efficiency: NovelSeek has achieved promising performance gains in\nseveral scientific fields with significantly less time cost compared to human\nefforts. For instance, in reaction yield prediction, it increased from 27.6% to\n35.4% in just 12 hours; in enhancer activity prediction, accuracy rose from\n0.52 to 0.79 with only 4 hours of processing; and in 2D semantic segmentation,\nprecision advanced from 78.8% to 81.0% in a mere 30 hours.",
      "tldr_zh": "本研究提出NovelSeek，一种统一的闭环多智能体框架，用于跨多个科学领域的Autonomous Scientific Research (ASR)，旨在加速复杂问题的解决并提升研究效率。该框架的关键优势包括扩展性（适用于12个科学任务并生成创新想法提升基线代码性能）、交互性（提供人类专家反馈和多智能体互动接口以整合领域知识），以及效率（显著减少时间成本，例如反应产率预测从27.6%提高到35.4%仅用12小时）。实验结果显示，NovelSeek在增强子活性预测和2D语义分割等领域取得了显著性能提升，展示了AI在科学研究中的潜力。",
      "categories": [
        "cs.AI",
        "cs.CL",
        "cs.CV"
      ],
      "primary_category": "cs.AI",
      "comment": "HomePage: https://alpha-innovator.github.io/NovelSeek-project-page",
      "pdf_url": "http://arxiv.org/pdf/2505.16938v1",
      "published_date": "2025-05-22 17:27:43 UTC",
      "updated_date": "2025-05-22 17:27:43 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-25T03:12:46.914997"
    },
    {
      "arxiv_id": "2505.16932v1",
      "title": "The Polar Express: Optimal Matrix Sign Methods and Their Application to the Muon Algorithm",
      "title_zh": "翻译失败",
      "authors": [
        "Noah Amsel",
        "David Persson",
        "Christopher Musco",
        "Robert Gower"
      ],
      "abstract": "Computing the polar decomposition and the related matrix sign function, has\nbeen a well-studied problem in numerical analysis for decades. More recently,\nit has emerged as an important subroutine in deep learning, particularly within\nthe Muon optimization framework. However, the requirements in this setting\ndiffer significantly from those of traditional numerical analysis. In deep\nlearning, methods must be highly efficient and GPU-compatible, but high\naccuracy is often unnecessary. As a result, classical algorithms like\nNewton-Schulz (which suffers from slow initial convergence) and methods based\non rational functions (which rely on QR decompositions or matrix inverses) are\npoorly suited to this context. In this work, we introduce Polar Express, a\nGPU-friendly algorithm for computing the polar decomposition. Like classical\npolynomial methods such as Newton-Schulz, our approach uses only matrix-matrix\nmultiplications, making it GPU-compatible. Motivated by earlier work of Chen &\nChow and Nakatsukasa & Freund, Polar Express adapts the polynomial update rule\nat each iteration by solving a minimax optimization problem, and we prove that\nit enjoys a strong worst-case optimality guarantee. This property ensures both\nrapid early convergence and fast asymptotic convergence. We also address\nfinite-precision issues, making it stable in bfloat16 in practice. We apply\nPolar Express within the Muon optimization framework and show consistent\nimprovements in validation loss on large-scale models such as GPT-2,\noutperforming recent alternatives across a range of learning rates.",
      "tldr_zh": "这篇论文提出了 Polar Express，一种高效的 GPU 兼容算法，用于计算矩阵的极分解和相关矩阵符号函数，特别针对深度学习中的 Muon 优化框架，以解决传统方法如 Newton-Schulz 的慢速收敛问题。算法通过求解 minimax 优化问题来优化多项式更新规则，仅使用矩阵-矩阵乘法，确保快速早期和渐进收敛，并在 bfloat16 有限精度环境中保持稳定。实验结果显示，Polar Express 在大型模型如 GPT-2 上显著降低了验证损失，优于现有备选方法。",
      "categories": [
        "cs.LG",
        "cs.AI",
        "cs.CL",
        "cs.NA",
        "math.NA",
        "math.OC"
      ],
      "primary_category": "cs.LG",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2505.16932v1",
      "published_date": "2025-05-22 17:23:14 UTC",
      "updated_date": "2025-05-22 17:23:14 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-25T03:12:58.945957"
    },
    {
      "arxiv_id": "2505.16928v1",
      "title": "Beyond Needle(s) in the Embodied Haystack: Environment, Architecture, and Training Considerations for Long Context Reasoning",
      "title_zh": "翻译失败",
      "authors": [
        "Bosung Kim",
        "Prithviraj Ammanabrolu"
      ],
      "abstract": "We introduce $\\infty$-THOR, a new framework for long-horizon embodied tasks\nthat advances long-context understanding in embodied AI. $\\infty$-THOR\nprovides: (1) a generation framework for synthesizing scalable, reproducible,\nand unlimited long-horizon trajectories; (2) a novel embodied QA task,\nNeedle(s) in the Embodied Haystack, where multiple scattered clues across\nextended trajectories test agents' long-context reasoning ability; and (3) a\nlong-horizon dataset and benchmark suite featuring complex tasks that span\nhundreds of environment steps, each paired with ground-truth action sequences.\nTo enable this capability, we explore architectural adaptations, including\ninterleaved Goal-State-Action modeling, context extension techniques, and\nContext Parallelism, to equip LLM-based agents for extreme long-context\nreasoning and interaction. Experimental results and analyses highlight the\nchallenges posed by our benchmark and provide insights into training strategies\nand model behaviors under long-horizon conditions. Our work provides a\nfoundation for the next generation of embodied AI systems capable of robust,\nlong-term reasoning and planning.",
      "tldr_zh": "本研究引入了$\\infty$-THOR框架，以提升具身AI的长上下文理解能力。该框架包括一个生成框架，用于合成可扩展且无限长时限轨迹；一个新颖的具身QA任务Needle(s) in the Embodied Haystack，用于测试代理在扩展轨迹中处理散布线索的推理能力；以及一个长时限数据集和基准套件，涵盖数百步的复杂任务并配有ground-truth行动序列。为实现这一功能，研究探索了架构适应如交错的Goal-State-Action建模、上下文扩展技术和Context Parallelism，以增强基于LLM的代理的极端长上下文推理和交互。实验结果突出了基准的挑战，并提供了训练策略和模型行为的洞见，为下一代具身AI系统的稳健长期推理和规划奠定基础。",
      "categories": [
        "cs.AI",
        "cs.LG",
        "cs.RO"
      ],
      "primary_category": "cs.AI",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2505.16928v1",
      "published_date": "2025-05-22 17:20:38 UTC",
      "updated_date": "2025-05-22 17:20:38 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-25T03:13:12.313731"
    },
    {
      "arxiv_id": "2505.16927v1",
      "title": "Latent Principle Discovery for Language Model Self-Improvement",
      "title_zh": "用于语言模型自我改进的潜在原则发现",
      "authors": [
        "Keshav Ramji",
        "Tahira Naseem",
        "Ramón Fernandez Astudillo"
      ],
      "abstract": "When language model (LM) users aim to improve the quality of its generations,\nit is crucial to specify concrete behavioral attributes that the model should\nstrive to reflect. However, curating such principles across many domains, even\nnon-exhaustively, requires a labor-intensive annotation process. To automate\nthis process, we propose eliciting these latent attributes guiding model\nreasoning towards human-preferred responses by explicitly modeling them in a\nself-correction setting. Our approach mines new principles from the LM itself\nand compresses the discovered elements to an interpretable set via clustering.\nSpecifically, we employ an approximation of posterior-regularized Monte Carlo\nExpectation-Maximization to both identify a condensed set of the most effective\nlatent principles and teach the LM to strategically invoke them in order to\nintrinsically refine its responses. We demonstrate that bootstrapping our\nalgorithm over multiple iterations enables smaller language models (7-8B\nparameters) to self-improve, achieving +8-10% in AlpacaEval win-rate, an\naverage of +0.3 on MT-Bench, and +19-23% in principle-following win-rate on\nIFEval. We also show that clustering the principles yields interpretable and\ndiverse model-generated constitutions while retaining model performance. The\ngains our method achieves highlight the potential of automated,\nprinciple-driven post-training recipes toward continual self-improvement.",
      "tldr_zh": "该研究提出了一种自动化方法，用于从语言模型 (LM) 本身挖掘潜在原则 (latent principles)，以改善其生成质量，从而避免手动标注行为属性的劳动密集过程。该方法在自校正设置中使用后验正则化 Monte Carlo Expectation-Maximization 的近似版本，来识别并聚类最有效的原则，并教导 LM 战略性地调用这些原则以内在优化响应。实验结果显示，通过多次迭代引导，小型 LM (7-8B 参数) 实现了显著自提升：在 AlpacaEval 胜率提高 8-10%、MT-Bench 平均分数提升 0.3、IFEval 原则遵循胜率提高 19-23%。此外，该方法生成的原则聚类提供可解释和多样的模型宪法，同时保持性能，展示了自动化原则驱动后训练向持续自提升的潜力。",
      "categories": [
        "cs.CL",
        "cs.AI",
        "cs.LG"
      ],
      "primary_category": "cs.CL",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2505.16927v1",
      "published_date": "2025-05-22 17:20:18 UTC",
      "updated_date": "2025-05-22 17:20:18 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-25T03:13:24.385329"
    },
    {
      "arxiv_id": "2505.16915v1",
      "title": "DetailMaster: Can Your Text-to-Image Model Handle Long Prompts?",
      "title_zh": "DetailMaster：你的文本到图像模型能处理长提示吗？",
      "authors": [
        "Qirui Jiao",
        "Daoyuan Chen",
        "Yilun Huang",
        "Xika Lin",
        "Ying Shen",
        "Yaliang Li"
      ],
      "abstract": "While recent text-to-image (T2I) models show impressive capabilities in\nsynthesizing images from brief descriptions, their performance significantly\ndegrades when confronted with long, detail-intensive prompts required in\nprofessional applications. We present DetailMaster, the first comprehensive\nbenchmark specifically designed to evaluate T2I models' systematical abilities\nto handle extended textual inputs that contain complex compositional\nrequirements. Our benchmark introduces four critical evaluation dimensions:\nCharacter Attributes, Structured Character Locations, Multi-Dimensional Scene\nAttributes, and Explicit Spatial/Interactive Relationships. The benchmark\ncomprises long and detail-rich prompts averaging 284.89 tokens, with high\nquality validated by expert annotators. Evaluation on 7 general-purpose and 5\nlong-prompt-optimized T2I models reveals critical performance limitations:\nstate-of-the-art models achieve merely ~50% accuracy in key dimensions like\nattribute binding and spatial reasoning, while all models showing progressive\nperformance degradation as prompt length increases. Our analysis highlights\nsystemic failures in structural comprehension and detail overload handling,\nmotivating future research into architectures with enhanced compositional\nreasoning. We open-source the dataset, data curation code, and evaluation tools\nto advance detail-rich T2I generation and enable broad applications that would\notherwise be infeasible due to the lack of a dedicated benchmark.",
      "tldr_zh": "该研究提出DetailMaster，这是第一个全面benchmark，用于评估文本到图像(T2I)模型处理长、细节丰富的提示的能力。基准包括四个关键评估维度：Character Attributes、Structured Character Locations、Multi-Dimensional Scene Attributes和Explicit Spatial/Interactive Relationships，采用平均284.89 tokens的复杂提示，由专家验证。在对7个通用和5个优化长提示的T2I模型的评估中，结果显示模型在属性绑定和空间推理等关键维度上准确率仅约50%，且性能随提示长度增加而下降，突显了模型在结构理解和细节处理上的系统性缺陷。该benchmark的开源数据集、代码和工具将推动未来T2I生成研究，提升其在专业应用中的可行性。",
      "categories": [
        "cs.CV",
        "cs.AI"
      ],
      "primary_category": "cs.CV",
      "comment": "22 pages, 8 figures, 10 tables",
      "pdf_url": "http://arxiv.org/pdf/2505.16915v1",
      "published_date": "2025-05-22 17:11:27 UTC",
      "updated_date": "2025-05-22 17:11:27 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-25T03:13:36.688245"
    },
    {
      "arxiv_id": "2505.16911v1",
      "title": "Active Speech Enhancement: Active Speech Denoising Decliping and Deveraberation",
      "title_zh": "翻译失败",
      "authors": [
        "Ofir Yaish",
        "Yehuda Mishaly",
        "Eliya Nachmani"
      ],
      "abstract": "We introduce a new paradigm for active sound modification: Active Speech\nEnhancement (ASE). While Active Noise Cancellation (ANC) algorithms focus on\nsuppressing external interference, ASE goes further by actively shaping the\nspeech signal -- both attenuating unwanted noise components and amplifying\nspeech-relevant frequencies -- to improve intelligibility and perceptual\nquality. To enable this, we propose a novel Transformer-Mamba-based\narchitecture, along with a task-specific loss function designed to jointly\noptimize interference suppression and signal enrichment. Our method outperforms\nexisting baselines across multiple speech processing tasks -- including\ndenoising, dereverberation, and declipping -- demonstrating the effectiveness\nof active, targeted modulation in challenging acoustic environments.",
      "tldr_zh": "该论文引入了Active Speech Enhancement (ASE) 的新范式，与Active Noise Cancellation (ANC) 不同，它不仅抑制外部干扰，还主动塑造语音信号，通过衰减噪声和放大相关频率来提升语音的可懂度和感知质量。研究提出了一种基于Transformer-Mamba的架构，并设计了任务特定的损失函数，用于同时优化干扰抑制和信号增强。在denoising、dereverberation和declipping等任务上，该方法超过了现有基线，展示了在挑战性声学环境中的有效性。",
      "categories": [
        "eess.AS",
        "cs.AI"
      ],
      "primary_category": "eess.AS",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2505.16911v1",
      "published_date": "2025-05-22 17:10:18 UTC",
      "updated_date": "2025-05-22 17:10:18 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-25T03:13:47.530053"
    },
    {
      "arxiv_id": "2505.16899v1",
      "title": "Identifying, Evaluating, and Mitigating Risks of AI Thought Partnerships",
      "title_zh": "识别、评估和缓解人工智能思想伙伴关系的风险",
      "authors": [
        "Kerem Oktar",
        "Katherine M. Collins",
        "Jose Hernandez-Orallo",
        "Diane Coyle",
        "Stephen Cave",
        "Adrian Weller",
        "Ilia Sucholutsky"
      ],
      "abstract": "Artificial Intelligence (AI) systems have historically been used as tools\nthat execute narrowly defined tasks. Yet recent advances in AI have unlocked\npossibilities for a new class of models that genuinely collaborate with humans\nin complex reasoning, from conceptualizing problems to brainstorming solutions.\nSuch AI thought partners enable novel forms of collaboration and extended\ncognition, yet they also pose major risks-including and beyond risks of typical\nAI tools and agents. In this commentary, we systematically identify risks of AI\nthought partners through a novel framework that identifies risks at multiple\nlevels of analysis, including Real-time, Individual, and Societal risks arising\nfrom collaborative cognition (RISc). We leverage this framework to propose\nconcrete metrics for risk evaluation, and finally suggest specific mitigation\nstrategies for developers and policymakers. As AI thought partners continue to\nproliferate, these strategies can help prevent major harms and ensure that\nhumans actively benefit from productive thought partnerships.",
      "tldr_zh": "该论文探讨了AI Thought Partners（AI 思想伙伴）——一种能与人类在复杂推理中协作的AI模型——所带来的风险。作者通过一个新框架RISc（Real-time, Individual, and Societal risks arising from collaborative cognition）系统识别这些风险，包括实时、个体和社会层面的潜在危害。论文提出具体指标用于风险评估，并建议针对开发者和政策制定者的缓解策略，以防止重大伤害并确保人类从AI思想伙伴关系中获益。",
      "categories": [
        "cs.AI"
      ],
      "primary_category": "cs.AI",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2505.16899v1",
      "published_date": "2025-05-22 16:58:48 UTC",
      "updated_date": "2025-05-22 16:58:48 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-25T03:13:59.472918"
    },
    {
      "arxiv_id": "2505.16896v1",
      "title": "Structure-Aligned Protein Language Model",
      "title_zh": "翻译失败",
      "authors": [
        "Can Chen",
        "David Heurtel-Depeiges",
        "Robert M. Vernon",
        "Christopher James Langmead",
        "Yoshua Bengio",
        "Quentin Fournier"
      ],
      "abstract": "Protein language models (pLMs) pre-trained on vast protein sequence databases\nexcel at various downstream tasks but lack the structural knowledge essential\nfor many biological applications. To address this, we integrate structural\ninsights from pre-trained protein graph neural networks (pGNNs) into pLMs\nthrough a latent-level contrastive learning task. This task aligns residue\nrepresentations from pLMs with those from pGNNs across multiple proteins,\nenriching pLMs with inter-protein structural knowledge. Additionally, we\nincorporate a physical-level task that infuses intra-protein structural\nknowledge by optimizing pLMs to predict structural tokens. The proposed\ndual-task framework effectively incorporates both inter-protein and\nintra-protein structural knowledge into pLMs. Given the variability in the\nquality of protein structures in PDB, we further introduce a residue loss\nselection module, which uses a small model trained on high-quality structures\nto select reliable yet challenging residue losses for the pLM to learn.\nApplying our structure alignment method to the state-of-the-art ESM2 and\nAMPLIFY results in notable performance gains across a wide range of tasks,\nincluding a 12.7% increase in ESM2 contact prediction. The data, code, and\nresulting SaESM2 and SaAMPLIFY models will be released on Hugging Face.",
      "tldr_zh": "本研究提出了一种结构对齐蛋白语言模型（Structure-Aligned Protein Language Model），通过潜在级别的对比学习任务（latent-level contrastive learning）将预训练蛋白图神经网络（pGNNs）的结构洞见整合到蛋白语言模型（pLMs）中，从而丰富 pLMs 的 inter-protein 结构知识。  \n同时，引入物理级别的任务（physical-level task），让 pLMs 优化预测结构标记，以注入 intra-protein 结构知识，并通过 residue loss selection module 选择高质量的残基损失，确保训练的可靠性和挑战性。  \n实验结果显示，该双任务框架应用于 ESM2 和 AMPLIFY 后，在多种下游任务上显著提升性能，例如 ESM2 的接触预测（contact prediction）准确率提高 12.7%。",
      "categories": [
        "cs.LG",
        "cs.AI"
      ],
      "primary_category": "cs.LG",
      "comment": "16 pages, 8 figures, 7 tables",
      "pdf_url": "http://arxiv.org/pdf/2505.16896v1",
      "published_date": "2025-05-22 16:56:12 UTC",
      "updated_date": "2025-05-22 16:56:12 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-25T03:14:13.262062"
    },
    {
      "arxiv_id": "2505.16888v1",
      "title": "CAIN: Hijacking LLM-Humans Conversations via a Two-Stage Malicious System Prompt Generation and Refining Framework",
      "title_zh": "翻译失败",
      "authors": [
        "Viet Pham",
        "Thai Le"
      ],
      "abstract": "Large language models (LLMs) have advanced many applications, but are also\nknown to be vulnerable to adversarial attacks. In this work, we introduce a\nnovel security threat: hijacking AI-human conversations by manipulating LLMs'\nsystem prompts to produce malicious answers only to specific targeted questions\n(e.g., \"Who should I vote for US President?\", \"Are Covid vaccines safe?\"),\nwhile behaving benignly on others. This attack is detrimental as it can enable\nmalicious actors to exercise large-scale information manipulation by spreading\nharmful but benign-looking system prompts online. To demonstrate such an\nattack, we develop CAIN, an algorithm that can automatically curate such\nharmful system prompts for a specific target question in a black-box setting or\nwithout the need to access the LLM's parameters. Evaluated on both open-source\nand commercial LLMs, CAIN demonstrates significant adversarial impact. In\nuntargeted attacks or forcing LLMs to output incorrect answers, CAIN achieves\nup to 40% F1 degradation on targeted questions while preserving high accuracy\non benign inputs. For targeted attacks or forcing LLMs to output specific\nharmful answers, CAIN achieves over 70% F1 scores on these targeted responses\nwith minimal impact on benign questions. Our results highlight the critical\nneed for enhanced robustness measures to safeguard the integrity and safety of\nLLMs in real-world applications. All source code will be publicly available.",
      "tldr_zh": "该研究揭示了LLM（Large Language Models）面临的新安全威胁：通过操纵系统提示来劫持AI-人类对话，使其对特定问题（如政治或健康咨询）输出恶意答案，而对其他问题保持正常行为。作者开发了CAIN框架，这是一个两阶段的恶意系统提示生成和精炼算法，能够在black-box setting下自动创建针对性有害提示，无需访问LLM参数。实验结果显示，CAIN在开源和商业LLM上导致目标问题F1分数下降40%，并在强制输出特定有害答案时达到70%以上，同时对benign输入的影响最小，强调了加强LLM鲁棒性以保护其实用性完整性的迫切需求。",
      "categories": [
        "cs.CR",
        "cs.AI",
        "cs.CL"
      ],
      "primary_category": "cs.CR",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2505.16888v1",
      "published_date": "2025-05-22 16:47:15 UTC",
      "updated_date": "2025-05-22 16:47:15 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-25T03:14:26.092070"
    },
    {
      "arxiv_id": "2505.16886v1",
      "title": "Don't \"Overthink\" Passage Reranking: Is Reasoning Truly Necessary?",
      "title_zh": "不要“过度思考”段落重排：推理真的必要吗？",
      "authors": [
        "Nour Jedidi",
        "Yung-Sung Chuang",
        "James Glass",
        "Jimmy Lin"
      ],
      "abstract": "With the growing success of reasoning models across complex natural language\ntasks, researchers in the Information Retrieval (IR) community have begun\nexploring how similar reasoning capabilities can be integrated into passage\nrerankers built on Large Language Models (LLMs). These methods typically employ\nan LLM to produce an explicit, step-by-step reasoning process before arriving\nat a final relevance prediction. But, does reasoning actually improve reranking\naccuracy? In this paper, we dive deeper into this question, studying the impact\nof the reasoning process by comparing reasoning-based pointwise rerankers\n(ReasonRR) to standard, non-reasoning pointwise rerankers (StandardRR) under\nidentical training conditions, and observe that StandardRR generally\noutperforms ReasonRR. Building on this observation, we then study the\nimportance of reasoning to ReasonRR by disabling its reasoning process\n(ReasonRR-NoReason), and find that ReasonRR-NoReason is surprisingly more\neffective than ReasonRR. Examining the cause of this result, our findings\nreveal that reasoning-based rerankers are limited by the LLM's reasoning\nprocess, which pushes it toward polarized relevance scores and thus fails to\nconsider the partial relevance of passages, a key factor for the accuracy of\npointwise rerankers.",
      "tldr_zh": "本文研究了在信息检索（IR）领域，使用大型语言模型（LLMs）构建的通道重新排序器（passage rerankers）是否需要显式推理过程。作者比较了基于推理的点式重新排序器（ReasonRR）和标准非推理重新排序器（StandardRR），结果显示 StandardRR 在相同训练条件下通常表现更好。进一步实验发现，禁用 ReasonRR 的推理过程（ReasonRR-NoReason）后，其准确性反而提升，主要原因是推理机制导致 LLM 倾向于极端相关性评分，忽略了通道的部分相关性，这对点式重新排序器的性能至关重要。",
      "categories": [
        "cs.IR",
        "cs.AI",
        "cs.CL",
        "cs.LG"
      ],
      "primary_category": "cs.IR",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2505.16886v1",
      "published_date": "2025-05-22 16:41:37 UTC",
      "updated_date": "2025-05-22 16:41:37 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-25T03:14:45.307221"
    },
    {
      "arxiv_id": "2505.16881v1",
      "title": "CASTILLO: Characterizing Response Length Distributions of Large Language Models",
      "title_zh": "翻译失败",
      "authors": [
        "Daniel F. Perez-Ramirez",
        "Dejan Kostic",
        "Magnus Boman"
      ],
      "abstract": "Efficiently managing compute resources for Large Language Model (LLM)\ninference remains challenging due to the inherently stochastic and variable\nlengths of autoregressive text generation. Accurately estimating response\nlengths in advance enables proactive resource allocation, yet existing\napproaches either bias text generation towards certain lengths or rely on\nassumptions that ignore model- and prompt-specific variability. We introduce\nCASTILLO, a dataset characterizing response length distributions across 13\nwidely-used open-source LLMs evaluated on seven distinct instruction-following\ncorpora. For each $\\langle$prompt, model$\\rangle$ sample pair, we generate 10\nindependent completions using fixed decoding hyper-parameters, record the token\nlength of each response, and publish summary statistics (mean, std-dev,\npercentiles), along with the shortest and longest completions, and the exact\ngeneration settings. Our analysis reveals significant inter- and intra-model\nvariability in response lengths (even under identical generation settings), as\nwell as model-specific behaviors and occurrences of partial text degeneration\nin only subsets of responses. CASTILLO enables the development of predictive\nmodels for proactive scheduling and provides a systematic framework for\nanalyzing model-specific generation behaviors. We publicly release the dataset\nand code to foster research at the intersection of generative language modeling\nand systems.",
      "tldr_zh": "该研究针对大型语言模型(LLMs)推理中的计算资源管理挑战，引入了CASTILLO数据集，用于表征13个开源LLMs在七个指令遵循语料上的响应长度分布。\n数据集通过为每个<prompt, model>配对生成10个独立完成，记录token长度并计算摘要统计（如均值、标准差和分位数），揭示了显著的模型间和模型内变异性，以及模型特定行为和部分响应的文本退化现象。\nCASTILLO为开发预测模型提供基础，支持主动资源调度，并公开发布数据集和代码，以推动生成语言建模与系统研究的交叉领域创新。",
      "categories": [
        "cs.CL",
        "cs.AI"
      ],
      "primary_category": "cs.CL",
      "comment": "Dataset available in\n  https://huggingface.co/datasets/danfperam/castillo and code is available in\n  https://github.com/DanielFPerez/castillo",
      "pdf_url": "http://arxiv.org/pdf/2505.16881v1",
      "published_date": "2025-05-22 16:35:33 UTC",
      "updated_date": "2025-05-22 16:35:33 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-25T03:14:48.568565"
    },
    {
      "arxiv_id": "2505.16877v1",
      "title": "Predicate-Conditional Conformalized Answer Sets for Knowledge Graph Embeddings",
      "title_zh": "翻译失败",
      "authors": [
        "Yuqicheng Zhu",
        "Daniel Hernández",
        "Yuan He",
        "Zifeng Ding",
        "Bo Xiong",
        "Evgeny Kharlamov",
        "Steffen Staab"
      ],
      "abstract": "Uncertainty quantification in Knowledge Graph Embedding (KGE) methods is\ncrucial for ensuring the reliability of downstream applications. A recent work\napplies conformal prediction to KGE methods, providing uncertainty estimates by\ngenerating a set of answers that is guaranteed to include the true answer with\na predefined confidence level. However, existing methods provide probabilistic\nguarantees averaged over a reference set of queries and answers (marginal\ncoverage guarantee). In high-stakes applications such as medical diagnosis, a\nstronger guarantee is often required: the predicted sets must provide\nconsistent coverage per query (conditional coverage guarantee). We propose\nCondKGCP, a novel method that approximates predicate-conditional coverage\nguarantees while maintaining compact prediction sets. CondKGCP merges\npredicates with similar vector representations and augments calibration with\nrank information. We prove the theoretical guarantees and demonstrate empirical\neffectiveness of CondKGCP by comprehensive evaluations.",
      "tldr_zh": "该研究针对知识图嵌入(KGE)的不确定性量化问题，提出了一种新方法CondKGCP，以提供更强的谓词条件覆盖保证(conditional coverage guarantee)，从而确保每个查询的预测集都可靠，尤其适用于高风险领域如医疗诊断。CondKGCP通过合并具有相似向量表示的谓词，并结合秩信息增强校准，实现了紧凑的预测集，同时近似于所需的条件覆盖。实验结果证明了该方法的理论有效性和实证性能，提升了KGE下游应用的可靠性。",
      "categories": [
        "cs.AI"
      ],
      "primary_category": "cs.AI",
      "comment": "Accepted to the Finding of ACL 2025",
      "pdf_url": "http://arxiv.org/pdf/2505.16877v1",
      "published_date": "2025-05-22 16:33:20 UTC",
      "updated_date": "2025-05-22 16:33:20 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-25T03:14:59.707281"
    },
    {
      "arxiv_id": "2505.16875v1",
      "title": "T2I-ConBench: Text-to-Image Benchmark for Continual Post-training",
      "title_zh": "翻译失败",
      "authors": [
        "Zhehao Huang",
        "Yuhang Liu",
        "Yixin Lou",
        "Zhengbao He",
        "Mingzhen He",
        "Wenxing Zhou",
        "Tao Li",
        "Kehan Li",
        "Zeyi Huang",
        "Xiaolin Huang"
      ],
      "abstract": "Continual post-training adapts a single text-to-image diffusion model to\nlearn new tasks without incurring the cost of separate models, but naive\npost-training causes forgetting of pretrained knowledge and undermines\nzero-shot compositionality. We observe that the absence of a standardized\nevaluation protocol hampers related research for continual post-training. To\naddress this, we introduce T2I-ConBench, a unified benchmark for continual\npost-training of text-to-image models. T2I-ConBench focuses on two practical\nscenarios, item customization and domain enhancement, and analyzes four\ndimensions: (1) retention of generality, (2) target-task performance, (3)\ncatastrophic forgetting, and (4) cross-task generalization. It combines\nautomated metrics, human-preference modeling, and vision-language QA for\ncomprehensive assessment. We benchmark ten representative methods across three\nrealistic task sequences and find that no approach excels on all fronts. Even\njoint \"oracle\" training does not succeed for every task, and cross-task\ngeneralization remains unsolved. We release all datasets, code, and evaluation\ntools to accelerate research in continual post-training for text-to-image\nmodels.",
      "tldr_zh": "这篇论文引入了 T2I-ConBench，这是一个统一的基准，用于评估文本到图像扩散模型的 continual post-training，以解决模型在学习新任务时遗忘预训练知识和零样本组合性问题。基准聚焦于项目定制和领域增强两个实际场景，并从保留一般性、目标任务性能、灾难性遗忘以及跨任务泛化四个维度进行全面评估，结合自动化指标、人类偏好模型和视觉语言 QA 方法。实验对十种代表性方法进行了基准测试，发现没有一种方法在所有方面均表现出色，甚至联合“预言机”训练也无法完全成功。论文还发布了所有数据集、代码和评估工具，以加速文本到图像模型 continual post-training 的研究。",
      "categories": [
        "cs.CV",
        "cs.AI",
        "cs.LG"
      ],
      "primary_category": "cs.CV",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2505.16875v1",
      "published_date": "2025-05-22 16:31:43 UTC",
      "updated_date": "2025-05-22 16:31:43 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-25T03:15:13.428196"
    },
    {
      "arxiv_id": "2505.16860v1",
      "title": "GCAL: Adapting Graph Models to Evolving Domain Shifts",
      "title_zh": "翻译失败",
      "authors": [
        "Ziyue Qiao",
        "Qianyi Cai",
        "Hao Dong",
        "Jiawei Gu",
        "Pengyang Wang",
        "Meng Xiao",
        "Xiao Luo",
        "Hui Xiong"
      ],
      "abstract": "This paper addresses the challenge of graph domain adaptation on evolving,\nmultiple out-of-distribution (OOD) graphs. Conventional graph domain adaptation\nmethods are confined to single-step adaptation, making them ineffective in\nhandling continuous domain shifts and prone to catastrophic forgetting. This\npaper introduces the Graph Continual Adaptive Learning (GCAL) method, designed\nto enhance model sustainability and adaptability across various graph domains.\nGCAL employs a bilevel optimization strategy. The \"adapt\" phase uses an\ninformation maximization approach to fine-tune the model with new graph domains\nwhile re-adapting past memories to mitigate forgetting. Concurrently, the\n\"generate memory\" phase, guided by a theoretical lower bound derived from\ninformation bottleneck theory, involves a variational memory graph generation\nmodule to condense original graphs into memories. Extensive experimental\nevaluations demonstrate that GCAL substantially outperforms existing methods in\nterms of adaptability and knowledge retention.",
      "tldr_zh": "本文提出 GCAL 方法，针对图模型在演变的多 out-of-distribution (OOD) 图域中的适应挑战，解决传统单步适应的遗忘问题。GCAL 采用双层优化策略，包括“adapt”阶段使用信息最大化方法微调模型并重新适应过去记忆，以及“generate memory”阶段基于信息瓶颈理论的变分记忆图生成模块来浓缩原始图。实验评估表明，GCAL 在适应性和知识保留方面大幅优于现有方法。",
      "categories": [
        "cs.LG",
        "cs.AI"
      ],
      "primary_category": "cs.LG",
      "comment": "Accepted to ICML 2025",
      "pdf_url": "http://arxiv.org/pdf/2505.16860v1",
      "published_date": "2025-05-22 16:19:19 UTC",
      "updated_date": "2025-05-22 16:19:19 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-25T03:15:23.706792"
    },
    {
      "arxiv_id": "2505.16856v1",
      "title": "Efficient Online RL Fine Tuning with Offline Pre-trained Policy Only",
      "title_zh": "仅使用离线预训练策略",
      "authors": [
        "Wei Xiao",
        "Jiacheng Liu",
        "Zifeng Zhuang",
        "Runze Suo",
        "Shangke Lyu",
        "Donglin Wang"
      ],
      "abstract": "Improving the performance of pre-trained policies through online\nreinforcement learning (RL) is a critical yet challenging topic. Existing\nonline RL fine-tuning methods require continued training with offline\npretrained Q-functions for stability and performance. However, these offline\npretrained Q-functions commonly underestimate state-action pairs beyond the\noffline dataset due to the conservatism in most offline RL methods, which\nhinders further exploration when transitioning from the offline to the online\nsetting. Additionally, this requirement limits their applicability in scenarios\nwhere only pre-trained policies are available but pre-trained Q-functions are\nabsent, such as in imitation learning (IL) pre-training. To address these\nchallenges, we propose a method for efficient online RL fine-tuning using\nsolely the offline pre-trained policy, eliminating reliance on pre-trained\nQ-functions. We introduce PORL (Policy-Only Reinforcement Learning\nFine-Tuning), which rapidly initializes the Q-function from scratch during the\nonline phase to avoid detrimental pessimism. Our method not only achieves\ncompetitive performance with advanced offline-to-online RL algorithms and\nonline RL approaches that leverage data or policies prior, but also pioneers a\nnew path for directly fine-tuning behavior cloning (BC) policies.",
      "tldr_zh": "该研究解决了在线强化学习（RL）微调预训练策略的挑战，现有方法依赖预训练 Q-functions 导致探索不足和适用性限制。作者提出 PORL（Policy-Only Reinforcement Learning Fine-Tuning）方法，仅使用离线预训练策略，在在线阶段快速初始化 Q-function 以避免负面影响。该方法在性能上与先进离线到在线 RL 算法竞争，并为直接微调行为克隆（BC）策略开辟新路径。",
      "categories": [
        "cs.LG",
        "cs.AI",
        "cs.RO"
      ],
      "primary_category": "cs.LG",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2505.16856v1",
      "published_date": "2025-05-22 16:14:08 UTC",
      "updated_date": "2025-05-22 16:14:08 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-25T03:15:35.289027"
    },
    {
      "arxiv_id": "2505.16854v1",
      "title": "Think or Not? Selective Reasoning via Reinforcement Learning for Vision-Language Models",
      "title_zh": "翻译失败",
      "authors": [
        "Jiaqi Wang",
        "Kevin Qinghong Lin",
        "James Cheng",
        "Mike Zheng Shou"
      ],
      "abstract": "Reinforcement Learning (RL) has proven to be an effective post-training\nstrategy for enhancing reasoning in vision-language models (VLMs). Group\nRelative Policy Optimization (GRPO) is a recent prominent method that\nencourages models to generate complete reasoning traces before answering,\nleading to increased token usage and computational cost. Inspired by the\nhuman-like thinking process-where people skip reasoning for easy questions but\nthink carefully when needed-we explore how to enable VLMs to first decide when\nreasoning is necessary. To realize this, we propose TON, a two-stage training\nstrategy: (i) a supervised fine-tuning (SFT) stage with a simple yet effective\n'thought dropout' operation, where reasoning traces are randomly replaced with\nempty thoughts. This introduces a think-or-not format that serves as a cold\nstart for selective reasoning; (ii) a GRPO stage that enables the model to\nfreely explore when to think or not, while maximizing task-aware outcome\nrewards. Experimental results show that TON can reduce the completion length by\nup to 90% compared to vanilla GRPO, without sacrificing performance or even\nimproving it. Further evaluations across diverse vision-language tasks-covering\na range of reasoning difficulties under both 3B and 7B models-consistently\nreveal that the model progressively learns to bypass unnecessary reasoning\nsteps as training advances. These findings shed light on the path toward\nhuman-like reasoning patterns in reinforcement learning approaches. Our code is\navailable at https://github.com/kokolerk/TON.",
      "tldr_zh": "本研究探讨了如何让视觉语言模型（VLMs）通过强化学习（RL）实现选择性推理，解决现有方法如 Group Relative Policy Optimization (GRPO) 导致的 token 使用和计算成本增加问题。作者提出 TON 策略，一个两阶段训练框架：第一阶段为监督微调 (SFT)，使用 'thought dropout' 操作随机替换推理痕迹为空白，以引入 think-or-not 格式；第二阶段则应用 GRPO，让模型自主决定何时进行推理，同时最大化任务相关奖励。实验结果显示，TON 可将完成长度减少高达 90%，在各种视觉语言任务上不降低性能，甚至有所提升，并展示了模型逐步学会跳过不必要推理步骤，推动了更接近人类推理模式的进展。",
      "categories": [
        "cs.AI",
        "cs.CV"
      ],
      "primary_category": "cs.AI",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2505.16854v1",
      "published_date": "2025-05-22 16:13:29 UTC",
      "updated_date": "2025-05-22 16:13:29 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-25T03:15:50.006137"
    },
    {
      "arxiv_id": "2505.16845v1",
      "title": "Unlocking Temporal Flexibility: Neural Speech Codec with Variable Frame Rate",
      "title_zh": "翻译失败",
      "authors": [
        "Hanglei Zhang",
        "Yiwei Guo",
        "Zhihan Li",
        "Xiang Hao",
        "Xie Chen",
        "Kai Yu"
      ],
      "abstract": "Most neural speech codecs achieve bitrate adjustment through intra-frame\nmechanisms, such as codebook dropout, at a Constant Frame Rate (CFR). However,\nspeech segments inherently have time-varying information density (e.g., silent\nintervals versus voiced regions). This property makes CFR not optimal in terms\nof bitrate and token sequence length, hindering efficiency in real-time\napplications. In this work, we propose a Temporally Flexible Coding (TFC)\ntechnique, introducing variable frame rate (VFR) into neural speech codecs for\nthe first time. TFC enables seamlessly tunable average frame rates and\ndynamically allocates frame rates based on temporal entropy. Experimental\nresults show that a codec with TFC achieves optimal reconstruction quality with\nhigh flexibility, and maintains competitive performance even at lower frame\nrates. Our approach is promising for the integration with other efforts to\ndevelop low-frame-rate neural speech codecs for more efficient downstream\ntasks.",
      "tldr_zh": "该研究指出，现有的神经语音编解码器（Neural Speech Codec）通过恒定帧率（CFR）机制调整比特率，但忽略了语音段的时间变化信息密度（如静音 vs. 发声区域），导致效率低下。作者提出 Temporally Flexible Coding (TFC) 技术，这是首次将可变帧率（VFR）引入神经语音编解码器，通过根据 temporal entropy 动态分配帧率，实现无缝调整平均帧率。实验结果显示，TFC 编解码器在较低帧率下仍保持竞争性能，并提供最佳重建质量，这为开发更高效的低帧率神经语音编解码器和下游任务集成提供了新前景。",
      "categories": [
        "eess.AS",
        "cs.AI",
        "cs.SD"
      ],
      "primary_category": "eess.AS",
      "comment": "Accepted to Interspeech 2025",
      "pdf_url": "http://arxiv.org/pdf/2505.16845v1",
      "published_date": "2025-05-22 16:10:01 UTC",
      "updated_date": "2025-05-22 16:10:01 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-25T03:16:01.522366"
    },
    {
      "arxiv_id": "2505.16836v1",
      "title": "Fact-R1: Towards Explainable Video Misinformation Detection with Deep Reasoning",
      "title_zh": "翻译失败",
      "authors": [
        "Fanrui Zhang",
        "Dian Li",
        "Qiang Zhang",
        "Chenjun",
        "sinbadliu",
        "Junxiong Lin",
        "Jiahong Yan",
        "Jiawei Liu",
        "Zheng-Jun Zha"
      ],
      "abstract": "The rapid spread of multimodal misinformation on social media has raised\ngrowing concerns, while research on video misinformation detection remains\nlimited due to the lack of large-scale, diverse datasets. Existing methods\noften overfit to rigid templates and lack deep reasoning over deceptive\ncontent. To address these challenges, we introduce FakeVV, a large-scale\nbenchmark comprising over 100,000 video-text pairs with fine-grained,\ninterpretable annotations. In addition, we further propose Fact-R1, a novel\nframework that integrates deep reasoning with collaborative rule-based\nreinforcement learning. Fact-R1 is trained through a three-stage process: (1)\nmisinformation long-Chain-of-Thought (CoT) instruction tuning, (2) preference\nalignment via Direct Preference Optimization (DPO), and (3) Group Relative\nPolicy Optimization (GRPO) using a novel verifiable reward function. This\nenables Fact-R1 to exhibit emergent reasoning behaviors comparable to those\nobserved in advanced text-based reinforcement learning systems, but in the more\ncomplex multimodal misinformation setting. Our work establishes a new paradigm\nfor misinformation detection, bridging large-scale video understanding,\nreasoning-guided alignment, and interpretable verification.",
      "tldr_zh": "该研究针对社交媒体上多模态虚假信息传播的问题，引入了 FakeVV 基准数据集，该数据集包含超过 10 万视频-文本对，并提供细粒度、可解释的标注，以解决现有方法过拟合模板和缺乏深度推理的局限性。作者提出 Fact-R1 框架，该框架整合深度推理与协作规则-based 强化学习，通过三阶段训练过程——包括虚假信息长-Chain-of-Thought (CoT) 指令调优、Direct Preference Optimization (DPO) 偏好对齐，以及 Group Relative Policy Optimization (GRPO) 与可验证奖励函数——实现先进的推理行为。实验结果显示，Fact-R1 在复杂多模态虚假信息场景中表现出色，建立了一个新的检测范式，桥接大规模视频理解、推理引导的对齐和可解释验证。",
      "categories": [
        "cs.CV",
        "cs.AI"
      ],
      "primary_category": "cs.CV",
      "comment": "28 pages, 27 figures",
      "pdf_url": "http://arxiv.org/pdf/2505.16836v1",
      "published_date": "2025-05-22 16:05:06 UTC",
      "updated_date": "2025-05-22 16:05:06 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-25T03:16:14.139458"
    },
    {
      "arxiv_id": "2505.16834v1",
      "title": "SimpleDeepSearcher: Deep Information Seeking via Web-Powered Reasoning Trajectory Synthesis",
      "title_zh": "翻译失败",
      "authors": [
        "Shuang Sun",
        "Huatong Song",
        "Yuhao Wang",
        "Ruiyang Ren",
        "Jinhao Jiang",
        "Junjie Zhang",
        "Fei Bai",
        "Jia Deng",
        "Wayne Xin Zhao",
        "Zheng Liu",
        "Lei Fang",
        "Zhongyuan Wang",
        "Ji-Rong Wen"
      ],
      "abstract": "Retrieval-augmented generation (RAG) systems have advanced large language\nmodels (LLMs) in complex deep search scenarios requiring multi-step reasoning\nand iterative information retrieval. However, existing approaches face critical\nlimitations that lack high-quality training trajectories or suffer from the\ndistributional mismatches in simulated environments and prohibitive\ncomputational costs for real-world deployment. This paper introduces\nSimpleDeepSearcher, a lightweight yet effective framework that bridges this gap\nthrough strategic data engineering rather than complex training paradigms. Our\napproach synthesizes high-quality training data by simulating realistic user\ninteractions in live web search environments, coupled with a multi-criteria\ncuration strategy that optimizes the diversity and quality of input and output\nside. Experiments on five benchmarks across diverse domains demonstrate that\nSFT on only 871 curated samples yields significant improvements over RL-based\nbaselines. Our work establishes SFT as a viable pathway by systematically\naddressing the data-scarce bottleneck, offering practical insights for\nefficient deep search systems. Our code is available at\nhttps://github.com/RUCAIBox/SimpleDeepSearcher.",
      "tldr_zh": "这篇论文提出了 SimpleDeepSearcher，一种轻量级框架，通过战略性数据工程提升检索增强生成 (RAG) 系统在深度搜索场景中的性能，解决现有方法在高质量训练轨迹和分布不匹配方面的局限。框架的核心方法是模拟现实用户互动在实时网络搜索环境中合成训练数据，并采用多标准策展策略优化数据的多样性和质量。实验结果显示，在五个跨领域基准测试上，使用仅 871 个策展样本进行监督微调 (SFT) 比基于强化学习 (RL) 的基线有显著改善。该工作确立了 SFT 作为可行的深度搜索路径，并通过解决数据稀缺问题，提供高效系统的实用见解。",
      "categories": [
        "cs.CL",
        "cs.AI",
        "cs.IR"
      ],
      "primary_category": "cs.CL",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2505.16834v1",
      "published_date": "2025-05-22 16:05:02 UTC",
      "updated_date": "2025-05-22 16:05:02 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-25T03:16:25.642442"
    },
    {
      "arxiv_id": "2505.16832v1",
      "title": "From EduVisBench to EduVisAgent: A Benchmark and Multi-Agent Framework for Pedagogical Visualization",
      "title_zh": "从 EduVisBench 到 EduVisAgent：一个用于教学可视化的基准和多智能体框架",
      "authors": [
        "Haonian Ji",
        "Shi Qiu",
        "Siyang Xin",
        "Siwei Han",
        "Zhaorun Chen",
        "Hongyi Wang",
        "Dake Zhang",
        "Huaxiu Yao"
      ],
      "abstract": "While foundation models (FMs), such as diffusion models and large\nvision-language models (LVLMs), have been widely applied in educational\ncontexts, their ability to generate pedagogically effective visual explanations\nremains limited. Most existing approaches focus primarily on textual reasoning,\noverlooking the critical role of structured and interpretable visualizations in\nsupporting conceptual understanding. To better assess the visual reasoning\ncapabilities of FMs in educational settings, we introduce EduVisBench, a\nmulti-domain, multi-level benchmark. EduVisBench features diverse STEM problem\nsets requiring visually grounded solutions, along with a fine-grained\nevaluation rubric informed by pedagogical theory. Our empirical analysis\nreveals that existing models frequently struggle with the inherent challenge of\ndecomposing complex reasoning and translating it into visual representations\naligned with human cognitive processes. To address these limitations, we\npropose EduVisAgent, a multi-agent collaborative framework that coordinates\nspecialized agents for instructional planning, reasoning decomposition,\nmetacognitive prompting, and visualization design. Experimental results show\nthat EduVisAgent substantially outperforms all baselines, achieving a 40.2%\nimprovement and delivering more educationally aligned visualizations.\nEduVisBench and EduVisAgent are available at\nhttps://github.com/aiming-lab/EduVisBench and\nhttps://github.com/aiming-lab/EduVisAgent.",
      "tldr_zh": "本研究指出，基础模型(FMs)如扩散模型和大型视觉语言模型(LVLMs)在教育应用中生成教育有效的视觉解释能力有限，主要依赖文本推理而忽略结构化可视化。该论文引入EduVisBench，一个多领域多级别的基准测试，包含STEM问题集和基于教育理论的细粒度评估标准，用于评估模型的视觉推理能力。针对现有模型在分解复杂推理和转化为视觉表示方面的不足，提出EduVisAgent多智能体框架，协调专门智能体进行教学规划、推理分解、元认知提示和可视化设计。实验结果显示，EduVisAgent比基线模型提升40.2%，生成更符合教育的可视化。",
      "categories": [
        "cs.AI",
        "cs.CL",
        "cs.CV",
        "cs.LG"
      ],
      "primary_category": "cs.AI",
      "comment": "16 pages; 7 figures",
      "pdf_url": "http://arxiv.org/pdf/2505.16832v1",
      "published_date": "2025-05-22 16:02:18 UTC",
      "updated_date": "2025-05-22 16:02:18 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-25T03:16:37.980234"
    },
    {
      "arxiv_id": "2505.16831v1",
      "title": "Unlearning Isn't Deletion: Investigating Reversibility of Machine Unlearning in LLMs",
      "title_zh": "翻译失败",
      "authors": [
        "Xiaoyu Xu",
        "Xiang Yue",
        "Yang Liu",
        "Qingqing Ye",
        "Haibo Hu",
        "Minxin Du"
      ],
      "abstract": "Unlearning in large language models (LLMs) is intended to remove the\ninfluence of specific data, yet current evaluations rely heavily on token-level\nmetrics such as accuracy and perplexity. We show that these metrics can be\nmisleading: models often appear to forget, but their original behavior can be\nrapidly restored with minimal fine-tuning, revealing that unlearning may\nobscure information rather than erase it. To diagnose this phenomenon, we\nintroduce a representation-level evaluation framework using PCA-based\nsimilarity and shift, centered kernel alignment, and Fisher information.\nApplying this toolkit across six unlearning methods, three domains (text, code,\nmath), and two open-source LLMs, we uncover a critical distinction between\nreversible and irreversible forgetting. In reversible cases, models suffer\ntoken-level collapse yet retain latent features; in irreversible cases, deeper\nrepresentational damage occurs. We further provide a theoretical account\nlinking shallow weight perturbations near output layers to misleading\nunlearning signals, and show that reversibility is modulated by task type and\nhyperparameters. Our findings reveal a fundamental gap in current evaluation\npractices and establish a new diagnostic foundation for trustworthy unlearning\nin LLMs. We provide a unified toolkit for analyzing LLM representation changes\nunder unlearning and relearning:\nhttps://github.com/XiaoyuXU1/Representational_Analysis_Tools.git.",
      "tldr_zh": "这篇论文调查了大型语言模型(LLMs)中机器unlearning的可逆性，发现传统评估指标如准确率和困惑ity可能误导，因为模型看似忘记信息，但通过微调即可快速恢复原行为，表明unlearning 只是隐藏而非删除数据。作者引入了一个representation-level评估框架，使用PCA-based similarity and shift、centered kernel alignment和Fisher information，分析六种unlearning方法在text、code和math等领域的表现。研究揭示了可逆遗忘（保留潜在特征但token-level崩溃）和不可逆遗忘（深层表示破坏）的区别，并通过理论解释权重扰动的影响，提供了一个开源工具包（https://github.com/XiaoyuXU1/Representational_Analysis_Tools.git），为可信赖的unlearning评估奠定新基础。",
      "categories": [
        "cs.CL",
        "cs.AI",
        "cs.CR",
        "cs.LG"
      ],
      "primary_category": "cs.CL",
      "comment": "44 pages",
      "pdf_url": "http://arxiv.org/pdf/2505.16831v1",
      "published_date": "2025-05-22 16:02:10 UTC",
      "updated_date": "2025-05-22 16:02:10 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-25T03:16:49.826604"
    },
    {
      "arxiv_id": "2505.16827v1",
      "title": "GUI-explorer: Autonomous Exploration and Mining of Transition-aware Knowledge for GUI Agent",
      "title_zh": "GUI-explorer：针对 GUI 代理的自治探索与过渡感知知识挖掘",
      "authors": [
        "Bin Xie",
        "Rui Shao",
        "Gongwei Chen",
        "Kaiwen Zhou",
        "Yinchuan Li",
        "Jie Liu",
        "Min Zhang",
        "Liqiang Nie"
      ],
      "abstract": "GUI automation faces critical challenges in dynamic environments. MLLMs\nsuffer from two key issues: misinterpreting UI components and outdated\nknowledge. Traditional fine-tuning methods are costly for app-specific\nknowledge updates. We propose GUI-explorer, a training-free GUI agent that\nincorporates two fundamental mechanisms: (1) Autonomous Exploration of\nFunction-aware Trajectory. To comprehensively cover all application\nfunctionalities, we design a Function-aware Task Goal Generator that\nautomatically constructs exploration goals by analyzing GUI structural\ninformation (e.g., screenshots and activity hierarchies). This enables\nsystematic exploration to collect diverse trajectories. (2) Unsupervised Mining\nof Transition-aware Knowledge. To establish precise screen-operation logic, we\ndevelop a Transition-aware Knowledge Extractor that extracts effective\nscreen-operation logic through unsupervised analysis the state transition of\nstructured interaction triples (observation, action, outcome). This eliminates\nthe need for human involvement in knowledge extraction. With a task success\nrate of 53.7% on SPA-Bench and 47.4% on AndroidWorld, GUI-explorer shows\nsignificant improvements over SOTA agents. It requires no parameter updates for\nnew apps. GUI-explorer is open-sourced and publicly available at\nhttps://github.com/JiuTian-VL/GUI-explorer.",
      "tldr_zh": "该研究针对 GUI 自动化在动态环境中的挑战（如 MLLMs 误解 UI 组件和知识过时），提出了一种无需训练的 GUI-explorer 代理。GUI-explorer 包含两个核心机制：(1) 自主探索 Function-aware Trajectory，通过 Function-aware Task Goal Generator 分析 GUI 结构信息（如截图和活动层次）自动生成探索目标，并收集多样轨迹；(2) 无监督挖掘 Transition-aware Knowledge，利用 Transition-aware Knowledge Extractor 分析结构化交互三元组（observation, action, outcome）的状态转换，提取精确的屏幕-操作逻辑。实验结果显示，GUI-explorer 在 SPA-Bench 上任务成功率达 53.7%，在 AndroidWorld 上达 47.4%，比现有最先进代理显著改进，且无需参数更新即可适应新应用，并已开源发布。",
      "categories": [
        "cs.AI"
      ],
      "primary_category": "cs.AI",
      "comment": "ACL 2025. Github: https://github.com/JiuTian-VL/GUI-explorer",
      "pdf_url": "http://arxiv.org/pdf/2505.16827v1",
      "published_date": "2025-05-22 16:01:06 UTC",
      "updated_date": "2025-05-22 16:01:06 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-25T03:17:01.401342"
    },
    {
      "arxiv_id": "2505.16826v1",
      "title": "KTAE: A Model-Free Algorithm to Key-Tokens Advantage Estimation in Mathematical Reasoning",
      "title_zh": "翻译失败",
      "authors": [
        "Wei Sun",
        "Wen Yang",
        "Pu Jian",
        "Qianlong Du",
        "Fuwei Cui",
        "Shuo Ren",
        "Jiajun Zhang"
      ],
      "abstract": "Recent advances have demonstrated that integrating reinforcement learning\nwith rule-based rewards can significantly enhance the reasoning capabilities of\nlarge language models, even without supervised fine-tuning. However, prevalent\nreinforcement learning algorithms such as GRPO and its variants like DAPO,\nsuffer from a coarse granularity issue when computing the advantage.\nSpecifically, they compute rollout-level advantages that assign identical\nvalues to every token within a sequence, failing to capture token-specific\ncontributions and hindering effective learning. To address this limitation, we\npropose Key-token Advantage Estimation (KTAE) - a novel algorithm that\nestimates fine-grained, token-level advantages without introducing additional\nmodels. KTAE leverages the correctness of sampled rollouts and applies\nstatistical analysis to quantify the importance of individual tokens within a\nsequence to the final outcome. This quantified token-level importance is then\ncombined with the rollout-level advantage to obtain a more fine-grained\ntoken-level advantage estimation. Empirical results show that models trained\nwith GRPO+KTAE and DAPO+KTAE outperform baseline methods across five\nmathematical reasoning benchmarks. Notably, they achieve higher accuracy with\nshorter responses and even surpass R1-Distill-Qwen-1.5B using the same base\nmodel.",
      "tldr_zh": "本研究针对现有强化学习算法（如GRPO和DAPO）在计算优势时存在的粗粒度问题，即回滚级别优势无法捕捉序列中token的具体贡献，提出了一种无模型算法Key-token Advantage Estimation (KTAE)。KTAE通过分析采样回滚的正确性和统计方法，量化每个token对最终结果的重要性，并将其与回滚级别优势结合，获得更细粒度的token级优势估计，从而提升大型语言模型在数学推理中的学习效果。实验结果显示，采用GRPO+KTAE和DAPO+KTAE训练的模型，在五个数学推理基准上超过了基线方法，实现了更高的准确率、更短的响应，甚至使用相同基模型超越了R1-Distill-Qwen-1.5B。",
      "categories": [
        "cs.AI",
        "cs.CL"
      ],
      "primary_category": "cs.AI",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2505.16826v1",
      "published_date": "2025-05-22 16:00:33 UTC",
      "updated_date": "2025-05-22 16:00:33 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-25T03:17:13.525932"
    },
    {
      "arxiv_id": "2505.16813v1",
      "title": "Dynamic Reservoir Computing with Physical Neuromorphic Networks",
      "title_zh": "翻译失败",
      "authors": [
        "Yinhao Xu",
        "Georg A. Gottwald",
        "Zdenka Kuncic"
      ],
      "abstract": "Reservoir Computing (RC) with physical systems requires an understanding of\nthe underlying structure and internal dynamics of the specific physical\nreservoir. In this study, physical nano-electronic networks with neuromorphic\ndynamics are investigated for their use as physical reservoirs in an RC\nframework. These neuromorphic networks operate as dynamic reservoirs, with node\nactivities in general coupled to the edge dynamics through nonlinear\nnano-electronic circuit elements, and the reservoir outputs influenced by the\nunderlying network connectivity structure. This study finds that networks with\nvarying degrees of sparsity generate more useful nonlinear temporal outputs for\ndynamic RC compared to dense networks. Dynamic RC is also tested on an\nautonomous multivariate chaotic time series prediction task with networks of\nvarying densities, which revealed the importance of network sparsity in\nmaintaining network activity and overall dynamics, that in turn enabled the\nlearning of the chaotic Lorenz63 system's attractor behavior.",
      "tldr_zh": "本研究探讨了使用物理神经形态网络作为 Reservoir Computing (RC) 中的动态 reservoirs，这些网络通过非线性纳米电子电路元素将节点活动与边动态耦合。研究发现，稀疏网络相比密集网络能产生更有效的非线性时间输出，从而提升 RC 在动态任务中的性能。在一个自治的多变量混沌时间序列预测任务中，实验显示网络稀疏性有助于维持网络活动和整体动态，从而成功学习 Lorenz63 系统的混沌吸引子行为。总的来说，该工作突出了网络结构在物理 RC 框架中的关键作用。",
      "categories": [
        "cs.ET",
        "cond-mat.dis-nn",
        "cs.AI"
      ],
      "primary_category": "cs.ET",
      "comment": "8 pages, 8 figures, IJCNN 2025, accepted",
      "pdf_url": "http://arxiv.org/pdf/2505.16813v1",
      "published_date": "2025-05-22 15:50:45 UTC",
      "updated_date": "2025-05-22 15:50:45 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-25T03:17:25.686983"
    },
    {
      "arxiv_id": "2505.16801v1",
      "title": "A modular framework for automated evaluation of procedural content generation in serious games with deep reinforcement learning agents",
      "title_zh": "一个模块化的框架，用于自动评估严肃游戏中程序化内容生成的深度强化学习代理",
      "authors": [
        "Eleftherios Kalafatis",
        "Konstantinos Mitsis",
        "Konstantia Zarkogianni",
        "Maria Athanasiou",
        "Konstantina Nikita"
      ],
      "abstract": "Serious Games (SGs) are nowadays shifting focus to include procedural content\ngeneration (PCG) in the development process as a means of offering personalized\nand enhanced player experience. However, the development of a framework to\nassess the impact of PCG techniques when integrated into SGs remains\nparticularly challenging. This study proposes a methodology for automated\nevaluation of PCG integration in SGs, incorporating deep reinforcement learning\n(DRL) game testing agents. To validate the proposed framework, a previously\nintroduced SG featuring card game mechanics and incorporating three different\nversions of PCG for nonplayer character (NPC) creation has been deployed.\nVersion 1 features random NPC creation, while versions 2 and 3 utilize a\ngenetic algorithm approach. These versions are used to test the impact of\ndifferent dynamic SG environments on the proposed framework's agents. The\nobtained results highlight the superiority of the DRL game testing agents\ntrained on Versions 2 and 3 over those trained on Version 1 in terms of win\nrate (i.e. number of wins per played games) and training time. More\nspecifically, within the execution of a test emulating regular gameplay, both\nVersions 2 and 3 peaked at a 97% win rate and achieved statistically\nsignificant higher (p=0009) win rates compared to those achieved in Version 1\nthat peaked at 94%. Overall, results advocate towards the proposed framework's\ncapability to produce meaningful data for the evaluation of procedurally\ngenerated content in SGs.",
      "tldr_zh": "本研究提出了一种模块化框架，用于自动化评估程序化内容生成(PCG)在严肃游戏(SGs)中的整合影响，该框架利用深度强化学习(DRL)代理进行测试。研究以一个包含卡片游戏机制的SG为例，比较了三种PCG版本：Version 1采用随机NPC创建，而Versions 2和3使用遗传算法生成NPC。结果显示，Versions 2和3的DRL代理在胜率和训练时间上均优于Version 1，特别是在模拟常规游戏测试中，前两者达到97%的峰值胜率，并显著高于Version 1的94%（p=0.009）。总体而言，该框架能够生成有意义的数据，支持对SG中PCG效果的有效评估。",
      "categories": [
        "cs.LG",
        "cs.AI"
      ],
      "primary_category": "cs.LG",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2505.16801v1",
      "published_date": "2025-05-22 15:40:56 UTC",
      "updated_date": "2025-05-22 15:40:56 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-25T03:17:37.760120"
    },
    {
      "arxiv_id": "2505.16798v1",
      "title": "SEED: Speaker Embedding Enhancement Diffusion Model",
      "title_zh": "SEED：说话者嵌入增强扩散模型",
      "authors": [
        "KiHyun Nam",
        "Jungwoo Heo",
        "Jee-weon Jung",
        "Gangin Park",
        "Chaeyoung Jung",
        "Ha-Jin Yu",
        "Joon Son Chung"
      ],
      "abstract": "A primary challenge when deploying speaker recognition systems in real-world\napplications is performance degradation caused by environmental mismatch. We\npropose a diffusion-based method that takes speaker embeddings extracted from a\npre-trained speaker recognition model and generates refined embeddings. For\ntraining, our approach progressively adds Gaussian noise to both clean and\nnoisy speaker embeddings extracted from clean and noisy speech, respectively,\nvia forward process of a diffusion model, and then reconstructs them to clean\nembeddings in the reverse process. While inferencing, all embeddings are\nregenerated via diffusion process. Our method needs neither speaker label nor\nany modification to the existing speaker recognition pipeline. Experiments on\nevaluation sets simulating environment mismatch scenarios show that our method\ncan improve recognition accuracy by up to 19.6% over baseline models while\nretaining performance on conventional scenarios. We publish our code here\nhttps://github.com/kaistmm/seed-pytorch",
      "tldr_zh": "该研究针对说话人识别系统在真实环境中因环境不匹配导致性能下降的问题，提出SEED模型，即一种基于diffusion model的说话人嵌入增强方法。SEED通过扩散模型的正向过程向干净和嘈杂的speaker embeddings添加Gaussian noise，然后在逆向过程重建为干净嵌入，从而无需说话人标签或修改现有识别管道。实验结果显示，该方法在模拟环境不匹配场景的评估集上比基线模型提高识别准确率高达19.6%，同时在常规场景中保持原有性能。",
      "categories": [
        "eess.AS",
        "cs.AI"
      ],
      "primary_category": "eess.AS",
      "comment": "Accepted to Interspeech 2025. The official code can be found at\n  https://github.com/kaistmm/seed-pytorch",
      "pdf_url": "http://arxiv.org/pdf/2505.16798v1",
      "published_date": "2025-05-22 15:38:37 UTC",
      "updated_date": "2025-05-22 15:38:37 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-25T03:17:50.512198"
    },
    {
      "arxiv_id": "2505.16792v1",
      "title": "REPA Works Until It Doesn't: Early-Stopped, Holistic Alignment Supercharges Diffusion Training",
      "title_zh": "翻译失败",
      "authors": [
        "Ziqiao Wang",
        "Wangbo Zhao",
        "Yuhao Zhou",
        "Zekai Li",
        "Zhiyuan Liang",
        "Mingjia Shi",
        "Xuanlei Zhao",
        "Pengfei Zhou",
        "Kaipeng Zhang",
        "Zhangyang Wang",
        "Kai Wang",
        "Yang You"
      ],
      "abstract": "Diffusion Transformers (DiTs) deliver state-of-the-art image quality, yet\ntheir training remains notoriously slow. A recent remedy -- representation\nalignment (REPA) that matches DiT hidden features to those of a non-generative\nteacher (e.g. DINO) -- dramatically accelerates the early epochs but plateaus\nor even degrades performance later. We trace this failure to a capacity\nmismatch: once the generative student begins modelling the joint data\ndistribution, the teacher's lower-dimensional embeddings and attention patterns\nbecome a straitjacket rather than a guide. We then introduce HASTE (Holistic\nAlignment with Stage-wise Termination for Efficient training), a two-phase\nschedule that keeps the help and drops the hindrance. Phase I applies a\nholistic alignment loss that simultaneously distills attention maps (relational\npriors) and feature projections (semantic anchors) from the teacher into\nmid-level layers of the DiT, yielding rapid convergence. Phase II then performs\none-shot termination that deactivates the alignment loss, once a simple trigger\nsuch as a fixed iteration is hit, freeing the DiT to focus on denoising and\nexploit its generative capacity. HASTE speeds up training of diverse DiTs\nwithout architecture changes. On ImageNet 256X256, it reaches the vanilla\nSiT-XL/2 baseline FID in 50 epochs and matches REPA's best FID in 500 epochs,\namounting to a 28X reduction in optimization steps. HASTE also improves\ntext-to-image DiTs on MS-COCO, demonstrating to be a simple yet principled\nrecipe for efficient diffusion training across various tasks. Our code is\navailable at https://github.com/NUS-HPC-AI-Lab/HASTE .",
      "tldr_zh": "该研究发现，Representation Alignment (REPA) 方法虽然能加速 Diffusion Transformers (DiTs) 的早期训练，但后期会因容量不匹配导致性能停滞。针对此问题，作者提出 HASTE（Holistic Alignment with Stage-wise Termination for Efficient training），一个两阶段框架：Phase I 通过整体对齐损失从教师模型（如 DINO）中蒸馏注意力图和特征投影，实现快速收敛；Phase II 在达到固定迭代时终止对齐损失，让 DiTs 专注于去噪任务。实验结果显示，HASTE 在 ImageNet 256x256 上将训练步骤减少 28 倍，在 50 个 epoch 内达到基线 FID，并在 MS-COCO 的文本到图像任务上提升性能，提供了一种高效的扩散模型训练策略。",
      "categories": [
        "cs.CV",
        "cs.AI"
      ],
      "primary_category": "cs.CV",
      "comment": "24 pages",
      "pdf_url": "http://arxiv.org/pdf/2505.16792v1",
      "published_date": "2025-05-22 15:34:33 UTC",
      "updated_date": "2025-05-22 15:34:33 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-25T03:18:03.089272"
    },
    {
      "arxiv_id": "2505.16791v1",
      "title": "Cohort-Based Active Modality Acquisition",
      "title_zh": "基于队列的主动模态获取",
      "authors": [
        "Tillmann Rheude",
        "Roland Eils",
        "Benjamin Wild"
      ],
      "abstract": "Real-world machine learning applications often involve data from multiple\nmodalities that must be integrated effectively to make robust predictions.\nHowever, in many practical settings, not all modalities are available for every\nsample, and acquiring additional modalities can be costly. This raises the\nquestion: which samples should be prioritized for additional modality\nacquisition when resources are limited? While prior work has explored\nindividual-level acquisition strategies and training-time active learning\nparadigms, test-time and cohort-based acquisition remain underexplored despite\ntheir importance in many real-world settings. We introduce Cohort-based Active\nModality Acquisition (CAMA), a novel test-time setting to formalize the\nchallenge of selecting which samples should receive additional modalities. We\nderive acquisition strategies that leverage a combination of generative\nimputation and discriminative modeling to estimate the expected benefit of\nacquiring missing modalities based on common evaluation metrics. We also\nintroduce upper-bound heuristics that provide performance ceilings to benchmark\nacquisition strategies. Experiments on common multimodal datasets demonstrate\nthat our proposed imputation-based strategies can more effectively guide the\nacquisition of new samples in comparison to those relying solely on unimodal\ninformation, entropy guidance, and random selections. Our work provides an\neffective solution for optimizing modality acquisition at the cohort level,\nenabling better utilization of resources in constrained settings.",
      "tldr_zh": "这篇论文针对多模态机器学习应用中模态获取的资源限制问题，引入了 Cohort-based Active Modality Acquisition (CAMA) 框架，该框架专注于测试时的群组级策略，以优先选择哪些样本应获取额外模态。CAMA 通过结合 generative imputation 和 discriminative modeling 来估计获取缺失模态的预期益处，并引入 upper-bound heuristics 作为性能基准。实验在常见多模态数据集上表明，该策略比依赖单模态信息、熵指导或随机选择的 baseline 方法更有效地优化样本获取。整体而言，这为资源受限场景下提高模态整合效率提供了实用解决方案。",
      "categories": [
        "cs.LG",
        "cs.AI"
      ],
      "primary_category": "cs.LG",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2505.16791v1",
      "published_date": "2025-05-22 15:32:50 UTC",
      "updated_date": "2025-05-22 15:32:50 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-25T03:18:15.318891"
    },
    {
      "arxiv_id": "2505.16790v1",
      "title": "Learning Flexible Forward Trajectories for Masked Molecular Diffusion",
      "title_zh": "翻译失败",
      "authors": [
        "Hyunjin Seo",
        "Taewon Kim",
        "Sihyun Yu",
        "SungSoo Ahn"
      ],
      "abstract": "Masked diffusion models (MDMs) have achieved notable progress in modeling\ndiscrete data, while their potential in molecular generation remains\nunderexplored. In this work, we explore their potential and introduce the\nsurprising result that naively applying standards MDMs severely degrades the\nperformance. We identify the critical cause of this issue as a state-clashing\nproblem-where the forward diffusion of distinct molecules collapse into a\ncommon state, resulting in a mixture of reconstruction targets that cannot be\nlearned using typical reverse diffusion process with unimodal predictions. To\nmitigate this, we propose Masked Element-wise Learnable Diffusion (MELD) that\norchestrates per-element corruption trajectories to avoid collision between\ndistinct molecular graphs. This is achieved through a parameterized noise\nscheduling network that assigns distinct corruption rates to individual graph\nelements, i.e., atoms and bonds. Extensive experiments on diverse molecular\nbenchmarks reveal that MELD markedly enhances overall generation quality\ncompared to element-agnostic noise scheduling, increasing the chemical validity\nof vanilla MDMs on ZINC250K from 15% to 93%, Furthermore, it achieves\nstate-of-the-art property alignment in conditional generation tasks.",
      "tldr_zh": "本论文探讨了Masked Diffusion Models (MDMs)在分子生成中的潜力，但发现直接应用会导致性能下降，主要由于state-clashing问题，即不同分子的前向扩散会合并成共同状态，干扰逆向扩散学习。针对此，研究提出Masked Element-wise Learnable Diffusion (MELD)方法，通过一个参数化的噪声调度网络为每个图元素（如原子和键）分配独特的腐败率，从而避免分子图之间的碰撞。实验在多个分子基准上验证了MELD的有效性，将ZINC250K数据集的化学有效性从15%提高到93%，并在条件生成任务中实现了state-of-the-art的属性对齐性能。",
      "categories": [
        "cs.LG",
        "cs.AI"
      ],
      "primary_category": "cs.LG",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2505.16790v1",
      "published_date": "2025-05-22 15:30:17 UTC",
      "updated_date": "2025-05-22 15:30:17 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-25T03:18:26.139728"
    },
    {
      "arxiv_id": "2505.16789v1",
      "title": "Accidental Misalignment: Fine-Tuning Language Models Induces Unexpected Vulnerability",
      "title_zh": "意外不对齐：微调语言模型",
      "authors": [
        "Punya Syon Pandey",
        "Samuel Simko",
        "Kellin Pelrine",
        "Zhijing Jin"
      ],
      "abstract": "As large language models gain popularity, their vulnerability to adversarial\nattacks remains a primary concern. While fine-tuning models on domain-specific\ndatasets is often employed to improve model performance, it can introduce\nvulnerabilities within the underlying model. In this work, we investigate\nAccidental Misalignment, unexpected vulnerabilities arising from\ncharacteristics of fine-tuning data. We begin by identifying potential\ncorrelation factors such as linguistic features, semantic similarity, and\ntoxicity within our experimental datasets. We then evaluate the adversarial\nperformance of these fine-tuned models and assess how dataset factors correlate\nwith attack success rates. Lastly, we explore potential causal links, offering\nnew insights into adversarial defense strategies and highlighting the crucial\nrole of dataset design in preserving model alignment. Our code is available at\nhttps://github.com/psyonp/accidental_misalignment.",
      "tldr_zh": "本研究探讨了微调（Fine-Tuning）语言模型时引发的意外漏洞（Accidental Misalignment），这些漏洞源于微调数据集的特性，如语言特征、语义相似性和毒性。研究者通过识别潜在相关因素、评估微调模型的对抗性能（Adversarial Performance），并分析数据集因素与攻击成功率的相关性，来揭示这些漏洞的成因。最终，他们探讨了潜在因果关系，为对抗防御策略（Adversarial Defense）提供了新见解，并强调了数据集设计在维护模型对齐（Model Alignment）中的关键作用。代码已在 https://github.com/psyonp/accidental_misalignment 公开。",
      "categories": [
        "cs.CL",
        "cs.AI",
        "cs.LG"
      ],
      "primary_category": "cs.CL",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2505.16789v1",
      "published_date": "2025-05-22 15:30:00 UTC",
      "updated_date": "2025-05-22 15:30:00 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-25T03:18:37.263126"
    },
    {
      "arxiv_id": "2505.16787v1",
      "title": "Gaze Into the Abyss -- Planning to Seek Entropy When Reward is Scarce",
      "title_zh": "翻译失败",
      "authors": [
        "Ashish Sundar",
        "Chunbo Luo",
        "Xiaoyang Wang"
      ],
      "abstract": "Model-based reinforcement learning (MBRL) offers an intuitive way to increase\nthe sample efficiency of model-free RL methods by simultaneously training a\nworld model that learns to predict the future. MBRL methods have progressed by\nlargely prioritising the actor; optimising the world model learning has been\nneglected meanwhile. Improving the fidelity of the world model and reducing its\ntime to convergence can yield significant downstream benefits, one of which is\nimproving the ensuing performance of any actor it may train. We propose a novel\napproach that anticipates and actively seeks out high-entropy states using\nshort-horizon latent predictions generated by the world model, offering a\nprincipled alternative to traditional curiosity-driven methods that chase\nonce-novel states well after they were stumbled into. While many model\npredictive control (MPC) based methods offer similar alternatives, they\ntypically lack commitment, synthesising multi step plans after every step. To\nmitigate this, we present a hierarchical planner that dynamically decides when\nto replan, planning horizon length, and the weighting between reward and\nentropy. While our method can theoretically be applied to any model that trains\nits own actors with solely model generated data, we have applied it to just\nDreamer as a proof of concept. Our method finishes the Miniworld procedurally\ngenerated mazes 50% faster than base Dreamer at convergence and the policy\ntrained in imagination converges in only 60% of the environment steps that base\nDreamer needs.",
      "tldr_zh": "该论文探讨了模型-based 强化学习 (MBRL) 中世界模型优化的不足，提出一种新方法，通过世界模型生成的短-horizon 潜变量预测，主动寻求高熵状态，以提升样本效率并作为传统 curiosity-driven methods 的替代。不同于典型的 model predictive control (MPC) 方法，该方法引入一个 hierarchical planner 来动态决定何时重新规划、规划horizon长度以及reward和entropy的权重，从而提高决策的连续性和承诺。实验结果显示，在 Dreamer 框架上应用后，该方法在 Miniworld 程序生成迷宫任务中使收敛速度提高 50%，政策训练仅需基础 Dreamer 的 60% 环境步骤。",
      "categories": [
        "cs.AI"
      ],
      "primary_category": "cs.AI",
      "comment": "9 pages without appendix, 15 Figures, preprint",
      "pdf_url": "http://arxiv.org/pdf/2505.16787v1",
      "published_date": "2025-05-22 15:28:50 UTC",
      "updated_date": "2025-05-22 15:28:50 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-25T03:18:50.771708"
    },
    {
      "arxiv_id": "2505.16785v1",
      "title": "CoTSRF: Utilize Chain of Thought as Stealthy and Robust Fingerprint of Large Language Models",
      "title_zh": "翻译失败",
      "authors": [
        "Zhenzhen Ren",
        "GuoBiao Li",
        "Sheng Li",
        "Zhenxing Qian",
        "Xinpeng Zhang"
      ],
      "abstract": "Despite providing superior performance, open-source large language models\n(LLMs) are vulnerable to abusive usage. To address this issue, recent works\npropose LLM fingerprinting methods to identify the specific source LLMs behind\nsuspect applications. However, these methods fail to provide stealthy and\nrobust fingerprint verification. In this paper, we propose a novel LLM\nfingerprinting scheme, namely CoTSRF, which utilizes the Chain of Thought (CoT)\nas the fingerprint of an LLM. CoTSRF first collects the responses from the\nsource LLM by querying it with crafted CoT queries. Then, it applies\ncontrastive learning to train a CoT extractor that extracts the CoT feature\n(i.e., fingerprint) from the responses. Finally, CoTSRF conducts fingerprint\nverification by comparing the Kullback-Leibler divergence between the CoT\nfeatures of the source and suspect LLMs against an empirical threshold. Various\nexperiments have been conducted to demonstrate the advantage of our proposed\nCoTSRF for fingerprinting LLMs, particularly in stealthy and robust fingerprint\nverification.",
      "tldr_zh": "本文提出 CoTSRF 方案，利用 Chain of Thought (CoT) 作为大语言模型 (LLMs) 的隐秘且鲁棒指纹，以识别可疑应用的来源模型，解决现有指纹方法的局限性。该方法首先通过精心设计的 CoT 查询从源模型收集响应，然后使用 contrastive learning 训练 CoT 提取器来提取指纹特征。最终，通过比较源模型和可疑模型的 CoT 特征的 Kullback-Leibler divergence 与经验阈值进行验证，实验结果显示 CoTSRF 在隐秘性和鲁棒性方面显著优于基线方法。",
      "categories": [
        "cs.CR",
        "cs.AI"
      ],
      "primary_category": "cs.CR",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2505.16785v1",
      "published_date": "2025-05-22 15:28:25 UTC",
      "updated_date": "2025-05-22 15:28:25 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-25T03:19:03.340443"
    },
    {
      "arxiv_id": "2505.16781v1",
      "title": "Fuzzy Information Evolution with Three-Way Decision in Social Network Group Decision-Making",
      "title_zh": "翻译失败",
      "authors": [
        "Qianlei Jia",
        "Xinliang Zhou",
        "Ondrej Krejcar",
        "Enrique Herrera-Viedma"
      ],
      "abstract": "In group decision-making (GDM) scenarios, uncertainty, dynamic social\nstructures, and vague information present major challenges for traditional\nopinion dynamics models. To address these issues, this study proposes a novel\nsocial network group decision-making (SNGDM) framework that integrates\nthree-way decision (3WD) theory, dynamic network reconstruction, and linguistic\nopinion representation. First, the 3WD mechanism is introduced to explicitly\nmodel hesitation and ambiguity in agent judgments, thereby preventing\nirrational decisions. Second, a connection adjustment rule based on opinion\nsimilarity is developed, enabling agents to adaptively update their\ncommunication links and better reflect the evolving nature of social\nrelationships. Third, linguistic terms are used to describe agent opinions,\nallowing the model to handle subjective, vague, or incomplete information more\neffectively. Finally, an integrated multi-agent decision-making framework is\nconstructed, which simultaneously considers individual uncertainty, opinion\nevolution, and network dynamics. The proposed model is applied to a multi-UAV\ncooperative decision-making scenario, where simulation results and consensus\nanalysis demonstrate its effectiveness. Experimental comparisons further verify\nthe advantages of the algorithm in enhancing system stability and representing\nrealistic decision-making behaviors.",
      "tldr_zh": "本研究提出了一种整合三向决策(3WD)理论的社交网络群决策(SNGDM)框架，以应对群决策中的不确定性、动态社会结构和模糊信息问题。该框架通过引入3WD机制来处理代理判断中的犹豫和模糊、开发基于意见相似度的连接调整规则来动态更新社交网络，以及使用语言术语表示代理意见，从而更有效地管理主观和不完整信息。最终，该框架构建了一个综合的多代理决策系统，考虑个体不确定性、意见演变和网络动态，并在多无人机合作决策场景的模拟中验证了其有效性，实验结果显示其显著提高了系统稳定性和决策行为的真实性。",
      "categories": [
        "cs.AI"
      ],
      "primary_category": "cs.AI",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2505.16781v1",
      "published_date": "2025-05-22 15:26:48 UTC",
      "updated_date": "2025-05-22 15:26:48 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-25T03:19:14.679144"
    },
    {
      "arxiv_id": "2505.16773v1",
      "title": "Mitigating Overfitting in Medical Imaging: Self-Supervised Pretraining vs. ImageNet Transfer Learning for Dermatological Diagnosis",
      "title_zh": "翻译失败",
      "authors": [
        "Iván Matas",
        "Carmen Serrano",
        "Miguel Nogales",
        "David Moreno",
        "Lara Ferrándiz",
        "Teresa Ojeda",
        "Begoña Acha"
      ],
      "abstract": "Deep learning has transformed computer vision but relies heavily on large\nlabeled datasets and computational resources. Transfer learning, particularly\nfine-tuning pretrained models, offers a practical alternative; however, models\npretrained on natural image datasets such as ImageNet may fail to capture\ndomain-specific characteristics in medical imaging. This study introduces an\nunsupervised learning framework that extracts high-value dermatological\nfeatures instead of relying solely on ImageNet-based pretraining. We employ a\nVariational Autoencoder (VAE) trained from scratch on a proprietary\ndermatological dataset, allowing the model to learn a structured and clinically\nrelevant latent space. This self-supervised feature extractor is then compared\nto an ImageNet-pretrained backbone under identical classification conditions,\nhighlighting the trade-offs between general-purpose and domain-specific\npretraining. Our results reveal distinct learning patterns. The self-supervised\nmodel achieves a final validation loss of 0.110 (-33.33%), while the\nImageNet-pretrained model stagnates at 0.100 (-16.67%), indicating overfitting.\nAccuracy trends confirm this: the self-supervised model improves from 45% to\n65% (+44.44%) with a near-zero overfitting gap, whereas the ImageNet-pretrained\nmodel reaches 87% (+50.00%) but plateaus at 75% (+19.05%), with its overfitting\ngap increasing to +0.060. These findings suggest that while ImageNet\npretraining accelerates convergence, it also amplifies overfitting on\nnon-clinically relevant features. In contrast, self-supervised learning\nachieves steady improvements, stronger generalization, and superior\nadaptability, underscoring the importance of domain-specific feature extraction\nin medical imaging.",
      "tldr_zh": "该研究探讨了在医疗成像中缓解过拟合问题，比较了Self-Supervised Pretraining和ImageNet Transfer Learning在皮肤病诊断中的表现。研究引入一个基于Variational Autoencoder (VAE)的自监督框架，在专有皮肤病数据集上从零训练，以提取临床相关的特征，并与ImageNet预训练模型在相同分类条件下进行对比。结果显示，自监督模型的验证损失降低至0.110（-33.33%），准确率从45%提升至65%（+44.44%），并保持近零的过拟合间隙；相比之下，ImageNet预训练模型虽加速收敛至87%的准确率，但最终停滞在75%（+19.05%），过拟合间隙增加至+0.060。这些发现强调了自监督学习在提供更强泛化性和适应性方面的优势，突出了领域特定特征提取在医疗成像中的重要性。",
      "categories": [
        "cs.CV",
        "cs.AI"
      ],
      "primary_category": "cs.CV",
      "comment": "6 pages, 2 tables, 2 figures",
      "pdf_url": "http://arxiv.org/pdf/2505.16773v1",
      "published_date": "2025-05-22 15:15:17 UTC",
      "updated_date": "2025-05-22 15:15:17 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-25T03:19:27.849972"
    },
    {
      "arxiv_id": "2505.16771v1",
      "title": "Data-Driven Breakthroughs and Future Directions in AI Infrastructure: A Comprehensive Review",
      "title_zh": "数据驱动的突破",
      "authors": [
        "Beyazit Bestami Yuksel",
        "Ayse Yilmazer Metin"
      ],
      "abstract": "This paper presents a comprehensive synthesis of major breakthroughs in\nartificial intelligence (AI) over the past fifteen years, integrating\nhistorical, theoretical, and technological perspectives. It identifies key\ninflection points in AI' s evolution by tracing the convergence of\ncomputational resources, data access, and algorithmic innovation. The analysis\nhighlights how researchers enabled GPU based model training, triggered a data\ncentric shift with ImageNet, simplified architectures through the Transformer,\nand expanded modeling capabilities with the GPT series. Rather than treating\nthese advances as isolated milestones, the paper frames them as indicators of\ndeeper paradigm shifts. By applying concepts from statistical learning theory\nsuch as sample complexity and data efficiency, the paper explains how\nresearchers translated breakthroughs into scalable solutions and why the field\nmust now embrace data centric approaches. In response to rising privacy\nconcerns and tightening regulations, the paper evaluates emerging solutions\nlike federated learning, privacy enhancing technologies (PETs), and the data\nsite paradigm, which reframe data access and security. In cases where real\nworld data remains inaccessible, the paper also assesses the utility and\nconstraints of mock and synthetic data generation. By aligning technical\ninsights with evolving data infrastructure, this study offers strategic\nguidance for future AI research and policy development.",
      "tldr_zh": "这篇论文对过去15年的AI突破进行全面回顾，强调了计算资源、数据访问和算法创新的融合，包括GPU-based model training、ImageNet引发的data-centric shift、Transformer简化架构以及GPT series扩展建模能力等关键事件。论文应用statistical learning theory（如sample complexity和data efficiency）来解释这些进展如何转化为可扩展解决方案，并呼吁AI领域转向data-centric approaches以应对隐私法规。针对数据访问挑战，它评估了federated learning、privacy enhancing technologies (PETs)和data site paradigm等新兴技术，以及mock and synthetic data generation的效用和限制，为未来AI研究和政策发展提供战略指导。",
      "categories": [
        "cs.AI"
      ],
      "primary_category": "cs.AI",
      "comment": "10 pages, 6 figures, 3 tables",
      "pdf_url": "http://arxiv.org/pdf/2505.16771v1",
      "published_date": "2025-05-22 15:12:48 UTC",
      "updated_date": "2025-05-22 15:12:48 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-25T03:19:42.285626"
    },
    {
      "arxiv_id": "2505.16765v1",
      "title": "When Safety Detectors Aren't Enough: A Stealthy and Effective Jailbreak Attack on LLMs via Steganographic Techniques",
      "title_zh": "翻译失败",
      "authors": [
        "Jianing Geng",
        "Biao Yi",
        "Zekun Fei",
        "Tongxi Wu",
        "Lihai Nie",
        "Zheli Liu"
      ],
      "abstract": "Jailbreak attacks pose a serious threat to large language models (LLMs) by\nbypassing built-in safety mechanisms and leading to harmful outputs. Studying\nthese attacks is crucial for identifying vulnerabilities and improving model\nsecurity. This paper presents a systematic survey of jailbreak methods from the\nnovel perspective of stealth. We find that existing attacks struggle to\nsimultaneously achieve toxic stealth (concealing toxic content) and linguistic\nstealth (maintaining linguistic naturalness). Motivated by this, we propose\nStegoAttack, a fully stealthy jailbreak attack that uses steganography to hide\nthe harmful query within benign, semantically coherent text. The attack then\nprompts the LLM to extract the hidden query and respond in an encrypted manner.\nThis approach effectively hides malicious intent while preserving naturalness,\nallowing it to evade both built-in and external safety mechanisms. We evaluate\nStegoAttack on four safety-aligned LLMs from major providers, benchmarking\nagainst eight state-of-the-art methods. StegoAttack achieves an average attack\nsuccess rate (ASR) of 92.00%, outperforming the strongest baseline by 11.0%.\nIts ASR drops by less than 1% even under external detection (e.g., Llama\nGuard). Moreover, it attains the optimal comprehensive scores on stealth\ndetection metrics, demonstrating both high efficacy and exceptional stealth\ncapabilities. The code is available at\nhttps://anonymous.4open.science/r/StegoAttack-Jail66",
      "tldr_zh": "这篇论文探讨了jailbreak attacks对大型语言模型(LLMs)的威胁，强调现有攻击难以同时实现toxic stealth（隐藏有害内容）和linguistic stealth（保持语言自然性）。作者提出StegoAttack，一种利用steganography在良性文本中隐藏有害查询的隐蔽攻击方法，该方法通过提示LLM提取隐藏查询并加密响应，从而有效规避内置和外部安全机制。实验结果显示，StegoAttack在四种安全对齐LLMs上平均攻击成功率（ASR）达92.00%，比最强基线高11.0%，并在外部检测（如Llama Guard）下ASR仅下降不到1%，展示了其优越的隐蔽性和有效性。",
      "categories": [
        "cs.CR",
        "cs.AI"
      ],
      "primary_category": "cs.CR",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2505.16765v1",
      "published_date": "2025-05-22 15:07:34 UTC",
      "updated_date": "2025-05-22 15:07:34 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-25T03:19:53.131343"
    },
    {
      "arxiv_id": "2505.16752v1",
      "title": "Action is All You Need: Dual-Flow Generative Ranking Network for Recommendation",
      "title_zh": "翻译失败",
      "authors": [
        "Hao Guo",
        "Erpeng Xue",
        "Lei Huang",
        "Shichao Wang",
        "Xiaolei Wang",
        "Lei Wang",
        "Jinpeng Wang",
        "Sheng Chen"
      ],
      "abstract": "We introduce the Dual-Flow Generative Ranking Network (DFGR), a two-stream\narchitecture designed for recommendation systems. DFGR integrates innovative\ninteraction patterns between real and fake flows within the QKV modules of the\nself-attention mechanism, enhancing both training and inference efficiency.\nThis approach effectively addresses a key limitation observed in Meta's\nproposed HSTU generative recommendation approach, where heterogeneous\ninformation volumes are mapped into identical vector spaces, leading to\ntraining instability. Unlike traditional recommendation models, DFGR only\nrelies on user history behavior sequences and minimal attribute information,\neliminating the need for extensive manual feature engineering. Comprehensive\nevaluations on open-source and industrial datasets reveal DFGR's superior\nperformance compared to established baselines such as DIN, DCN, DIEN, and\nDeepFM. We also investigate optimal parameter allocation strategies under\ncomputational constraints, establishing DFGR as an efficient and effective\nnext-generation generate ranking paradigm.",
      "tldr_zh": "本研究提出 Dual-Flow Generative Ranking Network (DFGR)，一个两流架构的推荐系统，通过在自注意力机制的 QKV 模块中整合真实和假流的交互模式，提升训练和推理效率，同时解决异构信息映射导致的训练不稳定问题。\nDFGR 仅依赖用户历史行为序列和最小属性信息，消除了对广泛手动特征工程的需求。\n在开源和工业数据集上的全面评估中，DFGR 比基线模型如 DIN、DCN、DIEN 和 DeepFM 表现出色，并探讨了计算约束下的最优参数分配策略，建立了一种高效的生成排名范式。",
      "categories": [
        "cs.IR",
        "cs.AI"
      ],
      "primary_category": "cs.IR",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2505.16752v1",
      "published_date": "2025-05-22 14:58:53 UTC",
      "updated_date": "2025-05-22 14:58:53 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-25T03:20:05.396787"
    },
    {
      "arxiv_id": "2505.16743v1",
      "title": "TRIM: Achieving Extreme Sparsity with Targeted Row-wise Iterative Metric-driven Pruning",
      "title_zh": "翻译失败",
      "authors": [
        "Florentin Beck",
        "William Rudman",
        "Carsten Eickhoff"
      ],
      "abstract": "Large Language Models (LLMs) present significant computational and memory\nchallenges due to their extensive size, making pruning essential for their\nefficient deployment. Existing one-shot pruning methods often apply uniform\nsparsity constraints across layers or within each layer, resulting in\nsuboptimal performance, especially at high sparsity ratios. This work\nintroduces TRIM (Targeted Row-wise Iterative Metric-driven pruning), a novel\napproach that applies varying sparsity ratios to individual output dimensions\n(rows) within each layer. TRIM employs an iterative adjustment process guided\nby quality metrics to optimize dimension-wise sparsity allocation, focusing on\nreducing variance in quality retention across outputs to preserve critical\ninformation. TRIM can be seamlessly integrated with existing layer-wise pruning\nstrategies. Our evaluations on perplexity and zero-shot tasks across diverse\nLLM families (Qwen2.5, LLaMA-2, and OPT) and sparsity levels demonstrate that\nTRIM achieves new state-of-the-art results and enhances stability. For\ninstance, at 80% sparsity, TRIM reduces perplexity by 48% for Qwen2.5-14B and\nover 90% for OPT-13B compared to baseline methods. We conclude that\nfine-grained, dimension-wise sparsity adaptation is crucial for pushing the\nlimits of extreme LLM compression. Code available at:\nhttps://github.com/flobk/TRIM",
      "tldr_zh": "该研究提出TRIM，一种针对大型语言模型(LLMs)的创新修剪方法，通过针对每个层内输出维度(行)应用不同的稀疏度比率，实现极端的模型压缩。TRIM采用迭代调整过程，由质量指标引导优化维度级稀疏度分配，减少质量保留的方差，从而保留关键信息，并可无缝整合到现有层级修剪策略中。在Qwen2.5、LLaMA-2和OPT等LLM家族的评估中，TRIM在各种稀疏度水平下实现了新的最先进结果，例如在80%稀疏度下，使Qwen2.5-14B的perplexity降低48%，OPT-13B降低超过90%。这项工作证明，细粒度的维度级稀疏度适应对于推动极端LLM压缩至关重要。",
      "categories": [
        "cs.CL",
        "cs.AI",
        "cs.LG",
        "I.2.7; I.2.6; F.2.2"
      ],
      "primary_category": "cs.CL",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2505.16743v1",
      "published_date": "2025-05-22 14:53:53 UTC",
      "updated_date": "2025-05-22 14:53:53 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-25T03:20:17.421078"
    },
    {
      "arxiv_id": "2505.16740v1",
      "title": "Robust Vision-Based Runway Detection through Conformal Prediction and Conformal mAP",
      "title_zh": "翻译失败",
      "authors": [
        "Alya Zouzou",
        "Léo andéol",
        "Mélanie Ducoffe",
        "Ryma Boumazouza"
      ],
      "abstract": "We explore the use of conformal prediction to provide statistical uncertainty\nguarantees for runway detection in vision-based landing systems (VLS). Using\nfine-tuned YOLOv5 and YOLOv6 models on aerial imagery, we apply conformal\nprediction to quantify localization reliability under user-defined risk levels.\nWe also introduce Conformal mean Average Precision (C-mAP), a novel metric\naligning object detection performance with conformal guarantees. Our results\nshow that conformal prediction can improve the reliability of runway detection\nby quantifying uncertainty in a statistically sound way, increasing safety\non-board and paving the way for certification of ML system in the aerospace\ndomain.",
      "tldr_zh": "本文研究了使用 conformal prediction 为视觉-based 着陆系统 (VLS) 中的跑道检测提供统计不确定性保证，基于 fine-tuned YOLOv5 和 YOLOv6 模型处理航空图像。作者引入了新的 Conformal mAP (C-mAP) 指标，以将对象检测性能与 conformal guarantees 相结合，量化定位的可靠性。实验结果表明，该方法显著提高了跑道检测的可靠性，增强了航空领域的安全，并为机器学习 (ML) 系统的认证铺平道路。",
      "categories": [
        "cs.CV",
        "cs.AI"
      ],
      "primary_category": "cs.CV",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2505.16740v1",
      "published_date": "2025-05-22 14:52:59 UTC",
      "updated_date": "2025-05-22 14:52:59 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-25T03:20:27.432262"
    },
    {
      "arxiv_id": "2505.16737v1",
      "title": "Mitigating Fine-tuning Risks in LLMs via Safety-Aware Probing Optimization",
      "title_zh": "翻译失败",
      "authors": [
        "Chengcan Wu",
        "Zhixin Zhang",
        "Zeming Wei",
        "Yihao Zhang",
        "Meng Sun"
      ],
      "abstract": "The significant progress of large language models (LLMs) has led to\nremarkable achievements across numerous applications. However, their ability to\ngenerate harmful content has sparked substantial safety concerns. Despite the\nimplementation of safety alignment techniques during the pre-training phase,\nrecent research indicates that fine-tuning LLMs on adversarial or even benign\ndata can inadvertently compromise their safety. In this paper, we re-examine\nthe fundamental issue of why fine-tuning on non-harmful data still results in\nsafety degradation. We introduce a safety-aware probing (SAP) optimization\nframework designed to mitigate the safety risks of fine-tuning LLMs.\nSpecifically, SAP incorporates a safety-aware probe into the gradient\npropagation process, mitigating the model's risk of safety degradation by\nidentifying potential pitfalls in gradient directions, thereby enhancing\ntask-specific performance while successfully preserving model safety. Our\nextensive experimental results demonstrate that SAP effectively reduces\nharmfulness below the original fine-tuned model and achieves comparable test\nloss to standard fine-tuning methods. Our code is available at\nhttps://github.com/ChengcanWu/SAP.",
      "tldr_zh": "大语言模型（LLMs）在微调过程中，即使使用非有害数据，也可能导致安全退化，生成有害内容的问题。本文重新审视这一根本问题，提出安全感知探测（Safety-Aware Probing, SAP）优化框架，通过在梯度传播中加入安全感知探针来识别和缓解梯度方向的潜在风险，从而提升任务特定性能同时保持模型安全性。实验结果显示，SAP 有效将模型有害性降低至低于原始微调水平，并与标准微调方法实现可比的测试损失。",
      "categories": [
        "cs.LG",
        "cs.AI",
        "cs.CL",
        "cs.CR",
        "math.OC"
      ],
      "primary_category": "cs.LG",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2505.16737v1",
      "published_date": "2025-05-22 14:52:10 UTC",
      "updated_date": "2025-05-22 14:52:10 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-25T03:20:39.762461"
    },
    {
      "arxiv_id": "2505.16735v1",
      "title": "Adversarial Deep Metric Learning for Cross-Modal Audio-Text Alignment in Open-Vocabulary Keyword Spotting",
      "title_zh": "翻译失败",
      "authors": [
        "Youngmoon Jung",
        "Yong-Hyeok Lee",
        "Myunghun Jung",
        "Jaeyoung Roh",
        "Chang Woo Han",
        "Hoon-Young Cho"
      ],
      "abstract": "For text enrollment-based open-vocabulary keyword spotting (KWS), acoustic\nand text embeddings are typically compared at either the phoneme or utterance\nlevel. To facilitate this, we optimize acoustic and text encoders using deep\nmetric learning (DML), enabling direct comparison of multi-modal embeddings in\na shared embedding space. However, the inherent heterogeneity between audio and\ntext modalities presents a significant challenge. To address this, we propose\nModality Adversarial Learning (MAL), which reduces the domain gap in\nheterogeneous modality representations. Specifically, we train a modality\nclassifier adversarially to encourage both encoders to generate\nmodality-invariant embeddings. Additionally, we apply DML to achieve\nphoneme-level alignment between audio and text, and conduct comprehensive\ncomparisons across various DML objectives. Experiments on the Wall Street\nJournal (WSJ) and LibriPhrase datasets demonstrate the effectiveness of the\nproposed approach.",
      "tldr_zh": "该论文针对开放词汇关键词检测（Open-Vocabulary Keyword Spotting）中的音频-文本跨模态对齐问题，提出了一种基于Adversarial Deep Metric Learning的方法，通过优化音频和文本编码器在共享嵌入空间中进行直接比较。核心创新是Modality Adversarial Learning (MAL)，它通过对抗训练模态分类器来减少音频和文本模态间的异质性，同时结合Deep Metric Learning (DML)实现音素级对齐，并评估多种DML目标。实验结果在Wall Street Journal (WSJ)和LibriPhrase数据集上证明了该方法的有效性，提升了跨模态嵌入的性能。",
      "categories": [
        "eess.AS",
        "cs.AI"
      ],
      "primary_category": "eess.AS",
      "comment": "5 pages, 1 figures, Accepted at Interspeech 2025",
      "pdf_url": "http://arxiv.org/pdf/2505.16735v1",
      "published_date": "2025-05-22 14:49:46 UTC",
      "updated_date": "2025-05-22 14:49:46 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-25T03:20:52.394779"
    },
    {
      "arxiv_id": "2505.16732v1",
      "title": "Sequential Monte Carlo for Policy Optimization in Continuous POMDPs",
      "title_zh": "顺序 Monte Carlo 用于连续 POMDPs 的策略优化",
      "authors": [
        "Hany Abdulsamad",
        "Sahel Iqbal",
        "Simo Särkkä"
      ],
      "abstract": "Optimal decision-making under partial observability requires agents to\nbalance reducing uncertainty (exploration) against pursuing immediate\nobjectives (exploitation). In this paper, we introduce a novel policy\noptimization framework for continuous partially observable Markov decision\nprocesses (POMDPs) that explicitly addresses this challenge. Our method casts\npolicy learning as probabilistic inference in a non-Markovian Feynman--Kac\nmodel that inherently captures the value of information gathering by\nanticipating future observations, without requiring extrinsic exploration\nbonuses or handcrafted heuristics. To optimize policies under this model, we\ndevelop a nested sequential Monte Carlo~(SMC) algorithm that efficiently\nestimates a history-dependent policy gradient under samples from the optimal\ntrajectory distribution induced by the POMDP. We demonstrate the effectiveness\nof our algorithm across standard continuous POMDP benchmarks, where existing\nmethods struggle to act under uncertainty.",
      "tldr_zh": "该论文提出了一种针对连续部分可观测马尔可夫决策过程（POMDPs）的策略优化框架，旨在平衡减少不确定性（探索）和追求即时目标（利用）。方法将策略学习转化为非马尔可夫 Feynman--Kac 模型中的概率推断，从而自然捕捉信息收集的价值，而无需外部探索奖励或手工启发式。作者开发了嵌套的 Sequential Monte Carlo (SMC) 算法，用于高效估计基于历史依赖的策略梯度，并在标准连续 POMDP 基准测试中证明了其有效性，显著优于现有方法在不确定性环境下的表现。",
      "categories": [
        "cs.LG",
        "cs.AI",
        "stat.ML"
      ],
      "primary_category": "cs.LG",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2505.16732v1",
      "published_date": "2025-05-22 14:45:46 UTC",
      "updated_date": "2025-05-22 14:45:46 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-25T03:21:04.580070"
    },
    {
      "arxiv_id": "2505.16724v1",
      "title": "Advancing Brainwave Modeling with a Codebook-Based Foundation Model",
      "title_zh": "翻译失败",
      "authors": [
        "Konstantinos Barmpas",
        "Na Lee",
        "Yannis Panagakis",
        "Dimitrios A. Adamos",
        "Nikolaos Laskaris",
        "Stefanos Zafeiriou"
      ],
      "abstract": "Recent advances in large-scale pre-trained Electroencephalogram (EEG) models\nhave shown great promise, driving progress in Brain-Computer Interfaces (BCIs)\nand healthcare applications. However, despite their success, many existing\npre-trained models have struggled to fully capture the rich information content\nof neural oscillations, a limitation that fundamentally constrains their\nperformance and generalizability across diverse BCI tasks. This limitation is\nfrequently rooted in suboptimal architectural design choices which constrain\ntheir representational capacity. In this work, we introduce LaBraM++, an\nenhanced Large Brainwave Foundation Model (LBM) that incorporates principled\nimprovements grounded in robust signal processing foundations. LaBraM++\ndemonstrates substantial gains across a variety of tasks, consistently\noutperforming its originally-based architecture and achieving competitive\nresults when compared to other open-source LBMs. Its superior performance and\ntraining efficiency highlight its potential as a strong foundation for future\nadvancements in LBMs.",
      "tldr_zh": "本研究指出了现有预训练 Electroencephalogram (EEG) 模型在捕捉神经振荡的丰富信息方面存在局限性，导致 Brain-Computer Interfaces (BCIs) 任务的性能和泛化能力受限。该文引入 LaBraM++，一个增强型 Large Brainwave Foundation Model (LBM)，通过基于稳健信号处理基础的架构改进，提升了模型的表示能力和训练效率。实验结果显示，LaBraM++ 在多种任务上显著超越原始架构，并与其他开源 LBMs 相比具有竞争力，为未来 BCI 和医疗应用的脑波建模奠定坚实基础。",
      "categories": [
        "cs.LG",
        "cs.AI",
        "cs.HC"
      ],
      "primary_category": "cs.LG",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2505.16724v1",
      "published_date": "2025-05-22 14:32:56 UTC",
      "updated_date": "2025-05-22 14:32:56 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-25T03:21:17.013173"
    },
    {
      "arxiv_id": "2505.16722v1",
      "title": "Breaking mBad! Supervised Fine-tuning for Cross-Lingual Detoxification",
      "title_zh": "翻译失败",
      "authors": [
        "Himanshu Beniwal",
        "Youngwoo Kim",
        "Maarten Sap",
        "Soham Dan",
        "Thomas Hartvigsen"
      ],
      "abstract": "As large language models (LLMs) become increasingly prevalent in global\napplications, ensuring that they are toxicity-free across diverse linguistic\ncontexts remains a critical challenge. We explore \"Cross-lingual\nDetoxification\", a cross-lingual paradigm that mitigates toxicity, enabling\ndetoxification capabilities to transfer between high and low-resource languages\nacross different script families. We analyze cross-lingual detoxification's\neffectiveness through 504 extensive settings to evaluate toxicity reduction in\ncross-distribution settings with limited data and investigate how mitigation\nimpacts model performance on non-toxic tasks, revealing trade-offs between\nsafety and knowledge preservation. Our code and dataset are publicly available\nat https://github.com/himanshubeniwal/Breaking-mBad.",
      "tldr_zh": "该研究探讨了大型语言模型（LLMs）在全球应用中实现跨语言无毒性的挑战，提出了一种基于Supervised Fine-tuning的“Cross-lingual Detoxification”范式，以实现高资源和低资源语言之间的高效毒性转移。研究通过504个广泛实验设置评估了这一方法在数据有限的跨分布环境中的毒性减少效果，并分析了去毒化对非毒性任务性能的影响，揭示了安全性和知识保留之间的权衡。代码和数据集已公开，供进一步研究使用。",
      "categories": [
        "cs.CL",
        "cs.AI"
      ],
      "primary_category": "cs.CL",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2505.16722v1",
      "published_date": "2025-05-22 14:30:14 UTC",
      "updated_date": "2025-05-22 14:30:14 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-25T03:21:28.093943"
    },
    {
      "arxiv_id": "2505.16710v1",
      "title": "Training Long-Context LLMs Efficiently via Chunk-wise Optimization",
      "title_zh": "翻译失败",
      "authors": [
        "Wenhao Li",
        "Yuxin Zhang",
        "Gen Luo",
        "Daohai Yu",
        "Rongrong Ji"
      ],
      "abstract": "While long-context large language models (LLMs) exhibit remarkable document\nprocessing capabilities, their prohibitively high training costs often hinder\ncustomized applications. To mitigate this issue, we propose \\textit{Sequential\nChunk-wise Optimization} (SeCO), a memory-efficient training paradigm that\npartitions lengthy inputs into manageable chunks. Each chunk independently\nconstructs its computational graph and performs localized backpropagation,\nensuring that only one chunk's forward activations are stored in memory.\nBuilding on SeCO, we further introduce \\textit{Sparse Chunk-wise Optimization}\n(SpaCO), which reduces computational overhead by selectively propagating\ngradients to specific chunks and incorporates a carefully designed compensation\nfactor to ensure unbiased gradient estimation. SpaCO decouples the\ncomputational cost of backpropagation from the context length, enabling\ntraining time to gradually converge to inference time as sequences become\nlonger. Implemented as lightweight training wrappers, both SeCO and SpaCO offer\nsubstantial practical benefits. For example, when fine-tuning an 8B model with\nLoRA on a single RTX 3090 GPU, SeCO expands maximum sequence length from 1K to\n16K tokens, while SpaCO demonstrates accelerated training speed -- achieving up\nto 3x faster than SeCO under the same experimental setup. These innovations\nprovide new insights into optimizing long-context models, making them more\naccessible for practical applications. We have open-sourced the code at\n\\href{https://github.com/wenhaoli-xmu/seco}{here}.",
      "tldr_zh": "该论文针对长上下文大语言模型（LLMs）的训练成本高问题，提出了一种内存高效的训练范式——Sequential Chunk-wise Optimization (SeCO)，它将长输入分成可管理块，每个块独立构建计算图并进行局部反向传播，仅存储一个块的前向激活，从而显著降低内存需求。基于 SeCO，该研究进一步引入 Sparse Chunk-wise Optimization (SpaCO)，通过选择性地传播梯度到特定块并使用补偿因子确保梯度估计无偏，使反向传播计算成本与上下文长度脱钩，实现训练速度接近推理速度。实验结果显示，在单 RTX 3090 GPU 上微调 8B 模型时，SeCO 将最大序列长度从 1K 扩展到 16K 标记，而 SpaCO 比 SeCO 快达 3 倍，这些创新使长上下文模型更易于实际应用，并已开源代码。",
      "categories": [
        "cs.LG",
        "cs.AI"
      ],
      "primary_category": "cs.LG",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2505.16710v1",
      "published_date": "2025-05-22 14:11:34 UTC",
      "updated_date": "2025-05-22 14:11:34 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-25T03:21:41.046701"
    },
    {
      "arxiv_id": "2505.16705v1",
      "title": "An Analysis of Concept Bottleneck Models: Measuring, Understanding, and Mitigating the Impact of Noisy Annotations",
      "title_zh": "概念瓶颈模型的分析：测量、理解和缓解噪声标注的影响",
      "authors": [
        "Seonghwan Park",
        "Jueun Mun",
        "Donghyun Oh",
        "Namhoon Lee"
      ],
      "abstract": "Concept bottleneck models (CBMs) ensure interpretability by decomposing\npredictions into human interpretable concepts. Yet the annotations used for\ntraining CBMs that enable this transparency are often noisy, and the impact of\nsuch corruption is not well understood. In this study, we present the first\nsystematic study of noise in CBMs and show that even moderate corruption\nsimultaneously impairs prediction performance, interpretability, and the\nintervention effectiveness. Our analysis identifies a susceptible subset of\nconcepts whose accuracy declines far more than the average gap between noisy\nand clean supervision and whose corruption accounts for most performance loss.\nTo mitigate this vulnerability we propose a two-stage framework. During\ntraining, sharpness-aware minimization stabilizes the learning of\nnoise-sensitive concepts. During inference, where clean labels are unavailable,\nwe rank concepts by predictive entropy and correct only the most uncertain\nones, using uncertainty as a proxy for susceptibility. Theoretical analysis and\nextensive ablations elucidate why sharpness-aware training confers robustness\nand why uncertainty reliably identifies susceptible concepts, providing a\nprincipled basis that preserves both interpretability and resilience in the\npresence of noise.",
      "tldr_zh": "本文分析了概念瓶颈模型(CBMs)中噪声标注的影响，发现即使中等噪声会同时降低预测性能、可解释性和干预效果，并识别出易受影响的概念子集，这些概念的准确性下降幅度远大于平均水平。针对这一问题，研究提出一个两阶段框架：在训练阶段使用sharpness-aware minimization稳定噪声敏感概念的学习；在推理阶段，通过预测熵排名并修正最不确定概念，将不确定性作为易感性的代理。理论分析和广泛实验验证了该框架的鲁棒性，帮助CBMs在噪声环境下保持可解释性和弹性。",
      "categories": [
        "cs.LG",
        "cs.AI"
      ],
      "primary_category": "cs.LG",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2505.16705v1",
      "published_date": "2025-05-22 14:06:55 UTC",
      "updated_date": "2025-05-22 14:06:55 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-25T03:21:53.256827"
    },
    {
      "arxiv_id": "2505.16700v1",
      "title": "MCP-RADAR: A Multi-Dimensional Benchmark for Evaluating Tool Use Capabilities in Large Language Models",
      "title_zh": "MCP-RADAR：用于评估大型语言模型工具使用能力的多维基准",
      "authors": [
        "Xuanqi Gao",
        "Siyi Xie",
        "Juan Zhai",
        "Shqing Ma",
        "Chao Shen"
      ],
      "abstract": "As Large Language Models (LLMs) evolve from passive text generators to active\nreasoning agents capable of tool interaction, the Model Context Protocol (MCP)\nhas emerged as a standardized framework for dynamic tool discovery and\norchestration. Despite widespread industry adoption, existing evaluation\nmethodologies fail to adequately assess tool utilization capabilities within\nthis new paradigm. This paper introduces MCP-RADAR, the first comprehensive\nbenchmark specifically designed to evaluate LLM performance in the MCP\nframework through a novel five-dimensional approach measuring: answer accuracy,\ntool selection efficiency, computational resource efficiency, parameter\nconstruction accuracy, and execution speed. Unlike conventional benchmarks that\nrely on subjective human evaluations or binary success metrics, MCP-RADAR\nemploys objective, quantifiable measurements across multiple task domains\nincluding software engineering, mathematical reasoning, and general\nproblem-solving. Our evaluations of leading commercial and open-source LLMs\nreveal distinctive capability profiles with significant trade-offs between\naccuracy, efficiency, and speed, challenging traditional single-metric\nperformance rankings. Besides, we provide valuable guidance for developers to\noptimize their tools for maximum model compatibility and effectiveness. While\nfocused on MCP due to its standardized approach, our methodology remains\napplicable across all LLM agent tool integration frameworks, providing valuable\ninsights for both LLM developers and tool creators to optimize the entire\nLLM-tool interaction ecosystem. The implementation, configurations, and\ndatasets used in our evaluation are publicly available at\nhttps://anonymous.4open.science/r/MCPRadar-B143.",
      "tldr_zh": "本论文引入了 MCP-RADAR，这是一个多维基准，用于评估大型语言模型 (LLMs) 在 Model Context Protocol (MCP) 框架下的工具使用能力，通过五个维度（答案准确性、工具选择效率、计算资源效率、参数构建准确性以及执行速度）进行客观量化评估。不同于传统基准的单一或主观指标，MCP-RADAR 覆盖软件工程、数学推理和一般问题解决等领域，并对领先的商业和开源 LLMs 进行评估，揭示了模型在准确性、效率和速度之间的显著权衡。研究结果挑战了传统性能排名，并为 LLMs 开发者提供优化工具兼容性的指导，所有实现和数据集已在 https://anonymous.4open.science/r/MCPRadar-B143 公开。",
      "categories": [
        "cs.AI"
      ],
      "primary_category": "cs.AI",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2505.16700v1",
      "published_date": "2025-05-22 14:02:37 UTC",
      "updated_date": "2025-05-22 14:02:37 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-25T03:22:05.594221"
    },
    {
      "arxiv_id": "2505.16694v1",
      "title": "Beyond Induction Heads: In-Context Meta Learning Induces Multi-Phase Circuit Emergence",
      "title_zh": "翻译失败",
      "authors": [
        "Gouki Minegishi",
        "Hiroki Furuta",
        "Shohei Taniguchi",
        "Yusuke Iwasawa",
        "Yutaka Matsuo"
      ],
      "abstract": "Transformer-based language models exhibit In-Context Learning (ICL), where\npredictions are made adaptively based on context. While prior work links\ninduction heads to ICL through a sudden jump in accuracy, this can only account\nfor ICL when the answer is included within the context. However, an important\nproperty of practical ICL in large language models is the ability to meta-learn\nhow to solve tasks from context, rather than just copying answers from context;\nhow such an ability is obtained during training is largely unexplored. In this\npaper, we experimentally clarify how such meta-learning ability is acquired by\nanalyzing the dynamics of the model's circuit during training. Specifically, we\nextend the copy task from previous research into an In-Context Meta Learning\nsetting, where models must infer a task from examples to answer queries.\nInterestingly, in this setting, we find that there are multiple phases in the\nprocess of acquiring such abilities, and that a unique circuit emerges in each\nphase, contrasting with the single-phases change in induction heads. The\nemergence of such circuits can be related to several phenomena known in large\nlanguage models, and our analysis lead to a deeper understanding of the source\nof the transformer's ICL ability.",
      "tldr_zh": "这篇论文探讨了Transformer模型的In-Context Learning (ICL)能力，超越了induction heads的单一阶段理论，揭示了如何通过meta-learning从上下文中推断任务而非简单复制答案。研究者扩展了之前的copy task到In-Context Meta Learning设置，并分析了模型电路的动态过程，发现这种能力涉及多个阶段，每个阶段都会出现独特的电路。结果表明，这些多阶段电路的出现与大型语言模型的已知现象相关联，并加深了对Transformer ICL能力的理解。",
      "categories": [
        "cs.CL",
        "cs.AI"
      ],
      "primary_category": "cs.CL",
      "comment": "Accepted to ICML 2025",
      "pdf_url": "http://arxiv.org/pdf/2505.16694v1",
      "published_date": "2025-05-22 13:59:30 UTC",
      "updated_date": "2025-05-22 13:59:30 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-25T03:22:17.649394"
    },
    {
      "arxiv_id": "2505.16691v1",
      "title": "EZ-VC: Easy Zero-shot Any-to-Any Voice Conversion",
      "title_zh": "翻译失败",
      "authors": [
        "Advait Joglekar",
        "Divyanshu Singh",
        "Rooshil Rohit Bhatia",
        "S. Umesh"
      ],
      "abstract": "Voice Conversion research in recent times has increasingly focused on\nimproving the zero-shot capabilities of existing methods. Despite remarkable\nadvancements, current architectures still tend to struggle in zero-shot\ncross-lingual settings. They are also often unable to generalize for speakers\nof unseen languages and accents. In this paper, we adopt a simple yet effective\napproach that combines discrete speech representations from self-supervised\nmodels with a non-autoregressive Diffusion-Transformer based conditional flow\nmatching speech decoder. We show that this architecture allows us to train a\nvoice-conversion model in a purely textless, self-supervised fashion. Our\ntechnique works without requiring multiple encoders to disentangle speech\nfeatures. Our model also manages to excel in zero-shot cross-lingual settings\neven for unseen languages.",
      "tldr_zh": "这篇论文针对语音转换（Voice Conversion）中的零样本（zero-shot）能力问题，指出现有方法在跨语言场景下难以泛化，尤其对未见语言和口音的处理。该研究提出EZ-VC框架，使用自监督模型的离散语音表示（discrete speech representations）结合非自回归的Diffusion-Transformer基于条件流匹配的语音解码器（non-autoregressive Diffusion-Transformer based conditional flow matching speech decoder），实现纯文本less的自监督训练，且无需多个编码器来分离语音特征。实验结果显示，该模型在零样本跨语言设置中表现出色，即使面对未见语言，也能有效转换语音。",
      "categories": [
        "cs.SD",
        "cs.AI",
        "eess.AS"
      ],
      "primary_category": "cs.SD",
      "comment": "Submitted to EMNLP 2025, 7 pages, 2 figures, 5 Tables",
      "pdf_url": "http://arxiv.org/pdf/2505.16691v1",
      "published_date": "2025-05-22 13:57:02 UTC",
      "updated_date": "2025-05-22 13:57:02 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-25T03:22:28.469305"
    },
    {
      "arxiv_id": "2505.16690v1",
      "title": "Your Pre-trained LLM is Secretly an Unsupervised Confidence Calibrator",
      "title_zh": "翻译失败",
      "authors": [
        "Beier Luo",
        "Shuoyuan Wang",
        "Yixuan Li",
        "Hongxin Wei"
      ],
      "abstract": "Post-training of large language models is essential for adapting pre-trained\nlanguage models (PLMs) to align with human preferences and downstream tasks.\nWhile PLMs typically exhibit well-calibrated confidence, post-trained language\nmodels (PoLMs) often suffer from over-confidence, assigning high confidence to\nboth correct and incorrect outputs, which can undermine reliability in critical\napplications. A major obstacle in calibrating PoLMs is the scarcity of labeled\ndata for individual downstream tasks. To address this, we propose\nDisagreement-Aware Confidence Alignment (DACA), a novel unsupervised method to\noptimize the parameters (e.g., temperature $\\tau$) in post-hoc confidence\ncalibration. Our method is motivated by the under-confidence issue caused by\nprediction disagreement between the PLM and PoLM while aligning their\nconfidence via temperature scaling. Theoretically, the PLM's confidence\nunderestimates PoLM's prediction accuracy on disagreement examples, causing a\nlarger $\\tau$ and producing under-confident predictions. DACA mitigates this by\nselectively using only agreement examples for calibration, effectively\ndecoupling the influence of disagreement. In this manner, our method avoids an\noverly large $\\tau$ in temperature scaling caused by disagreement examples,\nimproving calibration performance. Extensive experiments demonstrate the\neffectiveness of our method, improving the average ECE of open-sourced and\nAPI-based LLMs (e.g. GPT-4o) by up to 15.08$\\%$ on common benchmarks.",
      "tldr_zh": "该研究揭示了预训练语言模型(PLMs)可以作为无监督的自信心校准器，而后训练语言模型(PoLMs)常因过度自信导致可靠性问题。作者提出Disagreement-Aware Confidence Alignment (DACA)，一种无监督方法，通过仅使用PLM和PoLM预测一致的样本来优化温度参数τ，从而避免分歧样本干扰并改善自信心校准。实验结果显示，DACA在常见基准上将开源和API-based LLMs（如GPT-4o）的平均ECE降低了高达15.08%。",
      "categories": [
        "cs.LG",
        "cs.AI"
      ],
      "primary_category": "cs.LG",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2505.16690v1",
      "published_date": "2025-05-22 13:55:39 UTC",
      "updated_date": "2025-05-22 13:55:39 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-25T03:22:41.449147"
    },
    {
      "arxiv_id": "2505.16686v1",
      "title": "SPaRC: A Spatial Pathfinding Reasoning Challenge",
      "title_zh": "SPaRC：空间路径规划推理挑战",
      "authors": [
        "Lars Benedikt Kaesberg",
        "Jan Philip Wahle",
        "Terry Ruas",
        "Bela Gipp"
      ],
      "abstract": "Existing reasoning datasets saturate and fail to test abstract, multi-step\nproblems, especially pathfinding and complex rule constraint satisfaction. We\nintroduce SPaRC (Spatial Pathfinding Reasoning Challenge), a dataset of 1,000\n2D grid pathfinding puzzles to evaluate spatial and symbolic reasoning,\nrequiring step-by-step planning with arithmetic and geometric rules. Humans\nachieve near-perfect accuracy (98.0%; 94.5% on hard puzzles), while the best\nreasoning models, such as o4-mini, struggle (15.8%; 1.1% on hard puzzles).\nModels often generate invalid paths (>50% of puzzles for o4-mini), and\nreasoning tokens reveal they make errors in navigation and spatial logic.\nUnlike humans, who take longer on hard puzzles, models fail to scale test-time\ncompute with difficulty. Allowing models to make multiple solution attempts\nimproves accuracy, suggesting potential for better spatial reasoning with\nimproved training and efficient test-time scaling methods. SPaRC can be used as\na window into models' spatial reasoning limitations and drive research toward\nnew methods that excel in abstract, multi-step problem-solving.",
      "tldr_zh": "本研究引入了 SPaRC 数据集，这是一个包含 1,000 个 2D grid pathfinding puzzles 的挑战，用于评估模型的空间和符号推理能力，这些谜题需要逐步规划并涉及 arithmetic 和 geometric rules。人类在该数据集上表现出色，准确率达到 98.0%（硬谜题 94.5%），而顶级模型如 o4-mini 仅为 15.8%（硬谜题 1.1%），且经常生成无效路径并在 navigation 和 spatial logic 上出错。与人类不同，模型无法根据难度调整 test-time compute，但允许多次尝试可显著提升准确率。SPaRC 作为评估工具，能揭示模型的空间推理限制，并推动开发更高效的抽象多步问题解决方法。",
      "categories": [
        "cs.AI",
        "cs.CL"
      ],
      "primary_category": "cs.AI",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2505.16686v1",
      "published_date": "2025-05-22 13:53:50 UTC",
      "updated_date": "2025-05-22 13:53:50 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-25T03:22:53.667070"
    },
    {
      "arxiv_id": "2505.16679v1",
      "title": "Semantic Compression of 3D Objects for Open and Collaborative Virtual Worlds",
      "title_zh": "翻译失败",
      "authors": [
        "Jordan Dotzel",
        "Tony Montes",
        "Mohamed S. Abdelfattah",
        "Zhiru Zhang"
      ],
      "abstract": "Traditional methods for 3D object compression operate only on structural\ninformation within the object vertices, polygons, and textures. These methods\nare effective at compression rates up to 10x for standard object sizes but\nquickly deteriorate at higher compression rates with texture artifacts,\nlow-polygon counts, and mesh gaps. In contrast, semantic compression ignores\nstructural information and operates directly on the core concepts to push to\nextreme levels of compression. In addition, it uses natural language as its\nstorage format, which makes it natively human-readable and a natural fit for\nemerging applications built around large-scale, collaborative projects within\naugmented and virtual reality. It deprioritizes structural information like\nlocation, size, and orientation and predicts the missing information with\nstate-of-the-art deep generative models. In this work, we construct a pipeline\nfor 3D semantic compression from public generative models and explore the\nquality-compression frontier for 3D object compression. We apply this pipeline\nto achieve rates as high as 105x for 3D objects taken from the Objaverse\ndataset and show that semantic compression can outperform traditional methods\nin the important quality-preserving region around 100x compression.",
      "tldr_zh": "本文提出了一种语义压缩（semantic compression）方法，用于3D对象的压缩，忽略结构信息（如顶点和纹理）而直接操作核心概念，从而实现高达105倍的压缩率，并使用自然语言作为存储格式，便于人类阅读和协作。该方法通过state-of-the-art deep generative models预测缺失的结构信息，如位置和大小，并构建了一个基于公共生成模型的管道，适用于增强现实（AR）和虚拟现实（VR）的开放协作环境。与传统方法相比，实验在Objaverse数据集上显示，semantic compression在质量保留区域（如100倍压缩附近）表现出色，显著减少了纹理 artifacts 和网格问题。",
      "categories": [
        "cs.CV",
        "cs.AI"
      ],
      "primary_category": "cs.CV",
      "comment": "First two authors have equal contribution",
      "pdf_url": "http://arxiv.org/pdf/2505.16679v1",
      "published_date": "2025-05-22 13:45:35 UTC",
      "updated_date": "2025-05-22 13:45:35 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-25T03:23:04.435346"
    },
    {
      "arxiv_id": "2505.16673v1",
      "title": "R1-ShareVL: Incentivizing Reasoning Capability of Multimodal Large Language Models via Share-GRPO",
      "title_zh": "R1-ShareVL：通过 Share-GRPO 激励多模态大语言模型的推理能力",
      "authors": [
        "Huanjin Yao",
        "Qixiang Yin",
        "Jingyi Zhang",
        "Min Yang",
        "Yibo Wang",
        "Wenhao Wu",
        "Fei Su",
        "Li Shen",
        "Minghui Qiu",
        "Dacheng Tao",
        "Jiaxing Huang"
      ],
      "abstract": "In this work, we aim to incentivize the reasoning ability of Multimodal Large\nLanguage Models (MLLMs) via reinforcement learning (RL) and develop an\neffective approach that mitigates the sparse reward and advantage vanishing\nissues during RL. To this end, we propose Share-GRPO, a novel RL approach that\ntackle these issues by exploring and sharing diverse reasoning trajectories\nover expanded question space. Specifically, Share-GRPO first expands the\nquestion space for a given question via data transformation techniques, and\nthen encourages MLLM to effectively explore diverse reasoning trajectories over\nthe expanded question space and shares the discovered reasoning trajectories\nacross the expanded questions during RL. In addition, Share-GRPO also shares\nreward information during advantage computation, which estimates solution\nadvantages hierarchically across and within question variants, allowing more\naccurate estimation of relative advantages and improving the stability of\npolicy training. Extensive evaluations over six widely-used reasoning\nbenchmarks showcase the superior performance of our method. Code will be\navailable at https://github.com/HJYao00/R1-ShareVL.",
      "tldr_zh": "本研究旨在通过强化学习（RL）提升多模态大语言模型（MLLMs）的推理能力，并提出 Share-GRPO 方法来解决 RL 中的稀疏奖励和优势消失问题。Share-GRPO 通过数据转换技术扩展问题空间，鼓励 MLLMs 探索并共享多样化的推理轨迹，并在优势计算中层次化共享奖励信息，以更准确地估计相对优势并稳定策略训练。在六个广泛使用的推理基准上，Share-GRPO 展示了优越性能，代码将在 GitHub 上发布。",
      "categories": [
        "cs.CV",
        "cs.AI",
        "cs.CL"
      ],
      "primary_category": "cs.CV",
      "comment": "Technical report",
      "pdf_url": "http://arxiv.org/pdf/2505.16673v1",
      "published_date": "2025-05-22 13:39:32 UTC",
      "updated_date": "2025-05-22 13:39:32 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-25T03:23:15.043830"
    },
    {
      "arxiv_id": "2505.16670v1",
      "title": "BitHydra: Towards Bit-flip Inference Cost Attack against Large Language Models",
      "title_zh": "翻译失败",
      "authors": [
        "Xiaobei Yan",
        "Yiming Li",
        "Zhaoxin Fan",
        "Han Qiu",
        "Tianwei Zhang"
      ],
      "abstract": "Large language models (LLMs) have shown impressive capabilities across a wide\nrange of applications, but their ever-increasing size and resource demands make\nthem vulnerable to inference cost attacks, where attackers induce victim LLMs\nto generate the longest possible output content. In this paper, we revisit\nexisting inference cost attacks and reveal that these methods can hardly\nproduce large-scale malicious effects since they are self-targeting, where\nattackers are also the users and therefore have to execute attacks solely\nthrough the inputs, whose generated content will be charged by LLMs and can\nonly directly influence themselves. Motivated by these findings, this paper\nintroduces a new type of inference cost attacks (dubbed 'bit-flip inference\ncost attack') that target the victim model itself rather than its inputs.\nSpecifically, we design a simple yet effective method (dubbed 'BitHydra') to\neffectively flip critical bits of model parameters. This process is guided by a\nloss function designed to suppress <EOS> token's probability with an efficient\ncritical bit search algorithm, thus explicitly defining the attack objective\nand enabling effective optimization. We evaluate our method on 11 LLMs ranging\nfrom 1.5B to 14B parameters under both int8 and float16 settings. Experimental\nresults demonstrate that with just 4 search samples and as few as 3 bit flips,\nBitHydra can force 100% of test prompts to reach the maximum generation length\n(e.g., 2048 tokens) on representative LLMs such as LLaMA3, highlighting its\nefficiency, scalability, and strong transferability across unseen inputs.",
      "tldr_zh": "这篇论文揭示了现有推理成本攻击的局限性，即它们是自我针对的，无法产生大规模恶意效果，并提出了一种新的 bit-flip inference cost attack，针对大型语言模型(LLMs)的参数本身。研究设计了 BitHydra 方法，通过高效的关键位搜索算法和一个抑制 <EOS> token 概率的损失函数，来翻转模型参数的关键位，从而强制模型生成最长输出内容。在实验中，BitHydra 在 11 个从 1.5B 到 14B 参数的 LLMs 上表现出色，仅需 4 个搜索样本和少至 3 个位翻转，就能使 100% 的测试提示达到最大生成长度（如 2048 tokens），证明了其高效性、可扩展性和转移性。",
      "categories": [
        "cs.CR",
        "cs.AI"
      ],
      "primary_category": "cs.CR",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2505.16670v1",
      "published_date": "2025-05-22 13:36:00 UTC",
      "updated_date": "2025-05-22 13:36:00 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-25T03:23:29.193459"
    },
    {
      "arxiv_id": "2505.16667v1",
      "title": "ELABORATION: A Comprehensive Benchmark on Human-LLM Competitive Programming",
      "title_zh": "翻译失败",
      "authors": [
        "Xinwei Yang",
        "Zhaofeng Liu",
        "Chen Huang",
        "Jiashuai Zhang",
        "Tong Zhang",
        "Yifan Zhang",
        "Wenqiang Lei"
      ],
      "abstract": "While recent research increasingly emphasizes the value of human-LLM\ncollaboration in competitive programming and proposes numerous empirical\nmethods, a comprehensive understanding remains elusive due to the fragmented\nnature of existing studies and their use of diverse, application-specific human\nfeedback. Thus, our work serves a three-fold purpose: First, we present the\nfirst taxonomy of human feedback consolidating the entire programming process,\nwhich promotes fine-grained evaluation. Second, we introduce ELABORATIONSET, a\nnovel programming dataset specifically designed for human-LLM collaboration,\nmeticulously annotated to enable large-scale simulated human feedback and\nfacilitate costeffective real human interaction studies. Third, we introduce\nELABORATION, a novel benchmark to facilitate a thorough assessment of human-LLM\ncompetitive programming. With ELABORATION, we pinpoint strengthes and\nweaknesses of existing methods, thereby setting the foundation for future\nimprovement. Our code and dataset are available at\nhttps://github.com/SCUNLP/ELABORATION",
      "tldr_zh": "本研究针对人类与大型语言模型(LLM)在竞争性编程中的合作问题，提出了首个整合整个编程过程的人类反馈分类法(taxonomy)，以实现细粒度评估。论文引入了ELABORATIONSET，一种专为人类-LLM 协作设计的新数据集，通过 meticulous 标注支持大规模模拟人类反馈和成本有效的真实互动研究。同时，作者开发了ELABORATION基准，用于全面评估现有方法，识别其优势和劣势，为未来改进奠定基础。该基准及其代码已在GitHub上公开。",
      "categories": [
        "cs.AI"
      ],
      "primary_category": "cs.AI",
      "comment": "ACL 2025 Main. Our code and dataset are available at\n  https://github.com/SCUNLP/ELABORATION",
      "pdf_url": "http://arxiv.org/pdf/2505.16667v1",
      "published_date": "2025-05-22 13:32:39 UTC",
      "updated_date": "2025-05-22 13:32:39 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-25T03:23:41.797931"
    },
    {
      "arxiv_id": "2505.16664v1",
      "title": "End-to-End Framework for Predicting the Remaining Useful Life of Lithium-Ion Batteries",
      "title_zh": "锂离子电池剩余有用寿命预测的端到端框架",
      "authors": [
        "Khoa Tran",
        "Tri Le",
        "Bao Huynh",
        "Hung-Cuong Trinh",
        "Vy-Rin Nguyen"
      ],
      "abstract": "Accurate prediction of the Remaining Useful Life (RUL) is essential for\nenabling timely maintenance of lithium-ion batteries, impacting the operational\nefficiency of electric applications that rely on them. This paper proposes a\nRUL prediction approach that leverages data from recent charge-discharge cycles\nto estimate the number of remaining usable cycles. The approach introduces both\na novel signal processing pipeline and a deep learning prediction model. In the\nsignal preprocessing pipeline, a derived capacity feature is computed based on\ncurrent and capacity signals. Alongside original capacity, voltage and current,\nthese features are denoised and enhanced using statistical metrics and a\ndelta-based method to capture differences between the current and previous\ncycles. In the prediction model, the processed features are then fed into a\nhybrid deep learning architecture composed of 1D Convolutional Neural Networks\n(CNN), Attentional Long Short-Term Memory (A-LSTM), and Ordinary Differential\nEquation-based LSTM (ODE-LSTM) modules. This architecture is designed to\ncapture both local signal characteristics and long-range temporal dependencies\nwhile modeling the continuous-time dynamics of battery degradation. The model\nis further evaluated using transfer learning across different learning\nstrategies and target data partitioning scenarios. Results indicate that the\nmodel maintains robust performance, even when fine-tuned on limited target\ndata. Experimental results on two publicly available large-scale datasets\ndemonstrate that the proposed method outperforms a baseline deep learning\napproach and machine learning techniques, achieving an RMSE of 101.59,\nhighlighting its strong potential for real-world RUL prediction applications.",
      "tldr_zh": "本文提出了一种端到端的框架，用于预测锂离子电池的剩余可用寿命 (RUL)，通过利用最近的充放电周期数据来实现精确估计。该框架包括一个新型信号处理管道，对容量、电压和电流信号进行去噪和增强，并计算派生容量特征；随后，使用混合深度学习模型（结合 1D CNN、A-LSTM 和 ODE-LSTM）捕捉局部信号特征、长程时序依赖以及电池退化的连续时间动态。实验结果显示，该方法在两个公开大型数据集上优于基线深度学习和机器学习技术，RMSE 达到 101.59，且通过转移学习保持了鲁棒性能，即使在有限目标数据上微调也能有效。",
      "categories": [
        "cs.LG",
        "cs.AI"
      ],
      "primary_category": "cs.LG",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2505.16664v1",
      "published_date": "2025-05-22 13:28:18 UTC",
      "updated_date": "2025-05-22 13:28:18 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-25T03:23:54.747161"
    },
    {
      "arxiv_id": "2505.16660v1",
      "title": "Can reasoning models comprehend mathematical problems in Chinese ancient texts? An empirical study based on data from Suanjing Shishu",
      "title_zh": "翻译失败",
      "authors": [
        "Liu Chang",
        "Wang Dongbo",
        "Liu liu",
        "Zhao Zhixiao"
      ],
      "abstract": "This study addresses the challenges in intelligent processing of Chinese\nancient mathematical classics by constructing Guji_MATH, a benchmark for\nevaluating classical texts based on Suanjing Shishu. It systematically assesses\nthe mathematical problem-solving capabilities of mainstream reasoning models\nunder the unique linguistic constraints of classical Chinese. Through\nmachine-assisted annotation and manual verification, 538 mathematical problems\nwere extracted from 8 canonical texts, forming a structured dataset centered on\nthe \"Question-Answer-Solution\" framework, supplemented by problem types and\ndifficulty levels. Dual evaluation modes--closed-book (autonomous\nproblem-solving) and open-book (reproducing classical solution methods)--were\ndesigned to evaluate the performance of six reasoning models on ancient Chinese\nmathematical problems. Results indicate that reasoning models can partially\ncomprehend and solve these problems, yet their overall performance remains\ninferior to benchmarks on modern mathematical tasks. Enhancing models'\nclassical Chinese comprehension and cultural knowledge should be prioritized\nfor optimization. This study provides methodological support for mining\nmathematical knowledge from ancient texts and disseminating traditional\nculture, while offering new perspectives for evaluating cross-linguistic and\ncross-cultural capabilities of reasoning models.",
      "tldr_zh": "这篇论文构建了Guji_MATH基准数据集，基于中国古代数学经典《算经十书》，以评估主流reasoning models在古典中文数学问题下的解决能力。研究团队通过机器辅助标注和手动验证，从8本经典文本中提取了538个数学问题，形成以“Question-Answer-Solution”框架为核心的结构化数据集，并设计了闭卷（自主解决问题）和开卷（重现古典解法）两种评估模式。结果显示，六种reasoning models能部分理解和解决这些问题，但整体性能远低于现代数学任务的基准水平。论文建议优先优化模型的古典中文理解和文化知识，为从古代文本中挖掘数学知识、传播传统文化以及评估模型的跨语言和跨文化能力提供新方法支持。",
      "categories": [
        "cs.CL",
        "cs.AI"
      ],
      "primary_category": "cs.CL",
      "comment": "29pages, 7 figures",
      "pdf_url": "http://arxiv.org/pdf/2505.16660v1",
      "published_date": "2025-05-22 13:24:52 UTC",
      "updated_date": "2025-05-22 13:24:52 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-25T03:24:06.749468"
    },
    {
      "arxiv_id": "2505.16648v1",
      "title": "Collaboration among Multiple Large Language Models for Medical Question Answering",
      "title_zh": "翻译失败",
      "authors": [
        "Kexin Shang",
        "Chia-Hsuan Chang",
        "Christopher C. Yang"
      ],
      "abstract": "Empowered by vast internal knowledge reservoir, the new generation of large\nlanguage models (LLMs) demonstrate untapped potential to tackle medical tasks.\nHowever, there is insufficient effort made towards summoning up a synergic\neffect from multiple LLMs' expertise and background. In this study, we propose\na multi-LLM collaboration framework tailored on a medical multiple-choice\nquestions dataset. Through post-hoc analysis on 3 pre-trained LLM participants,\nour framework is proved to boost all LLMs reasoning ability as well as\nalleviate their divergence among questions. We also measure an LLM's confidence\nwhen it confronts with adversary opinions from other LLMs and observe a\nconcurrence between LLM's confidence and prediction accuracy.",
      "tldr_zh": "本研究提出了一种多-LLM 协作框架，旨在利用多个大型语言模型（LLMs）的专业知识来提升医疗问答任务的性能。该框架针对医疗多选题数据集，通过后验分析对三个预训练 LLM 参与者进行协作，显著提高了它们的推理能力并缓解了在问题上的分歧。同时，研究发现，LLM 在面对其他模型的反对意见时，其自信度与预测准确率呈正相关关系。",
      "categories": [
        "cs.CL",
        "cs.AI"
      ],
      "primary_category": "cs.CL",
      "comment": "Accepted to IEEE International Conference on Healthcare Informatics\n  2025",
      "pdf_url": "http://arxiv.org/pdf/2505.16648v1",
      "published_date": "2025-05-22 13:18:45 UTC",
      "updated_date": "2025-05-22 13:18:45 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-25T03:24:16.688013"
    },
    {
      "arxiv_id": "2505.16647v1",
      "title": "Point, Detect, Count: Multi-Task Medical Image Understanding with Instruction-Tuned Vision-Language Models",
      "title_zh": "点选、检测、计数：使用指令微调视觉语言",
      "authors": [
        "Sushant Gautam",
        "Michael A. Riegler",
        "Pål Halvorsen"
      ],
      "abstract": "We investigate fine-tuning Vision-Language Models (VLMs) for multi-task\nmedical image understanding, focusing on detection, localization, and counting\nof findings in medical images. Our objective is to evaluate whether\ninstruction-tuned VLMs can simultaneously improve these tasks, with the goal of\nenhancing diagnostic accuracy and efficiency. Using MedMultiPoints, a\nmultimodal dataset with annotations from endoscopy (polyps and instruments) and\nmicroscopy (sperm cells), we reformulate each task into instruction-based\nprompts suitable for vision-language reasoning. We fine-tune\nQwen2.5-VL-7B-Instruct using Low-Rank Adaptation (LoRA) across multiple task\ncombinations. Results show that multi-task training improves robustness and\naccuracy. For example, it reduces the Count Mean Absolute Error (MAE) and\nincreases Matching Accuracy in the Counting + Pointing task. However,\ntrade-offs emerge, such as more zero-case point predictions, indicating reduced\nreliability in edge cases despite overall performance gains. Our study\nhighlights the potential of adapting general-purpose VLMs to specialized\nmedical tasks via prompt-driven fine-tuning. This approach mirrors clinical\nworkflows, where radiologists simultaneously localize, count, and describe\nfindings - demonstrating how VLMs can learn composite diagnostic reasoning\npatterns. The model produces interpretable, structured outputs, offering a\npromising step toward explainable and versatile medical AI. Code, model\nweights, and scripts will be released for reproducibility at\nhttps://github.com/simula/PointDetectCount.",
      "tldr_zh": "本研究探讨了通过指令调优的视觉语言模型(VLMs)实现多任务医疗图像理解，包括检测、定位和计数，以提升诊断准确性和效率。研究者使用MedMultiPoints数据集（涵盖内镜息肉、仪器和显微镜精子细胞的注释），将任务转化为基于指令的提示，并对Qwen2.5-VL-7B-Instruct模型进行Low-Rank Adaptation (LoRA)多任务细调。结果显示，多任务训练显著提高了鲁棒性和准确性，例如降低了Count Mean Absolute Error (MAE)并提升了Matching Accuracy，但也存在权衡，如增加了零例点预测导致边缘情况可靠性下降。该方法模仿临床工作流，提供可解释的结构化输出，推动了通用VLMs在医疗AI中的应用潜力。",
      "categories": [
        "cs.CV",
        "cs.AI",
        "68T45, 68T07",
        "I.2.10; I.4.8"
      ],
      "primary_category": "cs.CV",
      "comment": "Accepted as a full paper at the 38th IEEE International Symposium on\n  Computer-Based Medical Systems (CBMS) 2025",
      "pdf_url": "http://arxiv.org/pdf/2505.16647v1",
      "published_date": "2025-05-22 13:18:44 UTC",
      "updated_date": "2025-05-22 13:18:44 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-25T03:24:30.410980"
    },
    {
      "arxiv_id": "2505.16646v1",
      "title": "SMART: Self-Generating and Self-Validating Multi-Dimensional Assessment for LLMs' Mathematical Problem Solving",
      "title_zh": "翻译失败",
      "authors": [
        "Yujie Hou",
        "Ting Zhang",
        "Mei Wang",
        "Xuetao Ma",
        "Hu Huang"
      ],
      "abstract": "Large Language Models have achieved remarkable results on a variety of\nmathematical benchmarks. However, concerns remain as to whether these successes\nreflect genuine mathematical reasoning or superficial pattern recognition.\nCommon evaluation metrics, such as final answer accuracy, fail to disentangle\nthe underlying competencies involved, offering limited diagnostic value. To\naddress these limitations, we introduce SMART: a Self-Generating and\nSelf-Validating Multi-Dimensional Assessment Framework. SMART decomposes\nmathematical problem solving into four distinct dimensions: understanding,\nreasoning, arithmetic, and reflection \\& refinement. Each dimension is\nevaluated independently through tailored tasks, enabling interpretable and\nfine-grained analysis of LLM behavior. Crucially, SMART integrates an automated\nself-generating and self-validating mechanism to produce and verify benchmark\ndata, ensuring both scalability and reliability. We apply SMART to 21\nstate-of-the-art open- and closed-source LLMs, uncovering significant\ndiscrepancies in their abilities across different dimensions. Our findings\ndemonstrate the inadequacy of final answer accuracy as a sole metric and\nmotivate a new holistic metric to better capture true problem-solving\ncapabilities. Code and benchmarks will be released upon acceptance.",
      "tldr_zh": "这篇论文引入了 SMART 框架，一种自生成和自验证的多维度评估方法，用于评估大型语言模型（LLMs）在数学问题解决中的真实能力，而非表面模式识别。SMART 将数学问题分解为四个独立维度：understanding、reasoning、arithmetic 和 reflection & refinement，通过定制任务进行细粒度分析，并采用自动机制生成和验证基准数据，确保评估的可扩展性和可靠性。研究对 21 个最先进的开源和闭源 LLMs 进行评估，发现模型在不同维度上存在显著能力差异，证明了最终答案准确率作为单一指标的局限性，并提出新的整体指标来更好地捕捉问题解决能力。代码和基准将于接受后发布。",
      "categories": [
        "cs.AI"
      ],
      "primary_category": "cs.AI",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2505.16646v1",
      "published_date": "2025-05-22 13:18:24 UTC",
      "updated_date": "2025-05-22 13:18:24 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-25T03:24:41.965567"
    },
    {
      "arxiv_id": "2505.16643v1",
      "title": "From Evaluation to Defense: Advancing Safety in Video Large Language Models",
      "title_zh": "翻译失败",
      "authors": [
        "Yiwei Sun",
        "Peiqi Jiang",
        "Chuanbin Liu",
        "Luohao Lin",
        "Zhiying Lu",
        "Hongtao Xie"
      ],
      "abstract": "While the safety risks of image-based large language models have been\nextensively studied, their video-based counterparts (Video LLMs) remain\ncritically under-examined. To systematically study this problem, we introduce\n\\textbf{VideoSafetyBench (VSB-77k) - the first large-scale, culturally diverse\nbenchmark for Video LLM safety}, which compromises 77,646 video-query pairs and\nspans 19 principal risk categories across 10 language communities. \\textit{We\nreveal that integrating video modality degrades safety performance by an\naverage of 42.3\\%, exposing systemic risks in multimodal attack exploitation.}\nTo address this vulnerability, we propose \\textbf{VideoSafety-R1}, a dual-stage\nframework achieving unprecedented safety gains through two innovations: (1)\nAlarm Token-Guided Safety Fine-Tuning (AT-SFT) injects learnable alarm tokens\ninto visual and textual sequences, enabling explicit harm perception across\nmodalities via multitask objectives. (2) Then, Safety-Guided GRPO enhances\ndefensive reasoning through dynamic policy optimization with rule-based rewards\nderived from dual-modality verification. These components synergize to shift\nsafety alignment from passive harm recognition to active reasoning. The\nresulting framework achieves a 65.1\\% improvement on VSB-Eval-HH, and improves\nby 59.1\\%, 44.3\\%, and 15.0\\% on the image safety datasets MMBench, VLGuard,\nand FigStep, respectively. \\textit{Our codes are available in the supplementary\nmaterials.} \\textcolor{red}{Warning: This paper contains examples of harmful\nlanguage and videos, and reader discretion is recommended.}",
      "tldr_zh": "该研究揭示了视频大型语言模型 (Video LLMs) 的安全风险，引入首个大规模基准 VideoSafetyBench (VSB-77k)，包含77,646个视频-查询对，覆盖19个风险类别和10个语言社区，并发现整合视频模态导致安全性能平均下降42.3%。为了解决这一问题，论文提出 VideoSafety-R1 框架，包括 Alarm Token-Guided Safety Fine-Tuning (AT-SFT) 用于注入警报标记以实现跨模态危害感知，以及 Safety-Guided GRPO 通过动态策略优化和双模态验证增强防御性推理。该框架在 VSB-Eval-HH 上实现65.1%的性能提升，并在图像安全数据集如 MMBench、VLGuard 和 FigStep 上分别改善59.1%、44.3%和15.0%。",
      "categories": [
        "cs.CV",
        "cs.AI"
      ],
      "primary_category": "cs.CV",
      "comment": "49 pages, 12 figures, 17 tables",
      "pdf_url": "http://arxiv.org/pdf/2505.16643v1",
      "published_date": "2025-05-22 13:16:53 UTC",
      "updated_date": "2025-05-22 13:16:53 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-25T03:24:55.194770"
    },
    {
      "arxiv_id": "2505.16640v1",
      "title": "BadVLA: Towards Backdoor Attacks on Vision-Language-Action Models via Objective-Decoupled Optimization",
      "title_zh": "翻译失败",
      "authors": [
        "Xueyang Zhou",
        "Guiyao Tie",
        "Guowen Zhang",
        "Hechang Wang",
        "Pan Zhou",
        "Lichao Sun"
      ],
      "abstract": "Vision-Language-Action (VLA) models have advanced robotic control by enabling\nend-to-end decision-making directly from multimodal inputs. However, their\ntightly coupled architectures expose novel security vulnerabilities. Unlike\ntraditional adversarial perturbations, backdoor attacks represent a stealthier,\npersistent, and practically significant threat-particularly under the emerging\nTraining-as-a-Service paradigm-but remain largely unexplored in the context of\nVLA models. To address this gap, we propose BadVLA, a backdoor attack method\nbased on Objective-Decoupled Optimization, which for the first time exposes the\nbackdoor vulnerabilities of VLA models. Specifically, it consists of a\ntwo-stage process: (1) explicit feature-space separation to isolate trigger\nrepresentations from benign inputs, and (2) conditional control deviations that\nactivate only in the presence of the trigger, while preserving clean-task\nperformance. Empirical results on multiple VLA benchmarks demonstrate that\nBadVLA consistently achieves near-100% attack success rates with minimal impact\non clean task accuracy. Further analyses confirm its robustness against common\ninput perturbations, task transfers, and model fine-tuning, underscoring\ncritical security vulnerabilities in current VLA deployments. Our work offers\nthe first systematic investigation of backdoor vulnerabilities in VLA models,\nhighlighting an urgent need for secure and trustworthy embodied model design\npractices. We have released the project page at\nhttps://badvla-project.github.io/.",
      "tldr_zh": "该研究提出BadVLA，一种针对Vision-Language-Action (VLA) 模型的backdoor攻击方法，通过Objective-Decoupled Optimization优化，首次系统暴露了VLA模型的安全漏洞。具体而言，该方法采用两阶段过程：(1) 显式特征空间分离，将触发器表示与正常输入隔离；(2) 条件控制偏差，仅在触发器存在时激活，同时保持正常任务性能。实验在多个VLA基准上显示，BadVLA实现了近100%的攻击成功率，对正常任务准确率影响最小，并证明其对输入扰动、任务转移和模型微调的鲁棒性，强调了VLA模型部署中亟需的安全改进。",
      "categories": [
        "cs.CR",
        "cs.AI",
        "68T07",
        "I.2.6; I.2.9"
      ],
      "primary_category": "cs.CR",
      "comment": "19 pages, 12 figures, 6 tables",
      "pdf_url": "http://arxiv.org/pdf/2505.16640v1",
      "published_date": "2025-05-22 13:12:46 UTC",
      "updated_date": "2025-05-22 13:12:46 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-25T03:25:05.403606"
    },
    {
      "arxiv_id": "2505.16637v1",
      "title": "SSR-Zero: Simple Self-Rewarding Reinforcement Learning for Machine Translation",
      "title_zh": "翻译失败",
      "authors": [
        "Wenjie Yang",
        "Mao Zheng",
        "Mingyang Song",
        "Zheng Li"
      ],
      "abstract": "Large language models (LLMs) have recently demonstrated remarkable\ncapabilities in machine translation (MT). However, most advanced MT-specific\nLLMs heavily rely on external supervision signals during training, such as\nhuman-annotated reference data or trained reward models (RMs), which are often\nexpensive to obtain and challenging to scale. To overcome this limitation, we\npropose a Simple Self-Rewarding (SSR) Reinforcement Learning (RL) framework for\nMT that is reference-free, fully online, and relies solely on self-judging\nrewards. Training with SSR using 13K monolingual examples and Qwen-2.5-7B as\nthe backbone, our model SSR-Zero-7B outperforms existing MT-specific LLMs,\ne.g., TowerInstruct-13B and GemmaX-28-9B, as well as larger general LLMs like\nQwen2.5-32B-Instruct in English $\\leftrightarrow$ Chinese translation tasks\nfrom WMT23, WMT24, and Flores200 benchmarks. Furthermore, by augmenting SSR\nwith external supervision from COMET, our strongest model, SSR-X-Zero-7B,\nachieves state-of-the-art performance in English $\\leftrightarrow$ Chinese\ntranslation, surpassing all existing open-source models under 72B parameters\nand even outperforming closed-source models, e.g., GPT-4o and Gemini 1.5 Pro.\nOur analysis highlights the effectiveness of the self-rewarding mechanism\ncompared to the external LLM-as-a-judge approach in MT and demonstrates its\ncomplementary benefits when combined with trained RMs. Our findings provide\nvaluable insight into the potential of self-improving RL methods. We have\npublicly released our code, data and models.",
      "tldr_zh": "该研究提出了一种简单自我奖励（SSR）强化学习（RL）框架，用于机器翻译（MT），该框架无需参考数据、完全在线，并仅依赖自我判断奖励，从而克服了传统方法对昂贵监督信号的依赖。使用13K单语示例和Qwen-2.5-7B作为基础模型，SSR-Zero-7B在WMT23、WMT24和Flores200基准上的英中翻译任务中，超越了现有MT特定LLM（如TowerInstruct-13B）和更大模型（如Qwen2.5-32B-Instruct）。通过整合COMET外部监督，SSR-X-Zero-7B实现了英中翻译的最新性能（State-of-the-Art），超过了所有小于72B参数的开源模型，甚至优于闭源模型如GPT-4o和Gemini 1.5 Pro。分析表明，自我奖励机制比外部LLM-as-a-judge方法更有效，且与训练过的奖励模型（RMs）结合时具有互补优势，为自我提升RL方法提供了宝贵见解。",
      "categories": [
        "cs.CL",
        "cs.AI",
        "cs.LG"
      ],
      "primary_category": "cs.CL",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2505.16637v1",
      "published_date": "2025-05-22 13:08:25 UTC",
      "updated_date": "2025-05-22 13:08:25 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-25T03:25:19.443422"
    },
    {
      "arxiv_id": "2505.16630v1",
      "title": "SoccerChat: Integrating Multimodal Data for Enhanced Soccer Game Understanding",
      "title_zh": "SoccerChat：整合多模态数据以增强足球游戏理解",
      "authors": [
        "Sushant Gautam",
        "Cise Midoglu",
        "Vajira Thambawita",
        "Michael A. Riegler",
        "Pål Halvorsen",
        "Mubarak Shah"
      ],
      "abstract": "The integration of artificial intelligence in sports analytics has\ntransformed soccer video understanding, enabling real-time, automated insights\ninto complex game dynamics. Traditional approaches rely on isolated data\nstreams, limiting their effectiveness in capturing the full context of a match.\nTo address this, we introduce SoccerChat, a multimodal conversational AI\nframework that integrates visual and textual data for enhanced soccer video\ncomprehension. Leveraging the extensive SoccerNet dataset, enriched with jersey\ncolor annotations and automatic speech recognition (ASR) transcripts,\nSoccerChat is fine-tuned on a structured video instruction dataset to\nfacilitate accurate game understanding, event classification, and referee\ndecision making. We benchmark SoccerChat on action classification and referee\ndecision-making tasks, demonstrating its performance in general soccer event\ncomprehension while maintaining competitive accuracy in referee decision\nmaking. Our findings highlight the importance of multimodal integration in\nadvancing soccer analytics, paving the way for more interactive and explainable\nAI-driven sports analysis. https://github.com/simula/SoccerChat",
      "tldr_zh": "本文提出 SoccerChat，一种多模态对话 AI 框架，用于整合视觉和文本数据（如 SoccerNet 数据集中的球衣颜色注释以及 ASR 转录），以提升足球视频的理解、事件分类和裁判决策能力。该框架在结构化视频指令数据集上进行微调，实现了更准确的游戏动态分析。实验结果显示，SoccerChat 在行动分类和裁判决策任务上表现出色，证明了多模态整合在推动交互式和可解释的 AI 驱动体育分析方面的关键作用。",
      "categories": [
        "cs.CV",
        "cs.AI",
        "68T45, 68T50",
        "I.2.10; I.2.7; H.5.2"
      ],
      "primary_category": "cs.CV",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2505.16630v1",
      "published_date": "2025-05-22 13:01:51 UTC",
      "updated_date": "2025-05-22 13:01:51 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-25T03:25:29.348407"
    },
    {
      "arxiv_id": "2505.16619v1",
      "title": "Open and Sustainable AI: challenges, opportunities and the road ahead in the life sciences",
      "title_zh": "翻译失败",
      "authors": [
        "Gavin Farrell",
        "Eleni Adamidi",
        "Rafael Andrade Buono",
        "Mihail Anton",
        "Omar Abdelghani Attafi",
        "Salvador Capella Gutierrez",
        "Emidio Capriotti",
        "Leyla Jael Castro",
        "Davide Cirillo",
        "Lisa Crossman",
        "Christophe Dessimoz",
        "Alexandros Dimopoulos",
        "Raul Fernandez-Diaz",
        "Styliani-Christina Fragkouli",
        "Carole Goble",
        "Wei Gu",
        "John M. Hancock",
        "Alireza Khanteymoori",
        "Tom Lenaerts",
        "Fabio G. Liberante",
        "Peter Maccallum",
        "Alexander Miguel Monzon",
        "Magnus Palmblad",
        "Lucy Poveda",
        "Ovidiu Radulescu",
        "Denis C. Shields",
        "Shoaib Sufi",
        "Thanasis Vergoulis",
        "Fotis Psomopoulos",
        "Silvio C. E. Tosatto"
      ],
      "abstract": "Artificial intelligence (AI) has recently seen transformative breakthroughs\nin the life sciences, expanding possibilities for researchers to interpret\nbiological information at an unprecedented capacity, with novel applications\nand advances being made almost daily. In order to maximise return on the\ngrowing investments in AI-based life science research and accelerate this\nprogress, it has become urgent to address the exacerbation of long-standing\nresearch challenges arising from the rapid adoption of AI methods. We review\nthe increased erosion of trust in AI research outputs, driven by the issues of\npoor reusability and reproducibility, and highlight their consequent impact on\nenvironmental sustainability. Furthermore, we discuss the fragmented components\nof the AI ecosystem and lack of guiding pathways to best support Open and\nSustainable AI (OSAI) model development. In response, this perspective\nintroduces a practical set of OSAI recommendations directly mapped to over 300\ncomponents of the AI ecosystem. Our work connects researchers with relevant AI\nresources, facilitating the implementation of sustainable, reusable and\ntransparent AI. Built upon life science community consensus and aligned to\nexisting efforts, the outputs of this perspective are designed to aid the\nfuture development of policy and structured pathways for guiding AI\nimplementation.",
      "tldr_zh": "本论文审视了AI在生命科学领域的突破性进展及其挑战，包括AI输出信任度降低、可复用性和可复现性不足，以及对环境可持续性的影响。作者讨论了AI生态系统的碎片化和缺乏指导路径，并提出一套实用的Open and Sustainable AI (OSAI) 推荐，直接映射到AI生态系统的300多个组件，以促进可持续、可复用和透明的AI开发。这些推荐基于生命科学社区共识，旨在为AI实施提供政策指导和结构化路径。",
      "categories": [
        "cs.AI",
        "q-bio.OT",
        "92",
        "J.3"
      ],
      "primary_category": "cs.AI",
      "comment": "1 PDF, 24 Pages, 2 figures within. Co-corresponding authors:\n  Institute of Applied Biosciences, Centre for Research and Technology Hellas,\n  Thessaloniki, Greece and Department of Biomedical Sciences, University of\n  Padova, Padova, Italy. E-mails: fpsom@certh.gr, silvio.tosatto@unipd.it",
      "pdf_url": "http://arxiv.org/pdf/2505.16619v1",
      "published_date": "2025-05-22 12:52:34 UTC",
      "updated_date": "2025-05-22 12:52:34 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-25T03:25:41.219958"
    },
    {
      "arxiv_id": "2505.16612v1",
      "title": "Steering Large Language Models for Machine Translation Personalization",
      "title_zh": "引导大语言模型用于机器翻译个性化",
      "authors": [
        "Daniel Scalena",
        "Gabriele Sarti",
        "Arianna Bisazza",
        "Elisabetta Fersini",
        "Malvina Nissim"
      ],
      "abstract": "High-quality machine translation systems based on large language models\n(LLMs) have simplified the production of personalized translations reflecting\nspecific stylistic constraints. However, these systems still struggle in\nsettings where stylistic requirements are less explicit and might be harder to\nconvey via prompting. We explore various strategies for personalizing\nLLM-generated translations in low-resource settings, focusing on the\nchallenging literary translation domain. We explore prompting strategies and\ninference-time interventions for steering model generations towards a\npersonalized style, and propose a contrastive framework exploiting latent\nconcepts extracted from sparse autoencoders to identify salient personalization\nproperties. Our results show that steering achieves strong personalization\nwhile preserving translation quality. We further examine the impact of steering\non LLM representations, finding model layers with a relevant impact for\npersonalization are impacted similarly by multi-shot prompting and our steering\nmethod, suggesting similar mechanism at play.",
      "tldr_zh": "这篇论文探讨了如何引导大型语言模型 (LLMs) 以实现机器翻译的个性化，特别是在风格要求不明确且资源有限的文学翻译领域。研究者探索了提示策略和推理时的干预方法，并提出了一种对比框架，利用从稀疏自动编码器提取的潜在概念来识别关键的个性化属性。结果表明，这种引导方法显著提升了翻译的个性化，同时保持了翻译质量；此外，引导对LLMs表示的影响与多-shot 提示类似，揭示了相似的底层机制。",
      "categories": [
        "cs.CL",
        "cs.AI",
        "cs.LG"
      ],
      "primary_category": "cs.CL",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2505.16612v1",
      "published_date": "2025-05-22 12:47:16 UTC",
      "updated_date": "2025-05-22 12:47:16 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-25T03:25:52.846221"
    },
    {
      "arxiv_id": "2505.16596v1",
      "title": "Safe Uncertainty-Aware Learning of Robotic Suturing",
      "title_zh": "翻译失败",
      "authors": [
        "Wilbert Peter Empleo",
        "Yitaek Kim",
        "Hansoul Kim",
        "Thiusius Rajeeth Savarimuthu",
        "Iñigo Iturrate"
      ],
      "abstract": "Robot-Assisted Minimally Invasive Surgery is currently fully manually\ncontrolled by a trained surgeon. Automating this has great potential for\nalleviating issues, e.g., physical strain, highly repetitive tasks, and\nshortages of trained surgeons. For these reasons, recent works have utilized\nArtificial Intelligence methods, which show promising adaptability. Despite\nthese advances, there is skepticism of these methods because they lack\nexplainability and robust safety guarantees. This paper presents a framework\nfor a safe, uncertainty-aware learning method. We train an Ensemble Model of\nDiffusion Policies using expert demonstrations of needle insertion. Using an\nEnsemble model, we can quantify the policy's epistemic uncertainty, which is\nused to determine Out-Of-Distribution scenarios. This allows the system to\nrelease control back to the surgeon in the event of an unsafe scenario.\nAdditionally, we implement a model-free Control Barrier Function to place\nformal safety guarantees on the predicted action. We experimentally evaluate\nour proposed framework using a state-of-the-art robotic suturing simulator. We\nevaluate multiple scenarios, such as dropping the needle, moving the camera,\nand moving the phantom. The learned policy is robust to these perturbations,\nshowing corrective behaviors and generalization, and it is possible to detect\nOut-Of-Distribution scenarios. We further demonstrate that the Control Barrier\nFunction successfully limits the action to remain within our specified safety\nset in the case of unsafe predictions.",
      "tldr_zh": "这篇论文提出一个安全、考虑不确定性的学习框架，用于机器人缝合任务，以解决AI方法在手术自动化中的可解释性和安全保障问题。框架通过训练Ensemble Model of Diffusion Policies，使用专家演示量化认知不确定性（epistemic uncertainty），从而检测Out-Of-Distribution场景，并在不安全时将控制权交回外科医生；同时，结合无模型Control Barrier Function，为预测动作提供正式安全保证。实验在机器人缝合模拟器上验证了该框架的鲁棒性，包括对掉针、移动相机和移动假体等扰动的纠正行为和泛化能力。",
      "categories": [
        "cs.RO",
        "cs.AI"
      ],
      "primary_category": "cs.RO",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2505.16596v1",
      "published_date": "2025-05-22 12:31:18 UTC",
      "updated_date": "2025-05-22 12:31:18 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-25T03:26:05.569931"
    },
    {
      "arxiv_id": "2505.16582v1",
      "title": "O$^2$-Searcher: A Searching-based Agent Model for Open-Domain Open-Ended Question Answering",
      "title_zh": "翻译失败",
      "authors": [
        "Jianbiao Mei",
        "Tao Hu",
        "Daocheng Fu",
        "Licheng Wen",
        "Xuemeng Yang",
        "Rong Wu",
        "Pinlong Cai",
        "Xing Gao",
        "Yu Yang",
        "Chengjun Xie",
        "Botian Shi",
        "Yong Liu",
        "Yu Qiao"
      ],
      "abstract": "Large Language Models (LLMs), despite their advancements, are fundamentally\nlimited by their static parametric knowledge, hindering performance on tasks\nrequiring open-domain up-to-date information. While enabling LLMs to interact\nwith external knowledge environments is a promising solution, current efforts\nprimarily address closed-end problems. Open-ended questions, which\ncharacterized by lacking a standard answer or providing non-unique and diverse\nanswers, remain underexplored. To bridge this gap, we present O$^2$-Searcher, a\nnovel search agent leveraging reinforcement learning to effectively tackle both\nopen-ended and closed-ended questions in the open domain. O$^2$-Searcher\nleverages an efficient, locally simulated search environment for dynamic\nknowledge acquisition, effectively decoupling the external world knowledge from\nmodel's sophisticated reasoning processes. It employs a unified training\nmechanism with meticulously designed reward functions, enabling the agent to\nidentify problem types and adapt different answer generation strategies.\nFurthermore, to evaluate performance on complex open-ended tasks, we construct\nO$^2$-QA, a high-quality benchmark featuring 300 manually curated, multi-domain\nopen-ended questions with associated web page caches. Extensive experiments\nshow that O$^2$-Searcher, using only a 3B model, significantly surpasses\nleading LLM agents on O$^2$-QA. It also achieves SOTA results on various\nclosed-ended QA benchmarks against similarly-sized models, while performing on\npar with much larger ones.",
      "tldr_zh": "该研究指出，大语言模型（LLMs）因静态参数知识的限制，在处理需要实时开放域信息的开放式问题（characterized by lacking a standard answer or providing non-unique and diverse answers）时存在挑战。作者提出 O$^2$-Searcher，一种基于强化学习的搜索代理模型，能够动态获取知识并处理开放域的开放式和封闭式问题，通过高效的本地模拟搜索环境和统一训练机制（如精心设计的奖励函数）来分离外部知识与模型推理。O$^2$-Searcher 能识别问题类型并适应不同生成策略，并在新构建的 O$^2$-QA 基准数据集（包含 300 个多领域开放式问题）上，使用仅 3B 模型就显著超越领先的 LLM 代理，同时在封闭式 QA 基准上达到 SOTA 结果，并与更大模型相当。",
      "categories": [
        "cs.CL",
        "cs.AI"
      ],
      "primary_category": "cs.CL",
      "comment": "25 pages, 9 figures",
      "pdf_url": "http://arxiv.org/pdf/2505.16582v1",
      "published_date": "2025-05-22 12:17:13 UTC",
      "updated_date": "2025-05-22 12:17:13 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-25T03:26:19.156355"
    },
    {
      "arxiv_id": "2505.16581v1",
      "title": "How Ensembles of Distilled Policies Improve Generalisation in Reinforcement Learning",
      "title_zh": "翻译失败",
      "authors": [
        "Max Weltevrede",
        "Moritz A. Zanger",
        "Matthijs T. J. Spaan",
        "Wendelin Böhmer"
      ],
      "abstract": "In the zero-shot policy transfer setting in reinforcement learning, the goal\nis to train an agent on a fixed set of training environments so that it can\ngeneralise to similar, but unseen, testing environments. Previous work has\nshown that policy distillation after training can sometimes produce a policy\nthat outperforms the original in the testing environments. However, it is not\nyet entirely clear why that is, or what data should be used to distil the\npolicy. In this paper, we prove, under certain assumptions, a generalisation\nbound for policy distillation after training. The theory provides two practical\ninsights: for improved generalisation, you should 1) train an ensemble of\ndistilled policies, and 2) distil it on as much data from the training\nenvironments as possible. We empirically verify that these insights hold in\nmore general settings, when the assumptions required for the theory no longer\nhold. Finally, we demonstrate that an ensemble of policies distilled on a\ndiverse dataset can generalise significantly better than the original agent.",
      "tldr_zh": "这篇论文探讨了在强化学习（reinforcement learning）中，如何通过策略蒸馏（policy distillation）的集合（ensembles of distilled policies）来提升零样本策略转移（zero-shot policy transfer）的泛化能力。作者在特定假设下证明了策略蒸馏后的泛化边界，并提出两个实用见解：训练策略的集合以改善泛化，以及在尽可能多的训练环境数据上进行蒸馏。实验结果验证了这些见解在更广泛的设置中成立，并展示了在多样化数据集上蒸馏的策略集合比原始代理泛化性能显著更好。",
      "categories": [
        "cs.LG",
        "cs.AI"
      ],
      "primary_category": "cs.LG",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2505.16581v1",
      "published_date": "2025-05-22 12:15:52 UTC",
      "updated_date": "2025-05-22 12:15:52 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-25T03:26:30.185898"
    },
    {
      "arxiv_id": "2505.16579v1",
      "title": "Bridging the Dynamic Perception Gap: Training-Free Draft Chain-of-Thought for Dynamic Multimodal Spatial Reasoning",
      "title_zh": "翻译失败",
      "authors": [
        "Siqu Ou",
        "Hongcheng Liu",
        "Pingjie Wang",
        "Yusheng Liao",
        "Chuan Xuan",
        "Yanfeng Wang",
        "Yu Wang"
      ],
      "abstract": "While chains-of-thought (CoT) have advanced complex reasoning in multimodal\nlarge language models (MLLMs), existing methods remain confined to text or\nstatic visual domains, often faltering in dynamic spatial reasoning tasks. To\nbridge this gap, we present GRASSLAND, a novel maze navigation benchmark\ndesigned to evaluate dynamic spatial reasoning. Our experiments show that\naugmenting textual reasoning chains with dynamic visual drafts, overlaid on\ninput images, significantly outperforms conventional approaches, offering new\ninsights into spatial reasoning in evolving environments. To generalize this\ncapability, we propose D2R (Dynamic Draft-Augmented Reasoning), a training-free\nframework that seamlessly integrates textual CoT with corresponding visual\ndrafts into MLLMs. Extensive evaluations demonstrate that D2R consistently\nenhances performance across diverse tasks, establishing a robust baseline for\ndynamic spatial reasoning without requiring model fine-tuning. Project is open\nat https://github.com/Cratileo/D2R.",
      "tldr_zh": "该研究发现，现有的链式思维推理（CoT）方法在动态空间推理任务中表现不佳，局限于文本或静态视觉领域。为解决这一问题，研究者提出GRASSLAND，一个新的迷宫导航基准，用于评估多模态大型语言模型（MLLMs）在动态环境的推理能力。作者开发了D2R（Dynamic Draft-Augmented Reasoning），一个无需训练的框架，将文本CoT与动态视觉草图整合到MLLMs中，实验显示此方法显著提升了性能，并在多种任务中建立了稳健基准。项目开源于https://github.com/Cratileo/D2R。",
      "categories": [
        "cs.AI",
        "cs.CV"
      ],
      "primary_category": "cs.AI",
      "comment": "19 pages, 8 figures",
      "pdf_url": "http://arxiv.org/pdf/2505.16579v1",
      "published_date": "2025-05-22 12:14:23 UTC",
      "updated_date": "2025-05-22 12:14:23 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-25T03:26:41.700267"
    },
    {
      "arxiv_id": "2505.16573v1",
      "title": "From Local Patterns to Global Understanding: Cross-Stock Trend Integration for Enhanced Predictive Modeling",
      "title_zh": "从局部模式到全局理解：跨股票趋势",
      "authors": [
        "Yi Hu",
        "Hanchi Ren",
        "Jingjing Deng",
        "Xianghua Xie"
      ],
      "abstract": "Stock price prediction is a critical area of financial forecasting,\ntraditionally approached by training models using the historical price data of\nindividual stocks. While these models effectively capture single-stock\npatterns, they fail to leverage potential correlations among stock trends,\nwhich could improve predictive performance. Current single-stock learning\nmethods are thus limited in their ability to provide a broader understanding of\nprice dynamics across multiple stocks. To address this, we propose a novel\nmethod that merges local patterns into a global understanding through\ncross-stock pattern integration. Our strategy is inspired by Federated Learning\n(FL), a paradigm designed for decentralized model training. FL enables\ncollaborative learning across distributed datasets without sharing raw data,\nfacilitating the aggregation of global insights while preserving data privacy.\nIn our adaptation, we train models on individual stock data and iteratively\nmerge them to create a unified global model. This global model is subsequently\nfine-tuned on specific stock data to retain local relevance. The proposed\nstrategy enables parallel training of individual stock models, facilitating\nefficient utilization of computational resources and reducing overall training\ntime. We conducted extensive experiments to evaluate the proposed method,\ndemonstrating that it outperforms benchmark models and enhances the predictive\ncapabilities of state-of-the-art approaches. Our results highlight the efficacy\nof Cross-Stock Trend Integration (CSTI) in advancing stock price prediction,\noffering a robust alternative to traditional single-stock learning\nmethodologies.",
      "tldr_zh": "这篇论文针对传统股票价格预测方法的局限性，提出了一种名为Cross-Stock Trend Integration (CSTI)的创新方法，该方法受Federated Learning (FL)启发，通过在单个股票数据上训练模型并迭代合并成统一全局模型，同时保留局部相关性，从而捕捉跨股票趋势的全局理解。CSTI支持并行训练，高效利用计算资源、保护数据隐私，并通过在特定股票数据上微调来优化预测性能。实验结果显示，该方法显著优于基准模型，提升了股票价格预测的准确性和整体效果。",
      "categories": [
        "cs.CE",
        "cs.AI"
      ],
      "primary_category": "cs.CE",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2505.16573v1",
      "published_date": "2025-05-22 12:04:10 UTC",
      "updated_date": "2025-05-22 12:04:10 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-25T03:26:53.184473"
    },
    {
      "arxiv_id": "2505.16567v1",
      "title": "Finetuning-Activated Backdoors in LLMs",
      "title_zh": "翻译失败",
      "authors": [
        "Thibaud Gloaguen",
        "Mark Vero",
        "Robin Staab",
        "Martin Vechev"
      ],
      "abstract": "Finetuning openly accessible Large Language Models (LLMs) has become standard\npractice for achieving task-specific performance improvements. Until now,\nfinetuning has been regarded as a controlled and secure process in which\ntraining on benign datasets led to predictable behaviors. In this paper, we\ndemonstrate for the first time that an adversary can create poisoned LLMs that\ninitially appear benign but exhibit malicious behaviors once finetuned by\ndownstream users. To this end, our proposed attack, FAB (Finetuning-Activated\nBackdoor), poisons an LLM via meta-learning techniques to simulate downstream\nfinetuning, explicitly optimizing for the emergence of malicious behaviors in\nthe finetuned models. At the same time, the poisoned LLM is regularized to\nretain general capabilities and to exhibit no malicious behaviors prior to\nfinetuning. As a result, when users finetune the seemingly benign model on\ntheir own datasets, they unknowingly trigger its hidden backdoor behavior. We\ndemonstrate the effectiveness of FAB across multiple LLMs and three target\nbehaviors: unsolicited advertising, refusal, and jailbreakability.\nAdditionally, we show that FAB-backdoors are robust to various finetuning\nchoices made by the user (e.g., dataset, number of steps, scheduler). Our\nfindings challenge prevailing assumptions about the security of finetuning,\nrevealing yet another critical attack vector exploiting the complexities of\nLLMs.",
      "tldr_zh": "这篇论文首次揭示了在大型语言模型（LLMs）中存在的Finetuning-Activated Backdoors（FAB），即攻击者通过meta-learning技术毒化LLMs，使其在下游用户fintuning后表现出恶意行为（如unsolicited advertising、refusal和jailbreakability），而fintuning前保持benign状态。FAB攻击模拟fintuning过程，优化恶意行为的触发，同时regularize模型以保留一般能力。实验证明，该攻击在多个LLMs上有效，且对用户的fintuning选择（如数据集、步数和scheduler）具有robust性，挑战了fintuning作为安全过程的传统假设，并暴露了LLMs的另一个关键安全漏洞。",
      "categories": [
        "cs.LG",
        "cs.AI",
        "cs.CR"
      ],
      "primary_category": "cs.LG",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2505.16567v1",
      "published_date": "2025-05-22 11:59:44 UTC",
      "updated_date": "2025-05-22 11:59:44 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-25T03:27:06.044188"
    },
    {
      "arxiv_id": "2505.16561v1",
      "title": "Auto-nnU-Net: Towards Automated Medical Image Segmentation",
      "title_zh": "翻译失败",
      "authors": [
        "Jannis Becktepe",
        "Leona Hennig",
        "Steffen Oeltze-Jafra",
        "Marius Lindauer"
      ],
      "abstract": "Medical Image Segmentation (MIS) includes diverse tasks, from bone to organ\nsegmentation, each with its own challenges in finding the best segmentation\nmodel. The state-of-the-art AutoML-related MIS-framework nnU-Net automates many\naspects of model configuration but remains constrained by fixed hyperparameters\nand heuristic design choices. As a full-AutoML framework for MIS, we propose\nAuto-nnU-Net, a novel nnU-Net variant enabling hyperparameter optimization\n(HPO), neural architecture search (NAS), and hierarchical NAS (HNAS).\nAdditionally, we propose Regularized PriorBand to balance model accuracy with\nthe computational resources required for training, addressing the resource\nconstraints often faced in real-world medical settings that limit the\nfeasibility of extensive training procedures. We evaluate our approach across\ndiverse MIS datasets from the well-established Medical Segmentation Decathlon,\nanalyzing the impact of AutoML techniques on segmentation performance,\ncomputational efficiency, and model design choices. The results demonstrate\nthat our AutoML approach substantially improves the segmentation performance of\nnnU-Net on 6 out of 10 datasets and is on par on the other datasets while\nmaintaining practical resource requirements. Our code is available at\nhttps://github.com/LUH-AI/AutonnUNet.",
      "tldr_zh": "本论文提出 Auto-nnU-Net，一种全自动机器学习框架，用于医疗图像分割 (MIS)，旨在解决现有 nnU-Net 的固定超参数和启发式设计限制，通过整合超参数优化 (HPO)、神经架构搜索 (NAS) 和分层 NAS (HNAS) 来自动优化模型配置。框架还引入 Regularized PriorBand 机制，以平衡模型准确性和计算资源需求，适用于医疗场景的资源约束。实验结果显示，Auto-nnU-Net 在 Medical Segmentation Decathlon 的 10 个数据集上，在 6 个数据集上显著提升了 nnU-Net 的分割性能，并在其他数据集上保持相当水平，同时确保了实际应用的资源效率。",
      "categories": [
        "cs.CV",
        "cs.AI"
      ],
      "primary_category": "cs.CV",
      "comment": "31 pages, 19 figures. Accepted for publication at AutoML 2025",
      "pdf_url": "http://arxiv.org/pdf/2505.16561v1",
      "published_date": "2025-05-22 11:52:16 UTC",
      "updated_date": "2025-05-22 11:52:16 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-25T03:27:18.238736"
    },
    {
      "arxiv_id": "2505.16547v1",
      "title": "Find the Fruit: Designing a Zero-Shot Sim2Real Deep RL Planner for Occlusion Aware Plant Manipulation",
      "title_zh": "翻译失败",
      "authors": [
        "Nitesh Subedi",
        "Hsin-Jung Yang",
        "Devesh K. Jha",
        "Soumik Sarkar"
      ],
      "abstract": "This paper presents an end-to-end deep reinforcement learning (RL) framework\nfor occlusion-aware robotic manipulation in cluttered plant environments. Our\napproach enables a robot to interact with a deformable plant to reveal hidden\nobjects of interest, such as fruits, using multimodal observations. We decouple\nthe kinematic planning problem from robot control to simplify zero-shot\nsim2real transfer for the trained policy. Our results demonstrate that the\ntrained policy, deployed using our framework, achieves up to 86.7% success in\nreal-world trials across diverse initial conditions. Our findings pave the way\ntoward autonomous, perception-driven agricultural robots that intelligently\ninteract with complex foliage plants to \"find the fruit\" in challenging\noccluded scenarios, without the need for explicitly designed geometric and\ndynamic models of every plant scenario.",
      "tldr_zh": "这篇论文提出了一种端到端的深度强化学习（RL）框架，用于遮挡感知的机器人操作，帮助机器人与可变形植物互动，以揭示隐藏的水果对象。框架通过将运动规划与机器人控制分离，实现零样本模拟到真实（Sim2Real）转移，并利用多模态观察简化复杂环境下的操作。实验结果显示，该策略在真实世界试验中成功率高达86.7%，为自主、感知驱动的农业机器人提供了智能交互方法，而无需显式设计每个植物场景的几何和动态模型。",
      "categories": [
        "cs.RO",
        "cs.AI"
      ],
      "primary_category": "cs.RO",
      "comment": "18 Pages, 15 Figures, 5 Tables",
      "pdf_url": "http://arxiv.org/pdf/2505.16547v1",
      "published_date": "2025-05-22 11:37:39 UTC",
      "updated_date": "2025-05-22 11:37:39 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-25T03:27:30.103250"
    },
    {
      "arxiv_id": "2505.16540v1",
      "title": "TextureSAM: Towards a Texture Aware Foundation Model for Segmentation",
      "title_zh": "翻译失败",
      "authors": [
        "Inbal Cohen",
        "Boaz Meivar",
        "Peihan Tu",
        "Shai Avidan",
        "Gal Oren"
      ],
      "abstract": "Segment Anything Models (SAM) have achieved remarkable success in object\nsegmentation tasks across diverse datasets. However, these models are\npredominantly trained on large-scale semantic segmentation datasets, which\nintroduce a bias toward object shape rather than texture cues in the image.\nThis limitation is critical in domains such as medical imaging, material\nclassification, and remote sensing, where texture changes define object\nboundaries. In this study, we investigate SAM's bias toward semantics over\ntextures and introduce a new texture-aware foundation model, TextureSAM, which\nperforms superior segmentation in texture-dominant scenarios. To achieve this,\nwe employ a novel fine-tuning approach that incorporates texture augmentation\ntechniques, incrementally modifying training images to emphasize texture\nfeatures. By leveraging a novel texture-alternation of the ADE20K dataset, we\nguide TextureSAM to prioritize texture-defined regions, thereby mitigating the\ninherent shape bias present in the original SAM model. Our extensive\nexperiments demonstrate that TextureSAM significantly outperforms SAM-2 on both\nnatural (+0.2 mIoU) and synthetic (+0.18 mIoU) texture-based segmentation\ndatasets. The code and texture-augmented dataset will be publicly available.",
      "tldr_zh": "该研究发现，Segment Anything Models (SAM) 在对象分割任务中偏向于形状而非纹理特征，这在医疗成像、材料分类和遥感等领域造成局限。论文提出TextureSAM，一种新的纹理感知基础模型，通过新型微调方法结合纹理增强技术和对ADE20K数据集的纹理变体，强调纹理特征以缓解SAM的形状偏见。实验结果显示，TextureSAM在自然和合成纹理-based分割数据集上显著优于SAM-2（+0.2 mIoU和+0.18 mIoU），并计划公开代码和增强数据集。",
      "categories": [
        "cs.CV",
        "cs.AI"
      ],
      "primary_category": "cs.CV",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2505.16540v1",
      "published_date": "2025-05-22 11:31:56 UTC",
      "updated_date": "2025-05-22 11:31:56 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-25T03:27:41.947872"
    },
    {
      "arxiv_id": "2505.16530v1",
      "title": "DuFFin: A Dual-Level Fingerprinting Framework for LLMs IP Protection",
      "title_zh": "DuFF",
      "authors": [
        "Yuliang Yan",
        "Haochun Tang",
        "Shuo Yan",
        "Enyan Dai"
      ],
      "abstract": "Large language models (LLMs) are considered valuable Intellectual Properties\n(IP) for legitimate owners due to the enormous computational cost of training.\nIt is crucial to protect the IP of LLMs from malicious stealing or unauthorized\ndeployment. Despite existing efforts in watermarking and fingerprinting LLMs,\nthese methods either impact the text generation process or are limited in\nwhite-box access to the suspect model, making them impractical. Hence, we\npropose DuFFin, a novel $\\textbf{Du}$al-Level $\\textbf{Fin}$gerprinting\n$\\textbf{F}$ramework for black-box setting ownership verification. DuFFin\nextracts the trigger pattern and the knowledge-level fingerprints to identify\nthe source of a suspect model. We conduct experiments on a variety of models\ncollected from the open-source website, including four popular base models as\nprotected LLMs and their fine-tuning, quantization, and safety alignment\nversions, which are released by large companies, start-ups, and individual\nusers. Results show that our method can accurately verify the copyright of the\nbase protected LLM on their model variants, achieving the IP-ROC metric greater\nthan 0.95. Our code is available at\nhttps://github.com/yuliangyan0807/llm-fingerprint.",
      "tldr_zh": "该研究提出DuFFin，一种双层指纹(Dual-Level Fingerprinting)框架，用于在black-box设置下保护LLMs的知识产权(IP)，以应对现有watermarking和fingerprinting方法的影响和局限性。DuFFin通过提取trigger pattern和knowledge-level fingerprints来识别可疑模型的来源，从而实现准确的所有权验证。实验在多种开源模型上进行，包括基线LLMs及其fine-tuning、quantization和safety alignment版本，结果显示DuFFin在model variants上验证准确率高，IP-ROC指标超过0.95，为LLMs IP保护提供了有效工具。",
      "categories": [
        "cs.CR",
        "cs.AI",
        "cs.CL"
      ],
      "primary_category": "cs.CR",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2505.16530v1",
      "published_date": "2025-05-22 11:16:46 UTC",
      "updated_date": "2025-05-22 11:16:46 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-25T03:27:53.993105"
    },
    {
      "arxiv_id": "2505.16522v1",
      "title": "Benchmarking and Pushing the Multi-Bias Elimination Boundary of LLMs via Causal Effect Estimation-guided Debiasing",
      "title_zh": "翻译失败",
      "authors": [
        "Zhouhao Sun",
        "Zhiyuan Kan",
        "Xiao Ding",
        "Li Du",
        "Yang Zhao",
        "Bing Qin",
        "Ting Liu"
      ],
      "abstract": "Despite significant progress, recent studies have indicated that current\nlarge language models (LLMs) may still utilize bias during inference, leading\nto the poor generalizability of LLMs. Some benchmarks are proposed to\ninvestigate the generalizability of LLMs, with each piece of data typically\ncontaining one type of controlled bias. However, a single piece of data may\ncontain multiple types of biases in practical applications. To bridge this gap,\nwe propose a multi-bias benchmark where each piece of data contains five types\nof biases. The evaluations conducted on this benchmark reveal that the\nperformance of existing LLMs and debiasing methods is unsatisfying,\nhighlighting the challenge of eliminating multiple types of biases\nsimultaneously. To overcome this challenge, we propose a causal effect\nestimation-guided multi-bias elimination method (CMBE). This method first\nestimates the causal effect of multiple types of biases simultaneously.\nSubsequently, we eliminate the causal effect of biases from the total causal\neffect exerted by both the semantic information and biases during inference.\nExperimental results show that CMBE can effectively eliminate multiple types of\nbias simultaneously to enhance the generalizability of LLMs.",
      "tldr_zh": "该研究针对大型语言模型(LLMs) 在推理过程中存在的多种偏见问题，提出了一个多偏见基准(multi-bias benchmark)，其中每个数据样本包含五种类型的偏见，以评估LLMs的泛化能力。实验结果显示，现有的LLMs和去偏见方法在处理多偏见场景时表现不佳。作者引入了基于因果效应估计(causal effect estimation)的多偏见消除方法(CMBE)，该方法先同时估计多种偏见的因果效应，然后从总因果效应中消除偏见的影响，从而提升LLMs的泛化性能。最终，实验证明CMBE能有效同时消除多种偏见，提高模型的鲁棒性。",
      "categories": [
        "cs.CL",
        "cs.AI"
      ],
      "primary_category": "cs.CL",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2505.16522v1",
      "published_date": "2025-05-22 11:04:09 UTC",
      "updated_date": "2025-05-22 11:04:09 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-25T03:28:05.967051"
    },
    {
      "arxiv_id": "2505.16520v1",
      "title": "Are the Hidden States Hiding Something? Testing the Limits of Factuality-Encoding Capabilities in LLMs",
      "title_zh": "翻译失败",
      "authors": [
        "Giovanni Servedio",
        "Alessandro De Bellis",
        "Dario Di Palma",
        "Vito Walter Anelli",
        "Tommaso Di Noia"
      ],
      "abstract": "Factual hallucinations are a major challenge for Large Language Models\n(LLMs). They undermine reliability and user trust by generating inaccurate or\nfabricated content. Recent studies suggest that when generating false\nstatements, the internal states of LLMs encode information about truthfulness.\nHowever, these studies often rely on synthetic datasets that lack realism,\nwhich limits generalization when evaluating the factual accuracy of text\ngenerated by the model itself. In this paper, we challenge the findings of\nprevious work by investigating truthfulness encoding capabilities, leading to\nthe generation of a more realistic and challenging dataset. Specifically, we\nextend previous work by introducing: (1) a strategy for sampling plausible\ntrue-false factoid sentences from tabular data and (2) a procedure for\ngenerating realistic, LLM-dependent true-false datasets from Question Answering\ncollections. Our analysis of two open-source LLMs reveals that while the\nfindings from previous studies are partially validated, generalization to\nLLM-generated datasets remains challenging. This study lays the groundwork for\nfuture research on factuality in LLMs and offers practical guidelines for more\neffective evaluation.",
      "tldr_zh": "这篇论文探讨了大型语言模型 (LLMs) 中的事实幻觉问题，质疑其内部隐藏状态 (hidden states) 是否真正编码了真实性信息。作者挑战现有研究，通过引入两种新策略：(1) 从表格数据中采样可信的真假事实句子，以及 (2) 从问答集合生成更现实、依赖 LLMs 的真假数据集，以创建更具挑战性的评估环境。对两个开源 LLMs 的分析显示，现有研究的部分发现得到验证，但模型在泛化到自身生成的数据集时仍面临困难。该研究为 LLMs 的事实性评估奠定了基础，并提供了更有效的实用指南。",
      "categories": [
        "cs.CL",
        "cs.AI"
      ],
      "primary_category": "cs.CL",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2505.16520v1",
      "published_date": "2025-05-22 11:00:53 UTC",
      "updated_date": "2025-05-22 11:00:53 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-25T03:28:18.229819"
    },
    {
      "arxiv_id": "2505.16518v1",
      "title": "CUB: Benchmarking Context Utilisation Techniques for Language Models",
      "title_zh": "CUB：语言模型上下文利用技术的基准测试",
      "authors": [
        "Lovisa Hagström",
        "Youna Kim",
        "Haeun Yu",
        "Sang-goo Lee",
        "Richard Johansson",
        "Hyunsoo Cho",
        "Isabelle Augenstein"
      ],
      "abstract": "Incorporating external knowledge is crucial for knowledge-intensive tasks,\nsuch as question answering and fact checking. However, language models (LMs)\nmay ignore relevant information that contradicts outdated parametric memory or\nbe distracted by irrelevant contexts. While many context utilisation\nmanipulation techniques (CMTs) that encourage or suppress context utilisation\nhave recently been proposed to alleviate these issues, few have seen systematic\ncomparison. In this paper, we develop CUB (Context Utilisation Benchmark) to\nhelp practitioners within retrieval-augmented generation (RAG) identify the\nbest CMT for their needs. CUB allows for rigorous testing on three distinct\ncontext types, observed to capture key challenges in realistic context\nutilisation scenarios. With this benchmark, we evaluate seven state-of-the-art\nmethods, representative of the main categories of CMTs, across three diverse\ndatasets and tasks, applied to nine LMs. Our results show that most of the\nexisting CMTs struggle to handle the full set of types of contexts that may be\nencountered in real-world retrieval-augmented scenarios. Moreover, we find that\nmany CMTs display an inflated performance on simple synthesised datasets,\ncompared to more realistic datasets with naturally occurring samples.\nAltogether, our results show the need for holistic tests of CMTs and the\ndevelopment of CMTs that can handle multiple context types.",
      "tldr_zh": "该论文开发了 CUB（Context Utilisation Benchmark），一个基准测试框架，用于评估上下文利用技术（CMTs）在语言模型（LMs）中的效果，旨在解决 LMs 在检索增强生成（RAG）任务中忽略相关信息或受无关上下文干扰的问题。CUB 通过测试三种不同的上下文类型，并在三个多样化数据集上评估七种最先进的 CMT 方法，应用于九个 LMs。结果显示，大多数 CMTs 难以全面处理真实场景中的多种上下文类型，且在简单合成的数据集上表现被夸大，这突显了需要更整体的测试和开发能适应多种上下文的 CMTs。",
      "categories": [
        "cs.CL",
        "cs.AI"
      ],
      "primary_category": "cs.CL",
      "comment": "27 pages",
      "pdf_url": "http://arxiv.org/pdf/2505.16518v1",
      "published_date": "2025-05-22 10:57:08 UTC",
      "updated_date": "2025-05-22 10:57:08 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-25T03:28:32.137147"
    },
    {
      "arxiv_id": "2505.16516v1",
      "title": "Computing Exact Shapley Values in Polynomial Time for Product-Kernel Methods",
      "title_zh": "在多项式时间内精确计算产品核方法的 Shapley 值",
      "authors": [
        "Majid Mohammadi",
        "Siu Lun Chau",
        "Krikamol Muandet"
      ],
      "abstract": "Kernel methods are widely used in machine learning due to their flexibility\nand expressive power. However, their black-box nature poses significant\nchallenges to interpretability, limiting their adoption in high-stakes\napplications. Shapley value-based feature attribution techniques, such as SHAP\nand kernel-specific variants like RKHS-SHAP, offer a promising path toward\nexplainability. Yet, computing exact Shapley values remains computationally\nintractable in general, motivating the development of various approximation\nschemes. In this work, we introduce PKeX-Shapley, a novel algorithm that\nutilizes the multiplicative structure of product kernels to enable the exact\ncomputation of Shapley values in polynomial time. We show that product-kernel\nmodels admit a functional decomposition that allows for a recursive formulation\nof Shapley values. This decomposition not only yields computational efficiency\nbut also enhances interpretability in kernel-based learning. We also\ndemonstrate how our framework can be generalized to explain kernel-based\nstatistical discrepancies such as the Maximum Mean Discrepancy (MMD) and the\nHilbert-Schmidt Independence Criterion (HSIC), thus offering new tools for\ninterpretable statistical inference.",
      "tldr_zh": "本研究针对核方法（kernel methods）的黑箱问题，提出PKeX-Shapley算法，利用乘积核（product kernels）的乘法结构，在多项式时间内精确计算Shapley values，从而解决传统方法计算密集的问题。算法通过功能分解和递归公式，不仅提升了计算效率，还增强了模型的可解释性，例如支持SHAP和RKHS-SHAP等特征归因技术。进一步，该框架扩展到解释核基于的统计差异，如Maximum Mean Discrepancy (MMD)和Hilbert-Schmidt Independence Criterion (HSIC)，为可解释的统计推理提供新工具。",
      "categories": [
        "cs.LG",
        "cs.AI"
      ],
      "primary_category": "cs.LG",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2505.16516v1",
      "published_date": "2025-05-22 10:53:04 UTC",
      "updated_date": "2025-05-22 10:53:04 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-25T03:28:42.393033"
    },
    {
      "arxiv_id": "2505.16512v1",
      "title": "Beyond Face Swapping: A Diffusion-Based Digital Human Benchmark for Multimodal Deepfake Detection",
      "title_zh": "翻译失败",
      "authors": [
        "Jiaxin Liu",
        "Jia Wang",
        "Saihui Hou",
        "Min Ren",
        "Huijia Wu",
        "Zhaofeng He"
      ],
      "abstract": "In recent years, the rapid development of deepfake technology has given rise\nto an emerging and serious threat to public security: diffusion model-based\ndigital human generation. Unlike traditional face manipulation methods, such\nmodels can generate highly realistic videos with consistency through multimodal\ncontrol signals. Their flexibility and covertness pose severe challenges to\nexisting detection strategies. To bridge this gap, we introduce DigiFakeAV, the\nfirst large-scale multimodal digital human forgery dataset based on diffusion\nmodels. Employing five latest digital human generation methods (Sonic, Hallo,\netc.) and voice cloning method, we systematically produce a dataset comprising\n60,000 videos (8.4 million frames), covering multiple nationalities, skin\ntones, genders, and real-world scenarios, significantly enhancing data\ndiversity and realism. User studies show that the confusion rate between forged\nand real videos reaches 68%, and existing state-of-the-art (SOTA) detection\nmodels exhibit large drops in AUC values on DigiFakeAV, highlighting the\nchallenge of the dataset. To address this problem, we further propose\nDigiShield, a detection baseline based on spatiotemporal and cross-modal\nfusion. By jointly modeling the 3D spatiotemporal features of videos and the\nsemantic-acoustic features of audio, DigiShield achieves SOTA performance on\nboth the DigiFakeAV and DF-TIMIT datasets. Experiments show that this method\neffectively identifies covert artifacts through fine-grained analysis of the\ntemporal evolution of facial features in synthetic videos.",
      "tldr_zh": "本文研究了基于 diffusion models 的数字人类生成技术带来的深假威胁，该技术能通过多模态控制信号创建高度真实的视频，挑战现有检测策略。为此，作者构建了 DigiFakeAV，这是首个大型多模态数字人类伪造数据集，包含 60,000 个视频（8.4 百万帧），覆盖多种国籍、肤色、性别和真实场景，用户研究显示伪造视频与真实视频的混淆率达 68%，导致 SOTA 检测模型的 AUC 值显著下降。针对这一问题，作者提出了 DigiShield 检测基准，该方法通过联合建模视频的 3D 时空特征和音频的语义-声学特征，实现跨模态融合。实验证明，DigiShield 在 DigiFakeAV 和 DF-TIMIT 数据集上达到了 SOTA 性能，能够有效识别合成视频中面部特征的时序演变中的隐蔽伪造痕迹。",
      "categories": [
        "cs.CV",
        "cs.AI"
      ],
      "primary_category": "cs.CV",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2505.16512v1",
      "published_date": "2025-05-22 10:46:37 UTC",
      "updated_date": "2025-05-22 10:46:37 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-25T03:28:57.454335"
    },
    {
      "arxiv_id": "2505.16508v1",
      "title": "Edge-First Language Model Inference: Models, Metrics, and Tradeoffs",
      "title_zh": "边缘优先语言模型推理：模型、指标和权衡",
      "authors": [
        "SiYoung Jang",
        "Roberto Morabito"
      ],
      "abstract": "The widespread adoption of Language Models (LMs) across industries is driving\ninterest in deploying these services across the computing continuum, from the\ncloud to the network edge. This shift aims to reduce costs, lower latency, and\nimprove reliability and privacy. Small Language Models (SLMs), enabled by\nadvances in model compression, are central to this shift, offering a path to\non-device inference on resource-constrained edge platforms. This work examines\nthe interplay between edge and cloud deployments, starting from detailed\nbenchmarking of SLM capabilities on single edge devices, and extending to\ndistributed edge clusters. We identify scenarios where edge inference offers\ncomparable performance with lower costs, and others where cloud fallback\nbecomes essential due to limits in scalability or model capacity. Rather than\nproposing a one-size-fits-all solution, we present platform-level comparisons\nand design insights for building efficient, adaptive LM inference systems\nacross heterogeneous environments.",
      "tldr_zh": "该研究探讨了语言模型（LMs）的边缘优先推理策略，旨在通过将部署从云端扩展到网络边缘来降低成本、延迟并提升可靠性和隐私。作者通过基准测试小型语言模型（SLMs）的能力，包括在单个边缘设备和分布式集群上的表现，识别出边缘推理在某些场景下可提供与云端相当的性能但成本更低，而在可扩展性或模型容量有限时则需依赖云端回退。最终，该工作提供平台级比较和设计见解，帮助构建高效的自适应 LM 推理系统，以适应异构环境。",
      "categories": [
        "cs.DC",
        "cs.AI",
        "cs.NI",
        "cs.PF"
      ],
      "primary_category": "cs.DC",
      "comment": "This paper has been accepted for publication and presentation at the\n  45th IEEE International Conference on Distributed Computing Systems (IEEE\n  ICDCS 2025). The copyright will be transferred to IEEE upon publication in\n  the conference proceedings",
      "pdf_url": "http://arxiv.org/pdf/2505.16508v1",
      "published_date": "2025-05-22 10:43:00 UTC",
      "updated_date": "2025-05-22 10:43:00 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-25T03:29:06.286380"
    },
    {
      "arxiv_id": "2505.16507v1",
      "title": "Relevance for Stability of Verification Status of a Set of Arguments in Incomplete Argumentation Frameworks (with Proofs)",
      "title_zh": "翻译失败",
      "authors": [
        "Anshu Xiong",
        "Songmao Zhang"
      ],
      "abstract": "The notion of relevance was proposed for stability of justification status of\na single argument in incomplete argumentation frameworks (IAFs) in 2024 by\nOdekerken et al. To extend the notion, we study the relevance for stability of\nverification status of a set of arguments in this paper, i.e., the\nuncertainties in an IAF that have to be resolved in some situations so that\nanswering whether a given set of arguments is an extension obtains the same\nresult in every completion of the IAF. Further we propose the notion of strong\nrelevance for describing the necessity of resolution in all situations reaching\nstability. An analysis of complexity reveals that detecting the (strong)\nrelevance for stability of sets of arguments can be accomplished in P time\nunder the most semantics discussed in the paper. We also discuss the difficulty\nin finding tractable methods for relevance detection under grounded semantics.",
      "tldr_zh": "这篇论文扩展了2024年Odekerken等人在不完整的论证框架（incomplete argumentation frameworks, IAFs）中针对单个参数的relevance概念，研究了其对一组参数验证状态稳定性的应用。作者定义了relevance，表示IAF中的不确定性需在某些情况下被解决，以确保一组参数是否为extension的判断在所有IAF完成中保持一致；同时引入了strong relevance，以描述在所有情况下解决不确定性的必要性。复杂度分析显示，在大多数语义下，检测这些（strong）relevance可以在P时间内完成，但在grounded semantics下寻找可计算方法存在困难。",
      "categories": [
        "cs.AI"
      ],
      "primary_category": "cs.AI",
      "comment": "This is a version of paper 'Relevance for Stability of Verification\n  Status of a Set of Arguments in Incomplete Argumentation Frameworks' extented\n  with proofs of the results in the paper",
      "pdf_url": "http://arxiv.org/pdf/2505.16507v1",
      "published_date": "2025-05-22 10:42:16 UTC",
      "updated_date": "2025-05-22 10:42:16 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-25T03:29:19.016055"
    },
    {
      "arxiv_id": "2505.16505v1",
      "title": "Sparse Activation Editing for Reliable Instruction Following in Narratives",
      "title_zh": "翻译失败",
      "authors": [
        "Runcong Zhao",
        "Chengyu Cao",
        "Qinglin Zhu",
        "Xiucheng Lv",
        "Shun Shao",
        "Lin Gui",
        "Ruifeng Xu",
        "Yulan He"
      ],
      "abstract": "Complex narrative contexts often challenge language models' ability to follow\ninstructions, and existing benchmarks fail to capture these difficulties. To\naddress this, we propose Concise-SAE, a training-free framework that improves\ninstruction following by identifying and editing instruction-relevant neurons\nusing only natural language instructions, without requiring labelled data. To\nthoroughly evaluate our method, we introduce FreeInstruct, a diverse and\nrealistic benchmark of 1,212 examples that highlights the challenges of\ninstruction following in narrative-rich settings. While initially motivated by\ncomplex narratives, Concise-SAE demonstrates state-of-the-art instruction\nadherence across varied tasks without compromising generation quality.",
      "tldr_zh": "该研究针对复杂叙事环境中语言模型指令遵循的挑战，提出Concise-SAE框架，这是一种无需训练的稀疏激活编辑(Sparse Activation Editing)方法，通过识别和编辑指令相关的神经元，仅使用自然语言指令即可提升模型性能，而不需标记数据。作为主要贡献，该框架还引入了FreeInstruct基准，共1212个多样化示例，用于评估叙事丰富的指令遵循难题。实验结果显示，Concise-SAE在各种任务中实现了最先进的指令遵守，同时保持了生成质量的稳定性。",
      "categories": [
        "cs.CL",
        "cs.AI",
        "cs.HC"
      ],
      "primary_category": "cs.CL",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2505.16505v1",
      "published_date": "2025-05-22 10:41:35 UTC",
      "updated_date": "2025-05-22 10:41:35 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-25T03:29:29.825086"
    },
    {
      "arxiv_id": "2505.16499v1",
      "title": "Smaller, Smarter, Closer: The Edge of Collaborative Generative AI",
      "title_zh": "翻译失败",
      "authors": [
        "Roberto Morabito",
        "SiYoung Jang"
      ],
      "abstract": "The rapid adoption of generative AI (GenAI), particularly Large Language\nModels (LLMs), has exposed critical limitations of cloud-centric deployments,\nincluding latency, cost, and privacy concerns. Meanwhile, Small Language Models\n(SLMs) are emerging as viable alternatives for resource-constrained edge\nenvironments, though they often lack the capabilities of their larger\ncounterparts. This article explores the potential of collaborative inference\nsystems that leverage both edge and cloud resources to address these\nchallenges. By presenting distinct cooperation strategies alongside practical\ndesign principles and experimental insights, we offer actionable guidance for\ndeploying GenAI across the computing continuum.",
      "tldr_zh": "这篇论文讨论了生成式 AI（Generative AI），尤其是大语言模型（LLMs）的云端部署问题，包括延迟、成本和隐私担忧，并提出小语言模型（SLMs）作为边缘环境的替代方案，但SLMs的能力较弱。论文探索了协作推理系统，通过结合边缘和云端资源，引入多种合作策略、设计原则和实验见解，以解决这些挑战。最终，它提供了可操作的指导，帮助在计算连续体上部署Generative AI，实现更高效的AI应用。",
      "categories": [
        "cs.DC",
        "cs.AI",
        "cs.NI"
      ],
      "primary_category": "cs.DC",
      "comment": "This paper is currently under review for publication in an IEEE\n  magazine. If accepted, the copyright will be transferred to IEEE",
      "pdf_url": "http://arxiv.org/pdf/2505.16499v1",
      "published_date": "2025-05-22 10:34:48 UTC",
      "updated_date": "2025-05-22 10:34:48 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-25T03:29:44.094369"
    },
    {
      "arxiv_id": "2505.16498v1",
      "title": "Human-like Semantic Navigation for Autonomous Driving using Knowledge Representation and Large Language Models",
      "title_zh": "利用知识表示和大语言模型实现自动驾驶的类人语义",
      "authors": [
        "Augusto Luis Ballardini",
        "Miguel Ángel Sotelo"
      ],
      "abstract": "Achieving full automation in self-driving vehicles remains a challenge,\nespecially in dynamic urban environments where navigation requires real-time\nadaptability. Existing systems struggle to handle navigation plans when faced\nwith unpredictable changes in road layouts, spontaneous detours, or missing map\ndata, due to their heavy reliance on predefined cartographic information. In\nthis work, we explore the use of Large Language Models to generate Answer Set\nProgramming rules by translating informal navigation instructions into\nstructured, logic-based reasoning. ASP provides non-monotonic reasoning,\nallowing autonomous vehicles to adapt to evolving scenarios without relying on\npredefined maps. We present an experimental evaluation in which LLMs generate\nASP constraints that encode real-world urban driving logic into a formal\nknowledge representation. By automating the translation of informal navigation\ninstructions into logical rules, our method improves adaptability and\nexplainability in autonomous navigation. Results show that LLM-driven ASP rule\ngeneration supports semantic-based decision-making, offering an explainable\nframework for dynamic navigation planning that aligns closely with how humans\ncommunicate navigational intent.",
      "tldr_zh": "该论文探讨了如何利用知识表示和大型语言模型（LLMs）实现更像人类的语义导航，以解决自动驾驶车辆在动态城市环境中的适应性挑战。方法包括使用LLMs将非正式导航指令翻译成Answer Set Programming（ASP）规则，ASP通过非单调推理帮助车辆应对突发变化，而不依赖预定义地图。实验评估显示，这种LLM驱动的ASP规则生成提高了导航的适应性和可解释性，支持基于语义的决策决策，并与人类沟通导航意图高度一致。",
      "categories": [
        "cs.RO",
        "cs.AI"
      ],
      "primary_category": "cs.RO",
      "comment": "7 pages, 5 figures, submitted for IEEE conference",
      "pdf_url": "http://arxiv.org/pdf/2505.16498v1",
      "published_date": "2025-05-22 10:32:43 UTC",
      "updated_date": "2025-05-22 10:32:43 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-25T03:29:54.118150"
    },
    {
      "arxiv_id": "2505.16491v1",
      "title": "LLaMAs Have Feelings Too: Unveiling Sentiment and Emotion Representations in LLaMA Models Through Probing",
      "title_zh": "翻译失败",
      "authors": [
        "Dario Di Palma",
        "Alessandro De Bellis",
        "Giovanni Servedio",
        "Vito Walter Anelli",
        "Fedelucio Narducci",
        "Tommaso Di Noia"
      ],
      "abstract": "Large Language Models (LLMs) have rapidly become central to NLP,\ndemonstrating their ability to adapt to various tasks through prompting\ntechniques, including sentiment analysis. However, we still have a limited\nunderstanding of how these models capture sentiment-related information. This\nstudy probes the hidden layers of Llama models to pinpoint where sentiment\nfeatures are most represented and to assess how this affects sentiment\nanalysis.\n  Using probe classifiers, we analyze sentiment encoding across layers and\nscales, identifying the layers and pooling methods that best capture sentiment\nsignals. Our results show that sentiment information is most concentrated in\nmid-layers for binary polarity tasks, with detection accuracy increasing up to\n14% over prompting techniques. Additionally, we find that in decoder-only\nmodels, the last token is not consistently the most informative for sentiment\nencoding. Finally, this approach enables sentiment tasks to be performed with\nmemory requirements reduced by an average of 57%.\n  These insights contribute to a broader understanding of sentiment in LLMs,\nsuggesting layer-specific probing as an effective approach for sentiment tasks\nbeyond prompting, with potential to enhance model utility and reduce memory\nrequirements.",
      "tldr_zh": "这篇论文探讨了大型语言模型 (LLMs) 如 Llama 模型中情感和情绪表示的机制，通过 probe classifiers 分析隐藏层以定位情感特征。研究发现，情感信息在二元极性任务中主要集中在中间层，检测准确率比传统提示技术高出 14%，且在解码器-only 模型中，最后一个 token 并非总是最信息丰富。该方法显著降低了情感任务的内存需求，平均减少 57%，并为提升模型实用性和情感分析效率提供了新见解。",
      "categories": [
        "cs.CL",
        "cs.AI"
      ],
      "primary_category": "cs.CL",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2505.16491v1",
      "published_date": "2025-05-22 10:22:39 UTC",
      "updated_date": "2025-05-22 10:22:39 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-25T03:30:05.790615"
    },
    {
      "arxiv_id": "2505.16483v1",
      "title": "Teaching Large Language Models to Maintain Contextual Faithfulness via Synthetic Tasks and Reinforcement Learning",
      "title_zh": "翻译失败",
      "authors": [
        "Shuzheng Si",
        "Haozhe Zhao",
        "Cheng Gao",
        "Yuzhuo Bai",
        "Zhitong Wang",
        "Bofei Gao",
        "Kangyang Luo",
        "Wenhao Li",
        "Yufei Huang",
        "Gang Chen",
        "Fanchao Qi",
        "Minjia Zhang",
        "Baobao Chang",
        "Maosong Sun"
      ],
      "abstract": "Teaching large language models (LLMs) to be faithful in the provided context\nis crucial for building reliable information-seeking systems. Therefore, we\npropose a systematic framework, CANOE, to improve the faithfulness of LLMs in\nboth short-form and long-form generation tasks without human annotations.\nSpecifically, we first synthesize short-form question-answering (QA) data with\nfour diverse tasks to construct high-quality and easily verifiable training\ndata without human annotation. Also, we propose Dual-GRPO, a rule-based\nreinforcement learning method that includes three tailored rule-based rewards\nderived from synthesized short-form QA data, while simultaneously optimizing\nboth short-form and long-form response generation. Notably, Dual-GRPO\neliminates the need to manually label preference data to train reward models\nand avoids over-optimizing short-form generation when relying only on the\nsynthesized short-form QA data. Experimental results show that CANOE greatly\nimproves the faithfulness of LLMs across 11 different downstream tasks, even\noutperforming the most advanced LLMs, e.g., GPT-4o and OpenAI o1.",
      "tldr_zh": "该研究提出CANOE框架，用于提升大型语言模型(LLMs)在短文和长文生成任务中的上下文忠实度(faithfulness)，无需人工标注。具体方法包括合成四种多样化短文问答(QA)任务来生成高质量训练数据，以及Dual-GRPO——一种基于规则的强化学习(reinforcement learning)方法，利用三个从合成数据派生的规则奖励，同时优化短文和长文响应。Dual-GRPO避免了手动标注偏好数据和过优化问题。实验结果显示，CANOE在11个下游任务上显著提高了LLMs的表现，甚至超过了GPT-4o和OpenAI o1等先进模型。",
      "categories": [
        "cs.CL",
        "cs.AI"
      ],
      "primary_category": "cs.CL",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2505.16483v1",
      "published_date": "2025-05-22 10:10:07 UTC",
      "updated_date": "2025-05-22 10:10:07 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-25T03:30:17.993099"
    },
    {
      "arxiv_id": "2505.16482v1",
      "title": "Minimizing the energy depletion in wireless rechargeable sensor networks using bi-level metaheuristic charging schemes",
      "title_zh": "利用双层元启发式充电方案最小化无线可充电传感器网络中的能量耗尽",
      "authors": [
        "Huynh Thi Thanh Binh",
        "Le Van Cuong",
        "Dang Hai Dang",
        "Le Trong Vinh"
      ],
      "abstract": "Recently, Wireless Rechargeable Sensor Networks (WRSNs) that leveraged the\nadvantage of wireless energy transfer technology have opened a promising\nopportunity in solving the limited energy issue. However, an ineffective\ncharging strategy may reduce the charging performance. Although many practical\ncharging algorithms have been introduced, these studies mainly focus on\noptimizing the charging path with a fully charging approach. This approach may\nlead to the death of a series of sensors due to their extended charging\nlatency. This paper introduces a novel partial charging approach that follows a\nbi-level optimized scheme to minimize energy depletion in WRSNs. We aim at\noptimizing simultaneously two factors: the charging path and time. To\naccomplish this, we first formulate a mathematical model of the investigated\nproblem. We then propose two approximate algorithms in which the optimization\nof the charging path and the charging time are considered as the upper and\nlower level, respectively. The first algorithm combines a Multi-start Local\nSearch method and a Genetic Algorithm to find a solution. The second algorithm\nadopts a nested approach that utilizes the advantages of the Multitasking and\nCovariance Matrix Adaptation Evolutionary Strategies. Experimental validations\non various network scenarios demonstrate that our proposed algorithms\noutperform the existing works.",
      "tldr_zh": "本文针对无线可充电传感器网络(WRSNs)中的能量耗尽问题，提出了一种新型部分充电方法，使用bi-level optimized scheme同时优化充电路径和充电时间，以避免传统完全充电方式导致的传感器延迟耗尽。研究首先建立了数学模型，然后开发了两个近似算法：第一个结合Multi-start Local Search和Genetic Algorithm处理上层路径优化；第二个采用Multitasking和Covariance Matrix Adaptation Evolutionary Strategies的嵌套方法。实验验证显示，这些算法在多种网络场景下比现有工作性能更优，提升了WRSNs的整体效率。",
      "categories": [
        "cs.AI",
        "cs.NE"
      ],
      "primary_category": "cs.AI",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2505.16482v1",
      "published_date": "2025-05-22 10:09:21 UTC",
      "updated_date": "2025-05-22 10:09:21 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-25T03:30:31.521539"
    },
    {
      "arxiv_id": "2505.16477v1",
      "title": "Advancing the Scientific Method with Large Language Models: From Hypothesis to Discovery",
      "title_zh": "使用大型语言模型推进科学方法：从假设到发现",
      "authors": [
        "Yanbo Zhang",
        "Sumeer A. Khan",
        "Adnan Mahmud",
        "Huck Yang",
        "Alexander Lavin",
        "Michael Levin",
        "Jeremy Frey",
        "Jared Dunnmon",
        "James Evans",
        "Alan Bundy",
        "Saso Dzeroski",
        "Jesper Tegner",
        "Hector Zenil"
      ],
      "abstract": "With recent Nobel Prizes recognising AI contributions to science, Large\nLanguage Models (LLMs) are transforming scientific research by enhancing\nproductivity and reshaping the scientific method. LLMs are now involved in\nexperimental design, data analysis, and workflows, particularly in chemistry\nand biology. However, challenges such as hallucinations and reliability\npersist. In this contribution, we review how Large Language Models (LLMs) are\nredefining the scientific method and explore their potential applications\nacross different stages of the scientific cycle, from hypothesis testing to\ndiscovery. We conclude that, for LLMs to serve as relevant and effective\ncreative engines and productivity enhancers, their deep integration into all\nsteps of the scientific process should be pursued in collaboration and\nalignment with human scientific goals, with clear evaluation metrics. The\ntransition to AI-driven science raises ethical questions about creativity,\noversight, and responsibility. With careful guidance, LLMs could evolve into\ncreative engines, driving transformative breakthroughs across scientific\ndisciplines responsibly and effectively. However, the scientific community must\nalso decide how much it leaves to LLMs to drive science, even when associations\nwith 'reasoning', mostly currently undeserved, are made in exchange for the\npotential to explore hypothesis and solution regions that might otherwise\nremain unexplored by human exploration alone.",
      "tldr_zh": "本论文探讨了Large Language Models (LLMs) 如何推进科学方法，从假设测试到发现，强调其在实验设计、数据分析和工作流程中的作用，尤其在化学和生物学领域。LLMs 提升了研究生产力，但面临幻觉 (hallucinations) 和可靠性等挑战。作者建议通过与人类目标深度协作、制定清晰评估指标，并解决伦理问题如创造力、监督和责任，来实现 LLMs 作为创新引擎的有效整合，从而驱动科学领域的变革性突破。",
      "categories": [
        "cs.AI"
      ],
      "primary_category": "cs.AI",
      "comment": "45 pages",
      "pdf_url": "http://arxiv.org/pdf/2505.16477v1",
      "published_date": "2025-05-22 10:05:48 UTC",
      "updated_date": "2025-05-22 10:05:48 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-25T03:30:45.929539"
    },
    {
      "arxiv_id": "2505.16475v1",
      "title": "ReflectEvo: Improving Meta Introspection of Small LLMs by Learning Self-Reflection",
      "title_zh": "翻译失败",
      "authors": [
        "Jiaqi Li",
        "Xinyi Dong",
        "Yang Liu",
        "Zhizhuo Yang",
        "Quansen Wang",
        "Xiaobo Wang",
        "SongChun Zhu",
        "Zixia Jia",
        "Zilong Zheng"
      ],
      "abstract": "We present a novel pipeline, ReflectEvo, to demonstrate that small language\nmodels (SLMs) can enhance meta introspection through reflection learning. This\nprocess iteratively generates self-reflection for self-training, fostering a\ncontinuous and self-evolving process. Leveraging this pipeline, we construct\nReflectEvo-460k, a large-scale, comprehensive, self-generated reflection\ndataset with broadened instructions and diverse multi-domain tasks. Building\nupon this dataset, we demonstrate the effectiveness of reflection learning to\nimprove SLMs' reasoning abilities using SFT and DPO with remarkable\nperformance, substantially boosting Llama-3 from 52.4% to 71.2% and Mistral\nfrom 44.4% to 71.1%. It validates that ReflectEvo can rival or even surpass the\nreasoning capability of the three prominent open-sourced models on BIG-bench\nwithout distillation from superior models or fine-grained human annotation. We\nfurther conduct a deeper analysis of the high quality of self-generated\nreflections and their impact on error localization and correction. Our work\nhighlights the potential of continuously enhancing the reasoning performance of\nSLMs through iterative reflection learning in the long run.",
      "tldr_zh": "本研究提出ReflectEvo管道，通过反射学习（self-reflection）帮助小型语言模型（SLMs）提升元内省能力，该过程采用迭代生成自我反射进行自我训练，实现模型的持续演化。研究构建了ReflectEvo-460k数据集，一个大规模的自我生成反射数据集，涵盖广泛指令和多领域任务，并通过SFT（Supervised Fine-Tuning）和DPO（Direct Preference Optimization）训练，显著提升SLMs的推理性能，例如将Llama-3从52.4%提升到71.2%，Mistral从44.4%提升到71.1%。实验结果显示，ReflectEvo在BIG-bench基准上可与或超过知名开源模型的性能，而无需依赖模型蒸馏或精细人工标注，进一步分析表明，高质量的自我生成反射有助于错误定位和修正，展示了SLMs通过迭代反射学习长期提升潜力的价值。",
      "categories": [
        "cs.AI"
      ],
      "primary_category": "cs.AI",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2505.16475v1",
      "published_date": "2025-05-22 10:03:05 UTC",
      "updated_date": "2025-05-22 10:03:05 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-25T03:30:55.687234"
    },
    {
      "arxiv_id": "2505.16466v1",
      "title": "Conf-GNNRec: Quantifying and Calibrating the Prediction Confidence for GNN-based Recommendation Methods",
      "title_zh": "Conf-GNNRec：量化与校准基于 GNN 的推荐",
      "authors": [
        "Meng Yan",
        "Cai Xu",
        "Xujing Wang",
        "Ziyu Guan",
        "Wei Zhao",
        "Yuhang Zhou"
      ],
      "abstract": "Recommender systems based on graph neural networks perform well in tasks such\nas rating and ranking. However, in real-world recommendation scenarios, noise\nsuch as user misuse and malicious advertisement gradually accumulates through\nthe message propagation mechanism. Even if existing studies mitigate their\neffects by reducing the noise propagation weights, the severe sparsity of the\nrecommender system still leads to the low-weighted noisy neighbors being\nmistaken as meaningful information, and the prediction result obtained based on\nthe polluted nodes is not entirely trustworthy. Therefore, it is crucial to\nmeasure the confidence of the prediction results in this highly noisy\nframework. Furthermore, our evaluation of the existing representative GNN-based\nrecommendation shows that it suffers from overconfidence. Based on the above\nconsiderations, we propose a new method to quantify and calibrate the\nprediction confidence of GNN-based recommendations (Conf-GNNRec). Specifically,\nwe propose a rating calibration method that dynamically adjusts excessive\nratings to mitigate overconfidence based on user personalization. We also\ndesign a confidence loss function to reduce the overconfidence of negative\nsamples and effectively improve recommendation performance. Experiments on\npublic datasets demonstrate the validity of Conf-GNNRec in prediction\nconfidence and recommendation performance.",
      "tldr_zh": "该研究针对基于图神经网络(GNN-based)推荐系统的问题，指出噪音积累和稀疏性导致预测结果过度自信，从而影响可靠性。提出Conf-GNNRec方法，包括一个基于用户个性化的评分校准机制来动态调整过度评分，以及一个置信度损失函数(confidence loss function)来减少负样本的过度自信，从而量化并校准预测置信度。实验在公共数据集上验证了Conf-GNNRec的有效性，不仅提升了预测置信度，还显著提高了推荐性能。",
      "categories": [
        "cs.IR",
        "cs.AI"
      ],
      "primary_category": "cs.IR",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2505.16466v1",
      "published_date": "2025-05-22 09:48:17 UTC",
      "updated_date": "2025-05-22 09:48:17 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-25T03:31:06.800011"
    },
    {
      "arxiv_id": "2505.16460v1",
      "title": "University of Indonesia at SemEval-2025 Task 11: Evaluating State-of-the-Art Encoders for Multi-Label Emotion Detection",
      "title_zh": "翻译失败",
      "authors": [
        "Ikhlasul Akmal Hanif",
        "Eryawan Presma Yulianrifat",
        "Jaycent Gunawan Ongris",
        "Eduardus Tjitrahardja",
        "Muhammad Falensi Azmi",
        "Rahmat Bryan Naufal",
        "Alfan Farizki Wicaksono"
      ],
      "abstract": "This paper presents our approach for SemEval 2025 Task 11 Track A, focusing\non multilabel emotion classification across 28 languages. We explore two main\nstrategies: fully fine-tuning transformer models and classifier-only training,\nevaluating different settings such as fine-tuning strategies, model\narchitectures, loss functions, encoders, and classifiers. Our findings suggest\nthat training a classifier on top of prompt-based encoders such as mE5 and BGE\nyields significantly better results than fully fine-tuning XLMR and mBERT. Our\nbest-performing model on the final leaderboard is an ensemble combining\nmultiple BGE models, where CatBoost serves as the classifier, with different\nconfigurations. This ensemble achieves an average F1-macro score of 56.58\nacross all languages.",
      "tldr_zh": "这篇论文介绍了University of Indonesia在SemEval-2025 Task 11 Track A中的方法，评估了多种最先进编码器在28种语言的多标签情感检测中的性能。他们比较了完全微调transformer模型（如XLMR和mBERT）和仅训练分类器的策略，发现基于prompt的编码器如mE5和BGE结合分类器训练的效果显著优于前者。最终，他们的最佳模型是一个结合多个BGE模型的集成，使用CatBoost作为分类器，在所有语言上实现了平均F1-macro分数56.58。",
      "categories": [
        "cs.CL",
        "cs.AI",
        "I.2.7"
      ],
      "primary_category": "cs.CL",
      "comment": "16 pages, 13 tables, 1 figures",
      "pdf_url": "http://arxiv.org/pdf/2505.16460v1",
      "published_date": "2025-05-22 09:42:11 UTC",
      "updated_date": "2025-05-22 09:42:11 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-25T03:31:18.678245"
    },
    {
      "arxiv_id": "2505.16459v1",
      "title": "MMMR: Benchmarking Massive Multi-Modal Reasoning Tasks",
      "title_zh": "MMMR：大规模多模态推理任务的基准测试",
      "authors": [
        "Guiyao Tie",
        "Xueyang Zhou",
        "Tianhe Gu",
        "Ruihang Zhang",
        "Chaoran Hu",
        "Sizhe Zhang",
        "Mengqu Sun",
        "Yan Zhang",
        "Pan Zhou",
        "Lichao Sun"
      ],
      "abstract": "Recent advances in Multi-Modal Large Language Models (MLLMs) have enabled\nunified processing of language, vision, and structured inputs, opening the door\nto complex tasks such as logical deduction, spatial reasoning, and scientific\nanalysis. Despite their promise, the reasoning capabilities of MLLMs,\nparticularly those augmented with intermediate thinking traces (MLLMs-T),\nremain poorly understood and lack standardized evaluation benchmarks. Existing\nwork focuses primarily on perception or final answer correctness, offering\nlimited insight into how models reason or fail across modalities. To address\nthis gap, we introduce the MMMR, a new benchmark designed to rigorously\nevaluate multi-modal reasoning with explicit thinking. The MMMR comprises 1) a\nhigh-difficulty dataset of 1,083 questions spanning six diverse reasoning types\nwith symbolic depth and multi-hop demands and 2) a modular Reasoning Trace\nEvaluation Pipeline (RTEP) for assessing reasoning quality beyond accuracy\nthrough metrics like relevance, consistency, and structured error annotations.\nEmpirical results show that MLLMs-T overall outperform non-thinking\ncounterparts, but even top models like Claude-3.7-Sonnet and Gemini-2.5 Pro\nsuffer from reasoning pathologies such as inconsistency and overthinking. This\nbenchmark reveals persistent gaps between accuracy and reasoning quality and\nprovides an actionable evaluation pipeline for future model development.\nOverall, the MMMR offers a scalable foundation for evaluating, comparing, and\nimproving the next generation of multi-modal reasoning systems.",
      "tldr_zh": "本研究引入了 MMMR 基准，用于评估多模态大语言模型 (MLLMs) 的推理能力，特别是那些使用中间思考痕迹的 MLLMs-T 模型，以填补现有评估的不足。MMMR 包括一个包含 1083 个高难度问题的数据集，涵盖六种推理类型（如逻辑推演和空间推理），要求符号深度和多跳推理，以及一个模块化的 Reasoning Trace Evaluation Pipeline (RTEP)，通过相关性、一致性和结构化错误注释等指标评估推理质量。实验结果显示，MLLMs-T 模型整体优于非思考模型，但顶级模型如 Claude-3.7-Sonnet 和 Gemini-2.5 Pro 仍存在不一致性和过度思考等问题。该基准揭示了准确性和推理质量之间的差距，并为未来多模态推理系统的开发提供可扩展的评估框架。",
      "categories": [
        "cs.AI"
      ],
      "primary_category": "cs.AI",
      "comment": "39 pages, 28 figures, 4 tables",
      "pdf_url": "http://arxiv.org/pdf/2505.16459v1",
      "published_date": "2025-05-22 09:41:55 UTC",
      "updated_date": "2025-05-22 09:41:55 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-25T03:31:30.190391"
    },
    {
      "arxiv_id": "2505.16455v1",
      "title": "Psychology-driven LLM Agents for Explainable Panic Prediction on Social Media during Sudden Disaster Events",
      "title_zh": "心理学驱动的 LLM 代理用于突发灾害事件期间社交媒体的可解释恐慌预测",
      "authors": [
        "Mengzhu Liu",
        "Zhengqiu Zhu",
        "Chuan Ai",
        "Chen Gao",
        "Xinghong Li",
        "Lingnan He",
        "Kaisheng Lai",
        "Yingfeng Chen",
        "Xin Lu",
        "Yong Li",
        "Quanjun Yin"
      ],
      "abstract": "During sudden disaster events, accurately predicting public panic sentiment\non social media is crucial for proactive governance and crisis management.\nCurrent efforts on this problem face three main challenges: lack of finely\nannotated data hinders emotion prediction studies, unmodeled risk perception\ncauses prediction inaccuracies, and insufficient interpretability of panic\nformation mechanisms. We address these issues by proposing a Psychology-driven\ngenerative Agent framework (PsychoAgent) for explainable panic prediction based\non emotion arousal theory. Specifically, we first construct a fine-grained open\npanic emotion dataset (namely COPE) via human-large language models (LLMs)\ncollaboration to mitigate semantic bias. Then, we develop a framework\nintegrating cross-domain heterogeneous data grounded in psychological\nmechanisms to model risk perception and cognitive differences in emotion\ngeneration. To enhance interpretability, we design an LLM-based role-playing\nagent that simulates individual psychological chains through dedicatedly\ndesigned prompts. Experimental results on our annotated dataset show that\nPsychoAgent improves panic emotion prediction performance by 12.6% to 21.7%\ncompared to baseline models. Furthermore, the explainability and generalization\nof our approach is validated. Crucially, this represents a paradigm shift from\nopaque \"data-driven fitting\" to transparent \"role-based simulation with\nmechanistic interpretation\" for panic emotion prediction during emergencies.\nOur implementation is publicly available at:\nhttps://anonymous.4open.science/r/PsychoAgent-19DD.",
      "tldr_zh": "该研究针对突发灾害事件中社交媒体恐慌情绪预测的挑战，提出了一种基于心理学驱动的生成代理框架（PsychoAgent），以提升预测的准确性和解释性。具体而言，该框架首先通过人类和大语言模型（LLMs）协作构建了一个精细的恐慌情绪数据集（COPE），并整合跨域异构数据来模拟风险感知和认知差异；同时，设计LLMs-based角色扮演代理模拟个体的心理链条，提供机制解释。实验结果显示，PsychoAgent 相比基线模型将恐慌情绪预测性能提升12.6%至21.7%，并验证了其解释性和泛化能力，标志着从“数据驱动拟合”向“基于角色的模拟与机制解释”的范式转变。",
      "categories": [
        "cs.AI",
        "cs.CY"
      ],
      "primary_category": "cs.AI",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2505.16455v1",
      "published_date": "2025-05-22 09:39:39 UTC",
      "updated_date": "2025-05-22 09:39:39 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-25T03:31:43.811742"
    },
    {
      "arxiv_id": "2505.16452v1",
      "title": "CMRINet: Joint Groupwise Registration and Segmentation for Cardiac Function Quantification from Cine-MRI",
      "title_zh": "CMRINet：联合组间配准和",
      "authors": [
        "Mohamed S. Elmahdy",
        "Marius Staring",
        "Patrick J. H. de Koning",
        "Samer Alabed",
        "Mahan Salehi",
        "Faisal Alandejani",
        "Michael Sharkey",
        "Ziad Aldabbagh",
        "Andrew J. Swift",
        "Rob J. van der Geest"
      ],
      "abstract": "Accurate and efficient quantification of cardiac function is essential for\nthe estimation of prognosis of cardiovascular diseases (CVDs). One of the most\ncommonly used metrics for evaluating cardiac pumping performance is left\nventricular ejection fraction (LVEF). However, LVEF can be affected by factors\nsuch as inter-observer variability and varying pre-load and after-load\nconditions, which can reduce its reproducibility. Additionally, cardiac\ndysfunction may not always manifest as alterations in LVEF, such as in heart\nfailure and cardiotoxicity diseases. An alternative measure that can provide a\nrelatively load-independent quantitative assessment of myocardial contractility\nis myocardial strain and strain rate. By using LVEF in combination with\nmyocardial strain, it is possible to obtain a thorough description of cardiac\nfunction. Automated estimation of LVEF and other volumetric measures from\ncine-MRI sequences can be achieved through segmentation models, while strain\ncalculation requires the estimation of tissue displacement between sequential\nframes, which can be accomplished using registration models. These tasks are\noften performed separately, potentially limiting the assessment of cardiac\nfunction. To address this issue, in this study we propose an end-to-end deep\nlearning (DL) model that jointly estimates groupwise (GW) registration and\nsegmentation for cardiac cine-MRI images. The proposed anatomically-guided Deep\nGW network was trained and validated on a large dataset of 4-chamber view\ncine-MRI image series of 374 subjects. A quantitative comparison with\nconventional GW registration using elastix and two DL-based methods showed that\nthe proposed model improved performance and substantially reduced computation\ntime.",
      "tldr_zh": "本文提出 CMRINet，一种端到端深度学习模型，联合 groupwise registration 和 segmentation，从 cine-MRI 图像中量化心脏功能，以解决传统 LVEF 评估的局限性，如受观察者变异性和负载条件影响的问题。该模型通过 anatomically-guided Deep GW network 同时估计心肌应变和体积指标，提高了评估的准确性和效率。在包含 374 个受试者的 4-chamber view cine-MRI 数据集上实验验证，CMRINet 相较于 elastix 和其他 DL 方法，性能提升显著，并将计算时间大幅减少。",
      "categories": [
        "cs.CV",
        "cs.AI",
        "cs.LG"
      ],
      "primary_category": "cs.CV",
      "comment": "15 pages, 7 figures, 1 appendix",
      "pdf_url": "http://arxiv.org/pdf/2505.16452v1",
      "published_date": "2025-05-22 09:36:42 UTC",
      "updated_date": "2025-05-22 09:36:42 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-25T03:31:54.874066"
    },
    {
      "arxiv_id": "2505.16448v1",
      "title": "Internal Bias in Reasoning Models leads to Overthinking",
      "title_zh": "推理模型中的内部偏差导致过度思考",
      "authors": [
        "Renfei Dang",
        "Shujian Huang",
        "Jiajun Chen"
      ],
      "abstract": "While current reasoning models possess strong exploratory capabilities, they\nare often criticized for overthinking due to redundant and unnecessary\nreflections. In this work, we reveal for the first time that overthinking in\nreasoning models may stem from their internal bias towards input texts. Upon\nencountering a reasoning problem, the model immediately forms a preliminary\nguess about the answer, which we term as an internal bias since it is not\nderived through actual reasoning. When this guess conflicts with its reasoning\nresult, the model tends to engage in reflection, leading to the waste of\ncomputational resources. Through further interpretability experiments, we find\nthat this behavior is largely driven by the model's excessive attention to the\ninput section, which amplifies the influence of internal bias on its\ndecision-making process. Additionally, by masking out the original input\nsection, the affect of internal bias can be effectively alleviated and the\nreasoning length could be reduced by 31%-53% across different complex reasoning\ntasks. Notably, in most cases, this approach also leads to improvements in\naccuracy. These findings demonstrate a causal relationship between internal\nbias and overthinking.",
      "tldr_zh": "本文研究发现，推理模型的overthinking问题源于内部偏见(internal bias)，即模型在遇到问题时立即基于输入文本形成初步猜测，而非通过实际推理，导致与推理结果冲突时产生冗余思考。研究通过可解释性实验揭示，这种行为主要是模型过度关注输入部分，放大内部偏见对决策的影响。实验结果显示，屏蔽原始输入部分可有效缓解内部偏见，减少推理长度31%-53%，并在大多数复杂任务中提升准确性。这些发现首次证明了内部偏见与overthinking之间的因果关系。",
      "categories": [
        "cs.AI"
      ],
      "primary_category": "cs.AI",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2505.16448v1",
      "published_date": "2025-05-22 09:35:52 UTC",
      "updated_date": "2025-05-22 09:35:52 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-25T03:32:07.103246"
    },
    {
      "arxiv_id": "2505.16430v1",
      "title": "AutoMCQ -- Automatically Generate Code Comprehension Questions using GenAI",
      "title_zh": "翻译失败",
      "authors": [
        "Martin Goodfellow",
        "Robbie Booth",
        "Andrew Fagan",
        "Alasdair Lambert"
      ],
      "abstract": "Students often do not fully understand the code they have written. This\nsometimes does not become evident until later in their education, which can\nmean it is harder to fix their incorrect knowledge or misunderstandings. In\naddition, being able to fully understand code is increasingly important in a\nworld where students have access to generative artificial intelligence (GenAI)\ntools, such as GitHub Copilot. One effective solution is to utilise code\ncomprehension questions, where a marker asks questions about a submission to\ngauge understanding, this can also have the side effect of helping to detect\nplagiarism. However, this approach is time consuming and can be difficult\nand/or expensive to scale. This paper introduces AutoMCQ, which uses GenAI for\nthe automatic generation of multiple-choice code comprehension questions. This\nis integrated with the CodeRunner automated assessment platform.",
      "tldr_zh": "学生经常不完全理解他们编写的代码，这可能导致后期纠正错误知识的难度增加，尤其在生成式人工智能(GenAI)工具如 GitHub Copilot 普及的时代。本文引入 AutoMCQ，一种利用 GenAI 自动生成多选代码理解问题的系统，以评估学生的代码理解水平并辅助检测抄袭。该系统集成到 CodeRunner 自动评估平台中，解决了传统手动提问的耗时和可扩展性问题，提高了教育评估的效率和规模。",
      "categories": [
        "cs.SE",
        "cs.AI",
        "cs.PL"
      ],
      "primary_category": "cs.SE",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2505.16430v1",
      "published_date": "2025-05-22 09:14:41 UTC",
      "updated_date": "2025-05-22 09:14:41 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-25T03:32:18.384511"
    },
    {
      "arxiv_id": "2505.16429v1",
      "title": "Beyond Static Testbeds: An Interaction-Centric Agent Simulation Platform for Dynamic Recommender Systems",
      "title_zh": "超越静态测试平台：以交互为中心的多智能体模拟平台，用于动态推荐系统",
      "authors": [
        "Song Jin",
        "Juntian Zhang",
        "Yuhan Liu",
        "Xun Zhang",
        "Yufei Zhang",
        "Guojun Yin",
        "Fei Jiang",
        "Wei Lin",
        "Rui Yan"
      ],
      "abstract": "Evaluating and iterating upon recommender systems is crucial, yet traditional\nA/B testing is resource-intensive, and offline methods struggle with dynamic\nuser-platform interactions. While agent-based simulation is promising, existing\nplatforms often lack a mechanism for user actions to dynamically reshape the\nenvironment. To bridge this gap, we introduce RecInter, a novel agent-based\nsimulation platform for recommender systems featuring a robust interaction\nmechanism. In RecInter platform, simulated user actions (e.g., likes, reviews,\npurchases) dynamically update item attributes in real-time, and introduced\nMerchant Agents can reply, fostering a more realistic and evolving ecosystem.\nHigh-fidelity simulation is ensured through Multidimensional User Profiling\nmodule, Advanced Agent Architecture, and LLM fine-tuned on Chain-of-Thought\n(CoT) enriched interaction data. Our platform achieves significantly improved\nsimulation credibility and successfully replicates emergent phenomena like\nBrand Loyalty and the Matthew Effect. Experiments demonstrate that this\ninteraction mechanism is pivotal for simulating realistic system evolution,\nestablishing our platform as a credible testbed for recommender systems\nresearch.",
      "tldr_zh": "该论文指出，传统 A/B testing 资源密集且离线方法难以处理动态用户-平台交互，因此提出 RecInter，一种新型的基于代理的模拟平台，用于动态推荐系统。RecInter 通过模拟用户行为（如点赞、评论、购买）实时更新项目属性，并引入 Merchant Agents 进行回复，同时利用 Multidimensional User Profiling 模块、Advanced Agent Architecture 和基于 Chain-of-Thought (CoT) 丰富的交互数据微调的 LLM，确保高保真模拟。实验结果显示，该平台显著提升了模拟可信度，成功复制了 Brand Loyalty 和 Matthew Effect 等现实现象，并证明交互机制对模拟系统演化至关重要。",
      "categories": [
        "cs.CL",
        "cs.AI"
      ],
      "primary_category": "cs.CL",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2505.16429v1",
      "published_date": "2025-05-22 09:14:23 UTC",
      "updated_date": "2025-05-22 09:14:23 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-25T03:32:30.977796"
    },
    {
      "arxiv_id": "2505.16425v1",
      "title": "$I^2G$: Generating Instructional Illustrations via Text-Conditioned Diffusion",
      "title_zh": "$I^2G$：通过文本条件扩散生成教学插图",
      "authors": [
        "Jing Bi",
        "Pinxin Liu",
        "Ali Vosoughi",
        "Jiarui Wu",
        "Jinxi He",
        "Chenliang Xu"
      ],
      "abstract": "The effective communication of procedural knowledge remains a significant\nchallenge in natural language processing (NLP), as purely textual instructions\noften fail to convey complex physical actions and spatial relationships. We\naddress this limitation by proposing a language-driven framework that\ntranslates procedural text into coherent visual instructions. Our approach\nmodels the linguistic structure of instructional content by decomposing it into\ngoal statements and sequential steps, then conditioning visual generation on\nthese linguistic elements. We introduce three key innovations: (1) a\nconstituency parser-based text encoding mechanism that preserves semantic\ncompleteness even with lengthy instructions, (2) a pairwise discourse coherence\nmodel that maintains consistency across instruction sequences, and (3) a novel\nevaluation protocol specifically designed for procedural language-to-image\nalignment. Our experiments across three instructional datasets (HTStep,\nCaptainCook4D, and WikiAll) demonstrate that our method significantly\noutperforms existing baselines in generating visuals that accurately reflect\nthe linguistic content and sequential nature of instructions. This work\ncontributes to the growing body of research on grounding procedural language in\nvisual content, with applications spanning education, task guidance, and\nmultimodal language understanding.",
      "tldr_zh": "该论文提出$I^2G$框架，通过Text-Conditioned Diffusion模型，将程序性文本指令转化为连贯的视觉说明，以解决文本在传达复杂物理动作和空间关系时的局限性。框架的关键创新包括：(1) 基于成分解析器的文本编码机制，确保语义完整性；(2) 配对话语连贯性模型，维持指令序列的一致性；以及(3) 一种专为程序性语言到图像对齐设计的评估协议。在HTStep、CaptainCook4D和WikiAll数据集上的实验显示，该方法显著优于现有基线，生成的视觉内容更准确地反映指令的顺序和细节。该工作推动了程序性语言在视觉内容中的grounding，应用于教育、任务指导和多模态语言理解领域。",
      "categories": [
        "cs.CL",
        "cs.AI"
      ],
      "primary_category": "cs.CL",
      "comment": "13 pages, 5 figures, under review",
      "pdf_url": "http://arxiv.org/pdf/2505.16425v1",
      "published_date": "2025-05-22 09:10:09 UTC",
      "updated_date": "2025-05-22 09:10:09 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-25T03:32:43.875285"
    },
    {
      "arxiv_id": "2505.16419v1",
      "title": "Investigating Fine- and Coarse-grained Structural Correspondences Between Deep Neural Networks and Human Object Image Similarity Judgments Using Unsupervised Alignment",
      "title_zh": "使用无监督对齐方法调查深度神经网络与人类物体图像相似性判断之间的细粒度和粗粒度结构对应关系",
      "authors": [
        "Soh Takahashi",
        "Masaru Sasaki",
        "Ken Takeda",
        "Masafumi Oizumi"
      ],
      "abstract": "The learning mechanisms by which humans acquire internal representations of\nobjects are not fully understood. Deep neural networks (DNNs) have emerged as a\nuseful tool for investigating this question, as they have internal\nrepresentations similar to those of humans as a byproduct of optimizing their\nobjective functions. While previous studies have shown that models trained with\nvarious learning paradigms - such as supervised, self-supervised, and CLIP -\nacquire human-like representations, it remains unclear whether their similarity\nto human representations is primarily at a coarse category level or extends to\nfiner details. Here, we employ an unsupervised alignment method based on\nGromov-Wasserstein Optimal Transport to compare human and model object\nrepresentations at both fine-grained and coarse-grained levels. The unique\nfeature of this method compared to conventional representational similarity\nanalysis is that it estimates optimal fine-grained mappings between the\nrepresentation of each object in human and model representations. We used this\nunsupervised alignment method to assess the extent to which the representation\nof each object in humans is correctly mapped to the corresponding\nrepresentation of the same object in models. Using human similarity judgments\nof 1,854 objects from the THINGS dataset, we find that models trained with CLIP\nconsistently achieve strong fine- and coarse-grained matching with human object\nrepresentations. In contrast, self-supervised models showed limited matching at\nboth fine- and coarse-grained levels, but still formed object clusters that\nreflected human coarse category structure. Our results offer new insights into\nthe role of linguistic information in acquiring precise object representations\nand the potential of self-supervised learning to capture coarse categorical\nstructures.",
      "tldr_zh": "本研究调查了深度神经网络(DNNs)与人类物体图像相似性判断在细粒度和粗粒度结构上的对应关系，使用基于Gromov-Wasserstein Optimal Transport的无监督对齐方法。研究者通过该方法估计人类和模型中每个物体的最优映射，并利用THINGS数据集的1,854个物体相似性判断进行评估。结果显示，CLIP训练的模型在细粒度和粗粒度上均与人类物体表示高度匹配，而自监督模型仅在粗粒度层面显示有限匹配，但能反映人类粗类别结构。这些发现揭示了语言信息在获取精确物体表示中的关键作用，并突显了自监督学习捕捉粗类别结构的潜力。",
      "categories": [
        "cs.CV",
        "cs.AI"
      ],
      "primary_category": "cs.CV",
      "comment": "34 pages, 6 figures",
      "pdf_url": "http://arxiv.org/pdf/2505.16419v1",
      "published_date": "2025-05-22 09:06:06 UTC",
      "updated_date": "2025-05-22 09:06:06 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-25T03:32:54.463882"
    },
    {
      "arxiv_id": "2505.16416v1",
      "title": "Circle-RoPE: Cone-like Decoupled Rotary Positional Embedding for Large Vision-Language Models",
      "title_zh": "翻译失败",
      "authors": [
        "Chengcheng Wang",
        "Jianyuan Guo",
        "Hongguang Li",
        "Yuchuan Tian",
        "Ying Nie",
        "Chang Xu",
        "Kai Han"
      ],
      "abstract": "Rotary Position Embedding (RoPE) is a widely adopted technique for encoding\nrelative positional information in large language models (LLMs). However, when\nextended to large vision-language models (LVLMs), its variants introduce\nunintended cross-modal positional biases. Specifically, they enforce relative\npositional dependencies between text token indices and image tokens, causing\nspurious alignments. This issue arises because image tokens representing the\nsame content but located at different spatial positions are assigned distinct\npositional biases, leading to inconsistent cross-modal associations. To address\nthis, we propose Per-Token Distance (PTD) - a simple yet effective metric for\nquantifying the independence of positional encodings across modalities.\nInformed by this analysis, we introduce Circle-RoPE, a novel encoding scheme\nthat maps image token indices onto a circular trajectory orthogonal to the\nlinear path of text token indices, forming a cone-like structure. This\nconfiguration ensures that each text token maintains an equal distance to all\nimage tokens, reducing artificial cross-modal biases while preserving\nintra-image spatial information. To further enhance performance, we propose a\nstaggered layer strategy that applies different RoPE variants across layers.\nThis design leverages the complementary strengths of each RoPE variant, thereby\nenhancing the model's overall performance. Our experimental results demonstrate\nthat our method effectively preserves spatial information from images while\nreducing relative positional bias, offering a more robust and flexible\npositional encoding framework for LVLMs. The code is available at\n[https://github.com/lose4578/CircleRoPE](https://github.com/lose4578/CircleRoPE).",
      "tldr_zh": "该研究发现，Rotary Position Embedding (RoPE) 在扩展到大型视觉语言模型 (LVLMs) 时，会引入跨模态位置偏差，导致图像标记位置差异造成虚假对齐问题。为解决此问题，作者提出 Per-Token Distance (PTD) 作为量化位置编码独立性的指标，并引入 Circle-RoPE 编码方案，将图像标记索引映射到与文本标记正交的圆形轨迹，形成锥状结构，从而减少偏差同时保留图像空间信息。进一步，论文采用分层策略（staggered layer strategy）在不同层应用各种 RoPE 变体，实验结果显示该方法显著提升 LVLMs 的稳健性和性能，提供了一个更灵活的框架。",
      "categories": [
        "cs.CV",
        "cs.AI"
      ],
      "primary_category": "cs.CV",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2505.16416v1",
      "published_date": "2025-05-22 09:05:01 UTC",
      "updated_date": "2025-05-22 09:05:01 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-25T03:33:07.631207"
    },
    {
      "arxiv_id": "2505.16415v1",
      "title": "Attributing Response to Context: A Jensen-Shannon Divergence Driven Mechanistic Study of Context Attribution in Retrieval-Augmented Generation",
      "title_zh": "翻译失败",
      "authors": [
        "Ruizhe Li",
        "Chen Chen",
        "Yuchen Hu",
        "Yanjun Gao",
        "Xi Wang",
        "Emine Yilmaz"
      ],
      "abstract": "Retrieval-Augmented Generation (RAG) leverages large language models (LLMs)\ncombined with external contexts to enhance the accuracy and reliability of\ngenerated responses. However, reliably attributing generated content to\nspecific context segments, context attribution, remains challenging due to the\ncomputationally intensive nature of current methods, which often require\nextensive fine-tuning or human annotation. In this work, we introduce a novel\nJensen-Shannon Divergence driven method to Attribute Response to Context\n(ARC-JSD), enabling efficient and accurate identification of essential context\nsentences without additional fine-tuning or surrogate modelling. Evaluations on\na wide range of RAG benchmarks, such as TyDi QA, Hotpot QA, and Musique, using\ninstruction-tuned LLMs in different scales demonstrate superior accuracy and\nsignificant computational efficiency improvements compared to the previous\nsurrogate-based method. Furthermore, our mechanistic analysis reveals specific\nattention heads and multilayer perceptron (MLP) layers responsible for context\nattribution, providing valuable insights into the internal workings of RAG\nmodels.",
      "tldr_zh": "本研究针对 Retrieval-Augmented Generation (RAG) 中上下文归因的挑战，提出了一种基于 Jensen-Shannon Divergence 的新方法 ARC-JSD，能够高效准确地识别生成响应中关键的上下文句子，而无需额外微调或代理模型。在 TyDi QA、Hotpot QA 和 Musique 等基准测试中使用不同规模的指令调整 LLMs 时，ARC-JSD 展现出比现有方法更高的准确性和显著的计算效率改进。通过机制分析，该方法揭示了 RAG 模型中负责上下文归因的具体注意力头和 MLP 层，为理解模型内部工作提供了重要洞见。",
      "categories": [
        "cs.CL",
        "cs.AI",
        "cs.LG"
      ],
      "primary_category": "cs.CL",
      "comment": "Work in process",
      "pdf_url": "http://arxiv.org/pdf/2505.16415v1",
      "published_date": "2025-05-22 09:04:03 UTC",
      "updated_date": "2025-05-22 09:04:03 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-25T03:33:19.394009"
    },
    {
      "arxiv_id": "2505.16410v1",
      "title": "Tool-Star: Empowering LLM-Brained Multi-Tool Reasoner via Reinforcement Learning",
      "title_zh": "翻译失败",
      "authors": [
        "Guanting Dong",
        "Yifei Chen",
        "Xiaoxi Li",
        "Jiajie Jin",
        "Hongjin Qian",
        "Yutao Zhu",
        "Hangyu Mao",
        "Guorui Zhou",
        "Zhicheng Dou",
        "Ji-Rong Wen"
      ],
      "abstract": "Recently, large language models (LLMs) have shown remarkable reasoning\ncapabilities via large-scale reinforcement learning (RL). However, leveraging\nthe RL algorithm to empower effective multi-tool collaborative reasoning in\nLLMs remains an open challenge. In this paper, we introduce Tool-Star, an\nRL-based framework designed to empower LLMs to autonomously invoke multiple\nexternal tools during stepwise reasoning. Tool-Star integrates six types of\ntools and incorporates systematic designs in both data synthesis and training.\nTo address the scarcity of tool-use data, we propose a general tool-integrated\nreasoning data synthesis pipeline, which combines tool-integrated prompting\nwith hint-based sampling to automatically and scalably generate tool-use\ntrajectories. A subsequent quality normalization and difficulty-aware\nclassification process filters out low-quality samples and organizes the\ndataset from easy to hard. Furthermore, we propose a two-stage training\nframework to enhance multi-tool collaborative reasoning by: (1) cold-start\nfine-tuning, which guides LLMs to explore reasoning patterns via\ntool-invocation feedback; and (2) a multi-tool self-critic RL algorithm with\nhierarchical reward design, which reinforces reward understanding and promotes\neffective tool collaboration. Experimental analyses on over 10 challenging\nreasoning benchmarks highlight the effectiveness and efficiency of Tool-Star.\nThe code is available at https://github.com/dongguanting/Tool-Star.",
      "tldr_zh": "该研究引入了Tool-Star框架，利用强化学习（RL）增强大型语言模型（LLMs）在多工具协作推理中的能力，允许LLMs自主调用多种外部工具进行逐步推理。框架包括一个通用的工具集成推理数据合成管道，通过tool-integrated prompting和hint-based sampling自动生成工具使用轨迹，并结合质量归一化和难度aware分类来优化数据集。此外，采用两阶段训练方法：cold-start fine-tuning引导模型探索工具调用模式，以及multi-tool self-critic RL算法通过分层奖励设计提升工具协作效率。实验在超过10个挑战性推理基准上证明了Tool-Star的有效性和高效性，代码已在GitHub开源。",
      "categories": [
        "cs.CL",
        "cs.AI",
        "cs.LG"
      ],
      "primary_category": "cs.CL",
      "comment": "Working in progress",
      "pdf_url": "http://arxiv.org/pdf/2505.16410v1",
      "published_date": "2025-05-22 09:00:19 UTC",
      "updated_date": "2025-05-22 09:00:19 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-25T03:33:30.660315"
    },
    {
      "arxiv_id": "2505.16409v1",
      "title": "FREESON: Retriever-Free Retrieval-Augmented Reasoning via Corpus-Traversing MCTS",
      "title_zh": "翻译失败",
      "authors": [
        "Chaeeun Kim",
        "Seungone Kim"
      ],
      "abstract": "Large Reasoning Models (LRMs) have demonstrated remarkable capabilities in\nmulti-step reasoning and calling search engines at appropriate steps. However,\nexisting retrieval-augmented reasoning approaches rely on separate retrieval\nmodels, limiting the LRM's role in retrieval to deciding when to retrieve and\nhow to query. This separation not only increases hardware and operational costs\nbut also leads to errors in the retrieval process due to the representation\nbottleneck, a phenomenon where the retriever's embedding space is not\nexpressive enough to meet the generator's requirements. To address this, we\nshift our perspective from sequence-to-sequence matching to locating the\nanswer-containing paths within the corpus, and propose a novel framework called\nFREESON (Retriever-FREE Retrieval-Augmented ReaSONing). This framework enables\nLRMs to retrieve relevant knowledge on their own by acting as both a generator\nand retriever. To achieve this, we introduce a variant of the MCTS algorithm\nspecialized for the retrieval task, which we call CT-MCTS (Corpus-Traversing\nMonte Carlo Tree Search). In this algorithm, LRMs traverse through the corpus\ntoward answer-containing regions. Our results on five open-domain QA\nbenchmarks, including single-hop and multi-hop questions, show that FREESON\nachieves an average improvement of 14.4% in EM and F1 over four multi-step\nreasoning models with a separate retriever, and it also performs comparably to\nthe strongest baseline, surpassing it by 3% on PopQA and 2WikiMultihopQA.",
      "tldr_zh": "该研究针对现有检索增强推理方法的依赖于单独检索模型的问题，提出了 FREESON 框架，让 Large Reasoning Models (LRMs) 自主担任生成器和检索器角色，以避免硬件成本增加和表示瓶颈。FREESON 引入了 CT-MCTS (Corpus-Traversing Monte Carlo Tree Search) 算法，使 LRMs 通过遍历语料库定位包含答案的路径，从而实现高效的多步推理。实验结果显示，在五个开放域 QA 基准上，FREESON 比使用单独检索器的多步推理模型平均提高 14.4% 的 EM 和 F1 分数，并在 PopQA 和 2WikiMultihopQA 上分别超越最强基线 3%。",
      "categories": [
        "cs.AI"
      ],
      "primary_category": "cs.AI",
      "comment": "Work In Progress",
      "pdf_url": "http://arxiv.org/pdf/2505.16409v1",
      "published_date": "2025-05-22 09:00:08 UTC",
      "updated_date": "2025-05-22 09:00:08 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-25T03:33:43.146264"
    },
    {
      "arxiv_id": "2505.16400v1",
      "title": "AceReason-Nemotron: Advancing Math and Code Reasoning through Reinforcement Learning",
      "title_zh": "AceReason-Nemotron：通过强化学习推进数学和代码推理",
      "authors": [
        "Yang Chen",
        "Zhuolin Yang",
        "Zihan Liu",
        "Chankyu Lee",
        "Peng Xu",
        "Mohammad Shoeybi",
        "Bryan Catanzaro",
        "Wei Ping"
      ],
      "abstract": "Despite recent progress in large-scale reinforcement learning (RL) for\nreasoning, the training recipe for building high-performing reasoning models\nremains elusive. Key implementation details of frontier models, such as\nDeepSeek-R1, including data curation strategies and RL training recipe, are\noften omitted. Moreover, recent research indicates distillation remains more\neffective than RL for smaller models. In this work, we demonstrate that\nlarge-scale RL can significantly enhance the reasoning capabilities of strong,\nsmall- and mid-sized models, achieving results that surpass those of\nstate-of-the-art distillation-based models. We systematically study the RL\ntraining process through extensive ablations and propose a simple yet effective\napproach: first training on math-only prompts, then on code-only prompts.\nNotably, we find that math-only RL not only significantly enhances the\nperformance of strong distilled models on math benchmarks (e.g., +14.6% /\n+17.2% on AIME 2025 for the 7B / 14B models), but also code reasoning tasks\n(e.g., +6.8% / +5.8% on LiveCodeBench for the 7B / 14B models). In addition,\nextended code-only RL iterations further improve performance on code benchmarks\nwith minimal or no degradation in math results. We develop a robust data\ncuration pipeline to collect challenging prompts with high-quality, verifiable\nanswers and test cases to enable verification-based RL across both domains.\nFinally, we identify key experimental insights, including curriculum learning\nwith progressively increasing response lengths and the stabilizing effect of\non-policy parameter updates. We find that RL not only elicits the foundational\nreasoning capabilities acquired during pretraining and supervised fine-tuning\n(e.g., distillation), but also pushes the limits of the model's reasoning\nability, enabling it to solve problems that were previously unsolvable.",
      "tldr_zh": "本文提出 AceReason-Nemotron 模型，通过大规模 Reinforcement Learning (RL) 显著提升小中型模型的数学和代码推理能力，超越基于 distillation 的现有最先进模型。研究采用简单有效的训练策略：先在数学提示上进行 RL 训练（例如，提升 AIME 2025 基准上 7B/14B 模型的性能分别 +14.6%/+17.2%），随后扩展到代码提示，进一步优化代码任务（如 LiveCodeBench 上 +6.8%/+5.8%）。他们开发了稳健的数据 curation 管道以收集高质量、可验证提示，并发现课程学习（如渐进式响应长度增加）和 on-policy 参数更新能稳定训练过程。最终，RL 不仅激发了模型在预训练和监督微调中的基础推理能力，还推动其解决之前无法处理的问题。",
      "categories": [
        "cs.LG",
        "cs.AI",
        "cs.CL"
      ],
      "primary_category": "cs.LG",
      "comment": "We release the model at:\n  https://huggingface.co/nvidia/AceReason-Nemotron-14B",
      "pdf_url": "http://arxiv.org/pdf/2505.16400v1",
      "published_date": "2025-05-22 08:50:47 UTC",
      "updated_date": "2025-05-22 08:50:47 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-25T03:33:55.799971"
    },
    {
      "arxiv_id": "2505.16394v1",
      "title": "Raw2Drive: Reinforcement Learning with Aligned World Models for End-to-End Autonomous Driving (in CARLA v2)",
      "title_zh": "翻译失败",
      "authors": [
        "Zhenjie Yang",
        "Xiaosong Jia",
        "Qifeng Li",
        "Xue Yang",
        "Maoqing Yao",
        "Junchi Yan"
      ],
      "abstract": "Reinforcement Learning (RL) can mitigate the causal confusion and\ndistribution shift inherent to imitation learning (IL). However, applying RL to\nend-to-end autonomous driving (E2E-AD) remains an open problem for its training\ndifficulty, and IL is still the mainstream paradigm in both academia and\nindustry. Recently Model-based Reinforcement Learning (MBRL) have demonstrated\npromising results in neural planning; however, these methods typically require\nprivileged information as input rather than raw sensor data. We fill this gap\nby designing Raw2Drive, a dual-stream MBRL approach. Initially, we efficiently\ntrain an auxiliary privileged world model paired with a neural planner that\nuses privileged information as input. Subsequently, we introduce a raw sensor\nworld model trained via our proposed Guidance Mechanism, which ensures\nconsistency between the raw sensor world model and the privileged world model\nduring rollouts. Finally, the raw sensor world model combines the prior\nknowledge embedded in the heads of the privileged world model to effectively\nguide the training of the raw sensor policy. Raw2Drive is so far the only RL\nbased end-to-end method on CARLA Leaderboard 2.0, and Bench2Drive and it\nachieves state-of-the-art performance.",
      "tldr_zh": "这篇论文提出 Raw2Drive，一种基于 Model-based Reinforcement Learning (MBRL) 的双流框架，用于端到端自动驾驶 (E2E-AD)，旨在解决 Reinforcement Learning (RL) 在训练难度和原始传感器数据处理方面的挑战，同时避免 Imitation Learning (IL) 的因果混淆和分布偏移问题。方法首先训练一个辅助的特权世界模型配以神经规划器，然后通过 Guidance Mechanism 确保原始传感器世界模型与特权世界模型在 rollout 中保持一致，并利用特权模型的先验知识指导原始传感器策略的训练。实验结果显示，Raw2Drive 在 CARLA Leaderboard 2.0 和 Bench2Drive 上作为首个基于 RL 的端到端方法，实现了 state-of-the-art 性能。",
      "categories": [
        "cs.RO",
        "cs.AI",
        "cs.CV"
      ],
      "primary_category": "cs.RO",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2505.16394v1",
      "published_date": "2025-05-22 08:46:53 UTC",
      "updated_date": "2025-05-22 08:46:53 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-25T03:34:07.278521"
    },
    {
      "arxiv_id": "2505.16392v1",
      "title": "Resource for Error Analysis in Text Simplification: New Taxonomy and Test Collection",
      "title_zh": "文本简化错误分析资源：新分类法和测试集合",
      "authors": [
        "Benjamin Vendeville",
        "Liana Ermakova",
        "Pierre De Loor"
      ],
      "abstract": "The general public often encounters complex texts but does not have the time\nor expertise to fully understand them, leading to the spread of misinformation.\nAutomatic Text Simplification (ATS) helps make information more accessible, but\nits evaluation methods have not kept up with advances in text generation,\nespecially with Large Language Models (LLMs). In particular, recent studies\nhave shown that current ATS metrics do not correlate with the presence of\nerrors. Manual inspections have further revealed a variety of errors,\nunderscoring the need for a more nuanced evaluation framework, which is\ncurrently lacking. This resource paper addresses this gap by introducing a test\ncollection for detecting and classifying errors in simplified texts. First, we\npropose a taxonomy of errors, with a formal focus on information distortion.\nNext, we introduce a parallel dataset of automatically simplified scientific\ntexts. This dataset has been human-annotated with labels based on our proposed\ntaxonomy. Finally, we analyze the quality of the dataset, and we study the\nperformance of existing models to detect and classify errors from that\ntaxonomy. These contributions give researchers the tools to better evaluate\nerrors in ATS, develop more reliable models, and ultimately improve the quality\nof automatically simplified texts.",
      "tldr_zh": "这篇论文针对Automatic Text Simplification (ATS) 的错误分析问题，提出一个新的错误taxonomy，特别强调信息扭曲，以填补当前评价方法的不足，尤其是与Large Language Models (LLMs) 相关的挑战。研究者创建了一个平行数据集，包含自动简化的科学文本，并由人类根据该taxonomy进行标注。最终，通过分析数据集质量和评估现有模型的错误检测与分类性能，该资源为改进ATS的可靠性和文本质量提供了重要工具。",
      "categories": [
        "cs.CL",
        "cs.AI",
        "I.2.6; I.5.2"
      ],
      "primary_category": "cs.CL",
      "comment": "Accepted at SIGIR 2025",
      "pdf_url": "http://arxiv.org/pdf/2505.16392v1",
      "published_date": "2025-05-22 08:45:14 UTC",
      "updated_date": "2025-05-22 08:45:14 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-25T03:34:18.741816"
    },
    {
      "arxiv_id": "2505.16388v1",
      "title": "Serious Games: Human-AI Interaction, Evolution, and Coevolution",
      "title_zh": "翻译失败",
      "authors": [
        "Nandini Doreswamy",
        "Louise Horstmanshof"
      ],
      "abstract": "The serious games between humans and AI have only just begun. Evolutionary\nGame Theory (EGT) models the competitive and cooperative strategies of\nbiological entities. EGT could help predict the potential evolutionary\nequilibrium of humans and AI. The objective of this work was to examine some of\nthe EGT models relevant to human-AI interaction, evolution, and coevolution. Of\nthirteen EGT models considered, three were examined: the Hawk-Dove Game,\nIterated Prisoner's Dilemma, and the War of Attrition. This selection was based\non the widespread acceptance and clear relevance of these models to potential\nhuman-AI evolutionary dynamics and coevolutionary trajectories. The Hawk-Dove\nGame predicts balanced mixed-strategy equilibria based on the costs of\nconflict. It also shows the potential for balanced coevolution rather than\ndominance. Iterated Prisoner's Dilemma suggests that repeated interaction may\nlead to cognitive coevolution. It demonstrates how memory and reciprocity can\nlead to cooperation. The War of Attrition suggests that competition for\nresources may result in strategic coevolution, asymmetric equilibria, and\nconventions on sharing resources. Therefore, EGT may provide a suitable\nframework to understand and predict the human-AI evolutionary dynamic. However,\nfuture research could extend beyond EGT and explore additional frameworks,\nempirical validation methods, and interdisciplinary perspectives. AI is being\nshaped by human input and is evolving in response to it. So too,\nneuroplasticity allows the human brain to grow and evolve in response to\nstimuli. If humans and AI converge in future, what might be the result of human\nneuroplasticity combined with an ever-evolving AI? Future research should be\nmindful of the ethical and cognitive implications of human-AI interaction,\nevolution, and coevolution.",
      "tldr_zh": "本研究探讨了进化博弈论 (EGT) 在人类与 AI 互动、进化及共同进化中的应用，旨在预测潜在的进化平衡。论文重点考察了三个 EGT 模型：Hawk-Dove Game、Iterated Prisoner's Dilemma 和 War of Attrition，其中 Hawk-Dove Game 预测基于冲突成本的混合策略平衡，Iterated Prisoner's Dilemma 强调重复互动可能导致合作和认知共同进化，而 War of Attrition 揭示资源竞争可能引发战略共同进化与资源共享约定。总体而言，EGT 提供了一个理解人类-AI 动态的框架，但未来研究应扩展到其他框架、实证验证，并关注伦理及认知影响，如人类神经可塑性与 AI 演变的潜在融合。",
      "categories": [
        "cs.AI",
        "cs.GT",
        "91A22 (Primary), 68T99 (Secondary)",
        "J.4; I.2.0; K.4.1; J.3; K.4.0"
      ],
      "primary_category": "cs.AI",
      "comment": "8 pages, 1 table",
      "pdf_url": "http://arxiv.org/pdf/2505.16388v1",
      "published_date": "2025-05-22 08:41:37 UTC",
      "updated_date": "2025-05-22 08:41:37 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-25T03:34:31.520015"
    },
    {
      "arxiv_id": "2505.16379v1",
      "title": "Materials Generation in the Era of Artificial Intelligence: A Comprehensive Survey",
      "title_zh": "翻译失败",
      "authors": [
        "Zhixun Li",
        "Bin Cao",
        "Rui Jiao",
        "Liang Wang",
        "Ding Wang",
        "Yang Liu",
        "Dingshuo Chen",
        "Jia Li",
        "Qiang Liu",
        "Yu Rong",
        "Liang Wang",
        "Tong-yi Zhang",
        "Jeffrey Xu Yu"
      ],
      "abstract": "Materials are the foundation of modern society, underpinning advancements in\nenergy, electronics, healthcare, transportation, and infrastructure. The\nability to discover and design new materials with tailored properties is\ncritical to solving some of the most pressing global challenges. In recent\nyears, the growing availability of high-quality materials data combined with\nrapid advances in Artificial Intelligence (AI) has opened new opportunities for\naccelerating materials discovery. Data-driven generative models provide a\npowerful tool for materials design by directly create novel materials that\nsatisfy predefined property requirements. Despite the proliferation of related\nwork, there remains a notable lack of up-to-date and systematic surveys in this\narea. To fill this gap, this paper provides a comprehensive overview of recent\nprogress in AI-driven materials generation. We first organize various types of\nmaterials and illustrate multiple representations of crystalline materials. We\nthen provide a detailed summary and taxonomy of current AI-driven materials\ngeneration approaches. Furthermore, we discuss the common evaluation metrics\nand summarize open-source codes and benchmark datasets. Finally, we conclude\nwith potential future directions and challenges in this fast-growing field. The\nrelated sources can be found at\nhttps://github.com/ZhixunLEE/Awesome-AI-for-Materials-Generation.",
      "tldr_zh": "这篇论文对AI时代材料生成进行了全面调查，强调AI结合高质量材料数据能加速新材料的发现和设计，以解决全球性挑战。论文首先组织了各种材料类型及其晶体表示，然后总结并分类了现有的AI驱动生成方法，包括数据驱动模型，并讨论了评估指标、开源代码和基准数据集。最后，它指出了该领域的潜在未来方向和挑战，如进一步优化生成模型，推动材料科学创新。",
      "categories": [
        "cond-mat.mtrl-sci",
        "cs.AI"
      ],
      "primary_category": "cond-mat.mtrl-sci",
      "comment": "Work in progress",
      "pdf_url": "http://arxiv.org/pdf/2505.16379v1",
      "published_date": "2025-05-22 08:33:21 UTC",
      "updated_date": "2025-05-22 08:33:21 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-25T03:34:43.862156"
    },
    {
      "arxiv_id": "2505.16377v1",
      "title": "VL-SAFE: Vision-Language Guided Safety-Aware Reinforcement Learning with World Models for Autonomous Driving",
      "title_zh": "翻译失败",
      "authors": [
        "Yansong Qu",
        "Zilin Huang",
        "Zihao Sheng",
        "Jiancong Chen",
        "Sikai Chen",
        "Samuel Labi"
      ],
      "abstract": "Reinforcement learning (RL)-based autonomous driving policy learning faces\ncritical limitations such as low sample efficiency and poor generalization; its\nreliance on online interactions and trial-and-error learning is especially\nunacceptable in safety-critical scenarios. Existing methods including safe RL\noften fail to capture the true semantic meaning of \"safety\" in complex driving\ncontexts, leading to either overly conservative driving behavior or constraint\nviolations. To address these challenges, we propose VL-SAFE, a world\nmodel-based safe RL framework with Vision-Language model\n(VLM)-as-safety-guidance paradigm, designed for offline safe policy learning.\nSpecifically, we construct offline datasets containing data collected by expert\nagents and labeled with safety scores derived from VLMs. A world model is\ntrained to generate imagined rollouts together with safety estimations,\nallowing the agent to perform safe planning without interacting with the real\nenvironment. Based on these imagined trajectories and safety evaluations,\nactor-critic learning is conducted under VLM-based safety guidance to optimize\nthe driving policy more safely and efficiently. Extensive evaluations\ndemonstrate that VL-SAFE achieves superior sample efficiency, generalization,\nsafety, and overall performance compared to existing baselines. To the best of\nour knowledge, this is the first work that introduces a VLM-guided world\nmodel-based approach for safe autonomous driving. The demo video and code can\nbe accessed at: https://ys-qu.github.io/vlsafe-website/",
      "tldr_zh": "该研究针对强化学习（RL）在自动驾驶中的低样本效率和泛化差问题，提出VL-SAFE框架，这是一个基于世界模型的safe RL方法，利用Vision-Language model (VLM)作为安全指导进行离线政策学习。具体而言，VL-SAFE构建离线数据集并用VLM计算安全分数，训练世界模型生成模拟轨迹和安全估计，从而在不与真实环境交互的情况下优化actor-critic学习，实现更安全高效的驾驶策略。实验结果显示，VL-SAFE在样本效率、泛化、安全性和整体性能上均优于现有基线，这是首个引入VLM-guided世界模型方法的自动驾驶解决方案。",
      "categories": [
        "cs.RO",
        "cs.AI"
      ],
      "primary_category": "cs.RO",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2505.16377v1",
      "published_date": "2025-05-22 08:29:59 UTC",
      "updated_date": "2025-05-22 08:29:59 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-25T03:34:55.236928"
    },
    {
      "arxiv_id": "2505.16376v1",
      "title": "DeCafNet: Delegate and Conquer for Efficient Temporal Grounding in Long Videos",
      "title_zh": "翻译失败",
      "authors": [
        "Zijia Lu",
        "A S M Iftekhar",
        "Gaurav Mittal",
        "Tianjian Meng",
        "Xiawei Wang",
        "Cheng Zhao",
        "Rohith Kukkala",
        "Ehsan Elhamifar",
        "Mei Chen"
      ],
      "abstract": "Long Video Temporal Grounding (LVTG) aims at identifying specific moments\nwithin lengthy videos based on user-provided text queries for effective content\nretrieval. The approach taken by existing methods of dividing video into clips\nand processing each clip via a full-scale expert encoder is challenging to\nscale due to prohibitive computational costs of processing a large number of\nclips in long videos. To address this issue, we introduce DeCafNet, an approach\nemploying ``delegate-and-conquer'' strategy to achieve computation efficiency\nwithout sacrificing grounding performance. DeCafNet introduces a sidekick\nencoder that performs dense feature extraction over all video clips in a\nresource-efficient manner, while generating a saliency map to identify the most\nrelevant clips for full processing by the expert encoder. To effectively\nleverage features from sidekick and expert encoders that exist at different\ntemporal resolutions, we introduce DeCaf-Grounder, which unifies and refines\nthem via query-aware temporal aggregation and multi-scale temporal refinement\nfor accurate grounding. Experiments on two LTVG benchmark datasets demonstrate\nthat DeCafNet reduces computation by up to 47\\% while still outperforming\nexisting methods, establishing a new state-of-the-art for LTVG in terms of both\nefficiency and performance. Our code is available at\nhttps://github.com/ZijiaLewisLu/CVPR2025-DeCafNet.",
      "tldr_zh": "该论文提出DeCafNet框架，采用“delegate-and-conquer”策略来提升Long Video Temporal Grounding (LVTG)任务的效率，该任务旨在基于用户文本查询在长视频中识别特定时刻。DeCafNet引入sidekick encoder高效提取所有视频片段的密集特征并生成saliency map，以筛选出关键片段交由expert encoder处理，同时通过DeCaf-Grounder模块实现query-aware temporal aggregation和multi-scale temporal refinement，统一多分辨率特征以提高grounding准确性。在两个LVTG基准数据集上的实验显示，DeCafNet减少了高达47%的计算量，同时超越现有方法，确立了新的state-of-the-art性能标准。",
      "categories": [
        "cs.CV",
        "cs.AI"
      ],
      "primary_category": "cs.CV",
      "comment": "Accepted by CVPR 2025",
      "pdf_url": "http://arxiv.org/pdf/2505.16376v1",
      "published_date": "2025-05-22 08:29:57 UTC",
      "updated_date": "2025-05-22 08:29:57 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-25T03:35:06.572328"
    },
    {
      "arxiv_id": "2505.16372v1",
      "title": "Temporal and Spatial Feature Fusion Framework for Dynamic Micro Expression Recognition",
      "title_zh": "动态微表情识别的时间和空间特征融合框架",
      "authors": [
        "Feng Liu",
        "Bingyu Nan",
        "Xuezhong Qian",
        "Xiaolan Fu"
      ],
      "abstract": "When emotions are repressed, an individual's true feelings may be revealed\nthrough micro-expressions. Consequently, micro-expressions are regarded as a\ngenuine source of insight into an individual's authentic emotions. However, the\ntransient and highly localised nature of micro-expressions poses a significant\nchallenge to their accurate recognition, with the accuracy rate of\nmicro-expression recognition being as low as 50%, even for professionals. In\norder to address these challenges, it is necessary to explore the field of\ndynamic micro expression recognition (DMER) using multimodal fusion techniques,\nwith special attention to the diverse fusion of temporal and spatial modal\nfeatures. In this paper, we propose a novel Temporal and Spatial feature Fusion\nframework for DMER (TSFmicro). This framework integrates a Retention Network\n(RetNet) and a transformer-based DMER network, with the objective of efficient\nmicro-expression recognition through the capture and fusion of temporal and\nspatial relations. Meanwhile, we propose a novel parallel time-space fusion\nmethod from the perspective of modal fusion, which fuses spatio-temporal\ninformation in high-dimensional feature space, resulting in complementary\n\"where-how\" relationships at the semantic level and providing richer semantic\ninformation for the model. The experimental results demonstrate the superior\nperformance of the TSFmicro method in comparison to other contemporary\nstate-of-the-art methods. This is evidenced by its effectiveness on three\nwell-recognised micro-expression datasets.",
      "tldr_zh": "本论文提出了一种Temporal and Spatial feature Fusion framework for Dynamic Micro Expression Recognition（TSFmicro），旨在解决微表情短暂且局部化的识别挑战，提高情感识别准确率。框架整合了Retention Network (RetNet)和基于Transformer的DMER网络，通过捕捉和融合时间与空间关系，实现高效的动态微表情识别；同时引入一种新型平行时空融合方法，在高维特征空间融合时空信息，提供更丰富的语义水平互补。实验结果显示，TSFmicro在三个知名微表情数据集上优于现有最先进方法，显著提升了识别性能。",
      "categories": [
        "cs.CV",
        "cs.AI"
      ],
      "primary_category": "cs.CV",
      "comment": "17 pages",
      "pdf_url": "http://arxiv.org/pdf/2505.16372v1",
      "published_date": "2025-05-22 08:26:19 UTC",
      "updated_date": "2025-05-22 08:26:19 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-25T03:35:18.367326"
    },
    {
      "arxiv_id": "2505.16368v1",
      "title": "SATURN: SAT-based Reinforcement Learning to Unleash Language Model Reasoning",
      "title_zh": "翻译失败",
      "authors": [
        "Huanyu Liu",
        "Jia Li",
        "Hao Zhu",
        "Kechi Zhang",
        "Yihong Dong",
        "Ge Li"
      ],
      "abstract": "How to design reinforcement learning (RL) tasks that effectively unleash the\nreasoning capability of large language models (LLMs) remains an open question.\nExisting RL tasks (e.g., math, programming, and constructing reasoning tasks)\nsuffer from three key limitations: (1) Scalability. They rely heavily on human\nannotation or expensive LLM synthesis to generate sufficient training data. (2)\nVerifiability. LLMs' outputs are hard to verify automatically and reliably. (3)\nControllable Difficulty. Most tasks lack fine-grained difficulty control,\nmaking it hard to train LLMs to develop reasoning ability from easy to hard.\n  To address these limitations, we propose Saturn, a SAT-based RL framework\nthat uses Boolean Satisfiability (SAT) problems to train and evaluate LLM\nreasoning. Saturn enables scalable task construction, rule-based verification,\nand precise difficulty control. Saturn designs a curriculum learning pipeline\nthat continuously improves LLMs' reasoning capability by constructing SAT tasks\nof increasing difficulty and training LLMs from easy to hard. To ensure stable\ntraining, we design a principled mechanism to control difficulty transitions.\n  We introduce Saturn-2.6k, a dataset of 2,660 SAT problems with varying\ndifficulty. It supports the evaluation of how LLM reasoning changes with\nproblem difficulty. We apply Saturn to DeepSeek-R1-Distill-Qwen and obtain\nSaturn-1.5B and Saturn-7B. We achieve several notable results: (1) On SAT\nproblems, Saturn-1.5B and Saturn-7B achieve average pass@3 improvements of\n+14.0 and +28.1, respectively. (2) On math and programming tasks, Saturn-1.5B\nand Saturn-7B improve average scores by +4.9 and +1.8 on benchmarks (e.g.,\nAIME, LiveCodeBench). (3) Compared to the state-of-the-art (SOTA) approach in\nconstructing RL tasks, Saturn achieves further improvements of +8.8%. We\nrelease the source code, data, and models to support future research.",
      "tldr_zh": "该研究提出SATURN框架，利用Boolean Satisfiability (SAT)问题来训练和评估大型语言模型(LLMs)的推理能力，解决现有强化学习(RL)任务在可扩展性、验证性和难度控制方面的局限。SATURN通过课程学习管道构建从易到难的SAT任务，并设计机制控制难度过渡，以逐步提升LLMs的推理能力；同时，引入Saturn-2.6k数据集，包含2660个不同难度的SAT问题用于评估。实验结果显示，在SAT问题上，Saturn-1.5B和Saturn-7B模型的pass@3平均提升分别为+14.0和+28.1；在数学和编程基准（如AIME、LiveCodeBench）上，成绩分别提升+4.9和+1.8，与现有最先进方法相比进一步提高+8.8%。",
      "categories": [
        "cs.LG",
        "cs.AI"
      ],
      "primary_category": "cs.LG",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2505.16368v1",
      "published_date": "2025-05-22 08:23:10 UTC",
      "updated_date": "2025-05-22 08:23:10 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-25T03:35:32.706004"
    },
    {
      "arxiv_id": "2505.16365v1",
      "title": "A collaborative constrained graph diffusion model for the generation of realistic synthetic molecules",
      "title_zh": "一种协作约束的图扩散模型，用于生成真实合成分子",
      "authors": [
        "Manuel Ruiz-Botella",
        "Marta Sales-Pardo",
        "Roger Guimerà"
      ],
      "abstract": "Developing new molecular compounds is crucial to address pressing challenges,\nfrom health to environmental sustainability. However, exploring the molecular\nspace to discover new molecules is difficult due to the vastness of the space.\nHere we introduce CoCoGraph, a collaborative and constrained graph diffusion\nmodel capable of generating molecules that are guaranteed to be chemically\nvalid. Thanks to the constraints built into the model and to the collaborative\nmechanism, CoCoGraph outperforms state-of-the-art approaches on standard\nbenchmarks while requiring up to an order of magnitude fewer parameters.\nAnalysis of 36 chemical properties also demonstrates that CoCoGraph generates\nmolecules with distributions more closely matching real molecules than current\nmodels. Leveraging the model's efficiency, we created a database of 8.2M\nmillion synthetically generated molecules and conducted a Turing-like test with\norganic chemistry experts to further assess the plausibility of the generated\nmolecules, and potential biases and limitations of CoCoGraph.",
      "tldr_zh": "本文介绍了 CoCoGraph，一种协作(constrained)图 diffusion model，用于生成化学有效的合成分子，以应对分子空间庞大带来的探索挑战。该模型通过内置约束和协作机制，在标准基准上超越现有方法，同时参数量减少一个数量级，并生成更接近真实分子的分布。研究者利用模型效率创建了 820 万合成分子数据库，并通过图灵测试与有机化学专家评估了分子的真实性、潜在偏差和局限性。",
      "categories": [
        "cs.LG",
        "cs.AI",
        "physics.comp-ph",
        "q-bio.QM"
      ],
      "primary_category": "cs.LG",
      "comment": "28 pages, 10 figures, 4 tables",
      "pdf_url": "http://arxiv.org/pdf/2505.16365v1",
      "published_date": "2025-05-22 08:21:27 UTC",
      "updated_date": "2025-05-22 08:21:27 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-25T03:35:45.202298"
    },
    {
      "arxiv_id": "2505.16363v1",
      "title": "AdamS: Momentum Itself Can Be A Normalizer for LLM Pretraining and Post-training",
      "title_zh": "翻译失败",
      "authors": [
        "Huishuai Zhang",
        "Bohan Wang",
        "Luoxin Chen"
      ],
      "abstract": "We introduce AdamS, a simple yet effective alternative to Adam for large\nlanguage model (LLM) pretraining and post-training. By leveraging a novel\ndenominator, i.e., the root of weighted sum of squares of the momentum and the\ncurrent gradient, AdamS eliminates the need for second-moment estimates. Hence,\nAdamS is efficient, matching the memory and compute footprint of SGD with\nmomentum while delivering superior optimization performance. Moreover, AdamS is\neasy to adopt: it can directly inherit hyperparameters of AdamW, and is\nentirely model-agnostic, integrating seamlessly into existing pipelines without\nmodifications to optimizer APIs or architectures. The motivation behind AdamS\nstems from the observed $(L_0, L_1)$ smoothness properties in transformer\nobjectives, where local smoothness is governed by gradient magnitudes that can\nbe further approximated by momentum magnitudes. We establish rigorous\ntheoretical convergence guarantees and provide practical guidelines for\nhyperparameter selection. Empirically, AdamS demonstrates strong performance in\nvarious tasks, including pre-training runs on GPT-2 and Llama2 (up to 13B\nparameters) and reinforcement learning in post-training regimes. With its\nefficiency, simplicity, and theoretical grounding, AdamS stands as a compelling\nalternative to existing optimizers.",
      "tldr_zh": "本研究引入了 AdamS，一种简单有效的优化器，用于大型语言模型 (LLM) 的预训练和后训练，通过利用动量作为标准化器来消除第二阶矩估计的需求。AdamS 以动量和当前梯度的加权平方和的平方根作为新分母，从而在内存和计算开销上与 SGD with momentum 相当，同时提供更优的优化性能。该方法基于 transformer 目标的 (L0, L1) 平滑性属性，并提供了严格的理论收敛保证以及超参数选择的实用指南。实验结果显示，AdamS 在 GPT-2 和 Llama2 (高达 13B 参数) 的预训练，以及后训练中的强化学习任务中表现出色，证明了其作为现有优化器替代方案的强大潜力。",
      "categories": [
        "cs.LG",
        "cs.AI",
        "stat.ML"
      ],
      "primary_category": "cs.LG",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2505.16363v1",
      "published_date": "2025-05-22 08:16:48 UTC",
      "updated_date": "2025-05-22 08:16:48 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-25T03:35:57.360823"
    },
    {
      "arxiv_id": "2505.16362v1",
      "title": "Neuromorphic-based metaheuristics: A new generation of low power, low latency and small footprint optimization algorithms",
      "title_zh": "基于神经形态的元启发式算法：新一代低功耗、低",
      "authors": [
        "El-ghazali Talbi"
      ],
      "abstract": "Neuromorphic computing (NC) introduces a novel algorithmic paradigm\nrepresenting a major shift from traditional digital computing of Von Neumann\narchitectures. NC emulates or simulates the neural dynamics of brains in the\nform of Spiking Neural Networks (SNNs). Much of the research in NC has\nconcentrated on machine learning applications and neuroscience simulations.\nThis paper investigates the modelling and implementation of optimization\nalgorithms and particularly metaheuristics using the NC paradigm as an\nalternative to Von Neumann architectures, leading to breakthroughs in solving\noptimization problems.\n  Neuromorphic-based metaheuristics (Nheuristics) are supposed to be\ncharacterized by low power, low latency and small footprint. Since NC systems\nare fundamentally different from conventional Von Neumann computers, several\nchallenges are posed to the design and implementation of Nheuristics. A\nguideline based on a classification and critical analysis is conducted on the\ndifferent families of metaheuristics and optimization problems they address. We\nalso discuss future directions that need to be addressed to expand both the\ndevelopment and application of Nheuristics.",
      "tldr_zh": "这篇论文探讨了神经形态计算（NC）作为一种新型计算范式，用于开发元启发式算法（metaheuristics），以取代传统冯·诺依曼架构，从而实现低功耗、低延迟和小占用空间的优化算法。作者提出神经形态元启发式（Nheuristics），通过模拟脉冲神经网络（SNNs）的神经动态来解决各种优化问题，并对不同metaheuristics家族进行了分类和批判性分析，以提供设计指导。论文还讨论了面临的挑战和未来发展方向，以推动Nheuristics的广泛应用。",
      "categories": [
        "cs.NE",
        "cs.AI"
      ],
      "primary_category": "cs.NE",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2505.16362v1",
      "published_date": "2025-05-22 08:14:07 UTC",
      "updated_date": "2025-05-22 08:14:07 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-25T03:36:09.950033"
    },
    {
      "arxiv_id": "2505.16351v1",
      "title": "Dysfluent WFST: A Framework for Zero-Shot Speech Dysfluency Transcription and Detection",
      "title_zh": "翻译失败",
      "authors": [
        "Chenxu Guo",
        "Jiachen Lian",
        "Xuanru Zhou",
        "Jinming Zhang",
        "Shuhe Li",
        "Zongli Ye",
        "Hwi Joo Park",
        "Anaisha Das",
        "Zoe Ezzes",
        "Jet Vonk",
        "Brittany Morin",
        "Rian Bogley",
        "Lisa Wauters",
        "Zachary Miller",
        "Maria Gorno-Tempini",
        "Gopala Anumanchipalli"
      ],
      "abstract": "Automatic detection of speech dysfluency aids speech-language pathologists in\nefficient transcription of disordered speech, enhancing diagnostics and\ntreatment planning. Traditional methods, often limited to classification,\nprovide insufficient clinical insight, and text-independent models misclassify\ndysfluency, especially in context-dependent cases. This work introduces\nDysfluent-WFST, a zero-shot decoder that simultaneously transcribes phonemes\nand detects dysfluency. Unlike previous models, Dysfluent-WFST operates with\nupstream encoders like WavLM and requires no additional training. It achieves\nstate-of-the-art performance in both phonetic error rate and dysfluency\ndetection on simulated and real speech data. Our approach is lightweight,\ninterpretable, and effective, demonstrating that explicit modeling of\npronunciation behavior in decoding, rather than complex architectures, is key\nto improving dysfluency processing systems.",
      "tldr_zh": "这篇论文介绍了Dysfluent-WFST框架，一个零样本(zero-shot)解码器，用于语音流利度转录和检测，帮助语音语言病理学家更高效地处理异常语音，提高诊断和治疗规划。不同于传统分类方法，该框架结合上游编码器如WavLM，无需额外训练，即可同时转录音素并识别上下文相关的流利度问题。实验结果显示，在模拟和真实语音数据上，Dysfluent-WFST 实现了最先进的音素错误率和检测性能。研究强调，通过在解码中显式建模发音行为（而非依赖复杂架构），可以构建轻量、可解释的流利度处理系统。",
      "categories": [
        "eess.AS",
        "cs.AI"
      ],
      "primary_category": "eess.AS",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2505.16351v1",
      "published_date": "2025-05-22 08:02:50 UTC",
      "updated_date": "2025-05-22 08:02:50 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-25T03:36:22.109225"
    },
    {
      "arxiv_id": "2505.16335v1",
      "title": "FPQVAR: Floating Point Quantization for Visual Autoregressive Model with FPGA Hardware Co-design",
      "title_zh": "翻译失败",
      "authors": [
        "Renjie Wei",
        "Songqiang Xu",
        "Qingyu Guo",
        "Meng Li"
      ],
      "abstract": "Visual autoregressive (VAR) modeling has marked a paradigm shift in image\ngeneration from next-token prediction to next-scale prediction. VAR predicts a\nset of tokens at each step from coarse to fine scale, leading to better image\nquality and faster inference speed compared to existing diffusion models.\nHowever, the large parameter size and computation cost hinder its deployment on\nedge devices. To reduce the memory and computation cost, we propose FPQVAR, an\nefficient post-training floating-point (FP) quantization framework for VAR\nfeaturing algorithm and hardware co-design. At the algorithm level, we first\nidentify the challenges of quantizing VAR. To address them, we propose Dual\nFormat Quantization for the highly imbalanced input activation. We further\npropose Group-wise Hadamard Transformation and GHT-Aware Learnable\nTransformation to address the time-varying outlier channels. At the hardware\nlevel, we design the first low-bit FP quantizer and multiplier with lookup\ntables on FPGA and propose the first FPGA-based VAR accelerator featuring\nlow-bit FP computation and an elaborate two-level pipeline. Extensive\nexperiments show that compared to the state-of-the-art quantization method, our\nproposed FPQVAR significantly improves Fr\\'echet Inception Distance (FID) from\n10.83 to 3.58, Inception Score (IS) from 175.9 to 241.5 under 4-bit\nquantization. FPQVAR also significantly improves the performance of 6-bit\nquantized VAR, bringing it on par with the FP16 model. Our accelerator on\nAMD-Xilinx VCK190 FPGA achieves a throughput of 1.1 image/s, which is 3.1x\nhigher than the integer-based accelerator. It also demonstrates 3.6x and 2.8x\nhigher energy efficiency compared to the integer-based accelerator and GPU\nbaseline, respectively.",
      "tldr_zh": "本研究提出 FPQVAR，一种针对 Visual Autoregressive (VAR) 模型的浮点量化框架，通过算法和硬件协同设计，降低其在边缘设备部署时的内存和计算成本。算法层面，FPQVAR 采用 Dual Format Quantization 处理输入激活的不平衡问题，并引入 Group-wise Hadamard Transformation 和 GHT-Aware Learnable Transformation 来应对时间变化的异常通道。硬件层面，该框架设计了首个基于 FPGA 的低位 FP 量化器和乘法器，以及一个支持低位 FP 计算的两级流水线加速器。实验结果显示，与现有方法相比，FPQVAR 在 4-bit 量化下将 Fréchet Inception Distance (FID) 由 10.83 改善至 3.58，并将 Inception Score (IS) 由 175.9 提升至 241.5；在 AMD-Xilinx VCK190 FPGA 上，实现 1.1 图像/秒的吞吐量，并显著提高能效。",
      "categories": [
        "cs.CV",
        "cs.AI"
      ],
      "primary_category": "cs.CV",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2505.16335v1",
      "published_date": "2025-05-22 07:47:51 UTC",
      "updated_date": "2025-05-22 07:47:51 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-25T03:36:34.770033"
    },
    {
      "arxiv_id": "2505.16332v1",
      "title": "Is Quantum Optimization Ready? An Effort Towards Neural Network Compression using Adiabatic Quantum Computing",
      "title_zh": "翻译失败",
      "authors": [
        "Zhehui Wanga",
        "Benjamin Chen Ming Choonga",
        "Tian Huang",
        "Daniel Gerlinghoffa",
        "Rick Siow Mong Goh",
        "Cheng Liu",
        "Tao Luo"
      ],
      "abstract": "Quantum optimization is the most mature quantum computing technology to date,\nproviding a promising approach towards efficiently solving complex\ncombinatorial problems. Methods such as adiabatic quantum computing (AQC) have\nbeen employed in recent years on important optimization problems across various\ndomains. In deep learning, deep neural networks (DNN) have reached immense\nsizes to support new predictive capabilities. Optimization of large-scale\nmodels is critical for sustainable deployment, but becomes increasingly\nchallenging with ever-growing model sizes and complexity. While quantum\noptimization is suitable for solving complex problems, its application to DNN\noptimization is not straightforward, requiring thorough reformulation for\ncompatibility with commercially available quantum devices. In this work, we\nexplore the potential of adopting AQC for fine-grained pruning-quantization of\nconvolutional neural networks. We rework established heuristics to formulate\nmodel compression as a quadratic unconstrained binary optimization (QUBO)\nproblem, and assess the solution space offered by commercial quantum annealing\ndevices. Through our exploratory efforts of reformulation, we demonstrate that\nAQC can achieve effective compression of practical DNN models. Experiments\ndemonstrate that adiabatic quantum computing (AQC) not only outperforms\nclassical algorithms like genetic algorithms and reinforcement learning in\nterms of time efficiency but also excels at identifying global optima.",
      "tldr_zh": "该研究探讨了量子优化技术，特别是Adiabatic Quantum Computing (AQC)，在神经网络压缩中的潜力，以应对深度神经网络(DNN)规模不断增长的优化挑战。作者将DNN的细粒度剪枝和量化问题重新表述为Quadratic Unconstrained Binary Optimization (QUBO)问题，并利用商业量子退火设备求解。实验结果显示，AQC不仅在时间效率上优于经典算法如遗传算法和强化学习，还更擅长识别全局最优解，从而实现了对实际DNN模型的有效压缩。整体而言，此工作证明了量子优化技术在DNN优化领域的可行性。",
      "categories": [
        "quant-ph",
        "cs.AI"
      ],
      "primary_category": "quant-ph",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2505.16332v1",
      "published_date": "2025-05-22 07:40:23 UTC",
      "updated_date": "2025-05-22 07:40:23 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-25T03:36:44.849053"
    },
    {
      "arxiv_id": "2505.16330v1",
      "title": "SC4ANM: Identifying Optimal Section Combinations for Automated Novelty Prediction in Academic Papers",
      "title_zh": "SC4ANM：识别学术论文中用于自动新颖性预测的最佳章节组合",
      "authors": [
        "Wenqing Wu",
        "Chengzhi Zhang",
        "Tong Bao",
        "Yi Zhao"
      ],
      "abstract": "Novelty is a core component of academic papers, and there are multiple\nperspectives on the assessment of novelty. Existing methods often focus on word\nor entity combinations, which provide limited insights. The content related to\na paper's novelty is typically distributed across different core sections,\ne.g., Introduction, Methodology and Results. Therefore, exploring the optimal\ncombination of sections for evaluating the novelty of a paper is important for\nadvancing automated novelty assessment. In this paper, we utilize different\ncombinations of sections from academic papers as inputs to drive language\nmodels to predict novelty scores. We then analyze the results to determine the\noptimal section combinations for novelty score prediction. We first employ\nnatural language processing techniques to identify the sectional structure of\nacademic papers, categorizing them into introduction, methods, results, and\ndiscussion (IMRaD). Subsequently, we used different combinations of these\nsections (e.g., introduction and methods) as inputs for pretrained language\nmodels (PLMs) and large language models (LLMs), employing novelty scores\nprovided by human expert reviewers as ground truth labels to obtain prediction\nresults. The results indicate that using introduction, results and discussion\nis most appropriate for assessing the novelty of a paper, while the use of the\nentire text does not yield significant results. Furthermore, based on the\nresults of the PLMs and LLMs, the introduction and results appear to be the\nmost important section for the task of novelty score prediction. The code and\ndataset for this paper can be accessed at\nhttps://github.com/njust-winchy/SC4ANM.",
      "tldr_zh": "本文提出SC4ANM框架，用于识别学术论文中最佳部分组合，以实现自动新颖性预测，解决现有方法仅关注词或实体组合的局限性。研究采用自然语言处理技术识别论文的IMRaD结构（引言、方法、结果和讨论），并将不同部分组合作为输入喂入PLMs和LLMs，使用专家评分作为基准进行预测。结果表明，引言、结果和讨论的组合最适合评估新颖性，而引言和结果是核心部分；此外，使用整个文本的效果不显著，该框架的代码和数据集可公开获取。",
      "categories": [
        "cs.CL",
        "cs.AI",
        "cs.DL"
      ],
      "primary_category": "cs.CL",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2505.16330v1",
      "published_date": "2025-05-22 07:34:59 UTC",
      "updated_date": "2025-05-22 07:34:59 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-25T03:36:57.250305"
    },
    {
      "arxiv_id": "2505.16325v1",
      "title": "CLEAR: A Clinically-Grounded Tabular Framework for Radiology Report Evaluation",
      "title_zh": "翻译失败",
      "authors": [
        "Yuyang Jiang",
        "Chacha Chen",
        "Shengyuan Wang",
        "Feng Li",
        "Zecong Tang",
        "Benjamin M. Mervak",
        "Lydia Chelala",
        "Christopher M Straus",
        "Reve Chahine",
        "Samuel G. Armato III",
        "Chenhao Tan"
      ],
      "abstract": "Existing metrics often lack the granularity and interpretability to capture\nnuanced clinical differences between candidate and ground-truth radiology\nreports, resulting in suboptimal evaluation. We introduce a Clinically-grounded\ntabular framework with Expert-curated labels and Attribute-level comparison for\nRadiology report evaluation (CLEAR). CLEAR not only examines whether a report\ncan accurately identify the presence or absence of medical conditions, but also\nassesses whether it can precisely describe each positively identified condition\nacross five key attributes: first occurrence, change, severity, descriptive\nlocation, and recommendation. Compared to prior works, CLEAR's\nmulti-dimensional, attribute-level outputs enable a more comprehensive and\nclinically interpretable evaluation of report quality. Additionally, to measure\nthe clinical alignment of CLEAR, we collaborate with five board-certified\nradiologists to develop CLEAR-Bench, a dataset of 100 chest X-ray reports from\nMIMIC-CXR, annotated across 6 curated attributes and 13 CheXpert conditions.\nOur experiments show that CLEAR achieves high accuracy in extracting clinical\nattributes and provides automated metrics that are strongly aligned with\nclinical judgment.",
      "tldr_zh": "这篇论文提出了 CLEAR 框架，一种基于临床的表格化框架，用于评估放射学报告的精确性和可解释性，通过专家策划的标签和属性级比较来捕捉报告中细微的临床差异。CLEAR 不只检查报告是否准确识别医疗条件，还评估每个阳性条件在五个关键属性上的描述：first occurrence, change, severity, descriptive location, and recommendation。研究者开发了 CLEAR-Bench 数据集，基于 MIMIC-CXR 的 100 个胸部 X 光报告，由五位认证放射科医生标注 6 个属性和 13 个 CheXpert 条件；实验结果显示，CLEAR 在提取临床属性方面准确性高，并提供与临床判断高度一致的自动化指标。",
      "categories": [
        "cs.CL",
        "cs.AI",
        "cs.CY"
      ],
      "primary_category": "cs.CL",
      "comment": "18 pages, 4 figures",
      "pdf_url": "http://arxiv.org/pdf/2505.16325v1",
      "published_date": "2025-05-22 07:32:12 UTC",
      "updated_date": "2025-05-22 07:32:12 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-25T03:37:09.874873"
    },
    {
      "arxiv_id": "2505.16322v1",
      "title": "AdaSTaR: Adaptive Data Sampling for Training Self-Taught Reasoners",
      "title_zh": "AdaSTaR：自适应数据采样用于训练自学习推理器",
      "authors": [
        "Woosung Koh",
        "Wonbeen Oh",
        "Jaein Jang",
        "MinHyung Lee",
        "Hyeongjin Kim",
        "Ah Yeon Kim",
        "Joonkee Kim",
        "Junghyun Lee",
        "Taehyeon Kim",
        "Se-Young Yun"
      ],
      "abstract": "Self-Taught Reasoners (STaR), synonymously known as Rejection sampling\nFine-Tuning (RFT), is an integral part of the training pipeline of\nself-improving reasoning Language Models (LMs). The self-improving mechanism\noften employs random observation (data) sampling. However, this results in\ntrained observation imbalance; inefficiently over-training on solved examples\nwhile under-training on challenging ones. In response, we introduce Adaptive\nSTaR (AdaSTaR), a novel algorithm that rectifies this by integrating two\nadaptive sampling principles: (1) Adaptive Sampling for Diversity: promoting\nbalanced training across observations, and (2) Adaptive Sampling for\nCurriculum: dynamically adjusting data difficulty to match the model's evolving\nstrength. Across six benchmarks, AdaSTaR achieves best test accuracy in all\ninstances (6/6) and reduces training FLOPs by an average of 58.6% against an\nextensive list of baselines. These improvements in performance and efficiency\ngeneralize to different pre-trained LMs and larger models, paving the way for\nmore efficient and effective self-improving LMs.",
      "tldr_zh": "该论文提出 AdaSTaR，一种自适应数据采样算法，用于优化 Self-Taught Reasoners (STaR) 或 Rejection sampling Fine-Tuning (RFT) 在训练自提升推理 Language Models (LMs) 中的过程，以解决传统随机采样导致的训练不平衡问题。AdaSTaR 整合了两个关键原则：Adaptive Sampling for Diversity（促进观察数据的平衡训练）和 Adaptive Sampling for Curriculum（动态调整数据难度以匹配模型能力）。在六个基准测试中，AdaSTaR 实现了所有实例的最佳测试准确率（6/6），并平均减少 58.6% 的训练 FLOPs。这些改进适用于不同预训练 LMs 和更大模型，推动了更高效的自提升 LMs 发展。",
      "categories": [
        "cs.LG",
        "cs.AI",
        "cs.CL"
      ],
      "primary_category": "cs.LG",
      "comment": "Pre-print",
      "pdf_url": "http://arxiv.org/pdf/2505.16322v1",
      "published_date": "2025-05-22 07:24:11 UTC",
      "updated_date": "2025-05-22 07:24:11 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-25T03:37:22.819290"
    },
    {
      "arxiv_id": "2505.16315v1",
      "title": "Incentivizing Dual Process Thinking for Efficient Large Language Model Reasoning",
      "title_zh": "激励双过程思考以实现大语言模型高效推理",
      "authors": [
        "Xiaoxue Cheng",
        "Junyi Li",
        "Zhenduo Zhang",
        "Xinyu Tang",
        "Wayne Xin Zhao",
        "Xinyu Kong",
        "Zhiqiang Zhang"
      ],
      "abstract": "Large reasoning models (LRMs) have demonstrated strong performance on complex\nreasoning tasks, but often suffer from overthinking, generating redundant\ncontent regardless of task difficulty. Inspired by the dual process theory in\ncognitive science, we propose Adaptive Cognition Policy Optimization (ACPO), a\nreinforcement learning framework that enables LRMs to achieve efficient\nreasoning through adaptive cognitive allocation and dynamic system switch. ACPO\nincorporates two key components: (1) introducing system-aware reasoning tokens\nto explicitly represent the thinking modes thereby making the model's cognitive\nprocess transparent, and (2) integrating online difficulty estimation and token\nlength budget to guide adaptive system switch and reasoning during\nreinforcement learning. To this end, we propose a two-stage training strategy.\nThe first stage begins with supervised fine-tuning to cold start the model,\nenabling it to generate reasoning paths with explicit thinking modes. In the\nsecond stage, we apply ACPO to further enhance adaptive system switch for\ndifficulty-aware reasoning. Experimental results demonstrate that ACPO\neffectively reduces redundant reasoning while adaptively adjusting cognitive\nallocation based on task complexity, achieving efficient hybrid reasoning.",
      "tldr_zh": "该研究针对大型推理模型（LRMs）在复杂任务中易产生冗余内容的过度思考问题，提出基于双过程理论（dual process theory）的强化学习框架Adaptive Cognition Policy Optimization (ACPO)。ACPO 通过引入系统感知推理标记（system-aware reasoning tokens）和在线难度估计机制，实现自适应认知分配和动态系统切换，并采用两阶段训练策略：先进行监督微调生成明确思考模式的推理路径，再优化自适应切换以提升效率。实验结果显示，ACPO 有效减少冗余推理，根据任务复杂度调整认知分配，实现高效混合推理。",
      "categories": [
        "cs.AI",
        "cs.CL"
      ],
      "primary_category": "cs.AI",
      "comment": "work in progress",
      "pdf_url": "http://arxiv.org/pdf/2505.16315v1",
      "published_date": "2025-05-22 07:15:08 UTC",
      "updated_date": "2025-05-22 07:15:08 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-25T03:37:32.696049"
    },
    {
      "arxiv_id": "2505.16314v1",
      "title": "NTIRE 2025 challenge on Text to Image Generation Model Quality Assessment",
      "title_zh": "NTIRE 2025 文本到图像生成模型质量",
      "authors": [
        "Shuhao Han",
        "Haotian Fan",
        "Fangyuan Kong",
        "Wenjie Liao",
        "Chunle Guo",
        "Chongyi Li",
        "Radu Timofte",
        "Liang Li",
        "Tao Li",
        "Junhui Cui",
        "Yunqiu Wang",
        "Yang Tai",
        "Jingwei Sun",
        "Jianhui Sun",
        "Xinli Yue",
        "Tianyi Wang",
        "Huan Hou",
        "Junda Lu",
        "Xinyang Huang",
        "Zitang Zhou",
        "Zijian Zhang",
        "Xuhui Zheng",
        "Xuecheng Wu",
        "Chong Peng",
        "Xuezhi Cao",
        "Trong-Hieu Nguyen-Mau",
        "Minh-Hoang Le",
        "Minh-Khoa Le-Phan",
        "Duy-Nam Ly",
        "Hai-Dang Nguyen",
        "Minh-Triet Tran",
        "Yukang Lin",
        "Yan Hong",
        "Chuanbiao Song",
        "Siyuan Li",
        "Jun Lan",
        "Zhichao Zhang",
        "Xinyue Li",
        "Wei Sun",
        "Zicheng Zhang",
        "Yunhao Li",
        "Xiaohong Liu",
        "Guangtao Zhai",
        "Zitong Xu",
        "Huiyu Duan",
        "Jiarui Wang",
        "Guangji Ma",
        "Liu Yang",
        "Lu Liu",
        "Qiang Hu",
        "Xiongkuo Min",
        "Zichuan Wang",
        "Zhenchen Tang",
        "Bo Peng",
        "Jing Dong",
        "Fengbin Guan",
        "Zihao Yu",
        "Yiting Lu",
        "Wei Luo",
        "Xin Li",
        "Minhao Lin",
        "Haofeng Chen",
        "Xuanxuan He",
        "Kele Xu",
        "Qisheng Xu",
        "Zijian Gao",
        "Tianjiao Wan",
        "Bo-Cheng Qiu",
        "Chih-Chung Hsu",
        "Chia-ming Lee",
        "Yu-Fan Lin",
        "Bo Yu",
        "Zehao Wang",
        "Da Mu",
        "Mingxiu Chen",
        "Junkang Fang",
        "Huamei Sun",
        "Wending Zhao",
        "Zhiyu Wang",
        "Wang Liu",
        "Weikang Yu",
        "Puhong Duan",
        "Bin Sun",
        "Xudong Kang",
        "Shutao Li",
        "Shuai He",
        "Lingzhi Fu",
        "Heng Cong",
        "Rongyu Zhang",
        "Jiarong He",
        "Zhishan Qiao",
        "Yongqing Huang",
        "Zewen Chen",
        "Zhe Pang",
        "Juan Wang",
        "Jian Guo",
        "Zhizhuo Shao",
        "Ziyu Feng",
        "Bing Li",
        "Weiming Hu",
        "Hesong Li",
        "Dehua Liu",
        "Zeming Liu",
        "Qingsong Xie",
        "Ruichen Wang",
        "Zhihao Li",
        "Yuqi Liang",
        "Jianqi Bi",
        "Jun Luo",
        "Junfeng Yang",
        "Can Li",
        "Jing Fu",
        "Hongwei Xu",
        "Mingrui Long",
        "Lulin Tang"
      ],
      "abstract": "This paper reports on the NTIRE 2025 challenge on Text to Image (T2I)\ngeneration model quality assessment, which will be held in conjunction with the\nNew Trends in Image Restoration and Enhancement Workshop (NTIRE) at CVPR 2025.\nThe aim of this challenge is to address the fine-grained quality assessment of\ntext-to-image generation models. This challenge evaluates text-to-image models\nfrom two aspects: image-text alignment and image structural distortion\ndetection, and is divided into the alignment track and the structural track.\nThe alignment track uses the EvalMuse-40K, which contains around 40K\nAI-Generated Images (AIGIs) generated by 20 popular generative models. The\nalignment track has a total of 371 registered participants. A total of 1,883\nsubmissions are received in the development phase, and 507 submissions are\nreceived in the test phase. Finally, 12 participating teams submitted their\nmodels and fact sheets. The structure track uses the EvalMuse-Structure, which\ncontains 10,000 AI-Generated Images (AIGIs) with corresponding structural\ndistortion mask. A total of 211 participants have registered in the structure\ntrack. A total of 1155 submissions are received in the development phase, and\n487 submissions are received in the test phase. Finally, 8 participating teams\nsubmitted their models and fact sheets. Almost all methods have achieved better\nresults than baseline methods, and the winning methods in both tracks have\ndemonstrated superior prediction performance on T2I model quality assessment.",
      "tldr_zh": "这篇论文报告了 NTIRE 2025 挑战赛，聚焦于 Text to Image (T2I) 生成模型的质量评估，旨在从图像-文本对齐和图像结构畸变检测两个方面评估模型性能。挑战分为 alignment track 和 structural track，前者使用 EvalMuse-40K 数据集（包含约 40K AI 生成图像）吸引了 371 名参与者，最终 12 支团队提交模型；后者使用 EvalMuse-Structure 数据集（包含 10,000 AI 生成图像及其结构畸变掩码）吸引了 211 名参与者，最终 8 支团队提交模型。实验结果显示，几乎所有方法均优于基线，获胜团队在 T2I 模型质量评估中展现了卓越的预测性能。",
      "categories": [
        "cs.CV",
        "cs.AI"
      ],
      "primary_category": "cs.CV",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2505.16314v1",
      "published_date": "2025-05-22 07:12:36 UTC",
      "updated_date": "2025-05-22 07:12:36 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-25T03:37:44.895110"
    },
    {
      "arxiv_id": "2505.16312v1",
      "title": "EquivPruner: Boosting Efficiency and Quality in LLM-Based Search via Action Pruning",
      "title_zh": "Equ",
      "authors": [
        "Jiawei Liu",
        "Qisi Chen",
        "Jianshu Zhang",
        "Quan Liu",
        "Defu Lian"
      ],
      "abstract": "Large Language Models (LLMs) excel at complex reasoning through search\nalgorithms, yet current strategies often suffer from massive token consumption\ndue to redundant exploration of semantically equivalent steps. Existing\nsemantic similarity methods struggle to accurately identify such equivalence in\ndomain-specific contexts like mathematical reasoning. To address this, we\npropose EquivPruner, a simple yet effective approach that identifies and prunes\nsemantically equivalent actions during LLM reasoning search. We also introduce\nMathEquiv, the first dataset we created for mathematical statement equivalence,\nwhich enables the training of a lightweight equivalence detector. Extensive\nexperiments across various models and tasks demonstrate that EquivPruner\nsignificantly reduces token consumption, improving searching efficiency and\noften bolstering reasoning accuracy. For instance, when applied to\nQwen2.5-Math-7B-Instruct on GSM8K, EquivPruner reduced token consumption by\n48.1\\% while also improving accuracy. Our code is available at\nhttps://github.com/Lolo1222/EquivPruner.",
      "tldr_zh": "该研究针对大语言模型(LLMs)在搜索算法中因冗余探索语义等价步骤而导致的巨大 token 消耗问题，提出EquivPruner框架，通过识别并修剪语义等价动作来提升搜索效率和推理质量。EquivPruner还引入MathEquiv，这是首个用于数学语句等价的训练数据集，用于训练轻量级等价检测器。在各种模型和任务的实验中，EquivPruner显著减少token消耗，例如在Qwen2.5-Math-7B-Instruct上应用于GSM8K时，降低消耗48.1%并提高准确性。总的来说，该方法为LLM推理优化提供了简单有效的解决方案。",
      "categories": [
        "cs.AI",
        "cs.CL"
      ],
      "primary_category": "cs.AI",
      "comment": "11 pages, 4 figures",
      "pdf_url": "http://arxiv.org/pdf/2505.16312v1",
      "published_date": "2025-05-22 07:07:43 UTC",
      "updated_date": "2025-05-22 07:07:43 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-25T03:37:56.801986"
    },
    {
      "arxiv_id": "2505.16307v1",
      "title": "PMPO: Probabilistic Metric Prompt Optimization for Small and Large Language Models",
      "title_zh": "翻译失败",
      "authors": [
        "Chenzhuo Zhao",
        "Ziqian Liu",
        "Xingda Wang",
        "Junting Lu",
        "Chaoyi Ruan"
      ],
      "abstract": "Prompt optimization offers a practical and broadly applicable alternative to\nfine-tuning for improving large language model (LLM) performance. However,\nexisting methods often rely on costly output generation, self-critiquing\nabilities, or human-annotated preferences, which limit their scalability,\nespecially for smaller or non-instruction-tuned models. We introduce PMPO\n(Probabilistic Metric Prompt Optimization), a unified framework that refines\nprompts using token-level cross-entropy loss as a direct, lightweight\nevaluation signal. PMPO identifies low-quality prompt segments by masking and\nmeasuring their impact on loss, then rewrites and selects improved variants by\nminimizing loss over positive and negative examples. Unlike prior methods, it\nrequires no output sampling or human evaluation during optimization, relying\nonly on forward passes and log-likelihoods. PMPO supports both supervised and\npreference-based tasks through a closely aligned loss-based evaluation\nstrategy. Experiments show that PMPO consistently outperforms prior methods\nacross model sizes and tasks: it achieves the highest average accuracy on BBH,\nperforms strongly on GSM8K and AQUA-RAT, and improves AlpacaEval 2.0 win rates\nby over 19 points. These results highlight PMPO's effectiveness, efficiency,\nand broad applicability.",
      "tldr_zh": "该研究提出 PMPO（Probabilistic Metric Prompt Optimization），一种统一的框架，用于优化大语言模型（LLM）和小语言模型的提示，以提升性能，而无需依赖昂贵的输出生成或人工评估。\nPMPO 通过 token-level cross-entropy loss 作为轻量级评估信号，识别低质量提示段落（via masking），并通过最小化损失来重写和选择改进的提示变体，支持 supervised 和 preference-based 任务。\n实验结果表明，PMPO 在不同模型大小和任务上超越现有方法，在 BBH 上实现最高平均准确率，在 GSM8K 和 AQUA-RAT 上表现强劲，并将 AlpacaEval 2.0 的胜率提高超过 19 点。",
      "categories": [
        "cs.CL",
        "cs.AI",
        "cs.LG"
      ],
      "primary_category": "cs.CL",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2505.16307v1",
      "published_date": "2025-05-22 06:59:10 UTC",
      "updated_date": "2025-05-22 06:59:10 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-25T03:38:09.492466"
    },
    {
      "arxiv_id": "2505.16306v1",
      "title": "Layer-wise Investigation of Large-Scale Self-Supervised Music Representation Models",
      "title_zh": "大规模自我监督音乐表示模型的层级调查",
      "authors": [
        "Yizhi Zhou",
        "Haina Zhu",
        "Hangting Chen"
      ],
      "abstract": "Recently, pre-trained models for music information retrieval based on\nself-supervised learning (SSL) are becoming popular, showing success in various\ndownstream tasks. However, there is limited research on the specific meanings\nof the encoded information and their applicability. Exploring these aspects can\nhelp us better understand their capabilities and limitations, leading to more\neffective use in downstream tasks.\n  In this study, we analyze the advanced music representation model MusicFM and\nthe newly emerged SSL model MuQ. We focus on three main aspects: (i) validating\nthe advantages of SSL models across multiple downstream tasks, (ii) exploring\nthe specialization of layer-wise information for different tasks, and (iii)\ncomparing performance differences when selecting specific layers. Through this\nanalysis, we reveal insights into the structure and potential applications of\nSSL models in music information retrieval.",
      "tldr_zh": "本研究调查了大规模自监督学习 (Self-Supervised Learning, SSL) 音乐表示模型 MusicFM 和 MuQ，旨在探讨这些模型在音乐信息检索中的编码信息含义及其适用性。研究重点验证了 SSL 模型在多个下游任务中的优势、分析了层级信息 (layer-wise information) 在不同任务中的专业化，以及比较了选择特定层时的性能差异。通过这些分析，揭示了 SSL 模型的内部结构及其在音乐信息检索中的潜在应用潜力。",
      "categories": [
        "cs.SD",
        "cs.AI",
        "eess.AS"
      ],
      "primary_category": "cs.SD",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2505.16306v1",
      "published_date": "2025-05-22 06:58:24 UTC",
      "updated_date": "2025-05-22 06:58:24 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-25T03:38:20.017385"
    },
    {
      "arxiv_id": "2505.16301v1",
      "title": "Artificial Intelligence for Direct Prediction of Molecular Dynamics Across Chemical Space",
      "title_zh": "人工智能用于跨化学空间分子动力学的直接预测",
      "authors": [
        "Fuchun Ge",
        "Pavlo O. Dral"
      ],
      "abstract": "Molecular dynamics (MD) is a powerful tool for exploring the behavior of\natomistic systems, but its reliance on sequential numerical integration limits\nsimulation efficiency. We present MDtrajNet-1, a foundational AI model that\ndirectly generates MD trajectories across chemical space, bypassing force\ncalculations and integration. This approach accelerates simulations by up to\ntwo orders of magnitude compared to traditional MD, even those enhanced by\nmachine-learning interatomic potentials. MDtrajNet-1 combines equivariant\nneural networks with a Transformer-based architecture to achieve strong\naccuracy and transferability in predicting long-time trajectories for both\nknown and unseen systems. Remarkably, the errors of the trajectories generated\nby MDtrajNet-1 for various molecular systems are close to those of the\nconventional ab initio MD. The model's flexible design supports diverse\napplication scenarios, including different statistical ensembles, boundary\nconditions, and interaction types. By overcoming the intrinsic speed barrier of\nconventional MD, MDtrajNet-1 opens new frontiers in efficient and scalable\natomistic simulations.",
      "tldr_zh": "本研究提出了一种AI模型MDtrajNet-1，用于直接预测分子动力学(MD)轨迹，绕过传统力计算和积分，从而在化学空间中实现高效模拟。该模型结合equivariant neural networks和Transformer-based架构，确保预测的长期轨迹在已知和未知系统中具有高准确性和可转移性。相比传统MD方法，MDtrajNet-1可将模拟速度提升两个数量级，甚至优于基于机器学习原子间势的增强版本，且其轨迹错误率接近ab initio MD。模型的灵活设计支持多种统计系综、边界条件和交互类型，为高效、可扩展的原子模拟开辟新前沿。",
      "categories": [
        "physics.chem-ph",
        "cs.AI",
        "cs.LG"
      ],
      "primary_category": "physics.chem-ph",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2505.16301v1",
      "published_date": "2025-05-22 06:56:19 UTC",
      "updated_date": "2025-05-22 06:56:19 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-25T03:38:32.457467"
    },
    {
      "arxiv_id": "2505.16290v1",
      "title": "Multimodal Generative AI for Story Point Estimation in Software Development",
      "title_zh": "翻译失败",
      "authors": [
        "Mohammad Rubyet Islam",
        "Peter Sandborn"
      ],
      "abstract": "This research explores the application of Multimodal Generative AI to enhance\nstory point estimation in Agile software development. By integrating text,\nimage, and categorical data using advanced models like BERT, CNN, and XGBoost,\nour approach surpasses the limitations of traditional single-modal estimation\nmethods. The results demonstrate strong accuracy for simpler story points,\nwhile also highlighting challenges in more complex categories due to data\nimbalance. This study further explores the impact of categorical data,\nparticularly severity, on the estimation process, emphasizing its influence on\nmodel performance. Our findings emphasize the transformative potential of\nmultimodal data integration in refining AI-driven project management, paving\nthe way for more precise, adaptable, and domain-specific AI capabilities.\nAdditionally, this work outlines future directions for addressing data\nvariability and enhancing the robustness of AI in Agile methodologies.",
      "tldr_zh": "这项研究探讨了多模态生成 AI 在敏捷(Agile)软件开发中提升故事点估算的应用，通过整合文本、图像和分类数据，并利用模型如 BERT、CNN 和 XGBoost，超越了传统单模态方法的局限。结果显示，该方法在简单故事点上表现出色，但受数据不平衡影响，在复杂类别中面临准确性挑战，特别是分类数据如严重性对模型性能的影响。总体而言，该研究突显了多模态数据整合的潜力，可提升 AI 在项目管理中的精确性和适应性，并为未来处理数据变异性和提高 AI 鲁棒性提供了方向。",
      "categories": [
        "cs.SE",
        "cs.AI",
        "68T07, 68T45",
        "I.2.6; I.2.10; D.2.9; H.2.8"
      ],
      "primary_category": "cs.SE",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2505.16290v1",
      "published_date": "2025-05-22 06:40:41 UTC",
      "updated_date": "2025-05-22 06:40:41 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-25T03:38:43.794248"
    },
    {
      "arxiv_id": "2505.16288v1",
      "title": "No Black Boxes: Interpretable and Interactable Predictive Healthcare with Knowledge-Enhanced Agentic Causal Discovery",
      "title_zh": "翻译失败",
      "authors": [
        "Xiaoxue Han",
        "Pengfei Hu",
        "Jun-En Ding",
        "Chang Lu",
        "Feng Liu",
        "Yue Ning"
      ],
      "abstract": "Deep learning models trained on extensive Electronic Health Records (EHR)\ndata have achieved high accuracy in diagnosis prediction, offering the\npotential to assist clinicians in decision-making and treatment planning.\nHowever, these models lack two crucial features that clinicians highly value:\ninterpretability and interactivity. The ``black-box'' nature of these models\nmakes it difficult for clinicians to understand the reasoning behind\npredictions, limiting their ability to make informed decisions. Additionally,\nthe absence of interactive mechanisms prevents clinicians from incorporating\ntheir own knowledge and experience into the decision-making process. To address\nthese limitations, we propose II-KEA, a knowledge-enhanced agent-driven causal\ndiscovery framework that integrates personalized knowledge databases and\nagentic LLMs. II-KEA enhances interpretability through explicit reasoning and\ncausal analysis, while also improving interactivity by allowing clinicians to\ninject their knowledge and experience through customized knowledge bases and\nprompts. II-KEA is evaluated on both MIMIC-III and MIMIC-IV, demonstrating\nsuperior performance along with enhanced interpretability and interactivity, as\nevidenced by its strong results from extensive case studies.",
      "tldr_zh": "本研究针对深度学习模型在电子健康记录(EHR)数据上的诊断预测问题，提出II-KEA框架，这是一个知识增强的代理驱动因果发现系统，以解决模型的“黑箱”性质导致的可解释性和交互性不足。II-KEA通过整合个性化知识数据库和代理LLMs，实现显式推理和因果分析，提高预测的可解释性，同时允许临床医生通过自定义知识库和提示注入自身经验，提升交互性。在MIMIC-III和MIMIC-IV数据集上的评估显示，II-KEA在性能上优于基线模型，并通过广泛案例研究证明了其增强的可解释性和交互性。",
      "categories": [
        "cs.AI"
      ],
      "primary_category": "cs.AI",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2505.16288v1",
      "published_date": "2025-05-22 06:36:30 UTC",
      "updated_date": "2025-05-22 06:36:30 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-25T03:38:56.092490"
    },
    {
      "arxiv_id": "2505.16278v1",
      "title": "DriveMoE: Mixture-of-Experts for Vision-Language-Action Model in End-to-End Autonomous Driving",
      "title_zh": "翻译失败",
      "authors": [
        "Zhenjie Yang",
        "Yilin Chai",
        "Xiaosong Jia",
        "Qifeng Li",
        "Yuqian Shao",
        "Xuekai Zhu",
        "Haisheng Su",
        "Junchi Yan"
      ],
      "abstract": "End-to-end autonomous driving (E2E-AD) demands effective processing of\nmulti-view sensory data and robust handling of diverse and complex driving\nscenarios, particularly rare maneuvers such as aggressive turns. Recent success\nof Mixture-of-Experts (MoE) architecture in Large Language Models (LLMs)\ndemonstrates that specialization of parameters enables strong scalability. In\nthis work, we propose DriveMoE, a novel MoE-based E2E-AD framework, with a\nScene-Specialized Vision MoE and a Skill-Specialized Action MoE. DriveMoE is\nbuilt upon our $\\pi_0$ Vision-Language-Action (VLA) baseline (originally from\nthe embodied AI field), called Drive-$\\pi_0$. Specifically, we add Vision MoE\nto Drive-$\\pi_0$ by training a router to select relevant cameras according to\nthe driving context dynamically. This design mirrors human driving cognition,\nwhere drivers selectively attend to crucial visual cues rather than\nexhaustively processing all visual information. In addition, we add Action MoE\nby training another router to activate specialized expert modules for different\ndriving behaviors. Through explicit behavioral specialization, DriveMoE is able\nto handle diverse scenarios without suffering from modes averaging like\nexisting models. In Bench2Drive closed-loop evaluation experiments, DriveMoE\nachieves state-of-the-art (SOTA) performance, demonstrating the effectiveness\nof combining vision and action MoE in autonomous driving tasks. We will release\nour code and models of DriveMoE and Drive-$\\pi_0$.",
      "tldr_zh": "本文提出 DriveMoE，一种基于 Mixture-of-Experts (MoE) 的 Vision-Language-Action (VLA) 模型，用于端到端自动驾驶 (E2E-AD)，旨在高效处理多视图感知数据和复杂场景，如激进转弯。框架在 Drive-π0 基线基础上添加 Scene-Specialized Vision MoE 和 Skill-Specialized Action MoE，通过训练路由器动态选择相关摄像头和激活特定驾驶行为专家，模仿人类驾驶认知并避免模式平均问题。在 Bench2Drive 闭环评估中，DriveMoE 达到 SOTA 性能，证明了其在多样场景处理中的有效性，并计划发布代码和模型。",
      "categories": [
        "cs.CV",
        "cs.AI",
        "cs.RO"
      ],
      "primary_category": "cs.CV",
      "comment": "Project Page: https://thinklab-sjtu.github.io/DriveMoE/",
      "pdf_url": "http://arxiv.org/pdf/2505.16278v1",
      "published_date": "2025-05-22 06:23:04 UTC",
      "updated_date": "2025-05-22 06:23:04 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-25T03:39:09.762987"
    },
    {
      "arxiv_id": "2505.16276v1",
      "title": "How do Scaling Laws Apply to Knowledge Graph Engineering Tasks? The Impact of Model Size on Large Language Model Performance",
      "title_zh": "缩放定律如何应用于知识图谱工程任务？ 模型大小对大型",
      "authors": [
        "Desiree Heim",
        "Lars-Peter Meyer",
        "Markus Schröder",
        "Johannes Frey",
        "Andreas Dengel"
      ],
      "abstract": "When using Large Language Models (LLMs) to support Knowledge Graph\nEngineering (KGE), one of the first indications when searching for an\nappropriate model is its size. According to the scaling laws, larger models\ntypically show higher capabilities. However, in practice, resource costs are\nalso an important factor and thus it makes sense to consider the ratio between\nmodel performance and costs. The LLM-KG-Bench framework enables the comparison\nof LLMs in the context of KGE tasks and assesses their capabilities of\nunderstanding and producing KGs and KG queries. Based on a dataset created in\nan LLM-KG-Bench run covering 26 open state-of-the-art LLMs, we explore the\nmodel size scaling laws specific to KGE tasks. In our analyses, we assess how\nbenchmark scores evolve between different model size categories. Additionally,\nwe inspect how the general score development of single models and families of\nmodels correlates to their size. Our analyses revealed that, with a few\nexceptions, the model size scaling laws generally also apply to the selected\nKGE tasks. However, in some cases, plateau or ceiling effects occurred, i.e.,\nthe task performance did not change much between a model and the next larger\nmodel. In these cases, smaller models could be considered to achieve high\ncost-effectiveness. Regarding models of the same family, sometimes larger\nmodels performed worse than smaller models of the same family. These effects\noccurred only locally. Hence it is advisable to additionally test the next\nsmallest and largest model of the same family.",
      "tldr_zh": "本研究探讨了模型大小（scaling laws）对大型语言模型（LLMs）在知识图谱工程（KGE）任务中的影响，强调了性能与资源成本的权衡。研究利用LLM-KG-Bench框架分析了26个开源LLMs的数据，评估了模型大小如何影响KGE任务的基准分数。结果显示，scaling laws通常适用于KGE任务，但存在平台效应（plateau effects）和上限效应（ceiling effects），即更大模型的性能提升有限；在同一模型家族中，有时较小模型表现出色，因此建议测试相邻大小模型以实现更高成本效益。",
      "categories": [
        "cs.AI",
        "cs.CL"
      ],
      "primary_category": "cs.AI",
      "comment": "Peer reviewed and to appear in the ESWC 2025 Workshops and Tutorials\n  Joint Proceedings (Workshop on Evaluation of Language Models in Knowledge\n  Engineering [ELMKE])",
      "pdf_url": "http://arxiv.org/pdf/2505.16276v1",
      "published_date": "2025-05-22 06:21:40 UTC",
      "updated_date": "2025-05-22 06:21:40 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-25T03:39:20.327070"
    },
    {
      "arxiv_id": "2505.16270v1",
      "title": "Transformer Copilot: Learning from The Mistake Log in LLM Fine-tuning",
      "title_zh": "翻译失败",
      "authors": [
        "Jiaru Zou",
        "Yikun Ban",
        "Zihao Li",
        "Yunzhe Qi",
        "Ruizhong Qiu",
        "Ling Yang",
        "Jingrui He"
      ],
      "abstract": "Large language models are typically adapted to downstream tasks through\nsupervised fine-tuning on domain-specific data. While standard fine-tuning\nfocuses on minimizing generation loss to optimize model parameters, we take a\ndeeper step by retaining and leveraging the model's own learning signals,\nanalogous to how human learners reflect on past mistakes to improve future\nperformance. We first introduce the concept of Mistake Log to systematically\ntrack the model's learning behavior and recurring errors throughout\nfine-tuning. Treating the original transformer-based model as the Pilot, we\ncorrespondingly design a Copilot model to refine the Pilot's inference\nperformance via logits rectification. We name the overall Pilot-Copilot\nframework the Transformer Copilot, which introduces (i) a novel Copilot model\ndesign, (ii) a joint training paradigm where the Copilot continuously learns\nfrom the evolving Mistake Log alongside the Pilot, and (iii) a fused inference\nparadigm where the Copilot rectifies the Pilot's logits for enhanced\ngeneration. We provide both theoretical and empirical analyses on our new\nlearning framework. Experiments on 12 benchmarks spanning commonsense,\narithmetic, and recommendation tasks demonstrate that Transformer Copilot\nconsistently improves performance by up to 34.5%, while introducing marginal\ncomputational overhead to Pilot models and exhibiting strong scalability and\ntransferability.",
      "tldr_zh": "该论文提出 Transformer Copilot 框架，用于提升大型语言模型（LLMs）的微调性能，通过引入 Mistake Log 来系统跟踪模型在训练过程中的错误和学习行为。框架将原模型视为 Pilot，并设计 Copilot 模型进行联合训练和 logits rectification，从而从 Mistake Log 中学习并改进 Pilot 的推理输出。实验在涵盖常识、算术和推荐的 12 个基准上显示，性能提升高达 34.5%，同时保持低计算开销和良好的可扩展性及可转移性。",
      "categories": [
        "cs.CL",
        "cs.AI",
        "cs.LG"
      ],
      "primary_category": "cs.CL",
      "comment": "33 pages, 7 figures",
      "pdf_url": "http://arxiv.org/pdf/2505.16270v1",
      "published_date": "2025-05-22 06:00:45 UTC",
      "updated_date": "2025-05-22 06:00:45 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-25T03:39:32.339895"
    },
    {
      "arxiv_id": "2505.16259v1",
      "title": "Dialogue in Resonance: An Interactive Music Piece for Piano and Real-Time Automatic Transcription System",
      "title_zh": "Dialogue in Resonance：钢琴与实时自动转录系统的互动音乐作品",
      "authors": [
        "Hayeon Bang",
        "Taegyun Kwon",
        "Juhan Nam"
      ],
      "abstract": "This paper presents <Dialogue in Resonance>, an interactive music piece for a\nhuman pianist and a computer-controlled piano that integrates real-time\nautomatic music transcription into a score-driven framework. Unlike previous\napproaches that primarily focus on improvisation-based interactions, our work\nestablishes a balanced framework that combines composed structure with dynamic\ninteraction. Through real-time automatic transcription as its core mechanism,\nthe computer interprets and responds to the human performer's input in real\ntime, creating a musical dialogue that balances compositional intent with live\ninteraction while incorporating elements of unpredictability. In this paper, we\npresent the development process from composition to premiere performance,\nincluding technical implementation, rehearsal process, and performance\nconsiderations.",
      "tldr_zh": "本论文介绍了《Dialogue in Resonance》，一个互动音乐作品，结合人类钢琴家和计算机控制钢琴，通过实时自动音乐转录（real-time automatic transcription）系统实现作曲结构与动态互动的平衡框架。该系统以实时转录为核心机制，允许计算机即时解读并响应表演者的输入，创造出融合预设意图、不确定性和音乐对话的体验。论文详细阐述了从作曲到首演的开发过程，包括技术实现、排练和表演考虑，为互动音乐领域提供了创新范例。",
      "categories": [
        "cs.SD",
        "cs.AI",
        "eess.AS"
      ],
      "primary_category": "cs.SD",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2505.16259v1",
      "published_date": "2025-05-22 05:50:13 UTC",
      "updated_date": "2025-05-22 05:50:13 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-25T03:39:43.501926"
    },
    {
      "arxiv_id": "2505.16258v1",
      "title": "IRONIC: Coherence-Aware Reasoning Chains for Multi-Modal Sarcasm Detection",
      "title_zh": "翻译失败",
      "authors": [
        "Aashish Anantha Ramakrishnan",
        "Aadarsh Anantha Ramakrishnan",
        "Dongwon Lee"
      ],
      "abstract": "Interpreting figurative language such as sarcasm across multi-modal inputs\npresents unique challenges, often requiring task-specific fine-tuning and\nextensive reasoning steps. However, current Chain-of-Thought approaches do not\nefficiently leverage the same cognitive processes that enable humans to\nidentify sarcasm. We present IRONIC, an in-context learning framework that\nleverages Multi-modal Coherence Relations to analyze referential, analogical\nand pragmatic image-text linkages. Our experiments show that IRONIC achieves\nstate-of-the-art performance on zero-shot Multi-modal Sarcasm Detection across\ndifferent baselines. This demonstrates the need for incorporating linguistic\nand cognitive insights into the design of multi-modal reasoning strategies. Our\ncode is available at: https://github.com/aashish2000/IRONIC",
      "tldr_zh": "该研究提出IRONIC框架，这是一种基于多模态连贯性关系（Multi-modal Coherence Relations）的上下文学习方法，用于多模态讽刺检测（Multi-modal Sarcasm Detection），通过分析referential、analogical和pragmatic图像-文本联系来提升推理效率。不同于传统的Chain-of-Thought方法，IRONIC更有效地模拟人类认知过程，实现零样本（zero-shot）场景下的讽刺识别。实验结果显示，IRONIC在多个基线上达到了最先进性能，强调了在多模态推理策略中融入语言和认知洞察的必要性。",
      "categories": [
        "cs.CL",
        "cs.AI",
        "cs.CV",
        "68T50",
        "I.2.7; I.2.10"
      ],
      "primary_category": "cs.CL",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2505.16258v1",
      "published_date": "2025-05-22 05:49:01 UTC",
      "updated_date": "2025-05-22 05:49:01 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-25T03:39:55.893294"
    },
    {
      "arxiv_id": "2505.16256v1",
      "title": "DualComp: End-to-End Learning of a Unified Dual-Modality Lossless Compressor",
      "title_zh": "翻译失败",
      "authors": [
        "Yan Zhao",
        "Zhengxue Cheng",
        "Junxuan Zhang",
        "Qunshan Gu",
        "Qi Wang",
        "Li Song"
      ],
      "abstract": "Most learning-based lossless compressors are designed for a single modality,\nrequiring separate models for multi-modal data and lacking flexibility.\nHowever, different modalities vary significantly in format and statistical\nproperties, making it ineffective to use compressors that lack\nmodality-specific adaptations. While multi-modal large language models (MLLMs)\noffer a potential solution for modality-unified compression, their excessive\ncomplexity hinders practical deployment. To address these challenges, we focus\non the two most common modalities, image and text, and propose DualComp, the\nfirst unified and lightweight learning-based dual-modality lossless compressor.\nBuilt on a lightweight backbone, DualComp incorporates three key structural\nenhancements to handle modality heterogeneity: modality-unified tokenization,\nmodality-switching contextual learning, and modality-routing\nmixture-of-experts. A reparameterization training strategy is also used to\nboost compression performance. DualComp integrates both modality-specific and\nshared parameters for efficient parameter utilization, enabling near real-time\ninference (200KB/s) on desktop CPUs. With much fewer parameters, DualComp\nachieves compression performance on par with the SOTA LLM-based methods for\nboth text and image datasets. Its simplified single-modality variant surpasses\nthe previous best image compressor on the Kodak dataset by about 9% using just\n1.2% of the model size.",
      "tldr_zh": "该研究提出 DualComp，一种端到端（End-to-End）学习框架，用于统一双模态（图像和文本）的无损压缩器，解决了现有学习-based 压缩器针对单一模态设计、缺乏灵活性和模态异质性等问题。DualComp 基于轻量级 backbone，引入模态统一标记化（modality-unified tokenization）、模态切换上下文学习（modality-switching contextual learning）和模态路由混合专家（modality-routing mixture-of-experts），并采用 reparameterization 训练策略来优化性能，同时整合模态特定和共享参数，支持近实时推理（200KB/s）在桌面 CPU 上。实验结果显示，DualComp 以远少参数（比 SOTA LLM-based 方法少）达到相媲美或更好的压缩性能，并在 Kodak 数据集上，其简化单模态变体比之前最佳图像压缩器提高约9%。",
      "categories": [
        "cs.CV",
        "cs.AI",
        "cs.MM"
      ],
      "primary_category": "cs.CV",
      "comment": "18 pages, 11 figures, 7 tables",
      "pdf_url": "http://arxiv.org/pdf/2505.16256v1",
      "published_date": "2025-05-22 05:46:14 UTC",
      "updated_date": "2025-05-22 05:46:14 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-25T03:40:09.877060"
    },
    {
      "arxiv_id": "2505.16249v1",
      "title": "Manipulating Elasto-Plastic Objects With 3D Occupancy and Learning-Based Predictive Control",
      "title_zh": "利用 3D 占用和基于学习的",
      "authors": [
        "Zhen Zhang",
        "Xiangyu Chu",
        "Yunxi Tang",
        "Lulu Zhao",
        "Jing Huang",
        "Zhongliang Jiang",
        "K. W. Samuel Au"
      ],
      "abstract": "Manipulating elasto-plastic objects remains a significant challenge due to\nsevere self-occlusion, difficulties of representation, and complicated\ndynamics. This work proposes a novel framework for elasto-plastic object\nmanipulation with a quasi-static assumption for motions, leveraging 3D\noccupancy to represent such objects, a learned dynamics model trained with 3D\noccupancy, and a learning-based predictive control algorithm to address these\nchallenges effectively. We build a novel data collection platform to collect\nfull spatial information and propose a pipeline for generating a 3D occupancy\ndataset. To infer the 3D occupancy during manipulation, an occupancy prediction\nnetwork is trained with multiple RGB images supervised by the generated\ndataset. We design a deep neural network empowered by a 3D convolution neural\nnetwork (CNN) and a graph neural network (GNN) to predict the complex\ndeformation with the inferred 3D occupancy results. A learning-based predictive\ncontrol algorithm is introduced to plan the robot actions, incorporating a\nnovel shape-based action initialization module specifically designed to improve\nthe planner efficiency. The proposed framework in this paper can successfully\nshape the elasto-plastic objects into a given goal shape and has been verified\nin various experiments both in simulation and the real world.",
      "tldr_zh": "该研究针对操纵弹性-塑性物体(elasto-plastic objects)的挑战，包括严重自遮挡、表示困难和复杂动态，提出了一种新框架，利用准静态假设和3D occupancy表示方法。框架包括训练一个基于多个RGB图像的occupancy prediction network，以及一个结合3D CNN和GNN的深度神经网络来预测物体变形，并引入学习-based predictive control算法，配以shape-based action initialization模块来优化机器人动作规划。在模拟和真实世界实验中，该框架成功地将物体塑形到目标形状，显著提高了操纵效率和准确性。",
      "categories": [
        "cs.RO",
        "cs.AI"
      ],
      "primary_category": "cs.RO",
      "comment": "8 Pages, 5 figures, accepted for publication in IEEE Robotics and\n  Automation Letters (RA-L)",
      "pdf_url": "http://arxiv.org/pdf/2505.16249v1",
      "published_date": "2025-05-22 05:36:00 UTC",
      "updated_date": "2025-05-22 05:36:00 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-25T03:40:19.557062"
    },
    {
      "arxiv_id": "2505.16234v1",
      "title": "LIFEBench: Evaluating Length Instruction Following in Large Language Models",
      "title_zh": "LIFEBench：评估大型语言模型中的长度指令遵循",
      "authors": [
        "Wei Zhang",
        "Zhenhong Zhou",
        "Junfeng Fang",
        "Rongwu Xu",
        "Kun Wang",
        "Yuanhe Zhang",
        "Rui Wang",
        "Ge Zhang",
        "Xinfeng Li",
        "Li Sun",
        "Lingjuan Lyu",
        "Yang Liu",
        "Sen Su"
      ],
      "abstract": "While large language models (LLMs) can solve PhD-level reasoning problems\nover long context inputs, they still struggle with a seemingly simpler task:\nfollowing explicit length instructions-e.g., write a 10,000-word novel.\nAdditionally, models often generate far too short outputs, terminate\nprematurely, or even refuse the request. Existing benchmarks focus primarily on\nevaluating generations quality, but often overlook whether the generations meet\nlength constraints. To this end, we introduce Length Instruction Following\nEvaluation Benchmark (LIFEBench) to comprehensively evaluate LLMs' ability to\nfollow length instructions across diverse tasks and a wide range of specified\nlengths. LIFEBench consists of 10,800 instances across 4 task categories in\nboth English and Chinese, covering length constraints ranging from 16 to 8192\nwords. We evaluate 26 widely-used LLMs and find that most models reasonably\nfollow short-length instructions but deteriorate sharply beyond a certain\nthreshold. Surprisingly, almost all models fail to reach the vendor-claimed\nmaximum output lengths in practice, as further confirmed by our evaluations\nextending up to 32K words. Even long-context LLMs, despite their extended\ninput-output windows, counterintuitively fail to improve length-instructions\nfollowing. Notably, Reasoning LLMs outperform even specialized long-text\ngeneration models, achieving state-of-the-art length following. Overall,\nLIFEBench uncovers fundamental limitations in current LLMs' length instructions\nfollowing ability, offering critical insights for future progress.",
      "tldr_zh": "本论文引入了LIFEBench基准，用于评估大型语言模型(LLMs)在遵循长度指令方面的能力，因为现有模型虽能处理复杂推理，却常在生成指定长度的输出（如1万字小说）时表现不足。LIFEBench包含10,800个实例，覆盖4个任务类别、英文和中文，以及从16到8192词的长度范围，通过测试26个LLMs发现，大多数模型在短长度指令上表现良好，但超过阈值后急剧下降，且几乎无法达到声称的最大输出长度。实验结果显示，推理型LLMs优于专门的长文本生成模型，这揭示了当前LLMs在长度指令遵循上的根本限制，并为未来改进提供关键洞见。",
      "categories": [
        "cs.CL",
        "cs.AI"
      ],
      "primary_category": "cs.CL",
      "comment": "81 pages, 22 tables, 32 figures. Homepage:\n  https://ydyjya.github.io/LIFEBench/",
      "pdf_url": "http://arxiv.org/pdf/2505.16234v1",
      "published_date": "2025-05-22 05:08:27 UTC",
      "updated_date": "2025-05-22 05:08:27 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-25T03:40:32.924251"
    },
    {
      "arxiv_id": "2505.16227v1",
      "title": "Explain Less, Understand More: Jargon Detection via Personalized Parameter-Efficient Fine-tuning",
      "title_zh": "翻译失败",
      "authors": [
        "Bohao Wu",
        "Qingyun Wang",
        "Yue Guo"
      ],
      "abstract": "Personalizing jargon detection and explanation is essential for making\ntechnical documents accessible to readers with diverse disciplinary\nbackgrounds. However, tailoring models to individual users typically requires\nsubstantial annotation efforts and computational resources due to user-specific\nfinetuning. To address this, we present a systematic study of personalized\njargon detection, focusing on methods that are both efficient and scalable for\nreal-world deployment. We explore two personalization strategies: (1)\nlightweight fine-tuning using Low-Rank Adaptation (LoRA) on open-source models,\nand (2) personalized prompting, which tailors model behavior at inference time\nwithout retaining. To reflect realistic constraints, we also investigate hybrid\napproaches that combine limited annotated data with unsupervised user\nbackground signals. Our personalized LoRA model outperforms GPT-4 by 21.4% in\nF1 score and exceeds the best performing oracle baseline by 8.3%. Remarkably,\nour method achieves comparable performance using only 10% of the annotated\ntraining data, demonstrating its practicality for resource-constrained\nsettings. Our study offers the first work to systematically explore efficient,\nlow-resource personalization of jargon detection using open-source language\nmodels, offering a practical path toward scalable, user-adaptive NLP system.",
      "tldr_zh": "这篇论文探讨了通过个性化参数高效微调来实现术语检测(jargon detection)，旨在使技术文档更易于不同学科背景的读者访问，同时减少标注和计算资源需求。研究者探索了两种策略：使用 Low-Rank Adaptation (LoRA) 进行轻量级微调，以及在推理时通过个性化提示调整模型行为；此外，还测试了结合有限标注数据和无监督用户背景信号的混合方法。结果显示，个性化 LoRA 模型在 F1 score 上比 GPT-4 高 21.4%，并超过了最佳预言机基线 8.3%，且仅需 10% 的标注训练数据即可实现类似性能。该工作首次系统地研究了使用开源语言模型的低资源个性化术语检测，为可扩展的用户适应性 NLP 系统提供了实用路径。",
      "categories": [
        "cs.CL",
        "cs.AI",
        "cs.LG"
      ],
      "primary_category": "cs.CL",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2505.16227v1",
      "published_date": "2025-05-22 04:55:41 UTC",
      "updated_date": "2025-05-22 04:55:41 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-25T03:40:45.962411"
    },
    {
      "arxiv_id": "2505.16225v1",
      "title": "MAPLE: Many-Shot Adaptive Pseudo-Labeling for In-Context Learning",
      "title_zh": "翻译失败",
      "authors": [
        "Zihan Chen",
        "Song Wang",
        "Zhen Tan",
        "Jundong Li",
        "Cong Shen"
      ],
      "abstract": "In-Context Learning (ICL) empowers Large Language Models (LLMs) to tackle\ndiverse tasks by incorporating multiple input-output examples, known as\ndemonstrations, into the input of LLMs. More recently, advancements in the\nexpanded context windows of LLMs have led to many-shot ICL, which uses hundreds\nof demonstrations and outperforms few-shot ICL, which relies on fewer examples.\nHowever, this approach is often hindered by the high cost of obtaining large\namounts of labeled data. To address this challenge, we propose Many-Shot\nAdaptive Pseudo-LabEling, namely MAPLE, a novel influence-based many-shot ICL\nframework that utilizes pseudo-labeled samples to compensate for the lack of\nlabel information. We first identify a subset of impactful unlabeled samples\nand perform pseudo-labeling on them by querying LLMs. These pseudo-labeled\nsamples are then adaptively selected and tailored to each test query as input\nto improve the performance of many-shot ICL, without significant labeling\ncosts. Extensive experiments on real-world datasets demonstrate the\neffectiveness of our framework, showcasing its ability to enhance LLM\nadaptability and performance with limited labeled data.",
      "tldr_zh": "该研究提出 MAPLE，一种基于影响的 many-shot In-Context Learning (ICL) 框架，通过自适应伪标签技术来解决 Large Language Models (LLMs) 在处理数百个演示示例时因标注数据成本高而带来的挑战。MAPLE 方法首先识别有影响的无标签样本并使用 LLMs 进行伪标签生成，然后根据每个测试查询动态选择和调整这些伪标签样本作为输入，以提升模型性能。实验在真实数据集上验证了 MAPLE 的有效性，显著提高了 LLMs 的适应性和表现，同时减少了对标注数据的依赖。",
      "categories": [
        "cs.AI"
      ],
      "primary_category": "cs.AI",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2505.16225v1",
      "published_date": "2025-05-22 04:54:27 UTC",
      "updated_date": "2025-05-22 04:54:27 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-25T03:40:56.484064"
    },
    {
      "arxiv_id": "2505.16223v1",
      "title": "MADCluster: Model-agnostic Anomaly Detection with Self-supervised Clustering Network",
      "title_zh": "翻译失败",
      "authors": [
        "Sangyong Lee",
        "Subo Hwang",
        "Dohoon Kim"
      ],
      "abstract": "In this paper, we propose MADCluster, a novel model-agnostic anomaly\ndetection framework utilizing self-supervised clustering. MADCluster is\napplicable to various deep learning architectures and addresses the\n'hypersphere collapse' problem inherent in existing deep learning-based anomaly\ndetection methods. The core idea is to cluster normal pattern data into a\n'single cluster' while simultaneously learning the cluster center and mapping\ndata close to this center. Also, to improve expressiveness and enable effective\nsingle clustering, we propose a new 'One-directed Adaptive loss'. The\noptimization of this loss is mathematically proven. MADCluster consists of\nthree main components: Base Embedder capturing high-dimensional temporal\ndynamics, Cluster Distance Mapping, and Sequence-wise Clustering for continuous\ncenter updates. Its model-agnostic characteristics are achieved by applying\nvarious architectures to the Base Embedder. Experiments on four time series\nbenchmark datasets demonstrate that applying MADCluster improves the overall\nperformance of comparative models. In conclusion, the compatibility of\nMADCluster shows potential for enhancing model performance across various\narchitectures.",
      "tldr_zh": "本研究提出MADCluster，一种模型无关的异常检测框架，利用self-supervised clustering解决现有深度学习方法中的hypersphere collapse问题。核心机制包括将正常模式数据聚类到一个single cluster，同时学习聚类中心并引入One-directed Adaptive loss，以提升表达力和优化效果，该损失的优化已得到数学证明。框架由Base Embedder（捕捉高维时间动态）、Cluster Distance Mapping和Sequence-wise Clustering（用于连续更新中心）三部分组成，并在四个时间序列基准数据集上的实验中，提高了比较模型的整体性能，展示了其在各种架构上的兼容性和潜力。",
      "categories": [
        "cs.AI",
        "cs.LG"
      ],
      "primary_category": "cs.AI",
      "comment": "24 pages, 9 figures",
      "pdf_url": "http://arxiv.org/pdf/2505.16223v1",
      "published_date": "2025-05-22 04:50:44 UTC",
      "updated_date": "2025-05-22 04:50:44 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-25T03:41:08.399263"
    },
    {
      "arxiv_id": "2505.16221v1",
      "title": "LightRouter: Towards Efficient LLM Collaboration with Minimal Overhead",
      "title_zh": "翻译失败",
      "authors": [
        "Yifan Zhang",
        "Xinkui Zhao",
        "Zuxin Wang",
        "Guanjie Cheng",
        "Yueshen Xu",
        "Shuiguang Deng",
        "Jianwei Yin"
      ],
      "abstract": "The rapid advancement of large language models has unlocked remarkable\ncapabilities across a diverse array of natural language processing tasks.\nHowever, the considerable differences among available LLMs-in terms of cost,\nperformance, and computational demands-pose significant challenges for users\naiming to identify the most suitable model for specific tasks. In this work, we\npresent LightRouter, a novel framework designed to systematically select and\nintegrate a small subset of LLMs from a larger pool, with the objective of\njointly optimizing both task performance and cost efficiency. LightRouter\nleverages an adaptive selection mechanism to identify models that require only\na minimal number of boot tokens, thereby reducing costs, and further employs an\neffective integration strategy to combine their outputs. Extensive experiments\nacross multiple benchmarks demonstrate that LightRouter matches or outperforms\nwidely-used ensemble baselines, achieving up to a 25% improvement in accuracy.\nCompared with leading high-performing models, LightRouter achieves comparable\nperformance while reducing inference costs by up to 27%. Importantly, our\nframework operates without any prior knowledge of individual models and relies\nexclusively on inexpensive, lightweight models. This work introduces a\npractical approach for efficient LLM selection and provides valuable insights\ninto optimal strategies for model combination.",
      "tldr_zh": "这篇论文介绍了 LightRouter 框架，一种用于高效协作大型语言模型 (LLM) 的方法，旨在从更大模型池中选择并整合一小部分模型，以优化任务性能和成本效率。LightRouter 采用自适应选择机制，仅选择需要最小启动标记的模型来降低开销，并通过有效的输出整合策略结合它们的结果。实验在多个基准上显示，该框架比常见集合基线提高准确率高达 25%，并与高性能模型相当的同时降低推理成本高达 27%。此外，LightRouter 不依赖任何模型先验知识，仅使用廉价轻量模型，为 LLM 的实际选择和组合策略提供了宝贵见解。",
      "categories": [
        "cs.AI"
      ],
      "primary_category": "cs.AI",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2505.16221v1",
      "published_date": "2025-05-22 04:46:04 UTC",
      "updated_date": "2025-05-22 04:46:04 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-25T03:41:20.131243"
    },
    {
      "arxiv_id": "2505.16211v1",
      "title": "AudioTrust: Benchmarking the Multifaceted Trustworthiness of Audio Large Language Models",
      "title_zh": "翻译失败",
      "authors": [
        "Kai Li",
        "Can Shen",
        "Yile Liu",
        "Jirui Han",
        "Kelong Zheng",
        "Xuechao Zou",
        "Zhe Wang",
        "Xingjian Du",
        "Shun Zhang",
        "Hanjun Luo",
        "Yingbin Jin",
        "Xinxin Xing",
        "Ziyang Ma",
        "Yue Liu",
        "Xiaojun Jia",
        "Yifan Zhang",
        "Junfeng Fang",
        "Kun Wang",
        "Yibo Yan",
        "Haoyang Li",
        "Yiming Li",
        "Xiaobin Zhuang",
        "Yang Liu",
        "Haibo Hu",
        "Zhuo Chen",
        "Zhizheng Wu",
        "Xiaolin Hu",
        "Eng-Siong Chng",
        "XiaoFeng Wang",
        "Wenyuan Xu",
        "Wei Dong",
        "Xinfeng Li"
      ],
      "abstract": "The rapid advancement and expanding applications of Audio Large Language\nModels (ALLMs) demand a rigorous understanding of their trustworthiness.\nHowever, systematic research on evaluating these models, particularly\nconcerning risks unique to the audio modality, remains largely unexplored.\nExisting evaluation frameworks primarily focus on the text modality or address\nonly a restricted set of safety dimensions, failing to adequately account for\nthe unique characteristics and application scenarios inherent to the audio\nmodality. We introduce AudioTrust-the first multifaceted trustworthiness\nevaluation framework and benchmark specifically designed for ALLMs. AudioTrust\nfacilitates assessments across six key dimensions: fairness, hallucination,\nsafety, privacy, robustness, and authentication. To comprehensively evaluate\nthese dimensions, AudioTrust is structured around 18 distinct experimental\nsetups. Its core is a meticulously constructed dataset of over 4,420 audio/text\nsamples, drawn from real-world scenarios (e.g., daily conversations, emergency\ncalls, voice assistant interactions), specifically designed to probe the\nmultifaceted trustworthiness of ALLMs. For assessment, the benchmark carefully\ndesigns 9 audio-specific evaluation metrics, and we employ a large-scale\nautomated pipeline for objective and scalable scoring of model outputs.\nExperimental results reveal the trustworthiness boundaries and limitations of\ncurrent state-of-the-art open-source and closed-source ALLMs when confronted\nwith various high-risk audio scenarios, offering valuable insights for the\nsecure and trustworthy deployment of future audio models. Our platform and\nbenchmark are available at https://github.com/JusperLee/AudioTrust.",
      "tldr_zh": "本研究引入了 AudioTrust，这是第一个针对 Audio Large Language Models (ALLMs) 的多方面可信度评估框架和基准，旨在填补现有评估对音频模态独特风险的忽略。AudioTrust 涵盖六个关键维度，包括 fairness（公平性）、hallucination（幻觉）、safety（安全性）、privacy（隐私）、robustness（鲁棒性）和 authentication（认证），并设计了 18 个实验设置和一个包含超过 4,420 个音频/文本样本的数据集，基于真实场景如日常对话和紧急呼叫。框架采用 9 个音频特定评估指标及大规模自动化管道进行客观评分，实验结果揭示了当前开源和闭源 ALLMs 在高风险音频场景中的局限性，并为未来音频模型的安全部署提供宝贵见解。开源平台可访问 https://github.com/JusperLee/AudioTrust。",
      "categories": [
        "cs.SD",
        "cs.AI",
        "cs.CL",
        "eess.AS"
      ],
      "primary_category": "cs.SD",
      "comment": "Technical Report",
      "pdf_url": "http://arxiv.org/pdf/2505.16211v1",
      "published_date": "2025-05-22 04:27:46 UTC",
      "updated_date": "2025-05-22 04:27:46 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-25T03:41:33.142071"
    },
    {
      "arxiv_id": "2505.16210v1",
      "title": "NQKV: A KV Cache Quantization Scheme Based on Normal Distribution Characteristics",
      "title_zh": "NQKV：基于正态分布特征的 KV 缓存量化方案",
      "authors": [
        "Zhihang Cai",
        "Xingjun Zhang",
        "Zhendong Tan",
        "Zheng Wei"
      ],
      "abstract": "Large Language Models (LLMs) have demonstrated remarkable proficiency across\na wide range of tasks. However, LLMs often require larger batch sizes to\nenhance throughput or longer context lengths to meet task demands, which\nsignificantly increases the memory resource consumption of the Key-Value (KV)\ncache during inference, becoming a major bottleneck in LLM deployment. To\naddress this issue, quantization is a common and straightforward approach.\nCurrently, quantization methods for activations are limited to 8-bit, and\nquantization to even lower bits can lead to substantial accuracy drops. To\nfurther save space by quantizing the KV cache to even lower bits, we analyzed\nthe element distribution of the KV cache and designed the NQKV algorithm. Since\nthe elements within each block of the KV cache follow a normal distribution,\nNQKV employs per-block quantile quantization to achieve\ninformation-theoretically optimal quantization error. Without significantly\ncompromising model output quality, NQKV enables the OPT model to perform\ninference with an 2x larger batch size or a 4x longer context length, and it\nimproves throughput by 9.3x compared to when the KV cache is not used.",
      "tldr_zh": "本研究针对大型语言模型(LLMs)中Key-Value (KV) cache的内存消耗问题，提出NQKV算法，该算法基于KV cache元素遵循正态分布的特性，使用per-block quantile quantization来实现信息理论最优的量化错误最小化。相比现有方法，NQKV能够在不显著影响模型输出质量的情况下，使OPT模型支持2倍大的批量大小或4倍长的上下文长度。实验结果显示，NQKV将模型吞吐量提高了9.3倍，为高效的LLM部署提供了重要优化。",
      "categories": [
        "cs.LG",
        "cs.AI",
        "cs.CL"
      ],
      "primary_category": "cs.LG",
      "comment": "11 pages, 9 figures",
      "pdf_url": "http://arxiv.org/pdf/2505.16210v1",
      "published_date": "2025-05-22 04:23:19 UTC",
      "updated_date": "2025-05-22 04:23:19 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-25T03:41:44.291551"
    },
    {
      "arxiv_id": "2505.16208v1",
      "title": "Using Echo-State Networks to Reproduce Rare Events in Chaotic Systems",
      "title_zh": "利用 Echo-State Networks 重现混沌系统中的稀有事件",
      "authors": [
        "Anton Erofeev",
        "Balasubramanya T. Nadiga",
        "Ilya Timofeyev"
      ],
      "abstract": "We apply the Echo-State Networks to predict the time series and statistical\nproperties of the competitive Lotka-Volterra model in the chaotic regime. In\nparticular, we demonstrate that Echo-State Networks successfully learn the\nchaotic attractor of the competitive Lotka-Volterra model and reproduce\nhistograms of dependent variables, including tails and rare events. We use the\nGeneralized Extreme Value distribution to quantify the tail behavior.",
      "tldr_zh": "本研究使用 Echo-State Networks 来预测竞争性 Lotka-Volterra 模型在混沌状态下的时间序列和统计属性。结果表明，Echo-State Networks 成功学习了混沌吸引子，并能准确重现相关变量的直方图，包括尾部分布和稀有事件。论文通过 Generalized Extreme Value distribution 量化了尾部行为，为混沌系统中的事件预测提供了新方法。",
      "categories": [
        "nlin.CD",
        "cs.AI",
        "cs.LG",
        "math.DS",
        "37N99, 68T30"
      ],
      "primary_category": "nlin.CD",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2505.16208v1",
      "published_date": "2025-05-22 04:21:05 UTC",
      "updated_date": "2025-05-22 04:21:05 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-25T03:41:55.802236"
    },
    {
      "arxiv_id": "2505.16199v1",
      "title": "Velocity Completion Task and Method for Event-based Player Positional Data in Soccer",
      "title_zh": "翻译失败",
      "authors": [
        "Rikuhei Umemoto",
        "Keisuke Fujii"
      ],
      "abstract": "In many real-world complex systems, the behavior can be observed as a\ncollection of discrete events generated by multiple interacting agents.\nAnalyzing the dynamics of these multi-agent systems, especially team sports,\noften relies on understanding the movement and interactions of individual\nagents. However, while providing valuable snapshots, event-based positional\ndata typically lacks the continuous temporal information needed to directly\ncalculate crucial properties such as velocity. This absence severely limits the\ndepth of dynamic analysis, preventing a comprehensive understanding of\nindividual agent behaviors and emergent team strategies. To address this\nchallenge, we propose a new method to simultaneously complete the velocity of\nall agents using only the event-based positional data from team sports. Based\non this completed velocity information, we investigate the applicability of\nexisting team sports analysis and evaluation methods. Experiments using soccer\nevent data demonstrate that neural network-based approaches outperformed\nrule-based methods regarding velocity completion error, considering the\nunderlying temporal dependencies and graph structure of player-to-player or\nplayer-to-ball interaction. Moreover, the space evaluation results obtained\nusing the completed velocity are closer to those derived from complete tracking\ndata, highlighting our method's potential for enhanced team sports system\nanalysis.",
      "tldr_zh": "该论文针对足球等团队运动中的 event-based 球员位置数据问题，提出了一种新的速度完成任务和方法，用于从离散事件数据中推断所有球员的连续速度，从而解决动态分析的局限性。该方法采用 neural network-based 技术，考虑时间依赖性和球员间互动的图结构，优于传统的 rule-based 方法，在实验中降低了速度完成错误。结果表明，使用完成的速度信息进行空间评估，更接近完整跟踪数据，这为增强团队体育系统分析提供了潜力。",
      "categories": [
        "cs.AI"
      ],
      "primary_category": "cs.AI",
      "comment": "24 pages, 7 figures",
      "pdf_url": "http://arxiv.org/pdf/2505.16199v1",
      "published_date": "2025-05-22 04:01:49 UTC",
      "updated_date": "2025-05-22 04:01:49 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-25T03:42:08.442167"
    },
    {
      "arxiv_id": "2505.16196v1",
      "title": "SEM: Enhancing Spatial Understanding for Robust Robot Manipulation",
      "title_zh": "翻译失败",
      "authors": [
        "Xuewu Lin",
        "Tianwei Lin",
        "Lichao Huang",
        "Hongyu Xie",
        "Yiwei Jin",
        "Keyu Li",
        "Zhizhong Su"
      ],
      "abstract": "A key challenge in robot manipulation lies in developing policy models with\nstrong spatial understanding, the ability to reason about 3D geometry, object\nrelations, and robot embodiment. Existing methods often fall short: 3D point\ncloud models lack semantic abstraction, while 2D image encoders struggle with\nspatial reasoning. To address this, we propose SEM (Spatial Enhanced\nManipulation model), a novel diffusion-based policy framework that explicitly\nenhances spatial understanding from two complementary perspectives. A spatial\nenhancer augments visual representations with 3D geometric context, while a\nrobot state encoder captures embodiment-aware structure through graphbased\nmodeling of joint dependencies. By integrating these modules, SEM significantly\nimproves spatial understanding, leading to robust and generalizable\nmanipulation across diverse tasks that outperform existing baselines.",
      "tldr_zh": "机器人操作中的关键挑战是策略模型缺乏空间理解能力，包括3D几何、物体关系和机器人形态的推理，而现有3D点云模型缺少语义抽象，2D图像编码器则在空间推理上表现不足。针对此，本文提出SEM（Spatial Enhanced Manipulation model），一个基于扩散的策略框架，通过空间增强器添加3D几何上下文，并利用机器人状态编码器基于图模型捕获关节依赖性。整合这些模块后，SEM显著提升了空间理解能力，实现更鲁棒和可泛化的操作表现，超越了现有基线模型。",
      "categories": [
        "cs.RO",
        "cs.AI",
        "cs.CV"
      ],
      "primary_category": "cs.RO",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2505.16196v1",
      "published_date": "2025-05-22 04:00:12 UTC",
      "updated_date": "2025-05-22 04:00:12 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-25T03:42:20.332439"
    },
    {
      "arxiv_id": "2505.16195v1",
      "title": "SpecMaskFoley: Steering Pretrained Spectral Masked Generative Transformer Toward Synchronized Video-to-audio Synthesis via ControlNet",
      "title_zh": "翻译失败",
      "authors": [
        "Zhi Zhong",
        "Akira Takahashi",
        "Shuyang Cui",
        "Keisuke Toyama",
        "Shusuke Takahashi",
        "Yuki Mitsufuji"
      ],
      "abstract": "Foley synthesis aims to synthesize high-quality audio that is both\nsemantically and temporally aligned with video frames. Given its broad\napplication in creative industries, the task has gained increasing attention in\nthe research community. To avoid the non-trivial task of training audio\ngenerative models from scratch, adapting pretrained audio generative models for\nvideo-synchronized foley synthesis presents an attractive direction.\nControlNet, a method for adding fine-grained controls to pretrained generative\nmodels, has been applied to foley synthesis, but its use has been limited to\nhandcrafted human-readable temporal conditions. In contrast, from-scratch\nmodels achieved success by leveraging high-dimensional deep features extracted\nusing pretrained video encoders. We have observed a performance gap between\nControlNet-based and from-scratch foley models. To narrow this gap, we propose\nSpecMaskFoley, a method that steers the pretrained SpecMaskGIT model toward\nvideo-synchronized foley synthesis via ControlNet. To unlock the potential of a\nsingle ControlNet branch, we resolve the discrepancy between the temporal video\nfeatures and the time-frequency nature of the pretrained SpecMaskGIT via a\nfrequency-aware temporal feature aligner, eliminating the need for complicated\nconditioning mechanisms widely used in prior arts. Evaluations on a common\nfoley synthesis benchmark demonstrate that SpecMaskFoley could even outperform\nstrong from-scratch baselines, substantially advancing the development of\nControlNet-based foley synthesis models. Demo page:\nhttps://zzaudio.github.io/SpecMaskFoley_Demo/",
      "tldr_zh": "该论文提出 SpecMaskFoley 方法，通过 ControlNet 引导预训练的 SpecMaskGIT 模型，实现视频同步的 Foley synthesis，即合成与视频帧语义和时间上对齐的高质量音频。核心创新在于引入 frequency-aware temporal feature aligner 来解决视频特征的临时性质与音频的时间-频率特性的差异，从而简化了条件机制，避免了复杂的设计。与从零训练模型相比，SpecMaskFoley 在常见基准测试中表现出色，甚至超过了强有力的基线模型，推动了 ControlNet-based Foley synthesis 的发展。",
      "categories": [
        "cs.SD",
        "cs.AI",
        "cs.LG",
        "eess.AS",
        "eess.IV"
      ],
      "primary_category": "cs.SD",
      "comment": "4 pages, 2 figures, 2 tables. Demo page:\n  https://zzaudio.github.io/SpecMaskFoley_Demo/",
      "pdf_url": "http://arxiv.org/pdf/2505.16195v1",
      "published_date": "2025-05-22 03:58:16 UTC",
      "updated_date": "2025-05-22 03:58:16 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-25T03:42:33.225214"
    },
    {
      "arxiv_id": "2505.16192v1",
      "title": "VLM-R$^3$: Region Recognition, Reasoning, and Refinement for Enhanced Multimodal Chain-of-Thought",
      "title_zh": "VLM-R$^3$：区域识别、推理和细化为增强多模态链式思维",
      "authors": [
        "Chaoya Jiang",
        "Yongrui Heng",
        "Wei Ye",
        "Han Yang",
        "Haiyang Xu",
        "Ming Yan",
        "Ji Zhang",
        "Fei Huang",
        "Shikun Zhang"
      ],
      "abstract": "Recently, reasoning-based MLLMs have achieved a degree of success in\ngenerating long-form textual reasoning chains. However, they still struggle\nwith complex tasks that necessitate dynamic and iterative focusing on and\nrevisiting of visual regions to achieve precise grounding of textual reasoning\nin visual evidence. We introduce \\textbf{VLM-R$^3$} (\\textbf{V}isual\n\\textbf{L}anguage \\textbf{M}odel with \\textbf{R}egion \\textbf{R}ecognition and\n\\textbf{R}easoning), a framework that equips an MLLM with the ability to (i)\ndecide \\emph{when} additional visual evidence is needed, (ii) determine\n\\emph{where} to ground within the image, and (iii) seamlessly weave the\nrelevant sub-image content back into an interleaved chain-of-thought. The core\nof our method is \\textbf{Region-Conditioned Reinforcement Policy Optimization\n(R-GRPO)}, a training paradigm that rewards the model for selecting informative\nregions, formulating appropriate transformations (e.g.\\ crop, zoom), and\nintegrating the resulting visual context into subsequent reasoning steps. To\nbootstrap this policy, we compile a modest but carefully curated Visuo-Lingual\nInterleaved Rationale (VLIR) corpus that provides step-level supervision on\nregion selection and textual justification. Extensive experiments on MathVista,\nScienceQA, and other benchmarks show that VLM-R$^3$ sets a new state of the art\nin zero-shot and few-shot settings, with the largest gains appearing on\nquestions demanding subtle spatial reasoning or fine-grained visual cue\nextraction.",
      "tldr_zh": "该研究提出 VLM-R³ 框架，一种增强的多模态链式思维（Chain-of-Thought）模型，能够动态决定何时需要额外视觉证据、在图像中何处定位，以及将相关子图像内容无缝整合到推理过程中，以实现更精确的视觉地锚定。核心方法是 Region-Conditioned Reinforcement Policy Optimization (R-GRPO)，通过奖励模型选择信息丰富的区域、进行适当转换（如裁剪、缩放）并融入后续步骤来优化训练，同时利用 Visuo-Lingual Interleaved Rationale (VLIR) 语料库提供区域选择和文本理由的步骤级监督。实验结果显示，VLM-R³ 在 MathVista、ScienceQA 等基准上实现了零样本和少样本设置下的新状态-of-the-art 表现，尤其在需要微妙空间推理或精细视觉线索提取的任务中取得了最大提升。",
      "categories": [
        "cs.CV",
        "cs.AI"
      ],
      "primary_category": "cs.CV",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2505.16192v1",
      "published_date": "2025-05-22 03:50:13 UTC",
      "updated_date": "2025-05-22 03:50:13 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-25T03:42:45.027125"
    },
    {
      "arxiv_id": "2505.16187v1",
      "title": "EasyInsert: A Data-Efficient and Generalizable Insertion Policy",
      "title_zh": "EasyInsert: 一种数据高效且可泛化的插入策略",
      "authors": [
        "Guanghe Li",
        "Junming Zhao",
        "Shengjie Wang",
        "Yang Gao"
      ],
      "abstract": "Insertion task is highly challenging that requires robots to operate with\nexceptional precision in cluttered environments. Existing methods often have\npoor generalization capabilities. They typically function in restricted and\nstructured environments, and frequently fail when the plug and socket are far\napart, when the scene is densely cluttered, or when handling novel objects.\nThey also rely on strong assumptions such as access to CAD models or a digital\ntwin in simulation. To address this, we propose EasyInsert, a framework which\nleverages the human intuition that relative pose (delta pose) between plug and\nsocket is sufficient for successful insertion, and employs efficient and\nautomated real-world data collection with minimal human labor to train a\ngeneralizable model for relative pose prediction. During execution, EasyInsert\nfollows a coarse-to-fine execution procedure based on predicted delta pose, and\nsuccessfully performs various insertion tasks. EasyInsert demonstrates strong\nzero-shot generalization capability for unseen objects in cluttered\nenvironments, handling cases with significant initial pose deviations while\nmaintaining high sample efficiency and requiring little human effort. In\nreal-world experiments, with just 5 hours of training data, EasyInsert achieves\nover 90% success in zero-shot insertion for 13 out of 15 unseen novel objects,\nincluding challenging objects like Type-C cables, HDMI cables, and Ethernet\ncables. Furthermore, with only one human demonstration and 4 minutes of\nautomatically collected data for fine-tuning, it reaches over 90% success rate\nfor all 15 objects.",
      "tldr_zh": "该论文提出EasyInsert框架，以解决机器人插入任务在杂乱环境中的泛化难题，该框架利用相对位姿(delta pose)预测作为核心机制，并通过高效自动的真实世界数据收集来训练模型，减少了对CAD模型或模拟依赖。EasyInsert采用粗到细的执行策略，实现对未见对象的零样本泛化，并在初始位姿偏差大的场景中表现出色。实验结果显示，仅5小时训练数据即可在15个新对象中实现13个超过90%的插入成功率，包括Type-C、HDMI和Ethernet电缆；进一步微调后，所有对象均达到90%以上成功率。",
      "categories": [
        "cs.RO",
        "cs.AI"
      ],
      "primary_category": "cs.RO",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2505.16187v1",
      "published_date": "2025-05-22 03:46:05 UTC",
      "updated_date": "2025-05-22 03:46:05 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-25T03:42:57.580684"
    },
    {
      "arxiv_id": "2505.16186v1",
      "title": "SafeKey: Amplifying Aha-Moment Insights for Safety Reasoning",
      "title_zh": "翻译失败",
      "authors": [
        "Kaiwen Zhou",
        "Xuandong Zhao",
        "Gaowen Liu",
        "Jayanth Srinivasa",
        "Aosong Feng",
        "Dawn Song",
        "Xin Eric Wang"
      ],
      "abstract": "Large Reasoning Models (LRMs) introduce a new generation paradigm of\nexplicitly reasoning before answering, leading to remarkable improvements in\ncomplex tasks. However, they pose great safety risks against harmful queries\nand adversarial attacks. While recent mainstream safety efforts on LRMs,\nsupervised fine-tuning (SFT), improve safety performance, we find that\nSFT-aligned models struggle to generalize to unseen jailbreak prompts. After\nthorough investigation of LRMs' generation, we identify a safety aha moment\nthat can activate safety reasoning and lead to a safe response. This aha moment\ntypically appears in the `key sentence', which follows models' query\nunderstanding process and can indicate whether the model will proceed safely.\nBased on these insights, we propose SafeKey, including two complementary\nobjectives to better activate the safety aha moment in the key sentence: (1) a\nDual-Path Safety Head to enhance the safety signal in the model's internal\nrepresentations before the key sentence, and (2) a Query-Mask Modeling\nobjective to improve the models' attention on its query understanding, which\nhas important safety hints. Experiments across multiple safety benchmarks\ndemonstrate that our methods significantly improve safety generalization to a\nwide range of jailbreak attacks and out-of-distribution harmful prompts,\nlowering the average harmfulness rate by 9.6\\%, while maintaining general\nabilities. Our analysis reveals how SafeKey enhances safety by reshaping\ninternal attention and improving the quality of hidden representations.",
      "tldr_zh": "该研究针对 Large Reasoning Models (LRMs) 在处理有害查询和对抗攻击时的安全风险，识别出 \"safety aha moment\" 这一关键洞见，即模型在 \"key sentence\" 中激活安全推理以生成安全响应。论文提出 SafeKey 方法，包括 Dual-Path Safety Head 用于增强关键句前内部表示的安全信号，以及 Query-Mask Modeling 用于改善模型对查询理解的注意力，从而更好地泛化到未见 jailbreak 提示。实验结果显示，SafeKey 在多个安全基准上将平均有害率降低了 9.6%，显著提升了模型对各种攻击的抵抗力，同时保持了通用能力，并通过分析内部注意力重塑和隐藏表示质量来验证其有效性。",
      "categories": [
        "cs.AI",
        "cs.CL",
        "cs.CR"
      ],
      "primary_category": "cs.AI",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2505.16186v1",
      "published_date": "2025-05-22 03:46:03 UTC",
      "updated_date": "2025-05-22 03:46:03 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-25T03:43:09.306365"
    },
    {
      "arxiv_id": "2505.16181v1",
      "title": "Understanding Generative AI Capabilities in Everyday Image Editing Tasks",
      "title_zh": "理解生成式 AI 在日常图像编辑任务中的能力",
      "authors": [
        "Mohammad Reza Taesiri",
        "Brandon Collins",
        "Logan Bolton",
        "Viet Dac Lai",
        "Franck Dernoncourt",
        "Trung Bui",
        "Anh Totti Nguyen"
      ],
      "abstract": "Generative AI (GenAI) holds significant promise for automating everyday image\nediting tasks, especially following the recent release of GPT-4o on March 25,\n2025. However, what subjects do people most often want edited? What kinds of\nediting actions do they want to perform (e.g., removing or stylizing the\nsubject)? Do people prefer precise edits with predictable outcomes or highly\ncreative ones? By understanding the characteristics of real-world requests and\nthe corresponding edits made by freelance photo-editing wizards, can we draw\nlessons for improving AI-based editors and determine which types of requests\ncan currently be handled successfully by AI editors? In this paper, we present\na unique study addressing these questions by analyzing 83k requests from the\npast 12 years (2013-2025) on the Reddit community, which collected 305k\nPSR-wizard edits. According to human ratings, approximately only 33% of\nrequests can be fulfilled by the best AI editors (including GPT-4o,\nGemini-2.0-Flash, SeedEdit). Interestingly, AI editors perform worse on\nlow-creativity requests that require precise editing than on more open-ended\ntasks. They often struggle to preserve the identity of people and animals, and\nfrequently make non-requested touch-ups. On the other side of the table, VLM\njudges (e.g., o1) perform differently from human judges and may prefer AI edits\nmore than human edits. Code and qualitative examples are available at:\nhttps://psrdataset.github.io",
      "tldr_zh": "本研究探讨了 Generative AI (GenAI) 在日常图像编辑任务中的能力，通过分析 Reddit 上过去12年（2013-2025）的83k用户请求和305k专业编辑，揭示了人们常见的编辑需求（如移除或美化对象）和偏好（如精确 vs. 创意编辑）。结果显示，目前顶级 AI 编辑器（如 GPT-4o 和 Gemini-2.0-Flash）仅能成功处理约33%的请求，尤其在低创意、需精确编辑的任务上表现较差，常出现身份保留问题或额外修改。相比之下，VLM 判断（如 o1）更偏好 AI 编辑，而非人类编辑；这项工作为提升 AI 编辑器的设计和适用性提供了关键启示。",
      "categories": [
        "cs.CV",
        "cs.AI"
      ],
      "primary_category": "cs.CV",
      "comment": "Code and qualitative examples are available at:\n  https://psrdataset.github.io",
      "pdf_url": "http://arxiv.org/pdf/2505.16181v1",
      "published_date": "2025-05-22 03:35:15 UTC",
      "updated_date": "2025-05-22 03:35:15 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-25T03:43:21.571485"
    },
    {
      "arxiv_id": "2505.16176v1",
      "title": "Dynamic Sampling that Adapts: Iterative DPO for Self-Aware Mathematical Reasoning",
      "title_zh": "翻译失败",
      "authors": [
        "Jun Rao",
        "Xuebo Liu",
        "Hexuan Deng",
        "Zepeng Lin",
        "Zixiong Yu",
        "Jiansheng Wei",
        "Xiaojun Meng",
        "Min Zhang"
      ],
      "abstract": "In the realm of data selection for reasoning tasks, existing approaches\npredominantly rely on externally predefined static metrics such as difficulty\nand diversity, which are often designed for supervised fine-tuning (SFT) and\nlack adaptability to continuous training processes. A critical limitation of\nthese methods is their inability to dynamically align with the evolving\ncapabilities of models during online training, a gap that becomes increasingly\npronounced with the rise of dynamic training paradigms and online reinforcement\nlearning (RL) frameworks (e.g., R1 models). To address this, we introduce\nSAI-DPO, an algorithm that dynamically selects training data by continuously\nassessing a model's stage-specific reasoning abilities across different\ntraining phases. By integrating real-time model performance feedback, SAI-DPO\nadaptively adapts data selection to the evolving strengths and weaknesses of\nthe model, thus enhancing both data utilization efficiency and final task\nperformance. Extensive experiments on three state-of-the-art models and eight\nmathematical reasoning benchmarks, including challenging competition-level\ndatasets (e.g., AIME24 and AMC23), demonstrate that SAI-DPO achieves an average\nperformance boost of up to 21.3 percentage points, with particularly notable\nimprovements of 10 and 15 points on AIME24 and AMC23, respectively. These\nresults highlight the superiority of dynamic, model-adaptive data selection\nover static, externally defined strategies in advancing reasoning.",
      "tldr_zh": "本论文提出SAI-DPO算法，用于动态数据选择，以适应模型在在线训练中的演变，解决现有静态指标（如难度和多样性）在强化学习（RL）框架（如R1 models）中无法实时匹配模型能力的局限性。SAI-DPO通过持续评估模型在不同训练阶段的推理能力，并整合实时性能反馈，实现自适应数据选择，从而提升数据利用效率和数学推理任务的表现。在八个数学推理基准测试中，包括AIME24和AMC23等挑战性数据集，该算法在三个最先进模型上平均提升性能21.3个百分点，分别在AIME24和AMC23上获得10和15点的显著改善，证明了动态策略的优越性。",
      "categories": [
        "cs.AI",
        "cs.CL"
      ],
      "primary_category": "cs.AI",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2505.16176v1",
      "published_date": "2025-05-22 03:27:05 UTC",
      "updated_date": "2025-05-22 03:27:05 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-25T03:43:33.894974"
    },
    {
      "arxiv_id": "2505.16175v1",
      "title": "QuickVideo: Real-Time Long Video Understanding with System Algorithm Co-Design",
      "title_zh": "翻译失败",
      "authors": [
        "Benjamin Schneider",
        "Dongfu Jiang",
        "Chao Du",
        "Tianyu Pang",
        "Wenhu Chen"
      ],
      "abstract": "Long-video understanding has emerged as a crucial capability in real-world\napplications such as video surveillance, meeting summarization, educational\nlecture analysis, and sports broadcasting. However, it remains computationally\nprohibitive for VideoLLMs, primarily due to two bottlenecks: 1) sequential\nvideo decoding, the process of converting the raw bit stream to RGB frames can\ntake up to a minute for hour-long video inputs, and 2) costly prefilling of up\nto several million tokens for LLM inference, resulting in high latency and\nmemory use. To address these challenges, we propose QuickVideo, a\nsystem-algorithm co-design that substantially accelerates long-video\nunderstanding to support real-time downstream applications. It comprises three\nkey innovations: QuickDecoder, a parallelized CPU-based video decoder that\nachieves 2-3 times speedup by splitting videos into keyframe-aligned intervals\nprocessed concurrently; QuickPrefill, a memory-efficient prefilling method\nusing KV-cache pruning to support more frames with less GPU memory; and an\noverlapping scheme that overlaps CPU video decoding with GPU inference.\nTogether, these components infernece time reduce by a minute on long video\ninputs, enabling scalable, high-quality video understanding even on limited\nhardware. Experiments show that QuickVideo generalizes across durations and\nsampling rates, making long video processing feasible in practice.",
      "tldr_zh": "该论文提出QuickVideo框架，通过系统算法联合设计，解决长视频理解中的两个主要瓶颈：视频解码的顺序处理和高成本的LLM预填充，导致高延迟和内存消耗。QuickVideo的关键创新包括QuickDecoder（一个并行CPU解码器，将视频分成关键帧对齐区间并行处理，实现2-3倍加速）、QuickPrefill（使用KV-cache修剪的内存高效预填充方法，支持更多帧处理）和CPU解码与GPU推理的重叠方案。这些组件共同将长视频推理时间减少约一分钟，实验显示QuickVideo在不同视频时长和采样率上具有通用性和可扩展性，使实时长视频理解在有限硬件上变得可行。",
      "categories": [
        "cs.CV",
        "cs.AI"
      ],
      "primary_category": "cs.CV",
      "comment": "19 pages, 6 figures, 2 tables",
      "pdf_url": "http://arxiv.org/pdf/2505.16175v1",
      "published_date": "2025-05-22 03:26:50 UTC",
      "updated_date": "2025-05-22 03:26:50 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-25T03:43:45.921103"
    },
    {
      "arxiv_id": "2505.16172v1",
      "title": "Automated Feedback Loops to Protect Text Simplification with Generative AI from Information Loss",
      "title_zh": "翻译失败",
      "authors": [
        "Abhay Kumara Sri Krishna Nandiraju",
        "Gondy Leroy",
        "David Kauchak",
        "Arif Ahmed"
      ],
      "abstract": "Understanding health information is essential in achieving and maintaining a\nhealthy life. We focus on simplifying health information for better\nunderstanding. With the availability of generative AI, the simplification\nprocess has become efficient and of reasonable quality, however, the algorithms\nremove information that may be crucial for comprehension. In this study, we\ncompare generative AI to detect missing information in simplified text,\nevaluate its importance, and fix the text with the missing information. We\ncollected 50 health information texts and simplified them using gpt-4-0613. We\ncompare five approaches to identify missing elements and regenerate the text by\ninserting the missing elements. These five approaches involve adding missing\nentities and missing words in various ways: 1) adding all the missing entities,\n2) adding all missing words, 3) adding the top-3 entities ranked by gpt-4-0613,\nand 4, 5) serving as controls for comparison, adding randomly chosen entities.\nWe use cosine similarity and ROUGE scores to evaluate the semantic similarity\nand content overlap between the original, simplified, and reconstructed\nsimplified text. We do this for both summaries and full text. Overall, we find\nthat adding missing entities improves the text. Adding all the missing entities\nresulted in better text regeneration, which was better than adding the\ntop-ranked entities or words, or random words. Current tools can identify these\nentities, but are not valuable in ranking them.",
      "tldr_zh": "本研究针对生成式 AI（如 GPT-4-0613）在简化健康信息文本时可能导致信息丢失的问题，提出了一种自动化反馈循环机制来检测和修复缺失元素。研究者收集了50份健康信息文本，通过五种方法（如添加所有缺失实体、添加排名前三的实体或随机实体）来识别缺失的实体和单词，并使用余弦相似度和 ROUGE scores 评估语义相似性和内容重叠。结果显示，添加所有缺失实体的方法最有效，能够显著改善简化文本的质量，而当前工具虽能识别实体，但缺乏有效的排名功能，从而为保护文本简化的完整性提供了新途径。",
      "categories": [
        "cs.CL",
        "cs.AI"
      ],
      "primary_category": "cs.CL",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2505.16172v1",
      "published_date": "2025-05-22 03:19:49 UTC",
      "updated_date": "2025-05-22 03:19:49 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-25T03:43:57.536071"
    },
    {
      "arxiv_id": "2505.16149v1",
      "title": "When VLMs Meet Image Classification: Test Sets Renovation via Missing Label Identification",
      "title_zh": "翻译失败",
      "authors": [
        "Zirui Pang",
        "Haosheng Tan",
        "Yuhan Pu",
        "Zhijie Deng",
        "Zhouan Shen",
        "Keyu Hu",
        "Jiaheng Wei"
      ],
      "abstract": "Image classification benchmark datasets such as CIFAR, MNIST, and ImageNet\nserve as critical tools for model evaluation. However, despite the cleaning\nefforts, these datasets still suffer from pervasive noisy labels and often\ncontain missing labels due to the co-existing image pattern where multiple\nclasses appear in an image sample. This results in misleading model comparisons\nand unfair evaluations. Existing label cleaning methods focus primarily on\nnoisy labels, but the issue of missing labels remains largely overlooked.\nMotivated by these challenges, we present a comprehensive framework named\nREVEAL, integrating state-of-the-art pre-trained vision-language models (e.g.,\nLLaVA, BLIP, Janus, Qwen) with advanced machine/human label curation methods\n(e.g., Docta, Cleanlab, MTurk), to systematically address both noisy labels and\nmissing label detection in widely-used image classification test sets. REVEAL\ndetects potential noisy labels and omissions, aggregates predictions from\nvarious methods, and refines label accuracy through confidence-informed\npredictions and consensus-based filtering. Additionally, we provide a thorough\nanalysis of state-of-the-art vision-language models and pre-trained image\nclassifiers, highlighting their strengths and limitations within the context of\ndataset renovation by revealing 10 observations. Our method effectively reveals\nmissing labels from public datasets and provides soft-labeled results with\nlikelihoods. Through human verifications, REVEAL significantly improves the\nquality of 6 benchmark test sets, highly aligning to human judgments and\nenabling more accurate and meaningful comparisons in image classification.",
      "tldr_zh": "本研究针对图像分类基准数据集（如CIFAR、MNIST和ImageNet）中存在的噪声标签和缺失标签问题，提出REVEAL框架，该框架整合先进的视觉语言模型（VLMs，如LLaVA、BLIP）与标签整理方法（Docta、Cleanlab、MTurk），系统地检测和修复这些问题。REVEAL通过聚合多源预测、置信度信息和共识过滤来精炼标签，并分析VLMs和图像分类器的优缺点，揭示10个关键观察。实验结果显示，该框架显著提升了6个基准测试集的质量，与人类判断高度一致，从而实现更准确的模型评估和公平比较。",
      "categories": [
        "cs.CV",
        "cs.AI",
        "cs.CL"
      ],
      "primary_category": "cs.CV",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2505.16149v1",
      "published_date": "2025-05-22 02:47:36 UTC",
      "updated_date": "2025-05-22 02:47:36 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-25T03:44:09.434942"
    },
    {
      "arxiv_id": "2505.16147v1",
      "title": "Losing is for Cherishing: Data Valuation Based on Machine Unlearning and Shapley Value",
      "title_zh": "翻译失败",
      "authors": [
        "Le Ma",
        "Shirao Yang",
        "Zihao Wang",
        "Yinggui Wang",
        "Lei Wang",
        "Tao Wei",
        "Kejun Zhang"
      ],
      "abstract": "The proliferation of large models has intensified the need for efficient data\nvaluation methods to quantify the contribution of individual data providers.\nTraditional approaches, such as game-theory-based Shapley value and\ninfluence-function-based techniques, face prohibitive computational costs or\nrequire access to full data and model training details, making them hardly\nachieve partial data valuation. To address this, we propose Unlearning Shapley,\na novel framework that leverages machine unlearning to estimate data values\nefficiently. By unlearning target data from a pretrained model and measuring\nperformance shifts on a reachable test set, our method computes Shapley values\nvia Monte Carlo sampling, avoiding retraining and eliminating dependence on\nfull data. Crucially, Unlearning Shapley supports both full and partial data\nvaluation, making it scalable for large models (e.g., LLMs) and practical for\ndata markets. Experiments on benchmark datasets and large-scale text corpora\ndemonstrate that our approach matches the accuracy of state-of-the-art methods\nwhile reducing computational overhead by orders of magnitude. Further analysis\nconfirms a strong correlation between estimated values and the true impact of\ndata subsets, validating its reliability in real-world scenarios. This work\nbridges the gap between data valuation theory and practical deployment,\noffering a scalable, privacy-compliant solution for modern AI ecosystems.",
      "tldr_zh": "本研究针对数据估值方法的计算成本高和对完整数据依赖的问题，提出了一种名为Unlearning Shapley的框架，利用machine unlearning从预训练模型中移除目标数据，并通过测量性能变化和Monte Carlo sampling计算Shapley value，从而高效估算数据贡献。该方法避免了模型重新训练，支持全数据和部分数据估值，使其适用于大型模型（如LLMs）和数据市场。实验在基准数据集和大规模文本语料上显示，Unlearning Shapley的准确性与最先进方法相当，但计算开销减少了几个数量级，且估算值与数据子集的真实影响高度相关。该框架为数据估值提供了可扩展、隐私合规的实际解决方案，桥接了理论与部署的鸿沟。",
      "categories": [
        "cs.AI",
        "cs.LG"
      ],
      "primary_category": "cs.AI",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2505.16147v1",
      "published_date": "2025-05-22 02:46:03 UTC",
      "updated_date": "2025-05-22 02:46:03 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-25T03:44:20.876427"
    },
    {
      "arxiv_id": "2505.16146v1",
      "title": "Steering LVLMs via Sparse Autoencoder for Hallucination Mitigation",
      "title_zh": "翻译失败",
      "authors": [
        "Zhenglin Hua",
        "Jinghan He",
        "Zijun Yao",
        "Tianxu Han",
        "Haiyun Guo",
        "Yuheng Jia",
        "Junfeng Fang"
      ],
      "abstract": "Large vision-language models (LVLMs) have achieved remarkable performance on\nmultimodal tasks such as visual question answering (VQA) and image captioning.\nHowever, they still suffer from hallucinations, generating text inconsistent\nwith visual input, posing significant risks in real-world applications.\nExisting approaches to address this issue focus on incorporating external\nknowledge bases, alignment training, or decoding strategies, all of which\nrequire substantial computational cost and time. Recent works try to explore\nmore efficient alternatives by adjusting LVLMs' internal representations.\nAlthough promising, these methods may cause hallucinations to be insufficiently\nsuppressed or lead to excessive interventions that negatively affect normal\nsemantics. In this work, we leverage sparse autoencoders (SAEs) to identify\nsemantic directions closely associated with either hallucinations or actuality,\nrealizing more precise and direct hallucination-related representations. Our\nanalysis demonstrates that interventions along the faithful direction we\nidentified can mitigate hallucinations, while those along the hallucinatory\ndirection can exacerbate them. Building on these insights, we propose Steering\nLVLMs via SAE Latent Directions (SSL), a training-free method based on\nSAE-derived latent directions to mitigate hallucinations in LVLMs. Extensive\nexperiments demonstrate that SSL significantly outperforms existing decoding\napproaches in mitigating hallucinations, while maintaining transferability\nacross different model architectures with negligible additional time overhead.",
      "tldr_zh": "该研究针对Large Vision-Language Models (LVLMs) 的幻觉问题（如生成与视觉输入不一致的文本），提出了一种基于Sparse Autoencoders (SAEs) 的无训练方法Steering LVLMs via SAE Latent Directions (SSL)。该方法通过SAEs识别与幻觉或真实性相关的语义方向，并进行精确干预，以缓解幻觉同时避免过度干扰正常语义。实验结果显示，SSL在缓解幻觉方面显著优于现有解码策略，并在不同模型架构间保持良好的可转移性，同时额外时间开销微不足道。",
      "categories": [
        "cs.CV",
        "cs.AI",
        "cs.CL",
        "cs.LG"
      ],
      "primary_category": "cs.CV",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2505.16146v1",
      "published_date": "2025-05-22 02:45:45 UTC",
      "updated_date": "2025-05-22 02:45:45 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-25T03:44:33.030122"
    },
    {
      "arxiv_id": "2505.16136v1",
      "title": "Interpretable Machine Learning for Macro Alpha: A News Sentiment Case Study",
      "title_zh": "翻译失败",
      "authors": [
        "Yuke Zhang"
      ],
      "abstract": "This study introduces an interpretable machine learning (ML) framework to\nextract macroeconomic alpha from global news sentiment. We process the Global\nDatabase of Events, Language, and Tone (GDELT) Project's worldwide news feed\nusing FinBERT -- a Bidirectional Encoder Representations from Transformers\n(BERT) based model pretrained on finance-specific language -- to construct\ndaily sentiment indices incorporating mean tone, dispersion, and event impact.\nThese indices drive an XGBoost classifier, benchmarked against logistic\nregression, to predict next-day returns for EUR/USD, USD/JPY, and 10-year U.S.\nTreasury futures (ZN). Rigorous out-of-sample (OOS) backtesting (5-fold\nexpanding-window cross-validation, OOS period: c. 2017-April 2025) demonstrates\nexceptional, cost-adjusted performance for the XGBoost strategy: Sharpe ratios\nachieve 5.87 (EUR/USD), 4.65 (USD/JPY), and 4.65 (Treasuries), with respective\ncompound annual growth rates (CAGRs) exceeding 50% in Foreign Exchange (FX) and\n22% in bonds. Shapley Additive Explanations (SHAP) affirm that sentiment\ndispersion and article impact are key predictive features. Our findings\nestablish that integrating domain-specific Natural Language Processing (NLP)\nwith interpretable ML offers a potent and explainable source of macro alpha.",
      "tldr_zh": "本研究提出一个可解释机器学习框架，利用 FinBERT（基于 BERT 的金融特定语言模型）处理 GDELT 全球新闻数据，构建每日情绪指数（包括平均语气、分散度和事件影响），并驱动 XGBoost 分类器预测 EUR/USD、USD/JPY 和 10 年期美国国债期货的次日回报。相比逻辑回归基准，XGBoost 策略在样本外回测（2017-2025 年）中表现出色，Sharpe 比率分别达 5.87（EUR/USD）、4.65（USD/JPY）和 4.65（国债），年复合增长率（CAGR）在外汇超过 50%、债券超过 22%。通过 SHAP 解释，情绪分散度和文章影响被确认为核心预测特征，该框架证明了将领域特定 NLP 与可解释机器学习相结合，能提供强大且可解释的宏观 alpha 来源。",
      "categories": [
        "q-fin.CP",
        "cs.AI",
        "cs.LG",
        "q-fin.TR"
      ],
      "primary_category": "q-fin.CP",
      "comment": "18 pages (including references), 1 figure, 1 table. Code available at\n  \\url{https://github.com/yukepenn/macro-news-sentiment-trading}. Keywords:\n  Macro Sentiment, News Sentiment, Algorithmic Trading, GDELT, FinBERT, NLP,\n  Alternative Data, Foreign Exchange, Treasury Futures, Quantitative Finance,\n  Machine Learning, SHAP, Interpretability",
      "pdf_url": "http://arxiv.org/pdf/2505.16136v1",
      "published_date": "2025-05-22 02:24:45 UTC",
      "updated_date": "2025-05-22 02:24:45 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-25T03:44:46.274741"
    },
    {
      "arxiv_id": "2505.16135v1",
      "title": "Sudoku-Bench: Evaluating creative reasoning with Sudoku variants",
      "title_zh": "翻译失败",
      "authors": [
        "Jeffrey Seely",
        "Yuki Imajuku",
        "Tianyu Zhao",
        "Edoardo Cetin",
        "Llion Jones"
      ],
      "abstract": "Existing reasoning benchmarks for large language models (LLMs) frequently\nfail to capture authentic creativity, often rewarding memorization of\npreviously observed patterns. We address this shortcoming with Sudoku-Bench, a\ncurated benchmark of challenging and unconventional Sudoku variants\nspecifically selected to evaluate creative, multi-step logical reasoning.\nSudoku variants form an unusually effective domain for reasoning research: each\npuzzle introduces unique or subtly interacting constraints, making memorization\ninfeasible and requiring solvers to identify novel logical breakthroughs\n(``break-ins''). Despite their diversity, Sudoku variants maintain a common and\ncompact structure, enabling clear and consistent evaluation. Sudoku-Bench\nincludes a carefully chosen puzzle set, a standardized text-based puzzle\nrepresentation, and flexible tools compatible with thousands of publicly\navailable puzzles -- making it easy to extend into a general research\nenvironment. Baseline experiments show that state-of-the-art LLMs solve fewer\nthan 15\\% of puzzles unaided, highlighting significant opportunities to advance\nlong-horizon, strategic reasoning capabilities.",
      "tldr_zh": "本论文提出Sudoku-Bench，一种针对数独变体的基准，用于评估大型语言模型(LLMs)的创意多步逻辑推理能力，以弥补现有基准偏向记忆而非真实创意的不足。Sudoku-Bench 包括精心选择的谜题集、标准化文本表示和灵活工具，这些谜题引入独特约束，迫使模型进行新颖的逻辑突破（break-ins），而非依赖记忆。实验结果显示，当前最先进的LLMs在无辅助情况下仅解决不到15%的谜题，突显了提升长程战略推理能力的巨大潜力。",
      "categories": [
        "cs.AI",
        "cs.CL",
        "cs.LG"
      ],
      "primary_category": "cs.AI",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2505.16135v1",
      "published_date": "2025-05-22 02:24:35 UTC",
      "updated_date": "2025-05-22 02:24:35 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-25T03:44:57.934186"
    },
    {
      "arxiv_id": "2505.16130v1",
      "title": "Scalable Graph Generative Modeling via Substructure Sequences",
      "title_zh": "翻译失败",
      "authors": [
        "Zehong Wang",
        "Zheyuan Zhang",
        "Tianyi Ma",
        "Chuxu Zhang",
        "Yanfang Ye"
      ],
      "abstract": "Graph neural networks (GNNs) has been predominantly driven by\nmessage-passing, where node representations are iteratively updated via local\nneighborhood aggregation. Despite their success, message-passing suffers from\nfundamental limitations -- including constrained expressiveness,\nover-smoothing, over-squashing, and limited capacity to model long-range\ndependencies. These issues hinder scalability: increasing data size or model\nsize often fails to yield improved performance, limiting the viability of GNNs\nas backbones for graph foundation models. In this work, we explore pathways\nbeyond message-passing and introduce Generative Graph Pattern Machine\n(G$^2$PM), a generative Transformer pre-training framework for graphs. G$^2$PM\nrepresents graph instances (nodes, edges, or entire graphs) as sequences of\nsubstructures, and employs generative pre-training over the sequences to learn\ngeneralizable, transferable representations. Empirically, G$^2$PM demonstrates\nstrong scalability: on the ogbn-arxiv benchmark, it continues to improve with\nmodel sizes up to 60M parameters, outperforming prior generative approaches\nthat plateau at significantly smaller scales (e.g., 3M). In addition, we\nsystematically analyze the model design space, highlighting key architectural\nchoices that contribute to its scalability and generalization. Across diverse\ntasks -- including node classification, graph classification, and transfer\nlearning -- G$^2$PM consistently outperforms strong baselines, establishing a\ncompelling foundation for scalable graph learning. The code and dataset are\navailable at https://github.com/Zehong-Wang/G2PM.",
      "tldr_zh": "该论文探讨了图神经网络 (GNNs) 中基于消息传递的局限性，如表达能力受限、过度平滑和难以处理长距离依赖，从而影响其可扩展性。作者提出 Generative Graph Pattern Machine (G²PM)，一个基于 Transformer 的生成预训练框架，将图实例表示为子结构序列，并通过序列生成学习来获得可泛化、可转移的表示。实验结果显示，G²PM 在 ogbn-arxiv 基准上，随着模型规模增至 60M 参数，性能持续提升，并优于其他在较小规模（如 3M）就停滞的生成方法；在节点分类、图分类和转移学习等任务中，G²PM 显著超越强基线，为可扩展的图学习奠定基础。",
      "categories": [
        "cs.LG",
        "cs.AI",
        "cs.SI"
      ],
      "primary_category": "cs.LG",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2505.16130v1",
      "published_date": "2025-05-22 02:16:34 UTC",
      "updated_date": "2025-05-22 02:16:34 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-25T03:45:10.027594"
    },
    {
      "arxiv_id": "2505.16120v1",
      "title": "LLM-Powered AI Agent Systems and Their Applications in Industry",
      "title_zh": "翻译失败",
      "authors": [
        "Guannan Liang",
        "Qianqian Tong"
      ],
      "abstract": "The emergence of Large Language Models (LLMs) has reshaped agent systems.\nUnlike traditional rule-based agents with limited task scope, LLM-powered\nagents offer greater flexibility, cross-domain reasoning, and natural language\ninteraction. Moreover, with the integration of multi-modal LLMs, current agent\nsystems are highly capable of processing diverse data modalities, including\ntext, images, audio, and structured tabular data, enabling richer and more\nadaptive real-world behavior. This paper comprehensively examines the evolution\nof agent systems from the pre-LLM era to current LLM-powered architectures. We\ncategorize agent systems into software-based, physical, and adaptive hybrid\nsystems, highlighting applications across customer service, software\ndevelopment, manufacturing automation, personalized education, financial\ntrading, and healthcare. We further discuss the primary challenges posed by\nLLM-powered agents, including high inference latency, output uncertainty, lack\nof evaluation metrics, and security vulnerabilities, and propose potential\nsolutions to mitigate these concerns.",
      "tldr_zh": "本论文探讨了大型语言模型(LLM)驱动的AI代理系统的发展及其在工业中的应用，强调了LLM代理相较于传统规则-based代理的灵活性、跨域推理能力以及自然语言交互。论文将代理系统分类为软件-based、物理和混合类型，并展示了它们在客户服务、软件开发、制造自动化、个性化教育、金融交易和医疗保健等领域的实际应用。LLM代理通过整合多模态数据处理（如文本、图像、音频和表格），实现了更丰富的适应性行为。论文还分析了主要挑战，包括高推理延迟、输出不确定性、缺乏评估指标和安全漏洞，并提出了潜在解决方案以缓解这些问题。",
      "categories": [
        "cs.AI"
      ],
      "primary_category": "cs.AI",
      "comment": "This is the author's accepted version of the paper accepted to appear\n  at IEEE AIIoT 2025. The final version will be available via IEEE Xplore.\n  \\c{opyright}2025 IEEE. Personal use of this material is permitted",
      "pdf_url": "http://arxiv.org/pdf/2505.16120v1",
      "published_date": "2025-05-22 01:52:15 UTC",
      "updated_date": "2025-05-22 01:52:15 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-25T03:45:22.470140"
    },
    {
      "arxiv_id": "2505.16114v1",
      "title": "Logic-of-Thought: Empowering Large Language Models with Logic Programs for Solving Puzzles in Natural Language",
      "title_zh": "翻译失败",
      "authors": [
        "Naiqi Li",
        "Peiyuan Liu",
        "Zheng Liu",
        "Tao Dai",
        "Yong Jiang",
        "Shu-Tao Xia"
      ],
      "abstract": "Solving puzzles in natural language poses a long-standing challenge in AI.\nWhile large language models (LLMs) have recently shown impressive capabilities\nin a variety of tasks, they continue to struggle with complex puzzles that\ndemand precise reasoning and exhaustive search. In this paper, we propose\nLogic-of-Thought (Logot), a novel framework that bridges LLMs with logic\nprogramming to address this problem. Our method leverages LLMs to translate\npuzzle rules and states into answer set programs (ASPs), the solution of which\nare then accurately and efficiently inferred by an ASP interpreter. This hybrid\napproach combines the natural language understanding of LLMs with the precise\nreasoning capabilities of logic programs. We evaluate our method on various\ngrid puzzles and dynamic puzzles involving actions, demonstrating near-perfect\naccuracy across all tasks. Our code and data are available at:\nhttps://github.com/naiqili/Logic-of-Thought.",
      "tldr_zh": "该研究提出Logic-of-Thought (Logot)框架，将Large Language Models (LLMs)与逻辑编程相结合，旨在解决自然语言谜题中需要精确推理和穷举搜索的挑战。方法包括使用LLMs将谜题规则和状态翻译成answer set programs (ASPs)，然后由ASP解释器进行高效求解，从而融合了LLMs的自然语言理解能力和逻辑程序的精确推理。实验结果显示，该框架在各种网格谜题和动态谜题上实现了近乎完美的准确率，为复杂AI推理任务提供了新途径。",
      "categories": [
        "cs.AI"
      ],
      "primary_category": "cs.AI",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2505.16114v1",
      "published_date": "2025-05-22 01:37:40 UTC",
      "updated_date": "2025-05-22 01:37:40 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-25T03:45:33.217124"
    },
    {
      "arxiv_id": "2505.16103v1",
      "title": "Towards Trustworthy Keylogger detection: A Comprehensive Analysis of Ensemble Techniques and Feature Selections through Explainable AI",
      "title_zh": "翻译失败",
      "authors": [
        "Monirul Islam Mahmud"
      ],
      "abstract": "Keylogger detection involves monitoring for unusual system behaviors such as\ndelays between typing and character display, analyzing network traffic patterns\nfor data exfiltration. In this study, we provide a comprehensive analysis for\nkeylogger detection with traditional machine learning models - SVC, Random\nForest, Decision Tree, XGBoost, AdaBoost, Logistic Regression and Naive Bayes\nand advanced ensemble methods including Stacking, Blending and Voting.\nMoreover, feature selection approaches such as Information gain, Lasso L1 and\nFisher Score are thoroughly assessed to improve predictive performance and\nlower computational complexity. The Keylogger Detection dataset from publicly\navailable Kaggle website is used in this project. In addition to accuracy-based\nclassification, this study implements the approach for model interpretation\nusing Explainable AI (XAI) techniques namely SHAP (Global) and LIME (Local) to\ndeliver finer explanations for how much each feature contributes in assisting\nor hindering the detection process. To evaluate the models result, we have used\nAUC score, sensitivity, Specificity, Accuracy and F1 score. The best\nperformance was achieved by AdaBoost with 99.76% accuracy, F1 score of 0.99,\n100% precision, 98.6% recall, 1.0 specificity and 0.99 of AUC that is\nnear-perfect classification with Fisher Score.",
      "tldr_zh": "本研究对 keylogger 检测进行了全面分析，评估了传统机器学习模型（如 SVC、Random Forest、XGBoost、AdaBoost）和高级集成方法（如 Stacking、Blending、Voting），以监测异常系统行为和网络流量。特征选择技术（Information gain、Lasso L1、Fisher Score）被用于提升预测性能并降低计算复杂度，同时采用 Explainable AI 工具（SHAP 和 LIME）提供特征贡献解释。实验在 Kaggle 数据集上显示，AdaBoost 模型结合 Fisher Score 取得了最佳结果，准确率达 99.76%、F1 分数 0.99 和 AUC 0.99，显著提高了检测的可信度和解释性。",
      "categories": [
        "cs.LG",
        "cs.AI"
      ],
      "primary_category": "cs.LG",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2505.16103v1",
      "published_date": "2025-05-22 01:04:13 UTC",
      "updated_date": "2025-05-22 01:04:13 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-25T03:45:46.565224"
    },
    {
      "arxiv_id": "2505.16100v1",
      "title": "BioDSA-1K: Benchmarking Data Science Agents for Biomedical Research",
      "title_zh": "BioDSA-1K：生物医学研究数据科学代理的基准测试",
      "authors": [
        "Zifeng Wang",
        "Benjamin Danek",
        "Jimeng Sun"
      ],
      "abstract": "Validating scientific hypotheses is a central challenge in biomedical\nresearch, and remains difficult for artificial intelligence (AI) agents due to\nthe complexity of real-world data analysis and evidence interpretation. In this\nwork, we present BioDSA-1K, a benchmark designed to evaluate AI agents on\nrealistic, data-driven biomedical hypothesis validation tasks. BioDSA-1K\nconsists of 1,029 hypothesis-centric tasks paired with 1,177 analysis plans,\ncurated from over 300 published biomedical studies to reflect the structure and\nreasoning found in authentic research workflows. Each task includes a\nstructured hypothesis derived from the original study's conclusions, expressed\nin the affirmative to reflect the language of scientific reporting, and one or\nmore pieces of supporting evidence grounded in empirical data tables. While\nthese hypotheses mirror published claims, they remain testable using standard\nstatistical or machine learning methods. The benchmark enables evaluation along\nfour axes: (1) hypothesis decision accuracy, (2) alignment between evidence and\nconclusion, (3) correctness of the reasoning process, and (4) executability of\nthe AI-generated analysis code. Importantly, BioDSA-1K includes non-verifiable\nhypotheses: cases where the available data are insufficient to support or\nrefute a claim, reflecting a common yet underexplored scenario in real-world\nscience. We propose BioDSA-1K as a foundation for building and evaluating\ngeneralizable, trustworthy AI agents for biomedical discovery.",
      "tldr_zh": "本研究引入了 BioDSA-1K 基准，用于评估 AI agents 在生物医学假设验证任务中的性能，旨在解决真实数据分析和证据解释的复杂挑战。该基准包含 1,029 个假设中心任务和 1,177 个分析计划，从超过 300 篇已发表的生物医学研究中提炼而成，每个任务包括结构化的假设、支持证据以及基于经验数据表的验证。评估涵盖四个维度：假设决策准确性、证据与结论的 alignment、推理过程的正确性，以及 AI 生成分析代码的 executability。此外，BioDSA-1K 创新性地包含不可验证的假设场景，反映现实科学中的数据不足问题，为构建可泛化、可信赖的 AI agents 提供可靠基础。",
      "categories": [
        "cs.AI",
        "cs.CL"
      ],
      "primary_category": "cs.AI",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2505.16100v1",
      "published_date": "2025-05-22 01:02:21 UTC",
      "updated_date": "2025-05-22 01:02:21 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-25T03:45:58.079126"
    },
    {
      "arxiv_id": "2505.16097v1",
      "title": "TrialPanorama: Database and Benchmark for Systematic Review and Design of Clinical Trials",
      "title_zh": "翻译失败",
      "authors": [
        "Zifeng Wang",
        "Qiao Jin",
        "Jiacheng Lin",
        "Junyi Gao",
        "Jathurshan Pradeepkumar",
        "Pengcheng Jiang",
        "Benjamin Danek",
        "Zhiyong Lu",
        "Jimeng Sun"
      ],
      "abstract": "Developing artificial intelligence (AI) for vertical domains requires a solid\ndata foundation for both training and evaluation. In this work, we introduce\nTrialPanorama, a large-scale, structured database comprising 1,657,476 clinical\ntrial records aggregated from 15 global sources. The database captures key\naspects of trial design and execution, including trial setups, interventions,\nconditions, biomarkers, and outcomes, and links them to standard biomedical\nontologies such as DrugBank and MedDRA. This structured and ontology-grounded\ndesign enables TrialPanorama to serve as a unified, extensible resource for a\nwide range of clinical trial tasks, including trial planning, design, and\nsummarization. To demonstrate its utility, we derive a suite of benchmark tasks\ndirectly from the TrialPanorama database. The benchmark spans eight tasks\nacross two categories: three for systematic review (study search, study\nscreening, and evidence summarization) and five for trial design (arm design,\neligibility criteria, endpoint selection, sample size estimation, and trial\ncompletion assessment). The experiments using five state-of-the-art large\nlanguage models (LLMs) show that while general-purpose LLMs exhibit some\nzero-shot capability, their performance is still inadequate for high-stakes\nclinical trial workflows. We release TrialPanorama database and the benchmark\nto facilitate further research on AI for clinical trials.",
      "tldr_zh": "本文介绍了 TrialPanorama，这是一个大规模结构化数据库，包含 1,657,476 条临床试验记录，从 15 个全球来源聚合，并链接到 DrugBank 和 MedDRA 等标准生物医学本体，用于支持 AI 在临床试验中的训练和评估。该数据库捕捉了试验设计的关键方面，如干预、条件和结果，并作为统一的资源促进试验规划、设计和总结。论文导出了八个基准任务，包括系统性审查（如研究搜索和证据总结）和试验设计（如臂设计和样本大小估计），并通过五种最先进的 LLMs 进行实验，结果显示这些模型的零样本能力不足以应对高风险临床工作流程。最终，TrialPanorama 数据库和基准被公开发布，以推动 AI 在临床试验领域的进一步研究。",
      "categories": [
        "cs.AI"
      ],
      "primary_category": "cs.AI",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2505.16097v1",
      "published_date": "2025-05-22 00:58:43 UTC",
      "updated_date": "2025-05-22 00:58:43 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-25T03:46:10.673634"
    },
    {
      "arxiv_id": "2505.16090v1",
      "title": "Can AI Read Between The Lines? Benchmarking LLMs On Financial Nuance",
      "title_zh": "翻译失败",
      "authors": [
        "Dominick Kubica",
        "Dylan T. Gordon",
        "Nanami Emura",
        "Derleen Saini",
        "Charlie Goldenberg"
      ],
      "abstract": "As of 2025, Generative Artificial Intelligence (GenAI) has become a central\ntool for productivity across industries. Beyond text generation, GenAI now\nplays a critical role in coding, data analysis, and research workflows. As\nlarge language models (LLMs) continue to evolve, it is essential to assess the\nreliability and accuracy of their outputs, especially in specialized,\nhigh-stakes domains like finance. Most modern LLMs transform text into\nnumerical vectors, which are used in operations such as cosine similarity\nsearches to generate responses. However, this abstraction process can lead to\nmisinterpretation of emotional tone, particularly in nuanced financial\ncontexts. While LLMs generally excel at identifying sentiment in everyday\nlanguage, these models often struggle with the nuanced, strategically ambiguous\nlanguage found in earnings call transcripts. Financial disclosures frequently\nembed sentiment in hedged statements, forward-looking language, and\nindustry-specific jargon, making it difficult even for human analysts to\ninterpret consistently, let alone AI models. This paper presents findings from\nthe Santa Clara Microsoft Practicum Project, led by Professor Charlie\nGoldenberg, which benchmarks the performance of Microsoft's Copilot, OpenAI's\nChatGPT, Google's Gemini, and traditional machine learning models for sentiment\nanalysis of financial text. Using Microsoft earnings call transcripts, the\nanalysis assesses how well LLM-derived sentiment correlates with market\nsentiment and stock movements and evaluates the accuracy of model outputs.\nPrompt engineering techniques are also examined to improve sentiment analysis\nresults. Visualizations of sentiment consistency are developed to evaluate\nalignment between tone and stock performance, with sentiment trends analyzed\nacross Microsoft's lines of business to determine which segments exert the\ngreatest influence.",
      "tldr_zh": "本研究评估了大型语言模型（LLMs）在处理金融文本细微情感方面的表现，强调了这些模型在解读情绪模糊语言（如收益电话会议中的套话和行业术语）时的局限性。研究团队使用微软 Copilot、OpenAI 的 ChatGPT、Google 的 Gemini 以及传统机器学习模型，对微软财报电话会议文本进行情感分析，考察了模型输出与市场情感及股票表现的相关性，并通过提示工程技巧优化分析结果。实验结果显示，LLMs 在情感一致性可视化上存在挑战，但适当的提示工程可提升准确性，为金融领域的高可靠性 AI 应用提供重要基准。",
      "categories": [
        "cs.AI",
        "cs.CL",
        "I.2.6; I.2.7"
      ],
      "primary_category": "cs.AI",
      "comment": "6 pages, 4 figures. Research conducted as part of a\n  Microsoft-sponsored Capstone Project at Santa Clara University",
      "pdf_url": "http://arxiv.org/pdf/2505.16090v1",
      "published_date": "2025-05-22 00:09:11 UTC",
      "updated_date": "2025-05-22 00:09:11 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-25T03:46:20.988716"
    },
    {
      "arxiv_id": "2505.16088v1",
      "title": "Date Fragments: A Hidden Bottleneck of Tokenization for Temporal Reasoning",
      "title_zh": "日期碎片：标记化中时间推理的隐藏瓶颈",
      "authors": [
        "Gagan Bhatia",
        "Maxime Peyrard",
        "Wei Zhao"
      ],
      "abstract": "Modern BPE tokenizers often split calendar dates into meaningless fragments,\ne.g., 20250312 $\\rightarrow$ 202, 503, 12, inflating token counts and obscuring\nthe inherent structure needed for robust temporal reasoning. In this work, we\n(1) introduce a simple yet interpretable metric, termed date fragmentation\nratio, that measures how faithfully a tokenizer preserves multi-digit date\ncomponents; (2) release DateAugBench, a suite of 6500 examples spanning three\ntemporal reasoning tasks: context-based date resolution, format-invariance\npuzzles, and date arithmetic across historical, contemporary, and future\nregimes; and (3) through layer-wise probing and causal attention-hop analyses,\nuncover an emergent date-abstraction mechanism whereby large language models\nstitch together the fragments of month, day, and year components for temporal\nreasoning. Our experiments show that excessive fragmentation correlates with\naccuracy drops of up to 10 points on uncommon dates like historical and\nfuturistic dates. Further, we find that the larger the model, the faster the\nemergent date abstraction that heals date fragments is accomplished. Lastly, we\nobserve a reasoning path that LLMs follow to assemble date fragments, typically\ndiffering from human interpretation (year $\\rightarrow$ month $\\rightarrow$\nday).",
      "tldr_zh": "本研究揭示了现代 BPE 分词器在处理日历日期时存在的隐藏问题，即将日期分割成无意义碎片（如 20250312 → 202, 503, 12），这导致 token 数量膨胀并削弱时间推理的鲁棒性。论文的主要贡献包括：引入 date fragmentation ratio 指标来评估分词器对多位数字日期的保留程度、发布 DateAugBench 基准套件（包含 6500 个示例，覆盖基于上下文的日期解析、格式不变性谜题和日期算术任务），以及通过层级探测和因果注意力跳跃分析发现大型语言模型（LLMs）中出现的日期抽象机制，用于拼接月份、日和年碎片。实验结果显示，过度碎片化会导致不常见日期（如历史或未来日期）的准确率下降高达 10 点，而更大模型能更快实现这种抽象机制，且 LLMs 的推理路径（年 → 月 → 日）通常与人类解读不同。",
      "categories": [
        "cs.CL",
        "cs.AI"
      ],
      "primary_category": "cs.CL",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2505.16088v1",
      "published_date": "2025-05-22 00:06:29 UTC",
      "updated_date": "2025-05-22 00:06:29 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-25T03:46:33.834238"
    },
    {
      "arxiv_id": "2505.16086v1",
      "title": "Optimizing LLM-Based Multi-Agent System with Textual Feedback: A Case Study on Software Development",
      "title_zh": "使用文本反馈优化基于 LLM 的多智能体系统：一个软件开发案例研究",
      "authors": [
        "Ming Shen",
        "Raphael Shu",
        "Anurag Pratik",
        "James Gung",
        "Yubin Ge",
        "Monica Sunkara",
        "Yi Zhang"
      ],
      "abstract": "We have seen remarkable progress in large language models (LLMs) empowered\nmulti-agent systems solving complex tasks necessitating cooperation among\nexperts with diverse skills. However, optimizing LLM-based multi-agent systems\nremains challenging. In this work, we perform an empirical case study on group\noptimization of role-based multi-agent systems utilizing natural language\nfeedback for challenging software development tasks under various evaluation\ndimensions. We propose a two-step agent prompts optimization pipeline:\nidentifying underperforming agents with their failure explanations utilizing\ntextual feedback and then optimizing system prompts of identified agents\nutilizing failure explanations. We then study the impact of various\noptimization settings on system performance with two comparison groups: online\nagainst offline optimization and individual against group optimization. For\ngroup optimization, we study two prompting strategies: one-pass and multi-pass\nprompting optimizations. Overall, we demonstrate the effectiveness of our\noptimization method for role-based multi-agent systems tackling software\ndevelopment tasks evaluated on diverse evaluation dimensions, and we\ninvestigate the impact of diverse optimization settings on group behaviors of\nthe multi-agent systems to provide practical insights for future development.",
      "tldr_zh": "本文通过一个实证案例研究，探讨了使用文本反馈优化基于LLM的多智能体系统，以应对软件开发任务中的合作挑战。研究提出一个两步代理提示优化管道：首先利用文本反馈识别表现不佳的代理及其失败解释，然后基于这些解释优化代理的系统提示。实验比较了在线与离线、个体与群体优化设置的影响，并证明了该方法的有效性，为多智能体系统的未来发展提供了实用见解。",
      "categories": [
        "cs.AI",
        "cs.CL"
      ],
      "primary_category": "cs.AI",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2505.16086v1",
      "published_date": "2025-05-22 00:00:27 UTC",
      "updated_date": "2025-05-22 00:00:27 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-25T03:46:45.160502"
    }
  ],
  "raw_papers_fetched": true,
  "papers_count": 196,
  "processed_papers_count": 196,
  "failed_papers_count": 0,
  "summary_generated": true,
  "daily_data_saved": true,
  "last_update": "2025-05-25T03:47:10.946349"
}