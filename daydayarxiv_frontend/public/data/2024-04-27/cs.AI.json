{
  "date": "2024-04-27",
  "category": "cs.AI",
  "summary": "欢迎来到 UTC 时间 2024-04-27 的 arXiv 中文 TLDR 快报！\n\n今天 arXiv 更新了 51 篇论文，主要聚焦于人工智能（AI）模型的应用，尤其是大型语言模型（LLM）在医疗、生物、日志解析和联邦学习等领域，令人印象深刻的是 CRISPR-GPT 将 LLM 用于基因编辑自动化设计，而知名学者如 Russ Altman 和 Le Cong 的参与进一步提升了话题度；其他亮点包括 LLM 在医疗诊断和隐私保护方面的创新。\n\n以下是今日重点论文的简要解析，我将优先讨论重要、创新性强的论文（如 LLM 相关和医疗应用），并将相关主题归类讨论。篇幅有限，对较基础或理论性较弱的论文（如某些数学模型或通用数据集分析）将快速掠过。\n\n### LLM 在生物和医疗领域的应用\n- **CRISPR-GPT: An LLM Agent for Automated Design of Gene-Editing Experiments**（中文：CRISPR-GPT：用于自动化基因编辑实验设计的 LLM 代理；英文：CRISPR-GPT: An LLM Agent for Automated Design of Gene-Editing Experiments）  \n  这篇论文由 Russ Altman 和 Le Cong 等知名学者主导，提出 CRISPR-GPT 框架，利用 LLM 增强的领域知识和外部工具自动化 CRISPR 基因编辑过程，包括选择系统、设计 guide RNA 和验证实验。主要贡献是桥接初学者与基因工程技术，实证显示其在真实场景中的有效性，并讨论了伦理问题，显著提升了生物研究效率。\n\n- **MediFact at MEDIQA-CORR 2024: Why AI Needs a Human Touch**（中文：MediFact 在 MEDIQA-CORR 2024：为什么 AI 需要人文触达；英文：MediFact at MEDIQA-CORR 2024: Why AI Needs a Human Touch）  \n  作者 Nadia Saeed 强调 AI 在临床文本校正中的局限，提出结合提取式和抽象式问答方法的监督框架，融入领域专家知识以提高准确性。主要发现是人类中心策略在医疗 NLP 中的重要性，帮助减少 LLM 的错误。\n\n- **MediFact at MEDIQA-M3G 2024: Medical Question Answering in Dermatology with Multimodal Learning**（中文：MediFact 在 MEDIQA-M3G 2024：使用多模态学习的皮肤病医疗问答；英文：MediFact at MEDIQA-M3G 2024: Medical Question Answering in Dermatology with Multimodal Learning）  \n  同样由 Nadia Saeed 撰写，针对皮肤病的多语言问答，采用弱监督学习和 VGG16-CNN-SVM 模型融合视觉与文本信息。主要贡献是生成全面答案，提升临床决策支持，尽管依赖多模态融合。\n\n- **SERPENT-VLM: Self-Refining Radiology Report Generation Using Vision Language Models**（中文：SERPENT-VLM：使用视觉语言模型的自精炼放射学报告生成；英文：SERPENT-VLM: Self-Refining Radiology Report Generation Using Vision Language Models）  \n  这篇论文提出自精炼机制，通过自监督损失优化 LLM 生成的放射学报告，减少幻觉问题。主要发现是结合图像表示与文本语境的框架在 IU X-ray 和 ROCO 数据集上实现 SOTA 性能。\n\n- **Advancing Healthcare Automation: Multi-Agent System for Medical Necessity Justification**（中文：推进医疗自动化：用于医疗必要性证明的多代理系统；英文：Advancing Healthcare Automation: Multi-Agent System for Medical Necessity Justification）  \n  作者使用多代理 LLM 系统自动化先期授权任务，分解为子任务并优化提示策略。主要贡献是 GPT-4 在预测准确率达 86.2%，提升医疗流程效率和可解释性。\n\n### LLM 在其他应用和安全领域的创新\n- **LLMParser: An Exploratory Study on Using Large Language Models for Log Parsing**（中文：LLMParser：使用大型语言模型进行日志解析的探索性研究；英文：LLMParser: An Exploratory Study on Using Large Language Models for Log Parsing）  \n  论文探索 LLM 在日志解析中的潜力，提出基于 Flan-T5 和 LLaMA 的 LLMParser 框架，实现了 96% 的解析准确率，优于传统方法。主要发现是小型 LLM 如 Flan-T5-base 在推理时间上更高效。\n\n- **Detection of Conspiracy Theories Beyond Keyword Bias in German-Language Telegram Using Large Language Models**（中文：使用大型语言模型检测德语 Telegram 中的阴谋论（超越关键词偏差）；英文：Detection of Conspiracy Theories Beyond Keyword Bias in German-Language Telegram Using Large Language Models）  \n  作者使用 BERT 和 GPT-4 进行无关键词偏置的阴谋论检测，F1 分数达 0.8。主要贡献是提示方法在零样本设置下的鲁棒性，适用于社交媒体监控。\n\n- **FedCRL: Personalized Federated Learning with Contrastive Shared Representations for Label Heterogeneity in Non-IID Data**（中文：FedCRL：针对非独立同分布数据中标签异质性的对比共享表示的个性化联邦学习；英文：FedCRL: Personalized Federated Learning with Contrastive Shared Representations for Label Heterogeneity in Non-IID Data）  \n  这篇论文提出 FedCRL 框架，使用对比学习处理联邦学习中的标签异质性，提高了模型准确性和公平性。主要发现是共享表示在处理数据稀缺时的有效性。\n\n- **Privacy-Preserving Aggregation for Decentralized Learning with Byzantine-Robustness**（中文：具有拜占庭鲁棒性的去中心化学习隐私保护聚合；英文：Privacy-Preserving Aggregation for Decentralized Learning with Byzantine-Robustness）  \n  作者引入 SecureDL 协议，通过安全多方计算检测恶意更新，抵抗 80% 拜占庭攻击。主要贡献是平衡隐私和鲁棒性，在多个数据集上保持高准确率。\n\n### 其他值得注意的论文\n- **CUE-Net: Violence Detection Video Analytics with Spatial Cropping, Enhanced UniformerV2 and Modified Efficient Additive Attention**（中文：CUE-Net：使用空间裁剪、增强 UniformerV2 和改进高效加性注意力的暴力检测视频分析；英文：CUE-Net: Violence Detection Video Analytics with Spatial Cropping, Enhanced UniformerV2 and Modified Efficient Additive Attention）  \n  快速提及：提出 CUE-Net 架构，提升视频监控中的暴力检测性能，在 RWF-2000 数据集上达到 SOTA。\n\n- **Deep Learning for Low-Latency, Quantum-Ready RF Sensing**（中文：用于低延迟量子就绪射频感知的深度学习；英文：Deep Learning for Low-Latency, Quantum-Ready RF Sensing）  \n  作者优化 RNN 和 CWT 架构，实现亚毫秒级推理，适用于量子射频传感器。主要发现是结合深度学习提升实时性。\n\n对于剩余论文，如一些纯理论或数据分析（如 DTization 或 GLIMS），它们虽有贡献（如 GLIMS 在医学图像分割中的效率提升），但影响力较小，我仅快速掠过不做深入讨论。总体而言，今天的更新突显了 LLM 在实际应用中的潜力，尤其在医疗和隐私保护领域，期待后续研究进一步优化这些模型的鲁棒性和伦理问题。明日见！",
  "papers": [
    {
      "arxiv_id": "2404.18021v1",
      "title": "CRISPR-GPT: An LLM Agent for Automated Design of Gene-Editing Experiments",
      "title_zh": "CRISPR-GPT：用于基因编辑实验自动化设计的LLM代理",
      "authors": [
        "Kaixuan Huang",
        "Yuanhao Qu",
        "Henry Cousins",
        "William A. Johnson",
        "Di Yin",
        "Mihir Shah",
        "Denny Zhou",
        "Russ Altman",
        "Mengdi Wang",
        "Le Cong"
      ],
      "abstract": "The introduction of genome engineering technology has transformed biomedical\nresearch, making it possible to make precise changes to genetic information.\nHowever, creating an efficient gene-editing system requires a deep\nunderstanding of CRISPR technology, and the complex experimental systems under\ninvestigation. While Large Language Models (LLMs) have shown promise in various\ntasks, they often lack specific knowledge and struggle to accurately solve\nbiological design problems. In this work, we introduce CRISPR-GPT, an LLM agent\naugmented with domain knowledge and external tools to automate and enhance the\ndesign process of CRISPR-based gene-editing experiments. CRISPR-GPT leverages\nthe reasoning ability of LLMs to facilitate the process of selecting CRISPR\nsystems, designing guide RNAs, recommending cellular delivery methods, drafting\nprotocols, and designing validation experiments to confirm editing outcomes. We\nshowcase the potential of CRISPR-GPT for assisting non-expert researchers with\ngene-editing experiments from scratch and validate the agent's effectiveness in\na real-world use case. Furthermore, we explore the ethical and regulatory\nconsiderations associated with automated gene-editing design, highlighting the\nneed for responsible and transparent use of these tools. Our work aims to\nbridge the gap between beginner biological researchers and CRISPR genome\nengineering techniques, and demonstrate the potential of LLM agents in\nfacilitating complex biological discovery tasks.",
      "tldr_zh": "本研究引入CRISPR-GPT，一种基于Large Language Models (LLMs)的智能代理，用于自动化CRISPR基因编辑实验的设计，旨在解决LLMs在生物领域知识不足的问题。CRISPR-GPT通过整合域知识和外部工具，利用LLMs的推理能力来辅助选择CRISPR系统、设计guide RNAs、推荐细胞递送方法、起草实验协议以及设计验证实验。实验验证显示，该代理能有效帮助非专家从零开始进行基因编辑，并探讨了相关的伦理和监管考虑，以促进CRISPR技术的负责任应用和生物发现任务的简化。",
      "categories": [
        "cs.AI",
        "cs.CL",
        "cs.HC",
        "q-bio.QM"
      ],
      "primary_category": "cs.AI",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2404.18021v1",
      "published_date": "2024-04-27 22:59:17 UTC",
      "updated_date": "2024-04-27 22:59:17 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-18T04:03:32.702865"
    },
    {
      "arxiv_id": "2404.18001v1",
      "title": "LLMParser: An Exploratory Study on Using Large Language Models for Log Parsing",
      "title_zh": "LLMParser：关于使用大型语言模型进行日志解析的探索性研究",
      "authors": [
        "Zeyang Ma",
        "An Ran Chen",
        "Dong Jae Kim",
        "Tse-Hsun Chen",
        "Shaowei Wang"
      ],
      "abstract": "Logs are important in modern software development with runtime information.\nLog parsing is the first step in many log-based analyses, that involve\nextracting structured information from unstructured log data. Traditional log\nparsers face challenges in accurately parsing logs due to the diversity of log\nformats, which directly impacts the performance of downstream log-analysis\ntasks. In this paper, we explore the potential of using Large Language Models\n(LLMs) for log parsing and propose LLMParser, an LLM-based log parser based on\ngenerative LLMs and few-shot tuning. We leverage four LLMs, Flan-T5-small,\nFlan-T5-base, LLaMA-7B, and ChatGLM-6B in LLMParsers. Our evaluation of 16\nopen-source systems shows that LLMParser achieves statistically significantly\nhigher parsing accuracy than state-of-the-art parsers (a 96% average parsing\naccuracy). We further conduct a comprehensive empirical analysis on the effect\nof training size, model size, and pre-training LLM on log parsing accuracy. We\nfind that smaller LLMs may be more effective than more complex LLMs; for\ninstance where Flan-T5-base achieves comparable results as LLaMA-7B with a\nshorter inference time. We also find that using LLMs pre-trained using logs\nfrom other systems does not always improve parsing accuracy. While using\npre-trained Flan-T5-base shows an improvement in accuracy, pre-trained LLaMA\nresults in a decrease (decrease by almost 55% in group accuracy). In short, our\nstudy provides empirical evidence for using LLMs for log parsing and highlights\nthe limitations and future research direction of LLM-based log parsers.",
      "tldr_zh": "本文探索使用 Large Language Models (LLMs) 进行日志解析的问题，提出 LLMParser，一种基于生成式 LLMs 和少样本微调的解析框架，使用 Flan-T5-small、Flan-T5-base、LLaMA-7B 和 ChatGLM-6B 等模型来处理日志格式多样性挑战。实验在 16 个开源系统中显示，LLMParser 的平均解析准确率达到 96%，显著高于现有最佳解析器。研究进一步分析了训练数据大小、模型大小和预训练 LLMs 对准确率的影响，发现较小模型如 Flan-T5-base 可能比复杂模型如 LLaMA-7B 更高效，而使用其他系统的日志预训练并不总是提升性能（如 LLaMA 的准确率下降近 55%）。总之，该研究提供了 LLMs 在日志解析中的实证证据，并指出了其局限性及未来研究方向。",
      "categories": [
        "cs.SE",
        "cs.AI"
      ],
      "primary_category": "cs.SE",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2404.18001v1",
      "published_date": "2024-04-27 20:34:29 UTC",
      "updated_date": "2024-04-27 20:34:29 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-18T04:03:46.392757"
    },
    {
      "arxiv_id": "2404.17999v1",
      "title": "MediFact at MEDIQA-CORR 2024: Why AI Needs a Human Touch",
      "title_zh": "翻译失败",
      "authors": [
        "Nadia Saeed"
      ],
      "abstract": "Accurate representation of medical information is crucial for patient safety,\nyet artificial intelligence (AI) systems, such as Large Language Models (LLMs),\nencounter challenges in error-free clinical text interpretation. This paper\npresents a novel approach submitted to the MEDIQA-CORR 2024 shared task (Ben\nAbacha et al., 2024a), focusing on the automatic correction of single-word\nerrors in clinical notes. Unlike LLMs that rely on extensive generic data, our\nmethod emphasizes extracting contextually relevant information from available\nclinical text data. Leveraging an ensemble of extractive and abstractive\nquestion-answering approaches, we construct a supervised learning framework\nwith domain-specific feature engineering. Our methodology incorporates domain\nexpertise to enhance error correction accuracy. By integrating domain expertise\nand prioritizing meaningful information extraction, our approach underscores\nthe significance of a human-centric strategy in adapting AI for healthcare.",
      "tldr_zh": "这篇论文探讨了AI在临床文本解释中的错误挑战，特别是Large Language Models (LLMs)在医疗信息处理中的局限性，并针对MEDIQA-CORR 2024共享任务提出了一种新方法，用于自动修正临床笔记中的单字错误。与依赖泛化数据的LLMs不同，该方法通过提取式和抽象式question-answering的集成，构建了一个监督learning框架，并融入domain-specific feature engineering和领域专家知识，以提升准确性。最终，研究强调了在医疗AI中整合人类元素的重要性，以实现更可靠的错误修正和患者安全保障。",
      "categories": [
        "cs.CL",
        "cs.AI",
        "cs.LG"
      ],
      "primary_category": "cs.CL",
      "comment": "7 pages, 4 figures, Clinical NLP 2024 Workshop",
      "pdf_url": "http://arxiv.org/pdf/2404.17999v1",
      "published_date": "2024-04-27 20:28:38 UTC",
      "updated_date": "2024-04-27 20:28:38 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-18T04:03:57.322939"
    },
    {
      "arxiv_id": "2404.18952v1",
      "title": "CUE-Net: Violence Detection Video Analytics with Spatial Cropping, Enhanced UniformerV2 and Modified Efficient Additive Attention",
      "title_zh": "翻译失败",
      "authors": [
        "Damith Chamalke Senadeera",
        "Xiaoyun Yang",
        "Dimitrios Kollias",
        "Gregory Slabaugh"
      ],
      "abstract": "In this paper we introduce CUE-Net, a novel architecture designed for\nautomated violence detection in video surveillance. As surveillance systems\nbecome more prevalent due to technological advances and decreasing costs, the\nchallenge of efficiently monitoring vast amounts of video data has intensified.\nCUE-Net addresses this challenge by combining spatial Cropping with an enhanced\nversion of the UniformerV2 architecture, integrating convolutional and\nself-attention mechanisms alongside a novel Modified Efficient Additive\nAttention mechanism (which reduces the quadratic time complexity of\nself-attention) to effectively and efficiently identify violent activities.\nThis approach aims to overcome traditional challenges such as capturing distant\nor partially obscured subjects within video frames. By focusing on both local\nand global spatiotemporal features, CUE-Net achieves state-of-the-art\nperformance on the RWF-2000 and RLVS datasets, surpassing existing methods.",
      "tldr_zh": "本研究提出CUE-Net，一种新型架构，用于视频监控中的自动暴力检测，旨在高效处理海量视频数据并解决捕捉远距离或部分遮挡主体的传统挑战。CUE-Net结合spatial Cropping、enhanced UniformerV2（整合卷积和自注意力机制）以及Modified Efficient Additive Attention机制（减少自注意力二次时间复杂度），从而同时关注局部和全局时空特征。在RWF-2000和RLVS数据集上，CUE-Net实现了state-of-the-art性能，超越现有方法。",
      "categories": [
        "cs.CV",
        "cs.AI",
        "cs.LG"
      ],
      "primary_category": "cs.CV",
      "comment": "To be published in the proceedings of 2024 IEEE/CVF Conference on\n  Computer Vision and Pattern Recognition Workshops (CVPRW)",
      "pdf_url": "http://arxiv.org/pdf/2404.18952v1",
      "published_date": "2024-04-27 20:09:40 UTC",
      "updated_date": "2024-04-27 20:09:40 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-18T04:04:07.308516"
    },
    {
      "arxiv_id": "2405.01583v1",
      "title": "MediFact at MEDIQA-M3G 2024: Medical Question Answering in Dermatology with Multimodal Learning",
      "title_zh": "翻译失败",
      "authors": [
        "Nadia Saeed"
      ],
      "abstract": "The MEDIQA-M3G 2024 challenge necessitates novel solutions for Multilingual &\nMultimodal Medical Answer Generation in dermatology (wai Yim et al., 2024a).\nThis paper addresses the limitations of traditional methods by proposing a\nweakly supervised learning approach for open-ended medical question-answering\n(QA). Our system leverages readily available MEDIQA-M3G images via a\nVGG16-CNN-SVM model, enabling multilingual (English, Chinese, Spanish) learning\nof informative skin condition representations. Using pre-trained QA models, we\nfurther bridge the gap between visual and textual information through\nmultimodal fusion. This approach tackles complex, open-ended questions even\nwithout predefined answer choices. We empower the generation of comprehensive\nanswers by feeding the ViT-CLIP model with multiple responses alongside images.\nThis work advances medical QA research, paving the way for clinical decision\nsupport systems and ultimately improving healthcare delivery.",
      "tldr_zh": "这篇论文针对MEDIQA-M3G 2024挑战，提出了一种弱监督学习方法，用于多语言（English, Chinese, Spanish）和多模态的皮肤病医疗问答（QA）。系统利用VGG16-CNN-SVM模型处理MEDIQA-M3G图像，学习皮肤病信息的表示，并通过预训练QA模型和multimodal fusion桥接视觉与文本信息，以应对复杂开放式问题。进一步，作者采用ViT-CLIP模型结合多重响应和图像生成全面答案，即使没有预定义选项也能有效工作。该方法推动医疗QA研究，为临床决策支持系统铺平道路，并提升医疗服务质量。",
      "categories": [
        "cs.CL",
        "cs.AI",
        "cs.CV",
        "cs.LG"
      ],
      "primary_category": "cs.CL",
      "comment": "7 pages, 3 figures, Clinical NLP 2024 workshop proceedings in Shared\n  Task",
      "pdf_url": "http://arxiv.org/pdf/2405.01583v1",
      "published_date": "2024-04-27 20:03:47 UTC",
      "updated_date": "2024-04-27 20:03:47 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-18T04:04:20.750546"
    },
    {
      "arxiv_id": "2404.17985v1",
      "title": "Detection of Conspiracy Theories Beyond Keyword Bias in German-Language Telegram Using Large Language Models",
      "title_zh": "翻译失败",
      "authors": [
        "Milena Pustet",
        "Elisabeth Steffen",
        "Helena Mihaljević"
      ],
      "abstract": "The automated detection of conspiracy theories online typically relies on\nsupervised learning. However, creating respective training data requires\nexpertise, time and mental resilience, given the often harmful content.\nMoreover, available datasets are predominantly in English and often\nkeyword-based, introducing a token-level bias into the models. Our work\naddresses the task of detecting conspiracy theories in German Telegram\nmessages. We compare the performance of supervised fine-tuning approaches using\nBERT-like models with prompt-based approaches using Llama2, GPT-3.5, and GPT-4\nwhich require little or no additional training data. We use a dataset of\n$\\sim\\!\\! 4,000$ messages collected during the COVID-19 pandemic, without the\nuse of keyword filters.\n  Our findings demonstrate that both approaches can be leveraged effectively:\nFor supervised fine-tuning, we report an F1 score of $\\sim\\!\\! 0.8$ for the\npositive class, making our model comparable to recent models trained on\nkeyword-focused English corpora. We demonstrate our model's adaptability to\nintra-domain temporal shifts, achieving F1 scores of $\\sim\\!\\! 0.7$. Among\nprompting variants, the best model is GPT-4, achieving an F1 score of $\\sim\\!\\!\n0.8$ for the positive class in a zero-shot setting and equipped with a custom\nconspiracy theory definition.",
      "tldr_zh": "本研究探讨了使用大型语言模型检测德语Telegram消息中的阴谋论问题，旨在避免传统基于关键词的偏见。研究比较了监督微调（如BERT-like模型）的性能，以及基于提示的方法（如Llama2、GPT-3.5和GPT-4），后者在零样本设置下无需大量训练数据。使用约4000条COVID-19期间的非关键词过滤数据集，结果显示监督微调方法在正类F1分数达到约0.8，并能适应时间偏移（F1约0.7），而GPT-4在提示方法中表现最佳，也达到约0.8的F1分数。总体上，这证明了这些方法在跨语言阴谋论检测中的有效性和可扩展性。",
      "categories": [
        "cs.CL",
        "cs.AI",
        "cs.SI",
        "I.2.7"
      ],
      "primary_category": "cs.CL",
      "comment": "Accepted to the 8th Workshop on Online Abuse and Harms (WOAH), ACL\n  2024",
      "pdf_url": "http://arxiv.org/pdf/2404.17985v1",
      "published_date": "2024-04-27 19:17:31 UTC",
      "updated_date": "2024-04-27 19:17:31 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-18T04:04:32.905310"
    },
    {
      "arxiv_id": "2404.17984v1",
      "title": "Privacy-Preserving, Dropout-Resilient Aggregation in Decentralized Learning",
      "title_zh": "翻译失败",
      "authors": [
        "Ali Reza Ghavamipour",
        "Benjamin Zi Hao Zhao",
        "Fatih Turkmen"
      ],
      "abstract": "Decentralized learning (DL) offers a novel paradigm in machine learning by\ndistributing training across clients without central aggregation, enhancing\nscalability and efficiency. However, DL's peer-to-peer model raises challenges\nin protecting against inference attacks and privacy leaks. By forgoing central\nbottlenecks, DL demands privacy-preserving aggregation methods to protect data\nfrom 'honest but curious' clients and adversaries, maintaining network-wide\nprivacy. Privacy-preserving DL faces the additional hurdle of client dropout,\nclients not submitting updates due to connectivity problems or unavailability,\nfurther complicating aggregation.\n  This work proposes three secret sharing-based dropout resilience approaches\nfor privacy-preserving DL. Our study evaluates the efficiency, performance, and\naccuracy of these protocols through experiments on datasets such as MNIST,\nFashion-MNIST, SVHN, and CIFAR-10. We compare our protocols with traditional\nsecret-sharing solutions across scenarios, including those with up to 1000\nclients. Evaluations show that our protocols significantly outperform\nconventional methods, especially in scenarios with up to 30% of clients dropout\nand model sizes of up to $10^6$ parameters. Our approaches demonstrate markedly\nhigh efficiency with larger models, higher dropout rates, and extensive client\nnetworks, highlighting their effectiveness in enhancing decentralized learning\nsystems' privacy and dropout robustness.",
      "tldr_zh": "本研究针对去中心化学习 (Decentralized Learning, DL) 中的隐私泄露和客户端掉线 (client dropout) 问题，提出三种基于秘密分享 (secret sharing) 的聚合方案，以保护数据免受“诚实但好奇”的客户端和攻击者的影响，同时提高系统鲁棒性。这些方案通过分布式训练机制处理掉线场景，确保网络隐私和高效聚合。实验在 MNIST、Fashion-MNIST、SVHN 和 CIFAR-10 数据集上评估了这些协议的效率、性能和准确性，结果显示它们在多达 1000 个客户端和高达 30% 掉线率的环境中，显著优于传统方法，尤其适用于模型参数达 $10^6$ 的较大模型。该方法增强了 DL 系统的隐私保护和 dropout 弹性，为大规模分布式学习提供了实用解决方案。",
      "categories": [
        "cs.CR",
        "cs.AI"
      ],
      "primary_category": "cs.CR",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2404.17984v1",
      "published_date": "2024-04-27 19:17:02 UTC",
      "updated_date": "2024-04-27 19:17:02 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-18T04:04:47.575247"
    },
    {
      "arxiv_id": "2404.17977v2",
      "title": "Advancing Healthcare Automation: Multi-Agent System for Medical Necessity Justification",
      "title_zh": "推进医疗保健自动化：多智能体系统用于医疗必要性证明",
      "authors": [
        "Himanshu Pandey",
        "Akhil Amod",
        "Shivang"
      ],
      "abstract": "Prior Authorization delivers safe, appropriate, and cost-effective care that\nis medically justified with evidence-based guidelines. However, the process\noften requires labor-intensive manual comparisons between patient medical\nrecords and clinical guidelines, that is both repetitive and time-consuming.\nRecent developments in Large Language Models (LLMs) have shown potential in\naddressing complex medical NLP tasks with minimal supervision. This paper\nexplores the application of Multi-Agent System (MAS) that utilize specialized\nLLM agents to automate Prior Authorization task by breaking them down into\nsimpler and manageable sub-tasks. Our study systematically investigates the\neffects of various prompting strategies on these agents and benchmarks the\nperformance of different LLMs. We demonstrate that GPT-4 achieves an accuracy\nof 86.2% in predicting checklist item-level judgments with evidence, and 95.6%\nin determining overall checklist judgment. Additionally, we explore how these\nagents can contribute to explainability of steps taken in the process, thereby\nenhancing trust and transparency in the system.",
      "tldr_zh": "该论文针对 Prior Authorization 过程的劳动密集型问题，提出了一种基于 Multi-Agent System (MAS) 的自动化框架，利用专门的 Large Language Models (LLMs) 代理将任务分解为更简单的子任务，从而实现对患者医疗记录与临床指南的自动化比较。研究系统地评估了不同提示策略对代理的影响，并对各种 LLMs 进行了基准测试，结果显示 GPT-4 在预测清单项级判断的准确率达 86.2%，在整体清单判断上达 95.6%。此外，该系统通过增强过程的可解释性，提高了医疗自动化决策的信任和透明度，为医疗保健自动化提供了重要进展。",
      "categories": [
        "cs.AI",
        "cs.MA"
      ],
      "primary_category": "cs.AI",
      "comment": "Accepted at BioNLP2024",
      "pdf_url": "http://arxiv.org/pdf/2404.17977v2",
      "published_date": "2024-04-27 18:40:05 UTC",
      "updated_date": "2024-07-06 09:29:16 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-18T04:04:56.847873"
    },
    {
      "arxiv_id": "2404.17975v2",
      "title": "Automating Customer Needs Analysis: A Comparative Study of Large Language Models in the Travel Industry",
      "title_zh": "自动化客户需求分析：大语言模型在旅游行业的比较研究",
      "authors": [
        "Simone Barandoni",
        "Filippo Chiarello",
        "Lorenzo Cascone",
        "Emiliano Marrale",
        "Salvatore Puccio"
      ],
      "abstract": "In the rapidly evolving landscape of Natural Language Processing (NLP), Large\nLanguage Models (LLMs) have emerged as powerful tools for many tasks, such as\nextracting valuable insights from vast amounts of textual data. In this study,\nwe conduct a comparative analysis of LLMs for the extraction of travel customer\nneeds from TripAdvisor and Reddit posts. Leveraging a diverse range of models,\nincluding both open-source and proprietary ones such as GPT-4 and Gemini, we\naim to elucidate their strengths and weaknesses in this specialized domain.\nThrough an evaluation process involving metrics such as BERTScore, ROUGE, and\nBLEU, we assess the performance of each model in accurately identifying and\nsummarizing customer needs. Our findings highlight the efficacy of opensource\nLLMs, particularly Mistral 7B, in achieving comparable performance to larger\nclosed models while offering affordability and customization benefits.\nAdditionally, we underscore the importance of considering factors such as model\nsize, resource requirements, and performance metrics when selecting the most\nsuitable LLM for customer needs analysis tasks. Overall, this study contributes\nvaluable insights for businesses seeking to leverage advanced NLP techniques to\nenhance customer experience and drive operational efficiency in the travel\nindustry.",
      "tldr_zh": "这篇论文比较了各种大型语言模型（LLMs）在从 TripAdvisor 和 Reddit 帖子中提取旅行客户需求方面的性能，包括开源模型如 Mistral 7B 和专有模型如 GPT-4 与 Gemini。研究通过 BERTScore、ROUGE 和 BLEU 等指标评估这些模型的准确性和总结能力，结果显示 Mistral 7B 等开源模型在性能上可与大型闭源模型媲美，同时提供更高的成本效益和可定制性。论文强调了在选择 LLM 时需考虑模型大小、资源需求和性能指标的重要性，并为旅行行业企业提供见解，以利用 NLP 技术提升客户体验和操作效率。",
      "categories": [
        "cs.CL",
        "cs.AI",
        "cs.HC",
        "cs.LG"
      ],
      "primary_category": "cs.CL",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2404.17975v2",
      "published_date": "2024-04-27 18:28:10 UTC",
      "updated_date": "2025-04-09 10:21:07 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-18T04:05:09.351737"
    },
    {
      "arxiv_id": "2404.17970v1",
      "title": "Privacy-Preserving Aggregation for Decentralized Learning with Byzantine-Robustness",
      "title_zh": "具有拜占庭鲁",
      "authors": [
        "Ali Reza Ghavamipour",
        "Benjamin Zi Hao Zhao",
        "Oguzhan Ersoy",
        "Fatih Turkmen"
      ],
      "abstract": "Decentralized machine learning (DL) has been receiving an increasing interest\nrecently due to the elimination of a single point of failure, present in\nFederated learning setting. Yet, it is threatened by the looming threat of\nByzantine clients who intentionally disrupt the learning process by\nbroadcasting arbitrary model updates to other clients, seeking to degrade the\nperformance of the global model. In response, robust aggregation schemes have\nemerged as promising solutions to defend against such Byzantine clients,\nthereby enhancing the robustness of Decentralized Learning. Defenses against\nByzantine adversaries, however, typically require access to the updates of\nother clients, a counterproductive privacy trade-off that in turn increases the\nrisk of inference attacks on those same model updates.\n  In this paper, we introduce SecureDL, a novel DL protocol designed to enhance\nthe security and privacy of DL against Byzantine threats. SecureDL~facilitates\na collaborative defense, while protecting the privacy of clients' model updates\nthrough secure multiparty computation. The protocol employs efficient\ncomputation of cosine similarity and normalization of updates to robustly\ndetect and exclude model updates detrimental to model convergence. By using\nMNIST, Fashion-MNIST, SVHN and CIFAR-10 datasets, we evaluated SecureDL against\nvarious Byzantine attacks and compared its effectiveness with four existing\ndefense mechanisms. Our experiments show that SecureDL is effective even in the\ncase of attacks by the malicious majority (e.g., 80% Byzantine clients) while\npreserving high training accuracy.",
      "tldr_zh": "该论文探讨了去中心化机器学习 (Decentralized Learning) 在面对 Byzantine 客户端攻击时存在的隐私风险，这些攻击通过广播任意模型更新来破坏全局模型性能。作者提出 SecureDL，一种新型协议，利用安全多方计算 (Secure Multiparty Computation) 保护客户端模型更新的隐私，同时通过计算余弦相似度 (Cosine Similarity) 和更新归一化来检测并排除有害更新。实验结果显示，SecureDL 在 MNIST、Fashion-MNIST、SVHN 和 CIFAR-10 数据集上，对抗各种 Byzantine 攻击（包括80%恶意客户端）时，保持了高训练准确率，并优于现有四种防御机制。",
      "categories": [
        "cs.CR",
        "cs.AI"
      ],
      "primary_category": "cs.CR",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2404.17970v1",
      "published_date": "2024-04-27 18:17:36 UTC",
      "updated_date": "2024-04-27 18:17:36 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-18T04:05:21.273819"
    },
    {
      "arxiv_id": "2404.17962v2",
      "title": "Deep Learning for Low-Latency, Quantum-Ready RF Sensing",
      "title_zh": "翻译失败",
      "authors": [
        "Pranav Gokhale",
        "Caitlin Carnahan",
        "William Clark",
        "Teague Tomesh",
        "Frederic T. Chong"
      ],
      "abstract": "Recent work has shown the promise of applying deep learning to enhance\nsoftware processing of radio frequency (RF) signals. In parallel, hardware\ndevelopments with quantum RF sensors based on Rydberg atoms are breaking\nlongstanding barriers in frequency range, resolution, and sensitivity. In this\npaper, we describe our implementations of quantum-ready machine learning\napproaches for RF signal classification. Our primary objective is latency:\nwhile deep learning offers a more powerful computational paradigm, it also\ntraditionally incurs latency overheads that hinder wider scale deployment. Our\nwork spans three axes. (1) A novel continuous wavelet transform (CWT) based\nrecurrent neural network (RNN) architecture that enables flexible online\nclassification of RF signals on-the-fly with reduced sampling time. (2)\nLow-latency inference techniques for both GPU and CPU that span over 100x\nreductions in inference time, enabling real-time operation with sub-millisecond\ninference. (3) Quantum-readiness validated through application of our models to\nphysics-based simulation of Rydberg atom QRF sensors. Altogether, our work\nbridges towards next-generation RF sensors that use quantum technology to\nsurpass previous physical limits, paired with latency-optimized AI/ML software\nthat is suitable for real-time deployment.",
      "tldr_zh": "这篇论文探讨了深度学习在低延迟、量子-ready 射频 (RF) 感知中的应用，旨在通过机器学习提升 RF 信号分类的实时性能，同时兼容基于 Rydberg 原子等量子传感器。研究提出了一种新型基于连续小波变换 (CWT) 的循环神经网络 (RNN) 架构，以及针对 GPU 和 CPU 的低延迟推理技术，实现推理时间减少超过 100 倍，支持亚毫秒级实时操作。主要结果显示，该方法在物理模拟中验证了量子就绪性，为下一代超越物理极限的 RF 传感器提供高效 AI/ML 软件支持。",
      "categories": [
        "quant-ph",
        "cs.AI",
        "cs.LG",
        "cs.PF",
        "cs.SY",
        "eess.SY"
      ],
      "primary_category": "quant-ph",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2404.17962v2",
      "published_date": "2024-04-27 17:22:12 UTC",
      "updated_date": "2025-04-23 03:33:09 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-18T04:05:36.470967"
    },
    {
      "arxiv_id": "2404.17947v1",
      "title": "Bounding the Expected Robustness of Graph Neural Networks Subject to Node Feature Attacks",
      "title_zh": "在节点特征攻击下的图神经网络期望鲁棒",
      "authors": [
        "Yassine Abbahaddou",
        "Sofiane Ennadir",
        "Johannes F. Lutzeyer",
        "Michalis Vazirgiannis",
        "Henrik Boström"
      ],
      "abstract": "Graph Neural Networks (GNNs) have demonstrated state-of-the-art performance\nin various graph representation learning tasks. Recently, studies revealed\ntheir vulnerability to adversarial attacks. In this work, we theoretically\ndefine the concept of expected robustness in the context of attributed graphs\nand relate it to the classical definition of adversarial robustness in the\ngraph representation learning literature. Our definition allows us to derive an\nupper bound of the expected robustness of Graph Convolutional Networks (GCNs)\nand Graph Isomorphism Networks subject to node feature attacks. Building on\nthese findings, we connect the expected robustness of GNNs to the\northonormality of their weight matrices and consequently propose an\nattack-independent, more robust variant of the GCN, called the Graph\nConvolutional Orthonormal Robust Networks (GCORNs). We further introduce a\nprobabilistic method to estimate the expected robustness, which allows us to\nevaluate the effectiveness of GCORN on several real-world datasets.\nExperimental experiments showed that GCORN outperforms available defense\nmethods. Our code is publicly available at:\n\\href{https://github.com/Sennadir/GCORN}{https://github.com/Sennadir/GCORN}.",
      "tldr_zh": "这篇论文定义了图神经网络(GNNs)在节点特征攻击下的预期鲁棒性(expected robustness)，并将其与传统对抗鲁棒性相关联，针对Graph Convolutional Networks (GCNs)和Graph Isomorphism Networks推导了其上界。研究者将expected robustness与权重矩阵的orthonormality联系起来，提出了一种更鲁棒的变体Graph Convolutional Orthonormal Robust Networks (GCORNs)，并引入概率方法进行估计。实验结果显示，GCORNs在多个真实数据集上优于现有防御方法，代码已在GitHub上公开。",
      "categories": [
        "cs.LG",
        "cs.AI",
        "cs.CR"
      ],
      "primary_category": "cs.LG",
      "comment": "Accepted at ICLR 2024",
      "pdf_url": "http://arxiv.org/pdf/2404.17947v1",
      "published_date": "2024-04-27 15:57:35 UTC",
      "updated_date": "2024-04-27 15:57:35 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-18T04:05:46.064758"
    },
    {
      "arxiv_id": "2404.17943v2",
      "title": "Deep Representation Learning for Forecasting Recursive and Multi-Relational Events in Temporal Networks",
      "title_zh": "深度表示学习用于预测时间网络中",
      "authors": [
        "Tony Gracious",
        "Ambedkar Dukkipati"
      ],
      "abstract": "Understanding relations arising out of interactions among entities can be\nvery difficult, and predicting them is even more challenging. This problem has\nmany applications in various fields, such as financial networks and e-commerce.\nThese relations can involve much more complexities than just involving more\nthan two entities. One such scenario is evolving recursive relations between\nmultiple entities, and so far, this is still an open problem. This work\naddresses the problem of forecasting higher-order interaction events that can\nbe multi-relational and recursive. We pose the problem in the framework of\nrepresentation learning of temporal hypergraphs that can capture complex\nrelationships involving multiple entities. The proposed model,\n\\textit{Relational Recursive Hyperedge Temporal Point Process} (RRHyperTPP)\nuses an encoder that learns a dynamic node representation based on the\nhistorical interaction patterns and then a hyperedge link prediction-based\ndecoder to model the occurrence of interaction events. These learned\nrepresentations are then used for downstream tasks involving forecasting the\ntype and time of interactions. The main challenge in learning from hyperedge\nevents is that the number of possible hyperedges grows exponentially with the\nnumber of nodes in the network. This will make the computation of negative\nlog-likelihood of the temporal point process expensive, as the calculation of\nsurvival function requires a summation over all possible hyperedges. In our\nwork, we develop a noise contrastive estimation method to learn the parameters\nof our model, and we have experimentally shown that our models perform better\nthan previous state-of-the-art methods for interaction forecasting.",
      "tldr_zh": "本论文探讨了在时间网络中预测递归和多关系事件的问题，提出了一种基于深度表示学习的模型 RRHyperTPP（Relational Recursive Hyperedge Temporal Point Process）。该模型使用时间超图框架，通过一个编码器学习动态节点表示基于历史交互模式，以及一个超边链接预测解码器来预测交互事件的类型和时间。针对超边数量指数增长导致的计算挑战，论文引入了噪声对比估计方法来高效学习模型参数。实验结果显示，该模型在交互预测任务上优于现有最先进方法。",
      "categories": [
        "cs.LG",
        "cs.AI",
        "cs.SI"
      ],
      "primary_category": "cs.LG",
      "comment": "AAAI-2025",
      "pdf_url": "http://arxiv.org/pdf/2404.17943v2",
      "published_date": "2024-04-27 15:46:54 UTC",
      "updated_date": "2024-12-18 16:33:51 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-18T04:05:57.921949"
    },
    {
      "arxiv_id": "2404.17937v1",
      "title": "DTization: A New Method for Supervised Feature Scaling",
      "title_zh": "DTization：一种用于监督特征缩放的新方法",
      "authors": [
        "Niful Islam"
      ],
      "abstract": "Artificial intelligence is currently a dominant force in shaping various\naspects of the world. Machine learning is a sub-field in artificial\nintelligence. Feature scaling is one of the data pre-processing techniques that\nimproves the performance of machine learning algorithms. The traditional\nfeature scaling techniques are unsupervised where they do not have influence of\nthe dependent variable in the scaling process. In this paper, we have presented\na novel feature scaling technique named DTization that employs decision tree\nand robust scaler for supervised feature scaling. The proposed method utilizes\ndecision tree to measure the feature importance and based on the importance,\ndifferent features get scaled differently with the robust scaler algorithm. The\nproposed method has been extensively evaluated on ten classification and\nregression datasets on various evaluation matrices and the results show a\nnoteworthy performance improvement compared to the traditional feature scaling\nmethods.",
      "tldr_zh": "这篇论文提出了一种新的监督特征缩放方法，名为 DTization，利用 decision tree 测量特征重要性，并结合 robust scaler 根据重要性对不同特征进行差异化缩放，以改善机器学习算法的性能。不同于传统的无监督特征缩放技术，DTization 考虑了因变量的影响，使缩放过程更具针对性。在 10 个分类和回归数据集上的实验评估显示，该方法在各种评价矩阵上比传统方法取得了显著的性能提升。",
      "categories": [
        "cs.LG",
        "cs.AI"
      ],
      "primary_category": "cs.LG",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2404.17937v1",
      "published_date": "2024-04-27 15:25:03 UTC",
      "updated_date": "2024-04-27 15:25:03 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-18T04:06:10.793905"
    },
    {
      "arxiv_id": "2404.17930v1",
      "title": "Multi-Stream Cellular Test-Time Adaptation of Real-Time Models Evolving in Dynamic Environments",
      "title_zh": "翻译失败",
      "authors": [
        "Benoît Gérin",
        "Anaïs Halin",
        "Anthony Cioppa",
        "Maxim Henry",
        "Bernard Ghanem",
        "Benoît Macq",
        "Christophe De Vleeschouwer",
        "Marc Van Droogenbroeck"
      ],
      "abstract": "In the era of the Internet of Things (IoT), objects connect through a dynamic\nnetwork, empowered by technologies like 5G, enabling real-time data sharing.\nHowever, smart objects, notably autonomous vehicles, face challenges in\ncritical local computations due to limited resources. Lightweight AI models\noffer a solution but struggle with diverse data distributions. To address this\nlimitation, we propose a novel Multi-Stream Cellular Test-Time Adaptation\n(MSC-TTA) setup where models adapt on the fly to a dynamic environment divided\ninto cells. Then, we propose a real-time adaptive student-teacher method that\nleverages the multiple streams available in each cell to quickly adapt to\nchanging data distributions. We validate our methodology in the context of\nautonomous vehicles navigating across cells defined based on location and\nweather conditions. To facilitate future benchmarking, we release a new\nmulti-stream large-scale synthetic semantic segmentation dataset, called DADE,\nand show that our multi-stream approach outperforms a single-stream baseline.\nWe believe that our work will open research opportunities in the IoT and 5G\neras, offering solutions for real-time model adaptation.",
      "tldr_zh": "本研究针对物联网(IoT)时代中智能物体（如自动驾驶车辆）在动态环境中进行实时计算的挑战，提出了一种新型Multi-Stream Cellular Test-Time Adaptation (MSC-TTA)框架。该框架将环境划分为多个单元，并采用实时自适应学生-教师方法，利用每个单元中的多流数据快速适应变化的数据分布。在自动驾驶车辆场景中进行验证，该方法基于位置和天气条件定义单元，并发布了新的多流大规模合成语义分割数据集DADE，结果显示多流方法优于单流基准，提升了模型适应性。该工作为IoT和5G时代提供实时模型适应的解决方案，开启了新的研究机会。",
      "categories": [
        "cs.CV",
        "cs.AI",
        "eess.IV"
      ],
      "primary_category": "cs.CV",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2404.17930v1",
      "published_date": "2024-04-27 15:00:57 UTC",
      "updated_date": "2024-04-27 15:00:57 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-18T04:06:24.177984"
    },
    {
      "arxiv_id": "2404.17929v1",
      "title": "Spatio-Temporal Side Tuning Pre-trained Foundation Models for Video-based Pedestrian Attribute Recognition",
      "title_zh": "翻译失败",
      "authors": [
        "Xiao Wang",
        "Qian Zhu",
        "Jiandong Jin",
        "Jun Zhu",
        "Futian Wang",
        "Bo Jiang",
        "Yaowei Wang",
        "Yonghong Tian"
      ],
      "abstract": "Existing pedestrian attribute recognition (PAR) algorithms are mainly\ndeveloped based on a static image, however, the performance is unreliable in\nchallenging scenarios, such as heavy occlusion, motion blur, etc. In this work,\nwe propose to understand human attributes using video frames that can fully use\ntemporal information by fine-tuning a pre-trained multi-modal foundation model\nefficiently. Specifically, we formulate the video-based PAR as a\nvision-language fusion problem and adopt a pre-trained foundation model CLIP to\nextract the visual features. More importantly, we propose a novel\nspatiotemporal side-tuning strategy to achieve parameter-efficient optimization\nof the pre-trained vision foundation model. To better utilize the semantic\ninformation, we take the full attribute list that needs to be recognized as\nanother input and transform the attribute words/phrases into the corresponding\nsentence via split, expand, and prompt operations. Then, the text encoder of\nCLIP is utilized for embedding processed attribute descriptions. The averaged\nvisual tokens and text tokens are concatenated and fed into a fusion\nTransformer for multi-modal interactive learning. The enhanced tokens will be\nfed into a classification head for pedestrian attribute prediction. Extensive\nexperiments on two large-scale video-based PAR datasets fully validated the\neffectiveness of our proposed framework. The source code of this paper is\navailable at https://github.com/Event-AHU/OpenPAR.",
      "tldr_zh": "本文提出了一种基于视频的行人属性识别（PAR）方法，通过高效微调预训练的多模态基础模型 CLIP 来充分利用时空信息，解决传统图像-based PAR 在重度遮挡和运动模糊等挑战场景下的性能问题。核心创新是引入时空侧向微调（spatio-temporal side-tuning）策略，实现参数高效优化，并将视觉特征与处理后的属性描述文本通过融合 Transformer 进行多模态交互学习。实验在两个大规模视频 PAR 数据集上验证了该框架的有效性，显著提升了识别准确率，并提供了开源代码。",
      "categories": [
        "cs.CV",
        "cs.AI",
        "cs.CL"
      ],
      "primary_category": "cs.CV",
      "comment": "Parameter Efficient Fine-Tuning Strategy for Video-based Pedestrian\n  Attribute Recognition",
      "pdf_url": "http://arxiv.org/pdf/2404.17929v1",
      "published_date": "2024-04-27 14:43:32 UTC",
      "updated_date": "2024-04-27 14:43:32 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-18T04:06:34.929711"
    },
    {
      "arxiv_id": "2404.17926v1",
      "title": "Pre-training on High Definition X-ray Images: An Experimental Study",
      "title_zh": "高清 X 射线图像的预训练：一个实验研究",
      "authors": [
        "Xiao Wang",
        "Yuehang Li",
        "Wentao Wu",
        "Jiandong Jin",
        "Yao Rong",
        "Bo Jiang",
        "Chuanfu Li",
        "Jin Tang"
      ],
      "abstract": "Existing X-ray based pre-trained vision models are usually conducted on a\nrelatively small-scale dataset (less than 500k samples) with limited resolution\n(e.g., 224 $\\times$ 224). However, the key to the success of self-supervised\npre-training large models lies in massive training data, and maintaining high\nresolution in the field of X-ray images is the guarantee of effective solutions\nto difficult miscellaneous diseases. In this paper, we address these issues by\nproposing the first high-definition (1280 $\\times$ 1280) X-ray based\npre-trained foundation vision model on our newly collected large-scale dataset\nwhich contains more than 1 million X-ray images. Our model follows the masked\nauto-encoder framework which takes the tokens after mask processing (with a\nhigh rate) is used as input, and the masked image patches are reconstructed by\nthe Transformer encoder-decoder network. More importantly, we introduce a novel\ncontext-aware masking strategy that utilizes the chest contour as a boundary\nfor adaptive masking operations. We validate the effectiveness of our model on\ntwo downstream tasks, including X-ray report generation and disease\nrecognition. Extensive experiments demonstrate that our pre-trained medical\nfoundation vision model achieves comparable or even new state-of-the-art\nperformance on downstream benchmark datasets. The source code and pre-trained\nmodels of this paper will be released on\nhttps://github.com/Event-AHU/Medical_Image_Analysis.",
      "tldr_zh": "本研究针对现有X-ray预训练视觉模型数据规模小（少于50万样本）和分辨率低（例如224×224）的局限性，提出第一个高分辨率（1280×1280）的X-ray基础视觉模型，使用一个新收集的超过100万张图像的大型数据集进行预训练。模型采用Masked Auto-Encoder框架，通过高比例掩码处理后的tokens作为输入，并引入创新的context-aware masking策略，利用胸部轮廓作为边界进行自适应掩码，以提升重建精度。实验结果显示，该模型在X-ray报告生成和疾病识别等下游任务上，实现了与现有方法相当或新的state-of-the-art性能，并计划在GitHub上开源代码和预训练模型。",
      "categories": [
        "eess.IV",
        "cs.AI",
        "cs.CV",
        "cs.LG"
      ],
      "primary_category": "eess.IV",
      "comment": "Technology Report",
      "pdf_url": "http://arxiv.org/pdf/2404.17926v1",
      "published_date": "2024-04-27 14:29:53 UTC",
      "updated_date": "2024-04-27 14:29:53 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-18T04:06:47.093439"
    },
    {
      "arxiv_id": "2404.17924v2",
      "title": "Results about sets of desirable gamble sets",
      "title_zh": "翻译失败",
      "authors": [
        "Catrin Campbell-Moore"
      ],
      "abstract": "Coherent sets of desirable gamble sets is used as a model for representing an\nagents opinions and choice preferences under uncertainty. In this paper we\nprovide some results about the axioms required for coherence and the natural\nextension of a given set of desirable gamble sets. We also show that coherent\nsets of desirable gamble sets can be represented by a proper filter of coherent\nsets of desirable gambles.",
      "tldr_zh": "本论文探讨了 coherent sets of desirable gamble sets 作为一种建模代理在不确定性下意见和选择偏好的框架。研究提供了关于 coherence 公理以及给定 set of desirable gamble sets 的 natural extension 的结果，深化了对该模型的理论基础。论文进一步证明，coherent sets of desirable gamble sets 可以由一个 proper filter of coherent sets of desirable gambles 表示，从而为不确定性决策理论提供了新的表示方法。",
      "categories": [
        "cs.AI",
        "cs.GT"
      ],
      "primary_category": "cs.AI",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2404.17924v2",
      "published_date": "2024-04-27 14:29:13 UTC",
      "updated_date": "2024-05-16 16:35:01 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-18T04:06:56.539960"
    },
    {
      "arxiv_id": "2404.17916v2",
      "title": "FedCRL: Personalized Federated Learning with Contrastive Shared Representations for Label Heterogeneity in Non-IID Data",
      "title_zh": "翻译失败",
      "authors": [
        "Chenghao Huang",
        "Xiaolu Chen",
        "Yanru Zhang",
        "Hao Wang"
      ],
      "abstract": "Heterogeneity resulting from label distribution skew and data scarcity can\nlead to inaccuracy and unfairness in intelligent communication applications\nthat mainly rely on distributed computing. To deal with it, this paper proposes\na novel personalized federated learning algorithm, named Federated Contrastive\nShareable Representations (FedCoSR), to facilitate knowledge sharing among\nclients while maintaining data privacy. Specifically, parameters of local\nmodels' shallow layers and typical local representations are both considered\nshareable information for the server and aggregated globally. To address poor\nperformance caused by label distribution skew among clients, contrastive\nlearning is adopted between local and global representations to enrich local\nknowledge. Additionally, to ensure fairness for clients with scarce data,\nFedCoSR introduces adaptive local aggregation to coordinate the global model\ninvolvement in each client. Our simulations demonstrate FedCoSR's effectiveness\nin mitigating label heterogeneity by achieving accuracy and fairness\nimprovements over existing methods on datasets with varying degrees of label\nheterogeneity.",
      "tldr_zh": "这篇论文提出了一种名为 FedCRL 的个性化联邦学习算法，用于处理非 IID 数据中标签异质性带来的不准确性和不公平问题。算法通过共享本地模型浅层参数和典型本地表示进行全局聚合，并采用 Contrastive Learning 在本地和全局表示之间进行对比学习，以丰富本地知识并缓解标签分布偏差。此外，引入自适应本地聚合机制，确保数据稀缺客户端的公平性；实验结果显示，FedCRL 在不同标签异质性数据集上，比现有方法显著提高了准确性和公平性。",
      "categories": [
        "cs.LG",
        "cs.AI"
      ],
      "primary_category": "cs.LG",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2404.17916v2",
      "published_date": "2024-04-27 14:05:18 UTC",
      "updated_date": "2024-11-22 12:51:47 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-18T04:07:09.574829"
    },
    {
      "arxiv_id": "2404.17912v2",
      "title": "SERPENT-VLM : Self-Refining Radiology Report Generation Using Vision Language Models",
      "title_zh": "翻译失败",
      "authors": [
        "Manav Nitin Kapadnis",
        "Sohan Patnaik",
        "Abhilash Nandy",
        "Sourjyadip Ray",
        "Pawan Goyal",
        "Debdoot Sheet"
      ],
      "abstract": "Radiology Report Generation (R2Gen) demonstrates how Multi-modal Large\nLanguage Models (MLLMs) can automate the creation of accurate and coherent\nradiological reports. Existing methods often hallucinate details in text-based\nreports that don't accurately reflect the image content. To mitigate this, we\nintroduce a novel strategy, SERPENT-VLM (SElf Refining Radiology RePort\nGENeraTion using Vision Language Models), which improves the R2Gen task by\nintegrating a self-refining mechanism into the MLLM framework. We employ a\nunique self-supervised loss that leverages similarity between pooled image\nrepresentations and the contextual representations of the generated\nradiological text, alongside the standard Causal Language Modeling objective,\nto refine image-text representations. This allows the model to scrutinize and\nalign the generated text through dynamic interaction between a given image and\nthe generated text, therefore reducing hallucination and continuously enhancing\nnuanced report generation. SERPENT-VLM outperforms existing baselines such as\nLLaVA-Med, BiomedGPT, etc., achieving SoTA performance on the IU X-ray and\nRadiology Objects in COntext (ROCO) datasets, and also proves to be robust\nagainst noisy images. A qualitative case study emphasizes the significant\nadvancements towards more sophisticated MLLM frameworks for R2Gen, opening\npaths for further research into self-supervised refinement in the medical\nimaging domain.",
      "tldr_zh": "该研究提出了一种名为 SERPENT-VLM 的新策略，用于改进放射学报告生成 (R2Gen)，通过整合自精炼机制到多模态大型语言模型 (MLLMs) 中，减少报告中的幻觉问题。SERPENT-VLM 采用自监督损失来衡量图像表示与生成文本的上下文表示的相似性，并结合因果语言建模 (Causal Language Modeling) 目标，实现图像和文本的动态对齐，从而提升报告的准确性和细致度。在 IU X-ray 和 ROCO 数据集上，该模型超越了基线如 LLaVA-Med 和 BiomedGPT，实现了最先进 (SoTA) 性能，并证明了对噪声图像的鲁棒性，为医疗成像领域的自监督精炼技术开辟了新研究方向。",
      "categories": [
        "cs.CL",
        "cs.AI",
        "cs.LG"
      ],
      "primary_category": "cs.CL",
      "comment": "8 pages, 3 figures, 4 tables, Accepted as oral at Clinical NLP\n  workshop at NAACL 2024",
      "pdf_url": "http://arxiv.org/pdf/2404.17912v2",
      "published_date": "2024-04-27 13:46:23 UTC",
      "updated_date": "2024-07-18 16:03:18 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-18T04:07:24.744780"
    },
    {
      "arxiv_id": "2404.17892v1",
      "title": "Shared learning of powertrain control policies for vehicle fleets",
      "title_zh": "车辆车队的动力系统控制策略共享学习",
      "authors": [
        "Lindsey Kerbel",
        "Beshah Ayalew",
        "Andrej Ivanco"
      ],
      "abstract": "Emerging data-driven approaches, such as deep reinforcement learning (DRL),\naim at on-the-field learning of powertrain control policies that optimize fuel\neconomy and other performance metrics. Indeed, they have shown great potential\nin this regard for individual vehicles on specific routes or drive cycles.\nHowever, for fleets of vehicles that must service a distribution of routes, DRL\napproaches struggle with learning stability issues that result in high\nvariances and challenge their practical deployment. In this paper, we present a\nnovel framework for shared learning among a fleet of vehicles through the use\nof a distilled group policy as the knowledge sharing mechanism for the policy\nlearning computations at each vehicle. We detail the mathematical formulation\nthat makes this possible. Several scenarios are considered to analyze the\nfunctionality, performance, and computational scalability of the framework with\nfleet size. Comparisons of the cumulative performance of fleets using our\nproposed shared learning approach with a baseline of individual learning agents\nand another state-of-the-art approach with a centralized learner show clear\nadvantages to our approach. For example, we find a fleet average asymptotic\nimprovement of 8.5 percent in fuel economy compared to the baseline while also\nimproving on the metrics of acceleration error and shifting frequency for\nfleets serving a distribution of suburban routes. Furthermore, we include\ndemonstrative results that show how the framework reduces variance within a\nfleet and also how it helps individual agents adapt better to new routes.",
      "tldr_zh": "这篇论文针对车辆车队使用深度强化学习 (DRL) 优化动力系统控制策略时存在的学习稳定性问题和高方差挑战，提出了一种共享学习框架。该框架通过蒸馏的群组策略 (distilled group policy) 作为知识共享机制，让车队车辆共同学习和适应多种路线。论文详细阐述了数学公式支持下的实现方法，并通过多种场景比较显示，与个体学习和集中式学习方法相比，该框架平均提高了8.5%的燃油经济性，同时改善了加速误差和换档频率。此外，该方法还降低了车队内方差，帮助车辆更好地适应新路线。",
      "categories": [
        "eess.SY",
        "cs.AI",
        "cs.LG",
        "cs.SY"
      ],
      "primary_category": "eess.SY",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2404.17892v1",
      "published_date": "2024-04-27 13:01:05 UTC",
      "updated_date": "2024-04-27 13:01:05 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-18T04:07:38.286636"
    },
    {
      "arxiv_id": "2404.17890v2",
      "title": "DPER: Diffusion Prior Driven Neural Representation for Limited Angle and Sparse View CT Reconstruction",
      "title_zh": "DPER：扩散先验驱动神经表示用于有限角度和",
      "authors": [
        "Chenhe Du",
        "Xiyue Lin",
        "Qing Wu",
        "Xuanyu Tian",
        "Ying Su",
        "Zhe Luo",
        "Rui Zheng",
        "Yang Chen",
        "Hongjiang Wei",
        "S. Kevin Zhou",
        "Jingyi Yu",
        "Yuyao Zhang"
      ],
      "abstract": "Limited-angle and sparse-view computed tomography (LACT and SVCT) are crucial\nfor expanding the scope of X-ray CT applications. However, they face challenges\ndue to incomplete data acquisition, resulting in diverse artifacts in the\nreconstructed CT images. Emerging implicit neural representation (INR)\ntechniques, such as NeRF, NeAT, and NeRP, have shown promise in\nunder-determined CT imaging reconstruction tasks. However, the unsupervised\nnature of INR architecture imposes limited constraints on the solution space,\nparticularly for the highly ill-posed reconstruction task posed by LACT and\nultra-SVCT. In this study, we introduce the Diffusion Prior Driven Neural\nRepresentation (DPER), an advanced unsupervised framework designed to address\nthe exceptionally ill-posed CT reconstruction inverse problems. DPER adopts the\nHalf Quadratic Splitting (HQS) algorithm to decompose the inverse problem into\ndata fidelity and distribution prior sub-problems. The two sub-problems are\nrespectively addressed by INR reconstruction scheme and pre-trained score-based\ndiffusion model. This combination first injects the implicit image local\nconsistency prior from INR. Additionally, it effectively augments the\nfeasibility of the solution space for the inverse problem through the\ngenerative diffusion model, resulting in increased stability and precision in\nthe solutions. We conduct comprehensive experiments to evaluate the performance\nof DPER on LACT and ultra-SVCT reconstruction with two public datasets (AAPM\nand LIDC), an in-house clinical COVID-19 dataset and a public raw projection\ndataset created by Mayo Clinic. The results show that our method outperforms\nthe state-of-the-art reconstruction methods on in-domain datasets, while\nachieving significant performance improvements on out-of-domain (OOD) datasets.",
      "tldr_zh": "本研究提出DPER框架，用于解决Limited-angle CT (LACT)和Sparse-view CT (SVCT)重建中的不完整数据问题，这些问题常导致重建图像出现伪影。DPER采用Half Quadratic Splitting (HQS)算法将逆问题分解为数据保真度和分布先验子问题，分别通过Implicit Neural Representation (INR)方案和预训练的score-based diffusion model进行处理，从而注入INR的局部一致性先验并增强diffusion model的生成能力，提高重建的稳定性和精度。在多个公开数据集（如AAPM、LIDC和Mayo Clinic）上的实验表明，DPER优于现有最先进方法，尤其在out-of-domain数据集上实现了显著性能提升。",
      "categories": [
        "eess.IV",
        "cs.AI",
        "cs.CV",
        "I.2.10; I.4.5"
      ],
      "primary_category": "eess.IV",
      "comment": "16 pages, 11 figures",
      "pdf_url": "http://arxiv.org/pdf/2404.17890v2",
      "published_date": "2024-04-27 12:55:13 UTC",
      "updated_date": "2024-07-19 08:12:24 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-18T04:07:49.540117"
    },
    {
      "arxiv_id": "2404.17886v1",
      "title": "Feature graphs for interpretable unsupervised tree ensembles: centrality, interaction, and application in disease subtyping",
      "title_zh": "翻译失败",
      "authors": [
        "Christel Sirocchi",
        "Martin Urschler",
        "Bastian Pfeifer"
      ],
      "abstract": "Interpretable machine learning has emerged as central in leveraging\nartificial intelligence within high-stakes domains such as healthcare, where\nunderstanding the rationale behind model predictions is as critical as\nachieving high predictive accuracy. In this context, feature selection assumes\na pivotal role in enhancing model interpretability by identifying the most\nimportant input features in black-box models. While random forests are\nfrequently used in biomedicine for their remarkable performance on tabular\ndatasets, the accuracy gained from aggregating decision trees comes at the\nexpense of interpretability. Consequently, feature selection for enhancing\ninterpretability in random forests has been extensively explored in supervised\nsettings. However, its investigation in the unsupervised regime remains notably\nlimited. To address this gap, the study introduces novel methods to construct\nfeature graphs from unsupervised random forests and feature selection\nstrategies to derive effective feature combinations from these graphs. Feature\ngraphs are constructed for the entire dataset as well as individual clusters\nleveraging the parent-child node splits within the trees, such that feature\ncentrality captures their relevance to the clustering task, while edge weights\nreflect the discriminating power of feature pairs. Graph-based feature\nselection methods are extensively evaluated on synthetic and benchmark datasets\nboth in terms of their ability to reduce dimensionality while improving\nclustering performance, as well as to enhance model interpretability. An\napplication on omics data for disease subtyping identifies the top features for\neach cluster, showcasing the potential of the proposed approach to enhance\ninterpretability in clustering analyses and its utility in a real-world\nbiomedical application.",
      "tldr_zh": "这篇论文针对无监督随机森林的可解释性挑战，提出了一种基于特征图（feature graphs）的新方法，用于识别关键特征并提升模型解释。方法通过树中的父子节点分裂构建特征图（feature graphs），利用特征中心性（feature centrality）评估特征与聚类任务的相关性，并通过边权重（edge weights）衡量特征对的区分能力。实验在合成和基准数据集上验证了该方法的有效性，能够减少维度、改善聚类性能，并在疾病亚型（disease subtyping）的组学数据应用中成功识别每个聚类的顶级特征，从而增强生物医学分析的可解释性。",
      "categories": [
        "cs.LG",
        "cs.AI",
        "I.2.1; I.5.3; J.3"
      ],
      "primary_category": "cs.LG",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2404.17886v1",
      "published_date": "2024-04-27 12:47:37 UTC",
      "updated_date": "2024-04-27 12:47:37 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-18T04:08:03.262340"
    },
    {
      "arxiv_id": "2404.17871v4",
      "title": "Deep Learning Library Testing: Definition, Methods and Challenges",
      "title_zh": "深度学习库测试：定义、方法和挑战",
      "authors": [
        "Xiaoyu Zhang",
        "Weipeng Jiang",
        "Chao Shen",
        "Qi Li",
        "Qian Wang",
        "Chenhao Lin",
        "Xiaohong Guan"
      ],
      "abstract": "In recent years, software systems powered by deep learning (DL) techniques\nhave significantly facilitated people's lives in many aspects. As the backbone\nof these DL systems, various DL libraries undertake the underlying optimization\nand computation. However, like traditional software, DL libraries are not\nimmune to bugs, which can pose serious threats to users' personal property and\nsafety. Studying the characteristics of DL libraries, their associated bugs,\nand the corresponding testing methods is crucial for enhancing the security of\nDL systems and advancing the widespread application of DL technology. This\npaper provides an overview of the testing research related to various DL\nlibraries, discusses the strengths and weaknesses of existing methods, and\nprovides guidance and reference for the application of the DL library. This\npaper first introduces the workflow of DL underlying libraries and the\ncharacteristics of three kinds of DL libraries involved, namely DL framework,\nDL compiler, and DL hardware library. It then provides definitions for DL\nunderlying library bugs and testing. Additionally, this paper summarizes the\nexisting testing methods and tools tailored to these DL libraries separately\nand analyzes their effectiveness and limitations. It also discusses the\nexisting challenges of DL library testing and outlines potential directions for\nfuture research.",
      "tldr_zh": "这篇论文探讨了Deep Learning Library Testing的定义、方法和挑战，旨在提升DL库的安全性和应用。论文首先介绍了DL底层库的工作流程及其类型，包括DL framework、DL compiler和DL hardware library，并对DL库bug和测试进行了定义。随后，它总结了现有的测试方法和工具，分析了它们的有效性与局限性。最后，论文讨论了当前测试面临的挑战，并为未来研究指出了潜在方向。",
      "categories": [
        "cs.SE",
        "cs.AI"
      ],
      "primary_category": "cs.SE",
      "comment": "37 pages, 10 figures, 5 tables",
      "pdf_url": "http://arxiv.org/pdf/2404.17871v4",
      "published_date": "2024-04-27 11:42:13 UTC",
      "updated_date": "2025-02-05 02:29:52 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-18T04:08:13.198269"
    },
    {
      "arxiv_id": "2404.17865v1",
      "title": "Vision-based Discovery of Nonlinear Dynamics for 3D Moving Target",
      "title_zh": "翻译失败",
      "authors": [
        "Zitong Zhang",
        "Yang Liu",
        "Hao Sun"
      ],
      "abstract": "Data-driven discovery of governing equations has kindled significant\ninterests in many science and engineering areas. Existing studies primarily\nfocus on uncovering equations that govern nonlinear dynamics based on direct\nmeasurement of the system states (e.g., trajectories). Limited efforts have\nbeen placed on distilling governing laws of dynamics directly from videos for\nmoving targets in a 3D space. To this end, we propose a vision-based approach\nto automatically uncover governing equations of nonlinear dynamics for 3D\nmoving targets via raw videos recorded by a set of cameras. The approach is\ncomposed of three key blocks: (1) a target tracking module that extracts plane\npixel motions of the moving target in each video, (2) a Rodrigues' rotation\nformula-based coordinate transformation learning module that reconstructs the\n3D coordinates with respect to a predefined reference point, and (3) a\nspline-enhanced library-based sparse regressor that uncovers the underlying\ngoverning law of dynamics. This framework is capable of effectively handling\nthe challenges associated with measurement data, e.g., noise in the video,\nimprecise tracking of the target that causes data missing, etc. The efficacy of\nour method has been demonstrated through multiple sets of synthetic videos\nconsidering different nonlinear dynamics.",
      "tldr_zh": "本文提出了一种基于视觉的方法，用于从原始视频自动发现3D移动目标的nonlinear dynamics治理方程，填补了现有研究的空白。该方法包括三个关键模块：目标跟踪模块提取视频中的平面像素运动、基于Rodrigues' rotation formula的坐标变换学习模块重建3D坐标，以及spline-enhanced library-based sparse regressor揭示潜在动力学法则。该框架能有效处理视频噪声和数据缺失等挑战，并在多种合成视频实验中验证了其有效性。",
      "categories": [
        "cs.CV",
        "cs.AI",
        "nlin.CD"
      ],
      "primary_category": "cs.CV",
      "comment": "17 pages",
      "pdf_url": "http://arxiv.org/pdf/2404.17865v1",
      "published_date": "2024-04-27 11:13:55 UTC",
      "updated_date": "2024-04-27 11:13:55 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-18T04:08:26.062881"
    },
    {
      "arxiv_id": "2404.17854v1",
      "title": "GLIMS: Attention-Guided Lightweight Multi-Scale Hybrid Network for Volumetric Semantic Segmentation",
      "title_zh": "翻译失败",
      "authors": [
        "Ziya Ata Yazıcı",
        "İlkay Öksüz",
        "Hazım Kemal Ekenel"
      ],
      "abstract": "Convolutional Neural Networks (CNNs) have become widely adopted for medical\nimage segmentation tasks, demonstrating promising performance. However, the\ninherent inductive biases in convolutional architectures limit their ability to\nmodel long-range dependencies and spatial correlations. While recent\ntransformer-based architectures address these limitations by leveraging\nself-attention mechanisms to encode long-range dependencies and learn\nexpressive representations, they often struggle to extract low-level features\nand are highly dependent on data availability. This motivated us for the\ndevelopment of GLIMS, a data-efficient attention-guided hybrid volumetric\nsegmentation network. GLIMS utilizes Dilated Feature Aggregator Convolutional\nBlocks (DACB) to capture local-global feature correlations efficiently.\nFurthermore, the incorporated Swin Transformer-based bottleneck bridges the\nlocal and global features to improve the robustness of the model. Additionally,\nGLIMS employs an attention-guided segmentation approach through Channel and\nSpatial-Wise Attention Blocks (CSAB) to localize expressive features for\nfine-grained border segmentation. Quantitative and qualitative results on\nglioblastoma and multi-organ CT segmentation tasks demonstrate GLIMS'\neffectiveness in terms of complexity and accuracy. GLIMS demonstrated\noutstanding performance on BraTS2021 and BTCV datasets, surpassing the\nperformance of Swin UNETR. Notably, GLIMS achieved this high performance with a\nsignificantly reduced number of trainable parameters. Specifically, GLIMS has\n47.16M trainable parameters and 72.30G FLOPs, while Swin UNETR has 61.98M\ntrainable parameters and 394.84G FLOPs. The code is publicly available on\nhttps://github.com/yaziciz/GLIMS.",
      "tldr_zh": "这篇论文提出了 GLIMS，一种注意力引导的轻量级多尺度混合网络，用于体积语义分割，旨在克服 CNNs 在处理长距离依赖和空间相关性方面的局限，同时缓解 Transformer 模型对数据依赖和低级特征提取的不足。GLIMS 通过 Dilated Feature Aggregator Convolutional Blocks (DACB) 捕获局部-全局特征相关性、Swin Transformer-based 瓶颈桥接特征以提升鲁棒性，以及 Channel and Spatial-Wise Attention Blocks (CSAB) 实现精细边界定位。实验结果显示，GLIMS 在 BraTS2021 和 BTCV 数据集上超越了 Swin UNETR，在准确性方面表现出色，同时参数量仅为 47.16M 和 FLOPs 为 72.30G，大大降低了计算复杂度。",
      "categories": [
        "cs.CV",
        "cs.AI"
      ],
      "primary_category": "cs.CV",
      "comment": "The article was accepted for publication in the Image and Vision\n  Computing journal",
      "pdf_url": "http://arxiv.org/pdf/2404.17854v1",
      "published_date": "2024-04-27 10:18:55 UTC",
      "updated_date": "2024-04-27 10:18:55 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-18T04:08:39.974821"
    },
    {
      "arxiv_id": "2404.17842v1",
      "title": "Using LLMs in Software Requirements Specifications: An Empirical Evaluation",
      "title_zh": "在软件需求规范中使用大型语言模型：一项经验评估",
      "authors": [
        "Madhava Krishna",
        "Bhagesh Gaur",
        "Arsh Verma",
        "Pankaj Jalote"
      ],
      "abstract": "The creation of a Software Requirements Specification (SRS) document is\nimportant for any software development project. Given the recent prowess of\nLarge Language Models (LLMs) in answering natural language queries and\ngenerating sophisticated textual outputs, our study explores their capability\nto produce accurate, coherent, and structured drafts of these documents to\naccelerate the software development lifecycle. We assess the performance of\nGPT-4 and CodeLlama in drafting an SRS for a university club management system\nand compare it against human benchmarks using eight distinct criteria. Our\nresults suggest that LLMs can match the output quality of an entry-level\nsoftware engineer to generate an SRS, delivering complete and consistent\ndrafts. We also evaluate the capabilities of LLMs to identify and rectify\nproblems in a given requirements document. Our experiments indicate that GPT-4\nis capable of identifying issues and giving constructive feedback for\nrectifying them, while CodeLlama's results for validation were not as\nencouraging. We repeated the generation exercise for four distinct use cases to\nstudy the time saved by employing LLMs for SRS generation. The experiment\ndemonstrates that LLMs may facilitate a significant reduction in development\ntime for entry-level software engineers. Hence, we conclude that the LLMs can\nbe gainfully used by software engineers to increase productivity by saving time\nand effort in generating, validating and rectifying software requirements.",
      "tldr_zh": "本研究实证评估了大型语言模型（LLMs）如 GPT-4 和 CodeLlama 在生成软件需求规格（SRS）文档中的能力，通过与人类基准（如入门级软件工程师）比较八个标准。结果显示，LLMs 可以产生完整、一致的 SRS 草稿，其质量与人类输出相当，并在四个不同用例中显著减少开发时间。实验进一步表明，GPT-4 擅长识别和修复 SRS 中的问题，而 CodeLlama 的验证表现不佳。总之，该研究证明 LLMs 可帮助软件工程师提高生产力，节省时间和精力。",
      "categories": [
        "cs.SE",
        "cs.AI"
      ],
      "primary_category": "cs.SE",
      "comment": "Accepted to RE@Next! at the IEEE International Requirements\n  Engineering Conference 2024 at Reykjavik, Iceland",
      "pdf_url": "http://arxiv.org/pdf/2404.17842v1",
      "published_date": "2024-04-27 09:37:00 UTC",
      "updated_date": "2024-04-27 09:37:00 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-18T04:08:51.262555"
    },
    {
      "arxiv_id": "2404.17833v1",
      "title": "Testing and Understanding Erroneous Planning in LLM Agents through Synthesized User Inputs",
      "title_zh": "通过合成的用户输入测试和理解 LLM 代理中的错误规划",
      "authors": [
        "Zhenlan Ji",
        "Daoyuan Wu",
        "Pingchuan Ma",
        "Zongjie Li",
        "Shuai Wang"
      ],
      "abstract": "Agents based on large language models (LLMs) have demonstrated effectiveness\nin solving a wide range of tasks by integrating LLMs with key modules such as\nplanning, memory, and tool usage. Increasingly, customers are adopting LLM\nagents across a variety of commercial applications critical to reliability,\nincluding support for mental well-being, chemical synthesis, and software\ndevelopment. Nevertheless, our observations and daily use of LLM agents\nindicate that they are prone to making erroneous plans, especially when the\ntasks are complex and require long-term planning.\n  In this paper, we propose PDoctor, a novel and automated approach to testing\nLLM agents and understanding their erroneous planning. As the first work in\nthis direction, we formulate the detection of erroneous planning as a\nconstraint satisfiability problem: an LLM agent's plan is considered erroneous\nif its execution violates the constraints derived from the user inputs. To this\nend, PDoctor first defines a domain-specific language (DSL) for user queries\nand synthesizes varying inputs with the assistance of the Z3 constraint solver.\nThese synthesized inputs are natural language paragraphs that specify the\nrequirements for completing a series of tasks. Then, PDoctor derives\nconstraints from these requirements to form a testing oracle. We evaluate\nPDoctor with three mainstream agent frameworks and two powerful LLMs (GPT-3.5\nand GPT-4). The results show that PDoctor can effectively detect diverse errors\nin agent planning and provide insights and error characteristics that are\nvaluable to both agent developers and users. We conclude by discussing\npotential alternative designs and directions to extend PDoctor.",
      "tldr_zh": "这篇论文针对大语言模型 (LLM) 代理在复杂任务中易产生的错误规划问题，提出了一种自动化测试方法 PDoctor，以提升代理的可靠性和理解。PDoctor 将错误规划检测表述为约束满足问题 (constraint satisfiability problem)，通过定义领域特定语言 (DSL) 和利用 Z3 constraint solver 合成多样化的用户输入，并从中派生约束作为测试预言机。实验结果显示，在三个主流代理框架和 GPT-3.5/GPT-4 等 LLM 上，PDoctor 能有效检测各种规划错误，并提供宝贵的见解和错误特征，为代理开发者和用户带来实际价值。",
      "categories": [
        "cs.AI",
        "cs.PL"
      ],
      "primary_category": "cs.AI",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2404.17833v1",
      "published_date": "2024-04-27 08:56:45 UTC",
      "updated_date": "2024-04-27 08:56:45 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-18T04:09:03.742687"
    },
    {
      "arxiv_id": "2404.17820v1",
      "title": "Motion planning for off-road autonomous driving based on human-like cognition and weight adaptation",
      "title_zh": "基于仿人类认知和权重适应的越野自主驾驶运动规划",
      "authors": [
        "Yuchun Wang",
        "Cheng Gong",
        "Jianwei Gong",
        "Peng Jia"
      ],
      "abstract": "Driving in an off-road environment is challenging for autonomous vehicles due\nto the complex and varied terrain. To ensure stable and efficient travel, the\nvehicle requires consideration and balancing of environmental factors, such as\nundulations, roughness, and obstacles, to generate optimal trajectories that\ncan adapt to changing scenarios. However, traditional motion planners often\nutilize a fixed cost function for trajectory optimization, making it difficult\nto adapt to different driving strategies in challenging irregular terrains and\nuncommon scenarios. To address these issues, we propose an adaptive motion\nplanner based on human-like cognition and cost evaluation for off-road driving.\nFirst, we construct a multi-layer map describing different features of off-road\nterrains, including terrain elevation, roughness, obstacle, and artificial\npotential field map. Subsequently, we employ a CNN-LSTM network to learn the\ntrajectories planned by human drivers in various off-road scenarios. Then,\nbased on human-like generated trajectories in different environments, we design\na primitive-based trajectory planner that aims to mimic human trajectories and\ncost weight selection, generating trajectories that are consistent with the\ndynamics of off-road vehicles. Finally, we compute optimal cost weights and\nselect and extend behavioral primitives to generate highly adaptive, stable,\nand efficient trajectories.\n  We validate the effectiveness of the proposed method through experiments in a\ndesert off-road environment with complex terrain and varying road conditions.\nThe experimental results show that the proposed human-like motion planner has\nexcellent adaptability to different off-road conditions. It shows real-time\noperation, greater stability, and more human-like planning ability in diverse\nand challenging scenarios.",
      "tldr_zh": "该研究针对越野自动驾驶的运动规划问题，提出了一种基于人类认知和权重适应的自适应规划器，以应对复杂地形（如起伏、粗糙度和障碍物）带来的挑战。方法包括构建多层地图（包含地形高度、粗糙度、障碍物和人工势场地图）、使用 CNN-LSTM 网络学习人类驾驶轨迹，并设计基于原语的轨迹规划器来模仿人类行为和动态成本权重选择，从而生成高效适应的轨迹。实验在沙漠越野环境中验证了该规划器的有效性，展示了其优秀的实时性、稳定性和人类-like 规划能力，比传统方法更适应多样化场景。",
      "categories": [
        "cs.RO",
        "cs.AI",
        "cs.LG"
      ],
      "primary_category": "cs.RO",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2404.17820v1",
      "published_date": "2024-04-27 08:00:35 UTC",
      "updated_date": "2024-04-27 08:00:35 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-18T04:09:13.894032"
    },
    {
      "arxiv_id": "2405.09556v2",
      "title": "Co-learning-aided Multi-modal-deep-learning Framework of Passive DOA Estimators for a Heterogeneous Hybrid Massive MIMO Receiver",
      "title_zh": "翻译失败",
      "authors": [
        "Jiatong Bai",
        "Feng Shu",
        "Qinghe Zheng",
        "Bo Xu",
        "Baihua Shi",
        "Yiwen Chen",
        "Weibin Zhang",
        "Xianpeng Wang"
      ],
      "abstract": "Due to its excellent performance in rate and resolution, fully-digital (FD)\nmassive multiple-input multiple-output (MIMO) antenna arrays has been widely\napplied in data transmission and direction of arrival (DOA) measurements, etc.\nBut it confronts with two main challenges: high computational complexity and\ncircuit cost. The two problems may be addressed well by hybrid analog-digital\n(HAD) structure. But there exists the problem of phase ambiguity for HAD, which\nleads to its low-efficiency or high-latency. Does exist there such a MIMO\nstructure of owning low-cost, low-complexity and high time efficiency at the\nsame time. To satisfy the three properties, a novel heterogeneous hybrid MIMO\nreceiver structure of integrating FD and heterogeneous HAD ($\\rm{H}^2$AD-FD) is\nproposed and corresponding multi-modal (MD)-learning framework is developed.\nThe framework includes three major stages: 1) generate the candidate sets via\nroot multiple signal classification (Root-MUSIC) or deep learning (DL); 2)\ninfer the class of true solutions from candidate sets using machine learning\n(ML) methods; 3) fuse the two-part true solutions to achieve a better DOA\nestimation. The above process form two methods named MD-Root-MUSIC and MDDL. To\nimprove DOA estimation accuracy and reduce the clustering complexity, a\nco-learning-aided MD framework is proposed to form two enhanced methods named\nCoMDDL and CoMD-RootMUSIC. Moreover, the Cramer-Rao lower bound (CRLB) for the\nproposed $\\rm{H}^2$AD-FD structure is also derived. Experimental results\ndemonstrate that our proposed four methods could approach the CRLB for\nsignal-to-noise ratio (SNR) > 0 dB and the proposed CoMDDL and MDDL perform\nbetter than CoMD-RootMUSIC and MD-RootMUSIC, particularly in the extremely low\nSNR region.",
      "tldr_zh": "本研究针对全数字（FD）Massive MIMO 阵列在数据传输和方向到达（DOA）估计中面临的计算复杂性和电路成本高问题，提出了一种新型异构混合MIMO接收器结构（H²AD-FD），结合FD和异构混合模拟数字（HAD）技术，以实现低成本、低复杂性和高时间效率。\n\n该框架开发了多模态（MD）学习方法，包括生成候选集（使用Root-MUSIC或深度学习DL）、利用机器学习（ML）推断真实解以及融合解，形成MD-Root-MUSIC和MD-DL两种方法；进一步引入co-learning辅助机制，增强为CoMDDL和CoMD-RootMUSIC，以提高DOA估计准确性和降低聚类复杂性。\n\n实验结果显示，四种方法在信噪比（SNR）> 0 dB时接近Cramer-Rao下界（CRLB），且CoMDDL和MDDL在极低SNR区域表现出色，优于CoMD-RootMUSIC和MD-RootMUSIC。",
      "categories": [
        "eess.SP",
        "cs.AI",
        "cs.IT",
        "math.IT"
      ],
      "primary_category": "eess.SP",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2405.09556v2",
      "published_date": "2024-04-27 07:34:36 UTC",
      "updated_date": "2024-06-12 08:16:01 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-18T04:09:27.279776"
    },
    {
      "arxiv_id": "2404.18947v3",
      "title": "Multimodal Fusion on Low-quality Data: A Comprehensive Survey",
      "title_zh": "低质量数据上的多模态融合：一份全面综述",
      "authors": [
        "Qingyang Zhang",
        "Yake Wei",
        "Zongbo Han",
        "Huazhu Fu",
        "Xi Peng",
        "Cheng Deng",
        "Qinghua Hu",
        "Cai Xu",
        "Jie Wen",
        "Di Hu",
        "Changqing Zhang"
      ],
      "abstract": "Multimodal fusion focuses on integrating information from multiple modalities\nwith the goal of more accurate prediction, which has achieved remarkable\nprogress in a wide range of scenarios, including autonomous driving and medical\ndiagnosis. However, the reliability of multimodal fusion remains largely\nunexplored especially under low-quality data settings. This paper surveys the\ncommon challenges and recent advances of multimodal fusion in the wild and\npresents them in a comprehensive taxonomy. From a data-centric view, we\nidentify four main challenges that are faced by multimodal fusion on\nlow-quality data, namely (1) noisy multimodal data that are contaminated with\nheterogeneous noises, (2) incomplete multimodal data that some modalities are\nmissing, (3) imbalanced multimodal data that the qualities or properties of\ndifferent modalities are significantly different and (4) quality-varying\nmultimodal data that the quality of each modality dynamically changes with\nrespect to different samples. This new taxonomy will enable researchers to\nunderstand the state of the field and identify several potential directions. We\nalso provide discussion for the open problems in this field together with\ninteresting future research directions.",
      "tldr_zh": "这篇论文对低质量数据下的多模态融合(Multimodal Fusion)进行了全面调查，探讨了其在实际场景中的挑战和进展。作者从数据-centric 的视角识别了四个主要挑战：(1) 带有异质噪声的嘈杂多模态数据(noisy multimodal data)，(2) 某些模态缺失的不完整多模态数据(incomplete multimodal data)，(3) 不同模态质量或属性显著不同的不平衡多模态数据(imbalanced multimodal data)，以及(4) 每个模态质量随样本变化的质量可变多模态数据(quality-varying multimodal data)。论文通过新的分类法(taxonomy)总结了现有研究，并讨论了开放问题和潜在的未来研究方向，以推动该领域的可靠性提升。",
      "categories": [
        "cs.LG",
        "cs.AI"
      ],
      "primary_category": "cs.LG",
      "comment": "Feel free to comment on our manuscript: qingyangzhang@tju$.$edu$.$cn",
      "pdf_url": "http://arxiv.org/pdf/2404.18947v3",
      "published_date": "2024-04-27 07:22:28 UTC",
      "updated_date": "2024-11-01 13:53:44 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-18T04:09:40.287117"
    },
    {
      "arxiv_id": "2404.17809v1",
      "title": "Recall, Retrieve and Reason: Towards Better In-Context Relation Extraction",
      "title_zh": "翻译失败",
      "authors": [
        "Guozheng Li",
        "Peng Wang",
        "Wenjun Ke",
        "Yikai Guo",
        "Ke Ji",
        "Ziyu Shang",
        "Jiajun Liu",
        "Zijie Xu"
      ],
      "abstract": "Relation extraction (RE) aims to identify relations between entities\nmentioned in texts. Although large language models (LLMs) have demonstrated\nimpressive in-context learning (ICL) abilities in various tasks, they still\nsuffer from poor performances compared to most supervised fine-tuned RE\nmethods. Utilizing ICL for RE with LLMs encounters two challenges: (1)\nretrieving good demonstrations from training examples, and (2) enabling LLMs\nexhibit strong ICL abilities in RE. On the one hand, retrieving good\ndemonstrations is a non-trivial process in RE, which easily results in low\nrelevance regarding entities and relations. On the other hand, ICL with an LLM\nachieves poor performance in RE while RE is different from language modeling in\nnature or the LLM is not large enough. In this work, we propose a novel\nrecall-retrieve-reason RE framework that synergizes LLMs with retrieval corpora\n(training examples) to enable relevant retrieving and reliable in-context\nreasoning. Specifically, we distill the consistently ontological knowledge from\ntraining datasets to let LLMs generate relevant entity pairs grounded by\nretrieval corpora as valid queries. These entity pairs are then used to\nretrieve relevant training examples from the retrieval corpora as\ndemonstrations for LLMs to conduct better ICL via instruction tuning. Extensive\nexperiments on different LLMs and RE datasets demonstrate that our method\ngenerates relevant and valid entity pairs and boosts ICL abilities of LLMs,\nachieving competitive or new state-of-the-art performance on sentence-level RE\ncompared to previous supervised fine-tuning methods and ICL-based methods.",
      "tldr_zh": "本研究针对关系抽取(RE)任务中，大语言模型(LLMs)的In-Context Learning (ICL)性能较差的问题，提出了一种新型recall-retrieve-reason框架，以提升LLMs的检索和推理能力。框架首先从训练数据集提炼本体知识，让LLMs生成相关实体对作为查询，然后使用这些实体对从检索语料中获取相关训练示例作为演示，并通过指令微调强化ICL。实验在不同LLMs和RE数据集上证明，该方法能生成有效实体对，并实现与监督微调方法相当或优于现有ICL-based方法的性能。",
      "categories": [
        "cs.CL",
        "cs.AI"
      ],
      "primary_category": "cs.CL",
      "comment": "IJCAI 2024",
      "pdf_url": "http://arxiv.org/pdf/2404.17809v1",
      "published_date": "2024-04-27 07:12:52 UTC",
      "updated_date": "2024-04-27 07:12:52 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-18T04:09:53.762816"
    },
    {
      "arxiv_id": "2404.17807v1",
      "title": "Meta In-Context Learning Makes Large Language Models Better Zero and Few-Shot Relation Extractors",
      "title_zh": "翻译失败",
      "authors": [
        "Guozheng Li",
        "Peng Wang",
        "Jiajun Liu",
        "Yikai Guo",
        "Ke Ji",
        "Ziyu Shang",
        "Zijie Xu"
      ],
      "abstract": "Relation extraction (RE) is an important task that aims to identify the\nrelationships between entities in texts. While large language models (LLMs)\nhave revealed remarkable in-context learning (ICL) capability for general zero\nand few-shot learning, recent studies indicate that current LLMs still struggle\nwith zero and few-shot RE. Previous studies are mainly dedicated to design\nprompt formats and select good examples for improving ICL-based RE. Although\nboth factors are vital for ICL, if one can fundamentally boost the ICL\ncapability of LLMs in RE, the zero and few-shot RE performance via ICL would be\nsignificantly improved. To this end, we introduce \\textsc{Micre} (\\textbf{M}eta\n\\textbf{I}n-\\textbf{C}ontext learning of LLMs for \\textbf{R}elation\n\\textbf{E}xtraction), a new meta-training framework for zero and few-shot RE\nwhere an LLM is tuned to do ICL on a diverse collection of RE datasets (i.e.,\nlearning to learn in context for RE). Through meta-training, the model becomes\nmore effectively to learn a new RE task in context by conditioning on a few\ntraining examples with no parameter updates or task-specific templates at\ninference time, enabling better zero and few-shot task generalization. We\nexperiment \\textsc{Micre} on various LLMs with different model scales and 12\npublic RE datasets, and then evaluate it on unseen RE benchmarks under zero and\nfew-shot settings. \\textsc{Micre} delivers comparable or superior performance\ncompared to a range of baselines including supervised fine-tuning and typical\nin-context learning methods. We find that the gains are particular significant\nfor larger model scales, and using a diverse set of the meta-training RE\ndatasets is key to improvements. Empirically, we show that \\textsc{Micre} can\ntransfer the relation semantic knowledge via relation label name during\ninference on target RE datasets.",
      "tldr_zh": "本文提出 \\textsc{Micre} 框架，通过元训练 (meta-training) 增强大语言模型 (LLMs) 在关系抽取 (RE) 任务上的 in-context learning (ICL) 能力，旨在解决 LLMs 在零样本和少样本 RE 中的表现不足问题。 该框架在多样化的 RE 数据集上训练模型，使其能够在推理时无需参数更新或任务特定模板，即通过少量示例实现更好的任务泛化。 实验结果显示，\\textsc{Micre} 在 12 个公共数据集上优于监督微调和典型 ICL 方法，尤其在大模型规模下表现显著，并通过关系标签名称转移语义知识，提升零样本和少样本 RE 的准确性。",
      "categories": [
        "cs.CL",
        "cs.AI"
      ],
      "primary_category": "cs.CL",
      "comment": "IJCAI 2024",
      "pdf_url": "http://arxiv.org/pdf/2404.17807v1",
      "published_date": "2024-04-27 07:06:39 UTC",
      "updated_date": "2024-04-27 07:06:39 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-18T04:10:05.218017"
    },
    {
      "arxiv_id": "2404.17802v1",
      "title": "Empirical Analysis of Dialogue Relation Extraction with Large Language Models",
      "title_zh": "大型语言模型在对话关系抽取中的实证分析",
      "authors": [
        "Guozheng Li",
        "Zijie Xu",
        "Ziyu Shang",
        "Jiajun Liu",
        "Ke Ji",
        "Yikai Guo"
      ],
      "abstract": "Dialogue relation extraction (DRE) aims to extract relations between two\narguments within a dialogue, which is more challenging than standard RE due to\nthe higher person pronoun frequency and lower information density in dialogues.\nHowever, existing DRE methods still suffer from two serious issues: (1) hard to\ncapture long and sparse multi-turn information, and (2) struggle to extract\ngolden relations based on partial dialogues, which motivates us to discover\nmore effective methods that can alleviate the above issues. We notice that the\nrise of large language models (LLMs) has sparked considerable interest in\nevaluating their performance across diverse tasks. To this end, we initially\ninvestigate the capabilities of different LLMs in DRE, considering both\nproprietary models and open-source models. Interestingly, we discover that LLMs\nsignificantly alleviate two issues in existing DRE methods. Generally, we have\nfollowing findings: (1) scaling up model size substantially boosts the overall\nDRE performance and achieves exceptional results, tackling the difficulty of\ncapturing long and sparse multi-turn information; (2) LLMs encounter with much\nsmaller performance drop from entire dialogue setting to partial dialogue\nsetting compared to existing methods; (3) LLMs deliver competitive or superior\nperformances under both full-shot and few-shot settings compared to current\nstate-of-the-art; (4) LLMs show modest performances on inverse relations but\nmuch stronger improvements on general relations, and they can handle dialogues\nof various lengths especially for longer sequences.",
      "tldr_zh": "这篇论文对大型语言模型（LLMs）在对话关系提取（DRE）中的性能进行了实证分析，旨在解决DRE面临的挑战，如捕捉长而稀疏的多轮信息和基于部分对话提取关系的问题。研究比较了专有和开源LLMs，发现模型规模的增大显著提升了整体DRE性能，尤其在处理多轮信息方面。LLMs在从完整对话到部分对话的场景中，性能下降更小，并在全样本和少样本设置下表现出色或优于现有最先进方法。此外，LLMs在一般关系上改善明显，并能有效处理各种长度对话，特别是较长序列。",
      "categories": [
        "cs.CL",
        "cs.AI"
      ],
      "primary_category": "cs.CL",
      "comment": "IJCAI 2024",
      "pdf_url": "http://arxiv.org/pdf/2404.17802v1",
      "published_date": "2024-04-27 06:55:41 UTC",
      "updated_date": "2024-04-27 06:55:41 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-18T04:10:16.560840"
    },
    {
      "arxiv_id": "2404.17799v1",
      "title": "Personalized Federated Learning via Sequential Layer Expansion in Representation Learning",
      "title_zh": "翻译失败",
      "authors": [
        "Jaewon Jang",
        "Bonjun Choi"
      ],
      "abstract": "Federated learning ensures the privacy of clients by conducting distributed\ntraining on individual client devices and sharing only the model weights with a\ncentral server. However, in real-world scenarios, the heterogeneity of data\namong clients necessitates appropriate personalization methods. In this paper,\nwe aim to address this heterogeneity using a form of parameter decoupling known\nas representation learning. Representation learning divides deep learning\nmodels into 'base' and 'head' components. The base component, capturing common\nfeatures across all clients, is shared with the server, while the head\ncomponent, capturing unique features specific to individual clients, remains\nlocal. We propose a new representation learning-based approach that suggests\ndecoupling the entire deep learning model into more densely divided parts with\nthe application of suitable scheduling methods, which can benefit not only data\nheterogeneity but also class heterogeneity. In this paper, we compare and\nanalyze two layer scheduling approaches, namely forward (\\textit{Vanilla}) and\nbackward (\\textit{Anti}), in the context of data and class heterogeneity among\nclients. Our experimental results show that the proposed algorithm, when\ncompared to existing personalized federated learning algorithms, achieves\nincreased accuracy, especially under challenging conditions, while reducing\ncomputation costs.",
      "tldr_zh": "这篇论文针对联邦学习中客户端数据异质性的问题，提出了一种基于Representation Learning的个性化方法，通过Sequential Layer Expansion将深度学习模型解耦成更多密集部分，并应用forward (Vanilla) 和 backward (Anti) 两种层调度策略，以处理数据和类别异质性。相比传统方法，该方法允许base组件共享共同特征，而head组件保留本地独特特征，从而提升模型的适应性。实验结果表明，该算法在各种异质性条件下实现了更高的准确率，同时降低了计算成本。",
      "categories": [
        "cs.LG",
        "cs.AI"
      ],
      "primary_category": "cs.LG",
      "comment": "12 pages, 7 figure",
      "pdf_url": "http://arxiv.org/pdf/2404.17799v1",
      "published_date": "2024-04-27 06:37:19 UTC",
      "updated_date": "2024-04-27 06:37:19 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-18T04:10:28.401005"
    },
    {
      "arxiv_id": "2404.17794v1",
      "title": "GPT for Games: A Scoping Review (2020-2023)",
      "title_zh": "翻译失败",
      "authors": [
        "Daijin Yang",
        "Erica Kleinman",
        "Casper Harteveld"
      ],
      "abstract": "This paper introduces a scoping review of 55 articles to explore GPT's\npotential for games, offering researchers a comprehensive understanding of the\ncurrent applications and identifying both emerging trends and unexplored areas.\nWe identify five key applications of GPT in current game research: procedural\ncontent generation, mixed-initiative game design, mixed-initiative gameplay,\nplaying games, and game user research. Drawing from insights in each of these\napplication areas, we propose directions for future research in each one. This\nreview aims to lay the groundwork by illustrating the state of the art for\ninnovative GPT applications in games, promising to enrich game development and\nenhance player experiences with cutting-edge AI innovations.",
      "tldr_zh": "这篇论文对2020-2023年间55篇文献进行了scoping review，旨在探讨GPT在游戏领域的潜力，并提供当前应用的全景理解。研究识别了五个关键应用：procedural content generation、mixed-initiative game design、mixed-initiative gameplay、playing games和game user research。基于这些领域的洞见，论文提出了未来研究方向，以推动GPT在游戏开发中的创新应用，并提升玩家体验。",
      "categories": [
        "cs.HC",
        "cs.AI"
      ],
      "primary_category": "cs.HC",
      "comment": "To be published in IEEE Conference on Games 2024",
      "pdf_url": "http://arxiv.org/pdf/2404.17794v1",
      "published_date": "2024-04-27 06:26:18 UTC",
      "updated_date": "2024-04-27 06:26:18 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-18T04:10:39.713074"
    },
    {
      "arxiv_id": "2404.17790v1",
      "title": "Continual Pre-Training for Cross-Lingual LLM Adaptation: Enhancing Japanese Language Capabilities",
      "title_zh": "翻译失败",
      "authors": [
        "Kazuki Fujii",
        "Taishi Nakamura",
        "Mengsay Loem",
        "Hiroki Iida",
        "Masanari Ohi",
        "Kakeru Hattori",
        "Hirai Shota",
        "Sakae Mizuki",
        "Rio Yokota",
        "Naoaki Okazaki"
      ],
      "abstract": "Cross-lingual continual pre-training of large language models (LLMs)\ninitially trained on English corpus allows us to leverage the vast amount of\nEnglish language resources and reduce the pre-training cost. In this study, we\nconstructed Swallow, an LLM with enhanced Japanese capability, by extending the\nvocabulary of Llama 2 to include Japanese characters and conducting continual\npre-training on a large Japanese web corpus. Experimental results confirmed\nthat the performance on Japanese tasks drastically improved through continual\npre-training, and the performance monotonically increased with the amount of\ntraining data up to 100B tokens. Consequently, Swallow achieved superior\nperformance compared to other LLMs that were trained from scratch in English\nand Japanese. An analysis of the effects of continual pre-training revealed\nthat it was particularly effective for Japanese question answering tasks.\nFurthermore, to elucidate effective methodologies for cross-lingual continual\npre-training from English to Japanese, we investigated the impact of vocabulary\nexpansion and the effectiveness of incorporating parallel corpora. The results\nshowed that the efficiency gained through vocabulary expansion had no negative\nimpact on performance, except for the summarization task, and that the combined\nuse of parallel corpora enhanced translation ability.",
      "tldr_zh": "这篇论文探讨了通过跨语言持续预-training（Continual Pre-Training）来增强大型语言模型（LLMs）的日语能力，具体构建了Swallow模型，该模型基于Llama 2扩展词汇表并在日语网络语料上进行预训练，以利用英语资源降低成本。实验结果显示，持续预训练显著提高了日语任务的性能，尤其是问答任务，且随着训练数据量增加至100B tokens，模型表现持续提升，与从零训练的模型相比更具优势。进一步分析表明，词汇扩展（Vocabulary Expansion）提高了效率并无负面影响，而结合并行语料（Parallel Corpora）增强了翻译能力。",
      "categories": [
        "cs.CL",
        "cs.AI"
      ],
      "primary_category": "cs.CL",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2404.17790v1",
      "published_date": "2024-04-27 06:07:55 UTC",
      "updated_date": "2024-04-27 06:07:55 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-18T04:10:51.999901"
    },
    {
      "arxiv_id": "2405.09545v1",
      "title": "Intrinsic Voltage Offsets in Memcapacitive Bio-Membranes Enable High-Performance Physical Reservoir Computing",
      "title_zh": "翻译失败",
      "authors": [
        "Ahmed S. Mohamed",
        "Anurag Dhungel",
        "Md Sakib Hasan",
        "Joseph S. Najem"
      ],
      "abstract": "Reservoir computing is a brain-inspired machine learning framework for\nprocessing temporal data by mapping inputs into high-dimensional spaces.\nPhysical reservoir computers (PRCs) leverage native fading memory and\nnonlinearity in physical substrates, including atomic switches, photonics,\nvolatile memristors, and, recently, memcapacitors, to achieve efficient\nhigh-dimensional mapping. Traditional PRCs often consist of homogeneous device\narrays, which rely on input encoding methods and large stochastic\ndevice-to-device variations for increased nonlinearity and high-dimensional\nmapping. These approaches incur high pre-processing costs and restrict\nreal-time deployment. Here, we introduce a novel heterogeneous\nmemcapacitor-based PRC that exploits internal voltage offsets to enable both\nmonotonic and non-monotonic input-state correlations crucial for efficient\nhigh-dimensional transformations. We demonstrate our approach's efficacy by\npredicting a second-order nonlinear dynamical system with an extremely low\nprediction error (0.00018). Additionally, we predict a chaotic H\\'enon map,\nachieving a low normalized root mean square error (0.080). Unlike previous\nPRCs, such errors are achieved without input encoding methods, underscoring the\npower of distinct input-state correlations. Most importantly, we generalize our\napproach to other neuromorphic devices that lack inherent voltage offsets using\nexternally applied offsets to realize various input-state correlations. Our\napproach and unprecedented performance are a major milestone towards\nhigh-performance full in-materia PRCs.",
      "tldr_zh": "该研究提出了一种新型异质 memcapacitor-based Physical Reservoir Computing (PRCs)，利用 memcapacitive bio-membranes 的内部电压偏移来实现单调和非单调的输入-状态相关性，从而高效地处理时间数据并进行高维映射。不同于传统 PRCs 的同质设备阵列和依赖输入编码的方法，该框架无需预处理即可显著提升性能，在预测二阶非线性动态系统时达到极低预测误差 (0.00018)，并在混沌 Hénon map 上实现归一化均方根误差 (0.080)。此外，该方法可推广到其他缺乏固有电压偏移的神经形态设备，通过外部偏移生成多样输入-状态相关性，推动高性能全 in-materia PRCs 的发展。",
      "categories": [
        "cs.ET",
        "cs.AI",
        "cs.LG"
      ],
      "primary_category": "cs.ET",
      "comment": "Supplementary Information is included under the main text",
      "pdf_url": "http://arxiv.org/pdf/2405.09545v1",
      "published_date": "2024-04-27 05:47:38 UTC",
      "updated_date": "2024-04-27 05:47:38 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-18T04:11:05.276982"
    },
    {
      "arxiv_id": "2404.17780v1",
      "title": "Verco: Learning Coordinated Verbal Communication for Multi-agent Reinforcement Learning",
      "title_zh": "Verco：用于多智能体强化学习的协调口头沟通学习",
      "authors": [
        "Dapeng Li",
        "Hang Dong",
        "Lu Wang",
        "Bo Qiao",
        "Si Qin",
        "Qingwei Lin",
        "Dongmei Zhang",
        "Qi Zhang",
        "Zhiwei Xu",
        "Bin Zhang",
        "Guoliang Fan"
      ],
      "abstract": "In recent years, multi-agent reinforcement learning algorithms have made\nsignificant advancements in diverse gaming environments, leading to increased\ninterest in the broader application of such techniques. To address the\nprevalent challenge of partial observability, communication-based algorithms\nhave improved cooperative performance through the sharing of numerical\nembedding between agents. However, the understanding of the formation of\ncollaborative mechanisms is still very limited, making designing a\nhuman-understandable communication mechanism a valuable problem to address. In\nthis paper, we propose a novel multi-agent reinforcement learning algorithm\nthat embeds large language models into agents, endowing them with the ability\nto generate human-understandable verbal communication. The entire framework has\na message module and an action module. The message module is responsible for\ngenerating and sending verbal messages to other agents, effectively enhancing\ninformation sharing among agents. To further enhance the message module, we\nemploy a teacher model to generate message labels from the global view and\nupdate the student model through Supervised Fine-Tuning (SFT). The action\nmodule receives messages from other agents and selects actions based on current\nlocal observations and received messages. Experiments conducted on the\nOvercooked game demonstrate our method significantly enhances the learning\nefficiency and performance of existing methods, while also providing an\ninterpretable tool for humans to understand the process of multi-agent\ncooperation.",
      "tldr_zh": "这篇论文提出了 Verco，一种新型多智能体强化学习算法，通过嵌入大型语言模型 (LLMs) 来实现代理间的协调口头通信，解决部分可观察性带来的合作挑战。框架包括消息模块（负责生成和发送人类可理解的消息，并利用教师模型从全局视角生成标签，通过 Supervised Fine-Tuning (SFT) 优化学生模型）和行动模块（基于本地观察和接收消息选择行动）。实验在 Overcooked 游戏中表明，Verco 显著提升了现有方法的学习效率和性能，同时提供了一个可解释的工具，帮助人类理解多智能体合作过程。",
      "categories": [
        "cs.MA",
        "cs.AI"
      ],
      "primary_category": "cs.MA",
      "comment": "12 pages, 6 figures",
      "pdf_url": "http://arxiv.org/pdf/2404.17780v1",
      "published_date": "2024-04-27 05:10:33 UTC",
      "updated_date": "2024-04-27 05:10:33 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-18T04:11:16.876951"
    },
    {
      "arxiv_id": "2404.17778v1",
      "title": "MRScore: Evaluating Radiology Report Generation with LLM-based Reward System",
      "title_zh": "翻译失败",
      "authors": [
        "Yunyi Liu",
        "Zhanyu Wang",
        "Yingshu Li",
        "Xinyu Liang",
        "Lingqiao Liu",
        "Lei Wang",
        "Luping Zhou"
      ],
      "abstract": "In recent years, automated radiology report generation has experienced\nsignificant growth. This paper introduces MRScore, an automatic evaluation\nmetric tailored for radiology report generation by leveraging Large Language\nModels (LLMs). Conventional NLG (natural language generation) metrics like BLEU\nare inadequate for accurately assessing the generated radiology reports, as\nsystematically demonstrated by our observations within this paper. To address\nthis challenge, we collaborated with radiologists to develop a framework that\nguides LLMs for radiology report evaluation, ensuring alignment with human\nanalysis. Our framework includes two key components: i) utilizing GPT to\ngenerate large amounts of training data, i.e., reports with different\nqualities, and ii) pairing GPT-generated reports as accepted and rejected\nsamples and training LLMs to produce MRScore as the model reward. Our\nexperiments demonstrate MRScore's higher correlation with human judgments and\nsuperior performance in model selection compared to traditional metrics. Our\ncode and datasets will be available on GitHub.",
      "tldr_zh": "本论文提出 MRScore，一种基于大型语言模型 (LLMs) 的自动评估指标，专门用于评估放射学报告生成，以解决传统 NLG 指标如 BLEU 在准确性上的不足。作者与放射科医生合作，开发了一个框架，包括使用 GPT 生成不同质量的报告作为训练数据，并将这些报告配对训练 LLMs 以输出 MRScore 作为模型奖励。实验结果表明，MRScore 与人类判断的相关性更高，并在模型选择方面表现出色。代码和数据集将公开在 GitHub 上。",
      "categories": [
        "cs.CL",
        "cs.AI"
      ],
      "primary_category": "cs.CL",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2404.17778v1",
      "published_date": "2024-04-27 04:42:45 UTC",
      "updated_date": "2024-04-27 04:42:45 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-18T04:11:28.801875"
    },
    {
      "arxiv_id": "2405.00728v1",
      "title": "Evaluating the Application of ChatGPT in Outpatient Triage Guidance: A Comparative Study",
      "title_zh": "翻译失败",
      "authors": [
        "Dou Liu",
        "Ying Han",
        "Xiandi Wang",
        "Xiaomei Tan",
        "Di Liu",
        "Guangwu Qian",
        "Kang Li",
        "Dan Pu",
        "Rong Yin"
      ],
      "abstract": "The integration of Artificial Intelligence (AI) in healthcare presents a\ntransformative potential for enhancing operational efficiency and health\noutcomes. Large Language Models (LLMs), such as ChatGPT, have shown their\ncapabilities in supporting medical decision-making. Embedding LLMs in medical\nsystems is becoming a promising trend in healthcare development. The potential\nof ChatGPT to address the triage problem in emergency departments has been\nexamined, while few studies have explored its application in outpatient\ndepartments. With a focus on streamlining workflows and enhancing efficiency\nfor outpatient triage, this study specifically aims to evaluate the consistency\nof responses provided by ChatGPT in outpatient guidance, including both\nwithin-version response analysis and between-version comparisons. For\nwithin-version, the results indicate that the internal response consistency for\nChatGPT-4.0 is significantly higher than ChatGPT-3.5 (p=0.03) and both have a\nmoderate consistency (71.2% for 4.0 and 59.6% for 3.5) in their top\nrecommendation. However, the between-version consistency is relatively low\n(mean consistency score=1.43/3, median=1), indicating few recommendations match\nbetween the two versions. Also, only 50% top recommendations match perfectly in\nthe comparisons. Interestingly, ChatGPT-3.5 responses are more likely to be\ncomplete than those from ChatGPT-4.0 (p=0.02), suggesting possible differences\nin information processing and response generation between the two versions. The\nfindings offer insights into AI-assisted outpatient operations, while also\nfacilitating the exploration of potentials and limitations of LLMs in\nhealthcare utilization. Future research may focus on carefully optimizing LLMs\nand AI integration in healthcare systems based on ergonomic and human factors\nprinciples, precisely aligning with the specific needs of effective outpatient\ntriage.",
      "tldr_zh": "本研究评估了 ChatGPT 在门诊分诊指导中的应用，通过比较 ChatGPT-3.5 和 ChatGPT-4.0 的响应一致性，包括内部版本分析和跨版本比较。结果显示，ChatGPT-4.0 的内部响应一致性显著高于 ChatGPT-3.5（p=0.03），两者的一致性分别为 71.2% 和 59.6%。然而，跨版本一致性较低（平均分数 1.43/3，中位数 1），且只有 50% 的顶级推荐完全匹配，同时 ChatGPT-3.5 的响应更完整（p=0.02）。该研究为 LLMs 在医疗中的应用提供了重要见解，并建议未来基于人体工程学原则优化 AI 系统以提升门诊分诊效率。",
      "categories": [
        "cs.CL",
        "cs.AI",
        "cs.HC"
      ],
      "primary_category": "cs.CL",
      "comment": "8 pages, 1 figure, conference(International Ergonomics Association)",
      "pdf_url": "http://arxiv.org/pdf/2405.00728v1",
      "published_date": "2024-04-27 04:12:02 UTC",
      "updated_date": "2024-04-27 04:12:02 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-18T04:11:42.638786"
    },
    {
      "arxiv_id": "2404.17768v2",
      "title": "Changing the Training Data Distribution to Reduce Simplicity Bias Improves In-distribution Generalization",
      "title_zh": "翻译失败",
      "authors": [
        "Dang Nguyen",
        "Paymon Haddad",
        "Eric Gan",
        "Baharan Mirzasoleiman"
      ],
      "abstract": "Can we modify the training data distribution to encourage the underlying\noptimization method toward finding solutions with superior generalization\nperformance on in-distribution data? In this work, we approach this question\nfor the first time by comparing the inductive bias of gradient descent (GD)\nwith that of sharpness-aware minimization (SAM). By studying a two-layer CNN,\nwe rigorously prove that SAM learns different features more uniformly,\nparticularly in early epochs. That is, SAM is less susceptible to simplicity\nbias compared to GD. We also show that examples containing features that are\nlearned early are separable from the rest based on the model's output. Based on\nthis observation, we propose a method that (i) clusters examples based on the\nnetwork output early in training, (ii) identifies a cluster of examples with\nsimilar network output, and (iii) upsamples the rest of examples only once to\nalleviate the simplicity bias. We show empirically that USEFUL effectively\nimproves the generalization performance on the original data distribution when\ntraining with various gradient methods, including (S)GD and SAM. Notably, we\ndemonstrate that our method can be combined with SAM variants and existing data\naugmentation strategies to achieve, to the best of our knowledge,\nstate-of-the-art performance for training ResNet18 on CIFAR10, STL10, CINIC10,\nTiny-ImageNet; ResNet34 on CIFAR100; and VGG19 and DenseNet121 on CIFAR10.",
      "tldr_zh": "该研究首次比较了梯度下降(GD)和锐度感知最小化(SAM)的归纳偏差，发现SAM在早期训练中更均匀学习特征，从而减少了simplicity bias并提升in-distribution generalization。论文提出USEFUL方法，通过在训练早期基于网络输出聚类例子、识别相似输出聚类并仅上采样其他例子一次，来修改训练数据分布缓解简单性偏差。实验结果显示，USEFUL与(S)GD、SAM等梯度方法结合，能显著改善泛化性能，并在CIFAR10、STL10等数据集上与现有数据增强策略结合，达到了state-of-the-art水平。",
      "categories": [
        "cs.LG",
        "cs.AI",
        "cs.CV"
      ],
      "primary_category": "cs.LG",
      "comment": "43 pages, 15 figures, 9 tables",
      "pdf_url": "http://arxiv.org/pdf/2404.17768v2",
      "published_date": "2024-04-27 03:30:50 UTC",
      "updated_date": "2024-11-02 00:51:16 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-18T04:11:54.958140"
    },
    {
      "arxiv_id": "2404.17766v1",
      "title": "Implementation of Big AI Models for Wireless Networks with Collaborative Edge Computing",
      "title_zh": "翻译失败",
      "authors": [
        "Liekang Zeng",
        "Shengyuan Ye",
        "Xu Chen",
        "Yang Yang"
      ],
      "abstract": "Big Artificial Intelligence (AI) models have emerged as a crucial element in\nvarious intelligent applications at the edge, such as voice assistants in smart\nhomes and autonomous robotics in smart factories. Training big AI models, e.g.,\nfor personalized fine-tuning and continual model refinement, poses significant\nchallenges to edge devices due to the inherent conflict between limited\ncomputing resources and intensive workload associated with training. Despite\nthe constraints of on-device training, traditional approaches usually resort to\naggregating training data and sending it to a remote cloud for centralized\ntraining. Nevertheless, this approach is neither sustainable, which strains\nlong-range backhaul transmission and energy-consuming datacenters, nor safely\nprivate, which shares users' raw data with remote infrastructures. To address\nthese challenges, we alternatively observe that prevalent edge environments\nusually contain a diverse collection of trusted edge devices with untapped idle\nresources, which can be leveraged for edge training acceleration. Motivated by\nthis, in this article, we propose collaborative edge training, a novel training\nmechanism that orchestrates a group of trusted edge devices as a resource pool\nfor expedited, sustainable big AI model training at the edge. As an initial\nstep, we present a comprehensive framework for building collaborative edge\ntraining systems and analyze in-depth its merits and sustainable scheduling\nchoices following its workflow. To further investigate the impact of its\nparallelism design, we empirically study a case of four typical parallelisms\nfrom the perspective of energy demand with realistic testbeds. Finally, we\ndiscuss open challenges for sustainable collaborative edge training to point to\nfuture directions of edge-centric big AI model training.",
      "tldr_zh": "本论文探讨了在无线网络中部署Big AI Models的挑战，特别是边缘设备资源有限导致的训练难题，以及传统云端训练的可持续性和隐私问题。为解决这些问题，作者提出了一种协作边缘训练机制，利用一组可信边缘设备的闲置资源作为资源池，实现高效、可持续的Big AI Models训练，并提供了一个全面框架来分析其优点和调度选择。通过真实测试床实验，研究了四种典型并行性的能源需求影响，发现这种方法可显著降低能源消耗。最终，论文讨论了可持续协作边缘训练的开放挑战，为边缘中心化Big AI Models训练指明未来方向。",
      "categories": [
        "cs.LG",
        "cs.AI",
        "cs.DC",
        "cs.NI"
      ],
      "primary_category": "cs.LG",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2404.17766v1",
      "published_date": "2024-04-27 03:09:39 UTC",
      "updated_date": "2024-04-27 03:09:39 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-18T04:12:05.357736"
    },
    {
      "arxiv_id": "2404.17760v1",
      "title": "Adversarial Examples: Generation Proposal in the Context of Facial Recognition Systems",
      "title_zh": "翻译失败",
      "authors": [
        "Marina Fuster",
        "Ignacio Vidaurreta"
      ],
      "abstract": "In this paper we investigate the vulnerability that facial recognition\nsystems present to adversarial examples by introducing a new methodology from\nthe attacker perspective. The technique is based on the use of the autoencoder\nlatent space, organized with principal component analysis. We intend to analyze\nthe potential to craft adversarial examples suitable for both dodging and\nimpersonation attacks, against state-of-the-art systems. Our initial\nhypothesis, which was not strongly favoured by the results, stated that it\nwould be possible to separate between the \"identity\" and \"facial expression\"\nfeatures to produce high-quality examples. Despite the findings not supporting\nit, the results sparked insights into adversarial examples generation and\nopened new research avenues in the area.",
      "tldr_zh": "本论文探讨了人脸识别系统对 adversarial examples 的易感性，提出了一种新方法，从攻击者视角利用 autoencoder 的潜在空间并结合 principal component analysis 组织，旨在生成适合 dodging attacks 和 impersonation attacks 的对抗样本。研究假设可以通过分离“identity”（身份）和“facial expression”（面部表情）特征来创建高质量样本，但实验结果并未强烈支持这一假设。总体而言，该方法虽未验证初始假设，却为 adversarial examples 生成提供了新见解，并开辟了相关研究领域的新方向。",
      "categories": [
        "cs.CV",
        "cs.AI",
        "cs.LG"
      ],
      "primary_category": "cs.CV",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2404.17760v1",
      "published_date": "2024-04-27 02:35:15 UTC",
      "updated_date": "2024-04-27 02:35:15 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-18T04:12:17.372465"
    },
    {
      "arxiv_id": "2404.17758v2",
      "title": "The Common Core Ontologies",
      "title_zh": "翻译失败",
      "authors": [
        "Mark Jensen",
        "Giacomo De Colle",
        "Sean Kindya",
        "Cameron More",
        "Alexander P. Cox",
        "John Beverley"
      ],
      "abstract": "The Common Core Ontologies (CCO) are designed as a mid-level ontology suite\nthat extends the Basic Formal Ontology. CCO has since been increasingly adopted\nby a broad group of users and applications and is proposed as the first\nstandard mid-level ontology. Despite these successes, documentation of the\ncontents and design patterns of the CCO has been comparatively minimal. This\npaper is a step toward providing enhanced documentation for the mid-level\nontology suite through a discussion of the contents of the eleven ontologies\nthat collectively comprise the Common Core Ontology suite.",
      "tldr_zh": "Common Core Ontologies (CCO) 是一个扩展 Basic Formal Ontology 的中层本体套件，已被广泛应用于各种用户和场景，并被提议作为第一个标准中层本体。尽管其成功，但对 CCO 内容和设计模式的文档化相对不足。本文旨在通过详细讨论组成 CCO 的 11 个本体，提供增强的文档支持，以促进其更好地理解和采用。",
      "categories": [
        "cs.AI",
        "cs.DB",
        "cs.LO"
      ],
      "primary_category": "cs.AI",
      "comment": "12 pages",
      "pdf_url": "http://arxiv.org/pdf/2404.17758v2",
      "published_date": "2024-04-27 02:23:02 UTC",
      "updated_date": "2024-08-16 03:26:25 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-18T04:12:28.113001"
    },
    {
      "arxiv_id": "2404.17757v2",
      "title": "Middle Architecture Criteria",
      "title_zh": "中层架构标准",
      "authors": [
        "John Beverley",
        "Giacomo De Colle",
        "Mark Jensen",
        "Carter Benson",
        "Barry Smith"
      ],
      "abstract": "Mid-level ontologies are used to integrate terminologies and data across\ndisparate domains. There are, however, no clear, defensible criteria for\ndetermining whether a given ontology should count as mid-level, because we lack\na rigorous characterization of what the middle level of generality is supposed\nto contain. Attempts to provide such a characterization have failed, we\nbelieve, because they have focused on the goal of specifying what is\ncharacteristic of those single ontologies that have been advanced as mid-level\nontologies. Unfortunately, single ontologies of this sort are generally a\nmixture of top- and mid-level, and sometimes even of domain-level terms. To\ngain clarity, we aim to specify the necessary and sufficient conditions for a\ncollection of one or more ontologies to inhabit what we call a mid-level\narchitecture.",
      "tldr_zh": "该论文探讨了中层本体（mid-level ontologies）的定义问题，这些本体用于整合不同领域的术语和数据，但目前缺乏明确标准来判断一个本体是否属于中层。作者认为，过去的尝试失败是因为它们专注于单个本体，而这些本体往往混合了高层（top-level）、中层和领域级别的术语。论文的目标是提出必要和充分条件，以定义一个或多个本体集合构成“中层架构”（mid-level architecture），从而为中层本体应用提供更清晰的框架。",
      "categories": [
        "cs.AI",
        "cs.DB",
        "cs.LO"
      ],
      "primary_category": "cs.AI",
      "comment": "14 pages",
      "pdf_url": "http://arxiv.org/pdf/2404.17757v2",
      "published_date": "2024-04-27 02:16:26 UTC",
      "updated_date": "2024-08-16 03:20:35 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-18T04:12:40.482205"
    },
    {
      "arxiv_id": "2404.17753v1",
      "title": "Leveraging Cross-Modal Neighbor Representation for Improved CLIP Classification",
      "title_zh": "翻译失败",
      "authors": [
        "Chao Yi",
        "Lu Ren",
        "De-Chuan Zhan",
        "Han-Jia Ye"
      ],
      "abstract": "CLIP showcases exceptional cross-modal matching capabilities due to its\ntraining on image-text contrastive learning tasks. However, without specific\noptimization for unimodal scenarios, its performance in single-modality feature\nextraction might be suboptimal. Despite this, some studies have directly used\nCLIP's image encoder for tasks like few-shot classification, introducing a\nmisalignment between its pre-training objectives and feature extraction\nmethods. This inconsistency can diminish the quality of the image's feature\nrepresentation, adversely affecting CLIP's effectiveness in target tasks. In\nthis paper, we view text features as precise neighbors of image features in\nCLIP's space and present a novel CrOss-moDal nEighbor Representation(CODER)\nbased on the distance structure between images and their neighbor texts. This\nfeature extraction method aligns better with CLIP's pre-training objectives,\nthereby fully leveraging CLIP's robust cross-modal capabilities. The key to\nconstruct a high-quality CODER lies in how to create a vast amount of\nhigh-quality and diverse texts to match with images. We introduce the Auto Text\nGenerator(ATG) to automatically generate the required texts in a data-free and\ntraining-free manner. We apply CODER to CLIP's zero-shot and few-shot image\nclassification tasks. Experiment results across various datasets and models\nconfirm CODER's effectiveness. Code is available\nat:https://github.com/YCaigogogo/CVPR24-CODER.",
      "tldr_zh": "这篇论文针对 CLIP 在单模态任务中的 suboptimal 性能，提出了一种新型特征提取方法 CrOss-moDal nEighbor Representation (CODER)，通过利用文本特征作为图像特征的邻居，并基于图像和邻居文本的距离结构来更好地对齐 CLIP 的预训练目标。论文引入 Auto Text Generator (ATG)，一种无需数据或训练的自动文本生成工具，来创建大量高质量、多样化的文本匹配图像，从而构建高品质的 CODER。实验结果显示，在各种数据集和模型上，CODER 显著提升了 CLIP 的零样本和少样本图像分类性能。",
      "categories": [
        "cs.CV",
        "cs.AI"
      ],
      "primary_category": "cs.CV",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2404.17753v1",
      "published_date": "2024-04-27 02:04:36 UTC",
      "updated_date": "2024-04-27 02:04:36 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-18T04:12:53.964509"
    },
    {
      "arxiv_id": "2404.17749v2",
      "title": "UMass-BioNLP at MEDIQA-M3G 2024: DermPrompt -- A Systematic Exploration of Prompt Engineering with GPT-4V for Dermatological Diagnosis",
      "title_zh": "翻译失败",
      "authors": [
        "Parth Vashisht",
        "Abhilasha Lodha",
        "Mukta Maddipatla",
        "Zonghai Yao",
        "Avijit Mitra",
        "Zhichao Yang",
        "Junda Wang",
        "Sunjae Kwon",
        "Hong Yu"
      ],
      "abstract": "This paper presents our team's participation in the MEDIQA-ClinicalNLP2024\nshared task B. We present a novel approach to diagnosing clinical dermatology\ncases by integrating large multimodal models, specifically leveraging the\ncapabilities of GPT-4V under a retriever and a re-ranker framework. Our\ninvestigation reveals that GPT-4V, when used as a retrieval agent, can\naccurately retrieve the correct skin condition 85% of the time using\ndermatological images and brief patient histories. Additionally, we empirically\nshow that Naive Chain-of-Thought (CoT) works well for retrieval while Medical\nGuidelines Grounded CoT is required for accurate dermatological diagnosis.\nFurther, we introduce a Multi-Agent Conversation (MAC) framework and show its\nsuperior performance and potential over the best CoT strategy. The experiments\nsuggest that using naive CoT for retrieval and multi-agent conversation for\ncritique-based diagnosis, GPT-4V can lead to an early and accurate diagnosis of\ndermatological conditions. The implications of this work extend to improving\ndiagnostic workflows, supporting dermatological education, and enhancing\npatient care by providing a scalable, accessible, and accurate diagnostic tool.",
      "tldr_zh": "本研究探讨了使用GPT-4V进行皮肤病诊断的DermPrompt方法，参与MEDIQA-ClinicalNLP2024共享任务B，通过整合检索器和重新排序器框架来处理皮肤图像及患者病史。研究发现，Naive Chain-of-Thought (CoT) 在检索任务中表现良好，准确率达85%，而Medical Guidelines Grounded CoT 则更适合精确诊断，且引入的Multi-Agent Conversation (MAC) 框架比最佳CoT策略更优越。实验结果表明，这种方法能实现早期准确诊断，并为改善诊断流程、支持皮肤病教育和提升患者护理提供可扩展的工具。",
      "categories": [
        "cs.AI",
        "cs.CL"
      ],
      "primary_category": "cs.AI",
      "comment": "Accepted at NAACL-ClinicalNLP workshop 2024",
      "pdf_url": "http://arxiv.org/pdf/2404.17749v2",
      "published_date": "2024-04-27 01:39:05 UTC",
      "updated_date": "2024-05-08 21:57:24 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-18T04:13:05.568315"
    },
    {
      "arxiv_id": "2404.19640v1",
      "title": "Attacking Bayes: On the Adversarial Robustness of Bayesian Neural Networks",
      "title_zh": "翻译失败",
      "authors": [
        "Yunzhen Feng",
        "Tim G. J. Rudner",
        "Nikolaos Tsilivis",
        "Julia Kempe"
      ],
      "abstract": "Adversarial examples have been shown to cause neural networks to fail on a\nwide range of vision and language tasks, but recent work has claimed that\nBayesian neural networks (BNNs) are inherently robust to adversarial\nperturbations. In this work, we examine this claim. To study the adversarial\nrobustness of BNNs, we investigate whether it is possible to successfully break\nstate-of-the-art BNN inference methods and prediction pipelines using even\nrelatively unsophisticated attacks for three tasks: (1) label prediction under\nthe posterior predictive mean, (2) adversarial example detection with Bayesian\npredictive uncertainty, and (3) semantic shift detection. We find that BNNs\ntrained with state-of-the-art approximate inference methods, and even BNNs\ntrained with Hamiltonian Monte Carlo, are highly susceptible to adversarial\nattacks. We also identify various conceptual and experimental errors in\nprevious works that claimed inherent adversarial robustness of BNNs and\nconclusively demonstrate that BNNs and uncertainty-aware Bayesian prediction\npipelines are not inherently robust against adversarial attacks.",
      "tldr_zh": "该论文质疑了Bayesian Neural Networks (BNNs) 的对抗鲁棒性，挑战了先前声称BNNs天生对对抗攻击具有内在抵抗力的观点。研究者通过实验攻击BNNs的预测管道，包括标签预测、对抗示例检测（利用Bayesian预测不确定性）和语义偏移检测，结果显示即使采用Hamiltonian Monte Carlo等先进推理方法，BNNs也高度易受攻击。论文还指出了之前工作的概念和实验错误，证明BNNs及其不确定性预测机制并非固有鲁棒。",
      "categories": [
        "cs.LG",
        "cs.AI",
        "cs.CV",
        "stat.ME",
        "stat.ML"
      ],
      "primary_category": "cs.LG",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2404.19640v1",
      "published_date": "2024-04-27 01:34:46 UTC",
      "updated_date": "2024-04-27 01:34:46 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-18T04:13:17.424005"
    },
    {
      "arxiv_id": "2404.17735v3",
      "title": "Causal Diffusion Autoencoders: Toward Counterfactual Generation via Diffusion Probabilistic Models",
      "title_zh": "翻译失败",
      "authors": [
        "Aneesh Komanduri",
        "Chen Zhao",
        "Feng Chen",
        "Xintao Wu"
      ],
      "abstract": "Diffusion probabilistic models (DPMs) have become the state-of-the-art in\nhigh-quality image generation. However, DPMs have an arbitrary noisy latent\nspace with no interpretable or controllable semantics. Although there has been\nsignificant research effort to improve image sample quality, there is little\nwork on representation-controlled generation using diffusion models.\nSpecifically, causal modeling and controllable counterfactual generation using\nDPMs is an underexplored area. In this work, we propose CausalDiffAE, a\ndiffusion-based causal representation learning framework to enable\ncounterfactual generation according to a specified causal model. Our key idea\nis to use an encoder to extract high-level semantically meaningful causal\nvariables from high-dimensional data and model stochastic variation using\nreverse diffusion. We propose a causal encoding mechanism that maps\nhigh-dimensional data to causally related latent factors and parameterize the\ncausal mechanisms among latent factors using neural networks. To enforce the\ndisentanglement of causal variables, we formulate a variational objective and\nleverage auxiliary label information in a prior to regularize the latent space.\nWe propose a DDIM-based counterfactual generation procedure subject to\ndo-interventions. Finally, to address the limited label supervision scenario,\nwe also study the application of CausalDiffAE when a part of the training data\nis unlabeled, which also enables granular control over the strength of\ninterventions in generating counterfactuals during inference. We empirically\nshow that CausalDiffAE learns a disentangled latent space and is capable of\ngenerating high-quality counterfactual images.",
      "tldr_zh": "本论文提出 CausalDiffAE 框架，利用 Diffusion Probabilistic Models (DPMs) 进行因果表示学习，以实现根据指定因果模型的可控反事实生成。框架的核心是使用编码器从高维数据中提取语义上有意义的因果变量，并通过神经网络参数化潜在因素之间的因果机制，同时采用变分目标和辅助标签信息来确保变量的解缠(disentanglement)。论文还引入基于 DDIM 的生成过程，支持 do-interventions，并在部分数据未标记的场景下实现干预强度的粒度控制。实验结果表明，CausalDiffAE 成功学习了解缠的潜在空间，并能生成高质量的反事实图像。",
      "categories": [
        "cs.LG",
        "cs.AI",
        "stat.ME"
      ],
      "primary_category": "cs.LG",
      "comment": "Accepted to the 27th European Conference on Artificial Intelligence\n  (ECAI 2024)",
      "pdf_url": "http://arxiv.org/pdf/2404.17735v3",
      "published_date": "2024-04-27 00:09:26 UTC",
      "updated_date": "2024-08-23 22:02:23 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-18T04:13:31.378538"
    },
    {
      "arxiv_id": "2404.17733v1",
      "title": "Building a Large Japanese Web Corpus for Large Language Models",
      "title_zh": "为大型语言模型构建大型日语网络语料库",
      "authors": [
        "Naoaki Okazaki",
        "Kakeru Hattori",
        "Hirai Shota",
        "Hiroki Iida",
        "Masanari Ohi",
        "Kazuki Fujii",
        "Taishi Nakamura",
        "Mengsay Loem",
        "Rio Yokota",
        "Sakae Mizuki"
      ],
      "abstract": "Open Japanese large language models (LLMs) have been trained on the Japanese\nportions of corpora such as CC-100, mC4, and OSCAR. However, these corpora were\nnot created for the quality of Japanese texts. This study builds a large\nJapanese web corpus by extracting and refining text from the Common Crawl\narchive (21 snapshots of approximately 63.4 billion pages crawled between 2020\nand 2023). This corpus consists of approximately 312.1 billion characters\n(approximately 173 million pages), which is the largest of all available\ntraining corpora for Japanese LLMs, surpassing CC-100 (approximately 25.8\nbillion characters), mC4 (approximately 239.7 billion characters) and OSCAR\n23.10 (approximately 74 billion characters). To confirm the quality of the\ncorpus, we performed continual pre-training on Llama 2 7B, 13B, 70B, Mistral 7B\nv0.1, and Mixtral 8x7B Instruct as base LLMs and gained consistent (6.6-8.1\npoints) improvements on Japanese benchmark datasets. We also demonstrate that\nthe improvement on Llama 2 13B brought from the presented corpus was the\nlargest among those from other existing corpora.",
      "tldr_zh": "本研究构建了一个大型日语网络语料库，用于训练 Large Language Models (LLMs)，通过从 Common Crawl 档案的 21 个快照（2020-2023 年）中提取和精炼文本，获得了约 312.1 亿字符（约 1.73 亿页面）的规模，这超过了现有语料库如 CC-100（约 25.8 亿字符）、mC4（约 239.7 亿字符）和 OSCAR（约 74 亿字符）。为了验证语料库质量，研究者对 Llama 2 7B、13B、70B、Mistral 7B v0.1 和 Mixtral 8x7B Instruct 等基线模型进行持续预训练，结果显示在日语基准数据集上性能提升 6.6-8.1 点。相比其他语料库，该新语料库在 Llama 2 13B 上的改进幅度最大，证明了其在提升日语 LLM 性能方面的显著贡献。",
      "categories": [
        "cs.CL",
        "cs.AI"
      ],
      "primary_category": "cs.CL",
      "comment": "17 pages",
      "pdf_url": "http://arxiv.org/pdf/2404.17733v1",
      "published_date": "2024-04-27 00:02:45 UTC",
      "updated_date": "2024-04-27 00:02:45 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-18T04:13:45.444069"
    }
  ],
  "raw_papers_fetched": true,
  "papers_count": 51,
  "processed_papers_count": 51,
  "failed_papers_count": 0,
  "summary_generated": true,
  "daily_data_saved": true,
  "last_update": "2025-05-18T04:14:13.604991"
}