{
  "date": "2024-07-06",
  "category": "cs.AI",
  "summary": "欢迎来到 UTC 时间 2024-07-06 的 arXiv 中文 TLDR 快报！今天 arXiv 更新了 41 篇论文，主要聚焦 AI 尤其是大型语言模型 (LLMs) 的推理、安全和应用扩展，同时涉及医疗图像处理、通信系统和数据增强等领域；令人印象深刻的包括 LLMs 在文本到 SQL 推理的创新框架，以及医疗领域的多模态模型改进，而有名的学者如 Muhammad Abdul-Mageed 的 NADI 任务系列论文值得关注。\n\n### AI 和 LLMs 领域：重点和热门话题\nAI 论文占据了今日的大部分更新，许多聚焦 LLMs 的工具调用、推理和优化，这些主题高度相关且有实际应用潜力。\n\n- **Lucy: Think and Reason to Solve Text-to-SQL（Lucy: 思考和推理解决文本到 SQL）**  \n  这篇论文提出了一种结合 LLMs 和自动推理的框架，用于处理大型企业数据库的复杂查询。核心贡献是超越现有方法的零样本性能，尤其在复杂关系数据库上，显著提高了查询准确性，展示了 LLMs 在实际数据库应用中的潜力。\n\n- **Are LLMs Correctly Integrated into Software Systems?（LLMs 是否正确集成到软件系统中？）**  \n  作者分析了 100 个开源应用，发现 77% 存在集成缺陷（如功能和安全问题）。主要发现是通过系统指南和开源缺陷库（如 Hydrangea）解决这些问题，强调了 LLMs 在软件工程中的可靠性和潜在风险。\n\n- **Solving for X and Beyond: Can Large Language Models Solve Complex Math Problems with More-Than-Two Unknowns?（解决 X 及更多：LLMs 能处理多未知数数学问题吗？）**  \n  引入 BeyondX 基准，测试 LLMs 在多未知数数学推理中的表现。关键发现是现有模型性能随未知数增加下降高达 70%，并提出 Formulate-and-Solve 策略提升泛化能力，这对 LLMs 的数学应用有重要启示。\n\n- **RULE: Reliable Multimodal RAG for Factuality in Medical Vision Language Models（RULE: 用于医疗视觉语言模型事实性的可靠多模态 RAG）**  \n  针对医疗 AI 的幻觉问题，提出 RULE 框架，包括检索上下文优化和偏好数据集微调。贡献是显著提高事实准确性（平均提升 47.4%），并在医疗问答和报告生成任务中验证了其有效性，已被 EMNLP 2024 接受。\n\n- **How do you know that? Teaching Generative Language Models to Reference Answers to Biomedical Questions（你怎么知道的？教生成式语言模型引用生物医学问题的答案）**  \n  构建了一个 RAG 系统，使 LLMs 在生物医学问答中引用 PubMed 摘要。核心发现是检索系统比 PubMed 引擎提升 23%，并通过微调模型实现了高引用准确性，适合事实敏感领域。\n\n- **Achieving Tool Calling Functionality in LLMs Using Only Prompt Engineering Without Fine-Tuning（仅用提示工程实现 LLMs 的工具调用功能，无需微调）**  \n  这篇简短论文展示了通过巧妙提示和代码设计，使 LLMs 实现 100% 工具调用成功率。贡献在于避免了微调的资源消耗，提供了一种高效、低成本的 LLMs 扩展方法。\n\n其他 LLMs 相关论文，如 **RAMO: Retrieval-Augmented Generation for Enhancing MOOCs Recommendations（RAMO: 增强 MOOCs 推荐的检索增强生成）** 和 **LogicVista: Multimodal LLM Logical Reasoning Benchmark in Visual Contexts（LogicVista: 多模态 LLMs 在视觉上下文中的逻辑推理基准）**，分别通过对话式推荐和基准评估提升了教育和视觉任务的性能，但细节较常规，快速掠过。\n\n### 医疗和生物领域：安全与数据增强\n医疗论文强调模型安全和数据处理，相关主题紧跟现实应用需求。\n\n- **BadCLM: Backdoor Attack in Clinical Language Models for Electronic Health Records（BadCLM: 电子健康记录临床语言模型中的后门攻击）**  \n  引入 BadCLM 方法，展示了后门攻击对临床决策模型的威胁。核心发现是通过 MIMIC III 数据集验证了攻击的有效性，揭示了医疗 AI 的安全风险，并为防御提供思路，已被 AMIA 2024 接受。\n\n- **FlowLearn: Evaluating Large Vision-Language Models on Flowchart Understanding（FlowLearn: 评估大型视觉语言模型在流程图理解上的性能）**  \n  发布 FlowLearn 数据集，包含科学流程图和模拟图。贡献是评估 LVLMs 在流程图任务（如节点计数和 OCR）的表现，GPT-4V 在某些任务达到 58% 准确率，但整体仍有局限，适合医疗通信研究。\n\n其他医疗论文，如 **Synthetic Data Aided Federated Learning Using Foundation Models（使用基础模型的合成数据辅助联邦学习）**，通过差分隐私提升了联邦学习在图像数据集上的性能（准确率提升 9%），但相对次要，简要提及。\n\n### 通信和硬件领域：优化与预测\n这些论文聚焦系统优化，部分有实际工程价值。\n\n- **A Generalized Transformer-based Radio Link Failure Prediction Framework in 5G RANs（基于 Transformer 的 5G RANs 无线链路故障预测框架）**  \n  提出 GenTrap 框架，结合 GNN 和时间序列 Transformer 预测链路故障。核心发现是在真实数据集上实现高 F1 分数（0.93 和 0.79），提升了 5G 网络的可靠性和泛化能力。\n\n其他如 **Communication and Control Co-Design in 6G: Sequential Decision-Making with LLMs（6G 中的通信与控制联合设计：使用 LLMs 的顺序决策）**，探索了 LLMs 在 6G 决策中的作用，但实验初步，快速掠过。\n\n### 其他领域：快速概述\n剩余论文涉及图像处理、数学和数据挖掘等领域，但影响力较小，仅快速列出关键点：\n- **DMTG: One-Shot Differentiable Multi-Task Grouping（DMTG: 一键可微多任务分组）**：通过可微剪枝优化多任务学习，已被 ICML 2024 接受。\n- **NADI 2024: The Fifth Nuanced Arabic Dialect Identification Shared Task（NADI 2024: 第五届细微阿拉伯方言识别共享任务）**：评估方言识别和机器翻译，51 队参与，展示了 Arabic NLP 的挑战。\n- **MMSci: A Dataset for Graduate-Level Multi-Discipline Multimodal Scientific Understanding（MMSci: 研究生级多学科多模态科学理解数据集）**：发布新数据集，提升科学图表理解，Qwen2-VL-7B 在基准上超越 GPT-4o。\n\n今日 arXiv 整体质量高，AI 领域论文尤其值得跟踪，读者可关注 LLMs 的推理和医疗应用以寻找潜在研究机会。更多细节请查阅 arXiv。",
  "papers": [
    {
      "arxiv_id": "2407.05213v1",
      "title": "BadCLM: Backdoor Attack in Clinical Language Models for Electronic Health Records",
      "title_zh": "BadCLM：临床语言模型中针对电子健康记录的后门",
      "authors": [
        "Weimin Lyu",
        "Zexin Bi",
        "Fusheng Wang",
        "Chao Chen"
      ],
      "abstract": "The advent of clinical language models integrated into electronic health\nrecords (EHR) for clinical decision support has marked a significant\nadvancement, leveraging the depth of clinical notes for improved\ndecision-making. Despite their success, the potential vulnerabilities of these\nmodels remain largely unexplored. This paper delves into the realm of backdoor\nattacks on clinical language models, introducing an innovative attention-based\nbackdoor attack method, BadCLM (Bad Clinical Language Models). This technique\nclandestinely embeds a backdoor within the models, causing them to produce\nincorrect predictions when a pre-defined trigger is present in inputs, while\nfunctioning accurately otherwise. We demonstrate the efficacy of BadCLM through\nan in-hospital mortality prediction task with MIMIC III dataset, showcasing its\npotential to compromise model integrity. Our findings illuminate a significant\nsecurity risk in clinical decision support systems and pave the way for future\nendeavors in fortifying clinical language models against such vulnerabilities.",
      "tldr_zh": "本论文探讨了临床语言模型在电子健康记录 (EHR) 中的安全漏洞，提出了一种创新的注意力-based 后门攻击方法，名为 BadCLM。该方法通过在模型中嵌入后门，使得当输入包含预定义触发器时，模型产生错误预测，而在其他情况下保持正常功能。在 MIMIC III 数据集上的住院死亡率预测任务中，实验证明了 BadCLM 的有效性，揭示了临床决策支持系统的重大安全风险，并为未来强化模型防护提供了方向。",
      "categories": [
        "cs.CL",
        "cs.AI"
      ],
      "primary_category": "cs.CL",
      "comment": "AMIA 2024",
      "pdf_url": "http://arxiv.org/pdf/2407.05213v1",
      "published_date": "2024-07-06 23:56:43 UTC",
      "updated_date": "2024-07-06 23:56:43 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-19T04:04:00.950487"
    },
    {
      "arxiv_id": "2407.05202v1",
      "title": "Harnessing the Power of LLMs: Automating Unit Test Generation for High-Performance Computing",
      "title_zh": "翻译失败",
      "authors": [
        "Rabimba Karanjai",
        "Aftab Hussain",
        "Md Rafiqul Islam Rabin",
        "Lei Xu",
        "Weidong Shi",
        "Mohammad Amin Alipour"
      ],
      "abstract": "Unit testing is crucial in software engineering for ensuring quality.\nHowever, it's not widely used in parallel and high-performance computing\nsoftware, particularly scientific applications, due to their smaller, diverse\nuser base and complex logic. These factors make unit testing challenging and\nexpensive, as it requires specialized knowledge and existing automated tools\nare often ineffective.\n  To address this, we propose an automated method for generating unit tests for\nsuch software, considering their unique features like complex logic and\nparallel processing. Recently, large language models (LLMs) have shown promise\nin coding and testing. We explored the capabilities of Davinci\n(text-davinci-002) and ChatGPT (gpt-3.5-turbo) in creating unit tests for C++\nparallel programs. Our results show that LLMs can generate mostly correct and\ncomprehensive unit tests, although they have some limitations, such as\nrepetitive assertions and blank test cases.",
      "tldr_zh": "本论文探讨了在高性能计算软件中自动化单位测试的挑战，这些软件因复杂逻辑和并行处理而难以测试。研究提出了一种利用大型语言模型(LLMs)的方法，包括Davinci (text-davinci-002)和ChatGPT (gpt-3.5-turbo)，来为C++并行程序生成单位测试。结果表明，LLMs能够产生大部分正确且全面的测试用例，但存在局限性，如重复的断言和空白测试用例。该方法为提升高性能计算软件的质量提供了高效的自动化解决方案。",
      "categories": [
        "cs.SE",
        "cs.AI"
      ],
      "primary_category": "cs.SE",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2407.05202v1",
      "published_date": "2024-07-06 22:45:55 UTC",
      "updated_date": "2024-07-06 22:45:55 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-19T04:04:12.957710"
    },
    {
      "arxiv_id": "2407.05197v1",
      "title": "A Generalized Transformer-based Radio Link Failure Prediction Framework in 5G RANs",
      "title_zh": "翻译失败",
      "authors": [
        "Kazi Hasan",
        "Thomas Trappenberg",
        "Israat Haque"
      ],
      "abstract": "Radio link failure (RLF) prediction system in Radio Access Networks (RANs) is\ncritical for ensuring seamless communication and meeting the stringent\nrequirements of high data rates, low latency, and improved reliability in 5G\nnetworks. However, weather conditions such as precipitation, humidity,\ntemperature, and wind impact these communication links. Usually, historical\nradio link Key Performance Indicators (KPIs) and their surrounding weather\nstation observations are utilized for building learning-based RLF prediction\nmodels. However, such models must be capable of learning the spatial weather\ncontext in a dynamic RAN and effectively encoding time series KPIs with the\nweather observation data. Existing works fail to incorporate both of these\nessential design aspects of the prediction models. This paper fills the gap by\nproposing GenTrap, a novel RLF prediction framework that introduces a graph\nneural network (GNN)-based learnable weather effect aggregation module and\nemploys state-of-the-art time series transformer as the temporal feature\nextractor for radio link failure prediction. The proposed aggregation method of\nGenTrap can be integrated into any existing prediction model to achieve better\nperformance and generalizability. We evaluate GenTrap on two real-world\ndatasets (rural and urban) with 2.6 million KPI data points and show that\nGenTrap offers a significantly higher F1-score (0.93 for rural and 0.79 for\nurban) compared to its counterparts while possessing generalization capability.",
      "tldr_zh": "本文提出 GenTrap，一种通用的基于 Transformer 的无线链路故障 (RLF) 预测框架，用于 5G RANs，以应对天气条件（如降水、湿度和温度）对通信链路的影响。框架创新性地整合了基于图神经网络 (GNN) 的可学习天气效应聚合模块和先进的时序 Transformer 作为时间特征提取器，从而有效处理空间天气上下文和时间序列关键性能指标 (KPIs)。实验在两个真实数据集上评估，GenTrap 实现了显著更高的 F1 分数（农村 0.93，城市 0.79），并展示了优秀的性能和泛化能力，可与其他模型无缝整合。",
      "categories": [
        "cs.AI",
        "cs.NI"
      ],
      "primary_category": "cs.AI",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2407.05197v1",
      "published_date": "2024-07-06 21:57:23 UTC",
      "updated_date": "2024-07-06 21:57:23 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-19T04:04:24.398665"
    },
    {
      "arxiv_id": "2407.05193v2",
      "title": "CBM: Curriculum by Masking",
      "title_zh": "翻译失败",
      "authors": [
        "Andrei Jarca",
        "Florinel-Alin Croitoru",
        "Radu Tudor Ionescu"
      ],
      "abstract": "We propose Curriculum by Masking (CBM), a novel state-of-the-art curriculum\nlearning strategy that effectively creates an easy-to-hard training schedule\nvia patch (token) masking, offering significant accuracy improvements over the\nconventional training regime and previous curriculum learning (CL) methods. CBM\nleverages gradient magnitudes to prioritize the masking of salient image\nregions via a novel masking algorithm and a novel masking block. Our approach\nenables controlling sample difficulty via the patch masking ratio, generating\nan effective easy-to-hard curriculum by gradually introducing harder samples as\ntraining progresses. CBM operates with two easily configurable parameters, i.e.\nthe number of patches and the curriculum schedule, making it a versatile\ncurriculum learning approach for object recognition and detection. We conduct\nexperiments with various neural architectures, ranging from convolutional\nnetworks to vision transformers, on five benchmark data sets (CIFAR-10,\nCIFAR-100, ImageNet, Food-101 and PASCAL VOC), to compare CBM with conventional\nas well as curriculum-based training regimes. Our results reveal the\nsuperiority of our strategy compared with the state-of-the-art curriculum\nlearning regimes. We also observe improvements in transfer learning contexts,\nwhere CBM surpasses previous work by considerable margins in terms of accuracy.\nWe release our code for free non-commercial use at\nhttps://github.com/CroitoruAlin/CBM.",
      "tldr_zh": "本研究提出了一种先进的课程学习策略——Curriculum by Masking (CBM)，通过 patch (token) masking 创建从易到难的训练进度，从而显著提升物体识别和检测任务的准确性。CBM 利用梯度幅度优先掩盖图像的关键区域，并引入新颖的掩盖算法和掩盖块，仅需配置 patch 数量和课程进度参数，即可控制样本难度并逐步引入更复杂样本。实验在多种神经架构（如卷积网络和 vision transformers）上，在 CIFAR-10、CIFAR-100、ImageNet、Food-101 和 PASCAL VOC 等五个基准数据集上进行，结果显示 CBM 优于传统和现有 curriculum learning 方法，尤其在迁移学习场景中实现了显著的准确性提升。作者已开源代码以供非商业使用。",
      "categories": [
        "cs.CV",
        "cs.AI",
        "cs.LG"
      ],
      "primary_category": "cs.CV",
      "comment": "Accepted at ECAI 2024",
      "pdf_url": "http://arxiv.org/pdf/2407.05193v2",
      "published_date": "2024-07-06 21:35:18 UTC",
      "updated_date": "2024-07-09 09:40:38 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-19T04:04:36.264392"
    },
    {
      "arxiv_id": "2407.05183v2",
      "title": "FlowLearn: Evaluating Large Vision-Language Models on Flowchart Understanding",
      "title_zh": "翻译失败",
      "authors": [
        "Huitong Pan",
        "Qi Zhang",
        "Cornelia Caragea",
        "Eduard Dragut",
        "Longin Jan Latecki"
      ],
      "abstract": "Flowcharts are graphical tools for representing complex concepts in concise\nvisual representations. This paper introduces the FlowLearn dataset, a resource\ntailored to enhance the understanding of flowcharts. FlowLearn contains complex\nscientific flowcharts and simulated flowcharts. The scientific subset contains\n3,858 flowcharts sourced from scientific literature and the simulated subset\ncontains 10,000 flowcharts created using a customizable script. The dataset is\nenriched with annotations for visual components, OCR, Mermaid code\nrepresentation, and VQA question-answer pairs. Despite the proven capabilities\nof Large Vision-Language Models (LVLMs) in various visual understanding tasks,\ntheir effectiveness in decoding flowcharts - a crucial element of scientific\ncommunication - has yet to be thoroughly investigated. The FlowLearn test set\nis crafted to assess the performance of LVLMs in flowchart comprehension. Our\nstudy thoroughly evaluates state-of-the-art LVLMs, identifying existing\nlimitations and establishing a foundation for future enhancements in this\nrelatively underexplored domain. For instance, in tasks involving simulated\nflowcharts, GPT-4V achieved the highest accuracy (58%) in counting the number\nof nodes, while Claude recorded the highest accuracy (83%) in OCR tasks.\nNotably, no single model excels in all tasks within the FlowLearn framework,\nhighlighting significant opportunities for further development.",
      "tldr_zh": "本文介绍了FlowLearn数据集，用于评估大型视觉语言模型(LVLMs)在流程图理解方面的性能。该数据集包含3,858个来自科学文献的流程图和10,000个通过脚本生成的模拟流程图，并附带视觉组件、OCR、Mermaid代码表示以及VQA问答对注解。通过实验评估，研究发现LVLMs在任务如节点计数和OCR中表现不一，例如GPT-4V在节点计数任务中准确率达58%，Claude在OCR任务中达83%，但无单一模型全面领先，这为未来LVLMs的改进奠定了基础。",
      "categories": [
        "cs.CV",
        "cs.AI"
      ],
      "primary_category": "cs.CV",
      "comment": "ECAI 2024",
      "pdf_url": "http://arxiv.org/pdf/2407.05183v2",
      "published_date": "2024-07-06 20:58:51 UTC",
      "updated_date": "2024-07-09 21:16:00 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-19T04:04:48.775078"
    },
    {
      "arxiv_id": "2407.05174v1",
      "title": "Synthetic Data Aided Federated Learning Using Foundation Models",
      "title_zh": "翻译失败",
      "authors": [
        "Fatima Abacha",
        "Sin G. Teo",
        "Lucas C. Cordeiro",
        "Mustafa A. Mustafa"
      ],
      "abstract": "In heterogeneous scenarios where the data distribution amongst the Federated\nLearning (FL) participants is Non-Independent and Identically distributed\n(Non-IID), FL suffers from the well known problem of data heterogeneity. This\nleads the performance of FL to be significantly degraded, as the global model\ntends to struggle to converge. To solve this problem, we propose Differentially\nPrivate Synthetic Data Aided Federated Learning Using Foundation Models\n(DPSDA-FL), a novel data augmentation strategy that aids in homogenizing the\nlocal data present on the clients' side. DPSDA-FL improves the training of the\nlocal models by leveraging differentially private synthetic data generated from\nfoundation models. We demonstrate the effectiveness of our approach by\nevaluating it on the benchmark image dataset: CIFAR-10. Our experimental\nresults have shown that DPSDA-FL can improve class recall and classification\naccuracy of the global model by up to 26% and 9%, respectively, in FL with\nNon-IID issues.",
      "tldr_zh": "该论文提出了一种名为 DPSDA-FL 的新方法，用于解决 Federated Learning (FL) 在 Non-IID 数据分布下的异质性问题，通过利用基础模型生成差分隐私合成数据来增强客户端的本地数据分布。DPSDA-FL 通过这种数据增强策略改善本地模型的训练效果，从而促进全局模型的收敛。实验结果显示，在 CIFAR-10 数据集上，该方法将全局模型的类别召回率和分类准确率分别提高了多达 26% 和 9%。",
      "categories": [
        "cs.LG",
        "cs.AI"
      ],
      "primary_category": "cs.LG",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2407.05174v1",
      "published_date": "2024-07-06 20:31:43 UTC",
      "updated_date": "2024-07-06 20:31:43 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-19T04:05:00.413898"
    },
    {
      "arxiv_id": "2407.05154v1",
      "title": "Identifying Intensity of the Structure and Content in Tweets and the Discriminative Power of Attributes in Context with Referential Translation Machines",
      "title_zh": "翻译失败",
      "authors": [
        "Ergun Biçici"
      ],
      "abstract": "We use referential translation machines (RTMs) to identify the similarity\nbetween an attribute and two words in English by casting the task as machine\ntranslation performance prediction (MTPP) between the words and the attribute\nword and the distance between their similarities for Task 10 with stacked RTM\nmodels. RTMs are also used to predict the intensity of the structure and\ncontent in tweets in English, Arabic, and Spanish in Task 1 where MTPP is\nbetween the tweets and the set of words for the emotion selected from WordNet\naffect emotion lists. Stacked RTM models obtain encouraging results in both.",
      "tldr_zh": "本研究利用 Referential Translation Machines (RTMs) 来评估推文结构和内容的强度，以及属性在上下文中的辨别力。具体而言，通过将任务转化为 Machine Translation Performance Prediction (MTPP)，论文使用堆叠 RTM 模型计算属性与英文单词的相似性距离（针对 Task 10），并预测英文、阿拉伯语和西班牙语推文的情感强度（针对 Task 1），后者基于推文与 WordNet 情感列表中选定单词的 MTPP。实验结果显示，堆叠 RTM 模型在两个任务中取得了令人鼓舞的表现。",
      "categories": [
        "cs.CL",
        "cs.AI",
        "I.2.7"
      ],
      "primary_category": "cs.CL",
      "comment": "11 pages, 3 figures, 12 tables",
      "pdf_url": "http://arxiv.org/pdf/2407.05154v1",
      "published_date": "2024-07-06 18:58:10 UTC",
      "updated_date": "2024-07-06 18:58:10 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-19T04:05:11.915260"
    },
    {
      "arxiv_id": "2407.05153v1",
      "title": "Lucy: Think and Reason to Solve Text-to-SQL",
      "title_zh": "Lucy: 思考与推理解决文本到 SQL",
      "authors": [
        "Nina Narodytska",
        "Shay Vargaftik"
      ],
      "abstract": "Large Language Models (LLMs) have made significant progress in assisting\nusers to query databases in natural language. While LLM-based techniques\nprovide state-of-the-art results on many standard benchmarks, their performance\nsignificantly drops when applied to large enterprise databases. The reason is\nthat these databases have a large number of tables with complex relationships\nthat are challenging for LLMs to reason about. We analyze challenges that LLMs\nface in these settings and propose a new solution that combines the power of\nLLMs in understanding questions with automated reasoning techniques to handle\ncomplex database constraints. Based on these ideas, we have developed a new\nframework that outperforms state-of-the-art techniques in zero-shot text-to-SQL\non complex benchmarks",
      "tldr_zh": "这项研究探讨了大型语言模型（LLMs）在处理复杂企业数据库时的挑战，这些数据库涉及众多表和复杂关系，导致LLMs的性能显著下降。论文提出了一种名为Lucy的新框架，该框架结合LLMs在理解自然语言查询方面的优势与自动化推理技术，来有效处理数据库约束。实验结果显示，Lucy在零样本（zero-shot）文本到SQL基准测试中超越了最先进的技术，展示了其在复杂场景下的优越性能。",
      "categories": [
        "cs.AI"
      ],
      "primary_category": "cs.AI",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2407.05153v1",
      "published_date": "2024-07-06 18:56:42 UTC",
      "updated_date": "2024-07-06 18:56:42 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-19T04:05:23.298685"
    },
    {
      "arxiv_id": "2407.05138v2",
      "title": "Are LLMs Correctly Integrated into Software Systems?",
      "title_zh": "翻译失败",
      "authors": [
        "Yuchen Shao",
        "Yuheng Huang",
        "Jiawei Shen",
        "Lei Ma",
        "Ting Su",
        "Chengcheng Wan"
      ],
      "abstract": "Large language models (LLMs) provide effective solutions in various\napplication scenarios, with the support of retrieval-augmented generation\n(RAG). However, developers face challenges in integrating LLM and RAG into\nsoftware systems, due to lacking interface specifications, various requirements\nfrom software context, and complicated system management. In this paper, we\nhave conducted a comprehensive study of 100 open-source applications that\nincorporate LLMs with RAG support, and identified 18 defect patterns. Our study\nreveals that 77% of these applications contain more than three types of\nintegration defects that degrade software functionality, efficiency, and\nsecurity. Guided by our study, we propose systematic guidelines for resolving\nthese defects in software life cycle. We also construct an open-source defect\nlibrary Hydrangea.",
      "tldr_zh": "本研究调查了大型语言模型（LLMs）和检索增强生成（RAG）整合到软件系统中的问题，通过分析100个开源应用，识别了18种缺陷模式。结果显示，77%的应用存在超过三种整合缺陷，导致软件功能、效率和安全受损。论文据此提出系统指南，用于在软件生命周期中解决这些缺陷，并构建了开源缺陷库Hydrangea，以指导未来的LLM整合实践。",
      "categories": [
        "cs.SE",
        "cs.AI"
      ],
      "primary_category": "cs.SE",
      "comment": "accepted by ICSE 2025",
      "pdf_url": "http://arxiv.org/pdf/2407.05138v2",
      "published_date": "2024-07-06 17:25:11 UTC",
      "updated_date": "2025-02-08 08:57:00 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-19T04:05:34.839880"
    },
    {
      "arxiv_id": "2407.05134v1",
      "title": "Solving for X and Beyond: Can Large Language Models Solve Complex Math Problems with More-Than-Two Unknowns?",
      "title_zh": "翻译失败",
      "authors": [
        "Kuei-Chun Kao",
        "Ruochen Wang",
        "Cho-Jui Hsieh"
      ],
      "abstract": "Large Language Models (LLMs) have demonstrated remarkable performance in\nsolving math problems, a hallmark of human intelligence. Despite high success\nrates on current benchmarks; however, these often feature simple problems with\nonly one or two unknowns, which do not sufficiently challenge their reasoning\ncapacities. This paper introduces a novel benchmark, BeyondX, designed to\naddress these limitations by incorporating problems with multiple unknowns.\nRecognizing the challenges in proposing multi-unknown problems from scratch, we\ndeveloped BeyondX using an innovative automated pipeline that progressively\nincreases complexity by expanding the number of unknowns in simpler problems.\nEmpirical study on BeyondX reveals that the performance of existing LLMs, even\nthose fine-tuned specifically on math tasks, significantly decreases as the\nnumber of unknowns increases - with a performance drop of up to 70\\% observed\nin GPT-4. To tackle these challenges, we propose the Formulate-and-Solve\nstrategy, a generalized prompting approach that effectively handles problems\nwith an arbitrary number of unknowns. Our findings reveal that this strategy\nnot only enhances LLM performance on the BeyondX benchmark but also provides\ndeeper insights into the computational limits of LLMs when faced with more\ncomplex mathematical challenges.",
      "tldr_zh": "本研究评估了大语言模型（LLMs）在解决多未知数复杂数学问题上的能力，发现现有模型在仅涉及一两个未知数的基准上表现良好，但面对更多未知数时性能急剧下降。论文引入了新基准 BeyondX，通过一个自动化管道从简单问题逐步增加未知数来生成测试集，实验显示 GPT-4 等模型的准确率可能下降高达70%。为应对这一挑战，研究提出 Formulate-and-Solve 策略，这是一种通用的提示方法，能有效提升 LLMs 在 BeyondX 上的表现，并提供对模型计算极限的深入洞见。",
      "categories": [
        "cs.AI",
        "cs.CL",
        "cs.LG"
      ],
      "primary_category": "cs.AI",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2407.05134v1",
      "published_date": "2024-07-06 17:01:04 UTC",
      "updated_date": "2024-07-06 17:01:04 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-19T04:05:48.554878"
    },
    {
      "arxiv_id": "2407.05131v2",
      "title": "RULE: Reliable Multimodal RAG for Factuality in Medical Vision Language Models",
      "title_zh": "翻译失败",
      "authors": [
        "Peng Xia",
        "Kangyu Zhu",
        "Haoran Li",
        "Hongtu Zhu",
        "Yun Li",
        "Gang Li",
        "Linjun Zhang",
        "Huaxiu Yao"
      ],
      "abstract": "The recent emergence of Medical Large Vision Language Models (Med-LVLMs) has\nenhanced medical diagnosis. However, current Med-LVLMs frequently encounter\nfactual issues, often generating responses that do not align with established\nmedical facts. Retrieval-Augmented Generation (RAG), which utilizes external\nknowledge, can improve the factual accuracy of these models but introduces two\nmajor challenges. First, limited retrieved contexts might not cover all\nnecessary information, while excessive retrieval can introduce irrelevant and\ninaccurate references, interfering with the model's generation. Second, in\ncases where the model originally responds correctly, applying RAG can lead to\nan over-reliance on retrieved contexts, resulting in incorrect answers. To\naddress these issues, we propose RULE, which consists of two components. First,\nwe introduce a provably effective strategy for controlling factuality risk\nthrough the calibrated selection of the number of retrieved contexts. Second,\nbased on samples where over-reliance on retrieved contexts led to errors, we\ncurate a preference dataset to fine-tune the model, balancing its dependence on\ninherent knowledge and retrieved contexts for generation. We demonstrate the\neffectiveness of RULE on medical VQA and report generation tasks across three\ndatasets, achieving an average improvement of 47.4% in factual accuracy. We\npublicly release our benchmark and code in\nhttps://github.com/richard-peng-xia/RULE.",
      "tldr_zh": "该研究针对医疗视觉语言模型（Med-LVLMs）的事实性问题，提出RULE框架，以改进Retrieval-Augmented Generation (RAG)技术的可靠性。RULE包括两个关键组件：一是通过校准策略控制检索上下文的数量，以避免信息不足或引入无关内容；二是利用偏好数据集微调模型，平衡其对内在知识和检索上下文的依赖，从而减少过度依赖导致的错误。在医疗视觉问答（VQA）和报告生成任务上，RULE在三个数据集上实现了事实准确性平均提高47.4%，并公开了基准和代码以促进进一步研究。",
      "categories": [
        "cs.LG",
        "cs.AI",
        "cs.CL",
        "cs.CV",
        "cs.CY"
      ],
      "primary_category": "cs.LG",
      "comment": "EMNLP 2024 main",
      "pdf_url": "http://arxiv.org/pdf/2407.05131v2",
      "published_date": "2024-07-06 16:45:07 UTC",
      "updated_date": "2024-10-17 01:55:28 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-19T04:06:01.703875"
    },
    {
      "arxiv_id": "2407.05116v1",
      "title": "Automatic Prediction of the Performance of Every Parser",
      "title_zh": "翻译失败",
      "authors": [
        "Ergun Biçici"
      ],
      "abstract": "We present a new parser performance prediction (PPP) model using machine\ntranslation performance prediction system (MTPPS), statistically independent of\nany language or parser, relying only on extrinsic and novel features based on\ntextual, link structural, and bracketing tree structural information. This new\nsystem, MTPPS-PPP, can predict the performance of any parser in any language\nand can be useful for estimating the grammatical difficulty when understanding\na given text, for setting expectations from parsing output, for parser\nselection for a specific domain, and for parser combination systems. We obtain\nSoA results in PPP of bracketing $F_1$ with better results over textual\nfeatures and similar performance with previous results that use parser and\nlinguistic label specific information. Our results show the contribution of\ndifferent types of features as well as rankings of individual features in\ndifferent experimental settings (cased vs. uncased), in different learning\ntasks (in-domain vs. out-of-domain), with different training sets, with\ndifferent learning algorithms, and with different dimensionality reduction\ntechniques. We achieve $0.0678$ MAE and $0.85$ RAE in setting +Link, which\ncorresponds to about $7.4\\%$ error when predicting the bracketing $F_1$ score\nfor the Charniak and Johnson parser on the WSJ23 test set. MTPPS-PPP system can\npredict without parsing using only the text, without a supervised parser using\nonly an unsupervised parser, without any parser or language dependent\ninformation, without using a reference parser output, and can be used to\npredict the performance of any parser in any language.",
      "tldr_zh": "本研究提出了一种新的解析器性能预测（PPP）模型 MTPPS-PPP，基于机器翻译性能预测系统（MTPPS），仅依赖于文本、链接结构和括号树结构的外在特征，从而独立于任何语言或解析器。 该模型可用于估计文本的语法难度、设置解析输出期望、选择特定领域的解析器以及解析器组合系统，并在 PPP 的 bracketing F1 分数上取得了 state-of-the-art (SoA) 结果。 实验显示，不同特征类型（如文本特征）的贡献显著，并在各种设置中（如领域内/外学习）表现优异，实现了 MAE 0.0678 和 RAE 0.85 的性能，预测误差约为 7.4%。 总体而言，该系统无需解析器输出或语言特定信息，就能准确预测任何解析器的性能。",
      "categories": [
        "cs.CL",
        "cs.AI",
        "I.2.7"
      ],
      "primary_category": "cs.CL",
      "comment": "8 pages, 2 figures, 7 tables",
      "pdf_url": "http://arxiv.org/pdf/2407.05116v1",
      "published_date": "2024-07-06 15:49:24 UTC",
      "updated_date": "2024-07-06 15:49:24 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-19T04:06:15.499869"
    },
    {
      "arxiv_id": "2407.05112v1",
      "title": "Releasing Malevolence from Benevolence: The Menace of Benign Data on Machine Unlearning",
      "title_zh": "翻译失败",
      "authors": [
        "Binhao Ma",
        "Tianhang Zheng",
        "Hongsheng Hu",
        "Di Wang",
        "Shuo Wang",
        "Zhongjie Ba",
        "Zhan Qin",
        "Kui Ren"
      ],
      "abstract": "Machine learning models trained on vast amounts of real or synthetic data\noften achieve outstanding predictive performance across various domains.\nHowever, this utility comes with increasing concerns about privacy, as the\ntraining data may include sensitive information. To address these concerns,\nmachine unlearning has been proposed to erase specific data samples from\nmodels. While some unlearning techniques efficiently remove data at low costs,\nrecent research highlights vulnerabilities where malicious users could request\nunlearning on manipulated data to compromise the model. Despite these attacks'\neffectiveness, perturbed data differs from original training data, failing hash\nverification. Existing attacks on machine unlearning also suffer from practical\nlimitations and require substantial additional knowledge and resources. To fill\nthe gaps in current unlearning attacks, we introduce the Unlearning Usability\nAttack. This model-agnostic, unlearning-agnostic, and budget-friendly attack\ndistills data distribution information into a small set of benign data. These\ndata are identified as benign by automatic poisoning detection tools due to\ntheir positive impact on model training. While benign for machine learning,\nunlearning these data significantly degrades model information. Our evaluation\ndemonstrates that unlearning this benign data, comprising no more than 1% of\nthe total training data, can reduce model accuracy by up to 50%. Furthermore,\nour findings show that well-prepared benign data poses challenges for recent\nunlearning techniques, as erasing these synthetic instances demands higher\nresources than regular data. These insights underscore the need for future\nresearch to reconsider \"data poisoning\" in the context of machine unlearning.",
      "tldr_zh": "该论文探讨了机器取消学习（machine unlearning）中的新威胁，即利用良性数据（benign data）进行攻击。研究引入了Unlearning Usability Attack，这是一种模型无关、取消学习无关且低成本的方法，通过将数据分布信息浓缩成少量良性数据，这些数据不会被自动中毒检测工具识别，但却能显著破坏模型性能。实验结果显示，取消学习不超过1%的训练数据即可使模型准确率下降高达50%，并对现有取消学习技术提出挑战，因为处理这些合成数据需要更多资源。该研究强调，需要重新审视“数据中毒”（data poisoning）在机器取消学习中的含义，以提升系统的安全性。",
      "categories": [
        "cs.CR",
        "cs.AI"
      ],
      "primary_category": "cs.CR",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2407.05112v1",
      "published_date": "2024-07-06 15:42:28 UTC",
      "updated_date": "2024-07-06 15:42:28 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-19T04:06:25.118069"
    },
    {
      "arxiv_id": "2407.11042v1",
      "title": "An Automated Approach to Collecting and Labeling Time Series Data for Event Detection Using Elastic Node Hardware",
      "title_zh": "翻译失败",
      "authors": [
        "Tianheng Ling",
        "Islam Mansour",
        "Chao Qian",
        "Gregor Schiele"
      ],
      "abstract": "Recent advancements in IoT technologies have underscored the importance of\nusing sensor data to understand environmental contexts effectively. This paper\nintroduces a novel embedded system designed to autonomously label sensor data\ndirectly on IoT devices, thereby enhancing the efficiency of data collection\nmethods. We present an integrated hardware and software solution equipped with\nspecialized labeling sensors that streamline the capture and labeling of\ndiverse types of sensor data. By implementing local processing with lightweight\nlabeling methods, our system minimizes the need for extensive data transmission\nand reduces dependence on external resources. Experimental validation with\ncollected data and a Convolutional Neural Network model achieved a high\nclassification accuracy of up to 91.67%, as confirmed through 4-fold\ncross-validation. These results demonstrate the system's robust capability to\ncollect audio and vibration data with correct labels.",
      "tldr_zh": "本研究提出了一种自动化方法，用于收集和标记时序数据，以支持事件检测，特别利用弹性节点硬件（Elastic Node Hardware）提升 IoT 设备的数据处理效率。该方法通过一个集成硬件和软件的嵌入式系统，实现传感器数据的自主标记，使用专用标记传感器和本地轻量级处理技术，减少数据传输需求和外部资源依赖。实验结果显示，在音频和振动数据上应用 Convolutional Neural Network (CNN) 模型后，通过 4-fold cross-validation 验证，分类准确率高达 91.67%，证明了系统的鲁棒性和有效性。",
      "categories": [
        "cs.LG",
        "cs.AI"
      ],
      "primary_category": "cs.LG",
      "comment": "This paper is accepted by the 4th Workshop on Collaborative\n  Technologies and Data Science in Smart City Applications (CODASSCA 2024)",
      "pdf_url": "http://arxiv.org/pdf/2407.11042v1",
      "published_date": "2024-07-06 15:19:16 UTC",
      "updated_date": "2024-07-06 15:19:16 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-19T04:06:36.292170"
    },
    {
      "arxiv_id": "2407.05102v1",
      "title": "Towards Auto-Building of Embedded FPGA-based Soft Sensors for Wastewater Flow Estimation",
      "title_zh": "翻译失败",
      "authors": [
        "Tianheng Ling",
        "Chao Qian",
        "Gregor Schiele"
      ],
      "abstract": "Executing flow estimation using Deep Learning (DL)-based soft sensors on\nresource-limited IoT devices has demonstrated promise in terms of reliability\nand energy efficiency. However, its application in the field of wastewater flow\nestimation remains underexplored due to: (1) a lack of available datasets, (2)\ninconvenient toolchains for on-device AI model development and deployment, and\n(3) hardware platforms designed for general DL purposes rather than being\noptimized for energy-efficient soft sensor applications. This study addresses\nthese gaps by proposing an automated, end-to-end solution for wastewater flow\nestimation using a prototype IoT device.",
      "tldr_zh": "这篇论文探讨了使用DL-based软传感器在资源有限的IoT设备上进行废水流量估计的挑战，主要包括数据集缺乏、不便的工具链以及非优化的硬件平台。针对这些问题，研究者提出了一种自动化的端到端解决方案，利用嵌入式FPGA-based软传感器和原型IoT设备，实现高效的废水流量估计。该方法有望提升系统的可靠性和能源效率，为实际应用提供更便捷的框架。",
      "categories": [
        "eess.SP",
        "cs.AI"
      ],
      "primary_category": "eess.SP",
      "comment": "This paper is accepted by 2024 IEEE Annual Congress on Artificial\n  Intelligence of Things (IEEE AIoT)",
      "pdf_url": "http://arxiv.org/pdf/2407.05102v1",
      "published_date": "2024-07-06 15:10:27 UTC",
      "updated_date": "2024-07-06 15:10:27 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-19T04:06:49.812203"
    },
    {
      "arxiv_id": "2407.12051v1",
      "title": "Dy-mer: An Explainable DNA Sequence Representation Scheme using Sparse Recovery",
      "title_zh": "翻译失败",
      "authors": [
        "Zhiyuan Peng",
        "Yuanbo Tang",
        "Yang Li"
      ],
      "abstract": "DNA sequences encode vital genetic and biological information, yet these\nunfixed-length sequences cannot serve as the input of common data mining\nalgorithms. Hence, various representation schemes have been developed to\ntransform DNA sequences into fixed-length numerical representations. However,\nthese schemes face difficulties in learning high-quality representations due to\nthe complexity and sparsity of DNA data. Additionally, DNA sequences are\ninherently noisy because of mutations. While several schemes have been proposed\nfor their effectiveness, they often lack semantic structure, making it\ndifficult for biologists to validate and leverage the results. To address these\nchallenges, we propose \\textbf{Dy-mer}, an explainable and robust DNA\nrepresentation scheme based on sparse recovery. Leveraging the underlying\nsemantic structure of DNA, we modify the traditional sparse recovery to capture\nrecurring patterns indicative of biological functions by representing frequent\nK-mers as basis vectors and reconstructing each DNA sequence through simple\nconcatenation. Experimental results demonstrate that \\textbf{Dy-mer} achieves\nstate-of-the-art performance in DNA promoter classification, yielding a\nremarkable \\textbf{13\\%} increase in accuracy. Moreover, its inherent\nexplainability facilitates DNA clustering and motif detection, enhancing its\nutility in biological research.",
      "tldr_zh": "这篇论文提出了 Dy-mer，一种基于 sparse recovery 的可解释 DNA 序列表示方案，旨在解决传统方法在处理复杂、稀疏和噪声（如突变）DNA 数据时的局限性。Dy-mer 通过修改传统 sparse recovery 技术，将频繁的 K-mers 作为基向量并通过简单连接重建序列，从而捕获 DNA 的语义结构，提供更高质量的表示。实验结果显示，Dy-mer 在 DNA 启动子分类任务中实现了 state-of-the-art 性能，提高了 13% 的准确率，并增强了 DNA 聚类和基序检测的可解释性，为生物研究提供了更可靠的工具。",
      "categories": [
        "q-bio.GN",
        "cs.AI",
        "cs.LG"
      ],
      "primary_category": "q-bio.GN",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2407.12051v1",
      "published_date": "2024-07-06 15:08:31 UTC",
      "updated_date": "2024-07-06 15:08:31 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-19T04:07:01.514577"
    },
    {
      "arxiv_id": "2407.11041v4",
      "title": "Integer-only Quantized Transformers for Embedded FPGA-based Time-series Forecasting in AIoT",
      "title_zh": "仅整数量化的Transformer用于AIoT中基于嵌入式FPGA的时间序列预测",
      "authors": [
        "Tianheng Ling",
        "Chao Qian",
        "Gregor Schiele"
      ],
      "abstract": "This paper presents the design of a hardware accelerator for Transformers,\noptimized for on-device time-series forecasting in AIoT systems. It integrates\ninteger-only quantization and Quantization-Aware Training with optimized\nhardware designs to realize 6-bit and 4-bit quantized Transformer models, which\nachieved precision comparable to 8-bit quantized models from related research.\nUtilizing a complete implementation on an embedded FPGA (Xilinx Spartan-7\nXC7S15), we examine the feasibility of deploying Transformer models on embedded\nIoT devices. This includes a thorough analysis of achievable precision,\nresource utilization, timing, power, and energy consumption for on-device\ninference. Our results indicate that while sufficient performance can be\nattained, the optimization process is not trivial. For instance, reducing the\nquantization bitwidth does not consistently result in decreased latency or\nenergy consumption, underscoring the necessity of systematically exploring\nvarious optimization combinations. Compared to an 8-bit quantized Transformer\nmodel in related studies, our 4-bit quantized Transformer model increases test\nloss by only 0.63%, operates up to 132.33x faster, and consumes 48.19x less\nenergy.",
      "tldr_zh": "本论文设计了一种Integer-only Quantized Transformers硬件加速器，针对AIoT系统中嵌入式FPGA（Xilinx Spartan-7 XC7S15）的时序预测任务，通过整合Integer-only Quantization和Quantization-Aware Training，实现了6-bit和4-bit量化模型，其精度可与相关研究的8-bit模型媲美。实验分析了精度、资源利用、时序、功耗和能耗，结果表明4-bit量化模型的测试损失仅增加0.63%，速度提升132.33倍，能耗降低48.19倍。论文强调，减少量化位宽并不总是降低延迟或能耗，优化过程需要系统地探索多种组合，以实现高效的AIoT部署。",
      "categories": [
        "cs.LG",
        "cs.AI"
      ],
      "primary_category": "cs.LG",
      "comment": "Accepted by 2024 IEEE Annual Congress on Artificial Intelligence of\n  Things (IEEE AIoT) and got best paper award. 7 pages, 3 figures, 4 tables",
      "pdf_url": "http://arxiv.org/pdf/2407.11041v4",
      "published_date": "2024-07-06 15:03:40 UTC",
      "updated_date": "2024-10-04 10:15:10 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-19T04:07:13.800631"
    },
    {
      "arxiv_id": "2407.05098v2",
      "title": "FedTSA: A Cluster-based Two-Stage Aggregation Method for Model-heterogeneous Federated Learning",
      "title_zh": "翻译失败",
      "authors": [
        "Boyu Fan",
        "Chenrui Wu",
        "Xiang Su",
        "Pan Hui"
      ],
      "abstract": "Despite extensive research into data heterogeneity in federated learning\n(FL), system heterogeneity remains a significant yet often overlooked\nchallenge. Traditional FL approaches typically assume homogeneous hardware\nresources across FL clients, implying that clients can train a global model\nwithin a comparable time frame. However, in practical FL systems, clients often\nhave heterogeneous resources, which impacts their training capacity. This\ndiscrepancy underscores the importance of exploring model-heterogeneous FL, a\nparadigm allowing clients to train different models based on their resource\ncapabilities. To address this challenge, we introduce FedTSA, a cluster-based\ntwo-stage aggregation method tailored for system heterogeneity in FL. FedTSA\nbegins by clustering clients based on their capabilities, then performs a\ntwo-stage aggregation: conventional weight averaging for homogeneous models in\nStage 1, and deep mutual learning with a diffusion model for aggregating\nheterogeneous models in Stage 2. Extensive experiments demonstrate that FedTSA\nnot only outperforms the baselines but also explores various factors\ninfluencing model performance, validating FedTSA as a promising approach for\nmodel-heterogeneous FL.",
      "tldr_zh": "联邦学习 (FL) 中，系统异质性问题常被忽略，导致客户端资源差异影响模型训练，FedTSA 提出了一种基于集群的二阶段聚合方法来解决模型异质 FL 挑战。方法首先将客户端按能力进行集群，然后在第一阶段对同质模型执行常规权重平均，在第二阶段使用深度互学习 (deep mutual learning) 和扩散模型 (diffusion model) 聚合异质模型。通过广泛实验，FedTSA 优于基线模型，并分析了影响性能的各种因素，证明其是处理系统异质性的有效方法。",
      "categories": [
        "cs.LG",
        "cs.AI"
      ],
      "primary_category": "cs.LG",
      "comment": "Accepted at ECCV 2024",
      "pdf_url": "http://arxiv.org/pdf/2407.05098v2",
      "published_date": "2024-07-06 14:59:55 UTC",
      "updated_date": "2024-07-15 08:19:30 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-19T04:07:26.088645"
    },
    {
      "arxiv_id": "2407.06227v2",
      "title": "Communication and Control Co-Design in 6G: Sequential Decision-Making with LLMs",
      "title_zh": "翻译失败",
      "authors": [
        "Xianfu Chen",
        "Celimuge Wu",
        "Yi Shen",
        "Yusheng Ji",
        "Tsutomu Yoshinaga",
        "Qiang Ni",
        "Charilaos C. Zarakovitis",
        "Honggang Zhang"
      ],
      "abstract": "This article investigates a control system within the context of\nsix-generation wireless networks. The control performance optimization\nconfronts the technical challenges that arise from the intricate interactions\nbetween communication and control sub-systems, asking for a co-design.\nAccounting for the system dynamics, we formulate the sequential co-design\ndecision-makings of communication and control over the discrete time horizon as\na Markov decision process, for which a practical offline learning framework is\nproposed. Our proposed framework integrates large language models into the\nelements of reinforcement learning. We present a case study on the age of\nsemantics-aware communication and control co-design to showcase the potentials\nfrom our proposed learning framework. Furthermore, we discuss the open issues\nremaining to make our proposed offline learning framework feasible for\nreal-world implementations, and highlight the research directions for future\nexplorations.",
      "tldr_zh": "本论文探讨了6G无线网络中通信和控制子系统的联合设计问题，旨在优化控制性能以应对两者之间复杂交互的挑战。作者将顺序决策过程建模为Markov decision process (MDP)，并提出一个整合large language models (LLMs)的离线学习框架，嵌入强化学习元素来处理离散时间决策。通过一个语义感知通信和控制联合设计的案例研究，展示了该框架的潜力，并讨论了其在实际实现中的开放问题及未来研究方向。该方法为6G系统的可靠性和效率提供了新颖的路径。",
      "categories": [
        "eess.SY",
        "cs.AI",
        "cs.SY"
      ],
      "primary_category": "eess.SY",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2407.06227v2",
      "published_date": "2024-07-06 14:49:46 UTC",
      "updated_date": "2024-09-09 11:38:24 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-19T04:07:36.514585"
    },
    {
      "arxiv_id": "2407.05087v1",
      "title": "Linear Attention Based Deep Nonlocal Means Filtering for Multiplicative Noise Removal",
      "title_zh": "基于线性注意力的深度非局部均值过滤，用于去除乘性噪声",
      "authors": [
        "Xiao Siyao",
        "Huang Libing",
        "Zhang Shunsheng"
      ],
      "abstract": "Multiplicative noise widely exists in radar images, medical images and other\nimportant fields' images. Compared to normal noises, multiplicative noise has a\ngenerally stronger effect on the visual expression of images. Aiming at the\ndenoising problem of multiplicative noise, we linearize the nonlocal means\nalgorithm with deep learning and propose a linear attention mechanism based\ndeep nonlocal means filtering (LDNLM). Starting from the traditional nonlocal\nmeans filtering, we employ deep channel convolution neural networks to extract\nthe information of the neighborhood matrix and obtain representation vectors of\nevery pixel. Then we replace the similarity calculation and weighted averaging\nprocesses with the inner operations of the attention mechanism. To reduce the\ncomputational overhead, through the formula of similarity calculation and\nweighted averaging, we derive a nonlocal filter with linear complexity.\nExperiments on both simulated and real multiplicative noise demonstrate that\nthe LDNLM is more competitive compared with the state-of-the-art methods.\nAdditionally, we prove that the LDNLM possesses interpretability close to\ntraditional NLM.",
      "tldr_zh": "本文针对乘性噪声（multiplicative noise）在雷达图像和医疗图像等领域的去噪问题，提出了一种基于线性注意力机制的深度非局部均值过滤（LDNLM）。该方法从传统的非局部均值过滤（nonlocal means filtering）出发，使用深度通道卷积神经网络提取像素邻域矩阵的信息，并通过注意力机制替换相似性计算和加权平均过程，以实现线性复杂度并减少计算开销。实验结果表明，LDNLM 在模拟和真实噪声数据集上比最先进方法更具竞争力，同时保持了接近传统 NLM 的可解释性。",
      "categories": [
        "eess.IV",
        "cs.AI",
        "cs.CV"
      ],
      "primary_category": "eess.IV",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2407.05087v1",
      "published_date": "2024-07-06 14:22:07 UTC",
      "updated_date": "2024-07-06 14:22:07 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-19T04:07:49.714495"
    },
    {
      "arxiv_id": "2407.05082v1",
      "title": "DMTG: One-Shot Differentiable Multi-Task Grouping",
      "title_zh": "DMTG：一次性可微多任务分组",
      "authors": [
        "Yuan Gao",
        "Shuguo Jiang",
        "Moran Li",
        "Jin-Gang Yu",
        "Gui-Song Xia"
      ],
      "abstract": "We aim to address Multi-Task Learning (MTL) with a large number of tasks by\nMulti-Task Grouping (MTG). Given N tasks, we propose to simultaneously identify\nthe best task groups from 2^N candidates and train the model weights\nsimultaneously in one-shot, with the high-order task-affinity fully exploited.\nThis is distinct from the pioneering methods which sequentially identify the\ngroups and train the model weights, where the group identification often relies\non heuristics. As a result, our method not only improves the training\nefficiency, but also mitigates the objective bias introduced by the sequential\nprocedures that potentially lead to a suboptimal solution. Specifically, we\nformulate MTG as a fully differentiable pruning problem on an adaptive network\narchitecture determined by an underlying Categorical distribution. To\ncategorize N tasks into K groups (represented by K encoder branches), we\ninitially set up KN task heads, where each branch connects to all N task heads\nto exploit the high-order task-affinity. Then, we gradually prune the KN heads\ndown to N by learning a relaxed differentiable Categorical distribution,\nensuring that each task is exclusively and uniquely categorized into only one\nbranch. Extensive experiments on CelebA and Taskonomy datasets with detailed\nablations show the promising performance and efficiency of our method. The\ncodes are available at https://github.com/ethanygao/DMTG.",
      "tldr_zh": "该研究提出了一种名为 DMTG 的 one-shot 可微多任务分组方法，用于处理大规模 Multi-Task Learning (MTL)，它能同时从 2^N 个候选中识别最佳任务分组并训练模型权重，充分利用高阶任务亲和性 (high-order task-affinity)。与传统顺序方法不同，DMTG 将多任务分组表述为一个完全可微的剪枝问题，利用自适应网络架构和 Categorical 分布，从初始的 KN 个任务头逐步剪枝到 N 个，确保每个任务唯一分配到一个分支，从而提高训练效率并减少潜在偏差。实验在 CelebA 和 Taskonomy 数据集上证明了 DMTG 的优越性能和效率，代码已开源于 GitHub。",
      "categories": [
        "cs.LG",
        "cs.AI",
        "cs.CV",
        "stat.ML"
      ],
      "primary_category": "cs.LG",
      "comment": "Accepted to ICML 2024",
      "pdf_url": "http://arxiv.org/pdf/2407.05082v1",
      "published_date": "2024-07-06 13:54:00 UTC",
      "updated_date": "2024-07-06 13:54:00 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-19T04:08:02.492913"
    },
    {
      "arxiv_id": "2407.05079v1",
      "title": "Form Forge: Latent Space Exploration of Architectural Forms via Explicit Latent Variable Manipulation",
      "title_zh": "翻译失败",
      "authors": [
        "Kevin Dunnell",
        "Andy Lippman"
      ],
      "abstract": "This paper presents 'Form Forge,' a prototype of a creative system for\ninteractively exploring the latent space of architectural forms, inspired by\nFranois Blanciak's SITELESS: 1001 Building Forms via direct manipulation of\nlatent variables. Utilizing a fine-tuned StyleGAN2-ADA model, the system allows\nusers to navigate an array of possible building forms derived from Blanciak's\nsketches. Distinct from common latent space exploration tools that often rely\non projected navigation landmarks, Form Forge provides direct access to\nmanipulate each latent variable, aiming to offer a more granular exploration of\nthe model's capabilities. Form Forge's design is intended to simplify the\ninteraction with a complex, high-dimensional space and to serve as a\npreliminary investigation into how such tools might support creative processes\nin architectural design.",
      "tldr_zh": "本研究提出“Form Forge”，一个交互式创意系统，用于探索建筑形式的潜在空间(latent space)，灵感来源于François Blanciak的SITELESS: 1001 Building Forms。系统利用fine-tuned StyleGAN2-ADA模型，允许用户直接操纵每个潜在变量(latent variable)，从而实现比传统投影导航地标更细粒度的探索。Form Forge旨在简化高维空间的交互，并作为初步调查，支持建筑设计中的创意过程。",
      "categories": [
        "cs.HC",
        "cs.AI"
      ],
      "primary_category": "cs.HC",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2407.05079v1",
      "published_date": "2024-07-06 13:46:23 UTC",
      "updated_date": "2024-07-06 13:46:23 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-19T04:08:13.671581"
    },
    {
      "arxiv_id": "2407.05058v1",
      "title": "Advancing Algorithmic Approaches to Probabilistic Argumentation under the Constellation Approach",
      "title_zh": "翻译失败",
      "authors": [
        "Andrei Popescu",
        "Johannes P. Wallner"
      ],
      "abstract": "Reasoning with defeasible and conflicting knowledge in an argumentative form\nis a key research field in computational argumentation. Reasoning under various\nforms of uncertainty is both a key feature and a challenging barrier for\nautomated argumentative reasoning. It was shown that argumentative reasoning\nusing probabilities faces in general high computational complexity, in\nparticular for the so-called constellation approach. In this paper, we develop\nan algorithmic approach to overcome this obstacle. We refine existing\ncomplexity results and show that two main reasoning tasks, that of computing\nthe probability of a given set being an extension and an argument being\nacceptable, diverge in their complexity: the former is #P-complete and the\nlatter is #-dot-NP-complete when considering their underlying counting\nproblems. We present an algorithm for the complex task of computing the\nprobability of a set of arguments being a complete extension by using dynamic\nprogramming operating on tree-decompositions. An experimental evaluation shows\npromise of our approach.",
      "tldr_zh": "该论文推进了在 Constellation Approach 下概率论辩的算法方法，以应对不确定性环境下论证推理的高计算复杂度问题。研究者细化了现有复杂度结果，发现计算一组论点是扩展的概率为 #P-complete，而论点可接受性的概率为 #-dot-NP-complete。论文提出了一种基于动态编程和树分解的算法，用于计算论点集是完整扩展的概率，并通过实验评估证明了该方法的有效性。",
      "categories": [
        "cs.AI"
      ],
      "primary_category": "cs.AI",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2407.05058v1",
      "published_date": "2024-07-06 12:08:38 UTC",
      "updated_date": "2024-07-06 12:08:38 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-19T04:08:26.453789"
    },
    {
      "arxiv_id": "2407.05047v3",
      "title": "MFE-ETP: A Comprehensive Evaluation Benchmark for Multi-modal Foundation Models on Embodied Task Planning",
      "title_zh": "翻译失败",
      "authors": [
        "Min Zhang",
        "Xian Fu",
        "Jianye Hao",
        "Peilong Han",
        "Hao Zhang",
        "Lei Shi",
        "Hongyao Tang",
        "Yan Zheng"
      ],
      "abstract": "In recent years, Multi-modal Foundation Models (MFMs) and Embodied Artificial\nIntelligence (EAI) have been advancing side by side at an unprecedented pace.\nThe integration of the two has garnered significant attention from the AI\nresearch community. In this work, we attempt to provide an in-depth and\ncomprehensive evaluation of the performance of MFM s on embodied task planning,\naiming to shed light on their capabilities and limitations in this domain. To\nthis end, based on the characteristics of embodied task planning, we first\ndevelop a systematic evaluation framework, which encapsulates four crucial\ncapabilities of MFMs: object understanding, spatio-temporal perception, task\nunderstanding, and embodied reasoning. Following this, we propose a new\nbenchmark, named MFE-ETP, characterized its complex and variable task\nscenarios, typical yet diverse task types, task instances of varying\ndifficulties, and rich test case types ranging from multiple embodied question\nanswering to embodied task reasoning. Finally, we offer a simple and\neasy-to-use automatic evaluation platform that enables the automated testing of\nmultiple MFMs on the proposed benchmark. Using the benchmark and evaluation\nplatform, we evaluated several state-of-the-art MFMs and found that they\nsignificantly lag behind human-level performance. The MFE-ETP is a\nhigh-quality, large-scale, and challenging benchmark relevant to real-world\ntasks.",
      "tldr_zh": "这篇论文提出了一种全面评价基准 MFE-ETP，用于评估 Multi-modal Foundation Models (MFMs) 在 Embodied Task Planning 中的性能，旨在揭示其能力和局限性。论文基于 embodied task planning 的特性，开发了一个系统评价框架，包括 object understanding、spatio-temporal perception、task understanding 和 embodied reasoning 等四个关键能力，并设计了复杂任务场景、多样化任务类型和丰富测试案例的基准。实验结果显示，现有 MFMs 的表现远低于人类水平，而该基准作为高质量、大规模的工具，为真实世界任务相关研究提供了宝贵挑战。",
      "categories": [
        "cs.AI"
      ],
      "primary_category": "cs.AI",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2407.05047v3",
      "published_date": "2024-07-06 11:07:18 UTC",
      "updated_date": "2024-10-07 14:05:05 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-19T04:08:39.580102"
    },
    {
      "arxiv_id": "2407.05015v1",
      "title": "How do you know that? Teaching Generative Language Models to Reference Answers to Biomedical Questions",
      "title_zh": "翻译失败",
      "authors": [
        "Bojana Bašaragin",
        "Adela Ljajić",
        "Darija Medvecki",
        "Lorenzo Cassano",
        "Miloš Košprdić",
        "Nikola Milošević"
      ],
      "abstract": "Large language models (LLMs) have recently become the leading source of\nanswers for users' questions online. Despite their ability to offer eloquent\nanswers, their accuracy and reliability can pose a significant challenge. This\nis especially true for sensitive domains such as biomedicine, where there is a\nhigher need for factually correct answers. This paper introduces a biomedical\nretrieval-augmented generation (RAG) system designed to enhance the reliability\nof generated responses. The system is based on a fine-tuned LLM for the\nreferenced question-answering, where retrieved relevant abstracts from PubMed\nare passed to LLM's context as input through a prompt. Its output is an answer\nbased on PubMed abstracts, where each statement is referenced accordingly,\nallowing the users to verify the answer. Our retrieval system achieves an\nabsolute improvement of 23% compared to the PubMed search engine. Based on the\nmanual evaluation on a small sample, our fine-tuned LLM component achieves\ncomparable results to GPT-4 Turbo in referencing relevant abstracts. We make\nthe dataset used to fine-tune the models and the fine-tuned models based on\nMistral-7B-instruct-v0.1 and v0.2 publicly available.",
      "tldr_zh": "本论文探讨了大型语言模型 (LLMs) 在生物医学问答中的准确性和可靠性问题，提出了一种生物医学检索增强生成 (RAG) 系统，以提升响应可靠性。该系统通过微调 LLM 并从 PubMed 检索相关摘要，将这些摘要作为输入提示，生成基于引用的答案，每个语句均附带来源以便用户验证。实验结果显示，该检索系统较 PubMed 搜索引擎绝对提升 23%，而微调的 LLM 在引用相关摘要方面与 GPT-4 Turbo 相当。最后，作者公开了用于微调的数据集和基于 Mistral-7B-instruct-v0.1/v0.2 的模型，促进进一步研究。",
      "categories": [
        "cs.CL",
        "cs.AI"
      ],
      "primary_category": "cs.CL",
      "comment": "Accepted at BioNLP Workshop 2024, colocated with ACL 2024",
      "pdf_url": "http://arxiv.org/pdf/2407.05015v1",
      "published_date": "2024-07-06 09:10:05 UTC",
      "updated_date": "2024-07-06 09:10:05 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-19T04:08:52.081334"
    },
    {
      "arxiv_id": "2407.04997v1",
      "title": "Achieving Tool Calling Functionality in LLMs Using Only Prompt Engineering Without Fine-Tuning",
      "title_zh": "翻译失败",
      "authors": [
        "Shengtao He"
      ],
      "abstract": "Currently, the vast majority of locally deployed open-source large language\nmodels (LLMs) and some commercial model interfaces do not support stable tool\ncalling functionality. The existing solution involves fine-tuning LLMs, which\nresults in significant time and computational resource consumption. This paper\nproposes a method that enables LLMs to achieve stable tool calling capabilities\nusing only prompt engineering and some ingenious code design. We conducted\nexperiments on multiple LLMs that lack tool calling capabilities across various\ntool calling tasks, achieving a success rate of 100%.",
      "tldr_zh": "这篇论文提出了一种创新方法，使用仅提示工程(prompt engineering)和巧妙代码设计，使大型语言模型(LLMs)实现稳定的工具调用功能，而无需进行微调，从而避免了高昂的时间和计算资源消耗。实验在多种缺乏工具调用能力的LLMs上进行，涵盖各种任务，并取得了100%的成功率。该方法为提升LLMs的功能扩展提供了高效、可复制的解决方案。",
      "categories": [
        "cs.SE",
        "cs.AI",
        "cs.HC",
        "I.2.7"
      ],
      "primary_category": "cs.SE",
      "comment": "5 pages, 2 figures,review comments welcome",
      "pdf_url": "http://arxiv.org/pdf/2407.04997v1",
      "published_date": "2024-07-06 08:29:12 UTC",
      "updated_date": "2024-07-06 08:29:12 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-19T04:09:01.548889"
    },
    {
      "arxiv_id": "2407.11040v1",
      "title": "High-Quality and Full Bandwidth Seismic Signal Synthesis using Operational GANs",
      "title_zh": "基于操作型 GANs 的高质量全带宽地震信号合成",
      "authors": [
        "Ozer Can Devecioglu",
        "Serkan Kiranyaz",
        "Zafer Yilmaz",
        "Onur Avci",
        "Moncef Gabbouj",
        "Ertugrul Taciroglu"
      ],
      "abstract": "Vibration sensors are essential in acquiring seismic activity for an accurate\nearthquake assessment. The state-of-the-art sensors can provide the best signal\nquality and the highest bandwidth; however, their high cost usually hinders a\nwide range of applicability and coverage, which is otherwise possible with\ntheir basic and cheap counterparts. But, their poor quality and low bandwidth\ncan significantly degrade the signal fidelity and result in an imprecise\nanalysis. To address these drawbacks, in this study, we propose a novel,\nhigh-quality, and full bandwidth seismic signal synthesis by transforming the\nsignal acquired from an inferior sensor. We employ 1D Operational Generative\nAdversarial Networks (Op-GANs) with novel loss functions to achieve this.\nTherefore, the study's key contributions include releasing a new dataset,\naddressing operational constraints in seismic monitoring, and pioneering a\ndeep-learning transformation technique to create the first virtual seismic\nsensor. The proposed method is extensively evaluated over the Simulated Ground\nMotion (SimGM) benchmark dataset, and the results demonstrated that the\nproposed approach significantly improves the quality and bandwidth of seismic\nsignals acquired from a variety of sensors, including a cheap seismic sensor,\nthe CSN-Phidgets, and the integrated accelerometers of an Android, and iOS\nphone, to the same level as the state-of-the-art sensor (e.g.,\nKinemetrics-Episensor). The SimGM dataset, our results, and the optimized\nPyTorch implementation of the proposed approach are publicly shared.",
      "tldr_zh": "本研究针对高端地震振动传感器成本高的问题，提出一种利用1D Operational GANs（Op-GANs）及其新型损失函数的方法，将低端传感器的低质量、低带宽地震信号转化为高质量、全带宽信号。关键贡献包括发布新数据集SimGM、解决地震监测中的操作约束，以及开创深度学习转换技术以创建首个虚拟地震传感器。该方法在SimGM基准数据集上进行评估，结果显示显著提升了多种传感器（如CSN-Phidgets和手机加速度计）的信号质量，使其达到高端传感器（如Kinemetrics-Episensor）的水平，并公开共享数据集、结果及优化PyTorch实现。",
      "categories": [
        "cs.LG",
        "cs.AI"
      ],
      "primary_category": "cs.LG",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2407.11040v1",
      "published_date": "2024-07-06 08:07:23 UTC",
      "updated_date": "2024-07-06 08:07:23 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-19T04:09:14.503875"
    },
    {
      "arxiv_id": "2407.04992v2",
      "title": "Scalable Variational Causal Discovery Unconstrained by Acyclicity",
      "title_zh": "翻译失败",
      "authors": [
        "Nu Hoang",
        "Bao Duong",
        "Thin Nguyen"
      ],
      "abstract": "Bayesian causal discovery offers the power to quantify epistemic\nuncertainties among a broad range of structurally diverse causal theories\npotentially explaining the data, represented in forms of directed acyclic\ngraphs (DAGs). However, existing methods struggle with efficient DAG sampling\ndue to the complex acyclicity constraint. In this study, we propose a scalable\nBayesian approach to effectively learn the posterior distribution over causal\ngraphs given observational data thanks to the ability to generate DAGs without\nexplicitly enforcing acyclicity. Specifically, we introduce a novel\ndifferentiable DAG sampling method that can generate a valid acyclic causal\ngraph by mapping an unconstrained distribution of implicit topological orders\nto a distribution over DAGs. Given this efficient DAG sampling scheme, we are\nable to model the posterior distribution over causal graphs using a simple\nvariational distribution over a continuous domain, which can be learned via the\nvariational inference framework. Extensive empirical experiments on both\nsimulated and real datasets demonstrate the superior performance of the\nproposed model compared to several state-of-the-art baselines.",
      "tldr_zh": "本文提出了一种可扩展的 Bayesian 因果发现方法，旨在克服现有技术在采样 directed acyclic graphs (DAGs) 时因 acyclicity 约束带来的效率问题。该方法引入一种新型可微 DAG 采样技术，通过将无约束的隐式拓扑顺序映射到 DAG 分布，并利用 variational inference 框架学习因果图的后验分布。实验在模拟和真实数据集上表明，该模型的表现优于多项 state-of-the-art 基线，显著提升了因果发现的准确性和可扩展性。",
      "categories": [
        "cs.LG",
        "cs.AI",
        "stat.ME"
      ],
      "primary_category": "cs.LG",
      "comment": "Accepted at ECAI 2024",
      "pdf_url": "http://arxiv.org/pdf/2407.04992v2",
      "published_date": "2024-07-06 07:56:23 UTC",
      "updated_date": "2024-08-29 00:40:05 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-19T04:09:25.792099"
    },
    {
      "arxiv_id": "2407.04990v1",
      "title": "Conditional Semi-Supervised Data Augmentation for Spam Message Detection with Low Resource Data",
      "title_zh": "翻译失败",
      "authors": [
        "Ulin Nuha",
        "Chih-Hsueh Lin"
      ],
      "abstract": "Several machine learning schemes have attempted to perform the detection of\nspam messages. However, those schemes mostly require a huge amount of labeled\ndata. The existing techniques addressing the lack of data availability have\nissues with effectiveness and robustness. Therefore, this paper proposes a\nconditional semi-supervised data augmentation (CSSDA) for a spam detection\nmodel lacking the availability of data. The main architecture of CSSDA\ncomprises feature extraction and enhanced generative network. Here, we exploit\nunlabeled data for data augmentation to extend training data. The enhanced\ngenerative in our proposed scheme produces latent variables as fake samples\nfrom unlabeled data through a conditional scheme. Latent variables can come\nfrom labeled and unlabeled data as the input for the final classifier in our\nspam detection model. The experimental results indicate that our proposed CSSDA\nachieves excellent results compared to several related methods both exploiting\nunlabeled data and not. In the experiment stage with various amounts of\nunlabeled data, CSSDA is the only robust model that obtains a balanced accuracy\nof about 85% when the availability of labeled data is large. We also conduct\nseveral ablation studies to investigate our proposed scheme in detail. The\nresult also shows that several ablation studies strengthen our proposed\ninnovations. These experiments indicate that unlabeled data has a significant\ncontribution to data augmentation using the conditional semi-supervised scheme\nfor spam detection.",
      "tldr_zh": "本文提出了一种条件半监督数据增强（CSSDA）方法，用于在数据资源有限的情况下进行垃圾邮件检测（spam message detection），以解决现有方法对大量标记数据的依赖和鲁棒性不足问题。CSSDA 的架构包括特征提取和增强生成网络，通过利用未标记数据生成潜在变量作为假样本，从而扩展训练数据集并提高模型性能。实验结果表明，该方法在各种未标记数据量下表现出色，比相关基线模型更鲁棒，平衡准确率可达约85%，并通过消融研究证实了未标记数据在条件半监督方案中的显著贡献。",
      "categories": [
        "cs.AI",
        "cs.CL"
      ],
      "primary_category": "cs.AI",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2407.04990v1",
      "published_date": "2024-07-06 07:51:24 UTC",
      "updated_date": "2024-07-06 07:51:24 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-19T04:09:39.074242"
    },
    {
      "arxiv_id": "2407.04986v1",
      "title": "Calorie Burn Estimation in Community Parks Through DLICP: A Mathematical Modelling Approach",
      "title_zh": "翻译失败",
      "authors": [
        "Abhishek Sebastian",
        "Annis Fathima A",
        "Pragna R",
        "Madhan Kumar S",
        "Jesher Joshua M"
      ],
      "abstract": "Community parks play a crucial role in promoting physical activity and\noverall well-being. This study introduces DLICP (Deep Learning Integrated\nCommunity Parks), an innovative approach that combines deep learning techniques\nspecifically, face recognition technology with a novel walking activity\nmeasurement algorithm to enhance user experience in community parks. The DLICP\nutilizes a camera with face recognition software to accurately identify and\ntrack park users. Simultaneously, a walking activity measurement algorithm\ncalculates parameters such as the average pace and calories burned, tailored to\nindividual attributes. Extensive evaluations confirm the precision of DLICP,\nwith a Mean Absolute Error (MAE) of 5.64 calories and a Mean Percentage Error\n(MPE) of 1.96%, benchmarked against widely available fitness measurement\ndevices, such as the Apple Watch Series 6. This study contributes significantly\nto the development of intelligent smart park systems, enabling real-time\nupdates on burned calories and personalized fitness tracking.",
      "tldr_zh": "本研究提出DLICP（Deep Learning Integrated Community Parks），一种结合深度学习人脸识别技术和步行活动测量算法的系统，用于社区公园中估算卡路里消耗。系统通过带有人脸识别软件的摄像头识别并跟踪用户，同时根据个人属性计算平均步速和卡路里燃烧参数。实验评估显示，DLICP的Mean Absolute Error (MAE)为5.64卡路里，Mean Percentage Error (MPE)为1.96%，与Apple Watch Series 6等设备相比具有较高精确性。该方法为智能公园系统的发展做出了贡献，支持实时卡路里更新和个性化健身跟踪。",
      "categories": [
        "cs.CV",
        "cs.AI",
        "cs.LG"
      ],
      "primary_category": "cs.CV",
      "comment": "Accepted and to be presented at Intellisys 2024 , Also Part of the\n  Indian Patent: 202441050325",
      "pdf_url": "http://arxiv.org/pdf/2407.04986v1",
      "published_date": "2024-07-06 07:45:05 UTC",
      "updated_date": "2024-07-06 07:45:05 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-19T04:09:50.767728"
    },
    {
      "arxiv_id": "2407.04980v2",
      "title": "Enabling Causal Discovery in Post-Nonlinear Models with Normalizing Flows",
      "title_zh": "翻译失败",
      "authors": [
        "Nu Hoang",
        "Bao Duong",
        "Thin Nguyen"
      ],
      "abstract": "Post-nonlinear (PNL) causal models stand out as a versatile and adaptable\nframework for modeling intricate causal relationships. However, accurately\ncapturing the invertibility constraint required in PNL models remains\nchallenging in existing studies. To address this problem, we introduce CAF-PoNo\n(Causal discovery via Normalizing Flows for Post-Nonlinear models), harnessing\nthe power of the normalizing flows architecture to enforce the crucial\ninvertibility constraint in PNL models. Through normalizing flows, our method\nprecisely reconstructs the hidden noise, which plays a vital role in\ncause-effect identification through statistical independence testing.\nFurthermore, the proposed approach exhibits remarkable extensibility, as it can\nbe seamlessly expanded to facilitate multivariate causal discovery via causal\norder identification, empowering us to efficiently unravel complex causal\nrelationships. Extensive experimental evaluations on both simulated and real\ndatasets consistently demonstrate that the proposed method outperforms several\nstate-of-the-art approaches in both bivariate and multivariate causal discovery\ntasks.",
      "tldr_zh": "本研究针对 Post-Nonlinear (PNL) 因果模型中难以捕获的 invertibility 约束问题，提出 CAF-PoNo 方法，利用 Normalizing Flows 架构来强制这一约束，并通过重建隐藏噪声和统计独立性测试来精确识别因果关系。CAF-PoNo 不仅适用于二元因果发现，还可扩展到多变量场景，通过识别因果顺序来揭示复杂关系。实验结果显示，该方法在模拟和真实数据集上优于现有技术，在二元和多变量因果发现任务中表现出显著优势。",
      "categories": [
        "cs.LG",
        "cs.AI",
        "stat.ME"
      ],
      "primary_category": "cs.LG",
      "comment": "Acepted at ECAI 2024",
      "pdf_url": "http://arxiv.org/pdf/2407.04980v2",
      "published_date": "2024-07-06 07:19:21 UTC",
      "updated_date": "2024-08-29 00:34:59 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-19T04:10:03.428715"
    },
    {
      "arxiv_id": "2407.04973v1",
      "title": "LogicVista: Multimodal LLM Logical Reasoning Benchmark in Visual Contexts",
      "title_zh": "LogicVista：视觉上下文中的多模态LLM逻辑推理基准",
      "authors": [
        "Yijia Xiao",
        "Edward Sun",
        "Tianyu Liu",
        "Wei Wang"
      ],
      "abstract": "We propose LogicVista, an evaluation benchmark that assesses the integrated\nlogical reasoning capabilities of multimodal large language models (MLLMs) in\nVisual contexts. Recent advancements in MLLMs have demonstrated various\nfascinating abilities, from crafting poetry based on an image to performing\nmathematical reasoning. However, there is still a lack of systematic evaluation\nof MLLMs' proficiency in logical reasoning tasks, which are essential for\nactivities like navigation and puzzle-solving. Thus we evaluate general logical\ncognition abilities across 5 logical reasoning tasks encompassing 9 different\ncapabilities, using a sample of 448 multiple-choice questions. Each question is\nannotated with the correct answer and the human-written reasoning behind the\nselection, enabling both open-ended and multiple-choice evaluation. A total of\n8 MLLMs are comprehensively evaluated using LogicVista. Code and Data Available\nat https://github.com/Yijia-Xiao/LogicVista.",
      "tldr_zh": "我们提出 LogicVista，这是一个评估多模态大型语言模型 (MLLMs) 在视觉上下文中的逻辑推理能力的基准，旨在填补现有评估的系统性空白。基准涵盖 5 个逻辑推理任务和 9 种能力，使用 448 个多选题，每题包括正确答案和人类编写的推理解释，支持开放式和多选评估。我们对 8 个 MLLMs 进行了全面评估，实验结果显示了这些模型的逻辑认知水平，相关代码和数据可在 GitHub 获取。",
      "categories": [
        "cs.AI",
        "cs.CL",
        "cs.CV",
        "cs.LG"
      ],
      "primary_category": "cs.AI",
      "comment": "LogicVista benchmarks the logical reasoning of multimodal large\n  language models in visual tasks",
      "pdf_url": "http://arxiv.org/pdf/2407.04973v1",
      "published_date": "2024-07-06 06:48:16 UTC",
      "updated_date": "2024-07-06 06:48:16 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-19T04:10:15.948049"
    },
    {
      "arxiv_id": "2407.04964v1",
      "title": "ZOBNN: Zero-Overhead Dependable Design of Binary Neural Networks with Deliberately Quantized Parameters",
      "title_zh": "翻译失败",
      "authors": [
        "Behnam Ghavami",
        "Mohammad Shahidzadeh",
        "Lesley Shannon",
        "Steve Wilton"
      ],
      "abstract": "Low-precision weights and activations in deep neural networks (DNNs)\noutperform their full-precision counterparts in terms of hardware efficiency.\nWhen implemented with low-precision operations, specifically in the extreme\ncase where network parameters are binarized (i.e. BNNs), the two most\nfrequently mentioned benefits of quantization are reduced memory consumption\nand a faster inference process. In this paper, we introduce a third advantage\nof very low-precision neural networks: improved fault-tolerance attribute. We\ninvestigate the impact of memory faults on state-of-the-art binary neural\nnetworks (BNNs) through comprehensive analysis. Despite the inclusion of\nfloating-point parameters in BNN architectures to improve accuracy, our\nfindings reveal that BNNs are highly sensitive to deviations in these\nparameters caused by memory faults. In light of this crucial finding, we\npropose a technique to improve BNN dependability by restricting the range of\nfloat parameters through a novel deliberately uniform quantization. The\nintroduced quantization technique results in a reduction in the proportion of\nfloating-point parameters utilized in the BNN, without incurring any additional\ncomputational overheads during the inference stage. The extensive experimental\nfault simulation on the proposed BNN architecture (i.e. ZOBNN) reveal a\nremarkable 5X enhancement in robustness compared to conventional floating-point\nDNN. Notably, this improvement is achieved without incurring any computational\noverhead. Crucially, this enhancement comes without computational overhead.\n\\ToolName~excels in critical edge applications characterized by limited\ncomputational resources, prioritizing both dependability and real-time\nperformance.",
      "tldr_zh": "该论文提出 ZOBNN，一种零开销的二进制神经网络 (BNNs) 设计方法，通过 deliberate uniform quantization 技术来量化浮点参数，从而提升网络的故障容错性。研究发现，现有的 BNNs 对内存故障高度敏感，因此新方法限制了浮点参数的范围，减少了其比例，同时不增加推理阶段的计算开销。实验结果显示，ZOBNN 的鲁棒性比传统浮点深度神经网络 (DNNs) 提高了 5 倍，并适用于计算资源有限的边缘应用，优先考虑可靠性和实时性能。",
      "categories": [
        "cs.AI"
      ],
      "primary_category": "cs.AI",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2407.04964v1",
      "published_date": "2024-07-06 05:31:11 UTC",
      "updated_date": "2024-07-06 05:31:11 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-19T04:10:27.510595"
    },
    {
      "arxiv_id": "2407.12848v2",
      "title": "Applicability of Large Language Models and Generative Models for Legal Case Judgement Summarization",
      "title_zh": "大型语言模型和生成模型在法律案件判决总结中的适用性",
      "authors": [
        "Aniket Deroy",
        "Kripabandhu Ghosh",
        "Saptarshi Ghosh"
      ],
      "abstract": "Automatic summarization of legal case judgements, which are known to be long\nand complex, has traditionally been tried via extractive summarization models.\nIn recent years, generative models including abstractive summarization models\nand Large language models (LLMs) have gained huge popularity. In this paper, we\nexplore the applicability of such models for legal case judgement\nsummarization. We applied various domain specific abstractive summarization\nmodels and general domain LLMs as well as extractive summarization models over\ntwo sets of legal case judgements from the United Kingdom (UK) Supreme Court\nand the Indian (IN) Supreme Court and evaluated the quality of the generated\nsummaries. We also perform experiments on a third dataset of legal documents of\na different type, Government reports from the United States (US). Results show\nthat abstractive summarization models and LLMs generally perform better than\nthe extractive methods as per traditional metrics for evaluating summary\nquality. However, detailed investigation shows the presence of inconsistencies\nand hallucinations in the outputs of the generative models, and we explore ways\nto reduce the hallucinations and inconsistencies in the summaries. Overall, the\ninvestigation suggests that further improvements are needed to enhance the\nreliability of abstractive models and LLMs for legal case judgement\nsummarization. At present, a human-in-the-loop technique is more suitable for\nperforming manual checks to identify inconsistencies in the generated\nsummaries.",
      "tldr_zh": "这篇论文探讨了Large Language Models (LLMs) 和生成式模型在法律案件判决摘要中的适用性，相比传统的extractive summarization models，这些模型在英国最高法院和印度最高法院的判决数据集上表现更优。研究者应用了各种领域特定abstractive summarization models、通用LLMs 和提取式模型，并扩展到美国政府报告数据集，结果显示生成式模型在传统评估指标上取得了更好的摘要质量。然而，详细分析发现这些模型存在hallucinations 和不一致性问题，因此论文建议通过进一步优化和采用人类参与的循环技术来提升其可靠性，以实现更准确的法律摘要。",
      "categories": [
        "cs.CL",
        "cs.AI"
      ],
      "primary_category": "cs.CL",
      "comment": "Accepted at Artificial Intelligence and Law, Springer, 2024",
      "pdf_url": "http://arxiv.org/pdf/2407.12848v2",
      "published_date": "2024-07-06 04:49:40 UTC",
      "updated_date": "2024-07-20 05:50:41 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-19T04:10:39.660750"
    },
    {
      "arxiv_id": "2407.04925v1",
      "title": "RAMO: Retrieval-Augmented Generation for Enhancing MOOCs Recommendations",
      "title_zh": "翻译失败",
      "authors": [
        "Jiarui Rao",
        "Jionghao Lin"
      ],
      "abstract": "Massive Open Online Courses (MOOCs) have significantly enhanced educational\naccessibility by offering a wide variety of courses and breaking down\ntraditional barriers related to geography, finance, and time. However, students\noften face difficulties navigating the vast selection of courses, especially\nwhen exploring new fields of study. Driven by this challenge, researchers have\nbeen exploring course recommender systems to offer tailored guidance that\naligns with individual learning preferences and career aspirations. These\nsystems face particular challenges in effectively addressing the ``cold start''\nproblem for new users. Recent advancements in recommender systems suggest\nintegrating large language models (LLMs) into the recommendation process to\nenhance personalized recommendations and address the ``cold start'' problem.\nMotivated by these advancements, our study introduces RAMO (Retrieval-Augmented\nGeneration for MOOCs), a system specifically designed to overcome the ``cold\nstart'' challenges of traditional course recommender systems. The RAMO system\nleverages the capabilities of LLMs, along with Retrieval-Augmented Generation\n(RAG)-facilitated contextual understanding, to provide course recommendations\nthrough a conversational interface, aiming to enhance the e-learning\nexperience.",
      "tldr_zh": "本研究针对MOOCs（Massive Open Online Courses）推荐系统中的“cold start”问题，提出了一种名为RAMO的系统，利用Retrieval-Augmented Generation（RAG）和大型语言模型（LLMs）来增强个性化课程推荐。RAMO通过对话界面整合RAG的上下文理解能力，帮助新用户快速获取与学习偏好和职业目标相匹配的课程建议，从而改善在线学习体验。该系统旨在解决传统推荐系统的局限性，提供更高效的导航工具。",
      "categories": [
        "cs.IR",
        "cs.AI",
        "cs.HC"
      ],
      "primary_category": "cs.IR",
      "comment": "7 pages, this paper underwent a rigorous review process and was\n  officially accepted on May 31, 2024, for presentation at the Educational Data\n  Mining 2024 Workshop: Leveraging Large Language Models for Next Generation\n  Educational Technologies",
      "pdf_url": "http://arxiv.org/pdf/2407.04925v1",
      "published_date": "2024-07-06 02:22:25 UTC",
      "updated_date": "2024-07-06 02:22:25 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-19T04:10:50.025835"
    },
    {
      "arxiv_id": "2407.11039v3",
      "title": "Balancing Immediate Revenue and Future Off-Policy Evaluation in Coupon Allocation",
      "title_zh": "在优惠券分配中平衡即时收入与未来离策略评估",
      "authors": [
        "Naoki Nishimura",
        "Ken Kobayashi",
        "Kazuhide Nakata"
      ],
      "abstract": "Coupon allocation drives customer purchases and boosts revenue. However, it\npresents a fundamental trade-off between exploiting the current optimal policy\nto maximize immediate revenue and exploring alternative policies to collect\ndata for future policy improvement via off-policy evaluation (OPE). To balance\nthis trade-off, we propose a novel approach that combines a model-based revenue\nmaximization policy and a randomized exploration policy for data collection.\nOur framework enables flexible adjustment of the mixture ratio between these\ntwo policies to optimize the balance between short-term revenue and future\npolicy improvement. We formulate the problem of determining the optimal mixture\nratio as multi-objective optimization, enabling quantitative evaluation of this\ntrade-off. We empirically verified the effectiveness of the proposed mixed\npolicy using synthetic data. Our main contributions are: (1) Demonstrating a\nmixed policy combining deterministic and probabilistic policies, flexibly\nadjusting the data collection vs. revenue trade-off. (2) Formulating the\noptimal mixture ratio problem as multi-objective optimization, enabling\nquantitative evaluation of this trade-off.",
      "tldr_zh": "该论文探讨了优惠券分配中的核心权衡问题，即在最大化即时收入（exploiting the current optimal policy）和收集数据以支持未来 Off-Policy Evaluation (OPE) 策略改进（exploring alternative policies）之间寻求平衡。作者提出了一种新型混合框架，将模型-based 收入最大化策略与随机探索策略结合，通过灵活调整混合比例来优化短期收入与长期改进的权衡。该问题被表述为多目标优化(multi-objective optimization)，并通过合成数据实验验证了混合策略的有效性，主要贡献在于展示了结合确定性与概率策略的灵活方法，以及对权衡的定量评估。",
      "categories": [
        "cs.LG",
        "cs.AI"
      ],
      "primary_category": "cs.LG",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2407.11039v3",
      "published_date": "2024-07-06 02:04:17 UTC",
      "updated_date": "2024-09-08 23:10:59 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-19T04:11:04.193073"
    },
    {
      "arxiv_id": "2407.04921v1",
      "title": "Aortic root landmark localization with optimal transport loss for heatmap regression",
      "title_zh": "翻译失败",
      "authors": [
        "Tsuyoshi Ishizone",
        "Masaki Miyasaka",
        "Sae Ochi",
        "Norio Tada",
        "Kazuyuki Nakamura"
      ],
      "abstract": "Anatomical landmark localization is gaining attention to ease the burden on\nphysicians. Focusing on aortic root landmark localization, the three hinge\npoints of the aortic valve can reduce the burden by automatically determining\nthe valve size required for transcatheter aortic valve implantation surgery.\nExisting methods for landmark prediction of the aortic root mainly use\ntime-consuming two-step estimation methods. We propose a highly accurate\none-step landmark localization method from even coarse images. The proposed\nmethod uses an optimal transport loss to break the trade-off between prediction\nprecision and learning stability in conventional heatmap regression methods. We\napply the proposed method to the 3D CT image dataset collected at Sendai Kousei\nHospital and show that it significantly improves the estimation error over\nexisting methods and other loss functions. Our code is available on GitHub.",
      "tldr_zh": "这篇论文针对主动脉根部地标定位问题，提出了一种高精度单步方法，以自动确定经导管主动脉瓣植入术所需的瓣膜大小，从而减轻医生负担。方法使用optimal transport loss来优化heatmap regression，解决传统方法中预测精度与学习稳定性之间的权衡。实验结果显示，在Sendai Kousei医院的3D CT图像数据集上，该方法显著降低了估计误差，并提供了开源代码以便进一步应用。",
      "categories": [
        "cs.CV",
        "cs.AI",
        "stat.AP"
      ],
      "primary_category": "cs.CV",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2407.04921v1",
      "published_date": "2024-07-06 02:01:48 UTC",
      "updated_date": "2024-07-06 02:01:48 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-19T04:11:14.752074"
    },
    {
      "arxiv_id": "2407.11038v2",
      "title": "Fuzzy Recurrent Stochastic Configuration Networks for Industrial Data Analytics",
      "title_zh": "翻译失败",
      "authors": [
        "Dianhui Wang",
        "Gang Dang"
      ],
      "abstract": "This paper presents a novel neuro-fuzzy model, termed fuzzy recurrent\nstochastic configuration networks (F-RSCNs), for industrial data analytics.\nUnlike the original recurrent stochastic configuration network (RSCN), the\nproposed F-RSCN is constructed by multiple sub-reservoirs, and each\nsub-reservoir is associated with a Takagi-Sugeno-Kang (TSK) fuzzy rule. Through\nthis hybrid framework, first, the interpretability of the model is enhanced by\nincorporating fuzzy reasoning to embed the prior knowledge into the network.\nThen, the parameters of the neuro-fuzzy model are determined by the recurrent\nstochastic configuration (RSC) algorithm. This scheme not only ensures the\nuniversal approximation property and fast learning speed of the built model but\nalso overcomes uncertain problems, such as unknown dynamic orders, arbitrary\nstructure determination, and the sensitivity of learning parameters in\nmodelling nonlinear dynamics. Finally, an online update of the output weights\nis performed using the projection algorithm, and the convergence analysis of\nthe learning parameters is given. By integrating TSK fuzzy inference systems\ninto RSCNs, F-RSCNs have strong fuzzy inference capability and can achieve\nsound performance for both learning and generalization. Comprehensive\nexperiments show that the proposed F-RSCNs outperform other classical\nneuro-fuzzy and non-fuzzy models, demonstrating great potential for modelling\ncomplex industrial systems.",
      "tldr_zh": "本文提出了一种新型神经模糊模型，名为 Fuzzy Recurrent Stochastic Configuration Networks (F-RSCNs)，旨在用于工业数据分析。该模型由多个子reservoir 组成，每个与 Takagi-Sugeno-Kang (TSK) 模糊规则相关联，通过 Recurrent Stochastic Configuration (RSC) 算法确定参数，从而提升模型的可解释性、通用逼近能力和快速学习速度，同时解决非线性动态建模中的不确定问题，如未知动态顺序和参数敏感性。F-RSCNs 还采用投影算法进行输出权重的在线更新，并提供了学习参数的收敛分析。实验结果表明，该模型在学习和泛化性能上优于其他经典神经模糊和非模糊模型，展示了在建模复杂工业系统方面的巨大潜力。",
      "categories": [
        "cs.LG",
        "cs.AI",
        "cs.NE"
      ],
      "primary_category": "cs.LG",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2407.11038v2",
      "published_date": "2024-07-06 01:40:31 UTC",
      "updated_date": "2024-08-13 00:55:09 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-19T04:11:29.176767"
    },
    {
      "arxiv_id": "2407.04910v1",
      "title": "NADI 2024: The Fifth Nuanced Arabic Dialect Identification Shared Task",
      "title_zh": "翻译失败",
      "authors": [
        "Muhammad Abdul-Mageed",
        "Amr Keleg",
        "AbdelRahim Elmadany",
        "Chiyu Zhang",
        "Injy Hamed",
        "Walid Magdy",
        "Houda Bouamor",
        "Nizar Habash"
      ],
      "abstract": "We describe the findings of the fifth Nuanced Arabic Dialect Identification\nShared Task (NADI 2024). NADI's objective is to help advance SoTA Arabic NLP by\nproviding guidance, datasets, modeling opportunities, and standardized\nevaluation conditions that allow researchers to collaboratively compete on\npre-specified tasks. NADI 2024 targeted both dialect identification cast as a\nmulti-label task (Subtask~1), identification of the Arabic level of dialectness\n(Subtask~2), and dialect-to-MSA machine translation (Subtask~3). A total of 51\nunique teams registered for the shared task, of whom 12 teams have participated\n(with 76 valid submissions during the test phase). Among these, three teams\nparticipated in Subtask~1, three in Subtask~2, and eight in Subtask~3. The\nwinning teams achieved 50.57 F\\textsubscript{1} on Subtask~1, 0.1403 RMSE for\nSubtask~2, and 20.44 BLEU in Subtask~3, respectively. Results show that Arabic\ndialect processing tasks such as dialect identification and machine translation\nremain challenging. We describe the methods employed by the participating teams\nand briefly offer an outlook for NADI.",
      "tldr_zh": "本研究介绍了第五届 Nuanced Arabic Dialect Identification Shared Task (NADI 2024)，旨在通过提供指导、数据集和标准化评估条件，推动阿拉伯语 NLP 领域的最新技术进展。任务包括三个子任务：多标签方言识别 (Subtask 1)、阿拉伯语方言程度识别 (Subtask 2)，以及方言到现代标准阿拉伯语 (MSA) 的机器翻译 (Subtask 3)。共有 51 个团队注册，12 个团队参与并提交了 76 个有效测试结果，获胜团队分别在 Subtask 1 取得 50.57 F1 分数、在 Subtask 2 达到 0.1403 RMSE，以及在 Subtask 3 获得 20.44 BLEU。结果显示，阿拉伯方言处理任务仍具挑战性，并为未来 NADI 发展提供了展望。",
      "categories": [
        "cs.CL",
        "cs.AI"
      ],
      "primary_category": "cs.CL",
      "comment": "Accepted by The Second Arabic Natural Language Processing Conference",
      "pdf_url": "http://arxiv.org/pdf/2407.04910v1",
      "published_date": "2024-07-06 01:18:58 UTC",
      "updated_date": "2024-07-06 01:18:58 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-19T04:11:40.379963"
    },
    {
      "arxiv_id": "2407.04903v3",
      "title": "MMSci: A Dataset for Graduate-Level Multi-Discipline Multimodal Scientific Understanding",
      "title_zh": "MMSci：研究生水平多学科多模态科学理解数据集",
      "authors": [
        "Zekun Li",
        "Xianjun Yang",
        "Kyuri Choi",
        "Wanrong Zhu",
        "Ryan Hsieh",
        "HyeonJung Kim",
        "Jin Hyuk Lim",
        "Sungyoung Ji",
        "Byungju Lee",
        "Xifeng Yan",
        "Linda Ruth Petzold",
        "Stephen D. Wilson",
        "Woosang Lim",
        "William Yang Wang"
      ],
      "abstract": "Scientific figure interpretation is a crucial capability for AI-driven\nscientific assistants built on advanced Large Vision Language Models. However,\ncurrent datasets and benchmarks primarily focus on simple charts or other\nrelatively straightforward figures from limited science domains. To address\nthis gap, we present a comprehensive dataset compiled from peer-reviewed Nature\nCommunications articles covering 72 scientific fields, encompassing complex\nvisualizations such as schematic diagrams, microscopic images, and experimental\ndata which require graduate-level expertise to interpret. We evaluated 19\nproprietary and open-source models on two benchmark tasks, figure captioning\nand multiple-choice, and conducted human expert annotation. Our analysis\nrevealed significant task challenges and performance gaps among models. Beyond\nserving as a benchmark, this dataset serves as a valuable resource for\nlarge-scale training. Fine-tuning Qwen2-VL-7B with our task-specific data\nachieved better performance than GPT-4o and even human experts in\nmultiple-choice evaluations. Furthermore, continuous pre-training on our\ninterleaved article and figure data substantially enhanced the model's\ndownstream task performance in materials science. We have released our dataset\nto support further research.",
      "tldr_zh": "本研究引入了 MMSci 数据集，该数据集从 Nature Communications 的同行评议文章中编译，涵盖 72 个科学领域，包括复杂的可视化如示意图、显微图像和实验数据，需要研究生级别的专业知识来解读。研究评估了 19 个专有和开源模型在图表标题生成和多项选择任务上的性能，并通过人类专家注释揭示了显著的任务挑战和模型性能差距。微调 Qwen2-VL-7B 模型后，其在多项选择任务的表现超过了 GPT-4o 甚至人类专家，而持续预训练进一步提升了模型在材料科学下游任务的效能；数据集已公开发布，以支持大规模训练和进一步研究。",
      "categories": [
        "cs.CL",
        "cs.AI",
        "cs.CV"
      ],
      "primary_category": "cs.CL",
      "comment": "Code and data are available at https://github.com/Leezekun/MMSci",
      "pdf_url": "http://arxiv.org/pdf/2407.04903v3",
      "published_date": "2024-07-06 00:40:53 UTC",
      "updated_date": "2025-02-20 05:57:34 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-19T04:11:51.585928"
    },
    {
      "arxiv_id": "2407.04899v1",
      "title": "Algorithmic Language Models with Neurally Compiled Libraries",
      "title_zh": "使用神经编译库的算法语言模型",
      "authors": [
        "Lucas Saldyt",
        "Subbarao Kambhampati"
      ],
      "abstract": "Important tasks such as reasoning and planning are fundamentally algorithmic,\nmeaning that solving them robustly requires acquiring true reasoning or\nplanning algorithms, rather than shortcuts. Large Language Models lack true\nalgorithmic ability primarily because of the limitations of neural network\noptimization algorithms, their optimization data and optimization objective,\nbut also due to architectural inexpressivity. To solve this, our paper proposes\naugmenting LLMs with a library of fundamental operations and sophisticated\ndifferentiable programs, so that common algorithms do not need to be learned\nfrom scratch. We add memory, registers, basic operations, and adaptive\nrecurrence to a transformer architecture built on LLaMA3. Then, we define a\nmethod for directly compiling algorithms into a differentiable starting\nlibrary, which is used natively and propagates gradients for optimization. In\nthis preliminary study, we explore the feasability of augmenting LLaMA3 with a\ndifferentiable computer, for instance by fine-tuning small transformers on\nsimple algorithmic tasks with variable computational depth.",
      "tldr_zh": "该论文指出，大型语言模型（LLMs）在处理算法性任务如推理和规划时存在局限性，主要由于神经网络优化算法、数据、目标以及架构表达性的不足。作者提出一种解决方案，通过为LLMs添加一个神经编译库，包括内存、寄存器、基本操作和自适应循环，从而避免从零学习常见算法。基于LLaMA3的Transformer架构，他们定义了一种直接将算法编译成可微程序的方法，该程序可原生使用并传播梯度以进行优化。在初步研究中，论文通过在简单算法任务上微调小Transformer，验证了这种增强的可行性，为提升LLMs的算法能力提供了新途径。",
      "categories": [
        "cs.AI",
        "cs.CL",
        "cs.PL"
      ],
      "primary_category": "cs.AI",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2407.04899v1",
      "published_date": "2024-07-06 00:27:05 UTC",
      "updated_date": "2024-07-06 00:27:05 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-19T04:12:06.383824"
    }
  ],
  "raw_papers_fetched": true,
  "papers_count": 41,
  "processed_papers_count": 41,
  "failed_papers_count": 0,
  "summary_generated": true,
  "daily_data_saved": true,
  "last_update": "2025-05-19T04:12:28.411554"
}