[
  {
    "arxiv_id": "2506.08295v1",
    "title": "From Passive to Active Reasoning: Can Large Language Models Ask the Right Questions under Incomplete Information?",
    "authors": [
      "Zhanke Zhou",
      "Xiao Feng",
      "Zhaocheng Zhu",
      "Jiangchao Yao",
      "Sanmi Koyejo",
      "Bo Han"
    ],
    "abstract": "While existing benchmarks probe the reasoning abilities of large language models (LLMs) across diverse domains, they predominantly assess passive reasoning, providing models with all the information needed to reach a solution. By contrast, active reasoning-where an LLM must interact with external systems to acquire missing evidence or data-has received little systematic attention. To address this shortfall, we present AR-Bench, a novel benchmark designed explicitly to evaluate an LLM's active reasoning skills. AR-Bench comprises three task families-detective cases, situation puzzles, and guessing numbers-that together simulate real-world, agentic scenarios and measure performance across commonsense, logical, and symbolic reasoning challenges. Empirical evaluation on AR-Bench demonstrates that contemporary LLMs exhibit pronounced difficulties with active reasoning: they frequently fail to acquire or leverage the information needed to solve tasks. This gap highlights a stark divergence between their passive and active reasoning abilities. Moreover, ablation studies indicate that even advanced strategies, such as tree-based searching or post-training approaches, yield only modest gains and fall short of the levels required for real-world deployment. Collectively, these findings highlight the critical need to advance methodology for active reasoning, e.g., incorporating interactive learning, real-time feedback loops, and environment-aware objectives for training. The benchmark is publicly available at: https://github.com/tmlr-group/AR-Bench.",
    "categories": [
      "cs.LG",
      "cs.AI",
      "cs.CL"
    ],
    "primary_category": "cs.LG",
    "comment": "Accepted by ICML 2025",
    "pdf_url": "https://arxiv.org/pdf/2506.08295v1",
    "published_date": "2025-06-09 23:56:41 UTC",
    "updated_date": "2025-06-09 23:56:41 UTC"
  },
  {
    "arxiv_id": "2506.13780v1",
    "title": "Hidden Bias in the Machine: Stereotypes in Text-to-Image Models",
    "authors": [
      "Sedat Porikli",
      "Vedat Porikli"
    ],
    "abstract": "Text-to-Image (T2I) models have transformed visual content creation, producing highly realistic images from natural language prompts. However, concerns persist around their potential to replicate and magnify existing societal biases. To investigate these issues, we curated a diverse set of prompts spanning thematic categories such as occupations, traits, actions, ideologies, emotions, family roles, place descriptions, spirituality, and life events. For each of the 160 unique topics, we crafted multiple prompt variations to reflect a wide range of meanings and perspectives. Using Stable Diffusion 1.5 (UNet-based) and Flux-1 (DiT-based) models with original checkpoints, we generated over 16,000 images under consistent settings. Additionally, we collected 8,000 comparison images from Google Image Search. All outputs were filtered to exclude abstract, distorted, or nonsensical results. Our analysis reveals significant disparities in the representation of gender, race, age, somatotype, and other human-centric factors across generated images. These disparities often mirror and reinforce harmful stereotypes embedded in societal narratives. We discuss the implications of these findings and emphasize the need for more inclusive datasets and development practices to foster fairness in generative visual systems.",
    "categories": [
      "cs.CV",
      "cs.AI",
      "cs.CY",
      "cs.LG"
    ],
    "primary_category": "cs.CV",
    "comment": "Equal contribution by both authors, Published at CVPR 2025 Workshop on Experimental Model Auditing via Controllable Synthesis (EMACS) and Workshop on Demographic Diversity in Computer Vision (DemoDiv)",
    "pdf_url": "https://arxiv.org/pdf/2506.13780v1",
    "published_date": "2025-06-09 23:06:04 UTC",
    "updated_date": "2025-06-09 23:06:04 UTC"
  },
  {
    "arxiv_id": "2506.08279v1",
    "title": "Seeing Voices: Generating A-Roll Video from Audio with Mirage",
    "authors": [
      "Aditi Sundararaman",
      "Amogh Adishesha",
      "Andrew Jaegle",
      "Dan Bigioi",
      "Hyoung-Kyu Song",
      "Jon Kyl",
      "Justin Mao",
      "Kevin Lan",
      "Mojtaba Komeili",
      "ShahRukh Athar",
      "Sheila Babayan",
      "Stanislau Beliasau",
      "William Buchwalter"
    ],
    "abstract": "From professional filmmaking to user-generated content, creators and consumers have long recognized that the power of video depends on the harmonious integration of what we hear (the video's audio track) with what we see (the video's image sequence). Current approaches to video generation either ignore sound to focus on general-purpose but silent image sequence generation or address both visual and audio elements but focus on restricted application domains such as re-dubbing. We introduce Mirage, an audio-to-video foundation model that excels at generating realistic, expressive output imagery from scratch given an audio input. When integrated with existing methods for speech synthesis (text-to-speech, or TTS), Mirage results in compelling multimodal video. When trained on audio-video footage of people talking (A-roll) and conditioned on audio containing speech, Mirage generates video of people delivering a believable interpretation of the performance implicit in input audio. Our central technical contribution is a unified method for training self-attention-based audio-to-video generation models, either from scratch or given existing weights. This methodology allows Mirage to retain generality as an approach to audio-to-video generation while producing outputs of superior subjective quality to methods that incorporate audio-specific architectures or loss components specific to people, speech, or details of how images or audio are captured. We encourage readers to watch and listen to the results of Mirage for themselves (see paper and comments for links).",
    "categories": [
      "cs.CV",
      "cs.AI",
      "cs.LG"
    ],
    "primary_category": "cs.CV",
    "comment": "Technical report website: mirage.app/research/seeing-voices, product website: mirage.app",
    "pdf_url": "https://arxiv.org/pdf/2506.08279v1",
    "published_date": "2025-06-09 22:56:02 UTC",
    "updated_date": "2025-06-09 22:56:02 UTC"
  },
  {
    "arxiv_id": "2506.08277v1",
    "title": "Instruction-Tuned Video-Audio Models Elucidate Functional Specialization in the Brain",
    "authors": [
      "Subba Reddy Oota",
      "Khushbu Pahwa",
      "Prachi Jindal",
      "Satya Sai Srinath Namburi",
      "Maneesh Singh",
      "Tanmoy Chakraborty",
      "Bapi S. Raju",
      "Manish Gupta"
    ],
    "abstract": "Recent voxel-wise multimodal brain encoding studies have shown that multimodal large language models (MLLMs) exhibit a higher degree of brain alignment compared to unimodal models in both unimodal and multimodal stimulus settings. More recently, instruction-tuned multimodal models have shown to generate task-specific representations that align strongly with brain activity. However, prior work evaluating the brain alignment of MLLMs has primarily focused on unimodal settings or relied on non-instruction-tuned multimodal models for multimodal stimuli. To address this gap, we investigated brain alignment, that is, measuring the degree of predictivity of neural activity recorded while participants were watching naturalistic movies (video along with audio) with representations derived from MLLMs. We utilized instruction-specific embeddings from six video and two audio instruction-tuned MLLMs. Experiments with 13 video task-specific instructions show that instruction-tuned video MLLMs significantly outperform non-instruction-tuned multimodal (by 15%) and unimodal models (by 20%). Our evaluation of MLLMs for both video and audio tasks using language-guided instructions shows clear disentanglement in task-specific representations from MLLMs, leading to precise differentiation of multimodal functional processing in the brain. We also find that MLLM layers align hierarchically with the brain, with early sensory areas showing strong alignment with early layers, while higher-level visual and language regions align more with middle to late layers. These findings provide clear evidence for the role of task-specific instructions in improving the alignment between brain activity and MLLMs, and open new avenues for mapping joint information processing in both the systems. We make the code publicly available [https://github.com/subbareddy248/mllm_videos].",
    "categories": [
      "q-bio.NC",
      "cs.AI",
      "cs.CL",
      "cs.CV",
      "cs.LG"
    ],
    "primary_category": "q-bio.NC",
    "comment": "39 pages, 22 figures",
    "pdf_url": "https://arxiv.org/pdf/2506.08277v1",
    "published_date": "2025-06-09 22:48:36 UTC",
    "updated_date": "2025-06-09 22:48:36 UTC"
  },
  {
    "arxiv_id": "2506.08267v2",
    "title": "Sparse Interpretable Deep Learning with LIES Networks for Symbolic Regression",
    "authors": [
      "Mansooreh Montazerin",
      "Majd Al Aawar",
      "Antonio Ortega",
      "Ajitesh Srivastava"
    ],
    "abstract": "Symbolic regression (SR) aims to discover closed-form mathematical expressions that accurately describe data, offering interpretability and analytical insight beyond standard black-box models. Existing SR methods often rely on population-based search or autoregressive modeling, which struggle with scalability and symbolic consistency. We introduce LIES (Logarithm, Identity, Exponential, Sine), a fixed neural network architecture with interpretable primitive activations that are optimized to model symbolic expressions. We develop a framework to extract compact formulae from LIES networks by training with an appropriate oversampling strategy and a tailored loss function to promote sparsity and to prevent gradient instability. After training, it applies additional pruning strategies to further simplify the learned expressions into compact formulae. Our experiments on SR benchmarks show that the LIES framework consistently produces sparse and accurate symbolic formulae outperforming all baselines. We also demonstrate the importance of each design component through ablation studies.",
    "categories": [
      "cs.LG",
      "cs.AI"
    ],
    "primary_category": "cs.LG",
    "comment": "",
    "pdf_url": "https://arxiv.org/pdf/2506.08267v2",
    "published_date": "2025-06-09 22:05:53 UTC",
    "updated_date": "2025-06-14 21:24:10 UTC"
  },
  {
    "arxiv_id": "2506.08266v1",
    "title": "Reinforcement Learning from Human Feedback with High-Confidence Safety Constraints",
    "authors": [
      "Yaswanth Chittepu",
      "Blossom Metevier",
      "Will Schwarzer",
      "Austin Hoag",
      "Scott Niekum",
      "Philip S. Thomas"
    ],
    "abstract": "Existing approaches to language model alignment often treat safety as a tradeoff against helpfulness, which can lead to unacceptable responses in sensitive domains. To ensure reliable performance in such settings, we propose High-Confidence Safe Reinforcement Learning from Human Feedback (HC-RLHF), a method that provides high-confidence safety guarantees while maximizing helpfulness. Similar to previous methods, HC-RLHF explicitly decouples human preferences into helpfulness and harmlessness (safety), which are learned by training a reward model and a cost model, respectively. It then employs a two-step process to find safe solutions. In the first step, it optimizes the reward function under an intentionally pessimistic version of the cost constraint. In the second step, the trained model undergoes a safety test to verify whether its performance stays within an upper-confidence bound of the actual cost constraint. We provide a theoretical analysis of HC-RLHF, including proof that it will not return an unsafe solution with a probability greater than a user-specified threshold. For our empirical analysis, we apply HC-RLHF to align three different language models (Qwen2-1.5B, Qwen2.5-3B, and LLaMa3.2-3B) with human preferences. Our results demonstrate that HC-RLHF produces safe models with high probability and can improve harmlessness and helpfulness compared to previous methods.",
    "categories": [
      "cs.LG",
      "cs.AI",
      "cs.CL",
      "stat.AP"
    ],
    "primary_category": "cs.LG",
    "comment": "20 pages, 6 figures, 4 tables, Second Reinforcement Learning Conference (RLC 2025)",
    "pdf_url": "https://arxiv.org/pdf/2506.08266v1",
    "published_date": "2025-06-09 22:03:56 UTC",
    "updated_date": "2025-06-09 22:03:56 UTC"
  },
  {
    "arxiv_id": "2506.08260v1",
    "title": "Automatic Generation of Inference Making Questions for Reading Comprehension Assessments",
    "authors": [
      "Wanjing Anya Ma",
      "Michael Flor",
      "Zuowei Wang"
    ],
    "abstract": "Inference making is an essential but complex skill in reading comprehension (RC). Some inferences require resolving references across sentences, and some rely on using prior knowledge to fill in the detail that is not explicitly written in the text. Diagnostic RC questions can help educators provide more effective and targeted reading instruction and interventions for school-age students. We introduce a taxonomy of inference types for RC and use it to analyze the distribution of items within a diagnostic RC item bank. Next, we present experiments using GPT-4o to generate bridging-inference RC items for given reading passages via few-shot prompting, comparing conditions with and without chain-of-thought prompts. Generated items were evaluated on three aspects: overall item quality, appropriate inference type, and LLM reasoning, achieving high inter-rater agreements above 0.90. Our results show that GPT-4o produced 93.8% good-quality questions suitable for operational use in grade 3-12 contexts; however, only 42.6% of the generated questions accurately matched the targeted inference type. We conclude that combining automatic item generation with human judgment offers a promising path toward scalable, high-quality diagnostic RC assessments.",
    "categories": [
      "cs.CL",
      "cs.AI"
    ],
    "primary_category": "cs.CL",
    "comment": "Accepted to the 20th Workshop on Innovative Use of NLP for Building Educational Applications (BEA 2025), co-located with the ACL 2025",
    "pdf_url": "https://arxiv.org/pdf/2506.08260v1",
    "published_date": "2025-06-09 21:50:12 UTC",
    "updated_date": "2025-06-09 21:50:12 UTC"
  },
  {
    "arxiv_id": "2506.08257v1",
    "title": "Highly Compressed Tokenizer Can Generate Without Training",
    "authors": [
      "L. Lao Beyer",
      "T. Li",
      "X. Chen",
      "S. Karaman",
      "K. He"
    ],
    "abstract": "Commonly used image tokenizers produce a 2D grid of spatially arranged tokens. In contrast, so-called 1D image tokenizers represent images as highly compressed one-dimensional sequences of as few as 32 discrete tokens. We find that the high degree of compression achieved by a 1D tokenizer with vector quantization enables image editing and generative capabilities through heuristic manipulation of tokens, demonstrating that even very crude manipulations -- such as copying and replacing tokens between latent representations of images -- enable fine-grained image editing by transferring appearance and semantic attributes. Motivated by the expressivity of the 1D tokenizer's latent space, we construct an image generation pipeline leveraging gradient-based test-time optimization of tokens with plug-and-play loss functions such as reconstruction or CLIP similarity. Our approach is demonstrated for inpainting and text-guided image editing use cases, and can generate diverse and realistic samples without requiring training of any generative model.",
    "categories": [
      "cs.CV",
      "cs.AI"
    ],
    "primary_category": "cs.CV",
    "comment": "Main manuscript: 9 pages, 7 figures. Appendix: 8 pages, 9 figures. To appear in the Proceedings of the 42nd International Conference on Machine Learning",
    "pdf_url": "https://arxiv.org/pdf/2506.08257v1",
    "published_date": "2025-06-09 21:45:03 UTC",
    "updated_date": "2025-06-09 21:45:03 UTC"
  },
  {
    "arxiv_id": "2506.08255v3",
    "title": "SHIELD: Secure Hypernetworks for Incremental Expansion Learning Defense",
    "authors": [
      "Patryk Krukowski",
      "Łukasz Gorczyca",
      "Piotr Helm",
      "Kamil Książek",
      "Przemysław Spurek"
    ],
    "abstract": "Continual learning under adversarial conditions remains an open problem, as existing methods often compromise either robustness, scalability, or both. We propose a novel framework that integrates Interval Bound Propagation (IBP) with a hypernetwork-based architecture to enable certifiably robust continual learning across sequential tasks. Our method, SHIELD, generates task-specific model parameters via a shared hypernetwork conditioned solely on compact task embeddings, eliminating the need for replay buffers or full model copies and enabling efficient over time. To further enhance robustness, we introduce Interval MixUp, a novel training strategy that blends virtual examples represented as $\\ell_{\\infty}$ balls centered around MixUp points. Leveraging interval arithmetic, this technique guarantees certified robustness while mitigating the wrapping effect, resulting in smoother decision boundaries. We evaluate SHIELD under strong white-box adversarial attacks, including PGD and AutoAttack, across multiple benchmarks. It consistently outperforms existing robust continual learning methods, achieving state-of-the-art average accuracy while maintaining both scalability and certification. These results represent a significant step toward practical and theoretically grounded continual learning in adversarial settings.",
    "categories": [
      "cs.LG",
      "cs.AI",
      "cs.CR"
    ],
    "primary_category": "cs.LG",
    "comment": "",
    "pdf_url": "https://arxiv.org/pdf/2506.08255v3",
    "published_date": "2025-06-09 21:43:56 UTC",
    "updated_date": "2025-11-21 16:58:45 UTC"
  },
  {
    "arxiv_id": "2506.08244v1",
    "title": "Parameter-free approximate equivariance for tasks with finite group symmetry",
    "authors": [
      "Riccardo Ali",
      "Pietro Liò",
      "Jamie Vicary"
    ],
    "abstract": "Equivariant neural networks incorporate symmetries through group actions, embedding them as an inductive bias to improve performance on a wide variety of tasks. However, existing equivariant methods can be computationally intensive, with high parameter counts, and are often tied to a specific architecture. We propose a simple zero-parameter approach that imposes approximate equivariance for a finite group in the latent representation, as an additional term in the loss function. We conduct experiments which allow the network to learn a group representation on the latent space, and show in every case it prefers to learn the regular representation. Fixing this action on the latent space, this yields a simple method to impose approximate equivariance as an additional loss penalty. We benchmark our approach on three datasets and compare it against several existing equivariant methods, showing that in many cases it achieves similar or better performance for a fraction of the parameters.",
    "categories": [
      "cs.LG",
      "cs.AI",
      "stat.ML"
    ],
    "primary_category": "cs.LG",
    "comment": "",
    "pdf_url": "https://arxiv.org/pdf/2506.08244v1",
    "published_date": "2025-06-09 21:23:26 UTC",
    "updated_date": "2025-06-09 21:23:26 UTC"
  },
  {
    "arxiv_id": "2506.08243v1",
    "title": "Temporalizing Confidence: Evaluation of Chain-of-Thought Reasoning with Signal Temporal Logic",
    "authors": [
      "Zhenjiang Mao",
      "Artem Bisliouk",
      "Rohith Reddy Nama",
      "Ivan Ruchkin"
    ],
    "abstract": "Large Language Models (LLMs) have shown impressive performance in mathematical reasoning tasks when guided by Chain-of-Thought (CoT) prompting. However, they tend to produce highly confident yet incorrect outputs, which poses significant risks in domains like education, where users may lack the expertise to assess reasoning steps. To address this, we propose a structured framework that models stepwise confidence as a temporal signal and evaluates it using Signal Temporal Logic (STL). In particular, we define formal STL-based constraints to capture desirable temporal properties and compute robustness scores that serve as structured, interpretable confidence estimates. Our approach also introduces a set of uncertainty reshaping strategies to enforce smoothness, monotonicity, and causal consistency across the reasoning trajectory. Experiments show that our approach consistently improves calibration metrics and provides more reliable uncertainty estimates than conventional confidence aggregation and post-hoc calibration.",
    "categories": [
      "cs.LG",
      "cs.AI"
    ],
    "primary_category": "cs.LG",
    "comment": "",
    "pdf_url": "https://arxiv.org/pdf/2506.08243v1",
    "published_date": "2025-06-09 21:21:12 UTC",
    "updated_date": "2025-06-09 21:21:12 UTC"
  },
  {
    "arxiv_id": "2506.17263v1",
    "title": "Memory Allocation in Resource-Constrained Reinforcement Learning",
    "authors": [
      "Massimiliano Tamborski",
      "David Abel"
    ],
    "abstract": "Resource constraints can fundamentally change both learning and decision-making. We explore how memory constraints influence an agent's performance when navigating unknown environments using standard reinforcement learning algorithms. Specifically, memory-constrained agents face a dilemma: how much of their limited memory should be allocated to each of the agent's internal processes, such as estimating a world model, as opposed to forming a plan using that model? We study this dilemma in MCTS- and DQN-based algorithms and examine how different allocations of memory impact performance in episodic and continual learning settings.",
    "categories": [
      "cs.LG",
      "cs.AI"
    ],
    "primary_category": "cs.LG",
    "comment": "RLDM 2025",
    "pdf_url": "https://arxiv.org/pdf/2506.17263v1",
    "published_date": "2025-06-09 21:15:37 UTC",
    "updated_date": "2025-06-09 21:15:37 UTC"
  },
  {
    "arxiv_id": "2506.08235v1",
    "title": "Can AI Validate Science? Benchmarking LLMs for Accurate Scientific Claim $\\rightarrow$ Evidence Reasoning",
    "authors": [
      "Shashidhar Reddy Javaji",
      "Yupeng Cao",
      "Haohang Li",
      "Yangyang Yu",
      "Nikhil Muralidhar",
      "Zining Zhu"
    ],
    "abstract": "Large language models (LLMs) are increasingly being used for complex research tasks such as literature review, idea generation, and scientific paper analysis, yet their ability to truly understand and process the intricate relationships within complex research papers, such as the logical links between claims and supporting evidence remains largely unexplored. In this study, we present CLAIM-BENCH, a comprehensive benchmark for evaluating LLMs' capabilities in scientific claim-evidence extraction and validation, a task that reflects deeper comprehension of scientific argumentation. We systematically compare three approaches which are inspired by divide and conquer approaches, across six diverse LLMs, highlighting model-specific strengths and weaknesses in scientific comprehension. Through evaluation involving over 300 claim-evidence pairs across multiple research domains, we reveal significant limitations in LLMs' ability to process complex scientific content. Our results demonstrate that closed-source models like GPT-4 and Claude consistently outperform open-source counterparts in precision and recall across claim-evidence identification tasks. Furthermore, strategically designed three-pass and one-by-one prompting approaches significantly improve LLMs' abilities to accurately link dispersed evidence with claims, although this comes at increased computational cost. CLAIM-BENCH sets a new standard for evaluating scientific comprehension in LLMs, offering both a diagnostic tool and a path forward for building systems capable of deeper, more reliable reasoning across full-length papers.",
    "categories": [
      "cs.CL",
      "cs.AI"
    ],
    "primary_category": "cs.CL",
    "comment": "21 pages, 6 figures, Under review",
    "pdf_url": "https://arxiv.org/pdf/2506.08235v1",
    "published_date": "2025-06-09 21:04:39 UTC",
    "updated_date": "2025-06-09 21:04:39 UTC"
  },
  {
    "arxiv_id": "2506.08234v2",
    "title": "Compound AI Systems Optimization: A Survey of Methods, Challenges, and Future Directions",
    "authors": [
      "Yu-Ang Lee",
      "Guan-Ting Yi",
      "Mei-Yi Liu",
      "Jui-Chao Lu",
      "Guan-Bo Yang",
      "Yun-Nung Chen"
    ],
    "abstract": "Recent advancements in large language models (LLMs) and AI systems have led to a paradigm shift in the design and optimization of complex AI workflows. By integrating multiple components, compound AI systems have become increasingly adept at performing sophisticated tasks. However, as these systems grow in complexity, new challenges arise in optimizing not only individual components but also their interactions. While traditional optimization methods such as supervised fine-tuning (SFT) and reinforcement learning (RL) remain foundational, the rise of natural language feedback introduces promising new approaches, especially for optimizing non-differentiable systems. This paper provides a systematic review of recent progress in optimizing compound AI systems, encompassing both numerical and language-based techniques. We formalize the notion of compound AI system optimization, classify existing methods along several key dimensions, and highlight open research challenges and future directions in this rapidly evolving field. A list of surveyed papers is publicly available at https://github.com/MiuLab/AISysOpt-Survey.",
    "categories": [
      "cs.CL",
      "cs.AI"
    ],
    "primary_category": "cs.CL",
    "comment": "Accepted to EMNLP 2025 (Main)",
    "pdf_url": "https://arxiv.org/pdf/2506.08234v2",
    "published_date": "2025-06-09 21:04:14 UTC",
    "updated_date": "2025-10-07 01:23:00 UTC"
  },
  {
    "arxiv_id": "2506.08231v1",
    "title": "Ensuring Reliability of Curated EHR-Derived Data: The Validation of Accuracy for LLM/ML-Extracted Information and Data (VALID) Framework",
    "authors": [
      "Melissa Estevez",
      "Nisha Singh",
      "Lauren Dyson",
      "Blythe Adamson",
      "Qianyu Yuan",
      "Megan W. Hildner",
      "Erin Fidyk",
      "Olive Mbah",
      "Farhad Khan",
      "Kathi Seidl-Rathkopf",
      "Aaron B. Cohen"
    ],
    "abstract": "Large language models (LLMs) are increasingly used to extract clinical data from electronic health records (EHRs), offering significant improvements in scalability and efficiency for real-world data (RWD) curation in oncology. However, the adoption of LLMs introduces new challenges in ensuring the reliability, accuracy, and fairness of extracted data, which are essential for research, regulatory, and clinical applications. Existing quality assurance frameworks for RWD and artificial intelligence do not fully address the unique error modes and complexities associated with LLM-extracted data. In this paper, we propose a comprehensive framework for evaluating the quality of clinical data extracted by LLMs. The framework integrates variable-level performance benchmarking against expert human abstraction, automated verification checks for internal consistency and plausibility, and replication analyses comparing LLM-extracted data to human-abstracted datasets or external standards. This multidimensional approach enables the identification of variables most in need of improvement, systematic detection of latent errors, and confirmation of dataset fitness-for-purpose in real-world research. Additionally, the framework supports bias assessment by stratifying metrics across demographic subgroups. By providing a rigorous and transparent method for assessing LLM-extracted RWD, this framework advances industry standards and supports the trustworthy use of AI-powered evidence generation in oncology research and practice.",
    "categories": [
      "cs.LG",
      "cs.AI",
      "cs.PF"
    ],
    "primary_category": "cs.LG",
    "comment": "18 pages, 3 tables, 1 figure",
    "pdf_url": "https://arxiv.org/pdf/2506.08231v1",
    "published_date": "2025-06-09 20:59:16 UTC",
    "updated_date": "2025-06-09 20:59:16 UTC"
  },
  {
    "arxiv_id": "2506.08229v1",
    "title": "AI-Driven Early Detection of Cardiovascular Diseases: Reducing Healthcare Costs and improving patient Outcomes",
    "authors": [
      "Ahasan Ahmed",
      "Albatoul Khaled",
      "Muhammad Waqar",
      "DrJavaid Akhtar Hashmi",
      "Hazem AbdulKareem Alfanash",
      "Wesam Taher Almagharbeh",
      "Amine Hamdache",
      "Ilias Elmouki"
    ],
    "abstract": "The main goal from this study is to discuss the main features of Artificial intelligence (AI) as well as their applicability for early cardiovascular Disease (CVDs) Detection, Material and Method : Systematic review approach Results : It was seen that integrating AI algorithm the diagnosis of CVDs become more accurate and lee time consuming. Conclusion: Now the concept of using AI technologies in cardiovascular health care holds the potential to transform disease management .",
    "categories": [
      "q-bio.TO",
      "cs.AI"
    ],
    "primary_category": "q-bio.TO",
    "comment": "",
    "pdf_url": "https://arxiv.org/pdf/2506.08229v1",
    "published_date": "2025-06-09 20:56:14 UTC",
    "updated_date": "2025-06-09 20:56:14 UTC"
  },
  {
    "arxiv_id": "2506.08228v2",
    "title": "Scaling Laws of Motion Forecasting and Planning -- Technical Report",
    "authors": [
      "Mustafa Baniodeh",
      "Kratarth Goel",
      "Scott Ettinger",
      "Carlos Fuertes",
      "Ari Seff",
      "Tim Shen",
      "Cole Gulino",
      "Chenjie Yang",
      "Ghassen Jerfel",
      "Dokook Choe",
      "Rui Wang",
      "Benjamin Charrow",
      "Vinutha Kallem",
      "Sergio Casas",
      "Rami Al-Rfou",
      "Benjamin Sapp",
      "Dragomir Anguelov"
    ],
    "abstract": "We study the empirical scaling laws of a family of encoder-decoder autoregressive transformer models on the task of joint motion forecasting and planning in the autonomous driving domain. Using a 500 thousand hours driving dataset, we demonstrate that, similar to language modeling, model performance improves as a power-law function of the total compute budget, and we observe a strong correlation between model training loss and model evaluation metrics. Most interestingly, closed-loop metrics also improve with scaling, which has important implications for the suitability of open-loop metrics for model development and hill climbing. We also study the optimal scaling of the number of transformer parameters and the training data size for a training compute-optimal model. We find that as the training compute budget grows, optimal scaling requires increasing the model size 1.5x as fast as the dataset size. We also study inference-time compute scaling, where we observe that sampling and clustering the output of smaller models makes them competitive with larger models, up to a crossover point beyond which a larger models becomes more inference-compute efficient. Overall, our experimental results demonstrate that optimizing the training and inference-time scaling properties of motion forecasting and planning models is a key lever for improving their performance to address a wide variety of driving scenarios. Finally, we briefly study the utility of training on general logged driving data of other agents to improve the performance of the ego-agent, an important research area to address the scarcity of robotics data for large capacity models training.",
    "categories": [
      "cs.LG",
      "cs.AI",
      "cs.RO"
    ],
    "primary_category": "cs.LG",
    "comment": "",
    "pdf_url": "https://arxiv.org/pdf/2506.08228v2",
    "published_date": "2025-06-09 20:54:23 UTC",
    "updated_date": "2025-09-08 00:53:59 UTC"
  },
  {
    "arxiv_id": "2506.08224v2",
    "title": "AI-Assisted Rapid Crystal Structure Generation Towards a Target Local Environment",
    "authors": [
      "Osman Goni Ridwan",
      "Sylvain Pitié",
      "Monish Soundar Raj",
      "Dong Dai",
      "Gilles Frapper",
      "Hongfei Xue",
      "Qiang Zhu"
    ],
    "abstract": "In the field of material design, traditional crystal structure prediction approaches require extensive structural sampling through computationally expensive energy minimization methods using either force fields or quantum mechanical simulations. While emerging artificial intelligence (AI) generative models have shown great promise in generating realistic crystal structures more rapidly, most existing models fail to account for the unique symmetries and periodicity of crystalline materials, and they are limited to handling structures with only a few tens of atoms per unit cell. Here, we present a symmetry-informed AI generative approach called Local Environment Geometry-Oriented Crystal Generator (LEGO-xtal) that overcomes these limitations. Our method generates initial structures using AI models trained on an augmented small dataset, and then optimizes them using machine learning structure descriptors rather than traditional energy-based optimization. We demonstrate the effectiveness of LEGO-xtal by expanding from 25 known low-energy sp2 carbon allotropes to over 1,700, all within 0.5 eV/atom of the ground-state energy of graphite. This framework offers a generalizable strategy for the targeted design of materials with modular building blocks, such as metal-organic frameworks and next-generation battery materials.",
    "categories": [
      "cond-mat.mtrl-sci",
      "cs.AI",
      "physics.comp-ph"
    ],
    "primary_category": "cond-mat.mtrl-sci",
    "comment": "27 pages, 15 figures",
    "pdf_url": "https://arxiv.org/pdf/2506.08224v2",
    "published_date": "2025-06-09 20:47:36 UTC",
    "updated_date": "2025-09-05 02:02:24 UTC"
  },
  {
    "arxiv_id": "2506.08210v1",
    "title": "A Comprehensive Study of Decoder-Only LLMs for Text-to-Image Generation",
    "authors": [
      "Andrew Z. Wang",
      "Songwei Ge",
      "Tero Karras",
      "Ming-Yu Liu",
      "Yogesh Balaji"
    ],
    "abstract": "Both text-to-image generation and large language models (LLMs) have made significant advancements. However, many text-to-image models still employ the somewhat outdated T5 and CLIP as their text encoders. In this work, we investigate the effectiveness of using modern decoder-only LLMs as text encoders for text-to-image diffusion models. We build a standardized training and evaluation pipeline that allows us to isolate and evaluate the effect of different text embeddings. We train a total of 27 text-to-image models with 12 different text encoders to analyze the critical aspects of LLMs that could impact text-to-image generation, including the approaches to extract embeddings, different LLMs variants, and model sizes. Our experiments reveal that the de facto way of using last-layer embeddings as conditioning leads to inferior performance. Instead, we explore embeddings from various layers and find that using layer-normalized averaging across all layers significantly improves alignment with complex prompts. Most LLMs with this conditioning outperform the baseline T5 model, showing enhanced performance in advanced visio-linguistic reasoning skills.",
    "categories": [
      "cs.CV",
      "cs.AI",
      "cs.CL",
      "cs.LG"
    ],
    "primary_category": "cs.CV",
    "comment": "CVPR 2025",
    "pdf_url": "https://arxiv.org/pdf/2506.08210v1",
    "published_date": "2025-06-09 20:29:53 UTC",
    "updated_date": "2025-06-09 20:29:53 UTC"
  },
  {
    "arxiv_id": "2506.08185v2",
    "title": "Agentic Surgical AI: Surgeon Style Fingerprinting and Privacy Risk Quantification via Discrete Diffusion in a Vision-Language-Action Framework",
    "authors": [
      "Huixin Zhan",
      "Jason H. Moore"
    ],
    "abstract": "Surgeons exhibit distinct operating styles shaped by training, experience, and motor behavior-yet most surgical AI systems overlook this personalization signal. We propose a novel agentic modeling approach for surgeon-specific behavior prediction in robotic surgery, combining a discrete diffusion framework with a vision-language-action (VLA) pipeline. Gesture prediction is framed as a structured sequence denoising task, conditioned on multimodal inputs including surgical video, intent language, and personalized embeddings of surgeon identity and skill. These embeddings are encoded through natural language prompts using third-party language models, allowing the model to retain individual behavioral style without exposing explicit identity. We evaluate our method on the JIGSAWS dataset and demonstrate that it accurately reconstructs gesture sequences while learning meaningful motion fingerprints unique to each surgeon. To quantify the privacy implications of personalization, we perform membership inference attacks and find that more expressive embeddings improve task performance but simultaneously increase susceptibility to identity leakage. These findings demonstrate that while personalized embeddings improve performance, they also increase vulnerability to identity leakage, revealing the importance of balancing personalization with privacy risk in surgical modeling. Code is available at: https://github.com/huixin-zhan-ai/Surgeon_style_fingerprinting.",
    "categories": [
      "cs.CV",
      "cs.AI"
    ],
    "primary_category": "cs.CV",
    "comment": "",
    "pdf_url": "https://arxiv.org/pdf/2506.08185v2",
    "published_date": "2025-06-09 19:49:55 UTC",
    "updated_date": "2025-06-14 12:02:06 UTC"
  },
  {
    "arxiv_id": "2506.08184v3",
    "title": "Unable to Forget: Proactive Interference Reveals Working Memory Limits in LLMs Beyond Context Length",
    "authors": [
      "Chupei Wang",
      "Jiaqiu Vince Sun"
    ],
    "abstract": "Information retrieval in Large Language Models (LLMs) is increasingly recognized as intertwined with generation capabilities rather than mere lookup. While longer contexts are often assumed to improve retrieval, the effects of intra-context interference remain understudied. To address this, we adapt the proactive interference (PI) paradigm from cognitive science, where earlier information disrupts recall of newer updates. In humans, susceptibility to such interference is inversely linked to working memory capacity. We introduce PI-LLM, an evaluation that sequentially streams semantically related key-value updates and queries only the final values. Although these final values are clearly positioned just before the query, LLM retrieval accuracy declines log-linearly toward zero as interference accumulates; errors arise from retrieving previously overwritten values. Attempts to mitigate interference via prompt engineering (e.g., instructing models to ignore earlier input) yield limited success. These findings reveal a fundamental constraint on LLMs' ability to disentangle interference and flexibly manipulate information, suggesting a working memory bottleneck beyond mere context access. This calls for approaches that strengthen models' ability to suppress irrelevant content during retrieval.",
    "categories": [
      "cs.CL",
      "cs.AI",
      "q-bio.NC"
    ],
    "primary_category": "cs.CL",
    "comment": "Accepted at ICML 2025 Workshop on Long Context Foundation Models (ICFM). Code: https://github.com/zhuangziGiantfish/Unable-to-Forget",
    "pdf_url": "https://arxiv.org/pdf/2506.08184v3",
    "published_date": "2025-06-09 19:49:11 UTC",
    "updated_date": "2025-07-31 16:45:51 UTC"
  },
  {
    "arxiv_id": "2506.08173v1",
    "title": "Repeton: Structured Bug Repair with ReAct-Guided Patch-and-Test Cycles",
    "authors": [
      "Nguyen Phu Vinh",
      "Anh Chung Hoang",
      "Chris Ngo",
      "Truong-Son Hy"
    ],
    "abstract": "Large Language Models (LLMs) have shown strong capabilities in code generation and comprehension, yet their application to complex software engineering tasks often suffers from low precision and limited interpretability. We present Repeton, a fully open-source framework that leverages LLMs for precise and automated code manipulation in real-world Git repositories. Rather than generating holistic fixes, Repeton operates through a structured patch-and-test pipeline: it iteratively diagnoses issues, proposes code changes, and validates each patch through automated testing. This stepwise process is guided by lightweight heuristics and development tools, avoiding reliance on embedding-based retrieval systems. Evaluated on the SWE-bench Lite benchmark, our method shows good performance compared to RAG-based methods in both patch validity and interpretability. By decomposing software engineering tasks into modular, verifiable stages, Repeton provides a practical path toward scalable and transparent autonomous debugging.",
    "categories": [
      "cs.SE",
      "cs.AI"
    ],
    "primary_category": "cs.SE",
    "comment": "",
    "pdf_url": "https://arxiv.org/pdf/2506.08173v1",
    "published_date": "2025-06-09 19:36:40 UTC",
    "updated_date": "2025-06-09 19:36:40 UTC"
  },
  {
    "arxiv_id": "2506.08171v2",
    "title": "Worst-Case Symbolic Constraints Analysis and Generalisation with Large Language Models",
    "authors": [
      "Daniel Koh",
      "Yannic Noller",
      "Corina S. Pasareanu",
      "Adrians Skapars",
      "Youcheng Sun"
    ],
    "abstract": "Large language models (LLMs) have demonstrated strong performance on coding tasks such as generation, completion and repair, but their ability to handle complex symbolic reasoning over code still remains underexplored. We introduce the task of worst-case symbolic constraints analysis, which requires inferring the symbolic constraints that characterise worst-case program executions; these constraints can be solved to obtain inputs that expose performance bottlenecks or denial-of-service vulnerabilities in software systems. We show that even state-of-the-art LLMs (e.g., GPT-5) struggle when applied directly on this task. To address this challenge, we propose WARP, an innovative neurosymbolic approach that computes worst-case constraints on smaller concrete input sizes using existing program analysis tools, and then leverages LLMs to generalise these constraints to larger input sizes. Concretely, WARP comprises: (1) an incremental strategy for LLM-based worst-case reasoning, (2) a solver-aligned neurosymbolic framework that integrates reinforcement learning with SMT (Satisfiability Modulo Theories) solving, and (3) a curated dataset of symbolic constraints. Experimental results show that WARP consistently improves performance on worst-case constraint reasoning. Leveraging the curated constraint dataset, we use reinforcement learning to fine-tune a model, WARP-1.0-3B, which significantly outperforms size-matched and even larger baselines. These results demonstrate that incremental constraint reasoning enhances LLMs' ability to handle symbolic reasoning and highlight the potential for deeper integration between neural learning and formal methods in rigorous program analysis.",
    "categories": [
      "cs.SE",
      "cs.AI"
    ],
    "primary_category": "cs.SE",
    "comment": "",
    "pdf_url": "https://arxiv.org/pdf/2506.08171v2",
    "published_date": "2025-06-09 19:33:30 UTC",
    "updated_date": "2025-09-16 10:35:33 UTC"
  },
  {
    "arxiv_id": "2506.08167v1",
    "title": "UniVarFL: Uniformity and Variance Regularized Federated Learning for Heterogeneous Data",
    "authors": [
      "Sunny Gupta",
      "Nikita Jangid",
      "Amit Sethi"
    ],
    "abstract": "Federated Learning (FL) often suffers from severe performance degradation when faced with non-IID data, largely due to local classifier bias. Traditional remedies such as global model regularization or layer freezing either incur high computational costs or struggle to adapt to feature shifts. In this work, we propose UniVarFL, a novel FL framework that emulates IID-like training dynamics directly at the client level, eliminating the need for global model dependency. UniVarFL leverages two complementary regularization strategies during local training: Classifier Variance Regularization, which aligns class-wise probability distributions with those expected under IID conditions, effectively mitigating local classifier bias; and Hyperspherical Uniformity Regularization, which encourages a uniform distribution of feature representations across the hypersphere, thereby enhancing the model's ability to generalize under diverse data distributions. Extensive experiments on multiple benchmark datasets demonstrate that UniVarFL outperforms existing methods in accuracy, highlighting its potential as a highly scalable and efficient solution for real-world FL deployments, especially in resource-constrained settings. Code: https://github.com/sunnyinAI/UniVarFL",
    "categories": [
      "cs.LG",
      "cs.AI",
      "cs.CV",
      "cs.DC"
    ],
    "primary_category": "cs.LG",
    "comment": "",
    "pdf_url": "https://arxiv.org/pdf/2506.08167v1",
    "published_date": "2025-06-09 19:25:35 UTC",
    "updated_date": "2025-06-09 19:25:35 UTC"
  },
  {
    "arxiv_id": "2506.08153v1",
    "title": "A Metrics-Oriented Architectural Model to Characterize Complexity on Machine Learning-Enabled Systems",
    "authors": [
      "Renato Cordeiro Ferreira"
    ],
    "abstract": "How can the complexity of ML-enabled systems be managed effectively? The goal of this research is to investigate how complexity affects ML-Enabled Systems (MLES). To address this question, this research aims to introduce a metrics-based architectural model to characterize the complexity of MLES. The goal is to support architectural decisions, providing a guideline for the inception and growth of these systems. This paper showcases the first step for creating the metrics-based architectural model: an extension of a reference architecture that can describe MLES to collect their metrics.",
    "categories": [
      "cs.SE",
      "cs.AI",
      "cs.LG"
    ],
    "primary_category": "cs.SE",
    "comment": "4 pages, 3 figures (2 diagrams, 1 table), to be published in CAIN 2025",
    "pdf_url": "https://arxiv.org/pdf/2506.08153v1",
    "published_date": "2025-06-09 19:02:19 UTC",
    "updated_date": "2025-06-09 19:02:19 UTC"
  },
  {
    "arxiv_id": "2506.08150v1",
    "title": "Compiling Metric Temporal Answer Set Programming",
    "authors": [
      "Arvid Becker",
      "Pedro Cabalar",
      "Martin Diéguez",
      "Javier Romero",
      "Susana Hahn",
      "Torsten Schaub"
    ],
    "abstract": "We develop a computational approach to Metric Answer Set Programming (ASP) to allow for expressing quantitative temporal constrains, like durations and deadlines. A central challenge is to maintain scalability when dealing with fine-grained timing constraints, which can significantly exacerbate ASP's grounding bottleneck. To address this issue, we leverage extensions of ASP with difference constraints, a simplified form of linear constraints, to handle time-related aspects externally. Our approach effectively decouples metric ASP from the granularity of time, resulting in a solution that is unaffected by time precision.",
    "categories": [
      "cs.AI",
      "cs.LO"
    ],
    "primary_category": "cs.AI",
    "comment": "",
    "pdf_url": "https://arxiv.org/pdf/2506.08150v1",
    "published_date": "2025-06-09 18:56:57 UTC",
    "updated_date": "2025-06-09 18:56:57 UTC"
  },
  {
    "arxiv_id": "2506.08149v1",
    "title": "Ego-centric Learning of Communicative World Models for Autonomous Driving",
    "authors": [
      "Hang Wang",
      "Dechen Gao",
      "Junshan Zhang"
    ],
    "abstract": "We study multi-agent reinforcement learning (MARL) for tasks in complex high-dimensional environments, such as autonomous driving. MARL is known to suffer from the \\textit{partial observability} and \\textit{non-stationarity} issues. To tackle these challenges, information sharing is often employed, which however faces major hurdles in practice, including overwhelming communication overhead and scalability concerns. By making use of generative AI embodied in world model together with its latent representation, we develop {\\it CALL}, \\underline{C}ommunic\\underline{a}tive Wor\\underline{l}d Mode\\underline{l}, for MARL, where 1) each agent first learns its world model that encodes its state and intention into low-dimensional latent representation with smaller memory footprint, which can be shared with other agents of interest via lightweight communication; and 2) each agent carries out ego-centric learning while exploiting lightweight information sharing to enrich her world model, and then exploits its generalization capacity to improve prediction for better planning. We characterize the gain on the prediction accuracy from the information sharing and its impact on performance gap. Extensive experiments are carried out on the challenging local trajectory planning tasks in the CARLA platform to demonstrate the performance gains of using \\textit{CALL}.",
    "categories": [
      "cs.RO",
      "cs.AI"
    ],
    "primary_category": "cs.RO",
    "comment": "",
    "pdf_url": "https://arxiv.org/pdf/2506.08149v1",
    "published_date": "2025-06-09 18:56:40 UTC",
    "updated_date": "2025-06-09 18:56:40 UTC"
  },
  {
    "arxiv_id": "2506.08147v1",
    "title": "Multilingual Hate Speech Detection in Social Media Using Translation-Based Approaches with Large Language Models",
    "authors": [
      "Muhammad Usman",
      "Muhammad Ahmad",
      "M. Shahiki Tash",
      "Irina Gelbukh",
      "Rolando Quintero Tellez",
      "Grigori Sidorov"
    ],
    "abstract": "Social media platforms are critical spaces for public discourse, shaping opinions and community dynamics, yet their widespread use has amplified harmful content, particularly hate speech, threatening online safety and inclusivity. While hate speech detection has been extensively studied in languages like English and Spanish, Urdu remains underexplored, especially using translation-based approaches. To address this gap, we introduce a trilingual dataset of 10,193 tweets in English (3,834 samples), Urdu (3,197 samples), and Spanish (3,162 samples), collected via keyword filtering, with a balanced distribution of 4,849 Hateful and 5,344 Not-Hateful labels. Our methodology leverages attention layers as a precursor to transformer-based models and large language models (LLMs), enhancing feature extraction for multilingual hate speech detection. For non-transformer models, we use TF-IDF for feature extraction. The dataset is benchmarked using state-of-the-art models, including GPT-3.5 Turbo and Qwen 2.5 72B, alongside traditional machine learning models like SVM and other transformers (e.g., BERT, RoBERTa). Three annotators, following rigorous guidelines, ensured high dataset quality, achieving a Fleiss' Kappa of 0.821. Our approach, integrating attention layers with GPT-3.5 Turbo and Qwen 2.5 72B, achieves strong performance, with macro F1 scores of 0.87 for English (GPT-3.5 Turbo), 0.85 for Spanish (GPT-3.5 Turbo), 0.81 for Urdu (Qwen 2.5 72B), and 0.88 for the joint multilingual model (Qwen 2.5 72B). These results reflect improvements of 8.75% in English (over SVM baseline 0.80), 8.97% in Spanish (over SVM baseline 0.78), 5.19% in Urdu (over SVM baseline 0.77), and 7.32% in the joint multilingual model (over SVM baseline 0.82). Our framework offers a robust solution for multilingual hate speech detection, fostering safer digital communities worldwide.",
    "categories": [
      "cs.CL",
      "cs.AI",
      "cs.LG"
    ],
    "primary_category": "cs.CL",
    "comment": "",
    "pdf_url": "https://arxiv.org/pdf/2506.08147v1",
    "published_date": "2025-06-09 18:53:56 UTC",
    "updated_date": "2025-06-09 18:53:56 UTC"
  },
  {
    "arxiv_id": "2506.08139v2",
    "title": "SoftStep: Learning Sparse Similarity Powers Deep Neighbor-Based Regression",
    "authors": [
      "Aviad Susman",
      "Baihan Lin",
      "Mayte Suárez-Fariñas",
      "Joseph T Colonel"
    ],
    "abstract": "Neighbor-based methods are a natural alternative to linear prediction for tabular data when relationships between inputs and targets exhibit complexity such as nonlinearity, periodicity, or heteroscedasticity. Yet in deep learning on unstructured data, nonparametric neighbor-based approaches are rarely implemented in lieu of simple linear heads. This is primarily due to the ability of systems equipped with linear regression heads to co-learn internal representations along with the linear head's parameters. To unlock the full potential of neighbor-based methods in neural networks we introduce SoftStep, a parametric module that learns sparse instance-wise similarity measures directly from data. When integrated with existing neighbor-based methods, SoftStep enables regression models that consistently outperform linear heads across diverse architectures, domains, and training scenarios. We focus on regression tasks, where we show theoretically that neighbor-based prediction with a mean squared error objective constitutes a metric learning algorithm that induces well-structured embedding spaces. We then demonstrate analytically and empirically that this representational structure translates into superior performance when combined with the sparse, instance-wise similarity measures introduced by SoftStep. Beyond regression, SoftStep is a general method for learning instance-wise similarity in deep neural networks, with broad applicability to attention mechanisms, metric learning, representational alignment, and related paradigms.",
    "categories": [
      "cs.LG",
      "cs.AI"
    ],
    "primary_category": "cs.LG",
    "comment": "",
    "pdf_url": "https://arxiv.org/pdf/2506.08139v2",
    "published_date": "2025-06-09 18:41:48 UTC",
    "updated_date": "2025-12-04 15:32:42 UTC"
  },
  {
    "arxiv_id": "2506.08137v2",
    "title": "IGraSS: Learning to Identify Infrastructure Networks from Satellite Imagery by Iterative Graph-constrained Semantic Segmentation",
    "authors": [
      "Oishee Bintey Hoque",
      "Abhijin Adiga",
      "Aniruddha Adiga",
      "Siddharth Chaudhary",
      "Madhav V. Marathe",
      "S. S. Ravi",
      "Kirti Rajagopalan",
      "Amanda Wilson",
      "Samarth Swarup"
    ],
    "abstract": "Accurate canal network mapping is essential for water management, including irrigation planning and infrastructure maintenance. State-of-the-art semantic segmentation models for infrastructure mapping, such as roads, rely on large, well-annotated remote sensing datasets. However, incomplete or inadequate ground truth can hinder these learning approaches. Many infrastructure networks have graph-level properties such as reachability to a source (like canals) or connectivity (roads) that can be leveraged to improve these existing ground truth. This paper develops a novel iterative framework IGraSS, combining a semantic segmentation module-incorporating RGB and additional modalities (NDWI, DEM)-with a graph-based ground-truth refinement module. The segmentation module processes satellite imagery patches, while the refinement module operates on the entire data viewing the infrastructure network as a graph. Experiments show that IGraSS reduces unreachable canal segments from around 18% to 3%, and training with refined ground truth significantly improves canal identification. IGraSS serves as a robust framework for both refining noisy ground truth and mapping canal networks from remote sensing imagery. We also demonstrate the effectiveness and generalizability of IGraSS using road networks as an example, applying a different graph-theoretic constraint to complete road networks.",
    "categories": [
      "cs.CV",
      "cs.AI"
    ],
    "primary_category": "cs.CV",
    "comment": "",
    "pdf_url": "https://arxiv.org/pdf/2506.08137v2",
    "published_date": "2025-06-09 18:40:22 UTC",
    "updated_date": "2025-06-11 02:45:23 UTC"
  },
  {
    "arxiv_id": "2506.08134v3",
    "title": "The AI Imperative: Scaling High-Quality Peer Review in Machine Learning",
    "authors": [
      "Qiyao Wei",
      "Samuel Holt",
      "Jing Yang",
      "Markus Wulfmeier",
      "Mihaela van der Schaar"
    ],
    "abstract": "Peer review, the bedrock of scientific advancement in machine learning (ML), is strained by a crisis of scale. Exponential growth in manuscript submissions to premier ML venues such as NeurIPS, ICML, and ICLR is outpacing the finite capacity of qualified reviewers, leading to concerns about review quality, consistency, and reviewer fatigue. This position paper argues that AI-assisted peer review must become an urgent research and infrastructure priority. We advocate for a comprehensive AI-augmented ecosystem, leveraging Large Language Models (LLMs) not as replacements for human judgment, but as sophisticated collaborators for authors, reviewers, and Area Chairs (ACs). We propose specific roles for AI in enhancing factual verification, guiding reviewer performance, assisting authors in quality improvement, and supporting ACs in decision-making. Crucially, we contend that the development of such systems hinges on access to more granular, structured, and ethically-sourced peer review process data. We outline a research agenda, including illustrative experiments, to develop and validate these AI assistants, and discuss significant technical and ethical challenges. We call upon the ML community to proactively build this AI-assisted future, ensuring the continued integrity and scalability of scientific validation, while maintaining high standards of peer review.",
    "categories": [
      "cs.AI",
      "cs.CY"
    ],
    "primary_category": "cs.AI",
    "comment": "18 pages, 3 figures. Position paper",
    "pdf_url": "https://arxiv.org/pdf/2506.08134v3",
    "published_date": "2025-06-09 18:37:14 UTC",
    "updated_date": "2025-06-27 14:00:06 UTC"
  },
  {
    "arxiv_id": "2506.08119v1",
    "title": "SOP-Bench: Complex Industrial SOPs for Evaluating LLM Agents",
    "authors": [
      "Subhrangshu Nandi",
      "Arghya Datta",
      "Nikhil Vichare",
      "Indranil Bhattacharya",
      "Huzefa Raja",
      "Jing Xu",
      "Shayan Ray",
      "Giuseppe Carenini",
      "Abhi Srivastava",
      "Aaron Chan",
      "Man Ho Woo",
      "Amar Kandola",
      "Brandon Theresa",
      "Francesco Carbone"
    ],
    "abstract": "Large Language Models (LLMs) demonstrate impressive general-purpose reasoning and problem-solving abilities. However, they struggle with executing complex, long-horizon workflows that demand strict adherence to Standard Operating Procedures (SOPs), a critical requirement for real-world industrial automation. Despite this need, there is a lack of public benchmarks that reflect the complexity, structure, and domain-specific nuances of SOPs. To address this, we present three main contributions. First, we introduce a synthetic data generation framework to create realistic, industry-grade SOPs that rigorously test the planning, reasoning, and tool-use capabilities of LLM-based agents. Second, using this framework, we develop SOP-Bench, a benchmark of over 1,800 tasks across 10 industrial domains, each with APIs, tool interfaces, and human-validated test cases. Third, we evaluate two prominent agent architectures: Function-Calling and ReAct Agents, on SOP-Bench, observing average success rates of only 27% and 48%, respectively. Remarkably, when the tool registry is much larger than necessary, agents invoke incorrect tools nearly 100% of the time. These findings underscore a substantial gap between current agentic capabilities of LLMs and the demands of automating real-world SOPs. Performance varies significantly by task and domain, highlighting the need for domain-specific benchmarking and architectural choices before deployment. SOP-Bench is publicly available at http://sop-bench.s3-website-us-west-2.amazonaws.com/. We also release the prompts underpinning the data generation framework to support new domain-specific SOP benchmarks. We invite the community to extend SOP-Bench with SOPs from their industrial domains.",
    "categories": [
      "cs.AI"
    ],
    "primary_category": "cs.AI",
    "comment": "Under review",
    "pdf_url": "https://arxiv.org/pdf/2506.08119v1",
    "published_date": "2025-06-09 18:20:12 UTC",
    "updated_date": "2025-06-09 18:20:12 UTC"
  },
  {
    "arxiv_id": "2506.08113v2",
    "title": "Benchmarking Pre-Trained Time Series Models for Electricity Price Forecasting",
    "authors": [
      "Timothée Hornek Amir Sartipi",
      "Igor Tchappi",
      "Gilbert Fridgen"
    ],
    "abstract": "Accurate electricity price forecasting (EPF) is crucial for effective decision-making in power trading on the spot market. While recent advances in generative artificial intelligence (GenAI) and pre-trained large language models (LLMs) have inspired the development of numerous time series foundation models (TSFMs) for time series forecasting, their effectiveness in EPF remains uncertain. To address this gap, we benchmark several state-of-the-art pretrained models--Chronos-Bolt, Chronos-T5, TimesFM, Moirai, Time-MoE, and TimeGPT--against established statistical and machine learning (ML) methods for EPF. Using 2024 day-ahead auction (DAA) electricity prices from Germany, France, the Netherlands, Austria, and Belgium, we generate daily forecasts with a one-day horizon. Chronos-Bolt and Time-MoE emerge as the strongest among the TSFMs, performing on par with traditional models. However, the biseasonal MSTL model, which captures daily and weekly seasonality, stands out for its consistent performance across countries and evaluation metrics, with no TSFM statistically outperforming it.",
    "categories": [
      "cs.LG",
      "cs.AI",
      "q-fin.ST"
    ],
    "primary_category": "cs.LG",
    "comment": "",
    "pdf_url": "https://arxiv.org/pdf/2506.08113v2",
    "published_date": "2025-06-09 18:10:00 UTC",
    "updated_date": "2025-08-20 07:59:08 UTC"
  },
  {
    "arxiv_id": "2506.08098v1",
    "title": "Cognitive Weave: Synthesizing Abstracted Knowledge with a Spatio-Temporal Resonance Graph",
    "authors": [
      "Akash Vishwakarma",
      "Hojin Lee",
      "Mohith Suresh",
      "Priyam Shankar Sharma",
      "Rahul Vishwakarma",
      "Sparsh Gupta",
      "Yuvraj Anupam Chauhan"
    ],
    "abstract": "The emergence of capable large language model (LLM) based agents necessitates memory architectures that transcend mere data storage, enabling continuous learning, nuanced reasoning, and dynamic adaptation. Current memory systems often grapple with fundamental limitations in structural flexibility, temporal awareness, and the ability to synthesize higher-level insights from raw interaction data. This paper introduces Cognitive Weave, a novel memory framework centered around a multi-layered spatio-temporal resonance graph (STRG). This graph manages information as semantically rich insight particles (IPs), which are dynamically enriched with resonance keys, signifiers, and situational imprints via a dedicated semantic oracle interface (SOI). These IPs are interconnected through typed relational strands, forming an evolving knowledge tapestry. A key component of Cognitive Weave is the cognitive refinement process, an autonomous mechanism that includes the synthesis of insight aggregates (IAs) condensed, higher-level knowledge structures derived from identified clusters of related IPs. We present comprehensive experimental results demonstrating Cognitive Weave's marked enhancement over existing approaches in long-horizon planning tasks, evolving question-answering scenarios, and multi-session dialogue coherence. The system achieves a notable 34% average improvement in task completion rates and a 42% reduction in mean query latency when compared to state-of-the-art baselines. Furthermore, this paper explores the ethical considerations inherent in such advanced memory systems, discusses the implications for long-term memory in LLMs, and outlines promising future research trajectories.",
    "categories": [
      "cs.AI"
    ],
    "primary_category": "cs.AI",
    "comment": "",
    "pdf_url": "https://arxiv.org/pdf/2506.08098v1",
    "published_date": "2025-06-09 18:00:46 UTC",
    "updated_date": "2025-06-09 18:00:46 UTC"
  },
  {
    "arxiv_id": "2506.08013v1",
    "title": "StableMTL: Repurposing Latent Diffusion Models for Multi-Task Learning from Partially Annotated Synthetic Datasets",
    "authors": [
      "Anh-Quan Cao",
      "Ivan Lopes",
      "Raoul de Charette"
    ],
    "abstract": "Multi-task learning for dense prediction is limited by the need for extensive annotation for every task, though recent works have explored training with partial task labels. Leveraging the generalization power of diffusion models, we extend the partial learning setup to a zero-shot setting, training a multi-task model on multiple synthetic datasets, each labeled for only a subset of tasks. Our method, StableMTL, repurposes image generators for latent regression. Adapting a denoising framework with task encoding, per-task conditioning and a tailored training scheme. Instead of per-task losses requiring careful balancing, a unified latent loss is adopted, enabling seamless scaling to more tasks. To encourage inter-task synergy, we introduce a multi-stream model with a task-attention mechanism that converts N-to-N task interactions into efficient 1-to-N attention, promoting effective cross-task sharing. StableMTL outperforms baselines on 7 tasks across 8 benchmarks.",
    "categories": [
      "cs.CV",
      "cs.AI",
      "cs.LG"
    ],
    "primary_category": "cs.CV",
    "comment": "Code is available at https://github.com/astra-vision/StableMTL",
    "pdf_url": "https://arxiv.org/pdf/2506.08013v1",
    "published_date": "2025-06-09 17:59:59 UTC",
    "updated_date": "2025-06-09 17:59:59 UTC"
  },
  {
    "arxiv_id": "2506.08012v1",
    "title": "GUI-Reflection: Empowering Multimodal GUI Models with Self-Reflection Behavior",
    "authors": [
      "Penghao Wu",
      "Shengnan Ma",
      "Bo Wang",
      "Jiaheng Yu",
      "Lewei Lu",
      "Ziwei Liu"
    ],
    "abstract": "Multimodal Large Language Models (MLLMs) have shown great potential in revolutionizing Graphical User Interface (GUI) automation. However, existing GUI models mostly rely on learning from nearly error-free offline trajectories, thus lacking reflection and error recovery capabilities. To bridge this gap, we propose GUI-Reflection, a novel framework that explicitly integrates self-reflection and error correction capabilities into end-to-end multimodal GUI models throughout dedicated training stages: GUI-specific pre-training, offline supervised fine-tuning (SFT), and online reflection tuning. GUI-reflection enables self-reflection behavior emergence with fully automated data generation and learning processes without requiring any human annotation. Specifically, 1) we first propose scalable data pipelines to automatically construct reflection and error correction data from existing successful trajectories. While existing GUI models mainly focus on grounding and UI understanding ability, we propose the GUI-Reflection Task Suite to learn and evaluate reflection-oriented abilities explicitly. 2) Furthermore, we built a diverse and efficient environment for online training and data collection of GUI models on mobile devices. 3) We also present an iterative online reflection tuning algorithm leveraging the proposed environment, enabling the model to continuously enhance its reflection and error correction abilities. Our framework equips GUI agents with self-reflection and correction capabilities, paving the way for more robust, adaptable, and intelligent GUI automation, with all data, models, environments, and tools to be released publicly.",
    "categories": [
      "cs.AI",
      "cs.CV"
    ],
    "primary_category": "cs.AI",
    "comment": "Project Page at https://penghao-wu.github.io/GUI_Reflection/",
    "pdf_url": "https://arxiv.org/pdf/2506.08012v1",
    "published_date": "2025-06-09 17:59:57 UTC",
    "updated_date": "2025-06-09 17:59:57 UTC"
  },
  {
    "arxiv_id": "2506.08010v5",
    "title": "Vision Transformers Don't Need Trained Registers",
    "authors": [
      "Nick Jiang",
      "Amil Dravid",
      "Alexei Efros",
      "Yossi Gandelsman"
    ],
    "abstract": "We investigate the mechanism underlying a previously identified phenomenon in Vision Transformers - the emergence of high-norm tokens that lead to noisy attention maps (Darcet et al., 2024). We observe that in multiple models (e.g., CLIP, DINOv2), a sparse set of neurons is responsible for concentrating high-norm activations on outlier tokens, leading to irregular attention patterns and degrading downstream visual processing. While the existing solution for removing these outliers involves retraining models from scratch with additional learned register tokens, we use our findings to create a training-free approach to mitigate these artifacts. By shifting the high-norm activations from our discovered register neurons into an additional untrained token, we can mimic the effect of register tokens on a model already trained without registers. We demonstrate that our method produces cleaner attention and feature maps, enhances performance over base models across multiple downstream visual tasks, and achieves results comparable to models explicitly trained with register tokens. We then extend test-time registers to off-the-shelf vision-language models, yielding cleaner attention-based, text-to-image attribution. Finally, we outline a simple mathematical model that reflects the observed behavior of register neurons and high norm tokens. Our results suggest that test-time registers effectively take on the role of register tokens at test-time, offering a training-free solution for any pre-trained model released without them.",
    "categories": [
      "cs.CV",
      "cs.AI"
    ],
    "primary_category": "cs.CV",
    "comment": "Project page and code: https://avdravid.github.io/test-time-registers. Accepted to NeurIPS '25 (spotlight)",
    "pdf_url": "https://arxiv.org/pdf/2506.08010v5",
    "published_date": "2025-06-09 17:59:57 UTC",
    "updated_date": "2025-10-25 03:27:47 UTC"
  },
  {
    "arxiv_id": "2506.08009v2",
    "title": "Self Forcing: Bridging the Train-Test Gap in Autoregressive Video Diffusion",
    "authors": [
      "Xun Huang",
      "Zhengqi Li",
      "Guande He",
      "Mingyuan Zhou",
      "Eli Shechtman"
    ],
    "abstract": "We introduce Self Forcing, a novel training paradigm for autoregressive video diffusion models. It addresses the longstanding issue of exposure bias, where models trained on ground-truth context must generate sequences conditioned on their own imperfect outputs during inference. Unlike prior methods that denoise future frames based on ground-truth context frames, Self Forcing conditions each frame's generation on previously self-generated outputs by performing autoregressive rollout with key-value (KV) caching during training. This strategy enables supervision through a holistic loss at the video level that directly evaluates the quality of the entire generated sequence, rather than relying solely on traditional frame-wise objectives. To ensure training efficiency, we employ a few-step diffusion model along with a stochastic gradient truncation strategy, effectively balancing computational cost and performance. We further introduce a rolling KV cache mechanism that enables efficient autoregressive video extrapolation. Extensive experiments demonstrate that our approach achieves real-time streaming video generation with sub-second latency on a single GPU, while matching or even surpassing the generation quality of significantly slower and non-causal diffusion models. Project website: http://self-forcing.github.io/",
    "categories": [
      "cs.CV",
      "cs.AI",
      "cs.LG"
    ],
    "primary_category": "cs.CV",
    "comment": "NeurIPS 2025 spotlight. Project website: http://self-forcing.github.io/",
    "pdf_url": "https://arxiv.org/pdf/2506.08009v2",
    "published_date": "2025-06-09 17:59:55 UTC",
    "updated_date": "2025-11-10 04:36:27 UTC"
  },
  {
    "arxiv_id": "2506.08008v1",
    "title": "Hidden in plain sight: VLMs overlook their visual representations",
    "authors": [
      "Stephanie Fu",
      "Tyler Bonnen",
      "Devin Guillory",
      "Trevor Darrell"
    ],
    "abstract": "Language provides a natural interface to specify and evaluate performance on visual tasks. To realize this possibility, vision language models (VLMs) must successfully integrate visual and linguistic information. Our work compares VLMs to a direct readout of their visual encoders to understand their ability to integrate across these modalities. Across a series of vision-centric benchmarks (e.g., depth estimation, correspondence), we find that VLMs perform substantially worse than their visual encoders, dropping to near-chance performance. We investigate these results through a series of analyses across the entire VLM: namely 1) the degradation of vision representations, 2) brittleness to task prompt, and 3) the language model's role in solving the task. We find that the bottleneck in performing these vision-centric tasks lies in this third category; VLMs are not effectively using visual information easily accessible throughout the entire model, and they inherit the language priors present in the LLM. Our work helps diagnose the failure modes of open-source VLMs, and presents a series of evaluations useful for future investigations into visual understanding within VLMs.",
    "categories": [
      "cs.CV",
      "cs.AI",
      "cs.LG"
    ],
    "primary_category": "cs.CV",
    "comment": "Project page: https://hidden-plain-sight.github.io/",
    "pdf_url": "https://arxiv.org/pdf/2506.08008v1",
    "published_date": "2025-06-09 17:59:54 UTC",
    "updated_date": "2025-06-09 17:59:54 UTC"
  },
  {
    "arxiv_id": "2506.08004v1",
    "title": "Dynamic View Synthesis as an Inverse Problem",
    "authors": [
      "Hidir Yesiltepe",
      "Pinar Yanardag"
    ],
    "abstract": "In this work, we address dynamic view synthesis from monocular videos as an inverse problem in a training-free setting. By redesigning the noise initialization phase of a pre-trained video diffusion model, we enable high-fidelity dynamic view synthesis without any weight updates or auxiliary modules. We begin by identifying a fundamental obstacle to deterministic inversion arising from zero-terminal signal-to-noise ratio (SNR) schedules and resolve it by introducing a novel noise representation, termed K-order Recursive Noise Representation. We derive a closed form expression for this representation, enabling precise and efficient alignment between the VAE-encoded and the DDIM inverted latents. To synthesize newly visible regions resulting from camera motion, we introduce Stochastic Latent Modulation, which performs visibility aware sampling over the latent space to complete occluded regions. Comprehensive experiments demonstrate that dynamic view synthesis can be effectively performed through structured latent manipulation in the noise initialization phase.",
    "categories": [
      "cs.CV",
      "cs.AI"
    ],
    "primary_category": "cs.CV",
    "comment": "Project Page: https://inverse-dvs.github.io/",
    "pdf_url": "https://arxiv.org/pdf/2506.08004v1",
    "published_date": "2025-06-09 17:59:47 UTC",
    "updated_date": "2025-06-09 17:59:47 UTC"
  },
  {
    "arxiv_id": "2506.08003v1",
    "title": "Audio-Sync Video Generation with Multi-Stream Temporal Control",
    "authors": [
      "Shuchen Weng",
      "Haojie Zheng",
      "Zheng Chang",
      "Si Li",
      "Boxin Shi",
      "Xinlong Wang"
    ],
    "abstract": "Audio is inherently temporal and closely synchronized with the visual world, making it a naturally aligned and expressive control signal for controllable video generation (e.g., movies). Beyond control, directly translating audio into video is essential for understanding and visualizing rich audio narratives (e.g., Podcasts or historical recordings). However, existing approaches fall short in generating high-quality videos with precise audio-visual synchronization, especially across diverse and complex audio types. In this work, we introduce MTV, a versatile framework for audio-sync video generation. MTV explicitly separates audios into speech, effects, and music tracks, enabling disentangled control over lip motion, event timing, and visual mood, respectively -- resulting in fine-grained and semantically aligned video generation. To support the framework, we additionally present DEMIX, a dataset comprising high-quality cinematic videos and demixed audio tracks. DEMIX is structured into five overlapped subsets, enabling scalable multi-stage training for diverse generation scenarios. Extensive experiments demonstrate that MTV achieves state-of-the-art performance across six standard metrics spanning video quality, text-video consistency, and audio-video alignment. Project page: https://hjzheng.net/projects/MTV/.",
    "categories": [
      "cs.CV",
      "cs.AI"
    ],
    "primary_category": "cs.CV",
    "comment": "",
    "pdf_url": "https://arxiv.org/pdf/2506.08003v1",
    "published_date": "2025-06-09 17:59:42 UTC",
    "updated_date": "2025-06-09 17:59:42 UTC"
  },
  {
    "arxiv_id": "2506.08001v4",
    "title": "Reparameterized LLM Training via Orthogonal Equivalence Transformation",
    "authors": [
      "Zeju Qiu",
      "Simon Buchholz",
      "Tim Z. Xiao",
      "Maximilian Dax",
      "Bernhard Schölkopf",
      "Weiyang Liu"
    ],
    "abstract": "While large language models (LLMs) are driving the rapid advancement of artificial intelligence, effectively and reliably training these large models remains one of the field's most significant challenges. To address this challenge, we propose POET, a novel reParameterized training algorithm that uses Orthogonal Equivalence Transformation to optimize neurons. Specifically, POET reparameterizes each neuron with two learnable orthogonal matrices and a fixed random weight matrix. Because of its provable preservation of spectral properties of weight matrices, POET can stably optimize the objective function with improved generalization. We further develop efficient approximations that make POET flexible and scalable for training large-scale neural networks. Extensive experiments validate the effectiveness and scalability of POET in training LLMs.",
    "categories": [
      "cs.LG",
      "cs.AI",
      "cs.CL"
    ],
    "primary_category": "cs.LG",
    "comment": "NeurIPS 2025 (40 pages, 26 figures, project page: https://spherelab.ai/poet/, v4: added experiments of finetuning and larger-scale pretraining)",
    "pdf_url": "https://arxiv.org/pdf/2506.08001v4",
    "published_date": "2025-06-09 17:59:34 UTC",
    "updated_date": "2025-12-10 21:22:55 UTC"
  },
  {
    "arxiv_id": "2506.08074v1",
    "title": "Hierarchical Lexical Graph for Enhanced Multi-Hop Retrieval",
    "authors": [
      "Abdellah Ghassel",
      "Ian Robinson",
      "Gabriel Tanase",
      "Hal Cooper",
      "Bryan Thompson",
      "Zhen Han",
      "Vassilis N. Ioannidis",
      "Soji Adeshina",
      "Huzefa Rangwala"
    ],
    "abstract": "Retrieval-Augmented Generation (RAG) grounds large language models in external evidence, yet it still falters when answers must be pieced together across semantically distant documents. We close this gap with the Hierarchical Lexical Graph (HLG), a three-tier index that (i) traces every atomic proposition to its source, (ii) clusters propositions into latent topics, and (iii) links entities and relations to expose cross-document paths. On top of HLG we build two complementary, plug-and-play retrievers: StatementGraphRAG, which performs fine-grained entity-aware beam search over propositions for high-precision factoid questions, and TopicGraphRAG, which selects coarse topics before expanding along entity links to supply broad yet relevant context for exploratory queries. Additionally, existing benchmarks lack the complexity required to rigorously evaluate multi-hop summarization systems, often focusing on single-document queries or limited datasets. To address this, we introduce a synthetic dataset generation pipeline that curates realistic, multi-document question-answer pairs, enabling robust evaluation of multi-hop retrieval systems. Extensive experiments across five datasets demonstrate that our methods outperform naive chunk-based RAG achieving an average relative improvement of 23.1% in retrieval recall and correctness. Open-source Python library is available at https://github.com/awslabs/graphrag-toolkit.",
    "categories": [
      "cs.IR",
      "cs.AI",
      "cs.CL"
    ],
    "primary_category": "cs.IR",
    "comment": "KDD '25",
    "pdf_url": "https://arxiv.org/pdf/2506.08074v1",
    "published_date": "2025-06-09 17:58:35 UTC",
    "updated_date": "2025-06-09 17:58:35 UTC"
  },
  {
    "arxiv_id": "2506.08073v1",
    "title": "Domain Switching on the Pareto Front: Multi-Objective Deep Kernel Learning in Automated Piezoresponse Force Microscopy",
    "authors": [
      "Yu Liu",
      "Utkarsh Pratiush",
      "Kamyar Barakati",
      "Hiroshi Funakubo",
      "Ching-Che Lin",
      "Jaegyu Kim",
      "Lane W. Martin",
      "Sergei V. Kalinin"
    ],
    "abstract": "Ferroelectric polarization switching underpins the functional performance of a wide range of materials and devices, yet its dependence on complex local microstructural features renders systematic exploration by manual or grid-based spectroscopic measurements impractical. Here, we introduce a multi-objective kernel-learning workflow that infers the microstructural rules governing switching behavior directly from high-resolution imaging data. Applied to automated piezoresponse force microscopy (PFM) experiments, our framework efficiently identifies the key relationships between domain-wall configurations and local switching kinetics, revealing how specific wall geometries and defect distributions modulate polarization reversal. Post-experiment analysis projects abstract reward functions, such as switching ease and domain symmetry, onto physically interpretable descriptors including domain configuration and proximity to boundaries. This enables not only high-throughput active learning, but also mechanistic insight into the microstructural control of switching phenomena. While demonstrated for ferroelectric domain switching, our approach provides a powerful, generalizable tool for navigating complex, non-differentiable design spaces, from structure-property correlations in molecular discovery to combinatorial optimization across diverse imaging modalities.",
    "categories": [
      "cond-mat.mtrl-sci",
      "cond-mat.mes-hall",
      "cs.AI",
      "cs.LG"
    ],
    "primary_category": "cond-mat.mtrl-sci",
    "comment": "",
    "pdf_url": "https://arxiv.org/pdf/2506.08073v1",
    "published_date": "2025-06-09 17:58:27 UTC",
    "updated_date": "2025-06-09 17:58:27 UTC"
  },
  {
    "arxiv_id": "2506.10024v1",
    "title": "Private Memorization Editing: Turning Memorization into a Defense to Strengthen Data Privacy in Large Language Models",
    "authors": [
      "Elena Sofia Ruzzetti",
      "Giancarlo A. Xompero",
      "Davide Venditti",
      "Fabio Massimo Zanzotto"
    ],
    "abstract": "Large Language Models (LLMs) memorize, and thus, among huge amounts of uncontrolled data, may memorize Personally Identifiable Information (PII), which should not be stored and, consequently, not leaked. In this paper, we introduce Private Memorization Editing (PME), an approach for preventing private data leakage that turns an apparent limitation, that is, the LLMs' memorization ability, into a powerful privacy defense strategy. While attacks against LLMs have been performed exploiting previous knowledge regarding their training data, our approach aims to exploit the same kind of knowledge in order to make a model more robust. We detect a memorized PII and then mitigate the memorization of PII by editing a model knowledge of its training data. We verify that our procedure does not affect the underlying language model while making it more robust against privacy Training Data Extraction attacks. We demonstrate that PME can effectively reduce the number of leaked PII in a number of configurations, in some cases even reducing the accuracy of the privacy attacks to zero.",
    "categories": [
      "cs.CR",
      "cs.AI",
      "cs.CL"
    ],
    "primary_category": "cs.CR",
    "comment": "To be published at ACL 2025 (Main)",
    "pdf_url": "https://arxiv.org/pdf/2506.10024v1",
    "published_date": "2025-06-09 17:57:43 UTC",
    "updated_date": "2025-06-09 17:57:43 UTC"
  },
  {
    "arxiv_id": "2506.07982v1",
    "title": "$τ^2$-Bench: Evaluating Conversational Agents in a Dual-Control Environment",
    "authors": [
      "Victor Barres",
      "Honghua Dong",
      "Soham Ray",
      "Xujie Si",
      "Karthik Narasimhan"
    ],
    "abstract": "Existing benchmarks for conversational AI agents simulate single-control environments, where only the AI agent can use tools to interact with the world, while the user remains a passive information provider. This differs from real-world scenarios like technical support, where users need to actively participate in modifying the state of the (shared) world. In order to address this gap, we introduce $τ^2$-bench, with four key contributions:\n  1) A novel Telecom dual-control domain modeled as a Dec-POMDP, where both agent and user make use of tools to act in a shared, dynamic environment that tests both agent coordination and communication,\n  2) A compositional task generator that programmatically creates diverse, verifiable tasks from atomic components, ensuring domain coverage and controlled complexity,\n  3) A reliable user simulator tightly coupled with the environment, whose behavior is constrained by tools and observable states, improving simulation fidelity,\n  4) Fine-grained analysis of agent performance through multiple ablations including separating errors arising from reasoning vs communication/coordination.\n  In particular, our experiments show significant performance drops when agents shift from no-user to dual-control, highlighting the challenges of guiding users. Overall, $τ^2$-bench provides a controlled testbed for agents that must both reason effectively and guide user actions.",
    "categories": [
      "cs.AI",
      "cs.CL"
    ],
    "primary_category": "cs.AI",
    "comment": "",
    "pdf_url": "https://arxiv.org/pdf/2506.07982v1",
    "published_date": "2025-06-09 17:52:18 UTC",
    "updated_date": "2025-06-09 17:52:18 UTC"
  },
  {
    "arxiv_id": "2506.07976v2",
    "title": "Thinking vs. Doing: Agents that Reason by Scaling Test-Time Interaction",
    "authors": [
      "Junhong Shen",
      "Hao Bai",
      "Lunjun Zhang",
      "Yifei Zhou",
      "Amrith Setlur",
      "Shengbang Tong",
      "Diego Caples",
      "Nan Jiang",
      "Tong Zhang",
      "Ameet Talwalkar",
      "Aviral Kumar"
    ],
    "abstract": "The current paradigm of test-time scaling relies on generating long reasoning traces (\"thinking\" more) before producing a response. In agent problems that require interaction, this can be done by generating thinking traces before acting in the world. However, this process does not allow agents to acquire new information from the environment or adapt their behavior over time. In this work, we propose to scale test-time interaction, an untapped dimension of test-time scaling that increases the agent's interaction horizon to enable running rich behaviors such as exploration, backtracking, and dynamic re-planning within a single rollout. To demonstrate the promise of this scaling dimension, we study the domain of web agents. We first show that even prompting-based interaction scaling without any training can improve task success on web benchmarks non-trivially. Building on this, we introduce TTI (Test-Time Interaction), a curriculum-based online reinforcement learning (RL) approach that trains agents by adaptively adjusting their rollout lengths. Using a Gemma 3 12B model, TTI produces state-of-the-art open-source, open-data web agents on WebVoyager and WebArena benchmarks. We further show that TTI enables agents to balance exploration and exploitation adaptively. Our results establish interaction scaling as a powerful, complementary axis to scaling per-step compute, offering new avenues for training adaptive agents.",
    "categories": [
      "cs.LG",
      "cs.AI"
    ],
    "primary_category": "cs.LG",
    "comment": "Fixed typo in Figure 6 and Conclusion",
    "pdf_url": "https://arxiv.org/pdf/2506.07976v2",
    "published_date": "2025-06-09 17:50:02 UTC",
    "updated_date": "2025-06-10 12:50:18 UTC"
  },
  {
    "arxiv_id": "2506.07972v1",
    "title": "HeuriGym: An Agentic Benchmark for LLM-Crafted Heuristics in Combinatorial Optimization",
    "authors": [
      "Hongzheng Chen",
      "Yingheng Wang",
      "Yaohui Cai",
      "Hins Hu",
      "Jiajie Li",
      "Shirley Huang",
      "Chenhui Deng",
      "Rongjian Liang",
      "Shufeng Kong",
      "Haoxing Ren",
      "Samitha Samaranayake",
      "Carla P. Gomes",
      "Zhiru Zhang"
    ],
    "abstract": "While Large Language Models (LLMs) have demonstrated significant advancements in reasoning and agent-based problem-solving, current evaluation methodologies fail to adequately assess their capabilities: existing benchmarks either rely on closed-ended questions prone to saturation and memorization, or subjective comparisons that lack consistency and rigor. In this work, we introduce HeuriGym, an agentic framework designed for evaluating heuristic algorithms generated by LLMs for combinatorial optimization problems, characterized by clearly defined objectives and expansive solution spaces. HeuriGym empowers LLMs to propose heuristics, receive evaluative feedback via code execution, and iteratively refine their solutions. We evaluate nine state-of-the-art models on nine problems across domains such as computer systems, logistics, and biology, exposing persistent limitations in tool use, planning, and adaptive reasoning. To quantify performance, we propose the Quality-Yield Index (QYI), a metric that captures both solution pass rate and quality. Even top models like GPT-o4-mini-high and Gemini-2.5-Pro attain QYI scores of only 0.6, well below the expert baseline of 1. Our open-source benchmark aims to guide the development of LLMs toward more effective and realistic problem-solving in scientific and engineering domains.",
    "categories": [
      "cs.LG",
      "cs.AI",
      "cs.CL"
    ],
    "primary_category": "cs.LG",
    "comment": "",
    "pdf_url": "https://arxiv.org/pdf/2506.07972v1",
    "published_date": "2025-06-09 17:46:47 UTC",
    "updated_date": "2025-06-09 17:46:47 UTC"
  },
  {
    "arxiv_id": "2506.07964v1",
    "title": "SlideCoder: Layout-aware RAG-enhanced Hierarchical Slide Generation from Design",
    "authors": [
      "Wenxin Tang",
      "Jingyu Xiao",
      "Wenxuan Jiang",
      "Xi Xiao",
      "Yuhang Wang",
      "Xuxin Tang",
      "Qing Li",
      "Yuehe Ma",
      "Junliang Liu",
      "Shisong Tang",
      "Michael R. Lyu"
    ],
    "abstract": "Manual slide creation is labor-intensive and requires expert prior knowledge. Existing natural language-based LLM generation methods struggle to capture the visual and structural nuances of slide designs. To address this, we formalize the Reference Image to Slide Generation task and propose Slide2Code, the first benchmark with difficulty-tiered samples based on a novel Slide Complexity Metric. We introduce SlideCoder, a layout-aware, retrieval-augmented framework for generating editable slides from reference images. SlideCoder integrates a Color Gradient-based Segmentation algorithm and a Hierarchical Retrieval-Augmented Generation method to decompose complex tasks and enhance code generation. We also release SlideMaster, a 7B open-source model fine-tuned with improved reverse-engineered data. Experiments show that SlideCoder outperforms state-of-the-art baselines by up to 40.5 points, demonstrating strong performance across layout fidelity, execution accuracy, and visual consistency. Our code is available at https://github.com/vinsontang1/SlideCoder.",
    "categories": [
      "cs.CV",
      "cs.AI"
    ],
    "primary_category": "cs.CV",
    "comment": "",
    "pdf_url": "https://arxiv.org/pdf/2506.07964v1",
    "published_date": "2025-06-09 17:39:48 UTC",
    "updated_date": "2025-06-09 17:39:48 UTC"
  },
  {
    "arxiv_id": "2506.07963v3",
    "title": "SUDER: Self-Improving Unified Large Multimodal Models for Understanding and Generation with Dual Self-Rewards",
    "authors": [
      "Jixiang Hong",
      "Yiran Zhang",
      "Guanzhong Wang",
      "Yi Liu",
      "Ji-Rong Wen",
      "Rui Yan"
    ],
    "abstract": "Building upon large language models (LLMs), recent large multimodal models (LMMs) unify cross-model understanding and generation into a single framework. However, LMMs still struggle to achieve accurate vision-language alignment, prone to generating text responses contradicting the visual input or failing to follow the text-to-image prompts. Current solutions require external supervision (e.g., human feedback or reward models) and only address unidirectional tasks-either understanding or generation. In this work, based on the observation that understanding and generation are naturally inverse dual tasks, we propose \\textbf{SUDER} (\\textbf{S}elf-improving \\textbf{U}nified LMMs with \\textbf{D}ual s\\textbf{E}lf-\\textbf{R}ewards), a framework reinforcing the understanding and generation capabilities of LMMs with a self-supervised dual reward mechanism. SUDER leverages the inherent duality between understanding and generation tasks to provide self-supervised optimization signals for each other. Specifically, we sample multiple outputs for a given input in one task domain, then reverse the input-output pairs to compute the dual likelihood within the model as self-rewards for optimization. Extensive experimental results on visual understanding and generation benchmarks demonstrate that our method can effectively enhance the performance of the model without any external supervision, especially achieving remarkable improvements in text-to-image tasks.",
    "categories": [
      "cs.AI",
      "cs.CL",
      "cs.CV"
    ],
    "primary_category": "cs.AI",
    "comment": "",
    "pdf_url": "https://arxiv.org/pdf/2506.07963v3",
    "published_date": "2025-06-09 17:38:45 UTC",
    "updated_date": "2025-09-08 14:31:08 UTC"
  },
  {
    "arxiv_id": "2506.07962v1",
    "title": "Correlated Errors in Large Language Models",
    "authors": [
      "Elliot Kim",
      "Avi Garg",
      "Kenny Peng",
      "Nikhil Garg"
    ],
    "abstract": "Diversity in training data, architecture, and providers is assumed to mitigate homogeneity in LLMs. However, we lack empirical evidence on whether different LLMs differ meaningfully. We conduct a large-scale empirical evaluation on over 350 LLMs overall, using two popular leaderboards and a resume-screening task. We find substantial correlation in model errors -- on one leaderboard dataset, models agree 60% of the time when both models err. We identify factors driving model correlation, including shared architectures and providers. Crucially, however, larger and more accurate models have highly correlated errors, even with distinct architectures and providers. Finally, we show the effects of correlation in two downstream tasks: LLM-as-judge evaluation and hiring -- the latter reflecting theoretical predictions regarding algorithmic monoculture.",
    "categories": [
      "cs.CL",
      "cs.AI",
      "cs.CY",
      "stat.ML"
    ],
    "primary_category": "cs.CL",
    "comment": "Accepted to ICML 2025",
    "pdf_url": "https://arxiv.org/pdf/2506.07962v1",
    "published_date": "2025-06-09 17:37:18 UTC",
    "updated_date": "2025-06-09 17:37:18 UTC"
  },
  {
    "arxiv_id": "2506.07961v2",
    "title": "BridgeVLA: Input-Output Alignment for Efficient 3D Manipulation Learning with Vision-Language Models",
    "authors": [
      "Peiyan Li",
      "Yixiang Chen",
      "Hongtao Wu",
      "Xiao Ma",
      "Xiangnan Wu",
      "Yan Huang",
      "Liang Wang",
      "Tao Kong",
      "Tieniu Tan"
    ],
    "abstract": "Recently, leveraging pre-trained vision-language models (VLMs) for building vision-language-action (VLA) models has emerged as a promising approach to effective robot manipulation learning. However, only few methods incorporate 3D signals into VLMs for action prediction, and they do not fully leverage the spatial structure inherent in 3D data, leading to low sample efficiency. In this paper, we introduce BridgeVLA, a novel 3D VLA model that (1) projects 3D inputs to multiple 2D images, ensuring input alignment with the VLM backbone, and (2) utilizes 2D heatmaps for action prediction, unifying the input and output spaces within a consistent 2D image space. In addition, we propose a scalable pre-training method that equips the VLM backbone with the capability to predict 2D heatmaps before downstream policy learning. Extensive experiments show the proposed method is able to learn 3D manipulation efficiently and effectively. BridgeVLA outperforms state-of-the-art baseline methods across three simulation benchmarks. In RLBench, it improves the average success rate from 81.4% to 88.2%. In COLOSSEUM, it demonstrates significantly better performance in challenging generalization settings, boosting the average success rate from 56.7% to 64.0%. In GemBench, it surpasses all the comparing baseline methods in terms of average success rate. In real-robot experiments, BridgeVLA outperforms a state-of-the-art baseline method by 32% on average. It generalizes robustly in multiple out-of-distribution settings, including visual disturbances and unseen instructions. Remarkably, it is able to achieve a success rate of 96.8% on 10+ tasks with only 3 trajectories per task, highlighting its extraordinary sample efficiency. Project Website:https://bridgevla.github.io/",
    "categories": [
      "cs.RO",
      "cs.AI"
    ],
    "primary_category": "cs.RO",
    "comment": "NeurIPS 2025",
    "pdf_url": "https://arxiv.org/pdf/2506.07961v2",
    "published_date": "2025-06-09 17:36:34 UTC",
    "updated_date": "2025-10-14 12:26:03 UTC"
  },
  {
    "arxiv_id": "2506.07945v2",
    "title": "ProtocolLLM: RTL Benchmark for SystemVerilog Generation of Communication Protocols",
    "authors": [
      "Arnav Sheth",
      "Ivaxi Sheth",
      "Mario Fritz"
    ],
    "abstract": "Recent advances in large language models (LLMs) have demonstrated strong performance in generating code for general-purpose programming languages. However, their potential for hardware description languages (HDLs), such as SystemVerilog, remains largely unexplored. HDL code generation poses unique challenges due to strict timing semantics, concurrency, and synthesizability constraints essential for correct hardware functionality. Further, HDL-based design flows encompass a broad set of tasks beyond structural code generation, including testbench development, assertion-based verification, timing closure, and protocol-level integration for on-chip communication. In this work, we evaluate the capabilities of both open-source and state-of-the-art LLMs in generating synthesizable and functionally accurate SystemVerilog implementations of widely used communication protocols that are critical components of embedded and System-on-Chip (SoC) systems. We introduce ProtocolLLM, the first benchmark suite specifically targeting these protocols with tasks spanning multiple design abstraction levels and varying prompt specificity. Our evaluation method also focuses on timing correctness in addition to synthesizability and syntactic correctness. We observe that most of the models fail to generate SystemVerilog code for communication protocols that follow timing constrains.",
    "categories": [
      "cs.AR",
      "cs.AI",
      "cs.CL"
    ],
    "primary_category": "cs.AR",
    "comment": "Accepted at MLSysArch@ISCA 2025",
    "pdf_url": "https://arxiv.org/pdf/2506.07945v2",
    "published_date": "2025-06-09 17:10:47 UTC",
    "updated_date": "2025-07-15 16:24:28 UTC"
  },
  {
    "arxiv_id": "2506.07943v2",
    "title": "Decoupling the Image Perception and Multimodal Reasoning for Reasoning Segmentation with Digital Twin Representations",
    "authors": [
      "Yizhen Li",
      "Dell Zhang",
      "Xuelong Li",
      "Yiqing Shen"
    ],
    "abstract": "Reasoning Segmentation (RS) is a multimodal vision-text task that requires segmenting objects based on implicit text queries, demanding both precise visual perception and vision-text reasoning capabilities. Current RS approaches rely on fine-tuning vision-language models (VLMs) for both perception and reasoning, but their tokenization of images fundamentally disrupts continuous spatial relationships between objects. We introduce DTwinSeger, a novel RS approach that leverages Digital Twin (DT) representation as an intermediate layer to decouple perception from reasoning. Innovatively, DTwinSeger reformulates RS as a two-stage process, where the first transforms the image into a structured DT representation that preserves spatial relationships and semantic properties and then employs a Large Language Model (LLM) to perform explicit reasoning over this representation to identify target objects. We propose a supervised fine-tuning method specifically for LLM with DT representation, together with a corresponding fine-tuning dataset Seg-DT, to enhance the LLM's reasoning capabilities with DT representations. Experiments show that our method can achieve state-of-the-art performance on two image RS benchmarks and three image referring segmentation benchmarks. It yields that DT representation functions as an effective bridge between vision and text, enabling complex multimodal reasoning tasks to be accomplished solely with an LLM.",
    "categories": [
      "cs.CV",
      "cs.AI"
    ],
    "primary_category": "cs.CV",
    "comment": "This work was submitted without the consent of all co-authors. We request withdrawal until all parties agree",
    "pdf_url": "https://arxiv.org/pdf/2506.07943v2",
    "published_date": "2025-06-09 17:05:02 UTC",
    "updated_date": "2025-06-11 13:48:23 UTC"
  },
  {
    "arxiv_id": "2506.08070v2",
    "title": "Info-Coevolution: An Efficient Framework for Data Model Coevolution",
    "authors": [
      "Ziheng Qin",
      "Hailun Xu",
      "Wei Chee Yew",
      "Qi Jia",
      "Yang Luo",
      "Kanchan Sarkar",
      "Danhui Guan",
      "Kai Wang",
      "Yang You"
    ],
    "abstract": "Machine learning relies heavily on data, yet the continuous growth of real-world data poses challenges for efficient dataset construction and training. A fundamental yet unsolved question is: given our current model and data, does a new data (sample/batch) need annotation/learning? Conventional approaches retain all available data, leading to non-optimal data and training efficiency. Active learning aims to reduce data redundancy by selecting a subset of samples to annotate, while it increases pipeline complexity and introduces bias. In this work, we propose Info-Coevolution, a novel framework that efficiently enables models and data to coevolve through online selective annotation with no bias. Leveraging task-specific models (and open-source models), it selectively annotates and integrates online and web data to improve datasets efficiently. For real-world datasets like ImageNet-1K, Info-Coevolution reduces annotation and training costs by 32\\% without performance loss. It is able to automatically give the saving ratio without tuning the ratio. It can further reduce the annotation ratio to 50\\% with semi-supervised learning. We also explore retrieval-based dataset enhancement using unlabeled open-source data. Code is available at https://github.com/NUS-HPC-AI-Lab/Info-Coevolution/.",
    "categories": [
      "cs.LG",
      "cs.AI"
    ],
    "primary_category": "cs.LG",
    "comment": "V1",
    "pdf_url": "https://arxiv.org/pdf/2506.08070v2",
    "published_date": "2025-06-09 17:04:11 UTC",
    "updated_date": "2025-06-20 02:52:55 UTC"
  },
  {
    "arxiv_id": "2506.07940v2",
    "title": "Gradients: When Markets Meet Fine-tuning -- A Distributed Approach to Model Optimisation",
    "authors": [
      "Christopher Subia-Waud"
    ],
    "abstract": "Current AutoML platforms leave substantial performance untapped. Testing 180 fine-tuning tasks across models from 70M to 70B parameters, we found that HuggingFace AutoTrain, TogetherAI, Databricks, and Google Cloud consistently produce suboptimal configurations. Gradients, built on the Bittensor network, attacks this problem through competition. Independent miners race to find optimal hyperparameters, earning rewards proportional to their models' performance. This tournament drives exploration of configuration spaces that single-strategy methods never examine. In our experiments, Gradients achieved a 100\\% win rate against TogetherAI, Databricks, and Google Cloud, and beat HuggingFace AutoTrain in 82.8\\% of experiments. Mean improvements reached 42.1\\% against commercial platforms. Retrieval-augmented generation tasks saw 30-40\\% gains; diffusion models improved 23.4\\% on person-specific generation. When miners compete for rewards, they develop optimization strategies that centralized approaches overlook. These findings demonstrate that decentralized systems with economic incentives can systematically outperform traditional AutoML, suggesting market dynamics may be key to achieving superior fine-tuning results. Code is available at https://github.com/rayonlabs/G.O.D.",
    "categories": [
      "cs.AI",
      "cs.LG"
    ],
    "primary_category": "cs.AI",
    "comment": "",
    "pdf_url": "https://arxiv.org/pdf/2506.07940v2",
    "published_date": "2025-06-09 17:00:38 UTC",
    "updated_date": "2025-09-03 09:39:22 UTC"
  },
  {
    "arxiv_id": "2506.07936v1",
    "title": "Mimicking or Reasoning: Rethinking Multi-Modal In-Context Learning in Vision-Language Models",
    "authors": [
      "Chengyue Huang",
      "Yuchen Zhu",
      "Sichen Zhu",
      "Jingyun Xiao",
      "Moises Andrade",
      "Shivang Chopra",
      "Zsolt Kira"
    ],
    "abstract": "Vision-language models (VLMs) are widely assumed to exhibit in-context learning (ICL), a property similar to that of their language-only counterparts. While recent work suggests VLMs can perform multimodal ICL (MM-ICL), studies show they often rely on shallow heuristics -- such as copying or majority voting -- rather than true task understanding. We revisit this assumption by evaluating VLMs under distribution shifts, where support examples come from a dataset different from the query. Surprisingly, performance often degrades with more demonstrations, and models tend to copy answers rather than learn from them. To investigate further, we propose a new MM-ICL with Reasoning pipeline that augments each demonstration with a generated rationale alongside the answer. We conduct extensive and comprehensive experiments on both perception- and reasoning-required datasets with open-source VLMs ranging from 3B to 72B and proprietary models such as Gemini 2.0. We conduct controlled studies varying shot count, retrieval method, rationale quality, and distribution. Our results show limited performance sensitivity across these factors, suggesting that current VLMs do not effectively utilize demonstration-level information as intended in MM-ICL.",
    "categories": [
      "cs.CV",
      "cs.AI",
      "cs.CL",
      "cs.LG"
    ],
    "primary_category": "cs.CV",
    "comment": "",
    "pdf_url": "https://arxiv.org/pdf/2506.07936v1",
    "published_date": "2025-06-09 16:55:32 UTC",
    "updated_date": "2025-06-09 16:55:32 UTC"
  },
  {
    "arxiv_id": "2506.07935v1",
    "title": "Diffusion of Responsibility in Collective Decision Making",
    "authors": [
      "Pavel Naumov",
      "Jia Tao"
    ],
    "abstract": "The term \"diffusion of responsibility'' refers to situations in which multiple agents share responsibility for an outcome, obscuring individual accountability. This paper examines this frequently undesirable phenomenon in the context of collective decision-making mechanisms.\n  The work shows that if a decision is made by two agents, then the only way to avoid diffusion of responsibility is for one agent to act as a \"dictator'', making the decision unilaterally. In scenarios with more than two agents, any diffusion-free mechanism is an \"elected dictatorship'' where the agents elect a single agent to make a unilateral decision.\n  The technical results are obtained by defining a bisimulation of decision-making mechanisms, proving that bisimulation preserves responsibility-related properties, and establishing the results for a smallest bisimular mechanism.",
    "categories": [
      "cs.MA",
      "cs.AI",
      "cs.GT"
    ],
    "primary_category": "cs.MA",
    "comment": "",
    "pdf_url": "https://arxiv.org/pdf/2506.07935v1",
    "published_date": "2025-06-09 16:54:56 UTC",
    "updated_date": "2025-06-09 16:54:56 UTC"
  },
  {
    "arxiv_id": "2506.07927v3",
    "title": "Solving Inequality Proofs with Large Language Models",
    "authors": [
      "Pan Lu",
      "Jiayi Sheng",
      "Luna Lyu",
      "Jikai Jin",
      "Tony Xia",
      "Alex Gu",
      "James Zou"
    ],
    "abstract": "Inequality proving, crucial across diverse scientific and mathematical fields, tests advanced reasoning skills such as discovering tight bounds and strategic theorem application. This makes it a distinct, demanding frontier for large language models (LLMs), offering insights beyond general mathematical problem-solving. Progress in this area is hampered by existing datasets that are often scarce, synthetic, or rigidly formal. We address this by proposing an informal yet verifiable task formulation, recasting inequality proving into two automatically checkable subtasks: bound estimation and relation prediction. Building on this, we release IneqMath, an expert-curated dataset of Olympiad-level inequalities, including a test set and training corpus enriched with step-wise solutions and theorem annotations. We also develop a novel LLM-as-judge evaluation framework, combining a final-answer judge with four step-wise judges designed to detect common reasoning flaws. A systematic evaluation of 29 leading LLMs on IneqMath reveals a surprising reality: even top models like o1 achieve less than 10% overall accuracy under step-wise scrutiny; this is a drop of up to 65.5% from their accuracy considering only final answer equivalence. This discrepancy exposes fragile deductive chains and a critical gap for current LLMs between merely finding an answer and constructing a rigorous proof. Scaling model size and increasing test-time computation yield limited gains in overall proof correctness. Instead, our findings highlight promising research directions such as theorem-guided reasoning and self-refinement. Code and data are available at https://ineqmath.github.io/.",
    "categories": [
      "cs.AI",
      "cs.CL",
      "cs.LG"
    ],
    "primary_category": "cs.AI",
    "comment": "50 pages, 24 figures, accepted as a Spotlight at NeurIPS 2025",
    "pdf_url": "https://arxiv.org/pdf/2506.07927v3",
    "published_date": "2025-06-09 16:43:38 UTC",
    "updated_date": "2025-12-15 01:49:41 UTC"
  },
  {
    "arxiv_id": "2506.07919v2",
    "title": "Uncovering the Computational Roles of Nonlinearity in Sequence Modeling Using Almost-Linear RNNs",
    "authors": [
      "Manuel Brenner",
      "Georgia Koppe"
    ],
    "abstract": "Sequence modeling tasks across domains such as natural language processing, time series forecasting, and control require learning complex input-output mappings. Nonlinear recurrence is theoretically required for universal approximation of sequence-to-sequence functions, yet linear recurrent models often prove surprisingly effective. This raises the question of when nonlinearity is truly required. We present a framework to systematically dissect the functional role of nonlinearity in recurrent networks, identifying when it is computationally necessary and what mechanisms it enables. We address this using Almost Linear Recurrent Neural Networks (AL-RNNs), which allow recurrence nonlinearity to be gradually attenuated and decompose network dynamics into analyzable linear regimes, making computational mechanisms explicit. We illustrate the framework across diverse synthetic and real-world tasks, including classic sequence modeling benchmarks, a neuroscientific stimulus-selection task, and a multi-task suite. We demonstrate how the AL-RNN's piecewise linear structure enables identification of computational primitives such as gating, rule-based integration, and memory-dependent transients, revealing that these operations emerge within predominantly linear backbones. Across tasks, sparse nonlinearity improves interpretability by reducing and localizing nonlinear computations, promotes shared representations in multi-task settings, and reduces computational cost. Moreover, sparse nonlinearity acts as a useful inductive bias: in low-data regimes or when tasks require discrete switching between linear regimes, sparsely nonlinear models often match or exceed fully nonlinear architectures. Our findings provide a principled approach for identifying where nonlinearity is functionally necessary, guiding the design of recurrent architectures that balance performance, efficiency, and interpretability.",
    "categories": [
      "cs.LG",
      "cs.AI",
      "cs.CL",
      "nlin.CD",
      "physics.comp-ph"
    ],
    "primary_category": "cs.LG",
    "comment": "Published in Transactions on Machine Learning Research (TMLR), https://openreview.net/forum?id=qI2Vt9P9rl",
    "pdf_url": "https://arxiv.org/pdf/2506.07919v2",
    "published_date": "2025-06-09 16:32:19 UTC",
    "updated_date": "2026-01-12 15:09:14 UTC"
  },
  {
    "arxiv_id": "2506.07915v1",
    "title": "LUCIFER: Language Understanding and Context-Infused Framework for Exploration and Behavior Refinement",
    "authors": [
      "Dimitris Panagopoulos",
      "Adolfo Perrusquia",
      "Weisi Guo"
    ],
    "abstract": "In dynamic environments, the rapid obsolescence of pre-existing environmental knowledge creates a gap between an agent's internal model and the evolving reality of its operational context. This disparity between prior and updated environmental valuations fundamentally limits the effectiveness of autonomous decision-making. To bridge this gap, the contextual bias of human domain stakeholders, who naturally accumulate insights through direct, real-time observation, becomes indispensable. However, translating their nuanced, and context-rich input into actionable intelligence for autonomous systems remains an open challenge. To address this, we propose LUCIFER (Language Understanding and Context-Infused Framework for Exploration and Behavior Refinement), a domain-agnostic framework that integrates a hierarchical decision-making architecture with reinforcement learning (RL) and large language models (LLMs) into a unified system. This architecture mirrors how humans decompose complex tasks, enabling a high-level planner to coordinate specialised sub-agents, each focused on distinct objectives and temporally interdependent actions. Unlike traditional applications where LLMs are limited to single role, LUCIFER integrates them in two synergistic roles: as context extractors, structuring verbal stakeholder input into domain-aware representations that influence decision-making through an attention space mechanism aligning LLM-derived insights with the agent's learning process, and as zero-shot exploration facilitators guiding the agent's action selection process during exploration. We benchmark various LLMs in both roles and demonstrate that LUCIFER improves exploration efficiency and decision quality, outperforming flat, goal-conditioned policies. Our findings show the potential of context-driven decision-making, where autonomous systems leverage human contextual knowledge for operational success.",
    "categories": [
      "cs.AI",
      "cs.CL",
      "eess.SY"
    ],
    "primary_category": "cs.AI",
    "comment": "12 pages, 4 Figures, 3 Tables, submitted to the IEEE for possible publication",
    "pdf_url": "https://arxiv.org/pdf/2506.07915v1",
    "published_date": "2025-06-09 16:30:05 UTC",
    "updated_date": "2025-06-09 16:30:05 UTC"
  },
  {
    "arxiv_id": "2506.07903v2",
    "title": "Diffuse Everything: Multimodal Diffusion Models on Arbitrary State Spaces",
    "authors": [
      "Kevin Rojas",
      "Yuchen Zhu",
      "Sichen Zhu",
      "Felix X. -F. Ye",
      "Molei Tao"
    ],
    "abstract": "Diffusion models have demonstrated remarkable performance in generating unimodal data across various tasks, including image, video, and text generation. On the contrary, the joint generation of multimodal data through diffusion models is still in the early stages of exploration. Existing approaches heavily rely on external preprocessing protocols, such as tokenizers and variational autoencoders, to harmonize varied data representations into a unified, unimodal format. This process heavily demands the high accuracy of encoders and decoders, which can be problematic for applications with limited data. To lift this restriction, we propose a novel framework for building multimodal diffusion models on arbitrary state spaces, enabling native generation of coupled data across different modalities. By introducing an innovative decoupled noise schedule for each modality, we enable both unconditional and modality-conditioned generation within a single model simultaneously. We empirically validate our approach for text-image generation and mixed-type tabular data synthesis, demonstrating that it achieves competitive performance.",
    "categories": [
      "cs.LG",
      "cs.AI",
      "cs.CV"
    ],
    "primary_category": "cs.LG",
    "comment": "Accepted to ICML 2025. Code available at https://github.com/KevinRojas1499/Diffuse-Everything",
    "pdf_url": "https://arxiv.org/pdf/2506.07903v2",
    "published_date": "2025-06-09 16:20:20 UTC",
    "updated_date": "2025-06-12 23:40:11 UTC"
  },
  {
    "arxiv_id": "2506.07900v2",
    "title": "MiniCPM4: Ultra-Efficient LLMs on End Devices",
    "authors": [
      "MiniCPM Team",
      "Chaojun Xiao",
      "Yuxuan Li",
      "Xu Han",
      "Yuzhuo Bai",
      "Jie Cai",
      "Haotian Chen",
      "Wentong Chen",
      "Xin Cong",
      "Ganqu Cui",
      "Ning Ding",
      "Shengda Fan",
      "Yewei Fang",
      "Zixuan Fu",
      "Wenyu Guan",
      "Yitong Guan",
      "Junshao Guo",
      "Yufeng Han",
      "Bingxiang He",
      "Yuxiang Huang",
      "Baoxi Ji",
      "Cunliang Kong",
      "Qiuzuo Li",
      "Siyuan Li",
      "Wenhao Li",
      "Xin Li",
      "Yanghao Li",
      "Yishan Li",
      "Zhen Li",
      "Dan Liu",
      "Biyuan Lin",
      "Yankai Lin",
      "Xiang Long",
      "Quanyu Lu",
      "Yaxi Lu",
      "Peiyan Luo",
      "Hongya Lyu",
      "Litu Ou",
      "Yinxu Pan",
      "Lushi Pu",
      "Zekai Qu",
      "Qundong Shi",
      "Zijun Song",
      "Jiayuan Su",
      "Zhou Su",
      "Ao Sun",
      "Xianghui Sun",
      "Peijun Tang",
      "Fangzheng Wang",
      "Feng Wang",
      "Shuo Wang",
      "Yudong Wang",
      "Zheng Wang",
      "Yesai Wu",
      "Zhenyu Xiao",
      "Jie Xie",
      "Zihao Xie",
      "Xiaoyue Xu",
      "Yukun Yan",
      "Jiarui Yuan",
      "Jinqian Zhang",
      "Kaihuo Zhang",
      "Lei Zhang",
      "Linyue Zhang",
      "Xueren Zhang",
      "Yudi Zhang",
      "Hengyu Zhao",
      "Weilin Zhao",
      "Weilun Zhao",
      "Yuanqian Zhao",
      "Zhi Zheng",
      "Chuyue Zhou",
      "Ge Zhou",
      "Jie Zhou",
      "Wei Zhou",
      "Yanghao Zhou",
      "Zihan Zhou",
      "Zixuan Zhou",
      "Zhiyuan Liu",
      "Guoyang Zeng",
      "Chao Jia",
      "Dahai Li",
      "Maosong Sun"
    ],
    "abstract": "This paper introduces MiniCPM4, a highly efficient large language model (LLM) designed explicitly for end-side devices. We achieve this efficiency through systematic innovation in four key dimensions: model architecture, training data, training algorithms, and inference systems. Specifically, in terms of model architecture, we propose InfLLM v2, a trainable sparse attention mechanism that accelerates both prefilling and decoding phases for long-context processing. Regarding training data, we propose UltraClean, an efficient and accurate pre-training data filtering and generation strategy, and UltraChat v2, a comprehensive supervised fine-tuning dataset. These datasets enable satisfactory model performance to be achieved using just 8 trillion training tokens. Regarding training algorithms, we propose ModelTunnel v2 for efficient pre-training strategy search, and improve existing post-training methods by introducing chunk-wise rollout for load-balanced reinforcement learning and data-efficient tenary LLM, BitCPM. Regarding inference systems, we propose CPM.cu that integrates sparse attention, model quantization, and speculative sampling to achieve efficient prefilling and decoding. To meet diverse on-device requirements, MiniCPM4 is available in two versions, with 0.5B and 8B parameters, respectively. Furthermore, we construct a hybrid reasoning model, MiniCPM4.1, which can be used in both deep reasoning mode and non-reasoning mode. Evaluation results demonstrate that MiniCPM4 and MiniCPM4.1 outperform similar-sized open-source models across benchmarks, with the 8B variants showing significant speed improvements on long sequence understanding and generation.",
    "categories": [
      "cs.CL",
      "cs.AI"
    ],
    "primary_category": "cs.CL",
    "comment": "MiniCPM4 Technical Report",
    "pdf_url": "https://arxiv.org/pdf/2506.07900v2",
    "published_date": "2025-06-09 16:16:50 UTC",
    "updated_date": "2025-09-04 16:23:02 UTC"
  },
  {
    "arxiv_id": "2506.13778v1",
    "title": "Knowledge Compression via Question Generation: Enhancing Multihop Document Retrieval without Fine-tuning",
    "authors": [
      "Anvi Alex Eponon",
      "Moein Shahiki-Tash",
      "Ildar Batyrshin",
      "Christian E. Maldonado-Sifuentes",
      "Grigori Sidorov",
      "Alexander Gelbukh"
    ],
    "abstract": "This study presents a question-based knowledge encoding approach that improves retrieval-augmented generation (RAG) systems without requiring fine-tuning or traditional chunking. We encode textual content using generated questions that span the lexical and semantic space, creating targeted retrieval cues combined with a custom syntactic reranking method.\n  In single-hop retrieval over 109 scientific papers, our approach achieves a Recall@3 of 0.84, outperforming traditional chunking methods by 60 percent. We also introduce \"paper-cards\", concise paper summaries under 300 characters, which enhance BM25 retrieval, increasing MRR@3 from 0.56 to 0.85 on simplified technical queries.\n  For multihop tasks, our reranking method reaches an F1 score of 0.52 with LLaMA2-Chat-7B on the LongBench 2WikiMultihopQA dataset, surpassing chunking and fine-tuned baselines which score 0.328 and 0.412 respectively.\n  This method eliminates fine-tuning requirements, reduces retrieval latency, enables intuitive question-driven knowledge access, and decreases vector storage demands by 80%, positioning it as a scalable and efficient RAG alternative.",
    "categories": [
      "cs.IR",
      "cs.AI",
      "cs.CL"
    ],
    "primary_category": "cs.IR",
    "comment": "",
    "pdf_url": "https://arxiv.org/pdf/2506.13778v1",
    "published_date": "2025-06-09 16:15:11 UTC",
    "updated_date": "2025-06-09 16:15:11 UTC"
  },
  {
    "arxiv_id": "2506.07897v1",
    "title": "GaussianVAE: Adaptive Learning Dynamics of 3D Gaussians for High-Fidelity Super-Resolution",
    "authors": [
      "Shuja Khalid",
      "Mohamed Ibrahim",
      "Yang Liu"
    ],
    "abstract": "We present a novel approach for enhancing the resolution and geometric fidelity of 3D Gaussian Splatting (3DGS) beyond native training resolution. Current 3DGS methods are fundamentally limited by their input resolution, producing reconstructions that cannot extrapolate finer details than are present in the training views. Our work breaks this limitation through a lightweight generative model that predicts and refines additional 3D Gaussians where needed most. The key innovation is our Hessian-assisted sampling strategy, which intelligently identifies regions that are likely to benefit from densification, ensuring computational efficiency. Unlike computationally intensive GANs or diffusion approaches, our method operates in real-time (0.015s per inference on a single consumer-grade GPU), making it practical for interactive applications. Comprehensive experiments demonstrate significant improvements in both geometric accuracy and rendering quality compared to state-of-the-art methods, establishing a new paradigm for resolution-free 3D scene enhancement.",
    "categories": [
      "cs.GR",
      "cs.AI",
      "cs.CV",
      "cs.LG"
    ],
    "primary_category": "cs.GR",
    "comment": "",
    "pdf_url": "https://arxiv.org/pdf/2506.07897v1",
    "published_date": "2025-06-09 16:13:12 UTC",
    "updated_date": "2025-06-09 16:13:12 UTC"
  },
  {
    "arxiv_id": "2506.07896v1",
    "title": "Evaluating Large Language Models on the Frame and Symbol Grounding Problems: A Zero-shot Benchmark",
    "authors": [
      "Shoko Oka"
    ],
    "abstract": "Recent advancements in large language models (LLMs) have revitalized philosophical debates surrounding artificial intelligence. Two of the most fundamental challenges - namely, the Frame Problem and the Symbol Grounding Problem - have historically been viewed as unsolvable within traditional symbolic AI systems. This study investigates whether modern LLMs possess the cognitive capacities required to address these problems. To do so, I designed two benchmark tasks reflecting the philosophical core of each problem, administered them under zero-shot conditions to 13 prominent LLMs (both closed and open-source), and assessed the quality of the models' outputs across five trials each. Responses were scored along multiple criteria, including contextual reasoning, semantic coherence, and information filtering. The results demonstrate that while open-source models showed variability in performance due to differences in model size, quantization, and instruction tuning, several closed models consistently achieved high scores. These findings suggest that select modern LLMs may be acquiring capacities sufficient to produce meaningful and stable responses to these long-standing theoretical challenges.",
    "categories": [
      "cs.AI",
      "cs.CL"
    ],
    "primary_category": "cs.AI",
    "comment": "52 pages, Additional resources available on GitHub repository",
    "pdf_url": "https://arxiv.org/pdf/2506.07896v1",
    "published_date": "2025-06-09 16:12:47 UTC",
    "updated_date": "2025-06-09 16:12:47 UTC"
  },
  {
    "arxiv_id": "2506.17262v1",
    "title": "AI to Identify Strain-sensitive Regions of the Optic Nerve Head Linked to Functional Loss in Glaucoma",
    "authors": [
      "Thanadet Chuangsuwanich",
      "Monisha E. Nongpiur",
      "Fabian A. Braeu",
      "Tin A. Tun",
      "Alexandre Thiery",
      "Shamira Perera",
      "Ching Lin Ho",
      "Martin Buist",
      "George Barbastathis",
      "Tin Aung",
      "Michaël J. A. Girard"
    ],
    "abstract": "Objective: (1) To assess whether ONH biomechanics improves prediction of three progressive visual field loss patterns in glaucoma; (2) to use explainable AI to identify strain-sensitive ONH regions contributing to these predictions.\n  Methods: We recruited 237 glaucoma subjects. The ONH of one eye was imaged under two conditions: (1) primary gaze and (2) primary gaze with IOP elevated to ~35 mmHg via ophthalmo-dynamometry. Glaucoma experts classified the subjects into four categories based on the presence of specific visual field defects: (1) superior nasal step (N=26), (2) superior partial arcuate (N=62), (3) full superior hemifield defect (N=25), and (4) other/non-specific defects (N=124). Automatic ONH tissue segmentation and digital volume correlation were used to compute IOP-induced neural tissue and lamina cribrosa (LC) strains. Biomechanical and structural features were input to a Geometric Deep Learning model. Three classification tasks were performed to detect: (1) superior nasal step, (2) superior partial arcuate, (3) full superior hemifield defect. For each task, the data were split into 80% training and 20% testing sets. Area under the curve (AUC) was used to assess performance. Explainable AI techniques were employed to highlight the ONH regions most critical to each classification.\n  Results: Models achieved high AUCs of 0.77-0.88, showing that ONH strain improved VF loss prediction beyond morphology alone. The inferior and inferotemporal rim were identified as key strain-sensitive regions, contributing most to visual field loss prediction and showing progressive expansion with increasing disease severity.\n  Conclusion and Relevance: ONH strain enhances prediction of glaucomatous VF loss patterns. Neuroretinal rim, rather than the LC, was the most critical region contributing to model predictions.",
    "categories": [
      "cs.LG",
      "cs.AI"
    ],
    "primary_category": "cs.LG",
    "comment": "",
    "pdf_url": "https://arxiv.org/pdf/2506.17262v1",
    "published_date": "2025-06-09 16:00:01 UTC",
    "updated_date": "2025-06-09 16:00:01 UTC"
  },
  {
    "arxiv_id": "2506.07883v1",
    "title": "Diffusion Counterfactual Generation with Semantic Abduction",
    "authors": [
      "Rajat Rasal",
      "Avinash Kori",
      "Fabio De Sousa Ribeiro",
      "Tian Xia",
      "Ben Glocker"
    ],
    "abstract": "Counterfactual image generation presents significant challenges, including preserving identity, maintaining perceptual quality, and ensuring faithfulness to an underlying causal model. While existing auto-encoding frameworks admit semantic latent spaces which can be manipulated for causal control, they struggle with scalability and fidelity. Advancements in diffusion models present opportunities for improving counterfactual image editing, having demonstrated state-of-the-art visual quality, human-aligned perception and representation learning capabilities. Here, we present a suite of diffusion-based causal mechanisms, introducing the notions of spatial, semantic and dynamic abduction. We propose a general framework that integrates semantic representations into diffusion models through the lens of Pearlian causality to edit images via a counterfactual reasoning process. To our knowledge, this is the first work to consider high-level semantic identity preservation for diffusion counterfactuals and to demonstrate how semantic control enables principled trade-offs between faithful causal control and identity preservation.",
    "categories": [
      "cs.LG",
      "cs.AI",
      "cs.CV",
      "stat.ML"
    ],
    "primary_category": "cs.LG",
    "comment": "Proceedings of the 42nd International Conference on Machine Learning, Vancouver, Canada",
    "pdf_url": "https://arxiv.org/pdf/2506.07883v1",
    "published_date": "2025-06-09 15:54:00 UTC",
    "updated_date": "2025-06-09 15:54:00 UTC"
  },
  {
    "arxiv_id": "2506.07865v1",
    "title": "FreeGave: 3D Physics Learning from Dynamic Videos by Gaussian Velocity",
    "authors": [
      "Jinxi Li",
      "Ziyang Song",
      "Siyuan Zhou",
      "Bo Yang"
    ],
    "abstract": "In this paper, we aim to model 3D scene geometry, appearance, and the underlying physics purely from multi-view videos. By applying various governing PDEs as PINN losses or incorporating physics simulation into neural networks, existing works often fail to learn complex physical motions at boundaries or require object priors such as masks or types. In this paper, we propose FreeGave to learn the physics of complex dynamic 3D scenes without needing any object priors. The key to our approach is to introduce a physics code followed by a carefully designed divergence-free module for estimating a per-Gaussian velocity field, without relying on the inefficient PINN losses. Extensive experiments on three public datasets and a newly collected challenging real-world dataset demonstrate the superior performance of our method for future frame extrapolation and motion segmentation. Most notably, our investigation into the learned physics codes reveals that they truly learn meaningful 3D physical motion patterns in the absence of any human labels in training.",
    "categories": [
      "cs.CV",
      "cs.AI",
      "cs.CE",
      "cs.LG",
      "cs.RO"
    ],
    "primary_category": "cs.CV",
    "comment": "CVPR 2025. Code and data are available at: https://github.com/vLAR-group/FreeGave",
    "pdf_url": "https://arxiv.org/pdf/2506.07865v1",
    "published_date": "2025-06-09 15:31:25 UTC",
    "updated_date": "2025-06-09 15:31:25 UTC"
  },
  {
    "arxiv_id": "2506.07864v2",
    "title": "Lightweight Sequential Transformers for Blood Glucose Level Prediction in Type-1 Diabetes",
    "authors": [
      "Mirko Paolo Barbato",
      "Giorgia Rigamonti",
      "Davide Marelli",
      "Paolo Napoletano"
    ],
    "abstract": "Type 1 Diabetes (T1D) affects millions worldwide, requiring continuous monitoring to prevent severe hypo- and hyperglycemic events. While continuous glucose monitoring has improved blood glucose management, deploying predictive models on wearable devices remains challenging due to computational and memory constraints. To address this, we propose a novel Lightweight Sequential Transformer model designed for blood glucose prediction in T1D. By integrating the strengths of Transformers' attention mechanisms and the sequential processing of recurrent neural networks, our architecture captures long-term dependencies while maintaining computational efficiency. The model is optimized for deployment on resource-constrained edge devices and incorporates a balanced loss function to handle the inherent data imbalance in hypo- and hyperglycemic events. Experiments on two benchmark datasets, OhioT1DM and DiaTrend, demonstrate that the proposed model outperforms state-of-the-art methods in predicting glucose levels and detecting adverse events. This work fills the gap between high-performance modeling and practical deployment, providing a reliable and efficient T1D management solution.",
    "categories": [
      "cs.LG",
      "cs.AI"
    ],
    "primary_category": "cs.LG",
    "comment": "",
    "pdf_url": "https://arxiv.org/pdf/2506.07864v2",
    "published_date": "2025-06-09 15:27:43 UTC",
    "updated_date": "2025-06-14 15:43:35 UTC"
  },
  {
    "arxiv_id": "2506.07861v1",
    "title": "Fairness Overfitting in Machine Learning: An Information-Theoretic Perspective",
    "authors": [
      "Firas Laakom",
      "Haobo Chen",
      "Jürgen Schmidhuber",
      "Yuheng Bu"
    ],
    "abstract": "Despite substantial progress in promoting fairness in high-stake applications using machine learning models, existing methods often modify the training process, such as through regularizers or other interventions, but lack formal guarantees that fairness achieved during training will generalize to unseen data. Although overfitting with respect to prediction performance has been extensively studied, overfitting in terms of fairness loss has received far less attention. This paper proposes a theoretical framework for analyzing fairness generalization error through an information-theoretic lens. Our novel bounding technique is based on Efron-Stein inequality, which allows us to derive tight information-theoretic fairness generalization bounds with both Mutual Information (MI) and Conditional Mutual Information (CMI). Our empirical results validate the tightness and practical relevance of these bounds across diverse fairness-aware learning algorithms. Our framework offers valuable insights to guide the design of algorithms improving fairness generalization.",
    "categories": [
      "cs.LG",
      "cs.AI",
      "cs.IT"
    ],
    "primary_category": "cs.LG",
    "comment": "38 pages",
    "pdf_url": "https://arxiv.org/pdf/2506.07861v1",
    "published_date": "2025-06-09 15:24:56 UTC",
    "updated_date": "2025-06-09 15:24:56 UTC"
  },
  {
    "arxiv_id": "2506.07857v1",
    "title": "LogoSP: Local-global Grouping of Superpoints for Unsupervised Semantic Segmentation of 3D Point Clouds",
    "authors": [
      "Zihui Zhang",
      "Weisheng Dai",
      "Hongtao Wen",
      "Bo Yang"
    ],
    "abstract": "We study the problem of unsupervised 3D semantic segmentation on raw point clouds without needing human labels in training. Existing methods usually formulate this problem into learning per-point local features followed by a simple grouping strategy, lacking the ability to discover additional and possibly richer semantic priors beyond local features. In this paper, we introduce LogoSP to learn 3D semantics from both local and global point features. The key to our approach is to discover 3D semantic information by grouping superpoints according to their global patterns in the frequency domain, thus generating highly accurate semantic pseudo-labels for training a segmentation network. Extensive experiments on two indoor and an outdoor datasets show that our LogoSP surpasses all existing unsupervised methods by large margins, achieving the state-of-the-art performance for unsupervised 3D semantic segmentation. Notably, our investigation into the learned global patterns reveals that they truly represent meaningful 3D semantics in the absence of human labels during training.",
    "categories": [
      "cs.CV",
      "cs.AI",
      "cs.LG",
      "cs.RO"
    ],
    "primary_category": "cs.CV",
    "comment": "CVPR 2025. Code and data are available at: https://github.com/vLAR-group/LogoSP",
    "pdf_url": "https://arxiv.org/pdf/2506.07857v1",
    "published_date": "2025-06-09 15:21:37 UTC",
    "updated_date": "2025-06-09 15:21:37 UTC"
  },
  {
    "arxiv_id": "2506.07854v1",
    "title": "Residual Reweighted Conformal Prediction for Graph Neural Networks",
    "authors": [
      "Zheng Zhang",
      "Jie Bao",
      "Zhixin Zhou",
      "Nicolo Colombo",
      "Lixin Cheng",
      "Rui Luo"
    ],
    "abstract": "Graph Neural Networks (GNNs) excel at modeling relational data but face significant challenges in high-stakes domains due to unquantified uncertainty. Conformal prediction (CP) offers statistical coverage guarantees, but existing methods often produce overly conservative prediction intervals that fail to account for graph heteroscedasticity and structural biases. While residual reweighting CP variants address some of these limitations, they neglect graph topology, cluster-specific uncertainties, and risk data leakage by reusing training sets. To address these issues, we propose Residual Reweighted GNN (RR-GNN), a framework designed to generate minimal prediction sets with provable marginal coverage guarantees.\n  RR-GNN introduces three major innovations to enhance prediction performance. First, it employs Graph-Structured Mondrian CP to partition nodes or edges into communities based on topological features, ensuring cluster-conditional coverage that reflects heterogeneity. Second, it uses Residual-Adaptive Nonconformity Scores by training a secondary GNN on a held-out calibration set to estimate task-specific residuals, dynamically adjusting prediction intervals according to node or edge uncertainty. Third, it adopts a Cross-Training Protocol, which alternates the optimization of the primary GNN and the residual predictor to prevent information leakage while maintaining graph dependencies. We validate RR-GNN on 15 real-world graphs across diverse tasks, including node classification, regression, and edge weight prediction. Compared to CP baselines, RR-GNN achieves improved efficiency over state-of-the-art methods, with no loss of coverage.",
    "categories": [
      "cs.LG",
      "cs.AI",
      "stat.ML"
    ],
    "primary_category": "cs.LG",
    "comment": "",
    "pdf_url": "https://arxiv.org/pdf/2506.07854v1",
    "published_date": "2025-06-09 15:19:17 UTC",
    "updated_date": "2025-06-09 15:19:17 UTC"
  },
  {
    "arxiv_id": "2506.07853v4",
    "title": "Modeling the Diachronic Evolution of Legal Norms: An LRMoo-Based, Component-Level, Event-Centric Approach to Legal Knowledge Graphs",
    "authors": [
      "Hudson de Martim"
    ],
    "abstract": "Representing the temporal evolution of legal norms is a critical challenge for automated processing. While foundational frameworks exist, they lack a formal pattern for granular, component-level versioning, hindering the deterministic point-in-time reconstruction of legal texts required by reliable AI applications. This paper proposes a structured, temporal modeling pattern grounded in the LRMoo ontology. Our approach models a norm's evolution as a diachronic chain of versioned F1 Works, distinguishing between language-agnostic Temporal Versions (TV)-each being a distinct Work-and their monolingual Language Versions (LV), modeled as F2 Expressions. The legislative amendment process is formalized through event-centric modeling, allowing changes to be traced precisely. Using the Brazilian Constitution as a case study, we demonstrate that our architecture enables the exact reconstruction of any part of a legal text as it existed on a specific date. This provides a verifiable semantic backbone for legal knowledge graphs, offering a deterministic foundation for trustworthy legal AI.",
    "categories": [
      "cs.AI",
      "cs.IR"
    ],
    "primary_category": "cs.AI",
    "comment": "Model Refinement: Defining Temporal Versions as F1 Works",
    "pdf_url": "https://arxiv.org/pdf/2506.07853v4",
    "published_date": "2025-06-09 15:18:36 UTC",
    "updated_date": "2025-11-14 15:26:18 UTC"
  },
  {
    "arxiv_id": "2506.07848v1",
    "title": "PolyVivid: Vivid Multi-Subject Video Generation with Cross-Modal Interaction and Enhancement",
    "authors": [
      "Teng Hu",
      "Zhentao Yu",
      "Zhengguang Zhou",
      "Jiangning Zhang",
      "Yuan Zhou",
      "Qinglin Lu",
      "Ran Yi"
    ],
    "abstract": "Despite recent advances in video generation, existing models still lack fine-grained controllability, especially for multi-subject customization with consistent identity and interaction. In this paper, we propose PolyVivid, a multi-subject video customization framework that enables flexible and identity-consistent generation. To establish accurate correspondences between subject images and textual entities, we design a VLLM-based text-image fusion module that embeds visual identities into the textual space for precise grounding. To further enhance identity preservation and subject interaction, we propose a 3D-RoPE-based enhancement module that enables structured bidirectional fusion between text and image embeddings. Moreover, we develop an attention-inherited identity injection module to effectively inject fused identity features into the video generation process, mitigating identity drift. Finally, we construct an MLLM-based data pipeline that combines MLLM-based grounding, segmentation, and a clique-based subject consolidation strategy to produce high-quality multi-subject data, effectively enhancing subject distinction and reducing ambiguity in downstream video generation. Extensive experiments demonstrate that PolyVivid achieves superior performance in identity fidelity, video realism, and subject alignment, outperforming existing open-source and commercial baselines.",
    "categories": [
      "cs.CV",
      "cs.AI"
    ],
    "primary_category": "cs.CV",
    "comment": "",
    "pdf_url": "https://arxiv.org/pdf/2506.07848v1",
    "published_date": "2025-06-09 15:11:09 UTC",
    "updated_date": "2025-06-09 15:11:09 UTC"
  },
  {
    "arxiv_id": "2506.07841v1",
    "title": "Diffusion models under low-noise regime",
    "authors": [
      "Elizabeth Pavlova",
      "Xue-Xin Wei"
    ],
    "abstract": "Recent work on diffusion models proposed that they operate in two regimes: memorization, in which models reproduce their training data, and generalization, in which they generate novel samples. While this has been tested in high-noise settings, the behavior of diffusion models as effective denoisers when the corruption level is small remains unclear. To address this gap, we systematically investigated the behavior of diffusion models under low-noise diffusion dynamics, with implications for model robustness and interpretability. Using (i) CelebA subsets of varying sample sizes and (ii) analytic Gaussian mixture benchmarks, we reveal that models trained on disjoint data diverge near the data manifold even when their high-noise outputs converge. We quantify how training set size, data geometry, and model objective choice shape denoising trajectories and affect score accuracy, providing insights into how these models actually learn representations of data distributions. This work starts to address gaps in our understanding of generative model reliability in practical applications where small perturbations are common.",
    "categories": [
      "cs.CV",
      "cs.AI"
    ],
    "primary_category": "cs.CV",
    "comment": "",
    "pdf_url": "https://arxiv.org/pdf/2506.07841v1",
    "published_date": "2025-06-09 15:07:16 UTC",
    "updated_date": "2025-06-09 15:07:16 UTC"
  },
  {
    "arxiv_id": "2506.07837v1",
    "title": "HAIBU-ReMUD: Reasoning Multimodal Ultrasound Dataset and Model Bridging to General Specific Domains",
    "authors": [
      "Shijie Wang",
      "Yilun Zhang",
      "Zeyu Lai",
      "Dexing Kong"
    ],
    "abstract": "Multimodal large language models (MLLMs) have shown great potential in general domains but perform poorly in some specific domains due to a lack of domain-specific data, such as image-text data or vedio-text data. In some specific domains, there is abundant graphic and textual data scattered around, but lacks standardized arrangement. In the field of medical ultrasound, there are ultrasonic diagnostic books, ultrasonic clinical guidelines, ultrasonic diagnostic reports, and so on. However, these ultrasonic materials are often saved in the forms of PDF, images, etc., and cannot be directly used for the training of MLLMs. This paper proposes a novel image-text reasoning supervised fine-tuning data generation pipeline to create specific domain quadruplets (image, question, thinking trace, and answer) from domain-specific materials. A medical ultrasound domain dataset ReMUD is established, containing over 45,000 reasoning and non-reasoning supervised fine-tuning Question Answering (QA) and Visual Question Answering (VQA) data. The ReMUD-7B model, fine-tuned on Qwen2.5-VL-7B-Instruct, outperforms general-domain MLLMs in medical ultrasound field. To facilitate research, the ReMUD dataset, data generation codebase, and ReMUD-7B parameters will be released at https://github.com/ShiDaizi/ReMUD, addressing the data shortage issue in specific domain MLLMs.",
    "categories": [
      "cs.AI"
    ],
    "primary_category": "cs.AI",
    "comment": "",
    "pdf_url": "https://arxiv.org/pdf/2506.07837v1",
    "published_date": "2025-06-09 15:01:38 UTC",
    "updated_date": "2025-06-09 15:01:38 UTC"
  },
  {
    "arxiv_id": "2506.07836v1",
    "title": "Are Trees Really Green? A Detection Approach of IoT Malware Attacks",
    "authors": [
      "Silvia Lucia Sanna",
      "Diego Soi",
      "Davide Maiorca",
      "Giorgio Giacinto"
    ],
    "abstract": "Nowadays, the Internet of Things (IoT) is widely employed, and its usage is growing exponentially because it facilitates remote monitoring, predictive maintenance, and data-driven decision making, especially in the healthcare and industrial sectors. However, IoT devices remain vulnerable due to their resource constraints and difficulty in applying security patches. Consequently, various cybersecurity attacks are reported daily, such as Denial of Service, particularly in IoT-driven solutions. Most attack detection methodologies are based on Machine Learning (ML) techniques, which can detect attack patterns. However, the focus is more on identification rather than considering the impact of ML algorithms on computational resources. This paper proposes a green methodology to identify IoT malware networking attacks based on flow privacy-preserving statistical features. In particular, the hyperparameters of three tree-based models -- Decision Trees, Random Forest and Extra-Trees -- are optimized based on energy consumption and test-time performance in terms of Matthew's Correlation Coefficient. Our results show that models maintain high performance and detection accuracy while consistently reducing power usage in terms of watt-hours (Wh). This suggests that on-premise ML-based Intrusion Detection Systems are suitable for IoT and other resource-constrained devices.",
    "categories": [
      "cs.CR",
      "cs.AI",
      "cs.NI"
    ],
    "primary_category": "cs.CR",
    "comment": "",
    "pdf_url": "https://arxiv.org/pdf/2506.07836v1",
    "published_date": "2025-06-09 15:01:04 UTC",
    "updated_date": "2025-06-09 15:01:04 UTC"
  },
  {
    "arxiv_id": "2506.07833v2",
    "title": "Improving Large Language Models with Concept-Aware Fine-Tuning",
    "authors": [
      "Michael K. Chen",
      "Xikun Zhang",
      "Jiaxing Huang",
      "Dacheng Tao"
    ],
    "abstract": "Large language models (LLMs) have become the cornerstone of modern AI. However, the existing paradigm of next-token prediction fundamentally limits their ability to form coherent, high-level concepts, making it a critical barrier to human-like understanding and reasoning. Take the phrase \"ribonucleic acid\" as an example: an LLM will first decompose it into tokens, i.e., artificial text fragments (\"rib\", \"on\", ...), then learn each token sequentially, rather than grasping the phrase as a unified, coherent semantic entity. This fragmented representation hinders deeper conceptual understanding and, ultimately, the development of truly intelligent systems. In response, we introduce Concept-Aware Fine-Tuning (CAFT), a novel multi-token training method that redefines how LLMs are fine-tuned. By enabling the learning of sequences that span multiple tokens, this method fosters stronger concept-aware learning. Our experiments demonstrate significant improvements compared to conventional next-token finetuning methods across diverse tasks, including traditional applications like text summarization and domain-specific ones like de novo protein design. Multi-token prediction was previously only possible in the prohibitively expensive pretraining phase; CAFT, to our knowledge, is the first to bring the multi-token setting to the post-training phase, thus effectively democratizing its benefits for the broader community of practitioners and researchers. Finally, the unexpected effectiveness of our proposed method suggests wider implications for the machine learning research community. All code and data are available at https://github.com/michaelchen-lab/caft-llm",
    "categories": [
      "cs.LG",
      "cs.AI",
      "cs.CL"
    ],
    "primary_category": "cs.LG",
    "comment": "",
    "pdf_url": "https://arxiv.org/pdf/2506.07833v2",
    "published_date": "2025-06-09 14:55:00 UTC",
    "updated_date": "2025-06-13 17:24:38 UTC"
  },
  {
    "arxiv_id": "2506.07829v2",
    "title": "Decentralizing Multi-Agent Reinforcement Learning with Temporal Causal Information",
    "authors": [
      "Jan Corazza",
      "Hadi Partovi Aria",
      "Hyohun Kim",
      "Daniel Neider",
      "Zhe Xu"
    ],
    "abstract": "Reinforcement learning (RL) algorithms can find an optimal policy for a single agent to accomplish a particular task. However, many real-world problems require multiple agents to collaborate in order to achieve a common goal. For example, a robot executing a task in a warehouse may require the assistance of a drone to retrieve items from high shelves. In Decentralized Multi-Agent RL (DMARL), agents learn independently and then combine their policies at execution time, but often must satisfy constraints on compatibility of local policies to ensure that they can achieve the global task when combined. In this paper, we study how providing high-level symbolic knowledge to agents can help address unique challenges of this setting, such as privacy constraints, communication limitations, and performance concerns. In particular, we extend the formal tools used to check the compatibility of local policies with the team task, making decentralized training with theoretical guarantees usable in more scenarios. Furthermore, we empirically demonstrate that symbolic knowledge about the temporal evolution of events in the environment can significantly expedite the learning process in DMARL.",
    "categories": [
      "cs.LG",
      "cs.AI",
      "cs.MA"
    ],
    "primary_category": "cs.LG",
    "comment": "Code available at https://github.com/corazza/tcdmarl",
    "pdf_url": "https://arxiv.org/pdf/2506.07829v2",
    "published_date": "2025-06-09 14:53:03 UTC",
    "updated_date": "2025-10-14 21:29:34 UTC"
  },
  {
    "arxiv_id": "2506.07824v2",
    "title": "Addition in Four Movements: Mapping Layer-wise Information Trajectories in LLMs",
    "authors": [
      "Yao Yan"
    ],
    "abstract": "Multi-digit addition is a clear probe of the computational power of large language models. To dissect the internal arithmetic processes in LLaMA-3-8B-Instruct, we combine linear probing with logit-lens inspection. Inspired by the step-by-step manner in which humans perform addition, we propose and analyze a coherent four-stage trajectory in the forward pass:Formula-structure representations become linearly decodable first, while the answer token is still far down the candidate list.Core computational features then emerge prominently.At deeper activation layers, numerical abstractions of the result become clearer, enabling near-perfect detection and decoding of the individual digits in the sum.Near the output, the model organizes and generates the final content, with the correct token reliably occupying the top rank.This trajectory suggests a hierarchical process that favors internal computation over rote memorization. We release our code and data to facilitate reproducibility.",
    "categories": [
      "cs.AI"
    ],
    "primary_category": "cs.AI",
    "comment": "12 pages, including appendix, 7 figures. EMNLP 2025 submission (ARR May 2025 cycle, reviews pending)",
    "pdf_url": "https://arxiv.org/pdf/2506.07824v2",
    "published_date": "2025-06-09 14:48:43 UTC",
    "updated_date": "2025-09-09 16:35:39 UTC"
  },
  {
    "arxiv_id": "2506.07822v2",
    "title": "Accelerating Diffusion Planners in Offline RL via Reward-Aware Consistency Trajectory Distillation",
    "authors": [
      "Xintong Duan",
      "Yutong He",
      "Fahim Tajwar",
      "Ruslan Salakhutdinov",
      "J. Zico Kolter",
      "Jeff Schneider"
    ],
    "abstract": "Although diffusion models have achieved strong results in decision-making tasks, their slow inference speed remains a key limitation. While consistency models offer a potential solution, existing applications to decision-making either struggle with suboptimal demonstrations under behavior cloning or rely on complex concurrent training of multiple networks under the actor-critic framework. In this work, we propose a novel approach to consistency distillation for offline reinforcement learning that directly incorporates reward optimization into the distillation process. Our method achieves single-step sampling while generating higher-reward action trajectories through decoupled training and noise-free reward signals. Empirical evaluations on the Gym MuJoCo, FrankaKitchen, and long horizon planning benchmarks demonstrate that our approach can achieve a 9.7% improvement over previous state-of-the-art while offering up to 142x speedup over diffusion counterparts in inference time.",
    "categories": [
      "cs.LG",
      "cs.AI"
    ],
    "primary_category": "cs.LG",
    "comment": "",
    "pdf_url": "https://arxiv.org/pdf/2506.07822v2",
    "published_date": "2025-06-09 14:48:19 UTC",
    "updated_date": "2025-12-26 17:50:58 UTC"
  },
  {
    "arxiv_id": "2506.07820v2",
    "title": "Guideline Forest: Experience-Induced Multi-Guideline Reasoning with Stepwise Aggregation",
    "authors": [
      "Jiaxiang Chen",
      "Zhuo Wang",
      "Mingxi Zou",
      "Qifan Wang",
      "Zenglin Xu"
    ],
    "abstract": "Human reasoning is flexible, adaptive, and grounded in prior experience-qualities that large language models (LLMs) still struggle to emulate. Existing methods either explore diverse reasoning paths at inference time or search for optimal workflows through expensive operations, but both fall short in leveraging multiple reusable strategies in a structured, efficient manner. We propose Guideline Forest, a framework that enhances LLMs reasoning by inducing structured reasoning strategies-called guidelines-from verified examples and executing them via step-wise aggregation. Unlike test-time search or single-path distillation, our method draws on verified reasoning experiences by inducing reusable guidelines and expanding each into diverse variants. Much like human reasoning, these variants reflect alternative thought patterns, are executed in parallel, refined via self-correction, and aggregated step by step-enabling the model to adaptively resolve uncertainty and synthesize robust solutions.We evaluate Guideline Forest on four benchmarks-GSM8K, MATH-500, MBPP, and HumanEval-spanning mathematical and programmatic reasoning. Guideline Forest consistently outperforms strong baselines, including CoT, ReAct, ToT, FoT, and AFlow. Ablation studies further highlight the effectiveness of multi-path reasoning and stepwise aggregation, underscoring the Guideline Forest's adaptability and generalization potential.",
    "categories": [
      "cs.AI"
    ],
    "primary_category": "cs.AI",
    "comment": "",
    "pdf_url": "https://arxiv.org/pdf/2506.07820v2",
    "published_date": "2025-06-09 14:46:31 UTC",
    "updated_date": "2025-06-10 02:05:49 UTC"
  },
  {
    "arxiv_id": "2506.07813v1",
    "title": "Self-Cascaded Diffusion Models for Arbitrary-Scale Image Super-Resolution",
    "authors": [
      "Junseo Bang",
      "Joonhee Lee",
      "Kyeonghyun Lee",
      "Haechang Lee",
      "Dong Un Kang",
      "Se Young Chun"
    ],
    "abstract": "Arbitrary-scale image super-resolution aims to upsample images to any desired resolution, offering greater flexibility than traditional fixed-scale super-resolution. Recent approaches in this domain utilize regression-based or generative models, but many of them are a single-stage upsampling process, which may be challenging to learn across a wide, continuous distribution of scaling factors. Progressive upsampling strategies have shown promise in mitigating this issue, yet their integration with diffusion models for flexible upscaling remains underexplored. Here, we present CasArbi, a novel self-cascaded diffusion framework for arbitrary-scale image super-resolution. CasArbi meets the varying scaling demands by breaking them down into smaller sequential factors and progressively enhancing the image resolution at each step with seamless transitions for arbitrary scales. Our novel coordinate-guided residual diffusion model allows for the learning of continuous image representations while enabling efficient diffusion sampling. Extensive experiments demonstrate that our CasArbi outperforms prior arts in both perceptual and distortion performance metrics across diverse arbitrary-scale super-resolution benchmarks.",
    "categories": [
      "cs.CV",
      "cs.AI"
    ],
    "primary_category": "cs.CV",
    "comment": "",
    "pdf_url": "https://arxiv.org/pdf/2506.07813v1",
    "published_date": "2025-06-09 14:43:21 UTC",
    "updated_date": "2025-06-09 14:43:21 UTC"
  },
  {
    "arxiv_id": "2506.18915v2",
    "title": "Automatic Depression Assessment using Machine Learning: A Comprehensive Survey",
    "authors": [
      "Siyang Song",
      "Yupeng Huo",
      "Shiqing Tang",
      "Jiaee Cheong",
      "Rui Gao",
      "Michel Valstar",
      "Hatice Gunes"
    ],
    "abstract": "Depression is a common mental illness across current human society. Traditional depression assessment relying on inventories and interviews with psychologists frequently suffer from subjective diagnosis results, slow and expensive diagnosis process as well as lack of human resources. Since there is a solid evidence that depression is reflected by various human internal brain activities and external expressive behaviours, early traditional machine learning (ML) and advanced deep learning (DL) models have been widely explored for human behaviour-based automatic depression assessment (ADA) since 2012. However, recent ADA surveys typically only focus on a limited number of human behaviour modalities. Despite being used as a theoretical basis for developing ADA approaches, existing ADA surveys lack a comprehensive review and summary of multi-modal depression-related human behaviours. To bridge this gap, this paper specifically summarises depression-related human behaviours across a range of modalities (e.g. the human brain, verbal language and non-verbal audio/facial/body behaviours). We focus on conducting an up-to-date and comprehensive survey of ML-based ADA approaches for learning depression cues from these behaviours as well as discussing and comparing their distinctive features and limitations. In addition, we also review existing ADA competitions and datasets, identify and discuss the main challenges and opportunities to provide further research directions for future ADA researchers.",
    "categories": [
      "q-bio.NC",
      "cs.AI",
      "cs.LG"
    ],
    "primary_category": "q-bio.NC",
    "comment": "",
    "pdf_url": "https://arxiv.org/pdf/2506.18915v2",
    "published_date": "2025-06-09 14:40:16 UTC",
    "updated_date": "2025-06-29 10:44:28 UTC"
  },
  {
    "arxiv_id": "2506.07807v2",
    "title": "A Proposal to Extend the Common Model of Cognition with Metacognition",
    "authors": [
      "John Laird",
      "Christian Lebiere",
      "Paul Rosenbloom",
      "Andrea Stocco"
    ],
    "abstract": "The Common Model of Cognition (CMC) provides an abstract characterization of the structure and processing required by a cognitive architecture for human-like minds. We propose a unified approach to integrating metacognition within the CMC. We propose that metacognition involves reasoning over explicit representations of an agent's cognitive capabilities and processes in working memory. Our proposal exploits the existing cognitive capabilities of the CMC, making minimal extensions in the structure and information available within working memory. We provide examples of metacognition within our proposal.",
    "categories": [
      "cs.AI"
    ],
    "primary_category": "cs.AI",
    "comment": "",
    "pdf_url": "https://arxiv.org/pdf/2506.07807v2",
    "published_date": "2025-06-09 14:35:48 UTC",
    "updated_date": "2025-06-11 20:35:45 UTC"
  },
  {
    "arxiv_id": "2506.07804v1",
    "title": "Enhancing Adversarial Robustness with Conformal Prediction: A Framework for Guaranteed Model Reliability",
    "authors": [
      "Jie Bao",
      "Chuangyin Dang",
      "Rui Luo",
      "Hanwei Zhang",
      "Zhixin Zhou"
    ],
    "abstract": "As deep learning models are increasingly deployed in high-risk applications, robust defenses against adversarial attacks and reliable performance guarantees become paramount. Moreover, accuracy alone does not provide sufficient assurance or reliable uncertainty estimates for these models. This study advances adversarial training by leveraging principles from Conformal Prediction. Specifically, we develop an adversarial attack method, termed OPSA (OPtimal Size Attack), designed to reduce the efficiency of conformal prediction at any significance level by maximizing model uncertainty without requiring coverage guarantees. Correspondingly, we introduce OPSA-AT (Adversarial Training), a defense strategy that integrates OPSA within a novel conformal training paradigm. Experimental evaluations demonstrate that our OPSA attack method induces greater uncertainty compared to baseline approaches for various defenses. Conversely, our OPSA-AT defensive model significantly enhances robustness not only against OPSA but also other adversarial attacks, and maintains reliable prediction. Our findings highlight the effectiveness of this integrated approach for developing trustworthy and resilient deep learning models for safety-critical domains. Our code is available at https://github.com/bjbbbb/Enhancing-Adversarial-Robustness-with-Conformal-Prediction.",
    "categories": [
      "cs.LG",
      "cs.AI",
      "stat.ML"
    ],
    "primary_category": "cs.LG",
    "comment": "",
    "pdf_url": "https://arxiv.org/pdf/2506.07804v1",
    "published_date": "2025-06-09 14:33:28 UTC",
    "updated_date": "2025-06-09 14:33:28 UTC"
  },
  {
    "arxiv_id": "2506.07801v3",
    "title": "MultiMatch: Multihead Consistency Regularization Matching for Semi-Supervised Text Classification",
    "authors": [
      "Iustin Sirbu",
      "Robert-Adrian Popovici",
      "Cornelia Caragea",
      "Stefan Trausan-Matu",
      "Traian Rebedea"
    ],
    "abstract": "We introduce MultiMatch, a novel semi-supervised learning (SSL) algorithm combining the paradigms of co-training and consistency regularization with pseudo-labeling. At its core, MultiMatch features a pseudo-label weighting module designed for selecting and filtering pseudo-labels based on head agreement and model confidence, and weighting them according to the perceived classification difficulty. This novel module enhances and unifies three existing techniques -- heads agreement from Multihead Co-training, self-adaptive thresholds from FreeMatch, and Average Pseudo-Margins from MarginMatch -- resulting in a holistic approach that improves robustness and performance in SSL settings. Experimental results on benchmark datasets highlight the superior performance of MultiMatch, i.e., MultiMatch achieves state-of-the-art results on 8 out of 10 setups from 5 natural language processing datasets and ranks first according to the Friedman test among 21 methods. Furthermore, MultiMatch demonstrates exceptional robustness in highly imbalanced settings, outperforming the second-best approach by 3.26%, a critical advantage for real-world text classification tasks. Our code is available on GitHub.",
    "categories": [
      "cs.CL",
      "cs.AI",
      "cs.LG"
    ],
    "primary_category": "cs.CL",
    "comment": "This is the camera-ready version of the paper, accepted for publication in the Proceedings of the 2025 Conference on Empirical Methods in Natural Language Processing (EMNLP 2025)",
    "pdf_url": "https://arxiv.org/pdf/2506.07801v3",
    "published_date": "2025-06-09 14:27:47 UTC",
    "updated_date": "2025-11-01 10:40:37 UTC"
  },
  {
    "arxiv_id": "2506.07785v1",
    "title": "Re-ranking Reasoning Context with Tree Search Makes Large Vision-Language Models Stronger",
    "authors": [
      "Qi Yang",
      "Chenghao Zhang",
      "Lubin Fan",
      "Kun Ding",
      "Jieping Ye",
      "Shiming Xiang"
    ],
    "abstract": "Recent advancements in Large Vision Language Models (LVLMs) have significantly improved performance in Visual Question Answering (VQA) tasks through multimodal Retrieval-Augmented Generation (RAG). However, existing methods still face challenges, such as the scarcity of knowledge with reasoning examples and erratic responses from retrieved knowledge. To address these issues, in this study, we propose a multimodal RAG framework, termed RCTS, which enhances LVLMs by constructing a Reasoning Context-enriched knowledge base and a Tree Search re-ranking method. Specifically, we introduce a self-consistent evaluation mechanism to enrich the knowledge base with intrinsic reasoning patterns. We further propose a Monte Carlo Tree Search with Heuristic Rewards (MCTS-HR) to prioritize the most relevant examples. This ensures that LVLMs can leverage high-quality contextual reasoning for better and more consistent responses. Extensive experiments demonstrate that our framework achieves state-of-the-art performance on multiple VQA datasets, significantly outperforming In-Context Learning (ICL) and Vanilla-RAG methods. It highlights the effectiveness of our knowledge base and re-ranking method in improving LVLMs. Our code is available at https://github.com/yannqi/RCTS-RAG.",
    "categories": [
      "cs.CV",
      "cs.AI",
      "cs.LG"
    ],
    "primary_category": "cs.CV",
    "comment": "ICML 2025 Spotlight. 22 pages, 16 figures",
    "pdf_url": "https://arxiv.org/pdf/2506.07785v1",
    "published_date": "2025-06-09 14:00:57 UTC",
    "updated_date": "2025-06-09 14:00:57 UTC"
  },
  {
    "arxiv_id": "2506.08066v2",
    "title": "WWAggr: A Window Wasserstein-based Aggregation for Ensemble Change Point Detection",
    "authors": [
      "Alexander Stepikin",
      "Evgenia Romanenkova",
      "Alexey Zaytsev"
    ],
    "abstract": "Change Point Detection (CPD) aims to identify moments of abrupt distribution shifts in data streams. Real-world high-dimensional CPD remains challenging due to data pattern complexity and violation of common assumptions. Resorting to standalone deep neural networks, the current state-of-the-art detectors have yet to achieve perfect quality. Concurrently, ensembling provides more robust solutions, boosting the performance. In this paper, we investigate ensembles of deep change point detectors and realize that standard prediction aggregation techniques, e.g., averaging, are suboptimal and fail to account for problem peculiarities. Alternatively, we introduce WWAggr -- a novel task-specific method of ensemble aggregation based on the Wasserstein distance. Our procedure is versatile, working effectively with various ensembles of deep CPD models. Moreover, unlike existing solutions, we practically lift a long-standing problem of the decision threshold selection for CPD.",
    "categories": [
      "stat.ML",
      "cs.AI",
      "cs.LG"
    ],
    "primary_category": "stat.ML",
    "comment": "",
    "pdf_url": "https://arxiv.org/pdf/2506.08066v2",
    "published_date": "2025-06-09 13:52:10 UTC",
    "updated_date": "2025-10-02 11:27:46 UTC"
  },
  {
    "arxiv_id": "2506.13981v1",
    "title": "HAELT: A Hybrid Attentive Ensemble Learning Transformer Framework for High-Frequency Stock Price Forecasting",
    "authors": [
      "Thanh Dan Bui"
    ],
    "abstract": "High-frequency stock price prediction is challenging due to non-stationarity, noise, and volatility. To tackle these issues, we propose the Hybrid Attentive Ensemble Learning Transformer (HAELT), a deep learning framework combining a ResNet-based noise-mitigation module, temporal self-attention for dynamic focus on relevant history, and a hybrid LSTM-Transformer core that captures both local and long-range dependencies. These components are adaptively ensembled based on recent performance. Evaluated on hourly Apple Inc. (AAPL) data from Jan 2024 to May 2025, HAELT achieves the highest F1-Score on the test set, effectively identifying both upward and downward price movements. This demonstrates HAELT's potential for robust, practical financial forecasting and algorithmic trading.",
    "categories": [
      "cs.LG",
      "cs.AI"
    ],
    "primary_category": "cs.LG",
    "comment": "",
    "pdf_url": "https://arxiv.org/pdf/2506.13981v1",
    "published_date": "2025-06-09 13:40:18 UTC",
    "updated_date": "2025-06-09 13:40:18 UTC"
  },
  {
    "arxiv_id": "2506.07759v1",
    "title": "REMoH: A Reflective Evolution of Multi-objective Heuristics approach via Large Language Models",
    "authors": [
      "Diego Forniés-Tabuenca",
      "Alejandro Uribe",
      "Urtzi Otamendi",
      "Arkaitz Artetxe",
      "Juan Carlos Rivera",
      "Oier Lopez de Lacalle"
    ],
    "abstract": "Multi-objective optimization is fundamental in complex decision-making tasks. Traditional algorithms, while effective, often demand extensive problem-specific modeling and struggle to adapt to nonlinear structures. Recent advances in Large Language Models (LLMs) offer enhanced explainability, adaptability, and reasoning. This work proposes Reflective Evolution of Multi-objective Heuristics (REMoH), a novel framework integrating NSGA-II with LLM-based heuristic generation. A key innovation is a reflection mechanism that uses clustering and search-space reflection to guide the creation of diverse, high-quality heuristics, improving convergence and maintaining solution diversity. The approach is evaluated on the Flexible Job Shop Scheduling Problem (FJSSP) in-depth benchmarking against state-of-the-art methods using three instance datasets: Dauzere, Barnes, and Brandimarte. Results demonstrate that REMoH achieves competitive results compared to state-of-the-art approaches with reduced modeling effort and enhanced adaptability. These findings underscore the potential of LLMs to augment traditional optimization, offering greater flexibility, interpretability, and robustness in multi-objective scenarios.",
    "categories": [
      "cs.AI",
      "cs.NE"
    ],
    "primary_category": "cs.AI",
    "comment": "21 pages, 5 tables, 7 figures and 4 appendixes. Pre-print submitted to IEEE Transactions on Evolutionary Computation",
    "pdf_url": "https://arxiv.org/pdf/2506.07759v1",
    "published_date": "2025-06-09 13:38:28 UTC",
    "updated_date": "2025-06-09 13:38:28 UTC"
  },
  {
    "arxiv_id": "2506.07756v2",
    "title": "Agent Semantics, Semantic Spacetime, and Graphical Reasoning",
    "authors": [
      "Mark Burgess"
    ],
    "abstract": "Some formal aspects of the Semantic Spacetime graph model are presented, with reference to its use for directed knowledge representations and process modelling. A finite $γ(3,4)$ representation is defined to form a closed set of operations that can scale to any degree of semantic complexity. The Semantic Spacetime postulates bring predictability with minimal constraints to pathways in graphs. The ubiquitous appearance of absorbing states in any partial graph means that a graph process leaks information. The issue is closely associated with the issue of division by zero, which signals a loss of closure and the need for manual injection of remedial information. The Semantic Spacetime model (and its Promise Theory) origins help to clarify how such absorbing states are associated with boundary information where intentionality can enter.",
    "categories": [
      "cs.AI",
      "cs.LG",
      "cs.MA"
    ],
    "primary_category": "cs.AI",
    "comment": "Some typos corrected",
    "pdf_url": "https://arxiv.org/pdf/2506.07756v2",
    "published_date": "2025-06-09 13:37:47 UTC",
    "updated_date": "2025-06-13 14:51:05 UTC"
  },
  {
    "arxiv_id": "2506.07754v1",
    "title": "Comparing Credit Risk Estimates in the Gen-AI Era",
    "authors": [
      "Nicola Lavecchia",
      "Sid Fadanelli",
      "Federico Ricciuti",
      "Gennaro Aloe",
      "Enrico Bagli",
      "Pietro Giuffrida",
      "Daniele Vergari"
    ],
    "abstract": "Generative AI technologies have demonstrated significant potential across diverse applications. This study provides a comparative analysis of credit score modeling techniques, contrasting traditional approaches with those leveraging generative AI. Our findings reveal that current generative AI models fall short of matching the performance of traditional methods, regardless of the integration strategy employed. These results highlight the limitations in the current capabilities of generative AI for credit risk scoring, emphasizing the need for further research and development before the possibility of applying generative AI for this specific task, or equivalent ones.",
    "categories": [
      "cs.LG",
      "cs.AI"
    ],
    "primary_category": "cs.LG",
    "comment": "",
    "pdf_url": "https://arxiv.org/pdf/2506.07754v1",
    "published_date": "2025-06-09 13:37:04 UTC",
    "updated_date": "2025-06-09 13:37:04 UTC"
  },
  {
    "arxiv_id": "2506.07751v3",
    "title": "AbstRaL: Augmenting LLMs' Reasoning by Reinforcing Abstract Thinking",
    "authors": [
      "Silin Gao",
      "Antoine Bosselut",
      "Samy Bengio",
      "Emmanuel Abbe"
    ],
    "abstract": "Recent studies have shown that large language models (LLMs), especially smaller ones, often lack robustness in grade school math (GSM) reasoning. In particular, they tend to experience performance drops when faced with distribution shifts, such as changes to numerical or nominal variables, or insertions of distracting clauses. A possible strategy to address this involves generating synthetic data to further \"instantiate\" reasoning problems on potential variations. In this work, we instead focuses on the strategy of \"abstracting\" reasoning problems. This not only helps counteract distribution shifts but also facilitates the connection to symbolic tools for deriving solutions. Focusing on GSM, we find that this abstraction process is better acquired through reinforcement learning (RL) than just supervised fine-tuning, which often fails to produce faithful abstractions. Our method, AbstRaL -- which promotes abstract reasoning in LLMs using RL on granular abstraction data -- significantly mitigates performance degradation on recent GSM perturbation benchmarks. Besides, improving GSM robustness via AbstRaL is shown to also implicitly benefit LLMs' capabilities on OOD mathematical and general reasoning tasks, indicating that abstract thinking broadly enables better generalizability.",
    "categories": [
      "cs.CL",
      "cs.AI",
      "cs.SC"
    ],
    "primary_category": "cs.CL",
    "comment": "Under review",
    "pdf_url": "https://arxiv.org/pdf/2506.07751v3",
    "published_date": "2025-06-09 13:34:50 UTC",
    "updated_date": "2025-11-24 14:29:20 UTC"
  },
  {
    "arxiv_id": "2506.07744v3",
    "title": "Graph-Assisted Stitching for Offline Hierarchical Reinforcement Learning",
    "authors": [
      "Seungho Baek",
      "Taegeon Park",
      "Jongchan Park",
      "Seungjun Oh",
      "Yusung Kim"
    ],
    "abstract": "Existing offline hierarchical reinforcement learning methods rely on high-level policy learning to generate subgoal sequences. However, their efficiency degrades as task horizons increase, and they lack effective strategies for stitching useful state transitions across different trajectories. We propose Graph-Assisted Stitching (GAS), a novel framework that formulates subgoal selection as a graph search problem rather than learning an explicit high-level policy. By embedding states into a Temporal Distance Representation (TDR) space, GAS clusters semantically similar states from different trajectories into unified graph nodes, enabling efficient transition stitching. A shortest-path algorithm is then applied to select subgoal sequences within the graph, while a low-level policy learns to reach the subgoals. To improve graph quality, we introduce the Temporal Efficiency (TE) metric, which filters out noisy or inefficient transition states, significantly enhancing task performance. GAS outperforms prior offline HRL methods across locomotion, navigation, and manipulation tasks. Notably, in the most stitching-critical task, it achieves a score of 88.3, dramatically surpassing the previous state-of-the-art score of 1.0. Our source code is available at: https://github.com/qortmdgh4141/GAS.",
    "categories": [
      "cs.LG",
      "cs.AI",
      "cs.RO"
    ],
    "primary_category": "cs.LG",
    "comment": "ICML 2025",
    "pdf_url": "https://arxiv.org/pdf/2506.07744v3",
    "published_date": "2025-06-09 13:26:23 UTC",
    "updated_date": "2025-07-07 14:23:25 UTC"
  },
  {
    "arxiv_id": "2506.07739v3",
    "title": "ArchiLense: A Framework for Quantitative Analysis of Architectural Styles Based on Vision Large Language Models",
    "authors": [
      "Jing Zhong",
      "Jun Yin",
      "Peilin Li",
      "Pengyu Zeng",
      "Miao Zang",
      "Ran Luo",
      "Shuai Lu"
    ],
    "abstract": "Architectural cultures across regions are characterized by stylistic diversity, shaped by historical, social, and technological contexts in addition to geograph-ical conditions. Understanding architectural styles requires the ability to describe and analyze the stylistic features of different architects from various regions through visual observations of architectural imagery. However, traditional studies of architectural culture have largely relied on subjective expert interpretations and historical literature reviews, often suffering from regional biases and limited ex-planatory scope. To address these challenges, this study proposes three core contributions: (1) We construct a professional architectural style dataset named ArchDiffBench, which comprises 1,765 high-quality architectural images and their corresponding style annotations, collected from different regions and historical periods. (2) We propose ArchiLense, an analytical framework grounded in Vision-Language Models and constructed using the ArchDiffBench dataset. By integrating ad-vanced computer vision techniques, deep learning, and machine learning algo-rithms, ArchiLense enables automatic recognition, comparison, and precise classi-fication of architectural imagery, producing descriptive language outputs that ar-ticulate stylistic differences. (3) Extensive evaluations show that ArchiLense achieves strong performance in architectural style recognition, with a 92.4% con-sistency rate with expert annotations and 84.5% classification accuracy, effec-tively capturing stylistic distinctions across images. The proposed approach transcends the subjectivity inherent in traditional analyses and offers a more objective and accurate perspective for comparative studies of architectural culture.",
    "categories": [
      "cs.CV",
      "cs.AI"
    ],
    "primary_category": "cs.CV",
    "comment": "",
    "pdf_url": "https://arxiv.org/pdf/2506.07739v3",
    "published_date": "2025-06-09 13:22:57 UTC",
    "updated_date": "2025-08-02 12:10:07 UTC"
  },
  {
    "arxiv_id": "2506.07736v3",
    "title": "RSafe: Incentivizing proactive reasoning to build robust and adaptive LLM safeguards",
    "authors": [
      "Jingnan Zheng",
      "Xiangtian Ji",
      "Yijun Lu",
      "Chenhang Cui",
      "Weixiang Zhao",
      "Gelei Deng",
      "Zhenkai Liang",
      "An Zhang",
      "Tat-Seng Chua"
    ],
    "abstract": "Large Language Models (LLMs) continue to exhibit vulnerabilities despite deliberate safety alignment efforts, posing significant risks to users and society. To safeguard against the risk of policy-violating content, system-level moderation via external guard models-designed to monitor LLM inputs and outputs and block potentially harmful content-has emerged as a prevalent mitigation strategy. Existing approaches of training guard models rely heavily on extensive human curated datasets and struggle with out-of-distribution threats, such as emerging harmful categories or jailbreak attacks. To address these limitations, we propose RSafe, an adaptive reasoning-based safeguard that conducts guided safety reasoning to provide robust protection within the scope of specified safety policies. RSafe operates in two stages: 1) guided reasoning, where it analyzes safety risks of input content through policy-guided step-by-step reasoning, and 2) reinforced alignment, where rule-based RL optimizes its reasoning paths to align with accurate safety prediction. This two-stage training paradigm enables RSafe to internalize safety principles to generalize safety protection capability over unseen or adversarial safety violation scenarios. During inference, RSafe accepts user-specified safety policies to provide enhanced safeguards tailored to specific safety requirements.",
    "categories": [
      "cs.AI"
    ],
    "primary_category": "cs.AI",
    "comment": "",
    "pdf_url": "https://arxiv.org/pdf/2506.07736v3",
    "published_date": "2025-06-09 13:20:04 UTC",
    "updated_date": "2025-10-24 06:18:17 UTC"
  },
  {
    "arxiv_id": "2506.09071v2",
    "title": "Segment Any Architectural Facades (SAAF):An automatic segmentation model for building facades, walls and windows based on multimodal semantics guidance",
    "authors": [
      "Peilin Li",
      "Jun Yin",
      "Jing Zhong",
      "Ran Luo",
      "Pengyu Zeng",
      "Miao Zhang"
    ],
    "abstract": "In the context of the digital development of architecture, the automatic segmentation of walls and windows is a key step in improving the efficiency of building information models and computer-aided design. This study proposes an automatic segmentation model for building facade walls and windows based on multimodal semantic guidance, called Segment Any Architectural Facades (SAAF). First, SAAF has a multimodal semantic collaborative feature extraction mechanism. By combining natural language processing technology, it can fuse the semantic information in text descriptions with image features, enhancing the semantic understanding of building facade components. Second, we developed an end-to-end training framework that enables the model to autonomously learn the mapping relationship from text descriptions to image segmentation, reducing the influence of manual intervention on the segmentation results and improving the automation and robustness of the model. Finally, we conducted extensive experiments on multiple facade datasets. The segmentation results of SAAF outperformed existing methods in the mIoU metric, indicating that the SAAF model can maintain high-precision segmentation ability when faced with diverse datasets. Our model has made certain progress in improving the accuracy and generalization ability of the wall and window segmentation task. It is expected to provide a reference for the development of architectural computer vision technology and also explore new ideas and technical paths for the application of multimodal learning in the architectural field.",
    "categories": [
      "cs.CV",
      "cs.AI"
    ],
    "primary_category": "cs.CV",
    "comment": "",
    "pdf_url": "https://arxiv.org/pdf/2506.09071v2",
    "published_date": "2025-06-09 13:16:46 UTC",
    "updated_date": "2025-08-02 12:21:14 UTC"
  },
  {
    "arxiv_id": "2506.07731v1",
    "title": "NeurIPS 2025 E2LM Competition : Early Training Evaluation of Language Models",
    "authors": [
      "Mouadh Yagoubi",
      "Yasser Dahou",
      "Billel Mokeddem",
      "Younes Belkada",
      "Phuc H. Le-Khac",
      "Basma El Amel Boussaha",
      "Reda Alami",
      "Jingwei Zuo",
      "Damiano Marsili",
      "Mugariya Farooq",
      "Mounia Lalmas",
      "Georgia Gkioxari",
      "Patrick Gallinari",
      "Philip Torr",
      "Hakim Hacid"
    ],
    "abstract": "Existing benchmarks have proven effective for assessing the performance of fully trained large language models. However, we find striking differences in the early training stages of small models, where benchmarks often fail to provide meaningful or discriminative signals. To explore how these differences arise, this competition tackles the challenge of designing scientific knowledge evaluation tasks specifically tailored for measuring early training progress of language models. Participants are invited to develop novel evaluation methodologies or adapt existing benchmarks to better capture performance differences among language models. To support this effort, we provide three pre-trained small models (0.5B, 1B, and 3B parameters), along with intermediate checkpoints sampled during training up to 200B tokens. All experiments and development work can be run on widely available free cloud-based GPU platforms, making participation accessible to researchers with limited computational resources. Submissions will be evaluated based on three criteria: the quality of the performance signal they produce, the consistency of model rankings at 1 trillion tokens of training, and their relevance to the scientific knowledge domain. By promoting the design of tailored evaluation strategies for early training, this competition aims to attract a broad range of participants from various disciplines, including those who may not be machine learning experts or have access to dedicated GPU resources. Ultimately, this initiative seeks to make foundational LLM research more systematic and benchmark-informed from the earliest phases of model development.",
    "categories": [
      "cs.AI"
    ],
    "primary_category": "cs.AI",
    "comment": "",
    "pdf_url": "https://arxiv.org/pdf/2506.07731v1",
    "published_date": "2025-06-09 13:15:50 UTC",
    "updated_date": "2025-06-09 13:15:50 UTC"
  },
  {
    "arxiv_id": "2506.07725v1",
    "title": "ETA: Efficiency through Thinking Ahead, A Dual Approach to Self-Driving with Large Models",
    "authors": [
      "Shadi Hamdan",
      "Chonghao Sima",
      "Zetong Yang",
      "Hongyang Li",
      "Fatma Güney"
    ],
    "abstract": "How can we benefit from large models without sacrificing inference speed, a common dilemma in self-driving systems? A prevalent solution is a dual-system architecture, employing a small model for rapid, reactive decisions and a larger model for slower but more informative analyses. Existing dual-system designs often implement parallel architectures where inference is either directly conducted using the large model at each current frame or retrieved from previously stored inference results. However, these works still struggle to enable large models for a timely response to every online frame. Our key insight is to shift intensive computations of the current frame to previous time steps and perform a batch inference of multiple time steps to make large models respond promptly to each time step. To achieve the shifting, we introduce Efficiency through Thinking Ahead (ETA), an asynchronous system designed to: (1) propagate informative features from the past to the current frame using future predictions from the large model, (2) extract current frame features using a small model for real-time responsiveness, and (3) integrate these dual features via an action mask mechanism that emphasizes action-critical image regions. Evaluated on the Bench2Drive CARLA Leaderboard-v2 benchmark, ETA advances state-of-the-art performance by 8% with a driving score of 69.53 while maintaining a near-real-time inference speed at 50 ms.",
    "categories": [
      "cs.CV",
      "cs.AI"
    ],
    "primary_category": "cs.CV",
    "comment": "ICCV 2025 submission. For code, see https://github.com/opendrivelab/ETA",
    "pdf_url": "https://arxiv.org/pdf/2506.07725v1",
    "published_date": "2025-06-09 13:11:02 UTC",
    "updated_date": "2025-06-09 13:11:02 UTC"
  },
  {
    "arxiv_id": "2506.07713v2",
    "title": "Consistent Video Editing as Flow-Driven Image-to-Video Generation",
    "authors": [
      "Ge Wang",
      "Songlin Fan",
      "Hangxu Liu",
      "Quanjian Song",
      "Hewei Wang",
      "Jinfeng Xu"
    ],
    "abstract": "With the prosper of video diffusion models, down-stream applications like video editing have been significantly promoted without consuming much computational cost. One particular challenge in this task lies at the motion transfer process from the source video to the edited one, where it requires the consideration of the shape deformation in between, meanwhile maintaining the temporal consistency in the generated video sequence. However, existing methods fail to model complicated motion patterns for video editing, and are fundamentally limited to object replacement, where tasks with non-rigid object motions like multi-object and portrait editing are largely neglected. In this paper, we observe that optical flows offer a promising alternative in complex motion modeling, and present FlowV2V to re-investigate video editing as a task of flow-driven Image-to-Video (I2V) generation. Specifically, FlowV2V decomposes the entire pipeline into first-frame editing and conditional I2V generation, and simulates pseudo flow sequence that aligns with the deformed shape, thus ensuring the consistency during editing. Experimental results on DAVIS-EDIT with improvements of 13.67% and 50.66% on DOVER and warping error illustrate the superior temporal consistency and sample quality of FlowV2V compared to existing state-of-the-art ones. Furthermore, we conduct comprehensive ablation studies to analyze the internal functionalities of the first-frame paradigm and flow alignment in the proposed method.",
    "categories": [
      "cs.CV",
      "cs.AI"
    ],
    "primary_category": "cs.CV",
    "comment": "16 pages, 12 figures",
    "pdf_url": "https://arxiv.org/pdf/2506.07713v2",
    "published_date": "2025-06-09 12:57:30 UTC",
    "updated_date": "2025-06-13 09:10:58 UTC"
  },
  {
    "arxiv_id": "2506.07698v1",
    "title": "NOVA3D: Normal Aligned Video Diffusion Model for Single Image to 3D Generation",
    "authors": [
      "Yuxiao Yang",
      "Peihao Li",
      "Yuhong Zhang",
      "Junzhe Lu",
      "Xianglong He",
      "Minghan Qin",
      "Weitao Wang",
      "Haoqian Wang"
    ],
    "abstract": "3D AI-generated content (AIGC) has made it increasingly accessible for anyone to become a 3D content creator. While recent methods leverage Score Distillation Sampling to distill 3D objects from pretrained image diffusion models, they often suffer from inadequate 3D priors, leading to insufficient multi-view consistency. In this work, we introduce NOVA3D, an innovative single-image-to-3D generation framework. Our key insight lies in leveraging strong 3D priors from a pretrained video diffusion model and integrating geometric information during multi-view video fine-tuning. To facilitate information exchange between color and geometric domains, we propose the Geometry-Temporal Alignment (GTA) attention mechanism, thereby improving generalization and multi-view consistency. Moreover, we introduce the de-conflict geometry fusion algorithm, which improves texture fidelity by addressing multi-view inaccuracies and resolving discrepancies in pose alignment. Extensive experiments validate the superiority of NOVA3D over existing baselines.",
    "categories": [
      "cs.CV",
      "cs.AI"
    ],
    "primary_category": "cs.CV",
    "comment": "8 pages, 7 figures, accepted by ICME 2025",
    "pdf_url": "https://arxiv.org/pdf/2506.07698v1",
    "published_date": "2025-06-09 12:37:46 UTC",
    "updated_date": "2025-06-09 12:37:46 UTC"
  },
  {
    "arxiv_id": "2506.10022v1",
    "title": "LLMs Caught in the Crossfire: Malware Requests and Jailbreak Challenges",
    "authors": [
      "Haoyang Li",
      "Huan Gao",
      "Zhiyuan Zhao",
      "Zhiyu Lin",
      "Junyu Gao",
      "Xuelong Li"
    ],
    "abstract": "The widespread adoption of Large Language Models (LLMs) has heightened concerns about their security, particularly their vulnerability to jailbreak attacks that leverage crafted prompts to generate malicious outputs. While prior research has been conducted on general security capabilities of LLMs, their specific susceptibility to jailbreak attacks in code generation remains largely unexplored. To fill this gap, we propose MalwareBench, a benchmark dataset containing 3,520 jailbreaking prompts for malicious code-generation, designed to evaluate LLM robustness against such threats. MalwareBench is based on 320 manually crafted malicious code generation requirements, covering 11 jailbreak methods and 29 code functionality categories. Experiments show that mainstream LLMs exhibit limited ability to reject malicious code-generation requirements, and the combination of multiple jailbreak methods further reduces the model's security capabilities: specifically, the average rejection rate for malicious content is 60.93%, dropping to 39.92% when combined with jailbreak attack algorithms. Our work highlights that the code security capabilities of LLMs still pose significant challenges.",
    "categories": [
      "cs.CR",
      "cs.AI"
    ],
    "primary_category": "cs.CR",
    "comment": "Accepted as ACL 2025 main conference",
    "pdf_url": "https://arxiv.org/pdf/2506.10022v1",
    "published_date": "2025-06-09 12:02:39 UTC",
    "updated_date": "2025-06-09 12:02:39 UTC"
  },
  {
    "arxiv_id": "2506.07675v3",
    "title": "QUITE: A Query Rewrite System Beyond Rules with LLM Agents",
    "authors": [
      "Yuyang Song",
      "Hanxu Yan",
      "Jiale Lao",
      "Yibo Wang",
      "Yufei Li",
      "Yuanchun Zhou",
      "Jianguo Wang",
      "Mingjie Tang"
    ],
    "abstract": "Query rewrite transforms SQL queries into semantically equivalent forms that run more efficiently. Existing approaches mainly rely on predefined rewrite rules, but they handle a limited subset of queries and can cause performance regressions. This limitation stems from three challenges of rule-based query rewrite: (1) it is hard to discover and verify new rules, (2) fixed rewrite rules do not generalize to new query patterns, and (3) some rewrite techniques cannot be expressed as fixed rules. Motivated by the fact that human experts exhibit significantly better rewrite ability but suffer from scalability, and Large Language Models (LLMs) have demonstrated nearly human-level semantic and reasoning abilities, we propose a new approach of using LLMs to rewrite SQL queries beyond rules. Due to the hallucination problems in LLMs, directly applying LLMs often leads to nonequivalent and suboptimal queries. To address this issue, we propose QUITE (query rewrite), a training-free and feedback-aware system based on LLM agents that rewrites SQL queries into semantically equivalent forms with significantly better performance, covering a broader range of query patterns and rewrite strategies compared to rule-based methods. Firstly, we design a multi-agent framework controlled by a finite state machine (FSM) to equip LLMs with the ability to use external tools and enhance the rewrite process with real-time database feedback. Secondly, we develop a rewrite middleware to enhance the ability of LLMs to generate optimized query equivalents. Finally, we employ a novel hint injection technique to improve execution plans for rewritten queries. Extensive experiments show that QUITE reduces query execution time by up to 35.8% over state-of-the-art approaches and produces 24.1% more rewrites than prior methods, covering query cases that earlier systems did not handle.",
    "categories": [
      "cs.DB",
      "cs.AI"
    ],
    "primary_category": "cs.DB",
    "comment": "",
    "pdf_url": "https://arxiv.org/pdf/2506.07675v3",
    "published_date": "2025-06-09 11:51:27 UTC",
    "updated_date": "2026-01-02 16:51:25 UTC"
  },
  {
    "arxiv_id": "2506.07672v1",
    "title": "MCPWorld: A Unified Benchmarking Testbed for API, GUI, and Hybrid Computer Use Agents",
    "authors": [
      "Yunhe Yan",
      "Shihe Wang",
      "Jiajun Du",
      "Yexuan Yang",
      "Yuxuan Shan",
      "Qichen Qiu",
      "Xianqing Jia",
      "Xinge Wang",
      "Xin Yuan",
      "Xu Han",
      "Mao Qin",
      "Yinxiao Chen",
      "Chen Peng",
      "Shangguang Wang",
      "Mengwei Xu"
    ],
    "abstract": "(M)LLM-powered computer use agents (CUA) are emerging as a transformative technique to automate human-computer interaction. However, existing CUA benchmarks predominantly target GUI agents, whose evaluation methods are susceptible to UI changes and ignore function interactions exposed by application APIs, e.g., Model Context Protocol (MCP). To this end, we propose MCPWorld, the first automatic CUA testbed for API, GUI, and API-GUI hybrid agents. A key principle of MCPWorld is the use of \"white-box apps\", i.e., those with source code availability and can be revised/re-compiled as needed (e.g., adding MCP support), with two notable advantages:\n  (1) It greatly broadens the design space of CUA, such as what and how the app features to be exposed/extracted as CUA-callable APIs.\n  (2) It allows MCPWorld to programmatically verify task completion by directly monitoring application behavior through techniques like dynamic code instrumentation, offering robust, accurate CUA evaluation decoupled from specific agent implementations or UI states.\n  Currently, MCPWorld includes 201 well curated and annotated user tasks, covering diversified use cases and difficulty levels. MCPWorld is also fully containerized with GPU acceleration support for flexible adoption on different OS/hardware environments. Our preliminary experiments, using a representative LLM-powered CUA framework, achieve 75.12% task completion accuracy, simultaneously providing initial evidence on the practical effectiveness of agent automation leveraging MCP. Overall, we anticipate MCPWorld to facilitate and standardize the benchmarking of next-generation computer use agents that can leverage rich external tools. Our code and dataset are publicly available at https://github.com/SAAgent/MCPWorld.",
    "categories": [
      "cs.AI"
    ],
    "primary_category": "cs.AI",
    "comment": "",
    "pdf_url": "https://arxiv.org/pdf/2506.07672v1",
    "published_date": "2025-06-09 11:50:33 UTC",
    "updated_date": "2025-06-09 11:50:33 UTC"
  },
  {
    "arxiv_id": "2506.11117v1",
    "title": "ScIRGen: Synthesize Realistic and Large-Scale RAG Dataset for Scientific Research",
    "authors": [
      "Junyong Lin",
      "Lu Dai",
      "Ruiqian Han",
      "Yijie Sui",
      "Ruilin Wang",
      "Xingliang Sun",
      "Qinglin Wu",
      "Min Feng",
      "Hao Liu",
      "Hui Xiong"
    ],
    "abstract": "Scientific researchers need intensive information about datasets to effectively evaluate and develop theories and methodologies. The information needs regarding datasets are implicitly embedded in particular research tasks, rather than explicitly expressed in search queries. However, existing scientific retrieval and question-answering (QA) datasets typically address straightforward questions, which do not align with the distribution of real-world research inquiries. To bridge this gap, we developed ScIRGen, a dataset generation framework for scientific QA \\& retrieval that more accurately reflects the information needs of professional science researchers, and uses it to create a large-scale scientific retrieval-augmented generation (RAG) dataset with realistic queries, datasets and papers. Technically, we designed a dataset-oriented information extraction method that leverages academic papers to augment the dataset representation. We then proposed a question generation framework by employing cognitive taxonomy to ensure the quality of synthesized questions. We also design a method to automatically filter synthetic answers based on the perplexity shift of LLMs, which is highly aligned with human judgment of answers' validity. Collectively, these methodologies culminated in the creation of the 61k QA dataset, ScIRGen-Geo. We benchmarked representative methods on the ScIRGen-Geo dataset for their question-answering and retrieval capabilities, finding out that current methods still suffer from reasoning from complex questions. This work advances the development of more sophisticated tools to support the intricate information needs of the scientific community.",
    "categories": [
      "cs.CL",
      "cs.AI",
      "cs.IR"
    ],
    "primary_category": "cs.CL",
    "comment": "KDD 2025 Accepted",
    "pdf_url": "https://arxiv.org/pdf/2506.11117v1",
    "published_date": "2025-06-09 11:47:13 UTC",
    "updated_date": "2025-06-09 11:47:13 UTC"
  },
  {
    "arxiv_id": "2506.07671v1",
    "title": "GaRAGe: A Benchmark with Grounding Annotations for RAG Evaluation",
    "authors": [
      "Ionut-Teodor Sorodoc",
      "Leonardo F. R. Ribeiro",
      "Rexhina Blloshmi",
      "Christopher Davis",
      "Adrià de Gispert"
    ],
    "abstract": "We present GaRAGe, a large RAG benchmark with human-curated long-form answers and annotations of each grounding passage, allowing a fine-grained evaluation of whether LLMs can identify relevant grounding when generating RAG answers. Our benchmark contains 2366 questions of diverse complexity, dynamism, and topics, and includes over 35K annotated passages retrieved from both private document sets and the Web, to reflect real-world RAG use cases. This makes it an ideal test bed to evaluate an LLM's ability to identify only the relevant information necessary to compose a response, or provide a deflective response when there is insufficient information. Evaluations of multiple state-of-the-art LLMs on GaRAGe show that the models tend to over-summarise rather than (a) ground their answers strictly on the annotated relevant passages (reaching at most a Relevance-Aware Factuality Score of 60%), or (b) deflect when no relevant grounding is available (reaching at most 31% true positive rate in deflections). The F1 in attribution to relevant sources is at most 58.9%, and we show that performance is particularly reduced when answering time-sensitive questions and when having to draw knowledge from sparser private grounding sources.",
    "categories": [
      "cs.CL",
      "cs.AI"
    ],
    "primary_category": "cs.CL",
    "comment": "ACL 2025 (Findings)",
    "pdf_url": "https://arxiv.org/pdf/2506.07671v1",
    "published_date": "2025-06-09 11:47:03 UTC",
    "updated_date": "2025-06-09 11:47:03 UTC"
  },
  {
    "arxiv_id": "2506.07664v2",
    "title": "Synthesis by Design: Controlled Data Generation via Structural Guidance",
    "authors": [
      "Lei Xu",
      "Sirui Chen",
      "Yuxuan Huang",
      "Chaochao Lu"
    ],
    "abstract": "Mathematical reasoning remains challenging for LLMs due to complex logic and the need for precise computation. Existing methods enhance LLM reasoning by synthesizing datasets through problem rephrasing, but face issues with generation quality and problem complexity. To address this, we propose to extract structural information with generated problem-solving code from mathematical reasoning and guide data generation with structured solutions. Applied to MATH and GSM8K, our approach produces 39K problems with labeled intermediate steps and a 6.1K-problem benchmark of higher difficulty. Results on our benchmark show that model performance declines as reasoning length increases. Additionally, we conducted fine-tuning experiments using the proposed training data on a range of LLMs, and the results validate the effectiveness of our dataset. We hope the proposed method and dataset will contribute to future research in enhancing LLM reasoning capabilities. Our code and data are available at https://github.com/OpenCausaLab/StructuralGeneration.",
    "categories": [
      "cs.CL",
      "cs.AI"
    ],
    "primary_category": "cs.CL",
    "comment": "",
    "pdf_url": "https://arxiv.org/pdf/2506.07664v2",
    "published_date": "2025-06-09 11:38:23 UTC",
    "updated_date": "2025-06-10 21:19:15 UTC"
  },
  {
    "arxiv_id": "2506.07652v1",
    "title": "FMaMIL: Frequency-Driven Mamba Multi-Instance Learning for Weakly Supervised Lesion Segmentation in Medical Images",
    "authors": [
      "Hangbei Cheng",
      "Xiaorong Dong",
      "Xueyu Liu",
      "Jianan Zhang",
      "Xuetao Ma",
      "Mingqiang Wei",
      "Liansheng Wang",
      "Junxin Chen",
      "Yongfei Wu"
    ],
    "abstract": "Accurate lesion segmentation in histopathology images is essential for diagnostic interpretation and quantitative analysis, yet it remains challenging due to the limited availability of costly pixel-level annotations. To address this, we propose FMaMIL, a novel two-stage framework for weakly supervised lesion segmentation based solely on image-level labels. In the first stage, a lightweight Mamba-based encoder is introduced to capture long-range dependencies across image patches under the MIL paradigm. To enhance spatial sensitivity and structural awareness, we design a learnable frequency-domain encoding module that supplements spatial-domain features with spectrum-based information. CAMs generated in this stage are used to guide segmentation training. In the second stage, we refine the initial pseudo labels via a CAM-guided soft-label supervision and a self-correction mechanism, enabling robust training even under label noise. Extensive experiments on both public and private histopathology datasets demonstrate that FMaMIL outperforms state-of-the-art weakly supervised methods without relying on pixel-level annotations, validating its effectiveness and potential for digital pathology applications.",
    "categories": [
      "cs.CV",
      "cs.AI"
    ],
    "primary_category": "cs.CV",
    "comment": "",
    "pdf_url": "https://arxiv.org/pdf/2506.07652v1",
    "published_date": "2025-06-09 11:18:02 UTC",
    "updated_date": "2025-06-09 11:18:02 UTC"
  },
  {
    "arxiv_id": "2506.07636v2",
    "title": "SWE-Dev: Building Software Engineering Agents with Training and Inference Scaling",
    "authors": [
      "Haoran Wang",
      "Zhenyu Hou",
      "Yao Wei",
      "Jie Tang",
      "Yuxiao Dong"
    ],
    "abstract": "Large language models (LLMs) have advanced rapidly from conversational problem solving to addressing real-world tasks involving tool use, such as software engineering (SWE). Recent LLM-powered toolkits, such as OpenAI Codex and Cursor, have offered end-to-end automation of the software development process. However, building effective SWE agents remains challenging due to the lack of high-quality training data and effective test cases. To address this issue, we present SWE-Dev, an SWE agent built upon open-source LLMs. First, we develop a robust pipeline to synthesize test cases for patch evaluation. Second, we scale up agent trajectories to construct the training data for building SWE-Dev. Experiments on the SWE-bench-Verified benchmark show that the SWE-Dev models can achieve top performance among all open SWE agents. Specifically, the success rates of the SWE-Dev 7B and 32B parameter models reach 23.4% and 36.6%, respectively, outperforming state-of-the-art open-source models. All code, models, and datasets are publicly available at https://github.com/THUDM/SWE-Dev.",
    "categories": [
      "cs.AI"
    ],
    "primary_category": "cs.AI",
    "comment": "Accepted to Findings of ACL'25",
    "pdf_url": "https://arxiv.org/pdf/2506.07636v2",
    "published_date": "2025-06-09 11:03:16 UTC",
    "updated_date": "2025-06-23 01:00:06 UTC"
  },
  {
    "arxiv_id": "2506.07621v1",
    "title": "LoRMA: Low-Rank Multiplicative Adaptation for LLMs",
    "authors": [
      "Harsh Bihany",
      "Shubham Patel",
      "Ashutosh Modi"
    ],
    "abstract": "Large Language Models have shown remarkable capabilities in the NLP domain. Their effectiveness can mainly be attributed to their ability to adapt to an array of downstream tasks. However, generally, full fine-tuning is a computationally expensive job. To mitigate this, many techniques have been developed that prime efficiency, a prominent one being Low-Rank Adaptation (LoRA). However, LoRA and its variants employ re-parametrized additive updates. In this paper, we propose Low-Rank Multiplicative Adaptation (LoRMA), which shifts the paradigm of additive updates to a richer space of matrix multiplicative transformations. We tackle challenges such as computational complexity and rank bottleneck of matrix multiplication by effectively re-ordering operations and introducing rank inflation strategies. We conduct extensive experiments to demonstrate the effectiveness of our approach in terms of various evaluation metrics.",
    "categories": [
      "cs.CL",
      "cs.AI",
      "cs.LG"
    ],
    "primary_category": "cs.CL",
    "comment": "Accepted at ACL Findings 2025; 21 pages (9 main paper + 5 pages references + 7 pages appendix)",
    "pdf_url": "https://arxiv.org/pdf/2506.07621v1",
    "published_date": "2025-06-09 10:36:46 UTC",
    "updated_date": "2025-06-09 10:36:46 UTC"
  },
  {
    "arxiv_id": "2506.07606v1",
    "title": "PolitiSky24: U.S. Political Bluesky Dataset with User Stance Labels",
    "authors": [
      "Peyman Rostami",
      "Vahid Rahimzadeh",
      "Ali Adibi",
      "Azadeh Shakery"
    ],
    "abstract": "Stance detection identifies the viewpoint expressed in text toward a specific target, such as a political figure. While previous datasets have focused primarily on tweet-level stances from established platforms, user-level stance resources, especially on emerging platforms like Bluesky remain scarce. User-level stance detection provides a more holistic view by considering a user's complete posting history rather than isolated posts. We present the first stance detection dataset for the 2024 U.S. presidential election, collected from Bluesky and centered on Kamala Harris and Donald Trump. The dataset comprises 16,044 user-target stance pairs enriched with engagement metadata, interaction graphs, and user posting histories. PolitiSky24 was created using a carefully evaluated pipeline combining advanced information retrieval and large language models, which generates stance labels with supporting rationales and text spans for transparency. The labeling approach achieves 81\\% accuracy with scalable LLMs. This resource addresses gaps in political stance analysis through its timeliness, open-data nature, and user-level perspective. The dataset is available at https://doi.org/10.5281/zenodo.15616911",
    "categories": [
      "cs.CL",
      "cs.AI",
      "cs.IR",
      "cs.SI"
    ],
    "primary_category": "cs.CL",
    "comment": "The dataset is available at https://doi.org/10.5281/zenodo.15616911",
    "pdf_url": "https://arxiv.org/pdf/2506.07606v1",
    "published_date": "2025-06-09 10:06:25 UTC",
    "updated_date": "2025-06-09 10:06:25 UTC"
  },
  {
    "arxiv_id": "2506.07603v2",
    "title": "SurgBench: A Unified Large-Scale Benchmark for Surgical Video Analysis",
    "authors": [
      "Jianhui Wei",
      "Zikai Xiao",
      "Danyu Sun",
      "Luqi Gong",
      "Zongxin Yang",
      "Zuozhu Liu",
      "Jian Wu"
    ],
    "abstract": "Surgical video understanding is pivotal for enabling automated intraoperative decision-making, skill assessment, and postoperative quality improvement. However, progress in developing surgical video foundation models (FMs) remains hindered by the scarcity of large-scale, diverse datasets for pretraining and systematic evaluation. In this paper, we introduce \\textbf{SurgBench}, a unified surgical video benchmarking framework comprising a pretraining dataset, \\textbf{SurgBench-P}, and an evaluation benchmark, \\textbf{SurgBench-E}. SurgBench offers extensive coverage of diverse surgical scenarios, with SurgBench-P encompassing 53 million frames across 22 surgical procedures and 11 specialties, and SurgBench-E providing robust evaluation across six categories (phase classification, camera motion, tool recognition, disease diagnosis, action classification, and organ detection) spanning 72 fine-grained tasks. Extensive experiments reveal that existing video FMs struggle to generalize across varied surgical video analysis tasks, whereas pretraining on SurgBench-P yields substantial performance improvements and superior cross-domain generalization to unseen procedures and modalities. Our dataset and code are available upon request.",
    "categories": [
      "cs.CV",
      "cs.AI"
    ],
    "primary_category": "cs.CV",
    "comment": "",
    "pdf_url": "https://arxiv.org/pdf/2506.07603v2",
    "published_date": "2025-06-09 10:02:58 UTC",
    "updated_date": "2025-06-16 03:31:25 UTC"
  },
  {
    "arxiv_id": "2506.07600v1",
    "title": "SceneRAG: Scene-level Retrieval-Augmented Generation for Video Understanding",
    "authors": [
      "Nianbo Zeng",
      "Haowen Hou",
      "Fei Richard Yu",
      "Si Shi",
      "Ying Tiffany He"
    ],
    "abstract": "Despite recent advances in retrieval-augmented generation (RAG) for video understanding, effectively understanding long-form video content remains underexplored due to the vast scale and high complexity of video data. Current RAG approaches typically segment videos into fixed-length chunks, which often disrupts the continuity of contextual information and fails to capture authentic scene boundaries. Inspired by the human ability to naturally organize continuous experiences into coherent scenes, we present SceneRAG, a unified framework that leverages large language models to segment videos into narrative-consistent scenes by processing ASR transcripts alongside temporal metadata. SceneRAG further sharpens these initial boundaries through lightweight heuristics and iterative correction. For each scene, the framework fuses information from both visual and textual modalities to extract entity relations and dynamically builds a knowledge graph, enabling robust multi-hop retrieval and generation that account for long-range dependencies. Experiments on the LongerVideos benchmark, featuring over 134 hours of diverse content, confirm that SceneRAG substantially outperforms prior baselines, achieving a win rate of up to 72.5 percent on generation tasks.",
    "categories": [
      "cs.CV",
      "cs.AI"
    ],
    "primary_category": "cs.CV",
    "comment": "",
    "pdf_url": "https://arxiv.org/pdf/2506.07600v1",
    "published_date": "2025-06-09 10:00:54 UTC",
    "updated_date": "2025-06-09 10:00:54 UTC"
  },
  {
    "arxiv_id": "2506.07591v1",
    "title": "Automating Exploratory Multiomics Research via Language Models",
    "authors": [
      "Shang Qu",
      "Ning Ding",
      "Linhai Xie",
      "Yifei Li",
      "Zaoqu Liu",
      "Kaiyan Zhang",
      "Yibai Xiong",
      "Yuxin Zuo",
      "Zhangren Chen",
      "Ermo Hua",
      "Xingtai Lv",
      "Youbang Sun",
      "Yang Li",
      "Dong Li",
      "Fuchu He",
      "Bowen Zhou"
    ],
    "abstract": "This paper introduces PROTEUS, a fully automated system that produces data-driven hypotheses from raw data files. We apply PROTEUS to clinical proteogenomics, a field where effective downstream data analysis and hypothesis proposal is crucial for producing novel discoveries. PROTEUS uses separate modules to simulate different stages of the scientific process, from open-ended data exploration to specific statistical analysis and hypothesis proposal. It formulates research directions, tools, and results in terms of relationships between biological entities, using unified graph structures to manage complex research processes. We applied PROTEUS to 10 clinical multiomics datasets from published research, arriving at 360 total hypotheses. Results were evaluated through external data validation and automatic open-ended scoring. Through exploratory and iterative research, the system can navigate high-throughput and heterogeneous multiomics data to arrive at hypotheses that balance reliability and novelty. In addition to accelerating multiomic analysis, PROTEUS represents a path towards tailoring general autonomous systems to specialized scientific domains to achieve open-ended hypothesis generation from data.",
    "categories": [
      "cs.AI",
      "q-bio.QM"
    ],
    "primary_category": "cs.AI",
    "comment": "",
    "pdf_url": "https://arxiv.org/pdf/2506.07591v1",
    "published_date": "2025-06-09 09:44:21 UTC",
    "updated_date": "2025-06-09 09:44:21 UTC"
  },
  {
    "arxiv_id": "2506.08062v2",
    "title": "FairDICE: Fairness-Driven Offline Multi-Objective Reinforcement Learning",
    "authors": [
      "Woosung Kim",
      "Jinho Lee",
      "Jongmin Lee",
      "Byung-Jun Lee"
    ],
    "abstract": "Multi-objective reinforcement learning (MORL) aims to optimize policies in the presence of conflicting objectives, where linear scalarization is commonly used to reduce vector-valued returns into scalar signals. While effective for certain preferences, this approach cannot capture fairness-oriented goals such as Nash social welfare or max-min fairness, which require nonlinear and non-additive trade-offs. Although several online algorithms have been proposed for specific fairness objectives, a unified approach for optimizing nonlinear welfare criteria in the offline setting-where learning must proceed from a fixed dataset-remains unexplored. In this work, we present FairDICE, the first offline MORL framework that directly optimizes nonlinear welfare objective. FairDICE leverages distribution correction estimation to jointly account for welfare maximization and distributional regularization, enabling stable and sample-efficient learning without requiring explicit preference weights or exhaustive weight search. Across multiple offline benchmarks, FairDICE demonstrates strong fairness-aware performance compared to existing baselines.",
    "categories": [
      "cs.LG",
      "cs.AI"
    ],
    "primary_category": "cs.LG",
    "comment": "Multi-objective Reinforcement Learning",
    "pdf_url": "https://arxiv.org/pdf/2506.08062v2",
    "published_date": "2025-06-09 09:40:11 UTC",
    "updated_date": "2025-11-18 05:22:56 UTC"
  },
  {
    "arxiv_id": "2506.07587v1",
    "title": "PrunePEFT: Iterative Hybrid Pruning for Parameter-Efficient Fine-tuning of LLMs",
    "authors": [
      "Tongzhou Yu",
      "Zhuhao Zhang",
      "Guanghui Zhu",
      "Shen Jiang",
      "Meikang Qiu",
      "Yihua Huang"
    ],
    "abstract": "Parameter Efficient Fine-Tuning (PEFT) methods have emerged as effective and promising approaches for fine-tuning pre-trained language models. Compared with Full parameter Fine-Tuning (FFT), PEFT achieved comparable task performance with a substantial reduction of trainable parameters, which largely saved the training and storage costs. However, using the PEFT method requires considering a vast design space, such as the type of PEFT modules and their insertion layers. Inadequate configurations can lead to sub-optimal results. Conventional solutions such as architectural search techniques, while effective, tend to introduce substantial additional overhead. In this paper, we propose a novel approach, PrunePEFT, which formulates the PEFT strategy search as a pruning problem and introduces a hybrid pruning strategy that capitalizes on the sensitivity of pruning methods to different PEFT modules. This method extends traditional pruning techniques by iteratively removing redundant or conflicting PEFT modules, thereby optimizing the fine-tuned configuration. By efficiently identifying the most relevant modules, our approach significantly reduces the computational burden typically associated with architectural search processes, making it a more scalable and efficient solution for fine-tuning large pre-trained models.",
    "categories": [
      "cs.LG",
      "cs.AI"
    ],
    "primary_category": "cs.LG",
    "comment": "",
    "pdf_url": "https://arxiv.org/pdf/2506.07587v1",
    "published_date": "2025-06-09 09:32:58 UTC",
    "updated_date": "2025-06-09 09:32:58 UTC"
  },
  {
    "arxiv_id": "2506.07583v1",
    "title": "Beyond the Sentence: A Survey on Context-Aware Machine Translation with Large Language Models",
    "authors": [
      "Ramakrishna Appicharla",
      "Baban Gain",
      "Santanu Pal",
      "Asif Ekbal"
    ],
    "abstract": "Despite the popularity of the large language models (LLMs), their application to machine translation is relatively underexplored, especially in context-aware settings. This work presents a literature review of context-aware translation with LLMs. The existing works utilise prompting and fine-tuning approaches, with few focusing on automatic post-editing and creating translation agents for context-aware machine translation. We observed that the commercial LLMs (such as ChatGPT and Tower LLM) achieved better results than the open-source LLMs (such as Llama and Bloom LLMs), and prompt-based approaches serve as good baselines to assess the quality of translations. Finally, we present some interesting future directions to explore.",
    "categories": [
      "cs.CL",
      "cs.AI"
    ],
    "primary_category": "cs.CL",
    "comment": "",
    "pdf_url": "https://arxiv.org/pdf/2506.07583v1",
    "published_date": "2025-06-09 09:27:00 UTC",
    "updated_date": "2025-06-09 09:27:00 UTC"
  },
  {
    "arxiv_id": "2506.07581v1",
    "title": "FedCGD: Collective Gradient Divergence Optimized Scheduling for Wireless Federated Learning",
    "authors": [
      "Tan Chen",
      "Jintao Yan",
      "Yuxuan Sun",
      "Sheng Zhou",
      "Zhisheng Niu"
    ],
    "abstract": "Federated learning (FL) is a promising paradigm for multiple devices to cooperatively train a model. When applied in wireless networks, two issues consistently affect the performance of FL, i.e., data heterogeneity of devices and limited bandwidth. Many papers have investigated device scheduling strategies considering the two issues. However, most of them recognize data heterogeneity as a property of individual devices. In this paper, we prove that the convergence speed of FL is affected by the sum of device-level and sample-level collective gradient divergence (CGD). The device-level CGD refers to the gradient divergence of the scheduled device group, instead of the sum of the individual device divergence. The sample-level CGD is statistically upper bounded by sampling variance, which is inversely proportional to the total number of samples scheduled for local update. To derive a tractable form of the device-level CGD, we further consider a classification problem and transform it into the weighted earth moving distance (WEMD) between the group distribution and the global distribution. Then we propose FedCGD algorithm to minimize the sum of multi-level CGDs by balancing WEMD and sampling variance, within polynomial time. Simulation shows that the proposed strategy increases classification accuracy on the CIFAR-10 dataset by up to 4.2\\% while scheduling 41.8\\% fewer devices, and flexibly switches between reducing WEMD and reducing sampling variance.",
    "categories": [
      "cs.LG",
      "cs.AI",
      "cs.DC"
    ],
    "primary_category": "cs.LG",
    "comment": "",
    "pdf_url": "https://arxiv.org/pdf/2506.07581v1",
    "published_date": "2025-06-09 09:24:33 UTC",
    "updated_date": "2025-06-09 09:24:33 UTC"
  },
  {
    "arxiv_id": "2506.07578v3",
    "title": "Denoising the Future: Top-p Distributions for Moving Through Time",
    "authors": [
      "Florian Andreas Marwitz",
      "Ralf Möller",
      "Magnus Bender",
      "Marcel Gehrke"
    ],
    "abstract": "Inference in dynamic probabilistic models is a complex task involving expensive operations. In particular, for Hidden Markov Models, the whole state space has to be enumerated for advancing in time. Even states with negligible probabilities are considered, resulting in computational inefficiency and increased noise due to the propagation of unlikely probability mass. We propose to denoise the future and speed up inference by using only the top-p states, i.e., the most probable states with accumulated probability p. We show that the error introduced by using only the top-p states is bound by p and the so-called minimal mixing rate of the underlying model. Moreover, in our empirical evaluation, we show that we can expect speedups of at least an order of magnitude, while the error in terms of total variation distance is below 0.09.",
    "categories": [
      "cs.LG",
      "cs.AI"
    ],
    "primary_category": "cs.LG",
    "comment": "Accepted at ECSQARU 2025",
    "pdf_url": "https://arxiv.org/pdf/2506.07578v3",
    "published_date": "2025-06-09 09:23:09 UTC",
    "updated_date": "2025-10-21 12:18:34 UTC"
  },
  {
    "arxiv_id": "2506.07570v2",
    "title": "OptiScene: LLM-driven Indoor Scene Layout Generation via Scaled Human-aligned Data Synthesis and Multi-Stage Preference Optimization",
    "authors": [
      "Yixuan Yang",
      "Zhen Luo",
      "Tongsheng Ding",
      "Junru Lu",
      "Mingqi Gao",
      "Jinyu Yang",
      "Victor Sanchez",
      "Feng Zheng"
    ],
    "abstract": "Automatic indoor layout generation has attracted increasing attention due to its potential in interior design, virtual environment construction, and embodied AI. Existing methods fall into two categories: prompt-driven approaches that leverage proprietary LLM services (e.g., GPT APIs) and learning-based methods trained on layout data upon diffusion-based models. Prompt-driven methods often suffer from spatial inconsistency and high computational costs, while learning-based methods are typically constrained by coarse relational graphs and limited datasets, restricting their generalization to diverse room categories. In this paper, we revisit LLM-based indoor layout generation and present 3D-SynthPlace, a large-scale dataset that combines synthetic layouts generated via a 'GPT synthesize, Human inspect' pipeline, upgraded from the 3D-Front dataset. 3D-SynthPlace contains nearly 17,000 scenes, covering four common room types -- bedroom, living room, kitchen, and bathroom -- enriched with diverse objects and high-level spatial annotations. We further introduce OptiScene, a strong open-source LLM optimized for indoor layout generation, fine-tuned based on our 3D-SynthPlace dataset through our two-stage training. For the warum-up stage I, we adopt supervised fine-tuning (SFT), which is taught to first generate high-level spatial descriptions then conditionally predict concrete object placements. For the reinforcing stage II, to better align the generated layouts with human design preferences, we apply multi-turn direct preference optimization (DPO), which significantly improving layout quality and generation success rates. Extensive experiments demonstrate that OptiScene outperforms traditional prompt-driven and learning-based baselines. Moreover, OptiScene shows promising potential in interactive tasks such as scene editing and robot navigation.",
    "categories": [
      "cs.CV",
      "cs.AI"
    ],
    "primary_category": "cs.CV",
    "comment": "",
    "pdf_url": "https://arxiv.org/pdf/2506.07570v2",
    "published_date": "2025-06-09 09:13:06 UTC",
    "updated_date": "2025-09-19 09:25:25 UTC"
  },
  {
    "arxiv_id": "2506.07564v3",
    "title": "SAFEFLOW: A Principled Protocol for Trustworthy and Transactional Autonomous Agent Systems",
    "authors": [
      "Peiran Li",
      "Xinkai Zou",
      "Zhuohang Wu",
      "Ruifeng Li",
      "Shuo Xing",
      "Hanwen Zheng",
      "Zhikai Hu",
      "Yuping Wang",
      "Haoxi Li",
      "Qin Yuan",
      "Yingmo Zhang",
      "Zhengzhong Tu"
    ],
    "abstract": "Recent advances in large language models (LLMs) and vision-language models (VLMs) have enabled powerful autonomous agents capable of complex reasoning and multi-modal tool use. Despite their growing capabilities, today's agent frameworks remain fragile, lacking principled mechanisms for secure information flow, reliability, and multi-agent coordination. In this work, we introduce SAFEFLOW, a new protocol-level framework for building trustworthy LLM/VLM-based agents. SAFEFLOW enforces fine-grained information flow control (IFC), precisely tracking provenance, integrity, and confidentiality of all the data exchanged between agents, tools, users, and environments. By constraining LLM reasoning to respect these security labels, SAFEFLOW prevents untrusted or adversarial inputs from contaminating high-integrity decisions. To ensure robustness in concurrent multi-agent settings, SAFEFLOW introduces transactional execution, conflict resolution, and secure scheduling over shared state, preserving global consistency across agents. We further introduce mechanisms, including write-ahead logging, rollback, and secure caches, that further enhance resilience against runtime errors and policy violations. To validate the performances, we built SAFEFLOWBENCH, a comprehensive benchmark suite designed to evaluate agent reliability under adversarial, noisy, and concurrent operational conditions. Extensive experiments demonstrate that agents built with SAFEFLOW maintain impressive task performance and security guarantees even in hostile environments, substantially outperforming state-of-the-art. Together, SAFEFLOW and SAFEFLOWBENCH lay the groundwork for principled, robust, and secure agent ecosystems, advancing the frontier of reliable autonomy.",
    "categories": [
      "cs.AI",
      "cs.CL"
    ],
    "primary_category": "cs.AI",
    "comment": "Former versions either contain unrelated content or cannot be properly converted to PDF",
    "pdf_url": "https://arxiv.org/pdf/2506.07564v3",
    "published_date": "2025-06-09 09:04:37 UTC",
    "updated_date": "2025-06-11 03:14:10 UTC"
  },
  {
    "arxiv_id": "2506.07563v3",
    "title": "MoE-MLoRA for Multi-Domain CTR Prediction: Efficient Adaptation with Expert Specialization",
    "authors": [
      "Ken Yaggel",
      "Eyal German",
      "Aviel Ben Siman Tov"
    ],
    "abstract": "Personalized recommendation systems must adapt to user interactions across different domains. Traditional approaches like MLoRA apply a single adaptation per domain but lack flexibility in handling diverse user behaviors. To address this, we propose MoE-MLoRA, a mixture-of-experts framework where each expert is first trained independently to specialize in its domain before a gating network is trained to weight their contributions dynamically. We evaluate MoE-MLoRA across eight CTR models on Movielens and Taobao, showing that it improves performance in large-scale, dynamic datasets (+1.45 Weighed-AUC in Taobao-20) but offers limited benefits in structured datasets with low domain diversity and sparsity. Further analysis of the number of experts per domain reveals that larger ensembles do not always improve performance, indicating the need for model-aware tuning. Our findings highlight the potential of expert-based architectures for multi-domain recommendation systems, demonstrating that task-aware specialization and adaptive gating can enhance predictive accuracy in complex environments. The implementation and code are available in our GitHub repository.",
    "categories": [
      "cs.IR",
      "cs.AI"
    ],
    "primary_category": "cs.IR",
    "comment": "",
    "pdf_url": "https://arxiv.org/pdf/2506.07563v3",
    "published_date": "2025-06-09 09:03:05 UTC",
    "updated_date": "2025-06-11 07:55:32 UTC"
  },
  {
    "arxiv_id": "2506.07557v1",
    "title": "SELT: Self-Evaluation Tree Search for LLMs with Task Decomposition",
    "authors": [
      "Mengsong Wu",
      "Di Zhang",
      "Yuqiang Li",
      "Dongzhan Zhou",
      "Wenliang Chen"
    ],
    "abstract": "While Large Language Models (LLMs) have achieved remarkable success in a wide range of applications, their performance often degrades in complex reasoning tasks. In this work, we introduce SELT (Self-Evaluation LLM Tree Search), a novel framework that leverages a modified Monte Carlo Tree Search (MCTS) to enhance LLM reasoning without relying on external reward models. By redefining the Upper Confidence Bound scoring to align with intrinsic self-evaluation capabilities of LLMs and decomposing the inference process into atomic subtasks augmented with semantic clustering at each node, SELT effectively balances exploration and exploitation, reduces redundant reasoning paths, and mitigates hallucination. We validate our approach on challenging benchmarks, including the knowledge-based MMLU and the Tool Learning dataset Seal-Tools, where SELT achieves significant improvements in answer accuracy and reasoning robustness compared to baseline methods. Notably, our framework operates without task-specific fine-tuning, demonstrating strong generalizability across diverse reasoning tasks. Relevant results and code are available at https://github.com/fairyshine/SELT .",
    "categories": [
      "cs.CL",
      "cs.AI"
    ],
    "primary_category": "cs.CL",
    "comment": "11 pages, 5 figures",
    "pdf_url": "https://arxiv.org/pdf/2506.07557v1",
    "published_date": "2025-06-09 08:52:27 UTC",
    "updated_date": "2025-06-09 08:52:27 UTC"
  },
  {
    "arxiv_id": "2506.07555v3",
    "title": "Synthesize Privacy-Preserving High-Resolution Images via Private Textual Intermediaries",
    "authors": [
      "Haoxiang Wang",
      "Zinan Lin",
      "Da Yu",
      "Huishuai Zhang"
    ],
    "abstract": "Generating high fidelity, differentially private (DP) synthetic images offers a promising route to share and analyze sensitive visual data without compromising individual privacy. However, existing DP image synthesis methods struggle to produce high resolution outputs that faithfully capture the structure of the original data. In this paper, we introduce a novel method, referred to as Synthesis via Private Textual Intermediaries (SPTI), that can generate high resolution DP images with easy adoption. The key idea is to shift the challenge of DP image synthesis from the image domain to the text domain by leveraging state of the art DP text generation methods. SPTI first summarizes each private image into a concise textual description using image to text models, then applies a modified Private Evolution algorithm to generate DP text, and finally reconstructs images using text to image models. Notably, SPTI requires no model training, only inference with off the shelf models. Given a private dataset, SPTI produces synthetic images of substantially higher quality than prior DP approaches. On the LSUN Bedroom dataset, SPTI attains an FID equal to 26.71 under epsilon equal to 1.0, improving over Private Evolution FID of 40.36. Similarly, on MM CelebA HQ, SPTI achieves an FID equal to 33.27 at epsilon equal to 1.0, compared to 57.01 from DP fine tuning baselines. Overall, our results demonstrate that Synthesis via Private Textual Intermediaries provides a resource efficient and proprietary model compatible framework for generating high resolution DP synthetic images, greatly expanding access to private visual datasets.",
    "categories": [
      "cs.CV",
      "cs.AI"
    ],
    "primary_category": "cs.CV",
    "comment": "",
    "pdf_url": "https://arxiv.org/pdf/2506.07555v3",
    "published_date": "2025-06-09 08:48:06 UTC",
    "updated_date": "2025-10-27 16:44:01 UTC"
  },
  {
    "arxiv_id": "2506.07553v3",
    "title": "GTR-CoT: Graph Traversal as Visual Chain of Thought for Molecular Structure Recognition",
    "authors": [
      "Jingchao Wang",
      "Yifan He",
      "Haote Yang",
      "Jiang Wu",
      "Lingli Ge",
      "Xingjian Wei",
      "Yinfan Wang",
      "Linye Li",
      "Huijie Ao",
      "Chengjin Liu",
      "Bin Wang",
      "Lijun Wu",
      "Conghui He"
    ],
    "abstract": "Optical Chemical Structure Recognition (OCSR) is essential for converting molecular images into machine-readable formats. While recent vision-language models (VLMs) have shown promise, their image-captioning approach often struggles with complex molecular structures and inconsistent annotations. To address these issues, we introduce GTR-VL, featuring two key innovations: (1) the \\textit{Graph Traversal as Visual Chain of Thought} mechanism that emulates human reasoning by incrementally parsing molecular graphs through sequential atom-bond predictions, and (2) the data-centric \\textit{Faithfully Recognize What You've Seen} principle, which aligns abbreviated structures in images with their expanded annotations. For hand-drawn OCSR tasks, where datasets lack graph annotations and only provide final SMILES, we apply reinforcement learning using the GRPO method, introducing reward mechanisms like format reward, graph reward, and SMILES reward. This approach significantly enhances performance in hand-drawn recognition tasks through weak supervision. We developed GTR-1.3M, a large-scale instruction-tuning dataset with corrected annotations, and MolRec-Bench, the first benchmark for fine-grained evaluation of graph-parsing accuracy in OCSR. Our two-stage training scheme involves SFT training for printed images and the GRPO method for transferring capabilities to hand-drawn tasks. Experiments show that GTR-VL outperforms specialist models, chemistry-domain VLMs, and commercial VLMs on both printed and hand-drawn datasets.",
    "categories": [
      "cs.AI",
      "q-bio.QM"
    ],
    "primary_category": "cs.AI",
    "comment": "",
    "pdf_url": "https://arxiv.org/pdf/2506.07553v3",
    "published_date": "2025-06-09 08:47:10 UTC",
    "updated_date": "2026-01-13 07:21:42 UTC"
  },
  {
    "arxiv_id": "2506.07551v2",
    "title": "CheMatAgent: Enhancing LLMs for Chemistry and Materials Science through Tree-Search Based Tool Learning",
    "authors": [
      "Mengsong Wu",
      "YaFei Wang",
      "Yidong Ming",
      "Yuqi An",
      "Yuwei Wan",
      "Wenliang Chen",
      "Binbin Lin",
      "Yuqiang Li",
      "Tong Xie",
      "Dongzhan Zhou"
    ],
    "abstract": "Large language models (LLMs) have recently demonstrated promising capabilities in chemistry tasks while still facing challenges due to outdated pretraining knowledge and the difficulty of incorporating specialized chemical expertise. To address these issues, we propose an LLM-based agent that synergistically integrates 137 external chemical tools created ranging from basic information retrieval to complex reaction predictions, and a dataset curation pipeline to generate the dataset ChemToolBench that facilitates both effective tool selection and precise parameter filling during fine-tuning and evaluation. We introduce a Hierarchical Evolutionary Monte Carlo Tree Search (HE-MCTS) framework, enabling independent optimization of tool planning and execution. By leveraging self-generated data, our approach supports step-level fine-tuning (FT) of the policy model and training task-adaptive PRM and ORM that surpass GPT-4o. Experimental evaluations demonstrate that our approach significantly improves performance in Chemistry QA and discovery tasks, offering a robust solution to integrate specialized tools with LLMs for advanced chemical applications. All datasets and code are available at https://github.com/AI4Chem/ChemistryAgent .",
    "categories": [
      "cs.LG",
      "cs.AI",
      "cs.CE",
      "cs.CL"
    ],
    "primary_category": "cs.LG",
    "comment": "15 pages, 6 figures",
    "pdf_url": "https://arxiv.org/pdf/2506.07551v2",
    "published_date": "2025-06-09 08:41:39 UTC",
    "updated_date": "2025-06-12 07:30:27 UTC"
  },
  {
    "arxiv_id": "2506.07548v1",
    "title": "Curriculum Learning With Counterfactual Group Relative Policy Advantage For Multi-Agent Reinforcement Learning",
    "authors": [
      "Weiqiang Jin",
      "Hongyang Du",
      "Guizhong Liu",
      "Dong In Kim"
    ],
    "abstract": "Multi-agent reinforcement learning (MARL) has achieved strong performance in cooperative adversarial tasks. However, most existing methods typically train agents against fixed opponent strategies and rely on such meta-static difficulty conditions, which limits their adaptability to changing environments and often leads to suboptimal policies. Inspired by the success of curriculum learning (CL) in supervised tasks, we propose a dynamic CL framework for MARL that employs an self-adaptive difficulty adjustment mechanism. This mechanism continuously modulates opponent strength based on real-time agent training performance, allowing agents to progressively learn from easier to more challenging scenarios. However, the dynamic nature of CL introduces instability due to nonstationary environments and sparse global rewards. To address this challenge, we develop a Counterfactual Group Relative Policy Advantage (CGRPA), which is tightly coupled with the curriculum by providing intrinsic credit signals that reflect each agent's impact under evolving task demands. CGRPA constructs a counterfactual advantage function that isolates individual contributions within group behavior, facilitating more reliable policy updates throughout the curriculum. CGRPA evaluates each agent's contribution through constructing counterfactual action advantage function, providing intrinsic rewards that enhance credit assignment and stabilize learning under non-stationary conditions. Extensive experiments demonstrate that our method improves both training stability and final performance, achieving competitive results against state-of-the-art methods. The code is available at https://github.com/NICE-HKU/CL2MARL-SMAC.",
    "categories": [
      "cs.AI",
      "cs.RO"
    ],
    "primary_category": "cs.AI",
    "comment": "16 pages; 12figures",
    "pdf_url": "https://arxiv.org/pdf/2506.07548v1",
    "published_date": "2025-06-09 08:38:18 UTC",
    "updated_date": "2025-06-09 08:38:18 UTC"
  },
  {
    "arxiv_id": "2506.08060v1",
    "title": "Eliciting Fine-Tuned Transformer Capabilities via Inference-Time Techniques",
    "authors": [
      "Asankhaya Sharma"
    ],
    "abstract": "Large language models have transformed natural language processing, yet supervised fine-tuning (SFT) remains computationally intensive. This paper formally proves that capabilities acquired through SFT can be approximated by a base transformer model using inference-time techniques, specifically in-context learning (ICL), without altering model parameters, under idealized assumptions including unbounded computational resources and access to the fine-tuning dataset. We extend these results to practical scenarios with finite context lengths and partial dataset access. For text generation tasks with fixed output length $l$, datasets of size $\\mathrm{O}\\left( \\frac{m V}{\\varepsilon^2} \\log \\frac{m}δ \\right)$ or, with bounded context, $\\mathrm{O}\\left( \\frac{l \\log V}{\\varepsilon^2} \\log \\frac{1}δ \\right)$ suffice to approximate fine-tuned behavior across $m$ contexts within error $\\varepsilon$, where $V$ is the vocabulary size and $δ$ is the failure probability. For linear classification, datasets of size $\\mathrm{O}\\left( \\frac{d}{\\varepsilon} \\right)$ or, with fixed context, $\\mathrm{O}\\left( \\frac{1}{\\varepsilon^2} \\log \\frac{1}δ \\right)$ are sufficient, where $d$ is the input dimension. Grounded in the Turing completeness of transformers, these results provide a theoretical foundation for resource-efficient deployment of large language models, with practical techniques like retrieval-augmented generation bridging theory to real-world applications.",
    "categories": [
      "cs.LG",
      "cs.AI"
    ],
    "primary_category": "cs.LG",
    "comment": "",
    "pdf_url": "https://arxiv.org/pdf/2506.08060v1",
    "published_date": "2025-06-09 08:37:19 UTC",
    "updated_date": "2025-06-09 08:37:19 UTC"
  },
  {
    "arxiv_id": "2506.07542v1",
    "title": "APTOS-2024 challenge report: Generation of synthetic 3D OCT images from fundus photographs",
    "authors": [
      "Bowen Liu",
      "Weiyi Zhang",
      "Peranut Chotcomwongse",
      "Xiaolan Chen",
      "Ruoyu Chen",
      "Pawin Pakaymaskul",
      "Niracha Arjkongharn",
      "Nattaporn Vongsa",
      "Xuelian Cheng",
      "Zongyuan Ge",
      "Kun Huang",
      "Xiaohui Li",
      "Yiru Duan",
      "Zhenbang Wang",
      "BaoYe Xie",
      "Qiang Chen",
      "Huazhu Fu",
      "Michael A. Mahr",
      "Jiaqi Qu",
      "Wangyiyang Chen",
      "Shiye Wang",
      "Yubo Tan",
      "Yongjie Li",
      "Mingguang He",
      "Danli Shi",
      "Paisan Ruamviboonsuk"
    ],
    "abstract": "Optical Coherence Tomography (OCT) provides high-resolution, 3D, and non-invasive visualization of retinal layers in vivo, serving as a critical tool for lesion localization and disease diagnosis. However, its widespread adoption is limited by equipment costs and the need for specialized operators. In comparison, 2D color fundus photography offers faster acquisition and greater accessibility with less dependence on expensive devices. Although generative artificial intelligence has demonstrated promising results in medical image synthesis, translating 2D fundus images into 3D OCT images presents unique challenges due to inherent differences in data dimensionality and biological information between modalities. To advance generative models in the fundus-to-3D-OCT setting, the Asia Pacific Tele-Ophthalmology Society (APTOS-2024) organized a challenge titled Artificial Intelligence-based OCT Generation from Fundus Images. This paper details the challenge framework (referred to as APTOS-2024 Challenge), including: the benchmark dataset, evaluation methodology featuring two fidelity metrics-image-based distance (pixel-level OCT B-scan similarity) and video-based distance (semantic-level volumetric consistency), and analysis of top-performing solutions. The challenge attracted 342 participating teams, with 42 preliminary submissions and 9 finalists. Leading methodologies incorporated innovations in hybrid data preprocessing or augmentation (cross-modality collaborative paradigms), pre-training on external ophthalmic imaging datasets, integration of vision foundation models, and model architecture improvement. The APTOS-2024 Challenge is the first benchmark demonstrating the feasibility of fundus-to-3D-OCT synthesis as a potential solution for improving ophthalmic care accessibility in under-resourced healthcare settings, while helping to expedite medical research and clinical applications.",
    "categories": [
      "cs.CV",
      "cs.AI"
    ],
    "primary_category": "cs.CV",
    "comment": "",
    "pdf_url": "https://arxiv.org/pdf/2506.07542v1",
    "published_date": "2025-06-09 08:29:37 UTC",
    "updated_date": "2025-06-09 08:29:37 UTC"
  },
  {
    "arxiv_id": "2506.07539v1",
    "title": "Domain Randomization for Object Detection in Manufacturing Applications using Synthetic Data: A Comprehensive Study",
    "authors": [
      "Xiaomeng Zhu",
      "Jacob Henningsson",
      "Duruo Li",
      "Pär Mårtensson",
      "Lars Hanson",
      "Mårten Björkman",
      "Atsuto Maki"
    ],
    "abstract": "This paper addresses key aspects of domain randomization in generating synthetic data for manufacturing object detection applications. To this end, we present a comprehensive data generation pipeline that reflects different factors: object characteristics, background, illumination, camera settings, and post-processing. We also introduce the Synthetic Industrial Parts Object Detection dataset (SIP15-OD) consisting of 15 objects from three industrial use cases under varying environments as a test bed for the study, while also employing an industrial dataset publicly available for robotic applications. In our experiments, we present more abundant results and insights into the feasibility as well as challenges of sim-to-real object detection. In particular, we identified material properties, rendering methods, post-processing, and distractors as important factors. Our method, leveraging these, achieves top performance on the public dataset with Yolov8 models trained exclusively on synthetic data; mAP@50 scores of 96.4% for the robotics dataset, and 94.1%, 99.5%, and 95.3% across three of the SIP15-OD use cases, respectively. The results showcase the effectiveness of the proposed domain randomization, potentially covering the distribution close to real data for the applications.",
    "categories": [
      "cs.CV",
      "cs.AI"
    ],
    "primary_category": "cs.CV",
    "comment": "This is accepted by 2025 IEEE International Conference on Robotics & Automation (ICRA), waiting for publication. 14 pages, 14 figures",
    "pdf_url": "https://arxiv.org/pdf/2506.07539v1",
    "published_date": "2025-06-09 08:26:19 UTC",
    "updated_date": "2025-06-09 08:26:19 UTC"
  },
  {
    "arxiv_id": "2506.07528v2",
    "title": "Coordinating Search-Informed Reasoning and Reasoning-Guided Search in Claim Verification",
    "authors": [
      "Qisheng Hu",
      "Quanyu Long",
      "Wenya Wang"
    ],
    "abstract": "Multi-hop claim verification is inherently challenging, requiring multi-step reasoning to construct verification chains while iteratively searching for information to uncover hidden bridging facts. This process is fundamentally interleaved, as effective reasoning relies on dynamically retrieved evidence, while effective search demands reasoning to refine queries based on partial information. To achieve this, we propose Hierarchical Agent Reasoning and Information Search (HARIS), explicitly modeling the coordinated process of reasoning-driven searching and search-informed reasoning. HARIS consists of a high-level reasoning agent that focuses on constructing the main verification chain, generating factual questions when more information is needed, and a low-level search agent that iteratively retrieves more information, refining its search based on intermediate findings. This design allows each agent to specialize in its respective task, enhancing verification accuracy and interpretability. HARIS is trained using reinforcement learning with outcome-based rewards. Experimental results on the EX-FEVER and HOVER benchmarks demonstrate that HARIS achieves strong performance, greatly advancing multi-hop claim verification.",
    "categories": [
      "cs.AI"
    ],
    "primary_category": "cs.AI",
    "comment": "Work in progress",
    "pdf_url": "https://arxiv.org/pdf/2506.07528v2",
    "published_date": "2025-06-09 08:11:43 UTC",
    "updated_date": "2025-07-31 17:12:54 UTC"
  },
  {
    "arxiv_id": "2506.07527v2",
    "title": "Learning What Reinforcement Learning Can't: Interleaved Online Fine-Tuning for Hardest Questions",
    "authors": [
      "Lu Ma",
      "Hao Liang",
      "Meiyi Qiang",
      "Lexiang Tang",
      "Xiaochen Ma",
      "Zhen Hao Wong",
      "Junbo Niu",
      "Chengyu Shen",
      "Runming He",
      "Yanhao Li",
      "Bin Cui",
      "Wentao Zhang"
    ],
    "abstract": "Recent advances in large language model (LLM) reasoning have shown that sophisticated behaviors such as planning and self-reflection can emerge through reinforcement learning (RL). However, despite these successes, RL in its current form remains insufficient to induce capabilities that exceed the limitations of the base model, as it is primarily optimized based on existing knowledge of the model rather than facilitating the acquisition of new information. To address this limitation, we employ supervised fine-tuning (SFT) to learn what RL cannot, which enables the incorporation of new knowledge and reasoning patterns by leveraging high-quality demonstration data. We analyze the training dynamics of RL and SFT for LLM reasoning and find that RL excels at maintaining and improving performance on questions within the model's original capabilities, while SFT is more effective at enabling progress on questions beyond the current scope of the model. Motivated by the complementary strengths of RL and SFT, we introduce a novel training approach, \\textbf{ReLIFT} (\\textbf{Re}inforcement \\textbf{L}earning \\textbf{I}nterleaved with Online \\textbf{F}ine-\\textbf{T}uning). In ReLIFT, the model is primarily trained using RL, but when it encounters challenging questions, high-quality solutions are collected for fine-tuning, and the training process alternates between RL and fine-tuning to enhance the model's reasoning abilities. ReLIFT achieves an average improvement of over +5.2 points across five competition-level benchmarks and one out-of-distribution benchmark compared to other zero-RL models. Furthermore, we demonstrate that ReLIFT outperforms both RL and SFT while using only 13\\% of the detailed demonstration data, highlighting its scalability. These results provide compelling evidence that ReLIFT overcomes the fundamental limitations of RL and underscores the significant potential.",
    "categories": [
      "cs.AI",
      "cs.LG"
    ],
    "primary_category": "cs.AI",
    "comment": "12 pages, 5 figures",
    "pdf_url": "https://arxiv.org/pdf/2506.07527v2",
    "published_date": "2025-06-09 08:11:20 UTC",
    "updated_date": "2025-10-04 04:07:04 UTC"
  },
  {
    "arxiv_id": "2506.07524v3",
    "title": "TAI3: Testing Agent Integrity in Interpreting User Intent",
    "authors": [
      "Shiwei Feng",
      "Xiangzhe Xu",
      "Xuan Chen",
      "Kaiyuan Zhang",
      "Syed Yusuf Ahmed",
      "Zian Su",
      "Mingwei Zheng",
      "Xiangyu Zhang"
    ],
    "abstract": "LLM agents are increasingly deployed to automate real-world tasks by invoking APIs through natural language instructions. While powerful, they often suffer from misinterpretation of user intent, leading to the agent's actions that diverge from the user's intended goal, especially as external toolkits evolve. Traditional software testing assumes structured inputs and thus falls short in handling the ambiguity of natural language. We introduce TAI3, an API-centric stress testing framework that systematically uncovers intent integrity violations in LLM agents. Unlike prior work focused on fixed benchmarks or adversarial inputs, TAI3 generates realistic tasks based on toolkits' documentation and applies targeted mutations to expose subtle agent errors while preserving user intent. To guide testing, we propose semantic partitioning, which organizes natural language tasks into meaningful categories based on toolkit API parameters and their equivalence classes. Within each partition, seed tasks are mutated and ranked by a lightweight predictor that estimates the likelihood of triggering agent errors. To enhance efficiency, TAI3 maintains a datatype-aware strategy memory that retrieves and adapts effective mutation patterns from past cases. Experiments on 80 toolkit APIs demonstrate that TAI3 effectively uncovers intent integrity violations, significantly outperforming baselines in both error-exposing rate and query efficiency. Moreover, TAI3 generalizes well to stronger target models using smaller LLMs for test generation, and adapts to evolving APIs across domains.",
    "categories": [
      "cs.SE",
      "cs.AI",
      "cs.CY"
    ],
    "primary_category": "cs.SE",
    "comment": "Accepted to NeurIPS 2025",
    "pdf_url": "https://arxiv.org/pdf/2506.07524v3",
    "published_date": "2025-06-09 08:09:08 UTC",
    "updated_date": "2025-10-23 21:47:44 UTC"
  },
  {
    "arxiv_id": "2506.07520v3",
    "title": "LeVo: High-Quality Song Generation with Multi-Preference Alignment",
    "authors": [
      "Shun Lei",
      "Yaoxun Xu",
      "Zhiwei Lin",
      "Huaicheng Zhang",
      "Wei Tan",
      "Hangting Chen",
      "Jianwei Yu",
      "Yixuan Zhang",
      "Chenyu Yang",
      "Haina Zhu",
      "Shuai Wang",
      "Zhiyong Wu",
      "Dong Yu"
    ],
    "abstract": "Recent advances in large language models (LLMs) and audio language models have significantly improved music generation, particularly in lyrics-to-song generation. However, existing approaches still struggle with the complex composition of songs and the scarcity of high-quality data, leading to limitations in audio quality, musicality, instruction following, and vocal-instrument harmony. To address these challenges, we introduce LeVo, a language model based framework consisting of LeLM and Music Codec. LeLM is capable of parallel modeling of two types of tokens: mixed tokens, which represent the combined audio of vocals and accompaniment to achieve better vocal-instrument harmony, and dual-track tokens, which separately encode vocals and accompaniment for high-quality song generation. It employs two decoder-only transformers and a modular extension training strategy to prevent interference between different token types. To further enhance musicality and instruction following ability, we introduce a multi-preference alignment method based on Direct Preference Optimization (DPO). This method handles diverse human preferences through a semi-automatic data construction process and post-training. Experimental results demonstrate that LeVo significantly outperforms existing open-source methods in both objective and subjective metrics, while performing competitively with industry systems. Ablation studies further justify the effectiveness of our designs. Audio examples and source code are available at https://levo-demo.github.io and https://github.com/tencent-ailab/songgeneration.",
    "categories": [
      "cs.SD",
      "cs.AI",
      "eess.AS"
    ],
    "primary_category": "cs.SD",
    "comment": "Accepted by NeurIPS 2025",
    "pdf_url": "https://arxiv.org/pdf/2506.07520v3",
    "published_date": "2025-06-09 07:57:24 UTC",
    "updated_date": "2025-10-23 12:07:37 UTC"
  },
  {
    "arxiv_id": "2506.09070v1",
    "title": "STREAMINGGS: Voxel-Based Streaming 3D Gaussian Splatting with Memory Optimization and Architectural Support",
    "authors": [
      "Chenqi Zhang",
      "Yu Feng",
      "Jieru Zhao",
      "Guangda Liu",
      "Wenchao Ding",
      "Chentao Wu",
      "Minyi Guo"
    ],
    "abstract": "3D Gaussian Splatting (3DGS) has gained popularity for its efficiency and sparse Gaussian-based representation. However, 3DGS struggles to meet the real-time requirement of 90 frames per second (FPS) on resource-constrained mobile devices, achieving only 2 to 9 FPS.Existing accelerators focus on compute efficiency but overlook memory efficiency, leading to redundant DRAM traffic. We introduce STREAMINGGS, a fully streaming 3DGS algorithm-architecture co-design that achieves fine-grained pipelining and reduces DRAM traffic by transforming from a tile-centric rendering to a memory-centric rendering. Results show that our design achieves up to 45.7 $\\times$ speedup and 62.9 $\\times$ energy savings over mobile Ampere GPUs.",
    "categories": [
      "cs.GR",
      "cs.AI"
    ],
    "primary_category": "cs.GR",
    "comment": "",
    "pdf_url": "https://arxiv.org/pdf/2506.09070v1",
    "published_date": "2025-06-09 07:51:34 UTC",
    "updated_date": "2025-06-09 07:51:34 UTC"
  },
  {
    "arxiv_id": "2506.07505v1",
    "title": "Reinforcement Learning via Implicit Imitation Guidance",
    "authors": [
      "Perry Dong",
      "Alec M. Lessing",
      "Annie S. Chen",
      "Chelsea Finn"
    ],
    "abstract": "We study the problem of sample efficient reinforcement learning, where prior data such as demonstrations are provided for initialization in lieu of a dense reward signal. A natural approach is to incorporate an imitation learning objective, either as regularization during training or to acquire a reference policy. However, imitation learning objectives can ultimately degrade long-term performance, as it does not directly align with reward maximization. In this work, we propose to use prior data solely for guiding exploration via noise added to the policy, sidestepping the need for explicit behavior cloning constraints. The key insight in our framework, Data-Guided Noise (DGN), is that demonstrations are most useful for identifying which actions should be explored, rather than forcing the policy to take certain actions. Our approach achieves up to 2-3x improvement over prior reinforcement learning from offline data methods across seven simulated continuous control tasks.",
    "categories": [
      "cs.LG",
      "cs.AI"
    ],
    "primary_category": "cs.LG",
    "comment": "",
    "pdf_url": "https://arxiv.org/pdf/2506.07505v1",
    "published_date": "2025-06-09 07:32:52 UTC",
    "updated_date": "2025-06-09 07:32:52 UTC"
  },
  {
    "arxiv_id": "2506.08059v1",
    "title": "CaliciBoost: Performance-Driven Evaluation of Molecular Representations for Caco-2 Permeability Prediction",
    "authors": [
      "Huong Van Le",
      "Weibin Ren",
      "Junhong Kim",
      "Yukyung Yun",
      "Young Bin Park",
      "Young Jun Kim",
      "Bok Kyung Han",
      "Inho Choi",
      "Jong IL Park",
      "Hwi-Yeol Yun",
      "Jae-Mun Choi"
    ],
    "abstract": "Caco-2 permeability serves as a critical in vitro indicator for predicting the oral absorption of drug candidates during early-stage drug discovery. To enhance the accuracy and efficiency of computational predictions, we systematically investigated the impact of eight molecular feature representation types including 2D/3D descriptors, structural fingerprints, and deep learning-based embeddings combined with automated machine learning techniques to predict Caco-2 permeability. Using two datasets of differing scale and diversity (TDC benchmark and curated OCHEM data), we assessed model performance across representations and identified PaDEL, Mordred, and RDKit descriptors as particularly effective for Caco-2 prediction. Notably, the AutoML-based model CaliciBoost achieved the best MAE performance. Furthermore, for both PaDEL and Mordred representations, the incorporation of 3D descriptors resulted in a 15.73% reduction in MAE compared to using 2D features alone, as confirmed by feature importance analysis. These findings highlight the effectiveness of AutoML approaches in ADMET modeling and offer practical guidance for feature selection in data-limited prediction tasks.",
    "categories": [
      "q-bio.QM",
      "cs.AI",
      "cs.LG"
    ],
    "primary_category": "q-bio.QM",
    "comment": "49 pages, 11 figures",
    "pdf_url": "https://arxiv.org/pdf/2506.08059v1",
    "published_date": "2025-06-09 07:30:28 UTC",
    "updated_date": "2025-06-09 07:30:28 UTC"
  },
  {
    "arxiv_id": "2506.07501v1",
    "title": "Graph-of-Causal Evolution: Challenging Chain-of-Model for Reasoning",
    "authors": [
      "Libo Wang"
    ],
    "abstract": "In view of the problem that each subchain in the chain-of-model (CoM) relies only on the information of the previous subchain and may lose long-range dependencies due to the causal mask blocking the global context flow between multi-level subchains, this work proposes a graph of causal evolution (GoCE). Its core principle is to map the implicit token representation into a differentiable and sparse causal adjacency matrix, then permeate causal constraints through each layer of calculation using causal-masked attention and causal-MoE. By combining intervention consistency loss test and self-evolution gate, the dynamic balance between causal structure learning and adaptive updating of transformer architecture is realized. The researcher built experimental environments in sandboxes built with Claude Sonnet 4, o4-mini-high, and DeepSeek R1 respectively with the transformer variant architecture introduced in GoCE. It is evaluated on publicly available datasets including CLUTRR, CLADDER, EX-FEVER, and CausalQA and compared with the baseline LLMs. The finding proves that GoCE strengthens the transformer's ability to capture long-range causal dependencies, while the ability to self-evolve is improved. It not only surpasses the design of CoM in terms of design principles, but also provides experience for future research on causal learning and continuous adaptive improvement.",
    "categories": [
      "cs.LG",
      "cs.AI",
      "cs.CL"
    ],
    "primary_category": "cs.LG",
    "comment": "The relevant code has been uploaded to the publicly available GitHub repository. The link is: https://github.com/brucewang123456789/GeniusTrail/tree/main/GoCE",
    "pdf_url": "https://arxiv.org/pdf/2506.07501v1",
    "published_date": "2025-06-09 07:26:47 UTC",
    "updated_date": "2025-06-09 07:26:47 UTC"
  },
  {
    "arxiv_id": "2506.07484v1",
    "title": "CoCoA-Mix: Confusion-and-Confidence-Aware Mixture Model for Context Optimization",
    "authors": [
      "Dasol Hong",
      "Wooju Lee",
      "Hyun Myung"
    ],
    "abstract": "Prompt tuning, which adapts vision-language models by freezing model parameters and optimizing only the prompt, has proven effective for task-specific adaptations. The core challenge in prompt tuning is improving specialization for a specific task and generalization for unseen domains. However, frozen encoders often produce misaligned features, leading to confusion between classes and limiting specialization. To overcome this issue, we propose a confusion-aware loss (CoA-loss) that improves specialization by refining the decision boundaries between confusing classes. Additionally, we mathematically demonstrate that a mixture model can enhance generalization without compromising specialization. This is achieved using confidence-aware weights (CoA-weights), which adjust the weights of each prediction in the mixture model based on its confidence within the class domains. Extensive experiments show that CoCoA-Mix, a mixture model with CoA-loss and CoA-weights, outperforms state-of-the-art methods by enhancing specialization and generalization. Our code is publicly available at https://github.com/url-kaist/CoCoA-Mix.",
    "categories": [
      "cs.CV",
      "cs.AI",
      "cs.LG"
    ],
    "primary_category": "cs.CV",
    "comment": "8 pages, 5 figures; accepted at ICML 2025",
    "pdf_url": "https://arxiv.org/pdf/2506.07484v1",
    "published_date": "2025-06-09 07:04:47 UTC",
    "updated_date": "2025-06-09 07:04:47 UTC"
  },
  {
    "arxiv_id": "2506.07477v1",
    "title": "Premise Selection for a Lean Hammer",
    "authors": [
      "Thomas Zhu",
      "Joshua Clune",
      "Jeremy Avigad",
      "Albert Qiaochu Jiang",
      "Sean Welleck"
    ],
    "abstract": "Neural methods are transforming automated reasoning for proof assistants, yet integrating these advances into practical verification workflows remains challenging. Hammers are tools that interface with external automatic theorem provers to automate tedious reasoning steps. They have dramatically improved productivity in proof assistants, but the Lean proof assistant still does not have a hammer despite its growing popularity. We present LeanHammer, the first end-to-end domain-general hammer for Lean, built on a novel neural premise selection system for a hammer in dependent type theory. Unlike existing Lean premise selectors, our approach dynamically adapts to user-specific contexts and combines with symbolic proof search and reconstruction to create a practical hammer. With comprehensive evaluations, we show that our premise selector enables LeanHammer to solve 21\\% more goals relative to existing premise selectors, and generalize well to diverse domains. Our work bridges the gap between neural retrieval and symbolic reasoning, making formal verification more accessible to researchers and practitioners.",
    "categories": [
      "cs.LG",
      "cs.AI",
      "cs.LO"
    ],
    "primary_category": "cs.LG",
    "comment": "LeanHammer is available at https://github.com/JOSHCLUNE/LeanHammer",
    "pdf_url": "https://arxiv.org/pdf/2506.07477v1",
    "published_date": "2025-06-09 06:50:59 UTC",
    "updated_date": "2025-06-09 06:50:59 UTC"
  },
  {
    "arxiv_id": "2506.07471v1",
    "title": "Ambiguity-Restrained Text-Video Representation Learning for Partially Relevant Video Retrieval",
    "authors": [
      "CH Cho",
      "WJ Moon",
      "W Jun",
      "MS Jung",
      "JP Heo"
    ],
    "abstract": "Partially Relevant Video Retrieval~(PRVR) aims to retrieve a video where a specific segment is relevant to a given text query. Typical training processes of PRVR assume a one-to-one relationship where each text query is relevant to only one video. However, we point out the inherent ambiguity between text and video content based on their conceptual scope and propose a framework that incorporates this ambiguity into the model learning process. Specifically, we propose Ambiguity-Restrained representation Learning~(ARL) to address ambiguous text-video pairs. Initially, ARL detects ambiguous pairs based on two criteria: uncertainty and similarity. Uncertainty represents whether instances include commonly shared context across the dataset, while similarity indicates pair-wise semantic overlap. Then, with the detected ambiguous pairs, our ARL hierarchically learns the semantic relationship via multi-positive contrastive learning and dual triplet margin loss. Additionally, we delve into fine-grained relationships within the video instances. Unlike typical training at the text-video level, where pairwise information is provided, we address the inherent ambiguity within frames of the same untrimmed video, which often contains multiple contexts. This allows us to further enhance learning at the text-frame level. Lastly, we propose cross-model ambiguity detection to mitigate the error propagation that occurs when a single model is employed to detect ambiguous pairs for its training. With all components combined, our proposed method demonstrates its effectiveness in PRVR.",
    "categories": [
      "cs.CV",
      "cs.AI"
    ],
    "primary_category": "cs.CV",
    "comment": "Accepted to AAAI 2025",
    "pdf_url": "https://arxiv.org/pdf/2506.07471v1",
    "published_date": "2025-06-09 06:44:45 UTC",
    "updated_date": "2025-06-09 06:44:45 UTC"
  },
  {
    "arxiv_id": "2507.21071v1",
    "title": "FingerTip 20K: A Benchmark for Proactive and Personalized Mobile LLM Agents",
    "authors": [
      "Qinglong Yang",
      "Haoming Li",
      "Haotian Zhao",
      "Xiaokai Yan",
      "Jingtao Ding",
      "Fengli Xu",
      "Yong Li"
    ],
    "abstract": "Mobile GUI agents are becoming critical tools for enhancing human-device interaction efficiency, with multimodal large language models (MLLMs) emerging as dominant paradigms in this domain. Current agents, however, are limited to following explicit human instructions, resulting in insufficient capability for proactive intent anticipation. Additionally, these agents fail to leverage the contextual information associated with users during task execution, thereby neglecting potentially vast differences in user preferences. To address these challenges, we introduce the FingerTip benchmark. It contains two new tracks: proactive task suggestions by analyzing environment observation and users' previous intents, and personalized task execution by catering to users' action preferences. We collected unique human demonstrations of multi-step Android device interactions across a variety of everyday apps. These demonstrations are not isolated but are continuously acquired from the users' long-term usage in their real lives, and encompass essential user-related contextual information. Our experiments reveal challenges of the tasks we propose. The model fine-tuned with the data we collected effectively utilized user information and achieved good results, highlighting the potential of our approach in building more user-oriented mobile GUI agents. Our code is open-source at https://anonymous.4open.science/r/FingerTip-57B8 for reproducibility.",
    "categories": [
      "cs.HC",
      "cs.AI"
    ],
    "primary_category": "cs.HC",
    "comment": "",
    "pdf_url": "https://arxiv.org/pdf/2507.21071v1",
    "published_date": "2025-06-09 06:38:41 UTC",
    "updated_date": "2025-06-09 06:38:41 UTC"
  },
  {
    "arxiv_id": "2506.11116v1",
    "title": "Infinity Instruct: Scaling Instruction Selection and Synthesis to Enhance Language Models",
    "authors": [
      "Jijie Li",
      "Li Du",
      "Hanyu Zhao",
      "Bo-wen Zhang",
      "Liangdong Wang",
      "Boyan Gao",
      "Guang Liu",
      "Yonghua Lin"
    ],
    "abstract": "Large Language Models (LLMs) demonstrate strong performance in real-world applications, yet existing open-source instruction datasets often concentrate on narrow domains, such as mathematics or coding, limiting generalization and widening the gap with proprietary models. To bridge this gap, we introduce Infinity-Instruct, a high-quality instruction dataset designed to enhance both foundational and chat capabilities of LLMs through a two-phase pipeline. In Phase 1, we curate 7.4M high-quality foundational instructions (InfInstruct-F-7.4M) from over 100M samples using hybrid data selection techniques. In Phase 2, we synthesize 1.5M high-quality chat instructions (InfInstruct-G-1.5M) through a two-stage process involving instruction selection, evolution, and diagnostic filtering. We empirically evaluate Infinity-Instruct by fine-tuning several open-source models, including Mistral, LLaMA, Qwen, and Yi, and observe substantial performance gains across both foundational and instruction following benchmarks, consistently surpassing official instruction-tuned counterparts. Notably, InfInstruct-LLaMA3.1-70B outperforms GPT-4-0314 by 8.6\\% on instruction following tasks while achieving comparable foundational performance. These results underscore the synergy between foundational and chat training and offer new insights into holistic LLM development. Our dataset\\footnote{https://huggingface.co/datasets/BAAI/Infinity-Instruct} and codes\\footnote{https://gitee.com/li-touch/infinity-instruct} have been publicly released.",
    "categories": [
      "cs.CL",
      "cs.AI"
    ],
    "primary_category": "cs.CL",
    "comment": "",
    "pdf_url": "https://arxiv.org/pdf/2506.11116v1",
    "published_date": "2025-06-09 06:37:15 UTC",
    "updated_date": "2025-06-09 06:37:15 UTC"
  },
  {
    "arxiv_id": "2506.13777v1",
    "title": "A Survey of Physics-Informed AI for Complex Urban Systems",
    "authors": [
      "En Xu",
      "Huandong Wang",
      "Yunke Zhang",
      "Sibo Li",
      "Yinzhou Tang",
      "Zhilun Zhou",
      "Yuming Lin",
      "Yuan Yuan",
      "Xiaochen Fan",
      "Jingtao Ding",
      "Yong Li"
    ],
    "abstract": "Urban systems are typical examples of complex systems, where the integration of physics-based modeling with artificial intelligence (AI) presents a promising paradigm for enhancing predictive accuracy, interpretability, and decision-making. In this context, AI excels at capturing complex, nonlinear relationships, while physics-based models ensure consistency with real-world laws and provide interpretable insights. We provide a comprehensive review of physics-informed AI methods in urban applications. The proposed taxonomy categorizes existing approaches into three paradigms - Physics-Integrated AI, Physics-AI Hybrid Ensemble, and AI-Integrated Physics - and further details seven representative methods. This classification clarifies the varying degrees and directions of physics-AI integration, guiding the selection and development of appropriate methods based on application needs and data availability. We systematically examine their applications across eight key urban domains: energy, environment, economy, transportation, information, public services, emergency management, and the urban system as a whole. Our analysis highlights how these methodologies leverage physical laws and data-driven models to address urban challenges, enhancing system reliability, efficiency, and adaptability. By synthesizing existing methodologies and their urban applications, we identify critical gaps and outline future research directions, paving the way toward next-generation intelligent urban system modeling.",
    "categories": [
      "physics.soc-ph",
      "cs.AI",
      "cs.CY"
    ],
    "primary_category": "physics.soc-ph",
    "comment": "",
    "pdf_url": "https://arxiv.org/pdf/2506.13777v1",
    "published_date": "2025-06-09 06:19:14 UTC",
    "updated_date": "2025-06-09 06:19:14 UTC"
  },
  {
    "arxiv_id": "2506.07464v4",
    "title": "DeepVideo-R1: Video Reinforcement Fine-Tuning via Difficulty-aware Regressive GRPO",
    "authors": [
      "Jinyoung Park",
      "Jeehye Na",
      "Jinyoung Kim",
      "Hyunwoo J. Kim"
    ],
    "abstract": "Recent works have demonstrated the effectiveness of reinforcement learning (RL)-based post-training for enhancing the reasoning capabilities of large language models (LLMs). In particular, Group Relative Policy Optimization (GRPO) has shown impressive success using a PPO-style reinforcement algorithm with group-normalized rewards. However, the effectiveness of GRPO in Video Large Language Models (VideoLLMs) has still been less studyed. In this paper, we explore GRPO and identify two problems that deteriorate the effective learning: (1) reliance on safeguards, and (2) vanishing advantage. To mitigate these challenges, we propose DeepVideo-R1, a video large language model trained with Reg-GRPO (Regressive GRPO) and difficulty-aware data augmentation. Reg-GRPO reformulates the GRPO loss function into a regression task that directly predicts the advantage in GRPO, eliminating the need for safeguards such as the clipping and min functions. It directly aligns the model with advantages, providing guidance to prefer better ones. The difficulty-aware data augmentation strategy augments input prompts/videos to locate the difficulty of samples at solvable difficulty levels, enabling diverse reward signals. Our experimental results show that our approach significantly improves video reasoning performance across multiple benchmarks.",
    "categories": [
      "cs.CV",
      "cs.AI"
    ],
    "primary_category": "cs.CV",
    "comment": "NeurIPS 2025",
    "pdf_url": "https://arxiv.org/pdf/2506.07464v4",
    "published_date": "2025-06-09 06:15:54 UTC",
    "updated_date": "2025-10-31 12:13:12 UTC"
  },
  {
    "arxiv_id": "2506.07463v1",
    "title": "CCI4.0: A Bilingual Pretraining Dataset for Enhancing Reasoning in Large Language Models",
    "authors": [
      "Guang Liu",
      "Liangdong Wang",
      "Jijie Li",
      "Yang Yu",
      "Yao Xu",
      "Jiabei Chen",
      "Yu Bai",
      "Feng Liao",
      "Yonghua Lin"
    ],
    "abstract": "We introduce CCI4.0, a large-scale bilingual pre-training dataset engineered for superior data quality and diverse human-like reasoning trajectory. CCI4.0 occupies roughly $35$ TB of disk space and comprises two sub-datasets: CCI4.0-M2-Base and CCI4.0-M2-CoT. CCI4.0-M2-Base combines a $5.2$ TB carefully curated Chinese web corpus, a $22.5$ TB English subset from Nemotron-CC, and diverse sources from math, wiki, arxiv, and code. Although these data are mostly sourced from well-processed datasets, the quality standards of various domains are dynamic and require extensive expert experience and labor to process. So, we propose a novel pipeline justifying data quality mainly based on models through two-stage deduplication, multiclassifier quality scoring, and domain-aware fluency filtering. We extract $4.5$ billion pieces of CoT(Chain-of-Thought) templates, named CCI4.0-M2-CoT. Differing from the distillation of CoT from larger models, our proposed staged CoT extraction exemplifies diverse reasoning patterns and significantly decreases the possibility of hallucination. Empirical evaluations demonstrate that LLMs pre-trained in CCI4.0 benefit from cleaner, more reliable training signals, yielding consistent improvements in downstream tasks, especially in math and code reflection tasks. Our results underscore the critical role of rigorous data curation and human thinking templates in advancing LLM performance, shedding some light on automatically processing pretraining corpora.",
    "categories": [
      "cs.CL",
      "cs.AI"
    ],
    "primary_category": "cs.CL",
    "comment": "",
    "pdf_url": "https://arxiv.org/pdf/2506.07463v1",
    "published_date": "2025-06-09 06:14:19 UTC",
    "updated_date": "2025-06-09 06:14:19 UTC"
  },
  {
    "arxiv_id": "2506.07458v2",
    "title": "KScope: A Framework for Characterizing the Knowledge Status of Language Models",
    "authors": [
      "Yuxin Xiao",
      "Shan Chen",
      "Jack Gallifant",
      "Danielle Bitterman",
      "Thomas Hartvigsen",
      "Marzyeh Ghassemi"
    ],
    "abstract": "Characterizing a large language model's (LLM's) knowledge of a given question is challenging. As a result, prior work has primarily examined LLM behavior under knowledge conflicts, where the model's internal parametric memory contradicts information in the external context. However, this does not fully reflect how well the model knows the answer to the question. In this paper, we first introduce a taxonomy of five knowledge statuses based on the consistency and correctness of LLM knowledge modes. We then propose KScope, a hierarchical framework of statistical tests that progressively refines hypotheses about knowledge modes and characterizes LLM knowledge into one of these five statuses. We apply KScope to nine LLMs across four datasets and systematically establish: (1) Supporting context narrows knowledge gaps across models. (2) Context features related to difficulty, relevance, and familiarity drive successful knowledge updates. (3) LLMs exhibit similar feature preferences when partially correct or conflicted, but diverge sharply when consistently wrong. (4) Context summarization constrained by our feature analysis, together with enhanced credibility, further improves update effectiveness and generalizes across LLMs.",
    "categories": [
      "cs.CL",
      "cs.AI",
      "cs.LG"
    ],
    "primary_category": "cs.CL",
    "comment": "Accepted by NeurIPS 2025",
    "pdf_url": "https://arxiv.org/pdf/2506.07458v2",
    "published_date": "2025-06-09 06:06:05 UTC",
    "updated_date": "2025-10-16 06:05:43 UTC"
  },
  {
    "arxiv_id": "2506.07454v2",
    "title": "Language-Grounded Hierarchical Planning and Execution with Multi-Robot 3D Scene Graphs",
    "authors": [
      "Jared Strader",
      "Aaron Ray",
      "Jacob Arkin",
      "Mason B. Peterson",
      "Yun Chang",
      "Nathan Hughes",
      "Christopher Bradley",
      "Yi Xuan Jia",
      "Carlos Nieto-Granda",
      "Rajat Talak",
      "Chuchu Fan",
      "Luca Carlone",
      "Jonathan P. How",
      "Nicholas Roy"
    ],
    "abstract": "In this paper, we introduce a multi-robot system that integrates mapping, localization, and task and motion planning (TAMP) enabled by 3D scene graphs to execute complex instructions expressed in natural language. Our system builds a shared 3D scene graph incorporating an open-set object-based map, which is leveraged for multi-robot 3D scene graph fusion. This representation supports real-time, view-invariant relocalization (via the object-based map) and planning (via the 3D scene graph), allowing a team of robots to reason about their surroundings and execute complex tasks. Additionally, we introduce a planning approach that translates operator intent into Planning Domain Definition Language (PDDL) goals using a Large Language Model (LLM) by leveraging context from the shared 3D scene graph and robot capabilities. We provide an experimental assessment of the performance of our system on real-world tasks in large-scale, outdoor environments. A supplementary video is available at https://youtu.be/8xbGGOLfLAY.",
    "categories": [
      "cs.RO",
      "cs.AI"
    ],
    "primary_category": "cs.RO",
    "comment": "12 pages, 4 figures, 4 tables",
    "pdf_url": "https://arxiv.org/pdf/2506.07454v2",
    "published_date": "2025-06-09 06:02:34 UTC",
    "updated_date": "2025-07-10 23:26:07 UTC"
  },
  {
    "arxiv_id": "2506.07452v2",
    "title": "When Style Breaks Safety: Defending LLMs Against Superficial Style Alignment",
    "authors": [
      "Yuxin Xiao",
      "Sana Tonekaboni",
      "Walter Gerych",
      "Vinith Suriyakumar",
      "Marzyeh Ghassemi"
    ],
    "abstract": "Large language models (LLMs) can be prompted with specific styles (e.g., formatting responses as lists), including in malicious queries. Prior jailbreak research mainly augments these queries with additional string transformations to maximize attack success rate (ASR). However, the impact of style patterns in the original queries that are semantically irrelevant to the malicious intent remains unclear. In this work, we seek to understand whether style patterns compromise LLM safety, how superficial style alignment increases model vulnerability, and how best to mitigate these risks during alignment. We first define ASR inflation as the increase in ASR due to style patterns in existing jailbreak benchmark queries. By evaluating 32 LLMs across seven benchmarks, we find that nearly all models exhibit ASR inflation. Notably, the inflation correlates with an LLM's relative attention to style patterns, which also overlap more with its instruction-tuning data when inflation occurs. We then investigate superficial style alignment, and find that fine-tuning with specific styles makes LLMs more vulnerable to jailbreaks of those same styles. Finally, we propose SafeStyle, a defense strategy that incorporates a small amount of safety training data augmented to match the distribution of style patterns in the fine-tuning data. Across three LLMs, six fine-tuning style settings, and two real-world instruction-tuning datasets, SafeStyle consistently outperforms baselines in maintaining LLM safety.",
    "categories": [
      "cs.LG",
      "cs.AI",
      "cs.CL",
      "cs.CY"
    ],
    "primary_category": "cs.LG",
    "comment": "",
    "pdf_url": "https://arxiv.org/pdf/2506.07452v2",
    "published_date": "2025-06-09 05:57:39 UTC",
    "updated_date": "2025-10-16 06:50:23 UTC"
  },
  {
    "arxiv_id": "2506.07450v1",
    "title": "Efficient Generation of Diverse Cooperative Agents with World Models",
    "authors": [
      "Yi Loo",
      "Akshunn Trivedi",
      "Malika Meghjani"
    ],
    "abstract": "A major bottleneck in the training process for Zero-Shot Coordination (ZSC) agents is the generation of partner agents that are diverse in collaborative conventions. Current Cross-play Minimization (XPM) methods for population generation can be very computationally expensive and sample inefficient as the training objective requires sampling multiple types of trajectories. Each partner agent in the population is also trained from scratch, despite all of the partners in the population learning policies of the same coordination task. In this work, we propose that simulated trajectories from the dynamics model of an environment can drastically speed up the training process for XPM methods. We introduce XPM-WM, a framework for generating simulated trajectories for XPM via a learned World Model (WM). We show XPM with simulated trajectories removes the need to sample multiple trajectories. In addition, we show our proposed method can effectively generate partners with diverse conventions that match the performance of previous methods in terms of SP population training reward as well as training partners for ZSC agents. Our method is thus, significantly more sample efficient and scalable to a larger number of partners.",
    "categories": [
      "cs.AI"
    ],
    "primary_category": "cs.AI",
    "comment": "",
    "pdf_url": "https://arxiv.org/pdf/2506.07450v1",
    "published_date": "2025-06-09 05:52:45 UTC",
    "updated_date": "2025-06-09 05:52:45 UTC"
  },
  {
    "arxiv_id": "2506.07448v1",
    "title": "Extending Epistemic Uncertainty Beyond Parameters Would Assist in Designing Reliable LLMs",
    "authors": [
      "T. Duy Nguyen-Hien",
      "Desi R. Ivanova",
      "Yee Whye Teh",
      "Wee Sun Lee"
    ],
    "abstract": "Although large language models (LLMs) are highly interactive and extendable, current approaches to ensure reliability in deployments remain mostly limited to rejecting outputs with high uncertainty in order to avoid misinformation. This conservative strategy reflects the current lack of tools to systematically distinguish and respond to different sources of uncertainty. In this paper, we advocate for the adoption of Bayesian Modeling of Experiments -- a framework that provides a coherent foundation to reason about uncertainty and clarify the reducibility of uncertainty -- for managing and proactively addressing uncertainty that arises in LLM deployments. This framework enables LLMs and their users to take contextually appropriate steps, such as requesting clarification, retrieving external information, or refining inputs. By supporting active resolution rather than passive avoidance, it opens the door to more reliable, transparent, and broadly applicable LLM systems, particularly in high-stakes, real-world settings.",
    "categories": [
      "cs.LG",
      "cs.AI"
    ],
    "primary_category": "cs.LG",
    "comment": "",
    "pdf_url": "https://arxiv.org/pdf/2506.07448v1",
    "published_date": "2025-06-09 05:52:03 UTC",
    "updated_date": "2025-06-09 05:52:03 UTC"
  },
  {
    "arxiv_id": "2506.07449v1",
    "title": "LlamaRec-LKG-RAG: A Single-Pass, Learnable Knowledge Graph-RAG Framework for LLM-Based Ranking",
    "authors": [
      "Vahid Azizi",
      "Fatemeh Koochaki"
    ],
    "abstract": "Recent advances in Large Language Models (LLMs) have driven their adoption in recommender systems through Retrieval-Augmented Generation (RAG) frameworks. However, existing RAG approaches predominantly rely on flat, similarity-based retrieval that fails to leverage the rich relational structure inherent in user-item interactions. We introduce LlamaRec-LKG-RAG, a novel single-pass, end-to-end trainable framework that integrates personalized knowledge graph context into LLM-based recommendation ranking. Our approach extends the LlamaRec architecture by incorporating a lightweight user preference module that dynamically identifies salient relation paths within a heterogeneous knowledge graph constructed from user behavior and item metadata. These personalized subgraphs are seamlessly integrated into prompts for a fine-tuned Llama-2 model, enabling efficient and interpretable recommendations through a unified inference step. Comprehensive experiments on ML-100K and Amazon Beauty datasets demonstrate consistent and significant improvements over LlamaRec across key ranking metrics (MRR, NDCG, Recall). LlamaRec-LKG-RAG demonstrates the critical value of structured reasoning in LLM-based recommendations and establishes a foundation for scalable, knowledge-aware personalization in next-generation recommender systems. Code is available at~\\href{https://github.com/VahidAz/LlamaRec-LKG-RAG}{repository}.",
    "categories": [
      "cs.IR",
      "cs.AI",
      "cs.CL"
    ],
    "primary_category": "cs.IR",
    "comment": "",
    "pdf_url": "https://arxiv.org/pdf/2506.07449v1",
    "published_date": "2025-06-09 05:52:03 UTC",
    "updated_date": "2025-06-09 05:52:03 UTC"
  },
  {
    "arxiv_id": "2506.07446v1",
    "title": "Fact in Fragments: Deconstructing Complex Claims via LLM-based Atomic Fact Extraction and Verification",
    "authors": [
      "Liwen Zheng",
      "Chaozhuo Li",
      "Zheng Liu",
      "Feiran Huang",
      "Haoran Jia",
      "Zaisheng Ye",
      "Xi Zhang"
    ],
    "abstract": "Fact verification plays a vital role in combating misinformation by assessing the veracity of claims through evidence retrieval and reasoning. However, traditional methods struggle with complex claims requiring multi-hop reasoning over fragmented evidence, as they often rely on static decomposition strategies and surface-level semantic retrieval, which fail to capture the nuanced structure and intent of the claim. This results in accumulated reasoning errors, noisy evidence contamination, and limited adaptability to diverse claims, ultimately undermining verification accuracy in complex scenarios. To address this, we propose Atomic Fact Extraction and Verification (AFEV), a novel framework that iteratively decomposes complex claims into atomic facts, enabling fine-grained retrieval and adaptive reasoning. AFEV dynamically refines claim understanding and reduces error propagation through iterative fact extraction, reranks evidence to filter noise, and leverages context-specific demonstrations to guide the reasoning process. Extensive experiments on five benchmark datasets demonstrate that AFEV achieves state-of-the-art performance in both accuracy and interpretability.",
    "categories": [
      "cs.AI"
    ],
    "primary_category": "cs.AI",
    "comment": "",
    "pdf_url": "https://arxiv.org/pdf/2506.07446v1",
    "published_date": "2025-06-09 05:49:43 UTC",
    "updated_date": "2025-06-09 05:49:43 UTC"
  },
  {
    "arxiv_id": "2506.07443v1",
    "title": "LegalReasoner: Step-wised Verification-Correction for Legal Judgment Reasoning",
    "authors": [
      "Weijie Shi",
      "Han Zhu",
      "Jiaming Ji",
      "Mengze Li",
      "Jipeng Zhang",
      "Ruiyuan Zhang",
      "Jia Zhu",
      "Jiajie Xu",
      "Sirui Han",
      "Yike Guo"
    ],
    "abstract": "Legal judgment prediction (LJP) aims to function as a judge by making final rulings based on case claims and facts, which plays a vital role in the judicial domain for supporting court decision-making and improving judicial efficiency. However, existing methods often struggle with logical errors when conducting complex legal reasoning. We propose LegalReasoner, which enhances LJP reliability through step-wise verification and correction of the reasoning process. Specifically, it first identifies dispute points to decompose complex cases, and then conducts step-wise reasoning while employing a process verifier to validate each step's logic from correctness, progressiveness, and potential perspectives. When errors are detected, expert-designed attribution and resolution strategies are applied for correction. To fine-tune LegalReasoner, we release the LegalHK dataset, containing 58,130 Hong Kong court cases with detailed annotations of dispute points, step-by-step reasoning chains, and process verification labels. Experiments demonstrate that LegalReasoner significantly improves concordance with court decisions from 72.37 to 80.27 on LLAMA-3.1-70B. The data is available at https://huggingface.co/datasets/weijiezz/LegalHK.",
    "categories": [
      "cs.AI"
    ],
    "primary_category": "cs.AI",
    "comment": "",
    "pdf_url": "https://arxiv.org/pdf/2506.07443v1",
    "published_date": "2025-06-09 05:48:35 UTC",
    "updated_date": "2025-06-09 05:48:35 UTC"
  },
  {
    "arxiv_id": "2506.07436v1",
    "title": "Prompt to Protection: A Comparative Study of Multimodal LLMs in Construction Hazard Recognition",
    "authors": [
      "Nishi Chaudhary",
      "S M Jamil Uddin",
      "Sathvik Sharath Chandra",
      "Anto Ovid",
      "Alex Albert"
    ],
    "abstract": "The recent emergence of multimodal large language models (LLMs) has introduced new opportunities for improving visual hazard recognition on construction sites. Unlike traditional computer vision models that rely on domain-specific training and extensive datasets, modern LLMs can interpret and describe complex visual scenes using simple natural language prompts. However, despite growing interest in their applications, there has been limited investigation into how different LLMs perform in safety-critical visual tasks within the construction domain. To address this gap, this study conducts a comparative evaluation of five state-of-the-art LLMs: Claude-3 Opus, GPT-4.5, GPT-4o, GPT-o3, and Gemini 2.0 Pro, to assess their ability to identify potential hazards from real-world construction images. Each model was tested under three prompting strategies: zero-shot, few-shot, and chain-of-thought (CoT). Zero-shot prompting involved minimal instruction, few-shot incorporated basic safety context and a hazard source mnemonic, and CoT provided step-by-step reasoning examples to scaffold model thinking. Quantitative analysis was performed using precision, recall, and F1-score metrics across all conditions. Results reveal that prompting strategy significantly influenced performance, with CoT prompting consistently producing higher accuracy across models. Additionally, LLM performance varied under different conditions, with GPT-4.5 and GPT-o3 outperforming others in most settings. The findings also demonstrate the critical role of prompt design in enhancing the accuracy and consistency of multimodal LLMs for construction safety applications. This study offers actionable insights into the integration of prompt engineering and LLMs for practical hazard recognition, contributing to the development of more reliable AI-assisted safety systems.",
    "categories": [
      "cs.CV",
      "cs.AI",
      "cs.ET"
    ],
    "primary_category": "cs.CV",
    "comment": "",
    "pdf_url": "https://arxiv.org/pdf/2506.07436v1",
    "published_date": "2025-06-09 05:22:35 UTC",
    "updated_date": "2025-06-09 05:22:35 UTC"
  },
  {
    "arxiv_id": "2506.07435v2",
    "title": "Fast Geometric Embedding for Node Influence Maximization",
    "authors": [
      "Alexander Kolpakov",
      "Igor Rivin"
    ],
    "abstract": "Computing classical centrality measures such as betweenness and closeness is computationally expensive on large-scale graphs. In this work, we introduce an efficient force layout algorithm that embeds a graph into a low-dimensional space, where the radial distance from the origin serves as a proxy for various centrality measures. We evaluate our method on multiple graph families and demonstrate strong correlations with degree, PageRank, and paths-based centralities. As an application, it turns out that the proposed embedding allows to find high-influence nodes in a network, and provides a fast and scalable alternative to the standard greedy algorithm.",
    "categories": [
      "cs.SI",
      "cs.AI",
      "cs.LG"
    ],
    "primary_category": "cs.SI",
    "comment": "8 pages, 4 figures, 18 tables; Github repository available (https://github.com/sashakolpakov/graphem/); Package available on PyPi (https://pypi.org/project/graphem-jax/)",
    "pdf_url": "https://arxiv.org/pdf/2506.07435v2",
    "published_date": "2025-06-09 05:21:56 UTC",
    "updated_date": "2025-08-18 12:21:34 UTC"
  },
  {
    "arxiv_id": "2506.07434v1",
    "title": "Well Begun is Half Done: Low-resource Preference Alignment by Weak-to-Strong Decoding",
    "authors": [
      "Feifan Song",
      "Shaohang Wei",
      "Wen Luo",
      "Yuxuan Fan",
      "Tianyu Liu",
      "Guoyin Wang",
      "Houfeng Wang"
    ],
    "abstract": "Large Language Models (LLMs) require alignment with human preferences to avoid generating offensive, false, or meaningless content. Recently, low-resource methods for LLM alignment have been popular, while still facing challenges in obtaining both high-quality and aligned content. Motivated by the observation that the difficulty of generating aligned responses is concentrated at the beginning of decoding, we propose a novel framework, Weak-to-Strong Decoding (WSD), to enhance the alignment ability of base models by the guidance of a small aligned model. The small model first drafts well-aligned beginnings, followed by the large base model to continue the rest, controlled by a well-designed auto-switch mechanism. We also collect a new dataset, GenerAlign, to fine-tune a small-sized Pilot-3B as the draft model, which effectively enhances different base models under the WSD framework to outperform all baseline methods, while avoiding degradation on downstream tasks, termed as the alignment tax. Extensive experiments are further conducted to examine the impact of different settings and time efficiency, as well as analyses on the intrinsic mechanisms of WSD in depth.",
    "categories": [
      "cs.CL",
      "cs.AI"
    ],
    "primary_category": "cs.CL",
    "comment": "Accepted by ACL 2025 Findings",
    "pdf_url": "https://arxiv.org/pdf/2506.07434v1",
    "published_date": "2025-06-09 05:21:22 UTC",
    "updated_date": "2025-06-09 05:21:22 UTC"
  },
  {
    "arxiv_id": "2506.07431v2",
    "title": "FAMSeg: Fetal Femur and Cranial Ultrasound Segmentation Using Feature-Aware Attention and Mamba Enhancement",
    "authors": [
      "Jie He",
      "Minglang Chen",
      "Minying Lu",
      "Bocheng Liang",
      "Junming Wei",
      "Guiyan Peng",
      "Jiaxi Chen",
      "Ying Tan"
    ],
    "abstract": "Accurate ultrasound image segmentation is a prerequisite for precise biometrics and accurate assessment. Relying on manual delineation introduces significant errors and is time-consuming. However, existing segmentation models are designed based on objects in natural scenes, making them difficult to adapt to ultrasound objects with high noise and high similarity. This is particularly evident in small object segmentation, where a pronounced jagged effect occurs. Therefore, this paper proposes a fetal femur and cranial ultrasound image segmentation model based on feature perception and Mamba enhancement to address these challenges. Specifically, a longitudinal and transverse independent viewpoint scanning convolution block and a feature perception module were designed to enhance the ability to capture local detail information and improve the fusion of contextual information. Combined with the Mamba-optimized residual structure, this design suppresses the interference of raw noise and enhances local multi-dimensional scanning. The system builds global information and local feature dependencies, and is trained with a combination of different optimizers to achieve the optimal solution. After extensive experimental validation, the FAMSeg network achieved the fastest loss reduction and the best segmentation performance across images of varying sizes and orientations.",
    "categories": [
      "cs.CV",
      "cs.AI"
    ],
    "primary_category": "cs.CV",
    "comment": "",
    "pdf_url": "https://arxiv.org/pdf/2506.07431v2",
    "published_date": "2025-06-09 05:06:47 UTC",
    "updated_date": "2025-06-14 10:40:44 UTC"
  },
  {
    "arxiv_id": "2506.07428v1",
    "title": "HeTa: Relation-wise Heterogeneous Graph Foundation Attack Model",
    "authors": [
      "Yuling Wang",
      "Zihui Chen",
      "Pengfei Jiao",
      "Xiao Wang"
    ],
    "abstract": "Heterogeneous Graph Neural Networks (HGNNs) are vulnerable, highlighting the need for tailored attacks to assess their robustness and ensure security. However, existing HGNN attacks often require complex retraining of parameters to generate specific perturbations for new scenarios. Recently, foundation models have opened new horizons for the generalization of graph neural networks by capturing shared semantics across various graph distributions. This leads us to ask:Can we design a foundation attack model for HGNNs that enables generalizable perturbations across different HGNNs, and quickly adapts to new heterogeneous graphs (HGs)? Empirical findings reveal that, despite significant differences in model design and parameter space, different HGNNs surprisingly share common vulnerability patterns from a relation-aware perspective. Therefore, we explore how to design foundation HGNN attack criteria by mining shared attack units. In this paper, we propose a novel relation-wise heterogeneous graph foundation attack model, HeTa. We introduce a foundation surrogate model to align heterogeneity and identify the importance of shared relation-aware attack units. Building on this, we implement a serialized relation-by-relation attack based on the identified relational weights. In this way, the perturbation can be transferred to various target HGNNs and easily fine-tuned for new HGs. Extensive experiments exhibit powerful attack performances and generalizability of our method.",
    "categories": [
      "cs.AI",
      "cs.LG"
    ],
    "primary_category": "cs.AI",
    "comment": "Accepted by IJCAI 2025",
    "pdf_url": "https://arxiv.org/pdf/2506.07428v1",
    "published_date": "2025-06-09 04:59:14 UTC",
    "updated_date": "2025-06-09 04:59:14 UTC"
  },
  {
    "arxiv_id": "2506.11115v1",
    "title": "Incorporating Domain Knowledge into Materials Tokenization",
    "authors": [
      "Yerim Oh",
      "Jun-Hyung Park",
      "Junho Kim",
      "SungHo Kim",
      "SangKeun Lee"
    ],
    "abstract": "While language models are increasingly utilized in materials science, typical models rely on frequency-centric tokenization methods originally developed for natural language processing. However, these methods frequently produce excessive fragmentation and semantic loss, failing to maintain the structural and semantic integrity of material concepts. To address this issue, we propose MATTER, a novel tokenization approach that integrates material knowledge into tokenization. Based on MatDetector trained on our materials knowledge base and a re-ranking method prioritizing material concepts in token merging, MATTER maintains the structural integrity of identified material concepts and prevents fragmentation during tokenization, ensuring their semantic meaning remains intact. The experimental results demonstrate that MATTER outperforms existing tokenization methods, achieving an average performance gain of $4\\%$ and $2\\%$ in the generation and classification tasks, respectively. These results underscore the importance of domain knowledge for tokenization strategies in scientific text processing. Our code is available at https://github.com/yerimoh/MATTER",
    "categories": [
      "cs.CL",
      "cs.AI"
    ],
    "primary_category": "cs.CL",
    "comment": "",
    "pdf_url": "https://arxiv.org/pdf/2506.11115v1",
    "published_date": "2025-06-09 04:59:13 UTC",
    "updated_date": "2025-06-09 04:59:13 UTC"
  },
  {
    "arxiv_id": "2506.07424v1",
    "title": "Plug-in and Fine-tuning: Bridging the Gap between Small Language Models and Large Language Models",
    "authors": [
      "Kyeonghyun Kim",
      "Jinhee Jang",
      "Juhwan Choi",
      "Yoonji Lee",
      "Kyohoon Jin",
      "YoungBin Kim"
    ],
    "abstract": "Large language models (LLMs) are renowned for their extensive linguistic knowledge and strong generalization capabilities, but their high computational demands make them unsuitable for resource-constrained environments. In contrast, small language models (SLMs) are computationally efficient but often lack the broad generalization capacity of LLMs. To bridge this gap, we propose PiFi, a novel framework that combines the strengths of both LLMs and SLMs to achieve high performance while maintaining efficiency. PiFi integrates a single frozen layer from an LLM into a SLM and fine-tunes the combined model for specific tasks, boosting performance without a significant increase in computational cost. We show that PiFi delivers consistent performance improvements across a range of natural language processing tasks, including both natural language understanding and generation. Moreover, our findings demonstrate PiFi's ability to effectively leverage LLM knowledge, enhancing generalization to unseen domains and facilitating the transfer of linguistic abilities.",
    "categories": [
      "cs.CL",
      "cs.AI"
    ],
    "primary_category": "cs.CL",
    "comment": "ACL 2025 main conference",
    "pdf_url": "https://arxiv.org/pdf/2506.07424v1",
    "published_date": "2025-06-09 04:45:13 UTC",
    "updated_date": "2025-06-09 04:45:13 UTC"
  },
  {
    "arxiv_id": "2506.07418v1",
    "title": "Evaluating Visual Mathematics in Multimodal LLMs: A Multilingual Benchmark Based on the Kangaroo Tests",
    "authors": [
      "Arnau Igualde Sáez",
      "Lamyae Rhomrasi",
      "Yusef Ahsini",
      "Ricardo Vinuesa",
      "Sergio Hoyas",
      "Jose P. García Sabater",
      "Marius J. Fullana i Alfonso",
      "J. Alberto Conejero"
    ],
    "abstract": "Multimodal Large Language Models (MLLMs) promise advanced vision language capabilities, yet their effectiveness in visually presented mathematics remains underexplored. This paper analyzes the development and evaluation of MLLMs for mathematical problem solving, focusing on diagrams, multilingual text, and symbolic notation. We then assess several models, including GPT 4o, Pixtral, Qwen VL, Llama 3.2 Vision variants, and Gemini 2.0 Flash in a multilingual Kangaroo style benchmark spanning English, French, Spanish, and Catalan. Our experiments reveal four key findings. First, overall precision remains moderate across geometry, visual algebra, logic, patterns, and combinatorics: no single model excels in every topic. Second, while most models see improved accuracy with questions that do not have images, the gain is often limited; performance for some remains nearly unchanged without visual input, indicating underutilization of diagrammatic information. Third, substantial variation exists across languages and difficulty levels: models frequently handle easier items but struggle with advanced geometry and combinatorial reasoning. Notably, Gemini 2.0 Flash achieves the highest precision on image based tasks, followed by Qwen VL 2.5 72B and GPT 4o, though none approach human level performance. Fourth, a complementary analysis aimed at distinguishing whether models reason or simply recite reveals that Gemini and GPT 4o stand out for their structured reasoning and consistent accuracy. In contrast, Pixtral and Llama exhibit less consistent reasoning, often defaulting to heuristics or randomness when unable to align their outputs with the given answer options.",
    "categories": [
      "cs.AI"
    ],
    "primary_category": "cs.AI",
    "comment": "16 pages, 4 figures",
    "pdf_url": "https://arxiv.org/pdf/2506.07418v1",
    "published_date": "2025-06-09 04:35:02 UTC",
    "updated_date": "2025-06-09 04:35:02 UTC"
  },
  {
    "arxiv_id": "2506.07417v2",
    "title": "Evidential Spectrum-Aware Contrastive Learning for OOD Detection in Dynamic Graphs",
    "authors": [
      "Nan Sun",
      "Xixun Lin",
      "Zhiheng Zhou",
      "Yanmin Shang",
      "Zhenlin Cheng",
      "Yanan Cao"
    ],
    "abstract": "Recently, Out-of-distribution (OOD) detection in dynamic graphs, which aims to identify whether incoming data deviates from the distribution of the in-distribution (ID) training set, has garnered considerable attention in security-sensitive fields. Current OOD detection paradigms primarily focus on static graphs and confront two critical challenges: i) high bias and high variance caused by single-point estimation, which makes the predictions sensitive to randomness in the data; ii) score homogenization resulting from the lack of OOD training data, where the model only learns ID-specific patterns, resulting in overall low OOD scores and a narrow score gap between ID and OOD data. To tackle these issues, we first investigate OOD detection in dynamic graphs through the lens of Evidential Deep Learning (EDL). Specifically, we propose EviSEC, an innovative and effective OOD detector via Evidential Spectrum-awarE Contrastive Learning. We design an evidential neural network to redefine the output as the posterior Dirichlet distribution, explaining the randomness of inputs through the uncertainty of distribution, which is overlooked by single-point estimation. Moreover, spectrum-aware augmentation module generates OOD approximations to identify patterns with high OOD scores, thereby widening the score gap between ID and OOD data and mitigating score homogenization. Extensive experiments on real-world datasets demonstrate that EviSAC effectively detects OOD samples in dynamic graphs.",
    "categories": [
      "cs.LG",
      "cs.AI"
    ],
    "primary_category": "cs.LG",
    "comment": "Accepted by ECML-PKDD 2025",
    "pdf_url": "https://arxiv.org/pdf/2506.07417v2",
    "published_date": "2025-06-09 04:34:46 UTC",
    "updated_date": "2025-06-13 13:08:22 UTC"
  },
  {
    "arxiv_id": "2506.07416v2",
    "title": "LiteVLM: A Low-Latency Vision-Language Model Inference Pipeline for Resource-Constrained Environments",
    "authors": [
      "Jin Huang",
      "Yuchao Jin",
      "Le An",
      "Josh Park"
    ],
    "abstract": "This paper introduces an efficient Vision-Language Model (VLM) pipeline specifically optimized for deployment on embedded devices, such as those used in robotics and autonomous driving. The pipeline significantly reduces the computational overhead by jointly leveraging patch selection to filter irrelevant camera views, a token selection module to reduce input sequence length for the LLM, and speculative decoding to accelerate token generation. Evaluation on the NVIDIA DRIVE Thor platform for automonous driving application, our pipeline achieves $2.5\\times$ end-to-end latency reduction without compromising task accuracy. The speed-up further increases to $3.2\\times$ when applying FP8 post-training quantization. These results demonstrate our pipeline as a viable solution for enabling real-time VLM deployment in resource-constrained environments.",
    "categories": [
      "cs.LG",
      "cs.AI"
    ],
    "primary_category": "cs.LG",
    "comment": "",
    "pdf_url": "https://arxiv.org/pdf/2506.07416v2",
    "published_date": "2025-06-09 04:30:25 UTC",
    "updated_date": "2025-10-31 20:18:06 UTC"
  },
  {
    "arxiv_id": "2506.07411v1",
    "title": "An Intelligent Fault Self-Healing Mechanism for Cloud AI Systems via Integration of Large Language Models and Deep Reinforcement Learning",
    "authors": [
      "Ze Yang",
      "Yihong Jin",
      "Juntian Liu",
      "Xinhe Xu"
    ],
    "abstract": "As the scale and complexity of cloud-based AI systems continue to increase, the detection and adaptive recovery of system faults have become the core challenges to ensure service reliability and continuity. In this paper, we propose an Intelligent Fault Self-Healing Mechanism (IFSHM) that integrates Large Language Model (LLM) and Deep Reinforcement Learning (DRL), aiming to realize a fault recovery framework with semantic understanding and policy optimization capabilities in cloud AI systems. On the basis of the traditional DRL-based control model, the proposed method constructs a two-stage hybrid architecture: (1) an LLM-driven fault semantic interpretation module, which can dynamically extract deep contextual semantics from multi-source logs and system indicators to accurately identify potential fault modes; (2) DRL recovery strategy optimizer, based on reinforcement learning, learns the dynamic matching of fault types and response behaviors in the cloud environment. The innovation of this method lies in the introduction of LLM for environment modeling and action space abstraction, which greatly improves the exploration efficiency and generalization ability of reinforcement learning. At the same time, a memory-guided meta-controller is introduced, combined with reinforcement learning playback and LLM prompt fine-tuning strategy, to achieve continuous adaptation to new failure modes and avoid catastrophic forgetting. Experimental results on the cloud fault injection platform show that compared with the existing DRL and rule methods, the IFSHM framework shortens the system recovery time by 37% with unknown fault scenarios.",
    "categories": [
      "cs.AI"
    ],
    "primary_category": "cs.AI",
    "comment": "Proceedings of 2025 IEEE 8th International Conference on Advanced Electronic Materials, Computers and Software Engineering (AEMCSE 2025)",
    "pdf_url": "https://arxiv.org/pdf/2506.07411v1",
    "published_date": "2025-06-09 04:14:05 UTC",
    "updated_date": "2025-06-09 04:14:05 UTC"
  },
  {
    "arxiv_id": "2506.13776v1",
    "title": "Recommendations and Reporting Checklist for Rigorous & Transparent Human Baselines in Model Evaluations",
    "authors": [
      "Kevin L. Wei",
      "Patricia Paskov",
      "Sunishchal Dev",
      "Michael J. Byun",
      "Anka Reuel",
      "Xavier Roberts-Gaal",
      "Rachel Calcott",
      "Evie Coxon",
      "Chinmay Deshpande"
    ],
    "abstract": "In this position paper, we argue that human baselines in foundation model evaluations must be more rigorous and more transparent to enable meaningful comparisons of human vs. AI performance, and we provide recommendations and a reporting checklist towards this end. Human performance baselines are vital for the machine learning community, downstream users, and policymakers to interpret AI evaluations. Models are often claimed to achieve \"super-human\" performance, but existing baselining methods are neither sufficiently rigorous nor sufficiently well-documented to robustly measure and assess performance differences. Based on a meta-review of the measurement theory and AI evaluation literatures, we derive a framework with recommendations for designing, executing, and reporting human baselines. We synthesize our recommendations into a checklist that we use to systematically review 115 human baselines (studies) in foundation model evaluations and thus identify shortcomings in existing baselining methods; our checklist can also assist researchers in conducting human baselines and reporting results. We hope our work can advance more rigorous AI evaluation practices that can better serve both the research community and policymakers. Data is available at: https://github.com/kevinlwei/human-baselines",
    "categories": [
      "cs.AI",
      "cs.CY",
      "cs.HC"
    ],
    "primary_category": "cs.AI",
    "comment": "A version of this paper has been accepted to ICML 2025 as a position paper (spotlight), with the title: \"Position: Human Baselines in Model Evaluations Need Rigor and Transparency (With Recommendations & Reporting Checklist).\"",
    "pdf_url": "https://arxiv.org/pdf/2506.13776v1",
    "published_date": "2025-06-09 04:08:16 UTC",
    "updated_date": "2025-06-09 04:08:16 UTC"
  },
  {
    "arxiv_id": "2506.08054v2",
    "title": "STAMImputer: Spatio-Temporal Attention MoE for Traffic Data Imputation",
    "authors": [
      "Yiming Wang",
      "Hao Peng",
      "Senzhang Wang",
      "Haohua Du",
      "Chunyang Liu",
      "Jia Wu",
      "Guanlin Wu"
    ],
    "abstract": "Traffic data imputation is fundamentally important to support various applications in intelligent transportation systems such as traffic flow prediction. However, existing time-to-space sequential methods often fail to effectively extract features in block-wise missing data scenarios. Meanwhile, the static graph structure for spatial feature propagation significantly constrains the models flexibility in handling the distribution shift issue for the nonstationary traffic data. To address these issues, this paper proposes a SpatioTemporal Attention Mixture of experts network named STAMImputer for traffic data imputation. Specifically, we introduce a Mixture of Experts (MoE) framework to capture latent spatio-temporal features and their influence weights, effectively imputing block missing. A novel Low-rank guided Sampling Graph ATtention (LrSGAT) mechanism is designed to dynamically balance the local and global correlations across road networks. The sampled attention vectors are utilized to generate dynamic graphs that capture real-time spatial correlations. Extensive experiments are conducted on four traffic datasets for evaluation. The result shows STAMImputer achieves significantly performance improvement compared with existing SOTA approaches. Our codes are available at https://github.com/RingBDStack/STAMImupter.",
    "categories": [
      "cs.LG",
      "cs.AI"
    ],
    "primary_category": "cs.LG",
    "comment": "10 pages, 5 figures, 3 tables. Extended version of paper accepted at IJCAI 2025",
    "pdf_url": "https://arxiv.org/pdf/2506.08054v2",
    "published_date": "2025-06-09 04:05:00 UTC",
    "updated_date": "2025-06-11 02:33:59 UTC"
  },
  {
    "arxiv_id": "2506.07408v1",
    "title": "Fractional-order Jacobian Matrix Differentiation and Its Application in Artificial Neural Networks",
    "authors": [
      "Xiaojun zhou",
      "Chunna Zhao",
      "Yaqun Huang",
      "Chengli Zhou",
      "Junjie Ye",
      "Kemeng Xiang"
    ],
    "abstract": "Fractional-order differentiation has many characteristics different from integer-order differentiation. These characteristics can be applied to the optimization algorithms of artificial neural networks to obtain better results. However, due to insufficient theoretical research, at present, there is no fractional-order matrix differentiation method that is perfectly compatible with automatic differentiation (Autograd) technology. Therefore, we propose a fractional-order matrix differentiation calculation method. This method is introduced by the definition of the integer-order Jacobian matrix. We denote it as fractional-order Jacobian matrix differentiation (${\\bf{J}^α}$). Through ${\\bf{J}^α}$, we can carry out the matrix-based fractional-order chain rule. Based on the Linear module and the fractional-order differentiation, we design the fractional-order Autograd technology to enable the use of fractional-order differentiation in hidden layers, thereby enhancing the practicality of fractional-order differentiation in deep learning. In the experiment, according to the PyTorch framework, we design fractional-order Linear (FLinear) and replace nn.Linear in the multilayer perceptron with FLinear. Through the qualitative analysis of the training set and validation set $Loss$, the quantitative analysis of the test set indicators, and the analysis of time consumption and GPU memory usage during model training, we verify the superior performance of ${\\bf{J}^α}$ and prove that it is an excellent fractional-order gradient descent method in the field of deep learning.",
    "categories": [
      "cs.LG",
      "cs.AI"
    ],
    "primary_category": "cs.LG",
    "comment": "",
    "pdf_url": "https://arxiv.org/pdf/2506.07408v1",
    "published_date": "2025-06-09 04:04:08 UTC",
    "updated_date": "2025-06-09 04:04:08 UTC"
  },
  {
    "arxiv_id": "2506.07407v1",
    "title": "Anomaly Detection and Early Warning Mechanism for Intelligent Monitoring Systems in Multi-Cloud Environments Based on LLM",
    "authors": [
      "Yihong Jin",
      "Ze Yang",
      "Juntian Liu",
      "Xinhe Xu"
    ],
    "abstract": "With the rapid development of multi-cloud environments, it is increasingly important to ensure the security and reliability of intelligent monitoring systems. In this paper, we propose an anomaly detection and early warning mechanism for intelligent monitoring system in multi-cloud environment based on Large-Scale Language Model (LLM). On the basis of the existing monitoring framework, the proposed model innovatively introduces a multi-level feature extraction method, which combines the natural language processing ability of LLM with traditional machine learning methods to enhance the accuracy of anomaly detection and improve the real-time response efficiency. By introducing the contextual understanding capabilities of LLMs, the model dynamically adapts to different cloud service providers and environments, so as to more effectively detect abnormal patterns and predict potential failures. Experimental results show that the proposed model is significantly better than the traditional anomaly detection system in terms of detection accuracy and latency, and significantly improves the resilience and active management ability of cloud infrastructure.",
    "categories": [
      "cs.LG",
      "cs.AI"
    ],
    "primary_category": "cs.LG",
    "comment": "Proceedings of 2025 5th International Symposium on Computer Technology and Information Science (ISCTIS 2025)",
    "pdf_url": "https://arxiv.org/pdf/2506.07407v1",
    "published_date": "2025-06-09 04:00:23 UTC",
    "updated_date": "2025-06-09 04:00:23 UTC"
  },
  {
    "arxiv_id": "2506.07406v2",
    "title": "InverseScope: Scalable Activation Inversion for Interpreting Large Language Models",
    "authors": [
      "Yifan Luo",
      "Zhennan Zhou",
      "Bin Dong"
    ],
    "abstract": "Understanding the internal representations of large language models (LLMs) is a central challenge in interpretability research. Existing feature interpretability methods often rely on strong assumptions about the structure of representations that may not hold in practice. In this work, we introduce InverseScope, an assumption-light and scalable framework for interpreting neural activations via input inversion. Given a target activation, we define a distribution over inputs that generate similar activations and analyze this distribution to infer the encoded information. To address the inefficiency of sampling in high-dimensional spaces, we propose a novel conditional generation architecture that significantly improves sample efficiency compared to previous method. We further introduce a quantitative evaluation protocol that tests interpretability hypotheses using the feature consistency rate computed over the sampled inputs. InverseScope scales inversion-based interpretability methods to larger models and practical tasks, enabling systematic and quantitative analysis of internal representations in real-world LLMs.",
    "categories": [
      "cs.LG",
      "cs.AI"
    ],
    "primary_category": "cs.LG",
    "comment": "18 pages, 9 figures",
    "pdf_url": "https://arxiv.org/pdf/2506.07406v2",
    "published_date": "2025-06-09 03:59:28 UTC",
    "updated_date": "2025-09-27 02:04:29 UTC"
  },
  {
    "arxiv_id": "2506.07400v3",
    "title": "MedChat: A Multi-Agent Framework for Multimodal Diagnosis with Large Language Models",
    "authors": [
      "Philip R. Liu",
      "Sparsh Bansal",
      "Jimmy Dinh",
      "Aditya Pawar",
      "Ramani Satishkumar",
      "Shail Desai",
      "Neeraj Gupta",
      "Xin Wang",
      "Shu Hu"
    ],
    "abstract": "The integration of deep learning-based glaucoma detection with large language models (LLMs) presents an automated strategy to mitigate ophthalmologist shortages and improve clinical reporting efficiency. However, applying general LLMs to medical imaging remains challenging due to hallucinations, limited interpretability, and insufficient domain-specific medical knowledge, which can potentially reduce clinical accuracy. Although recent approaches combining imaging models with LLM reasoning have improved reporting, they typically rely on a single generalist agent, restricting their capacity to emulate the diverse and complex reasoning found in multidisciplinary medical teams. To address these limitations, we propose MedChat, a multi-agent diagnostic framework and platform that combines specialized vision models with multiple role-specific LLM agents, all coordinated by a director agent. This design enhances reliability, reduces hallucination risk, and enables interactive diagnostic reporting through an interface tailored for clinical review and educational use. Code available at https://github.com/Purdue-M2/MedChat.",
    "categories": [
      "cs.MA",
      "cs.AI",
      "cs.CV",
      "cs.LG"
    ],
    "primary_category": "cs.MA",
    "comment": "",
    "pdf_url": "https://arxiv.org/pdf/2506.07400v3",
    "published_date": "2025-06-09 03:51:18 UTC",
    "updated_date": "2025-12-16 22:52:21 UTC"
  },
  {
    "arxiv_id": "2506.07399v1",
    "title": "MrM: Black-Box Membership Inference Attacks against Multimodal RAG Systems",
    "authors": [
      "Peiru Yang",
      "Jinhua Yin",
      "Haoran Zheng",
      "Xueying Bai",
      "Huili Wang",
      "Yufei Sun",
      "Xintian Li",
      "Shangguang Wang",
      "Yongfeng Huang",
      "Tao Qi"
    ],
    "abstract": "Multimodal retrieval-augmented generation (RAG) systems enhance large vision-language models by integrating cross-modal knowledge, enabling their increasing adoption across real-world multimodal tasks. These knowledge databases may contain sensitive information that requires privacy protection. However, multimodal RAG systems inherently grant external users indirect access to such data, making them potentially vulnerable to privacy attacks, particularly membership inference attacks (MIAs). % Existing MIA methods targeting RAG systems predominantly focus on the textual modality, while the visual modality remains relatively underexplored. To bridge this gap, we propose MrM, the first black-box MIA framework targeted at multimodal RAG systems. It utilizes a multi-object data perturbation framework constrained by counterfactual attacks, which can concurrently induce the RAG systems to retrieve the target data and generate information that leaks the membership information. Our method first employs an object-aware data perturbation method to constrain the perturbation to key semantics and ensure successful retrieval. Building on this, we design a counterfact-informed mask selection strategy to prioritize the most informative masked regions, aiming to eliminate the interference of model self-knowledge and amplify attack efficacy. Finally, we perform statistical membership inference by modeling query trials to extract features that reflect the reconstruction of masked semantics from response patterns. Experiments on two visual datasets and eight mainstream commercial visual-language models (e.g., GPT-4o, Gemini-2) demonstrate that MrM achieves consistently strong performance across both sample-level and set-level evaluations, and remains robust under adaptive defenses.",
    "categories": [
      "cs.CV",
      "cs.AI"
    ],
    "primary_category": "cs.CV",
    "comment": "",
    "pdf_url": "https://arxiv.org/pdf/2506.07399v1",
    "published_date": "2025-06-09 03:48:50 UTC",
    "updated_date": "2025-06-09 03:48:50 UTC"
  },
  {
    "arxiv_id": "2506.07392v4",
    "title": "From Static to Adaptive Defense: Federated Multi-Agent Deep Reinforcement Learning-Driven Moving Target Defense Against DoS Attacks in UAV Swarm Networks",
    "authors": [
      "Yuyang Zhou",
      "Guang Cheng",
      "Kang Du",
      "Zihan Chen",
      "Tian Qin",
      "Yuyu Zhao"
    ],
    "abstract": "The proliferation of UAVs has enabled a wide range of mission-critical applications and is becoming a cornerstone of low-altitude networks, supporting smart cities, emergency response, and more. However, the open wireless environment, dynamic topology, and resource constraints of UAVs expose low-altitude networks to severe DoS threats. Traditional defense approaches, which rely on fixed configurations or centralized decision-making, cannot effectively respond to the rapidly changing conditions in UAV swarm environments. To address these challenges, we propose a novel federated multi-agent deep reinforcement learning (FMADRL)-driven moving target defense (MTD) framework for proactive DoS mitigation in low-altitude networks. Specifically, we design lightweight and coordinated MTD mechanisms, including leader switching, route mutation, and frequency hopping, to disrupt attacker efforts and enhance network resilience. The defense problem is formulated as a multi-agent partially observable Markov decision process, capturing the uncertain nature of UAV swarms under attack. Each UAV is equipped with a policy agent that autonomously selects MTD actions based on partial observations and local experiences. By employing a policy gradient-based algorithm, UAVs collaboratively optimize their policies via reward-weighted aggregation. Extensive simulations demonstrate that our approach significantly outperforms state-of-the-art baselines, achieving up to a 34.6% improvement in attack mitigation rate, a reduction in average recovery time of up to 94.6%, and decreases in energy consumption and defense cost by as much as 29.3% and 98.3%, respectively, under various DoS attack strategies. These results highlight the potential of intelligent, distributed defense mechanisms to protect low-altitude networks, paving the way for reliable and scalable low-altitude economy.",
    "categories": [
      "cs.CR",
      "cs.AI",
      "cs.LG"
    ],
    "primary_category": "cs.CR",
    "comment": "15pages; Accepted by IEEE TCCN",
    "pdf_url": "https://arxiv.org/pdf/2506.07392v4",
    "published_date": "2025-06-09 03:33:04 UTC",
    "updated_date": "2025-11-20 09:41:03 UTC"
  },
  {
    "arxiv_id": "2506.07390v1",
    "title": "Boosting Vulnerability Detection of LLMs via Curriculum Preference Optimization with Synthetic Reasoning Data",
    "authors": [
      "Xin-Cheng Wen",
      "Yijun Yang",
      "Cuiyun Gao",
      "Yang Xiao",
      "Deheng Ye"
    ],
    "abstract": "Large language models (LLMs) demonstrate considerable proficiency in numerous coding-related tasks; however, their capabilities in detecting software vulnerabilities remain limited. This limitation primarily stems from two factors: (1) the absence of reasoning data related to vulnerabilities, which hinders the models' ability to capture underlying vulnerability patterns; and (2) their focus on learning semantic representations rather than the reason behind them, thus failing to recognize semantically similar vulnerability samples. Furthermore, the development of LLMs specialized in vulnerability detection is challenging, particularly in environments characterized by the scarcity of high-quality datasets. In this paper, we propose a novel framework ReVD that excels at mining vulnerability patterns through reasoning data synthesizing and vulnerability-specific preference optimization. Specifically, we construct forward and backward reasoning processes for vulnerability and corresponding fixed code, ensuring the synthesis of high-quality reasoning data. Moreover, we design the triplet supervised fine-tuning followed by curriculum online preference optimization for enabling ReVD to better understand vulnerability patterns. The extensive experiments conducted on PrimeVul and SVEN datasets demonstrate that ReVD sets new state-of-the-art for LLM-based software vulnerability detection, e.g., 12.24\\%-22.77\\% improvement in the accuracy. The source code and data are available at https://github.com/Xin-Cheng-Wen/PO4Vul.",
    "categories": [
      "cs.AI",
      "cs.SE"
    ],
    "primary_category": "cs.AI",
    "comment": "Accepted by ACL 2025 Findings",
    "pdf_url": "https://arxiv.org/pdf/2506.07390v1",
    "published_date": "2025-06-09 03:25:23 UTC",
    "updated_date": "2025-06-09 03:25:23 UTC"
  },
  {
    "arxiv_id": "2506.07388v1",
    "title": "Shapley-Coop: Credit Assignment for Emergent Cooperation in Self-Interested LLM Agents",
    "authors": [
      "Yun Hua",
      "Haosheng Chen",
      "Shiqin Wang",
      "Wenhao Li",
      "Xiangfeng Wang",
      "Jun Luo"
    ],
    "abstract": "Large Language Models (LLMs) show strong collaborative performance in multi-agent systems with predefined roles and workflows. However, in open-ended environments lacking coordination rules, agents tend to act in self-interested ways. The central challenge in achieving coordination lies in credit assignment -- fairly evaluating each agent's contribution and designing pricing mechanisms that align their heterogeneous goals. This problem is critical as LLMs increasingly participate in complex human-AI collaborations, where fair compensation and accountability rely on effective pricing mechanisms. Inspired by how human societies address similar coordination challenges (e.g., through temporary collaborations such as employment or subcontracting), we propose a cooperative workflow, Shapley-Coop. Shapley-Coop integrates Shapley Chain-of-Thought -- leveraging marginal contributions as a principled basis for pricing -- with structured negotiation protocols for effective price matching, enabling LLM agents to coordinate through rational task-time pricing and post-task reward redistribution. This approach aligns agent incentives, fosters cooperation, and maintains autonomy. We evaluate Shapley-Coop across two multi-agent games and a software engineering simulation, demonstrating that it consistently enhances LLM agent collaboration and facilitates equitable credit assignment. These results highlight the effectiveness of Shapley-Coop's pricing mechanisms in accurately reflecting individual contributions during task execution.",
    "categories": [
      "cs.MA",
      "cs.AI"
    ],
    "primary_category": "cs.MA",
    "comment": "",
    "pdf_url": "https://arxiv.org/pdf/2506.07388v1",
    "published_date": "2025-06-09 03:24:01 UTC",
    "updated_date": "2025-06-09 03:24:01 UTC"
  },
  {
    "arxiv_id": "2506.07376v1",
    "title": "Adapter Naturally Serves as Decoupler for Cross-Domain Few-Shot Semantic Segmentation",
    "authors": [
      "Jintao Tong",
      "Ran Ma",
      "Yixiong Zou",
      "Guangyao Chen",
      "Yuhua Li",
      "Ruixuan Li"
    ],
    "abstract": "Cross-domain few-shot segmentation (CD-FSS) is proposed to pre-train the model on a source-domain dataset with sufficient samples, and then transfer the model to target-domain datasets where only a few samples are available for efficient fine-tuning. There are majorly two challenges in this task: (1) the domain gap and (2) fine-tuning with scarce data. To solve these challenges, we revisit the adapter-based methods, and discover an intriguing insight not explored in previous works: the adapter not only helps the fine-tuning of downstream tasks but also naturally serves as a domain information decoupler. Then, we delve into this finding for an interpretation, and find the model's inherent structure could lead to a natural decoupling of domain information. Building upon this insight, we propose the Domain Feature Navigator (DFN), which is a structure-based decoupler instead of loss-based ones like current works, to capture domain-specific information, thereby directing the model's attention towards domain-agnostic knowledge. Moreover, to prevent the potential excessive overfitting of DFN during the source-domain training, we further design the SAM-SVN method to constrain DFN from learning sample-specific knowledge. On target domains, we freeze the model and fine-tune the DFN to learn target-specific knowledge specific. Extensive experiments demonstrate that our method surpasses the state-of-the-art method in CD-FSS significantly by 2.69% and 4.68% MIoU in 1-shot and 5-shot scenarios, respectively.",
    "categories": [
      "cs.CV",
      "cs.AI",
      "cs.LG"
    ],
    "primary_category": "cs.CV",
    "comment": "ICML 2025 Spotlight",
    "pdf_url": "https://arxiv.org/pdf/2506.07376v1",
    "published_date": "2025-06-09 02:51:06 UTC",
    "updated_date": "2025-06-09 02:51:06 UTC"
  },
  {
    "arxiv_id": "2506.07373v1",
    "title": "HyColor: An Efficient Heuristic Algorithm for Graph Coloring",
    "authors": [
      "Enqiang Zhu",
      "Yu Zhang",
      "Haopeng Sun",
      "Ziqi Wei",
      "Witold Pedrycz",
      "Chanjuan Liu",
      "Jin Xu"
    ],
    "abstract": "The graph coloring problem (GCP) is a classic combinatorial optimization problem that aims to find the minimum number of colors assigned to vertices of a graph such that no two adjacent vertices receive the same color. GCP has been extensively studied by researchers from various fields, including mathematics, computer science, and biological science. Due to the NP-hard nature, many heuristic algorithms have been proposed to solve GCP. However, existing GCP algorithms focus on either small hard graphs or large-scale sparse graphs (with up to 10^7 vertices). This paper presents an efficient hybrid heuristic algorithm for GCP, named HyColor, which excels in handling large-scale sparse graphs while achieving impressive results on small dense graphs. The efficiency of HyColor comes from the following three aspects: a local decision strategy to improve the lower bound on the chromatic number; a graph-reduction strategy to reduce the working graph; and a k-core and mixed degree-based greedy heuristic for efficiently coloring graphs. HyColor is evaluated against three state-of-the-art GCP algorithms across four benchmarks, comprising three large-scale sparse graph benchmarks and one small dense graph benchmark, totaling 209 instances. The results demonstrate that HyColor consistently outperforms existing heuristic algorithms in both solution accuracy and computational efficiency for the majority of instances. Notably, HyColor achieved the best solutions in 194 instances (over 93%), with 34 of these solutions significantly surpassing those of other algorithms. Furthermore, HyColor successfully determined the chromatic number and achieved optimal coloring in 128 instances.",
    "categories": [
      "cs.DM",
      "cs.AI"
    ],
    "primary_category": "cs.DM",
    "comment": "14 pages, 4 figures",
    "pdf_url": "https://arxiv.org/pdf/2506.07373v1",
    "published_date": "2025-06-09 02:45:08 UTC",
    "updated_date": "2025-06-09 02:45:08 UTC"
  },
  {
    "arxiv_id": "2506.07368v2",
    "title": "C3S3: Complementary Competition and Contrastive Selection for Semi-Supervised Medical Image Segmentation",
    "authors": [
      "Jiaying He",
      "Yitong Lin",
      "Jiahe Chen",
      "Honghui Xu",
      "Jianwei Zheng"
    ],
    "abstract": "For the immanent challenge of insufficiently annotated samples in the medical field, semi-supervised medical image segmentation (SSMIS) offers a promising solution. Despite achieving impressive results in delineating primary target areas, most current methodologies struggle to precisely capture the subtle details of boundaries. This deficiency often leads to significant diagnostic inaccuracies. To tackle this issue, we introduce C3S3, a novel semi-supervised segmentation model that synergistically integrates complementary competition and contrastive selection. This design significantly sharpens boundary delineation and enhances overall precision. Specifically, we develop an Outcome-Driven Contrastive Learning module dedicated to refining boundary localization. Additionally, we incorporate a Dynamic Complementary Competition module that leverages two high-performing sub-networks to generate pseudo-labels, thereby further improving segmentation quality. The proposed C3S3 undergoes rigorous validation on two publicly accessible datasets, encompassing the practices of both MRI and CT scans. The results demonstrate that our method achieves superior performance compared to previous cutting-edge competitors. Especially, on the 95HD and ASD metrics, our approach achieves a notable improvement of at least 6%, highlighting the significant advancements. The code is available at https://github.com/Y-TARL/C3S3.",
    "categories": [
      "cs.CV",
      "cs.AI"
    ],
    "primary_category": "cs.CV",
    "comment": "Accepted to ICME 2025",
    "pdf_url": "https://arxiv.org/pdf/2506.07368v2",
    "published_date": "2025-06-09 02:34:19 UTC",
    "updated_date": "2025-06-25 05:23:29 UTC"
  },
  {
    "arxiv_id": "2506.07364v1",
    "title": "Multiple Object Stitching for Unsupervised Representation Learning",
    "authors": [
      "Chengchao Shen",
      "Dawei Liu",
      "Jianxin Wang"
    ],
    "abstract": "Contrastive learning for single object centric images has achieved remarkable progress on unsupervised representation, but suffering inferior performance on the widespread images with multiple objects. In this paper, we propose a simple but effective method, Multiple Object Stitching (MOS), to refine the unsupervised representation for multi-object images. Specifically, we construct the multi-object images by stitching the single object centric ones, where the objects in the synthesized multi-object images are predetermined. Hence, compared to the existing contrastive methods, our method provides additional object correspondences between multi-object images without human annotations. In this manner, our method pays more attention to the representations of each object in multi-object image, thus providing more detailed representations for complicated downstream tasks, such as object detection and semantic segmentation. Experimental results on ImageNet, CIFAR and COCO datasets demonstrate that our proposed method achieves the leading unsupervised representation performance on both single object centric images and multi-object ones. The source code is available at https://github.com/visresearch/MultipleObjectStitching.",
    "categories": [
      "cs.CV",
      "cs.AI",
      "cs.LG"
    ],
    "primary_category": "cs.CV",
    "comment": "",
    "pdf_url": "https://arxiv.org/pdf/2506.07364v1",
    "published_date": "2025-06-09 02:28:21 UTC",
    "updated_date": "2025-06-09 02:28:21 UTC"
  },
  {
    "arxiv_id": "2506.11114v1",
    "title": "KokushiMD-10: Benchmark for Evaluating Large Language Models on Ten Japanese National Healthcare Licensing Examinations",
    "authors": [
      "Junyu Liu",
      "Kaiqi Yan",
      "Tianyang Wang",
      "Qian Niu",
      "Momoko Nagai-Tanima",
      "Tomoki Aoyama"
    ],
    "abstract": "Recent advances in large language models (LLMs) have demonstrated notable performance in medical licensing exams. However, comprehensive evaluation of LLMs across various healthcare roles, particularly in high-stakes clinical scenarios, remains a challenge. Existing benchmarks are typically text-based, English-centric, and focus primarily on medicines, which limits their ability to assess broader healthcare knowledge and multimodal reasoning. To address these gaps, we introduce KokushiMD-10, the first multimodal benchmark constructed from ten Japanese national healthcare licensing exams. This benchmark spans multiple fields, including Medicine, Dentistry, Nursing, Pharmacy, and allied health professions. It contains over 11588 real exam questions, incorporating clinical images and expert-annotated rationales to evaluate both textual and visual reasoning. We benchmark over 30 state-of-the-art LLMs, including GPT-4o, Claude 3.5, and Gemini, across both text and image-based settings. Despite promising results, no model consistently meets passing thresholds across domains, highlighting the ongoing challenges in medical AI. KokushiMD-10 provides a comprehensive and linguistically grounded resource for evaluating and advancing reasoning-centric medical AI across multilingual and multimodal clinical tasks.",
    "categories": [
      "cs.CL",
      "cs.AI"
    ],
    "primary_category": "cs.CL",
    "comment": "9pages, 3 figures",
    "pdf_url": "https://arxiv.org/pdf/2506.11114v1",
    "published_date": "2025-06-09 02:26:02 UTC",
    "updated_date": "2025-06-09 02:26:02 UTC"
  },
  {
    "arxiv_id": "2506.17258v1",
    "title": "A Digital Twin Framework for Generation-IV Reactors with Reinforcement Learning-Enabled Health-Aware Supervisory Control",
    "authors": [
      "Jasmin Y. Lim",
      "Dimitrios Pylorof",
      "Humberto E. Garcia",
      "Karthik Duraisamy"
    ],
    "abstract": "Generation IV (Gen-IV) nuclear power plants are envisioned to replace the current reactor fleet, bringing improvements in performance, safety, reliability, and sustainability. However, large cost investments currently inhibit the deployment of these advanced reactor concepts. Digital twins bridge real-world systems with digital tools to reduce costs, enhance decision-making, and boost operational efficiency. In this work, a digital twin framework is designed to operate the Gen-IV Fluoride-salt-cooled High-temperature Reactor, utilizing data-enhanced methods to optimize operational and maintenance policies while adhering to system constraints. The closed-loop framework integrates surrogate modeling, reinforcement learning, and Bayesian inference to streamline end-to-end communication for online regulation and self-adjustment. Reinforcement learning is used to consider component health and degradation to drive the target power generations, with constraints enforced through a Reference Governor control algorithm that ensures compliance with pump flow rate and temperature limits. These input driving modules benefit from detailed online simulations that are assimilated to measurement data with Bayesian filtering. The digital twin is demonstrated in three case studies: a one-year long-term operational period showcasing maintenance planning capabilities, short-term accuracy refinement with high-frequency measurements, and system shock capturing that demonstrates real-time recalibration capabilities when change in boundary conditions. These demonstrations validate robustness for health-aware and constraint-informed nuclear plant operation, with general applicability to other advanced reactor concepts and complex engineering systems.",
    "categories": [
      "eess.SY",
      "cs.AI"
    ],
    "primary_category": "eess.SY",
    "comment": "39 pages, 22 figures",
    "pdf_url": "https://arxiv.org/pdf/2506.17258v1",
    "published_date": "2025-06-09 02:23:34 UTC",
    "updated_date": "2025-06-09 02:23:34 UTC"
  },
  {
    "arxiv_id": "2506.07358v1",
    "title": "Lightweight Joint Audio-Visual Deepfake Detection via Single-Stream Multi-Modal Learning Framework",
    "authors": [
      "Kuiyuan Zhang",
      "Wenjie Pei",
      "Rushi Lan",
      "Yifang Guo",
      "Zhongyun Hua"
    ],
    "abstract": "Deepfakes are AI-synthesized multimedia data that may be abused for spreading misinformation. Deepfake generation involves both visual and audio manipulation. To detect audio-visual deepfakes, previous studies commonly employ two relatively independent sub-models to learn audio and visual features, respectively, and fuse them subsequently for deepfake detection. However, this may underutilize the inherent correlations between audio and visual features. Moreover, utilizing two isolated feature learning sub-models can result in redundant neural layers, making the overall model inefficient and impractical for resource-constrained environments.\n  In this work, we design a lightweight network for audio-visual deepfake detection via a single-stream multi-modal learning framework. Specifically, we introduce a collaborative audio-visual learning block to efficiently integrate multi-modal information while learning the visual and audio features. By iteratively employing this block, our single-stream network achieves a continuous fusion of multi-modal features across its layers. Thus, our network efficiently captures visual and audio features without the need for excessive block stacking, resulting in a lightweight network design. Furthermore, we propose a multi-modal classification module that can boost the dependence of the visual and audio classifiers on modality content. It also enhances the whole resistance of the video classifier against the mismatches between audio and visual modalities. We conduct experiments on the DF-TIMIT, FakeAVCeleb, and DFDC benchmark datasets. Compared to state-of-the-art audio-visual joint detection methods, our method is significantly lightweight with only 0.48M parameters, yet it achieves superiority in both uni-modal and multi-modal deepfakes, as well as in unseen types of deepfakes.",
    "categories": [
      "cs.SD",
      "cs.AI",
      "cs.LG",
      "eess.AS"
    ],
    "primary_category": "cs.SD",
    "comment": "",
    "pdf_url": "https://arxiv.org/pdf/2506.07358v1",
    "published_date": "2025-06-09 02:13:04 UTC",
    "updated_date": "2025-06-09 02:13:04 UTC"
  },
  {
    "arxiv_id": "2506.07355v2",
    "title": "SALT: A Lightweight Model Adaptation Method for Closed Split Computing Environments",
    "authors": [
      "Yuya Okada",
      "Takayuki Nishio"
    ],
    "abstract": "We propose SALT (Split-Adaptive Lightweight Tuning), a lightweight model adaptation framework for Split Computing under closed constraints, where the head and tail networks are proprietary and inaccessible to users. In such closed environments, conventional adaptation methods are infeasible since they require access to model parameters or architectures. SALT addresses this challenge by introducing a compact, trainable adapter on the client side to refine latent features from the head network, enabling user-specific adaptation without modifying the original models or increasing communication overhead. We evaluate SALT on user-specific classification tasks with CIFAR-10 and CIFAR-100, demonstrating improved accuracy with lower training latency compared to fine-tuning methods. Furthermore, SALT facilitates model adaptation for robust inference over lossy networks, a common challenge in edge-cloud environments. With minimal deployment overhead, SALT offers a practical solution for personalized inference in edge AI systems under strict system constraints.",
    "categories": [
      "cs.LG",
      "cs.AI",
      "cs.NI"
    ],
    "primary_category": "cs.LG",
    "comment": "6 pages, submitted to IEEE Globecom 2025 (under review)",
    "pdf_url": "https://arxiv.org/pdf/2506.07355v2",
    "published_date": "2025-06-09 02:08:02 UTC",
    "updated_date": "2025-06-14 10:41:57 UTC"
  },
  {
    "arxiv_id": "2506.07347v1",
    "title": "Distributed Risk-Sensitive Safety Filters for Uncertain Discrete-Time Systems",
    "authors": [
      "Armin Lederer",
      "Erfaun Noorani",
      "Andreas Krause"
    ],
    "abstract": "Ensuring safety in multi-agent systems is a significant challenge, particularly in settings where centralized coordination is impractical. In this work, we propose a novel risk-sensitive safety filter for discrete-time multi-agent systems with uncertain dynamics that leverages control barrier functions (CBFs) defined through value functions. Our approach relies on centralized risk-sensitive safety conditions based on exponential risk operators to ensure robustness against model uncertainties. We introduce a distributed formulation of the safety filter by deriving two alternative strategies: one based on worst-case anticipation and another on proximity to a known safe policy. By allowing agents to switch between strategies, feasibility can be ensured. Through detailed numerical evaluations, we demonstrate the efficacy of our approach in maintaining safety without being overly conservative.",
    "categories": [
      "eess.SY",
      "cs.AI",
      "cs.LG"
    ],
    "primary_category": "eess.SY",
    "comment": "",
    "pdf_url": "https://arxiv.org/pdf/2506.07347v1",
    "published_date": "2025-06-09 01:48:25 UTC",
    "updated_date": "2025-06-09 01:48:25 UTC"
  },
  {
    "arxiv_id": "2506.07339v2",
    "title": "Real-Time Execution of Action Chunking Flow Policies",
    "authors": [
      "Kevin Black",
      "Manuel Y. Galliker",
      "Sergey Levine"
    ],
    "abstract": "Modern AI systems, especially those interacting with the physical world, increasingly require real-time performance. However, the high latency of state-of-the-art generalist models, including recent vision-language action models (VLAs), poses a significant challenge. While action chunking has enabled temporal consistency in high-frequency control tasks, it does not fully address the latency problem, leading to pauses or out-of-distribution jerky movements at chunk boundaries. This paper presents a novel inference-time algorithm that enables smooth asynchronous execution of action chunking policies. Our method, real-time chunking (RTC), is applicable to any diffusion- or flow-based VLA out of the box with no re-training. It generates the next action chunk while executing the current one, \"freezing\" actions guaranteed to execute and \"inpainting\" the rest. To test RTC, we introduce a new benchmark of 12 highly dynamic tasks in the Kinetix simulator, as well as evaluate 6 challenging real-world bimanual manipulation tasks. Results demonstrate that RTC is fast, performant, and uniquely robust to inference delay, significantly improving task throughput and enabling high success rates in precise tasks $\\unicode{x2013}$ such as lighting a match $\\unicode{x2013}$ even in the presence of significant latency. See https://pi.website/research/real_time_chunking for videos.",
    "categories": [
      "cs.RO",
      "cs.AI",
      "cs.LG"
    ],
    "primary_category": "cs.RO",
    "comment": "published in NeurIPS 2025",
    "pdf_url": "https://arxiv.org/pdf/2506.07339v2",
    "published_date": "2025-06-09 01:01:59 UTC",
    "updated_date": "2025-12-05 07:35:35 UTC"
  },
  {
    "arxiv_id": "2506.07335v2",
    "title": "Improving LLM Reasoning through Interpretable Role-Playing Steering",
    "authors": [
      "Anyi Wang",
      "Dong Shu",
      "Yifan Wang",
      "Yunpu Ma",
      "Mengnan Du"
    ],
    "abstract": "Role-playing has emerged as an effective technique for enhancing the reasoning capabilities of large language models (LLMs). However, existing methods primarily rely on prompt engineering, which often lacks stability and interpretability. In this paper, we introduce Sparse Autoencoder Role-Playing Steering (SRPS), a novel framework that identifies and manipulates internal model features associated with role-playing behavior. Our approach extracts latent representations from role-play prompts, selects the most relevant features based on activation patterns, and constructs a steering vector that can be injected into the model's residual stream with controllable intensity. Our method enables fine-grained control over role-specific behavior and offers insights into how role information influences internal model activations. Extensive experiments across various reasoning benchmarks and model sizes demonstrate consistent performance gains. Notably, in the zero-shot chain-of-thought (CoT) setting, the accuracy of Llama3.1-8B on CSQA improves from 31.86% to 39.80%, while Gemma2-9B on SVAMP increases from 37.50% to 45.10%. These results highlight the potential of SRPS to enhance reasoning ability in LLMs, providing better interpretability and stability compared to traditional prompt-based role-playing.",
    "categories": [
      "cs.CL",
      "cs.AI"
    ],
    "primary_category": "cs.CL",
    "comment": "Accepted at EMNLP 2025 Findings",
    "pdf_url": "https://arxiv.org/pdf/2506.07335v2",
    "published_date": "2025-06-09 00:31:17 UTC",
    "updated_date": "2025-09-28 10:11:49 UTC"
  },
  {
    "arxiv_id": "2506.07330v1",
    "title": "JavelinGuard: Low-Cost Transformer Architectures for LLM Security",
    "authors": [
      "Yash Datta",
      "Sharath Rajasekar"
    ],
    "abstract": "We present JavelinGuard, a suite of low-cost, high-performance model architectures designed for detecting malicious intent in Large Language Model (LLM) interactions, optimized specifically for production deployment. Recent advances in transformer architectures, including compact BERT(Devlin et al. 2019) variants (e.g., ModernBERT (Warner et al. 2024)), allow us to build highly accurate classifiers with as few as approximately 400M parameters that achieve rapid inference speeds even on standard CPU hardware. We systematically explore five progressively sophisticated transformer-based architectures: Sharanga (baseline transformer classifier), Mahendra (enhanced attention-weighted pooling with deeper heads), Vaishnava and Ashwina (hybrid neural ensemble architectures), and Raudra (an advanced multi-task framework with specialized loss functions). Our models are rigorously benchmarked across nine diverse adversarial datasets, including popular sets like the NotInject series, BIPIA, Garak, ImprovedLLM, ToxicChat, WildGuard, and our newly introduced JavelinBench, specifically crafted to test generalization on challenging borderline and hard-negative cases. Additionally, we compare our architectures against leading open-source guardrail models as well as large decoder-only LLMs such as gpt-4o, demonstrating superior cost-performance trade-offs in terms of accuracy, and latency. Our findings reveal that while Raudra's multi-task design offers the most robust performance overall, each architecture presents unique trade-offs in speed, interpretability, and resource requirements, guiding practitioners in selecting the optimal balance of complexity and efficiency for real-world LLM security applications.",
    "categories": [
      "cs.LG",
      "cs.AI",
      "cs.CR"
    ],
    "primary_category": "cs.LG",
    "comment": "16 pages, 1 Figure and 5 Tables",
    "pdf_url": "https://arxiv.org/pdf/2506.07330v1",
    "published_date": "2025-06-09 00:11:06 UTC",
    "updated_date": "2025-06-09 00:11:06 UTC"
  }
]