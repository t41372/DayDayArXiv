{
  "date": "2024-08-24",
  "category": "cs.AI",
  "summary": "欢迎来到 UTC 时间 2024-08-24 的 arXiv 中文 TLDR 快报！今天 arXiv 更新了 32 篇论文，主要聚焦 AI、机器学习、隐私保护和多模态模型等领域，其中令人印象深刻的是对大型语言模型（LLM）的优化与理论分析（如下一标记预测定律），以及知名学者如 Ruairidh M. Battleday 和 Samuel J. Gershman 的作品，强调 AI 在科学中的挑战和实际应用潜力。\n\n今天的核心话题围绕 AI 的公平性、效率优化和跨领域应用，突出 LLM 在推理、预测和多模态任务中的进展，以及联邦学习和差分隐私在实际场景中的平衡。以下挑选并简要讨论最具话题度和影响力的论文，先从 AI 理论与优化入手，再聊隐私与联邦学习，最后快速掠过其他应用性较强的文章。\n\n**1. 差分隐私在智能电网数据发布（Differential Private Publication of Electricity Time Series Data）**  \n这篇论文提出 STPT 方法，利用 RNN 分析时空属性，实现差分隐私（Differential Privacy）下的电力消费数据发布，平衡了数据效用和隐私保护。通过实验证明，STPT 在真实和合成数据集上优于现有基准，提供更高效的资源分配策略，对于智能电网隐私管理有重要启发。\n\n**7. AI 在科学中的易问题和难问题（Artificial intelligence for science: The easy and hard problems）**  \n知名学者 Ruairidh M. Battleday 和 Samuel J. Gershman 的作品，区分了 AI 在科学中的“易问题”（优化问题，如训练算法）和“难问题”（概念创新）。论文强调通过认知科学研究人类科学家行为来设计新算法，解决概念修订挑战，这为 AI 驱动的科学发现提供了新视角，值得关注 AI 的理论边界。\n\n**3. 联邦学习中的子模函数最大化方法（Submodular Maximization Approaches for Equitable Client Selection in Federated Learning）**  \n论文引入 SUBTRUNC 和 UNIONFL 方法，使用子模函数最大化（Submodular Maximization）改善联邦学习中的客户端选择，确保公平性。针对医疗和金融任务，方法通过损失信息和历史数据优化模型表现，并提供收敛保证，实验显示显著提升公平度指标，是联邦学习公平性研究的重要进展。\n\n**20. 通过标记级奖励函数估计的选择性偏好优化（Selective Preference Optimization via Token-Level Reward Function Estimation）**  \n这篇聚焦 LLM 优化的论文提出 SePO 方法，通过基于 Direct Preference Optimization 的标记级奖励函数选择关键标记，仅优化 30% 的标记即可提升性能。实验在多个基准上超越基线，并证明弱模型能指导强模型，缓解过优化问题，对于高效 LLM 微调有实际价值。\n\n**32. LLM 的下一个标记预测定律（A Law of Next-Token Prediction in Large Language Models）**  \n论文揭示 LLM 中上下文标记嵌入学习的定律：每个层级对预测准确性贡献相等，适用于 Transformer、RWKV 和 Mamba 等架构。这为模型缩放、预训练和信息流设计提供指导，强调 LLM 内部机制的细粒度理解，是 AI 理论研究的亮点。\n\n**22. 通过物理感知重编程的 LLM 增强时空预测（Language Model Empowered Spatio-Temporal Forecasting via Physics-Aware Reprogramming）**  \n论文提出 RePST 框架，利用 LLM 的推理能力通过物理感知分解器处理时空数据，在数据稀缺场景下提升预测准确性。实验显示其在真实数据集上优于基线，对于交通和气候预测有应用潜力。\n\n其他论文中，快速提一下几篇有应用价值的：  \n- **4. 面向复杂过程工程图的人类级理解多代理框架（Towards Human-Level Understanding of Complex Process Engineering Schematics: A Pedagogical, Introspective Multi-Agent Framework for Open-Domain Question Answering）**：使用多代理 RAG 框架提升 PFD 和 P&ID 图的问答性能，提供安全的企业解决方案。  \n- **5. 层次网络融合用于多模态电子显微镜表示学习（Hierarchical Network Fusion for Multi-Modal Electron Micrograph Representation Learning with Foundational Large Language Models）**：融合视觉图和 LLM 描述，实现纳米材料分类，优于传统方法。  \n- **18. 平衡 LLM 生成的多样性和风险（Balancing Diversity and Risk in LLM Sampling: How to Select Your Method and Parameter for Open-Ended Text Generation）**：提供截断采样的系统指南，基于前缀树评估权衡，帮助优化文本生成。  \n- 其余如音频过滤（8）、选举模型（9）和异常检测（21）等论文虽有贡献，但相对应用性较窄，故从简不详述。\n\n今天的更新展示 AI 领域的多样创新，LLM 优化和隐私技术尤为值得跟踪。如果你对特定主题感兴趣，建议查看这些论文的完整摘要！",
  "papers": [
    {
      "arxiv_id": "2408.16017v1",
      "title": "Differentially Private Publication of Electricity Time Series Data in Smart Grids",
      "title_zh": "翻译失败",
      "authors": [
        "Sina Shaham",
        "Gabriel Ghinita",
        "Bhaskar Krishnamachari",
        "Cyrus Shahabi"
      ],
      "abstract": "Smart grids are a valuable data source to study consumer behavior and guide\nenergy policy decisions. In particular, time-series of power consumption over\ngeographical areas are essential in deciding the optimal placement of expensive\nresources (e.g., transformers, storage elements) and their activation\nschedules. However, publication of such data raises significant privacy issues,\nas it may reveal sensitive details about personal habits and lifestyles.\nDifferential privacy (DP) is well-suited for sanitization of individual data,\nbut current DP techniques for time series lead to significant loss in utility,\ndue to the existence of temporal correlation between data readings. We\nintroduce {\\em STPT (Spatio-Temporal Private Timeseries)}, a novel method for\nDP-compliant publication of electricity consumption data that analyzes\nspatio-temporal attributes and captures both micro and macro patterns by\nleveraging RNNs. Additionally, it employs a partitioning method for releasing\nelectricity consumption time series based on identified patterns. We\ndemonstrate through extensive experiments, on both real-world and synthetic\ndatasets, that STPT significantly outperforms existing benchmarks, providing a\nwell-balanced trade-off between data utility and user privacy.",
      "tldr_zh": "本研究针对智能电网电力时间序列数据的发布问题，提出了一种基于差分隐私(DP)的创新方法STPT(Spatio-Temporal Private Timeseries)，以解决现有技术在处理时间相关性时导致的数据效用损失。该方法利用RNNs分析时空属性，捕捉微观和宏观模式，并通过分区技术发布电力消耗数据，从而在保护用户隐私的同时保留数据价值。通过在真实和合成数据集上的广泛实验，STPT显著优于现有基准，提供了一个数据效用与隐私保护之间的良好平衡。",
      "categories": [
        "cs.CR",
        "cs.AI",
        "cs.LG"
      ],
      "primary_category": "cs.CR",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2408.16017v1",
      "published_date": "2024-08-24 23:30:09 UTC",
      "updated_date": "2024-08-24 23:30:09 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-19T18:28:30.919594"
    },
    {
      "arxiv_id": "2408.13684v1",
      "title": "Evaluating Alternative Training Interventions Using Personalized Computational Models of Learning",
      "title_zh": "翻译失败",
      "authors": [
        "Christopher James MacLellan",
        "Kimberly Stowers",
        "Lisa Brady"
      ],
      "abstract": "Evaluating different training interventions to determine which produce the\nbest learning outcomes is one of the main challenges faced by instructional\ndesigners. Typically, these designers use A/B experiments to evaluate each\nintervention; however, it is costly and time consuming to run such studies. To\naddress this issue, we explore how computational models of learning might\nsupport designers in reasoning causally about alternative interventions within\na fractions tutor. We present an approach for automatically tuning models to\nspecific individuals and show that personalized models make better predictions\nof students' behavior than generic ones. Next, we conduct simulations to\ngenerate counterfactual predictions of performance and learning for two\nstudents (high and low performing) in different versions of the fractions\ntutor. Our approach makes predictions that align with previous human findings,\nas well as testable predictions that might be evaluated with future human\nexperiments.",
      "tldr_zh": "这篇论文探讨了使用个性化计算模型（personalized computational models）来评估不同训练干预措施，以解决教学设计师在确定最佳学习成果时面临的 A/B 实验耗时问题。研究者提出了一种自动调整模型以适应特定个体的方法，并在分数导师（fractions tutor）中测试，结果显示个性化模型比通用模型更准确地预测学生行为。通过模拟生成反事实预测（counterfactual predictions），论文为高绩效和低绩效学生在不同导师版本中的表现提供了可测试的预测，这些预测与先前人类研究一致，并为未来实验提供了新见解。",
      "categories": [
        "cs.AI",
        "cs.CY",
        "cs.HC"
      ],
      "primary_category": "cs.AI",
      "comment": "18 pages, 7 figures",
      "pdf_url": "http://arxiv.org/pdf/2408.13684v1",
      "published_date": "2024-08-24 22:51:57 UTC",
      "updated_date": "2024-08-24 22:51:57 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-19T18:28:43.072315"
    },
    {
      "arxiv_id": "2408.13683v2",
      "title": "Submodular Maximization Approaches for Equitable Client Selection in Federated Learning",
      "title_zh": "亚模函数最大化方法用于联邦学习中的公平客户端选择",
      "authors": [
        "Andrés Catalino Castillo Jiménez",
        "Ege C. Kaya",
        "Lintao Ye",
        "Abolfazl Hashemi"
      ],
      "abstract": "In a conventional Federated Learning framework, client selection for training\ntypically involves the random sampling of a subset of clients in each\niteration. However, this random selection often leads to disparate performance\namong clients, raising concerns regarding fairness, particularly in\napplications where equitable outcomes are crucial, such as in medical or\nfinancial machine learning tasks. This disparity typically becomes more\npronounced with the advent of performance-centric client sampling techniques.\nThis paper introduces two novel methods, namely SUBTRUNC and UNIONFL, designed\nto address the limitations of random client selection. Both approaches utilize\nsubmodular function maximization to achieve more balanced models. By modifying\nthe facility location problem, they aim to mitigate the fairness concerns\nassociated with random selection. SUBTRUNC leverages client loss information to\ndiversify solutions, while UNIONFL relies on historical client selection data\nto ensure a more equitable performance of the final model. Moreover, these\nalgorithms are accompanied by robust theoretical guarantees regarding\nconvergence under reasonable assumptions. The efficacy of these methods is\ndemonstrated through extensive evaluations across heterogeneous scenarios,\nrevealing significant improvements in fairness as measured by a client\ndissimilarity metric.",
      "tldr_zh": "本论文针对联邦学习中随机客户端选择的公平性问题，提出两种新方法：SUBTRUNC 和 UNIONFL，以解决传统方法导致的性能不均等问题。SUBTRUNC 通过利用客户端损失信息和 submodular function maximization 来多样化解决方案，而 UNIONFL 依赖历史客户端选择数据，修改 facility location 问题以实现更均衡的模型性能。这两种方法提供 robust 理论收敛保证，并在异构场景的广泛实验中显示出显著改善，特别是在客户端差异度量上的公平性提升。",
      "categories": [
        "cs.LG",
        "cs.AI",
        "cs.SY",
        "eess.SP",
        "eess.SY"
      ],
      "primary_category": "cs.LG",
      "comment": "13 pages",
      "pdf_url": "http://arxiv.org/pdf/2408.13683v2",
      "published_date": "2024-08-24 22:40:31 UTC",
      "updated_date": "2024-08-27 19:27:07 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-19T18:28:55.246854"
    },
    {
      "arxiv_id": "2409.00082v1",
      "title": "Towards Human-Level Understanding of Complex Process Engineering Schematics: A Pedagogical, Introspective Multi-Agent Framework for Open-Domain Question Answering",
      "title_zh": "翻译失败",
      "authors": [
        "Sagar Srinivas Sakhinana",
        "Geethan Sannidhi",
        "Venkataramana Runkana"
      ],
      "abstract": "In the chemical and process industries, Process Flow Diagrams (PFDs) and\nPiping and Instrumentation Diagrams (P&IDs) are critical for design,\nconstruction, and maintenance. Recent advancements in Generative AI, such as\nLarge Multimodal Models (LMMs) like GPT4 (Omni), have shown promise in\nunderstanding and interpreting process diagrams for Visual Question Answering\n(VQA). However, proprietary models pose data privacy risks, and their\ncomputational complexity prevents knowledge editing for domain-specific\ncustomization on consumer hardware. To overcome these challenges, we propose a\nsecure, on-premises enterprise solution using a hierarchical, multi-agent\nRetrieval Augmented Generation (RAG) framework for open-domain question\nanswering (ODQA) tasks, offering enhanced data privacy, explainability, and\ncost-effectiveness. Our novel multi-agent framework employs introspective and\nspecialized sub-agents using open-source, small-scale multimodal models with\nthe ReAct (Reason+Act) prompting technique for PFD and P&ID analysis,\nintegrating multiple information sources to provide accurate and contextually\nrelevant answers. Our approach, supported by iterative self-correction, aims to\ndeliver superior performance in ODQA tasks. We conducted rigorous experimental\nstudies, and the empirical results validated the proposed approach\neffectiveness.",
      "tldr_zh": "本研究针对化学和过程工业中的Process Flow Diagrams (PFDs) 和Piping and Instrumentation Diagrams (P&IDs)，提出了一种分层多智能体Retrieval Augmented Generation (RAG)框架，用于实现开放域问答(Open-Domain Question Answering, ODQA)，以达到接近人类水平的图表理解。框架采用开源小规模多模态模型结合ReAct (Reason+Act)提示技术、内省和专业子智能体，整合多种信息来源，并通过迭代自校正机制提升答案的准确性和相关性。该方法解决了现有Large Multimodal Models (LMMs)如GPT-4的隐私风险和计算复杂性问题，并在实验中验证了其有效性，提供更好的数据隐私、可解释性和成本效益。",
      "categories": [
        "cs.CL",
        "cs.AI",
        "cs.CV",
        "cs.LG"
      ],
      "primary_category": "cs.CL",
      "comment": "Our paper is accepted for publication at ML4CCE workshop at ECML PKDD\n  2024",
      "pdf_url": "http://arxiv.org/pdf/2409.00082v1",
      "published_date": "2024-08-24 19:34:04 UTC",
      "updated_date": "2024-08-24 19:34:04 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-19T18:29:08.267096"
    },
    {
      "arxiv_id": "2408.13661v1",
      "title": "Hierarchical Network Fusion for Multi-Modal Electron Micrograph Representation Learning with Foundational Large Language Models",
      "title_zh": "翻译失败",
      "authors": [
        "Sakhinana Sagar Srinivas",
        "Geethan Sannidhi",
        "Venkataramana Runkana"
      ],
      "abstract": "Characterizing materials with electron micrographs is a crucial task in\nfields such as semiconductors and quantum materials. The complex hierarchical\nstructure of micrographs often poses challenges for traditional classification\nmethods. In this study, we propose an innovative backbone architecture for\nanalyzing electron micrographs. We create multi-modal representations of the\nmicrographs by tokenizing them into patch sequences and, additionally,\nrepresenting them as vision graphs, commonly referred to as patch attributed\ngraphs. We introduce the Hierarchical Network Fusion (HNF), a multi-layered\nnetwork structure architecture that facilitates information exchange between\nthe multi-modal representations and knowledge integration across different\npatch resolutions. Furthermore, we leverage large language models (LLMs) to\ngenerate detailed technical descriptions of nanomaterials as auxiliary\ninformation to assist in the downstream task. We utilize a cross-modal\nattention mechanism for knowledge fusion across cross-domain\nrepresentations(both image-based and linguistic insights) to predict the\nnanomaterial category. This multi-faceted approach promises a more\ncomprehensive and accurate representation and classification of micrographs for\nnanomaterial identification. Our framework outperforms traditional methods,\novercoming challenges posed by distributional shifts, and facilitating\nhigh-throughput screening.",
      "tldr_zh": "该研究针对电子显微镜图像在材料科学中的复杂层次结构分类挑战，提出了一种创新的骨干架构，通过将图像转化为多模态表示（包括 patch sequences 和 patch attributed graphs）。他们引入了 Hierarchical Network Fusion (HNF)，一个多层网络结构，用于在不同 patch resolutions 之间交换信息，并利用 Large Language Models (LLMs) 生成纳米材料的技术描述作为辅助输入，再通过 cross-modal attention 机制融合图像和语言表示，以提升分类准确性。该框架在纳米材料识别任务中超越传统方法，成功克服分布偏移问题，并促进高通量筛选的应用。",
      "categories": [
        "cs.CV",
        "cs.AI",
        "cs.LG"
      ],
      "primary_category": "cs.CV",
      "comment": "Our paper is published at the workshop on Robustness of Few-shot and\n  Zero-shot Learning in Foundation Models at NeurIPS 2023",
      "pdf_url": "http://arxiv.org/pdf/2408.13661v1",
      "published_date": "2024-08-24 19:24:44 UTC",
      "updated_date": "2024-08-24 19:24:44 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-19T18:29:20.625268"
    },
    {
      "arxiv_id": "2408.13659v3",
      "title": "ReactZyme: A Benchmark for Enzyme-Reaction Prediction",
      "title_zh": "ReactZyme：酶反应预测基准",
      "authors": [
        "Chenqing Hua",
        "Bozitao Zhong",
        "Sitao Luan",
        "Liang Hong",
        "Guy Wolf",
        "Doina Precup",
        "Shuangjia Zheng"
      ],
      "abstract": "Enzymes, with their specific catalyzed reactions, are necessary for all\naspects of life, enabling diverse biological processes and adaptations.\nPredicting enzyme functions is essential for understanding biological pathways,\nguiding drug development, enhancing bioproduct yields, and facilitating\nevolutionary studies. Addressing the inherent complexities, we introduce a new\napproach to annotating enzymes based on their catalyzed reactions. This method\nprovides detailed insights into specific reactions and is adaptable to newly\ndiscovered reactions, diverging from traditional classifications by protein\nfamily or expert-derived reaction classes. We employ machine learning\nalgorithms to analyze enzyme reaction datasets, delivering a much more refined\nview on the functionality of enzymes. Our evaluation leverages the largest\nenzyme-reaction dataset to date, derived from the SwissProt and Rhea databases\nwith entries up to January 8, 2024. We frame the enzyme-reaction prediction as\na retrieval problem, aiming to rank enzymes by their catalytic ability for\nspecific reactions. With our model, we can recruit proteins for novel reactions\nand predict reactions in novel proteins, facilitating enzyme discovery and\nfunction annotation (https://github.com/WillHua127/ReactZyme).",
      "tldr_zh": "本研究引入ReactZyme基准，用于酶反应预测（Enzyme-Reaction Prediction），旨在通过基于催化的反应注释酶功能，提供比传统蛋白质家族分类更详细且适配新反应的方法。研究采用机器学习算法分析酶反应数据集，将预测问题 framing 为检索问题，以排名酶的催化能力。基于截至2024年1月8日的SwissProt和Rhea数据库构建的迄今最大数据集，模型能够为新反应招募蛋白质并预测新蛋白质的反应，促进酶发现和功能注释（GitHub：https://github.com/WillHua127/ReactZyme）。",
      "categories": [
        "cs.LG",
        "cs.AI",
        "cs.CE",
        "q-bio.QM"
      ],
      "primary_category": "cs.LG",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2408.13659v3",
      "published_date": "2024-08-24 19:19:33 UTC",
      "updated_date": "2024-10-01 02:12:41 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-19T18:29:32.116209"
    },
    {
      "arxiv_id": "2408.14508v2",
      "title": "Artificial intelligence for science: The easy and hard problems",
      "title_zh": "翻译失败",
      "authors": [
        "Ruairidh M. Battleday",
        "Samuel J. Gershman"
      ],
      "abstract": "A suite of impressive scientific discoveries have been driven by recent\nadvances in artificial intelligence. These almost all result from training\nflexible algorithms to solve difficult optimization problems specified in\nadvance by teams of domain scientists and engineers with access to large\namounts of data. Although extremely useful, this kind of problem solving only\ncorresponds to one part of science - the \"easy problem.\" The other part of\nscientific research is coming up with the problem itself - the \"hard problem.\"\nSolving the hard problem is beyond the capacities of current algorithms for\nscientific discovery because it requires continual conceptual revision based on\npoorly defined constraints. We can make progress on understanding how humans\nsolve the hard problem by studying the cognitive science of scientists, and\nthen use the results to design new computational agents that automatically\ninfer and update their scientific paradigms.",
      "tldr_zh": "该论文讨论了人工智能(AI)在科学中的应用，将科学问题分为“easy problem”（通过训练算法解决预定义的优化问题，如利用大量数据驱动发现）和“hard problem”（提出问题本身，需要基于模糊约束的持续概念修订）。当前AI算法仅能有效处理easy problem，而无法应对hard problem，因为它涉及人类式的创新和概念更新。作者建议通过研究科学家的认知科学，设计新计算代理来自动推断和更新科学范式，从而推动AI在更全面科学发现中的潜力。",
      "categories": [
        "cs.AI",
        "cs.LG",
        "q-bio.NC"
      ],
      "primary_category": "cs.AI",
      "comment": "16 pages, 3 boxes, 5 figures",
      "pdf_url": "http://arxiv.org/pdf/2408.14508v2",
      "published_date": "2024-08-24 18:22:06 UTC",
      "updated_date": "2024-12-17 01:55:42 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-19T18:29:42.860132"
    },
    {
      "arxiv_id": "2408.13644v1",
      "title": "Studying the Effect of Audio Filters in Pre-Trained Models for Environmental Sound Classification",
      "title_zh": "翻译失败",
      "authors": [
        "Aditya Dawn",
        "Wazib Ansar"
      ],
      "abstract": "Environmental Sound Classification is an important problem of sound\nrecognition and is more complicated than speech recognition problems as\nenvironmental sounds are not well structured with respect to time and\nfrequency. Researchers have used various CNN models to learn audio features\nfrom different audio features like log mel spectrograms, gammatone spectral\ncoefficients, mel-frequency spectral coefficients, generated from the audio\nfiles, over the past years. In this paper, we propose a new methodology :\nTwo-Level Classification; the Level 1 Classifier will be responsible to\nclassify the audio signal into a broader class and the Level 2 Classifiers will\nbe responsible to find the actual class to which the audio belongs, based on\nthe output of the Level 1 Classifier. We have also shown the effects of\ndifferent audio filters, among which a new method of Audio Crop is introduced\nin this paper, which gave the highest accuracies in most of the cases. We have\nused the ESC-50 dataset for our experiment and obtained a maximum accuracy of\n78.75% in case of Level 1 Classification and 98.04% in case of Level 2\nClassifications.",
      "tldr_zh": "本文研究了音频过滤器对预训练模型在环境声音分类中的影响，强调了环境声音相对于语音识别的复杂性，如时间和频率的不结构化。作者提出了一种Two-Level Classification方法，其中Level 1分类器负责将音频信号归类到更宽泛的类别，Level 2分类器则基于此输出确定具体类别，并引入了新的Audio Crop过滤器以提升准确率。在ESC-50数据集实验中，该方法实现了Level 1分类最高78.75%的准确率和Level 2分类最高98.04%的准确率，Audio Crop过滤器在多数情况下表现最佳。",
      "categories": [
        "cs.SD",
        "cs.AI",
        "eess.AS"
      ],
      "primary_category": "cs.SD",
      "comment": "19 pages, 16 figures",
      "pdf_url": "http://arxiv.org/pdf/2408.13644v1",
      "published_date": "2024-08-24 18:13:07 UTC",
      "updated_date": "2024-08-24 18:13:07 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-19T18:29:58.154847"
    },
    {
      "arxiv_id": "2408.13637v2",
      "title": "Temporal Elections: Welfare, Strategyproofness, and Proportionality",
      "title_zh": "时序选举：福利、策略证明性和比例性",
      "authors": [
        "Edith Elkind",
        "Tzeh Yuan Neoh",
        "Nicholas Teh"
      ],
      "abstract": "We investigate a model of sequential decision-making where a single\nalternative is chosen at each round. We focus on two objectives -- utilitarian\nwelfare (Util) and egalitarian welfare (Egal) -- and consider the computational\ncomplexity of maximizing these objectives, as well as their compatibility with\nstrategyproofness and proportionality. We observe that maximizing Util is easy,\nbut the corresponding decision problem for Egal is NP-complete even in\nrestricted cases. We complement this hardness result for Egal with\nparameterized complexity analysis and an approximation algorithm. Additionally,\nwe show that, while a mechanism that outputs an outcome that maximizes Util is\nstrategyproof, all deterministic mechanisms for computing outcomes that\nmaximize Egal fail a very weak variant of strategyproofness, called non-obvious\nmanipulability (NOM). However, we show that when agents have non-empty approval\nsets at each timestep, choosing an Egal-maximizing outcome while breaking ties\nlexicographically satisfies NOM. Regarding proportionality, we prove that a\nproportional (PROP) outcome can be computed efficiently, but finding an outcome\nthat maximizes Util while guaranteeing PROP is NP-hard. We also derive upper\nand lower bounds on the (strong) price of proportionality with respect to Util\nand Egal. Some of our results extend to $p$-mean welfare measures other than\nEgal and Util.",
      "tldr_zh": "这篇论文研究了顺序决策模型中的备选方案选择，聚焦于功利主义福利 (Util) 和平等主义福利 (Egal) 的最大化问题。作者分析了这些目标的计算复杂性，发现最大化 Util 计算简单且机制策略证明 (strategyproof)，而最大化 Egal 即使在限制情况下也是 NP-complete，并提供了参数化复杂性分析和近似算法。对于策略证明性，他们证明了所有确定性 Egal 最大化机制失败弱策略证明性 (NOM)，但在代理人批准集非空时，通过字典序破平可满足 NOM；同时，计算比例性 (PROP) 结果是有效的，但最大化 Util 同时保证 PROP 是 NP-hard。论文还给出了比例性对 Util 和 Egal 的价格界限，并扩展到其他 p-均福利措施。",
      "categories": [
        "cs.GT",
        "cs.AI"
      ],
      "primary_category": "cs.GT",
      "comment": "Appears in the 27th European Conference on Artificial Intelligence\n  (ECAI), 2024",
      "pdf_url": "http://arxiv.org/pdf/2408.13637v2",
      "published_date": "2024-08-24 17:52:26 UTC",
      "updated_date": "2024-12-20 13:29:43 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-19T18:30:10.015723"
    },
    {
      "arxiv_id": "2409.06708v1",
      "title": "Ensuring Fairness with Transparent Auditing of Quantitative Bias in AI Systems",
      "title_zh": "翻译失败",
      "authors": [
        "Chih-Cheng Rex Yuan",
        "Bow-Yaw Wang"
      ],
      "abstract": "With the rapid advancement of AI, there is a growing trend to integrate AI\ninto decision-making processes. However, AI systems may exhibit biases that\nlead decision-makers to draw unfair conclusions. Notably, the COMPAS system\nused in the American justice system to evaluate recidivism was found to favor\nracial majority groups; specifically, it violates a fairness standard called\nequalized odds. Various measures have been proposed to assess AI fairness. We\npresent a framework for auditing AI fairness, involving third-party auditors\nand AI system providers, and we have created a tool to facilitate systematic\nexamination of AI systems. The tool is open-sourced and publicly available.\nUnlike traditional AI systems, we advocate a transparent white-box and\nstatistics-based approach. It can be utilized by third-party auditors, AI\ndevelopers, or the general public for reference when judging the fairness\ncriterion of AI systems.",
      "tldr_zh": "这篇论文探讨了 AI 系统中的量化偏见问题，例如 COMPAS 系统在美国司法决策中违反 equalized odds 公平标准，导致种族不公。作者提出一个透明审计框架，涉及第三方审计员和 AI 提供者，并开发了一个开源工具，用于系统地评估 AI 公平性。工具采用白-box 和基于统计的方法，便于 AI 开发者、审计员或公众参考，从而促进更公平的 AI 决策。",
      "categories": [
        "cs.CY",
        "cs.AI",
        "cs.HC"
      ],
      "primary_category": "cs.CY",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2409.06708v1",
      "published_date": "2024-08-24 17:16:50 UTC",
      "updated_date": "2024-08-24 17:16:50 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-19T18:30:20.789589"
    },
    {
      "arxiv_id": "2408.13630v1",
      "title": "DeepVoting: Learning Voting Rules with Tailored Embeddings",
      "title_zh": "翻译失败",
      "authors": [
        "Leonardo Matone",
        "Ben Abramowitz",
        "Nicholas Mattei",
        "Avinash Balakrishnan"
      ],
      "abstract": "Aggregating the preferences of multiple agents into a collective decision is\na common step in many important problems across areas of computer science\nincluding information retrieval, reinforcement learning, and recommender\nsystems. As Social Choice Theory has shown, the problem of designing algorithms\nfor aggregation rules with specific properties (axioms) can be difficult, or\nprovably impossible in some cases. Instead of designing algorithms by hand, one\ncan learn aggregation rules, particularly voting rules, from data. However, the\nprior work in this area has required extremely large models, or been limited by\nthe choice of preference representation, i.e., embedding. We recast the problem\nof designing a good voting rule into one of learning probabilistic versions of\nvoting rules that output distributions over a set of candidates. Specifically,\nwe use neural networks to learn probabilistic social choice functions from the\nliterature. We show that embeddings of preference profiles derived from the\nsocial choice literature allows us to learn existing voting rules more\nefficiently and scale to larger populations of voters more easily than other\nwork if the embedding is tailored to the learning objective. Moreover, we show\nthat rules learned using embeddings can be tweaked to create novel voting rules\nwith improved axiomatic properties. Namely, we show that existing voting rules\nrequire only minor modification to combat a probabilistic version of the No\nShow Paradox.",
      "tldr_zh": "该论文探讨了通过学习投票规则（voting rules）来聚合多个代理偏好的问题，以应用于信息检索、强化学习和推荐系统等领域。作者提出DeepVoting方法，使用神经网络学习概率版本的投票规则，并采用量身定制的嵌入（tailored embeddings）来表示偏好配置文件，从而更高效地学习现有投票规则并扩展到更大规模的选民群体。实验结果显示，这种方法不仅提高了学习效率，还能通过微调嵌入创建新型投票规则，提升公理属性，如缓解概率版本的No Show Paradox。",
      "categories": [
        "cs.MA",
        "cs.AI",
        "cs.GT",
        "cs.LG",
        "econ.GN",
        "q-fin.EC"
      ],
      "primary_category": "cs.MA",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2408.13630v1",
      "published_date": "2024-08-24 17:15:20 UTC",
      "updated_date": "2024-08-24 17:15:20 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-19T18:30:35.264865"
    },
    {
      "arxiv_id": "2408.13628v2",
      "title": "Enhancing Uplift Modeling in Multi-Treatment Marketing Campaigns: Leveraging Score Ranking and Calibration Techniques",
      "title_zh": "增强多处理营销活动中的提升建模：利用得分排名和校准技术",
      "authors": [
        "Yoon Tae Park",
        "Ting Xu",
        "Mohamed Anany"
      ],
      "abstract": "Uplift modeling is essential for optimizing marketing strategies by selecting\nindividuals likely to respond positively to specific marketing campaigns. This\nimportance escalates in multi-treatment marketing campaigns, where diverse\ntreatment is available and we may want to assign the customers to treatment\nthat can make the most impact. While there are existing approaches with\nconvenient frameworks like Causalml, there are potential spaces to enhance the\neffect of uplift modeling in multi treatment cases. This paper introduces a\nnovel approach to uplift modeling in multi-treatment campaigns, leveraging\nscore ranking and calibration techniques to improve overall performance of the\nmarketing campaign. We review existing uplift models, including Meta Learner\nframeworks (S, T, X), and their application in real-world scenarios.\nAdditionally, we delve into insights from multi-treatment studies to highlight\nthe complexities and potential advancements in the field. Our methodology\nincorporates Meta-Learner calibration and a scoring rank-based offer selection\nstrategy. Extensive experiment results with real-world datasets demonstrate the\npractical benefits and superior performance of our approach. The findings\nunderscore the critical role of integrating score ranking and calibration\ntechniques in refining the performance and reliability of uplift predictions,\nthereby advancing predictive modeling in marketing analytics and providing\nactionable insights for practitioners seeking to optimize their campaign\nstrategies.",
      "tldr_zh": "这篇论文针对多治疗营销活动中的提升建模（uplift modeling），提出了一种新方法，通过分数排名（score ranking）和校准技术（calibration techniques）来优化营销策略。该方法整合了Meta Learner框架的校准以及基于分数排名的优惠选择策略，以更好地处理多治疗场景的复杂性。实验结果显示，该方法在真实数据集上表现出色，显著提高了提升预测的性能和可靠性，为营销分析提供可操作的见解。",
      "categories": [
        "stat.ML",
        "cs.AI",
        "cs.LG",
        "stat.AP"
      ],
      "primary_category": "stat.ML",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2408.13628v2",
      "published_date": "2024-08-24 17:10:59 UTC",
      "updated_date": "2024-08-27 12:53:22 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-19T18:30:45.287229"
    },
    {
      "arxiv_id": "2408.14507v3",
      "title": "Prompt-Matcher: Leveraging Large Models to Reduce Uncertainty in Schema Matching Results",
      "title_zh": "Prompt-Matcher：利用大型模型减少模式匹配结果中的不确定性",
      "authors": [
        "Longyu Feng",
        "Huahang Li",
        "Chen Jason Zhang"
      ],
      "abstract": "Schema matching is the process of identifying correspondences between the\nelements of two given schemata, essential for database management systems, data\nintegration, and data warehousing. For datasets across different scenarios, the\noptimal schema matching algorithm is different. For single algorithm,\nhyperparameter tuning also cases multiple results. All results assigned equal\nprobabilities are stored in probabilistic databases to facilitate uncertainty\nmanagement. The substantial degree of uncertainty diminishes the efficiency and\nreliability of data processing, thereby precluding the provision of more\naccurate information for decision-makers. To address this problem, we introduce\na new approach based on fine-grained correspondence verification with specific\nprompt of Large Language Model.\n  Our approach is an iterative loop that consists of three main components: (1)\nthe correspondence selection algorithm, (2) correspondence verification, and\n(3) the update of probability distribution. The core idea is that\ncorrespondences intersect across multiple results, thereby linking the\nverification of correspondences to the reduction of uncertainty in candidate\nresults.\n  The task of selecting an optimal correspondence set to maximize the\nanticipated uncertainty reduction within a fixed budgetary framework is\nestablished as an NP-hard problem. We propose a novel $(1-1/e)$-approximation\nalgorithm that significantly outperforms brute algorithm in terms of\ncomputational efficiency. To enhance correspondence verification, we have\ndeveloped two prompt templates that enable GPT-4 to achieve state-of-the-art\nperformance across two established benchmark datasets. Our comprehensive\nexperimental evaluation demonstrates the superior effectiveness and robustness\nof the proposed approach.",
      "tldr_zh": "该论文针对 schema matching 中的不确定性问题（如算法差异和超参数调整导致的多重结果），提出 Prompt-Matcher 方法，利用 Large Language Models 通过细粒度对应验证来减少不确定性。该方法采用一个迭代循环，包括对应选择算法（correspondence selection algorithm）、对应验证和概率分布更新，核心思想是通过验证交叉出现的对应关系来优化结果，并将选择最佳对应集的问题建模为 NP-hard 问题，提供了一个 (1-1/e)-approximation 算法以提升计算效率。实验评估显示，该方法在两个基准数据集上实现了最先进性能，显著提高了 schema matching 的有效性和鲁棒性。",
      "categories": [
        "cs.DB",
        "cs.AI"
      ],
      "primary_category": "cs.DB",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2408.14507v3",
      "published_date": "2024-08-24 16:54:08 UTC",
      "updated_date": "2025-03-06 10:26:32 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-19T18:31:00.022679"
    },
    {
      "arxiv_id": "2408.13626v1",
      "title": "Towards Case-based Interpretability for Medical Federated Learning",
      "title_zh": "翻译失败",
      "authors": [
        "Laura Latorre",
        "Liliana Petrychenko",
        "Regina Beets-Tan",
        "Taisiya Kopytova",
        "Wilson Silva"
      ],
      "abstract": "We explore deep generative models to generate case-based explanations in a\nmedical federated learning setting. Explaining AI model decisions through\ncase-based interpretability is paramount to increasing trust and allowing\nwidespread adoption of AI in clinical practice. However, medical AI training\nparadigms are shifting towards federated learning settings in order to comply\nwith data protection regulations. In a federated scenario, past data is\ninaccessible to the current user. Thus, we use a deep generative model to\ngenerate synthetic examples that protect privacy and explain decisions. Our\nproof-of-concept focuses on pleural effusion diagnosis and uses publicly\navailable Chest X-ray data.",
      "tldr_zh": "本文探讨了在医疗联邦学习(federated learning)环境中，使用深度生成模型(deep generative models)生成基于案例(case-based interpretability)的解释，以提升AI决策的可解释性并增加临床信任。研究方法通过合成示例保护患者隐私，解决联邦场景中数据不可访问的挑战。概念验证集中在胸腔积液诊断上，使用公开的胸部X光数据，展示了这种方法在符合数据保护法规的同时，促进AI在医疗实践中的广泛采用。",
      "categories": [
        "cs.LG",
        "cs.AI"
      ],
      "primary_category": "cs.LG",
      "comment": "\\c{opyright} 20XX IEEE. Personal use of this material is permitted.\n  Permission from IEEE must be obtained for all other uses, in any current or\n  future media, including reprinting/republishing this material for advertising\n  or promotional purposes, creating new collective works, for resale or\n  redistribution to servers or lists, or reuse of any copyrighted component of\n  this work in other works",
      "pdf_url": "http://arxiv.org/pdf/2408.13626v1",
      "published_date": "2024-08-24 16:42:12 UTC",
      "updated_date": "2024-08-24 16:42:12 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-19T18:31:09.407979"
    },
    {
      "arxiv_id": "2408.13624v1",
      "title": "No Dataset Needed for Downstream Knowledge Benchmarking: Response Dispersion Inversely Correlates with Accuracy on Domain-specific QA",
      "title_zh": "翻译失败",
      "authors": [
        "Robert L Simione II"
      ],
      "abstract": "This research seeks to obviate the need for creating QA datasets and grading\n(chatbot) LLM responses when comparing LLMs' knowledge in specific topic\ndomains. This is done in an entirely end-user centric way without need for\naccess to any inner workings of the LLM, so long as it can be prompted and\ngiven a random seed to create different generations to the same prompt. The\npaper does this by, for a given topic domain, defining the \"response\ndispersion\" of an LLM by repeatedly asking an LLM the same opinion question\nabout that topic domain. Namely, the response dispersion is the count of\nsingular values needed to explain 95% of the variance in the embedding matrix\nof the LLM's responses. It is found that the response dispersion is inversely\ncorrelated with accuracy on relevant QA evaluations (average spearman rank\ncorrelation stronger than -.59). A use-case analysis shows that when comparing\ntwo different LLMs on the same topic domain, comparing their response\ndispersion is a suitable replacement for comparing their QA accuracy between\n74% and 89% of the time, the range depending on certain reasonable\naccuracy-difference tolerances that may be acceptable to an end-user in\nexchange for the labor being saved using response dispersion instead of QA\naccuracy for comparison. Two response embeddings are studied for creating the\nembedding matrix in this study, one is from OpenAI's APIs and one is a novel\nembedding, here named reference sentence similarity embeddings, that can be\ncomputed locally and performs very nearly as well in calculating response\ndispersion. Also in this research, a pre-existing dataset called the IRC-Wiki\nTrivia dataset, originally developed for trivia games, has been re-purposed,\ncurated, and the curation, called IRC-WikiTriviaQA, is made available for the\npurpose of this research.",
      "tldr_zh": "这篇论文提出了一种无需创建QA数据集的方法，通过计算LLMs的“response dispersion”（响应分散度）来评估和比较LLMs在特定主题领域的知识，该指标基于重复询问同一意见问题并分析响应嵌入矩阵的奇异值分解。研究发现，response dispersion与相关QA准确率呈负相关（Spearman rank correlation强于-0.59），表明分散度越高，准确率越低。作者证明，在比较不同LLMs时，使用response dispersion作为替代指标可在74%至89%的场景中准确预测QA性能，从而节省评估劳动力；此外，还引入了新型“reference sentence similarity embeddings”并发布了IRC-WikiTriviaQA数据集以支持进一步研究。",
      "categories": [
        "cs.CL",
        "cs.AI",
        "I.2.7"
      ],
      "primary_category": "cs.CL",
      "comment": "16 pages, 3 tables, 1 figure",
      "pdf_url": "http://arxiv.org/pdf/2408.13624v1",
      "published_date": "2024-08-24 16:35:00 UTC",
      "updated_date": "2024-08-24 16:35:00 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-19T18:31:22.864422"
    },
    {
      "arxiv_id": "2408.13622v1",
      "title": "Advancing Enterprise Spatio-Temporal Forecasting Applications: Data Mining Meets Instruction Tuning of Language Models For Multi-modal Time Series Analysis in Low-Resource Settings",
      "title_zh": "翻译失败",
      "authors": [
        "Sagar Srinivas Sakhinana",
        "Geethan Sannidhi",
        "Chidaksh Ravuru",
        "Venkataramana Runkana"
      ],
      "abstract": "Spatio-temporal forecasting is crucial in transportation, logistics, and\nsupply chain management. However, current methods struggle with large, complex\ndatasets. We propose a dynamic, multi-modal approach that integrates the\nstrengths of traditional forecasting methods and instruction tuning of small\nlanguage models for time series trend analysis. This approach utilizes a\nmixture of experts (MoE) architecture with parameter-efficient fine-tuning\n(PEFT) methods, tailored for consumer hardware to scale up AI solutions in low\nresource settings while balancing performance and latency tradeoffs.\nAdditionally, our approach leverages related past experiences for similar input\ntime series to efficiently handle both intra-series and inter-series\ndependencies of non-stationary data with a time-then-space modeling approach,\nusing grouped-query attention, while mitigating the limitations of traditional\nforecasting techniques in handling distributional shifts. Our approach models\npredictive uncertainty to improve decision-making. Our framework enables\non-premises customization with reduced computational and memory demands, while\nmaintaining inference speed and data privacy/security. Extensive experiments on\nvarious real-world datasets demonstrate that our framework provides robust and\naccurate forecasts, significantly outperforming existing methods.",
      "tldr_zh": "本文提出了一种动态多模态方法，用于企业空间-时间预测（Spatio-Temporal Forecasting），通过整合传统数据挖掘和语言模型的指令微调（Instruction Tuning），以应对低资源环境中的复杂数据集挑战。该方法采用 Mixture of Experts (MoE) 架构和 Parameter-Efficient Fine-Tuning (PEFT) 技术，利用过去相关经验、时间-空间建模以及 Grouped-Query Attention 来处理非平稳数据的内部和外部依赖，并缓解分布偏移问题，同时模型预测不确定性以提升决策质量。框架设计注重降低计算和内存需求，支持本地定制、推理速度优化以及数据隐私/安全保护。在各种真实数据集上的广泛实验表明，该方法提供鲁棒且准确的预测，显著优于现有技术。",
      "categories": [
        "cs.LG",
        "cs.AI"
      ],
      "primary_category": "cs.LG",
      "comment": "Published at the ICLR 2024 Workshop on Practical ML for Low Resource\n  Settings(PML4LRS)",
      "pdf_url": "http://arxiv.org/pdf/2408.13622v1",
      "published_date": "2024-08-24 16:32:58 UTC",
      "updated_date": "2024-08-24 16:32:58 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-19T18:31:36.622296"
    },
    {
      "arxiv_id": "2408.13621v1",
      "title": "Preliminary Investigations of a Multi-Faceted Robust and Synergistic Approach in Semiconductor Electron Micrograph Analysis: Integrating Vision Transformers with Large Language and Multimodal Models",
      "title_zh": "翻译失败",
      "authors": [
        "Sakhinana Sagar Srinivas",
        "Geethan Sannidhi",
        "Sreeja Gangasani",
        "Chidaksh Ravuru",
        "Venkataramana Runkana"
      ],
      "abstract": "Characterizing materials using electron micrographs is crucial in areas such\nas semiconductors and quantum materials. Traditional classification methods\nfalter due to the intricatestructures of these micrographs. This study\nintroduces an innovative architecture that leverages the generative\ncapabilities of zero-shot prompting in Large Language Models (LLMs) such as\nGPT-4(language only), the predictive ability of few-shot (in-context) learning\nin Large Multimodal Models (LMMs) such as GPT-4(V)ision, and fuses knowledge\nacross image based and linguistic insights for accurate nanomaterial category\nprediction. This comprehensive approach aims to provide a robust solution for\nthe automated nanomaterial identification task in semiconductor manufacturing,\nblending performance, efficiency, and interpretability. Our method surpasses\nconventional approaches, offering precise nanomaterial identification and\nfacilitating high-throughput screening.",
      "tldr_zh": "这项研究探讨了在半导体和量子材料领域，使用电子显微镜图像表征材料的挑战，传统分类方法因图像结构复杂而表现不佳。研究提出了一种创新架构，结合 Vision Transformers 与 Large Language Models (LLMs) 如 GPT-4 的零-shot prompting 生成能力，以及 Large Multimodal Models (LMMs) 如 GPT-4(V)ision 的 few-shot 学习预测能力，通过融合图像和语言洞见实现纳米材料类别的准确预测。该方法在半导体制造中提供了一个鲁棒、高效且可解释的解决方案，超越传统方法，支持精确的纳米材料识别和高通量筛选。",
      "categories": [
        "cs.CV",
        "cs.AI",
        "cs.CL",
        "cs.LG"
      ],
      "primary_category": "cs.CV",
      "comment": "Published at Deployable AI (DAI) Workshop at AAAI-2024",
      "pdf_url": "http://arxiv.org/pdf/2408.13621v1",
      "published_date": "2024-08-24 16:28:00 UTC",
      "updated_date": "2024-08-24 16:28:00 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-19T18:31:45.163804"
    },
    {
      "arxiv_id": "2408.13586v2",
      "title": "Balancing Diversity and Risk in LLM Sampling: How to Select Your Method and Parameter for Open-Ended Text Generation",
      "title_zh": "翻译失败",
      "authors": [
        "Yuxuan Zhou",
        "Margret Keuper",
        "Mario Fritz"
      ],
      "abstract": "Sampling-based decoding strategies have been widely adopted for Large\nLanguage Models (LLMs) in numerous applications, targeting a balance between\ndiversity and quality via temperature tuning and tail truncation. Considering\nthe strong dependency of the candidate next tokens on different prefixes,\nrecent studies propose to adaptively truncate the tail of LLMs' predicted\ndistribution. Although improved results have been reported with these methods\non open-ended text generation tasks, the results are highly dependent on the\ncurated parameters and the limited exemplar text. In this paper, we propose a\nsystematic way to estimate the capacity of a truncation sampling method by\nconsidering the trade-off between diversity and risk at each decoding step,\nbased on our collected prefix tree which preserves the context of a full\nsentence. Our work offers a comprehensive comparison of existing truncation\nsampling methods and serves as a practical user guideline for their parameter\nselection.",
      "tldr_zh": "本研究探讨了在大型语言模型（LLMs）中基于采样的解码策略如何平衡多样性和质量，特别是在开放文本生成任务中，通过温度调整和尾部截断（tail truncation）来优化输出。作者提出了一种系统方法，利用收集的prefix tree来保留句子上下文，并在每个解码步骤评估多样性和风险的权衡，从而估计截断采样方法的容量。该方法对现有截断采样技术进行了全面比较，并提供了实用的参数选择指南，帮助用户根据具体任务选择最佳策略。",
      "categories": [
        "cs.CL",
        "cs.AI"
      ],
      "primary_category": "cs.CL",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2408.13586v2",
      "published_date": "2024-08-24 14:14:32 UTC",
      "updated_date": "2025-01-08 02:09:15 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-19T18:32:01.327175"
    },
    {
      "arxiv_id": "2408.13546v2",
      "title": "Synesthesia of Machines (SoM)-Enhanced ISAC Precoding for Vehicular Networks with Double Dynamics",
      "title_zh": "翻译失败",
      "authors": [
        "Zonghui Yang",
        "Shijian Gao",
        "Xiang Cheng",
        "Liuqing Yang"
      ],
      "abstract": "Integrated sensing and communication (ISAC) technology is vital for vehicular\nnetworks, yet the time-varying communication channels and rapid movement of\ntargets present significant challenges for real-time precoding design.\nTraditional optimization-based methods are computationally complex and depend\non perfect prior information, which is often unavailable in double-dynamic\nscenarios. In this paper, we propose a synesthesia of machine (SoM)-enhanced\nprecoding paradigm that leverages modalities such as positioning and channel\ninformation to adapt to these dynamics. Utilizing a deep reinforcement learning\n(DRL) framework, our approach pushes ISAC performance boundaries. We also\nintroduce a parameter-shared actor-critic architecture to accelerate training\nin complex state and action spaces. Extensive experiments validate the\nsuperiority of our method over existing approaches.",
      "tldr_zh": "这篇论文针对车辆网络中集成感知与通信（ISAC）技术的双重动态挑战（如时间变化的通信通道和快速移动目标），提出了一种基于机器联觉（SoM）增强的预编码范式，以利用定位和通道信息适应这些动态。方法采用深度强化学习（DRL）框架，并引入参数共享的actor-critic架构来加速训练过程，处理复杂的状态和动作空间。实验结果证明，该方法在ISAC性能上显著优于传统优化方法，提高了实时预编码的有效性。",
      "categories": [
        "eess.SP",
        "cs.AI"
      ],
      "primary_category": "eess.SP",
      "comment": "Submitted to IEEE for possible publication",
      "pdf_url": "http://arxiv.org/pdf/2408.13546v2",
      "published_date": "2024-08-24 10:35:10 UTC",
      "updated_date": "2024-12-04 01:45:42 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-19T18:32:19.501064"
    },
    {
      "arxiv_id": "2408.13518v1",
      "title": "Selective Preference Optimization via Token-Level Reward Function Estimation",
      "title_zh": "翻译失败",
      "authors": [
        "Kailai Yang",
        "Zhiwei Liu",
        "Qianqian Xie",
        "Jimin Huang",
        "Erxue Min",
        "Sophia Ananiadou"
      ],
      "abstract": "Recent advancements in large language model alignment leverage token-level\nsupervisions to perform fine-grained preference optimization. However, existing\ntoken-level alignment methods either optimize on all available tokens, which\ncan be noisy and inefficient, or perform selective training with complex and\nexpensive key token selection strategies. In this work, we propose Selective\nPreference Optimization (SePO), a novel selective alignment strategy that\ncenters on efficient key token selection. SePO proposes the first token\nselection method based on Direct Preference Optimization (DPO), which trains an\noracle model to estimate a token-level reward function on the target data. This\nmethod applies to any existing alignment datasets with response-level\nannotations and enables cost-efficient token selection with small-scale oracle\nmodels and training data. The estimated reward function is then utilized to\nscore all tokens within the target dataset, where only the key tokens are\nselected to supervise the target policy model with a reference model-free\ncontrastive objective function. Extensive experiments on three public\nevaluation benchmarks show that SePO significantly outperforms competitive\nbaseline methods by only optimizing 30% key tokens on the target dataset. SePO\napplications on weak-to-strong generalization show that weak oracle models\neffectively supervise strong policy models with up to 16.8x more parameters.\nSePO also effectively selects key tokens from out-of-distribution data to\nenhance strong policy models and alleviate the over-optimization problem.",
      "tldr_zh": "本文提出 Selective Preference Optimization (SePO)，一种基于 Direct Preference Optimization (DPO) 的新型选择性对齐策略，通过训练一个小型 oracle 模型来估计 token-level 奖励函数，从而高效选择关键 tokens 进行优化。SePO 适用于任何带有 response-level 注解的数据集，仅需优化目标数据集的 30% 关键 tokens，就能以 reference model-free 对比目标函数监督目标策略模型。实验结果显示，SePO 在三个公共基准上显著优于基线方法，并在 weak-to-strong 泛化中实现弱模型对强模型的有效监督（参数多达 16.8 倍），同时能从 out-of-distribution 数据中选择关键 tokens，增强模型性能并缓解过优化问题。",
      "categories": [
        "cs.CL",
        "cs.AI",
        "cs.LG"
      ],
      "primary_category": "cs.CL",
      "comment": "Work in progress",
      "pdf_url": "http://arxiv.org/pdf/2408.13518v1",
      "published_date": "2024-08-24 08:44:04 UTC",
      "updated_date": "2024-08-24 08:44:04 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-19T18:32:22.376637"
    },
    {
      "arxiv_id": "2408.13516v1",
      "title": "AnoPLe: Few-Shot Anomaly Detection via Bi-directional Prompt Learning with Only Normal Samples",
      "title_zh": "翻译失败",
      "authors": [
        "Yujin Lee",
        "Seoyoon Jang",
        "Hyunsoo Yoon"
      ],
      "abstract": "Few-shot Anomaly Detection (FAD) poses significant challenges due to the\nlimited availability of training samples and the frequent absence of abnormal\nsamples. Previous approaches often rely on annotations or true abnormal samples\nto improve detection, but such textual or visual cues are not always\naccessible. To address this, we introduce AnoPLe, a multi-modal prompt learning\nmethod designed for anomaly detection without prior knowledge of anomalies.\nAnoPLe simulates anomalies and employs bidirectional coupling of textual and\nvisual prompts to facilitate deep interaction between the two modalities.\nAdditionally, we integrate a lightweight decoder with a learnable multi-view\nsignal, trained on multi-scale images to enhance local semantic comprehension.\nTo further improve performance, we align global and local semantics, enriching\nthe image-level understanding of anomalies. The experimental results\ndemonstrate that AnoPLe achieves strong FAD performance, recording 94.1% and\n86.2% Image AUROC on MVTec-AD and VisA respectively, with only around a 1% gap\ncompared to the SoTA, despite not being exposed to true anomalies. Code is\navailable at https://github.com/YoojLee/AnoPLe.",
      "tldr_zh": "本论文提出 AnoPLe，一种仅使用正常样本的 Few-Shot Anomaly Detection (FAD) 方法，通过 bi-directional prompt learning 模拟异常并实现文本和视觉模态的双向耦合，促进深度交互。AnoPLe 整合轻量级解码器和可学习的多视图信号，对多尺度图像进行训练，并对齐全局和局部语义，以增强局部语义理解和图像级异常检测。实验结果显示，该方法在 MVTec-AD 和 VisA 数据集上分别达到 94.1% 和 86.2% Image AUROC，与 SoTA 方法的差距仅约 1%，证明其在无真实异常样本情况下的高效性。",
      "categories": [
        "cs.CV",
        "cs.AI"
      ],
      "primary_category": "cs.CV",
      "comment": "Code is available at https://github.com/YoojLee/AnoPLe",
      "pdf_url": "http://arxiv.org/pdf/2408.13516v1",
      "published_date": "2024-08-24 08:41:19 UTC",
      "updated_date": "2024-08-24 08:41:19 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-19T18:32:37.132930"
    },
    {
      "arxiv_id": "2408.14505v2",
      "title": "Language Model Empowered Spatio-Temporal Forecasting via Physics-Aware Reprogramming",
      "title_zh": "翻译失败",
      "authors": [
        "Hao Wang",
        "Jindong Han",
        "Wei Fan",
        "Hao Liu"
      ],
      "abstract": "Spatio-temporal forecasting is pivotal in numerous real-world applications,\nincluding transportation planning, energy management, and climate monitoring.\nIn this work, we aim to harness the reasoning and generalization abilities of\nPre-trained Language Models (PLMs) for more effective spatio-temporal\nforecasting, particularly in data-scarce scenarios. However, recent studies\nuncover that PLMs, which are primarily trained on textual data, often falter\nwhen tasked with modeling the intricate correlations in numerical time series,\nthereby limiting their effectiveness in comprehending spatio-temporal data. To\nbridge the gap, we propose RePST, a physics-aware PLM reprogramming framework\ntailored for spatio-temporal forecasting. Specifically, we first propose a\nphysics-aware decomposer that adaptively disentangles spatially correlated time\nseries into interpretable sub-components, which facilitates PLM to understand\nsophisticated spatio-temporal dynamics via a divide-and-conquer strategy.\nMoreover, we propose a selective discrete reprogramming scheme, which\nintroduces an expanded spatio-temporal vocabulary space to project\nspatio-temporal series into discrete representations. This scheme minimizes the\ninformation loss during reprogramming and enriches the representations derived\nby PLMs. Extensive experiments on real-world datasets show that the proposed\nRePST outperforms twelve state-of-the-art baseline methods, particularly in\ndata-scarce scenarios, highlighting the effectiveness and superior\ngeneralization capabilities of PLMs for spatio-temporal forecasting.",
      "tldr_zh": "本文提出RePST框架，利用预训练语言模型(PLMs)的推理和泛化能力来提升Spatio-Temporal Forecasting的表现，尤其在数据稀缺场景中。框架包括physics-aware decomposer模块，该模块自适应地将空间相关时间序列分解成可解释的子组件，便于PLMs通过divide-and-conquer策略理解复杂动态；此外，selective discrete reprogramming方案引入扩展的空间-时间词汇空间，将序列投影到离散表示，以最小化信息损失并丰富表示。实验结果显示，RePST在真实数据集上优于12个最先进基线方法，突显了PLMs在Spatio-Temporal Forecasting中的有效性和泛化能力。",
      "categories": [
        "cs.LG",
        "cs.AI",
        "cs.CL"
      ],
      "primary_category": "cs.LG",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2408.14505v2",
      "published_date": "2024-08-24 07:59:36 UTC",
      "updated_date": "2024-10-04 17:08:17 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-19T18:32:47.589295"
    },
    {
      "arxiv_id": "2408.14504v1",
      "title": "Is Functional Correctness Enough to Evaluate Code Language Models? Exploring Diversity of Generated Codes",
      "title_zh": "功能正确性是否足以评估代码语言模型？ 探索生成的代码多样性",
      "authors": [
        "Heejae Chon",
        "Seonghyeon Lee",
        "Jinyoung Yeo",
        "Dongha Lee"
      ],
      "abstract": "Language models (LMs) have exhibited impressive abilities in generating codes\nfrom natural language requirements. In this work, we highlight the diversity of\ncode generated by LMs as a critical criterion for evaluating their code\ngeneration capabilities, in addition to functional correctness. Despite its\npractical implications, there is a lack of studies focused on assessing the\ndiversity of generated code, which overlooks its importance in the development\nof code LMs. We propose a systematic approach to evaluate the diversity of\ngenerated code, utilizing various metrics for inter-code similarity as well as\nfunctional correctness. Specifically, we introduce a pairwise code similarity\nmeasure that leverages large LMs' capabilities in code understanding and\nreasoning, demonstrating the highest correlation with human judgment. We\nextensively investigate the impact of various factors on the quality of\ngenerated code, including model sizes, temperatures, training approaches,\nprompting strategies, and the difficulty of input problems. Our consistent\nobservation of a positive correlation between the test pass score and the\ninter-code similarity score indicates that current LMs tend to produce\nfunctionally correct code with limited diversity.",
      "tldr_zh": "本研究质疑仅靠功能正确性（functional correctness）评估代码语言模型（LMs）的局限性，强调生成的代码多样性（diversity）作为关键评价标准。作者提出一种系统方法，使用代码间相似性指标（如基于LMs的成对代码相似性测量）结合功能正确性来评估多样性，该测量显示出与人类判断的最高相关性。实验分析了模型大小、温度、训练方法、提示策略和输入问题难度等因素对代码质量的影响，结果显示当前LMs倾向于生成功能正确的代码，但多样性有限，且测试通过分数与代码相似性分数呈正相关。总之，此工作揭示了提升代码生成多样性的必要性，为更全面的模型评估提供新见解。",
      "categories": [
        "cs.SE",
        "cs.AI",
        "cs.PL"
      ],
      "primary_category": "cs.SE",
      "comment": "15pages, 6 figures, 8 tables",
      "pdf_url": "http://arxiv.org/pdf/2408.14504v1",
      "published_date": "2024-08-24 07:40:22 UTC",
      "updated_date": "2024-08-24 07:40:22 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-19T18:32:59.141094"
    },
    {
      "arxiv_id": "2408.13493v2",
      "title": "Thresholded Lexicographic Ordered Multiobjective Reinforcement Learning",
      "title_zh": "阈值化的字典序排序多目标强化学习",
      "authors": [
        "Alperen Tercan",
        "Vinayak S. Prabhu"
      ],
      "abstract": "Lexicographic multi-objective problems, which impose a lexicographic\nimportance order over the objectives, arise in many real-life scenarios.\nExisting Reinforcement Learning work directly addressing lexicographic tasks\nhas been scarce. The few proposed approaches were all noted to be heuristics\nwithout theoretical guarantees as the Bellman equation is not applicable to\nthem. Additionally, the practical applicability of these prior approaches also\nsuffers from various issues such as not being able to reach the goal state.\nWhile some of these issues have been known before, in this work we investigate\nfurther shortcomings, and propose fixes for improving practical performance in\nmany cases. We also present a policy optimization approach using our\nLexicographic Projection Optimization (LPO) algorithm that has the potential to\naddress these theoretical and practical concerns. Finally, we demonstrate our\nproposed algorithms on benchmark problems.",
      "tldr_zh": "该论文探讨了词典式多目标强化学习（Lexicographic multi-objective Reinforcement Learning），强调这些问题在现实场景中的重要性，但现有方法多为启发式（heuristics），缺乏理论保证，因为Bellman equation 不适用，且存在实际问题如无法达到目标状态。作者进一步调查了这些方法的不足，并提出修复策略来提升实际性能。论文引入了Lexicographic Projection Optimization (LPO) 算法作为一种策略优化方法，以解决理论和实践上的关切，并通过在基准问题上的实验演示了其有效性。",
      "categories": [
        "cs.LG",
        "cs.AI"
      ],
      "primary_category": "cs.LG",
      "comment": "Full version of ECAI 2024 paper",
      "pdf_url": "http://arxiv.org/pdf/2408.13493v2",
      "published_date": "2024-08-24 06:32:30 UTC",
      "updated_date": "2024-09-04 01:00:12 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-19T18:33:10.835912"
    },
    {
      "arxiv_id": "2408.13482v2",
      "title": "MPruner: Optimizing Neural Network Size with CKA-Based Mutual Information Pruning",
      "title_zh": "MPruner：基于 CKA 的互信息修剪优化神经网络大小",
      "authors": [
        "Seungbeom Hu",
        "ChanJun Park",
        "Andrew Ferraiuolo",
        "Sang-Ki Ko",
        "Jinwoo Kim",
        "Haein Song",
        "Jieung Kim"
      ],
      "abstract": "Determining the optimal size of a neural network is critical, as it directly\nimpacts runtime performance and memory usage. Pruning is a well-established\nmodel compression technique that reduces the size of neural networks while\nmathematically guaranteeing accuracy preservation. However, many recent pruning\nmethods overlook the global contributions of individual model components,\nmaking it difficult to ensure that a pruned model meets the desired dataset and\nperformance requirements. To address these challenges, we developed a new\npruning algorithm, MPruner, that leverages mutual information through vector\nsimilarity. MPruner utilizes layer clustering with the Centered Kernel\nAlignment (CKA) similarity metric, allowing us to incorporate global\ninformation from the neural network for more precise and efficient layer-wise\npruning. We evaluated MPruner across various architectures and configurations,\ndemonstrating its versatility and providing practical guidelines. MPruner\nachieved up to a 50% reduction in parameters and memory usage for CNN and\ntransformer-based models, with minimal to no loss in accuracy.",
      "tldr_zh": "该研究提出 MPruner，一种基于 CKA (Centered Kernel Alignment) 相似度的互信息修剪算法，用于优化神经网络的大小，以平衡性能和内存使用。\nMPruner 通过层聚类和向量相似性整合神经网络的全局信息，实现更精确的层级修剪，从而解决现有方法忽略组件全局贡献的问题。\n实验结果显示，在各种架构如 CNN 和 transformer 模型上，MPruner 实现了高达 50% 的参数和内存减少，同时准确性损失最小或无损失。",
      "categories": [
        "cs.LG",
        "cs.AI"
      ],
      "primary_category": "cs.LG",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2408.13482v2",
      "published_date": "2024-08-24 05:54:47 UTC",
      "updated_date": "2024-09-03 00:48:37 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-19T18:33:23.257559"
    },
    {
      "arxiv_id": "2408.13471v1",
      "title": "Disentangled Generative Graph Representation Learning",
      "title_zh": "解耦生成式图表示学习",
      "authors": [
        "Xinyue Hu",
        "Zhibin Duan",
        "Xinyang Liu",
        "Yuxin Li",
        "Bo Chen",
        "Mingyuan Zhou"
      ],
      "abstract": "Recently, generative graph models have shown promising results in learning\ngraph representations through self-supervised methods. However, most existing\ngenerative graph representation learning (GRL) approaches rely on random\nmasking across the entire graph, which overlooks the entanglement of learned\nrepresentations. This oversight results in non-robustness and a lack of\nexplainability. Furthermore, disentangling the learned representations remains\na significant challenge and has not been sufficiently explored in GRL research.\nBased on these insights, this paper introduces DiGGR (Disentangled Generative\nGraph Representation Learning), a self-supervised learning framework. DiGGR\naims to learn latent disentangled factors and utilizes them to guide graph mask\nmodeling, thereby enhancing the disentanglement of learned representations and\nenabling end-to-end joint learning. Extensive experiments on 11 public datasets\nfor two different graph learning tasks demonstrate that DiGGR consistently\noutperforms many previous self-supervised methods, verifying the effectiveness\nof the proposed approach.",
      "tldr_zh": "该论文指出，现有的生成图表示学习（Generative Graph Representation Learning, GRL）方法依赖随机掩码，导致表示纠缠（entanglement），从而影响模型的鲁棒性和可解释性。针对这一问题，作者提出 DiGGR（Disentangled Generative Graph Representation Learning）框架，这是一个自监督学习（self-supervised learning）方法，通过学习潜在的解纠缠因素（disentangled factors）并指导图掩码建模，实现表示的解纠缠和端到端联合学习。在 11 个公共数据集上的实验显示，DiGGR 在两个图学习任务中显著优于现有自监督方法，验证了其有效性。",
      "categories": [
        "cs.LG",
        "cs.AI"
      ],
      "primary_category": "cs.LG",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2408.13471v1",
      "published_date": "2024-08-24 05:13:02 UTC",
      "updated_date": "2024-08-24 05:13:02 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-19T18:33:34.862708"
    },
    {
      "arxiv_id": "2408.13467v2",
      "title": "LlamaDuo: LLMOps Pipeline for Seamless Migration from Service LLMs to Small-Scale Local LLMs",
      "title_zh": "LlamaDuo：LLMOps 管道，用于从服务型大语言模型到",
      "authors": [
        "Chansung Park",
        "Juyong Jiang",
        "Fan Wang",
        "Sayak Paul",
        "Jing Tang"
      ],
      "abstract": "The widespread adoption of cloud-based proprietary large language models\n(LLMs) has introduced significant challenges, including operational\ndependencies, privacy concerns, and the necessity of continuous internet\nconnectivity. In this work, we introduce an LLMOps pipeline, \"LlamaDuo\", for\nthe seamless migration of knowledge and abilities from service-oriented LLMs to\nsmaller, locally manageable models. This pipeline is crucial for ensuring\nservice continuity in the presence of operational failures, strict privacy\npolicies, or offline requirements. Our LlamaDuo involves fine-tuning a small\nlanguage model against the service LLM using a synthetic dataset generated by\nthe latter. If the performance of the fine-tuned model falls short of\nexpectations, it is enhanced by further fine-tuning with additional similar\ndata created by the service LLM. This iterative process guarantees that the\nsmaller model can eventually match or even surpass the service LLM's\ncapabilities in specific downstream tasks, offering a practical and scalable\nsolution for managing AI deployments in constrained environments. Extensive\nexperiments with leading edge LLMs are conducted to demonstrate the\neffectiveness, adaptability, and affordability of LlamaDuo across various\ndownstream tasks. Our pipeline implementation is available at\nhttps://github.com/deep-diver/llamaduo.",
      "tldr_zh": "这篇论文介绍了 LlamaDuo，一种 LLMOps 管道，旨在实现从服务 LLMs 到小型本地 LLMs 的无缝迁移，解决操作依赖、隐私问题和离线需求等挑战。该管道通过使用服务 LLMs 生成合成数据集，对小型模型进行 fine-tuning，如果性能未达预期则迭代添加类似数据优化，确保小型模型在特定下游任务上匹配或超越服务 LLMs 的能力。实验结果证明了 LlamaDuo 的有效性、可适应性和经济性，并提供了开源实现（https://github.com/deep-diver/llamaduo）。",
      "categories": [
        "cs.LG",
        "cs.AI",
        "cs.DC"
      ],
      "primary_category": "cs.LG",
      "comment": "28 pages, 18 figures, 6 tables",
      "pdf_url": "http://arxiv.org/pdf/2408.13467v2",
      "published_date": "2024-08-24 05:03:08 UTC",
      "updated_date": "2024-08-29 00:54:27 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-19T18:33:48.216821"
    },
    {
      "arxiv_id": "2408.13464v2",
      "title": "Uncovering Biases with Reflective Large Language Models",
      "title_zh": "通过反思性大型语言模型揭示偏差",
      "authors": [
        "Edward Y. Chang"
      ],
      "abstract": "Biases and errors in human-labeled data present significant challenges for\nmachine learning, especially in supervised learning reliant on potentially\nflawed ground truth data. These flaws, including diagnostic errors and societal\nbiases, risk being propagated and amplified through models trained using\nmaximum likelihood estimation. We present the Reflective LLM Dialogue Framework\nRLDF, which leverages structured adversarial dialogues between multiple\ninstances of a single LLM or different LLMs to uncover diverse perspectives and\ncorrect inconsistencies. By conditioning LLMs to adopt opposing stances, RLDF\nenables systematic bias detection through conditional statistics, information\ntheory, and divergence metrics. Experiments show RLDF successfully identifies\npotential biases in public content while exposing limitations in human-labeled\ndata. Our framework supports measurable progress tracking and explainable\nremediation actions, offering a scalable approach for improving content\nneutrality through transparent, multi-perspective analysis.",
      "tldr_zh": "该研究探讨了人类标记数据中的偏差和错误如何影响机器学习模型，特别是通过最大似然估计(Maximum Likelihood Estimation)训练时可能放大这些问题。作者提出Reflective LLM Dialogue Framework (RLDF)，一种利用多个Large Language Models (LLMs)实例进行结构化对抗对话的框架，让模型采用对立立场，并通过条件统计、信息理论和偏差指标系统检测潜在偏差。实验结果表明，RLDF能够有效识别公共内容中的偏差，暴露人类标记数据的局限性，并提供可衡量的进步跟踪和可解释的修复行动，从而实现内容中立性的可扩展改进。",
      "categories": [
        "cs.AI",
        "cs.CL",
        "cs.LG",
        "I.2.7"
      ],
      "primary_category": "cs.AI",
      "comment": "18 pages, 4 figures, 9 tables",
      "pdf_url": "http://arxiv.org/pdf/2408.13464v2",
      "published_date": "2024-08-24 04:48:32 UTC",
      "updated_date": "2024-10-24 07:09:43 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-19T18:33:58.911023"
    },
    {
      "arxiv_id": "2408.13461v1",
      "title": "Probing the Robustness of Vision-Language Pretrained Models: A Multimodal Adversarial Attack Approach",
      "title_zh": "探究视觉-语言预训练模型的鲁棒性：一种多模态对抗攻击方法",
      "authors": [
        "Jiwei Guan",
        "Tianyu Ding",
        "Longbing Cao",
        "Lei Pan",
        "Chen Wang",
        "Xi Zheng"
      ],
      "abstract": "Vision-language pretraining (VLP) with transformers has demonstrated\nexceptional performance across numerous multimodal tasks. However, the\nadversarial robustness of these models has not been thoroughly investigated.\nExisting multimodal attack methods have largely overlooked cross-modal\ninteractions between visual and textual modalities, particularly in the context\nof cross-attention mechanisms. In this paper, we study the adversarial\nvulnerability of recent VLP transformers and design a novel Joint Multimodal\nTransformer Feature Attack (JMTFA) that concurrently introduces adversarial\nperturbations in both visual and textual modalities under white-box settings.\nJMTFA strategically targets attention relevance scores to disrupt important\nfeatures within each modality, generating adversarial samples by fusing\nperturbations and leading to erroneous model predictions. Experimental results\nindicate that the proposed approach achieves high attack success rates on\nvision-language understanding and reasoning downstream tasks compared to\nexisting baselines. Notably, our findings reveal that the textual modality\nsignificantly influences the complex fusion processes within VLP transformers.\nMoreover, we observe no apparent relationship between model size and\nadversarial robustness under our proposed attacks. These insights emphasize a\nnew dimension of adversarial robustness and underscore potential risks in the\nreliable deployment of multimodal AI systems.",
      "tldr_zh": "该研究探讨了视觉语言预训练（VLP）模型的对抗鲁棒性问题，指出现有方法忽略了视觉和文本模态间的交互，特别是 cross-attention 机制。作者提出了一种新颖的 Joint Multimodal Transformer Feature Attack (JMTFA)，在白盒设置下同时对视觉和文本模态引入扰动，针对 attention relevance scores 破坏关键特征，从而生成对抗样本并导致模型预测错误。实验结果显示，JMTFA 在视觉语言理解和推理任务上比基线方法实现更高攻击成功率，并揭示文本模态对 VLP 变换器的融合过程有显著影响，同时模型大小与对抗鲁棒性无关，这突显了多模态 AI 系统部署中的潜在风险。",
      "categories": [
        "cs.CV",
        "cs.AI"
      ],
      "primary_category": "cs.CV",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2408.13461v1",
      "published_date": "2024-08-24 04:31:37 UTC",
      "updated_date": "2024-08-24 04:31:37 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-19T18:34:11.788693"
    },
    {
      "arxiv_id": "2408.13457v3",
      "title": "Make Every Penny Count: Difficulty-Adaptive Self-Consistency for Cost-Efficient Reasoning",
      "title_zh": "翻译失败",
      "authors": [
        "Xinglin Wang",
        "Shaoxiong Feng",
        "Yiwei Li",
        "Peiwen Yuan",
        "Yueqi Zhang",
        "Chuyi Tan",
        "Boyuan Pan",
        "Yao Hu",
        "Kan Li"
      ],
      "abstract": "Self-consistency (SC), a widely used decoding strategy for chain-of-thought\nreasoning, shows significant gains across various multi-step reasoning tasks\nbut comes with a high cost due to multiple sampling with the preset size. Its\nvariants, Adaptive self-consistency (ASC) and Early-stopping self-consistency\n(ESC), dynamically adjust the number of samples based on the posterior\ndistribution of a set of pre-samples, reducing the cost of SC with minimal\nimpact on performance. Both methods, however, do not exploit the prior\ninformation about question difficulty. It often results in unnecessary repeated\nsampling for easy questions that could be accurately answered with just one\nattempt, wasting resources. To tackle this problem, we propose\nDifficulty-Adaptive Self-Consistency (DSC), which leverages the difficulty\ninformation of batch queries from both prior and posterior perspectives to\nadaptively allocate inference resources, further reducing the overall cost of\nSC. To demonstrate the effectiveness of DSC, we conduct extensive experiments\non three popular categories of reasoning tasks: arithmetic, commonsense and\nsymbolic reasoning on six benchmarks. The empirical results show that DSC\nconsistently surpasses the strong baseline ASC and ESC in terms of costs by a\nsignificant margin, while attaining comparable performances.",
      "tldr_zh": "该论文针对Self-consistency (SC) 在链式思维推理中的高采样成本问题，提出了一种Difficulty-Adaptive Self-Consistency (DSC) 方法，通过整合问题难度的先验和后验信息，动态调整推理资源的分配，避免在简单问题上进行不必要的重复采样。DSC 相对于现有变体如Adaptive self-consistency (ASC) 和Early-stopping self-consistency (ESC)，更有效地优化了成本，同时保持了性能的稳定。实验在算术、常识和符号推理的六个基准上进行，结果显示 DSC 在成本上显著优于 ASC 和 ESC，而在任务表现上达到了可比水平。",
      "categories": [
        "cs.CL",
        "cs.AI"
      ],
      "primary_category": "cs.CL",
      "comment": "NAACL2025 Findings",
      "pdf_url": "http://arxiv.org/pdf/2408.13457v3",
      "published_date": "2024-08-24 04:03:35 UTC",
      "updated_date": "2025-02-12 02:52:25 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-19T18:34:23.011975"
    },
    {
      "arxiv_id": "2409.06706v3",
      "title": "SAN: Hypothesizing Long-Term Synaptic Development and Neural Engram Mechanism in Scalable Model's Parameter-Efficient Fine-Tuning",
      "title_zh": "翻译失败",
      "authors": [
        "Gaole Dai",
        "Chun-Kai Fan",
        "Yiming Tang",
        "Zhi Zhang",
        "Yuan Zhang",
        "Yulu Gan",
        "Qizhe Zhang",
        "Cheng-Ching Tseng",
        "Shanghang Zhang",
        "Tiejun Huang"
      ],
      "abstract": "Advances in Parameter-Efficient Fine-Tuning (PEFT) bridged the performance\ngap with Full Fine-Tuning (FFT) through sophisticated analysis of pre-trained\nparameter spaces. Starting from drawing insights from Neural Engrams (NE) in\nBiological Neural Networks (BNNs), we establish a connection between the\nlow-rank property observed during PEFT's parameter space shifting and\nneurobiological mechanisms. This observation leads to our proposed method,\nSynapse and Neuron (SAN), which decomposes and propagates scaling components\nfrom anterior feature adjusting vectors towards posterior weight matrices. Our\napproach is theoretically grounded in Long-Term Potentiation/Depression (LTP/D)\nphenomena, which govern synapse development through neurotransmitter release\nmodulation. Extensive experiments demonstrate its effectiveness: on\n\\textbf{vision tasks} across VTAB, FGVC, and GIC (25 datasets) using ViT, SwinT\nand ConvNeXt, SAN outperforms FFT up to 8.7% and LoRA by 3.2%; on language\ntasks using Commonsense Reasoning (8 datasets) with LLaMA models (all\ngenerations), surpassing ChatGPT up to 8.5% and LoRA by 4.7%; on\nvisual-language tasks using Mixed Visual Instruction (7 datasets) with LLaVA\nmodels, it exceeds FFT up to 2.4% and LoRA by 1.9%. Our code and W&B log will\nbe released.",
      "tldr_zh": "本论文从神经印迹 (Neural Engrams) 和生物神经网络 (BNNs) 中汲取灵感，探讨了参数高效微调 (PEFT) 的低秩属性与神经生物学机制的关联，提出了一种新方法 Synapse and Neuron (SAN)。SAN 通过分解和传播缩放组件，从前向后调整特征向量，并基于长时程增强/抑制 (LTP/D) 现象模拟突触发展，从而提升预训练模型的微调效率。实验结果显示，SAN 在视觉任务（如 VTAB、FGVC 和 GIC 上的 ViT、SwinT 和 ConvNeXt 模型）中比 Full Fine-Tuning (FFT) 高出 8.7% 并超过 LoRA 3.2%；在语言任务（如 Commonsense Reasoning 上的 LLaMA 模型）中超越 ChatGPT 8.5% 和 LoRA 4.7%；在视觉-语言任务（如 LLaVA 模型）中领先 FFT 2.4% 和 LoRA 1.9%，证明了其在多种任务上的优越性能。",
      "categories": [
        "cs.NE",
        "cs.AI",
        "cs.LG"
      ],
      "primary_category": "cs.NE",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2409.06706v3",
      "published_date": "2024-08-24 03:27:29 UTC",
      "updated_date": "2025-02-26 07:07:05 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-19T18:34:37.613137"
    },
    {
      "arxiv_id": "2408.13442v1",
      "title": "A Law of Next-Token Prediction in Large Language Models",
      "title_zh": "翻译失败",
      "authors": [
        "Hangfeng He",
        "Weijie J. Su"
      ],
      "abstract": "Large language models (LLMs) have been widely employed across various\napplication domains, yet their black-box nature poses significant challenges to\nunderstanding how these models process input data internally to make\npredictions. In this paper, we introduce a precise and quantitative law that\ngoverns the learning of contextualized token embeddings through intermediate\nlayers in pre-trained LLMs for next-token prediction. Our findings reveal that\neach layer contributes equally to enhancing prediction accuracy, from the\nlowest to the highest layer -- a universal phenomenon observed across a diverse\narray of open-source LLMs, built on architectures such as Transformer, RWKV,\nand Mamba. We demonstrate that this law offers new perspectives and insights to\ninform and guide practices in LLM development and applications, including model\nscaling, pre-training tasks, and information flow. Overall, our law enables\nmore fine-grained approaches to the design, training, and interpretation of\nLLMs through scrutinizing their internal data processing mechanisms.",
      "tldr_zh": "这篇论文引入了一个精确的定量规律，描述大型语言模型 (LLMs) 在预训练过程中如何通过中间层学习上下文化的 token 嵌入，以提升下一 token 预测的准确性。研究发现，每个层都平等地贡献于预测性能提升，这一现象从最低层到最高层在基于 Transformer、RWKV 和 Mamba 等架构的开源 LLMs 中普遍存在。该规律为 LLM 的开发提供新视角，包括模型缩放、预训练任务和信息流优化，最终支持更细粒度的模型设计、训练和解释。",
      "categories": [
        "cs.LG",
        "cs.AI",
        "cs.CL",
        "stat.ML"
      ],
      "primary_category": "cs.LG",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2408.13442v1",
      "published_date": "2024-08-24 02:48:40 UTC",
      "updated_date": "2024-08-24 02:48:40 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-19T18:34:47.229055"
    }
  ],
  "raw_papers_fetched": true,
  "papers_count": 32,
  "processed_papers_count": 32,
  "failed_papers_count": 0,
  "summary_generated": true,
  "daily_data_saved": true,
  "last_update": "2025-05-19T18:35:05.289799"
}