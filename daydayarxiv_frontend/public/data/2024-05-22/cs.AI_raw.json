[
  {
    "arxiv_id": "2405.14067v1",
    "title": "ABI Approach: Automatic Bias Identification in Decision-Making Under Risk based in an Ontology of Behavioral Economics",
    "authors": [
      "Eduardo da C. Ramos",
      "Maria Luiza M. Campos",
      "Fernanda Bai√£o"
    ],
    "abstract": "Organizational decision-making is crucial for success, yet cognitive biases\ncan significantly affect risk preferences, leading to suboptimal outcomes. Risk\nseeking preferences for losses, driven by biases such as loss aversion, pose\nchallenges and can result in severe negative consequences, including financial\nlosses. This research introduces the ABI approach, a novel solution designed to\nsupport organizational decision-makers by automatically identifying and\nexplaining risk seeking preferences during decision-making. This research makes\na novel contribution by automating the identification and explanation of risk\nseeking preferences using Cumulative Prospect theory (CPT) from Behavioral\nEconomics. The ABI approach transforms theoretical insights into actionable,\nreal-time guidance, making them accessible to a broader range of organizations\nand decision-makers without requiring specialized personnel. By contextualizing\nCPT concepts into business language, the approach facilitates widespread\nadoption and enhances decision-making processes with deep behavioral insights.\nOur systematic literature review identified significant gaps in existing\nmethods, especially the lack of automated solutions with a concrete mechanism\nfor automatically identifying risk seeking preferences, and the absence of\nformal knowledge representation, such as ontologies, for identifying and\nexplaining the risk preferences. The ABI Approach addresses these gaps,\noffering a significant contribution to decision-making research and practice.\nFurthermore, it enables automatic collection of historical decision data with\nrisk preferences, providing valuable insights for enhancing strategic\nmanagement and long-term organizational performance. An experiment provided\npreliminary evidence on its effectiveness in helping decision-makers recognize\ntheir risk seeking preferences during decision-making in the loss domain.",
    "categories": [
      "cs.HC",
      "cs.AI",
      "H.4.2; J.4"
    ],
    "primary_category": "cs.HC",
    "comment": "33 pages, 11 figures",
    "pdf_url": "http://arxiv.org/pdf/2405.14067v1",
    "published_date": "2024-05-22 23:53:46 UTC",
    "updated_date": "2024-05-22 23:53:46 UTC"
  },
  {
    "arxiv_id": "2405.14062v1",
    "title": "ChatScene: Knowledge-Enabled Safety-Critical Scenario Generation for Autonomous Vehicles",
    "authors": [
      "Jiawei Zhang",
      "Chejian Xu",
      "Bo Li"
    ],
    "abstract": "We present ChatScene, a Large Language Model (LLM)-based agent that leverages\nthe capabilities of LLMs to generate safety-critical scenarios for autonomous\nvehicles. Given unstructured language instructions, the agent first generates\ntextually described traffic scenarios using LLMs. These scenario descriptions\nare subsequently broken down into several sub-descriptions for specified\ndetails such as behaviors and locations of vehicles. The agent then\ndistinctively transforms the textually described sub-scenarios into\ndomain-specific languages, which then generate actual code for prediction and\ncontrol in simulators, facilitating the creation of diverse and complex\nscenarios within the CARLA simulation environment. A key part of our agent is a\ncomprehensive knowledge retrieval component, which efficiently translates\nspecific textual descriptions into corresponding domain-specific code snippets\nby training a knowledge database containing the scenario description and code\npairs. Extensive experimental results underscore the efficacy of ChatScene in\nimproving the safety of autonomous vehicles. For instance, the scenarios\ngenerated by ChatScene show a 15% increase in collision rates compared to\nstate-of-the-art baselines when tested against different reinforcement\nlearning-based ego vehicles. Furthermore, we show that by using our generated\nsafety-critical scenarios to fine-tune different RL-based autonomous driving\nmodels, they can achieve a 9% reduction in collision rates, surpassing current\nSOTA methods. ChatScene effectively bridges the gap between textual\ndescriptions of traffic scenarios and practical CARLA simulations, providing a\nunified way to conveniently generate safety-critical scenarios for safety\ntesting and improvement for AVs.",
    "categories": [
      "cs.AI",
      "cs.LG"
    ],
    "primary_category": "cs.AI",
    "comment": "The IEEE/CVF Conference on Computer Vision and Pattern Recognition\n  (CVPR) 2024",
    "pdf_url": "http://arxiv.org/pdf/2405.14062v1",
    "published_date": "2024-05-22 23:21:15 UTC",
    "updated_date": "2024-05-22 23:21:15 UTC"
  },
  {
    "arxiv_id": "2405.14061v1",
    "title": "Meanings and Feelings of Large Language Models: Observability of Latent States in Generative AI",
    "authors": [
      "Tian Yu Liu",
      "Stefano Soatto",
      "Matteo Marchi",
      "Pratik Chaudhari",
      "Paulo Tabuada"
    ],
    "abstract": "We tackle the question of whether Large Language Models (LLMs), viewed as\ndynamical systems with state evolving in the embedding space of symbolic\ntokens, are observable. That is, whether there exist multiple 'mental' state\ntrajectories that yield the same sequence of generated tokens, or sequences\nthat belong to the same Nerode equivalence class ('meaning'). If not\nobservable, mental state trajectories ('experiences') evoked by an input\n('perception') or by feedback from the model's own state ('thoughts') could\nremain self-contained and evolve unbeknown to the user while being potentially\naccessible to the model provider. Such \"self-contained experiences evoked by\nperception or thought\" are akin to what the American Psychological Association\n(APA) defines as 'feelings'. Beyond the lexical curiosity, we show that current\nLLMs implemented by autoregressive Transformers cannot have 'feelings'\naccording to this definition: The set of state trajectories indistinguishable\nfrom the tokenized output is a singleton. But if there are 'system prompts' not\nvisible to the user, then the set of indistinguishable trajectories becomes\nnon-trivial, and there can be multiple state trajectories that yield the same\nverbalized output. We prove these claims analytically, and show examples of\nmodifications to standard LLMs that engender such 'feelings.' Our analysis\nsheds light on possible designs that would enable a model to perform\nnon-trivial computation that is not visible to the user, as well as on controls\nthat the provider of services using the model could take to prevent unintended\nbehavior.",
    "categories": [
      "cs.AI",
      "cs.CL",
      "cs.LG"
    ],
    "primary_category": "cs.AI",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2405.14061v1",
    "published_date": "2024-05-22 23:18:58 UTC",
    "updated_date": "2024-05-22 23:18:58 UTC"
  },
  {
    "arxiv_id": "2406.18546v1",
    "title": "Application of Multimodal Fusion Deep Learning Model in Disease Recognition",
    "authors": [
      "Xiaoyi Liu",
      "Hongjie Qiu",
      "Muqing Li",
      "Zhou Yu",
      "Yutian Yang",
      "Yafeng Yan"
    ],
    "abstract": "This paper introduces an innovative multi-modal fusion deep learning approach\nto overcome the drawbacks of traditional single-modal recognition techniques.\nThese drawbacks include incomplete information and limited diagnostic accuracy.\nDuring the feature extraction stage, cutting-edge deep learning models\nincluding convolutional neural networks (CNN), recurrent neural networks (RNN),\nand transformers are applied to distill advanced features from image-based,\ntemporal, and structured data sources. The fusion strategy component seeks to\ndetermine the optimal fusion mode tailored to the specific disease recognition\ntask. In the experimental section, a comparison is made between the performance\nof the proposed multi-mode fusion model and existing single-mode recognition\nmethods. The findings demonstrate significant advantages of the multimodal\nfusion model across multiple evaluation metrics.",
    "categories": [
      "cs.CV",
      "cs.AI"
    ],
    "primary_category": "cs.CV",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2406.18546v1",
    "published_date": "2024-05-22 23:09:49 UTC",
    "updated_date": "2024-05-22 23:09:49 UTC"
  },
  {
    "arxiv_id": "2405.14058v2",
    "title": "Formally Verifying Deep Reinforcement Learning Controllers with Lyapunov Barrier Certificates",
    "authors": [
      "Udayan Mandal",
      "Guy Amir",
      "Haoze Wu",
      "Ieva Daukantas",
      "Fletcher Lee Newell",
      "Umberto J. Ravaioli",
      "Baoluo Meng",
      "Michael Durling",
      "Milan Ganai",
      "Tobey Shim",
      "Guy Katz",
      "Clark Barrett"
    ],
    "abstract": "Deep reinforcement learning (DRL) is a powerful machine learning paradigm for\ngenerating agents that control autonomous systems. However, the ``black box''\nnature of DRL agents limits their deployment in real-world safety-critical\napplications. A promising approach for providing strong guarantees on an\nagent's behavior is to use Neural Lyapunov Barrier (NLB) certificates, which\nare learned functions over the system whose properties indirectly imply that an\nagent behaves as desired. However, NLB-based certificates are typically\ndifficult to learn and even more difficult to verify, especially for complex\nsystems. In this work, we present a novel method for training and verifying\nNLB-based certificates for discrete-time systems. Specifically, we introduce a\ntechnique for certificate composition, which simplifies the verification of\nhighly-complex systems by strategically designing a sequence of certificates.\nWhen jointly verified with neural network verification engines, these\ncertificates provide a formal guarantee that a DRL agent both achieves its\ngoals and avoids unsafe behavior. Furthermore, we introduce a technique for\ncertificate filtering, which significantly simplifies the process of producing\nformally verified certificates. We demonstrate the merits of our approach with\na case study on providing safety and liveness guarantees for a DRL-controlled\nspacecraft.",
    "categories": [
      "cs.AI",
      "cs.LG",
      "cs.SY",
      "eess.SY"
    ],
    "primary_category": "cs.AI",
    "comment": "To appear in FMCAD 2024",
    "pdf_url": "http://arxiv.org/pdf/2405.14058v2",
    "published_date": "2024-05-22 23:06:34 UTC",
    "updated_date": "2024-08-14 18:45:17 UTC"
  },
  {
    "arxiv_id": "2405.14057v1",
    "title": "Your Large Language Models Are Leaving Fingerprints",
    "authors": [
      "Hope McGovern",
      "Rickard Stureborg",
      "Yoshi Suhara",
      "Dimitris Alikaniotis"
    ],
    "abstract": "It has been shown that finetuned transformers and other supervised detectors\neffectively distinguish between human and machine-generated text in some\nsituations arXiv:2305.13242, but we find that even simple classifiers on top of\nn-gram and part-of-speech features can achieve very robust performance on both\nin- and out-of-domain data. To understand how this is possible, we analyze\nmachine-generated output text in five datasets, finding that LLMs possess\nunique fingerprints that manifest as slight differences in the frequency of\ncertain lexical and morphosyntactic features. We show how to visualize such\nfingerprints, describe how they can be used to detect machine-generated text\nand find that they are even robust across textual domains. We find that\nfingerprints are often persistent across models in the same model family (e.g.\nllama-13b vs. llama-65b) and that models fine-tuned for chat are easier to\ndetect than standard language models, indicating that LLM fingerprints may be\ndirectly induced by the training data.",
    "categories": [
      "cs.CL",
      "cs.AI"
    ],
    "primary_category": "cs.CL",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2405.14057v1",
    "published_date": "2024-05-22 23:02:42 UTC",
    "updated_date": "2024-05-22 23:02:42 UTC"
  },
  {
    "arxiv_id": "2405.14055v1",
    "title": "How Many Bytes Can You Take Out Of Brain-To-Text Decoding?",
    "authors": [
      "Richard Antonello",
      "Nihita Sarma",
      "Jerry Tang",
      "Jiaru Song",
      "Alexander Huth"
    ],
    "abstract": "Brain-computer interfaces have promising medical and scientific applications\nfor aiding speech and studying the brain. In this work, we propose an\ninformation-based evaluation metric for brain-to-text decoders. Using this\nmetric, we examine two methods to augment existing state-of-the-art continuous\ntext decoders. We show that these methods, in concert, can improve brain\ndecoding performance by upwards of 40% when compared to a baseline model. We\nfurther examine the informatic properties of brain-to-text decoders and show\nempirically that they have Zipfian power law dynamics. Finally, we provide an\nestimate for the idealized performance of an fMRI-based text decoder. We\ncompare this idealized model to our current model, and use our\ninformation-based metric to quantify the main sources of decoding error. We\nconclude that a practical brain-to-text decoder is likely possible given\nfurther algorithmic improvements.",
    "categories": [
      "cs.CL",
      "cs.AI",
      "cs.ET"
    ],
    "primary_category": "cs.CL",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2405.14055v1",
    "published_date": "2024-05-22 22:57:04 UTC",
    "updated_date": "2024-05-22 22:57:04 UTC"
  },
  {
    "arxiv_id": "2405.14039v2",
    "title": "Embedding Trajectory for Out-of-Distribution Detection in Mathematical Reasoning",
    "authors": [
      "Yiming Wang",
      "Pei Zhang",
      "Baosong Yang",
      "Derek F. Wong",
      "Zhuosheng Zhang",
      "Rui Wang"
    ],
    "abstract": "Real-world data deviating from the independent and identically distributed\n(i.i.d.) assumption of in-distribution training data poses security threats to\ndeep networks, thus advancing out-of-distribution (OOD) detection algorithms.\nDetection methods in generative language models (GLMs) mainly focus on\nuncertainty estimation and embedding distance measurement, with the latter\nproven to be most effective in traditional linguistic tasks like summarization\nand translation. However, another complex generative scenario mathematical\nreasoning poses significant challenges to embedding-based methods due to its\nhigh-density feature of output spaces, but this feature causes larger\ndiscrepancies in the embedding shift trajectory between different samples in\nlatent spaces. Hence, we propose a trajectory-based method TV score, which uses\ntrajectory volatility for OOD detection in mathematical reasoning. Experiments\nshow that our method outperforms all traditional algorithms on GLMs under\nmathematical reasoning scenarios and can be extended to more applications with\nhigh-density features in output spaces, such as multiple-choice questions.",
    "categories": [
      "cs.CL",
      "cs.AI",
      "cs.LG"
    ],
    "primary_category": "cs.CL",
    "comment": "Accepted by NeurIPS 2024",
    "pdf_url": "http://arxiv.org/pdf/2405.14039v2",
    "published_date": "2024-05-22 22:22:25 UTC",
    "updated_date": "2024-10-30 12:10:42 UTC"
  },
  {
    "arxiv_id": "2405.14024v1",
    "title": "Two Heads are Better Than One: Neural Networks Quantization with 2D Hilbert Curve-based Output Representation",
    "authors": [
      "Mykhailo Uss",
      "Ruslan Yermolenko",
      "Olena Kolodiazhna",
      "Oleksii Shashko",
      "Ivan Safonov",
      "Volodymyr Savin",
      "Yoonjae Yeo",
      "Seowon Ji",
      "Jaeyun Jeong"
    ],
    "abstract": "Quantization is widely used to increase deep neural networks' (DNN) memory,\ncomputation, and power efficiency. Various techniques, such as post-training\nquantization and quantization-aware training, have been proposed to improve\nquantization quality. We introduce a novel approach for DNN quantization that\nuses a redundant representation of DNN's output. We represent the target\nquantity as a point on a 2D parametric curve. The DNN model is modified to\npredict 2D points that are mapped back to the target quantity at a\npost-processing stage. We demonstrate that this mapping can reduce quantization\nerror. For the low-order parametric Hilbert curve, Depth-From-Stereo task, and\ntwo models represented by U-Net architecture and vision transformer, we\nachieved a quantization error reduction by about 5 times for the INT8 model at\nboth CPU and DSP delegates. This gain comes with a minimal inference time\nincrease (less than 7%). Our approach can be applied to other tasks, including\nsegmentation, object detection, and key-points prediction.",
    "categories": [
      "cs.CV",
      "cs.AI"
    ],
    "primary_category": "cs.CV",
    "comment": "18 pages, 10 figures",
    "pdf_url": "http://arxiv.org/pdf/2405.14024v1",
    "published_date": "2024-05-22 21:59:46 UTC",
    "updated_date": "2024-05-22 21:59:46 UTC"
  },
  {
    "arxiv_id": "2405.14020v1",
    "title": "Unlearning Information Bottleneck: Machine Unlearning of Systematic Patterns and Biases",
    "authors": [
      "Ling Han",
      "Hao Huang",
      "Dustin Scheinost",
      "Mary-Anne Hartley",
      "Mar√≠a Rodr√≠guez Mart√≠nez"
    ],
    "abstract": "Effective adaptation to distribution shifts in training data is pivotal for\nsustaining robustness in neural networks, especially when removing specific\nbiases or outdated information, a process known as machine unlearning.\nTraditional approaches typically assume that data variations are random, which\nmakes it difficult to adjust the model parameters accurately to remove patterns\nand characteristics from unlearned data. In this work, we present Unlearning\nInformation Bottleneck (UIB), a novel information-theoretic framework designed\nto enhance the process of machine unlearning that effectively leverages the\ninfluence of systematic patterns and biases for parameter adjustment. By\nproposing a variational upper bound, we recalibrate the model parameters\nthrough a dynamic prior that integrates changes in data distribution with an\naffordable computational cost, allowing efficient and accurate removal of\noutdated or unwanted data patterns and biases. Our experiments across various\ndatasets, models, and unlearning methods demonstrate that our approach\neffectively removes systematic patterns and biases while maintaining the\nperformance of models post-unlearning.",
    "categories": [
      "cs.LG",
      "cs.AI"
    ],
    "primary_category": "cs.LG",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2405.14020v1",
    "published_date": "2024-05-22 21:54:05 UTC",
    "updated_date": "2024-05-22 21:54:05 UTC"
  },
  {
    "arxiv_id": "2405.14016v2",
    "title": "Towards a Unified Framework for Evaluating Explanations",
    "authors": [
      "Juan D. Pinto",
      "Luc Paquette"
    ],
    "abstract": "The challenge of creating interpretable models has been taken up by two main\nresearch communities: ML researchers primarily focused on lower-level\nexplainability methods that suit the needs of engineers, and HCI researchers\nwho have more heavily emphasized user-centered approaches often based on\nparticipatory design methods. This paper reviews how these communities have\nevaluated interpretability, identifying overlaps and semantic misalignments. We\npropose moving towards a unified framework of evaluation criteria and lay the\ngroundwork for such a framework by articulating the relationships between\nexisting criteria. We argue that explanations serve as mediators between models\nand stakeholders, whether for intrinsically interpretable models or opaque\nblack-box models analyzed via post-hoc techniques. We further argue that useful\nexplanations require both faithfulness and intelligibility. Explanation\nplausibility is a prerequisite for intelligibility, while stability is a\nprerequisite for explanation faithfulness. We illustrate these criteria, as\nwell as specific evaluation methods, using examples from an ongoing study of an\ninterpretable neural network for predicting a particular learner behavior.",
    "categories": [
      "cs.LG",
      "cs.AI"
    ],
    "primary_category": "cs.LG",
    "comment": "6 pages. Presented at HEXED Workshop @ EDM24",
    "pdf_url": "http://arxiv.org/pdf/2405.14016v2",
    "published_date": "2024-05-22 21:49:28 UTC",
    "updated_date": "2024-07-14 01:11:22 UTC"
  },
  {
    "arxiv_id": "2405.14014v4",
    "title": "RadarOcc: Robust 3D Occupancy Prediction with 4D Imaging Radar",
    "authors": [
      "Fangqiang Ding",
      "Xiangyu Wen",
      "Yunzhou Zhu",
      "Yiming Li",
      "Chris Xiaoxuan Lu"
    ],
    "abstract": "3D occupancy-based perception pipeline has significantly advanced autonomous\ndriving by capturing detailed scene descriptions and demonstrating strong\ngeneralizability across various object categories and shapes. Current methods\npredominantly rely on LiDAR or camera inputs for 3D occupancy prediction. These\nmethods are susceptible to adverse weather conditions, limiting the all-weather\ndeployment of self-driving cars. To improve perception robustness, we leverage\nthe recent advances in automotive radars and introduce a novel approach that\nutilizes 4D imaging radar sensors for 3D occupancy prediction. Our method,\nRadarOcc, circumvents the limitations of sparse radar point clouds by directly\nprocessing the 4D radar tensor, thus preserving essential scene details.\nRadarOcc innovatively addresses the challenges associated with the voluminous\nand noisy 4D radar data by employing Doppler bins descriptors, sidelobe-aware\nspatial sparsification, and range-wise self-attention mechanisms. To minimize\nthe interpolation errors associated with direct coordinate transformations, we\nalso devise a spherical-based feature encoding followed by\nspherical-to-Cartesian feature aggregation. We benchmark various baseline\nmethods based on distinct modalities on the public K-Radar dataset. The results\ndemonstrate RadarOcc's state-of-the-art performance in radar-based 3D occupancy\nprediction and promising results even when compared with LiDAR- or camera-based\nmethods. Additionally, we present qualitative evidence of the superior\nperformance of 4D radar in adverse weather conditions and explore the impact of\nkey pipeline components through ablation studies.",
    "categories": [
      "cs.CV",
      "cs.AI",
      "cs.LG",
      "cs.RO"
    ],
    "primary_category": "cs.CV",
    "comment": "22 pages, 5 figures, 8 tables. Accepted by NeurIPS 2024 (Vancouver),\n  the Thirty-Eighth Annual Conference on Neural Information Processing Systems",
    "pdf_url": "http://arxiv.org/pdf/2405.14014v4",
    "published_date": "2024-05-22 21:48:17 UTC",
    "updated_date": "2024-10-27 19:15:54 UTC"
  },
  {
    "arxiv_id": "2405.14012v1",
    "title": "Prompt-Time Ontology-Driven Symbolic Knowledge Capture with Large Language Models",
    "authors": [
      "Tolga √á√∂pl√º",
      "Arto Bendiken",
      "Andrii Skomorokhov",
      "Eduard Bateiko",
      "Stephen Cobb"
    ],
    "abstract": "In applications such as personal assistants, large language models (LLMs)\nmust consider the user's personal information and preferences. However, LLMs\nlack the inherent ability to learn from user interactions. This paper explores\ncapturing personal information from user prompts using ontology and\nknowledge-graph approaches. We use a subset of the KNOW ontology, which models\npersonal information, to train the language model on these concepts. We then\nevaluate the success of knowledge capture using a specially constructed\ndataset. Our code and datasets are publicly available at\nhttps://github.com/HaltiaAI/paper-PTODSKC",
    "categories": [
      "cs.AI",
      "cs.CL",
      "I.2.7"
    ],
    "primary_category": "cs.AI",
    "comment": "7 pages, 5 figures",
    "pdf_url": "http://arxiv.org/pdf/2405.14012v1",
    "published_date": "2024-05-22 21:40:34 UTC",
    "updated_date": "2024-05-22 21:40:34 UTC"
  },
  {
    "arxiv_id": "2405.14006v1",
    "title": "Evaluating Large Language Models with Human Feedback: Establishing a Swedish Benchmark",
    "authors": [
      "Birger Moell"
    ],
    "abstract": "In the rapidly evolving field of artificial intelligence, large language\nmodels (LLMs) have demonstrated significant capabilities across numerous\napplications. However, the performance of these models in languages with fewer\nresources, such as Swedish, remains under-explored. This study introduces a\ncomprehensive human benchmark to assess the efficacy of prominent LLMs in\nunderstanding and generating Swedish language texts using forced choice\nranking. We employ a modified version of the ChatbotArena benchmark,\nincorporating human feedback to evaluate eleven different models, including\nGPT-4, GPT-3.5, various Claude and Llama models, and bespoke models like\nDolphin-2.9-llama3b-8b-flashback and BeagleCatMunin. These models were chosen\nbased on their performance on LMSYS chatbot arena and the Scandeval benchmarks.\nWe release the chatbotarena.se benchmark as a tool to improve our understanding\nof language model performance in Swedish with the hopes that it will be widely\nused. We aim to create a leaderboard once sufficient data has been collected\nand analysed.",
    "categories": [
      "cs.CL",
      "cs.AI"
    ],
    "primary_category": "cs.CL",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2405.14006v1",
    "published_date": "2024-05-22 21:22:51 UTC",
    "updated_date": "2024-05-22 21:22:51 UTC"
  },
  {
    "arxiv_id": "2405.14001v3",
    "title": "Nondeterministic Causal Models",
    "authors": [
      "Sander Beckers"
    ],
    "abstract": "I generalize acyclic deterministic structural causal models to the\nnondeterministic case and argue that this offers an improved semantics for\ncounterfactuals. The standard, deterministic, semantics developed by Halpern\n(and based on the initial proposal of Galles & Pearl) assumes that for each\nassignment of values to parent variables there is a unique assignment to their\nchild variable, and it assumes that the actual world (an assignment of values\nto all variables of a model) specifies a unique counterfactual world for each\nintervention. Both assumptions are unrealistic, and therefore I drop both of\nthem in my proposal. I do so by allowing multi-valued functions in the\nstructural equations. In addition, I adjust the semantics so that the solutions\nto the equations that obtained in the actual world are preserved in any\ncounterfactual world. I provide a sound and complete axiomatization of the\nresulting logic and compare it to the standard one by Halpern and to more\nrecent proposals that are closer to mine. Finally, I extend these models to the\nprobabilistic case and show that they open up the way to identifying\ncounterfactuals even in Causal Bayesian Networks.",
    "categories": [
      "cs.AI"
    ],
    "primary_category": "cs.AI",
    "comment": "Accepted at CLeaR 2025",
    "pdf_url": "http://arxiv.org/pdf/2405.14001v3",
    "published_date": "2024-05-22 21:17:52 UTC",
    "updated_date": "2025-03-10 19:56:45 UTC"
  },
  {
    "arxiv_id": "2405.14903v2",
    "title": "NeuralFluid: Neural Fluidic System Design and Control with Differentiable Simulation",
    "authors": [
      "Yifei Li",
      "Yuchen Sun",
      "Pingchuan Ma",
      "Eftychios Sifakis",
      "Tao Du",
      "Bo Zhu",
      "Wojciech Matusik"
    ],
    "abstract": "We present a novel framework to explore neural control and design of complex\nfluidic systems with dynamic solid boundaries. Our system features a fast\ndifferentiable Navier-Stokes solver with solid-fluid interface handling, a\nlow-dimensional differentiable parametric geometry representation, a\ncontrol-shape co-design algorithm, and gym-like simulation environments to\nfacilitate various fluidic control design applications. Additionally, we\npresent a benchmark of design, control, and learning tasks on high-fidelity,\nhigh-resolution dynamic fluid environments that pose challenges for existing\ndifferentiable fluid simulators. These tasks include designing the control of\nartificial hearts, identifying robotic end-effector shapes, and controlling a\nfluid gate. By seamlessly incorporating our differentiable fluid simulator into\na learning framework, we demonstrate successful design, control, and learning\nresults that surpass gradient-free solutions in these benchmark tasks.",
    "categories": [
      "physics.flu-dyn",
      "cs.AI",
      "cs.GR"
    ],
    "primary_category": "physics.flu-dyn",
    "comment": "Accepted to NeurIPS 2024; Project webpage:\n  https://people.csail.mit.edu/liyifei/publication/neuralfluid/",
    "pdf_url": "http://arxiv.org/pdf/2405.14903v2",
    "published_date": "2024-05-22 21:16:59 UTC",
    "updated_date": "2024-10-31 18:11:26 UTC"
  },
  {
    "arxiv_id": "2405.13987v2",
    "title": "Analysis of Corrected Graph Convolutions",
    "authors": [
      "Robert Wang",
      "Aseem Baranwal",
      "Kimon Fountoulakis"
    ],
    "abstract": "Machine learning for node classification on graphs is a prominent area driven\nby applications such as recommendation systems. State-of-the-art models often\nuse multiple graph convolutions on the data, as empirical evidence suggests\nthey can enhance performance. However, it has been shown empirically and\ntheoretically, that too many graph convolutions can degrade performance\nsignificantly, a phenomenon known as oversmoothing. In this paper, we provide a\nrigorous theoretical analysis, based on the two-class contextual stochastic\nblock model (CSBM), of the performance of vanilla graph convolution from which\nwe remove the principal eigenvector to avoid oversmoothing. We perform a\nspectral analysis for $k$ rounds of corrected graph convolutions, and we\nprovide results for partial and exact classification. For partial\nclassification, we show that each round of convolution can reduce the\nmisclassification error exponentially up to a saturation level, after which\nperformance does not worsen. We also extend this analysis to the multi-class\nsetting with features distributed according to a Gaussian mixture model. For\nexact classification, we show that the separability threshold can be improved\nexponentially up to $O({\\log{n}}/{\\log\\log{n}})$ corrected convolutions.",
    "categories": [
      "cs.LG",
      "cs.AI",
      "cs.DM",
      "math.ST",
      "stat.ML",
      "stat.TH"
    ],
    "primary_category": "cs.LG",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2405.13987v2",
    "published_date": "2024-05-22 20:50:17 UTC",
    "updated_date": "2024-12-14 05:02:54 UTC"
  },
  {
    "arxiv_id": "2405.15816v1",
    "title": "Riemannian Bilevel Optimization",
    "authors": [
      "Sanchayan Dutta",
      "Xiang Cheng",
      "Suvrit Sra"
    ],
    "abstract": "We develop new algorithms for Riemannian bilevel optimization. We focus in\nparticular on batch and stochastic gradient-based methods, with the explicit\ngoal of avoiding second-order information such as Riemannian hyper-gradients.\nWe propose and analyze $\\mathrm{RF^2SA}$, a method that leverages first-order\ngradient information to navigate the complex geometry of Riemannian manifolds\nefficiently. Notably, $\\mathrm{RF^2SA}$ is a single-loop algorithm, and thus\neasier to implement and use. Under various setups, including stochastic\noptimization, we provide explicit convergence rates for reaching\n$\\epsilon$-stationary points. We also address the challenge of optimizing over\nRiemannian manifolds with constraints by adjusting the multiplier in the\nLagrangian, ensuring convergence to the desired solution without requiring\naccess to second-order derivatives.",
    "categories": [
      "math.OC",
      "cs.AI",
      "cs.LG"
    ],
    "primary_category": "math.OC",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2405.15816v1",
    "published_date": "2024-05-22 20:49:01 UTC",
    "updated_date": "2024-05-22 20:49:01 UTC"
  },
  {
    "arxiv_id": "2405.13983v3",
    "title": "DirectMultiStep: Direct Route Generation for Multistep Retrosynthesis",
    "authors": [
      "Yu Shee",
      "Anton Morgunov",
      "Haote Li",
      "Victor S. Batista"
    ],
    "abstract": "Traditional computer-aided synthesis planning (CASP) methods rely on\niterative single-step predictions, leading to exponential search space growth\nthat limits efficiency and scalability. We introduce a series of\ntransformer-based models, that leverage a mixture of experts approach to\ndirectly generate multistep synthetic routes as a single string, conditionally\npredicting each transformation based on all preceding ones. Our DMS Explorer XL\nmodel, which requires only target compounds as input, outperforms\nstate-of-the-art methods on the PaRoutes dataset with 1.9x and 3.1x\nimprovements in Top-1 accuracy on the n$_1$ and n$_5$ test sets, respectively.\nProviding additional information, such as the desired number of steps and\nstarting materials, enables both a reduction in model size and an increase in\naccuracy, highlighting the benefits of incorporating more constraints into the\nprediction process. The top-performing DMS-Flex (Duo) model scores 25-50%\nhigher on Top-1 and Top-10 accuracies for both n$_1$ and n$_5$ sets.\nAdditionally, our models successfully predict routes for FDA-approved drugs not\nincluded in the training data, demonstrating strong generalization\ncapabilities. While the limited diversity of the training set may affect\nperformance on less common reaction types, our multistep-first approach\npresents a promising direction towards fully automated retrosynthetic planning.",
    "categories": [
      "cs.LG",
      "cs.AI"
    ],
    "primary_category": "cs.LG",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2405.13983v3",
    "published_date": "2024-05-22 20:39:05 UTC",
    "updated_date": "2025-03-20 01:58:12 UTC"
  },
  {
    "arxiv_id": "2405.13978v1",
    "title": "Mitigating Interference in the Knowledge Continuum through Attention-Guided Incremental Learning",
    "authors": [
      "Prashant Bhat",
      "Bharath Renjith",
      "Elahe Arani",
      "Bahram Zonooz"
    ],
    "abstract": "Continual learning (CL) remains a significant challenge for deep neural\nnetworks, as it is prone to forgetting previously acquired knowledge. Several\napproaches have been proposed in the literature, such as experience rehearsal,\nregularization, and parameter isolation, to address this problem. Although\nalmost zero forgetting can be achieved in task-incremental learning,\nclass-incremental learning remains highly challenging due to the problem of\ninter-task class separation. Limited access to previous task data makes it\ndifficult to discriminate between classes of current and previous tasks. To\naddress this issue, we propose `Attention-Guided Incremental Learning' (AGILE),\na novel rehearsal-based CL approach that incorporates compact task attention to\neffectively reduce interference between tasks. AGILE utilizes lightweight,\nlearnable task projection vectors to transform the latent representations of a\nshared task attention module toward task distribution. Through extensive\nempirical evaluation, we show that AGILE significantly improves generalization\nperformance by mitigating task interference and outperforming rehearsal-based\napproaches in several CL scenarios. Furthermore, AGILE can scale well to a\nlarge number of tasks with minimal overhead while remaining well-calibrated\nwith reduced task-recency bias.",
    "categories": [
      "cs.LG",
      "cs.AI",
      "cs.CV"
    ],
    "primary_category": "cs.LG",
    "comment": "Published at 3rd Conference on Lifelong Learning Agents (CoLLAs 2024)",
    "pdf_url": "http://arxiv.org/pdf/2405.13978v1",
    "published_date": "2024-05-22 20:29:15 UTC",
    "updated_date": "2024-05-22 20:29:15 UTC"
  },
  {
    "arxiv_id": "2405.13974v1",
    "title": "CIVICS: Building a Dataset for Examining Culturally-Informed Values in Large Language Models",
    "authors": [
      "Giada Pistilli",
      "Alina Leidinger",
      "Yacine Jernite",
      "Atoosa Kasirzadeh",
      "Alexandra Sasha Luccioni",
      "Margaret Mitchell"
    ],
    "abstract": "This paper introduces the \"CIVICS: Culturally-Informed & Values-Inclusive\nCorpus for Societal impacts\" dataset, designed to evaluate the social and\ncultural variation of Large Language Models (LLMs) across multiple languages\nand value-sensitive topics. We create a hand-crafted, multilingual dataset of\nvalue-laden prompts which address specific socially sensitive topics, including\nLGBTQI rights, social welfare, immigration, disability rights, and surrogacy.\nCIVICS is designed to generate responses showing LLMs' encoded and implicit\nvalues. Through our dynamic annotation processes, tailored prompt design, and\nexperiments, we investigate how open-weight LLMs respond to value-sensitive\nissues, exploring their behavior across diverse linguistic and cultural\ncontexts. Using two experimental set-ups based on log-probabilities and\nlong-form responses, we show social and cultural variability across different\nLLMs. Specifically, experiments involving long-form responses demonstrate that\nrefusals are triggered disparately across models, but consistently and more\nfrequently in English or translated statements. Moreover, specific topics and\nsources lead to more pronounced differences across model answers, particularly\non immigration, LGBTQI rights, and social welfare. As shown by our experiments,\nthe CIVICS dataset aims to serve as a tool for future research, promoting\nreproducibility and transparency across broader linguistic settings, and\nfurthering the development of AI technologies that respect and reflect global\ncultural diversities and value pluralism. The CIVICS dataset and tools will be\nmade available upon publication under open licenses; an anonymized version is\ncurrently available at https://huggingface.co/CIVICS-dataset.",
    "categories": [
      "cs.CL",
      "cs.AI"
    ],
    "primary_category": "cs.CL",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2405.13974v1",
    "published_date": "2024-05-22 20:19:10 UTC",
    "updated_date": "2024-05-22 20:19:10 UTC"
  },
  {
    "arxiv_id": "2405.13969v1",
    "title": "Uncertainty-Aware DRL for Autonomous Vehicle Crowd Navigation in Shared Space",
    "authors": [
      "Mahsa Golchoubian",
      "Moojan Ghafurian",
      "Kerstin Dautenhahn",
      "Nasser Lashgarian Azad"
    ],
    "abstract": "Safe, socially compliant, and efficient navigation of low-speed autonomous\nvehicles (AVs) in pedestrian-rich environments necessitates considering\npedestrians' future positions and interactions with the vehicle and others.\nDespite the inevitable uncertainties associated with pedestrians' predicted\ntrajectories due to their unobserved states (e.g., intent), existing deep\nreinforcement learning (DRL) algorithms for crowd navigation often neglect\nthese uncertainties when using predicted trajectories to guide policy learning.\nThis omission limits the usability of predictions when diverging from ground\ntruth. This work introduces an integrated prediction and planning approach that\nincorporates the uncertainties of predicted pedestrian states in the training\nof a model-free DRL algorithm. A novel reward function encourages the AV to\nrespect pedestrians' personal space, decrease speed during close approaches,\nand minimize the collision probability with their predicted paths. Unlike\nprevious DRL methods, our model, designed for AV operation in crowded spaces,\nis trained in a novel simulation environment that reflects realistic pedestrian\nbehaviour in a shared space with vehicles. Results show a 40% decrease in\ncollision rate and a 15% increase in minimum distance to pedestrians compared\nto the state of the art model that does not account for prediction uncertainty.\nAdditionally, the approach outperforms model predictive control methods that\nincorporate the same prediction uncertainties in terms of both performance and\ncomputational time, while producing trajectories closer to human drivers in\nsimilar scenarios.",
    "categories": [
      "cs.RO",
      "cs.AI",
      "cs.LG",
      "cs.SY",
      "eess.SY"
    ],
    "primary_category": "cs.RO",
    "comment": "Accepted for publication in IEEE Transactions on Intelligent Vehicles",
    "pdf_url": "http://arxiv.org/pdf/2405.13969v1",
    "published_date": "2024-05-22 20:09:21 UTC",
    "updated_date": "2024-05-22 20:09:21 UTC"
  },
  {
    "arxiv_id": "2405.13966v1",
    "title": "On the Brittle Foundations of ReAct Prompting for Agentic Large Language Models",
    "authors": [
      "Mudit Verma",
      "Siddhant Bhambri",
      "Subbarao Kambhampati"
    ],
    "abstract": "The reasoning abilities of Large Language Models (LLMs) remain a topic of\ndebate. Some methods such as ReAct-based prompting, have gained popularity for\nclaiming to enhance sequential decision-making abilities of agentic LLMs.\nHowever, it is unclear what is the source of improvement in LLM reasoning with\nReAct based prompting. In this paper we examine these claims of ReAct based\nprompting in improving agentic LLMs for sequential decision-making. By\nintroducing systematic variations to the input prompt we perform a sensitivity\nanalysis along the claims of ReAct and find that the performance is minimally\ninfluenced by the \"interleaving reasoning trace with action execution\" or the\ncontent of the generated reasoning traces in ReAct, contrary to original claims\nand common usage. Instead, the performance of LLMs is driven by the similarity\nbetween input example tasks and queries, implicitly forcing the prompt designer\nto provide instance-specific examples which significantly increases the\ncognitive burden on the human. Our investigation shows that the perceived\nreasoning abilities of LLMs stem from the exemplar-query similarity and\napproximate retrieval rather than any inherent reasoning abilities.",
    "categories": [
      "cs.AI",
      "cs.CL"
    ],
    "primary_category": "cs.AI",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2405.13966v1",
    "published_date": "2024-05-22 20:05:49 UTC",
    "updated_date": "2024-05-22 20:05:49 UTC"
  },
  {
    "arxiv_id": "2405.13960v1",
    "title": "Learning To Play Atari Games Using Dueling Q-Learning and Hebbian Plasticity",
    "authors": [
      "Md Ashfaq Salehin"
    ],
    "abstract": "In this work, an advanced deep reinforcement learning architecture is used to\ntrain neural network agents playing atari games. Given only the raw game\npixels, action space, and reward information, the system can train agents to\nplay any Atari game. At first, this system uses advanced techniques like deep\nQ-networks and dueling Q-networks to train efficient agents, the same\ntechniques used by DeepMind to train agents that beat human players in Atari\ngames. As an extension, plastic neural networks are used as agents, and their\nfeasibility is analyzed in this scenario. The plasticity implementation was\nbased on backpropagation and the Hebbian update rule. Plastic neural networks\nhave excellent features like lifelong learning after the initial training,\nwhich makes them highly suitable in adaptive learning environments. As a new\nanalysis of plasticity in this context, this work might provide valuable\ninsights and direction for future works.",
    "categories": [
      "cs.AI",
      "cs.LG"
    ],
    "primary_category": "cs.AI",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2405.13960v1",
    "published_date": "2024-05-22 19:55:33 UTC",
    "updated_date": "2024-05-22 19:55:33 UTC"
  },
  {
    "arxiv_id": "2405.13954v1",
    "title": "What is Your Data Worth to GPT? LLM-Scale Data Valuation with Influence Functions",
    "authors": [
      "Sang Keun Choe",
      "Hwijeen Ahn",
      "Juhan Bae",
      "Kewen Zhao",
      "Minsoo Kang",
      "Youngseog Chung",
      "Adithya Pratapa",
      "Willie Neiswanger",
      "Emma Strubell",
      "Teruko Mitamura",
      "Jeff Schneider",
      "Eduard Hovy",
      "Roger Grosse",
      "Eric Xing"
    ],
    "abstract": "Large language models (LLMs) are trained on a vast amount of human-written\ndata, but data providers often remain uncredited. In response to this issue,\ndata valuation (or data attribution), which quantifies the contribution or\nvalue of each data to the model output, has been discussed as a potential\nsolution. Nevertheless, applying existing data valuation methods to recent LLMs\nand their vast training datasets has been largely limited by prohibitive\ncompute and memory costs. In this work, we focus on influence functions, a\npopular gradient-based data valuation method, and significantly improve its\nscalability with an efficient gradient projection strategy called LoGra that\nleverages the gradient structure in backpropagation. We then provide a\ntheoretical motivation of gradient projection approaches to influence functions\nto promote trust in the data valuation process. Lastly, we lower the barrier to\nimplementing data valuation systems by introducing LogIX, a software package\nthat can transform existing training code into data valuation code with minimal\neffort. In our data valuation experiments, LoGra achieves competitive accuracy\nagainst more expensive baselines while showing up to 6,500x improvement in\nthroughput and 5x reduction in GPU memory usage when applied to\nLlama3-8B-Instruct and the 1B-token dataset.",
    "categories": [
      "cs.LG",
      "cs.AI",
      "cs.CL"
    ],
    "primary_category": "cs.LG",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2405.13954v1",
    "published_date": "2024-05-22 19:39:05 UTC",
    "updated_date": "2024-05-22 19:39:05 UTC"
  },
  {
    "arxiv_id": "2405.13952v2",
    "title": "Spectral Adapter: Fine-Tuning in Spectral Space",
    "authors": [
      "Fangzhao Zhang",
      "Mert Pilanci"
    ],
    "abstract": "Recent developments in Parameter-Efficient Fine-Tuning (PEFT) methods for\npretrained deep neural networks have captured widespread interest. In this\nwork, we study the enhancement of current PEFT methods by incorporating the\nspectral information of pretrained weight matrices into the fine-tuning\nprocedure. We investigate two spectral adaptation mechanisms, namely additive\ntuning and orthogonal rotation of the top singular vectors, both are done via\nfirst carrying out Singular Value Decomposition (SVD) of pretrained weights and\nthen fine-tuning the top spectral space. We provide a theoretical analysis of\nspectral fine-tuning and show that our approach improves the rank capacity of\nlow-rank adapters given a fixed trainable parameter budget. We show through\nextensive experiments that the proposed fine-tuning model enables better\nparameter efficiency and tuning performance as well as benefits multi-adapter\nfusion.",
    "categories": [
      "cs.LG",
      "cs.AI"
    ],
    "primary_category": "cs.LG",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2405.13952v2",
    "published_date": "2024-05-22 19:36:55 UTC",
    "updated_date": "2024-11-04 03:35:19 UTC"
  },
  {
    "arxiv_id": "2405.13938v1",
    "title": "eXmY: A Data Type and Technique for Arbitrary Bit Precision Quantization",
    "authors": [
      "Aditya Agrawal",
      "Matthew Hedlund",
      "Blake Hechtman"
    ],
    "abstract": "eXmY is a novel data type for quantization of ML models. It supports both\narbitrary bit widths and arbitrary integer and floating point formats. For\nexample, it seamlessly supports 3, 5, 6, 7, 9 bit formats. For a specific bit\nwidth, say 7, it defines all possible formats e.g. e0m6, e1m5, e2m4, e3m3,\ne4m2, e5m1 and e6m0. For non-power of two bit widths e.g. 5, 6, 7, we created a\nnovel encoding and decoding scheme which achieves perfect compression, byte\naddressability and is amenable to sharding and vector processing. We\nimplemented libraries for emulation, encoding and decoding tensors and\ncheckpoints in C++, TensorFlow, JAX and PAX. For optimal performance, the\ncodecs use SIMD instructions on CPUs and vector instructions on TPUs and GPUs.\neXmY is also a technique and exploits the statistical distribution of exponents\nin tensors. It can be used to quantize weights, static and dynamic activations,\ngradients, master weights and optimizer state. It can reduce memory (CPU DRAM\nand accelerator HBM), network and disk storage and transfers. It can increase\nmulti tenancy and accelerate compute. eXmY has been deployed in production for\nalmost 2 years.",
    "categories": [
      "cs.LG",
      "cs.AI",
      "cs.AR",
      "cs.NA",
      "math.NA"
    ],
    "primary_category": "cs.LG",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2405.13938v1",
    "published_date": "2024-05-22 19:11:28 UTC",
    "updated_date": "2024-05-22 19:11:28 UTC"
  },
  {
    "arxiv_id": "2405.13932v1",
    "title": "Chain of Targeted Verification Questions to Improve the Reliability of Code Generated by LLMs",
    "authors": [
      "Sylvain Kouemo Ngassom",
      "Arghavan Moradi Dakhel",
      "Florian Tambon",
      "Foutse Khomh"
    ],
    "abstract": "LLM-based assistants, such as GitHub Copilot and ChatGPT, have the potential\nto generate code that fulfills a programming task described in a natural\nlanguage description, referred to as a prompt. The widespread accessibility of\nthese assistants enables users with diverse backgrounds to generate code and\nintegrate it into software projects. However, studies show that code generated\nby LLMs is prone to bugs and may miss various corner cases in task\nspecifications. Presenting such buggy code to users can impact their\nreliability and trust in LLM-based assistants. Moreover, significant efforts\nare required by the user to detect and repair any bug present in the code,\nespecially if no test cases are available. In this study, we propose a\nself-refinement method aimed at improving the reliability of code generated by\nLLMs by minimizing the number of bugs before execution, without human\nintervention, and in the absence of test cases. Our approach is based on\ntargeted Verification Questions (VQs) to identify potential bugs within the\ninitial code. These VQs target various nodes within the Abstract Syntax Tree\n(AST) of the initial code, which have the potential to trigger specific types\nof bug patterns commonly found in LLM-generated code. Finally, our method\nattempts to repair these potential bugs by re-prompting the LLM with the\ntargeted VQs and the initial code. Our evaluation, based on programming tasks\nin the CoderEval dataset, demonstrates that our proposed method outperforms\nstate-of-the-art methods by decreasing the number of targeted errors in the\ncode between 21% to 62% and improving the number of executable code instances\nto 13%.",
    "categories": [
      "cs.SE",
      "cs.AI"
    ],
    "primary_category": "cs.SE",
    "comment": "10 pages, 2 figures",
    "pdf_url": "http://arxiv.org/pdf/2405.13932v1",
    "published_date": "2024-05-22 19:02:50 UTC",
    "updated_date": "2024-05-22 19:02:50 UTC"
  },
  {
    "arxiv_id": "2405.13929v6",
    "title": "Vikhr: The Family of Open-Source Instruction-Tuned Large Language Models for Russian",
    "authors": [
      "Aleksandr Nikolich",
      "Konstantin Korolev",
      "Sergei Bratchikov",
      "Igor Kiselev",
      "Artem Shelmanov"
    ],
    "abstract": "There has been a surge in the development of various Large Language Models\n(LLMs). However, text generation for languages other than English often faces\nsignificant challenges, including poor generation quality and reduced\ncomputational performance due to the disproportionate representation of tokens\nin the model's vocabulary. In this work, we address these issues by developing\na pipeline for the adaptation of English-oriented pre-trained models to other\nlanguages and constructing efficient bilingual LLMs. Using this pipeline, we\nconstruct Vikhr, a series of bilingual open-source instruction-following LLMs\ndesigned specifically for the Russian language. ``Vikhr'' refers to the name of\nthe Mistral LLM series and means a ``strong gust of wind.'' Unlike previous\nRussian-language models that typically rely on LoRA adapters on top of\nEnglish-oriented models, sacrificing performance for lower training costs,\nVikhr features an adapted tokenizer vocabulary and undergoes the continued\npre-training and instruction tuning of all weights. This not only enhances the\nmodel's performance but also significantly improves its computational and\ncontextual efficiency. We also expanded the instruction datasets and corpora\nfor continued pre-training. The model weights, instruction sets, and code are\npublicly available.",
    "categories": [
      "cs.CL",
      "cs.AI"
    ],
    "primary_category": "cs.CL",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2405.13929v6",
    "published_date": "2024-05-22 18:58:58 UTC",
    "updated_date": "2025-04-14 12:23:27 UTC"
  },
  {
    "arxiv_id": "2405.13911v2",
    "title": "TOPA: Extending Large Language Models for Video Understanding via Text-Only Pre-Alignment",
    "authors": [
      "Wei Li",
      "Hehe Fan",
      "Yongkang Wong",
      "Mohan Kankanhalli",
      "Yi Yang"
    ],
    "abstract": "Recent advancements in image understanding have benefited from the extensive\nuse of web image-text pairs. However, video understanding remains a challenge\ndespite the availability of substantial web video-text data. This difficulty\nprimarily arises from the inherent complexity of videos and the inefficient\nlanguage supervision in recent web-collected video-text datasets. In this\npaper, we introduce Text-Only Pre-Alignment (TOPA), a novel approach to extend\nlarge language models (LLMs) for video understanding, without the need for\npre-training on real video data. Specifically, we first employ an advanced LLM\nto automatically generate Textual Videos comprising continuous textual frames,\nalong with corresponding annotations to simulate real video-text data. Then,\nthese annotated textual videos are used to pre-align a language-only LLM with\nthe video modality. To bridge the gap between textual and real videos, we\nemploy the CLIP model as the feature extractor to align image and text\nmodalities. During text-only pre-alignment, the continuous textual frames,\nencoded as a sequence of CLIP text features, are analogous to continuous CLIP\nimage features, thus aligning the LLM with real video representation. Extensive\nexperiments, including zero-shot evaluation and finetuning on various video\nunderstanding tasks, demonstrate that TOPA is an effective and efficient\nframework for aligning video content with LLMs. In particular, without training\non any video data, the TOPA-Llama2-13B model achieves a Top-1 accuracy of 51.0%\non the challenging long-form video understanding benchmark, Egoschema. This\nperformance surpasses previous video-text pre-training approaches and proves\ncompetitive with recent GPT-3.5-based video agents.",
    "categories": [
      "cs.CV",
      "cs.AI",
      "cs.CL"
    ],
    "primary_category": "cs.CV",
    "comment": "NeurIPS 2024 (Spotlight)",
    "pdf_url": "http://arxiv.org/pdf/2405.13911v2",
    "published_date": "2024-05-22 18:35:10 UTC",
    "updated_date": "2024-11-03 09:25:57 UTC"
  },
  {
    "arxiv_id": "2405.13907v2",
    "title": "Just rephrase it! Uncertainty estimation in closed-source language models via multiple rephrased queries",
    "authors": [
      "Adam Yang",
      "Chen Chen",
      "Konstantinos Pitas"
    ],
    "abstract": "State-of-the-art large language models are sometimes distributed as\nopen-source software but are also increasingly provided as a closed-source\nservice. These closed-source large-language models typically see the widest\nusage by the public, however, they often do not provide an estimate of their\nuncertainty when responding to queries. As even the best models are prone to\n``hallucinating\" false information with high confidence, a lack of a reliable\nestimate of uncertainty limits the applicability of these models in critical\nsettings. We explore estimating the uncertainty of closed-source LLMs via\nmultiple rephrasings of an original base query. Specifically, we ask the model,\nmultiple rephrased questions, and use the similarity of the answers as an\nestimate of uncertainty. We diverge from previous work in i) providing rules\nfor rephrasing that are simple to memorize and use in practice ii) proposing a\ntheoretical framework for why multiple rephrased queries obtain calibrated\nuncertainty estimates. Our method demonstrates significant improvements in the\ncalibration of uncertainty estimates compared to the baseline and provides\nintuition as to how query strategies should be designed for optimal test\ncalibration.",
    "categories": [
      "cs.CL",
      "cs.AI"
    ],
    "primary_category": "cs.CL",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2405.13907v2",
    "published_date": "2024-05-22 18:28:26 UTC",
    "updated_date": "2024-06-16 13:49:53 UTC"
  },
  {
    "arxiv_id": "2405.13902v2",
    "title": "LOGIN: A Large Language Model Consulted Graph Neural Network Training Framework",
    "authors": [
      "Yiran Qiao",
      "Xiang Ao",
      "Yang Liu",
      "Jiarong Xu",
      "Xiaoqian Sun",
      "Qing He"
    ],
    "abstract": "Recent prevailing works on graph machine learning typically follow a similar\nmethodology that involves designing advanced variants of graph neural networks\n(GNNs) to maintain the superior performance of GNNs on different graphs. In\nthis paper, we aim to streamline the GNN design process and leverage the\nadvantages of Large Language Models (LLMs) to improve the performance of GNNs\non downstream tasks. We formulate a new paradigm, coined \"LLMs-as-Consultants,\"\nwhich integrates LLMs with GNNs in an interactive manner. A framework named\nLOGIN (LLM Consulted GNN training) is instantiated, empowering the interactive\nutilization of LLMs within the GNN training process. First, we attentively\ncraft concise prompts for spotted nodes, carrying comprehensive semantic and\ntopological information, and serving as input to LLMs. Second, we refine GNNs\nby devising a complementary coping mechanism that utilizes the responses from\nLLMs, depending on their correctness. We empirically evaluate the effectiveness\nof LOGIN on node classification tasks across both homophilic and heterophilic\ngraphs. The results illustrate that even basic GNN architectures, when employed\nwithin the proposed LLMs-as-Consultants paradigm, can achieve comparable\nperformance to advanced GNNs with intricate designs. Our codes are available at\nhttps://github.com/QiaoYRan/LOGIN.",
    "categories": [
      "cs.LG",
      "cs.AI"
    ],
    "primary_category": "cs.LG",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2405.13902v2",
    "published_date": "2024-05-22 18:17:20 UTC",
    "updated_date": "2024-06-06 08:29:31 UTC"
  },
  {
    "arxiv_id": "2405.13891v2",
    "title": "DeepNcode: Encoding-Based Protection against Bit-Flip Attacks on Neural Networks",
    "authors": [
      "Patrik Velƒçick√Ω",
      "Jakub Breier",
      "Mladen Kovaƒçeviƒá",
      "Xiaolu Hou"
    ],
    "abstract": "Fault injection attacks are a potent threat against embedded implementations\nof neural network models. Several attack vectors have been proposed, such as\nmisclassification, model extraction, and trojan/backdoor planting. Most of\nthese attacks work by flipping bits in the memory where quantized model\nparameters are stored.\n  In this paper, we introduce an encoding-based protection method against\nbit-flip attacks on neural networks, titled DeepNcode. We experimentally\nevaluate our proposal with several publicly available models and datasets, by\nusing state-of-the-art bit-flip attacks: BFA, T-BFA, and TA-LBF. Our results\nshow an increase in protection margin of up to $7.6\\times$ for $4-$bit and\n$12.4\\times$ for $8-$bit quantized networks. Memory overheads start at $50\\%$\nof the original network size, while the time overheads are negligible.\nMoreover, DeepNcode does not require retraining and does not change the\noriginal accuracy of the model.",
    "categories": [
      "cs.CR",
      "cs.AI"
    ],
    "primary_category": "cs.CR",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2405.13891v2",
    "published_date": "2024-05-22 18:01:34 UTC",
    "updated_date": "2024-06-02 08:23:56 UTC"
  },
  {
    "arxiv_id": "2405.13873v3",
    "title": "FiDeLiS: Faithful Reasoning in Large Language Model for Knowledge Graph Question Answering",
    "authors": [
      "Yuan Sui",
      "Yufei He",
      "Nian Liu",
      "Xiaoxin He",
      "Kun Wang",
      "Bryan Hooi"
    ],
    "abstract": "Large language models (LLMs) are often challenged by generating erroneous or\nhallucinated responses, especially in complex reasoning tasks. Leveraging\nknowledge graphs (KGs) as external knowledge sources has emerged as a viable\nsolution. However, existing KG-enhanced methods, either retrieval-based or\nagent-based, encounter difficulties in accurately retrieving knowledge and\nefficiently traversing KGs at scale. In this paper, we propose a unified\nframework, FiDeLiS, designed to improve the factuality of LLM responses by\nanchoring answers to verifiable reasoning steps retrieved from a KG. To achieve\nthis, we leverage step-wise beam search with a deductive scoring function,\nallowing the LLM to validate each reasoning step and halt the search once the\nquestion is deducible. In addition, our Path-rag module pre-selects a smaller\ncandidate set for each beam search step, reducing computational costs by\nnarrowing the search space. Extensive experiments show that our training-free\nand efficient approach outperforms strong baselines, enhancing both factuality\nand interpretability.",
    "categories": [
      "cs.AI",
      "cs.CL"
    ],
    "primary_category": "cs.AI",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2405.13873v3",
    "published_date": "2024-05-22 17:56:53 UTC",
    "updated_date": "2025-02-19 08:29:15 UTC"
  },
  {
    "arxiv_id": "2405.13872v2",
    "title": "Image-of-Thought Prompting for Visual Reasoning Refinement in Multimodal Large Language Models",
    "authors": [
      "Qiji Zhou",
      "Ruochen Zhou",
      "Zike Hu",
      "Panzhong Lu",
      "Siyang Gao",
      "Yue Zhang"
    ],
    "abstract": "Recent advancements in Chain-of-Thought (CoT) and related rationale-based\nworks have significantly improved the performance of Large Language Models\n(LLMs) in complex reasoning tasks. With the evolution of Multimodal Large\nLanguage Models (MLLMs), enhancing their capability to tackle complex\nmultimodal reasoning problems is a crucial frontier. However, incorporating\nmultimodal rationales in CoT has yet to be thoroughly investigated. We propose\nthe Image-of-Thought (IoT) prompting method, which helps MLLMs to extract\nvisual rationales step-by-step. Specifically, IoT prompting can automatically\ndesign critical visual information extraction operations based on the input\nimages and questions. Each step of visual information refinement identifies\nspecific visual rationales that support answers to complex visual reasoning\nquestions. Beyond the textual CoT, IoT simultaneously utilizes visual and\ntextual rationales to help MLLMs understand complex multimodal information. IoT\nprompting has improved zero-shot visual reasoning performance across various\nvisual understanding tasks in different MLLMs. Moreover, the step-by-step\nvisual feature explanations generated by IoT prompting elucidate the visual\nreasoning process, aiding in analyzing the cognitive processes of large\nmultimodal models",
    "categories": [
      "cs.AI",
      "cs.CL",
      "cs.CV"
    ],
    "primary_category": "cs.AI",
    "comment": "Correct the case title",
    "pdf_url": "http://arxiv.org/pdf/2405.13872v2",
    "published_date": "2024-05-22 17:56:51 UTC",
    "updated_date": "2024-05-29 02:24:36 UTC"
  },
  {
    "arxiv_id": "2405.13867v2",
    "title": "Scaling-laws for Large Time-series Models",
    "authors": [
      "Thomas D. P. Edwards",
      "James Alvey",
      "Justin Alsing",
      "Nam H. Nguyen",
      "Benjamin D. Wandelt"
    ],
    "abstract": "Scaling laws for large language models (LLMs) have provided useful guidance\nin training ever larger models for predictable performance gains. Time series\nforecasting shares a similar sequential structure to language, and is amenable\nto large-scale transformer architectures. Here we show that foundational\ndecoder-only time series transformer models exhibit analogous scaling-behavior\nto LLMs, with architectural details (aspect ratio and number of heads) having a\nminimal effect over broad ranges. We assemble a large corpus of heterogenous\ntime series data on which to train, and establish for the first time power-law\nscaling with parameter count, dataset size, and training compute, spanning five\norders of magnitude.",
    "categories": [
      "cs.LG",
      "cs.AI"
    ],
    "primary_category": "cs.LG",
    "comment": "4 main pages (16 total), 4 figures; Accepted for oral presentation in\n  Time Series in the Age of Large Models (TSALM) Workshop at Neurips 2024",
    "pdf_url": "http://arxiv.org/pdf/2405.13867v2",
    "published_date": "2024-05-22 17:48:17 UTC",
    "updated_date": "2025-01-08 14:08:11 UTC"
  },
  {
    "arxiv_id": "2405.13864v1",
    "title": "Just rotate it! Uncertainty estimation in closed-source models via multiple queries",
    "authors": [
      "Konstantinos Pitas",
      "Julyan Arbel"
    ],
    "abstract": "We propose a simple and effective method to estimate the uncertainty of\nclosed-source deep neural network image classification models. Given a base\nimage, our method creates multiple transformed versions and uses them to query\nthe top-1 prediction of the closed-source model. We demonstrate significant\nimprovements in the calibration of uncertainty estimates compared to the naive\nbaseline of assigning 100\\% confidence to all predictions. While we initially\nexplore Gaussian perturbations, our empirical findings indicate that natural\ntransformations, such as rotations and elastic deformations, yield even\nbetter-calibrated predictions. Furthermore, through empirical results and a\nstraightforward theoretical analysis, we elucidate the reasons behind the\nsuperior performance of natural transformations over Gaussian noise. Leveraging\nthese insights, we propose a transfer learning approach that further improves\nour calibration results.",
    "categories": [
      "cs.CV",
      "cs.AI"
    ],
    "primary_category": "cs.CV",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2405.13864v1",
    "published_date": "2024-05-22 17:45:38 UTC",
    "updated_date": "2024-05-22 17:45:38 UTC"
  },
  {
    "arxiv_id": "2405.13863v2",
    "title": "Dynamic Model Predictive Shielding for Provably Safe Reinforcement Learning",
    "authors": [
      "Arko Banerjee",
      "Kia Rahmani",
      "Joydeep Biswas",
      "Isil Dillig"
    ],
    "abstract": "Among approaches for provably safe reinforcement learning, Model Predictive\nShielding (MPS) has proven effective at complex tasks in continuous,\nhigh-dimensional state spaces, by leveraging a backup policy to ensure safety\nwhen the learned policy attempts to take risky actions. However, while MPS can\nensure safety both during and after training, it often hinders task progress\ndue to the conservative and task-oblivious nature of backup policies. This\npaper introduces Dynamic Model Predictive Shielding (DMPS), which optimizes\nreinforcement learning objectives while maintaining provable safety. DMPS\nemploys a local planner to dynamically select safe recovery actions that\nmaximize both short-term progress as well as long-term rewards. Crucially, the\nplanner and the neural policy play a synergistic role in DMPS. When planning\nrecovery actions for ensuring safety, the planner utilizes the neural policy to\nestimate long-term rewards, allowing it to observe beyond its short-term\nplanning horizon. Conversely, the neural policy under training learns from the\nrecovery plans proposed by the planner, converging to policies that are both\nhigh-performing and safe in practice. This approach guarantees safety during\nand after training, with bounded recovery regret that decreases exponentially\nwith planning horizon depth. Experimental results demonstrate that DMPS\nconverges to policies that rarely require shield interventions after training\nand achieve higher rewards compared to several state-of-the-art baselines.",
    "categories": [
      "cs.AI",
      "cs.LG"
    ],
    "primary_category": "cs.AI",
    "comment": "Presented at Neurips 2024",
    "pdf_url": "http://arxiv.org/pdf/2405.13863v2",
    "published_date": "2024-05-22 17:44:07 UTC",
    "updated_date": "2024-12-20 23:55:33 UTC"
  },
  {
    "arxiv_id": "2405.17455v1",
    "title": "WeatherFormer: A Pretrained Encoder Model for Learning Robust Weather Representations from Small Datasets",
    "authors": [
      "Adib Hasan",
      "Mardavij Roozbehani",
      "Munther Dahleh"
    ],
    "abstract": "This paper introduces WeatherFormer, a transformer encoder-based model\ndesigned to learn robust weather features from minimal observations. It\naddresses the challenge of modeling complex weather dynamics from small\ndatasets, a bottleneck for many prediction tasks in agriculture, epidemiology,\nand climate science. WeatherFormer was pretrained on a large pretraining\ndataset comprised of 39 years of satellite measurements across the Americas.\nWith a novel pretraining task and fine-tuning, WeatherFormer achieves\nstate-of-the-art performance in county-level soybean yield prediction and\ninfluenza forecasting. Technical innovations include a unique spatiotemporal\nencoding that captures geographical, annual, and seasonal variations, adapting\nthe transformer architecture to continuous weather data, and a pretraining\nstrategy to learn representations that are robust to missing weather features.\nThis paper for the first time demonstrates the effectiveness of pretraining\nlarge transformer encoder models for weather-dependent applications across\nmultiple domains.",
    "categories": [
      "cs.CV",
      "cs.AI",
      "cs.LG",
      "physics.ao-ph",
      "stat.ML"
    ],
    "primary_category": "cs.CV",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2405.17455v1",
    "published_date": "2024-05-22 17:43:46 UTC",
    "updated_date": "2024-05-22 17:43:46 UTC"
  },
  {
    "arxiv_id": "2405.13845v3",
    "title": "Semantic Density: Uncertainty Quantification for Large Language Models through Confidence Measurement in Semantic Space",
    "authors": [
      "Xin Qiu",
      "Risto Miikkulainen"
    ],
    "abstract": "With the widespread application of Large Language Models (LLMs) to various\ndomains, concerns regarding the trustworthiness of LLMs in safety-critical\nscenarios have been raised, due to their unpredictable tendency to hallucinate\nand generate misinformation. Existing LLMs do not have an inherent\nfunctionality to provide the users with an uncertainty/confidence metric for\neach response it generates, making it difficult to evaluate trustworthiness.\nAlthough several studies aim to develop uncertainty quantification methods for\nLLMs, they have fundamental limitations, such as being restricted to\nclassification tasks, requiring additional training and data, considering only\nlexical instead of semantic information, and being prompt-wise but not\nresponse-wise. A new framework is proposed in this paper to address these\nissues. Semantic density extracts uncertainty/confidence information for each\nresponse from a probability distribution perspective in semantic space. It has\nno restriction on task types and is \"off-the-shelf\" for new models and tasks.\nExperiments on seven state-of-the-art LLMs, including the latest Llama 3 and\nMixtral-8x22B models, on four free-form question-answering benchmarks\ndemonstrate the superior performance and robustness of semantic density\ncompared to prior approaches.",
    "categories": [
      "cs.CL",
      "cs.AI"
    ],
    "primary_category": "cs.CL",
    "comment": "Accepted to Neurips 2024",
    "pdf_url": "http://arxiv.org/pdf/2405.13845v3",
    "published_date": "2024-05-22 17:13:49 UTC",
    "updated_date": "2024-11-01 13:25:52 UTC"
  },
  {
    "arxiv_id": "2405.13832v1",
    "title": "Federated Learning in Healthcare: Model Misconducts, Security, Challenges, Applications, and Future Research Directions -- A Systematic Review",
    "authors": [
      "Md Shahin Ali",
      "Md Manjurul Ahsan",
      "Lamia Tasnim",
      "Sadia Afrin",
      "Koushik Biswas",
      "Md Maruf Hossain",
      "Md Mahfuz Ahmed",
      "Ronok Hashan",
      "Md Khairul Islam",
      "Shivakumar Raman"
    ],
    "abstract": "Data privacy has become a major concern in healthcare due to the increasing\ndigitization of medical records and data-driven medical research. Protecting\nsensitive patient information from breaches and unauthorized access is\ncritical, as such incidents can have severe legal and ethical complications.\nFederated Learning (FL) addresses this concern by enabling multiple healthcare\ninstitutions to collaboratively learn from decentralized data without sharing\nit. FL's scope in healthcare covers areas such as disease prediction, treatment\ncustomization, and clinical trial research. However, implementing FL poses\nchallenges, including model convergence in non-IID (independent and identically\ndistributed) data environments, communication overhead, and managing\nmulti-institutional collaborations. A systematic review of FL in healthcare is\nnecessary to evaluate how effectively FL can provide privacy while maintaining\nthe integrity and usability of medical data analysis. In this study, we analyze\nexisting literature on FL applications in healthcare. We explore the current\nstate of model security practices, identify prevalent challenges, and discuss\npractical applications and their implications. Additionally, the review\nhighlights promising future research directions to refine FL implementations,\nenhance data security protocols, and expand FL's use to broader healthcare\napplications, which will benefit future researchers and practitioners.",
    "categories": [
      "cs.CR",
      "cs.AI",
      "cs.LG"
    ],
    "primary_category": "cs.CR",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2405.13832v1",
    "published_date": "2024-05-22 16:59:50 UTC",
    "updated_date": "2024-05-22 16:59:50 UTC"
  },
  {
    "arxiv_id": "2405.13828v2",
    "title": "Babysit A Language Model From Scratch: Interactive Language Learning by Trials and Demonstrations",
    "authors": [
      "Ziqiao Ma",
      "Zekun Wang",
      "Joyce Chai"
    ],
    "abstract": "Humans are efficient language learners and inherently social creatures. Our\nlanguage development is largely shaped by our social interactions, for example,\nthe demonstration and feedback from caregivers. Contrary to human language\nlearning, recent advancements in large language models have primarily adopted a\nnon-interactive training paradigm, and refined pre-trained models through\nfeedback afterward. In this work, we explore how corrective feedback from\ninteractions influences neural language acquisition from scratch through\nsystematically controlled experiments, assessing whether it contributes to word\nlearning efficiency in language models. We introduce a trial-and-demonstration\n(TnD) learning framework that incorporates three distinct components: student\ntrials, teacher demonstrations, and a reward conditioned on language competence\nat various developmental stages. Our experiments reveal that the TnD approach\naccelerates word acquisition for student models of equal and smaller numbers of\nparameters, and we highlight the significance of both trials and\ndemonstrations. We further show that the teacher's choices of words influence\nstudents' word-specific learning efficiency, and a practice-makes-perfect\neffect is evident by a strong correlation between the frequency of words in\ntrials and their respective learning curves. Our findings suggest that\ninteractive language learning, with teacher demonstrations and active trials,\ncan facilitate efficient word learning in language models.",
    "categories": [
      "cs.CL",
      "cs.AI"
    ],
    "primary_category": "cs.CL",
    "comment": "NAACL 2025 (Main) & Workshop on Large Language Models and Cognition @\n  ICML 2024 (Oral)",
    "pdf_url": "http://arxiv.org/pdf/2405.13828v2",
    "published_date": "2024-05-22 16:57:02 UTC",
    "updated_date": "2025-04-18 16:06:57 UTC"
  },
  {
    "arxiv_id": "2405.13810v1",
    "title": "Leveraging 2D Information for Long-term Time Series Forecasting with Vanilla Transformers",
    "authors": [
      "Xin Cheng",
      "Xiuying Chen",
      "Shuqi Li",
      "Di Luo",
      "Xun Wang",
      "Dongyan Zhao",
      "Rui Yan"
    ],
    "abstract": "Time series prediction is crucial for understanding and forecasting complex\ndynamics in various domains, ranging from finance and economics to climate and\nhealthcare. Based on Transformer architecture, one approach involves encoding\nmultiple variables from the same timestamp into a single temporal token to\nmodel global dependencies. In contrast, another approach embeds the time points\nof individual series into separate variate tokens. The former method faces\nchallenges in learning variate-centric representations, while the latter risks\nmissing essential temporal information critical for accurate forecasting. In\nour work, we introduce GridTST, a model that combines the benefits of two\napproaches using innovative multi-directional attentions based on a vanilla\nTransformer. We regard the input time series data as a grid, where the $x$-axis\nrepresents the time steps and the $y$-axis represents the variates. A vertical\nslicing of this grid combines the variates at each time step into a\n\\textit{time token}, while a horizontal slicing embeds the individual series\nacross all time steps into a \\textit{variate token}. Correspondingly, a\n\\textit{horizontal attention mechanism} focuses on time tokens to comprehend\nthe correlations between data at various time steps, while a \\textit{vertical},\nvariate-aware \\textit{attention} is employed to grasp multivariate\ncorrelations. This combination enables efficient processing of information\nacross both time and variate dimensions, thereby enhancing the model's\nanalytical strength. % We also integrate the patch technique, segmenting time\ntokens into subseries-level patches, ensuring that local semantic information\nis retained in the embedding. The GridTST model consistently delivers\nstate-of-the-art performance across various real-world datasets.",
    "categories": [
      "cs.LG",
      "cs.AI"
    ],
    "primary_category": "cs.LG",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2405.13810v1",
    "published_date": "2024-05-22 16:41:21 UTC",
    "updated_date": "2024-05-22 16:41:21 UTC"
  },
  {
    "arxiv_id": "2405.13805v2",
    "title": "Perceptual Fairness in Image Restoration",
    "authors": [
      "Guy Ohayon",
      "Michael Elad",
      "Tomer Michaeli"
    ],
    "abstract": "Fairness in image restoration tasks is the desire to treat different\nsub-groups of images equally well. Existing definitions of fairness in image\nrestoration are highly restrictive. They consider a reconstruction to be a\ncorrect outcome for a group (e.g., women) only if it falls within the group's\nset of ground truth images (e.g., natural images of women); otherwise, it is\nconsidered entirely incorrect. Consequently, such definitions are prone to\ncontroversy, as errors in image restoration can manifest in various ways. In\nthis work we offer an alternative approach towards fairness in image\nrestoration, by considering the Group Perceptual Index (GPI), which we define\nas the statistical distance between the distribution of the group's ground\ntruth images and the distribution of their reconstructions. We assess the\nfairness of an algorithm by comparing the GPI of different groups, and say that\nit achieves perfect Perceptual Fairness (PF) if the GPIs of all groups are\nidentical. We motivate and theoretically study our new notion of fairness, draw\nits connection to previous ones, and demonstrate its utility on\nstate-of-the-art face image restoration algorithms.",
    "categories": [
      "eess.IV",
      "cs.AI",
      "cs.CV",
      "cs.LG"
    ],
    "primary_category": "eess.IV",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2405.13805v2",
    "published_date": "2024-05-22 16:32:20 UTC",
    "updated_date": "2024-10-12 12:43:47 UTC"
  },
  {
    "arxiv_id": "2405.13800v2",
    "title": "Dense Connector for MLLMs",
    "authors": [
      "Huanjin Yao",
      "Wenhao Wu",
      "Taojiannan Yang",
      "YuXin Song",
      "Mengxi Zhang",
      "Haocheng Feng",
      "Yifan Sun",
      "Zhiheng Li",
      "Wanli Ouyang",
      "Jingdong Wang"
    ],
    "abstract": "Do we fully leverage the potential of visual encoder in Multimodal Large\nLanguage Models (MLLMs)? The recent outstanding performance of MLLMs in\nmultimodal understanding has garnered broad attention from both academia and\nindustry. In the current MLLM rat race, the focus seems to be predominantly on\nthe linguistic side. We witness the rise of larger and higher-quality\ninstruction datasets, as well as the involvement of larger-sized LLMs. Yet,\nscant attention has been directed towards the visual signals utilized by MLLMs,\noften assumed to be the final high-level features extracted by a frozen visual\nencoder. In this paper, we introduce the Dense Connector - a simple, effective,\nand plug-and-play vision-language connector that significantly enhances\nexisting MLLMs by leveraging multi-layer visual features, with minimal\nadditional computational overhead. Building on this, we also propose the\nEfficient Dense Connector, which achieves performance comparable to LLaVA-v1.5\nwith only 25% of the visual tokens. Furthermore, our model, trained solely on\nimages, showcases remarkable zero-shot capabilities in video understanding as\nwell. Experimental results across various vision encoders, image resolutions,\ntraining dataset scales, varying sizes of LLMs (2.7B->70B), and diverse\narchitectures of MLLMs (e.g., LLaVA-v1.5, LLaVA-NeXT and Mini-Gemini) validate\nthe versatility and scalability of our approach, achieving state-of-the-art\nperformance across 19 image and video benchmarks. We hope that this work will\nprovide valuable experience and serve as a basic module for future MLLM\ndevelopment. Code is available at https://github.com/HJYao00/DenseConnector .",
    "categories": [
      "cs.CV",
      "cs.AI"
    ],
    "primary_category": "cs.CV",
    "comment": "27 pages, NeurIPS 2024",
    "pdf_url": "http://arxiv.org/pdf/2405.13800v2",
    "published_date": "2024-05-22 16:25:03 UTC",
    "updated_date": "2024-11-14 23:53:05 UTC"
  },
  {
    "arxiv_id": "2405.13798v3",
    "title": "Slaves to the Law of Large Numbers: An Asymptotic Equipartition Property for Perplexity in Generative Language Models",
    "authors": [
      "Avinash Mudireddy",
      "Tyler Bell",
      "Raghu Mudumbai"
    ],
    "abstract": "We prove a new asymptotic equipartition property for the perplexity of long\ntexts generated by a language model and present supporting experimental\nevidence from open-source models. Specifically we show that the logarithmic\nperplexity of any large text generated by a language model must asymptotically\nconverge to the average entropy of its token distributions. This defines a\n\"typical set\" that all long synthetic texts generated by a language model must\nbelong to. We show that this typical set is a vanishingly small subset of all\npossible grammatically correct outputs. These results suggest possible\napplications to important practical problems such as (a) detecting synthetic\nAI-generated text, and (b) testing whether a text was used to train a language\nmodel. We make no simplifying assumptions (such as stationarity) about the\nstatistics of language model outputs, and therefore our results are directly\napplicable to practical real-world models without any approximations.",
    "categories": [
      "cs.CL",
      "cs.AI",
      "cs.IT",
      "math.IT"
    ],
    "primary_category": "cs.CL",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2405.13798v3",
    "published_date": "2024-05-22 16:23:40 UTC",
    "updated_date": "2025-01-30 12:03:48 UTC"
  },
  {
    "arxiv_id": "2405.13796v5",
    "title": "Generalizing Weather Forecast to Fine-grained Temporal Scales via Physics-AI Hybrid Modeling",
    "authors": [
      "Wanghan Xu",
      "Fenghua Ling",
      "Wenlong Zhang",
      "Tao Han",
      "Hao Chen",
      "Wanli Ouyang",
      "Lei Bai"
    ],
    "abstract": "Data-driven artificial intelligence (AI) models have made significant\nadvancements in weather forecasting, particularly in medium-range and\nnowcasting. However, most data-driven weather forecasting models are black-box\nsystems that focus on learning data mapping rather than fine-grained physical\nevolution in the time dimension. Consequently, the limitations in the temporal\nscale of datasets prevent these models from forecasting at finer time scales.\nThis paper proposes a physics-AI hybrid model (i.e., WeatherGFT) which\ngeneralizes weather forecasts to finer-grained temporal scales beyond training\ndataset. Specifically, we employ a carefully designed PDE kernel to simulate\nphysical evolution on a small time scale (e.g., 300 seconds) and use a parallel\nneural networks with a learnable router for bias correction. Furthermore, we\nintroduce a lead time-aware training framework to promote the generalization of\nthe model at different lead times. The weight analysis of physics-AI modules\nindicates that physics conducts major evolution while AI performs corrections\nadaptively. Extensive experiments show that WeatherGFT trained on an hourly\ndataset, effectively generalizes forecasts across multiple time scales,\nincluding 30-minute, which is even smaller than the dataset's temporal\nresolution.",
    "categories": [
      "cs.LG",
      "cs.AI"
    ],
    "primary_category": "cs.LG",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2405.13796v5",
    "published_date": "2024-05-22 16:21:02 UTC",
    "updated_date": "2025-01-13 06:35:54 UTC"
  },
  {
    "arxiv_id": "2405.13792v2",
    "title": "xRAG: Extreme Context Compression for Retrieval-augmented Generation with One Token",
    "authors": [
      "Xin Cheng",
      "Xun Wang",
      "Xingxing Zhang",
      "Tao Ge",
      "Si-Qing Chen",
      "Furu Wei",
      "Huishuai Zhang",
      "Dongyan Zhao"
    ],
    "abstract": "This paper introduces xRAG, an innovative context compression method tailored\nfor retrieval-augmented generation. xRAG reinterprets document embeddings in\ndense retrieval--traditionally used solely for retrieval--as features from the\nretrieval modality. By employing a modality fusion methodology, xRAG seamlessly\nintegrates these embeddings into the language model representation space,\neffectively eliminating the need for their textual counterparts and achieving\nan extreme compression rate. In xRAG, the only trainable component is the\nmodality bridge, while both the retriever and the language model remain frozen.\nThis design choice allows for the reuse of offline-constructed document\nembeddings and preserves the plug-and-play nature of retrieval augmentation.\nExperimental results demonstrate that xRAG achieves an average improvement of\nover 10% across six knowledge-intensive tasks, adaptable to various language\nmodel backbones, ranging from a dense 7B model to an 8x7B Mixture of Experts\nconfiguration. xRAG not only significantly outperforms previous context\ncompression methods but also matches the performance of uncompressed models on\nseveral datasets, while reducing overall FLOPs by a factor of 3.53. Our work\npioneers new directions in retrieval-augmented generation from the perspective\nof multimodality fusion, and we hope it lays the foundation for future\nefficient and scalable retrieval-augmented systems",
    "categories": [
      "cs.CL",
      "cs.AI",
      "cs.IR"
    ],
    "primary_category": "cs.CL",
    "comment": "Neurips 2024",
    "pdf_url": "http://arxiv.org/pdf/2405.13792v2",
    "published_date": "2024-05-22 16:15:17 UTC",
    "updated_date": "2024-12-09 06:07:03 UTC"
  },
  {
    "arxiv_id": "2405.13786v1",
    "title": "Towards Explainable Test Case Prioritisation with Learning-to-Rank Models",
    "authors": [
      "Aurora Ram√≠rez",
      "Mario Berrios",
      "Jos√© Ra√∫l Romero",
      "Robert Feldt"
    ],
    "abstract": "Test case prioritisation (TCP) is a critical task in regression testing to\nensure quality as software evolves. Machine learning has become a common way to\nachieve it. In particular, learning-to-rank (LTR) algorithms provide an\neffective method of ordering and prioritising test cases. However, their use\nposes a challenge in terms of explainability, both globally at the model level\nand locally for particular results. Here, we present and discuss scenarios that\nrequire different explanations and how the particularities of TCP (multiple\nbuilds over time, test case and test suite variations, etc.) could influence\nthem. We include a preliminary experiment to analyse the similarity of\nexplanations, showing that they do not only vary depending on test\ncase-specific predictions, but also on the relative ranks.",
    "categories": [
      "cs.SE",
      "cs.AI",
      "D.2.5; I.2.6"
    ],
    "primary_category": "cs.SE",
    "comment": "3rd International Workshop on Artificial Intelligence in Software\n  Testing (AIST) - International Conference on Software Testing and Validation\n  (ICST)",
    "pdf_url": "http://arxiv.org/pdf/2405.13786v1",
    "published_date": "2024-05-22 16:11:45 UTC",
    "updated_date": "2024-05-22 16:11:45 UTC"
  },
  {
    "arxiv_id": "2405.13785v2",
    "title": "Efficient Two-Stage Gaussian Process Regression Via Automatic Kernel Search and Subsampling",
    "authors": [
      "Shifan Zhao",
      "Jiaying Lu",
      "Ji Yang",
      "Edmond Chow",
      "Yuanzhe Xi"
    ],
    "abstract": "Gaussian Process Regression (GPR) is widely used in statistics and machine\nlearning for prediction tasks requiring uncertainty measures. Its efficacy\ndepends on the appropriate specification of the mean function, covariance\nkernel function, and associated hyperparameters. Severe misspecifications can\nlead to inaccurate results and problematic consequences, especially in\nsafety-critical applications. However, a systematic approach to handle these\nmisspecifications is lacking in the literature. In this work, we propose a\ngeneral framework to address these issues. Firstly, we introduce a flexible\ntwo-stage GPR framework that separates mean prediction and uncertainty\nquantification (UQ) to prevent mean misspecification, which can introduce bias\ninto the model. Secondly, kernel function misspecification is addressed through\na novel automatic kernel search algorithm, supported by theoretical analysis,\nthat selects the optimal kernel from a candidate set. Additionally, we propose\na subsampling-based warm-start strategy for hyperparameter initialization to\nimprove efficiency and avoid hyperparameter misspecification. With much lower\ncomputational cost, our subsampling-based strategy can yield competitive or\nbetter performance than training exclusively on the full dataset. Combining all\nthese components, we recommend two GPR methods-exact and scalable-designed to\nmatch available computational resources and specific UQ requirements. Extensive\nevaluation on real-world datasets, including UCI benchmarks and a\nsafety-critical medical case study, demonstrates the robustness and precision\nof our methods.",
    "categories": [
      "cs.LG",
      "cs.AI",
      "math.PR",
      "stat.ML",
      "G.3; J.3"
    ],
    "primary_category": "cs.LG",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2405.13785v2",
    "published_date": "2024-05-22 16:11:29 UTC",
    "updated_date": "2024-09-19 13:44:26 UTC"
  },
  {
    "arxiv_id": "2405.13779v1",
    "title": "Robust Disaster Assessment from Aerial Imagery Using Text-to-Image Synthetic Data",
    "authors": [
      "Tarun Kalluri",
      "Jihyeon Lee",
      "Kihyuk Sohn",
      "Sahil Singla",
      "Manmohan Chandraker",
      "Joseph Xu",
      "Jeremiah Liu"
    ],
    "abstract": "We present a simple and efficient method to leverage emerging text-to-image\ngenerative models in creating large-scale synthetic supervision for the task of\ndamage assessment from aerial images. While significant recent advances have\nresulted in improved techniques for damage assessment using aerial or satellite\nimagery, they still suffer from poor robustness to domains where manual labeled\ndata is unavailable, directly impacting post-disaster humanitarian assistance\nin such under-resourced geographies. Our contribution towards improving domain\nrobustness in this scenario is two-fold. Firstly, we leverage the text-guided\nmask-based image editing capabilities of generative models and build an\nefficient and easily scalable pipeline to generate thousands of post-disaster\nimages from low-resource domains. Secondly, we propose a simple two-stage\ntraining approach to train robust models while using manual supervision from\ndifferent source domains along with the generated synthetic target domain data.\nWe validate the strength of our proposed framework under cross-geography domain\ntransfer setting from xBD and SKAI images in both single-source and\nmulti-source settings, achieving significant improvements over a source-only\nbaseline in each case.",
    "categories": [
      "cs.CV",
      "cs.AI",
      "cs.LG"
    ],
    "primary_category": "cs.CV",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2405.13779v1",
    "published_date": "2024-05-22 16:07:05 UTC",
    "updated_date": "2024-05-22 16:07:05 UTC"
  },
  {
    "arxiv_id": "2405.13777v3",
    "title": "No Filter: Cultural and Socioeconomic Diversity in Contrastive Vision-Language Models",
    "authors": [
      "Ang√©line Pouget",
      "Lucas Beyer",
      "Emanuele Bugliarello",
      "Xiao Wang",
      "Andreas Peter Steiner",
      "Xiaohua Zhai",
      "Ibrahim Alabdulmohsin"
    ],
    "abstract": "We study cultural and socioeconomic diversity in contrastive vision-language\nmodels (VLMs). Using a broad range of benchmark datasets and evaluation\nmetrics, we bring to attention several important findings. First, the common\nfiltering of training data to English image-text pairs disadvantages\ncommunities of lower socioeconomic status and negatively impacts cultural\nunderstanding. Notably, this performance gap is not captured by - and even at\nodds with - the currently popular evaluation metrics derived from the\nWestern-centric ImageNet and COCO datasets. Second, pretraining with global,\nunfiltered data before fine-tuning on English content can improve cultural\nunderstanding without sacrificing performance on said popular benchmarks.\nThird, we introduce the task of geo-localization as a novel evaluation metric\nto assess cultural diversity in VLMs. Our work underscores the value of using\ndiverse data to create more inclusive multimodal systems and lays the\ngroundwork for developing VLMs that better represent global perspectives.",
    "categories": [
      "cs.CV",
      "cs.AI"
    ],
    "primary_category": "cs.CV",
    "comment": "17 pages, 5 figures, 4 tables. 38th Conference on Neural Information\n  Processing Systems (NeurIPS 2024)",
    "pdf_url": "http://arxiv.org/pdf/2405.13777v3",
    "published_date": "2024-05-22 16:04:22 UTC",
    "updated_date": "2024-10-23 21:25:39 UTC"
  },
  {
    "arxiv_id": "2405.14899v2",
    "title": "DETAIL: Task DEmonsTration Attribution for Interpretable In-context Learning",
    "authors": [
      "Zijian Zhou",
      "Xiaoqiang Lin",
      "Xinyi Xu",
      "Alok Prakash",
      "Daniela Rus",
      "Bryan Kian Hsiang Low"
    ],
    "abstract": "In-context learning (ICL) allows transformer-based language models that are\npre-trained on general text to quickly learn a specific task with a few \"task\ndemonstrations\" without updating their parameters, significantly boosting their\nflexibility and generality. ICL possesses many distinct characteristics from\nconventional machine learning, thereby requiring new approaches to interpret\nthis learning paradigm. Taking the viewpoint of recent works showing that\ntransformers learn in context by formulating an internal optimizer, we propose\nan influence function-based attribution technique, DETAIL, that addresses the\nspecific characteristics of ICL. We empirically verify the effectiveness of our\napproach for demonstration attribution while being computationally efficient.\nLeveraging the results, we then show how DETAIL can help improve model\nperformance in real-world scenarios through demonstration reordering and\ncuration. Finally, we experimentally prove the wide applicability of DETAIL by\nshowing our attribution scores obtained on white-box models are transferable to\nblack-box models in improving model performance.",
    "categories": [
      "cs.CL",
      "cs.AI",
      "cs.LG"
    ],
    "primary_category": "cs.CL",
    "comment": "Accepted at NeurIPS 2024",
    "pdf_url": "http://arxiv.org/pdf/2405.14899v2",
    "published_date": "2024-05-22 15:52:52 UTC",
    "updated_date": "2024-12-15 02:13:10 UTC"
  },
  {
    "arxiv_id": "2407.00032v1",
    "title": "Design a Win-Win Strategy That Is Fair to Both Service Providers and Tasks When Rejection Is Not an Option",
    "authors": [
      "Yohai Trabelsi",
      "Pan Xu",
      "Sarit Kraus"
    ],
    "abstract": "Assigning tasks to service providers is a frequent procedure across various\napplications. Often the tasks arrive dynamically while the service providers\nremain static. Preventing task rejection caused by service provider overload is\nof utmost significance. To ensure a positive experience in relevant\napplications for both service providers and tasks, fairness must be considered.\nTo address the issue, we model the problem as an online matching within a\nbipartite graph and tackle two minimax problems: one focuses on minimizing the\nhighest waiting time of a task, while the other aims to minimize the highest\nworkload of a service provider. We show that the second problem can be\nexpressed as a linear program and thus solved efficiently while maintaining a\nreasonable approximation to the objective of the first problem. We developed\nnovel methods that utilize the two minimax problems. We conducted extensive\nsimulation experiments using real data and demonstrated that our novel\nheuristics, based on the linear program, performed remarkably well.",
    "categories": [
      "cs.DC",
      "cs.AI"
    ],
    "primary_category": "cs.DC",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2407.00032v1",
    "published_date": "2024-05-22 15:52:33 UTC",
    "updated_date": "2024-05-22 15:52:33 UTC"
  },
  {
    "arxiv_id": "2405.13758v1",
    "title": "Counterfactual Gradients-based Quantification of Prediction Trust in Neural Networks",
    "authors": [
      "Mohit Prabhushankar",
      "Ghassan AlRegib"
    ],
    "abstract": "The widespread adoption of deep neural networks in machine learning calls for\nan objective quantification of esoteric trust. In this paper we propose\nGradTrust, a classification trust measure for large-scale neural networks at\ninference. The proposed method utilizes variance of counterfactual gradients,\ni.e. the required changes in the network parameters if the label were\ndifferent. We show that GradTrust is superior to existing techniques for\ndetecting misprediction rates on $50000$ images from ImageNet validation\ndataset. Depending on the network, GradTrust detects images where either the\nground truth is incorrect or ambiguous, or the classes are co-occurring. We\nextend GradTrust to Video Action Recognition on Kinetics-400 dataset. We\nshowcase results on $14$ architectures pretrained on ImageNet and $5$\narchitectures pretrained on Kinetics-400. We observe the following: (i) simple\nmethodologies like negative log likelihood and margin classifiers outperform\nstate-of-the-art uncertainty and out-of-distribution detection techniques for\nmisprediction rates, and (ii) the proposed GradTrust is in the Top-2 performing\nmethods on $37$ of the considered $38$ experimental modalities. The code is\navailable at: https://github.com/olivesgatech/GradTrust",
    "categories": [
      "cs.CV",
      "cs.AI",
      "cs.LG"
    ],
    "primary_category": "cs.CV",
    "comment": "2024 IEEE 7th International Conference on Multimedia Information\n  Processing and Retrieval (MIPR)",
    "pdf_url": "http://arxiv.org/pdf/2405.13758v1",
    "published_date": "2024-05-22 15:39:54 UTC",
    "updated_date": "2024-05-22 15:39:54 UTC"
  },
  {
    "arxiv_id": "2405.13753v3",
    "title": "A Dynamic Model of Performative Human-ML Collaboration: Theory and Empirical Evidence",
    "authors": [
      "Tom S√ºhr",
      "Samira Samadi",
      "Chiara Farronato"
    ],
    "abstract": "Machine learning (ML) models are increasingly used in various applications,\nfrom recommendation systems in e-commerce to diagnosis prediction in\nhealthcare. In this paper, we present a novel dynamic framework for thinking\nabout the deployment of ML models in a performative, human-ML collaborative\nsystem. In our framework, the introduction of ML recommendations changes the\ndata-generating process of human decisions, which are only a proxy to the\nground truth and which are then used to train future versions of the model. We\nshow that this dynamic process in principle can converge to different stable\npoints, i.e. where the ML model and the Human+ML system have the same\nperformance. Some of these stable points are suboptimal with respect to the\nactual ground truth. As a proof of concept, we conduct an empirical user study\nwith 1,408 participants. In the study, humans solve instances of the knapsack\nproblem with the help of machine learning predictions of varying performance.\nThis is an ideal setting because we can identify the actual ground truth, and\nevaluate the performance of human decisions supported by ML recommendations. We\nfind that for many levels of ML performance, humans can improve upon the ML\npredictions. We also find that the improvement could be even higher if humans\nrationally followed the ML recommendations. Finally, we test whether monetary\nincentives can increase the quality of human decisions, but we fail to find any\npositive effect. Using our empirical data to approximate our collaborative\nsystem suggests that the learning process would dynamically reach an\nequilibrium performance that is around 92% of the maximum knapsack value. Our\nresults have practical implications for the deployment of ML models in contexts\nwhere human decisions may deviate from the indisputable ground truth.",
    "categories": [
      "cs.LG",
      "cs.AI",
      "cs.HC",
      "econ.GN",
      "q-fin.EC",
      "68T05",
      "I.2.1; I.2.6; K.6"
    ],
    "primary_category": "cs.LG",
    "comment": "10 Pages and appendix",
    "pdf_url": "http://arxiv.org/pdf/2405.13753v3",
    "published_date": "2024-05-22 15:38:30 UTC",
    "updated_date": "2024-10-07 08:20:55 UTC"
  },
  {
    "arxiv_id": "2405.15815v1",
    "title": "A social path to human-like artificial intelligence",
    "authors": [
      "Edgar A. Du√©√±ez-Guzm√°n",
      "Suzanne Sadedin",
      "Jane X. Wang",
      "Kevin R. McKee",
      "Joel Z. Leibo"
    ],
    "abstract": "Traditionally, cognitive and computer scientists have viewed intelligence\nsolipsistically, as a property of unitary agents devoid of social context.\nGiven the success of contemporary learning algorithms, we argue that the\nbottleneck in artificial intelligence (AI) progress is shifting from data\nassimilation to novel data generation. We bring together evidence showing that\nnatural intelligence emerges at multiple scales in networks of interacting\nagents via collective living, social relationships and major evolutionary\ntransitions, which contribute to novel data generation through mechanisms such\nas population pressures, arms races, Machiavellian selection, social learning\nand cumulative culture. Many breakthroughs in AI exploit some of these\nprocesses, from multi-agent structures enabling algorithms to master complex\ngames like Capture-The-Flag and StarCraft II, to strategic communication in\nDiplomacy and the shaping of AI data streams by other AIs. Moving beyond a\nsolipsistic view of agency to integrate these mechanisms suggests a path to\nhuman-like compounding innovation through ongoing novel data generation.",
    "categories": [
      "cs.AI",
      "cs.LG",
      "68T05",
      "I.2.6"
    ],
    "primary_category": "cs.AI",
    "comment": "17 pages, 2 figures, 1 box",
    "pdf_url": "http://arxiv.org/pdf/2405.15815v1",
    "published_date": "2024-05-22 15:38:10 UTC",
    "updated_date": "2024-05-22 15:38:10 UTC"
  },
  {
    "arxiv_id": "2405.13751v1",
    "title": "GameVLM: A Decision-making Framework for Robotic Task Planning Based on Visual Language Models and Zero-sum Games",
    "authors": [
      "Aoran Mei",
      "Jianhua Wang",
      "Guo-Niu Zhu",
      "Zhongxue Gan"
    ],
    "abstract": "With their prominent scene understanding and reasoning capabilities,\npre-trained visual-language models (VLMs) such as GPT-4V have attracted\nincreasing attention in robotic task planning. Compared with traditional task\nplanning strategies, VLMs are strong in multimodal information parsing and code\ngeneration and show remarkable efficiency. Although VLMs demonstrate great\npotential in robotic task planning, they suffer from challenges like\nhallucination, semantic complexity, and limited context. To handle such issues,\nthis paper proposes a multi-agent framework, i.e., GameVLM, to enhance the\ndecision-making process in robotic task planning. In this study, VLM-based\ndecision and expert agents are presented to conduct the task planning.\nSpecifically, decision agents are used to plan the task, and the expert agent\nis employed to evaluate these task plans. Zero-sum game theory is introduced to\nresolve inconsistencies among different agents and determine the optimal\nsolution. Experimental results on real robots demonstrate the efficacy of the\nproposed framework, with an average success rate of 83.3%.",
    "categories": [
      "cs.RO",
      "cs.AI"
    ],
    "primary_category": "cs.RO",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2405.13751v1",
    "published_date": "2024-05-22 15:37:28 UTC",
    "updated_date": "2024-05-22 15:37:28 UTC"
  },
  {
    "arxiv_id": "2406.19399v1",
    "title": "Predicting Customer Goals in Financial Institution Services: A Data-Driven LSTM Approach",
    "authors": [
      "Andrew Estornell",
      "Stylianos Loukas Vasileiou",
      "William Yeoh",
      "Daniel Borrajo",
      "Rui Silva"
    ],
    "abstract": "In today's competitive financial landscape, understanding and anticipating\ncustomer goals is crucial for institutions to deliver a personalized and\noptimized user experience. This has given rise to the problem of accurately\npredicting customer goals and actions. Focusing on that problem, we use\nhistorical customer traces generated by a realistic simulator and present two\nsimple models for predicting customer goals and future actions -- an LSTM model\nand an LSTM model enhanced with state-space graph embeddings. Our results\ndemonstrate the effectiveness of these models when it comes to predicting\ncustomer goals and actions.",
    "categories": [
      "q-fin.ST",
      "cs.AI",
      "cs.CE"
    ],
    "primary_category": "q-fin.ST",
    "comment": "Accepted at the FinPlan 2023 workshop at ICAPS 2023",
    "pdf_url": "http://arxiv.org/pdf/2406.19399v1",
    "published_date": "2024-05-22 15:36:03 UTC",
    "updated_date": "2024-05-22 15:36:03 UTC"
  },
  {
    "arxiv_id": "2405.13746v2",
    "title": "CG-FedLLM: How to Compress Gradients in Federated Fune-tuning for Large Language Models",
    "authors": [
      "Huiwen Wu",
      "Xiaohan Li",
      "Deyi Zhang",
      "Xiaogang Xu",
      "Jiafei Wu",
      "Puning Zhao",
      "Zhe Liu"
    ],
    "abstract": "The success of current Large-Language Models (LLMs) hinges on extensive\ntraining data that is collected and stored centrally, called Centralized\nLearning (CL). However, such a collection manner poses a privacy threat, and\none potential solution is Federated Learning (FL), which transfers gradients,\nnot raw data, among clients. Unlike traditional networks, FL for LLMs incurs\nsignificant communication costs due to their tremendous parameters. This study\nintroduces an innovative approach to compress gradients to improve\ncommunication efficiency during LLM FL, formulating the new FL pipeline named\nCG-FedLLM. This approach integrates an encoder on the client side to acquire\nthe compressed gradient features and a decoder on the server side to\nreconstruct the gradients. We also developed a novel training strategy that\ncomprises Temporal-ensemble Gradient-Aware Pre-training (TGAP) to identify\ncharacteristic gradients of the target model and Federated AutoEncoder-Involved\nFine-tuning (FAF) to compress gradients adaptively. Extensive experiments\nconfirm that our approach reduces communication costs and improves performance\n(e.g., average 3 points increment compared with traditional CL- and FL-based\nfine-tuning with LlaMA on a well-recognized benchmark, C-Eval). This\nimprovement is because our encoder-decoder, trained via TGAP and FAF, can\nfilter gradients while selectively preserving critical features. Furthermore,\nwe present a series of experimental analyses focusing on the signal-to-noise\nratio, compression rate, and robustness within this privacy-centric framework,\nproviding insight into developing more efficient and secure LLMs.",
    "categories": [
      "cs.LG",
      "cs.AI",
      "cs.DC"
    ],
    "primary_category": "cs.LG",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2405.13746v2",
    "published_date": "2024-05-22 15:32:38 UTC",
    "updated_date": "2024-05-24 03:17:41 UTC"
  },
  {
    "arxiv_id": "2405.13735v2",
    "title": "Transfer of Safety Controllers Through Learning Deep Inverse Dynamics Model",
    "authors": [
      "Alireza Nadali",
      "Ashutosh Trivedi",
      "Majid Zamani"
    ],
    "abstract": "Control barrier certificates have proven effective in formally guaranteeing\nthe safety of the control systems. However, designing a control barrier\ncertificate is a time-consuming and computationally expensive endeavor that\nrequires expert input in the form of domain knowledge and mathematical\nmaturity. Additionally, when a system undergoes slight changes, the new\ncontroller and its correctness certificate need to be recomputed, incurring\nsimilar computational challenges as those faced during the design of the\noriginal controller. Prior approaches have utilized transfer learning to\ntransfer safety guarantees in the form of a barrier certificate while\nmaintaining the control invariant. Unfortunately, in practical settings, the\nsource and the target environments often deviate substantially in their control\ninputs, rendering the aforementioned approach impractical. To address this\nchallenge, we propose integrating \\emph{inverse dynamics} -- a neural network\nthat suggests required action given a desired successor state -- of the target\nsystem with the barrier certificate of the source system to provide formal\nproof of safety. In addition, we propose a validity condition that, when met,\nguarantees correctness of the controller. We demonstrate the effectiveness of\nour approach through three case studies.",
    "categories": [
      "eess.SY",
      "cs.AI",
      "cs.LG",
      "cs.SY"
    ],
    "primary_category": "eess.SY",
    "comment": "Extended Version, submitted to ADHS 2024",
    "pdf_url": "http://arxiv.org/pdf/2405.13735v2",
    "published_date": "2024-05-22 15:28:43 UTC",
    "updated_date": "2024-05-24 19:29:48 UTC"
  },
  {
    "arxiv_id": "2405.13729v2",
    "title": "ComboStoc: Combinatorial Stochasticity for Diffusion Generative Models",
    "authors": [
      "Rui Xu",
      "Jiepeng Wang",
      "Hao Pan",
      "Yang Liu",
      "Xin Tong",
      "Shiqing Xin",
      "Changhe Tu",
      "Taku Komura",
      "Wenping Wang"
    ],
    "abstract": "In this paper, we study an under-explored but important factor of diffusion\ngenerative models, i.e., the combinatorial complexity. Data samples are\ngenerally high-dimensional, and for various structured generation tasks, there\nare additional attributes which are combined to associate with data samples. We\nshow that the space spanned by the combination of dimensions and attributes is\ninsufficiently sampled by existing training scheme of diffusion generative\nmodels, causing degraded test time performance. We present a simple fix to this\nproblem by constructing stochastic processes that fully exploit the\ncombinatorial structures, hence the name ComboStoc. Using this simple strategy,\nwe show that network training is significantly accelerated across diverse data\nmodalities, including images and 3D structured shapes. Moreover, ComboStoc\nenables a new way of test time generation which uses insynchronized time steps\nfor different dimensions and attributes, thus allowing for varying degrees of\ncontrol over them.",
    "categories": [
      "cs.LG",
      "cs.AI",
      "cs.CV",
      "cs.GR"
    ],
    "primary_category": "cs.LG",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2405.13729v2",
    "published_date": "2024-05-22 15:23:10 UTC",
    "updated_date": "2024-05-24 07:05:59 UTC"
  },
  {
    "arxiv_id": "2405.13715v3",
    "title": "Traffic Scenario Logic: A Spatial-Temporal Logic for Modeling and Reasoning of Urban Traffic Scenarios",
    "authors": [
      "Ruolin Wang",
      "Yuejiao Xu",
      "Jianmin Ji"
    ],
    "abstract": "Formal representations of traffic scenarios can be used to generate test\ncases for the safety verification of autonomous driving. However, most existing\nmethods are limited to highway or highly simplified intersection scenarios due\nto the intricacy and diversity of traffic scenarios. In response, we propose\nTraffic Scenario Logic (TSL), which is a spatial-temporal logic designed for\nmodeling and reasoning of urban pedestrian-free traffic scenarios. TSL provides\na formal representation of the urban road network that can be derived from\nOpenDRIVE, i.e., the de facto industry standard of high-definition maps for\nautonomous driving, enabling the representation of a broad range of traffic\nscenarios without discretization approximations. We implemented the reasoning\nof TSL using Telingo, i.e., a solver for temporal programs based on Answer Set\nProgramming, and tested it on different urban road layouts. Demonstrations show\nthe effectiveness of TSL in test scenario generation and its potential value in\nareas like decision-making and control verification of autonomous driving. The\ncode for TSL reasoning has been open-sourced.",
    "categories": [
      "cs.LO",
      "cs.AI"
    ],
    "primary_category": "cs.LO",
    "comment": "Accepted by AAAI 2025. 8 pages of main text, 19 pages of technical\n  appendix",
    "pdf_url": "http://arxiv.org/pdf/2405.13715v3",
    "published_date": "2024-05-22 15:06:50 UTC",
    "updated_date": "2025-02-20 06:58:25 UTC"
  },
  {
    "arxiv_id": "2405.13711v1",
    "title": "VAE-Var: Variational-Autoencoder-Enhanced Variational Assimilation",
    "authors": [
      "Yi Xiao",
      "Qilong Jia",
      "Wei Xue",
      "Lei Bai"
    ],
    "abstract": "Data assimilation refers to a set of algorithms designed to compute the\noptimal estimate of a system's state by refining the prior prediction (known as\nbackground states) using observed data. Variational assimilation methods rely\non the maximum likelihood approach to formulate a variational cost, with the\noptimal state estimate derived by minimizing this cost. Although traditional\nvariational methods have achieved great success and have been widely used in\nmany numerical weather prediction centers, they generally assume Gaussian\nerrors in the background states, which limits the accuracy of these algorithms\ndue to the inherent inaccuracies of this assumption. In this paper, we\nintroduce VAE-Var, a novel variational algorithm that leverages a variational\nautoencoder (VAE) to model a non-Gaussian estimate of the background error\ndistribution. We theoretically derive the variational cost under the VAE\nestimation and present the general formulation of VAE-Var; we implement VAE-Var\non low-dimensional chaotic systems and demonstrate through experimental results\nthat VAE-Var consistently outperforms traditional variational assimilation\nmethods in terms of accuracy across various observational settings.",
    "categories": [
      "cs.LG",
      "cs.AI",
      "math.DS",
      "physics.ao-ph"
    ],
    "primary_category": "cs.LG",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2405.13711v1",
    "published_date": "2024-05-22 15:01:05 UTC",
    "updated_date": "2024-05-22 15:01:05 UTC"
  },
  {
    "arxiv_id": "2405.13707v2",
    "title": "Rethinking and Accelerating Graph Condensation: A Training-Free Approach with Class Partition",
    "authors": [
      "Xinyi Gao",
      "Guanhua Ye",
      "Tong Chen",
      "Wentao Zhang",
      "Junliang Yu",
      "Hongzhi Yin"
    ],
    "abstract": "The increasing prevalence of large-scale graphs poses a significant challenge\nfor graph neural network training, attributed to their substantial\ncomputational requirements. In response, graph condensation (GC) emerges as a\npromising data-centric solution aiming to substitute the large graph with a\nsmall yet informative condensed graph to facilitate data-efficient GNN\ntraining. However, existing GC methods suffer from intricate optimization\nprocesses, necessitating excessive computing resources and training time. In\nthis paper, we revisit existing GC optimization strategies and identify two\npervasive issues therein: (1) various GC optimization strategies converge to\ncoarse-grained class-level node feature matching between the original and\ncondensed graphs; (2) existing GC methods rely on a Siamese graph network\narchitecture that requires time-consuming bi-level optimization with iterative\ngradient computations. To overcome these issues, we propose a training-free GC\nframework termed Class-partitioned Graph Condensation (CGC), which refines the\nnode distribution matching from the class-to-class paradigm into a novel\nclass-to-node paradigm, transforming the GC optimization into a class partition\nproblem which can be efficiently solved by any clustering methods. Moreover,\nCGC incorporates a pre-defined graph structure to enable a closed-form solution\nfor condensed node features, eliminating the need for back-and-forth gradient\ndescent in existing GC approaches. Extensive experiments demonstrate that CGC\nachieves an exceedingly efficient condensation process with advanced accuracy.\nCompared with the state-of-the-art GC methods, CGC condenses the Ogbn-products\ngraph within 30 seconds, achieving a speedup ranging from $10^2$X to $10^4$X\nand increasing accuracy by up to 4.2%.",
    "categories": [
      "cs.LG",
      "cs.AI"
    ],
    "primary_category": "cs.LG",
    "comment": "ACM Web Conference 2025 (WWW '25)",
    "pdf_url": "http://arxiv.org/pdf/2405.13707v2",
    "published_date": "2024-05-22 14:57:09 UTC",
    "updated_date": "2025-01-23 08:49:04 UTC"
  },
  {
    "arxiv_id": "2405.17454v1",
    "title": "Generative AI for the Optimization of Next-Generation Wireless Networks: Basics, State-of-the-Art, and Open Challenges",
    "authors": [
      "Fahime Khoramnejad",
      "Ekram Hossain"
    ],
    "abstract": "Next-generation (xG) wireless networks, with their complex and dynamic\nnature, present significant challenges to using traditional optimization\ntechniques. Generative AI (GAI) emerges as a powerful tool due to its unique\nstrengths. Unlike traditional optimization techniques and other machine\nlearning methods, GAI excels at learning from real-world network data,\ncapturing its intricacies. This enables safe, offline exploration of various\nconfigurations and generation of diverse, unseen scenarios, empowering\nproactive, data-driven exploration and optimization for xG networks.\nAdditionally, GAI's scalability makes it ideal for large-scale xG networks.\nThis paper surveys how GAI-based models unlock optimization opportunities in xG\nwireless networks. We begin by providing a review of GAI models and some of the\nmajor communication paradigms of xG (e.g., 6G) wireless networks. We then delve\ninto exploring how GAI can be used to improve resource allocation and enhance\noverall network performance. Additionally, we briefly review the networking\nrequirements for supporting GAI applications in xG wireless networks. The paper\nfurther discusses the key challenges and future research directions in\nleveraging GAI for network optimization. Finally, a case study demonstrates the\napplication of a diffusion-based GAI model for load balancing, carrier\naggregation, and backhauling optimization in non-terrestrial networks, a core\ntechnology of xG networks. This case study serves as a practical example of how\nthe combination of reinforcement learning and GAI can be implemented to address\nreal-world network optimization problems.",
    "categories": [
      "cs.NI",
      "cs.AI"
    ],
    "primary_category": "cs.NI",
    "comment": "Submitted for possible publication",
    "pdf_url": "http://arxiv.org/pdf/2405.17454v1",
    "published_date": "2024-05-22 14:56:25 UTC",
    "updated_date": "2024-05-22 14:56:25 UTC"
  },
  {
    "arxiv_id": "2405.13699v1",
    "title": "Uncertainty-aware Evaluation of Auxiliary Anomalies with the Expected Anomaly Posterior",
    "authors": [
      "Lorenzo Perini",
      "Maja Rudolph",
      "Sabrina Schmedding",
      "Chen Qiu"
    ],
    "abstract": "Anomaly detection is the task of identifying examples that do not behave as\nexpected. Because anomalies are rare and unexpected events, collecting real\nanomalous examples is often challenging in several applications. In addition,\nlearning an anomaly detector with limited (or no) anomalies often yields poor\nprediction performance. One option is to employ auxiliary synthetic anomalies\nto improve the model training. However, synthetic anomalies may be of poor\nquality: anomalies that are unrealistic or indistinguishable from normal\nsamples may deteriorate the detector's performance. Unfortunately, no existing\nmethods quantify the quality of auxiliary anomalies. We fill in this gap and\npropose the expected anomaly posterior (EAP), an uncertainty-based score\nfunction that measures the quality of auxiliary anomalies by quantifying the\ntotal uncertainty of an anomaly detector. Experimentally on 40 benchmark\ndatasets of images and tabular data, we show that EAP outperforms 12 adapted\ndata quality estimators in the majority of cases.",
    "categories": [
      "cs.LG",
      "cs.AI"
    ],
    "primary_category": "cs.LG",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2405.13699v1",
    "published_date": "2024-05-22 14:43:29 UTC",
    "updated_date": "2024-05-22 14:43:29 UTC"
  },
  {
    "arxiv_id": "2405.13698v2",
    "title": "How to set AdamW's weight decay as you scale model and dataset size",
    "authors": [
      "Xi Wang",
      "Laurence Aitchison"
    ],
    "abstract": "The scaling of the optimal AdamW weight decay hyperparameter with model and\ndataset size is critical as we seek to build larger models, but is poorly\nunderstood. We show that weights learned by AdamW can be understood as an\nexponential moving average (EMA) of recent updates. This gives critical\ninsights for how to set the weight decay in AdamW, and how the weight decay\nshould scale with model and dataset size. In particular, the key hyperparameter\nfor an exponential moving average is the EMA timescale. Intuitively, the EMA\ntimescale can be understood as the number of recent iterations the EMA averages\nover. We find that the optimal timescale, measured in epochs, is roughly\nconstant as we change model and dataset size. Moreover, given a learning rate,\nthere is a one-to-one mapping from the EMA timescale to the weight decay\nhyperparameter. Thus, if the optimal EMA timescale is constant, that implies\nthat as the dataset size increases, the optimal weight decay should fall and as\nthe model size increases, the optimal weight decay should increase (if we\nfollow the muP recommendation for scaling the learning rate). We validate these\nscaling rules on ResNet-18 and Vision Transformers trained on CIFAR-10 and\nImageNet, and on NanoGPT pre-training on OpenWebText. Finally, we found that as\ntraining progresses, muP's learning rate scaling breaks down for AdamW unless\nweight decay is scaled appropriately.",
    "categories": [
      "cs.LG",
      "cs.AI"
    ],
    "primary_category": "cs.LG",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2405.13698v2",
    "published_date": "2024-05-22 14:43:02 UTC",
    "updated_date": "2025-02-02 21:46:50 UTC"
  },
  {
    "arxiv_id": "2405.13651v1",
    "title": "ConcertoRL: An Innovative Time-Interleaved Reinforcement Learning Approach for Enhanced Control in Direct-Drive Tandem-Wing Vehicles",
    "authors": [
      "Minghao Zhang",
      "Bifeng Song",
      "Changhao Chen",
      "Xinyu Lang"
    ],
    "abstract": "In control problems for insect-scale direct-drive experimental platforms\nunder tandem wing influence, the primary challenge facing existing\nreinforcement learning models is their limited safety in the exploration\nprocess and the stability of the continuous training process. We introduce the\nConcertoRL algorithm to enhance control precision and stabilize the online\ntraining process, which consists of two main innovations: a time-interleaved\nmechanism to interweave classical controllers with reinforcement learning-based\ncontrollers aiming to improve control precision in the initial stages, a policy\ncomposer organizes the experience gained from previous learning to ensure the\nstability of the online training process. This paper conducts a series of\nexperiments. First, experiments incorporating the time-interleaved mechanism\ndemonstrate a substantial performance boost of approximately 70% over scenarios\nwithout reinforcement learning enhancements and a 50% increase in efficiency\ncompared to reference controllers with doubled control frequencies. These\nresults highlight the algorithm's ability to create a synergistic effect that\nexceeds the sum of its parts.",
    "categories": [
      "cs.AI",
      "cs.RO",
      "68T40",
      "I.2.9"
    ],
    "primary_category": "cs.AI",
    "comment": "48 pages, 35 figures",
    "pdf_url": "http://arxiv.org/pdf/2405.13651v1",
    "published_date": "2024-05-22 13:53:10 UTC",
    "updated_date": "2024-05-22 13:53:10 UTC"
  },
  {
    "arxiv_id": "2405.13640v2",
    "title": "Knowledge Graph Reasoning with Self-supervised Reinforcement Learning",
    "authors": [
      "Ying Ma",
      "Owen Burns",
      "Mingqiu Wang",
      "Gang Li",
      "Nan Du",
      "Laurent El Shafey",
      "Liqiang Wang",
      "Izhak Shafran",
      "Hagen Soltau"
    ],
    "abstract": "Reinforcement learning (RL) is an effective method of finding reasoning\npathways in incomplete knowledge graphs (KGs). To overcome the challenges of a\nlarge action space, a self-supervised pre-training method is proposed to warm\nup the policy network before the RL training stage. To alleviate the\ndistributional mismatch issue in general self-supervised RL (SSRL), in our\nsupervised learning (SL) stage, the agent selects actions based on the policy\nnetwork and learns from generated labels; this self-generation of labels is the\nintuition behind the name self-supervised. With this training framework, the\ninformation density of our SL objective is increased and the agent is prevented\nfrom getting stuck with the early rewarded paths. Our self-supervised RL (SSRL)\nmethod improves the performance of RL by pairing it with the wide coverage\nachieved by SL during pretraining, since the breadth of the SL objective makes\nit infeasible to train an agent with that alone. We show that our SSRL model\nmeets or exceeds current state-of-the-art results on all Hits@k and mean\nreciprocal rank (MRR) metrics on four large benchmark KG datasets. This SSRL\nmethod can be used as a plug-in for any RL architecture for a KGR task. We\nadopt two RL architectures, i.e., MINERVA and MultiHopKG as our baseline RL\nmodels and experimentally show that our SSRL model consistently outperforms\nboth baselines on all of these four KG reasoning tasks. Full code for the paper\navailable at\nhttps://github.com/owenonline/Knowledge-Graph-Reasoning-with-Self-supervised-Reinforcement-Learning.",
    "categories": [
      "cs.CL",
      "cs.AI",
      "cs.LG"
    ],
    "primary_category": "cs.CL",
    "comment": "17 pages, 11 figures",
    "pdf_url": "http://arxiv.org/pdf/2405.13640v2",
    "published_date": "2024-05-22 13:39:33 UTC",
    "updated_date": "2025-04-15 21:48:58 UTC"
  },
  {
    "arxiv_id": "2405.13637v6",
    "title": "Curriculum Direct Preference Optimization for Diffusion and Consistency Models",
    "authors": [
      "Florinel-Alin Croitoru",
      "Vlad Hondru",
      "Radu Tudor Ionescu",
      "Nicu Sebe",
      "Mubarak Shah"
    ],
    "abstract": "Direct Preference Optimization (DPO) has been proposed as an effective and\nefficient alternative to reinforcement learning from human feedback (RLHF). In\nthis paper, we propose a novel and enhanced version of DPO based on curriculum\nlearning for text-to-image generation. Our method is divided into two training\nstages. First, a ranking of the examples generated for each prompt is obtained\nby employing a reward model. Then, increasingly difficult pairs of examples are\nsampled and provided to a text-to-image generative (diffusion or consistency)\nmodel. Generated samples that are far apart in the ranking are considered to\nform easy pairs, while those that are close in the ranking form hard pairs. In\nother words, we use the rank difference between samples as a measure of\ndifficulty. The sampled pairs are split into batches according to their\ndifficulty levels, which are gradually used to train the generative model. Our\napproach, Curriculum DPO, is compared against state-of-the-art fine-tuning\napproaches on nine benchmarks, outperforming the competing methods in terms of\ntext alignment, aesthetics and human preference. Our code is available at\nhttps://github.com/CroitoruAlin/Curriculum-DPO.",
    "categories": [
      "cs.CV",
      "cs.AI",
      "cs.LG"
    ],
    "primary_category": "cs.CV",
    "comment": "Accepted at CVPR 2025",
    "pdf_url": "http://arxiv.org/pdf/2405.13637v6",
    "published_date": "2024-05-22 13:36:48 UTC",
    "updated_date": "2025-05-09 08:38:29 UTC"
  },
  {
    "arxiv_id": "2405.13636v1",
    "title": "Audio Mamba: Pretrained Audio State Space Model For Audio Tagging",
    "authors": [
      "Jiaju Lin",
      "Haoxuan Hu"
    ],
    "abstract": "Audio tagging is an important task of mapping audio samples to their\ncorresponding categories. Recently endeavours that exploit transformer models\nin this field have achieved great success. However, the quadratic\nself-attention cost limits the scaling of audio transformer models and further\nconstrains the development of more universal audio models. In this paper, we\nattempt to solve this problem by proposing Audio Mamba, a self-attention-free\napproach that captures long audio spectrogram dependency with state space\nmodels. Our experimental results on two audio-tagging datasets demonstrate the\nparameter efficiency of Audio Mamba, it achieves comparable results to SOTA\naudio spectrogram transformers with one third parameters.",
    "categories": [
      "cs.SD",
      "cs.AI",
      "eess.AS"
    ],
    "primary_category": "cs.SD",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2405.13636v1",
    "published_date": "2024-05-22 13:35:56 UTC",
    "updated_date": "2024-05-22 13:35:56 UTC"
  },
  {
    "arxiv_id": "2405.13606v1",
    "title": "From the evolution of public data ecosystems to the evolving horizons of the forward-looking intelligent public data ecosystem empowered by emerging technologies",
    "authors": [
      "Anastasija Nikiforova",
      "Martin Lnenicka",
      "Petar Miliƒá",
      "Mariusz Luterek",
      "Manuel Pedro Rodr√≠guez Bol√≠var"
    ],
    "abstract": "Public data ecosystems (PDEs) represent complex socio-technical systems\ncrucial for optimizing data use in the public sector and outside it.\nRecognizing their multifaceted nature, previous research pro-posed a\nsix-generation Evolutionary Model of Public Data Ecosystems (EMPDE). Designed\nas a result of a systematic literature review on the topic spanning three\ndecade, this model, while theoretically robust, necessitates empirical\nvalidation to enhance its practical applicability. This study addresses this\ngap by validating the theoretical model through a real-life examination in five\nEuropean countries - Latvia, Serbia, Czech Republic, Spain, and Poland. This\nempirical validation provides insights into PDEs dynamics and variations of\nimplementations across contexts, particularly focusing on the 6th generation of\nforward-looking PDE generation named \"Intelligent Public Data Generation\" that\nrepresents a paradigm shift driven by emerging technologies such as cloud\ncomputing, Artificial Intelligence, Natural Language Processing tools,\nGenerative AI, and Large Language Models (LLM) with potential to contribute to\nboth automation and augmentation of business processes within these ecosystems.\nBy transcending their traditional status as a mere component, evolving into\nboth an actor and a stakeholder simultaneously, these technologies catalyze\ninnovation and progress, enhancing PDE management strategies to align with\nsocietal, regulatory, and technical imperatives in the digital era.",
    "categories": [
      "cs.CY",
      "cs.AI",
      "cs.ET",
      "cs.HC",
      "cs.IR"
    ],
    "primary_category": "cs.CY",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2405.13606v1",
    "published_date": "2024-05-22 12:58:02 UTC",
    "updated_date": "2024-05-22 12:58:02 UTC"
  },
  {
    "arxiv_id": "2405.13602v1",
    "title": "COTET: Cross-view Optimal Transport for Knowledge Graph Entity Typing",
    "authors": [
      "Zhiwei Hu",
      "V√≠ctor Guti√©rrez-Basulto",
      "Zhiliang Xiang",
      "Ru Li",
      "Jeff Z. Pan"
    ],
    "abstract": "Knowledge graph entity typing (KGET) aims to infer missing entity type\ninstances in knowledge graphs. Previous research has predominantly centered\naround leveraging contextual information associated with entities, which\nprovides valuable clues for inference. However, they have long ignored the dual\nnature of information inherent in entities, encompassing both high-level\ncoarse-grained cluster knowledge and fine-grained type knowledge. This paper\nintroduces Cross-view Optimal Transport for knowledge graph Entity Typing\n(COTET), a method that effectively incorporates the information on how types\nare clustered into the representation of entities and types. COTET comprises\nthree modules: i) Multi-view Generation and Encoder, which captures structured\nknowledge at different levels of granularity through entity-type,\nentity-cluster, and type-cluster-type perspectives; ii) Cross-view Optimal\nTransport, transporting view-specific embeddings to a unified space by\nminimizing the Wasserstein distance from a distributional alignment\nperspective; iii) Pooling-based Entity Typing Prediction, employing a mixture\npooling mechanism to aggregate prediction scores from diverse neighbors of an\nentity. Additionally, we introduce a distribution-based loss function to\nmitigate the occurrence of false negatives during training. Extensive\nexperiments demonstrate the effectiveness of COTET when compared to existing\nbaselines.",
    "categories": [
      "cs.AI",
      "cs.CL",
      "cs.LG"
    ],
    "primary_category": "cs.AI",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2405.13602v1",
    "published_date": "2024-05-22 12:53:12 UTC",
    "updated_date": "2024-05-22 12:53:12 UTC"
  },
  {
    "arxiv_id": "2405.13586v2",
    "title": "Bond Graphs for multi-physics informed Neural Networks for multi-variate time series",
    "authors": [
      "Alexis-Raja Brachet",
      "Pierre-Yves Richard",
      "C√©line Hudelot"
    ],
    "abstract": "In the trend of hybrid Artificial Intelligence techniques, Physical-Informed\nMachine Learning has seen a growing interest. It operates mainly by imposing\ndata, learning, or architecture bias with simulation data, Partial Differential\nEquations, or equivariance and invariance properties. While it has shown great\nsuccess on tasks involving one physical domain, such as fluid dynamics,\nexisting methods are not adapted to tasks with complex multi-physical and\nmulti-domain phenomena. In addition, it is mainly formulated as an end-to-end\nlearning scheme. To address these challenges, we propose to leverage Bond\nGraphs, a multi-physics modeling approach, together with Message Passing Graph\nNeural Networks. We propose a Neural Bond graph Encoder (NBgE) producing\nmulti-physics-informed representations that can be fed into any task-specific\nmodel. It provides a unified way to integrate both data and architecture biases\nin deep learning. Our experiments on two challenging multi-domain physical\nsystems - a Direct Current Motor and the Respiratory System - demonstrate the\neffectiveness of our approach on a multivariate time-series forecasting task.",
    "categories": [
      "cs.LG",
      "cs.AI"
    ],
    "primary_category": "cs.LG",
    "comment": "9 pages, 3 figures, paper under review",
    "pdf_url": "http://arxiv.org/pdf/2405.13586v2",
    "published_date": "2024-05-22 12:30:25 UTC",
    "updated_date": "2024-08-02 14:59:48 UTC"
  },
  {
    "arxiv_id": "2405.13581v1",
    "title": "Safety Alignment for Vision Language Models",
    "authors": [
      "Zhendong Liu",
      "Yuanbi Nie",
      "Yingshui Tan",
      "Xiangyu Yue",
      "Qiushi Cui",
      "Chongjun Wang",
      "Xiaoyong Zhu",
      "Bo Zheng"
    ],
    "abstract": "Benefiting from the powerful capabilities of Large Language Models (LLMs),\npre-trained visual encoder models connected to an LLMs can realize Vision\nLanguage Models (VLMs). However, existing research shows that the visual\nmodality of VLMs is vulnerable, with attackers easily bypassing LLMs' safety\nalignment through visual modality features to launch attacks. To address this\nissue, we enhance the existing VLMs' visual modality safety alignment by adding\nsafety modules, including a safety projector, safety tokens, and a safety head,\nthrough a two-stage training process, effectively improving the model's defense\nagainst risky images. For example, building upon the LLaVA-v1.5 model, we\nachieve a safety score of 8.26, surpassing the GPT-4V on the Red Teaming Visual\nLanguage Models (RTVLM) benchmark. Our method boasts ease of use, high\nflexibility, and strong controllability, and it enhances safety while having\nminimal impact on the model's general performance. Moreover, our alignment\nstrategy also uncovers some possible risky content within commonly used\nopen-source multimodal datasets. Our code will be open sourced after the\nanonymous review.",
    "categories": [
      "cs.CV",
      "cs.AI"
    ],
    "primary_category": "cs.CV",
    "comment": "23 pages, 15 figures",
    "pdf_url": "http://arxiv.org/pdf/2405.13581v1",
    "published_date": "2024-05-22 12:21:27 UTC",
    "updated_date": "2024-05-22 12:21:27 UTC"
  },
  {
    "arxiv_id": "2405.13575v3",
    "title": "Unlocking the Power of Patch: Patch-Based MLP for Long-Term Time Series Forecasting",
    "authors": [
      "Peiwang Tang",
      "Weitai Zhang"
    ],
    "abstract": "Recent studies have attempted to refine the Transformer architecture to\ndemonstrate its effectiveness in Long-Term Time Series Forecasting (LTSF)\ntasks. Despite surpassing many linear forecasting models with ever-improving\nperformance, we remain skeptical of Transformers as a solution for LTSF. We\nattribute the effectiveness of these models largely to the adopted Patch\nmechanism, which enhances sequence locality to an extent yet fails to fully\naddress the loss of temporal information inherent to the permutation-invariant\nself-attention mechanism. Further investigation suggests that simple linear\nlayers augmented with the Patch mechanism may outperform complex\nTransformer-based LTSF models. Moreover, diverging from models that use channel\nindependence, our research underscores the importance of cross-variable\ninteractions in enhancing the performance of multivariate time series\nforecasting. The interaction information between variables is highly valuable\nbut has been misapplied in past studies, leading to suboptimal cross-variable\nmodels. Based on these insights, we propose a novel and simple Patch-based MLP\n(PatchMLP) for LTSF tasks. Specifically, we employ simple moving averages to\nextract smooth components and noise-containing residuals from time series data,\nengaging in semantic information interchange through channel mixing and\nspecializing in random noise with channel independence processing. The PatchMLP\nmodel consistently achieves state-of-the-art results on several real-world\ndatasets. We hope this surprising finding will spur new research directions in\nthe LTSF field and pave the way for more efficient and concise solutions.",
    "categories": [
      "cs.LG",
      "cs.AI"
    ],
    "primary_category": "cs.LG",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2405.13575v3",
    "published_date": "2024-05-22 12:12:20 UTC",
    "updated_date": "2024-12-25 08:07:56 UTC"
  },
  {
    "arxiv_id": "2405.13568v1",
    "title": "CPE-Identifier: Automated CPE identification and CVE summaries annotation with Deep Learning and NLP",
    "authors": [
      "Wanyu Hu",
      "Vrizlynn L. L. Thing"
    ],
    "abstract": "With the drastic increase in the number of new vulnerabilities in the\nNational Vulnerability Database (NVD) every year, the workload for NVD analysts\nto associate the Common Platform Enumeration (CPE) with the Common\nVulnerabilities and Exposures (CVE) summaries becomes increasingly laborious\nand slow. The delay causes organisations, which depend on NVD for vulnerability\nmanagement and security measurement, to be more vulnerable to zero-day attacks.\nThus, it is essential to come out with a technique and tool to extract the CPEs\nin the CVE summaries accurately and quickly. In this work, we propose the\nCPE-Identifier system, an automated CPE annotating and extracting system, from\nthe CVE summaries. The system can be used as a tool to identify CPE entities\nfrom new CVE text inputs. Moreover, we also automate the data generating and\nlabeling processes using deep learning models. Due to the complexity of the CVE\ntexts, new technical terminologies appear frequently. To identify novel words\nin future CVE texts, we apply Natural Language Processing (NLP) Named Entity\nRecognition (NER), to identify new technical jargons in the text. Our proposed\nmodel achieves an F1 score of 95.48%, an accuracy score of 99.13%, a precision\nof 94.83%, and a recall of 96.14%. We show that it outperforms prior works on\nautomated CVE-CPE labeling by more than 9% on all metrics.",
    "categories": [
      "cs.CR",
      "cs.AI",
      "cs.CL",
      "cs.LG"
    ],
    "primary_category": "cs.CR",
    "comment": "International Conference on Information Systems Security and Privacy\n  2024",
    "pdf_url": "http://arxiv.org/pdf/2405.13568v1",
    "published_date": "2024-05-22 12:05:17 UTC",
    "updated_date": "2024-05-22 12:05:17 UTC"
  },
  {
    "arxiv_id": "2405.13565v1",
    "title": "AI-Assisted Assessment of Coding Practices in Modern Code Review",
    "authors": [
      "Manushree Vijayvergiya",
      "Ma≈Çgorzata Salawa",
      "Ivan Budiseliƒá",
      "Dan Zheng",
      "Pascal Lamblin",
      "Marko Ivankoviƒá",
      "Juanjo Carin",
      "Mateusz Lewko",
      "Jovan Andonov",
      "Goran Petroviƒá",
      "Daniel Tarlow",
      "Petros Maniatis",
      "Ren√© Just"
    ],
    "abstract": "Modern code review is a process in which an incremental code contribution\nmade by a code author is reviewed by one or more peers before it is committed\nto the version control system. An important element of modern code review is\nverifying that code contributions adhere to best practices. While some of these\nbest practices can be automatically verified, verifying others is commonly left\nto human reviewers. This paper reports on the development, deployment, and\nevaluation of AutoCommenter, a system backed by a large language model that\nautomatically learns and enforces coding best practices. We implemented\nAutoCommenter for four programming languages (C++, Java, Python, and Go) and\nevaluated its performance and adoption in a large industrial setting. Our\nevaluation shows that an end-to-end system for learning and enforcing coding\nbest practices is feasible and has a positive impact on the developer workflow.\nAdditionally, this paper reports on the challenges associated with deploying\nsuch a system to tens of thousands of developers and the corresponding lessons\nlearned.",
    "categories": [
      "cs.SE",
      "cs.AI"
    ],
    "primary_category": "cs.SE",
    "comment": "To appear at the ACM International Conference on AI-Powered Software\n  (AIware '24)",
    "pdf_url": "http://arxiv.org/pdf/2405.13565v1",
    "published_date": "2024-05-22 11:57:18 UTC",
    "updated_date": "2024-05-22 11:57:18 UTC"
  },
  {
    "arxiv_id": "2405.13560v1",
    "title": "Navigating User Experience of ChatGPT-based Conversational Recommender Systems: The Effects of Prompt Guidance and Recommendation Domain",
    "authors": [
      "Yizhe Zhang",
      "Yucheng Jin",
      "Li Chen",
      "Ting Yang"
    ],
    "abstract": "Conversational recommender systems (CRS) enable users to articulate their\npreferences and provide feedback through natural language. With the advent of\nlarge language models (LLMs), the potential to enhance user engagement with CRS\nand augment the recommendation process with LLM-generated content has received\nincreasing attention. However, the efficacy of LLM-powered CRS is contingent\nupon the use of prompts, and the subjective perception of recommendation\nquality can differ across various recommendation domains. Therefore, we have\ndeveloped a ChatGPT-based CRS to investigate the impact of these two factors,\nprompt guidance (PG) and recommendation domain (RD), on the overall user\nexperience of the system. We conducted an online empirical study (N = 100) by\nemploying a mixed-method approach that utilized a between-subjects design for\nthe variable of PG (with vs. without) and a within-subjects design for RD (book\nrecommendations vs. job recommendations). The findings reveal that PG can\nsubstantially enhance the system's explainability, adaptability, perceived ease\nof use, and transparency. Moreover, users are inclined to perceive a greater\nsense of novelty and demonstrate a higher propensity to engage with and try\nrecommended items in the context of book recommendations as opposed to job\nrecommendations. Furthermore, the influence of PG on certain user experience\nmetrics and interactive behaviors appears to be modulated by the recommendation\ndomain, as evidenced by the interaction effects between the two examined\nfactors. This work contributes to the user-centered evaluation of ChatGPT-based\nCRS by investigating two prominent factors and offers practical design\nguidance.",
    "categories": [
      "cs.HC",
      "cs.AI"
    ],
    "primary_category": "cs.HC",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2405.13560v1",
    "published_date": "2024-05-22 11:49:40 UTC",
    "updated_date": "2024-05-22 11:49:40 UTC"
  },
  {
    "arxiv_id": "2405.13557v2",
    "title": "MotionCraft: Physics-based Zero-Shot Video Generation",
    "authors": [
      "Luca Savant Aira",
      "Antonio Montanaro",
      "Emanuele Aiello",
      "Diego Valsesia",
      "Enrico Magli"
    ],
    "abstract": "Generating videos with realistic and physically plausible motion is one of\nthe main recent challenges in computer vision. While diffusion models are\nachieving compelling results in image generation, video diffusion models are\nlimited by heavy training and huge models, resulting in videos that are still\nbiased to the training dataset. In this work we propose MotionCraft, a new\nzero-shot video generator to craft physics-based and realistic videos.\nMotionCraft is able to warp the noise latent space of an image diffusion model,\nsuch as Stable Diffusion, by applying an optical flow derived from a physics\nsimulation. We show that warping the noise latent space results in coherent\napplication of the desired motion while allowing the model to generate missing\nelements consistent with the scene evolution, which would otherwise result in\nartefacts or missing content if the flow was applied in the pixel space. We\ncompare our method with the state-of-the-art Text2Video-Zero reporting\nqualitative and quantitative improvements, demonstrating the effectiveness of\nour approach to generate videos with finely-prescribed complex motion dynamics.\nProject page: https://mezzelfo.github.io/MotionCraft/",
    "categories": [
      "cs.LG",
      "cs.AI",
      "cs.CV"
    ],
    "primary_category": "cs.LG",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2405.13557v2",
    "published_date": "2024-05-22 11:44:57 UTC",
    "updated_date": "2024-10-25 10:01:22 UTC"
  },
  {
    "arxiv_id": "2405.13554v3",
    "title": "The Influencer Next Door: How Misinformation Creators Use GenAI",
    "authors": [
      "Amelia Hassoun",
      "Ariel Abonizio",
      "Katy Osborn",
      "Cameron Wu",
      "Beth Goldberg"
    ],
    "abstract": "Advances in generative AI (GenAI) have raised concerns about detecting and\ndiscerning AI-generated content from human-generated content. Most existing\nliterature assumes a paradigm where 'expert' organized disinformation creators\nand flawed AI models deceive 'ordinary' users. Based on longitudinal\nethnographic research with misinformation creators and consumers between\n2022-2023, we instead find that GenAI supports bricolage work, where\nnon-experts increasingly use GenAI to remix, repackage, and (re)produce content\nto meet their personal needs and desires. This research yielded four key\nfindings: First, participants primarily used GenAI for creation, rather than\ntruth-seeking. Second, a spreading 'influencer millionaire' narrative drove\nparticipants to become content creators, using GenAI as a productivity tool to\ngenerate a volume of (often misinformative) content. Third, GenAI lowered the\nbarrier to entry for content creation across modalities, enticing consumers to\nbecome creators and significantly increasing existing creators' output.\nFinally, participants used Gen AI to learn and deploy marketing tactics to\nexpand engagement and monetize their content. We argue for shifting analysis\nfrom the public as consumers of AI content to bricoleurs who use GenAI\ncreatively, often without a detailed understanding of its underlying\ntechnology. We analyze how these understudied emergent uses of GenAI produce\nnew or accelerated misinformation harms, and their implications for AI\nproducts, platforms and policies.",
    "categories": [
      "cs.HC",
      "cs.AI"
    ],
    "primary_category": "cs.HC",
    "comment": "44 pages, 25 figures",
    "pdf_url": "http://arxiv.org/pdf/2405.13554v3",
    "published_date": "2024-05-22 11:40:22 UTC",
    "updated_date": "2024-06-18 09:29:48 UTC"
  },
  {
    "arxiv_id": "2405.13551v1",
    "title": "Large Language Models are Effective Priors for Causal Graph Discovery",
    "authors": [
      "Victor-Alexandru Darvariu",
      "Stephen Hailes",
      "Mirco Musolesi"
    ],
    "abstract": "Causal structure discovery from observations can be improved by integrating\nbackground knowledge provided by an expert to reduce the hypothesis space.\nRecently, Large Language Models (LLMs) have begun to be considered as sources\nof prior information given the low cost of querying them relative to a human\nexpert. In this work, firstly, we propose a set of metrics for assessing LLM\njudgments for causal graph discovery independently of the downstream algorithm.\nSecondly, we systematically study a set of prompting designs that allows the\nmodel to specify priors about the structure of the causal graph. Finally, we\npresent a general methodology for the integration of LLM priors in graph\ndiscovery algorithms, finding that they help improve performance on\ncommon-sense benchmarks and especially when used for assessing edge\ndirectionality. Our work highlights the potential as well as the shortcomings\nof the use of LLMs in this problem space.",
    "categories": [
      "cs.LG",
      "cs.AI"
    ],
    "primary_category": "cs.LG",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2405.13551v1",
    "published_date": "2024-05-22 11:39:11 UTC",
    "updated_date": "2024-05-22 11:39:11 UTC"
  },
  {
    "arxiv_id": "2405.13547v1",
    "title": "HighwayLLM: Decision-Making and Navigation in Highway Driving with RL-Informed Language Model",
    "authors": [
      "Mustafa Yildirim",
      "Barkin Dagda",
      "Saber Fallah"
    ],
    "abstract": "Autonomous driving is a complex task which requires advanced decision making\nand control algorithms. Understanding the rationale behind the autonomous\nvehicles' decision is crucial to ensure their safe and effective operation on\nhighway driving. This study presents a novel approach, HighwayLLM, which\nharnesses the reasoning capabilities of large language models (LLMs) to predict\nthe future waypoints for ego-vehicle's navigation. Our approach also utilizes a\npre-trained Reinforcement Learning (RL) model to serve as a high-level planner,\nmaking decisions on appropriate meta-level actions. The HighwayLLM combines the\noutput from the RL model and the current state information to make safe,\ncollision-free, and explainable predictions for the next states, thereby\nconstructing a trajectory for the ego-vehicle. Subsequently, a PID-based\ncontroller guides the vehicle to the waypoints predicted by the LLM agent. This\nintegration of LLM with RL and PID enhances the decision-making process and\nprovides interpretability for highway autonomous driving.",
    "categories": [
      "cs.RO",
      "cs.AI"
    ],
    "primary_category": "cs.RO",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2405.13547v1",
    "published_date": "2024-05-22 11:32:37 UTC",
    "updated_date": "2024-05-22 11:32:37 UTC"
  },
  {
    "arxiv_id": "2405.13541v1",
    "title": "Annotation-Efficient Preference Optimization for Language Model Alignment",
    "authors": [
      "Yuu Jinnai",
      "Ukyo Honda"
    ],
    "abstract": "Preference optimization is a standard approach to fine-tuning large language\nmodels to align with human preferences. The quality, diversity, and quantity of\nthe preference dataset are critical to the effectiveness of preference\noptimization. However, obtaining a large amount of high-quality and diverse\npreference annotations is difficult in many applications. This raises the\nquestion of how to use the limited annotation budget to create an effective\npreference dataset. To this end, we propose Annotation-Efficient Preference\nOptimization (AEPO). Instead of exhaustively annotating preference over all\navailable response texts, AEPO selects a subset of responses that maximizes\nquality and diversity from the available responses, and then annotates\npreference over the selected ones. In this way, AEPO focuses the annotation\nbudget on labeling preference over a smaller subset of responses with diversity\nand of high quality. We evaluate the performance of Direct Preference\nOptimization (DPO) using AEPO and show that it outperforms models trained using\na standard DPO with the same annotation budget. Our code is available at\nhttps://github.com/CyberAgentAILab/annotation-efficient-po",
    "categories": [
      "cs.CL",
      "cs.AI",
      "cs.LG"
    ],
    "primary_category": "cs.CL",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2405.13541v1",
    "published_date": "2024-05-22 11:23:03 UTC",
    "updated_date": "2024-05-22 11:23:03 UTC"
  },
  {
    "arxiv_id": "2405.13536v2",
    "title": "Attention Mechanisms Don't Learn Additive Models: Rethinking Feature Importance for Transformers",
    "authors": [
      "Tobias Leemann",
      "Alina Fastowski",
      "Felix Pfeiffer",
      "Gjergji Kasneci"
    ],
    "abstract": "We address the critical challenge of applying feature attribution methods to\nthe transformer architecture, which dominates current applications in natural\nlanguage processing and beyond. Traditional attribution methods to explainable\nAI (XAI) explicitly or implicitly rely on linear or additive surrogate models\nto quantify the impact of input features on a model's output. In this work, we\nformally prove an alarming incompatibility: transformers are structurally\nincapable of representing linear or additive surrogate models used for feature\nattribution, undermining the grounding of these conventional explanation\nmethodologies. To address this discrepancy, we introduce the Softmax-Linked\nAdditive Log Odds Model (SLALOM), a novel surrogate model specifically designed\nto align with the transformer framework. SLALOM demonstrates the capacity to\ndeliver a range of insightful explanations with both synthetic and real-world\ndatasets. We highlight SLALOM's unique efficiency-quality curve by showing that\nSLALOM can produce explanations with substantially higher fidelity than\ncompeting surrogate models or provide explanations of comparable quality at a\nfraction of their computational costs. We release code for SLALOM as an\nopen-source project online at https://github.com/tleemann/slalom_explanations.",
    "categories": [
      "cs.LG",
      "cs.AI",
      "cs.CL"
    ],
    "primary_category": "cs.LG",
    "comment": "TMLR Camera-Ready version",
    "pdf_url": "http://arxiv.org/pdf/2405.13536v2",
    "published_date": "2024-05-22 11:14:00 UTC",
    "updated_date": "2025-01-09 17:58:44 UTC"
  },
  {
    "arxiv_id": "2405.13527v1",
    "title": "End-to-End Real-World Polyphonic Piano Audio-to-Score Transcription with Hierarchical Decoding",
    "authors": [
      "Wei Zeng",
      "Xian He",
      "Ye Wang"
    ],
    "abstract": "Piano audio-to-score transcription (A2S) is an important yet underexplored\ntask with extensive applications for music composition, practice, and analysis.\nHowever, existing end-to-end piano A2S systems faced difficulties in retrieving\nbar-level information such as key and time signatures, and have been trained\nand evaluated with only synthetic data. To address these limitations, we\npropose a sequence-to-sequence (Seq2Seq) model with a hierarchical decoder that\naligns with the hierarchical structure of musical scores, enabling the\ntranscription of score information at both the bar and note levels by\nmulti-task learning. To bridge the gap between synthetic data and recordings of\nhuman performance, we propose a two-stage training scheme, which involves\npre-training the model using an expressive performance rendering (EPR) system\non synthetic audio, followed by fine-tuning the model using recordings of human\nperformance. To preserve the voicing structure for score reconstruction, we\npropose a pre-processing method for **Kern scores in scenarios with an\nunconstrained number of voices. Experimental results support the effectiveness\nof our proposed approaches, in terms of both transcription performance on\nsynthetic audio data in comparison to the current state-of-the-art, and the\nfirst experiment on human recordings.",
    "categories": [
      "cs.SD",
      "cs.AI",
      "eess.AS"
    ],
    "primary_category": "cs.SD",
    "comment": "8 pages, 5 figures, accepted by IJCAI 2024 - AI, Arts & Creativity\n  Track",
    "pdf_url": "http://arxiv.org/pdf/2405.13527v1",
    "published_date": "2024-05-22 10:52:04 UTC",
    "updated_date": "2024-05-22 10:52:04 UTC"
  },
  {
    "arxiv_id": "2405.13522v2",
    "title": "Beyond Trend and Periodicity: Guiding Time Series Forecasting with Textual Cues",
    "authors": [
      "Zhijian Xu",
      "Yuxuan Bian",
      "Jianyuan Zhong",
      "Xiangyu Wen",
      "Qiang Xu"
    ],
    "abstract": "This work introduces a novel Text-Guided Time Series Forecasting (TGTSF)\ntask. By integrating textual cues, such as channel descriptions and dynamic\nnews, TGTSF addresses the critical limitations of traditional methods that rely\npurely on historical data. To support this task, we propose TGForecaster, a\nrobust baseline model that fuses textual cues and time series data using\ncross-attention mechanisms. We then present four meticulously curated benchmark\ndatasets to validate the proposed framework, ranging from simple periodic data\nto complex, event-driven fluctuations. Our comprehensive evaluations\ndemonstrate that TGForecaster consistently achieves state-of-the-art\nperformance, highlighting the transformative potential of incorporating textual\ninformation into time series forecasting. This work not only pioneers a novel\nforecasting task but also establishes a new benchmark for future research,\ndriving advancements in multimodal data integration for time series models.",
    "categories": [
      "cs.LG",
      "cs.AI",
      "cs.CL"
    ],
    "primary_category": "cs.LG",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2405.13522v2",
    "published_date": "2024-05-22 10:45:50 UTC",
    "updated_date": "2024-05-24 15:10:27 UTC"
  },
  {
    "arxiv_id": "2405.13515v1",
    "title": "Multi-Scale Feature Fusion Quantum Depthwise Convolutional Neural Networks for Text Classification",
    "authors": [
      "Yixiong Chen",
      "Weichuan Fang"
    ],
    "abstract": "In recent years, with the development of quantum machine learning, quantum\nneural networks (QNNs) have gained increasing attention in the field of natural\nlanguage processing (NLP) and have achieved a series of promising results.\nHowever, most existing QNN models focus on the architectures of quantum\nrecurrent neural network (QRNN) and self-attention mechanism (QSAM). In this\nwork, we propose a novel QNN model based on quantum convolution. We develop the\nquantum depthwise convolution that significantly reduces the number of\nparameters and lowers computational complexity. We also introduce the\nmulti-scale feature fusion mechanism to enhance model performance by\nintegrating word-level and sentence-level features. Additionally, we propose\nthe quantum word embedding and quantum sentence embedding, which provide\nembedding vectors more efficiently. Through experiments on two benchmark text\nclassification datasets, we demonstrate our model outperforms a wide range of\nstate-of-the-art QNN models. Notably, our model achieves a new state-of-the-art\ntest accuracy of 96.77% on the RP dataset. We also show the advantages of our\nquantum model over its classical counterparts in its ability to improve test\naccuracy using fewer parameters. Finally, an ablation test confirms the\neffectiveness of the multi-scale feature fusion mechanism and quantum depthwise\nconvolution in enhancing model performance.",
    "categories": [
      "quant-ph",
      "cs.AI",
      "cs.LG"
    ],
    "primary_category": "quant-ph",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2405.13515v1",
    "published_date": "2024-05-22 10:19:34 UTC",
    "updated_date": "2024-05-22 10:19:34 UTC"
  },
  {
    "arxiv_id": "2405.13488v1",
    "title": "Non-Deterministic Planning for Hyperproperty Verification",
    "authors": [
      "Raven Beutner",
      "Bernd Finkbeiner"
    ],
    "abstract": "Non-deterministic planning aims to find a policy that achieves a given\nobjective in an environment where actions have uncertain effects, and the agent\n- potentially - only observes parts of the current state. Hyperproperties are\nproperties that relate multiple paths of a system and can, e.g., capture\nsecurity and information-flow policies. Popular logics for expressing temporal\nhyperproperties - such as HyperLTL - extend LTL by offering selective\nquantification over executions of a system. In this paper, we show that\nplanning offers a powerful intermediate language for the automated verification\nof hyperproperties. Concretely, we present an algorithm that, given a HyperLTL\nverification problem, constructs a non-deterministic multi-agent planning\ninstance (in the form of a QDec-POMDP) that, when admitting a plan, implies the\nsatisfaction of the verification problem. We show that for large fragments of\nHyperLTL, the resulting planning instance corresponds to a classical, FOND, or\nPOND planning problem. We implement our encoding in a prototype verification\ntool and report on encouraging experimental results.",
    "categories": [
      "cs.LO",
      "cs.AI",
      "cs.FL"
    ],
    "primary_category": "cs.LO",
    "comment": "ICAPS 2024",
    "pdf_url": "http://arxiv.org/pdf/2405.13488v1",
    "published_date": "2024-05-22 09:57:49 UTC",
    "updated_date": "2024-05-22 09:57:49 UTC"
  },
  {
    "arxiv_id": "2405.13487v2",
    "title": "Qualitative and quantitative analysis of student's perceptions in the use of generative AI in educational environments",
    "authors": [
      "Sergio Altares-L√≥pez",
      "Jos√© M. Bengochea-Guevara",
      "Carlos Ranz",
      "H√©ctor Montes",
      "Angela Ribeiro"
    ],
    "abstract": "The effective integration of generative artificial intelligence in education\nis a fundamental aspect to prepare future generations. The objective of this\nstudy is to analyze from a quantitative and qualitative point of view the\nperception of controlled student-IA interaction within the classroom. This\nanalysis includes assessing the ethical implications and everyday use of AI\ntools, as well as understanding whether AI tools encourage students to pursue\nSTEM careers. Several points for improvement in education are found, such as\nthe challenge of getting teachers to engage with new technologies and adapt\ntheir methods in all subjects, not just those related to technologies.",
    "categories": [
      "cs.CY",
      "cs.AI",
      "cs.HC"
    ],
    "primary_category": "cs.CY",
    "comment": "17 pages, 7 figures, 4 tables",
    "pdf_url": "http://arxiv.org/pdf/2405.13487v2",
    "published_date": "2024-05-22 09:56:05 UTC",
    "updated_date": "2024-09-02 11:43:18 UTC"
  },
  {
    "arxiv_id": "2405.13474v1",
    "title": "Why do explanations fail? A typology and discussion on failures in XAI",
    "authors": [
      "Clara Bove",
      "Thibault Laugel",
      "Marie-Jeanne Lesot",
      "Charles Tijus",
      "Marcin Detyniecki"
    ],
    "abstract": "As Machine Learning (ML) models achieve unprecedented levels of performance,\nthe XAI domain aims at making these models understandable by presenting\nend-users with intelligible explanations. Yet, some existing XAI approaches\nfail to meet expectations: several issues have been reported in the literature,\ngenerally pointing out either technical limitations or misinterpretations by\nusers. In this paper, we argue that the resulting harms arise from a complex\noverlap of multiple failures in XAI, which existing ad-hoc studies fail to\ncapture. This work therefore advocates for a holistic perspective, presenting a\nsystematic investigation of limitations of current XAI methods and their impact\non the interpretation of explanations. By distinguishing between\nsystem-specific and user-specific failures, we propose a typological framework\nthat helps revealing the nuanced complexities of explanation failures.\nLeveraging this typology, we also discuss some research directions to help AI\npractitioners better understand the limitations of XAI systems and enhance the\nquality of ML explanations.",
    "categories": [
      "cs.LG",
      "cs.AI",
      "cs.HC"
    ],
    "primary_category": "cs.LG",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2405.13474v1",
    "published_date": "2024-05-22 09:32:24 UTC",
    "updated_date": "2024-05-22 09:32:24 UTC"
  },
  {
    "arxiv_id": "2405.13473v2",
    "title": "Class-Conditional self-reward mechanism for improved Text-to-Image models",
    "authors": [
      "Safouane El Ghazouali",
      "Arnaud Gucciardi",
      "Umberto Michelucci"
    ],
    "abstract": "Self-rewarding have emerged recently as a powerful tool in the field of\nNatural Language Processing (NLP), allowing language models to generate\nhigh-quality relevant responses by providing their own rewards during training.\nThis innovative technique addresses the limitations of other methods that rely\non human preferences. In this paper, we build upon the concept of\nself-rewarding models and introduce its vision equivalent for Text-to-Image\ngenerative AI models. This approach works by fine-tuning diffusion model on a\nself-generated self-judged dataset, making the fine-tuning more automated and\nwith better data quality. The proposed mechanism makes use of other pre-trained\nmodels such as vocabulary based-object detection, image captioning and is\nconditioned by the a set of object for which the user might need to improve\ngenerated data quality. The approach has been implemented, fine-tuned and\nevaluated on stable diffusion and has led to a performance that has been\nevaluated to be at least 60\\% better than existing commercial and research\nText-to-image models. Additionally, the built self-rewarding mechanism allowed\na fully automated generation of images, while increasing the visual quality of\nthe generated images and also more efficient following of prompt instructions.\nThe code used in this work is freely available on\nhttps://github.com/safouaneelg/SRT2I.",
    "categories": [
      "cs.CV",
      "cs.AI"
    ],
    "primary_category": "cs.CV",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2405.13473v2",
    "published_date": "2024-05-22 09:28:43 UTC",
    "updated_date": "2024-05-25 07:05:51 UTC"
  },
  {
    "arxiv_id": "2405.13462v1",
    "title": "Blockchain and Artificial Intelligence: Synergies and Conflicts",
    "authors": [
      "Leon Witt",
      "Armando Teles Fortes",
      "Kentaroh Toyoda",
      "Wojciech Samek",
      "Dan Li"
    ],
    "abstract": "Blockchain technology and Artificial Intelligence (AI) have emerged as\ntransformative forces in their respective domains. This paper explores\nsynergies and challenges between these two technologies. Our research analyses\nthe biggest projects combining blockchain and AI, based on market\ncapitalization, and derives a novel framework to categorize contemporary and\nfuture use cases. Despite the theoretical compatibility, current real-world\napplications combining blockchain and AI remain in their infancy.",
    "categories": [
      "cs.AI",
      "cs.CY",
      "cs.DC"
    ],
    "primary_category": "cs.AI",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2405.13462v1",
    "published_date": "2024-05-22 09:04:52 UTC",
    "updated_date": "2024-05-22 09:04:52 UTC"
  },
  {
    "arxiv_id": "2405.13461v1",
    "title": "Analogical proportions II",
    "authors": [
      "Christian Antiƒá"
    ],
    "abstract": "Analogical reasoning is the ability to detect parallels between two seemingly\ndistant objects or situations, a fundamental human capacity used for example in\ncommonsense reasoning, learning, and creativity which is believed by many\nresearchers to be at the core of human and artificial general intelligence.\nAnalogical proportions are expressions of the form ``$a$ is to $b$ what $c$ is\nto $d$'' at the core of analogical reasoning. The author has recently\nintroduced an abstract algebraic framework of analogical proportions within the\ngeneral setting of universal algebra. It is the purpose of this paper to\nfurther develop the mathematical theory of analogical proportions within that\nframework as motivated by the fact that it has already been successfully\napplied to logic program synthesis in artificial intelligence.",
    "categories": [
      "cs.LO",
      "cs.AI",
      "cs.DM",
      "math.LO"
    ],
    "primary_category": "cs.LO",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2405.13461v1",
    "published_date": "2024-05-22 09:02:12 UTC",
    "updated_date": "2024-05-22 09:02:12 UTC"
  },
  {
    "arxiv_id": "2405.13449v1",
    "title": "Input Guided Multiple Deconstruction Single Reconstruction neural network models for Matrix Factorization",
    "authors": [
      "Prasun Dutta",
      "Rajat K. De"
    ],
    "abstract": "Referring back to the original text in the course of hierarchical learning is\na common human trait that ensures the right direction of learning. The models\ndeveloped based on the concept of Non-negative Matrix Factorization (NMF), in\nthis paper are inspired by this idea. They aim to deal with high-dimensional\ndata by discovering its low rank approximation by determining a unique pair of\nfactor matrices. The model, named Input Guided Multiple Deconstruction Single\nReconstruction neural network for Non-negative Matrix Factorization\n(IG-MDSR-NMF), ensures the non-negativity constraints of both factors. Whereas\nInput Guided Multiple Deconstruction Single Reconstruction neural network for\nRelaxed Non-negative Matrix Factorization (IG-MDSR-RNMF) introduces a novel\nidea of factorization with only the basis matrix adhering to the non-negativity\ncriteria. This relaxed version helps the model to learn more enriched low\ndimensional embedding of the original data matrix. The competency of preserving\nthe local structure of data in its low rank embedding produced by both the\nmodels has been appropriately verified. The superiority of low dimensional\nembedding over that of the original data justifying the need for dimension\nreduction has been established. The primacy of both the models has also been\nvalidated by comparing their performances separately with that of nine other\nestablished dimension reduction algorithms on five popular datasets. Moreover,\ncomputational complexity of the models and convergence analysis have also been\npresented testifying to the supremacy of the models.",
    "categories": [
      "cs.LG",
      "cs.AI"
    ],
    "primary_category": "cs.LG",
    "comment": "50 pages, 25 figures",
    "pdf_url": "http://arxiv.org/pdf/2405.13449v1",
    "published_date": "2024-05-22 08:41:32 UTC",
    "updated_date": "2024-05-22 08:41:32 UTC"
  },
  {
    "arxiv_id": "2405.13445v1",
    "title": "Task-agnostic Decision Transformer for Multi-type Agent Control with Federated Split Training",
    "authors": [
      "Zhiyuan Wang",
      "Bokui Chen",
      "Xiaoyang Qu",
      "Zhenhou Hong",
      "Jing Xiao",
      "Jianzong Wang"
    ],
    "abstract": "With the rapid advancements in artificial intelligence, the development of\nknowledgeable and personalized agents has become increasingly prevalent.\nHowever, the inherent variability in state variables and action spaces among\npersonalized agents poses significant aggregation challenges for traditional\nfederated learning algorithms. To tackle these challenges, we introduce the\nFederated Split Decision Transformer (FSDT), an innovative framework designed\nexplicitly for AI agent decision tasks. The FSDT framework excels at navigating\nthe intricacies of personalized agents by harnessing distributed data for\ntraining while preserving data privacy. It employs a two-stage training\nprocess, with local embedding and prediction models on client agents and a\nglobal transformer decoder model on the server. Our comprehensive evaluation\nusing the benchmark D4RL dataset highlights the superior performance of our\nalgorithm in federated split learning for personalized agents, coupled with\nsignificant reductions in communication and computational overhead compared to\ntraditional centralized training approaches. The FSDT framework demonstrates\nstrong potential for enabling efficient and privacy-preserving collaborative\nlearning in applications such as autonomous driving decision systems. Our\nfindings underscore the efficacy of the FSDT framework in effectively\nleveraging distributed offline reinforcement learning data to enable powerful\nmulti-type agent decision systems.",
    "categories": [
      "cs.LG",
      "cs.AI"
    ],
    "primary_category": "cs.LG",
    "comment": "Accepted by the 2024 International Joint Conference on Neural\n  Networks (IJCNN 2024)",
    "pdf_url": "http://arxiv.org/pdf/2405.13445v1",
    "published_date": "2024-05-22 08:37:37 UTC",
    "updated_date": "2024-05-22 08:37:37 UTC"
  },
  {
    "arxiv_id": "2405.13432v1",
    "title": "Disperse-Then-Merge: Pushing the Limits of Instruction Tuning via Alignment Tax Reduction",
    "authors": [
      "Tingchen Fu",
      "Deng Cai",
      "Lemao Liu",
      "Shuming Shi",
      "Rui Yan"
    ],
    "abstract": "Supervised fine-tuning (SFT) on instruction-following corpus is a crucial\napproach toward the alignment of large language models (LLMs). However, the\nperformance of LLMs on standard knowledge and reasoning benchmarks tends to\nsuffer from deterioration at the latter stage of the SFT process, echoing the\nphenomenon of alignment tax. Through our pilot study, we put a hypothesis that\nthe data biases are probably one cause behind the phenomenon. To address the\nissue, we introduce a simple disperse-then-merge framework. To be concrete, we\ndisperse the instruction-following data into portions and train multiple\nsub-models using different data portions. Then we merge multiple models into a\nsingle one via model merging techniques. Despite its simplicity, our framework\noutperforms various sophisticated methods such as data curation and training\nregularization on a series of standard knowledge and reasoning benchmarks.",
    "categories": [
      "cs.CL",
      "cs.AI"
    ],
    "primary_category": "cs.CL",
    "comment": "Accepted to the findings of ACL2024",
    "pdf_url": "http://arxiv.org/pdf/2405.13432v1",
    "published_date": "2024-05-22 08:18:19 UTC",
    "updated_date": "2024-05-22 08:18:19 UTC"
  },
  {
    "arxiv_id": "2405.13426v1",
    "title": "A New Era in Human Factors Engineering: A Survey of the Applications and Prospects of Large Multimodal Models",
    "authors": [
      "Li Fan",
      "Lee Ching-Hung",
      "Han Su",
      "Feng Shanshan",
      "Jiang Zhuoxuan",
      "Sun Zhu"
    ],
    "abstract": "In recent years, the potential applications of Large Multimodal Models (LMMs)\nin fields such as healthcare, social psychology, and industrial design have\nattracted wide research attention, providing new directions for human factors\nresearch. For instance, LMM-based smart systems have become novel research\nsubjects of human factors studies, and LMM introduces new research paradigms\nand methodologies to this field. Therefore, this paper aims to explore the\napplications, challenges, and future prospects of LMM in the domain of human\nfactors and ergonomics through an expert-LMM collaborated literature review.\nSpecifically, a novel literature review method is proposed, and research\nstudies of LMM-based accident analysis, human modelling and intervention design\nare introduced. Subsequently, the paper discusses future trends of the research\nparadigm and challenges of human factors and ergonomics studies in the era of\nLMMs. It is expected that this study can provide a valuable perspective and\nserve as a reference for integrating human factors with artificial\nintelligence.",
    "categories": [
      "cs.HC",
      "cs.AI"
    ],
    "primary_category": "cs.HC",
    "comment": "14 pages, journal paper",
    "pdf_url": "http://arxiv.org/pdf/2405.13426v1",
    "published_date": "2024-05-22 08:14:40 UTC",
    "updated_date": "2024-05-22 08:14:40 UTC"
  },
  {
    "arxiv_id": "2405.13407v1",
    "title": "Dynamic Context Adaptation and Information Flow Control in Transformers: Introducing the Evaluator Adjuster Unit and Gated Residual Connections",
    "authors": [
      "Sahil Rajesh Dhayalkar"
    ],
    "abstract": "Transformers have revolutionized various domains of artificial intelligence\ndue to their unique ability to model long-range dependencies in data. However,\nthey lack in nuanced, context-dependent modulation of features and information\nflow. This paper introduces two significant enhancements to the transformer\narchitecture - the Evaluator Adjuster Unit (EAU) and Gated Residual Connections\n(GRC) - designed to address these limitations. The EAU dynamically modulates\nattention outputs based on the relevance of the input context, allowing for\nmore adaptive response patterns. Concurrently, the GRC modifies the\ntransformer's residual connections through a gating mechanism that selectively\ncontrols the information flow, thereby enhancing the network's ability to focus\non contextually important features. We evaluate the performance of these\nenhancements across several benchmarks in natural language processing. Our\nresults demonstrate improved adaptability and efficiency, suggesting that these\nmodifications could set new standards for designing flexible and context-aware\ntransformer models.",
    "categories": [
      "cs.LG",
      "cs.AI"
    ],
    "primary_category": "cs.LG",
    "comment": "10 pages, 2 figures, 4 experiments",
    "pdf_url": "http://arxiv.org/pdf/2405.13407v1",
    "published_date": "2024-05-22 07:33:24 UTC",
    "updated_date": "2024-05-22 07:33:24 UTC"
  },
  {
    "arxiv_id": "2405.13394v1",
    "title": "A theory of neural emulators",
    "authors": [
      "Catalin C. Mitelut"
    ],
    "abstract": "A central goal in neuroscience is to provide explanations for how animal\nnervous systems can generate actions and cognitive states such as consciousness\nwhile artificial intelligence (AI) and machine learning (ML) seek to provide\nmodels that are increasingly better at prediction. Despite many decades of\nresearch we have made limited progress on providing neuroscience explanations\nyet there is an increased use of AI and ML methods in neuroscience for\nprediction of behavior and even cognitive states. Here we propose emulator\ntheory (ET) and neural emulators as circuit- and scale-independent predictive\nmodels of biological brain activity and emulator theory (ET) as an alternative\nresearch paradigm in neuroscience. ET proposes that predictive models trained\nsolely on neural dynamics and behaviors can generate functionally\nindistinguishable systems from their sources. That is, compared to the\nbiological organisms which they model, emulators may achieve indistinguishable\nbehavior and cognitive states - including consciousness - without any\nmechanistic explanations. We posit ET via several conjectures, discuss the\nnature of endogenous and exogenous activation of neural circuits, and discuss\nneural causality of phenomenal states. ET provides the conceptual and empirical\nframework for prediction-based models of neural dynamics and behavior without\nexplicit representations of idiosyncratically evolved nervous systems.",
    "categories": [
      "q-bio.NC",
      "cs.AI"
    ],
    "primary_category": "q-bio.NC",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2405.13394v1",
    "published_date": "2024-05-22 07:12:03 UTC",
    "updated_date": "2024-05-22 07:12:03 UTC"
  },
  {
    "arxiv_id": "2405.13393v1",
    "title": "NFCL: Simply interpretable neural networks for a short-term multivariate forecasting",
    "authors": [
      "Wonkeun Jo",
      "Dongil Kim"
    ],
    "abstract": "Multivariate time-series forecasting (MTSF) stands as a compelling field\nwithin the machine learning community. Diverse neural network based\nmethodologies deployed in MTSF applications have demonstrated commendable\nefficacy. Despite the advancements in model performance, comprehending the\nrationale behind the model's behavior remains an enigma. Our proposed model,\nthe Neural ForeCasting Layer (NFCL), employs a straightforward amalgamation of\nneural networks. This uncomplicated integration ensures that each neural\nnetwork contributes inputs and predictions independently, devoid of\ninterference from other inputs. Consequently, our model facilitates a\ntransparent explication of forecast results. This paper introduces NFCL along\nwith its diverse extensions. Empirical findings underscore NFCL's superior\nperformance compared to nine benchmark models across 15 available open\ndatasets. Notably, NFCL not only surpasses competitors but also provides\nelucidation for its predictions. In addition, Rigorous experimentation\ninvolving diverse model structures bolsters the justification of NFCL's unique\nconfiguration.",
    "categories": [
      "cs.LG",
      "cs.AI",
      "I.2.1; I.5.4"
    ],
    "primary_category": "cs.LG",
    "comment": "24 pages, 9 figures, preprint",
    "pdf_url": "http://arxiv.org/pdf/2405.13393v1",
    "published_date": "2024-05-22 07:08:27 UTC",
    "updated_date": "2024-05-22 07:08:27 UTC"
  },
  {
    "arxiv_id": "2405.13386v1",
    "title": "360Zhinao Technical Report",
    "authors": [
      "360Zhinao Team"
    ],
    "abstract": "We present 360Zhinao models with 7B parameter size and context lengths\nspanning 4K, 32K and 360K, all available at\nhttps://github.com/Qihoo360/360zhinao. For rapid development in pretraining, we\nestablish a stable and sensitive ablation environment to evaluate and compare\nexperiment runs with minimal model size. Under such guidance, we perfect our\ndata cleaning and composition strategies to pretrain\n$\\texttt{360Zhinao-7B-Base}$ on 3.4T tokens. We also mainly emphasize data\nduring alignment, where we strive to balance quantity and quality with\nfiltering and reformatting. With tailored data, 360Zhinao-7B's context window\nis easily extended to 32K and 360K. RMs and RLHF are trained following SFT and\ncredibly applied to specific tasks. All together these contributions lead to\n360Zhinao-7B's competitive performance among models of similar size.",
    "categories": [
      "cs.CL",
      "cs.AI"
    ],
    "primary_category": "cs.CL",
    "comment": "360Zhinao technical report. Github:\n  https://github.com/Qihoo360/360zhinao",
    "pdf_url": "http://arxiv.org/pdf/2405.13386v1",
    "published_date": "2024-05-22 06:45:38 UTC",
    "updated_date": "2024-05-22 06:45:38 UTC"
  },
  {
    "arxiv_id": "2405.13374v1",
    "title": "Collaboration of Teachers for Semi-supervised Object Detection",
    "authors": [
      "Liyu Chen",
      "Huaao Tang",
      "Yi Wen",
      "Hanting Chen",
      "Wei Li",
      "Junchao Liu",
      "Jie Hu"
    ],
    "abstract": "Recent semi-supervised object detection (SSOD) has achieved remarkable\nprogress by leveraging unlabeled data for training. Mainstream SSOD methods\nrely on Consistency Regularization methods and Exponential Moving Average\n(EMA), which form a cyclic data flow. However, the EMA updating training\napproach leads to weight coupling between the teacher and student models. This\ncoupling in a cyclic data flow results in a decrease in the utilization of\nunlabeled data information and the confirmation bias on low-quality or\nerroneous pseudo-labels. To address these issues, we propose the Collaboration\nof Teachers Framework (CTF), which consists of multiple pairs of teacher and\nstudent models for training. In the learning process of CTF, the Data\nPerformance Consistency Optimization module (DPCO) informs the best pair of\nteacher models possessing the optimal pseudo-labels during the past training\nprocess, and these most reliable pseudo-labels generated by the best performing\nteacher would guide the other student models. As a consequence, this framework\ngreatly improves the utilization of unlabeled data and prevents the positive\nfeedback cycle of unreliable pseudo-labels. The CTF achieves outstanding\nresults on numerous SSOD datasets, including a 0.71% mAP improvement on the 10%\nannotated COCO dataset and a 0.89% mAP improvement on the VOC dataset compared\nto LabelMatch and converges significantly faster. Moreover, the CTF is\nplug-and-play and can be integrated with other mainstream SSOD methods.",
    "categories": [
      "cs.CV",
      "cs.AI"
    ],
    "primary_category": "cs.CV",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2405.13374v1",
    "published_date": "2024-05-22 06:17:50 UTC",
    "updated_date": "2024-05-22 06:17:50 UTC"
  },
  {
    "arxiv_id": "2405.13360v1",
    "title": "How to Trace Latent Generative Model Generated Images without Artificial Watermark?",
    "authors": [
      "Zhenting Wang",
      "Vikash Sehwag",
      "Chen Chen",
      "Lingjuan Lyu",
      "Dimitris N. Metaxas",
      "Shiqing Ma"
    ],
    "abstract": "Latent generative models (e.g., Stable Diffusion) have become more and more\npopular, but concerns have arisen regarding potential misuse related to images\ngenerated by these models. It is, therefore, necessary to analyze the origin of\nimages by inferring if a particular image was generated by a specific latent\ngenerative model. Most existing methods (e.g., image watermark and model\nfingerprinting) require extra steps during training or generation. These\nrequirements restrict their usage on the generated images without such extra\noperations, and the extra required operations might compromise the quality of\nthe generated images. In this work, we ask whether it is possible to\neffectively and efficiently trace the images generated by a specific latent\ngenerative model without the aforementioned requirements. To study this\nproblem, we design a latent inversion based method called LatentTracer to trace\nthe generated images of the inspected model by checking if the examined images\ncan be well-reconstructed with an inverted latent input. We leverage gradient\nbased latent inversion and identify a encoder-based initialization critical to\nthe success of our approach. Our experiments on the state-of-the-art latent\ngenerative models, such as Stable Diffusion, show that our method can\ndistinguish the images generated by the inspected model and other images with a\nhigh accuracy and efficiency. Our findings suggest the intriguing possibility\nthat today's latent generative generated images are naturally watermarked by\nthe decoder used in the source models. Code:\nhttps://github.com/ZhentingWang/LatentTracer.",
    "categories": [
      "cs.CV",
      "cs.AI",
      "cs.LG"
    ],
    "primary_category": "cs.CV",
    "comment": "ICML 2024",
    "pdf_url": "http://arxiv.org/pdf/2405.13360v1",
    "published_date": "2024-05-22 05:33:47 UTC",
    "updated_date": "2024-05-22 05:33:47 UTC"
  },
  {
    "arxiv_id": "2405.13356v2",
    "title": "Large Language Models (LLMs) Assisted Wireless Network Deployment in Urban Settings",
    "authors": [
      "Nurullah Sevim",
      "Mostafa Ibrahim",
      "Sabit Ekin"
    ],
    "abstract": "The advent of Large Language Models (LLMs) has revolutionized language\nunderstanding and human-like text generation, drawing interest from many other\nfields with this question in mind: What else are the LLMs capable of? Despite\ntheir widespread adoption, ongoing research continues to explore new ways to\nintegrate LLMs into diverse systems.\n  This paper explores new techniques to harness the power of LLMs for 6G (6th\nGeneration) wireless communication technologies, a domain where automation and\nintelligent systems are pivotal. The inherent adaptability of LLMs to\ndomain-specific tasks positions them as prime candidates for enhancing wireless\nsystems in the 6G landscape.\n  We introduce a novel Reinforcement Learning (RL) based framework that\nleverages LLMs for network deployment in wireless communications. Our approach\ninvolves training an RL agent, utilizing LLMs as its core, in an urban setting\nto maximize coverage. The agent's objective is to navigate the complexities of\nurban environments and identify the network parameters for optimal area\ncoverage. Additionally, we integrate LLMs with Convolutional Neural Networks\n(CNNs) to capitalize on their strengths while mitigating their limitations. The\nDeep Deterministic Policy Gradient (DDPG) algorithm is employed for training\npurposes. The results suggest that LLM-assisted models can outperform CNN-based\nmodels in some cases while performing at least as well in others.",
    "categories": [
      "cs.AI"
    ],
    "primary_category": "cs.AI",
    "comment": "This work has been submitted to the IEEE for possible publication",
    "pdf_url": "http://arxiv.org/pdf/2405.13356v2",
    "published_date": "2024-05-22 05:19:51 UTC",
    "updated_date": "2024-08-08 21:13:31 UTC"
  },
  {
    "arxiv_id": "2405.13352v1",
    "title": "\"Turing Tests\" For An AI Scientist",
    "authors": [
      "Xiaoxin Yin"
    ],
    "abstract": "While LLMs have shown impressive capabilities in solving math or coding\nproblems, the ability to make scientific discoveries remains a distinct\nchallenge. This paper proposes a \"Turing test for an AI scientist\" to assess\nwhether an AI agent can conduct scientific research independently, without\nrelying on human-generated knowledge. Drawing inspiration from the historical\ndevelopment of science, we propose seven benchmark tests that evaluate an AI\nagent's ability to make groundbreaking discoveries in various scientific\ndomains. These tests include inferring the heliocentric model from celestial\nobservations, discovering the laws of motion in a simulated environment,\nderiving the differential equation governing vibrating strings, inferring\nMaxwell's equations from electrodynamics simulations, inventing numerical\nmethods for initial value problems, discovering Huffman coding for data\ncompression, and developing efficient sorting algorithms. To ensure the\nvalidity of these tests, the AI agent is provided with interactive libraries or\ndatasets specific to each problem, without access to human knowledge that could\npotentially contain information about the target discoveries. The ultimate goal\nis to create an AI scientist capable of making novel and impactful scientific\ndiscoveries, surpassing the best human experts in their respective fields.\nThese \"Turing tests\" serve as intermediate milestones, assessing the AI agent's\nability to make discoveries that were groundbreaking in their time. If an AI\nagent can pass the majority of these seven tests, it would indicate significant\nprogress towards building an AI scientist, paving the way for future\nadvancements in autonomous scientific discovery. This paper aims to establish a\nbenchmark for the capabilities of AI in scientific research and to stimulate\nfurther research in this exciting field.",
    "categories": [
      "cs.AI"
    ],
    "primary_category": "cs.AI",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2405.13352v1",
    "published_date": "2024-05-22 05:14:27 UTC",
    "updated_date": "2024-05-22 05:14:27 UTC"
  },
  {
    "arxiv_id": "2405.13347v2",
    "title": "Time-Series Forecasting and Sequence Learning Using Memristor-based Reservoir System",
    "authors": [
      "Abdullah M. Zyarah",
      "Dhireesha Kudithipudi"
    ],
    "abstract": "Pushing the frontiers of time-series information processing in the\never-growing domain of edge devices with stringent resources has been impeded\nby the systems' ability to process information and learn locally on the device.\nLocal processing and learning of time-series information typically demand\nintensive computations and massive storage as the process involves retrieving\ninformation and tuning hundreds of parameters back in time. In this work, we\ndeveloped a memristor-based echo state network accelerator that features\nefficient temporal data processing and in-situ online learning. The proposed\ndesign is benchmarked using various datasets involving real-world tasks, such\nas forecasting the load energy consumption and weather conditions. The\nexperimental results illustrate that the hardware model experiences a marginal\ndegradation in performance as compared to the software counterpart. This is\nmainly attributed to the limited precision and dynamic range of network\nparameters when emulated using memristor devices. The proposed system is\nevaluated for lifespan, robustness, and energy-delay product. It is observed\nthat the system demonstrates reasonable robustness for device failure below\n10%, which may occur due to stuck-at faults. Furthermore, 247X reduction in\nenergy consumption is achieved when compared to a custom CMOS digital design\nimplemented at the same technology node.",
    "categories": [
      "cs.LG",
      "cs.AI",
      "cs.AR"
    ],
    "primary_category": "cs.LG",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2405.13347v2",
    "published_date": "2024-05-22 05:07:56 UTC",
    "updated_date": "2024-09-15 15:10:57 UTC"
  },
  {
    "arxiv_id": "2405.13325v3",
    "title": "DEGAP: Dual Event-Guided Adaptive Prefixes for Templated-Based Event Argument Extraction with Slot Querying",
    "authors": [
      "Guanghui Wang",
      "Dexi Liu",
      "Jian-Yun Nie",
      "Qizhi Wan",
      "Rong Hu",
      "Xiping Liu",
      "Wanlong Liu",
      "Jiaming Liu"
    ],
    "abstract": "Recent advancements in event argument extraction (EAE) involve incorporating\nuseful auxiliary information into models during training and inference, such as\nretrieved instances and event templates. These methods face two challenges: (1)\nthe retrieval results may be irrelevant and (2) templates are developed\nindependently for each event without considering their possible relationship.\nIn this work, we propose DEGAP to address these challenges through a simple yet\neffective components: dual prefixes, i.e. learnable prompt vectors, where the\ninstance-oriented prefix and template-oriented prefix are trained to learn\ninformation from different event instances and templates. Additionally, we\npropose an event-guided adaptive gating mechanism, which can adaptively\nleverage possible connections between different events and thus capture\nrelevant information from the prefix. Finally, these event-guided prefixes\nprovide relevant information as cues to EAE model without retrieval. Extensive\nexperiments demonstrate that our method achieves new state-of-the-art\nperformance on four datasets (ACE05, RAMS, WIKIEVENTS, and MLEE). Further\nanalysis shows the impact of different components.",
    "categories": [
      "cs.CL",
      "cs.AI",
      "cs.IR"
    ],
    "primary_category": "cs.CL",
    "comment": "Published as a conference paper in COLING 2025",
    "pdf_url": "http://arxiv.org/pdf/2405.13325v3",
    "published_date": "2024-05-22 03:56:55 UTC",
    "updated_date": "2025-05-08 16:33:22 UTC"
  },
  {
    "arxiv_id": "2405.13324v1",
    "title": "Adversarial Training via Adaptive Knowledge Amalgamation of an Ensemble of Teachers",
    "authors": [
      "Shayan Mohajer Hamidi",
      "Linfeng Ye"
    ],
    "abstract": "Adversarial training (AT) is a popular method for training robust deep neural\nnetworks (DNNs) against adversarial attacks. Yet, AT suffers from two\nshortcomings: (i) the robustness of DNNs trained by AT is highly intertwined\nwith the size of the DNNs, posing challenges in achieving robustness in smaller\nmodels; and (ii) the adversarial samples employed during the AT process exhibit\npoor generalization, leaving DNNs vulnerable to unforeseen attack types. To\naddress these dual challenges, this paper introduces adversarial training via\nadaptive knowledge amalgamation of an ensemble of teachers (AT-AKA). In\nparticular, we generate a diverse set of adversarial samples as the inputs to\nan ensemble of teachers; and then, we adaptively amalgamate the logtis of these\nteachers to train a generalized-robust student. Through comprehensive\nexperiments, we illustrate the superior efficacy of AT-AKA over existing AT\nmethods and adversarial robustness distillation techniques against cutting-edge\nattacks, including AutoAttack.",
    "categories": [
      "cs.LG",
      "cs.AI"
    ],
    "primary_category": "cs.LG",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2405.13324v1",
    "published_date": "2024-05-22 03:47:55 UTC",
    "updated_date": "2024-05-22 03:47:55 UTC"
  },
  {
    "arxiv_id": "2405.13300v3",
    "title": "FAITH: Frequency-domain Attention In Two Horizons for Time Series Forecasting",
    "authors": [
      "Ruiqi Li",
      "Maowei Jiang",
      "Kai Wang",
      "Kaiduo Feng",
      "Quangao Liu",
      "Yue Sun",
      "Xiufang Zhou"
    ],
    "abstract": "Time Series Forecasting plays a crucial role in various fields such as\nindustrial equipment maintenance, meteorology, energy consumption, traffic flow\nand financial investment. However, despite their considerable advantages over\ntraditional statistical approaches, current deep learning-based predictive\nmodels often exhibit a significant deviation between their forecasting outcomes\nand the ground truth. This discrepancy is largely due to an insufficient\nemphasis on extracting the sequence's latent information, particularly its\nglobal information within the frequency domain and the relationship between\ndifferent variables. To address this issue, we propose a novel model\nFrequency-domain Attention In Two Horizons, which decomposes time series into\ntrend and seasonal components using a multi-scale sequence adaptive\ndecomposition and fusion architecture, and processes them separately. FAITH\nutilizes Frequency Channel feature Extraction Module and Frequency Temporal\nfeature Extraction Module to capture inter-channel relationships and temporal\nglobal information in the sequence, significantly improving its ability to\nhandle long-term dependencies and complex patterns. Furthermore, FAITH achieves\ntheoretically linear complexity by modifying the time-frequency domain\ntransformation method, effectively reducing computational costs. Extensive\nexperiments on 6 benchmarks for long-term forecasting and 3 benchmarks for\nshort-term forecasting demonstrate that FAITH outperforms existing models in\nmany fields, such as electricity, weather and traffic, proving its\neffectiveness and superiority both in long-term and short-term time series\nforecasting tasks. Our codes and data are available at\nhttps://github.com/LRQ577/FAITH.",
    "categories": [
      "cs.LG",
      "cs.AI"
    ],
    "primary_category": "cs.LG",
    "comment": "We think there are some errors in the experiment result, it may lead\n  to a wrong conclusion. So we think it will be responsible to withdraw it",
    "pdf_url": "http://arxiv.org/pdf/2405.13300v3",
    "published_date": "2024-05-22 02:37:02 UTC",
    "updated_date": "2024-07-01 04:01:11 UTC"
  },
  {
    "arxiv_id": "2406.00014v2",
    "title": "KU-DMIS at EHRSQL 2024:Generating SQL query via question templatization in EHR",
    "authors": [
      "Hajung Kim",
      "Chanhwi Kim",
      "Hoonick Lee",
      "Kyochul Jang",
      "Jiwoo Lee",
      "Kyungjae Lee",
      "Gangwoo Kim",
      "Jaewoo Kang"
    ],
    "abstract": "Transforming natural language questions into SQL queries is crucial for\nprecise data retrieval from electronic health record (EHR) databases. A\nsignificant challenge in this process is detecting and rejecting unanswerable\nquestions that request information beyond the database's scope or exceed the\nsystem's capabilities. In this paper, we introduce a novel text-to-SQL\nframework that robustly handles out-of-domain questions and verifies the\ngenerated queries with query execution.Our framework begins by standardizing\nthe structure of questions into a templated format. We use a powerful large\nlanguage model (LLM), fine-tuned GPT-3.5 with detailed prompts involving the\ntable schemas of the EHR database system. Our experimental results demonstrate\nthe effectiveness of our framework on the EHRSQL-2024 benchmark benchmark, a\nshared task in the ClinicalNLP workshop. Although a straightforward fine-tuning\nof GPT shows promising results on the development set, it struggled with the\nout-of-domain questions in the test set. With our framework, we improve our\nsystem's adaptability and achieve competitive performances in the official\nleaderboard of the EHRSQL-2024 challenge.",
    "categories": [
      "cs.DB",
      "cs.AI",
      "cs.CL",
      "cs.IR"
    ],
    "primary_category": "cs.DB",
    "comment": "Published at ClinicalNLP workshop @ NAACL 2024",
    "pdf_url": "http://arxiv.org/pdf/2406.00014v2",
    "published_date": "2024-05-22 02:15:57 UTC",
    "updated_date": "2024-06-19 16:21:46 UTC"
  },
  {
    "arxiv_id": "2405.13290v1",
    "title": "Theoretical Analysis of Meta Reinforcement Learning: Generalization Bounds and Convergence Guarantees",
    "authors": [
      "Cangqing Wang",
      "Mingxiu Sui",
      "Dan Sun",
      "Zecheng Zhang",
      "Yan Zhou"
    ],
    "abstract": "This research delves deeply into Meta Reinforcement Learning (Meta RL)\nthrough a exploration focusing on defining generalization limits and ensuring\nconvergence. By employing a approach this article introduces an innovative\ntheoretical framework to meticulously assess the effectiveness and performance\nof Meta RL algorithms. We present an explanation of generalization limits\nmeasuring how well these algorithms can adapt to learning tasks while\nmaintaining consistent results. Our analysis delves into the factors that\nimpact the adaptability of Meta RL revealing the relationship, between\nalgorithm design and task complexity. Additionally we establish convergence\nassurances by proving conditions under which Meta RL strategies are guaranteed\nto converge towards solutions. We examine the convergence behaviors of Meta RL\nalgorithms across scenarios providing a comprehensive understanding of the\ndriving forces behind their long term performance. This exploration covers both\nconvergence and real time efficiency offering a perspective, on the\ncapabilities of these algorithms.",
    "categories": [
      "cs.LG",
      "cs.AI"
    ],
    "primary_category": "cs.LG",
    "comment": "This paper has been accepted by the 2024 International Conference on\n  Modeling, Natural Language Processing and Machine Learning(CMNM 2024)",
    "pdf_url": "http://arxiv.org/pdf/2405.13290v1",
    "published_date": "2024-05-22 02:09:22 UTC",
    "updated_date": "2024-05-22 02:09:22 UTC"
  },
  {
    "arxiv_id": "2407.06194v2",
    "title": "More Distinctively Black and Feminine Faces Lead to Increased Stereotyping in Vision-Language Models",
    "authors": [
      "Messi H. J. Lee",
      "Jacob M. Montgomery",
      "Calvin K. Lai"
    ],
    "abstract": "Vision Language Models (VLMs), exemplified by GPT-4V, adeptly integrate text\nand vision modalities. This integration enhances Large Language Models' ability\nto mimic human perception, allowing them to process image inputs. Despite VLMs'\nadvanced capabilities, however, there is a concern that VLMs inherit biases of\nboth modalities in ways that make biases more pervasive and difficult to\nmitigate. Our study explores how VLMs perpetuate homogeneity bias and trait\nassociations with regards to race and gender. When prompted to write stories\nbased on images of human faces, GPT-4V describes subordinate racial and gender\ngroups with greater homogeneity than dominant groups and relies on distinct,\nyet generally positive, stereotypes. Importantly, VLM stereotyping is driven by\nvisual cues rather than group membership alone such that faces that are rated\nas more prototypically Black and feminine are subject to greater stereotyping.\nThese findings suggest that VLMs may associate subtle visual cues related to\nracial and gender groups with stereotypes in ways that could be challenging to\nmitigate. We explore the underlying reasons behind this behavior and discuss\nits implications and emphasize the importance of addressing these biases as\nVLMs come to mirror human perception.",
    "categories": [
      "cs.CV",
      "cs.AI",
      "cs.CL"
    ],
    "primary_category": "cs.CV",
    "comment": "This submission is being withdrawn to address concerns related to the\n  terms of use of a database utilized in the research. We aim to ensure full\n  compliance with all data usage agreements before proceeding with publication",
    "pdf_url": "http://arxiv.org/pdf/2407.06194v2",
    "published_date": "2024-05-22 00:45:29 UTC",
    "updated_date": "2024-11-16 00:29:20 UTC"
  },
  {
    "arxiv_id": "2405.13264v1",
    "title": "Part-based Quantitative Analysis for Heatmaps",
    "authors": [
      "Osman Tursun",
      "Sinan Kalkan",
      "Simon Denman",
      "Sridha Sridharan",
      "Clinton Fookes"
    ],
    "abstract": "Heatmaps have been instrumental in helping understand deep network decisions,\nand are a common approach for Explainable AI (XAI). While significant progress\nhas been made in enhancing the informativeness and accessibility of heatmaps,\nheatmap analysis is typically very subjective and limited to domain experts. As\nsuch, developing automatic, scalable, and numerical analysis methods to make\nheatmap-based XAI more objective, end-user friendly, and cost-effective is\nvital. In addition, there is a need for comprehensive evaluation metrics to\nassess heatmap quality at a granular level.",
    "categories": [
      "cs.LG",
      "cs.AI",
      "cs.CV"
    ],
    "primary_category": "cs.LG",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2405.13264v1",
    "published_date": "2024-05-22 00:24:17 UTC",
    "updated_date": "2024-05-22 00:24:17 UTC"
  },
  {
    "arxiv_id": "2405.13256v1",
    "title": "Traffic control using intelligent timing of traffic lights with reinforcement learning technique and real-time processing of surveillance camera images",
    "authors": [
      "Mahdi Jamebozorg",
      "Mohsen Hami",
      "Sajjad Deh Deh Jani"
    ],
    "abstract": "Optimal management of traffic light timing is one of the most effective\nfactors in reducing urban traffic. In most old systems, fixed timing was used\nalong with human factors to control traffic, which is not very efficient in\nterms of time and cost. Nowadays, methods in the field of traffic management\nare based on the use of artificial intelligence. In this method, by using\nreal-time processing of video surveillance camera images along with\nreinforcement learning, the optimal timing of traffic lights is determined and\napplied according to several parameters. In the research, deep learning methods\nwere used in vehicle detection using the YOLOv9-C model to estimate the number\nand other characteristics of vehicles such as speed. Finally, by modeling\nvehicles in an urban environment simulator at OpenAI Gym using multi-factor\nreinforcement learning and the DQN Rainbow algorithm, timing is applied to\ntraffic lights at intersections. Additionally, the use of transfer learning\nalong with retraining the model on images of Iranian cars has increased the\naccuracy of the model. The results of the proposed method show a model that is\nreasonably accurate in both parts of analyzing surveillance cameras and finding\nthe optimal timing, and it has been observed that it has better accuracy than\nprevious research.",
    "categories": [
      "cs.CV",
      "cs.AI"
    ],
    "primary_category": "cs.CV",
    "comment": "6th International conference on traffic management and safety ,Tehran\n  city, 12 pages in Persian",
    "pdf_url": "http://arxiv.org/pdf/2405.13256v1",
    "published_date": "2024-05-22 00:04:32 UTC",
    "updated_date": "2024-05-22 00:04:32 UTC"
  }
]