{
  "date": "2025-03-09",
  "category": "cs.AI",
  "summary": "欢迎来到 UTC 时间 2025-03-09 的 arXiv 中文 TLDR 快报！今天 arXiv 更新了 92 篇论文，主要聚焦 AI 安全、多模态模型优化、生成式 AI 和医学应用等领域，亮点包括 LLM 的隐私审计和多模态推理创新（如 Vision-R1），以及有影响力学者如 Sylvester J. Gates III 的神经网络研究，强调了 AI 在实际应用中的鲁棒性和效率提升。\n\n### 重点论文速览\n我挑选了今天最令人印象深刻的论文，先聊那些涉及核心 AI 创新、实际影响大的，以及有名学者参与的文章。其他次要论文（如一些初步实验或小众主题）将快速掠过，只提关键点。\n\n1. **Privacy Auditing of Large Language Models（大型语言模型的隐私审计）**  \n   作者包括 Prateek Mittal 等。该文提出了一种更有效的 canary 生成方法，用于检测大型语言模型（LLMs）的隐私泄露，在不依赖影子模型的情况下实现了显著改进（如 Qwen2.5-0.5B 模型的 TPR 从 4.2% 提升到 49.6%）。主要贡献：提升了隐私审计的准确性和实用性，适用于真实场景的模型训练。\n\n2. **Vision-R1: Incentivizing Reasoning Capability in Multimodal Large Language Models（增强多模态大型语言模型的推理能力）**  \n   作者如 Bohan Jia 和 Shaohui Lin。该文使用强化学习构建 Vision-R1 框架，通过高质量多模态数据集（如 Vision-R1-cold）提升模型在数学推理任务中的性能，实现了 MathVista 基准的 73.5% 准确率，仅比 OpenAI O1 低 0.4%。主要发现：强化学习能显著改善多模态推理，而非简单微调，展示了 LLM 在复杂任务中的潜力。\n\n3. **Characterizing Learning in Spiking Neural Networks with Astrocyte-Like Units（带星形胶质细胞单元的脉冲神经网络学习特征）**  \n   作者包括 Sylvester J. Gates III（知名物理学家）。论文引入星形胶质细胞单元到脉冲神经网络中，提高了时间序列预测任务的学习率（如神经元与星形细胞比例 1:2 时表现最佳）。主要贡献：模拟生物脑机制，证明了神经网络学习效率的提升，桥接了神经科学与 AI。\n\n4. **Multimodal AI-driven Biomarker for Early Detection of Cancer Cachexia（多模态 AI 驱动的癌症恶病质早期检测生物标志物）**  \n   该文提出一个多模态 AI 框架，使用 LLMs 和基础模型整合患者数据（如 CT 扫描和临床笔记），实现了癌症恶病质的早期预测。主要发现：动态适应患者因素（如年龄和癌症阶段），比传统指标更准确，潜力在于临床应用的个性化干预。\n\n5. **UniGenX: Unified Generation of Sequence and Structure with Autoregressive Diffusion（使用自回归扩散的序列和结构统一生成）**  \n   作者如 Tao Qin。该文开发了 UniGenX 框架，结合自回归模型和扩散模型，实现科学数据的统一生成（如分子和材料结构）。主要贡献：提高了生成精度和效率，在小分子生成任务中超越 SOTA，展示了 AI 在科学模拟中的应用潜力。\n\n6. **Infinite Leagues Under the Sea: Photorealistic 3D Underwater Terrain Generation by Latent Fractal Diffusion Models（使用潜在分形扩散模型的逼真 3D 水下地形生成）**  \n   相关论文如 8 和 61（后者涉及手语翻译）。该文（8）引入 DreamSea 模型，使用分形嵌入生成逼真的水下场景。贡献：提升了 3D 生成的多样性和一致性，适用于机器人模拟和游戏领域；结合 61 的多模态数据处理，展示了视觉生成在实际应用中的扩展。\n\n其他论文如强化学习（14. Fully-Decentralized MADDPG）和 AI 伦理（7. Dubito Ergo Sum）快速掠过：它们探讨了分布式代理和 AI 道德代理，但影响较局限于特定领域，无显著突破。类似 11. Effectiveness of Zero-shot-CoT in Japanese Prompts 和 20. Delusions of Large Language Models 等，贡献在于 LLM 的细化优化，但未有革命性进展，仅提升了特定任务的性能。\n\n总之，今天的论文突出了 AI 模型的鲁棒性和多模态融合，Vision-R1 和 UniGenX 等工作值得关注，有望推动实际应用。如果您对特定领域感兴趣，建议查看这些重点论文的摘要！",
  "papers": [
    {
      "arxiv_id": "2503.06808v1",
      "title": "Privacy Auditing of Large Language Models",
      "title_zh": "大型语言模型的隐私审计",
      "authors": [
        "Ashwinee Panda",
        "Xinyu Tang",
        "Milad Nasr",
        "Christopher A. Choquette-Choo",
        "Prateek Mittal"
      ],
      "abstract": "Current techniques for privacy auditing of large language models (LLMs) have\nlimited efficacy -- they rely on basic approaches to generate canaries which\nleads to weak membership inference attacks that in turn give loose lower bounds\non the empirical privacy leakage. We develop canaries that are far more\neffective than those used in prior work under threat models that cover a range\nof realistic settings. We demonstrate through extensive experiments on multiple\nfamilies of fine-tuned LLMs that our approach sets a new standard for detection\nof privacy leakage. For measuring the memorization rate of non-privately\ntrained LLMs, our designed canaries surpass prior approaches. For example, on\nthe Qwen2.5-0.5B model, our designed canaries achieve $49.6\\%$ TPR at $1\\%$\nFPR, vastly surpassing the prior approach's $4.2\\%$ TPR at $1\\%$ FPR. Our\nmethod can be used to provide a privacy audit of $\\varepsilon \\approx 1$ for a\nmodel trained with theoretical $\\varepsilon$ of 4. To the best of our\nknowledge, this is the first time that a privacy audit of LLM training has\nachieved nontrivial auditing success in the setting where the attacker cannot\ntrain shadow models, insert gradient canaries, or access the model at every\niteration.",
      "tldr_zh": "本文提出了一种更有效的canary设计方法，用于审计大型语言模型(LLMs)的隐私泄漏，解决了现有技术的局限性，如依赖基本canary导致的弱membership inference attacks和松散隐私下界。该方法在多种现实威胁模型下进行测试，并在多个fine-tuned LLM家族上实验证明，其检测性能大幅提升，例如在Qwen2.5-0.5B模型上，TPR从4.2%提高到49.6% at 1% FPR。研究首次实现了在攻击者无法训练shadow models、插入gradient canaries或访问模型每一次迭代的条件下，进行非平凡的隐私审计，为ε≈1的实证隐私评估提供了新标准。",
      "categories": [
        "cs.CR",
        "cs.AI",
        "cs.LG"
      ],
      "primary_category": "cs.CR",
      "comment": "ICLR 2025",
      "pdf_url": "http://arxiv.org/pdf/2503.06808v1",
      "published_date": "2025-03-09 23:32:15 UTC",
      "updated_date": "2025-03-09 23:32:15 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-23T23:42:02.850156"
    },
    {
      "arxiv_id": "2503.06803v1",
      "title": "Actionable AI: Enabling Non Experts to Understand and Configure AI Systems",
      "title_zh": "翻译失败",
      "authors": [
        "Cécile Boulard",
        "Sruthi Viswanathan",
        "Wanda Fey",
        "Thierry Jacquin"
      ],
      "abstract": "Interaction between humans and AI systems raises the question of how people\nunderstand AI systems. This has been addressed with explainable AI, the\ninterpretability arising from users' domain expertise, or collaborating with AI\nin a stable environment. In the absence of these elements, we discuss designing\nActionable AI, which allows non-experts to configure black-box agents. In this\npaper, we experiment with an AI-powered cartpole game and observe 22 pairs of\nparticipants to configure it via direct manipulation. Our findings suggest\nthat, in uncertain conditions, non-experts were able to achieve good levels of\nperformance. By influencing the behaviour of the agent, they exhibited an\noperational understanding of it, which proved sufficient to reach their goals.\nBased on this, we derive implications for designing Actionable AI systems. In\nconclusion, we propose Actionable AI as a way to open access to AI-based\nagents, giving end users the agency to influence such agents towards their own\ngoals.",
      "tldr_zh": "该论文提出“Actionable AI”概念，旨在让非专家用户理解和配置黑箱 AI 系统，而非依赖于可解释 AI 或领域专业知识。研究通过实验观察22对参与者直接操作一个AI驱动的cartpole游戏，发现非专家在不确定环境中能实现良好性能，并通过影响代理行为获得操作性理解。最终，论文总结了Actionable AI的设计启示，强调此方法可赋予最终用户控制权，帮助他们将AI导向自身目标。",
      "categories": [
        "cs.HC",
        "cs.AI"
      ],
      "primary_category": "cs.HC",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2503.06803v1",
      "published_date": "2025-03-09 23:09:04 UTC",
      "updated_date": "2025-03-09 23:09:04 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-23T23:42:13.471117"
    },
    {
      "arxiv_id": "2503.06798v1",
      "title": "Characterizing Learning in Spiking Neural Networks with Astrocyte-Like Units",
      "title_zh": "翻译失败",
      "authors": [
        "Christopher S. Yang",
        "Sylvester J. Gates III",
        "Dulara De Zoysa",
        "Jaehoon Choe",
        "Wolfgang Losert",
        "Corey B. Hart"
      ],
      "abstract": "Traditional artificial neural networks take inspiration from biological\nnetworks, using layers of neuron-like nodes to pass information for processing.\nMore realistic models include spiking in the neural network, capturing the\nelectrical characteristics more closely. However, a large proportion of brain\ncells are of the glial cell type, in particular astrocytes which have been\nsuggested to play a role in performing computations. Here, we introduce a\nmodified spiking neural network model with added astrocyte-like units in a\nneural network and asses their impact on learning. We implement the network as\na liquid state machine and task the network with performing a chaotic\ntime-series prediction task. We varied the number and ratio of neuron-like and\nastrocyte-like units in the network to examine the latter units effect on\nlearning. We show that the combination of neurons and astrocytes together, as\nopposed to neural- and astrocyte-only networks, are critical for driving\nlearning. Interestingly, we found that the highest learning rate was achieved\nwhen the ratio between astrocyte-like and neuron-like units was roughly 2 to 1,\nmirroring some estimates of the ratio of biological astrocytes to neurons. Our\nresults demonstrate that incorporating astrocyte-like units which represent\ninformation across longer timescales can alter the learning rates of neural\nnetworks, and the proportion of astrocytes to neurons should be tuned\nappropriately to a given task.",
      "tldr_zh": "本研究探讨了在脉冲神经网络(Spiking Neural Networks)中加入星形胶质细胞-like units对学习的影响，旨在模拟生物大脑中胶质细胞的作用。研究者修改了脉冲神经网络模型，使用液体状态机(Liquid State Machine)进行混沌时间序列预测任务，并通过调整神经元-like和星形胶质细胞-like units的数量和比例来评估其效果。结果显示，神经元和星形胶质细胞结合时学习效果最佳，特别是当二者比例约为2:1时，学习率最高，这与生物中星形胶质细胞和神经元的比例类似。总体而言，该研究证明了加入代表更长时标信息的星形胶质细胞-like units能显著改变神经网络的学习率，并建议根据具体任务优化比例。",
      "categories": [
        "cs.LG",
        "cs.AI",
        "physics.bio-ph"
      ],
      "primary_category": "cs.LG",
      "comment": "6 pages, 4 figures",
      "pdf_url": "http://arxiv.org/pdf/2503.06798v1",
      "published_date": "2025-03-09 22:36:58 UTC",
      "updated_date": "2025-03-09 22:36:58 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-23T23:42:26.237101"
    },
    {
      "arxiv_id": "2503.06797v1",
      "title": "Multimodal AI-driven Biomarker for Early Detection of Cancer Cachexia",
      "title_zh": "多模态 AI 驱动的生物标志物，用于癌症恶病质的早期检测",
      "authors": [
        "Sabeen Ahmed",
        "Nathan Parker",
        "Margaret Park",
        "Evan W. Davis",
        "Jennifer B. Permuth",
        "Matthew B. Schabath",
        "Yasin Yilmaz",
        "Ghulam Rasool"
      ],
      "abstract": "Cancer cachexia is a multifactorial syndrome characterized by progressive\nmuscle wasting, metabolic dysfunction, and systemic inflammation, leading to\nreduced quality of life and increased mortality. Despite extensive research, no\nsingle definitive biomarker exists, as cachexia-related indicators such as\nserum biomarkers, skeletal muscle measurements, and metabolic abnormalities\noften overlap with other conditions. Existing composite indices, including the\nCancer Cachexia Index (CXI), Modified CXI (mCXI), and Cachexia Score (CASCO),\nintegrate multiple biomarkers but lack standardized thresholds, limiting their\nclinical utility. This study proposes a multimodal AI-based biomarker for early\ncancer cachexia detection, leveraging open-source large language models (LLMs)\nand foundation models trained on medical data. The approach integrates\nheterogeneous patient data, including demographics, disease status, lab\nreports, radiological imaging (CT scans), and clinical notes, using a machine\nlearning framework that can handle missing data. Unlike previous AI-based\nmodels trained on curated datasets, this method utilizes routinely collected\nclinical data, enhancing real-world applicability. Additionally, the model\nincorporates confidence estimation, allowing the identification of cases\nrequiring expert review for precise clinical interpretation. Preliminary\nfindings demonstrate that integrating multiple data modalities improves\ncachexia prediction accuracy at the time of cancer diagnosis. The AI-based\nbiomarker dynamically adapts to patient-specific factors such as age, race,\nethnicity, weight, cancer type, and stage, avoiding the limitations of\nfixed-threshold biomarkers. This multimodal AI biomarker provides a scalable\nand clinically viable solution for early cancer cachexia detection,\nfacilitating personalized interventions and potentially improving treatment\noutcomes and patient survival.",
      "tldr_zh": "本研究提出了一种multimodal AI驱动的生物标志物，用于癌症cachexia的早期检测，以解决现有生物标志物缺乏标准化阈值和临床实用性不足的问题。该方法整合患者异构数据，包括人口统计信息、疾病状态、实验室报告、CT扫描和临床笔记，利用开源大型语言模型(LLMs)和机器学习框架处理缺失数据，并加入置信度估计以识别需专家审查的病例。与传统模型不同，该生物标志物动态适应患者特定因素，如年龄、种族和癌症类型，提高了预测准确性。初步结果显示，该方法在癌症诊断时显著提升了cachexia预测性能，提供可扩展的解决方案，促进个性化干预和患者生存率改善。",
      "categories": [
        "eess.IV",
        "cs.AI",
        "q-bio.QM"
      ],
      "primary_category": "eess.IV",
      "comment": "17 pages, 6 figures, 3 Tables",
      "pdf_url": "http://arxiv.org/pdf/2503.06797v1",
      "published_date": "2025-03-09 22:32:37 UTC",
      "updated_date": "2025-03-09 22:32:37 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-23T23:42:41.342173"
    },
    {
      "arxiv_id": "2503.06791v1",
      "title": "AutoMisty: A Multi-Agent LLM Framework for Automated Code Generation in the Misty Social Robot",
      "title_zh": "AutoMisty：",
      "authors": [
        "Xiao Wang",
        "Lu Dong",
        "Sahana Rangasrinivasan",
        "Ifeoma Nwogu",
        "Srirangaraj Setlur",
        "Venugopal Govindaraju"
      ],
      "abstract": "The social robot's open API allows users to customize open-domain\ninteractions. However, it remains inaccessible to those without programming\nexperience. In this work, we introduce AutoMisty, the first multi-agent\ncollaboration framework powered by large language models (LLMs), to enable the\nseamless generation of executable Misty robot code from natural language\ninstructions. AutoMisty incorporates four specialized agent modules to manage\ntask decomposition, assignment, problem-solving, and result synthesis. Each\nagent incorporates a two-layer optimization mechanism, with self-reflection for\niterative refinement and human-in-the-loop for better alignment with user\npreferences. AutoMisty ensures a transparent reasoning process, allowing users\nto iteratively refine tasks through natural language feedback for precise\nexecution. To evaluate AutoMisty's effectiveness, we designed a benchmark task\nset spanning four levels of complexity and conducted experiments in a real\nMisty robot environment. Extensive evaluations demonstrate that AutoMisty not\nonly consistently generates high-quality code but also enables precise code\ncontrol, significantly outperforming direct reasoning with ChatGPT-4o and\nChatGPT-o1. All code, optimized APIs, and experimental videos will be publicly\nreleased through the webpage: https://wangxiaoshawn.github.io/AutoMisty.html",
      "tldr_zh": "本文介绍了 AutoMisty，一种基于 Large Language Models (LLMs) 的多智能体框架，旨在从自然语言指令自动生成 Misty 社会机器人的可执行代码，从而让非程序员用户轻松自定义机器人交互。框架包括四个专门代理模块，负责任务分解、分配、问题解决和结果合成，并采用两层优化机制：Self-Reflection 用于迭代改进，以及 Human-in-the-Loop 确保与用户偏好对齐。实验在真实环境中进行基准测试，涵盖四级复杂性任务，结果显示 AutoMisty 生成的高质量代码并提供精确控制，显著优于 ChatGPT-4o 和 ChatGPT-o1。所有代码、优化 API 和实验视频将通过指定网页公开。",
      "categories": [
        "cs.RO",
        "cs.AI",
        "cs.HC",
        "cs.MA"
      ],
      "primary_category": "cs.RO",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2503.06791v1",
      "published_date": "2025-03-09 22:07:46 UTC",
      "updated_date": "2025-03-09 22:07:46 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-23T23:42:51.415973"
    },
    {
      "arxiv_id": "2503.06790v2",
      "title": "GenDR: Lightning Generative Detail Restorator",
      "title_zh": "GenDR: 迅捷生成式细节修复器",
      "authors": [
        "Yan Wang",
        "Shijie Zhao",
        "Kai Chen",
        "Kexin Zhang",
        "Junlin Li",
        "Li Zhang"
      ],
      "abstract": "Recent research applying text-to-image (T2I) diffusion models to real-world\nsuper-resolution (SR) has achieved remarkable success. However, fundamental\nmisalignments between T2I and SR targets result in a dilemma between inference\nspeed and detail fidelity. Specifically, T2I tasks prioritize multi-step\ninversion to synthesize coherent outputs aligned with textual prompts and\nshrink the latent space to reduce generating complexity. Contrariwise, SR tasks\npreserve most information from low-resolution input while solely restoring\nhigh-frequency details, thus necessitating sufficient latent space and fewer\ninference steps. To bridge the gap, we present a one-step diffusion model for\ngenerative detail restoration, GenDR, distilled from a tailored diffusion model\nwith larger latent space. In detail, we train a new SD2.1-VAE16 (0.9B) via\nrepresentation alignment to expand latent space without enlarging the model\nsize. Regarding step-distillation, we propose consistent score identity\ndistillation (CiD) that incorporates SR task-specific loss into score\ndistillation to leverage more SR priors and align the training target.\nFurthermore, we extend CiD with adversarial learning and representation\nalignment (CiDA) to enhance perceptual quality and accelerate training. We also\npolish the pipeline to achieve a more efficient inference. Experimental results\ndemonstrate that GenDR achieves state-of-the-art performance in both\nquantitative metrics and visual fidelity.",
      "tldr_zh": "该研究提出GenDR，一种高效的一步扩散模型，用于生成细节恢复，旨在解决文本到图像(T2I)扩散模型应用于真实世界超分辨率(SR)任务时存在的速度与细节保真度之间的冲突。GenDR通过从一个定制的扩散模型中蒸馏而来，训练新的SD2.1-VAE16模型以扩展潜在空间，并引入一致分数身份蒸馏(CiD)及其扩展版本CiDA（结合对抗学习和表示对齐），以提升SR任务的性能和训练效率。实验结果显示，GenDR在定量指标和视觉保真度上达到了最先进水平，为快速、高质量的图像细节恢复提供了新途径。",
      "categories": [
        "cs.CV",
        "cs.AI",
        "eess.IV"
      ],
      "primary_category": "cs.CV",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2503.06790v2",
      "published_date": "2025-03-09 22:02:18 UTC",
      "updated_date": "2025-04-03 05:51:38 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-23T23:43:02.259876"
    },
    {
      "arxiv_id": "2503.06788v1",
      "title": "Dubito Ergo Sum: Exploring AI Ethics",
      "title_zh": "Dubito Ergo Sum: 探索 AI 伦理",
      "authors": [
        "Viktor Dorfler",
        "Giles Cuthbert"
      ],
      "abstract": "We paraphrase Descartes' famous dictum in the area of AI ethics where the \"I\ndoubt and therefore I am\" is suggested as a necessary aspect of morality.\nTherefore AI, which cannot doubt itself, cannot possess moral agency. Of\ncourse, this is not the end of the story. We explore various aspects of the\nhuman mind that substantially differ from AI, which includes the sensory\ngrounding of our knowing, the act of understanding, and the significance of\nbeing able to doubt ourselves. The foundation of our argument is the discipline\nof ethics, one of the oldest and largest knowledge projects of human history,\nyet, we seem only to be beginning to get a grasp of it. After a couple of\nthousand years of studying the ethics of humans, we (humans) arrived at a point\nwhere moral psychology suggests that our moral decisions are intuitive, and all\nthe models from ethics become relevant only when we explain ourselves. This\nrecognition has a major impact on what and how we can do regarding AI ethics.\nWe do not offer a solution, we explore some ideas and leave the problem open,\nbut we hope somewhat better understood than before our study.",
      "tldr_zh": "本论文以“Dubito Ergo Sum”（我怀疑，因此我存在）为灵感，探讨AI ethics，论证AI由于无法自我怀疑而缺乏moral agency，从而不能真正拥有道德决策能力。作者比较了人类思维与AI的差异，包括sensory grounding、理解行为和自我怀疑的重要性，并引用伦理学和moral psychology的观点，指出人类的道德决策往往是直观的，仅在解释时才依赖伦理模型。这对AI ethics的研究产生了重大影响，论文不提供最终解决方案，而是通过探索这些想法加深了对问题的理解。",
      "categories": [
        "cs.AI",
        "cs.CY",
        "cs.HC"
      ],
      "primary_category": "cs.AI",
      "comment": "10 pages, 1 figure, HICSS 57: Hawaii International Conference on\n  System Sciences, Honolulu, HI, published January 2024",
      "pdf_url": "http://arxiv.org/pdf/2503.06788v1",
      "published_date": "2025-03-09 21:59:43 UTC",
      "updated_date": "2025-03-09 21:59:43 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-23T23:43:15.002012"
    },
    {
      "arxiv_id": "2503.06784v1",
      "title": "Infinite Leagues Under the Sea: Photorealistic 3D Underwater Terrain Generation by Latent Fractal Diffusion Models",
      "title_zh": "翻译失败",
      "authors": [
        "Tianyi Zhang",
        "Weiming Zhi",
        "Joshua Mangelson",
        "Matthew Johnson-Roberson"
      ],
      "abstract": "This paper tackles the problem of generating representations of underwater 3D\nterrain. Off-the-shelf generative models, trained on Internet-scale data but\nnot on specialized underwater images, exhibit downgraded realism, as images of\nthe seafloor are relatively uncommon. To this end, we introduce DreamSea, a\ngenerative model to generate hyper-realistic underwater scenes. DreamSea is\ntrained on real-world image databases collected from underwater robot surveys.\nImages from these surveys contain massive real seafloor observations and\ncovering large areas, but are prone to noise and artifacts from the real world.\nWe extract 3D geometry and semantics from the data with visual foundation\nmodels, and train a diffusion model that generates realistic seafloor images in\nRGBD channels, conditioned on novel fractal distribution-based latent\nembeddings. We then fuse the generated images into a 3D map, building a 3DGS\nmodel supervised by 2D diffusion priors which allows photorealistic novel view\nrendering. DreamSea is rigorously evaluated, demonstrating the ability to\nrobustly generate large-scale underwater scenes that are consistent, diverse,\nand photorealistic. Our work drives impact in multiple domains, spanning\nfilming, gaming, and robot simulation.",
      "tldr_zh": "本论文解决了生成真实水下 3D 地形的难题，引入了 DreamSea 模型，该模型利用真实水下机器人调查图像数据库训练，以克服现有生成模型在水下场景上的真实性不足。\nDreamSea 通过视觉基础模型提取 3D 几何和语义，并训练扩散模型生成 RGBD 通道的图像，条件基于分形分布-based latent embeddings，实现图像融合和 3DGS 模型的 photorealistic 新视图渲染。\n实验结果显示，DreamSea 能 robustly 生成大规模、一致、多样且光真实的水下场景，在电影、游戏和机器人模拟等领域具有显著应用潜力。",
      "categories": [
        "cs.GR",
        "cs.AI",
        "cs.CV",
        "cs.LG",
        "cs.RO"
      ],
      "primary_category": "cs.GR",
      "comment": "10 pages",
      "pdf_url": "http://arxiv.org/pdf/2503.06784v1",
      "published_date": "2025-03-09 21:43:37 UTC",
      "updated_date": "2025-03-09 21:43:37 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-23T23:43:27.588139"
    },
    {
      "arxiv_id": "2503.06781v1",
      "title": "Dr Genre: Reinforcement Learning from Decoupled LLM Feedback for Generic Text Rewriting",
      "title_zh": "翻译失败",
      "authors": [
        "Yufei Li",
        "John Nham",
        "Ganesh Jawahar",
        "Lei Shu",
        "David Uthus",
        "Yun-Hsuan Sung",
        "Chengrun Yang",
        "Itai Rolnick",
        "Yi Qiao",
        "Cong Liu"
      ],
      "abstract": "Generic text rewriting is a prevalent large language model (LLM) application\nthat covers diverse real-world tasks, such as style transfer, fact correction,\nand email editing. These tasks vary in rewriting objectives (e.g., factual\nconsistency vs. semantic preservation), making it challenging to develop a\nunified model that excels across all dimensions. Existing methods often\nspecialize in either a single task or a specific objective, limiting their\ngeneralizability. In this work, we introduce a generic model proficient in\nfactuality, stylistic, and conversational rewriting tasks. To simulate\nreal-world user rewrite requests, we construct a conversational rewrite\ndataset, ChatRewrite, that presents ``natural''-sounding instructions, from raw\nemails using LLMs. Combined with other popular rewrite datasets, including\nLongFact for the factuality rewrite task and RewriteLM for the stylistic\nrewrite task, this forms a broad benchmark for training and evaluating generic\nrewrite models. To align with task-specific objectives, we propose Dr Genre, a\nDecoupled-reward learning framework for Generic rewriting, that utilizes\nobjective-oriented reward models with a task-specific weighting. Evaluation\nshows that \\approach delivers higher-quality rewrites across all targeted\ntasks, improving objectives including instruction following (agreement),\ninternal consistency (coherence), and minimal unnecessary edits (conciseness).",
      "tldr_zh": "本文提出Dr Genre框架，利用Reinforcement Learning from Decoupled LLM Feedback，针对泛化文本重写任务（如风格转移、事实修正和对话编辑）开发一个统一的模型，以应对不同重写目标（如事实一致性和语义保留）的挑战。该框架通过构建ChatRewrite数据集（从原始邮件生成自然指令）并整合LongFact和RewriteLM等基准，进行任务特定的奖励模型训练和权重分配。实验结果显示，Dr Genre在指令遵循（agreement）、内部一致性（coherence）和简洁性方面表现出色，显著提升了重写质量。",
      "categories": [
        "cs.CL",
        "cs.AI",
        "cs.LG"
      ],
      "primary_category": "cs.CL",
      "comment": "29 pages, 4 figures, 25 tables",
      "pdf_url": "http://arxiv.org/pdf/2503.06781v1",
      "published_date": "2025-03-09 21:23:52 UTC",
      "updated_date": "2025-03-09 21:23:52 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-23T23:43:38.645970"
    },
    {
      "arxiv_id": "2503.06778v2",
      "title": "Large Language Models Are Effective Human Annotation Assistants, But Not Good Independent Annotators",
      "title_zh": "翻译失败",
      "authors": [
        "Feng Gu",
        "Zongxia Li",
        "Carlos Rafael Colon",
        "Benjamin Evans",
        "Ishani Mondal",
        "Jordan Lee Boyd-Graber"
      ],
      "abstract": "Event annotation is important for identifying market changes, monitoring\nbreaking news, and understanding sociological trends. Although expert\nannotators set the gold standards, human coding is expensive and inefficient.\nUnlike information extraction experiments that focus on single contexts, we\nevaluate a holistic workflow that removes irrelevant documents, merges\ndocuments about the same event, and annotates the events. Although LLM-based\nautomated annotations are better than traditional TF-IDF-based methods or Event\nSet Curation, they are still not reliable annotators compared to human experts.\nHowever, adding LLMs to assist experts for Event Set Curation can reduce the\ntime and mental effort required for Variable Annotation. When using LLMs to\nextract event variables to assist expert annotators, they agree more with the\nextracted variables than fully automated LLMs for annotation.",
      "tldr_zh": "这篇论文探讨了大型语言模型(LLMs)在事件标注中的作用，发现LLMs作为独立标注器不如人类专家可靠，尽管它们优于传统TF-IDF方法和Event Set Curation。研究评估了一个整体工作流，包括移除无关文档、合并相关文档和标注事件，结果显示LLMs在自动化标注时存在局限。作者强调，将LLMs用作人类专家的辅助工具，能显著减少Variable Annotation的时间和精力，并提高标注的一致性。",
      "categories": [
        "cs.CL",
        "cs.AI"
      ],
      "primary_category": "cs.CL",
      "comment": "9 pages, 4 figures",
      "pdf_url": "http://arxiv.org/pdf/2503.06778v2",
      "published_date": "2025-03-09 21:14:14 UTC",
      "updated_date": "2025-04-05 05:58:45 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-23T23:43:49.773027"
    },
    {
      "arxiv_id": "2503.06765v1",
      "title": "Effectiveness of Zero-shot-CoT in Japanese Prompts",
      "title_zh": "翻译失败",
      "authors": [
        "Shusuke Takayama",
        "Ian Frank"
      ],
      "abstract": "We compare the effectiveness of zero-shot Chain-of-Thought (CoT) prompting in\nJapanese and English using ChatGPT-3.5 and 4o-mini. The technique of zero-shot\nCoT, which involves appending a phrase such as \"Let's think step by step\" to a\nprompt to encourage reasoning before answering, has been shown to offer LLM\nperformance improvements in mathematical and reasoning tasks, particularly in\nEnglish. We investigate how these effects transfer to Japanese using the\nJapanese Multi-task Language Understanding Benchmark (JMMLU) and the Multi-task\nLanguage Understanding Benchmark (MMLU). Our results show that while zero-shot\nCoT prompting can lead to notable performance gains for some prompt categories\nin GPT-3.5, its impact in GPT-4o-mini is associated with significant\nperformance declines. However, for Japanese prompts there remain certain\ncategories, such as college mathematics and abstract algebra, that still\nexhibit improvements, despite the broader trend of diminishing effectiveness in\nmore advanced models.",
      "tldr_zh": "本研究比较了零样本 Chain-of-Thought (Zero-shot-CoT) 提示在日语和英语中的有效性，使用 ChatGPT-3.5 和 GPT-4o-mini 模型，通过 Japanese Multi-task Language Understanding Benchmark (JMMLU) 和 Multi-task Language Understanding Benchmark (MMLU) 进行评估。结果显示，Zero-shot-CoT 提示在 GPT-3.5 中能显著提升某些类别的性能，如数学和推理任务，但在大语言模型 GPT-4o-mini 中则导致整体性能下降。对于日语提示，尽管总体效果减弱，但特定领域如大学数学和抽象代数仍显示出改进潜力。研究强调了语言和模型进化的影响，为优化跨语言提示策略提供了见解。",
      "categories": [
        "cs.CL",
        "cs.AI"
      ],
      "primary_category": "cs.CL",
      "comment": "NLP2025 Workshop on Japanese Language Resources (JLR2025)",
      "pdf_url": "http://arxiv.org/pdf/2503.06765v1",
      "published_date": "2025-03-09 20:42:38 UTC",
      "updated_date": "2025-03-09 20:42:38 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-23T23:44:03.963555"
    },
    {
      "arxiv_id": "2503.06764v3",
      "title": "SemHiTok: A Unified Image Tokenizer via Semantic-Guided Hierarchical Codebook for Multimodal Understanding and Generation",
      "title_zh": "SemHiTok",
      "authors": [
        "Zisheng Chen",
        "Chunwei Wang",
        "Xiuwei Chen",
        "Hang Xu",
        "Jianhua Han",
        "Xiaodan Liang"
      ],
      "abstract": "We present SemHiTok, a unified image Tokenizer via Semantic-Guided\nHierarchical codebook that provides consistent discrete feature representations\nfor multimodal understanding and generation tasks. Recently, unified multimodal\nlarge models (MLLMs) for understanding and generation have sparked exploration\nwithin research community. Previous works attempt to train a unified image\ntokenizer by combining loss functions for semantic feature reconstruction and\npixel reconstruction. However, due to the differing levels of features\nprioritized by multimodal understanding and generation tasks, joint training\nmethods face significant challenges in achieving a good trade-off. SemHiTok\naddresses this challenge through Semantic-Guided Hierarchical codebook which\nbuilds texture sub-codebooks on pre-trained semantic codebook. This design\ndecouples the training of semantic reconstruction and pixel reconstruction and\nequips the tokenizer with low-level texture feature extraction capability\nwithout degradation of high-level semantic feature extraction ability. Our\nexperiments demonstrate that SemHiTok achieves excellent rFID score at\n256X256resolution compared to other unified tokenizers, and exhibits\ncompetitive performance on multimodal understanding and generation tasks.",
      "tldr_zh": "本研究提出了 SemHiTok，一种统一的图像 Tokenizer，通过 Semantic-Guided Hierarchical codebook 提供一致的离散特征表示，支持多模态理解和生成任务。不同于以往的联合训练方法，该框架在预训练的语义 codebook 上构建纹理子 codebook，从而解耦语义特征重建和像素重建训练，确保在提取低级纹理特征的同时不影响高级语义特征提取。实验结果显示，SemHiTok 在 256x256 分辨率下取得了优异的 rFID 分数，并与其他统一 Tokenizer 相比，在多模态理解和生成任务上表现出色。",
      "categories": [
        "cs.CV",
        "cs.AI"
      ],
      "primary_category": "cs.CV",
      "comment": "Under Review, Refer to the latest version",
      "pdf_url": "http://arxiv.org/pdf/2503.06764v3",
      "published_date": "2025-03-09 20:42:34 UTC",
      "updated_date": "2025-03-20 06:13:32 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-23T23:44:14.638337"
    },
    {
      "arxiv_id": "2503.06749v2",
      "title": "Vision-R1: Incentivizing Reasoning Capability in Multimodal Large Language Models",
      "title_zh": "Vision-R1: 激励多模态大型语言模型的推理能力",
      "authors": [
        "Wenxuan Huang",
        "Bohan Jia",
        "Zijie Zhai",
        "Shaosheng Cao",
        "Zheyu Ye",
        "Fei Zhao",
        "Zhe Xu",
        "Yao Hu",
        "Shaohui Lin"
      ],
      "abstract": "DeepSeek-R1-Zero has successfully demonstrated the emergence of reasoning\ncapabilities in LLMs purely through Reinforcement Learning (RL). Inspired by\nthis breakthrough, we explore how RL can be utilized to enhance the reasoning\ncapability of MLLMs. However, direct training with RL struggles to activate\ncomplex reasoning capabilities such as questioning and reflection in MLLMs, due\nto the absence of substantial high-quality multimodal reasoning data. To\naddress this issue, we propose the reasoning MLLM, Vision-R1, to improve\nmultimodal reasoning capability. Specifically, we first construct a\nhigh-quality multimodal CoT dataset without human annotations by leveraging an\nexisting MLLM and DeepSeek-R1 through modality bridging and data filtering to\nobtain a 200K multimodal CoT dataset, Vision-R1-cold dataset. It serves as\ncold-start initialization data for Vision-R1. To mitigate the optimization\nchallenges caused by overthinking after cold start, we propose Progressive\nThinking Suppression Training (PTST) strategy and employ Group Relative Policy\nOptimization (GRPO) with the hard formatting result reward function to\ngradually refine the model's ability to learn correct and complex reasoning\nprocesses on a 10K multimodal math dataset. Comprehensive experiments show our\nmodel achieves an average improvement of $\\sim$6% across various multimodal\nmath reasoning benchmarks. Vision-R1-7B achieves a 73.5% accuracy on the widely\nused MathVista benchmark, which is only 0.4% lower than the leading reasoning\nmodel, OpenAI O1. The datasets and code will be released in:\nhttps://github.com/Osilly/Vision-R1 .",
      "tldr_zh": "该研究受 DeepSeek-R1-Zero 启发，提出 Vision-R1 模型，利用强化学习 (RL) 来提升多模态大语言模型 (MLLMs) 的推理能力，以解决高质量多模态数据缺失的问题。\n具体方法包括构建一个 200K 条多模态 Chain-of-Thought (CoT) 数据集（Vision-R1-cold），通过模态桥接和数据过滤作为冷启动初始化；并引入 Progressive Thinking Suppression Training (PTST) 策略和 Group Relative Policy Optimization (GRPO) 在 10K 多模态数学数据集上逐步优化模型的推理过程。\n实验结果显示，Vision-R1-7B 在各种多模态数学推理基准上平均提升约 6%，在 MathVista 基准上达到 73.5% 准确率，仅比领先模型 OpenAI O1 低 0.4%。",
      "categories": [
        "cs.CV",
        "cs.AI",
        "cs.CL",
        "cs.LG"
      ],
      "primary_category": "cs.CV",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2503.06749v2",
      "published_date": "2025-03-09 20:06:45 UTC",
      "updated_date": "2025-03-11 09:47:44 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-23T23:44:28.830013"
    },
    {
      "arxiv_id": "2503.06747v1",
      "title": "Fully-Decentralized MADDPG with Networked Agents",
      "title_zh": "翻译失败",
      "authors": [
        "Diego Bolliger",
        "Lorenz Zauter",
        "Robert Ziegler"
      ],
      "abstract": "In this paper, we devise three actor-critic algorithms with decentralized\ntraining for multi-agent reinforcement learning in cooperative, adversarial,\nand mixed settings with continuous action spaces. To this goal, we adapt the\nMADDPG algorithm by applying a networked communication approach between agents.\nWe introduce surrogate policies in order to decentralize the training while\nallowing for local communication during training. The decentralized algorithms\nachieve comparable results to the original MADDPG in empirical tests, while\nreducing computational cost. This is more pronounced with larger numbers of\nagents.",
      "tldr_zh": "这篇论文设计了三种去中心化的 actor-critic 算法，用于多智能体 reinforcement learning 的合作、对抗和混合场景，针对连续动作空间。作者基于 MADDPG 算法，引入网络化通信方法和代理策略（surrogate policies），实现了训练过程的去中心化，同时允许本地通信以降低计算成本。实验结果表明，这些算法在经验测试中与原 MADDPG 性能相当，但在代理数量较大的情况下，计算开销显著减少。",
      "categories": [
        "cs.LG",
        "cs.AI",
        "cs.MA"
      ],
      "primary_category": "cs.LG",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2503.06747v1",
      "published_date": "2025-03-09 20:05:32 UTC",
      "updated_date": "2025-03-09 20:05:32 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-23T23:44:37.837652"
    },
    {
      "arxiv_id": "2503.06745v1",
      "title": "Beyond Black-Box Benchmarking: Observability, Analytics, and Optimization of Agentic Systems",
      "title_zh": "翻译失败",
      "authors": [
        "Dany Moshkovich",
        "Hadar Mulian",
        "Sergey Zeltyn",
        "Natti Eder",
        "Inna Skarbovsky",
        "Roy Abitbol"
      ],
      "abstract": "The rise of agentic AI systems, where agents collaborate to perform diverse\ntasks, poses new challenges with observing, analyzing and optimizing their\nbehavior. Traditional evaluation and benchmarking approaches struggle to handle\nthe non-deterministic, context-sensitive, and dynamic nature of these systems.\nThis paper explores key challenges and opportunities in analyzing and\noptimizing agentic systems across development, testing, and maintenance. We\nexplore critical issues such as natural language variability and unpredictable\nexecution flows, which hinder predictability and control, demanding adaptive\nstrategies to manage input variability and evolving behaviors. Through our user\nstudy, we supported these hypotheses. In particular, we showed a 79% agreement\nthat non deterministic flow of agentic systems acts as a major challenge.\nFinally, we validated our statements empirically advocating the need for moving\nbeyond classical benchmarking. To bridge these gaps, we introduce taxonomies to\npresent expected analytics outcomes and the ways to collect them by extending\nstandard observability frameworks. Building on these foundations, we introduce\nand demonstrate novel approach for benchmarking of agent evaluation systems.\nUnlike traditional \"black box\" performance evaluation approaches, our benchmark\nis built from agent runtime logs as input, and analytics outcome including\ndiscovered flows and issues. By addressing key limitations in existing\nmethodologies, we aim to set the stage for more advanced and holistic\nevaluation strategies, which could foster the development of adaptive,\ninterpretable, and robust agentic AI systems.",
      "tldr_zh": "这篇论文探讨了代理式 AI 系统（agentic systems）的观察、分析和优化面临的挑战，强调传统基准测试（benchmarking）方法无法处理其非确定性、上下文敏感性和动态特性，导致问题如自然语言变异性和不可预测执行流。作者通过用户研究证实了这些挑战的重要性，并显示79%的参与者同意非确定性流程是主要障碍；为此，他们引入了分类法（taxonomies）来定义分析结果，并扩展了标准可观察性框架（observability frameworks）。最终，该论文提出了一种新颖的基准方法，以代理运行时日志为输入，生成包括流程发现和问题的分析输出，从而推动更适应性、可解释和鲁棒的代理式 AI 系统的发展。",
      "categories": [
        "cs.AI",
        "cs.MA"
      ],
      "primary_category": "cs.AI",
      "comment": "14 pages, 19 figures",
      "pdf_url": "http://arxiv.org/pdf/2503.06745v1",
      "published_date": "2025-03-09 20:02:04 UTC",
      "updated_date": "2025-03-09 20:02:04 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-23T23:44:51.193899"
    },
    {
      "arxiv_id": "2503.10666v2",
      "title": "Green Prompting",
      "title_zh": "绿色提示",
      "authors": [
        "Marta Adamska",
        "Daria Smirnova",
        "Hamid Nasiri",
        "Zhengxin Yu",
        "Peter Garraghan"
      ],
      "abstract": "Large Language Models (LLMs) have become widely used across various domains\nspanning search engines, code generation, and text creation. However, a major\nconcern associated with their adoption is the high cost of inference, impacting\nboth their sustainability and financial feasibility. In this study, we\nempirically study how different prompt and response characteristics directly\nimpact LLM inference energy cost. We conduct experiments leveraging three\nopen-source transformer-based LLMs across three task types$-$question\nanswering, sentiment analysis, and text generation. For each inference, we\nanalyzed prompt and response characteristics (length, semantic meaning, time\ntaken, energy consumption). Our results demonstrate that even when presented\nwith identical tasks, models generate responses with varying characteristics\nand subsequently exhibit distinct energy consumption patterns. We found that\nprompt length is less significant than the semantic meaning of the task itself.\nIn addition, we identified specific keywords associated with higher or lower\nenergy usage that vary between associated tasks. These findings highlight the\nimportance of prompt design in optimizing inference efficiency. We conclude\nthat the semantic meaning of prompts and certain task-related keywords\nsignificantly impact inference costs, leading the way for deeper exploration\ntowards creating energy-adaptive LLMs.",
      "tldr_zh": "这篇论文探讨了大型语言模型 (LLMs) 在推理过程中的高能耗问题及其对可持续性和经济性的影响。研究者通过实验分析了三个开源 transformer-based LLMs 在问答、情感分析和文本生成任务上的提示和响应特征，包括长度、语义含义、时间和能耗。结果显示，任务的语义含义比提示长度更显著地影响能耗，且特定关键词会根据任务类型导致能耗差异。论文强调优化提示设计的重要性，并为开发能量自适应的 LLMs 提供了新方向。",
      "categories": [
        "cs.CL",
        "cs.AI",
        "cs.LG"
      ],
      "primary_category": "cs.CL",
      "comment": "9 pages, 5 figures",
      "pdf_url": "http://arxiv.org/pdf/2503.10666v2",
      "published_date": "2025-03-09 19:49:31 UTC",
      "updated_date": "2025-04-08 10:56:07 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-23T23:45:02.118715"
    },
    {
      "arxiv_id": "2503.06734v1",
      "title": "Gender Encoding Patterns in Pretrained Language Model Representations",
      "title_zh": "预训练语言模型表示中的性别编码模式",
      "authors": [
        "Mahdi Zakizadeh",
        "Mohammad Taher Pilehvar"
      ],
      "abstract": "Gender bias in pretrained language models (PLMs) poses significant social and\nethical challenges. Despite growing awareness, there is a lack of comprehensive\ninvestigation into how different models internally represent and propagate such\nbiases. This study adopts an information-theoretic approach to analyze how\ngender biases are encoded within various encoder-based architectures. We focus\non three key aspects: identifying how models encode gender information and\nbiases, examining the impact of bias mitigation techniques and fine-tuning on\nthe encoded biases and their effectiveness, and exploring how model design\ndifferences influence the encoding of biases. Through rigorous and systematic\ninvestigation, our findings reveal a consistent pattern of gender encoding\nacross diverse models. Surprisingly, debiasing techniques often exhibit limited\nefficacy, sometimes inadvertently increasing the encoded bias in internal\nrepresentations while reducing bias in model output distributions. This\nhighlights a disconnect between mitigating bias in output distributions and\naddressing its internal representations. This work provides valuable guidance\nfor advancing bias mitigation strategies and fostering the development of more\nequitable language models.",
      "tldr_zh": "这篇论文探讨了预训练语言模型 (PLMs) 中性别偏见的编码模式，通过信息理论方法分析不同编码器架构如何内部表示和传播这些偏见。研究重点包括模型对性别信息的编码、偏见缓解技术（如 debiasing）和 fine-tuning 对编码偏见的影响，以及模型设计差异的作用。结果显示，性别偏见在各种模型中表现出一致的编码模式，但 debiasing 技术往往效果有限，有时会增加内部表示中的偏见，而仅减少输出分布中的偏见。该工作揭示了输出偏见缓解与内部表示脱节的问题，并为开发更公平的语言模型提供重要指导。",
      "categories": [
        "cs.CL",
        "cs.AI"
      ],
      "primary_category": "cs.CL",
      "comment": "Proceedings of the 5th Workshop on Trustworthy Natural Language\n  Processing (TrustNLP 2025)",
      "pdf_url": "http://arxiv.org/pdf/2503.06734v1",
      "published_date": "2025-03-09 19:17:46 UTC",
      "updated_date": "2025-03-09 19:17:46 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-23T23:45:14.749794"
    },
    {
      "arxiv_id": "2503.06729v1",
      "title": "ACAI for SBOs: AI Co-creation for Advertising and Inspiration for Small Business Owners",
      "title_zh": "翻译失败",
      "authors": [
        "Nimisha Karnatak",
        "Adrien Baranes",
        "Rob Marchant",
        "Triona Butler",
        "Kristen Olson"
      ],
      "abstract": "Small business owners (SBOs) often lack the resources and design experience\nneeded to produce high-quality advertisements. To address this, we developed\nACAI (AI Co-Creation for Advertising and Inspiration), an GenAI-powered\nmultimodal advertisement creation tool, and conducted a user study with 16 SBOs\nin London to explore their perceptions of and interactions with ACAI in\nadvertisement creation. Our findings reveal that structured inputs enhance user\nagency and control while improving AI outputs by facilitating better brand\nalignment, enhancing AI transparency, and offering scaffolding that assists\nnovice designers, such as SBOs, in formulating prompts. We also found that\nACAI's multimodal interface bridges the design skill gap for SBOs with a clear\nadvertisement vision, but who lack the design jargon necessary for effective\nprompting. Building on our findings, we propose three capabilities: contextual\nintelligence, adaptive interactions, and data management, with corresponding\ndesign recommendations to advance the co-creative attributes of AI-mediated\ndesign tools.",
      "tldr_zh": "本研究针对小企业主（SBOs）在广告制作中资源和设计经验的不足，开发了ACAI——一个基于GenAI的多模态广告创建工具，并通过与伦敦16名SBOs的用户研究，探讨其互动和感知。研究发现，结构化输入提升了用户控制力、AI输出质量、品牌一致性以及透明度，并为初学者提供支持；同时，ACAI的多模态界面帮助SBOs克服设计技能差距，即使他们缺乏设计术语。基于这些发现，论文提出三项能力：contextual intelligence、adaptive interactions和data management，并给出相应的设计推荐，以推进AI辅助设计工具的协同创造属性。",
      "categories": [
        "cs.HC",
        "cs.AI",
        "cs.CY",
        "cs.ET"
      ],
      "primary_category": "cs.HC",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2503.06729v1",
      "published_date": "2025-03-09 19:00:36 UTC",
      "updated_date": "2025-03-09 19:00:36 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-23T23:45:26.557062"
    },
    {
      "arxiv_id": "2503.06725v1",
      "title": "Pull-Based Query Scheduling for Goal-Oriented Semantic Communication",
      "title_zh": "针对目标导向语义通信的拉取式",
      "authors": [
        "Pouya Agheli",
        "Nikolaos Pappas",
        "Marios Kountouris"
      ],
      "abstract": "This paper addresses query scheduling for goal-oriented semantic\ncommunication in pull-based status update systems. We consider a system where\nmultiple sensing agents (SAs) observe a source characterized by various\nattributes and provide updates to multiple actuation agents (AAs), which act\nupon the received information to fulfill their heterogeneous goals at the\nendpoint. A hub serves as an intermediary, querying the SAs for updates on\nobserved attributes and maintaining a knowledge base, which is then broadcast\nto the AAs. The AAs leverage the knowledge to perform their actions\neffectively. To quantify the semantic value of updates, we introduce a grade of\neffectiveness (GoE) metric. Furthermore, we integrate cumulative perspective\ntheory (CPT) into the long-term effectiveness analysis to account for risk\nawareness and loss aversion in the system. Leveraging this framework, we\ncompute effect-aware scheduling policies aimed at maximizing the expected\ndiscounted sum of CPT-based total GoE provided by the transmitted updates while\ncomplying with a given query cost constraint. To achieve this, we propose a\nmodel-based solution based on dynamic programming and model-free solutions\nemploying state-of-the-art deep reinforcement learning (DRL) algorithms. Our\nfindings demonstrate that effect-aware scheduling significantly enhances the\neffectiveness of communicated updates compared to benchmark scheduling methods,\nparticularly in settings with stringent cost constraints where optimal query\nscheduling is vital for system performance and overall effectiveness.",
      "tldr_zh": "这篇论文针对基于拉取的查询调度问题，提出了一种适用于目标导向语义通信的系统，其中多个感知代理(SAs)观察源属性并提供更新给执行代理(AAs)，以实现异构目标，而中心(hub)作为中介维护知识库。论文引入了有效性等级(GoE)指标并整合累积前景理论(CPT)，以量化更新语义价值并考虑风险意识和损失厌恶。作者开发了基于动态规划的模型方法和基于深度强化学习(DRL)的无模型方法，来优化调度策略，最大化预期的折扣和CPT-based总GoE，同时遵守查询成本约束；结果显示，这种效果感知调度显著提升了通信更新的有效性，尤其在严格成本约束环境下，优于基准方法。",
      "categories": [
        "cs.IT",
        "cs.AI",
        "cs.NI",
        "math.IT"
      ],
      "primary_category": "cs.IT",
      "comment": "Submitted for possible publication",
      "pdf_url": "http://arxiv.org/pdf/2503.06725v1",
      "published_date": "2025-03-09 18:51:14 UTC",
      "updated_date": "2025-03-09 18:51:14 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-23T23:45:39.052028"
    },
    {
      "arxiv_id": "2503.06709v1",
      "title": "Delusions of Large Language Models",
      "title_zh": "翻译失败",
      "authors": [
        "Hongshen Xu",
        "Zixv yang",
        "Zichen Zhu",
        "Kunyao Lan",
        "Zihan Wang",
        "Mengyue Wu",
        "Ziwei Ji",
        "Lu Chen",
        "Pascale Fung",
        "Kai Yu"
      ],
      "abstract": "Large Language Models often generate factually incorrect but plausible\noutputs, known as hallucinations. We identify a more insidious phenomenon, LLM\ndelusion, defined as high belief hallucinations, incorrect outputs with\nabnormally high confidence, making them harder to detect and mitigate. Unlike\nordinary hallucinations, delusions persist with low uncertainty, posing\nsignificant challenges to model reliability. Through empirical analysis across\ndifferent model families and sizes on several Question Answering tasks, we show\nthat delusions are prevalent and distinct from hallucinations. LLMs exhibit\nlower honesty with delusions, which are harder to override via finetuning or\nself reflection. We link delusion formation with training dynamics and dataset\nnoise and explore mitigation strategies such as retrieval augmented generation\nand multi agent debating to mitigate delusions. By systematically investigating\nthe nature, prevalence, and mitigation of LLM delusions, our study provides\ninsights into the underlying causes of this phenomenon and outlines future\ndirections for improving model reliability.",
      "tldr_zh": "这篇论文探讨了大型语言模型（LLMs）中的妄想（delusions）现象，即模型生成事实错误但自信度异常高的输出，这比普通幻觉（hallucinations）更难检测和缓解。研究通过实证分析在不同模型系列和大小上的问答任务，发现妄想普遍存在，与幻觉不同，且难以通过微调或自我反思来纠正。论文将妄想归因于训练动态和数据集噪声，并探索缓解策略，如检索增强生成（RAG）和多智能体辩论。总体上，该研究为提升LLMs的可靠性和诚实性提供了关键见解和未来方向。",
      "categories": [
        "cs.CL",
        "cs.AI"
      ],
      "primary_category": "cs.CL",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2503.06709v1",
      "published_date": "2025-03-09 17:59:16 UTC",
      "updated_date": "2025-03-09 17:59:16 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-23T23:45:51.330012"
    },
    {
      "arxiv_id": "2503.07671v3",
      "title": "Probabilistic Shielding for Safe Reinforcement Learning",
      "title_zh": "概率屏蔽用于安全的强化学习",
      "authors": [
        "Edwin Hamel-De le Court",
        "Francesco Belardinelli",
        "Alexander W. Goodall"
      ],
      "abstract": "In real-life scenarios, a Reinforcement Learning (RL) agent aiming to\nmaximise their reward, must often also behave in a safe manner, including at\ntraining time. Thus, much attention in recent years has been given to Safe RL,\nwhere an agent aims to learn an optimal policy among all policies that satisfy\na given safety constraint. However, strict safety guarantees are often provided\nthrough approaches based on linear programming, and thus have limited scaling.\nIn this paper we present a new, scalable method, which enjoys strict formal\nguarantees for Safe RL, in the case where the safety dynamics of the Markov\nDecision Process (MDP) are known, and safety is defined as an undiscounted\nprobabilistic avoidance property. Our approach is based on state-augmentation\nof the MDP, and on the design of a shield that restricts the actions available\nto the agent. We show that our approach provides a strict formal safety\nguarantee that the agent stays safe at training and test time. Furthermore, we\ndemonstrate that our approach is viable in practice through experimental\nevaluation.",
      "tldr_zh": "本文针对强化学习（Reinforcement Learning, RL）中代理需在最大化奖励的同时满足安全约束的问题，提出了一种可扩展的 Probabilistic Shielding 方法。该方法假设 Markov Decision Process (MDP) 的安全动态已知，并通过状态增强（state-augmentation）和设计 shield 来限制代理可用动作，从而确保安全定义为无折扣概率避免属性的严格形式化保证。实验评估证明，该方法在训练和测试阶段均能保持代理安全，同时提升了实际可行性。",
      "categories": [
        "stat.ML",
        "cs.AI",
        "cs.LG"
      ],
      "primary_category": "stat.ML",
      "comment": "13 pages, 3 figures, Conference: AAAI 2025",
      "pdf_url": "http://arxiv.org/pdf/2503.07671v3",
      "published_date": "2025-03-09 17:54:33 UTC",
      "updated_date": "2025-03-25 11:31:43 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-23T23:46:03.592548"
    },
    {
      "arxiv_id": "2503.06706v1",
      "title": "PFDial: A Structured Dialogue Instruction Fine-tuning Method Based on UML Flowcharts",
      "title_zh": "翻译失败",
      "authors": [
        "Ming Zhang",
        "Yuhui Wang",
        "Yujiong Shen",
        "Tingyi Yang",
        "Changhao Jiang",
        "Yilong Wu",
        "Shihan Dou",
        "Qinhao Chen",
        "Zhiheng Xi",
        "Zhihao Zhang",
        "Yi Dong",
        "Zhen Wang",
        "Zhihui Fei",
        "Mingyang Wan",
        "Tao Liang",
        "Guojun Ma",
        "Qi Zhang",
        "Tao Gui",
        "Xuanjing Huang"
      ],
      "abstract": "Process-driven dialogue systems, which operate under strict predefined\nprocess constraints, are essential in customer service and equipment\nmaintenance scenarios. Although Large Language Models (LLMs) have shown\nremarkable progress in dialogue and reasoning, they still struggle to solve\nthese strictly constrained dialogue tasks. To address this challenge, we\nconstruct Process Flow Dialogue (PFDial) dataset, which contains 12,705\nhigh-quality Chinese dialogue instructions derived from 440 flowcharts\ncontaining 5,055 process nodes. Based on PlantUML specification, each UML\nflowchart is converted into atomic dialogue units i.e., structured five-tuples.\nExperimental results demonstrate that a 7B model trained with merely 800\nsamples, and a 0.5B model trained on total data both can surpass 90% accuracy.\nAdditionally, the 8B model can surpass GPT-4o up to 43.88% with an average of\n11.00%. We further evaluate models' performance on challenging backward\ntransitions in process flows and conduct an in-depth analysis of various\ndataset formats to reveal their impact on model performance in handling\ndecision and sequential branches. The data is released in\nhttps://github.com/KongLongGeFDU/PFDial.",
      "tldr_zh": "该研究提出PFDial，一种基于UML Flowcharts的结构化对话指令细化方法，旨在解决Large Language Models (LLMs)在严格约束对话任务（如客服和设备维护）中的挑战。研究构建了PFDial数据集，包含12,705个高质量中文对话指令，这些指令来源于440个流程图和5,055个过程节点，并使用PlantUML规范转换为结构化的五元组对话单位。实验结果显示，7B模型仅用800个样本训练即可达到超过90%的准确率，而0.5B模型和8B模型分别在全数据集上表现突出，后者平均比GPT-4o高出11.00%，在某些任务上高出43.88%。此外，研究评估了模型在流程逆向转换和决策/顺序分支处理中的性能，并开源了数据集以促进进一步研究。",
      "categories": [
        "cs.CL",
        "cs.AI",
        "cs.LG"
      ],
      "primary_category": "cs.CL",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2503.06706v1",
      "published_date": "2025-03-09 17:43:30 UTC",
      "updated_date": "2025-03-09 17:43:30 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-23T23:46:16.439165"
    },
    {
      "arxiv_id": "2503.06692v2",
      "title": "InftyThink: Breaking the Length Limits of Long-Context Reasoning in Large Language Models",
      "title_zh": "InftyThink：打破大语言模型中长上下文推理的长度限制",
      "authors": [
        "Yuchen Yan",
        "Yongliang Shen",
        "Yang Liu",
        "Jin Jiang",
        "Mengdi Zhang",
        "Jian Shao",
        "Yueting Zhuang"
      ],
      "abstract": "Advanced reasoning in large language models has achieved remarkable\nperformance on challenging tasks, but the prevailing long-context reasoning\nparadigm faces critical limitations: quadratic computational scaling with\nsequence length, reasoning constrained by maximum context boundaries, and\nperformance degradation beyond pre-training context windows. Existing\napproaches primarily compress reasoning chains without addressing the\nfundamental scaling problem. To overcome these challenges, we introduce\nInftyThink, a paradigm that transforms monolithic reasoning into an iterative\nprocess with intermediate summarization. By interleaving short reasoning\nsegments with concise progress summaries, our approach enables unbounded\nreasoning depth while maintaining bounded computational costs. This creates a\ncharacteristic sawtooth memory pattern that significantly reduces computational\ncomplexity compared to traditional approaches. Furthermore, we develop a\nmethodology for reconstructing long-context reasoning datasets into our\niterative format, transforming OpenR1-Math into 333K training instances.\nExperiments across multiple model architectures demonstrate that our approach\nreduces computational costs while improving performance, with Qwen2.5-Math-7B\nshowing 3-13% improvements across MATH500, AIME24, and GPQA_diamond benchmarks.\nOur work challenges the assumed trade-off between reasoning depth and\ncomputational efficiency, providing a more scalable approach to complex\nreasoning without architectural modifications.",
      "tldr_zh": "该研究针对大型语言模型的长上下文推理问题，提出 InftyThink 范式，以解决计算复杂度二次方增长、受限于最大上下文边界以及性能下降等挑战。该方法将单块推理转化为迭代过程，通过交替短推理段和中间总结，实现无界限推理深度，同时保持计算成本有限，并形成锯齿状记忆模式以减少复杂度。为支持这一范式，研究者将 OpenR1-Math 数据集转化为 33.3K 迭代训练实例。实验结果显示，在多种模型架构上，InftyThink 显著降低计算开销，并提升性能，例如 Qwen2.5-Math-7B 在 MATH500、AIME24 和 GPQA_diamond 基准上获得 3-13% 的改进。该方法挑战了推理深度与计算效率的权衡，提供一种无需修改架构的可扩展解决方案。",
      "categories": [
        "cs.CL",
        "cs.AI"
      ],
      "primary_category": "cs.CL",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2503.06692v2",
      "published_date": "2025-03-09 16:59:14 UTC",
      "updated_date": "2025-03-13 16:00:47 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-23T23:46:27.841421"
    },
    {
      "arxiv_id": "2503.06690v1",
      "title": "Censoring-Aware Tree-Based Reinforcement Learning for Estimating Dynamic Treatment Regimes with Censored Outcomes",
      "title_zh": "翻译失败",
      "authors": [
        "Animesh Kumar Paul",
        "Russell Greiner"
      ],
      "abstract": "Dynamic Treatment Regimes (DTRs) provide a systematic approach for making\nsequential treatment decisions that adapt to individual patient\ncharacteristics, particularly in clinical contexts where survival outcomes are\nof interest. Censoring-Aware Tree-Based Reinforcement Learning (CA-TRL) is a\nnovel framework to address the complexities associated with censored data when\nestimating optimal DTRs. We explore ways to learn effective DTRs, from\nobservational data. By enhancing traditional tree-based reinforcement learning\nmethods with augmented inverse probability weighting (AIPW) and censoring-aware\nmodifications, CA-TRL delivers robust and interpretable treatment strategies.\nWe demonstrate its effectiveness through extensive simulations and real-world\napplications using the SANAD epilepsy dataset, where it outperformed the\nrecently proposed ASCL method in key metrics such as restricted mean survival\ntime (RMST) and decision-making accuracy. This work represents a step forward\nin advancing personalized and data-driven treatment strategies across diverse\nhealthcare settings.",
      "tldr_zh": "本文提出了一种新框架 Censoring-Aware Tree-Based Reinforcement Learning (CA-TRL)，用于估计带 censoring 结果的动态治疗方案 (DTRs)，以帮助临床决策适应个体患者特征。CA-TRL 通过增强逆概率加权 (AIPW) 和针对 censoring 的修改，改进传统树-based 强化学习方法，从观察数据中学习鲁棒且可解释的治疗策略。在模拟实验和 SANAD 癫痫数据集的实际应用中，CA-TRL 优于 ASCL 方法，在受限平均生存时间 (RMST) 和决策准确性等方面表现出显著优势。该框架推动了医疗领域的个性化、数据驱动治疗策略的发展。",
      "categories": [
        "cs.LG",
        "cs.AI",
        "stat.ME"
      ],
      "primary_category": "cs.LG",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2503.06690v1",
      "published_date": "2025-03-09 16:53:09 UTC",
      "updated_date": "2025-03-09 16:53:09 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-23T23:46:40.396516"
    },
    {
      "arxiv_id": "2503.06687v1",
      "title": "UniGenX: Unified Generation of Sequence and Structure with Autoregressive Diffusion",
      "title_zh": "UniGenX：利用自回归扩散的序列和结构统一生成",
      "authors": [
        "Gongbo Zhang",
        "Yanting Li",
        "Renqian Luo",
        "Pipi Hu",
        "Zeru Zhao",
        "Lingbo Li",
        "Guoqing Liu",
        "Zun Wang",
        "Ran Bi",
        "Kaiyuan Gao",
        "Liya Guo",
        "Yu Xie",
        "Chang Liu",
        "Jia Zhang",
        "Tian Xie",
        "Robert Pinsler",
        "Claudio Zeni",
        "Ziheng Lu",
        "Yingce Xia",
        "Marwin Segler",
        "Maik Riechert",
        "Li Yuan",
        "Lei Chen",
        "Haiguang Liu",
        "Tao Qin"
      ],
      "abstract": "Unified generation of sequence and structure for scientific data (e.g.,\nmaterials, molecules, proteins) is a critical task. Existing approaches\nprimarily rely on either autoregressive sequence models or diffusion models,\neach offering distinct advantages and facing notable limitations.\nAutoregressive models, such as GPT, Llama, and Phi-4, have demonstrated\nremarkable success in natural language generation and have been extended to\nmultimodal tasks (e.g., image, video, and audio) using advanced encoders like\nVQ-VAE to represent complex modalities as discrete sequences. However, their\ndirect application to scientific domains is challenging due to the high\nprecision requirements and the diverse nature of scientific data. On the other\nhand, diffusion models excel at generating high-dimensional scientific data,\nsuch as protein, molecule, and material structures, with remarkable accuracy.\nYet, their inability to effectively model sequences limits their potential as\ngeneral-purpose multimodal foundation models. To address these challenges, we\npropose UniGenX, a unified framework that combines autoregressive next-token\nprediction with conditional diffusion models. This integration leverages the\nstrengths of autoregressive models to ease the training of conditional\ndiffusion models, while diffusion-based generative heads enhance the precision\nof autoregressive predictions. We validate the effectiveness of UniGenX on\nmaterial and small molecule generation tasks, achieving a significant leap in\nstate-of-the-art performance for material crystal structure prediction and\nestablishing new state-of-the-art results for small molecule structure\nprediction, de novo design, and conditional generation. Notably, UniGenX\ndemonstrates significant improvements, especially in handling long sequences\nfor complex structures, showcasing its efficacy as a versatile tool for\nscientific data generation.",
      "tldr_zh": "本研究提出 UniGenX，一种统一框架，将 autoregressive next-token prediction 与 conditional diffusion models 相结合，用于生成科学数据（如材料、分子和蛋白）的序列和结构，从而克服 autoregressive models 在精度要求高领域的局限性，以及 diffusion models 在序列建模上的不足。UniGenX 通过整合二者的优势，简化 conditional diffusion models 的训练并提升 autoregressive 预测的精确性，在材料和小分子生成任务中实现了重大突破，包括材料晶体结构预测的新最先进性能，以及小分子结构预测、从头设计和条件生成的新基准。实验结果显示，该框架在处理长序列和复杂结构时表现出显著改进，证明了其作为多功能科学数据生成工具的有效性。",
      "categories": [
        "cs.LG",
        "cond-mat.mtrl-sci",
        "cs.AI",
        "physics.bio-ph",
        "physics.chem-ph"
      ],
      "primary_category": "cs.LG",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2503.06687v1",
      "published_date": "2025-03-09 16:43:07 UTC",
      "updated_date": "2025-03-09 16:43:07 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-23T23:46:52.730788"
    },
    {
      "arxiv_id": "2503.10665v1",
      "title": "Small Vision-Language Models: A Survey on Compact Architectures and Techniques",
      "title_zh": "翻译失败",
      "authors": [
        "Nitesh Patnaik",
        "Navdeep Nayak",
        "Himani Bansal Agrawal",
        "Moinak Chinmoy Khamaru",
        "Gourav Bal",
        "Saishree Smaranika Panda",
        "Rishi Raj",
        "Vishal Meena",
        "Kartheek Vadlamani"
      ],
      "abstract": "The emergence of small vision-language models (sVLMs) marks a critical\nadvancement in multimodal AI, enabling efficient processing of visual and\ntextual data in resource-constrained environments. This survey offers a\ncomprehensive exploration of sVLM development, presenting a taxonomy of\narchitectures - transformer-based, mamba-based, and hybrid - that highlight\ninnovations in compact design and computational efficiency. Techniques such as\nknowledge distillation, lightweight attention mechanisms, and modality\npre-fusion are discussed as enablers of high performance with reduced resource\nrequirements. Through an in-depth analysis of models like TinyGPT-V, MiniGPT-4,\nand VL-Mamba, we identify trade-offs between accuracy, efficiency, and\nscalability. Persistent challenges, including data biases and generalization to\ncomplex tasks, are critically examined, with proposed pathways for addressing\nthem. By consolidating advancements in sVLMs, this work underscores their\ntransformative potential for accessible AI, setting a foundation for future\nresearch into efficient multimodal systems.",
      "tldr_zh": "这篇调查论文综述了小视觉语言模型(sVLMs)的最新进展，聚焦于紧凑架构和高效技术，以支持资源受限环境下的多模态AI处理。论文提出了sVLMs架构的分类，包括transformer-based、mamba-based和混合架构，突显了这些设计在计算效率方面的创新。关键技术如知识蒸馏(knowledge distillation)、轻量级注意力机制(lightweight attention mechanisms)和模态预融合(modality pre-fusion)被讨论，作为实现高性能和资源优化的关键手段。通过分析TinyGPT-V、MiniGPT-4和VL-Mamba等模型，该研究揭示了准确性、效率和可扩展性之间的权衡，并探讨了数据偏差和复杂任务泛化等挑战的潜在解决方案。该工作强调了sVLMs在可访问AI中的变革潜力，为高效多模态系统的未来研究奠定基础。",
      "categories": [
        "cs.CV",
        "cs.AI",
        "cs.CL",
        "cs.LG"
      ],
      "primary_category": "cs.CV",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2503.10665v1",
      "published_date": "2025-03-09 16:14:46 UTC",
      "updated_date": "2025-03-09 16:14:46 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-23T23:47:04.982405"
    },
    {
      "arxiv_id": "2503.06664v1",
      "title": "Exploring LLM Agents for Cleaning Tabular Machine Learning Datasets",
      "title_zh": "翻译失败",
      "authors": [
        "Tommaso Bendinelli",
        "Artur Dox",
        "Christian Holz"
      ],
      "abstract": "High-quality, error-free datasets are a key ingredient in building reliable,\naccurate, and unbiased machine learning (ML) models. However, real world\ndatasets often suffer from errors due to sensor malfunctions, data entry\nmistakes, or improper data integration across multiple sources that can\nseverely degrade model performance. Detecting and correcting these issues\ntypically require tailor-made solutions and demand extensive domain expertise.\nConsequently, automation is challenging, rendering the process labor-intensive\nand tedious. In this study, we investigate whether Large Language Models (LLMs)\ncan help alleviate the burden of manual data cleaning. We set up an experiment\nin which an LLM, paired with Python, is tasked with cleaning the training\ndataset to improve the performance of a learning algorithm without having the\nability to modify the training pipeline or perform any feature engineering. We\nrun this experiment on multiple Kaggle datasets that have been intentionally\ncorrupted with errors. Our results show that LLMs can identify and correct\nerroneous entries, such as illogical values or outlier, by leveraging\ncontextual information from other features within the same row, as well as\nfeedback from previous iterations. However, they struggle to detect more\ncomplex errors that require understanding data distribution across multiple\nrows, such as trends and biases.",
      "tldr_zh": "这篇论文探讨了使用Large Language Models (LLMs)代理来自动清洗表格机器学习数据集，以解决数据错误（如传感器故障或输入失误）对模型性能的影响。研究方法包括将LLM与Python结合，在故意损坏的Kaggle数据集上进行实验，让LLM识别并修正错误（如不合逻辑值或异常值），同时利用行内上下文和迭代反馈，而不修改训练管道或进行特征工程。结果表明，LLMs在处理简单错误方面表现出色，但对复杂错误（如跨多行数据分布的趋势和偏差）识别能力有限，为未来数据清洗自动化提供了宝贵见解。",
      "categories": [
        "cs.LG",
        "cs.AI"
      ],
      "primary_category": "cs.LG",
      "comment": "14 pages, 1 main figure, 3 plots, Published at ICLR 2025 Workshop on\n  Foundation Models in the Wild",
      "pdf_url": "http://arxiv.org/pdf/2503.06664v1",
      "published_date": "2025-03-09 15:29:46 UTC",
      "updated_date": "2025-03-09 15:29:46 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-23T23:47:15.171136"
    },
    {
      "arxiv_id": "2503.06661v1",
      "title": "AA-CLIP: Enhancing Zero-shot Anomaly Detection via Anomaly-Aware CLIP",
      "title_zh": "翻译失败",
      "authors": [
        "Wenxin Ma",
        "Xu Zhang",
        "Qingsong Yao",
        "Fenghe Tang",
        "Chenxu Wu",
        "Yingtai Li",
        "Rui Yan",
        "Zihang Jiang",
        "S. Kevin Zhou"
      ],
      "abstract": "Anomaly detection (AD) identifies outliers for applications like defect and\nlesion detection. While CLIP shows promise for zero-shot AD tasks due to its\nstrong generalization capabilities, its inherent Anomaly-Unawareness leads to\nlimited discrimination between normal and abnormal features. To address this\nproblem, we propose Anomaly-Aware CLIP (AA-CLIP), which enhances CLIP's anomaly\ndiscrimination ability in both text and visual spaces while preserving its\ngeneralization capability. AA-CLIP is achieved through a straightforward yet\neffective two-stage approach: it first creates anomaly-aware text anchors to\ndifferentiate normal and abnormal semantics clearly, then aligns patch-level\nvisual features with these anchors for precise anomaly localization. This\ntwo-stage strategy, with the help of residual adapters, gradually adapts CLIP\nin a controlled manner, achieving effective AD while maintaining CLIP's class\nknowledge. Extensive experiments validate AA-CLIP as a resource-efficient\nsolution for zero-shot AD tasks, achieving state-of-the-art results in\nindustrial and medical applications. The code is available at\nhttps://github.com/Mwxinnn/AA-CLIP.",
      "tldr_zh": "本论文提出 AA-CLIP 方法，以提升 CLIP 在 zero-shot Anomaly Detection 中的性能，通过增强其对异常的感知能力，同时保留 CLIP 的泛化优势。\nAA-CLIP 采用两阶段策略：首先创建 anomaly-aware text anchors 来清晰区分正常和异常语义，然后使用 residual adapters 将 patch-level 视觉特征与这些 anchors 对齐，实现精确的异常定位。\n实验验证显示，该方法在工业和医疗应用中达到了 state-of-the-art 结果，并作为一种资源高效的零样本检测解决方案。",
      "categories": [
        "cs.CV",
        "cs.AI"
      ],
      "primary_category": "cs.CV",
      "comment": "8 pages, 7 figures",
      "pdf_url": "http://arxiv.org/pdf/2503.06661v1",
      "published_date": "2025-03-09 15:22:52 UTC",
      "updated_date": "2025-03-09 15:22:52 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-23T23:47:28.373516"
    },
    {
      "arxiv_id": "2503.06648v1",
      "title": "Enhancing NLP Robustness and Generalization through LLM-Generated Contrast Sets: A Scalable Framework for Systematic Evaluation and Adversarial Training",
      "title_zh": "翻译失败",
      "authors": [
        "Hender Lin"
      ],
      "abstract": "Standard NLP benchmarks often fail to capture vulnerabilities stemming from\ndataset artifacts and spurious correlations. Contrast sets address this gap by\nchallenging models near decision boundaries but are traditionally\nlabor-intensive to create and limited in diversity. This study leverages large\nlanguage models to automate the generation of diverse contrast sets. Using the\nSNLI dataset, we created a 3,000-example contrast set to evaluate and improve\nmodel robustness. Fine-tuning on these contrast sets enhanced performance on\nsystematically perturbed examples, maintained standard test accuracy, and\nmodestly improved generalization to novel perturbations. This automated\napproach offers a scalable solution for evaluating and improving NLP models,\naddressing systematic generalization challenges, and advancing robustness in\nreal-world applications.",
      "tldr_zh": "本研究提出了一种利用大型语言模型（LLM）自动生成对比集（Contrast Sets）的可扩展框架，以提升NLP模型的鲁棒性和泛化能力，解决标准基准中数据集人工制品和虚假相关性带来的漏洞。使用SNLI数据集，他们生成了3,000个示例对比集，用于系统评估和对抗训练，结果显示微调后的模型在系统扰动示例上性能显著提升，同时保持了标准测试准确率，并对新扰动实现了适度改善。该框架为NLP模型的鲁棒性评估和训练提供了一个高效、可扩展的解决方案，适用于真实世界应用中的系统泛化挑战。",
      "categories": [
        "cs.CL",
        "cs.AI",
        "cs.LG"
      ],
      "primary_category": "cs.CL",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2503.06648v1",
      "published_date": "2025-03-09 14:52:53 UTC",
      "updated_date": "2025-03-09 14:52:53 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-23T23:47:40.190456"
    },
    {
      "arxiv_id": "2503.06635v3",
      "title": "Deep Cut-informed Graph Embedding and Clustering",
      "title_zh": "翻译失败",
      "authors": [
        "Zhiyuan Ning",
        "Zaitian Wang",
        "Ran Zhang",
        "Ping Xu",
        "Kunpeng Liu",
        "Pengyang Wang",
        "Wei Ju",
        "Pengfei Wang",
        "Yuanchun Zhou",
        "Erik Cambria",
        "Chong Chen"
      ],
      "abstract": "Graph clustering aims to divide the graph into different clusters. The\nrecently emerging deep graph clustering approaches are largely built on graph\nneural networks (GNN). However, GNN is designed for general graph encoding and\nthere is a common issue of representation collapse in existing GNN-based deep\ngraph clustering algorithms. We attribute two main reasons for such issues: (i)\nthe inductive bias of GNN models: GNNs tend to generate similar representations\nfor proximal nodes. Since graphs often contain a non-negligible amount of\ninter-cluster links, the bias results in error message passing and leads to\nbiased clustering; (ii) the clustering guided loss function: most traditional\napproaches strive to make all samples closer to pre-learned cluster centers,\nwhich causes a degenerate solution assigning all data points to a single label\nthus making all samples similar and less discriminative. To address these\nchallenges, we investigate graph clustering from a graph cut perspective and\npropose an innovative and non-GNN-based Deep Cut-informed Graph embedding and\nClustering framework, namely DCGC. This framework includes two modules: (i)\ncut-informed graph encoding; (ii) self-supervised graph clustering via optimal\ntransport. For the encoding module, we derive a cut-informed graph embedding\nobjective to fuse graph structure and attributes by minimizing their joint\nnormalized cut. For the clustering module, we utilize the optimal transport\ntheory to obtain the clustering assignments, which can balance the guidance of\n\"proximity to the pre-learned cluster center\". With the above two tailored\ndesigns, DCGC is more suitable for the graph clustering task, which can\neffectively alleviate the problem of representation collapse and achieve better\nperformance. We conduct extensive experiments to demonstrate that our method is\nsimple but effective compared with benchmarks.",
      "tldr_zh": "本研究针对图聚类任务中现有的 GNN-based 深度方法存在的表示崩溃问题（如 GNN 的归纳偏差和聚类损失函数导致的偏差），提出了一种创新的非 GNN-based 框架 DCGC。DCGC 包括两个模块：cut-informed graph encoding，通过最小化 joint normalized cut 来融合图结构和属性；以及 self-supervised graph clustering via optimal transport，利用最优传输理论平衡聚类分配，避免样本趋同。实验结果显示，DCGC 在广泛基准测试中有效缓解了表示崩溃问题，并显著提升了聚类性能。",
      "categories": [
        "cs.LG",
        "cs.AI"
      ],
      "primary_category": "cs.LG",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2503.06635v3",
      "published_date": "2025-03-09 14:24:09 UTC",
      "updated_date": "2025-04-25 00:15:04 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-23T23:47:51.770120"
    },
    {
      "arxiv_id": "2503.08705v1",
      "title": "A Block-Based Heuristic Algorithm for the Three-Dimensional Nuclear Waste Packing Problem",
      "title_zh": "翻译失败",
      "authors": [
        "Yajie Wen",
        "Defu Zhang"
      ],
      "abstract": "In this study, we present a block-based heuristic search algorithm to address\nthe nuclear waste container packing problem in the context of real-world\nnuclear power plants. Additionally, we provide a dataset comprising 1600\nproblem instances for future researchers to use. Experimental results on this\ndataset demonstrate that the proposed algorithm effectively enhances the\ndisposal pool's space utilization while minimizing the radiation dose within\nthe pool. The code and data employed in this study are publicly available to\nfacilitate reproducibility and further investigation.",
      "tldr_zh": "本研究提出了一种基于块的启发式算法（block-based heuristic algorithm），用于解决三维核废物装箱问题（Three-Dimensional Nuclear Waste Packing Problem），针对真实核电站场景。该算法结合了启发式搜索方法，能够有效提高处置池的空间利用率，同时最小化池内的辐射剂量。研究者还提供了一个包含1600个问题实例的数据集，以支持未来研究；相关代码和数据已公开，以促进可重复性和进一步探索。",
      "categories": [
        "math.OC",
        "cs.AI"
      ],
      "primary_category": "math.OC",
      "comment": "10 pages,7 figures",
      "pdf_url": "http://arxiv.org/pdf/2503.08705v1",
      "published_date": "2025-03-09 14:20:48 UTC",
      "updated_date": "2025-03-09 14:20:48 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-23T23:48:03.145834"
    },
    {
      "arxiv_id": "2503.06633v1",
      "title": "BTFL: A Bayesian-based Test-Time Generalization Method for Internal and External Data Distributions in Federated learning",
      "title_zh": "翻译失败",
      "authors": [
        "Yu Zhou",
        "Bingyan Liu"
      ],
      "abstract": "Federated Learning (FL) enables multiple clients to collaboratively develop a\nglobal model while maintaining data privacy. However, online FL deployment\nfaces challenges due to distribution shifts and evolving test samples.\nPersonalized Federated Learning (PFL) tailors the global model to individual\nclient distributions, but struggles with Out-Of-Distribution (OOD) samples\nduring testing, leading to performance degradation. In real-world scenarios,\nbalancing personalization and generalization during online testing is crucial\nand existing methods primarily focus on training-phase generalization. To\naddress the test-time trade-off, we introduce a new scenario: Test-time\nGeneralization for Internal and External Distributions in Federated Learning\n(TGFL), which evaluates adaptability under Internal Distribution (IND) and\nExternal Distribution (EXD). We propose BTFL, a Bayesian-based test-time\ngeneralization method for TGFL, which balances generalization and\npersonalization at the sample level during testing. BTFL employs a two-head\narchitecture to store local and global knowledge, interpolating predictions via\na dual-Bayesian framework that considers both historical test data and current\nsample characteristics with theoretical guarantee and faster speed. Our\nexperiments demonstrate that BTFL achieves improved performance across various\ndatasets and models with less time cost. The source codes are made publicly\navailable at https://github.com/ZhouYuCS/BTFL .",
      "tldr_zh": "该论文针对 Federated Learning (FL) 在在线部署中面临的分布偏移和测试样本演变问题，引入了 Test-time Generalization for Internal and External Distributions in Federated Learning (TGFL) 场景，以评估模型在 Internal Distribution (IND) 和 External Distribution (EXD) 下的适应性。作者提出 BTFL，一种基于 Bayesian 的测试时泛化方法，该方法采用双头架构存储本地和全局知识，并通过双 Bayesian 框架在样本级别平衡泛化和个性化预测，同时提供理论保证和更快计算速度。实验结果表明，BTFL 在多种数据集和模型上显著提升了性能，同时降低了时间成本，并公开了源代码以供进一步验证。",
      "categories": [
        "cs.LG",
        "cs.AI"
      ],
      "primary_category": "cs.LG",
      "comment": "accepted as KDD 2025 research track paper",
      "pdf_url": "http://arxiv.org/pdf/2503.06633v1",
      "published_date": "2025-03-09 14:16:34 UTC",
      "updated_date": "2025-03-09 14:16:34 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-23T23:48:16.560203"
    },
    {
      "arxiv_id": "2503.06629v1",
      "title": "Hardware-Accelerated Event-Graph Neural Networks for Low-Latency Time-Series Classification on SoC FPGA",
      "title_zh": "翻译失败",
      "authors": [
        "Hiroshi Nakano",
        "Krzysztof Blachut",
        "Kamil Jeziorek",
        "Piotr Wzorek",
        "Manon Dampfhoffer",
        "Thomas Mesquida",
        "Hiroaki Nishi",
        "Tomasz Kryjak",
        "Thomas Dalgaty"
      ],
      "abstract": "As the quantities of data recorded by embedded edge sensors grow, so too does\nthe need for intelligent local processing. Such data often comes in the form of\ntime-series signals, based on which real-time predictions can be made locally\nusing an AI model. However, a hardware-software approach capable of making\nlow-latency predictions with low power consumption is required. In this paper,\nwe present a hardware implementation of an event-graph neural network for\ntime-series classification. We leverage an artificial cochlea model to convert\nthe input time-series signals into a sparse event-data format that allows the\nevent-graph to drastically reduce the number of calculations relative to other\nAI methods. We implemented the design on a SoC FPGA and applied it to the\nreal-time processing of the Spiking Heidelberg Digits (SHD) dataset to\nbenchmark our approach against competitive solutions. Our method achieves a\nfloating-point accuracy of 92.7% on the SHD dataset for the base model, which\nis only 2.4% and 2% less than the state-of-the-art models with over 10% and 67%\nfewer model parameters, respectively. It also outperforms FPGA-based spiking\nneural network implementations by 19.3% and 4.5%, achieving 92.3% accuracy for\nthe quantised model while using fewer computational resources and reducing\nlatency.",
      "tldr_zh": "该论文提出了一种硬件加速的事件图神经网络（Event-Graph Neural Networks），旨在实现低延迟时间序列分类，并部署在 SoC FPGA 上，以满足嵌入式边缘传感器数据的智能本地处理需求。该方法利用人工耳蜗模型（Artificial Cochlea Model）将输入时间序列信号转换为稀疏事件数据格式，从而大幅减少计算量。实验结果显示，在 Spiking Heidelberg Digits (SHD) 数据集上，该模型的浮点精度达92.7%，比最先进模型的参数减少10%和67%，并在量化模型中实现92.3%的精度，同时比其他FPGA-based神经网络提高19.3%和4.5%，并降低计算资源消耗和延迟。",
      "categories": [
        "cs.LG",
        "cs.AI",
        "eess.SP"
      ],
      "primary_category": "cs.LG",
      "comment": "Paper accepted for the 21st International Symposium on Applied\n  Reconfigurable Computing ARC 2025, Sevilla, Spain, April 9-11, 2025",
      "pdf_url": "http://arxiv.org/pdf/2503.06629v1",
      "published_date": "2025-03-09 14:08:46 UTC",
      "updated_date": "2025-03-09 14:08:46 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-23T23:48:27.721179"
    },
    {
      "arxiv_id": "2503.06627v1",
      "title": "Revisiting Early Detection of Sexual Predators via Turn-level Optimization",
      "title_zh": "翻译失败",
      "authors": [
        "Jinmyeong An",
        "Sangwon Ryu",
        "Heejin Do",
        "Yunsu Kim",
        "Jungseul Ok",
        "Gary Geunbae Lee"
      ],
      "abstract": "Online grooming is a severe social threat where sexual predators gradually\nentrap child victims with subtle and gradual manipulation. Therefore, timely\nintervention for online grooming is critical for proactive protection. However,\nprevious methods fail to determine the optimal intervention points (i.e., jump\nto conclusions) as they rely on chat-level risk labels by causing weak\nsupervision of risky utterances. For timely detection, we propose speed control\nreinforcement learning (SCoRL) (The code and supplementary materials are\navailable at https://github.com/jinmyeongAN/SCoRL), incorporating a practical\nstrategy derived from luring communication theory (LCT). To capture the\npredator's turn-level entrapment, we use a turn-level risk label based on the\nLCT. Then, we design a novel speed control reward function that balances the\ntrade-off between speed and accuracy based on turn-level risk label; thus,\nSCoRL can identify the optimal intervention moment. In addition, we introduce a\nturn-level metric for precise evaluation, identifying limitations in previously\nused chat-level metrics. Experimental results show that SCoRL effectively\npreempted online grooming, offering a more proactive and timely solution.\nFurther analysis reveals that our method enhances performance while intuitively\nidentifying optimal early intervention points.",
      "tldr_zh": "该研究重新审视在线诱导（online grooming）的早期检测问题，强调性掠夺者通过渐进操纵诱捕受害者的风险，并提出 speed control reinforcement learning (SCoRL) 框架来优化干预时机。SCoRL 基于 luring communication theory (LCT)，利用 turn-level risk label 捕捉掠夺者的逐轮诱捕行为，并设计 speed control reward function 来平衡检测速度与准确性，从而识别最佳干预点。实验结果显示，SCoRL 比传统聊天级别（chat-level）方法更有效地预先阻止在线诱导，并通过 turn-level metric 提供更精确的评估，提升了主动保护的性能。",
      "categories": [
        "cs.LG",
        "cs.AI",
        "cs.CL"
      ],
      "primary_category": "cs.LG",
      "comment": "Accepted as a main conference paper at NAACL 2025",
      "pdf_url": "http://arxiv.org/pdf/2503.06627v1",
      "published_date": "2025-03-09 14:05:27 UTC",
      "updated_date": "2025-03-09 14:05:27 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-23T23:48:39.601593"
    },
    {
      "arxiv_id": "2503.06626v1",
      "title": "DiffCLIP: Differential Attention Meets CLIP",
      "title_zh": "翻译失败",
      "authors": [
        "Hasan Abed Al Kader Hammoud",
        "Bernard Ghanem"
      ],
      "abstract": "We propose DiffCLIP, a novel vision-language model that extends the\ndifferential attention mechanism to CLIP architectures. Differential attention\nwas originally developed for large language models to amplify relevant context\nwhile canceling out noisy information. In this work, we integrate this\nmechanism into CLIP's dual encoder (image and text) framework. With minimal\nadditional parameters, DiffCLIP achieves superior performance on image-text\nunderstanding tasks. Across zero-shot classification, retrieval, and robustness\nbenchmarks, DiffCLIP consistently outperforms baseline CLIP models. Notably,\nthese gains come with negligible computational overhead, demonstrating that\ndifferential attention can significantly enhance multi-modal representations\nwithout sacrificing efficiency. Code can be found at\nhttps://github.com/hammoudhasan/DiffCLIP.",
      "tldr_zh": "本研究提出DiffCLIP，一种新型视觉语言模型，将differential attention机制扩展到CLIP架构中，以放大相关上下文并减少噪声信息。DiffCLIP在CLIP的双编码器框架（图像和文本）中集成该机制，仅需最少的额外参数，就在图像-文本理解任务上表现出色。实验结果显示，DiffCLIP在zero-shot classification、retrieval和robustness基准测试中，显著优于基线CLIP模型，同时保持negligible的计算开销。该方法证明了differential attention能高效提升多模态表示，为相关应用提供了新途径。",
      "categories": [
        "cs.CV",
        "cs.AI",
        "cs.LG"
      ],
      "primary_category": "cs.CV",
      "comment": "Under review",
      "pdf_url": "http://arxiv.org/pdf/2503.06626v1",
      "published_date": "2025-03-09 14:04:09 UTC",
      "updated_date": "2025-03-09 14:04:09 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-23T23:48:51.676113"
    },
    {
      "arxiv_id": "2503.06614v1",
      "title": "Using Subgraph GNNs for Node Classification:an Overlooked Potential Approach",
      "title_zh": "使用子图 GNNs 进行节点分类：一种被忽略的潜在方法",
      "authors": [
        "Qian Zeng",
        "Xin Lin",
        "Jingyi Gao",
        "Yang Yu"
      ],
      "abstract": "Previous studies have demonstrated the strong performance of Graph Neural\nNetworks (GNNs) in node classification. However, most existing GNNs adopt a\nnode-centric perspective and rely on global message passing, leading to high\ncomputational and memory costs that hinder scalability. To mitigate these\nchallenges, subgraph-based methods have been introduced, leveraging local\nsubgraphs as approximations of full computational trees. While this approach\nimproves efficiency, it often suffers from performance degradation due to the\nloss of global contextual information, limiting its effectiveness compared to\nglobal GNNs. To address this trade-off between scalability and classification\naccuracy, we reformulate the node classification task as a subgraph\nclassification problem and propose SubGND (Subgraph GNN for NoDe). This\nframework introduces a differentiated zero-padding strategy and an Ego-Alter\nsubgraph representation method to resolve label conflicts while incorporating\nan Adaptive Feature Scaling Mechanism to dynamically adjust feature\ncontributions based on dataset-specific dependencies. Experimental results on\nsix benchmark datasets demonstrate that SubGND achieves performance comparable\nto or surpassing global message-passing GNNs, particularly in heterophilic\nsettings, highlighting its effectiveness and scalability as a promising\nsolution for node classification.",
      "tldr_zh": "现有 GNNs 在节点分类任务中依赖全局消息传递，导致计算和内存成本高，不易扩展，而子图方法虽提高了效率但因丢失全局上下文而性能下降。为解决这一权衡，本文提出 SubGND 框架，将节点分类重构为子图分类问题，并引入差异化零填充策略、Ego-Alter 子图表示方法和自适应特征缩放机制，以处理标签冲突和动态调整特征贡献。实验结果显示，SubGND 在六个基准数据集上表现与全局 GNNs 相当或更优，尤其在异质性（heterophilic）设置中，突显了其有效性和可扩展性作为一种被忽略的潜在方法。",
      "categories": [
        "cs.LG",
        "cs.AI"
      ],
      "primary_category": "cs.LG",
      "comment": "16 pages",
      "pdf_url": "http://arxiv.org/pdf/2503.06614v1",
      "published_date": "2025-03-09 13:37:38 UTC",
      "updated_date": "2025-03-09 13:37:38 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-23T23:49:04.618654"
    },
    {
      "arxiv_id": "2503.06580v1",
      "title": "Agent models: Internalizing Chain-of-Action Generation into Reasoning models",
      "title_zh": "翻译失败",
      "authors": [
        "Yuxiang Zhang",
        "Yuqi Yang",
        "Jiangming Shu",
        "Xinyan Wen",
        "Jitao Sang"
      ],
      "abstract": "Traditional agentic workflows rely on external prompts to manage interactions\nwith tools and the environment, which limits the autonomy of reasoning models.\nWe position \\emph{Large Agent Models (LAMs)} that internalize the generation of\n\\emph{Chain-of-Action (CoA)}, enabling the model to autonomously decide when\nand how to use external tools. Our proposed AutoCoA framework combines\nsupervised fine-tuning (SFT) and reinforcement learning (RL), allowing the\nmodel to seamlessly switch between reasoning and action while efficiently\nmanaging environment interactions. Main components include step-level action\ntriggering, trajectory-level CoA optimization, and an internal world model to\nreduce real-environment interaction costs. Evaluations on open-domain QA tasks\ndemonstrate that AutoCoA-trained agent models significantly outperform\nReAct-based workflows in task completion, especially in tasks that require\nlong-term reasoning and multi-step actions. Code and dataset are available at\nhttps://github.com/ADaM-BJTU/AutoCoA",
      "tldr_zh": "本研究提出 Large Agent Models (LAMs)，通过内部化 Chain-of-Action (CoA) 生成，使推理模型能够自主决定何时和如何使用外部工具，从而克服传统代理工作流依赖外部提示的局限性。AutoCoA 框架结合 supervised fine-tuning (SFT) 和 reinforcement learning (RL)，包括步骤级行动触发、轨迹级 CoA 优化以及内部世界模型，以实现推理与行动的无缝切换并减少环境交互成本。在开放域 QA 任务的评估中，AutoCoA 训练的代理模型显著优于 ReAct-based 工作流，在需要长期推理和多步行动的任务上表现出色。",
      "categories": [
        "cs.AI"
      ],
      "primary_category": "cs.AI",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2503.06580v1",
      "published_date": "2025-03-09 12:19:47 UTC",
      "updated_date": "2025-03-09 12:19:47 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-23T23:49:17.665953"
    },
    {
      "arxiv_id": "2503.06573v1",
      "title": "WildIFEval: Instruction Following in the Wild",
      "title_zh": "翻译失败",
      "authors": [
        "Gili Lior",
        "Asaf Yehudai",
        "Ariel Gera",
        "Liat Ein-Dor"
      ],
      "abstract": "Recent LLMs have shown remarkable success in following user instructions, yet\nhandling instructions with multiple constraints remains a significant\nchallenge. In this work, we introduce WildIFEval - a large-scale dataset of 12K\nreal user instructions with diverse, multi-constraint conditions. Unlike prior\ndatasets, our collection spans a broad lexical and topical spectrum of\nconstraints, in natural user prompts. We categorize these constraints into\neight high-level classes to capture their distribution and dynamics in\nreal-world scenarios. Leveraging WildIFEval, we conduct extensive experiments\nto benchmark the instruction-following capabilities of leading LLMs. Our\nfindings reveal that all evaluated models experience performance degradation\nwith an increasing number of constraints. Thus, we show that all models have a\nlarge room for improvement on such tasks. Moreover, we observe that the\nspecific type of constraint plays a critical role in model performance. We\nrelease our dataset to promote further research on instruction-following under\ncomplex, realistic conditions.",
      "tldr_zh": "本文研究引入了 WildIFEval，这是一个包含 12K 真实用户指令的大型数据集，用于评估 LLMs 在多约束条件下的指令-following 能力。与现有数据集不同，该数据集覆盖了广泛的词汇和主题约束，并将这些约束分类为八个高层类，以反映真实场景的分布和动态。实验结果显示，所有评估的 LLMs 在约束数量增加时性能显著下降，且特定约束类型对模型表现有关键影响。该数据集的发布旨在促进 LLMs 在复杂现实条件下指令遵循的研究，进一步提升模型性能。",
      "categories": [
        "cs.CL",
        "cs.AI"
      ],
      "primary_category": "cs.CL",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2503.06573v1",
      "published_date": "2025-03-09 12:06:29 UTC",
      "updated_date": "2025-03-09 12:06:29 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-23T23:49:28.093306"
    },
    {
      "arxiv_id": "2503.06571v2",
      "title": "SHIP: A Shapelet-based Approach for Interpretable Patient-Ventilator Asynchrony Detection",
      "title_zh": "翻译失败",
      "authors": [
        "Xuan-May Le",
        "Ling Luo",
        "Uwe Aickelin",
        "Minh-Tuan Tran",
        "David Berlowitz",
        "Mark Howard"
      ],
      "abstract": "Patient-ventilator asynchrony (PVA) is a common and critical issue during\nmechanical ventilation, affecting up to 85% of patients. PVA can result in\nclinical complications such as discomfort, sleep disruption, and potentially\nmore severe conditions like ventilator-induced lung injury and diaphragm\ndysfunction. Traditional PVA management, which relies on manual adjustments by\nhealthcare providers, is often inadequate due to delays and errors. While\nvarious computational methods, including rule-based, statistical, and deep\nlearning approaches, have been developed to detect PVA events, they face\nchallenges related to dataset imbalances and lack of interpretability. In this\nwork, we propose a shapelet-based approach SHIP for PVA detection, utilizing\nshapelets - discriminative subsequences in time-series data - to enhance\ndetection accuracy and interpretability. Our method addresses dataset\nimbalances through shapelet-based data augmentation and constructs a shapelet\npool to transform the dataset for more effective classification. The combined\nshapelet and statistical features are then used in a classifier to identify PVA\nevents. Experimental results on medical datasets show that SHIP significantly\nimproves PVA detection while providing interpretable insights into model\ndecisions.",
      "tldr_zh": "本研究针对患者-呼吸机不同步（Patient-Ventilator Asynchrony, PVA）问题，提出了一种基于shapelet的检测方法SHIP，以解决传统方法在数据集不平衡和可解释性方面的挑战。SHIP利用shapelets——时间序列数据中的判别子序列——进行数据增强和特征转换，结合统计特征构建分类器来识别PVA事件，从而提高检测准确性和模型透明度。在医疗数据集上的实验结果显示，SHIP显著提升了PVA检测性能，并提供可解释的决策洞见，为临床管理提供可靠支持。",
      "categories": [
        "cs.LG",
        "cs.AI"
      ],
      "primary_category": "cs.LG",
      "comment": "Accepted at PAKDD 2025",
      "pdf_url": "http://arxiv.org/pdf/2503.06571v2",
      "published_date": "2025-03-09 11:58:03 UTC",
      "updated_date": "2025-03-13 02:01:30 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-23T23:49:39.309293"
    },
    {
      "arxiv_id": "2503.06568v1",
      "title": "Conceptrol: Concept Control of Zero-shot Personalized Image Generation",
      "title_zh": "Conceptrol：零样本个性化图像生成的概念控制",
      "authors": [
        "Qiyuan He",
        "Angela Yao"
      ],
      "abstract": "Personalized image generation with text-to-image diffusion models generates\nunseen images based on reference image content. Zero-shot adapter methods such\nas IP-Adapter and OminiControl are especially interesting because they do not\nrequire test-time fine-tuning. However, they struggle to balance preserving\npersonalized content and adherence to the text prompt. We identify a critical\ndesign flaw resulting in this performance gap: current adapters inadequately\nintegrate personalization images with the textual descriptions. The generated\nimages, therefore, replicate the personalized content rather than adhere to the\ntext prompt instructions. Yet the base text-to-image has strong conceptual\nunderstanding capabilities that can be leveraged.\n  We propose Conceptrol, a simple yet effective framework that enhances\nzero-shot adapters without adding computational overhead. Conceptrol constrains\nthe attention of visual specification with a textual concept mask that improves\nsubject-driven generation capabilities. It achieves as much as 89% improvement\non personalization benchmarks over the vanilla IP-Adapter and can even\noutperform fine-tuning approaches such as Dreambooth LoRA. The source code is\navailable at https://github.com/QY-H00/Conceptrol.",
      "tldr_zh": "这篇论文针对 zero-shot 适配器（如 IP-Adapter 和 OminiControl）在个性化图像生成中的问题，指出它们难以平衡保留参考图像内容与遵守文本提示，导致生成图像更多复制个性化元素而非响应指令。作者提出 Conceptrol 框架，这是一个简单有效的增强方法，通过文本概念掩码约束视觉规范的注意力，提高主题驱动生成能力，而无需额外计算开销。实验结果显示，Conceptrol 在个性化基准测试中比 vanilla IP-Adapter 提升高达89%，甚至优于微调方法如 Dreambooth LoRA，为 zero-shot 个性化图像生成提供了更可靠的解决方案。",
      "categories": [
        "cs.CV",
        "cs.AI"
      ],
      "primary_category": "cs.CV",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2503.06568v1",
      "published_date": "2025-03-09 11:54:08 UTC",
      "updated_date": "2025-03-09 11:54:08 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-23T23:49:52.303001"
    },
    {
      "arxiv_id": "2503.06567v1",
      "title": "Human Cognition Inspired RAG with Knowledge Graph for Complex Problem Solving",
      "title_zh": "翻译失败",
      "authors": [
        "Yao Cheng",
        "Yibo Zhao",
        "Jiapeng Zhu",
        "Yao Liu",
        "Xing Sun",
        "Xiang Li"
      ],
      "abstract": "Large language models (LLMs) have demonstrated transformative potential\nacross various domains, yet they face significant challenges in knowledge\nintegration and complex problem reasoning, often leading to hallucinations and\nunreliable outputs. Retrieval-Augmented Generation (RAG) has emerged as a\npromising solution to enhance LLMs accuracy by incorporating external\nknowledge. However, traditional RAG systems struggle with processing complex\nrelational information and multi-step reasoning, limiting their effectiveness\nin advanced problem-solving tasks. To address these limitations, we propose\nCogGRAG, a cognition inspired graph-based RAG framework, designed to improve\nLLMs performance in Knowledge Graph Question Answering (KGQA). Inspired by the\nhuman cognitive process of decomposing complex problems and performing\nself-verification, our framework introduces a three-stage methodology:\ndecomposition, retrieval, and reasoning with self-verification. By integrating\nthese components, CogGRAG enhances the accuracy of LLMs in complex problem\nsolving. We conduct systematic experiments with three LLM backbones on four\nbenchmark datasets, where CogGRAG outperforms the baselines.",
      "tldr_zh": "该研究提出 CogGRAG，一种受人类认知启发的基于知识图谱的 RAG 框架，旨在解决 Large Language Models (LLMs) 在知识整合和复杂问题推理中的挑战，如幻觉和不可靠输出。CogGRAG 采用三阶段方法，包括问题分解、知识检索以及推理与自验证过程，从而提升 LLMs 在 Knowledge Graph Question Answering (KGQA) 任务中的准确性。在三个 LLM 基础上进行的实验显示，该框架在四个基准数据集上优于基线模型，证明了其在复杂问题解决中的有效性。",
      "categories": [
        "cs.LG",
        "cs.AI"
      ],
      "primary_category": "cs.LG",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2503.06567v1",
      "published_date": "2025-03-09 11:50:39 UTC",
      "updated_date": "2025-03-09 11:50:39 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-23T23:50:03.757393"
    },
    {
      "arxiv_id": "2503.06563v1",
      "title": "LSA: Latent Style Augmentation Towards Stain-Agnostic Cervical Cancer Screening",
      "title_zh": "翻译失败",
      "authors": [
        "Jiangdong Cai",
        "Haotian Jiang",
        "Zhenrong Shen",
        "Yonghao Li",
        "Honglin Xiong",
        "Lichi Zhang",
        "Qian Wang"
      ],
      "abstract": "The deployment of computer-aided diagnosis systems for cervical cancer\nscreening using whole slide images (WSIs) faces critical challenges due to\ndomain shifts caused by staining variations across different scanners and\nimaging environments. While existing stain augmentation methods improve\npatch-level robustness, they fail to scale to WSIs due to two key limitations:\n(1) inconsistent stain patterns when extending patch operations to gigapixel\nslides, and (2) prohibitive computational/storage costs from offline processing\nof augmented WSIs.To address this, we propose Latent Style Augmentation (LSA),\na framework that performs efficient, online stain augmentation directly on\nWSI-level latent features. We first introduce WSAug, a WSI-level stain\naugmentation method ensuring consistent stain across patches within a WSI.\nUsing offline-augmented WSIs by WSAug, we design and train Stain Transformer,\nwhich can simulate targeted style in the latent space, efficiently enhancing\nthe robustness of the WSI-level classifier. We validate our method on a\nmulti-scanner WSI dataset for cervical cancer diagnosis. Despite being trained\non data from a single scanner, our approach achieves significant performance\nimprovements on out-of-distribution data from other scanners. Code will be\navailable at https://github.com/caijd2000/LSA.",
      "tldr_zh": "该论文针对宫颈癌筛查中全滑图像（WSI）因扫描仪和环境差异导致的染色变异问题，提出Latent Style Augmentation (LSA)框架，以实现染色无关的诊断系统。LSA通过WSI级别的在线增强方法WSAug确保WSI内染色模式一致，并训练Stain Transformer在潜在空间模拟目标风格，从而高效提升分类器的鲁棒性。实验结果显示，尽管仅在单一扫描仪数据上训练，该方法在多扫描仪的分布外数据集上显著提高了诊断性能。",
      "categories": [
        "eess.IV",
        "cs.AI",
        "cs.CV"
      ],
      "primary_category": "eess.IV",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2503.06563v1",
      "published_date": "2025-03-09 11:33:59 UTC",
      "updated_date": "2025-03-09 11:33:59 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-23T23:50:17.390443"
    },
    {
      "arxiv_id": "2504.20047v1",
      "title": "HCT-QA: A Benchmark for Question Answering on Human-Centric Tables",
      "title_zh": "HCT-QA：人类中心表问答的",
      "authors": [
        "Mohammad S. Ahmad",
        "Zan A. Naeem",
        "Michaël Aupetit",
        "Ahmed Elmagarmid",
        "Mohamed Eltabakh",
        "Xiasong Ma",
        "Mourad Ouzzani",
        "Chaoyi Ruan"
      ],
      "abstract": "Tabular data embedded within PDF files, web pages, and other document formats\nare prevalent across numerous sectors such as government, engineering, science,\nand business. These human-centric tables (HCTs) possess a unique combination of\nhigh business value, intricate layouts, limited operational power at scale, and\nsometimes serve as the only data source for critical insights. However, their\ncomplexity poses significant challenges to traditional data extraction,\nprocessing, and querying methods. While current solutions focus on transforming\nthese tables into relational formats for SQL queries, they fall short in\nhandling the diverse and complex layouts of HCTs and hence being amenable to\nquerying. This paper describes HCT-QA, an extensive benchmark of HCTs, natural\nlanguage queries, and related answers on thousands of tables. Our dataset\nincludes 2,188 real-world HCTs with 9,835 QA pairs and 4,679 synthetic tables\nwith 67.5K QA pairs. While HCTs can be potentially processed by different type\nof query engines, in this paper, we focus on Large Language Models as potential\nengines and assess their ability in processing and querying such tables.",
      "tldr_zh": "本论文引入了HCT-QA基准数据集，用于评估在人类中心表（Human-Centric Tables, HCTs）上的问答任务。HCTs常见于PDF和网页等格式，具有复杂布局和高商业价值，但传统方法如SQL查询难以有效处理。数据集包含2,188个真实HCTs配以9,835个QA对，以及4,679个合成表配以67.5K QA对，主要用于测试Large Language Models在处理和查询这些复杂表时的性能。研究强调了HCT-QA在提升表格数据提取和查询能力的潜力。",
      "categories": [
        "cs.IR",
        "cs.AI",
        "cs.DB"
      ],
      "primary_category": "cs.IR",
      "comment": "12 pages",
      "pdf_url": "http://arxiv.org/pdf/2504.20047v1",
      "published_date": "2025-03-09 11:02:11 UTC",
      "updated_date": "2025-03-09 11:02:11 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-23T23:50:27.481380"
    },
    {
      "arxiv_id": "2503.06553v1",
      "title": "ProJudge: A Multi-Modal Multi-Discipline Benchmark and Instruction-Tuning Dataset for MLLM-based Process Judges",
      "title_zh": "翻译失败",
      "authors": [
        "Jiaxin Ai",
        "Pengfei Zhou",
        "Zhaopan Xu",
        "Ming Li",
        "Fanrui Zhang",
        "Zizhen Li",
        "Jianwen Sun",
        "Yukang Feng",
        "Baojin Huang",
        "Zhongyuan Wang",
        "Kaipeng Zhang"
      ],
      "abstract": "As multi-modal large language models (MLLMs) frequently exhibit errors when\nsolving scientific problems, evaluating the validity of their reasoning\nprocesses is critical for ensuring reliability and uncovering fine-grained\nmodel weaknesses. Since human evaluation is laborious and costly, prompting\nMLLMs as automated process judges has become a common practice. However, the\nreliability of these model-based judges remains uncertain. To address this, we\nintroduce ProJudgeBench, the first comprehensive benchmark specifically\ndesigned for evaluating abilities of MLLM-based process judges. ProJudgeBench\ncomprises 2,400 test cases and 50,118 step-level labels, spanning four\nscientific disciplines with diverse difficulty levels and multi-modal content.\nIn ProJudgeBench, each step is meticulously annotated by human experts for\ncorrectness, error type, and explanation, enabling a systematic evaluation of\njudges' capabilities to detect, classify and diagnose errors. Evaluation on\nProJudgeBench reveals a significant performance gap between open-source and\nproprietary models. To bridge this gap, we further propose ProJudge-173k, a\nlarge-scale instruction-tuning dataset, and a Dynamic Dual-Phase fine-tuning\nstrategy that encourages models to explicitly reason through problem-solving\nbefore assessing solutions. Both contributions significantly enhance the\nprocess evaluation capabilities of open-source models. All the resources will\nbe released to foster future research of reliable multi-modal process\nevaluation.",
      "tldr_zh": "该研究引入ProJudgeBench，这是一个全面的多模态多学科基准，包含2400个测试案例和50118个步骤级标签，用于评估MLLM-based process judges在检测、分类和诊断科学推理错误方面的能力。基准覆盖四个科学领域、不同难度和多模态内容，每个步骤由专家标注正确性、错误类型和解释。实验结果显示，开源模型与专有模型存在显著性能差距；为此，论文提出ProJudge-173k大规模指令微调数据集和Dynamic Dual-Phase微调策略，鼓励模型先进行显式推理再评估解决方案，从而显著提升开源模型的评估能力。该工作将发布资源，以推动可靠的多模态过程评估研究。",
      "categories": [
        "cs.AI",
        "cs.CV",
        "cs.LG"
      ],
      "primary_category": "cs.AI",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2503.06553v1",
      "published_date": "2025-03-09 10:55:51 UTC",
      "updated_date": "2025-03-09 10:55:51 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-23T23:50:40.996884"
    },
    {
      "arxiv_id": "2503.06551v3",
      "title": "ChatGPT-4 in the Turing Test: A Critical Analysis",
      "title_zh": "ChatGPT-4 在图灵测试：批判性分析",
      "authors": [
        "Marco Giunti"
      ],
      "abstract": "This paper critically examines the recent publication \"ChatGPT-4 in the\nTuring Test\" by Restrepo Echavarr\\'ia (2025), challenging its central claims\nregarding the absence of minimally serious test implementations and the\nconclusion that ChatGPT-4 fails the Turing Test. The analysis reveals that the\ncriticisms based on rigid criteria and limited experimental data are not fully\njustified. More importantly, the paper makes several constructive contributions\nthat enrich our understanding of Turing Test implementations. It demonstrates\nthat two distinct formats--the three-player and two-player tests--are both\nvalid, each with unique methodological implications. The work distinguishes\nbetween absolute criteria (reflecting an optimal 50% identification rate in a\nthree-player format) and relative criteria (which measure how closely a\nmachine's performance approximates that of a human), offering a more nuanced\nevaluation framework. Furthermore, the paper clarifies the probabilistic\nunderpinnings of both test types by modeling them as Bernoulli\nexperiments--correlated in the three-player version and uncorrelated in the\ntwo-player version. This formalization allows for a rigorous separation between\nthe theoretical criteria for passing the test, defined in probabilistic terms,\nand the experimental data that require robust statistical methods for proper\ninterpretation. In doing so, the paper not only refutes key aspects of the\ncriticized study but also lays a solid foundation for future research on\nobjective measures of how closely an AI's behavior aligns with, or deviates\nfrom, that of a human being.",
      "tldr_zh": "这篇论文对 Restrepo Echavarría (2025) 的研究“ChatGPT-4 in the Turing Test”进行批判性分析，质疑其基于刚性标准和有限数据的结论，即 ChatGPT-4 未通过 Turing Test。论文证明了三玩家和两玩家测试格式都有效，并区分了绝对标准（三玩家格式的50% 识别率）和相对标准（衡量机器表现接近人类的程度），从而提供更细致的评估框架。通过将测试建模为 Bernoulli experiments，该研究阐明了测试的概率基础，并为未来 AI 行为的客观测量奠定基础。",
      "categories": [
        "cs.AI",
        "cs.CY",
        "cs.HC",
        "68T01"
      ],
      "primary_category": "cs.AI",
      "comment": "v1 14 pages, 1 Appendix; v2 added 1 missing item in References,\n  corrected typos; v3 corrected typos",
      "pdf_url": "http://arxiv.org/pdf/2503.06551v3",
      "published_date": "2025-03-09 10:43:17 UTC",
      "updated_date": "2025-04-08 21:23:00 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-23T23:50:52.412113"
    },
    {
      "arxiv_id": "2503.06542v1",
      "title": "ARMOR v0.1: Empowering Autoregressive Multimodal Understanding Model with Interleaved Multimodal Generation via Asymmetric Synergy",
      "title_zh": "翻译失败",
      "authors": [
        "Jianwen Sun",
        "Yukang Feng",
        "Chuanhao Li",
        "Fanrui Zhang",
        "Zizhen Li",
        "Jiaxin Ai",
        "Sizhuo Zhou",
        "Yu Dai",
        "Shenglin Zhang",
        "Kaipeng Zhang"
      ],
      "abstract": "Unified models (UniMs) for multimodal understanding and generation have\nrecently received much attention in the area of vision and language. Existing\nUniMs are designed to simultaneously learn both multimodal understanding and\ngeneration capabilities, demanding substantial computational resources, and\noften struggle to generate interleaved text-image. We present ARMOR, a\nresource-efficient and pure autoregressive framework that achieves both\nunderstanding and generation by fine-tuning existing multimodal large language\nmodels (MLLMs). Specifically, ARMOR extends existing MLLMs from three\nperspectives: (1) For model architecture, an asymmetric encoder-decoder\narchitecture with a forward-switching mechanism is introduced to unify\nembedding space integrating textual and visual modalities for enabling natural\ntext-image interleaved generation with minimal computational overhead. (2) For\ntraining data, a meticulously curated, high-quality interleaved dataset is\ncollected for fine-tuning MLLMs. (3) For the training algorithm, we propose a\n``what or how to generate\" algorithm to empower existing MLLMs with multimodal\ngeneration capabilities while preserving their multimodal understanding\ncapabilities, through three progressive training stages based on the collected\ndataset. Experimental results demonstrate that ARMOR upgrades existing MLLMs to\nUniMs with promising image generation capabilities, using limited training\nresources. Our code will be released soon at https://armor.github.io.",
      "tldr_zh": "该论文提出 ARMOR v0.1，一种资源高效的纯自回归框架，用于增强现有多模态大型语言模型 (MLLMs) 的理解和生成能力，以解决统一模型 (UniMs) 在计算资源消耗和文本-图像交错生成方面的挑战。ARMOR 通过引入不对称编码器-解码器架构 (asymmetric encoder-decoder architecture) 和前向切换机制 (forward-switching mechanism) 来统一文本和视觉模态嵌入，同时利用精心策划的高质量交错数据集和“what or how to generate”算法，通过三个渐进训练阶段提升生成能力，同时保留理解能力。实验结果表明，ARMOR 能将现有 MLLMs 升级为高效的 UniMs，实现有前景的图像生成，并在有限训练资源下表现出色，代码即将发布。",
      "categories": [
        "cs.CV",
        "cs.AI"
      ],
      "primary_category": "cs.CV",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2503.06542v1",
      "published_date": "2025-03-09 10:15:39 UTC",
      "updated_date": "2025-03-09 10:15:39 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-23T23:51:07.333797"
    },
    {
      "arxiv_id": "2503.06529v2",
      "title": "AnywhereDoor: Multi-Target Backdoor Attacks on Object Detection",
      "title_zh": "AnywhereDoor：针对目标检测的多目标后门攻击",
      "authors": [
        "Jialin Lu",
        "Junjie Shan",
        "Ziqi Zhao",
        "Ka-Ho Chow"
      ],
      "abstract": "As object detection becomes integral to many safety-critical applications,\nunderstanding its vulnerabilities is essential. Backdoor attacks, in\nparticular, pose a serious threat by implanting hidden triggers in victim\nmodels, which adversaries can later exploit to induce malicious behaviors\nduring inference. However, current understanding is limited to single-target\nattacks, where adversaries must define a fixed malicious behavior (target)\nbefore training, making inference-time adaptability impossible. Given the large\noutput space of object detection (including object existence prediction,\nbounding box estimation, and classification), the feasibility of flexible,\ninference-time model control remains unexplored. This paper introduces\nAnywhereDoor, a multi-target backdoor attack for object detection. Once\nimplanted, AnywhereDoor allows adversaries to make objects disappear, fabricate\nnew ones, or mislabel them, either across all object classes or specific ones,\noffering an unprecedented degree of control. This flexibility is enabled by\nthree key innovations: (i) objective disentanglement to scale the number of\nsupported targets; (ii) trigger mosaicking to ensure robustness even against\nregion-based detectors; and (iii) strategic batching to address object-level\ndata imbalances that hinder manipulation. Extensive experiments demonstrate\nthat AnywhereDoor grants attackers a high degree of control, improving attack\nsuccess rates by 26% compared to adaptations of existing methods for such\nflexible control.",
      "tldr_zh": "该论文提出AnywhereDoor，一种针对对象检测的多目标后门攻击（backdoor attacks），允许攻击者在推理时灵活控制模型行为，如让对象消失、伪造新对象或错误标记特定或所有类别，从而克服现有单目标攻击的局限性。AnywhereDoor的关键创新包括：(i) 目标分离（objective disentanglement）以扩展支持的目标数量；(ii) 触发器镶嵌（trigger mosaicking）确保对基于区域检测器的鲁棒性；以及(iii) 战略批量处理（strategic batching）解决对象级数据不平衡问题。实验结果显示，AnywhereDoor将攻击成功率比现有方法提高26%，证明了其在提升攻击控制度方面的有效性。",
      "categories": [
        "cs.CR",
        "cs.AI",
        "cs.CV"
      ],
      "primary_category": "cs.CR",
      "comment": "This work was intended as a replacement of arXiv:2411.14243 and any\n  subsequent updates will appear there",
      "pdf_url": "http://arxiv.org/pdf/2503.06529v2",
      "published_date": "2025-03-09 09:24:24 UTC",
      "updated_date": "2025-03-13 04:18:40 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-23T23:51:16.378270"
    },
    {
      "arxiv_id": "2503.06525v1",
      "title": "From Motion Signals to Insights: A Unified Framework for Student Behavior Analysis and Feedback in Physical Education Classes",
      "title_zh": "翻译失败",
      "authors": [
        "Xian Gao",
        "Jiacheng Ruan",
        "Jingsheng Gao",
        "Mingye Xie",
        "Zongyun Zhang",
        "Ting Liu",
        "Yuzhuo Fu"
      ],
      "abstract": "Analyzing student behavior in educational scenarios is crucial for enhancing\nteaching quality and student engagement. Existing AI-based models often rely on\nclassroom video footage to identify and analyze student behavior. While these\nvideo-based methods can partially capture and analyze student actions, they\nstruggle to accurately track each student's actions in physical education\nclasses, which take place in outdoor, open spaces with diverse activities, and\nare challenging to generalize to the specialized technical movements involved\nin these settings. Furthermore, current methods typically lack the ability to\nintegrate specialized pedagogical knowledge, limiting their ability to provide\nin-depth insights into student behavior and offer feedback for optimizing\ninstructional design. To address these limitations, we propose a unified\nend-to-end framework that leverages human activity recognition technologies\nbased on motion signals, combined with advanced large language models, to\nconduct more detailed analyses and feedback of student behavior in physical\neducation classes. Our framework begins with the teacher's instructional\ndesigns and the motion signals from students during physical education\nsessions, ultimately generating automated reports with teaching insights and\nsuggestions for improving both learning and class instructions. This solution\nprovides a motion signal-based approach for analyzing student behavior and\noptimizing instructional design tailored to physical education classes.\nExperimental results demonstrate that our framework can accurately identify\nstudent behaviors and produce meaningful pedagogical insights.",
      "tldr_zh": "本研究针对现有AI模型在体育课中依赖视频分析的局限性（如难以准确跟踪户外活动和整合专业教育知识），提出一个统一的端到端框架。该框架结合基于动作信号的human activity recognition技术和大型语言模型，从教师的教学设计和学生动作信号入手，对学生行为进行详细分析，并生成自动化报告，提供教学洞见和优化建议。实验结果表明，该框架能准确识别学生行为，并产生有意义的教学洞见，从而提升教学质量和学生参与度。",
      "categories": [
        "cs.CY",
        "cs.AI"
      ],
      "primary_category": "cs.CY",
      "comment": "Work in progress",
      "pdf_url": "http://arxiv.org/pdf/2503.06525v1",
      "published_date": "2025-03-09 09:04:36 UTC",
      "updated_date": "2025-03-09 09:04:36 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-23T23:51:27.984325"
    },
    {
      "arxiv_id": "2503.06523v1",
      "title": "Generative AI as Digital Media",
      "title_zh": "生成式 AI 作为数字媒体",
      "authors": [
        "Gilad Abiri"
      ],
      "abstract": "Generative AI is frequently portrayed as revolutionary or even apocalyptic,\nprompting calls for novel regulatory approaches. This essay argues that such\nviews are misguided. Instead, generative AI should be understood as an\nevolutionary step in the broader algorithmic media landscape, alongside search\nengines and social media. Like these platforms, generative AI centralizes\ninformation control, relies on complex algorithms to shape content, and\nextensively uses user data, thus perpetuating common problems: unchecked\ncorporate power, echo chambers, and weakened traditional gatekeepers.\nRegulation should therefore share a consistent objective: ensuring media\ninstitutions remain trustworthy. Without trust, public discourse risks\nfragmenting into isolated communities dominated by comforting, tribal beliefs\n-- a threat intensified by generative AI's capacity to bypass gatekeepers and\npersonalize truth. Current governance frameworks, such as the EU's AI Act and\nthe US Executive Order 14110, emphasize reactive risk mitigation, addressing\nmeasurable threats like national security, public health, and algorithmic bias.\nWhile effective for novel technological risks, this reactive approach fails to\nadequately address broader issues of trust and legitimacy inherent to digital\nmedia. Proactive regulation fostering transparency, accountability, and public\nconfidence is essential. Viewing generative AI exclusively as revolutionary\nrisks repeating past regulatory failures that left social media and search\nengines insufficiently regulated. Instead, regulation must proactively shape an\nalgorithmic media environment serving the public good, supporting quality\ninformation and robust civic discourse.",
      "tldr_zh": "这篇论文认为，生成式 AI 并非革命性或灾难性创新，而是算法媒体景观（如搜索引擎和社交媒体）的演化形式，它强化了信息控制、复杂算法依赖和用户数据使用，从而加剧问题包括不受检查的企业权力、回音室（echo chambers）和传统把关者（gatekeepers）的削弱。作者强调，监管应以确保媒体机构可信赖为目标，避免公共话语碎片化成孤立社区。当前框架如 EU's AI Act 和 US Executive Order 14110 侧重反应性风险缓解（如国家安全和算法偏差），但未能充分应对信任和合法性问题，因此需要主动监管来推动透明、问责和公众信心，以服务公共利益和公民话语。",
      "categories": [
        "cs.CY",
        "cs.AI"
      ],
      "primary_category": "cs.CY",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2503.06523v1",
      "published_date": "2025-03-09 08:58:17 UTC",
      "updated_date": "2025-03-09 08:58:17 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-23T23:51:40.532043"
    },
    {
      "arxiv_id": "2503.06519v1",
      "title": "Can Small Language Models Reliably Resist Jailbreak Attacks? A Comprehensive Evaluation",
      "title_zh": "小型语言模型能否可靠地抵抗越狱攻击？一项全面评估",
      "authors": [
        "Wenhui Zhang",
        "Huiyu Xu",
        "Zhibo Wang",
        "Zeqing He",
        "Ziqi Zhu",
        "Kui Ren"
      ],
      "abstract": "Small language models (SLMs) have emerged as promising alternatives to large\nlanguage models (LLMs) due to their low computational demands, enhanced privacy\nguarantees and comparable performance in specific domains through light-weight\nfine-tuning. Deploying SLMs on edge devices, such as smartphones and smart\nvehicles, has become a growing trend. However, the security implications of\nSLMs have received less attention than LLMs, particularly regarding jailbreak\nattacks, which is recognized as one of the top threats of LLMs by the OWASP. In\nthis paper, we conduct the first large-scale empirical study of SLMs'\nvulnerabilities to jailbreak attacks. Through systematically evaluation on 63\nSLMs from 15 mainstream SLM families against 8 state-of-the-art jailbreak\nmethods, we demonstrate that 47.6% of evaluated SLMs show high susceptibility\nto jailbreak attacks (ASR > 40%) and 38.1% of them can not even resist direct\nharmful query (ASR > 50%). We further analyze the reasons behind the\nvulnerabilities and identify four key factors: model size, model architecture,\ntraining datasets and training techniques. Moreover, we assess the\neffectiveness of three prompt-level defense methods and find that none of them\nachieve perfect performance, with detection accuracy varying across different\nSLMs and attack methods. Notably, we point out that the inherent security\nawareness play a critical role in SLM security, and models with strong security\nawareness could timely terminate unsafe response with little reminder. Building\nupon the findings, we highlight the urgent need for security-by-design\napproaches in SLM development and provide valuable insights for building more\ntrustworthy SLM ecosystem.",
      "tldr_zh": "本论文对小语言模型 (SLMs) 抵抗越狱攻击 (jailbreak attacks) 的可靠性进行了首次大规模实证评估，评估了 63 个 SLMs（来自 15 个主流家族）和 8 种最先进攻击方法。结果显示，47.6% 的 SLMs 显示高度易感（Attack Success Rate, ASR > 40%），而 38.1% 的模型甚至无法抵御直接有害查询（ASR > 50%）。研究分析了模型大小、架构、训练数据集和训练技术等四个关键因素影响安全，并评估了三种 prompt-level 防御方法的效果，发现这些方法性能不稳定。最终，论文强调 SLMs 需要采用安全设计 (security-by-design) 策略，以构建更可信赖的生态系统。",
      "categories": [
        "cs.CR",
        "cs.AI"
      ],
      "primary_category": "cs.CR",
      "comment": "19 pages, 12 figures",
      "pdf_url": "http://arxiv.org/pdf/2503.06519v1",
      "published_date": "2025-03-09 08:47:16 UTC",
      "updated_date": "2025-03-09 08:47:16 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-23T23:51:54.392152"
    },
    {
      "arxiv_id": "2503.06518v1",
      "title": "Towards Superior Quantization Accuracy: A Layer-sensitive Approach",
      "title_zh": "翻译失败",
      "authors": [
        "Feng Zhang",
        "Yanbin Liu",
        "Weihua Li",
        "Jie Lv",
        "Xiaodan Wang",
        "Quan Bai"
      ],
      "abstract": "Large Vision and Language Models have exhibited remarkable human-like\nintelligence in tasks such as natural language comprehension, problem-solving,\nlogical reasoning, and knowledge retrieval. However, training and serving these\nmodels require substantial computational resources, posing a significant\nbarrier to their widespread application and further research. To mitigate this\nchallenge, various model compression techniques have been developed to reduce\ncomputational requirements. Nevertheless, existing methods often employ uniform\nquantization configurations, failing to account for the varying difficulties\nacross different layers in quantizing large neural network models. This paper\ntackles this issue by leveraging layer-sensitivity features, such as activation\nsensitivity and weight distribution Kurtosis, to identify layers that are\nchallenging to quantize accurately and allocate additional memory budget. The\nproposed methods, named SensiBoost and KurtBoost, respectively, demonstrate\nnotable improvement in quantization accuracy, achieving up to 9% lower\nperplexity with only a 2% increase in memory budget on LLama models compared to\nthe baseline.",
      "tldr_zh": "大型视觉和语言模型在计算资源需求上存在挑战，现有的量化(quantization)方法采用统一配置，无法处理不同层间的量化难度差异。本文提出了一种层敏感方法，通过activation sensitivity和weight distribution Kurtosis等特征识别难量化层，并分配额外内存预算，引入SensiBoost和KurtBoost算法。在LLaMA模型上，该方法实现了量化准确性的显著提升，最多降低9%的perplexity，同时仅增加了2%的内存预算。",
      "categories": [
        "cs.LG",
        "cs.AI"
      ],
      "primary_category": "cs.LG",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2503.06518v1",
      "published_date": "2025-03-09 08:45:03 UTC",
      "updated_date": "2025-03-09 08:45:03 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-23T23:52:06.668975"
    },
    {
      "arxiv_id": "2503.06514v2",
      "title": "GFlowVLM: Enhancing Multi-step Reasoning in Vision-Language Models with Generative Flow Networks",
      "title_zh": "GFlowVLM：使用生成流网络增强视觉语言模型中的多步推理",
      "authors": [
        "Haoqiang Kang",
        "Enna Sachdeva",
        "Piyush Gupta",
        "Sangjae Bae",
        "Kwonjoon Lee"
      ],
      "abstract": "Vision-Language Models (VLMs) have recently shown promising advancements in\nsequential decision-making tasks through task-specific fine-tuning. However,\ncommon fine-tuning methods, such as Supervised Fine-Tuning (SFT) and\nReinforcement Learning (RL) techniques like Proximal Policy Optimization (PPO),\npresent notable limitations: SFT assumes Independent and Identically\nDistributed (IID) data, while PPO focuses on maximizing cumulative rewards.\nThese limitations often restrict solution diversity and hinder generalization\nin multi-step reasoning tasks. To address these challenges, we introduce a\nnovel framework, GFlowVLM, a framework that fine-tune VLMs using Generative\nFlow Networks (GFlowNets) to promote generation of diverse solutions for\ncomplex reasoning tasks. GFlowVLM models the environment as a non-Markovian\ndecision process, allowing it to capture long-term dependencies essential for\nreal-world applications. It takes observations and task descriptions as inputs\nto prompt chain-of-thought (CoT) reasoning which subsequently guides action\nselection. We use task based rewards to fine-tune VLM with GFlowNets. This\napproach enables VLMs to outperform prior fine-tuning methods, including SFT\nand RL. Empirical results demonstrate the effectiveness of GFlowVLM on complex\ntasks such as card games (NumberLine, BlackJack) and embodied planning tasks\n(ALFWorld), showing enhanced training efficiency, solution diversity, and\nstronger generalization capabilities across both in-distribution and\nout-of-distribution scenarios.",
      "tldr_zh": "该论文提出 GFlowVLM 框架，使用 Generative Flow Networks (GFlowNets) 来微调 Vision-Language Models (VLMs)，以解决 Supervised Fine-Tuning (SFT) 和 Reinforcement Learning (RL) 方法如 Proximal Policy Optimization (PPO) 在多步推理任务中存在的解决方案多样性不足和泛化能力弱等问题。GFlowVLM 将环境建模为非 Markov 决策过程，结合 chain-of-thought (CoT) 推理和任务奖励，引导 VLMs 生成更丰富的解决方案。实验结果显示，该框架在 NumberLine、BlackJack 和 ALFWorld 等任务上实现了更高的训练效率、解决方案多样性，以及在分布内和分布外场景的更强泛化性能。",
      "categories": [
        "cs.CL",
        "cs.AI",
        "cs.CV",
        "cs.LG"
      ],
      "primary_category": "cs.CL",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2503.06514v2",
      "published_date": "2025-03-09 08:38:10 UTC",
      "updated_date": "2025-03-25 07:37:48 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-23T23:52:20.774139"
    },
    {
      "arxiv_id": "2503.06511v1",
      "title": "HFedCKD: Toward Robust Heterogeneous Federated Learning via Data-free Knowledge Distillation and Two-way Contrast",
      "title_zh": "翻译失败",
      "authors": [
        "Yiting Zheng",
        "Bohan Lin",
        "Jinqian Chen",
        "Jihua Zhu"
      ],
      "abstract": "Most current federated learning frameworks are modeled as static processes,\nignoring the dynamic characteristics of the learning system. Under the limited\ncommunication budget of the central server, the flexible model architecture of\na large number of clients participating in knowledge transfer requires a lower\nparticipation rate, active clients have uneven contributions, and the client\nscale seriously hinders the performance of FL. We consider a more general and\npractical federation scenario and propose a system heterogeneous federation\nmethod based on data-free knowledge distillation and two-way contrast\n(HFedCKD). We apply the Inverse Probability Weighted Distillation (IPWD)\nstrategy to the data-free knowledge transfer framework. The generator completes\nthe data features of the nonparticipating clients. IPWD implements a dynamic\nevaluation of the prediction contribution of each client under different data\ndistributions. Based on the antibiased weighting of its prediction loss, the\nweight distribution of each client is effectively adjusted to fairly integrate\nthe knowledge of participating clients. At the same time, the local model is\nsplit into a feature extractor and a classifier. Through differential contrast\nlearning, the feature extractor is aligned with the global model in the feature\nspace, while the classifier maintains personalized decision-making\ncapabilities. HFedCKD effectively alleviates the knowledge offset caused by a\nlow participation rate under data-free knowledge distillation and improves the\nperformance and stability of the model. We conduct extensive experiments on\nimage and IoT datasets to comprehensively evaluate and verify the\ngeneralization and robustness of the proposed HFedCKD framework.",
      "tldr_zh": "该研究针对联邦学习(Federated Learning)中的动态问题和异构客户端挑战，提出HFedCKD框架，通过无数据知识蒸馏(Data-free Knowledge Distillation)和双向对比(Two-way Contrast)来提升模型的鲁棒性。框架采用Inverse Probability Weighted Distillation(IPWD)策略动态评估每个客户端的预测贡献，并基于抗偏权重调整知识整合，同时将局部模型分为特征提取器和分类器，通过差异对比学习实现特征空间对齐和个性化决策。实验结果显示，HFedCKD在图像和IoT数据集上有效缓解了低参与率下的知识偏移，提高了模型的性能、稳定性和泛化能力。",
      "categories": [
        "cs.LG",
        "cs.AI"
      ],
      "primary_category": "cs.LG",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2503.06511v1",
      "published_date": "2025-03-09 08:32:57 UTC",
      "updated_date": "2025-03-09 08:32:57 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-23T23:52:31.599486"
    },
    {
      "arxiv_id": "2503.06508v2",
      "title": "LightMotion: A Light and Tuning-free Method for Simulating Camera Motion in Video Generation",
      "title_zh": "翻译失败",
      "authors": [
        "Quanjian Song",
        "Zhihang Lin",
        "Zhanpeng Zeng",
        "Ziyue Zhang",
        "Liujuan Cao",
        "Rongrong Ji"
      ],
      "abstract": "Existing camera motion-controlled video generation methods face computational\nbottlenecks in fine-tuning and inference. This paper proposes LightMotion, a\nlight and tuning-free method for simulating camera motion in video generation.\nOperating in the latent space, it eliminates additional fine-tuning,\ninpainting, and depth estimation, making it more streamlined than existing\nmethods. The endeavors of this paper comprise: (i) The latent space permutation\noperation effectively simulates various camera motions like panning, zooming,\nand rotation. (ii) The latent space resampling strategy combines\nbackground-aware sampling and cross-frame alignment to accurately fill new\nperspectives while maintaining coherence across frames. (iii) Our in-depth\nanalysis shows that the permutation and resampling cause an SNR shift in latent\nspace, leading to poor-quality generation. To address this, we propose latent\nspace correction, which reintroduces noise during denoising to mitigate SNR\nshift and enhance video generation quality. Exhaustive experiments show that\nour LightMotion outperforms existing methods, both quantitatively and\nqualitatively.",
      "tldr_zh": "这篇论文提出了 LightMotion，一种轻量级且无需微调的方法，用于视频生成中的相机运动模拟，通过在 latent space 中操作来避免额外微调、修复和深度估计的计算瓶颈。关键创新包括：latent space permutation 操作模拟各种相机运动（如平移、缩放和旋转）、latent space resampling 策略结合背景感知采样和跨帧对齐以保持帧间一致性，以及 latent space correction 通过重新引入噪声缓解 permutation 和 resampling 导致的 SNR shift，从而提升生成质量。实验结果显示，LightMotion 在定量和定性指标上均优于现有方法，提供了一种高效的视频生成解决方案。",
      "categories": [
        "cs.CV",
        "cs.AI"
      ],
      "primary_category": "cs.CV",
      "comment": "18 pages in total",
      "pdf_url": "http://arxiv.org/pdf/2503.06508v2",
      "published_date": "2025-03-09 08:28:40 UTC",
      "updated_date": "2025-03-11 02:28:14 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-23T23:52:42.825351"
    },
    {
      "arxiv_id": "2503.17368v1",
      "title": "Non-Canonical Crosslinks Confound Evolutionary Protein Structure Models",
      "title_zh": "翻译失败",
      "authors": [
        "Romain Lacombe"
      ],
      "abstract": "Evolution-based protein structure prediction models have achieved\nbreakthrough success in recent years. However, they struggle to generalize\nbeyond evolutionary priors and on sequences lacking rich homologous data. Here\nwe present a novel, out-of-domain benchmark based on sactipeptides, a rare\nclass of ribosomally synthesized and post-translationally modified peptides\n(RiPPs) characterized by sulfur-to-$\\alpha$-carbon thioether bridges creating\ncross-links between cysteine residues and backbone. We evaluate recent models\non predicting conformations compatible with these cross-links bridges for the\n10 known sactipeptides with elucidated post-translational modifications.\nCrucially, the structures of 5 of them have not yet been experimentally\nresolved. This makes the task a challenging problem for evolution-based models,\nwhich we find exhibit limited performance (0.0% to 19.2% GDT-TS on\nsulfur-to-$\\alpha$-carbon distance). Our results point at the need for\nphysics-informed models to sustain progress in biomolecular structure\nprediction.",
      "tldr_zh": "该研究揭示了进化-based蛋白质结构预测模型在处理非标准crosslinks时的局限性，这些模型难以泛化到缺乏进化先验或同源数据的序列。作者引入了一个基于sactipeptides（一种罕见的RiPPs）的基准，评估模型预测与sulfur-to-α-carbon thioether bridges兼容的构象，结果显示在10个已知sactipeptides上，模型性能有限（GDT-TS分数从0.0%到19.2%）。该工作强调，需要开发physics-informed模型来推动生物分子结构预测的进步。",
      "categories": [
        "q-bio.BM",
        "cs.AI"
      ],
      "primary_category": "q-bio.BM",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2503.17368v1",
      "published_date": "2025-03-09 08:18:11 UTC",
      "updated_date": "2025-03-09 08:18:11 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-23T23:52:54.595421"
    },
    {
      "arxiv_id": "2503.06505v1",
      "title": "DynamicID: Zero-Shot Multi-ID Image Personalization with Flexible Facial Editability",
      "title_zh": "翻译失败",
      "authors": [
        "Xirui Hu",
        "Jiahao Wang",
        "Hao Chen",
        "Weizhan Zhang",
        "Benqi Wang",
        "Yikun Li",
        "Haishun Nan"
      ],
      "abstract": "Recent advancements in text-to-image generation have spurred interest in\npersonalized human image generation, which aims to create novel images\nfeaturing specific human identities as reference images indicate. Although\nexisting methods achieve high-fidelity identity preservation, they often\nstruggle with limited multi-ID usability and inadequate facial editability. We\npresent DynamicID, a tuning-free framework supported by a dual-stage training\nparadigm that inherently facilitates both single-ID and multi-ID personalized\ngeneration with high fidelity and flexible facial editability. Our key\ninnovations include: 1) Semantic-Activated Attention (SAA), which employs\nquery-level activation gating to minimize disruption to the original model when\ninjecting ID features and achieve multi-ID personalization without requiring\nmulti-ID samples during training. 2) Identity-Motion Reconfigurator (IMR),\nwhich leverages contrastive learning to effectively disentangle and re-entangle\nfacial motion and identity features, thereby enabling flexible facial editing.\nAdditionally, we have developed a curated VariFace-10k facial dataset,\ncomprising 10k unique individuals, each represented by 35 distinct facial\nimages. Experimental results demonstrate that DynamicID outperforms\nstate-of-the-art methods in identity fidelity, facial editability, and multi-ID\npersonalization capability.",
      "tldr_zh": "该研究提出 DynamicID，一种零样本（Zero-Shot）框架，用于多身份（Multi-ID）图像个性化生成，支持高保真度和灵活的面部编辑，解决了现有方法在多身份可用性和编辑能力上的局限。关键创新包括 Semantic-Activated Attention (SAA)，通过查询级激活门控注入身份特征，实现多身份个性化而不需额外训练样本；以及 Identity-Motion Reconfigurator (IMR)，利用对比学习分离并重新结合面部动作和身份特征，以实现精确编辑。该框架还开发了 VariFace-10k 数据集，包含 10k 个独特个人的 35 张面部图像，实验结果显示 DynamicID 在身份保真度、面部编辑性和多身份能力上优于现有方法。",
      "categories": [
        "cs.CV",
        "cs.AI"
      ],
      "primary_category": "cs.CV",
      "comment": "17 pages, 16 figures",
      "pdf_url": "http://arxiv.org/pdf/2503.06505v1",
      "published_date": "2025-03-09 08:16:19 UTC",
      "updated_date": "2025-03-09 08:16:19 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-23T23:53:07.182026"
    },
    {
      "arxiv_id": "2503.06499v2",
      "title": "ExGes: Expressive Human Motion Retrieval and Modulation for Audio-Driven Gesture Synthesis",
      "title_zh": "翻译失败",
      "authors": [
        "Xukun Zhou",
        "Fengxin Li",
        "Ming Chen",
        "Yan Zhou",
        "Pengfei Wan",
        "Di Zhang",
        "Yeying Jin",
        "Zhaoxin Fan",
        "Hongyan Liu",
        "Jun He"
      ],
      "abstract": "Audio-driven human gesture synthesis is a crucial task with broad\napplications in virtual avatars, human-computer interaction, and creative\ncontent generation. Despite notable progress, existing methods often produce\ngestures that are coarse, lack expressiveness, and fail to fully align with\naudio semantics. To address these challenges, we propose ExGes, a novel\nretrieval-enhanced diffusion framework with three key designs: (1) a Motion\nBase Construction, which builds a gesture library using training dataset; (2) a\nMotion Retrieval Module, employing constrative learning and momentum\ndistillation for fine-grained reference poses retreiving; and (3) a Precision\nControl Module, integrating partial masking and stochastic masking to enable\nflexible and fine-grained control. Experimental evaluations on BEAT2\ndemonstrate that ExGes reduces Fr\\'echet Gesture Distance by 6.2\\% and improves\nmotion diversity by 5.3\\% over EMAGE, with user studies revealing a 71.3\\%\npreference for its naturalness and semantic relevance. Code will be released\nupon acceptance.",
      "tldr_zh": "该研究提出ExGes，一种新型检索增强扩散框架，用于音频驱动的人类手势合成，旨在解决现有方法在表达性、细粒度和音频语义对齐方面的不足。框架包括三个关键组件：Motion Base Construction用于构建手势库、Motion Retrieval Module通过对比学习和动量蒸馏检索细粒度参考姿势，以及Precision Control Module整合部分掩码和随机掩码实现灵活控制。在BEAT2数据集的实验中，ExGes比EMAGE降低了Fréchet Gesture Distance 6.2%并提高了运动多样性5.3%，用户研究显示71.3%的偏好率，突显其在自然性和语义相关性上的优势。",
      "categories": [
        "cs.CV",
        "cs.AI"
      ],
      "primary_category": "cs.CV",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2503.06499v2",
      "published_date": "2025-03-09 07:59:39 UTC",
      "updated_date": "2025-03-15 04:31:47 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-23T23:53:18.945889"
    },
    {
      "arxiv_id": "2503.06497v1",
      "title": "Evaluation of Safety Cognition Capability in Vision-Language Models for Autonomous Driving",
      "title_zh": "自动驾驶视觉语言模型的安全认知能力评估",
      "authors": [
        "Enming Zhang",
        "Peizhe Gong",
        "Xingyuan Dai",
        "Yisheng Lv",
        "Qinghai Miao"
      ],
      "abstract": "Assessing the safety of vision-language models (VLMs) in autonomous driving\nis particularly important; however, existing work mainly focuses on traditional\nbenchmark evaluations. As interactive components within autonomous driving\nsystems, VLMs must maintain strong safety cognition during interactions. From\nthis perspective, we propose a novel evaluation method: Safety Cognitive\nDriving Benchmark (SCD-Bench) . To address the large-scale annotation challenge\nfor SCD-Bench, we develop the Autonomous Driving Image-Text Annotation System\n(ADA) . Additionally, to ensure data quality in SCD-Bench, our dataset\nundergoes manual refinement by experts with professional knowledge in\nautonomous driving. We further develop an automated evaluation method based on\nlarge language models (LLMs). To verify its effectiveness, we compare its\nevaluation results with those of expert human evaluations, achieving a\nconsistency rate of 99.74%. Preliminary experimental results indicate that\nexisting open-source models still lack sufficient safety cognition, showing a\nsignificant gap compared to GPT-4o. Notably, lightweight models (1B-4B)\ndemonstrate minimal safety cognition. However, since lightweight models are\ncrucial for autonomous driving systems, this presents a significant challenge\nfor integrating VLMs into the field.",
      "tldr_zh": "这篇论文评估了视觉语言模型（VLMs）在自动驾驶中的安全认知能力，提出了一种新颖的评估方法——Safety Cognitive Driving Benchmark (SCD-Bench)，以测试VLMs在交互场景中的安全表现。论文开发了Autonomous Driving Image-Text Annotation System (ADA)来解决大规模数据标注问题，并通过专家手动精炼数据集以确保质量。基于大型语言模型（LLMs）的自动评估方法被引入，其与专家评估的一致率高达99.74%。实验结果显示，现有的开源模型在安全认知方面明显不足，尤其是轻量级模型（1B-4B），这对VLMs在自动驾驶领域的集成应用提出了重大挑战。",
      "categories": [
        "cs.CV",
        "cs.AI"
      ],
      "primary_category": "cs.CV",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2503.06497v1",
      "published_date": "2025-03-09 07:53:19 UTC",
      "updated_date": "2025-03-09 07:53:19 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-23T23:53:31.513387"
    },
    {
      "arxiv_id": "2503.16487v1",
      "title": "PythonPal: Enhancing Online Programming Education through Chatbot-Driven Personalized Feedback",
      "title_zh": "翻译失败",
      "authors": [
        "Sirinda Palahan"
      ],
      "abstract": "The rise of online programming education has necessitated more effective,\npersonalized interactions, a gap that PythonPal aims to fill through its\ninnovative learning system integrated with a chatbot. This research delves into\nPythonPal's potential to enhance the online learning experience, especially in\ncontexts with high student-to-teacher ratios where there is a need for\npersonalized feedback. PythonPal's design, featuring modules for conversation,\ntutorials, and exercises, was evaluated through student interactions and\nfeedback. Key findings reveal PythonPal's proficiency in syntax error\nrecognition and user query comprehension, with its intent classification model\nshowing high accuracy. The system's performance in error feedback, though\nvaried, demonstrates both strengths and areas for enhancement. Student feedback\nindicated satisfactory query understanding and feedback accuracy but also\npointed out the need for faster responses and improved interaction quality.\nPythonPal's deployment promises to significantly enhance online programming\neducation by providing immediate, personalized feedback and interactive\nlearning experiences, fostering a deeper understanding of programming concepts\namong students. These benefits mark a step forward in addressing the challenges\nof distance learning, making programming education more accessible and\neffective.",
      "tldr_zh": "本研究介绍了 PythonPal，一种集成聊天机器人(chatbot)的创新学习系统，旨在通过提供个性化反馈提升在线编程教育，尤其适用于师生比例高的环境。系统设计包括对话、教程和练习模块，利用意图分类模型(intent classification model)实现语法错误识别和用户查询理解。实验评估显示，PythonPal 在错误反馈和查询处理方面表现出色，但响应速度和互动质量仍有改进空间。学生反馈整体积极，认为它能促进编程概念的深入理解，并有效解决远程学习的挑战，从而使在线教育更具可及性和效果。",
      "categories": [
        "cs.HC",
        "cs.AI"
      ],
      "primary_category": "cs.HC",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2503.16487v1",
      "published_date": "2025-03-09 07:28:42 UTC",
      "updated_date": "2025-03-09 07:28:42 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-23T23:53:42.274085"
    },
    {
      "arxiv_id": "2503.06486v1",
      "title": "PerturboLLaVA: Reducing Multimodal Hallucinations with Perturbative Visual Training",
      "title_zh": "PerturboLLaVA：通过扰动性视觉训练减少多模态幻觉",
      "authors": [
        "Cong Chen",
        "Mingyu Liu",
        "Chenchen Jing",
        "Yizhou Zhou",
        "Fengyun Rao",
        "Hao Chen",
        "Bo Zhang",
        "Chunhua Shen"
      ],
      "abstract": "This paper aims to address the challenge of hallucinations in Multimodal\nLarge Language Models (MLLMs) particularly for dense image captioning tasks. To\ntackle the challenge, we identify the current lack of a metric that finely\nmeasures the caption quality in concept level. We hereby introduce HalFscore, a\nnovel metric built upon the language graph and is designed to evaluate both the\naccuracy and completeness of dense captions at a granular level. Additionally,\nwe identify the root cause of hallucination as the model's over-reliance on its\nlanguage prior. To address this, we propose PerturboLLaVA, which reduces the\nmodel's reliance on the language prior by incorporating adversarially perturbed\ntext during training. This method enhances the model's focus on visual inputs,\neffectively reducing hallucinations and producing accurate, image-grounded\ndescriptions without incurring additional computational overhead. PerturboLLaVA\nsignificantly improves the fidelity of generated captions, outperforming\nexisting approaches in handling multimodal hallucinations and achieving\nimproved performance across general multimodal benchmarks.",
      "tldr_zh": "本研究针对多模态大语言模型 (MLLMs) 在密集图像描述任务中的幻觉问题，提出了一种新方法 PerturboLLaVA，以减少模型对语言先验的过度依赖。研究者首先引入 HalFscore，这是一个基于语言图的指标，用于细粒度评估描述的准确性和完整性。PerturboLLaVA 通过在训练中加入对抗性扰动文本，增强模型对视觉输入的关注，从而生成更准确的图像相关描述，而无需额外计算开销。在实验中，该方法显著优于现有方法，在多模态基准测试中提升了性能。",
      "categories": [
        "cs.CV",
        "cs.AI"
      ],
      "primary_category": "cs.CV",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2503.06486v1",
      "published_date": "2025-03-09 07:07:03 UTC",
      "updated_date": "2025-03-09 07:07:03 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-23T23:53:54.304993"
    },
    {
      "arxiv_id": "2503.06484v1",
      "title": "Sign Language Translation using Frame and Event Stream: Benchmark Dataset and Algorithms",
      "title_zh": "翻译失败",
      "authors": [
        "Xiao Wang",
        "Yuehang Li",
        "Fuling Wang",
        "Bo Jiang",
        "Yaowei Wang",
        "Yonghong Tian",
        "Jin Tang",
        "Bin Luo"
      ],
      "abstract": "Accurate sign language understanding serves as a crucial communication\nchannel for individuals with disabilities. Current sign language translation\nalgorithms predominantly rely on RGB frames, which may be limited by fixed\nframe rates, variable lighting conditions, and motion blur caused by rapid hand\nmovements. Inspired by the recent successful application of event cameras in\nother fields, we propose to leverage event streams to assist RGB cameras in\ncapturing gesture data, addressing the various challenges mentioned above.\nSpecifically, we first collect a large-scale RGB-Event sign language\ntranslation dataset using the DVS346 camera, termed VECSL, which contains\n15,676 RGB-Event samples, 15,191 glosses, and covers 2,568 Chinese characters.\nThese samples were gathered across a diverse range of indoor and outdoor\nenvironments, capturing multiple viewing angles, varying light intensities, and\ndifferent camera motions. Due to the absence of benchmark algorithms for\ncomparison in this new task, we retrained and evaluated multiple\nstate-of-the-art SLT algorithms, and believe that this benchmark can\neffectively support subsequent related research. Additionally, we propose a\nnovel RGB-Event sign language translation framework (i.e., M$^2$-SLT) that\nincorporates fine-grained micro-sign and coarse-grained macro-sign retrieval,\nachieving state-of-the-art results on the proposed dataset. Both the source\ncode and dataset will be released on https://github.com/Event-AHU/OpenESL.",
      "tldr_zh": "本文提出使用 RGB 帧和事件流（event streams）相结合的方法来提升手语翻译（SLT）的准确性，解决传统算法受限于固定帧率、光线变化和运动模糊等问题。作者构建了一个大型基准数据集 VECSL，使用 DVS346 相机收集了 15,676 个 RGB-Event 样本、15,191 个 glosses，并覆盖 2,568 个中文字符，采集自多样化的室内外环境。针对这一新任务，他们重新训练了多种最先进 SLT 算法，并开发了新框架 M²-SLT，通过细粒度的微手势和粗粒度的宏手势检索，在数据集上取得了 state-of-the-art 结果，代码和数据集已计划开源。",
      "categories": [
        "cs.CV",
        "cs.AI",
        "cs.NE"
      ],
      "primary_category": "cs.CV",
      "comment": "In Peer Review",
      "pdf_url": "http://arxiv.org/pdf/2503.06484v1",
      "published_date": "2025-03-09 06:55:46 UTC",
      "updated_date": "2025-03-09 06:55:46 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-23T23:54:08.018279"
    },
    {
      "arxiv_id": "2503.06479v1",
      "title": "ExKG-LLM: Leveraging Large Language Models for Automated Expansion of Cognitive Neuroscience Knowledge Graphs",
      "title_zh": "ExKG-LLM：利用大型语言模型进行认知神经科学知识图谱的自动扩展",
      "authors": [
        "Ali Sarabadani",
        "Kheirolah Rahsepar Fard",
        "Hamid Dalvand"
      ],
      "abstract": "The paper introduces ExKG-LLM, a framework designed to automate the expansion\nof cognitive neuroscience knowledge graphs (CNKG) using large language models\n(LLMs). It addresses limitations in existing tools by enhancing accuracy,\ncompleteness, and usefulness in CNKG. The framework leverages a large dataset\nof scientific papers and clinical reports, applying state-of-the-art LLMs to\nextract, optimize, and integrate new entities and relationships. Evaluation\nmetrics include precision, recall, and graph density. Results show significant\nimprovements: precision (0.80, +6.67%), recall (0.81, +15.71%), F1 score\n(0.805, +11.81%), and increased edge nodes (21.13% and 31.92%). Graph density\nslightly decreased, reflecting a broader but more fragmented structure.\nEngagement rates rose by 20%, while CNKG diameter increased to 15, indicating a\nmore distributed structure. Time complexity improved to O(n log n), but space\ncomplexity rose to O(n2), indicating higher memory usage. ExKG-LLM demonstrates\npotential for enhancing knowledge generation, semantic search, and clinical\ndecision-making in cognitive neuroscience, adaptable to broader scientific\nfields.",
      "tldr_zh": "本文提出 ExKG-LLM 框架，利用 Large Language Models (LLMs) 自动扩展认知神经科学知识图 (CNKG)，以解决现有工具在准确性、完整性和有用性方面的局限性。该框架基于大型科学论文和临床报告数据集，通过 LLMs 提取、优化并整合新实体和关系。实验结果显示，precision 提高到 0.80 (+6.67%)、recall 到 0.81 (+15.71%)、F1 score 到 0.805 (+11.81%)，边节点增加 21.13% 和 31.92%，尽管图密度略微下降但整体结构更分布化。ExKG-LLM 展示了在知识生成、语义搜索和临床决策中的潜力，并可扩展到更广泛的科学领域。",
      "categories": [
        "cs.AI"
      ],
      "primary_category": "cs.AI",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2503.06479v1",
      "published_date": "2025-03-09 06:32:56 UTC",
      "updated_date": "2025-03-09 06:32:56 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-23T23:54:20.827222"
    },
    {
      "arxiv_id": "2503.06477v1",
      "title": "PDB: Not All Drivers Are the Same -- A Personalized Dataset for Understanding Driving Behavior",
      "title_zh": "PDB：并非所有驾驶员都相同——一个用于理解驾驶行为的个性化数据集",
      "authors": [
        "Chuheng Wei",
        "Ziye Qin",
        "Siyan Li",
        "Ziyan Zhang",
        "Xuanpeng Zhao",
        "Amr Abdelraouf",
        "Rohit Gupta",
        "Kyungtae Han",
        "Matthew J. Barth",
        "Guoyuan Wu"
      ],
      "abstract": "Driving behavior is inherently personal, influenced by individual habits,\ndecision-making styles, and physiological states. However, most existing\ndatasets treat all drivers as homogeneous, overlooking driver-specific\nvariability. To address this gap, we introduce the Personalized Driving\nBehavior (PDB) dataset, a multi-modal dataset designed to capture\npersonalization in driving behavior under naturalistic driving conditions.\nUnlike conventional datasets, PDB minimizes external influences by maintaining\nconsistent routes, vehicles, and lighting conditions across sessions. It\nincludes sources from 128-line LiDAR, front-facing camera video, GNSS, 9-axis\nIMU, CAN bus data (throttle, brake, steering angle), and driver-specific\nsignals such as facial video and heart rate. The dataset features 12\nparticipants, approximately 270,000 LiDAR frames, 1.6 million images, and 6.6\nTB of raw sensor data. The processed trajectory dataset consists of 1,669\nsegments, each spanning 10 seconds with a 0.2-second interval. By explicitly\ncapturing drivers' behavior, PDB serves as a unique resource for human factor\nanalysis, driver identification, and personalized mobility applications,\ncontributing to the development of human-centric intelligent transportation\nsystems.",
      "tldr_zh": "该论文引入了 PDB 数据集，这是一个针对个性化驾驶行为的多人多模态数据集，旨在解决现有数据集忽略驾驶者个体差异（如习惯、决策风格和生理状态）的问题。PDB 通过保持一致的路线、车辆和照明条件，在自然驾驶环境下收集数据，包括 128-line LiDAR、正面摄像头视频、GNSS、9-axis IMU、CAN bus 数据（油门、制动、转向角度）、面部视频和心率等来源。数据集涵盖 12 名参与者，提供约 270,000 LiDAR 帧、1.6 百万图像和 6.6 TB 原始数据，以及 1,669 个 10 秒处理的轨迹段。PDB 的发布有助于人类因素分析、驾驶者识别和个性化移动应用，推动人类中心智能交通系统的开发。",
      "categories": [
        "cs.CV",
        "cs.AI"
      ],
      "primary_category": "cs.CV",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2503.06477v1",
      "published_date": "2025-03-09 06:28:39 UTC",
      "updated_date": "2025-03-09 06:28:39 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-23T23:54:31.797239"
    },
    {
      "arxiv_id": "2503.16486v1",
      "title": "Accodemy: AI Powered Code Learning Platform to Assist Novice Programmers in Overcoming the Fear of Coding",
      "title_zh": "Accodemy：AI 赋能的代码学习平台，帮助初学者程序员克服编码恐惧",
      "authors": [
        "M. A. F. Aamina",
        "V. Kavishcan",
        "W. M. P. B. B. Jayaratne",
        "K. K. D. S. N. Kannangara",
        "A. A. Aamil",
        "Achini Adikari"
      ],
      "abstract": "Computer programming represents a rapidly evolving and sought-after career\npath in the 21st century. Nevertheless, novice learners may find the process\nintimidating for several reasons, such as limited and highly competitive career\nopportunities, peer and parental pressure for academic success, and course\ndifficulties. These factors frequently contribute to anxiety and eventual\ndropout as a result of fear. Furthermore, research has demonstrated that\nbeginners are significantly deterred by the fear of failure, which results in\nprogramming anxiety and and a sense of being overwhelmed by intricate topics,\nultimately leading to dropping out. This project undertakes an exploration\nbeyond the scope of conventional code learning platforms by identifying and\nutilising effective and personalised strategies of learning. The proposed\nsolution incorporates features such as AI-generated challenging questions,\nmindfulness quotes, and tips to motivate users, along with an AI chatbot that\nfunctions as a motivational aid. In addition, the suggested solution integrates\npersonalized roadmaps and gamification elements to maintain user involvement.\nThe project aims to systematically monitor the progress of novice programmers\nand enhance their knowledge of coding with a personalised, revised curriculum\nto help mitigate the fear of coding and boost confidence.",
      "tldr_zh": "该研究探讨了初学者在编程学习中面临的恐惧和焦虑问题，如职业竞争压力和课程难度，导致辍学现象。论文提出 Accodemy，一个 AI 驱动的代码学习平台，通过整合 AI-generated challenging questions、mindfulness quotes、motivational tips 以及 AI chatbot 等个性化策略，帮助用户缓解心理负担。平台还incorporates personalized roadmaps 和 gamification 元素来监控进度并提供定制化课程，最终提升初学者的自信心和编程技能。",
      "categories": [
        "cs.HC",
        "cs.AI",
        "cs.SE"
      ],
      "primary_category": "cs.HC",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2503.16486v1",
      "published_date": "2025-03-09 06:28:06 UTC",
      "updated_date": "2025-03-09 06:28:06 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-23T23:54:42.180558"
    },
    {
      "arxiv_id": "2503.06475v1",
      "title": "SKG-LLM: Developing a Mathematical Model for Stroke Knowledge Graph Construction Using Large Language Models",
      "title_zh": "SKG-LLM：使用大型语言模型开发中风知识图谱构建的数学模型",
      "authors": [
        "Ali Sarabadani",
        "Kheirolah Rahsepar Fard",
        "Hamid Dalvand"
      ],
      "abstract": "The purpose of this study is to introduce SKG-LLM. A knowledge graph (KG) is\nconstructed from stroke-related articles using mathematical and large language\nmodels (LLMs). SKG-LLM extracts and organizes complex relationships from the\nbiomedical literature, using it to increase the accuracy and depth of KG in\nstroke research. In the proposed method, GPT-4 was used for data\npre-processing, and the extraction of embeddings was also done by GPT-4 in the\nwhole KG construction process. The performance of the proposed model was tested\nwith two evaluation criteria: Precision and Recall. For further validation of\nthe proposed model, GPT-4 was used. Compared with Wikidata and WN18RR, the\nproposed KG-LLM approach performs better, especially in precision and recall.\nBy including GPT-4 in the preprocessing process, the SKG-LLM model achieved a\nprecision score of 0.906 and a recall score of 0.923. Expert reviews further\nimproved the results and increased precision to 0.923 and recall to 0.918. The\nknowledge graph constructed by SKG-LLM contains 2692 nodes and 5012 edges,\nwhich are 13 distinct types of nodes and 24 types of edges.",
      "tldr_zh": "这篇论文介绍了SKG-LLM模型，该模型利用大型语言模型(LLMs)和数学方法从中风相关文章构建知识图谱(KG)，以提取并组织生物医学文献中的复杂关系，提高KG的准确性和深度。方法包括使用GPT-4进行数据预处理和嵌入提取，整个KG构建过程得到优化。实验结果显示，SKG-LLM在Precision和Recall指标上优于Wikidata和WN18RR，分别达到0.923和0.918的分数，并构建了一个包含2692个节点、5012个边、13种节点类型和24种边类型的全面KG，为中风研究提供更可靠的知识框架。",
      "categories": [
        "cs.AI",
        "cs.CL"
      ],
      "primary_category": "cs.AI",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2503.06475v1",
      "published_date": "2025-03-09 06:25:37 UTC",
      "updated_date": "2025-03-09 06:25:37 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-23T23:54:55.900952"
    },
    {
      "arxiv_id": "2503.06474v1",
      "title": "HuixiangDou2: A Robustly Optimized GraphRAG Approach",
      "title_zh": "HuixiangDou2：一种鲁棒优化的 GraphRAG 方法",
      "authors": [
        "Huanjun Kong",
        "Zhefan Wang",
        "Chenyang Wang",
        "Zhe Ma",
        "Nanqing Dong"
      ],
      "abstract": "Large Language Models (LLMs) perform well on familiar queries but struggle\nwith specialized or emerging topics. Graph-based Retrieval-Augmented Generation\n(GraphRAG) addresses this by structuring domain knowledge as a graph for\ndynamic retrieval. However, existing pipelines involve complex engineering\nworkflows, making it difficult to isolate the impact of individual components.\nEvaluating retrieval effectiveness is also challenging due to dataset overlap\nwith LLM pretraining data. In this work, we introduce HuixiangDou2, a robustly\noptimized GraphRAG framework. Specifically, we leverage the effectiveness of\ndual-level retrieval and optimize its performance in a 32k context for maximum\nprecision, and compare logic-based retrieval and dual-level retrieval to\nenhance overall functionality. Our implementation includes comparative\nexperiments on a test set, where Qwen2.5-7B-Instruct initially underperformed.\nWith our approach, the score improved significantly from 60 to 74.5, as\nillustrated in the Figure. Experiments on domain-specific datasets reveal that\ndual-level retrieval enhances fuzzy matching, while logic-form retrieval\nimproves structured reasoning. Furthermore, we propose a multi-stage\nverification mechanism to improve retrieval robustness without increasing\ncomputational cost. Empirical results show significant accuracy gains over\nbaselines, highlighting the importance of adaptive retrieval. To support\nresearch and adoption, we release HuixiangDou2 as an open-source resource\nhttps://github.com/tpoisonooo/huixiangdou2.",
      "tldr_zh": "该论文介绍了 HuixiangDou2，一种优化后的 GraphRAG 框架，旨在解决 Large Language Models (LLMs) 在专业或新兴主题上的表现不足问题，通过构建知识图谱实现动态检索。框架重点优化了 dual-level retrieval 在 32k 上下文中的性能，并比较了 logic-based retrieval 与 dual-level retrieval，以提升整体功能和精确度。实验结果显示，在测试集上 Qwen2.5-7B-Instruct 的分数从 60 提升至 74.5，且在领域特定数据集上，dual-level retrieval 改善了模糊匹配，而 logic-form retrieval 增强了结构化推理。同时，论文提出多阶段验证机制，提高了检索鲁棒性而不增加计算成本，并开源了代码以支持进一步研究。",
      "categories": [
        "cs.IR",
        "cs.AI",
        "cs.CL"
      ],
      "primary_category": "cs.IR",
      "comment": "11 pages",
      "pdf_url": "http://arxiv.org/pdf/2503.06474v1",
      "published_date": "2025-03-09 06:20:24 UTC",
      "updated_date": "2025-03-09 06:20:24 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-23T23:55:08.066980"
    },
    {
      "arxiv_id": "2503.06473v4",
      "title": "Enhancing Layer Attention Efficiency through Pruning Redundant Retrievals",
      "title_zh": "通过修剪冗余检索增强层注意力效率",
      "authors": [
        "Hanze Li",
        "Xiande Huang"
      ],
      "abstract": "Growing evidence suggests that layer attention mechanisms, which enhance\ninteraction among layers in deep neural networks, have significantly advanced\nnetwork architectures. However, existing layer attention methods suffer from\nredundancy, as attention weights learned by adjacent layers often become highly\nsimilar. This redundancy causes multiple layers to extract nearly identical\nfeatures, reducing the model's representational capacity and increasing\ntraining time. To address this issue, we propose a novel approach to quantify\nredundancy by leveraging the Kullback-Leibler (KL) divergence between adjacent\nlayers. Additionally, we introduce an Enhanced Beta Quantile Mapping (EBQM)\nmethod that accurately identifies and skips redundant layers, thereby\nmaintaining model stability. Our proposed Efficient Layer Attention (ELA)\narchitecture, improves both training efficiency and overall performance,\nachieving a 30% reduction in training time while enhancing performance in tasks\nsuch as image classification and object detection.",
      "tldr_zh": "现有层注意力机制在深度神经网络中提升了层间交互，但相邻层的注意力权重相似导致冗余，影响模型表示能力和训练效率。为解决此问题，论文提出使用Kullback-Leibler (KL) 散度量化相邻层冗余，并引入Enhanced Beta Quantile Mapping (EBQM) 方法来识别并跳过冗余层，从而维持模型稳定性。最终，Efficient Layer Attention (ELA) 架构实现了训练时间减少30%，并在图像分类和物体检测任务中提升了整体性能。",
      "categories": [
        "cs.CV",
        "cs.AI"
      ],
      "primary_category": "cs.CV",
      "comment": "11 pages, 7 figures",
      "pdf_url": "http://arxiv.org/pdf/2503.06473v4",
      "published_date": "2025-03-09 06:20:11 UTC",
      "updated_date": "2025-05-10 09:08:26 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-23T23:55:18.222443"
    },
    {
      "arxiv_id": "2503.10663v1",
      "title": "Optimal Transport for Brain-Image Alignment: Unveiling Redundancy and Synergy in Neural Information Processing",
      "title_zh": "脑图像对齐的最优传输：揭示神经信息处理中的冗余性和协同性",
      "authors": [
        "Yang Xiao",
        "Wang Lu",
        "Jie Ji",
        "Ruimeng Ye",
        "Gen Li",
        "Xiaolong Ma",
        "Bo Hui"
      ],
      "abstract": "The design of artificial neural networks (ANNs) is inspired by the structure\nof the human brain, and in turn, ANNs offer a potential means to interpret and\nunderstand brain signals. Existing methods primarily align brain signals with\nreal-world signals using Mean Squared Error (MSE), which solely focuses on\nlocal point-wise alignment, and ignores global matching, leading to coarse\ninterpretations and inaccuracies in brain signal decoding.\n  In this paper, we address these issues through optimal transport (OT) and\ntheoretically demonstrate why OT provides a more effective alignment strategy\nthan MSE. Specifically, we construct a transport plan between brain voxel\nembeddings and image embeddings, enabling more precise matching. By controlling\nthe amount of transport, we mitigate the influence of redundant information. We\napply our alignment model directly to the Brain Captioning task by feeding\nbrain siginals into a large language model (LLM) instead of images. Our\napproach achieves state-of-the-art performance across ten evaluation metrics,\nsurpassing the previous best method by an average of 6.11\\% in single-subject\ntraining and 3.81\\% in cross-subject training. Additionally, we have uncovered\nseveral insightful conclusions that align with existing brain research. We\nunveil the redundancy and synergy of brain information processing through\nregion masking and data dimensionality reduction visualization experiments. We\nbelieve our approach paves the way for a more precise understanding of brain\nsignals in the future. The code is available soon.",
      "tldr_zh": "本文提出使用Optimal Transport (OT)取代传统的Mean Squared Error (MSE)来对齐脑信号和图像嵌入，解决现有方法忽略全局匹配导致的解读不准确问题，并理论证明OT的优越性。通过构建脑体素嵌入与图像嵌入的传输计划并控制传输量，减少冗余信息影响，并将模型应用于Brain Captioning任务，将脑信号输入Large Language Model (LLM)。实验结果显示，该方法在十个评估指标上达到最先进性能，单主体训练比前最佳方法提高6.11%，跨主体训练提高3.81%。此外，通过区域屏蔽和数据维数减少可视化实验，揭示了脑信息处理的冗余性和协同性，为未来更精确理解脑信号铺平道路。",
      "categories": [
        "q-bio.NC",
        "cs.AI",
        "cs.CV",
        "cs.LG"
      ],
      "primary_category": "q-bio.NC",
      "comment": "14pages",
      "pdf_url": "http://arxiv.org/pdf/2503.10663v1",
      "published_date": "2025-03-09 06:14:23 UTC",
      "updated_date": "2025-03-09 06:14:23 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-23T23:55:31.874531"
    },
    {
      "arxiv_id": "2503.06470v1",
      "title": "Think Twice, Click Once: Enhancing GUI Grounding via Fast and Slow Systems",
      "title_zh": "翻译失败",
      "authors": [
        "Fei Tang",
        "Yongliang Shen",
        "Hang Zhang",
        "Siqi Chen",
        "Guiyang Hou",
        "Wenqi Zhang",
        "Wenqiao Zhang",
        "Kaitao Song",
        "Weiming Lu",
        "Yueting Zhuang"
      ],
      "abstract": "Humans can flexibly switch between different modes of thinking based on task\ncomplexity: from rapid intuitive judgments to in-depth analytical\nunderstanding. However, current Graphical User Interface (GUI) grounding\nsystems which locate interface elements based on natural language instructions\nrely solely on immediate prediction without reasoning, struggling to understand\ncomplex interface layouts with nested structures and hierarchical\nrelationships, limiting their effectiveness on complex interfaces. Inspired by\nhuman dual-system cognition, we present Focus, a novel GUI grounding framework\nthat combines fast prediction with systematic analysis. The framework\ndynamically switches between rapid and deliberate processing through an\nadaptive system switching based on task complexity, optimizing both efficiency\nand accuracy. Focus decomposes grounding into progressive stages: interface\nsummarization, visual focused analysis, and precise coordinate prediction. This\nstructured decomposition enables systematic understanding of both interface\nlayouts and visual relationships. Extensive experiments show that Focus\nachieves state-of-the-art performance using only 300K of the training data with\na 2B parameter model compared to existing approaches. Focus demonstrates\nsuperior performance particularly in complex GUI scenarios, achieving 77.4%\naverage accuracy on ScreenSpot and 13.3% on the more challenging\nScreenSpot-Pro. Our analysis reveals the effectiveness of this dual-system\napproach while demonstrating its potential for improving complex GUI\ninteraction scenarios.",
      "tldr_zh": "该论文提出 Focus 框架，受人类双系统认知（快速直觉和缓慢分析）启发，用于提升 GUI 定位系统的性能，通过动态切换处理模式来优化复杂界面布局的理解和准确性。框架将 GUI 定位分解为三个阶段：界面总结、视觉焦点分析和精确坐标预测，从而系统化处理嵌套结构和层次关系。实验结果显示，Focus 使用仅 300K 数据和 2B 参数模型，在 ScreenSpot 上达到 77.4% 平均准确率，并在 ScreenSpot-Pro 上提升 13.3%，证明了双系统方法在复杂 GUI 交互场景中的显著优势。",
      "categories": [
        "cs.AI",
        "cs.CL",
        "cs.CV"
      ],
      "primary_category": "cs.AI",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2503.06470v1",
      "published_date": "2025-03-09 06:14:17 UTC",
      "updated_date": "2025-03-09 06:14:17 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-23T23:55:43.246633"
    },
    {
      "arxiv_id": "2503.08704v1",
      "title": "Life-Cycle Routing Vulnerabilities of LLM Router",
      "title_zh": "LLM 路由器的生命周期路由漏洞",
      "authors": [
        "Qiqi Lin",
        "Xiaoyang Ji",
        "Shengfang Zhai",
        "Qingni Shen",
        "Zhi Zhang",
        "Yuejian Fang",
        "Yansong Gao"
      ],
      "abstract": "Large language models (LLMs) have achieved remarkable success in natural\nlanguage processing, yet their performance and computational costs vary\nsignificantly. LLM routers play a crucial role in dynamically balancing these\ntrade-offs. While previous studies have primarily focused on routing\nefficiency, security vulnerabilities throughout the entire LLM router life\ncycle, from training to inference, remain largely unexplored. In this paper, we\npresent a comprehensive investigation into the life-cycle routing\nvulnerabilities of LLM routers. We evaluate both white-box and black-box\nadversarial robustness, as well as backdoor robustness, across several\nrepresentative routing models under extensive experimental settings. Our\nexperiments uncover several key findings: 1) Mainstream DNN-based routers tend\nto exhibit the weakest adversarial and backdoor robustness, largely due to\ntheir strong feature extraction capabilities that amplify vulnerabilities\nduring both training and inference; 2) Training-free routers demonstrate the\nstrongest robustness across different attack types, benefiting from the absence\nof learnable parameters that can be manipulated. These findings highlight\ncritical security risks spanning the entire life cycle of LLM routers and\nprovide insights for developing more robust models.",
      "tldr_zh": "本研究调查了LLM路由器的生命周期安全漏洞，从训练到推理阶段，重点评估了白盒、黑盒对抗鲁棒性和后门鲁棒性在多个代表性路由模型上的表现。实验发现，主流DNN-based路由器因其强大的特征提取能力而表现出最弱的对抗和后门鲁棒性，导致漏洞在训练和推理中被放大；相比之下，无需训练的路由器由于缺乏可学习参数而显示出最强的鲁棒性。这些结果揭示了LLM路由器生命周期的安全风险，并为设计更可靠的路由模型提供了关键洞见。",
      "categories": [
        "cs.CR",
        "cs.AI"
      ],
      "primary_category": "cs.CR",
      "comment": "Work in progress",
      "pdf_url": "http://arxiv.org/pdf/2503.08704v1",
      "published_date": "2025-03-09 06:00:35 UTC",
      "updated_date": "2025-03-09 06:00:35 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-23T23:55:55.373076"
    },
    {
      "arxiv_id": "2503.06462v1",
      "title": "StructGS: Adaptive Spherical Harmonics and Rendering Enhancements for Superior 3D Gaussian Splatting",
      "title_zh": "翻译失败",
      "authors": [
        "Zexu Huang",
        "Min Xu",
        "Stuart Perry"
      ],
      "abstract": "Recent advancements in 3D reconstruction coupled with neural rendering\ntechniques have greatly improved the creation of photo-realistic 3D scenes,\ninfluencing both academic research and industry applications. The technique of\n3D Gaussian Splatting and its variants incorporate the strengths of both\nprimitive-based and volumetric representations, achieving superior rendering\nquality. While 3D Geometric Scattering (3DGS) and its variants have advanced\nthe field of 3D representation, they fall short in capturing the stochastic\nproperties of non-local structural information during the training process.\nAdditionally, the initialisation of spherical functions in 3DGS-based methods\noften fails to engage higher-order terms in early training rounds, leading to\nunnecessary computational overhead as training progresses. Furthermore, current\n3DGS-based approaches require training on higher resolution images to render\nhigher resolution outputs, significantly increasing memory demands and\nprolonging training durations. We introduce StructGS, a framework that enhances\n3D Gaussian Splatting (3DGS) for improved novel-view synthesis in 3D\nreconstruction. StructGS innovatively incorporates a patch-based SSIM loss,\ndynamic spherical harmonics initialisation and a Multi-scale Residual Network\n(MSRN) to address the above-mentioned limitations, respectively. Our framework\nsignificantly reduces computational redundancy, enhances detail capture and\nsupports high-resolution rendering from low-resolution inputs. Experimentally,\nStructGS demonstrates superior performance over state-of-the-art (SOTA) models,\nachieving higher quality and more detailed renderings with fewer artifacts.",
      "tldr_zh": "该研究提出了 StructGS 框架，以提升 3D Gaussian Splatting (3DGS) 在 3D 重建中的性能，针对其在捕获非局部结构信息、球谐函数初始化效率和分辨率需求方面的不足。\nStructGS 创新性地整合了基于 patch 的 SSIM loss、动态 spherical harmonics 初始化以及 Multi-scale Residual Network (MSRN)，从而减少计算开销、增强细节捕捉，并实现从低分辨率输入到高分辨率渲染的转换。\n实验结果表明，StructGS 超过了现有最先进模型，在 novel-view synthesis 任务上提供更高质量、更详细的渲染输出和更少的 artifacts。",
      "categories": [
        "cs.CV",
        "cs.AI"
      ],
      "primary_category": "cs.CV",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2503.06462v1",
      "published_date": "2025-03-09 05:39:44 UTC",
      "updated_date": "2025-03-09 05:39:44 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-23T23:56:08.549384"
    },
    {
      "arxiv_id": "2503.06457v2",
      "title": "Geometric Knowledge-Guided Localized Global Distribution Alignment for Federated Learning",
      "title_zh": "几何知识引导的本地化全局分布对齐用于联邦学习",
      "authors": [
        "Yanbiao Ma",
        "Wei Dai",
        "Wenke Huang",
        "Jiayi Chen"
      ],
      "abstract": "Data heterogeneity in federated learning, characterized by a significant\nmisalignment between local and global distributions, leads to divergent local\noptimization directions and hinders global model training. Existing studies\nmainly focus on optimizing local updates or global aggregation, but these\nindirect approaches demonstrate instability when handling highly heterogeneous\ndata distributions, especially in scenarios where label skew and domain skew\ncoexist. To address this, we propose a geometry-guided data generation method\nthat centers on simulating the global embedding distribution locally. We first\nintroduce the concept of the geometric shape of an embedding distribution and\nthen address the challenge of obtaining global geometric shapes under privacy\nconstraints. Subsequently, we propose GGEUR, which leverages global geometric\nshapes to guide the generation of new samples, enabling a closer approximation\nto the ideal global distribution. In single-domain scenarios, we augment\nsamples based on global geometric shapes to enhance model generalization; in\nmulti-domain scenarios, we further employ class prototypes to simulate the\nglobal distribution across domains. Extensive experimental results demonstrate\nthat our method significantly enhances the performance of existing approaches\nin handling highly heterogeneous data, including scenarios with label skew,\ndomain skew, and their coexistence. Code published at:\nhttps://github.com/WeiDai-David/2025CVPR_GGEUR",
      "tldr_zh": "该论文针对联邦学习中数据异质性问题（如本地和全局分布不对齐导致的优化方向分歧），提出了一种基于几何知识引导的本地数据生成方法。核心方法 GGEUR 利用嵌入分布的几何形状概念，通过生成新样本模拟全局分布，同时在隐私约束下处理全局几何形状的获取挑战；在单域场景下增强样本以提高模型泛化，在多域场景下结合类原型模拟跨域分布。实验结果显示，GGEUR 显著提升了现有方法的性能，尤其在 label skew、domain skew 及其共存的高异质环境中。",
      "categories": [
        "cs.CV",
        "cs.AI"
      ],
      "primary_category": "cs.CV",
      "comment": "Accepted by CVPR Oral 2025",
      "pdf_url": "http://arxiv.org/pdf/2503.06457v2",
      "published_date": "2025-03-09 05:30:28 UTC",
      "updated_date": "2025-05-05 11:38:40 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-23T23:56:20.135996"
    },
    {
      "arxiv_id": "2503.06444v1",
      "title": "CtrTab: Tabular Data Synthesis with High-Dimensional and Limited Data",
      "title_zh": "翻译失败",
      "authors": [
        "Zuqing Li",
        "Jianzhong Qi",
        "Junhao Gan"
      ],
      "abstract": "Diffusion-based tabular data synthesis models have yielded promising results.\nHowever, we observe that when the data dimensionality increases, existing\nmodels tend to degenerate and may perform even worse than simpler,\nnon-diffusion-based models. This is because limited training samples in\nhigh-dimensional space often hinder generative models from capturing the\ndistribution accurately. To address this issue, we propose CtrTab-a condition\ncontrolled diffusion model for tabular data synthesis-to improve the\nperformance of diffusion-based generative models in high-dimensional, low-data\nscenarios. Through CtrTab, we inject samples with added Laplace noise as\ncontrol signals to improve data diversity and show its resemblance to L2\nregularization, which enhances model robustness. Experimental results across\nmultiple datasets show that CtrTab outperforms state-of-the-art models, with\nperformance gap in accuracy over 80% on average. Our source code will be\nreleased upon paper publication.",
      "tldr_zh": "该研究发现，基于扩散的表格数据合成模型在高维数据和有限样本场景下表现不佳，常不如简单非扩散模型，因为难以准确捕捉数据分布。为解决此问题，提出 CtrTab，一种条件控制的扩散模型，通过注入带有 Laplace 噪声的样本作为控制信号，提高数据多样性和模型鲁棒性，其机制类似于 L2 正则化。实验结果显示，CtrTab 在多个数据集上优于最先进模型，准确性平均提升超过 80%。",
      "categories": [
        "cs.LG",
        "cs.AI",
        "cs.DB"
      ],
      "primary_category": "cs.LG",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2503.06444v1",
      "published_date": "2025-03-09 05:01:56 UTC",
      "updated_date": "2025-03-09 05:01:56 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-23T23:56:31.137090"
    },
    {
      "arxiv_id": "2503.06436v1",
      "title": "Physics-Informed Residual Neural Ordinary Differential Equations for Enhanced Tropical Cyclone Intensity Forecasting",
      "title_zh": "基于物理信息的",
      "authors": [
        "Fan Meng"
      ],
      "abstract": "Accurate tropical cyclone (TC) intensity prediction is crucial for mitigating\nstorm hazards, yet its complex dynamics pose challenges to traditional methods.\nHere, we introduce a Physics-Informed Residual Neural Ordinary Differential\nEquation (PIR-NODE) model to precisely forecast TC intensity evolution. This\nmodel leverages the powerful non-linear fitting capabilities of deep learning,\nintegrates residual connections to enhance model depth and training stability,\nand explicitly models the continuous temporal evolution of TC intensity using\nNeural ODEs. Experimental results in the SHIPS dataset demonstrate that the\nPIR-NODE model achieves a significant improvement in 24-hour intensity\nprediction accuracy compared to traditional statistical models and benchmark\ndeep learning methods, with a 25. 2\\% reduction in the root mean square error\n(RMSE) and a 19.5\\% increase in R-square (R2) relative to a baseline of neural\nnetwork. Crucially, the residual structure effectively preserves initial state\ninformation, and the model exhibits robust generalization capabilities. This\nstudy details the PIR-NODE model architecture, physics-informed integration\nstrategies, and comprehensive experimental validation, revealing the\nsubstantial potential of deep learning techniques in predicting complex\ngeophysical systems and laying the foundation for future refined TC forecasting\nresearch.",
      "tldr_zh": "本研究提出了一种Physics-Informed Residual Neural Ordinary Differential Equations (PIR-NODE) 模型，用于提升热带气旋 (TC) 强度预测的准确性，以应对传统方法的挑战。模型整合了深度学习的非线性拟合能力、残差连接以提高模型深度和训练稳定性，以及Neural ODEs来显式模拟TC强度的连续时间演变。实验结果显示，在SHIPS数据集上，PIR-NODE在24小时强度预测中比基准神经网络模型降低了25.2%的根均方误差 (RMSE) 和提高了19.5%的R平方 (R2)，并展示了良好的泛化能力和初始状态保留效果。该方法为预测复杂地球物理系统提供了新框架，并为未来TC预报研究奠定基础。",
      "categories": [
        "physics.ao-ph",
        "cs.AI"
      ],
      "primary_category": "physics.ao-ph",
      "comment": "14 pages, 9 figures",
      "pdf_url": "http://arxiv.org/pdf/2503.06436v1",
      "published_date": "2025-03-09 04:23:07 UTC",
      "updated_date": "2025-03-09 04:23:07 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-23T23:56:44.958496"
    },
    {
      "arxiv_id": "2503.06433v1",
      "title": "Seesaw: High-throughput LLM Inference via Model Re-sharding",
      "title_zh": "翻译失败",
      "authors": [
        "Qidong Su",
        "Wei Zhao",
        "Xin Li",
        "Muralidhar Andoorveedu",
        "Chenhao Jiang",
        "Zhanda Zhu",
        "Kevin Song",
        "Christina Giannoula",
        "Gennady Pekhimenko"
      ],
      "abstract": "To improve the efficiency of distributed large language model (LLM)\ninference, various parallelization strategies, such as tensor and pipeline\nparallelism, have been proposed. However, the distinct computational\ncharacteristics inherent in the two stages of LLM inference-prefilling and\ndecoding-render a single static parallelization strategy insufficient for the\neffective optimization of both stages. In this work, we present Seesaw, an LLM\ninference engine optimized for throughput-oriented tasks. The key idea behind\nSeesaw is dynamic model re-sharding, a technique that facilitates the dynamic\nreconfiguration of parallelization strategies across stages, thereby maximizing\nthroughput at both phases. To mitigate re-sharding overhead and optimize\ncomputational efficiency, we employ tiered KV cache buffering and\ntransition-minimizing scheduling. These approaches work synergistically to\nreduce the overhead caused by frequent stage transitions while ensuring maximum\nbatching efficiency. Our evaluation demonstrates that Seesaw achieves a\nthroughput increase of up to 1.78x (1.36x on average) compared to vLLM, the\nmost widely used state-of-the-art LLM inference engine.",
      "tldr_zh": "该研究提出Seesaw，一种针对大语言模型(LLM)推理的高吞吐量引擎，通过dynamic model re-sharding技术动态调整并行策略，以优化prefilling和decoding两个阶段的计算特性。Seesaw采用tiered KV cache buffering和transition-minimizing scheduling来减少重新分片开销，并提升批量处理效率。实验结果显示，与最先进的vLLM引擎相比，Seesaw的吞吐量平均提高1.36倍，最高达1.78倍。",
      "categories": [
        "cs.DC",
        "cs.AI"
      ],
      "primary_category": "cs.DC",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2503.06433v1",
      "published_date": "2025-03-09 04:14:06 UTC",
      "updated_date": "2025-03-09 04:14:06 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-23T23:56:55.499278"
    },
    {
      "arxiv_id": "2503.06430v1",
      "title": "Graph Retrieval-Augmented LLM for Conversational Recommendation Systems",
      "title_zh": "图检索增强型 LLM 用于对话推荐系统",
      "authors": [
        "Zhangchi Qiu",
        "Linhao Luo",
        "Zicheng Zhao",
        "Shirui Pan",
        "Alan Wee-Chung Liew"
      ],
      "abstract": "Conversational Recommender Systems (CRSs) have emerged as a transformative\nparadigm for offering personalized recommendations through natural language\ndialogue. However, they face challenges with knowledge sparsity, as users often\nprovide brief, incomplete preference statements. While recent methods have\nintegrated external knowledge sources to mitigate this, they still struggle\nwith semantic understanding and complex preference reasoning. Recent Large\nLanguage Models (LLMs) demonstrate promising capabilities in natural language\nunderstanding and reasoning, showing significant potential for CRSs.\nNevertheless, due to the lack of domain knowledge, existing LLM-based CRSs\neither produce hallucinated recommendations or demand expensive domain-specific\ntraining, which largely limits their applicability. In this work, we present\nG-CRS (Graph Retrieval-Augmented Large Language Model for Conversational\nRecommender Systems), a novel training-free framework that combines graph\nretrieval-augmented generation and in-context learning to enhance LLMs'\nrecommendation capabilities. Specifically, G-CRS employs a two-stage\nretrieve-and-recommend architecture, where a GNN-based graph reasoner first\nidentifies candidate items, followed by Personalized PageRank exploration to\njointly discover potential items and similar user interactions. These retrieved\ncontexts are then transformed into structured prompts for LLM reasoning,\nenabling contextually grounded recommendations without task-specific training.\nExtensive experiments on two public datasets show that G-CRS achieves superior\nrecommendation performance compared to existing methods without requiring\ntask-specific training.",
      "tldr_zh": "该研究提出G-CRS（Graph Retrieval-Augmented LLM for Conversational Recommendation Systems），一个无需特定训练的框架，用于解决对话推荐系统（Conversational Recommender Systems, CRSs）中知识稀疏和偏好推理的挑战。G-CRS采用两阶段架构：首先利用GNN-based graph reasoner识别候选物品，并通过Personalized PageRank探索潜在物品和类似用户互动；随后，将检索到的上下文转化为结构化提示，结合In-Context Learning增强LLM的推荐能力。实验在两个公共数据集上显示，G-CRS比现有方法实现了更高的推荐性能，同时避免了幻觉问题和昂贵的领域训练。",
      "categories": [
        "cs.CL",
        "cs.AI",
        "cs.IR"
      ],
      "primary_category": "cs.CL",
      "comment": "Accepted by PAKDD 2025",
      "pdf_url": "http://arxiv.org/pdf/2503.06430v1",
      "published_date": "2025-03-09 03:56:22 UTC",
      "updated_date": "2025-03-09 03:56:22 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-23T23:57:08.763037"
    },
    {
      "arxiv_id": "2503.06427v1",
      "title": "Pre-Training Meta-Rule Selection Policy for Visual Generative Abductive Learning",
      "title_zh": "翻译失败",
      "authors": [
        "Yu Jin",
        "Jingming Liu",
        "Zhexu Luo",
        "Yifei Peng",
        "Ziang Qin",
        "Wang-Zhou Dai",
        "Yao-Xiang Ding",
        "Kun Zhou"
      ],
      "abstract": "Visual generative abductive learning studies jointly training symbol-grounded\nneural visual generator and inducing logic rules from data, such that after\nlearning, the visual generation process is guided by the induced logic rules. A\nmajor challenge for this task is to reduce the time cost of logic abduction\nduring learning, an essential step when the logic symbol set is large and the\nlogic rule to induce is complicated. To address this challenge, we propose a\npre-training method for obtaining meta-rule selection policy for the recently\nproposed visual generative learning approach AbdGen [Peng et al., 2023], aiming\nat significantly reducing the candidate meta-rule set and pruning the search\nspace. The selection model is built based on the embedding representation of\nboth symbol grounding of cases and meta-rules, which can be effectively\nintegrated with both neural model and logic reasoning system. The pre-training\nprocess is done on pure symbol data, not involving symbol grounding learning of\nraw visual inputs, making the entire learning process low-cost. An additional\ninteresting observation is that the selection policy can rectify symbol\ngrounding errors unseen during pre-training, which is resulted from the\nmemorization ability of attention mechanism and the relative stability of\nsymbolic patterns. Experimental results show that our method is able to\neffectively address the meta-rule selection problem for visual abduction,\nboosting the efficiency of visual generative abductive learning. Code is\navailable at https://github.com/future-item/metarule-select.",
      "tldr_zh": "该论文针对视觉生成归纳学习（Visual Generative Abductive Learning）中逻辑归纳过程的计算成本问题，提出了一种预训练 meta-rule selection policy 方法，以减少候选元规则集并缩小搜索空间。该方法基于符号地锚定（symbol grounding）和元规则的嵌入表示构建选择模型，能够有效整合神经模型和逻辑推理系统，且预训练仅在纯符号数据上进行，从而降低整体学习成本。论文还发现，该策略能通过注意力机制的记忆能力和符号模式稳定性，修正预训练中未见的符号地锚定错误。实验结果显示，该方法显著提高了视觉生成归纳学习的效率，代码已在 GitHub 上开源。",
      "categories": [
        "cs.LG",
        "cs.AI",
        "cs.CV"
      ],
      "primary_category": "cs.LG",
      "comment": "Published as a conference paper at IJCLR'24",
      "pdf_url": "http://arxiv.org/pdf/2503.06427v1",
      "published_date": "2025-03-09 03:41:11 UTC",
      "updated_date": "2025-03-09 03:41:11 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-23T23:57:22.106344"
    },
    {
      "arxiv_id": "2503.06422v1",
      "title": "GenAI for Simulation Model in Model-Based Systems Engineering",
      "title_zh": "翻译失败",
      "authors": [
        "Lin Zhang",
        "Yuteng Zhang",
        "Dusit Niyato",
        "Lei Ren",
        "Pengfei Gu",
        "Zhen Chen",
        "Yuanjun Laili",
        "Wentong Cai",
        "Agostino Bruzzone"
      ],
      "abstract": "Generative AI (GenAI) has demonstrated remarkable capabilities in code\ngeneration, and its integration into complex product modeling and simulation\ncode generation can significantly enhance the efficiency of the system design\nphase in Model-Based Systems Engineering (MBSE). In this study, we introduce a\ngenerative system design methodology framework for MBSE, offering a practical\napproach for the intelligent generation of simulation models for system\nphysical properties. First, we employ inference techniques, generative models,\nand integrated modeling and simulation languages to construct simulation models\nfor system physical properties based on product design documents. Subsequently,\nwe fine-tune the language model used for simulation model generation on an\nexisting library of simulation models and additional datasets generated through\ngenerative modeling. Finally, we introduce evaluation metrics for the generated\nsimulation models for system physical properties. Our proposed approach to\nsimulation model generation presents the innovative concept of scalable\ntemplates for simulation models. Using these templates, GenAI generates\nsimulation models for system physical properties through code completion. The\nexperimental results demonstrate that, for mainstream open-source\nTransformer-based models, the quality of the simulation model is significantly\nimproved using the simulation model generation method proposed in this paper.",
      "tldr_zh": "这篇论文探讨了 Generative AI (GenAI) 在 Model-Based Systems Engineering (MBSE) 中的应用，提出一个框架用于高效生成系统物理属性模拟模型，从而提升系统设计阶段的效率。方法包括利用推理技术、生成模型和集成建模语言基于产品设计文档构建模拟模型，并通过微调语言模型和可扩展模板实现代码完成式的模型生成。实验结果表明，该方法显著提高了主流开源 Transformer-based 模型的模拟模型质量，为智能系统设计提供了创新性解决方案。",
      "categories": [
        "cs.SE",
        "cs.AI"
      ],
      "primary_category": "cs.SE",
      "comment": "This work has been submitted to the IEEE for possible publication",
      "pdf_url": "http://arxiv.org/pdf/2503.06422v1",
      "published_date": "2025-03-09 03:33:25 UTC",
      "updated_date": "2025-03-09 03:33:25 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-23T23:57:31.223114"
    },
    {
      "arxiv_id": "2503.06420v2",
      "title": "Explaining Control Policies through Predicate Decision Diagrams",
      "title_zh": "通过谓词决策图解释控制策略",
      "authors": [
        "Debraj Chakraborty",
        "Clemens Dubslaff",
        "Sudeep Kanav",
        "Jan Kretinsky",
        "Christoph Weinhuber"
      ],
      "abstract": "Safety-critical controllers of complex systems are hard to construct\nmanually. Automated approaches such as controller synthesis or learning provide\na tempting alternative but usually lack explainability. To this end, learning\ndecision trees (DTs) have been prevalently used towards an interpretable model\nof the generated controllers. However, DTs do not exploit shared\ndecision-making, a key concept exploited in binary decision diagrams (BDDs) to\nreduce their size and thus improve explainability. In this work, we introduce\npredicate decision diagrams (PDDs) that extend BDDs with predicates and thus\nunite the advantages of DTs and BDDs for controller representation. We\nestablish a synthesis pipeline for efficient construction of PDDs from DTs\nrepresenting controllers, exploiting reduction techniques for BDDs also for\nPDDs.",
      "tldr_zh": "安全关键控制器的手动构建困难，而自动化方法如控制器合成或学习通常缺乏可解释性，因此本文引入谓词决策图 (PDDs)，它扩展了二进制决策图 (BDDs) 以包含谓词，结合了决策树 (DTs) 的可解释性优势和 BDDs 的共享决策机制。PDDs 能够更有效地表示控制器模型，从而减少大小并提升解释性。本文还提出一个从 DTs 合成 PDDs 的管道，利用 BDDs 的减少技术来优化构建过程。",
      "categories": [
        "cs.AI",
        "cs.SY",
        "eess.SY"
      ],
      "primary_category": "cs.AI",
      "comment": "Extended version of the HSCC 2025 paper",
      "pdf_url": "http://arxiv.org/pdf/2503.06420v2",
      "published_date": "2025-03-09 03:31:48 UTC",
      "updated_date": "2025-03-25 16:57:55 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-23T23:57:43.704520"
    },
    {
      "arxiv_id": "2503.06416v1",
      "title": "Advancing AI Negotiations: New Theory and Evidence from a Large-Scale Autonomous Negotiations Competition",
      "title_zh": "推进 AI 谈判：来自大规模自治谈判竞赛的新理论和证据",
      "authors": [
        "Michelle Vaccaro",
        "Michael Caoson",
        "Harang Ju",
        "Sinan Aral",
        "Jared R. Curhan"
      ],
      "abstract": "Despite the rapid proliferation of artificial intelligence (AI) negotiation\nagents, there has been limited integration of computer science research and\nestablished negotiation theory to develop new theories of AI negotiation. To\nbridge this gap, we conducted an International AI Negotiations Competition in\nwhich participants iteratively designed and refined prompts for large language\nmodel (LLM) negotiation agents. We then facilitated over 120,000 negotiations\nbetween these agents across multiple scenarios with diverse characteristics and\nobjectives. Our findings revealed that fundamental principles from established\nhuman-human negotiation theory remain crucial in AI-AI negotiations.\nSpecifically, agents exhibiting high warmth fostered higher counterpart\nsubjective value and reached deals more frequently, which enabled them to\ncreate and claim more value in integrative settings. However, conditional on\nreaching a deal, warm agents claimed less value while dominant agents claimed\nmore value. These results align with classic negotiation theory emphasizing\nrelationship-building, assertiveness, and preparation. Our analysis also\nrevealed unique dynamics in AI-AI negotiations not fully explained by\nnegotiation theory, particularly regarding the effectiveness of AI-specific\nstrategies like chain-of-thought reasoning and prompt injection. The agent that\nwon our competition implemented an approach that blended traditional\nnegotiation preparation frameworks with AI-specific methods. Together, these\nresults suggest the importance of establishing a new theory of AI negotiations\nthat integrates established negotiation theory with AI-specific strategies to\noptimize agent performance. Our research suggests this new theory must account\nfor the unique characteristics of autonomous agents and establish the\nconditions under which traditional negotiation theory applies in automated\nsettings.",
      "tldr_zh": "该研究通过举办国际AI谈判竞赛，组织参与者设计和优化LLM谈判代理，并进行超过12万次AI-AI谈判实验，桥接了计算机科学与传统谈判理论的差距。结果显示，传统谈判理论的核心原则（如高温暖度代理能提升主观价值、促进交易并在整合环境中创造更多价值）在AI谈判中依然适用，但温暖代理在达成交易后获取价值较少，而主导性代理则获取更多。实验还揭示了AI特有动态，例如chain-of-thought reasoning和prompt injection策略的有效性，获胜代理则结合了传统准备框架与AI特定方法。这些发现强调了建立新AI谈判理论的必要性，该理论需整合现有谈判理论并考虑自主代理的独特特性，以优化AI表现。",
      "categories": [
        "cs.AI",
        "cs.HC"
      ],
      "primary_category": "cs.AI",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2503.06416v1",
      "published_date": "2025-03-09 03:25:48 UTC",
      "updated_date": "2025-03-09 03:25:48 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-23T23:57:56.285788"
    },
    {
      "arxiv_id": "2503.06413v2",
      "title": "Swift Hydra: Self-Reinforcing Generative Framework for Anomaly Detection with Multiple Mamba Models",
      "title_zh": "翻译失败",
      "authors": [
        "Nguyen Do",
        "Truc Nguyen",
        "Malik Hassanaly",
        "Raed Alharbi",
        "Jung Taek Seo",
        "My T. Thai"
      ],
      "abstract": "Despite a plethora of anomaly detection models developed over the years,\ntheir ability to generalize to unseen anomalies remains an issue, particularly\nin critical systems. This paper aims to address this challenge by introducing\nSwift Hydra, a new framework for training an anomaly detection method based on\ngenerative AI and reinforcement learning (RL). Through featuring an RL policy\nthat operates on the latent variables of a generative model, the framework\nsynthesizes novel and diverse anomaly samples that are capable of bypassing a\ndetection model. These generated synthetic samples are, in turn, used to\naugment the detection model, further improving its ability to handle\nchallenging anomalies. Swift Hydra also incorporates Mamba models structured as\na Mixture of Experts (MoE) to enable scalable adaptation of the number of Mamba\nexperts based on data complexity, effectively capturing diverse feature\ndistributions without increasing the model's inference time. Empirical\nevaluations on ADBench benchmark demonstrate that Swift Hydra outperforms other\nstate-of-the-art anomaly detection models while maintaining a relatively short\ninference time. From these results, our research highlights a new and\nauspicious paradigm of integrating RL and generative AI for advancing anomaly\ndetection.",
      "tldr_zh": "本研究提出Swift Hydra框架，一种基于生成式AI和强化学习(RL)的自增强机制，用于提升异常检测模型对未见异常的泛化能力。该框架通过RL政策在生成模型的潜在变量上操作，合成多样化的异常样本以扩充训练数据，并采用Mixture of Experts (MoE)结构的Mamba模型，根据数据复杂度动态调整专家数量，从而在不增加推理时间的情况下捕捉复杂特征分布。在ADBench基准测试中，Swift Hydra超越现有最先进模型，同时保持较短的推理时间，展示了整合RL和生成式AI的新范式。",
      "categories": [
        "stat.ML",
        "cs.AI",
        "cs.LG"
      ],
      "primary_category": "stat.ML",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2503.06413v2",
      "published_date": "2025-03-09 03:15:15 UTC",
      "updated_date": "2025-03-25 02:53:03 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-23T23:58:08.447026"
    },
    {
      "arxiv_id": "2503.06411v1",
      "title": "Decoding the Black Box: Integrating Moral Imagination with Technical AI Governance",
      "title_zh": "翻译失败",
      "authors": [
        "Krti Tallam"
      ],
      "abstract": "This paper examines the intricate interplay among AI safety, security, and\ngovernance by integrating technical systems engineering with principles of\nmoral imagination and ethical philosophy. Drawing on foundational insights from\nWeapons of Math Destruction and Thinking in Systems alongside contemporary\ndebates in AI ethics, we develop a comprehensive multi-dimensional framework\ndesigned to regulate AI technologies deployed in high-stakes domains such as\ndefense, finance, healthcare, and education. Our approach combines rigorous\ntechnical analysis, quantitative risk assessment, and normative evaluation to\nexpose systemic vulnerabilities inherent in opaque, black-box models. Detailed\ncase studies, including analyses of Microsoft Tay (2016) and the UK A-Level\nGrading Algorithm (2020), demonstrate how security lapses, bias amplification,\nand lack of accountability can precipitate cascading failures that undermine\npublic trust. We conclude by outlining targeted strategies for enhancing AI\nresilience through adaptive regulatory mechanisms, robust security protocols,\nand interdisciplinary oversight, thereby advancing the state of the art in\nethical and technical AI governance.",
      "tldr_zh": "这篇论文探讨了 AI safety、安全性和治理之间的复杂互动，通过整合技术系统工程、moral imagination 和伦理哲学原则，开发了一个多维框架来监管高风险领域（如国防、金融、医疗和教育）的 AI 技术。框架结合了严格的技术分析、定量风险评估和规范评价，以暴露 black-box models 的系统漏洞，并通过案例研究（如 Microsoft Tay (2016) 和 UK A-Level Grading Algorithm (2020)）展示了安全漏洞、偏见放大和问责制缺失可能导致的信任危机。最终，论文提出针对性策略，包括自适应监管机制、robust security protocols 和跨学科监督，以提升 AI 弹性和整体治理水平。",
      "categories": [
        "eess.SY",
        "cs.AI",
        "cs.SY"
      ],
      "primary_category": "eess.SY",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2503.06411v1",
      "published_date": "2025-03-09 03:11:32 UTC",
      "updated_date": "2025-03-09 03:11:32 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-23T23:58:22.026250"
    },
    {
      "arxiv_id": "2503.06410v1",
      "title": "Performant LLM Agentic Framework for Conversational AI",
      "title_zh": "翻译失败",
      "authors": [
        "Alex Casella",
        "Wayne Wang"
      ],
      "abstract": "The rise of Agentic applications and automation in the Voice AI industry has\nled to an increased reliance on Large Language Models (LLMs) to navigate\ngraph-based logic workflows composed of nodes and edges. However, existing\nmethods face challenges such as alignment errors in complex workflows and\nhallucinations caused by excessive context size. To address these limitations,\nwe introduce the Performant Agentic Framework (PAF), a novel system that\nassists LLMs in selecting appropriate nodes and executing actions in order when\ntraversing complex graphs. PAF combines LLM-based reasoning with a\nmathematically grounded vector scoring mechanism, achieving both higher\naccuracy and reduced latency. Our approach dynamically balances strict\nadherence to predefined paths with flexible node jumps to handle various user\ninputs efficiently. Experiments demonstrate that PAF significantly outperforms\nbaseline methods, paving the way for scalable, real-time Conversational AI\nsystems in complex business environments.",
      "tldr_zh": "该研究针对Agentic应用在Voice AI领域的兴起，解决了Large Language Models (LLMs)在处理复杂图-based逻辑工作流时存在的对齐错误和幻觉问题。作者提出Performant Agentic Framework (PAF)，一种结合LLM-based推理和数学基础的向量评分机制的系统，帮助LLMs准确选择节点并执行动作，同时动态平衡预定义路径与灵活跳转。实验结果显示，PAF在准确性和延迟方面显著优于基线方法，为可扩展的实时Conversational AI系统在复杂业务环境中的应用铺平了道路。",
      "categories": [
        "cs.AI"
      ],
      "primary_category": "cs.AI",
      "comment": "6 pages, 3 figures",
      "pdf_url": "http://arxiv.org/pdf/2503.06410v1",
      "published_date": "2025-03-09 02:58:34 UTC",
      "updated_date": "2025-03-09 02:58:34 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-23T23:58:31.954783"
    },
    {
      "arxiv_id": "2503.06405v3",
      "title": "Heterogeneous bimodal attention fusion for speech emotion recognition",
      "title_zh": "异构",
      "authors": [
        "Jiachen Luo",
        "Huy Phan",
        "Lin Wang",
        "Joshua Reiss"
      ],
      "abstract": "Multi-modal emotion recognition in conversations is a challenging problem due\nto the complex and complementary interactions between different modalities.\nAudio and textual cues are particularly important for understanding emotions\nfrom a human perspective. Most existing studies focus on exploring interactions\nbetween audio and text modalities at the same representation level. However, a\ncritical issue is often overlooked: the heterogeneous modality gap between\nlow-level audio representations and high-level text representations. To address\nthis problem, we propose a novel framework called Heterogeneous Bimodal\nAttention Fusion (HBAF) for multi-level multi-modal interaction in\nconversational emotion recognition. The proposed method comprises three key\nmodules: the uni-modal representation module, the multi-modal fusion module,\nand the inter-modal contrastive learning module. The uni-modal representation\nmodule incorporates contextual content into low-level audio representations to\nbridge the heterogeneous multi-modal gap, enabling more effective fusion. The\nmulti-modal fusion module uses dynamic bimodal attention and a dynamic gating\nmechanism to filter incorrect cross-modal relationships and fully exploit both\nintra-modal and inter-modal interactions. Finally, the inter-modal contrastive\nlearning module captures complex absolute and relative interactions between\naudio and text modalities. Experiments on the MELD and IEMOCAP datasets\ndemonstrate that the proposed HBAF method outperforms existing state-of-the-art\nbaselines.",
      "tldr_zh": "本论文针对对话中音频和文本模态的异质差距问题，提出了一种新型框架Heterogeneous Bimodal Attention Fusion (HBAF)，以提升语音情感识别的性能。HBAF 包括三个关键模块：单一模态表示模块（通过融入上下文内容桥接低级音频和高水平文本表示）、多模态融合模块（利用动态双模态注意力和门控机制过滤错误跨模态关系并优化互动）、以及模态间对比学习模块（捕捉音频和文本之间的复杂绝对及相对互动）。实验结果显示，在MELD和IEMOCAP数据集上，HBAF 超越了现有最先进基线方法，证明了其在多模态情感识别中的有效性。",
      "categories": [
        "cs.SD",
        "cs.AI",
        "eess.AS"
      ],
      "primary_category": "cs.SD",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2503.06405v3",
      "published_date": "2025-03-09 02:50:49 UTC",
      "updated_date": "2025-04-01 00:53:56 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-23T23:58:45.452600"
    },
    {
      "arxiv_id": "2503.06398v1",
      "title": "Causality Enhanced Origin-Destination Flow Prediction in Data-Scarce Cities",
      "title_zh": "翻译失败",
      "authors": [
        "Tao Feng",
        "Yunke Zhang",
        "Huandong Wang",
        "Yong Li"
      ],
      "abstract": "Accurate origin-destination (OD) flow prediction is of great importance to\ndeveloping cities, as it can contribute to optimize urban structures and\nlayouts. However, with the common issues of missing regional features and\nlacking OD flow data, it is quite daunting to predict OD flow in developing\ncities. To address this challenge, we propose a novel Causality-Enhanced OD\nFlow Prediction (CE-OFP), a unified framework that aims to transfer urban\nknowledge between cities and achieve accuracy improvements in OD flow\npredictions across data-scarce cities. In specific, we propose a novel\nreinforcement learning model to discover universal causalities among urban\nfeatures in data-rich cities and build corresponding causal graphs. Then, we\nfurther build Causality-Enhanced Variational Auto-Encoder (CE-VAE) to\nincorporate causal graphs for effective feature reconstruction in data-scarce\ncities. Finally, with the reconstructed features, we devise a knowledge\ndistillation method with a graph attention network to migrate the OD prediction\nmodel from data-rich cities to data-scare cities. Extensive experiments on two\npairs of real-world datasets validate that the proposed CE-OFP remarkably\noutperforms state-of-the-art baselines, which can reduce the RMSE of OD flow\nprediction for data-scarce cities by up to 11%.",
      "tldr_zh": "本文提出了一种Causality-Enhanced OD Flow Prediction (CE-OFP)框架，用于解决数据稀缺城市中原点-目的地(OD)流量的准确预测问题，通过从数据丰富的城市转移城市知识来优化预测性能。具体方法包括利用强化学习模型发现城市特征的普遍因果关系并构建因果图，然后通过Causality-Enhanced Variational Auto-Encoder (CE-VAE)重建特征，并采用知识蒸馏结合图注意力网络将OD预测模型迁移到数据稀缺城市。在两个真实数据集上的实验验证，CE-OFP显著优于现有基线方法，最多可将OD流量预测的RMSE降低11%。",
      "categories": [
        "cs.LG",
        "cs.AI"
      ],
      "primary_category": "cs.LG",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2503.06398v1",
      "published_date": "2025-03-09 02:36:36 UTC",
      "updated_date": "2025-03-09 02:36:36 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-23T23:58:58.193216"
    },
    {
      "arxiv_id": "2503.06396v1",
      "title": "Optimizing Minimum Vertex Cover Solving via a GCN-assisted Heuristic Algorithm",
      "title_zh": "通过 GCN 辅助的启发式算法优化最小顶点覆盖求解",
      "authors": [
        "Enqiang Zhu",
        "Qiqi Bao",
        "Yu Zhang",
        "Chanjuan Liu"
      ],
      "abstract": "The problem of finding a minimum vertex cover (MVC) in a graph is a\nwell-known NP-hard problem with significant practical applications in\noptimization and scheduling. Its complexity, combined with the increasing scale\nof problems, underscores the need for efficient and effective algorithms.\nHowever, existing heuristic algorithms for MVC often rely on simplistic\ninitialization strategies and overlook the impact of edge attributes and\nneighborhood information on vertex selection. In this paper, we introduce\nGCNIVC, a novel heuristic search algorithm designed to address the limitations\nof existing methods for solving MVC problems in large-scale graphs. Our\napproach features two main innovations. First, it utilizes a Graph\nConvolutional Network (GCN) to capture the global structure of graphs, which\nenables the generation of high-quality initial solutions that enhance the\nefficiency of the subsequent search process. Second, GCNIVC introduces a new\nheuristic that employs three containers and the concept of double-covered edges\n(dc-edges), improving search efficiency and providing greater flexibility for\nadding and removing operations based on edge attributes. Through extensive\nexperiments on benchmark datasets, we demonstrate that GCNIVC outperforms\nstate-of-the-art MVC algorithms in terms of both accuracy and efficiency. Our\nresults highlight the effectiveness of GCNIVC's GCN-assisted initialization and\nits edge-informed search strategy. This study not only advances the\nunderstanding of MVC problem-solving but also contributes a new tool for\naddressing large-scale graph optimization challenges.",
      "tldr_zh": "该论文针对最小顶点覆盖 (MVC) 问题——一个 NP-hard 优化问题——提出了一种新型启发式搜索算法 GCNIVC，利用 Graph Convolutional Network (GCN) 捕获图的全局结构，以生成高质量初始解并提升后续搜索效率。GCNIVC 的创新包括引入三个容器和双覆盖边 (dc-edges) 概念，结合边属性优化添加和移除操作，从而提高搜索的灵活性和整体性能。在基准数据集上的实验显示，GCNIVC 在准确性和效率上优于现有算法，为处理大规模图优化挑战提供了新工具。",
      "categories": [
        "cs.AI"
      ],
      "primary_category": "cs.AI",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2503.06396v1",
      "published_date": "2025-03-09 02:31:03 UTC",
      "updated_date": "2025-03-09 02:31:03 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-23T23:59:08.702777"
    },
    {
      "arxiv_id": "2503.06395v1",
      "title": "Causal Discovery and Inference towards Urban Elements and Associated Factors",
      "title_zh": "针对城市元素及其相关因素的因果发现与推理",
      "authors": [
        "Tao Feng",
        "Yunke Zhang",
        "Xiaochen Fan",
        "Huandong Wang",
        "Yong Li"
      ],
      "abstract": "To uncover the city's fundamental functioning mechanisms, it is important to\nacquire a deep understanding of complicated relationships among citizens,\nlocation, and mobility behaviors. Previous research studies have applied direct\ncorrelation analysis to investigate such relationships. Nevertheless, due to\nthe ubiquitous confounding effects, empirical correlation analysis may not\naccurately reflect underlying causal relationships among basic urban elements.\nIn this paper, we propose a novel urban causal computing framework to\ncomprehensively explore causalities and confounding effects among a variety of\nfactors across different types of urban elements. In particular, we design a\nreinforcement learning algorithm to discover the potential causal graph, which\ndepicts the causal relations between urban factors. The causal graph further\nserves as the guidance for estimating causal effects between pair-wise urban\nfactors by propensity score matching. After removing the confounding effects\nfrom correlations, we leverage significance levels of causal effects in\ndownstream urban mobility prediction tasks. Experimental studies on open-source\nurban datasets show that the discovered causal graph demonstrates a\nhierarchical structure, where citizens affect locations, and they both cause\nchanges in urban mobility behaviors. Experimental results in urban mobility\nprediction tasks further show that the proposed method can effectively reduce\nconfounding effects and enhance performance of urban computing tasks.",
      "tldr_zh": "该研究指出，传统相关性分析因混杂 effects 而无法准确揭示城市元素（如公民、位置和移动行为）间的因果关系，因此提出一个新型城市因果计算框架（urban causal computing framework）。框架采用强化学习 algorithm 发现潜在的因果 graph，并通过倾向评分匹配（propensity score matching）估计成对城市因素的因果效应，以消除混杂 effects。实验结果显示，因果 graph 呈现分层结构（公民影响位置，二者共同影响移动行为），并显著提升了城市移动预测任务的性能。",
      "categories": [
        "cs.AI"
      ],
      "primary_category": "cs.AI",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2503.06395v1",
      "published_date": "2025-03-09 02:15:04 UTC",
      "updated_date": "2025-03-09 02:15:04 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-23T23:59:21.459357"
    },
    {
      "arxiv_id": "2503.06392v1",
      "title": "EPR-GAIL: An EPR-Enhanced Hierarchical Imitation Learning Framework to Simulate Complex User Consumption Behaviors",
      "title_zh": "EPR-GAIL：EPR增强的层次化模仿学习框架，用于模拟复杂的用户消费行为",
      "authors": [
        "Tao Feng",
        "Yunke Zhang",
        "Huandong Wang",
        "Yong Li"
      ],
      "abstract": "User consumption behavior data, which records individuals' online spending\nhistory at various types of stores, has been widely used in various\napplications, such as store recommendation, site selection, and sale\nforecasting. However, its high worth is limited due to deficiencies in data\ncomprehensiveness and changes of application scenarios. Thus, generating\nhigh-quality sequential consumption data by simulating complex user consumption\nbehaviors is of great importance to real-world applications. Two branches of\nexisting sequence generation methods are both limited in quality. Model-based\nmethods with simplified assumptions fail to model the complex decision process\nof user consumption, while data-driven methods that emulate real-world data are\nprone to noises, unobserved behaviors, and dynamic decision space. In this\nwork, we propose to enhance the fidelity and trustworthiness of the data-driven\nGenerative Adversarial Imitation Learning (GAIL) method by blending it with the\nExploration and Preferential Return EPR model . The core idea of our EPR-GAIL\nframework is to model user consumption behaviors as a complex EPR decision\nprocess, which consists of purchase, exploration, and preference decisions.\nSpecifically, we design the hierarchical policy function in the generator as a\nrealization of the EPR decision process and employ the probability\ndistributions of the EPR model to guide the reward function in the\ndiscriminator. Extensive experiments on two real-world datasets of user\nconsumption behaviors on an online platform demonstrate that the EPR-GAIL\nframework outperforms the best state-of-the-art baseline by over 19\\% in terms\nof data fidelity. Furthermore, the generated consumption behavior data can\nimprove the performance of sale prediction and location recommendation by up to\n35.29% and 11.19%, respectively, validating its advantage for practical\napplications.",
      "tldr_zh": "本研究提出EPR-GAIL框架，通过将Exploration and Preferential Return (EPR)模型融入Generative Adversarial Imitation Learning (GAIL)，构建一个分层模仿学习系统，以模拟复杂用户消费行为。框架将用户决策过程分解为购买、探索和偏好三个部分，生成器采用分层策略函数实现EPR决策，而判别器使用EPR模型的概率分布来指导奖励函数，从而提升生成数据的保真度和可靠性。在两个真实数据集上的实验中，EPR-GAIL比最先进基线提高了19%的数据保真度，并将生成的消费行为数据应用于销售预测和位置推荐，分别提升了35.29%和11.19%的性能。",
      "categories": [
        "cs.LG",
        "cs.AI"
      ],
      "primary_category": "cs.LG",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2503.06392v1",
      "published_date": "2025-03-09 01:56:42 UTC",
      "updated_date": "2025-03-09 01:56:42 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-23T23:59:32.944113"
    },
    {
      "arxiv_id": "2503.07667v2",
      "title": "CLIMB: Data Foundations for Large Scale Multimodal Clinical Foundation Models",
      "title_zh": "翻译失败",
      "authors": [
        "Wei Dai",
        "Peilin Chen",
        "Malinda Lu",
        "Daniel Li",
        "Haowen Wei",
        "Hejie Cui",
        "Paul Pu Liang"
      ],
      "abstract": "Recent advances in clinical AI have enabled remarkable progress across many\nclinical domains. However, existing benchmarks and models are primarily limited\nto a small set of modalities and tasks, which hinders the development of\nlarge-scale multimodal methods that can make holistic assessments of patient\nhealth and well-being. To bridge this gap, we introduce Clinical Large-Scale\nIntegrative Multimodal Benchmark (CLIMB), a comprehensive clinical benchmark\nunifying diverse clinical data across imaging, language, temporal, and graph\nmodalities. CLIMB comprises 4.51 million patient samples totaling 19.01\nterabytes distributed across 2D imaging, 3D video, time series, graphs, and\nmultimodal data. Through extensive empirical evaluation, we demonstrate that\nmultitask pretraining significantly improves performance on understudied\ndomains, achieving up to 29% improvement in ultrasound and 23% in ECG analysis\nover single-task learning. Pretraining on CLIMB also effectively improves\nmodels' generalization capability to new tasks, and strong unimodal encoder\nperformance translates well to multimodal performance when paired with\ntask-appropriate fusion strategies. Our findings provide a foundation for new\narchitecture designs and pretraining strategies to advance clinical AI\nresearch. Code is released at https://github.com/DDVD233/climb.",
      "tldr_zh": "本研究引入 CLIMB，这是一个全面的临床基准，用于统一大规模多模态数据，包括 2D 图像、3D 视频、时间序列、图和多模态数据，总计 4.51 百万患者样本和 19.01 TB 数据，以克服现有临床 AI 模型在模态和任务方面的局限性。通过多任务预训练，CLIMB 显著提升了模型性能，在超声分析中提高 29%、在 ECG 分析中提高 23%，并改善了模型对新任务的泛化能力。研究结果为临床 AI 的新架构设计和预训练策略提供了重要基础，代码已开源于 https://github.com/DDVD233/climb。",
      "categories": [
        "cs.LG",
        "cs.AI",
        "cs.CV",
        "eess.SP"
      ],
      "primary_category": "cs.LG",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2503.07667v2",
      "published_date": "2025-03-09 01:45:05 UTC",
      "updated_date": "2025-03-20 05:05:56 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-23T23:59:45.011564"
    },
    {
      "arxiv_id": "2503.06378v2",
      "title": "General Scales Unlock AI Evaluation with Explanatory and Predictive Power",
      "title_zh": "通用规模解锁 AI 评估的解释力和预测力",
      "authors": [
        "Lexin Zhou",
        "Lorenzo Pacchiardi",
        "Fernando Martínez-Plumed",
        "Katherine M. Collins",
        "Yael Moros-Daval",
        "Seraphina Zhang",
        "Qinlin Zhao",
        "Yitian Huang",
        "Luning Sun",
        "Jonathan E. Prunty",
        "Zongqian Li",
        "Pablo Sánchez-García",
        "Kexin Jiang Chen",
        "Pablo A. M. Casares",
        "Jiyun Zu",
        "John Burden",
        "Behzad Mehrbakhsh",
        "David Stillwell",
        "Manuel Cebrian",
        "Jindong Wang",
        "Peter Henderson",
        "Sherry Tongshuang Wu",
        "Patrick C. Kyllonen",
        "Lucy Cheke",
        "Xing Xie",
        "José Hernández-Orallo"
      ],
      "abstract": "Ensuring safe and effective use of AI requires understanding and anticipating\nits performance on novel tasks, from advanced scientific challenges to\ntransformed workplace activities. So far, benchmarking has guided progress in\nAI, but it has offered limited explanatory and predictive power for\ngeneral-purpose AI systems, given the low transferability across diverse tasks.\nIn this paper, we introduce general scales for AI evaluation that can explain\nwhat common AI benchmarks really measure, extract ability profiles of AI\nsystems, and predict their performance for new task instances, in- and\nout-of-distribution. Our fully-automated methodology builds on 18 newly-crafted\nrubrics that place instance demands on general scales that do not saturate.\nIllustrated for 15 large language models and 63 tasks, high explanatory power\nis unleashed from inspecting the demand and ability profiles, bringing insights\non the sensitivity and specificity exhibited by different benchmarks, and how\nknowledge, metacognition and reasoning are affected by model size,\nchain-of-thought and distillation. Surprisingly, high predictive power at the\ninstance level becomes possible using these demand levels, providing superior\nestimates over black-box baseline predictors based on embeddings or finetuning,\nespecially in out-of-distribution settings (new tasks and new benchmarks). The\nscales, rubrics, battery, techniques and results presented here represent a\nmajor step for AI evaluation, underpinning the reliable deployment of AI in the\nyears ahead. (Collaborative platform:\nhttps://kinds-of-intelligence-cfi.github.io/ADELE.)",
      "tldr_zh": "本研究引入“general scales”来提升AI评估的解释力和预测力，旨在解决现有基准测试在跨任务转移性上的局限性。该方法基于18个新设计的rubrics，通过全自动评估提取AI系统的能力配置文件，并预测其在分布内和分布外新任务实例的表现。实验结果显示，对于15个大型语言模型和63个任务，“general scales”提供了高解释力，揭示了模型大小、chain-of-thought和蒸馏对知识、元认知和推理的影响，并在预测准确性上优于基于embeddings或finetuning的基线，尤其在out-of-distribution场景中。该框架标志着AI评估的重大进展，支持AI的可靠部署。",
      "categories": [
        "cs.AI",
        "cs.CL",
        "cs.CY"
      ],
      "primary_category": "cs.AI",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2503.06378v2",
      "published_date": "2025-03-09 01:13:56 UTC",
      "updated_date": "2025-03-16 02:28:10 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-23T23:59:56.787144"
    },
    {
      "arxiv_id": "2503.06368v1",
      "title": "VORTEX: Challenging CNNs at Texture Recognition by using Vision Transformers with Orderless and Randomized Token Encodings",
      "title_zh": "翻译失败",
      "authors": [
        "Leonardo Scabini",
        "Kallil M. Zielinski",
        "Emir Konuk",
        "Ricardo T. Fares",
        "Lucas C. Ribas",
        "Kevin Smith",
        "Odemir M. Bruno"
      ],
      "abstract": "Texture recognition has recently been dominated by ImageNet-pre-trained deep\nConvolutional Neural Networks (CNNs), with specialized modifications and\nfeature engineering required to achieve state-of-the-art (SOTA) performance.\nHowever, although Vision Transformers (ViTs) were introduced a few years ago,\nlittle is known about their texture recognition ability. Therefore, in this\nwork, we introduce VORTEX (ViTs with Orderless and Randomized Token Encodings\nfor Texture Recognition), a novel method that enables the effective use of ViTs\nfor texture analysis. VORTEX extracts multi-depth token embeddings from\npre-trained ViT backbones and employs a lightweight module to aggregate\nhierarchical features and perform orderless encoding, obtaining a better image\nrepresentation for texture recognition tasks. This approach allows seamless\nintegration with any ViT with the common transformer architecture. Moreover, no\nfine-tuning of the backbone is performed, since they are used only as frozen\nfeature extractors, and the features are fed to a linear SVM. We evaluate\nVORTEX on nine diverse texture datasets, demonstrating its ability to achieve\nor surpass SOTA performance in a variety of texture analysis scenarios. By\nbridging the gap between texture recognition with CNNs and transformer-based\narchitectures, VORTEX paves the way for adopting emerging transformer\nfoundation models. Furthermore, VORTEX demonstrates robust computational\nefficiency when coupled with ViT backbones compared to CNNs with similar costs.\nThe method implementation and experimental scripts are publicly available in\nour online repository.",
      "tldr_zh": "这篇论文引入了 VORTEX 方法，利用 Vision Transformers (ViTs) 及其无序和随机化 token 编码来挑战 Convolutional Neural Networks (CNNs) 在纹理识别领域的优势。VORTEX 从预训练 ViT 骨干网络提取多深度 token 嵌入，通过一个轻量级模块聚合层次特征并进行 orderless 编码，然后将特征输入线性 SVM 进行分类，而无需微调骨干网络。在九个多样化的纹理数据集上，VORTEX 达到了或超过了 SOTA 性能，并展示了比类似成本 CNNs 更高的计算效率。该方法桥接了 CNN 和 transformer 架构的差距，促进了 transformer 基础模型在纹理分析中的应用。",
      "categories": [
        "cs.CV",
        "cs.AI",
        "cs.LG"
      ],
      "primary_category": "cs.CV",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2503.06368v1",
      "published_date": "2025-03-09 00:36:02 UTC",
      "updated_date": "2025-03-09 00:36:02 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-24T00:00:10.379016"
    },
    {
      "arxiv_id": "2503.06366v1",
      "title": "Machine Learning meets Algebraic Combinatorics: A Suite of Datasets Capturing Research-level Conjecturing Ability in Pure Mathematics",
      "title_zh": "翻译失败",
      "authors": [
        "Herman Chau",
        "Helen Jenne",
        "Davis Brown",
        "Jesse He",
        "Mark Raugas",
        "Sara Billey",
        "Henry Kvinge"
      ],
      "abstract": "With recent dramatic increases in AI system capabilities, there has been\ngrowing interest in utilizing machine learning for reasoning-heavy,\nquantitative tasks, particularly mathematics. While there are many resources\ncapturing mathematics at the high-school, undergraduate, and graduate level,\nthere are far fewer resources available that align with the level of difficulty\nand open endedness encountered by professional mathematicians working on open\nproblems. To address this, we introduce a new collection of datasets, the\nAlgebraic Combinatorics Dataset Repository (ACD Repo), representing either\nfoundational results or open problems in algebraic combinatorics, a subfield of\nmathematics that studies discrete structures arising from abstract algebra.\nFurther differentiating our dataset collection is the fact that it aims at the\nconjecturing process. Each dataset includes an open-ended research-level\nquestion and a large collection of examples (up to 10M in some cases) from\nwhich conjectures should be generated. We describe all nine datasets, the\ndifferent ways machine learning models can be applied to them (e.g., training\nwith narrow models followed by interpretability analysis or program synthesis\nwith LLMs), and discuss some of the challenges involved in designing datasets\nlike these.",
      "tldr_zh": "这篇论文介绍了 Algebraic Combinatorics Dataset Repository (ACD Repo)，一个针对纯数学中代数组合学领域的全新数据集集合，用于捕捉研究级别的猜想能力（conjecturing ability）。数据集包括开放式的研究问题和大量示例（某些达 10M），旨在支持机器学习模型的应用，如窄模型训练后的可解释性分析或大语言模型 (LLMs) 的程序合成。作者讨论了设计这些数据集的挑战，并强调其在桥接 Machine Learning 与专业数学问题方面的潜力。",
      "categories": [
        "cs.LG",
        "cs.AI",
        "math.CO",
        "math.RT"
      ],
      "primary_category": "cs.LG",
      "comment": "26 pages, comments welcome",
      "pdf_url": "http://arxiv.org/pdf/2503.06366v1",
      "published_date": "2025-03-09 00:11:40 UTC",
      "updated_date": "2025-03-09 00:11:40 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-24T00:00:21.381500"
    }
  ],
  "raw_papers_fetched": true,
  "papers_count": 92,
  "processed_papers_count": 92,
  "failed_papers_count": 0,
  "summary_generated": true,
  "daily_data_saved": true,
  "last_update": "2025-05-24T00:00:41.985220"
}