[
  {
    "arxiv_id": "2503.06808v1",
    "title": "Privacy Auditing of Large Language Models",
    "authors": [
      "Ashwinee Panda",
      "Xinyu Tang",
      "Milad Nasr",
      "Christopher A. Choquette-Choo",
      "Prateek Mittal"
    ],
    "abstract": "Current techniques for privacy auditing of large language models (LLMs) have\nlimited efficacy -- they rely on basic approaches to generate canaries which\nleads to weak membership inference attacks that in turn give loose lower bounds\non the empirical privacy leakage. We develop canaries that are far more\neffective than those used in prior work under threat models that cover a range\nof realistic settings. We demonstrate through extensive experiments on multiple\nfamilies of fine-tuned LLMs that our approach sets a new standard for detection\nof privacy leakage. For measuring the memorization rate of non-privately\ntrained LLMs, our designed canaries surpass prior approaches. For example, on\nthe Qwen2.5-0.5B model, our designed canaries achieve $49.6\\%$ TPR at $1\\%$\nFPR, vastly surpassing the prior approach's $4.2\\%$ TPR at $1\\%$ FPR. Our\nmethod can be used to provide a privacy audit of $\\varepsilon \\approx 1$ for a\nmodel trained with theoretical $\\varepsilon$ of 4. To the best of our\nknowledge, this is the first time that a privacy audit of LLM training has\nachieved nontrivial auditing success in the setting where the attacker cannot\ntrain shadow models, insert gradient canaries, or access the model at every\niteration.",
    "categories": [
      "cs.CR",
      "cs.AI",
      "cs.LG"
    ],
    "primary_category": "cs.CR",
    "comment": "ICLR 2025",
    "pdf_url": "http://arxiv.org/pdf/2503.06808v1",
    "published_date": "2025-03-09 23:32:15 UTC",
    "updated_date": "2025-03-09 23:32:15 UTC"
  },
  {
    "arxiv_id": "2503.06803v1",
    "title": "Actionable AI: Enabling Non Experts to Understand and Configure AI Systems",
    "authors": [
      "CÃ©cile Boulard",
      "Sruthi Viswanathan",
      "Wanda Fey",
      "Thierry Jacquin"
    ],
    "abstract": "Interaction between humans and AI systems raises the question of how people\nunderstand AI systems. This has been addressed with explainable AI, the\ninterpretability arising from users' domain expertise, or collaborating with AI\nin a stable environment. In the absence of these elements, we discuss designing\nActionable AI, which allows non-experts to configure black-box agents. In this\npaper, we experiment with an AI-powered cartpole game and observe 22 pairs of\nparticipants to configure it via direct manipulation. Our findings suggest\nthat, in uncertain conditions, non-experts were able to achieve good levels of\nperformance. By influencing the behaviour of the agent, they exhibited an\noperational understanding of it, which proved sufficient to reach their goals.\nBased on this, we derive implications for designing Actionable AI systems. In\nconclusion, we propose Actionable AI as a way to open access to AI-based\nagents, giving end users the agency to influence such agents towards their own\ngoals.",
    "categories": [
      "cs.HC",
      "cs.AI"
    ],
    "primary_category": "cs.HC",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2503.06803v1",
    "published_date": "2025-03-09 23:09:04 UTC",
    "updated_date": "2025-03-09 23:09:04 UTC"
  },
  {
    "arxiv_id": "2503.06798v1",
    "title": "Characterizing Learning in Spiking Neural Networks with Astrocyte-Like Units",
    "authors": [
      "Christopher S. Yang",
      "Sylvester J. Gates III",
      "Dulara De Zoysa",
      "Jaehoon Choe",
      "Wolfgang Losert",
      "Corey B. Hart"
    ],
    "abstract": "Traditional artificial neural networks take inspiration from biological\nnetworks, using layers of neuron-like nodes to pass information for processing.\nMore realistic models include spiking in the neural network, capturing the\nelectrical characteristics more closely. However, a large proportion of brain\ncells are of the glial cell type, in particular astrocytes which have been\nsuggested to play a role in performing computations. Here, we introduce a\nmodified spiking neural network model with added astrocyte-like units in a\nneural network and asses their impact on learning. We implement the network as\na liquid state machine and task the network with performing a chaotic\ntime-series prediction task. We varied the number and ratio of neuron-like and\nastrocyte-like units in the network to examine the latter units effect on\nlearning. We show that the combination of neurons and astrocytes together, as\nopposed to neural- and astrocyte-only networks, are critical for driving\nlearning. Interestingly, we found that the highest learning rate was achieved\nwhen the ratio between astrocyte-like and neuron-like units was roughly 2 to 1,\nmirroring some estimates of the ratio of biological astrocytes to neurons. Our\nresults demonstrate that incorporating astrocyte-like units which represent\ninformation across longer timescales can alter the learning rates of neural\nnetworks, and the proportion of astrocytes to neurons should be tuned\nappropriately to a given task.",
    "categories": [
      "cs.LG",
      "cs.AI",
      "physics.bio-ph"
    ],
    "primary_category": "cs.LG",
    "comment": "6 pages, 4 figures",
    "pdf_url": "http://arxiv.org/pdf/2503.06798v1",
    "published_date": "2025-03-09 22:36:58 UTC",
    "updated_date": "2025-03-09 22:36:58 UTC"
  },
  {
    "arxiv_id": "2503.06797v1",
    "title": "Multimodal AI-driven Biomarker for Early Detection of Cancer Cachexia",
    "authors": [
      "Sabeen Ahmed",
      "Nathan Parker",
      "Margaret Park",
      "Evan W. Davis",
      "Jennifer B. Permuth",
      "Matthew B. Schabath",
      "Yasin Yilmaz",
      "Ghulam Rasool"
    ],
    "abstract": "Cancer cachexia is a multifactorial syndrome characterized by progressive\nmuscle wasting, metabolic dysfunction, and systemic inflammation, leading to\nreduced quality of life and increased mortality. Despite extensive research, no\nsingle definitive biomarker exists, as cachexia-related indicators such as\nserum biomarkers, skeletal muscle measurements, and metabolic abnormalities\noften overlap with other conditions. Existing composite indices, including the\nCancer Cachexia Index (CXI), Modified CXI (mCXI), and Cachexia Score (CASCO),\nintegrate multiple biomarkers but lack standardized thresholds, limiting their\nclinical utility. This study proposes a multimodal AI-based biomarker for early\ncancer cachexia detection, leveraging open-source large language models (LLMs)\nand foundation models trained on medical data. The approach integrates\nheterogeneous patient data, including demographics, disease status, lab\nreports, radiological imaging (CT scans), and clinical notes, using a machine\nlearning framework that can handle missing data. Unlike previous AI-based\nmodels trained on curated datasets, this method utilizes routinely collected\nclinical data, enhancing real-world applicability. Additionally, the model\nincorporates confidence estimation, allowing the identification of cases\nrequiring expert review for precise clinical interpretation. Preliminary\nfindings demonstrate that integrating multiple data modalities improves\ncachexia prediction accuracy at the time of cancer diagnosis. The AI-based\nbiomarker dynamically adapts to patient-specific factors such as age, race,\nethnicity, weight, cancer type, and stage, avoiding the limitations of\nfixed-threshold biomarkers. This multimodal AI biomarker provides a scalable\nand clinically viable solution for early cancer cachexia detection,\nfacilitating personalized interventions and potentially improving treatment\noutcomes and patient survival.",
    "categories": [
      "eess.IV",
      "cs.AI",
      "q-bio.QM"
    ],
    "primary_category": "eess.IV",
    "comment": "17 pages, 6 figures, 3 Tables",
    "pdf_url": "http://arxiv.org/pdf/2503.06797v1",
    "published_date": "2025-03-09 22:32:37 UTC",
    "updated_date": "2025-03-09 22:32:37 UTC"
  },
  {
    "arxiv_id": "2503.06791v1",
    "title": "AutoMisty: A Multi-Agent LLM Framework for Automated Code Generation in the Misty Social Robot",
    "authors": [
      "Xiao Wang",
      "Lu Dong",
      "Sahana Rangasrinivasan",
      "Ifeoma Nwogu",
      "Srirangaraj Setlur",
      "Venugopal Govindaraju"
    ],
    "abstract": "The social robot's open API allows users to customize open-domain\ninteractions. However, it remains inaccessible to those without programming\nexperience. In this work, we introduce AutoMisty, the first multi-agent\ncollaboration framework powered by large language models (LLMs), to enable the\nseamless generation of executable Misty robot code from natural language\ninstructions. AutoMisty incorporates four specialized agent modules to manage\ntask decomposition, assignment, problem-solving, and result synthesis. Each\nagent incorporates a two-layer optimization mechanism, with self-reflection for\niterative refinement and human-in-the-loop for better alignment with user\npreferences. AutoMisty ensures a transparent reasoning process, allowing users\nto iteratively refine tasks through natural language feedback for precise\nexecution. To evaluate AutoMisty's effectiveness, we designed a benchmark task\nset spanning four levels of complexity and conducted experiments in a real\nMisty robot environment. Extensive evaluations demonstrate that AutoMisty not\nonly consistently generates high-quality code but also enables precise code\ncontrol, significantly outperforming direct reasoning with ChatGPT-4o and\nChatGPT-o1. All code, optimized APIs, and experimental videos will be publicly\nreleased through the webpage: https://wangxiaoshawn.github.io/AutoMisty.html",
    "categories": [
      "cs.RO",
      "cs.AI",
      "cs.HC",
      "cs.MA"
    ],
    "primary_category": "cs.RO",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2503.06791v1",
    "published_date": "2025-03-09 22:07:46 UTC",
    "updated_date": "2025-03-09 22:07:46 UTC"
  },
  {
    "arxiv_id": "2503.06790v1",
    "title": "GenDR: Lightning Generative Detail Restorator",
    "authors": [
      "Yan Wang",
      "Shijie Zhao",
      "Kai Chen",
      "Kexin Zhang",
      "Junlin Li",
      "Li Zhang"
    ],
    "abstract": "Recent research applying text-to-image (T2I) diffusion models to real-world\nsuper-resolution (SR) has achieved remarkable success. However, fundamental\nmisalignments between T2I and SR targets result in a dilemma between inference\nspeed and detail fidelity. Specifically, T2I tasks prioritize multi-step\ninversion to synthesize coherent outputs aligned with textual prompts and\nshrink the latent space to reduce generating complexity. Contrariwise, SR tasks\npreserve most information from low-resolution input while solely restoring\nhigh-frequency details, thus necessitating sufficient latent space and fewer\ninference steps. To bridge the gap, we present a one-step diffusion model for\ngenerative detail restoration, GenDR, distilled from a tailored diffusion model\nwith larger latent space. In detail, we train a new SD2.1-VAE16 (0.9B) via\nrepresentation alignment to expand latent space without enlarging the model\nsize. Regarding step-distillation, we propose consistent score identity\ndistillation (CiD) that incorporates SR task-specific loss into score\ndistillation to leverage more SR priors and align the training target.\nFurthermore, we extend CiD with adversarial learning and representation\nalignment (CiDA) to enhance perceptual quality and accelerate training. We also\npolish the pipeline to achieve a more efficient inference. Experimental results\ndemonstrate that GenDR achieves state-of-the-art performance in both\nquantitative metrics and visual fidelity.",
    "categories": [
      "cs.CV",
      "cs.AI",
      "eess.IV"
    ],
    "primary_category": "cs.CV",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2503.06790v1",
    "published_date": "2025-03-09 22:02:18 UTC",
    "updated_date": "2025-03-09 22:02:18 UTC"
  },
  {
    "arxiv_id": "2503.06788v1",
    "title": "Dubito Ergo Sum: Exploring AI Ethics",
    "authors": [
      "Viktor Dorfler",
      "Giles Cuthbert"
    ],
    "abstract": "We paraphrase Descartes' famous dictum in the area of AI ethics where the \"I\ndoubt and therefore I am\" is suggested as a necessary aspect of morality.\nTherefore AI, which cannot doubt itself, cannot possess moral agency. Of\ncourse, this is not the end of the story. We explore various aspects of the\nhuman mind that substantially differ from AI, which includes the sensory\ngrounding of our knowing, the act of understanding, and the significance of\nbeing able to doubt ourselves. The foundation of our argument is the discipline\nof ethics, one of the oldest and largest knowledge projects of human history,\nyet, we seem only to be beginning to get a grasp of it. After a couple of\nthousand years of studying the ethics of humans, we (humans) arrived at a point\nwhere moral psychology suggests that our moral decisions are intuitive, and all\nthe models from ethics become relevant only when we explain ourselves. This\nrecognition has a major impact on what and how we can do regarding AI ethics.\nWe do not offer a solution, we explore some ideas and leave the problem open,\nbut we hope somewhat better understood than before our study.",
    "categories": [
      "cs.AI",
      "cs.CY",
      "cs.HC"
    ],
    "primary_category": "cs.AI",
    "comment": "10 pages, 1 figure, HICSS 57: Hawaii International Conference on\n  System Sciences, Honolulu, HI, published January 2024",
    "pdf_url": "http://arxiv.org/pdf/2503.06788v1",
    "published_date": "2025-03-09 21:59:43 UTC",
    "updated_date": "2025-03-09 21:59:43 UTC"
  },
  {
    "arxiv_id": "2503.06784v1",
    "title": "Infinite Leagues Under the Sea: Photorealistic 3D Underwater Terrain Generation by Latent Fractal Diffusion Models",
    "authors": [
      "Tianyi Zhang",
      "Weiming Zhi",
      "Joshua Mangelson",
      "Matthew Johnson-Roberson"
    ],
    "abstract": "This paper tackles the problem of generating representations of underwater 3D\nterrain. Off-the-shelf generative models, trained on Internet-scale data but\nnot on specialized underwater images, exhibit downgraded realism, as images of\nthe seafloor are relatively uncommon. To this end, we introduce DreamSea, a\ngenerative model to generate hyper-realistic underwater scenes. DreamSea is\ntrained on real-world image databases collected from underwater robot surveys.\nImages from these surveys contain massive real seafloor observations and\ncovering large areas, but are prone to noise and artifacts from the real world.\nWe extract 3D geometry and semantics from the data with visual foundation\nmodels, and train a diffusion model that generates realistic seafloor images in\nRGBD channels, conditioned on novel fractal distribution-based latent\nembeddings. We then fuse the generated images into a 3D map, building a 3DGS\nmodel supervised by 2D diffusion priors which allows photorealistic novel view\nrendering. DreamSea is rigorously evaluated, demonstrating the ability to\nrobustly generate large-scale underwater scenes that are consistent, diverse,\nand photorealistic. Our work drives impact in multiple domains, spanning\nfilming, gaming, and robot simulation.",
    "categories": [
      "cs.GR",
      "cs.AI",
      "cs.CV",
      "cs.LG",
      "cs.RO"
    ],
    "primary_category": "cs.GR",
    "comment": "10 pages",
    "pdf_url": "http://arxiv.org/pdf/2503.06784v1",
    "published_date": "2025-03-09 21:43:37 UTC",
    "updated_date": "2025-03-09 21:43:37 UTC"
  },
  {
    "arxiv_id": "2503.06781v1",
    "title": "Dr Genre: Reinforcement Learning from Decoupled LLM Feedback for Generic Text Rewriting",
    "authors": [
      "Yufei Li",
      "John Nham",
      "Ganesh Jawahar",
      "Lei Shu",
      "David Uthus",
      "Yun-Hsuan Sung",
      "Chengrun Yang",
      "Itai Rolnick",
      "Yi Qiao",
      "Cong Liu"
    ],
    "abstract": "Generic text rewriting is a prevalent large language model (LLM) application\nthat covers diverse real-world tasks, such as style transfer, fact correction,\nand email editing. These tasks vary in rewriting objectives (e.g., factual\nconsistency vs. semantic preservation), making it challenging to develop a\nunified model that excels across all dimensions. Existing methods often\nspecialize in either a single task or a specific objective, limiting their\ngeneralizability. In this work, we introduce a generic model proficient in\nfactuality, stylistic, and conversational rewriting tasks. To simulate\nreal-world user rewrite requests, we construct a conversational rewrite\ndataset, ChatRewrite, that presents ``natural''-sounding instructions, from raw\nemails using LLMs. Combined with other popular rewrite datasets, including\nLongFact for the factuality rewrite task and RewriteLM for the stylistic\nrewrite task, this forms a broad benchmark for training and evaluating generic\nrewrite models. To align with task-specific objectives, we propose Dr Genre, a\nDecoupled-reward learning framework for Generic rewriting, that utilizes\nobjective-oriented reward models with a task-specific weighting. Evaluation\nshows that \\approach delivers higher-quality rewrites across all targeted\ntasks, improving objectives including instruction following (agreement),\ninternal consistency (coherence), and minimal unnecessary edits (conciseness).",
    "categories": [
      "cs.CL",
      "cs.AI",
      "cs.LG"
    ],
    "primary_category": "cs.CL",
    "comment": "29 pages, 4 figures, 25 tables",
    "pdf_url": "http://arxiv.org/pdf/2503.06781v1",
    "published_date": "2025-03-09 21:23:52 UTC",
    "updated_date": "2025-03-09 21:23:52 UTC"
  },
  {
    "arxiv_id": "2503.06778v1",
    "title": "Large Language Models Are Effective Human Annotation Assistants, But Not Good Independent Annotators",
    "authors": [
      "Feng Gu",
      "Zongxia Li",
      "Carlos Rafael Colon",
      "Benjamin Evans",
      "Ishani Mondal",
      "Jordan Lee Boyd-Graber"
    ],
    "abstract": "Event annotation is important for identifying market changes, monitoring\nbreaking news, and understanding sociological trends. Although expert\nannotators set the gold standards, human coding is expensive and inefficient.\nUnlike information extraction experiments that focus on single contexts, we\nevaluate a holistic workflow that removes irrelevant documents, merges\ndocuments about the same event, and annotates the events. Although LLM-based\nautomated annotations are better than traditional TF-IDF-based methods or Event\nSet Curation, they are still not reliable annotators compared to human experts.\nHowever, adding LLMs to assist experts for Event Set Curation can reduce the\ntime and mental effort required for Variable Annotation. When using LLMs to\nextract event variables to assist expert annotators, they agree more with the\nextracted variables than fully automated LLMs for annotation.",
    "categories": [
      "cs.CL",
      "cs.AI"
    ],
    "primary_category": "cs.CL",
    "comment": "9 pages, 4 figures",
    "pdf_url": "http://arxiv.org/pdf/2503.06778v1",
    "published_date": "2025-03-09 21:14:14 UTC",
    "updated_date": "2025-03-09 21:14:14 UTC"
  },
  {
    "arxiv_id": "2503.06765v1",
    "title": "Effectiveness of Zero-shot-CoT in Japanese Prompts",
    "authors": [
      "Shusuke Takayama",
      "Ian Frank"
    ],
    "abstract": "We compare the effectiveness of zero-shot Chain-of-Thought (CoT) prompting in\nJapanese and English using ChatGPT-3.5 and 4o-mini. The technique of zero-shot\nCoT, which involves appending a phrase such as \"Let's think step by step\" to a\nprompt to encourage reasoning before answering, has been shown to offer LLM\nperformance improvements in mathematical and reasoning tasks, particularly in\nEnglish. We investigate how these effects transfer to Japanese using the\nJapanese Multi-task Language Understanding Benchmark (JMMLU) and the Multi-task\nLanguage Understanding Benchmark (MMLU). Our results show that while zero-shot\nCoT prompting can lead to notable performance gains for some prompt categories\nin GPT-3.5, its impact in GPT-4o-mini is associated with significant\nperformance declines. However, for Japanese prompts there remain certain\ncategories, such as college mathematics and abstract algebra, that still\nexhibit improvements, despite the broader trend of diminishing effectiveness in\nmore advanced models.",
    "categories": [
      "cs.CL",
      "cs.AI"
    ],
    "primary_category": "cs.CL",
    "comment": "NLP2025 Workshop on Japanese Language Resources (JLR2025)",
    "pdf_url": "http://arxiv.org/pdf/2503.06765v1",
    "published_date": "2025-03-09 20:42:38 UTC",
    "updated_date": "2025-03-09 20:42:38 UTC"
  },
  {
    "arxiv_id": "2503.06764v3",
    "title": "SemHiTok: A Unified Image Tokenizer via Semantic-Guided Hierarchical Codebook for Multimodal Understanding and Generation",
    "authors": [
      "Zisheng Chen",
      "Chunwei Wang",
      "Xiuwei Chen",
      "Hang Xu",
      "Jianhua Han",
      "Xiaodan Liang"
    ],
    "abstract": "We present SemHiTok, a unified image Tokenizer via Semantic-Guided\nHierarchical codebook that provides consistent discrete feature representations\nfor multimodal understanding and generation tasks. Recently, unified multimodal\nlarge models (MLLMs) for understanding and generation have sparked exploration\nwithin research community. Previous works attempt to train a unified image\ntokenizer by combining loss functions for semantic feature reconstruction and\npixel reconstruction. However, due to the differing levels of features\nprioritized by multimodal understanding and generation tasks, joint training\nmethods face significant challenges in achieving a good trade-off. SemHiTok\naddresses this challenge through Semantic-Guided Hierarchical codebook which\nbuilds texture sub-codebooks on pre-trained semantic codebook. This design\ndecouples the training of semantic reconstruction and pixel reconstruction and\nequips the tokenizer with low-level texture feature extraction capability\nwithout degradation of high-level semantic feature extraction ability. Our\nexperiments demonstrate that SemHiTok achieves excellent rFID score at\n256X256resolution compared to other unified tokenizers, and exhibits\ncompetitive performance on multimodal understanding and generation tasks.",
    "categories": [
      "cs.CV",
      "cs.AI"
    ],
    "primary_category": "cs.CV",
    "comment": "Under Review, Refer to the latest version",
    "pdf_url": "http://arxiv.org/pdf/2503.06764v3",
    "published_date": "2025-03-09 20:42:34 UTC",
    "updated_date": "2025-03-20 06:13:32 UTC"
  },
  {
    "arxiv_id": "2503.06749v2",
    "title": "Vision-R1: Incentivizing Reasoning Capability in Multimodal Large Language Models",
    "authors": [
      "Wenxuan Huang",
      "Bohan Jia",
      "Zijie Zhai",
      "Shaosheng Cao",
      "Zheyu Ye",
      "Fei Zhao",
      "Zhe Xu",
      "Yao Hu",
      "Shaohui Lin"
    ],
    "abstract": "DeepSeek-R1-Zero has successfully demonstrated the emergence of reasoning\ncapabilities in LLMs purely through Reinforcement Learning (RL). Inspired by\nthis breakthrough, we explore how RL can be utilized to enhance the reasoning\ncapability of MLLMs. However, direct training with RL struggles to activate\ncomplex reasoning capabilities such as questioning and reflection in MLLMs, due\nto the absence of substantial high-quality multimodal reasoning data. To\naddress this issue, we propose the reasoning MLLM, Vision-R1, to improve\nmultimodal reasoning capability. Specifically, we first construct a\nhigh-quality multimodal CoT dataset without human annotations by leveraging an\nexisting MLLM and DeepSeek-R1 through modality bridging and data filtering to\nobtain a 200K multimodal CoT dataset, Vision-R1-cold dataset. It serves as\ncold-start initialization data for Vision-R1. To mitigate the optimization\nchallenges caused by overthinking after cold start, we propose Progressive\nThinking Suppression Training (PTST) strategy and employ Group Relative Policy\nOptimization (GRPO) with the hard formatting result reward function to\ngradually refine the model's ability to learn correct and complex reasoning\nprocesses on a 10K multimodal math dataset. Comprehensive experiments show our\nmodel achieves an average improvement of $\\sim$6% across various multimodal\nmath reasoning benchmarks. Vision-R1-7B achieves a 73.5% accuracy on the widely\nused MathVista benchmark, which is only 0.4% lower than the leading reasoning\nmodel, OpenAI O1. The datasets and code will be released in:\nhttps://github.com/Osilly/Vision-R1 .",
    "categories": [
      "cs.CV",
      "cs.AI",
      "cs.CL",
      "cs.LG"
    ],
    "primary_category": "cs.CV",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2503.06749v2",
    "published_date": "2025-03-09 20:06:45 UTC",
    "updated_date": "2025-03-11 09:47:44 UTC"
  },
  {
    "arxiv_id": "2503.06747v1",
    "title": "Fully-Decentralized MADDPG with Networked Agents",
    "authors": [
      "Diego Bolliger",
      "Lorenz Zauter",
      "Robert Ziegler"
    ],
    "abstract": "In this paper, we devise three actor-critic algorithms with decentralized\ntraining for multi-agent reinforcement learning in cooperative, adversarial,\nand mixed settings with continuous action spaces. To this goal, we adapt the\nMADDPG algorithm by applying a networked communication approach between agents.\nWe introduce surrogate policies in order to decentralize the training while\nallowing for local communication during training. The decentralized algorithms\nachieve comparable results to the original MADDPG in empirical tests, while\nreducing computational cost. This is more pronounced with larger numbers of\nagents.",
    "categories": [
      "cs.LG",
      "cs.AI",
      "cs.MA"
    ],
    "primary_category": "cs.LG",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2503.06747v1",
    "published_date": "2025-03-09 20:05:32 UTC",
    "updated_date": "2025-03-09 20:05:32 UTC"
  },
  {
    "arxiv_id": "2503.06745v1",
    "title": "Beyond Black-Box Benchmarking: Observability, Analytics, and Optimization of Agentic Systems",
    "authors": [
      "Dany Moshkovich",
      "Hadar Mulian",
      "Sergey Zeltyn",
      "Natti Eder",
      "Inna Skarbovsky",
      "Roy Abitbol"
    ],
    "abstract": "The rise of agentic AI systems, where agents collaborate to perform diverse\ntasks, poses new challenges with observing, analyzing and optimizing their\nbehavior. Traditional evaluation and benchmarking approaches struggle to handle\nthe non-deterministic, context-sensitive, and dynamic nature of these systems.\nThis paper explores key challenges and opportunities in analyzing and\noptimizing agentic systems across development, testing, and maintenance. We\nexplore critical issues such as natural language variability and unpredictable\nexecution flows, which hinder predictability and control, demanding adaptive\nstrategies to manage input variability and evolving behaviors. Through our user\nstudy, we supported these hypotheses. In particular, we showed a 79% agreement\nthat non deterministic flow of agentic systems acts as a major challenge.\nFinally, we validated our statements empirically advocating the need for moving\nbeyond classical benchmarking. To bridge these gaps, we introduce taxonomies to\npresent expected analytics outcomes and the ways to collect them by extending\nstandard observability frameworks. Building on these foundations, we introduce\nand demonstrate novel approach for benchmarking of agent evaluation systems.\nUnlike traditional \"black box\" performance evaluation approaches, our benchmark\nis built from agent runtime logs as input, and analytics outcome including\ndiscovered flows and issues. By addressing key limitations in existing\nmethodologies, we aim to set the stage for more advanced and holistic\nevaluation strategies, which could foster the development of adaptive,\ninterpretable, and robust agentic AI systems.",
    "categories": [
      "cs.AI",
      "cs.MA"
    ],
    "primary_category": "cs.AI",
    "comment": "14 pages, 19 figures",
    "pdf_url": "http://arxiv.org/pdf/2503.06745v1",
    "published_date": "2025-03-09 20:02:04 UTC",
    "updated_date": "2025-03-09 20:02:04 UTC"
  },
  {
    "arxiv_id": "2503.10666v1",
    "title": "Green Prompting",
    "authors": [
      "Marta Adamska",
      "Daria Smirnova",
      "Hamid Nasiri",
      "Zhengxin Yu",
      "Peter Garraghan"
    ],
    "abstract": "Large Language Models (LLMs) have become widely used across various domains\nspanning search engines, code generation, and text creation. However, a major\nconcern associated with their adoption is the high cost of inference, impacting\nboth their sustainability and financial feasibility. In this study, we\nempirically study how different prompt and response characteristics directly\nimpact LLM inference energy cost. We conduct experiments leveraging three\nopen-source transformer-based LLMs across three task types$-$question\nanswering, sentiment analysis, and text generation. For each inference, we\nanalyzed prompt and response characteristics (length, semantic meaning, time\ntaken, energy consumption). Our results demonstrate that even when presented\nwith identical tasks, models generate responses with varying characteristics\nand subsequently exhibit distinct energy consumption patterns. We found that\nprompt length is less significant than the semantic meaning of the task itself.\nIn addition, we identified specific keywords associated with higher or lower\nenergy usage that vary between associated tasks. These findings highlight the\nimportance of prompt design in optimizing inference efficiency. We conclude\nthat the semantic meaning of prompts and certain task-related keywords\nsignificantly impact inference costs, leading the way for deeper exploration\ntowards creating energy-adaptive LLMs.",
    "categories": [
      "cs.CL",
      "cs.AI",
      "cs.LG"
    ],
    "primary_category": "cs.CL",
    "comment": "9 pages, 5 figures",
    "pdf_url": "http://arxiv.org/pdf/2503.10666v1",
    "published_date": "2025-03-09 19:49:31 UTC",
    "updated_date": "2025-03-09 19:49:31 UTC"
  },
  {
    "arxiv_id": "2503.06734v1",
    "title": "Gender Encoding Patterns in Pretrained Language Model Representations",
    "authors": [
      "Mahdi Zakizadeh",
      "Mohammad Taher Pilehvar"
    ],
    "abstract": "Gender bias in pretrained language models (PLMs) poses significant social and\nethical challenges. Despite growing awareness, there is a lack of comprehensive\ninvestigation into how different models internally represent and propagate such\nbiases. This study adopts an information-theoretic approach to analyze how\ngender biases are encoded within various encoder-based architectures. We focus\non three key aspects: identifying how models encode gender information and\nbiases, examining the impact of bias mitigation techniques and fine-tuning on\nthe encoded biases and their effectiveness, and exploring how model design\ndifferences influence the encoding of biases. Through rigorous and systematic\ninvestigation, our findings reveal a consistent pattern of gender encoding\nacross diverse models. Surprisingly, debiasing techniques often exhibit limited\nefficacy, sometimes inadvertently increasing the encoded bias in internal\nrepresentations while reducing bias in model output distributions. This\nhighlights a disconnect between mitigating bias in output distributions and\naddressing its internal representations. This work provides valuable guidance\nfor advancing bias mitigation strategies and fostering the development of more\nequitable language models.",
    "categories": [
      "cs.CL",
      "cs.AI"
    ],
    "primary_category": "cs.CL",
    "comment": "Proceedings of the 5th Workshop on Trustworthy Natural Language\n  Processing (TrustNLP 2025)",
    "pdf_url": "http://arxiv.org/pdf/2503.06734v1",
    "published_date": "2025-03-09 19:17:46 UTC",
    "updated_date": "2025-03-09 19:17:46 UTC"
  },
  {
    "arxiv_id": "2503.06729v1",
    "title": "ACAI for SBOs: AI Co-creation for Advertising and Inspiration for Small Business Owners",
    "authors": [
      "Nimisha Karnatak",
      "Adrien Baranes",
      "Rob Marchant",
      "Triona Butler",
      "Kristen Olson"
    ],
    "abstract": "Small business owners (SBOs) often lack the resources and design experience\nneeded to produce high-quality advertisements. To address this, we developed\nACAI (AI Co-Creation for Advertising and Inspiration), an GenAI-powered\nmultimodal advertisement creation tool, and conducted a user study with 16 SBOs\nin London to explore their perceptions of and interactions with ACAI in\nadvertisement creation. Our findings reveal that structured inputs enhance user\nagency and control while improving AI outputs by facilitating better brand\nalignment, enhancing AI transparency, and offering scaffolding that assists\nnovice designers, such as SBOs, in formulating prompts. We also found that\nACAI's multimodal interface bridges the design skill gap for SBOs with a clear\nadvertisement vision, but who lack the design jargon necessary for effective\nprompting. Building on our findings, we propose three capabilities: contextual\nintelligence, adaptive interactions, and data management, with corresponding\ndesign recommendations to advance the co-creative attributes of AI-mediated\ndesign tools.",
    "categories": [
      "cs.HC",
      "cs.AI",
      "cs.CY",
      "cs.ET"
    ],
    "primary_category": "cs.HC",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2503.06729v1",
    "published_date": "2025-03-09 19:00:36 UTC",
    "updated_date": "2025-03-09 19:00:36 UTC"
  },
  {
    "arxiv_id": "2503.06725v1",
    "title": "Pull-Based Query Scheduling for Goal-Oriented Semantic Communication",
    "authors": [
      "Pouya Agheli",
      "Nikolaos Pappas",
      "Marios Kountouris"
    ],
    "abstract": "This paper addresses query scheduling for goal-oriented semantic\ncommunication in pull-based status update systems. We consider a system where\nmultiple sensing agents (SAs) observe a source characterized by various\nattributes and provide updates to multiple actuation agents (AAs), which act\nupon the received information to fulfill their heterogeneous goals at the\nendpoint. A hub serves as an intermediary, querying the SAs for updates on\nobserved attributes and maintaining a knowledge base, which is then broadcast\nto the AAs. The AAs leverage the knowledge to perform their actions\neffectively. To quantify the semantic value of updates, we introduce a grade of\neffectiveness (GoE) metric. Furthermore, we integrate cumulative perspective\ntheory (CPT) into the long-term effectiveness analysis to account for risk\nawareness and loss aversion in the system. Leveraging this framework, we\ncompute effect-aware scheduling policies aimed at maximizing the expected\ndiscounted sum of CPT-based total GoE provided by the transmitted updates while\ncomplying with a given query cost constraint. To achieve this, we propose a\nmodel-based solution based on dynamic programming and model-free solutions\nemploying state-of-the-art deep reinforcement learning (DRL) algorithms. Our\nfindings demonstrate that effect-aware scheduling significantly enhances the\neffectiveness of communicated updates compared to benchmark scheduling methods,\nparticularly in settings with stringent cost constraints where optimal query\nscheduling is vital for system performance and overall effectiveness.",
    "categories": [
      "cs.IT",
      "cs.AI",
      "cs.NI",
      "math.IT"
    ],
    "primary_category": "cs.IT",
    "comment": "Submitted for possible publication",
    "pdf_url": "http://arxiv.org/pdf/2503.06725v1",
    "published_date": "2025-03-09 18:51:14 UTC",
    "updated_date": "2025-03-09 18:51:14 UTC"
  },
  {
    "arxiv_id": "2503.06709v1",
    "title": "Delusions of Large Language Models",
    "authors": [
      "Hongshen Xu",
      "Zixv yang",
      "Zichen Zhu",
      "Kunyao Lan",
      "Zihan Wang",
      "Mengyue Wu",
      "Ziwei Ji",
      "Lu Chen",
      "Pascale Fung",
      "Kai Yu"
    ],
    "abstract": "Large Language Models often generate factually incorrect but plausible\noutputs, known as hallucinations. We identify a more insidious phenomenon, LLM\ndelusion, defined as high belief hallucinations, incorrect outputs with\nabnormally high confidence, making them harder to detect and mitigate. Unlike\nordinary hallucinations, delusions persist with low uncertainty, posing\nsignificant challenges to model reliability. Through empirical analysis across\ndifferent model families and sizes on several Question Answering tasks, we show\nthat delusions are prevalent and distinct from hallucinations. LLMs exhibit\nlower honesty with delusions, which are harder to override via finetuning or\nself reflection. We link delusion formation with training dynamics and dataset\nnoise and explore mitigation strategies such as retrieval augmented generation\nand multi agent debating to mitigate delusions. By systematically investigating\nthe nature, prevalence, and mitigation of LLM delusions, our study provides\ninsights into the underlying causes of this phenomenon and outlines future\ndirections for improving model reliability.",
    "categories": [
      "cs.CL",
      "cs.AI"
    ],
    "primary_category": "cs.CL",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2503.06709v1",
    "published_date": "2025-03-09 17:59:16 UTC",
    "updated_date": "2025-03-09 17:59:16 UTC"
  },
  {
    "arxiv_id": "2503.07671v3",
    "title": "Probabilistic Shielding for Safe Reinforcement Learning",
    "authors": [
      "Edwin Hamel-De le Court",
      "Francesco Belardinelli",
      "Alexander W. Goodall"
    ],
    "abstract": "In real-life scenarios, a Reinforcement Learning (RL) agent aiming to\nmaximise their reward, must often also behave in a safe manner, including at\ntraining time. Thus, much attention in recent years has been given to Safe RL,\nwhere an agent aims to learn an optimal policy among all policies that satisfy\na given safety constraint. However, strict safety guarantees are often provided\nthrough approaches based on linear programming, and thus have limited scaling.\nIn this paper we present a new, scalable method, which enjoys strict formal\nguarantees for Safe RL, in the case where the safety dynamics of the Markov\nDecision Process (MDP) are known, and safety is defined as an undiscounted\nprobabilistic avoidance property. Our approach is based on state-augmentation\nof the MDP, and on the design of a shield that restricts the actions available\nto the agent. We show that our approach provides a strict formal safety\nguarantee that the agent stays safe at training and test time. Furthermore, we\ndemonstrate that our approach is viable in practice through experimental\nevaluation.",
    "categories": [
      "stat.ML",
      "cs.AI",
      "cs.LG"
    ],
    "primary_category": "stat.ML",
    "comment": "13 pages, 3 figures, Conference: AAAI 2025",
    "pdf_url": "http://arxiv.org/pdf/2503.07671v3",
    "published_date": "2025-03-09 17:54:33 UTC",
    "updated_date": "2025-03-25 11:31:43 UTC"
  },
  {
    "arxiv_id": "2503.06706v1",
    "title": "PFDial: A Structured Dialogue Instruction Fine-tuning Method Based on UML Flowcharts",
    "authors": [
      "Ming Zhang",
      "Yuhui Wang",
      "Yujiong Shen",
      "Tingyi Yang",
      "Changhao Jiang",
      "Yilong Wu",
      "Shihan Dou",
      "Qinhao Chen",
      "Zhiheng Xi",
      "Zhihao Zhang",
      "Yi Dong",
      "Zhen Wang",
      "Zhihui Fei",
      "Mingyang Wan",
      "Tao Liang",
      "Guojun Ma",
      "Qi Zhang",
      "Tao Gui",
      "Xuanjing Huang"
    ],
    "abstract": "Process-driven dialogue systems, which operate under strict predefined\nprocess constraints, are essential in customer service and equipment\nmaintenance scenarios. Although Large Language Models (LLMs) have shown\nremarkable progress in dialogue and reasoning, they still struggle to solve\nthese strictly constrained dialogue tasks. To address this challenge, we\nconstruct Process Flow Dialogue (PFDial) dataset, which contains 12,705\nhigh-quality Chinese dialogue instructions derived from 440 flowcharts\ncontaining 5,055 process nodes. Based on PlantUML specification, each UML\nflowchart is converted into atomic dialogue units i.e., structured five-tuples.\nExperimental results demonstrate that a 7B model trained with merely 800\nsamples, and a 0.5B model trained on total data both can surpass 90% accuracy.\nAdditionally, the 8B model can surpass GPT-4o up to 43.88% with an average of\n11.00%. We further evaluate models' performance on challenging backward\ntransitions in process flows and conduct an in-depth analysis of various\ndataset formats to reveal their impact on model performance in handling\ndecision and sequential branches. The data is released in\nhttps://github.com/KongLongGeFDU/PFDial.",
    "categories": [
      "cs.CL",
      "cs.AI",
      "cs.LG"
    ],
    "primary_category": "cs.CL",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2503.06706v1",
    "published_date": "2025-03-09 17:43:30 UTC",
    "updated_date": "2025-03-09 17:43:30 UTC"
  },
  {
    "arxiv_id": "2503.06692v2",
    "title": "InftyThink: Breaking the Length Limits of Long-Context Reasoning in Large Language Models",
    "authors": [
      "Yuchen Yan",
      "Yongliang Shen",
      "Yang Liu",
      "Jin Jiang",
      "Mengdi Zhang",
      "Jian Shao",
      "Yueting Zhuang"
    ],
    "abstract": "Advanced reasoning in large language models has achieved remarkable\nperformance on challenging tasks, but the prevailing long-context reasoning\nparadigm faces critical limitations: quadratic computational scaling with\nsequence length, reasoning constrained by maximum context boundaries, and\nperformance degradation beyond pre-training context windows. Existing\napproaches primarily compress reasoning chains without addressing the\nfundamental scaling problem. To overcome these challenges, we introduce\nInftyThink, a paradigm that transforms monolithic reasoning into an iterative\nprocess with intermediate summarization. By interleaving short reasoning\nsegments with concise progress summaries, our approach enables unbounded\nreasoning depth while maintaining bounded computational costs. This creates a\ncharacteristic sawtooth memory pattern that significantly reduces computational\ncomplexity compared to traditional approaches. Furthermore, we develop a\nmethodology for reconstructing long-context reasoning datasets into our\niterative format, transforming OpenR1-Math into 333K training instances.\nExperiments across multiple model architectures demonstrate that our approach\nreduces computational costs while improving performance, with Qwen2.5-Math-7B\nshowing 3-13% improvements across MATH500, AIME24, and GPQA_diamond benchmarks.\nOur work challenges the assumed trade-off between reasoning depth and\ncomputational efficiency, providing a more scalable approach to complex\nreasoning without architectural modifications.",
    "categories": [
      "cs.CL",
      "cs.AI"
    ],
    "primary_category": "cs.CL",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2503.06692v2",
    "published_date": "2025-03-09 16:59:14 UTC",
    "updated_date": "2025-03-13 16:00:47 UTC"
  },
  {
    "arxiv_id": "2503.06690v1",
    "title": "Censoring-Aware Tree-Based Reinforcement Learning for Estimating Dynamic Treatment Regimes with Censored Outcomes",
    "authors": [
      "Animesh Kumar Paul",
      "Russell Greiner"
    ],
    "abstract": "Dynamic Treatment Regimes (DTRs) provide a systematic approach for making\nsequential treatment decisions that adapt to individual patient\ncharacteristics, particularly in clinical contexts where survival outcomes are\nof interest. Censoring-Aware Tree-Based Reinforcement Learning (CA-TRL) is a\nnovel framework to address the complexities associated with censored data when\nestimating optimal DTRs. We explore ways to learn effective DTRs, from\nobservational data. By enhancing traditional tree-based reinforcement learning\nmethods with augmented inverse probability weighting (AIPW) and censoring-aware\nmodifications, CA-TRL delivers robust and interpretable treatment strategies.\nWe demonstrate its effectiveness through extensive simulations and real-world\napplications using the SANAD epilepsy dataset, where it outperformed the\nrecently proposed ASCL method in key metrics such as restricted mean survival\ntime (RMST) and decision-making accuracy. This work represents a step forward\nin advancing personalized and data-driven treatment strategies across diverse\nhealthcare settings.",
    "categories": [
      "cs.LG",
      "cs.AI",
      "stat.ME"
    ],
    "primary_category": "cs.LG",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2503.06690v1",
    "published_date": "2025-03-09 16:53:09 UTC",
    "updated_date": "2025-03-09 16:53:09 UTC"
  },
  {
    "arxiv_id": "2503.06687v1",
    "title": "UniGenX: Unified Generation of Sequence and Structure with Autoregressive Diffusion",
    "authors": [
      "Gongbo Zhang",
      "Yanting Li",
      "Renqian Luo",
      "Pipi Hu",
      "Zeru Zhao",
      "Lingbo Li",
      "Guoqing Liu",
      "Zun Wang",
      "Ran Bi",
      "Kaiyuan Gao",
      "Liya Guo",
      "Yu Xie",
      "Chang Liu",
      "Jia Zhang",
      "Tian Xie",
      "Robert Pinsler",
      "Claudio Zeni",
      "Ziheng Lu",
      "Yingce Xia",
      "Marwin Segler",
      "Maik Riechert",
      "Li Yuan",
      "Lei Chen",
      "Haiguang Liu",
      "Tao Qin"
    ],
    "abstract": "Unified generation of sequence and structure for scientific data (e.g.,\nmaterials, molecules, proteins) is a critical task. Existing approaches\nprimarily rely on either autoregressive sequence models or diffusion models,\neach offering distinct advantages and facing notable limitations.\nAutoregressive models, such as GPT, Llama, and Phi-4, have demonstrated\nremarkable success in natural language generation and have been extended to\nmultimodal tasks (e.g., image, video, and audio) using advanced encoders like\nVQ-VAE to represent complex modalities as discrete sequences. However, their\ndirect application to scientific domains is challenging due to the high\nprecision requirements and the diverse nature of scientific data. On the other\nhand, diffusion models excel at generating high-dimensional scientific data,\nsuch as protein, molecule, and material structures, with remarkable accuracy.\nYet, their inability to effectively model sequences limits their potential as\ngeneral-purpose multimodal foundation models. To address these challenges, we\npropose UniGenX, a unified framework that combines autoregressive next-token\nprediction with conditional diffusion models. This integration leverages the\nstrengths of autoregressive models to ease the training of conditional\ndiffusion models, while diffusion-based generative heads enhance the precision\nof autoregressive predictions. We validate the effectiveness of UniGenX on\nmaterial and small molecule generation tasks, achieving a significant leap in\nstate-of-the-art performance for material crystal structure prediction and\nestablishing new state-of-the-art results for small molecule structure\nprediction, de novo design, and conditional generation. Notably, UniGenX\ndemonstrates significant improvements, especially in handling long sequences\nfor complex structures, showcasing its efficacy as a versatile tool for\nscientific data generation.",
    "categories": [
      "cs.LG",
      "cond-mat.mtrl-sci",
      "cs.AI",
      "physics.bio-ph",
      "physics.chem-ph"
    ],
    "primary_category": "cs.LG",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2503.06687v1",
    "published_date": "2025-03-09 16:43:07 UTC",
    "updated_date": "2025-03-09 16:43:07 UTC"
  },
  {
    "arxiv_id": "2503.10665v1",
    "title": "Small Vision-Language Models: A Survey on Compact Architectures and Techniques",
    "authors": [
      "Nitesh Patnaik",
      "Navdeep Nayak",
      "Himani Bansal Agrawal",
      "Moinak Chinmoy Khamaru",
      "Gourav Bal",
      "Saishree Smaranika Panda",
      "Rishi Raj",
      "Vishal Meena",
      "Kartheek Vadlamani"
    ],
    "abstract": "The emergence of small vision-language models (sVLMs) marks a critical\nadvancement in multimodal AI, enabling efficient processing of visual and\ntextual data in resource-constrained environments. This survey offers a\ncomprehensive exploration of sVLM development, presenting a taxonomy of\narchitectures - transformer-based, mamba-based, and hybrid - that highlight\ninnovations in compact design and computational efficiency. Techniques such as\nknowledge distillation, lightweight attention mechanisms, and modality\npre-fusion are discussed as enablers of high performance with reduced resource\nrequirements. Through an in-depth analysis of models like TinyGPT-V, MiniGPT-4,\nand VL-Mamba, we identify trade-offs between accuracy, efficiency, and\nscalability. Persistent challenges, including data biases and generalization to\ncomplex tasks, are critically examined, with proposed pathways for addressing\nthem. By consolidating advancements in sVLMs, this work underscores their\ntransformative potential for accessible AI, setting a foundation for future\nresearch into efficient multimodal systems.",
    "categories": [
      "cs.CV",
      "cs.AI",
      "cs.CL",
      "cs.LG"
    ],
    "primary_category": "cs.CV",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2503.10665v1",
    "published_date": "2025-03-09 16:14:46 UTC",
    "updated_date": "2025-03-09 16:14:46 UTC"
  },
  {
    "arxiv_id": "2503.06664v1",
    "title": "Exploring LLM Agents for Cleaning Tabular Machine Learning Datasets",
    "authors": [
      "Tommaso Bendinelli",
      "Artur Dox",
      "Christian Holz"
    ],
    "abstract": "High-quality, error-free datasets are a key ingredient in building reliable,\naccurate, and unbiased machine learning (ML) models. However, real world\ndatasets often suffer from errors due to sensor malfunctions, data entry\nmistakes, or improper data integration across multiple sources that can\nseverely degrade model performance. Detecting and correcting these issues\ntypically require tailor-made solutions and demand extensive domain expertise.\nConsequently, automation is challenging, rendering the process labor-intensive\nand tedious. In this study, we investigate whether Large Language Models (LLMs)\ncan help alleviate the burden of manual data cleaning. We set up an experiment\nin which an LLM, paired with Python, is tasked with cleaning the training\ndataset to improve the performance of a learning algorithm without having the\nability to modify the training pipeline or perform any feature engineering. We\nrun this experiment on multiple Kaggle datasets that have been intentionally\ncorrupted with errors. Our results show that LLMs can identify and correct\nerroneous entries, such as illogical values or outlier, by leveraging\ncontextual information from other features within the same row, as well as\nfeedback from previous iterations. However, they struggle to detect more\ncomplex errors that require understanding data distribution across multiple\nrows, such as trends and biases.",
    "categories": [
      "cs.LG",
      "cs.AI"
    ],
    "primary_category": "cs.LG",
    "comment": "14 pages, 1 main figure, 3 plots, Published at ICLR 2025 Workshop on\n  Foundation Models in the Wild",
    "pdf_url": "http://arxiv.org/pdf/2503.06664v1",
    "published_date": "2025-03-09 15:29:46 UTC",
    "updated_date": "2025-03-09 15:29:46 UTC"
  },
  {
    "arxiv_id": "2503.06661v1",
    "title": "AA-CLIP: Enhancing Zero-shot Anomaly Detection via Anomaly-Aware CLIP",
    "authors": [
      "Wenxin Ma",
      "Xu Zhang",
      "Qingsong Yao",
      "Fenghe Tang",
      "Chenxu Wu",
      "Yingtai Li",
      "Rui Yan",
      "Zihang Jiang",
      "S. Kevin Zhou"
    ],
    "abstract": "Anomaly detection (AD) identifies outliers for applications like defect and\nlesion detection. While CLIP shows promise for zero-shot AD tasks due to its\nstrong generalization capabilities, its inherent Anomaly-Unawareness leads to\nlimited discrimination between normal and abnormal features. To address this\nproblem, we propose Anomaly-Aware CLIP (AA-CLIP), which enhances CLIP's anomaly\ndiscrimination ability in both text and visual spaces while preserving its\ngeneralization capability. AA-CLIP is achieved through a straightforward yet\neffective two-stage approach: it first creates anomaly-aware text anchors to\ndifferentiate normal and abnormal semantics clearly, then aligns patch-level\nvisual features with these anchors for precise anomaly localization. This\ntwo-stage strategy, with the help of residual adapters, gradually adapts CLIP\nin a controlled manner, achieving effective AD while maintaining CLIP's class\nknowledge. Extensive experiments validate AA-CLIP as a resource-efficient\nsolution for zero-shot AD tasks, achieving state-of-the-art results in\nindustrial and medical applications. The code is available at\nhttps://github.com/Mwxinnn/AA-CLIP.",
    "categories": [
      "cs.CV",
      "cs.AI"
    ],
    "primary_category": "cs.CV",
    "comment": "8 pages, 7 figures",
    "pdf_url": "http://arxiv.org/pdf/2503.06661v1",
    "published_date": "2025-03-09 15:22:52 UTC",
    "updated_date": "2025-03-09 15:22:52 UTC"
  },
  {
    "arxiv_id": "2503.06648v1",
    "title": "Enhancing NLP Robustness and Generalization through LLM-Generated Contrast Sets: A Scalable Framework for Systematic Evaluation and Adversarial Training",
    "authors": [
      "Hender Lin"
    ],
    "abstract": "Standard NLP benchmarks often fail to capture vulnerabilities stemming from\ndataset artifacts and spurious correlations. Contrast sets address this gap by\nchallenging models near decision boundaries but are traditionally\nlabor-intensive to create and limited in diversity. This study leverages large\nlanguage models to automate the generation of diverse contrast sets. Using the\nSNLI dataset, we created a 3,000-example contrast set to evaluate and improve\nmodel robustness. Fine-tuning on these contrast sets enhanced performance on\nsystematically perturbed examples, maintained standard test accuracy, and\nmodestly improved generalization to novel perturbations. This automated\napproach offers a scalable solution for evaluating and improving NLP models,\naddressing systematic generalization challenges, and advancing robustness in\nreal-world applications.",
    "categories": [
      "cs.CL",
      "cs.AI",
      "cs.LG"
    ],
    "primary_category": "cs.CL",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2503.06648v1",
    "published_date": "2025-03-09 14:52:53 UTC",
    "updated_date": "2025-03-09 14:52:53 UTC"
  },
  {
    "arxiv_id": "2503.06635v1",
    "title": "Deep Cut-informed Graph Embedding and Clustering",
    "authors": [
      "Zhiyuan Ning",
      "Zaitian Wang",
      "Ran Zhang",
      "Ping Xu",
      "Kunpeng Liu",
      "Pengyang Wang",
      "Chong Chen",
      "Pengfei Wang",
      "Yuanchun Zhou",
      "Erik Cambria"
    ],
    "abstract": "Graph clustering aims to divide the graph into different clusters. The\nrecently emerging deep graph clustering approaches are largely built on graph\nneural networks (GNN). However, GNN is designed for general graph encoding and\nthere is a common issue of representation collapse in existing GNN-based deep\ngraph clustering algorithms. We attribute two main reasons for such issue: (i)\nthe inductive bias of GNN models: GNNs tend to generate similar representations\nfor proximal nodes. Since graphs often contain a non-negligible amount of\ninter-cluster links, the bias results in error message passing and leads to\nbiased clustering; (ii) the clustering guided loss function: most traditional\napproaches strive to make all samples closer to pre-learned cluster centers,\nwhich cause a degenerate solution assigning all data points to a single label\nthus make all samples and less discriminative. To address these challenges, we\ninvestigate graph clustering from a graph cut perspective and propose an\ninnovative and non-GNN-based Deep Cut-informed Graph embedding and Clustering\nframework, namely DCGC. This framework includes two modules: (i) cut-informed\ngraph encoding; (ii) self-supervised graph clustering via optimal transport.\nFor the encoding module, we derive a cut-informed graph embedding objective to\nfuse graph structure and attributes by minimizing their joint normalized cut.\nFor the clustering module, we utilize the optimal transport theory to obtain\nthe clustering assignments, which can balance the guidance of proximity to the\npre-learned cluster center. With the above two tailored designs, DCGC is more\nsuitable for the graph clustering task, which can effectively alleviate the\nproblem of representation collapse and achieve better performance. We conduct\nextensive experiments to demonstrate that our method is simple but effective\ncompared with benchmarks.",
    "categories": [
      "cs.LG",
      "cs.AI"
    ],
    "primary_category": "cs.LG",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2503.06635v1",
    "published_date": "2025-03-09 14:24:09 UTC",
    "updated_date": "2025-03-09 14:24:09 UTC"
  },
  {
    "arxiv_id": "2503.08705v1",
    "title": "A Block-Based Heuristic Algorithm for the Three-Dimensional Nuclear Waste Packing Problem",
    "authors": [
      "Yajie Wen",
      "Defu Zhang"
    ],
    "abstract": "In this study, we present a block-based heuristic search algorithm to address\nthe nuclear waste container packing problem in the context of real-world\nnuclear power plants. Additionally, we provide a dataset comprising 1600\nproblem instances for future researchers to use. Experimental results on this\ndataset demonstrate that the proposed algorithm effectively enhances the\ndisposal pool's space utilization while minimizing the radiation dose within\nthe pool. The code and data employed in this study are publicly available to\nfacilitate reproducibility and further investigation.",
    "categories": [
      "math.OC",
      "cs.AI"
    ],
    "primary_category": "math.OC",
    "comment": "10 pages,7 figures",
    "pdf_url": "http://arxiv.org/pdf/2503.08705v1",
    "published_date": "2025-03-09 14:20:48 UTC",
    "updated_date": "2025-03-09 14:20:48 UTC"
  },
  {
    "arxiv_id": "2503.06633v1",
    "title": "BTFL: A Bayesian-based Test-Time Generalization Method for Internal and External Data Distributions in Federated learning",
    "authors": [
      "Yu Zhou",
      "Bingyan Liu"
    ],
    "abstract": "Federated Learning (FL) enables multiple clients to collaboratively develop a\nglobal model while maintaining data privacy. However, online FL deployment\nfaces challenges due to distribution shifts and evolving test samples.\nPersonalized Federated Learning (PFL) tailors the global model to individual\nclient distributions, but struggles with Out-Of-Distribution (OOD) samples\nduring testing, leading to performance degradation. In real-world scenarios,\nbalancing personalization and generalization during online testing is crucial\nand existing methods primarily focus on training-phase generalization. To\naddress the test-time trade-off, we introduce a new scenario: Test-time\nGeneralization for Internal and External Distributions in Federated Learning\n(TGFL), which evaluates adaptability under Internal Distribution (IND) and\nExternal Distribution (EXD). We propose BTFL, a Bayesian-based test-time\ngeneralization method for TGFL, which balances generalization and\npersonalization at the sample level during testing. BTFL employs a two-head\narchitecture to store local and global knowledge, interpolating predictions via\na dual-Bayesian framework that considers both historical test data and current\nsample characteristics with theoretical guarantee and faster speed. Our\nexperiments demonstrate that BTFL achieves improved performance across various\ndatasets and models with less time cost. The source codes are made publicly\navailable at https://github.com/ZhouYuCS/BTFL .",
    "categories": [
      "cs.LG",
      "cs.AI"
    ],
    "primary_category": "cs.LG",
    "comment": "accepted as KDD 2025 research track paper",
    "pdf_url": "http://arxiv.org/pdf/2503.06633v1",
    "published_date": "2025-03-09 14:16:34 UTC",
    "updated_date": "2025-03-09 14:16:34 UTC"
  },
  {
    "arxiv_id": "2503.06629v1",
    "title": "Hardware-Accelerated Event-Graph Neural Networks for Low-Latency Time-Series Classification on SoC FPGA",
    "authors": [
      "Hiroshi Nakano",
      "Krzysztof Blachut",
      "Kamil Jeziorek",
      "Piotr Wzorek",
      "Manon Dampfhoffer",
      "Thomas Mesquida",
      "Hiroaki Nishi",
      "Tomasz Kryjak",
      "Thomas Dalgaty"
    ],
    "abstract": "As the quantities of data recorded by embedded edge sensors grow, so too does\nthe need for intelligent local processing. Such data often comes in the form of\ntime-series signals, based on which real-time predictions can be made locally\nusing an AI model. However, a hardware-software approach capable of making\nlow-latency predictions with low power consumption is required. In this paper,\nwe present a hardware implementation of an event-graph neural network for\ntime-series classification. We leverage an artificial cochlea model to convert\nthe input time-series signals into a sparse event-data format that allows the\nevent-graph to drastically reduce the number of calculations relative to other\nAI methods. We implemented the design on a SoC FPGA and applied it to the\nreal-time processing of the Spiking Heidelberg Digits (SHD) dataset to\nbenchmark our approach against competitive solutions. Our method achieves a\nfloating-point accuracy of 92.7% on the SHD dataset for the base model, which\nis only 2.4% and 2% less than the state-of-the-art models with over 10% and 67%\nfewer model parameters, respectively. It also outperforms FPGA-based spiking\nneural network implementations by 19.3% and 4.5%, achieving 92.3% accuracy for\nthe quantised model while using fewer computational resources and reducing\nlatency.",
    "categories": [
      "cs.LG",
      "cs.AI",
      "eess.SP"
    ],
    "primary_category": "cs.LG",
    "comment": "Paper accepted for the 21st International Symposium on Applied\n  Reconfigurable Computing ARC 2025, Sevilla, Spain, April 9-11, 2025",
    "pdf_url": "http://arxiv.org/pdf/2503.06629v1",
    "published_date": "2025-03-09 14:08:46 UTC",
    "updated_date": "2025-03-09 14:08:46 UTC"
  },
  {
    "arxiv_id": "2503.06627v1",
    "title": "Revisiting Early Detection of Sexual Predators via Turn-level Optimization",
    "authors": [
      "Jinmyeong An",
      "Sangwon Ryu",
      "Heejin Do",
      "Yunsu Kim",
      "Jungseul Ok",
      "Gary Geunbae Lee"
    ],
    "abstract": "Online grooming is a severe social threat where sexual predators gradually\nentrap child victims with subtle and gradual manipulation. Therefore, timely\nintervention for online grooming is critical for proactive protection. However,\nprevious methods fail to determine the optimal intervention points (i.e., jump\nto conclusions) as they rely on chat-level risk labels by causing weak\nsupervision of risky utterances. For timely detection, we propose speed control\nreinforcement learning (SCoRL) (The code and supplementary materials are\navailable at https://github.com/jinmyeongAN/SCoRL), incorporating a practical\nstrategy derived from luring communication theory (LCT). To capture the\npredator's turn-level entrapment, we use a turn-level risk label based on the\nLCT. Then, we design a novel speed control reward function that balances the\ntrade-off between speed and accuracy based on turn-level risk label; thus,\nSCoRL can identify the optimal intervention moment. In addition, we introduce a\nturn-level metric for precise evaluation, identifying limitations in previously\nused chat-level metrics. Experimental results show that SCoRL effectively\npreempted online grooming, offering a more proactive and timely solution.\nFurther analysis reveals that our method enhances performance while intuitively\nidentifying optimal early intervention points.",
    "categories": [
      "cs.LG",
      "cs.AI",
      "cs.CL"
    ],
    "primary_category": "cs.LG",
    "comment": "Accepted as a main conference paper at NAACL 2025",
    "pdf_url": "http://arxiv.org/pdf/2503.06627v1",
    "published_date": "2025-03-09 14:05:27 UTC",
    "updated_date": "2025-03-09 14:05:27 UTC"
  },
  {
    "arxiv_id": "2503.06626v1",
    "title": "DiffCLIP: Differential Attention Meets CLIP",
    "authors": [
      "Hasan Abed Al Kader Hammoud",
      "Bernard Ghanem"
    ],
    "abstract": "We propose DiffCLIP, a novel vision-language model that extends the\ndifferential attention mechanism to CLIP architectures. Differential attention\nwas originally developed for large language models to amplify relevant context\nwhile canceling out noisy information. In this work, we integrate this\nmechanism into CLIP's dual encoder (image and text) framework. With minimal\nadditional parameters, DiffCLIP achieves superior performance on image-text\nunderstanding tasks. Across zero-shot classification, retrieval, and robustness\nbenchmarks, DiffCLIP consistently outperforms baseline CLIP models. Notably,\nthese gains come with negligible computational overhead, demonstrating that\ndifferential attention can significantly enhance multi-modal representations\nwithout sacrificing efficiency. Code can be found at\nhttps://github.com/hammoudhasan/DiffCLIP.",
    "categories": [
      "cs.CV",
      "cs.AI",
      "cs.LG"
    ],
    "primary_category": "cs.CV",
    "comment": "Under review",
    "pdf_url": "http://arxiv.org/pdf/2503.06626v1",
    "published_date": "2025-03-09 14:04:09 UTC",
    "updated_date": "2025-03-09 14:04:09 UTC"
  },
  {
    "arxiv_id": "2503.06614v1",
    "title": "Using Subgraph GNNs for Node Classification:an Overlooked Potential Approach",
    "authors": [
      "Qian Zeng",
      "Xin Lin",
      "Jingyi Gao",
      "Yang Yu"
    ],
    "abstract": "Previous studies have demonstrated the strong performance of Graph Neural\nNetworks (GNNs) in node classification. However, most existing GNNs adopt a\nnode-centric perspective and rely on global message passing, leading to high\ncomputational and memory costs that hinder scalability. To mitigate these\nchallenges, subgraph-based methods have been introduced, leveraging local\nsubgraphs as approximations of full computational trees. While this approach\nimproves efficiency, it often suffers from performance degradation due to the\nloss of global contextual information, limiting its effectiveness compared to\nglobal GNNs. To address this trade-off between scalability and classification\naccuracy, we reformulate the node classification task as a subgraph\nclassification problem and propose SubGND (Subgraph GNN for NoDe). This\nframework introduces a differentiated zero-padding strategy and an Ego-Alter\nsubgraph representation method to resolve label conflicts while incorporating\nan Adaptive Feature Scaling Mechanism to dynamically adjust feature\ncontributions based on dataset-specific dependencies. Experimental results on\nsix benchmark datasets demonstrate that SubGND achieves performance comparable\nto or surpassing global message-passing GNNs, particularly in heterophilic\nsettings, highlighting its effectiveness and scalability as a promising\nsolution for node classification.",
    "categories": [
      "cs.LG",
      "cs.AI"
    ],
    "primary_category": "cs.LG",
    "comment": "16 pages",
    "pdf_url": "http://arxiv.org/pdf/2503.06614v1",
    "published_date": "2025-03-09 13:37:38 UTC",
    "updated_date": "2025-03-09 13:37:38 UTC"
  },
  {
    "arxiv_id": "2503.06580v1",
    "title": "Agent models: Internalizing Chain-of-Action Generation into Reasoning models",
    "authors": [
      "Yuxiang Zhang",
      "Yuqi Yang",
      "Jiangming Shu",
      "Xinyan Wen",
      "Jitao Sang"
    ],
    "abstract": "Traditional agentic workflows rely on external prompts to manage interactions\nwith tools and the environment, which limits the autonomy of reasoning models.\nWe position \\emph{Large Agent Models (LAMs)} that internalize the generation of\n\\emph{Chain-of-Action (CoA)}, enabling the model to autonomously decide when\nand how to use external tools. Our proposed AutoCoA framework combines\nsupervised fine-tuning (SFT) and reinforcement learning (RL), allowing the\nmodel to seamlessly switch between reasoning and action while efficiently\nmanaging environment interactions. Main components include step-level action\ntriggering, trajectory-level CoA optimization, and an internal world model to\nreduce real-environment interaction costs. Evaluations on open-domain QA tasks\ndemonstrate that AutoCoA-trained agent models significantly outperform\nReAct-based workflows in task completion, especially in tasks that require\nlong-term reasoning and multi-step actions. Code and dataset are available at\nhttps://github.com/ADaM-BJTU/AutoCoA",
    "categories": [
      "cs.AI"
    ],
    "primary_category": "cs.AI",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2503.06580v1",
    "published_date": "2025-03-09 12:19:47 UTC",
    "updated_date": "2025-03-09 12:19:47 UTC"
  },
  {
    "arxiv_id": "2503.06573v1",
    "title": "WildIFEval: Instruction Following in the Wild",
    "authors": [
      "Gili Lior",
      "Asaf Yehudai",
      "Ariel Gera",
      "Liat Ein-Dor"
    ],
    "abstract": "Recent LLMs have shown remarkable success in following user instructions, yet\nhandling instructions with multiple constraints remains a significant\nchallenge. In this work, we introduce WildIFEval - a large-scale dataset of 12K\nreal user instructions with diverse, multi-constraint conditions. Unlike prior\ndatasets, our collection spans a broad lexical and topical spectrum of\nconstraints, in natural user prompts. We categorize these constraints into\neight high-level classes to capture their distribution and dynamics in\nreal-world scenarios. Leveraging WildIFEval, we conduct extensive experiments\nto benchmark the instruction-following capabilities of leading LLMs. Our\nfindings reveal that all evaluated models experience performance degradation\nwith an increasing number of constraints. Thus, we show that all models have a\nlarge room for improvement on such tasks. Moreover, we observe that the\nspecific type of constraint plays a critical role in model performance. We\nrelease our dataset to promote further research on instruction-following under\ncomplex, realistic conditions.",
    "categories": [
      "cs.CL",
      "cs.AI"
    ],
    "primary_category": "cs.CL",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2503.06573v1",
    "published_date": "2025-03-09 12:06:29 UTC",
    "updated_date": "2025-03-09 12:06:29 UTC"
  },
  {
    "arxiv_id": "2503.06571v2",
    "title": "SHIP: A Shapelet-based Approach for Interpretable Patient-Ventilator Asynchrony Detection",
    "authors": [
      "Xuan-May Le",
      "Ling Luo",
      "Uwe Aickelin",
      "Minh-Tuan Tran",
      "David Berlowitz",
      "Mark Howard"
    ],
    "abstract": "Patient-ventilator asynchrony (PVA) is a common and critical issue during\nmechanical ventilation, affecting up to 85% of patients. PVA can result in\nclinical complications such as discomfort, sleep disruption, and potentially\nmore severe conditions like ventilator-induced lung injury and diaphragm\ndysfunction. Traditional PVA management, which relies on manual adjustments by\nhealthcare providers, is often inadequate due to delays and errors. While\nvarious computational methods, including rule-based, statistical, and deep\nlearning approaches, have been developed to detect PVA events, they face\nchallenges related to dataset imbalances and lack of interpretability. In this\nwork, we propose a shapelet-based approach SHIP for PVA detection, utilizing\nshapelets - discriminative subsequences in time-series data - to enhance\ndetection accuracy and interpretability. Our method addresses dataset\nimbalances through shapelet-based data augmentation and constructs a shapelet\npool to transform the dataset for more effective classification. The combined\nshapelet and statistical features are then used in a classifier to identify PVA\nevents. Experimental results on medical datasets show that SHIP significantly\nimproves PVA detection while providing interpretable insights into model\ndecisions.",
    "categories": [
      "cs.LG",
      "cs.AI"
    ],
    "primary_category": "cs.LG",
    "comment": "Accepted at PAKDD 2025",
    "pdf_url": "http://arxiv.org/pdf/2503.06571v2",
    "published_date": "2025-03-09 11:58:03 UTC",
    "updated_date": "2025-03-13 02:01:30 UTC"
  },
  {
    "arxiv_id": "2503.06568v1",
    "title": "Conceptrol: Concept Control of Zero-shot Personalized Image Generation",
    "authors": [
      "Qiyuan He",
      "Angela Yao"
    ],
    "abstract": "Personalized image generation with text-to-image diffusion models generates\nunseen images based on reference image content. Zero-shot adapter methods such\nas IP-Adapter and OminiControl are especially interesting because they do not\nrequire test-time fine-tuning. However, they struggle to balance preserving\npersonalized content and adherence to the text prompt. We identify a critical\ndesign flaw resulting in this performance gap: current adapters inadequately\nintegrate personalization images with the textual descriptions. The generated\nimages, therefore, replicate the personalized content rather than adhere to the\ntext prompt instructions. Yet the base text-to-image has strong conceptual\nunderstanding capabilities that can be leveraged.\n  We propose Conceptrol, a simple yet effective framework that enhances\nzero-shot adapters without adding computational overhead. Conceptrol constrains\nthe attention of visual specification with a textual concept mask that improves\nsubject-driven generation capabilities. It achieves as much as 89% improvement\non personalization benchmarks over the vanilla IP-Adapter and can even\noutperform fine-tuning approaches such as Dreambooth LoRA. The source code is\navailable at https://github.com/QY-H00/Conceptrol.",
    "categories": [
      "cs.CV",
      "cs.AI"
    ],
    "primary_category": "cs.CV",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2503.06568v1",
    "published_date": "2025-03-09 11:54:08 UTC",
    "updated_date": "2025-03-09 11:54:08 UTC"
  },
  {
    "arxiv_id": "2503.06567v1",
    "title": "Human Cognition Inspired RAG with Knowledge Graph for Complex Problem Solving",
    "authors": [
      "Yao Cheng",
      "Yibo Zhao",
      "Jiapeng Zhu",
      "Yao Liu",
      "Xing Sun",
      "Xiang Li"
    ],
    "abstract": "Large language models (LLMs) have demonstrated transformative potential\nacross various domains, yet they face significant challenges in knowledge\nintegration and complex problem reasoning, often leading to hallucinations and\nunreliable outputs. Retrieval-Augmented Generation (RAG) has emerged as a\npromising solution to enhance LLMs accuracy by incorporating external\nknowledge. However, traditional RAG systems struggle with processing complex\nrelational information and multi-step reasoning, limiting their effectiveness\nin advanced problem-solving tasks. To address these limitations, we propose\nCogGRAG, a cognition inspired graph-based RAG framework, designed to improve\nLLMs performance in Knowledge Graph Question Answering (KGQA). Inspired by the\nhuman cognitive process of decomposing complex problems and performing\nself-verification, our framework introduces a three-stage methodology:\ndecomposition, retrieval, and reasoning with self-verification. By integrating\nthese components, CogGRAG enhances the accuracy of LLMs in complex problem\nsolving. We conduct systematic experiments with three LLM backbones on four\nbenchmark datasets, where CogGRAG outperforms the baselines.",
    "categories": [
      "cs.LG",
      "cs.AI"
    ],
    "primary_category": "cs.LG",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2503.06567v1",
    "published_date": "2025-03-09 11:50:39 UTC",
    "updated_date": "2025-03-09 11:50:39 UTC"
  },
  {
    "arxiv_id": "2503.06563v1",
    "title": "LSA: Latent Style Augmentation Towards Stain-Agnostic Cervical Cancer Screening",
    "authors": [
      "Jiangdong Cai",
      "Haotian Jiang",
      "Zhenrong Shen",
      "Yonghao Li",
      "Honglin Xiong",
      "Lichi Zhang",
      "Qian Wang"
    ],
    "abstract": "The deployment of computer-aided diagnosis systems for cervical cancer\nscreening using whole slide images (WSIs) faces critical challenges due to\ndomain shifts caused by staining variations across different scanners and\nimaging environments. While existing stain augmentation methods improve\npatch-level robustness, they fail to scale to WSIs due to two key limitations:\n(1) inconsistent stain patterns when extending patch operations to gigapixel\nslides, and (2) prohibitive computational/storage costs from offline processing\nof augmented WSIs.To address this, we propose Latent Style Augmentation (LSA),\na framework that performs efficient, online stain augmentation directly on\nWSI-level latent features. We first introduce WSAug, a WSI-level stain\naugmentation method ensuring consistent stain across patches within a WSI.\nUsing offline-augmented WSIs by WSAug, we design and train Stain Transformer,\nwhich can simulate targeted style in the latent space, efficiently enhancing\nthe robustness of the WSI-level classifier. We validate our method on a\nmulti-scanner WSI dataset for cervical cancer diagnosis. Despite being trained\non data from a single scanner, our approach achieves significant performance\nimprovements on out-of-distribution data from other scanners. Code will be\navailable at https://github.com/caijd2000/LSA.",
    "categories": [
      "eess.IV",
      "cs.AI",
      "cs.CV"
    ],
    "primary_category": "eess.IV",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2503.06563v1",
    "published_date": "2025-03-09 11:33:59 UTC",
    "updated_date": "2025-03-09 11:33:59 UTC"
  },
  {
    "arxiv_id": "2503.06553v1",
    "title": "ProJudge: A Multi-Modal Multi-Discipline Benchmark and Instruction-Tuning Dataset for MLLM-based Process Judges",
    "authors": [
      "Jiaxin Ai",
      "Pengfei Zhou",
      "Zhaopan Xu",
      "Ming Li",
      "Fanrui Zhang",
      "Zizhen Li",
      "Jianwen Sun",
      "Yukang Feng",
      "Baojin Huang",
      "Zhongyuan Wang",
      "Kaipeng Zhang"
    ],
    "abstract": "As multi-modal large language models (MLLMs) frequently exhibit errors when\nsolving scientific problems, evaluating the validity of their reasoning\nprocesses is critical for ensuring reliability and uncovering fine-grained\nmodel weaknesses. Since human evaluation is laborious and costly, prompting\nMLLMs as automated process judges has become a common practice. However, the\nreliability of these model-based judges remains uncertain. To address this, we\nintroduce ProJudgeBench, the first comprehensive benchmark specifically\ndesigned for evaluating abilities of MLLM-based process judges. ProJudgeBench\ncomprises 2,400 test cases and 50,118 step-level labels, spanning four\nscientific disciplines with diverse difficulty levels and multi-modal content.\nIn ProJudgeBench, each step is meticulously annotated by human experts for\ncorrectness, error type, and explanation, enabling a systematic evaluation of\njudges' capabilities to detect, classify and diagnose errors. Evaluation on\nProJudgeBench reveals a significant performance gap between open-source and\nproprietary models. To bridge this gap, we further propose ProJudge-173k, a\nlarge-scale instruction-tuning dataset, and a Dynamic Dual-Phase fine-tuning\nstrategy that encourages models to explicitly reason through problem-solving\nbefore assessing solutions. Both contributions significantly enhance the\nprocess evaluation capabilities of open-source models. All the resources will\nbe released to foster future research of reliable multi-modal process\nevaluation.",
    "categories": [
      "cs.AI",
      "cs.CV",
      "cs.LG"
    ],
    "primary_category": "cs.AI",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2503.06553v1",
    "published_date": "2025-03-09 10:55:51 UTC",
    "updated_date": "2025-03-09 10:55:51 UTC"
  },
  {
    "arxiv_id": "2503.06551v2",
    "title": "ChatGPT-4 in the Turing Test: A Critical Analysis",
    "authors": [
      "Marco Giunti"
    ],
    "abstract": "This paper critically examines the recent publication \"ChatGPT-4 in the\nTuring Test\" by Restrepo Echavarr\\'ia (2025), challenging its central claims\nregarding the absence of minimally serious test implementations and the\nconclusion that ChatGPT-4 fails the Turing Test. The analysis reveals that the\ncriticisms based on rigid criteria and limited experimental data are not fully\njustified. More importantly, the paper makes several constructive contributions\nthat enrich our understanding of Turing Test implementations. It demonstrates\nthat two distinct formats--the three-player and two-player tests--are both\nvalid, each with unique methodological implications. The work distinguishes\nbetween absolute criteria (reflecting an optimal 50% identification rate in a\nthree-player format) and relative criteria (which measure how closely a\nmachine's performance approximates that of a human), offering a more nuanced\nevaluation framework. Furthermore, the paper clarifies the probabilistic\nunderpinnings of both test types by modeling them as Bernoulli\nexperiments--correlated in the three-player version and uncorrelated in the\ntwo-player version. This formalization allows for a rigorous separation between\nthe theoretical criteria for passing the test, defined in probabilistic terms,\nand the experimental data that require robust statistical methods for proper\ninterpretation. In doing so, the paper not only refutes key aspects of the\ncriticized study but also lays a solid foundation for future research on\nobjective measures of how closely an AI's behavior aligns with, or deviates\nfrom, that of a human being.",
    "categories": [
      "cs.AI",
      "cs.CY",
      "cs.HC",
      "68T01"
    ],
    "primary_category": "cs.AI",
    "comment": "14 pages, 1 Appendix, added 1 missing item in References, corrected\n  typos",
    "pdf_url": "http://arxiv.org/pdf/2503.06551v2",
    "published_date": "2025-03-09 10:43:17 UTC",
    "updated_date": "2025-03-11 12:33:04 UTC"
  },
  {
    "arxiv_id": "2503.06542v1",
    "title": "ARMOR v0.1: Empowering Autoregressive Multimodal Understanding Model with Interleaved Multimodal Generation via Asymmetric Synergy",
    "authors": [
      "Jianwen Sun",
      "Yukang Feng",
      "Chuanhao Li",
      "Fanrui Zhang",
      "Zizhen Li",
      "Jiaxin Ai",
      "Sizhuo Zhou",
      "Yu Dai",
      "Shenglin Zhang",
      "Kaipeng Zhang"
    ],
    "abstract": "Unified models (UniMs) for multimodal understanding and generation have\nrecently received much attention in the area of vision and language. Existing\nUniMs are designed to simultaneously learn both multimodal understanding and\ngeneration capabilities, demanding substantial computational resources, and\noften struggle to generate interleaved text-image. We present ARMOR, a\nresource-efficient and pure autoregressive framework that achieves both\nunderstanding and generation by fine-tuning existing multimodal large language\nmodels (MLLMs). Specifically, ARMOR extends existing MLLMs from three\nperspectives: (1) For model architecture, an asymmetric encoder-decoder\narchitecture with a forward-switching mechanism is introduced to unify\nembedding space integrating textual and visual modalities for enabling natural\ntext-image interleaved generation with minimal computational overhead. (2) For\ntraining data, a meticulously curated, high-quality interleaved dataset is\ncollected for fine-tuning MLLMs. (3) For the training algorithm, we propose a\n``what or how to generate\" algorithm to empower existing MLLMs with multimodal\ngeneration capabilities while preserving their multimodal understanding\ncapabilities, through three progressive training stages based on the collected\ndataset. Experimental results demonstrate that ARMOR upgrades existing MLLMs to\nUniMs with promising image generation capabilities, using limited training\nresources. Our code will be released soon at https://armor.github.io.",
    "categories": [
      "cs.CV",
      "cs.AI"
    ],
    "primary_category": "cs.CV",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2503.06542v1",
    "published_date": "2025-03-09 10:15:39 UTC",
    "updated_date": "2025-03-09 10:15:39 UTC"
  },
  {
    "arxiv_id": "2503.06529v2",
    "title": "AnywhereDoor: Multi-Target Backdoor Attacks on Object Detection",
    "authors": [
      "Jialin Lu",
      "Junjie Shan",
      "Ziqi Zhao",
      "Ka-Ho Chow"
    ],
    "abstract": "As object detection becomes integral to many safety-critical applications,\nunderstanding its vulnerabilities is essential. Backdoor attacks, in\nparticular, pose a serious threat by implanting hidden triggers in victim\nmodels, which adversaries can later exploit to induce malicious behaviors\nduring inference. However, current understanding is limited to single-target\nattacks, where adversaries must define a fixed malicious behavior (target)\nbefore training, making inference-time adaptability impossible. Given the large\noutput space of object detection (including object existence prediction,\nbounding box estimation, and classification), the feasibility of flexible,\ninference-time model control remains unexplored. This paper introduces\nAnywhereDoor, a multi-target backdoor attack for object detection. Once\nimplanted, AnywhereDoor allows adversaries to make objects disappear, fabricate\nnew ones, or mislabel them, either across all object classes or specific ones,\noffering an unprecedented degree of control. This flexibility is enabled by\nthree key innovations: (i) objective disentanglement to scale the number of\nsupported targets; (ii) trigger mosaicking to ensure robustness even against\nregion-based detectors; and (iii) strategic batching to address object-level\ndata imbalances that hinder manipulation. Extensive experiments demonstrate\nthat AnywhereDoor grants attackers a high degree of control, improving attack\nsuccess rates by 26% compared to adaptations of existing methods for such\nflexible control.",
    "categories": [
      "cs.CR",
      "cs.AI",
      "cs.CV"
    ],
    "primary_category": "cs.CR",
    "comment": "This work was intended as a replacement of arXiv:2411.14243 and any\n  subsequent updates will appear there",
    "pdf_url": "http://arxiv.org/pdf/2503.06529v2",
    "published_date": "2025-03-09 09:24:24 UTC",
    "updated_date": "2025-03-13 04:18:40 UTC"
  },
  {
    "arxiv_id": "2503.06525v1",
    "title": "From Motion Signals to Insights: A Unified Framework for Student Behavior Analysis and Feedback in Physical Education Classes",
    "authors": [
      "Xian Gao",
      "Jiacheng Ruan",
      "Jingsheng Gao",
      "Mingye Xie",
      "Zongyun Zhang",
      "Ting Liu",
      "Yuzhuo Fu"
    ],
    "abstract": "Analyzing student behavior in educational scenarios is crucial for enhancing\nteaching quality and student engagement. Existing AI-based models often rely on\nclassroom video footage to identify and analyze student behavior. While these\nvideo-based methods can partially capture and analyze student actions, they\nstruggle to accurately track each student's actions in physical education\nclasses, which take place in outdoor, open spaces with diverse activities, and\nare challenging to generalize to the specialized technical movements involved\nin these settings. Furthermore, current methods typically lack the ability to\nintegrate specialized pedagogical knowledge, limiting their ability to provide\nin-depth insights into student behavior and offer feedback for optimizing\ninstructional design. To address these limitations, we propose a unified\nend-to-end framework that leverages human activity recognition technologies\nbased on motion signals, combined with advanced large language models, to\nconduct more detailed analyses and feedback of student behavior in physical\neducation classes. Our framework begins with the teacher's instructional\ndesigns and the motion signals from students during physical education\nsessions, ultimately generating automated reports with teaching insights and\nsuggestions for improving both learning and class instructions. This solution\nprovides a motion signal-based approach for analyzing student behavior and\noptimizing instructional design tailored to physical education classes.\nExperimental results demonstrate that our framework can accurately identify\nstudent behaviors and produce meaningful pedagogical insights.",
    "categories": [
      "cs.CY",
      "cs.AI"
    ],
    "primary_category": "cs.CY",
    "comment": "Work in progress",
    "pdf_url": "http://arxiv.org/pdf/2503.06525v1",
    "published_date": "2025-03-09 09:04:36 UTC",
    "updated_date": "2025-03-09 09:04:36 UTC"
  },
  {
    "arxiv_id": "2503.06523v1",
    "title": "Generative AI as Digital Media",
    "authors": [
      "Gilad Abiri"
    ],
    "abstract": "Generative AI is frequently portrayed as revolutionary or even apocalyptic,\nprompting calls for novel regulatory approaches. This essay argues that such\nviews are misguided. Instead, generative AI should be understood as an\nevolutionary step in the broader algorithmic media landscape, alongside search\nengines and social media. Like these platforms, generative AI centralizes\ninformation control, relies on complex algorithms to shape content, and\nextensively uses user data, thus perpetuating common problems: unchecked\ncorporate power, echo chambers, and weakened traditional gatekeepers.\nRegulation should therefore share a consistent objective: ensuring media\ninstitutions remain trustworthy. Without trust, public discourse risks\nfragmenting into isolated communities dominated by comforting, tribal beliefs\n-- a threat intensified by generative AI's capacity to bypass gatekeepers and\npersonalize truth. Current governance frameworks, such as the EU's AI Act and\nthe US Executive Order 14110, emphasize reactive risk mitigation, addressing\nmeasurable threats like national security, public health, and algorithmic bias.\nWhile effective for novel technological risks, this reactive approach fails to\nadequately address broader issues of trust and legitimacy inherent to digital\nmedia. Proactive regulation fostering transparency, accountability, and public\nconfidence is essential. Viewing generative AI exclusively as revolutionary\nrisks repeating past regulatory failures that left social media and search\nengines insufficiently regulated. Instead, regulation must proactively shape an\nalgorithmic media environment serving the public good, supporting quality\ninformation and robust civic discourse.",
    "categories": [
      "cs.CY",
      "cs.AI"
    ],
    "primary_category": "cs.CY",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2503.06523v1",
    "published_date": "2025-03-09 08:58:17 UTC",
    "updated_date": "2025-03-09 08:58:17 UTC"
  },
  {
    "arxiv_id": "2503.06519v1",
    "title": "Can Small Language Models Reliably Resist Jailbreak Attacks? A Comprehensive Evaluation",
    "authors": [
      "Wenhui Zhang",
      "Huiyu Xu",
      "Zhibo Wang",
      "Zeqing He",
      "Ziqi Zhu",
      "Kui Ren"
    ],
    "abstract": "Small language models (SLMs) have emerged as promising alternatives to large\nlanguage models (LLMs) due to their low computational demands, enhanced privacy\nguarantees and comparable performance in specific domains through light-weight\nfine-tuning. Deploying SLMs on edge devices, such as smartphones and smart\nvehicles, has become a growing trend. However, the security implications of\nSLMs have received less attention than LLMs, particularly regarding jailbreak\nattacks, which is recognized as one of the top threats of LLMs by the OWASP. In\nthis paper, we conduct the first large-scale empirical study of SLMs'\nvulnerabilities to jailbreak attacks. Through systematically evaluation on 63\nSLMs from 15 mainstream SLM families against 8 state-of-the-art jailbreak\nmethods, we demonstrate that 47.6% of evaluated SLMs show high susceptibility\nto jailbreak attacks (ASR > 40%) and 38.1% of them can not even resist direct\nharmful query (ASR > 50%). We further analyze the reasons behind the\nvulnerabilities and identify four key factors: model size, model architecture,\ntraining datasets and training techniques. Moreover, we assess the\neffectiveness of three prompt-level defense methods and find that none of them\nachieve perfect performance, with detection accuracy varying across different\nSLMs and attack methods. Notably, we point out that the inherent security\nawareness play a critical role in SLM security, and models with strong security\nawareness could timely terminate unsafe response with little reminder. Building\nupon the findings, we highlight the urgent need for security-by-design\napproaches in SLM development and provide valuable insights for building more\ntrustworthy SLM ecosystem.",
    "categories": [
      "cs.CR",
      "cs.AI"
    ],
    "primary_category": "cs.CR",
    "comment": "19 pages, 12 figures",
    "pdf_url": "http://arxiv.org/pdf/2503.06519v1",
    "published_date": "2025-03-09 08:47:16 UTC",
    "updated_date": "2025-03-09 08:47:16 UTC"
  },
  {
    "arxiv_id": "2503.06518v1",
    "title": "Towards Superior Quantization Accuracy: A Layer-sensitive Approach",
    "authors": [
      "Feng Zhang",
      "Yanbin Liu",
      "Weihua Li",
      "Jie Lv",
      "Xiaodan Wang",
      "Quan Bai"
    ],
    "abstract": "Large Vision and Language Models have exhibited remarkable human-like\nintelligence in tasks such as natural language comprehension, problem-solving,\nlogical reasoning, and knowledge retrieval. However, training and serving these\nmodels require substantial computational resources, posing a significant\nbarrier to their widespread application and further research. To mitigate this\nchallenge, various model compression techniques have been developed to reduce\ncomputational requirements. Nevertheless, existing methods often employ uniform\nquantization configurations, failing to account for the varying difficulties\nacross different layers in quantizing large neural network models. This paper\ntackles this issue by leveraging layer-sensitivity features, such as activation\nsensitivity and weight distribution Kurtosis, to identify layers that are\nchallenging to quantize accurately and allocate additional memory budget. The\nproposed methods, named SensiBoost and KurtBoost, respectively, demonstrate\nnotable improvement in quantization accuracy, achieving up to 9% lower\nperplexity with only a 2% increase in memory budget on LLama models compared to\nthe baseline.",
    "categories": [
      "cs.LG",
      "cs.AI"
    ],
    "primary_category": "cs.LG",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2503.06518v1",
    "published_date": "2025-03-09 08:45:03 UTC",
    "updated_date": "2025-03-09 08:45:03 UTC"
  },
  {
    "arxiv_id": "2503.06514v2",
    "title": "GFlowVLM: Enhancing Multi-step Reasoning in Vision-Language Models with Generative Flow Networks",
    "authors": [
      "Haoqiang Kang",
      "Enna Sachdeva",
      "Piyush Gupta",
      "Sangjae Bae",
      "Kwonjoon Lee"
    ],
    "abstract": "Vision-Language Models (VLMs) have recently shown promising advancements in\nsequential decision-making tasks through task-specific fine-tuning. However,\ncommon fine-tuning methods, such as Supervised Fine-Tuning (SFT) and\nReinforcement Learning (RL) techniques like Proximal Policy Optimization (PPO),\npresent notable limitations: SFT assumes Independent and Identically\nDistributed (IID) data, while PPO focuses on maximizing cumulative rewards.\nThese limitations often restrict solution diversity and hinder generalization\nin multi-step reasoning tasks. To address these challenges, we introduce a\nnovel framework, GFlowVLM, a framework that fine-tune VLMs using Generative\nFlow Networks (GFlowNets) to promote generation of diverse solutions for\ncomplex reasoning tasks. GFlowVLM models the environment as a non-Markovian\ndecision process, allowing it to capture long-term dependencies essential for\nreal-world applications. It takes observations and task descriptions as inputs\nto prompt chain-of-thought (CoT) reasoning which subsequently guides action\nselection. We use task based rewards to fine-tune VLM with GFlowNets. This\napproach enables VLMs to outperform prior fine-tuning methods, including SFT\nand RL. Empirical results demonstrate the effectiveness of GFlowVLM on complex\ntasks such as card games (NumberLine, BlackJack) and embodied planning tasks\n(ALFWorld), showing enhanced training efficiency, solution diversity, and\nstronger generalization capabilities across both in-distribution and\nout-of-distribution scenarios.",
    "categories": [
      "cs.CL",
      "cs.AI",
      "cs.CV",
      "cs.LG"
    ],
    "primary_category": "cs.CL",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2503.06514v2",
    "published_date": "2025-03-09 08:38:10 UTC",
    "updated_date": "2025-03-25 07:37:48 UTC"
  },
  {
    "arxiv_id": "2503.06511v1",
    "title": "HFedCKD: Toward Robust Heterogeneous Federated Learning via Data-free Knowledge Distillation and Two-way Contrast",
    "authors": [
      "Yiting Zheng",
      "Bohan Lin",
      "Jinqian Chen",
      "Jihua Zhu"
    ],
    "abstract": "Most current federated learning frameworks are modeled as static processes,\nignoring the dynamic characteristics of the learning system. Under the limited\ncommunication budget of the central server, the flexible model architecture of\na large number of clients participating in knowledge transfer requires a lower\nparticipation rate, active clients have uneven contributions, and the client\nscale seriously hinders the performance of FL. We consider a more general and\npractical federation scenario and propose a system heterogeneous federation\nmethod based on data-free knowledge distillation and two-way contrast\n(HFedCKD). We apply the Inverse Probability Weighted Distillation (IPWD)\nstrategy to the data-free knowledge transfer framework. The generator completes\nthe data features of the nonparticipating clients. IPWD implements a dynamic\nevaluation of the prediction contribution of each client under different data\ndistributions. Based on the antibiased weighting of its prediction loss, the\nweight distribution of each client is effectively adjusted to fairly integrate\nthe knowledge of participating clients. At the same time, the local model is\nsplit into a feature extractor and a classifier. Through differential contrast\nlearning, the feature extractor is aligned with the global model in the feature\nspace, while the classifier maintains personalized decision-making\ncapabilities. HFedCKD effectively alleviates the knowledge offset caused by a\nlow participation rate under data-free knowledge distillation and improves the\nperformance and stability of the model. We conduct extensive experiments on\nimage and IoT datasets to comprehensively evaluate and verify the\ngeneralization and robustness of the proposed HFedCKD framework.",
    "categories": [
      "cs.LG",
      "cs.AI"
    ],
    "primary_category": "cs.LG",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2503.06511v1",
    "published_date": "2025-03-09 08:32:57 UTC",
    "updated_date": "2025-03-09 08:32:57 UTC"
  },
  {
    "arxiv_id": "2503.06508v2",
    "title": "LightMotion: A Light and Tuning-free Method for Simulating Camera Motion in Video Generation",
    "authors": [
      "Quanjian Song",
      "Zhihang Lin",
      "Zhanpeng Zeng",
      "Ziyue Zhang",
      "Liujuan Cao",
      "Rongrong Ji"
    ],
    "abstract": "Existing camera motion-controlled video generation methods face computational\nbottlenecks in fine-tuning and inference. This paper proposes LightMotion, a\nlight and tuning-free method for simulating camera motion in video generation.\nOperating in the latent space, it eliminates additional fine-tuning,\ninpainting, and depth estimation, making it more streamlined than existing\nmethods. The endeavors of this paper comprise: (i) The latent space permutation\noperation effectively simulates various camera motions like panning, zooming,\nand rotation. (ii) The latent space resampling strategy combines\nbackground-aware sampling and cross-frame alignment to accurately fill new\nperspectives while maintaining coherence across frames. (iii) Our in-depth\nanalysis shows that the permutation and resampling cause an SNR shift in latent\nspace, leading to poor-quality generation. To address this, we propose latent\nspace correction, which reintroduces noise during denoising to mitigate SNR\nshift and enhance video generation quality. Exhaustive experiments show that\nour LightMotion outperforms existing methods, both quantitatively and\nqualitatively.",
    "categories": [
      "cs.CV",
      "cs.AI"
    ],
    "primary_category": "cs.CV",
    "comment": "18 pages in total",
    "pdf_url": "http://arxiv.org/pdf/2503.06508v2",
    "published_date": "2025-03-09 08:28:40 UTC",
    "updated_date": "2025-03-11 02:28:14 UTC"
  },
  {
    "arxiv_id": "2503.17368v1",
    "title": "Non-Canonical Crosslinks Confound Evolutionary Protein Structure Models",
    "authors": [
      "Romain Lacombe"
    ],
    "abstract": "Evolution-based protein structure prediction models have achieved\nbreakthrough success in recent years. However, they struggle to generalize\nbeyond evolutionary priors and on sequences lacking rich homologous data. Here\nwe present a novel, out-of-domain benchmark based on sactipeptides, a rare\nclass of ribosomally synthesized and post-translationally modified peptides\n(RiPPs) characterized by sulfur-to-$\\alpha$-carbon thioether bridges creating\ncross-links between cysteine residues and backbone. We evaluate recent models\non predicting conformations compatible with these cross-links bridges for the\n10 known sactipeptides with elucidated post-translational modifications.\nCrucially, the structures of 5 of them have not yet been experimentally\nresolved. This makes the task a challenging problem for evolution-based models,\nwhich we find exhibit limited performance (0.0% to 19.2% GDT-TS on\nsulfur-to-$\\alpha$-carbon distance). Our results point at the need for\nphysics-informed models to sustain progress in biomolecular structure\nprediction.",
    "categories": [
      "q-bio.BM",
      "cs.AI"
    ],
    "primary_category": "q-bio.BM",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2503.17368v1",
    "published_date": "2025-03-09 08:18:11 UTC",
    "updated_date": "2025-03-09 08:18:11 UTC"
  },
  {
    "arxiv_id": "2503.06505v1",
    "title": "DynamicID: Zero-Shot Multi-ID Image Personalization with Flexible Facial Editability",
    "authors": [
      "Xirui Hu",
      "Jiahao Wang",
      "Hao Chen",
      "Weizhan Zhang",
      "Benqi Wang",
      "Yikun Li",
      "Haishun Nan"
    ],
    "abstract": "Recent advancements in text-to-image generation have spurred interest in\npersonalized human image generation, which aims to create novel images\nfeaturing specific human identities as reference images indicate. Although\nexisting methods achieve high-fidelity identity preservation, they often\nstruggle with limited multi-ID usability and inadequate facial editability. We\npresent DynamicID, a tuning-free framework supported by a dual-stage training\nparadigm that inherently facilitates both single-ID and multi-ID personalized\ngeneration with high fidelity and flexible facial editability. Our key\ninnovations include: 1) Semantic-Activated Attention (SAA), which employs\nquery-level activation gating to minimize disruption to the original model when\ninjecting ID features and achieve multi-ID personalization without requiring\nmulti-ID samples during training. 2) Identity-Motion Reconfigurator (IMR),\nwhich leverages contrastive learning to effectively disentangle and re-entangle\nfacial motion and identity features, thereby enabling flexible facial editing.\nAdditionally, we have developed a curated VariFace-10k facial dataset,\ncomprising 10k unique individuals, each represented by 35 distinct facial\nimages. Experimental results demonstrate that DynamicID outperforms\nstate-of-the-art methods in identity fidelity, facial editability, and multi-ID\npersonalization capability.",
    "categories": [
      "cs.CV",
      "cs.AI"
    ],
    "primary_category": "cs.CV",
    "comment": "17 pages, 16 figures",
    "pdf_url": "http://arxiv.org/pdf/2503.06505v1",
    "published_date": "2025-03-09 08:16:19 UTC",
    "updated_date": "2025-03-09 08:16:19 UTC"
  },
  {
    "arxiv_id": "2503.06499v2",
    "title": "ExGes: Expressive Human Motion Retrieval and Modulation for Audio-Driven Gesture Synthesis",
    "authors": [
      "Xukun Zhou",
      "Fengxin Li",
      "Ming Chen",
      "Yan Zhou",
      "Pengfei Wan",
      "Di Zhang",
      "Yeying Jin",
      "Zhaoxin Fan",
      "Hongyan Liu",
      "Jun He"
    ],
    "abstract": "Audio-driven human gesture synthesis is a crucial task with broad\napplications in virtual avatars, human-computer interaction, and creative\ncontent generation. Despite notable progress, existing methods often produce\ngestures that are coarse, lack expressiveness, and fail to fully align with\naudio semantics. To address these challenges, we propose ExGes, a novel\nretrieval-enhanced diffusion framework with three key designs: (1) a Motion\nBase Construction, which builds a gesture library using training dataset; (2) a\nMotion Retrieval Module, employing constrative learning and momentum\ndistillation for fine-grained reference poses retreiving; and (3) a Precision\nControl Module, integrating partial masking and stochastic masking to enable\nflexible and fine-grained control. Experimental evaluations on BEAT2\ndemonstrate that ExGes reduces Fr\\'echet Gesture Distance by 6.2\\% and improves\nmotion diversity by 5.3\\% over EMAGE, with user studies revealing a 71.3\\%\npreference for its naturalness and semantic relevance. Code will be released\nupon acceptance.",
    "categories": [
      "cs.CV",
      "cs.AI"
    ],
    "primary_category": "cs.CV",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2503.06499v2",
    "published_date": "2025-03-09 07:59:39 UTC",
    "updated_date": "2025-03-15 04:31:47 UTC"
  },
  {
    "arxiv_id": "2503.06497v1",
    "title": "Evaluation of Safety Cognition Capability in Vision-Language Models for Autonomous Driving",
    "authors": [
      "Enming Zhang",
      "Peizhe Gong",
      "Xingyuan Dai",
      "Yisheng Lv",
      "Qinghai Miao"
    ],
    "abstract": "Assessing the safety of vision-language models (VLMs) in autonomous driving\nis particularly important; however, existing work mainly focuses on traditional\nbenchmark evaluations. As interactive components within autonomous driving\nsystems, VLMs must maintain strong safety cognition during interactions. From\nthis perspective, we propose a novel evaluation method: Safety Cognitive\nDriving Benchmark (SCD-Bench) . To address the large-scale annotation challenge\nfor SCD-Bench, we develop the Autonomous Driving Image-Text Annotation System\n(ADA) . Additionally, to ensure data quality in SCD-Bench, our dataset\nundergoes manual refinement by experts with professional knowledge in\nautonomous driving. We further develop an automated evaluation method based on\nlarge language models (LLMs). To verify its effectiveness, we compare its\nevaluation results with those of expert human evaluations, achieving a\nconsistency rate of 99.74%. Preliminary experimental results indicate that\nexisting open-source models still lack sufficient safety cognition, showing a\nsignificant gap compared to GPT-4o. Notably, lightweight models (1B-4B)\ndemonstrate minimal safety cognition. However, since lightweight models are\ncrucial for autonomous driving systems, this presents a significant challenge\nfor integrating VLMs into the field.",
    "categories": [
      "cs.CV",
      "cs.AI"
    ],
    "primary_category": "cs.CV",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2503.06497v1",
    "published_date": "2025-03-09 07:53:19 UTC",
    "updated_date": "2025-03-09 07:53:19 UTC"
  },
  {
    "arxiv_id": "2503.16487v1",
    "title": "PythonPal: Enhancing Online Programming Education through Chatbot-Driven Personalized Feedback",
    "authors": [
      "Sirinda Palahan"
    ],
    "abstract": "The rise of online programming education has necessitated more effective,\npersonalized interactions, a gap that PythonPal aims to fill through its\ninnovative learning system integrated with a chatbot. This research delves into\nPythonPal's potential to enhance the online learning experience, especially in\ncontexts with high student-to-teacher ratios where there is a need for\npersonalized feedback. PythonPal's design, featuring modules for conversation,\ntutorials, and exercises, was evaluated through student interactions and\nfeedback. Key findings reveal PythonPal's proficiency in syntax error\nrecognition and user query comprehension, with its intent classification model\nshowing high accuracy. The system's performance in error feedback, though\nvaried, demonstrates both strengths and areas for enhancement. Student feedback\nindicated satisfactory query understanding and feedback accuracy but also\npointed out the need for faster responses and improved interaction quality.\nPythonPal's deployment promises to significantly enhance online programming\neducation by providing immediate, personalized feedback and interactive\nlearning experiences, fostering a deeper understanding of programming concepts\namong students. These benefits mark a step forward in addressing the challenges\nof distance learning, making programming education more accessible and\neffective.",
    "categories": [
      "cs.HC",
      "cs.AI"
    ],
    "primary_category": "cs.HC",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2503.16487v1",
    "published_date": "2025-03-09 07:28:42 UTC",
    "updated_date": "2025-03-09 07:28:42 UTC"
  },
  {
    "arxiv_id": "2503.06486v1",
    "title": "PerturboLLaVA: Reducing Multimodal Hallucinations with Perturbative Visual Training",
    "authors": [
      "Cong Chen",
      "Mingyu Liu",
      "Chenchen Jing",
      "Yizhou Zhou",
      "Fengyun Rao",
      "Hao Chen",
      "Bo Zhang",
      "Chunhua Shen"
    ],
    "abstract": "This paper aims to address the challenge of hallucinations in Multimodal\nLarge Language Models (MLLMs) particularly for dense image captioning tasks. To\ntackle the challenge, we identify the current lack of a metric that finely\nmeasures the caption quality in concept level. We hereby introduce HalFscore, a\nnovel metric built upon the language graph and is designed to evaluate both the\naccuracy and completeness of dense captions at a granular level. Additionally,\nwe identify the root cause of hallucination as the model's over-reliance on its\nlanguage prior. To address this, we propose PerturboLLaVA, which reduces the\nmodel's reliance on the language prior by incorporating adversarially perturbed\ntext during training. This method enhances the model's focus on visual inputs,\neffectively reducing hallucinations and producing accurate, image-grounded\ndescriptions without incurring additional computational overhead. PerturboLLaVA\nsignificantly improves the fidelity of generated captions, outperforming\nexisting approaches in handling multimodal hallucinations and achieving\nimproved performance across general multimodal benchmarks.",
    "categories": [
      "cs.CV",
      "cs.AI"
    ],
    "primary_category": "cs.CV",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2503.06486v1",
    "published_date": "2025-03-09 07:07:03 UTC",
    "updated_date": "2025-03-09 07:07:03 UTC"
  },
  {
    "arxiv_id": "2503.06484v1",
    "title": "Sign Language Translation using Frame and Event Stream: Benchmark Dataset and Algorithms",
    "authors": [
      "Xiao Wang",
      "Yuehang Li",
      "Fuling Wang",
      "Bo Jiang",
      "Yaowei Wang",
      "Yonghong Tian",
      "Jin Tang",
      "Bin Luo"
    ],
    "abstract": "Accurate sign language understanding serves as a crucial communication\nchannel for individuals with disabilities. Current sign language translation\nalgorithms predominantly rely on RGB frames, which may be limited by fixed\nframe rates, variable lighting conditions, and motion blur caused by rapid hand\nmovements. Inspired by the recent successful application of event cameras in\nother fields, we propose to leverage event streams to assist RGB cameras in\ncapturing gesture data, addressing the various challenges mentioned above.\nSpecifically, we first collect a large-scale RGB-Event sign language\ntranslation dataset using the DVS346 camera, termed VECSL, which contains\n15,676 RGB-Event samples, 15,191 glosses, and covers 2,568 Chinese characters.\nThese samples were gathered across a diverse range of indoor and outdoor\nenvironments, capturing multiple viewing angles, varying light intensities, and\ndifferent camera motions. Due to the absence of benchmark algorithms for\ncomparison in this new task, we retrained and evaluated multiple\nstate-of-the-art SLT algorithms, and believe that this benchmark can\neffectively support subsequent related research. Additionally, we propose a\nnovel RGB-Event sign language translation framework (i.e., M$^2$-SLT) that\nincorporates fine-grained micro-sign and coarse-grained macro-sign retrieval,\nachieving state-of-the-art results on the proposed dataset. Both the source\ncode and dataset will be released on https://github.com/Event-AHU/OpenESL.",
    "categories": [
      "cs.CV",
      "cs.AI",
      "cs.NE"
    ],
    "primary_category": "cs.CV",
    "comment": "In Peer Review",
    "pdf_url": "http://arxiv.org/pdf/2503.06484v1",
    "published_date": "2025-03-09 06:55:46 UTC",
    "updated_date": "2025-03-09 06:55:46 UTC"
  },
  {
    "arxiv_id": "2503.06479v1",
    "title": "ExKG-LLM: Leveraging Large Language Models for Automated Expansion of Cognitive Neuroscience Knowledge Graphs",
    "authors": [
      "Ali Sarabadani",
      "Kheirolah Rahsepar Fard",
      "Hamid Dalvand"
    ],
    "abstract": "The paper introduces ExKG-LLM, a framework designed to automate the expansion\nof cognitive neuroscience knowledge graphs (CNKG) using large language models\n(LLMs). It addresses limitations in existing tools by enhancing accuracy,\ncompleteness, and usefulness in CNKG. The framework leverages a large dataset\nof scientific papers and clinical reports, applying state-of-the-art LLMs to\nextract, optimize, and integrate new entities and relationships. Evaluation\nmetrics include precision, recall, and graph density. Results show significant\nimprovements: precision (0.80, +6.67%), recall (0.81, +15.71%), F1 score\n(0.805, +11.81%), and increased edge nodes (21.13% and 31.92%). Graph density\nslightly decreased, reflecting a broader but more fragmented structure.\nEngagement rates rose by 20%, while CNKG diameter increased to 15, indicating a\nmore distributed structure. Time complexity improved to O(n log n), but space\ncomplexity rose to O(n2), indicating higher memory usage. ExKG-LLM demonstrates\npotential for enhancing knowledge generation, semantic search, and clinical\ndecision-making in cognitive neuroscience, adaptable to broader scientific\nfields.",
    "categories": [
      "cs.AI"
    ],
    "primary_category": "cs.AI",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2503.06479v1",
    "published_date": "2025-03-09 06:32:56 UTC",
    "updated_date": "2025-03-09 06:32:56 UTC"
  },
  {
    "arxiv_id": "2503.06477v1",
    "title": "PDB: Not All Drivers Are the Same -- A Personalized Dataset for Understanding Driving Behavior",
    "authors": [
      "Chuheng Wei",
      "Ziye Qin",
      "Siyan Li",
      "Ziyan Zhang",
      "Xuanpeng Zhao",
      "Amr Abdelraouf",
      "Rohit Gupta",
      "Kyungtae Han",
      "Matthew J. Barth",
      "Guoyuan Wu"
    ],
    "abstract": "Driving behavior is inherently personal, influenced by individual habits,\ndecision-making styles, and physiological states. However, most existing\ndatasets treat all drivers as homogeneous, overlooking driver-specific\nvariability. To address this gap, we introduce the Personalized Driving\nBehavior (PDB) dataset, a multi-modal dataset designed to capture\npersonalization in driving behavior under naturalistic driving conditions.\nUnlike conventional datasets, PDB minimizes external influences by maintaining\nconsistent routes, vehicles, and lighting conditions across sessions. It\nincludes sources from 128-line LiDAR, front-facing camera video, GNSS, 9-axis\nIMU, CAN bus data (throttle, brake, steering angle), and driver-specific\nsignals such as facial video and heart rate. The dataset features 12\nparticipants, approximately 270,000 LiDAR frames, 1.6 million images, and 6.6\nTB of raw sensor data. The processed trajectory dataset consists of 1,669\nsegments, each spanning 10 seconds with a 0.2-second interval. By explicitly\ncapturing drivers' behavior, PDB serves as a unique resource for human factor\nanalysis, driver identification, and personalized mobility applications,\ncontributing to the development of human-centric intelligent transportation\nsystems.",
    "categories": [
      "cs.CV",
      "cs.AI"
    ],
    "primary_category": "cs.CV",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2503.06477v1",
    "published_date": "2025-03-09 06:28:39 UTC",
    "updated_date": "2025-03-09 06:28:39 UTC"
  },
  {
    "arxiv_id": "2503.16486v1",
    "title": "Accodemy: AI Powered Code Learning Platform to Assist Novice Programmers in Overcoming the Fear of Coding",
    "authors": [
      "M. A. F. Aamina",
      "V. Kavishcan",
      "W. M. P. B. B. Jayaratne",
      "K. K. D. S. N. Kannangara",
      "A. A. Aamil",
      "Achini Adikari"
    ],
    "abstract": "Computer programming represents a rapidly evolving and sought-after career\npath in the 21st century. Nevertheless, novice learners may find the process\nintimidating for several reasons, such as limited and highly competitive career\nopportunities, peer and parental pressure for academic success, and course\ndifficulties. These factors frequently contribute to anxiety and eventual\ndropout as a result of fear. Furthermore, research has demonstrated that\nbeginners are significantly deterred by the fear of failure, which results in\nprogramming anxiety and and a sense of being overwhelmed by intricate topics,\nultimately leading to dropping out. This project undertakes an exploration\nbeyond the scope of conventional code learning platforms by identifying and\nutilising effective and personalised strategies of learning. The proposed\nsolution incorporates features such as AI-generated challenging questions,\nmindfulness quotes, and tips to motivate users, along with an AI chatbot that\nfunctions as a motivational aid. In addition, the suggested solution integrates\npersonalized roadmaps and gamification elements to maintain user involvement.\nThe project aims to systematically monitor the progress of novice programmers\nand enhance their knowledge of coding with a personalised, revised curriculum\nto help mitigate the fear of coding and boost confidence.",
    "categories": [
      "cs.HC",
      "cs.AI",
      "cs.SE"
    ],
    "primary_category": "cs.HC",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2503.16486v1",
    "published_date": "2025-03-09 06:28:06 UTC",
    "updated_date": "2025-03-09 06:28:06 UTC"
  },
  {
    "arxiv_id": "2503.06475v1",
    "title": "SKG-LLM: Developing a Mathematical Model for Stroke Knowledge Graph Construction Using Large Language Models",
    "authors": [
      "Ali Sarabadani",
      "Kheirolah Rahsepar Fard",
      "Hamid Dalvand"
    ],
    "abstract": "The purpose of this study is to introduce SKG-LLM. A knowledge graph (KG) is\nconstructed from stroke-related articles using mathematical and large language\nmodels (LLMs). SKG-LLM extracts and organizes complex relationships from the\nbiomedical literature, using it to increase the accuracy and depth of KG in\nstroke research. In the proposed method, GPT-4 was used for data\npre-processing, and the extraction of embeddings was also done by GPT-4 in the\nwhole KG construction process. The performance of the proposed model was tested\nwith two evaluation criteria: Precision and Recall. For further validation of\nthe proposed model, GPT-4 was used. Compared with Wikidata and WN18RR, the\nproposed KG-LLM approach performs better, especially in precision and recall.\nBy including GPT-4 in the preprocessing process, the SKG-LLM model achieved a\nprecision score of 0.906 and a recall score of 0.923. Expert reviews further\nimproved the results and increased precision to 0.923 and recall to 0.918. The\nknowledge graph constructed by SKG-LLM contains 2692 nodes and 5012 edges,\nwhich are 13 distinct types of nodes and 24 types of edges.",
    "categories": [
      "cs.AI",
      "cs.CL"
    ],
    "primary_category": "cs.AI",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2503.06475v1",
    "published_date": "2025-03-09 06:25:37 UTC",
    "updated_date": "2025-03-09 06:25:37 UTC"
  },
  {
    "arxiv_id": "2503.06474v1",
    "title": "HuixiangDou2: A Robustly Optimized GraphRAG Approach",
    "authors": [
      "Huanjun Kong",
      "Zhefan Wang",
      "Chenyang Wang",
      "Zhe Ma",
      "Nanqing Dong"
    ],
    "abstract": "Large Language Models (LLMs) perform well on familiar queries but struggle\nwith specialized or emerging topics. Graph-based Retrieval-Augmented Generation\n(GraphRAG) addresses this by structuring domain knowledge as a graph for\ndynamic retrieval. However, existing pipelines involve complex engineering\nworkflows, making it difficult to isolate the impact of individual components.\nEvaluating retrieval effectiveness is also challenging due to dataset overlap\nwith LLM pretraining data. In this work, we introduce HuixiangDou2, a robustly\noptimized GraphRAG framework. Specifically, we leverage the effectiveness of\ndual-level retrieval and optimize its performance in a 32k context for maximum\nprecision, and compare logic-based retrieval and dual-level retrieval to\nenhance overall functionality. Our implementation includes comparative\nexperiments on a test set, where Qwen2.5-7B-Instruct initially underperformed.\nWith our approach, the score improved significantly from 60 to 74.5, as\nillustrated in the Figure. Experiments on domain-specific datasets reveal that\ndual-level retrieval enhances fuzzy matching, while logic-form retrieval\nimproves structured reasoning. Furthermore, we propose a multi-stage\nverification mechanism to improve retrieval robustness without increasing\ncomputational cost. Empirical results show significant accuracy gains over\nbaselines, highlighting the importance of adaptive retrieval. To support\nresearch and adoption, we release HuixiangDou2 as an open-source resource\nhttps://github.com/tpoisonooo/huixiangdou2.",
    "categories": [
      "cs.IR",
      "cs.AI",
      "cs.CL"
    ],
    "primary_category": "cs.IR",
    "comment": "11 pages",
    "pdf_url": "http://arxiv.org/pdf/2503.06474v1",
    "published_date": "2025-03-09 06:20:24 UTC",
    "updated_date": "2025-03-09 06:20:24 UTC"
  },
  {
    "arxiv_id": "2503.06473v3",
    "title": "Enhancing Layer Attention Efficiency through Pruning Redundant Retrievals",
    "authors": [
      "Hanze Li",
      "Xiande Huang"
    ],
    "abstract": "Growing evidence suggests that layer attention mechanisms, which enhance\ninteraction among layers in deep neural networks, have significantly advanced\nnetwork architectures. However, existing layer attention methods suffer from\nredundancy, as attention weights learned by adjacent layers often become highly\nsimilar. This redundancy causes multiple layers to extract nearly identical\nfeatures, reducing the model's representational capacity and increasing\ntraining time. To address this issue, we propose a novel approach to quantify\nredundancy by leveraging the Kullback-Leibler (KL) divergence between adjacent\nlayers. Additionally, we introduce an Enhanced Beta Quantile Mapping (EBQM)\nmethod that accurately identifies and skips redundant layers, thereby\nmaintaining model stability. Our proposed Efficient Layer Attention (ELA)\narchitecture, improves both training efficiency and overall performance,\nachieving a 30\\% reduction in training time while enhancing performance in\ntasks such as image classification and object detection.",
    "categories": [
      "cs.CV",
      "cs.AI"
    ],
    "primary_category": "cs.CV",
    "comment": "11 pages, 7 figures",
    "pdf_url": "http://arxiv.org/pdf/2503.06473v3",
    "published_date": "2025-03-09 06:20:11 UTC",
    "updated_date": "2025-03-22 12:05:30 UTC"
  },
  {
    "arxiv_id": "2503.10663v1",
    "title": "Optimal Transport for Brain-Image Alignment: Unveiling Redundancy and Synergy in Neural Information Processing",
    "authors": [
      "Yang Xiao",
      "Wang Lu",
      "Jie Ji",
      "Ruimeng Ye",
      "Gen Li",
      "Xiaolong Ma",
      "Bo Hui"
    ],
    "abstract": "The design of artificial neural networks (ANNs) is inspired by the structure\nof the human brain, and in turn, ANNs offer a potential means to interpret and\nunderstand brain signals. Existing methods primarily align brain signals with\nreal-world signals using Mean Squared Error (MSE), which solely focuses on\nlocal point-wise alignment, and ignores global matching, leading to coarse\ninterpretations and inaccuracies in brain signal decoding.\n  In this paper, we address these issues through optimal transport (OT) and\ntheoretically demonstrate why OT provides a more effective alignment strategy\nthan MSE. Specifically, we construct a transport plan between brain voxel\nembeddings and image embeddings, enabling more precise matching. By controlling\nthe amount of transport, we mitigate the influence of redundant information. We\napply our alignment model directly to the Brain Captioning task by feeding\nbrain siginals into a large language model (LLM) instead of images. Our\napproach achieves state-of-the-art performance across ten evaluation metrics,\nsurpassing the previous best method by an average of 6.11\\% in single-subject\ntraining and 3.81\\% in cross-subject training. Additionally, we have uncovered\nseveral insightful conclusions that align with existing brain research. We\nunveil the redundancy and synergy of brain information processing through\nregion masking and data dimensionality reduction visualization experiments. We\nbelieve our approach paves the way for a more precise understanding of brain\nsignals in the future. The code is available soon.",
    "categories": [
      "q-bio.NC",
      "cs.AI",
      "cs.CV",
      "cs.LG"
    ],
    "primary_category": "q-bio.NC",
    "comment": "14pages",
    "pdf_url": "http://arxiv.org/pdf/2503.10663v1",
    "published_date": "2025-03-09 06:14:23 UTC",
    "updated_date": "2025-03-09 06:14:23 UTC"
  },
  {
    "arxiv_id": "2503.06470v1",
    "title": "Think Twice, Click Once: Enhancing GUI Grounding via Fast and Slow Systems",
    "authors": [
      "Fei Tang",
      "Yongliang Shen",
      "Hang Zhang",
      "Siqi Chen",
      "Guiyang Hou",
      "Wenqi Zhang",
      "Wenqiao Zhang",
      "Kaitao Song",
      "Weiming Lu",
      "Yueting Zhuang"
    ],
    "abstract": "Humans can flexibly switch between different modes of thinking based on task\ncomplexity: from rapid intuitive judgments to in-depth analytical\nunderstanding. However, current Graphical User Interface (GUI) grounding\nsystems which locate interface elements based on natural language instructions\nrely solely on immediate prediction without reasoning, struggling to understand\ncomplex interface layouts with nested structures and hierarchical\nrelationships, limiting their effectiveness on complex interfaces. Inspired by\nhuman dual-system cognition, we present Focus, a novel GUI grounding framework\nthat combines fast prediction with systematic analysis. The framework\ndynamically switches between rapid and deliberate processing through an\nadaptive system switching based on task complexity, optimizing both efficiency\nand accuracy. Focus decomposes grounding into progressive stages: interface\nsummarization, visual focused analysis, and precise coordinate prediction. This\nstructured decomposition enables systematic understanding of both interface\nlayouts and visual relationships. Extensive experiments show that Focus\nachieves state-of-the-art performance using only 300K of the training data with\na 2B parameter model compared to existing approaches. Focus demonstrates\nsuperior performance particularly in complex GUI scenarios, achieving 77.4%\naverage accuracy on ScreenSpot and 13.3% on the more challenging\nScreenSpot-Pro. Our analysis reveals the effectiveness of this dual-system\napproach while demonstrating its potential for improving complex GUI\ninteraction scenarios.",
    "categories": [
      "cs.AI",
      "cs.CL",
      "cs.CV"
    ],
    "primary_category": "cs.AI",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2503.06470v1",
    "published_date": "2025-03-09 06:14:17 UTC",
    "updated_date": "2025-03-09 06:14:17 UTC"
  },
  {
    "arxiv_id": "2503.08704v1",
    "title": "Life-Cycle Routing Vulnerabilities of LLM Router",
    "authors": [
      "Qiqi Lin",
      "Xiaoyang Ji",
      "Shengfang Zhai",
      "Qingni Shen",
      "Zhi Zhang",
      "Yuejian Fang",
      "Yansong Gao"
    ],
    "abstract": "Large language models (LLMs) have achieved remarkable success in natural\nlanguage processing, yet their performance and computational costs vary\nsignificantly. LLM routers play a crucial role in dynamically balancing these\ntrade-offs. While previous studies have primarily focused on routing\nefficiency, security vulnerabilities throughout the entire LLM router life\ncycle, from training to inference, remain largely unexplored. In this paper, we\npresent a comprehensive investigation into the life-cycle routing\nvulnerabilities of LLM routers. We evaluate both white-box and black-box\nadversarial robustness, as well as backdoor robustness, across several\nrepresentative routing models under extensive experimental settings. Our\nexperiments uncover several key findings: 1) Mainstream DNN-based routers tend\nto exhibit the weakest adversarial and backdoor robustness, largely due to\ntheir strong feature extraction capabilities that amplify vulnerabilities\nduring both training and inference; 2) Training-free routers demonstrate the\nstrongest robustness across different attack types, benefiting from the absence\nof learnable parameters that can be manipulated. These findings highlight\ncritical security risks spanning the entire life cycle of LLM routers and\nprovide insights for developing more robust models.",
    "categories": [
      "cs.CR",
      "cs.AI"
    ],
    "primary_category": "cs.CR",
    "comment": "Work in progress",
    "pdf_url": "http://arxiv.org/pdf/2503.08704v1",
    "published_date": "2025-03-09 06:00:35 UTC",
    "updated_date": "2025-03-09 06:00:35 UTC"
  },
  {
    "arxiv_id": "2503.06462v1",
    "title": "StructGS: Adaptive Spherical Harmonics and Rendering Enhancements for Superior 3D Gaussian Splatting",
    "authors": [
      "Zexu Huang",
      "Min Xu",
      "Stuart Perry"
    ],
    "abstract": "Recent advancements in 3D reconstruction coupled with neural rendering\ntechniques have greatly improved the creation of photo-realistic 3D scenes,\ninfluencing both academic research and industry applications. The technique of\n3D Gaussian Splatting and its variants incorporate the strengths of both\nprimitive-based and volumetric representations, achieving superior rendering\nquality. While 3D Geometric Scattering (3DGS) and its variants have advanced\nthe field of 3D representation, they fall short in capturing the stochastic\nproperties of non-local structural information during the training process.\nAdditionally, the initialisation of spherical functions in 3DGS-based methods\noften fails to engage higher-order terms in early training rounds, leading to\nunnecessary computational overhead as training progresses. Furthermore, current\n3DGS-based approaches require training on higher resolution images to render\nhigher resolution outputs, significantly increasing memory demands and\nprolonging training durations. We introduce StructGS, a framework that enhances\n3D Gaussian Splatting (3DGS) for improved novel-view synthesis in 3D\nreconstruction. StructGS innovatively incorporates a patch-based SSIM loss,\ndynamic spherical harmonics initialisation and a Multi-scale Residual Network\n(MSRN) to address the above-mentioned limitations, respectively. Our framework\nsignificantly reduces computational redundancy, enhances detail capture and\nsupports high-resolution rendering from low-resolution inputs. Experimentally,\nStructGS demonstrates superior performance over state-of-the-art (SOTA) models,\nachieving higher quality and more detailed renderings with fewer artifacts.",
    "categories": [
      "cs.CV",
      "cs.AI"
    ],
    "primary_category": "cs.CV",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2503.06462v1",
    "published_date": "2025-03-09 05:39:44 UTC",
    "updated_date": "2025-03-09 05:39:44 UTC"
  },
  {
    "arxiv_id": "2503.06457v1",
    "title": "Geometric Knowledge-Guided Localized Global Distribution Alignment for Federated Learning",
    "authors": [
      "Yanbiao Ma",
      "Wei Dai",
      "Wenke Huang",
      "Jiayi Chen"
    ],
    "abstract": "Data heterogeneity in federated learning, characterized by a significant\nmisalignment between local and global distributions, leads to divergent local\noptimization directions and hinders global model training. Existing studies\nmainly focus on optimizing local updates or global aggregation, but these\nindirect approaches demonstrate instability when handling highly heterogeneous\ndata distributions, especially in scenarios where label skew and domain skew\ncoexist. To address this, we propose a geometry-guided data generation method\nthat centers on simulating the global embedding distribution locally. We first\nintroduce the concept of the geometric shape of an embedding distribution and\nthen address the challenge of obtaining global geometric shapes under privacy\nconstraints. Subsequently, we propose GGEUR, which leverages global geometric\nshapes to guide the generation of new samples, enabling a closer approximation\nto the ideal global distribution. In single-domain scenarios, we augment\nsamples based on global geometric shapes to enhance model generalization; in\nmulti-domain scenarios, we further employ class prototypes to simulate the\nglobal distribution across domains. Extensive experimental results demonstrate\nthat our method significantly enhances the performance of existing approaches\nin handling highly heterogeneous data, including scenarios with label skew,\ndomain skew, and their coexistence. Code published at:\nhttps://github.com/WeiDai-David/2025CVPR_GGEUR",
    "categories": [
      "cs.CV",
      "cs.AI"
    ],
    "primary_category": "cs.CV",
    "comment": "Accepted by CVPR 2025",
    "pdf_url": "http://arxiv.org/pdf/2503.06457v1",
    "published_date": "2025-03-09 05:30:28 UTC",
    "updated_date": "2025-03-09 05:30:28 UTC"
  },
  {
    "arxiv_id": "2503.06444v1",
    "title": "CtrTab: Tabular Data Synthesis with High-Dimensional and Limited Data",
    "authors": [
      "Zuqing Li",
      "Jianzhong Qi",
      "Junhao Gan"
    ],
    "abstract": "Diffusion-based tabular data synthesis models have yielded promising results.\nHowever, we observe that when the data dimensionality increases, existing\nmodels tend to degenerate and may perform even worse than simpler,\nnon-diffusion-based models. This is because limited training samples in\nhigh-dimensional space often hinder generative models from capturing the\ndistribution accurately. To address this issue, we propose CtrTab-a condition\ncontrolled diffusion model for tabular data synthesis-to improve the\nperformance of diffusion-based generative models in high-dimensional, low-data\nscenarios. Through CtrTab, we inject samples with added Laplace noise as\ncontrol signals to improve data diversity and show its resemblance to L2\nregularization, which enhances model robustness. Experimental results across\nmultiple datasets show that CtrTab outperforms state-of-the-art models, with\nperformance gap in accuracy over 80% on average. Our source code will be\nreleased upon paper publication.",
    "categories": [
      "cs.LG",
      "cs.AI",
      "cs.DB"
    ],
    "primary_category": "cs.LG",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2503.06444v1",
    "published_date": "2025-03-09 05:01:56 UTC",
    "updated_date": "2025-03-09 05:01:56 UTC"
  },
  {
    "arxiv_id": "2503.06436v1",
    "title": "Physics-Informed Residual Neural Ordinary Differential Equations for Enhanced Tropical Cyclone Intensity Forecasting",
    "authors": [
      "Fan Meng"
    ],
    "abstract": "Accurate tropical cyclone (TC) intensity prediction is crucial for mitigating\nstorm hazards, yet its complex dynamics pose challenges to traditional methods.\nHere, we introduce a Physics-Informed Residual Neural Ordinary Differential\nEquation (PIR-NODE) model to precisely forecast TC intensity evolution. This\nmodel leverages the powerful non-linear fitting capabilities of deep learning,\nintegrates residual connections to enhance model depth and training stability,\nand explicitly models the continuous temporal evolution of TC intensity using\nNeural ODEs. Experimental results in the SHIPS dataset demonstrate that the\nPIR-NODE model achieves a significant improvement in 24-hour intensity\nprediction accuracy compared to traditional statistical models and benchmark\ndeep learning methods, with a 25. 2\\% reduction in the root mean square error\n(RMSE) and a 19.5\\% increase in R-square (R2) relative to a baseline of neural\nnetwork. Crucially, the residual structure effectively preserves initial state\ninformation, and the model exhibits robust generalization capabilities. This\nstudy details the PIR-NODE model architecture, physics-informed integration\nstrategies, and comprehensive experimental validation, revealing the\nsubstantial potential of deep learning techniques in predicting complex\ngeophysical systems and laying the foundation for future refined TC forecasting\nresearch.",
    "categories": [
      "physics.ao-ph",
      "cs.AI"
    ],
    "primary_category": "physics.ao-ph",
    "comment": "14 pages, 9 figures",
    "pdf_url": "http://arxiv.org/pdf/2503.06436v1",
    "published_date": "2025-03-09 04:23:07 UTC",
    "updated_date": "2025-03-09 04:23:07 UTC"
  },
  {
    "arxiv_id": "2503.06433v1",
    "title": "Seesaw: High-throughput LLM Inference via Model Re-sharding",
    "authors": [
      "Qidong Su",
      "Wei Zhao",
      "Xin Li",
      "Muralidhar Andoorveedu",
      "Chenhao Jiang",
      "Zhanda Zhu",
      "Kevin Song",
      "Christina Giannoula",
      "Gennady Pekhimenko"
    ],
    "abstract": "To improve the efficiency of distributed large language model (LLM)\ninference, various parallelization strategies, such as tensor and pipeline\nparallelism, have been proposed. However, the distinct computational\ncharacteristics inherent in the two stages of LLM inference-prefilling and\ndecoding-render a single static parallelization strategy insufficient for the\neffective optimization of both stages. In this work, we present Seesaw, an LLM\ninference engine optimized for throughput-oriented tasks. The key idea behind\nSeesaw is dynamic model re-sharding, a technique that facilitates the dynamic\nreconfiguration of parallelization strategies across stages, thereby maximizing\nthroughput at both phases. To mitigate re-sharding overhead and optimize\ncomputational efficiency, we employ tiered KV cache buffering and\ntransition-minimizing scheduling. These approaches work synergistically to\nreduce the overhead caused by frequent stage transitions while ensuring maximum\nbatching efficiency. Our evaluation demonstrates that Seesaw achieves a\nthroughput increase of up to 1.78x (1.36x on average) compared to vLLM, the\nmost widely used state-of-the-art LLM inference engine.",
    "categories": [
      "cs.DC",
      "cs.AI"
    ],
    "primary_category": "cs.DC",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2503.06433v1",
    "published_date": "2025-03-09 04:14:06 UTC",
    "updated_date": "2025-03-09 04:14:06 UTC"
  },
  {
    "arxiv_id": "2503.06430v1",
    "title": "Graph Retrieval-Augmented LLM for Conversational Recommendation Systems",
    "authors": [
      "Zhangchi Qiu",
      "Linhao Luo",
      "Zicheng Zhao",
      "Shirui Pan",
      "Alan Wee-Chung Liew"
    ],
    "abstract": "Conversational Recommender Systems (CRSs) have emerged as a transformative\nparadigm for offering personalized recommendations through natural language\ndialogue. However, they face challenges with knowledge sparsity, as users often\nprovide brief, incomplete preference statements. While recent methods have\nintegrated external knowledge sources to mitigate this, they still struggle\nwith semantic understanding and complex preference reasoning. Recent Large\nLanguage Models (LLMs) demonstrate promising capabilities in natural language\nunderstanding and reasoning, showing significant potential for CRSs.\nNevertheless, due to the lack of domain knowledge, existing LLM-based CRSs\neither produce hallucinated recommendations or demand expensive domain-specific\ntraining, which largely limits their applicability. In this work, we present\nG-CRS (Graph Retrieval-Augmented Large Language Model for Conversational\nRecommender Systems), a novel training-free framework that combines graph\nretrieval-augmented generation and in-context learning to enhance LLMs'\nrecommendation capabilities. Specifically, G-CRS employs a two-stage\nretrieve-and-recommend architecture, where a GNN-based graph reasoner first\nidentifies candidate items, followed by Personalized PageRank exploration to\njointly discover potential items and similar user interactions. These retrieved\ncontexts are then transformed into structured prompts for LLM reasoning,\nenabling contextually grounded recommendations without task-specific training.\nExtensive experiments on two public datasets show that G-CRS achieves superior\nrecommendation performance compared to existing methods without requiring\ntask-specific training.",
    "categories": [
      "cs.CL",
      "cs.AI",
      "cs.IR"
    ],
    "primary_category": "cs.CL",
    "comment": "Accepted by PAKDD 2025",
    "pdf_url": "http://arxiv.org/pdf/2503.06430v1",
    "published_date": "2025-03-09 03:56:22 UTC",
    "updated_date": "2025-03-09 03:56:22 UTC"
  },
  {
    "arxiv_id": "2503.06427v1",
    "title": "Pre-Training Meta-Rule Selection Policy for Visual Generative Abductive Learning",
    "authors": [
      "Yu Jin",
      "Jingming Liu",
      "Zhexu Luo",
      "Yifei Peng",
      "Ziang Qin",
      "Wang-Zhou Dai",
      "Yao-Xiang Ding",
      "Kun Zhou"
    ],
    "abstract": "Visual generative abductive learning studies jointly training symbol-grounded\nneural visual generator and inducing logic rules from data, such that after\nlearning, the visual generation process is guided by the induced logic rules. A\nmajor challenge for this task is to reduce the time cost of logic abduction\nduring learning, an essential step when the logic symbol set is large and the\nlogic rule to induce is complicated. To address this challenge, we propose a\npre-training method for obtaining meta-rule selection policy for the recently\nproposed visual generative learning approach AbdGen [Peng et al., 2023], aiming\nat significantly reducing the candidate meta-rule set and pruning the search\nspace. The selection model is built based on the embedding representation of\nboth symbol grounding of cases and meta-rules, which can be effectively\nintegrated with both neural model and logic reasoning system. The pre-training\nprocess is done on pure symbol data, not involving symbol grounding learning of\nraw visual inputs, making the entire learning process low-cost. An additional\ninteresting observation is that the selection policy can rectify symbol\ngrounding errors unseen during pre-training, which is resulted from the\nmemorization ability of attention mechanism and the relative stability of\nsymbolic patterns. Experimental results show that our method is able to\neffectively address the meta-rule selection problem for visual abduction,\nboosting the efficiency of visual generative abductive learning. Code is\navailable at https://github.com/future-item/metarule-select.",
    "categories": [
      "cs.LG",
      "cs.AI",
      "cs.CV"
    ],
    "primary_category": "cs.LG",
    "comment": "Published as a conference paper at IJCLR'24",
    "pdf_url": "http://arxiv.org/pdf/2503.06427v1",
    "published_date": "2025-03-09 03:41:11 UTC",
    "updated_date": "2025-03-09 03:41:11 UTC"
  },
  {
    "arxiv_id": "2503.06422v1",
    "title": "GenAI for Simulation Model in Model-Based Systems Engineering",
    "authors": [
      "Lin Zhang",
      "Yuteng Zhang",
      "Dusit Niyato",
      "Lei Ren",
      "Pengfei Gu",
      "Zhen Chen",
      "Yuanjun Laili",
      "Wentong Cai",
      "Agostino Bruzzone"
    ],
    "abstract": "Generative AI (GenAI) has demonstrated remarkable capabilities in code\ngeneration, and its integration into complex product modeling and simulation\ncode generation can significantly enhance the efficiency of the system design\nphase in Model-Based Systems Engineering (MBSE). In this study, we introduce a\ngenerative system design methodology framework for MBSE, offering a practical\napproach for the intelligent generation of simulation models for system\nphysical properties. First, we employ inference techniques, generative models,\nand integrated modeling and simulation languages to construct simulation models\nfor system physical properties based on product design documents. Subsequently,\nwe fine-tune the language model used for simulation model generation on an\nexisting library of simulation models and additional datasets generated through\ngenerative modeling. Finally, we introduce evaluation metrics for the generated\nsimulation models for system physical properties. Our proposed approach to\nsimulation model generation presents the innovative concept of scalable\ntemplates for simulation models. Using these templates, GenAI generates\nsimulation models for system physical properties through code completion. The\nexperimental results demonstrate that, for mainstream open-source\nTransformer-based models, the quality of the simulation model is significantly\nimproved using the simulation model generation method proposed in this paper.",
    "categories": [
      "cs.SE",
      "cs.AI"
    ],
    "primary_category": "cs.SE",
    "comment": "This work has been submitted to the IEEE for possible publication",
    "pdf_url": "http://arxiv.org/pdf/2503.06422v1",
    "published_date": "2025-03-09 03:33:25 UTC",
    "updated_date": "2025-03-09 03:33:25 UTC"
  },
  {
    "arxiv_id": "2503.06420v2",
    "title": "Explaining Control Policies through Predicate Decision Diagrams",
    "authors": [
      "Debraj Chakraborty",
      "Clemens Dubslaff",
      "Sudeep Kanav",
      "Jan Kretinsky",
      "Christoph Weinhuber"
    ],
    "abstract": "Safety-critical controllers of complex systems are hard to construct\nmanually. Automated approaches such as controller synthesis or learning provide\na tempting alternative but usually lack explainability. To this end, learning\ndecision trees (DTs) have been prevalently used towards an interpretable model\nof the generated controllers. However, DTs do not exploit shared\ndecision-making, a key concept exploited in binary decision diagrams (BDDs) to\nreduce their size and thus improve explainability. In this work, we introduce\npredicate decision diagrams (PDDs) that extend BDDs with predicates and thus\nunite the advantages of DTs and BDDs for controller representation. We\nestablish a synthesis pipeline for efficient construction of PDDs from DTs\nrepresenting controllers, exploiting reduction techniques for BDDs also for\nPDDs.",
    "categories": [
      "cs.AI",
      "cs.SY",
      "eess.SY"
    ],
    "primary_category": "cs.AI",
    "comment": "Extended version of the HSCC 2025 paper",
    "pdf_url": "http://arxiv.org/pdf/2503.06420v2",
    "published_date": "2025-03-09 03:31:48 UTC",
    "updated_date": "2025-03-25 16:57:55 UTC"
  },
  {
    "arxiv_id": "2503.06416v1",
    "title": "Advancing AI Negotiations: New Theory and Evidence from a Large-Scale Autonomous Negotiations Competition",
    "authors": [
      "Michelle Vaccaro",
      "Michael Caoson",
      "Harang Ju",
      "Sinan Aral",
      "Jared R. Curhan"
    ],
    "abstract": "Despite the rapid proliferation of artificial intelligence (AI) negotiation\nagents, there has been limited integration of computer science research and\nestablished negotiation theory to develop new theories of AI negotiation. To\nbridge this gap, we conducted an International AI Negotiations Competition in\nwhich participants iteratively designed and refined prompts for large language\nmodel (LLM) negotiation agents. We then facilitated over 120,000 negotiations\nbetween these agents across multiple scenarios with diverse characteristics and\nobjectives. Our findings revealed that fundamental principles from established\nhuman-human negotiation theory remain crucial in AI-AI negotiations.\nSpecifically, agents exhibiting high warmth fostered higher counterpart\nsubjective value and reached deals more frequently, which enabled them to\ncreate and claim more value in integrative settings. However, conditional on\nreaching a deal, warm agents claimed less value while dominant agents claimed\nmore value. These results align with classic negotiation theory emphasizing\nrelationship-building, assertiveness, and preparation. Our analysis also\nrevealed unique dynamics in AI-AI negotiations not fully explained by\nnegotiation theory, particularly regarding the effectiveness of AI-specific\nstrategies like chain-of-thought reasoning and prompt injection. The agent that\nwon our competition implemented an approach that blended traditional\nnegotiation preparation frameworks with AI-specific methods. Together, these\nresults suggest the importance of establishing a new theory of AI negotiations\nthat integrates established negotiation theory with AI-specific strategies to\noptimize agent performance. Our research suggests this new theory must account\nfor the unique characteristics of autonomous agents and establish the\nconditions under which traditional negotiation theory applies in automated\nsettings.",
    "categories": [
      "cs.AI",
      "cs.HC"
    ],
    "primary_category": "cs.AI",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2503.06416v1",
    "published_date": "2025-03-09 03:25:48 UTC",
    "updated_date": "2025-03-09 03:25:48 UTC"
  },
  {
    "arxiv_id": "2503.06413v2",
    "title": "Swift Hydra: Self-Reinforcing Generative Framework for Anomaly Detection with Multiple Mamba Models",
    "authors": [
      "Nguyen Do",
      "Truc Nguyen",
      "Malik Hassanaly",
      "Raed Alharbi",
      "Jung Taek Seo",
      "My T. Thai"
    ],
    "abstract": "Despite a plethora of anomaly detection models developed over the years,\ntheir ability to generalize to unseen anomalies remains an issue, particularly\nin critical systems. This paper aims to address this challenge by introducing\nSwift Hydra, a new framework for training an anomaly detection method based on\ngenerative AI and reinforcement learning (RL). Through featuring an RL policy\nthat operates on the latent variables of a generative model, the framework\nsynthesizes novel and diverse anomaly samples that are capable of bypassing a\ndetection model. These generated synthetic samples are, in turn, used to\naugment the detection model, further improving its ability to handle\nchallenging anomalies. Swift Hydra also incorporates Mamba models structured as\na Mixture of Experts (MoE) to enable scalable adaptation of the number of Mamba\nexperts based on data complexity, effectively capturing diverse feature\ndistributions without increasing the model's inference time. Empirical\nevaluations on ADBench benchmark demonstrate that Swift Hydra outperforms other\nstate-of-the-art anomaly detection models while maintaining a relatively short\ninference time. From these results, our research highlights a new and\nauspicious paradigm of integrating RL and generative AI for advancing anomaly\ndetection.",
    "categories": [
      "stat.ML",
      "cs.AI",
      "cs.LG"
    ],
    "primary_category": "stat.ML",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2503.06413v2",
    "published_date": "2025-03-09 03:15:15 UTC",
    "updated_date": "2025-03-25 02:53:03 UTC"
  },
  {
    "arxiv_id": "2503.06411v1",
    "title": "Decoding the Black Box: Integrating Moral Imagination with Technical AI Governance",
    "authors": [
      "Krti Tallam"
    ],
    "abstract": "This paper examines the intricate interplay among AI safety, security, and\ngovernance by integrating technical systems engineering with principles of\nmoral imagination and ethical philosophy. Drawing on foundational insights from\nWeapons of Math Destruction and Thinking in Systems alongside contemporary\ndebates in AI ethics, we develop a comprehensive multi-dimensional framework\ndesigned to regulate AI technologies deployed in high-stakes domains such as\ndefense, finance, healthcare, and education. Our approach combines rigorous\ntechnical analysis, quantitative risk assessment, and normative evaluation to\nexpose systemic vulnerabilities inherent in opaque, black-box models. Detailed\ncase studies, including analyses of Microsoft Tay (2016) and the UK A-Level\nGrading Algorithm (2020), demonstrate how security lapses, bias amplification,\nand lack of accountability can precipitate cascading failures that undermine\npublic trust. We conclude by outlining targeted strategies for enhancing AI\nresilience through adaptive regulatory mechanisms, robust security protocols,\nand interdisciplinary oversight, thereby advancing the state of the art in\nethical and technical AI governance.",
    "categories": [
      "eess.SY",
      "cs.AI",
      "cs.SY"
    ],
    "primary_category": "eess.SY",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2503.06411v1",
    "published_date": "2025-03-09 03:11:32 UTC",
    "updated_date": "2025-03-09 03:11:32 UTC"
  },
  {
    "arxiv_id": "2503.06410v1",
    "title": "Performant LLM Agentic Framework for Conversational AI",
    "authors": [
      "Alex Casella",
      "Wayne Wang"
    ],
    "abstract": "The rise of Agentic applications and automation in the Voice AI industry has\nled to an increased reliance on Large Language Models (LLMs) to navigate\ngraph-based logic workflows composed of nodes and edges. However, existing\nmethods face challenges such as alignment errors in complex workflows and\nhallucinations caused by excessive context size. To address these limitations,\nwe introduce the Performant Agentic Framework (PAF), a novel system that\nassists LLMs in selecting appropriate nodes and executing actions in order when\ntraversing complex graphs. PAF combines LLM-based reasoning with a\nmathematically grounded vector scoring mechanism, achieving both higher\naccuracy and reduced latency. Our approach dynamically balances strict\nadherence to predefined paths with flexible node jumps to handle various user\ninputs efficiently. Experiments demonstrate that PAF significantly outperforms\nbaseline methods, paving the way for scalable, real-time Conversational AI\nsystems in complex business environments.",
    "categories": [
      "cs.AI"
    ],
    "primary_category": "cs.AI",
    "comment": "6 pages, 3 figures",
    "pdf_url": "http://arxiv.org/pdf/2503.06410v1",
    "published_date": "2025-03-09 02:58:34 UTC",
    "updated_date": "2025-03-09 02:58:34 UTC"
  },
  {
    "arxiv_id": "2503.06405v2",
    "title": "Heterogeneous bimodal attention fusion for speech emotion recognition",
    "authors": [
      "Jiachen Luo",
      "Huy Phan",
      "Lin Wang",
      "Joshua Reiss"
    ],
    "abstract": "Multi-modal emotion recognition in conversations is a challenging problem due\nto the complex and complementary interactions between different modalities.\nAudio and textual cues are particularly important for understanding emotions\nfrom a human perspective. Most existing studies focus on exploring interactions\nbetween audio and text modalities at the same representation level. However, a\ncritical issue is often overlooked: the heterogeneous modality gap between\nlow-level audio representations and high-level text representations. To address\nthis problem, we propose a novel framework called Heterogeneous Bimodal\nAttention Fusion (HBAF) for multi-level multi-modal interaction in\nconversational emotion recognition. The proposed method comprises three key\nmodules: the uni-modal representation module, the multi-modal fusion module,\nand the inter-modal contrastive learning module. The uni-modal representation\nmodule incorporates contextual content into low-level audio representations to\nbridge the heterogeneous multi-modal gap, enabling more effective fusion. The\nmulti-modal fusion module uses dynamic bimodal attention and a dynamic gating\nmechanism to filter incorrect cross-modal relationships and fully exploit both\nintra-modal and inter-modal interactions. Finally, the inter-modal contrastive\nlearning module captures complex absolute and relative interactions between\naudio and text modalities. Experiments on the MELD and IEMOCAP datasets\ndemonstrate that the proposed HBAF method outperforms existing state-of-the-art\nbaselines.",
    "categories": [
      "cs.SD",
      "cs.AI",
      "eess.AS"
    ],
    "primary_category": "cs.SD",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2503.06405v2",
    "published_date": "2025-03-09 02:50:49 UTC",
    "updated_date": "2025-03-23 08:21:43 UTC"
  },
  {
    "arxiv_id": "2503.06398v1",
    "title": "Causality Enhanced Origin-Destination Flow Prediction in Data-Scarce Cities",
    "authors": [
      "Tao Feng",
      "Yunke Zhang",
      "Huandong Wang",
      "Yong Li"
    ],
    "abstract": "Accurate origin-destination (OD) flow prediction is of great importance to\ndeveloping cities, as it can contribute to optimize urban structures and\nlayouts. However, with the common issues of missing regional features and\nlacking OD flow data, it is quite daunting to predict OD flow in developing\ncities. To address this challenge, we propose a novel Causality-Enhanced OD\nFlow Prediction (CE-OFP), a unified framework that aims to transfer urban\nknowledge between cities and achieve accuracy improvements in OD flow\npredictions across data-scarce cities. In specific, we propose a novel\nreinforcement learning model to discover universal causalities among urban\nfeatures in data-rich cities and build corresponding causal graphs. Then, we\nfurther build Causality-Enhanced Variational Auto-Encoder (CE-VAE) to\nincorporate causal graphs for effective feature reconstruction in data-scarce\ncities. Finally, with the reconstructed features, we devise a knowledge\ndistillation method with a graph attention network to migrate the OD prediction\nmodel from data-rich cities to data-scare cities. Extensive experiments on two\npairs of real-world datasets validate that the proposed CE-OFP remarkably\noutperforms state-of-the-art baselines, which can reduce the RMSE of OD flow\nprediction for data-scarce cities by up to 11%.",
    "categories": [
      "cs.LG",
      "cs.AI"
    ],
    "primary_category": "cs.LG",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2503.06398v1",
    "published_date": "2025-03-09 02:36:36 UTC",
    "updated_date": "2025-03-09 02:36:36 UTC"
  },
  {
    "arxiv_id": "2503.06396v1",
    "title": "Optimizing Minimum Vertex Cover Solving via a GCN-assisted Heuristic Algorithm",
    "authors": [
      "Enqiang Zhu",
      "Qiqi Bao",
      "Yu Zhang",
      "Chanjuan Liu"
    ],
    "abstract": "The problem of finding a minimum vertex cover (MVC) in a graph is a\nwell-known NP-hard problem with significant practical applications in\noptimization and scheduling. Its complexity, combined with the increasing scale\nof problems, underscores the need for efficient and effective algorithms.\nHowever, existing heuristic algorithms for MVC often rely on simplistic\ninitialization strategies and overlook the impact of edge attributes and\nneighborhood information on vertex selection. In this paper, we introduce\nGCNIVC, a novel heuristic search algorithm designed to address the limitations\nof existing methods for solving MVC problems in large-scale graphs. Our\napproach features two main innovations. First, it utilizes a Graph\nConvolutional Network (GCN) to capture the global structure of graphs, which\nenables the generation of high-quality initial solutions that enhance the\nefficiency of the subsequent search process. Second, GCNIVC introduces a new\nheuristic that employs three containers and the concept of double-covered edges\n(dc-edges), improving search efficiency and providing greater flexibility for\nadding and removing operations based on edge attributes. Through extensive\nexperiments on benchmark datasets, we demonstrate that GCNIVC outperforms\nstate-of-the-art MVC algorithms in terms of both accuracy and efficiency. Our\nresults highlight the effectiveness of GCNIVC's GCN-assisted initialization and\nits edge-informed search strategy. This study not only advances the\nunderstanding of MVC problem-solving but also contributes a new tool for\naddressing large-scale graph optimization challenges.",
    "categories": [
      "cs.AI"
    ],
    "primary_category": "cs.AI",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2503.06396v1",
    "published_date": "2025-03-09 02:31:03 UTC",
    "updated_date": "2025-03-09 02:31:03 UTC"
  },
  {
    "arxiv_id": "2503.06395v1",
    "title": "Causal Discovery and Inference towards Urban Elements and Associated Factors",
    "authors": [
      "Tao Feng",
      "Yunke Zhang",
      "Xiaochen Fan",
      "Huandong Wang",
      "Yong Li"
    ],
    "abstract": "To uncover the city's fundamental functioning mechanisms, it is important to\nacquire a deep understanding of complicated relationships among citizens,\nlocation, and mobility behaviors. Previous research studies have applied direct\ncorrelation analysis to investigate such relationships. Nevertheless, due to\nthe ubiquitous confounding effects, empirical correlation analysis may not\naccurately reflect underlying causal relationships among basic urban elements.\nIn this paper, we propose a novel urban causal computing framework to\ncomprehensively explore causalities and confounding effects among a variety of\nfactors across different types of urban elements. In particular, we design a\nreinforcement learning algorithm to discover the potential causal graph, which\ndepicts the causal relations between urban factors. The causal graph further\nserves as the guidance for estimating causal effects between pair-wise urban\nfactors by propensity score matching. After removing the confounding effects\nfrom correlations, we leverage significance levels of causal effects in\ndownstream urban mobility prediction tasks. Experimental studies on open-source\nurban datasets show that the discovered causal graph demonstrates a\nhierarchical structure, where citizens affect locations, and they both cause\nchanges in urban mobility behaviors. Experimental results in urban mobility\nprediction tasks further show that the proposed method can effectively reduce\nconfounding effects and enhance performance of urban computing tasks.",
    "categories": [
      "cs.AI"
    ],
    "primary_category": "cs.AI",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2503.06395v1",
    "published_date": "2025-03-09 02:15:04 UTC",
    "updated_date": "2025-03-09 02:15:04 UTC"
  },
  {
    "arxiv_id": "2503.06392v1",
    "title": "EPR-GAIL: An EPR-Enhanced Hierarchical Imitation Learning Framework to Simulate Complex User Consumption Behaviors",
    "authors": [
      "Tao Feng",
      "Yunke Zhang",
      "Huandong Wang",
      "Yong Li"
    ],
    "abstract": "User consumption behavior data, which records individuals' online spending\nhistory at various types of stores, has been widely used in various\napplications, such as store recommendation, site selection, and sale\nforecasting. However, its high worth is limited due to deficiencies in data\ncomprehensiveness and changes of application scenarios. Thus, generating\nhigh-quality sequential consumption data by simulating complex user consumption\nbehaviors is of great importance to real-world applications. Two branches of\nexisting sequence generation methods are both limited in quality. Model-based\nmethods with simplified assumptions fail to model the complex decision process\nof user consumption, while data-driven methods that emulate real-world data are\nprone to noises, unobserved behaviors, and dynamic decision space. In this\nwork, we propose to enhance the fidelity and trustworthiness of the data-driven\nGenerative Adversarial Imitation Learning (GAIL) method by blending it with the\nExploration and Preferential Return EPR model . The core idea of our EPR-GAIL\nframework is to model user consumption behaviors as a complex EPR decision\nprocess, which consists of purchase, exploration, and preference decisions.\nSpecifically, we design the hierarchical policy function in the generator as a\nrealization of the EPR decision process and employ the probability\ndistributions of the EPR model to guide the reward function in the\ndiscriminator. Extensive experiments on two real-world datasets of user\nconsumption behaviors on an online platform demonstrate that the EPR-GAIL\nframework outperforms the best state-of-the-art baseline by over 19\\% in terms\nof data fidelity. Furthermore, the generated consumption behavior data can\nimprove the performance of sale prediction and location recommendation by up to\n35.29% and 11.19%, respectively, validating its advantage for practical\napplications.",
    "categories": [
      "cs.LG",
      "cs.AI"
    ],
    "primary_category": "cs.LG",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2503.06392v1",
    "published_date": "2025-03-09 01:56:42 UTC",
    "updated_date": "2025-03-09 01:56:42 UTC"
  },
  {
    "arxiv_id": "2503.07667v2",
    "title": "CLIMB: Data Foundations for Large Scale Multimodal Clinical Foundation Models",
    "authors": [
      "Wei Dai",
      "Peilin Chen",
      "Malinda Lu",
      "Daniel Li",
      "Haowen Wei",
      "Hejie Cui",
      "Paul Pu Liang"
    ],
    "abstract": "Recent advances in clinical AI have enabled remarkable progress across many\nclinical domains. However, existing benchmarks and models are primarily limited\nto a small set of modalities and tasks, which hinders the development of\nlarge-scale multimodal methods that can make holistic assessments of patient\nhealth and well-being. To bridge this gap, we introduce Clinical Large-Scale\nIntegrative Multimodal Benchmark (CLIMB), a comprehensive clinical benchmark\nunifying diverse clinical data across imaging, language, temporal, and graph\nmodalities. CLIMB comprises 4.51 million patient samples totaling 19.01\nterabytes distributed across 2D imaging, 3D video, time series, graphs, and\nmultimodal data. Through extensive empirical evaluation, we demonstrate that\nmultitask pretraining significantly improves performance on understudied\ndomains, achieving up to 29% improvement in ultrasound and 23% in ECG analysis\nover single-task learning. Pretraining on CLIMB also effectively improves\nmodels' generalization capability to new tasks, and strong unimodal encoder\nperformance translates well to multimodal performance when paired with\ntask-appropriate fusion strategies. Our findings provide a foundation for new\narchitecture designs and pretraining strategies to advance clinical AI\nresearch. Code is released at https://github.com/DDVD233/climb.",
    "categories": [
      "cs.LG",
      "cs.AI",
      "cs.CV",
      "eess.SP"
    ],
    "primary_category": "cs.LG",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2503.07667v2",
    "published_date": "2025-03-09 01:45:05 UTC",
    "updated_date": "2025-03-20 05:05:56 UTC"
  },
  {
    "arxiv_id": "2503.06378v2",
    "title": "General Scales Unlock AI Evaluation with Explanatory and Predictive Power",
    "authors": [
      "Lexin Zhou",
      "Lorenzo Pacchiardi",
      "Fernando MartÃ­nez-Plumed",
      "Katherine M. Collins",
      "Yael Moros-Daval",
      "Seraphina Zhang",
      "Qinlin Zhao",
      "Yitian Huang",
      "Luning Sun",
      "Jonathan E. Prunty",
      "Zongqian Li",
      "Pablo SÃ¡nchez-GarcÃ­a",
      "Kexin Jiang Chen",
      "Pablo A. M. Casares",
      "Jiyun Zu",
      "John Burden",
      "Behzad Mehrbakhsh",
      "David Stillwell",
      "Manuel Cebrian",
      "Jindong Wang",
      "Peter Henderson",
      "Sherry Tongshuang Wu",
      "Patrick C. Kyllonen",
      "Lucy Cheke",
      "Xing Xie",
      "JosÃ© HernÃ¡ndez-Orallo"
    ],
    "abstract": "Ensuring safe and effective use of AI requires understanding and anticipating\nits performance on novel tasks, from advanced scientific challenges to\ntransformed workplace activities. So far, benchmarking has guided progress in\nAI, but it has offered limited explanatory and predictive power for\ngeneral-purpose AI systems, given the low transferability across diverse tasks.\nIn this paper, we introduce general scales for AI evaluation that can explain\nwhat common AI benchmarks really measure, extract ability profiles of AI\nsystems, and predict their performance for new task instances, in- and\nout-of-distribution. Our fully-automated methodology builds on 18 newly-crafted\nrubrics that place instance demands on general scales that do not saturate.\nIllustrated for 15 large language models and 63 tasks, high explanatory power\nis unleashed from inspecting the demand and ability profiles, bringing insights\non the sensitivity and specificity exhibited by different benchmarks, and how\nknowledge, metacognition and reasoning are affected by model size,\nchain-of-thought and distillation. Surprisingly, high predictive power at the\ninstance level becomes possible using these demand levels, providing superior\nestimates over black-box baseline predictors based on embeddings or finetuning,\nespecially in out-of-distribution settings (new tasks and new benchmarks). The\nscales, rubrics, battery, techniques and results presented here represent a\nmajor step for AI evaluation, underpinning the reliable deployment of AI in the\nyears ahead. (Collaborative platform:\nhttps://kinds-of-intelligence-cfi.github.io/ADELE.)",
    "categories": [
      "cs.AI",
      "cs.CL",
      "cs.CY"
    ],
    "primary_category": "cs.AI",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2503.06378v2",
    "published_date": "2025-03-09 01:13:56 UTC",
    "updated_date": "2025-03-16 02:28:10 UTC"
  },
  {
    "arxiv_id": "2503.06368v1",
    "title": "VORTEX: Challenging CNNs at Texture Recognition by using Vision Transformers with Orderless and Randomized Token Encodings",
    "authors": [
      "Leonardo Scabini",
      "Kallil M. Zielinski",
      "Emir Konuk",
      "Ricardo T. Fares",
      "Lucas C. Ribas",
      "Kevin Smith",
      "Odemir M. Bruno"
    ],
    "abstract": "Texture recognition has recently been dominated by ImageNet-pre-trained deep\nConvolutional Neural Networks (CNNs), with specialized modifications and\nfeature engineering required to achieve state-of-the-art (SOTA) performance.\nHowever, although Vision Transformers (ViTs) were introduced a few years ago,\nlittle is known about their texture recognition ability. Therefore, in this\nwork, we introduce VORTEX (ViTs with Orderless and Randomized Token Encodings\nfor Texture Recognition), a novel method that enables the effective use of ViTs\nfor texture analysis. VORTEX extracts multi-depth token embeddings from\npre-trained ViT backbones and employs a lightweight module to aggregate\nhierarchical features and perform orderless encoding, obtaining a better image\nrepresentation for texture recognition tasks. This approach allows seamless\nintegration with any ViT with the common transformer architecture. Moreover, no\nfine-tuning of the backbone is performed, since they are used only as frozen\nfeature extractors, and the features are fed to a linear SVM. We evaluate\nVORTEX on nine diverse texture datasets, demonstrating its ability to achieve\nor surpass SOTA performance in a variety of texture analysis scenarios. By\nbridging the gap between texture recognition with CNNs and transformer-based\narchitectures, VORTEX paves the way for adopting emerging transformer\nfoundation models. Furthermore, VORTEX demonstrates robust computational\nefficiency when coupled with ViT backbones compared to CNNs with similar costs.\nThe method implementation and experimental scripts are publicly available in\nour online repository.",
    "categories": [
      "cs.CV",
      "cs.AI",
      "cs.LG"
    ],
    "primary_category": "cs.CV",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2503.06368v1",
    "published_date": "2025-03-09 00:36:02 UTC",
    "updated_date": "2025-03-09 00:36:02 UTC"
  },
  {
    "arxiv_id": "2503.06366v1",
    "title": "Machine Learning meets Algebraic Combinatorics: A Suite of Datasets Capturing Research-level Conjecturing Ability in Pure Mathematics",
    "authors": [
      "Herman Chau",
      "Helen Jenne",
      "Davis Brown",
      "Jesse He",
      "Mark Raugas",
      "Sara Billey",
      "Henry Kvinge"
    ],
    "abstract": "With recent dramatic increases in AI system capabilities, there has been\ngrowing interest in utilizing machine learning for reasoning-heavy,\nquantitative tasks, particularly mathematics. While there are many resources\ncapturing mathematics at the high-school, undergraduate, and graduate level,\nthere are far fewer resources available that align with the level of difficulty\nand open endedness encountered by professional mathematicians working on open\nproblems. To address this, we introduce a new collection of datasets, the\nAlgebraic Combinatorics Dataset Repository (ACD Repo), representing either\nfoundational results or open problems in algebraic combinatorics, a subfield of\nmathematics that studies discrete structures arising from abstract algebra.\nFurther differentiating our dataset collection is the fact that it aims at the\nconjecturing process. Each dataset includes an open-ended research-level\nquestion and a large collection of examples (up to 10M in some cases) from\nwhich conjectures should be generated. We describe all nine datasets, the\ndifferent ways machine learning models can be applied to them (e.g., training\nwith narrow models followed by interpretability analysis or program synthesis\nwith LLMs), and discuss some of the challenges involved in designing datasets\nlike these.",
    "categories": [
      "cs.LG",
      "cs.AI",
      "math.CO",
      "math.RT"
    ],
    "primary_category": "cs.LG",
    "comment": "26 pages, comments welcome",
    "pdf_url": "http://arxiv.org/pdf/2503.06366v1",
    "published_date": "2025-03-09 00:11:40 UTC",
    "updated_date": "2025-03-09 00:11:40 UTC"
  }
]