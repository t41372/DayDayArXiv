[
  {
    "arxiv_id": "2407.13775v1",
    "title": "Lessons in Cooperation: A Qualitative Analysis of Driver Sentiments towards Real-Time Advisory Systems from a Driving Simulator User Study",
    "authors": [
      "Aamir Hasan",
      "Neeloy Chakraborty",
      "Haonan Chen",
      "Cathy Wu",
      "Katherine Driggs-Campbell"
    ],
    "abstract": "Real-time Advisory (RTA) systems, such as navigational and eco-driving\nassistants, are becoming increasingly ubiquitous in vehicles due to their\nbenefits for users and society. Until autonomous vehicles mature, such advisory\nsystems will continue to expand their ability to cooperate with drivers,\nenabling safer and more eco-friendly driving practices while improving user\nexperience. However, the interactions between these systems and drivers have\nnot been studied extensively. To this end, we conduct a driving simulator study\n(N=16) to capture driver reactions to a Cooperative RTA system. Through a case\nstudy with a congestion mitigation assistant, we qualitatively analyze the\nsentiments of drivers towards advisory systems and discuss driver preferences\nfor various aspects of the interaction. We comment on how the advice should be\ncommunicated, the effects of the advice on driver trust, and how drivers adapt\nto the system. We present recommendations to inform the future design of\nCooperative RTA systems.",
    "categories": [
      "cs.HC",
      "cs.AI"
    ],
    "primary_category": "cs.HC",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2407.13775v1",
    "published_date": "2024-06-29 23:21:42 UTC",
    "updated_date": "2024-06-29 23:21:42 UTC"
  },
  {
    "arxiv_id": "2407.00541v1",
    "title": "Answering real-world clinical questions using large language model based systems",
    "authors": [
      "Yen Sia Low",
      "Michael L. Jackson",
      "Rebecca J. Hyde",
      "Robert E. Brown",
      "Neil M. Sanghavi",
      "Julian D. Baldwin",
      "C. William Pike",
      "Jananee Muralidharan",
      "Gavin Hui",
      "Natasha Alexander",
      "Hadeel Hassan",
      "Rahul V. Nene",
      "Morgan Pike",
      "Courtney J. Pokrzywa",
      "Shivam Vedak",
      "Adam Paul Yan",
      "Dong-han Yao",
      "Amy R. Zipursky",
      "Christina Dinh",
      "Philip Ballentine",
      "Dan C. Derieg",
      "Vladimir Polony",
      "Rehan N. Chawdry",
      "Jordan Davies",
      "Brigham B. Hyde",
      "Nigam H. Shah",
      "Saurabh Gombar"
    ],
    "abstract": "Evidence to guide healthcare decisions is often limited by a lack of relevant\nand trustworthy literature as well as difficulty in contextualizing existing\nresearch for a specific patient. Large language models (LLMs) could potentially\naddress both challenges by either summarizing published literature or\ngenerating new studies based on real-world data (RWD). We evaluated the ability\nof five LLM-based systems in answering 50 clinical questions and had nine\nindependent physicians review the responses for relevance, reliability, and\nactionability. As it stands, general-purpose LLMs (ChatGPT-4, Claude 3 Opus,\nGemini Pro 1.5) rarely produced answers that were deemed relevant and\nevidence-based (2% - 10%). In contrast, retrieval augmented generation\n(RAG)-based and agentic LLM systems produced relevant and evidence-based\nanswers for 24% (OpenEvidence) to 58% (ChatRWD) of questions. Only the agentic\nChatRWD was able to answer novel questions compared to other LLMs (65% vs.\n0-9%). These results suggest that while general-purpose LLMs should not be used\nas-is, a purpose-built system for evidence summarization based on RAG and one\nfor generating novel evidence working synergistically would improve\navailability of pertinent evidence for patient care.",
    "categories": [
      "cs.CL",
      "cs.AI",
      "cs.IR"
    ],
    "primary_category": "cs.CL",
    "comment": "28 pages (2 figures, 3 tables) inclusive of 8 pages of supplemental\n  materials (4 supplemental figures and 4 supplemental tables)",
    "pdf_url": "http://arxiv.org/pdf/2407.00541v1",
    "published_date": "2024-06-29 22:39:20 UTC",
    "updated_date": "2024-06-29 22:39:20 UTC"
  },
  {
    "arxiv_id": "2407.00538v1",
    "title": "Privacy-Preserving and Trustworthy Deep Learning for Medical Imaging",
    "authors": [
      "Kiarash Sedghighadikolaei",
      "Attila A Yavuz"
    ],
    "abstract": "The shift towards efficient and automated data analysis through Machine\nLearning (ML) has notably impacted healthcare systems, particularly Radiomics.\nRadiomics leverages ML to analyze medical images accurately and efficiently for\nprecision medicine. Current methods rely on Deep Learning (DL) to improve\nperformance and accuracy (Deep Radiomics). Given the sensitivity of medical\nimages, ensuring privacy throughout the Deep Radiomics pipeline-from data\ngeneration and collection to model training and inference-is essential,\nespecially when outsourced. Thus, Privacy-Enhancing Technologies (PETs) are\ncrucial tools for Deep Radiomics. Previous studies and systematization efforts\nhave either broadly overviewed PETs and their applications or mainly focused on\nsubsets of PETs for ML algorithms. In Deep Radiomics, where efficiency,\naccuracy, and privacy are crucial, many PETs, while theoretically applicable,\nmay not be practical without specialized optimizations or hybrid designs.\nAdditionally, not all DL models are suitable for Radiomics. Consequently, there\nis a need for specialized studies that investigate and systematize the\neffective and practical integration of PETs into the Deep Radiomics pipeline.\nThis work addresses this research gap by (1) classifying existing PETs,\npresenting practical hybrid PETS constructions, and a taxonomy illustrating\ntheir potential integration with the Deep Radiomics pipeline, with comparative\nanalyses detailing assumptions, architectural suitability, and security, (2)\nOffering technical insights, describing potential challenges and means of\ncombining PETs into the Deep Radiomics pipeline, including integration\nstrategies, subtilities, and potential challenges, (3) Proposing potential\nresearch directions, identifying challenges, and suggesting solutions to\nenhance the PETs in Deep Radiomics.",
    "categories": [
      "cs.CR",
      "cs.AI",
      "cs.CV",
      "eess.IV"
    ],
    "primary_category": "cs.CR",
    "comment": "This work has been submitted to the IEEE for possible publication",
    "pdf_url": "http://arxiv.org/pdf/2407.00538v1",
    "published_date": "2024-06-29 22:26:05 UTC",
    "updated_date": "2024-06-29 22:26:05 UTC"
  },
  {
    "arxiv_id": "2407.05952v3",
    "title": "H-STAR: LLM-driven Hybrid SQL-Text Adaptive Reasoning on Tables",
    "authors": [
      "Nikhil Abhyankar",
      "Vivek Gupta",
      "Dan Roth",
      "Chandan K. Reddy"
    ],
    "abstract": "Tabular reasoning involves interpreting natural language queries about\ntabular data, which presents a unique challenge of combining language\nunderstanding with structured data analysis. Existing methods employ either\ntextual reasoning, which excels in semantic interpretation but struggles with\nmathematical operations, or symbolic reasoning, which handles computations well\nbut lacks semantic understanding. This paper introduces a novel algorithm\nH-STAR that integrates both symbolic and semantic (textual) approaches in a\ntwo-stage process to address these limitations. H-STAR employs: (1) step-wise\ntable extraction using `multi-view' column retrieval followed by row\nextraction, and (2) adaptive reasoning that adapts reasoning strategies based\non question types, utilizing semantic reasoning for direct lookup and complex\nlexical queries while augmenting textual reasoning with symbolic reasoning\nsupport for quantitative and logical tasks. Our extensive experiments\ndemonstrate that H-STAR significantly outperforms state-of-the-art methods\nacross three tabular question-answering (QA) and fact-verification datasets,\nunderscoring its effectiveness and efficiency.",
    "categories": [
      "cs.DB",
      "cs.AI",
      "cs.CL",
      "cs.LG"
    ],
    "primary_category": "cs.DB",
    "comment": "NAACL 2025 Main Conference",
    "pdf_url": "http://arxiv.org/pdf/2407.05952v3",
    "published_date": "2024-06-29 21:24:19 UTC",
    "updated_date": "2025-04-07 00:44:34 UTC"
  },
  {
    "arxiv_id": "2407.00531v1",
    "title": "Interpreting Pretrained Speech Models for Automatic Speech Assessment of Voice Disorders",
    "authors": [
      "Hok-Shing Lau",
      "Mark Huntly",
      "Nathon Morgan",
      "Adesua Iyenoma",
      "Biao Zeng",
      "Tim Bashford"
    ],
    "abstract": "Speech contains information that is clinically relevant to some diseases,\nwhich has the potential to be used for health assessment. Recent work shows an\ninterest in applying deep learning algorithms, especially pretrained large\nspeech models to the applications of Automatic Speech Assessment. One question\nthat has not been explored is how these models output the results based on\ntheir inputs. In this work, we train and compare two configurations of Audio\nSpectrogram Transformer in the context of Voice Disorder Detection and apply\nthe attention rollout method to produce model relevance maps, the computed\nrelevance of the spectrogram regions when the model makes predictions. We use\nthese maps to analyse how models make predictions in different conditions and\nto show that the spread of attention is reduced as a model is finetuned, and\nthe model attention is concentrated on specific phoneme regions.",
    "categories": [
      "cs.SD",
      "cs.AI",
      "eess.AS"
    ],
    "primary_category": "cs.SD",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2407.00531v1",
    "published_date": "2024-06-29 21:14:48 UTC",
    "updated_date": "2024-06-29 21:14:48 UTC"
  },
  {
    "arxiv_id": "2407.09557v1",
    "title": "Deep Reinforcement Learning Strategies in Finance: Insights into Asset Holding, Trading Behavior, and Purchase Diversity",
    "authors": [
      "Alireza Mohammadshafie",
      "Akram Mirzaeinia",
      "Haseebullah Jumakhan",
      "Amir Mirzaeinia"
    ],
    "abstract": "Recent deep reinforcement learning (DRL) methods in finance show promising\noutcomes. However, there is limited research examining the behavior of these\nDRL algorithms. This paper aims to investigate their tendencies towards holding\nor trading financial assets as well as purchase diversity. By analyzing their\ntrading behaviors, we provide insights into the decision-making processes of\nDRL models in finance applications. Our findings reveal that each DRL algorithm\nexhibits unique trading patterns and strategies, with A2C emerging as the top\nperformer in terms of cumulative rewards. While PPO and SAC engage in\nsignificant trades with a limited number of stocks, DDPG and TD3 adopt a more\nbalanced approach. Furthermore, SAC and PPO tend to hold positions for shorter\ndurations, whereas DDPG, A2C, and TD3 display a propensity to remain stationary\nfor extended periods.",
    "categories": [
      "q-fin.TR",
      "cs.AI",
      "cs.LG"
    ],
    "primary_category": "q-fin.TR",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2407.09557v1",
    "published_date": "2024-06-29 20:56:58 UTC",
    "updated_date": "2024-06-29 20:56:58 UTC"
  },
  {
    "arxiv_id": "2407.00521v2",
    "title": "A Medical Low-Back Pain Physical Rehabilitation Dataset for Human Body Movement Analysis",
    "authors": [
      "Sao Mai Nguyen",
      "Maxime Devanne",
      "Olivier Remy-Neris",
      "Mathieu Lempereur",
      "Andr√© Thepaut"
    ],
    "abstract": "While automatic monitoring and coaching of exercises are showing encouraging\nresults in non-medical applications, they still have limitations such as errors\nand limited use contexts. To allow the development and assessment of physical\nrehabilitation by an intelligent tutoring system, we identify in this article\nfour challenges to address and propose a medical dataset of clinical patients\ncarrying out low back-pain rehabilitation exercises. The dataset includes 3D\nKinect skeleton positions and orientations, RGB videos, 2D skeleton data, and\nmedical annotations to assess the correctness, and error classification and\nlocalisation of body part and timespan. Along this dataset, we perform a\ncomplete research path, from data collection to processing, and finally a small\nbenchmark. We evaluated on the dataset two baseline movement recognition\nalgorithms, pertaining to two different approaches: the probabilistic approach\nwith a Gaussian Mixture Model (GMM), and the deep learning approach with a\nLong-Short Term Memory (LSTM).\n  This dataset is valuable because it includes rehabilitation relevant motions\nin a clinical setting with patients in their rehabilitation program, using a\ncost-effective, portable, and convenient sensor, and because it shows the\npotential for improvement on these challenges.",
    "categories": [
      "cs.LG",
      "cs.AI",
      "cs.CV",
      "cs.HC",
      "I.5.4; I.4.8"
    ],
    "primary_category": "cs.LG",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2407.00521v2",
    "published_date": "2024-06-29 19:50:06 UTC",
    "updated_date": "2025-01-11 02:30:56 UTC"
  },
  {
    "arxiv_id": "2407.00519v1",
    "title": "Test Case Features as Hyper-heuristics for Inductive Programming",
    "authors": [
      "Edward McDaid",
      "Sarah McDaid"
    ],
    "abstract": "Instruction subsets are heuristics that can reduce the size of the inductive\nprogramming search space by tens of orders of magnitude. Comprising many\noverlapping subsets of different sizes, they serve as predictions of the\ninstructions required to code a solution for any problem. Currently, this\napproach employs a single, large family of subsets meaning that some problems\ncan search thousands of subsets before a solution is found. In this paper we\nintroduce the use of test case type signatures as hyper-heuristics to select\none of many, smaller families of instruction subsets. The type signature for\nany set of test cases maps directly to a single family and smaller families\nmean that fewer subsets need to be considered for most problems. Having many\nfamilies also permits subsets to be reordered to better reflect their relative\noccurrence in human code - again reducing the search space size for many\nproblems. Overall the new approach can further reduce the size of the inductive\nprogramming search space by between 1 and 3 orders of magnitude, depending on\nthe type signature. Larger and more consistent reductions are possible through\nthe use of more sophisticated type systems. The potential use of additional\ntest case features as hyper-heuristics and some other possible future work is\nalso briefly discussed.",
    "categories": [
      "cs.AI",
      "D.1.2; D.3.3; F.1.1; F.3.1; F.3.3; I.2.1; I.2.2; I.2.4; I.2.5;\n  I.2.8; I.5.3"
    ],
    "primary_category": "cs.AI",
    "comment": "14 pages, 3 figures. Accepted for 20th IFIP WG 12.5 International\n  Conference, AIAI 2024 Corfu, Greece, June 27-30, 2024",
    "pdf_url": "http://arxiv.org/pdf/2407.00519v1",
    "published_date": "2024-06-29 19:46:11 UTC",
    "updated_date": "2024-06-29 19:46:11 UTC"
  },
  {
    "arxiv_id": "2407.00510v1",
    "title": "Stochastic stem bucking using mixture density neural networks",
    "authors": [
      "Simon Schmiedel"
    ],
    "abstract": "Poor bucking decisions made by forest harvesters can have a negative effect\non the products that are generated from the logs. Making the right bucking\ndecisions is not an easy task because harvesters must rely on predictions of\nthe stem profile for the part of the stems that is not yet measured. The goal\nof this project is to improve the bucking decisions made by forest harvesters\nwith a stochastic bucking method. We developed a Long Short-Term Memory (LSTM)\nneural network that predicted the parameters of a Gaussian distribution\nconditioned on the known part of the stem, enabling the creation of multiple\nsamples of stem profile predictions for the unknown part of the stem. The\nbucking decisions could then be optimized using a novel stochastic bucking\nalgorithm which used all the stem profiles generated to choose the logs to\ngenerate from the stem. The stochastic bucking algorithm was compared to two\nbenchmark models: A polynomial model that could not condition its predictions\non more than one diameter measurement, and a deterministic LSTM neural network.\nAll models were evaluated on stem profiles of four coniferous species prevalent\nin eastern Canada. In general, the best bucking decisions were taken by the\nstochastic LSTM models, demonstrating the usefulness of the method. The\nsecond-best results were mostly obtained by the deterministic LSTM model and\nthe worst results by the polynomial model, corroborating the usefulness of\nconditioning the stem curve predictions on multiple measurements.",
    "categories": [
      "cs.LG",
      "cs.AI"
    ],
    "primary_category": "cs.LG",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2407.00510v1",
    "published_date": "2024-06-29 18:44:49 UTC",
    "updated_date": "2024-06-29 18:44:49 UTC"
  },
  {
    "arxiv_id": "2407.00509v2",
    "title": "Leveraging Ontologies to Document Bias in Data",
    "authors": [
      "Mayra Russo",
      "Maria-Esther Vidal"
    ],
    "abstract": "Machine Learning (ML) systems are capable of reproducing and often amplifying\nundesired biases. This puts emphasis on the importance of operating under\npractices that enable the study and understanding of the intrinsic\ncharacteristics of ML pipelines, prompting the emergence of documentation\nframeworks with the idea that ``any remedy for bias starts with awareness of\nits existence''. However, a resource that can formally describe these pipelines\nin terms of biases detected is still amiss. To fill this gap, we present the\nDoc-BiasO ontology, a resource that aims to create an integrated vocabulary of\nbiases defined in the \\textit{fair-ML} literature and their measures, as well\nas to incorporate relevant terminology and the relationships between them.\nOverseeing ontology engineering best practices, we re-use existing vocabulary\non machine learning and AI, to foster knowledge sharing and interoperability\nbetween the actors concerned with its research, development, regulation, among\nothers. Overall, our main objective is to contribute towards clarifying\nexisting terminology on bias research as it rapidly expands to all areas of AI\nand to improve the interpretation of bias in data and downstream impact.",
    "categories": [
      "cs.AI"
    ],
    "primary_category": "cs.AI",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2407.00509v2",
    "published_date": "2024-06-29 18:41:07 UTC",
    "updated_date": "2024-08-09 18:18:55 UTC"
  },
  {
    "arxiv_id": "2407.00506v2",
    "title": "ShapG: new feature importance method based on the Shapley value",
    "authors": [
      "Chi Zhao",
      "Jing Liu",
      "Elena Parilina"
    ],
    "abstract": "With wide application of Artificial Intelligence (AI), it has become\nparticularly important to make decisions of AI systems explainable and\ntransparent. In this paper, we proposed a new Explainable Artificial\nIntelligence (XAI) method called ShapG (Explanations based on Shapley value for\nGraphs) for measuring feature importance. ShapG is a model-agnostic global\nexplanation method. At the first stage, it defines an undirected graph based on\nthe dataset, where nodes represent features and edges are added based on\ncalculation of correlation coefficients between features. At the second stage,\nit calculates an approximated Shapley value by sampling the data taking into\naccount this graph structure. The sampling approach of ShapG allows to\ncalculate the importance of features efficiently, i.e. to reduce computational\ncomplexity. Comparison of ShapG with other existing XAI methods shows that it\nprovides more accurate explanations for two examined datasets. We also compared\nother XAI methods developed based on cooperative game theory with ShapG in\nrunning time, and the results show that ShapG exhibits obvious advantages in\nits running time, which further proves efficiency of ShapG. In addition,\nextensive experiments demonstrate a wide range of applicability of the ShapG\nmethod for explaining complex models. We find ShapG an important tool in\nimproving explainability and transparency of AI systems and believe it can be\nwidely used in various fields.",
    "categories": [
      "cs.AI",
      "cs.GT",
      "cs.LG",
      "68T01, 68T20"
    ],
    "primary_category": "cs.AI",
    "comment": "This paper has been published in the journal \"Engineering\n  Applications of Artificial Intelligence\"",
    "pdf_url": "http://arxiv.org/pdf/2407.00506v2",
    "published_date": "2024-06-29 18:19:55 UTC",
    "updated_date": "2025-03-31 06:57:08 UTC"
  },
  {
    "arxiv_id": "2407.00502v1",
    "title": "Deep Frequency Derivative Learning for Non-stationary Time Series Forecasting",
    "authors": [
      "Wei Fan",
      "Kun Yi",
      "Hangting Ye",
      "Zhiyuan Ning",
      "Qi Zhang",
      "Ning An"
    ],
    "abstract": "While most time series are non-stationary, it is inevitable for models to\nface the distribution shift issue in time series forecasting. Existing\nsolutions manipulate statistical measures (usually mean and std.) to adjust\ntime series distribution. However, these operations can be theoretically seen\nas the transformation towards zero frequency component of the spectrum which\ncannot reveal full distribution information and would further lead to\ninformation utilization bottleneck in normalization, thus hindering forecasting\nperformance. To address this problem, we propose to utilize the whole frequency\nspectrum to transform time series to make full use of data distribution from\nthe frequency perspective. We present a deep frequency derivative learning\nframework, DERITS, for non-stationary time series forecasting. Specifically,\nDERITS is built upon a novel reversible transformation, namely Frequency\nDerivative Transformation (FDT) that makes signals derived in the frequency\ndomain to acquire more stationary frequency representations. Then, we propose\nthe Order-adaptive Fourier Convolution Network to conduct adaptive frequency\nfiltering and learning. Furthermore, we organize DERITS as a parallel-stacked\narchitecture for the multi-order derivation and fusion for forecasting.\nFinally, we conduct extensive experiments on several datasets which show the\nconsistent superiority in both time series forecasting and shift alleviation.",
    "categories": [
      "cs.LG",
      "cs.AI"
    ],
    "primary_category": "cs.LG",
    "comment": "Accepted by IJCAI 2024",
    "pdf_url": "http://arxiv.org/pdf/2407.00502v1",
    "published_date": "2024-06-29 17:56:59 UTC",
    "updated_date": "2024-06-29 17:56:59 UTC"
  },
  {
    "arxiv_id": "2407.00501v1",
    "title": "Aeroengine performance prediction using a physical-embedded data-driven method",
    "authors": [
      "Tong Mo",
      "Shiran Dai",
      "An Fu",
      "Xiaomeng Zhu",
      "Shuxiao Li"
    ],
    "abstract": "Accurate and efficient prediction of aeroengine performance is of paramount\nimportance for engine design, maintenance, and optimization endeavours.\nHowever, existing methodologies often struggle to strike an optimal balance\namong predictive accuracy, computational efficiency, modelling complexity, and\ndata dependency. To address these challenges, we propose a strategy that\nsynergistically combines domain knowledge from both the aeroengine and neural\nnetwork realms to enable real-time prediction of engine performance parameters.\nLeveraging aeroengine domain knowledge, we judiciously design the network\nstructure and regulate the internal information flow. Concurrently, drawing\nupon neural network domain expertise, we devise four distinct feature fusion\nmethods and introduce an innovative loss function formulation. To rigorously\nevaluate the effectiveness and robustness of our proposed strategy, we conduct\ncomprehensive validation across two distinct datasets. The empirical results\ndemonstrate :(1) the evident advantages of our tailored loss function; (2) our\nmodel's ability to maintain equal or superior performance with a reduced\nparameter count; (3) our model's reduced data dependency compared to\ngeneralized neural network architectures; (4)Our model is more interpretable\nthan traditional black box machine learning methods.",
    "categories": [
      "cs.LG",
      "cs.AI",
      "cs.CE"
    ],
    "primary_category": "cs.LG",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2407.00501v1",
    "published_date": "2024-06-29 17:56:58 UTC",
    "updated_date": "2024-06-29 17:56:58 UTC"
  },
  {
    "arxiv_id": "2407.00500v1",
    "title": "Intrinsic PAPR for Point-level 3D Scene Albedo and Shading Editing",
    "authors": [
      "Alireza Moazeni",
      "Shichong Peng",
      "Ke Li"
    ],
    "abstract": "Recent advancements in neural rendering have excelled at novel view synthesis\nfrom multi-view RGB images. However, they often lack the capability to edit the\nshading or colour of the scene at a detailed point-level, while ensuring\nconsistency across different viewpoints. In this work, we address the challenge\nof point-level 3D scene albedo and shading editing from multi-view RGB images,\nfocusing on detailed editing at the point-level rather than at a part or global\nlevel. While prior works based on volumetric representation such as NeRF\nstruggle with achieving 3D consistent editing at the point level, recent\nadvancements in point-based neural rendering show promise in overcoming this\nchallenge. We introduce ``Intrinsic PAPR'', a novel method based on the recent\npoint-based neural rendering technique Proximity Attention Point Rendering\n(PAPR). Unlike other point-based methods that model the intrinsic decomposition\nof the scene, our approach does not rely on complicated shading models or\nsimplistic priors that may not universally apply. Instead, we directly model\nscene decomposition into albedo and shading components, leading to better\nestimation accuracy. Comparative evaluations against the latest point-based\ninverse rendering methods demonstrate that Intrinsic PAPR achieves\nhigher-quality novel view rendering and superior point-level albedo and shading\nediting.",
    "categories": [
      "cs.CV",
      "cs.AI",
      "cs.GR",
      "cs.LG"
    ],
    "primary_category": "cs.CV",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2407.00500v1",
    "published_date": "2024-06-29 17:46:10 UTC",
    "updated_date": "2024-06-29 17:46:10 UTC"
  },
  {
    "arxiv_id": "2407.00499v3",
    "title": "ConU: Conformal Uncertainty in Large Language Models with Correctness Coverage Guarantees",
    "authors": [
      "Zhiyuan Wang",
      "Jinhao Duan",
      "Lu Cheng",
      "Yue Zhang",
      "Qingni Wang",
      "Xiaoshuang Shi",
      "Kaidi Xu",
      "Hengtao Shen",
      "Xiaofeng Zhu"
    ],
    "abstract": "Uncertainty quantification (UQ) in natural language generation (NLG) tasks\nremains an open challenge, exacerbated by the closed-source nature of the\nlatest large language models (LLMs). This study investigates applying conformal\nprediction (CP), which can transform any heuristic uncertainty notion into\nrigorous prediction sets, to black-box LLMs in open-ended NLG tasks. We\nintroduce a novel uncertainty measure based on self-consistency theory, and\nthen develop a conformal uncertainty criterion by integrating the uncertainty\ncondition aligned with correctness into the CP algorithm. Empirical evaluations\nindicate that our uncertainty measure outperforms prior state-of-the-art\nmethods. Furthermore, we achieve strict control over the correctness coverage\nrate utilizing 7 popular LLMs on 4 free-form NLG datasets, spanning\ngeneral-purpose and medical scenarios. Additionally, the calibrated prediction\nsets with small size further highlights the efficiency of our method in\nproviding trustworthy guarantees for practical open-ended NLG applications.",
    "categories": [
      "cs.CL",
      "cs.AI",
      "cs.LG"
    ],
    "primary_category": "cs.CL",
    "comment": "Accepted by EMNLP 2024 Findings",
    "pdf_url": "http://arxiv.org/pdf/2407.00499v3",
    "published_date": "2024-06-29 17:33:07 UTC",
    "updated_date": "2024-11-18 08:33:35 UTC"
  },
  {
    "arxiv_id": "2407.00496v1",
    "title": "A Two-stage Reinforcement Learning-based Approach for Multi-entity Task Allocation",
    "authors": [
      "Aicheng Gong",
      "Kai Yang",
      "Jiafei Lyu",
      "Xiu Li"
    ],
    "abstract": "Task allocation is a key combinatorial optimization problem, crucial for\nmodern applications such as multi-robot cooperation and resource scheduling.\nDecision makers must allocate entities to tasks reasonably across different\nscenarios. However, traditional methods assume static attributes and numbers of\ntasks and entities, often relying on dynamic programming and heuristic\nalgorithms for solutions. In reality, task allocation resembles Markov decision\nprocesses, with dynamically changing task and entity attributes. Thus,\nalgorithms must dynamically allocate tasks based on their states. To address\nthis issue, we propose a two-stage task allocation algorithm based on\nsimilarity, utilizing reinforcement learning to learn allocation strategies.\nThe proposed pre-assign strategy allows entities to preselect appropriate\ntasks, effectively avoiding local optima and thereby better finding the optimal\nallocation. We also introduce an attention mechanism and a hyperparameter\nnetwork structure to adapt to the changing number and attributes of entities\nand tasks, enabling our network structure to generalize to new tasks.\nExperimental results across multiple environments demonstrate that our\nalgorithm effectively addresses the challenges of dynamic task allocation in\npractical applications. Compared to heuristic algorithms like genetic\nalgorithms, our reinforcement learning approach better solves dynamic\nallocation problems and achieves zero-shot generalization to new tasks with\ngood performance. The code is available at\nhttps://github.com/yk7333/TaskAllocation.",
    "categories": [
      "cs.LG",
      "cs.AI"
    ],
    "primary_category": "cs.LG",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2407.00496v1",
    "published_date": "2024-06-29 17:13:44 UTC",
    "updated_date": "2024-06-29 17:13:44 UTC"
  },
  {
    "arxiv_id": "2407.00488v1",
    "title": "PFME: A Modular Approach for Fine-grained Hallucination Detection and Editing of Large Language Models",
    "authors": [
      "Kunquan Deng",
      "Zeyu Huang",
      "Chen Li",
      "Chenghua Lin",
      "Min Gao",
      "Wenge Rong"
    ],
    "abstract": "Large Language Models (LLMs) excel in fluency but risk producing inaccurate\ncontent, called \"hallucinations.\" This paper outlines a standardized process\nfor categorizing fine-grained hallucination types and proposes an innovative\nframework--the Progressive Fine-grained Model Editor (PFME)--specifically\ndesigned to detect and correct fine-grained hallucinations in LLMs. PFME\nconsists of two collaborative modules: the Real-time Fact Retrieval Module and\nthe Fine-grained Hallucination Detection and Editing Module. The former\nidentifies key entities in the document and retrieves the latest factual\nevidence from credible sources. The latter further segments the document into\nsentence-level text and, based on relevant evidence and previously edited\ncontext, identifies, locates, and edits each sentence's hallucination type.\nExperimental results on FavaBench and FActScore demonstrate that PFME\noutperforms existing methods in fine-grained hallucination detection tasks.\nParticularly, when using the Llama3-8B-Instruct model, PFME's performance in\nfine-grained hallucination detection with external knowledge assistance\nimproves by 8.7 percentage points (pp) compared to ChatGPT. In editing tasks,\nPFME further enhances the FActScore of FActScore-Alpaca13B and\nFActScore-ChatGPT datasets, increasing by 16.2pp and 4.6pp, respectively.",
    "categories": [
      "cs.CL",
      "cs.AI"
    ],
    "primary_category": "cs.CL",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2407.00488v1",
    "published_date": "2024-06-29 16:35:57 UTC",
    "updated_date": "2024-06-29 16:35:57 UTC"
  },
  {
    "arxiv_id": "2407.00482v1",
    "title": "Quantifying Spuriousness of Biased Datasets Using Partial Information Decomposition",
    "authors": [
      "Barproda Halder",
      "Faisal Hamman",
      "Pasan Dissanayake",
      "Qiuyi Zhang",
      "Ilia Sucholutsky",
      "Sanghamitra Dutta"
    ],
    "abstract": "Spurious patterns refer to a mathematical association between two or more\nvariables in a dataset that are not causally related. However, this notion of\nspuriousness, which is usually introduced due to sampling biases in the\ndataset, has classically lacked a formal definition. To address this gap, this\nwork presents the first information-theoretic formalization of spuriousness in\na dataset (given a split of spurious and core features) using a mathematical\nframework called Partial Information Decomposition (PID). Specifically, we\ndisentangle the joint information content that the spurious and core features\nshare about another target variable (e.g., the prediction label) into distinct\ncomponents, namely unique, redundant, and synergistic information. We propose\nthe use of unique information, with roots in Blackwell Sufficiency, as a novel\nmetric to formally quantify dataset spuriousness and derive its desirable\nproperties. We empirically demonstrate how higher unique information in the\nspurious features in a dataset could lead a model into choosing the spurious\nfeatures over the core features for inference, often having low\nworst-group-accuracy. We also propose a novel autoencoder-based estimator for\ncomputing unique information that is able to handle high-dimensional image\ndata. Finally, we also show how this unique information in the spurious feature\nis reduced across several dataset-based spurious-pattern-mitigation techniques\nsuch as data reweighting and varying levels of background mixing, demonstrating\na novel tradeoff between unique information (spuriousness) and\nworst-group-accuracy.",
    "categories": [
      "cs.LG",
      "cs.AI",
      "cs.CV",
      "cs.CY",
      "cs.IT",
      "math.IT"
    ],
    "primary_category": "cs.LG",
    "comment": "Accepted at ICML 2024 Workshop on Data-centric Machine Learning\n  Research (DMLR): Datasets for Foundation Models",
    "pdf_url": "http://arxiv.org/pdf/2407.00482v1",
    "published_date": "2024-06-29 16:05:47 UTC",
    "updated_date": "2024-06-29 16:05:47 UTC"
  },
  {
    "arxiv_id": "2407.00478v3",
    "title": "Beyond Scaleup: Knowledge-aware Parsimony Learning from Deep Networks",
    "authors": [
      "Quanming Yao",
      "Yongqi Zhang",
      "Yaqing Wang",
      "Nan Yin",
      "James Kwok",
      "Qiang Yang"
    ],
    "abstract": "The brute-force scaleup of training datasets, learnable parameters and\ncomputation power, has become a prevalent strategy for developing more robust\nlearning models. However, due to bottlenecks in data, computation, and trust,\nthe sustainability of this strategy is a serious concern. In this paper, we\nattempt to address this issue in a parsimonious manner (i.e., achieving greater\npotential with simpler models). The key is to drive models using\ndomain-specific knowledge, such as symbols, logic, and formulas, instead of\npurely relying on scaleup. This approach allows us to build a framework that\nuses this knowledge as \"building blocks\" to achieve parsimony in model design,\ntraining, and interpretation. Empirical results show that our methods surpass\nthose that typically follow the scaling law. We also demonstrate our framework\nin AI for science, specifically in the problem of drug-drug interaction\nprediction. We hope our research can foster more diverse technical roadmaps in\nthe era of foundation models.",
    "categories": [
      "cs.LG",
      "cs.AI"
    ],
    "primary_category": "cs.LG",
    "comment": "Accepted to AI Magazine",
    "pdf_url": "http://arxiv.org/pdf/2407.00478v3",
    "published_date": "2024-06-29 15:52:37 UTC",
    "updated_date": "2024-12-17 07:30:46 UTC"
  },
  {
    "arxiv_id": "2407.00474v1",
    "title": "MH-pFLGB: Model Heterogeneous personalized Federated Learning via Global Bypass for Medical Image Analysis",
    "authors": [
      "Luyuan Xie",
      "Manqing Lin",
      "ChenMing Xu",
      "Tianyu Luan",
      "Zhipeng Zeng",
      "Wenjun Qian",
      "Cong Li",
      "Yuejian Fang",
      "Qingni Shen",
      "Zhonghai Wu"
    ],
    "abstract": "In the evolving application of medical artificial intelligence, federated\nlearning is notable for its ability to protect training data privacy. Federated\nlearning facilitates collaborative model development without the need to share\nlocal data from healthcare institutions. Yet, the statistical and system\nheterogeneity among these institutions poses substantial challenges, which\naffects the effectiveness of federated learning and hampers the exchange of\ninformation between clients. To address these issues, we introduce a novel\napproach, MH-pFLGB, which employs a global bypass strategy to mitigate the\nreliance on public datasets and navigate the complexities of non-IID data\ndistributions. Our method enhances traditional federated learning by\nintegrating a global bypass model, which would share the information among the\nclients, but also serves as part of the network to enhance the performance on\neach client. Additionally, MH-pFLGB provides a feature fusion module to better\ncombine the local and global features. We validate \\model{}'s effectiveness and\nadaptability through extensive testing on different medical tasks,\ndemonstrating superior performance compared to existing state-of-the-art\nmethods.",
    "categories": [
      "cs.LG",
      "cs.AI"
    ],
    "primary_category": "cs.LG",
    "comment": "arXiv admin note: text overlap with arXiv:2405.06822",
    "pdf_url": "http://arxiv.org/pdf/2407.00474v1",
    "published_date": "2024-06-29 15:38:37 UTC",
    "updated_date": "2024-06-29 15:38:37 UTC"
  },
  {
    "arxiv_id": "2407.00468v2",
    "title": "MMEvalPro: Calibrating Multimodal Benchmarks Towards Trustworthy and Efficient Evaluation",
    "authors": [
      "Jinsheng Huang",
      "Liang Chen",
      "Taian Guo",
      "Fu Zeng",
      "Yusheng Zhao",
      "Bohan Wu",
      "Ye Yuan",
      "Haozhe Zhao",
      "Zhihui Guo",
      "Yichi Zhang",
      "Jingyang Yuan",
      "Wei Ju",
      "Luchen Liu",
      "Tianyu Liu",
      "Baobao Chang",
      "Ming Zhang"
    ],
    "abstract": "Large Multimodal Models (LMMs) exhibit impressive cross-modal understanding\nand reasoning abilities, often assessed through multiple-choice questions\n(MCQs) that include an image, a question, and several options. However, many\nbenchmarks used for such evaluations suffer from systematic biases. Remarkably,\nLarge Language Models (LLMs) without any visual perception capabilities achieve\nnon-trivial performance, undermining the credibility of these evaluations. To\naddress this issue while maintaining the efficiency of MCQ evaluations, we\npropose MMEvalPro, a benchmark designed to avoid Type-I errors through a\ntrilogy evaluation pipeline and more rigorous metrics. For each original\nquestion from existing benchmarks, human annotators augment it by creating one\nperception question and one knowledge anchor question through a meticulous\nannotation process. MMEvalPro comprises $2,138$ question triplets, totaling\n$6,414$ distinct questions. Two-thirds of these questions are manually labeled\nby human experts, while the rest are sourced from existing benchmarks (MMMU,\nScienceQA, and MathVista). Compared with the existing benchmarks, our\nexperiments with the latest LLMs and LMMs demonstrate that MMEvalPro is more\nchallenging (the best LMM lags behind human performance by $31.73\\%$, compared\nto an average gap of $8.03\\%$ in previous benchmarks) and more trustworthy (the\nbest LLM trails the best LMM by $23.09\\%$, whereas the gap for previous\nbenchmarks is just $14.64\\%$). Our in-depth analysis explains the reason for\nthe large performance gap and justifies the trustworthiness of evaluation,\nunderscoring its significant potential for advancing future research.",
    "categories": [
      "cs.CV",
      "cs.AI",
      "cs.CL"
    ],
    "primary_category": "cs.CV",
    "comment": "18 pages, code released at https://github.com/chenllliang/MMEvalPro,\n  Homepage at https://mmevalpro.github.io/",
    "pdf_url": "http://arxiv.org/pdf/2407.00468v2",
    "published_date": "2024-06-29 15:28:45 UTC",
    "updated_date": "2025-02-27 15:10:56 UTC"
  },
  {
    "arxiv_id": "2407.00466v1",
    "title": "BioKGBench: A Knowledge Graph Checking Benchmark of AI Agent for Biomedical Science",
    "authors": [
      "Xinna Lin",
      "Siqi Ma",
      "Junjie Shan",
      "Xiaojing Zhang",
      "Shell Xu Hu",
      "Tiannan Guo",
      "Stan Z. Li",
      "Kaicheng Yu"
    ],
    "abstract": "Pursuing artificial intelligence for biomedical science, a.k.a. AI Scientist,\ndraws increasing attention, where one common approach is to build a copilot\nagent driven by Large Language Models (LLMs). However, to evaluate such\nsystems, people either rely on direct Question-Answering (QA) to the LLM\nitself, or in a biomedical experimental manner. How to precisely benchmark\nbiomedical agents from an AI Scientist perspective remains largely unexplored.\nTo this end, we draw inspiration from one most important abilities of\nscientists, understanding the literature, and introduce BioKGBench. In contrast\nto traditional evaluation benchmark that only focuses on factual QA, where the\nLLMs are known to have hallucination issues, we first disentangle\n\"Understanding Literature\" into two atomic abilities, i) \"Understanding\" the\nunstructured text from research papers by performing scientific claim\nverification, and ii) Ability to interact with structured Knowledge-Graph\nQuestion-Answering (KGQA) as a form of \"Literature\" grounding. We then\nformulate a novel agent task, dubbed KGCheck, using KGQA and domain-based\nRetrieval-Augmented Generation (RAG) to identify the factual errors of existing\nlarge-scale knowledge graph databases. We collect over two thousand data for\ntwo atomic tasks and 225 high-quality annotated data for the agent task.\nSurprisingly, we discover that state-of-the-art agents, both daily scenarios\nand biomedical ones, have either failed or inferior performance on our\nbenchmark. We then introduce a simple yet effective baseline, dubbed BKGAgent.\nOn the widely used popular knowledge graph, we discover over 90 factual errors\nwhich provide scenarios for agents to make discoveries and demonstrate the\neffectiveness of our approach. The code and data are available at\nhttps://github.com/westlake-autolab/BioKGBench.",
    "categories": [
      "cs.CL",
      "cs.AI"
    ],
    "primary_category": "cs.CL",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2407.00466v1",
    "published_date": "2024-06-29 15:23:28 UTC",
    "updated_date": "2024-06-29 15:23:28 UTC"
  },
  {
    "arxiv_id": "2407.00463v5",
    "title": "Open-Source Conversational AI with SpeechBrain 1.0",
    "authors": [
      "Mirco Ravanelli",
      "Titouan Parcollet",
      "Adel Moumen",
      "Sylvain de Langen",
      "Cem Subakan",
      "Peter Plantinga",
      "Yingzhi Wang",
      "Pooneh Mousavi",
      "Luca Della Libera",
      "Artem Ploujnikov",
      "Francesco Paissan",
      "Davide Borra",
      "Salah Zaiem",
      "Zeyu Zhao",
      "Shucong Zhang",
      "Georgios Karakasidis",
      "Sung-Lin Yeh",
      "Pierre Champion",
      "Aku Rouhe",
      "Rudolf Braun",
      "Florian Mai",
      "Juan Zuluaga-Gomez",
      "Seyed Mahed Mousavi",
      "Andreas Nautsch",
      "Ha Nguyen",
      "Xuechen Liu",
      "Sangeet Sagar",
      "Jarod Duret",
      "Salima Mdhaffar",
      "Gaelle Laperriere",
      "Mickael Rouvier",
      "Renato De Mori",
      "Yannick Esteve"
    ],
    "abstract": "SpeechBrain is an open-source Conversational AI toolkit based on PyTorch,\nfocused particularly on speech processing tasks such as speech recognition,\nspeech enhancement, speaker recognition, text-to-speech, and much more. It\npromotes transparency and replicability by releasing both the pre-trained\nmodels and the complete \"recipes\" of code and algorithms required for training\nthem. This paper presents SpeechBrain 1.0, a significant milestone in the\nevolution of the toolkit, which now has over 200 recipes for speech, audio, and\nlanguage processing tasks, and more than 100 models available on Hugging Face.\nSpeechBrain 1.0 introduces new technologies to support diverse learning\nmodalities, Large Language Model (LLM) integration, and advanced decoding\nstrategies, along with novel models, tasks, and modalities. It also includes a\nnew benchmark repository, offering researchers a unified platform for\nevaluating models across diverse tasks.",
    "categories": [
      "cs.LG",
      "cs.AI",
      "cs.CL",
      "cs.HC",
      "eess.AS"
    ],
    "primary_category": "cs.LG",
    "comment": "Accepted to the Journal of Machine Learning research (JMLR), Machine\n  Learning Open Source Software",
    "pdf_url": "http://arxiv.org/pdf/2407.00463v5",
    "published_date": "2024-06-29 15:20:11 UTC",
    "updated_date": "2024-10-16 16:13:32 UTC"
  },
  {
    "arxiv_id": "2407.00462v1",
    "title": "pFLFE: Cross-silo Personalized Federated Learning via Feature Enhancement on Medical Image Segmentation",
    "authors": [
      "Luyuan Xie",
      "Manqing Lin",
      "Siyuan Liu",
      "ChenMing Xu",
      "Tianyu Luan",
      "Cong Li",
      "Yuejian Fang",
      "Qingni Shen",
      "Zhonghai Wu"
    ],
    "abstract": "In medical image segmentation, personalized cross-silo federated learning\n(FL) is becoming popular for utilizing varied data across healthcare settings\nto overcome data scarcity and privacy concerns. However, existing methods often\nsuffer from client drift, leading to inconsistent performance and delayed\ntraining. We propose a new framework, Personalized Federated Learning via\nFeature Enhancement (pFLFE), designed to mitigate these challenges. pFLFE\nconsists of two main stages: feature enhancement and supervised learning. The\nfirst stage improves differentiation between foreground and background\nfeatures, and the second uses these enhanced features for learning from\nsegmentation masks. We also design an alternative training approach that\nrequires fewer communication rounds without compromising segmentation quality,\neven with limited communication resources. Through experiments on three medical\nsegmentation tasks, we demonstrate that pFLFE outperforms the state-of-the-art\nmethods.",
    "categories": [
      "cs.CV",
      "cs.AI"
    ],
    "primary_category": "cs.CV",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2407.00462v1",
    "published_date": "2024-06-29 15:20:03 UTC",
    "updated_date": "2024-06-29 15:20:03 UTC"
  },
  {
    "arxiv_id": "2407.00460v1",
    "title": "A Rule-Based Behaviour Planner for Autonomous Driving",
    "authors": [
      "Bouchard Frederic",
      "Sedwards Sean",
      "Czarnecki Krzysztof"
    ],
    "abstract": "Autonomous vehicles require highly sophisticated decision-making to determine\ntheir motion. This paper describes how such functionality can be achieved with\na practical rule engine learned from expert driving decisions. We propose an\nalgorithm to create and maintain a rule-based behaviour planner, using a\ntwo-layer rule-based theory. The first layer determines a set of feasible\nparametrized behaviours, given the perceived state of the environment. From\nthese, a resolution function chooses the most conservative high-level maneuver.\nThe second layer then reconciles the parameters into a single behaviour. To\ndemonstrate the practicality of our approach, we report results of its\nimplementation in a level-3 autonomous vehicle and its field test in an urban\nenvironment.",
    "categories": [
      "cs.AI",
      "cs.RO"
    ],
    "primary_category": "cs.AI",
    "comment": "Use https://link.springer.com/chapter/10.1007/978-3-031-21541-4_17\n  for citations",
    "pdf_url": "http://arxiv.org/pdf/2407.00460v1",
    "published_date": "2024-06-29 15:15:41 UTC",
    "updated_date": "2024-06-29 15:15:41 UTC"
  },
  {
    "arxiv_id": "2407.00456v1",
    "title": "Beyond Functional Correctness: Investigating Coding Style Inconsistencies in Large Language Models",
    "authors": [
      "Yanlin Wang",
      "Tianyue Jiang",
      "Mingwei Liu",
      "Jiachi Chen",
      "Zibin Zheng"
    ],
    "abstract": "Large language models (LLMs) have brought a paradigm shift to the field of\ncode generation, offering the potential to enhance the software development\nprocess. However, previous research mainly focuses on the accuracy of code\ngeneration, while coding style differences between LLMs and human developers\nremain under-explored. In this paper, we empirically analyze the differences in\ncoding style between the code generated by mainstream Code LLMs and the code\nwritten by human developers, and summarize coding style inconsistency taxonomy.\nSpecifically, we first summarize the types of coding style inconsistencies by\nmanually analyzing a large number of generation results. We then compare the\ncode generated by Code LLMs with the code written by human programmers in terms\nof readability, conciseness, and robustness. The results reveal that LLMs and\ndevelopers have different coding styles. Additionally, we study the possible\ncauses of these inconsistencies and provide some solutions to alleviate the\nproblem.",
    "categories": [
      "cs.SE",
      "cs.AI"
    ],
    "primary_category": "cs.SE",
    "comment": "13pages, 14 figures",
    "pdf_url": "http://arxiv.org/pdf/2407.00456v1",
    "published_date": "2024-06-29 14:56:11 UTC",
    "updated_date": "2024-06-29 14:56:11 UTC"
  },
  {
    "arxiv_id": "2407.00452v1",
    "title": "KHNNs: hypercomplex neural networks computations via Keras using TensorFlow and PyTorch",
    "authors": [
      "Agnieszka Niemczynowicz",
      "Rados≈Çaw Antoni Kycia"
    ],
    "abstract": "Neural networks used in computations with more advanced algebras than real\nnumbers perform better in some applications. However, there is no general\nframework for constructing hypercomplex neural networks. We propose a library\nintegrated with Keras that can do computations within TensorFlow and PyTorch.\nIt provides Dense and Convolutional 1D, 2D, and 3D layers architectures.",
    "categories": [
      "cs.LG",
      "cs.AI",
      "cs.NE"
    ],
    "primary_category": "cs.LG",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2407.00452v1",
    "published_date": "2024-06-29 14:36:37 UTC",
    "updated_date": "2024-06-29 14:36:37 UTC"
  },
  {
    "arxiv_id": "2407.01630v1",
    "title": "A survey on the impact of AI-based recommenders on human behaviours: methodologies, outcomes and future directions",
    "authors": [
      "Luca Pappalardo",
      "Emanuele Ferragina",
      "Salvatore Citraro",
      "Giuliano Cornacchia",
      "Mirco Nanni",
      "Giulio Rossetti",
      "Gizem Gezici",
      "Fosca Giannotti",
      "Margherita Lalli",
      "Daniele Gambetta",
      "Giovanni Mauro",
      "Virginia Morini",
      "Valentina Pansanella",
      "Dino Pedreschi"
    ],
    "abstract": "Recommendation systems and assistants (in short, recommenders) are ubiquitous\nin online platforms and influence most actions of our day-to-day lives,\nsuggesting items or providing solutions based on users' preferences or\nrequests. This survey analyses the impact of recommenders in four human-AI\necosystems: social media, online retail, urban mapping and generative AI\necosystems. Its scope is to systematise a fast-growing field in which\nterminologies employed to classify methodologies and outcomes are fragmented\nand unsystematic. We follow the customary steps of qualitative systematic\nreview, gathering 144 articles from different disciplines to develop a\nparsimonious taxonomy of: methodologies employed (empirical, simulation,\nobservational, controlled), outcomes observed (concentration, model collapse,\ndiversity, echo chamber, filter bubble, inequality, polarisation,\nradicalisation, volume), and their level of analysis (individual, item, model,\nand systemic). We systematically discuss all findings of our survey\nsubstantively and methodologically, highlighting also potential avenues for\nfuture research. This survey is addressed to scholars and practitioners\ninterested in different human-AI ecosystems, policymakers and institutional\nstakeholders who want to understand better the measurable outcomes of\nrecommenders, and tech companies who wish to obtain a systematic view of the\nimpact of their recommenders.",
    "categories": [
      "cs.IR",
      "cs.AI",
      "cs.CY",
      "cs.HC"
    ],
    "primary_category": "cs.IR",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2407.01630v1",
    "published_date": "2024-06-29 14:34:32 UTC",
    "updated_date": "2024-06-29 14:34:32 UTC"
  },
  {
    "arxiv_id": "2407.00449v2",
    "title": "Fully tensorial approach to hypercomplex neural networks",
    "authors": [
      "Agnieszka Niemczynowicz",
      "Rados≈Çaw Antoni Kycia"
    ],
    "abstract": "Fully tensorial theory of hypercomplex neural networks is given. It allows\nneural networks to use arithmetic based on arbitrary algebras. The key point is\nto observe that algebra multiplication can be represented as a rank three\ntensor and use this tensor in every algebraic operation. This approach is\nattractive for neural network libraries that support effective tensorial\noperations. It agrees with previous implementations for four-dimensional\nalgebras.",
    "categories": [
      "cs.LG",
      "cs.AI",
      "cs.NE",
      "15A69, 15-04"
    ],
    "primary_category": "cs.LG",
    "comment": "13 pages",
    "pdf_url": "http://arxiv.org/pdf/2407.00449v2",
    "published_date": "2024-06-29 14:19:40 UTC",
    "updated_date": "2024-09-19 14:10:25 UTC"
  },
  {
    "arxiv_id": "2407.00429v2",
    "title": "Time Series Clustering with General State Space Models via Stochastic Variational Inference",
    "authors": [
      "Ryoichi Ishizuka",
      "Takashi Imai",
      "Kaoru Kawamoto"
    ],
    "abstract": "In this paper, we propose a novel method of model-based time series\nclustering with mixtures of general state space models (MSSMs). Each component\nof MSSMs is associated with each cluster. An advantage of the proposed method\nis that it enables the use of time series models appropriate to the specific\ntime series. This not only improves clustering and prediction accuracy but also\nenhances the interpretability of the estimated parameters. The parameters of\nthe MSSMs are estimated using stochastic variational inference, a subtype of\nvariational inference. The proposed method estimates the latent variables of an\narbitrary state space model by using neural networks with a normalizing flow as\na variational estimator. The number of clusters can be estimated using the\nBayesian information criterion. In addition, to prevent MSSMs from converging\nto the local optimum, we propose several optimization tricks, including an\nadditional penalty term called entropy annealing. To our best knowledge, the\nproposed method is the first computationally feasible one for time series\nclustering based on general (possibly nonlinear, non-Gaussian) state space\nmodels. Experiments on simulated datasets show that the proposed method is\neffective for clustering, parameter estimation, and estimating the number of\nclusters.",
    "categories": [
      "cs.LG",
      "cs.AI"
    ],
    "primary_category": "cs.LG",
    "comment": "23 pages, 4 figures",
    "pdf_url": "http://arxiv.org/pdf/2407.00429v2",
    "published_date": "2024-06-29 12:48:53 UTC",
    "updated_date": "2024-08-22 14:50:24 UTC"
  },
  {
    "arxiv_id": "2407.03368v5",
    "title": "Balancing Forecast Accuracy and Switching Costs in Online Optimization of Energy Management Systems",
    "authors": [
      "Evgenii Genov",
      "Julian Ruddick",
      "Christoph Bergmeir",
      "Majid Vafaeipour",
      "Thierry Coosemans",
      "Salvador Garcia",
      "Maarten Messagie"
    ],
    "abstract": "This study investigates the integration of forecasting and optimization in\nenergy management systems, with a focus on the role of switching costs --\npenalties incurred from frequent operational adjustments. We develop a\ntheoretical and empirical framework to examine how forecast accuracy and\nstability interact with switching costs in online decision-making settings. Our\nanalysis spans both deterministic and stochastic optimization approaches, using\npoint and probabilistic forecasts. A novel metric for measuring temporal\nconsistency in probabilistic forecasts is introduced, and the framework is\nvalidated in a real-world battery scheduling case based on the CityLearn 2022\nchallenge. Results show that switching costs significantly alter the trade-off\nbetween forecast accuracy and stability, and that more stable forecasts can\nreduce the performance loss due to switching. Contrary to common practice, the\nfindings suggest that, under non-negligible switching costs, longer commitment\nperiods may lead to better overall outcomes. These insights have practical\nimplications for the design of intelligent, forecast-aware energy management\nsystems.",
    "categories": [
      "eess.SY",
      "cs.AI",
      "cs.SY"
    ],
    "primary_category": "eess.SY",
    "comment": "34 pages, contains the Appendix with a comment on KPIs, MPC\n  formulation, Theoretical analysis of the MPC performance bounds and extra\n  results on the in-sample performance",
    "pdf_url": "http://arxiv.org/pdf/2407.03368v5",
    "published_date": "2024-06-29 12:28:30 UTC",
    "updated_date": "2025-04-15 15:12:35 UTC"
  },
  {
    "arxiv_id": "2407.00419v1",
    "title": "On the Complexity of Learning to Cooperate with Populations of Socially Rational Agents",
    "authors": [
      "Robert Loftin",
      "Saptarashmi Bandyopadhyay",
      "Mustafa Mert √áelikok"
    ],
    "abstract": "Artificially intelligent agents deployed in the real-world will require the\nability to reliably \\textit{cooperate} with humans (as well as other,\nheterogeneous AI agents). To provide formal guarantees of successful\ncooperation, we must make some assumptions about how partner agents could\nplausibly behave. Any realistic set of assumptions must account for the fact\nthat other agents may be just as adaptable as our agent is. In this work, we\nconsider the problem of cooperating with a \\textit{population} of agents in a\nfinitely-repeated, two player general-sum matrix game with private utilities.\nTwo natural assumptions in such settings are that: 1) all agents in the\npopulation are individually rational learners, and 2) when any two members of\nthe population are paired together, with high-probability they will achieve at\nleast the same utility as they would under some Pareto efficient equilibrium\nstrategy. Our results first show that these assumptions alone are insufficient\nto ensure \\textit{zero-shot} cooperation with members of the target population.\nWe therefore consider the problem of \\textit{learning} a strategy for\ncooperating with such a population using prior observations its members\ninteracting with one another. We provide upper and lower bounds on the number\nof samples needed to learn an effective cooperation strategy. Most importantly,\nwe show that these bounds can be much stronger than those arising from a\n\"naive'' reduction of the problem to one of imitation learning.",
    "categories": [
      "cs.LG",
      "cs.AI",
      "cs.GT",
      "cs.MA"
    ],
    "primary_category": "cs.LG",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2407.00419v1",
    "published_date": "2024-06-29 11:59:52 UTC",
    "updated_date": "2024-06-29 11:59:52 UTC"
  },
  {
    "arxiv_id": "2407.00411v3",
    "title": "Explainability of Machine Learning Models under Missing Data",
    "authors": [
      "Tuan L. Vo",
      "Thu Nguyen",
      "Luis M. Lopez-Ramos",
      "Hugo L. Hammer",
      "Michael A. Riegler",
      "Pal Halvorsen"
    ],
    "abstract": "Missing data is a prevalent issue that can significantly impair model\nperformance and explainability. This paper briefly summarizes the development\nof the field of missing data with respect to Explainable Artificial\nIntelligence and experimentally investigates the effects of various imputation\nmethods on SHAP (SHapley Additive exPlanations), a popular technique for\nexplaining the output of complex machine learning models. Next, we compare\ndifferent imputation strategies and assess their impact on feature importance\nand interaction as determined by Shapley values. Moreover, we also\ntheoretically analyze the effects of missing values on Shapley values.\nImportantly, our findings reveal that the choice of imputation method can\nintroduce biases that could lead to changes in the Shapley values, thereby\naffecting the explainability of the model. Moreover, we also show that a lower\ntest prediction MSE (Mean Square Error) does not necessarily imply a lower MSE\nin Shapley values and vice versa. Also, while XGBoost (eXtreme Gradient\nBoosting) is a method that could handle missing data directly, using XGBoost\ndirectly on missing data can seriously affect explainability compared to\nimputing the data before training XGBoost. This study provides a comprehensive\nevaluation of imputation methods in the context of model explanations, offering\npractical guidance for selecting appropriate techniques based on dataset\ncharacteristics and analysis objectives. The results underscore the importance\nof considering imputation effects to ensure robust and reliable insights from\nmachine learning models.",
    "categories": [
      "cs.LG",
      "cs.AI"
    ],
    "primary_category": "cs.LG",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2407.00411v3",
    "published_date": "2024-06-29 11:31:09 UTC",
    "updated_date": "2025-01-22 10:14:22 UTC"
  },
  {
    "arxiv_id": "2407.04730v1",
    "title": "The OPS-SAT benchmark for detecting anomalies in satellite telemetry",
    "authors": [
      "Bogdan Ruszczak",
      "Krzysztof Kotowski",
      "David Evans",
      "Jakub Nalepa"
    ],
    "abstract": "Detecting anomalous events in satellite telemetry is a critical task in space\noperations. This task, however, is extremely time-consuming, error-prone and\nhuman dependent, thus automated data-driven anomaly detection algorithms have\nbeen emerging at a steady pace. However, there are no publicly available\ndatasets of real satellite telemetry accompanied with the ground-truth\nannotations that could be used to train and verify anomaly detection supervised\nmodels. In this article, we address this research gap and introduce the\nAI-ready benchmark dataset (OPSSAT-AD) containing the telemetry data acquired\non board OPS-SAT -- a CubeSat mission which has been operated by the European\nSpace Agency which has come to an end during the night of 22--23 May 2024\n(CEST). The dataset is accompanied with the baseline results obtained using 30\nsupervised and unsupervised classic and deep machine learning algorithms for\nanomaly detection. They were trained and validated using the training-test\ndataset split introduced in this work, and we present a suggested set of\nquality metrics which should be always calculated to confront the new\nalgorithms for anomaly detection while exploiting OPSSAT-AD. We believe that\nthis work may become an important step toward building a fair, reproducible and\nobjective validation procedure that can be used to quantify the capabilities of\nthe emerging anomaly detection techniques in an unbiased and fully transparent\nway.",
    "categories": [
      "eess.SP",
      "cs.AI",
      "cs.LG"
    ],
    "primary_category": "eess.SP",
    "comment": "13 pages, 8 figures, 3 tables",
    "pdf_url": "http://arxiv.org/pdf/2407.04730v1",
    "published_date": "2024-06-29 11:12:22 UTC",
    "updated_date": "2024-06-29 11:12:22 UTC"
  },
  {
    "arxiv_id": "2407.00402v3",
    "title": "Is It Really Long Context if All You Need Is Retrieval? Towards Genuinely Difficult Long Context NLP",
    "authors": [
      "Omer Goldman",
      "Alon Jacovi",
      "Aviv Slobodkin",
      "Aviya Maimon",
      "Ido Dagan",
      "Reut Tsarfaty"
    ],
    "abstract": "Improvements in language models' capabilities have pushed their applications\ntowards longer contexts, making long-context evaluation and development an\nactive research area. However, many disparate use-cases are grouped together\nunder the umbrella term of \"long-context\", defined simply by the total length\nof the model's input, including - for example - Needle-in-a-Haystack tasks,\nbook summarization, and information aggregation. Given their varied difficulty,\nin this position paper we argue that conflating different tasks by their\ncontext length is unproductive. As a community, we require a more precise\nvocabulary to understand what makes long-context tasks similar or different. We\npropose to unpack the taxonomy of long-context based on the properties that\nmake them more difficult with longer contexts. We propose two orthogonal axes\nof difficulty: (I) Diffusion: How hard is it to find the necessary information\nin the context? (II) Scope: How much necessary information is there to find? We\nsurvey the literature on long-context, provide justification for this taxonomy\nas an informative descriptor, and situate the literature with respect to it. We\nconclude that the most difficult and interesting settings, whose necessary\ninformation is very long and highly diffused within the input, is severely\nunder-explored. By using a descriptive vocabulary and discussing the relevant\nproperties of difficulty in long-context, we can implement more informed\nresearch in this area. We call for a careful design of tasks and benchmarks\nwith distinctly long context, taking into account the characteristics that make\nit qualitatively different from shorter context.",
    "categories": [
      "cs.CL",
      "cs.AI"
    ],
    "primary_category": "cs.CL",
    "comment": "EMNLP 2024",
    "pdf_url": "http://arxiv.org/pdf/2407.00402v3",
    "published_date": "2024-06-29 11:09:47 UTC",
    "updated_date": "2024-10-06 09:09:26 UTC"
  },
  {
    "arxiv_id": "2407.00401v1",
    "title": "PUZZLES: A Benchmark for Neural Algorithmic Reasoning",
    "authors": [
      "Benjamin Estermann",
      "Luca A. Lanzend√∂rfer",
      "Yannick Niedermayr",
      "Roger Wattenhofer"
    ],
    "abstract": "Algorithmic reasoning is a fundamental cognitive ability that plays a pivotal\nrole in problem-solving and decision-making processes. Reinforcement Learning\n(RL) has demonstrated remarkable proficiency in tasks such as motor control,\nhandling perceptual input, and managing stochastic environments. These\nadvancements have been enabled in part by the availability of benchmarks. In\nthis work we introduce PUZZLES, a benchmark based on Simon Tatham's Portable\nPuzzle Collection, aimed at fostering progress in algorithmic and logical\nreasoning in RL. PUZZLES contains 40 diverse logic puzzles of adjustable sizes\nand varying levels of complexity; many puzzles also feature a diverse set of\nadditional configuration parameters. The 40 puzzles provide detailed\ninformation on the strengths and generalization capabilities of RL agents.\nFurthermore, we evaluate various RL algorithms on PUZZLES, providing baseline\ncomparisons and demonstrating the potential for future research. All the\nsoftware, including the environment, is available at\nhttps://github.com/ETH-DISCO/rlp.",
    "categories": [
      "cs.LG",
      "cs.AI"
    ],
    "primary_category": "cs.LG",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2407.00401v1",
    "published_date": "2024-06-29 11:02:05 UTC",
    "updated_date": "2024-06-29 11:02:05 UTC"
  },
  {
    "arxiv_id": "2407.00396v1",
    "title": "A Study on Effect of Reference Knowledge Choice in Generating Technical Content Relevant to SAPPhIRE Model Using Large Language Model",
    "authors": [
      "Kausik Bhattacharya",
      "Anubhab Majumder",
      "Amaresh Chakrabarti"
    ],
    "abstract": "Representation of systems using the SAPPhIRE model of causality can be an\ninspirational stimulus in design. However, creating a SAPPhIRE model of a\ntechnical or a natural system requires sourcing technical knowledge from\nmultiple technical documents regarding how the system works. This research\ninvestigates how to generate technical content accurately relevant to the\nSAPPhIRE model of causality using a Large Language Model, also called LLM. This\npaper, which is the first part of the two-part research, presents a method for\nhallucination suppression using Retrieval Augmented Generating with LLM to\ngenerate technical content supported by the scientific information relevant to\na SAPPhIRE con-struct. The result from this research shows that the selection\nof reference knowledge used in providing context to the LLM for generating the\ntechnical content is very important. The outcome of this research is used to\nbuild a software support tool to generate the SAPPhIRE model of a given\ntechnical system.",
    "categories": [
      "cs.CL",
      "cs.AI"
    ],
    "primary_category": "cs.CL",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2407.00396v1",
    "published_date": "2024-06-29 10:46:01 UTC",
    "updated_date": "2024-06-29 10:46:01 UTC"
  },
  {
    "arxiv_id": "2407.14268v1",
    "title": "Urban Visual Appeal According to ChatGPT: Contrasting AI and Human Insights",
    "authors": [
      "Milad Malekzadeh",
      "Elias Willberg",
      "Jussi Torkko",
      "Tuuli Toivonen"
    ],
    "abstract": "The visual appeal of urban environments significantly impacts residents'\nsatisfaction with their living spaces and their overall mood, which in turn,\naffects their health and well-being. Given the resource-intensive nature of\ngathering evaluations on urban visual appeal through surveys or inquiries from\nresidents, there is a constant quest for automated solutions to streamline this\nprocess and support spatial planning. In this study, we applied an\noff-the-shelf AI model to automate the analysis of urban visual appeal, using\nover 1,800 Google Street View images of Helsinki, Finland. By incorporating the\nGPT-4 model with specified criteria, we assessed these images. Simultaneously,\n24 participants were asked to rate the images. Our results demonstrated a\nstrong alignment between GPT-4 and participant ratings, although geographic\ndisparities were noted. Specifically, GPT-4 showed a preference for suburban\nareas with significant greenery, contrasting with participants who found these\nareas less appealing. Conversely, in the city centre and densely populated\nurban regions of Helsinki, GPT-4 assigned lower visual appeal scores than\nparticipant ratings. While there was general agreement between AI and human\nassessments across various locations, GPT-4 struggled to incorporate contextual\nnuances into its ratings, unlike participants, who considered both context and\nfeatures of the urban environment. The study suggests that leveraging AI models\nlike GPT-4 allows spatial planners to gather insights into the visual appeal of\ndifferent areas efficiently, aiding decisions that enhance residents' and\ntravellers' satisfaction and mental health. Although AI models provide valuable\ninsights, human perspectives are essential for a comprehensive understanding of\nurban visual appeal. This will ensure that planning and design decisions\npromote healthy living environments effectively.",
    "categories": [
      "cs.HC",
      "cs.AI",
      "cs.CY",
      "J.4"
    ],
    "primary_category": "cs.HC",
    "comment": "42 pages, 4 figures, 6 tables",
    "pdf_url": "http://arxiv.org/pdf/2407.14268v1",
    "published_date": "2024-06-29 10:32:58 UTC",
    "updated_date": "2024-06-29 10:32:58 UTC"
  },
  {
    "arxiv_id": "2407.00386v1",
    "title": "Multi-task multi-constraint differential evolution with elite-guided knowledge transfer for coal mine integrated energy system dispatching",
    "authors": [
      "Canyun Dai",
      "Xiaoyan Sun",
      "Hejuan Hu",
      "Wei Song",
      "Yong Zhang",
      "Dunwei Gong"
    ],
    "abstract": "The dispatch optimization of coal mine integrated energy system is\nchallenging due to high dimensionality, strong coupling constraints, and\nmultiobjective. Existing constrained multiobjective evolutionary algorithms\nstruggle with locating multiple small and irregular feasible regions, making\nthem inaplicable to this problem. To address this issue, we here develop a\nmultitask evolutionary algorithm framework that incorporates the dispatch\ncorrelated domain knowledge to effectively deal with strong constraints and\nmultiobjective optimization. Possible evolutionary multitask construction\nstrategy based on complex constraint relationship analysis and handling, i.e.,\nconstraint coupled spatial decomposition, constraint strength classification\nand constraint handling technique, is first explored. Within the multitask\nevolutionary optimization framework, two strategies, i.e., an elite guided\nknowledge transfer by designing a special crowding distance mechanism to select\ndominant individuals from each task, and an adaptive neighborhood technology\nbased mutation to effectively balance the diversity and convergence of each\noptimized task for the differential evolution algorithm, are further developed.\nThe performance of the proposed algorithm in feasibility, convergence, and\ndiversity is demonstrated in a case study of a coal mine integrated energy\nsystem by comparing with CPLEX solver and seven constrained multiobjective\nevolutionary algorithms.",
    "categories": [
      "cs.NE",
      "cs.AI"
    ],
    "primary_category": "cs.NE",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2407.00386v1",
    "published_date": "2024-06-29 10:00:16 UTC",
    "updated_date": "2024-06-29 10:00:16 UTC"
  },
  {
    "arxiv_id": "2407.00383v1",
    "title": "FANFOLD: Graph Normalizing Flows-driven Asymmetric Network for Unsupervised Graph-Level Anomaly Detection",
    "authors": [
      "Rui Cao",
      "Shijie Xue",
      "Jindong Li",
      "Qi Wang",
      "Yi Chang"
    ],
    "abstract": "Unsupervised graph-level anomaly detection (UGAD) has attracted increasing\ninterest due to its widespread application. In recent studies, knowledge\ndistillation-based methods have been widely used in unsupervised anomaly\ndetection to improve model efficiency and generalization. However, the inherent\nsymmetry between the source (teacher) and target (student) networks typically\nresults in consistent outputs across both architectures, making it difficult to\ndistinguish abnormal graphs from normal graphs. Also, existing methods mainly\nrely on graph features to distinguish anomalies, which may be unstable with\ncomplex and diverse data and fail to capture the essence that differentiates\nnormal graphs from abnormal ones. In this work, we propose a Graph Normalizing\nFlows-driven Asymmetric Network For Unsupervised Graph-Level Anomaly Detection\n(FANFOLD in short). We introduce normalizing flows to unsupervised graph-level\nanomaly detection due to their successful application and superior quality in\nlearning the underlying distribution of samples. Specifically, we adopt the\nknowledge distillation technique and apply normalizing flows on the source\nnetwork, achieving the asymmetric network. In the training stage, FANFOLD\ntransforms the original distribution of normal graphs to a standard normal\ndistribution. During inference, FANFOLD computes the anomaly score using the\nsource-target loss to discriminate between normal and anomalous graphs. We\nconduct extensive experiments on 15 datasets of different fields with 9\nbaseline methods to validate the superiority of FANFOLD.",
    "categories": [
      "cs.LG",
      "cs.AI"
    ],
    "primary_category": "cs.LG",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2407.00383v1",
    "published_date": "2024-06-29 09:49:16 UTC",
    "updated_date": "2024-06-29 09:49:16 UTC"
  },
  {
    "arxiv_id": "2407.12816v1",
    "title": "Quantum Algorithms for Weighted Constrained Sampling and Weighted Model Counting",
    "authors": [
      "Fabrizio Riguzzi"
    ],
    "abstract": "We consider the problems of weighted constrained sampling and weighted model\ncounting, where we are given a propositional formula and a weight for each\nworld. The first problem consists of sampling worlds with a probability\nproportional to their weight given that the formula is satisfied. The latter is\nthe problem of computing the sum of the weights of the models of the formula.\nBoth have applications in many fields such as probabilistic reasoning,\ngraphical models, statistical physics, statistics and hardware verification. In\nthis article, we propose QWCS and QWMC, quantum algorithms for performing\nweighted constrained sampling and weighted model counting, respectively. Both\nare based on the quantum search/quantum model counting algorithms that are\nmodified to take into account the weights. In the black box model of\ncomputation, where we can only query an oracle for evaluating the Boolean\nfunction given an assignment, QWCS requires\n$O(2^{\\frac{n}{2}}+1/\\sqrt{\\text{WMC}})$ oracle calls, where where $n$ is the\nnumber of Boolean variables and $\\text{WMC}$ is the normalized between 0 and 1\nweighted model count of the formula, while a classical algorithm has a\ncomplexity of $\\Omega(1/\\text{WMC})$. QWMC takes $\\Theta(2^{\\frac{n}{2}})$\noracle calss, while classically the best complexity is $\\Theta(2^n)$, thus\nachieving a quadratic speedup.",
    "categories": [
      "quant-ph",
      "cs.AI",
      "68Q12"
    ],
    "primary_category": "quant-ph",
    "comment": "Under submission",
    "pdf_url": "http://arxiv.org/pdf/2407.12816v1",
    "published_date": "2024-06-29 09:44:44 UTC",
    "updated_date": "2024-06-29 09:44:44 UTC"
  },
  {
    "arxiv_id": "2407.00382v4",
    "title": "Towards Universal Mesh Movement Networks",
    "authors": [
      "Mingrui Zhang",
      "Chunyang Wang",
      "Stephan Kramer",
      "Joseph G. Wallwork",
      "Siyi Li",
      "Jiancheng Liu",
      "Xiang Chen",
      "Matthew D. Piggott"
    ],
    "abstract": "Solving complex Partial Differential Equations (PDEs) accurately and\nefficiently is an essential and challenging problem in all scientific and\nengineering disciplines. Mesh movement methods provide the capability to\nimprove the accuracy of the numerical solution without increasing the overall\nmesh degree of freedom count. Conventional sophisticated mesh movement methods\nare extremely expensive and struggle to handle scenarios with complex boundary\ngeometries. However, existing learning-based methods require re-training from\nscratch given a different PDE type or boundary geometry, which limits their\napplicability, and also often suffer from robustness issues in the form of\ninverted elements. In this paper, we introduce the Universal Mesh Movement\nNetwork (UM2N), which -- once trained -- can be applied in a non-intrusive,\nzero-shot manner to move meshes with different size distributions and\nstructures, for solvers applicable to different PDE types and boundary\ngeometries. UM2N consists of a Graph Transformer (GT) encoder for extracting\nfeatures and a Graph Attention Network (GAT) based decoder for moving the mesh.\nWe evaluate our method on advection and Navier-Stokes based examples, as well\nas a real-world tsunami simulation case. Our method outperforms existing\nlearning-based mesh movement methods in terms of the benchmarks described\nabove. In comparison to the conventional sophisticated Monge-Amp\\`ere\nPDE-solver based method, our approach not only significantly accelerates mesh\nmovement, but also proves effective in scenarios where the conventional method\nfails. Our project page is at https://erizmr.github.io/UM2N/.",
    "categories": [
      "math.NA",
      "cs.AI",
      "cs.CE",
      "cs.LG",
      "cs.NA"
    ],
    "primary_category": "math.NA",
    "comment": "Accepted at NeurIPS 2024 as a spotlight paper",
    "pdf_url": "http://arxiv.org/pdf/2407.00382v4",
    "published_date": "2024-06-29 09:35:12 UTC",
    "updated_date": "2024-12-03 04:07:32 UTC"
  },
  {
    "arxiv_id": "2407.00379v2",
    "title": "GraphArena: Evaluating and Exploring Large Language Models on Graph Computation",
    "authors": [
      "Jianheng Tang",
      "Qifan Zhang",
      "Yuhan Li",
      "Nuo Chen",
      "Jia Li"
    ],
    "abstract": "The ``arms race'' of Large Language Models (LLMs) demands new benchmarks to\nexamine their progresses. In this paper, we introduce GraphArena, a\nbenchmarking tool designed to evaluate LLMs on real-world graph computational\nproblems. It offers a suite of four polynomial-time tasks (e.g., Shortest\nDistance) and six NP-complete challenges (e.g., Traveling Salesman Problem).\nGraphArena features a rigorous evaluation framework that classifies LLM outputs\nas correct, suboptimal (feasible but not optimal), hallucinatory (properly\nformatted but infeasible), or missing. Evaluation of over 10 LLMs reveals that\neven top-performing LLMs struggle with larger, more complex graph problems and\nexhibit hallucination issues. We further explore four potential solutions to\naddress this issue and improve LLMs on graph computation, including\nchain-of-thought prompting, instruction tuning, code writing, and scaling\ntest-time compute, each demonstrating unique strengths and limitations.\nGraphArena complements the existing LLM benchmarks and is open-sourced at\nhttps://github.com/squareRoot3/GraphArena.",
    "categories": [
      "cs.AI",
      "cs.CL"
    ],
    "primary_category": "cs.AI",
    "comment": "ICLR 2025 camera ready version",
    "pdf_url": "http://arxiv.org/pdf/2407.00379v2",
    "published_date": "2024-06-29 09:19:23 UTC",
    "updated_date": "2025-02-15 09:39:28 UTC"
  },
  {
    "arxiv_id": "2407.00377v2",
    "title": "The Factuality Tax of Diversity-Intervened Text-to-Image Generation: Benchmark and Fact-Augmented Intervention",
    "authors": [
      "Yixin Wan",
      "Di Wu",
      "Haoran Wang",
      "Kai-Wei Chang"
    ],
    "abstract": "Prompt-based \"diversity interventions\" are commonly adopted to improve the\ndiversity of Text-to-Image (T2I) models depicting individuals with various\nracial or gender traits. However, will this strategy result in nonfactual\ndemographic distribution, especially when generating real historical figures.\nIn this work, we propose DemOgraphic FActualIty Representation (DoFaiR), a\nbenchmark to systematically quantify the trade-off between using diversity\ninterventions and preserving demographic factuality in T2I models. DoFaiR\nconsists of 756 meticulously fact-checked test instances to reveal the\nfactuality tax of various diversity prompts through an automated\nevidence-supported evaluation pipeline. Experiments on DoFaiR unveil that\ndiversity-oriented instructions increase the number of different gender and\nracial groups in DALLE-3's generations at the cost of historically inaccurate\ndemographic distributions. To resolve this issue, we propose Fact-Augmented\nIntervention (FAI), which instructs a Large Language Model (LLM) to reflect on\nverbalized or retrieved factual information about gender and racial\ncompositions of generation subjects in history, and incorporate it into the\ngeneration context of T2I models. By orienting model generations using the\nreflected historical truths, FAI significantly improves the demographic\nfactuality under diversity interventions while preserving diversity.",
    "categories": [
      "cs.CL",
      "cs.AI",
      "cs.CV",
      "cs.CY"
    ],
    "primary_category": "cs.CL",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2407.00377v2",
    "published_date": "2024-06-29 09:09:42 UTC",
    "updated_date": "2024-10-23 22:53:28 UTC"
  },
  {
    "arxiv_id": "2407.00371v1",
    "title": "Axiomatization of Gradient Smoothing in Neural Networks",
    "authors": [
      "Linjiang Zhou",
      "Xiaochuan Shi",
      "Chao Ma",
      "Zepeng Wang"
    ],
    "abstract": "Gradients play a pivotal role in neural networks explanation. The inherent\nhigh dimensionality and structural complexity of neural networks result in the\noriginal gradients containing a significant amount of noise. While several\napproaches were proposed to reduce noise with smoothing, there is little\ndiscussion of the rationale behind smoothing gradients in neural networks. In\nthis work, we proposed a gradient smooth theoretical framework for neural\nnetworks based on the function mollification and Monte Carlo integration. The\nframework intrinsically axiomatized gradient smoothing and reveals the\nrationale of existing methods. Furthermore, we provided an approach to design\nnew smooth methods derived from the framework. By experimental measurement of\nseveral newly designed smooth methods, we demonstrated the research potential\nof our framework.",
    "categories": [
      "cs.LG",
      "cs.AI"
    ],
    "primary_category": "cs.LG",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2407.00371v1",
    "published_date": "2024-06-29 08:43:38 UTC",
    "updated_date": "2024-06-29 08:43:38 UTC"
  },
  {
    "arxiv_id": "2407.00362v2",
    "title": "JSCDS: A Core Data Selection Method with Jason-Shannon Divergence for Caries RGB Images-Efficient Learning",
    "authors": [
      "Peiliang Zhang",
      "Yujia Tong",
      "Chenghu Du",
      "Chao Che",
      "Yongjun Zhu"
    ],
    "abstract": "Deep learning-based RGB caries detection improves the efficiency of caries\nidentification and is crucial for preventing oral diseases. The performance of\ndeep learning models depends on high-quality data and requires substantial\ntraining resources, making efficient deployment challenging. Core data\nselection, by eliminating low-quality and confusing data, aims to enhance\ntraining efficiency without significantly compromising model performance.\nHowever, distance-based data selection methods struggle to distinguish\ndependencies among high-dimensional caries data. To address this issue, we\npropose a Core Data Selection Method with Jensen-Shannon Divergence (JSCDS) for\nefficient caries image learning and caries classification. We describe the core\ndata selection criterion as the distribution of samples in different classes.\nJSCDS calculates the cluster centers by sample embedding representation in the\ncaries classification network and utilizes Jensen-Shannon Divergence to compute\nthe mutual information between data samples and cluster centers, capturing\nnonlinear dependencies among high-dimensional data. The average mutual\ninformation is calculated to fit the above distribution, serving as the\ncriterion for constructing the core set for model training. Extensive\nexperiments on RGB caries datasets show that JSCDS outperforms other data\nselection methods in prediction performance and time consumption. Notably,\nJSCDS exceeds the performance of the full dataset model with only 50% of the\ncore data, with its performance advantage becoming more pronounced in the 70%\nof core data.",
    "categories": [
      "cs.CV",
      "cs.AI"
    ],
    "primary_category": "cs.CV",
    "comment": "Accepted in KDD 2024 Workshop AIDSH",
    "pdf_url": "http://arxiv.org/pdf/2407.00362v2",
    "published_date": "2024-06-29 08:19:25 UTC",
    "updated_date": "2024-07-07 03:36:14 UTC"
  },
  {
    "arxiv_id": "2407.00361v1",
    "title": "From RAG to RICHES: Retrieval Interlaced with Sequence Generation",
    "authors": [
      "Palak Jain",
      "Livio Baldini Soares",
      "Tom Kwiatkowski"
    ],
    "abstract": "We present RICHES, a novel approach that interleaves retrieval with sequence\ngeneration tasks. RICHES offers an alternative to conventional RAG systems by\neliminating the need for separate retriever and generator. It retrieves\ndocuments by directly decoding their contents, constrained on the corpus.\nUnifying retrieval with generation allows us to adapt to diverse new tasks via\nprompting alone. RICHES can work with any Instruction-tuned model, without\nadditional training. It provides attributed evidence, supports multi-hop\nretrievals and interleaves thoughts to plan on what to retrieve next, all\nwithin a single decoding pass of the LLM. We demonstrate the strong performance\nof RICHES across ODQA tasks including attributed and multi-hop QA.",
    "categories": [
      "cs.CL",
      "cs.AI"
    ],
    "primary_category": "cs.CL",
    "comment": "18 pages, 3 figures, Preprint",
    "pdf_url": "http://arxiv.org/pdf/2407.00361v1",
    "published_date": "2024-06-29 08:16:58 UTC",
    "updated_date": "2024-06-29 08:16:58 UTC"
  },
  {
    "arxiv_id": "2407.00352v2",
    "title": "PhyTracker: An Online Tracker for Phytoplankton",
    "authors": [
      "Yang Yu",
      "Qingxuan Lv",
      "Yuezun Li",
      "Zhiqiang Wei",
      "Junyu Dong"
    ],
    "abstract": "Phytoplankton, a crucial component of aquatic ecosystems, requires efficient\nmonitoring to understand marine ecological processes and environmental\nconditions. Traditional phytoplankton monitoring methods, relying on non-in\nsitu observations, are time-consuming and resource-intensive, limiting timely\nanalysis. To address these limitations, we introduce PhyTracker, an intelligent\nin situ tracking framework designed for automatic tracking of phytoplankton.\nPhyTracker overcomes significant challenges unique to phytoplankton monitoring,\nsuch as constrained mobility within water flow, inconspicuous appearance, and\nthe presence of impurities. Our method incorporates three innovative modules: a\nTexture-enhanced Feature Extraction (TFE) module, an Attention-enhanced\nTemporal Association (ATA) module, and a Flow-agnostic Movement Refinement\n(FMR) module. These modules enhance feature capture, differentiate between\nphytoplankton and impurities, and refine movement characteristics,\nrespectively. Extensive experiments on the PMOT dataset validate the\nsuperiority of PhyTracker in phytoplankton tracking, and additional tests on\nthe MOT dataset demonstrate its general applicability, outperforming\nconventional tracking methods. This work highlights key differences between\nphytoplankton and traditional objects, offering an effective solution for\nphytoplankton monitoring.",
    "categories": [
      "cs.CV",
      "cs.AI"
    ],
    "primary_category": "cs.CV",
    "comment": "13pages,eleven figures",
    "pdf_url": "http://arxiv.org/pdf/2407.00352v2",
    "published_date": "2024-06-29 07:53:47 UTC",
    "updated_date": "2024-11-12 13:01:48 UTC"
  },
  {
    "arxiv_id": "2407.00342v7",
    "title": "KPC-cF: Aspect-Based Sentiment Analysis via Implicit-Feature Alignment with Corpus Filtering",
    "authors": [
      "Kibeom Nam"
    ],
    "abstract": "Investigations into Aspect-Based Sentiment Analysis (ABSA) for Korean\nindustrial reviews are notably lacking in the existing literature. Our research\nproposes an intuitive and effective framework for ABSA in low-resource\nlanguages such as Korean. It optimizes prediction labels by integrating\ntranslated benchmark and unlabeled Korean data. Using a model fine-tuned on\ntranslated data, we pseudo-labeled the actual Korean NLI set. Subsequently, we\napplied LaBSE and \\MSP{}-based filtering to this pseudo-NLI set as implicit\nfeature, enhancing Aspect Category Detection and Polarity determination through\nadditional training. Incorporating dual filtering, this model bridged dataset\ngaps and facilitates feature alignment with minimal resources. By implementing\nalignment pipelines, our approach aims to leverage high-resource datasets to\ndevelop reliable predictive and refined models within corporate or individual\ncommunities in low-resource language countries. Compared to English ABSA, our\nframework showed an approximately 3\\% difference in F1 scores and accuracy. We\nwill release our dataset and code for Korean ABSA, at this link.",
    "categories": [
      "cs.CL",
      "cs.AI"
    ],
    "primary_category": "cs.CL",
    "comment": "Work in Progress, DMLR@ICML 2024",
    "pdf_url": "http://arxiv.org/pdf/2407.00342v7",
    "published_date": "2024-06-29 07:01:51 UTC",
    "updated_date": "2025-04-16 02:18:10 UTC"
  },
  {
    "arxiv_id": "2407.01626v1",
    "title": "SPARKLE: Enhancing SPARQL Generation with Direct KG Integration in Decoding",
    "authors": [
      "Jaebok Lee",
      "Hyeonjeong Shin"
    ],
    "abstract": "Existing KBQA methods have traditionally relied on multi-stage methodologies,\ninvolving tasks such as entity linking, subgraph retrieval and query structure\ngeneration. However, multi-stage approaches are dependent on the accuracy of\npreceding steps, leading to cascading errors and increased inference time.\nAlthough a few studies have explored the use of end-to-end models, they often\nsuffer from lower accuracy and generate inoperative query that is not supported\nby the underlying data. Furthermore, most prior approaches are limited to the\nstatic training data, potentially overlooking the evolving nature of knowledge\nbases over time. To address these challenges, we present a novel end-to-end\nnatural language to SPARQL framework, SPARKLE. Notably SPARKLE leverages the\nstructure of knowledge base directly during the decoding, effectively\nintegrating knowledge into the query generation. Our study reveals that simply\nreferencing knowledge base during inference significantly reduces the\noccurrence of inexecutable query generations. SPARKLE achieves new\nstate-of-the-art results on SimpleQuestions-Wiki and highest F1 score on LCQuAD\n1.0 (among models not using gold entities), while getting slightly lower result\non the WebQSP dataset. Finally, we demonstrate SPARKLE's fast inference speed\nand its ability to adapt when the knowledge base differs between the training\nand inference stages.",
    "categories": [
      "cs.CL",
      "cs.AI",
      "cs.DB",
      "cs.IR"
    ],
    "primary_category": "cs.CL",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2407.01626v1",
    "published_date": "2024-06-29 06:43:11 UTC",
    "updated_date": "2024-06-29 06:43:11 UTC"
  },
  {
    "arxiv_id": "2407.01624v1",
    "title": "Guided Trajectory Generation with Diffusion Models for Offline Model-based Optimization",
    "authors": [
      "Taeyoung Yun",
      "Sujin Yun",
      "Jaewoo Lee",
      "Jinkyoo Park"
    ],
    "abstract": "Optimizing complex and high-dimensional black-box functions is ubiquitous in\nscience and engineering fields. Unfortunately, the online evaluation of these\nfunctions is restricted due to time and safety constraints in most cases. In\noffline model-based optimization (MBO), we aim to find a design that maximizes\nthe target function using only a pre-existing offline dataset. While prior\nmethods consider forward or inverse approaches to address the problem, these\napproaches are limited by conservatism and the difficulty of learning highly\nmulti-modal mappings. Recently, there has been an emerging paradigm of learning\nto improve solutions with synthetic trajectories constructed from the offline\ndataset. In this paper, we introduce a novel conditional generative modeling\napproach to produce trajectories toward high-scoring regions. First, we\nconstruct synthetic trajectories toward high-scoring regions using the dataset\nwhile injecting locality bias for consistent improvement directions. Then, we\ntrain a conditional diffusion model to generate trajectories conditioned on\ntheir scores. Lastly, we sample multiple trajectories from the trained model\nwith guidance to explore high-scoring regions beyond the dataset and select\nhigh-fidelity designs among generated trajectories with the proxy function.\nExtensive experiment results demonstrate that our method outperforms\ncompetitive baselines on Design-Bench and its practical variants. The code is\npublicly available in \\texttt{https://github.com/dbsxodud-11/GTG}.",
    "categories": [
      "cs.LG",
      "cs.AI"
    ],
    "primary_category": "cs.LG",
    "comment": "29 pages, 11 figures, 17 tables",
    "pdf_url": "http://arxiv.org/pdf/2407.01624v1",
    "published_date": "2024-06-29 06:12:36 UTC",
    "updated_date": "2024-06-29 06:12:36 UTC"
  },
  {
    "arxiv_id": "2407.00326v3",
    "title": "Teola: Towards End-to-End Optimization of LLM-based Applications",
    "authors": [
      "Xin Tan",
      "Yimin Jiang",
      "Yitao Yang",
      "Hong Xu"
    ],
    "abstract": "Large language model (LLM)-based applications consist of both LLM and non-LLM\ncomponents, each contributing to the end-to-end latency. Despite great efforts\nto optimize LLM inference, end-to-end workflow optimization has been\noverlooked. Existing frameworks employ coarse-grained orchestration with task\nmodules, which confines optimizations to within each module and yields\nsuboptimal scheduling decisions. We propose fine-grained end-to-end\norchestration, which utilizes task primitives as the basic units and represents\neach query's workflow as a primitive-level dataflow graph. This explicitly\nexposes a much larger design space, enables optimizations in parallelization\nand pipelining across primitives of different modules, and enhances scheduling\nto improve application-level performance. We build Teola, a novel orchestration\nframework for LLM-based applications that implements this scheme. Comprehensive\nexperiments show that Teola can achieve up to 2.09x speedup over existing\nsystems across various popular LLM applications. The code is available at\nhttps://github.com/NetX-lab/Ayo.",
    "categories": [
      "cs.DC",
      "cs.AI",
      "cs.NI"
    ],
    "primary_category": "cs.DC",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2407.00326v3",
    "published_date": "2024-06-29 05:59:53 UTC",
    "updated_date": "2025-03-31 13:33:54 UTC"
  },
  {
    "arxiv_id": "2407.00320v1",
    "title": "LiteSearch: Efficacious Tree Search for LLM",
    "authors": [
      "Ante Wang",
      "Linfeng Song",
      "Ye Tian",
      "Baolin Peng",
      "Dian Yu",
      "Haitao Mi",
      "Jinsong Su",
      "Dong Yu"
    ],
    "abstract": "Recent research suggests that tree search algorithms (e.g. Monte Carlo Tree\nSearch) can dramatically boost LLM performance on complex mathematical\nreasoning tasks. However, they often require more than 10 times the\ncomputational resources of greedy decoding due to wasteful search strategies,\nmaking them difficult to be deployed in practical applications. This study\nintroduces a novel guided tree search algorithm with dynamic node selection and\nnode-level exploration budget (maximum number of children) calculation to\ntackle this issue. By considering the search progress towards the final answer\n(history) and the guidance from a value network (future) trained without any\nstep-wise annotations, our algorithm iteratively selects the most promising\ntree node before expanding it within the boundaries of the allocated\ncomputational budget. Experiments conducted on the GSM8K and TabMWP datasets\ndemonstrate that our approach not only offers competitive performance but also\nenjoys significantly lower computational costs compared to baseline methods.",
    "categories": [
      "cs.CL",
      "cs.AI",
      "cs.LG"
    ],
    "primary_category": "cs.CL",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2407.00320v1",
    "published_date": "2024-06-29 05:14:04 UTC",
    "updated_date": "2024-06-29 05:14:04 UTC"
  },
  {
    "arxiv_id": "2407.00312v4",
    "title": "UDC: A Unified Neural Divide-and-Conquer Framework for Large-Scale Combinatorial Optimization Problems",
    "authors": [
      "Zhi Zheng",
      "Changliang Zhou",
      "Tong Xialiang",
      "Mingxuan Yuan",
      "Zhenkun Wang"
    ],
    "abstract": "Single-stage neural combinatorial optimization solvers have achieved\nnear-optimal results on various small-scale combinatorial optimization (CO)\nproblems without requiring expert knowledge. However, these solvers exhibit\nsignificant performance degradation when applied to large-scale CO problems.\nRecently, two-stage neural methods motivated by divide-and-conquer strategies\nhave shown efficiency in addressing large-scale CO problems. Nevertheless, the\nperformance of these methods highly relies on problem-specific heuristics in\neither the dividing or the conquering procedure, which limits their\napplicability to general CO problems. Moreover, these methods employ separate\ntraining schemes and ignore the interdependencies between the dividing and\nconquering strategies, often leading to sub-optimal solutions. To tackle these\ndrawbacks, this article develops a unified neural divide-and-conquer framework\n(i.e., UDC) for solving general large-scale CO problems. UDC offers a\nDivide-Conquer-Reunion (DCR) training method to eliminate the negative impact\nof a sub-optimal dividing policy. Employing a high-efficiency Graph Neural\nNetwork (GNN) for global instance dividing and a fixed-length sub-path solver\nfor conquering divided sub-problems, the proposed UDC framework demonstrates\nextensive applicability, achieving superior performance in 10 representative\nlarge-scale CO problems. The code is available at\nhttps://github.com/CIAM-Group/NCO_code/tree/main/single_objective/UDC-Large-scale-CO-master.",
    "categories": [
      "cs.AI",
      "cs.NE"
    ],
    "primary_category": "cs.AI",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2407.00312v4",
    "published_date": "2024-06-29 04:29:03 UTC",
    "updated_date": "2025-01-18 06:02:08 UTC"
  },
  {
    "arxiv_id": "2407.00299v4",
    "title": "Human-Agent Joint Learning for Efficient Robot Manipulation Skill Acquisition",
    "authors": [
      "Shengcheng Luo",
      "Quanquan Peng",
      "Jun Lv",
      "Kaiwen Hong",
      "Katherine Rose Driggs-Campbell",
      "Cewu Lu",
      "Yong-Lu Li"
    ],
    "abstract": "Employing a teleoperation system for gathering demonstrations offers the\npotential for more efficient learning of robot manipulation. However,\nteleoperating a robot arm equipped with a dexterous hand or gripper, via a\nteleoperation system presents inherent challenges due to the task's high\ndimensionality, complexity of motion, and differences between physiological\nstructures. In this study, we introduce a novel system for joint learning\nbetween human operators and robots, that enables human operators to share\ncontrol of a robot end-effector with a learned assistive agent, simplifies the\ndata collection process, and facilitates simultaneous human demonstration\ncollection and robot manipulation training. As data accumulates, the assistive\nagent gradually learns. Consequently, less human effort and attention are\nrequired, enhancing the efficiency of the data collection process. It also\nallows the human operator to adjust the control ratio to achieve a trade-off\nbetween manual and automated control. We conducted experiments in both\nsimulated environments and physical real-world settings. Through user studies\nand quantitative evaluations, it is evident that the proposed system could\nenhance data collection efficiency and reduce the need for human adaptation\nwhile ensuring the collected data is of sufficient quality for downstream\ntasks. \\textit{For more details, please refer to our webpage\nhttps://norweig1an.github.io/HAJL.github.io/.",
    "categories": [
      "cs.RO",
      "cs.AI",
      "cs.CV",
      "cs.HC",
      "cs.LG"
    ],
    "primary_category": "cs.RO",
    "comment": "8 pages, 6 figures",
    "pdf_url": "http://arxiv.org/pdf/2407.00299v4",
    "published_date": "2024-06-29 03:37:29 UTC",
    "updated_date": "2024-10-21 15:56:23 UTC"
  },
  {
    "arxiv_id": "2407.00278v2",
    "title": "PerAct2: Benchmarking and Learning for Robotic Bimanual Manipulation Tasks",
    "authors": [
      "Markus Grotz",
      "Mohit Shridhar",
      "Tamim Asfour",
      "Dieter Fox"
    ],
    "abstract": "Bimanual manipulation is challenging due to precise spatial and temporal\ncoordination required between two arms. While there exist several real-world\nbimanual systems, there is a lack of simulated benchmarks with a large task\ndiversity for systematically studying bimanual capabilities across a wide range\nof tabletop tasks. This paper addresses the gap by extending RLBench to\nbimanual manipulation. We open-source our code and benchmark comprising 13 new\ntasks with 23 unique task variations, each requiring a high degree of\ncoordination and adaptability. To kickstart the benchmark, we extended several\nstate-of-the art methods to bimanual manipulation and also present a\nlanguage-conditioned behavioral cloning agent -- PerAct2, which enables the\nlearning and execution of bimanual 6-DoF manipulation tasks. Our novel network\narchitecture efficiently integrates language processing with action prediction,\nallowing robots to understand and perform complex bimanual tasks in response to\nuser-specified goals. Project website with code is available at:\nhttp://bimanual.github.io",
    "categories": [
      "cs.RO",
      "cs.AI",
      "cs.CV",
      "cs.LG"
    ],
    "primary_category": "cs.RO",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2407.00278v2",
    "published_date": "2024-06-29 02:06:01 UTC",
    "updated_date": "2024-07-31 17:57:37 UTC"
  }
]