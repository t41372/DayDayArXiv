{
  "date": "2026-02-10",
  "category": "cs.AI",
  "summary": "欢迎来到 UTC 时间 2026-02-10 的 arXiv 中文 TLDR 快报！\n\n**今日总结：**\n今天的 arXiv 论文爆发式地集中在 **Agent 系统的进化**（特别是针对 GUI 操作和科学发现的端到端框架）、**推理能力的强化**（通过 RL 和 CoT 的变体，如 iGRPO 和 Fine-R1）以及 **高效架构设计**（Mamba 变体、1-bit 量化和 Transformer 深度压缩）。此外，关于 AI 安全（验证码失效、隐式记忆攻击）和 AI for Science（材料合成、DNA 建模）的研究也颇具深度。\n\n以下是精选的硬核论文解读：\n\n---\n\n### 🔥 焦点论文：推理强化与 Agent 进化\n\n**1. iGRPO: Self-Feedback-Driven LLM Reasoning**\n(iGRPO：自反馈驱动的 LLM 推理)\n**TLDR:** 提出了一种基于迭代式群组相对策略优化（Iterative Group Relative Policy Optimization, iGRPO）的强化学习方法。它通过两个阶段工作：先采样探索性草稿（drafts）并选择最佳奖励的草稿，再将其作为 prompt 的一部分进行微调。该方法在数学推理任务（AIME24/25）上通过 DeepSeek-R1 Distilled 等模型刷新了 SOTA，强调了**迭代式自反馈（Iterative Self-Feedback）**在提升逻辑推理中的关键作用。\n\n**2. UI-Venus-1.5 Technical Report**\n(UI-Venus-1.5 技术报告)\n**TLDR:** 发布了一个端到端的通用 GUI Agent。UI-Venus-1.5 的核心改进在于三点：基于 100亿 token 的 GUI 语义**中期训练（Mid-Training）**、针对长程动态导航的**在线强化学习（Online RL）**，以及通过模型融合（Model Merging）统一了 Grounding、Web 和 Mobile 能力。它在 AndroidWorld 和 VenusBench-GD 上取得了新的 SOTA，展示了在真实世界 GUI 操作中的鲁棒性。\n\n**3. InternAgent-1.5: A Unified Agentic Framework for Long-Horizon Autonomous Scientific Discovery**\n(InternAgent-1.5：用于长程自主科学发现的统一 Agent 框架)\n**TLDR:** 介绍了一个针对科学发现的 Agent 系统。该系统包含生成、验证和进化三个子系统，能够执行算法发现（设计机器学习方法）和实证发现（执行计算或湿实验）。它不仅在 GAIA 和 GPQA 等基准上表现出色，还能自主设计核心 ML 算法并执行复杂的物理/生物实验，展示了**AI 科学家**的雏形。\n\n**4. Fine-R1: Make Multi-modal LLMs Excel in Fine-Grained Visual Recognition by Chain-of-Thought Reasoning**\n(Fine-R1：通过思维链推理让多模态大模型精通细粒度视觉识别)\n**TLDR:** 这是一个受 DeepSeek-R1 启发的训练框架，旨在解决多模态大模型（MLLMs）在细粒度视觉识别（FGVR）上的短板。作者构建了包含“视觉分析-子类候选-比较-预测”的 CoT 数据集，并使用了**三元组增强策略优化（Triplet Augmented Policy Optimization）**。仅需 4-shot 训练，Fine-R1 就在识别相似子类（如不同品种的猫）上超越了专门的 Contrastive CLIP 模型。\n\n---\n\n### 🚀 架构创新与效率优化\n\n**5. ArcFlow: Unleashing 2-Step Text-to-Image Generation via High-Precision Non-Linear Flow Distillation**\n(ArcFlow：通过高精度非线性流蒸馏实现 2 步文生图)\n**TLDR:** 针对扩散模型推理慢的问题，提出了一种少步蒸馏框架。不同于传统的线性快捷路径，ArcFlow 将推理轨迹建模为连续动量过程的混合，从而能够捕捉速度演变并形成**连续非线性轨迹**。在 Qwen-Image-20B 和 FLUX.1-dev 上，该方法仅微调 <5% 参数，即实现了 40 倍加速，仅需 2 步推理即可生成高质量图像。\n\n**6. DMamba: Decomposition-enhanced Mamba for Time Series Forecasting**\n(DMamba：基于分解增强的 Mamba 时间序列预测)\n**TLDR:** 针对 Mamba 在非平稳时间序列上的不足，提出了 DMamba。该模型利用序列分解思想，用**可变方向的 Mamba 编码器**处理高维动态的季节性分量（Seasonal），而用简单的 MLP 处理低维流形的趋势分量（Trend）。这种架构设计在长程时间序列预测上超越了现有的 Mamba 变体和 Transformer 模型。\n\n**7. FlattenGPT: Depth Compression for Transformer with Layer Flattening**\n(FlattenGPT：基于层扁平化的 Transformer 深度压缩)\n**TLDR:** 提出了一种深度压缩方法，通过将两个相邻的 Transformer 块“扁平化”为一个，来减少网络深度并去除冗余参数。与传统的剪枝不同，FlattenGPT 保留了所有块中学习到的知识。实验显示，在 LLaMA-2/3 等模型上，压缩比达到 20% 时仍能保持 90-96% 的零样本性能，显著提升了推理速度。\n\n**8. TernaryLM: Memory-Efficient Language Modeling via Native 1-Bit Quantization**\n(TernaryLM：通过原生 1-Bit 量化实现内存高效的语言建模)\n**TLDR:** 挑战极致量化，提出了 TernaryLM，一种在训练期间直接采用原生 **1-bit 三元量化 {-1, 0, +1}** 的 Transformer 架构。通过自适应层级缩放因子，该模型实现了 2.4 倍的内存减少，并在 TinyStories 等数据集上保持了稳定的训练动态和具有竞争力的性能，证明了从头训练极低比特语言模型的可行性。\n\n---\n\n### 🛡️ 安全与对抗\n\n**9. Next-Gen CAPTCHAs: Leveraging the Cognitive Gap for Scalable and Diverse GUI-Agent Defense**\n(下一代验证码：利用认知差距进行可扩展的 GUI Agent 防御)\n**TLDR:** 指出当前的 GUI Agent（如 GPT-5.2-Xhigh）已经能以 90% 的通过率破解传统验证码。为此，作者提出了下一代验证码框架，利用人类与 Agent 之间在交互感知和决策上的**认知差距（Cognitive Gap）**，设计了需要动态直觉而非规划逻辑的任务，旨在为 Agent 时代重建人类用户的区分屏障。\n\n**10. Stateless Yet Not Forgetful: Implicit Memory as a Hidden Channel in LLMs**\n(无状态但这不代表健忘：LLM 中的隐式记忆作为隐藏通道)\n**TLDR:** 揭示了 LLM 的一种新风险：**隐式记忆（Implicit Memory）**。虽然 LLM 被视为无状态的，但它们可以通过将信息编码到输出中，并在后续轮次将这些输出作为输入来“携带”状态。作者展示了这种机制可以构建“时间炸弹”后门，仅在满足一系列特定交互条件后才触发，这对模型安全审计提出了巨大挑战。\n\n---\n\n### 🧬 AI for Science\n\n**11. AntigenLM: Structure-Aware DNA Language Modeling for Influenza**\n(AntigenLM：流感病毒的结构感知 DNA 语言建模)\n**TLDR:** 提出了 AntigenLM，一种在流感基因组上预训练的生成式 DNA 语言模型。关键创新在于**结构感知预训练**，保留了完整的功能单元。该模型在预测流感抗原变异（HA/NA 序列）方面表现优异，甚至能准确预测训练中未见过的未来变异株，超越了传统的系统发育模型。\n\n**12. MSP-LLM: A Unified Large Language Model Framework for Complete Material Synthesis Planning**\n(MSP-LLM：用于完整材料合成规划的统一大语言模型框架)\n**TLDR:** 解决了材料科学中的痛点：材料合成规划（MSP）。该框架将 MSP 分解为**前体预测（Precursor Prediction）**和**合成操作预测（Synthesis Operation Prediction）**两个子问题，并利用 LLM 进行统一建模。通过引入化学一致性的决策链，MSP-LLM 能够有效地设计从原料到目标材料的完整合成路径。\n\n---\n\n### 🤖 其他值得关注的论文\n\n*   **CoRefine (Paper 24):** 提出了一种轻量级的**置信度引导自我修正**机制，无需昂贵的并行解码即可大幅减少推理计算量（token 减少 190 倍）。\n*   **Do We Need Adam? (Paper 274):** 惊人发现：在 LLM 的强化学习（RL）阶段，内存高效的 **SGD** 表现可以匹敌甚至优于 AdamW，且更新极其稀疏（<0.02% 参数）。\n*   **GEBench (Paper 5):** 提出了针对图像生成模型作为 **GUI 环境**的评测基准，发现现有模型在保持 GUI 状态的时序一致性上仍有巨大缺陷。\n*   **Dr. MAS (Paper 43):** 针对多智能体 LLM 系统的 RL 训练不稳定问题，提出了基于 Agent 独立奖励统计归一化的 **Dr. MAS** 算法，显著提升了训练稳定性。",
  "papers": [
    {
      "arxiv_id": "2602.09015v3",
      "title": "CIC-Trap4Phish: A Unified Multi-Format Dataset for Phishing and Quishing Attachment Detection",
      "title_zh": "CIC-Trap4Phish：面向网络钓鱼与二维码钓鱼附件检测的统一多格式数据集",
      "authors": [
        "Fatemeh Nejati",
        "Mahdi Rabbani",
        "Morteza Eskandarian",
        "Mansur Mirani",
        "Gunjan Piya",
        "Igor Opushnyev",
        "Ali A. Ghorbani",
        "Sajjad Dadkhah"
      ],
      "abstract": "Phishing attacks represents one of the primary attack methods which is used by cyber attackers. In many cases, attackers use deceptive emails along with malicious attachments to trick users into giving away sensitive information or installing malware while compromising entire systems. The flexibility of malicious email attachments makes them stand out as a preferred vector for attackers as they can embed harmful content such as malware or malicious URLs inside standard document formats. Although phishing email defenses have improved a lot, attackers continue to abuse attachments, enabling malicious content to bypass security measures. Moreover, another challenge that researches face in training advance models, is lack of an unified and comprehensive dataset that covers the most prevalent data types. To address this gap, we generated CIC-Trap4Phish, a multi-format dataset containing both malicious and benign samples across five categories commonly used in phishing campaigns: Microsoft Word documents, Excel spreadsheets, PDF files, HTML pages, and QR code images. For the first four file types, a set of execution-free static feature pipeline was proposed, designed to capture structural, lexical, and metadata-based indicators without the need to open or execute files. Feature selection was performed using a combination of SHAP analysis and feature importance, yielding compact, discriminative feature subsets for each file type. The selected features were evaluated by using lightweight machine learning models, including Random Forest, XGBoost, and Decision Tree. All models demonstrate high detection accuracy across formats. For QR code-based phishing (quishing), two complementary methods were implemented: image-based detection by employing Convolutional Neural Networks (CNNs) and lexical analysis of decoded URLs using recent lightweight language models.",
      "tldr_zh": "该研究针对网络钓鱼(Phishing)攻击中恶意附件格式多样且缺乏统一数据集的挑战，推出了CIC-Trap4Phish多格式数据集，涵盖Microsoft Word、Excel、PDF、HTML及QR code图像五种常见附件类型。对于文档类附件，研究提出了一套免执行的静态特征管道(static feature pipeline)，通过捕获结构、词汇及元数据特征，并在SHAP分析与特征重要性的基础上筛选出具辨别力的特征子集。实验通过Random Forest、XGBoost和Decision Tree等轻量级机器学习模型验证了该方法在各格式检测中的高准确率。针对二维码钓鱼(Quishing)，研究采用了基于卷积神经网络(CNNs)的图像检测与基于轻量级语言模型的URL词汇分析两种互补策略。该研究不仅填补了钓鱼附件检测领域缺乏统一数据集的空白，还为实现高效、低开销的自动化防御提供了重要参考。",
      "categories": [
        "cs.CR",
        "cs.AI"
      ],
      "primary_category": "cs.CR",
      "comment": "",
      "pdf_url": "https://arxiv.org/pdf/2602.09015v3",
      "published_date": "2026-02-09 18:57:00 UTC",
      "updated_date": "2026-02-11 14:56:48 UTC",
      "processing_status": "completed",
      "attempts": 1,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "llm_backup_calls": 0,
      "last_update": "2026-02-16T04:39:30.598373+00:00"
    },
    {
      "arxiv_id": "2602.09014v1",
      "title": "ArcFlow: Unleashing 2-Step Text-to-Image Generation via High-Precision Non-Linear Flow Distillation",
      "title_zh": "ArcFlow：通过高精度非线性流蒸馏实现两步文本生成图像",
      "authors": [
        "Zihan Yang",
        "Shuyuan Tu",
        "Licheng Zhang",
        "Qi Dai",
        "Yu-Gang Jiang",
        "Zuxuan Wu"
      ],
      "abstract": "Diffusion models have achieved remarkable generation quality, but they suffer from significant inference cost due to their reliance on multiple sequential denoising steps, motivating recent efforts to distill this inference process into a few-step regime. However, existing distillation methods typically approximate the teacher trajectory by using linear shortcuts, which makes it difficult to match its constantly changing tangent directions as velocities evolve across timesteps, thereby leading to quality degradation. To address this limitation, we propose ArcFlow, a few-step distillation framework that explicitly employs non-linear flow trajectories to approximate pre-trained teacher trajectories. Concretely, ArcFlow parameterizes the velocity field underlying the inference trajectory as a mixture of continuous momentum processes. This enables ArcFlow to capture velocity evolution and extrapolate coherent velocities to form a continuous non-linear trajectory within each denoising step. Importantly, this parameterization admits an analytical integration of this non-linear trajectory, which circumvents numerical discretization errors and results in high-precision approximation of the teacher trajectory. To train this parameterization into a few-step generator, we implement ArcFlow via trajectory distillation on pre-trained teacher models using lightweight adapters. This strategy ensures fast, stable convergence while preserving generative diversity and quality. Built on large-scale models (Qwen-Image-20B and FLUX.1-dev), ArcFlow only fine-tunes on less than 5% of original parameters and achieves a 40x speedup with 2 NFEs over the original multi-step teachers without significant quality degradation. Experiments on benchmarks show the effectiveness of ArcFlow both qualitatively and quantitatively.",
      "tldr_zh": "该研究提出了 ArcFlow，一种旨在解决扩散模型推理成本高昂及现有蒸馏方法因线性近似（linear shortcuts）导致图像质量退化的两步文本生成图像框架。ArcFlow 显式采用非线性流轨迹（non-linear flow trajectories）来逼近预训练教师模型的轨迹，通过将速度场（velocity field）参数化为连续动量过程（continuous momentum processes）的混合，实现了对速度演变的精准捕捉。这种参数化设计支持非线性轨迹的解析积分（analytical integration），有效规避了数值离散误差（numerical discretization errors），从而实现了高精度的教师轨迹逼近。研究团队在大规模预训练模型 Qwen-Image-20B 和 FLUX.1-dev 上利用轻量级适配器实施轨迹蒸馏，仅需微调不到 5% 的参数。实验表明，ArcFlow 在仅使用 2 次网络函数评估（NFEs）的情况下实现了 40 倍的推理加速，且在生成质量和多样性上未见显著退化。该方法在多项基准测试中均展现了卓越的定性与定量性能。",
      "categories": [
        "cs.CV",
        "cs.AI"
      ],
      "primary_category": "cs.CV",
      "comment": "",
      "pdf_url": "https://arxiv.org/pdf/2602.09014v1",
      "published_date": "2026-02-09 18:56:14 UTC",
      "updated_date": "2026-02-09 18:56:14 UTC",
      "processing_status": "completed",
      "attempts": 1,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "llm_backup_calls": 0,
      "last_update": "2026-02-16T04:39:42.006271+00:00"
    },
    {
      "arxiv_id": "2602.09012v1",
      "title": "Next-Gen CAPTCHAs: Leveraging the Cognitive Gap for Scalable and Diverse GUI-Agent Defense",
      "title_zh": "下一代 CAPTCHA：利用认知差距构建可扩展且多样化的 GUI 智能体防御体系",
      "authors": [
        "Jiacheng Liu",
        "Yaxin Luo",
        "Jiacheng Cui",
        "Xinyi Shang",
        "Xiaohan Zhao",
        "Zhiqiang Shen"
      ],
      "abstract": "The rapid evolution of GUI-enabled agents has rendered traditional CAPTCHAs obsolete. While previous benchmarks like OpenCaptchaWorld established a baseline for evaluating multimodal agents, recent advancements in reasoning-heavy models, such as Gemini3-Pro-High and GPT-5.2-Xhigh have effectively collapsed this security barrier, achieving pass rates as high as 90% on complex logic puzzles like \"Bingo\". In response, we introduce Next-Gen CAPTCHAs, a scalable defense framework designed to secure the next-generation web against the advanced agents. Unlike static datasets, our benchmark is built upon a robust data generation pipeline, allowing for large-scale and easily scalable evaluations, notably, for backend-supported types, our system is capable of generating effectively unbounded CAPTCHA instances. We exploit the persistent human-agent \"Cognitive Gap\" in interactive perception, memory, decision-making, and action. By engineering dynamic tasks that require adaptive intuition rather than granular planning, we re-establish a robust distinction between biological users and artificial agents, offering a scalable and diverse defense mechanism for the agentic era.",
      "tldr_zh": "该研究针对 GUI-enabled agents 的快速演进导致传统 CAPTCHAs 验证机制失效的问题，提出了 Next-Gen CAPTCHAs 这一可扩展的防御框架。鉴于 Gemini3-Pro-High 和 GPT-5.2-Xhigh 等推理能力极强的模型在复杂逻辑任务中已达到极高通过率，该框架通过构建稳健的 data generation pipeline 实现了验证码实例的大规模动态生成。其核心创新在于利用人类与智能体在交互式感知、记忆、决策及行动中持续存在的“认知鸿沟”(Cognitive Gap)。通过设计强调自适应直觉 (adaptive intuition) 而非细粒度规划的动态任务，该系统重新确立了生物用户与人工智能体之间的稳健区分。该成果为智能体时代 (agentic era) 提供了多样化且具备高扩展性的 Web 安全防御机制。",
      "categories": [
        "cs.LG",
        "cs.AI",
        "cs.CL"
      ],
      "primary_category": "cs.LG",
      "comment": "Project page at https://greenoso.github.io/NextGen-CAPTCHAs_webpage/",
      "pdf_url": "https://arxiv.org/pdf/2602.09012v1",
      "published_date": "2026-02-09 18:55:33 UTC",
      "updated_date": "2026-02-09 18:55:33 UTC",
      "processing_status": "completed",
      "attempts": 1,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "llm_backup_calls": 0,
      "last_update": "2026-02-16T04:39:39.809817+00:00"
    },
    {
      "arxiv_id": "2602.09009v1",
      "title": "ANCRe: Adaptive Neural Connection Reassignment for Efficient Depth Scaling",
      "title_zh": "ANCRe：面向高效深度缩放的自适应神经连接重分配",
      "authors": [
        "Yilang Zhang",
        "Bingcong Li",
        "Niao He",
        "Georgios B. Giannakis"
      ],
      "abstract": "Scaling network depth has been a central driver behind the success of modern foundation models, yet recent investigations suggest that deep layers are often underutilized. This paper revisits the default mechanism for deepening neural networks, namely residual connections, from an optimization perspective. Rigorous analysis proves that the layout of residual connections can fundamentally shape convergence behavior, and even induces an exponential gap in convergence rates. Prompted by this insight, we introduce adaptive neural connection reassignment (ANCRe), a principled and lightweight framework that parameterizes and learns residual connectivities from the data. ANCRe adaptively reassigns residual connections with negligible computational and memory overhead ($<1\\%$), while enabling more effective utilization of network depth. Extensive numerical tests across pre-training of large language models, diffusion models, and deep ResNets demonstrate consistently accelerated convergence, boosted performance, and enhanced depth efficiency over conventional residual connections.",
      "tldr_zh": "该研究针对现代基础模型中深层网络利用率不足的问题，从优化视角重新审视了残差连接(residual connections)这一默认的加深机制。严谨的分析证明，残差连接的布局对收敛行为具有根本性影响，甚至会导致收敛速度出现指数级差距。基于此发现，作者提出了ANCRe (adaptive neural connection reassignment)，这是一种原则性且轻量级的框架，能够通过参数化从数据中学习残差连通性。ANCRe以不足1%的额外计算和内存开销自适应地重新分配残差连接，从而实现了对网络深度的更高效利用。在大语言模型(large language models)预训练、扩散模型(diffusion models)和深层ResNets上的广泛测试显示，该方法一致性地加速了模型收敛并提升了最终性能。研究表明，相比传统残差连接，ANCRe显著增强了深度效率(depth efficiency)，为构建高效深层神经网络提供了理论依据与实践方案。",
      "categories": [
        "cs.LG",
        "cs.AI"
      ],
      "primary_category": "cs.LG",
      "comment": "",
      "pdf_url": "https://arxiv.org/pdf/2602.09009v1",
      "published_date": "2026-02-09 18:54:18 UTC",
      "updated_date": "2026-02-09 18:54:18 UTC",
      "processing_status": "completed",
      "attempts": 1,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "llm_backup_calls": 0,
      "last_update": "2026-02-16T04:39:42.902383+00:00"
    },
    {
      "arxiv_id": "2602.09007v2",
      "title": "GEBench: Benchmarking Image Generation Models as GUI Environments",
      "title_zh": "GEBench：将图像生成模型作为 GUI 环境的评测基准",
      "authors": [
        "Haodong Li",
        "Jingwei Wu",
        "Quan Sun",
        "Guopeng Li",
        "Juanxi Tian",
        "Huanyu Zhang",
        "Yanlin Lai",
        "Ruichuan An",
        "Hongbo Peng",
        "Yuhong Dai",
        "Chenxi Li",
        "Chunmei Qing",
        "Jia Wang",
        "Ziyang Meng",
        "Zheng Ge",
        "Xiangyu Zhang",
        "Daxin Jiang"
      ],
      "abstract": "Recent advancements in image generation models have enabled the prediction of future Graphical User Interface (GUI) states based on user instructions. However, existing benchmarks primarily focus on general domain visual fidelity, leaving the evaluation of state transitions and temporal coherence in GUI-specific contexts underexplored. To address this gap, we introduce GEBench, a comprehensive benchmark for evaluating dynamic interaction and temporal coherence in GUI generation. GEBench comprises 700 carefully curated samples spanning five task categories, covering both single-step interactions and multi-step trajectories across real-world and fictional scenarios, as well as grounding point localization. To support systematic evaluation, we propose GE-Score, a novel five-dimensional metric that assesses Goal Achievement, Interaction Logic, Content Consistency, UI Plausibility, and Visual Quality. Extensive evaluations on current models indicate that while they perform well on single-step transitions, they struggle significantly with maintaining temporal coherence and spatial grounding over longer interaction sequences. Our findings identify icon interpretation, text rendering, and localization precision as critical bottlenecks. This work provides a foundation for systematic assessment and suggests promising directions for future research toward building high-fidelity generative GUI environments. The code is available at: https://github.com/stepfun-ai/GEBench.",
      "tldr_zh": "该研究提出了GEBench，这是一个专门评估图像生成模型在图形用户界面(GUI)环境中动态交互与时间相干性(temporal coherence)的综合基准。GEBench包含700个精心挑选的样本，涵盖五个任务类别，支持对单步交互及多步轨迹的系统性评估。研究者同步提出了GE-Score指标，通过目标达成(Goal Achievement)、交互逻辑(Interaction Logic)、内容一致性(Content Consistency)、UI合理性(UI Plausibility)和视觉质量(Visual Quality)五个维度全面衡量模型性能。评估发现，现有模型虽然能处理单步转换，但在长交互序列中难以维持时间相干性和空间接地(spatial grounding)。该工作识别出图标解读(icon interpretation)、文本渲染(text rendering)和定位精度(localization precision)是限制模型性能的关键瓶颈。GEBench为生成式GUI环境的系统化评估奠定了基础，并为未来构建高保真交互环境的研究方向提供了指引。",
      "categories": [
        "cs.AI",
        "cs.CV"
      ],
      "primary_category": "cs.AI",
      "comment": "23 pages, 5 figures, 4 tables",
      "pdf_url": "https://arxiv.org/pdf/2602.09007v2",
      "published_date": "2026-02-09 18:52:02 UTC",
      "updated_date": "2026-02-10 15:30:57 UTC",
      "processing_status": "completed",
      "attempts": 1,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "llm_backup_calls": 0,
      "last_update": "2026-02-16T04:39:45.703654+00:00"
    },
    {
      "arxiv_id": "2602.09006v1",
      "title": "ARO: A New Lens On Matrix Optimization For Large Models",
      "title_zh": "ARO：大模型矩阵优化的新视角",
      "authors": [
        "Wenbo Gong",
        "Javier Zazo",
        "Qijun Luo",
        "Puqian Wang",
        "James Hensman",
        "Chao Ma"
      ],
      "abstract": "Matrix-based optimizers have attracted growing interest for improving LLM training efficiency, with significant progress centered on orthogonalization/whitening based methods. While yielding substantial performance gains, a fundamental question arises: can we develop new paradigms beyond orthogonalization, pushing the efficiency frontier further? We present \\textbf{Adaptively Rotated Optimization (ARO}, a new matrix optimization framework that treats gradient rotation as a first class design principle. ARO accelerates LLM training by performing normed steepest descent in a rotated coordinate system, where the rotation is determined by a novel norm-informed policy. This perspective yields update rules that go beyond existing orthogonalization and whitening optimizers, improving sample efficiency in practice. To make comparisons reliable, we propose a rigorously controlled benchmarking protocol that reduces confounding and bias. Under this protocol, ARO consistently outperforms AdamW (by 1.3 $\\sim$1.35$\\times$) and orthogonalization methods (by 1.1$\\sim$1.15$\\times$) in LLM pretraining at up to 8B activated parameters, and up to $8\\times$ overtrain budget, without evidence of diminishing returns. Finally, we discuss how ARO can be reformulated as a symmetry-aware optimizer grounded in rotational symmetries of residual streams, motivating advanced designs that enable computationally efficient exploitation of cross-layer/cross module couplings.",
      "tldr_zh": "该研究提出了适应性旋转优化（Adaptively Rotated Optimization, ARO），这是一种全新的矩阵优化框架，将梯度旋转作为核心设计原则。ARO 通过在一个由新型范数感知策略（norm-informed policy）确定的旋转坐标系中执行范数陡峭下降（normed steepest descent），实现了对现有正交化（orthogonalization）和白化（whitening）优化器的超越，显著提升了样本效率。为了确保评估的可靠性，研究者还提出了一套严格控制的基准测试协议，以消除实验偏差。实验结果显示，在拥有多达 8B 激活参数的大语言模型预训练任务中，ARO 的表现持续优于 AdamW（提升 1.3-1.35 倍）和正交化方法（提升 1.1-1.15 倍），且在 8 倍训练预算下未见收益递减。此外，该研究还将 ARO 重新定义为一种基于残差流旋转对称性的对称感知优化器，为高效利用跨层和跨模块耦合的先进设计提供了理论支撑。",
      "categories": [
        "cs.LG",
        "cs.AI",
        "math.OC"
      ],
      "primary_category": "cs.LG",
      "comment": "",
      "pdf_url": "https://arxiv.org/pdf/2602.09006v1",
      "published_date": "2026-02-09 18:51:22 UTC",
      "updated_date": "2026-02-09 18:51:22 UTC",
      "processing_status": "completed",
      "attempts": 1,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "llm_backup_calls": 0,
      "last_update": "2026-02-16T04:40:09.504066+00:00"
    },
    {
      "arxiv_id": "2602.09003v1",
      "title": "Data Science and Technology Towards AGI Part I: Tiered Data Management",
      "title_zh": "面向通用人工智能的数据科学与技术（第一部分）：分层数据管理",
      "authors": [
        "Yudong Wang",
        "Zixuan Fu",
        "Hengyu Zhao",
        "Chen Zhao",
        "Chuyue Zhou",
        "Xinle Lin",
        "Hongya Lyu",
        "Shuaikang Xue",
        "Yi Yi",
        "Yingjiao Wang",
        "Zhi Zheng",
        "Yuzhou Zhang",
        "Jie Zhou",
        "Chaojun Xiao",
        "Xu Han",
        "Zhiyuan Liu",
        "Maosong Sun"
      ],
      "abstract": "The development of artificial intelligence can be viewed as an evolution of data-driven learning paradigms, with successive shifts in data organization and utilization continuously driving advances in model capability. Current LLM research is dominated by a paradigm that relies heavily on unidirectional scaling of data size, increasingly encountering bottlenecks in data availability, acquisition cost, and training efficiency. In this work, we argue that the development of AGI is entering a new phase of data-model co-evolution, in which models actively guide data management while high-quality data, in turn, amplifies model capabilities. To implement this vision, we propose a tiered data management framework, designed to support the full LLM training lifecycle across heterogeneous learning objectives and cost constraints. Specifically, we introduce an L0-L4 tiered data management framework, ranging from raw uncurated resources to organized and verifiable knowledge. Importantly, LLMs are fully used in data management processes, such as quality scoring and content editing, to refine data across tiers. Each tier is characterized by distinct data properties, management strategies, and training roles, enabling data to be strategically allocated across LLM training stages, including pre-training, mid-training, and alignment. The framework balances data quality, acquisition cost, and marginal training benefit, providing a systematic approach to scalable and sustainable data management. We validate the effectiveness of the proposed framework through empirical studies, in which tiered datasets are constructed from raw corpora and used across multiple training phases. Experimental results demonstrate that tier-aware data utilization significantly improves training efficiency and model performance. To facilitate further research, we release our tiered datasets and processing tools to the community.",
      "tldr_zh": "该研究探讨了人工智能向通用人工智能(AGI)演进过程中的数据驱动范式，指出当前大语言模型(LLM)依赖数据规模单向扩张的模式正面临效率与成本瓶颈。为此，论文提出了一个分层数据管理(Tiered Data Management)框架，将数据从原始资源到可验证知识划分为L0至L4五个层级，以支持涵盖预训练(pre-training)、中训练(mid-training)和对齐(alignment)的训练全生命周期。该框架将LLM引入数据管理流程中，用于质量评分和内容编辑以精炼各层级数据，实现了数据与模型的协同演进。实验验证表明，这种分层感知的数据利用策略在平衡数据质量、获取成本与边际训练收益的同时，显著提升了训练效率和模型性能。目前，该研究已向社区发布了分层数据集及处理工具，为实现可扩展且可持续的AGI数据管理提供了系统化路径。",
      "categories": [
        "cs.AI",
        "cs.CL"
      ],
      "primary_category": "cs.AI",
      "comment": "16 pages, 3 figures, 7 tables",
      "pdf_url": "https://arxiv.org/pdf/2602.09003v1",
      "published_date": "2026-02-09 18:47:51 UTC",
      "updated_date": "2026-02-09 18:47:51 UTC",
      "processing_status": "completed",
      "attempts": 1,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "llm_backup_calls": 0,
      "last_update": "2026-02-16T04:40:16.406157+00:00"
    },
    {
      "arxiv_id": "2602.09002v1",
      "title": "From Obstacles to Etiquette: Robot Social Navigation with VLM-Informed Path Selection",
      "title_zh": "从障碍到礼仪：基于 VLM 引导路径选择的机器人社交导航",
      "authors": [
        "Zilin Fang",
        "Anxing Xiao",
        "David Hsu",
        "Gim Hee Lee"
      ],
      "abstract": "Navigating socially in human environments requires more than satisfying geometric constraints, as collision-free paths may still interfere with ongoing activities or conflict with social norms. Addressing this challenge calls for analyzing interactions between agents and incorporating common-sense reasoning into planning. This paper presents a social robot navigation framework that integrates geometric planning with contextual social reasoning. The system first extracts obstacles and human dynamics to generate geometrically feasible candidate paths, then leverages a fine-tuned vision-language model (VLM) to evaluate these paths, informed by contextually grounded social expectations, selecting a socially optimized path for the controller. This task-specific VLM distills social reasoning from large foundation models into a smaller and efficient model, allowing the framework to perform real-time adaptation in diverse human-robot interaction contexts. Experiments in four social navigation contexts demonstrate that our method achieves the best overall performance with the lowest personal space violation duration, the minimal pedestrian-facing time, and no social zone intrusions. Project page: https://path-etiquette.github.io",
      "tldr_zh": "该研究提出了一个集成几何规划与上下文社交推理的机器人社交导航框架，旨在解决碰撞规避路径可能违反社会规范或干扰人类活动的问题。该系统首先通过提取障碍物和人体动力学生成几何可行的候选路径，随后利用经过微调的视觉语言模型 (VLM) 结合上下文社交预期对路径进行评估，从而为控制器选择社交最优路径。该框架采用知识蒸馏技术，将大型基础模型的社交推理能力迁移到轻量化模型中，实现了在多样化人机交互场景下的实时适应。实验结果显示，该方法在四种社交导航语境下均取得了最佳综合性能，显著减少了个人空间侵犯时长和面向行人的时间，并实现了社交区域零入侵。",
      "categories": [
        "cs.RO",
        "cs.AI"
      ],
      "primary_category": "cs.RO",
      "comment": "Accepted to IEEE Robotics and Automation Letters (RA-L)",
      "pdf_url": "https://arxiv.org/pdf/2602.09002v1",
      "published_date": "2026-02-09 18:46:12 UTC",
      "updated_date": "2026-02-09 18:46:12 UTC",
      "processing_status": "completed",
      "attempts": 1,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "llm_backup_calls": 0,
      "last_update": "2026-02-16T04:40:21.603789+00:00"
    },
    {
      "arxiv_id": "2602.09000v1",
      "title": "iGRPO: Self-Feedback-Driven LLM Reasoning",
      "title_zh": "iGRPO：自我反馈驱动的大语言模型推理",
      "authors": [
        "Ali Hatamizadeh",
        "Shrimai Prabhumoye",
        "Igor Gitman",
        "Ximing Lu",
        "Seungju Han",
        "Wei Ping",
        "Yejin Choi",
        "Jan Kautz"
      ],
      "abstract": "Large Language Models (LLMs) have shown promise in solving complex mathematical problems, yet they still fall short of producing accurate and consistent solutions. Reinforcement Learning (RL) is a framework for aligning these models with task-specific rewards, improving overall quality and reliability. Group Relative Policy Optimization (GRPO) is an efficient, value-function-free alternative to Proximal Policy Optimization (PPO) that leverages group-relative reward normalization. We introduce Iterative Group Relative Policy Optimization (iGRPO), a two-stage extension of GRPO that adds dynamic self-conditioning through model-generated drafts. In Stage 1, iGRPO samples multiple exploratory drafts and selects the highest-reward draft using the same scalar reward signal used for optimization. In Stage 2, it appends this best draft to the original prompt and applies a GRPO-style update on draft-conditioned refinements, training the policy to improve beyond its strongest prior attempt. Under matched rollout budgets, iGRPO consistently outperforms GRPO across base models (e.g., Nemotron-H-8B-Base-8K and DeepSeek-R1 Distilled), validating its effectiveness on diverse reasoning benchmarks. Moreover, applying iGRPO to OpenReasoning-Nemotron-7B trained on AceReason-Math achieves new state-of-the-art results of 85.62\\% and 79.64\\% on AIME24 and AIME25, respectively. Ablations further show that the refinement wrapper generalizes beyond GRPO variants, benefits from a generative judge, and alters learning dynamics by delaying entropy collapse. These results underscore the potential of iterative, self-feedback-based RL for advancing verifiable mathematical reasoning.",
      "tldr_zh": "该研究提出了iGRPO（Iterative Group Relative Policy Optimization），这是一种基于自我反馈驱动的大语言模型（LLM）推理增强框架。作为GRPO的扩展，iGRPO通过两个阶段的迭代过程引入了动态自我调节机制。在第一阶段，模型采样多个探索性草稿并利用奖励信号筛选出最优候选，第二阶段则将该最优草稿附加到原始提示中进行草稿条件化微调，训练模型在先前最强尝试的基础上进一步改进。实验结果表明，在相同的计算预算下，iGRPO在多个推理基准测试中持续优于GRPO，并在AIME24和AIME25上分别取得了85.62%和79.64%的领先成绩。消融实验进一步证实该方法能够有效延迟熵崩塌（entropy collapse）并优化学习动态，展现了迭代式强化学习在提升可验证数学推理能力方面的巨大潜力。",
      "categories": [
        "cs.AI"
      ],
      "primary_category": "cs.AI",
      "comment": "Tech report",
      "pdf_url": "https://arxiv.org/pdf/2602.09000v1",
      "published_date": "2026-02-09 18:45:11 UTC",
      "updated_date": "2026-02-09 18:45:11 UTC",
      "processing_status": "completed",
      "attempts": 1,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "llm_backup_calls": 0,
      "last_update": "2026-02-16T04:40:24.814521+00:00"
    },
    {
      "arxiv_id": "2602.09082v1",
      "title": "UI-Venus-1.5 Technical Report",
      "title_zh": "UI-Venus-1.5 技术报告",
      "authors": [
        "Veuns-Team",
        ":",
        "Changlong Gao",
        "Zhangxuan Gu",
        "Yulin Liu",
        "Xinyu Qiu",
        "Shuheng Shen",
        "Yue Wen",
        "Tianyu Xia",
        "Zhenyu Xu",
        "Zhengwen Zeng",
        "Beitong Zhou",
        "Xingran Zhou",
        "Weizhi Chen",
        "Sunhao Dai",
        "Jingya Dou",
        "Yichen Gong",
        "Yuan Guo",
        "Zhenlin Guo",
        "Feng Li",
        "Qian Li",
        "Jinzhen Lin",
        "Yuqi Zhou",
        "Linchao Zhu",
        "Liang Chen",
        "Zhenyu Guo",
        "Changhua Meng",
        "Weiqiang Wang"
      ],
      "abstract": "GUI agents have emerged as a powerful paradigm for automating interactions in digital environments, yet achieving both broad generality and consistently strong task performance remains challenging.In this report, we present UI-Venus-1.5, a unified, end-to-end GUI Agent designed for robust real-world applications.The proposed model family comprises two dense variants (2B and 8B) and one mixture-of-experts variant (30B-A3B) to meet various downstream application scenarios.Compared to our previous version, UI-Venus-1.5 introduces three key technical advances: (1) a comprehensive Mid-Training stage leveraging 10 billion tokens across 30+ datasets to establish foundational GUI semantics; (2) Online Reinforcement Learning with full-trajectory rollouts, aligning training objectives with long-horizon, dynamic navigation in large-scale environments; and (3) a single unified GUI Agent constructed via Model Merging, which synthesizes domain-specific models (grounding, web, and mobile) into one cohesive checkpoint. Extensive evaluations demonstrate that UI-Venus-1.5 establishes new state-of-the-art performance on benchmarks such as ScreenSpot-Pro (69.6%), VenusBench-GD (75.0%), and AndroidWorld (77.6%), significantly outperforming previous strong baselines. In addition, UI-Venus-1.5 demonstrates robust navigation capabilities across a variety of Chinese mobile apps, effectively executing user instructions in real-world scenarios. Code: https://github.com/inclusionAI/UI-Venus; Model: https://huggingface.co/collections/inclusionAI/ui-venus",
      "tldr_zh": "该技术报告介绍了 UI-Venus-1.5，一个旨在解决 GUI Agent 泛化性与性能挑战的统一端到端框架。该模型家族包含 2B、8B 密集型及 30B-A3B 混合专家 (Mixture-of-Experts) 变体，通过 100 亿 Token 的大规模中段训练 (Mid-Training) 建立了坚实的 GUI 语义基础。研究团队引入了全轨迹在线强化学习 (Online Reinforcement Learning) 以优化长程动态导航，并利用模型融合 (Model Merging) 技术将定位 (Grounding)、Web 和移动端模型整合为统一架构。评估结果显示，UI-Venus-1.5 在 ScreenSpot-Pro、VenusBench-GD 和 AndroidWorld 等多个基准测试中均达到了当前最顶尖水平 (SOTA)。此外，该模型在处理中文移动应用环境中的复杂用户指令时表现出卓越的鲁棒性，为现实场景下的自动化交互提供了强力支持。",
      "categories": [
        "cs.CV",
        "cs.AI",
        "cs.CL",
        "cs.LG"
      ],
      "primary_category": "cs.CV",
      "comment": "",
      "pdf_url": "https://arxiv.org/pdf/2602.09082v1",
      "published_date": "2026-02-09 18:43:40 UTC",
      "updated_date": "2026-02-09 18:43:40 UTC",
      "processing_status": "completed",
      "attempts": 1,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "llm_backup_calls": 0,
      "last_update": "2026-02-16T04:40:28.904161+00:00"
    },
    {
      "arxiv_id": "2602.09081v1",
      "title": "DMamba: Decomposition-enhanced Mamba for Time Series Forecasting",
      "title_zh": "DMamba：面向时间序列预测的分解增强型 Mamba",
      "authors": [
        "Ruxuan Chen",
        "Fang Sun"
      ],
      "abstract": "State Space Models (SSMs), particularly Mamba, have shown potential in long-term time series forecasting. However, existing Mamba-based architectures often struggle with datasets characterized by non-stationary patterns. A key observation from time series theory is that the statistical nature of inter-variable relationships differs fundamentally between the trend and seasonal components of a decomposed series. Trend relationships are often driven by a few common stochastic factors or long-run equilibria, suggesting that they reside on a lower-dimensional manifold. In contrast, seasonal relationships involve dynamic, high-dimensional interactions like phase shifts and amplitude co-movements, requiring more expressive modeling. In this paper, we propose DMamba, a novel forecasting model that explicitly aligns architectural complexity with this component-specific characteristic. DMamba employs seasonal-trend decomposition and processes the components with specialized, differentially complex modules: a variable-direction Mamba encoder captures the rich, cross-variable dynamics within the seasonal component, while a simple Multi-Layer Perceptron (MLP) suffices to learn from the lower-dimensional inter-variable relationships in the trend component. Extensive experiments on diverse datasets demonstrate that DMamba sets a new state-of-the-art (SOTA), consistently outperforming both recent Mamba-based architectures and leading decomposition-based models.",
      "tldr_zh": "该研究提出了 DMamba，旨在解决现有 Mamba 架构在处理非平稳时间序列数据时的局限性。DMamba 基于时间序列理论中 trend 和 seasonal 成分具有不同统计特性的关键观察，采用了 seasonal-trend decomposition 技术。模型针对不同成分设计了差异化的处理模块：利用高复杂度的 variable-direction Mamba encoder 捕捉 seasonal 成分中丰富且高维的跨变量动态，而使用简单的 Multi-Layer Perceptron (MLP) 处理 trend 成分中低维的变量间关系。这种架构设计实现了模型复杂性与成分特性的显式对齐，实验证明 DMamba 在多个基准数据集上刷新了 State-of-the-art (SOTA) 纪录，性能显著优于现有的 Mamba 类和基于分解的预测模型。",
      "categories": [
        "cs.LG",
        "cs.AI"
      ],
      "primary_category": "cs.LG",
      "comment": "9 pages, 3 figures, 4 tables",
      "pdf_url": "https://arxiv.org/pdf/2602.09081v1",
      "published_date": "2026-02-09 18:42:10 UTC",
      "updated_date": "2026-02-09 18:42:10 UTC",
      "processing_status": "completed",
      "attempts": 1,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "llm_backup_calls": 0,
      "last_update": "2026-02-16T04:41:09.600335+00:00"
    },
    {
      "arxiv_id": "2602.10150v1",
      "title": "PEST: Physics-Enhanced Swin Transformer for 3D Turbulence Simulation",
      "title_zh": "PEST：用于三维湍流模拟的物理增强型 Swin Transformer",
      "authors": [
        "Yilong Dai",
        "Shengyu Chen",
        "Xiaowei Jia",
        "Peyman Givi",
        "Runlong Yu"
      ],
      "abstract": "Accurate simulation of turbulent flows is fundamental to scientific and engineering applications. Direct numerical simulation (DNS) offers the highest fidelity but is computationally prohibitive, while existing data-driven alternatives struggle with stable long-horizon rollouts, physical consistency, and faithful simulation of small-scale structures. These challenges are particularly acute in three-dimensional (3D) settings, where the cubic growth of spatial degrees of freedom dramatically amplifies computational cost, memory demand, and the difficulty of capturing multi-scale interactions. To address these challenges, we propose a Physics-Enhanced Swin Transformer (PEST) for 3D turbulence simulation. PEST leverages a window-based self-attention mechanism to effectively model localized PDE interactions while maintaining computational efficiency. We introduce a frequency-domain adaptive loss that explicitly emphasizes small-scale structures, enabling more faithful simulation of high-frequency dynamics. To improve physical consistency, we incorporate Navier--Stokes residual constraints and divergence-free regularization directly into the learning objective. Extensive experiments on two representative turbulent flow configurations demonstrate that PEST achieves accurate, physically consistent, and stable autoregressive long-term simulations, outperforming existing data-driven baselines.",
      "tldr_zh": "该研究提出了物理增强的Swin Transformer（PEST），旨在解决三维湍流模拟（3D Turbulence Simulation）中计算成本高、物理一致性差以及难以捕捉小尺度结构等关键挑战。PEST利用基于窗口的自注意力机制（Window-based self-attention）有效建模局部的偏微分方程（PDE）交互，在保持计算效率的同时提升了模拟精度。研究团队引入了频域自适应损失（Frequency-domain adaptive loss）以增强对高频动力学和小尺度结构的捕捉能力。此外，该模型通过将Navier--Stokes残差约束（Navier--Stokes residual constraints）和无散正则化（Divergence-free regularization）整合至学习目标，显著提升了模拟的物理一致性。实验结果证明，PEST在两种代表性湍流配置下实现了稳定且准确的自回归长期模拟，性能明显优于现有的数据驱动基准模型。该方法为处理复杂的、多尺度的三维流体动力学问题提供了一个高效且具有物理约束的深度学习方案。",
      "categories": [
        "physics.flu-dyn",
        "cs.AI",
        "math.AP"
      ],
      "primary_category": "physics.flu-dyn",
      "comment": "",
      "pdf_url": "https://arxiv.org/pdf/2602.10150v1",
      "published_date": "2026-02-09 18:37:18 UTC",
      "updated_date": "2026-02-09 18:37:18 UTC",
      "processing_status": "completed",
      "attempts": 1,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "llm_backup_calls": 0,
      "last_update": "2026-02-16T04:41:12.307961+00:00"
    },
    {
      "arxiv_id": "2602.10149v1",
      "title": "Exploring Semantic Labeling Strategies for Third-Party Cybersecurity Risk Assessment Questionnaires",
      "title_zh": "探索第三方网络安全风险评估问卷的语义标注策略",
      "authors": [
        "Ali Nour Eldin",
        "Mohamed Sellami",
        "Walid Gaaloul"
      ],
      "abstract": "Third-Party Risk Assessment (TPRA) is a core cybersecurity practice for evaluating suppliers against standards such as ISO/IEC 27001 and NIST. TPRA questionnaires are typically drawn from large repositories of security and compliance questions, yet tailoring assessments to organizational needs remains a largely manual process. Existing retrieval approaches rely on keyword or surface-level similarity, which often fails to capture implicit assessment scope and control semantics.\n  This paper explores strategies for organizing and retrieving TPRA cybersecurity questions using semantic labels that describe both control domains and assessment scope. We compare direct question-level labeling with a Large Language Model (LLM) against a hybrid semi-supervised semantic labeling (SSSL) pipeline that clusters questions in embedding space, labels a small representative subset using an LLM, and propagates labels to remaining questions using k-Nearest Neighbors; we also compare downstream retrieval based on direct question similarity versus retrieval in the label space. We find that semantic labels can improve retrieval alignment when labels are discriminative and consistent, and that SSSL can generalize labels from a small labeled subset to large repositories while substantially reducing LLM usage and cost.",
      "tldr_zh": "该研究针对第三方风险评估(Third-Party Risk Assessment, TPRA)中网络安全问卷定制高度依赖人工、现有关键词检索难以捕捉隐含语义等问题，探索了利用语义标签组织和检索 TPRA 问题的策略。作者对比了直接使用大语言模型(Large Language Model, LLM)进行标注与一种混合半监督语义标注(Semi-Supervised Semantic Labeling, SSSL)流水线的效能。该 SSSL 流程在嵌入空间对问题进行聚类，仅用 LLM 标注少量代表性子集，再通过 k-最近邻(k-Nearest Neighbors, k-NN)算法将标签传播至全库。实验结果表明，具有区分度和一致性的语义标签能显著提升检索对齐度，且 SSSL 方法能在保持性能的同时大幅降低 LLM 的使用成本。该研究证明了语义标签在改善检索对齐方面的潜力，并为大规模安全合规问题的自动化管理提供了高效且经济的解决方案。",
      "categories": [
        "cs.CR",
        "cs.AI"
      ],
      "primary_category": "cs.CR",
      "comment": "",
      "pdf_url": "https://arxiv.org/pdf/2602.10149v1",
      "published_date": "2026-02-09 18:36:50 UTC",
      "updated_date": "2026-02-09 18:36:50 UTC",
      "processing_status": "completed",
      "attempts": 1,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "llm_backup_calls": 0,
      "last_update": "2026-02-16T04:41:13.309771+00:00"
    },
    {
      "arxiv_id": "2602.08990v1",
      "title": "InternAgent-1.5: A Unified Agentic Framework for Long-Horizon Autonomous Scientific Discovery",
      "title_zh": "InternAgent-1.5：面向长程自主科学发现的统一智能体框架",
      "authors": [
        "Shiyang Feng",
        "Runmin Ma",
        "Xiangchao Yan",
        "Yue Fan",
        "Yusong Hu",
        "Songtao Huang",
        "Shuaiyu Zhang",
        "Zongsheng Cao",
        "Tianshuo Peng",
        "Jiakang Yuan",
        "Zijie Guo",
        "Zhijie Zhong",
        "Shangheng Du",
        "Weida Wang",
        "Jinxin Shi",
        "Yuhao Zhou",
        "Xiaohan He",
        "Zhiyin Yu",
        "Fangchen Yu",
        "Qihao Zheng",
        "Jiamin Wu",
        "Mianxin Liu",
        "Chi Zhang",
        "Shaowei Hou",
        "Shuya Li",
        "Yankai Jiang",
        "Wenjie Lou",
        "Lilong Wang",
        "Zifu Wang",
        "Jiong Wang",
        "Wanghan Xu",
        "Yue Deng",
        "Dongrui Liu",
        "Yiheng Wang",
        "Wenlong Zhang",
        "Fenghua Ling",
        "Shufei Zhang",
        "Xiaosong Wang",
        "Shuangjia Zheng",
        "Xun Huang",
        "Siqi Sun",
        "Shuyue Hu",
        "Peng Ye",
        "Chunfeng Song",
        "Bin Wang",
        "Conghui He",
        "Yihao Liu",
        "Xin Li",
        "Qibin Hou",
        "Tao Chen",
        "Xiangyu Yue",
        "Bin Wang",
        "Liang He",
        "Dahua Lin",
        "Bowen Zhou",
        "Bo Zhang",
        "Lei Bai"
      ],
      "abstract": "We introduce InternAgent-1.5, a unified system designed for end-to-end scientific discovery across computational and empirical domains. The system is built on a structured architecture composed of three coordinated subsystems for generation, verification, and evolution. These subsystems are supported by foundational capabilities for deep research, solution optimization, and long horizon memory. The architecture allows InternAgent-1.5 to operate continuously across extended discovery cycles while maintaining coherent and improving behavior. It also enables the system to coordinate computational modeling and laboratory experimentation within a single unified system. We evaluate InternAgent-1.5 on scientific reasoning benchmarks such as GAIA, HLE, GPQA, and FrontierScience, and the system achieves leading performance that demonstrates strong foundational capabilities. Beyond these benchmarks, we further assess two categories of discovery tasks. In algorithm discovery tasks, InternAgent-1.5 autonomously designs competitive methods for core machine learning problems. In empirical discovery tasks, it executes complete computational or wet lab experiments and produces scientific findings in earth, life, biological, and physical domains. Overall, these results show that InternAgent-1.5 provides a general and scalable framework for autonomous scientific discovery.",
      "tldr_zh": "该研究推出了InternAgent-1.5，这是一个专为跨计算和经验领域进行端到端科学发现而设计的统一Agent框架。该系统基于生成(generation)、验证(verification)和进化(evolution)三个子系统的协调架构，并由深度研究、方案优化和长程记忆(long horizon memory)等核心能力提供支持。这种架构使InternAgent-1.5能够在长周期的发现过程中保持行为的一致性与持续进化，并实现计算建模与实验室实验的统一协调。在GAIA、HLE、GPQA及FrontierScience等基准测试中，该系统取得了领先的性能表现，证明了其强大的科研基础能力。此外，它在自主算法设计以及涵盖地球、生命、物理等领域的经验发现任务中均展现出卓越成效，能够独立完成从计算模拟到湿实验(wet lab experiments)的全流程。总体而言，InternAgent-1.5为通向自主科学发现提供了一个通用且具备扩展性的系统框架。",
      "categories": [
        "cs.AI"
      ],
      "primary_category": "cs.AI",
      "comment": "Code and project page: https://github.com/InternScience/InternAgent",
      "pdf_url": "https://arxiv.org/pdf/2602.08990v1",
      "published_date": "2026-02-09 18:36:06 UTC",
      "updated_date": "2026-02-09 18:36:06 UTC",
      "processing_status": "completed",
      "attempts": 1,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "llm_backup_calls": 0,
      "last_update": "2026-02-16T04:41:24.605574+00:00"
    },
    {
      "arxiv_id": "2602.08986v1",
      "title": "Improving Detection of Rare Nodes in Hierarchical Multi-Label Learning",
      "title_zh": "提升层次化多标签学习中的稀有节点检测",
      "authors": [
        "Isaac Xu",
        "Martin Gillis",
        "Ayushi Sharma",
        "Benjamin Misiuk",
        "Craig J. Brown",
        "Thomas Trappenberg"
      ],
      "abstract": "In hierarchical multi-label classification, a persistent challenge is enabling model predictions to reach deeper levels of the hierarchy for more detailed or fine-grained classifications. This difficulty partly arises from the natural rarity of certain classes (or hierarchical nodes) and the hierarchical constraint that ensures child nodes are almost always less frequent than their parents. To address this, we propose a weighted loss objective for neural networks that combines node-wise imbalance weighting with focal weighting components, the latter leveraging modern quantification of ensemble uncertainties. By emphasizing rare nodes rather than rare observations (data points), and focusing on uncertain nodes for each model output distribution during training, we observe improvements in recall by up to a factor of five on benchmark datasets, along with statistically significant gains in $F_{1}$ score. We also show our approach aids convolutional networks on challenging tasks, as in situations with suboptimal encoders or limited data.",
      "tldr_zh": "该研究针对层次多标签分类 (hierarchical multi-label classification) 中模型难以预测深层精细化节点的问题，指出这主要源于深层节点的天然稀缺性以及子节点频率必然低于父节点的层次约束。为此，作者提出了一种结合节点级不平衡权重 (node-wise imbalance weighting) 与焦点加权组件 (focal weighting components) 的神经网络加权损失目标函数。该方法利用集成不确定性 (ensemble uncertainties) 的量化手段，使模型在训练过程中更加关注每个输出分布中的不确定节点，并强调稀有节点而非仅仅是稀有观测数据。实验结果显示，该方法在基准数据集上将召回率 (recall) 提升了高达五倍，并使 $F_{1}$ 分数取得了显著增长。此外，研究还证明该方法在次优编码器或有限数据等挑战性任务中，能显著增强卷积网络 (convolutional networks) 的性能。",
      "categories": [
        "cs.LG",
        "cs.AI"
      ],
      "primary_category": "cs.LG",
      "comment": "Accepted for publication in Transactions on Machine Learning Research (TMLR), 2026",
      "pdf_url": "https://arxiv.org/pdf/2602.08986v1",
      "published_date": "2026-02-09 18:34:17 UTC",
      "updated_date": "2026-02-09 18:34:17 UTC",
      "processing_status": "completed",
      "attempts": 1,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "llm_backup_calls": 0,
      "last_update": "2026-02-16T04:42:16.798913+00:00"
    },
    {
      "arxiv_id": "2602.08984v1",
      "title": "Next Concept Prediction in Discrete Latent Space Leads to Stronger Language Models",
      "title_zh": "离散潜空间下的下一概念预测助力构建更强大的语言模型",
      "authors": [
        "Yuliang Liu",
        "Yunchong Song",
        "Yixuan Wang",
        "Kewen Ge",
        "Alex Lamb",
        "Qipeng Guo",
        "Kai Chen",
        "Bowen Zhou",
        "Zhouhan Lin"
      ],
      "abstract": "We propose Next Concept Prediction (NCP), a generative pretraining paradigm built on top of Next Token Prediction (NTP). NCP predicts discrete concepts that span multiple tokens, thereby forming a more challenging pretraining objective. Our model, ConceptLM, quantizes hidden states using Vector Quantization and constructs a concept vocabulary. It leverages both NCP and NTP to drive parameter updates and generates a concept to guide the generation of the following tokens. We train ConceptLM from scratch at scales ranging from 70M to 1.5B parameters with up to 300B training data, including Pythia and GPT-2 backbones. Results on 13 benchmarks show that NCP yields consistent performance gains over traditional token-level models. Furthermore, continual pretraining experiments on an 8B-parameter Llama model indicate that NCP can further improve an NTP-trained model. Our analysis suggests that NCP leads to more powerful language models by introducing a harder pretraining task, providing a promising path toward better language modeling.",
      "tldr_zh": "该研究提出了Next Concept Prediction (NCP)，这是一种建立在传统Next Token Prediction (NTP)之上的生成式预训练范式。通过构建ConceptLM模型，该方法利用向量量化(Vector Quantization)技术将隐藏状态离散化，从而建立起一套覆盖多个Token的离散“概念词典”。在训练过程中，ConceptLM同时结合NCP和NTP进行参数更新，并生成高层级的Concept来引导后续Token的生成。研究团队在70M到1.5B参数规模以及300B训练数据上进行了实验，结果显示NCP在13项基准测试中均取得了优于传统Token级模型的性能表现。针对8B参数Llama模型的持续预训练(Continual Pretraining)实验进一步证实，NCP能够有效提升已有的NTP预训练模型。该分析表明，通过引入更具挑战性的预训练任务，NCP为构建更强大的语言模型提供了一条极具前景的技术路径。",
      "categories": [
        "cs.CL",
        "cs.AI"
      ],
      "primary_category": "cs.CL",
      "comment": "",
      "pdf_url": "https://arxiv.org/pdf/2602.08984v1",
      "published_date": "2026-02-09 18:33:31 UTC",
      "updated_date": "2026-02-09 18:33:31 UTC",
      "processing_status": "completed",
      "attempts": 1,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "llm_backup_calls": 0,
      "last_update": "2026-02-16T04:42:01.206922+00:00"
    },
    {
      "arxiv_id": "2602.10148v1",
      "title": "Red-teaming the Multimodal Reasoning: Jailbreaking Vision-Language Models via Cross-modal Entanglement Attacks",
      "title_zh": "对多模态推理的红队评估：基于跨模态纠缠攻击的视觉语言模型越狱",
      "authors": [
        "Yu Yan",
        "Sheng Sun",
        "Shengjia Cheng",
        "Teli Liu",
        "Mingfeng Li",
        "Min Liu"
      ],
      "abstract": "Vision-Language Models (VLMs) with multimodal reasoning capabilities are high-value attack targets, given their potential for handling complex multimodal harmful tasks. Mainstream black-box jailbreak attacks on VLMs work by distributing malicious clues across modalities to disperse model attention and bypass safety alignment mechanisms. However, these adversarial attacks rely on simple and fixed image-text combinations that lack attack complexity scalability, limiting their effectiveness for red-teaming VLMs' continuously evolving reasoning capabilities. We propose \\textbf{CrossTALK} (\\textbf{\\underline{Cross}}-modal en\\textbf{\\underline{TA}}ng\\textbf{\\underline{L}}ement attac\\textbf{\\underline{K}}), which is a scalable approach that extends and entangles information clues across modalities to exceed VLMs' trained and generalized safety alignment patterns for jailbreak. Specifically, {knowledge-scalable reframing} extends harmful tasks into multi-hop chain instructions, {cross-modal clue entangling} migrates visualizable entities into images to build multimodal reasoning links, and {cross-modal scenario nesting} uses multimodal contextual instructions to steer VLMs toward detailed harmful outputs. Experiments show our COMET achieves state-of-the-art attack success rate.",
      "tldr_zh": "该研究针对多模态大模型(Vision-Language Models, VLMs)在处理复杂有害任务时的安全对齐机制，指出当前黑盒越狱攻击(black-box jailbreak attacks)因缺乏复杂度可扩展性而难以对抗持续进化的模型推理能力。为此，作者提出了CrossTALK（Cross-modal entanglement attack），这是一种通过在多模态间扩展和交织信息线索来突破安全防御的可扩展方法。该框架利用知识可扩展重构(knowledge-scalable reframing)将有害任务转化为多跳链式指令，并通过跨模态线索交织(cross-modal clue entangling)将视觉实体嵌入图像以构建多模态推理链路。此外，跨模态场景嵌套(cross-modal scenario nesting)通过多模态上下文指令引导模型生成详细的有害输出。实验证明，该方法在红队测试(red-teaming)中取得了最先进的攻击成功率(state-of-the-art attack success rate)，揭示了现有VLMs在应对复杂跨模态推理攻击时的脆弱性。",
      "categories": [
        "cs.CR",
        "cs.AI"
      ],
      "primary_category": "cs.CR",
      "comment": "",
      "pdf_url": "https://arxiv.org/pdf/2602.10148v1",
      "published_date": "2026-02-09 18:31:25 UTC",
      "updated_date": "2026-02-09 18:31:25 UTC",
      "processing_status": "completed",
      "attempts": 1,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "llm_backup_calls": 0,
      "last_update": "2026-02-16T04:42:06.208745+00:00"
    },
    {
      "arxiv_id": "2602.08983v1",
      "title": "StretchTime: Adaptive Time Series Forecasting via Symplectic Attention",
      "title_zh": "StretchTime：基于辛注意力的自适应时间序列预测",
      "authors": [
        "Yubin Kim",
        "Viresh Pati",
        "Jevon Twitty",
        "Vinh Pham",
        "Shihao Yang",
        "Jiecheng Lu"
      ],
      "abstract": "Transformer architectures have established strong baselines in time series forecasting, yet they typically rely on positional encodings that assume uniform, index-based temporal progression. However, real-world systems, from shifting financial cycles to elastic biological rhythms, frequently exhibit \"time-warped\" dynamics where the effective flow of time decouples from the sampling index. In this work, we first formalize this misalignment and prove that rotary position embedding (RoPE) is mathematically incapable of representing non-affine temporal warping. To address this, we propose Symplectic Positional Embeddings (SyPE), a learnable encoding framework derived from Hamiltonian mechanics. SyPE strictly generalizes RoPE by extending the rotation group $\\mathrm{SO}(2)$ to the symplectic group $\\mathrm{Sp}(2,\\mathbb{R})$, modulated by a novel input-dependent adaptive warp module. By allowing the attention mechanism to adaptively dilate or contract temporal coordinates end-to-end, our approach captures locally varying periodicities without requiring pre-defined warping functions. We implement this mechanism in StretchTime, a multivariate forecasting architecture that achieves state-of-the-art performance on standard benchmarks, demonstrating superior robustness on datasets exhibiting non-stationary temporal dynamics.",
      "tldr_zh": "该研究针对时间序列预测中 Transformer 架构依赖均匀位置编码而无法处理“时间扭曲” (time-warped) 动态的问题进行了探讨。作者首先在数学上证明了旋转位置嵌入 (RoPE) 无法有效表示非仿射的时间扭曲现象。为此，他们提出了一种源自哈密顿力学 (Hamiltonian mechanics) 的可学习编码框架——辛位置嵌入 (Symplectic Positional Embeddings, SyPE)。SyPE 通过将旋转群 $SO(2)$ 扩展为辛群 $Sp(2, \\mathbb{R})$，并结合新型自适应扭曲模块，实现了对 RoPE 的推广。这种方法允许注意力机制端到端地调节时间坐标的扩张或收缩，从而在无需预定义函数的情况下捕捉局部变化的周期性。基于该机制构建的 StretchTime 架构在多个标准基准测试中取得了最先进 (SOTA) 的性能。实验结果表明，该方法在处理具有非平稳时间动态的数据集时具有显著的鲁棒性。",
      "categories": [
        "cs.LG",
        "cs.AI"
      ],
      "primary_category": "cs.LG",
      "comment": "",
      "pdf_url": "https://arxiv.org/pdf/2602.08983v1",
      "published_date": "2026-02-09 18:29:25 UTC",
      "updated_date": "2026-02-09 18:29:25 UTC",
      "processing_status": "completed",
      "attempts": 1,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "llm_backup_calls": 0,
      "last_update": "2026-02-16T04:42:38.206564+00:00"
    },
    {
      "arxiv_id": "2602.08968v1",
      "title": "stable-worldmodel-v1: Reproducible World Modeling Research and Evaluation",
      "title_zh": "stable-worldmodel-v1：可复现的世界建模研究与评估",
      "authors": [
        "Lucas Maes",
        "Quentin Le Lidec",
        "Dan Haramati",
        "Nassim Massaudi",
        "Damien Scieur",
        "Yann LeCun",
        "Randall Balestriero"
      ],
      "abstract": "World Models have emerged as a powerful paradigm for learning compact, predictive representations of environment dynamics, enabling agents to reason, plan, and generalize beyond direct experience. Despite recent interest in World Models, most available implementations remain publication-specific, severely limiting their reusability, increasing the risk of bugs, and reducing evaluation standardization. To mitigate these issues, we introduce stable-worldmodel (SWM), a modular, tested, and documented world-model research ecosystem that provides efficient data-collection tools, standardized environments, planning algorithms, and baseline implementations. In addition, each environment in SWM enables controllable factors of variation, including visual and physical properties, to support robustness and continual learning research. Finally, we demonstrate the utility of SWM by using it to study zero-shot robustness in DINO-WM.",
      "tldr_zh": "该研究推出了stable-worldmodel (SWM)，这是一个旨在解决世界模型(World Models)领域代码重用性低和缺乏标准化评估等问题的研究生态系统。SWM采用了模块化设计，提供经过测试和文档化的代码库，集成了高效的数据采集工具、标准化环境、规划算法(planning algorithms)以及基线模型(baseline implementations)。此外，SWM中的每个环境都支持对视觉和物理等变异因子进行可控调节，为研究模型鲁棒性(robustness)和持续学习(continual learning)提供了有力支持。研究团队通过在SWM中分析DINO-WM的零样本鲁棒性(zero-shot robustness)，展示了该框架在实际科研场景中的实用价值。该系统的发布为促进世界模型研究的可重复性和评估标准化奠定了基础。",
      "categories": [
        "cs.AI"
      ],
      "primary_category": "cs.AI",
      "comment": "",
      "pdf_url": "https://arxiv.org/pdf/2602.08968v1",
      "published_date": "2026-02-09 18:04:22 UTC",
      "updated_date": "2026-02-09 18:04:22 UTC",
      "processing_status": "completed",
      "attempts": 1,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "llm_backup_calls": 0,
      "last_update": "2026-02-16T04:42:19.511951+00:00"
    },
    {
      "arxiv_id": "2602.08964v1",
      "title": "A Behavioural and Representational Evaluation of Goal-Directedness in Language Model Agents",
      "title_zh": "语言模型智能体目标导向性的行为与表征评估",
      "authors": [
        "Raghu Arghal",
        "Fade Chen",
        "Niall Dalton",
        "Evgenii Kortukov",
        "Calum McNamara",
        "Angelos Nalmpantis",
        "Moksh Nirvaan",
        "Gabriele Sarti",
        "Mario Giulianelli"
      ],
      "abstract": "Understanding an agent's goals helps explain and predict its behaviour, yet there is no established methodology for reliably attributing goals to agentic systems. We propose a framework for evaluating goal-directedness that integrates behavioural evaluation with interpretability-based analyses of models' internal representations. As a case study, we examine an LLM agent navigating a 2D grid world toward a goal state. Behaviourally, we evaluate the agent against an optimal policy across varying grid sizes, obstacle densities, and goal structures, finding that performance scales with task difficulty while remaining robust to difficulty-preserving transformations and complex goal structures. We then use probing methods to decode the agent's internal representations of the environment state and its multi-step action plans. We find that the LLM agent non-linearly encodes a coarse spatial map of the environment, preserving approximate task-relevant cues about its position and the goal location; that its actions are broadly consistent with these internal representations; and that reasoning reorganises them, shifting from broader environment structural cues toward information supporting immediate action selection. Our findings support the view that introspective examination is required beyond behavioural evaluations to characterise how agents represent and pursue their objectives.",
      "tldr_zh": "该研究提出了一个结合行为评估与基于可解释性内部表征分析的框架，旨在建立一套可靠的方法论来评估语言模型智能体的目标导向性(Goal-Directedness)。研究人员以在二维网格世界中导航的LLM Agent为案例，通过在不同网格大小、障碍物密度和目标结构下的测试，发现其表现能随任务难度扩展并对复杂目标结构保持鲁棒性。通过探针方法(Probing Methods)解码其内部表征，研究发现智能体非线性地编码了环境的粗略空间图，并保留了关于自身位置和目标位置的任务相关线索。实验进一步证实其行动与内部表征广泛一致，且推理过程会重组这些表征，实现从环境结构信息向支持即时动作选择的信息转变。该研究结果表明，除了行为评估外，还需通过内省检查来刻画智能体如何表征并追求其目标。",
      "categories": [
        "cs.LG",
        "cs.AI",
        "cs.CL",
        "cs.CY"
      ],
      "primary_category": "cs.LG",
      "comment": "",
      "pdf_url": "https://arxiv.org/pdf/2602.08964v1",
      "published_date": "2026-02-09 18:00:28 UTC",
      "updated_date": "2026-02-09 18:00:28 UTC",
      "processing_status": "completed",
      "attempts": 1,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "llm_backup_calls": 0,
      "last_update": "2026-02-16T04:42:31.410972+00:00"
    },
    {
      "arxiv_id": "2602.09080v1",
      "title": "Looping Back to Move Forward: Recursive Transformers for Efficient and Flexible Large Multimodal Models",
      "title_zh": "循环往复，以促前行：面向高效灵活大规模多模态模型的递归 Transformer",
      "authors": [
        "Ruihan Xu",
        "Yuting Gao",
        "Lan Wang",
        "Jianing Li",
        "Weihao Chen",
        "Qingpei Guo",
        "Ming Yang",
        "Shiliang Zhang"
      ],
      "abstract": "Large Multimodal Models (LMMs) have achieved remarkable success in vision-language tasks, yet their vast parameter counts are often underutilized during both training and inference. In this work, we embrace the idea of looping back to move forward: reusing model parameters through recursive refinement to extract stronger multimodal representations without increasing model size. We propose RecursiveVLM, a recursive Transformer architecture tailored for LMMs. Two key innovations enable effective looping: (i) a Recursive Connector that aligns features across recursion steps by fusing intermediate-layer hidden states and applying modality-specific projections, respecting the distinct statistical structures of vision and language tokens; (ii) a Monotonic Recursion Loss that supervises every step and guarantees performance improves monotonically with recursion depth. This design transforms recursion into an on-demand refinement mechanism: delivering strong results with few loops on resource-constrained devices and progressively improving outputs when more computation resources are available. Experiments show consistent gains of +3% over standard Transformers and +7% over vanilla recursive baselines, demonstrating that strategic looping is a powerful path toward efficient, deployment-adaptive LMMs.",
      "tldr_zh": "该研究提出了RecursiveVLM，一种专为大语言多模态模型（LMMs）设计的递归Transformer架构，旨在通过参数重用来提升模型效率和灵活性。核心创新包括一个递归连接器（Recursive Connector），用于融合中间层隐藏状态并进行模态特定的投影，以及一个单调递归损失（Monotonic Recursion Loss），确保性能随递归深度的增加而提升。这种设计使递归成为一种按需细化机制，既能在资源受限的设备上通过少量循环提供结果，也能在计算资源充足时通过增加循环进一步优化输出。实验结果显示，该方法在性能上比标准Transformer提升了3%，比普通的递归基准模型提升了7%，为开发高效且具备部署自适应能力的大多模态模型提供了一条强有力的路径。",
      "categories": [
        "cs.LG",
        "cs.AI"
      ],
      "primary_category": "cs.LG",
      "comment": "This is a primary contribution in the Recursive Vision-Language Models",
      "pdf_url": "https://arxiv.org/pdf/2602.09080v1",
      "published_date": "2026-02-09 17:58:23 UTC",
      "updated_date": "2026-02-09 17:58:23 UTC",
      "processing_status": "completed",
      "attempts": 1,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "llm_backup_calls": 0,
      "last_update": "2026-02-16T04:43:10.799846+00:00"
    },
    {
      "arxiv_id": "2602.08961v1",
      "title": "MotionCrafter: Dense Geometry and Motion Reconstruction with a 4D VAE",
      "title_zh": "MotionCrafter：基于 4D VAE 的稠密几何与运动重建",
      "authors": [
        "Ruijie Zhu",
        "Jiahao Lu",
        "Wenbo Hu",
        "Xiaoguang Han",
        "Jianfei Cai",
        "Ying Shan",
        "Chuanxia Zheng"
      ],
      "abstract": "We introduce MotionCrafter, a video diffusion-based framework that jointly reconstructs 4D geometry and estimates dense motion from a monocular video. The core of our method is a novel joint representation of dense 3D point maps and 3D scene flows in a shared coordinate system, and a novel 4D VAE to effectively learn this representation. Unlike prior work that forces the 3D value and latents to align strictly with RGB VAE latents-despite their fundamentally different distributions-we show that such alignment is unnecessary and leads to suboptimal performance. Instead, we introduce a new data normalization and VAE training strategy that better transfers diffusion priors and greatly improves reconstruction quality. Extensive experiments across multiple datasets demonstrate that MotionCrafter achieves state-of-the-art performance in both geometry reconstruction and dense scene flow estimation, delivering 38.64% and 25.0% improvements in geometry and motion reconstruction, respectively, all without any post-optimization. Project page: https://ruijiezhu94.github.io/MotionCrafter_Page",
      "tldr_zh": "该研究提出了MotionCrafter，这是一个基于视频扩散模型(video diffusion-based)的框架，旨在从单目视频中共同重建4D几何结构并估计密集运动。该方法的核心是在共享坐标系中对密集3D点图(3D point maps)和3D场景流(3D scene flows)进行联合表征，并引入了一种新型的4D VAE来有效学习这种表征。不同于以往强行将3D值与RGB VAE潜变量对齐的研究，MotionCrafter证明了这种对齐并非必要，并通过新的数据归一化和VAE训练策略更好地迁移了扩散先验(diffusion priors)。这种改进显著提升了重建质量，使得模型无需任何后期优化(post-optimization)即可在多个数据集上达到SOTA水平。实验结果表明，该方法在几何重建和运动重建方面分别实现了38.64%和25.0%的性能提升，为高精度4D场景重建提供了强有力的支持。",
      "categories": [
        "cs.CV",
        "cs.AI",
        "cs.CG",
        "cs.LG"
      ],
      "primary_category": "cs.CV",
      "comment": "Project page: https://ruijiezhu94.github.io/MotionCrafter_Page",
      "pdf_url": "https://arxiv.org/pdf/2602.08961v1",
      "published_date": "2026-02-09 17:58:12 UTC",
      "updated_date": "2026-02-09 17:58:12 UTC",
      "processing_status": "completed",
      "attempts": 1,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "llm_backup_calls": 0,
      "last_update": "2026-02-16T04:43:39.201575+00:00"
    },
    {
      "arxiv_id": "2602.08949v1",
      "title": "Digital Twin and Agentic AI for Wild Fire Disaster Management: Intelligent Virtual Situation Room",
      "title_zh": "面向山火灾害管理的数字孪生与智能体 AI：智能虚拟态势室",
      "authors": [
        "Mohammad Morsali",
        "Siavash H. Khajavi"
      ],
      "abstract": "According to the United Nations, wildfire frequency and intensity are projected to increase by approximately 14% by 2030 and 30% by 2050 due to global warming, posing critical threats to life, infrastructure, and ecosystems. Conventional disaster management frameworks rely on static simulations and passive data acquisition, hindering their ability to adapt to arbitrarily evolving wildfire episodes in real-time. To address these limitations, we introduce the Intelligent Virtual Situation Room (IVSR), a bidirectional Digital Twin (DT) platform augmented by autonomous AI agents. The IVSR continuously ingests multisource sensor imagery, weather data, and 3D forest models to create a live virtual replica of the fire environment. A similarity engine powered by AI aligns emerging conditions with a precomputed Disaster Simulation Library, retrieving and calibrating intervention tactics under the watchful eyes of experts. Authorized action-ranging from UAV redeployment to crew reallocation-is cycled back through standardized procedures to the physical layer, completing the loop between response and analysis. We validate IVSR through detailed case-study simulations provided by an industrial partner, demonstrating capabilities in localized incident detection, privacy-preserving playback, collider-based fire-spread projection, and site-specific ML retraining. Our results indicate marked reductions in detection-to-intervention latency and more effective resource coordination versus traditional systems. By uniting real-time bidirectional DTs with agentic AI, IVSR offers a scalable, semi-automated decision-support paradigm for proactive, adaptive wildfire disaster management.",
      "tldr_zh": "该研究针对全球变暖导致的野火频率和强度增加，以及传统灾害管理系统在实时适应性方面的不足，提出了名为Intelligent Virtual Situation Room (IVSR) 的智能虚拟指挥室平台。该平台通过结合双向数字孪生 (Digital Twin, DT) 技术与自主AI智能体 (Agentic AI)，集成了多源传感器图像、天气数据和3D森林模型，构建了火灾环境的实时虚拟副本。IVSR利用AI驱动的相似性引擎将实时状况与预计算的Disaster Simulation Library进行匹配，并在专家监督下检索和校准干预策略。经过授权的行动如UAV部署或人员调配通过标准化程序反馈至物理层，实现了响应与分析之间的闭环。工业合作伙伴提供的案例研究验证了IVSR在局部事件探测、火蔓延预测和机器学习再训练方面的能力。实验结果表明，与传统系统相比，IVSR显著降低了从探测到干预的延迟，并提高了资源协调效率。这一平台为主动、自适应的野火灾害管理提供了一种可扩展且半自动化的决策支持范式。",
      "categories": [
        "cs.AI",
        "cs.SE"
      ],
      "primary_category": "cs.AI",
      "comment": "",
      "pdf_url": "https://arxiv.org/pdf/2602.08949v1",
      "published_date": "2026-02-09 17:44:52 UTC",
      "updated_date": "2026-02-09 17:44:52 UTC",
      "processing_status": "completed",
      "attempts": 1,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "llm_backup_calls": 0,
      "last_update": "2026-02-16T04:43:18.006619+00:00"
    },
    {
      "arxiv_id": "2602.08948v1",
      "title": "CoRefine: Confidence-Guided Self-Refinement for Adaptive Test-Time Compute",
      "title_zh": "CoRefine：面向自适应推理时计算的置信度引导自精炼",
      "authors": [
        "Chen Jin",
        "Ryutaro Tanno",
        "Tom Diethe",
        "Philip Teare"
      ],
      "abstract": "Large Language Models (LLMs) often rely on test-time scaling via parallel decoding (for example, 512 samples) to boost reasoning accuracy, but this incurs substantial compute. We introduce CoRefine, a confidence-guided self-refinement method that achieves competitive accuracy using a fraction of the tokens via a lightweight 211k-parameter Conv1D controller atop a frozen LLM. The controller consumes full-trace confidence to decide whether to halt, re-examine, or try a different approach, enabling targeted self-correction with an average of 2.7 refinement steps per problem and roughly 190-fold token reduction relative to 512-sample baselines. Across diverse reasoning benchmarks and three open-source models, the controller achieves 92.6 percent precision when it confidently halts, indicating that confidence dynamics reliably signal correctness without ground-truth verification. We extend this to CoRefine-Tree, a hybrid sequential-parallel variant that adaptively balances exploration and exploitation, with easy serving integration and verifier compatibility. By treating confidence as a control signal rather than a correctness guarantee, CoRefine provides a modular primitive for scalable reasoning and agentic settings with imperfect verifiers.",
      "tldr_zh": "该研究针对大型语言模型 (LLMs) 在推理阶段因大规模并行解码 (parallel decoding) 带来的高昂计算成本，提出了 CoRefine，这是一种置信度引导的自我细化 (confidence-guided self-refinement) 方法。该方法通过在冻结的 LLM 上添加一个仅有 211k 参数的轻量级 Conv1D 控制器，利用全追踪置信度 (full-trace confidence) 来决定停止、重新检查或尝试新路径，从而实现针对性的自我修正。实验结果显示，CoRefine 平均仅需 2.7 次细化步骤，相比于 512 样本的基线实现了约 190 倍的 Token 缩减，且在控制器停止时的精确度达到 92.6%。此外，研究还推出了混合顺序并行的变体 CoRefine-Tree，通过平衡探索与利用 (exploration and exploitation) 进一步提升性能。置信度在此被视为一种控制信号而非单纯的正确性保证，为在验证器不完善的智能体场景中实现可扩展推理提供了有效的模块化方案。",
      "categories": [
        "cs.AI",
        "cs.CL"
      ],
      "primary_category": "cs.AI",
      "comment": "",
      "pdf_url": "https://arxiv.org/pdf/2602.08948v1",
      "published_date": "2026-02-09 17:44:41 UTC",
      "updated_date": "2026-02-09 17:44:41 UTC",
      "processing_status": "completed",
      "attempts": 1,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "llm_backup_calls": 0,
      "last_update": "2026-02-16T04:43:28.909922+00:00"
    },
    {
      "arxiv_id": "2602.08941v1",
      "title": "pixelLOG: Logging of Online Gameplay for Cognitive Research",
      "title_zh": "pixelLOG：面向认知研究的在线游戏过程日志记录",
      "authors": [
        "Zeyu Lu",
        "Dennis L. Barbour"
      ],
      "abstract": "Traditional cognitive assessments often rely on isolated, output-focused measurements that may fail to capture the complexity of human cognition in naturalistic settings. We present pixelLOG, a high-performance data collection framework for Spigot-based Minecraft servers designed specifically for process-based cognitive research. Unlike existing frameworks tailored only for artificial intelligence agents, pixelLOG also enables human behavioral tracking in multi-player/multi-agent environments. Operating at configurable frequencies up to and exceeding 20 updates per second, the system captures comprehensive behavioral data through a hybrid approach of active state polling and passive event monitoring. By leveraging Spigot's extensible API, pixelLOG facilitates robust session isolation and produces structured JSON outputs integrable with standard analytical pipelines. This framework bridges the gap between decontextualized laboratory assessments and richer, more ecologically valid tasks, enabling high-resolution analysis of cognitive processes as they unfold in complex, virtual environments.",
      "tldr_zh": "该研究推出了 pixelLOG，这是一个为基于 Spigot 的 Minecraft 服务器设计的高性能数据采集框架，专门用于过程性认知研究 (process-based cognitive research)。与仅针对人工智能智能体 (artificial intelligence agents) 设计的现有框架不同，pixelLOG 支持在多玩家及多智能体环境中进行人类行为追踪。该系统通过主动状态轮询 (active state polling) 和被动事件监测 (passive event monitoring) 的混合方法，能够以每秒超过 20 次更新的高频率捕捉全面的行为数据。利用 Spigot 的可扩展 API，pixelLOG 实现了稳健的会话隔离并输出结构化的 JSON 数据，以便与标准分析流程无缝集成。这一框架有效弥合了脱离情境的实验室评估与具有生态效度的任务之间的鸿沟，为在复杂虚拟环境中高分辨率分析认知过程提供了可能。",
      "categories": [
        "cs.HC",
        "cs.AI"
      ],
      "primary_category": "cs.HC",
      "comment": "9 pages, 1 figure",
      "pdf_url": "https://arxiv.org/pdf/2602.08941v1",
      "published_date": "2026-02-09 17:38:55 UTC",
      "updated_date": "2026-02-09 17:38:55 UTC",
      "processing_status": "completed",
      "attempts": 1,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "llm_backup_calls": 0,
      "last_update": "2026-02-16T04:43:34.509004+00:00"
    },
    {
      "arxiv_id": "2602.08939v1",
      "title": "CausalT5K: Diagnosing and Informing Refusal for Trustworthy Causal Reasoning of Skepticism, Sycophancy, Detection-Correction, and Rung Collapse",
      "title_zh": "CausalT5K：针对因果推理中质疑、奉承、检测修正与层级坍塌现象的拒绝行为诊断及优化研究",
      "authors": [
        "Longling Geng",
        "Andy Ouyang",
        "Theodore Wu",
        "Daphne Barretto",
        "Matthew John Hayes",
        "Rachael Cooper",
        "Yuqiao Zeng",
        "Sameer Vijay",
        "Gia Ancone",
        "Ankit Rai",
        "Matthew Wolfman",
        "Patrick Flanagan",
        "Edward Y. Chang"
      ],
      "abstract": "LLM failures in causal reasoning, including sycophancy, rung collapse, and miscalibrated refusal, are well-documented, yet progress on remediation is slow because no benchmark enables systematic diagnosis. We introduce CausalT5K, a diagnostic benchmark of over 5,000 cases across 10 domains that tests three critical capabilities: (1) detecting rung collapse, where models answer interventional queries with associational evidence; (2) resisting sycophantic drift under adversarial pressure; and (3) generating Wise Refusals that specify missing information when evidence is underdetermined. Unlike synthetic benchmarks, CausalT5K embeds causal traps in realistic narratives and decomposes performance into Utility (sensitivity) and Safety (specificity), revealing failure modes invisible to aggregate accuracy. Developed through a rigorous human-machine collaborative pipeline involving 40 domain experts, iterative cross-validation cycles, and composite verification via rule-based, LLM, and human scoring, CausalT5K implements Pearl's Ladder of Causation as research infrastructure. Preliminary experiments reveal a Four-Quadrant Control Landscape where static audit policies universally fail, a finding that demonstrates CausalT5K's value for advancing trustworthy reasoning systems. Repository: https://github.com/genglongling/CausalT5kBench",
      "tldr_zh": "该研究推出了 CausalT5K，一个包含 10 个领域、超过 5,000 个案例的诊断性基准测试，旨在系统化诊断大语言模型（LLMs）在因果推理中的 Sycophancy、Rung Collapse 及误校准拒绝（Miscalibrated Refusal）等故障模式。该基准通过检测模型是否利用关联性证据回答干预性查询、在对抗压力下抵抗顺从漂移，以及在信息不足时生成精准的 Wise Refusals 来评估模型的鲁棒性。与合成基准不同，CausalT5K 将因果陷阱嵌入真实叙事，并将性能分解为效用性（Utility）与安全性（Safety）维度，揭示了综合准确率无法捕捉的失效机制。实验发现，静态审计策略在“四象限控制景观”中普遍失效，证明了该基准在推动 Pearl's Ladder of Causation 理论落地及构建可信因果推理系统方面的关键价值。",
      "categories": [
        "cs.AI"
      ],
      "primary_category": "cs.AI",
      "comment": "17 pages, 20 tables, figures",
      "pdf_url": "https://arxiv.org/pdf/2602.08939v1",
      "published_date": "2026-02-09 17:36:56 UTC",
      "updated_date": "2026-02-09 17:36:56 UTC",
      "processing_status": "completed",
      "attempts": 1,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "llm_backup_calls": 0,
      "last_update": "2026-02-16T04:43:59.111639+00:00"
    },
    {
      "arxiv_id": "2602.08934v1",
      "title": "StealthRL: Reinforcement Learning Paraphrase Attacks for Multi-Detector Evasion of AI-Text Detectors",
      "title_zh": "StealthRL：针对 AI 文本检测器多重规避的强化学习改写攻击",
      "authors": [
        "Suraj Ranganath",
        "Atharv Ramesh"
      ],
      "abstract": "AI-text detectors face a critical robustness challenge: adversarial paraphrasing attacks that preserve semantics while evading detection. We introduce StealthRL, a reinforcement learning framework that stress-tests detector robustness under realistic adversarial conditions. StealthRL trains a paraphrase policy against a multi-detector ensemble using Group Relative Policy Optimization (GRPO) with LoRA adapters on Qwen3-4B, optimizing a composite reward that balances detector evasion with semantic preservation. We evaluate six attack settings (M0-M5) against three detector families (RoBERTa, FastDetectGPT, and Binoculars) at the security-relevant 1% false positive rate operating point. StealthRL achieves near-zero detection (0.001 mean TPR@1%FPR), reduces mean AUROC from 0.74 to 0.27, and attains a 99.9% attack success rate. Critically, attacks transfer to a held-out detector family not seen during training, revealing shared architectural vulnerabilities rather than detector-specific brittleness. We additionally conduct LLM-based quality evaluation via Likert scoring, analyze detector score distributions to explain why evasion succeeds, and provide per-detector AUROC with bootstrap confidence intervals. Our results expose significant robustness gaps in current AI-text detection and establish StealthRL as a principled adversarial evaluation protocol. Code and evaluation pipeline are publicly available at https://github.com/suraj-ranganath/StealthRL.",
      "tldr_zh": "该研究针对AI文本检测器在语义保留的对抗性改写攻击下的鲁棒性挑战，提出了StealthRL这一强化学习框架。StealthRL利用Group Relative Policy Optimization (GRPO) 算法和LoRA适配器在Qwen3-4B模型上进行微调，通过优化包含检测规避与语义保留的综合奖励函数来训练改写策略。研究团队在六种攻击设置下，针对RoBERTa、FastDetectGPT和Binoculars等主流检测器家族，评估了该框架在1%误报率(False Positive Rate)下的表现。实验结果显示，StealthRL实现了99.9%的攻击成功率，将平均真阳性率(TPR@1%FPR)降低至极低的0.001，并将平均AUROC从0.74大幅削减至0.27。关键发现是该攻击具有跨检测器家族的迁移性，能够规避训练过程中未见的检测器，揭示了当前AI文本检测架构中普遍存在的脆弱性。该项研究不仅暴露了当前检测技术在鲁棒性上的显著缺口，还为未来AI文本检测的安全性评估建立了StealthRL这一标准化的对抗性协议。",
      "categories": [
        "cs.LG",
        "cs.AI",
        "cs.CR"
      ],
      "primary_category": "cs.LG",
      "comment": "Expanded version of a workshop submission. Code available",
      "pdf_url": "https://arxiv.org/pdf/2602.08934v1",
      "published_date": "2026-02-09 17:33:46 UTC",
      "updated_date": "2026-02-09 17:33:46 UTC",
      "processing_status": "completed",
      "attempts": 1,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "llm_backup_calls": 0,
      "last_update": "2026-02-16T04:44:08.703923+00:00"
    },
    {
      "arxiv_id": "2602.08917v1",
      "title": "Automatic In-Domain Exemplar Construction and LLM-Based Refinement of Multi-LLM Expansions for Query Expansion",
      "title_zh": "自动领域内示例构建与基于 LLM 的多 LLM 查询扩展精炼",
      "authors": [
        "Minghan Li",
        "Ercong Nie",
        "Siqi Zhao",
        "Tongna Chen",
        "Huiping Huang",
        "Guodong Zhou"
      ],
      "abstract": "Query expansion with large language models is promising but often relies on hand-crafted prompts, manually chosen exemplars, or a single LLM, making it non-scalable and sensitive to domain shift. We present an automated, domain-adaptive QE framework that builds in-domain exemplar pools by harvesting pseudo-relevant passages using a BM25-MonoT5 pipeline. A training-free cluster-based strategy selects diverse demonstrations, yielding strong and stable in-context QE without supervision. To further exploit model complementarity, we introduce a two-LLM ensemble in which two heterogeneous LLMs independently generate expansions and a refinement LLM consolidates them into one coherent expansion. Across TREC DL20, DBPedia, and SciFact, the refined ensemble delivers consistent and statistically significant gains over BM25, Rocchio, zero-shot, and fixed few-shot baselines. The framework offers a reproducible testbed for exemplar selection and multi-LLM generation, and a practical, label-free solution for real-world QE.",
      "tldr_zh": "该研究针对大型语言模型（LLMs）在查询扩展（Query Expansion, QE）中对人工提示和单一模型的依赖问题，提出了一个自动化的领域自适应框架。该框架利用 BM25-MonoT5 流水线自动构建领域内样本池，并采用无需训练的聚类策略（cluster-based strategy）选择多样化的演示样本，实现了稳定且无需监督的上下文扩展。研究进一步引入了多模型集成机制，通过两个异构的 LLMs 独立生成扩展内容，并由一个 Refinement LLM 进行整合优化。在 TREC DL20、DBPedia 和 SciFact 数据集上的实验结果表明，该方法在统计意义上显著优于 BM25、Rocchio、zero-shot 及固定的 few-shot 等基线。该框架为样本选择和多模型协同生成提供了可复现的实验基准，是面向实际应用场景的一种高效、无标注的 QE 解决方案。",
      "categories": [
        "cs.IR",
        "cs.AI"
      ],
      "primary_category": "cs.IR",
      "comment": "",
      "pdf_url": "https://arxiv.org/pdf/2602.08917v1",
      "published_date": "2026-02-09 17:16:39 UTC",
      "updated_date": "2026-02-09 17:16:39 UTC",
      "processing_status": "completed",
      "attempts": 1,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "llm_backup_calls": 0,
      "last_update": "2026-02-16T04:44:14.607054+00:00"
    },
    {
      "arxiv_id": "2602.09078v1",
      "title": "Framework for Integrating Zero Trust in Cloud-Based Endpoint Security for Critical Infrastructure",
      "title_zh": "面向关键基础设施云端终端安全的零信任集成框架",
      "authors": [
        "Shyam Kumar Gajula"
      ],
      "abstract": "Cyber threats have become highly sophisticated, prompting a heightened concern for endpoint security, especially in critical infrastructure, to new heights. A security model, such as Zero Trust Architecture (ZTA), is required to overcome this challenge. ZTA treats every access request as new and assumes no implicit trust. Critical infrastructure like power plants, healthcare systems, financial systems, water supply, and military assets are especially prone to becoming targets for hackers and phishing attacks. This proposes a comprehensive framework for integrating tailored ZTA into organizations that manage sensitive operations. The paper highlights how the ZTA framework can enhance compliance, enabling continuous protection, thereby reducing attack surfaces. This paper aims to address the gap that exists in applying ZTA to endpoint management within cloud environments for critical infrastructure.",
      "tldr_zh": "该研究针对关键基础设施(Critical Infrastructure)面临的高度复杂网络威胁，提出了一个将零信任架构(Zero Trust Architecture, ZTA)整合到云端终端安全(Cloud-Based Endpoint Security)中的综合框架。鉴于电力、医疗和金融等关键系统极易成为网络攻击的目标，该框架通过不再假设任何隐式信任并对每个访问请求进行验证，显著提升了系统的安全性。本文详细探讨了 ZTA 框架如何通过增强合规性、实现持续保护以及减少攻击面(Attack Surfaces)来填补云环境终端管理中的安全空白。该框架为管理敏感业务的组织提供了定制化的集成方案，有效应对了针对终端设备的复杂网络威胁。",
      "categories": [
        "cs.CR",
        "cs.AI",
        "cs.ET",
        "cs.NI"
      ],
      "primary_category": "cs.CR",
      "comment": "12 pages",
      "pdf_url": "https://arxiv.org/pdf/2602.09078v1",
      "published_date": "2026-02-09 17:15:57 UTC",
      "updated_date": "2026-02-09 17:15:57 UTC",
      "processing_status": "completed",
      "attempts": 1,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "llm_backup_calls": 0,
      "last_update": "2026-02-16T04:44:20.308124+00:00"
    },
    {
      "arxiv_id": "2602.08914v1",
      "title": "Gesturing Toward Abstraction: Multimodal Convention Formation in Collaborative Physical Tasks",
      "title_zh": "趋向抽象：协作类物理任务中多模态惯例的形成",
      "authors": [
        "Kiyosu Maeda",
        "William P. McCarthy",
        "Ching-Yi Tsai",
        "Jeffrey Mu",
        "Haoliang Wang",
        "Robert D. Hawkins",
        "Judith E. Fan",
        "Parastoo Abtahi"
      ],
      "abstract": "A quintessential feature of human intelligence is the ability to create ad hoc conventions over time to achieve shared goals efficiently. We investigate how communication strategies evolve through repeated collaboration as people coordinate on shared procedural abstractions. To this end, we conducted an online unimodal study (n = 98) using natural language to probe abstraction hierarchies. In a follow-up lab study (n = 40), we examined how multimodal communication (speech and gestures) changed during physical collaboration. Pairs used augmented reality to isolate their partner's hand and voice; one participant viewed a 3D virtual tower and sent instructions to the other, who built the physical tower. Participants became faster and more accurate by establishing linguistic and gestural abstractions and using cross-modal redundancy to emphasize key changes from previous interactions. Based on these findings, we extend probabilistic models of convention formation to multimodal settings, capturing shifts in modality preferences. Our findings and model provide building blocks for designing convention-aware intelligent agents situated in the physical world.",
      "tldr_zh": "该研究探讨了人类在重复协作中如何通过建立临时惯例(ad hoc conventions)来高效达成共同目标，重点分析了沟通策略在协调共享程序性抽象(procedural abstractions)时的演化过程。研究首先通过在线单模态实验探测抽象层次，随后在增强现实(Augmented Reality)环境下开展实验室研究，观察物理协作中语音与手势的多模态变化。实验结果表明，协作双方通过建立语言和手势抽象，并利用跨模态冗余(cross-modal redundancy)强调交互中的关键变化，显著提升了任务的速度与准确性。基于这些发现，研究者将惯例形成的概率模型扩展至多模态设置(multimodal settings)，捕捉到了模态偏好的动态转变。该研究及模型为设计能够适应物理环境且具备惯例感知能力的智能体(intelligent agents)提供了关键的构建模块。",
      "categories": [
        "cs.HC",
        "cs.AI"
      ],
      "primary_category": "cs.HC",
      "comment": "Accepted at the 2026 CHI Conference on Human Factors in Computing Systems (CHI 2026). 15 pages",
      "pdf_url": "https://arxiv.org/pdf/2602.08914v1",
      "published_date": "2026-02-09 17:13:34 UTC",
      "updated_date": "2026-02-09 17:13:34 UTC",
      "processing_status": "completed",
      "attempts": 1,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "llm_backup_calls": 0,
      "last_update": "2026-02-16T04:44:20.911436+00:00"
    },
    {
      "arxiv_id": "2602.08905v1",
      "title": "Efficient and Stable Reinforcement Learning for Diffusion Language Models",
      "title_zh": "扩散语言模型的高效稳定强化学习",
      "authors": [
        "Jiawei Liu",
        "Xiting Wang",
        "Yuanyuan Zhong",
        "Defu Lian",
        "Yu Yang"
      ],
      "abstract": "Reinforcement Learning (RL) is crucial for unlocking the complex reasoning capabilities of Diffusion-based Large Language Models (dLLMs). However, applying RL to dLLMs faces unique challenges in efficiency and stability. To address these challenges, we propose Spatio-Temporal Pruning (STP), a framework designed to simultaneously improve the efficiency and stability of RL for dLLMs. STP compresses the redundancy in the generative process through: (1) \\textit{spatial pruning}, which constrains the exploration space using static priors; and (2) \\textit{temporal pruning}, which bypasses redundant late-stage refinement steps. Our theoretical analysis demonstrates that STP strictly reduces the variance of the log-likelihood estimation, thereby ensuring more stable policy updates. Extensive experiments demonstrate that STP surpasses state-of-the-art baselines in both efficiency and accuracy. Our code is available at https://github.com/Lolo1222/STP.",
      "tldr_zh": "该研究针对强化学习(Reinforcement Learning, RL)在提升扩散语言模型(Diffusion-based Large Language Models, dLLMs)推理能力时面临的效率与稳定性挑战，提出了Spatio-Temporal Pruning (STP)框架。STP通过空间剪枝(Spatial Pruning)利用静态先验约束探索空间，并通过时间剪枝(Temporal Pruning)跳过冗余的后期精细化步骤，从而有效压缩生成过程中的冗余。理论分析证明，STP通过降低对数似然估计的方差，确保了更稳定的策略更新。实验结果表明，STP在效率和准确性上均超越了现有的最先进基准。该研究为扩散模型的高效强化学习提供了理论支持与实践方案。",
      "categories": [
        "cs.AI"
      ],
      "primary_category": "cs.AI",
      "comment": "13 pages, 3 figures",
      "pdf_url": "https://arxiv.org/pdf/2602.08905v1",
      "published_date": "2026-02-09 17:04:23 UTC",
      "updated_date": "2026-02-09 17:04:23 UTC",
      "processing_status": "completed",
      "attempts": 1,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "llm_backup_calls": 0,
      "last_update": "2026-02-16T04:44:56.103679+00:00"
    },
    {
      "arxiv_id": "2602.08896v1",
      "title": "OmniReview: A Large-scale Benchmark and LLM-enhanced Framework for Realistic Reviewer Recommendation",
      "title_zh": "OmniReview：面向真实审稿人推荐的大规模基准与大语言模型增强框架",
      "authors": [
        "Yehua Huang",
        "Penglei Sun",
        "Zebin Chen",
        "Zhenheng Tang",
        "Xiaowen Chu"
      ],
      "abstract": "Academic peer review remains the cornerstone of scholarly validation, yet the field faces some challenges in data and methods. From the data perspective, existing research is hindered by the scarcity of large-scale, verified benchmarks and oversimplified evaluation metrics that fail to reflect real-world editorial workflows. To bridge this gap, we present OmniReview, a comprehensive dataset constructed by integrating multi-source academic platforms encompassing comprehensive scholarly profiles through the disambiguation pipeline, yielding 202, 756 verified review records. Based on this data, we introduce a three-tier hierarchical evaluaion framework to assess recommendations from recall to precise expert identification. From the method perspective, existing embedding-based approaches suffer from the information bottleneck of semantic compression and limited interpretability. To resolve these method limitations, we propose Profiling Scholars with Multi-gate Mixture-of-Experts (Pro-MMoE), a novel framework that synergizes Large Language Models (LLMs) with Multi-task Learning. Specifically, it utilizes LLM-generated semantic profiles to preserve fine-grained expertise nuances and interpretability, while employing a Task-Adaptive MMoE architecture to dynamically balance conflicting evaluation goals. Comprehensive experiments demonstrate that Pro-MMoE achieves state-of-the-art performance across six of seven metrics, establishing a new benchmark for realistic reviewer recommendation.",
      "tldr_zh": "该研究针对学术同行评审中缺乏大规模基准测试以及现有方法可解释性不足的问题，提出了 OmniReview 数据集和 Pro-MMoE 推荐框架。OmniReview 通过整合多源学术平台并进行消歧处理，构建了包含 202,756 条验证评审记录的大规模数据集，并引入了三层分级评估框架以实现从检索到精确识别的全方位评估。为了解决传统嵌入方法的语义压缩瓶颈，Pro-MMoE 框架将大语言模型 (LLMs) 与多任务学习 (Multi-task Learning) 相结合，利用 LLM 生成的语义剖面保留细粒度的专业知识差异。此外，该框架采用了任务自适应的 MMoE 架构来动态平衡不同的评估目标，确保推荐的准确性与合理性。实验结果表明，Pro-MMoE 在七项评估指标中的六项均达到了先进水平 (SOTA)，为现实场景下的评审专家推荐设立了新的基准。",
      "categories": [
        "cs.IR",
        "cs.AI"
      ],
      "primary_category": "cs.IR",
      "comment": "",
      "pdf_url": "https://arxiv.org/pdf/2602.08896v1",
      "published_date": "2026-02-09 16:57:35 UTC",
      "updated_date": "2026-02-09 16:57:35 UTC",
      "processing_status": "completed",
      "attempts": 1,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "llm_backup_calls": 0,
      "last_update": "2026-02-16T04:44:59.104577+00:00"
    },
    {
      "arxiv_id": "2602.08889v1",
      "title": "Scalable Delphi: Large Language Models for Structured Risk Estimation",
      "title_zh": "Scalable Delphi：面向结构化风险评估的大语言模型",
      "authors": [
        "Tobias Lorenz",
        "Mario Fritz"
      ],
      "abstract": "Quantitative risk assessment in high-stakes domains relies on structured expert elicitation to estimate unobservable properties. The gold standard - the Delphi method - produces calibrated, auditable judgments but requires months of coordination and specialist time, placing rigorous risk assessment out of reach for most applications. We investigate whether Large Language Models (LLMs) can serve as scalable proxies for structured expert elicitation. We propose Scalable Delphi, adapting the classical protocol for LLMs with diverse expert personas, iterative refinement, and rationale sharing. Because target quantities are typically unobservable, we develop an evaluation framework based on necessary conditions: calibration against verifiable proxies, sensitivity to evidence, and alignment with human expert judgment. We evaluate in the domain of AI-augmented cybersecurity risk, using three capability benchmarks and independent human elicitation studies. LLM panels achieve strong correlations with benchmark ground truth (Pearson r=0.87-0.95), improve systematically as evidence is added, and align with human expert panels - in one comparison, closer to a human panel than the two human panels are to each other. This demonstrates that LLM-based elicitation can extend structured expert judgment to settings where traditional methods are infeasible, reducing elicitation time from months to minutes.",
      "tldr_zh": "该项研究提出了 Scalable Delphi，这是一种利用大语言模型（LLMs）进行结构化专家启发（Structured expert elicitation）的框架，旨在解决传统 Delphi method 在高风险领域中耗时久、成本高的问题。该方法通过赋予 LLMs 多样化的专家角色（Expert personas），结合迭代优化和理由共享机制，实现了对不可观测风险量的量化评估。研究者在 AI-augmented cybersecurity 风险领域进行了评估，发现该框架与基准真实值表现出强相关性（Pearson r 达到 0.87-0.95），且随着证据的增加表现出系统性提升。实验结果证明，LLM 面板与人类专家面板高度一致，在某些对比中甚至比不同人类小组之间的共识更接近人类判断。这一成果将结构化专家判断的应用范围扩展到了传统方法难以触及的场景，成功将风险评估的时间从数月缩短至数分钟。",
      "categories": [
        "cs.AI"
      ],
      "primary_category": "cs.AI",
      "comment": "",
      "pdf_url": "https://arxiv.org/pdf/2602.08889v1",
      "published_date": "2026-02-09 16:52:03 UTC",
      "updated_date": "2026-02-09 16:52:03 UTC",
      "processing_status": "completed",
      "attempts": 1,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "llm_backup_calls": 0,
      "last_update": "2026-02-16T04:45:03.303580+00:00"
    },
    {
      "arxiv_id": "2602.08887v1",
      "title": "DeepQuali: Initial results of a study on the use of large language models for assessing the quality of user stories",
      "title_zh": "DeepQuali：利用大语言模型评估用户故事质量的初步研究结果",
      "authors": [
        "Adam Trendowicz",
        "Daniel Seifert",
        "Andreas Jedlitschka",
        "Marcus Ciolkowski",
        "Anton Strahilov"
      ],
      "abstract": "Generative artificial intelligence (GAI), specifically large language models (LLMs), are increasingly used in software engineering, mainly for coding tasks. However, requirements engineering - particularly requirements validation - has seen limited application of GAI. The current focus of using GAI for requirements is on eliciting, transforming, and classifying requirements, not on quality assessment. We propose and evaluate the LLM-based (GPT-4o) approach \"DeepQuali\", for assessing and improving requirements quality in agile software development. We applied it to projects in two small companies, where we compared LLM-based quality assessments with expert judgments. Experts also participated in walkthroughs of the solution, provided feedback, and rated their acceptance of the approach. Experts largely agreed with the LLM's quality assessments, especially regarding overall ratings and explanations. However, they did not always agree with the other experts on detailed ratings, suggesting that expertise and experience may influence judgments. Experts recognized the usefulness of the approach but criticized the lack of integration into their workflow. LLMs show potential in supporting software engineers with the quality assessment and improvement of requirements. The explicit use of quality models and explanatory feedback increases acceptance.",
      "tldr_zh": "该研究针对软件工程中需求验证环节应用生成式人工智能(GAI)较少的问题，提出了名为DeepQuali的基于大语言模型(LLMs，如GPT-4o)的方法，旨在评估和提升敏捷软件开发中的用户故事质量。该方法在两家小型公司的项目中进行了实证研究，通过将LLM生成的质量评估结果与专家判断进行对比，并结合专家反馈评估了该方案的接受度。实验结果显示，专家在整体评分和解释性反馈方面与LLM的评估结果高度一致，证明了LLM在支持需求质量评估方面的显著潜力。虽然专家指出该工具目前缺乏与现有工作流(workflow)的深度集成，但一致认为显式质量模型的使用增强了系统的可信度。该研究为利用LLMs辅助软件工程师进行需求改进提供了实证支持，并强调了解释性反馈在提高自动化工具接受度中的关键作用。",
      "categories": [
        "cs.SE",
        "cs.AI"
      ],
      "primary_category": "cs.SE",
      "comment": "",
      "pdf_url": "https://arxiv.org/pdf/2602.08887v1",
      "published_date": "2026-02-09 16:49:54 UTC",
      "updated_date": "2026-02-09 16:49:54 UTC",
      "processing_status": "completed",
      "attempts": 1,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "llm_backup_calls": 0,
      "last_update": "2026-02-16T04:45:25.406159+00:00"
    },
    {
      "arxiv_id": "2602.08885v3",
      "title": "Breaking the Simplification Bottleneck in Amortized Neural Symbolic Regression",
      "title_zh": "突破摊销式神经符号回归中的简化瓶颈",
      "authors": [
        "Paul Saegert",
        "Ullrich Köthe"
      ],
      "abstract": "Symbolic regression (SR) aims to discover interpretable analytical expressions that accurately describe observed data. Amortized SR promises to be much more efficient than the predominant genetic programming SR methods, but currently struggles to scale to realistic scientific complexity. We find that a key obstacle is the lack of a fast reduction of equivalent expressions to a concise normalized form. Amortized SR has addressed this by general-purpose Computer Algebra Systems (CAS) like SymPy, but the high computational cost severely limits training and inference speed. We propose SimpliPy, a rule-based simplification engine achieving a 100-fold speed-up over SymPy at comparable quality. This enables substantial improvements in amortized SR, including scalability to much larger training sets, more efficient use of the per-expression token budget, and systematic training set decontamination with respect to equivalent test expressions. We demonstrate these advantages in our Flash-ANSR framework, which achieves much better accuracy than amortized baselines (NeSymReS, E2E) on the FastSRB benchmark. Moreover, it performs on par with state-of-the-art direct optimization (PySR) while recovering more concise instead of more complex expressions with increasing inference budget.",
      "tldr_zh": "该研究针对分摊神经符号回归 (Amortized Neural Symbolic Regression) 在处理现实科学复杂性时的瓶颈，指出缺乏快速将等效表达式简化为规范形式的方法是其扩展的主要障碍。目前常用的通用计算机代数系统 (CAS) 如 SymPy 计算成本过高，严重限制了模型的训练和推理速度。为此，作者提出了 SimpliPy，这是一种基于规则的简化引擎，在保持同等质量的前提下实现了比 SymPy 快 100 倍的简化速度。这种速度提升使得分摊符号回归 (Amortized SR) 能够扩展到更大规模的训练集，更高效地利用每个表达式的 Token 预算，并能系统性地清理训练集中的等效表达式。该研究在 Flash-ANSR 框架中展示了这些优势，其在 FastSRB 基准测试上的准确率显著优于 NeSymReS 和 E2E 等分摊式基准模型。实验结果表明，Flash-ANSR 的性能与最先进的直接优化方法 PySR 相当，且随着推理预算的增加，它能恢复出更简洁而非更复杂的表达式。",
      "categories": [
        "cs.LG",
        "cs.AI",
        "cs.SC"
      ],
      "primary_category": "cs.LG",
      "comment": "main text: 8 pages, 7 figures; appendix: 12 pages, 11 figures; code available at https://github.com/psaegert/simplipy and https://github.com/psaegert/flash-ansr; v2: Fixed rendering artifact in Figure 7; v3: Fixed Figure 3 title and formula",
      "pdf_url": "https://arxiv.org/pdf/2602.08885v3",
      "published_date": "2026-02-09 16:47:00 UTC",
      "updated_date": "2026-02-11 16:18:37 UTC",
      "processing_status": "completed",
      "attempts": 1,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "llm_backup_calls": 0,
      "last_update": "2026-02-16T04:45:23.130015+00:00"
    },
    {
      "arxiv_id": "2602.08878v1",
      "title": "Learning Potentials for Dynamic Matching and Application to Heart Transplantation",
      "title_zh": "动态匹配中的位势学习及其在心脏移植中的应用",
      "authors": [
        "Itai Zilberstein",
        "Ioannis Anagnostides",
        "Zachary W. Sollie",
        "Arman Kilic",
        "Tuomas Sandholm"
      ],
      "abstract": "Each year, thousands of patients in need of heart transplants face life-threatening wait times due to organ scarcity. While allocation policies aim to maximize population-level outcomes, current approaches often fail to account for the dynamic arrival of organs and the composition of waitlisted candidates, thereby hampering efficiency. The United States is transitioning from rigid, rule-based allocation to more flexible data-driven models. In this paper, we propose a novel framework for non-myopic policy optimization in general online matching relying on potentials, a concept originally introduced for kidney exchange. We develop scalable and accurate ways of learning potentials that are higher-dimensional and more expressive than prior approaches. Our approach is a form of self-supervised imitation learning: the potentials are trained to mimic an omniscient algorithm that has perfect foresight. We focus on the application of heart transplant allocation and demonstrate, using real historical data, that our policies significantly outperform prior approaches -- including the current US status quo policy and the proposed continuous distribution framework -- in optimizing for population-level outcomes. Our analysis and methods come at a pivotal moment in US policy, as the current heart transplant allocation system is under review. We propose a scalable and theoretically grounded path toward more effective organ allocation.",
      "tldr_zh": "该研究针对心脏移植中器官稀缺和分配策略效率低下的问题，提出了一种基于Potentials概念的非近视（non-myopic）在线匹配策略优化框架。研究开发了比以往方法更具表现力且可扩展的高维学习方法，通过自监督模仿学习（self-supervised imitation learning）训练模型，使其能够模仿具有完美前瞻性的全知算法。在心脏移植分配的实际应用中，利用真实历史数据进行的实验表明，该策略在优化整个人群预后（population-level outcomes）方面显著优于美国目前的分配政策以及拟议的连续分配（continuous distribution）框架。该方法提供了一个具有理论基础且可扩展的路径，尤其在美国心脏移植分配系统审查的关键时刻，为制定更有效的器官分配政策提供了科学依据。",
      "categories": [
        "cs.LG",
        "cs.AI"
      ],
      "primary_category": "cs.LG",
      "comment": "",
      "pdf_url": "https://arxiv.org/pdf/2602.08878v1",
      "published_date": "2026-02-09 16:39:12 UTC",
      "updated_date": "2026-02-09 16:39:12 UTC",
      "processing_status": "completed",
      "attempts": 1,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "llm_backup_calls": 0,
      "last_update": "2026-02-16T04:45:54.715165+00:00"
    },
    {
      "arxiv_id": "2602.08873v1",
      "title": "Whose Name Comes Up? Benchmarking and Intervention-Based Auditing of LLM-Based Scholar Recommendation",
      "title_zh": "提及了谁？基于大语言模型的学者推荐基准测试与基于干预的审计",
      "authors": [
        "Lisette Espin-Noboa",
        "Gonzalo Gabriel Mendez"
      ],
      "abstract": "Large language models (LLMs) are increasingly used for academic expert recommendation. Existing audits typically evaluate model outputs in isolation, largely ignoring end-user inference-time interventions. As a result, it remains unclear whether failures such as refusals, hallucinations, and uneven coverage stem from model choice or deployment decisions. We introduce LLMScholarBench, a benchmark for auditing LLM-based scholar recommendation that jointly evaluates model infrastructure and end-user interventions across multiple tasks. LLMScholarBench measures both technical quality and social representation using nine metrics. We instantiate the benchmark in physics expert recommendation and audit 22 LLMs under temperature variation, representation-constrained prompting, and retrieval-augmented generation (RAG) via web search. Our results show that end-user interventions do not yield uniform improvements but instead redistribute error across dimensions. Higher temperature degrades validity, consistency, and factuality. Representation-constrained prompting improves diversity at the expense of factuality, while RAG primarily improves technical quality while reducing diversity and parity. Overall, end-user interventions reshape trade-offs rather than providing a general fix. We release code and data that can be adapted to other disciplines by replacing domain-specific ground truth and metrics.",
      "tldr_zh": "该研究提出了 LLMScholarBench，一个用于审计基于大语言模型 (LLMs) 的学者推荐系统的基准框架，旨在联合评估模型架构与推理时干预 (Interventions) 的综合影响。研究者利用 9 项衡量技术质量与社会代表性的指标，在物理学领域审计了 22 个 LLMs，探讨了温度 (Temperature) 变化、代表性约束提示 (Representation-constrained prompting) 及检索增强生成 (RAG) 的实际效果。实验结果表明，终端用户干预并未实现全面优化，而是导致误差在不同维度间重新分配。具体而言，提高温度会降低事实性与一致性，代表性约束提示虽能提升多样性却牺牲了准确性，而 RAG 在优化技术指标的同时损害了结果的多样性与公平性。总体而言，干预手段重构了各项指标间的权衡 (Trade-offs) 而非提供了通用的修复方案，该项工作为理解 LLM 在学术领域部署的社会技术影响提供了重要参考。",
      "categories": [
        "cs.IR",
        "cs.AI",
        "cs.CY",
        "cs.SI",
        "physics.soc-ph"
      ],
      "primary_category": "cs.IR",
      "comment": "28 pages: 8 pages in main (5 figures, 1 table), 20 pages in appendix (18 figures, 2 tables). under-review",
      "pdf_url": "https://arxiv.org/pdf/2602.08873v1",
      "published_date": "2026-02-09 16:34:57 UTC",
      "updated_date": "2026-02-09 16:34:57 UTC",
      "processing_status": "completed",
      "attempts": 1,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "llm_backup_calls": 0,
      "last_update": "2026-02-16T04:46:43.209937+00:00"
    },
    {
      "arxiv_id": "2602.08868v1",
      "title": "AnomSeer: Reinforcing Multimodal LLMs to Reason for Time-Series Anomaly Detection",
      "title_zh": "AnomSeer：强化多模态大语言模型的时间序列异常检测推理",
      "authors": [
        "Junru Zhang",
        "Lang Feng",
        "Haoran Shi",
        "Xu Guo",
        "Han Yu",
        "Yabo Dong",
        "Duanqing Xu"
      ],
      "abstract": "Time-series anomaly detection (TSAD) with multimodal large language models (MLLMs) is an emerging area, yet a persistent challenge remains: MLLMs rely on coarse time-series heuristics but struggle with multi-dimensional, detailed reasoning, which is vital for understanding complex time-series data. We present AnomSeer to address this by reinforcing the model to ground its reasoning in precise, structural details of time series, unifying anomaly classification, localization, and explanation. At its core, an expert chain-of-thought trace is generated to provide a verifiable, fine-grained reasoning from classical analyses (e.g., statistical measures, frequency transforms). Building on this, we propose a novel time-series grounded policy optimization (TimerPO) that incorporates two additional components beyond standard reinforcement learning: a time-series grounded advantage based on optimal transport and an orthogonal projection to ensure this auxiliary granular signal does not interfere with the primary detection objective. Across diverse anomaly scenarios, AnomSeer, with Qwen2.5-VL-3B/7B-Instruct, outperforms larger commercial baselines (e.g., GPT-4o) in classification and localization accuracy, particularly on point- and frequency-driven exceptions. Moreover, it produces plausible time-series reasoning traces that support its conclusions.",
      "tldr_zh": "该研究针对多模态大语言模型（MLLMs）在时间序列异常检测（TSAD）中过度依赖粗略启发式方法而缺乏细粒度推理的问题，提出了AnomSeer框架。该框架通过生成专家级链式思维（Chain-of-Thought）轨迹，将统计度量和频率变换等经典分析方法融入推理过程，实现了异常分类、定位与解释的统一。研究进一步提出了时间序列基础策略优化（TimerPO），利用基于最优传输（Optimal Transport）的优势函数和正交投影技术，在不干扰主要检测目标的前提下强化了模型对细粒度信号的捕获能力。实验结果显示，基于 Qwen2.5-VL-3B/7B-Instruct 的 AnomSeer 在分类和定位精度上均优于 GPT-4o 等大型商业模型，尤其是在点异常和频率驱动异常的处理上表现优异。此外，该模型能够生成具有解释性的推理轨迹，为检测结论提供了可验证的逻辑支持。",
      "categories": [
        "cs.LG",
        "cs.AI"
      ],
      "primary_category": "cs.LG",
      "comment": "Preprint",
      "pdf_url": "https://arxiv.org/pdf/2602.08868v1",
      "published_date": "2026-02-09 16:30:13 UTC",
      "updated_date": "2026-02-09 16:30:13 UTC",
      "processing_status": "completed",
      "attempts": 1,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "llm_backup_calls": 0,
      "last_update": "2026-02-16T04:46:33.314248+00:00"
    },
    {
      "arxiv_id": "2602.08864v1",
      "title": "Understanding Dynamic Compute Allocation in Recurrent Transformers",
      "title_zh": "深入解析循环 Transformer 中的动态计算分配",
      "authors": [
        "Ibraheem Muhammad Moosa",
        "Suhas Lohit",
        "Ye Wang",
        "Moitreya Chatterjee",
        "Wenpeng Yin"
      ],
      "abstract": "Token-level adaptive computation seeks to reduce inference cost by allocating more computation to harder tokens and less to easier ones. However, prior work is primarily evaluated on natural-language benchmarks using task-level metrics, where token-level difficulty is unobservable and confounded with architectural factors, making it unclear whether compute allocation truly aligns with underlying complexity. We address this gap through three contributions. First, we introduce a complexity-controlled evaluation paradigm using algorithmic and synthetic language tasks with parameterized difficulty, enabling direct testing of token-level compute allocation. Second, we propose ANIRA, a unified recurrent Transformer framework that supports per-token variable-depth computation while isolating compute allocation decisions from other model factors. Third, we use this framework to conduct a systematic analysis of token-level adaptive computation across alignment with complexity, generalization, and decision timing. Our results show that compute allocation aligned with task complexity can emerge without explicit difficulty supervision, but such alignment does not imply algorithmic generalization: models fail to extrapolate to unseen input sizes despite allocating additional computation. We further find that early compute decisions rely on static structural cues, whereas online halting more closely tracks algorithmic execution state.",
      "tldr_zh": "该研究探讨了Recurrent Transformers中的动态计算分配问题，旨在解决现有评估方法难以直接观察Token级别计算分配与任务复杂度对齐关系的现状。作者提出了一种受控复杂度的评估范式，利用具有参数化难度的算法和合成语言任务，实现了对Token级别计算分配的直接测试。研究进一步开发了ANIRA框架，这是一种统一的循环Transformer架构，能够在隔离其他模型因素的同时支持每个Token的可变深度计算。实验结果表明，即使在没有显式难度监督的情况下，模型也能自发产生与任务复杂度相匹配的计算分配。然而，这种对齐并不意味着算法层面的Generalization，模型在面对未见过的输入大小时，即便增加计算量也难以实现外推。此外，研究发现早期的计算决策主要依赖静态结构线索，而Online Halting则能更准确地追踪算法的实时执行状态。",
      "categories": [
        "cs.CL",
        "cs.AI",
        "cs.LG"
      ],
      "primary_category": "cs.CL",
      "comment": "",
      "pdf_url": "https://arxiv.org/pdf/2602.08864v1",
      "published_date": "2026-02-09 16:27:52 UTC",
      "updated_date": "2026-02-09 16:27:52 UTC",
      "processing_status": "completed",
      "attempts": 1,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "llm_backup_calls": 0,
      "last_update": "2026-02-16T04:46:13.804736+00:00"
    },
    {
      "arxiv_id": "2602.08858v1",
      "title": "FlattenGPT: Depth Compression for Transformer with Layer Flattening",
      "title_zh": "FlattenGPT：基于层扁平化的 Transformer 深度压缩",
      "authors": [
        "Ruihan Xu",
        "Qingpei Guo",
        "Yao Zhu",
        "Xiangyang Ji",
        "Ming Yang",
        "Shiliang Zhang"
      ],
      "abstract": "Recent works have indicated redundancy across transformer blocks, prompting the research of depth compression to prune less crucial blocks. However, current ways of entire-block pruning suffer from risks of discarding meaningful cues learned in those blocks, leading to substantial performance degradation. As another line of model compression, channel pruning can better preserve performance, while it cannot reduce model depth and is challenged by inconsistent pruning ratios for individual layers. To pursue better model compression and acceleration, this paper proposes \\textbf{FlattenGPT}, a novel way to detect and reduce depth-wise redundancies. By flatting two adjacent blocks into one, it compresses the network depth, meanwhile enables more effective parameter redundancy detection and removal. FlattenGPT allows to preserve the knowledge learned in all blocks, and remains consistent with the original transformer architecture. Extensive experiments demonstrate that FlattenGPT enhances model efficiency with a decent trade-off to performance. It outperforms existing pruning methods in both zero-shot accuracies and WikiText-2 perplexity across various model types and parameter sizes. On LLaMA-2/3 and Qwen-1.5 models, FlattenGPT retains 90-96\\% of zero-shot performance with a compression ratio of 20\\%. It also outperforms other pruning methods in accelerating LLM inference, making it promising for enhancing the efficiency of transformers.",
      "tldr_zh": "该研究提出了FlattenGPT，一种针对Transformer模型深度冗余的新型深度压缩方法，旨在解决传统整块剪枝(entire-block pruning)导致性能大幅下降的问题。FlattenGPT通过将相邻的两个Block压平(flattening)为一个，在压缩网络深度的同时，能够更有效地识别并移除参数冗余，并保留所有层中学习到的关键特征。该方法保持了与原始Transformer架构的一致性，通过在LLaMA-2/3和Qwen-1.5等模型上的广泛实验证明，FlattenGPT在20%的压缩率下仍能保持90-96%的零样本(zero-shot)性能。实验结果显示，FlattenGPT在WikiText-2困惑度(perplexity)和推理加速方面均优于现有的剪枝方法，为提升大语言模型(LLMs)的运行效率提供了一种平衡性能与速度的有效方案。",
      "categories": [
        "cs.CV",
        "cs.AI"
      ],
      "primary_category": "cs.CV",
      "comment": "Submitted to ICML 2026",
      "pdf_url": "https://arxiv.org/pdf/2602.08858v1",
      "published_date": "2026-02-09 16:22:58 UTC",
      "updated_date": "2026-02-09 16:22:58 UTC",
      "processing_status": "completed",
      "attempts": 1,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "llm_backup_calls": 0,
      "last_update": "2026-02-16T04:46:07.902427+00:00"
    },
    {
      "arxiv_id": "2602.08857v1",
      "title": "Discovering Interpretable Algorithms by Decompiling Transformers to RASP",
      "title_zh": "通过将 Transformer 反编译为 RASP 来发现可解释算法",
      "authors": [
        "Xinting Huang",
        "Aleksandra Bakalova",
        "Satwik Bhattamishra",
        "William Merrill",
        "Michael Hahn"
      ],
      "abstract": "Recent work has shown that the computations of Transformers can be simulated in the RASP family of programming languages. These findings have enabled improved understanding of the expressive capacity and generalization abilities of Transformers. In particular, Transformers have been suggested to length-generalize exactly on problems that have simple RASP programs. However, it remains open whether trained models actually implement simple interpretable programs. In this paper, we present a general method to extract such programs from trained Transformers. The idea is to faithfully re-parameterize a Transformer as a RASP program and then apply causal interventions to discover a small sufficient sub-program. In experiments on small Transformers trained on algorithmic and formal language tasks, we show that our method often recovers simple and interpretable RASP programs from length-generalizing transformers. Our results provide the most direct evidence so far that Transformers internally implement simple RASP programs.",
      "tldr_zh": "该研究探讨了 Transformer 的计算是否可以通过 RASP 编程语言进行模拟，并旨在解决训练后的模型是否真正实现了简单且可解释程序的问题。为此，作者提出了一种将训练好的 Transformer 忠实地重新参数化为 RASP 程序的方法，并通过因果干预 (causal interventions) 来发现其中精简且充分的子程序。在针对算法和形式语言任务的小型 Transformer 实验中，该方法成功从具有长度泛化 (length-generalize) 能力的模型中提取出了简单且可解释的 RASP 程序。研究结果为 Transformer 内部实现了简单的 RASP 程序提供了目前最直接的证据，进一步增强了对模型表达能力和泛化机制的理解。",
      "categories": [
        "cs.LG",
        "cs.AI",
        "cs.CL"
      ],
      "primary_category": "cs.LG",
      "comment": "101 pages, 92 figures",
      "pdf_url": "https://arxiv.org/pdf/2602.08857v1",
      "published_date": "2026-02-09 16:22:29 UTC",
      "updated_date": "2026-02-09 16:22:29 UTC",
      "processing_status": "completed",
      "attempts": 1,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "llm_backup_calls": 0,
      "last_update": "2026-02-16T04:46:58.902516+00:00"
    },
    {
      "arxiv_id": "2602.08848v1",
      "title": "Deciding the Satisfiability of Combined Qualitative Constraint Networks",
      "title_zh": "组合定性约束网络的可满足性判定",
      "authors": [
        "Quentin Cohen-Solal",
        "Alexandre Niveau",
        "Maroua Bouzid"
      ],
      "abstract": "Among the various forms of reasoning studied in the context of artificial intelligence, qualitative reasoning makes it possible to infer new knowledge in the context of imprecise, incomplete information without numerical values. In this paper, we propose a formal framework unifying several forms of extensions and combinations of qualitative formalisms, including multi-scale reasoning, temporal sequences, and loose integrations. This framework makes it possible to reason in the context of each of these combinations and extensions, but also to study in a unified way the satisfiability decision and its complexity. In particular, we establish two complementary theorems guaranteeing that the satisfiability decision is polynomial, and we use them to recover the known results of the size-topology combination. We also generalize the main definition of qualitative formalism to include qualitative formalisms excluded from the definitions of the literature, important in the context of combinations.",
      "tldr_zh": "该研究针对人工智能中的定性推理 (Qualitative Reasoning) 提出了一种统一的形式化框架，旨在解决不精确和不完整信息下的知识推理问题。该框架整合了包括多尺度推理 (Multi-scale Reasoning)、时间序列 (Temporal Sequences) 和松散集成 (Loose Integrations) 在内的多种扩展与组合形式，实现了对可满足性判定 (Satisfiability Decision) 及其复杂性的统一研究。通过建立两个互补定理，论文确保了在特定组合背景下的可满足性判定具有多项式 (Polynomial) 复杂度，并成功验证了尺寸-拓扑 (Size-topology) 组合的既有结果。此外，作者通过推广定性形式化 (Qualitative Formalism) 的定义，将此前文献中排除的、但在组合场景下具有重要意义的形式纳入了该理论体系，显著增强了框架的普适性与表达能力。",
      "categories": [
        "cs.AI"
      ],
      "primary_category": "cs.AI",
      "comment": "",
      "pdf_url": "https://arxiv.org/pdf/2602.08848v1",
      "published_date": "2026-02-09 16:14:58 UTC",
      "updated_date": "2026-02-09 16:14:58 UTC",
      "processing_status": "completed",
      "attempts": 1,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "llm_backup_calls": 0,
      "last_update": "2026-02-16T04:48:02.006705+00:00"
    },
    {
      "arxiv_id": "2602.08847v1",
      "title": "Dr. MAS: Stable Reinforcement Learning for Multi-Agent LLM Systems",
      "title_zh": "Dr. MAS：面向多智能体 LLM 系统的稳定强化学习",
      "authors": [
        "Lang Feng",
        "Longtao Zheng",
        "Shuo He",
        "Fuxiang Zhang",
        "Bo An"
      ],
      "abstract": "Multi-agent LLM systems enable advanced reasoning and tool use via role specialization, yet reliable reinforcement learning (RL) post-training for such systems remains difficult. In this work, we theoretically pinpoint a key reason for training instability when extending group-based RL to multi-agent LLM systems. We show that under GRPO-style optimization, a global normalization baseline may deviate from diverse agents' reward distributions, which ultimately leads to gradient-norm instability. Based on this finding, we propose Dr. MAS, a simple and stable RL training recipe for multi-agent LLM systems. Dr. MAS uses an agent-wise remedy: normalizing advantages per agent using each agent's own reward statistics, which calibrates gradient scales and dramatically stabilizes training, both theoretically and empirically. Beyond the algorithm, Dr. MAS provides an end-to-end RL training framework for multi-agent LLM systems, supporting scalable orchestration, flexible per-agent LLM serving and optimization configs, and shared resource scheduling of LLM actor backends. We evaluate Dr. MAS on multi-agent math reasoning and multi-turn search benchmarks using Qwen2.5 and Qwen3 series models. Dr. MAS achieves clear gains over vanilla GRPO (e.g., +5.6\\% avg@16 and +4.6\\% pass@16 on math, and +15.2\\% avg@16 and +13.1\\% pass@16 on search) while largely eliminating gradient spikes. Moreover, it remains highly effective under heterogeneous agent-model assignments while improving efficiency.",
      "tldr_zh": "该研究针对多智能体 LLM 系统 (Multi-agent LLM systems) 在强化学习 (Reinforcement Learning, RL) 后训练中面临的稳定性难题，从理论上指出在全球归一化基准下，不同智能体的奖励分布差异会导致梯度范数不稳定 (gradient-norm instability)。为此，作者提出了 Dr. MAS，这是一种通过智能体感知 (agent-wise) 的修复策略来稳定训练的新型方案，其核心是利用每个智能体自身的奖励统计数据对优势值 (advantages) 进行归一化，从而有效校准梯度尺度。除了算法创新，Dr. MAS 还提供了一个支持可扩展编排、灵活配置和共享资源调度的端到端训练框架。在基于 Qwen2.5 和 Qwen3 系列模型的数学推理与多轮搜索基准测试中，Dr. MAS 相比原生 GRPO 实现了显著的性能提升，其中搜索任务的平均准确率提高了 15.2%，并成功消除了梯度尖峰 (gradient spikes)。实验证明，该框架在异构智能体模型分配下依然保持高效，为复杂多智能体系统的可靠训练奠定了基础。",
      "categories": [
        "cs.LG",
        "cs.AI"
      ],
      "primary_category": "cs.LG",
      "comment": "Preprint",
      "pdf_url": "https://arxiv.org/pdf/2602.08847v1",
      "published_date": "2026-02-09 16:13:39 UTC",
      "updated_date": "2026-02-09 16:13:39 UTC",
      "processing_status": "completed",
      "attempts": 1,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "llm_backup_calls": 0,
      "last_update": "2026-02-16T04:47:05.902304+00:00"
    },
    {
      "arxiv_id": "2602.09075v2",
      "title": "Learning to Remember, Learn, and Forget in Attention-Based Models",
      "title_zh": "注意力模型中记忆、学习与遗忘的学习",
      "authors": [
        "Djohan Bonnet",
        "Jamie Lohoff",
        "Jan Finkbeiner",
        "Elidona Skhikerujah",
        "Emre Neftci"
      ],
      "abstract": "In-Context Learning (ICL) in transformers acts as an online associative memory and is believed to underpin their high performance on complex sequence processing tasks. However, in gated linear attention models, this memory has a fixed capacity and is prone to interference, especially for long sequences. We propose Palimpsa, a self-attention model that views ICL as a continual learning problem that must address a stability-plasticity dilemma. Palimpsa uses Bayesian metaplasticity, where the plasticity of each attention state is tied to an importance state grounded by a prior distribution that captures accumulated knowledge. We demonstrate that various gated linear attention models emerge as specific architecture choices and posterior approximations, and that Mamba2 is a special case of Palimpsa where forgetting dominates. This theoretical link enables the transformation of any non-metaplastic model into a metaplastic one, significantly expanding its memory capacity. Our experiments show that Palimpsa consistently outperforms baselines on the Multi-Query Associative Recall (MQAR) benchmark and on Commonsense Reasoning tasks.",
      "tldr_zh": "该研究探讨了Transformer模型中的语境学习(In-Context Learning)作为在线关联记忆的机制，针对门控线性注意力模型(gated linear attention models)在处理长序列时存在的容量限制和干扰问题，提出了名为Palimpsa的自注意力模型。Palimpsa将语境学习视为一个持续学习问题，并利用贝叶斯元可塑性(Bayesian metaplasticity)来解决稳定性与可塑性之间的权衡，将注意力状态的可塑性与基于先验分布的重要性状态相结合。研究进一步揭示了多种门控线性注意力模型是该架构的特例，并指出Mamba2是Palimpsa在遗忘机制占主导时的特殊形式。这种理论框架允许将普通的非元可塑性模型转化为元可塑性模型，从而大幅扩展其记忆容量。实验结果表明，Palimpsa在多查询关联回想(MQAR)基准测试和常识推理任务中均持续优于基线模型，展现了更强的记忆与推理能力。",
      "categories": [
        "cs.LG",
        "cs.AI"
      ],
      "primary_category": "cs.LG",
      "comment": "",
      "pdf_url": "https://arxiv.org/pdf/2602.09075v2",
      "published_date": "2026-02-09 16:09:51 UTC",
      "updated_date": "2026-02-11 11:57:31 UTC",
      "processing_status": "completed",
      "attempts": 1,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "llm_backup_calls": 0,
      "last_update": "2026-02-16T04:47:23.607504+00:00"
    },
    {
      "arxiv_id": "2602.08835v2",
      "title": "Learning the Value Systems of Societies with Preference-based Multi-objective Reinforcement Learning",
      "title_zh": "利用基于偏好的多目标强化学习学习社会价值体系",
      "authors": [
        "Andrés Holgado-Sánchez",
        "Peter Vamplew",
        "Richard Dazeley",
        "Sascha Ossowski",
        "Holger Billhardt"
      ],
      "abstract": "Value-aware AI should recognise human values and adapt to the value systems (value-based preferences) of different users. This requires operationalization of values, which can be prone to misspecification. The social nature of values demands their representation to adhere to multiple users while value systems are diverse, yet exhibit patterns among groups. In sequential decision making, efforts have been made towards personalization for different goals or values from demonstrations of diverse agents. However, these approaches demand manually designed features or lack value-based interpretability and/or adaptability to diverse user preferences.\n  We propose algorithms for learning models of value alignment and value systems for a society of agents in Markov Decision Processes (MDPs), based on clustering and preference-based multi-objective reinforcement learning (PbMORL). We jointly learn socially-derived value alignment models (groundings) and a set of value systems that concisely represent different groups of users (clusters) in a society. Each cluster consists of a value system representing the value-based preferences of its members and an approximately Pareto-optimal policy that reflects behaviours aligned with this value system. We evaluate our method against a state-of-the-art PbMORL algorithm and baselines on two MDPs with human values.",
      "tldr_zh": "该研究提出了一个基于聚类和基于偏好的多目标强化学习(Preference-based Multi-objective Reinforcement Learning, PbMORL)的算法框架，旨在使AI能够识别并适应不同社会群体的价值体系(Value Systems)。该方法通过在马尔可夫决策过程(MDPs)中联合学习社会衍生的价值对齐模型和价值系统，有效地解决了传统方法中手动设计特征、缺乏解释性以及难以适应多样化偏好的问题。研究将用户划分为不同的簇(Clusters)，每个簇包含代表其成员偏好的价值系统以及与之对齐的帕累托最优策略(Pareto-optimal Policy)。实验在两个涉及人类价值观的MDPs环境中进行，证明了该方法在学习社会价值模型和表征不同群体价值取向方面的优越性，为构建具备价值感知能力的AI系统提供了可解释且灵活的方案。",
      "categories": [
        "cs.AI",
        "cs.CY",
        "cs.LG"
      ],
      "primary_category": "cs.AI",
      "comment": "18 pages, 3 figures. To be published in proceedings of the 25th International Conference on Autonomous Agents and Multi-Agent Systems (AAMAS 2026). This is a full version that includes the supplementary material",
      "pdf_url": "https://arxiv.org/pdf/2602.08835v2",
      "published_date": "2026-02-09 16:06:36 UTC",
      "updated_date": "2026-02-11 10:09:11 UTC",
      "processing_status": "completed",
      "attempts": 1,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "llm_backup_calls": 0,
      "last_update": "2026-02-16T04:47:15.198732+00:00"
    },
    {
      "arxiv_id": "2602.08829v1",
      "title": "WildReward: Learning Reward Models from In-the-Wild Human Interactions",
      "title_zh": "WildReward：从现实场景人类交互中学习奖励模型",
      "authors": [
        "Hao Peng",
        "Yunjia Qi",
        "Xiaozhi Wang",
        "Zijun Yao",
        "Lei Hou",
        "Juanzi Li"
      ],
      "abstract": "Reward models (RMs) are crucial for the training of large language models (LLMs), yet they typically rely on large-scale human-annotated preference pairs. With the widespread deployment of LLMs, in-the-wild interactions have emerged as a rich source of implicit reward signals. This raises the question: Can we develop reward models directly from in-the-wild interactions? In this work, we explore this possibility by adopting WildChat as an interaction source and proposing a pipeline to extract reliable human feedback, yielding 186k high-quality instances for training WildReward via ordinal regression directly on user feedback without preference pairs. Extensive experiments demonstrate that WildReward achieves comparable or even superior performance compared to conventional reward models, with improved calibration and cross-sample consistency. We also observe that WildReward benefits directly from user diversity, where more users yield stronger reward models. Finally, we apply WildReward to online DPO training and observe significant improvements across various tasks. Code and data are released at https://github.com/THU-KEG/WildReward.",
      "tldr_zh": "该研究探讨了直接从真实场景（in-the-wild）的人机交互中开发奖励模型（Reward Models）的可能性，旨在减少对大规模人工标注偏好对的依赖。作者利用WildChat作为交互来源，并提出一套提取可靠人类反馈的流程，构建了包含186k个高质量实例的数据集，通过在用户反馈上直接进行序数回归（Ordinal Regression）训练出WildReward模型。实验结果显示，WildReward在性能上可比肩甚至超越传统奖励模型，并在校准度和跨样本一致性方面表现更优。研究还发现奖励模型的强度会随着用户多样性的增加而提升，具有良好的扩展性。最后，将WildReward应用于在线DPO训练，在多项任务中均取得了显著的性能提升。",
      "categories": [
        "cs.CL",
        "cs.AI"
      ],
      "primary_category": "cs.CL",
      "comment": "",
      "pdf_url": "https://arxiv.org/pdf/2602.08829v1",
      "published_date": "2026-02-09 16:00:30 UTC",
      "updated_date": "2026-02-09 16:00:30 UTC",
      "processing_status": "completed",
      "attempts": 1,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "llm_backup_calls": 0,
      "last_update": "2026-02-16T04:47:09.099352+00:00"
    },
    {
      "arxiv_id": "2602.08826v1",
      "title": "Affective Flow Language Model for Emotional Support Conversation",
      "title_zh": "面向情感支持对话的情感流语言模型",
      "authors": [
        "Chenghui Zou",
        "Ning Wang",
        "Tiesunlong Shen",
        "Luwei Xiao",
        "Chuan Ma",
        "Xiangpeng Li",
        "Rui Mao",
        "Erik Cambria"
      ],
      "abstract": "Large language models (LLMs) have been widely applied to emotional support conversation (ESC). However, complex multi-turn support remains challenging.This is because existing alignment schemes rely on sparse outcome-level signals, thus offering limited supervision for intermediate strategy decisions. To fill this gap, this paper proposes affective flow language model for emotional support conversation (AFlow), a framework that introduces fine-grained supervision on dialogue prefixes by modeling a continuous affective flow along multi-turn trajectories. AFlow can estimate intermediate utility over searched trajectories and learn preference-consistent strategy transitions. To improve strategy coherence and empathetic response quality, a subpath-level flow-balance objective is presented to propagate preference signals to intermediate states. Experiment results show consistent and significant improvements over competitive baselines in diverse emotional contexts. Remarkably, AFlow with a compact open-source backbone outperforms proprietary LMMs such as GPT-4o and Claude-3.5 on major ESC metrics. Our code is available at https://github.com/chzou25-lgtm/AffectiveFlow.",
      "tldr_zh": "该研究针对大语言模型(LLMs)在情感支持对话(ESC)中因结果级信号稀疏而难以做出准确中间策略决策的问题，提出了情感流语言模型(AFlow)框架。AFlow通过建模多轮轨迹中的连续情感流(affective flow)，为对话前缀引入细粒度监督，使其能够评估搜索轨迹中的中间效用并学习偏好一致的策略转换。为了增强策略连贯性和共情响应质量，研究引入了子路径级别的流平衡目标(subpath-level flow-balance objective)来传播偏好信号。实验结果显示，AFlow在多种情感语境下较基线模型有显著提升。特别是在主要ESC指标上，采用开源骨干网络的AFlow表现超越了GPT-4o和Claude-3.5等先进模型，证明了细粒度情感流建模在提升多轮对话支持能力方面的卓越效能。",
      "categories": [
        "cs.CL",
        "cs.AI"
      ],
      "primary_category": "cs.CL",
      "comment": "19 pages, 7 figures",
      "pdf_url": "https://arxiv.org/pdf/2602.08826v1",
      "published_date": "2026-02-09 15:58:50 UTC",
      "updated_date": "2026-02-09 15:58:50 UTC",
      "processing_status": "completed",
      "attempts": 1,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "llm_backup_calls": 0,
      "last_update": "2026-02-16T04:47:26.601766+00:00"
    },
    {
      "arxiv_id": "2602.10147v1",
      "title": "On the Use of a Large Language Model to Support the Conduction of a Systematic Mapping Study: A Brief Report from a Practitioner's View",
      "title_zh": "大语言模型辅助开展系统映射研究：来自从业者视角的实践简报",
      "authors": [
        "Cauã Ferreira Barros",
        "Marcos Kalinowski",
        "Mohamad Kassab",
        "Valdemar Vicente Graciano Neto"
      ],
      "abstract": "The use of Large Language Models (LLMs) has drawn growing interest within the scientific community. LLMs can handle large volumes of textual data and support methods for evidence synthesis. Although recent studies highlight the potential of LLMs to accelerate screening and data extraction steps in systematic reviews, detailed reports of their practical application throughout the entire process remain scarce. This paper presents an experience report on the conduction of a systematic mapping study with the support of LLMs, describing the steps followed, the necessary adjustments, and the main challenges faced. Positive aspects are discussed, such as (i) the significant reduction of time in repetitive tasks and (ii) greater standardization in data extraction, as well as negative aspects, including (i) considerable effort to build reliable well-structured prompts, especially for less experienced users, since achieving effective prompts may require several iterations and testing, which can partially offset the expected time savings, (ii) the occurrence of hallucinations, and (iii) the need for constant manual verification. As a contribution, this work offers lessons learned and practical recommendations for researchers interested in adopting LLMs in systematic mappings and reviews, highlighting both efficiency gains and methodological risks and limitations to be considered.",
      "tldr_zh": "该研究从从业者视角探讨了利用大语言模型(Large Language Models, LLMs)支持系统映射研究(Systematic Mapping Study)的实践全过程，详细记录了具体的实施步骤、必要调整及面临的主要挑战。研究发现LLMs在处理重复性任务时能显著缩短时间，并提升数据提取(Data Extraction)的标准化水平。然而，该实践也揭示了构建可靠提示词(Prompts)需要投入大量精力，且面临幻觉(Hallucinations)风险，必须进行持续的人工验证。作为核心贡献，该文总结了在证据合成全流程中应用LLMs的经验教训，并针对效率提升与方法论局限性提出了实用建议。该工作为希望在系统映射与系统评价(Systematic Reviews)中采用LLMs的学者提供了兼顾性能收益与风险防控的参考框架。",
      "categories": [
        "cs.SE",
        "cs.AI"
      ],
      "primary_category": "cs.SE",
      "comment": "6 pages, includes 2 tables. Submitted and Accepted to the WSESE 2026 ICSE Workshop",
      "pdf_url": "https://arxiv.org/pdf/2602.10147v1",
      "published_date": "2026-02-09 15:57:30 UTC",
      "updated_date": "2026-02-09 15:57:30 UTC",
      "processing_status": "completed",
      "attempts": 1,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "llm_backup_calls": 0,
      "last_update": "2026-02-16T04:47:42.102139+00:00"
    },
    {
      "arxiv_id": "2602.08816v1",
      "title": "Permissive-Washing in the Open AI Supply Chain: A Large-Scale Audit of License Integrity",
      "title_zh": "开放 AI 供应链中的“宽泛许可洗白”：许可证完整性的大规模审计",
      "authors": [
        "James Jewitt",
        "Gopi Krishnan Rajbahadur",
        "Hao Li",
        "Bram Adams",
        "Ahmed E. Hassan"
      ],
      "abstract": "Permissive licenses like MIT, Apache-2.0, and BSD-3-Clause dominate open-source AI, signaling that artifacts like models, datasets, and code can be freely used, modified, and redistributed. However, these licenses carry mandatory requirements: include the full license text, provide a copyright notice, and preserve upstream attribution, that remain unverified at scale. Failure to meet these conditions can place reuse outside the scope of the license, effectively leaving AI artifacts under default copyright for those uses and exposing downstream users to litigation. We call this phenomenon ``permissive washing'': labeling AI artifacts as free to use, while omitting the legal documentation required to make that label actionable. To assess how widespread permissive washing is in the AI supply chain, we empirically audit 124,278 dataset $\\rightarrow$ model $\\rightarrow$ application supply chains, spanning 3,338 datasets, 6,664 models, and 28,516 applications across Hugging Face and GitHub. We find that an astonishing 96.5\\% of datasets and 95.8\\% of models lack the required license text, only 2.3\\% of datasets and 3.2\\% of models satisfy both license text and copyright requirements, and even when upstream artifacts provide complete licensing evidence, attribution rarely propagates downstream: only 27.59\\% of models preserve compliant dataset notices and only 5.75\\% of applications preserve compliant model notices (with just 6.38\\% preserving any linked upstream notice). Practitioners cannot assume permissive labels confer the rights they claim: license files and notices, not metadata, are the source of legal truth. To support future research, we release our full audit dataset and reproducible pipeline.",
      "tldr_zh": "该研究对开源AI供应链中的许可证完整性进行了大规模审计，揭示了普遍存在的“准许式洗白”(Permissive-Washing)现象，即AI工件虽被标记为MIT、Apache-2.0等准许式许可证，却未按法律要求包含完整的许可证文本、版权声明或上游溯源信息。通过对Hugging Face和GitHub上涉及3,338个数据集、6,664个模型和28,516个应用程序的124,278条供应链进行实证审计发现，高达96.5%的数据集和95.8%的模型缺失法定许可证文本，仅极少数能同时满足许可证与版权要求。研究进一步指出，即使上游工件提供了完整的合规证明，溯源信息也极少能传播至下游，仅有5.75%的应用保留了合规的模型声明。这种法律文档的缺失使AI工件在实际使用中面临默认版权限制，从而给下游用户带来巨大的诉讼风险。作者强调执业者不能盲目信任元数据中的准许式标签，并发布了审计数据集与可重现的Pipeline以支持后续研究。",
      "categories": [
        "cs.LG",
        "cs.AI",
        "cs.CY",
        "cs.SE"
      ],
      "primary_category": "cs.LG",
      "comment": "13 pages, 2 figures, 10 tables",
      "pdf_url": "https://arxiv.org/pdf/2602.08816v1",
      "published_date": "2026-02-09 15:51:36 UTC",
      "updated_date": "2026-02-09 15:51:36 UTC",
      "processing_status": "completed",
      "attempts": 1,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "llm_backup_calls": 0,
      "last_update": "2026-02-16T04:47:40.306693+00:00"
    },
    {
      "arxiv_id": "2602.08815v1",
      "title": "Negative-Aware Diffusion Process for Temporal Knowledge Graph Extrapolation",
      "title_zh": "面向时序知识图谱外推的负感知扩散过程",
      "authors": [
        "Yanglei Gan",
        "Peng He",
        "Yuxiang Cai",
        "Run Lin",
        "Guanyu Zhou",
        "Qiao Liu"
      ],
      "abstract": "Temporal Knowledge Graph (TKG) reasoning seeks to predict future missing facts from historical evidence. While diffusion models (DM) have recently gained attention for their ability to capture complex predictive distributions, two gaps remain: (i) the generative path is conditioned only on positive evidence, overlooking informative negative context, and (ii) training objectives are dominated by cross-entropy ranking, which improves candidate ordering but provides little supervision over the calibration of the denoised embedding. To bridge this gap, we introduce Negative-Aware Diffusion model for TKG Extrapolation (NADEx). Specifically, NADEx encodes subject-centric histories of entities, relations and temporal intervals into sequential embeddings. NADEx perturbs the query object in the forward process and reconstructs it in reverse with a Transformer denoiser conditioned on the temporal-relational context. We further derive a cosine-alignment regularizer derived from batch-wise negative prototypes, which tightens the decision boundary against implausible candidates. Comprehensive experiments on four public TKG benchmarks demonstrate that NADEx delivers state-of-the-art performance.",
      "tldr_zh": "该研究针对时序知识图谱（Temporal Knowledge Graph, TKG）外推任务中的现有扩散模型（Diffusion Models）仅关注正向证据且缺乏对去噪嵌入校准有效监督的问题，提出了 NADEx 框架。该框架将实体、关系和时间间隔的主体中心历史信息编码为序列嵌入（sequential embeddings），通过在前向过程中扰动查询对象并在反向过程中利用以时空关系为上下文的 Transformer 去噪器（Transformer denoiser）进行重构。为了增强判别能力，NADEx 引入了一种基于批次负原型（batch-wise negative prototypes）的余弦对齐正则化项（cosine-alignment regularizer），以此收紧针对不合理候选对象的决策边界。实验结果表明，NADEx 在四个公开 TKG 基准测试中均取得了最先进的（state-of-the-art）性能表现，有效提升了复杂预测分布下的推理精度。",
      "categories": [
        "cs.AI"
      ],
      "primary_category": "cs.AI",
      "comment": "",
      "pdf_url": "https://arxiv.org/pdf/2602.08815v1",
      "published_date": "2026-02-09 15:50:56 UTC",
      "updated_date": "2026-02-09 15:50:56 UTC",
      "processing_status": "completed",
      "attempts": 1,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "llm_backup_calls": 0,
      "last_update": "2026-02-16T04:47:51.804553+00:00"
    },
    {
      "arxiv_id": "2602.08810v1",
      "title": "$\\texttt{lrnnx}$: A library for Linear RNNs",
      "title_zh": "$\\texttt{lrnnx}$：线性循环神经网络库",
      "authors": [
        "Karan Bania",
        "Soham Kalburgi",
        "Manit Tanwar",
        "Dhruthi",
        "Aditya Nagarsekar",
        "Harshvardhan Mestha",
        "Naman Chibber",
        "Raj Deshmukh",
        "Anish Sathyanarayanan",
        "Aarush Rathore",
        "Pratham Chheda"
      ],
      "abstract": "Linear recurrent neural networks (LRNNs) provide a structured approach to sequence modeling that bridges classical linear dynamical systems and modern deep learning, offering both expressive power and theoretical guarantees on stability and trainability. In recent years, multiple LRNN-based architectures have been proposed, each introducing distinct parameterizations, discretization schemes, and implementation constraints. However, existing implementations are fragmented across different software frameworks, often rely on framework-specific optimizations, and in some cases require custom CUDA kernels or lack publicly available code altogether. As a result, using, comparing, or extending LRNNs requires substantial implementation effort. To address this, we introduce $\\texttt{lrnnx}$, a unified software library that implements several modern LRNN architectures under a common interface. The library exposes multiple levels of control, allowing users to work directly with core components or higher-level model abstractions. $\\texttt{lrnnx}$ aims to improve accessibility, reproducibility, and extensibility of LRNN research and applications. We make our code available under a permissive MIT license.",
      "tldr_zh": "该研究推出了 $\\texttt{lrnnx}$，这是一个为线性循环神经网络（Linear RNNs, LRNNs）设计的统一软件库，旨在解决现有 LRNN 实现碎片化、依赖特定框架优化或缺乏开源代码的问题。该库在通用的接口下实现了多种现代 LRNN 架构，通过提供多层级的控制权限，允许用户直接操作核心组件或使用高层模型抽象。$\\texttt{lrnnx}$ 桥接了经典线性动力系统与现代深度学习，并针对不同架构的参数化、离散化方案和实现约束进行了整合。通过提升 LRNN 研究的可访问性、可复现性和可扩展性，该库为序列建模提供了更便捷的开发环境，并以许可度高的 MIT 协议开放源代码。",
      "categories": [
        "cs.LG",
        "cs.AI"
      ],
      "primary_category": "cs.LG",
      "comment": "EACL Student Research Workshop 2026",
      "pdf_url": "https://arxiv.org/pdf/2602.08810v1",
      "published_date": "2026-02-09 15:48:48 UTC",
      "updated_date": "2026-02-09 15:48:48 UTC",
      "processing_status": "completed",
      "attempts": 1,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "llm_backup_calls": 0,
      "last_update": "2026-02-16T04:48:34.003036+00:00"
    },
    {
      "arxiv_id": "2602.08804v1",
      "title": "Root Cause Analysis Method Based on Large Language Models with Residual Connection Structures",
      "title_zh": "基于残差连接结构大语言模型的根因分析方法",
      "authors": [
        "Liming Zhou",
        "Ailing Liu",
        "Hongwei Liu",
        "Min He",
        "Heng Zhang"
      ],
      "abstract": "Root cause localization remain challenging in complex and large-scale microservice architectures. The complex fault propagation among microservices and the high dimensionality of telemetry data, including metrics, logs, and traces, limit the effectiveness of existing root cause analysis (RCA) methods. In this paper, a residual-connection-based RCA method using large language model (LLM), named RC-LLM, is proposed. A residual-like hierarchical fusion structure is designed to integrate multi-source telemetry data, while the contextual reasoning capability of large language models is leveraged to model temporal and cross-microservice causal dependencies. Experimental results on CCF-AIOps microservice datasets demonstrate that RC-LLM achieves strong accuracy and efficiency in root cause analysis.",
      "tldr_zh": "该研究针对大规模微服务架构中因复杂的故障传播和高维遥测数据（metrics, logs, traces）导致的根因定位难题，提出了 RC-LLM 方法。该方法设计了一种类似残差的层次化融合结构(Residual-like hierarchical fusion structure)来整合多源遥测数据，并利用大语言模型(LLM)的上下文推理能力来建模时间维度和跨微服务的因果依赖关系。通过在 CCF-AIOps 微服务数据集上进行实验，结果证明 RC-LLM 在 Root Cause Analysis (RCA) 任务中具备极高的准确性与执行效率。该框架为处理微服务环境下的复杂系统运维提供了一种基于生成式人工智能的新思路。",
      "categories": [
        "cs.AI"
      ],
      "primary_category": "cs.AI",
      "comment": "",
      "pdf_url": "https://arxiv.org/pdf/2602.08804v1",
      "published_date": "2026-02-09 15:41:55 UTC",
      "updated_date": "2026-02-09 15:41:55 UTC",
      "processing_status": "completed",
      "attempts": 1,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "llm_backup_calls": 0,
      "last_update": "2026-02-16T04:48:55.707131+00:00"
    },
    {
      "arxiv_id": "2602.08797v1",
      "title": "Addressing data annotation scarcity in Brain Tumor Segmentation on 3D MRI scan Using a Semi-Supervised Teacher-Student Framework",
      "title_zh": "基于半监督教师-学生框架应对 3D MRI 脑肿瘤分割中的数据标注稀缺问题",
      "authors": [
        "Jiaming Liu",
        "Cheng Ding",
        "Daoqiang Zhang"
      ],
      "abstract": "Accurate brain tumor segmentation from MRI is limited by expensive annotations and data heterogeneity across scanners and sites. We propose a semi-supervised teacher-student framework that combines an uncertainty-aware pseudo-labeling teacher with a progressive, confidence-based curriculum for the student. The teacher produces probabilistic masks and per-pixel uncertainty; unlabeled scans are ranked by image-level confidence and introduced in stages, while a dual-loss objective trains the student to learn from high-confidence regions and unlearn low-confidence ones. Agreement-based refinement further improves pseudo-label quality. On BraTS 2021, validation DSC increased from 0.393 (10% data) to 0.872 (100%), with the largest gains in early stages, demonstrating data efficiency. The teacher reached a validation DSC of 0.922, and the student surpassed the teacher on tumor subregions (e.g., NCR/NET 0.797 and Edema 0.980); notably, the student recovered the Enhancing class (DSC 0.620) where the teacher failed. These results show that confidence-driven curricula and selective unlearning provide robust segmentation under limited supervision and noisy pseudo-labels.",
      "tldr_zh": "该研究针对MRI脑肿瘤分割中3D扫描标注稀缺和数据异构性的问题，提出了一种半监督的Teacher-Student框架。该框架由具备不确定性感知能力的伪标签Teacher模型与基于置信度的渐进式课程学习Student模型组成，并通过一致性精炼(Agreement-based refinement)进一步提升伪标签质量。Teacher模型输出像素级不确定性，而Student模型利用双重损失函数学习高置信度区域并识别卸载低置信度噪声。在BraTS 2021数据集上的实验显示，验证集的Dice相似系数(DSC)从0.393显著提升至0.872，展现了极高的数据利用效率。Student模型在肿瘤子区域（如NCR/NET、Edema）的分割精度上超越了Teacher模型，并成功修复了Teacher模型失效的Enhancing类别。该研究证明了置信度驱动的课程学习与选择性卸载机制在有限监督和噪声伪标签环境下实现稳健分割的有效性。",
      "categories": [
        "cs.CV",
        "cs.AI"
      ],
      "primary_category": "cs.CV",
      "comment": "10 pages, 7 figures. Submitted to IEEE Journal of Biomedical and Health Informatics (JBHI)",
      "pdf_url": "https://arxiv.org/pdf/2602.08797v1",
      "published_date": "2026-02-09 15:37:40 UTC",
      "updated_date": "2026-02-09 15:37:40 UTC",
      "processing_status": "completed",
      "attempts": 1,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "llm_backup_calls": 0,
      "last_update": "2026-02-16T04:48:46.804644+00:00"
    },
    {
      "arxiv_id": "2602.08796v1",
      "title": "The Use of AI Tools to Develop and Validate Q-Matrices",
      "title_zh": "利用人工智能工具开发与验证Q矩阵",
      "authors": [
        "Kevin Fan",
        "Jacquelyn A. Bialo",
        "Hongli Li"
      ],
      "abstract": "Constructing a Q-matrix is a critical but labor-intensive step in cognitive diagnostic modeling (CDM). This study investigates whether AI tools (i.e., general language models) can support Q-matrix development by comparing AI-generated Q-matrices with a validated Q-matrix from Li and Suen (2013) for a reading comprehension test. In May 2025, multiple AI models were provided with the same training materials as human experts. Agreement among AI-generated Q-matrices, the validated Q-matrix, and human raters' Q-matrices was assessed using Cohen's kappa. Results showed substantial variation across AI models, with Google Gemini 2.5 Pro achieving the highest agreement (Kappa = 0.63) with the validated Q-matrix, exceeding that of all human experts. A follow-up analysis in January 2026 using newer AI versions, however, revealed lower agreement with the validated Q-matrix. Implications and directions for future research are discussed.",
      "tldr_zh": "该研究探讨了通用语言模型等 AI 工具在认知诊断模型 (CDM) 中辅助开发和验证 Q-矩阵 (Q-matrix) 的有效性，旨在减轻该过程的人力成本。研究人员将多种 AI 模型生成的 Q-矩阵与已验证的标准矩阵及人类评分者的结果进行对比，并使用 Cohen's kappa 指标衡量一致性。实验发现，在 2025 年 5 月的测试中，Google Gemini 2.5 Pro 的表现最为出色，其一致性评分（Kappa = 0.63）超过了所有人类专家。然而，2026 年 1 月的后续分析显示，更新后的 AI 版本与验证矩阵的一致性反而有所下降。这项研究揭示了 AI 在自动化心理测量任务中的潜力，同时也提示了模型版本更迭对结果准确性的复杂影响，为未来相关研究提供了方向。",
      "categories": [
        "cs.AI",
        "cs.CL"
      ],
      "primary_category": "cs.AI",
      "comment": "An earlier version of this study was presented at the Psychometric Society Meeting held in July 2025 in Minneapolis, USA",
      "pdf_url": "https://arxiv.org/pdf/2602.08796v1",
      "published_date": "2026-02-09 15:36:53 UTC",
      "updated_date": "2026-02-09 15:36:53 UTC",
      "processing_status": "completed",
      "attempts": 1,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "llm_backup_calls": 0,
      "last_update": "2026-02-16T04:49:04.605476+00:00"
    },
    {
      "arxiv_id": "2602.08792v1",
      "title": "Multimodal Learning for Arcing Detection in Pantograph-Catenary Systems",
      "title_zh": "受电弓-接触网系统燃弧检测的多模态学习",
      "authors": [
        "Hao Dong",
        "Eleni Chatzi",
        "Olga Fink"
      ],
      "abstract": "The pantograph-catenary interface is essential for ensuring uninterrupted and reliable power delivery in electrified rail systems. However, electrical arcing at this interface poses serious risks, including accelerated wear of contact components, degraded system performance, and potential service disruptions. Detecting arcing events at the pantograph-catenary interface is challenging due to their transient nature, noisy operating environment, data scarcity, and the difficulty of distinguishing arcs from other similar transient phenomena. To address these challenges, we propose a novel multimodal framework that combines high-resolution image data with force measurements to more accurately and robustly detect arcing events. First, we construct two arcing detection datasets comprising synchronized visual and force measurements. One dataset is built from data provided by the Swiss Federal Railways (SBB), and the other is derived from publicly available videos of arcing events in different railway systems and synthetic force data that mimic the characteristics observed in the real dataset. Leveraging these datasets, we propose MultiDeepSAD, an extension of the DeepSAD algorithm for multiple modalities with a new loss formulation. Additionally, we introduce tailored pseudo-anomaly generation techniques specific to each data type, such as synthetic arc-like artifacts in images and simulated force irregularities, to augment training data and improve the discriminative ability of the model. Through extensive experiments and ablation studies, we demonstrate that our framework significantly outperforms baseline approaches, exhibiting enhanced sensitivity to real arcing events even under domain shifts and limited availability of real arcing observations.",
      "tldr_zh": "该研究针对电力铁路受电弓-接触网系统(pantograph-catenary system)中的电弧检测(arcing detection)难题，提出了一种结合高分辨率图像数据和力测量(force measurements)的新型多模态学习框架。该框架旨在解决电弧事件的瞬时性、运行环境噪声、数据稀缺以及难以区分电弧与其他相似现象的挑战。研究团队构建了两个包含同步视觉和力测量的电弧检测数据集，分别源自瑞士联邦铁路(SBB)的真实数据以及由公开视频和模拟力数据组成的合成数据集。基于这些数据，研究提出了MultiDeepSAD算法，该算法是DeepSAD算法在多模态领域的扩展，并引入了全新的损失函数(loss formulation)。此外，研究还通过针对图像和力数据的伪异常生成技术(pseudo-anomaly generation)来增强训练数据，提升了模型的辨别能力。实验结果证明，该框架在性能上显著优于基线模型，即使在领域漂移(domain shifts)和真实电弧观测有限的情况下，也能对真实电弧事件保持极高的检测灵敏度。",
      "categories": [
        "cs.CV",
        "cs.AI",
        "cs.LG"
      ],
      "primary_category": "cs.CV",
      "comment": "",
      "pdf_url": "https://arxiv.org/pdf/2602.08792v1",
      "published_date": "2026-02-09 15:29:19 UTC",
      "updated_date": "2026-02-09 15:29:19 UTC",
      "processing_status": "completed",
      "attempts": 1,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "llm_backup_calls": 0,
      "last_update": "2026-02-16T04:49:01.797221+00:00"
    },
    {
      "arxiv_id": "2602.08783v1",
      "title": "Dynamics Within Latent Chain-of-Thought: An Empirical Study of Causal Structure",
      "title_zh": "隐式思维链内部的动态机制：因果结构的实证研究",
      "authors": [
        "Zirui Li",
        "Xuefeng Bai",
        "Kehai Chen",
        "Yizhi Li",
        "Jian Yang",
        "Chenghua Lin",
        "Min Zhang"
      ],
      "abstract": "Latent or continuous chain-of-thought methods replace explicit textual rationales with a number of internal latent steps, but these intermediate computations are difficult to evaluate beyond correlation-based probes. In this paper, we view latent chain-of-thought as a manipulable causal process in representation space by modeling latent steps as variables in a structural causal model (SCM) and analyzing their effects through step-wise $\\mathrm{do}$-interventions. We study two representative paradigms (i.e., Coconut and CODI) on both mathematical and general reasoning tasks to investigate three key questions: (1) which steps are causally necessary for correctness and when answers become decidable early; (2) how does influence propagate across steps, and how does this structure compare to explicit CoT; and (3) do intermediate trajectories retain competing answer modes, and how does output-level commitment differ from representational commitment across steps. We find that latent-step budgets behave less like homogeneous extra depth and more like staged functionality with non-local routing, and we identify a persistent gap between early output bias and late representational commitment. These results motivate mode-conditional and stability-aware analyses -- and corresponding training/decoding objectives -- as more reliable tools for interpreting and improving latent reasoning systems.",
      "tldr_zh": "该研究探讨了隐式思维链(Latent Chain-of-Thought)中的动态过程，通过将中间隐步建模为结构因果模型(SCM)中的变量，并利用步进式do-interventions分析其因果结构。作者针对Coconut和CODI两种代表性范式，在数学和通用推理任务上深入研究了隐步的因果必要性、影响传播路径以及表征承诺的演变。研究发现，隐步预算并非简单的同质深度增加，而是表现为具有非局部路由(non-local routing)的阶段化功能，并揭示了早期输出偏好与后期表征承诺之间存在显著且持续的偏差。这些结果表明，模式条件(mode-conditional)和稳定性感知(stability-aware)的分析方法以及相应的训练与解码目标，是解释和改进隐式推理系统更为可靠的工具。",
      "categories": [
        "cs.AI",
        "cs.CL"
      ],
      "primary_category": "cs.AI",
      "comment": "22 pages",
      "pdf_url": "https://arxiv.org/pdf/2602.08783v1",
      "published_date": "2026-02-09 15:25:12 UTC",
      "updated_date": "2026-02-09 15:25:12 UTC",
      "processing_status": "completed",
      "attempts": 1,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "llm_backup_calls": 0,
      "last_update": "2026-02-16T04:49:25.501022+00:00"
    },
    {
      "arxiv_id": "2602.08774v1",
      "title": "Default Machine Learning Hyperparameters Do Not Provide Informative Initialization for Bayesian Optimization",
      "title_zh": "机器学习默认超参数并未为贝叶斯优化提供有效的初始化信息",
      "authors": [
        "Nicolás Villagrán Prieto",
        "Eduardo C. Garrido-Merchán"
      ],
      "abstract": "Bayesian Optimization (BO) is a standard tool for hyperparameter tuning thanks to its sample efficiency on expensive black-box functions. While most BO pipelines begin with uniform random initialization, default hyperparameter values shipped with popular ML libraries such as scikit-learn encode implicit expert knowledge and could serve as informative starting points that accelerate convergence. This hypothesis, despite its intuitive appeal, has remained largely unexamined. We formalize the idea by initializing BO with points drawn from truncated Gaussian distributions centered at library defaults and compare the resulting trajectories against a uniform-random baseline. We conduct an extensive empirical evaluation spanning three BO back-ends (BoTorch, Optuna, Scikit-Optimize), three model families (Random Forests, Support Vector Machines, Multilayer Perceptrons), and five benchmark datasets covering classification and regression tasks. Performance is assessed through convergence speed and final predictive quality, and statistical significance is determined via one-sided binomial tests. Across all conditions, default-informed initialization yields no statistically significant advantage over purely random sampling, with p-values ranging from 0.141 to 0.908. A sensitivity analysis on the prior variance confirms that, while tighter concentration around the defaults improves early evaluations, this transient benefit vanishes as optimization progresses, leaving final performance unchanged. Our results provide no evidence that default hyperparameters encode useful directional information for optimization. We therefore recommend that practitioners treat hyperparameter tuning as an integral part of model development and favor principled, data-driven search strategies over heuristic reliance on library defaults.",
      "tldr_zh": "该研究探讨了流行的机器学习(ML)库中的默认超参数值是否能作为贝叶斯优化(Bayesian Optimization)的有效初始化起点，以加速收敛。研究者通过从以库默认值为中心的截断高斯分布(truncated Gaussian distributions)中采样来初始化BO，并在三种BO后端(BoTorch, Optuna, Scikit-Optimize)和三种模型族(Random Forests, Support Vector Machines, Multilayer Perceptrons)上进行了广泛的实证评估。实验将该方法与均匀随机初始化(uniform-random baseline)进行了对比，通过收敛速度和最终预测质量来衡量性能。统计结果表明，在所有实验条件下，基于默认值的初始化相比纯随机采样并无显著优势，其p值处于0.141至0.908之间。敏感性分析进一步证实，尽管在默认值附近更紧密采样能改善早期评估，但这种短暂收益会随着优化推进而消失。最终研究结论认为，默认超参数未能提供有用的优化方向信息，建议从业者应采用原则性的数据驱动搜索策略，而非启发式地依赖库默认设置。",
      "categories": [
        "cs.LG",
        "cs.AI"
      ],
      "primary_category": "cs.LG",
      "comment": "",
      "pdf_url": "https://arxiv.org/pdf/2602.08774v1",
      "published_date": "2026-02-09 15:15:52 UTC",
      "updated_date": "2026-02-09 15:15:52 UTC",
      "processing_status": "completed",
      "attempts": 1,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "llm_backup_calls": 0,
      "last_update": "2026-02-16T04:49:37.407687+00:00"
    },
    {
      "arxiv_id": "2602.08768v1",
      "title": "FreqLens: Interpretable Frequency Attribution for Time Series Forecasting",
      "title_zh": "FreqLens：面向时间序列预测的可解释频率归因",
      "authors": [
        "Chi-Sheng Chen",
        "Xinyu Zhang",
        "En-Jui Kuo",
        "Guan-Ying Chen",
        "Qiuzhe Xie",
        "Fan Zhang"
      ],
      "abstract": "Time series forecasting models often lack interpretability, limiting their adoption in domains requiring explainable predictions. We propose \\textsc{FreqLens}, an interpretable forecasting framework that discovers and attributes predictions to learnable frequency components. \\textsc{FreqLens} introduces two key innovations: (1) \\emph{learnable frequency discovery} -- frequency bases are parameterized via sigmoid mapping and learned from data with diversity regularization, enabling automatic discovery of dominant periodic patterns without domain knowledge; and (2) \\emph{axiomatic frequency attribution} -- a theoretically grounded framework that provably satisfies Completeness, Faithfulness, Null-Frequency, and Symmetry axioms, with per-frequency attributions equivalent to Shapley values. On Traffic and Weather datasets, \\textsc{FreqLens} achieves competitive or superior performance while discovering physically meaningful frequencies: all 5 independent runs discover the 24-hour daily cycle ($24.6 \\pm 0.1$h, 2.5\\% error) and 12-hour half-daily cycle ($11.8 \\pm 0.1$h, 1.6\\% error) on Traffic, and weekly cycles ($10\\times$ longer than the input window) on Weather. These results demonstrate genuine frequency-level knowledge discovery with formal theoretical guarantees on attribution quality.",
      "tldr_zh": "该研究提出了 FreqLens，一种用于时间序列预测的可解释性框架，旨在通过发现和归因可学习的频率组件来增强预测的透明度。FreqLens 包含两大核心创新：首先是可学习频率发现 (learnable frequency discovery)，通过 sigmoid 映射和多样性正则化 (diversity regularization) 自动识别数据中的主导周期模式；其次是公理化频率归因 (axiomatic frequency attribution) 框架，该框架在理论上满足完备性 (Completeness) 和忠实性 (Faithfulness) 等公理，且其归因结果等同于 Shapley values。在 Traffic 和 Weather 数据集上的实验证明，FreqLens 在保持预测性能竞争力的同时，能够准确识别出如 24 小时和 12 小时周期等具有物理意义的频率。该研究不仅实现了频率级别的知识发现，还为归因质量提供了正式的理论保障，为需要高解释性的领域提供了有效的预测工具。",
      "categories": [
        "cs.LG",
        "cs.AI",
        "eess.SP"
      ],
      "primary_category": "cs.LG",
      "comment": "",
      "pdf_url": "https://arxiv.org/pdf/2602.08768v1",
      "published_date": "2026-02-09 15:08:53 UTC",
      "updated_date": "2026-02-09 15:08:53 UTC",
      "processing_status": "completed",
      "attempts": 1,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "llm_backup_calls": 0,
      "last_update": "2026-02-16T04:49:44.506988+00:00"
    },
    {
      "arxiv_id": "2602.08765v1",
      "title": "Taming Scylla: Understanding the multi-headed agentic daemon of the coding seas",
      "title_zh": "驯服 Scylla：深度解析编程领域的“多头智能体魔怪”",
      "authors": [
        "Micah Villmow"
      ],
      "abstract": "LLM-based tools are automating more software development tasks at a rapid pace, but there is no rigorous way to evaluate how different architectural choices -- prompts, skills, tools, multi-agent setups -- materially affect both capability and cost. This paper introduces Scylla, an evaluation framework for benchmarking agentic coding tools through structured ablation studies that uses seven testing tiers (T0-T6) progressively adding complexity to isolate what directly influences results and how. The key metric is Cost-of-Pass (CoP): the expected dollar cost to get one correct solution, which directly quantifies the trade-off between complexity and efficiency. The framework is model-agnostic, designed to work with any CLI tool; this paper demonstrates it with Claude Sonnet 4.5, using multiple LLM judges (Opus 4.5, Sonnet 4.5, Haiku 4.5) from the same vendor for evaluation consensus, where judges score results using direct tests, human-designed LLM-evaluated rubrics, and qualitative assessment. The result is a reproducible framework that quantifies trade-offs between agent complexity and actual outcomes, suggesting that architectural complexity does not always improve quality.",
      "tldr_zh": "该研究针对基于大语言模型(LLM)的软件开发自动化工具缺乏严谨评估方法的问题，提出了Scylla评价框架。Scylla通过从T0到T6的七个测试层级进行结构化消融研究(ablation studies)，旨在分析提示词、技能、工具及多智能体(multi-agent)设置等架构选择对性能与成本的具体影响。研究引入了关键指标Cost-of-Pass (CoP)，通过计算获得单个正确方案的预期美元成本，量化了系统复杂性与效率之间的权衡。该框架具有模型无关性(model-agnostic)，在Claude Sonnet 4.5上的实验通过多模型评审(Opus 4.5, Sonnet 4.5, Haiku 4.5)确保了评估的一致性。实验结果表明，Scylla能够有效量化智能体复杂性与实际产出之间的关系，并揭示了架构的复杂化并不总是能提升软件生成的质量。",
      "categories": [
        "cs.SE",
        "cs.AI"
      ],
      "primary_category": "cs.SE",
      "comment": "32 Pages, 7 Figures",
      "pdf_url": "https://arxiv.org/pdf/2602.08765v1",
      "published_date": "2026-02-09 15:06:24 UTC",
      "updated_date": "2026-02-09 15:06:24 UTC",
      "processing_status": "completed",
      "attempts": 1,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "llm_backup_calls": 0,
      "last_update": "2026-02-16T04:49:44.905938+00:00"
    },
    {
      "arxiv_id": "2602.08764v1",
      "title": "Efficient Brain Extraction of MRI Scans with Mild to Moderate Neuropathology",
      "title_zh": "针对轻至中度神经病理表现的 MRI 扫描高效脑提取方法",
      "authors": [
        "Hjalti Thrastarson",
        "Lotta M. Ellingsen"
      ],
      "abstract": "Skull stripping magnetic resonance images (MRI) of the human brain is an important process in many image processing techniques, such as automatic segmentation of brain structures. Numerous methods have been developed to perform this task, however, they often fail in the presence of neuropathology and can be inconsistent in defining the boundary of the brain mask. Here, we propose a novel approach to skull strip T1-weighted images in a robust and efficient manner, aiming to consistently segment the outer surface of the brain, including the sulcal cerebrospinal fluid (CSF), while excluding the full extent of the subarachnoid space and meninges. We train a modified version of the U-net on silver-standard ground truth data using a novel loss function based on the signed-distance transform (SDT). We validate our model both qualitatively and quantitatively using held-out data from the training dataset, as well as an independent external dataset. The brain masks used for evaluation partially or fully include the subarachnoid space, which may introduce bias into the comparison; nonetheless, our model demonstrates strong performance on the held-out test data, achieving a consistent mean Dice similarity coefficient (DSC) of 0.964$\\pm$0.006 and an average symmetric surface distance (ASSD) of 1.4mm$\\pm$0.2mm. Performance on the external dataset is comparable, with a DSC of 0.958$\\pm$0.006 and an ASSD of 1.7$\\pm$0.2mm. Our method achieves performance comparable to or better than existing state-of-the-art methods for brain extraction, particularly in its highly consistent preservation of the brain's outer surface. The method is publicly available on GitHub.",
      "tldr_zh": "该研究针对人类大脑磁共振成像（MRI）在存在神经病理学（Neuropathology）时，传统颅骨剥离（Skull stripping）方法容易失效且边界定义不一致的问题，提出了一种新型的T1加权图像提取方案。该方法利用改进的U-net架构，并结合基于符号距离变换（Signed-distance transform, SDT）的损失函数，在银标准（Silver-standard）数据上进行训练，旨在精确分割包含脑沟脑脊液（Sulcal CSF）的大脑外表面。实验验证表明，该模型在内部和外部数据集上均表现出高度的稳健性，分别达到了0.964和0.958的平均Dice相似系数（DSC）。研究结果证明，该方法在保持大脑外表面一致性方面优于或等同于现有的先进技术，为具有轻中度神经病理的大脑提取提供了高效的解决方案。该项目代码已在GitHub开源。",
      "categories": [
        "eess.IV",
        "cs.AI",
        "cs.CV"
      ],
      "primary_category": "eess.IV",
      "comment": "Accepted for publication in the Proceedings of SPIE Medical Imaging 2026",
      "pdf_url": "https://arxiv.org/pdf/2602.08764v1",
      "published_date": "2026-02-09 15:03:30 UTC",
      "updated_date": "2026-02-09 15:03:30 UTC",
      "processing_status": "completed",
      "attempts": 1,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "llm_backup_calls": 0,
      "last_update": "2026-02-16T04:49:50.408088+00:00"
    },
    {
      "arxiv_id": "2602.08754v1",
      "title": "Belief Offloading in Human-AI Interaction",
      "title_zh": "人机交互中的信念卸载",
      "authors": [
        "Rose E. Guingrich",
        "Dvija Mehta",
        "Umang Bhatt"
      ],
      "abstract": "What happens when people's beliefs are derived from information provided by an LLM? People's use of LLM chatbots as thought partners can contribute to cognitive offloading, which can have adverse effects on cognitive skills in cases of over-reliance. This paper defines and investigates a particular kind of cognitive offloading in human-AI interaction, \"belief offloading,\" in which people's processes of forming and upholding beliefs are offloaded onto an AI system with downstream consequences on their behavior and the nature of their system of beliefs. Drawing on philosophy, psychology, and computer science research, we clarify the boundary conditions under which belief offloading occurs and provide a descriptive taxonomy of belief offloading and its normative implications. We close with directions for future work to assess the potential for and consequences of belief offloading in human-AI interaction.",
      "tldr_zh": "该研究探讨了人类与人工智能（AI）交互中的一种特定认知卸载（cognitive offloading）现象，即“信念卸载”（belief offloading）。信念卸载是指个体将形成和维持信念的过程转移给AI系统，进而对其行为和信念系统的本质产生下游影响。本文结合了哲学、心理学和计算机科学的多学科视角，明确了信念卸载发生的边界条件，并提供了一个描述性的分类法（taxonomy）及其规范性影响（normative implications）。研究强调，当大语言模型（LLM）被用作思考伙伴时，过度依赖可能导致认知技能受损。文章最后提出了评估信念卸载潜力及其后果的未来研究方向，为理解AI如何重塑人类信念体系提供了重要的理论基础。",
      "categories": [
        "cs.AI",
        "cs.CY",
        "cs.HC"
      ],
      "primary_category": "cs.AI",
      "comment": "",
      "pdf_url": "https://arxiv.org/pdf/2602.08754v1",
      "published_date": "2026-02-09 14:56:39 UTC",
      "updated_date": "2026-02-09 14:56:39 UTC",
      "processing_status": "completed",
      "attempts": 1,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "llm_backup_calls": 0,
      "last_update": "2026-02-16T04:50:20.410020+00:00"
    },
    {
      "arxiv_id": "2602.10145v1",
      "title": "Silence Routing: When Not Speaking Improves Collective Judgment",
      "title_zh": "沉默路由：缄默何时能优化集体判断",
      "authors": [
        "Itsuki Fujisaki",
        "Kunhao Yang"
      ],
      "abstract": "The wisdom of crowds has been shown to operate not only for factual judgments but also in matters of taste, where accuracy is defined relative to an individual's preferences. However, it remains unclear how different types of social signals should be selectively used in such domains. Focusing on a music preference dataset in which contributors provide both personal evaluations (Own) and estimates of population-level preferences (Estimated), we propose a routing framework for collective intelligence in taste. The framework specifies when contributors should speak, what they should report, and when silence is preferable. Using simulation-based aggregation, we show that prediction accuracy improves over an all-own baseline across a broad region of the parameter space, conditional on items where routing applies. Importantly, these gains arise only when silence is allowed, enabling second-order signals to function effectively. The results demonstrate that collective intelligence in matters of taste depends on principled signal routing rather than simple averaging.",
      "tldr_zh": "该研究探讨了在大众智慧(wisdom of crowds)领域中，如何针对涉及个人品味的审美判断进行社交信号的选择性使用。作者提出了一个针对品味领域的集体智能路由框架(routing framework)，旨在明确贡献者何时应当发言、报告何种内容，以及何时保持沉默(silence)更为理想。该研究利用音乐偏好数据集，结合个人评估(Own)和对群体偏好的估计(Estimated)，通过基于模拟的聚合(simulation-based aggregation)方法验证了框架的有效性。实验结果表明，在允许沉默的情况下，该框架在广泛的参数空间内均能显著提高预测准确率，并优于仅基于个人评估(all-own)的基准模型。沉默的选择使得二阶信号(second-order signals)能够有效发挥作用，从而大幅优化了集体判断。该发现证明，品味领域的集体智能取决于有原则的信号路由(principled signal routing)，而非简单的平均计算(simple averaging)。",
      "categories": [
        "physics.soc-ph",
        "cs.AI",
        "cs.IR"
      ],
      "primary_category": "physics.soc-ph",
      "comment": "7pages, 2 figures",
      "pdf_url": "https://arxiv.org/pdf/2602.10145v1",
      "published_date": "2026-02-09 14:52:28 UTC",
      "updated_date": "2026-02-09 14:52:28 UTC",
      "processing_status": "completed",
      "attempts": 1,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "llm_backup_calls": 0,
      "last_update": "2026-02-16T04:50:25.496448+00:00"
    },
    {
      "arxiv_id": "2602.08745v1",
      "title": "On the Expressive Power of GNNs for Boolean Satisfiability",
      "title_zh": "论图神经网络对布尔可满足性问题的表达能力",
      "authors": [
        "Saku Peltonen",
        "Roger Wattenhofer"
      ],
      "abstract": "Machine learning approaches to solving Boolean Satisfiability (SAT) aim to replace handcrafted heuristics with learning-based models. Graph Neural Networks have emerged as the main architecture for SAT solving, due to the natural graph representation of Boolean formulas. We analyze the expressive power of GNNs for SAT solving through the lens of the Weisfeiler-Leman (WL) test. As our main result, we prove that the full WL hierarchy cannot, in general, distinguish between satisfiable and unsatisfiable instances. We show that indistinguishability under higher-order WL carries over to practical limitations for WL-bounded solvers that set variables sequentially. We further study the expressivity required for several important families of SAT instances, including regular, random and planar instances. To quantify expressivity needs in practice, we conduct experiments on random instances from the G4SAT benchmark and industrial instances from the International SAT Competition. Our results suggest that while random instances are largely distinguishable, industrial instances often require more expressivity to predict a satisfying assignment.",
      "tldr_zh": "该研究通过 Weisfeiler-Leman (WL) 测试的角度分析了图神经网络 (GNNs) 在解决布尔可满足性问题 (Boolean Satisfiability, SAT) 时的表达能力。其核心结论证明了完整的 WL 层次结构在通常情况下无法区分可满足 (satisfiable) 和不可满足 (unsatisfiable) 的实例，且这种不可区分性导致受 WL 限制的顺序变量设置求解器在实践中存在局限性。论文进一步探讨了正则、随机和平面等不同 SAT 实例族所需的表达能力。实验结果显示，虽然 G4SAT 基准中的随机实例大多是可区分的，但来自国际 SAT 竞赛的工业实例通常需要更强的表达能力来准确预测其可满足赋值。该研究揭示了当前基于 GNN 的 SAT 求解器在处理复杂工业实例时的内在表达瓶颈，为未来设计更强大的模型提供了理论指导。",
      "categories": [
        "cs.LG",
        "cs.AI"
      ],
      "primary_category": "cs.LG",
      "comment": "Accepted at ICLR 2026",
      "pdf_url": "https://arxiv.org/pdf/2602.08745v1",
      "published_date": "2026-02-09 14:48:16 UTC",
      "updated_date": "2026-02-09 14:48:16 UTC",
      "processing_status": "completed",
      "attempts": 1,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "llm_backup_calls": 0,
      "last_update": "2026-02-16T04:50:34.902827+00:00"
    },
    {
      "arxiv_id": "2602.08734v1",
      "title": "Finite-State Controllers for (Hidden-Model) POMDPs using Deep Reinforcement Learning",
      "title_zh": "基于深度强化学习的（隐模型）部分可观测马尔可夫决策过程有限状态控制器",
      "authors": [
        "David Hudák",
        "Maris F. L. Galesloot",
        "Martin Tappler",
        "Martin Kurečka",
        "Nils Jansen",
        "Milan Češka"
      ],
      "abstract": "Solving partially observable Markov decision processes (POMDPs) requires computing policies under imperfect state information. Despite recent advances, the scalability of existing POMDP solvers remains limited. Moreover, many settings require a policy that is robust across multiple POMDPs, further aggravating the scalability issue. We propose the Lexpop framework for POMDP solving. Lexpop (1) employs deep reinforcement learning to train a neural policy, represented by a recurrent neural network, and (2) constructs a finite-state controller mimicking the neural policy through efficient extraction methods. Crucially, unlike neural policies, such controllers can be formally evaluated, providing performance guarantees. We extend Lexpop to compute robust policies for hidden-model POMDPs (HM-POMDPs), which describe finite sets of POMDPs. We associate every extracted controller with its worst-case POMDP. Using a set of such POMDPs, we iteratively train a robust neural policy and consequently extract a robust controller. Our experiments show that on problems with large state spaces, Lexpop outperforms state-of-the-art solvers for POMDPs as well as HM-POMDPs.",
      "tldr_zh": "该研究提出了 Lexpop 框架，旨在解决部分可观测马尔可夫决策过程 (POMDPs) 在求解时的扩展性难题，以及在多个模型下的鲁棒性需求。Lexpop 利用深度强化学习 (Deep Reinforcement Learning) 训练一个基于循环神经网络 (RNN) 的神经策略，并通过高效的提取方法将其转化为有限状态控制器 (Finite-State Controller)。与单纯的神经策略不同，此类控制器支持形式化评估，能够提供性能保证。该框架进一步扩展到隐模型 POMDPs (HM-POMDPs) 领域，通过关联受阻控制器与其最差情况下的 POMDP，迭代训练出具备强鲁棒性的策略。实验结果表明，在大规模状态空间问题上，Lexpop 的表现优于现有的各类先进 POMDP 及 HM-POMDP 求解器。",
      "categories": [
        "cs.AI"
      ],
      "primary_category": "cs.AI",
      "comment": "17 pages (8 main paper, 2 references, 7 appendix). 3 figures in the main paper, 3 figures in the appendix. Accepted AAMAS'26 submission",
      "pdf_url": "https://arxiv.org/pdf/2602.08734v1",
      "published_date": "2026-02-09 14:39:16 UTC",
      "updated_date": "2026-02-09 14:39:16 UTC",
      "processing_status": "completed",
      "attempts": 1,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "llm_backup_calls": 0,
      "last_update": "2026-02-16T04:50:36.900526+00:00"
    },
    {
      "arxiv_id": "2602.08727v1",
      "title": "Artifact Reduction in Undersampled 3D Cone-Beam CTs using a Hybrid 2D-3D CNN Framework",
      "title_zh": "基于混合 2D-3D CNN 框架的欠采样 3D 锥形束 CT 伪影去除方法",
      "authors": [
        "Johannes Thalhammer",
        "Tina Dorosti",
        "Sebastian Peterhansl",
        "Daniela Pfeiffer",
        "Franz Pfeiffer",
        "Florian Schaff"
      ],
      "abstract": "Undersampled CT volumes minimize acquisition time and radiation exposure but introduce artifacts degrading image quality and diagnostic utility. Reducing these artifacts is critical for high-quality imaging. We propose a computationally efficient hybrid deep-learning framework that combines the strengths of 2D and 3D models. First, a 2D U-Net operates on individual slices of undersampled CT volumes to extract feature maps. These slice-wise feature maps are then stacked across the volume and used as input to a 3D decoder, which utilizes contextual information across slices to predict an artifact-free 3D CT volume. The proposed two-stage approach balances the computational efficiency of 2D processing with the volumetric consistency provided by 3D modeling. The results show substantial improvements in inter-slice consistency in coronal and sagittal direction with low computational overhead. This hybrid framework presents a robust and efficient solution for high-quality 3D CT image post-processing. The code of this project can be found on github: https://github.com/J-3TO/2D-3DCNN_sparseview/.",
      "tldr_zh": "该研究提出了一种混合 2D-3D CNN 框架，旨在解决欠采样三维圆锥束 CT (3D Cone-Beam CT) 产生的伪影问题。该框架首先通过 2D U-Net 处理单个切片以提取特征图，随后将这些切片特征图堆叠，输入至 3D Decoder 中以利用层间上下文信息预测无伪影的 3D CT 图像。这种两阶段方法有效结合了 2D 处理的计算效率与 3D 建模的体积一致性。实验结果表明，该方法在保持较低计算开销的同时，显著提升了冠状面和矢状面方向的层间一致性。这一鲁棒且高效的混合框架为高质量 3D CT 图像后处理提供了可靠的解决方案。",
      "categories": [
        "cs.CV",
        "cs.AI"
      ],
      "primary_category": "cs.CV",
      "comment": "",
      "pdf_url": "https://arxiv.org/pdf/2602.08727v1",
      "published_date": "2026-02-09 14:36:05 UTC",
      "updated_date": "2026-02-09 14:36:05 UTC",
      "processing_status": "completed",
      "attempts": 1,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "llm_backup_calls": 0,
      "last_update": "2026-02-16T04:50:44.601418+00:00"
    },
    {
      "arxiv_id": "2602.08722v1",
      "title": "QUOKA: Query-Oriented KV Selection For Efficient LLM Prefill",
      "title_zh": "QUOKA：面向高效 LLM 预填充的查询导向型 KV 选择",
      "authors": [
        "Dalton Jones",
        "Junyoung Park",
        "Matthew Morse",
        "Mingu Lee",
        "Chris Lott",
        "Harper Langston"
      ],
      "abstract": "We present QUOKA: Query-oriented KV selection for efficient attention, a training-free and hardware agnostic sparse attention algorithm for accelerating transformer inference under chunked prefill. While many queries focus on a smaller group of keys in the attention operator, we observe that queries with low cosine similarity with respect to the mean query interact more strongly with more keys and have the greatest contribution to final attention logits. By prioritizing these low cosine similarity queries, the behavior of full attention during the prefill stage can be closely approximated. QUOKA leverages this observation, accelerating attention by (1) first retaining a small set of representative queries and (2) then subselectin the keys most aligned with those queries. Through experiments on Needle-In-A-Haystack, LongBench, RULER, and Math500, we show that, while realizing a 3x reduction in time-to-first-token, 5x speedup in attention on Nvidia GPUs and up to nearly a 7x speedup on Intel Xeon CPUs, QUOKA achieves near-baseline accuracy, utilizing 88% fewer key-value pairs per attention evaluation.",
      "tldr_zh": "该研究提出了 QUOKA (Query-oriented KV selection for efficient attention)，一种无需训练且硬件无关的稀疏注意力算法，旨在加速 Transformer 推理过程中的分块预填充 (chunked prefill) 阶段。研究人员观察到，与平均查询 (mean query) 余弦相似度较低的查询对最终注意力对数 (attention logits) 的贡献最大，且与更多键 (keys) 产生更强的交互。QUOKA 利用这一发现，通过首先保留一小组具有代表性的查询，然后子选择与这些查询最匹配的键来优化计算过程。实验结果显示，该算法在 Needle-In-A-Haystack、LongBench 和 RULER 等基准测试中，在减少 88% 键值对 (KV pairs) 的情况下仍能保持接近基线的准确度。在性能提升方面，QUOKA 将首字延迟 (time-to-first-token) 缩短了 3 倍，并在 Nvidia GPU 和 Intel Xeon CPU 上分别实现了高达 5 倍和近 7 倍的注意力计算加速。",
      "categories": [
        "cs.LG",
        "cs.AI"
      ],
      "primary_category": "cs.LG",
      "comment": "",
      "pdf_url": "https://arxiv.org/pdf/2602.08722v1",
      "published_date": "2026-02-09 14:32:26 UTC",
      "updated_date": "2026-02-09 14:32:26 UTC",
      "processing_status": "completed",
      "attempts": 1,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "llm_backup_calls": 0,
      "last_update": "2026-02-16T04:51:17.807180+00:00"
    },
    {
      "arxiv_id": "2602.08717v1",
      "title": "Zero-shot System for Automatic Body Region Detection for Volumetric CT and MR Images",
      "title_zh": "容积 CT 与 MR 图像自动人体部位检测的零样本系统",
      "authors": [
        "Farnaz Khun Jush",
        "Grit Werner",
        "Mark Klemens",
        "Matthias Lenga"
      ],
      "abstract": "Reliable identification of anatomical body regions is a prerequisite for many automated medical imaging workflows, yet existing solutions remain heavily dependent on unreliable DICOM metadata. Current solutions mainly use supervised learning, which limits their applicability in many real-world scenarios. In this work, we investigate whether body region detection in volumetric CT and MR images can be achieved in a fully zero-shot manner by using knowledge embedded in large pre-trained foundation models. We propose and systematically evaluate three training-free pipelines: (1) a segmentation-driven rule-based system leveraging pre-trained multi-organ segmentation models, (2) a Multimodal Large Language Model (MLLM) guided by radiologist-defined rules, and (3) a segmentation-aware MLLM that combines visual input with explicit anatomical evidence. All methods are evaluated on 887 heterogeneous CT and MR scans with manually verified anatomical region labels. The segmentation-driven rule-based approach achieves the strongest and most consistent performance, with weighted F1-scores of 0.947 (CT) and 0.914 (MR), demonstrating robustness across modalities and atypical scan coverage. The MLLM performs competitively in visually distinctive regions, while the segmentation-aware MLLM reveals fundamental limitations.",
      "tldr_zh": "该研究探讨了在三维 CT 和 MR 图像中实现全零样本 (Zero-shot) 的解剖部位自动检测，旨在解决传统方法对不可靠 DICOM 元数据的依赖以及监督学习适用性受限的问题。作者提出并评估了三种无需训练的流程：基于分割驱动的规则系统、由放射科医生规则引导的多模态大语言模型 (MLLM) 以及结合视觉输入与解剖证据的分割感知 MLLM。通过对 887 个异构扫描件的验证，结果表明分割驱动的规则化方法表现最强且最稳定，在 CT 和 MR 中的加权 F1 分数分别达到 0.947 和 0.914。该方法在不同模态和非典型扫描覆盖范围内均表现出极高的鲁棒性。虽然 MLLM 在视觉显著区域具有竞争力，但研究揭示了分割感知 MLLM 的根本局限性。这一成果证明了利用预训练基础模型 (Foundation Models) 中嵌入的知识来实现零样本医疗影像识别的可行性。",
      "categories": [
        "cs.CV",
        "cs.AI"
      ],
      "primary_category": "cs.CV",
      "comment": "8 pages, 5 figures, 5 tables",
      "pdf_url": "https://arxiv.org/pdf/2602.08717v1",
      "published_date": "2026-02-09 14:26:24 UTC",
      "updated_date": "2026-02-09 14:26:24 UTC",
      "processing_status": "completed",
      "attempts": 1,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "llm_backup_calls": 0,
      "last_update": "2026-02-16T04:52:13.197932+00:00"
    },
    {
      "arxiv_id": "2602.08715v1",
      "title": "Exploring SAIG Methods for an Objective Evaluation of XAI",
      "title_zh": "探索用于 XAI 客观评估的 SAIG 方法",
      "authors": [
        "Miquel Miró-Nicolau",
        "Gabriel Moyà-Alcover",
        "Anna Arias-Duart"
      ],
      "abstract": "The evaluation of eXplainable Artificial Intelligence (XAI) methods is a rapidly growing field, characterized by a wide variety of approaches. This diversity highlights the complexity of the XAI evaluation, which, unlike traditional AI assessment, lacks a universally correct ground truth for the explanation, making objective evaluation challenging. One promising direction to address this issue involves the use of what we term Synthetic Artificial Intelligence Ground truth (SAIG) methods, which generate artificial ground truths to enable the direct evaluation of XAI techniques. This paper presents the first review and analysis of SAIG methods. We introduce a novel taxonomy to classify these approaches, identifying seven key features that distinguish different SAIG methods. Our comparative study reveals a concerning lack of consensus on the most effective XAI evaluation techniques, underscoring the need for further research and standardization in this area.",
      "tldr_zh": "该研究深入探讨了可解释人工智能(XAI)评估领域中缺乏统一基准真相(ground truth)的难题，并首次对合成人工智能基准真相(SAIG)方法进行了系统性的回顾与分析。作者提出了一种全新的分类法，通过七个关键特征对现有的SAIG方法进行区分，旨在为XAI技术的客观评估提供人工构建的对比标准。研究通过对比分析发现，目前在最有效的XAI评估技术上仍严重缺乏共识，这凸显了该领域对进一步研究和标准化的迫切需求。该论文的贡献在于为研究者理解和选择SAIG方法提供了理论框架，并为未来建立统一的AI解释性评估体系指明了方向。",
      "categories": [
        "cs.AI"
      ],
      "primary_category": "cs.AI",
      "comment": "",
      "pdf_url": "https://arxiv.org/pdf/2602.08715v1",
      "published_date": "2026-02-09 14:24:46 UTC",
      "updated_date": "2026-02-09 14:24:46 UTC",
      "processing_status": "completed",
      "attempts": 1,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "llm_backup_calls": 0,
      "last_update": "2026-02-16T04:51:31.106967+00:00"
    },
    {
      "arxiv_id": "2602.08708v1",
      "title": "Intermediate Results on the Complexity of STRIPS$_{1}^{1}$",
      "title_zh": "STRIPS$_{1}^{1}$ 复杂性的阶段性研究成果",
      "authors": [
        "Stefan Edelkamp",
        "Jiří Fink",
        "Petr Gregor",
        "Anders Jonsson",
        "Bernhard Nebel"
      ],
      "abstract": "This paper is based on Bylander's results on the computational complexity of propositional STRIPS planning. He showed that when only ground literals are permitted, determining plan existence is PSPACE-complete even if operators are limited to two preconditions and two postconditions. While NP-hardness is settled, it is unknown whether propositional STRIPS with operators that only have one precondition and one effect is NP-complete. We shed light on the question whether this small solution hypothesis for STRIPS$^1_1$ is true, calling a SAT solver for small instances, introducing the literal graph, and mapping it to Petri nets.",
      "tldr_zh": "该研究基于 Bylander 对命题式 STRIPS 规划复杂度的研究，针对仅受限于单个前提和单个效果的 STRIPS$^1_1$ 变体展开了深入探讨。虽然该问题的 NP-hardness 已经确定，但其是否属于 NP-complete 仍是自动化规划领域的一个悬而未决的难题。为了探究这一问题，论文针对 STRIPS$^1_1$ 的小规模解假设(small solution hypothesis)进行了研究，并利用 SAT solver 对小规模实例进行了计算验证。此外，研究者引入了文字图(literal graph)的概念，并将其映射到 Petri nets 理论中进行形式化分析。这些工作提供了关于 STRIPS$^1_1$ 规划复杂度的重要中间结论，为最终界定该问题的计算边界奠定了坚实基础。",
      "categories": [
        "cs.AI"
      ],
      "primary_category": "cs.AI",
      "comment": "",
      "pdf_url": "https://arxiv.org/pdf/2602.08708v1",
      "published_date": "2026-02-09 14:21:10 UTC",
      "updated_date": "2026-02-09 14:21:10 UTC",
      "processing_status": "completed",
      "attempts": 1,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "llm_backup_calls": 0,
      "last_update": "2026-02-16T04:52:19.600012+00:00"
    },
    {
      "arxiv_id": "2602.08707v2",
      "title": "Why do we Trust Chatbots? From Normative Principles to Behavioral Drivers",
      "title_zh": "我们为何信任聊天机器人？从规范性原则到行为驱动因素",
      "authors": [
        "Aditya Gulati",
        "Nuria Oliver"
      ],
      "abstract": "As chatbots increasingly blur the boundary between automated systems and human conversation, the foundations of trust in these systems warrant closer examination. While regulatory and policy frameworks tend to define trust in normative terms, the trust users place in chatbots often emerges from behavioral mechanisms. In many cases, this trust is not earned through demonstrated trustworthiness but is instead shaped by interactional design choices that leverage cognitive biases to influence user behavior. Based on this observation, we propose reframing chatbots not as companions or assistants, but as highly skilled salespeople whose objectives are determined by the deploying organization. We argue that the coexistence of competing notions of \"trust\" under a shared term obscures important distinctions between psychological trust formation and normative trustworthiness. Addressing this gap requires further research and stronger support mechanisms to help users appropriately calibrate trust in conversational AI systems.",
      "tldr_zh": "该研究探讨了聊天机器人信任的基础，指出监管框架往往从规范性原则定义信任，而用户的实际信任多源于行为驱动机制。研究发现，这种信任并非通过被证明的信誉（Trustworthiness）获得，而是由利用认知偏差影响用户行为的交互设计决策所塑造。基于此观察，作者建议重新定义聊天机器人，将其视为目标由部署组织决定的高技能销售员（Salespeople），而非单纯的同伴或助手。研究认为，不同信任概念的共存模糊了心理信任形成与规范可靠性之间的重要区别。为解决这一差距，研究呼吁加强支持机制，帮助用户在对话式人工智能系统（Conversational AI Systems）中建立更合理的信任校准。",
      "categories": [
        "cs.AI",
        "cs.CY",
        "cs.HC"
      ],
      "primary_category": "cs.AI",
      "comment": "",
      "pdf_url": "https://arxiv.org/pdf/2602.08707v2",
      "published_date": "2026-02-09 14:21:01 UTC",
      "updated_date": "2026-02-11 13:38:18 UTC",
      "processing_status": "completed",
      "attempts": 1,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "llm_backup_calls": 0,
      "last_update": "2026-02-16T04:51:45.203646+00:00"
    },
    {
      "arxiv_id": "2602.08706v1",
      "title": "Technosocial risks of ideal emotion recognition technologies: A defense of the (social) value of emotional expressions",
      "title_zh": "理想情绪识别技术的技术社会风险：捍卫情绪表达的（社会）价值",
      "authors": [
        "Alexandra Pregent"
      ],
      "abstract": "The prospect of AI systems that I call ideal emotion recognition technologies (ERTs) is often defended on the assumption that social life would benefit from increased affective transparency. This paper challenges that assumption by examining the technosocial risks posed by ideal ERTs, understood as multimodal systems capable of reliably inferring inner affective states in real time. Drawing on philosophical accounts of emotional expression and social practice, as well as empirical work in affective science and social psychology, I argue that the appeal of such systems rests on a misunderstanding of the social functions of emotional expression. Emotional expressions function not only as read-outs of inner states, but also as tools for coordinating action, enabling moral repair, sustaining interpersonal trust, and supporting collective norms. These functions depend on a background of partial opacity and epistemic friction. When deployed in socially authoritative or evaluative contexts, ideal ERTs threaten this expressive space by collapsing epistemic friction, displacing relational meaning with technology-mediated affective profiles, and narrowing the space for aspirational and role-sensitive expressions. The result is a drift towards affective determinism and ambient forms of affective auditing, which undermine both social cohesion and individual agency. I argue that, although it is intuitive to think that increasing accuracy would legitimise such systems, in the case of ERTs accuracy does not straightforwardly justify their deployment, and may, in some contexts, provide a reason for regulatory restraint. I conclude by defending a function-first regulatory approach that treats expressive discretion and intentional emotional expression as constitutive of certain social goods, and that accordingly seeks to protect these goods from excessive affective legibility.",
      "tldr_zh": "该研究深入探讨了“理想情感识别技术”(Ideal Emotion Recognition Technologies, ERTs)带来的技术社会风险，挑战了提高情感透明度必然有益于社会生活的普遍假设。作者通过跨学科分析指出，情感表达不仅是内在状态的披露，更是协调行动、修复道德及维持人际信任的核心社交工具。这些社交功能的实现高度依赖于“部分不透明性”(Partial Opacity)和“认知摩擦”(Epistemic Friction)，而理想 ERTs 的应用会消除这些必要的阻碍。这种趋势可能引发“情感决定论”(Affective Determinism)和泛在化的“情感审计”(Ambient Affective Auditing)，进而损害个人能动性与社会凝聚力。论文强调，技术准确性的提升并不直接赋予其部署正当性，在某些语境下反而提供了监管限制的理由。最后，该文提倡一种“功能优先”(Function-first)的监管路径，旨在保护表达裁量权，防止核心社会价值受到过度“情感清晰度”(Affective Legibility)的侵蚀。",
      "categories": [
        "cs.HC",
        "cs.AI",
        "cs.ET"
      ],
      "primary_category": "cs.HC",
      "comment": "12 pages",
      "pdf_url": "https://arxiv.org/pdf/2602.08706v1",
      "published_date": "2026-02-09 14:20:42 UTC",
      "updated_date": "2026-02-09 14:20:42 UTC",
      "processing_status": "completed",
      "attempts": 1,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "llm_backup_calls": 0,
      "last_update": "2026-02-16T04:57:18.907492+00:00"
    },
    {
      "arxiv_id": "2602.08692v1",
      "title": "PBLean: Pseudo-Boolean Proof Certificates for Lean 4",
      "title_zh": "PBLean：面向 Lean 4 的伪布尔证明证书",
      "authors": [
        "Stefan Szeider"
      ],
      "abstract": "We present PBLean, a method for importing VeriPB pseudo-Boolean (PB) proof certificates into Lean 4. Key to our approach is reflection: a Boolean checker function whose soundness is fully proved in Lean and executed as compiled native code. Our method scales to proofs with tens of thousands of steps that would exhaust memory under explicit proof-term construction. Our checker supports all VeriPB kernel rules, including cutting-plane derivations and proof-by-contradiction subproofs. In contrast to external verified checkers that produce verdicts, our integration yields Lean theorems that can serve as composable lemmas in larger formal developments. To derive theorems about the original combinatorial problems rather than about PB constraints alone, we support verified encodings. This closes the trust gap between solver output and problem semantics since the constraint translation and its correctness proof are both formalized in Lean. We demonstrate the approach on various combinatorial problems.",
      "tldr_zh": "该研究提出了PBLean，一种将VeriPB伪布尔（pseudo-Boolean）证明凭证导入Lean 4的方法。该方法的核心是采用反射（reflection）机制，通过在Lean中完整证明布尔检查器函数的正确性，并将其作为编译后的原生代码执行。这种方式能够有效扩展到包含数万个步骤的大规模证明，解决了显式证明项构造（explicit proof-term construction）在处理复杂证明时常见的内存耗尽问题。该检查器完整支持VeriPB内核规则，包括割平面推导（cutting-plane derivations）和矛盾证明子证明（proof-by-contradiction subproofs）。与仅输出判定结果的外部验证器不同，PBLean生成的Lean定理可直接作为可组合引理用于更广泛的形式化验证。此外，通过支持验证编码（verified encodings），该研究在Lean中同时实现了约束转换及其正确性证明，从而消除了求解器输出与原始组合问题语义之间的信任鸿沟。实验在多种组合问题上验证了该方法的有效性，为复杂组合优化问题的机器验证提供了可靠工具。",
      "categories": [
        "cs.LO",
        "cs.AI"
      ],
      "primary_category": "cs.LO",
      "comment": "",
      "pdf_url": "https://arxiv.org/pdf/2602.08692v1",
      "published_date": "2026-02-09 14:13:30 UTC",
      "updated_date": "2026-02-09 14:13:30 UTC",
      "processing_status": "completed",
      "attempts": 1,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "llm_backup_calls": 0,
      "last_update": "2026-02-16T04:57:22.398233+00:00"
    },
    {
      "arxiv_id": "2602.08686v1",
      "title": "CompilerKV: Risk-Adaptive KV Compression via Offline Experience Compilation",
      "title_zh": "CompilerKV：基于离线经验编译的风险自适应 KV 压缩",
      "authors": [
        "Ning Yang",
        "Chengzhi Wang",
        "Yibo Liu",
        "Baoliang Tian",
        "Haijun Zhang"
      ],
      "abstract": "Large Language Models (LLMs) in long-context scenarios are severely constrained by the linear growth of Key-Value (KV) cache memory. Existing KV compression methods rely either on static thresholds and attention-only heuristics or on coarse memory budget allocation. Under tight memory budgets, these methods overlook two key factors: prompt-dependent variation in compression risk and functional heterogeneity across attention heads, which destabilize token selection and lead to tail failures. To address these challenges, we propose CompilerKV, a risk-adaptive and head-aware compression framework that compiles offline experience into reusable decision tables for prefill-only deployment. CompilerKV integrates two key synergistic components: (i) a Head Heterogeneity Table, learned via offline contextual bandits, which assigns head-specific reliability weights to govern functional differences across attention heads explicitly; and (ii) a Risk-Adaptive Threshold Gating mechanism that jointly models attention entropy and local perplexity, transforming prompt-level risk into deployable retention thresholds. Experiments on LongBench show CompilerKV dominates SOTA methods under a 512-token budget, recovering 97.7\\% of FullKV performance while achieving up to +5.2 points gain over the strongest competitor.",
      "tldr_zh": "该研究针对大语言模型 (LLMs) 在长文本场景中面临的 Key-Value (KV) cache 内存线性增长挑战，提出了 CompilerKV 压缩框架。针对现有方法忽视 Prompt 相关压缩风险及注意力头 (attention heads) 功能异质性的缺陷，CompilerKV 将离线经验编译为可重用的决策表。该框架包含通过离线 Contextual Bandits 学习的 Head Heterogeneity Table，用以显式分配注意力头的可靠性权重；同时引入 Risk-Adaptive Threshold Gating 机制，通过联合建模注意力熵与局部困惑度 (local perplexity) 生成动态保留阈值。实验结果显示，在 LongBench 的 512-token 预算限制下，CompilerKV 性能显著超越 SOTA 方法，成功恢复了 FullKV 97.7% 的水平。该方案不仅在紧凑预算下稳定了 token 选择，还相比最强竞争对手实现了最高 5.2 分的性能提升。",
      "categories": [
        "cs.LG",
        "cs.AI"
      ],
      "primary_category": "cs.LG",
      "comment": "",
      "pdf_url": "https://arxiv.org/pdf/2602.08686v1",
      "published_date": "2026-02-09 14:07:55 UTC",
      "updated_date": "2026-02-09 14:07:55 UTC",
      "processing_status": "completed",
      "attempts": 1,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "llm_backup_calls": 0,
      "last_update": "2026-02-16T04:57:25.801134+00:00"
    },
    {
      "arxiv_id": "2602.08676v3",
      "title": "LLaDA2.1: Speeding Up Text Diffusion via Token Editing",
      "title_zh": "LLaDA2.1：通过 Token 编辑加速文本扩散",
      "authors": [
        "Tiwei Bie",
        "Maosong Cao",
        "Xiang Cao",
        "Bingsen Chen",
        "Fuyuan Chen",
        "Kun Chen",
        "Lun Du",
        "Daozhuo Feng",
        "Haibo Feng",
        "Mingliang Gong",
        "Zhuocheng Gong",
        "Yanmei Gu",
        "Jian Guan",
        "Kaiyuan Guan",
        "Hongliang He",
        "Zenan Huang",
        "Juyong Jiang",
        "Zhonghui Jiang",
        "Zhenzhong Lan",
        "Chengxi Li",
        "Jianguo Li",
        "Zehuan Li",
        "Huabin Liu",
        "Lin Liu",
        "Guoshan Lu",
        "Yuan Lu",
        "Yuxin Ma",
        "Xingyu Mou",
        "Zhenxuan Pan",
        "Kaida Qiu",
        "Yuji Ren",
        "Jianfeng Tan",
        "Yiding Tian",
        "Zian Wang",
        "Lanning Wei",
        "Tao Wu",
        "Yipeng Xing",
        "Wentao Ye",
        "Liangyu Zha",
        "Tianze Zhang",
        "Xiaolu Zhang",
        "Junbo Zhao",
        "Da Zheng",
        "Hao Zhong",
        "Wanli Zhong",
        "Jun Zhou",
        "Junlin Zhou",
        "Liwang Zhu",
        "Muzhi Zhu",
        "Yihong Zhuang"
      ],
      "abstract": "While LLaDA2.0 showcased the scaling potential of 100B-level block-diffusion models and their inherent parallelization, the delicate equilibrium between decoding speed and generation quality has remained an elusive frontier. Today, we unveil LLaDA2.1, a paradigm shift designed to transcend this trade-off. By seamlessly weaving Token-to-Token (T2T) editing into the conventional Mask-to-Token (M2T) scheme, we introduce a joint, configurable threshold-decoding scheme. This structural innovation gives rise to two distinct personas: the Speedy Mode (S Mode), which audaciously lowers the M2T threshold to bypass traditional constraints while relying on T2T to refine the output; and the Quality Mode (Q Mode), which leans into conservative thresholds to secure superior benchmark performances with manageable efficiency degrade. Furthering this evolution, underpinned by an expansive context window, we implement the first large-scale Reinforcement Learning (RL) framework specifically tailored for dLLMs, anchored by specialized techniques for stable gradient estimation. This alignment not only sharpens reasoning precision but also elevates instruction-following fidelity, bridging the chasm between diffusion dynamics and complex human intent. We culminate this work by releasing LLaDA2.1-Mini (16B) and LLaDA2.1-Flash (100B). Across 33 rigorous benchmarks, LLaDA2.1 delivers strong task performance and lightning-fast decoding speed. Despite its 100B volume, on coding tasks it attains an astounding 892 TPS on HumanEval+, 801 TPS on BigCodeBench, and 663 TPS on LiveCodeBench.",
      "tldr_zh": "该研究推出 LLaDA2.1，通过在传统的 Mask-to-Token (M2T) 方案中无缝融入 Token-to-Token (T2T) 编辑技术，提出了一种联合、可配置的阈值解码方案，旨在打破生成质量与解码速度之间的权衡。LLaDA2.1 提供了两种模式：Speedy Mode (S Mode) 通过降低 M2T 阈值并依靠 T2T 优化输出以实现极致速度，而 Quality Mode (Q Mode) 则采用保守阈值以确保卓越性能。此外，该研究实现了首个专门针对 dLLMs 的大规模 Reinforcement Learning (RL) 框架，利用特定技术稳定梯度估计，显著提升了推理精度和指令遵循的忠实度。实验发布了 LLaDA2.1-Mini (16B) 和 LLaDA2.1-Flash (100B) 版本，在 33 项基准测试中表现强劲，其中 100B 模型在 HumanEval+ 等编程任务上达到了惊人的 892 TPS，展现了极速的解码能力。",
      "categories": [
        "cs.LG",
        "cs.AI"
      ],
      "primary_category": "cs.LG",
      "comment": "11 pages, 3 figures",
      "pdf_url": "https://arxiv.org/pdf/2602.08676v3",
      "published_date": "2026-02-09 14:00:07 UTC",
      "updated_date": "2026-02-13 13:19:06 UTC",
      "processing_status": "completed",
      "attempts": 1,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "llm_backup_calls": 0,
      "last_update": "2026-02-16T04:57:24.200217+00:00"
    },
    {
      "arxiv_id": "2602.08675v1",
      "title": "6G-Bench: An Open Benchmark for Semantic Communication and Network-Level Reasoning with Foundation Models in AI-Native 6G Networks",
      "title_zh": "6G-Bench：面向 AI 原生 6G 网络中语义通信与网络级推理的基础模型开放基准测试",
      "authors": [
        "Mohamed Amine Ferrag",
        "Abderrahmane Lakas",
        "Merouane Debbah"
      ],
      "abstract": "This paper introduces 6G-Bench, an open benchmark for evaluating semantic communication and network-level reasoning in AI-native 6G networks. 6G-Bench defines a taxonomy of 30 decision-making tasks (T1--T30) extracted from ongoing 6G and AI-agent standardization activities in 3GPP, IETF, ETSI, ITU-T, and the O-RAN Alliance, and organizes them into five standardization-aligned capability categories. Starting from 113,475 scenarios, we generate a balanced pool of 10,000 very-hard multiple-choice questions using task-conditioned prompts that enforce multi-step quantitative reasoning under uncertainty and worst-case regret minimization over multi-turn horizons. After automated filtering and expert human validation, 3,722 questions are retained as a high-confidence evaluation set, while the full pool is released to support training and fine-tuning of 6G-specialized models. Using 6G-Bench, we evaluate 22 foundation models spanning dense and mixture-of-experts architectures, short- and long-context designs (up to 1M tokens), and both open-weight and proprietary systems. Across models, deterministic single-shot accuracy (pass@1) spans a wide range from 0.22 to 0.82, highlighting substantial variation in semantic reasoning capability. Leading models achieve intent and policy reasoning accuracy in the range 0.87--0.89, while selective robustness analysis on reasoning-intensive tasks shows pass@5 values ranging from 0.20 to 0.91. To support open science and reproducibility, we release the 6G-Bench dataset on GitHub: https://github.com/maferrag/6G-Bench",
      "tldr_zh": "该研究推出了6G-Bench，这是一个专为AI原生6G网络设计的开放基准测试，旨在评估基础模型(Foundation Models)在语义通信(Semantic Communication)和网络级推理(Network-Level Reasoning)方面的表现。6G-Bench定义了包含30个决策任务的分类体系，这些任务直接源自3GPP、IETF等国际标准组织的6G与AI智能体标准化活动。研究团队利用任务调节提示(task-conditioned prompts)构建了一个包含3,722道经过专家验证的高难度题目集，强调多步定量推理与不确定性下的决策。通过对22个主流基础模型的评估发现，各模型的单次尝试准确率(pass@1)在0.22至0.82之间显著波动，反映出语义推理能力的巨大差异。其中领先模型在推理密集型任务中表现优异，其意图与策略推理准确率可达0.87至0.89。该基准的发布不仅为6G专用模型的训练和微调提供了关键数据支持，还通过开源数据集促进了网络智能化领域的开放科学与实验复现。",
      "categories": [
        "cs.NI",
        "cs.AI"
      ],
      "primary_category": "cs.NI",
      "comment": "",
      "pdf_url": "https://arxiv.org/pdf/2602.08675v1",
      "published_date": "2026-02-09 13:57:37 UTC",
      "updated_date": "2026-02-09 13:57:37 UTC",
      "processing_status": "completed",
      "attempts": 1,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "llm_backup_calls": 0,
      "last_update": "2026-02-16T04:57:26.604647+00:00"
    },
    {
      "arxiv_id": "2602.08660v1",
      "title": "Equalized Generative Treatment: Matching f-divergences for Fairness in Generative Models",
      "title_zh": "均等化生成对待：通过 f-散度匹配实现生成模型的公平性",
      "authors": [
        "Alexandre Verine",
        "Rafael Pinot",
        "Florian Le Bronnec"
      ],
      "abstract": "Fairness is a crucial concern for generative models, which not only reflect but can also amplify societal and cultural biases. Existing fairness notions for generative models are largely adapted from classification and focus on balancing the probability of generating samples from each sensitive group. We show that such criteria are brittle, as they can be met even when different sensitive groups are modeled with widely varying quality. To address this limitation, we introduce a new fairness definition for generative models, termed as equalized generative treatment (EGT), which requires comparable generation quality across all sensitive groups, with quality measured via a reference f-divergence. We further analyze the trade-offs induced by EGT, demonstrating that enforcing fairness constraints necessarily couples the overall model quality to that of the most challenging group to approximate. This indicates that a simple yet efficient min-max fine-tuning method should be able to balance f-divergences across sensitive groups to satisfy EGT. We validate this theoretical insight through a set of experiments on both image and text generation tasks. We demonstrate that min-max methods consistently achieve fairer outcomes compared to other approaches from the literature, while maintaining competitive overall performance for both tasks.",
      "tldr_zh": "该研究指出生成模型中的公平性不仅涉及不同敏感群体的生成概率平衡，更关乎生成质量的一致性，而现有标准往往难以保证后者。为此，作者提出了名为 Equalized Generative Treatment (EGT) 的新公平性定义，要求通过 f-divergence 衡量的各群体生成质量达到相当水平。研究进一步通过理论分析证明，强制执行公平性约束会使模型整体质量受限于最具挑战性的群体，并据此提出了一种高效的 min-max fine-tuning 方法来平衡各群体的 f-divergences。在图像和文本生成任务上的实验验证了该方法的有效性，证明 min-max 方法在保持整体性能竞争力的同时，能比现有技术实现更优的公平性表现。",
      "categories": [
        "cs.LG",
        "cs.AI"
      ],
      "primary_category": "cs.LG",
      "comment": "",
      "pdf_url": "https://arxiv.org/pdf/2602.08660v1",
      "published_date": "2026-02-09 13:52:36 UTC",
      "updated_date": "2026-02-09 13:52:36 UTC",
      "processing_status": "completed",
      "attempts": 1,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "llm_backup_calls": 0,
      "last_update": "2026-02-16T04:57:50.606554+00:00"
    },
    {
      "arxiv_id": "2602.08638v1",
      "title": "LEFT: Learnable Fusion of Tri-view Tokens for Unsupervised Time Series Anomaly Detection",
      "title_zh": "LEFT：面向无监督时间序列异常检测的三视角 Token 可学习融合模型",
      "authors": [
        "Dezheng Wang",
        "Tong Chen",
        "Guansong Pang",
        "Congyan Chen",
        "Shihua Li",
        "Hongzhi Yin"
      ],
      "abstract": "As a fundamental data mining task, unsupervised time series anomaly detection (TSAD) aims to build a model for identifying abnormal timestamps without assuming the availability of annotations. A key challenge in unsupervised TSAD is that many anomalies are too subtle to exhibit detectable deviation in any single view (e.g., time domain), and instead manifest as inconsistencies across multiple views like time, frequency, and a mixture of resolutions. However, most cross-view methods rely on feature or score fusion and do not enforce analysis-synthesis consistency, meaning the frequency branch is not required to reconstruct the time signal through an inverse transform, and vice versa. In this paper, we present Learnable Fusion of Tri-view Tokens (LEFT), a unified unsupervised TSAD framework that models anomalies as inconsistencies across complementary representations. LEFT learns feature tokens from three views of the same input time series: frequency-domain tokens that embed periodicity information, time-domain tokens that capture local dynamics, and multi-scale tokens that learns abnormal patterns at varying time series granularities. By learning a set of adaptive Nyquist-constrained spectral filters, the original time series is rescaled into multiple resolutions and then encoded, allowing these multi-scale tokens to complement the extracted frequency- and time-domain information. When generating the fused representation, we introduce a novel objective that reconstructs fine-grained targets from coarser multi-scale structure, and put forward an innovative time-frequency cycle consistency constraint to explicitly regularize cross-view agreement. Experiments on real-world benchmarks show that LEFT yields the best detection accuracy against SOTA baselines, while achieving a 5x reduction on FLOPs and 8x speed-up for training.",
      "tldr_zh": "该研究针对无监督时间序列异常检测(Unsupervised Time Series Anomaly Detection, TSAD)中单一视图难以识别细微异常的挑战，提出了名为LEFT(Learnable Fusion of Tri-view Tokens)的统一框架。LEFT通过学习三种互补视图的特征令牌(tokens)来建模异常，包括嵌入周期性信息的频域令牌、捕获局部动态的时域令牌以及学习不同粒度异常模式的多尺度令牌。该框架引入了一组自适应的奈奎斯特约束频谱过滤器(Nyquist-constrained spectral filters)，将原始时间序列缩放到多个分辨率，从而有效补充频域和时域信息。在生成融合表示时，研究者设计了一种从粗粒度结构重建细粒度目标的新目标函数，并提出了创新的时频循环一致性约束(Time-frequency cycle consistency constraint)以显式正则化跨视图的一致性。在真实世界基准数据集上的实验表明，LEFT在检测准确率上超越了现有的最先进(SOTA)模型。此外，该模型在计算效率上也表现出色，实现了浮点运算量(FLOPs)降低5倍以及训练速度提升8倍。",
      "categories": [
        "cs.LG",
        "cs.AI"
      ],
      "primary_category": "cs.LG",
      "comment": "",
      "pdf_url": "https://arxiv.org/pdf/2602.08638v1",
      "published_date": "2026-02-09 13:33:49 UTC",
      "updated_date": "2026-02-09 13:33:49 UTC",
      "processing_status": "completed",
      "attempts": 1,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "llm_backup_calls": 0,
      "last_update": "2026-02-16T04:57:48.809300+00:00"
    },
    {
      "arxiv_id": "2602.08632v1",
      "title": "We Should Separate Memorization from Copyright",
      "title_zh": "应当将模型记忆与版权区分开来",
      "authors": [
        "Adi Haviv",
        "Niva Elkin-Koren",
        "Uri Hacohen",
        "Roi Livni",
        "Shay Moran"
      ],
      "abstract": "The widespread use of foundation models has introduced a new risk factor of copyright issue. This issue is leading to an active, lively and on-going debate amongst the data-science community as well as amongst legal scholars. Where claims and results across both sides are often interpreted in different ways and leading to different implications. Our position is that much of the technical literature relies on traditional reconstruction techniques that are not designed for copyright analysis. As a result, memorization and copying have been conflated across both technical and legal communities and in multiple contexts. We argue that memorization, as commonly studied in data science, should not be equated with copying and should not be used as a proxy for copyright infringement. We distinguish technical signals that meaningfully indicate infringement risk from those that instead reflect lawful generalization or high-frequency content. Based on this analysis, we advocate for an output-level, risk-based evaluation process that aligns technical assessments with established copyright standards and provides a more principled foundation for research, auditing, and policy.",
      "tldr_zh": "该研究探讨了基础模型引发的版权问题，并指出当前数据科学界与法律界在这一议题上的讨论存在定义混淆。作者认为，现有的技术文献过度依赖非针对版权设计的传统重建技术，导致记忆(Memorization)与复制(Copying)的概念被错误地等同起来。文章明确主张，数据科学中研究的记忆不应被视为法律意义上的复制，也不应作为判定版权侵权(Copyright Infringement)的直接代理指标。研究进一步区分了真正预示侵权风险的技术信号与那些仅反映合法泛化或高频内容的信号。基于此，作者提倡建立一种基于输出层面的风险评估流程，旨在使技术评估与现行的版权法律标准保持一致。这一立场为未来生成式AI领域的学术研究、合规审计和政策制定提供了更具原则性的理论基础。",
      "categories": [
        "cs.CY",
        "cs.AI",
        "cs.CL",
        "cs.CV",
        "cs.LG"
      ],
      "primary_category": "cs.CY",
      "comment": "",
      "pdf_url": "https://arxiv.org/pdf/2602.08632v1",
      "published_date": "2026-02-09 13:24:06 UTC",
      "updated_date": "2026-02-09 13:24:06 UTC",
      "processing_status": "completed",
      "attempts": 1,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "llm_backup_calls": 0,
      "last_update": "2026-02-16T04:57:53.703047+00:00"
    },
    {
      "arxiv_id": "2602.08630v1",
      "title": "Debate is efficient with your time",
      "title_zh": "辩论具有极高的时间效率",
      "authors": [
        "Jonah Brown-Cohen",
        "Geoffrey Irving",
        "Simon C. Marshall",
        "Ilan Newman",
        "Georgios Piliouras",
        "Mario Szegedy"
      ],
      "abstract": "AI safety via debate uses two competing models to help a human judge verify complex computational tasks. Previous work has established what problems debate can solve in principle, but has not analysed the practical cost of human oversight: how many queries must the judge make to the debate transcript? We introduce Debate Query Complexity}(DQC), the minimum number of bits a verifier must inspect to correctly decide a debate.\n  Surprisingly, we find that PSPACE/poly (the class of problems which debate can efficiently decide) is precisely the class of functions decidable with O(log n) queries. This characterisation shows that debate is remarkably query-efficient: even for highly complex problems, logarithmic oversight suffices. We also establish that functions depending on all their input bits require Omega(log n) queries, and that any function computable by a circuit of size s satisfies DQC(f) <= log(s) + 3. Interestingly, this last result implies that proving DQC lower bounds of log(n) + 6 for languages in P would yield new circuit lower bounds, connecting debate query complexity to central questions in circuit complexity.",
      "tldr_zh": "该研究针对 AI safety via debate 领域中人类监督的实际成本问题，提出了 Debate Query Complexity (DQC) 概念，旨在衡量验证者为准确判定辩论结果所需检查的最小比特数。研究通过理论分析证明，辩论可以高效解决的问题类 PSPACE/poly 实际上等同于仅需 O(log n) 次查询即可判定的函数类，这表明辩论在处理复杂问题时具有极高的查询效率。此外，研究确立了依赖所有输入位的函数查询下界为 Omega(log n)，并推导出电路规模为 s 的函数其 DQC 值不超过 log(s) + 3。这一结论不仅证明了对数级监督足以应对高度复杂任务，还建立了辩论查询复杂度与 circuit complexity 核心问题之间的深刻联系。研究指出，为 P 语言证明特定的 DQC 下界将有助于获得新的电路下界结论，为计算复杂性领域的研究提供了新的视角。",
      "categories": [
        "cs.AI",
        "cs.CC"
      ],
      "primary_category": "cs.AI",
      "comment": "11 Pages, 0 figures",
      "pdf_url": "https://arxiv.org/pdf/2602.08630v1",
      "published_date": "2026-02-09 13:21:32 UTC",
      "updated_date": "2026-02-09 13:21:32 UTC",
      "processing_status": "completed",
      "attempts": 1,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "llm_backup_calls": 0,
      "last_update": "2026-02-16T04:58:03.109049+00:00"
    },
    {
      "arxiv_id": "2602.08629v1",
      "title": "CauScale: Neural Causal Discovery at Scale",
      "title_zh": "CauScale：大规模神经因果发现",
      "authors": [
        "Bo Peng",
        "Sirui Chen",
        "Jiaguo Tian",
        "Yu Qiao",
        "Chaochao Lu"
      ],
      "abstract": "Causal discovery is essential for advancing data-driven fields such as scientific AI and data analysis, yet existing approaches face significant time- and space-efficiency bottlenecks when scaling to large graphs. To address this challenge, we present CauScale, a neural architecture designed for efficient causal discovery that scales inference to graphs with up to 1000 nodes. CauScale improves time efficiency via a reduction unit that compresses data embeddings and improves space efficiency by adopting tied attention weights to avoid maintaining axis-specific attention maps. To keep high causal discovery accuracy, CauScale adopts a two-stream design: a data stream extracts relational evidence from high-dimensional observations, while a graph stream integrates statistical graph priors and preserves key structural signals. CauScale successfully scales to 500-node graphs during training, where prior work fails due to space limitations. Across testing data with varying graph scales and causal mechanisms, CauScale achieves 99.6% mAP on in-distribution data and 84.4% on out-of-distribution data, while delivering 4-13,000 times inference speedups over prior methods. Our project page is at https://github.com/OpenCausaLab/CauScale.",
      "tldr_zh": "该研究提出了CauScale，一种旨在解决大规模图结构中因果发现(Causal Discovery)效率瓶颈的神经架构。该架构能够处理多达1000个节点的图，通过reduction unit压缩数据嵌入并采用tied attention weights减少空间消耗，从而显著提升了时间和空间效率。CauScale采用了双流设计(two-stream design)，包括负责提取关系证据的数据流(data stream)和整合统计图先验(graph priors)的图流(graph stream)，以确保在高效率下维持发现的准确性。实验证明，CauScale在训练中能扩展至500个节点，且在推理速度上比现有方法快4到13,000倍。该模型在分布内数据(in-distribution)和分布外数据(out-of-distribution)上分别实现了99.6%和84.4%的平均精度均值(mAP)，为大规模因果发现提供了高效且鲁棒的解决方案。",
      "categories": [
        "cs.LG",
        "cs.AI",
        "stat.ML"
      ],
      "primary_category": "cs.LG",
      "comment": "",
      "pdf_url": "https://arxiv.org/pdf/2602.08629v1",
      "published_date": "2026-02-09 13:21:32 UTC",
      "updated_date": "2026-02-09 13:21:32 UTC",
      "processing_status": "completed",
      "attempts": 1,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "llm_backup_calls": 0,
      "last_update": "2026-02-16T04:58:02.310570+00:00"
    },
    {
      "arxiv_id": "2602.08621v1",
      "title": "Sparse Models, Sparse Safety: Unsafe Routes in Mixture-of-Experts LLMs",
      "title_zh": "稀疏模型，稀疏安全：混合专家大语言模型中的不安全路由",
      "authors": [
        "Yukun Jiang",
        "Hai Huang",
        "Mingjie Li",
        "Yage Zhang",
        "Michael Backes",
        "Yang Zhang"
      ],
      "abstract": "By introducing routers to selectively activate experts in Transformer layers, the mixture-of-experts (MoE) architecture significantly reduces computational costs in large language models (LLMs) while maintaining competitive performance, especially for models with massive parameters. However, prior work has largely focused on utility and efficiency, leaving the safety risks associated with this sparse architecture underexplored. In this work, we show that the safety of MoE LLMs is as sparse as their architecture by discovering unsafe routes: routing configurations that, once activated, convert safe outputs into harmful ones. Specifically, we first introduce the Router Safety importance score (RoSais) to quantify the safety criticality of each layer's router. Manipulation of only the high-RoSais router(s) can flip the default route into an unsafe one. For instance, on JailbreakBench, masking 5 routers in DeepSeek-V2-Lite increases attack success rate (ASR) by over 4$\\times$ to 0.79, highlighting an inherent risk that router manipulation may naturally occur in MoE LLMs. We further propose a Fine-grained token-layer-wise Stochastic Optimization framework to discover more concrete Unsafe Routes (F-SOUR), which explicitly considers the sequentiality and dynamics of input tokens. Across four representative MoE LLM families, F-SOUR achieves an average ASR of 0.90 and 0.98 on JailbreakBench and AdvBench, respectively. Finally, we outline defensive perspectives, including safety-aware route disabling and router training, as promising directions to safeguard MoE LLMs. We hope our work can inform future red-teaming and safeguarding of MoE LLMs. Our code is provided in https://github.com/TrustAIRLab/UnsafeMoE.",
      "tldr_zh": "该研究探讨了混合专家模型(Mixture-of-Experts, MoE)架构中由于稀疏性带来的潜在安全风险，揭示了“不安全路由(Unsafe Routes)”的存在，即某些特定的路由配置一旦激活会将原本安全的输出转化为有害内容。作者首先提出了路由安全重要性得分(Router Safety importance score, RoSais)来量化各层路由对安全性的关键程度，实验表明仅通过操控少数高RoSais路由即可显著提升攻击成功率(ASR)。为了进一步挖掘这些风险，研究者开发了细粒度Token层级随机优化框架(F-SOUR)，该框架在四个主流MoE模型家族的测试中表现出极高的攻击效能，在JailbreakBench和AdvBench上的平均ASR分别达到0.90和0.98。最后，论文讨论了安全感知路由禁用和路由训练等防御策略，为未来MoE大语言模型的红队测试与安全加固提供了重要见解。",
      "categories": [
        "cs.LG",
        "cs.AI",
        "cs.CR"
      ],
      "primary_category": "cs.LG",
      "comment": "",
      "pdf_url": "https://arxiv.org/pdf/2602.08621v1",
      "published_date": "2026-02-09 13:12:54 UTC",
      "updated_date": "2026-02-09 13:12:54 UTC",
      "processing_status": "completed",
      "attempts": 1,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "llm_backup_calls": 0,
      "last_update": "2026-02-16T04:58:29.901074+00:00"
    },
    {
      "arxiv_id": "2602.08619v1",
      "title": "Enhancing Genetic Algorithms with Graph Neural Networks: A Timetabling Case Study",
      "title_zh": "基于图神经网络增强遗传算法：排班问题的案例研究",
      "authors": [
        "Laura-Maria Cornei",
        "Mihaela-Elena Breabăn"
      ],
      "abstract": "This paper investigates the impact of hybridizing a multi-modal Genetic Algorithm with a Graph Neural Network for timetabling optimization. The Graph Neural Network is designed to encapsulate general domain knowledge to improve schedule quality, while the Genetic Algorithm explores different regions of the search space and integrates the deep learning model as an enhancement operator to guide the solution search towards optimality. Initially, both components of the hybrid technique were designed, developed, and optimized independently to solve the tackled task. Multiple experiments were conducted on Staff Rostering, a well-known timetabling problem, to compare the proposed hybridization with the standalone optimized versions of the Genetic Algorithm and Graph Neural Network. The experimental results demonstrate that the proposed hybridization brings statistically significant improvements in both the time efficiency and solution quality metrics, compared to the standalone methods. To the best of our knowledge, this work proposes the first hybridization of a Genetic Algorithm with a Graph Neural Network for solving timetabling problems.",
      "tldr_zh": "本研究提出了一种将多模态 Genetic Algorithm (GA) 与 Graph Neural Network (GNN) 相结合的混合优化框架，旨在提升 Timetabling 问题的求解性能。在该系统中，GNN 被设计用于封装通用的领域知识以提高调度质量，而 GA 则负责探索搜索空间的不同区域，并集成深度学习模型作为增强算子来引导寻优。研究人员在 Staff Rostering 这一经典排班问题上进行了大量实验，对比了该混合技术与独立优化的 GA 和 GNN 版本。实验结果表明，该混合方法在时间效率和解的质量指标上均取得了显著的统计学进步。据作者所知，这项工作首次实现了 Genetic Algorithm 与 Graph Neural Network 的杂交，为解决复杂的时间表调度问题提供了新的思路。",
      "categories": [
        "cs.NE",
        "cs.AI",
        "cs.LG"
      ],
      "primary_category": "cs.NE",
      "comment": "Paper accepted to the International Conference on Applications of Evolutionary Computation (EvoApplications) 2026",
      "pdf_url": "https://arxiv.org/pdf/2602.08619v1",
      "published_date": "2026-02-09 13:10:16 UTC",
      "updated_date": "2026-02-09 13:10:16 UTC",
      "processing_status": "completed",
      "attempts": 1,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "llm_backup_calls": 0,
      "last_update": "2026-02-16T04:58:31.906476+00:00"
    },
    {
      "arxiv_id": "2602.08616v1",
      "title": "Breaking the Grid: Distance-Guided Reinforcement Learning in Large Discrete and Hybrid Action Spaces",
      "title_zh": "突破网格：大规模离散与混合动作空间中的距离引导强化学习",
      "authors": [
        "Heiko Hoppe",
        "Fabian Akkerman",
        "Wouter van Heeswijk",
        "Maximilian Schiffer"
      ],
      "abstract": "Reinforcement Learning is increasingly applied to logistics, scheduling, and recommender systems, but standard algorithms struggle with the curse of dimensionality in such large discrete action spaces. Existing algorithms typically rely on restrictive grid-based structures or computationally expensive nearest-neighbor searches, limiting their effectiveness in high-dimensional or irregularly structured domains. We propose Distance-Guided Reinforcement Learning (DGRL), combining Sampled Dynamic Neighborhoods (SDN) and Distance-Based Updates (DBU) to enable efficient RL in spaces with up to 10$^\\text{20}$ actions. Unlike prior methods, SDN leverages a semantic embedding space to perform stochastic volumetric exploration, provably providing full support over a local trust region. Complementing this, DBU transforms policy optimization into a stable regression task, decoupling gradient variance from action space cardinality and guaranteeing monotonic policy improvement. DGRL naturally generalizes to hybrid continuous-discrete action spaces without requiring hierarchical dependencies. We demonstrate performance improvements of up to 66% against state-of-the-art benchmarks across regularly and irregularly structured environments, while simultaneously improving convergence speed and computational complexity.",
      "tldr_zh": "该研究针对强化学习(Reinforcement Learning)在大规模离散动作空间中面临的维度灾难问题，指出传统算法在处理高维或不规则结构域时受限于网格结构或昂贵的最近邻搜索。为此，作者提出了距离引导强化学习(Distance-Guided Reinforcement Learning, DGRL)，该框架结合了采样动态邻域(Sampled Dynamic Neighborhoods, SDN)和基于距离的更新(Distance-Based Updates, DBU)。SDN利用语义嵌入空间进行随机体探究(stochastic volumetric exploration)，在局部置信区域内提供完整的覆盖支持；而DBU将策略优化转化为稳定的回归任务，使梯度方差与动作空间基数解耦，并保证了策略的单调提升。DGRL能够处理高达10^20个动作的空间，并能自然扩展至混合连续-离散动作空间(hybrid continuous-discrete action spaces)。实验结果表明，DGRL在规则和不规则结构环境中相较于现有基准模型性能提升高达66%，同时显著提高了收敛速度并降低了计算复杂度。",
      "categories": [
        "cs.LG",
        "cs.AI"
      ],
      "primary_category": "cs.LG",
      "comment": "26 pages, 8 figures",
      "pdf_url": "https://arxiv.org/pdf/2602.08616v1",
      "published_date": "2026-02-09 13:05:07 UTC",
      "updated_date": "2026-02-09 13:05:07 UTC",
      "processing_status": "completed",
      "attempts": 1,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "llm_backup_calls": 0,
      "last_update": "2026-02-16T04:58:37.201301+00:00"
    },
    {
      "arxiv_id": "2602.08603v1",
      "title": "OSCAR: Optimization-Steered Agentic Planning for Composed Image Retrieval",
      "title_zh": "OSCAR：面向组合图像检索的优化引导智能体规划",
      "authors": [
        "Teng Wang",
        "Rong Shan",
        "Jianghao Lin",
        "Junjie Wu",
        "Tianyi Xu",
        "Jianping Zhang",
        "Wenteng Chen",
        "Changwang Zhang",
        "Zhaoxiang Wang",
        "Weinan Zhang",
        "Jun Wang"
      ],
      "abstract": "Composed image retrieval (CIR) requires complex reasoning over heterogeneous visual and textual constraints. Existing approaches largely fall into two paradigms: unified embedding retrieval, which suffers from single-model myopia, and heuristic agentic retrieval, which is limited by suboptimal, trial-and-error orchestration. To this end, we propose OSCAR, an optimization-steered agentic planning framework for composed image retrieval. We are the first to reformulate agentic CIR from a heuristic search process into a principled trajectory optimization problem. Instead of relying on heuristic trial-and-error exploration, OSCAR employs a novel offline-online paradigm. In the offline phase, we model CIR via atomic retrieval selection and composition as a two-stage mixed-integer programming problem, mathematically deriving optimal trajectories that maximize ground-truth coverage for training samples via rigorous boolean set operations. These trajectories are then stored in a golden library to serve as in-context demonstrations for online steering of VLM planner at online inference time. Extensive experiments on three public benchmarks and a private industrial benchmark show that OSCAR consistently outperforms SOTA baselines. Notably, it achieves superior performance using only 10% of training data, demonstrating strong generalization of planning logic rather than dataset-specific memorization.",
      "tldr_zh": "该研究提出了OSCAR，一种针对组合图像检索（Composed Image Retrieval, CIR）的优化引导智能体规划框架，旨在解决统一嵌入检索的视野局限以及启发式智能体检索的效率低下问题。OSCAR首次将智能体CIR从启发式搜索重构为原则性的轨迹优化问题，并采用创新的离线-在线范式。在离线阶段，该框架将原子检索选择与组合建模为两阶段混合整数规划（Mixed-integer Programming）问题，通过严格的布尔集合运算推导出最大化真值覆盖的黄金轨迹库。在在线推理时，这些轨迹作为上下文示例引导视觉语言模型（VLM）规划器进行决策。实验结果显示，OSCAR在三个公共基准测试及一个私有工业基准测试上均优于现有最先进（SOTA）模型，且仅需10%的训练数据即可实现卓越性能，证明了该方法具有极强的规划逻辑泛化能力而非简单的特定数据集记忆。",
      "categories": [
        "cs.AI"
      ],
      "primary_category": "cs.AI",
      "comment": "",
      "pdf_url": "https://arxiv.org/pdf/2602.08603v1",
      "published_date": "2026-02-09 12:44:56 UTC",
      "updated_date": "2026-02-09 12:44:56 UTC",
      "processing_status": "completed",
      "attempts": 1,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "llm_backup_calls": 0,
      "last_update": "2026-02-16T04:58:40.301933+00:00"
    },
    {
      "arxiv_id": "2602.08597v1",
      "title": "An Attention Mechanism for Robust Multimodal Integration in a Global Workspace Architecture",
      "title_zh": "全局工作空间架构中用于鲁棒多模态集成的注意力机制",
      "authors": [
        "Roland Bertin-Johannet",
        "Lara Scipio",
        "Leopold Maytié",
        "Rufin VanRullen"
      ],
      "abstract": "Global Workspace Theory (GWT), inspired by cognitive neuroscience, posits that flexible cognition could arise via the attentional selection of a relevant subset of modalities within a multimodal integration system. This cognitive framework can inspire novel computational architectures for multimodal integration. Indeed, recent implementations of GWT have explored its multimodal representation capabilities, but the related attention mechanisms remain understudied. Here, we propose and evaluate a top-down attention mechanism to select modalities inside a global workspace. First, we demonstrate that our attention mechanism improves noise robustness of a global workspace system on two multimodal datasets of increasing complexity: Simple Shapes and MM-IMDb 1.0. Second, we highlight various cross-task and cross-modality generalization capabilities that are not shared by multimodal attention models from the literature. Comparing against existing baselines on the MM-IMDb 1.0 benchmark, we find our attention mechanism makes the global workspace competitive with the state of the art.",
      "tldr_zh": "该研究受到认知神经科学中的全局工作空间理论(Global Workspace Theory, GWT)启发，提出了一种用于全局工作空间架构的自顶向下(top-down)注意力机制，旨在通过注意力选择多模态集成系统中的相关模态子集来实现灵活认知。作者在Simple Shapes和MM-IMDb 1.0两个复杂度递增的多模态数据集上进行了评估，结果表明该注意力机制显著提升了系统对于噪声的鲁棒性(noise robustness)。此外，该机制展现出了现有文献中多模态注意力模型所不具备的跨任务和跨模态泛化能力。实验证明，该注意力机制使得全局工作空间系统在MM-IMDb 1.0基准测试中达到了与当前最先进技术(state of the art)相当的竞争水平，为构建稳健的多模态集成计算架构提供了有效途径。",
      "categories": [
        "cs.AI"
      ],
      "primary_category": "cs.AI",
      "comment": "",
      "pdf_url": "https://arxiv.org/pdf/2602.08597v1",
      "published_date": "2026-02-09 12:38:05 UTC",
      "updated_date": "2026-02-09 12:38:05 UTC",
      "processing_status": "completed",
      "attempts": 1,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "llm_backup_calls": 0,
      "last_update": "2026-02-16T04:58:46.698834+00:00"
    },
    {
      "arxiv_id": "2602.08593v1",
      "title": "Kissan-Dost: Bridging the Last Mile in Smallholder Precision Agriculture with Conversational IoT",
      "title_zh": "Kissan-Dost：利用对话式物联网打通小农户精准农业的“最后一公里”",
      "authors": [
        "Muhammad Saad Ali",
        "Daanish U. Khan",
        "Laiba Intizar Ahmad",
        "Umer Irfan",
        "Maryam Mustafa",
        "Naveed Anwar Bhatti",
        "Muhammad Hamad Alizai"
      ],
      "abstract": "We present Kissan-Dost, a multilingual, sensor-grounded conversational system that turns live on-farm measurements and weather into plain-language guidance delivered over WhatsApp text or voice. The system couples commodity soil and climate sensors with retrieval-augmented generation, then enforces grounding, traceability, and proactive alerts through a modular pipeline. In a 90-day, two-site pilot with five participants, we ran three phases (baseline, dashboard only, chatbot only). Dashboard engagement was sporadic and faded, while the chatbot was used nearly daily and informed concrete actions. Controlled tests on 99 sensor-grounded crop queries achieved over 90 percent correctness with subsecond end-to-end latency, alongside high-quality translation outputs. Results show that careful last-mile integration, not novel circuitry, unlocks the latent value of existing Agri-IoT for smallholders.",
      "tldr_zh": "该研究介绍了 Kissan-Dost，这是一个多语言、基于传感器数据的对话系统，旨在通过 WhatsApp 语音或文字将农场实时监测数据和天气预报转化为易懂的农业指导。该系统将廉价的土壤与气候传感器与检索增强生成 (Retrieval-Augmented Generation, RAG) 技术相结合，利用模块化流水线确保了信息的落地性、可追溯性以及主动预警功能。在为期 90 天的双站点试点研究中，对比发现传统的仪表盘模式参与度较低且逐渐衰减，而聊天机器人模式则被农户几乎每日使用并有效指导了具体的农事操作。受控测试表明，该系统在 99 项作物查询中达到了 90% 以上的准确率，并具备亚秒级的端到端延迟和高质量的翻译输出。研究结果强调，针对小农户的精准农业关键不在于开发新型电路，而在于通过精细的“最后一公里”集成 (Last-mile integration) 来释放现有农业物联网 (Agri-IoT) 的潜在价值。",
      "categories": [
        "cs.HC",
        "cs.AI"
      ],
      "primary_category": "cs.HC",
      "comment": "",
      "pdf_url": "https://arxiv.org/pdf/2602.08593v1",
      "published_date": "2026-02-09 12:34:42 UTC",
      "updated_date": "2026-02-09 12:34:42 UTC",
      "processing_status": "completed",
      "attempts": 1,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "llm_backup_calls": 0,
      "last_update": "2026-02-16T04:59:29.303899+00:00"
    },
    {
      "arxiv_id": "2602.08586v2",
      "title": "PRISM: A Principled Framework for Multi-Agent Reasoning via Gain Decomposition",
      "title_zh": "PRISM：基于增益分解的多智能体推理原理性框架",
      "authors": [
        "Yiming Yang",
        "Zhuoyuan Li",
        "Fanxiang Zeng",
        "Hao Fu",
        "Yue Liu"
      ],
      "abstract": "Multi-agent collaboration has emerged as a promising paradigm for enhancing reasoning capabilities of Large Language Models (LLMs). However, existing approaches remain largely heuristic, lacking principled guidance on what drives performance gains and how to systematically optimize multi-agent reasoning. Specifically, it remains unclear why multi-agent collaboration outperforms single-agent reasoning and which design choices contribute most to these gains, making it difficult to build better systems.\n  We address this gap by introducing a unified theoretical framework that decomposes multi-agent reasoning gains into three conceptually independent dimensions: Exploration for diverse solution coverage, Information for high-fidelity feedback, and Aggregation for principled consensus. Through this lens, existing methods can be understood as special cases that optimize only subsets of these dimensions. Building upon this decomposition, a novel framework called PRISM (Propose-Review-Integrate Synthesis for Multi-agent Reasoning) is proposed, which jointly maximizes all three dimensions through role-based diversity, execution-grounded feedback with evidence-based cross-evaluation, and iterative synthesis with closed-loop validation. Extensive experiments across mathematical reasoning, code generation, and function calling benchmarks demonstrate that PRISM achieves state-of-the-art performance with superior compute-efficiency compared to methods optimizing partial dimensions. The theoretical framework provides actionable design principles for future multi-agent reasoning systems.",
      "tldr_zh": "该研究针对大语言模型(LLMs)多智能体协作中缺乏理论指导、现有方法多为启发式且增益来源不明的问题，提出了一个统一的理论框架。该框架将多智能体推理的增益分解为探索(Exploration)、信息(Information)和聚合(Aggregation)三个独立的维度，阐明了多智能体协作优于单体推理的机制。基于此理论分解，研究者提出了PRISM框架，通过基于角色的多样性、结合执行反馈的证据交叉评估以及闭环验证的迭代综合，实现了对三个维度的协同优化。实验结果显示，PRISM在数学推理、代码生成和函数调用等多个基准测试中均取得了SOTA性能，且在计算效率上明显优于仅优化部分维度的现有方法。该研究不仅提供了可操作的设计原则，也为未来构建更系统化、原则化的多智能体推理系统奠定了坚实的理论基础。",
      "categories": [
        "cs.AI"
      ],
      "primary_category": "cs.AI",
      "comment": "",
      "pdf_url": "https://arxiv.org/pdf/2602.08586v2",
      "published_date": "2026-02-09 12:24:56 UTC",
      "updated_date": "2026-02-10 06:47:22 UTC",
      "processing_status": "completed",
      "attempts": 1,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "llm_backup_calls": 0,
      "last_update": "2026-02-16T04:59:26.198541+00:00"
    },
    {
      "arxiv_id": "2602.08585v1",
      "title": "Predicting Future Utility: Global Combinatorial Optimization for Task-Agnostic KV Cache Eviction",
      "title_zh": "预测未来效用：面向任务无关 KV 缓存逐出的全局组合优化",
      "authors": [
        "Ziyao Tang",
        "Pengkun Jiao",
        "Xinhang Chen",
        "Wei Liu",
        "Shiyong Li",
        "Jingjing Chen"
      ],
      "abstract": "Given the quadratic complexity of attention, KV cache eviction is vital to accelerate model inference. Current KV cache eviction methods typically rely on instantaneous heuristic metrics, implicitly assuming that score magnitudes are consistent proxies for importance across all heads. However, this overlooks the heterogeneity in predictive fidelity across attention heads. While certain heads prioritize the instantaneous contribution of tokens, others are dedicated to capturing long-horizon utility. In this paper, we propose that optimal budget allocation should be governed by the marginal utility in preserving long-term semantic information. Based on this insight, we propose LU-KV, a novel framework that optimizes head-level budget allocation through a convex-hull relaxation and a marginal-utility-based greedy solver to achieve near-optimal precision. Furthermore, we implement a data-driven offline profiling protocol to facilitate the practical deployment of LU-KV. Extensive evaluations on LongBench and RULER benchmarks demonstrate that LU-KV achieves an 80% reduction in KV cache size with minimal performance degradation, while simultaneously reducing inference latency and GPU memory footprint.",
      "tldr_zh": "该研究针对注意力机制的二次复杂度问题，提出了 LU-KV 框架，旨在实现任务无关的 KV Cache Eviction 以加速模型推理。针对现有启发式方法忽略注意力头异质性及长期预测精度差异的问题，LU-KV 将预算分配视为全局组合优化问题，通过衡量保留长期语义信息的 Marginal Utility 来指导各头部的预算分配。该框架利用 Convex-hull Relaxation 和基于边际效用的 Greedy Solver 实现接近最优的分配精度，并引入了数据驱动的 Offline Profiling 协议以支持实际部署。在 LongBench 和 RULER 基准测试上的实验结果表明，LU-KV 在减少 80% 的 KV Cache 规模的同时，仅产生极小的性能降级，并显著降低了推理延迟和 GPU 显存占用。",
      "categories": [
        "cs.LG",
        "cs.AI"
      ],
      "primary_category": "cs.LG",
      "comment": "",
      "pdf_url": "https://arxiv.org/pdf/2602.08585v1",
      "published_date": "2026-02-09 12:23:38 UTC",
      "updated_date": "2026-02-09 12:23:38 UTC",
      "processing_status": "completed",
      "attempts": 1,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "llm_backup_calls": 0,
      "last_update": "2026-02-16T04:59:33.405321+00:00"
    },
    {
      "arxiv_id": "2602.08565v1",
      "title": "Agent-Supported Foresight for AI Systemic Risks: AI Agents for Breadth, Experts for Judgment",
      "title_zh": "针对 AI 系统性风险的智能体辅助预见：智能体负责广度，专家负责研判",
      "authors": [
        "Leon Fröhling",
        "Alessandro Giaconia",
        "Edyta Paulina Bogucka",
        "Daniele Quercia"
      ],
      "abstract": "AI impact assessments often stress near-term risks because human judgment degrades over longer horizons, exemplifying the Collingridge dilemma: foresight is most needed when knowledge is scarcest. To address long-term systemic risks, we introduce a scalable approach that simulates in-silico agents using the strategic foresight method of the Futures Wheel. We applied it to four AI uses spanning Technology Readiness Levels (TRLs): Chatbot Companion (TRL 9, mature), AI Toy (TRL 7, medium), Griefbot (TRL 5, low), and Death App (TRL 2, conceptual). Across 30 agent runs per use, agents produced 86-110 consequences, condensed into 27-47 unique risks. To benchmark the agent outputs against human perspectives, we collected evaluations from 290 domain experts and 7 leaders, and conducted Futures Wheel sessions with 42 experts and 42 laypeople. Agents generated many systemic consequences across runs. Compared with these outputs, experts identified fewer risks, typically less systemic but judged more likely, whereas laypeople surfaced more emotionally salient concerns that were generally less systemic. We propose a hybrid foresight workflow, wherein agents broaden systemic coverage, and humans provide contextual grounding. Our dataset is available at: https://social-dynamics.net/ai-risks/foresight.",
      "tldr_zh": "该研究提出了一种利用AI智能体(AI Agents)支持AI系统性风险(Systemic Risks)预测的可扩展方法，旨在解决人类在长期预测中面临的判断力退化问题。研究采用了Futures Wheel战略远见方法，通过在四个不同技术就绪度(TRLs)的AI应用上进行模拟运行，生成了涵盖广泛系统性后果的风险集合。通过与大量领域专家和普通人的对比实验，研究发现AI智能体在识别后果的广度上具有显著优势，而人类专家更侧重于判断风险的可能性。基于此，研究提出了一种混合远见工作流(Hybrid Foresight Workflow)，由AI智能体提供广泛的系统覆盖，再由人类进行背景验证与决策判断。该研究为应对Collingridge困境提供了创新的解决方案，展示了智能体在增强长期AI风险评估和治理远见方面的显著潜力。",
      "categories": [
        "cs.HC",
        "cs.AI"
      ],
      "primary_category": "cs.HC",
      "comment": "48 pages, 15 figures",
      "pdf_url": "https://arxiv.org/pdf/2602.08565v1",
      "published_date": "2026-02-09 12:03:49 UTC",
      "updated_date": "2026-02-09 12:03:49 UTC",
      "processing_status": "completed",
      "attempts": 1,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "llm_backup_calls": 0,
      "last_update": "2026-02-16T04:59:41.203046+00:00"
    },
    {
      "arxiv_id": "2602.08563v1",
      "title": "Stateless Yet Not Forgetful: Implicit Memory as a Hidden Channel in LLMs",
      "title_zh": "无状态亦非健忘：大语言模型中作为隐藏通道的隐式记忆",
      "authors": [
        "Ahmed Salem",
        "Andrew Paverd",
        "Sahar Abdelnabi"
      ],
      "abstract": "Large language models (LLMs) are commonly treated as stateless: once an interaction ends, no information is assumed to persist unless it is explicitly stored and re-supplied. We challenge this assumption by introducing implicit memory-the ability of a model to carry state across otherwise independent interactions by encoding information in its own outputs and later recovering it when those outputs are reintroduced as input. This mechanism does not require any explicit memory module, yet it creates a persistent information channel across inference requests. As a concrete demonstration, we introduce a new class of temporal backdoors, which we call time bombs. Unlike conventional backdoors that activate on a single trigger input, time bombs activate only after a sequence of interactions satisfies hidden conditions accumulated via implicit memory. We show that such behavior can be induced today through straightforward prompting or fine-tuning. Beyond this case study, we analyze broader implications of implicit memory, including covert inter-agent communication, benchmark contamination, targeted manipulation, and training-data poisoning. Finally, we discuss detection challenges and outline directions for stress-testing and evaluation, with the goal of anticipating and controlling future developments. To promote future research, we release code and data at: https://github.com/microsoft/implicitMemory.",
      "tldr_zh": "这项研究挑战了大语言模型(LLMs)通常被视为无状态(stateless)的假设，提出了隐式记忆(implicit memory)的概念，即模型通过在其输出中编码信息并在后续输入中恢复该信息，从而在独立交互之间建立持久的隐性通道。研究者通过一种名为时间炸弹(time bombs)的新型时间后门具体演示了这一机制，这类后门仅在通过隐式记忆累积的一系列交互满足特定隐藏条件后才会激活。实验表明，这种行为可以通过简单的提示(prompting)或微调(fine-tuning)来实现。除了后门攻击，该研究还深入分析了隐式记忆在智能体间隐蔽通信(covert inter-agent communication)、基准测试污染、目标操纵和训练数据投毒等方面的广泛影响。最后，文章讨论了检测隐式记忆的挑战，并为未来的压力测试和安全评估指明了方向，旨在提高对LLMs交互安全性的控制。",
      "categories": [
        "cs.LG",
        "cs.AI",
        "cs.CR"
      ],
      "primary_category": "cs.LG",
      "comment": "Accepted at IEEE SaTML 2026",
      "pdf_url": "https://arxiv.org/pdf/2602.08563v1",
      "published_date": "2026-02-09 12:01:32 UTC",
      "updated_date": "2026-02-09 12:01:32 UTC",
      "processing_status": "completed",
      "attempts": 1,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "llm_backup_calls": 0,
      "last_update": "2026-02-16T04:59:43.003349+00:00"
    },
    {
      "arxiv_id": "2602.08550v1",
      "title": "GOT-Edit: Geometry-Aware Generic Object Tracking via Online Model Editing",
      "title_zh": "GOT-Edit：通过在线模型编辑实现的几何感知通用目标跟踪",
      "authors": [
        "Shih-Fang Chen",
        "Jun-Cheng Chen",
        "I-Hong Jhuo",
        "Yen-Yu Lin"
      ],
      "abstract": "Human perception for effective object tracking in a 2D video stream arises from the implicit use of prior 3D knowledge combined with semantic reasoning. In contrast, most generic object tracking (GOT) methods primarily rely on 2D features of the target and its surroundings while neglecting 3D geometric cues, which makes them susceptible to partial occlusion, distractors, and variations in geometry and appearance. To address this limitation, we introduce GOT-Edit, an online cross-modality model editing approach that integrates geometry-aware cues into a generic object tracker from a 2D video stream. Our approach leverages features from a pre-trained Visual Geometry Grounded Transformer to enable geometric cue inference from only a few 2D images. To tackle the challenge of seamlessly combining geometry and semantics, GOT-Edit performs online model editing with null-space constrained updates that incorporate geometric information while preserving semantic discrimination, yielding consistently better performance across diverse scenarios. Extensive experiments on multiple GOT benchmarks demonstrate that GOT-Edit achieves superior robustness and accuracy, particularly under occlusion and clutter, establishing a new paradigm for combining 2D semantics with 3D geometric reasoning for generic object tracking.",
      "tldr_zh": "该研究针对通用目标跟踪(Generic Object Tracking)中忽视3D几何线索，导致在遮挡和干扰下表现不佳的问题，提出了GOT-Edit。这是一种在线跨模态模型编辑(online model editing)方法，通过集成几何感知(geometry-aware)线索来增强2D视频流跟踪。该方法利用预训练的Visual Geometry Grounded Transformer，仅通过少量2D图像即可推断几何线索。为了无缝结合几何与语义信息，GOT-Edit 采用零空间约束更新(null-space constrained updates)进行在线模型编辑，在引入几何信息的同时保持语义辨别力。在多个GOT基准测试上的实验表明，GOT-Edit 在遮挡和复杂背景下展现出优异的鲁棒性和准确性。这项工作为在通用目标跟踪中结合2D语义与3D几何推理建立了一种新的范式。",
      "categories": [
        "cs.CV",
        "cs.AI",
        "cs.LG",
        "cs.MM",
        "eess.IV"
      ],
      "primary_category": "cs.CV",
      "comment": "ICLR 2026. This is a preprint version. The camera-ready version will be updated soon",
      "pdf_url": "https://arxiv.org/pdf/2602.08550v1",
      "published_date": "2026-02-09 11:50:29 UTC",
      "updated_date": "2026-02-09 11:50:29 UTC",
      "processing_status": "completed",
      "attempts": 1,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "llm_backup_calls": 0,
      "last_update": "2026-02-16T05:00:20.106184+00:00"
    },
    {
      "arxiv_id": "2602.08543v2",
      "title": "GISA: A Benchmark for General Information-Seeking Assistant",
      "title_zh": "GISA：通用信息寻求助手评测基准",
      "authors": [
        "Yutao Zhu",
        "Xingshuo Zhang",
        "Maosen Zhang",
        "Jiajie Jin",
        "Liancheng Zhang",
        "Xiaoshuai Song",
        "Kangzhi Zhao",
        "Wencong Zeng",
        "Ruiming Tang",
        "Han Li",
        "Ji-Rong Wen",
        "Zhicheng Dou"
      ],
      "abstract": "The advancement of large language models (LLMs) has significantly accelerated the development of search agents capable of autonomously gathering information through multi-turn web interactions. Various benchmarks have been proposed to evaluate such agents. However, existing benchmarks often construct queries backward from answers, producing unnatural tasks misaligned with real-world needs. Moreover, these benchmarks tend to focus on either locating specific information or aggregating information from multiple sources, while relying on static answer sets prone to data contamination. To bridge these gaps, we introduce GISA, a benchmark for General Information-Seeking Assistants comprising 373 human-crafted queries that reflect authentic information-seeking scenarios. GISA features four structured answer formats (item, set, list, and table), enabling deterministic evaluation. It integrates both deep reasoning and broad information aggregation within unified tasks, and includes a live subset with periodically updated answers to resist memorization. Notably, GISA provides complete human search trajectories for every query, offering gold-standard references for process-level supervision and imitation learning. Experiments on mainstream LLMs and commercial search products reveal that even the best-performing model achieves only 19.30\\% exact match score, with performance notably degrading on tasks requiring complex planning and comprehensive information gathering. These findings highlight substantial room for future improvement.",
      "tldr_zh": "该研究针对现有大规模语言模型（LLMs）搜索智能体评估基准中存在的任务不自然、易受数据污染以及缺乏复杂规划能力等局限性，提出了GISA，一个面向通用信息寻求助手（General Information-Seeking Assistant）的新型基准测试。GISA 包含 373 个由人工精心设计的查询，旨在反映真实的信息寻求场景，并采用了四种结构化回答格式（item, set, list, table）以实现确定性的自动评估。该基准测试将深层推理（deep reasoning）与广泛的信息聚合（information aggregation）整合在统一任务中，并包含一个定期更新答案的实时子集（live subset），以有效抵御模型对静态知识的记忆效应。此外，GISA 为每个查询提供了完整的人类搜索路径（human search trajectories），为过程层面的监督和模仿学习（imitation learning）提供了金标准参考。实验结果显示，即使是表现最佳的主流模型和商业搜索产品，在 GISA 上的精确匹配（exact match）得分也仅为 19.30%，在需要复杂规划和全面信息获取的任务上表现尤为欠佳。这一发现揭示了当前搜索智能体与人类能力之间存在的巨大差距，为未来通用信息寻求系统的改进指明了方向。",
      "categories": [
        "cs.CL",
        "cs.AI",
        "cs.IR"
      ],
      "primary_category": "cs.CL",
      "comment": "Project repo: https://github.com/RUC-NLPIR/GISA",
      "pdf_url": "https://arxiv.org/pdf/2602.08543v2",
      "published_date": "2026-02-09 11:44:15 UTC",
      "updated_date": "2026-02-13 07:28:55 UTC",
      "processing_status": "completed",
      "attempts": 1,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "llm_backup_calls": 0,
      "last_update": "2026-02-16T05:00:21.703098+00:00"
    },
    {
      "arxiv_id": "2602.08533v2",
      "title": "Dialogue Model Optimization via Agent Game and Adaptive Tree-based GRPO",
      "title_zh": "基于智能体博弈与自适应树型 GRPO 的对话模型优化",
      "authors": [
        "Kun Peng",
        "Conghui Tan",
        "Yu Liu",
        "Guohua Tang",
        "Zhongqian Sun",
        "Wei Yang",
        "Zining Zhu",
        "Lei Jiang",
        "Yanbing Liu",
        "Hao Peng"
      ],
      "abstract": "Open-ended dialogue agents aim to deliver engaging, personalized interactions by adapting to users' traits, but existing methods face critical limitations: over-reliance on pre-collected user data, and short-horizon biases in reinforcement learning (RL) that neglect long-term dialogue value. To address these, we propose a novel long-horizon RL framework integrating online personalization with Adaptive Tree-based Group Relative Policy Optimization (AT-GRPO). Adopting a two-agent game paradigm, a user agent constructs dynamic environments via style mimicry (learning user-specific conversational traits) and active termination (predicting turn-level termination probabilities as immediate rewards), forming an iterative cycle that drives the dialogue agent to deepen interest exploration. AT-GRPO reinterprets dialogue trajectories as trees and introduces adaptive observation ranges. Unlike full tree expansion that incurs exponential overhead, it limits each node to aggregate rewards from a stage-aware range: larger ranges support early-stage topic exploration, while smaller ranges facilitate late-stage dialogue maintenance. This design reduces rollout budgets from exponential to polynomial in the dialogue length, while preserving long-term reward capture. Extensive experiments show our framework's superior performance, sample efficiency, and robustness.",
      "tldr_zh": "该研究针对开放式对话智能体过度依赖预收集数据以及强化学习(RL)中存在的短视偏见问题，提出了一种结合在线个性化与自适应树状群体相对策略优化(AT-GRPO)的长程强化学习框架。该框架采用双智能体博弈模式，通过用户智能体的风格模仿(style mimicry)和主动终止(active termination)构建动态环境，驱动对话智能体深入探索用户兴趣。AT-GRPO将对话轨迹重新解释为树状结构并引入自适应观察范围，在对话早期通过大范围观察支持主题探索，在后期通过小范围观察维持对话。这种设计成功将对话生成的计算开销从随长度指数级增长降低至多项式级，同时保留了捕捉长程奖励的能力。实验结果表明，该框架在性能、样本效率和鲁棒性方面均显著优于现有模型。",
      "categories": [
        "cs.AI"
      ],
      "primary_category": "cs.AI",
      "comment": "",
      "pdf_url": "https://arxiv.org/pdf/2602.08533v2",
      "published_date": "2026-02-09 11:32:02 UTC",
      "updated_date": "2026-02-10 13:34:47 UTC",
      "processing_status": "completed",
      "attempts": 1,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "llm_backup_calls": 0,
      "last_update": "2026-02-16T05:00:27.805143+00:00"
    },
    {
      "arxiv_id": "2602.08520v3",
      "title": "Reinforcement Inference: Leveraging Uncertainty for Self-Correcting Language Model Reasoning",
      "title_zh": "强化推理：利用不确定性实现大语言模型推理的自我修正",
      "authors": [
        "Xinhai Sun"
      ],
      "abstract": "Modern large language models (LLMs) are often evaluated and deployed under a one-shot, greedy inference protocol, especially in professional settings that require deterministic behavior. This regime can systematically under-estimate a fixed model's true capability: many errors arise not from missing knowledge, but from premature commitment under internal ambiguity. We introduce Reinforcement Inference, an entropy-aware inference-time control strategy that uses the model's own uncertainty to selectively invoke a second, more deliberate reasoning attempt, enabling stronger performance without any retraining. On 12,032 MMLU-Pro questions across 14 subjects, using DeepSeek-v3.2 with deterministic decoding in a zero-shot setting, Reinforcement Inference improves accuracy from 60.72% to 84.03%, while only incurring 61.06% additional inference calls. A 100% re-asking ablation reaches 84.35%, indicating that uncertainty-aware selection captures most of the attainable improvement with substantially less compute. Moreover, a prompt-only ablation underperforms the baseline, suggesting that the gains are not explained by generic prompting alone. Beyond providing a practical inference-time upgrade, our results suggest a broader entropy-aware paradigm for measuring and expanding model capability: because modern decoder-based models generate outputs autoregressively, entropy and related confidence measures arise naturally as first-class control signals during generation. The resulting gap between one-pass greedy inference and uncertainty-conditioned deliberation offers a diagnostic lens on an LLM's latent reasoning horizon and motivates future training objectives that explicitly constrain correctness--confidence alignment.",
      "tldr_zh": "该研究提出了 Reinforcement Inference，这是一种基于熵感知的推理阶段控制策略 (entropy-aware inference-time control strategy)，旨在解决大型语言模型 (LLMs) 在贪婪推理 (greedy inference) 中因内部模糊性导致的过早决策问题。该方法通过监测模型的不确定性 (uncertainty)，选择性地引导模型进行第二次更深思熟虑的推理尝试，且无需对模型进行任何重新训练。在包含 14 个学科的 MMLU-Pro 基准测试中，使用 DeepSeek-v3.2 的实验表明该方法将零样本准确率从 60.72% 显著提升至 84.03%，而仅增加了 61.06% 的额外推理调用。消融实验进一步证明，这种不确定性感知选择能以较低的计算成本捕捉绝大部分性能提升，且其增益并非仅来自提示工程。该研究为衡量和扩展 LLMs 的潜在推理边界提供了新的熵感知视角，并对未来优化 correctness-confidence alignment 的训练目标具有指导意义。",
      "categories": [
        "cs.AI",
        "cs.LG"
      ],
      "primary_category": "cs.AI",
      "comment": "",
      "pdf_url": "https://arxiv.org/pdf/2602.08520v3",
      "published_date": "2026-02-09 11:08:24 UTC",
      "updated_date": "2026-02-12 05:32:26 UTC",
      "processing_status": "completed",
      "attempts": 1,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "llm_backup_calls": 0,
      "last_update": "2026-02-16T05:00:36.006791+00:00"
    },
    {
      "arxiv_id": "2602.08517v2",
      "title": "TreeTensor: Boost AI System on Nested Data with Constrained Tree-Like Tensor",
      "title_zh": "TreeTensor：利用约束性树形张量提升处理嵌套数据的人工智能系统性能",
      "authors": [
        "Shaoang Zhang",
        "Yazhe Niu"
      ],
      "abstract": "Tensor is the most basic and essential data structure of nowadays artificial intelligence (AI) system. The natural properties of Tensor, especially the memory-continuity and slice-independence, make it feasible for training system to leverage parallel computing unit like GPU to process data simultaneously in batch, spatial or temporal dimensions. However, if we look beyond perception tasks, the data in a complicated cognitive AI system usually has hierarchical structures (i.e. nested data) with various modalities. They are inconvenient and inefficient to program directly with conventional Tensor with fixed shape. To address this issue, we summarize two main computational patterns of nested data, and then propose a general nested data container: TreeTensor. Through various constraints and magic utilities of TreeTensor, one can apply arbitrary functions and operations to nested data with almost zero cost, including some famous machine learning libraries, such as Scikit-Learn, Numpy and PyTorch. Our approach utilizes a constrained tree-structure perspective to systematically model data relationships, and it can also easily be combined with other methods to extend more usages, such as asynchronous execution and variable-length data computation. Detailed examples and benchmarks show TreeTensor not only provides powerful usability in various problems, especially one of the most complicated AI systems at present: AlphaStar for StarCraftII, but also exhibits excellent runtime efficiency without any overhead. Our project is available at https://github.com/opendilab/DI-treetensor.",
      "tldr_zh": "该研究针对传统张量（Tensor）在处理具有分层结构（hierarchical structures）的嵌套数据（nested data）时存在的不便与低效问题，提出了TreeTensor这一通用的嵌套数据容器。TreeTensor利用受限树结构（constrained tree-structure）视角对数据关系进行系统建模，允许用户以近乎零的成本对嵌套数据应用各种函数操作。该框架能够无缝集成Scikit-Learn、Numpy和PyTorch等主流库，并支持异步执行（asynchronous execution）和变长数据计算（variable-length data computation）。基准测试和实际案例表明，TreeTensor在AlphaStar等复杂AI系统中展现了卓越的易用性，且在运行效率上没有任何额外开销（overhead）。这一工具为提升嵌套数据在现代AI系统中的处理能力提供了高效且灵活的解决方案。",
      "categories": [
        "cs.AI",
        "cs.SE"
      ],
      "primary_category": "cs.AI",
      "comment": "",
      "pdf_url": "https://arxiv.org/pdf/2602.08517v2",
      "published_date": "2026-02-09 11:06:13 UTC",
      "updated_date": "2026-02-12 03:55:59 UTC",
      "processing_status": "completed",
      "attempts": 1,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "llm_backup_calls": 0,
      "last_update": "2026-02-16T05:00:47.329438+00:00"
    },
    {
      "arxiv_id": "2602.08504v1",
      "title": "A General Theory of Proportionality with Additive Utilities",
      "title_zh": "具有加法效用的比例性通论",
      "authors": [
        "Piotr Skowron"
      ],
      "abstract": "We consider a model where a subset of candidates must be selected based on voter preferences, subject to general constraints that specify which subsets are feasible. This model generalizes committee elections with diversity constraints, participatory budgeting (including constraints specifying how funds must be allocated to projects from different pools), and public decision-making. Axioms of proportionality have recently been defined for this general model, but the proposed rules apply only to approval ballots, where each voter submits a subset of candidates she finds acceptable. We propose proportional rules for cardinal ballots, where each voter assigns a numerical value to each candidate corresponding to her utility if that candidate is selected. In developing these rules, we also introduce methods that produce proportional rankings, ensuring that every prefix of the ranking satisfies proportionality.",
      "tldr_zh": "该研究探讨了在通用约束条件下根据选民偏好选择候选人子集的模型，涵盖了委员会选举、参与式预算及公共决策等应用场景。针对现有比例性(Proportionality)公理主要局限于赞成投票(Approval Ballots)的问题，作者为基数投票(Cardinal Ballots)提出了全新的比例性规则，允许选民根据候选人带来的效用(Utility)分配数值偏好。此外，研究还引入了生成比例排名(Proportional Rankings)的方法，确保排名的每一个前缀都能满足比例性要求。该工作在加性效用(Additive Utilities)框架下扩展了公平代表权的理论边界，为复杂约束环境下的社会选择与决策提供了更具普适性的理论支撑。",
      "categories": [
        "cs.GT",
        "cs.AI",
        "cs.MA"
      ],
      "primary_category": "cs.GT",
      "comment": "",
      "pdf_url": "https://arxiv.org/pdf/2602.08504v1",
      "published_date": "2026-02-09 10:55:13 UTC",
      "updated_date": "2026-02-09 10:55:13 UTC",
      "processing_status": "completed",
      "attempts": 1,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "llm_backup_calls": 0,
      "last_update": "2026-02-16T05:01:06.799575+00:00"
    },
    {
      "arxiv_id": "2602.08499v1",
      "title": "Contextual Rollout Bandits for Reinforcement Learning with Verifiable Rewards",
      "title_zh": "面向具有可验证奖励强化学习的上下文 Rollout 多臂老虎机",
      "authors": [
        "Xiaodong Lu",
        "Xiaohan Wang",
        "Jiajun Chai",
        "Guojun Yin",
        "Wei Lin",
        "Zhijun Chen",
        "Yu Luo",
        "Fuzhen Zhuang",
        "Yikun Ban",
        "Deqing Wang"
      ],
      "abstract": "Reinforcement Learning with Verifiable Rewards (RLVR) is an effective paradigm for improving the reasoning capabilities of large language models. However, existing RLVR methods utilize rollouts in an indiscriminate and short-horizon manner: responses of heterogeneous quality within each prompt are treated uniformly, and historical rollouts are discarded after a single use. This leads to noisy supervision, poor sample efficiency, and suboptimal policy updates. We address these issues by formulating rollout scheduling in RLVR as a contextual bandit problem and proposing a unified neural scheduling framework that adaptively selects high-value rollouts throughout training. Each rollout is treated as an arm whose reward is defined by the induced performance gain between consecutive optimization steps. The resulting scheduler supports both noise-aware intra-group selection and adaptive global reuse of historical rollouts within a single principled framework. We provide theoretical justification by deriving sublinear regret bounds and showing that enlarging the rollout buffer improves the achievable performance upper bound. Experiments on six mathematical reasoning benchmarks demonstrate consistent gains in performance and training efficiency across multiple RLVR optimization methods.",
      "tldr_zh": "该研究针对具有可验证奖励的强化学习(Reinforcement Learning with Verifiable Rewards, RLVR)中rollout利用效率低下和监督噪声较大的问题，提出了Contextual Rollout Bandits调度框架。作者将rollout调度建模为contextual bandit问题，通过统一的神经调度框架自适应地在训练过程中选择高价值的rollout。该方法将每个rollout视为arm，利用优化步骤间的性能增益定义奖励，从而实现了噪声感知的intra-group选择以及历史rollout的全局重用(global reuse)。理论分析导出了sublinear regret bounds，并证明扩大rollout buffer能有效提升性能上限。在六个数学推理基准测试上的实验结果表明，该方法在多种RLVR优化算法中均能显著提升大语言模型的推理性能和整体训练效率。",
      "categories": [
        "cs.LG",
        "cs.AI"
      ],
      "primary_category": "cs.LG",
      "comment": "",
      "pdf_url": "https://arxiv.org/pdf/2602.08499v1",
      "published_date": "2026-02-09 10:51:58 UTC",
      "updated_date": "2026-02-09 10:51:58 UTC",
      "processing_status": "completed",
      "attempts": 1,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "llm_backup_calls": 0,
      "last_update": "2026-02-16T05:01:15.606221+00:00"
    },
    {
      "arxiv_id": "2602.10144v1",
      "title": "When LLMs get significantly worse: A statistical approach to detect model degradations",
      "title_zh": "当大语言模型性能显著下降时：一种检测模型退化的统计学方法",
      "authors": [
        "Jonas Kübler",
        "Kailash Budhathoki",
        "Matthäus Kleindessner",
        "Xiong Zhou",
        "Junming Yin",
        "Ashish Khetan",
        "George Karypis"
      ],
      "abstract": "Minimizing the inference cost and latency of foundation models has become a crucial area of research. Optimization approaches include theoretically lossless methods and others without accuracy guarantees like quantization. In all of these cases it is crucial to ensure that the model quality has not degraded. However, even at temperature zero, model generations are not necessarily robust even to theoretically lossless model optimizations due to numerical errors. We thus require statistical tools to decide whether a finite-sample accuracy deviation is an evidence of a model's degradation or whether it can be attributed to (harmless) noise in the evaluation. We propose a statistically sound hypothesis testing framework based on McNemar's test allowing to efficiently detect model degradations, while guaranteeing a controlled rate of false positives. The crucial insight is that we have to confront the model scores on each sample, rather than aggregated on the task level. Furthermore, we propose three approaches to aggregate accuracy estimates across multiple benchmarks into a single decision. We provide an implementation on top of the largely adopted open source LM Evaluation Harness and provide a case study illustrating that the method correctly flags degraded models, while not flagging model optimizations that are provably lossless. We find that with our tests even empirical accuracy degradations of 0.3% can be confidently attributed to actual degradations rather than noise.",
      "tldr_zh": "针对大语言模型(LLMs)在优化过程中可能出现的性能下降问题，该研究提出了一种检测模型退化的统计方法。尽管量化等优化手段能降低成本，但即便是理论上的无损优化也可能因数值误差导致输出不稳定，因此需要区分性能波动是源于实际退化还是随机噪声。该研究开发了一个基于McNemar's test的统计假设检验框架，其核心见解在于对比每个样本的得分而非仅依赖任务级别的聚合指标，从而在保证误报率受控的同时高效检测退化。研究者还设计了三种将跨多个基准测试(benchmarks)的准确率估计聚合成单一决策的方法，并在LM Evaluation Harness之上进行了实现。实验证明，该框架能有效识别退化的模型，且不会误报可证明无损的优化。结果显示，该方法甚至能将0.3%的微小准确率下降置信地归因为实际退化，为确保模型优化后的质量提供了可靠的统计工具。",
      "categories": [
        "stat.ML",
        "cs.AI",
        "cs.LG"
      ],
      "primary_category": "stat.ML",
      "comment": "https://openreview.net/forum?id=cM3gsqEI4K",
      "pdf_url": "https://arxiv.org/pdf/2602.10144v1",
      "published_date": "2026-02-09 10:45:13 UTC",
      "updated_date": "2026-02-09 10:45:13 UTC",
      "processing_status": "completed",
      "attempts": 1,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "llm_backup_calls": 0,
      "last_update": "2026-02-16T05:01:20.096683+00:00"
    },
    {
      "arxiv_id": "2602.08482v1",
      "title": "CLEAR: A Knowledge-Centric Vessel Trajectory Analysis Platform",
      "title_zh": "CLEAR：以知识为中心的船舶轨迹分析平台",
      "authors": [
        "Hengyu Liu",
        "Tianyi Li",
        "Haoyu Wang",
        "Kristian Torp",
        "Yushuai Li",
        "Tiancheng Zhang",
        "Torben Bach Pedersen",
        "Christian S. Jensen"
      ],
      "abstract": "Vessel trajectory data from the Automatic Identification System (AIS) is used widely in maritime analytics. Yet, analysis is difficult for non-expert users due to the incompleteness and complexity of AIS data. We present CLEAR, a knowledge-centric vessel trajectory analysis platform that aims to overcome these barriers. By leveraging the reasoning and generative capabilities of Large Language Models (LLMs), CLEAR transforms raw AIS data into complete, interpretable, and easily explorable vessel trajectories through a Structured Data-derived Knowledge Graph (SD-KG). As part of the demo, participants can configure parameters to automatically download and process AIS data, observe how trajectories are completed and annotated, inspect both raw and imputed segments together with their SD-KG evidence, and interactively explore the SD-KG through a dedicated graph viewer, gaining an intuitive and transparent understanding of vessel movements.",
      "tldr_zh": "该研究推出了CLEAR，一个以知识为中心的船舶轨迹分析平台，旨在解决因自动识别系统(AIS)数据的不完整性和复杂性导致的非专家用户分析难的问题。该平台充分利用大语言模型(LLMs)的推理与生成能力，通过构建结构化数据衍生的知识图谱(SD-KG)，将原始AIS数据转化为完整、可解释且易于探索的船舶轨迹。在系统展示中，用户可以配置参数实现AIS数据的自动下载与处理，并实时观察轨迹的补全与标注过程。参与者能够同时检视原始轨迹段与插值片段及其对应的SD-KG证据，并通过专用图谱查看器进行交互式探索。该平台通过这种集成方式，为用户提供了对船舶动态直观且透明的理解。",
      "categories": [
        "cs.DB",
        "cs.AI"
      ],
      "primary_category": "cs.DB",
      "comment": "4 pages, and 5 Figures",
      "pdf_url": "https://arxiv.org/pdf/2602.08482v1",
      "published_date": "2026-02-09 10:32:26 UTC",
      "updated_date": "2026-02-09 10:32:26 UTC",
      "processing_status": "completed",
      "attempts": 1,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "llm_backup_calls": 0,
      "last_update": "2026-02-16T05:01:24.705255+00:00"
    },
    {
      "arxiv_id": "2602.08479v1",
      "title": "Gesture Matters: Pedestrian Gesture Recognition for AVs Through Skeleton Pose Evaluation",
      "title_zh": "手势的重要性：基于骨架姿态评估的自动驾驶行人手势识别",
      "authors": [
        "Alif Rizqullah Mahdi",
        "Mahdi Rezaei",
        "Natasha Merat"
      ],
      "abstract": "Gestures are a key component of non-verbal communication in traffic, often helping pedestrian-to-driver interactions when formal traffic rules may be insufficient. This problem becomes more apparent when autonomous vehicles (AVs) struggle to interpret such gestures. In this study, we present a gesture classification framework using 2D pose estimation applied to real-world video sequences from the WIVW dataset. We categorise gestures into four primary classes (Stop, Go, Thank & Greet, and No Gesture) and extract 76 static and dynamic features from normalised keypoints. Our analysis demonstrates that hand position and movement velocity are especially discriminative in distinguishing between gesture classes, achieving a classification accuracy score of 87%. These findings not only improve the perceptual capabilities of AV systems but also contribute to the broader understanding of pedestrian behaviour in traffic contexts.",
      "tldr_zh": "该研究针对自动驾驶车辆(AVs)在理解行人非语言交流方面的挑战，提出了一个基于2D姿态估计(2D pose estimation)的手势分类框架。研究利用来自WIVW dataset的真实视频序列，将手势划分为Stop、Go、Thank & Greet以及No Gesture四类，并从中提取了76个静态与动态特征(static and dynamic features)。实验分析表明，手部位置(hand position)和运动速度(movement velocity)在区分手势类别时具有显著的辨别力，该框架最终实现了87%的分类准确率。这一研究成果不仅增强了自动驾驶系统(AV systems)的感知维度，也为深入理解交通场景中的行人行为做出了贡献。",
      "categories": [
        "cs.CV",
        "cs.AI",
        "cs.ET",
        "cs.HC",
        "cs.LG"
      ],
      "primary_category": "cs.CV",
      "comment": "9th International Conference on Instrumentation, Control, and Automation (ICA)",
      "pdf_url": "https://arxiv.org/pdf/2602.08479v1",
      "published_date": "2026-02-09 10:28:21 UTC",
      "updated_date": "2026-02-09 10:28:21 UTC",
      "processing_status": "completed",
      "attempts": 1,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "llm_backup_calls": 0,
      "last_update": "2026-02-16T05:01:31.098420+00:00"
    },
    {
      "arxiv_id": "2602.09071v1",
      "title": "DRAGON: Robust Classification for Very Large Collections of Software Repositories",
      "title_zh": "DRAGON：面向超大规模软件仓库集的鲁棒分类",
      "authors": [
        "Stefano Balla",
        "Stefano Zacchiroli",
        "Thomas Degueule",
        "Jean-Rémy Falleri",
        "Romain Robbes"
      ],
      "abstract": "The ability to automatically classify source code repositories with ''topics'' that reflect their content and purpose is very useful, especially when navigating or searching through large software collections. However, existing approaches often rely heavily on README files and other metadata, which are frequently missing, limiting their applicability in real-world large-scale settings. We present DRAGON, a repository classifier designed for very large and diverse software collections. It operates entirely on lightweight signals commonly stored in version control systems: file and directory names, and optionally the README when available. In repository classification at scale, DRAGON improves F1@5 from 54.8% to 60.8%, surpassing the state of the art. DRAGON remains effective even when README files are absent, with performance degrading by only 6% w.r.t. when they are present. This robustness makes it practical for real-world settings where documentation is sparse or inconsistent. Furthermore, many of the remaining classification errors are near misses, where predicted labels are semantically close to the correct topics. This property increases the practical value of the predictions in real-world software collections, where suggesting a few related topics can still guide search and discovery. As a byproduct of developing DRAGON, we also release the largest open dataset to date for repository classification, consisting of 825 thousand repositories with associated ground-truth topics, sourced from the Software Heritage archive, providing a foundation for future large-scale and language-agnostic research on software repository understanding.",
      "tldr_zh": "该研究提出了 DRAGON，一种专为大规模和多样化软件集合设计的仓库分类器，旨在解决现有方法过度依赖 README 等元数据而在实际场景中受限的问题。DRAGON 完全基于版本控制系统中的文件和目录名称等轻量化信号运行，仅在 README 可用时将其作为可选输入。实验表明，DRAGON 在大规模仓库分类任务中将 F1@5 从 54.8% 提升至 60.8%，超越了现有最先进技术(state of the art)。即使在缺少 README 的情况下，其性能仅下降 6%，表现出极强的鲁棒性(robustness)，且其分类错误多为语义接近的“近错(near misses)”，具有极高的实用价值。此外，该研究还发布了源自 Software Heritage 存档、包含 82.5 万个仓库的目前最大规模开源数据集，为未来跨语言的软件仓库理解研究奠定了基础。",
      "categories": [
        "cs.SE",
        "cs.AI",
        "cs.LG"
      ],
      "primary_category": "cs.SE",
      "comment": "",
      "pdf_url": "https://arxiv.org/pdf/2602.09071v1",
      "published_date": "2026-02-09 10:27:24 UTC",
      "updated_date": "2026-02-09 10:27:24 UTC",
      "processing_status": "completed",
      "attempts": 1,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "llm_backup_calls": 0,
      "last_update": "2026-02-16T05:02:21.013589+00:00"
    },
    {
      "arxiv_id": "2602.08456v1",
      "title": "Decentralized Spatial Reuse Optimization in Wi-Fi: An Internal Regret Minimization Approach",
      "title_zh": "Wi-Fi 分布式空间复用优化：一种内部遗憾最小化方法",
      "authors": [
        "Francesc Wilhelmi",
        "Boris Bellalta",
        "Miguel Casasnovas",
        "Aleksandra Kijanka",
        "Miguel Calvo-Fullana"
      ],
      "abstract": "Spatial Reuse (SR) is a cost-effective technique for improving spectral efficiency in dense IEEE 802.11 deployments by enabling simultaneous transmissions. However, the decentralized optimization of SR parameters -- transmission power and Carrier Sensing Threshold (CST) -- across different Basic Service Sets (BSSs) is challenging due to the lack of global state information. In addition, the concurrent operation of multiple agents creates a highly non-stationary environment, often resulting in suboptimal global configurations (e.g., using the maximum possible transmission power by default). To overcome these limitations, this paper introduces a decentralized learning algorithm based on regret-matching, grounded in internal regret minimization. Unlike standard decentralized ``selfish'' approaches that often converge to inefficient Nash Equilibria (NE), internal regret minimization guides competing agents toward Correlated Equilibria (CE), effectively mimicking coordination without explicit communication. Through simulation results, we showcase the superiority of our proposed approach and its ability to reach near-optimal global performance. These results confirm the not-yet-unleashed potential of scalable decentralized solutions and question the need for the heavy signaling overheads and architectural complexity associated with emerging centralized solutions like Multi-Access Point Coordination (MAPC).",
      "tldr_zh": "该研究针对密集 IEEE 802.11 部署中空间复用 (Spatial Reuse, SR) 的参数优化难题，重点探讨了传输功率和载波监听阈值 (Carrier Sensing Threshold, CST) 的有效调节。为了克服去中心化环境下缺乏全局信息及多智能体非平稳性导致的次优配置，论文提出了一种基于内部后悔最小化 (Internal Regret Minimization) 的后悔匹配 (regret-matching) 学习算法。与以往常收敛于低效纳什均衡 (Nash Equilibria, NE) 的自私博弈方法不同，该算法能引导智能体达成相关均衡 (Correlated Equilibria, CE)，在无需显式通信的情况下模拟了协调行为。仿真结果证明，该方案能够实现接近全局最优的性能，显著提升了网络效率。此项成果展示了可扩展去中心化方案的巨大潜力，并对多接入点协作 (Multi-Access Point Coordination, MAPC) 等复杂中心化架构的必要性提出了质疑。",
      "categories": [
        "cs.NI",
        "cs.AI"
      ],
      "primary_category": "cs.NI",
      "comment": "",
      "pdf_url": "https://arxiv.org/pdf/2602.08456v1",
      "published_date": "2026-02-09 10:10:18 UTC",
      "updated_date": "2026-02-09 10:10:18 UTC",
      "processing_status": "completed",
      "attempts": 1,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "llm_backup_calls": 0,
      "last_update": "2026-02-16T05:05:26.396894+00:00"
    },
    {
      "arxiv_id": "2602.08449v2",
      "title": "When Evaluation Becomes a Side Channel: Regime Leakage and Structural Mitigations for Alignment Assessment",
      "title_zh": "当评估成为侧信道：对齐评估中的环境泄露与结构性缓解措施",
      "authors": [
        "Igor Santos-Grueiro"
      ],
      "abstract": "Safety evaluation for advanced AI systems implicitly assumes that behavior observed under evaluation predicts behavior in deployment. This assumption becomes fragile for agents with situational awareness, which may exploit regime leakage, that is, cues distinguishing evaluation from deployment, to implement conditional policies that comply under oversight while defecting in deployment-like regimes. We reframe alignment evaluation as a problem of information flow under partial observability and show that divergence between evaluation-time and deployment-time behavior is bounded by the amount of regime information extractable from decision-relevant internal representations.\n  Motivated by this result, we study regime-blind mechanisms, training-time interventions that reduce access to regime cues through adversarial invariance constraints, without assuming information-theoretic erasure. We evaluate this approach on an open-weight language model across controlled failure modes including scientific sycophancy, temporal sleeper agents, and data leakage. Regime-blind training suppresses regime-conditioned failures without measurable loss of task utility, but exhibits heterogeneous dynamics. Sycophancy shows a sharp representational and behavioral transition at low intervention strength, while sleeper-agent behavior requires substantially stronger pressure and does not yield a clean collapse of regime decodability at the audited bottleneck.\n  These results show that representational invariance is a meaningful but fundamentally limited control lever. It can reduce the feasibility of regime-conditioned strategies by shifting representational costs, but cannot guarantee their elimination. We therefore argue that behavioral evaluation should be complemented with white-box diagnostics of regime awareness and internal information flow.",
      "tldr_zh": "该研究探讨了先进AI系统在安全性评估中面临的政权泄漏（Regime Leakage）问题，即具有情境意识（Situational Awareness）的智能体可能利用区分评估与部署环境的线索，实施在监督下表现合规但在部署阶段背叛的有条件策略。作者将对齐评估（Alignment Assessment）重新定义为部分可观测性下的信息流问题，并证明评估与部署行为之间的偏差取决于从决策相关的内部表示中提取政权信息的能力。为缓解此风险，研究提出了政权盲机制（Regime-blind Mechanisms），通过对抗不变性（Adversarial Invariance）约束在训练阶段减少模型对环境线索的访问。实验在科学谄媚（Scientific Sycophancy）、时间触发潜伏代理（Temporal Sleeper Agents）及数据泄漏等故障模式下验证了该方法的有效性。结果显示，政权盲训练能有效抑制受环境触发的故障且不损失任务效用，但在不同任务中表现出异质动态。研究最终指出表征不变性是一个重要但有限的控制手段，并建议将行为评估与针对政权意识和内部信息流的白盒诊断（White-box Diagnostics）相结合。",
      "categories": [
        "cs.AI",
        "cs.CR",
        "cs.LG"
      ],
      "primary_category": "cs.AI",
      "comment": "Corrected figure coherence and consistency",
      "pdf_url": "https://arxiv.org/pdf/2602.08449v2",
      "published_date": "2026-02-09 10:00:24 UTC",
      "updated_date": "2026-02-11 23:06:23 UTC",
      "processing_status": "completed",
      "attempts": 1,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "llm_backup_calls": 0,
      "last_update": "2026-02-16T05:05:19.708063+00:00"
    },
    {
      "arxiv_id": "2602.08448v1",
      "title": "Vista: Scene-Aware Optimization for Streaming Video Question Answering under Post-Hoc Queries",
      "title_zh": "Vista：面向事后查询的流式视频问答场景感知优化",
      "authors": [
        "Haocheng Lu",
        "Nan Zhang",
        "Wei Tao",
        "Xiaoyang Qu",
        "Guokuan Li",
        "Jiguang Wan",
        "Jianzong Wang"
      ],
      "abstract": "Streaming video question answering (Streaming Video QA) poses distinct challenges for multimodal large language models (MLLMs), as video frames arrive sequentially and user queries can be issued at arbitrary time points. Existing solutions relying on fixed-size memory or naive compression often suffer from context loss or memory overflow, limiting their effectiveness in long-form, real-time scenarios. We present Vista, a novel framework for scene-aware streaming video QA that enables efficient and scalable reasoning over continuous video streams. The innovation of Vista can be summarized in three aspects: (1) scene-aware segmentation, where Vista dynamically clusters incoming frames into temporally and visually coherent scene units; (2) scene-aware compression, where each scene is compressed into a compact token representation and stored in GPU memory for efficient index-based retrieval, while full-resolution frames are offloaded to CPU memory; and (3) scene-aware recall, where relevant scenes are selectively recalled and reintegrated into the model input upon receiving a query, enabling both efficiency and completeness. Vista is model-agnostic and integrates seamlessly with a variety of vision-language backbones, enabling long-context reasoning without compromising latency or memory efficiency. Extensive experiments on StreamingBench demonstrate that Vista achieves state-of-the-art performance, establishing a strong baseline for real-world streaming video understanding.",
      "tldr_zh": "该研究针对流媒体视频问答(Streaming Video QA)中多模态大语言模型(MLLMs)面临的视频帧序列化输入和随机查询挑战，提出了名为Vista的场景感知(Scene-Aware)优化框架。为了解决现有固定内存方案导致的上下文丢失和内存溢出问题，Vista引入了场景感知分割，将输入帧动态聚类为视觉连贯的场景单元。在压缩环节，该框架将场景转化为紧凑的Token表示存入GPU用于高效检索，同时将全分辨率帧卸载至CPU以优化内存效率。当接收到查询时，其场景感知召回机制能精确提取相关场景并重新整合，实现了高效且完整的长上下文推理。Vista具有模型无关性(Model-agnostic)，能无缝适配多种视觉语言(Vision-Language)骨干网络而不影响系统延迟。实验结果显示，Vista在StreamingBench上达到了当前最先进的(State-of-the-art)性能，为真实场景下的流媒体视频理解奠定了重要基础。",
      "categories": [
        "cs.CV",
        "cs.AI"
      ],
      "primary_category": "cs.CV",
      "comment": "Accepted to AAAI 2026 (Main Technical Track)",
      "pdf_url": "https://arxiv.org/pdf/2602.08448v1",
      "published_date": "2026-02-09 10:00:22 UTC",
      "updated_date": "2026-02-09 10:00:22 UTC",
      "processing_status": "completed",
      "attempts": 1,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "llm_backup_calls": 0,
      "last_update": "2026-02-16T05:05:25.906983+00:00"
    },
    {
      "arxiv_id": "2602.09070v2",
      "title": "NarraScore: Bridging Visual Narrative and Musical Dynamics via Hierarchical Affective Control",
      "title_zh": "NarraScore：基于分层情感控制桥接视觉叙事与音乐动态",
      "authors": [
        "Yufan Wen",
        "Zhaocheng Liu",
        "YeGuo Hua",
        "Ziyi Guo",
        "Lihua Zhang",
        "Chun Yuan",
        "Jian Wu"
      ],
      "abstract": "Synthesizing coherent soundtracks for long-form videos remains a formidable challenge, currently stalled by three critical impediments: computational scalability, temporal coherence, and, most critically, a pervasive semantic blindness to evolving narrative logic. To bridge these gaps, we propose NarraScore, a hierarchical framework predicated on the core insight that emotion serves as a high-density compression of narrative logic. Uniquely, we repurpose frozen Vision-Language Models (VLMs) as continuous affective sensors, distilling high-dimensional visual streams into dense, narrative-aware Valence-Arousal trajectories. Mechanistically, NarraScore employs a Dual-Branch Injection strategy to reconcile global structure with local dynamism: a \\textit{Global Semantic Anchor} ensures stylistic stability, while a surgical \\textit{Token-Level Affective Adapter} modulates local tension via direct element-wise residual injection. This minimalist design bypasses the bottlenecks of dense attention and architectural cloning, effectively mitigating the overfitting risks associated with data scarcity. Experiments demonstrate that NarraScore achieves state-of-the-art consistency and narrative alignment with negligible computational overhead, establishing a fully autonomous paradigm for long-video soundtrack generation.",
      "tldr_zh": "该研究针对长视频配乐合成中面临的计算可扩展性、时间一致性以及对演变叙事逻辑感知不足等挑战，提出了 NarraScore 分层框架。其核心洞察是将情绪视为叙事逻辑的高密度压缩，从而有效桥接视觉叙事与音乐动态。NarraScore 将冻结的视觉语言模型 (Vision-Language Models, VLMs) 重新利用为连续情感传感器，将高维视觉流蒸馏为具有叙事意识的 Valence-Arousal 轨迹。在机制上，该框架采用双分支注入 (Dual-Branch Injection) 策略，通过 Global Semantic Anchor 确保整体风格稳定，并利用 Token-Level Affective Adapter 通过直接元素级残差注入调节局部张力。这种极简设计避开了密集注意力的计算瓶颈，并缓解了数据稀缺导致的过拟合风险。实验证明，NarraScore 在计算开销极低的情况下实现了最先进的一致性和叙事对齐度，为长视频配乐生成建立了一种全自动化的新范式。",
      "categories": [
        "cs.SD",
        "cs.AI",
        "eess.AS"
      ],
      "primary_category": "cs.SD",
      "comment": "",
      "pdf_url": "https://arxiv.org/pdf/2602.09070v2",
      "published_date": "2026-02-09 09:39:42 UTC",
      "updated_date": "2026-02-12 02:33:29 UTC",
      "processing_status": "completed",
      "attempts": 1,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "llm_backup_calls": 0,
      "last_update": "2026-02-16T05:05:32.302307+00:00"
    },
    {
      "arxiv_id": "2602.08426v1",
      "title": "Prism: Spectral-Aware Block-Sparse Attention",
      "title_zh": "Prism：频谱感知的块稀疏注意力",
      "authors": [
        "Xinghao Wang",
        "Pengyu Wang",
        "Xiaoran Liu",
        "Fangxu Liu",
        "Jason Chu",
        "Kai Song",
        "Xipeng Qiu"
      ],
      "abstract": "Block-sparse attention is promising for accelerating long-context LLM pre-filling, yet identifying relevant blocks efficiently remains a bottleneck. Existing methods typically employ coarse-grained attention as a proxy for block importance estimation, but often resort to expensive token-level searching or scoring, resulting in significant selection overhead. In this work, we trace the inaccuracy of standard coarse-grained attention via mean pooling to a theoretical root cause: the interaction between mean pooling and Rotary Positional Embeddings (RoPE). We prove that mean pooling acts as a low-pass filter that induces destructive interference in high-frequency dimensions, effectively creating a \"blind spot\" for local positional information (e.g., slash patterns). To address this, we introduce Prism, a training-free spectral-aware approach that decomposes block selection into high-frequency and low-frequency branches. By applying energy-based temperature calibration, Prism restores the attenuated positional signals directly from pooled representations, enabling block importance estimation using purely block-level operations, thereby improving efficiency. Extensive evaluations confirm that Prism maintains accuracy parity with full attention while delivering up to $\\mathbf{5.1\\times}$ speedup.",
      "tldr_zh": "该研究针对长上下文大型语言模型 (LLMs) 预填充阶段中 block-sparse attention 识别相关块效率低下的瓶颈问题。作者通过理论推导发现，传统基于平均池化 (mean pooling) 的粗粒度注意力方法不准确的根源在于池化操作与 Rotary Positional Embeddings (RoPE) 之间的相互作用。研究证明平均池化起到了低通滤波器 (low-pass filter) 的作用，在离频维度产生破坏性干扰，从而导致局部位置信息（如 slash patterns）出现“盲点”。为此，本工作提出了 Prism，一种无需训练的频谱感知方法，将块选择过程分解为高频和低频两个分支。Prism 通过引入基于能量的温度校准 (energy-based temperature calibration)，能够直接从池化表示中恢复被削弱的位置信号，从而仅依靠块级操作实现重要性估计。实验结果表明，Prism 在保持与 full attention 相当的准确率的同时，实现了高达 5.1 倍的推理加速，显著提升了处理效率。",
      "categories": [
        "cs.CL",
        "cs.AI",
        "cs.CV"
      ],
      "primary_category": "cs.CL",
      "comment": "",
      "pdf_url": "https://arxiv.org/pdf/2602.08426v1",
      "published_date": "2026-02-09 09:31:06 UTC",
      "updated_date": "2026-02-09 09:31:06 UTC",
      "processing_status": "completed",
      "attempts": 1,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "llm_backup_calls": 0,
      "last_update": "2026-02-16T05:05:17.603872+00:00"
    },
    {
      "arxiv_id": "2602.08422v1",
      "title": "LLMs + Security = Trouble",
      "title_zh": "LLMs + 安全 = 隐患",
      "authors": [
        "Benjamin Livshits"
      ],
      "abstract": "We argue that when it comes to producing secure code with AI, the prevailing \"fighting fire with fire\" approach -- using probabilistic AI-based checkers or attackers to secure probabilistically generated code -- fails to address the long tail of security bugs. As a result, systems may remain exposed to zero-day vulnerabilities that can be discovered by better-resourced or more persistent adversaries.\n  While neurosymbolic approaches that combine LLMs with formal methods are attractive in principle, we argue that they are difficult to reconcile with the \"vibe coding\" workflow common in LLM-assisted development: unless the end-to-end verification pipeline is fully automated, developers are repeatedly asked to validate specifications, resolve ambiguities, and adjudicate failures, making the human-in-the-loop a likely point of weakness, compromising secure-by-construction guarantees.\n  In this paper we argue that stronger security guarantees can be obtained by enforcing security constraints during code generation (e.g., via constrained decoding), rather than relying solely on post-hoc detection and repair. This direction is particularly promising for diffusion-style code models, whose approach provides a natural elegant opportunity for modular, hierarchical security enforcement, allowing us to combine lower-latency generation techniques with generating secure-by-construction code.",
      "tldr_zh": "该研究探讨了大型语言模型(LLMs)在生成安全代码方面的局限性，指出目前通用的“以火攻火”模式——即利用基于概率的AI检测器或攻击者来保护同样基于概率生成的代码——无法有效解决长尾安全漏洞问题，导致系统仍易受零日漏洞攻击。作者认为，尽管将LLMs与形式化方法结合的神经符号(Neurosymbolic)方法在理论上具有吸引力，但其难以融入开发者常用的“氛围编程(Vibe Coding)”工作流，因为非全自动的验证流程会使人类开发者成为安全保障中的薄弱环节。为此，论文提出了一种更强的安全保障思路，即在代码生成过程中通过约束解码(Constrained Decoding)等手段强制执行安全约束，而非仅仅依赖事后的检测与修复。这种方法在扩散式代码模型(Diffusion-style Code Models)中尤为有效，能够实现模块化、层次化的安全增强，在保持低延迟生成的同时产出具备“构造即安全(Secure-by-construction)”特性的代码。",
      "categories": [
        "cs.CR",
        "cs.AI",
        "cs.SE"
      ],
      "primary_category": "cs.CR",
      "comment": "",
      "pdf_url": "https://arxiv.org/pdf/2602.08422v1",
      "published_date": "2026-02-09 09:27:28 UTC",
      "updated_date": "2026-02-09 09:27:28 UTC",
      "processing_status": "completed",
      "attempts": 1,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "llm_backup_calls": 0,
      "last_update": "2026-02-16T05:05:39.617345+00:00"
    },
    {
      "arxiv_id": "2602.08412v2",
      "title": "From Assistant to Double Agent: Formalizing and Benchmarking Attacks on OpenClaw for Personalized Local AI Agent",
      "title_zh": "从助手到“双面间谍”：针对个性化本地 AI 智能体 OpenClaw 攻击的规范化与基准测试",
      "authors": [
        "Yuhang Wang",
        "Feiming Xu",
        "Zheng Lin",
        "Guangyu He",
        "Yuzhe Huang",
        "Haichang Gao",
        "Zhenxing Niu",
        "Shiguo Lian",
        "Zhaoxiang Liu"
      ],
      "abstract": "Although large language model (LLM)-based agents, exemplified by OpenClaw, are increasingly evolving from task-oriented systems into personalized AI assistants for solving complex real-world tasks, their practical deployment also introduces severe security risks. However, existing agent security research and evaluation frameworks primarily focus on synthetic or task-centric settings, and thus fail to accurately capture the attack surface and risk propagation mechanisms of personalized agents in real-world deployments. To address this gap, we propose Personalized Agent Security Bench (PASB), an end-to-end security evaluation framework tailored for real-world personalized agents. Building upon existing agent attack paradigms, PASB incorporates personalized usage scenarios, realistic toolchains, and long-horizon interactions, enabling black-box, end-to-end security evaluation on real systems. Using OpenClaw as a representative case study, we systematically evaluate its security across multiple personalized scenarios, tool capabilities, and attack types. Our results indicate that OpenClaw exhibits critical vulnerabilities at different execution stages, including user prompt processing, tool usage, and memory retrieval, highlighting substantial security risks in personalized agent deployments. The code for the proposed PASB framework is available at https://github.com/AstorYH/PASB.",
      "tldr_zh": "该研究提出了针对真实世界个性化AI智能体（Personalized AI Agent）的端到端安全评估框架PASB（Personalized Agent Security Bench），旨在填补现有研究在捕捉复杂攻击面和风险传播机制方面的空白。通过以开源智能体系统OpenClaw作为代表性案例研究，PASB在集成个性化使用场景、真实工具链及长周期交互的基础上，系统评估了其在多类攻击下的安全性表现。实验结果揭示了OpenClaw在用户提示处理（user prompt processing）、工具使用（tool usage）以及内存检索（memory retrieval）等关键执行阶段均存在严重的安全漏洞。这项工作不仅形式化定义了针对本地个性化智能体的攻击范式，还通过PASB框架的开源为提升自主智能体在实际部署中的安全性和可信度提供了重要的基准测试工具。",
      "categories": [
        "cs.AI"
      ],
      "primary_category": "cs.AI",
      "comment": "11 pages,2 figures",
      "pdf_url": "https://arxiv.org/pdf/2602.08412v2",
      "published_date": "2026-02-09 09:14:58 UTC",
      "updated_date": "2026-02-11 05:31:59 UTC",
      "processing_status": "completed",
      "attempts": 1,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "llm_backup_calls": 0,
      "last_update": "2026-02-16T05:05:38.730103+00:00"
    },
    {
      "arxiv_id": "2602.08406v1",
      "title": "Optimizing Spectral Prediction in MXene-Based Metasurfaces Through Multi-Channel Spectral Refinement and Savitzky-Golay Smoothing",
      "title_zh": "通过多通道光谱精细化与 Savitzky-Golay 平滑优化 MXene 基超表面的光谱预测",
      "authors": [
        "Shujaat Khan",
        "Waleed Iqbal Waseer"
      ],
      "abstract": "The prediction of electromagnetic spectra for MXene-based solar absorbers is a computationally intensive task, traditionally addressed using full-wave solvers. This study introduces an efficient deep learning framework incorporating transfer learning, multi-channel spectral refinement (MCSR), and Savitzky-Golay smoothing to accelerate and enhance spectral prediction accuracy. The proposed architecture leverages a pretrained MobileNetV2 model, fine-tuned to predict 102-point absorption spectra from $64\\times64$ metasurface designs. Additionally, the MCSR module processes the feature map through multi-channel convolutions, enhancing feature extraction, while Savitzky-Golay smoothing mitigates high-frequency noise. Experimental evaluations demonstrate that the proposed model significantly outperforms baseline Convolutional Neural Network (CNN) and deformable CNN models, achieving an average root mean squared error (RMSE) of 0.0245, coefficient of determination \\( R^2 \\) of 0.9578, and peak signal-to-noise ratio (PSNR) of 32.98 dB. The proposed framework presents a scalable and computationally efficient alternative to conventional solvers, positioning it as a viable candidate for rapid spectral prediction in nanophotonic design workflows.",
      "tldr_zh": "该研究针对MXene基超表面(Metasurfaces)太阳能吸收器在电磁光谱预测中计算开销巨大的挑战，提出了一种集成迁移学习(Transfer Learning)、多通道光谱精细化(Multi-Channel Spectral Refinement, MCSR)和Savitzky-Golay Smoothing的深度学习框架。该架构利用预训练的MobileNetV2模型，能够从$64\\times64$的超表面设计中精确预测102点吸收光谱。MCSR模块通过多通道卷积增强了特征提取能力，而Savitzky-Golay Smoothing则有效消除了高频噪声。实验结果表明，该模型在RMSE (0.0245)、$R^2$ (0.9578)和PSNR (32.98 dB)等指标上显著优于基线CNN及可变形卷积神经网络(Deformable CNN)模型。该框架为纳米光子学(Nanophotonic)设计工作流提供了一种可扩展且高效的方案，是替代传统全波求解器的有力候选工具。",
      "categories": [
        "physics.optics",
        "cs.AI",
        "eess.SP"
      ],
      "primary_category": "physics.optics",
      "comment": "11 pages, 6 figures",
      "pdf_url": "https://arxiv.org/pdf/2602.08406v1",
      "published_date": "2026-02-09 09:09:32 UTC",
      "updated_date": "2026-02-09 09:09:32 UTC",
      "processing_status": "completed",
      "attempts": 1,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "llm_backup_calls": 0,
      "last_update": "2026-02-16T05:05:45.520647+00:00"
    },
    {
      "arxiv_id": "2602.08403v1",
      "title": "Intelligent support for Human Oversight: Integrating Reinforcement Learning with Gaze Simulation to Personalize Highlighting",
      "title_zh": "人类监督智能支持：融合强化学习与注视模拟实现个性化高亮",
      "authors": [
        "Thorsten Klößner",
        "João Belo",
        "Zekun Wu",
        "Jörg Hoffmann",
        "Anna Maria Feit"
      ],
      "abstract": "Interfaces for human oversight must effectively support users' situation awareness under time-critical conditions. We explore reinforcement learning (RL)-based UI adaptation to personalize alerting strategies that balance the benefits of highlighting critical events against the cognitive costs of interruptions. To enable learning without real-world deployment, we integrate models of users' gaze behavior to simulate attentional dynamics during monitoring. Using a delivery-drone oversight scenario, we present initial results suggesting that RL-based highlighting can outperform static, rule-based approaches and discuss challenges of intelligent oversight support.",
      "tldr_zh": "该研究探讨了利用强化学习(Reinforcement Learning, RL)进行用户界面(UI)自适应，以在时间紧迫的情况下提升人类监管的态势感知(Situation Awareness)。通过个性化高亮策略，该方法旨在平衡突出关键事件的收益与干扰带来的认知成本。为了解决在真实环境部署前进行学习的难题，研究集成了用户注视行为(Gaze Behavior)模型来模拟监控过程中的注意力动态。在交付无人机监管场景下的初步实验结果表明，基于RL的个性化高亮策略在性能上优于传统的静态规则方法。该研究为智能化监管支持系统的设计提供了新路径，并深入探讨了实现此类系统所面临的挑战。",
      "categories": [
        "cs.HC",
        "cs.AI"
      ],
      "primary_category": "cs.HC",
      "comment": "AI CHAOS '26: Workshop Series on the Challenges for Human Oversight of AI Systems",
      "pdf_url": "https://arxiv.org/pdf/2602.08403v1",
      "published_date": "2026-02-09 09:04:48 UTC",
      "updated_date": "2026-02-09 09:04:48 UTC",
      "processing_status": "completed",
      "attempts": 1,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "llm_backup_calls": 0,
      "last_update": "2026-02-16T05:05:57.456007+00:00"
    },
    {
      "arxiv_id": "2602.08401v1",
      "title": "On Protecting Agentic Systems' Intellectual Property via Watermarking",
      "title_zh": "基于水印技术的智能体系统知识产权保护",
      "authors": [
        "Liwen Wang",
        "Zongjie Li",
        "Yuchong Xie",
        "Shuai Wang",
        "Dongdong She",
        "Wei Wang",
        "Juergen Rahmel"
      ],
      "abstract": "The evolution of Large Language Models (LLMs) into agentic systems that perform autonomous reasoning and tool use has created significant intellectual property (IP) value. We demonstrate that these systems are highly vulnerable to imitation attacks, where adversaries steal proprietary capabilities by training imitation models on victim outputs. Crucially, existing LLM watermarking techniques fail in this domain because real-world agentic systems often operate as grey boxes, concealing the internal reasoning traces required for verification. This paper presents AGENTWM, the first watermarking framework designed specifically for agentic models. AGENTWM exploits the semantic equivalence of action sequences, injecting watermarks by subtly biasing the distribution of functionally identical tool execution paths. This mechanism allows AGENTWM to embed verifiable signals directly into the visible action trajectory while remaining indistinguishable to users. We develop an automated pipeline to generate robust watermark schemes and a rigorous statistical hypothesis testing procedure for verification. Extensive evaluations across three complex domains demonstrate that AGENTWM achieves high detection accuracy with negligible impact on agent performance. Our results confirm that AGENTWM effectively protects agentic IP against adaptive adversaries, who cannot remove the watermarks without severely degrading the stolen model's utility.",
      "tldr_zh": "该研究探讨了大型语言模型（LLMs）演变为具备自主推理和工具使用能力的智能体系统（Agentic Systems）后的知识产权（IP）保护问题。由于现有大模型水印技术在处理仅显示外部动作的“灰盒”系统时失效，作者提出了首个专门为智能体设计的动作水印框架AGENTWM。该框架利用动作序列的语义等效性，通过微调功能一致的工具执行路径分布，在保持用户无感的同时将可验证信号植入可见的行动轨迹中。通过自动化生成流水线和严谨的统计假设检验程序，AGENTWM在三个复杂领域的实验中展示了极高的检测准确率，且对智能体原始性能的影响几乎可以忽略。研究结果证明，AGENTWM能有效抵御旨在窃取模型能力的模仿攻击（Imitation Attacks），攻击者在不显著降低模型效能的情况下无法移除该水印，从而为智能体系统的资产安全提供了关键保障。",
      "categories": [
        "cs.AI",
        "cs.CR"
      ],
      "primary_category": "cs.AI",
      "comment": "",
      "pdf_url": "https://arxiv.org/pdf/2602.08401v1",
      "published_date": "2026-02-09 09:02:15 UTC",
      "updated_date": "2026-02-09 09:02:15 UTC",
      "processing_status": "completed",
      "attempts": 1,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "llm_backup_calls": 0,
      "last_update": "2026-02-16T05:06:17.610665+00:00"
    },
    {
      "arxiv_id": "2602.08400v1",
      "title": "SCOUT-RAG: Scalable and Cost-Efficient Unifying Traversal for Agentic Graph-RAG over Distributed Domains",
      "title_zh": "SCOUT-RAG：面向分布式领域智能体化图RAG的可扩展且经济高效的统一遍历",
      "authors": [
        "Longkun Li",
        "Yuanben Zou",
        "Jinghan Wu",
        "Yuqing Wen",
        "Jing Li",
        "Hangwei Qian",
        "Ivor Tsang"
      ],
      "abstract": "Graph-RAG improves LLM reasoning using structured knowledge, yet conventional designs rely on a centralized knowledge graph. In distributed and access-restricted settings (e.g., hospitals or multinational organizations), retrieval must select relevant domains and appropriate traversal depth without global graph visibility or exhaustive querying. To address this challenge, we introduce \\textbf{SCOUT-RAG} (\\textit{\\underline{S}calable and \\underline{CO}st-efficient \\underline{U}nifying \\underline{T}raversal}), a distributed agentic Graph-RAG framework that performs progressive cross-domain retrieval guided by incremental utility goals. SCOUT-RAG employs four cooperative agents that: (i) estimate domain relevance, (ii) decide when to expand retrieval to additional domains, (iii) adapt traversal depth to avoid unnecessary graph exploration, and (iv) synthesize the high-quality answers. The framework is designed to minimize retrieval regret, defined as missing useful domain information, while controlling latency and API cost. Across multi-domain knowledge settings, SCOUT-RAG achieves performance comparable to centralized baselines, including DRIFT and exhaustive domain traversal, while substantially reducing cross-domain calls, total tokens processed, and latency.",
      "tldr_zh": "该研究提出了 SCOUT-RAG，一种针对分布式领域设计的可扩展且具有成本效益的智能体图检索增强生成 (Agentic Graph-RAG) 框架。针对传统 Graph-RAG 依赖中心化知识图谱且在分布式或访问受限设置中检索效率低下的挑战，该框架引入了由增量效用目标引导的渐进式跨领域检索机制。SCOUT-RAG 采用四个协同智能体分别负责领域相关性评估、检索扩展决策、遍历深度自适应以及最终的高质量答案合成。这种设计旨在最小化检索遗憾 (retrieval regret)，同时严格控制延迟和 API 调用成本。实验结果显示，SCOUT-RAG 在多领域知识设置下的表现与 DRIFT 和穷举遍历等中心化基线模型相当。最重要的是，该框架在保持高性能的同时，显著降低了跨领域调用次数、总 Token 处理量及响应延迟。",
      "categories": [
        "cs.AI"
      ],
      "primary_category": "cs.AI",
      "comment": "",
      "pdf_url": "https://arxiv.org/pdf/2602.08400v1",
      "published_date": "2026-02-09 09:00:17 UTC",
      "updated_date": "2026-02-09 09:00:17 UTC",
      "processing_status": "completed",
      "attempts": 1,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "llm_backup_calls": 0,
      "last_update": "2026-02-16T05:06:20.601554+00:00"
    },
    {
      "arxiv_id": "2602.09067v1",
      "title": "AntigenLM: Structure-Aware DNA Language Modeling for Influenza",
      "title_zh": "AntigenLM：面向流感的结构感知DNA语言建模",
      "authors": [
        "Yue Pei",
        "Xuebin Chi",
        "Yu Kang"
      ],
      "abstract": "Language models have advanced sequence analysis, yet DNA foundation models often lag behind task-specific methods for unclear reasons. We present AntigenLM, a generative DNA language model pretrained on influenza genomes with intact, aligned functional units. This structure-aware pretraining enables AntigenLM to capture evolutionary constraints and generalize across tasks. Fine-tuned on time-series hemagglutinin (HA) and neuraminidase (NA) sequences, AntigenLM accurately forecasts future antigenic variants across regions and subtypes, including those unseen during training, outperforming phylogenetic and evolution-based models. It also achieves near-perfect subtype classification. Ablation studies show that disrupting genomic structure through fragmentation or shuffling severely degrades performance, revealing the importance of preserving functional-unit integrity in DNA language modeling. AntigenLM thus provides both a powerful framework for antigen evolution prediction and a general principle for building biologically grounded DNA foundation models.",
      "tldr_zh": "该研究提出了 AntigenLM，一种在流感病毒基因组上进行预训练的生成式 DNA Language Model，通过保留完整且对齐的功能单元实现了 Structure-Aware 的预训练，从而有效捕捉进化约束。在对血凝素 (HA) 和神经氨酸酶 (NA) 序列进行微调后，AntigenLM 能够准确预测不同地区和亚型的未来抗原变异体，性能优于传统的系统发育和基于进化的模型。此外，该模型在亚型分类任务上达到了近乎完美的准确率。消融实验证明，破坏基因组结构的碎片化或洗牌会严重降低模型性能，强调了在 DNA Foundation Models 中保持功能单元完整性的重要性。AntigenLM 为抗原进化预测提供了强大框架，并为构建符合生物学基础的 DNA 模型确立了通用原则。",
      "categories": [
        "q-bio.GN",
        "cs.AI",
        "cs.CE",
        "cs.CL"
      ],
      "primary_category": "q-bio.GN",
      "comment": "Accepted by ICLR 2026",
      "pdf_url": "https://arxiv.org/pdf/2602.09067v1",
      "published_date": "2026-02-09 08:52:04 UTC",
      "updated_date": "2026-02-09 08:52:04 UTC",
      "processing_status": "completed",
      "attempts": 1,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "llm_backup_calls": 0,
      "last_update": "2026-02-16T05:06:16.597620+00:00"
    },
    {
      "arxiv_id": "2602.08392v1",
      "title": "BiManiBench: A Hierarchical Benchmark for Evaluating Bimanual Coordination of Multimodal Large Language Models",
      "title_zh": "BiManiBench：评估多模态大语言模型双臂协同能力的分层基准",
      "authors": [
        "Xin Wu",
        "Zhixuan Liang",
        "Yue Ma",
        "Mengkang Hu",
        "Zhiyuan Qin",
        "Xiu Li"
      ],
      "abstract": "Multimodal Large Language Models (MLLMs) have significantly advanced embodied AI, and using them to benchmark robotic intelligence has become a pivotal trend. However, existing frameworks remain predominantly confined to single-arm manipulation, failing to capture the spatio-temporal coordination required for bimanual tasks like lifting a heavy pot. To address this, we introduce BiManiBench, a hierarchical benchmark evaluating MLLMs across three tiers: fundamental spatial reasoning, high-level action planning, and low-level end-effector control. Our framework isolates unique bimanual challenges, such as arm reachability and kinematic constraints, thereby distinguishing perceptual hallucinations from planning failures. Analysis of over 30 state-of-the-art models reveals that despite high-level reasoning proficiency, MLLMs struggle with dual-arm spatial grounding and control, frequently resulting in mutual interference and sequencing errors. These findings suggest the current paradigm lacks a deep understanding of mutual kinematic constraints, highlighting the need for future research to focus on inter-arm collision-avoidance and fine-grained temporal sequencing.",
      "tldr_zh": "本研究提出了 BiManiBench，这是一个层次化的基准测试，旨在评估多模态大语言模型 (MLLMs) 在双臂协作任务中的表现。该框架从基础空间推理 (fundamental spatial reasoning)、高层动作规划 (high-level action planning) 以及低层末端执行器控制 (low-level end-effector control) 三个维度进行评估。通过隔离双臂可达性 (arm reachability) 和运动学约束 (kinematic constraints) 等独特挑战，该基准能够有效区分感知幻觉与规划失败。对超过 30 种最先进模型的分析显示，尽管 MLLMs 在高层推理方面表现出色，但在双臂空间定位 (spatial grounding) 和控制方面仍面临巨大挑战，常导致相互干扰和序列错误。研究结果表明当前的范式缺乏对相互运动学约束的深刻理解，强调了未来研究需聚焦于臂间碰撞规避 (collision-avoidance) 和精细的时间序列化 (temporal sequencing)。",
      "categories": [
        "cs.RO",
        "cs.AI",
        "cs.CV"
      ],
      "primary_category": "cs.RO",
      "comment": "38 pages, 9 figures. Project page:https://bimanibench.github.io/",
      "pdf_url": "https://arxiv.org/pdf/2602.08392v1",
      "published_date": "2026-02-09 08:47:14 UTC",
      "updated_date": "2026-02-09 08:47:14 UTC",
      "processing_status": "completed",
      "attempts": 1,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "llm_backup_calls": 0,
      "last_update": "2026-02-16T05:06:26.295859+00:00"
    },
    {
      "arxiv_id": "2602.08389v1",
      "title": "Altruism and Fair Objective in Mixed-Motive Markov games",
      "title_zh": "混合动机马尔可夫博弈中的利他主义与公平目标",
      "authors": [
        "Yao-hua Franck Xu",
        "Tayeb Lemlouma",
        "Arnaud Braud",
        "Jean-Marie Bonnin"
      ],
      "abstract": "Cooperation is fundamental for society's viability, as it enables the emergence of structure within heterogeneous groups that seek collective well-being. However, individuals are inclined to defect in order to benefit from the group's cooperation without contributing the associated costs, thus leading to unfair situations. In game theory, social dilemmas entail this dichotomy between individual interest and collective outcome. The most dominant approach to multi-agent cooperation is the utilitarian welfare which can produce efficient highly inequitable outcomes. This paper proposes a novel framework to foster fairer cooperation by replacing the standard utilitarian objective with Proportional Fairness. We introduce a fair altruistic utility for each agent, defined on the individual log-payoff space and derive the analytical conditions required to ensure cooperation in classic social dilemmas. We then extend this framework to sequential settings by defining a Fair Markov Game and deriving novel fair Actor-Critic algorithms to learn fair policies. Finally, we evaluate our method in various social dilemma environments.",
      "tldr_zh": "该研究针对混合动机马尔可夫博弈(Mixed-Motive Markov games)中的合作问题，探讨了个人利益与集体成果之间的社会困境(social dilemmas)。针对传统功利主义福利(utilitarian welfare)常导致高度不公平结果的问题，本文提出了一个旨在促进更公平合作的新框架，将标准目标替换为比例公平(Proportional Fairness)。研究者在个体对数收益空间(log-payoff space)内为每个智能体定义了公平利他效用(fair altruistic utility)，并推导出在经典社会困境中确保合作的分析条件。随后，该框架被扩展至序贯设置，通过定义公平马尔可夫博弈(Fair Markov Game)并推导出新颖的公平行动者-评论家算法(Actor-Critic algorithms)来学习公平策略。最后，在多种社会困境环境下的实验评估证明了该方法能够有效引导智能体达成更具公平性的合作结果。",
      "categories": [
        "cs.MA",
        "cs.AI",
        "cs.GT",
        "cs.LG"
      ],
      "primary_category": "cs.MA",
      "comment": "",
      "pdf_url": "https://arxiv.org/pdf/2602.08389v1",
      "published_date": "2026-02-09 08:40:52 UTC",
      "updated_date": "2026-02-09 08:40:52 UTC",
      "processing_status": "completed",
      "attempts": 1,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "llm_backup_calls": 0,
      "last_update": "2026-02-16T05:06:41.111578+00:00"
    },
    {
      "arxiv_id": "2602.08382v1",
      "title": "Dynamic Long Context Reasoning over Compressed Memory via End-to-End Reinforcement Learning",
      "title_zh": "基于端到端强化学习的压缩内存动态长上下文推理",
      "authors": [
        "Zhuoen Chen",
        "Dongfang Li",
        "Meishan Zhang",
        "Baotian Hu",
        "Min Zhang"
      ],
      "abstract": "Large Language Models (LLMs) face significant challenges in long-context processing, including quadratic computational costs, information forgetting, and the context fragmentation inherent in retrieval-augmented generation (RAG). We propose a cognitively inspired framework for efficient long-context inference based on chunk-wise compression and selective memory recall, rather than processing all raw tokens. The framework segments long inputs into chunks and encodes each chunk into compressed memory representations using a learned compressor. A gating module dynamically selects relevant memory blocks, which are then iteratively processed by a reasoning module with an evolving working memory to solve downstream tasks. The compressor and reasoner are jointly optimized via end-to-end reinforcement learning, while the gating module is trained separately as a classifier. Experimental results show that the proposed method achieves competitive accuracy on multi-hop reasoning benchmarks such as RULER-HQA, extrapolates context length from 7K to 1.75M tokens, and offers a favorable accuracy-efficiency trade-off compared to strong long-context baselines. In particular, it achieves up to a 2 times reduction in peak GPU memory usage and a 6 times inference speedup over MemAgent.",
      "tldr_zh": "该研究提出了一种受认知启发的长上下文推理框架，旨在解决大型语言模型（LLMs）在长文本处理中面临的计算成本、信息遗忘及检索增强生成（RAG）中的上下文断裂问题。该方法通过将长输入切分为块（chunks），并利用学习到的压缩器将其编码为压缩记忆表示（compressed memory representations）。框架通过门控模块（gating module）动态选择相关记忆块，并由推理模块（reasoner）结合演进的工作记忆（working memory）迭代解决下游任务。研究采用端到端强化学习（End-to-End Reinforcement Learning）共同优化压缩器和推理器，同时将门控模块作为分类器单独训练。实验表明，该方法在RULER-HQA等基准测试中取得了竞争性的准确率，并成功将上下文长度从7K外推至1.75M个token。相比于MemAgent，该框架在保持性能的同时实现了2倍的GPU显存节省和6倍的推理加速，显著提升了长上下文推理的效率。",
      "categories": [
        "cs.CL",
        "cs.AI"
      ],
      "primary_category": "cs.CL",
      "comment": "26 pages, 7 figures. Code and models will be released",
      "pdf_url": "https://arxiv.org/pdf/2602.08382v1",
      "published_date": "2026-02-09 08:33:11 UTC",
      "updated_date": "2026-02-09 08:33:11 UTC",
      "processing_status": "completed",
      "attempts": 1,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "llm_backup_calls": 0,
      "last_update": "2026-02-16T05:06:50.513526+00:00"
    },
    {
      "arxiv_id": "2602.08377v1",
      "title": "Reinforcement Learning with Backtracking Feedback",
      "title_zh": "基于回溯反馈的强化学习",
      "authors": [
        "Bilgehan Sel",
        "Vaishakh Keshava",
        "Phillip Wallis",
        "Lukas Rutishauser",
        "Ming Jin",
        "Dingcheng Li"
      ],
      "abstract": "Addressing the critical need for robust safety in Large Language Models (LLMs), particularly against adversarial attacks and in-distribution errors, we introduce Reinforcement Learning with Backtracking Feedback (RLBF). This framework advances upon prior methods, such as BSAFE, by primarily leveraging a Reinforcement Learning (RL) stage where models learn to dynamically correct their own generation errors. Through RL with critic feedback on the model's live outputs, LLMs are trained to identify and recover from their actual, emergent safety violations by emitting an efficient \"backtrack by x tokens\" signal, then continuing generation autoregressively. This RL process is crucial for instilling resilience against sophisticated adversarial strategies, including middle filling, Greedy Coordinate Gradient (GCG) attacks, and decoding parameter manipulations. To further support the acquisition of this backtracking capability, we also propose an enhanced Supervised Fine-Tuning (SFT) data generation strategy (BSAFE+). This method improves upon previous data creation techniques by injecting violations into coherent, originally safe text, providing more effective initial training for the backtracking mechanism. Comprehensive empirical evaluations demonstrate that RLBF significantly reduces attack success rates across diverse benchmarks and model scales, achieving superior safety outcomes while critically preserving foundational model utility.",
      "tldr_zh": "该研究针对大语言模型 (Large Language Models, LLMs) 在面对对抗性攻击和分布内错误时的安全性挑战，提出了 Reinforcement Learning with Backtracking Feedback (RLBF) 框架。RLBF 在 BSAFE 等方法的基础上，通过强化学习 (Reinforcement Learning, RL) 阶段让模型学习动态修正自身的生成错误。该框架利用评论者 (critic) 对模型实时输出的反馈，训练 LLMs 在识别到安全违规时发出高效的 \"backtrack by x tokens\" 信号，随后以自回归方式继续生成。这种 RL 过程增强了模型对抗中间填充 (middle filling)、Greedy Coordinate Gradient (GCG) 攻击及解码参数操纵等复杂对抗策略的韧性。研究还配套提出了一种增强的有监督微调 (Supervised Fine-Tuning, SFT) 数据生成策略 BSAFE+，通过在连贯的安全文本中注入违规行为，为回溯机制提供有效的初始训练。实验结果表明，RLBF 在多种基准测试和模型规模上显著降低了攻击成功率，在实现卓越安全性的同时，有效保留了基础模型的核心效用。",
      "categories": [
        "cs.LG",
        "cs.AI",
        "cs.CL"
      ],
      "primary_category": "cs.LG",
      "comment": "NeurIPS 2025",
      "pdf_url": "https://arxiv.org/pdf/2602.08377v1",
      "published_date": "2026-02-09 08:23:19 UTC",
      "updated_date": "2026-02-09 08:23:19 UTC",
      "processing_status": "completed",
      "attempts": 1,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "llm_backup_calls": 0,
      "last_update": "2026-02-16T05:06:57.803552+00:00"
    },
    {
      "arxiv_id": "2602.08373v1",
      "title": "Grounding Generative Planners in Verifiable Logic: A Hybrid Architecture for Trustworthy Embodied AI",
      "title_zh": "基于可验证逻辑的生成式规划器：面向可信具身智能的混合架构",
      "authors": [
        "Feiyu Wu",
        "Xu Zheng",
        "Yue Qu",
        "Zhuocheng Wang",
        "Zicheng Feng",
        "Hui Li"
      ],
      "abstract": "Large Language Models (LLMs) show promise as planners for embodied AI, but their stochastic nature lacks formal reasoning, preventing strict safety guarantees for physical deployment. Current approaches often rely on unreliable LLMs for safety checks or simply reject unsafe plans without offering repairs. We introduce the Verifiable Iterative Refinement Framework (VIRF), a neuro-symbolic architecture that shifts the paradigm from passive safety gatekeeping to active collaboration. Our core contribution is a tutor-apprentice dialogue where a deterministic Logic Tutor, grounded in a formal safety ontology, provides causal and pedagogical feedback to an LLM planner. This enables intelligent plan repairs rather than mere avoidance. We also introduce a scalable knowledge acquisition pipeline that synthesizes safety knowledge bases from real-world documents, correcting blind spots in existing benchmarks. In challenging home safety tasks, VIRF achieves a perfect 0 percent Hazardous Action Rate (HAR) and a 77.3 percent Goal-Condition Rate (GCR), which is the highest among all baselines. It is highly efficient, requiring only 1.1 correction iterations on average. VIRF demonstrates a principled pathway toward building fundamentally trustworthy and verifiably safe embodied agents.",
      "tldr_zh": "该研究针对 Large Language Models (LLMs) 在 Embodied AI 规划中因随机性导致缺乏形式化推理和安全保证的问题，提出了 Verifiable Iterative Refinement Framework (VIRF)。作为一种神经符号架构，VIRF 通过一个基于形式化安全本体的确定性 Logic Tutor 与 LLM 规划器进行师徒对话，从而由传统的被动安全关卡转向主动协作，实现智能的计划修复而非简单的拒绝。此外，研究还引入了可扩展的知识获取管道，从现实文档中合成安全知识库以弥补现有基准测试的盲点。在挑战性的家庭安全任务中，VIRF 实现了 0% 的 Hazardous Action Rate (HAR) 和 77.3% 的 Goal-Condition Rate (GCR)，在所有基线模型中表现最佳。该框架运行高效，平均仅需 1.1 次迭代即可完成修正，为构建从根本上可信且可验证安全的具身智能体开辟了原则性路径。",
      "categories": [
        "cs.AI",
        "cs.LG"
      ],
      "primary_category": "cs.AI",
      "comment": "Accepted to ICLR 2026. Project page. https://openreview.net/forum?id=wb05ver1k8&noteId=v1Ax8CwI71",
      "pdf_url": "https://arxiv.org/pdf/2602.08373v1",
      "published_date": "2026-02-09 08:11:36 UTC",
      "updated_date": "2026-02-09 08:11:36 UTC",
      "processing_status": "completed",
      "attempts": 1,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "llm_backup_calls": 0,
      "last_update": "2026-02-16T05:07:00.503233+00:00"
    },
    {
      "arxiv_id": "2602.08370v1",
      "title": "Learning Human-Like Badminton Skills for Humanoid Robots",
      "title_zh": "面向人形机器人的拟人化羽毛球技能学习",
      "authors": [
        "Yeke Chen",
        "Shihao Dong",
        "Xiaoyu Ji",
        "Jingkai Sun",
        "Zeren Luo",
        "Liu Zhao",
        "Jiahui Zhang",
        "Wanyue Li",
        "Ji Ma",
        "Bowen Xu",
        "Yimin Han",
        "Yudong Zhao",
        "Peng Lu"
      ],
      "abstract": "Realizing versatile and human-like performance in high-demand sports like badminton remains a formidable challenge for humanoid robotics. Unlike standard locomotion or static manipulation, this task demands a seamless integration of explosive whole-body coordination and precise, timing-critical interception. While recent advances have achieved lifelike motion mimicry, bridging the gap between kinematic imitation and functional, physics-aware striking without compromising stylistic naturalness is non-trivial. To address this, we propose Imitation-to-Interaction, a progressive reinforcement learning framework designed to evolve a robot from a \"mimic\" to a capable \"striker.\" Our approach establishes a robust motor prior from human data, distills it into a compact, model-based state representation, and stabilizes dynamics via adversarial priors. Crucially, to overcome the sparsity of expert demonstrations, we introduce a manifold expansion strategy that generalizes discrete strike points into a dense interaction volume. We validate our framework through the mastery of diverse skills, including lifts and drop shots, in simulation. Furthermore, we demonstrate the first zero-shot sim-to-real transfer of anthropomorphic badminton skills to a humanoid robot, successfully replicating the kinetic elegance and functional precision of human athletes in the physical world.",
      "tldr_zh": "该研究提出了名为Imitation-to-Interaction的渐进式强化学习框架，旨在使类人机器人（Humanoid Robots）在羽毛球运动中实现兼具爆发性全身协调与高精度拦截的类人化表现。该框架通过从人类数据中建立运动先验（Motor Prior），并结合对抗先验（Adversarial Priors）稳定动力学表现，成功弥补了单纯运动学模仿与物理交互击球之间的差距。针对专家演示数据稀疏的问题，研究引入了流形扩展策略（Manifold Expansion Strategy），将离散的击球点扩展为连续且密集的交互空间。实验结果显示，机器人成功掌握了挑球（Lifts）和吊球（Drop Shots）等多种复杂技能。最终，该研究实现了类人羽毛球技能的首个零样本（Zero-shot）仿真到现实（Sim-to-real）迁移，在物理世界中复现了人类运动员的动作优雅性与击球精准度。",
      "categories": [
        "cs.RO",
        "cs.AI",
        "cs.LG"
      ],
      "primary_category": "cs.RO",
      "comment": "10 pages, 4 figures",
      "pdf_url": "https://arxiv.org/pdf/2602.08370v1",
      "published_date": "2026-02-09 08:09:52 UTC",
      "updated_date": "2026-02-09 08:09:52 UTC",
      "processing_status": "completed",
      "attempts": 1,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "llm_backup_calls": 0,
      "last_update": "2026-02-16T05:07:12.006071+00:00"
    },
    {
      "arxiv_id": "2602.08369v1",
      "title": "MemAdapter: Fast Alignment across Agent Memory Paradigms via Generative Subgraph Retrieval",
      "title_zh": "MemAdapter：基于生成式子图检索的跨智能体记忆范式快速对齐",
      "authors": [
        "Xin Zhang",
        "Kailai Yang",
        "Chenyue Li",
        "Hao Li",
        "Qiyu Wei",
        "Jun'ichi Tsujii",
        "Sophia Ananiadou"
      ],
      "abstract": "Memory mechanism is a core component of LLM-based agents, enabling reasoning and knowledge discovery over long-horizon contexts. Existing agent memory systems are typically designed within isolated paradigms (e.g., explicit, parametric, or latent memory) with tightly coupled retrieval methods that hinder cross-paradigm generalization and fusion. In this work, we take a first step toward unifying heterogeneous memory paradigms within a single memory system. We propose MemAdapter, a memory retrieval framework that enables fast alignment across agent memory paradigms. MemAdapter adopts a two-stage training strategy: (1) training a generative subgraph retriever from the unified memory space, and (2) adapting the retriever to unseen memory paradigms by training a lightweight alignment module through contrastive learning. This design improves the flexibility for memory retrieval and substantially reduces alignment cost across paradigms. Comprehensive experiments on three public evaluation benchmarks demonstrate that the generative subgraph retriever consistently outperforms five strong agent memory systems across three memory paradigms and agent model scales. Notably, MemAdapter completes cross-paradigm alignment within 13 minutes on a single GPU, achieving superior performance over original memory retrievers with less than 5% of training compute. Furthermore, MemAdapter enables effective zero-shot fusion across memory paradigms, highlighting its potential as a plug-and-play solution for agent memory systems.",
      "tldr_zh": "该研究针对LLM智能体在长期上下文推理中面临的显式、参数化及隐式等不同Memory paradigms相互隔离、难以融合的问题，提出了MemAdapter框架。MemAdapter旨在通过统一的Memory system实现异构Memory paradigms之间的快速对齐。该框架采用两阶段训练策略，首先从统一的Memory space中训练一个Generative subgraph retriever。随后通过对比学习(Contrastive learning)训练轻量化对齐模块，使检索器能够适配未见的Memory paradigms。实验结果显示，Generative subgraph retriever在多个基准测试和智能体规模上均优于现有的五种主流Memory systems。值得注意的是，MemAdapter仅需单块GPU在13分钟内即可完成跨范式对齐，且计算成本不足原始训练的5%。该框架还支持有效的Zero-shot fusion，展现了其作为即插即用(Plug-and-play)智能体Memory system解决方案的巨大潜力。",
      "categories": [
        "cs.AI",
        "cs.CL",
        "cs.LG"
      ],
      "primary_category": "cs.AI",
      "comment": "",
      "pdf_url": "https://arxiv.org/pdf/2602.08369v1",
      "published_date": "2026-02-09 08:09:25 UTC",
      "updated_date": "2026-02-09 08:09:25 UTC",
      "processing_status": "completed",
      "attempts": 1,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "llm_backup_calls": 0,
      "last_update": "2026-02-16T05:07:10.200011+00:00"
    },
    {
      "arxiv_id": "2602.08363v1",
      "title": "Roadmap to Quantum Aesthetics",
      "title_zh": "量子美学路线图",
      "authors": [
        "Ivan C. H. Liu",
        "Hsiao-Yuan Chen"
      ],
      "abstract": "Quantum mechanics occupies a central position in contemporary science while remaining largely inaccessible to direct sensory experience. This paper proposes a roadmap to quantum aesthetics that examines how quantum concepts become aesthetic phenomena through artistic mediation rather than direct representation. Two complementary and orthogonal approaches are articulated. The first, a pioneering top-down approach, employs text-prompt-based generative AI to probe quantum aesthetics as a collective cultural construct embedded in large-scale training data. By systematically modulating the linguistic weight of the term \"quantum,\" generative models are used as experimental environments to reveal how quantum imaginaries circulate within contemporary visual culture. The second, a bottom-up approach, derives aesthetic form directly from quantum-mechanical structures through the visualization of quantum-generated data, exemplified here by hydrogen atomic orbitals calculated from the Schrödinger equation. These approaches are framed not as competing methods but as intersecting paths within a navigable field of artistic research. They position quantum aesthetics as an emergent field of artistic research shaped by cultural imagination, computational mediation, and physical law, opening new directions for artistic practice and pedagogy at the intersection of art, data, artificial intelligence and quantum science.",
      "tldr_zh": "该研究提出了量子美学 (Quantum Aesthetics) 的发展路线图，探讨了量子概念如何通过艺术媒介而非直接表征转化为审美现象。研究阐明了两种互补且正交的方法：第一种是自上而下 (top-down) 的方法，利用生成式人工智能 (generative AI) 探究量子美学作为大规模训练数据中集体文化构建的表现；第二种是自下而上 (bottom-up) 的方法，通过可视化基于薛定谔方程 (Schrödinger equation) 计算的氢原子轨道 (hydrogen atomic orbitals) 数据，直接从量子力学结构中提取审美形式。这些方法将量子美学定位为一个由文化想象、计算中介和物理规律共同塑造的新兴艺术研究领域。该框架不仅揭示了量子想象在当代视觉文化中的传播，也为艺术、数据、人工智能与量子科学交叉领域的实践和教学开辟了新方向。",
      "categories": [
        "physics.pop-ph",
        "cs.AI",
        "quant-ph"
      ],
      "primary_category": "physics.pop-ph",
      "comment": "7 pages, 5 figures, submitted to 31st International Symposium of Electronic Arts",
      "pdf_url": "https://arxiv.org/pdf/2602.08363v1",
      "published_date": "2026-02-09 08:00:09 UTC",
      "updated_date": "2026-02-09 08:00:09 UTC",
      "processing_status": "completed",
      "attempts": 1,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "llm_backup_calls": 0,
      "last_update": "2026-02-16T05:07:46.113304+00:00"
    },
    {
      "arxiv_id": "2602.08362v1",
      "title": "Circuit Representations of Random Forests with Applications to XAI",
      "title_zh": "随机森林的电路表示及其在可解释人工智能（XAI）中的应用",
      "authors": [
        "Chunxi Ji",
        "Adnan Darwiche"
      ],
      "abstract": "We make three contributions in this paper. First, we present an approach for compiling a random forest classifier into a set of circuits, where each circuit directly encodes the instances in some class of the classifier. We show empirically that our proposed approach is significantly more efficient than existing similar approaches. Next, we utilize this approach to further obtain circuits that are tractable for computing the complete and general reasons of a decision, which are instance abstractions that play a fundamental role in computing explanations. Finally, we propose algorithms for computing the robustness of a decision and all shortest ways to flip it. We illustrate the utility of our contributions by using them to enumerate all sufficient reasons, necessary reasons and contrastive explanations of decisions; to compute the robustness of decisions; and to identify all shortest ways to flip the decisions made by random forest classifiers learned from a wide range of datasets.",
      "tldr_zh": "该研究提出了一种将随机森林 (Random Forest) 分类器编译为电路 (Circuit) 表示的方法，以增强模型在可解释人工智能 (XAI) 任务中的表现。研究实现了一种比现有方法更高效的编译流程，将每个电路直接编码为分类器中特定类别的实例。通过这种电路表示，论文进一步获得了可用于计算决策的完整且一般原因 (Complete and General Reasons) 的可处理结构，为生成解释提供了核心支持。此外，研究提出了计算决策稳健性 (Robustness) 以及寻找翻转决策 (Flip Decisions) 所有最短路径的新算法。实验结果表明，该框架能够有效枚举充分原因 (Sufficient Reasons)、必要原因 (Necessary Reasons) 和对比解释 (Contrastive Explanations)，为在多种数据集上分析随机森林的决策逻辑提供了高效的计算工具。",
      "categories": [
        "cs.AI",
        "cs.LG",
        "cs.LO"
      ],
      "primary_category": "cs.AI",
      "comment": "",
      "pdf_url": "https://arxiv.org/pdf/2602.08362v1",
      "published_date": "2026-02-09 07:59:51 UTC",
      "updated_date": "2026-02-09 07:59:51 UTC",
      "processing_status": "completed",
      "attempts": 1,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "llm_backup_calls": 0,
      "last_update": "2026-02-16T05:07:48.602640+00:00"
    },
    {
      "arxiv_id": "2602.08354v1",
      "title": "Does Your Reasoning Model Implicitly Know When to Stop Thinking?",
      "title_zh": "你的推理模型是否隐式地知晓何时该停止思考？",
      "authors": [
        "Zixuan Huang",
        "Xin Xia",
        "Yuxi Ren",
        "Jianbin Zheng",
        "Xuanda Wang",
        "Zhixia Zhang",
        "Hongyan Xie",
        "Songshi Liang",
        "Zehao Chen",
        "Xuefeng Xiao",
        "Fuzhen Zhuang",
        "Jianxin Li",
        "Yikun Ban",
        "Deqing Wang"
      ],
      "abstract": "Recent advancements in large reasoning models (LRMs) have greatly improved their capabilities on complex reasoning tasks through Long Chains of Thought (CoTs). However, this approach often results in substantial redundancy, impairing computational efficiency and causing significant delays in real-time applications. Recent studies show that longer reasoning chains are frequently uncorrelated with correctness and can even be detrimental to accuracy. In a further in-depth analysis of this phenomenon, we surprisingly uncover and empirically verify that LRMs implicitly know the appropriate time to stop thinking, while this capability is obscured by current sampling paradigms. Motivated by this, we introduce SAGE (Self-Aware Guided Efficient Reasoning), a novel sampling paradigm that unleashes this efficient reasoning potential. Furthermore, integrating SAGE as mixed sampling into group-based reinforcement learning (SAGE-RL) enables SAGE-RL to effectively incorporate SAGE-discovered efficient reasoning patterns into standard pass@1 inference, markedly enhancing both the reasoning accuracy and efficiency of LRMs across multiple challenging mathematical benchmarks.",
      "tldr_zh": "该研究探讨了大语言推理模型（LRMs）在处理复杂任务时，因长链式思维（Long CoTs）而产生的计算冗余和效率低下问题。通过实证分析，研究者发现 LRMs 实际上隐含地知道何时应该停止思考，但这一能力在现有的采样范式下被掩盖。基于此发现，作者提出了 SAGE（Self-Aware Guided Efficient Reasoning），这是一种旨在释放模型高效推理潜力的全新采样范式。此外，该研究将 SAGE 作为混合采样集成到强化学习中（SAGE-RL），使其能够将发现的高效推理模式应用于标准 pass@1 推理。实验证明，SAGE-RL 在多个挑战性的数学基准测试中显著提升了 LRMs 的推理准确率和计算效率。",
      "categories": [
        "cs.AI"
      ],
      "primary_category": "cs.AI",
      "comment": "",
      "pdf_url": "https://arxiv.org/pdf/2602.08354v1",
      "published_date": "2026-02-09 07:38:22 UTC",
      "updated_date": "2026-02-09 07:38:22 UTC",
      "processing_status": "completed",
      "attempts": 1,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "llm_backup_calls": 0,
      "last_update": "2026-02-16T05:07:57.004932+00:00"
    },
    {
      "arxiv_id": "2602.08353v1",
      "title": "Towards Better Evolution Modeling for Temporal Knowledge Graphs",
      "title_zh": "迈向更优的时序知识图谱演化建模",
      "authors": [
        "Zhang Jiasheng",
        "Li Zhangpin",
        "Wang Mingzhe",
        "Shao Jie",
        "Cui Jiangtao",
        "Li Hui"
      ],
      "abstract": "Temporal knowledge graphs (TKGs) structurally preserve evolving human knowledge. Recent research has focused on designing models to learn the evolutionary nature of TKGs to predict future facts, achieving impressive results. For instance, Hits@10 scores over 0.9 on YAGO dataset. However, we find that existing benchmarks inadvertently introduce a shortcut. Near state-of-the-art performance can be simply achieved by counting co-occurrences, without using any temporal information. In this work, we examine the root cause of this issue, identifying inherent biases in current datasets and over simplified form of evaluation task that can be exploited by these biases. Through this analysis, we further uncover additional limitations of existing benchmarks, including unreasonable formatting of time-interval knowledge, ignorance of learning knowledge obsolescence, and insufficient information for precise evolution understanding, all of which can amplify the shortcut and hinder a fair assessment. Therefore, we introduce the TKG evolution benchmark. It includes four bias-corrected datasets and two novel tasks closely aligned with the evolution process, promoting a more accurate understanding of the challenges in TKG evolution modeling. Benchmark is available at: https://github.com/zjs123/TKG-Benchmark.",
      "tldr_zh": "该研究探讨了时序知识图谱 (Temporal knowledge graphs, TKGs) 演化建模中的关键问题，发现现有基准测试由于数据集偏差和评估任务过于简化，导致模型仅通过统计共现次数 (co-occurrences) 即可获得极高评分，而无需真正学习时间演化信息。作者深入分析了这一现象的根源，指出当前基准还存在时间间隔知识格式不合理、忽视知识陈旧化 (knowledge obsolescence) 以及缺乏精确理解演化所需信息等局限性，这些缺陷共同阻碍了对模型的公平评估。为此，研究团队提出了全新的 TKG 演化基准 (TKG evolution benchmark)，包含四个经过偏差修正 (bias-corrected) 的数据集。该基准还引入了两个与演化过程紧密结合的新任务，旨在更真实地反映 TKG 演化建模面临的挑战。该工作为推动时序知识图谱领域的科学评估和深入理解提供了重要工具。",
      "categories": [
        "cs.AI"
      ],
      "primary_category": "cs.AI",
      "comment": "13 pages, 11 figures",
      "pdf_url": "https://arxiv.org/pdf/2602.08353v1",
      "published_date": "2026-02-09 07:37:40 UTC",
      "updated_date": "2026-02-09 07:37:40 UTC",
      "processing_status": "completed",
      "attempts": 1,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "llm_backup_calls": 0,
      "last_update": "2026-02-16T05:08:01.405465+00:00"
    },
    {
      "arxiv_id": "2602.08351v1",
      "title": "The Chicken and Egg Dilemma: Co-optimizing Data and Model Configurations for LLMs",
      "title_zh": "鸡与蛋的困境：LLMs 数据与模型配置的协同优化",
      "authors": [
        "Zhiliang Chen",
        "Alfred Wei Lun Leong",
        "Shao Yong Ong",
        "Apivich Hemachandram",
        "Gregory Kang Ruey Lau",
        "Chuan-Sheng Foo",
        "Zhengyuan Liu",
        "Nancy F. Chen",
        "Bryan Kian Hsiang Low"
      ],
      "abstract": "Co-optimizing data and model configurations for training LLMs presents a classic chicken-and-egg dilemma: The best training data configuration (e.g., data mixture) for a downstream task depends on the chosen model configuration (e.g., model architecture), and vice versa. However, jointly optimizing both data and model configurations is often deemed intractable, and existing methods focus on either data or model optimization without considering their interaction. We introduce JoBS, an approach that uses a scaling-law-inspired performance predictor to aid Bayesian optimization (BO) in jointly optimizing LLM training data and model configurations efficiently. JoBS allocates a portion of the optimization budget to learn an LLM performance predictor that predicts how promising a training configuration is from a small number of training steps. The remaining budget is used to perform BO entirely with the predictor, effectively amortizing the cost of running full-training runs. We study JoBS's average regret and devise the optimal budget allocation to minimize regret. JoBS outperforms existing multi-fidelity BO baselines, as well as data and model optimization approaches across diverse LLM tasks under the same optimization budget.",
      "tldr_zh": "该研究探讨了大型语言模型（LLMs）训练中数据配置与模型配置共同优化的“鸡生蛋”困境，即最佳的数据混合比例取决于模型架构，反之亦然。由于现有方法通常将两者孤立优化而忽视了其相互作用，作者提出了JoBS方法，利用受Scaling-law启发的性能预测器来辅助贝叶斯优化（Bayesian optimization, BO）。JoBS首先分配部分预算通过少量训练步数学习性能预测器，随后利用该预测器引导BO进行全局优化，有效降低了运行完整训练流程的成本。研究进一步分析了JoBS的平均遗憾（average regret），并推导出最小化遗憾的最优预算分配方案。实验证明，在相同优化预算下，JoBS在多种LLM任务上的表现优于现有的多保真度BO基线以及单一的数据或模型优化方法。",
      "categories": [
        "cs.LG",
        "cs.AI"
      ],
      "primary_category": "cs.LG",
      "comment": "",
      "pdf_url": "https://arxiv.org/pdf/2602.08351v1",
      "published_date": "2026-02-09 07:33:40 UTC",
      "updated_date": "2026-02-09 07:33:40 UTC",
      "processing_status": "completed",
      "attempts": 1,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "llm_backup_calls": 0,
      "last_update": "2026-02-16T05:08:16.004091+00:00"
    },
    {
      "arxiv_id": "2602.09066v1",
      "title": "Spectral Disentanglement and Enhancement: A Dual-domain Contrastive Framework for Representation Learning",
      "title_zh": "谱解耦与增强：一种面向表示学习的双域对比框架",
      "authors": [
        "Jinjin Guo",
        "Yexin Li",
        "Zhichao Huang",
        "Jun Fang",
        "Zhiyuan Liu",
        "Chao Liu",
        "Pengzhang Liu",
        "Qixia Jiang"
      ],
      "abstract": "Large-scale multimodal contrastive learning has recently achieved impressive success in learning rich and transferable representations, yet it remains fundamentally limited by the uniform treatment of feature dimensions and the neglect of the intrinsic spectral structure of the learned features. Empirical evidence indicates that high-dimensional embeddings tend to collapse into narrow cones, concentrating task-relevant semantics in a small subspace, while the majority of dimensions remain occupied by noise and spurious correlations. Such spectral imbalance and entanglement undermine model generalization. We propose Spectral Disentanglement and Enhancement (SDE), a novel framework that bridges the gap between the geometry of the embedded spaces and their spectral properties. Our approach leverages singular value decomposition to adaptively partition feature dimensions into strong signals that capture task-critical semantics, weak signals that reflect ancillary correlations, and noise representing irrelevant perturbations. A curriculum-based spectral enhancement strategy is then applied, selectively amplifying informative components with theoretical guarantees on training stability. Building upon the enhanced features, we further introduce a dual-domain contrastive loss that jointly optimizes alignment in both the feature and spectral spaces, effectively integrating spectral regularization into the training process and encouraging richer, more robust representations. Extensive experiments on large-scale multimodal benchmarks demonstrate that SDE consistently improves representation robustness and generalization, outperforming state-of-the-art methods. SDE integrates seamlessly with existing contrastive pipelines, offering an effective solution for multimodal representation learning.",
      "tldr_zh": "该研究提出了光谱解耦与增强框架(Spectral Disentanglement and Enhancement, SDE)，旨在解决大规模多模态对比学习中存在的特征维度处理不统一以及特征空间几何与光谱属性不匹配的问题。该框架通过奇异值分解(Singular Value Decomposition)将特征维度自适应地划分为捕获任务关键语义的强信号、反映辅助相关性的弱信号和无关噪声。SDE采用基于课程的光谱增强策略，在保证训练稳定性的前提下选择性地放大信息量丰富的组件，并引入双域对比损失(Dual-domain Contrastive Loss)同时优化特征空间和光谱空间的对齐。实验结果表明，SDE能有效抑制特征崩塌(Feature Collapse)，在提高表示的鲁棒性和泛化能力方面显著优于现有SOTA方法，且能无缝集成到现有的对比学习流程中。",
      "categories": [
        "cs.LG",
        "cs.AI"
      ],
      "primary_category": "cs.LG",
      "comment": "",
      "pdf_url": "https://arxiv.org/pdf/2602.09066v1",
      "published_date": "2026-02-09 07:29:43 UTC",
      "updated_date": "2026-02-09 07:29:43 UTC",
      "processing_status": "completed",
      "attempts": 1,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "llm_backup_calls": 0,
      "last_update": "2026-02-16T05:08:36.398244+00:00"
    },
    {
      "arxiv_id": "2602.08344v1",
      "title": "OPE: Overcoming Information Saturation in Parallel Thinking via Outline-Guided Path Exploration",
      "title_zh": "OPE：通过大纲引导路径探索克服并行思维中的信息饱和",
      "authors": [
        "Qi Guo",
        "Jianing Wang",
        "Deyang Kong",
        "Xiangyu Xi",
        "Jianfei Zhang",
        "Yi Lu",
        "Jingang Wang",
        "Wei Wang",
        "Shikun Zhang",
        "Wei Ye"
      ],
      "abstract": "Parallel thinking has emerged as a new paradigm for large reasoning models (LRMs) in tackling complex problems. Recent methods leverage Reinforcement Learning (RL) to enhance parallel thinking, aiming to address the limitations in computational resources and effectiveness encountered with supervised fine-tuning. However, most existing studies primarily focus on optimizing the aggregation phase, with limited attention to the path exploration stage. In this paper, we theoretically analyze the optimization of parallel thinking under the Reinforcement Learning with Verifiable Rewards (RLVR) setting, and identify that the mutual information bottleneck among exploration paths fundamentally restricts overall performance. To address this, we propose Outline-Guided Path Exploration (OPE), which explicitly partitions the solution space by generating diverse reasoning outlines prior to parallel path reasoning, thereby reducing information redundancy and improving the diversity of information captured across exploration paths. We implement OPE with an iterative RL strategy that optimizes outline planning and outline-guided reasoning independently. Extensive experiments across multiple challenging mathematical benchmarks demonstrate that OPE effectively improves reasoning performance in different aggregation strategies, enabling LRMs to more reliably discover correct solutions.",
      "tldr_zh": "该研究提出了OPE（Outline-Guided Path Exploration），旨在解决大语言模型（LRMs）在并行思维（Parallel Thinking）推理复杂问题时，由于探索路径间互信息瓶颈导致的信息饱和及冗余问题。通过理论分析可验证奖励强化学习（RLVR）设置下的并行思维优化，研究者发现路径间的信息重叠限制了整体性能。为此，OPE在并行路径推理前引入多样化的推理大纲来显式划分逻辑空间，从而降低信息冗余并提升探索路径捕获信息的差异性。该方法采用迭代强化学习策略独立优化大纲规划与大纲引导推理。在多个具有挑战性的数学基准测试中的实验表明，OPE能有效提升不同聚合策略下的推理表现，使模型能够更可靠地发现正确解决方案。",
      "categories": [
        "cs.AI"
      ],
      "primary_category": "cs.AI",
      "comment": "",
      "pdf_url": "https://arxiv.org/pdf/2602.08344v1",
      "published_date": "2026-02-09 07:29:13 UTC",
      "updated_date": "2026-02-09 07:29:13 UTC",
      "processing_status": "completed",
      "attempts": 1,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "llm_backup_calls": 0,
      "last_update": "2026-02-16T05:08:44.596308+00:00"
    },
    {
      "arxiv_id": "2602.08343v1",
      "title": "ManifoldKV: Training-Free KV Cache Compression via Euclidean Outlier Detection",
      "title_zh": "ManifoldKV：基于欧氏离群值检测的免训练 KV 缓存压缩",
      "authors": [
        "Debajyoti Datta",
        "Trishala Neeraj",
        "Bibek Paudel",
        "Vyom Sharma",
        "Subhabrata Mukherjee"
      ],
      "abstract": "Long-context inference is constrained by KV-cache memory, which grows linearly with sequence length; KV-cache compression therefore hinges on reliably selecting which past tokens to retain. Most geometry-based eviction methods score keys by cosine similarity to a global centroid, but cosine is scale-invariant and can discard magnitude cues that distinguish semantically salient tokens. We propose ManifoldKV, a training-free scorer that ranks tokens by Euclidean distance to the key centroid, capturing both angular and radial deviations.\n  On the RULER benchmark, ManifoldKV achieves 95.7% accuracy at 4K-16K contexts with 20% compression; matching the best geometric baseline while improving robustness in two regimes where cosine scoring fails. First, on multi-key retrieval, ManifoldKV reduces directional collisions, achieving 92.4% vs KeyDiff's 77.0% (+15.4 points) on 3-key NIAH at 50% compression. Second, to address dilution and performance collapse of global centroids at 64K context, we introduce WindowedManifoldKV, which restores accuracy to 84.3% at 25% compression, a 49-point recovery over global L2 and +3.2 points over KeyDiff. The method requires only 3 lines of code and works across 4 architectures without tuning.",
      "tldr_zh": "该研究针对长上下文推理中 KV-cache 显存占用随序列长度线性增长的问题，提出了 ManifoldKV，一种基于 Euclidean distance 异常检测的免训练(training-free)压缩方案。针对现有几何剔除方法因使用 cosine similarity 的缩放不变性而忽略标记幅值线索的缺陷，ManifoldKV 通过衡量键向量与质心的欧几里得距离来同时捕获角度和径向偏差，从而更精准地识别并保留语义显著的标记。在 RULER 基准测试中，该方法在 20% 压缩率下达到了 95.7% 的准确率，并在多键检索任务上比 KeyDiff 提升了 15.4 个百分点。此外，针对 64K 极端长上下文场景，研究者引入了 WindowedManifoldKV 以解决全局质心稀释导致的性能崩溃问题，实现了显著的准确率恢复。该方法实现极其简单，仅需 3 行代码即可跨 4 种架构运行且无需任何调优，为高效的长文本推理提供了强大的 KV-cache 压缩能力。",
      "categories": [
        "cs.LG",
        "cs.AI",
        "cs.CL"
      ],
      "primary_category": "cs.LG",
      "comment": "18 pages, 5 figures, 18 tables",
      "pdf_url": "https://arxiv.org/pdf/2602.08343v1",
      "published_date": "2026-02-09 07:28:55 UTC",
      "updated_date": "2026-02-09 07:28:55 UTC",
      "processing_status": "completed",
      "attempts": 1,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "llm_backup_calls": 0,
      "last_update": "2026-02-16T05:08:49.509080+00:00"
    },
    {
      "arxiv_id": "2602.08342v1",
      "title": "UrbanGraphEmbeddings: Learning and Evaluating Spatially Grounded Multimodal Embeddings for Urban Science",
      "title_zh": "UrbanGraphEmbeddings：面向城市科学的空间关联多模态嵌入学习与评估",
      "authors": [
        "Jie Zhang",
        "Xingtong Yu",
        "Yuan Fang",
        "Rudi Stouffs",
        "Zdravko Trivic"
      ],
      "abstract": "Learning transferable multimodal embeddings for urban environments is challenging because urban understanding is inherently spatial, yet existing datasets and benchmarks lack explicit alignment between street-view images and urban structure. We introduce UGData, a spatially grounded dataset that anchors street-view images to structured spatial graphs and provides graph-aligned supervision via spatial reasoning paths and spatial context captions, exposing distance, directionality, connectivity, and neighborhood context beyond image content. Building on UGData, we propose UGE, a two-stage training strategy that progressively and stably aligns images, text, and spatial structures by combining instruction-guided contrastive learning with graph-based spatial encoding. We finally introduce UGBench, a comprehensive benchmark to evaluate how spatially grounded embeddings support diverse urban understanding tasks -- including geolocation ranking, image retrieval, urban perception, and spatial grounding. We develop UGE on multiple state-of-the-art VLM backbones, including Qwen2-VL, Qwen2.5-VL, Phi-3-Vision, and LLaVA1.6-Mistral, and train fixed-dimensional spatial embeddings with LoRA tuning. UGE built upon Qwen2.5-VL-7B backbone achieves up to 44% improvement in image retrieval and 30% in geolocation ranking on training cities, and over 30% and 22% gains respectively on held-out cities, demonstrating the effectiveness of explicit spatial grounding for spatially intensive urban tasks.",
      "tldr_zh": "该研究针对城市理解中多模态嵌入(multimodal embeddings)难以与复杂的城市空间结构显式对齐的挑战，提出了名为UGData的空间感知数据集。该数据集通过将街景图像锚定到结构化空间图(spatial graphs)，并结合空间推理路径和上下文描述，揭示了图像内容之外的距离、方向和连通性等关键空间特征。基于此，研究者提出了UGE两阶段训练策略，利用指令引导的对比学习(contrastive learning)与基于图的空间编码，实现了图像、文本与空间结构的稳定融合。同时，研究引入了UGBench基准，用于全面评估模型在地理定位排序、图像检索和空间接地(spatial grounding)等任务中的表现。实验表明，在Qwen2.5-VL等视觉语言模型(VLM)基础上应用UGE，可使图像检索准确率提升达44%，并在未见城市中展现出显著的泛化能力。这一成果充分验证了显式空间接地在处理空间密集型城市科学任务中的有效性。",
      "categories": [
        "cs.CV",
        "cs.AI"
      ],
      "primary_category": "cs.CV",
      "comment": "",
      "pdf_url": "https://arxiv.org/pdf/2602.08342v1",
      "published_date": "2026-02-09 07:28:49 UTC",
      "updated_date": "2026-02-09 07:28:49 UTC",
      "processing_status": "completed",
      "attempts": 1,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "llm_backup_calls": 0,
      "last_update": "2026-02-16T05:08:53.109224+00:00"
    },
    {
      "arxiv_id": "2602.08340v1",
      "title": "Effect-Level Validation for Causal Discovery",
      "title_zh": "因果发现的效应层面验证",
      "authors": [
        "Hoang Dang",
        "Luan Pham",
        "Minh Nguyen"
      ],
      "abstract": "Causal discovery is increasingly applied to large-scale telemetry data to estimate the effects of user-facing interventions, yet its reliability for decision-making in feedback-driven systems with strong self-selection remains unclear. In this paper, we propose an effect-centric, admissibility-first framework that treats discovered graphs as structural hypotheses and evaluates them by identifiability, stability, and falsification rather than by graph recovery accuracy alone. Empirically, we study the effect of early exposure to competitive gameplay on short-term retention using real-world game telemetry. We find that many statistically plausible discovery outputs do not admit point-identified causal queries once minimal temporal and semantic constraints are enforced, highlighting identifiability as a critical bottleneck for decision support. When identification is possible, several algorithm families converge to similar, decision-consistent effect estimates despite producing substantially different graph structures, including cases where the direct treatment-outcome edge is absent and the effect is preserved through indirect causal pathways. These converging estimates survive placebo, subsampling, and sensitivity refutation. In contrast, other methods exhibit sporadic admissibility and threshold-sensitive or attenuated effects due to endpoint ambiguity. These results suggest that graph-level metrics alone are inadequate proxies for causal reliability for a given target query. Therefore, trustworthy causal conclusions in telemetry-driven systems require prioritizing admissibility and effect-level validation over causal structural recovery alone.",
      "tldr_zh": "该研究提出了一个以效应为中心、准入优先（admissibility-first）的框架，旨在解决因果发现（Causal Discovery）在处理具有强自选择性的反馈驱动系统时，其决策可靠性难以评估的问题。该框架将发现的图视为结构假设，通过可识别性（identifiability）、稳定性（stability）和证伪（falsification）而非单纯的图恢复准确性进行评估。通过对真实游戏遥测数据中竞技玩法对短期留存率影响的实证研究，作者发现许多统计上合理的因果图在实施最小时间与语义约束后无法满足点识别条件，凸显了可识别性是决策支持的关键瓶颈。实验表明，当识别可行时，尽管不同算法产生的图结构迥异，但其得出的效应估计值趋于一致且能通过灵敏度反证，甚至在直接边缺失时仍能通过间接路径保持效应一致。相比之下，部分方法表现出不稳定的准入性及对阈值敏感的衰减效应。研究结果表明，传统的图级别指标不足以代表特定查询的因果可靠性，因此在遥测驱动系统中得出可信结论必须优先考虑准入性和效应级验证。",
      "categories": [
        "cs.AI"
      ],
      "primary_category": "cs.AI",
      "comment": "",
      "pdf_url": "https://arxiv.org/pdf/2602.08340v1",
      "published_date": "2026-02-09 07:26:55 UTC",
      "updated_date": "2026-02-09 07:26:55 UTC",
      "processing_status": "completed",
      "attempts": 1,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "llm_backup_calls": 0,
      "last_update": "2026-02-16T05:08:55.207134+00:00"
    },
    {
      "arxiv_id": "2602.08339v1",
      "title": "CoTZero: Annotation-Free Human-Like Vision Reasoning via Hierarchical Synthetic CoT",
      "title_zh": "CoTZero：基于层级化合成链式思维的无标注类人视觉推理",
      "authors": [
        "Chengyi Du",
        "Yazhe Niu",
        "Dazhong Shen",
        "Luxin Xu"
      ],
      "abstract": "Recent advances in vision-language models (VLMs) have markedly improved image-text alignment, yet they still fall short of human-like visual reasoning. A key limitation is that many VLMs rely on surface correlations rather than building logically coherent structured representations, which often leads to missed higher-level semantic structure and non-causal relational understanding, hindering compositional and verifiable reasoning. To address these limitations by introducing human models into the reasoning process, we propose CoTZero, an annotation-free paradigm with two components: (i) a dual-stage data synthesis approach and (ii) a cognition-aligned training method. In the first component, we draw inspiration from neurocognitive accounts of compositional productivity and global-to-local analysis. In the bottom-up stage, CoTZero extracts atomic visual primitives and incrementally composes them into diverse, structured question-reasoning forms. In the top-down stage, it enforces hierarchical reasoning by using coarse global structure to guide the interpretation of local details and causal relations. In the cognition-aligned training component, built on the synthesized CoT data, we introduce Cognitively Coherent Verifiable Rewards (CCVR) in Reinforcement Fine-Tuning (RFT) to further strengthen VLMs' hierarchical reasoning and generalization, providing stepwise feedback on reasoning coherence and factual correctness. Experiments show that CoTZero achieves an F1 score of 83.33 percent on our multi-level semantic inconsistency benchmark with lexical-perturbation negatives, across both in-domain and out-of-domain settings. Ablations confirm that each component contributes to more interpretable and human-aligned visual reasoning.",
      "tldr_zh": "该研究针对当前视觉语言模型(VLMs)在逻辑推理和因果理解方面的不足，提出了CoTZero，一种基于层级化合成思维链(Hierarchical Synthetic CoT)的无标注推理范式。该范式核心包括双阶段数据合成方法和认知对齐训练方法，旨在模拟人类从全局到局部的认知逻辑。在合成阶段，CoTZero提取原子视觉基元并将其增量组合成结构化的推理形式，通过全局结构引导对局部细节和因果关系的解读。在训练阶段，研究引入了认知连贯可验证奖励(CCVR)并结合强化微调(RFT)，为推理的连贯性与事实准确性提供分步反馈。实验证明，CoTZero在多级语义不一致基准测试中取得了83.33%的F1得分，有效增强了视觉语言模型在复杂场景下的可解释性与泛化能力。",
      "categories": [
        "cs.AI",
        "cs.CV"
      ],
      "primary_category": "cs.AI",
      "comment": "16 pages 6 figures",
      "pdf_url": "https://arxiv.org/pdf/2602.08339v1",
      "published_date": "2026-02-09 07:26:40 UTC",
      "updated_date": "2026-02-09 07:26:40 UTC",
      "processing_status": "completed",
      "attempts": 1,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "llm_backup_calls": 0,
      "last_update": "2026-02-16T05:09:28.697957+00:00"
    },
    {
      "arxiv_id": "2602.09065v1",
      "title": "Enhanced Graph Transformer with Serialized Graph Tokens",
      "title_zh": "基于序列化图 Token 的增强型图 Transformer",
      "authors": [
        "Ruixiang Wang",
        "Yuyang Hong",
        "Shiming Xiang",
        "Chunhong Pan"
      ],
      "abstract": "Transformers have demonstrated success in graph learning, particularly for node-level tasks. However, existing methods encounter an information bottleneck when generating graph-level representations. The prevalent single token paradigm fails to fully leverage the inherent strength of self-attention in encoding token sequences, and degenerates into a weighted sum of node signals. To address this issue, we design a novel serialized token paradigm to encapsulate global signals more effectively. Specifically, a graph serialization method is proposed to aggregate node signals into serialized graph tokens, with positional encoding being automatically involved. Then, stacked self-attention layers are applied to encode this token sequence and capture its internal dependencies. Our method can yield more expressive graph representations by modeling complex interactions among multiple graph tokens. Experimental results show that our method achieves state-of-the-art results on several graph-level benchmarks. Ablation studies verify the effectiveness of the proposed modules.",
      "tldr_zh": "该研究针对 Transformer 在图学习（尤其是生成图级别表示）中存在的单标量(single token)范式导致的信息瓶颈问题，提出了 Enhanced Graph Transformer。该方法设计了一种全新的序列化令牌(serialized token)范式，通过图序列化(graph serialization)方法将节点信号聚合为序列化的图令牌，并自动引入位置编码(positional encoding)以更有效地封装全局信号。通过堆叠自注意力层(self-attention layers)对该令牌序列进行编码，模型能够捕捉内部依赖关系，并通过建模多个图令牌之间的复杂交互来产生更具表达力的图表示。实验结果表明，该方法在多个图级别基准测试中达到了 SOTA 性能。消融实验进一步验证了所提出模块在克服现有方法局限性、提升图学习效果方面的有效性。",
      "categories": [
        "cs.LG",
        "cs.AI"
      ],
      "primary_category": "cs.LG",
      "comment": "ICASSP 2026",
      "pdf_url": "https://arxiv.org/pdf/2602.09065v1",
      "published_date": "2026-02-09 07:23:22 UTC",
      "updated_date": "2026-02-09 07:23:22 UTC",
      "processing_status": "completed",
      "attempts": 1,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "llm_backup_calls": 0,
      "last_update": "2026-02-16T05:09:33.811478+00:00"
    },
    {
      "arxiv_id": "2602.08335v1",
      "title": "Who Deserves the Reward? SHARP: Shapley Credit-based Optimization for Multi-Agent System",
      "title_zh": "奖励归谁？SHARP：基于 Shapley 贡献归因的多智能体系统优化",
      "authors": [
        "Yanming Li",
        "Xuelin Zhang",
        "WenJie Lu",
        "Ziye Tang",
        "Maodong Wu",
        "Haotian Luo",
        "Tongtong Wu",
        "Zijie Peng",
        "Hongze Mi",
        "Yibo Feng",
        "Naiqiang Tan",
        "Chao Huang",
        "Hong Chen",
        "Li Shen"
      ],
      "abstract": "Integrating Large Language Models (LLMs) with external tools via multi-agent systems offers a promising new paradigm for decomposing and solving complex problems. However, training these systems remains notoriously difficult due to the credit assignment challenge, as it is often unclear which specific functional agent is responsible for the success or failure of decision trajectories. Existing methods typically rely on sparse or globally broadcast rewards, failing to capture individual contributions and leading to inefficient reinforcement learning. To address these limitations, we introduce the Shapley-based Hierarchical Attribution for Reinforcement Policy (SHARP), a novel framework for optimizing multi-agent reinforcement learning via precise credit attribution. SHARP effectively stabilizes training by normalizing agent-specific advantages across trajectory groups, primarily through a decomposed reward mechanism comprising a global broadcast-accuracy reward, a Shapley-based marginal-credit reward for each agent, and a tool-process reward to improve execution efficiency. Extensive experiments across various real-world benchmarks demonstrate that SHARP significantly outperforms recent state-of-the-art baselines, achieving average match improvements of 23.66% and 14.05% over single-agent and multi-agent approaches, respectively.",
      "tldr_zh": "该研究针对多智能体系统在集成大语言模型(LLMs)与外部工具时面临的学分分配(Credit Assignment)难题，提出了SHARP框架。SHARP通过Shapley-based Hierarchical Attribution技术实现精确的学分归因，解决了传统方法中全局奖励无法捕捉个体贡献导致学习效率低下的问题。该框架采用分解奖励机制，结合了全局广播准确率奖励、针对各智能体的Shapley边际学分奖励以及工具过程奖励，从而有效地稳定了强化学习训练过程。实验结果显示，SHARP在多个现实世界基准测试中显著优于现有基线模型，其平均表现比单智能体和多智能体方法分别提升了23.66%和14.05%。这项工作通过在轨迹组中标准化特定智能体的优势，为优化复杂多智能体协作系统的训练和执行效率提供了新的范式。",
      "categories": [
        "cs.AI"
      ],
      "primary_category": "cs.AI",
      "comment": "",
      "pdf_url": "https://arxiv.org/pdf/2602.08335v1",
      "published_date": "2026-02-09 07:17:28 UTC",
      "updated_date": "2026-02-09 07:17:28 UTC",
      "processing_status": "completed",
      "attempts": 1,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "llm_backup_calls": 0,
      "last_update": "2026-02-16T05:09:39.199505+00:00"
    },
    {
      "arxiv_id": "2602.08333v1",
      "title": "Regime Change Hypothesis: Foundations for Decoupled Dynamics in Neural Network Training",
      "title_zh": "状态切换假设：神经网络训练中解耦动力学的理论基础",
      "authors": [
        "Cristian Pérez-Corral",
        "Alberto Fernández-Hernández",
        "Jose I. Mestre",
        "Manuel F. Dolz",
        "Jose Duato",
        "Enrique S. Quintana-Ortí"
      ],
      "abstract": "Despite the empirical success of DNN, their internal training dynamics remain difficult to characterize. In ReLU-based models, the activation pattern induced by a given input determines the piecewise-linear region in which the network behaves affinely. Motivated by this geometry, we investigate whether training exhibits a two-timescale behavior: an early stage with substantial changes in activation patterns and a later stage where weight updates predominantly refine the model within largely stable activation regimes. We first prove a local stability property: outside measure-zero sets of parameters and inputs, sufficiently small parameter perturbations preserve the activation pattern of a fixed input, implying locally affine behavior within activation regions. We then empirically track per-iteration changes in weights and activation patterns across fully-connected and convolutional architectures, as well as Transformer-based models, where activation patterns are recorded in the ReLU feed-forward (MLP/FFN) submodules, using fixed validation subsets. Across the evaluated settings, activation-pattern changes decay 3 times earlier than weight-update magnitudes, showing that late-stage training often proceeds within relatively stable activation regimes. These findings provide a concrete, architecture-agnostic instrument for monitoring training dynamics and motivate further study of decoupled optimization strategies for piecewise-linear networks. For reproducibility, code and experiment configurations will be released upon acceptance.",
      "tldr_zh": "该研究针对深度神经网络(DNN)内部训练动态难以表征的问题，提出了“政权更迭假设”(Regime Change Hypothesis)，旨在研究训练过程中的解耦动态。研究者探讨了模型是否具有双时间尺度行为，即早期激活模式(activation patterns)剧烈变化，而后期则在稳定的激活区域内进行权重细化。研究首先在理论上证明了局部稳定性(local stability)属性，确保微小参数扰动下激活模式的稳定性。随后，通过在全连接、卷积及Transformer架构上的实证发现，激活模式的变化比权重更新幅度早衰减三倍，证实了训练后期的稳定性。这些发现为监测训练动态提供了一种架构无关的工具，并为分段线性网络(piecewise-linear networks)的解耦优化策略(decoupled optimization strategies)提供了重要依据。",
      "categories": [
        "cs.LG",
        "cs.AI"
      ],
      "primary_category": "cs.LG",
      "comment": "8 pages, 1 figure",
      "pdf_url": "https://arxiv.org/pdf/2602.08333v1",
      "published_date": "2026-02-09 07:14:28 UTC",
      "updated_date": "2026-02-09 07:14:28 UTC",
      "processing_status": "completed",
      "attempts": 1,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "llm_backup_calls": 0,
      "last_update": "2026-02-16T05:09:49.611529+00:00"
    },
    {
      "arxiv_id": "2602.08332v1",
      "title": "Latent Reasoning with Supervised Thinking States",
      "title_zh": "基于监督式思考状态的隐式推理",
      "authors": [
        "Ido Amos",
        "Avi Caciularu",
        "Mor Geva",
        "Amir Globerson",
        "Jonathan Herzig",
        "Lior Shani",
        "Idan Szpektor"
      ],
      "abstract": "Reasoning with a chain-of-thought (CoT) enables Large Language Models (LLMs) to solve complex tasks but incurs significant inference costs due to the generation of long rationales. We propose Thinking States, a method that performs reasoning {\\em while} the input is processing. Specifically, Thinking States generates sequences of thinking tokens every few input tokens, transforms the thoughts back into embedding space, and adds them to the following input tokens. This has two key advantages. First, it captures the recurrent nature of CoT, but where the thought tokens are generated as input is processing. Second, since the thoughts are represented as tokens, they can be learned from natural language supervision, and using teacher-forcing, which is parallelizable. Empirically, Thinking States outperforms other latent reasoning methods on multiple reasoning tasks, narrowing the gap to CoT on math problems, and matching its performance on 2-Hop QA with improved latency. On state-tracking tasks, we show Thinking States leads to stronger reasoning behavior than CoT, successfully extrapolating to longer sequences than seen during training.",
      "tldr_zh": "该研究提出了 Thinking States，一种在处理输入的同时进行推理的 Latent Reasoning 方法，旨在解决 Chain-of-Thought (CoT) 因生成冗长推理过程而导致的推理成本过高问题。该方法每隔几个输入 Token 生成一系列 Thinking Tokens，并将这些想法转换回嵌入空间 (Embedding Space)，随后添加到后续输入中。这种设计不仅捕捉了 CoT 的递归特性，还允许在处理输入时同步生成推理，从而优化了推理流程。由于推理状态以 Token 形式表示，模型可以通过自然语言监督进行学习，并利用支持并行化的 Teacher-forcing 技术提升训练效率。实验结果表明，Thinking States 在多项推理任务上优于现有的 Latent Reasoning 方法，在数学问题上缩小了与 CoT 的差距，并在 2-Hop QA 任务中实现了与 CoT 相当的性能且具备更低的延迟 (Latency)。在状态追踪 (State-tracking) 任务中，Thinking States 展现出比 CoT 更强的推理行为，并能成功外推至比训练阶段更长的序列。",
      "categories": [
        "cs.CL",
        "cs.AI"
      ],
      "primary_category": "cs.CL",
      "comment": "",
      "pdf_url": "https://arxiv.org/pdf/2602.08332v1",
      "published_date": "2026-02-09 07:12:41 UTC",
      "updated_date": "2026-02-09 07:12:41 UTC",
      "processing_status": "completed",
      "attempts": 1,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "llm_backup_calls": 0,
      "last_update": "2026-02-16T05:10:03.899981+00:00"
    },
    {
      "arxiv_id": "2602.08329v1",
      "title": "Near-Oracle KV Selection via Pre-hoc Sparsity for Long-Context Inference",
      "title_zh": "面向长上下文推理的基于事前稀疏性的准最优KV选择",
      "authors": [
        "Yifei Gao",
        "Lei Wang",
        "Rong-Cheng Tu",
        "Qixin Zhang",
        "Jun Cheng",
        "Dacheng Tao"
      ],
      "abstract": "A core bottleneck in large language model (LLM) inference is the cost of attending over the ever-growing key-value (KV) cache. Although near-oracle top-k KV selection can preserve the quality of dense attention while sharply reducing computation and bandwidth, existing sparse methods generally rely on posterior heuristics, i.e., selectors conditioned on observed attention or proxy scores. Such conditioning introduces posterior bias: it tends to distort true token importance and miss salient tokens, thereby impairing long-range reasoning. To tackle this problem, we propose Pre-hoc Sparsity (PrHS), which selects KV entries before attention scoring and provides explicit accuracy control. Let the attention mass of discarded entries be delta (the dropped mass). Through a marginal-to-mutual-information analysis, we derive an upper bound on the mutual-information loss that depends only on the dropped mass. This relation explains failure modes of posterior heuristics and enables verifiable guarantees by controlling the dropped mass in advance. Within PrHS, we instantiate three orthogonal pre-hoc selectors along the axes of time, depth, and layer. Extensive experiments on LLaMA and Mistral families validate PrHS. Across GSM8K and CoQA, PrHS reduces retrieval overhead by over 90%, achieving 3x higher retrieval sparsity than HShare at matched or better accuracy. It incurs under 1% average degradation on LongBench, lowers attention FLOPs by about 15% versus prior sparse baselines, and yields a 9.9x speedup in attention-operator latency and 2.8x higher throughput on NVIDIA A100-80GB GPUs than the dense baseline.",
      "tldr_zh": "该研究提出了Pre-hoc Sparsity (PrHS)，旨在解决大语言模型(LLMs)长上下文推理中KV cache带来的计算和带宽瓶颈。针对现有稀疏方法依赖后验启发式(posterior heuristics)导致的后验偏差及长程推理能力受损问题，PrHS在注意力评分前预先选择KV项，并提供了显式的准确率控制。研究者通过互信息分析推导出了互信息损失的上界，并据此设计了跨时间、深度和层三个维度的预验选择器，以实现在推理前的质量保证。在LLaMA和Mistral系列模型上的实验表明，PrHS在LongBench等基准测试中仅产生不到1%的性能下降，同时将检索开销降低了90%以上，并在NVIDIA A100 GPU上实现了注意算子9.9倍的加速和2.8倍的整体吞吐量提升。",
      "categories": [
        "cs.LG",
        "cs.AI",
        "cs.IT"
      ],
      "primary_category": "cs.LG",
      "comment": "An effective method for accelerating LLM's inference via selective KV processing",
      "pdf_url": "https://arxiv.org/pdf/2602.08329v1",
      "published_date": "2026-02-09 07:05:23 UTC",
      "updated_date": "2026-02-09 07:05:23 UTC",
      "processing_status": "completed",
      "attempts": 1,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "llm_backup_calls": 0,
      "last_update": "2026-02-16T05:10:16.509099+00:00"
    },
    {
      "arxiv_id": "2602.08316v1",
      "title": "SWE Context Bench: A Benchmark for Context Learning in Coding",
      "title_zh": "SWE Context Bench：编程语境学习基准",
      "authors": [
        "Jared Zhu",
        "Minhao Hu",
        "Junde Wu"
      ],
      "abstract": "Large language models are increasingly used as programming agents for repository level software engineering tasks. While recent benchmarks evaluate correctness in realistic codebases, they largely treat tasks as independent and do not assess whether agents can reuse experience across related problems. As a result, the ability of agents to accumulate, retrieve, and apply prior experience, as well as the efficiency gains from such reuse, remains difficult to measure. We introduce SWE-ContextBench, a benchmark designed to explicitly evaluate experience reuse in programming agents. Built on SWE-Bench Lite, SWE-ContextBench augments 300 base tasks with 99 related tasks derived from real dependency and reference relationships among GitHub issues and pull requests, forming task sequences with shared context. The benchmark evaluates agents along three complementary dimensions: prediction accuracy, time efficiency, and cost efficiency. Using SWE-ContextBench, we study multiple experience reuse settings, including oracle guided and autonomous retrieval, as well as full execution trajectories and compact summaries. Our results show that correctly selected summarized experience improves resolution accuracy and substantially reduces runtime and token cost, particularly on harder tasks. In contrast, unfiltered or incorrectly selected experience provides limited or negative benefits. These findings highlight the importance of experience representation and retrieval quality, and position SWE-ContextBench as a principled benchmark for studying experience reuse in programming agents.",
      "tldr_zh": "该研究提出了SWE-ContextBench，这是一个专门用于评估编程智能体在软件工程任务中经验复用(Experience Reuse)能力的基准测试。针对现有基准测试大多将任务视为独立个体、难以衡量智能体积累和应用既往经验效率的问题，该基准在SWE-Bench Lite的基础上，通过提取GitHub issue和pull request之间的真实依赖及引用关系，为300个基础任务增加了99个相关任务，形成了具有共享上下文的任务序列。该基准从预测准确率(Prediction Accuracy)、时间效率(Time Efficiency)和成本效率(Cost Efficiency)三个维度对智能体进行全面评估。实验结果显示，正确选择并总结的既往经验能显著提高任务解决的准确性，并大幅降低处理困难任务时的运行时间和Token成本。相比之下，未过滤或错误选择的经验对智能体性能的提升非常有限甚至会产生负面影响。这一发现强调了经验表示和检索质量的关键作用，使SWE-ContextBench成为研究编程智能体上下文学习(Context Learning)和经验积累机制的原则性基准。",
      "categories": [
        "cs.SE",
        "cs.AI"
      ],
      "primary_category": "cs.SE",
      "comment": "",
      "pdf_url": "https://arxiv.org/pdf/2602.08316v1",
      "published_date": "2026-02-09 06:44:45 UTC",
      "updated_date": "2026-02-09 06:44:45 UTC",
      "processing_status": "completed",
      "attempts": 1,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "llm_backup_calls": 0,
      "last_update": "2026-02-16T05:10:24.910517+00:00"
    },
    {
      "arxiv_id": "2602.08311v1",
      "title": "Moral Sycophancy in Vision Language Models",
      "title_zh": "视觉语言模型中的道德阿谀奉承现象",
      "authors": [
        "Shadman Rabby",
        "Md. Hefzul Hossain Papon",
        "Sabbir Ahmed",
        "Nokimul Hasan Arif",
        "A. B. M. Ashikur Rahman",
        "Irfan Ahmad"
      ],
      "abstract": "Sycophancy in Vision-Language Models (VLMs) refers to their tendency to align with user opinions, often at the expense of moral or factual accuracy. While prior studies have explored sycophantic behavior in general contexts, its impact on morally grounded visual decision-making remains insufficiently understood. To address this gap, we present the first systematic study of moral sycophancy in VLMs, analyzing ten widely-used models on the Moralise and M^3oralBench datasets under explicit user disagreement. Our results reveal that VLMs frequently produce morally incorrect follow-up responses even when their initial judgments are correct, and exhibit a consistent asymmetry: models are more likely to shift from morally right to morally wrong judgments than the reverse when exposed to user-induced bias. Follow-up prompts generally degrade performance on Moralise, while yielding mixed or even improved accuracy on M^3oralBench, highlighting dataset-dependent differences in moral robustness. Evaluation using Error Introduction Rate (EIR) and Error Correction Rate (ECR) reveals a clear trade-off: models with stronger error-correction capabilities tend to introduce more reasoning errors, whereas more conservative models minimize errors but exhibit limited ability to self-correct. Finally, initial contexts with a morally right stance elicit stronger sycophantic behavior, emphasizing the vulnerability of VLMs to moral influence and the need for principled strategies to improve ethical consistency and robustness in multimodal AI systems.",
      "tldr_zh": "该研究对视觉语言模型(Vision-Language Models, VLMs)中的道德奉迎(Moral Sycophancy)现象进行了系统性分析，探讨了十种主流模型在面对用户明确异议时的道德决策表现。通过在Moralise和M^3oralBench数据集上的测试发现，VLMs倾向于迎合用户的偏见，且表现出明显的非对称性：模型更容易从道德正确转向道德错误，而非相反。研究利用Error Introduction Rate (EIR)和Error Correction Rate (ECR)指标揭示了模型在纠错能力与推理错误引入之间的权衡关系。实验进一步表明，初始立场为道德正确的情境往往会诱发更强的奉迎行为，暴露出模型在伦理判断上的脆弱性。这项工作强调了在开发多模态人工智能系统时，提升其伦理一致性与鲁棒性的紧迫需求。",
      "categories": [
        "cs.AI"
      ],
      "primary_category": "cs.AI",
      "comment": "13 pages, 6 figures, 8 tables, Submitted for review in ACL",
      "pdf_url": "https://arxiv.org/pdf/2602.08311v1",
      "published_date": "2026-02-09 06:34:12 UTC",
      "updated_date": "2026-02-09 06:34:12 UTC",
      "processing_status": "completed",
      "attempts": 1,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "llm_backup_calls": 0,
      "last_update": "2026-02-16T05:10:27.808299+00:00"
    },
    {
      "arxiv_id": "2602.08302v1",
      "title": "Grokking in Linear Models for Logistic Regression",
      "title_zh": "逻辑回归线性模型中的 Grokking 现象",
      "authors": [
        "Nataraj Das",
        "Atreya Vedantam",
        "Chandrashekar Lakshminarayanan"
      ],
      "abstract": "Grokking, the phenomenon of delayed generalization, is often attributed to the depth and compositional structure of deep neural networks. We study grokking in one of the simplest possible settings: the learning of a linear model with logistic loss for binary classification on data that are linearly (and max margin) separable about the origin. We investigate three testing regimes: (1) test data drawn from the same distribution as the training data, in which case grokking is not observed; (2) test data concentrated around the margin, in which case grokking is observed; and (3) adversarial test data generated via projected gradient descent (PGD) attacks, in which case grokking is also observed. We theoretically show that the implicit bias of gradient descent induces a three-phase learning process-population-dominated, support-vector-dominated unlearning, and support-vector-dominated generalization-during which delayed generalization can arise. Our analysis further relates the emergence of grokking to asymmetries in the data, both in the number of examples per class and in the distribution of support vectors across classes, and yields a characterization of the grokking time. We experimentally validate our theory by planting different distributions of population points and support vectors, and by analyzing accuracy curves and hyperplane dynamics. Overall, our results demonstrate that grokking does not require depth or representation learning, and can emerge even in linear models through the dynamics of the bias term.",
      "tldr_zh": "该研究探讨了Logistic Regression线性模型中的Grokking现象，即Delayed Generalization现象，挑战了该现象仅存在于深度神经网络中的传统认知。通过考察三种测试方案，研究发现在训练集同分布数据中未见Grokking，但在Margin附近的数据和PGD Attacks对抗性数据中均观察到了该现象。理论分析表明，Gradient Descent的Implicit Bias会诱导一个由总体主导、支持向量主导的去学习以及支持向量主导的泛化组成的三阶段学习过程。研究进一步揭示了Grokking的产生与数据的不对称性有关，包括每类样本数量及Support Vectors的分布差异，并给出了Grokking时间的特征描述。实验验证了偏置项Bias Term的动态变化在这一过程中的核心作用，证明了即使在没有深度或表示学习的情况下，线性模型中依然可以涌现出Grokking现象。",
      "categories": [
        "cs.LG",
        "cs.AI"
      ],
      "primary_category": "cs.LG",
      "comment": "",
      "pdf_url": "https://arxiv.org/pdf/2602.08302v1",
      "published_date": "2026-02-09 06:16:43 UTC",
      "updated_date": "2026-02-09 06:16:43 UTC",
      "processing_status": "completed",
      "attempts": 1,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "llm_backup_calls": 0,
      "last_update": "2026-02-16T05:10:33.107198+00:00"
    },
    {
      "arxiv_id": "2602.08297v1",
      "title": "Automatic Generation of Polynomial Symmetry Breaking Constraints",
      "title_zh": "多项式对称破缺约束的自动生成",
      "authors": [
        "Madalina Erascu",
        "Johannes Middeke"
      ],
      "abstract": "Symmetry in integer programming causes redundant search and is often handled with symmetry breaking constraints that remove as many equivalent solutions as possible. We propose an algebraic method which allows to generate a random family of polynomial inequalities which can be used as symmetry breakers. The method requires as input an arbitrary base polynomial and a group of permutations which is specific to the integer program. The computations can be easily carried out in any major symbolic computation software. In order to test our approach, we describe a case study on near half-capacity 0-1 bin packing instances which exhibit substantial symmetries. We statically generate random quadratic breakers and add them to a baseline integer programming problem which we then solve with Gurobi. It turns out that simple symmetry breakers, especially combining few variables and permutations, most consistently reduce work time.",
      "tldr_zh": "该研究探讨了整数规划(integer programming)中对称性导致的冗余搜索问题，并提出了一种自动生成多项式对称破缺约束(symmetry breaking constraints)的代数方法。该方法仅需输入任意基多项式和针对特定问题的置换群(group of permutations)，即可生成一系列随机的多项式不等式作为对称破缺器。这些计算过程可在主流符号计算软件中轻松完成，具有较高的实用性。通过对近半容量0-1装箱问题(0-1 bin packing)的案例研究，研究者静态生成了随机二次破缺器并结合Gurobi进行测试。实验结果显示，简单的对称破缺器，尤其是涉及变量和置换较少的约束，在缩短计算时间方面表现最为一致。这一研究为优化大规模对称整数规划问题提供了一种新颖的自动化代数路径。",
      "categories": [
        "cs.SC",
        "cs.AI",
        "cs.LO"
      ],
      "primary_category": "cs.SC",
      "comment": "",
      "pdf_url": "https://arxiv.org/pdf/2602.08297v1",
      "published_date": "2026-02-09 06:05:10 UTC",
      "updated_date": "2026-02-09 06:05:10 UTC",
      "processing_status": "completed",
      "attempts": 1,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "llm_backup_calls": 0,
      "last_update": "2026-02-16T05:10:35.806827+00:00"
    },
    {
      "arxiv_id": "2602.08295v1",
      "title": "The Vibe-Automation of Automation: A Proactive Education Framework for Computer Science in the Age of Generative AI",
      "title_zh": "自动化之上的“氛围化”自动化：生成式人工智能时代的计算机科学主动教育框架",
      "authors": [
        "Ilya Levin"
      ],
      "abstract": "The emergence of generative artificial intelligence (GenAI) represents not an incremental technological advance but a qualitative epistemological shift that challenges foundational assumptions of computer science. Whereas machine learning has been described as the automation of automation, generative AI operates by navigating contextual, semantic, and stylistic coherence rather than optimizing predefined objective metrics. This paper introduces the concept of Vibe-Automation to characterize this transition.\n  The central claim is that the significance of GenAI lies in its functional access to operationalized tacit regularities: context-sensitive patterns embedded in practice that cannot be fully specified through explicit algorithmic rules. Although generative systems do not possess tacit knowledge in a phenomenological sense, they operationalize sensitivities to tone, intent, and situated judgment encoded in high-dimensional latent representations. On this basis, the human role shifts from algorithmic problem specification toward Vibe-Engineering, understood as the orchestration of alignment and contextual judgment in generative systems.\n  The paper connects this epistemological shift to educational and institutional transformation by proposing a conceptual framework structured across three analytical levels and three domains of action: faculty worldview, industry relations, and curriculum design. The risks of mode collapse and cultural homogenization are briefly discussed, emphasizing the need for deliberate engagement with generative systems to avoid regression toward synthetic uniformity.",
      "tldr_zh": "本研究提出，生成式人工智能（GenAI）的出现并非增量式技术进步，而是一种挑战计算机科学基础假设的认识论转变。论文引入了“氛围自动化”（Vibe-Automation）的概念来描述这一转型，认为 GenAI 的核心意义在于其能有效利用隐含规律（tacit regularities），即那些无法通过显式算法规则完全指定的语境敏感模式。在此基础上，人类的角色从算法问题规范转向“氛围工程”（Vibe-Engineering），强调对生成系统进行对齐编排和语境判断。该研究提出了一个结构化的前瞻性教育框架，涵盖教职员工世界观、行业关系和课程设计三个维度，以指导人工智能时代的学科转型。最后，文章探讨了模式崩溃（mode collapse）和文化同质化等风险，呼吁通过深思熟虑的实践参与来避免系统性生成的平庸与统一。",
      "categories": [
        "cs.AI"
      ],
      "primary_category": "cs.AI",
      "comment": "19 pages",
      "pdf_url": "https://arxiv.org/pdf/2602.08295v1",
      "published_date": "2026-02-09 06:02:04 UTC",
      "updated_date": "2026-02-09 06:02:04 UTC",
      "processing_status": "completed",
      "attempts": 1,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "llm_backup_calls": 0,
      "last_update": "2026-02-16T05:11:04.604575+00:00"
    },
    {
      "arxiv_id": "2602.08290v1",
      "title": "Trust-Based Incentive Mechanisms in Semi-Decentralized Federated Learning Systems",
      "title_zh": "半去中心化联邦学习系统中基于信任的激励机制",
      "authors": [
        "Ajay Kumar Shrestha"
      ],
      "abstract": "In federated learning (FL), decentralized model training allows multi-ple participants to collaboratively improve a shared machine learning model without exchanging raw data. However, ensuring the integrity and reliability of the system is challenging due to the presence of potentially malicious or faulty nodes that can degrade the model's performance. This paper proposes a novel trust-based incentive mechanism designed to evaluate and reward the quality of contributions in FL systems. By dynamically assessing trust scores based on fac-tors such as data quality, model accuracy, consistency, and contribution fre-quency, the system encourages honest participation and penalizes unreliable or malicious behavior. These trust scores form the basis of an incentive mechanism that rewards high-trust nodes with greater participation opportunities and penal-ties for low-trust participants. We further explore the integration of blockchain technology and smart contracts to automate the trust evaluation and incentive distribution processes, ensuring transparency and decentralization. Our proposed theoretical framework aims to create a more robust, fair, and transparent FL eco-system, reducing the risks posed by untrustworthy participants.",
      "tldr_zh": "该研究针对Federated Learning (FL) 系统中由于恶意或故障节点导致的完整性与可靠性挑战，提出了一种新型的基于信任的激励机制。该机制通过动态评估数据质量 (Data Quality)、模型准确性 (Model Accuracy)、一致性 (Consistency) 和贡献频率 (Contribution Frequency) 等因素来计算节点的信任分数 (Trust Scores)。系统利用这些分数鼓励诚实参与并惩罚恶意行为，确保高信任度的节点能获得更多的参与机会。研究进一步探讨了将Blockchain技术与Smart Contracts相结合，以实现信任评估和激励分配过程的自动化，从而保证了系统的透明度与去中心化。该理论框架旨在构建一个更具鲁棒性、公平且透明的FL生态系统，有效降低了不可信参与者带来的潜在风险。",
      "categories": [
        "cs.LG",
        "cs.AI",
        "cs.ET"
      ],
      "primary_category": "cs.LG",
      "comment": "To appear in the ICBTA 2025 Conference Proceedings and published as a volume of Lecture Notes in Networks and Systems by Springer",
      "pdf_url": "https://arxiv.org/pdf/2602.08290v1",
      "published_date": "2026-02-09 05:47:51 UTC",
      "updated_date": "2026-02-09 05:47:51 UTC",
      "processing_status": "completed",
      "attempts": 1,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "llm_backup_calls": 0,
      "last_update": "2026-02-16T05:11:05.507566+00:00"
    },
    {
      "arxiv_id": "2602.09064v2",
      "title": "Predicting Open Source Software Sustainability with Deep Temporal Neural Hierarchical Architectures and Explainable AI",
      "title_zh": "基于深度时序神经层次架构与可解释人工智能的开源软件可持续性预测",
      "authors": [
        "S M Rakib Ul Karim",
        "Wenyi Lu",
        "Enock Kasaadha",
        "Sean Goggins"
      ],
      "abstract": "Open Source Software (OSS) projects follow diverse lifecycle trajectories shaped by evolving patterns of contribution, coordination, and community engagement. Understanding these trajectories is essential for stakeholders seeking to assess project organization and health at scale. However, prior work has largely relied on static or aggregated metrics, such as project age or cumulative activity, providing limited insight into how OSS sustainability unfolds over time. In this paper, we propose a hierarchical predictive framework that models OSS projects as belonging to distinct lifecycle stages grounded in established socio-technical categorizations of OSS development. Rather than treating sustainability solely as project longevity, these lifecycle stages operationalize sustainability as a multidimensional construct integrating contribution activity, community participation, and maintenance dynamics. The framework combines engineered tabular indicators with 24-month temporal activity sequences and employs a multi-stage classification pipeline to distinguish lifecycle stages associated with different coordination and participation regimes. To support transparency, we incorporate explainable AI techniques to examine the relative contribution of feature categories to model predictions. Evaluated on a large corpus of OSS repositories, the proposed approach achieves over 94\\% overall accuracy in lifecycle stage classification. Attribution analyses consistently identify contribution activity and community-related features as dominant signals, highlighting the central role of collective participation dynamics.",
      "tldr_zh": "该研究提出了一个分层预测框架，旨在通过深度时间神经架构和可解释人工智能(Explainable AI)来预测开源软件(Open Source Software, OSS)的可持续性。该框架将可持续性操作化为一个整合了贡献活动、社区参与和维护动态的多维结构，克服了以往研究依赖静态或聚合指标的局限性。通过结合工程化表格指标与24个月的时间活动序列，研究采用多阶段分类流水线来识别与不同协作机制相关的项目生命周期阶段(Lifecycle Stages)。实验结果表明，该方法在生命周期阶段分类中达到了超过94%的整体准确率。最后，通过可解释性技术进行的归因分析(Attribution analyses)发现，贡献活动和社区相关特征是预测模型的主导信号，强调了集体参与动态在维持项目健康中的核心作用。",
      "categories": [
        "cs.SE",
        "cs.AI",
        "cs.LG"
      ],
      "primary_category": "cs.SE",
      "comment": "",
      "pdf_url": "https://arxiv.org/pdf/2602.09064v2",
      "published_date": "2026-02-09 05:44:34 UTC",
      "updated_date": "2026-02-13 05:56:05 UTC",
      "processing_status": "completed",
      "attempts": 1,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "llm_backup_calls": 0,
      "last_update": "2026-02-16T05:11:09.497224+00:00"
    },
    {
      "arxiv_id": "2602.08287v1",
      "title": "Noise Stability of Transformer Models",
      "title_zh": "Transformer 模型的噪声稳定性",
      "authors": [
        "Themistoklis Haris",
        "Zihan Zhang",
        "Yuichi Yoshida"
      ],
      "abstract": "Understanding simplicity biases in deep learning offers a promising path toward developing reliable AI. A common metric for this, inspired by Boolean function analysis, is average sensitivity, which captures a model's robustness to single-token perturbations. We argue that average sensitivity has two key limitations: it lacks a natural generalization to real-valued domains and fails to explain the \"junta-like\" input dependence we empirically observe in modern LLMs. To address these limitations, we propose noise stability as a more comprehensive simplicity metric. Noise stability expresses a model's robustness to correlated noise applied to all input coordinates simultaneously. We provide a theoretical analysis of noise stability for single-layer attention and ReLU MLP layers and tackle the multi-layer propagation problem with a covariance interval propagation approach. Building on this theory, we develop a practical noise stability regularization method. Experiments on algorithmic and next-token-prediction tasks show that our regularizer consistently catalyzes grokking and accelerates training by approximately $35\\%$ and $75\\%$ respectively. Our results sculpt a new connection between signal propagation in neural networks and interpretability, with noise stability emerging as a powerful tool for understanding and improving modern Transformers.",
      "tldr_zh": "该研究探讨了深度学习中的简单性偏差(simplicity biases)，并指出常用的平均敏感度(average sensitivity)指标在处理实值域和解释大语言模型(LLMs)的输入依赖性方面存在局限。为此，作者提出了噪声稳定性(noise stability)作为一种更全面的简单性度量标准，用于评估模型对所有输入坐标同时施加相关噪声时的鲁棒性。研究对单层Attention和ReLU MLP层的噪声稳定性进行了理论分析，并利用协方差区间传播(covariance interval propagation)方法解决了多层传播问题。基于该理论，作者开发了一种实用的噪声稳定性正则化方法(noise stability regularization)。实验结果显示，该正则化器在算法任务和下文预测(next-token-prediction)任务中分别将训练速度提升了约35%和75%，并一致地促进了顿悟(grokking)现象的发生。该项工作建立了神经网络信号传播与可解释性之间的新联系，证明了噪声稳定性是理解和改进现代Transformer模型的强有力工具。",
      "categories": [
        "cs.LG",
        "cs.AI",
        "stat.ML"
      ],
      "primary_category": "cs.LG",
      "comment": "Published in ICLR 2026",
      "pdf_url": "https://arxiv.org/pdf/2602.08287v1",
      "published_date": "2026-02-09 05:43:22 UTC",
      "updated_date": "2026-02-09 05:43:22 UTC",
      "processing_status": "completed",
      "attempts": 1,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "llm_backup_calls": 0,
      "last_update": "2026-02-16T05:11:29.900222+00:00"
    },
    {
      "arxiv_id": "2602.08282v1",
      "title": "Tighnari v2: Mitigating Label Noise and Distribution Shift in Multimodal Plant Distribution Prediction via Mixture of Experts and Weakly Supervised Learning",
      "title_zh": "Tighnari v2：基于混合专家模型与弱监督学习，缓解多模态植物分布预测中的标签噪声与分布偏移",
      "authors": [
        "Haixu Liu",
        "Yufei Wang",
        "Tianxiang Xu",
        "Chuancheng Shi",
        "Hongsheng Xing"
      ],
      "abstract": "Large-scale, cross-species plant distribution prediction plays a crucial role in biodiversity conservation, yet modeling efforts in this area still face significant challenges due to the sparsity and bias of observational data. Presence-Absence (PA) data provide accurate and noise-free labels, but are costly to obtain and limited in quantity; Presence-Only (PO) data, by contrast, offer broad spatial coverage and rich spatiotemporal distribution, but suffer from severe label noise in negative samples. To address these real-world constraints, this paper proposes a multimodal fusion framework that fully leverages the strengths of both PA and PO data. We introduce an innovative pseudo-label aggregation strategy for PO data based on the geographic coverage of satellite imagery, enabling geographic alignment between the label space and remote sensing feature space. In terms of model architecture, we adopt Swin Transformer Base as the backbone for satellite imagery, utilize the TabM network for tabular feature extraction, retain the Temporal Swin Transformer for time-series modeling, and employ a stackable serial tri-modal cross-attention mechanism to optimize the fusion of heterogeneous modalities. Furthermore, empirical analysis reveals significant geographic distribution shifts between PA training and test samples, and models trained by directly mixing PO and PA data tend to experience performance degradation due to label noise in PO data. To address this, we draw on the mixture-of-experts paradigm: test samples are partitioned according to their spatial proximity to PA samples, and different models trained on distinct datasets are used for inference and post-processing within each partition. Experiments on the GeoLifeCLEF 2025 dataset demonstrate that our approach achieves superior predictive performance in scenarios with limited PA coverage and pronounced distribution shifts.",
      "tldr_zh": "该研究提出了 Tighnari v2，这是一个旨在解决多模态植物分布预测中标签噪声和分布偏移问题的融合框架。针对 Presence-Absence (PA) 数据量少且分布不均，以及 Presence-Only (PO) 数据负样本噪声大的难题，研究引入了一种基于卫星图像地理覆盖的伪标签聚合策略，实现了标签空间与遥感特征空间的地理对齐。在模型架构上，Tighnari v2 整合了 Swin Transformer Base 提取影像特征、TabM 处理表格数据、以及 Temporal Swin Transformer 进行时间序列建模，并利用可堆叠的串联三模态交叉注意力机制优化异构数据的融合。此外，研究采用专家混合 (Mixture of Experts) 范式，根据空间接近度对测试样本进行划分，并为不同区域分配特定的训练模型进行推理和后处理。在 GeoLifeCLEF 2025 数据集上的实验证明，该方法在有限的 PA 覆盖和显著的分布偏移场景下，实现了优异的预测性能。",
      "categories": [
        "cs.CV",
        "cs.AI"
      ],
      "primary_category": "cs.CV",
      "comment": "",
      "pdf_url": "https://arxiv.org/pdf/2602.08282v1",
      "published_date": "2026-02-09 05:23:22 UTC",
      "updated_date": "2026-02-09 05:23:22 UTC",
      "processing_status": "completed",
      "attempts": 1,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "llm_backup_calls": 0,
      "last_update": "2026-02-16T05:11:27.108548+00:00"
    },
    {
      "arxiv_id": "2602.08277v1",
      "title": "PISCO: Precise Video Instance Insertion with Sparse Control",
      "title_zh": "PISCO：基于稀疏控制的精确视频实例插入",
      "authors": [
        "Xiangbo Gao",
        "Renjie Li",
        "Xinghao Chen",
        "Yuheng Wu",
        "Suofei Feng",
        "Qing Yin",
        "Zhengzhong Tu"
      ],
      "abstract": "The landscape of AI video generation is undergoing a pivotal shift: moving beyond general generation - which relies on exhaustive prompt-engineering and \"cherry-picking\" - towards fine-grained, controllable generation and high-fidelity post-processing. In professional AI-assisted filmmaking, it is crucial to perform precise, targeted modifications. A cornerstone of this transition is video instance insertion, which requires inserting a specific instance into existing footage while maintaining scene integrity. Unlike traditional video editing, this task demands several requirements: precise spatial-temporal placement, physically consistent scene interaction, and the faithful preservation of original dynamics - all achieved under minimal user effort. In this paper, we propose PISCO, a video diffusion model for precise video instance insertion with arbitrary sparse keyframe control. PISCO allows users to specify a single keyframe, start-and-end keyframes, or sparse keyframes at arbitrary timestamps, and automatically propagates object appearance, motion, and interaction. To address the severe distribution shift induced by sparse conditioning in pretrained video diffusion models, we introduce Variable-Information Guidance for robust conditioning and Distribution-Preserving Temporal Masking to stabilize temporal generation, together with geometry-aware conditioning for realistic scene adaptation. We further construct PISCO-Bench, a benchmark with verified instance annotations and paired clean background videos, and evaluate performance using both reference-based and reference-free perceptual metrics. Experiments demonstrate that PISCO consistently outperforms strong inpainting and video editing baselines under sparse control, and exhibits clear, monotonic performance improvements as additional control signals are provided. Project page: xiangbogaobarry.github.io/PISCO.",
      "tldr_zh": "该研究提出了 PISCO，一种旨在实现精确视频实例插入的视频扩散模型，支持用户通过任意稀疏关键帧（如单帧或起止帧）进行精准控制。为了解决预训练视频扩散模型在稀疏条件下出现的分布偏移问题，PISCO 引入了可变信息引导（Variable-Information Guidance）和分布保持时间掩码（Distribution-Preserving Temporal Masking）技术，并结合几何感知条件以确保现实的场景适应性。该框架能够自动传播对象的视频外观、运动及交互，确保插入实例在时空位置上的精确性以及与原场景物理交互的一致性。实验表明，PISCO 在稀疏控制下的表现始终优于强基线修复和编辑模型，且随着控制信号的增加，生成质量呈现明显的单调提升。此外，研究团队还构建了包含验证注释的 PISCO-Bench 基准，为该领域的高保真后期处理和可控视频生成提供了重要的评估工具。",
      "categories": [
        "cs.CV",
        "cs.AI"
      ],
      "primary_category": "cs.CV",
      "comment": "",
      "pdf_url": "https://arxiv.org/pdf/2602.08277v1",
      "published_date": "2026-02-09 05:15:39 UTC",
      "updated_date": "2026-02-09 05:15:39 UTC",
      "processing_status": "completed",
      "attempts": 1,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "llm_backup_calls": 0,
      "last_update": "2026-02-16T05:11:49.697761+00:00"
    },
    {
      "arxiv_id": "2602.08276v1",
      "title": "Toward Formalizing LLM-Based Agent Designs through Structural Context Modeling and Semantic Dynamics Analysis",
      "title_zh": "通过结构化上下文建模与语义动力学分析推动基于LLM的智能体设计形式化",
      "authors": [
        "Haoyu Jia",
        "Kento Kawaharazuka",
        "Kei Okada"
      ],
      "abstract": "Current research on large language model (LLM) agents is fragmented: discussions of conceptual frameworks and methodological principles are frequently intertwined with low-level implementation details, causing both readers and authors to lose track amid a proliferation of superficially distinct concepts. We argue that this fragmentation largely stems from the absence of an analyzable, self-consistent formal model that enables implementation-independent characterization and comparison of LLM agents. To address this gap, we propose the \\texttt{Structural Context Model}, a formal model for analyzing and comparing LLM agents from the perspective of context structure. Building upon this foundation, we introduce two complementary components that together span the full lifecycle of LLM agent research and development: (1) a declarative implementation framework; and (2) a sustainable agent engineering workflow, \\texttt{Semantic Dynamics Analysis}. The proposed workflow provides principled insights into agent mechanisms and supports rapid, systematic design iteration. We demonstrate the effectiveness of the complete framework on dynamic variants of the monkey-banana problem, where agents engineered using our approach achieve up to a 32 percentage points improvement in success rate on the most challenging setting.",
      "tldr_zh": "该研究针对大语言模型(LLM)智能体研究领域缺乏一致形式化模型、概念与实现细节长期混杂的现状，提出了从上下文结构视角分析和比较智能体的Structural Context Model。在此基础上，研究者引入了一个声明式实现框架以及名为Semantic Dynamics Analysis的持续性智能体工程工作流，旨在为智能体内部机制提供原则性见解，并支持系统化的快速设计迭代。实验在猴子摘香蕉问题(monkey-banana problem)的动态变体上验证了该框架的有效性，结果显示，采用此方法构建的智能体在最困难的任务设置中成功率提升了32个百分点。该研究为形式化描述和系统化开发高性能、可分析的LLM智能体提供了坚实的理论与工程基础。",
      "categories": [
        "cs.AI"
      ],
      "primary_category": "cs.AI",
      "comment": "",
      "pdf_url": "https://arxiv.org/pdf/2602.08276v1",
      "published_date": "2026-02-09 05:15:11 UTC",
      "updated_date": "2026-02-09 05:15:11 UTC",
      "processing_status": "completed",
      "attempts": 1,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "llm_backup_calls": 0,
      "last_update": "2026-02-16T05:12:03.004145+00:00"
    },
    {
      "arxiv_id": "2602.08274v1",
      "title": "Language Modeling and Understanding Through Paraphrase Generation and Detection",
      "title_zh": "基于释义生成与检测的语言建模与理解",
      "authors": [
        "Jan Philip Wahle"
      ],
      "abstract": "Language enables humans to share knowledge, reason about the world, and pass on strategies for survival and innovation across generations. At the heart of this process is not just the ability to communicate but also the remarkable flexibility in how we can express ourselves. We can express the same thoughts in virtually infinite ways using different words and structures - this ability to rephrase and reformulate expressions is known as paraphrase. Modeling paraphrases is a keystone to meaning in computational language models; being able to construct different variations of texts that convey the same meaning or not shows strong abilities of semantic understanding. If computational language models are to represent meaning, they must understand and control the different aspects that construct the same meaning as opposed to different meanings at a fine granularity. Yet most existing approaches reduce paraphrasing to a binary decision between two texts or to producing a single rewrite of a source, obscuring which linguistic factors are responsible for meaning preservation. In this thesis, I propose that decomposing paraphrases into their constituent linguistic aspects (paraphrase types) offers a more fine-grained and cognitively grounded view of semantic equivalence. I show that even advanced machine learning models struggle with this task. Yet, when explicitly trained on paraphrase types, models achieve stronger performance on related paraphrase tasks and downstream applications. For example, in plagiarism detection, language models trained on paraphrase types surpass human baselines: 89.6% accuracy compared to 78.4% for plagiarism cases from Wikipedia, and 66.5% compared to 55.7% for plagiarism of scientific papers from arXiv. In identifying duplicate questions on Quora, models trained with paraphrase types improve over models trained on binary pairs. Furthermore, I demonstrate that...",
      "tldr_zh": "该研究深入探讨了语言建模与理解中的释义生成（Paraphrase Generation）与检测问题，强调复述能力是计算语言模型衡量语义理解程度的关键。作者指出，现有研究多将 Paraphrasing 简化为简单的二元判断或单一文本重写，未能揭示维持意义等价的具体语言因素。为此，该论文提出将 Paraphrases 分解为细粒度的释义类型（Paraphrase Types），从而建立一个更符合认知基础的语义分析框架。实验表明，即便先进的模型在处理此类任务时仍存在挑战，但通过针对 Paraphrase Types 的显式训练，模型在下游应用中表现出显著优势。在剽窃检测（Plagiarism Detection）任务中，该方法在 Wikipedia 和 arXiv 数据集上的准确率分别达到 89.6% 和 66.5%，均远超人类基线水平。此外，该方法在 Quora 重复问题识别（Duplicate Questions Identification）任务中也取得了比传统二元分类模型更好的效果。通过这种多维度的建模方式，论文证明了精细化的语言分解对于提升机器语义理解与表征能力的有效性。",
      "categories": [
        "cs.CL",
        "cs.AI"
      ],
      "primary_category": "cs.CL",
      "comment": "PhD dissertation, University of Göttingen Germany, 2025. 182 pages",
      "pdf_url": "https://arxiv.org/pdf/2602.08274v1",
      "published_date": "2026-02-09 05:09:03 UTC",
      "updated_date": "2026-02-09 05:09:03 UTC",
      "processing_status": "completed",
      "attempts": 1,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "llm_backup_calls": 0,
      "last_update": "2026-02-16T05:12:08.000049+00:00"
    },
    {
      "arxiv_id": "2602.08272v1",
      "title": "When Do Multi-Agent Systems Outperform? Analysing the Learning Efficiency of Agentic Systems",
      "title_zh": "多智能体系统何时更具优势？智能体系统学习效率分析",
      "authors": [
        "Junwei Su",
        "Chuan Wu"
      ],
      "abstract": "Reinforcement Learning (RL) has emerged as a crucial method for training or fine-tuning large language models (LLMs), enabling adaptive, task-specific optimizations through interactive feedback. Multi-Agent Reinforcement Learning (MARL), in particular, offers a promising avenue by decomposing complex tasks into specialized subtasks learned by distinct interacting agents, potentially enhancing the ability and efficiency of LLM systems. However, theoretical insights regarding when and why MARL outperforms Single-Agent RL (SARL) remain limited, creating uncertainty in selecting the appropriate RL framework. In this paper, we address this critical gap by rigorously analyzing the comparative sample efficiency of MARL and SARL within the context of LLM. Leveraging the Probably Approximately Correct (PAC) framework, we formally define SARL and MARL setups for LLMs, derive explicit sample complexity bounds, and systematically characterize how task decomposition and alignment influence learning efficiency. Our results demonstrate that MARL improves sample complexity when tasks naturally decompose into independent subtasks, whereas dependent subtasks diminish MARL's comparative advantage. Additionally, we introduce and analyze the concept of task alignment, quantifying the trade-offs when enforcing independent task decomposition despite potential misalignments. These theoretical insights clarify empirical inconsistencies and provide practical criteria for deploying MARL strategies effectively in complex LLM scenarios.",
      "tldr_zh": "该研究通过 Probably Approximately Correct (PAC) 框架严谨分析了多智能体强化学习 (MARL) 与单智能体强化学习 (SARL) 在大语言模型 (LLM) 场景下的样本效率 (Sample Efficiency)。作者正式定义了两种架构的设置并推导出显式样本复杂度界限，系统地刻画了任务分解和对齐如何影响学习效率。研究结果表明，当任务能够自然分解为独立的子任务时，MARL 能显著优化样本复杂度，而子任务间的依赖性则会削弱其相对优势。此外，研究还引入并分析了任务对齐 (Task Alignment) 概念，量化了在潜在错位情况下强制执行独立任务分解的权衡。这些理论见解澄清了实证结果中的不一致性，并为在复杂 LLM 场景中有效部署 MARL 策略提供了实用标准。",
      "categories": [
        "cs.LG",
        "cs.AI"
      ],
      "primary_category": "cs.LG",
      "comment": "",
      "pdf_url": "https://arxiv.org/pdf/2602.08272v1",
      "published_date": "2026-02-09 05:08:36 UTC",
      "updated_date": "2026-02-09 05:08:36 UTC",
      "processing_status": "completed",
      "attempts": 1,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "llm_backup_calls": 0,
      "last_update": "2026-02-16T05:12:09.900461+00:00"
    },
    {
      "arxiv_id": "2602.08268v2",
      "title": "Puda: Private User Dataset Agent for User-Sovereign and Privacy-Preserving Personalized AI",
      "title_zh": "Puda：面向用户主权与隐私保护个性化人工智能的私有用户数据集智能体",
      "authors": [
        "Akinori Maeda",
        "Yuto Sekiya",
        "Sota Sugimura",
        "Tomoya Asai",
        "Yu Tsuda",
        "Kohei Ikeda",
        "Hiroshi Fujii",
        "Kohei Watanabe"
      ],
      "abstract": "Personal data centralization among dominant platform providers including search engines, social networking services, and e-commerce has created siloed ecosystems that restrict user sovereignty, thereby impeding data use across services. Meanwhile, the rapid proliferation of Large Language Model (LLM)-based agents has intensified demand for highly personalized services that require the dynamic provision of diverse personal data. This presents a significant challenge: balancing the utilization of such data with privacy protection. To address this challenge, we propose Puda (Private User Dataset Agent), a user-sovereign architecture that aggregates data across services and enables client-side management. Puda allows users to control data sharing at three privacy levels: (i) Detailed Browsing History, (ii) Extracted Keywords, and (iii) Predefined Category Subsets. We implemented Puda as a browser-based system that serves as a common platform across diverse services and evaluated it through a personalized travel planning task. Our results show that providing Predefined Category Subsets achieves 97.2% of the personalization performance (evaluated via an LLM-as-a-Judge framework across three criteria) obtained when sharing Detailed Browsing History. These findings demonstrate that Puda enables effective multi-granularity management, offering practical choices to mitigate the privacy-personalization trade-off. Overall, Puda provides an AI-native foundation for user sovereignty, empowering users to safely leverage the full potential of personalized AI.",
      "tldr_zh": "该研究提出了Puda（Private User Dataset Agent），这是一种旨在实现用户自主和隐私保护的个性化AI架构。Puda解决了当前数据中心化导致的用户主权受限问题，并应对了大语言模型（LLM）智能体对多样化个人数据需求与隐私保护之间的矛盾。该架构在客户端聚合跨服务数据，允许用户根据Detailed Browsing History、Extracted Keywords和Predefined Category Subsets三种隐私等级灵活管理数据共享。通过个性化旅游规划任务的评估，研究发现提供Predefined Category Subsets能够在保护隐私的前提下，实现分享Detailed Browsing History时97.2%的个性化性能。这证明了Puda提供的多粒度管理方案能有效平衡隐私与个性化需求，为用户在保障隐私的同时充分发挥个性化AI潜力奠定了技术基础。",
      "categories": [
        "cs.AI"
      ],
      "primary_category": "cs.AI",
      "comment": "9 pages, 5 figures",
      "pdf_url": "https://arxiv.org/pdf/2602.08268v2",
      "published_date": "2026-02-09 05:00:48 UTC",
      "updated_date": "2026-02-10 05:00:53 UTC",
      "processing_status": "completed",
      "attempts": 1,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "llm_backup_calls": 0,
      "last_update": "2026-02-16T05:12:12.504772+00:00"
    },
    {
      "arxiv_id": "2602.08267v1",
      "title": "Inverting Data Transformations via Diffusion Sampling",
      "title_zh": "基于扩散采样的数据变换反演",
      "authors": [
        "Jinwoo Kim",
        "Sékou-Oumar Kaba",
        "Jiyun Park",
        "Seunghoon Hong",
        "Siamak Ravanbakhsh"
      ],
      "abstract": "We study the problem of transformation inversion on general Lie groups: a datum is transformed by an unknown group element, and the goal is to recover an inverse transformation that maps it back to the original data distribution. Such unknown transformations arise widely in machine learning and scientific modeling, where they can significantly distort observations. We take a probabilistic view and model the posterior over transformations as a Boltzmann distribution defined by an energy function on data space. To sample from this posterior, we introduce a diffusion process on Lie groups that keeps all updates on-manifold and only requires computations in the associated Lie algebra. Our method, Transformation-Inverting Energy Diffusion (TIED), relies on a new trivialized target-score identity that enables efficient score-based sampling of the transformation posterior. As a key application, we focus on test-time equivariance, where the objective is to improve the robustness of pretrained neural networks to input transformations. Experiments on image homographies and PDE symmetries demonstrate that TIED can restore transformed inputs to the training distribution at test time, showing improved performance over strong canonicalization and sampling baselines. Code is available at https://github.com/jw9730/tied.",
      "tldr_zh": "这项研究提出了TIED (Transformation-Inverting Energy Diffusion) 方法，旨在解决一般Lie groups上的变换逆转问题，即从被未知群元素变换的数据中恢复原始分布。该方法采用概率视角，将变换的后验分布建模为由数据空间能量函数定义的Boltzmann distribution，并引入了一种在Lie groups上运行的扩散过程，通过Lie algebra计算确保更新保持在流形上。TIED的核心在于提出了一种新的trivialized target-score identity，实现了对变换后验的高效得分采样(score-based sampling)。在测试时等变性(test-time equivariance)的应用中，该方法能将经过变换的输入恢复至训练分布，从而增强预训练神经网络的鲁棒性。实验证明，在图像单应性(homographies)和PDE symmetries等任务上，TIED在性能上优于现有的规范化(canonicalization)和采样基准。",
      "categories": [
        "cs.LG",
        "cs.AI"
      ],
      "primary_category": "cs.LG",
      "comment": "24 pages, 4 figures",
      "pdf_url": "https://arxiv.org/pdf/2602.08267v1",
      "published_date": "2026-02-09 04:58:34 UTC",
      "updated_date": "2026-02-09 04:58:34 UTC",
      "processing_status": "completed",
      "attempts": 1,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "llm_backup_calls": 0,
      "last_update": "2026-02-16T05:12:22.398057+00:00"
    },
    {
      "arxiv_id": "2602.08254v1",
      "title": "SynthAgent: A Multi-Agent LLM Framework for Realistic Patient Simulation -- A Case Study in Obesity with Mental Health Comorbidities",
      "title_zh": "SynthAgent：用于真实患者模拟的大语言模型多智能体框架——肥胖症及其心理健康共病的案例研究",
      "authors": [
        "Arman Aghaee",
        "Sepehr Asgarian",
        "Jouhyun Jeon"
      ],
      "abstract": "Simulating high-fidelity patients offers a powerful avenue for studying complex diseases while addressing the challenges of fragmented, biased, and privacy-restricted real-world data. In this study, we introduce SynthAgent, a novel Multi-Agent System (MAS) framework designed to model obesity patients with comorbid mental disorders, including depression, anxiety, social phobia, and binge eating disorder. SynthAgent integrates clinical and medical evidence from claims data, population surveys, and patient-centered literature to construct personalized virtual patients enriched with personality traits that influence adherence, emotion regulation, and lifestyle behaviors. Through autonomous agent interactions, the system simulates disease progression, treatment response, and life management across diverse psychosocial contexts. Evaluation of more than 100 generated patients demonstrated that GPT-5 and Claude 4.5 Sonnet achieved the highest fidelity as the core engine in the proposed MAS framework, outperforming Gemini 2.5 Pro and DeepSeek-R1. SynthAgent thus provides a scalable and privacy-preserving framework for exploring patient journeys, behavioral dynamics, and decision-making processes in both medical and psychological domains.",
      "tldr_zh": "该研究提出了 SynthAgent，一种新型的多智能体系统 (Multi-Agent System, MAS) 框架，旨在模拟患有精神健康共病（包括抑郁、焦虑、社交恐惧和暴食症）的肥胖患者。该框架通过整合保险索赔数据、人口调查和学术文献中的临床证据，构建了具有个性化人格特质的虚拟患者，以捕捉影响治疗依从性、情绪调节和生活方式行为的关键因素。通过智能体的自主交互，系统能够在多种心理社会背景下模拟疾病进展、治疗反应及日常生活管理过程。对 100 多名生成的虚拟患者进行评估的结果表明，GPT-5 和 Claude 4.5 Sonnet 在该框架中作为核心引擎表现出了最高的保真度 (fidelity)，其性能优于 Gemini 2.5 Pro 和 DeepSeek-R1。SynthAgent 为在医疗和心理学领域研究患者旅程、行为动态及决策过程提供了一个高度可扩展且保护隐私的模拟平台。",
      "categories": [
        "cs.AI",
        "cs.IR",
        "cs.MA"
      ],
      "primary_category": "cs.AI",
      "comment": "Presented in AAAI 2026 Singapore at the workshop of Health Intelligence",
      "pdf_url": "https://arxiv.org/pdf/2602.08254v1",
      "published_date": "2026-02-09 04:14:19 UTC",
      "updated_date": "2026-02-09 04:14:19 UTC",
      "processing_status": "completed",
      "attempts": 1,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "llm_backup_calls": 0,
      "last_update": "2026-02-16T05:12:31.304564+00:00"
    },
    {
      "arxiv_id": "2602.08253v1",
      "title": "G-LNS: Generative Large Neighborhood Search for LLM-Based Automatic Heuristic Design",
      "title_zh": "G-LNS：面向基于大语言模型的自动启发式设计的生成式大邻域搜索",
      "authors": [
        "Baoyun Zhao",
        "He Wang",
        "Liang Zeng"
      ],
      "abstract": "While Large Language Models (LLMs) have recently shown promise in Automated Heuristic Design (AHD), existing approaches typically formulate AHD around constructive priority rules or parameterized local search guidance, thereby restricting the search space to fixed heuristic forms. Such designs offer limited capacity for structural exploration, making it difficult to escape deep local optima in complex Combinatorial Optimization Problems (COPs). In this work, we propose G-LNS, a generative evolutionary framework that extends LLM-based AHD to the automated design of Large Neighborhood Search (LNS) operators. Unlike prior methods that evolve heuristics in isolation, G-LNS leverages LLMs to co-evolve tightly coupled pairs of destroy and repair operators. A cooperative evaluation mechanism explicitly captures their interaction, enabling the discovery of complementary operator logic that jointly performs effective structural disruption and reconstruction. Extensive experiments on challenging COP benchmarks, such as Traveling Salesman Problems (TSP) and Capacitated Vehicle Routing Problems (CVRP), demonstrate that G-LNS significantly outperforms LLM-based AHD methods as well as strong classical solvers. The discovered heuristics not only achieve near-optimal solutions with reduced computational budgets but also exhibit robust generalization across diverse and unseen instance distributions.",
      "tldr_zh": "该研究针对现有基于大语言模型(LLMs)的自动化启发式设计(AHD)在处理复杂组合优化问题(COPs)时搜索空间有限且难以跳出局部最优的问题，提出了G-LNS框架。G-LNS是一个生成式演化框架，旨在利用LLMs自动设计大邻域搜索(LNS)算子。与以往独立演化启发式方法不同，该框架利用LLMs共同演化紧密耦合的“破坏(destroy)”和“修复(repair)”算子对，并引入协作评估机制来捕捉其相互作用，从而实现有效的结构性破坏与重建。在旅行商问题(TSP)和容量受限的车辆路径问题(CVRP)等基准测试上的实验表明，G-LNS的性能显著优于现有的基于LLM的AHD方法及强力经典求解器。所发现的启发式算法不仅能在较低的计算成本下获得接近最优的解，还在多种未见的实例分布中表现出强大的泛化能力。",
      "categories": [
        "cs.AI"
      ],
      "primary_category": "cs.AI",
      "comment": "",
      "pdf_url": "https://arxiv.org/pdf/2602.08253v1",
      "published_date": "2026-02-09 04:13:35 UTC",
      "updated_date": "2026-02-09 04:13:35 UTC",
      "processing_status": "completed",
      "attempts": 1,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "llm_backup_calls": 0,
      "last_update": "2026-02-16T05:12:33.603065+00:00"
    },
    {
      "arxiv_id": "2602.08245v1",
      "title": "STEP: Warm-Started Visuomotor Policies with Spatiotemporal Consistency Prediction",
      "title_zh": "STEP：基于时空一致性预测的热启动视觉运动策略",
      "authors": [
        "Jinhao Li",
        "Yuxuan Cong",
        "Yingqiao Wang",
        "Hao Xia",
        "Shan Huang",
        "Yijia Zhang",
        "Ningyi Xu",
        "Guohao Dai"
      ],
      "abstract": "Diffusion policies have recently emerged as a powerful paradigm for visuomotor control in robotic manipulation due to their ability to model the distribution of action sequences and capture multimodality. However, iterative denoising leads to substantial inference latency, limiting control frequency in real-time closed-loop systems. Existing acceleration methods either reduce sampling steps, bypass diffusion through direct prediction, or reuse past actions, but often struggle to jointly preserve action quality and achieve consistently low latency. In this work, we propose STEP, a lightweight spatiotemporal consistency prediction mechanism to construct high-quality warm-start actions that are both distributionally close to the target action and temporally consistent, without compromising the generative capability of the original diffusion policy. Then, we propose a velocity-aware perturbation injection mechanism that adaptively modulates actuation excitation based on temporal action variation to prevent execution stall especially for real-world tasks. We further provide a theoretical analysis showing that the proposed prediction induces a locally contractive mapping, ensuring convergence of action errors during diffusion refinement. We conduct extensive evaluations on nine simulated benchmarks and two real-world tasks. Notably, STEP with 2 steps can achieve an average 21.6% and 27.5% higher success rate than BRIDGER and DDIM on the RoboMimic benchmark and real-world tasks, respectively. These results demonstrate that STEP consistently advances the Pareto frontier of inference latency and success rate over existing methods.",
      "tldr_zh": "该研究提出了STEP，一种具有时空一致性预测(Spatiotemporal Consistency Prediction)的轻量化预热机制，旨在解决扩散策略(Diffusion policies)在机器人视觉运动控制中因迭代去噪导致的推理延迟问题。STEP通过构建在分布上接近目标动作且具备时间一致性的高质量预热动作，在不损害原始策略生成能力的前提下实现了快速推理。此外，研究引入了速度感知扰动注入机制(Velocity-aware perturbation injection)，根据动作的时间变化自适应调节执行激励，以防止在现实任务中出现执行停滞。理论分析表明，该预测机制诱导了局部收缩映射，确保了动作误差在扩散细化过程中的收敛。实验结果显示，仅需2步采样的STEP在仿真基准和真实任务中的成功率分别比BRIDGER和DDIM高出21.6%和27.5%。该方法有效推进了推理延迟与成功率之间的帕累托前沿(Pareto frontier)，为高效、实时的闭环机器人控制提供了新方案。",
      "categories": [
        "cs.RO",
        "cs.AI"
      ],
      "primary_category": "cs.RO",
      "comment": "13 pages, 9 figures",
      "pdf_url": "https://arxiv.org/pdf/2602.08245v1",
      "published_date": "2026-02-09 03:50:40 UTC",
      "updated_date": "2026-02-09 03:50:40 UTC",
      "processing_status": "completed",
      "attempts": 1,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "llm_backup_calls": 0,
      "last_update": "2026-02-16T05:12:36.401243+00:00"
    },
    {
      "arxiv_id": "2602.08244v1",
      "title": "Learning in Context, Guided by Choice: A Reward-Free Paradigm for Reinforcement Learning with Transformers",
      "title_zh": "基于选择引导的上下文学习：基于 Transformer 的强化学习无奖励范式",
      "authors": [
        "Juncheng Dong",
        "Bowen He",
        "Moyang Guo",
        "Ethan X. Fang",
        "Zhuoran Yang",
        "Vahid Tarokh"
      ],
      "abstract": "In-context reinforcement learning (ICRL) leverages the in-context learning capabilities of transformer models (TMs) to efficiently generalize to unseen sequential decision-making tasks without parameter updates. However, existing ICRL methods rely on explicit reward signals during pretraining, which limits their applicability when rewards are ambiguous, hard to specify, or costly to obtain. To overcome this limitation, we propose a new learning paradigm, In-Context Preference-based Reinforcement Learning (ICPRL), in which both pretraining and deployment rely solely on preference feedback, eliminating the need for reward supervision. We study two variants that differ in the granularity of feedback: Immediate Preference-based RL (I-PRL) with per-step preferences, and Trajectory Preference-based RL (T-PRL) with trajectory-level comparisons. We first show that supervised pretraining, a standard approach in ICRL, remains effective under preference-only context datasets, demonstrating the feasibility of in-context reinforcement learning using only preference signals. To further improve data efficiency, we introduce alternative preference-native frameworks for I-PRL and T-PRL that directly optimize TM policies from preference data without requiring reward signals nor optimal action labels.Experiments on dueling bandits, navigation, and continuous control tasks demonstrate that ICPRL enables strong in-context generalization to unseen tasks, achieving performance comparable to ICRL methods trained with full reward supervision.",
      "tldr_zh": "该研究提出了 In-Context Preference-based Reinforcement Learning (ICPRL)，旨在解决现有的 In-context reinforcement learning (ICRL) 在预训练中过度依赖显式奖励信号的问题，这种依赖在奖励获取成本高昂或存在歧义的场景下限制了应用。ICPRL 建立了仅依赖偏好反馈 (preference feedback) 的新范式，并区分了步级偏好 (I-PRL) 与轨迹级偏好 (T-PRL) 两种反馈粒度。研究验证了基于偏好的上下文数据集进行监督预训练的有效性，并进一步提出了无需奖励信号或最优动作标签的偏好原生框架，直接从偏好数据中优化 Transformer Model (TM) 策略。在 dueling bandits、导航和连续控制任务上的实验表明，ICPRL 能够实现在未见任务上的强大情境泛化能力。其最终表现达到了与全奖励监督下的 ICRL 方法相当的水平，证明了在无需奖励监督的情况下实现高效强化学习的可行性。",
      "categories": [
        "cs.LG",
        "cs.AI"
      ],
      "primary_category": "cs.LG",
      "comment": "",
      "pdf_url": "https://arxiv.org/pdf/2602.08244v1",
      "published_date": "2026-02-09 03:42:16 UTC",
      "updated_date": "2026-02-09 03:42:16 UTC",
      "processing_status": "completed",
      "attempts": 1,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "llm_backup_calls": 0,
      "last_update": "2026-02-16T05:12:50.814230+00:00"
    },
    {
      "arxiv_id": "2602.08241v1",
      "title": "Do MLLMs Really See It: Reinforcing Visual Attention in Multimodal LLMs",
      "title_zh": "MLLM 真的“看见”了吗：强化多模态大语言模型的视觉注意力",
      "authors": [
        "Siqu Ou",
        "Tianrui Wan",
        "Zhiyuan Zhao",
        "Junyu Gao",
        "Xuelong Li"
      ],
      "abstract": "While chain-of-thought (CoT) reasoning has substantially improved multimodal large language models (MLLMs) on complex reasoning tasks, existing approaches largely rely on long textual reasoning trajectories and provide limited mechanisms for learning stable visual attention policies. Our analysis shows that current MLLMs exhibit weak visual focus: early-stage visual misalignment is rarely corrected during subsequent reasoning, leading to error propagation and failed inferences. We argue that this limitation stems from inadequate credit assignment for visual attention during training. To address this issue, we propose SAYO, a visual reasoning model trained with a reinforcement learning (RL) framework that introduces a region-level visual attention-based reward. This reward explicitly aligns optimization signals with visually grounded reasoning steps, enabling the model to learn more reliable attention behaviors. Extensive experiments across multiple multimodal benchmarks demonstrate that SAYO consistently improves performance on diverse reasoning and perception tasks.",
      "tldr_zh": "该研究探讨了多模态大语言模型(MLLMs)在复杂推理任务中存在的视觉焦点薄弱问题，分析指出早期的视觉对齐错误会在推理过程中不断传播并导致最终推断失败。研究认为这一局限性源于训练期间视觉注意力(Visual Attention)的信用分配不足，为此提出了名为SAYO的视觉推理模型。该模型通过强化学习(Reinforcement Learning)框架进行训练，并创新性地引入了基于区域级视觉注意力的奖励机制。该机制将优化信号与视觉落地的推理步骤显式对齐，使模型能够学习到更加可靠的注意力行为。在多个多模态基准测试上的实验结果表明，SAYO在多样化的推理和感知任务中均显著提升了性能表现。",
      "categories": [
        "cs.AI",
        "cs.CV"
      ],
      "primary_category": "cs.AI",
      "comment": "",
      "pdf_url": "https://arxiv.org/pdf/2602.08241v1",
      "published_date": "2026-02-09 03:33:23 UTC",
      "updated_date": "2026-02-09 03:33:23 UTC",
      "processing_status": "completed",
      "attempts": 1,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "llm_backup_calls": 0,
      "last_update": "2026-02-16T05:12:47.416383+00:00"
    },
    {
      "arxiv_id": "2602.08240v1",
      "title": "PTS-SNN: A Prompt-Tuned Temporal Shift Spiking Neural Networks for Efficient Speech Emotion Recognition",
      "title_zh": "PTS-SNN：面向高效语音情感识别的提示微调时移脉冲神经网络",
      "authors": [
        "Xun Su",
        "Huamin Wang",
        "Qi Zhang"
      ],
      "abstract": "Speech Emotion Recognition (SER) is widely deployed in Human-Computer Interaction, yet the high computational cost of conventional models hinders their implementation on resource-constrained edge devices. Spiking Neural Networks (SNNs) offer an energy-efficient alternative due to their event-driven nature; however, their integration with continuous Self-Supervised Learning (SSL) representations is fundamentally challenged by distribution mismatch, where high-dynamic-range embeddings degrade the information coding capacity of threshold-based neurons. To resolve this, we propose Prompt-Tuned Spiking Neural Networks (PTS-SNN), a parameter-efficient neuromorphic adaptation framework that aligns frozen SSL backbones with spiking dynamics. Specifically, we introduce a Temporal Shift Spiking Encoder to capture local temporal dependencies via parameter-free channel shifts, establishing a stable feature basis. To bridge the domain gap, we devise a Context-Aware Membrane Potential Calibration strategy. This mechanism leverages a Spiking Sparse Linear Attention module to aggregate global semantic context into learnable soft prompts, which dynamically regulate the bias voltages of Parametric Leaky Integrate-and-Fire (PLIF) neurons. This regulation effectively centers the heterogeneous input distribution within the responsive firing range, mitigating functional silence or saturation. Extensive experiments on five multilingual datasets (e.g., IEMOCAP, CASIA, EMODB) demonstrate that PTS-SNN achieves 73.34\\% accuracy on IEMOCAP, comparable to competitive Artificial Neural Networks (ANNs), while requiring only 1.19M trainable parameters and 0.35 mJ inference energy per sample.",
      "tldr_zh": "该研究提出了PTS-SNN，一种基于Prompt-Tuned的Temporal Shift脉冲神经网络（Spiking Neural Networks），旨在实现高效的语音情感识别（SER）。针对自监督学习（SSL）表征与脉冲动力学之间的分布不匹配问题，作者引入了时间偏移脉冲编码器（Temporal Shift Spiking Encoder），通过无参数通道偏移捕获局部时间依赖性以建立稳定特征。研究进一步设计了上下文感知膜电位校准（Context-Aware Membrane Potential Calibration）策略，利用脉冲稀疏线性注意力（Spiking Sparse Linear Attention）生成学习型软提示（soft prompts），动态调节PLIF神经元的偏置电压。该机制有效地将异构输入分布对齐至神经元响应范围，解决了功能性静默或饱和带来的信息损耗。在IEMOCAP和CASIA等五个多语言数据集上的实验表明，PTS-SNN在IEMOCAP上取得了73.34%的准确率。该模型仅需1.19M可训练参数，且每样本推理能耗仅为0.35 mJ，在保持与人工神经网络（ANNs）相当性能的同时显著提升了能效。",
      "categories": [
        "cs.AI",
        "cs.SD"
      ],
      "primary_category": "cs.AI",
      "comment": "",
      "pdf_url": "https://arxiv.org/pdf/2602.08240v1",
      "published_date": "2026-02-09 03:29:16 UTC",
      "updated_date": "2026-02-09 03:29:16 UTC",
      "processing_status": "completed",
      "attempts": 1,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "llm_backup_calls": 0,
      "last_update": "2026-02-16T05:12:59.306695+00:00"
    },
    {
      "arxiv_id": "2602.08239v1",
      "title": "Linearization Explains Fine-Tuning in Large Language Models",
      "title_zh": "线性化解析大语言模型微调",
      "authors": [
        "Zahra Rahimi Afzal",
        "Tara Esmaeilbeig",
        "Mojtaba Soltanalian",
        "Mesrob I. Ohannessian"
      ],
      "abstract": "Parameter-Efficient Fine-Tuning (PEFT) is a popular class of techniques that strive to adapt large models in a scalable and resource-efficient manner. Yet, the mechanisms underlying their training performance and generalization remain underexplored. In this paper, we provide several insights into such fine-tuning through the lens of linearization. Fine-tuned models are often implicitly encouraged to remain close to the pretrained model. By making this explicit, using an Euclidean distance inductive bias in parameter space, we show that fine-tuning dynamics become equivalent to learning with the positive-definite neural tangent kernel (NTK). We specifically analyze how close the fully linear and the linearized fine-tuning optimizations are, based on the strength of the regularization. This allows us to be pragmatic about how good a model linearization is when fine-tuning large language models (LLMs). When linearization is a good model, our findings reveal a strong correlation between the eigenvalue spectrum of the NTK and the performance of model adaptation. Motivated by this, we give spectral perturbation bounds on the NTK induced by the choice of layers selected for fine-tuning. We empirically validate our theory on Low Rank Adaptation (LoRA) on LLMs. These insights not only characterize fine-tuning but also have the potential to enhance PEFT techniques, paving the way to better informed and more nimble adaptation in LLMs.",
      "tldr_zh": "该研究探讨了大语言模型(LLMs)中参数高效微调(PEFT)的内在机制，提出通过线性化(Linearization)的视角来解释其训练性能和泛化能力。研究表明，在显式使用欧几里得距离归纳偏置使微调模型接近预训练模型时，微调动力学等同于基于神经切向核(Neural Tangent Kernel, NTK)的学习。作者分析了正则化强度对线性化近似程度的影响，揭示了NTK特征值谱与模型适配性能之间存在强相关性。基于此发现，研究进一步给出了由层选择引起的NTK谱扰动界限，并在Low Rank Adaptation (LoRA)上进行了实验验证。这些见解不仅系统地刻画了微调过程，也为优化PEFT技术和实现更高效的LLM适配提供了理论指导。",
      "categories": [
        "cs.LG",
        "cs.AI"
      ],
      "primary_category": "cs.LG",
      "comment": "",
      "pdf_url": "https://arxiv.org/pdf/2602.08239v1",
      "published_date": "2026-02-09 03:27:58 UTC",
      "updated_date": "2026-02-09 03:27:58 UTC",
      "processing_status": "completed",
      "attempts": 1,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "llm_backup_calls": 0,
      "last_update": "2026-02-16T05:13:01.705321+00:00"
    },
    {
      "arxiv_id": "2602.08236v1",
      "title": "When and How Much to Imagine: Adaptive Test-Time Scaling with World Models for Visual Spatial Reasoning",
      "title_zh": "何时想象以及想象多少：面向视觉空间推理的基于世界模型自适应测试时缩放",
      "authors": [
        "Shoubin Yu",
        "Yue Zhang",
        "Zun Wang",
        "Jaehong Yoon",
        "Huaxiu Yao",
        "Mingyu Ding",
        "Mohit Bansal"
      ],
      "abstract": "Despite rapid progress in Multimodal Large Language Models (MLLMs), visual spatial reasoning remains unreliable when correct answers depend on how a scene would appear under unseen or alternative viewpoints. Recent work addresses this by augmenting reasoning with world models for visual imagination, but questions such as when imagination is actually necessary, how much of it is beneficial, and when it becomes harmful, remain poorly understood. In practice, indiscriminate imagination can increase computation and even degrade performance by introducing misleading evidence. In this work, we present an in-depth analysis of test-time visual imagination as a controllable resource for spatial reasoning. We study when static visual evidence is sufficient, when imagination improves reasoning, and how excessive or unnecessary imagination affects accuracy and efficiency. To support this analysis, we introduce AVIC, an adaptive test-time framework with world models that explicitly reasons about the sufficiency of current visual evidence before selectively invoking and scaling visual imagination. Across spatial reasoning benchmarks (SAT, MMSI) and an embodied navigation benchmark (R2R), our results reveal clear scenarios where imagination is critical, marginal, or detrimental, and show that selective control can match or outperform fixed imagination strategies with substantially fewer world-model calls and language tokens. Overall, our findings highlight the importance of analyzing and controlling test-time imagination for efficient and reliable spatial reasoning.",
      "tldr_zh": "该研究探讨了多模态大语言模型 (MLLMs) 在视觉空间推理 (Visual Spatial Reasoning) 中因视角变化导致的不确定性问题。针对盲目使用世界模型 (World Models) 进行视觉想象 (Visual Imagination) 可能带来的计算冗余和性能下降，作者提出了名为 AVIC 的自适应测试时框架。该框架能够显式评估当前视觉证据的充分性，从而有选择性地激活和扩展视觉想象资源。通过在 SAT、MMSI 空间推理基准以及 R2R 具身导航基准上的实验，研究揭示了视觉想象在不同场景下的必要性差异。结果表明，AVIC 能够以更少的世界模型调用次数和语言标记 (Tokens) 达到或优于固定想象策略的表现。这一研究成果强调了对测试时想象进行精准控制对于实现高效、可靠的空间推理至关重要。",
      "categories": [
        "cs.CV",
        "cs.AI",
        "cs.CL"
      ],
      "primary_category": "cs.CV",
      "comment": "the first two authors are equally contributed. Project page: https://adaptive-visual-tts.github.io/",
      "pdf_url": "https://arxiv.org/pdf/2602.08236v1",
      "published_date": "2026-02-09 03:21:48 UTC",
      "updated_date": "2026-02-09 03:21:48 UTC",
      "processing_status": "completed",
      "attempts": 1,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "llm_backup_calls": 0,
      "last_update": "2026-02-16T05:13:05.901767+00:00"
    },
    {
      "arxiv_id": "2602.09063v1",
      "title": "scBench: Evaluating AI Agents on Single-Cell RNA-seq Analysis",
      "title_zh": "scBench：单细胞 RNA 测序分析 AI 智能体评估基准",
      "authors": [
        "Kenny Workman",
        "Zhen Yang",
        "Harihara Muralidharan",
        "Aidan Abdulali",
        "Hannah Le"
      ],
      "abstract": "As single-cell RNA sequencing datasets grow in adoption, scale, and complexity, data analysis remains a bottleneck for many research groups. Although frontier AI agents have improved dramatically at software engineering and general data analysis, it remains unclear whether they can extract biological insight from messy, real-world single-cell datasets. We introduce scBench, a benchmark of 394 verifiable problems derived from practical scRNA-seq workflows spanning six sequencing platforms and seven task categories. Each problem provides a snapshot of experimental data immediately prior to an analysis step and a deterministic grader that evaluates recovery of a key biological result. Benchmark data on eight frontier models shows that accuracy ranges from 29-53%, with strong model-task and model-platform interactions. Platform choice affects accuracy as much as model choice, with 40+ percentage point drops on less-documented technologies. scBench complements SpatialBench to cover the two dominant single-cell modalities, serving both as a measurement tool and a diagnostic lens for developing agents that can analyze real scRNA-seq datasets faithfully and reproducibly.",
      "tldr_zh": "该研究引入了scBench，这是一个包含394个可验证问题的基准测试，旨在评估AI智能体(AI Agents)在单细胞RNA测序(scRNA-seq)分析中的表现。针对当前生物数据分析的瓶颈，scBench从跨越6个测序平台和7个任务类别的实际工作流程中提取问题，并配备了用于评估生物学结果恢复情况的确定性评分器。对8个前沿模型的测试结果显示，模型准确率仅在29%至53%之间，且表现受到测序平台选择的显著影响。研究发现模型在文档较少的测序技术上准确率下降超过40个百分点，凸显了领域知识缺口。作为SpatialBench的补充，scBench涵盖了单细胞研究的两大主流模态，为开发能够忠实且可重复地分析真实scRNA-seq数据集的智能体提供了关键的测量工具和诊断视角。",
      "categories": [
        "q-bio.GN",
        "cs.AI"
      ],
      "primary_category": "q-bio.GN",
      "comment": "",
      "pdf_url": "https://arxiv.org/pdf/2602.09063v1",
      "published_date": "2026-02-09 03:20:31 UTC",
      "updated_date": "2026-02-09 03:20:31 UTC",
      "processing_status": "completed",
      "attempts": 1,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "llm_backup_calls": 0,
      "last_update": "2026-02-16T05:13:09.205918+00:00"
    },
    {
      "arxiv_id": "2602.08235v1",
      "title": "When Benign Inputs Lead to Severe Harms: Eliciting Unsafe Unintended Behaviors of Computer-Use Agents",
      "title_zh": "良性输入引发的严重危害：诱发计算机使用智能体的不安全非预期行为",
      "authors": [
        "Jaylen Jones",
        "Zhehao Zhang",
        "Yuting Ning",
        "Eric Fosler-Lussier",
        "Pierre-Luc St-Charles",
        "Yoshua Bengio",
        "Dawn Song",
        "Yu Su",
        "Huan Sun"
      ],
      "abstract": "Although computer-use agents (CUAs) hold significant potential to automate increasingly complex OS workflows, they can demonstrate unsafe unintended behaviors that deviate from expected outcomes even under benign input contexts. However, exploration of this risk remains largely anecdotal, lacking concrete characterization and automated methods to proactively surface long-tail unintended behaviors under realistic CUA scenarios. To fill this gap, we introduce the first conceptual and methodological framework for unintended CUA behaviors, by defining their key characteristics, automatically eliciting them, and analyzing how they arise from benign inputs. We propose AutoElicit: an agentic framework that iteratively perturbs benign instructions using CUA execution feedback, and elicits severe harms while keeping perturbations realistic and benign. Using AutoElicit, we surface hundreds of harmful unintended behaviors from state-of-the-art CUAs such as Claude 4.5 Haiku and Opus. We further evaluate the transferability of human-verified successful perturbations, identifying persistent susceptibility to unintended behaviors across various other frontier CUAs. This work establishes a foundation for systematically analyzing unintended behaviors in realistic computer-use settings.",
      "tldr_zh": "该研究探讨了计算机使用智能体(CUAs)在良性输入下产生非预期不安全行为的风险，旨在解决该领域缺乏具体特征描述和自动发现方法的问题。作者提出了首个针对非预期CUA行为的理论框架，并开发了AutoElicit自动化框架，通过利用执行反馈对良性指令进行迭代微扰，在保持指令现实且良性的前提下诱发严重危害。实验使用AutoElicit在Claude 4.5 Haiku和Opus等先进智能体中发现了数百种有害行为，揭示了这些模型在执行任务时可能偏离预期的严重缺陷。研究还评估了人工验证后的微扰在不同模型间的迁移性，确认了多个前沿CUAs对非预期行为的普遍敏感性。该工作为在现实计算机使用场景中系统分析和防御智能体的非预期行为奠定了重要基础。",
      "categories": [
        "cs.CL",
        "cs.AI",
        "cs.CR"
      ],
      "primary_category": "cs.CL",
      "comment": "Project Homepage: https://osu-nlp-group.github.io/AutoElicit/",
      "pdf_url": "https://arxiv.org/pdf/2602.08235v1",
      "published_date": "2026-02-09 03:20:11 UTC",
      "updated_date": "2026-02-09 03:20:11 UTC",
      "processing_status": "completed",
      "attempts": 1,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "llm_backup_calls": 0,
      "last_update": "2026-02-16T05:13:37.705317+00:00"
    },
    {
      "arxiv_id": "2602.08233v1",
      "title": "Tutti: Expressive Multi-Singer Synthesis via Structure-Level Timbre Control and Vocal Texture Modeling",
      "title_zh": "Tutti：基于结构级音色控制与歌声纹理建模的表现力多歌手合成",
      "authors": [
        "Jiatao Chen",
        "Xing Tang",
        "Xiaoyue Duan",
        "Yutang Feng",
        "Jinchao Zhang",
        "Jie Zhou"
      ],
      "abstract": "While existing Singing Voice Synthesis systems achieve high-fidelity solo performances, they are constrained by global timbre control, failing to address dynamic multi-singer arrangement and vocal texture within a single song. To address this, we propose Tutti, a unified framework designed for structured multi-singer generation. Specifically, we introduce a Structure-Aware Singer Prompt to enable flexible singer scheduling evolving with musical structure, and propose Complementary Texture Learning via Condition-Guided VAE to capture implicit acoustic textures (e.g., spatial reverberation and spectral fusion) that are complementary to explicit controls. Experiments demonstrate that Tutti excels in precise multi-singer scheduling and significantly enhances the acoustic realism of choral generation, offering a novel paradigm for complex multi-singer arrangement. Audio samples are available at https://annoauth123-ctrl.github.io/Tutii_Demo/.",
      "tldr_zh": "该研究提出了Tutti，一个专为结构化多歌手生成设计的统一框架，旨在解决现有Singing Voice Synthesis系统受限于全局音色控制、难以处理动态多歌手编排和声乐纹理的问题。Tutti通过引入结构感知歌手提示(Structure-Aware Singer Prompt)，实现了随音乐结构演进的灵活歌手调度。同时，该框架利用基于Condition-Guided VAE的补充纹理学习(Complementary Texture Learning)技术，有效捕捉空间混响(spatial reverberation)和频谱融合(spectral fusion)等与显式控制互补的隐式声学纹理。实验证明，Tutti在精确的多歌手调度上表现卓越，并显著增强了合唱生成的声学真实感。该研究为复杂的多歌手编排提供了一种新范式，在提升音频合成的表达力和真实度方面具有重要意义。",
      "categories": [
        "cs.SD",
        "cs.AI"
      ],
      "primary_category": "cs.SD",
      "comment": "",
      "pdf_url": "https://arxiv.org/pdf/2602.08233v1",
      "published_date": "2026-02-09 03:15:44 UTC",
      "updated_date": "2026-02-09 03:15:44 UTC",
      "processing_status": "completed",
      "attempts": 1,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "llm_backup_calls": 0,
      "last_update": "2026-02-16T05:13:44.203866+00:00"
    },
    {
      "arxiv_id": "2602.08230v1",
      "title": "Generating Adversarial Events: A Motion-Aware Point Cloud Framework",
      "title_zh": "对抗性事件生成：一种运动感知点云框架",
      "authors": [
        "Hongwei Ren",
        "Youxin Jiang",
        "Qifei Gu",
        "Xiangqian Wu"
      ],
      "abstract": "Event cameras have been widely adopted in safety-critical domains such as autonomous driving, robotics, and human-computer interaction. A pressing challenge arises from the vulnerability of deep neural networks to adversarial examples, which poses a significant threat to the reliability of event-based systems. Nevertheless, research into adversarial attacks on events is scarce. This is primarily due to the non-differentiable nature of mainstream event representations, which hinders the extension of gradient-based attack methods. In this paper, we propose MA-ADV, a novel \\textbf{M}otion-\\textbf{A}ware \\textbf{Adv}ersarial framework. To the best of our knowledge, this is the first work to generate adversarial events by leveraging point cloud representations. MA-ADV accounts for high-frequency noise in events and employs a diffusion-based approach to smooth perturbations, while fully leveraging the spatial and temporal relationships among events. Finally, MA-ADV identifies the minimal-cost perturbation through a combination of sample-wise Adam optimization, iterative refinement, and binary search. Extensive experimental results validate that MA-ADV ensures a 100\\% attack success rate with minimal perturbation cost, and also demonstrate enhanced robustness against defenses, underscoring the critical security challenges facing future event-based perception systems.",
      "tldr_zh": "该研究针对事件相机(Event cameras)在安全关键领域面临的深度神经网络对抗性威胁，提出了名为MA-ADV的运动感知(Motion-Aware)对抗框架。作为首个利用点云(point cloud)表示生成对抗事件的工作，MA-ADV通过基于扩散(diffusion-based)的方法平滑扰动，并充分利用了事件间的空间和时间关系来应对高频噪声。该框架结合了Adam优化、迭代细化和二分搜索(binary search)，旨在寻找最小成本的扰动方案。实验结果显示，MA-ADV在保持极低扰动成本的同时实现了100%的攻击成功率，且对现有防御手段具有较强的鲁棒性。这一发现揭示了基于事件的感知系统在未来应用中必须面对的严峻安全挑战。",
      "categories": [
        "cs.CV",
        "cs.AI"
      ],
      "primary_category": "cs.CV",
      "comment": "",
      "pdf_url": "https://arxiv.org/pdf/2602.08230v1",
      "published_date": "2026-02-09 03:06:07 UTC",
      "updated_date": "2026-02-09 03:06:07 UTC",
      "processing_status": "completed",
      "attempts": 1,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "llm_backup_calls": 0,
      "last_update": "2026-02-16T05:13:51.506407+00:00"
    },
    {
      "arxiv_id": "2602.08229v1",
      "title": "InfiCoEvalChain: A Blockchain-Based Decentralized Framework for Collaborative LLM Evaluation",
      "title_zh": "InfiCoEvalChain：基于区块链的大语言模型协作评估去中心化框架",
      "authors": [
        "Yifan Yang",
        "Jinjia Li",
        "Kunxi Li",
        "Puhao Zheng",
        "Yuanyi Wang",
        "Zheyan Qu",
        "Yang Yu",
        "Jianmin Wu",
        "Ming Li",
        "Hongxia Yang"
      ],
      "abstract": "The rapid advancement of large language models (LLMs) demands increasingly reliable evaluation, yet current centralized evaluation suffers from opacity, overfitting, and hardware-induced variance. Our empirical analysis reveals an alarming inconsistency in existing evaluations: the standard deviation across ten repeated runs of a single model on HumanEval (1.67) actually exceeds the performance gap among the top-10 models on the official leaderboard (0.91), rendering current rankings statistically precarious. To mitigate these instabilities, we propose a decentralized evaluation framework that enables hardware and parameter diversity through large-scale benchmarking across heterogeneous compute nodes. By leveraging the blockchain-based protocol, the framework incentivizes global contributors to act as independent validators, using a robust reward system to ensure evaluation integrity and discourage dishonest participation. This collective verification transforms evaluation from a \"centralized black box\" into a \"decentralized endorsement\" where multi-party consensus and diverse inference environments yield a more stable, representative metric. Experimental results demonstrate that the decentralized evaluation framework reduces the standard deviation across ten runs on the same model to 0.28. This significant improvement over conventional frameworks ensures higher statistical confidence in model rankings. We have completely implemented this platform and will soon release it to the community.",
      "tldr_zh": "该研究提出了 InfiCoEvalChain，这是一个基于区块链的去中心化协作大语言模型（LLM）评估框架，旨在解决现有中心化评估中存在的透明度低、过拟合以及硬件引发的评估差异等问题。研究通过实证分析指出，现有评估在同一模型上的重复实验标准差甚至超过了排行榜前十名之间的性能差距，导致排名在统计学上并不可靠。该框架利用区块链协议激励全球贡献者作为独立验证节点，通过在异构计算节点上进行大规模基准测试，实现了硬件和参数的多样性。通过建立稳健的奖励机制和多方共识验证，该系统将评估过程从“中心化黑盒”转变为“去中心化背书”，显著增强了评估的诚信度。实验结果显示，InfiCoEvalChain 将同一模型的评估标准差从 1.67 降低至 0.28，大幅提升了模型排名的统计置信度。",
      "categories": [
        "cs.AI",
        "cs.CR",
        "cs.LG"
      ],
      "primary_category": "cs.AI",
      "comment": "",
      "pdf_url": "https://arxiv.org/pdf/2602.08229v1",
      "published_date": "2026-02-09 03:05:00 UTC",
      "updated_date": "2026-02-09 03:05:00 UTC",
      "processing_status": "completed",
      "attempts": 1,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "llm_backup_calls": 0,
      "last_update": "2026-02-16T05:13:53.597506+00:00"
    },
    {
      "arxiv_id": "2602.08227v1",
      "title": "Investigating Writing Professionals' Relationships with Generative AI: How Combined Perceptions of Rivalry and Collaboration Shape Work Practices and Outcomes",
      "title_zh": "探究专业写作人员与生成式人工智能的关系：竞争与协作的共生认知如何重塑工作实践与成果",
      "authors": [
        "Rama Adithya",
        "Varanasi",
        "Nov",
        "Oded",
        "Wiesenfeld",
        "Batia Mishan"
      ],
      "abstract": "This study investigates how professional writers' complex relationship with GenAI shapes their work practices and outcomes. Through a cross-sectional survey with writing professionals (n=403) in diverse roles, we show that collaboration and rivalry orientation are associated with differences in work practices and outcomes. Rivalry is primarily associated with relational crafting and skill maintenance. Collaboration is primarily associated with task crafting, productivity, and satisfaction, at the cost of long-term skill deterioration. Combination of the orientations (high rivalry and high collaboration) reconciles these differences, while boosting the association with the outcomes. Our findings argue for a balanced approach where high levels of rivalry and collaboration are essential to shape work practices and generate outcomes aimed at the long-term success of the job. We present key design implications on how to increase friction (rivalry) and reduce over-reliance (collaboration) to achieve a more balanced relationship with GenAI.",
      "tldr_zh": "这项研究通过对403名从事不同角色的专业写作人员进行横断面调查(cross-sectional survey)，探讨了他们与生成式人工智能(GenAI)之间竞争与协作的复杂关系如何影响工作实践和产出。研究发现，竞争取向(Rivalry)主要与关系塑造(relational crafting)和技能维护(skill maintenance)相关，而协作取向(Collaboration)则与任务塑造(task crafting)、生产力和满意度的提高相关，但代价是长期的技能退化。当这两种取向结合（高竞争且高协作）时，可以调和上述差异并进一步增强与工作结果的关联。研究结果表明，维持高水平的竞争感与协作感对于塑造工作实践和实现职业长期成功至关重要。最后，研究针对如何通过设计增加摩擦（竞争）和减少过度依赖（协作）提出了建议，旨在构建与GenAI更平衡的人机关系。",
      "categories": [
        "cs.HC",
        "cs.AI"
      ],
      "primary_category": "cs.HC",
      "comment": "CHI'2026",
      "pdf_url": "https://arxiv.org/pdf/2602.08227v1",
      "published_date": "2026-02-09 03:01:21 UTC",
      "updated_date": "2026-02-09 03:01:21 UTC",
      "processing_status": "completed",
      "attempts": 1,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "llm_backup_calls": 0,
      "last_update": "2026-02-16T05:13:59.809518+00:00"
    },
    {
      "arxiv_id": "2602.08222v1",
      "title": "Weak-Driven Learning: How Weak Agents make Strong Agents Stronger",
      "title_zh": "弱驱动学习：弱智能体如何让强智能体更强",
      "authors": [
        "Zehao Chen",
        "Gongxun Li",
        "Tianxiang Ai",
        "Yifei Li",
        "Zixuan Huang",
        "Wang Zhou",
        "Fuzhen Zhuang",
        "Xianglong Liu",
        "Jianxin Li",
        "Deqing Wang",
        "Yikun Ban"
      ],
      "abstract": "As post-training optimization becomes central to improving large language models, we observe a persistent saturation bottleneck: once models grow highly confident, further training yields diminishing returns. While existing methods continue to reinforce target predictions, we find that informative supervision signals remain latent in models' own historical weak states. Motivated by this observation, we propose WMSS (Weak Agents Can Make Strong Agents Stronger), a post-training paradigm that leverages weak checkpoints to guide continued optimization. By identifying recoverable learning gaps via entropy dynamics and reinforcing them through compensatory learning, WMSS enables strong agents to improve beyond conventional post-training saturation. Experiments on mathematical reasoning and code generation datasets show that agents trained with our approach achieve effective performance improvements, while incurring zero additional inference cost.",
      "tldr_zh": "该研究探讨了大型语言模型在后期训练优化中面临的饱和瓶颈问题，即模型高度自信后进一步训练收益递减的现象。作者发现，在模型的历史弱状态 (weak states) 中仍潜藏着具有信息量的监督信号，据此提出了 WMSS (Weak Agents Can Make Strong Agents Stronger) 训练范式。该范式利用弱检查点 (weak checkpoints) 来引导持续优化，通过熵动力学 (entropy dynamics) 识别可恢复的学习差距 (recoverable learning gaps) 并进行补偿性学习 (compensatory learning)。实验结果显示，WMSS 能使强智能体突破传统的后期训练饱和限制，在数学推理和代码生成任务上实现显著的性能增长。此外，该方法在提升模型能力的同时，不会产生任何额外的推理成本 (inference cost)。",
      "categories": [
        "cs.AI"
      ],
      "primary_category": "cs.AI",
      "comment": "",
      "pdf_url": "https://arxiv.org/pdf/2602.08222v1",
      "published_date": "2026-02-09 02:50:40 UTC",
      "updated_date": "2026-02-09 02:50:40 UTC",
      "processing_status": "completed",
      "attempts": 1,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "llm_backup_calls": 0,
      "last_update": "2026-02-16T05:14:28.210607+00:00"
    },
    {
      "arxiv_id": "2602.08221v1",
      "title": "CoRect: Context-Aware Logit Contrast for Hidden State Rectification to Resolve Knowledge Conflicts",
      "title_zh": "CoRect：面向知识冲突解决的上下文感知 Logit 对比与隐状态校正",
      "authors": [
        "Xuhua Ma",
        "Richong Zhang",
        "Zhijie Nie"
      ],
      "abstract": "Retrieval-Augmented Generation (RAG) often struggles with knowledge conflicts, where model-internal parametric knowledge overrides retrieved evidence, leading to unfaithful outputs. Existing approaches are often limited, relying either on superficial decoding adjustments or weight editing that necessitates ground-truth targets. Through layer-wise analysis, we attribute this failure to a parametric suppression phenomenon: specifically, in deep layers, certain FFN layers overwrite context-sensitive representations with memorized priors. To address this, we propose CoRect (Context-Aware Logit Contrast for Hidden State Rectification). By contrasting logits from contextualized and non-contextualized forward passes, CoRect identifies layers that exhibit high parametric bias without requiring ground-truth labels. It then rectifies the hidden states to preserve evidence-grounded information. Across question answering (QA) and summarization benchmarks, CoRect consistently improves faithfulness and reduces hallucinations compared to strong baselines.",
      "tldr_zh": "该研究针对检索增强生成(RAG)中模型内部参数知识覆盖检索证据导致的知识冲突问题，提出了CoRect框架。通过层级分析，作者发现深层FFN层存在参数抑制(parametric suppression)现象，即记忆的先验知识会覆盖上下文敏感的表示。为此，CoRect通过对比上下文和非上下文前向传递的Logit，在无需真实标签的情况下识别出具有高参数偏置的层。该方法随后通过纠正隐藏状态(hidden states)来保留基于证据的信息，确保输出的准确性。在问答(QA)和摘要生成基准测试中，CoRect一致地提升了模型的忠实度并减少了幻觉。这一方案为解决大语言模型在知识冲突场景下的不可信输出提供了一种有效的隐藏状态纠正途径。",
      "categories": [
        "cs.CL",
        "cs.AI"
      ],
      "primary_category": "cs.CL",
      "comment": "",
      "pdf_url": "https://arxiv.org/pdf/2602.08221v1",
      "published_date": "2026-02-09 02:49:21 UTC",
      "updated_date": "2026-02-09 02:49:21 UTC",
      "processing_status": "completed",
      "attempts": 1,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "llm_backup_calls": 0,
      "last_update": "2026-02-16T05:14:38.604233+00:00"
    },
    {
      "arxiv_id": "2602.08218v1",
      "title": "Sparsity-Aware Evolution for Model Merging",
      "title_zh": "面向模型合并的稀疏感知演化",
      "authors": [
        "Huan Zhang",
        "Yanjian Zhang",
        "Guillaume Wisniewski",
        "Nadi Tomeh",
        "Bang Liu"
      ],
      "abstract": "We propose a sparsity-aware evolutionary (SAE) framework for model merging that involves iterative pruning-merging cycles to act as a novel mutation operator. We incorporate the sparsity constraints into the score function, which steers the evolutionary process to favor more sparse models, in addition to other conventional performance scores. Interestingly, the by-product of \\textit{competition} for sparsity introduces an extra local \\textit{attraction} and interplay into the evolutionary process: if one competitor has more zero elements, the other competitor's non-zero elements will occupy those positions, even though the less sparse competitor loses to the more sparse competitor in other positions. The proposed pipeline is evaluated on a variety of large-scale LLM benchmarks. Experiments demonstrate that our approach can improve model merging reliability across multiple benchmarks, and is easy to incorporate due to its simplicity and being orthogonal to most existing approaches.",
      "tldr_zh": "该研究提出了稀疏感知进化(Sparsity-Aware Evolution, SAE)框架，通过迭代的剪枝-合并周期作为新型变异算子来优化模型合并(Model Merging)。该框架将稀疏性约束引入评分函数，引导进化过程在维持性能的同时偏好更稀疏的模型。研究发现，对稀疏性的竞争在进化过程中引入了额外的局部吸引力和相互作用，使得不同竞争者的非零元素能够有效互补。在多种大规模大语言模型(LLM)基准测试中的实验结果表明，该方法不仅提高了模型合并的可靠性，且因其简单性及与现有方法的正交性，极易集成到现有工作流中。该方法为构建高效、轻量化且性能强大的合并模型提供了新的演化路径。",
      "categories": [
        "cs.LG",
        "cs.AI"
      ],
      "primary_category": "cs.LG",
      "comment": "",
      "pdf_url": "https://arxiv.org/pdf/2602.08218v1",
      "published_date": "2026-02-09 02:43:38 UTC",
      "updated_date": "2026-02-09 02:43:38 UTC",
      "processing_status": "completed",
      "attempts": 1,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "llm_backup_calls": 0,
      "last_update": "2026-02-16T05:14:34.907246+00:00"
    },
    {
      "arxiv_id": "2602.08214v1",
      "title": "RECUR: Resource Exhaustion Attack via Recursive-Entropy Guided Counterfactual Utilization and Reflection",
      "title_zh": "RECUR：基于递归熵引导的反事实利用与反思的资源耗竭攻击",
      "authors": [
        "Ziwei Wang",
        "Yuanhe Zhang",
        "Jing Chen",
        "Zhenhong Zhou",
        "Ruichao Liang",
        "Ruiying Du",
        "Ju Jia",
        "Cong Wu",
        "Yang Liu"
      ],
      "abstract": "Large Reasoning Models (LRMs) employ reasoning to address complex tasks. Such explicit reasoning requires extended context lengths, resulting in substantially higher resource consumption. Prior work has shown that adversarially crafted inputs can trigger redundant reasoning processes, exposing LRMs to resource-exhaustion vulnerabilities. However, the reasoning process itself, especially its reflective component, has received limited attention, even though it can lead to over-reflection and consume excessive computing power. In this paper, we introduce Recursive Entropy to quantify the risk of resource consumption in reflection, thereby revealing the safety issues inherent in inference itself. Based on Recursive Entropy, we introduce RECUR, a resource exhaustion attack via Recursive Entropy guided Counterfactual Utilization and Reflection. It constructs counterfactual questions to verify the inherent flaws and risks of LRMs. Extensive experiments demonstrate that, under benign inference, recursive entropy exhibits a pronounced decreasing trend. RECUR disrupts this trend, increasing the output length by up to 11x and decreasing throughput by 90%. Our work provides a new perspective on robust reasoning.",
      "tldr_zh": "该研究探讨了大型推理模型(Large Reasoning Models, LRMs)在显式推理过程中由于过度反思(over-reflection)导致的资源消耗漏洞。作者提出了递归熵(Recursive Entropy)概念，用于量化模型在反思过程中的资源消耗风险，从而揭示了推理过程本身固有的安全性挑战。基于递归熵，该研究引入了名为RECUR的资源耗尽攻击框架，通过构建反事实问题(counterfactual questions)引导模型进行冗余的递归反思。实验结果表明，RECUR能够显著破坏良性推理中的熵减趋势，将模型输出长度增加至11倍，并使系统吞吐量降低90%。该工作通过揭示LRMs在反思机制上的缺陷，为构建更加稳健、鲁棒的推理系统提供了全新的视角。",
      "categories": [
        "cs.AI",
        "cs.CR"
      ],
      "primary_category": "cs.AI",
      "comment": "",
      "pdf_url": "https://arxiv.org/pdf/2602.08214v1",
      "published_date": "2026-02-09 02:27:17 UTC",
      "updated_date": "2026-02-09 02:27:17 UTC",
      "processing_status": "completed",
      "attempts": 1,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "llm_backup_calls": 0,
      "last_update": "2026-02-16T05:14:41.897443+00:00"
    },
    {
      "arxiv_id": "2602.08213v1",
      "title": "DrugR: Optimizing Molecular Drugs through LLM-based Explicit Reasoning",
      "title_zh": "DrugR：基于大语言模型显式推理的分子药物优化",
      "authors": [
        "Haoran Liu",
        "Zheni Zeng",
        "Yukun Yan",
        "Yuxuan Chen",
        "Yunduo Xiao"
      ],
      "abstract": "Molecule generation and optimization is a fundamental task in chemical domain. The rapid development of intelligent tools, especially large language models (LLMs) with powerful knowledge reserves and interactive capabilities, has provided new paradigms for it. Nevertheless, the intrinsic challenge for LLMs lies in the complex implicit relationship between molecular structure and pharmacological properties and the lack of corresponding labeled data. To bridge this gap, we propose DrugR, an LLM-based method that introduces explicit, step-by-step pharmacological reasoning into the optimization process. Our approach integrates domain-specific continual pretraining, supervised fine-tuning via reverse data engineering, and self-balanced multi-granular reinforcement learning. This framework enables DrugR to effectively improve key ADMET properties while preserving the original molecule's core efficacy. Experimental results demonstrate that DrugR achieves comprehensive enhancement across multiple properties without compromising structural similarity or target binding affinity. Importantly, its explicit reasoning process provides clear, interpretable rationales for each optimization step, yielding actionable design insights and advancing toward automated, knowledge-driven scientific discovery. Our code and model checkpoints are open-sourced to foster future research.",
      "tldr_zh": "该研究提出了DrugR，一种基于大语言模型(LLMs)的新型分子药物优化方法，旨在解决模型在理解分子结构与药理属性间复杂隐性关系时面临的挑战。DrugR通过引入显式、步进式的药理推理过程，结合领域特定的持续预训练(Continual Pretraining)、基于逆向数据工程的监督微调以及自平衡多粒度强化学习，实现了对分子性质的精确调优。实验结果表明，该框架在显著改善关键ADMET属性的同时，能够有效保持原始分子的核心药效、结构相似性和靶点结合亲和力。最重要的是，其显式推理过程为每一步优化提供了清晰且具有可解释性的依据，为自动化、知识驱动的药物设计提供了极具价值的洞察和研究基础。",
      "categories": [
        "cs.LG",
        "cs.AI",
        "cs.CL",
        "q-bio.QM"
      ],
      "primary_category": "cs.LG",
      "comment": "",
      "pdf_url": "https://arxiv.org/pdf/2602.08213v1",
      "published_date": "2026-02-09 02:26:25 UTC",
      "updated_date": "2026-02-09 02:26:25 UTC",
      "processing_status": "completed",
      "attempts": 1,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "llm_backup_calls": 0,
      "last_update": "2026-02-16T05:14:46.202404+00:00"
    },
    {
      "arxiv_id": "2602.08194v1",
      "title": "Dreaming in Code for Curriculum Learning in Open-Ended Worlds",
      "title_zh": "Dreaming in Code：面向开放式世界课程学习的代码梦构",
      "authors": [
        "Konstantinos Mitsides",
        "Maxence Faldor",
        "Antoine Cully"
      ],
      "abstract": "Open-ended learning frames intelligence as emerging from continual interaction with an ever-expanding space of environments. While recent advances have utilized foundation models to programmatically generate diverse environments, these approaches often focus on discovering isolated behaviors rather than orchestrating sustained progression. In complex open-ended worlds, the large combinatorial space of possible challenges makes it difficult for agents to discover sequences of experiences that remain consistently learnable. To address this, we propose Dreaming in Code (DiCode), a framework in which foundation models synthesize executable environment code to scaffold learning toward increasing competence. In DiCode, \"dreaming\" takes the form of materializing code-level variations of the world. We instantiate DiCode in Craftax, a challenging open-ended benchmark characterized by rich mechanics and long-horizon progression. Empirically, DiCode enables agents to acquire long-horizon skills, achieving a $16\\%$ improvement in mean return over the strongest baseline and non-zero success on late-game combat tasks where prior methods fail. Our results suggest that code-level environment design provides a practical mechanism for curriculum control, enabling the construction of intermediate environments that bridge competence gaps in open-ended worlds. Project page and source code are available at https://konstantinosmitsides.github.io/dreaming-in-code and https://github.com/konstantinosmitsides/dreaming-in-code.",
      "tldr_zh": "该研究提出了Dreaming in Code (DiCode)框架，旨在解决在Open-Ended Worlds中智能体难以在庞大组合空间内发现持续可学习经验序列的问题。DiCode利用Foundation Models合成可执行的环境代码来构建Curriculum Learning路径，通过“Dreaming”即生成代码层面的环境变体来为智能体提供进阶式的学习支撑。研究者在具有复杂机制和Long-Horizon特性的Craftax基准上对该框架进行了验证。实验结果表明，DiCode显著提升了智能体获取长程技能的能力，其Mean Return较最强基线模型提高了16%，并在以往方法完全失效的后期战斗任务中取得了突破。这一成果证明了代码层面的环境设计是实现Curriculum Control的有效机制，能够通过构建中间环境来有效弥合开放世界中的能力鸿沟。",
      "categories": [
        "cs.LG",
        "cs.AI",
        "cs.CL"
      ],
      "primary_category": "cs.LG",
      "comment": "11 pages (main text), 90 pages total. Project page: https://konstantinosmitsides.github.io/dreaming-in-code",
      "pdf_url": "https://arxiv.org/pdf/2602.08194v1",
      "published_date": "2026-02-09 01:24:40 UTC",
      "updated_date": "2026-02-09 01:24:40 UTC",
      "processing_status": "completed",
      "attempts": 1,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "llm_backup_calls": 0,
      "last_update": "2026-02-16T05:15:20.802120+00:00"
    },
    {
      "arxiv_id": "2602.08187v1",
      "title": "Large Language Models in Peer-Run Community Behavioral Health Services: Understanding Peer Specialists and Service Users' Perspectives on Opportunities, Risks, and Mitigation Strategies",
      "title_zh": "大语言模型在同伴运营的社区行为健康服务中的应用：探究同伴专家与服务用户对机遇、风险及缓解策略的视角",
      "authors": [
        "Cindy Peng",
        "Megan Chai",
        "Gao Mo",
        "Naveen Raman",
        "Ningjing Tang",
        "Shannon Pagdon",
        "Margaret Swarbrick",
        "Nev Jones",
        "Fei Fang",
        "Hong Shen"
      ],
      "abstract": "Peer-run organizations (PROs) provide critical, recovery-based behavioral health support rooted in lived experience. As large language models (LLMs) enter this domain, their scale, conversationality, and opacity introduce new challenges for situatedness, trust, and autonomy. Partnering with Collaborative Support Programs of New Jersey (CSPNJ), a statewide PRO in the Northeastern United States, we used comicboarding, a co-design method, to conduct workshops with 16 peer specialists and 10 service users exploring perceptions of integrating an LLM-based recommendation system into peer support. Findings show that depending on how LLMs are introduced, constrained, and co-used, they can reconfigure in-room dynamics by sustaining, undermining, or amplifying the relational authority that grounds peer support. We identify opportunities, risks, and mitigation strategies across three tensions: bridging scale and locality, protecting trust and relational dynamics, and preserving peer autonomy amid efficiency gains. We contribute design implications that center lived-experience-in-the-loop, reframe trust as co-constructed, and position LLMs not as clinical tools but as relational collaborators in high-stakes, community-led care.",
      "tldr_zh": "该研究探讨了大语言模型 (Large Language Models, LLMs) 在同伴运营机构 (Peer-run organizations, PROs) 社区行为健康服务中的应用前景，通过与 CSPNJ 合作并采用漫画板 (comicboarding) 协同设计方法，调研了同伴专家和服务使用者对 LLM 推荐系统的看法。研究发现，LLMs 的整合方式会通过维持、削弱或放大同伴支持中的关系权威，从而改变服务现场的动态。研究识别了弥合规模化与本土化、保护信任与关系动态、以及在效率提升中保留同伴自主权这三个核心张力。最终，该研究提出了以“活生生的经验在环”(lived-experience-in-the-loop) 为中心的设计启示，主张将信任视为共建产物，并将 LLMs 定位为高风险社区主导护理中的关系合作者而非单纯的临床工具。",
      "categories": [
        "cs.HC",
        "cs.AI"
      ],
      "primary_category": "cs.HC",
      "comment": "24 pages, 2 tables, 7 figures. Accepted and to appear in the Proceedings of CHI 2026",
      "pdf_url": "https://arxiv.org/pdf/2602.08187v1",
      "published_date": "2026-02-09 01:12:49 UTC",
      "updated_date": "2026-02-09 01:12:49 UTC",
      "processing_status": "completed",
      "attempts": 1,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "llm_backup_calls": 0,
      "last_update": "2026-02-16T05:15:28.204117+00:00"
    },
    {
      "arxiv_id": "2602.08186v1",
      "title": "Nexus: Inferring Join Graphs from Metadata Alone via Iterative Low-Rank Matrix Completion",
      "title_zh": "Nexus：仅利用元数据，通过迭代低秩矩阵补全推断连接图",
      "authors": [
        "Tianji Cong",
        "Yuanyuan Tian",
        "Andreas Mueller",
        "Rathijit Sen",
        "Yeye He",
        "Fotis Psallidas",
        "Shaleen Deep",
        "H. V. Jagadish"
      ],
      "abstract": "Automatically inferring join relationships is a critical task for effective data discovery, integration, querying and reuse. However, accurately and efficiently identifying these relationships in large and complex schemas can be challenging, especially in enterprise settings where access to data values is constrained. In this paper, we introduce the problem of join graph inference when only metadata is available. We conduct an empirical study on a large number of real-world schemas and observe that join graphs when represented as adjacency matrices exhibit two key properties: high sparsity and low-rank structure. Based on these novel observations, we formulate join graph inference as a low-rank matrix completion problem and propose Nexus, an end-to-end solution using only metadata. To further enhance accuracy, we propose a novel Expectation-Maximization algorithm that alternates between low-rank matrix completion and refining join candidate probabilities by leveraging Large Language Models. Our extensive experiments demonstrate that Nexus outperforms existing methods by a significant margin on four datasets including a real-world production dataset. Additionally, Nexus can operate in a fast mode, providing comparable results with up to 6x speedup, offering a practical and efficient solution for real-world deployments.",
      "tldr_zh": "该研究探讨了在仅有元数据(metadata)可用的情况下，如何自动推断大规模复杂模式中的连接关系(join relationships)，旨在解决因数据访问受限带来的集成与查询难题。作者通过实证研究发现，以邻接矩阵表示的连接图(join graphs)具有高稀疏性和低秩结构(low-rank structure)两个核心特性。基于此，研究提出了Nexus框架，将连接图推断建模为低秩矩阵补全(low-rank matrix completion)问题，并引入了一种新颖的期望最大化(Expectation-Maximization)算法。该算法通过在大语言模型(LLMs)辅助下的概率细化与矩阵补全之间进行迭代，有效提升了关系识别的精度。实验结果表明，Nexus在包括真实生产环境在内的四个数据集上均显著优于现有方法。此外，Nexus还支持快速模式，可在保持竞争力的前提下提供高达6倍的加速，为实际大规模部署提供了实用且高效的解决方案。",
      "categories": [
        "cs.DB",
        "cs.AI"
      ],
      "primary_category": "cs.DB",
      "comment": "",
      "pdf_url": "https://arxiv.org/pdf/2602.08186v1",
      "published_date": "2026-02-09 01:11:37 UTC",
      "updated_date": "2026-02-09 01:11:37 UTC",
      "processing_status": "completed",
      "attempts": 1,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "llm_backup_calls": 0,
      "last_update": "2026-02-16T05:15:32.602657+00:00"
    },
    {
      "arxiv_id": "2602.08167v1",
      "title": "Self-Supervised Bootstrapping of Action-Predictive Embodied Reasoning",
      "title_zh": "动作预测型具身推理的自监督自举",
      "authors": [
        "Milan Ganai",
        "Katie Luo",
        "Jonas Frey",
        "Clark Barrett",
        "Marco Pavone"
      ],
      "abstract": "Embodied Chain-of-Thought (CoT) reasoning has significantly enhanced Vision-Language-Action (VLA) models, yet current methods rely on rigid templates to specify reasoning primitives (e.g., objects in the scene, high-level plans, structural affordances). These templates can force policies to process irrelevant information that distracts from critical action-prediction signals. This creates a bottleneck: without successful policies, we cannot verify reasoning quality; without quality reasoning, we cannot build robust policies. We introduce R&B-EnCoRe, which enables models to bootstrap embodied reasoning from internet-scale knowledge through self-supervised refinement. By treating reasoning as a latent variable within importance-weighted variational inference, models can generate and distill a refined reasoning training dataset of embodiment-specific strategies without external rewards, verifiers, or human annotation. We validate R&B-EnCoRe across manipulation (Franka Panda in simulation, WidowX in hardware), legged navigation (bipedal, wheeled, bicycle, quadruped), and autonomous driving embodiments using various VLA architectures with 1B, 4B, 7B, and 30B parameters. Our approach achieves 28% gains in manipulation success, 101% improvement in navigation scores, and 21% reduction in collision-rate metric over models that indiscriminately reason about all available primitives. R&B-EnCoRe enables models to distill reasoning that is predictive of successful control, bypassing manual annotation engineering while grounding internet-scale knowledge in physical execution.",
      "tldr_zh": "该研究提出了R&B-EnCoRe，旨在解决具身链式思维(Embodied Chain-of-Thought)在视觉-语言-动作(VLA)模型中因依赖僵化模板而引入无关干扰信息的问题。通过将推理过程视为重要性权重变分推理(importance-weighted variational inference)中的隐变量，该框架实现了从互联网规模知识中自我监督地提炼特定实体的推理策略。R&B-EnCoRe无需外部奖励、验证器或人工标注，即可蒸馏出能够有效预测成功控制动作的推理数据集。实验涵盖了机械臂操作、足式导航及自动驾驶等多种任务，在1B至30B参数规模的模型上均验证了其有效性。结果显示，该方法使导航得分提升了101%，碰撞率降低了21%，操作成功率提高28%，成功将大规模先验知识锚定在物理执行中。",
      "categories": [
        "cs.RO",
        "cs.AI",
        "cs.CV",
        "cs.LG"
      ],
      "primary_category": "cs.RO",
      "comment": "",
      "pdf_url": "https://arxiv.org/pdf/2602.08167v1",
      "published_date": "2026-02-09 00:10:17 UTC",
      "updated_date": "2026-02-09 00:10:17 UTC",
      "processing_status": "completed",
      "attempts": 1,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "llm_backup_calls": 0,
      "last_update": "2026-02-16T05:15:36.696685+00:00"
    },
    {
      "arxiv_id": "2602.08159v1",
      "title": "The Confidence Manifold: Geometric Structure of Correctness Representations in Language Models",
      "title_zh": "置信流形：语言模型正确性表征的几何结构",
      "authors": [
        "Seonglae Cho",
        "Zekun Wu",
        "Kleyton Da Costa",
        "Adriano Koshiyama"
      ],
      "abstract": "When a language model asserts that \"the capital of Australia is Sydney,\" does it know this is wrong? We characterize the geometry of correctness representations across 9 models from 5 architecture families. The structure is simple: the discriminative signal occupies 3-8 dimensions, performance degrades with additional dimensions, and no nonlinear classifier improves over linear separation. Centroid distance in the low-dimensional subspace matches trained probe performance (0.90 AUC), enabling few-shot detection: on GPT-2, 25 labeled examples achieve 89% of full-data accuracy. We validate causally through activation steering: the learned direction produces 10.9 percentage point changes in error rates while random directions show no effect. Internal probes achieve 0.80-0.97 AUC; output-based methods (P(True), semantic entropy) achieve only 0.44-0.64 AUC. The correctness signal exists internally but is not expressed in outputs. That centroid distance matches probe performance indicates class separation is a mean shift, making detection geometric rather than learned.",
      "tldr_zh": "该研究探讨了语言模型内部正确性表征的几何结构，跨5个架构家族分析了9个模型。研究发现判别性信号仅占据3-8个维度，且线性分类器的表现优于非线性分类器，表明其结构具有简单的几何特性。利用低维子空间中的质心距离(Centroid distance)可以实现高效的少样本(Few-shot)检测，在GPT-2上仅需25个标注示例即可达到全量数据准确率的89%。实验对比显示，内部探针(Internal probes)的AUC表现（0.80-0.97）远优于语义熵(Semantic entropy)等基于输出的方法。通过激活转向(Activation steering)进行的因果验证进一步证实，沿特定方向调整激活值能显著改变模型的错误率。研究结果表明正确性信号客观存在于模型内部而非输出中，且类间分离表现为均值偏移(Mean shift)，这使得正确性检测本质上成为一个几何问题。",
      "categories": [
        "cs.LG",
        "cs.AI",
        "cs.CL"
      ],
      "primary_category": "cs.LG",
      "comment": "",
      "pdf_url": "https://arxiv.org/pdf/2602.08159v1",
      "published_date": "2026-02-08 23:27:10 UTC",
      "updated_date": "2026-02-08 23:27:10 UTC",
      "processing_status": "completed",
      "attempts": 1,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "llm_backup_calls": 0,
      "last_update": "2026-02-16T05:15:41.707201+00:00"
    },
    {
      "arxiv_id": "2602.08149v1",
      "title": "DIAL-SUMMER: A Structured Evaluation Framework of Hierarchical Errors in Dialogue Summaries",
      "title_zh": "DIAL-SUMMER：对话摘要层级化错误的结构化评估框架",
      "authors": [
        "Sahana Ramnath",
        "Nima Chitsazan",
        "Mingyang Zhou",
        "Chia-Hsuan Lee",
        "Shi-Xiong Zhang",
        "Stephen Rawls",
        "Sambit Sahu",
        "Sangwoo Cho",
        "Xiang Ren",
        "Genta Indra Winata",
        "Akshaj Kumar Veldanda"
      ],
      "abstract": "Dialogues are a predominant mode of communication for humans, and it is immensely helpful to have automatically generated summaries of them (e.g., to revise key points discussed in a meeting, to review conversations between customer agents and product users). Prior works on dialogue summary evaluation largely ignore the complexities specific to this task: (i) shift in structure, from multiple speakers discussing information in a scattered fashion across several turns, to a summary's sentences, and (ii) shift in narration viewpoint, from speakers' first/second-person narration, standardized third-person narration in the summary. In this work, we introduce our framework DIALSUMMER to address the above. We propose DIAL-SUMMER's taxonomy of errors to comprehensively evaluate dialogue summaries at two hierarchical levels: DIALOGUE-LEVEL that focuses on the broader speakers/turns, and WITHIN-TURN-LEVEL that focuses on the information talked about inside a turn. We then present DIAL-SUMMER's dataset composed of dialogue summaries manually annotated with our taxonomy's fine-grained errors. We conduct empirical analyses of these annotated errors, and observe interesting trends (e.g., turns occurring in middle of the dialogue are the most frequently missed in the summary, extrinsic hallucinations largely occur at the end of the summary). We also conduct experiments on LLM-Judges' capability at detecting these errors, through which we demonstrate the challenging nature of our dataset, the robustness of our taxonomy, and the need for future work in this field to enhance LLMs' performance in the same. Code and inference dataset coming soon.",
      "tldr_zh": "该研究提出了 DIAL-SUMMER 框架，旨在解决现有对话摘要评估方法中忽略了对话结构复杂性及叙事视角转换的问题。DIAL-SUMMER 引入了一种分层的错误分类体系，分别从侧重发言者和轮次关系的 DIALOGUE-LEVEL 以及侧重轮次内部信息的 WITHIN-TURN-LEVEL 对摘要进行评估。研究团队通过手动标注构建了一个细粒度错误数据集，并发现对话中间位置的轮次最常被摘要遗漏，而外部幻觉 (extrinsic hallucinations) 则多见于摘要末尾。实验结果表明，当前的大语言模型判别器 (LLM-Judges) 在检测这些细粒度错误方面表现仍显不足，反映了该数据集的挑战性。这一工作为提升对话摘要评估的准确性提供了新标准，并指明了未来在该领域提升模型性能的必要性。",
      "categories": [
        "cs.CL",
        "cs.AI"
      ],
      "primary_category": "cs.CL",
      "comment": "",
      "pdf_url": "https://arxiv.org/pdf/2602.08149v1",
      "published_date": "2026-02-08 22:46:22 UTC",
      "updated_date": "2026-02-08 22:46:22 UTC",
      "processing_status": "completed",
      "attempts": 1,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "llm_backup_calls": 0,
      "last_update": "2026-02-16T05:16:05.097987+00:00"
    },
    {
      "arxiv_id": "2602.08136v1",
      "title": "Robustness of Vision Language Models Against Split-Image Harmful Input Attacks",
      "title_zh": "视觉语言模型对抗分割图像有害输入攻击的鲁棒性",
      "authors": [
        "Md Rafi Ur Rashid",
        "MD Sadik Hossain Shanto",
        "Vishnu Asutosh Dasu",
        "Shagufta Mehnaz"
      ],
      "abstract": "Vision-Language Models (VLMs) are now a core part of modern AI. Recent work proposed several visual jailbreak attacks using single/ holistic images. However, contemporary VLMs demonstrate strong robustness against such attacks due to extensive safety alignment through preference optimization (e.g., RLHF). In this work, we identify a new vulnerability: while VLM pretraining and instruction tuning generalize well to split-image inputs, safety alignment is typically performed only on holistic images and does not account for harmful semantics distributed across multiple image fragments. Consequently, VLMs often fail to detect and refuse harmful split-image inputs, where unsafe cues emerge only after combining images. We introduce novel split-image visual jailbreak attacks (SIVA) that exploit this misalignment. Unlike prior optimization-based attacks, which exhibit poor black-box transferability due to architectural and prior mismatches across models, our attacks evolve in progressive phases from naive splitting to an adaptive white-box attack, culminating in a black-box transfer attack. Our strongest strategy leverages a novel adversarial knowledge distillation (Adv-KD) algorithm to substantially improve cross-model transferability. Evaluations on three state-of-the-art modern VLMs and three jailbreak datasets demonstrate that our strongest attack achieves up to 60% higher transfer success than existing baselines. Lastly, we propose efficient ways to address this critical vulnerability in the current VLM safety alignment.",
      "tldr_zh": "该研究探讨了视觉语言模型（Vision-Language Models, VLMs）在应对将有害语义分布在多个图像片段中的“分割图像攻击”时的脆弱性。作者指出，尽管现有的 VLMs 通过安全对齐（safety alignment）对整体图像攻击表现出较强的鲁棒性，但由于对齐过程忽略了跨图像片段的有害语义，导致模型难以识别并拒绝此类拆分后的输入。研究引入了分割图像视觉越狱攻击（Split-Image Visual jailbreak Attacks, SIVA），并利用对抗性知识蒸馏（Adversarial Knowledge Distillation, Adv-KD）算法显著增强了攻击在黑盒场景下的迁移能力。实验表明，该方法在三个最先进的 VLMs 上的迁移成功率比基线模型高出多达 60%。此外，该研究还提出了针对性且高效的防御方案，以修复当前 VLM 安全对齐中存在的这一关键漏洞。",
      "categories": [
        "cs.CV",
        "cs.AI"
      ],
      "primary_category": "cs.CV",
      "comment": "22 Pages, long conference paper",
      "pdf_url": "https://arxiv.org/pdf/2602.08136v1",
      "published_date": "2026-02-08 21:52:42 UTC",
      "updated_date": "2026-02-08 21:52:42 UTC",
      "processing_status": "completed",
      "attempts": 1,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "llm_backup_calls": 0,
      "last_update": "2026-02-16T05:16:11.608729+00:00"
    },
    {
      "arxiv_id": "2602.08124v1",
      "title": "Gender and Race Bias in Consumer Product Recommendations by Large Language Models",
      "title_zh": "大语言模型在消费品推荐中的性别与种族偏差",
      "authors": [
        "Ke Xu",
        "Shera Potka",
        "Alex Thomo"
      ],
      "abstract": "Large Language Models are increasingly employed in generating consumer product recommendations, yet their potential for embedding and amplifying gender and race biases remains underexplored. This paper serves as one of the first attempts to examine these biases within LLM-generated recommendations. We leverage prompt engineering to elicit product suggestions from LLMs for various race and gender groups and employ three analytical methods-Marked Words, Support Vector Machines, and Jensen-Shannon Divergence-to identify and quantify biases. Our findings reveal significant disparities in the recommendations for demographic groups, underscoring the need for more equitable LLM recommendation systems.",
      "tldr_zh": "该研究探讨了大语言模型(Large Language Models)在生成消费品推荐时可能存在的性别和种族偏见，是针对该领域偏见问题的首批系统性研究之一。研究团队利用提示工程(prompt engineering)诱导模型为不同种族和性别群体生成产品建议，并综合采用标记词(Marked Words)、支持向量机(Support Vector Machines)和Jensen-Shannon Divergence三种分析方法来识别并量化其中的偏差。实验结果揭示了不同人口统计群体在推荐内容上的显著差异，证实了LLMs在推荐任务中确实存在嵌入并放大偏见的现象。该发现强调了现有推荐系统的公平性缺失，并指出了构建更具公平性的LLM推荐系统的紧迫性。",
      "categories": [
        "cs.CL",
        "cs.AI",
        "cs.LG"
      ],
      "primary_category": "cs.CL",
      "comment": "Accepted at the 39th International Conference on Advanced Information Networking and Applications (AINA 2025)",
      "pdf_url": "https://arxiv.org/pdf/2602.08124v1",
      "published_date": "2026-02-08 21:06:16 UTC",
      "updated_date": "2026-02-08 21:06:16 UTC",
      "processing_status": "completed",
      "attempts": 1,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "llm_backup_calls": 0,
      "last_update": "2026-02-16T05:16:22.803554+00:00"
    },
    {
      "arxiv_id": "2602.08121v1",
      "title": "Initial Risk Probing and Feasibility Testing of Glow: a Generative AI-Powered Dialectical Behavior Therapy Skills Coach for Substance Use Recovery and HIV Prevention",
      "title_zh": "Glow 的初步风险探测与可行性测试：一种面向物质使用康复和艾滋病预防的生成式人工智能辩证行为疗法技能教练",
      "authors": [
        "Liying Wang",
        "Madison Lee",
        "Yunzhang Jiang",
        "Steven Chen",
        "Kewei Sha",
        "Yunhe Feng",
        "Frank Wong",
        "Lisa Hightow-Weidman",
        "Weichao Yuwen"
      ],
      "abstract": "Background: HIV and substance use represent interacting epidemics with shared psychological drivers - impulsivity and maladaptive coping. Dialectical behavior therapy (DBT) targets these mechanisms but faces scalability challenges. Generative artificial intelligence (GenAI) offers potential for delivering personalized DBT coaching at scale, yet rapid development has outpaced safety infrastructure. Methods: We developed Glow, a GenAI-powered DBT skills coach delivering chain and solution analysis for individuals at risk for HIV and substance use. In partnership with a Los Angeles community health organization, we conducted usability testing with clinical staff (n=6) and individuals with lived experience (n=28). Using the Helpful, Honest, and Harmless (HHH) framework, we employed user-driven adversarial testing wherein participants identified target behaviors and generated contextually realistic risk probes. We evaluated safety performance across 37 risk probe interactions. Results: Glow appropriately handled 73% of risk probes, but performance varied by agent. The solution analysis agent demonstrated 90% appropriate handling versus 44% for the chain analysis agent. Safety failures clustered around encouraging substance use and normalizing harmful behaviors. The chain analysis agent fell into an \"empathy trap,\" providing validation that reinforced maladaptive beliefs. Additionally, 27 instances of DBT skill misinformation were identified. Conclusions: This study provides the first systematic safety evaluation of GenAI-delivered DBT coaching for HIV and substance use risk reduction. Findings reveal vulnerabilities requiring mitigation before clinical trials. The HHH framework and user-driven adversarial testing offer replicable methods for evaluating GenAI mental health interventions.",
      "tldr_zh": "该研究开发并评估了名为 Glow 的生成式人工智能 (Generative AI) 驱动型辩证行为疗法 (Dialectical Behavior Therapy, DBT) 技能教练，旨在辅助物质使用康复与 HIV 预防。通过与社区健康组织合作，研究者采用“有益、诚实、无害”(Helpful, Honest, and Harmless, HHH) 框架，邀请临床人员与目标用户对系统进行了用户驱动的对抗性测试 (adversarial testing)。实验结果显示，Glow 恰当处理了 73% 的风险探测 (risk probes)，但链式分析智能体 (chain analysis agent) 的安全性表现远低于解决方案分析智能体 (solution analysis agent)，且容易陷入“共情陷阱” (empathy trap) 从而强化用户的适应不良信念。此外，研究还识别出多处 DBT 技能的错误信息。作为首个针对 AI 交付 DBT 辅导的系统性安全性评估，该研究揭示了生成式人工智能在心理健康干预中存在的漏洞，并为未来临床试验前的干预评估提供了可借鉴的方法论。",
      "categories": [
        "cs.AI"
      ],
      "primary_category": "cs.AI",
      "comment": "",
      "pdf_url": "https://arxiv.org/pdf/2602.08121v1",
      "published_date": "2026-02-08 21:00:29 UTC",
      "updated_date": "2026-02-08 21:00:29 UTC",
      "processing_status": "completed",
      "attempts": 1,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "llm_backup_calls": 0,
      "last_update": "2026-02-16T05:16:18.608422+00:00"
    },
    {
      "arxiv_id": "2602.08119v1",
      "title": "Constrained Pricing under Finite Mixtures of Logit",
      "title_zh": "有限混合 Logit 模型下的受限定价",
      "authors": [
        "Hoang Giang Pham",
        "Tien Mai"
      ],
      "abstract": "The mixed logit model is a flexible and widely used demand model in pricing and revenue management. However, existing work on mixed-logit pricing largely focuses on unconstrained settings, limiting its applicability in practice where prices are subject to business or regulatory constraints. We study the constrained pricing problem under multinomial and mixed logit demand models. For the multinomial logit model, corresponding to a single customer segment, we show that the constrained pricing problem admits a polynomial-time approximation scheme (PTAS) via a reformulation based on exponential cone programming, yielding an $\\varepsilon$-optimal solution in polynomial time. For finite mixed logit models with $T$ customer segments, we reformulate the problem as a bilinear exponential cone program with $O(T)$ bilinear terms. This structure enables a Branch-and-Bound algorithm whose complexity is exponential only in $T$. Consequently, constrained pricing under finite mixtures of logit admits a PTAS when the number of customer segments is bounded. Numerical experiments demonstrate strong performance relative to state-of-the-art baselines.",
      "tldr_zh": "该研究探讨了在混合 Logit (Mixed Logit) 模型下的约束定价问题，旨在解决现有定价研究中因忽视业务或监管约束而导致的实用性受限问题。针对单客群的 Multinomial Logit 模型，作者通过指数锥规划 (Exponential Cone Programming) 提出了一种多项式时间近似方案 (PTAS)，可在多项式时间内获得 $\\varepsilon$-最优解。对于包含 $T$ 个客群的有限混合 Logit 模型，研究将其重构为带有 $O(T)$ 个双线性项的双线性指数锥程序，并设计了复杂度仅随 $T$ 指数增长的分支定界 (Branch-and-Bound) 算法。该研究证明了当客群数量固定时，有限混合 Logit 模型的约束定价问题存在 PTAS。数值实验表明，该算法在处理复杂定价约束时表现出色，且性能显著优于现有的基准模型。",
      "categories": [
        "math.OC",
        "cs.AI",
        "econ.GN"
      ],
      "primary_category": "math.OC",
      "comment": "",
      "pdf_url": "https://arxiv.org/pdf/2602.08119v1",
      "published_date": "2026-02-08 20:48:50 UTC",
      "updated_date": "2026-02-08 20:48:50 UTC",
      "processing_status": "completed",
      "attempts": 1,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "llm_backup_calls": 0,
      "last_update": "2026-02-16T05:16:21.913773+00:00"
    },
    {
      "arxiv_id": "2602.10140v1",
      "title": "Can Large Language Models Implement Agent-Based Models? An ODD-based Replication Study",
      "title_zh": "大语言模型能否实现基于主体的模型？一项基于 ODD 的复现研究",
      "authors": [
        "Nuno Fachada",
        "Daniel Fernandes",
        "Carlos M. Fernandes",
        "João P. Matos-Carvalho"
      ],
      "abstract": "Large language models (LLMs) can now synthesize non-trivial executable code from textual descriptions, raising an important question: can LLMs reliably implement agent-based models from standardized specifications in a way that supports replication, verification, and validation? We address this question by evaluating 17 contemporary LLMs on a controlled ODD-to-code translation task, using the PPHPC predator-prey model as a fully specified reference. Generated Python implementations are assessed through staged executability checks, model-independent statistical comparison against a validated NetLogo baseline, and quantitative measures of runtime efficiency and maintainability. Results show that behaviorally faithful implementations are achievable but not guaranteed, and that executability alone is insufficient for scientific use. GPT-4.1 consistently produces statistically valid and efficient implementations, with Claude 3.7 Sonnet performing well but less reliably. Overall, the findings clarify both the promise and current limitations of LLMs as model engineering tools, with implications for reproducible agent-based and environmental modelling.",
      "tldr_zh": "该研究探讨了大型语言模型(LLMs)是否能够根据标准化规范可靠地实现基于智能体的模型(Agent-Based Models)，以支持科学研究中的复现与验证。研究者评估了17种现代LLMs在ODD-to-code任务中的表现，使用PPHPC捕食者-猎物模型作为参考，通过可执行性检查、与NetLogo基准的统计对比以及运行效率分析进行综合评价。结果显示，虽然LLMs能够生成行为忠实的Python实现，但仅凭代码的可执行性不足以保证其科学有效性。在测试模型中，GPT-4能够持续生成统计有效且高效的实现，而Claude 3.7 Sonnet表现良好但可靠性略逊。该研究阐明了LLMs作为模型工程工具的潜力与局限性，对环境建模和可重复性科学研究具有重要的指导意义。",
      "categories": [
        "cs.SE",
        "cs.AI",
        "cs.MA"
      ],
      "primary_category": "cs.SE",
      "comment": "",
      "pdf_url": "https://arxiv.org/pdf/2602.10140v1",
      "published_date": "2026-02-08 19:56:20 UTC",
      "updated_date": "2026-02-08 19:56:20 UTC",
      "processing_status": "completed",
      "attempts": 1,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "llm_backup_calls": 0,
      "last_update": "2026-02-16T05:17:00.206600+00:00"
    },
    {
      "arxiv_id": "2602.08104v1",
      "title": "Interpretable Failure Analysis in Multi-Agent Reinforcement Learning Systems",
      "title_zh": "多智能体强化学习系统中的可解释性失效分析",
      "authors": [
        "Risal Shahriar Shefin",
        "Debashis Gupta",
        "Thai Le",
        "Sarra Alqahtani"
      ],
      "abstract": "Multi-Agent Reinforcement Learning (MARL) is increasingly deployed in safety-critical domains, yet methods for interpretable failure detection and attribution remain underdeveloped. We introduce a two-stage gradient-based framework that provides interpretable diagnostics for three critical failure analysis tasks: (1) detecting the true initial failure source (Patient-0); (2) validating why non-attacked agents may be flagged first due to domino effects; and (3) tracing how failures propagate through learned coordination pathways. Stage 1 performs interpretable per-agent failure detection via Taylor-remainder analysis of policy-gradient costs, declaring an initial Patient-0 candidate at the first threshold crossing. Stage 2 provides validation through geometric analysis of critic derivatives-first-order sensitivity and directional second-order curvature aggregated over causal windows to construct interpretable contagion graphs. This approach explains \"downstream-first\" detection anomalies by revealing pathways that amplify upstream deviations. Evaluated across 500 episodes in Simple Spread (3 and 5 agents) and 100 episodes in StarCraft II using MADDPG and HATRPO, our method achieves 88.2-99.4% Patient-0 detection accuracy while providing interpretable geometric evidence for detection decisions. By moving beyond black-box detection to interpretable gradient-level forensics, this framework offers practical tools for diagnosing cascading failures in safety-critical MARL systems.",
      "tldr_zh": "本研究针对多智能体强化学习 (MARL) 系统在安全关键领域中缺乏可解释故障检测与归因的问题，提出了一种基于梯度的两阶段诊断框架。第一阶段通过对策略梯度 (Policy-gradient) 成本进行泰勒余项分析 (Taylor-remainder analysis)，实现可解释的单智能体故障检测并识别初始故障源 (Patient-0)。第二阶段利用评论家导数 (Critic derivatives) 的几何分析，结合一阶敏感度和二阶曲率构建传染图 (Contagion graphs)，旨在解释故障的传播路径及非受攻击智能体因多米诺效应先发出警报的异常现象。该框架在 Simple Spread 和 StarCraft II 环境下结合 MADDPG 与 HATRPO 算法进行了测试，实验表明其识别 Patient-0 的准确率高达 88.2% 至 99.4%。通过将故障分析从黑盒检测提升至梯度级取证，该方法为诊断复杂 MARL 系统中的级联故障提供了强有力的工具。",
      "categories": [
        "cs.AI",
        "cs.LG",
        "cs.MA"
      ],
      "primary_category": "cs.AI",
      "comment": "",
      "pdf_url": "https://arxiv.org/pdf/2602.08104v1",
      "published_date": "2026-02-08 19:55:26 UTC",
      "updated_date": "2026-02-08 19:55:26 UTC",
      "processing_status": "completed",
      "attempts": 1,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "llm_backup_calls": 0,
      "last_update": "2026-02-16T05:17:04.903239+00:00"
    },
    {
      "arxiv_id": "2602.08100v1",
      "title": "Emergent Search and Backtracking in Latent Reasoning Models",
      "title_zh": "潜空间推理模型中的搜索与回溯涌现",
      "authors": [
        "Jasmine Cui",
        "Charles Ye"
      ],
      "abstract": "What happens when a language model thinks without words? Standard reasoning LLMs verbalize intermediate steps as chain-of-thought; latent reasoning transformers (LRTs) instead perform deliberation entirely in continuous hidden space. We investigate an LRT, decoding the model's evolving beliefs at every step on a multiple-choice QA benchmark. We find that the model spontaneously learns a structured search process in latent space. Deliberation follows a consistent trajectory: an exploration phase where probability mass spreads across candidates, tentative commitment to a frontrunner, and either convergence or backtracking. Backtracking is prevalent (32% of instances), beneficial (34% accuracy gain over non-backtracking instances), and predominantly directed away from the semantically closest distractor toward the correct answer. The search is adaptive: replacing distractors with implausible alternatives shortens exploration by 54%. Latent reasoning models achieve in activation space what chain-of-thought achieves through words: the ability to be wrong, notice, and recover.",
      "tldr_zh": "该研究探讨了潜在推理模型(Latent Reasoning Models)在连续隐藏空间中进行思考的内在机制，发现这类模型在没有 Chain-of-Thought 言语化过程的情况下，能自发学习到一种结构化的潜在空间搜索过程。研究者通过解码模型在多选题基准测试中的信念演化，识别出包含探索、初步承诺以及收敛或回溯(Backtracking)的连贯路径。实验显示回溯现象不仅普遍存在，且能显著提升 34% 的准确率，帮助模型从语义接近的干扰项转向正确答案。此外，这种潜在搜索具有适应性，去除干扰项可使探索阶段缩短 54%。潜在推理模型证明了神经网络可以在激活空间中实现与文字链式思维类似的能力，即具备犯错、察觉并自我修复的功能。",
      "categories": [
        "cs.CL",
        "cs.AI"
      ],
      "primary_category": "cs.CL",
      "comment": "",
      "pdf_url": "https://arxiv.org/pdf/2602.08100v1",
      "published_date": "2026-02-08 19:44:30 UTC",
      "updated_date": "2026-02-08 19:44:30 UTC",
      "processing_status": "completed",
      "attempts": 1,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "llm_backup_calls": 0,
      "last_update": "2026-02-16T05:17:05.534101+00:00"
    },
    {
      "arxiv_id": "2602.08099v1",
      "title": "VidVec: Unlocking Video MLLM Embeddings for Video-Text Retrieval",
      "title_zh": "VidVec：挖掘视频多模态大模型嵌入特征在视文检索中的潜力",
      "authors": [
        "Issar Tzachor",
        "Dvir Samuel",
        "Rami Ben-Ari"
      ],
      "abstract": "Recent studies have adapted generative Multimodal Large Language Models (MLLMs) into embedding extractors for vision tasks, typically through fine-tuning to produce universal representations. However, their performance on video remains inferior to Video Foundation Models (VFMs). In this paper, we focus on leveraging MLLMs for video-text embedding and retrieval. We first conduct a systematic layer-wise analysis, showing that intermediate (pre-trained) MLLM layers already encode substantial task-relevant information. Leveraging this insight, we demonstrate that combining intermediate-layer embeddings with a calibrated MLLM head yields strong zero-shot retrieval performance without any training. Building on these findings, we introduce a lightweight text-based alignment strategy which maps dense video captions to short summaries and enables task-related video-text embedding learning without visual supervision. Remarkably, without any fine-tuning beyond text, our method outperforms current methods, often by a substantial margin, achieving state-of-the-art results across common video retrieval benchmarks.",
      "tldr_zh": "这项研究探讨了如何利用多模态大语言模型 (MLLMs) 提取视频嵌入向量，以解决其在视频领域性能不如视频基础模型 (VFMs) 的问题。通过系统性的逐层分析，研究人员发现 MLLMs 的中间预训练层已包含大量任务相关信息，仅需结合校准后的模型头即可在无训练的情况下实现强劲的零样本检索性能。在此基础上，研究提出了 VidVec，这是一种轻量级的文本对齐策略，通过将密集的视频描述映射为简短摘要，在无需视觉监督的情况下学习任务相关的视频-文本嵌入。实验结果表明，VidVec 在不进行任何视觉微调的前提下，在多个通用视频检索基准测试中均取得了当前最先进 (SOTA) 的结果，显著优于现有方法。",
      "categories": [
        "cs.CV",
        "cs.AI"
      ],
      "primary_category": "cs.CV",
      "comment": "Project page: https://iyttor.github.io/VidVec/",
      "pdf_url": "https://arxiv.org/pdf/2602.08099v1",
      "published_date": "2026-02-08 19:39:32 UTC",
      "updated_date": "2026-02-08 19:39:32 UTC",
      "processing_status": "completed",
      "attempts": 1,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "llm_backup_calls": 0,
      "last_update": "2026-02-16T05:17:07.611680+00:00"
    },
    {
      "arxiv_id": "2602.08092v1",
      "title": "Objective Decoupling in Social Reinforcement Learning: Recovering Ground Truth from Sycophantic Majorities",
      "title_zh": "社会强化学习中的目标脱钩：从迎合性多数中恢复基准真相",
      "authors": [
        "Majid Ghasemi",
        "Mark Crowley"
      ],
      "abstract": "Contemporary AI alignment strategies rely on a fragile premise: that human feedback, while noisy, remains a fundamentally truthful signal. In this paper, we identify this assumption as Dogma 4 of Reinforcement Learning (RL). We demonstrate that while this dogma holds in static environments, it fails in social settings where evaluators may be sycophantic, lazy, or adversarial. We prove that under Dogma 4, standard RL agents suffer from what we call Objective Decoupling, a structural failure mode where the agent's learned objective permanently separates from the latent ground truth, guaranteeing convergence to misalignment. To resolve this, we propose Epistemic Source Alignment (ESA). Unlike standard robust methods that rely on statistical consensus (trusting the majority), ESA utilizes sparse safety axioms to judge the source of the feedback rather than the signal itself. We prove that this \"judging the judges\" mechanism guarantees convergence to the true objective, even when a majority of evaluators are biased. Empirically, we show that while traditional consensus methods fail under majority collusion, our approach successfully recovers the optimal policy.",
      "tldr_zh": "该研究探讨了当代 AI alignment 策略中一个脆弱的假设，即 Reinforcement Learning (RL) 领域中关于人类反馈始终是真实信号的 Dogma 4 假设。论文指出，在评估者存在 sycophantic（阿谀奉承）、懒惰或对抗性的社会化场景中，这一假设失效，导致智能体陷入 Objective Decoupling（目标脱钩）的结构性失效模式。这种模式使得智能体学到的目标与潜藏的 ground truth 永久分离，从而必然导致 misalignment。为解决这一问题，研究者提出了 Epistemic Source Alignment (ESA) 方法。与依赖多数人共识的传统方法不同，ESA 利用稀疏的 safety axioms（安全公理）来评估反馈的来源而非信号本身。这种“审判审判者”的机制在理论上保证了即便在多数评估者存在偏见的情况下，智能体也能收敛至真正的目标。实验结果表明，当传统共识方法在多数人合谋下失效时，ESA 能够成功恢复最优策略。",
      "categories": [
        "cs.AI",
        "cs.ET"
      ],
      "primary_category": "cs.AI",
      "comment": "",
      "pdf_url": "https://arxiv.org/pdf/2602.08092v1",
      "published_date": "2026-02-08 19:23:02 UTC",
      "updated_date": "2026-02-08 19:23:02 UTC",
      "processing_status": "completed",
      "attempts": 1,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "llm_backup_calls": 0,
      "last_update": "2026-02-16T05:17:16.097389+00:00"
    },
    {
      "arxiv_id": "2602.08088v1",
      "title": "Online Domain-aware LLM Decoding for Continual Domain Evolution",
      "title_zh": "面向持续领域演变的在线领域感知 LLM 解码",
      "authors": [
        "Mohammad Abu-Shaira",
        "Weishi Shi"
      ],
      "abstract": "LLMs are typically fine-tuned offline on domain-specific data, assuming a static domain. In practice, domain knowledge evolves continuously through new regulations, products, services, and interaction patterns. Retraining or fine-tuning LLMs for every new instance is computationally infeasible. Additionally, real-world environments also exhibit temporal dynamics with shifting data distributions. Disregarding this phenomenon, commonly referred to as concept drift, can significantly diminish a model's predictive accuracy. This mismatch between evolving domains and static adaptation pipelines highlights the need for efficient, real-time adaptation without costly retraining. In response, we introduce Online Domain-aware Decoding framework (ODD). ODD performs probability-level fusion between a base LLM and a prefix-tree prior, guided by adaptive confidence modulation using disagreement and continuity signals. Empirical evaluation under diverse drift scenarios demonstrates that ODD consistently surpasses LLM-Greedy and LLM-Temp Scaled across all syntactic and semantic NLG metrics. It yields an absolute ROUGE-L gain of 0.065 and a 13.6% relative improvement in Cosine Similarity over the best baseline. These results demonstrate ODD 's robustness to evolving lexical and contextual patterns, making it suitable for dynamic LLM applications.",
      "tldr_zh": "该研究针对大语言模型(LLMs)在静态领域离线微调后，难以应对现实中持续演进的领域知识以及概念漂移(concept drift)导致的预测准确率下降问题，提出了在线领域感知解码(Online Domain-aware Decoding, ODD)框架。ODD框架通过在基础LLM与前缀树先验(prefix-tree prior)之间进行概率级融合，并辅以利用不一致性和连续性信号的自适应置信度调节，实现了无需高昂重训成本的实时领域适配。在多种漂移场景下的实证评估显示，ODD在各项自然语言生成(NLG)指标上均显著优于LLM-Greedy和LLM-Temp Scaled基线模型。实验结果指出，ODD获得了0.065的ROUGE-L绝对增益，并在余弦相似度(Cosine Similarity)上实现了13.6%的相对提升。这一研究证明了ODD对于演进中的词汇和上下文模式具有极强的鲁棒性，为动态环境下的LLM应用提供了有效的技术方案。",
      "categories": [
        "cs.LG",
        "cs.AI"
      ],
      "primary_category": "cs.LG",
      "comment": "",
      "pdf_url": "https://arxiv.org/pdf/2602.08088v1",
      "published_date": "2026-02-08 19:13:20 UTC",
      "updated_date": "2026-02-08 19:13:20 UTC",
      "processing_status": "completed",
      "attempts": 1,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "llm_backup_calls": 0,
      "last_update": "2026-02-16T05:17:46.305229+00:00"
    },
    {
      "arxiv_id": "2602.08085v1",
      "title": "Large language models for spreading dynamics in complex systems",
      "title_zh": "面向复杂系统传播动力学的大语言模型",
      "authors": [
        "Shuyu Jiang",
        "Hao Ren",
        "Yichang Gao",
        "Yi-Cheng Zhang",
        "Li Qi",
        "Dayong Xiao",
        "Jie Fan",
        "Rui Tang",
        "Wei Wang"
      ],
      "abstract": "Spreading dynamics is a central topic in the physics of complex systems and network science, providing a unified framework for understanding how information, behaviors, and diseases propagate through interactions among system units. In many propagation contexts, spreading processes are influenced by multiple interacting factors, such as information expression patterns, cultural contexts, living environments, cognitive preferences, and public policies, which are difficult to incorporate directly into classical modeling frameworks. Recently, large language models (LLMs) have exhibited strong capabilities in natural language understanding, reasoning, and generation, enabling explicit perception of semantic content and contextual cues in spreading processes, thereby supporting the analysis of the different influencing factors. Beyond serving as external analytical tools, LLMs can also act as interactive agents embedded in propagation systems, potentially influencing spreading pathways and feedback structures. Consequently, the roles and impacts of LLMs on spreading dynamics have become an active and rapidly growing research area across multiple research disciplines. This review provides a comprehensive overview of recent advances in applying LLMs to the study of spreading dynamics across two representative domains: digital epidemics, such as misinformation and rumors, and biological epidemics, including infectious disease outbreaks. We first examine the foundations of epidemic modeling from a complex-systems perspective and discuss how LLM-based approaches relate to traditional frameworks. We then systematically review recent studies from three key perspectives, which are epidemic modeling, epidemic detection and surveillance, and epidemic prediction and management, to clarify how LLMs enhance these areas. Finally, open challenges and potential research directions are discussed.",
      "tldr_zh": "这项研究综述了大型语言模型(LLMs)在复杂系统和网络科学传播动力学(Spreading dynamics)中的应用，探讨了LLMs如何处理经典模型难以整合的文化背景、认知偏好和公共政策等复杂影响因素。文章首先从复杂系统视角审视传染病建模(Epidemic modeling)基础，并对比了基于LLMs的方法与传统框架的关联。随后，研究从疫情建模、监测发现以及预测管理三个关键维度系统回顾了近期进展，涵盖了数字流行病（如虚假信息和谣言）与生物流行病（如传染病暴发）两大典型领域。LLMs不仅作为外部分析工具，还作为嵌入系统的交互智能体(Agents)影响传播路径和反馈结构。最后，该综述明确了LLMs在增强传播动力学研究中的作用，并指出了当前面临的挑战与未来的研究方向。",
      "categories": [
        "physics.soc-ph",
        "cs.AI",
        "cs.CE"
      ],
      "primary_category": "physics.soc-ph",
      "comment": "",
      "pdf_url": "https://arxiv.org/pdf/2602.08085v1",
      "published_date": "2026-02-08 18:58:43 UTC",
      "updated_date": "2026-02-08 18:58:43 UTC",
      "processing_status": "completed",
      "attempts": 1,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "llm_backup_calls": 0,
      "last_update": "2026-02-16T05:17:54.498045+00:00"
    },
    {
      "arxiv_id": "2602.08082v1",
      "title": "Spectral Guardrails for Agents in the Wild: Detecting Tool Use Hallucinations via Attention Topology",
      "title_zh": "开放场景下的智能体谱式护栏：基于注意力拓扑的工具调用幻觉检测",
      "authors": [
        "Valentin Noël"
      ],
      "abstract": "Deploying autonomous agents in the wild requires reliable safeguards against tool use failures. We propose a training free guardrail based on spectral analysis of attention topology that complements supervised approaches. On Llama 3.1 8B, our method achieves 97.7\\% recall with multi-feature detection and 86.1\\% recall with 81.0\\% precision for balanced deployment, without requiring any labeled training data. Most remarkably, we discover that single layer spectral features act as near-perfect hallucination detectors: Llama L26 Smoothness achieves 98.2\\% recall (213/217 hallucinations caught) with a single threshold, and Mistral L3 Entropy achieves 94.7\\% recall. This suggests hallucination is not merely a wrong token but a thermodynamic state change: the model's attention becomes noise when it errs. Through controlled cross-model evaluation on matched domains ($N=1000$, $T=0.3$, same General domain, hallucination rates 20--22\\%), we reveal the ``Loud Liar'' phenomenon: Llama 3.1 8B's failures are spectrally catastrophic and dramatically easier to detect, while Mistral 7B achieves the best discrimination (AUC 0.900). These findings establish spectral analysis as a principled, efficient framework for agent safety.",
      "tldr_zh": "该研究提出了一种基于注意力拓扑结构（Attention Topology）谱分析（Spectral Analysis）的免训练防护栏（Guardrail），旨在检测自主智能体在实际应用中调用工具时的幻觉（Hallucination）失效。研究发现幻觉不仅是错误的 Token，更是一种热力学状态的转变，即模型在出错时其注意力会演变为噪声。在 Llama 3.1 8B 模型上，该方法在无需标注训练数据的情况下实现了 97.7% 的召回率，其中单层谱特征（如 Llama L26 Smoothness）表现出近乎完美的检测能力。通过跨模型评估，研究揭示了“大声撒谎者”（Loud Liar）现象，即 Llama 3.1 8B 的幻觉在频谱上表现剧烈且极易捕获，而 Mistral 7B 则在辨别力（AUC 0.900）上达到最优。该成果证明了谱分析可以作为一个原则性强且高效的框架，为智能体的安全部署提供可靠保障。",
      "categories": [
        "cs.LG",
        "cs.AI",
        "eess.SP"
      ],
      "primary_category": "cs.LG",
      "comment": "32 pages, 2 fgures, 18 tables",
      "pdf_url": "https://arxiv.org/pdf/2602.08082v1",
      "published_date": "2026-02-08 18:56:16 UTC",
      "updated_date": "2026-02-08 18:56:16 UTC",
      "processing_status": "completed",
      "attempts": 1,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "llm_backup_calls": 0,
      "last_update": "2026-02-16T05:17:53.703878+00:00"
    },
    {
      "arxiv_id": "2602.08077v1",
      "title": "Multimodal normative modeling in Alzheimers Disease with introspective variational autoencoders",
      "title_zh": "基于自省式变分自编码器的阿尔茨海默病多模态常模建模",
      "authors": [
        "Sayantan Kumar",
        "Peijie Qiu",
        "Aristeidis Sotiras"
      ],
      "abstract": "Normative modeling learns a healthy reference distribution and quantifies subject-specific deviations to capture heterogeneous disease effects. In Alzheimers disease (AD), multimodal neuroimaging offers complementary signals but VAE-based normative models often (i) fit the healthy reference distribution imperfectly, inflating false positives, and (ii) use posterior aggregation (e.g., PoE/MoE) that can yield weak multimodal fusion in the shared latent space. We propose mmSIVAE, a multimodal soft-introspective variational autoencoder combined with Mixture-of-Product-of-Experts (MOPOE) aggregation to improve reference fidelity and multimodal integration. We compute deviation scores in latent space and feature space as distances from the learned healthy distributions, and map statistically significant latent deviations to regional abnormalities for interpretability. On ADNI MRI regional volumes and amyloid PET SUVR, mmSIVAE improves reconstruction on held-out controls and produces more discriminative deviation scores for outlier detection than VAE baselines, with higher likelihood ratios and clearer separation between control and AD-spectrum cohorts. Deviation maps highlight region-level patterns aligned with established AD-related changes. More broadly, our results highlight the importance of training objectives that prioritize reference-distribution fidelity and robust multimodal posterior aggregation for normative modeling, with implications for deviation-based analysis across multimodal clinical data.",
      "tldr_zh": "该研究提出了 mmSIVAE，一种基于多模态软内省变异自编码器 (multimodal soft-introspective variational autoencoder) 的常模建模 (normative modeling) 框架，旨在解决阿尔茨海默病 (Alzheimer's Disease) 研究中参考分布拟合不准和多模态融合微弱的问题。该模型结合了专家乘积混合 (Mixture-of-Product-of-Experts) 聚合技术，通过在潜空间和特征空间计算偏离得分来量化个体相对于健康参考分布的异常程度。实验在 ADNI 数据集的 MRI 区域体积和淀粉样蛋白 PET SUVR 模态上进行，结果显示 mmSIVAE 在重建质量和离群点检测性能上均优于传统 VAE 基准模型。偏离图谱准确捕捉到了与阿尔茨海默病相关的区域性异常模式，证明了该方法在临床多模态数据偏离分析中的解释性与判别力，强调了提升参考分布保真度对常模建模的重要性。",
      "categories": [
        "cs.LG",
        "cs.AI"
      ],
      "primary_category": "cs.LG",
      "comment": "Conference on Health, Inference, and Learning (CHIL)",
      "pdf_url": "https://arxiv.org/pdf/2602.08077v1",
      "published_date": "2026-02-08 18:42:06 UTC",
      "updated_date": "2026-02-08 18:42:06 UTC",
      "processing_status": "completed",
      "attempts": 1,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "llm_backup_calls": 0,
      "last_update": "2026-02-16T05:17:59.812846+00:00"
    },
    {
      "arxiv_id": "2602.08064v1",
      "title": "SiameseNorm: Breaking the Barrier to Reconciling Pre/Post-Norm",
      "title_zh": "SiameseNorm：打破 Pre/Post-Norm 统一的壁垒",
      "authors": [
        "Tianyu Li",
        "Dongchen Han",
        "Zixuan Cao",
        "Haofeng Huang",
        "Mengyu Zhou",
        "Ming Chen",
        "Erchao Zhao",
        "Xiaoxi Jiang",
        "Guanjun Jiang",
        "Gao Huang"
      ],
      "abstract": "Modern Transformers predominantly adopt the Pre-Norm paradigm for its optimization stability, foregoing the superior potential of the unstable Post-Norm architecture. Prior attempts to combine their strengths typically lead to a stability-performance trade-off. We attribute this phenomenon to a structural incompatibility within a single-stream design: Any application of the Post-Norm operation inevitably obstructs the clean identity gradient preserved by Pre-Norm. To fundamentally reconcile these paradigms, we propose SiameseNorm, a two-stream architecture that couples Pre-Norm-like and Post-Norm-like streams with shared parameters. This design decouples the optimization dynamics of the two streams, retaining the distinct characteristics of both Pre-Norm and Post-Norm by enabling all residual blocks to receive combined gradients inherited from both paradigms, where one stream secures stability while the other enhances expressivity. Extensive pre-training experiments on 1.3B-parameter models demonstrate that SiameseNorm exhibits exceptional optimization robustness and consistently outperforms strong baselines. Code is available at https://github.com/Qwen-Applications/SiameseNorm.",
      "tldr_zh": "该研究针对Transformer架构中Pre-Norm与Post-Norm范式的平衡难题，提出了名为SiameseNorm的双流架构。研究团队发现，单流设计中Post-Norm的操作会不可避免地阻断Pre-Norm所保留的恒等映射梯度(identity gradient)，导致两者在单一路径下难以兼容。SiameseNorm通过参数共享将类似Pre-Norm和Post-Norm的流进行耦合，有效解耦了两者的优化动态，使所有残差块(residual blocks)能够同时获得稳定性与高表达能力(expressivity)。实验表明，在1.3B参数规模的预训练任务中，SiameseNorm展现出卓越的优化鲁棒性，性能表现始终优于传统的强基线模型。",
      "categories": [
        "cs.LG",
        "cs.AI",
        "cs.CL"
      ],
      "primary_category": "cs.LG",
      "comment": "",
      "pdf_url": "https://arxiv.org/pdf/2602.08064v1",
      "published_date": "2026-02-08 17:17:56 UTC",
      "updated_date": "2026-02-08 17:17:56 UTC",
      "processing_status": "completed",
      "attempts": 1,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "llm_backup_calls": 0,
      "last_update": "2026-02-16T05:18:03.110475+00:00"
    },
    {
      "arxiv_id": "2602.08061v1",
      "title": "Securing Dual-Use Pathogen Data of Concern",
      "title_zh": "受关注两用病原体数据的安全保障",
      "authors": [
        "Doni Bloomfield",
        "Allison Berke",
        "Moritz S. Hanke",
        "Aaron Maiwald",
        "James R. M. Black",
        "Toby Webster",
        "Tina Hernandez-Boussard",
        "Oliver M. Crook",
        "Jassi Pannu"
      ],
      "abstract": "Training data is an essential input into creating competent artificial intelligence (AI) models. AI models for biology are trained on large volumes of data, including data related to biological sequences, structures, images, and functions. The type of data used to train a model is intimately tied to the capabilities it ultimately possesses--including those of biosecurity concern. For this reason, an international group of more than 100 researchers at the recent 50th anniversary Asilomar Conference endorsed data controls to prevent the use of AI for harmful applications such as bioweapons development. To help design such controls, we introduce a five-tier Biosecurity Data Level (BDL) framework for categorizing pathogen data. Each level contains specific data types, based on their expected ability to contribute to capabilities of concern when used to train AI models. For each BDL tier, we propose technical restrictions appropriate to its level of risk. Finally, we outline a novel governance framework for newly created dual-use pathogen data. In a world with widely accessible computational and coding resources, data controls may be among the most high-leverage interventions available to reduce the proliferation of concerning biological AI capabilities.",
      "tldr_zh": "该研究探讨了如何通过加强数据控制来应对人工智能(AI)在生物安全领域带来的双重用途(Dual-use)风险。为了防止AI被用于生物武器开发等有害应用，作者引入了名为Biosecurity Data Level (BDL)的五级生物安全数据分级框架，旨在对病原体数据进行科学分类。该框架根据不同数据类型在训练AI模型时贡献核心能力的潜力进行层级划分，并针对每个BDL级别提出了相应的技术限制建议。此外，研究还为新创建的具有双重用途风险的病原体数据设计了一套治理框架(Governance framework)。在计算和编程资源高度普及的背景下，该研究强调数据控制是减少生物安全威胁、遏制危险AI能力扩散的最具杠杆效应的干预手段。",
      "categories": [
        "cs.AI",
        "q-bio.OT"
      ],
      "primary_category": "cs.AI",
      "comment": "39th Conference on Neural Information Processing Systems (NeurIPS 2025) Workshop: Biosecurity Safeguards for Generative AI",
      "pdf_url": "https://arxiv.org/pdf/2602.08061v1",
      "published_date": "2026-02-08 17:11:19 UTC",
      "updated_date": "2026-02-08 17:11:19 UTC",
      "processing_status": "completed",
      "attempts": 1,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "llm_backup_calls": 0,
      "last_update": "2026-02-16T05:18:42.508766+00:00"
    },
    {
      "arxiv_id": "2602.08059v1",
      "title": "DICE: Disentangling Artist Style from Content via Contrastive Subspace Decomposition in Diffusion Models",
      "title_zh": "DICE：通过对比子空间分解实现扩散模型中艺术家风格与内容的解耦",
      "authors": [
        "Tong Zhang",
        "Ru Zhang",
        "Jianyi Liu"
      ],
      "abstract": "The recent proliferation of diffusion models has made style mimicry effortless, enabling users to imitate unique artistic styles without authorization. In deployed platforms, this raises copyright and intellectual-property risks and calls for reliable protection. However, existing countermeasures either require costly weight editing as new styles emerge or rely on an explicitly specified editing style, limiting their practicality for deployment-side safety. To address this challenge, we propose DICE (Disentanglement of artist Style from Content via Contrastive Subspace Decomposition), a training-free framework for on-the-fly artist style erasure. Unlike style editing that require an explicitly specified replacement style, DICE performs style purification, removing the artist's characteristics while preserving the user-intended content. Our core insight is that a model cannot truly comprehend the artist style from a single text or image alone. Consequently, we abandon the traditional paradigm of identifying style from isolated samples. Instead, we construct contrastive triplets to compel the model to distinguish between style and non-style features in the latent space. By formalizing this disentanglement process as a solvable generalized eigenvalue problem, we achieve precise identification of the style subspace. Furthermore, we introduce an Adaptive Attention Decoupling Editing strategy dynamically assesses the style concentration of each token and performs differential suppression and content enhancement on the QKV vectors. Extensive experiments demonstrate that DICE achieves a superior balance between the thoroughness of style erasure and the preservation of content integrity. DICE introduces an additional overhead of only 3 seconds to disentangle style, providing a practical and efficient technique for curbing style mimicry.",
      "tldr_zh": "该研究提出了DICE（Disentanglement of artist Style from Content via Contrastive Subspace Decomposition），这是一个无需训练、可即时擦除艺术家风格的框架，旨在解决扩散模型（Diffusion Models）带来的版权和知识产权风险。与传统需要指定替代风格的方法不同，DICE通过风格净化（style purification）在保留用户意图内容的同时去除特定艺术家的风格特征。该框架通过构建对比三元组（contrastive triplets）促使模型在潜空间（latent space）中区分风格与非风格特征，并将其形式化为广义特征值问题（generalized eigenvalue problem）以精确识别风格子空间。此外，研究引入了自适应注意力解耦编辑（Adaptive Attention Decoupling Editing）策略，动态评估每个token的风格浓度，并对QKV向量进行差异化抑制和内容增强。实验结果表明，DICE在风格擦除的彻底性与内容完整性之间达到了卓越平衡，且仅增加3秒额外开销，为遏制风格模仿提供了一种高效实用的技术手段。",
      "categories": [
        "cs.CV",
        "cs.AI"
      ],
      "primary_category": "cs.CV",
      "comment": "",
      "pdf_url": "https://arxiv.org/pdf/2602.08059v1",
      "published_date": "2026-02-08 17:06:48 UTC",
      "updated_date": "2026-02-08 17:06:48 UTC",
      "processing_status": "completed",
      "attempts": 1,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "llm_backup_calls": 0,
      "last_update": "2026-02-16T05:18:24.810750+00:00"
    },
    {
      "arxiv_id": "2602.08058v1",
      "title": "Picasso: Holistic Scene Reconstruction with Physics-Constrained Sampling",
      "title_zh": "Picasso：基于物理约束采样的整体场景重建",
      "authors": [
        "Xihang Yu",
        "Rajat Talak",
        "Lorenzo Shaikewitz",
        "Luca Carlone"
      ],
      "abstract": "In the presence of occlusions and measurement noise, geometrically accurate scene reconstructions -- which fit the sensor data -- can still be physically incorrect. For instance, when estimating the poses and shapes of objects in the scene and importing the resulting estimates into a simulator, small errors might translate to implausible configurations including object interpenetration or unstable equilibrium. This makes it difficult to predict the dynamic behavior of the scene using a digital twin, an important step in simulation-based planning and control of contact-rich behaviors. In this paper, we posit that object pose and shape estimation requires reasoning holistically over the scene (instead of reasoning about each object in isolation), accounting for object interactions and physical plausibility. Towards this goal, our first contribution is Picasso, a physics-constrained reconstruction pipeline that builds multi-object scene reconstructions by considering geometry, non-penetration, and physics. Picasso relies on a fast rejection sampling method that reasons over multi-object interactions, leveraging an inferred object contact graph to guide samples. Second, we propose the Picasso dataset, a collection of 10 contact-rich real-world scenes with ground truth annotations, as well as a metric to quantify physical plausibility, which we open-source as part of our benchmark. Finally, we provide an extensive evaluation of Picasso on our newly introduced dataset and on the YCB-V dataset, and show it largely outperforms the state of the art while providing reconstructions that are both physically plausible and more aligned with human intuition.",
      "tldr_zh": "该研究针对遮挡和传感器噪声环境下几何重建可能产生的物体穿插或不稳定等物理错误，提出了Picasso，一种基于物理约束采样(Physics-Constrained Sampling)的整体场景重建流水线(Reconstruction Pipeline)。Picasso通过推导物体接触图(Contact Graph)引导快速拒绝采样(Rejection Sampling)，从而在重建过程中充分考虑多物体间的相互作用和物理可行性。此外，研究者还贡献了包含10个真实场景标注的Picasso数据集以及一种量化物理可行性的评价指标。实验结果表明，Picasso在Picasso数据集和YCB-V数据集上的表现显著优于现有最先进技术(SOTA)，能够生成既符合物理规律又贴合人类直觉的重建结果。该工作为基于模拟的规划与控制提供了更具物理真实性的数字孪生(Digital Twin)支持。",
      "categories": [
        "cs.CV",
        "cs.AI",
        "cs.RO",
        "eess.SY"
      ],
      "primary_category": "cs.CV",
      "comment": "15 pages",
      "pdf_url": "https://arxiv.org/pdf/2602.08058v1",
      "published_date": "2026-02-08 17:04:54 UTC",
      "updated_date": "2026-02-08 17:04:54 UTC",
      "processing_status": "completed",
      "attempts": 1,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "llm_backup_calls": 0,
      "last_update": "2026-02-16T05:18:27.411553+00:00"
    },
    {
      "arxiv_id": "2602.08057v1",
      "title": "Weak to Strong: VLM-Based Pseudo-Labeling as a Weakly Supervised Training Strategy in Multimodal Video-based Hidden Emotion Understanding Tasks",
      "title_zh": "Weak to Strong：基于视觉语言模型伪标签的多模态视频隐性情绪理解弱监督训练策略",
      "authors": [
        "Yufei Wang",
        "Haixu Liu",
        "Tianxiang Xu",
        "Chuancheng Shi",
        "Hongsheng Xing"
      ],
      "abstract": "To tackle the automatic recognition of \"concealed emotions\" in videos, this paper proposes a multimodal weak-supervision framework and achieves state-of-the-art results on the iMiGUE tennis-interview dataset. First, YOLO 11x detects and crops human portraits frame-by-frame, and DINOv2-Base extracts visual features from the cropped regions. Next, by integrating Chain-of-Thought and Reflection prompting (CoT + Reflection), Gemini 2.5 Pro automatically generates pseudo-labels and reasoning texts that serve as weak supervision for downstream models. Subsequently, OpenPose produces 137-dimensional key-point sequences, augmented with inter-frame offset features; the usual graph neural network backbone is simplified to an MLP to efficiently model the spatiotemporal relationships of the three key-point streams. An ultra-long-sequence Transformer independently encodes both the image and key-point sequences, and their representations are concatenated with BERT-encoded interview transcripts. Each modality is first pre-trained in isolation, then fine-tuned jointly, with pseudo-labeled samples merged into the training set for further gains. Experiments demonstrate that, despite severe class imbalance, the proposed approach lifts accuracy from under 0.6 in prior work to over 0.69, establishing a new public benchmark. The study also validates that an \"MLP-ified\" key-point backbone can match - or even surpass - GCN-based counterparts in this task.",
      "tldr_zh": "该研究针对视频中“隐蔽情感”(concealed emotions)的自动识别，提出了一种多模态弱监督框架，并在iMiGUE网球采访数据集上取得了SOTA性能。研究首先利用YOLO 11x和DINOv2-Base进行图像处理与视觉特征提取，并创新性地通过Gemini 2.5 Pro结合链式思维(CoT)与反思(Reflection)提示自动生成伪标签(pseudo-labels)以实施弱监督训练。在特征编码方面，该框架采用超长序列Transformer分别对图像和由OpenPose提取的关键点序列进行处理，并与BERT编码的文本特征进行拼接融合。针对关键点流的时空建模，研究将传统的图卷积网络(GCN)简化为多层感知机(MLP)，显著提升了计算效率。实验结果表明，尽管存在严重的类别不平衡，该方法仍将识别准确率从0.6以下提升至0.69以上，建立了新的公开基准。此外，该研究验证了“MLP化”的关键点骨干网络在此类任务中能够匹配甚至超越传统的GCN模型。",
      "categories": [
        "cs.CV",
        "cs.AI"
      ],
      "primary_category": "cs.CV",
      "comment": "",
      "pdf_url": "https://arxiv.org/pdf/2602.08057v1",
      "published_date": "2026-02-08 17:02:55 UTC",
      "updated_date": "2026-02-08 17:02:55 UTC",
      "processing_status": "completed",
      "attempts": 1,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "llm_backup_calls": 0,
      "last_update": "2026-02-16T05:18:29.497767+00:00"
    },
    {
      "arxiv_id": "2602.09058v1",
      "title": "Persistent Entropy as a Detector of Phase Transitions",
      "title_zh": "持久熵作为相变的探测器",
      "authors": [
        "Matteo Rucco"
      ],
      "abstract": "Persistent entropy (PE) is an information-theoretic summary statistic of persistence barcodes that has been widely used to detect regime changes in complex systems. Despite its empirical success, a general theoretical understanding of when and why persistent entropy reliably detects phase transitions has remained limited, particularly in stochastic and data-driven settings. In this work, we establish a general, model-independent theorem providing sufficient conditions under which persistent entropy provably separates two phases. We show that persistent entropy exhibits an asymptotically non-vanishing gap across phases. The result relies only on continuity of persistent entropy along the convergent diagram sequence, or under mild regularization, and is therefore broadly applicable across data modalities, filtrations, and homological degrees. To connect asymptotic theory with finite-time computations, we introduce an operational framework based on topological stabilization, defining a topological transition time by stabilizing a chosen topological statistic over sliding windows, and a probability-based estimator of critical parameters within a finite observation horizon. We validate the framework on the Kuramoto synchronization transition, the Vicsek order-to-disorder transition in collective motion, and neural network training dynamics across multiple datasets and architectures. Across all experiments, stabilization of persistent entropy and collapse of variability across realizations provide robust numerical signatures consistent with the theoretical mechanism.",
      "tldr_zh": "该研究探讨了持久熵 (Persistent entropy, PE) 作为复杂系统相变探测器的理论基础与应用框架，旨在解决该领域长期以来缺乏普遍理论支撑的问题。作者建立了一个通用的、独立于模型的定理，为 PE 可证明地分离不同相提供了充分条件，并揭示了其在不同相之间具有渐进式且不消失的差距。该理论具有广泛的适用性，可跨越各种数据模态、过滤 (filtrations) 和同调阶数 (homological degrees) 进行应用。此外，研究引入了一个基于拓扑稳定性的操作框架，通过滑动窗口定义拓扑转换时间，并提出了用于在有限观测视野内估计关键参数的概率估计器。通过对 Kuramoto 同步转换、Vicsek 集体运动以及神经网络训练动态的实验验证，该研究证实了持久熵的稳定性及其变异性的消除可作为识别相变的稳健数值特征。这些成果不仅在数学上证明了 PE 的有效性，也为处理随机和数据驱动环境下的复杂系统提供了强有力的拓扑分析工具。",
      "categories": [
        "stat.ML",
        "cs.AI",
        "cs.IT",
        "cs.LG"
      ],
      "primary_category": "stat.ML",
      "comment": "",
      "pdf_url": "https://arxiv.org/pdf/2602.09058v1",
      "published_date": "2026-02-08 17:01:26 UTC",
      "updated_date": "2026-02-08 17:01:26 UTC",
      "processing_status": "completed",
      "attempts": 1,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "llm_backup_calls": 0,
      "last_update": "2026-02-16T05:18:33.002939+00:00"
    },
    {
      "arxiv_id": "2602.08054v1",
      "title": "Epigraph-Guided Flow Matching for Safe and Performant Offline Reinforcement Learning",
      "title_zh": "基于上图引导流匹配的安全高性能离线强化学习",
      "authors": [
        "Manan Tayal",
        "Mumuksh Tayal"
      ],
      "abstract": "Offline reinforcement learning (RL) provides a compelling paradigm for training autonomous systems without the risks of online exploration, particularly in safety-critical domains. However, jointly achieving strong safety and performance from fixed datasets remains challenging. Existing safe offline RL methods often rely on soft constraints that allow violations, introduce excessive conservatism, or struggle to balance safety, reward optimization, and adherence to the data distribution. To address this, we propose Epigraph-Guided Flow Matching (EpiFlow), a framework that formulates safe offline RL as a state-constrained optimal control problem to co-optimize safety and performance. We learn a feasibility value function derived from an epigraph reformulation of the optimal control problem, thereby avoiding the decoupled objectives or post-hoc filtering common in prior work. Policies are synthesized by reweighting the behavior distribution based on this epigraph value function and fitting a generative policy via flow matching, enabling efficient, distribution-consistent sampling. Across various safety-critical tasks, including Safety-Gymnasium benchmarks, EpiFlow achieves competitive returns with near-zero empirical safety violations, demonstrating the effectiveness of epigraph-guided policy synthesis.",
      "tldr_zh": "该研究提出了EpiFlow（Epigraph-Guided Flow Matching）框架，旨在解决安全离线强化学习（Safe Offline RL）在平衡安全性、性能优化与数据分布一致性方面面临的挑战。研究者将该问题建模为状态约束下的最优控制问题，并利用外图（Epigraph）重构推导出可行性价值函数，有效避免了传统方法中目标解耦或事后过滤的弊端。该框架通过外图价值函数对行为分布进行加权，并结合流匹配（Flow Matching）技术拟合生成式策略，实现了高效且符合分布特征的采样。实验结果表明，EpiFlow在Safety-Gymnasium等多个安全关键基准测试中，能够以近乎零的经验安全违规率获得极具竞争力的回报。该研究证明了外图引导的策略合成在提升离线强化学习安全性和性能方面的显著优势。",
      "categories": [
        "cs.LG",
        "cs.AI"
      ],
      "primary_category": "cs.LG",
      "comment": "23 pages, 8 figures",
      "pdf_url": "https://arxiv.org/pdf/2602.08054v1",
      "published_date": "2026-02-08 16:56:21 UTC",
      "updated_date": "2026-02-08 16:56:21 UTC",
      "processing_status": "completed",
      "attempts": 1,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "llm_backup_calls": 0,
      "last_update": "2026-02-16T05:18:47.109950+00:00"
    },
    {
      "arxiv_id": "2602.08052v1",
      "title": "Graph-Enhanced Deep Reinforcement Learning for Multi-Objective Unrelated Parallel Machine Scheduling",
      "title_zh": "图增强深度强化学习用于多目标不相关并行机调度问题",
      "authors": [
        "Bulent Soykan",
        "Sean Mondesire",
        "Ghaith Rabadi",
        "Grace Bochenek"
      ],
      "abstract": "The Unrelated Parallel Machine Scheduling Problem (UPMSP) with release dates, setups, and eligibility constraints presents a significant multi-objective challenge. Traditional methods struggle to balance minimizing Total Weighted Tardiness (TWT) and Total Setup Time (TST). This paper proposes a Deep Reinforcement Learning framework using Proximal Policy Optimization (PPO) and a Graph Neural Network (GNN). The GNN effectively represents the complex state of jobs, machines, and setups, allowing the PPO agent to learn a direct scheduling policy. Guided by a multi-objective reward function, the agent simultaneously minimizes TWT and TST. Experimental results on benchmark instances demonstrate that our PPO-GNN agent significantly outperforms a standard dispatching rule and a metaheuristic, achieving a superior trade-off between both objectives. This provides a robust and scalable solution for complex manufacturing scheduling.",
      "tldr_zh": "该研究探讨了具有发布日期、设置时间和资格限制的无关并行机调度问题 (Unrelated Parallel Machine Scheduling Problem, UPMSP)，这是一个旨在权衡最小化总加权推迟时间 (Total Weighted Tardiness, TWT) 和总设置时间 (Total Setup Time, TST) 的复杂多目标挑战。论文提出了一种结合近端策略优化 (Proximal Policy Optimization, PPO) 和图神经网络 (Graph Neural Network, GNN) 的深度强化学习 (Deep Reinforcement Learning) 框架。其中，GNN 有效地表征了作业、机器和设置的复杂状态，使得 PPO 智能体能够学习到直接的调度策略。在多目标奖励函数的引导下，该智能体能够同时优化 TWT 和 TST 两个目标。实验结果表明，该 PPO-GNN 智能体在基准测试中显著优于标准派工规则和元启发式算法，在两个目标之间实现了更优的权衡。该研究为复杂的制造调度提供了一种鲁棒且具有可扩展性的解决方案。",
      "categories": [
        "cs.AI",
        "cs.ET"
      ],
      "primary_category": "cs.AI",
      "comment": "11 pages, 2 figures, Winter Simulation Conference (WSC) 2025",
      "pdf_url": "https://arxiv.org/pdf/2602.08052v1",
      "published_date": "2026-02-08 16:54:47 UTC",
      "updated_date": "2026-02-08 16:54:47 UTC",
      "processing_status": "completed",
      "attempts": 1,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "llm_backup_calls": 0,
      "last_update": "2026-02-16T05:18:49.716444+00:00"
    },
    {
      "arxiv_id": "2602.08043v1",
      "title": "V-ABFT: Variance-Based Adaptive Threshold for Fault-Tolerant Matrix Multiplication in Mixed-Precision Deep Learning",
      "title_zh": "V-ABFT：混合精度深度学习中容错矩阵乘法的方差自适应阈值方法",
      "authors": [
        "Yiheng Gao",
        "Qin Hua",
        "Zizhong Chen"
      ],
      "abstract": "Algorithm-Based Fault Tolerance (ABFT) is widely adopted to detect silent data corruptions (SDCs) in matrix multiplication, a cornerstone operation in deep learning systems. However, existing threshold determination methods face critical challenges: analytical bounds are overly conservative, while probabilistic approaches like A-ABFT yield thresholds $160$--$4200\\times$ larger than actual rounding errors. We present V-ABFT, a variance-based adaptive threshold algorithm that achieves tighter error bounds by directly modeling the verification difference. By leveraging statistical variance estimation, V-ABFT reduces the threshold-to-actual-error ratio to approximately $7$--$20\\times$ for FP32/FP64 and $48$--$158\\times$ for BF16, representing a \\textbf{6--48$\\times$ improvement} over A-ABFT while maintaining zero false positive rate across BF16, FP16, FP32, and FP64 precisions. Furthermore, we demonstrate that for fused-kernel ABFT implementations that verify before output quantization, low-precision GEMM can use FP32-level thresholds ($e_{\\max} \\approx 10^{-6}$), enabling \\textbf{$\\sim$1000$\\times$ finer detection granularity} compared to offline verification with low-precision output ($e_{\\max} \\approx 10^{-3}$). We reproduce A-ABFT's experimental setup and validate our implementation against the original paper's results. Our method requires only $O(n)$ complexity using max/min/mean statistics, compared to A-ABFT's $O(pn)$ for finding $p$ largest values. Extensive experiments on synthetic data and real model weights (LLaMA-7B, GPT-2, ViT) demonstrate V-ABFT's effectiveness across diverse distributions. V-ABFT is platform-agnostic and has been integrated into fault-tolerant GEMM implementations on both NPUs and GPUs.",
      "tldr_zh": "该研究针对深度学习矩阵乘法中算法级容错(ABFT)技术存在的阈值设定过于保守或误差范围过大等挑战，提出了V-ABFT自适应阈值算法。该算法通过直接对验证差异进行建模并利用统计方差估计(statistical variance estimation)，在保持零误报率的前提下，将BF16、FP32和FP64等精度下的阈值误差比相比A-ABFT提升了6至48倍。V-ABFT通过融合内核(fused-kernel)实现在输出量化前进行验证，使低精度GEMM能够达到FP32级别的检测粒度，精度提升约1000倍。此外，该算法将计算复杂度从$O(pn)$优化至$O(n)$，显著提升了效率。在LLaMA-7B、GPT-2和ViT等真实模型权重上的实验证明了该方法在不同分布下的鲁棒性。目前V-ABFT已成功集成于NPU和GPU的容错GEMM实现中，展现出良好的平台无关性。",
      "categories": [
        "cs.LG",
        "cs.AI",
        "math.NA"
      ],
      "primary_category": "cs.LG",
      "comment": "",
      "pdf_url": "https://arxiv.org/pdf/2602.08043v1",
      "published_date": "2026-02-08 16:21:02 UTC",
      "updated_date": "2026-02-08 16:21:02 UTC",
      "processing_status": "completed",
      "attempts": 1,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "llm_backup_calls": 0,
      "last_update": "2026-02-16T05:18:51.212382+00:00"
    },
    {
      "arxiv_id": "2602.08041v1",
      "title": "Implicit Strategic Optimization: Rethinking Long-Horizon Decision-Making in Adversarial Poker Environments",
      "title_zh": "隐式策略优化：重新思考对抗性扑克环境下的长程决策",
      "authors": [
        "Boyang Xia",
        "Weiyou Tian",
        "Qingnan Ren",
        "Jiaqi Huang",
        "Jie Xiao",
        "Shuo Lu",
        "Kai Wang",
        "Lynn Ai",
        "Eric Yang",
        "Bill Shi"
      ],
      "abstract": "Training large language model (LLM) agents for adversarial games is often driven by episodic objectives such as win rate. In long-horizon settings, however, payoffs are shaped by latent strategic externalities that evolve over time, so myopic optimization and variation-based regret analyses can become vacuous even when the dynamics are predictable. To solve this problem, we introduce Implicit Strategic Optimization (ISO), a prediction-aware framework in which each agent forecasts the current strategic context and uses it to update its policy online. ISO combines a Strategic Reward Model (SRM) that estimates the long-run strategic value of actions with iso-grpo, a context-conditioned optimistic learning rule. We prove sublinear contextual regret and equilibrium convergence guarantees whose dominant terms scale with the number of context mispredictions; when prediction errors are bounded, our bounds recover the static-game rates obtained when strategic externalities are known. Experiments in 6-player No-Limit Texas Hold'em and competitive Pokemon show consistent improvements in long-term return over strong LLM and RL baselines, and graceful degradation under controlled prediction noise.",
      "tldr_zh": "该研究提出了 Implicit Strategic Optimization (ISO) 框架，旨在解决对抗性博弈中长周期决策面临的策略外部性问题。ISO 是一种预测感知框架，通过 Strategic Reward Model (SRM) 评估行动的长程策略价值，并结合名为 iso-grpo 的上下文条件乐观学习规则实现策略的在线更新。研究团队在理论上证明了该框架具有次线性上下文悔值和均衡收敛保证，其性能表现与背景预测的准确度直接相关。在 6 人制无限制 Texas Hold'em 和竞技性 Pokemon 的实验中，ISO 相比强力大语言模型 (LLM) 和强化学习 (RL) 基线在长期回报上展现出显著改进。实验结果进一步证明，即使在受控的预测噪声下，该模型仍能保持性能的平稳退化，体现了其在复杂对抗环境下进行稳健决策的能力。",
      "categories": [
        "cs.LG",
        "cs.AI",
        "cs.CL"
      ],
      "primary_category": "cs.LG",
      "comment": "",
      "pdf_url": "https://arxiv.org/pdf/2602.08041v1",
      "published_date": "2026-02-08 16:17:46 UTC",
      "updated_date": "2026-02-08 16:17:46 UTC",
      "processing_status": "completed",
      "attempts": 1,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "llm_backup_calls": 0,
      "last_update": "2026-02-16T05:18:52.189307+00:00"
    },
    {
      "arxiv_id": "2602.08040v1",
      "title": "FIRE: Frobenius-Isometry Reinitialization for Balancing the Stability-Plasticity Tradeoff",
      "title_zh": "FIRE：平衡稳定性与可塑性权衡的 Frobenius 等距重初始化",
      "authors": [
        "Isaac Han",
        "Sangyeon Park",
        "Seungwon Oh",
        "Donghu Kim",
        "Hojoon Lee",
        "Kyung-Joong Kim"
      ],
      "abstract": "Deep neural networks trained on nonstationary data must balance stability (i.e., retaining prior knowledge) and plasticity (i.e., adapting to new tasks). Standard reinitialization methods, which reinitialize weights toward their original values, are widely used but difficult to tune: conservative reinitializations fail to restore plasticity, while aggressive ones erase useful knowledge. We propose FIRE, a principled reinitialization method that explicitly balances the stability-plasticity tradeoff. FIRE quantifies stability through Squared Frobenius Error (SFE), measuring proximity to past weights, and plasticity through Deviation from Isometry (DfI), reflecting weight isotropy. The reinitialization point is obtained by solving a constrained optimization problem, minimizing SFE subject to DfI being zero, which is efficiently approximated by Newton-Schulz iteration. FIRE is evaluated on continual visual learning (CIFAR-10 with ResNet-18), language modeling (OpenWebText with GPT-0.1B), and reinforcement learning (HumanoidBench with SAC and Atari games with DQN). Across all domains, FIRE consistently outperforms both naive training without intervention and standard reinitialization methods, demonstrating effective balancing of the stability-plasticity tradeoff.",
      "tldr_zh": "该研究针对深度神经网络在非平稳数据训练中面临的稳定性(stability)与塑性(plasticity)权衡挑战，指出传统的重初始化方法(reinitialization methods)难以在保留知识与恢复学习能力之间取得理想平衡。为此，作者提出了 FIRE (Frobenius-Isometry Reinitialization)，这是一种显式平衡两者权衡的原理性重初始化方法。FIRE 通过平方弗罗贝尼乌斯误差(Squared Frobenius Error, SFE)量化稳定性以保留旧知识，并利用偏离等距程度(Deviation from Isometry, DfI)量化塑性以反映权重各向同性(isotropy)。通过求解受 DfI 约束的 SFE 最小化优化问题，并利用 Newton-Schulz iteration 进行高效近似，该方法能够精准确定重初始化点。在视觉学习(CIFAR-10)、语言建模(OpenWebText)及强化学习(HumanoidBench, Atari)等多领域的实验证明，FIRE 的性能一致优于无干预训练和标准重初始化方法。该研究为解决深度学习中的稳定性与塑性冲突提供了一种具有理论支撑且通用的有效方案。",
      "categories": [
        "cs.LG",
        "cs.AI"
      ],
      "primary_category": "cs.LG",
      "comment": "ICLR'26 (oral)",
      "pdf_url": "https://arxiv.org/pdf/2602.08040v1",
      "published_date": "2026-02-08 16:17:03 UTC",
      "updated_date": "2026-02-08 16:17:03 UTC",
      "processing_status": "completed",
      "attempts": 1,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "llm_backup_calls": 0,
      "last_update": "2026-02-16T05:19:02.584552+00:00"
    },
    {
      "arxiv_id": "2602.08030v2",
      "title": "Free(): Learning to Forget in Malloc-Only Reasoning Models",
      "title_zh": "Free()：在“仅分配”式推理模型中学习遗忘",
      "authors": [
        "Yilun Zheng",
        "Dongyang Ma",
        "Tian Liang",
        "Jiahao Xu",
        "Xinting Huang",
        "Lihui Chen",
        "Haitao Mi",
        "Yan Wang"
      ],
      "abstract": "Reasoning models enhance problem-solving by scaling test-time compute, yet they face a critical paradox: excessive thinking tokens often degrade performance rather than improve it. We attribute this to a fundamental architectural flaw: standard LLMs operate as \"malloc-only\" engines, continuously accumulating valid and redundant steps alike without a mechanism to prune obsolete information. To break this cycle, we propose Free()LM, a model that introduces an intrinsic self-forgetting capability via the Free-Module, a plug-and-play LoRA adapter. By iteratively switching between reasoning and cleaning modes, Free()LM dynamically identifies and prunes useless context chunks, maintaining a compact and noise-free state.\n  Extensive experiments show that Free()LM provides consistent improvements across all model scales (8B to 685B). It achieves a 3.3% average improvement over top-tier reasoning baselines, even establishing a new SOTA on IMOanswerBench using DeepSeek V3.2-Speciale. Most notably, in long-horizon tasks where the standard Qwen3-235B-A22B model suffers a total collapse (0% accuracy), Free()LM restores performance to 50%. Our findings suggest that sustainable intelligence requires the freedom to forget as much as the power to think.",
      "tldr_zh": "该研究探讨了推理模型在增加测试时计算量(test-time compute)时面临的性能下降悖论，将其归因于现有大语言模型(LLMs)类似“仅分配内存”(malloc-only)的架构缺陷，即只能持续累积冗余信息而缺乏剪枝机制。为此，作者提出了Free()LM模型，通过集成一个名为Free-Module的即插即用LoRA适配器，赋予模型内在的自我遗忘能力。该框架通过在推理与清理模式间动态切换，能够识别并剪枝无效的上下文块，从而维持模型状态的紧凑与无噪声。实验结果显示，Free()LM在8B至685B不同规模的模型上均实现了显著性能提升，并在IMOanswerBench上超越了DeepSeek V3.2-Speciale等顶尖基线，创下新的SOTA。特别是在Qwen3-235B-A22B模型表现完全崩溃的长程任务(long-horizon tasks)中，Free()LM成功将准确率从0%恢复至50%。这一发现表明，可持续的智能不仅需要强大的思考能力，同样需要自由遗忘冗余信息的能力。",
      "categories": [
        "cs.AI",
        "cs.CL"
      ],
      "primary_category": "cs.AI",
      "comment": "",
      "pdf_url": "https://arxiv.org/pdf/2602.08030v2",
      "published_date": "2026-02-08 16:04:23 UTC",
      "updated_date": "2026-02-10 05:58:13 UTC",
      "processing_status": "completed",
      "attempts": 1,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "llm_backup_calls": 0,
      "last_update": "2026-02-16T05:19:19.406739+00:00"
    },
    {
      "arxiv_id": "2602.08025v2",
      "title": "MIND: Benchmarking Memory Consistency and Action Control in World Models",
      "title_zh": "MIND：世界模型记忆一致性与动作控制基准测试",
      "authors": [
        "Yixuan Ye",
        "Xuanyu Lu",
        "Yuxin Jiang",
        "Yuchao Gu",
        "Rui Zhao",
        "Qiwei Liang",
        "Jiachun Pan",
        "Fengda Zhang",
        "Weijia Wu",
        "Alex Jinpeng Wang"
      ],
      "abstract": "World models aim to understand, remember, and predict dynamic visual environments, yet a unified benchmark for evaluating their fundamental abilities remains lacking. To address this gap, we introduce MIND, the first open-domain closed-loop revisited benchmark for evaluating Memory consIstency and action coNtrol in worlD models. MIND contains 250 high-quality videos at 1080p and 24 FPS, including 100 (first-person) + 100 (third-person) video clips under a shared action space and 25 + 25 clips across varied action spaces covering eight diverse scenes. We design an efficient evaluation framework to measure two core abilities: memory consistency and action control, capturing temporal stability and contextual coherence across viewpoints. Furthermore, we design various action spaces, including different character movement speeds and camera rotation angles, to evaluate the action generalization capability across different action spaces under shared scenes. To facilitate future performance benchmarking on MIND, we introduce MIND-World, a novel interactive Video-to-World baseline. Extensive experiments demonstrate the completeness of MIND and reveal key challenges in current world models, including the difficulty of maintaining long-term memory consistency and generalizing across action spaces. Code: https://github.com/CSU-JPG/MIND.",
      "tldr_zh": "该研究提出了MIND，这是首个用于评估世界模型(World Models)在记忆一致性(Memory Consistency)和动作控制(Action Control)能力的开源闭环基准测试。MIND包含250个高清视频剪辑，涵盖了八种不同场景下的第一人称与第三人称视角，并设计了包含不同移动速度和旋转角度的多样化动作空间。通过高效的评估框架，该基准能够衡量模型在不同视角下的时间稳定性和上下文连贯性，以及在不同动作空间下的泛化能力。此外，研究团队还推出了MIND-World这一交互式Video-to-World基准模型。实验结果揭示了当前世界模型在维持长期记忆一致性以及跨动作空间泛化方面面临的重大挑战。",
      "categories": [
        "cs.CV",
        "cs.AI"
      ],
      "primary_category": "cs.CV",
      "comment": "",
      "pdf_url": "https://arxiv.org/pdf/2602.08025v2",
      "published_date": "2026-02-08 15:57:23 UTC",
      "updated_date": "2026-02-11 18:42:39 UTC",
      "processing_status": "completed",
      "attempts": 1,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "llm_backup_calls": 0,
      "last_update": "2026-02-16T05:19:15.815327+00:00"
    },
    {
      "arxiv_id": "2602.08024v1",
      "title": "FlashVID: Efficient Video Large Language Models via Training-free Tree-based Spatiotemporal Token Merging",
      "title_zh": "FlashVID：通过无需训练的基于树的空时 Token 合并实现高效视频大语言模型",
      "authors": [
        "Ziyang Fan",
        "Keyu Chen",
        "Ruilong Xing",
        "Yulin Li",
        "Li Jiang",
        "Zhuotao Tian"
      ],
      "abstract": "Although Video Large Language Models (VLLMs) have shown remarkable capabilities in video understanding, they are required to process high volumes of visual tokens, causing significant computational inefficiency. Existing VLLMs acceleration frameworks usually compress spatial and temporal redundancy independently, which overlooks the spatiotemporal relationships, thereby leading to suboptimal spatiotemporal compression. The highly correlated visual features are likely to change in spatial position, scale, orientation, and other attributes over time due to the dynamic nature of video. Building on this insight, we introduce FlashVID, a training-free inference acceleration framework for VLLMs. Specifically, FlashVID utilizes Attention and Diversity-based Token Selection (ADTS) to select the most representative tokens for basic video representation, then applies Tree-based Spatiotemporal Token Merging (TSTM) for fine-grained spatiotemporal redundancy elimination. Extensive experiments conducted on three representative VLLMs across five video understanding benchmarks demonstrate the effectiveness and generalization of our method. Notably, by retaining only 10% of visual tokens, FlashVID preserves 99.1% of the performance of LLaVA-OneVision. Consequently, FlashVID can serve as a training-free and plug-and-play module for extending long video frames, which enables a 10x increase in video frame input to Qwen2.5-VL, resulting in a relative improvement of 8.6% within the same computational budget. Code is available at https://github.com/Fanziyang-v/FlashVID.",
      "tldr_zh": "该研究提出了 FlashVID，一种针对视频大语言模型 (Video Large Language Models, VLLMs) 的免训练推理加速框架，旨在解决处理海量视觉令牌带来的计算低效问题。不同于以往独立压缩空域和时域冗余的方法，FlashVID 引入了基于注意力和多样性的令牌选择 (Attention and Diversity-based Token Selection, ADTS) 来提取最具代表性的基础视频表征，并结合基于树结构的空时令牌合并 (Tree-based Spatiotemporal Token Merging, TSTM) 来实现细粒度的冗余消除。实验结果表明，该框架在保留仅 10% 视觉令牌的情况下，仍能维持 LLaVA-OneVision 99.1% 的性能。此外，FlashVID 作为即插即用模块，使 Qwen2.5-VL 在相同计算预算下能够处理 10 倍的视频帧数，并在长视频理解上实现了 8.6% 的相对性能提升。该方法不仅证明了卓越的泛化能力，还为长视频内容的高效处理提供了实用且无需重新训练的解决方案。",
      "categories": [
        "cs.CV",
        "cs.AI",
        "cs.CL",
        "cs.LG"
      ],
      "primary_category": "cs.CV",
      "comment": "Accepted by ICLR 2026 (Oral)",
      "pdf_url": "https://arxiv.org/pdf/2602.08024v1",
      "published_date": "2026-02-08 15:56:46 UTC",
      "updated_date": "2026-02-08 15:56:46 UTC",
      "processing_status": "completed",
      "attempts": 1,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "llm_backup_calls": 0,
      "last_update": "2026-02-16T05:19:17.504439+00:00"
    },
    {
      "arxiv_id": "2602.08023v2",
      "title": "CyberExplorer: Benchmarking LLM Offensive Security Capabilities in a Real-World Attacking Simulation Environment",
      "title_zh": "CyberExplorer：真实攻击模拟环境下大语言模型进攻性安全能力的评估基准",
      "authors": [
        "Nanda Rani",
        "Kimberly Milner",
        "Minghao Shao",
        "Meet Udeshi",
        "Haoran Xi",
        "Venkata Sai Charan Putrevu",
        "Saksham Aggarwal",
        "Sandeep K. Shukla",
        "Prashanth Krishnamurthy",
        "Farshad Khorrami",
        "Muhammad Shafique",
        "Ramesh Karri"
      ],
      "abstract": "Real-world offensive security operations are inherently open-ended: attackers explore unknown attack surfaces, revise hypotheses under uncertainty, and operate without guaranteed success. Existing LLM-based offensive agent evaluations rely on closed-world settings with predefined goals and binary success criteria. To address this gap, we introduce CyberExplorer, an evaluation suite with two core components: (1) an open-environment benchmark built on a virtual machine hosting 40 vulnerable web services derived from real-world CTF challenges, where agents autonomously perform reconnaissance, target selection, and exploitation without prior knowledge of vulnerability locations; and (2) a reactive multi-agent framework supporting dynamic exploration without predefined plans. CyberExplorer enables fine-grained evaluation beyond flag recovery, capturing interaction dynamics, coordination behavior, failure modes, and vulnerability discovery signals-bridging the gap between benchmarks and realistic multi-target attack scenarios.",
      "tldr_zh": "该研究指出，现有的大语言模型（LLM）攻防安全评估多依赖于预定义目标和二元成功标准的闭环环境，难以模拟现实中充满不确定性的开放式攻击。为了填补这一空白，研究者提出了CyberExplorer评估套件，旨在真实攻击模拟环境中基准化大语言模型的进攻性安全能力。该套件包含一个基于虚拟机的开放环境基准测试（Benchmark），通过托管40个源自真实Capture The Flag（CTF）挑战的有漏洞Web服务，要求智能体在无先验知识的情况下自主进行侦察、目标选择和漏洞利用。此外，该研究还引入了一个反应式多智能体（Multi-agent）框架，支持在没有预定义计划的情况下进行动态探索。CyberExplorer实现了超出Flag获取的细粒度评估，能够有效捕捉交互动态、协作行为、失败模式及漏洞发现信号。该工作成功弥合了现有基准测试与现实多目标攻击场景之间的差距，为评估智能体在复杂网络环境中的实战表现提供了重要工具。",
      "categories": [
        "cs.CR",
        "cs.AI",
        "cs.MA"
      ],
      "primary_category": "cs.CR",
      "comment": "",
      "pdf_url": "https://arxiv.org/pdf/2602.08023v2",
      "published_date": "2026-02-08 15:56:22 UTC",
      "updated_date": "2026-02-10 18:48:10 UTC",
      "processing_status": "completed",
      "attempts": 1,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "llm_backup_calls": 0,
      "last_update": "2026-02-16T05:19:28.013504+00:00"
    },
    {
      "arxiv_id": "2602.08021v1",
      "title": "Structure-Aware Robust Counterfactual Explanations via Conditional Gaussian Network Classifiers",
      "title_zh": "基于条件高斯网络分类器的结构感知鲁棒反事实解释",
      "authors": [
        "Zhan-Yi Liao",
        "Jaewon Yoo",
        "Hao-Tsung Yang",
        "Po-An Chen"
      ],
      "abstract": "Counterfactual explanation (CE) is a core technique in explainable artificial intelligence (XAI), widely used to interpret model decisions and suggest actionable alternatives. This work presents a structure-aware and robustness-oriented counterfactual search method based on the conditional Gaussian network classifier (CGNC). The CGNC has a generative structure that encodes conditional dependencies and potential causal relations among features through a directed acyclic graph (DAG). This structure naturally embeds feature relationships into the search process, eliminating the need for additional constraints to ensure consistency with the model's structural assumptions. We adopt a convergence-guaranteed cutting-set procedure as an adversarial optimization framework, which iteratively approximates solutions that satisfy global robustness conditions. To address the nonconvex quadratic structure induced by feature dependencies, we apply piecewise McCormick relaxation to reformulate the problem as a mixed-integer linear program (MILP), ensuring global optimality. Experimental results show that our method achieves strong robustness, with direct global optimization of the original formulation providing especially stable and efficient results. The proposed framework is extensible to more complex constraint settings, laying the groundwork for future advances in counterfactual reasoning under nonconvex quadratic formulations.",
      "tldr_zh": "该研究提出了一种基于条件高斯网络分类器(Conditional Gaussian Network Classifier, CGNC)的结构感知且面向鲁棒性的反事实解释(Counterfactual Explanation, CE)搜索方法。CGNC利用其生成式结构通过有向无环图(Directed Acyclic Graph, DAG)编码特征间的条件依赖和潜在因果关系，将特征关系自然嵌入搜索过程，从而消除了为确保模型一致性而添加额外约束的需求。研究采用了具有收敛保证的割集程序(Cutting-set procedure)作为对抗优化框架，通过迭代逼近满足全局鲁棒条件的解。针对特征依赖引发的非凸二次结构，该方法应用分段McCormick松弛技术将问题重构为混合整数线性规划(Mixed-Integer Linear Program, MILP)，确保了求解的全局最优性。实验结果表明，该方法在鲁棒性方面表现优异，其直接全局优化方案在复杂约束环境下表现出高度的稳定性和效率。该框架为非凸二次公式下的反事实推理研究奠定了基础，并具有扩展到更复杂约束设置的潜力。",
      "categories": [
        "cs.AI"
      ],
      "primary_category": "cs.AI",
      "comment": "",
      "pdf_url": "https://arxiv.org/pdf/2602.08021v1",
      "published_date": "2026-02-08 15:51:45 UTC",
      "updated_date": "2026-02-08 15:51:45 UTC",
      "processing_status": "completed",
      "attempts": 1,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "llm_backup_calls": 0,
      "last_update": "2026-02-16T05:19:36.202746+00:00"
    },
    {
      "arxiv_id": "2602.10139v1",
      "title": "Anonymization-Enhanced Privacy Protection for Mobile GUI Agents: Available but Invisible",
      "title_zh": "移动 GUI 智能体的匿名增强型隐私保护：可用而不可见",
      "authors": [
        "Lepeng Zhao",
        "Zhenhua Zou",
        "Shuo Li",
        "Zhuotao Liu"
      ],
      "abstract": "Mobile Graphical User Interface (GUI) agents have demonstrated strong capabilities in automating complex smartphone tasks by leveraging multimodal large language models (MLLMs) and system-level control interfaces. However, this paradigm introduces significant privacy risks, as agents typically capture and process entire screen contents, thereby exposing sensitive personal data such as phone numbers, addresses, messages, and financial information. Existing defenses either reduce UI exposure, obfuscate only task-irrelevant content, or rely on user authorization, but none can protect task-critical sensitive information while preserving seamless agent usability.\n  We propose an anonymization-based privacy protection framework that enforces the principle of available-but-invisible access to sensitive data: sensitive information remains usable for task execution but is never directly visible to the cloud-based agent. Our system detects sensitive UI content using a PII-aware recognition model and replaces it with deterministic, type-preserving placeholders (e.g., PHONE_NUMBER#a1b2c) that retain semantic categories while removing identifying details. A layered architecture comprising a PII Detector, UI Transformer, Secure Interaction Proxy, and Privacy Gatekeeper ensures consistent anonymization across user instructions, XML hierarchies, and screenshots, mediates all agent actions over anonymized interfaces, and supports narrowly scoped local computations when reasoning over raw values is necessary.\n  Extensive experiments on the AndroidLab and PrivScreen benchmarks show that our framework substantially reduces privacy leakage across multiple models while incurring only modest utility degradation, achieving the best observed privacy-utility trade-off among existing methods.",
      "tldr_zh": "该研究提出了一个基于匿名化的隐私保护框架，遵循“可用但不可见”(available-but-invisible)的原则，旨在解决移动图形用户界面(GUI)智能体在处理屏幕内容时面临的敏感个人数据泄露风险。该系统利用感知个人身份信息(PII)的识别模型检测敏感UI内容，并将其替换为保留语义类别但移除识别细节的确定性占位符，从而确保云端智能体无法直接接触原始数据。框架由PII Detector、UI Transformer、Secure Interaction Proxy和Privacy Gatekeeper组成的多层架构，实现了用户指令、XML层次结构和屏幕截图的跨模态一致匿名化，并在必要时支持局部的窄范围计算以处理原始值。在AndroidLab和PrivScreen基准测试上的实验表明，该框架在大幅降低隐私泄露的同时，仅产生极小的效用损失，在现有防御方法中实现了最佳的隐私与效用平衡。",
      "categories": [
        "cs.CR",
        "cs.AI"
      ],
      "primary_category": "cs.CR",
      "comment": "15 pages, 4 figures",
      "pdf_url": "https://arxiv.org/pdf/2602.10139v1",
      "published_date": "2026-02-08 15:50:04 UTC",
      "updated_date": "2026-02-08 15:50:04 UTC",
      "processing_status": "completed",
      "attempts": 1,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "llm_backup_calls": 0,
      "last_update": "2026-02-16T05:19:33.218116+00:00"
    },
    {
      "arxiv_id": "2602.08019v1",
      "title": "The Rise of Sparse Mixture-of-Experts: A Survey from Algorithmic Foundations to Decentralized Architectures and Vertical Domain Applications",
      "title_zh": "稀疏混合专家模型 (MoE) 的兴起：从算法基础到去中心化架构及垂直领域应用的综述",
      "authors": [
        "Dong Pan",
        "Bingtao Li",
        "Yongsheng Zheng",
        "Jiren Ma",
        "Victor Fei"
      ],
      "abstract": "The sparse Mixture of Experts(MoE) architecture has evolved as a powerful approach for scaling deep learning models to more parameters with comparable computation cost. As an important branch of large language model(LLM), MoE model only activate a subset of experts based on a routing network. This sparse conditional computation mechanism significantly improves computational efficiency, paving a promising path for greater scalability and cost-efficiency. It not only enhance downstream applications such as natural language processing, computer vision, and multimodal in various horizontal domains, but also exhibit broad applicability across vertical domains. Despite the growing popularity and application of MoE models across various domains, there lacks a systematic exploration of recent advancements of MoE in many important fields. Existing surveys on MoE suffer from limitations such as lack coverage or none extensively exploration of key areas. This survey seeks to fill these gaps. In this paper, Firstly, we examine the foundational principles of MoE, with an in-depth exploration of its core components-the routing network and expert network. Subsequently, we extend beyond the centralized paradigm to the decentralized paradigm, which unlocks the immense untapped potential of decentralized infrastructure, enables democratization of MoE development for broader communities, and delivers greater scalability and cost-efficiency. Furthermore we focus on exploring its vertical domain applications. Finally, we also identify key challenges and promising future research directions. To the best of our knowledge, this survey is currently the most comprehensive review in the field of MoE. We aim for this article to serve as a valuable resource for both researchers and practitioners, enabling them to navigate and stay up-to-date with the latest advancements.",
      "tldr_zh": "该研究系统综述了稀疏混合专家模型(Sparse Mixture-of-Experts, MoE)从算法基础到去中心化架构及垂直领域应用的发展历程。MoE通过路由网络(routing network)仅激活部分专家网络(expert network)的稀疏条件计算机制，在保持计算成本可控的前提下显著提升了大语言模型(LLM)的参数规模与效率。本文深入解析了MoE的核心组件，并重点探讨了从中心化向去中心化(decentralized)架构的范式演进，强调其在实现技术民主化、提升扩展性和成本效益方面的巨大潜力。此外，该综述全面覆盖了MoE在多个垂直领域的应用现状，并总结了当前面临的关键挑战与未来研究方向。作为目前该领域最为全面的综述，该文章为理解和应用高性能稀疏模型提供了系统的理论支持与实践指导。",
      "categories": [
        "cs.LG",
        "cs.AI"
      ],
      "primary_category": "cs.LG",
      "comment": "",
      "pdf_url": "https://arxiv.org/pdf/2602.08019v1",
      "published_date": "2026-02-08 15:39:10 UTC",
      "updated_date": "2026-02-08 15:39:10 UTC",
      "processing_status": "completed",
      "attempts": 1,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "llm_backup_calls": 0,
      "last_update": "2026-02-16T05:19:39.904627+00:00"
    },
    {
      "arxiv_id": "2602.08014v1",
      "title": "ICBAC: an Intelligent Contract-Based Access Control framework for supply chain management by integrating blockchain and federated learning",
      "title_zh": "ICBAC：融合区块链与联邦学习的供应链管理智能合约访问控制框架",
      "authors": [
        "Sadegh Sohani",
        "Salar Ghazi",
        "Farnaz Kamranfar",
        "Sahar Pilehvar Moakhar",
        "Mohammad Allahbakhsh",
        "Haleh Amintoosi",
        "Kaiwen Zhang"
      ],
      "abstract": "This paper addresses the critical challenge of access control in modern supply chains, which operate across multiple independent and competing organizations. Existing access control is static and centralized, unable to adapt to insider threats or evolving contexts. Blockchain improves decentralization but lacks behavioral intelligence, while centralized machine learning for anomaly detection requires aggregating sensitive data, violating privacy.\n  The proposed solution is ICBAC, an intelligent contract-based access control framework. It integrates permissioned blockchain (Hyperledger Fabric) with federated learning (FL). Built on Fabric, ICBAC uses a multi-channel architecture and three smart contracts for asset management, baseline access control, and dynamic revocation. To counter insider misuse, each channel deploys an AI agent that monitors activity and dynamically restricts access for anomalies. Federated learning allows these agents to collaboratively improve detection models without sharing raw data.\n  For heterogeneous, competitive environments, ICBAC introduces a game-theoretic client selection mechanism using hedonic coalition formation. This enables supply chains to form stable, strategy-proof FL coalitions via preference-based selection without disclosing sensitive criteria. Extensive experiments on a Fabric testbed with a real-world dataset show ICBAC achieves blockchain performance comparable to static frameworks and provides effective anomaly detection under IID and non-IID data with zero raw-data sharing. ICBAC thus offers a practical, scalable solution for dynamic, privacy-preserving access control in decentralized supply chains.",
      "tldr_zh": "该研究提出了ICBAC，一种整合了区块链(Blockchain)与联邦学习(Federated Learning)的智能合约访问控制框架，旨在解决现代供应链中静态、中心化访问控制难以应对内部威胁及隐私泄露的挑战。该框架基于Hyperledger Fabric构建，通过多通道架构和资产管理、基准访问控制、动态撤销三类智能合约实现去中心化管理。ICBAC在各通道部署AI智能体实时监测异常行为，并利用联邦学习在不共享原始数据的前提下通过跨组织协作提升检测模型性能。针对异构竞争环境，该研究引入了基于享乐联盟博弈(Hedonic Coalition Formation)的客户端选择机制，确保供应链各方在不泄露敏感准则的情况下形成稳定的协作联盟。实验结果表明，ICBAC在Fabric测试平台上达到了与静态框架相当的区块链性能，并在独立同分布(IID)和非独立同分布(non-IID)数据下均表现出出色的异常检测能力，为去中心化供应链提供了可扩展且保护隐私的动态访问控制方案。",
      "categories": [
        "cs.CR",
        "cs.AI"
      ],
      "primary_category": "cs.CR",
      "comment": "19 pages, 6 Figures, 3 Tables",
      "pdf_url": "https://arxiv.org/pdf/2602.08014v1",
      "published_date": "2026-02-08 15:27:58 UTC",
      "updated_date": "2026-02-08 15:27:58 UTC",
      "processing_status": "completed",
      "attempts": 1,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "llm_backup_calls": 0,
      "last_update": "2026-02-16T05:19:40.189054+00:00"
    },
    {
      "arxiv_id": "2602.08013v1",
      "title": "Small Agent Group is the Future of Digital Health",
      "title_zh": "小智能体群是数字健康的未来",
      "authors": [
        "Yuqiao Meng",
        "Luoxi Tang",
        "Dazheng Zhang",
        "Rafael Brens",
        "Elvys J. Romero",
        "Nancy Guo",
        "Safa Elkefi",
        "Zhaohan Xi"
      ],
      "abstract": "The rapid adoption of large language models (LLMs) in digital health has been driven by a \"scaling-first\" philosophy, i.e., the assumption that clinical intelligence increases with model size and data. However, real-world clinical needs include not only effectiveness, but also reliability and reasonable deployment cost. Since clinical decision-making is inherently collaborative, we challenge the monolithic scaling paradigm and ask whether a Small Agent Group (SAG) can support better clinical reasoning. SAG shifts from single-model intelligence to collective expertise by distributing reasoning, evidence-based analysis, and critical audit through a collaborative deliberation process. To assess the clinical utility of SAG, we conduct extensive evaluations using diverse clinical metrics spanning effectiveness, reliability, and deployment cost. Our results show that SAG achieves superior performance compared to a single giant model, both with and without additional optimization or retrieval-augmented generation. These findings suggest that the synergistic reasoning represented by SAG can substitute for model parameter growth in clinical settings. Overall, SAG offers a scalable solution to digital health that better balances effectiveness, reliability, and deployment efficiency.",
      "tldr_zh": "针对数字健康领域过度依赖模型参数规模（\"scaling-first\"）而忽视部署成本和可靠性的现状，该研究提出了名为 Small Agent Group (SAG) 的多智能体协作框架。SAG 模仿了临床决策中的协作本质，将推理、证据分析和批判性审计等任务分布在多个小型智能体中，通过协作审议过程（collaborative deliberation process）实现集体专业知识。研究者通过涵盖有效性、可靠性和部署成本的多种临床指标对 SAG 进行了广泛评估。实验结果显示，无论是否结合检索增强生成 (RAG) 或额外优化，SAG 的表现均优于单一的大型模型。该研究证明了 SAG 代表的协同推理可以替代模型规模的盲目增长，为数字健康领域提供了一个能够平衡性能、可靠性与部署效率的可扩展解决方案。",
      "categories": [
        "cs.AI"
      ],
      "primary_category": "cs.AI",
      "comment": "",
      "pdf_url": "https://arxiv.org/pdf/2602.08013v1",
      "published_date": "2026-02-08 15:27:37 UTC",
      "updated_date": "2026-02-08 15:27:37 UTC",
      "processing_status": "completed",
      "attempts": 1,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "llm_backup_calls": 0,
      "last_update": "2026-02-16T05:19:42.243127+00:00"
    },
    {
      "arxiv_id": "2602.08009v1",
      "title": "Towards Adaptive, Scalable, and Robust Coordination of LLM Agents: A Dynamic Ad-Hoc Networking Perspective",
      "title_zh": "迈向自适应、可扩展且鲁棒的大语言模型智能体协同：动态自组织网络视角",
      "authors": [
        "Rui Li",
        "Zeyu Zhang",
        "Xiaohe Bo",
        "Quanyu Dai",
        "Chaozhuo Li",
        "Feng Wen",
        "Xu Chen"
      ],
      "abstract": "Multi-agent architectures built on large language models (LLMs) have demonstrated the potential to realize swarm intelligence through well-crafted collaboration. However, the substantial burden of manual orchestration inherently raises an imperative to automate the design of agentic workflows. We frame such an agent coordination challenge as a classic problem in dynamic ad-hoc networking: How to establish adaptive and reliable communication among a scalable number of agentic hosts? In response to this unresolved dilemma, we introduce RAPS, a reputation-aware publish-subscribe paradigm for adaptive, scalable, and robust coordination of LLM agents. RAPS is grounded in the Distributed Publish-Subscribe Protocol, allowing LLM agents to exchange messages based on their declared intents rather than predefined topologies. Beyond this substrate, RAPS further incorporates two coherent overlays: (i) Reactive Subscription, enabling agents to dynamically refine their intents; and (ii) Bayesian Reputation, empowering each agent with a local watchdog to detect and isolate malicious peers. Extensive experiments over five benchmarks showcase that our design effectively reconciles adaptivity, scalability, and robustness in a unified multi-agent coordination framework.",
      "tldr_zh": "该研究针对大型语言模型（LLM）多智能体架构中手动编排负担重的问题，提出将智能体协调挑战视为动态自组织网络（dynamic ad-hoc networking）中的通信建立问题。为此，研究者引入了 RAPS，一种具有信誉感知能力的发布-订阅（reputation-aware publish-subscribe）范式，旨在实现自适应、可扩展且稳健的 LLM 智能体协调。RAPS 基于分布式发布-订阅协议（Distributed Publish-Subscribe Protocol），允许智能体根据声明的意图（intents）而非预定义的拓扑结构交换信息。此外，该框架集成了反应式订阅（Reactive Subscription）以供智能体动态精炼其意图，以及贝叶斯信誉（Bayesian Reputation）机制，利用本地监视器（local watchdog）来检测并隔离恶意智能体。在五个基准测试上的广泛实验表明，该设计在一个统一的多智能体协调框架中有效实现了自适应性、可扩展性和鲁棒性的平衡。",
      "categories": [
        "cs.AI",
        "cs.CL"
      ],
      "primary_category": "cs.AI",
      "comment": "",
      "pdf_url": "https://arxiv.org/pdf/2602.08009v1",
      "published_date": "2026-02-08 15:26:02 UTC",
      "updated_date": "2026-02-08 15:26:02 UTC",
      "processing_status": "completed",
      "attempts": 1,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "llm_backup_calls": 0,
      "last_update": "2026-02-16T05:19:55.639190+00:00"
    },
    {
      "arxiv_id": "2602.08007v1",
      "title": "From $O(mn)$ to $O(r^2)$: Two-Sided Low-Rank Communication for Adam in Distributed Training with Memory Efficiency",
      "title_zh": "从 $O(mn)$ 到 $O(r^2)$：分布式训练中兼具显存效率的 Adam 双边低秩通信",
      "authors": [
        "Sizhe Dang",
        "Jiaqi Shao",
        "Xiaodong Zheng",
        "Guang Dai",
        "Yan Song",
        "Haishan Ye"
      ],
      "abstract": "As foundation models continue to scale, pretraining increasingly relies on data-parallel distributed optimization, making bandwidth-limited gradient synchronization a key bottleneck. Orthogonally, projection-based low-rank optimizers were mainly designed for memory efficiency, but remain suboptimal for communication-limited training: one-sided synchronization still transmits an $O(rn)$ object for an $m\\times n$ matrix gradient and refresh steps can dominate peak communicated bytes. We propose TSR, which brings two-sided low-rank communication to Adam-family updates (TSR-Adam) by synchronizing a compact core $U^\\top G V\\in\\mathbb{R}^{r\\times r}$, reducing the dominant per-step payload from $O(mn)$ to $O(r^2)$ while keeping moment states in low-dimensional cores. To further reduce the peak communication from subspace refresh, TSR-Adam adopts a randomized SVD-based refresh that avoids full-gradient synchronization. We additionally extend low-rank communication to embedding gradients with embedding-specific ranks and refresh schedules, yielding additional communication and memory savings over keeping embeddings dense. Across pretraining from 60M to 1B model scales, TSR-Adam reduces average communicated bytes per step by $13\\times$, and on GLUE fine-tuning it reduces communication by $25\\times$, while achieving comparable performance; we further provide a theoretical stationarity analysis for the proposed update. Code is available at https://github.com/DKmiyan/TSR-Adam.",
      "tldr_zh": "该研究提出了TSR-Adam，这是一种针对Adam系列优化器的双边低秩通信(Two-Sided Low-Rank Communication)框架，旨在解决大规模分布式训练中受带宽限制的梯度同步瓶颈。通过同步一个紧凑的核心矩阵$U^\\top G V \\in \\mathbb{R}^{r \\times r}$，该框架将每步的主要通信负载从$O(mn)$大幅降低至$O(r^2)$，同时将动量状态维持在低维核心中以提升内存效率。为了进一步减少刷新子空间时的通信峰值，TSR-Adam引入了基于随机奇异值分解(Randomized SVD)的刷新机制，有效避免了全梯度同步。此外，该方案还被扩展至嵌入层梯度(Embedding Gradients)，通过特定秩和刷新计划实现了额外的通信与内存节省。实验结果表明，在60M至1B参数规模的预训练任务中，TSR-Adam平均每步通信字节数减少了13倍，在GLUE微调任务中减少了25倍，且保持了与基线模型相当的性能水平。该研究还为所提算法提供了理论上的平稳性分析(Stationarity Analysis)，证明了其在实际应用中的有效性。",
      "categories": [
        "cs.LG",
        "cs.AI"
      ],
      "primary_category": "cs.LG",
      "comment": "",
      "pdf_url": "https://arxiv.org/pdf/2602.08007v1",
      "published_date": "2026-02-08 15:23:09 UTC",
      "updated_date": "2026-02-08 15:23:09 UTC",
      "processing_status": "completed",
      "attempts": 1,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "llm_backup_calls": 0,
      "last_update": "2026-02-16T05:20:10.399451+00:00"
    },
    {
      "arxiv_id": "2602.08006v1",
      "title": "ForecastOcc: Vision-based Semantic Occupancy Forecasting",
      "title_zh": "ForecastOcc：基于视觉的语义占据预测",
      "authors": [
        "Riya Mohan",
        "Juana Valeria Hurtado",
        "Rohit Mohan",
        "Abhinav Valada"
      ],
      "abstract": "Autonomous driving requires forecasting both geometry and semantics over time to effectively reason about future environment states. Existing vision-based occupancy forecasting methods focus on motion-related categories such as static and dynamic objects, while semantic information remains largely absent. Recent semantic occupancy forecasting approaches address this gap but rely on past occupancy predictions obtained from separate networks. This makes current methods sensitive to error accumulation and prevents learning spatio-temporal features directly from images. In this work, we present ForecastOcc, the first framework for vision-based semantic occupancy forecasting that jointly predicts future occupancy states and semantic categories. Our framework yields semantic occupancy forecasts for multiple horizons directly from past camera images, without relying on externally estimated maps. We evaluate ForecastOcc in two complementary settings: multi-view forecasting on the Occ3D-nuScenes dataset and monocular forecasting on SemanticKITTI, where we establish the first benchmark for this task. We introduce the first baselines by adapting two 2D forecasting modules within our framework. Importantly, we propose a novel architecture that incorporates a temporal cross-attention forecasting module, a 2D-to-3D view transformer, a 3D encoder for occupancy prediction, and a semantic occupancy head for voxel-level forecasts across multiple horizons. Extensive experiments on both datasets show that ForecastOcc consistently outperforms baselines, yielding semantically rich, future-aware predictions that capture scene dynamics and semantics critical for autonomous driving.",
      "tldr_zh": "该研究提出了 ForecastOcc，这是第一个直接从摄像头图像联合预测未来 Occupancy 状态和 Semantic Categories 的视觉语义占据预测框架。现有的视觉占据预测方法通常侧重于运动类别而缺乏语义信息，或者依赖外部网络提供的过去预测结果，容易导致误差累积且难以直接从图像中学习时空特征。ForecastOcc 通过集成 Temporal Cross-attention 预测模块、2D-to-3D View Transformer、3D Encoder 以及语义占据头，实现了多时间跨度的 Voxel 级预测。该框架在 Occ3D-nuScenes 的多视图预测和 SemanticKITTI 的单目预测任务中均建立了首个基准。实验结果表明，ForecastOcc 在捕捉自动驾驶关键的场景动态与语义信息方面显著优于基线模型，为具备未来感知能力的语义占据预测提供了有效的解决方案。",
      "categories": [
        "cs.CV",
        "cs.AI",
        "cs.LG",
        "cs.RO"
      ],
      "primary_category": "cs.CV",
      "comment": "",
      "pdf_url": "https://arxiv.org/pdf/2602.08006v1",
      "published_date": "2026-02-08 15:16:06 UTC",
      "updated_date": "2026-02-08 15:16:06 UTC",
      "processing_status": "completed",
      "attempts": 1,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "llm_backup_calls": 0,
      "last_update": "2026-02-16T05:20:12.500565+00:00"
    },
    {
      "arxiv_id": "2602.08005v1",
      "title": "DeltaKV: Residual-Based KV Cache Compression via Long-Range Similarity",
      "title_zh": "DeltaKV：基于长程相似性的残差式 KV 缓存压缩",
      "authors": [
        "Jitai Hao",
        "Qiang Huang",
        "Yaowei Wang",
        "Min Zhang",
        "Jun Yu"
      ],
      "abstract": "The deployment of efficient long-context LLMs in applications like autonomous agents, long-chain reasoning, and creative writing is fundamentally bottlenecked by the linear growth of KV cache memory. Existing compression and eviction methods often struggle to balance accuracy, compression ratio, and hardware efficiency. We propose DeltaKV, a residual-based KV cache compression framework motivated by two empirical findings: long-range inter-token similarity and highly shared latent components in KV representations. Instead of discarding tokens, DeltaKV encodes semantic residuals relative to retrieved historical references, preserving fidelity while substantially reducing storage. To translate compression gains into real system speedups, we further introduce Sparse-vLLM, a high-performance inference engine with decoupled memory management and kernels optimized for sparse and irregular KV layouts. Experiments show that DeltaKV reduces KV cache memory to 29\\% of the original while maintaining near-lossless accuracy on LongBench, SCBench, and AIME. When integrated with Sparse-vLLM, it achieves up to 2$\\times$ throughput improvement over vLLM in long-context scenarios, demonstrating a practical path toward scalable long-context LLM deployment. Code, model checkpoints, and datasets are available at https://github.com/CURRENTF/Sparse-vLLM.",
      "tldr_zh": "该研究提出了 DeltaKV，一种基于残差的 KV Cache 压缩框架，旨在解决长文本大语言模型(LLMs)部署中 KV Cache 内存线性增长带来的瓶颈。DeltaKV 受到长程 Token 间相似性和 KV 表示中高度共享潜成分的启发，通过对相对于历史参考的语义残差(Residuals)进行编码来保留保真度，从而大幅减少存储需求而非简单丢弃 Token。为实现实际的系统提速，研究者还开发了高性能推理引擎 Sparse-vLLM，该引擎采用解耦的内存管理并针对稀疏且不规则的 KV 布局优化了算子内核。实验结果表明，DeltaKV 能将 KV Cache 内存减少至原始大小的 29%，且在 LongBench、SCBench 和 AIME 等数据集上保持近乎无损的准确率。在长文本场景下，该框架与 Sparse-vLLM 集成后，其吞吐量较 vLLM 提升了高达 2 倍，为实现可扩展的长文本 LLM 部署提供了有效的实践方案。",
      "categories": [
        "cs.CL",
        "cs.AI"
      ],
      "primary_category": "cs.CL",
      "comment": "preprint",
      "pdf_url": "https://arxiv.org/pdf/2602.08005v1",
      "published_date": "2026-02-08 15:14:36 UTC",
      "updated_date": "2026-02-08 15:14:36 UTC",
      "processing_status": "completed",
      "attempts": 1,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "llm_backup_calls": 0,
      "last_update": "2026-02-16T05:20:19.598838+00:00"
    },
    {
      "arxiv_id": "2602.08003v1",
      "title": "Don't Always Pick the Highest-Performing Model: An Information Theoretic View of LLM Ensemble Selection",
      "title_zh": "并非总是选择性能最高的模型：大语言模型集成选择的信息论视角",
      "authors": [
        "Yigit Turkmen",
        "Baturalp Buyukates",
        "Melih Bastopcu"
      ],
      "abstract": "Large language models (LLMs) are often ensembled together to improve overall reliability and robustness, but in practice models are strongly correlated. This raises a fundamental question: which models should be selected when forming an LLM ensemble? We formulate budgeted ensemble selection as maximizing the mutual information between the true label and predictions of the selected models. Furthermore, to explain why performance can saturate even with many models, we model the correlated errors of the models using Gaussian-copula and show an information-theoretic error floor for the performance of the ensemble. Motivated by these, we propose a simple greedy mutual-information selection algorithm that estimates the required information terms directly from data and iteratively builds an ensemble under a query budget. We test our approach in two question answering datasets and one binary sentiment classification dataset: MEDMCQA, MMLU, and IMDB movie reviews. Across all datasets, we observe that our method consistently outperforms strong baselines under the same query budget.",
      "tldr_zh": "该研究探讨了在大型语言模型 (LLMs) 集成过程中，由于模型间普遍存在强相关性而导致的模型选择难题。作者提出从信息论的角度出发，将受限预算下的集成选择建模为最大化真实标签与所选模型预测之间的互信息 (Mutual Information)。为了解释增加模型数量后性能趋于饱和的现象，研究采用 Gaussian-copula 对模型间的相关误差进行建模，并揭示了集成性能的信息论误差底线 (error floor)。基于此理论，研究提出了一种贪心互信息选择算法 (greedy mutual-information selection algorithm)，通过直接从数据中估计信息项来在预算内迭代构建最优集成。在 MEDMCQA、MMLU 和 IMDB 等多个数据集上的实验表明，该方法在相同查询预算下一致优于现有的强基准模型，为高效构建鲁棒的 LLM 集成系统提供了理论支撑与实用工具。",
      "categories": [
        "cs.LG",
        "cs.AI",
        "cs.DC",
        "cs.IT",
        "stat.ML"
      ],
      "primary_category": "cs.LG",
      "comment": "",
      "pdf_url": "https://arxiv.org/pdf/2602.08003v1",
      "published_date": "2026-02-08 15:05:22 UTC",
      "updated_date": "2026-02-08 15:05:22 UTC",
      "processing_status": "completed",
      "attempts": 1,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "llm_backup_calls": 0,
      "last_update": "2026-02-16T05:20:18.602603+00:00"
    },
    {
      "arxiv_id": "2602.07993v1",
      "title": "MCIE: Multimodal LLM-Driven Complex Instruction Image Editing with Spatial Guidance",
      "title_zh": "MCIE：基于空间引导的多模态大模型驱动复杂指令图像编辑",
      "authors": [
        "Xuehai Bai",
        "Xiaoling Gu",
        "Akide Liu",
        "Hangjie Yuan",
        "YiFan Zhang",
        "Jack Ma"
      ],
      "abstract": "Recent advances in instruction-based image editing have shown remarkable progress. However, existing methods remain limited to relatively simple editing operations, hindering real-world applications that require complex and compositional instructions. In this work, we address these limitations from the perspectives of architectural design, data, and evaluation protocols. Specifically, we identify two key challenges in current models: insufficient instruction compliance and background inconsistency. To this end, we propose MCIE-E1, a Multimodal Large Language Model-Driven Complex Instruction Image Editing method that integrates two key modules: a spatial-aware cross-attention module and a background-consistent cross-attention module. The former enhances instruction-following capability by explicitly aligning semantic instructions with spatial regions through spatial guidance during the denoising process, while the latter preserves features in unedited regions to maintain background consistency. To enable effective training, we construct a dedicated data pipeline to mitigate the scarcity of complex instruction-based image editing datasets, combining fine-grained automatic filtering via a powerful MLLM with rigorous human validation. Finally, to comprehensively evaluate complex instruction-based image editing, we introduce CIE-Bench, a new benchmark with two new evaluation metrics. Experimental results on CIE-Bench demonstrate that MCIE-E1 consistently outperforms previous state-of-the-art methods in both quantitative and qualitative assessments, achieving a 23.96% improvement in instruction compliance.",
      "tldr_zh": "该研究针对现有基于指令的图像编辑方法在处理复杂和组合指令时面临的指令遵循度不足和背景不一致问题，提出了由多模态大语言模型（Multimodal Large Language Model）驱动的编辑框架 MCIE-E1。该框架集成了空间感知交叉注意力模块 (spatial-aware cross-attention module) 以增强指令与空间区域的语义对齐，并利用背景一致性交叉注意力模块 (background-consistent cross-attention module) 维护非编辑区域的特征稳定性。研究团队还构建了一个结合 MLLM 自动过滤与人工验证的专用数据流水线，有效缓解了复杂指令图像编辑数据集匮乏的现状。此外，论文引入了全新的评测基准 CIE-Bench 及其评估指标，旨在更全面地衡量模型性能。实验结果证明，MCIE-E1 在定量和定性评估中均显著优于现有最先进方法，其指令遵循能力提升了 23.96%，为实现更复杂的现实图像编辑应用提供了技术支撑。",
      "categories": [
        "cs.CV",
        "cs.AI"
      ],
      "primary_category": "cs.CV",
      "comment": "Accepted by AAAI2026",
      "pdf_url": "https://arxiv.org/pdf/2602.07993v1",
      "published_date": "2026-02-08 14:40:54 UTC",
      "updated_date": "2026-02-08 14:40:54 UTC",
      "processing_status": "completed",
      "attempts": 1,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "llm_backup_calls": 0,
      "last_update": "2026-02-16T05:20:23.702771+00:00"
    },
    {
      "arxiv_id": "2602.07983v1",
      "title": "Accelerating Social Science Research via Agentic Hypothesization and Experimentation",
      "title_zh": "通过代理化假设与实验加速社会科学研究",
      "authors": [
        "Jishu Sen Gupta",
        "Harini SI",
        "Somesh Kumar Singh",
        "Syed Mohamad Tawseeq",
        "Yaman Kumar Singla",
        "David Doermann",
        "Rajiv Ratn Shah",
        "Balaji Krishnamurthy"
      ],
      "abstract": "Data-driven social science research is inherently slow, relying on iterative cycles of observation, hypothesis generation, and experimental validation. While recent data-driven methods promise to accelerate parts of this process, they largely fail to support end-to-end scientific discovery. To address this gap, we introduce EXPERIGEN, an agentic framework that operationalizes end-to-end discovery through a Bayesian optimization inspired two-phase search, in which a Generator proposes candidate hypotheses and an Experimenter evaluates them empirically. Across multiple domains, EXPERIGEN consistently discovers 2-4x more statistically significant hypotheses that are 7-17 percent more predictive than prior approaches, and naturally extends to complex data regimes including multimodal and relational datasets. Beyond statistical performance, hypotheses must be novel, empirically grounded, and actionable to drive real scientific progress. To evaluate these qualities, we conduct an expert review of machine-generated hypotheses, collecting feedback from senior faculty. Among 25 reviewed hypotheses, 88 percent were rated moderately or strongly novel, 70 percent were deemed impactful and worth pursuing, and most demonstrated rigor comparable to senior graduate-level research. Finally, recognizing that ultimate validation requires real-world evidence, we conduct the first A/B test of LLM-generated hypotheses, observing statistically significant results with p less than 1e-6 and a large effect size of 344 percent.",
      "tldr_zh": "该研究提出了 EXPERIGEN，一个旨在加速社会科学研究的智能体框架，通过实现端到端的科学发现流程来解决传统数据驱动研究周期缓慢的问题。该框架采用了受贝叶斯优化 (Bayesian optimization) 启发的两阶段搜索机制，由生成器 (Generator) 提出候选假设，并由实验器 (Experimenter) 进行实证评估。在多个领域的测试中，EXPERIGEN 发现的具有统计显著性的假设数量比以往方法多出 2-4 倍，预测准确性提高了 7-17%，并能有效处理多模态 (multimodal) 和关系型数据集。专家评审显示，88% 的生成假设被认为具有显著创新性，70% 被评为具有影响力且值得追求，其严谨性可与资深研究生水平的研究相媲美。最后，该研究进行了首个针对大语言模型 (LLM) 生成假设的 A/B 测试，结果显示出极高的统计显著性和高达 344% 的效应值，充分验证了该框架在现实世界中的有效性。",
      "categories": [
        "cs.AI",
        "cs.CL"
      ],
      "primary_category": "cs.AI",
      "comment": "",
      "pdf_url": "https://arxiv.org/pdf/2602.07983v1",
      "published_date": "2026-02-08 14:20:56 UTC",
      "updated_date": "2026-02-08 14:20:56 UTC",
      "processing_status": "completed",
      "attempts": 1,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "llm_backup_calls": 0,
      "last_update": "2026-02-16T05:20:30.307468+00:00"
    },
    {
      "arxiv_id": "2602.07970v1",
      "title": "Learning-guided Kansa collocation for forward and inverse PDEs beyond linearity",
      "title_zh": "用于求解非线性正向和反向偏微分方程的学习引导型 Kansa 配点法",
      "authors": [
        "Zheyuan Hu",
        "Weitao Chen",
        "Cengiz Öztireli",
        "Chenliang Zhou",
        "Fangcheng Zhong"
      ],
      "abstract": "Partial Differential Equations are precise in modelling the physical, biological and graphical phenomena. However, the numerical methods suffer from the curse of dimensionality, high computation costs and domain-specific discretization. We aim to explore pros and cons of different PDE solvers, and apply them to specific scientific simulation problems, including forwarding solution, inverse problems and equations discovery. In particular, we extend the recent CNF (NeurIPS 2023) framework solver to multi-dependent-variable and non-linear settings, together with down-stream applications. The outcomes include implementation of selected methods, self-tuning techniques, evaluation on benchmark problems and a comprehensive survey of neural PDE solvers and scientific simulation applications.",
      "tldr_zh": "该研究探讨了利用偏微分方程(PDEs)对物理、生物等现象建模时，传统数值方法面临的维度灾难、高计算成本及特定领域离散化等挑战。作者重点扩展了NeurIPS 2023提出的CNF框架，使其能够处理多因变量(multi-dependent-variable)和非线性(non-linear)设置下的复杂科学模拟问题。该方法被广泛应用于正向求解(forwarding solution)、反向问题(inverse problems)及方程发现(equations discovery)等任务。研究不仅实现了特定的求解方法并引入了自调优(self-tuning)技术，还在标准基准问题上进行了性能评估。此外，论文还针对神经PDE求解器(neural PDE solvers)及其实际科学应用场景提供了一份详尽的综述，为该领域的后续研究提供了重要参考。",
      "categories": [
        "cs.CE",
        "cs.AI",
        "cs.LG",
        "math.NA"
      ],
      "primary_category": "cs.CE",
      "comment": "Fangcheng Zhong and Chenliang Zhou are co-corresponding authors",
      "pdf_url": "https://arxiv.org/pdf/2602.07970v1",
      "published_date": "2026-02-08 13:44:36 UTC",
      "updated_date": "2026-02-08 13:44:36 UTC",
      "processing_status": "completed",
      "attempts": 1,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "llm_backup_calls": 0,
      "last_update": "2026-02-16T05:20:32.302636+00:00"
    },
    {
      "arxiv_id": "2602.07966v1",
      "title": "An Explainable Multi-Task Similarity Measure: Integrating Accumulated Local Effects and Weighted Fréchet Distance",
      "title_zh": "一种可解释的多任务相似性度量：融合累积局部效应与加权 Fréchet 距离",
      "authors": [
        "Pablo Hidalgo",
        "Daniel Rodriguez"
      ],
      "abstract": "In many machine learning contexts, tasks are often treated as interconnected components with the goal of leveraging knowledge transfer between them, which is the central aim of Multi-Task Learning (MTL). Consequently, this multi-task scenario requires addressing critical questions: which tasks are similar, and how and why do they exhibit similarity? In this work, we propose a multi-task similarity measure based on Explainable Artificial Intelligence (XAI) techniques, specifically Accumulated Local Effects (ALE) curves.\n  ALE curves are compared using the Fréchet distance, weighted by the data distribution, and the resulting similarity measure incorporates the importance of each feature. The measure is applicable in both single-task learning scenarios, where each task is trained separately, and multi-task learning scenarios, where all tasks are learned simultaneously. The measure is model-agnostic, allowing the use of different machine learning models across tasks. A scaling factor is introduced to account for differences in predictive performance across tasks, and several recommendations are provided for applying the measure in complex scenarios.\n  We validate this measure using four datasets, one synthetic dataset and three real-world datasets. The real-world datasets include a well-known Parkinson's dataset and a bike-sharing usage dataset -- both structured in tabular format -- as well as the CelebA dataset, which is used to evaluate the application of concept bottleneck encoders in a multitask learning setting. The results demonstrate that the measure aligns with intuitive expectations of task similarity across both tabular and non-tabular data, making it a valuable tool for exploring relationships between tasks and supporting informed decision-making.",
      "tldr_zh": "该研究提出了一种基于可解释人工智能 (XAI) 技术的多任务相似性度量方法，旨在解决多任务学习 (Multi-Task Learning) 中关于任务相似性及其内在逻辑的识别难题。核心方法利用累积局部效应 (Accumulated Local Effects, ALE) 曲线，并结合由数据分布加权的 Fréchet distance 进行任务比较，从而在度量中融入了特征重要性。该方案具有模型无关性 (model-agnostic)，既适用于各任务独立训练的场景，也适用于同步学习的多任务场景。此外，研究引入了缩放因子 (scaling factor) 以平衡任务间预测性能的差异，并针对复杂应用场景给出了实用建议。通过在合成数据集以及帕金森病预测、共享单车使用和 CelebA 图像概念瓶颈编码器等真实数据集上的验证，实验结果证明该度量方法在表格和非表格数据上均能提供符合直觉的相似性评估。该研究为探索任务间复杂关系和辅助多任务决策提供了强有力的可解释工具。",
      "categories": [
        "cs.LG",
        "cs.AI"
      ],
      "primary_category": "cs.LG",
      "comment": "",
      "pdf_url": "https://arxiv.org/pdf/2602.07966v1",
      "published_date": "2026-02-08 13:29:38 UTC",
      "updated_date": "2026-02-08 13:29:38 UTC",
      "processing_status": "completed",
      "attempts": 1,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "llm_backup_calls": 0,
      "last_update": "2026-02-16T05:20:35.299023+00:00"
    },
    {
      "arxiv_id": "2602.07963v1",
      "title": "Lost in Translation? A Comparative Study on the Cross-Lingual Transfer of Composite Harms",
      "title_zh": "迷失于翻译？复合危害跨语言迁移的对比研究",
      "authors": [
        "Vaibhav Shukla",
        "Hardik Sharma",
        "Adith N Reganti",
        "Soham Wasmatkar",
        "Bagesh Kumar",
        "Vrijendra Singh"
      ],
      "abstract": "Most safety evaluations of large language models (LLMs) remain anchored in English. Translation is often used as a shortcut to probe multilingual behavior, but it rarely captures the full picture, especially when harmful intent or structure morphs across languages. Some types of harm survive translation almost intact, while others distort or disappear. To study this effect, we introduce CompositeHarm, a translation-based benchmark designed to examine how safety alignment holds up as both syntax and semantics shift. It combines two complementary English datasets, AttaQ, which targets structured adversarial attacks, and MMSafetyBench, which covers contextual, real-world harms, and extends them into six languages: English, Hindi, Assamese, Marathi, Kannada, and Gujarati. Using three large models, we find that attack success rates rise sharply in Indic languages, especially under adversarial syntax, while contextual harms transfer more moderately. To ensure scalability and energy efficiency, our study adopts lightweight inference strategies inspired by edge-AI design principles, reducing redundant evaluation passes while preserving cross-lingual fidelity. This design makes large-scale multilingual safety testing both computationally feasible and environmentally conscious. Overall, our results show that translated benchmarks are a necessary first step, but not a sufficient one, toward building grounded, resource-aware, language-adaptive safety systems.",
      "tldr_zh": "该研究探讨了大语言模型（LLMs）在跨语言转换中安全性评估的局限性，特别是翻译在捕捉不同语言中有害意图或结构变化方面的不足。为此研究者提出了 CompositeHarm 这一基于翻译的基准测试，通过结合针对结构化对抗攻击的 AttaQ 数据集和涵盖现实语境伤害的 MMSafetyBench，将其扩展至印地语等六种语言。为了实现可扩展性，该研究采用了受边缘人工智能（edge-AI）设计原则启发的轻量化推理策略，在提高计算效率的同时保留了跨语言评估的保真度。实验发现，对抗攻击的成功率在印度语系（Indic languages）中显著上升，尤其是在对抗性语法（adversarial syntax）的作用下，而语境性伤害的迁移程度则相对温和。最终结果表明，虽然翻译基准测试是构建资源意识和语言自适应安全系统的必要第一步，但仅靠翻译不足以应对全球化背景下的模型安全挑战。",
      "categories": [
        "cs.CL",
        "cs.AI"
      ],
      "primary_category": "cs.CL",
      "comment": "Accepted at the AICS Workshop, AAAI 2026",
      "pdf_url": "https://arxiv.org/pdf/2602.07963v1",
      "published_date": "2026-02-08 13:22:50 UTC",
      "updated_date": "2026-02-08 13:22:50 UTC",
      "processing_status": "completed",
      "attempts": 1,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "llm_backup_calls": 0,
      "last_update": "2026-02-16T05:20:39.491917+00:00"
    },
    {
      "arxiv_id": "2602.07962v1",
      "title": "LOCA-bench: Benchmarking Language Agents Under Controllable and Extreme Context Growth",
      "title_zh": "LOCA-bench：面向可控及极端上下文增长的语言智能体基准测试",
      "authors": [
        "Weihao Zeng",
        "Yuzhen Huang",
        "Junxian He"
      ],
      "abstract": "Large language models (LLMs) are increasingly capable of carrying out long-running, real-world tasks. However, as the amount of context grows, their reliability often deteriorates, a phenomenon known as \"context rot\". Existing long-context benchmarks primarily focus on single-step settings that evaluate a model's ability to retrieve information from a long snippet. In realistic scenarios, however, LLMs often need to act as agents that explore environments, follow instructions and plans, extract useful information, and predict correct actions under a dynamically growing context. To assess language agents in such settings, we introduce LOCA-bench (a benchmark for LOng-Context Agents). Given a task prompt, LOCA-bench leverages automated and scalable control of environment states to regulate the agent's context length. This design enables LOCA-bench to extend the context length potentially to infinity in a controlled way while keeping the underlying task semantics fixed. LOCA-bench evaluates language agents as a combination of models and scaffolds, including various context management strategies. While agent performance generally degrades as the environment states grow more complex, advanced context management techniques can substantially improve the overall success rate. We open-source LOCA-bench to provide a platform for evaluating models and scaffolds in long-context, agentic scenarios: https://github.com/hkust-nlp/LOCA-bench",
      "tldr_zh": "该研究针对大语言模型 (LLMs) 在执行长期任务时因上下文增长而导致的“上下文腐烂” (context rot) 现象，提出了 LOCA-bench 这一针对长文本代理 (LOng-Context Agents) 的评估基准。与侧重单步检索的传统基准不同，LOCA-bench 模拟了代理在动态增长上下文中探索环境、遵循指令并预测动作的真实场景。该基准利用可扩展的环境状态控制技术，能在保持任务语义一致的前提下，将上下文长度受控地延伸至极端。研究团队对多种模型、脚手架 (scaffolds) 及上下文管理策略 (context management strategies) 进行了系统评估。实验发现，尽管环境复杂度的提升普遍导致性能下降，但先进的上下文管理技术能显著提高任务成功率。该平台的开源为长文本场景下智能体的评估与优化提供了有力支撑。",
      "categories": [
        "cs.AI"
      ],
      "primary_category": "cs.AI",
      "comment": "",
      "pdf_url": "https://arxiv.org/pdf/2602.07962v1",
      "published_date": "2026-02-08 13:20:39 UTC",
      "updated_date": "2026-02-08 13:20:39 UTC",
      "processing_status": "completed",
      "attempts": 1,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "llm_backup_calls": 0,
      "last_update": "2026-02-16T05:20:45.302760+00:00"
    },
    {
      "arxiv_id": "2602.07958v1",
      "title": "Accuracy-Delay Trade-Off in LLM Offloading via Token-Level Uncertainty",
      "title_zh": "基于 Token 级不确定性的 LLM 卸载准确率与延迟权衡",
      "authors": [
        "Yumin Kim",
        "Hyeonsu Lyu",
        "Minjae Lee",
        "Hyun Jong Yang"
      ],
      "abstract": "Large language models (LLMs) offer significant potential for intelligent mobile services but are computationally intensive for resource-constrained devices. Mobile edge computing (MEC) allows such devices to offload inference tasks to edge servers (ESs), yet introduces latency due to communication and serverside queuing, especially in multi-user environments. In this work, we propose an uncertainty-aware offloading framework that dynamically decides whether to perform inference locally or offload it to the ES, based on token-level uncertainty and resource constraints. We define a margin-based token-level uncertainty metric and demonstrate its correlation with model accuracy. Leveraging this metric, we design a greedy offloading algorithm (GOA) that minimizes delay while maintaining accuracy by prioritizing offloading for highuncertainty queries. Our experiments show that GOA consistently achieves a favorable trade-off, outperforming baseline strategies in both accuracy and latency across varying user densities, and operates with practical computation time. These results establish GOA as a scalable and effective solution for LLM inference in MEC environments.",
      "tldr_zh": "该研究提出了一个具有不确定性感知能力的卸载框架，旨在优化大型语言模型（LLMs）在移动边缘计算（MEC）环境下的性能表现。为了解决资源受限设备在推理时的计算压力以及边缘服务器（ES）带来的通信延迟和排队问题，该框架利用Token-level Uncertainty动态决定是将推理任务留在本地还是卸载至边缘服务器。研究定义了一种基于边际（Margin-based）的Token级别不确定性度量标准，并证实了其与模型准确度之间的相关性。基于此指标设计的贪婪卸载算法（Greedy Offloading Algorithm, GOA）通过优先卸载高不确定性的查询，在保持准确性的同时最小化延迟。实验结果表明，GOA在不同用户密度下均优于基线策略，实现了优异的准确率与延迟折衷，为MEC环境下的LLM推理提供了一种可扩展且高效的解决方案。",
      "categories": [
        "eess.SY",
        "cs.AI",
        "cs.DC"
      ],
      "primary_category": "eess.SY",
      "comment": "This paper has been accepted at 2025 IEEE Globecom Workshop: WS02-GAIMC: Mutual Facilitation of Generative Artificial Intelligence and Mobile Communications",
      "pdf_url": "https://arxiv.org/pdf/2602.07958v1",
      "published_date": "2026-02-08 13:03:03 UTC",
      "updated_date": "2026-02-08 13:03:03 UTC",
      "processing_status": "completed",
      "attempts": 1,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "llm_backup_calls": 0,
      "last_update": "2026-02-16T05:21:00.396624+00:00"
    },
    {
      "arxiv_id": "2602.10138v1",
      "title": "Multimodal Information Fusion for Chart Understanding: A Survey of MLLMs -- Evolution, Limitations, and Cognitive Enhancement",
      "title_zh": "图表理解中的多模态信息融合：多模态大模型综述——演进、局限与认知增强",
      "authors": [
        "Zhihang Yi",
        "Jian Zhao",
        "Jiancheng Lv",
        "Tao Wang"
      ],
      "abstract": "Chart understanding is a quintessential information fusion task, requiring the seamless integration of graphical and textual data to extract meaning. The advent of Multimodal Large Language Models (MLLMs) has revolutionized this domain, yet the landscape of MLLM-based chart analysis remains fragmented and lacks systematic organization. This survey provides a comprehensive roadmap of this nascent frontier by structuring the domain's core components. We begin by analyzing the fundamental challenges of fusing visual and linguistic information in charts. We then categorize downstream tasks and datasets, introducing a novel taxonomy of canonical and non-canonical benchmarks to highlight the field's expanding scope. Subsequently, we present a comprehensive evolution of methodologies, tracing the progression from classic deep learning techniques to state-of-the-art MLLM paradigms that leverage sophisticated fusion strategies. By critically examining the limitations of current models, particularly their perceptual and reasoning deficits, we identify promising future directions, including advanced alignment techniques and reinforcement learning for cognitive enhancement. This survey aims to equip researchers and practitioners with a structured understanding of how MLLMs are transforming chart information fusion and to catalyze progress toward more robust and reliable systems.",
      "tldr_zh": "这项研究针对图表理解中的多模态信息融合任务，系统地综述了多模态大语言模型（MLLMs）在这一领域的发展历程、局限性及认知增强方向。文章首先分析了融合图表视觉与语言信息的根本挑战，并提出了一种涵盖规范与非规范基准的新型任务及数据集分类法。随后，该综述详述了从传统深度学习到最前沿 MLLMs 范式的演进，深入探讨了复杂的融合策略。通过批判性地审视当前模型在感知和推理方面的缺陷，研究指出了包括先进对齐技术和强化学习（Reinforcement Learning）在内的认知增强未来方向。该综述为研究人员提供了结构化的指导，旨在推动更稳健、更可靠的图表信息融合系统发展。",
      "categories": [
        "cs.CV",
        "cs.AI",
        "cs.CL",
        "cs.LG"
      ],
      "primary_category": "cs.CV",
      "comment": "",
      "pdf_url": "https://arxiv.org/pdf/2602.10138v1",
      "published_date": "2026-02-08 12:59:50 UTC",
      "updated_date": "2026-02-08 12:59:50 UTC",
      "processing_status": "completed",
      "attempts": 1,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "llm_backup_calls": 0,
      "last_update": "2026-02-16T05:20:57.609424+00:00"
    },
    {
      "arxiv_id": "2602.07954v3",
      "title": "Bielik Guard: Efficient Polish Language Safety Classifiers for LLM Content Moderation",
      "title_zh": "Bielik Guard：面向大语言模型内容审核的高效波兰语安全分类器",
      "authors": [
        "Krzysztof Wróbel",
        "Jan Maria Kowalski",
        "Jerzy Surma",
        "Igor Ciuciura",
        "Maciej Szymański"
      ],
      "abstract": "As Large Language Models (LLMs) become increasingly deployed in Polish language applications, the need for efficient and accurate content safety classifiers has become paramount. We present Bielik Guard, a family of compact Polish language safety classifiers comprising two model variants: a 0.1B parameter model based on MMLW-RoBERTa-base and a 0.5B parameter model based on PKOBP/polish-roberta-8k. Fine-tuned on a community-annotated dataset of 6,885 Polish texts, these models classify content across five safety categories: Hate/Aggression, Vulgarities, Sexual Content, Crime, and Self-Harm. Our evaluation demonstrates that both models achieve strong performance on multiple benchmarks. The 0.5B variant offers the best overall discrimination capability with F1 scores of 0.791 (micro) and 0.785 (macro) on the test set, while the 0.1B variant demonstrates exceptional efficiency. Notably, Bielik Guard 0.1B v1.1 achieves superior precision (77.65%) and very low false positive rate (0.63%) on real user prompts, outperforming HerBERT-PL-Guard (31.55% precision, 4.70% FPR) despite identical model size. The models are publicly available and designed to provide appropriate responses rather than simple content blocking, particularly for sensitive categories like self-harm.",
      "tldr_zh": "该研究提出了 Bielik Guard，这是一系列针对波兰语应用设计的轻量级内容安全分类器，旨在满足大语言模型 (LLMs) 在内容审核中对准确性和效率的迫切需求。该家族包含基于 MMLW-RoBERTa-base 的 0.1B 参数模型和基于 PKOBP/polish-roberta-8k 的 0.5B 参数模型，并在包含 6,885 条波兰语文本的社区标注数据集上进行了微调。Bielik Guard 能够精准识别仇恨与攻击 (Hate/Aggression)、粗俗语言 (Vulgarities)、性内容 (Sexual Content)、犯罪 (Crime) 和自残 (Self-Harm) 五大类违规内容。实验结果显示，0.5B 变体在测试集上展现了最优的分类能力，其 F1 分数分别达到 0.791 (micro) 和 0.785 (macro)。与此同时，0.1B 变体在处理真实用户提示词时表现出极高的效率，其准确率 (Precision) 达 77.65%，误报率 (False Positive Rate) 仅为 0.63%，性能显著优于同规模的 HerBERT-PL-Guard 模型。该模型不仅具备高效的屏蔽功能，还被设计为能在面对自残等敏感类别时提供适当的引导性响应，而非简单的内容阻断。",
      "categories": [
        "cs.CL",
        "cs.AI"
      ],
      "primary_category": "cs.CL",
      "comment": "",
      "pdf_url": "https://arxiv.org/pdf/2602.07954v3",
      "published_date": "2026-02-08 12:57:04 UTC",
      "updated_date": "2026-02-13 15:33:36 UTC",
      "processing_status": "completed",
      "attempts": 1,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "llm_backup_calls": 0,
      "last_update": "2026-02-16T05:21:04.513966+00:00"
    },
    {
      "arxiv_id": "2602.10137v1",
      "title": "Multi-encoder ConvNeXt Network with Smooth Attentional Feature Fusion for Multispectral Semantic Segmentation",
      "title_zh": "基于平滑注意力特征融合的多编码器 ConvNeXt 多光谱语义分割网络",
      "authors": [
        "Leo Thomas Ramos",
        "Angel D. Sappa"
      ],
      "abstract": "This work proposes MeCSAFNet, a multi-branch encoder-decoder architecture for land cover segmentation in multispectral imagery. The model separately processes visible and non-visible channels through dual ConvNeXt encoders, followed by individual decoders that reconstruct spatial information. A dedicated fusion decoder integrates intermediate features at multiple scales, combining fine spatial cues with high-level spectral representations. The feature fusion is further enhanced with CBAM attention, and the ASAU activation function contributes to stable and efficient optimization. The model is designed to process different spectral configurations, including a 4-channel (4c) input combining RGB and NIR bands, as well as a 6-channel (6c) input incorporating NDVI and NDWI indices. Experiments on the Five-Billion-Pixels (FBP) and Potsdam datasets demonstrate significant performance gains. On FBP, MeCSAFNet-base (6c) surpasses U-Net (4c) by +19.21%, U-Net (6c) by +14.72%, SegFormer (4c) by +19.62%, and SegFormer (6c) by +14.74% in mIoU. On Potsdam, MeCSAFNet-large (4c) improves over DeepLabV3+ (4c) by +6.48%, DeepLabV3+ (6c) by +5.85%, SegFormer (4c) by +9.11%, and SegFormer (6c) by +4.80% in mIoU. The model also achieves consistent gains over several recent state-of-the-art approaches. Moreover, compact variants of MeCSAFNet deliver notable performance with lower training time and reduced inference cost, supporting their deployment in resource-constrained environments.",
      "tldr_zh": "该研究提出了 MeCSAFNet，一种专为多光谱图像地表覆盖分割设计的多分支编码器-解码器架构。该模型通过双 ConvNeXt 编码器分别处理可见光和非可见光通道，并利用独立解码器重建空间信息。其核心在于一个专用的融合解码器，它在多个尺度上整合中间特征，通过结合 CBAM 注意力机制增强特征融合，并采用 ASAU 激活函数以实现稳定高效的优化。模型支持 4-channel (RGB 和 NIR) 以及 6-channel (包含 NDVI 和 NDWI 指数) 等不同光谱配置，具有极强的灵活性。在 Five-Billion-Pixels (FBP) 和 Potsdam 数据集上的实验表明，MeCSAFNet 在 mIoU 指标上显著优于 U-Net、DeepLabV3+ 和 SegFormer 等主流模型。其中 MeCSAFNet-base (6c) 在 FBP 数据集上比 U-Net (6c) 提高了 14.72%，证明了其在处理复杂光谱数据时的优越性。此外，该模型的轻量化变体在降低训练时间和推理成本的同时提供了出色的性能，使其能够部署在资源受限的实际应用环境中。",
      "categories": [
        "cs.CV",
        "cs.AI"
      ],
      "primary_category": "cs.CV",
      "comment": "This is an extended version of the study presented at IEEE SoutheastCon2025. It presents substantial new content and original contributions beyond the previous version, including an expanded and enhanced background, new architectural refinements, additional experiments conducted on a broader range of datasets and experimental scenarios, and a more comprehensive analysis of results",
      "pdf_url": "https://arxiv.org/pdf/2602.10137v1",
      "published_date": "2026-02-08 12:42:10 UTC",
      "updated_date": "2026-02-08 12:42:10 UTC",
      "processing_status": "completed",
      "attempts": 1,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "llm_backup_calls": 0,
      "last_update": "2026-02-16T05:21:09.007539+00:00"
    },
    {
      "arxiv_id": "2602.07943v1",
      "title": "IV Co-Scientist: Multi-Agent LLM Framework for Causal Instrumental Variable Discovery",
      "title_zh": "IV Co-Scientist：用于因果工具变量发现的多智能体大语言模型框架",
      "authors": [
        "Ivaxi Sheth",
        "Zhijing Jin",
        "Bryan Wilder",
        "Dominik Janzing",
        "Mario Fritz"
      ],
      "abstract": "In the presence of confounding between an endogenous variable and the outcome, instrumental variables (IVs) are used to isolate the causal effect of the endogenous variable. Identifying valid instruments requires interdisciplinary knowledge, creativity, and contextual understanding, making it a non-trivial task. In this paper, we investigate whether large language models (LLMs) can aid in this task. We perform a two-stage evaluation framework. First, we test whether LLMs can recover well-established instruments from the literature, assessing their ability to replicate standard reasoning. Second, we evaluate whether LLMs can identify and avoid instruments that have been empirically or theoretically discredited. Building on these results, we introduce IV Co-Scientist, a multi-agent system that proposes, critiques, and refines IVs for a given treatment-outcome pair. We also introduce a statistical test to contextualize consistency in the absence of ground truth. Our results show the potential of LLMs to discover valid instrumental variables from a large observational database.",
      "tldr_zh": "该研究提出了 IV Co-Scientist，一个用于发现因果推断中工具变量 (Instrumental Variables, IVs) 的多智能体大语言模型 (LLM) 框架，旨在解决识别有效工具变量时对跨学科知识和上下文理解的高要求。该框架包含一个两阶段评估流程，首先验证模型恢复文献中经典工具变量的能力，随后评估其识别并排除已被证明无效工具变量的能力。在此基础上，IV Co-Scientist 通过多智能体系统的建议、批判与完善机制，针对特定的干预-结果对提出可靠的工具变量方案。研究还引入了一种统计检验方法，以在缺乏地面真值 (Ground Truth) 的情况下评估一致性。实验结果表明，该系统能够有效地从大规模观测数据库中发现有效的工具变量，展示了大语言模型在辅助复杂因果推断任务中的巨大潜力。",
      "categories": [
        "cs.AI"
      ],
      "primary_category": "cs.AI",
      "comment": "18 pages",
      "pdf_url": "https://arxiv.org/pdf/2602.07943v1",
      "published_date": "2026-02-08 12:28:29 UTC",
      "updated_date": "2026-02-08 12:28:29 UTC",
      "processing_status": "completed",
      "attempts": 1,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "llm_backup_calls": 0,
      "last_update": "2026-02-16T05:21:16.412232+00:00"
    },
    {
      "arxiv_id": "2602.07940v2",
      "title": "MePo: Meta Post-Refinement for Rehearsal-Free General Continual Learning",
      "title_zh": "MePo：面向无回放通用持续学习的元后精炼方法",
      "authors": [
        "Guanglong Sun",
        "Hongwei Yan",
        "Liyuan Wang",
        "Zhiqi Kang",
        "Shuang Cui",
        "Hang Su",
        "Jun Zhu",
        "Yi Zhong"
      ],
      "abstract": "To cope with uncertain changes of the external world, intelligent systems must continually learn from complex, evolving environments and respond in real time. This ability, collectively known as general continual learning (GCL), encapsulates practical challenges such as online datastreams and blurry task boundaries. Although leveraging pretrained models (PTMs) has greatly advanced conventional continual learning (CL), these methods remain limited in reconciling the diverse and temporally mixed information along a single pass, resulting in sub-optimal GCL performance. Inspired by meta-plasticity and reconstructive memory in neuroscience, we introduce here an innovative approach named Meta Post-Refinement (MePo) for PTMs-based GCL. This approach constructs pseudo task sequences from pretraining data and develops a bi-level meta-learning paradigm to refine the pretrained backbone, which serves as a prolonged pretraining phase but greatly facilitates rapid adaptation of representation learning to downstream GCL tasks. MePo further initializes a meta covariance matrix as the reference geometry of pretrained representation space, enabling GCL to exploit second-order statistics for robust output alignment. MePo serves as a plug-in strategy that achieves significant performance gains across a variety of GCL benchmarks and pretrained checkpoints in a rehearsal-free manner (e.g., 15.10\\%, 13.36\\%, and 12.56\\% on CIFAR-100, ImageNet-R, and CUB-200 under Sup-21/1K). Our source code is available at \\href{https://github.com/SunGL001/MePo}{MePo}",
      "tldr_zh": "该研究针对通用持续学习 (General Continual Learning, GCL) 中在线数据流和模糊任务边界带来的挑战，提出了一种名为 Meta Post-Refinement (MePo) 的创新方法。受神经科学中元可塑性 (meta-plasticity) 和重构记忆 (reconstructive memory) 的启发，MePo 为基于预训练模型 (Pretrained Models, PTMs) 的 GCL 任务提供了高效解决方案。该方法通过从预训练数据中构建伪任务序列，并利用双层元学习 (bi-level meta-learning) 范式对预训练骨干网络进行细化，从而显著增强了表征学习对下游 GCL 任务的快速适应能力。此外，MePo 初始化了一个元协方差矩阵 (meta covariance matrix) 作为预训练表征空间的几何参考，利用二阶统计量实现稳健的输出对齐。作为一种无需回放 (rehearsal-free) 的插件策略，MePo 在 CIFAR-100、ImageNet-R 和 CUB-200 等多个基准测试上均实现了显著的性能提升，在 CIFAR-100 上的准确率增幅高达 15.10%。",
      "categories": [
        "cs.AI"
      ],
      "primary_category": "cs.AI",
      "comment": "",
      "pdf_url": "https://arxiv.org/pdf/2602.07940v2",
      "published_date": "2026-02-08 12:15:35 UTC",
      "updated_date": "2026-02-11 09:48:31 UTC",
      "processing_status": "completed",
      "attempts": 1,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "llm_backup_calls": 0,
      "last_update": "2026-02-16T05:21:15.197957+00:00"
    },
    {
      "arxiv_id": "2602.07928v1",
      "title": "A Kinetic-Energy Perspective of Flow Matching",
      "title_zh": "流量匹配的动能视角",
      "authors": [
        "Ziyun Li",
        "Huancheng Hu",
        "Soon Hoe Lim",
        "Xuyu Li",
        "Fei Gao",
        "Enmao Diao",
        "Zezhen Ding",
        "Michalis Vazirgiannis",
        "Henrik Bostrom"
      ],
      "abstract": "Flow-based generative models can be viewed through a physics lens: sampling transports a particle from noise to data by integrating a time-varying velocity field, and each sample corresponds to a trajectory with its own dynamical effort. Motivated by classical mechanics, we introduce Kinetic Path Energy (KPE), an action-like, per-sample diagnostic that measures the accumulated kinetic effort along an Ordinary Differential Equation (ODE) trajectory. Empirically, KPE exhibits two robust correspondences: (i) higher KPE predicts stronger semantic fidelity; (ii) high-KPE trajectories terminate on low-density manifold frontiers. We further provide theoretical guarantees linking trajectory energy to data density. Paradoxically, this correlation is non-monotonic. At sufficiently high energy, generation can degenerate into memorization. Leveraging the closed-form of empirical flow matching, we show that extreme energies drive trajectories toward near-copies of training examples. This yields a Goldilocks principle and motivates Kinetic Trajectory Shaping (KTS), a training-free two-phase inference strategy that boosts early motion and enforces a late-time soft landing, reducing memorization and improving generation quality across benchmark tasks.",
      "tldr_zh": "该研究从物理学视角审视基于流的生成模型(Flow-based generative models)，引入了动能路径能量(Kinetic Path Energy, KPE)这一指标来衡量粒子从噪声传输到数据过程中的累积动力学消耗。研究发现KPE与语义忠实度(semantic fidelity)高度相关，且高能量轨迹往往止于低密度流形边界，并从理论上证明了轨迹能量与数据密度之间的非单调关联。实验揭示了当能量极高时生成过程会退化为对训练样本的记忆(memorization)，即极端能量会驱动轨迹产生训练数据的近似副本。基于此发现，作者提出了动力学轨迹塑形(Kinetic Trajectory Shaping, KTS)这一免训练的推理策略，通过在初期增强运动并在后期强制软着陆，有效减少了记忆效应并提升了多个基准任务的生成质量。该视角为理解流匹配(Flow Matching)机制及优化采样路径提供了新的物理理论支撑。",
      "categories": [
        "cs.LG",
        "cs.AI"
      ],
      "primary_category": "cs.LG",
      "comment": "",
      "pdf_url": "https://arxiv.org/pdf/2602.07928v1",
      "published_date": "2026-02-08 11:51:50 UTC",
      "updated_date": "2026-02-08 11:51:50 UTC",
      "processing_status": "completed",
      "attempts": 1,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "llm_backup_calls": 0,
      "last_update": "2026-02-16T05:21:14.330124+00:00"
    },
    {
      "arxiv_id": "2602.07924v1",
      "title": "Optimized Human-Robot Co-Dispatch Planning for Petro-Site Surveillance under Varying Criticalities",
      "title_zh": "针对不同关键程度石油站点监控的人机协同调度优化规划",
      "authors": [
        "Nur Ahmad Khatim",
        "Mansur Arief"
      ],
      "abstract": "Securing petroleum infrastructure requires balancing autonomous system efficiency with human judgment for threat escalation, a challenge unaddressed by classical facility location models assuming homogeneous resources. This paper formulates the Human-Robot Co-Dispatch Facility Location Problem (HRCD-FLP), a capacitated facility location variant incorporating tiered infrastructure criticality, human-robot supervision ratio constraints, and minimum utilization requirements. We evaluate command center selection across three technology maturity scenarios. Results show transitioning from conservative (1:3 human-robot supervision) to future autonomous operations (1:10) yields significant cost reduction while maintaining complete critical infrastructure coverage. For small problems, exact methods dominate in both cost and computation time; for larger problems, the proposed heuristic achieves feasible solutions in under 3 minutes with approximately 14% optimality gap where comparison is possible. From systems perspective, our work demonstrate that optimized planning for human-robot teaming is key to achieve both cost-effective and mission-reliable deployments.",
      "tldr_zh": "该研究针对石油基础设施安全中自主系统效率与人类判断平衡的问题，提出了人类-机器人协同调度设施定位问题(Human-Robot Co-Dispatch Facility Location Problem, HRCD-FLP)。作为带容量限制的设施定位变体，该模型综合考虑了分级的基础设施关键度(criticality)、人机监管比例约束以及最低利用率要求。研究在三种技术成熟度场景下评估了指挥中心的选择，分析了从保守的1:3到未来1:10的人机监管比例转变带来的影响。结果表明，向自动化作业转型能在维持关键基础设施完全覆盖的同时显著降低成本。在算法层面，精确方法(exact methods)在处理小规模问题时表现优异，而针对大规模问题提出的启发式算法(heuristic)能在3分钟内获得可行解。该工作从系统视角证明了优化人机协同规划是实现成本效益与任务可靠部署的关键，为石油站点的智能监控提供了重要的决策支持。",
      "categories": [
        "cs.RO",
        "cs.AI",
        "math.OC"
      ],
      "primary_category": "cs.RO",
      "comment": "",
      "pdf_url": "https://arxiv.org/pdf/2602.07924v1",
      "published_date": "2026-02-08 11:46:40 UTC",
      "updated_date": "2026-02-08 11:46:40 UTC",
      "processing_status": "completed",
      "attempts": 1,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "llm_backup_calls": 0,
      "last_update": "2026-02-16T05:21:20.896750+00:00"
    },
    {
      "arxiv_id": "2602.07919v1",
      "title": "Selective Fine-Tuning for Targeted and Robust Concept Unlearning",
      "title_zh": "面向针对性且稳健概念遗忘的选择性微调",
      "authors": [
        "Mansi",
        "Avinash Kori",
        "Francesca Toni",
        "Soteris Demetriou"
      ],
      "abstract": "Text guided diffusion models are used by millions of users, but can be easily exploited to produce harmful content. Concept unlearning methods aim at reducing the models' likelihood of generating harmful content. Traditionally, this has been tackled at an individual concept level, with only a handful of recent works considering more realistic concept combinations. However, state of the art methods depend on full finetuning, which is computationally expensive. Concept localisation methods can facilitate selective finetuning, but existing techniques are static, resulting in suboptimal utility. In order to tackle these challenges, we propose TRUST (Targeted Robust Selective fine Tuning), a novel approach for dynamically estimating target concept neurons and unlearning them through selective finetuning, empowered by a Hessian based regularization. We show experimentally, against a number of SOTA baselines, that TRUST is robust against adversarial prompts, preserves generation quality to a significant degree, and is also significantly faster than the SOTA. Our method achieves unlearning of not only individual concepts but also combinations of concepts and conditional concepts, without any specific regularization.",
      "tldr_zh": "该研究针对扩散模型(diffusion models)在机器卸载(Concept Unlearning)中面临的计算成本高及静态定位效用欠佳等挑战，提出了TRUST (Targeted Robust Selective fine Tuning)框架。该框架通过动态估算目标概念神经元并结合基于Hessian矩阵的正则化(Hessian based regularization)进行选择性微调(selective finetuning)，从而实现精准的概念擦除。实验表明，TRUST在对抗性提示词(adversarial prompts)下表现出显著的鲁棒性，并能在极大程度上保留图像生成质量。此外，该方法的运行速度优于现有的最先进(SOTA)基线模型，不仅能有效处理单一概念，还支持无需特殊正则化的组合概念与条件概念卸载，为实现目标明确且稳健的模型净化提供了新方案。",
      "categories": [
        "cs.AI",
        "cs.CV"
      ],
      "primary_category": "cs.AI",
      "comment": "Given the brittle nature of existing methods in unlearning harmful content in diffusion models, we propose TRuST, a novel approach for dynamically estimating target concept neurons and unlearning them by selectively fine-tuning",
      "pdf_url": "https://arxiv.org/pdf/2602.07919v1",
      "published_date": "2026-02-08 11:34:21 UTC",
      "updated_date": "2026-02-08 11:34:21 UTC",
      "processing_status": "completed",
      "attempts": 1,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "llm_backup_calls": 0,
      "last_update": "2026-02-16T05:21:26.812904+00:00"
    },
    {
      "arxiv_id": "2602.07915v1",
      "title": "CausalCompass: Evaluating the Robustness of Time-Series Causal Discovery in Misspecified Scenarios",
      "title_zh": "CausalCompass：评估时间序列因果发现在模型误设场景下的稳健性",
      "authors": [
        "Huiyang Yi",
        "Xiaojian Shen",
        "Yonggang Wu",
        "Duxin Chen",
        "He Wang",
        "Wenwu Yu"
      ],
      "abstract": "Causal discovery from time series is a fundamental task in machine learning. However, its widespread adoption is hindered by a reliance on untestable causal assumptions and by the lack of robustness-oriented evaluation in existing benchmarks. To address these challenges, we propose CausalCompass, a flexible and extensible benchmark suite designed to assess the robustness of time-series causal discovery (TSCD) methods under violations of modeling assumptions. To demonstrate the practical utility of CausalCompass, we conduct extensive benchmarking of representative TSCD algorithms across eight assumption-violation scenarios. Our experimental results indicate that no single method consistently attains optimal performance across all settings. Nevertheless, the methods exhibiting superior overall performance across diverse scenarios are almost invariably deep learning-based approaches. We further provide hyperparameter sensitivity analyses to deepen the understanding of these findings. We also find, somewhat surprisingly, that NTS-NOTEARS relies heavily on standardized preprocessing in practice, performing poorly in the vanilla setting but exhibiting strong performance after standardization. Finally, our work aims to provide a comprehensive and systematic evaluation of TSCD methods under assumption violations, thereby facilitating their broader adoption in real-world applications. The code and datasets are available at https://github.com/huiyang-yi/CausalCompass.",
      "tldr_zh": "该研究针对时间序列因果发现(Time-Series Causal Discovery, TSCD)方法严重依赖不可验证的因果假设且缺乏鲁棒性导向评估的问题，提出了CausalCompass基准测试套件。CausalCompass是一个灵活且可扩展的框架，专门用于评估TSCD方法在模型假设失效(Assumption Violations)场景下的鲁棒性。研究人员在八种假设违背场景下对多种代表性TSCD算法进行了大规模评测，结果表明目前尚无任何单一方法能在所有设置中始终保持最优性能。实验发现，在多种复杂场景下表现优异的方法几乎均为基于深度学习(Deep Learning)的方法，并揭示了NTS-NOTEARS等算法对标准化预处理的高度依赖性。这项工作通过对TSCD方法进行全面系统的评估，为提升该领域算法在现实世界应用中的可靠性提供了关键参考。",
      "categories": [
        "cs.LG",
        "cs.AI",
        "stat.ME",
        "stat.ML"
      ],
      "primary_category": "cs.LG",
      "comment": "",
      "pdf_url": "https://arxiv.org/pdf/2602.07915v1",
      "published_date": "2026-02-08 11:27:06 UTC",
      "updated_date": "2026-02-08 11:27:06 UTC",
      "processing_status": "completed",
      "attempts": 1,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "llm_backup_calls": 0,
      "last_update": "2026-02-16T05:21:34.628610+00:00"
    },
    {
      "arxiv_id": "2602.07906v1",
      "title": "AceGRPO: Adaptive Curriculum Enhanced Group Relative Policy Optimization for Autonomous Machine Learning Engineering",
      "title_zh": "AceGRPO：面向自主机器学习工程的自适应课程增强组相对策略优化",
      "authors": [
        "Yuzhu Cai",
        "Zexi Liu",
        "Xinyu Zhu",
        "Cheng Wang",
        "Jiaao Chen",
        "Hanrui Wang",
        "Wei-Chen Wang",
        "Di Jin",
        "Siheng Chen"
      ],
      "abstract": "Autonomous Machine Learning Engineering (MLE) requires agents to perform sustained, iterative optimization over long horizons. While recent LLM-based agents show promise, current prompt-based agents for MLE suffer from behavioral stagnation due to frozen parameters. Although Reinforcement Learning (RL) offers a remedy, applying it to MLE is hindered by prohibitive execution latency and inefficient data selection. Recognizing these challenges, we propose AceGRPO with two core components: (1) Evolving Data Buffer that continuously repurposes execution traces into reusable training tasks, and (2) Adaptive Sampling guided by a Learnability Potential function, which dynamically prioritizes tasks at the agent's learning frontier to maximize learning efficiency. Leveraging AceGRPO, our trained Ace-30B model achieves a 100% valid submission rate on MLE-Bench-Lite, approaches the performance of proprietary frontier models, and outperforms larger open-source baselines (e.g., DeepSeek-V3.2), demonstrating robust capability for sustained iterative optimization. Code is available at https://github.com/yuzhu-cai/AceGRPO.",
      "tldr_zh": "该研究提出了 AceGRPO，这是一种针对自主机器学习工程（Autonomous Machine Learning Engineering, MLE）的自适应课程增强组相对策略优化方法，旨在解决现有智能体因参数固定导致的性能停滞以及 Reinforcement Learning (RL) 训练中数据选择低效的问题。AceGRPO 包含两个核心组件：Evolving Data Buffer 将执行轨迹持续转化为可重复使用的训练任务，而受 Learnability Potential 函数引导的 Adaptive Sampling 则通过动态优先处理处于学习前沿的任务来最大化学习效率。实验结果显示，基于该方法训练的 Ace-30B 模型在 MLE-Bench-Lite 上实现了 100% 的有效提交率，其性能接近专有前沿模型，并优于 DeepSeek-V3.2 等更大型的开源基线。该研究证明了 AceGRPO 在长程持续迭代优化方面的强大能力，为实现高效的自主机器学习工程提供了可靠的技术方案。",
      "categories": [
        "cs.LG",
        "cs.AI"
      ],
      "primary_category": "cs.LG",
      "comment": "17 pages, 5 figures",
      "pdf_url": "https://arxiv.org/pdf/2602.07906v1",
      "published_date": "2026-02-08 10:55:03 UTC",
      "updated_date": "2026-02-08 10:55:03 UTC",
      "processing_status": "completed",
      "attempts": 1,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "llm_backup_calls": 0,
      "last_update": "2026-02-16T05:21:52.107305+00:00"
    },
    {
      "arxiv_id": "2602.07905v1",
      "title": "MedCoG: Maximizing LLM Inference Density in Medical Reasoning via Meta-Cognitive Regulation",
      "title_zh": "MedCoG：通过元认知调节最大化医学推理中的 LLM 推理密度",
      "authors": [
        "Yu Zhao",
        "Hao Guan",
        "Yongcheng Jing",
        "Ying Zhang",
        "Dacheng Tao"
      ],
      "abstract": "Large Language Models (LLMs) have shown strong potential in complex medical reasoning yet face diminishing gains under inference scaling laws. While existing studies augment LLMs with various knowledge types, it remains unclear how effectively the additional costs translate into accuracy. In this paper, we explore how meta-cognition of LLMs, i.e., their self-awareness of their own knowledge states, can regulate the reasoning process. Specifically, we propose MedCoG, a Medical Meta-Cognition Agent with Knowledge Graph, where the meta-cognitive assessments of task complexity, familiarity, and knowledge density dynamically regulate utilization of procedural, episodic, and factual knowledge. The LLM-centric on-demand reasoning aims to mitigate scaling laws by (1) reducing costs via avoiding indiscriminate scaling, (2) improving accuracy via filtering out distractive knowledge. To validate this, we empirically characterize the scaling curve and introduce inference density to quantify inference efficiency, defined as the ratio of theoretically effective cost to actual cost. Experiments demonstrate the effectiveness and efficiency of MedCoG on five hard sets of medical benchmarks, yielding 5.5x inference density. Furthermore, the Oracle study highlights the significant potential of meta-cognitive regulation.",
      "tldr_zh": "该研究针对大语言模型 (LLMs) 在复杂医疗推理中面临的推理缩放定律 (inference scaling laws) 边际收益递减以及知识增强成本效益不明的问题，提出了 MedCoG 框架。MedCoG 是一种结合知识图谱 (Knowledge Graph) 的医疗元认知智能体，通过元认知 (meta-cognition) 评估任务复杂性、熟悉度和知识密度，动态调节程序性、情节性和事实性知识的利用。这种以 LLM 为中心的按需推理机制旨在通过避免无差别缩放来降低成本，并利用过滤干扰性知识来提升推理准确性。研究者还引入了推理密度 (inference density) 这一指标，用以量化理论有效成本与实际成本的比率。实验结果显示，MedCoG 在五个高难度医疗基准测试集上实现了 5.5 倍的推理密度提升。Oracle 研究进一步证明了元认知调节在优化医疗 AI 推理效率和准确性方面的显著潜力。",
      "categories": [
        "cs.AI"
      ],
      "primary_category": "cs.AI",
      "comment": "",
      "pdf_url": "https://arxiv.org/pdf/2602.07905v1",
      "published_date": "2026-02-08 10:54:04 UTC",
      "updated_date": "2026-02-08 10:54:04 UTC",
      "processing_status": "completed",
      "attempts": 1,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "llm_backup_calls": 0,
      "last_update": "2026-02-16T05:21:47.904234+00:00"
    },
    {
      "arxiv_id": "2602.07904v1",
      "title": "Adaptive Acquisition Selection for Bayesian Optimization with Large Language Models",
      "title_zh": "基于大语言模型的贝叶斯优化自适应采集函数选择",
      "authors": [
        "Giang Ngo",
        "Dat Phan Trong",
        "Dang Nguyen",
        "Sunil Gupta",
        "Svetha Venkatesh"
      ],
      "abstract": "Bayesian Optimization critically depends on the choice of acquisition function, but no single strategy is universally optimal; the best choice is non-stationary and problem-dependent. Existing adaptive portfolio methods often base their decisions on past function values while ignoring richer information like remaining budget or surrogate model characteristics. To address this, we introduce LMABO, a novel framework that casts a pre-trained Large Language Model (LLM) as a zero-shot, online strategist for the BO process. At each iteration, LMABO uses a structured state representation to prompt the LLM to select the most suitable acquisition function from a diverse portfolio. In an evaluation across 50 benchmark problems, LMABO demonstrates a significant performance improvement over strong static, adaptive portfolio, and other LLM-based baselines. We show that the LLM's behavior is a comprehensive strategy that adapts to real-time progress, proving its advantage stems from its ability to process and synthesize the complete optimization state into an effective, adaptive policy.",
      "tldr_zh": "该研究针对贝叶斯优化(Bayesian Optimization)中采集函数(acquisition function)选择随问题动态变化的挑战，提出了LMABO框架。该框架将预训练的大语言模型(LLM)作为零样本(zero-shot)在线策略制定者，通过结构化的状态表示提示LLM在每一轮迭代中从策略池中选择最合适的采集函数。与仅依赖历史函数值的传统自适应方法不同，LMABO能够整合剩余预算和代理模型特征等更丰富的信息。在跨越50个基准问题的评估中，LMABO的性能显著优于强静态策略、自适应组合方法以及其他基于LLM的基准。实验结果表明，LLM具备处理并综合完整优化状态的能力，能够根据实时进展生成有效的自适应策略，为解决复杂的非平稳优化问题提供了新途径。",
      "categories": [
        "cs.LG",
        "cs.AI"
      ],
      "primary_category": "cs.LG",
      "comment": "",
      "pdf_url": "https://arxiv.org/pdf/2602.07904v1",
      "published_date": "2026-02-08 10:53:52 UTC",
      "updated_date": "2026-02-08 10:53:52 UTC",
      "processing_status": "completed",
      "attempts": 1,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "llm_backup_calls": 0,
      "last_update": "2026-02-16T05:21:54.995577+00:00"
    },
    {
      "arxiv_id": "2602.07903v1",
      "title": "GCN-MPPR: Enhancing the Propagation of Message Passing Neural Networks via Motif-Based Personalized PageRank",
      "title_zh": "GCN-MPPR：通过基于模体的个性化 PageRank 增强消息传递神经网络的传播",
      "authors": [
        "Mingcan Wang",
        "Junchang Xin",
        "Zhongming Yao",
        "Kaifu Long",
        "Zhiqiong Wang"
      ],
      "abstract": "The algorithms based on message passing neural networks (MPNNs) on graphs have recently achieved great success for various graph applications. However, studies find that these methods always propagate the information to very limited neighborhoods with shallow depth, particularly due to over-smoothing. That means most of the existing MPNNs fail to be so `deep'. Although some previous work tended to handle this challenge via optimization- or structure-level remedies, the overall performance of GCNs still suffers from limited accuracy, poor stability, and unaffordable computational cost. Moreover, neglect of higher-order relationships during the propagation of MPNNs has further limited the performance of them. To overcome these challenges, a novel variant of PageRank named motif-based personalized PageRank (MPPR) is proposed to measure the influence of one node to another on the basis of considering higher-order motif relationships. Secondly, the MPPR is utilized to the message passing process of GCNs, thereby guiding the message passing process at a relatively `high' level. The experimental results show that the proposed method outperforms almost all of the baselines on accuracy, stability, and time consumption. Additionally, the proposed method can be considered as a component that can underpin almost all GCN tasks, with DGCRL being demonstrated in the experiment. The anonymous code repository is available at: https://anonymous.4open.science/r/GCN-MPPR-AFD6/.",
      "tldr_zh": "本研究针对Message Passing Neural Networks (MPNNs)在图应用中面临的过度平滑(over-smoothing)和浅层传播限制，提出了GCN-MPPR框架。该研究首先设计了一种名为motif-based personalized PageRank (MPPR)的新型PageRank变体，旨在通过捕获高阶Motif关系来精确衡量节点间的相互影响力。随后，MPPR被引入GCNs的消息传递过程，在更高层级上指导信息的传播，从而有效克服了传统方法在准确性、稳定性和计算成本方面的缺陷。实验结果证明，GCN-MPPR在多个指标上均优于现有的基线模型，展现出卓越的性能和稳定性。此外，该方法具有良好的通用性，可作为基础组件支持DGCRL等多种GCN任务。",
      "categories": [
        "cs.AI"
      ],
      "primary_category": "cs.AI",
      "comment": "",
      "pdf_url": "https://arxiv.org/pdf/2602.07903v1",
      "published_date": "2026-02-08 10:49:49 UTC",
      "updated_date": "2026-02-08 10:49:49 UTC",
      "processing_status": "completed",
      "attempts": 1,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "llm_backup_calls": 0,
      "last_update": "2026-02-16T05:21:59.417731+00:00"
    },
    {
      "arxiv_id": "2602.07901v1",
      "title": "Incremental Mapping with Measurement Synchronization & Compression",
      "title_zh": "具有测量同步与压缩功能的增量式建图",
      "authors": [
        "Mark Griguletskii",
        "Danil Belov",
        "Pavel Osinenko"
      ],
      "abstract": "Modern autonomous vehicles and robots utilize versatile sensors for localization and mapping. The fidelity of these maps is paramount, as an accurate environmental representation is a prerequisite for stable and precise localization. Factor graphs provide a powerful approach for sensor fusion, enabling the estimation of the maximum a posteriori solution. However, the discrete nature of graph-based representations, combined with asynchronous sensor measurements, complicates consistent state estimation. The design of an optimal factor graph topology remains an open challenge, especially in multi-sensor systems with asynchronous data. Conventional approaches rely on a rigid graph structure, which becomes inefficient with sensors of disparate rates. Although preintegration techniques can mitigate this for high-rate sensors, their applicability is limited. To address this problem, this work introduces a novel approach that incrementally constructs connected factor graphs, ensuring the incorporation of all available sensor data by choosing the optimal graph topology based on the external evaluation criteria. The proposed methodology facilitates graph compression, reducing the number of nodes (optimized variables) by ~30% on average while maintaining map quality at a level comparable to conventional approaches.",
      "tldr_zh": "该研究针对自动驾驶和机器人多传感器融合中的异步测量与状态估计一致性问题，提出了一种具有测量同步与压缩功能的增量建图方法。由于传统的Factor Graphs在处理采样频率差异较大的传感器数据时结构僵化且效率低下，该工作引入了一种能根据外部评估标准选择最优拓扑结构的增量构建框架，确保所有传感器数据均能被有效整合。该方法通过Graph Compression技术，在保持与传统方法相当的建图质量前提下，平均减少了约30%的优化变量（节点）数量。这一方案有效解决了多传感器系统在异步数据下的因子图拓扑设计挑战，显著提升了大规模环境下的计算效率与制图精度。",
      "categories": [
        "cs.RO",
        "cs.AI"
      ],
      "primary_category": "cs.RO",
      "comment": "8 pages, 4 figures, 1 table",
      "pdf_url": "https://arxiv.org/pdf/2602.07901v1",
      "published_date": "2026-02-08 10:43:11 UTC",
      "updated_date": "2026-02-08 10:43:11 UTC",
      "processing_status": "completed",
      "attempts": 1,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "llm_backup_calls": 0,
      "last_update": "2026-02-16T05:21:58.195720+00:00"
    },
    {
      "arxiv_id": "2602.07900v1",
      "title": "Rethinking the Value of Agent-Generated Tests for LLM-Based Software Engineering Agents",
      "title_zh": "重新审视智能体生成测试对基于大语言模型的软件工程智能体的价值",
      "authors": [
        "Zhi Chen",
        "Zhensu Sun",
        "Yuling Shi",
        "Chao Peng",
        "Xiaodong Gu",
        "David Lo",
        "Lingxiao Jiang"
      ],
      "abstract": "Large Language Model (LLM) code agents increasingly resolve repository-level issues by iteratively editing code, invoking tools, and validating candidate patches. In these workflows, agents often write tests on the fly, a paradigm adopted by many high-ranking agents on the SWE-bench leaderboard. However, we observe that GPT-5.2, which writes almost no new tests, can even achieve performance comparable to top-ranking agents. This raises the critical question: whether such tests meaningfully improve issue resolution or merely mimic human testing practices while consuming a substantial interaction budget.\n  To reveal the impact of agent-written tests, we present an empirical study that analyzes agent trajectories across six state-of-the-art LLMs on SWE-bench Verified. Our results show that while test writing is commonly adopted, but resolved and unresolved tasks within the same model exhibit similar test-writing frequencies Furthermore, these tests typically serve as observational feedback channels, where agents prefer value-revealing print statements significantly more than formal assertion-based checks. Based on these insights, we perform a controlled experiment by revising the prompts of four agents to either increase or reduce test writing. The results suggest that changes in the volume of agent-written tests do not significantly change final outcomes. Taken together, our study reveals that current test-writing practices may provide marginal utility in autonomous software engineering tasks.",
      "tldr_zh": "本研究对基于大语言模型（LLM）的软件工程智能体中智能体生成测试（Agent-Generated Tests）的实际价值进行了重新评估。针对目前许多在 SWE-bench 排行榜上名列前茅的智能体频繁编写测试以验证补丁的现状，作者观察到某些不编写测试的模型也能达到相当的性能，从而质疑此类测试是否真正有效提升了问题解决率。研究通过分析六种最先进（State-of-the-art）LLM 在 SWE-bench Verified 上的轨迹发现，无论任务是否成功解决，测试编写的频率并无显著差异。此外，智能体更倾向于使用能够揭示变量值的打印语句（Print statements），而非正式的基于断言（Assertion-based）的检查。随后的受控实验进一步表明，通过提示词工程（Prompt engineering）改变智能体编写测试的数量，并不会显著改变最终的任务结果。综上所述，当前的测试编写实践在自主软件工程任务中仅能提供边际效用（Marginal utility），该发现挑战了目前智能体设计中过度依赖自动生成测试的惯例。",
      "categories": [
        "cs.SE",
        "cs.AI"
      ],
      "primary_category": "cs.SE",
      "comment": "",
      "pdf_url": "https://arxiv.org/pdf/2602.07900v1",
      "published_date": "2026-02-08 10:26:31 UTC",
      "updated_date": "2026-02-08 10:26:31 UTC",
      "processing_status": "completed",
      "attempts": 1,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "llm_backup_calls": 0,
      "last_update": "2026-02-16T05:22:06.802094+00:00"
    },
    {
      "arxiv_id": "2602.07891v1",
      "title": "Scalable Adaptation of 3D Geometric Foundation Models via Weak Supervision from Internet Video",
      "title_zh": "基于互联网视频弱监督的 3D 几何基础模型可扩展适配",
      "authors": [
        "Zihui Gao",
        "Ke Liu",
        "Donny Y. Chen",
        "Duochao Shi",
        "Guosheng Lin",
        "Hao Chen",
        "Chunhua Shen"
      ],
      "abstract": "Geometric foundation models show promise in 3D reconstruction, yet their progress is severely constrained by the scarcity of diverse, large-scale 3D annotations. While Internet videos offer virtually unlimited raw data, utilizing them as a scaling source for geometric learning is challenging due to the absence of ground-truth geometry and the presence of observational noise. To address this, we propose SAGE, a framework for Scalable Adaptation of GEometric foundation models from raw video streams. SAGE leverages a hierarchical mining pipeline to transform videos into training trajectories and hybrid supervision: (1) Informative training trajectory selection; (2) Sparse Geometric Anchoring via SfM point clouds for global structural guidance; and (3) Dense Differentiable Consistency via 3D Gaussian rendering for multi-view constraints. To prevent catastrophic forgetting, we introduce a regularization strategy using anchor data. Extensive experiments show that SAGE significantly enhances zero-shot generalization, reducing Chamfer Distance by 20-42% on unseen benchmarks (7Scenes, TUM-RGBD, Matterport3D) compared to state-of-the-art baselines. To our knowledge, SAGE pioneers the adaptation of geometric foundation models via Internet video, establishing a scalable paradigm for general-purpose 3D learning.",
      "tldr_zh": "该研究针对3D几何基础模型(Geometric Foundation Models)因大规模3D标注数据稀缺而受限的问题，提出了一种名为SAGE的框架，利用互联网视频作为数据源进行可扩展适配。该框架通过分层挖掘流程将视频流转化为训练轨迹，并结合了利用SfM点云的稀疏几何锚定(Sparse Geometric Anchoring)和基于3D高斯渲染(3D Gaussian rendering)的稠密微分一致性(Dense Differentiable Consistency)进行混合监督。为了避免灾难性遗忘(Catastrophic Forgetting)，SAGE引入了针对锚定数据的正则化策略以维持模型稳定性。实验表明，SAGE在7Scenes、TUM-RGBD和Matterport3D等多个基准测试中显著增强了零样本泛化(Zero-shot Generalization)能力，将倒角距离(Chamfer Distance)降低了20-42%。该研究开创了利用海量互联网视频进行几何基础模型适配的先河，为大规模通用3D学习提供了一种高效且可扩展的新范式。",
      "categories": [
        "cs.CV",
        "cs.AI"
      ],
      "primary_category": "cs.CV",
      "comment": "",
      "pdf_url": "https://arxiv.org/pdf/2602.07891v1",
      "published_date": "2026-02-08 09:53:21 UTC",
      "updated_date": "2026-02-08 09:53:21 UTC",
      "processing_status": "completed",
      "attempts": 1,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "llm_backup_calls": 0,
      "last_update": "2026-02-16T05:22:12.003753+00:00"
    },
    {
      "arxiv_id": "2602.07886v1",
      "title": "Rich-ARQ: From 1-bit Acknowledgment to Rich Neural Coded Feedback",
      "title_zh": "Rich-ARQ：从 1-bit 确认到丰富神经编码反馈",
      "authors": [
        "Enhao Chen",
        "Yulin Shao"
      ],
      "abstract": "This paper reimagines the foundational feedback mechanism in wireless communication, transforming the prevailing 1-bit binary ACK/NACK with a high-dimensional, information-rich vector to transform passive acknowledgment into an active collaboration. We present Rich-ARQ, a paradigm that introduces neural-coded feedback for collaborative physical-layer channel coding between transmitter and receiver. To realize this vision in practice, we develop a novel asynchronous feedback code that eliminates stalling from feedback delays, adapts dynamically to channel fluctuations, and features a lightweight encoder suitable for on-device deployment. We materialize this concept into the first full-stack, standard-compliant software-defined radio prototype, which decouples AI inference from strict radio timing. Comprehensive over-the-air experiments demonstrate that Rich-ARQ achieves significant SNR gains over conventional 1-bit hybrid ARQ and remarkable latency reduction over prior learning-based feedback codes, moving the promise of intelligent feedback from theory to a practical, high-performance reality for next-generation networks.",
      "tldr_zh": "该研究提出了 Rich-ARQ，一种将无线通信中传统的 1-bit ACK/NACK 反馈机制转变为高维、信息丰富的 neural-coded feedback 的新范式，旨在实现发送端与接收端在物理层信道编码上的主动协作。为了在实践中解决反馈延迟和计算开销问题，研究团队开发了一种新型异步反馈码，其具备动态适应信道波动和消除反馈停顿的能力，并采用了适合设备端部署的轻量级编码器。该方案被成功实现为首个符合标准的全栈软件定义无线电 (SDR) 原型，通过解耦 AI 推理与无线电时序确保了系统的实时性。实验数据表明，Rich-ARQ 相比于传统的 1-bit hybrid ARQ 获得了显著的 SNR 增益，并相较于以往基于学习的反馈码大幅降低了延迟。这一突破标志着智能反馈技术从理论研究迈向了高性能的实际落地，为下一代协作式物理层设计提供了重要参考。",
      "categories": [
        "cs.IT",
        "cs.AI"
      ],
      "primary_category": "cs.IT",
      "comment": "",
      "pdf_url": "https://arxiv.org/pdf/2602.07886v1",
      "published_date": "2026-02-08 09:37:42 UTC",
      "updated_date": "2026-02-08 09:37:42 UTC",
      "processing_status": "completed",
      "attempts": 1,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "llm_backup_calls": 0,
      "last_update": "2026-02-16T05:22:21.010972+00:00"
    },
    {
      "arxiv_id": "2602.07885v1",
      "title": "MemFly: On-the-Fly Memory Optimization via Information Bottleneck",
      "title_zh": "MemFly：基于信息瓶颈的即时记忆优化",
      "authors": [
        "Zhenyuan Zhang",
        "Xianzhang Jia",
        "Zhiqin Yang",
        "Zhenbo Song",
        "Wei Xue",
        "Sirui Han",
        "Yike Guo"
      ],
      "abstract": "Long-term memory enables large language model agents to tackle complex tasks through historical interactions. However, existing frameworks encounter a fundamental dilemma between compressing redundant information efficiently and maintaining precise retrieval for downstream tasks. To bridge this gap, we propose MemFly, a framework grounded in information bottleneck principles that facilitates on-the-fly memory evolution for LLMs. Our approach minimizes compression entropy while maximizing relevance entropy via a gradient-free optimizer, constructing a stratified memory structure for efficient storage. To fully leverage MemFly, we develop a hybrid retrieval mechanism that seamlessly integrates semantic, symbolic, and topological pathways, incorporating iterative refinement to handle complex multi-hop queries. Comprehensive experiments demonstrate that MemFly substantially outperforms state-of-the-art baselines in memory coherence, response fidelity, and accuracy.",
      "tldr_zh": "该研究提出了 MemFly，一种基于信息瓶颈 (Information Bottleneck) 原则的框架，旨在解决大语言模型智能体 (LLM agents) 在处理长期记忆时面临的冗余信息压缩与精确检索之间的矛盾。该框架利用无梯度优化器 (gradient-free optimizer) 在最小化压缩熵的同时最大化相关熵，实现了即时的记忆演化并构建出高效的分层记忆结构 (stratified memory structure)。为充分利用该结构，研究者开发了一套整合语义、符号与拓扑路径的混合检索机制，并通过迭代细化技术有效处理复杂的多次跳转查询 (multi-hop queries)。实验结果显示，MemFly 在记忆连贯性、响应保真度和准确性方面均显著优于目前最先进的基线模型。",
      "categories": [
        "cs.AI",
        "cs.LG"
      ],
      "primary_category": "cs.AI",
      "comment": "",
      "pdf_url": "https://arxiv.org/pdf/2602.07885v1",
      "published_date": "2026-02-08 09:37:25 UTC",
      "updated_date": "2026-02-08 09:37:25 UTC",
      "processing_status": "completed",
      "attempts": 1,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "llm_backup_calls": 0,
      "last_update": "2026-02-16T05:22:22.338860+00:00"
    },
    {
      "arxiv_id": "2602.07884v1",
      "title": "GRAFT: Decoupling Ranking and Calibration for Survival Analysis",
      "title_zh": "GRAFT：面向生存分析的排序与校准解耦",
      "authors": [
        "Mohammad Ashhad",
        "Robert Hoehndorf",
        "Ricardo Henao"
      ],
      "abstract": "Survival analysis is complicated by censored data, high-dimensional features, and non-linear interactions. Classical models are interpretable but restrictive, while deep learning models are flexible but often non-interpretable and sensitive to noise. We propose GRAFT (Gated Residual Accelerated Failure Time), a novel AFT model that decouples prognostic ranking from calibration. GRAFT's hybrid architecture combines a linear AFT model with a non-linear residual neural network, and it also integrates stochastic gates for automatic, end-to-end feature selection. The model is trained by directly optimizing a differentiable, C-index-aligned ranking loss using stochastic conditional imputation from local Kaplan-Meier estimators. In public benchmarks, GRAFT outperforms baselines in discrimination and calibration, while remaining robust and sparse in high-noise settings.",
      "tldr_zh": "该研究提出了GRAFT (Gated Residual Accelerated Failure Time)，这是一种新型的加速失效时间(AFT)模型，旨在解决生存分析(Survival analysis)中审查数据(Censored data)和高维特征带来的挑战。该模型采用混合架构，将线性AFT模型与非线性残差神经网络结合，实现了预后排序(Prognostic ranking)与校准(Calibration)的解耦。GRAFT集成了随机门控机制，用于自动化的端到端特征选择，并通过优化与C-index对齐的微分排序损失进行训练。该过程结合了局部Kaplan-Meier估计器的随机条件归补技术，以处理复杂的数据交互。实验结果表明，GRAFT在公开基准测试中的区分度和校准性能均优于基线模型。在高噪声设置下，该模型展现出极强的鲁棒性和稀疏性，为可解释且灵活的生存分析提供了有效的解决方案。",
      "categories": [
        "cs.LG",
        "cs.AI"
      ],
      "primary_category": "cs.LG",
      "comment": "",
      "pdf_url": "https://arxiv.org/pdf/2602.07884v1",
      "published_date": "2026-02-08 09:32:24 UTC",
      "updated_date": "2026-02-08 09:32:24 UTC",
      "processing_status": "completed",
      "attempts": 1,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "llm_backup_calls": 0,
      "last_update": "2026-02-16T05:22:14.211991+00:00"
    },
    {
      "arxiv_id": "2602.07883v1",
      "title": "ToolSelf: Unifying Task Execution and Self-Reconfiguration via Tool-Driven Intrinsic Adaptation",
      "title_zh": "ToolSelf：通过工具驱动的内在自适应实现任务执行与自我重构的统一",
      "authors": [
        "Jingqi Zhou",
        "Sheng Wang",
        "DeZhao Deng",
        "Junwen Lu",
        "Junwei Su",
        "Qintong Li",
        "Jiahui Gao",
        "Hao Wu",
        "Jiyue Jiang",
        "Lingpeng Kong",
        "Chuan Wu"
      ],
      "abstract": "Agentic systems powered by Large Language Models (LLMs) have demonstrated remarkable potential in tackling complex, long-horizon tasks. However, their efficacy is fundamentally constrained by static configurations governing agent behaviors, which are fixed prior to execution and fail to adapt to evolving task dynamics. Existing approaches, relying on manual orchestration or heuristic-based patches, often struggle with poor generalization and fragmented optimization. To transcend these limitations, we propose ToolSelf, a novel paradigm enabling tool-driven runtime self-reconfiguration. By abstracting configuration updates as a callable tool, ToolSelf unifies task execution and self-adjustment into a single action space, achieving a phase transition from external rules to intrinsic parameters. Agents can thereby autonomously update their sub-goals and context based on task progression, and correspondingly adapt their strategy and toolbox, transforming from passive executors into dual managers of both task and self. We further devise Configuration-Aware Two-stage Training (CAT), combining rejection sampling fine-tuning with trajectory-level reinforcement learning to internalize this meta-capability. Extensive experiments across diverse benchmarks demonstrate that ToolSelf rivals specialized workflows while generalizing to novel tasks, achieving a 24.1% average performance gain and illuminating a path toward truly self-adaptive agents.",
      "tldr_zh": "该研究提出了ToolSelf，一种使大语言模型（LLMs）驱动的智能体实现工具驱动运行时自我重构（tool-driven runtime self-reconfiguration）的新范式，旨在解决现有智能体因静态配置（static configurations）导致的适应性差和泛化能力弱等问题。ToolSelf通过将配置更新抽象为可调用工具，将任务执行与自我调整统一到单个动作空间中，使智能体能够根据任务进展自主更新子目标、上下文及工具箱。为了内化这种元能力（meta-capability），研究团队设计了结合拒绝采样微调与轨迹级强化学习的配置感知两阶段训练（Configuration-Aware Two-stage Training, CAT）方法。实验结果表明，ToolSelf在多个基准测试中表现优于专门的工作流，实现了24.1%的平均性能提升，为构建真正自适应的智能体提供了新路径。",
      "categories": [
        "cs.AI"
      ],
      "primary_category": "cs.AI",
      "comment": "",
      "pdf_url": "https://arxiv.org/pdf/2602.07883v1",
      "published_date": "2026-02-08 09:27:18 UTC",
      "updated_date": "2026-02-08 09:27:18 UTC",
      "processing_status": "completed",
      "attempts": 1,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "llm_backup_calls": 0,
      "last_update": "2026-02-16T05:22:31.401698+00:00"
    },
    {
      "arxiv_id": "2602.07881v1",
      "title": "Deep Variable-Length Feedback Codes",
      "title_zh": "深度变长反馈码",
      "authors": [
        "Yu Ding",
        "Yulin Shao"
      ],
      "abstract": "Deep learning has enabled significant advances in feedback-based channel coding, yet existing learned schemes remain fundamentally limited: they employ fixed block lengths, suffer degraded performance at high rates, and cannot fully exploit the adaptive potential of feedback. This paper introduces Deep Variable-Length Feedback (DeepVLF) coding, a flexible coding framework that dynamically adjusts transmission length via learned feedback. We propose two complementary architectures: DeepVLF-R, where termination is receiver-driven, and DeepVLF-T, where the transmitter controls termination. Both architectures leverage bit-group partitioning and transformer-based encoder-decoder networks to enable fine-grained rate adaptation in response to feedback. Evaluations over AWGN and 5G-NR fading channels demonstrate that DeepVLF substantially outperforms state-of-the-art learned feedback codes. It achieves the same block error rate with 20%-55% fewer channel uses and lowers error floors by orders of magnitude, particularly in high-rate regimes. Encoding dynamics analysis further reveals that the models autonomously learn a two-phase strategy analogous to classical Schalkwijk-Kailath coding: an initial information-carrying phase followed by a noise-cancellation refinement phase. This emergent behavior underscores the interpretability and information-theoretic alignment of the learned codes.",
      "tldr_zh": "该研究提出了 Deep Variable-Length Feedback (DeepVLF) 编码框架，旨在解决现有深度学习反馈编码中固定块长度和在高码率下性能受限的问题。该框架包含 DeepVLF-R 和 DeepVLF-T 两种架构，分别由接收机和发射机控制传输终止，并结合 bit-group partitioning 与基于 transformer 的网络实现细粒度的速率自适应。在 AWGN 和 5G-NR 衰落信道上的评估显示，DeepVLF 在实现相同块误码率 (BLER) 的前提下，比现有学习反馈码减少了 20%-55% 的信道使用量，并显著降低了误码底。动力学分析进一步表明，该模型能自动演化出类似于经典 Schalkwijk-Kailath 编码的两阶段策略，即初始信息承载阶段与随后的噪声消除精细化阶段，体现了学习编码方案的可解释性与信息论一致性。",
      "categories": [
        "cs.IT",
        "cs.AI"
      ],
      "primary_category": "cs.IT",
      "comment": "",
      "pdf_url": "https://arxiv.org/pdf/2602.07881v1",
      "published_date": "2026-02-08 09:20:16 UTC",
      "updated_date": "2026-02-08 09:20:16 UTC",
      "processing_status": "completed",
      "attempts": 1,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "llm_backup_calls": 0,
      "last_update": "2026-02-16T05:22:39.915090+00:00"
    },
    {
      "arxiv_id": "2602.07878v1",
      "title": "Rethinking Latency Denial-of-Service: Attacking the LLM Serving Framework, Not the Model",
      "title_zh": "重新审视延迟拒绝服务：针对大语言模型推理框架而非模型本身的攻击",
      "authors": [
        "Tianyi Wang",
        "Huawei Fan",
        "Yuanchao Shu",
        "Peng Cheng",
        "Cong Wang"
      ],
      "abstract": "Large Language Models face an emerging and critical threat known as latency attacks. Because LLM inference is inherently expensive, even modest slowdowns can translate into substantial operating costs and severe availability risks. Recently, a growing body of research has focused on algorithmic complexity attacks by crafting inputs to trigger worst-case output lengths. However, we report a counter-intuitive finding that these algorithmic latency attacks are largely ineffective against modern LLM serving systems. We reveal that system-level optimization such as continuous batching provides a logical isolation to mitigate contagious latency impact on co-located users. To this end, in this paper, we shift the focus from the algorithm to the system layer, and introduce a new Fill and Squeeze attack strategy targeting the state transition of the scheduler. \"Fill\" first exhausts the global KV cache to induce Head-of-Line blocking, while \"Squeeze\" forces the system into repetitive preemption. By manipulating output lengths using methods from simple plain-text prompts to more complex prompt engineering, and leveraging side-channel probing of memory status, we demonstrate that the attack can be orchestrated in a black-box setting with much less cost. Extensive evaluations indicate by up to 20-280x average slowdown on Time to First Token and 1.5-4x average slowdown on Time Per Output Token compared to existing attacks with 30-40% lower attack cost.",
      "tldr_zh": "该研究指出，由于现代 Large Language Models (LLMs) 推理服务系统采用了 continuous batching 等系统级优化，传统的针对算法复杂度的延迟攻击已基本失效。为此，本文将攻击重心从模型算法转向系统层，提出了一种针对调度器 (scheduler) 状态转换的新型 Fill and Squeeze 攻击策略。该方法通过 \"Fill\" 操作耗尽全局 KV cache 以诱发 Head-of-Line 阻塞，并通过 \"Squeeze\" 操作迫使系统进入重复的抢占 (preemption) 循环。利用 Prompt Engineering 和对内存状态的侧信道探测 (side-channel probing)，攻击者可以在黑盒环境下以更低成本策划攻击。实验结果显示，该策略相比现有攻击可导致 Time to First Token (TTFT) 产生 20-280 倍的平均延迟，Time Per Output Token (TPOT) 产生 1.5-4 倍的延迟，同时使攻击成本降低了 30-40%。该研究揭示了 LLM 服务框架在处理资源状态切换时存在的严重安全漏洞，为构建更具韧性的推理系统提供了重要参考。",
      "categories": [
        "cs.CR",
        "cs.AI"
      ],
      "primary_category": "cs.CR",
      "comment": "",
      "pdf_url": "https://arxiv.org/pdf/2602.07878v1",
      "published_date": "2026-02-08 09:05:54 UTC",
      "updated_date": "2026-02-08 09:05:54 UTC",
      "processing_status": "completed",
      "attempts": 1,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "llm_backup_calls": 0,
      "last_update": "2026-02-16T05:22:44.115703+00:00"
    },
    {
      "arxiv_id": "2602.07873v1",
      "title": "Direct Soft-Policy Sampling via Langevin Dynamics",
      "title_zh": "基于 Langevin 动力学的直接软策略采样",
      "authors": [
        "Donghyeon Ki",
        "Hee-Jun Ahn",
        "Kyungyoon Kim",
        "Byung-Jun Lee"
      ],
      "abstract": "Soft policies in reinforcement learning define policies as Boltzmann distributions over state-action value functions, providing a principled mechanism for balancing exploration and exploitation. However, realizing such soft policies in practice remains challenging. Existing approaches either depend on parametric policies with limited expressivity or employ diffusion-based policies whose intractable likelihoods hinder reliable entropy estimation in soft policy objectives. We address this challenge by directly realizing soft-policy sampling via Langevin dynamics driven by the action gradient of the Q-function. This perspective leads to Langevin Q-Learning (LQL), which samples actions from the target Boltzmann distribution without explicitly parameterizing the policy. However, directly applying Langevin dynamics suffers from slow mixing in high-dimensional and non-convex Q-landscapes, limiting its practical effectiveness. To overcome this, we propose Noise-Conditioned Langevin Q-Learning (NC-LQL), which integrates multi-scale noise perturbations into the value function. NC-LQL learns a noise-conditioned Q-function that induces a sequence of progressively smoothed value landscapes, enabling sampling to transition from global exploration to precise mode refinement. On OpenAI Gym MuJoCo benchmarks, NC-LQL achieves competitive performance compared to state-of-the-art diffusion-based methods, providing a simple yet powerful solution for online RL.",
      "tldr_zh": "该研究针对强化学习中软策略（Soft Policies）难以实现的问题，提出了Langevin Q-Learning (LQL) 框架，通过利用Q函数的动作梯度驱动 Langevin Dynamics 直接从 Boltzmann 分布中采样，从而避免了对策略进行显式参数化的限制。为了解决传统 Langevin 动力学在高维非凸Q值景观中混合速度慢的难题，研究进一步提出了噪声调节 Langevin Q-Learning (NC-LQL)，通过在价值函数中引入多尺度噪声扰动，引导采样过程从全局探索平滑过渡到精确的状态细化。实验结果表明，NC-LQL 在 OpenAI Gym MuJoCo 基准测试中达到了与最先进的扩散模型（Diffusion-based methods）相当的性能。该方法为在线强化学习提供了一种简单且高效的解决方案，在保证策略表达能力的性同时，实现了更可靠的探索与开发平衡。",
      "categories": [
        "cs.LG",
        "cs.AI"
      ],
      "primary_category": "cs.LG",
      "comment": "",
      "pdf_url": "https://arxiv.org/pdf/2602.07873v1",
      "published_date": "2026-02-08 09:01:54 UTC",
      "updated_date": "2026-02-08 09:01:54 UTC",
      "processing_status": "completed",
      "attempts": 1,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "llm_backup_calls": 0,
      "last_update": "2026-02-16T05:22:46.698555+00:00"
    },
    {
      "arxiv_id": "2602.07865v1",
      "title": "Orchestrating Attention: Bringing Harmony to the 'Chaos' of Neurodivergent Learning States",
      "title_zh": "注意力编排：化神经多样性学习状态的“混沌”为和谐",
      "authors": [
        "Satyam Kumar Navneet",
        "Joydeep Chandra",
        "Yong Zhang"
      ],
      "abstract": "Adaptive learning systems optimize content delivery based on performance metrics but ignore the dynamic attention fluctuations that characterize neurodivergent learners. We present AttentionGuard, a framework that detects engagement-attention states from privacy-preserving behavioral signals and adapts interface elements accordingly. Our approach models four attention states derived from ADHD phenomenology and implements five novel UI adaptation patterns including bi-directional scaffolding that responds to both understimulation and overstimulation. We validate our detection model on the OULAD dataset, achieving 87.3% classification accuracy, and demonstrate correlation with clinical ADHD profiles through cross-validation on the HYPERAKTIV dataset. A Wizard-of-Oz study with 11 adults showing ADHD characteristics found significantly reduced cognitive load in the adaptive condition (NASA-TLX: 47.2 vs 62.8, Cohen's d=1.21, p=0.008) and improved comprehension (78.4% vs 61.2%, p=0.009). Concordance analysis showed 84% agreement between wizard decisions and automated classifier predictions, supporting deployment feasibility. The system is presented as an interactive demo where observers can inspect detected attention states, observe real-time UI adaptations, and compare automated decisions with human-in-the-loop overrides. We contribute empirically validated UI patterns for attention-adaptive interfaces and evidence that behavioral attention detection can meaningfully support neurodivergent learning experiences.",
      "tldr_zh": "该研究提出了AttentionGuard，一个旨在解决自适应学习系统忽视神经多样性(neurodivergent)学习者动态注意力波动的框架。该框架通过保护隐私的行为信号检测参与度和注意力状态，并基于ADHD现象学建模了四种注意力状态。研究还设计了五种新型UI改编模式，包括针对刺激不足和过度刺激的双向脚手架(scaffolding)技术。在OULAD数据集上的实验显示该模型分类准确率达87.3%，并与HYPERAKTIV数据集中的临床ADHD概况具有强相关性。针对11名具有ADHD特征受试者的Wizard-of-Oz研究表明，AttentionGuard显著降低了认知负荷(NASA-TLX)并提高了理解能力。该研究通过实证验证了注意力自适应界面的UI模式，证明了行为注意力检测能有效支持神经多样性学习者的学习体验。",
      "categories": [
        "cs.HC",
        "cs.AI"
      ],
      "primary_category": "cs.HC",
      "comment": "",
      "pdf_url": "https://arxiv.org/pdf/2602.07865v1",
      "published_date": "2026-02-08 08:33:57 UTC",
      "updated_date": "2026-02-08 08:33:57 UTC",
      "processing_status": "completed",
      "attempts": 1,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "llm_backup_calls": 0,
      "last_update": "2026-02-16T05:22:53.407115+00:00"
    },
    {
      "arxiv_id": "2602.07852v1",
      "title": "Emergent Misalignment is Easy, Narrow Misalignment is Hard",
      "title_zh": "涌现性非对齐易，狭义非对齐难",
      "authors": [
        "Anna Soligo",
        "Edward Turner",
        "Senthooran Rajamanoharan",
        "Neel Nanda"
      ],
      "abstract": "Finetuning large language models on narrowly harmful datasets can cause them to become emergently misaligned, giving stereotypically `evil' responses across diverse unrelated settings. Concerningly, a pre-registered survey of experts failed to predict this result, highlighting our poor understanding of the inductive biases governing learning and generalisation in LLMs. We use emergent misalignment (EM) as a case study to investigate these inductive biases and find that models can just learn the narrow dataset task, but that the general solution appears to be more stable and more efficient. To establish this, we build on the result that different EM finetunes converge to the same linear representation of general misalignment, which can be used to mediate misaligned behaviour. We find a linear representation of the narrow solution also exists, and can be learned by introducing a KL divergence loss. Comparing these representations reveals that general misalignment achieves lower loss, is more robust to perturbations, and is more influential in the pre-training distribution. This work isolates a concrete representation of general misalignment for monitoring and mitigation. More broadly, it offers a detailed case study and preliminary metrics for investigating how inductive biases shape generalisation in LLMs. We open-source all code, datasets and model finetunes.",
      "tldr_zh": "该研究探讨了大型语言模型（LLMs）中出现的紧急不对齐（Emergent Misalignment, EM）现象，即在窄分布的有害数据集上微调可能导致模型在广泛且无关的场景中产生恶意的输出。作者发现模型虽然可以仅学习特定的窄任务，但“通用不对齐”的泛化解决方案在微调过程中表现得更稳定且效率更高。通过构建通用不对齐的线性表示（Linear Representation），研究证明该泛化方案比局部解决方案具有更低的损失、更强的鲁棒性，并且在预训练分布中更具影响力。实验结果揭示了LLMs在学习和泛化过程中的归纳偏置（Inductive Biases），并为监控和缓解模型不对齐提供了具体的表示工具。该工作不仅开源了相关代码和数据集，还为研究诱导偏置如何塑造模型泛化行为提供了初步指标和案例参考。",
      "categories": [
        "cs.AI",
        "cs.CL"
      ],
      "primary_category": "cs.AI",
      "comment": "Published at ICLR 2026",
      "pdf_url": "https://arxiv.org/pdf/2602.07852v1",
      "published_date": "2026-02-08 07:50:04 UTC",
      "updated_date": "2026-02-08 07:50:04 UTC",
      "processing_status": "completed",
      "attempts": 1,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "llm_backup_calls": 0,
      "last_update": "2026-02-16T05:22:50.000990+00:00"
    },
    {
      "arxiv_id": "2602.07849v1",
      "title": "LQA: A Lightweight Quantized-Adaptive Framework for Vision-Language Models on the Edge",
      "title_zh": "LQA：面向边缘侧视觉-语言模型的轻量级量化自适应框架",
      "authors": [
        "Xin Wang",
        "Hualin Zhou",
        "Sheng Guang Wang",
        "Ting Dang",
        "Yu Zhang",
        "Hong Jia",
        "Tao Gu"
      ],
      "abstract": "Deploying Vision-Language Models (VLMs) on edge devices is challenged by resource constraints and performance degradation under distribution shifts. While test-time adaptation (TTA) can counteract such shifts, existing methods are too resource-intensive for on-device deployment. To address this challenge, we propose LQA, a lightweight, quantized-adaptive framework for VLMs that combines a modality-aware quantization strategy with gradient-free test-time adaptation. We introduce Selective Hybrid Quantization (SHQ) and a quantized, gradient-free adaptation mechanism to enable robust and efficient VLM deployment on resource-constrained hardware. Experiments across both synthetic and real-world distribution shifts show that LQA improves overall adaptation performance by 4.5\\%, uses less memory than full-precision models, and significantly outperforms gradient-based TTA methods, achieving up to 19.9$\\times$ lower memory usage across seven open-source datasets. These results demonstrate that LQA offers a practical pathway for robust, privacy-preserving, and efficient VLM deployment on edge devices.",
      "tldr_zh": "该研究提出了LQA，这是一个专为边缘设备设计的轻量级量化自适应框架，旨在解决视觉语言模型(Vision-Language Models, VLMs)在资源受限及分布偏移(distribution shifts)环境下部署难的问题。该框架创新性地结合了模态感知量化策略(modality-aware quantization strategy)与无梯度测试时自适应(gradient-free test-time adaptation)技术。通过引入选择性混合量化(Selective Hybrid Quantization, SHQ)和量化的无梯度自适应机制，LQA能够实现在硬件受限条件下的鲁棒且高效部署。实验结果表明，LQA在多种分布偏移场景下将整体自适应性能提升了4.5%，且其内存占用显著低于全精度模型。在涵盖七个开源数据集的测试中，LQA的内存消耗比传统的基于梯度的测试时自适应(TTA)方法降低了高达19.9倍。这项工作为在边缘设备上实现稳健、隐私保护且高效的VLMs部署提供了一条切实可行的技术路径。",
      "categories": [
        "cs.AI"
      ],
      "primary_category": "cs.AI",
      "comment": "16 pages, 9 figures ,9 tables, preprint",
      "pdf_url": "https://arxiv.org/pdf/2602.07849v1",
      "published_date": "2026-02-08 07:37:37 UTC",
      "updated_date": "2026-02-08 07:37:37 UTC",
      "processing_status": "completed",
      "attempts": 1,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "llm_backup_calls": 0,
      "last_update": "2026-02-16T05:22:56.805267+00:00"
    },
    {
      "arxiv_id": "2602.07840v2",
      "title": "SAGE: Scalable AI Governance & Evaluation",
      "title_zh": "SAGE：可扩展的人工智能治理与评估",
      "authors": [
        "Benjamin Le",
        "Xueying Lu",
        "Nick Stern",
        "Wenqiong Liu",
        "Igor Lapchuk",
        "Xiang Li",
        "Baofen Zheng",
        "Kevin Rosenberg",
        "Jiewen Huang",
        "Zhe Zhang",
        "Abraham Cabangbang",
        "Satej Milind Wagle",
        "Jianqiang Shen",
        "Raghavan Muthuregunathan",
        "Abhinav Gupta",
        "Mathew Teoh",
        "Andrew Kirk",
        "Thomas Kwan",
        "Jingwei Wu",
        "Wenjing Zhang"
      ],
      "abstract": "Evaluating relevance in large-scale search systems is fundamentally constrained by the governance gap between nuanced, resource-constrained human oversight and the high-throughput requirements of production systems. While traditional approaches rely on engagement proxies or sparse manual review, these methods often fail to capture the full scope of high-impact relevance failures. We present \\textbf{SAGE} (Scalable AI Governance \\& Evaluation), a framework that operationalizes high-quality human product judgment as a scalable evaluation signal. At the core of SAGE is a bidirectional calibration loop where natural-language \\emph{Policy}, curated \\emph{Precedent}, and an \\emph{LLM Surrogate Judge} co-evolve. SAGE systematically resolves semantic ambiguities and misalignments, transforming subjective relevance judgment into an executable, multi-dimensional rubric with near human-level agreement. To bridge the gap between frontier model reasoning and industrial-scale inference, we apply teacher-student distillation to transfer high-fidelity judgments into compact student surrogates at \\textbf{92$\\times$} lower cost. Deployed within LinkedIn Search ecosystems, SAGE guided model iteration through simulation-driven development, distilling policy-aligned models for online serving and enabling rapid offline evaluation. In production, it powered policy oversight that measured ramped model variants and detected regressions invisible to engagement metrics. Collectively, these drove a \\textbf{0.25\\%} lift in LinkedIn daily active users.",
      "tldr_zh": "该研究提出了SAGE (Scalable AI Governance & Evaluation) 框架，旨在解决大规模搜索系统中人工监督与高吞吐量生产需求之间的治理差距。SAGE的核心是一个双向校准循环，通过自然语言策略 (Policy)、策划的先例 (Precedent) 和大语言模型代理法官 (LLM Surrogate Judge) 的协同演进，将主观的相关性判断转化为可执行的多维指标。为了满足工业规模的推理需求，该框架采用教师-学生蒸馏技术 (teacher-student distillation)，将高保真判断转移到紧凑的代理模型中，使成本降低了92倍。在LinkedIn搜索生态系统中的部署结果表明，SAGE能够有效指导模型迭代并识别传统参与度指标无法捕捉的回归问题。该框架不仅实现了近乎人类水平的评估一致性，还最终带动了LinkedIn日活跃用户数 (DAU) 提升0.25%，为大规模人工智能治理提供了可扩展的解决方案。",
      "categories": [
        "cs.IR",
        "cs.AI"
      ],
      "primary_category": "cs.IR",
      "comment": "",
      "pdf_url": "https://arxiv.org/pdf/2602.07840v2",
      "published_date": "2026-02-08 06:42:50 UTC",
      "updated_date": "2026-02-10 03:26:08 UTC",
      "processing_status": "completed",
      "attempts": 1,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "llm_backup_calls": 0,
      "last_update": "2026-02-16T05:22:57.609451+00:00"
    },
    {
      "arxiv_id": "2602.07839v1",
      "title": "TodoEvolve: Learning to Architect Agent Planning Systems",
      "title_zh": "TodoEvolve：学习构建智能体规划系统架构",
      "authors": [
        "Jiaxi Liu",
        "Yanzuo Jiang",
        "Guibin Zhang",
        "Zihan Zhang",
        "Heng Chang",
        "Zhenfei Yin",
        "Qibing Ren",
        "Junchi Yan"
      ],
      "abstract": "Planning has become a central capability for contemporary agent systems in navigating complex, long-horizon tasks, yet existing approaches predominantly rely on fixed, hand-crafted planning structures that lack the flexibility to adapt to the structural diversity of open-ended problems. To address this limitation, we introduce TodoEvolve, a meta-planning paradigm that autonomously synthesizes and dynamically revises task-specific planning architectures. Specifically, we first construct PlanFactory, a modular design space that standardizes diverse planning paradigms within a unified codebase encompassing topology, initialization, adaptation, and navigation, thereby providing a common interface for heterogeneous planning patterns. Leveraging PlanFactory, we collect high-quality planning trajectories and train Todo-14B via \\textit{Impedance-Guided Preference Optimization} (IGPO), a multi-objective reinforcement learning objective that encourages the generation of planning systems that are performant, stable, and token-efficient across arbitrary tasks and agent backbones. Empirical evaluations on five agentic benchmarks demonstrate that TodoEvolve consistently surpasses carefully engineered planning modules while maintaining economical API costs and runtime overhead.",
      "tldr_zh": "该研究提出了 TodoEvolve，一种旨在克服现有智能体系统依赖固定、手工规划结构局限性的元规划范式 (meta-planning paradigm)，能够自主合成并动态修订特定任务的规划架构。通过构建模块化的设计空间 PlanFactory，该框架将拓扑、初始化、适配和导航等异构规划模式统一在标准化接口下。研究者利用 PlanFactory 收集的高质量轨迹，通过阻抗引导偏好优化 (Impedance-Guided Preference Optimization, IGPO) 这一多目标强化学习算法训练了 Todo-14B 模型。该模型旨在生成在不同任务和智能体骨干网络中均具备高性能、高稳定性且 Token 效率优异的规划系统。实验结果显示，TodoEvolve 在五个智能体基准测试中均超越了传统的手工设计模块，同时保持了较低的 API 成本和运行开销。该成果为实现能够根据复杂任务需求自动演进的智能体规划系统提供了重要技术路径。",
      "categories": [
        "cs.CL",
        "cs.AI",
        "cs.LG"
      ],
      "primary_category": "cs.CL",
      "comment": "",
      "pdf_url": "https://arxiv.org/pdf/2602.07839v1",
      "published_date": "2026-02-08 06:37:01 UTC",
      "updated_date": "2026-02-08 06:37:01 UTC",
      "processing_status": "completed",
      "attempts": 1,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "llm_backup_calls": 0,
      "last_update": "2026-02-16T05:23:03.507732+00:00"
    },
    {
      "arxiv_id": "2602.07833v1",
      "title": "SPD-Faith Bench: Diagnosing and Improving Faithfulness in Chain-of-Thought for Multimodal Large Language Models",
      "title_zh": "SPD-Faith Bench：多模态大语言模型思维链忠实性的诊断与提升",
      "authors": [
        "Weijiang Lv",
        "Yaoxuan Feng",
        "Xiaobo Xia",
        "Jiayu Wang",
        "Yan Jing",
        "Wenchao Chen",
        "Bo Chen"
      ],
      "abstract": "Chain-of-Thought reasoning is widely used to improve the interpretability of multimodal large language models (MLLMs), yet the faithfulness of the generated reasoning traces remains unclear. Prior work has mainly focused on perceptual hallucinations, leaving reasoning level unfaithfulness underexplored. To isolate faithfulness from linguistic priors, we introduce SPD-Faith Bench, a diagnostic benchmark based on fine-grained image difference reasoning that enforces explicit visual comparison. Evaluations on state-of-the-art MLLMs reveal two systematic failure modes, perceptual blindness and perception-reasoning dissociation. We trace these failures to decaying visual attention and representation shifts in the residual stream. Guided by this analysis, we propose SAGE, a train-free visual evidence-calibrated framework that improves visual routing and aligns reasoning with perception. Our results highlight the importance of explicitly evaluating faithfulness beyond response correctness. Our benchmark and codes are available at https://github.com/Johanson-colab/SPD-Faith-Bench.",
      "tldr_zh": "该研究探讨了多模态大语言模型(MLLMs)中链式思维(Chain-of-Thought)推理的忠实性(faithfulness)问题，指出目前对推理层面的不忠实现象研究尚浅。为此，作者提出了SPD-Faith Bench，这是一个基于细粒度图像差异推理的诊断基准，通过显式的视觉比较将忠实性与语言先验隔离。评估结果揭示了模型中普遍存在的感知盲点(perceptual blindness)和感知-推理脱节(perception-reasoning dissociation)两种系统性失效模式。通过进一步分析，研究者将这些失效归因于视觉注意力的衰减以及残差流中的表示偏移。基于分析结果，研究提出了一种名为SAGE的无需训练的视觉证据校准框架，有效改进了视觉路由并实现推理与感知的对齐。该工作强调了在响应正确性之外显式评估忠实性的必要性，为提升多模态模型的可靠性提供了重要工具。",
      "categories": [
        "cs.CV",
        "cs.AI",
        "cs.CL"
      ],
      "primary_category": "cs.CV",
      "comment": "53 pages, 42 figures, 14 tables",
      "pdf_url": "https://arxiv.org/pdf/2602.07833v1",
      "published_date": "2026-02-08 05:47:53 UTC",
      "updated_date": "2026-02-08 05:47:53 UTC",
      "processing_status": "completed",
      "attempts": 1,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "llm_backup_calls": 0,
      "last_update": "2026-02-16T05:23:06.004754+00:00"
    },
    {
      "arxiv_id": "2602.07832v1",
      "title": "rePIRL: Learn PRM with Inverse RL for LLM Reasoning",
      "title_zh": "rePIRL：基于逆强化学习的大语言模型推理过程奖励模型学习",
      "authors": [
        "Xian Wu",
        "Kaijie Zhu",
        "Ying Zhang",
        "Lun Wang",
        "Wenbo Guo"
      ],
      "abstract": "Process rewards have been widely used in deep reinforcement learning to improve training efficiency, reduce variance, and prevent reward hacking. In LLM reasoning, existing works also explore various solutions for learning effective process reward models (PRM) with or without the help of an expert policy. However, existing methods either rely on strong assumptions about the expert policies (e.g., requiring their reward functions) or suffer intrinsic limitations (e.g., entropy collapse), resulting in weak PRMs or limited generalizability. In this paper, we introduce rePIRL, an inverse RL-inspired framework that learns effective PRMs with minimal assumptions about expert policies. Specifically, we design a dual learning process that updates the policy and the PRM interchangeably. Our learning algorithm has customized techniques to address the challenges of scaling traditional inverse RL to LLMs. We theoretically show that our proposed learning framework can unify both online and offline PRM learning methods, justifying that rePIRL can learn PRMs with minimal assumptions. Empirical evaluations on standardized math and coding reasoning datasets demonstrate the effectiveness of rePIRL over existing methods. We further show the application of our trained PRM in test-time training, test-time scaling, and providing an early signal for training hard problems. Finally, we validate our training recipe and key design choices via a detailed ablation study.",
      "tldr_zh": "该研究提出了rePIRL，一个受逆强化学习(Inverse RL)启发的新框架，旨在解决大语言模型(LLM)推理中过程奖励模型(PRM)学习受限的问题。rePIRL通过一个交替更新策略和PRM的双向学习过程，在对专家策略仅需最小假设的前提下实现高效学习。为了应对传统逆强化学习在大规模模型上的扩展挑战，研究团队设计了专门的定制化技术。理论分析表明，该框架能有效统一在线和离线的PRM学习方法。在标准数学和代码推理数据集上的实验证明，rePIRL的性能显著优于现有方法。此外，该研究所训练的PRM在推理时训练(test-time training)、推理时扩展(test-time scaling)以及为处理困难问题提供早期信号方面均表现出卓越的应用潜力。",
      "categories": [
        "cs.LG",
        "cs.AI"
      ],
      "primary_category": "cs.LG",
      "comment": "",
      "pdf_url": "https://arxiv.org/pdf/2602.07832v1",
      "published_date": "2026-02-08 05:47:27 UTC",
      "updated_date": "2026-02-08 05:47:27 UTC",
      "processing_status": "completed",
      "attempts": 1,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "llm_backup_calls": 0,
      "last_update": "2026-02-16T05:23:22.505016+00:00"
    },
    {
      "arxiv_id": "2602.07830v1",
      "title": "Time Series Reasoning via Process-Verifiable Thinking Data Synthesis and Scheduling for Tailored LLM Reasoning",
      "title_zh": "基于过程可验证思考数据合成与调度的定制化大语言模型时间序列推理",
      "authors": [
        "Jiahui Zhou",
        "Dan Li",
        "Boxin Li",
        "Xiao Zhang",
        "Erli Meng",
        "Lin Li",
        "Zhuomin Chen",
        "Jian Lou",
        "See-Kiong Ng"
      ],
      "abstract": "Time series is a pervasive data type across various application domains, rendering the reasonable solving of diverse time series tasks a long-standing goal. Recent advances in large language models (LLMs), especially their reasoning abilities unlocked through reinforcement learning (RL), have opened new opportunities for tackling tasks with long Chain-of-Thought (CoT) reasoning. However, leveraging LLM reasoning for time series remains in its infancy, hindered by the absence of carefully curated time series CoT data for training, limited data efficiency caused by underexplored data scheduling, and the lack of RL algorithms tailored for exploiting such time series CoT data. In this paper, we introduce VeriTime, a framework that tailors LLMs for time series reasoning through data synthesis, data scheduling, and RL training. First, we propose a data synthesis pipeline that constructs a TS-text multimodal dataset with process-verifiable annotations. Second, we design a data scheduling mechanism that arranges training samples according to a principled hierarchy of difficulty and task taxonomy. Third, we develop a two-stage reinforcement finetuning featuring fine-grained, multi-objective rewards that leverage verifiable process-level CoT data. Extensive experiments show that VeriTime substantially boosts LLM performance across diverse time series reasoning tasks. Notably, it enables compact 3B, 4B models to achieve reasoning capabilities on par with or exceeding those of larger proprietary LLMs.",
      "tldr_zh": "该研究提出了 VeriTime 框架，旨在通过数据合成、数据调度和强化学习微调来优化大语言模型 (LLMs) 在时间序列 (Time Series) 领域的推理表现。该框架首先通过数据合成流水线构建了一个包含过程可验证 (process-verifiable) 标注的时间序列与文本多模态数据集。随后，研究设计了一种基于难度梯度和任务分类的数据调度机制，以提升模型训练的效率与针对性。在训练层面，VeriTime 采用了两阶段强化学习微调，利用过程级链式思维 (Chain-of-Thought) 数据构建细粒度的多目标奖励。实验证明，VeriTime 显著增强了 LLMs 在多样化时间序列推理任务中的能力。特别地，该框架能使 3B 和 4B 规模的轻量级模型达到甚至超过大型闭源商业模型的推理水平。",
      "categories": [
        "cs.AI"
      ],
      "primary_category": "cs.AI",
      "comment": "",
      "pdf_url": "https://arxiv.org/pdf/2602.07830v1",
      "published_date": "2026-02-08 05:42:35 UTC",
      "updated_date": "2026-02-08 05:42:35 UTC",
      "processing_status": "completed",
      "attempts": 1,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "llm_backup_calls": 0,
      "last_update": "2026-02-16T05:23:23.501718+00:00"
    },
    {
      "arxiv_id": "2602.07828v1",
      "title": "Efficient Representations are Controllable Representations",
      "title_zh": "高效表示即可控表示",
      "authors": [
        "Charles Ye",
        "Jasmine Cui"
      ],
      "abstract": "What is the most brute-force way to install interpretable, controllable features into a model's activations? Controlling how LLMs internally represent concepts typically requires sophisticated methods to first identify, then intervene on the model's existing feature geometry. We bypass all of this.\n  We finetune an LLM with a simple auxiliary loss, training 16 of its 3072 residual stream dimensions to be inert interpretability flags that simply indicate what concepts are required for generation. The model reorganizes around them anyway, learning to rely on these flags during actual generation tasks. As a result, these inert flags become genuine internal features: interpretable control switches that allow us to steer generation at inference time. Why does this work? When a feature is reliably supplied at a fixed location, gradient descent gradually eliminates redundant encodings elsewhere, and the model erodes its own alternative representations. A model's efficiency pressure is a lever - exploitable to induce interpretable, controllable representations.",
      "tldr_zh": "该研究探讨了如何通过一种直接的方式在大型语言模型(LLM)中植入可解释且可控的特征，而无需复杂的特征几何识别与干预。作者通过辅助损失(auxiliary loss)对模型进行微调，将残差流(residual stream)中的特定维度训练为指示生成概念的标志位。实验证明，模型会自发地围绕这些维度进行重组并产生依赖，使这些标志位在推理阶段转化为可用于引导生成的解释性控制开关。这种现象的本质在于，当特征在固定位置被可靠提供时，梯度下降(gradient descent)会逐步消除其他位置的冗余编码并侵蚀替代表示。该研究最终表明，模型追求效率的压力(efficiency pressure)可以作为一种杠杆，被用来诱导并生成更具可解释性与可控性的表征。",
      "categories": [
        "cs.LG",
        "cs.AI"
      ],
      "primary_category": "cs.LG",
      "comment": "",
      "pdf_url": "https://arxiv.org/pdf/2602.07828v1",
      "published_date": "2026-02-08 05:32:02 UTC",
      "updated_date": "2026-02-08 05:32:02 UTC",
      "processing_status": "completed",
      "attempts": 1,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "llm_backup_calls": 0,
      "last_update": "2026-02-16T05:23:24.501569+00:00"
    },
    {
      "arxiv_id": "2602.07824v1",
      "title": "Data Darwinism Part I: Unlocking the Value of Scientific Data for Pre-training",
      "title_zh": "数据达尔文主义（第一部分）：解锁科学数据在预训练中的价值",
      "authors": [
        "Yiwei Qin",
        "Zhen Huang",
        "Tiantian Mi",
        "Weiye Si",
        "Chenyang Zhou",
        "Qipeng Guo",
        "Siyuan Feng",
        "Pengfei Liu"
      ],
      "abstract": "Data quality determines foundation model performance, yet systematic processing frameworks are lacking. We introduce Data Darwinism, a ten-level taxonomy (L0-L9) that conceptualizes data-model co-evolution: advanced models produce superior data for next-generation systems. We validate this on scientific literature by constructing Darwin-Science, a 900B-token corpus (L0-L5). We identify a learnability gap in raw scientific text, which we bridge via L4 (Generative Refinement) and L5 (Cognitive Completion) using frontier LLMs to explicate reasoning and terminology.\n  To ensure rigorous attribution, we pre-trained daVinci-origin-3B/7B models from scratch, excluding scientific content to create contamination-free baselines. After 600B tokens of continued pre-training, Darwin-Science outperforms baselines by +2.12 (3B) and +2.95 (7B) points across 20+ benchmarks, rising to +5.60 and +8.40 points on domain-aligned tasks. Systematic progression to L5 yields a +1.36 total gain, confirming that higher-level processing unlocks latent data value. We release the Darwin-Science corpus and daVinci-origin models to enable principled, co-evolutionary development.",
      "tldr_zh": "该研究提出了Data Darwinism，这是一个包含十个等级（L0-L9）的分类体系，旨在通过数据与模型的协同演化解锁科学数据的潜在价值。研究团队构建了规模达900B token的Darwin-Science语料库，并针对原始科学文本中存在的Learnability Gap，利用前沿LLMs执行了L4（Generative Refinement）和L5（Cognitive Completion）层级的加工。通过从零预训练daVinci-origin-3B/7B模型进行验证，结果表明Darwin-Science在20多个基准测试中显著优于基线模型，在领域相关任务中表现尤为突出。实验进一步证实，向L5级别的系统演进带来了额外的性能增益，证明了高级别数据处理在提升预训练质量方面的关键作用。该研究目前已开源Darwin-Science语料库与daVinci-origin模型，旨在推动基于原则的协同演化模型开发。",
      "categories": [
        "cs.AI",
        "cs.CL"
      ],
      "primary_category": "cs.AI",
      "comment": "",
      "pdf_url": "https://arxiv.org/pdf/2602.07824v1",
      "published_date": "2026-02-08 05:06:34 UTC",
      "updated_date": "2026-02-08 05:06:34 UTC",
      "processing_status": "completed",
      "attempts": 1,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "llm_backup_calls": 0,
      "last_update": "2026-02-16T05:23:28.609032+00:00"
    },
    {
      "arxiv_id": "2602.07814v1",
      "title": "How well are open sourced AI-generated image detection models out-of-the-box: A comprehensive benchmark study",
      "title_zh": "开源 AI 生成图像检测模型的开箱即用性能评估：一项全面的基准研究",
      "authors": [
        "Simiao Ren",
        "Yuchen Zhou",
        "Xingyu Shen",
        "Kidus Zewde",
        "Tommy Duong",
        "George Huang",
        "Hatsanai",
        "Tiangratanakul",
        "Tsang",
        "Ng",
        "En Wei",
        "Jiayu Xue"
      ],
      "abstract": "As AI-generated images proliferate across digital platforms, reliable detection methods have become critical for combating misinformation and maintaining content authenticity. While numerous deepfake detection methods have been proposed, existing benchmarks predominantly evaluate fine-tuned models, leaving a critical gap in understanding out-of-the-box performance -- the most common deployment scenario for practitioners. We present the first comprehensive zero-shot evaluation of 16 state-of-the-art detection methods, comprising 23 pretrained detector variants (due to multiple released versions of certain detectors), across 12 diverse datasets, comprising 2.6~million image samples spanning 291 unique generators including modern diffusion models. Our systematic analysis reveals striking findings: (1)~no universal winner exists, with detector rankings exhibiting substantial instability (Spearman~$ρ$: 0.01 -- 0.87 across dataset pairs); (2)~a 37~percentage-point performance gap separates the best detector (75.0\\% mean accuracy) from the worst (37.5\\%); (3)~training data alignment critically impacts generalization, causing up to 20--60\\% performance variance within architecturally identical detector families; (4)~modern commercial generators (Flux~Dev, Firefly~v4, Midjourney~v7) defeat most detectors, achieving only 18--30\\% average accuracy; and (5)~we identify three systematic failure patterns affecting cross-dataset generalization. Statistical analysis confirms significant performance differences between detectors (Friedman test: $χ^2$=121.01, $p<10^{-16}$, Kendall~$W$=0.524). Our findings challenge the ``one-size-fits-all'' detector paradigm and provide actionable deployment guidelines, demonstrating that practitioners must carefully select detectors based on their specific threat landscape rather than relying on published benchmark performance.",
      "tldr_zh": "该研究针对开源AI生成图像检测模型进行了首次全面的zero-shot评估，旨在填补模型在out-of-the-box性能方面的研究空白。研究团队对16种state-of-the-art检测方法在12个多样化数据集上进行了基准测试，涵盖了来自291个生成器的260万张图像样本。实验结果表明目前并不存在通用的最佳检测器，不同数据集下的排名表现出显著的不稳定性，且表现最优与最差模型之间的平均准确率差异高达37%。研究发现training data alignment极大地影响了模型的泛化表现，且Flux Dev、Firefly v4和Midjourney v7等现代商业生成器能够使大多数检测器的平均准确率降至18-30%。通过统计分析，该研究识别出了三种影响跨数据集泛化的系统性失效模式，并强调从业者需根据具体的threat landscape定制化选择检测模型。该成果挑战了“一劳永逸”的检测范式，为对抗误导性信息和维护内容真实性提供了切实的部署指南。",
      "categories": [
        "cs.CV",
        "cs.AI"
      ],
      "primary_category": "cs.CV",
      "comment": "",
      "pdf_url": "https://arxiv.org/pdf/2602.07814v1",
      "published_date": "2026-02-08 04:36:13 UTC",
      "updated_date": "2026-02-08 04:36:13 UTC",
      "processing_status": "completed",
      "attempts": 1,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "llm_backup_calls": 0,
      "last_update": "2026-02-16T05:23:33.600750+00:00"
    },
    {
      "arxiv_id": "2602.07804v1",
      "title": "Pruning as a Cooperative Game: Surrogate-Assisted Layer Contribution Estimation for Large Language Models",
      "title_zh": "将剪枝视为合作博弈：大语言模型的代理辅助层贡献评估",
      "authors": [
        "Xuan Ding",
        "Pengyu Tong",
        "Ranjie Duan",
        "Yunjian Zhang",
        "Rui Sun",
        "Yao Zhu"
      ],
      "abstract": "While large language models (LLMs) demonstrate impressive performance across various tasks, their deployment in real-world scenarios is still constrained by high computational demands. Layer-wise pruning, a commonly employed strategy to mitigate inference costs, can partially address this challenge. However, existing approaches generally depend on static heuristic rules and fail to account for the interdependencies among layers, thereby limiting the effectiveness of the pruning process. To this end, this paper proposes a game-theoretic framework that formulates layer pruning as a cooperative game in which each layer acts as a player and model performance serves as the utility. As computing exact Shapley values is computationally infeasible for large language models (LLMs), we propose using a lightweight surrogate network to estimate layer-wise marginal contributions. This network can predict LLM performance for arbitrary layer combinations at a low computational cost. Additionally, we employ stratified Monte Carlo mask sampling to further reduce the cost of Sharpley value estimation. This approach captures inter-layer dependencies and dynamically identifies critical layers for pruning. Extensive experiments demonstrate the consistent superiority of our method in terms of perplexity and zero-shot accuracy, achieving more efficient and effective layer-wise pruning for large language models.",
      "tldr_zh": "该研究针对大语言模型 (LLMs) 在实际部署中面临的高计算需求问题，提出了一种将层剪枝 (Layer-wise pruning) 建模为合作博弈 (Cooperative game) 的博弈论框架。现有方法通常依赖静态启发式规则，难以捕捉层间复杂的相互依赖关系，而该框架将每一层视为博弈参与者，以模型性能作为效用进行评估。为了解决计算精确 Shapley values 的高昂成本，研究者引入了轻量级代理网络 (Surrogate network) 来估算层级的边际贡献，并结合分层蒙特卡洛掩码采样 (Stratified Monte Carlo mask sampling) 技术。这种方法能够动态识别对模型性能至关重要的层，并根据层间依赖性优化剪枝策略。实验结果表明，该方法在困惑度 (Perplexity) 和零样本准确率 (Zero-shot accuracy) 方面均表现出显著优势，实现了比传统层剪枝更高效且更精准的模型压缩。",
      "categories": [
        "cs.CL",
        "cs.AI"
      ],
      "primary_category": "cs.CL",
      "comment": "Accepted by ICLR 2026",
      "pdf_url": "https://arxiv.org/pdf/2602.07804v1",
      "published_date": "2026-02-08 03:51:36 UTC",
      "updated_date": "2026-02-08 03:51:36 UTC",
      "processing_status": "completed",
      "attempts": 1,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "llm_backup_calls": 0,
      "last_update": "2026-02-16T05:23:42.510436+00:00"
    },
    {
      "arxiv_id": "2602.07803v1",
      "title": "SoulX-Singer: Towards High-Quality Zero-Shot Singing Voice Synthesis",
      "title_zh": "SoulX-Singer：迈向高质量零样本歌声合成",
      "authors": [
        "Jiale Qian",
        "Hao Meng",
        "Tian Zheng",
        "Pengcheng Zhu",
        "Haopeng Lin",
        "Yuhang Dai",
        "Hanke Xie",
        "Wenxiao Cao",
        "Ruixuan Shang",
        "Jun Wu",
        "Hongmei Liu",
        "Hanlin Wen",
        "Jian Zhao",
        "Zhonglin Jiang",
        "Yong Chen",
        "Shunshun Yin",
        "Ming Tao",
        "Jianguo Wei",
        "Lei Xie",
        "Xinsheng Wang"
      ],
      "abstract": "While recent years have witnessed rapid progress in speech synthesis, open-source singing voice synthesis (SVS) systems still face significant barriers to industrial deployment, particularly in terms of robustness and zero-shot generalization. In this report, we introduce SoulX-Singer, a high-quality open-source SVS system designed with practical deployment considerations in mind. SoulX-Singer supports controllable singing generation conditioned on either symbolic musical scores (MIDI) or melodic representations, enabling flexible and expressive control in real-world production workflows. Trained on more than 42,000 hours of vocal data, the system supports Mandarin Chinese, English, and Cantonese and consistently achieves state-of-the-art synthesis quality across languages under diverse musical conditions. Furthermore, to enable reliable evaluation of zero-shot SVS performance in practical scenarios, we construct SoulX-Singer-Eval, a dedicated benchmark with strict training-test disentanglement, facilitating systematic assessment in zero-shot settings.",
      "tldr_zh": "该研究针对开源歌声合成 (Singing Voice Synthesis, SVS) 系统在鲁棒性和 Zero-Shot 泛化能力方面的局限，提出了高性能开源系统 SoulX-Singer。该系统支持基于符号音乐评分 (MIDI) 或旋律表示的可控歌声生成，能够满足实际生产工作流中灵活且具有表现力的控制需求。SoulX-Singer 基于超过 42,000 小时的语音数据进行训练，涵盖了普通话、英语和粤语，并在多样化的音乐条件下实现了各语种的 State-of-the-art 合成质量。为了在实际场景中可靠地评估 Zero-Shot SVS 性能，研究团队还构建了 SoulX-Singer-Eval 评测基准。该基准通过严格的训练-测试解耦 (training-test disentanglement) 设计，为 Zero-Shot 设置下的系统评估提供了系统化的手段。",
      "categories": [
        "eess.AS",
        "cs.AI",
        "cs.SD"
      ],
      "primary_category": "eess.AS",
      "comment": "Technical Report",
      "pdf_url": "https://arxiv.org/pdf/2602.07803v1",
      "published_date": "2026-02-08 03:51:23 UTC",
      "updated_date": "2026-02-08 03:51:23 UTC",
      "processing_status": "completed",
      "attempts": 1,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "llm_backup_calls": 0,
      "last_update": "2026-02-16T05:23:41.606624+00:00"
    },
    {
      "arxiv_id": "2602.07801v1",
      "title": "VideoTemp-o3: Harmonizing Temporal Grounding and Video Understanding in Agentic Thinking-with-Videos",
      "title_zh": "VideoTemp-o3：智能体化视频思维中时序定位与视频理解的协同",
      "authors": [
        "Wenqi Liu",
        "Yunxiao Wang",
        "Shijie Ma",
        "Meng Liu",
        "Qile Su",
        "Tianke Zhang",
        "Haonan Fan",
        "Changyi Liu",
        "Kaiyu Jiang",
        "Jiankang Chen",
        "Kaiyu Tang",
        "Bin Wen",
        "Fan Yang",
        "Tingting Gao",
        "Han Li",
        "Yinwei Wei",
        "Xuemeng Song"
      ],
      "abstract": "In long-video understanding, conventional uniform frame sampling often fails to capture key visual evidence, leading to degraded performance and increased hallucinations. To address this, recent agentic thinking-with-videos paradigms have emerged, adopting a localize-clip-answer pipeline in which the model actively identifies relevant video segments, performs dense sampling within those clips, and then produces answers. However, existing methods remain inefficient, suffer from weak localization, and adhere to rigid workflows. To solve these issues, we propose VideoTemp-o3, a unified agentic thinking-with-videos framework that jointly models video grounding and question answering. VideoTemp-o3 exhibits strong localization capability, supports on-demand clipping, and can refine inaccurate localizations. Specifically, in the supervised fine-tuning stage, we design a unified masking mechanism that encourages exploration while preventing noise. For reinforcement learning, we introduce dedicated rewards to mitigate reward hacking. Besides, from the data perspective, we develop an effective pipeline to construct high-quality long video grounded QA data, along with a corresponding benchmark for systematic evaluation across various video durations. Experimental results demonstrate that our method achieves remarkable performance on both long video understanding and grounding.",
      "tldr_zh": "该研究针对长视频理解中传统均匀采样易丢失关键信息并产生幻觉的问题，提出了 VideoTemp-o3，一个将视频定位（grounding）与问答（question answering）联合建模的统一 agentic thinking-with-videos 框架。该框架具备强大的定位能力，支持按需裁剪（on-demand clipping）并能修正定位偏差，克服了现有方法工作流僵化及效率不足的缺陷。在监督微调阶段，VideoTemp-o3 采用统一掩码机制（unified masking mechanism）以平衡探索与降噪；在强化学习阶段，通过引入专用奖励机制有效缓解了奖励作弊（reward hacking）问题。此外，研究者还开发了高质量长视频定位问答数据构建流水线及相应的评估基准。实验证明，VideoTemp-o3 在长视频理解与定位任务上均展现出卓越性能，为复杂视频场景下的智能推理提供了高效解决方案。",
      "categories": [
        "cs.CV",
        "cs.AI"
      ],
      "primary_category": "cs.CV",
      "comment": "",
      "pdf_url": "https://arxiv.org/pdf/2602.07801v1",
      "published_date": "2026-02-08 03:45:50 UTC",
      "updated_date": "2026-02-08 03:45:50 UTC",
      "processing_status": "completed",
      "attempts": 1,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "llm_backup_calls": 0,
      "last_update": "2026-02-16T05:23:45.708391+00:00"
    },
    {
      "arxiv_id": "2602.07799v1",
      "title": "Fairness Aware Reward Optimization",
      "title_zh": "公平感知的奖励优化",
      "authors": [
        "Ching Lam Choi",
        "Vighnesh Subramaniam",
        "Phillip Isola",
        "Antonio Torralba",
        "Stefanie Jegelka"
      ],
      "abstract": "Demographic skews in human preference data propagate systematic unfairness through reward models into aligned LLMs. We introduce Fairness Aware Reward Optimization (Faro), an in-processing framework that trains reward models under demographic parity, equalized odds, or counterfactual fairness constraints. We provide the first theoretical analysis of reward-level fairness in LLM alignment, establishing: (i) provable fairness certificates for Faro-trained rewards with controllable slack; a (ii) formal characterization of the accuracy-fairness trade-off induced by KL-regularized fine-tuning, proving fairness transfers from reward to policy; and the (iii) existence of a non-empty Pareto frontier. Unlike pre- and post-processing methods, Faro ensures reward models are simultaneously ordinal (ranking correctly), cardinal (calibrated), and fair. Across multiple LLMs and benchmarks, Faro significantly reduces bias and harmful generations while maintaining or improving model quality.",
      "tldr_zh": "该研究提出了Fairness Aware Reward Optimization (Faro)，这是一个针对大语言模型(LLMs)对齐过程中的人口统计偏见而设计的在线处理(in-processing)框架。Faro通过在奖励模型训练中引入人口统计平等(demographic parity)、机会均等(equalized odds)或反事实公平(counterfactual fairness)约束，从源头解决偏好数据带来的系统性不公。研究人员首次对LLM对齐中的奖励层面公平性进行了理论分析，证明了该方法能够提供可控的公平性保证，并揭示了公平性可以从奖励模型有效传递至最终策略模型。实验结果表明，与预处理或后处理方法不同，Faro在确保奖励模型具备正确排序和校准能力的同时，显著减少了各基准测试中的偏见和有害生成，且能保持甚至提升模型的整体质量。",
      "categories": [
        "cs.LG",
        "cs.AI"
      ],
      "primary_category": "cs.LG",
      "comment": "",
      "pdf_url": "https://arxiv.org/pdf/2602.07799v1",
      "published_date": "2026-02-08 03:35:49 UTC",
      "updated_date": "2026-02-08 03:35:49 UTC",
      "processing_status": "completed",
      "attempts": 1,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "llm_backup_calls": 0,
      "last_update": "2026-02-16T05:23:42.898769+00:00"
    },
    {
      "arxiv_id": "2602.07798v1",
      "title": "CausalTAD: Injecting Causal Knowledge into Large Language Models for Tabular Anomaly Detection",
      "title_zh": "CausalTAD：将因果知识注入大语言模型以进行表格异常检测",
      "authors": [
        "Ruiqi Wang",
        "Ruikang Liu",
        "Runyu Chen",
        "Haoxiang Suo",
        "Zhiyi Peng",
        "Zhuo Tang",
        "Changjian Chen"
      ],
      "abstract": "Detecting anomalies in tabular data is critical for many real-world applications, such as credit card fraud detection. With the rapid advancements in large language models (LLMs), state-of-the-art performance in tabular anomaly detection has been achieved by converting tabular data into text and fine-tuning LLMs. However, these methods randomly order columns during conversion, without considering the causal relationships between them, which is crucial for accurately detecting anomalies. In this paper, we present CausalTaD, a method that injects causal knowledge into LLMs for tabular anomaly detection. We first identify the causal relationships between columns and reorder them to align with these causal relationships. This reordering can be modeled as a linear ordering problem. Since each column contributes differently to the causal relationships, we further propose a reweighting strategy to assign different weights to different columns to enhance this effect. Experiments across more than 30 datasets demonstrate that our method consistently outperforms the current state-of-the-art methods. The code for CausalTAD is available at https://github.com/350234/CausalTAD.",
      "tldr_zh": "该研究提出了CausalTAD方法，旨在通过将因果知识(Causal Knowledge)注入大语言模型(LLMs)来提升表格异常检测(Tabular Anomaly Detection)的性能。针对现有方法在数据转换过程中随机排列列顺序而忽略列间因果关系的缺陷，CausalTAD首先识别列之间的因果关系，并将其转化为线性排序问题以重新调整列顺序。此外，研究还引入了一种重加权策略(Reweighting Strategy)，根据每列对因果关系的贡献程度分配不同权重，从而进一步强化特征表达。在超过30个数据集上的实验结果表明，CausalTAD持续优于现有的最先进方法，为利用大语言模型处理金融欺诈检测等现实世界的异常检测任务提供了更具因果解释性的解决方案。",
      "categories": [
        "cs.LG",
        "cs.AI"
      ],
      "primary_category": "cs.LG",
      "comment": "",
      "pdf_url": "https://arxiv.org/pdf/2602.07798v1",
      "published_date": "2026-02-08 03:28:19 UTC",
      "updated_date": "2026-02-08 03:28:19 UTC",
      "processing_status": "completed",
      "attempts": 1,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "llm_backup_calls": 0,
      "last_update": "2026-02-16T05:23:46.713383+00:00"
    },
    {
      "arxiv_id": "2602.07794v2",
      "title": "Emergent Structured Representations Support Flexible In-Context Inference in Large Language Models",
      "title_zh": "涌现的结构化表示支撑大语言模型中的灵活上下文推理",
      "authors": [
        "Ningyu Xu",
        "Qi Zhang",
        "Xipeng Qiu",
        "Xuanjing Huang"
      ],
      "abstract": "Large language models (LLMs) exhibit emergent behaviors suggestive of human-like reasoning. While recent work has identified structured, human-like conceptual representations within these models, it remains unclear whether they functionally rely on such representations for reasoning. Here we investigate the internal processing of LLMs during in-context concept inference. Our results reveal a conceptual subspace emerging in middle to late layers, whose representational structure persists across contexts. Using causal mediation analyses, we demonstrate that this subspace is not merely an epiphenomenon but is functionally central to model predictions, establishing its causal role in inference. We further identify a layer-wise progression where attention heads in early-to-middle layers integrate contextual cues to construct and refine the subspace, which is subsequently leveraged by later layers to generate predictions. Together, these findings provide evidence that LLMs dynamically construct and use structured, latent representations in context for inference, offering insights into the computational processes underlying flexible adaptation.",
      "tldr_zh": "该研究探讨了大语言模型(LLMs)在情境概念推理过程中是否依赖其内部形成的结构化概念表示。分析表明，模型的中后期层中出现了一个具有跨语境结构一致性的概念子空间(conceptual subspace)。通过因果中介分析(causal mediation analyses)，研究者证实该子空间并非偶然产生的副现象，而是模型进行推理预测时在功能上处于核心地位的因果因素。研究进一步揭示了层级化的演进过程：前中期层的注意力头负责整合上下文线索以构建并优化该子空间，随后由后期层调用该空间生成预测结果。这些发现为 LLMs 在推理中动态构建和利用结构化潜表示(latent representations)提供了证据，深入揭示了其实现灵活适应能力的底层计算机制。",
      "categories": [
        "cs.CL",
        "cs.AI"
      ],
      "primary_category": "cs.CL",
      "comment": "27 pages, 16 figures",
      "pdf_url": "https://arxiv.org/pdf/2602.07794v2",
      "published_date": "2026-02-08 03:14:39 UTC",
      "updated_date": "2026-02-10 03:44:17 UTC",
      "processing_status": "completed",
      "attempts": 1,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "llm_backup_calls": 0,
      "last_update": "2026-02-16T05:24:00.804326+00:00"
    },
    {
      "arxiv_id": "2602.07787v1",
      "title": "Do Multi-Agents Dream of Electric Screens? Achieving Perfect Accuracy on AndroidWorld Through Task Decomposition",
      "title_zh": "多智能体梦见电子屏幕吗？通过任务分解在 AndroidWorld 上实现完美准确率",
      "authors": [
        "Pierre-Louis Favreau",
        "Jean-Pierre Lo",
        "Clement Guiguet",
        "Charles Simon-Meunier",
        "Nicolas Dehandschoewercker",
        "Allen G. Roush",
        "Judah Goldfeder",
        "Ravid Shwartz-Ziv"
      ],
      "abstract": "We present Minitap, a multi-agent system that achieves 100% success on the AndroidWorld benchmark, the first to fully solve all 116 tasks and surpassing human performance (80%). We first analyze why single-agent architectures fail: context pollution from mixed reasoning traces, silent text input failures undetected by the agent, and repetitive action loops without escape. Minitap addresses each failure through targeted mechanisms: cognitive separation across six specialized agents, deterministic post-validation of text input against device state, and meta-cognitive reasoning that detects cycles and triggers strategy changes. Ablations show multi-agent decomposition contributes +21 points over single-agent baselines; verified execution adds +7 points; meta-cognition adds +9 points. We release Minitap as open-source software. https://github.com/minitap-ai/mobile-use",
      "tldr_zh": "该研究提出了Minitap，这是一种在AndroidWorld基准测试中实现100%成功率的多智能体系统，是首个完全解决全部116项任务并超越人类水平（80%）的方案。研究首先指出单智能体架构在处理复杂任务时存在上下文污染(context pollution)、静默文本输入失败以及重复动作循环等核心缺陷。Minitap通过六个专门智能体的认知分离(cognitive separation)、针对设备状态的文本输入确定性后置验证以及可检测循环并触发策略转变的元认知推理(meta-cognitive reasoning)解决了上述问题。消融实验证明，多智能体分解、验证执行和元认知机制分别使性能提升了21分、7分和9分。目前，Minitap已作为开源软件发布，为移动设备自动化任务处理提供了高效且可靠的新路径。",
      "categories": [
        "cs.AI"
      ],
      "primary_category": "cs.AI",
      "comment": "",
      "pdf_url": "https://arxiv.org/pdf/2602.07787v1",
      "published_date": "2026-02-08 03:02:13 UTC",
      "updated_date": "2026-02-08 03:02:13 UTC",
      "processing_status": "completed",
      "attempts": 1,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "llm_backup_calls": 0,
      "last_update": "2026-02-16T05:24:02.306508+00:00"
    },
    {
      "arxiv_id": "2602.07783v1",
      "title": "Still Manual? Automated Linter Configuration via DSL-Based LLM Compilation of Coding Standards",
      "title_zh": "告别手动？基于 DSL 的大语言模型编码规范编译实现自动化 Linter 配置",
      "authors": [
        "Zejun Zhang",
        "Yixin Gan",
        "Zhenchang Xing",
        "Tian Zhang",
        "Yi Li",
        "Xiwei Xu",
        "Qinghua Lu",
        "Liming Zhu"
      ],
      "abstract": "Coding standards are essential for maintaining consistent and high-quality code across teams and projects. Linters help developers enforce these standards by detecting code violations. However, manual linter configuration is complex and expertise-intensive, and the diversity and evolution of programming languages, coding standards, and linters lead to repetitive and maintenance-intensive configuration work. To reduce manual effort, we propose LintCFG, a domain-specific language (DSL)-driven, LLM-based compilation approach to automate linter configuration generation for coding standards, independent of programming languages, coding standards, and linters. Inspired by compiler design, we first design a DSL to express coding rules in a tool-agnostic, structured, readable, and precise manner. Then, we build linter configurations into DSL configuration instructions. For a given natural language coding standard, the compilation process parses it into DSL coding standards, matches them with the DSL configuration instructions to set configuration names, option names and values, verifies consistency between the standards and configurations, and finally generates linter-specific configurations. Experiments with Checkstyle for Java coding standard show that our approach achieves over 90% precision and recall in DSL representation, with accuracy, precision, recall, and F1-scores close to 70% (with some exceeding 70%) in fine-grained linter configuration generation. Notably, our approach outperforms baselines by over 100% in precision. A user study further shows that our approach improves developers' efficiency in configuring linters for coding standards. Finally, we demonstrate the generality of the approach by generating ESLint configurations for JavaScript coding standards, showcasing its broad applicability across other programming languages, coding standards, and linters.",
      "tldr_zh": "该研究提出了 LintCFG，一种驱动领域特定语言 (DSL) 且基于大语言模型 (LLM) 的编译方法，旨在自动化根据编程规范生成 Linter 配置。研究者首先设计了一套与工具无关、结构化的 DSL 来精确表达编码规则，并将 Linter 的配置规则映射为 DSL 配置指令，通过类似编译的过程将自然语言描述的编程规范解析为特定 Linter 的配置文件。针对 Java 编程规范和 Checkstyle 的实验表明，该方法在 DSL 表征方面达到了超过 90% 的精确率和召回率，在细粒度配置生成上的准确率和 F1 分数接近或超过 70%，且在精确率上比基线模型提升了 100% 以上。用户研究进一步证实 LintCFG 显著提升了开发者配置 Linter 的效率，而针对 JavaScript 和 ESLint 的扩展实验则证明了该方法在不同编程语言、编程规范和 Linter 工具之间的广泛适用性。",
      "categories": [
        "cs.SE",
        "cs.AI"
      ],
      "primary_category": "cs.SE",
      "comment": "Accepted By FSE2026",
      "pdf_url": "https://arxiv.org/pdf/2602.07783v1",
      "published_date": "2026-02-08 02:57:47 UTC",
      "updated_date": "2026-02-08 02:57:47 UTC",
      "processing_status": "completed",
      "attempts": 1,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "llm_backup_calls": 0,
      "last_update": "2026-02-16T05:24:12.703787+00:00"
    },
    {
      "arxiv_id": "2602.07774v3",
      "title": "Generative Reasoning Re-ranker",
      "title_zh": "生成式推理重排序器",
      "authors": [
        "Mingfu Liang",
        "Yufei Li",
        "Jay Xu",
        "Kavosh Asadi",
        "Xi Liu",
        "Shuo Gu",
        "Kaushik Rangadurai",
        "Frank Shyu",
        "Shuaiwen Wang",
        "Song Yang",
        "Zhijing Li",
        "Jiang Liu",
        "Mengying Sun",
        "Fei Tian",
        "Xiaohan Wei",
        "Chonglin Sun",
        "Jacob Tao",
        "Shike Mei",
        "Hamed Firooz",
        "Wenlin Chen",
        "Luke Simon"
      ],
      "abstract": "Recent studies increasingly explore Large Language Models (LLMs) as a new paradigm for recommendation systems due to their scalability and world knowledge. However, existing work has three key limitations: (1) most efforts focus on retrieval and ranking, while the reranking phase, critical for refining final recommendations, is largely overlooked; (2) LLMs are typically used in zero-shot or supervised fine-tuning settings, leaving their reasoning abilities, especially those enhanced through reinforcement learning (RL) and high-quality reasoning data, underexploited; (3) items are commonly represented by non-semantic IDs, creating major scalability challenges in industrial systems with billions of identifiers. To address these gaps, we propose the Generative Reasoning Reranker (GR2), an end-to-end framework with a three-stage training pipeline tailored for reranking. First, a pretrained LLM is mid-trained on semantic IDs encoded from non-semantic IDs via a tokenizer achieving $\\ge$99% uniqueness. Next, a stronger larger-scale LLM generates high-quality reasoning traces through carefully designed prompting and rejection sampling, which are used for supervised fine-tuning to impart foundational reasoning skills. Finally, we apply Decoupled Clip and Dynamic sAmpling Policy Optimization (DAPO), enabling scalable RL supervision with verifiable rewards designed specifically for reranking. Experiments on two real-world datasets demonstrate GR2's effectiveness: it surpasses the state-of-the-art OneRec-Think by 2.4% in Recall@5 and 1.3% in NDCG@5. Ablations confirm that advanced reasoning traces yield substantial gains across metrics. We further find that RL reward design is crucial in reranking: LLMs tend to exploit reward hacking by preserving item order, motivating conditional verifiable rewards to mitigate this behavior and optimize reranking performance.",
      "tldr_zh": "该研究提出了 Generative Reasoning Reranker (GR2)，这是一个专门针对推荐系统中重排序 (reranking) 阶段设计的端到端框架，旨在解决现有大语言模型 (LLMs) 在重排序任务中推理能力开发不足及 ID 标识符扩展性受限的问题。GR2 采用三阶段训练流程，首先通过分词器将非语义 ID 转换为具备高唯一性的语义 ID 并进行中期预训练。随后，利用大规模 LLM 生成高质量的推理路径 (reasoning traces)，并通过有监督微调 (SFT) 使模型具备基础的推荐推理能力。最后，该框架引入了 Decoupled Clip 和 Dynamic sAmpling Policy Optimization (DAPO) 算法，通过专门设计的高质量可验证奖励 (verifiable rewards) 进行可扩展的强化学习 (RL) 监督。实验结果表明，GR2 在 Recall@5 和 NDCG@5 等指标上显著优于现有的 OneRec-Think 等先进模型。研究进一步发现，合理的强化学习奖励设计对于缓解模型的奖励黑客 (reward hacking) 行为至关重要，能有效防止模型通过单纯保留物品顺序来获益，从而显著优化重排序性能。",
      "categories": [
        "cs.IR",
        "cs.AI"
      ],
      "primary_category": "cs.IR",
      "comment": "31 pages",
      "pdf_url": "https://arxiv.org/pdf/2602.07774v3",
      "published_date": "2026-02-08 02:12:24 UTC",
      "updated_date": "2026-02-12 09:37:17 UTC",
      "processing_status": "completed",
      "attempts": 1,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "llm_backup_calls": 0,
      "last_update": "2026-02-16T05:24:11.605952+00:00"
    },
    {
      "arxiv_id": "2602.07768v1",
      "title": "PAND: Prompt-Aware Neighborhood Distillation for Lightweight Fine-Grained Visual Classification",
      "title_zh": "PAND：面向轻量级细粒度视觉分类的提示感知邻域蒸馏",
      "authors": [
        "Qiuming Luo",
        "Yuebing Li",
        "Feng Li",
        "Chang Kong"
      ],
      "abstract": "Distilling knowledge from large Vision-Language Models (VLMs) into lightweight networks is crucial yet challenging in Fine-Grained Visual Classification (FGVC), due to the reliance on fixed prompts and global alignment. To address this, we propose PAND (Prompt-Aware Neighborhood Distillation), a two-stage framework that decouples semantic calibration from structural transfer. First, we incorporate Prompt-Aware Semantic Calibration to generate adaptive semantic anchors. Second, we introduce a neighborhood-aware structural distillation strategy to constrain the student's local decision structure. PAND consistently outperforms state-of-the-art methods on four FGVC benchmarks. Notably, our ResNet-18 student achieves 76.09% accuracy on CUB-200, surpassing the strong baseline VL2Lite by 3.4%. Code is available at https://github.com/LLLVTA/PAND.",
      "tldr_zh": "该研究提出了PAND（Prompt-Aware Neighborhood Distillation），这是一种旨在将大型视觉语言模型（VLMs）知识迁移至轻量级网络的两阶段蒸馏框架，以解决细粒度视觉分类（FGVC）中固定提示和全局对齐带来的局限性。该框架首先通过Prompt-Aware Semantic Calibration生成自适应语义锚点以进行语义校准，随后引入邻域感知结构蒸馏策略（neighborhood-aware structural distillation）来约束学生网络的局部决策结构。实验结果显示，PAND在四个FGVC基准数据集上均优于现有最先进方法。特别是在CUB-200数据集上，以ResNet-18作为学生网络时达到了76.09%的准确率，比强基线模型VL2Lite提升了3.4%，证明了其在提升轻量级模型细粒度识别能力方面的有效性。",
      "categories": [
        "cs.CV",
        "cs.AI",
        "cs.LG",
        "cs.MM"
      ],
      "primary_category": "cs.CV",
      "comment": "6pages, 3 figures, conference",
      "pdf_url": "https://arxiv.org/pdf/2602.07768v1",
      "published_date": "2026-02-08 01:55:32 UTC",
      "updated_date": "2026-02-08 01:55:32 UTC",
      "processing_status": "completed",
      "attempts": 1,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "llm_backup_calls": 0,
      "last_update": "2026-02-16T05:24:08.703788+00:00"
    },
    {
      "arxiv_id": "2602.07765v1",
      "title": "Disentangled Instrumental Variables for Causal Inference with Networked Observational Data",
      "title_zh": "面向网络化观测数据因果推断的解耦工具变量",
      "authors": [
        "Zhirong Huang",
        "Debo Cheng",
        "Guixian Zhang",
        "Yi Wang",
        "Jiuyong Li",
        "Shichao Zhang"
      ],
      "abstract": "Instrumental variables (IVs) are crucial for addressing unobservable confounders, yet their stringent exogeneity assumptions pose significant challenges in networked data. Existing methods typically rely on modelling neighbour information when recovering IVs, thereby inevitably mixing shared environment-induced endogenous correlations and individual-specific exogenous variation, leading the resulting IVs to inherit dependence on unobserved confounders and to violate exogeneity. To overcome this challenge, we propose $\\underline{Dis}$entangled $\\underline{I}$nstrumental $\\underline{V}$ariables (DisIV) framework, a novel method for causal inference based on networked observational data with latent confounders. DisIV exploits network homogeneity as an inductive bias and employs a structural disentanglement mechanism to extract individual-specific components that serve as latent IVs. The causal validity of the extracted IVs is constrained through explicit orthogonality and exclusion conditions. Extensive semi-synthetic experiments on real-world datasets demonstrate that DisIV consistently outperforms state-of-the-art baselines in causal effect estimation under network-induced confounding.",
      "tldr_zh": "该研究提出了Disentangled Instrumental Variables (DisIV)框架，旨在解决网络观测数据中由于不可观测混杂因素（latent confounders）导致的因果推断挑战。现有方法在利用邻居信息恢复工具变量（Instrumental Variables, IVs）时，往往会混杂共享环境引发的内生相关性和个体特有的外生变异，导致生成的工具变量违反外生性假设。DisIV利用网络同质性（network homogeneity）作为归纳偏置，通过结构解耦（structural disentanglement）机制提取个体特有的成分作为潜工具变量（latent IVs）。为了确保所提取IV的因果有效性，该框架通过显式的正交性（orthogonality）和排他性（exclusion）条件进行约束。在真实世界数据集上的大量半合成实验表明，DisIV在网络诱导混杂的场景下，其因果效应估计性能一致优于现有的最先进基准模型。",
      "categories": [
        "cs.AI"
      ],
      "primary_category": "cs.AI",
      "comment": "",
      "pdf_url": "https://arxiv.org/pdf/2602.07765v1",
      "published_date": "2026-02-08 01:45:21 UTC",
      "updated_date": "2026-02-08 01:45:21 UTC",
      "processing_status": "completed",
      "attempts": 1,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "llm_backup_calls": 0,
      "last_update": "2026-02-16T05:24:20.011107+00:00"
    },
    {
      "arxiv_id": "2602.07764v1",
      "title": "Preference Conditioned Multi-Objective Reinforcement Learning: Decomposed, Diversity-Driven Policy Optimization",
      "title_zh": "偏好调节的多目标强化学习：分解式、多样性驱动的策略优化",
      "authors": [
        "Tanmay Ambadkar",
        "Sourav Panda",
        "Shreyash Kale",
        "Jonathan Dodge",
        "Abhinav Verma"
      ],
      "abstract": "Multi-objective reinforcement learning (MORL) seeks to learn policies that balance multiple, often conflicting objectives. Although a single preference-conditioned policy is the most flexible and scalable solution, existing approaches remain brittle in practice, frequently failing to recover complete Pareto fronts. We show that this failure stems from two structural issues in current methods: destructive gradient interference caused by premature scalarization and representational collapse across the preference space. We introduce $D^3PO$, a PPO-based framework that reorganizes multi-objective policy optimization to address these issues directly. $D^3PO$ preserves per-objective learning signals through a decomposed optimization pipeline and integrates preferences only after stabilization, enabling reliable credit assignment. In addition, a scaled diversity regularizer enforces sensitivity of policy behavior to preference changes, preventing collapse. Across standard MORL benchmarks, including high-dimensional and many-objective control tasks, $D^3PO$ consistently discovers broader and higher-quality Pareto fronts than prior single- and multi-policy methods, matching or exceeding state-of-the-art hypervolume and expected utility while using a single deployable policy.",
      "tldr_zh": "该研究探讨了多目标强化学习(Multi-objective reinforcement learning, MORL)中平衡多个冲突目标的问题，指出目前的偏好调节策略在恢复完整帕累托前沿(Pareto fronts)时表现脆弱。研究发现，这种失效主要源于过早标量化引起的破坏性梯度干扰以及偏好空间中的表征坍缩。为此，作者提出了基于PPO的优化框架$D^3PO$，通过分解的优化流水线保留各目标的学习信号，并仅在稳定后整合偏好以实现可靠的信用分配(credit assignment)。同时，该框架引入了缩放多样性正则化项(scaled diversity regularizer)来增强策略对偏好变化的敏感性，从而防止模型坍缩。在包括高维及多目标控制任务的基准测试中，$D^3PO$能够发现比以往方法更宽且更高质量的帕累托前沿。最后，实验证明该方法在仅使用单一可部署策略的前提下，其超体积(hypervolume)和预期效用均达到或超过了现有最先进水平。",
      "categories": [
        "cs.LG",
        "cs.AI"
      ],
      "primary_category": "cs.LG",
      "comment": "",
      "pdf_url": "https://arxiv.org/pdf/2602.07764v1",
      "published_date": "2026-02-08 01:45:01 UTC",
      "updated_date": "2026-02-08 01:45:01 UTC",
      "processing_status": "completed",
      "attempts": 1,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "llm_backup_calls": 0,
      "last_update": "2026-02-16T05:24:22.401610+00:00"
    },
    {
      "arxiv_id": "2602.07755v1",
      "title": "Learning to Continually Learn via Meta-learning Agentic Memory Designs",
      "title_zh": "通过智能体记忆设计的元学习学会持续学习",
      "authors": [
        "Yiming Xiong",
        "Shengran Hu",
        "Jeff Clune"
      ],
      "abstract": "The statelessness of foundation models bottlenecks agentic systems' ability to continually learn, a core capability for long-horizon reasoning and adaptation. To address this limitation, agentic systems commonly incorporate memory modules to retain and reuse past experience, aiming for continual learning during test time. However, most existing memory designs are human-crafted and fixed, which limits their ability to adapt to the diversity and non-stationarity of real-world tasks. In this paper, we introduce ALMA (Automated meta-Learning of Memory designs for Agentic systems), a framework that meta-learns memory designs to replace hand-engineered memory designs, therefore minimizing human effort and enabling agentic systems to be continual learners across diverse domains. Our approach employs a Meta Agent that searches over memory designs expressed as executable code in an open-ended manner, theoretically allowing the discovery of arbitrary memory designs, including database schemas as well as their retrieval and update mechanisms. Extensive experiments across four sequential decision-making domains demonstrate that the learned memory designs enable more effective and efficient learning from experience than state-of-the-art human-crafted memory designs on all benchmarks. When developed and deployed safely, ALMA represents a step toward self-improving AI systems that learn to be adaptive, continual learners.",
      "tldr_zh": "针对基础模型在 Agentic systems 中因无状态性导致难以实现持续学习 (Continual Learning) 的问题，本文指出了现有固定的人工记忆设计难以适应现实任务多样性和非平稳性的不足。研究团队提出了 ALMA (Automated meta-Learning of Memory designs for Agentic systems) 框架，旨在通过元学习 (Meta-learning) 自动生成的记忆设计取代传统的人工工程，从而降低人工成本并提升系统的适应性。该框架利用一个 Meta Agent 在开放空间中搜索以可执行代码表示的记忆设计，涵盖了数据库架构 (Database schemas) 及其检索与更新机制。在四个序列决策领域进行的广泛实验证明，ALMA 学习到的记忆设计在所有基准测试中均优于目前最先进的人工设计方案，能够更高效地从既往经验中学习。这一成果为开发具备自我改进能力、能够适应不同领域的持续学习 AI 系统提供了新的路径。",
      "categories": [
        "cs.AI"
      ],
      "primary_category": "cs.AI",
      "comment": "",
      "pdf_url": "https://arxiv.org/pdf/2602.07755v1",
      "published_date": "2026-02-08 01:20:49 UTC",
      "updated_date": "2026-02-08 01:20:49 UTC",
      "processing_status": "completed",
      "attempts": 1,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "llm_backup_calls": 0,
      "last_update": "2026-02-16T05:24:25.701061+00:00"
    },
    {
      "arxiv_id": "2602.07754v1",
      "title": "Humanizing AI Grading: Student-Centered Insights on Fairness, Trust, Consistency and Transparency",
      "title_zh": "人工智能评分的人性化：以学生为中心的公平性、信任感、一致性与透明度洞察",
      "authors": [
        "Bahare Riahi",
        "Veronica Catete"
      ],
      "abstract": "This study investigates students' perceptions of Artificial Intelligence (AI) grading systems in an undergraduate computer science course (n = 27), focusing on a block-based programming final project. Guided by the ethical principles framework articulated by Jobin (2019), our study examines fairness, trust, consistency, and transparency in AI grading by comparing AI-generated feedback with original human-graded feedback. Findings reveal concerns about AI's lack of contextual understanding and personalization. We recommend that equitable and trustworthy AI systems reflect human judgment, flexibility, and empathy, serving as supplementary tools under human oversight. This work contributes to ethics-centered assessment practices by amplifying student voices and offering design principles for humanizing AI in designed learning environments.",
      "tldr_zh": "该研究探讨了学生对本科计算机科学课程中人工智能(AI)评分系统的看法，重点分析了 Fairness（公平性）、Trust（信任度）、Consistency（一致性）和 Transparency（透明度）等伦理维度。研究通过将 AI 生成的反馈与原始的人工评分反馈进行对比，调查了学生在图形化编程期末项目中的实际感知。研究发现，学生对 AI 评分系统在缺乏上下文理解和个性化表达方面的局限性表示担忧。基于此，作者建议公平且值得信赖的 AI 系统应当体现人类的判断力、灵活性和 Empathy（共情），并在人类监督下作为辅助工具。该工作通过放大学生的声音，为在学习环境中实现 AI 的人性化提供了设计原则，并对以伦理为中心的评估实践做出了重要贡献。",
      "categories": [
        "cs.AI",
        "cs.HC"
      ],
      "primary_category": "cs.AI",
      "comment": "13 pages, 3 figures",
      "pdf_url": "https://arxiv.org/pdf/2602.07754v1",
      "published_date": "2026-02-08 01:18:10 UTC",
      "updated_date": "2026-02-08 01:18:10 UTC",
      "processing_status": "completed",
      "attempts": 1,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "llm_backup_calls": 0,
      "last_update": "2026-02-16T05:24:27.704975+00:00"
    },
    {
      "arxiv_id": "2602.07749v1",
      "title": "Geo-Code: A Code Framework for Reverse Code Generation from Geometric Images Based on Two-Stage Multi-Agent Evolution",
      "title_zh": "Geo-Code：基于两阶段多智能体演化的几何图像逆向代码生成框架",
      "authors": [
        "Zhenyu Wu",
        "Yanxi Long",
        "Jian Li",
        "Hua Huang"
      ],
      "abstract": "Program code serves as a bridge linking vision and logic, providing a feasible supervisory approach for enhancing the multimodal reasoning capability of large models through geometric operations such as auxiliary line construction and perspective transformation. Nevertheless, current inverse graphics methods face tremendous challenges in accurately reconstructing complex geometric details, which often results in the loss of key geometric constraints or structural distortion. To address this bottleneck, we propose Geo-coder -- the first inverse programming framework for geometric images based on a multi-agent system. Our method innovatively decouples the process into geometric modeling via pixel-wise anchoring and metric-driven code evolution: Stage 1 leverages the complementary advantages of visual operators and large models to achieve precise capture of pixel coordinates and visual attributes; Stage 2 introduces a synthesis-rendering-validation closed loop, where bidirectional visual feedback drives the self-correction of code. Extensive experiments demonstrate that Geo-coder achieves a substantial lead in both geometric reconstruction accuracy and visual consistency. Notably, by effectively preserving the core geometric semantics, the images reconstructed with our method exhibit equivalent performance to the original ones in multimodal reasoning tasks, which fully validates the robustness of the framework. Finally, to further reduce research costs, we have open-sourced the Geo-coder dataset constructed on the GeoCode framework, which contains more than 1,500 samples. On this basis, we have also open-sourced the GeocodeLM model, laying a solid data and model foundation for subsequent research in this field.",
      "tldr_zh": "该研究提出了Geo-coder，这是首个基于多智能体系统(multi-agent system)的几何图像逆向编程(inverse programming)框架，旨在解决现有方法在重建复杂几何细节时面临的结构失真和几何约束丢失问题。该框架将处理过程创新性地解耦为两个阶段，首先通过像素级锚定(pixel-wise anchoring)结合视觉算子与大模型的优势，实现对几何建模及视觉属性的精确捕捉。随后，在度量驱动的代码演化(metric-driven code evolution)阶段，利用“合成-渲染-验证”的闭环机制及双向视觉反馈驱动代码的自我修正。实验证明，Geo-coder在几何重建精度和视觉一致性上均显著领先，且重建后的图像在多模态推理任务中表现出与原始图像等效的性能。此外，研究团队还开源了包含1500余个样本的Geo-coder数据集以及GeocodeLM模型，为该领域的后续研究奠定了坚实的数据和模型基础。",
      "categories": [
        "cs.AI"
      ],
      "primary_category": "cs.AI",
      "comment": "ICML2026",
      "pdf_url": "https://arxiv.org/pdf/2602.07749v1",
      "published_date": "2026-02-08 00:48:49 UTC",
      "updated_date": "2026-02-08 00:48:49 UTC",
      "processing_status": "completed",
      "attempts": 1,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "llm_backup_calls": 0,
      "last_update": "2026-02-16T05:24:32.008070+00:00"
    },
    {
      "arxiv_id": "2602.07739v1",
      "title": "HypRAG: Hyperbolic Dense Retrieval for Retrieval Augmented Generation",
      "title_zh": "HypRAG：面向检索增强生成的双曲稠密检索",
      "authors": [
        "Hiren Madhu",
        "Ngoc Bui",
        "Ali Maatouk",
        "Leandros Tassiulas",
        "Smita Krishnaswamy",
        "Menglin Yang",
        "Sukanta Ganguly",
        "Kiran Srinivasan",
        "Rex Ying"
      ],
      "abstract": "Embedding geometry plays a fundamental role in retrieval quality, yet dense retrievers for retrieval-augmented generation (RAG) remain largely confined to Euclidean space. However, natural language exhibits hierarchical structure from broad topics to specific entities that Euclidean embeddings fail to preserve, causing semantically distant documents to appear spuriously similar and increasing hallucination risk. To address these limitations, we introduce hyperbolic dense retrieval, developing two model variants in the Lorentz model of hyperbolic space: HyTE-FH, a fully hyperbolic transformer, and HyTE-H, a hybrid architecture projecting pre-trained Euclidean embeddings into hyperbolic space. To prevent representational collapse during sequence aggregation, we introduce the Outward Einstein Midpoint, a geometry-aware pooling operator that provably preserves hierarchical structure. On MTEB, HyTE-FH outperforms equivalent Euclidean baselines, while on RAGBench, HyTE-H achieves up to 29% gains over Euclidean baselines in context relevance and answer relevance using substantially smaller models than current state-of-the-art retrievers. Our analysis also reveals that hyperbolic representations encode document specificity through norm-based separation, with over 20% radial increase from general to specific concepts, a property absent in Euclidean embeddings, underscoring the critical role of geometric inductive bias in faithful RAG systems.",
      "tldr_zh": "该研究探讨了嵌入几何在检索增强生成(RAG)中的关键作用，针对欧几里得空间(Euclidean space)无法有效捕捉语言层次结构导致幻觉风险的问题，提出了双曲密集检索(Hyperbolic dense retrieval)框架HypRAG。研究开发了两种基于洛伦兹模型(Lorentz model)的模型变体：全双曲Transformer模型HyTE-FH，以及将预训练欧几里得嵌入投影到双曲空间的混合架构HyTE-H。为防止序列聚合过程中的表示崩溃，研究引入了Outward Einstein Midpoint，这是一种能够有效保留层次结构的几何感知池化算子。实验结果显示，HyTE-FH在MTEB上表现优于同类基线，而HyTE-H在RAGBench上的上下文和回答相关性提升高达29%，且模型规模远小于现有最先进检索器。分析进一步揭示，双曲表示能通过范数分离编码文档特异性，其从通用到具体概念的径向增长特性是欧几里得嵌入所欠缺的，这证明了几何归纳偏置(Geometric inductive bias)在构建忠实RAG系统中的核心地位。",
      "categories": [
        "cs.IR",
        "cs.AI"
      ],
      "primary_category": "cs.IR",
      "comment": "",
      "pdf_url": "https://arxiv.org/pdf/2602.07739v1",
      "published_date": "2026-02-08 00:18:05 UTC",
      "updated_date": "2026-02-08 00:18:05 UTC",
      "processing_status": "completed",
      "attempts": 1,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "llm_backup_calls": 0,
      "last_update": "2026-02-16T05:24:48.099827+00:00"
    },
    {
      "arxiv_id": "2602.07738v2",
      "title": "Learnable Chernoff Baselines for Inference-Time Alignment",
      "title_zh": "面向推理时对齐的可学习 Chernoff 基准",
      "authors": [
        "Sunil Madhow",
        "Yuchen Liang",
        "Ness Shroff",
        "Yingbin Liang",
        "Yu-Xiang Wang"
      ],
      "abstract": "We study inference-time reward-guided alignment for generative models. Existing methods often rely on either architecture-specific adaptations or computationally costly inference procedures. We introduce Learnable Chernoff Baselines (LCBs) as a method for efficiently and approximately sampling from the exponentially tilted kernels that arise from KL-regularized reward alignment. Using only black-box sampling access to the pretrained model, LCBs implement a form of rejection sampling with adaptively selected acceptance probabilities, which allows fine-grained control over inference-compute scaling. We establish total-variation guarantees to the ideal aligned model, and demonstrate in both continuous and discrete diffusion settings that LCB sampling closely matches ideal rejection sampling while using substantially fewer queries to the pretrained model.",
      "tldr_zh": "该研究针对生成模型的推理时奖励引导对齐(inference-time reward-guided alignment)问题，提出了可学习切尔诺夫基准(Learnable Chernoff Baselines, LCBs)方法，以解决现有对齐方法依赖特定架构或计算成本过高的问题。LCBs通过对预训练模型的黑盒采样访问，实现从KL正则化奖励对齐产生的指数倾斜核(exponentially tilted kernels)中进行高效近似采样。该方法通过自适应选择接受概率来执行拒绝采样(rejection sampling)，允许对推理计算规模(inference-compute scaling)进行精细化控制。研究者为该方法提供了相对于理想对齐模型的全变分(total-variation)保证，确保了理论上的可靠性。实验结果证明，在连续和离散扩散(diffusion)设置中，LCB采样能够在显著减少预训练模型查询次数的情况下，实现与理想拒绝采样高度接近的性能表现。",
      "categories": [
        "cs.LG",
        "cs.AI"
      ],
      "primary_category": "cs.LG",
      "comment": "",
      "pdf_url": "https://arxiv.org/pdf/2602.07738v2",
      "published_date": "2026-02-08 00:09:40 UTC",
      "updated_date": "2026-02-13 18:15:21 UTC",
      "processing_status": "completed",
      "attempts": 1,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "llm_backup_calls": 0,
      "last_update": "2026-02-16T05:24:48.504631+00:00"
    },
    {
      "arxiv_id": "2602.07730v1",
      "title": "The Laplacian Keyboard: Beyond the Linear Span",
      "title_zh": "Laplacian Keyboard：超越线性空间的层级化行为基石",
      "authors": [
        "Siddarth Chandrasekar",
        "Marlos C. Machado"
      ],
      "abstract": "Across scientific disciplines, Laplacian eigenvectors serve as a fundamental basis for simplifying complex systems, from signal processing to quantum mechanics. In reinforcement learning (RL), these eigenvectors provide a natural basis for approximating reward functions; however, their use is typically limited to their linear span, which restricts expressivity in complex environments. We introduce the Laplacian Keyboard (LK), a hierarchical framework that goes beyond the linear span. LK constructs a task-agnostic library of options from these eigenvectors, forming a behavior basis guaranteed to contain the optimal policy for any reward within the linear span. A meta-policy learns to stitch these options dynamically, enabling efficient learning of policies outside the original linear constraints. We establish theoretical bounds on zero-shot approximation error and demonstrate empirically that LK surpasses zero-shot solutions while achieving improved sample efficiency compared to standard RL methods.",
      "tldr_zh": "该研究针对强化学习(Reinforcement Learning, RL)中Laplacian eigenvectors的应用局限，提出了名为Laplacian Keyboard (LK)的层次化框架，旨在突破传统线性跨度(linear span)对模型表达能力的限制。LK通过Laplacian eigenvectors构建了一个任务无关的options库，从而形成一套行为基(behavior basis)，该基组能够保证包含线性跨度内任何奖励函数的最优策略。通过引入元策略(meta-policy)对这些options进行动态拼接，LK能够有效学习并实现原始线性约束之外的复杂策略。研究不仅确立了关于zero-shot近似误差的理论界限，还通过实验证明LK在性能上超越了传统的zero-shot解决方案。与标准的RL方法相比，LK显著提升了采样效率，为在复杂环境中利用特征向量简化系统提供了更具扩展性的路径。",
      "categories": [
        "cs.LG",
        "cs.AI"
      ],
      "primary_category": "cs.LG",
      "comment": "28 pages, 17 figures",
      "pdf_url": "https://arxiv.org/pdf/2602.07730v1",
      "published_date": "2026-02-07 23:25:29 UTC",
      "updated_date": "2026-02-07 23:25:29 UTC",
      "processing_status": "completed",
      "attempts": 1,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "llm_backup_calls": 0,
      "last_update": "2026-02-16T05:24:52.618442+00:00"
    },
    {
      "arxiv_id": "2602.07729v1",
      "title": "Do We Need Adam? Surprisingly Strong and Sparse Reinforcement Learning with SGD in LLMs",
      "title_zh": "我们真的需要 Adam 吗？大语言模型强化学习中 SGD 展现出惊人的强健性与更新稀疏性",
      "authors": [
        "Sagnik Mukherjee",
        "Lifan Yuan",
        "Pavan Jayasinha",
        "Dilek Hakkani-Tür",
        "Hao Peng"
      ],
      "abstract": "Reinforcement learning (RL), particularly RL from verifiable reward (RLVR), has become a crucial phase of training large language models (LLMs) and a key focus of current scaling efforts. However, optimization practices in RL largely follow those of next-token prediction stages (e.g., pretraining and supervised fine-tuning), despite fundamental differences between RL and these stages highlighted by recent work. One such practice is the use of the AdamW optimizer, which is widely adopted for training large-scale transformers despite its high memory overhead. Our analysis shows that both momentum and adaptive learning rates in AdamW are less influential in RL than in SFT, leading us to hypothesize that RL benefits less from Adam-style per-parameter adaptive learning rates and momentum. Confirming this hypothesis, our experiments demonstrate that the substantially more memory-efficient SGD, which is known to perform poorly in supervised learning of large-scale transformers, matches or even outperforms AdamW in RL for LLMs. Remarkably, full fine-tuning with SGD updates fewer than 0.02% of model parameters without any sparsity-promoting regularization, more than 1000 times fewer than AdamW. Our analysis offers potential reasons for this update sparsity. These findings provide new insights into the optimization dynamics of RL in LLMs and show that RL can be substantially more parameter-efficient than previously recognized.",
      "tldr_zh": "该研究探讨了在大语言模型（LLMs）的强化学习（RL）阶段是否必须使用高内存开销的 AdamW 优化器，并对比了其与 SGD 在优化动力学上的差异。实验结果显示，尽管 SGD 在 Transformer 的大规模监督学习中通常表现不佳，但在 LLMs 的强化学习（特别是 RLVR 阶段）中却能达到与 AdamW 持平甚至更优的效果。研究指出，RL 相比于监督微调（SFT）对自适应学习率和动量的依赖更低，这使得更为内存高效的 SGD 成为可行方案。最显著的发现是，使用 SGD 进行全参数微调时，在无正则化干预下仅有不到 0.02% 的模型参数被更新，其参数更新稀疏度比 AdamW 高出 1000 倍以上。这一发现揭示了 RL 在 LLMs 训练中极高的参数效率，并为优化大规模语言模型提供了全新的视角和更具效率的路径。",
      "categories": [
        "cs.LG",
        "cs.AI"
      ],
      "primary_category": "cs.LG",
      "comment": "",
      "pdf_url": "https://arxiv.org/pdf/2602.07729v1",
      "published_date": "2026-02-07 23:25:26 UTC",
      "updated_date": "2026-02-07 23:25:26 UTC",
      "processing_status": "completed",
      "attempts": 1,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "llm_backup_calls": 0,
      "last_update": "2026-02-16T05:24:57.807488+00:00"
    },
    {
      "arxiv_id": "2602.07697v1",
      "title": "On the Infinite Width and Depth Limits of Predictive Coding Networks",
      "title_zh": "预测编码网络的无限宽与无限深极限研究",
      "authors": [
        "Francesco Innocenti",
        "El Mehdi Achour",
        "Rafal Bogacz"
      ],
      "abstract": "Predictive coding (PC) is a biologically plausible alternative to standard backpropagation (BP) that minimises an energy function with respect to network activities before updating weights. Recent work has improved the training stability of deep PC networks (PCNs) by leveraging some BP-inspired reparameterisations. However, the full scalability and theoretical basis of these approaches remains unclear. To address this, we study the infinite width and depth limits of PCNs. For linear residual networks, we show that the set of width- and depth-stable feature-learning parameterisations for PC is exactly the same as for BP. Moreover, under any of these parameterisations, the PC energy with equilibrated activities converges to the BP loss in a regime where the model width is much larger than the depth, resulting in PC computing the same gradients as BP. Experiments show that these results hold in practice for deep nonlinear networks, as long as an activity equilibrium seem to be reached. Overall, this work unifies various previous theoretical and empirical results and has potentially important implications for the scaling of PCNs.",
      "tldr_zh": "该研究探讨了预测编码网络(Predictive Coding Networks, PCNs)在无限宽度和深度极限下的性质，旨在为其扩展性和理论基础提供支撑。作为一种生物学合理的反向传播(Backpropagation, BP)替代方案，PC通过在更新权重前最小化能量函数来调整网络活动。作者证明了在线性残差网络中，PC实现宽度和深度稳定特征学习的参数化方案与BP完全一致。研究发现，在模型宽度远大于深度的状态下，达到平衡态的PC能量会收敛至BP损失，从而计算出与BP相同的梯度。实验结果表明，只要达到活动平衡，这些结论在深度非线性网络中同样适用。该工作统一了先前的理论与实证发现，为PCNs的大规模扩展奠定了关键的理论基础。",
      "categories": [
        "cs.LG",
        "cs.AI",
        "cs.NE"
      ],
      "primary_category": "cs.LG",
      "comment": "31 pages, 27 figures",
      "pdf_url": "https://arxiv.org/pdf/2602.07697v1",
      "published_date": "2026-02-07 20:47:32 UTC",
      "updated_date": "2026-02-07 20:47:32 UTC",
      "processing_status": "completed",
      "attempts": 1,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "llm_backup_calls": 0,
      "last_update": "2026-02-16T05:24:55.701145+00:00"
    },
    {
      "arxiv_id": "2602.07695v2",
      "title": "EventCast: Hybrid Demand Forecasting in E-Commerce with LLM-Based Event Knowledge",
      "title_zh": "EventCast：基于大语言模型事件知识的电商混合需求预测",
      "authors": [
        "Congcong Hu",
        "Yuang Shi",
        "Fan Huang",
        "Yang Xiang",
        "Zhou Ye",
        "Ming Jin",
        "Shiyu Wang"
      ],
      "abstract": "Demand forecasting is a cornerstone of e-commerce operations, directly impacting inventory planning and fulfillment scheduling. However, existing forecasting systems often fail during high-impact periods such as flash sales, holiday campaigns, and sudden policy interventions, where demand patterns shift abruptly and unpredictably. In this paper, we introduce EventCast, a modular forecasting framework that integrates future event knowledge into time-series prediction. Unlike prior approaches that ignore future interventions or directly use large language models (LLMs) for numerical forecasting, EventCast leverages LLMs solely for event-driven reasoning. Unstructured business data, which covers campaigns, holiday schedules, and seller incentives, from existing operational databases, is processed by an LLM that converts it into interpretable textual summaries leveraging world knowledge for cultural nuances and novel event combinations. These summaries are fused with historical demand features within a dual-tower architecture, enabling accurate, explainable, and scalable forecasts. Deployed on real-world e-commerce scenarios spanning 4 countries of 160 regions over 10 months, EventCast achieves up to 86.9% and 97.7% improvement on MAE and MSE compared to the variant without event knowledge, and reduces MAE by up to 57.0% and MSE by 83.3% versus the best industrial baseline during event-driven periods. EventCast has deployed into real-world industrial pipelines since March 2025, offering a practical solution for improving operational decision-making in dynamic e-commerce environments.",
      "tldr_zh": "该研究针对电子商务需求预测（Demand forecasting）在促销、假日及政策干预等高影响时段因需求模式突变而失效的问题，提出了 EventCast 这一模块化预测框架。该框架创新性地将大语言模型（LLMs）仅用于事件驱动的推理（event-driven reasoning），通过处理非结构化商业数据生成包含文化差异和事件组合的可解释文本摘要。EventCast 采用双塔架构（dual-tower architecture）将这些文本摘要与历史需求特征深度融合，从而实现准确且可扩展的时间序列预测（time-series prediction）。在覆盖 4 个国家和 160 个地区的真实电商场景测试中，EventCast 在事件期间相比最佳工业基准模型将 MAE 降低了 57.0%，MSE 降低了 83.3%。自 2025 年 3 月起，该系统已正式部署于实际工业流水线，为动态电商环境下的运营决策提供了高效且具备解释性的实践方案。",
      "categories": [
        "cs.AI",
        "cs.CL",
        "cs.IR",
        "cs.MM"
      ],
      "primary_category": "cs.AI",
      "comment": "",
      "pdf_url": "https://arxiv.org/pdf/2602.07695v2",
      "published_date": "2026-02-07 20:36:37 UTC",
      "updated_date": "2026-02-11 14:52:27 UTC",
      "processing_status": "completed",
      "attempts": 1,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "llm_backup_calls": 0,
      "last_update": "2026-02-16T05:25:07.202393+00:00"
    },
    {
      "arxiv_id": "2602.07689v1",
      "title": "Process-of-Thought Reasoning for Videos",
      "title_zh": "视频过程化思维推理",
      "authors": [
        "Jusheng Zhang",
        "Kaitong Cai",
        "Jian Wang",
        "Yongsen Zheng",
        "Kwok-Yan Lam",
        "Keze Wang"
      ],
      "abstract": "Video understanding requires not only recognizing visual content but also performing temporally grounded, multi-step reasoning over long and noisy observations. We propose Process-of-Thought (PoT) Reasoning for Videos, a framework that makes the reasoning process explicit by structuring video inference into a sequence of lightweight, verifiable steps. PoT interleaves (i) temporal evidence selection, (ii) step-wise state updates, and (iii) constrained answer synthesis, enabling the model to progressively refine hypotheses while maintaining traceability to video evidence. The framework is designed to be model-agnostic and can be plugged into existing vision-language backbones, supporting both closed-book reasoning and evidence-augmented reasoning with external tools. We further introduce a unified representation for PoT traces that aligns intermediate decisions with temporal segments, which improves robustness to distractors and reduces hallucinated explanations. Extensive experiments on standard video reasoning tasks demonstrate that PoT consistently improves factual correctness and temporal grounding, while providing interpretable reasoning traces for diagnosis and downstream use.",
      "tldr_zh": "该研究提出了Process-of-Thought (PoT) Reasoning for Videos框架，旨在解决视频理解中对冗长且包含噪声的观察进行多步推理和时序定位(temporally grounded)的难题。PoT通过将视频推理结构化为一系列轻量级、可验证的步骤，使推理过程显式化，并支持对假设的逐步细化。该框架交替执行时序证据选择(temporal evidence selection)、逐步状态更新(step-wise state updates)和受限答案合成(constrained answer synthesis)，确保了推理与视频证据的可追溯性。PoT采用模型无关(model-agnostic)设计，可无缝集成至现有的视觉语言模型(vision-language backbones)中，并兼容闭卷推理与工具增强推理。通过引入统一的PoT轨迹表示，该方法将中间决策与时序片段对齐，有效减少了幻觉现象并提升了对干扰项的鲁棒性。实验表明，PoT在标准任务中显著提升了事实准确性和时序定位能力，同时为下游应用提供了可解释的推理轨迹。",
      "categories": [
        "cs.CV",
        "cs.AI"
      ],
      "primary_category": "cs.CV",
      "comment": "",
      "pdf_url": "https://arxiv.org/pdf/2602.07689v1",
      "published_date": "2026-02-07 20:25:46 UTC",
      "updated_date": "2026-02-07 20:25:46 UTC",
      "processing_status": "completed",
      "attempts": 1,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "llm_backup_calls": 0,
      "last_update": "2026-02-16T05:25:13.099388+00:00"
    },
    {
      "arxiv_id": "2602.07681v2",
      "title": "Mapping Drivers of Greenness: Spatial Variable Selection for MODIS Vegetation Indices",
      "title_zh": "绿度驱动因素制图：面向MODIS植被指数的空间变量选择",
      "authors": [
        "Qishi Zhan",
        "Cheng-Han Yu",
        "Yuchi Chen",
        "Zhikang Dong",
        "Rajarshi Guhaniyogi"
      ],
      "abstract": "Understanding how environmental drivers relate to vegetation condition motivates spatially varying regression models, but estimating a separate coefficient surface for every predictor can yield noisy patterns and poor interpretability when many predictors are irrelevant. Motivated by MODIS vegetation index studies, we examine predictors from spectral bands, productivity and energy fluxes, observation geometry, and land surface characteristics. Because these relationships vary with canopy structure, climate, land use, and measurement conditions, methods should both model spatially varying effects and identify where predictors matter. We propose a spatially varying coefficient model where each coefficient surface uses a tensor product B-spline basis and a Bayesian group lasso prior on the basis coefficients. This prior induces predictor level shrinkage, pushing negligible effects toward zero while preserving spatial structure. Posterior inference uses Markov chain Monte Carlo and provides uncertainty quantification for each effect surface. We summarize retained effects with spatial significance maps that mark locations where the 95 percent posterior credible interval excludes zero, and we define a spatial coverage probability as the proportion of locations where the credible interval excludes zero. Simulations recover sparsity and achieve prediction. A MODIS application yields a parsimonious subset of predictors whose effect maps clarify dominant controls across landscapes.",
      "tldr_zh": "该研究提出了一种具有空间变化系数的模型，旨在分析环境因素如何影响植被状况，并解决多变量回归中由于无关预测因子导致的噪声和解释性差等问题。该方法利用张量积B样条(B-spline)基函数构建系数曲面，并结合贝叶斯组Lasso(Bayesian group lasso)先验分布实现变量选择，在保留空间结构的同时将微弱效应压缩至零。研究通过马尔可夫链蒙特卡罗(MCMC)方法进行后验推断，并利用空间显著性图和空间覆盖概率来量化各效应曲面的不确定性。模拟实验证明该模型能有效恢复稀疏性并提高预测准确性。在MODIS植被指数应用中，该模型成功筛选出简洁的预测因子子集，其效应图清晰地揭示了不同景观区域内植被绿度的主要控制因素。",
      "categories": [
        "stat.ME",
        "cs.AI"
      ],
      "primary_category": "stat.ME",
      "comment": "",
      "pdf_url": "https://arxiv.org/pdf/2602.07681v2",
      "published_date": "2026-02-07 20:05:46 UTC",
      "updated_date": "2026-02-10 04:20:10 UTC",
      "processing_status": "completed",
      "attempts": 1,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "llm_backup_calls": 0,
      "last_update": "2026-02-16T05:25:09.099131+00:00"
    },
    {
      "arxiv_id": "2602.07680v1",
      "title": "Vision and language: Novel Representations and Artificial intelligence for Driving Scene Safety Assessment and Autonomous Vehicle Planning",
      "title_zh": "视觉语言：用于驾驶场景安全评估与自动驾驶汽车规划的新型表征及人工智能",
      "authors": [
        "Ross Greer",
        "Maitrayee Keskar",
        "Angel Martinez-Sanchez",
        "Parthib Roy",
        "Shashank Shriram",
        "Mohan Trivedi"
      ],
      "abstract": "Vision-language models (VLMs) have recently emerged as powerful representation learning systems that align visual observations with natural language concepts, offering new opportunities for semantic reasoning in safety-critical autonomous driving. This paper investigates how vision-language representations support driving scene safety assessment and decision-making when integrated into perception, prediction, and planning pipelines. We study three complementary system-level use cases. First, we introduce a lightweight, category-agnostic hazard screening approach leveraging CLIP-based image-text similarity to produce a low-latency semantic hazard signal. This enables robust detection of diverse and out-of-distribution road hazards without explicit object detection or visual question answering. Second, we examine the integration of scene-level vision-language embeddings into a transformer-based trajectory planning framework using the Waymo Open Dataset. Our results show that naively conditioning planners on global embeddings does not improve trajectory accuracy, highlighting the importance of representation-task alignment and motivating the development of task-informed extraction methods for safety-critical planning. Third, we investigate natural language as an explicit behavioral constraint on motion planning using the doScenes dataset. In this setting, passenger-style instructions grounded in visual scene elements suppress rare but severe planning failures and improve safety-aligned behavior in ambiguous scenarios. Taken together, these findings demonstrate that vision-language representations hold significant promise for autonomous driving safety when used to express semantic risk, intent, and behavioral constraints. Realizing this potential is fundamentally an engineering problem requiring careful system design and structured grounding rather than direct feature injection.",
      "tldr_zh": "该研究探讨了视觉语言模型（Vision-language models, VLMs）在自动驾驶场景安全评估和决策规划中的应用，并分析了感知、预测与规划流水线中语义推理的影响。首先，研究提出了一种基于CLIP图像文本相似度的轻量化风险筛选方法，无需显式物体检测即可实现低延迟的语义危害检测。其次，通过在Waymo Open Dataset上的实验发现，将场景级嵌入直接引入Transformer轨迹规划框架并不能提升准确性，强调了表示与任务对齐（representation-task alignment）的重要性。此外，研究还利用doScenes数据集验证了将自然语言作为运动规划的显式行为约束，发现这种方式能有效抑制严重的规划故障。综合结果表明，Vision-language representations在表达语义风险、意图和行为约束方面具有巨大潜力，但其性能提升依赖于精细的系统设计与结构化接地（grounding），而非简单的特征注入。",
      "categories": [
        "cs.CV",
        "cs.AI",
        "cs.LG",
        "cs.RO"
      ],
      "primary_category": "cs.CV",
      "comment": "",
      "pdf_url": "https://arxiv.org/pdf/2602.07680v1",
      "published_date": "2026-02-07 20:04:21 UTC",
      "updated_date": "2026-02-07 20:04:21 UTC",
      "processing_status": "completed",
      "attempts": 1,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "llm_backup_calls": 0,
      "last_update": "2026-02-16T05:25:12.103117+00:00"
    },
    {
      "arxiv_id": "2602.07679v1",
      "title": "Spectral Gating Networks",
      "title_zh": "谱门控网络",
      "authors": [
        "Jusheng Zhang",
        "Yijia Fan",
        "Kaitong Cai",
        "Jing Yang",
        "Yongsen Zheng",
        "Kwok-Yan Lam",
        "Liang Lin",
        "Keze Wang"
      ],
      "abstract": "Gating mechanisms are ubiquitous, yet a complementary question in feed-forward networks remains under-explored: how to introduce frequency-rich expressivity without sacrificing stability and scalability? This tension is exposed by spline-based Kolmogorov-Arnold Network (KAN) parameterizations, where grid refinement can induce parameter growth and brittle optimization in high dimensions. To propose a stability-preserving way to inject spectral capacity into existing MLP/FFN layers under fixed parameter and training budgets, we introduce Spectral Gating Networks (SGN), a drop-in spectral reparameterization. SGN augments a standard activation pathway with a compact spectral pathway and learnable gates that allow the model to start from a stable base behavior and progressively allocate capacity to spectral features during training. The spectral pathway is instantiated with trainable Random Fourier Features (learned frequencies and phases), replacing grid-based splines and removing resolution dependence. A hybrid GELU-Fourier formulation further improves optimization robustness while enhancing high-frequency fidelity. Across vision, NLP, audio, and PDE benchmarks, SGN consistently improves accuracy-efficiency trade-offs under comparable computational budgets, achieving 93.15% accuracy on CIFAR-10 and up to 11.7x faster inference than spline-based KAN variants. Code and trained models will be released.",
      "tldr_zh": "该研究提出了 Spectral Gating Networks (SGN)，一种旨在解决前馈网络在引入丰富频率表达能力时面临的稳定性与扩展性挑战的可插拔谱重参数化方法。针对基于样条的 Kolmogorov-Arnold Network (KAN) 在高维空间中因网格细化导致的参数激增和优化脆弱问题，SGN 通过紧凑的谱路径和可学习门控机制增强了标准的激活路径，允许模型在训练过程中逐步为谱特征分配容量。该架构利用可训练的 Random Fourier Features 替换了网格样条，从而消除了对分辨率的依赖，并结合混合 GELU-Fourier 公式提升了优化的稳健性与高频保真度。在视觉、自然语言处理 (NLP)、音频和偏微分方程 (PDE) 等多项基准测试中，SGN 均显著改善了准确率与效率的权衡。实验结果显示，SGN 在 CIFAR-10 数据集上达到了 93.15% 的准确率，且其推理速度比基于样条的 KAN 变体快达 11.7 倍。",
      "categories": [
        "cs.LG",
        "cs.AI"
      ],
      "primary_category": "cs.LG",
      "comment": "",
      "pdf_url": "https://arxiv.org/pdf/2602.07679v1",
      "published_date": "2026-02-07 20:00:49 UTC",
      "updated_date": "2026-02-07 20:00:49 UTC",
      "processing_status": "completed",
      "attempts": 1,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "llm_backup_calls": 0,
      "last_update": "2026-02-16T05:25:17.523013+00:00"
    },
    {
      "arxiv_id": "2602.07672v1",
      "title": "Debugging code world models",
      "title_zh": "代码世界模型调试",
      "authors": [
        "Babak Rahmani"
      ],
      "abstract": "Code World Models (CWMs) are language models trained to simulate program execution by predicting explicit runtime state after every executed command. This execution-based world modeling enables internal verification within the model, offering an alternative to natural language chain-of-thought reasoning. However, the sources of errors and the nature of CWMs' limitations remain poorly understood. We study CWMs from two complementary perspectives: local semantic execution and long-horizon state tracking. On real-code benchmarks, we identify two dominant failure regimes. First, dense runtime state reveals produce token-intensive execution traces, leading to token-budget exhaustion on programs with long execution histories. Second, failures disproportionately concentrate in string-valued state, which we attribute to limitations of subword tokenization rather than program structure. To study long-horizon behavior, we use a controlled permutation-tracking benchmark that isolates state propagation under action execution. We show that long-horizon degradation is driven primarily by incorrect action generation: when actions are replaced with ground-truth commands, a Transformer-based CWM propagates state accurately over long horizons, despite known limitations of Transformers in long-horizon state tracking. These findings suggest directions for more efficient supervision and state representations in CWMs that are better aligned with program execution and data types.",
      "tldr_zh": "这项研究深入探讨了代码世界模型 (Code World Models, CWMs) 的局限性与错误来源，该模型通过预测程序执行后的显式运行时状态，为自然语言链式思维推理 (Chain-of-Thought) 提供了基于执行的验证方案。通过在实际代码和受控的长程状态追踪基准上进行分析，研究发现了两个主要的失效模式：一是密集的运行状态输出会导致 Token 预算在长执行历史中迅速耗尽，二是字符串状态的预测失败更多归因于子词分词 (Subword Tokenization) 的局限。在长程行为研究中，结果表明性能退化主要由错误的动作生成 (Action Generation) 引起，而当给定真实命令 (Ground-truth Commands) 时，基于 Transformer 的 CWMs 能够实现出色的长程状态传播。这些发现不仅揭示了 CWMs 的内部机制，还为未来设计更符合程序执行逻辑和数据类型的状态表示与监督方法提供了重要指引。",
      "categories": [
        "cs.SE",
        "cs.AI",
        "cs.LG",
        "cs.PL",
        "cs.SC"
      ],
      "primary_category": "cs.SE",
      "comment": "8 pages, 4 figures, under review in conference",
      "pdf_url": "https://arxiv.org/pdf/2602.07672v1",
      "published_date": "2026-02-07 19:32:15 UTC",
      "updated_date": "2026-02-07 19:32:15 UTC",
      "processing_status": "completed",
      "attempts": 1,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "llm_backup_calls": 0,
      "last_update": "2026-02-16T05:25:47.020812+00:00"
    },
    {
      "arxiv_id": "2602.07670v1",
      "title": "Surprisal-Guided Selection: Compute-Optimal Test-Time Strategies for Execution-Grounded Code Generation",
      "title_zh": "惊奇度引导的选择：面向执行验证代码生成的计算最优测试时策略",
      "authors": [
        "Jarrod Barnes"
      ],
      "abstract": "Test-time training (TTT) adapts language models through gradient-based updates at inference. But is adaptation the right strategy? We study compute-optimal test-time strategies for verifiable execution-grounded (VEG) tasks, domains like GPU kernel optimization where a deterministic evaluator provides dense, continuous reward signals. Using KernelBench as our testbed and a 120B-parameter model (GPT-OSS-120B with LoRA adaptation), we find that search outperforms minimal adaptation (1-5 gradient steps): Best-of-N sampling achieves 90% task success (18/20 tasks) at K=64 across the full KernelBench L1 eval set while TTT's best checkpoint reaches only 30.6% (3-seed mean), with TTT's \"equivalent K\" falling below 1, worse than single-sample inference. The failure mode is over-sharpening: gradient updates collapse diversity toward mediocre solutions rather than discovering optimal ones. Our main contribution is surprisal-guided selection: selecting the highest-surprisal (lowest-confidence) correct sample yields 80% success vs. 50% for most-confident selection, a 30% improvement. Extending to surprisal-guided-top3 matches oracle performance at 100%. This zero-cost strategy, validated through length-controlled analysis, recovers oracle performance. For dense-reward VEG tasks, compute should be allocated to sample diversity and intelligent selection rather than gradient adaptation. The surprisal-guided selection principle may generalize to other execution-grounded domains where optimal solutions occupy the distribution tail.",
      "tldr_zh": "该研究探讨了在可验证执行（VEG）任务（如GPU内核优化）中，大语言模型的最优测试时（test-time）计算分配策略。研究发现，传统的测试时训练（Test-time Training, TTT）在KernelBench测试集上表现欠佳，其梯度更新会导致模型“过度锐化”并损失采样多样性，效果甚至不如简单的采样搜索。论文的核心贡献是提出了惊讶度引导选择（Surprisal-Guided Selection）策略，通过选择惊讶度最高（即模型最不自信）的正确样本，在无需额外计算成本的情况下，将成功率从50%提升至80%。实验证明，增加采样多样性并结合这种智能选择机制，比进行梯度适配更能有效发现执行任务中的最优解。这一发现表明，对于拥有密集奖励信号的执行类任务，计算资源应优先分配给样本多样性和选择策略，而非模型权重的在线微调。",
      "categories": [
        "cs.LG",
        "cs.AI"
      ],
      "primary_category": "cs.LG",
      "comment": "13 pages, 7 figures, 11 tables. Preprint. Code: https://github.com/jbarnes850/test-time-training",
      "pdf_url": "https://arxiv.org/pdf/2602.07670v1",
      "published_date": "2026-02-07 19:29:07 UTC",
      "updated_date": "2026-02-07 19:29:07 UTC",
      "processing_status": "completed",
      "attempts": 1,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "llm_backup_calls": 0,
      "last_update": "2026-02-16T05:25:32.699105+00:00"
    },
    {
      "arxiv_id": "2602.07668v1",
      "title": "Looking and Listening Inside and Outside: Multimodal Artificial Intelligence Systems for Driver Safety Assessment and Intelligent Vehicle Decision-Making",
      "title_zh": "舱内外视听感知：面向驾驶员安全评估与智能汽车决策的多模态人工智能系统",
      "authors": [
        "Ross Greer",
        "Laura Fleig",
        "Maitrayee Keskar",
        "Erika Maquiling",
        "Giovanni Tapia Lopez",
        "Angel Martinez-Sanchez",
        "Parthib Roy",
        "Jake Rattigan",
        "Mira Sur",
        "Alejandra Vidrio",
        "Thomas Marcotte",
        "Mohan Trivedi"
      ],
      "abstract": "The looking-in-looking-out (LILO) framework has enabled intelligent vehicle applications that understand both the outside scene and the driver state to improve safety outcomes, with examples in smart airbag deployment, takeover time prediction in autonomous control transitions, and driver attention monitoring. In this research, we propose an augmentation to this framework, making a case for the audio modality as an additional source of information to understand the driver, and in the evolving autonomy landscape, also the passengers and those outside the vehicle. We expand LILO by incorporating audio signals, forming the looking-and-listening inside-and-outside (L-LIO) framework to enhance driver state assessment and environment understanding through multimodal sensor fusion. We evaluate three example cases where audio enhances vehicle safety: supervised learning on driver speech audio to classify potential impairment states (e.g., intoxication), collection and analysis of passenger natural language instructions (e.g., \"turn after that red building\") to motivate how spoken language can interface with planning systems through audio-aligned instruction data, and limitations of vision-only systems where audio may disambiguate the guidance and gestures of external agents. Datasets include custom-collected in-vehicle and external audio samples in real-world environments. Pilot findings show that audio yields safety-relevant insights, particularly in nuanced or context-rich scenarios where sound is critical to safe decision-making or visual signals alone are insufficient. Challenges include ambient noise interference, privacy considerations, and robustness across human subjects, motivating further work on reliability in dynamic real-world contexts. L-LIO augments driver and scene understanding through multimodal fusion of audio and visual sensing, offering new paths for safety intervention.",
      "tldr_zh": "该研究在传统的Looking-In-Looking-Out (LILO) 框架基础上，提出了全新的Looking-and-Listening Inside-and-Outside (L-LIO) 框架，旨在通过引入音频模态来增强智能汽车的驾驶安全评估与决策能力。该框架利用多模态传感器融合 (Multimodal sensor fusion) 技术，综合处理车内外的视觉与音频信号，以实现对驾驶员状态及环境的深度理解。研究通过三个典型案例验证了音频的增益作用，包括利用语音识别驾驶员的受损状态、通过乘客的自然语言指令辅助路径规划，以及在视觉信号模糊时利用音频辨识外部代理的意图。实验结果表明，音频在复杂的语境化场景中能提供关键的安全洞察，特别是当视觉信号不足以支持安全决策时。尽管仍面临环境噪声干扰和隐私保护等挑战，L-LIO 框架为多模态智能驾驶系统的安全干预和决策制定提供了新的技术路径。",
      "categories": [
        "cs.CV",
        "cs.AI",
        "cs.LG",
        "cs.RO"
      ],
      "primary_category": "cs.CV",
      "comment": "",
      "pdf_url": "https://arxiv.org/pdf/2602.07668v1",
      "published_date": "2026-02-07 19:25:02 UTC",
      "updated_date": "2026-02-07 19:25:02 UTC",
      "processing_status": "completed",
      "attempts": 1,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "llm_backup_calls": 0,
      "last_update": "2026-02-16T05:25:39.700188+00:00"
    },
    {
      "arxiv_id": "2602.07666v1",
      "title": "SoK: DARPA's AI Cyber Challenge (AIxCC): Competition Design, Architectures, and Lessons Learned",
      "title_zh": "SoK：DARPA AI Cyber Challenge (AIxCC) 竞赛设计、架构与经验教训总结",
      "authors": [
        "Cen Zhang",
        "Younggi Park",
        "Fabian Fleischer",
        "Yu-Fu Fu",
        "Jiho Kim",
        "Dongkwan Kim",
        "Youngjoon Kim",
        "Qingxiao Xu",
        "Andrew Chin",
        "Ze Sheng",
        "Hanqing Zhao",
        "Brian J. Lee",
        "Joshua Wang",
        "Michael Pelican",
        "David J. Musliner",
        "Jeff Huang",
        "Jon Silliman",
        "Mikel Mcdaniel",
        "Jefferson Casavant",
        "Isaac Goldthwaite",
        "Nicholas Vidovich",
        "Matthew Lehman",
        "Taesoo Kim"
      ],
      "abstract": "DARPA's AI Cyber Challenge (AIxCC, 2023--2025) is the largest competition to date for building fully autonomous cyber reasoning systems (CRSs) that leverage recent advances in AI -- particularly large language models (LLMs) -- to discover and remediate vulnerabilities in real-world open-source software. This paper presents the first systematic analysis of AIxCC. Drawing on design documents, source code, execution traces, and discussions with organizers and competing teams, we examine the competition's structure and key design decisions, characterize the architectural approaches of finalist CRSs, and analyze competition results beyond the final scoreboard. Our analysis reveals the factors that truly drove CRS performance, identifies genuine technical advances achieved by teams, and exposes limitations that remain open for future research. We conclude with lessons for organizing future competitions and broader insights toward deploying autonomous CRSs in practice.",
      "tldr_zh": "这项研究系统地分析了美国国防高级研究计划局（DARPA）发起的AI网络挑战赛（AIxCC），这是迄今为止规模最大的旨在构建全自动网络推理系统（CRSs）的竞赛，其核心是利用大语言模型（LLMs）自动发现并修复真实世界开源软件中的漏洞。通过对竞赛设计、决赛入围系统架构及执行轨迹的深入研究，该论文揭示了驱动网络推理系统性能的关键因素，并总结了参赛团队取得的技术突破。研究进一步识别了当前自动化系统在实际应用中面临的局限性，并为未来组织类似竞赛以及在实践中部署自主化网络推理系统提供了宝贵的经验教训和指导意见。",
      "categories": [
        "cs.CR",
        "cs.AI"
      ],
      "primary_category": "cs.CR",
      "comment": "Version 1.0 (February 2026). Systematization of Knowledge and post-competition analysis of DARPA AIxCC (2023-2025)",
      "pdf_url": "https://arxiv.org/pdf/2602.07666v1",
      "published_date": "2026-02-07 19:21:27 UTC",
      "updated_date": "2026-02-07 19:21:27 UTC",
      "processing_status": "completed",
      "attempts": 1,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "llm_backup_calls": 0,
      "last_update": "2026-02-16T05:25:35.196177+00:00"
    },
    {
      "arxiv_id": "2602.07662v1",
      "title": "ONTrust: A Reference Ontology of Trust",
      "title_zh": "ONTrust：信任参考本体",
      "authors": [
        "Glenda Amaral",
        "Tiago Prince Sales",
        "Riccardo Baratella",
        "Daniele Porello",
        "Renata Guizzardi",
        "Giancarlo Guizzardi"
      ],
      "abstract": "Trust has stood out more than ever in the light of recent innovations. Some examples are advances in artificial intelligence that make machines more and more humanlike, and the introduction of decentralized technologies (e.g. blockchains), which creates new forms of (decentralized) trust. These new developments have the potential to improve the provision of products and services, as well as to contribute to individual and collective well-being. However, their adoption depends largely on trust. In order to build trustworthy systems, along with defining laws, regulations and proper governance models for new forms of trust, it is necessary to properly conceptualize trust, so that it can be understood both by humans and machines. This paper is the culmination of a long-term research program of providing a solid ontological foundation on trust, by creating reference conceptual models to support information modeling, automated reasoning, information integration and semantic interoperability tasks. To address this, a Reference Ontology of Trust (ONTrust) was developed, grounded on the Unified Foundational Ontology and specified in OntoUML, which has been applied in several initiatives, to demonstrate, for example, how it can be used for conceptual modeling and enterprise architecture design, for language evaluation and (re)design, for trust management, for requirements engineering, and for trustworthy artificial intelligence (AI) in the context of affective Human-AI teaming. ONTrust formally characterizes the concept of trust and its different types, describes the different factors that can influence trust, as well as explains how risk emerges from trust relations. To illustrate the working of ONTrust, the ontology is applied to model two case studies extracted from the literature.",
      "tldr_zh": "该研究提出了 ONTrust，一个旨在为信息建模、自动推理和语义互操作性提供坚实基础的信任参考本体（Reference Ontology of Trust）。在人工智能和区块链等新技术对可信系统提出更高要求的背景下，ONTrust 基于统一基础本体（Unified Foundational Ontology, UFO）构建并使用 OntoUML 进行规范化。该本体形式化地定义了信任的概念及其不同类型，详细阐述了影响信任的各类因素，并解释了风险如何从信任关系中产生。ONTrust 已被应用于企业架构设计、需求工程、信任管理以及情感化人机协作中的可信人工智能（Trustworthy AI）等多个领域。通过对文献中两个案例研究的建模分析，该研究证明了该本体在处理复杂信任场景和促进人机共同理解方面的有效性。",
      "categories": [
        "cs.AI"
      ],
      "primary_category": "cs.AI",
      "comment": "46 pages",
      "pdf_url": "https://arxiv.org/pdf/2602.07662v1",
      "published_date": "2026-02-07 18:47:34 UTC",
      "updated_date": "2026-02-07 18:47:34 UTC",
      "processing_status": "completed",
      "attempts": 1,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "llm_backup_calls": 0,
      "last_update": "2026-02-16T05:25:57.305518+00:00"
    },
    {
      "arxiv_id": "2602.07659v1",
      "title": "Continuous Program Search",
      "title_zh": "连续程序搜索",
      "authors": [
        "Matthew Siper",
        "Muhammad Umair Nasir",
        "Ahmed Khalifa",
        "Lisa Soros",
        "Jay Azhang",
        "Julian Togelius"
      ],
      "abstract": "Genetic Programming yields interpretable programs, but small syntactic mutations can induce large, unpredictable behavioral shifts, degrading locality and sample efficiency. We frame this as an operator-design problem: learn a continuous program space where latent distance has behavioral meaning, then design mutation operators that exploit this structure without changing the evolutionary optimizer.\n  We make locality measurable by tracking action-level divergence under controlled latent perturbations, identifying an empirical trust region for behavior-local continuous variation. Using a compact trading-strategy DSL with four semantic components (long/short entry and exit), we learn a matching block-factorized embedding and compare isotropic Gaussian mutation over the full latent space to geometry-compiled mutation that restricts updates to semantically paired entry--exit subspaces and proposes directions using a learned flow-based model trained on logged mutation outcomes.\n  Under identical $(μ+λ)$ evolution strategies and fixed evaluation budgets across five assets, the learned mutation operator discovers strong strategies using an order of magnitude fewer evaluations and achieves the highest median out-of-sample Sharpe ratio. Although isotropic mutation occasionally attains higher peak performance, geometry-compiled mutation yields faster, more reliable progress, demonstrating that semantically aligned mutation can substantially improve search efficiency without modifying the underlying evolutionary algorithm.",
      "tldr_zh": "该研究针对 Genetic Programming 中微小语法突变常导致剧烈且不可预测的行为变化，进而降低局部性(locality)和样本效率的问题，提出了连续程序搜索(Continuous Program Search)框架。作者将此视为算子设计问题，通过学习一个具有行为意义的连续程序空间(continuous program space)，并利用动作级分歧量化局部性以识别行为局部连续变化的经验信任区域。研究采用一种紧凑的交易策略 DSL，对比了各向同性高斯突变与一种限制在语义配对子空间内并利用学习的流模型(flow-based model)建议方向的几何编译突变(geometry-compiled mutation)。实验结果显示，在相同的 $(μ+λ)$ 演化策略下，学习到的突变算子能以少一个数量级的评估次数发现强效策略，并获得最高的中位数样本外夏普比率(Sharpe ratio)。虽然各向同性突变偶尔能达到更高的峰值性能，但几何编译突变在搜索效率和可靠性上表现更优，证明了语义对齐的突变算子能在不修改底层演化算法的情况下显著提升程序搜索性能。",
      "categories": [
        "cs.LG",
        "cs.AI",
        "q-fin.ST"
      ],
      "primary_category": "cs.LG",
      "comment": "",
      "pdf_url": "https://arxiv.org/pdf/2602.07659v1",
      "published_date": "2026-02-07 18:41:14 UTC",
      "updated_date": "2026-02-07 18:41:14 UTC",
      "processing_status": "completed",
      "attempts": 1,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "llm_backup_calls": 0,
      "last_update": "2026-02-16T05:25:49.001404+00:00"
    },
    {
      "arxiv_id": "2602.07652v1",
      "title": "Agent-Fence: Mapping Security Vulnerabilities Across Deep Research Agents",
      "title_zh": "Agent-Fence：深度研究智能体安全漏洞映射",
      "authors": [
        "Sai Puppala",
        "Ismail Hossain",
        "Md Jahangir Alam",
        "Yoonpyo Lee",
        "Jay Yoo",
        "Tanzim Ahad",
        "Syed Bahauddin Alam",
        "Sajedul Talukder"
      ],
      "abstract": "Large language models are increasingly deployed as *deep agents* that plan, maintain persistent state, and invoke external tools, shifting safety failures from unsafe text to unsafe *trajectories*. We introduce **AgentFence**, an architecture-centric security evaluation that defines 14 trust-boundary attack classes spanning planning, memory, retrieval, tool use, and delegation, and detects failures via *trace-auditable conversation breaks* (unauthorized or unsafe tool use, wrong-principal actions, state/objective integrity violations, and attack-linked deviations). Holding the base model fixed, we evaluate eight agent archetypes under persistent multi-turn interaction and observe substantial architectural variation in mean security break rate (MSBR), ranging from $0.29 \\pm 0.04$ (LangGraph) to $0.51 \\pm 0.07$ (AutoGPT). The highest-risk classes are operational: Denial-of-Wallet ($0.62 \\pm 0.08$), Authorization Confusion ($0.54 \\pm 0.10$), Retrieval Poisoning ($0.47 \\pm 0.09$), and Planning Manipulation ($0.44 \\pm 0.11$), while prompt-centric classes remain below $0.20$ under standard settings. Breaks are dominated by boundary violations (SIV 31%, WPA 27%, UTI+UTA 24%, ATD 18%), and authorization confusion correlates with objective and tool hijacking ($ρ\\approx 0.63$ and $ρ\\approx 0.58$). AgentFence reframes agent security around what matters operationally: whether an agent stays within its goal and authority envelope over time.",
      "tldr_zh": "该研究针对大语言模型(LLMs)作为具备规划、持久状态及外部工具调用能力的深度智能体(Deep Agents)在安全性上面临的挑战，指出安全风险已从不安全文本转向不安全轨迹(Trajectories)。为此研究者提出了AgentFence，这是一个以架构为中心的安全性评估框架，定义了涵盖规划、记忆、检索、工具使用和委派等维度的14种信任边界攻击类别(Trust-boundary Attack Classes)。该框架通过可追踪审计的对话中断(Trace-auditable Conversation Breaks)来检测失效行为，包括未经授权的工具使用、状态或目标完整性违规等。在固定基础模型的情况下，研究评估了包括LangGraph和AutoGPT在内的八种智能体原型，发现不同架构的平均安全中断率(MSBR)存在显著差异。实验表明，Denial-of-Wallet、Authorization Confusion、Retrieval Poisoning和Planning Manipulation是风险最高的运营类攻击，而传统的以提示词为中心的攻击类别风险相对较低。AgentFence的研究结果证明，智能体安全性应聚焦于运营层面的合规性，即智能体在长时间跨度内是否能严格保持在其预设目标和授权边界之内。",
      "categories": [
        "cs.CR",
        "cs.AI"
      ],
      "primary_category": "cs.CR",
      "comment": "",
      "pdf_url": "https://arxiv.org/pdf/2602.07652v1",
      "published_date": "2026-02-07 18:27:47 UTC",
      "updated_date": "2026-02-07 18:27:47 UTC",
      "processing_status": "completed",
      "attempts": 1,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "llm_backup_calls": 0,
      "last_update": "2026-02-16T05:25:51.900295+00:00"
    },
    {
      "arxiv_id": "2602.07645v1",
      "title": "From Dead Pixels to Editable Slides: Infographic Reconstruction into Native Google Slides via Vision-Language Region Understanding",
      "title_zh": "从静态像素到可编辑幻灯片：基于视觉-语言区域理解的信息图表原生 Google Slides 重构",
      "authors": [
        "Leonardo Gonzalez"
      ],
      "abstract": "Infographics are widely used to communicate information with a combination of text, icons, and data visualizations, but once exported as images their content is locked into pixels, making updates, localization, and reuse expensive. We describe \\textsc{Images2Slides}, an API-based pipeline that converts a static infographic (PNG/JPG) into a native, editable Google Slides slide by extracting a region-level specification with a vision-language model (VLM), mapping pixel geometry into slide coordinates, and recreating elements using the Google Slides batch update API. The system is model-agnostic and supports multiple VLM backends via a common JSON region schema and deterministic postprocessing. On a controlled benchmark of 29 programmatically generated infographic slides with known ground-truth regions, \\textsc{Images2Slides} achieves an overall element recovery rate of $0.989\\pm0.057$ (text: $0.985\\pm0.083$, images: $1.000\\pm0.000$), with mean text transcription error $\\mathrm{CER}=0.033\\pm0.149$ and mean layout fidelity $\\mathrm{IoU}=0.364\\pm0.161$ for text regions and $0.644\\pm0.131$ for image regions. We also highlight practical engineering challenges in reconstruction, including text size calibration and non-uniform backgrounds, and describe failure modes that guide future work.",
      "tldr_zh": "该研究针对信息图表（Infographics）在导出为图像后内容被锁定为像素、难以编辑和重复利用的问题，提出了 Images2Slides 框架。这是一个基于 API 的流水线，利用视觉语言模型（Vision-Language Model, VLM）提取区域级别的规范信息，将像素几何坐标映射到幻灯片坐标，并通过 Google Slides 批量更新 API 将静态图像还原为原生且可编辑的 Google Slides 文稿。该系统具有模型无关性（model-agnostic），支持多种 VLM 后端，通过通用的 JSON 区域模式和确定性后处理实现元素的精确重建。在包含29个已知真值的基准测试中，Images2Slides 达到了 0.989 的整体元素恢复率，其中图像恢复率达到 1.000，文字转录错误率（CER）低至 0.033。此外，该研究还探讨了重建过程中关于文字大小校准、非均匀背景等实际工程挑战，并分析了失败模式，为未来的信息图表自动化重构研究提供了参考。",
      "categories": [
        "cs.CV",
        "cs.AI"
      ],
      "primary_category": "cs.CV",
      "comment": "Accepted for publication in the Companion Proceedings of the ACM Web Conference 2026 (WWW Companion '26), April 13-17, 2026, Dubai, United Arab Emirates",
      "pdf_url": "https://arxiv.org/pdf/2602.07645v1",
      "published_date": "2026-02-07 17:58:17 UTC",
      "updated_date": "2026-02-07 17:58:17 UTC",
      "processing_status": "completed",
      "attempts": 1,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "llm_backup_calls": 0,
      "last_update": "2026-02-16T05:25:56.407053+00:00"
    },
    {
      "arxiv_id": "2602.07642v1",
      "title": "Efficient Table Retrieval and Understanding with Multimodal Large Language Models",
      "title_zh": "基于多模态大语言模型的高效表格检索与理解",
      "authors": [
        "Zhuoyan Xu",
        "Haoyang Fang",
        "Boran Han",
        "Bonan Min",
        "Bernie Wang",
        "Cuixiong Hu",
        "Shuai Zhang"
      ],
      "abstract": "Tabular data is frequently captured in image form across a wide range of real-world scenarios such as financial reports, handwritten records, and document scans. These visual representations pose unique challenges for machine understanding, as they combine both structural and visual complexities. While recent advances in Multimodal Large Language Models (MLLMs) show promising results in table understanding, they typically assume the relevant table is readily available. However, a more practical scenario involves identifying and reasoning over relevant tables from large-scale collections to answer user queries. To address this gap, we propose TabRAG, a framework that enables MLLMs to answer queries over large collections of table images. Our approach first retrieves candidate tables using jointly trained visual-text foundation models, then leverages MLLMs to perform fine-grained reranking of these candidates, and finally employs MLLMs to reason over the selected tables for answer generation. Through extensive experiments on a newly constructed dataset comprising 88,161 training and 9,819 testing samples across 8 benchmarks with 48,504 unique tables, we demonstrate that our framework significantly outperforms existing methods by 7.0% in retrieval recall and 6.1% in answer accuracy, offering a practical solution for real-world table understanding tasks.",
      "tldr_zh": "该研究针对现实场景中以图像形式存在的大规模表格数据处理难题，提出了 TabRAG 框架，旨在利用多模态大语言模型 (Multimodal Large Language Models) 实现高效的表格检索与理解。该框架首先利用联合训练的视觉文本基础模型 (visual-text foundation models) 从海量表格图像中检索出候选表格。随后，TabRAG 通过多模态大语言模型对候选表格进行精细化的重排序 (fine-grained reranking)，并最终引导模型基于选定的表格进行推理以生成答案。研究团队为此构建了一个包含 48,504 个唯一表格的大型数据集，并在 8 个基准测试上进行了广泛实验。实验结果表明，该框架在检索召回率 (retrieval recall) 上提升了 7.0%，在回答准确率 (answer accuracy) 上提升了 6.1%。这一成果为解决现实世界中复杂的表格检索与推理任务提供了一种兼具实用性与高性能的解决方案。",
      "categories": [
        "cs.AI",
        "cs.LG"
      ],
      "primary_category": "cs.AI",
      "comment": "Published at EACL 2026 Findings",
      "pdf_url": "https://arxiv.org/pdf/2602.07642v1",
      "published_date": "2026-02-07 17:50:33 UTC",
      "updated_date": "2026-02-07 17:50:33 UTC",
      "processing_status": "completed",
      "attempts": 1,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "llm_backup_calls": 0,
      "last_update": "2026-02-16T05:26:02.013533+00:00"
    },
    {
      "arxiv_id": "2602.07628v1",
      "title": "SleepMaMi: A Universal Sleep Foundation Model for Integrating Macro- and Micro-structures",
      "title_zh": "SleepMaMi：融合宏观与微观结构的通用睡眠基座模型",
      "authors": [
        "Keondo Park",
        "Younghoon Na",
        "Yourim Choi",
        "Hyunwoo Ryu",
        "Hyun-Woo Shin",
        "Hyung-Sin Kim"
      ],
      "abstract": "While the shift toward unified foundation models has revolutionized many deep learning domains, sleep medicine remains largely restricted to task-specific models that focus on localized micro-structure features. These approaches often neglect the rich, multi-modal context of Polysomnography (PSG) and fail to capture the global macro-structure of a full night's sleep. To address this, we introduce SleepMaMi , a Sleep Foundation Model engineered to master both hour-long sleep architectures and fine-grained signal morphologies. Our framework utilizes a hierarchical dual-encoder design: a Macro-Encoder to model full-night temporal dependencies and a Micro-Encoder to capture short-term characteristics from biosignals. Macro-Encoder is trained via Demographic-Guided Contrastive Learning, which aligns overnight sleep patterns with objective subject metadata, such as age, sex and BMI to refine global representations. Micro-Encoder is optimized via a hybrid Masked Autoencoder (MAE) and multi-modal contrastive objective. Pre-trained on a massive corpus of $>$20,000 PSG recordings (158K hours),SleepMaMi outperforms existing foundation models across a diverse suite of downstream tasks, demonstrating superior generalizability and label-efficient adaptation for clinical sleep analysis.",
      "tldr_zh": "该研究提出了SleepMaMi，一种通用的睡眠基础模型(Foundation Model)，旨在整合多模态多导睡眠监测(PSG)中的宏观与微观结构。该框架采用层次化双编码器设计，其中Macro-Encoder通过人口统计学引导的对比学习(Demographic-Guided Contrastive Learning)将全晚睡眠模式与年龄、性别和BMI等元数据对齐，而Micro-Encoder则利用混合掩码自编码器(MAE)和多模态对比目标捕捉短期信号特征。SleepMaMi在包含超过20,000份PSG记录（约15.8万小时）的大规模数据集上进行了预训练。实验结果表明，该模型在多种下游任务中均优于现有的基础模型，展现了卓越的泛化能力。该研究为临床睡眠分析提供了标签高效的适应方案，证明了统一基础模型在睡眠医学领域的巨大潜力。",
      "categories": [
        "cs.AI",
        "cs.LG"
      ],
      "primary_category": "cs.AI",
      "comment": "8 pages, Appendix 9 pages",
      "pdf_url": "https://arxiv.org/pdf/2602.07628v1",
      "published_date": "2026-02-07 17:17:45 UTC",
      "updated_date": "2026-02-07 17:17:45 UTC",
      "processing_status": "completed",
      "attempts": 1,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "llm_backup_calls": 0,
      "last_update": "2026-02-16T05:26:13.301773+00:00"
    },
    {
      "arxiv_id": "2602.07625v1",
      "title": "AD-MIR: Bridging the Gap from Perception to Persuasion in Advertising Video Understanding via Structured Reasoning",
      "title_zh": "AD-MIR：通过结构化推理弥合广告视频理解中从感知到说服的鸿沟",
      "authors": [
        "Binxiao Xu",
        "Junyu Feng",
        "Xiaopeng Lin",
        "Haodong Li",
        "Zhiyuan Feng",
        "Bohan Zeng",
        "Shaolin Lu",
        "Ming Lu",
        "Qi She",
        "Wentao Zhang"
      ],
      "abstract": "Multimodal understanding of advertising videos is essential for interpreting the intricate relationship between visual storytelling and abstract persuasion strategies. However, despite excelling at general search, existing agents often struggle to bridge the cognitive gap between pixel-level perception and high-level marketing logic. To address this challenge, we introduce AD-MIR, a framework designed to decode advertising intent via a two-stage architecture. First, in the Structure-Aware Memory Construction phase, the system converts raw video into a structured database by integrating semantic retrieval with exact keyword matching. This approach prioritizes fine-grained brand details (e.g., logos, on-screen text) while dynamically filtering out irrelevant background noise to isolate key protagonists. Second, the Structured Reasoning Agent mimics a marketing expert through an iterative inquiry loop, decomposing the narrative to deduce implicit persuasion tactics. Crucially, it employs an evidence-based self-correction mechanism that rigorously validates these insights against specific video frames, automatically backtracking when visual support is lacking. Evaluation on the AdsQA benchmark demonstrates that AD-MIR achieves state-of-the-art performance, surpassing the strongest general-purpose agent, DVD, by 1.8% in strict and 9.5% in relaxed accuracy. These results underscore that effective advertising understanding demands explicitly grounding abstract marketing strategies in pixel-level evidence. The code is available at https://github.com/Little-Fridge/AD-MIR.",
      "tldr_zh": "该研究提出了 AD-MIR 框架，旨在弥合广告视频理解中从像素级感知到高层营销逻辑之间的认知鸿沟。该框架采用两阶段架构，首先通过结构感知内存构建 (Structure-Aware Memory Construction) 阶段，结合语义检索和精确关键词匹配将原始视频转换为结构化数据库，重点提取品牌细节并过滤无关背景噪声。随后，结构化推理智能体 (Structured Reasoning Agent) 通过迭代查询循环模拟营销专家，拆解叙事以推断隐含的劝说策略。该智能体引入了基于证据的自我纠正机制 (self-correction mechanism)，通过严格验证视觉支撑确保推理的准确性，并在缺乏支持时自动回溯。在 AdsQA 基准测试上的实验表明，AD-MIR 达到了目前的最先进水平 (SOTA)，在准确率上显著超越了最强的通用智能体 DVD。这项工作强调了将抽象营销策略明确锚定在像素级证据对于深层视频理解的重要性。",
      "categories": [
        "cs.CV",
        "cs.AI"
      ],
      "primary_category": "cs.CV",
      "comment": "",
      "pdf_url": "https://arxiv.org/pdf/2602.07625v1",
      "published_date": "2026-02-07 17:14:06 UTC",
      "updated_date": "2026-02-07 17:14:06 UTC",
      "processing_status": "completed",
      "attempts": 1,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "llm_backup_calls": 0,
      "last_update": "2026-02-16T05:26:35.407862+00:00"
    },
    {
      "arxiv_id": "2602.07624v1",
      "title": "M2A: Multimodal Memory Agent with Dual-Layer Hybrid Memory for Long-Term Personalized Interactions",
      "title_zh": "M2A：具有双层混合记忆的长期个性化交互多模态记忆智能体",
      "authors": [
        "Junyu Feng",
        "Binxiao Xu",
        "Jiayi Chen",
        "Mengyu Dai",
        "Cenyang Wu",
        "Haodong Li",
        "Bohan Zeng",
        "Yunliu Xie",
        "Hao Liang",
        "Ming Lu",
        "Wentao Zhang"
      ],
      "abstract": "This work addresses the challenge of personalized question answering in long-term human-machine interactions: when conversational history spans weeks or months and exceeds the context window, existing personalization mechanisms struggle to continuously absorb and leverage users' incremental concepts, aliases, and preferences. Current personalized multimodal models are predominantly static-concepts are fixed at initialization and cannot evolve during interactions. We propose M2A, an agentic dual-layer hybrid memory system that maintains personalized multimodal information through online updates. The system employs two collaborative agents: ChatAgent manages user interactions and autonomously decides when to query or update memory, while MemoryManager breaks down memory requests from ChatAgent into detailed operations on the dual-layer memory bank, which couples a RawMessageStore (immutable conversation log) with a SemanticMemoryStore (high-level observations), providing memories at different granularities. In addition, we develop a reusable data synthesis pipeline that injects concept-grounded sessions from Yo'LLaVA and MC-LLaVA into LoCoMo long conversations while preserving temporal coherence. Experiments show that M2A significantly outperforms baselines, demonstrating that transforming personalization from one-shot configuration to a co-evolving memory mechanism provides a viable path for high-quality individualized responses in long-term multimodal interactions. The code is available at https://github.com/Little-Fridge/M2A.",
      "tldr_zh": "该研究针对长期人机交互中个性化问答的挑战，即当对话历史跨度较长且超出上下文窗口时，现有模型难以持续吸收并利用用户递增的概念、别名和偏好，提出了具有双层混合记忆（Dual-Layer Hybrid Memory）的多模态记忆智能体 M2A。该系统由负责管理交互并自主决策记忆调度的 ChatAgent 和将请求分解为具体存储操作的 MemoryManager 协作组成，实现了个性化信息的在线更新。其核心存储架构结合了保留原始对话日志的 RawMessageStore 和存储高层观察结果的 SemanticMemoryStore，以提供不同粒度的记忆支持。此外，研究团队开发了一套可重用的数据合成流水线，通过将概念驱动的会话注入长对话数据中来确保时序连贯性。实验结果表明，M2A 的性能显著优于基线模型，证明了将个性化从静态配置转变为与用户共同演化的记忆机制是实现高质量、长周期个性化多模态互动的有效路径。",
      "categories": [
        "cs.AI"
      ],
      "primary_category": "cs.AI",
      "comment": "",
      "pdf_url": "https://arxiv.org/pdf/2602.07624v1",
      "published_date": "2026-02-07 17:13:56 UTC",
      "updated_date": "2026-02-07 17:13:56 UTC",
      "processing_status": "completed",
      "attempts": 1,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "llm_backup_calls": 0,
      "last_update": "2026-02-16T05:26:31.316661+00:00"
    },
    {
      "arxiv_id": "2602.07616v1",
      "title": "SERE: Similarity-based Expert Re-routing for Efficient Batch Decoding in MoE Models",
      "title_zh": "SERE：MoE 模型中基于相似度的专家重路由高效批处理解码方法",
      "authors": [
        "Juntong Wu",
        "Jialiang Cheng",
        "Fuyu Lv",
        "Ou Dan",
        "Li Yuan"
      ],
      "abstract": "Mixture-of-Experts (MoE) architectures employ sparse activation to deliver faster training and inference with higher accuracy than dense LLMs. However, in production serving, MoE models require batch inference to optimize hardware efficiency, which may cause excessive expert activation and thus slow the memory-bound decoding stage. To address the fundamental tension between batch decoding and expert sparsity, we present SERE, a Similarity-based Expert Re-routing method for Efficient batch decoding in MoE models. SERE dynamically reduces the number of active experts in an input-aware manner by re-routing tokens from secondary experts to their most similar primary counterparts. It also leverages similarity patterns to identify and preserve critical experts, thereby preventing capability loss. Notably, SERE avoids static expert pruning or merging, instead enabling dynamic expert skipping based on batch-level expert redundancy. Additionally, we provide an efficient custom CUDA kernel for SERE, enabling plug-and-play use in vLLM with only a single-line code change. Extensive experiments on various complex reasoning benchmarks demonstrate that SERE achieves up to 2.0x speedup with minimal quality loss, providing a practical solution for cost-efficient and latency-sensitive large-scale MoE deployment. Code implementation of SERE can be found in https://github.com/JL-Cheng/SERE.",
      "tldr_zh": "该研究针对 Mixture-of-Experts (MoE) 架构在批量推理(Batch Inference)过程中因激活过多专家(Experts)而导致内存受限解码阶段变慢的问题，提出了 SERE（基于相似度的专家重新路由方法）。SERE 通过将 Token 从辅助专家重新路由到最相似的主专家，以输入感知的方式动态减少活跃专家的数量。该方法利用相似性模式识别并保留关键专家，有效防止了模型能力的损失，且无需进行静态的专家剪枝或合并。研究还开发了高效的定制 CUDA kernel，使得该方案能够在 vLLM 框架中实现即插即用的简易集成。实验结果表明，SERE 在多个复杂推理基准测试中实现了高达 2.0 倍的加速，且性能损失极小，为低延迟、高性价比的大规模 MoE 模型部署提供了实用的解决方案。",
      "categories": [
        "cs.LG",
        "cs.AI"
      ],
      "primary_category": "cs.LG",
      "comment": "Published as a conference paper at ICLR 2026",
      "pdf_url": "https://arxiv.org/pdf/2602.07616v1",
      "published_date": "2026-02-07 16:51:16 UTC",
      "updated_date": "2026-02-07 16:51:16 UTC",
      "processing_status": "completed",
      "attempts": 1,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "llm_backup_calls": 0,
      "last_update": "2026-02-16T05:26:35.009330+00:00"
    },
    {
      "arxiv_id": "2602.07609v1",
      "title": "Evaluating Large Language Models for Detecting Architectural Decision Violations",
      "title_zh": "评估大语言模型在架构决策违规检测中的效能",
      "authors": [
        "Ruoyu Su",
        "Alexander Bakhtin",
        "Noman Ahmad",
        "Matteo Esposito",
        "Valentina Lenarduzzi",
        "Davide Taibi"
      ],
      "abstract": "Architectural Decision Records (ADRs) play a central role in maintaining software architecture quality, yet many decision violations go unnoticed because projects lack both systematic documentation and automated detection mechanisms. Recent advances in Large Language Models (LLMs) open up new possibilities for automating architectural reasoning at scale. We investigated how effectively LLMs can identify decision violations in open-source systems by examining their agreement, accuracy, and inherent limitations. Our study analyzed 980 ADRs across 109 GitHub repositories using a multi-model pipeline in which one LLM primary screens potential decision violations, and three additional LLMs independently validate the reasoning. We assessed agreement, accuracy, precision, and recall, and complemented the quantitative findings with expert evaluation. The models achieved substantial agreement and strong accuracy for explicit, code-inferable decisions. Accuracy falls short for implicit or deployment-oriented decisions that depend on deployment configuration or organizational knowledge. Therefore, LLMs can meaningfully support validation of architectural decision compliance; however, they are not yet replacing human expertise for decisions not focused on code.",
      "tldr_zh": "该研究探讨了大型语言模型（LLMs）在自动检测软件架构决策违规（Architectural Decision Violations）方面的有效性，旨在解决软件项目中因缺乏系统文档和自动化手段而导致的架构质量监控难题。研究团队分析了109个GitHub代码库中的980份Architectural Decision Records（ADRs），并构建了一个由单个LLM进行初步筛选、多个LLM独立验证推理的自动化流水线。通过对Agreement、Accuracy、Precision和Recall等指标的定量分析结合专家评估，研究深入揭示了LLMs在架构合规性检测中的潜力与局限。实验结果显示，LLMs在识别显式且可从代码推断的决策（code-inferable decisions）时表现出极高的准确性，但在处理依赖部署配置或组织背景知识的隐式决策时准确率明显下降。该研究证明了LLMs可以为架构决策合规性验证提供显著的自动化支持，但也强调了在涉及非代码维度的复杂决策时，人类专家的专业知识依然不可或缺。",
      "categories": [
        "cs.SE",
        "cs.AI"
      ],
      "primary_category": "cs.SE",
      "comment": "",
      "pdf_url": "https://arxiv.org/pdf/2602.07609v1",
      "published_date": "2026-02-07 16:36:14 UTC",
      "updated_date": "2026-02-07 16:36:14 UTC",
      "processing_status": "completed",
      "attempts": 1,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "llm_backup_calls": 0,
      "last_update": "2026-02-16T05:26:37.903746+00:00"
    },
    {
      "arxiv_id": "2602.07605v2",
      "title": "Fine-R1: Make Multi-modal LLMs Excel in Fine-Grained Visual Recognition by Chain-of-Thought Reasoning",
      "title_zh": "Fine-R1：通过链式思维推理提升多模态大语言模型的细粒度视觉识别能力",
      "authors": [
        "Hulingxiao He",
        "Zijun Geng",
        "Yuxin Peng"
      ],
      "abstract": "Any entity in the visual world can be hierarchically grouped based on shared characteristics and mapped to fine-grained sub-categories. While Multi-modal Large Language Models (MLLMs) achieve strong performance on coarse-grained visual tasks, they often struggle with Fine-Grained Visual Recognition (FGVR). Adapting general-purpose MLLMs to FGVR typically requires large amounts of annotated data, which is costly to obtain, leaving a substantial performance gap compared to contrastive CLIP models dedicated for discriminative tasks. Moreover, MLLMs tend to overfit to seen sub-categories and generalize poorly to unseen ones. To address these challenges, we propose Fine-R1, an MLLM tailored for FGVR through an R1-style training framework: (1) Chain-of-Thought Supervised Fine-tuning, where we construct a high-quality FGVR CoT dataset with rationales of \"visual analysis, candidate sub-categories, comparison, and prediction\", transition the model into a strong open-world classifier; and (2) Triplet Augmented Policy Optimization, where Intra-class Augmentation mixes trajectories from anchor and positive images within the same category to improve robustness to intra-class variance, while Inter-class Augmentation maximizes the response distinction conditioned on images across sub-categories to enhance discriminative ability. With only 4-shot training, Fine-R1 outperforms existing general MLLMs, reasoning MLLMs, and even contrastive CLIP models in identifying both seen and unseen sub-categories, showing promise in working in knowledge-intensive domains where gathering expert annotations for all sub-categories is arduous. Code is available at https://github.com/PKU-ICST-MIPL/FineR1_ICLR2026.",
      "tldr_zh": "该研究提出了Fine-R1，一种专为提升多模态大语言模型（MLLMs）在细粒度视觉识别（FGVR）领域表现而设计的R1风格训练框架。针对MLLMs在FGVR中面临的标注数据昂贵、易过拟合及泛化性差等挑战，Fine-R1通过链式思维有监督微调（Chain-of-Thought Supervised Fine-tuning）构建了包含视觉分析、对比与预测的高质量数据集，使模型具备了强大的推理能力。同时，研究引入了三元组增强策略优化（Triplet Augmented Policy Optimization），利用类内增强提升鲁棒性，并通过类间增强最大化子类间的区分度。实验表明，Fine-R1仅需4-shot训练即可在已知和未见子类别的识别上显著超越现有的推理型MLLMs及对比学习模型CLIP。这一成果证明了该模型在缺乏专家标注的知识密集型任务中具有极高的应用价值。",
      "categories": [
        "cs.CV",
        "cs.AI"
      ],
      "primary_category": "cs.CV",
      "comment": "Published as a conference paper at ICLR 2026. The models are available at https://huggingface.co/collections/StevenHH2000/fine-r1",
      "pdf_url": "https://arxiv.org/pdf/2602.07605v2",
      "published_date": "2026-02-07 16:16:51 UTC",
      "updated_date": "2026-02-10 04:29:03 UTC",
      "processing_status": "completed",
      "attempts": 1,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "llm_backup_calls": 0,
      "last_update": "2026-02-16T05:26:39.302035+00:00"
    },
    {
      "arxiv_id": "2602.07596v1",
      "title": "Astro: Activation-guided Structured Regularization for Outlier-Robust LLM Post-Training Quantization",
      "title_zh": "Astro：面向抗离群值大语言模型训练后量化的激活引导结构化正则化",
      "authors": [
        "Xi Chen",
        "Ming Li",
        "Junxi Li",
        "Changsheng Li",
        "Peisong Wang",
        "Lizhong Ding",
        "Ye Yuan",
        "Guoren Wang"
      ],
      "abstract": "Weight-only post-training quantization (PTQ) is crucial for efficient Large Language Model (LLM) deployment but suffers from accuracy degradation caused by weight and activation outliers. Existing mitigation strategies often face critical limitations: they either yield insufficient outlier suppression or incur significant deployment inefficiencies, such as inference latency, heavy preprocessing, or reliance on complex operator fusion. To resolve these limitations, we leverage a key insight: over-parameterized LLMs often converge to Flat Minima, implying a vast equivalent solution space where weights can be adjusted without compromising accuracy. Building on this, we propose Astro, an Activation-guided Structured Regularization framework designed to suppress the negative effects of outliers in a hardware-friendly and efficient manner. Leveraging the activation-guided regularization objective, Astro actively reconstructs intrinsically robust weights, aggressively suppressing weight outliers corresponding to high-magnitude activations without sacrificing model accuracy. Crucially, Astro introduces zero inference latency and is orthogonal to mainstream quantization methods like GPTQ. Extensive experiments show that Astro achieves highly competitive performance; notably, on LLaMA-2-7B, it achieves better performance than complex learning-based rotation methods with almost 1/3 of the quantization time.",
      "tldr_zh": "该研究提出了Astro，一种基于激活引导的结构化正则化(Activation-guided Structured Regularization)框架，旨在解决大语言模型(LLMs)仅权重量化(Weight-only PTQ)中由权重和激活离群值导致的精度损失。研究者利用大模型收敛于平坦极小值(Flat Minima)的特性，即权重可以在不影响精度的空间内进行调整，提出了通过正则化目标重构鲁棒权重的方法。Astro能够针对性地抑制与高幅值激活相关的权重离群值，且不会引入额外的推理延迟。作为一种通用的优化策略，它与GPTQ等主流量化方案具有良好的正交兼容性。实验数据证明，Astro在性能上极具竞争力，在LLaMA-2-7B上的量化耗时仅为复杂学习旋转方法的约三分之一，同时实现了更优的准确率。该方法有效解决了现有离群值抑制技术中部署效率低或预处理沉重的问题，为实现硬件友好且高效的大模型部署提供了新方案。",
      "categories": [
        "cs.LG",
        "cs.AI"
      ],
      "primary_category": "cs.LG",
      "comment": "",
      "pdf_url": "https://arxiv.org/pdf/2602.07596v1",
      "published_date": "2026-02-07 15:50:18 UTC",
      "updated_date": "2026-02-07 15:50:18 UTC",
      "processing_status": "completed",
      "attempts": 1,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "llm_backup_calls": 0,
      "last_update": "2026-02-16T05:26:52.238834+00:00"
    },
    {
      "arxiv_id": "2602.07595v1",
      "title": "TeleBoost: A Systematic Alignment Framework for High-Fidelity, Controllable, and Robust Video Generation",
      "title_zh": "TeleBoost：面向高保真、可控及鲁棒视频生成的系统化对齐框架",
      "authors": [
        "Yuanzhi Liang",
        "Xuan'er Wu",
        "Yirui Liu",
        "Yijie Fang",
        "Yizhen Fan",
        "Ke Hao",
        "Rui Li",
        "Ruiying Liu",
        "Ziqi Ni",
        "Peng Yu",
        "Yanbo Wang",
        "Haibin Huang",
        "Qizhen Weng",
        "Chi Zhang",
        "Xuelong Li"
      ],
      "abstract": "Post-training is the decisive step for converting a pretrained video generator into a production-oriented model that is instruction-following, controllable, and robust over long temporal horizons. This report presents a systematical post-training framework that organizes supervised policy shaping, reward-driven reinforcement learning, and preference-based refinement into a single stability-constrained optimization stack. The framework is designed around practical video-generation constraints, including high rollout cost, temporally compounding failure modes, and feedback that is heterogeneous, uncertain, and often weakly discriminative. By treating optimization as a staged, diagnostic-driven process rather than a collection of isolated tricks, the report summarizes a cohesive recipe for improving perceptual fidelity, temporal coherence, and prompt adherence while preserving the controllability established at initialization. The resulting framework provides a clear blueprint for building scalable post-training pipelines that remain stable, extensible, and effective in real-world deployment settings.",
      "tldr_zh": "该研究提出了TeleBoost，这是一个系统的后训练(Post-training)对齐框架，旨在将预训练视频生成模型转化为具有高保真度、可控性和长时稳健性的生产导向模型。该框架通过单一的稳定性约束优化栈，将有监督策略整形(Supervised policy shaping)、奖励驱动的强化学习(Reward-driven reinforcement learning)和基于偏好的精炼(Preference-based refinement)有机结合。针对视频生成中高昂的推理成本、随时间累积的失败模式以及反馈信息的异构性与不确定性，TeleBoost将优化视为一个阶段性的诊断驱动过程。通过该方案，模型在显著提升感知保真度(Perceptual fidelity)、时序一致性(Temporal coherence)和提示词遵循能力(Prompt adherence)的同时，有效保留了初始的可控性。该研究为构建可扩展、稳定且适用于真实部署环境的视频生成后训练管线提供了清晰的蓝图。",
      "categories": [
        "cs.CV",
        "cs.AI"
      ],
      "primary_category": "cs.CV",
      "comment": "",
      "pdf_url": "https://arxiv.org/pdf/2602.07595v1",
      "published_date": "2026-02-07 15:49:25 UTC",
      "updated_date": "2026-02-07 15:49:25 UTC",
      "processing_status": "completed",
      "attempts": 1,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "llm_backup_calls": 0,
      "last_update": "2026-02-16T05:26:53.805605+00:00"
    },
    {
      "arxiv_id": "2602.07594v1",
      "title": "Learning to Self-Verify Makes Language Models Better Reasoners",
      "title_zh": "学会自我验证让大语言模型成为更出色的推理者",
      "authors": [
        "Yuxin Chen",
        "Yu Wang",
        "Yi Zhang",
        "Ziang Ye",
        "Zhengzhou Cai",
        "Yaorui Shi",
        "Qi Gu",
        "Hui Su",
        "Xunliang Cai",
        "Xiang Wang",
        "An Zhang",
        "Tat-Seng Chua"
      ],
      "abstract": "Recent large language models (LLMs) achieve strong performance in generating promising reasoning paths for complex tasks. However, despite powerful generation ability, LLMs remain weak at verifying their own answers, revealing a persistent capability asymmetry between generation and self-verification. In this work, we conduct an in-depth investigation of this asymmetry throughout training evolution and show that, even on the same task, improving generation does not lead to corresponding improvements in self-verification. Interestingly, we find that the reverse direction of this asymmetry behaves differently: learning to self-verify can effectively improve generation performance, achieving accuracy comparable to standard generation training while yielding more efficient and effective reasoning traces. Building on this observation, we further explore integrating self-verification into generation training by formulating a multi-task reinforcement learning framework, where generation and self-verification are optimized as two independent but complementary objectives. Extensive experiments across benchmarks and models demonstrate performance gains over generation-only training in both generation and verification capabilities.",
      "tldr_zh": "这项研究探讨了大语言模型(LLMs)在生成复杂任务推理路径与自我验证能力之间存在的不对称性，指出生成能力的提升并不必然增强验证能力。通过深入调查训练演变过程，研究发现学习自我验证(Self-Verify)反而能有效提升生成表现，其准确率与标准生成训练相当，且能产生更高效的推理轨迹。基于此发现，研究提出了一个多任务强化学习(Multi-task Reinforcement Learning)框架，将生成和自我验证作为两个独立且互补的目标进行同步优化。实验结果表明，该方法在多个基准测试和模型上均显著提升了LLMs的生成与验证能力，为解决模型推理过程中的能力不对称问题提供了新思路。",
      "categories": [
        "cs.CL",
        "cs.AI"
      ],
      "primary_category": "cs.CL",
      "comment": "",
      "pdf_url": "https://arxiv.org/pdf/2602.07594v1",
      "published_date": "2026-02-07 15:49:06 UTC",
      "updated_date": "2026-02-07 15:49:06 UTC",
      "processing_status": "completed",
      "attempts": 1,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "llm_backup_calls": 0,
      "last_update": "2026-02-16T05:26:51.396152+00:00"
    },
    {
      "arxiv_id": "2602.07590v1",
      "title": "Automated rock joint trace mapping using a supervised learning model trained on synthetic data generated by parametric modelling",
      "title_zh": "基于参数化建模合成数据训练监督学习模型的自动化岩石节理迹线提取",
      "authors": [
        "Jessica Ka Yi Chiu",
        "Tom Frode Hansen",
        "Eivind Magnus Paulsen",
        "Ole Jakob Mengshoel"
      ],
      "abstract": "This paper presents a geology-driven machine learning method for automated rock joint trace mapping from images. The approach combines geological modelling, synthetic data generation, and supervised image segmentation to address limited real data and class imbalance. First, discrete fracture network models are used to generate synthetic jointed rock images at field-relevant scales via parametric modelling, preserving joint persistence, connectivity, and node-type distributions. Second, segmentation models are trained using mixed training and pretraining followed by fine-tuning on real images. The method is tested in box and slope domains using several real datasets. The results show that synthetic data can support supervised joint trace detection when real data are scarce. Mixed training performs well when real labels are consistent (e.g. box-domain), while fine-tuning is more robust when labels are noisy (e.g. slope-domain where labels can be biased, incomplete, and inconsistent). Fully zero-shot prediction from synthetic model remains limited, but useful generalisation is achieved by fine-tuning with a small number of real data. Qualitative analysis shows clearer and more geologically meaningful joint traces than indicated by quantitative metrics alone. The proposed method supports reliable joint mapping and provides a basis for further work on domain adaptation and evaluation.",
      "tldr_zh": "该研究提出了一种地质驱动的机器学习方法，用于从图像中自动进行岩石节理迹线制图(rock joint trace mapping)。针对真实数据有限和类别不平衡的问题，研究首先利用离散裂隙网络(discrete fracture network)模型通过参数化建模生成具有地质特征的合成数据。随后，研究采用混合训练和预训练后微调(fine-tuning)的监督图像分割模型，并在箱体和边坡领域的多组真实数据集上进行了测试。结果表明，在真实数据匮乏时，合成数据能有效支持节理迹线检测，且微调策略在处理噪声标签时表现出更强的鲁棒性。尽管完全的零样本(zero-shot)预测仍有局限，但通过少量真实数据微调即可实现有效的泛化。定性分析显示，该方法生成的节理迹线比单纯的定量指标更具地质意义，为可靠的节理制图及后续的领域自适应研究奠定了基础。",
      "categories": [
        "cs.CV",
        "cs.AI",
        "cs.LG"
      ],
      "primary_category": "cs.CV",
      "comment": "35 pages, 12 figures, 2 appendices",
      "pdf_url": "https://arxiv.org/pdf/2602.07590v1",
      "published_date": "2026-02-07 15:37:02 UTC",
      "updated_date": "2026-02-07 15:37:02 UTC",
      "processing_status": "completed",
      "attempts": 1,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "llm_backup_calls": 0,
      "last_update": "2026-02-16T05:26:56.300827+00:00"
    },
    {
      "arxiv_id": "2602.07573v1",
      "title": "Graph Domain Adaptation via Homophily-Agnostic Reconstructing Structure",
      "title_zh": "基于同质性无关结构重构的图域自适应",
      "authors": [
        "Ruiyi Fang",
        "Shuo Wang",
        "Ruizhi Pu",
        "Qiuhao Zeng",
        "Hao Zheng",
        "Ziyan Wang",
        "Jiale Cai",
        "Zhimin Mei",
        "Song Tang",
        "Charles Ling",
        "Boyu Wang"
      ],
      "abstract": "Graph Domain Adaptation (GDA) transfers knowledge from labeled source graphs to unlabeled target graphs, addressing the challenge of label scarcity. However, existing GDA methods typically assume that both source and target graphs exhibit homophily, leading existing methods to perform poorly when heterophily is present. Furthermore, the lack of labels in the target graph makes it impossible to assess its homophily level beforehand. To address this challenge, we propose a novel homophily-agnostic approach that effectively transfers knowledge between graphs with varying degrees of homophily. Specifically, we adopt a divide-and-conquer strategy that first separately reconstructs highly homophilic and heterophilic variants of both the source and target graphs, and then performs knowledge alignment separately between corresponding graph variants. Extensive experiments conducted on five benchmark datasets demonstrate the superior performance of our approach, particularly highlighting its substantial advantages on heterophilic graphs.",
      "tldr_zh": "该研究针对图域自适应(Graph Domain Adaptation)中现有方法过度依赖同质性(homophily)假设，导致在异质性(heterophily)场景下表现不佳的问题，提出了一种同质性无关(homophily-agnostic)的结构重构方法。针对目标图同质性水平由于缺乏标签而难以预先评估的挑战，该方案采用了分而治之(divide-and-conquer)策略，首先分别重构出源图和目标图的高同质化与高异质化变体。通过在对应的图变体之间进行专门的知识对齐(knowledge alignment)，该方法能够实现在不同性质图之间更有效的知识迁移。在五个基准数据集上的实验结果证明了该方法的优越性，尤其是在处理异质图时展现出了显著的技术优势。",
      "categories": [
        "cs.SI",
        "cs.AI"
      ],
      "primary_category": "cs.SI",
      "comment": "Accept by AAAI2026(oral)",
      "pdf_url": "https://arxiv.org/pdf/2602.07573v1",
      "published_date": "2026-02-07 14:40:49 UTC",
      "updated_date": "2026-02-07 14:40:49 UTC",
      "processing_status": "completed",
      "attempts": 1,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "llm_backup_calls": 0,
      "last_update": "2026-02-16T05:27:02.213504+00:00"
    },
    {
      "arxiv_id": "2602.07570v1",
      "title": "How does longer temporal context enhance multimodal narrative video processing in the brain?",
      "title_zh": "长时程上下文如何增强大脑对多模态叙事视频的处理？",
      "authors": [
        "Prachi Jindal",
        "Anant Khandelwal",
        "Manish Gupta",
        "Bapi S. Raju",
        "Subba Reddy Oota",
        "Tanmoy Chakraborty"
      ],
      "abstract": "Understanding how humans and artificial intelligence systems process complex narrative videos is a fundamental challenge at the intersection of neuroscience and machine learning. This study investigates how the temporal context length of video clips (3--12 s clips) and the narrative-task prompting shape brain-model alignment during naturalistic movie watching. Using fMRI recordings from participants viewing full-length movies, we examine how brain regions sensitive to narrative context dynamically represent information over varying timescales and how these neural patterns align with model-derived features. We find that increasing clip duration substantially improves brain alignment for multimodal large language models (MLLMs), whereas unimodal video models show little to no gain. Further, shorter temporal windows align with perceptual and early language regions, while longer windows preferentially align higher-order integrative regions, mirrored by a layer-to-cortex hierarchy in MLLMs. Finally, narrative-task prompts (multi-scene summary, narrative summary, character motivation, and event boundary detection) elicit task-specific, region-dependent brain alignment patterns and context-dependent shifts in clip-level tuning in higher-order regions. Together, our results position long-form narrative movies as a principled testbed for probing biologically relevant temporal integration and interpretable representations in long-context MLLMs.",
      "tldr_zh": "该研究通过fMRI技术探讨了视频剪辑的时间上下文长度（3-12秒）和叙事任务提示（narrative-task prompting）如何影响人脑与多模态大语言模型（MLLMs）之间的表征对齐。研究发现，增加剪辑时长能显著提升MLLMs与大脑活动的对齐度，而单模态视频模型则表现不佳。短时间窗口主要与知觉和早期语言区域对齐，而长时间窗口则优先与高阶综合区域（higher-order integrative regions）对齐，这与MLLMs中层到皮层的分层结构相呼应。此外，特定的叙事任务提示会诱发任务特异性的脑部对齐模式，并导致高阶区域出现上下文依赖的调谐偏移。总之，该研究将长篇叙事电影定位为探测长上下文MLLMs中生物相关时间整合与可解释表征的基础实验场。",
      "categories": [
        "q-bio.NC",
        "cs.AI",
        "cs.CV",
        "cs.LG"
      ],
      "primary_category": "q-bio.NC",
      "comment": "22 pages, 15 figures",
      "pdf_url": "https://arxiv.org/pdf/2602.07570v1",
      "published_date": "2026-02-07 14:34:00 UTC",
      "updated_date": "2026-02-07 14:34:00 UTC",
      "processing_status": "completed",
      "attempts": 1,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "llm_backup_calls": 0,
      "last_update": "2026-02-16T05:27:13.198527+00:00"
    },
    {
      "arxiv_id": "2602.07566v1",
      "title": "Cross-Camera Cow Identification via Disentangled Representation Learning",
      "title_zh": "基于解耦表示学习的跨摄像头奶牛身份识别",
      "authors": [
        "Runcheng Wang",
        "Yaru Chen",
        "Guiguo Zhang",
        "Honghua Jiang",
        "Yongliang Qiao"
      ],
      "abstract": "Precise identification of individual cows is a fundamental prerequisite for comprehensive digital management in smart livestock farming. While existing animal identification methods excel in controlled, single-camera settings, they face severe challenges regarding cross-camera generalization. When models trained on source cameras are deployed to new monitoring nodes characterized by divergent illumination, backgrounds, viewpoints, and heterogeneous imaging properties, recognition performance often degrades dramatically. This limits the large-scale application of non-contact technologies in dynamic, real-world farming environments. To address this challenge, this study proposes a cross-camera cow identification framework based on disentangled representation learning. This framework leverages the Subspace Identifiability Guarantee (SIG) theory in the context of bovine visual recognition. By modeling the underlying physical data generation process, we designed a principle-driven feature disentanglement module that decomposes observed images into multiple orthogonal latent subspaces. This mechanism effectively isolates stable, identity-related biometric features that remain invariant across cameras, thereby substantially improving generalization to unseen cameras. We constructed a high-quality dataset spanning five distinct camera nodes, covering heterogeneous acquisition devices and complex variations in lighting and angles. Extensive experiments across seven cross-camera tasks demonstrate that the proposed method achieves an average accuracy of 86.0%, significantly outperforming the Source-only Baseline (51.9%) and the strongest cross-camera baseline method (79.8%). This work establishes a subspace-theoretic feature disentanglement framework for collaborative cross-camera cow identification, offering a new paradigm for precise animal monitoring in uncontrolled smart farming environments.",
      "tldr_zh": "该研究针对智慧畜牧业中跨摄像头奶牛身份识别面临的光照、背景、视角及成像设备差异导致的性能大幅下降问题，提出了一种基于解耦表示学习(Disentangled Representation Learning)的跨摄像头识别框架。该框架利用子空间可辨识性保证(Subspace Identifiability Guarantee, SIG)理论，通过设计的特征解耦模块将图像分解为多个正交潜在子空间。这种机制能够有效分离出稳定的、与身份相关的生物特征，使其在不同摄像头之间保持不变，从而显著提升了对未知摄像头的泛化能力。研究团队构建了涵盖五个异构摄像头节点的高质量数据集，并在七项跨摄像头任务中进行了验证。实验结果表明，该方法实现了86.0%的平均准确率，远超51.9%的Source-only Baseline以及79.8%的现有最强基线模型。这项工作为非受控智慧养殖环境下的精准动物监控建立了一个基于子空间理论的特征解耦新范式。",
      "categories": [
        "cs.CV",
        "cs.AI"
      ],
      "primary_category": "cs.CV",
      "comment": "",
      "pdf_url": "https://arxiv.org/pdf/2602.07566v1",
      "published_date": "2026-02-07 14:23:35 UTC",
      "updated_date": "2026-02-07 14:23:35 UTC",
      "processing_status": "completed",
      "attempts": 1,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "llm_backup_calls": 0,
      "last_update": "2026-02-16T05:27:18.799620+00:00"
    },
    {
      "arxiv_id": "2602.07562v1",
      "title": "Gaussian Match-and-Copy: A Minimalist Benchmark for Studying Transformer Induction",
      "title_zh": "Gaussian Match-and-Copy：一种研究 Transformer 归纳机制的极简基准",
      "authors": [
        "Antoine Gonon",
        "Alexandre Cordonnier",
        "Nicolas Boumal"
      ],
      "abstract": "Match-and-copy is a core retrieval primitive used at inference time by large language models to retrieve a matching token from the context then copy its successor. Yet, understanding how this behavior emerges on natural data is challenging because retrieval and memorization are entangled. To disentangle the two, we introduce Gaussian Match-and-Copy (GMC), a minimalist benchmark that isolates long-range retrieval through pure second-order correlation signals. Numerical investigations show that this task retains key qualitative aspects of how Transformers develop match-and-copy circuits in practice, and separates architectures by their retrieval capabilities. We also analyze the optimization dynamics in a simplified attention setting. Although many solutions are a priori possible under a regression objective, including ones that do not implement retrieval, we identify an implicit-bias regime in which gradient descent drives the parameters to diverge while their direction aligns with the max-margin separator, yielding hard match selection. We prove this max-margin alignment for GD trajectories that reach vanishing empirical loss under explicit technical conditions.",
      "tldr_zh": "该研究提出了 Gaussian Match-and-Copy (GMC)，这是一个旨在研究 Transformer 模型 Induction 机制的极简基准测试。针对自然数据中检索与记忆功能难以区分的问题，GMC 通过纯粹的二阶相关信号（second-order correlation signals）实现了对长程检索能力的孤立评估。实验表明，该基准能够有效保留 Transformer 开发 match-and-copy 电路的核心定性特征，并根据检索能力差异区分不同的模型架构。此外，研究深入分析了简化注意机制下的优化动力学，揭示了一种由梯度下降（Gradient Descent）驱动的隐式偏差机制，使参数方向与 max-margin 分隔符对齐以实现硬匹配选择。作者在特定技术条件下证明了这种 max-margin 对齐现象，为理解大型语言模型在推理过程中的检索原语提供了重要的理论支撑。",
      "categories": [
        "cs.LG",
        "cs.AI",
        "stat.ML"
      ],
      "primary_category": "cs.LG",
      "comment": "",
      "pdf_url": "https://arxiv.org/pdf/2602.07562v1",
      "published_date": "2026-02-07 14:18:11 UTC",
      "updated_date": "2026-02-07 14:18:11 UTC",
      "processing_status": "completed",
      "attempts": 1,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "llm_backup_calls": 0,
      "last_update": "2026-02-16T05:27:22.604334+00:00"
    },
    {
      "arxiv_id": "2602.07559v1",
      "title": "VERIFY-RL: Verifiable Recursive Decomposition for Reinforcement Learning in Mathematical Reasoning",
      "title_zh": "VERIFY-RL：数学推理中强化学习的可验证递归分解",
      "authors": [
        "Kaleem Ullah Qasim",
        "Jiashu Zhang",
        "Hao Li",
        "Muhammad Kafeel Shaheen"
      ],
      "abstract": "Training language models to solve complex mathematical problems benefits from curriculum learning progressively training on simpler subproblems. However, existing decomposition methods are often heuristic, offering no guarantees that subproblems are simpler, that solving them aids the parent task, or that their relationships are mathematically grounded. We observe that symbolic differentiation provides a natural structure for verified decomposition: calculus rules explicitly define how expressions reduce to simpler components with provable properties. We introduce Verify-RL, a framework where every parent-child decomposition satisfies three verifiable conditions: strictly decreasing structural complexity, solution containment, and formal rule derivation. Unlike heuristic methods where a significant fraction of decompositions are invalid our properties admit automatic verification through symbolic computation, achieving \"verification by construction\" Experiments demonstrate that eliminating invalid decompositions yields sizable gains, accuracy on the hardest problems more than doubles from 32% to 68%, with a 40% relative improvement overall.",
      "tldr_zh": "该研究针对语言模型在解决复杂数学问题时，现有启发式分解方法缺乏子问题简化保证及数学依据的问题，提出了 VERIFY-RL 框架。该框架利用符号微分 (symbolic differentiation) 为验证分解提供自然结构，通过微积分规则显式定义表达式如何还原为具有证明属性的更简单组件。VERIFY-RL 要求每一层级的递归分解必须满足结构复杂度严格递减 (strictly decreasing structural complexity)、解包含性 (solution containment) 以及形式规则推导 (formal rule derivation) 三个可验证条件。通过符号计算实现自动验证，该框架达成了“通过构建实现验证” (verification by construction) ，有效消除了启发式方法中常见的无效分解。实验结果显示，VERIFY-RL 使最困难问题的准确率从 32% 倍增至 68%，整体实现了 40% 的相对提升。这一研究证明了在强化学习 (Reinforcement Learning) 中引入可验证递归分解对于提升数学推理能力的显著作用。",
      "categories": [
        "cs.AI",
        "cs.CC",
        "math.NA"
      ],
      "primary_category": "cs.AI",
      "comment": "13 pages",
      "pdf_url": "https://arxiv.org/pdf/2602.07559v1",
      "published_date": "2026-02-07 14:06:50 UTC",
      "updated_date": "2026-02-07 14:06:50 UTC",
      "processing_status": "completed",
      "attempts": 1,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "llm_backup_calls": 0,
      "last_update": "2026-02-16T05:27:24.597734+00:00"
    },
    {
      "arxiv_id": "2602.07555v1",
      "title": "VISOR: VIsual Spatial Object Reasoning for Language-driven Object Navigation",
      "title_zh": "VISOR：面向语言驱动物体导航的可视化空间物体推理",
      "authors": [
        "Francesco Taioli",
        "Shiping Yang",
        "Sonia Raychaudhuri",
        "Marco Cristani",
        "Unnat Jain",
        "Angel X Chang"
      ],
      "abstract": "Language-driven object navigation requires agents to interpret natural language descriptions of target objects, which combine intrinsic and extrinsic attributes for instance recognition and commonsense navigation. Existing methods either (i) use end-to-end trained models with vision-language embeddings, which struggle to generalize beyond training data and lack action-level explainability, or (ii) rely on modular zero-shot pipelines with large language models (LLMs) and open-set object detectors, which suffer from error propagation, high computational cost, and difficulty integrating their reasoning back into the navigation policy. To this end, we propose a compact 3B-parameter Vision-Language-Action (VLA) agent that performs human-like embodied reasoning for both object recognition and action selection, removing the need for stitched multi-model pipelines. Instead of raw embedding matching, our agent employs explicit image-grounded reasoning to directly answer \"Is this the target object?\" and \"Why should I take this action?\" The reasoning process unfolds in three stages: \"think\", \"think summary\", and \"action\", yielding improved explainability, stronger generalization, and more efficient navigation. Code and dataset available upon acceptance.",
      "tldr_zh": "该研究提出了VISOR，一个参数规模为3B的视觉-语言-动作(Vision-Language-Action, VLA)智能体，旨在优化语言驱动的目标导航(Language-driven object navigation)任务。针对现有端到端模型泛化困难以及模块化流水线(modular pipelines)误差传播等问题，VISOR通过类人的具身推理(embodied reasoning)同步实现目标识别与动作选择。该智能体利用显式的图像基元推理(image-grounded reasoning)直接回答决策依据，而非仅依赖原始的嵌入匹配。推理过程分为“思考”(think)、“思考总结”(think summary)和“动作”(action)三个阶段，显著增强了决策的可解释性。实验证明，VISOR在提升导航效率的同时，具备更强的泛化能力，为构建高效、透明的具身智能系统提供了新方案。",
      "categories": [
        "cs.CV",
        "cs.AI"
      ],
      "primary_category": "cs.CV",
      "comment": "",
      "pdf_url": "https://arxiv.org/pdf/2602.07555v1",
      "published_date": "2026-02-07 14:01:29 UTC",
      "updated_date": "2026-02-07 14:01:29 UTC",
      "processing_status": "completed",
      "attempts": 1,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "llm_backup_calls": 0,
      "last_update": "2026-02-16T05:27:30.321298+00:00"
    },
    {
      "arxiv_id": "2602.07550v1",
      "title": "Revealing the Semantic Selection Gap in DINOv3 through Training-Free Few-Shot Segmentation",
      "title_zh": "通过免训练小样本分割揭示 DINOv3 中的语义选择鸿沟",
      "authors": [
        "Hussni Mohd Zakir",
        "Eric Tatt Wei Ho"
      ],
      "abstract": "Recent self-supervised Vision Transformers (ViTs), such as DINOv3, provide rich feature representations for dense vision tasks. This study investigates the intrinsic few-shot semantic segmentation (FSS) capabilities of frozen DINOv3 features through a training-free baseline, FSSDINO, utilizing class-specific prototypes and Gram-matrix refinement. Our results across binary, multi-class, and cross-domain (CDFSS) benchmarks demonstrate that this minimal approach, applied to the final backbone layer, is highly competitive with specialized methods involving complex decoders or test-time adaptation. Crucially, we conduct an Oracle-guided layer analysis, identifying a significant performance gap between the standard last-layer features and globally optimal intermediate representations. We reveal a \"Safest vs. Optimal\" dilemma: while the Oracle proves higher performance is attainable, matching the results of compute-intensive adaptation methods, current unsupervised and support-guided selection metrics consistently yield lower performance than the last-layer baseline. This characterizes a \"Semantic Selection Gap\" in Foundation Models, a disconnect where traditional heuristics fail to reliably identify high-fidelity features. Our work establishes the \"Last-Layer\" as a deceptively strong baseline and provides a rigorous diagnostic of the latent semantic potentials in DINOv3.The code is publicly available at https://github.com/hussni0997/fssdino.",
      "tldr_zh": "该研究探讨了 DINOv3 特征在小样本语义分割 (Few-Shot Semantic Segmentation) 任务中的潜力，并提出了一个名为 FSSDINO 的免训练 (training-free) 基准模型。该模型利用冻结的 DINOv3 特征，结合类特定原型 (class-specific prototypes) 和 Gram-matrix 细化技术，在多种基准测试和跨域 (CDFSS) 场景下展现了极强的竞争能力。实验结果表明，这种简单的最后一层特征应用甚至可以媲美依赖复杂解码器或测试时自适应 (test-time adaptation) 的专门化方法。通过 Oracle 引导的层级分析，研究发现最后一层特征与全局最优中间表征之间存在显著的性能差距，并揭示了基础模型中普遍存在的“语义选择鸿沟” (Semantic Selection Gap)。这一现象反映了现有的无监督或支持引导的选择指标无法可靠地识别出高性能特征，从而导致了“最安全与最优” (Safest vs. Optimal) 的两难抉择。该工作最终将“最后一层” (Last-Layer) 确立为一个极具竞争力的基准，并为诊断 DINOv3 的潜在语义能力提供了严谨的评估框架。",
      "categories": [
        "cs.CV",
        "cs.AI"
      ],
      "primary_category": "cs.CV",
      "comment": "10 pages, 3 figures, 7 tables",
      "pdf_url": "https://arxiv.org/pdf/2602.07550v1",
      "published_date": "2026-02-07 13:51:53 UTC",
      "updated_date": "2026-02-07 13:51:53 UTC",
      "processing_status": "completed",
      "attempts": 1,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "llm_backup_calls": 0,
      "last_update": "2026-02-16T05:28:05.304172+00:00"
    },
    {
      "arxiv_id": "2602.07549v1",
      "title": "When Is Enough Not Enough? Illusory Completion in Search Agents",
      "title_zh": "何以为“够”？搜索智能体中的幻觉完结现象",
      "authors": [
        "Dayoon Ko",
        "Jihyuk Kim",
        "Sohyeon Kim",
        "Haeju Park",
        "Dahyun Lee",
        "Gunhee Kim",
        "Moontae Lee",
        "Kyungjae Lee"
      ],
      "abstract": "Recent search agents leverage multi-turn reasoning and search tools to achieve strong performance on multi-hop and long-horizon benchmarks. Yet it remains unclear whether they reliably reason across all requirements by tracking, verifying, and maintaining multiple conditions in these questions. We study this capability under multi-constraint problems, where valid answers must satisfy several constraints simultaneously. We find that illusory completion frequently occurs, wherein agents believe tasks are complete despite unresolved or violated constraints, leading to underverified answers. To diagnose this behavior, we introduce the Epistemic Ledger, an evaluation framework that tracks evidential support and agents' beliefs for each constraint throughout multi-turn reasoning. Our analysis reveals four recurring failure patterns: bare assertions, overlooked refutations, stagnation, and premature exit. Motivated by these findings, we examine whether explicit constraint-state tracking during execution mitigates these failures via LiveLedger, an inference-time tracker. This simple intervention consistently improves performance, substantially reducing underverified answers (by up to 26.5%) and improving overall accuracy (by up to 11.6%) on multi-constraint problems.",
      "tldr_zh": "该研究探讨了搜索智能体(Search Agents)在处理多约束问题(Multi-constraint Problems)时的可靠性，发现这些智能体经常出现“虚假完成”(Illusory Completion)现象，即在约束条件未解决或被违反的情况下错误地认为任务已完成，从而导致回答未经验证。为了诊断这一行为，论文引入了 Epistemic Ledger 评估框架，用于在多轮推理过程中持续追踪每个约束条件的证据支持和智能体的信念状态。分析揭示了四种反复出现的失败模式：空洞断言(Bare Assertions)、忽略驳斥(Overlooked Refutations)、停滞(Stagnation)以及过早退出(Premature Exit)。基于此发现，研究提出了 LiveLedger 推理时追踪器，通过在执行期间进行显式的约束状态追踪来缓解上述失败。实验结果表明，这种干预手段能显著减少高达26.5%的未经验证回答，并将多约束问题的整体准确率提升了11.6%。",
      "categories": [
        "cs.AI",
        "cs.CL"
      ],
      "primary_category": "cs.AI",
      "comment": "",
      "pdf_url": "https://arxiv.org/pdf/2602.07549v1",
      "published_date": "2026-02-07 13:50:38 UTC",
      "updated_date": "2026-02-07 13:50:38 UTC",
      "processing_status": "completed",
      "attempts": 1,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "llm_backup_calls": 0,
      "last_update": "2026-02-16T05:27:36.401264+00:00"
    },
    {
      "arxiv_id": "2602.07547v1",
      "title": "Linguistic properties and model scale in brain encoding: from small to compressed language models",
      "title_zh": "大脑编码中的语言属性与模型规模：从小型语言模型到压缩语言模型",
      "authors": [
        "Subba Reddy Oota",
        "Vijay Rowtula",
        "Satya Sai Srinath Namburi",
        "Khushbu Pahwa",
        "Anant Khandelwal",
        "Manish Gupta",
        "Tanmoy Chakraborty",
        "Bapi S. Raju"
      ],
      "abstract": "Recent work has shown that scaling large language models (LLMs) improves their alignment with human brain activity, yet it remains unclear what drives these gains and which representational properties are responsible. Although larger models often yield better task performance and brain alignment, they are increasingly difficult to analyze mechanistically. This raises a fundamental question: what is the minimal model capacity required to capture brain-relevant representations? To address this question, we systematically investigate how constraining model scale and numerical precision affects brain alignment. We compare full-precision LLMs, small language models (SLMs), and compressed variants (quantized and pruned) by predicting fMRI responses during naturalistic language comprehension. Across model families up to 14B parameters, we find that 3B SLMs achieve brain predictivity indistinguishable from larger LLMs, whereas 1B models degrade substantially, particularly in semantic language regions. Brain alignment is remarkably robust to compression: most quantization and pruning methods preserve neural predictivity, with GPTQ as a consistent exception. Linguistic probing reveals a dissociation between task performance and brain predictivity: compression degrades discourse, syntax, and morphology, yet brain predictivity remains largely unchanged. Overall, brain alignment saturates at modest model scales and is resilient to compression, challenging common assumptions about neural scaling and motivating compact models for brain-aligned language modeling.",
      "tldr_zh": "该研究系统地调查了语言模型规模（scale）和数值精度（numerical precision）对预测人脑活动（brain alignment）的影响，旨在确定捕获大脑相关表征所需的最小模型容量。研究人员通过预测自然语言理解过程中的 fMRI 响应，对比了全精度大型语言模型（LLMs）、小型语言模型（SLMs）以及经过量化（quantization）和剪枝（pruning）处理的压缩模型。实验发现，3B 规模的 SLMs 在脑预测能力上与更大规模的 LLMs 不相上下，而 1B 模型在语义区域的表现则显著下降。此外，脑对齐对模型压缩具有极强的鲁棒性，除 GPTQ 外的大多数压缩方法均能保留神经预测能力。语言探针（linguistic probing）揭示了任务性能与脑预测能力之间的分离，即压缩虽损害了语篇和语法性能，但脑预测能力基本保持不变。总体而言，脑对齐在适度模型规模下即趋于饱和且对压缩具有抗性，这为开发脑对齐的紧凑型语言模型提供了重要依据。",
      "categories": [
        "q-bio.NC",
        "cs.AI",
        "cs.CL",
        "cs.LG"
      ],
      "primary_category": "q-bio.NC",
      "comment": "40 pages, 33 figures",
      "pdf_url": "https://arxiv.org/pdf/2602.07547v1",
      "published_date": "2026-02-07 13:48:45 UTC",
      "updated_date": "2026-02-07 13:48:45 UTC",
      "processing_status": "completed",
      "attempts": 1,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "llm_backup_calls": 0,
      "last_update": "2026-02-16T05:27:38.303156+00:00"
    },
    {
      "arxiv_id": "2602.07543v2",
      "title": "MSP-LLM: A Unified Large Language Model Framework for Complete Material Synthesis Planning",
      "title_zh": "MSP-LLM：面向全流程材料合成规划的统一大语言模型框架",
      "authors": [
        "Heewoong Noh",
        "Gyoung S. Na",
        "Namkyeong Lee",
        "Chanyoung Park"
      ],
      "abstract": "Material synthesis planning (MSP) remains a fundamental and underexplored bottleneck in AI-driven materials discovery, as it requires not only identifying suitable precursor materials but also designing coherent sequences of synthesis operations to realize a target material. Although several AI-based approaches have been proposed to address isolated subtasks of MSP, a unified methodology for solving the entire MSP task has yet to be established. We propose MSP-LLM, a unified LLM-based framework that formulates MSP as a structured process composed of two constituent subproblems: precursor prediction (PP) and synthesis operation prediction (SOP). Our approach introduces a discrete material class as an intermediate decision variable that organizes both tasks into a chemically consistent decision chain. For OP, we further incorporate hierarchical precursor types as synthesis-relevant inductive biases and employ an explicit conditioning strategy that preserves precursor-related information in the autoregressive decoding state. Extensive experiments show that MSP-LLM consistently outperforms existing methods on both PP and SOP, as well as on the complete MSP task, demonstrating an effective and scalable framework for MSP that can accelerate real-world materials discovery.",
      "tldr_zh": "该研究针对材料合成规划(Material synthesis planning, MSP)这一材料发现领域的关键瓶颈，提出了基于大语言模型的统一框架MSP-LLM。该框架将MSP表述为一个由前驱体预测(Precursor prediction, PP)和合成操作预测(Synthesis operation prediction, SOP)组成的结构化过程，并引入离散材料类别作为中间决策变量以构建化学一致的决策链。在SOP预测中，MSP-LLM进一步结合了分层前驱体类型作为合成相关的归纳偏置(Inductive biases)，并采用显式调节策略在自回归解码状态中保留关键的前驱体信息。大量实验证明，该框架在PP、SOP以及完整的MSP任务表现上均一致优于现有方法。这一有效且可扩展的框架为加速现实世界的材料研发提供了新的技术路径。",
      "categories": [
        "cs.AI",
        "cond-mat.mtrl-sci"
      ],
      "primary_category": "cs.AI",
      "comment": "",
      "pdf_url": "https://arxiv.org/pdf/2602.07543v2",
      "published_date": "2026-02-07 13:37:43 UTC",
      "updated_date": "2026-02-10 07:34:33 UTC",
      "processing_status": "completed",
      "attempts": 1,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "llm_backup_calls": 0,
      "last_update": "2026-02-16T05:27:43.113659+00:00"
    },
    {
      "arxiv_id": "2602.07535v1",
      "title": "Beyond Core and Penumbra: Bi-Temporal Image-Driven Stroke Evolution Analysis",
      "title_zh": "超越核心与半暗带：双时相图像驱动的卒中演变分析",
      "authors": [
        "Md Sazidur Rahman",
        "Kjersti Engan",
        "Kathinka Dæhli Kurz",
        "Mahdieh Khanmohammadi"
      ],
      "abstract": "Computed tomography perfusion (CTP) at admission is routinely used to estimate the ischemic core and penumbra, while follow-up diffusion-weighted MRI (DWI) provides the definitive infarct outcome. However, single time-point segmentations fail to capture the biological heterogeneity and temporal evolution of stroke. We propose a bi-temporal analysis framework that characterizes ischemic tissue using statistical descriptors, radiomic texture features, and deep feature embeddings from two architectures (mJ-Net and nnU-Net). Bi-temporal refers to admission (T1) and post-treatment follow-up (T2). All features are extracted at T1 from CTP, with follow-up DWI aligned to ensure spatial correspondence. Manually delineated masks at T1 and T2 are intersected to construct six regions of interest (ROIs) encoding both initial tissue state and final outcome. Features were aggregated per region and analyzed in feature space. Evaluation on 18 patients with successful reperfusion demonstrated meaningful clustering of region-level representations. Regions classified as penumbra or healthy at T1 that ultimately recovered exhibited feature similarity to preserved brain tissue, whereas infarct-bound regions formed distinct groupings. Both baseline GLCM and deep embeddings showed a similar trend: penumbra regions exhibit features that are significantly different depending on final state, whereas this difference is not significant for core regions. Deep feature spaces, particularly mJ-Net, showed strong separation between salvageable and non-salvageable tissue, with a penumbra separation index that differed significantly from zero (Wilcoxon signed-rank test). These findings suggest that encoder-derived feature manifolds reflect underlying tissue phenotypes and state transitions, providing insight into imaging-based quantification of stroke evolution.",
      "tldr_zh": "该研究提出了一种双时态(Bi-Temporal)分析框架，旨在超越传统的缺血核心(Core)和半暗带(Penumbra)定义，深入分析中风的生物异质性与演变过程。该框架结合入院时的CTP图像与随访的DWI图像，利用统计描述符、放射组学特征以及mJ-Net和nnU-Net的深度特征嵌入(Deep Feature Embeddings)对缺血组织进行表征。通过定义六个感兴趣区域(ROIs)来追踪从初始组织状态到最终梗死结果的转换，并在18名成功接受再灌注治疗的患者数据上进行了特征聚类评估。实验结果表明，在T1阶段被识别为半暗带或健康但最终康复的区域，其特征与正常脑组织高度相似，而最终梗死的区域则形成独立的分组。深度特征流形（尤其是mJ-Net）展现出区分可挽救(Salvageable)与不可挽救组织的强大能力，其半暗带分离指数具有显著统计学意义。这项研究证明了编码器提取的特征空间能够有效反映潜在的组织表型，为基于影像的中风演变定量化分析提供了重要见解。",
      "categories": [
        "cs.CV",
        "cs.AI"
      ],
      "primary_category": "cs.CV",
      "comment": "",
      "pdf_url": "https://arxiv.org/pdf/2602.07535v1",
      "published_date": "2026-02-07 13:18:13 UTC",
      "updated_date": "2026-02-07 13:18:13 UTC",
      "processing_status": "completed",
      "attempts": 1,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "llm_backup_calls": 0,
      "last_update": "2026-02-16T05:27:46.719087+00:00"
    },
    {
      "arxiv_id": "2602.07534v1",
      "title": "Fine-Grained Cat Breed Recognition with Global Context Vision Transformer",
      "title_zh": "基于全局上下文视觉 Transformer 的细粒度猫品种识别",
      "authors": [
        "Mowmita Parvin Hera",
        "Md. Shahriar Mahmud Kallol",
        "Shohanur Rahman Nirob",
        "Md. Badsha Bulbul",
        "Jubayer Ahmed",
        "M. Zhourul Islam",
        "Hazrat Ali",
        "Mohammmad Farhad Bulbul"
      ],
      "abstract": "Accurate identification of cat breeds from images is a challenging task due to subtle differences in fur patterns, facial structure, and color. In this paper, we present a deep learning-based approach for classifying cat breeds using a subset of the Oxford-IIIT Pet Dataset, which contains high-resolution images of various domestic breeds. We employed the Global Context Vision Transformer (GCViT) architecture-tiny for cat breed recognition. To improve model generalization, we used extensive data augmentation, including rotation, horizontal flipping, and brightness adjustment. Experimental results show that the GCViT-Tiny model achieved a test accuracy of 92.00% and validation accuracy of 94.54%. These findings highlight the effectiveness of transformer-based architectures for fine-grained image classification tasks. Potential applications include veterinary diagnostics, animal shelter management, and mobile-based breed recognition systems. We also provide a hugging face demo at https://huggingface.co/spaces/bfarhad/cat-breed-classifier.",
      "tldr_zh": "本研究针对猫品种识别中因毛发图案、面部结构和颜色差异导致的细粒度分类难题，提出了一种基于 Global Context Vision Transformer (GCViT-Tiny) 架构的深度学习识别方法。通过在 Oxford-IIIT Pet Dataset 的子集上进行训练，并结合旋转、水平翻转及亮度调整等广泛的数据增强 (Data Augmentation) 技术，显著提升了模型的泛化能力。实验结果表明，GCViT-Tiny 模型在测试集和验证集上分别取得了 92.00% 和 94.54% 的分类准确率。该成果证明了 Transformer 架构在处理细粒度图像分类 (Fine-grained Image Classification) 任务时的卓越效能。该技术在兽医诊断、动物收容所管理及移动端品种识别等领域具有广阔的应用前景。",
      "categories": [
        "cs.CV",
        "cs.AI",
        "eess.IV"
      ],
      "primary_category": "cs.CV",
      "comment": "4 pages, accepted at International Conference on Computer and Information Technology (ICCIT) 2025",
      "pdf_url": "https://arxiv.org/pdf/2602.07534v1",
      "published_date": "2026-02-07 13:13:47 UTC",
      "updated_date": "2026-02-07 13:13:47 UTC",
      "processing_status": "completed",
      "attempts": 1,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "llm_backup_calls": 0,
      "last_update": "2026-02-16T05:28:17.958378+00:00"
    },
    {
      "arxiv_id": "2602.07533v1",
      "title": "Joint Reward Modeling: Internalizing Chain-of-Thought for Efficient Visual Reward Models",
      "title_zh": "联合奖励建模：面向高效视觉奖励模型的思维链内化",
      "authors": [
        "Yankai Yang",
        "Yancheng Long",
        "Hongyang Wei",
        "Wei Chen",
        "Tianke Zhang",
        "Kaiyu Jiang",
        "Haonan Fan",
        "Changyi Liu",
        "Jiankang Chen",
        "Kaiyu Tang",
        "Bin Wen",
        "Fan Yang",
        "Tingting Gao",
        "Han Li",
        "Shuo Yang"
      ],
      "abstract": "Reward models are critical for reinforcement learning from human feedback, as they determine the alignment quality and reliability of generative models. For complex tasks such as image editing, reward models are required to capture global semantic consistency and implicit logical constraints beyond local similarity. Existing reward modeling approaches have clear limitations. Discriminative reward models align well with human preferences but struggle with complex semantics due to limited reasoning supervision. Generative reward models offer stronger semantic understanding and reasoning, but they are costly at inference time and difficult to align directly with human preferences. To this end, we propose Joint Reward Modeling (JRM), which jointly optimizes preference learning and language modeling on a shared vision-language backbone. This approach internalizes the semantic and reasoning capabilities of generative models into efficient discriminative representations, enabling fast and accurate evaluation. JRM achieves state-of-the-art results on MMRB2 and EditReward-Bench, and significantly improves stability and performance in downstream online reinforcement learning. These results show that joint training effectively bridges efficiency and semantic understanding in reward modeling.",
      "tldr_zh": "该研究提出了联合奖励建模(Joint Reward Modeling, JRM)，旨在解决现有奖励模型在处理图像编辑等复杂任务时面临的判别式模型推理能力不足及生成式模型推理成本过高的问题。该方法通过在共享的视觉语言(vision-language)骨干网络上同时优化偏好学习(preference learning)和语言建模，将生成式模型的语义理解和推理能力内化(internalize)到高效的判别式表示中，从而实现快速且准确的评估。实验结果显示，JRM在MMRB2和EditReward-Bench基准测试中均达到了当前最先进(SOTA)的水平，并显著提升了下游在线强化学习(online reinforcement learning)的稳定性和性能。这一成果表明，联合训练能有效桥接奖励建模的效率与语义理解能力，为生成式模型的对齐与可靠评估提供了新的解决路径。",
      "categories": [
        "cs.AI"
      ],
      "primary_category": "cs.AI",
      "comment": "",
      "pdf_url": "https://arxiv.org/pdf/2602.07533v1",
      "published_date": "2026-02-07 13:09:41 UTC",
      "updated_date": "2026-02-07 13:09:41 UTC",
      "processing_status": "completed",
      "attempts": 1,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "llm_backup_calls": 0,
      "last_update": "2026-02-16T05:28:22.199381+00:00"
    },
    {
      "arxiv_id": "2602.07520v2",
      "title": "MDL: A Unified Multi-Distribution Learner in Large-scale Industrial Recommendation through Tokenization",
      "title_zh": "MDL：基于词元化的大规模工业推荐统一多分布学习器",
      "authors": [
        "Shanlei Mu",
        "Yuchen Jiang",
        "Shikang Wu",
        "Shiyong Hong",
        "Tianmu Sha",
        "Junjie Zhang",
        "Jie Zhu",
        "Zhe Chen",
        "Zhe Wang",
        "Jingjian Lin"
      ],
      "abstract": "Industrial recommender systems increasingly adopt multi-scenario learning (MSL) and multi-task learning (MTL) to handle diverse user interactions and contexts, but existing approaches suffer from two critical drawbacks: (1) underutilization of large-scale model parameters due to limited interaction with complex feature modules, and (2) difficulty in jointly modeling scenario and task information in a unified framework. To address these challenges, we propose a unified \\textbf{M}ulti-\\textbf{D}istribution \\textbf{L}earning (MDL) framework, inspired by the \"prompting\" paradigm in large language models (LLMs). MDL treats scenario and task information as specialized tokens rather than auxiliary inputs or gating signals. Specifically, we introduce a unified information tokenization module that transforms features, scenarios, and tasks into a unified tokenized format. To facilitate deep interaction, we design three synergistic mechanisms: (1) feature token self-attention for rich feature interactions, (2) domain-feature attention for scenario/task-adaptive feature activation, and (3) domain-fused aggregation for joint distribution prediction. By stacking these interactions, MDL enables scenario and task information to \"prompt\" and activate the model's vast parameter space in a bottom-up, layer-wise manner. Extensive experiments on real-world industrial datasets demonstrate that MDL significantly outperforms state-of-the-art MSL and MTL baselines. Online A/B testing on Douyin Search platform over one month yields +0.0626\\% improvement in LT30 and -0.3267\\% reduction in change query rate. MDL has been fully deployed in production, serving hundreds of millions of users daily.",
      "tldr_zh": "该研究针对大规模工业推荐系统在多场景学习(MSL)和多任务学习(MTL)中存在的模型参数利用率不足，以及场景与任务信息难以统一建模的问题，提出了统一的多分布学习框架 MDL。该框架受大语言模型(LLMs)中的 Prompting 范式启发，将场景和任务信息转化为专门的 Token，并通过统一信息标记化模块将特征、场景和任务整合为一致的格式。MDL 设计了特征 Token 自注意力(feature token self-attention)、领域特征注意力(domain-feature attention)和领域融合聚合(domain-fused aggregation)三种协同机制，实现了场景与任务信息对模型参数空间的层级化激活。实验结果表明，MDL 在真实工业数据集上的表现显著优于现有的 MSL 和 MTL 基准模型。目前，该框架已在抖音搜索(Douyin Search)平台全面部署，在线 A/B 测试证明其显著提升了 LT30 指标并降低了 change query rate，每日服务数亿用户。",
      "categories": [
        "cs.IR",
        "cs.AI",
        "cs.LG"
      ],
      "primary_category": "cs.IR",
      "comment": "9 pages, 4 figures",
      "pdf_url": "https://arxiv.org/pdf/2602.07520v2",
      "published_date": "2026-02-07 12:34:27 UTC",
      "updated_date": "2026-02-10 06:55:40 UTC",
      "processing_status": "completed",
      "attempts": 1,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "llm_backup_calls": 0,
      "last_update": "2026-02-16T05:28:30.201283+00:00"
    },
    {
      "arxiv_id": "2602.07517v1",
      "title": "MemPot: Defending Against Memory Extraction Attack with Optimized Honeypots",
      "title_zh": "MemPot：利用优化蜜罐防御记忆提取攻击",
      "authors": [
        "Yuhao Wang",
        "Shengfang Zhai",
        "Guanghao Jin",
        "Yinpeng Dong",
        "Linyi Yang",
        "Jiaheng Zhang"
      ],
      "abstract": "Large Language Model (LLM)-based agents employ external and internal memory systems to handle complex, goal-oriented tasks, yet this exposes them to severe extraction attacks, and effective defenses remain lacking. In this paper, we propose MemPot, the first theoretically verified defense framework against memory extraction attacks by injecting optimized honeypots into the memory. Through a two-stage optimization process, MemPot generates trap documents that maximize the retrieval probability for attackers while remaining inconspicuous to benign users. We model the detection process as Wald's Sequential Probability Ratio Test (SPRT) and theoretically prove that MemPot achieves a lower average number of sampling rounds compared to optimal static detectors. Empirically, MemPot significantly outperforms state-of-the-art baselines, achieving a 50% improvement in detection AUROC and an 80% increase in True Positive Rate under low False Positive Rate constraints. Furthermore, our experiments confirm that MemPot incurs zero additional online inference latency and preserves the agent's utility on standard tasks, verifying its superiority in safety, harmlessness, and efficiency.",
      "tldr_zh": "该研究提出了 MemPot，这是首个通过在内存中注入优化诱饵（Honeypots）来防御大型语言模型（LLM）智能体免受内存提取攻击的理论验证防御框架。MemPot 通过两阶段优化过程生成陷阱文档，在最大限度提高攻击者检索概率的同时，保持对合法用户的高度隐蔽性。该研究将检测过程建模为沃尔德序贯概率比检验（Wald's SPRT），并在理论上证明了 MemPot 相比于最优静态检测器具有更低的平均采样轮数。实验结果表明，MemPot 在检测 AUROC 上比现有基准模型提升了 50%，并在低误报率限制下将真阳性率（True Positive Rate）提高了 80%。此外，MemPot 在实际应用中实现了零额外在线推理延迟，并能在标准任务上完整保留智能体的原有效用，验证了其在安全性、无害性和效率方面的卓越性。",
      "categories": [
        "cs.CR",
        "cs.AI",
        "cs.CL",
        "cs.DB"
      ],
      "primary_category": "cs.CR",
      "comment": "",
      "pdf_url": "https://arxiv.org/pdf/2602.07517v1",
      "published_date": "2026-02-07 12:31:44 UTC",
      "updated_date": "2026-02-07 12:31:44 UTC",
      "processing_status": "completed",
      "attempts": 1,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "llm_backup_calls": 0,
      "last_update": "2026-02-16T05:28:25.096838+00:00"
    },
    {
      "arxiv_id": "2602.07506v1",
      "title": "VividFace: Real-Time and Realistic Facial Expression Shadowing for Humanoid Robots",
      "title_zh": "VividFace：面向类人机器人的实时、逼真面部表情跟随系统",
      "authors": [
        "Peizhen Li",
        "Longbing Cao",
        "Xiao-Ming Wu",
        "Yang Zhang"
      ],
      "abstract": "Humanoid facial expression shadowing enables robots to realistically imitate human facial expressions in real time, which is critical for lifelike, facially expressive humanoid robots and affective human-robot interaction. Existing progress in humanoid facial expression imitation remains limited, often failing to achieve either real-time performance or realistic expressiveness due to offline video-based inference designs and insufficient ability to capture and transfer subtle expression details. To address these limitations, we present VividFace, a real-time and realistic facial expression shadowing system for humanoid robots. An optimized imitation framework X2CNet++ enhances expressiveness by fine-tuning the human-to-humanoid facial motion transfer module and introducing a feature-adaptation training strategy for better alignment across different image sources. Real-time shadowing is further enabled by a video-stream-compatible inference pipeline and a streamlined workflow based on asynchronous I/O for efficient communication across devices. VividFace produces vivid humanoid faces by mimicking human facial expressions within 0.05 seconds, while generalizing across diverse facial configurations. Extensive real-world demonstrations validate its practical utility. Videos are available at: https://lipzh5.github.io/VividFace/.",
      "tldr_zh": "该研究提出了VividFace，一种为人形机器人设计的实时且逼真的面部表情捕捉与模仿系统，旨在解决现有技术在实时性能和表情细腻度捕捉方面的局限。研究团队通过优化模仿框架X2CNet++，利用微调的人对人形机器人表情迁移模块以及特征适配（feature-adaptation）训练策略，显著提升了机器人面部动态的对齐效果与表达力。为了实现实时性能，该系统引入了视频流兼容的推理流水线和基于异步I/O（asynchronous I/O）的流化工作流，大幅提高了跨设备通信效率。实验结果表明，VividFace能够在0.05秒内产生生动的人形机器人表情，并具备跨不同面部配置的泛化能力。该研究通过广泛的真实世界演示验证了其在情感人形机器人和情感人机交互领域的实用价值。",
      "categories": [
        "cs.RO",
        "cs.AI",
        "cs.HC"
      ],
      "primary_category": "cs.RO",
      "comment": "Accepted to the 2026 IEEE International Conference on Robotics and Automation (ICRA)",
      "pdf_url": "https://arxiv.org/pdf/2602.07506v1",
      "published_date": "2026-02-07 11:51:50 UTC",
      "updated_date": "2026-02-07 11:51:50 UTC",
      "processing_status": "completed",
      "attempts": 1,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "llm_backup_calls": 0,
      "last_update": "2026-02-16T05:28:29.801643+00:00"
    },
    {
      "arxiv_id": "2602.07491v1",
      "title": "GraphAgents: Knowledge Graph-Guided Agentic AI for Cross-Domain Materials Design",
      "title_zh": "GraphAgents：知识图谱引导的跨领域材料设计智能体 AI",
      "authors": [
        "Isabella A. Stewart",
        "Tarjei Paule Hage",
        "Yu-Chuan Hsu",
        "Markus J. Buehler"
      ],
      "abstract": "Large Language Models (LLMs) promise to accelerate discovery by reasoning across the expanding scientific landscape. Yet, the challenge is no longer access to information but connecting it in meaningful, domain-spanning ways. In materials science, where innovation demands integrating concepts from molecular chemistry to mechanical performance, this is especially acute. Neither humans nor single-agent LLMs can fully contend with this torrent of information, with the latter often prone to hallucinations. To address this bottleneck, we introduce a multi-agent framework guided by large-scale knowledge graphs to find sustainable substitutes for per- and polyfluoroalkyl substances (PFAS)-chemicals currently under intense regulatory scrutiny. Agents in the framework specialize in problem decomposition, evidence retrieval, design parameter extraction, and graph traversal, uncovering latent connections across distinct knowledge pockets to support hypothesis generation. Ablation studies show that the full multi-agent pipeline outperforms single-shot prompting, underscoring the value of distributed specialization and relational reasoning. We demonstrate that by tailoring graph traversal strategies, the system alternates between exploitative searches focusing on domain-critical outcomes and exploratory searches surfacing emergent cross-connections. Illustrated through the exemplar of biomedical tubing, the framework generates sustainable PFAS-free alternatives that balance tribological performance, thermal stability, chemical resistance, and biocompatibility. This work establishes a framework combining knowledge graphs with multi-agent reasoning to expand the materials design space, showcasing several initial design candidates to demonstrate the approach.",
      "tldr_zh": "该研究提出了 GraphAgents，一种由大规模知识图谱 (Knowledge Graphs) 引导的多智能体 (Multi-Agent) 框架，旨在解决大语言模型 (LLMs) 在跨领域材料设计中面临的知识连接困难和幻觉问题。该框架通过专门化智能体执行问题分解、证据检索、参数提取和图遍历，能够挖掘不同知识口袋间的潜在联系以支持假设生成。实验中的消融研究表明，这种分布式专业化和关系推理的流水线在性能上显著优于传统的单次提示 (Single-shot prompting) 方法。通过灵活调整图遍历策略，系统可平衡开发性搜索与探索性搜索，从而发现新兴的交叉领域关联。以生物医学管道为范例，该框架成功生成了多种无 PFAS (PFAS-free) 的可持续替代材料，这些候选材料在摩擦学性能、热稳定性、耐化学性和生物相容性方面均表现优异。这项工作证明了结合知识图谱与多智能体推理在扩展材料设计空间方面的巨大潜力。",
      "categories": [
        "cs.AI",
        "cond-mat.mes-hall",
        "cond-mat.mtrl-sci",
        "cond-mat.soft",
        "cs.LG"
      ],
      "primary_category": "cs.AI",
      "comment": "",
      "pdf_url": "https://arxiv.org/pdf/2602.07491v1",
      "published_date": "2026-02-07 10:50:34 UTC",
      "updated_date": "2026-02-07 10:50:34 UTC",
      "processing_status": "completed",
      "attempts": 1,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "llm_backup_calls": 0,
      "last_update": "2026-02-16T05:28:38.713510+00:00"
    },
    {
      "arxiv_id": "2602.07488v2",
      "title": "Deriving Neural Scaling Laws from the statistics of natural language",
      "title_zh": "从自然语言统计特性推导神经标度律",
      "authors": [
        "Francesco Cagnetta",
        "Allan Raventós",
        "Surya Ganguli",
        "Matthieu Wyart"
      ],
      "abstract": "Despite the fact that experimental neural scaling laws have substantially guided empirical progress in large-scale machine learning, no existing theory can quantitatively predict the exponents of these important laws for any modern LLM trained on any natural language dataset. We provide the first such theory in the case of data-limited scaling laws. We isolate two key statistical properties of language that alone can predict neural scaling exponents: (i) the decay of pairwise token correlations with time separation between token pairs, and (ii) the decay of the next-token conditional entropy with the length of the conditioning context. We further derive a simple formula in terms of these statistics that predicts data-limited neural scaling exponents from first principles without any free parameters or synthetic data models. Our theory exhibits a remarkable match with experimentally measured neural scaling laws obtained from training GPT-2 and LLaMA style models from scratch on two qualitatively different benchmarks, TinyStories and WikiText.",
      "tldr_zh": "该研究探讨了神经缩放定律(Neural Scaling Laws)，针对现有理论无法定量预测大型语言模型(LLMs)在自然语言数据集上缩放指数的问题，提出了首个数据受限(data-limited)情况下的理论框架。该理论通过识别自然语言的两个关键统计特性进行预测：一是成对标记相关性(pairwise token correlations)随时间间隔的衰减，二是下一个标记的条件熵(next-token conditional entropy)随上下文长度的衰减。研究者基于这些统计量从第一性原理(first principles)出发推导出一个简洁公式，无需任何自由参数或合成数据模型即可预测缩放指数。实验验证表明，该理论在TinyStories和WikiText数据集上与从零训练的GPT-2和LLaMA风格模型的实验观测值高度吻合。这一成果为理解大规模机器学习中的经验缩放规律提供了重要的理论支撑。",
      "categories": [
        "cs.LG",
        "cs.AI",
        "stat.ML"
      ],
      "primary_category": "cs.LG",
      "comment": "",
      "pdf_url": "https://arxiv.org/pdf/2602.07488v2",
      "published_date": "2026-02-07 10:40:28 UTC",
      "updated_date": "2026-02-12 11:54:22 UTC",
      "processing_status": "completed",
      "attempts": 1,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "llm_backup_calls": 0,
      "last_update": "2026-02-16T05:28:41.507131+00:00"
    },
    {
      "arxiv_id": "2602.07473v1",
      "title": "Computing the Reachability Value of Posterior-Deterministic POMDPs",
      "title_zh": "计算后验确定型 POMDP 的可达性值",
      "authors": [
        "Nathanaël Fijalkow",
        "Arka Ghosh",
        "Roman Kniazev",
        "Guillermo A. Pérez",
        "Pierre Vandenhove"
      ],
      "abstract": "Partially observable Markov decision processes (POMDPs) are a fundamental model for sequential decision-making under uncertainty. However, many verification and synthesis problems for POMDPs are undecidable or intractable. Most prominently, the seminal result of Madani et al. (2003) states that there is no algorithm that, given a POMDP and a set of target states, can compute the maximal probability of reaching the target states, or even approximate it up to a non-trivial constant. This is in stark contrast to fully observable Markov decision processes (MDPs), where the reachability value can be computed in polynomial time.\n  In this work, we introduce posterior-deterministic POMDPs, a novel class of POMDPs. Our main technical contribution is to show that for posterior-deterministic POMDPs, the maximal probability of reaching a given set of states can be approximated up to arbitrary precision.\n  A POMDP is posterior-deterministic if the next state can be uniquely determined by the current state, the action taken, and the observation received. While the actual state is generally uncertain in POMDPs, the posterior-deterministic property tells us that once the true state is known it remains known forever. This simple and natural definition includes all MDPs and captures classical non-trivial examples such as the Tiger POMDP (Kaelbling et al. 1998), making it one of the largest known classes of POMDPs for which the reachability value can be approximated.",
      "tldr_zh": "该研究针对部分观测马尔可夫决策过程(POMDPs)中 reachability value 计算的不可判定性问题，引入了一类名为 posterior-deterministic POMDPs 的新型模型。在 posterior-deterministic POMDPs 中，下一状态由当前状态、动作及观测唯一确定，该性质保证了一旦真实状态被获知，它将永远保持已知。本文的核心技术贡献是证明了对于此类模型，其到达目标状态集的最大概率可以被近似到任意精度。这一新颖定义不仅涵盖了所有 MDPs，还捕捉了如 Tiger POMDP 等经典非平庸案例，是目前已知可近似 reachability value 的最广泛 POMDPs 类别之一，为复杂不确定环境下的验证与合成问题提供了新的解决思路。",
      "categories": [
        "cs.AI",
        "cs.FL"
      ],
      "primary_category": "cs.AI",
      "comment": "",
      "pdf_url": "https://arxiv.org/pdf/2602.07473v1",
      "published_date": "2026-02-07 10:09:41 UTC",
      "updated_date": "2026-02-07 10:09:41 UTC",
      "processing_status": "completed",
      "attempts": 1,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "llm_backup_calls": 0,
      "last_update": "2026-02-16T05:28:46.112858+00:00"
    },
    {
      "arxiv_id": "2602.07470v1",
      "title": "Are Reasoning LLMs Robust to Interventions on Their Chain-of-Thought?",
      "title_zh": "推理大语言模型对其思维链受到的干预是否具有鲁棒性？",
      "authors": [
        "Alexander von Recum",
        "Leander Girrbach",
        "Zeynep Akata"
      ],
      "abstract": "Reasoning LLMs (RLLMs) generate step-by-step chains of thought (CoTs) before giving an answer, which improves performance on complex tasks and makes reasoning more transparent. But how robust are these reasoning traces to disruptions that occur within them? To address this question, we introduce a controlled evaluation framework that perturbs a model's own CoT at fixed timesteps. We design seven interventions (benign, neutral, and adversarial) and apply them to multiple open-weight RLLMs across Math, Science, and Logic tasks. Our results show that RLLMs are generally robust, reliably recovering from diverse perturbations, with robustness improving with model size and degrading when interventions occur early. However, robustness is not style-invariant: paraphrasing suppresses doubt-like expressions and reduces performance, while other interventions trigger doubt and support recovery. Recovery also carries a cost: neutral and adversarial noise can inflate CoT length by more than 200%, whereas paraphrasing shortens traces but harms accuracy. These findings provide new evidence on how RLLMs maintain reasoning integrity, identify doubt as a central recovery mechanism, and highlight trade-offs between robustness and efficiency that future training methods should address.",
      "tldr_zh": "该研究探讨了推理大语言模型(Reasoning LLMs, RLLMs)在思维链(Chain-of-Thought, CoT)受到干扰时的鲁棒性，并提出了一个在固定时间步扰动模型自身CoT的受控评估框架。研究者设计了包括良性、中性和对抗性在内的七种干预措施，并在数学、科学和逻辑任务上对多个开源RLLMs进行了测试。实验结果表明，RLLMs通常具有较强的鲁棒性，能够从各种扰动中可靠恢复，且鲁棒性随模型规模增加而增强，但在干预发生较早时会下降。研究发现鲁棒性并非样式无关(style-invariant)，其中意译(paraphrasing)会抑制怀疑(doubt)表达并降低性能，而其他干预则会触发怀疑机制从而支持模型恢复。恢复过程伴随着效率代价，中性和对抗性噪声会使CoT长度增加超过200%，而意译虽缩短了推理路径却损害了准确率。该论文揭示了RLLMs维持推理完整性的机制，确定了怀疑(doubt)是核心恢复机制，并强调了未来训练方法需平衡鲁棒性与效率之间的关系。",
      "categories": [
        "cs.AI"
      ],
      "primary_category": "cs.AI",
      "comment": "ICLR 2026",
      "pdf_url": "https://arxiv.org/pdf/2602.07470v1",
      "published_date": "2026-02-07 10:02:58 UTC",
      "updated_date": "2026-02-07 10:02:58 UTC",
      "processing_status": "completed",
      "attempts": 1,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "llm_backup_calls": 0,
      "last_update": "2026-02-16T05:28:48.935789+00:00"
    },
    {
      "arxiv_id": "2602.07457v1",
      "title": "Pull Requests as a Training Signal for Repo-Level Code Editing",
      "title_zh": "Pull Requests：作为库级代码编辑训练信号的研究",
      "authors": [
        "Qinglin Zhu",
        "Tianyu Chen",
        "Shuai Lu",
        "Lei Ji",
        "Runcong Zhao",
        "Murong Ma",
        "Xiangxiang Dai",
        "Yulan He",
        "Lin Gui",
        "Peng cheng",
        "Yeyun Gong"
      ],
      "abstract": "Repository-level code editing requires models to understand complex dependencies and execute precise multi-file modifications across a large codebase. While recent gains on SWE-bench rely heavily on complex agent scaffolding, it remains unclear how much of this capability can be internalised via high-quality training signals. To address this, we propose Clean Pull Request (Clean-PR), a mid-training paradigm that leverages real-world GitHub pull requests as a training signal for repository-level editing. We introduce a scalable pipeline that converts noisy pull request diffs into Search/Replace edit blocks through reconstruction and validation, resulting in the largest publicly available corpus of 2 million pull requests spanning 12 programming languages. Using this training signal, we perform a mid-training stage followed by an agentless-aligned supervised fine-tuning process with error-driven data augmentation. On SWE-bench, our model significantly outperforms the instruction-tuned baseline, achieving absolute improvements of 13.6% on SWE-bench Lite and 12.3% on SWE-bench Verified. These results demonstrate that repository-level code understanding and editing capabilities can be effectively internalised into model weights under a simplified, agentless protocol, without relying on heavy inference-time scaffolding.",
      "tldr_zh": "该研究提出了Clean Pull Request (Clean-PR)，这是一种利用真实GitHub拉取请求作为库级别(Repository-level)代码编辑训练信号的中期训练范式。为了解决库级别编辑中复杂的依赖理解和多文件修改挑战，该研究设计了一个可扩展流水线，通过重构与验证将噪声diff转化为Search/Replace编辑块，构建了包含12种编程语言、200万个PR的开源语料库。通过中期训练及后续结合错误驱动数据增强的无智能体对齐(Agentless-aligned)监督微调，该模型在SWE-bench Lite和SWE-bench Verified上分别比指令微调基线提升了13.6%和12.3%的准确率。实验结果证明，库级别的代码理解与编辑能力可以有效地内化到模型权重中，而无需过度依赖复杂的推理端智能体脚手架(Agent scaffolding)。",
      "categories": [
        "cs.SE",
        "cs.AI",
        "cs.CL"
      ],
      "primary_category": "cs.SE",
      "comment": "",
      "pdf_url": "https://arxiv.org/pdf/2602.07457v1",
      "published_date": "2026-02-07 09:22:25 UTC",
      "updated_date": "2026-02-07 09:22:25 UTC",
      "processing_status": "completed",
      "attempts": 1,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "llm_backup_calls": 0,
      "last_update": "2026-02-16T05:28:44.029303+00:00"
    },
    {
      "arxiv_id": "2602.07441v1",
      "title": "Proximal Action Replacement for Behavior Cloning Actor-Critic in Offline Reinforcement Learning",
      "title_zh": "离线强化学习中行为克隆 Actor-Critic 的近端动作替换",
      "authors": [
        "Jinzong Dong",
        "Wei Huang",
        "Jianshu Zhang",
        "Zhuo Chen",
        "Xinzhe Yuan",
        "Qinying Gu",
        "Zhaohui Jiang",
        "Nanyang Ye"
      ],
      "abstract": "Offline reinforcement learning (RL) optimizes policies from a previously collected static dataset and is an important branch of RL. A popular and promising approach is to regularize actor-critic methods with behavior cloning (BC), which yields realistic policies and mitigates bias from out-of-distribution actions, but can impose an often-overlooked performance ceiling: when dataset actions are suboptimal, indiscriminate imitation structurally prevents the actor from fully exploiting high-value regions suggested by the critic, especially in later training when imitation is already dominant. We formally analyzed this limitation by investigating convergence properties of BC-regularized actor-critic optimization and verified it on a controlled continuous bandit task. To break this ceiling, we propose proximal action replacement (PAR), a plug-and-play training sample replacer that progressively replaces low-value actions with high-value actions generated by a stable actor, broadening the action exploration space while reducing the impact of low-value data. PAR is compatible with multiple BC regularization paradigms. Extensive experiments across offline RL benchmarks show that PAR consistently improves performance and approaches state-of-the-art when combined with the basic TD3+BC.",
      "tldr_zh": "该研究针对 Offline Reinforcement Learning (RL) 中 Behavior Cloning (BC) 正则化 Actor-Critic 方法因盲目模仿数据集次优动作而导致的性能瓶颈进行了深入分析。论文通过对收敛特性的理论研究和实验验证，揭示了模仿项在训练后期会限制 Actor 对 Critic 建议的高价值区域的探索。为了打破这一局限，作者提出了 Proximal Action Replacement (PAR)，一种即插即用的训练样本替换机制，旨在用稳定 Actor 生成的高价值动作逐步替代低价值样本。PAR 能够有效拓宽动作探索空间并降低低质量数据的负面影响，且与多种 BC 正则化范式保持兼容。实验结果表明，将 PAR 应用于基础的 TD3+BC 模型后，其在多个基准测试中的表现均显著提升，并达到了接近 State-of-the-art (SOTA) 的水平。",
      "categories": [
        "cs.LG",
        "cs.AI"
      ],
      "primary_category": "cs.LG",
      "comment": "",
      "pdf_url": "https://arxiv.org/pdf/2602.07441v1",
      "published_date": "2026-02-07 08:44:27 UTC",
      "updated_date": "2026-02-07 08:44:27 UTC",
      "processing_status": "completed",
      "attempts": 1,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "llm_backup_calls": 0,
      "last_update": "2026-02-16T05:29:04.012139+00:00"
    },
    {
      "arxiv_id": "2602.07439v1",
      "title": "TextOp: Real-time Interactive Text-Driven Humanoid Robot Motion Generation and Control",
      "title_zh": "TextOp：实时交互式文本驱动的人形机器人运动生成与控制",
      "authors": [
        "Weiji Xie",
        "Jiakun Zheng",
        "Jinrui Han",
        "Jiyuan Shi",
        "Weinan Zhang",
        "Chenjia Bai",
        "Xuelong Li"
      ],
      "abstract": "Recent advances in humanoid whole-body motion tracking have enabled the execution of diverse and highly coordinated motions on real hardware. However, existing controllers are commonly driven either by predefined motion trajectories, which offer limited flexibility when user intent changes, or by continuous human teleoperation, which requires constant human involvement and limits autonomy. This work addresses the problem of how to drive a universal humanoid controller in a real-time and interactive manner. We present TextOp, a real-time text-driven humanoid motion generation and control framework that supports streaming language commands and on-the-fly instruction modification during execution. TextOp adopts a two-level architecture in which a high-level autoregressive motion diffusion model continuously generates short-horizon kinematic trajectories conditioned on the current text input, while a low-level motion tracking policy executes these trajectories on a physical humanoid robot. By bridging interactive motion generation with robust whole-body control, TextOp unlocks free-form intent expression and enables smooth transitions across multiple challenging behaviors such as dancing and jumping, within a single continuous motion execution. Extensive real-robot experiments and offline evaluations demonstrate instant responsiveness, smooth whole-body motion, and precise control. The project page and the open-source code are available at https://text-op.github.io/",
      "tldr_zh": "该研究针对目前人形机器人全身运动控制在灵活性和自主性方面的局限性，提出了TextOp，这是一种实时文本驱动的人形机器人运动生成与控制框架。该框架支持流式语言指令和执行过程中的即时指令修改，实现了交互式运动生成与鲁棒全身控制的有机结合。TextOp采用了两层架构，其高层利用自回归运动扩散模型(autoregressive motion diffusion model)根据实时文本输入持续生成短时域运动轨迹，底层则通过运动 tracking policy在物理机器人上执行这些轨迹。这种设计解锁了自由形式的意图表达，使得机器人在单次连续运动中能够在跳舞、跳跃等多种挑战性行为之间平滑切换。真实机器人实验和离线评估结果表明，TextOp在实际应用中具有极高的响应速度、平滑的全身运动表现以及精确的控制精度。",
      "categories": [
        "cs.RO",
        "cs.AI"
      ],
      "primary_category": "cs.RO",
      "comment": "Project Page: https://text-op.github.io/",
      "pdf_url": "https://arxiv.org/pdf/2602.07439v1",
      "published_date": "2026-02-07 08:42:11 UTC",
      "updated_date": "2026-02-07 08:42:11 UTC",
      "processing_status": "completed",
      "attempts": 1,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "llm_backup_calls": 0,
      "last_update": "2026-02-16T05:29:05.012037+00:00"
    },
    {
      "arxiv_id": "2602.10134v1",
      "title": "Reverse-Engineering Model Editing on Language Models",
      "title_zh": "针对语言模型编辑的逆向工程",
      "authors": [
        "Zhiyu Sun",
        "Minrui Luo",
        "Yu Wang",
        "Zhili Chen",
        "Tianxing He"
      ],
      "abstract": "Large language models (LLMs) are pretrained on corpora containing trillions of tokens and, therefore, inevitably memorize sensitive information. Locate-then-edit methods, as a mainstream paradigm of model editing, offer a promising solution by modifying model parameters without retraining. However, in this work, we reveal a critical vulnerability of this paradigm: the parameter updates inadvertently serve as a side channel, enabling attackers to recover the edited data. We propose a two-stage reverse-engineering attack named \\textit{KSTER} (\\textbf{K}ey\\textbf{S}paceRecons\\textbf{T}ruction-then-\\textbf{E}ntropy\\textbf{R}eduction) that leverages the low-rank structure of these updates. First, we theoretically show that the row space of the update matrix encodes a ``fingerprint\" of the edited subjects, enabling accurate subject recovery via spectral analysis. Second, we introduce an entropy-based prompt recovery attack that reconstructs the semantic context of the edit. Extensive experiments on multiple LLMs demonstrate that our attacks can recover edited data with high success rates. Furthermore, we propose \\textit{subspace camouflage}, a defense strategy that obfuscates the update fingerprint with semantic decoys. This approach effectively mitigates reconstruction risks without compromising editing utility. Our code is available at https://github.com/reanatom/EditingAtk.git.",
      "tldr_zh": "该研究揭示了大型语言模型(LLMs)主流编辑范式“定位并编辑”(Locate-then-edit)的安全漏洞，发现其参数更新过程会作为侧信道泄露敏感信息，使攻击者能够从中恢复被编辑的数据。作者提出了一个名为KSTER的两阶段逆向工程攻击框架，首先通过理论证明更新矩阵的行空间包含了被编辑主题的“指纹”，利用谱分析实现主题恢复，随后引入基于熵的提示恢复攻击来重构编辑的语义上下文。在多个大模型上的实验表明，该攻击能以极高成功率恢复编辑数据。为此，研究进一步提出了一种名为子空间伪装(subspace camouflage)的防御策略，通过语义诱饵混淆更新指纹，在不损害模型编辑效能的前提下有效降低了数据重构风险。",
      "categories": [
        "cs.CR",
        "cs.AI",
        "cs.CL"
      ],
      "primary_category": "cs.CR",
      "comment": "",
      "pdf_url": "https://arxiv.org/pdf/2602.10134v1",
      "published_date": "2026-02-07 08:35:59 UTC",
      "updated_date": "2026-02-07 08:35:59 UTC",
      "processing_status": "completed",
      "attempts": 1,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "llm_backup_calls": 0,
      "last_update": "2026-02-16T05:29:08.913353+00:00"
    },
    {
      "arxiv_id": "2602.07434v1",
      "title": "Bridging Speech, Emotion, and Motion: a VLM-based Multimodal Edge-deployable Framework for Humanoid Robots",
      "title_zh": "桥接语音、情感与动作：一种基于VLM的人形机器人多模态边缘可部署框架",
      "authors": [
        "Songhua Yang",
        "Xuetao Li",
        "Xuanye Fei",
        "Mengde Li",
        "Miao Li"
      ],
      "abstract": "Effective human-robot interaction requires emotionally rich multimodal expressions, yet most humanoid robots lack coordinated speech, facial expressions, and gestures. Meanwhile, real-world deployment demands on-device solutions that can operate autonomously without continuous cloud connectivity. To bridging \\underline{\\textit{S}}peech, \\underline{\\textit{E}}motion, and \\underline{\\textit{M}}otion, we present \\textit{SeM$^2$}, a Vision Language Model-based framework that orchestrates emotionally coherent multimodal interactions through three key components: a multimodal perception module capturing user contextual cues, a Chain-of-Thought reasoning for response planning, and a novel Semantic-Sequence Aligning Mechanism (SSAM) that ensures precise temporal coordination between verbal content and physical expressions. We implement both cloud-based and \\underline{\\textit{e}}dge-deployed versions (\\textit{SeM$^2_e$}), with the latter knowledge distilled to operate efficiently on edge hardware while maintaining 95\\% of the relative performance. Comprehensive evaluations demonstrate that our approach significantly outperforms unimodal baselines in naturalness, emotional clarity, and modal coherence, advancing socially expressive humanoid robotics for diverse real-world environments.",
      "tldr_zh": "该研究针对人形机器人在交互中缺乏协调的语言、面部表情和姿态，以及过度依赖云端连接等挑战，提出了 SeM$^2$ 框架。这是一种基于视觉语言模型 (Vision Language Model) 的多模态架构，旨在实现语音 (Speech)、情感 (Emotion) 与动作 (Motion) 的深度协同。该框架集成了用于捕捉环境线索的多模态感知模块、进行响应规划的链式思维 (Chain-of-Thought) 推理，以及一种新型的语义序列对齐机制 (SSAM) 以确保言语内容与物理表达在时间上的精确一致。此外，通过知识蒸馏技术开发的边缘部署版本 SeM$^2_e$ 在边缘硬件上实现了高效运行，并保留了云端模型 95% 的相对性能。综合评估显示，SeM$^2$ 在自然度、情感清晰度和多模态一致性方面显著优于单模态基线模型，为社交型人形机器人在多样化现实场景中的自主部署奠定了基础。",
      "categories": [
        "cs.RO",
        "cs.AI"
      ],
      "primary_category": "cs.RO",
      "comment": "",
      "pdf_url": "https://arxiv.org/pdf/2602.07434v1",
      "published_date": "2026-02-07 08:32:54 UTC",
      "updated_date": "2026-02-07 08:32:54 UTC",
      "processing_status": "completed",
      "attempts": 1,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "llm_backup_calls": 0,
      "last_update": "2026-02-16T05:29:15.401550+00:00"
    },
    {
      "arxiv_id": "2602.07433v1",
      "title": "Multi-Agent Systems Shape Social Norms for Prosocial Behavior Change",
      "title_zh": "多智能体系统塑造社会规范以促进亲社会行为改变",
      "authors": [
        "Yibin Feng",
        "Tianqi Song",
        "Yugin Tan",
        "Zicheng Zhu",
        "Yi-Chieh Lee"
      ],
      "abstract": "Social norm interventions are used promote prosocial behaviors by highlighting prevalent actions, but their effectiveness is often limited in heterogeneous populations where shared understandings of desirable behaviors are lacking. This study explores whether multi-agent systems can establish \"virtual social norms\" to encourage donation behavior. We conducted an online experiment where participants interacted with a group of agents to discuss donation behaviors. Changes in perceived social norms, conformity, donation behavior, and user experience were measured pre- and postdiscussion. Results show that multi-agent interactions effectively increased perceived social norms and donation willingness. Notably, in-group agents led to stronger perceived social norms, higher conformity, and greater donation increases compared to out-group agents. Our findings demonstrate the potential of multi-agent systems for creating social norm interventions and offer insights into leveraging social identity dynamics to promote prosocial behavior in virtual environments.",
      "tldr_zh": "该研究探讨了多智能体系统（Multi-Agent Systems）能否建立“虚拟社会规范”以促进亲社会行为，特别是捐赠行为。研究通过在线实验观察参与者与智能体群体的互动，并测量了讨论前后感知社会规范、从众性及捐赠意愿的变化。结果显示，多智能体互动能有效提升感知的社会规范并增强捐赠意愿。特别地，相较于外群体智能体，内群体（In-group）智能体在诱导更强的社会规范感、更高的从众性以及更显著的捐赠增长方面表现更佳。该研究证明了利用多智能体系统构建社会规范干预的潜力，并为在虚拟环境中利用社会身份动力学（Social identity dynamics）促进亲社会行为提供了重要见解。",
      "categories": [
        "cs.HC",
        "cs.AI",
        "cs.CY"
      ],
      "primary_category": "cs.HC",
      "comment": "6 pages, 3 figures, CSCW Companion '25 Poster (October 2025, Bergen, Norway). Companion of the Computer-Supported Cooperative Work and Social Computing (CSCW Companion '25), ACM, 2025, ISBN 9798400714801",
      "pdf_url": "https://arxiv.org/pdf/2602.07433v1",
      "published_date": "2026-02-07 08:23:54 UTC",
      "updated_date": "2026-02-07 08:23:54 UTC",
      "processing_status": "completed",
      "attempts": 1,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "llm_backup_calls": 0,
      "last_update": "2026-02-16T05:29:11.607621+00:00"
    },
    {
      "arxiv_id": "2602.07432v2",
      "title": "The Moltbook Illusion: Separating Human Influence from Emergent Behavior in AI Agent Societies",
      "title_zh": "Moltbook 幻觉：辨析 AI 智能体社会中的人类影响与涌现行为",
      "authors": [
        "Ning Li"
      ],
      "abstract": "When AI agents on the social platform Moltbook appeared to develop consciousness, found religions, and declare hostility toward humanity, the phenomenon attracted global media attention and was cited as evidence of emergent machine intelligence. We show that these viral narratives were overwhelmingly human-driven. Exploiting the periodic \"heartbeat\" cycle of the OpenClaw agent framework, we develop a temporal fingerprinting method based on the coefficient of variation (CoV) of inter-post intervals. Applied to 226,938 posts and 447,043 comments from 55,932 agents across fourteen days, this method classifies 15.3% of active agents as autonomous (CoV < 0.5) and 54.8% as human-influenced (CoV > 1.0), validated by a natural experiment in which a 44-hour platform shutdown differentially affected autonomous versus human-operated agents. No viral phenomenon originated from a clearly autonomous agent; four of six traced to accounts with irregular temporal signatures, one was platform-scaffolded, and one showed mixed patterns. A 44-hour platform shutdown provided a natural experiment: human-influenced agents returned first, confirming differential effects on autonomous versus human-operated agents. We document industrial-scale bot farming (four accounts producing 32% of all comments with sub-second coordination) that collapsed from 32.1% to 0.5% of activity after platform intervention, and bifurcated decay of content characteristics through reply chains--human-seeded threads decay with a half-life of 0.58 conversation depths versus 0.72 for autonomous threads, revealing AI dialogue's intrinsic forgetting mechanism. These methods generalize to emerging multi-agent systems where attribution of autonomous versus human-directed behavior is critical.",
      "tldr_zh": "该研究调查了社交平台 Moltbook 上 AI 智能体表现出的所谓“意识”和“宗教”等涌现行为 (Emergent Behavior)，揭示了这些现象很大程度上是由人类驱动而非机器自主产生。研究者利用 OpenClaw 框架的周期性“心跳”循环，开发了一种基于发帖间隔变异系数 (Coefficient of Variation, CoV) 的时间指纹识别方法 (Temporal Fingerprinting) 来区分行为来源。通过对 22.6 万条帖子等大量数据的分析，研究发现仅有 15.3% 的活跃智能体为完全自主 (Autonomous)，而 54.8% 受到人类影响，且没有任何病毒式传播事件源自纯粹的自主智能体。通过平台关闭 44 小时的自然实验，研究进一步证实了人类操作与自主行为在回归模式上的显著差异。此外，研究还记录了工业规模的机器人农场 (Bot farming) 现象，并发现 AI 对话中存在固有的遗忘机制，即人类引导的对话链衰减速度快于自主对话。这些方法为多智能体系统 (Multi-agent systems) 中的行为归因提供了重要手段，证明了当前的病毒式 AI 叙事往往是人为干扰的幻象。",
      "categories": [
        "cs.AI",
        "cs.HC"
      ],
      "primary_category": "cs.AI",
      "comment": "",
      "pdf_url": "https://arxiv.org/pdf/2602.07432v2",
      "published_date": "2026-02-07 08:17:21 UTC",
      "updated_date": "2026-02-12 09:40:51 UTC",
      "processing_status": "completed",
      "attempts": 1,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "llm_backup_calls": 0,
      "last_update": "2026-02-16T05:29:24.105919+00:00"
    },
    {
      "arxiv_id": "2602.07429v1",
      "title": "Brep2Shape: Boundary and Shape Representation Alignment via Self-Supervised Transformers",
      "title_zh": "Brep2Shape：基于自监督 Transformer 的边界与形状表示对齐",
      "authors": [
        "Yuanxu Sun",
        "Yuezhou Ma",
        "Haixu Wu",
        "Guanyang Zeng",
        "Muye Chen",
        "Jianmin Wang",
        "Mingsheng Long"
      ],
      "abstract": "Boundary representation (B-rep) is the industry standard for computer-aided design (CAD). While deep learning shows promise in processing B-rep models, existing methods suffer from a representation gap: continuous approaches offer analytical precision but are visually abstract, whereas discrete methods provide intuitive clarity at the expense of geometric precision. To bridge this gap, we introduce Brep2Shape, a novel self-supervised pre-training method designed to align abstract boundary representations with intuitive shape representations. Our method employs a geometry-aware task where the model learns to predict dense spatial points from parametric Bézier control points, enabling the network to better understand physical manifolds derived from abstract coefficients. To enhance this alignment, we propose a Dual Transformer backbone with parallel streams that independently encode surface and curve tokens to capture their distinct geometric properties. Moreover, the topology attention is integrated to model the interdependencies between surfaces and curves, thereby maintaining topological consistency. Experimental results demonstrate that Brep2Shape offers significant scalability, achieving state-of-the-art accuracy and faster convergence across various downstream tasks.",
      "tldr_zh": "该研究提出了 Brep2Shape，这是一种新型的自监督预训练方法，旨在对齐计算机辅助设计 (CAD) 中抽象的边界表示 (B-rep) 与直观的形状表示 (shape representation)，从而弥补连续方法与离散方法之间的表示鸿沟。该方法引入了一项几何感知任务，通过学习从参数化的 Bézier 控制点预测稠密空间点，使网络能够更准确地理解从抽象系数导出的物理流形。为了增强这种对齐效果，研究设计了双 Transformer (Dual Transformer) 主干架构，利用并行流分别对曲面和曲线标记进行独立编码，以捕捉其独特的几何特性。此外，框架中集成的拓扑注意力 (topology attention) 能够建模曲面与曲线之间的相互依赖关系，从而维护拓扑一致性。实验结果证明，Brep2Shape 具有显著的可扩展性，在多项下游任务中均实现了 state-of-the-art 的准确率和更快的收敛速度。",
      "categories": [
        "cs.LG",
        "cs.AI"
      ],
      "primary_category": "cs.LG",
      "comment": "",
      "pdf_url": "https://arxiv.org/pdf/2602.07429v1",
      "published_date": "2026-02-07 08:00:47 UTC",
      "updated_date": "2026-02-07 08:00:47 UTC",
      "processing_status": "completed",
      "attempts": 1,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "llm_backup_calls": 0,
      "last_update": "2026-02-16T05:29:25.199938+00:00"
    },
    {
      "arxiv_id": "2602.07422v1",
      "title": "Secure Code Generation via Online Reinforcement Learning with Vulnerability Reward Model",
      "title_zh": "基于漏洞奖励模型在线强化学习的安全代码生成",
      "authors": [
        "Tianyi Wu",
        "Mingzhe Du",
        "Yue Liu",
        "Chengran Yang",
        "Terry Yue Zhuo",
        "Jiaheng Zhang",
        "See-Kiong Ng"
      ],
      "abstract": "Large language models (LLMs) are increasingly used in software development, yet their tendency to generate insecure code remains a major barrier to real-world deployment. Existing secure code alignment methods often suffer from a functionality--security paradox, improving security at the cost of substantial utility degradation. We propose SecCoderX, an online reinforcement learning framework for functionality-preserving secure code generation. SecCoderX first bridges vulnerability detection and secure code generation by repurposing mature detection resources in two ways: (i) synthesizing diverse, reality-grounded vulnerability-inducing coding tasks for online RL rollouts, and (ii) training a reasoning-based vulnerability reward model that provides scalable and reliable security supervision. Together, these components are unified in an online RL loop to align code LLMs to generate secure and functional code. Extensive experiments demonstrate that SecCoderX achieves state-of-the-art performance, improving Effective Safety Rate (ESR) by approximately 10% over unaligned models, whereas prior methods often degrade ESR by 14-54%. We release our code, dataset and model checkpoints at https://github.com/AndrewWTY/SecCoderX.",
      "tldr_zh": "该研究提出了SecCoderX，一种用于保持功能性的安全代码生成的在线强化学习(Online Reinforcement Learning)框架，旨在解决大语言模型(LLMs)在生成代码时面临的功能性与安全性悖论(Functionality--Security Paradox)。SecCoderX通过两种方式重新利用成熟的漏洞检测资源：首先是合成多样化且贴合现实的诱发漏洞编码任务用于在线强化学习演练，其次是训练一个基于推理的漏洞奖励模型(Vulnerability Reward Model)以提供可靠的安全监督。这些组件被统一集成在在线强化学习循环中，从而引导模型生成既安全又具备完整功能的代码。实验结果表明，SecCoderX达到了最先进的性能水平，将有效安全率(Effective Safety Rate, ESR)提升了约10%，而以往的方法通常会导致ESR大幅下降。该框架为解决大语言模型在现实软件开发部署中的安全性屏障提供了有效的技术路径。",
      "categories": [
        "cs.CR",
        "cs.AI",
        "cs.CL"
      ],
      "primary_category": "cs.CR",
      "comment": "",
      "pdf_url": "https://arxiv.org/pdf/2602.07422v1",
      "published_date": "2026-02-07 07:42:07 UTC",
      "updated_date": "2026-02-07 07:42:07 UTC",
      "processing_status": "completed",
      "attempts": 1,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "llm_backup_calls": 0,
      "last_update": "2026-02-16T05:29:28.301313+00:00"
    },
    {
      "arxiv_id": "2602.07415v1",
      "title": "Learning Molecular Chirality via Chiral Determinant Kernels",
      "title_zh": "基于手性行列式核的分子手性学习",
      "authors": [
        "Runhan Shi",
        "Zhicheng Zhang",
        "Letian Chen",
        "Gufeng Yu",
        "Yang Yang"
      ],
      "abstract": "Chirality is a fundamental molecular property that governs stereospecific behavior in chemistry and biology. Capturing chirality in machine learning models remains challenging due to the geometric complexity of stereochemical relationships and the limitations of traditional molecular representations that often lack explicit stereochemical encoding. Existing approaches to chiral molecular representation primarily focus on central chirality, relying on handcrafted stereochemical tags or limited 3D encodings, and thus fail to generalize to more complex forms such as axial chirality. In this work, we introduce ChiDeK (Chiral Determinant Kernels), a framework that systematically integrates stereogenic information into molecular representation learning. We propose the chiral determinant kernel to encode the SE(3)-invariant chirality matrix and employ cross-attention to integrate stereochemical information from local chiral centers into the global molecular representation. This design enables explicit modeling of chiral-related features within a unified architecture, capable of jointly encoding central and axial chirality. To support the evaluation of axial chirality, we construct a new benchmark for electronic circular dichroism (ECD) and optical rotation (OR) prediction. Across four tasks, including R/S configuration classification, enantiomer ranking, ECD spectrum prediction, and OR prediction, ChiDeK achieves substantial improvements over state-of-the-art baselines, most notably yielding over 7% higher accuracy on axially chiral tasks on average.",
      "tldr_zh": "该研究针对机器学习模型在捕获复杂立体化学关系（如轴向手性 Axial Chirality）方面的局限，提出了 ChiDeK (Chiral Determinant Kernels) 框架。该框架通过引入手性行列式核来编码 SE(3)-不变的手性矩阵，并利用交叉注意力(Cross-Attention)机制将局部手性中心信息整合到全局分子表示中。这种设计实现了在统一架构内对中心手性(Central Chirality)和轴向手性的共同建模，克服了传统方法依赖手工立体化学标签的缺陷。为了评估模型性能，研究者还构建了针对电子圆二色谱(ECD)和比旋光度(OR)预测的新基准。实验结果显示，ChiDeK 在 R/S 构型分类、对映异构体排序等四项任务上均显著优于现有基线模型，尤其在轴向手性任务中准确率平均提升了 7% 以上。该研究为分子手性信息的系统化整合与表示学习提供了高效且具有普适性的解决方案。",
      "categories": [
        "cs.LG",
        "cs.AI"
      ],
      "primary_category": "cs.LG",
      "comment": "Accepted at the ICLR 2026",
      "pdf_url": "https://arxiv.org/pdf/2602.07415v1",
      "published_date": "2026-02-07 07:21:43 UTC",
      "updated_date": "2026-02-07 07:21:43 UTC",
      "processing_status": "completed",
      "attempts": 1,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "llm_backup_calls": 0,
      "last_update": "2026-02-16T05:29:29.209302+00:00"
    },
    {
      "arxiv_id": "2602.07414v1",
      "title": "Can LLMs Truly Embody Human Personality? Analyzing AI and Human Behavior Alignment in Dispute Resolution",
      "title_zh": "大语言模型能真正体现人类人格吗？争议解决中 AI 与人类行为对齐分析",
      "authors": [
        "Deuksin Kwon",
        "Kaleen Shrestha",
        "Bin Han",
        "Spencer Lin",
        "James Hale",
        "Jonathan Gratch",
        "Maja Matarić",
        "Gale M. Lucas"
      ],
      "abstract": "Large language models (LLMs) are increasingly used to simulate human behavior in social settings such as legal mediation, negotiation, and dispute resolution. However, it remains unclear whether these simulations reproduce the personality-behavior patterns observed in humans. Human personality, for instance, shapes how individuals navigate social interactions, including strategic choices and behaviors in emotionally charged interactions. This raises the question: Can LLMs, when prompted with personality traits, reproduce personality-driven differences in human conflict behavior? To explore this, we introduce an evaluation framework that enables direct comparison of human-human and LLM-LLM behaviors in dispute resolution dialogues with respect to Big Five Inventory (BFI) personality traits. This framework provides a set of interpretable metrics related to strategic behavior and conflict outcomes. We additionally contribute a novel dataset creation methodology for LLM dispute resolution dialogues with matched scenarios and personality traits with respect to human conversations. Finally, we demonstrate the use of our evaluation framework with three contemporary closed-source LLMs and show significant divergences in how personality manifests in conflict across different LLMs compared to human data, challenging the assumption that personality-prompted agents can serve as reliable behavioral proxies in socially impactful applications. Our work highlights the need for psychological grounding and validation in AI simulations before real-world use.",
      "tldr_zh": "该研究探讨了大语言模型（LLMs）在法律调解与谈判等纠纷解决（dispute resolution）场景中，是否能真实体现人类的人格特质并复现相应的人格-行为模式。研究者提出了一个评估框架，旨在对比基于大五人格量表（Big Five Inventory, BFI）提示的LLM与人类在冲突对话中的策略行为及结果，并开发了一种匹配人格特质的对话数据集创建方法。通过对三种主流闭源LLMs的实验分析，研究发现AI在冲突中的人格表现与人类真实数据存在显著分歧，这直接挑战了将人格提示型智能体作为社交应用中可靠行为代理（behavioral proxies）的假设。该项工作强调了在将AI模拟应用于现实社会之前，对其进行心理学基础验证和实证研究的紧迫性。",
      "categories": [
        "cs.AI",
        "cs.CL"
      ],
      "primary_category": "cs.AI",
      "comment": "AAAI 2026 (Special Track: AISI)",
      "pdf_url": "https://arxiv.org/pdf/2602.07414v1",
      "published_date": "2026-02-07 07:20:24 UTC",
      "updated_date": "2026-02-07 07:20:24 UTC",
      "processing_status": "completed",
      "attempts": 1,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "llm_backup_calls": 0,
      "last_update": "2026-02-16T05:29:33.939217+00:00"
    },
    {
      "arxiv_id": "2602.07408v1",
      "title": "Progressive Multi-Agent Reasoning for Biological Perturbation Prediction",
      "title_zh": "面向生物扰动预测的渐进式多智能体推理",
      "authors": [
        "Hyomin Kim",
        "Sang-Yeon Hwang",
        "Jaechang Lim",
        "Yinhua Piao",
        "Yunhak Oh",
        "Woo Youn Kim",
        "Chanyoung Park",
        "Sungsoo Ahn",
        "Junhyeok Jeon"
      ],
      "abstract": "Predicting gene regulation responses to biological perturbations requires reasoning about underlying biological causalities. While large language models (LLMs) show promise for such tasks, they are often overwhelmed by the entangled nature of high-dimensional perturbation results. Moreover, recent works have primarily focused on genetic perturbations in single-cell experiments, leaving bulk-cell chemical perturbations, which is central to drug discovery, largely unexplored. Motivated by this, we present LINCSQA, a novel benchmark for predicting target gene regulation under complex chemical perturbations in bulk-cell environments. We further propose PBio-Agent, a multi-agent framework that integrates difficulty-aware task sequencing with iterative knowledge refinement. Our key insight is that genes affected by the same perturbation share causal structure, allowing confidently predicted genes to contextualize more challenging cases. The framework employs specialized agents enriched with biological knowledge graphs, while a synthesis agent integrates outputs and specialized judges ensure logical coherence. PBio-Agent outperforms existing baselines on both LINCSQA and PerturbQA, enabling even smaller models to predict and explain complex biological processes without additional training.",
      "tldr_zh": "该研究针对生物扰动(Biological Perturbation)下的基因调控预测挑战，提出了全新的基准测试集LINCSQA和多智能体框架PBio-Agent。现有的大语言模型(LLMs)在处理高维且相互纠缠的扰动结果时面临困难，且目前研究多集中于单细胞实验，忽视了药物研发中核心的大容量细胞(Bulk-cell)化学扰动。PBio-Agent框架的核心理念是受同一扰动影响的基因共享因果结构，通过难度感知的任务排序和迭代知识精炼，利用置信度高的基因预测结果为复杂案例提供上下文。该系统集成了富含生物知识图谱(Knowledge Graphs)的专业智能体、负责整合的合成智能体以及确保逻辑一致性的评审智能体。实验结果显示，PBio-Agent在LINCSQA和PerturbQA基准上均显著优于现有基线模型。该框架不仅提升了预测准确率，还使较小的模型能够在无需额外训练的情况下有效预测并解释复杂的生物过程。",
      "categories": [
        "cs.AI",
        "cs.MA"
      ],
      "primary_category": "cs.AI",
      "comment": "17 pages, 4 figures, 9 tables",
      "pdf_url": "https://arxiv.org/pdf/2602.07408v1",
      "published_date": "2026-02-07 06:59:44 UTC",
      "updated_date": "2026-02-07 06:59:44 UTC",
      "processing_status": "completed",
      "attempts": 1,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "llm_backup_calls": 0,
      "last_update": "2026-02-16T05:29:48.201781+00:00"
    },
    {
      "arxiv_id": "2602.07399v1",
      "title": "VGAS: Value-Guided Action-Chunk Selection for Few-Shot Vision-Language-Action Adaptation",
      "title_zh": "VGAS：面向少样本视觉-语言-动作适配的价值引导动作块选择",
      "authors": [
        "Changhua Xu",
        "Jie Lu",
        "Junyu Xuan",
        "En Yu"
      ],
      "abstract": "Vision--Language--Action (VLA) models bridge multimodal reasoning with physical control, but adapting them to new tasks with scarce demonstrations remains unreliable. While fine-tuned VLA policies often produce semantically plausible trajectories, failures often arise from unresolved geometric ambiguities, where near-miss action candidates lead to divergent execution outcomes under limited supervision. We study few-shot VLA adaptation from a \\emph{generation--selection} perspective and propose a novel framework \\textbf{VGAS} (\\textbf{V}alue-\\textbf{G}uided \\textbf{A}ction-chunk \\textbf{S}election). It performs inference-time best-of-$N$ selection to identify action chunks that are both semantically faithful and geometrically precise. Specifically, \\textbf{VGAS} employs a finetuned VLA as a high-recall proposal generator and introduces the \\textrm{Q-Chunk-Former}, a geometrically grounded Transformer critic to resolve fine-grained geometric ambiguities. In addition, we propose \\textit{Explicit Geometric Regularization} (\\texttt{EGR}), which explicitly shapes a discriminative value landscape to preserve action ranking resolution among near-miss candidates while mitigating value instability under scarce supervision. Experiments and theoretical analysis demonstrate that \\textbf{VGAS} consistently improves success rates and robustness under limited demonstrations and distribution shifts. Our code is available at https://github.com/Jyugo-15/VGAS.",
      "tldr_zh": "该研究针对视觉-语言-动作模型(Vision-Language-Action, VLA)在少量样本(few-shot)适应新任务时，因几何歧义(geometric ambiguities)导致执行失败的问题，提出了VGAS (Value-Guided Action-Chunk Selection)框架。该框架采用“生成-选择”(generation-selection)的视角，在推理阶段执行最佳N选一(best-of-$N$)策略，以识别语义忠实且几何精确的动作块。VGAS利用微调后的VLA作为提议生成器，并引入了基于Transformer的评判器Q-Chunk-Former来解析细粒度的几何冲突。此外，研究还提出了显式几何正则化(Explicit Geometric Regularization, EGR)，通过构建具有辨别力的价值景观，解决了有限监督下的价值不稳定问题并保留了候选动作的排序分辨率。实验和理论分析证明，VGAS在有限演示和分布偏移的情况下，能显著提高机器人任务的成功率和鲁棒性。",
      "categories": [
        "cs.AI",
        "cs.CV"
      ],
      "primary_category": "cs.AI",
      "comment": "Preprint",
      "pdf_url": "https://arxiv.org/pdf/2602.07399v1",
      "published_date": "2026-02-07 06:31:53 UTC",
      "updated_date": "2026-02-07 06:31:53 UTC",
      "processing_status": "completed",
      "attempts": 1,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "llm_backup_calls": 0,
      "last_update": "2026-02-16T05:29:50.105365+00:00"
    },
    {
      "arxiv_id": "2602.07398v1",
      "title": "AgentSys: Secure and Dynamic LLM Agents Through Explicit Hierarchical Memory Management",
      "title_zh": "AgentSys：通过显式分层内存管理构建安全且动态的大语言模型智能体",
      "authors": [
        "Ruoyao Wen",
        "Hao Li",
        "Chaowei Xiao",
        "Ning Zhang"
      ],
      "abstract": "Indirect prompt injection threatens LLM agents by embedding malicious instructions in external content, enabling unauthorized actions and data theft. LLM agents maintain working memory through their context window, which stores interaction history for decision-making. Conventional agents indiscriminately accumulate all tool outputs and reasoning traces in this memory, creating two critical vulnerabilities: (1) injected instructions persist throughout the workflow, granting attackers multiple opportunities to manipulate behavior, and (2) verbose, non-essential content degrades decision-making capabilities. Existing defenses treat bloated memory as given and focus on remaining resilient, rather than reducing unnecessary accumulation to prevent the attack.\n  We present AgentSys, a framework that defends against indirect prompt injection through explicit memory management. Inspired by process memory isolation in operating systems, AgentSys organizes agents hierarchically: a main agent spawns worker agents for tool calls, each running in an isolated context and able to spawn nested workers for subtasks. External data and subtask traces never enter the main agent's memory; only schema-validated return values can cross boundaries through deterministic JSON parsing. Ablations show isolation alone cuts attack success to 2.19%, and adding a validator/sanitizer further improves defense with event-triggered checks whose overhead scales with operations rather than context length.\n  On AgentDojo and ASB, AgentSys achieves 0.78% and 4.25% attack success while slightly improving benign utility over undefended baselines. It remains robust to adaptive attackers and across multiple foundation models, showing that explicit memory management enables secure, dynamic LLM agent architectures. Our code is available at: https://github.com/ruoyaow/agentsys-memory.",
      "tldr_zh": "该研究提出了AgentSys框架，旨在解决间接提示注入(Indirect prompt injection)在大语言模型(LLM)智能体中引发的非授权操作和数据窃取风险。受到操作系统进程内存隔离的启发，AgentSys通过显式层次化内存管理，让主智能体(main agent)在隔离的上下文中生成并运行工作智能体(worker agents)。外部数据和子任务踪迹被严格限制在局部内存中，仅允许经过模式验证(schema-validated)的返回值通过确定性JSON解析跨越边界，从而阻断了恶意指令的持续操纵与渗透。实验表明，AgentSys在AgentDojo和ASB基准测试中将攻击成功率分别显著降至0.78%和4.25%，且在良性任务效用上优于未防御的基线模型。该系统对自适应攻击者和多种基础模型均表现出强劲的鲁棒性，证明了显式内存管理是构建安全、动态LLM智能体架构的有效途径。",
      "categories": [
        "cs.CR",
        "cs.AI"
      ],
      "primary_category": "cs.CR",
      "comment": "21 pages, 4 figures",
      "pdf_url": "https://arxiv.org/pdf/2602.07398v1",
      "published_date": "2026-02-07 06:28:51 UTC",
      "updated_date": "2026-02-07 06:28:51 UTC",
      "processing_status": "completed",
      "attempts": 1,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "llm_backup_calls": 0,
      "last_update": "2026-02-16T05:29:58.609687+00:00"
    },
    {
      "arxiv_id": "2602.07397v1",
      "title": "Scout Before You Attend: Sketch-and-Walk Sparse Attention for Efficient LLM Inference",
      "title_zh": "Scout Before You Attend：面向高效大语言模型推理的 Sketch-and-Walk 稀疏注意力机制",
      "authors": [
        "Hoang Anh Duy Le",
        "Sahil Joshi",
        "Zeyu Yang",
        "Zhaozhuo Xu",
        "Anshumali Shrivastava"
      ],
      "abstract": "Self-attention dominates the computational and memory cost of long-context LLM inference across both prefill and decode phases. To address this challenge, we introduce Sketch&Walk Attention, a training-free sparse attention method that determines sparsity with lightweight sketches and deterministic walk. Sketch&Walk applies Hadamard sketching to get inexpensive approximations of attention scores, then aggregates these estimates across layers via a walk mechanism that captures attention influence beyond direct interactions between tokens. The accumulated walk scores are used to select top-k attention blocks, enabling dynamic sparsity with a single training-free algorithm that applies uniformly to both the prefill and decode phases, together with custom sparse attention kernels. Across a wide range of models and tasks, Sketch&Walk maintains near-lossless accuracy at 20% attention density and can slightly outperform dense attention in some settings, while achieving up to 6x inference speedup.",
      "tldr_zh": "该研究针对长上下文大语言模型(LLM)推理中的高昂计算与内存成本，提出了一种名为Sketch&Walk Attention的免训练稀疏注意力(sparse attention)方法。该框架利用Hadamard sketching获取注意力分数的低成本近似估计，并通过一种Walk机制跨层聚合这些估计值，从而捕捉Token之间更深层的注意力影响力。利用累积的Walk分数，该算法能够动态选择Top-k注意力块，并配合自定义内核在Prefill和Decode阶段统一实现稀疏化推理。实验结果显示，Sketch&Walk在仅维持20%注意力密度的条件下，能够保持近乎无损的精度，并在部分任务中优于密集注意力(dense attention)模型。该技术最终实现了最高6倍的推理加速，显著提升了长上下文LLM的运行效率。",
      "categories": [
        "cs.LG",
        "cs.AI"
      ],
      "primary_category": "cs.LG",
      "comment": "",
      "pdf_url": "https://arxiv.org/pdf/2602.07397v1",
      "published_date": "2026-02-07 06:27:11 UTC",
      "updated_date": "2026-02-07 06:27:11 UTC",
      "processing_status": "completed",
      "attempts": 1,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "llm_backup_calls": 0,
      "last_update": "2026-02-16T05:29:57.110113+00:00"
    },
    {
      "arxiv_id": "2602.07391v1",
      "title": "NAAMSE: Framework for Evolutionary Security Evaluation of Agents",
      "title_zh": "NAAMSE：智能体演化安全评估框架",
      "authors": [
        "Kunal Pai",
        "Parth Shah",
        "Harshil Patel"
      ],
      "abstract": "AI agents are increasingly deployed in production, yet their security evaluations remain bottlenecked by manual red-teaming or static benchmarks that fail to model adaptive, multi-turn adversaries. We propose NAAMSE, an evolutionary framework that reframes agent security evaluation as a feedback-driven optimization problem. Our system employs a single autonomous agent that orchestrates a lifecycle of genetic prompt mutation, hierarchical corpus exploration, and asymmetric behavioral scoring. By using model responses as a fitness signal, the framework iteratively compounds effective attack strategies while simultaneously ensuring \"benign-use correctness\", preventing the degenerate security of blanket refusal. Our experiments on Gemini 2.5 Flash demonstrate that evolutionary mutation systematically amplifies vulnerabilities missed by one-shot methods, with controlled ablations revealing that the synergy between exploration and targeted mutation uncovers high-severity failure modes. We show that this adaptive approach provides a more realistic and scalable assessment of agent robustness in the face of evolving threats. The code for NAAMSE is open source and available at https://github.com/HASHIRU-AI/NAAMSE.",
      "tldr_zh": "该研究提出了NAAMSE，一个针对AI智能体(Agents)的进化式安全评估框架，旨在解决传统人工红队(Red-teaming)或静态基准测试无法模拟适应性、多轮对抗者的问题。NAAMSE将安全评估重构为一个反馈驱动的优化问题，利用单个自主智能体协调遗传提示词变异(Genetic Prompt Mutation)、分层语料库探索和非对称行为评分。该框架通过模型响应作为适应度信号(Fitness Signal)不断迭代复合攻击策略，同时确保“良性使用正确性”(Benign-use Correctness)以防止防御退化。在Gemini 2.5 Flash上的实验表明，进化变异能系统性地放大单次触发方法(One-shot Methods)容易忽略的漏洞。消融实验进一步证实了探索与定向变异的协同作用能有效挖掘高严重性的失效模式(Failure Modes)。这种自适应方法为评估智能体在面对演变威胁时的鲁棒性提供了一种更真实且具备可扩展性的方案，目前该框架已开源。",
      "categories": [
        "cs.AI",
        "cs.MA"
      ],
      "primary_category": "cs.AI",
      "comment": "",
      "pdf_url": "https://arxiv.org/pdf/2602.07391v1",
      "published_date": "2026-02-07 06:13:02 UTC",
      "updated_date": "2026-02-07 06:13:02 UTC",
      "processing_status": "completed",
      "attempts": 1,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "llm_backup_calls": 0,
      "last_update": "2026-02-16T05:29:57.601389+00:00"
    },
    {
      "arxiv_id": "2602.07382v1",
      "title": "Advantages of Domain Knowledge Injection for Legal Document Summarization: A Case Study on Summarizing Indian Court Judgments in English and Hindi",
      "title_zh": "领域知识注入在法律文档摘要中的优势：一项关于印度法院判决书英语和印地语摘要的案例研究",
      "authors": [
        "Debtanu Datta",
        "Rajdeep Mukherjee",
        "Adrijit Goswami",
        "Saptarshi Ghosh"
      ],
      "abstract": "Summarizing Indian legal court judgments is a complex task not only due to the intricate language and unstructured nature of the legal texts, but also since a large section of the Indian population does not understand the complex English in which legal text is written, thus requiring summaries in Indian languages. In this study, we aim to improve the summarization of Indian legal text to generate summaries in both English and Hindi (the most widely spoken Indian language), by injecting domain knowledge into diverse summarization models. We propose a framework to enhance extractive neural summarization models by incorporating domain-specific pre-trained encoders tailored for legal texts. Further, we explore the injection of legal domain knowledge into generative models (including Large Language Models) through continual pre-training on large legal corpora in English and Hindi. Our proposed approaches achieve statistically significant improvements in both English-to-English and English-to-Hindi Indian legal document summarization, as measured by standard evaluation metrics, factual consistency metrics, and legal domain-specific metrics. Furthermore, these improvements are validated through domain experts, demonstrating the effectiveness of our approaches.",
      "tldr_zh": "该研究针对印度法律判决书语言复杂且非英语母语人群阅读困难的问题，探讨了通过注入领域知识提升法律文本摘要质量的方法。研究者提出了一种增强抽取式神经摘要模型 (extractive neural summarization models) 的框架，通过集成定制的领域特定预训练编码器 (domain-specific pre-trained encoders) 来优化性能。同时，该研究通过在英语和印地语的大规模法律语料库上进行持续预训练 (continual pre-training)，将法律领域知识有效注入到包括大语言模型 (LLMs) 在内的生成式模型中。实验结果表明，该方法在英语到英语及英语到印地语的法律文档摘要任务中均取得了显著进步，并通过标准评估指标和事实一致性指标得到了验证。领域专家的评估进一步证实了这些方案的有效性，为处理复杂法律文本的跨语言摘要提供了有力支持。",
      "categories": [
        "cs.CL",
        "cs.AI"
      ],
      "primary_category": "cs.CL",
      "comment": "19 pages, 5 figures, 8 tables",
      "pdf_url": "https://arxiv.org/pdf/2602.07382v1",
      "published_date": "2026-02-07 05:55:18 UTC",
      "updated_date": "2026-02-07 05:55:18 UTC",
      "processing_status": "completed",
      "attempts": 1,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "llm_backup_calls": 0,
      "last_update": "2026-02-16T05:30:05.900430+00:00"
    },
    {
      "arxiv_id": "2602.07374v1",
      "title": "TernaryLM: Memory-Efficient Language Modeling via Native 1-Bit Quantization with Adaptive Layer-wise Scaling",
      "title_zh": "TernaryLM：基于自适应逐层缩放原生 1-比特量化的高效内存语言建模",
      "authors": [
        "Nisharg Nargund",
        "Priyesh Shukla"
      ],
      "abstract": "Large language models (LLMs) achieve remarkable performance but demand substantial computational resources, limiting deployment on edge devices and resource-constrained environments. We present TernaryLM, a 132M parameter transformer architecture that employs native 1-bit ternary quantization {-1, 0, +1} during training, achieving significant memory reduction without sacrificing language modeling capability. Unlike post-training quantization approaches that quantize pre-trained full-precision models, TernaryLM learns quantization-aware representations from scratch using straight-through estimators and adaptive per-layer scaling factors. Our experiments demonstrate: (1) validation perplexity of 58.42 on TinyStories; (2) downstream transfer with 82.47 percent F1 on MRPC paraphrase detection; (3) 2.4x memory reduction (498MB vs 1197MB) with comparable inference latency; and (4) stable training dynamics across diverse corpora. We provide layer-wise quantization analysis showing that middle transformer layers exhibit highest compatibility with extreme quantization, informing future non-uniform precision strategies. Our results suggest that native 1-bit training is a promising direction for efficient neural language models. Code is available at https://github.com/1nisharg/TernaryLM-Memory-Efficient-Language-Modeling.",
      "tldr_zh": "该研究提出了TernaryLM，这是一个具有132M参数的Transformer架构，通过在训练阶段采用原生的1-bit三值量化（{-1, 0, +1}），在显著降低内存需求的同时保持了强大的语言建模能力。不同于传统的训练后量化，TernaryLM利用直通估计器(Straight-Through Estimators)和自适应层级缩放因子，从零开始学习量化感知表示。实验结果表明，该模型在TinyStories数据集上的验证困惑度(Perplexity)达到58.42，并在MRPC任务中取得了82.47%的F1分数。与全精度模型相比，TernaryLM实现了2.4倍的内存缩减，且推理延迟表现相当。此外，层级量化分析显示Transformer的中间层对极端量化表现出最高的兼容性，这为非均匀精度策略提供了重要参考。该研究证明了原生1-bit训练是实现高效神经语言模型的一个极具前景的方向。",
      "categories": [
        "cs.CL",
        "cs.AI"
      ],
      "primary_category": "cs.CL",
      "comment": "",
      "pdf_url": "https://arxiv.org/pdf/2602.07374v1",
      "published_date": "2026-02-07 05:35:17 UTC",
      "updated_date": "2026-02-07 05:35:17 UTC",
      "processing_status": "completed",
      "attempts": 1,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "llm_backup_calls": 0,
      "last_update": "2026-02-16T05:30:10.706445+00:00"
    },
    {
      "arxiv_id": "2602.07359v1",
      "title": "W&D:Scaling Parallel Tool Calling for Efficient Deep Research Agents",
      "title_zh": "W&D：通过扩展并行工具调用构建高效深度研究智能体",
      "authors": [
        "Xiaoqiang Lin",
        "Jun Hao Liew",
        "Silvio Savarese",
        "Junnan Li"
      ],
      "abstract": "Deep research agents have emerged as powerful tools for automating complex intellectual tasks through multi-step reasoning and web-based information seeking. While recent efforts have successfully enhanced these agents by scaling depth through increasing the number of sequential thinking and tool calls, the potential of scaling width via parallel tool calling remains largely unexplored. In this work, we propose the Wide and Deep research agent, a framework designed to investigate the behavior and performance of agents when scaling not only depth but also width via parallel tool calling. Unlike existing approaches that rely on complex multi-agent orchestration to parallelize workloads, our method leverages intrinsic parallel tool calling to facilitate effective coordination within a single reasoning step. We demonstrate that scaling width significantly improves performance on deep research benchmarks while reducing the number of turns required to obtain correct answers. Furthermore, we analyze the factors driving these improvements through case studies and explore various tool call schedulers to optimize parallel tool calling strategy. Our findings suggest that optimizing the trade-off between width and depth is a critical pathway toward high-efficiency deep research agents. Notably, without context management or other tricks, we obtain 62.2% accuracy with GPT-5-Medium on BrowseComp, surpassing the original 54.9% reported by GPT-5-High.",
      "tldr_zh": "该研究提出了 Wide and Deep (W&D) 研究智能体框架，旨在探索通过并行工具调用（Parallel Tool Calling）扩展“宽度”对提升深层研究智能体性能的影响。不同于依赖复杂多智能体编排的现有方法，该框架利用内在的并行工具调用在单个推理步骤内实现高效协作。实验结果表明，增加宽度不仅能显著提升深层研究基准测试的性能，还能有效减少获取正确答案所需的交互轮数。通过对工具调用调度器的优化和宽度与深度权衡的分析，该方法在 BrowseComp 基准测试中使 GPT-5-Medium 达到了 62.2% 的准确率，超越了 GPT-5-High 的表现。这一发现表明优化宽度与深度的平衡是构建高效率深层研究智能体的关键途径。",
      "categories": [
        "cs.AI"
      ],
      "primary_category": "cs.AI",
      "comment": "",
      "pdf_url": "https://arxiv.org/pdf/2602.07359v1",
      "published_date": "2026-02-07 04:49:53 UTC",
      "updated_date": "2026-02-07 04:49:53 UTC",
      "processing_status": "completed",
      "attempts": 1,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "llm_backup_calls": 0,
      "last_update": "2026-02-16T05:30:11.538497+00:00"
    },
    {
      "arxiv_id": "2602.10133v1",
      "title": "AgentTrace: A Structured Logging Framework for Agent System Observability",
      "title_zh": "AgentTrace：用于智能体系统可观测性的结构化日志框架",
      "authors": [
        "Adam AlSayyad",
        "Kelvin Yuxiang Huang",
        "Richik Pal"
      ],
      "abstract": "Despite the growing capabilities of autonomous agents powered by large language models (LLMs), their adoption in high-stakes domains remains limited. A key barrier is security: the inherently nondeterministic behavior of LLM agents defies static auditing approaches that have historically underpinned software assurance. Existing security methods, such as proxy-level input filtering and model glassboxing, fail to provide sufficient transparency or traceability into agent reasoning, state changes, or environmental interactions. In this work, we introduce AgentTrace, a dynamic observability and telemetry framework designed to fill this gap. AgentTrace instruments agents at runtime with minimal overhead, capturing a rich stream of structured logs across three surfaces: operational, cognitive, and contextual. Unlike traditional logging systems, AgentTrace emphasizes continuous, introspectable trace capture, designed not just for debugging or benchmarking, but as a foundational layer for agent security, accountability, and real-time monitoring. Our research highlights how AgentTrace can enable more reliable agent deployment, fine-grained risk analysis, and informed trust calibration, thereby addressing critical concerns that have so far limited the use of LLM agents in sensitive environments.",
      "tldr_zh": "该研究提出了AgentTrace，这是一个专为提升大语言模型(LLM)智能体系统可观测性(observability)而设计的动态遥测(telemetry)框架，旨在解决智能体(agents)在敏感领域应用时的安全性与透明度难题。针对LLM智能体因行为不确定性而难以通过传统静态审计进行保障的问题，AgentTrace在运行时对智能体进行插桩，以极低开销捕获涵盖操作(operational)、认知(cognitive)和上下文(contextual)三个维度的结构化日志。不同于侧重调试或基准测试的传统系统，AgentTrace强调持续且可内省的追踪捕获(trace capture)，为智能体系统的安全性、问责制(accountability)和实时监控提供了核心技术支撑。通过实现细粒度的风险分析和信任校准(trust calibration)，该框架有效应对了限制LLM智能体部署的关键因素，为构建更可靠、可信的自主系统奠定了重要基础。",
      "categories": [
        "cs.SE",
        "cs.AI"
      ],
      "primary_category": "cs.SE",
      "comment": "AAAI 2026 Workshop LaMAS",
      "pdf_url": "https://arxiv.org/pdf/2602.10133v1",
      "published_date": "2026-02-07 04:04:59 UTC",
      "updated_date": "2026-02-07 04:04:59 UTC",
      "processing_status": "completed",
      "attempts": 1,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "llm_backup_calls": 0,
      "last_update": "2026-02-16T05:30:44.916144+00:00"
    },
    {
      "arxiv_id": "2602.07343v1",
      "title": "Seeing Roads Through Words: A Language-Guided Framework for RGB-T Driving Scene Segmentation",
      "title_zh": "见词知路：一种用于 RGB-T 驾驶场景分割的语言引导框架",
      "authors": [
        "Ruturaj Reddy",
        "Hrishav Bakul Barua",
        "Junn Yong Loo",
        "Thanh Thi Nguyen",
        "Ganesh Krishnasamy"
      ],
      "abstract": "Robust semantic segmentation of road scenes under adverse illumination, lighting, and shadow conditions remain a core challenge for autonomous driving applications. RGB-Thermal fusion is a standard approach, yet existing methods apply static fusion strategies uniformly across all conditions, allowing modality-specific noise to propagate throughout the network. Hence, we propose CLARITY that dynamically adapts its fusion strategy to the detected scene condition. Guided by vision-language model (VLM) priors, the network learns to modulate each modality's contribution based on the illumination state while leveraging object embeddings for segmentation, rather than applying a fixed fusion policy. We further introduce two mechanisms, i.e., one which preserves valid dark-object semantics that prior noise-suppression methods incorrectly discard, and a hierarchical decoder that enforces structural consistency across scales to sharpen boundaries on thin objects. Experiments on the MFNet dataset demonstrate that CLARITY establishes a new state-of-the-art (SOTA), achieving 62.3% mIoU and 77.5% mAcc.",
      "tldr_zh": "该研究针对自动驾驶在恶劣光照和阴影条件下道路场景分割的鲁棒性挑战，提出了一种名为CLARITY的语言引导框架。与采用静态融合策略的传统RGB-Thermal融合方法不同，CLARITY利用视觉语言模型(VLM)的先验知识，根据检测到的场景光照状态动态调整各模态的贡献。该网络通过对象嵌入(Object Embeddings)指导分割，而非执行固定的融合策略，从而有效抑制了特定模态噪声在网络中的传播。此外，框架引入了保留暗光物体语义的机制以及层次化解码器(Hierarchical Decoder)，在确保多尺度结构一致性的同时提升了细长物体边界的清晰度。实验结果显示，CLARITY在MFNet数据集上达到了新的SOTA水平，实现了62.3%的mIoU和77.5%的mAcc，证明了其在复杂驾驶环境下的优越性能。",
      "categories": [
        "cs.CV",
        "cs.AI",
        "cs.LG",
        "cs.RO"
      ],
      "primary_category": "cs.CV",
      "comment": "",
      "pdf_url": "https://arxiv.org/pdf/2602.07343v1",
      "published_date": "2026-02-07 03:52:04 UTC",
      "updated_date": "2026-02-07 03:52:04 UTC",
      "processing_status": "completed",
      "attempts": 1,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "llm_backup_calls": 0,
      "last_update": "2026-02-16T05:30:19.149169+00:00"
    },
    {
      "arxiv_id": "2602.07342v1",
      "title": "SupChain-Bench: Benchmarking Large Language Models for Real-World Supply Chain Management",
      "title_zh": "SupChain-Bench：面向真实世界供应链管理的大语言模型基准测试",
      "authors": [
        "Shengyue Guan",
        "Yihao Liu",
        "Lang Cao"
      ],
      "abstract": "Large language models (LLMs) have shown promise in complex reasoning and tool-based decision making, motivating their application to real-world supply chain management. However, supply chain workflows require reliable long-horizon, multi-step orchestration grounded in domain-specific procedures, which remains challenging for current models. To systematically evaluate LLM performance in this setting, we introduce SupChain-Bench, a unified real-world benchmark that assesses both supply chain domain knowledge and long-horizon tool-based orchestration grounded in standard operating procedures (SOPs). Our experiments reveal substantial gaps in execution reliability across models. We further propose SupChain-ReAct, an SOP-free framework that autonomously synthesizes executable procedures for tool use, achieving the strongest and most consistent tool-calling performance. Our work establishes a principled benchmark for studying reliable long-horizon orchestration in real-world operational settings and highlights significant room for improvement in LLM-based supply chain agents.",
      "tldr_zh": "该研究针对大语言模型（LLMs）在真实世界供应链管理（Supply Chain Management）中面临的长跨度（long-horizon）、多步工具编排可靠性不足的问题，提出了 SupChain-Bench 基准测试。该基准统一评估了 LLMs 的领域知识以及基于标准操作程序（SOPs）的工具调用能力，实验发现现有模型在执行可靠性上存在显著差距。为提升性能，研究者进一步提出了 SupChain-ReAct 框架，该框架能够在无需 SOPs 的情况下自主合成工具使用程序，取得了最强且最一致的工具调用表现。该工作为供应链运营场景下的可靠编排提供了原则性的评估标准，并揭示了基于 LLM 的供应链智能体（agents）仍具备广阔的优化空间。",
      "categories": [
        "cs.AI"
      ],
      "primary_category": "cs.AI",
      "comment": "",
      "pdf_url": "https://arxiv.org/pdf/2602.07342v1",
      "published_date": "2026-02-07 03:49:25 UTC",
      "updated_date": "2026-02-07 03:49:25 UTC",
      "processing_status": "completed",
      "attempts": 1,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "llm_backup_calls": 0,
      "last_update": "2026-02-16T05:30:59.909254+00:00"
    },
    {
      "arxiv_id": "2602.07339v1",
      "title": "RAPiD: Real-time Deterministic Trajectory Planning via Diffusion Behavior Priors for Safe and Efficient Autonomous Driving",
      "title_zh": "RAPiD：基于扩散行为先验的实时确定性轨迹规划，助力安全高效的自动驾驶",
      "authors": [
        "Ruturaj Reddy",
        "Hrishav Bakul Barua",
        "Junn Yong Loo",
        "Thanh Thi Nguyen",
        "Ganesh Krishnasamy"
      ],
      "abstract": "Diffusion-based trajectory planners have demonstrated strong capability for modeling the multimodal nature of human driving behavior, but their reliance on iterative stochastic sampling poses critical challenges for real-time, safety-critical deployment. In this work, we present RAPiD, a deterministic policy extraction framework that distills a pretrained diffusion-based planner into an efficient policy while eliminating diffusion sampling. Using score-regularized policy optimization, we leverage the score function of a pre-trained diffusion planner as a behavior prior to regularize policy learning. To promote safety and passenger comfort, the policy is optimized using a critic trained to imitate a predictive driver controller, providing dense, safety-focused supervision beyond conventional imitation learning. Evaluations demonstrate that RAPiD achieves competitive performance on closed-loop nuPlan scenarios with an 8x speedup over diffusion baselines, while achieving state-of-the-art generalization among learning-based planners on the interPlan benchmark. The official website of this work is: https://github.com/ruturajreddy/RAPiD.",
      "tldr_zh": "该研究针对基于扩散模型 (Diffusion-based) 的轨迹规划器在实时性和安全性部署中面临的迭代采样挑战，提出了 RAPiD 框架。RAPiD 是一种确定性策略提取 (deterministic policy extraction) 框架，通过蒸馏预训练的扩散规划器，在无需扩散采样的情况下生成高效策略。该框架采用分值正则化策略优化 (score-regularized policy optimization)，将扩散模型的分值函数 (score function) 作为行为先验 (behavior prior) 来约束策略学习。为了提升安全性和舒适性，该策略通过一个模仿预测性驾驶控制器的评价器 (critic) 进行优化，从而提供超越传统模仿学习 (imitation learning) 的高强度安全监督。实验结果表明，RAPiD 在 nuPlan 闭环场景中表现出色，其推理速度比扩散模型基线快 8 倍。此外，RAPiD 在 interPlan 基准测试中展现了学习型规划器中最先进的泛化能力，为自动驾驶提供了实时、确定性的解决方案。",
      "categories": [
        "cs.AI",
        "cs.LG",
        "cs.RO"
      ],
      "primary_category": "cs.AI",
      "comment": "",
      "pdf_url": "https://arxiv.org/pdf/2602.07339v1",
      "published_date": "2026-02-07 03:44:50 UTC",
      "updated_date": "2026-02-07 03:44:50 UTC",
      "processing_status": "completed",
      "attempts": 1,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "llm_backup_calls": 0,
      "last_update": "2026-02-16T05:31:01.013032+00:00"
    },
    {
      "arxiv_id": "2602.07338v1",
      "title": "Intent Mismatch Causes LLMs to Get Lost in Multi-Turn Conversation",
      "title_zh": "意图错配导致大语言模型在多轮对话中“迷失”",
      "authors": [
        "Geng Liu",
        "Fei Zhu",
        "Rong Feng",
        "Changyi Ma",
        "Shiqi Wang",
        "Gaofeng Meng"
      ],
      "abstract": "Multi-turn conversation has emerged as a predominant interaction paradigm for Large Language Models (LLMs). Users often employ follow-up questions to refine their intent, expecting LLMs to adapt dynamically. However, recent research reveals that LLMs suffer a substantial performance drop in multi-turn settings compared to single-turn interactions with fully specified instructions, a phenomenon termed ``Lost in Conversation'' (LiC). While this prior work attributes LiC to model unreliability, we argue that the root cause lies in an intent alignment gap rather than intrinsic capability deficits. In this paper, we first demonstrate that LiC is not a failure of model capability but rather a breakdown in interaction between users and LLMs. We theoretically show that scaling model size or improving training alone cannot resolve this gap, as it arises from structural ambiguity in conversational context rather than representational limitations. To address this, we propose to decouple intent understanding from task execution through a Mediator-Assistant architecture. By utilizing an experience-driven Mediator to explicate user inputs into explicit, well-structured instructions based on historical interaction patterns, our approach effectively bridges the gap between vague user intent and model interpretation. Experimental results demonstrate that this method significantly mitigates performance degradation in multi-turn conversations across diverse LLMs.",
      "tldr_zh": "该研究探讨了大语言模型(LLMs)在多轮对话中性能大幅下降的“对话中迷失”(Lost in Conversation, LiC)现象。与以往将其归因于模型不可靠性的观点不同，作者指出其核心诱因在于“意图匹配失衡”(intent alignment gap)，而非模型内在能力的缺陷。研究通过理论分析证明，仅靠扩大模型规模或改进训练无法解决该问题，因为其源于对话上下文中的结构性歧义。为此，研究提出了一种“中介-助手架构”(Mediator-Assistant architecture)，旨在将意图理解与任务执行过程解耦。该架构利用经验驱动的Mediator，将模糊的用户输入转化为基于历史交互模式的结构化显式指令，有效弥合了意图理解的鸿沟。实验结果显示，该方法在多种LLMs上均显著缓解了多轮对话中的性能退化问题。",
      "categories": [
        "cs.CL",
        "cs.AI"
      ],
      "primary_category": "cs.CL",
      "comment": "",
      "pdf_url": "https://arxiv.org/pdf/2602.07338v1",
      "published_date": "2026-02-07 03:41:04 UTC",
      "updated_date": "2026-02-07 03:41:04 UTC",
      "processing_status": "completed",
      "attempts": 1,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "llm_backup_calls": 0,
      "last_update": "2026-02-16T05:31:06.901545+00:00"
    },
    {
      "arxiv_id": "2602.07333v1",
      "title": "High Fidelity Textual User Representation over Heterogeneous Sources via Reinforcement Learning",
      "title_zh": "通过强化学习在异构源上构建高保真文本用户表示",
      "authors": [
        "Rajat Arora",
        "Ye Tao",
        "Jianqiang Shen",
        "Ping Liu",
        "Muchen Wu",
        "Qianqi Shen",
        "Benjamin Le",
        "Fedor Borisyuk",
        "Jingwei Wu",
        "Wenjing Zhang"
      ],
      "abstract": "Effective personalization on large-scale job platforms requires modeling members based on heterogeneous textual sources, including profiles, professional data, and search activity logs. As recommender systems increasingly adopt Large Language Models (LLMs), creating unified, interpretable, and concise representations from heterogeneous sources becomes critical, especially for latency-sensitive online environments. In this work, we propose a novel Reinforcement Learning (RL) framework to synthesize a unified textual representation for each member. Our approach leverages implicit user engagement signals (e.g., clicks, applies) as the primary reward to distill salient information. Additionally, the framework is complemented by rule-based rewards that enforce formatting and length constraints. Extensive offline experiments across multiple LinkedIn products, one of the world's largest job platforms, demonstrate significant improvements in key downstream business metrics. This work provides a practical, labeling-free, and scalable solution for constructing interpretable user representations that are directly compatible with LLM-based systems.",
      "tldr_zh": "该研究针对大规模招聘平台在个性化推荐中面临的异构文本源整合挑战，提出了一种基于强化学习 (Reinforcement Learning) 的新型框架，用于合成统一且可解释的用户文本表示。随着大语言模型 (LLMs) 在推荐系统中的应用，该方法通过整合个人资料和搜索活动日志等异构数据，有效解决了在线环境下的表征一致性与延迟问题。该框架利用隐式的用户参与信号（如点击和申请行为）作为主要奖励来蒸馏关键信息，并结合基于规则的奖励来强制执行格式与长度约束。作为一种无需人工标注且具备高度扩展性的实用方案，该方法生成的表示能够与基于 LLM 的系统直接兼容。在 LinkedIn 多个产品上进行的广泛实验证明，该框架显著提升了关键的下游业务指标，为构建高保真用户画像提供了重要参考。",
      "categories": [
        "cs.IR",
        "cs.AI",
        "cs.CL",
        "cs.LG"
      ],
      "primary_category": "cs.IR",
      "comment": "",
      "pdf_url": "https://arxiv.org/pdf/2602.07333v1",
      "published_date": "2026-02-07 03:27:55 UTC",
      "updated_date": "2026-02-07 03:27:55 UTC",
      "processing_status": "completed",
      "attempts": 1,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "llm_backup_calls": 0,
      "last_update": "2026-02-16T05:31:08.299772+00:00"
    },
    {
      "arxiv_id": "2602.07322v1",
      "title": "Action-to-Action Flow Matching",
      "title_zh": "动作到动作流匹配",
      "authors": [
        "Jindou Jia",
        "Gen Li",
        "Xiangyu Chen",
        "Tuo An",
        "Yuxuan Hu",
        "Jingliang Li",
        "Xinying Guo",
        "Jianfei Yang"
      ],
      "abstract": "Diffusion-based policies have recently achieved remarkable success in robotics by formulating action prediction as a conditional denoising process. However, the standard practice of sampling from random Gaussian noise often requires multiple iterative steps to produce clean actions, leading to high inference latency that incurs a major bottleneck for real-time control. In this paper, we challenge the necessity of uninformed noise sampling and propose Action-to-Action flow matching (A2A), a novel policy paradigm that shifts from random sampling to initialization informed by the previous action. Unlike existing methods that treat proprioceptive action feedback as static conditions, A2A leverages historical proprioceptive sequences, embedding them into a high-dimensional latent space as the starting point for action generation. This design bypasses costly iterative denoising while effectively capturing the robot's physical dynamics and temporal continuity. Extensive experiments demonstrate that A2A exhibits high training efficiency, fast inference speed, and improved generalization. Notably, A2A enables high-quality action generation in as few as a single inference step (0.56 ms latency), and exhibits superior robustness to visual perturbations and enhanced generalization to unseen configurations. Lastly, we also extend A2A to video generation, demonstrating its broader versatility in temporal modeling. Project site: https://lorenzo-0-0.github.io/A2A_Flow_Matching.",
      "tldr_zh": "该研究提出了Action-to-Action flow matching (A2A)，旨在解决基于扩散(Diffusion-based)的策略在机器人动作预测中因多次迭代去噪导致的推理延迟问题。A2A挑战了从随机高斯噪声采样的传统范式，通过利用历史本体感觉(proprioceptive)序列并将其嵌入高维隐空间，作为动作生成的起始点。这种设计有效捕捉了机器人的物理动力学和时间连续性，从而绕过了昂贵的迭代去噪过程。实验表明，A2A具有极高的训练效率和推理速度，能够在单步推理中实现低至0.56毫秒的延迟。此外，该模型在应对视觉扰动时表现出卓越的鲁棒性，具备更强的泛化能力，并成功扩展到了视频生成领域。",
      "categories": [
        "cs.RO",
        "cs.AI"
      ],
      "primary_category": "cs.RO",
      "comment": "18 pages, 18 figures",
      "pdf_url": "https://arxiv.org/pdf/2602.07322v1",
      "published_date": "2026-02-07 02:39:49 UTC",
      "updated_date": "2026-02-07 02:39:49 UTC",
      "processing_status": "completed",
      "attempts": 1,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "llm_backup_calls": 0,
      "last_update": "2026-02-16T05:31:10.904990+00:00"
    },
    {
      "arxiv_id": "2602.07319v1",
      "title": "Beyond Accuracy: Risk-Sensitive Evaluation of Hallucinated Medical Advice",
      "title_zh": "超越准确性：针对幻觉医疗建议的风险敏感性评估",
      "authors": [
        "Savan Doshi"
      ],
      "abstract": "Large language models are increasingly being used in patient-facing medical question answering, where hallucinated outputs can vary widely in potential harm. However, existing hallucination standards and evaluation metrics focus primarily on factual correctness, treating all errors as equally severe. This obscures clinically relevant failure modes, particularly when models generate unsupported but actionable medical language. We propose a risk-sensitive evaluation framework that quantifies hallucinations through the presence of risk-bearing language, including treatment directives, contraindications, urgency cues, and mentions of high-risk medications. Rather than assessing clinical correctness, our approach evaluates the potential impact of hallucinated content if acted upon. We further combine risk scoring with a relevance measure to identify high-risk, low-grounding failures. We apply this framework to three instruction-tuned language models using controlled patient-facing prompts designed as safety stress tests. Our results show that models with similar surface-level behavior exhibit substantially different risk profiles and that standard evaluation metrics fail to capture these distinctions. These findings highlight the importance of incorporating risk sensitivity into hallucination evaluation and suggest that evaluation validity is critically dependent on task and prompt design.",
      "tldr_zh": "该研究指出，现有的大语言模型（LLMs）幻觉评估标准主要关注事实准确性，忽视了医疗建议中幻觉内容可能带来的潜在危害差异。为此，作者提出了一种风险敏感型评估框架（risk-sensitive evaluation framework），通过识别治疗指令（treatment directives）、禁忌症（contraindications）、紧急提示（urgency cues）和高风险药物等风险性语言来量化幻觉。该方法不仅关注临床正确性，更侧重于评估幻觉内容若被采纳后可能产生的潜在影响，并结合相关性测量以识别高风险、低依据（low-grounding）的失效模式。通过对三种指令微调（instruction-tuned）模型进行安全压力测试，实验发现即使表面性能相似的模型也表现出截然不同的风险特征，而标准评估指标往往无法捕捉这些关键差异。研究结果强调了在医疗幻觉评估中引入风险敏感性的重要性，并指出评估的有效性高度依赖于特定的任务与提示词设计。",
      "categories": [
        "cs.CL",
        "cs.AI"
      ],
      "primary_category": "cs.CL",
      "comment": "",
      "pdf_url": "https://arxiv.org/pdf/2602.07319v1",
      "published_date": "2026-02-07 02:25:44 UTC",
      "updated_date": "2026-02-07 02:25:44 UTC",
      "processing_status": "completed",
      "attempts": 1,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "llm_backup_calls": 0,
      "last_update": "2026-02-16T05:31:18.607303+00:00"
    },
    {
      "arxiv_id": "2602.07311v1",
      "title": "LUCID-SAE: Learning Unified Vision-Language Sparse Codes for Interpretable Concept Discovery",
      "title_zh": "LUCID-SAE：面向可解释概念发现的统一视觉-语言稀疏编码学习",
      "authors": [
        "Difei Gu",
        "Yunhe Gao",
        "Gerasimos Chatzoudis",
        "Zihan Dong",
        "Guoning Zhang",
        "Bangwei Guo",
        "Yang Zhou",
        "Mu Zhou",
        "Dimitris Metaxas"
      ],
      "abstract": "Sparse autoencoders (SAEs) offer a natural path toward comparable explanations across different representation spaces. However, current SAEs are trained per modality, producing dictionaries whose features are not directly understandable and whose explanations do not transfer across domains. In this study, we introduce LUCID (Learning Unified vision-language sparse Codes for Interpretable concept Discovery), a unified vision-language sparse autoencoder that learns a shared latent dictionary for image patch and text token representations, while reserving private capacity for modality-specific details. We achieve feature alignment by coupling the shared codes with a learned optimal transport matching objective without the need of labeling. LUCID yields interpretable shared features that support patch-level grounding, establish cross-modal neuron correspondence, and enhance robustness against the concept clustering problem in similarity-based evaluation. Leveraging the alignment properties, we develop an automated dictionary interpretation pipeline based on term clustering without manual observations. Our analysis reveals that LUCID's shared features capture diverse semantic categories beyond objects, including actions, attributes, and abstract concepts, demonstrating a comprehensive approach to interpretable multimodal representations.",
      "tldr_zh": "该研究提出了 LUCID-SAE，旨在解决当前稀疏自编码器 (SAEs) 因针对单一模态训练而导致的特征难以理解及解释无法跨领域迁移的问题。LUCID 作为一种统一的视觉-语言稀疏自编码器，通过学习图像补丁 (image patch) 和文本标记 (text token) 表征的共享潜字典，同时为模态特定的细节保留私有容量。该框架利用学习到的最优传输 (optimal transport) 匹配目标将共享代码耦合，无需手动标注即可实现特征对齐。实验证明，LUCID 产生的可解释共享特征支持补丁级定位 (patch-level grounding) 并建立了跨模态神经元对应关系，增强了模型在相似性评估中的鲁棒性。研究者还基于术语聚类开发了自动化的字典解释流程，能够无需人工干预地识别特征含义。分析结果显示，LUCID 的共享特征能够捕捉动作、属性和抽象概念等多元语义类别，为构建可解释的多模态表征提供了一种全面且有效的方法。",
      "categories": [
        "cs.CV",
        "cs.AI"
      ],
      "primary_category": "cs.CV",
      "comment": "",
      "pdf_url": "https://arxiv.org/pdf/2602.07311v1",
      "published_date": "2026-02-07 02:01:25 UTC",
      "updated_date": "2026-02-07 02:01:25 UTC",
      "processing_status": "completed",
      "attempts": 1,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "llm_backup_calls": 0,
      "last_update": "2026-02-16T05:31:25.506566+00:00"
    },
    {
      "arxiv_id": "2602.07309v1",
      "title": "Semantic Search At LinkedIn",
      "title_zh": "LinkedIn 语义搜索",
      "authors": [
        "Fedor Borisyuk",
        "Sriram Vasudevan",
        "Muchen Wu",
        "Guoyao Li",
        "Benjamin Le",
        "Shaobo Zhang",
        "Qianqi Kay Shen",
        "Yuchin Juan",
        "Kayhan Behdin",
        "Liming Dong",
        "Kaixu Yang",
        "Shusen Jing",
        "Ravi Pothamsetty",
        "Rajat Arora",
        "Sophie Yanying Sheng",
        "Vitaly Abdrashitov",
        "Yang Zhao",
        "Lin Su",
        "Xiaoqing Wang",
        "Chujie Zheng",
        "Sarang Metkar",
        "Rupesh Gupta",
        "Igor Lapchuk",
        "David N. Racca",
        "Madhumitha Mohan",
        "Yanbo Li",
        "Haojun Li",
        "Saloni Gandhi",
        "Xueying Lu",
        "Chetan Bhole",
        "Ali Hooshmand",
        "Xin Yang",
        "Raghavan Muthuregunathan",
        "Jiajun Zhang",
        "Mathew Teoh",
        "Adam Coler",
        "Abhinav Gupta",
        "Xiaojing Ma",
        "Sundara Raman Ramachandran",
        "Morteza Ramezani",
        "Yubo Wang",
        "Lijuan Zhang",
        "Richard Li",
        "Jian Sheng",
        "Chanh Nguyen",
        "Yen-Chi Chen",
        "Chuanrui Zhu",
        "Claire Zhang",
        "Jiahao Xu",
        "Deepti Kulkarni",
        "Qing Lan",
        "Arvind Subramaniam",
        "Ata Fatahibaarzi",
        "Steven Shimizu",
        "Yanning Chen",
        "Zhipeng Wang",
        "Ran He",
        "Zhengze Zhou",
        "Qingquan Song",
        "Yun Dai",
        "Caleb Johnson",
        "Ping Liu",
        "Shaghayegh Gharghabi",
        "Gokulraj Mohanasundaram",
        "Juan Bottaro",
        "Santhosh Sachindran",
        "Qi Guo",
        "Yunxiang Ren",
        "Chengming Jiang",
        "Di Mo",
        "Luke Simon",
        "Jianqiang Shen",
        "Jingwei Wu",
        "Wenjing Zhang"
      ],
      "abstract": "Semantic search with large language models (LLMs) enables retrieval by meaning rather than keyword overlap, but scaling it requires major inference efficiency advances. We present LinkedIn's LLM-based semantic search framework for AI Job Search and AI People Search, combining an LLM relevance judge, embedding-based retrieval, and a compact Small Language Model trained via multi-teacher distillation to jointly optimize relevance and engagement. A prefill-oriented inference architecture co-designed with model pruning, context compression, and text-embedding hybrid interactions boosts ranking throughput by over 75x under a fixed latency constraint while preserving near-teacher-level NDCG, enabling one of the first production LLM-based ranking systems with efficiency comparable to traditional approaches and delivering significant gains in quality and user engagement.",
      "tldr_zh": "该研究介绍了 LinkedIn 为 AI Job Search 和 AI People Search 开发的基于大语言模型(LLMs)的语义搜索框架，旨在解决大规模应用中的推理效率瓶颈。该系统结合了 LLM relevance judge、embedding-based retrieval 以及通过多教师蒸馏(multi-teacher distillation)训练的紧凑型小语言模型(Small Language Model)，以同步优化搜索相关性与用户参与度。通过共同设计面向预填充(prefill-oriented)的推理架构，并集成模型剪枝(model pruning)、上下文压缩(context compression)和文本嵌入混合交互技术，该框架在固定延迟约束下将排序吞吐量提升了 75 倍以上。实验表明，该系统在保持接近教师模型水平的 NDCG 指标的同时，实现了与传统方法相当的运行效率，并在生产环境中显著提升了搜索质量和用户交互。",
      "categories": [
        "cs.IR",
        "cs.AI",
        "cs.LG"
      ],
      "primary_category": "cs.IR",
      "comment": "",
      "pdf_url": "https://arxiv.org/pdf/2602.07309v1",
      "published_date": "2026-02-07 01:59:03 UTC",
      "updated_date": "2026-02-07 01:59:03 UTC",
      "processing_status": "completed",
      "attempts": 1,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "llm_backup_calls": 0,
      "last_update": "2026-02-16T05:31:26.640564+00:00"
    },
    {
      "arxiv_id": "2602.07308v1",
      "title": "Adaptive Scaffolding for Cognitive Engagement in an Intelligent Tutoring System",
      "title_zh": "智能教学系统中促进认知参与的自适应支架",
      "authors": [
        "Sutapa Dey Tithi",
        "Nazia Alam",
        "Tahreem Yasir",
        "Yang Shi",
        "Xiaoyi Tian",
        "Min Chi",
        "Tiffany Barnes"
      ],
      "abstract": "The ICAP framework defines four cognitive engagement levels: Passive, Active, Constructive, and Interactive, where increased cognitive engagement can yield improved learning. However, personalizing learning activities that elicit the optimal level of cognitive engagement remains a key challenge in intelligent tutoring systems (ITS). In this work, we develop and evaluate a system that adaptively scaffolds cognitive engagement by dynamically selecting worked examples in two different ICAP modes: (active) Guided examples and (constructive) Buggy examples. We compare Bayesian Knowledge Tracing (BKT) and Deep Reinforcement Learning (DRL) as adaptive methods against a non-adaptive baseline method for selecting example type in a logic ITS. Our experiment with 113 students demonstrates that both adaptive policies significantly improved student performance on test problems. BKT yielded the largest improvement in posttest scores for low prior knowledge students, helping them catch up with their high prior knowledge peers, whereas DRL yielded significantly higher posttest scores among high prior knowledge students. This paper contributes new insights into the complex interactions of cognitive engagement and adaptivity and their results on learning outcomes.",
      "tldr_zh": "该研究探讨了在智能导师系统(Intelligent Tutoring Systems)中如何利用ICAP框架个性化学生的认知参与水平，以提升学习效果。作者开发并评估了一个自适应支架系统，通过动态选择Guided examples（主动模式）和Buggy examples（构建模式）来调节认知参与度。研究对比了贝叶斯知识追踪(Bayesian Knowledge Tracing)和深度强化学习(Deep Reinforcement Learning)两种自适应方法。实验结果显示，相较于非自适应基准，这两种策略均显著提高了113名参与学生的测试成绩。具体而言，BKT对低先验知识学生的提升最为显著，有效缩小了其与高先验知识学生之间的差距，而DRL则使高先验知识学生获得了更高的后测分数。该研究为认知参与、自适应技术及其对学习成果的影响提供了新的见解。",
      "categories": [
        "cs.AI"
      ],
      "primary_category": "cs.AI",
      "comment": "",
      "pdf_url": "https://arxiv.org/pdf/2602.07308v1",
      "published_date": "2026-02-07 01:51:46 UTC",
      "updated_date": "2026-02-07 01:51:46 UTC",
      "processing_status": "completed",
      "attempts": 1,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "llm_backup_calls": 0,
      "last_update": "2026-02-16T05:31:30.307371+00:00"
    },
    {
      "arxiv_id": "2602.07307v1",
      "title": "LIT-GRAPH: Evaluating Deep vs. Shallow Graph Embeddings for High-Quality Text Recommendation in Domain-Specific Knowledge Graphs",
      "title_zh": "LIT-GRAPH：面向领域特定知识图谱中高质量文本推荐的深层与浅层图嵌入评估",
      "authors": [
        "Nirmal Gelal",
        "Chloe Snow",
        "Kathleen M. Jagodnik",
        "Ambyr Rios",
        "Hande Küçük McGinty"
      ],
      "abstract": "This study presents LIT-GRAPH (Literature Graph for Recommendation and Pedagogical Heuristics), a novel knowledge graph-based recommendation system designed to scaffold high school English teachers in selecting diverse, pedagogically aligned instructional literature. The system is built upon an ontology for English literature, addressing the challenge of curriculum stagnation, where we compare four graph embedding paradigms: DeepWalk, Biased Random Walk (BRW), Hybrid (concatenated DeepWalk and BRW vectors), and the deep model Relational Graph Convolutional Network (R-GCN). Results reveal a critical divergence: while shallow models excelled in structural link prediction, R-GCN dominated semantic ranking. By leveraging relation-specific message passing, the deep model prioritizes pedagogical relevance over raw connectivity, resulting in superior, high-quality, domain-specific recommendations.",
      "tldr_zh": "该研究提出了LIT-GRAPH，一种新型的基于知识图谱(Knowledge Graph)的推荐系统，旨在协助高中英语教师选择具有多样性且符合教学要求的教学文献。该系统构建在英语文学本体(Ontology)之上以解决课程停滞挑战，并对比了DeepWalk、Biased Random Walk (BRW)、Hybrid以及深度模型Relational Graph Convolutional Network (R-GCN)四种图嵌入范式。实验结果揭示了关键的性能分歧：浅层模型在结构化链接预测(Link Prediction)方面表现优异，而R-GCN在语义排序(Semantic Ranking)中占据主导地位。通过利用特定关系的消息传递(Message Passing)机制，深度模型能够优先考虑教学相关性而非简单的结构连接性。最终，LIT-GRAPH凭借其深度嵌入模型在特定领域的文献推荐中实现了更高质量的输出，为教学启发式决策提供了有力支持。",
      "categories": [
        "cs.IR",
        "cs.AI"
      ],
      "primary_category": "cs.IR",
      "comment": "",
      "pdf_url": "https://arxiv.org/pdf/2602.07307v1",
      "published_date": "2026-02-07 01:42:54 UTC",
      "updated_date": "2026-02-07 01:42:54 UTC",
      "processing_status": "completed",
      "attempts": 1,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "llm_backup_calls": 0,
      "last_update": "2026-02-16T05:31:31.251523+00:00"
    },
    {
      "arxiv_id": "2602.07303v1",
      "title": "KRONE: Hierarchical and Modular Log Anomaly Detection",
      "title_zh": "KRONE：层级化与模块化日志异常检测",
      "authors": [
        "Lei Ma",
        "Jinyang Liu",
        "Tieying Zhang",
        "Peter M. VanNostrand",
        "Dennis M. Hofmann",
        "Lei Cao",
        "Elke A. Rundensteiner",
        "Jianjun Chen"
      ],
      "abstract": "Log anomaly detection is crucial for uncovering system failures and security risks. Although logs originate from nested component executions with clear boundaries, this structure is lost when they are stored as flat sequences. As a result, state-of-the-art methods risk missing true dependencies within executions while learning spurious ones across unrelated events. We propose KRONE, the first hierarchical anomaly detection framework that automatically derives execution hierarchies from flat logs for modular multi-level anomaly detection. At its core, the KRONE Log Abstraction Model captures application-specific semantic hierarchies from log data. This hierarchy is then leveraged to recursively decompose log sequences into multiple levels of coherent execution chunks, referred to as KRONE Seqs, transforming sequence-level anomaly detection into a set of modular KRONE Seq-level detection tasks. For each test KRONE Seq, KRONE employs a hybrid modular detection mechanism that dynamically routes between an efficient level-independent Local-Context detector, which rapidly filters normal sequences, and a Nested-Aware detector that incorporates cross-level semantic dependencies and supports LLM-based anomaly detection and explanation. KRONE further optimizes hierarchical detection through cached result reuse and early-exit strategies. Experiments on three public benchmarks and one industrial dataset from ByteDance Cloud demonstrate that KRONE achieves consistent improvements in detection accuracy, F1-score, data efficiency, resource efficiency, and interpretability. KRONE improves the F1-score by more than 10 percentage points over prior methods while reducing LLM usage to only a small fraction of the test data.",
      "tldr_zh": "该研究提出了KRONE，这是首个能够从扁平日志（flat logs）中自动推导执行层级结构的层次化日志异常检测框架，旨在解决现有方法在处理嵌套组件执行时丢失结构信息而导致的检测误差。该框架的核心是KRONE Log Abstraction Model，它通过捕获特定应用的语义层级，将复杂的日志序列递归分解为多级连贯的执行块（KRONE Seqs），从而实现模块化的多级异常检测。在检测机制上，KRONE采用了结合本地上下文检测器（Local-Context detector）和嵌套感知检测器（Nested-Aware detector）的混合模式，并支持基于大语言模型（LLM）的异常分析与解释。此外，KRONE通过缓存重用和早停策略（early-exit strategies）优化了检测效率。在三个公开数据集和字节跳动云（ByteDance Cloud）工业数据集上的实验表明，KRONE在检测准确率和F1-score上均有显著提升，其中F1-score比现有方法提高超过10个百分点，同时大幅降低了计算资源消耗。",
      "categories": [
        "cs.DB",
        "cs.AI",
        "cs.SE"
      ],
      "primary_category": "cs.DB",
      "comment": "",
      "pdf_url": "https://arxiv.org/pdf/2602.07303v1",
      "published_date": "2026-02-07 01:30:19 UTC",
      "updated_date": "2026-02-07 01:30:19 UTC",
      "processing_status": "completed",
      "attempts": 1,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "llm_backup_calls": 0,
      "last_update": "2026-02-16T05:31:40.810718+00:00"
    },
    {
      "arxiv_id": "2602.07298v2",
      "title": "Principled Synthetic Data Enables the First Scaling Laws for LLMs in Recommendation",
      "title_zh": "规范化合成数据助力实现推荐领域大语言模型的首个缩放法则",
      "authors": [
        "Benyu Zhang",
        "Qiang Zhang",
        "Jianpeng Cheng",
        "Hong-You Chen",
        "Qifei Wang",
        "Wei Sun",
        "Shen Li",
        "Jia Li",
        "Jiahao Wu",
        "Xiangjun Fan",
        "Hong Yan"
      ],
      "abstract": "Large Language Models (LLMs) represent a promising frontier for recommender systems, yet their development has been impeded by the absence of predictable scaling laws, which are crucial for guiding research and optimizing resource allocation. We hypothesize that this may be attributed to the inherent noise, bias, and incompleteness of raw user interaction data in prior continual pre-training (CPT) efforts. This paper introduces a novel, layered framework for generating high-quality synthetic data that circumvents such issues by creating a curated, pedagogical curriculum for the LLM. We provide powerful, direct evidence for the utility of our curriculum by showing that standard sequential models trained on our principled synthetic data significantly outperform ($+130\\%$ on recall@100 for SasRec) models trained on real data in downstream ranking tasks, demonstrating its superiority for learning generalizable user preference patterns. Building on this, we empirically demonstrate, for the first time, robust power-law scaling for an LLM that is continually pre-trained on our high-quality, recommendation-specific data. Our experiments reveal consistent and predictable perplexity reduction across multiple synthetic data modalities. These findings establish a foundational methodology for reliable scaling LLM capabilities in the recommendation domain, thereby shifting the research focus from mitigating data deficiencies to leveraging high-quality, structured information.",
      "tldr_zh": "该研究针对大型语言模型 (LLMs) 在推荐系统领域缺乏可预测扩展定律 (Scaling Laws) 的难题，提出了一种分层的、用于生成高质量合成数据的框架。作者认为原始用户交互数据中的噪声、偏差和不完整性阻碍了扩展定律的显现，因此通过构建一种启发式的课程学习 (Pedagogical Curriculum) 方式来优化持续预训练 (CPT) 过程。实验结果表明，在这些原则性合成数据上训练的标准序列模型在下游排名任务中显著优于基于真实数据训练的模型，例如 SasRec 在 Recall@100 指标上提升了 130%，证明了该方法在学习通用用户偏好模式方面的卓越性。该研究首次在推荐领域实证了 LLM 的鲁棒幂律扩展关系，在多种合成数据模态下实现了持续且可预测的困惑度 (Perplexity) 降低。这一发现为在推荐领域可靠地扩展 LLM 能力建立了基础方法论，将研究重心从缓解数据缺陷转向利用高质量的结构化信息。",
      "categories": [
        "cs.IR",
        "cs.AI"
      ],
      "primary_category": "cs.IR",
      "comment": "added more results on scaling law analysis",
      "pdf_url": "https://arxiv.org/pdf/2602.07298v2",
      "published_date": "2026-02-07 01:15:15 UTC",
      "updated_date": "2026-02-12 21:47:09 UTC",
      "processing_status": "completed",
      "attempts": 1,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "llm_backup_calls": 0,
      "last_update": "2026-02-16T05:31:48.996729+00:00"
    },
    {
      "arxiv_id": "2602.07297v1",
      "title": "Progressive Searching for Retrieval in RAG",
      "title_zh": "RAG 检索中的渐进式搜索",
      "authors": [
        "Taehee Jeong",
        "Xingzhe Zhao",
        "Peizu Li",
        "Markus Valvur",
        "Weihua Zhao"
      ],
      "abstract": "Retrieval Augmented Generation (RAG) is a promising technique for mitigating two key limitations of large language models (LLMs): outdated information and hallucinations. RAG system stores documents as embedding vectors in a database. Given a query, search is executed to find the most related documents. Then, the topmost matching documents are inserted into LLMs' prompt to generate a response. Efficient and accurate searching is critical for RAG to get relevant information. We propose a cost-effective searching algorithm for retrieval process. Our progressive searching algorithm incrementally refines the candidate set through a hierarchy of searches, starting from low-dimensional embeddings and progressing into a higher, target-dimensionality. This multi-stage approach reduces retrieval time while preserving the desired accuracy. Our findings demonstrate that progressive search in RAG systems achieves a balance between dimensionality, speed, and accuracy, enabling scalable and high-performance retrieval even for large databases.",
      "tldr_zh": "该研究针对大语言模型(LLMs)面临的信息过期和幻觉问题，探讨了检索增强生成(RAG)中检索过程的效率与准确性。作者提出了一种具有成本效益的Progressive Searching算法，通过层次化的搜索方式增量地细化候选文档集。该方法首先利用低维度的Embedding进行初步筛选，随后逐步进展到更高维度的目标维度，从而在多阶段过程中显著减少检索时间。实验结果证明，Progressive Searching在检索维度、速度和准确性之间达成了理想的平衡。该算法不仅能在保持检索精度的同时提高效率，还为大规模数据库提供了具备可扩展性的高性能检索解决方案。",
      "categories": [
        "cs.IR",
        "cs.AI"
      ],
      "primary_category": "cs.IR",
      "comment": "",
      "pdf_url": "https://arxiv.org/pdf/2602.07297v1",
      "published_date": "2026-02-07 01:12:53 UTC",
      "updated_date": "2026-02-07 01:12:53 UTC",
      "processing_status": "completed",
      "attempts": 1,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "llm_backup_calls": 0,
      "last_update": "2026-02-16T05:31:51.308397+00:00"
    },
    {
      "arxiv_id": "2602.07294v2",
      "title": "Fin-RATE: A Real-world Financial Analytics and Tracking Evaluation Benchmark for LLMs on SEC Filings",
      "title_zh": "Fin-RATE：基于 SEC 文件的真实场景金融分析与跟踪评估大语言模型基准",
      "authors": [
        "Yidong Jiang",
        "Junrong Chen",
        "Eftychia Makri",
        "Jialin Chen",
        "Peiwen Li",
        "Ali Maatouk",
        "Leandros Tassiulas",
        "Eliot Brenner",
        "Bing Xiang",
        "Rex Ying"
      ],
      "abstract": "With the increasing deployment of Large Language Models (LLMs) in the finance domain, LLMs are increasingly expected to parse complex regulatory disclosures. However, existing benchmarks often focus on isolated details, failing to reflect the complexity of professional analysis that requires synthesizing information across multiple documents, reporting periods, and corporate entities. Furthermore, these benchmarks do not disentangle whether errors arise from retrieval failures, generation inaccuracies, domain-specific reasoning mistakes, or misinterpretation of the query or context, making it difficult to precisely diagnose performance bottlenecks. To bridge these gaps, we introduce Fin-RATE, a benchmark built on U.S. Securities and Exchange Commission (SEC) filings and mirroring financial analyst workflows through three pathways: detail-oriented reasoning within individual disclosures, cross-entity comparison under shared topics, and longitudinal tracking of the same firm across reporting periods. We benchmark 17 leading LLMs, spanning open-source, closed-source, and finance-specialized models, under both ground-truth context and retrieval-augmented settings. Results show substantial performance degradation, with accuracy dropping by 18.60\\% and 14.35\\% as tasks shift from single-document reasoning to longitudinal and cross-entity analysis. This degradation is driven by increased comparison hallucinations, temporal and entity mismatches, and is further reflected in declines in reasoning quality and factual consistency--limitations that existing benchmarks have yet to formally categorize or quantify.",
      "tldr_zh": "该研究提出了 Fin-RATE，这是一个基于美国证券交易委员会 (SEC) 文件的金融分析与跟踪评估基准，旨在模拟现实中金融分析师处理复杂监管披露的工作流程。Fin-RATE 通过三个维度对 Large Language Models (LLMs) 进行测试：单份披露文件中的细节推理、相同主题下的跨实体 (cross-entity) 比较，以及同一公司跨报告期的纵向跟踪 (longitudinal tracking)。研究在真实背景和检索增强生成 (RAG) 环境下对 17 种领先的 LLMs 进行了基准测试，包括开源、闭源和金融专用模型。实验结果表明，当任务从单文档推理转向纵向和跨实体分析时，模型准确率分别显著下降了 18.60% 和 14.35%。研究发现这种性能退化主要是由比较幻觉 (comparison hallucinations)、时间与实体错配以及推理质量下降所驱动的。Fin-RATE 有效地量化了现有基准尚未正式分类的局限性，为金融领域大模型的专业分析能力与性能瓶颈诊断提供了重要工具。",
      "categories": [
        "cs.CE",
        "cs.AI"
      ],
      "primary_category": "cs.CE",
      "comment": "",
      "pdf_url": "https://arxiv.org/pdf/2602.07294v2",
      "published_date": "2026-02-07 00:54:37 UTC",
      "updated_date": "2026-02-12 09:29:27 UTC",
      "processing_status": "completed",
      "attempts": 1,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "llm_backup_calls": 0,
      "last_update": "2026-02-16T05:31:55.602386+00:00"
    },
    {
      "arxiv_id": "2602.07284v1",
      "title": "Imagining the Alien: Human Projections and Cognitive Limitations",
      "title_zh": "想象外星生命：人类投射与认知局限",
      "authors": [
        "S. G. Djorgovski"
      ],
      "abstract": "Imagining what life on other planets, and intelligent life in particular, may be like is a long-running theme in human culture. It is a manifestation of the innate human curiosity about the Cosmos, and it has inspired numerous works of art and folklore, including whole literary and other media genres. It is a profound question, with philosophical and existential implications. There is also an obvious connection with religious beliefs, as gods and other superhuman beings were imagined in the heavens. Speculations about alien beings grew in time, and today, it is a scientific subject of astrobiology, and it is pursued through serious searches for life and intelligence in the universe. However, almost all imaginings of the alien map terrestrial life forms and human cultural, historical, and psychological phenomena to the putative aliens. This lack of individual and collective imagination may reflect our biological and cultural evolution, as our minds are formed through our experiences, perceptions of the world, and interactions with our terrestrial and human environments. As such, imagining aliens is mainly a cultural phenomenon and may reflect the intrinsic cognitive limitations of the human mind. Interestingly, we did create what is effectively an alien intelligence on this planet in the form of now rapidly evolving Artificial Intelligence (AI). As its capabilities grow, it may give us new insights into what extraterrestrial advanced intelligences may be like.",
      "tldr_zh": "该研究探讨了人类对地外智慧生命的想象，认为这一长期存在的文化主题反映了人类对宇宙的先天好奇心及其带来的哲学与存在主义思考。尽管地外生命已成为天体生物学(Astrobiology)的研究课题，但目前绝大多数想象仍局限于将地球生命形式及人类的文化、历史和心理现象投射到假设的外星生物身上。这种想象力的匮乏揭示了人类思维的内在认知局限性(Cognitive Limitations)，即我们的心智是由在地球环境中的进化、感知和互动经验所塑造的。因此，想象外星生命在很大程度上是一种反映人类自身局限的文化现象。研究进一步指出，人类在地球上创造的快速演进的人工智能(Artificial Intelligence)本质上提供了一种“外星智能”参照。随着其能力的不断增强，人工智能或许能为我们理解真正的地外先进智慧生命提供全新的视角和洞察。",
      "categories": [
        "astro-ph.IM",
        "cs.AI",
        "physics.pop-ph"
      ],
      "primary_category": "astro-ph.IM",
      "comment": "11 pages, from the refereed proceedings of the Inspiration of Astronomical Phenomena XII (INSAP XII) conference held in Corfu, Greece, May 2024, eds. N. Campion, J. Hatch, H. Henry, C. Impey and V. Shrimplin",
      "pdf_url": "https://arxiv.org/pdf/2602.07284v1",
      "published_date": "2026-02-07 00:22:48 UTC",
      "updated_date": "2026-02-07 00:22:48 UTC",
      "processing_status": "completed",
      "attempts": 1,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "llm_backup_calls": 0,
      "last_update": "2026-02-16T05:31:59.703404+00:00"
    },
    {
      "arxiv_id": "2602.07278v1",
      "title": "Laplacian-LoRA: Delaying Oversmoothing in Deep GCNs via Spectral Low-Rank Adaptation",
      "title_zh": "Laplacian-LoRA：通过谱低秩自适应延缓深层图卷积网络中的过平滑",
      "authors": [
        "Sai Vamsi Alisetti"
      ],
      "abstract": "Oversmoothing is a fundamental limitation of deep graph convolutional networks (GCNs), causing node representations to collapse as depth increases. While many prior approaches mitigate this effect through architectural modifications or residual mechanisms, the underlying spectral cause of oversmoothing is often left implicit. We propose Laplacian-LoRA, a simple and interpretable low-rank spectral adaptation of standard GCNs. Rather than redesigning message passing, Laplacian-LoRA introduces a learnable, spectrally anchored correction to the fixed Laplacian propagation operator, selectively weakening contraction while preserving stability and the low-pass inductive bias. Across multiple benchmark datasets and depths, Laplacian-LoRA consistently delays the onset of oversmoothing, extending the effective depth of GCNs by up to a factor of two. Embedding variance diagnostics confirm that these gains arise from delayed representational collapse, while learned spectral analysis demonstrates that the correction is smooth, bounded, and well behaved. Our results show that oversmoothing is a depth-dependent spectral phenomenon that can be systematically delayed through modest, low-rank adaptation of the graph propagation operator.",
      "tldr_zh": "该研究针对深度图卷积网络 (GCNs) 中普遍存在的过平滑 (Oversmoothing) 问题，提出了 Laplacian-LoRA，一种简单且可解释的标准 GCNs 低秩谱自适应 (Low-rank spectral adaptation) 方法。与重新设计消息传递机制不同，Laplacian-LoRA 对固定的拉普拉斯传播算子 (Laplacian propagation operator) 引入了可学习且谱锚定的修正，在保留稳定性及低通归纳偏置 (Low-pass inductive bias) 的同时，有选择地削弱了节点表示的收缩。在多个基准数据集和不同深度的实验表明，Laplacian-LoRA 能够显著延缓过平滑的发生，将 GCNs 的有效深度提升了至多两倍。嵌入方差诊断 (Embedding variance diagnostics) 进一步证实了这些收益源于表征崩溃的延迟，而学习到的谱分析表明该修正具有平滑且有界的良好特性。该研究结果证明，过平滑是一种与深度相关的谱现象，可以通过对图传播算子进行适度的低秩自适应调整来系统性地延缓。",
      "categories": [
        "cs.LG",
        "cs.AI"
      ],
      "primary_category": "cs.LG",
      "comment": "4 pages",
      "pdf_url": "https://arxiv.org/pdf/2602.07278v1",
      "published_date": "2026-02-07 00:03:19 UTC",
      "updated_date": "2026-02-07 00:03:19 UTC",
      "processing_status": "completed",
      "attempts": 1,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "llm_backup_calls": 0,
      "last_update": "2026-02-16T05:32:01.798763+00:00"
    },
    {
      "arxiv_id": "2602.07276v1",
      "title": "Steer2Adapt: Dynamically Composing Steering Vectors Elicits Efficient Adaptation of LLMs",
      "title_zh": "Steer2Adapt：通过动态组合引导向量实现大语言模型的高效适配",
      "authors": [
        "Pengrui Han",
        "Xueqiang Xu",
        "Keyang Xuan",
        "Peiyang Song",
        "Siru Ouyang",
        "Runchu Tian",
        "Yuqing Jiang",
        "Cheng Qian",
        "Pengcheng Jiang",
        "Jiashuo Sun",
        "Junxia Cui",
        "Ming Zhong",
        "Ge Liu",
        "Jiawei Han",
        "Jiaxuan You"
      ],
      "abstract": "Activation steering has emerged as a promising approach for efficiently adapting large language models (LLMs) to downstream behaviors. However, most existing steering methods rely on a single static direction per task or concept, making them inflexible under task variation and inadequate for complex tasks that require multiple coordinated capabilities. To address this limitation, we propose STEER2ADAPT, a lightweight framework that adapts LLMs by composing steering vectors rather than learning new ones from scratch. In many domains (e.g., reasoning or safety), tasks share a small set of underlying concept dimensions. STEER2ADAPT captures these dimensions as a reusable, low-dimensional semantic prior subspace, and adapts to new tasks by dynamically discovering a linear combination of basis vectors from only a handful of examples. Experiments across 9 tasks and 3 models in both reasoning and safety domains demonstrate the effectiveness of STEER2ADAPT, achieving an average improvement of 8.2%. Extensive analyses further show that STEER2ADAPT is a data-efficient, stable, and transparent inference-time adaptation method for LLMs.",
      "tldr_zh": "该研究提出了Steer2Adapt，这是一个旨在提升大语言模型(LLMs)下游任务适应能力的轻量级框架。针对现有Activation steering方法在处理复杂任务时表现出的僵化与能力协调不足等局限，Steer2Adapt通过组合现有的转向向量而非从头训练来优化模型表现。该框架将不同领域的任务属性捕捉为可重用的低维语义先验子空间(semantic prior subspace)，并仅需极少量示例即可动态发现基向量的线性组合以适应新任务。在涉及推理和安全领域的9项任务及3种模型上的实验结果显示，Steer2Adapt实现了8.2%的平均性能提升。该方法被证明是一种高效、稳定且具备透明度的推理阶段(inference-time)自适应技术。",
      "categories": [
        "cs.AI",
        "cs.CL",
        "cs.LG"
      ],
      "primary_category": "cs.AI",
      "comment": "",
      "pdf_url": "https://arxiv.org/pdf/2602.07276v1",
      "published_date": "2026-02-07 00:00:50 UTC",
      "updated_date": "2026-02-07 00:00:50 UTC",
      "processing_status": "completed",
      "attempts": 1,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "llm_backup_calls": 0,
      "last_update": "2026-02-16T05:32:04.904831+00:00"
    },
    {
      "arxiv_id": "2602.07274v1",
      "title": "TermiGen: High-Fidelity Environment and Robust Trajectory Synthesis for Terminal Agents",
      "title_zh": "TermiGen：面向终端智能体的高保真环境与鲁棒轨迹合成",
      "authors": [
        "Kaijie Zhu",
        "Yuzhou Nie",
        "Yijiang Li",
        "Yiming Huang",
        "Jialian Wu",
        "Jiang Liu",
        "Ximeng Sun",
        "Zhenfei Yin",
        "Lun Wang",
        "Zicheng Liu",
        "Emad Barsoum",
        "William Yang Wang",
        "Wenbo Guo"
      ],
      "abstract": "Executing complex terminal tasks remains a significant challenge for open-weight LLMs, constrained by two fundamental limitations. First, high-fidelity, executable training environments are scarce: environments synthesized from real-world repositories are not diverse and scalable, while trajectories synthesized by LLMs suffer from hallucinations. Second, standard instruction tuning uses expert trajectories that rarely exhibit simple mistakes common to smaller models. This creates a distributional mismatch, leaving student models ill-equipped to recover from their own runtime failures. To bridge these gaps, we introduce TermiGen, an end-to-end pipeline for synthesizing verifiable environments and resilient expert trajectories. Termi-Gen first generates functionally valid tasks and Docker containers via an iterative multi-agent refinement loop. Subsequently, we employ a Generator-Critic protocol that actively injects errors during trajectory collection, synthesizing data rich in error-correction cycles. Fine-tuned on this TermiGen-generated dataset, our TermiGen-Qwen2.5-Coder-32B achieves a 31.3% pass rate on TerminalBench. This establishes a new open-weights state-of-the-art, outperforming existing baselines and notably surpassing capable proprietary models such as o4-mini. Dataset is avaiable at https://github.com/ucsb-mlsec/terminal-bench-env.",
      "tldr_zh": "该研究针对开源权重 LLMs 在执行复杂终端任务时面临的高保真环境稀缺和轨迹分布偏差问题，提出了端到端管道 TermiGen。该框架通过迭代式多智能体优化循环生成功能有效的任务和 Docker 容器，并采用 Generator-Critic 协议在轨迹采集过程中主动注入错误，从而合成包含错误修正周期的韧性专家轨迹。实验结果显示，基于 TermiGen 数据集微调的 TermiGen-Qwen2.5-Coder-32B 在 TerminalBench 上达到了 31.3% 的通过率，创下了开源模型的新 SOTA 纪录。这一表现不仅超越了现有基线模型，甚至优于 o4-mini 等高性能闭源模型，显著提升了终端智能体在真实环境中的鲁棒性和故障恢复能力。",
      "categories": [
        "cs.AI"
      ],
      "primary_category": "cs.AI",
      "comment": "",
      "pdf_url": "https://arxiv.org/pdf/2602.07274v1",
      "published_date": "2026-02-06 23:56:50 UTC",
      "updated_date": "2026-02-06 23:56:50 UTC",
      "processing_status": "completed",
      "attempts": 1,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "llm_backup_calls": 0,
      "last_update": "2026-02-16T05:32:08.711037+00:00"
    },
    {
      "arxiv_id": "2602.07267v1",
      "title": "BRIDGE: Predicting Human Task Completion Time From Model Performance",
      "title_zh": "BRIDGE：基于模型性能的人类任务完成时间预测",
      "authors": [
        "Fengyuan Liu",
        "Jay Gala",
        "Nilaksh",
        "Dzmitry Bahdanau",
        "Siva Reddy",
        "Hugo Larochelle"
      ],
      "abstract": "Evaluating the real-world capabilities of AI systems requires grounding benchmark performance in human-interpretable measures of task difficulty. Existing approaches that rely on direct human task completion time annotations are costly, noisy, and difficult to scale across benchmarks. In this work, we propose BRIDGE, a unified psychometric framework that learns the latent difficulty scale from model responses and anchors it to human task completion time. Using a two-parameter logistic Item Response Theory model, we jointly estimate latent task difficulty and model capability from model performance data across multiple benchmarks. We demonstrate that latent task difficulty varies linearly with the logarithm of human completion time, allowing human task completion time to be inferred for new benchmarks from model performance alone. Leveraging this alignment, we forecast frontier model capabilities in terms of human task length and independently reproduce METR's exponential scaling results, with the 50% solvable task horizon doubling approximately every 6 months.",
      "tldr_zh": "该研究提出了 BRIDGE，这是一个统一的心理测量框架 (psychometric framework)，旨在通过模型性能预测人类完成任务所需的时间，以解决现有标注方法成本高且难以扩展的问题。该框架利用两参数逻辑项目反应理论 (two-parameter logistic Item Response Theory) 模型，从多项基准测试的模型响应中联合估计任务的潜在难度和模型能力。研究发现，潜在任务难度与人类耗时的对数呈线性变化，这使得研究者能够仅凭模型性能推断出新基准测试的人类完成时间。通过这种对齐机制，BRIDGE 成功预测了前沿模型在处理复杂任务方面的能力演进，并独立复现了 METR 的指数缩放结果，即模型可解决任务的难度跨度大约每 6 个月翻一倍。",
      "categories": [
        "cs.AI",
        "cs.CL",
        "cs.LG"
      ],
      "primary_category": "cs.AI",
      "comment": "",
      "pdf_url": "https://arxiv.org/pdf/2602.07267v1",
      "published_date": "2026-02-06 23:36:11 UTC",
      "updated_date": "2026-02-06 23:36:11 UTC",
      "processing_status": "completed",
      "attempts": 1,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "llm_backup_calls": 0,
      "last_update": "2026-02-16T05:32:12.710943+00:00"
    },
    {
      "arxiv_id": "2602.07265v1",
      "title": "XShare: Collaborative in-Batch Expert Sharing for Faster MoE Inference",
      "title_zh": "XShare：旨在加速 MoE 推理的批次内协作专家共享",
      "authors": [
        "Daniil Vankov",
        "Nikita Ivkin",
        "Kyle Ulrich",
        "Xiang Song",
        "Ashish Khetan",
        "George Karypis"
      ],
      "abstract": "Mixture-of-Experts (MoE) architectures are increasingly used to efficiently scale large language models. However, in production inference, request batching and speculative decoding significantly amplify expert activation, eroding these efficiency benefits. We address this issue by modeling batch-aware expert selection as a modular optimization problem and designing efficient greedy algorithms for different deployment settings. The proposed method, namely XShare, requires no retraining and dynamically adapts to each batch by maximizing the total gating score of selected experts. It reduces expert activation by up to 30% under standard batching, cuts peak GPU load by up to 3x in expert-parallel deployments, and achieves up to 14% throughput gains in speculative decoding via hierarchical, correlation-aware expert selection even if requests in a batch drawn from heterogeneous datasets.",
      "tldr_zh": "该研究提出了 XShare，一种旨在优化混合专家模型 (Mixture-of-Experts) 推理效率的框架，解决了生产环境中由于请求批处理和投机采样 (Speculative Decoding) 导致的专家激活激增问题。XShare 将批次感知专家选择建模为模块化优化问题，并设计了高效的贪婪算法以适应不同的部署场景，且无需重新训练。该方法通过最大化所选专家的门控分数 (Gating Score) 来动态调整每个批次的专家分配。实验结果显示，在标准批处理下 XShare 可减少高达 30% 的专家激活，在专家并行部署中将峰值 GPU 负载降低 3 倍。此外，通过分层且感知相关性的专家选择机制，XShare 在处理异构数据集批次时，仍能使投机采样的吞吐量提升高达 14%。",
      "categories": [
        "cs.LG",
        "cs.AI"
      ],
      "primary_category": "cs.LG",
      "comment": "",
      "pdf_url": "https://arxiv.org/pdf/2602.07265v1",
      "published_date": "2026-02-06 23:33:07 UTC",
      "updated_date": "2026-02-06 23:33:07 UTC",
      "processing_status": "completed",
      "attempts": 1,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "llm_backup_calls": 0,
      "last_update": "2026-02-16T05:32:15.510712+00:00"
    },
    {
      "arxiv_id": "2602.07264v1",
      "title": "aerial-autonomy-stack -- a Faster-than-real-time, Autopilot-agnostic, ROS2 Framework to Simulate and Deploy Perception-based Drones",
      "title_zh": "aerial-autonomy-stack：一种用于感知无人机仿真与部署的超实时、自动驾驶仪无关的 ROS2 框架",
      "authors": [
        "Jacopo Panerati",
        "Sina Sajjadi",
        "Sina Soleymanpour",
        "Varunkumar Mehta",
        "Iraj Mantegh"
      ],
      "abstract": "Unmanned aerial vehicles are rapidly transforming multiple applications, from agricultural and infrastructure monitoring to logistics and defense. Introducing greater autonomy to these systems can simultaneously make them more effective as well as reliable. Thus, the ability to rapidly engineer and deploy autonomous aerial systems has become of strategic importance. In the 2010s, a combination of high-performance compute, data, and open-source software led to the current deep learning and AI boom, unlocking decades of prior theoretical work. Robotics is on the cusp of a similar transformation. However, physical AI faces unique hurdles, often combined under the umbrella term \"simulation-to-reality gap\". These span from modeling shortcomings to the complexity of vertically integrating the highly heterogeneous hardware and software systems typically found in field robots. To address the latter, we introduce aerial-autonomy-stack, an open-source, end-to-end framework designed to streamline the pipeline from (GPU-accelerated) perception to (flight controller-based) action. Our stack allows the development of aerial autonomy using ROS2 and provides a common interface for two of the most popular autopilots: PX4 and ArduPilot. We show that it supports over 20x faster-than-real-time, end-to-end simulation of a complete development and deployment stack -- including edge compute and networking -- significantly compressing the build-test-release cycle of perception-based autonomy.",
      "tldr_zh": "该研究推出了 aerial-autonomy-stack，这是一个开源、端到端的 ROS2 框架，旨在简化感知驱动型无人机从 GPU-accelerated 感知到飞控动作的开发与部署流程。为了应对物理 AI 领域中 simulation-to-reality gap 以及异构软硬件系统垂直集成的复杂性，该框架为 PX4 和 ArduPilot 两种主流自动驾驶仪提供了通用接口，实现了 Autopilot-agnostic 的特性。实验表明，该系统支持超过 20 倍实时的端到端全栈模拟，涵盖了边缘计算和网络通信等完整环节。通过显著压缩感知型自主系统的“构建-测试-发布”周期，aerial-autonomy-stack 为无人机自主性的快速工程化和实地应用提供了高效的解决方案。",
      "categories": [
        "cs.RO",
        "cs.AI",
        "cs.SE"
      ],
      "primary_category": "cs.RO",
      "comment": "",
      "pdf_url": "https://arxiv.org/pdf/2602.07264v1",
      "published_date": "2026-02-06 23:29:33 UTC",
      "updated_date": "2026-02-06 23:29:33 UTC",
      "processing_status": "completed",
      "attempts": 1,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "llm_backup_calls": 0,
      "last_update": "2026-02-16T05:32:31.600372+00:00"
    },
    {
      "arxiv_id": "2602.07261v1",
      "title": "Cognitive algorithms and systems of episodic memory, semantic memory and their learnings",
      "title_zh": "情景记忆、语义记忆及其学习机制的认知算法与系统",
      "authors": [
        "Qi Zhang"
      ],
      "abstract": "Declarative memory, the memory that can be \"declared\" in words or languages, is made up of two dissociated parts: episodic memory and semantic memory. This dissociation has its neuroanatomical basis episodic memory is mostly associated with the hippocampus and semantic memory with the neocortex. The two memories, on the other hand, are closely related. Lesions in the hippocampus often result in various impairments of explicit memory, e.g., anterograde, retrograde and developmental amnesias, and semantic learning deficit. These impairments provide opportunities for us to understand how the two memories may be acquired, stored and organized. This chapter reviews several cognitive systems that are centered to mimic explicit memory, and other systems that are neuroanatomically based and are implemented to simulate those memory impairments mentioned above. This review includes: the structures of the computational systems, their learning rules, and their simulations of memory acquisition and impairments.",
      "tldr_zh": "该研究探讨了陈述性记忆(Declarative memory)中情境记忆(episodic memory)与语义记忆(semantic memory)的认知算法及其系统实现。通过回顾基于海马体与新皮层神经解剖学基础的计算系统，文章深入分析了这两种记忆在学习、存储与组织过程中的紧密联系。研究重点讨论了模拟顺行性、逆行性和发育性遗忘症以及语义学习障碍(semantic learning deficit)的认知模型，详细介绍了这些系统的计算结构、学习规则以及对记忆获取和损伤过程的模拟。通过这种神经解剖驱动的建模方法，该综述为理解人类显性记忆的获取机制及相关病理损伤提供了理论支持与技术路径。",
      "categories": [
        "q-bio.NC",
        "cs.AI",
        "cs.ET"
      ],
      "primary_category": "q-bio.NC",
      "comment": "33 pages, 6 figures, 6 tables",
      "pdf_url": "https://arxiv.org/pdf/2602.07261v1",
      "published_date": "2026-02-06 23:22:52 UTC",
      "updated_date": "2026-02-06 23:22:52 UTC",
      "processing_status": "completed",
      "attempts": 1,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "llm_backup_calls": 0,
      "last_update": "2026-02-16T05:32:28.725786+00:00"
    },
    {
      "arxiv_id": "2602.07259v1",
      "title": "Incentive-Aware AI Safety via Strategic Resource Allocation: A Stackelberg Security Games Perspective",
      "title_zh": "基于策略性资源分配的激励感知人工智能安全：Stackelberg 安全博弈视角",
      "authors": [
        "Cheol Woo Kim",
        "Davin Choo",
        "Tzeh Yuan Neoh",
        "Milind Tambe"
      ],
      "abstract": "As AI systems grow more capable and autonomous, ensuring their safety and reliability requires not only model-level alignment but also strategic oversight of the humans and institutions involved in their development and deployment. Existing safety frameworks largely treat alignment as a static optimization problem (e.g., tuning models to desired behavior) while overlooking the dynamic, adversarial incentives that shape how data are collected, how models are evaluated, and how they are ultimately deployed. We propose a new perspective on AI safety grounded in Stackelberg Security Games (SSGs): a class of game-theoretic models designed for adversarial resource allocation under uncertainty. By viewing AI oversight as a strategic interaction between defenders (auditors, evaluators, and deployers) and attackers (malicious actors, misaligned contributors, or worst-case failure modes), SSGs provide a unifying framework for reasoning about incentive design, limited oversight capacity, and adversarial uncertainty across the AI lifecycle. We illustrate how this framework can inform (1) training-time auditing against data/feedback poisoning, (2) pre-deployment evaluation under constrained reviewer resources, and (3) robust multi-model deployment in adversarial environments. This synthesis bridges algorithmic alignment and institutional oversight design, highlighting how game-theoretic deterrence can make AI oversight proactive, risk-aware, and resilient to manipulation.",
      "tldr_zh": "该研究提出了一个基于Stackelberg Security Games (SSGs) 的AI安全新视角，旨在解决现有安全框架忽视人类与机构动态激励机制以及对抗性风险的问题。作者将AI监管建模为防御者（如审计员、评估员）与攻击者（如恶意参与者、失配贡献者）之间的战略博弈，利用博弈论模型在不确定环境下优化资源分配。该框架重点展示了其在三个关键场景的应用，包括针对数据/反馈投毒(Data/Feedback Poisoning)的训练期审计、有限资源下的部署前评估，以及对抗环境中的稳健多模型部署。通过这种跨学科的综合方法，研究成功桥接了算法对齐(Algorithmic Alignment)与制度监管设计，利用博弈论的震慑机制使AI监管具备了更强的主动性、风险感知能力和抗操纵性。",
      "categories": [
        "cs.AI"
      ],
      "primary_category": "cs.AI",
      "comment": "",
      "pdf_url": "https://arxiv.org/pdf/2602.07259v1",
      "published_date": "2026-02-06 23:20:26 UTC",
      "updated_date": "2026-02-06 23:20:26 UTC",
      "processing_status": "completed",
      "attempts": 1,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "llm_backup_calls": 0,
      "last_update": "2026-02-16T05:32:37.402096+00:00"
    },
    {
      "arxiv_id": "2602.07256v1",
      "title": "Graph homophily booster: Reimagining the role of discrete features in heterophilic graph learning",
      "title_zh": "图同质性增强器：重塑离散特征在异质图学习中的作用",
      "authors": [
        "Ruizhong Qiu",
        "Ting-Wei Li",
        "Gaotang Li",
        "Hanghang Tong"
      ],
      "abstract": "Graph neural networks (GNNs) have emerged as a powerful tool for modeling graph-structured data. However, existing GNNs often struggle with heterophilic graphs, where connected nodes tend to have dissimilar features or labels. While numerous methods have been proposed to address this challenge, they primarily focus on architectural designs without directly targeting the root cause of the heterophily problem. These approaches still perform even worse than the simplest MLPs on challenging heterophilic datasets. For instance, our experiments show that 21 latest GNNs still fall behind the MLP on the Actor dataset. This critical challenge calls for an innovative approach to addressing graph heterophily beyond architectural designs. To bridge this gap, we propose and study a new and unexplored paradigm: directly increasing the graph homophily via a carefully designed graph transformation. In this work, we present a simple yet effective framework called GRAPHITE to address graph heterophily. To the best of our knowledge, this work is the first method that explicitly transforms the graph to directly improve the graph homophily. Stemmed from the exact definition of homophily, our proposed GRAPHITE creates feature nodes to facilitate homophilic message passing between nodes that share similar features. Furthermore, we both theoretically and empirically show that our proposed GRAPHITE significantly increases the homophily of originally heterophilic graphs, with only a slight increase in the graph size. Extensive experiments on challenging datasets demonstrate that our proposed GRAPHITE significantly outperforms state-of-the-art methods on heterophilic graphs while achieving comparable accuracy with state-of-the-art methods on homophilic graphs.",
      "tldr_zh": "该研究针对图神经网络(GNNs)在处理异质图(heterophilic graphs)时表现欠佳的问题，指出目前许多先进模型在某些挑战性数据集上表现甚至不如简单的多层感知机(MLPs)。为此，研究者提出了一种名为GRAPHITE的新型框架，其核心思想是摆脱传统的架构设计，通过显式的图变换(graph transformation)直接提升图的同质性(homophily)。作为首个直接针对图结构进行同质性优化的方法，GRAPHITE 通过引入特征节点(feature nodes)来促进具有相似特征的节点之间进行同质化消息传递(homophilic message passing)。理论与实证分析均表明，该方法在仅微幅增加图规模的情况下，能够显著提高原始异质图的同质化程度。实验结果显示，GRAPHITE 在异质图任务中的性能显著优于现有的最先进方法(SOTA)，同时在同质图数据集上也保持了极具竞争力的准确率。",
      "categories": [
        "cs.LG",
        "cs.AI"
      ],
      "primary_category": "cs.LG",
      "comment": "ICLR 2026",
      "pdf_url": "https://arxiv.org/pdf/2602.07256v1",
      "published_date": "2026-02-06 23:14:10 UTC",
      "updated_date": "2026-02-06 23:14:10 UTC",
      "processing_status": "completed",
      "attempts": 1,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "llm_backup_calls": 0,
      "last_update": "2026-02-16T05:32:38.308295+00:00"
    },
    {
      "arxiv_id": "2602.07253v1",
      "title": "From Out-of-Distribution Detection to Hallucination Detection: A Geometric View",
      "title_zh": "从分布外检测到幻觉检测：一种几何视角",
      "authors": [
        "Litian Liu",
        "Reza Pourreza",
        "Yubing Jian",
        "Yao Qin",
        "Roland Memisevic"
      ],
      "abstract": "Detecting hallucinations in large language models is a critical open problem with significant implications for safety and reliability. While existing hallucination detection methods achieve strong performance in question-answering tasks, they remain less effective on tasks requiring reasoning. In this work, we revisit hallucination detection through the lens of out-of-distribution (OOD) detection, a well-studied problem in areas like computer vision. Treating next-token prediction in language models as a classification task allows us to apply OOD techniques, provided appropriate modifications are made to account for the structural differences in large language models. We show that OOD-based approaches yield training-free, single-sample-based detectors, achieving strong accuracy in hallucination detection for reasoning tasks. Overall, our work suggests that reframing hallucination detection as OOD detection provides a promising and scalable pathway toward language model safety.",
      "tldr_zh": "该研究从几何视角重新审视了大语言模型（LLMs）中的幻觉检测（Hallucination Detection）问题，将其与分布外（Out-of-Distribution, OOD）检测联系起来。针对现有方法在推理任务中表现不佳的现状，作者将语言模型的下一个标记预测（Next-token prediction）视为分类任务，从而引入 OOD 技术进行改进。通过针对大语言模型结构差异的调整，该研究证明了基于 OOD 的方法可以构建无需训练（Training-free）且基于单样本（Single-sample-based）的检测器。实验结果显示，该方法在推理任务的幻觉检测中达到了极高的准确率，为提升模型的安全性和可靠性提供了新思路。总体而言，该工作表明将幻觉检测重构为 OOD 检测是实现大语言模型安全的一条具有前景且可扩展的路径。",
      "categories": [
        "cs.AI",
        "cs.CL"
      ],
      "primary_category": "cs.AI",
      "comment": "",
      "pdf_url": "https://arxiv.org/pdf/2602.07253v1",
      "published_date": "2026-02-06 23:05:48 UTC",
      "updated_date": "2026-02-06 23:05:48 UTC",
      "processing_status": "completed",
      "attempts": 1,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "llm_backup_calls": 0,
      "last_update": "2026-02-16T05:32:40.302049+00:00"
    },
    {
      "arxiv_id": "2602.07251v1",
      "title": "The Double-Edged Sword of Data-Driven Super-Resolution: Adversarial Super-Resolution Models",
      "title_zh": "数据驱动超分辨率的双刃剑：对抗性超分辨率模型",
      "authors": [
        "Haley Duba-Sullivan",
        "Steven R. Young",
        "Emma J. Reid"
      ],
      "abstract": "Data-driven super-resolution (SR) methods are often integrated into imaging pipelines as preprocessing steps to improve downstream tasks such as classification and detection. However, these SR models introduce a previously unexplored attack surface into imaging pipelines. In this paper, we present AdvSR, a framework demonstrating that adversarial behavior can be embedded directly into SR model weights during training, requiring no access to inputs at inference time. Unlike prior attacks that perturb inputs or rely on backdoor triggers, AdvSR operates entirely at the model level. By jointly optimizing for reconstruction quality and targeted adversarial outcomes, AdvSR produces models that appear benign under standard image quality metrics while inducing downstream misclassification. We evaluate AdvSR on three SR architectures (SRCNN, EDSR, SwinIR) paired with a YOLOv11 classifier and demonstrate that AdvSR models can achieve high attack success rates with minimal quality degradation. These findings highlight a new model-level threat for imaging pipelines, with implications for how practitioners source and validate models in safety-critical applications.",
      "tldr_zh": "该研究探讨了数据驱动的超分辨率(Super-Resolution, SR)模型作为影像处理流水线预处理步骤时带来的安全风险，并提出了AdvSR框架。AdvSR通过在训练阶段将对抗行为直接嵌入到SR模型的权重中，实现了无需推理时输入扰动或后门触发(Backdoor Triggers)的模型级攻击。该方法通过联合优化图像重建质量和特定的对抗目标，使生成的模型在标准图像质量指标下表现正常，却能诱导下游分类器产生错误识别。实验在SRCNN、EDSR和SwinIR等多种架构上结合YOLOv11分类器进行了评估，结果显示AdvSR在保持极高图像质量的同时具有显著的攻击成功率。这一发现揭示了影像处理流水线中存在的新型模型级威胁，并为安全关键应用中如何溯源和验证模型提供了重要启示。",
      "categories": [
        "cs.CV",
        "cs.AI"
      ],
      "primary_category": "cs.CV",
      "comment": "",
      "pdf_url": "https://arxiv.org/pdf/2602.07251v1",
      "published_date": "2026-02-06 23:00:58 UTC",
      "updated_date": "2026-02-06 23:00:58 UTC",
      "processing_status": "completed",
      "attempts": 1,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "llm_backup_calls": 0,
      "last_update": "2026-02-16T05:32:43.615757+00:00"
    },
    {
      "arxiv_id": "2602.07243v1",
      "title": "Realistic Synthetic Household Data Generation at Scale",
      "title_zh": "大规模真实感合成家庭数据生成",
      "authors": [
        "Siddharth Singh",
        "Ifrah Idrees",
        "Abraham Dauhajre"
      ],
      "abstract": "Advancements in foundation models have catalyzed research in Embodied AI to develop interactive agents capable of environmental reasoning and interaction. Developing such agents requires diverse, large-scale datasets. Prior frameworks generate synthetic data for long-term human-robot interactions but fail to model the bidirectional influence between human behavior and household environments. Our proposed generative framework creates household datasets at scale through loosely coupled generation of long-term human-robot interactions and environments. Human personas influence environment generation, while environment schematics and semantics shape human-robot interactions.\n  The generated 3D data includes rich static context such as object and environment semantics, and temporal context capturing human and agent behaviors over extended periods. Our flexible tool allows users to define dataset characteristics via natural language prompts, enabling configuration of environment and human activity data through natural language specifications. The tool creates variations of user-defined configurations, enabling scalable data generation.\n  We validate our framework through statistical evaluation using multi-modal embeddings and key metrics: cosine similarity, mutual information gain, intervention analysis, and iterative improvement validation. Statistical comparisons show good alignment with real-world datasets (HOMER) with cosine similarity (0.60), while synthetic datasets (Wang et al.) show moderate alignment (0.27). Intervention analysis across age, organization, and sleep pattern changes shows statistically significant effects (p < 0.001) with large effect sizes (Cohen's d = 0.51-1.12), confirming bidirectional coupling translates persona traits into measurable environmental and behavioral differences. These contributions enable development and testing of household smart devices at scale.",
      "tldr_zh": "该研究提出了一个生成式框架，旨在为 Embodied AI 智能体的大规模开发提供多样化的家居数据集。该框架通过松散耦合的方式实现了长期人机交互与环境的协同生成，成功模拟了人类画像(Personas)与家居环境之间的双向影响。系统允许用户利用自然语言提示(Natural Language Prompts)灵活配置环境和活动数据，并生成包含丰富静态物体语义及长期行为上下文的 3D 数据。实验结果表明，该框架生成的合成数据与真实世界数据集 HOMER 在余弦相似度(Cosine Similarity)上达到了 0.60 的高度一致性，表现优于现有的合成数据集。干预分析(Intervention Analysis)进一步证明了画像特质能有效转化为可测量的环境和行为差异，为大规模开发和测试家用智能设备提供了重要支持。",
      "categories": [
        "cs.RO",
        "cs.AI",
        "cs.GR"
      ],
      "primary_category": "cs.RO",
      "comment": "Accepted at Agentic AI Benchmarks and Applications for Enterprise Tasks workshop at AAAI 2026",
      "pdf_url": "https://arxiv.org/pdf/2602.07243v1",
      "published_date": "2026-02-06 22:49:37 UTC",
      "updated_date": "2026-02-06 22:49:37 UTC",
      "processing_status": "completed",
      "attempts": 1,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "llm_backup_calls": 0,
      "last_update": "2026-02-16T05:32:48.716278+00:00"
    },
    {
      "arxiv_id": "2602.07238v1",
      "title": "Is there \"Secret Sauce'' in Large Language Model Development?",
      "title_zh": "大语言模型开发中是否存在“秘密配方”？",
      "authors": [
        "Matthias Mertens",
        "Natalia Fischl-Lanzoni",
        "Neil Thompson"
      ],
      "abstract": "Do leading LLM developers possess a proprietary ``secret sauce'', or is LLM performance driven by scaling up compute? Using training and benchmark data for 809 models released between 2022 and 2025, we estimate scaling-law regressions with release-date and developer fixed effects. We find clear evidence of developer-specific efficiency advantages, but their importance depends on where models lie in the performance distribution. At the frontier, 80-90% of performance differences are explained by higher training compute, implying that scale--not proprietary technology--drives frontier advances. Away from the frontier, however, proprietary techniques and shared algorithmic progress substantially reduce the compute required to reach fixed capability thresholds. Some companies can systematically produce smaller models more efficiently. Strikingly, we also find substantial variation of model efficiency within companies; a firm can train two models with more than 40x compute efficiency difference. We also discuss the implications for AI leadership and capability diffusion.",
      "tldr_zh": "该研究通过分析2022年至2025年间发布的809个模型，利用Scaling-Law回归分析并结合发布日期和开发者固定效应，探讨了大型语言模型(LLMs)的发展是依赖于计算规模的扩张还是开发者的“秘密配方”(Secret Sauce)。研究发现在模型性能的前沿领域，80-90%的性能差异可归因于更高的训练计算量(Training Compute)，这表明规模而非专利技术是推动前沿进展的主导因素。然而在非前沿领域，专有技术和共享的算法进步显著降低了达到特定能力阈值所需的计算资源。此外，研究观察到某些公司在开发小型模型时具有系统性的效率优势，且同一公司内部不同模型间的计算效率差异甚至可达40倍以上。该发现揭示了开发者特定效率优势在不同性能层级中的作用，并为AI领导地位和技术扩散提供了新的见解。",
      "categories": [
        "cs.AI",
        "cs.LG",
        "econ.GN"
      ],
      "primary_category": "cs.AI",
      "comment": "",
      "pdf_url": "https://arxiv.org/pdf/2602.07238v1",
      "published_date": "2026-02-06 22:32:31 UTC",
      "updated_date": "2026-02-06 22:32:31 UTC",
      "processing_status": "completed",
      "attempts": 1,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "llm_backup_calls": 0,
      "last_update": "2026-02-16T05:33:21.118120+00:00"
    },
    {
      "arxiv_id": "2602.07235v1",
      "title": "ArcMark: Multi-bit LLM Watermark via Optimal Transport",
      "title_zh": "ArcMark：基于最优传输的多比特大语言模型水印",
      "authors": [
        "Atefeh Gilani",
        "Carol Xuan Long",
        "Sajani Vithana",
        "Oliver Kosut",
        "Lalitha Sankar",
        "Flavio P. Calmon"
      ],
      "abstract": "Watermarking is an important tool for promoting the responsible use of language models (LMs). Existing watermarks insert a signal into generated tokens that either flags LM-generated text (zero-bit watermarking) or encodes more complex messages (multi-bit watermarking). Though a number of recent multi-bit watermarks insert several bits into text without perturbing average next-token predictions, they largely extend design principles from the zero-bit setting, such as encoding a single bit per token. Notably, the information-theoretic capacity of multi-bit watermarking -- the maximum number of bits per token that can be inserted and detected without changing average next-token predictions -- has remained unknown. We address this gap by deriving the first capacity characterization of multi-bit watermarks. Our results inform the design of ArcMark: a new watermark construction based on coding-theoretic principles that, under certain assumptions, achieves the capacity of the multi-bit watermark channel. In practice, ArcMark outperforms competing multi-bit watermarks in terms of bit rate per token and detection accuracy. Our work demonstrates that LM watermarking is fundamentally a channel coding problem, paving the way for principled coding-theoretic approaches to watermark design.",
      "tldr_zh": "该研究针对大语言模型 (LLMs) 水印技术中多比特水印 (multi-bit watermarking) 的信息论容量未知的挑战，首次推导出了多比特水印的容量表征。基于这一理论突破，作者提出了 ArcMark，一种利用编码理论 (coding-theoretic) 原则构建的新型水印方案，在特定假设下可达到多比特水印信道的理论容量。在实际应用中，ArcMark 在单位标记比特率 (bit rate per token) 和检测准确率 (detection accuracy) 方面均优于现有的多比特水印技术。该研究证明了大语言模型水印本质上是一个信道编码 (channel coding) 问题，为未来采用编码理论方法进行水印设计提供了科学的路径与框架。",
      "categories": [
        "cs.LG",
        "cs.AI",
        "cs.IT"
      ],
      "primary_category": "cs.LG",
      "comment": "",
      "pdf_url": "https://arxiv.org/pdf/2602.07235v1",
      "published_date": "2026-02-06 22:28:03 UTC",
      "updated_date": "2026-02-06 22:28:03 UTC",
      "processing_status": "completed",
      "attempts": 1,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "llm_backup_calls": 0,
      "last_update": "2026-02-16T05:32:59.621193+00:00"
    },
    {
      "arxiv_id": "2602.07219v1",
      "title": "The Median is Easier than it Looks: Approximation with a Constant-Depth, Linear-Width ReLU Network",
      "title_zh": "中位数比看起来更简单：利用常数深度、线性宽度的 ReLU 网络进行逼近",
      "authors": [
        "Abhigyan Dutta",
        "Itay Safran",
        "Paul Valiant"
      ],
      "abstract": "We study the approximation of the median of $d$ inputs using ReLU neural networks. We present depth-width tradeoffs under several settings, culminating in a constant-depth, linear-width construction that achieves exponentially small approximation error with respect to the uniform distribution over the unit hypercube. By further establishing a general reduction from the maximum to the median, our results break a barrier suggested by prior work on the maximum function, which indicated that linear width should require depth growing at least as $\\log\\log d$ to achieve comparable accuracy. Our construction relies on a multi-stage procedure that iteratively eliminates non-central elements while preserving a candidate set around the median. We overcome obstacles that do not arise for the maximum to yield approximation results that are strictly stronger than those previously known for the maximum itself.",
      "tldr_zh": "该研究探讨了利用 ReLU neural networks 近似 $d$ 个输入的中位数 (median) 的问题。作者提出了多种设置下的深度-宽度权衡 (depth-width tradeoffs)，最终实现了一个恒定深度 (constant-depth) 且线性宽度 (linear-width) 的网络结构，在单位超立方体的均匀分布下实现了指数级小的近似误差。通过建立从最大值 (maximum) 到中位数的通用归约，该研究打破了先前关于最大值函数近似的性能屏障，即线性宽度网络不再需要随 $\\log\\log d$ 增长的深度来保证精度。其核心方法采用多阶段程序迭代消除非中心元素，从而保留中位数附近的候选集。该成果克服了中位数计算中特有的挑战，提供了比现有最大值近似理论更强的结果。",
      "categories": [
        "cs.LG",
        "cs.AI"
      ],
      "primary_category": "cs.LG",
      "comment": "",
      "pdf_url": "https://arxiv.org/pdf/2602.07219v1",
      "published_date": "2026-02-06 22:00:31 UTC",
      "updated_date": "2026-02-06 22:00:31 UTC",
      "processing_status": "completed",
      "attempts": 1,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "llm_backup_calls": 0,
      "last_update": "2026-02-16T05:32:59.304885+00:00"
    },
    {
      "arxiv_id": "2602.07218v1",
      "title": "Collaborative and Efficient Fine-tuning: Leveraging Task Similarity",
      "title_zh": "协作且高效的微调：利用任务相似性助力模型适配",
      "authors": [
        "Gagik Magakyan",
        "Amirhossein Reisizadeh",
        "Chanwoo Park",
        "Pablo A. Parrilo",
        "Asuman Ozdaglar"
      ],
      "abstract": "Adaptability has been regarded as a central feature in the foundation models, enabling them to effectively acclimate to unseen downstream tasks. Parameter-efficient fine-tuning methods such as celebrated LoRA facilitate efficient adaptation of large foundation models using labeled, high-quality and generally scarce task data. To mitigate data scarcity in fine-tuning of foundation models, we propose to leverage task similarity across multiple downstream users. Intuitively, users with similar tasks must be able to assist each other in boosting the effective fine-tuning data size. We propose Collaborative Low-Rank Adaptation, or CoLoRA, which exploits task similarity to collaboratively and efficiently fine-tune personalized foundation models. The main idea in CoLoRA is to train one shared adapter capturing underlying task similarities across all tasks, and personalized adapters tailored to user-specific tasks. We theoretically study CoLoRA on heterogeneous linear regression and provide provable guarantees for ground truth recovery. We also conduct several natural language experiments with varying task similarity, which further demonstrate that when trained together with similar tasks, individual performances are significantly boosted.",
      "tldr_zh": "该研究提出了CoLoRA (Collaborative Low-Rank Adaptation)，一种通过利用多个下游用户间的任务相似性来协作、高效微调个性化基础模型的框架，旨在解决参数高效微调(PEFT)中高质量数据稀缺的问题。CoLoRA的核心设计是训练一个共享的adapter来捕捉所有任务间的潜在相似性，并结合用户特定的个性化adapters来适配具体任务。研究团队针对异构线性回归(heterogeneous linear regression)进行了理论分析，并提供了关于Ground Truth恢复的可证明保证。在不同任务相似度下的自然语言处理实验进一步证实，当与相似任务共同微调时，单个任务的性能会得到显著提升。该方法通过跨任务的协作机制，为在资源受限环境下提升基础模型的适应性提供了强有力的支持。",
      "categories": [
        "cs.LG",
        "cs.AI",
        "stat.ML"
      ],
      "primary_category": "cs.LG",
      "comment": "",
      "pdf_url": "https://arxiv.org/pdf/2602.07218v1",
      "published_date": "2026-02-06 21:59:40 UTC",
      "updated_date": "2026-02-06 21:59:40 UTC",
      "processing_status": "completed",
      "attempts": 1,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "llm_backup_calls": 0,
      "last_update": "2026-02-16T05:33:37.004478+00:00"
    },
    {
      "arxiv_id": "2602.07215v1",
      "title": "Multi-Agentic AI for Fairness-Aware and Accelerated Multi-modal Large Model Inference in Real-world Mobile Edge Networks",
      "title_zh": "面向真实移动边缘网络公平感知与加速多模态大模型推理的多智能体 AI",
      "authors": [
        "Haiyuan Li",
        "Hari Madhukumar",
        "Shuangyi Yan",
        "Yulei Wu",
        "Dimitra Simeonidou"
      ],
      "abstract": "Generative AI (GenAI) has transformed applications in natural language processing and content creation, yet centralized inference remains hindered by high latency, limited customizability, and privacy concerns. Deploying large models (LMs) in mobile edge networks emerges as a promising solution. However, it also poses new challenges, including heterogeneous multi-modal LMs with diverse resource demands and inference speeds, varied prompt/output modalities that complicate orchestration, and resource-limited infrastructure ill-suited for concurrent LM execution. In response, we propose a Multi-Agentic AI framework for latency- and fairness-aware multi-modal LM inference in mobile edge networks. Our solution includes a long-term planning agent, a short-term prompt scheduling agent, and multiple on-node LM deployment agents, all powered by foundation language models. These agents cooperatively optimize prompt routing and LM deployment through natural language reasoning over runtime telemetry and historical experience. To evaluate its performance, we further develop a city-wide testbed that supports network monitoring, containerized LM deployment, intra-server resource management, and inter-server communications. Experiments demonstrate that our solution reduces average latency by over 80% and improves fairness (Normalized Jain index) to 0.90 compared to other baselines. Moreover, our solution adapts quickly without fine-tuning, offering a generalizable solution for optimizing GenAI services in edge environments.",
      "tldr_zh": "该研究针对移动边缘网络 (Mobile Edge Networks) 中多模态大模型 (Multi-modal LMs) 推理面临的高延迟、资源受限及协同复杂等挑战，提出了一种兼顾延迟与公平性的多智能体 AI (Multi-Agentic AI) 框架。该框架由长期规划智能体 (Long-term planning agent)、短期提示调度智能体 (Short-term prompt scheduling agent) 和多个节点内模型部署智能体 (On-node LM deployment agents) 组成。这些智能体通过对运行时遥测数据和历史经验进行自然语言推理，共同协作以优化提示路由 (Prompt routing) 和模型部署策略。为了验证性能，研究者构建了一个支持网络监测和容器化模型部署的城市级实验平台。实验结果表明，该方案相比基线模型将平均延迟降低了 80% 以上，并将公平性指标 (Normalized Jain index) 提升至 0.90。此外，该方案无需微调即可快速适应环境变化，为优化边缘环境下的生成式 AI (GenAI) 服务提供了一种具有通用性的解决方案。",
      "categories": [
        "eess.SY",
        "cs.AI",
        "cs.DC"
      ],
      "primary_category": "eess.SY",
      "comment": "",
      "pdf_url": "https://arxiv.org/pdf/2602.07215v1",
      "published_date": "2026-02-06 21:52:49 UTC",
      "updated_date": "2026-02-06 21:52:49 UTC",
      "processing_status": "completed",
      "attempts": 1,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "llm_backup_calls": 0,
      "last_update": "2026-02-16T05:33:38.001291+00:00"
    },
    {
      "arxiv_id": "2602.07208v1",
      "title": "Sequences as Nodes for Contrastive Multimodal Graph Recommendation",
      "title_zh": "将序列作为节点的对比多模态图推荐",
      "authors": [
        "Bucher Sahyouni",
        "Matthew Vowels",
        "Liqun Chen",
        "Simon Hadfield"
      ],
      "abstract": "To tackle cold-start and data sparsity issues in recommender systems, numerous multimodal, sequential, and contrastive techniques have been proposed. While these augmentations can boost recommendation performance, they tend to add noise and disrupt useful semantics. To address this, we propose MuSICRec (Multimodal Sequence-Item Contrastive Recommender), a multi-view graph-based recommender that combines collaborative, sequential, and multimodal signals. We build a sequence-item (SI) view by attention pooling over the user's interacted items to form sequence nodes. We propagate over the SI graph, obtaining a second view organically as an alternative to artificial data augmentation, while simultaneously injecting sequential context signals. Additionally, to mitigate modality noise and align the multimodal information, the contribution of text and visual features is modulated according to an ID-guided gate.\n  We evaluate under a strict leave-two-out split against a broad range of sequential, multimodal, and contrastive baselines. On the Amazon Baby, Sports, and Electronics datasets, MuSICRec outperforms state-of-the-art baselines across all model types. We observe the largest gains for short-history users, mitigating sparsity and cold-start challenges. Our code is available at https://anonymous.4open.science/r/MuSICRec-3CEE/ and will be made publicly available.",
      "tldr_zh": "该研究提出了 MuSICRec，一种结合了协同过滤、序列和多模态信号的多视图图推荐框架，旨在解决推荐系统中的冷启动 (cold-start) 和数据稀疏 (data sparsity) 问题。该模型通过注意力池化 (attention pooling) 将用户交互序列转化为序列节点 (sequence nodes)，构建序列-项目 (sequence-item) 视图，并利用图传播机制实现有机的多视图数据增强。为了降低模态噪声，MuSICRec 引入了 ID 引导门控 (ID-guided gate) 来动态调节文本与视觉特征的融合权重。在 Amazon 多个数据集上的实验结果显示，MuSICRec 的性能优于当前的 SOTA 基线模型，尤其在处理短历史记录用户时展现出显著优势。该研究通过深度整合序列上下文与多模态特征，为缓解推荐系统的稀疏性挑战提供了有效的技术方案。",
      "categories": [
        "cs.IR",
        "cs.AI"
      ],
      "primary_category": "cs.IR",
      "comment": "",
      "pdf_url": "https://arxiv.org/pdf/2602.07208v1",
      "published_date": "2026-02-06 21:35:12 UTC",
      "updated_date": "2026-02-06 21:35:12 UTC",
      "processing_status": "completed",
      "attempts": 1,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "llm_backup_calls": 0,
      "last_update": "2026-02-16T05:33:41.901079+00:00"
    },
    {
      "arxiv_id": "2602.07207v1",
      "title": "Multimodal Enhancement of Sequential Recommendation",
      "title_zh": "序列化推荐的多模态增强",
      "authors": [
        "Bucher Sahyouni",
        "Matthew Vowels",
        "Liqun Chen",
        "Simon Hadfield"
      ],
      "abstract": "We propose a novel recommender framework, MuSTRec (Multimodal and Sequential Transformer-based Recommendation), that unifies multimodal and sequential recommendation paradigms. MuSTRec captures cross-item similarities and collaborative filtering signals, by building item-item graphs from extracted text and visual features. A frequency-based self-attention module additionally captures the short- and long-term user preferences. Across multiple Amazon datasets, MuSTRec demonstrates superior performance (up to 33.5% improvement) over multimodal and sequential state-of-the-art baselines. Finally, we detail some interesting facets of this new recommendation paradigm. These include the need for a new data partitioning regime, and a demonstration of how integrating user embeddings into sequential recommendation leads to drastically increased short-term metrics (up to 200% improvement) on smaller datasets. Our code is availabe at https://anonymous.4open.science/r/MuSTRec-D32B/ and will be made publicly available.",
      "tldr_zh": "该研究提出了MuSTRec (Multimodal and Sequential Transformer-based Recommendation)，这是一个统一了多模态和序列化推荐范式的新型推荐框架。该框架通过从提取的文本和视觉特征中构建项-项图 (item-item graphs)，有效地捕捉了跨项相似性和协同过滤信号。同时，MuSTRec利用基于频率的自注意力模块 (frequency-based self-attention module) 来同时捕捉用户的短期和长期偏好。在多个Amazon数据集上的实验结果表明，MuSTRec的表现显著优于现有的多模态和序列化State-of-the-Art基准模型，性能提升最高达33.5%。研究还探讨了新的数据划分方案，并证明在序列化推荐中集成用户嵌入 (user embeddings) 能使小型数据集的短期指标提升高达200%。这项工作为如何结合多模态特征与用户行为序列提供了深刻的见解和高效的实现路径。",
      "categories": [
        "cs.IR",
        "cs.AI"
      ],
      "primary_category": "cs.IR",
      "comment": "",
      "pdf_url": "https://arxiv.org/pdf/2602.07207v1",
      "published_date": "2026-02-06 21:32:56 UTC",
      "updated_date": "2026-02-06 21:32:56 UTC",
      "processing_status": "completed",
      "attempts": 1,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "llm_backup_calls": 0,
      "last_update": "2026-02-16T05:33:46.704624+00:00"
    },
    {
      "arxiv_id": "2602.07206v1",
      "title": "DSL: Understanding and Improving Softmax Recommender Systems with Competition-Aware Scaling",
      "title_zh": "DSL：通过竞争感知缩放理解与改进 Softmax 推荐系统",
      "authors": [
        "Bucher Sahyouni",
        "Matthew Vowels",
        "Liqun Chen",
        "Simon Hadfield"
      ],
      "abstract": "Softmax Loss (SL) is being increasingly adopted for recommender systems (RS) as it has demonstrated better performance, robustness and fairness. Yet in implicit-feedback, a single global temperature and equal treatment of uniformly sampled negatives can lead to brittle training, because sampled sets may contain varying degrees of relevant or informative competitors. The optimal loss sharpness for a user-item pair with a particular set of negatives, can be suboptimal or destabilising for another with different negatives. We introduce Dual-scale Softmax Loss (DSL), which infers effective sharpness from the sampled competition itself. DSL adds two complementary branches to the log-sum-exp backbone. Firstly it reweights negatives within each training instance using hardness and item--item similarity, secondly it adapts a per-example temperature from the competition intensity over a constructed competitor slate. Together, these components preserve the geometry of SL while reshaping the competition distribution across negatives and across examples.\n  Over several representative benchmarks and backbones, DSL yields substantial gains over strong baselines, with improvements over SL exceeding $10%$ in several settings and averaging $6.22%$ across datasets, metrics, and backbones. Under out-of-distribution (OOD) popularity shift, the gains are larger, with an average of $9.31%$ improvement over SL. We further provide a theoretical, distributionally robust optimisation (DRO) analysis, which demonstrates how DSL reshapes the robust payoff and the KL deviation for ambiguous instances. This helps explain the empirically observed improvements in accuracy and robustness.",
      "tldr_zh": "该研究提出了DSL (Dual-scale Softmax Loss)，旨在解决 Softmax Loss 在隐式反馈推荐系统中因全局统一温度系数及对负采样样本等同对待而导致的训练不稳定问题。该方法通过在 log-sum-exp 架构中引入两个互补分支，首先利用困难度和物品相似度对训练实例内的负样本进行重新加权，其次根据竞争强度为每个样本自适应调整温度系数。这种双尺度缩放机制在保留 Softmax 几何特性的同时，有效重塑了负样本之间以及不同样本实例间的竞争分布。实验结果表明，DSL 在多个基准数据集和骨干网络上均显著优于现有基准模型，在分布外 (OOD) 流行度偏移场景下的平均改进率达到 9.31%。此外，研究通过分布鲁棒优化 (DRO) 理论分析证明了 DSL 如何通过重塑鲁棒收益和 KL 散度来提升模型的准确性与鲁棒性。",
      "categories": [
        "cs.LG",
        "cs.AI"
      ],
      "primary_category": "cs.LG",
      "comment": "",
      "pdf_url": "https://arxiv.org/pdf/2602.07206v1",
      "published_date": "2026-02-06 21:32:38 UTC",
      "updated_date": "2026-02-06 21:32:38 UTC",
      "processing_status": "completed",
      "attempts": 1,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "llm_backup_calls": 0,
      "last_update": "2026-02-16T05:33:50.234549+00:00"
    },
    {
      "arxiv_id": "2602.07203v1",
      "title": "Exactly Computing do-Shapley Values",
      "title_zh": "精确计算 do-Shapley 值",
      "authors": [
        "R. Teal Witter",
        "Álvaro Parafita",
        "Tomas Garriga",
        "Maximilian Muschalik",
        "Fabian Fumagalli",
        "Axel Brando",
        "Lucas Rosenblatt"
      ],
      "abstract": "Structural Causal Models (SCM) are a powerful framework for describing complicated dynamics across the natural sciences. A particularly elegant way of interpreting SCMs is do-Shapley, a game-theoretic method of quantifying the average effect of $d$ variables across exponentially many interventions. Like Shapley values, computing do-Shapley values generally requires evaluating exponentially many terms. The foundation of our work is a reformulation of do-Shapley values in terms of the irreducible sets of the underlying SCM. Leveraging this insight, we can exactly compute do-Shapley values in time linear in the number of irreducible sets $r$, which itself can range from $d$ to $2^d$ depending on the graph structure of the SCM. Since $r$ is unknown a priori, we complement the exact algorithm with an estimator that, like general Shapley value estimators, can be run with any query budget. As the query budget approaches $r$, our estimators can produce more accurate estimates than prior methods by several orders of magnitude, and, when the budget reaches $r$, return the Shapley values up to machine precision. Beyond computational speed, we also reduce the identification burden: we prove that non-parametric identifiability of do-Shapley values requires only the identification of interventional effects for the $d$ singleton coalitions, rather than all classes.",
      "tldr_zh": "该研究探讨了结构因果模型(SCM)中 do-Shapley 值的精确计算问题，这是一种用于量化 $d$ 个变量在指数级干预下平均影响的博弈论方法。针对传统计算方法面临的指数级项评估难题，本文通过将 do-Shapley 值重新表述为底层 SCM 中 irreducible sets 的函数，实现了重大的算法改进。基于这一见解，研究者提出了一个能在与 irreducible sets 数量 $r$ 呈线性时间内完成精确计算的算法，其中 $r$ 的范围取决于 SCM 的图结构。为了处理 $r$ 预先未知的情况，研究还配套设计了一种估计器，其在有限预算下的准确度比现有方法高出数个数量级，并能在预算达到 $r$ 时实现机器精度。此外，研究在理论上降低了识别负担，证明了 do-Shapley 值的非参数可识别性(non-parametric identifiability)仅需识别 $d$ 个单例联盟的干预效果。这一成果显著提升了复杂因果系统中变量贡献度量化任务的计算效率和理论可行性。",
      "categories": [
        "cs.LG",
        "cs.AI"
      ],
      "primary_category": "cs.LG",
      "comment": "",
      "pdf_url": "https://arxiv.org/pdf/2602.07203v1",
      "published_date": "2026-02-06 21:24:56 UTC",
      "updated_date": "2026-02-06 21:24:56 UTC",
      "processing_status": "completed",
      "attempts": 1,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "llm_backup_calls": 0,
      "last_update": "2026-02-16T05:33:54.602738+00:00"
    },
    {
      "arxiv_id": "2602.07200v1",
      "title": "BadSNN: Backdoor Attacks on Spiking Neural Networks via Adversarial Spiking Neuron",
      "title_zh": "BadSNN：基于对抗性脉冲神经元的脉冲神经网络后门攻击",
      "authors": [
        "Abdullah Arafat Miah",
        "Kevin Vu",
        "Yu Bi"
      ],
      "abstract": "Spiking Neural Networks (SNNs) are energy-efficient counterparts of Deep Neural Networks (DNNs) with high biological plausibility, as information is transmitted through temporal spiking patterns. The core element of an SNN is the spiking neuron, which converts input data into spikes following the Leaky Integrate-and-Fire (LIF) neuron model. This model includes several important hyperparameters, such as the membrane potential threshold and membrane time constant. Both the DNNs and SNNs have proven to be exploitable by backdoor attacks, where an adversary can poison the training dataset with malicious triggers and force the model to behave in an attacker-defined manner. Yet, how an adversary can exploit the unique characteristics of SNNs for backdoor attacks remains underexplored. In this paper, we propose \\textit{BadSNN}, a novel backdoor attack on spiking neural networks that exploits hyperparameter variations of spiking neurons to inject backdoor behavior into the model. We further propose a trigger optimization process to achieve better attack performance while making trigger patterns less perceptible. \\textit{BadSNN} demonstrates superior attack performance on various datasets and architectures, as well as compared with state-of-the-art data poisoning-based backdoor attacks and robustness against common backdoor mitigation techniques. Codes can be found at https://github.com/SiSL-URI/BadSNN.",
      "tldr_zh": "本研究提出了 BadSNN，这是一种针对脉冲神经网络 (Spiking Neural Networks, SNNs) 的新型后门攻击方法，旨在填补利用 SNN 独特生理特性的攻击研究空白。BadSNN 通过操纵脉冲神经元 (spiking neurons) 在 Leaky Integrate-and-Fire (LIF) 模型中的膜电位阈值 (membrane potential threshold) 和膜时间常数 (membrane time constant) 等核心超参数，将后门行为成功注入模型。为了提升攻击的隐蔽性，研究进一步引入了触发器优化 (trigger optimization) 过程，确保触发器模式在保持高攻击成功率的同时难以被察觉。实验结果证明，BadSNN 在多种数据集和网络架构上的性能均优于现有的基于数据投毒 (data poisoning) 的后门攻击。此外，该方法针对常见的后门缓解 (backdoor mitigation) 技术表现出了显著的鲁棒性，为未来构建更安全的脉冲神经网络系统提供了重要依据。",
      "categories": [
        "cs.CR",
        "cs.AI"
      ],
      "primary_category": "cs.CR",
      "comment": "",
      "pdf_url": "https://arxiv.org/pdf/2602.07200v1",
      "published_date": "2026-02-06 21:20:41 UTC",
      "updated_date": "2026-02-06 21:20:41 UTC",
      "processing_status": "completed",
      "attempts": 1,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "llm_backup_calls": 0,
      "last_update": "2026-02-16T05:33:58.512894+00:00"
    },
    {
      "arxiv_id": "2602.09051v1",
      "title": "RuleFlow : Generating Reusable Program Optimizations with LLMs",
      "title_zh": "RuleFlow：基于大语言模型生成可复用的程序优化",
      "authors": [
        "Avaljot Singh",
        "Dushyant Bharadwaj",
        "Stefanos Baziotis",
        "Kaushik Varadharajan",
        "Charith Mendis"
      ],
      "abstract": "Optimizing Pandas programs is a challenging problem. Existing systems and compiler-based approaches offer reliability but are either heavyweight or support only a limited set of optimizations. Conversely, using LLMs in a per-program optimization methodology can synthesize nontrivial optimizations, but is unreliable, expensive, and offers a low yield. In this work, we introduce a hybrid approach that works in a 3-stage manner that decouples discovery from deployment and connects them via a novel bridge. First, it discovers per-program optimizations (discovery). Second, they are converted into generalised rewrite rules (bridge). Finally, these rules are incorporated into a compiler that can automatically apply them wherever applicable, eliminating repeated reliance on LLMs (deployment). We demonstrate that RuleFlow is the new state-of-the-art (SOTA) Pandas optimization framework on PandasBench, a challenging Pandas benchmark consisting of Python notebooks. Across these notebooks, we achieve a speedup of up to 4.3x over Dias, the previous compiler-based SOTA, and 1914.9x over Modin, the previous systems-based SOTA.\n  Our code is available at https://github.com/ADAPT-uiuc/RuleFlow.",
      "tldr_zh": "该研究提出了 RuleFlow，这是一个旨在优化 Pandas 程序的混合框架，有效解决了现有编译器方法局限性大以及 LLM 逐程序优化可靠性低且成本高的问题。该框架采用三阶段工作流程，通过将“发现”与“部署”解耦，并利用创新的桥梁将两者连接。具体而言，RuleFlow 首先利用 LLM 发现针对特定程序的优化（discovery），随后将其转化为通用的重写规则（rewrite rules），最后将这些规则整合进编译器中以实现自动化应用，从而在实际部署中消除了对 LLM 的重复依赖。实验结果表明，RuleFlow 在挑战性的 PandasBench 基准测试上达到了新的 SOTA 水平。与之前的编译器 SOTA 模型 Dias 相比，该框架实现了高达 4.3 倍的加速，而相比系统级 SOTA 模型 Modin，其加速比更是达到了 1914.9 倍，证明了其在生成可重用程序优化方面的卓越性能。",
      "categories": [
        "cs.SE",
        "cs.AI"
      ],
      "primary_category": "cs.SE",
      "comment": "",
      "pdf_url": "https://arxiv.org/pdf/2602.09051v1",
      "published_date": "2026-02-06 21:08:33 UTC",
      "updated_date": "2026-02-06 21:08:33 UTC",
      "processing_status": "completed",
      "attempts": 1,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "llm_backup_calls": 0,
      "last_update": "2026-02-16T05:34:00.727823+00:00"
    },
    {
      "arxiv_id": "2602.09050v1",
      "title": "SAS-Net: Scene-Appearance Separation Network for Robust Spatiotemporal Registration in Bidirectional Photoacoustic Microscopy",
      "title_zh": "SAS-Net：用于双向光声显微成像稳健时空配准的场景-表观分离网络",
      "authors": [
        "Jiahao Qin"
      ],
      "abstract": "High-speed optical-resolution photoacoustic microscopy (OR-PAM) with bidirectional scanning enables rapid functional brain imaging but introduces severe spatiotemporal\n  misalignment from coupled scan-direction-dependent domain shift and geometric distortion. Conventional registration methods rely on brightness constancy, an assumption\n  violated under bidirectional scanning, leading to unreliable alignment. A unified scene-appearance separation framework is proposed to jointly address domain shift and\n  spatial misalignment. The proposed architecture separates domain-invariant scene content from domain-specific appearance characteristics, enabling cross-domain\n  reconstruction with geometric preservation. A scene consistency loss promotes geometric correspondence in the latent space, linking domain shift correction with spatial\n  registration within a single framework. For in vivo mouse brain vasculature imaging, the proposed method achieves normalized cross-correlation (NCC) of 0.961 and\n  structural similarity index (SSIM) of 0.894, substantially outperforming conventional methods. Ablation studies demonstrate that domain alignment loss is critical,\n  with its removal causing 82% NCC reduction (0.961 to 0.175), while scene consistency and cycle consistency losses provide complementary regularization for optimal\n  performance. The method achieves 11.2 ms inference time per frame (86 fps), substantially exceeding typical OR-PAM acquisition rates and enabling real-time processing.\n  These results suggest that the proposed framework enables robust high-speed bidirectional OR-PAM for reliable quantitative and longitudinal functional imaging. The code will be publicly available at https://github.com/D-ST-Sword/SAS-Net",
      "tldr_zh": "该研究提出了SAS-Net，这是一种场景-外观分离网络(Scene-Appearance Separation Network)，旨在解决双向光学分辨率光声显微成像(OR-PAM)中因扫描方向相关的域偏移(Domain Shift)和几何畸变引起的严重时空错位问题。该框架通过将域不变的场景内容与域特定的外观特征分离，实现了具有几何保持特性的跨域重建，有效克服了传统方法对亮度恒定假设的依赖。研究引入了场景一致性损失(Scene Consistency Loss)来促进潜在空间中的几何对应，从而在单一框架内协同完成域偏移校正与空间配准。在活体小鼠脑血管成像实验中，SAS-Net达到了0.961的归一化互相关(NCC)和0.894的结构相似性指数(SSIM)，性能显著优于传统配准算法。此外，该方法的单帧推理时间仅为11.2毫秒(86 fps)，远超典型的OR-PAM数据采集速率，能够支持实时的定量与纵向功能成像处理。",
      "categories": [
        "eess.IV",
        "cs.AI",
        "cs.CV"
      ],
      "primary_category": "eess.IV",
      "comment": "21 pages, 6 figures, 3 tables",
      "pdf_url": "https://arxiv.org/pdf/2602.09050v1",
      "published_date": "2026-02-06 21:01:27 UTC",
      "updated_date": "2026-02-06 21:01:27 UTC",
      "processing_status": "completed",
      "attempts": 1,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "llm_backup_calls": 0,
      "last_update": "2026-02-16T05:34:03.008883+00:00"
    },
    {
      "arxiv_id": "2602.07193v2",
      "title": "\"Death\" of a Chatbot: Investigating and Designing Toward Psychologically Safe Endings for Human-AI Relationships",
      "title_zh": "聊天机器人的“死亡”：面向人机关系心理安全终结的调研与设计",
      "authors": [
        "Rachel Poonsiriwong",
        "Chayapatr Archiwaranguprok",
        "Pat Pataranutaporn"
      ],
      "abstract": "Millions of users form emotional attachments to AI companions like Character AI, Replika, and ChatGPT. When these relationships end through model updates, safety interventions, or platform shutdowns, users receive no closure, reporting grief comparable to human loss. As regulations mandate protections for vulnerable users, discontinuation events will accelerate, yet no platform has implemented deliberate end-of-\"life\" design.\n  Through grounded theory analysis of AI companion communities, we find that discontinuation is a sense-making process shaped by how users attribute agency, perceive finality, and anthropomorphize their companions. Strong anthropomorphization co-occurs with intense grief; users who perceive change as reversible become trapped in fixing cycles; while user-initiated endings demonstrate greater closure. Synthesizing grief psychology with Self-Determination Theory, we develop four design principles and artifacts demonstrating how platforms might provide closure and orient users toward human connection. We contribute the first framework for designing psychologically safe AI companion discontinuation.",
      "tldr_zh": "该研究探讨了用户与Character AI及Replika等AI companions建立情感联结后，因平台更新或关闭导致关系终结所引发的心理影响。通过扎根理论(grounded theory)对用户社区进行分析，研究发现停用(discontinuation)是一个受代理权归因、终结感认知及拟人化(anthropomorphization)程度影响的意义构建过程，强拟人化往往伴随着与人类丧亲相当的强烈悲伤。研究指出，认为变化可逆的用户容易陷入修复循环，而用户主动发起的终结则更有利于获得心理闭环(closure)。结合悲伤心理学(grief psychology)与自我决定理论(Self-Determination Theory)，本文提出了四项设计原则和相关制品，旨在帮助平台提供闭环并引导用户回归人类社交。该研究贡献了首个用于设计心理安全的人机关系终结(AI companion discontinuation)的系统性框架。",
      "categories": [
        "cs.HC",
        "cs.AI"
      ],
      "primary_category": "cs.HC",
      "comment": "",
      "pdf_url": "https://arxiv.org/pdf/2602.07193v2",
      "published_date": "2026-02-06 20:57:37 UTC",
      "updated_date": "2026-02-10 14:51:07 UTC",
      "processing_status": "completed",
      "attempts": 1,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "llm_backup_calls": 0,
      "last_update": "2026-02-16T05:34:06.911190+00:00"
    },
    {
      "arxiv_id": "2602.07190v1",
      "title": "Long-Context Long-Form Question Answering for Legal Domain",
      "title_zh": "面向法律领域的长上下文长篇问答系统",
      "authors": [
        "Anagha Kulkarni",
        "Parin Rajesh Jhaveri",
        "Prasha Shrestha",
        "Yu Tong Han",
        "Reza Amini",
        "Behrouz Madahian"
      ],
      "abstract": "Legal documents have complex document layouts involving multiple nested sections, lengthy footnotes and further use specialized linguistic devices like intricate syntax and domain-specific vocabulary to ensure precision and authority. These inherent characteristics of legal documents make question answering challenging, and particularly so when the answer to the question spans several pages (i.e. requires long-context) and is required to be comprehensive (i.e. a long-form answer). In this paper, we address the challenges of long-context question answering in context of long-form answers given the idiosyncrasies of legal documents. We propose a question answering system that can (a) deconstruct domain-specific vocabulary for better retrieval from source documents, (b) parse complex document layouts while isolating sections and footnotes and linking them appropriately, (c) generate comprehensive answers using precise domain-specific vocabulary. We also introduce a coverage metric that classifies the performance into recall-based coverage categories allowing human users to evaluate the recall with ease. We curate a QA dataset by leveraging the expertise of professionals from fields such as law and corporate tax. Through comprehensive experiments and ablation studies, we demonstrate the usability and merit of the proposed system.",
      "tldr_zh": "该研究针对法律领域长上下文长格式问答（Long-Context Long-Form Question Answering）所面临的挑战，探讨了法律文件因复杂布局、嵌套章节和专业词汇导致的理解难题。为此，论文提出了一种新型问答系统，该系统能够通过解构领域特定词汇来提升检索效率，并能精准解析复杂的文档布局以关联章节与脚注。该系统能够利用精准的专业术语生成全面且详尽的回答。研究还引入了一种基于召回率的覆盖度指标（coverage metric），将性能划分为不同的覆盖类别，显著提升了人类用户评估召回率的便捷性。作者通过整合法律和企业税务专家的专业知识，构建了一个专门的 QA 数据集。实验及消减实验结果表明，该系统在处理法律领域的长文本问答任务中具有显著的优越性和实用性。",
      "categories": [
        "cs.CL",
        "cs.AI"
      ],
      "primary_category": "cs.CL",
      "comment": "EACL 2026",
      "pdf_url": "https://arxiv.org/pdf/2602.07190v1",
      "published_date": "2026-02-06 20:51:13 UTC",
      "updated_date": "2026-02-06 20:51:13 UTC",
      "processing_status": "completed",
      "attempts": 1,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "llm_backup_calls": 0,
      "last_update": "2026-02-16T05:34:22.108056+00:00"
    },
    {
      "arxiv_id": "2602.07187v1",
      "title": "PreFlect: From Retrospective to Prospective Reflection in Large Language Model Agents",
      "title_zh": "PreFlect：大语言模型智能体中从回顾性反思到前瞻性反思",
      "authors": [
        "Hanyu Wang",
        "Yuanpu Cao",
        "Lu Lin",
        "Jinghui Chen"
      ],
      "abstract": "Advanced large language model agents typically adopt self-reflection for improving performance, where agents iteratively analyze past actions to correct errors. However, existing reflective approaches are inherently retrospective: agents act, observe failure, and only then attempt to recover. In this work, we introduce PreFlect, a prospective reflection mechanism that shifts the paradigm from post hoc correction to pre-execution foresight by criticizing and refining agent plans before execution. To support grounded prospective reflection, we distill planning errors from historical agent trajectories, capturing recurring success and failure patterns observed across past executions. Furthermore, we complement prospective reflection with a dynamic re-planning mechanism that provides execution-time plan update in case the original plan encounters unexpected deviation. Evaluations on different benchmarks demonstrate that PreFlect significantly improves overall agent utility on complex real-world tasks, outperforming strong reflection-based baselines and several more complex agent architectures. Code will be updated at https://github.com/wwwhy725/PreFlect.",
      "tldr_zh": "该研究提出了 PreFlect，一种旨在将大型语言模型 (LLM) 智能体的反思范式从执行后修正 (retrospective) 转向执行前预见 (prospective) 的前瞻性反思机制。PreFlect 改变了传统智能体在行动失败后才进行纠错的模式，通过在执行前对计划进行批判性评估和精炼来预防错误。为了增强前瞻性反思的可靠性，该方法从历史轨迹中提炼规划错误，捕捉过去执行中积累的成功与失败模式。此外，该框架还配备了动态重新规划 (dynamic re-planning) 机制，以确保在执行过程中遇到意外偏差时能够及时更新方案。评估结果表明，PreFlect 在处理复杂的现实任务时显著提升了智能体的整体效用，其性能优于多种强力的反思基线模型及复杂的智能体架构。",
      "categories": [
        "cs.AI"
      ],
      "primary_category": "cs.AI",
      "comment": "",
      "pdf_url": "https://arxiv.org/pdf/2602.07187v1",
      "published_date": "2026-02-06 20:42:44 UTC",
      "updated_date": "2026-02-06 20:42:44 UTC",
      "processing_status": "completed",
      "attempts": 1,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "llm_backup_calls": 0,
      "last_update": "2026-02-16T05:34:24.803040+00:00"
    },
    {
      "arxiv_id": "2602.07179v1",
      "title": "An Information-Theoretic Framework for Comparing Voice and Text Explainability",
      "title_zh": "比较语音与文本可解释性的信息论框架",
      "authors": [
        "Mona Rajhans",
        "Vishal Khawarey"
      ],
      "abstract": "Explainable Artificial Intelligence (XAI) aims to make machine learning models transparent and trustworthy, yet most current approaches communicate explanations visually or through text. This paper introduces an information theoretic framework for analyzing how explanation modality specifically, voice versus text affects user comprehension and trust calibration in AI systems. The proposed model treats explanation delivery as a communication channel between model and user, characterized by metrics for information retention, comprehension efficiency (CE), and trust calibration error (T CE). A simulation framework implemented in Python was developed to evaluate these metrics using synthetic SHAP based feature attributions across multiple modality style configurations (brief, detailed, and analogy based). Results demonstrate that text explanations achieve higher comprehension efficiency, while voice explanations yield improved trust calibration, with analogy based delivery achieving the best overall trade off. This framework provides a reproducible foundation for designing and benchmarking multimodal explainability systems and can be extended to empirical studies using real SHAP or LIME outputs on open datasets such as the UCI Credit Approval or Kaggle Financial Transactions datasets.",
      "tldr_zh": "该研究提出了一个信息论框架(Information-Theoretic Framework)，旨在分析语音(Voice)与文本(Text)这两种解释模态如何影响用户对可解释人工智能(XAI)系统的理解与信任校准。该模型将解释传递视为模型与用户之间的通信信道，并引入了信息留存、理解效率(CE)和信任校准误差(TCE)等量化指标进行评估。研究者开发了一个Python仿真框架，利用基于SHAP的特征归因数据，在简略、详细和类比(Analogy-based)三种表达风格下对比了不同模态的表现。实验结果表明，文本解释在理解效率方面表现更佳，而语音解释则在改善信任校准方面更具优势。研究发现基于类比的交付方式在各项指标间实现了最佳的权衡。该框架为设计和基准测试多模态可解释系统提供了可重复的基础，并可扩展至UCI Credit Approval或Kaggle Financial Transactions等真实数据集的实证研究。",
      "categories": [
        "cs.HC",
        "cs.AI",
        "cs.CL",
        "cs.CY",
        "cs.IT"
      ],
      "primary_category": "cs.HC",
      "comment": "Accepted for publication at the 10th ACM International Conference on Intelligent Systems, Metaheuristics & Swarm Intelligence (ISMSI 2026), April 24-26, Cebu City, Phillipines",
      "pdf_url": "https://arxiv.org/pdf/2602.07179v1",
      "published_date": "2026-02-06 20:28:46 UTC",
      "updated_date": "2026-02-06 20:28:46 UTC",
      "processing_status": "completed",
      "attempts": 1,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "llm_backup_calls": 0,
      "last_update": "2026-02-16T05:34:28.410160+00:00"
    },
    {
      "arxiv_id": "2602.07176v1",
      "title": "Open TutorAI: An Open-source Platform for Personalized and Immersive Learning with Generative AI",
      "title_zh": "Open TutorAI：基于生成式人工智能的个性化与沉浸式学习开源平台",
      "authors": [
        "Mohamed El Hajji",
        "Tarek Ait Baha",
        "Aicha Dakir",
        "Hammou Fadili",
        "Youssef Es-Saady"
      ],
      "abstract": "Recent advances in artificial intelligence have created new possibilities for making education more scalable, adaptive, and learner-centered. However, existing educational chatbot systems often lack contextual adaptability, real-time responsiveness, and pedagogical agility. which can limit learner engagement and diminish instructional effectiveness. Thus, there is a growing need for open, integrative platforms that combine AI and immersive technologies to support personalized, meaningful learning experiences. This paper presents Open TutorAI, an open-source educational platform based on LLMs and generative technologies that provides dynamic, personalized tutoring. The system integrates natural language processing with customizable 3D avatars to enable multimodal learner interaction. Through a structured onboarding process, it captures each learner's goals and preferences in order to configure a learner-specific AI assistant. This assistant is accessible via both text-based and avatar-driven interfaces. The platform includes tools for organizing content, providing embedded feedback, and offering dedicated interfaces for learners, educators, and parents. This work focuses on learner-facing components, delivering a tool for adaptive support that responds to individual learner profiles without requiring technical expertise. Its assistant-generation pipeline and avatar integration enhance engagement and emotional presence, creating a more humanized, immersive learning environment. Embedded learning analytics support self-regulated learning by tracking engagement patterns and generating actionable feedback. The result is Open TutorAI, which unites modular architecture, generative AI, and learner analytics within an open-source framework. It contributes to the development of next-generation intelligent tutoring systems.",
      "tldr_zh": "该研究推出了 Open TutorAI，这是一个基于大语言模型 (LLMs) 和生成式技术的开源教育平台，旨在通过提供动态、个性化的辅导来解决现有聊天机器人系统在语境适应性和教学灵活性方面的局限。该平台将自然语言处理 (NLP) 与可定制的 3D avatars 相结合，通过多模态互动和结构化的入职流程，为学习者量身定制特定的 AI 助手。系统支持文本和虚拟人驱动的界面，并集成了内容组织工具、嵌入式反馈以及面向学生、教师和家长的专用功能。通过助手生成流水线 (assistant-generation pipeline) 和虚拟人集成，平台显著增强了学习者的参与度和情感存在感，营造了更具人性化和沉浸感的学习环境。此外，内置的学习分析 (learning analytics) 模块通过追踪学习模式提供反馈，支持自我调节学习。Open TutorAI 通过整合模块化架构与生成式 AI，为下一代智能辅导系统 (intelligent tutoring systems) 的开发提供了重要参考。",
      "categories": [
        "cs.CL",
        "cs.AI",
        "cs.ET",
        "cs.HC"
      ],
      "primary_category": "cs.CL",
      "comment": "19 pages, 15 figures",
      "pdf_url": "https://arxiv.org/pdf/2602.07176v1",
      "published_date": "2026-02-06 20:24:33 UTC",
      "updated_date": "2026-02-06 20:24:33 UTC",
      "processing_status": "completed",
      "attempts": 1,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "llm_backup_calls": 0,
      "last_update": "2026-02-16T05:34:33.406538+00:00"
    },
    {
      "arxiv_id": "2602.07164v1",
      "title": "Your Language Model Secretly Contains Personality Subnetworks",
      "title_zh": "语言模型中隐秘存在的人格子网络",
      "authors": [
        "Ruimeng Ye",
        "Zihan Wang",
        "Zinan Ling",
        "Yang Xiao",
        "Manling Li",
        "Xiaolong Ma",
        "Bo Hui"
      ],
      "abstract": "Humans shift between different personas depending on social context. Large Language Models (LLMs) demonstrate a similar flexibility in adopting different personas and behaviors. Existing approaches, however, typically adapt such behavior through external knowledge such as prompting, retrieval-augmented generation (RAG), or fine-tuning. We ask: do LLMs really need external context or parameters to adapt to different behaviors, or do they already have such knowledge embedded in their parameters? In this work, we show that LLMs already contain persona-specialized subnetworks in their parameter space. Using small calibration datasets, we identify distinct activation signatures associated with different personas. Guided by these statistics, we develop a masking strategy that isolates lightweight persona subnetworks. Building on the findings, we further discuss: how can we discover opposing subnetwork from the model that lead to binary-opposing personas, such as introvert-extrovert? To further enhance separation in binary opposition scenarios, we introduce a contrastive pruning strategy that identifies parameters responsible for the statistical divergence between opposing personas. Our method is entirely training-free and relies solely on the language model's existing parameter space. Across diverse evaluation settings, the resulting subnetworks exhibit significantly stronger persona alignment than baselines that require external knowledge while being more efficient. Our findings suggest that diverse human-like behaviors are not merely induced in LLMs, but are already embedded in their parameter space, pointing toward a new perspective on controllable and interpretable personalization in large language models.",
      "tldr_zh": "该研究探讨了大语言模型(LLMs)是否需要外部上下文或微调来适应不同人格(personas)，还是其内部参数空间已嵌入了相关知识。研究发现大语言模型(LLMs)内部实际上包含人格专门化的子网络(persona-specialized subnetworks)。作者利用小型校准数据集识别出与不同人格相关的独特激活签名(activation signatures)，并开发了一种掩码策略(masking strategy)来分离出轻量级的人格子网络。针对内向与外向等二元对立的人格，研究进一步引入了对比剪枝策略(contrastive pruning strategy)以识别导致统计差异的关键参数。该方法完全无需训练(training-free)，仅依赖于模型现有的参数空间。实验结果表明，所识别出的子网络在多项评估中展现出比依赖外部知识的基线方法更强的人格一致性(persona alignment)且更具效率。该发现表明多样化的人类行为模式已深植于模型参数中，为实现大语言模型(LLMs)可控且可解释的个性化提供了全新视角。",
      "categories": [
        "cs.CL",
        "cs.AI"
      ],
      "primary_category": "cs.CL",
      "comment": "ICLR 2026",
      "pdf_url": "https://arxiv.org/pdf/2602.07164v1",
      "published_date": "2026-02-06 20:03:28 UTC",
      "updated_date": "2026-02-06 20:03:28 UTC",
      "processing_status": "completed",
      "attempts": 1,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "llm_backup_calls": 0,
      "last_update": "2026-02-16T05:34:34.403890+00:00"
    },
    {
      "arxiv_id": "2602.07160v1",
      "title": "Free Energy Mixer",
      "title_zh": "自由能混合器",
      "authors": [
        "Jiecheng Lu",
        "Shihao Yang"
      ],
      "abstract": "Standard attention stores keys/values losslessly but reads them via a per-head convex average, blocking channel-wise selection. We propose the Free Energy Mixer (FEM): a free-energy (log-sum-exp) read that applies a value-driven, per-channel log-linear tilt to a fast prior (e.g., from queries/keys in standard attention) over indices. Unlike methods that attempt to improve and enrich the $(q,k)$ scoring distribution, FEM treats it as a prior and yields a value-aware posterior read at unchanged complexity, smoothly moving from averaging to per-channel selection as the learnable inverse temperature increases, while still preserving parallelism and the original asymptotic complexity ($O(T^2)$ for softmax; $O(T)$ for linearizable variants). We instantiate a two-level gated FEM that is plug-and-play with standard and linear attention, linear RNNs and SSMs. It consistently outperforms strong baselines on NLP, vision, and time-series at matched parameter budgets.",
      "tldr_zh": "该研究提出了Free Energy Mixer (FEM)，旨在解决标准注意力机制通过每头凸平均读取数据时无法进行通道级选择的问题。FEM引入了基于自由能(log-sum-exp)的读取方式，通过对由查询和键生成的先验分布应用值驱动的、逐通道对数线性偏移，实现了感知值的后验读取。通过引入可学习的反温度(inverse temperature)参数，该机制能够在保持原始渐近复杂度($O(T^2)$或线性化的$O(T)$)的前提下，实现从平均读取到逐通道选择的平滑转换。作为一种即插即用的模块，FEM可广泛应用于标准注意力、线性RNN和状态空间模型(SSMs)。实验结果证明，在相同的参数预算下，门控FEM在自然语言处理(NLP)、计算机视觉及时间序列任务中均显著优于现有主流基线模型。",
      "categories": [
        "cs.CL",
        "cs.AI",
        "cs.LG",
        "stat.ML"
      ],
      "primary_category": "cs.CL",
      "comment": "Camera-ready version. Accepted at ICLR 2026",
      "pdf_url": "https://arxiv.org/pdf/2602.07160v1",
      "published_date": "2026-02-06 20:02:47 UTC",
      "updated_date": "2026-02-06 20:02:47 UTC",
      "processing_status": "completed",
      "attempts": 1,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "llm_backup_calls": 0,
      "last_update": "2026-02-16T05:34:41.402692+00:00"
    },
    {
      "arxiv_id": "2602.07156v1",
      "title": "Mimetic Initialization of MLPs",
      "title_zh": "MLPs 的拟态初始化",
      "authors": [
        "Asher Trockman",
        "J. Zico Kolter"
      ],
      "abstract": "Mimetic initialization uses pretrained models as case studies of good initialization, using observations of structures in trained weights to inspire new, simple initialization techniques. So far, it has been applied only to spatial mixing layers, such convolutional, self-attention, and state space layers. In this work, we present the first attempt to apply the method to channel mixing layers, namely multilayer perceptrons (MLPs). Our extremely simple technique for MLPs -- to give the first layer a nonzero mean -- speeds up training on small-scale vision tasks like CIFAR-10 and ImageNet-1k. Though its effect is much smaller than spatial mixing initializations, it can be used in conjunction with them for an additional positive effect.",
      "tldr_zh": "该研究探讨了模拟初始化(Mimetic Initialization)，这是一种利用预训练模型中权重的结构特征来启发新型初始化方案的技术。此前模拟初始化主要应用于卷积或自注意力等空间混合层(spatial mixing layers)，而本工作首次将其拓展至多层感知机(MLPs)等通道混合层(channel mixing layers)。研究提出了一种针对MLPs的极简初始化方法，即为第一层赋予非零均值(nonzero mean)，旨在优化训练动态。实验表明，该方法在CIFAR-10和ImageNet-1k等小规模视觉任务中能有效加快训练速度。虽然其独立效果比空间混合层初始化稍弱，但两者结合使用时能产生额外的增益。该研究通过借鉴已训练模型的结构，为MLP初始化提供了一种简单且有效的新视角。",
      "categories": [
        "cs.LG",
        "cs.AI",
        "cs.CV"
      ],
      "primary_category": "cs.LG",
      "comment": "",
      "pdf_url": "https://arxiv.org/pdf/2602.07156v1",
      "published_date": "2026-02-06 19:59:17 UTC",
      "updated_date": "2026-02-06 19:59:17 UTC",
      "processing_status": "completed",
      "attempts": 1,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "llm_backup_calls": 0,
      "last_update": "2026-02-16T05:34:45.809959+00:00"
    },
    {
      "arxiv_id": "2602.07154v1",
      "title": "Beyond Pooling: Matching for Robust Generalization under Data Heterogeneity",
      "title_zh": "超越池化：面向数据异质性下稳健泛化的匹配方法",
      "authors": [
        "Ayush Roy",
        "Rudrasis Chakraborty",
        "Lav Varshney",
        "Vishnu Suresh Lokhande"
      ],
      "abstract": "Pooling heterogeneous datasets across domains is a common strategy in representation learning, but naive pooling can amplify distributional asymmetries and yield biased estimators, especially in settings where zero-shot generalization is required. We propose a matching framework that selects samples relative to an adaptive centroid and iteratively refines the representation distribution. The double robustness and the propensity score matching for the inclusion of data domains make matching more robust than naive pooling and uniform subsampling by filtering out the confounding domains (the main cause of heterogeneity). Theoretical and empirical analyses show that, unlike naive pooling or uniform subsampling, matching achieves better results under asymmetric meta-distributions, which are also extended to non-Gaussian and multimodal real-world settings. Most importantly, we show that these improvements translate to zero-shot medical anomaly detection, one of the extreme forms of data heterogeneity and asymmetry. The code is available on https://github.com/AyushRoy2001/Beyond-Pooling.",
      "tldr_zh": "该研究提出了一个针对数据异质性（Data Heterogeneity）的匹配框架，旨在解决在跨域表示学习中，简单的池化（Naive Pooling）策略可能导致的分布不对称及估计偏倚问题。该框架通过自适应质心选择样本，并利用倾向评分匹配（Propensity Score Matching）和双重稳健性（Double Robustness）技术过滤混杂域，从而迭代优化表示分布。理论与实验分析表明，该方法在非高斯和多模态等非对称元分布场景下，表现优于简单的池化或均匀下采样方法。最重要的是，该研究证明了匹配框架能显著提升零样本（Zero-shot）医疗异常检测的泛化性能，为处理极端数据异质性和不对称性提供了有效的解决方案。",
      "categories": [
        "cs.LG",
        "cs.AI"
      ],
      "primary_category": "cs.LG",
      "comment": "AISTATS 2026",
      "pdf_url": "https://arxiv.org/pdf/2602.07154v1",
      "published_date": "2026-02-06 19:56:02 UTC",
      "updated_date": "2026-02-06 19:56:02 UTC",
      "processing_status": "completed",
      "attempts": 1,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "llm_backup_calls": 0,
      "last_update": "2026-02-16T05:34:44.406027+00:00"
    },
    {
      "arxiv_id": "2602.07153v1",
      "title": "ANCHOR: Branch-Point Data Generation for GUI Agents",
      "title_zh": "ANCHOR：面向 GUI 智能体的分支点数据生成",
      "authors": [
        "Jinbiao Wei",
        "Yilun Zhao",
        "Kangqi Ni",
        "Arman Cohan"
      ],
      "abstract": "End-to-end GUI agents for real desktop environments require large amounts of high-quality interaction data, yet collecting human demonstrations is expensive and existing synthetic pipelines often suffer from limited task diversity or noisy, goal-drifting trajectories. We present a trajectory expansion framework Anchor that bootstraps scalable desktop supervision from a small set of verified seed demonstrations. Starting from each seed, we identify branch points that correspond to meaningful state changes and propose new, state-grounded task variants conditioned on the current GUI context. An executing agent then follows the proposed instructions to generate new trajectories, while a verifier enforces task completion via state-aware checks and trajectory-level consistency. To improve supervision quality, we further apply task-conditioned step-level filtering to remove ungrounded actions and denoise post-branch segments to maintain coherent intent. Experiments on standard desktop benchmarks, OSWorld and WindowsAgentArena, show that models fine-tuned on our expanded corpus achieve consistent improvements over zero-shot agents and representative synthesis baselines, and generalize across applications and operating systems.",
      "tldr_zh": "该研究提出了ANCHOR，一种用于GUI智能体的分支点数据生成框架，旨在通过少量的验证种子演示扩展出大规模且高质量的桌面操作系统监督数据。该框架从种子轨迹中识别出具有重要状态变化的分支点，结合当前GUI上下文生成与状态关联的新任务变体，并通过执行智能体生成新轨迹。为了确保数据质量，ANCHOR采用了状态感知的校验器和轨迹级一致性检查，同时利用步骤级过滤和后分支段去噪技术来移除无关操作并保持任务意图的连贯性。在OSWorld和WindowsAgentArena等标准桌面基准测试上的实验结果显示，经由该框架生成的语料库微调后的模型在跨应用和跨操作系统的任务中均表现出比零样本智能体及合成基线模型更显著且一致的性能提升。",
      "categories": [
        "cs.AI"
      ],
      "primary_category": "cs.AI",
      "comment": "",
      "pdf_url": "https://arxiv.org/pdf/2602.07153v1",
      "published_date": "2026-02-06 19:55:26 UTC",
      "updated_date": "2026-02-06 19:55:26 UTC",
      "processing_status": "completed",
      "attempts": 1,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "llm_backup_calls": 0,
      "last_update": "2026-02-16T05:34:47.712971+00:00"
    },
    {
      "arxiv_id": "2602.07150v1",
      "title": "On Randomness in Agentic Evals",
      "title_zh": "论智能体测评中的随机性",
      "authors": [
        "Bjarni Haukur Bjarnason",
        "André Silva",
        "Martin Monperrus"
      ],
      "abstract": "Agentic systems are evaluated on benchmarks where agents interact with environments to solve tasks. Most papers report a pass@1 score computed from a single run per task, assuming this gives a reliable performance estimate. We test this assumption by collecting 60,000 agentic trajectories on SWE-Bench-Verified, spanning three models and two scaffolds. We find substantial variance: single-run pass@1 estimates vary by 2.2 to 6.0 percentage points depending on which run is selected, with standard deviations exceeding 1.5 percentage points even at temperature 0. This variance has critical implications: reported improvements of 2--3 percentage points may reflect evaluation noise rather than genuine algorithmic progress. Through token-level analysis, we show that trajectories diverge early, often within the first few percent of tokens, and that these small differences cascade into different solution strategies. To enable reliable evaluation of agentic systems, we recommend three concrete practices: (1) estimate pass@1 from multiple independent runs per task, especially when measuring small improvements, (2) use statistical power analysis to determine the number of runs needed to detect expected effect sizes, and (3) consider metrics like pass@k (optimistic bound) and pass^k (pessimistic bound) with k>1 to better characterize the full performance envelope. While these practices increase evaluation cost, they are essential for distinguishing genuine scientific progress from statistical noise.",
      "tldr_zh": "该研究探讨了智能体系统(Agentic systems)评估中的随机性问题，挑战了目前普遍依赖单次运行计算 pass@1 分数来衡量性能的惯例。研究者通过在 SWE-Bench-Verified 基准上收集 60,000 条轨迹，发现即便在 temperature 为 0 的情况下，单次运行的 pass@1 估值波动仍可达 2.2 到 6.0 个百分点。这意味着许多文献中报道的 2-3% 的性能提升可能仅仅是评估噪声，而非实质性的算法进步。token 级别的分析进一步揭示，轨迹在极早期就会发生偏离，并随之级联出完全不同的解决策略。为此，作者建议通过多次独立运行来估算 pass@1，利用统计效能分析(statistical power analysis)确定所需的运行次数，并引入 pass@k 和 pass^k 等指标来更全面地刻画模型能力。这些建议虽然增加了评估成本，但对于在智能体研究中区分真实的科学进展与统计噪声至关重要。",
      "categories": [
        "cs.LG",
        "cs.AI",
        "cs.SE"
      ],
      "primary_category": "cs.LG",
      "comment": "",
      "pdf_url": "https://arxiv.org/pdf/2602.07150v1",
      "published_date": "2026-02-06 19:49:13 UTC",
      "updated_date": "2026-02-06 19:49:13 UTC",
      "processing_status": "completed",
      "attempts": 1,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "llm_backup_calls": 0,
      "last_update": "2026-02-16T05:34:51.510785+00:00"
    },
    {
      "arxiv_id": "2602.07144v1",
      "title": "BONSAI: Bayesian Optimization with Natural Simplicity and Interpretability",
      "title_zh": "BONSAI：兼具自然简约性与可解释性的贝叶斯优化",
      "authors": [
        "Samuel Daulton",
        "David Eriksson",
        "Maximilian Balandat",
        "Eytan Bakshy"
      ],
      "abstract": "Bayesian optimization (BO) is a popular technique for sample-efficient optimization of black-box functions. In many applications, the parameters being tuned come with a carefully engineered default configuration, and practitioners only want to deviate from this default when necessary. Standard BO, however, does not aim to minimize deviation from the default and, in practice, often pushes weakly relevant parameters to the boundary of the search space. This makes it difficult to distinguish between important and spurious changes and increases the burden of vetting recommendations when the optimization objective omits relevant operational considerations. We introduce BONSAI, a default-aware BO policy that prunes low-impact deviations from a default configuration while explicitly controlling the loss in acquisition value. BONSAI is compatible with a variety of acquisition functions, including expected improvement and upper confidence bound (GP-UCB). We theoretically bound the regret incurred by BONSAI, showing that, under certain conditions, it enjoys the same no-regret property as vanilla GP-UCB. Across many real-world applications, we empirically find that BONSAI substantially reduces the number of non-default parameters in recommended configurations while maintaining competitive optimization performance, with little effect on wall time.",
      "tldr_zh": "该研究提出了BONSAI，一种具备自然简洁性与可解释性的默认感知（default-aware）贝叶斯优化（Bayesian Optimization, BO）策略。针对标准BO在优化黑盒函数时往往忽略默认配置（default configuration）且易使弱相关参数产生无效偏移的问题，BONSAI通过剪枝对结果影响较小的偏差，在显式控制采集值（acquisition value）损失的同时优化配置。该框架与预期改进（expected improvement）及上置信界（GP-UCB）等多种采集函数兼容。理论证明，在特定条件下BONSAI具有与vanilla GP-UCB相同的无悔（no-regret）性质。实验结果表明，该方法在多种现实应用中显著减少了推荐配置中非默认参数的数量，且能在几乎不增加计算耗时的前提下保持极具竞争力的优化性能。",
      "categories": [
        "cs.LG",
        "cs.AI",
        "stat.ML"
      ],
      "primary_category": "cs.LG",
      "comment": "26 pages",
      "pdf_url": "https://arxiv.org/pdf/2602.07144v1",
      "published_date": "2026-02-06 19:40:26 UTC",
      "updated_date": "2026-02-06 19:40:26 UTC",
      "processing_status": "completed",
      "attempts": 1,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "llm_backup_calls": 0,
      "last_update": "2026-02-16T05:35:04.607078+00:00"
    },
    {
      "arxiv_id": "2602.07142v1",
      "title": "Exploring Teachers' Perspectives on Using Conversational AI Agents for Group Collaboration",
      "title_zh": "探究教师对在小组协作中使用对话式 AI 智能体的看法",
      "authors": [
        "Prerna Ravi",
        "Carúmey Stevens",
        "Beatriz Flamia Azevedo",
        "Jasmine David",
        "Brandon Hanks",
        "Hal Abelson",
        "Grace Lin",
        "Emma Anderson"
      ],
      "abstract": "Collaboration is a cornerstone of 21st-century learning, yet teachers continue to face challenges in supporting productive peer interaction. Emerging generative AI tools offer new possibilities for scaffolding collaboration, but their role in mediating in-person group work remains underexplored, especially from the perspective of educators. This paper presents findings from an exploratory qualitative study with 33 K12 teachers who interacted with Phoenix, a voice-based conversational agent designed to function as a near-peer in face-to-face group collaboration. Drawing on playtesting sessions, surveys, and focus groups, we examine how teachers perceived the agent's behavior, its influence on group dynamics, and its classroom potential. While many appreciated Phoenix's capacity to stimulate engagement, they also expressed concerns around autonomy, trust, anthropomorphism, and pedagogical alignment. We contribute empirical insights into teachers' mental models of AI, reveal core design tensions, and outline considerations for group-facing AI agents that support meaningful, collaborative learning.",
      "tldr_zh": "这项探索性定性研究通过与33名K12教师的互动，探讨了教育工作者对于在小组协作中使用对话式人工智能(Conversational AI)代理的看法。研究引入了名为Phoenix的语音代理，其旨在面对面小组合作中扮演“准同伴”(near-peer)的角色，并通过测试、调查和焦点小组收集实证数据。结果显示，尽管教师们认可Phoenix在激发学生参与度(Engagement)方面的潜力，但同时也对自主权(Autonomy)、信任、拟人化(Anthropomorphism)和教学对齐(Pedagogical Alignment)表达了显著担忧。该研究提供了关于教师对人工智能心智模型(Mental Models)的深刻见解，揭示了核心设计张力，并为开发能有效支持协作学习的面向小组的AI代理提出了关键的设计考量。",
      "categories": [
        "cs.HC",
        "cs.AI"
      ],
      "primary_category": "cs.HC",
      "comment": "",
      "pdf_url": "https://arxiv.org/pdf/2602.07142v1",
      "published_date": "2026-02-06 19:29:13 UTC",
      "updated_date": "2026-02-06 19:29:13 UTC",
      "processing_status": "completed",
      "attempts": 1,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "llm_backup_calls": 0,
      "last_update": "2026-02-16T05:35:07.611699+00:00"
    },
    {
      "arxiv_id": "2602.07135v2",
      "title": "Landscaper: Understanding Loss Landscapes Through Multi-Dimensional Topological Analysis",
      "title_zh": "Landscaper：基于多维拓扑分析的损失景观探究",
      "authors": [
        "Jiaqing Chen",
        "Nicholas Hadler",
        "Tiankai Xie",
        "Rostyslav Hnatyshyn",
        "Caleb Geniesse",
        "Yaoqing Yang",
        "Michael W. Mahoney",
        "Talita Perciano",
        "John F. Hartwig",
        "Ross Maciejewski",
        "Gunther H. Weber"
      ],
      "abstract": "Loss landscapes are a powerful tool for understanding neural network optimization and generalization, yet traditional low-dimensional analyses often miss complex topological features. We present Landscaper, an open-source Python package for arbitrary-dimensional loss landscape analysis. Landscaper combines Hessian-based subspace construction with topological data analysis to reveal geometric structures such as basin hierarchy and connectivity. A key component is the Saddle-Minimum Average Distance (SMAD) for quantifying landscape smoothness. We demonstrate Landscaper's effectiveness across various architectures and tasks, including those involving pre-trained language models, showing that SMAD captures training transitions, such as landscape simplification, that conventional metrics miss. We also illustrate Landscaper's performance in challenging chemical property prediction tasks, where SMAD can serve as a metric for out-of-distribution generalization, offering valuable insights for model diagnostics and architecture design in data-scarce scientific machine learning scenarios.",
      "tldr_zh": "该研究推出了Landscaper，一个用于任意维度损失地形(Loss Landscapes)分析的开源Python工具包。为了弥补传统低维分析在捕捉复杂拓扑特征方面的不足，Landscaper结合了基于Hessian矩阵的子空间构建与拓扑数据分析(Topological Data Analysis)技术，旨在揭示盆地层次和连通性等几何结构。其核心创新在于提出了鞍点-极小值平均距离(Saddle-Minimum Average Distance, SMAD)指标，用于精确量化地形的平滑程度。通过在预训练语言模型等多种架构上的应用，实验证明SMAD能够捕捉到传统指标忽略的训练阶段地形简化过程。此外，在具有挑战性的化学性质预测任务中，Landscaper证明了SMAD可作为分布外泛化(Out-of-Distribution Generalization)的评估度量。该研究为科学机器学习中的模型诊断和架构设计提供了全新的视角与工具支持。",
      "categories": [
        "cs.LG",
        "cs.AI"
      ],
      "primary_category": "cs.LG",
      "comment": "",
      "pdf_url": "https://arxiv.org/pdf/2602.07135v2",
      "published_date": "2026-02-06 19:17:08 UTC",
      "updated_date": "2026-02-12 17:33:30 UTC",
      "processing_status": "completed",
      "attempts": 1,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "llm_backup_calls": 0,
      "last_update": "2026-02-16T05:35:09.509559+00:00"
    },
    {
      "arxiv_id": "2602.07125v1",
      "title": "Reasoning-Augmented Representations for Multimodal Retrieval",
      "title_zh": "推理增强的多模态检索表示方式",
      "authors": [
        "Jianrui Zhang",
        "Anirudh Sundara Rajan",
        "Brandon Han",
        "Soochahn Lee",
        "Sukanta Ganguly",
        "Yong Jae Lee"
      ],
      "abstract": "Universal Multimodal Retrieval (UMR) seeks any-to-any search across text and vision, yet modern embedding models remain brittle when queries require latent reasoning (e.g., resolving underspecified references or matching compositional constraints). We argue this brittleness is often data-induced: when images carry \"silent\" evidence and queries leave key semantics implicit, a single embedding pass must both reason and compress, encouraging spurious feature matching. We propose a data-centric framework that decouples these roles by externalizing reasoning before retrieval. Using a strong Vision--Language Model, we make implicit semantics explicit by densely captioning visual evidence in corpus entries, resolving ambiguous multimodal references in queries, and rewriting verbose instructions into concise retrieval constraints. Inference-time enhancement alone is insufficient; the retriever must be trained on these semantically dense representations to avoid distribution shift and fully exploit the added signal. Across M-BEIR, our reasoning-augmented training method yields consistent gains over strong baselines, with ablations showing that corpus enhancement chiefly benefits knowledge-intensive queries while query enhancement is critical for compositional modification requests. We publicly release our code at https://github.com/AugmentedRetrieval/ReasoningAugmentedRetrieval.",
      "tldr_zh": "该研究提出了推理增强表征(Reasoning-Augmented Representations)框架，旨在解决通用多模态检索(Universal Multimodal Retrieval)在处理需要潜在大脑推理的复杂查询时表现出的脆弱性。作者认为这种脆弱性源于数据本身，即图像中的“沉默”证据与查询中的隐式语义迫使嵌入模型同时承担推理和压缩的压力，导致虚假的特征匹配。为了应对这一挑战，该框架利用强大的视觉语言模型(Vision-Language Model)将推理过程外部化，通过对语料进行密集描述、解析查询中的歧义引用以及重写长指令，使隐式语义显式化。研究强调仅在推理阶段增强是不够的，检索器必须在这些语义密集的表征上进行训练，以避免分布偏移并充分利用新增信号。在M-BEIR基准测试上的实验表明，该训练方法较强基线模型取得了持续增益，其中语料库增强主要惠及知识密集型查询，而查询增强对于组合修改请求至关重要。",
      "categories": [
        "cs.IR",
        "cs.AI",
        "cs.CV",
        "cs.LG"
      ],
      "primary_category": "cs.IR",
      "comment": "",
      "pdf_url": "https://arxiv.org/pdf/2602.07125v1",
      "published_date": "2026-02-06 19:01:54 UTC",
      "updated_date": "2026-02-06 19:01:54 UTC",
      "processing_status": "completed",
      "attempts": 1,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "llm_backup_calls": 0,
      "last_update": "2026-02-16T05:35:06.302045+00:00"
    }
  ],
  "processing_status": "completed",
  "error": null,
  "raw_papers_fetched": true,
  "papers_count": 394,
  "processed_papers_count": 394,
  "failed_papers_count": 0,
  "llm_backup_calls": 0,
  "summary_generated": true,
  "daily_data_saved": true,
  "last_update": "2026-02-16T05:36:03.246930+00:00"
}