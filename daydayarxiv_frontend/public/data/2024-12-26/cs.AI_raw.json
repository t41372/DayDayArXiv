[
  {
    "arxiv_id": "2412.19363v2",
    "title": "Large Language Models for Market Research: A Data-augmentation Approach",
    "authors": [
      "Mengxin Wang",
      "Dennis J. Zhang",
      "Heng Zhang"
    ],
    "abstract": "Large Language Models (LLMs) have transformed artificial intelligence by\nexcelling in complex natural language processing tasks. Their ability to\ngenerate human-like text has opened new possibilities for market research,\nparticularly in conjoint analysis, where understanding consumer preferences is\nessential but often resource-intensive. Traditional survey-based methods face\nlimitations in scalability and cost, making LLM-generated data a promising\nalternative. However, while LLMs have the potential to simulate real consumer\nbehavior, recent studies highlight a significant gap between LLM-generated and\nhuman data, with biases introduced when substituting between the two. In this\npaper, we address this gap by proposing a novel statistical data augmentation\napproach that efficiently integrates LLM-generated data with real data in\nconjoint analysis. Our method leverages transfer learning principles to debias\nthe LLM-generated data using a small amount of human data. This results in\nstatistically robust estimators with consistent and asymptotically normal\nproperties, in contrast to naive approaches that simply substitute human data\nwith LLM-generated data, which can exacerbate bias. We validate our framework\nthrough an empirical study on COVID-19 vaccine preferences, demonstrating its\nsuperior ability to reduce estimation error and save data and costs by 24.9% to\n79.8%. In contrast, naive approaches fail to save data due to the inherent\nbiases in LLM-generated data compared to human data. Another empirical study on\nsports car choices validates the robustness of our results. Our findings\nsuggest that while LLM-generated data is not a direct substitute for human\nresponses, it can serve as a valuable complement when used within a robust\nstatistical framework.",
    "categories": [
      "cs.AI",
      "cs.LG",
      "stat.ME",
      "stat.ML",
      "68T50, 90B60, 62F12",
      "I.2.7; J.4; G.3"
    ],
    "primary_category": "cs.AI",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2412.19363v2",
    "published_date": "2024-12-26 22:06:29 UTC",
    "updated_date": "2025-01-06 17:33:20 UTC"
  },
  {
    "arxiv_id": "2412.19360v1",
    "title": "Improving the network traffic classification using the Packet Vision approach",
    "authors": [
      "Rodrigo Moreira",
      "Larissa Ferreira Rodrigues",
      "Pedro Frosi Rosa",
      "Flávio de Oliveira Silva"
    ],
    "abstract": "The network traffic classification allows improving the management, and the\nnetwork services offer taking into account the kind of application. The future\nnetwork architectures, mainly mobile networks, foresee intelligent mechanisms\nin their architectural frameworks to deliver application-aware network\nrequirements. The potential of convolutional neural networks capabilities,\nwidely exploited in several contexts, can be used in network traffic\nclassification. Thus, it is necessary to develop methods based on the content\nof packets transforming it into a suitable input for CNN technologies. Hence,\nwe implemented and evaluated the Packet Vision, a method capable of building\nimages from packets raw-data, considering both header and payload. Our approach\nexcels those found in state-of-the-art by delivering security and privacy by\ntransforming the raw-data packet into images. Therefore, we built a dataset\nwith four traffic classes evaluating the performance of three CNNs\narchitectures: AlexNet, ResNet-18, and SqueezeNet. Experiments showcase the\nPacket Vision combined with CNNs applicability and suitability as a promising\napproach to deliver outstanding performance in classifying network traffic.",
    "categories": [
      "cs.NI",
      "cs.AI",
      "cs.CR",
      "cs.CV"
    ],
    "primary_category": "cs.NI",
    "comment": "6 pages",
    "pdf_url": "http://arxiv.org/pdf/2412.19360v1",
    "published_date": "2024-12-26 21:56:03 UTC",
    "updated_date": "2024-12-26 21:56:03 UTC"
  },
  {
    "arxiv_id": "2412.19350v1",
    "title": "On the Expressiveness and Length Generalization of Selective State-Space Models on Regular Languages",
    "authors": [
      "Aleksandar Terzić",
      "Michael Hersche",
      "Giacomo Camposampiero",
      "Thomas Hofmann",
      "Abu Sebastian",
      "Abbas Rahimi"
    ],
    "abstract": "Selective state-space models (SSMs) are an emerging alternative to the\nTransformer, offering the unique advantage of parallel training and sequential\ninference. Although these models have shown promising performance on a variety\nof tasks, their formal expressiveness and length generalization properties\nremain underexplored. In this work, we provide insight into the workings of\nselective SSMs by analyzing their expressiveness and length generalization\nperformance on regular language tasks, i.e., finite-state automaton (FSA)\nemulation. We address certain limitations of modern SSM-based architectures by\nintroducing the Selective Dense State-Space Model (SD-SSM), the first selective\nSSM that exhibits perfect length generalization on a set of various regular\nlanguage tasks using a single layer. It utilizes a dictionary of dense\ntransition matrices, a softmax selection mechanism that creates a convex\ncombination of dictionary matrices at each time step, and a readout consisting\nof layer normalization followed by a linear map. We then proceed to evaluate\nvariants of diagonal selective SSMs by considering their empirical performance\non commutative and non-commutative automata. We explain the experimental\nresults with theoretical considerations. Our code is available at\nhttps://github.com/IBM/selective-dense-state-space-model.",
    "categories": [
      "cs.LG",
      "cs.AI",
      "cs.CL"
    ],
    "primary_category": "cs.LG",
    "comment": "13 pages, 7 figures, to be published in AAAI 2025",
    "pdf_url": "http://arxiv.org/pdf/2412.19350v1",
    "published_date": "2024-12-26 20:53:04 UTC",
    "updated_date": "2024-12-26 20:53:04 UTC"
  },
  {
    "arxiv_id": "2412.19346v1",
    "title": "Semi-Supervised Learning from Small Annotated Data and Large Unlabeled Data for Fine-grained PICO Entity Recognition",
    "authors": [
      "Fangyi Chen",
      "Gongbo Zhang",
      "Yilu Fang",
      "Yifan Peng",
      "Chunhua Weng"
    ],
    "abstract": "Objective: Extracting PICO elements -- Participants, Intervention,\nComparison, and Outcomes -- from clinical trial literature is essential for\nclinical evidence retrieval, appraisal, and synthesis. Existing approaches do\nnot distinguish the attributes of PICO entities. This study aims to develop a\nnamed entity recognition (NER) model to extract PICO entities with fine\ngranularities.\n  Materials and Methods: Using a corpus of 2,511 abstracts with PICO mentions\nfrom 4 public datasets, we developed a semi-supervised method to facilitate the\ntraining of a NER model, FinePICO, by combining limited annotated data of PICO\nentities and abundant unlabeled data. For evaluation, we divided the entire\ndataset into two subsets: a smaller group with annotations and a larger group\nwithout annotations. We then established the theoretical lower and upper\nperformance bounds based on the performance of supervised learning models\ntrained solely on the small, annotated subset and on the entire set with\ncomplete annotations, respectively. Finally, we evaluated FinePICO on both the\nsmaller annotated subset and the larger, initially unannotated subset. We\nmeasured the performance of FinePICO using precision, recall, and F1.\n  Results: Our method achieved precision/recall/F1 of 0.567/0.636/0.60,\nrespectively, using a small set of annotated samples, outperforming the\nbaseline model (F1: 0.437) by more than 16\\%. The model demonstrates\ngeneralizability to a different PICO framework and to another corpus, which\nconsistently outperforms the benchmark in diverse experimental settings\n(p-value \\textless0.001).\n  Conclusion: This study contributes a generalizable and effective\nsemi-supervised approach to named entity recognition leveraging large unlabeled\ndata together with small, annotated data. It also initially supports\nfine-grained PICO extraction.",
    "categories": [
      "cs.CL",
      "cs.AI"
    ],
    "primary_category": "cs.CL",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2412.19346v1",
    "published_date": "2024-12-26 20:24:35 UTC",
    "updated_date": "2024-12-26 20:24:35 UTC"
  },
  {
    "arxiv_id": "2412.19340v1",
    "title": "A Reinforcement Learning-Based Task Mapping Method to Improve the Reliability of Clustered Manycores",
    "authors": [
      "Fatemeh Hossein-Khani",
      "Omid Akbari"
    ],
    "abstract": "The increasing scale of manycore systems poses significant challenges in\nmanaging reliability while meeting performance demands. Simultaneously, these\nsystems become more susceptible to different aging mechanisms such as\nnegative-bias temperature instability (NBTI), hot carrier injection (HCI), and\nthermal cycling (TC), as well as the electromigration (EM) phenomenon. In this\npaper, we propose a reinforcement learning (RL)-based task mapping method to\nimprove the reliability of manycore systems considering the aforementioned\naging mechanisms, which consists of three steps including bin packing,\ntask-to-bin mapping, and task-to-core mapping. In the initial step, a\ndensity-based spatial application with noise (DBSCAN) clustering method is\nemployed to compose some clusters (bins) based on the cores temperature. Then,\nthe Q-learning algorithm is used for the two latter steps, to map the arrived\ntask on a core such that the minimum thermal variation is occurred among all\nthe bins. Compared to the state-of-the-art works, the proposed method is\nperformed during runtime without requiring any parameter to be calculated\noffline. The effectiveness of the proposed technique is evaluated on 16, 32,\nand 64 cores systems using SPLASH2 and PARSEC benchmark suite applications. The\nresults demonstrate up to 27% increase in the mean time to failure (MTTF)\ncompared to the state-of-the-art task mapping techniques.",
    "categories": [
      "cs.LG",
      "cs.AI"
    ],
    "primary_category": "cs.LG",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2412.19340v1",
    "published_date": "2024-12-26 20:08:10 UTC",
    "updated_date": "2024-12-26 20:08:10 UTC"
  },
  {
    "arxiv_id": "2412.19331v2",
    "title": "CALICO: Part-Focused Semantic Co-Segmentation with Large Vision-Language Models",
    "authors": [
      "Kiet A. Nguyen",
      "Adheesh Juvekar",
      "Tianjiao Yu",
      "Muntasir Wahed",
      "Ismini Lourentzou"
    ],
    "abstract": "Recent advances in Large Vision-Language Models (LVLMs) have enabled\ngeneral-purpose vision tasks through visual instruction tuning. While existing\nLVLMs can generate segmentation masks from text prompts for single images, they\nstruggle with segmentation-grounded reasoning across images, especially at\nfiner granularities such as object parts. In this paper, we introduce the new\ntask of part-focused semantic co-segmentation, which involves identifying and\nsegmenting common objects, as well as common and unique object parts across\nimages. To address this task, we present CALICO, the first LVLM designed for\nmulti-image part-level reasoning segmentation. CALICO features two key\ncomponents, a novel Correspondence Extraction Module that identifies semantic\npart-level correspondences, and Correspondence Adaptation Modules that embed\nthis information into the LVLM to facilitate multi-image understanding in a\nparameter-efficient manner. To support training and evaluation, we curate\nMixedParts, a large-scale multi-image segmentation dataset containing\n$\\sim$2.4M samples across $\\sim$44K images spanning diverse object and part\ncategories. Experimental results demonstrate that CALICO, with just 0.3% of its\nparameters finetuned, achieves strong performance on this challenging task.",
    "categories": [
      "cs.CV",
      "cs.AI",
      "cs.LG"
    ],
    "primary_category": "cs.CV",
    "comment": "Accepted to CVPR 2025. Project page:\n  https://plan-lab.github.io/calico/",
    "pdf_url": "http://arxiv.org/pdf/2412.19331v2",
    "published_date": "2024-12-26 18:59:37 UTC",
    "updated_date": "2025-04-03 17:59:25 UTC"
  },
  {
    "arxiv_id": "2412.19325v1",
    "title": "Performance Control in Early Exiting to Deploy Large Models at the Same Cost of Smaller Ones",
    "authors": [
      "Mehrnaz Mofakhami",
      "Reza Bayat",
      "Ioannis Mitliagkas",
      "Joao Monteiro",
      "Valentina Zantedeschi"
    ],
    "abstract": "Early Exiting (EE) is a promising technique for speeding up inference by\nadaptively allocating compute resources to data points based on their\ndifficulty. The approach enables predictions to exit at earlier layers for\nsimpler samples while reserving more computation for challenging ones. In this\nstudy, we first present a novel perspective on the EE approach, showing that\nlarger models deployed with EE can achieve higher performance than smaller\nmodels while maintaining similar computational costs. As existing EE approaches\nrely on confidence estimation at each exit point, we further study the impact\nof overconfidence on the controllability of the compute-performance trade-off.\nWe introduce Performance Control Early Exiting (PCEE), a method that enables\naccuracy thresholding by basing decisions not on a data point's confidence but\non the average accuracy of samples with similar confidence levels from a\nheld-out validation set. In our experiments, we show that PCEE offers a simple\nyet computationally efficient approach that provides better control over\nperformance than standard confidence-based approaches, and allows us to scale\nup model sizes to yield performance gain while reducing the computational cost.",
    "categories": [
      "cs.LG",
      "cs.AI"
    ],
    "primary_category": "cs.LG",
    "comment": "Appeared at ICML 2024 Workshop on Efficient Systems for Foundation\n  Models (ES-FoMo-II)",
    "pdf_url": "http://arxiv.org/pdf/2412.19325v1",
    "published_date": "2024-12-26 18:54:32 UTC",
    "updated_date": "2024-12-26 18:54:32 UTC"
  },
  {
    "arxiv_id": "2412.19321v1",
    "title": "A novel framework for MCDM based on Z numbers and soft likelihood function",
    "authors": [
      "Yuanpeng He"
    ],
    "abstract": "The optimization on the structure of process of information management under\nuncertain environment has attracted lots of attention from researchers around\nthe world. Nevertheless, how to obtain accurate and rational evaluation from\nassessments produced by experts is still an open problem. Specially,\nintuitionistic fuzzy set provides an effective solution in handling\nindeterminate information. And Yager proposes a novel method for fusion of\nprobabilistic evidence to handle uncertain and conflicting information lately\nwhich is called soft likelihood function. This paper devises a novel framework\nof soft likelihood function based on information volume of fuzzy membership and\ncredibility measure for extracting truly useful and valuable information from\nuncertainty. An application is provided to verify the validity and correctness\nof the proposed framework. Besides, the comparisons with other existing methods\nfurther demonstrate the superiority of the novel framework of soft likelihood\nfunction.",
    "categories": [
      "cs.AI"
    ],
    "primary_category": "cs.AI",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2412.19321v1",
    "published_date": "2024-12-26 18:47:19 UTC",
    "updated_date": "2024-12-26 18:47:19 UTC"
  },
  {
    "arxiv_id": "2412.19312v2",
    "title": "From Interests to Insights: An LLM Approach to Course Recommendations Using Natural Language Queries",
    "authors": [
      "Hugh Van Deventer",
      "Mark Mills",
      "August Evrard"
    ],
    "abstract": "Most universities in the United States encourage their students to explore\nacademic areas before declaring a major and to acquire academic breadth by\nsatisfying a variety of requirements. Each term, students must choose among\nmany thousands of offerings, spanning dozens of subject areas, a handful of\ncourses to take. The curricular environment is also dynamic, and poor\ncommunication and search functions on campus can limit a student's ability to\ndiscover new courses of interest. To support both students and their advisers\nin such a setting, we explore a novel Large Language Model (LLM) course\nrecommendation system that applies a Retrieval Augmented Generation (RAG)\nmethod to the corpus of course descriptions. The system first generates an\n'ideal' course description based on the user's query. This description is\nconverted into a search vector using embeddings, which is then used to find\nactual courses with similar content by comparing embedding similarities. We\ndescribe the method and assess the quality and fairness of some example\nprompts. Steps to deploy a pilot system on campus are discussed.",
    "categories": [
      "cs.IR",
      "cs.AI",
      "H.3"
    ],
    "primary_category": "cs.IR",
    "comment": "17 pages, 9 figures",
    "pdf_url": "http://arxiv.org/pdf/2412.19312v2",
    "published_date": "2024-12-26 18:19:53 UTC",
    "updated_date": "2024-12-30 15:30:23 UTC"
  },
  {
    "arxiv_id": "2412.19311v1",
    "title": "xSRL: Safety-Aware Explainable Reinforcement Learning -- Safety as a Product of Explainability",
    "authors": [
      "Risal Shahriar Shefin",
      "Md Asifur Rahman",
      "Thai Le",
      "Sarra Alqahtani"
    ],
    "abstract": "Reinforcement learning (RL) has shown great promise in simulated\nenvironments, such as games, where failures have minimal consequences. However,\nthe deployment of RL agents in real-world systems such as autonomous vehicles,\nrobotics, UAVs, and medical devices demands a higher level of safety and\ntransparency, particularly when facing adversarial threats. Safe RL algorithms\nhave been developed to address these concerns by optimizing both task\nperformance and safety constraints. However, errors are inevitable, and when\nthey occur, it is essential that the RL agents can also explain their actions\nto human operators. This makes trust in the safety mechanisms of RL systems\ncrucial for effective deployment. Explainability plays a key role in building\nthis trust by providing clear, actionable insights into the agent's\ndecision-making process, ensuring that safety-critical decisions are well\nunderstood. While machine learning (ML) has seen significant advances in\ninterpretability and visualization, explainability methods for RL remain\nlimited. Current tools fail to address the dynamic, sequential nature of RL and\nits needs to balance task performance with safety constraints over time. The\nre-purposing of traditional ML methods, such as saliency maps, is inadequate\nfor safety-critical RL applications where mistakes can result in severe\nconsequences. To bridge this gap, we propose xSRL, a framework that integrates\nboth local and global explanations to provide a comprehensive understanding of\nRL agents' behavior. xSRL also enables developers to identify policy\nvulnerabilities through adversarial attacks, offering tools to debug and patch\nagents without retraining. Our experiments and user studies demonstrate xSRL's\neffectiveness in increasing safety in RL systems, making them more reliable and\ntrustworthy for real-world deployment. Code is available at\nhttps://github.com/risal-shefin/xSRL.",
    "categories": [
      "cs.AI",
      "cs.HC",
      "cs.LG",
      "cs.MA"
    ],
    "primary_category": "cs.AI",
    "comment": "Accepted to 24th International Conference on Autonomous Agents and\n  Multiagent Systems (AAMAS 2025)",
    "pdf_url": "http://arxiv.org/pdf/2412.19311v1",
    "published_date": "2024-12-26 18:19:04 UTC",
    "updated_date": "2024-12-26 18:19:04 UTC"
  },
  {
    "arxiv_id": "2412.19291v2",
    "title": "RAG with Differential Privacy",
    "authors": [
      "Nicolas Grislain"
    ],
    "abstract": "Retrieval-Augmented Generation (RAG) has emerged as the dominant technique to\nprovide \\emph{Large Language Models} (LLM) with fresh and relevant context,\nmitigating the risk of hallucinations and improving the overall quality of\nresponses in environments with large and fast moving knowledge bases. However,\nthe integration of external documents into the generation process raises\nsignificant privacy concerns. Indeed, when added to a prompt, it is not\npossible to guarantee a response will not inadvertently expose confidential\ndata, leading to potential breaches of privacy and ethical dilemmas. This paper\nexplores a practical solution to this problem suitable to general knowledge\nextraction from personal data. It shows \\emph{differentially private token\ngeneration} is a viable approach to private RAG.",
    "categories": [
      "cs.LG",
      "cs.AI",
      "cs.CR"
    ],
    "primary_category": "cs.LG",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2412.19291v2",
    "published_date": "2024-12-26 17:34:26 UTC",
    "updated_date": "2025-01-22 14:50:33 UTC"
  },
  {
    "arxiv_id": "2412.19289v3",
    "title": "ViPCap: Retrieval Text-Based Visual Prompts for Lightweight Image Captioning",
    "authors": [
      "Taewhan Kim",
      "Soeun Lee",
      "Si-Woo Kim",
      "Dong-Jin Kim"
    ],
    "abstract": "Recent lightweight image captioning models using retrieved data mainly focus\non text prompts. However, previous works only utilize the retrieved text as\ntext prompts, and the visual information relies only on the CLIP visual\nembedding. Because of this issue, there is a limitation that the image\ndescriptions inherent in the prompt are not sufficiently reflected in the\nvisual embedding space. To tackle this issue, we propose ViPCap, a novel\nretrieval text-based visual prompt for lightweight image captioning. ViPCap\nleverages the retrieved text with image information as visual prompts to\nenhance the ability of the model to capture relevant visual information. By\nmapping text prompts into the CLIP space and generating multiple randomized\nGaussian distributions, our method leverages sampling to explore randomly\naugmented distributions and effectively retrieves the semantic features that\ncontain image information. These retrieved features are integrated into the\nimage and designated as the visual prompt, leading to performance improvements\non the datasets such as COCO, Flickr30k, and NoCaps. Experimental results\ndemonstrate that ViPCap significantly outperforms prior lightweight captioning\nmodels in efficiency and effectiveness, demonstrating the potential for a\nplug-and-play solution. The source code is available at\nhttps://github.com/taewhankim/VIPCAP.",
    "categories": [
      "cs.CV",
      "cs.AI",
      "cs.CL",
      "cs.LG"
    ],
    "primary_category": "cs.CV",
    "comment": "Accepted to AAAI 2025",
    "pdf_url": "http://arxiv.org/pdf/2412.19289v3",
    "published_date": "2024-12-26 17:29:38 UTC",
    "updated_date": "2025-01-24 16:16:52 UTC"
  },
  {
    "arxiv_id": "2412.19286v1",
    "title": "Time Series Foundational Models: Their Role in Anomaly Detection and Prediction",
    "authors": [
      "Chathurangi Shyalika",
      "Harleen Kaur Bagga",
      "Ahan Bhatt",
      "Renjith Prasad",
      "Alaa Al Ghazo",
      "Amit Sheth"
    ],
    "abstract": "Time series foundational models (TSFM) have gained prominence in time series\nforecasting, promising state-of-the-art performance across various\napplications. However, their application in anomaly detection and prediction\nremains underexplored, with growing concerns regarding their black-box nature,\nlack of interpretability and applicability. This paper critically evaluates the\nefficacy of TSFM in anomaly detection and prediction tasks. We systematically\nanalyze TSFM across multiple datasets, including those characterized by the\nabsence of discernible patterns, trends and seasonality. Our analysis shows\nthat while TSFMs can be extended for anomaly detection and prediction,\ntraditional statistical and deep learning models often match or outperform TSFM\nin these tasks. Additionally, TSFMs require high computational resources but\nfail to capture sequential dependencies effectively or improve performance in\nfew-shot or zero-shot scenarios. \\noindent The preprocessed datasets, codes to\nreproduce the results and supplementary materials are available at\nhttps://github.com/smtmnfg/TSFM.",
    "categories": [
      "cs.LG",
      "cs.AI"
    ],
    "primary_category": "cs.LG",
    "comment": "12 pages, 6 figures, 5 tables. Accepted at AAAI2025 Anomaly Detection\n  in Scientific Domains Workshop",
    "pdf_url": "http://arxiv.org/pdf/2412.19286v1",
    "published_date": "2024-12-26 17:15:30 UTC",
    "updated_date": "2024-12-26 17:15:30 UTC"
  },
  {
    "arxiv_id": "2412.19284v1",
    "title": "PearSAN: A Machine Learning Method for Inverse Design using Pearson Correlated Surrogate Annealing",
    "authors": [
      "Michael Bezick",
      "Blake A. Wilson",
      "Vaishnavi Iyer",
      "Yuheng Chen",
      "Vladimir M. Shalaev",
      "Sabre Kais",
      "Alexander V. Kildishev",
      "Alexandra Boltasseva",
      "Brad Lackey"
    ],
    "abstract": "PearSAN is a machine learning-assisted optimization algorithm applicable to\ninverse design problems with large design spaces, where traditional optimizers\nstruggle. The algorithm leverages the latent space of a generative model for\nrapid sampling and employs a Pearson correlated surrogate model to predict the\nfigure of merit of the true design metric. As a showcase example, PearSAN is\napplied to thermophotovoltaic (TPV) metasurface design by matching the working\nbands between a thermal radiator and a photovoltaic cell. PearSAN can work with\nany pretrained generative model with a discretized latent space, making it easy\nto integrate with VQ-VAEs and binary autoencoders. Its novel Pearson\ncorrelational loss can be used as both a latent regularization method, similar\nto batch and layer normalization, and as a surrogate training loss. We compare\nboth to previous energy matching losses, which are shown to enforce poor\nregularization and performance, even with upgraded affine parameters. PearSAN\nachieves a state-of-the-art maximum design efficiency of 97%, and is at least\nan order of magnitude faster than previous methods, with an improved maximum\nfigure-of-merit gain.",
    "categories": [
      "cs.LG",
      "cs.AI"
    ],
    "primary_category": "cs.LG",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2412.19284v1",
    "published_date": "2024-12-26 17:02:19 UTC",
    "updated_date": "2024-12-26 17:02:19 UTC"
  },
  {
    "arxiv_id": "2501.06196v1",
    "title": "How Do Artificial Intelligences Think? The Three Mathematico-Cognitive Factors of Categorical Segmentation Operated by Synthetic Neurons",
    "authors": [
      "Michael Pichat",
      "William Pogrund",
      "Armanush Gasparian",
      "Paloma Pichat",
      "Samuel Demarchi",
      "Michael Veillet-Guillem"
    ],
    "abstract": "How do the synthetic neurons in language models create \"thought categories\"\nto segment and analyze their informational environment? What are the cognitive\ncharacteristics, at the very level of formal neurons, of this artificial\ncategorical thought? Based on the mathematical nature of algebraic operations\ninherent to neuronal aggregation functions, we attempt to identify\nmathematico-cognitive factors that genetically shape the categorical\nreconstruction of the informational world faced by artificial cognition. This\nstudy explores these concepts through the notions of priming, attention, and\ncategorical phasing.",
    "categories": [
      "q-bio.NC",
      "cs.AI",
      "cs.NE"
    ],
    "primary_category": "q-bio.NC",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2501.06196v1",
    "published_date": "2024-12-26 16:26:00 UTC",
    "updated_date": "2024-12-26 16:26:00 UTC"
  },
  {
    "arxiv_id": "2412.19260v2",
    "title": "MEDEC: A Benchmark for Medical Error Detection and Correction in Clinical Notes",
    "authors": [
      "Asma Ben Abacha",
      "Wen-wai Yim",
      "Yujuan Fu",
      "Zhaoyi Sun",
      "Meliha Yetisgen",
      "Fei Xia",
      "Thomas Lin"
    ],
    "abstract": "Several studies showed that Large Language Models (LLMs) can answer medical\nquestions correctly, even outperforming the average human score in some medical\nexams. However, to our knowledge, no study has been conducted to assess the\nability of language models to validate existing or generated medical text for\ncorrectness and consistency. In this paper, we introduce MEDEC\n(https://github.com/abachaa/MEDEC), the first publicly available benchmark for\nmedical error detection and correction in clinical notes, covering five types\nof errors (Diagnosis, Management, Treatment, Pharmacotherapy, and Causal\nOrganism). MEDEC consists of 3,848 clinical texts, including 488 clinical notes\nfrom three US hospital systems that were not previously seen by any LLM. The\ndataset has been used for the MEDIQA-CORR shared task to evaluate seventeen\nparticipating systems [Ben Abacha et al., 2024]. In this paper, we describe the\ndata creation methods and we evaluate recent LLMs (e.g., o1-preview, GPT-4,\nClaude 3.5 Sonnet, and Gemini 2.0 Flash) for the tasks of detecting and\ncorrecting medical errors requiring both medical knowledge and reasoning\ncapabilities. We also conducted a comparative study where two medical doctors\nperformed the same task on the MEDEC test set. The results showed that MEDEC is\na sufficiently challenging benchmark to assess the ability of models to\nvalidate existing or generated notes and to correct medical errors. We also\nfound that although recent LLMs have a good performance in error detection and\ncorrection, they are still outperformed by medical doctors in these tasks. We\ndiscuss the potential factors behind this gap, the insights from our\nexperiments, the limitations of current evaluation metrics, and share potential\npointers for future research.",
    "categories": [
      "cs.CL",
      "cs.AI",
      "cs.LG"
    ],
    "primary_category": "cs.CL",
    "comment": "This version has been updated with further clarification regarding\n  the model size estimates that were mined from public articles only and\n  provided to aid in contextualizing model performance. The authors cannot\n  vouch for the accuracy of those estimates",
    "pdf_url": "http://arxiv.org/pdf/2412.19260v2",
    "published_date": "2024-12-26 15:54:10 UTC",
    "updated_date": "2025-01-02 18:46:05 UTC"
  },
  {
    "arxiv_id": "2412.19254v1",
    "title": "Leveraging Self-Training and Variational Autoencoder for Agitation Detection in People with Dementia Using Wearable Sensors",
    "authors": [
      "Abeer Badawi",
      "Somayya Elmoghazy",
      "Samira Choudhury",
      "Khalid Elgazzar",
      "Amer Burhan"
    ],
    "abstract": "Dementia is a neurodegenerative disorder that has been growing among elder\npeople over the past decades. This growth profoundly impacts the quality of\nlife for patients and caregivers due to the symptoms arising from it. Agitation\nand aggression (AA) are some of the symptoms of people with severe dementia\n(PwD) in long-term care or hospitals. AA not only causes discomfort but also\nputs the patients or others at potential risk. Existing monitoring solutions\nutilizing different wearable sensors integrated with Artificial Intelligence\n(AI) offer a way to detect AA early enough for timely and adequate medical\nintervention. However, most studies are limited by the availability of\naccurately labeled datasets, which significantly affects the efficacy of such\nsolutions in real-world scenarios. This study presents a novel comprehensive\napproach to detect AA in PwD using physiological data from the Empatica E4\nwristbands. The research creates a diverse dataset, consisting of three\ndistinct datasets gathered from 14 participants across multiple hospitals in\nCanada. These datasets have not been extensively explored due to their limited\nlabeling. We propose a novel approach employing self-training and a variational\nautoencoder (VAE) to detect AA in PwD effectively. The proposed approach aims\nto learn the representation of the features extracted using the VAE and then\nuses a semi-supervised block to generate labels, classify events, and detect\nAA. We demonstrate that combining Self-Training and Variational Autoencoder\nmechanism significantly improves model performance in classifying AA in PwD.\nAmong the tested techniques, the XGBoost classifier achieved the highest\naccuracy of 90.16\\%. By effectively addressing the challenge of limited labeled\ndata, the proposed system not only learns new labels but also proves its\nsuperiority in detecting AA.",
    "categories": [
      "cs.AI"
    ],
    "primary_category": "cs.AI",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2412.19254v1",
    "published_date": "2024-12-26 15:34:25 UTC",
    "updated_date": "2024-12-26 15:34:25 UTC"
  },
  {
    "arxiv_id": "2412.19241v1",
    "title": "Latenrgy: Model Agnostic Latency and Energy Consumption Prediction for Binary Classifiers",
    "authors": [
      "Jason M. Pittman"
    ],
    "abstract": "Machine learning systems increasingly drive innovation across scientific\nfields and industry, yet challenges in compute overhead, specifically during\ninference, limit their scalability and sustainability. Responsible AI\nguardrails, essential for ensuring fairness, transparency, and privacy, further\nexacerbate these computational demands. This study addresses critical gaps in\nthe literature, chiefly the lack of generalized predictive techniques for\nlatency and energy consumption, limited cross-comparisons of classifiers, and\nunquantified impacts of RAI guardrails on inference performance. Using Theory\nConstruction Methodology, this work constructed a model-agnostic theoretical\nframework for predicting latency and energy consumption in binary\nclassification models during inference. The framework synthesizes classifier\ncharacteristics, dataset properties, and RAI guardrails into a unified\nanalytical instrument. Two predictive equations are derived that capture the\ninterplay between these factors while offering generalizability across diverse\nclassifiers. The proposed framework provides foundational insights for\ndesigning efficient, responsible ML systems. It enables researchers to\nbenchmark and optimize inference performance and assists practitioners in\ndeploying scalable solutions. Finally, this work establishes a theoretical\nfoundation for balancing computational efficiency with ethical AI principles,\npaving the way for future empirical validation and broader applications.",
    "categories": [
      "cs.LG",
      "cs.AI"
    ],
    "primary_category": "cs.LG",
    "comment": "8 pages, 2 tables",
    "pdf_url": "http://arxiv.org/pdf/2412.19241v1",
    "published_date": "2024-12-26 14:51:24 UTC",
    "updated_date": "2024-12-26 14:51:24 UTC"
  },
  {
    "arxiv_id": "2412.19235v1",
    "title": "Are Two Hidden Layers Still Enough for the Physics-Informed Neural Networks?",
    "authors": [
      "Vasiliy A. Es'kin",
      "Alexey O. Malkhanov",
      "Mikhail E. Smorkalov"
    ],
    "abstract": "The article discusses the development of various methods and techniques for\ninitializing and training neural networks with a single hidden layer, as well\nas training a separable physics-informed neural network consisting of neural\nnetworks with a single hidden layer to solve physical problems described by\nordinary differential equations (ODEs) and partial differential equations\n(PDEs). A method for strictly deterministic initialization of a neural network\nwith one hidden layer for solving physical problems described by an ODE is\nproposed. Modifications to existing methods for weighting the loss function are\ngiven, as well as new methods developed for training strictly\ndeterministic-initialized neural networks to solve ODEs (detaching, additional\nweighting based on the second derivative, predicted solution-based weighting,\nrelative residuals). An algorithm for physics-informed data-driven\ninitialization of a neural network with one hidden layer is proposed. A neural\nnetwork with pronounced generalizing properties is presented, whose\ngeneralizing abilities of which can be precisely controlled by adjusting\nnetwork parameters. A metric for measuring the generalization of such neural\nnetwork has been introduced. A gradient-free neuron-by-neuron fitting method\nhas been developed for adjusting the parameters of a single-hidden-layer neural\nnetwork, which does not require the use of an optimizer or solver for its\nimplementation. The proposed methods have been extended to 2D problems using\nthe separable physics-informed neural networks approach. Numerous experiments\nhave been carried out to develop the above methods and approaches. Experiments\non physical problems, such as solving various ODEs and PDEs, have demonstrated\nthat these methods for initializing and training neural networks with one or\ntwo hidden layers (SPINN) achieve competitive accuracy and, in some cases,\nstate-of-the-art results.",
    "categories": [
      "math.NA",
      "cs.AI",
      "cs.LG",
      "cs.NA",
      "physics.comp-ph",
      "68T07 (Primary) 65Z05, 65M99 (Secondary)",
      "I.2.1; I.2.7; J.2"
    ],
    "primary_category": "math.NA",
    "comment": "45 pages, 36 figures, 9 tables",
    "pdf_url": "http://arxiv.org/pdf/2412.19235v1",
    "published_date": "2024-12-26 14:30:54 UTC",
    "updated_date": "2024-12-26 14:30:54 UTC"
  },
  {
    "arxiv_id": "2501.01441v2",
    "title": "Explanatory Debiasing: Involving Domain Experts in the Data Generation Process to Mitigate Representation Bias in AI Systems",
    "authors": [
      "Aditya Bhattacharya",
      "Simone Stumpf",
      "Robin De Croon",
      "Katrien Verbert"
    ],
    "abstract": "Representation bias is one of the most common types of biases in artificial\nintelligence (AI) systems, causing AI models to perform poorly on\nunderrepresented data segments. Although AI practitioners use various methods\nto reduce representation bias, their effectiveness is often constrained by\ninsufficient domain knowledge in the debiasing process. To address this gap,\nthis paper introduces a set of generic design guidelines for effectively\ninvolving domain experts in representation debiasing. We instantiated our\nproposed guidelines in a healthcare-focused application and evaluated them\nthrough a comprehensive mixed-methods user study with 35 healthcare experts.\nOur findings show that involving domain experts can reduce representation bias\nwithout compromising model accuracy. Based on our findings, we also offer\nrecommendations for developers to build robust debiasing systems guided by our\ngeneric design guidelines, ensuring more effective inclusion of domain experts\nin the debiasing process.",
    "categories": [
      "cs.HC",
      "cs.AI"
    ],
    "primary_category": "cs.HC",
    "comment": "Pre-print version, please cite the main article instead of the\n  pre-print version",
    "pdf_url": "http://arxiv.org/pdf/2501.01441v2",
    "published_date": "2024-12-26 14:14:48 UTC",
    "updated_date": "2025-02-27 08:45:05 UTC"
  },
  {
    "arxiv_id": "2412.19228v2",
    "title": "Learning Cross-Domain Representations for Transferable Drug Perturbations on Single-Cell Transcriptional Responses",
    "authors": [
      "Hui Liu",
      "Shikai Jin"
    ],
    "abstract": "Phenotypic drug discovery has attracted widespread attention because of its\npotential to identify bioactive molecules. Transcriptomic profiling provides a\ncomprehensive reflection of phenotypic changes in cellular responses to\nexternal perturbations. In this paper, we propose XTransferCDR, a novel\ngenerative framework designed for feature decoupling and transferable\nrepresentation learning across domains. Given a pair of perturbed expression\nprofiles, our approach decouples the perturbation representations from basal\nstates through domain separation encoders and then cross-transfers them in the\nlatent space. The transferred representations are then used to reconstruct the\ncorresponding perturbed expression profiles via a shared decoder. This\ncross-transfer constraint effectively promotes the learning of transferable\ndrug perturbation representations. We conducted extensive evaluations of our\nmodel on multiple datasets, including single-cell transcriptional responses to\ndrugs and single- and combinatorial genetic perturbations. The experimental\nresults show that XTransferCDR achieved better performance than current\nstate-of-the-art methods, showcasing its potential to advance phenotypic drug\ndiscovery.",
    "categories": [
      "cs.LG",
      "cs.AI"
    ],
    "primary_category": "cs.LG",
    "comment": "Accepted by The 39th Annual AAAI Conference on Artificial Intelligenc\n  (AAAI 2025)",
    "pdf_url": "http://arxiv.org/pdf/2412.19228v2",
    "published_date": "2024-12-26 14:09:16 UTC",
    "updated_date": "2025-01-15 01:16:30 UTC"
  },
  {
    "arxiv_id": "2412.19226v1",
    "title": "VINEVI: A Virtualized Network Vision Architecture for Smart Monitoring of Heterogeneous Applications and Infrastructures",
    "authors": [
      "Rodrigo Moreira",
      "Hugo G. V. O. da Cunha",
      "Larissa F. Rodrigues Moreira",
      "Flávio de Oliveira Silva"
    ],
    "abstract": "Monitoring heterogeneous infrastructures and applications is essential to\ncope with user requirements properly, but it still lacks enhancements. The\nwell-known state-of-the-art methods and tools do not support seamless\nmonitoring of bare-metal, low-cost infrastructures, neither hosted nor\nvirtualized services with fine-grained details. This work proposes VIrtualized\nNEtwork VIsion architecture (VINEVI), an intelligent method for seamless\nmonitoring heterogeneous infrastructures and applications. The VINEVI\narchitecture advances state of the art with a node-embedded traffic\nclassification agent placing physical and virtualized infrastructures enabling\nreal-time traffic classification. VINEVI combines this real-time traffic\nclassification with well-known tools such as Prometheus and Victoria Metrics to\nmonitor the entire stack from the hardware to the virtualized applications.\nExperimental results showcased that VINEVI architecture allowed seamless\nheterogeneous infrastructure monitoring with a higher level of detail beyond\nliterature. Also, our node-embedded real-time Internet traffic classifier\nevolved with flexibility the methods with monitoring heterogeneous\ninfrastructures seamlessly.",
    "categories": [
      "cs.NI",
      "cs.AI",
      "cs.CV",
      "cs.LG"
    ],
    "primary_category": "cs.NI",
    "comment": "12 pages",
    "pdf_url": "http://arxiv.org/pdf/2412.19226v1",
    "published_date": "2024-12-26 14:05:14 UTC",
    "updated_date": "2024-12-26 14:05:14 UTC"
  },
  {
    "arxiv_id": "2412.19215v1",
    "title": "Optimizing Fantasy Sports Team Selection with Deep Reinforcement Learning",
    "authors": [
      "Shamik Bhattacharjee",
      "Kamlesh Marathe",
      "Hitesh Kapoor",
      "Nilesh Patil"
    ],
    "abstract": "Fantasy sports, particularly fantasy cricket, have garnered immense\npopularity in India in recent years, offering enthusiasts the opportunity to\nengage in strategic team-building and compete based on the real-world\nperformance of professional athletes. In this paper, we address the challenge\nof optimizing fantasy cricket team selection using reinforcement learning (RL)\ntechniques. By framing the team creation process as a sequential\ndecision-making problem, we aim to develop a model that can adaptively select\nplayers to maximize the team's potential performance. Our approach leverages\nhistorical player data to train RL algorithms, which then predict future\nperformance and optimize team composition. This not only represents a huge\nbusiness opportunity by enabling more accurate predictions of high-performing\nteams but also enhances the overall user experience. Through empirical\nevaluation and comparison with traditional fantasy team drafting methods, we\ndemonstrate the effectiveness of RL in constructing competitive fantasy teams.\nOur results show that RL-based strategies provide valuable insights into player\nselection in fantasy sports.",
    "categories": [
      "cs.AI",
      "cs.LG",
      "I.2.1"
    ],
    "primary_category": "cs.AI",
    "comment": "8 Pages including references, Accepted to CODS-COMAD 2024 conference",
    "pdf_url": "http://arxiv.org/pdf/2412.19215v1",
    "published_date": "2024-12-26 13:36:18 UTC",
    "updated_date": "2024-12-26 13:36:18 UTC"
  },
  {
    "arxiv_id": "2412.19198v1",
    "title": "Multi-Attribute Constraint Satisfaction via Language Model Rewriting",
    "authors": [
      "Ashutosh Baheti",
      "Debanjana Chakraborty",
      "Faeze Brahman",
      "Ronan Le Bras",
      "Ximing Lu",
      "Nouha Dziri",
      "Yejin Choi",
      "Mark Riedl",
      "Maarten Sap"
    ],
    "abstract": "Obeying precise constraints on top of multiple external attributes is a\ncommon computational problem underlying seemingly different domains, from\ncontrolled text generation to protein engineering. Existing language model (LM)\ncontrollability methods for multi-attribute constraint satisfaction often rely\non specialized architectures or gradient-based classifiers, limiting their\nflexibility to work with arbitrary black-box evaluators and pretrained models.\nCurrent general-purpose large language models, while capable, cannot achieve\nfine-grained multi-attribute control over external attributes. Thus, we create\nMulti-Attribute Constraint Satisfaction (MACS), a generalized method capable of\nfinetuning language models on any sequential domain to satisfy user-specified\nconstraints on multiple external real-value attributes. Our method trains LMs\nas editors by sampling diverse multi-attribute edit pairs from an initial set\nof paraphrased outputs. During inference, LM iteratively improves upon its\nprevious solution to satisfy constraints for all attributes by leveraging our\ndesigned constraint satisfaction reward. We additionally experiment with\nreward-weighted behavior cloning to further improve the constraint satisfaction\nrate of LMs. To evaluate our approach, we present a new Fine-grained Constraint\nSatisfaction (FineCS) benchmark, featuring two challenging tasks: (1) Text\nStyle Transfer, where the goal is to simultaneously modify the sentiment and\ncomplexity of reviews, and (2) Protein Design, focusing on modulating\nfluorescence and stability of Green Fluorescent Proteins (GFP). Our empirical\nresults show that MACS achieves the highest threshold satisfaction in both\nFineCS tasks, outperforming strong domain-specific baselines. Our work opens\nnew avenues for generalized and real-value multi-attribute control, with\nimplications for diverse applications spanning NLP and bioinformatics.",
    "categories": [
      "cs.AI"
    ],
    "primary_category": "cs.AI",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2412.19198v1",
    "published_date": "2024-12-26 12:36:39 UTC",
    "updated_date": "2024-12-26 12:36:39 UTC"
  },
  {
    "arxiv_id": "2412.19194v1",
    "title": "Provably Efficient Exploration in Reward Machines with Low Regret",
    "authors": [
      "Hippolyte Bourel",
      "Anders Jonsson",
      "Odalric-Ambrym Maillard",
      "Chenxiao Ma",
      "Mohammad Sadegh Talebi"
    ],
    "abstract": "We study reinforcement learning (RL) for decision processes with\nnon-Markovian reward, in which high-level knowledge of the task in the form of\nreward machines is available to the learner. We consider probabilistic reward\nmachines with initially unknown dynamics, and investigate RL under the\naverage-reward criterion, where the learning performance is assessed through\nthe notion of regret. Our main algorithmic contribution is a model-based RL\nalgorithm for decision processes involving probabilistic reward machines that\nis capable of exploiting the structure induced by such machines. We further\nderive high-probability and non-asymptotic bounds on its regret and demonstrate\nthe gain in terms of regret over existing algorithms that could be applied, but\nobliviously to the structure. We also present a regret lower bound for the\nstudied setting. To the best of our knowledge, the proposed algorithm\nconstitutes the first attempt to tailor and analyze regret specifically for RL\nwith probabilistic reward machines.",
    "categories": [
      "cs.LG",
      "cs.AI"
    ],
    "primary_category": "cs.LG",
    "comment": "35 pages",
    "pdf_url": "http://arxiv.org/pdf/2412.19194v1",
    "published_date": "2024-12-26 12:25:04 UTC",
    "updated_date": "2024-12-26 12:25:04 UTC"
  },
  {
    "arxiv_id": "2412.19191v1",
    "title": "Biology Instructions: A Dataset and Benchmark for Multi-Omics Sequence Understanding Capability of Large Language Models",
    "authors": [
      "Haonan He",
      "Yuchen Ren",
      "Yining Tang",
      "Ziyang Xu",
      "Junxian Li",
      "Minghao Yang",
      "Di Zhang",
      "Dong Yuan",
      "Tao Chen",
      "Shufei Zhang",
      "Yuqiang Li",
      "Nanqing Dong",
      "Wanli Ouyang",
      "Dongzhan Zhou",
      "Peng Ye"
    ],
    "abstract": "Large language models have already demonstrated their formidable capabilities\nin general domains, ushering in a revolutionary transformation. However,\nexploring and exploiting the extensive knowledge of these models to comprehend\nmulti-omics biology remains underexplored. To fill this research gap, we first\nintroduce Biology-Instructions, the first large-scale multi-omics biological\nsequences-related instruction-tuning dataset including DNA, RNA, proteins, and\nmulti-molecules, designed to bridge the gap between large language models\n(LLMs) and complex biological sequences-related tasks. This dataset can enhance\nthe versatility of LLMs by integrating diverse biological sequenced-based\nprediction tasks with advanced reasoning capabilities, while maintaining\nconversational fluency. Additionally, we reveal significant performance\nlimitations in even state-of-the-art LLMs on biological sequence-related\nmulti-omics tasks without specialized pre-training and instruction-tuning. We\nfurther develop a strong baseline called ChatMultiOmics with a novel\nthree-stage training pipeline, demonstrating the powerful ability to understand\nbiology by using Biology-Instructions. Biology-Instructions and ChatMultiOmics\nare publicly available and crucial resources for enabling more effective\nintegration of LLMs with multi-omics sequence analysis.",
    "categories": [
      "q-bio.BM",
      "cs.AI",
      "cs.LG"
    ],
    "primary_category": "q-bio.BM",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2412.19191v1",
    "published_date": "2024-12-26 12:12:23 UTC",
    "updated_date": "2024-12-26 12:12:23 UTC"
  },
  {
    "arxiv_id": "2412.19179v2",
    "title": "Mask Approximation Net: A Novel Diffusion Model Approach for Remote Sensing Change Captioning",
    "authors": [
      "Dongwei Sun",
      "Jing Yao",
      "Changsheng Zhou",
      "Xiangyong Cao",
      "Pedram Ghamisi"
    ],
    "abstract": "Remote sensing image change description represents an innovative multimodal\ntask within the realm of remote sensing processing. This task not only\nfacilitates the detection of alterations in surface conditions, but also\nprovides comprehensive descriptions of these changes, thereby improving human\ninterpretability and interactivity.Generally, existing deep-learning-based\nmethods predominantly utilized a three-stage framework that successively\nperform feature extraction, feature fusion, and localization from bitemporal\nimages before text generation. However, this reliance often leads to an\nexcessive focus on the design of specific network architectures and restricts\nthe feature distributions to the dataset at hand, which in turn results in\nlimited generalizability and robustness during application.To address these\nlimitations, this paper proposes a novel approach for remote sensing image\nchange detection and description that incorporates diffusion models, aiming to\ntransition the emphasis of modeling paradigms from conventional feature\nlearning to data distribution learning. The proposed method primarily includes\na simple multi-scale change detection module, whose output features are\nsubsequently refined by an well-designed diffusion model. Furthermore, we\nintroduce a frequency-guided complex filter module to boost the model\nperformance by managing high-frequency noise throughout the diffusion process.\nWe validate the effectiveness of our proposed method across several datasets\nfor remote sensing change detection and description, showcasing its superior\nperformance compared to existing techniques. The code will be available at\n\\href{https://github.com/sundongwei}{MaskApproxNet} after a possible\npublication.",
    "categories": [
      "cs.CV",
      "cs.AI",
      "cs.LG"
    ],
    "primary_category": "cs.CV",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2412.19179v2",
    "published_date": "2024-12-26 11:35:57 UTC",
    "updated_date": "2025-02-16 09:13:25 UTC"
  },
  {
    "arxiv_id": "2412.19178v1",
    "title": "Reversed in Time: A Novel Temporal-Emphasized Benchmark for Cross-Modal Video-Text Retrieval",
    "authors": [
      "Yang Du",
      "Yuqi Liu",
      "Qin Jin"
    ],
    "abstract": "Cross-modal (e.g. image-text, video-text) retrieval is an important task in\ninformation retrieval and multimodal vision-language understanding field.\nTemporal understanding makes video-text retrieval more challenging than\nimage-text retrieval. However, we find that the widely used video-text\nbenchmarks have shortcomings in comprehensively assessing abilities of models,\nespecially in temporal understanding, causing large-scale image-text\npre-trained models can already achieve comparable zero-shot performance with\nvideo-text pre-trained models. In this paper, we introduce RTime, a novel\ntemporal-emphasized video-text retrieval dataset. We first obtain videos of\nactions or events with significant temporality, and then reverse these videos\nto create harder negative samples. We then recruit annotators to judge the\nsignificance and reversibility of candidate videos, and write captions for\nqualified videos. We further adopt GPT-4 to extend more captions based on\nhuman-written captions. Our RTime dataset currently consists of 21k videos with\n10 captions per video, totalling about 122 hours. Based on RTime, we propose\nthree retrieval benchmark tasks: RTime-Origin, RTime-Hard, and RTime-Binary. We\nfurther enhance the use of harder-negatives in model training, and benchmark a\nvariety of video-text models on RTime. Extensive experiment analysis proves\nthat RTime indeed poses new and higher challenges to video-text retrieval. We\nrelease our RTime\ndataset\\footnote{\\url{https://github.com/qyr0403/Reversed-in-Time}} to further\nadvance video-text retrieval and multimodal understanding research.",
    "categories": [
      "cs.CV",
      "cs.AI",
      "cs.CL",
      "cs.IR",
      "cs.LG"
    ],
    "primary_category": "cs.CV",
    "comment": "ACMMM 2024 poster",
    "pdf_url": "http://arxiv.org/pdf/2412.19178v1",
    "published_date": "2024-12-26 11:32:00 UTC",
    "updated_date": "2024-12-26 11:32:00 UTC"
  },
  {
    "arxiv_id": "2412.19163v2",
    "title": "Master Stability Functions in Complex Networks",
    "authors": [
      "Suman Acharyya",
      "Priodyuti Pradhan",
      "Chandrakala Meena"
    ],
    "abstract": "Synchronization is an emergent and fundamental phenomenon in nature and\nengineered systems. Understanding the stability of a synchronized phenomenon is\ncrucial for ensuring functionality in various complex systems. The stability of\nthe synchronization phenomenon is extensively studied using the Master\nStability Function (MSF). This powerful and elegant tool plays a pivotal role\nin determining the stability of synchronization states, providing deep insights\ninto synchronization in coupled systems. Although MSF analysis has been used\nfor 25 years to study the stability of synchronization states, a systematic\ninvestigation of MSF across various networked systems remains missing from the\nliterature. In this article, we present a simplified and unified MSF analysis\nfor diverse undirected and directed networked systems. We begin with the\nanalytical MSF framework for pairwise-coupled identical systems with diffusive\nand natural coupling schemes and extend our analysis to directed networks and\nmultilayer networks, considering both intra-layer and inter-layer interactions.\nFurthermore, we revisit the MSF framework to incorporate higher-order\ninteractions alongside pairwise interactions. To enhance understanding, we also\nprovide a numerical analysis of synchronization in coupled R\\\"ossler systems\nunder pairwise diffusive coupling and propose algorithms for determining the\nMSF, identifying stability regimes, and classifying MSF functions. Overall, the\nprimary goal of this review is to present a systematic study of MSF in coupled\ndynamical networks in a clear and structured manner, making this powerful tool\nmore accessible. Furthermore, we highlight cases where the study of\nsynchronization states using MSF remains underexplored. Additionally, we\ndiscuss recent research focusing on MSF analysis using time series data and\nmachine learning approaches.",
    "categories": [
      "nlin.AO",
      "cs.AI",
      "nlin.CD"
    ],
    "primary_category": "nlin.AO",
    "comment": "49 pages, 5 figures",
    "pdf_url": "http://arxiv.org/pdf/2412.19163v2",
    "published_date": "2024-12-26 10:47:00 UTC",
    "updated_date": "2025-03-14 17:23:18 UTC"
  },
  {
    "arxiv_id": "2412.19160v2",
    "title": "Cross-Spectral Vision Transformer for Biometric Authentication using Forehead Subcutaneous Vein Pattern and Periocular Pattern",
    "authors": [
      "Arun K. Sharma",
      "Shubhobrata Bhattacharya",
      "Motahar Reza",
      "Bishakh Bhattacharya"
    ],
    "abstract": "Traditional biometric systems have encountered significant setbacks due to\nvarious unavoidable factors, for example, face recognition-based biometrics\nfails due to the wearing of face masks and fingerprints create hygiene\nconcerns. This paper proposes a novel lightweight cross-spectral vision\ntransformer (CS-ViT) for biometric authentication using forehead subcutaneous\nvein patterns and periocular patterns, offering a promising alternative to\ntraditional methods, capable of performing well even with the face masks and\nwithout any physical touch. The proposed framework comprises a cross-spectral\ndual-channel architecture designed to handle two distinct biometric traits and\nto capture inter-dependencies in terms of relative spectral patterns. Each\nchannel consists of a Phase-Only Correlation Cross-Spectral Attention (POC-CSA)\nthat captures their individual as well as correlated patterns. The computation\nof cross-spectral attention using POC extracts the phase correlation in the\nspatial features. Therefore, it is robust against the resolution/intensity\nvariations and illumination of the input images, assuming both biometric traits\nare from the same person. The lightweight model is suitable for edge device\ndeployment. The performance of the proposed algorithm was rigorously evaluated\nusing the Forehead Subcutaneous Vein Pattern and Periocular Biometric Pattern\n(FSVP-PBP) database. The results demonstrated the superiority of the algorithm\nover state-of-the-art methods, achieving a remarkable classification accuracy\nof 98.8% with the combined vein and periocular patterns.",
    "categories": [
      "cs.CV",
      "cs.AI",
      "cs.LG"
    ],
    "primary_category": "cs.CV",
    "comment": "Submitted to IEEE TPAMI",
    "pdf_url": "http://arxiv.org/pdf/2412.19160v2",
    "published_date": "2024-12-26 10:40:15 UTC",
    "updated_date": "2025-03-03 06:34:25 UTC"
  },
  {
    "arxiv_id": "2412.19159v1",
    "title": "Mobile Robots through Task-Based Human Instructions using Incremental Curriculum Learning",
    "authors": [
      "Muhammad A. Muttaqien",
      "Ayanori Yorozu",
      "Akihisa Ohya"
    ],
    "abstract": "This paper explores the integration of incremental curriculum learning (ICL)\nwith deep reinforcement learning (DRL) techniques to facilitate mobile robot\nnavigation through task-based human instruction. By adopting a curriculum that\nmirrors the progressive complexity encountered in human learning, our approach\nsystematically enhances robots' ability to interpret and execute complex\ninstructions over time. We explore the principles of DRL and its synergy with\nICL, demonstrating how this combination not only improves training efficiency\nbut also equips mobile robots with the generalization capability required for\nnavigating through dynamic indoor environments. Empirical results indicate that\nrobots trained with our ICL-enhanced DRL framework outperform those trained\nwithout curriculum learning, highlighting the benefits of structured learning\nprogressions in robotic training.",
    "categories": [
      "cs.RO",
      "cs.AI"
    ],
    "primary_category": "cs.RO",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2412.19159v1",
    "published_date": "2024-12-26 10:38:40 UTC",
    "updated_date": "2024-12-26 10:38:40 UTC"
  },
  {
    "arxiv_id": "2412.19152v1",
    "title": "To Predict or Not To Predict? Proportionally Masked Autoencoders for Tabular Data Imputation",
    "authors": [
      "Jungkyu Kim",
      "Kibok Lee",
      "Taeyoung Park"
    ],
    "abstract": "Masked autoencoders (MAEs) have recently demonstrated effectiveness in\ntabular data imputation. However, due to the inherent heterogeneity of tabular\ndata, the uniform random masking strategy commonly used in MAEs can disrupt the\ndistribution of missingness, leading to suboptimal performance. To address\nthis, we propose a proportional masking strategy for MAEs. Specifically, we\nfirst compute the statistics of missingness based on the observed proportions\nin the dataset, and then generate masks that align with these statistics,\nensuring that the distribution of missingness is preserved after masking.\nFurthermore, we argue that simple MLP-based token mixing offers competitive or\noften superior performance compared to attention mechanisms while being more\ncomputationally efficient, especially in the tabular domain with the inherent\nheterogeneity. Experimental results validate the effectiveness of the proposed\nproportional masking strategy across various missing data patterns in tabular\ndatasets. Code is available at: \\url{https://github.com/normal-kim/PMAE}.",
    "categories": [
      "cs.LG",
      "cs.AI",
      "stat.ML"
    ],
    "primary_category": "cs.LG",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2412.19152v1",
    "published_date": "2024-12-26 10:12:08 UTC",
    "updated_date": "2024-12-26 10:12:08 UTC"
  },
  {
    "arxiv_id": "2412.19146v1",
    "title": "AskChart: Universal Chart Understanding through Textual Enhancement",
    "authors": [
      "Xudong Yang",
      "Yifan Wu",
      "Yizhang Zhu",
      "Nan Tang",
      "Yuyu Luo"
    ],
    "abstract": "Chart understanding tasks such as ChartQA and Chart-to-Text involve\nautomatically extracting and interpreting key information from charts, enabling\nusers to query or convert visual data into structured formats. State-of-the-art\napproaches primarily focus on visual cues from chart images, failing to\nexplicitly incorporate rich textual information (e.g., data labels and axis\nlabels) embedded within the charts. This textual information is vital for\nintuitive human comprehension and interpretation of charts. Moreover, existing\nmodels are often large and computationally intensive, limiting their practical\napplicability. In this paper, we introduce AskChart, a universal model that\nexplicitly integrates both textual and visual cues from charts using a Mixture\nof Experts (MoE) architecture. AskChart facilitates the learning of enhanced\nvisual-textual representations of charts for effectively handling multiple\nchart understanding tasks, while maintaining a smaller model size. To capture\nthe synergy between visual and textual modalities, we curate a large-scale\ndataset named ChartBank with about 7.5M data samples, which helps align textual\nand visual information and facilitates the extraction of visual entities and\ntext. To effectively train AskChart, we design a three-stage training strategy\nto align visual and textual modalities for learning robust visual-textual\nrepresentations and optimizing the learning of the MoE layer. Extensive\nexperiments across five datasets demonstrate the significant performance gains\nof AskChart in four chart understanding tasks. Remarkably, AskChart with 4.6B\nparameters outperforms state-of-the-art models with 13B parameters by 68.3% in\nOpen-ended ChartQA and 49.2% in Chart-to-Text tasks, while achieving comparable\nperformance in ChartQA and Chart-to-Table tasks.",
    "categories": [
      "cs.CV",
      "cs.AI"
    ],
    "primary_category": "cs.CV",
    "comment": "23 pages, 12 figures, 14 tables",
    "pdf_url": "http://arxiv.org/pdf/2412.19146v1",
    "published_date": "2024-12-26 09:59:43 UTC",
    "updated_date": "2024-12-26 09:59:43 UTC"
  },
  {
    "arxiv_id": "2412.19140v1",
    "title": "SILC-EFSA: Self-aware In-context Learning Correction for Entity-level Financial Sentiment Analysis",
    "authors": [
      "Senbin Zhu",
      "Chenyuan He",
      "Hongde Liu",
      "Pengcheng Dong",
      "Hanjie Zhao",
      "Yuchen Yan",
      "Yuxiang Jia",
      "Hongying Zan",
      "Min Peng"
    ],
    "abstract": "In recent years, fine-grained sentiment analysis in finance has gained\nsignificant attention, but the scarcity of entity-level datasets remains a key\nchallenge. To address this, we have constructed the largest English and Chinese\nfinancial entity-level sentiment analysis datasets to date. Building on this\nfoundation, we propose a novel two-stage sentiment analysis approach called\nSelf-aware In-context Learning Correction (SILC). The first stage involves\nfine-tuning a base large language model to generate pseudo-labeled data\nspecific to our task. In the second stage, we train a correction model using a\nGNN-based example retriever, which is informed by the pseudo-labeled data. This\ntwo-stage strategy has allowed us to achieve state-of-the-art performance on\nthe newly constructed datasets, advancing the field of financial sentiment\nanalysis. In a case study, we demonstrate the enhanced practical utility of our\ndata and methods in monitoring the cryptocurrency market. Our datasets and code\nare available at https://github.com/NLP-Bin/SILC-EFSA.",
    "categories": [
      "cs.CL",
      "cs.AI",
      "cs.CE"
    ],
    "primary_category": "cs.CL",
    "comment": "This paper is to be published in the Proceedings of the 31st\n  International Conference on Computational Linguistics (COLING 2025)",
    "pdf_url": "http://arxiv.org/pdf/2412.19140v1",
    "published_date": "2024-12-26 09:53:01 UTC",
    "updated_date": "2024-12-26 09:53:01 UTC"
  },
  {
    "arxiv_id": "2412.19139v2",
    "title": "PlanLLM: Video Procedure Planning with Refinable Large Language Models",
    "authors": [
      "Dejie Yang",
      "Zijing Zhao",
      "Yang Liu"
    ],
    "abstract": "Video procedure planning, i.e., planning a sequence of action steps given the\nvideo frames of start and goal states, is an essential ability for embodied AI.\nRecent works utilize Large Language Models (LLMs) to generate enriched action\nstep description texts to guide action step decoding. Although LLMs are\nintroduced, these methods decode the action steps into a closed-set of one-hot\nvectors, limiting the model's capability of generalizing to new steps or tasks.\nAdditionally, fixed action step descriptions based on world-level commonsense\nmay contain noise in specific instances of visual states. In this paper, we\npropose PlanLLM, a cross-modal joint learning framework with LLMs for video\nprocedure planning. We propose an LLM-Enhanced Planning module which fully uses\nthe generalization ability of LLMs to produce free-form planning output and to\nenhance action step decoding. We also propose Mutual Information Maximization\nmodule to connect world-level commonsense of step descriptions and\nsample-specific information of visual states, enabling LLMs to employ the\nreasoning ability to generate step sequences. With the assistance of LLMs, our\nmethod can both closed-set and open vocabulary procedure planning tasks. Our\nPlanLLM achieves superior performance on three benchmarks, demonstrating the\neffectiveness of our designs.",
    "categories": [
      "cs.CV",
      "cs.AI",
      "cs.LG",
      "cs.MM"
    ],
    "primary_category": "cs.CV",
    "comment": "accepted to AAAI2025",
    "pdf_url": "http://arxiv.org/pdf/2412.19139v2",
    "published_date": "2024-12-26 09:51:05 UTC",
    "updated_date": "2025-01-07 01:50:11 UTC"
  },
  {
    "arxiv_id": "2412.19133v1",
    "title": "A Rhetorical Relations-Based Framework for Tailored Multimedia Document Summarization",
    "authors": [
      "Azze-Eddine Maredj",
      "Madjid Sadallah"
    ],
    "abstract": "In the rapidly evolving landscape of digital content, the task of summarizing\nmultimedia documents, which encompass textual, visual, and auditory elements,\npresents intricate challenges. These challenges include extracting pertinent\ninformation from diverse formats, maintaining the structural integrity and\nsemantic coherence of the original content, and generating concise yet\ninformative summaries. This paper introduces a novel framework for multimedia\ndocument summarization that capitalizes on the inherent structure of the\ndocument to craft coherent and succinct summaries. Central to this framework is\nthe incorporation of a rhetorical structure for structural analysis, augmented\nby a graph-based representation to facilitate the extraction of pivotal\ninformation. Weighting algorithms are employed to assign significance values to\ndocument units, thereby enabling effective ranking and selection of relevant\ncontent. Furthermore, the framework is designed to accommodate user preferences\nand time constraints, ensuring the production of personalized and contextually\nrelevant summaries. The summarization process is elaborately delineated,\nencompassing document specification, graph construction, unit weighting, and\nsummary extraction, supported by illustrative examples and algorithmic\nelucidation. This proposed framework represents a significant advancement in\nautomatic summarization, with broad potential applications across multimedia\ndocument processing, promising transformative impacts in the field.",
    "categories": [
      "cs.MM",
      "cs.AI",
      "cs.HC"
    ],
    "primary_category": "cs.MM",
    "comment": "10 pages, preprint",
    "pdf_url": "http://arxiv.org/pdf/2412.19133v1",
    "published_date": "2024-12-26 09:29:59 UTC",
    "updated_date": "2024-12-26 09:29:59 UTC"
  },
  {
    "arxiv_id": "2412.19124v1",
    "title": "Evaluating Self-Supervised Learning in Medical Imaging: A Benchmark for Robustness, Generalizability, and Multi-Domain Impact",
    "authors": [
      "Valay Bundele",
      "Oğuz Ata Çal",
      "Bora Kargi",
      "Karahan Sarıtaş",
      "Kıvanç Tezören",
      "Zohreh Ghaderi",
      "Hendrik Lensch"
    ],
    "abstract": "Self-supervised learning (SSL) has emerged as a promising paradigm in medical\nimaging, addressing the chronic challenge of limited labeled data in healthcare\nsettings. While SSL has shown impressive results, existing studies in the\nmedical domain are often limited in scope, focusing on specific datasets or\nmodalities, or evaluating only isolated aspects of model performance. This\nfragmented evaluation approach poses a significant challenge, as models\ndeployed in critical medical settings must not only achieve high accuracy but\nalso demonstrate robust performance and generalizability across diverse\ndatasets and varying conditions. To address this gap, we present a\ncomprehensive evaluation of SSL methods within the medical domain, with a\nparticular focus on robustness and generalizability. Using the MedMNIST dataset\ncollection as a standardized benchmark, we evaluate 8 major SSL methods across\n11 different medical datasets. Our study provides an in-depth analysis of model\nperformance in both in-domain scenarios and the detection of\nout-of-distribution (OOD) samples, while exploring the effect of various\ninitialization strategies, model architectures, and multi-domain pre-training.\nWe further assess the generalizability of SSL methods through cross-dataset\nevaluations and the in-domain performance with varying label proportions (1%,\n10%, and 100%) to simulate real-world scenarios with limited supervision. We\nhope this comprehensive benchmark helps practitioners and researchers make more\ninformed decisions when applying SSL methods to medical applications.",
    "categories": [
      "cs.CV",
      "cs.AI",
      "cs.LG"
    ],
    "primary_category": "cs.CV",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2412.19124v1",
    "published_date": "2024-12-26 08:51:56 UTC",
    "updated_date": "2024-12-26 08:51:56 UTC"
  },
  {
    "arxiv_id": "2412.19114v1",
    "title": "Discrete vs. Continuous Trade-offs for Generative Models",
    "authors": [
      "Jathin Korrapati",
      "Tanish Baranwal",
      "Rahul Shah"
    ],
    "abstract": "This work explores the theoretical and practical foundations of denoising\ndiffusion probabilistic models (DDPMs) and score-based generative models, which\nleverage stochastic processes and Brownian motion to model complex data\ndistributions. These models employ forward and reverse diffusion processes\ndefined through stochastic differential equations (SDEs) to iteratively add and\nremove noise, enabling high-quality data generation. By analyzing the\nperformance bounds of these models, we demonstrate how score estimation errors\npropagate through the reverse process and bound the total variation distance\nusing discrete Girsanov transformations, Pinsker's inequality, and the data\nprocessing inequality (DPI) for an information theoretic lens.",
    "categories": [
      "cs.LG",
      "cs.AI",
      "cs.IT",
      "cs.NA",
      "math.IT",
      "math.NA",
      "Primary 68T07, Secondary 60H10, 94A15, 68Q87"
    ],
    "primary_category": "cs.LG",
    "comment": "16 pages, 6 figures, includes theoretical analysis, experimental\n  results, and proofs of key results",
    "pdf_url": "http://arxiv.org/pdf/2412.19114v1",
    "published_date": "2024-12-26 08:14:27 UTC",
    "updated_date": "2024-12-26 08:14:27 UTC"
  },
  {
    "arxiv_id": "2412.19108v2",
    "title": "Graph Mixture of Experts and Memory-augmented Routers for Multivariate Time Series Anomaly Detection",
    "authors": [
      "Xiaoyu Huang",
      "Weidong Chen",
      "Bo Hu",
      "Zhendong Mao"
    ],
    "abstract": "Multivariate time series (MTS) anomaly detection is a critical task that\ninvolves identifying abnormal patterns or events in data that consist of\nmultiple interrelated time series. In order to better model the complex\ninterdependence between entities and the various inherent characteristics of\neach entity, the GNN based methods are widely adopted by existing methods. In\neach layer of GNN, node features aggregate information from their neighboring\nnodes to update their information. In doing so, from shallow layer to deep\nlayer in GNN, original individual node features continue to be weakened and\nmore structural information,i.e., from short-distance neighborhood to\nlong-distance neighborhood, continues to be enhanced. However, research to date\nhas largely ignored the understanding of how hierarchical graph information is\nrepresented and their characteristics that can benefit anomaly detection.\nExisting methods simply leverage the output from the last layer of GNN for\nanomaly estimation while neglecting the essential information contained in the\nintermediate GNN layers. To address such limitations, in this paper, we propose\na Graph Mixture of Experts (Graph-MoE) network for multivariate time series\nanomaly detection, which incorporates the mixture of experts (MoE) module to\nadaptively represent and integrate hierarchical multi-layer graph information\ninto entity representations. It is worth noting that our Graph-MoE can be\nintegrated into any GNN-based MTS anomaly detection method in a plug-and-play\nmanner. In addition, the memory-augmented routers are proposed in this paper to\ncapture the correlation temporal information in terms of the global historical\nfeatures of MTS to adaptively weigh the obtained entity representations to\nachieve successful anomaly estimation. Extensive experiments on five\nchallenging datasets prove the superiority of our approach and each proposed\nmodule.",
    "categories": [
      "cs.LG",
      "cs.AI"
    ],
    "primary_category": "cs.LG",
    "comment": "Accepted by AAAI 2025",
    "pdf_url": "http://arxiv.org/pdf/2412.19108v2",
    "published_date": "2024-12-26 07:49:51 UTC",
    "updated_date": "2024-12-30 13:10:06 UTC"
  },
  {
    "arxiv_id": "2412.19092v1",
    "title": "TrajGEOS: Trajectory Graph Enhanced Orientation-based Sequential Network for Mobility Prediction",
    "authors": [
      "Zhaoping Hu",
      "Zongyuan Huang",
      "Jinming Yang",
      "Tao Yang",
      "Yaohui Jin",
      "Yanyan Xu"
    ],
    "abstract": "Human mobility studies how people move to access their needed resources and\nplays a significant role in urban planning and location-based services. As a\nparamount task of human mobility modeling, next location prediction is\nchallenging because of the diversity of users' historical trajectories that\ngives rise to complex mobility patterns and various contexts. Deep sequential\nmodels have been widely used to predict the next location by leveraging the\ninherent sequentiality of trajectory data. However, they do not fully leverage\nthe relationship between locations and fail to capture users' multi-level\npreferences. This work constructs a trajectory graph from users' historical\ntraces and proposes a \\textbf{Traj}ectory \\textbf{G}raph \\textbf{E}nhanced\n\\textbf{O}rientation-based \\textbf{S}equential network (TrajGEOS) for\nnext-location prediction tasks. TrajGEOS introduces hierarchical graph\nconvolution to capture location and user embeddings. Such embeddings consider\nnot only the contextual feature of locations but also the relation between\nthem, and serve as additional features in downstream modules. In addition, we\ndesign an orientation-based module to learn users' mid-term preferences from\nsequential modeling modules and their recent trajectories. Extensive\nexperiments on three real-world LBSN datasets corroborate the value of graph\nand orientation-based modules and demonstrate that TrajGEOS outperforms the\nstate-of-the-art methods on the next location prediction task.",
    "categories": [
      "cs.AI"
    ],
    "primary_category": "cs.AI",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2412.19092v1",
    "published_date": "2024-12-26 07:18:38 UTC",
    "updated_date": "2024-12-26 07:18:38 UTC"
  },
  {
    "arxiv_id": "2412.19088v1",
    "title": "Integrating Artificial Open Generative Artificial Intelligence into Software Supply Chain Security",
    "authors": [
      "Vasileios Alevizos",
      "George A Papakostas",
      "Akebu Simasiku",
      "Dimitra Malliarou",
      "Antonis Messinis",
      "Sabrina Edralin",
      "Clark Xu",
      "Zongliang Yue"
    ],
    "abstract": "While new technologies emerge, human errors always looming. Software supply\nchain is increasingly complex and intertwined, the security of a service has\nbecome paramount to ensuring the integrity of products, safeguarding data\nprivacy, and maintaining operational continuity. In this work, we conducted\nexperiments on the promising open Large Language Models (LLMs) into two main\nsoftware security challenges: source code language errors and deprecated code,\nwith a focus on their potential to replace conventional static and dynamic\nsecurity scanners that rely on predefined rules and patterns. Our findings\nsuggest that while LLMs present some unexpected results, they also encounter\nsignificant limitations, particularly in memory complexity and the management\nof new and unfamiliar data patterns. Despite these challenges, the proactive\napplication of LLMs, coupled with extensive security databases and continuous\nupdates, holds the potential to fortify Software Supply Chain (SSC) processes\nagainst emerging threats.",
    "categories": [
      "cs.CR",
      "cs.AI",
      "cs.ET"
    ],
    "primary_category": "cs.CR",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2412.19088v1",
    "published_date": "2024-12-26 07:03:55 UTC",
    "updated_date": "2024-12-26 07:03:55 UTC"
  },
  {
    "arxiv_id": "2412.19064v1",
    "title": "Hierarchical Multi-agent Meta-Reinforcement Learning for Cross-channel Bidding",
    "authors": [
      "Shenghong He",
      "Chao Yu"
    ],
    "abstract": "Real-time bidding (RTB) plays a pivotal role in online advertising\necosystems. Advertisers employ strategic bidding to optimize their advertising\nimpact while adhering to various financial constraints, such as the\nreturn-on-investment (ROI) and cost-per-click (CPC). Primarily focusing on\nbidding with fixed budget constraints, traditional approaches cannot\neffectively manage the dynamic budget allocation problem where the goal is to\nachieve global optimization of bidding performance across multiple channels\nwith a shared budget. In this paper, we propose a hierarchical multi-agent\nreinforcement learning framework for multi-channel bidding optimization. In\nthis framework, the top-level strategy applies a CPC constrained diffusion\nmodel to dynamically allocate budgets among the channels according to their\ndistinct features and complex interdependencies, while the bottom-level\nstrategy adopts a state-action decoupled actor-critic method to address the\nproblem of extrapolation errors in offline learning caused by\nout-of-distribution actions and a context-based meta-channel knowledge learning\nmethod to improve the state representation capability of the policy based on\nthe shared knowledge among different channels. Comprehensive experiments\nconducted on a large scale real-world industrial dataset from the Meituan ad\nbidding platform demonstrate that our method achieves a state-of-the-art\nperformance.",
    "categories": [
      "cs.AI"
    ],
    "primary_category": "cs.AI",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2412.19064v1",
    "published_date": "2024-12-26 05:26:30 UTC",
    "updated_date": "2024-12-26 05:26:30 UTC"
  },
  {
    "arxiv_id": "2412.19043v1",
    "title": "Indonesian-English Code-Switching Speech Synthesizer Utilizing Multilingual STEN-TTS and Bert LID",
    "authors": [
      "Ahmad Alfani Handoyo",
      "Chung Tran",
      "Dessi Puji Lestari",
      "Sakriani Sakti"
    ],
    "abstract": "Multilingual text-to-speech systems convert text into speech across multiple\nlanguages. In many cases, text sentences may contain segments in different\nlanguages, a phenomenon known as code-switching. This is particularly common in\nIndonesia, especially between Indonesian and English. Despite its significance,\nno research has yet developed a multilingual TTS system capable of handling\ncode-switching between these two languages. This study addresses\nIndonesian-English code-switching in STEN-TTS. Key modifications include adding\na language identification component to the text-to-phoneme conversion using\nfinetuned BERT for per-word language identification, as well as removing\nlanguage embedding from the base model. Experimental results demonstrate that\nthe code-switching model achieves superior naturalness and improved speech\nintelligibility compared to the Indonesian and English baseline STEN-TTS\nmodels.",
    "categories": [
      "cs.CL",
      "cs.AI",
      "cs.SD",
      "eess.AS"
    ],
    "primary_category": "cs.CL",
    "comment": "Accepted at O-COCOSDA 2024",
    "pdf_url": "http://arxiv.org/pdf/2412.19043v1",
    "published_date": "2024-12-26 03:37:40 UTC",
    "updated_date": "2024-12-26 03:37:40 UTC"
  },
  {
    "arxiv_id": "2412.19037v2",
    "title": "CL-Attack: Textual Backdoor Attacks via Cross-Lingual Triggers",
    "authors": [
      "Jingyi Zheng",
      "Tianyi Hu",
      "Tianshuo Cong",
      "Xinlei He"
    ],
    "abstract": "Backdoor attacks significantly compromise the security of large language\nmodels by triggering them to output specific and controlled content. Currently,\ntriggers for textual backdoor attacks fall into two categories: fixed-token\ntriggers and sentence-pattern triggers. However, the former are typically easy\nto identify and filter, while the latter, such as syntax and style, do not\napply to all original samples and may lead to semantic shifts. In this paper,\ninspired by cross-lingual (CL) prompts of LLMs in real-world scenarios, we\npropose a higher-dimensional trigger method at the paragraph level, namely\nCL-attack. CL-attack injects the backdoor by using texts with specific\nstructures that incorporate multiple languages, thereby offering greater\nstealthiness and universality compared to existing backdoor attack techniques.\nExtensive experiments on different tasks and model architectures demonstrate\nthat CL-attack can achieve nearly 100% attack success rate with a low poisoning\nrate in both classification and generation tasks. We also empirically show that\nthe CL-attack is more robust against current major defense methods compared to\nbaseline backdoor attacks. Additionally, to mitigate CL-attack, we further\ndevelop a new defense called TranslateDefense, which can partially mitigate the\nimpact of CL-attack.",
    "categories": [
      "cs.CR",
      "cs.AI"
    ],
    "primary_category": "cs.CR",
    "comment": "The paper has been accepted to AAAI 2025",
    "pdf_url": "http://arxiv.org/pdf/2412.19037v2",
    "published_date": "2024-12-26 03:13:03 UTC",
    "updated_date": "2025-03-31 04:48:28 UTC"
  },
  {
    "arxiv_id": "2412.19031v1",
    "title": "Repository Structure-Aware Training Makes SLMs Better Issue Resolver",
    "authors": [
      "Zexiong Ma",
      "Shengnan An",
      "Zeqi Lin",
      "Yanzhen Zou",
      "Bing Xie"
    ],
    "abstract": "Language models have been applied to various software development tasks, but\nthe performance varies according to the scale of the models. Large Language\nModels (LLMs) outperform Small Language Models (SLMs) in complex tasks like\nrepository-level issue resolving, but raise concerns about privacy and cost. In\ncontrast, SLMs are more accessible but under-perform in complex tasks. In this\npaper, we introduce ReSAT (Repository Structure-Aware Training), construct\ntraining data based on a large number of issues and corresponding pull requests\nfrom open-source communities to enhance the model's understanding of repository\nstructure and issue resolving ability. We construct two types of training data:\n(1) localization training data, a multi-level progressive localization data to\nimprove code understanding and localization capability; (2) code edit training\ndata, which improves context-based code editing capability. The evaluation\nresults on SWE-Bench-verified and RepoQA demonstrate that ReSAT effectively\nenhances SLMs' issue-resolving and repository-level long-context understanding\ncapabilities.",
    "categories": [
      "cs.SE",
      "cs.AI"
    ],
    "primary_category": "cs.SE",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2412.19031v1",
    "published_date": "2024-12-26 03:01:32 UTC",
    "updated_date": "2024-12-26 03:01:32 UTC"
  },
  {
    "arxiv_id": "2412.19026v1",
    "title": "Modality-Projection Universal Model for Comprehensive Full-Body Medical Imaging Segmentation",
    "authors": [
      "Yixin Chen",
      "Lin Gao",
      "Yajuan Gao",
      "Rui Wang",
      "Jingge Lian",
      "Xiangxi Meng",
      "Yanhua Duan",
      "Leiying Chai",
      "Hongbin Han",
      "Zhaoping Cheng",
      "Zhaoheng Xie"
    ],
    "abstract": "The integration of deep learning in medical imaging has shown great promise\nfor enhancing diagnostic, therapeutic, and research outcomes. However, applying\nuniversal models across multiple modalities remains challenging due to the\ninherent variability in data characteristics. This study aims to introduce and\nevaluate a Modality Projection Universal Model (MPUM). MPUM employs a novel\nmodality-projection strategy, which allows the model to dynamically adjust its\nparameters to optimize performance across different imaging modalities. The\nMPUM demonstrated superior accuracy in identifying anatomical structures,\nenabling precise quantification for improved clinical decision-making. It also\nidentifies metabolic associations within the brain-body axis, advancing\nresearch on brain-body physiological correlations. Furthermore, MPUM's unique\ncontroller-based convolution layer enables visualization of saliency maps\nacross all network layers, significantly enhancing the model's\ninterpretability.",
    "categories": [
      "eess.IV",
      "cs.AI",
      "cs.CV"
    ],
    "primary_category": "eess.IV",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2412.19026v1",
    "published_date": "2024-12-26 02:23:27 UTC",
    "updated_date": "2024-12-26 02:23:27 UTC"
  },
  {
    "arxiv_id": "2412.19021v1",
    "title": "Relation-aware Hierarchical Prompt for Open-vocabulary Scene Graph Generation",
    "authors": [
      "Tao Liu",
      "Rongjie Li",
      "Chongyu Wang",
      "Xuming He"
    ],
    "abstract": "Open-vocabulary Scene Graph Generation (OV-SGG) overcomes the limitations of\nthe closed-set assumption by aligning visual relationship representations with\nopen-vocabulary textual representations. This enables the identification of\nnovel visual relationships, making it applicable to real-world scenarios with\ndiverse relationships. However, existing OV-SGG methods are constrained by\nfixed text representations, limiting diversity and accuracy in image-text\nalignment. To address these challenges, we propose the Relation-Aware\nHierarchical Prompting (RAHP) framework, which enhances text representation by\nintegrating subject-object and region-specific relation information. Our\napproach utilizes entity clustering to address the complexity of relation\ntriplet categories, enabling the effective integration of subject-object\ninformation. Additionally, we utilize a large language model (LLM) to generate\ndetailed region-aware prompts, capturing fine-grained visual interactions and\nimproving alignment between visual and textual modalities. RAHP also introduces\na dynamic selection mechanism within Vision-Language Models (VLMs), which\nadaptively selects relevant text prompts based on the visual content, reducing\nnoise from irrelevant prompts. Extensive experiments on the Visual Genome and\nOpen Images v6 datasets demonstrate that our framework consistently achieves\nstate-of-the-art performance, demonstrating its effectiveness in addressing the\nchallenges of open-vocabulary scene graph generation.",
    "categories": [
      "cs.CV",
      "cs.AI"
    ],
    "primary_category": "cs.CV",
    "comment": "Accepted by AAAI-25",
    "pdf_url": "http://arxiv.org/pdf/2412.19021v1",
    "published_date": "2024-12-26 02:12:37 UTC",
    "updated_date": "2024-12-26 02:12:37 UTC"
  },
  {
    "arxiv_id": "2412.19017v1",
    "title": "Brain Ageing Prediction using Isolation Forest Technique and Residual Neural Network (ResNet)",
    "authors": [
      "Saadat Behzadi",
      "Danial Sharifrazi",
      "Roohallah Alizadehsani",
      "Mojtaba Lotfaliany",
      "Mohammadreza Mohebbi"
    ],
    "abstract": "Brain aging is a complex and dynamic process, leading to functional and\nstructural changes in the brain. These changes could lead to the increased risk\nof neurodegenerative diseases and cognitive decline. Accurate brain-age\nestimation utilizing neuroimaging data has become necessary for detecting\ninitial signs of neurodegeneration. Here, we propose a novel deep learning\napproach using the Residual Neural Network 101 Version 2 (ResNet101V2) model to\npredict brain age from MRI scans. To train, validate and test our proposed\nmodel, we used a large dataset of 2102 images which were selected randomly from\nthe International Consortium for Brain Mapping (ICBM). Next, we applied data\npreprocessing techniques, including normalizing the images and using outlier\ndetection via Isolation Forest method. Then, we evaluated various pre-trained\napproaches (namely: MobileNetV2, ResNet50V2, ResNet101V2, Xception). The\nresults demonstrated that the ResNet101V2 model has higher performance compared\nwith the other models, attaining MAEs of 0.9136 and 0.8242 years for before and\nafter using Isolation Forest process. Our method achieved a high accuracy in\nbrain age estimation in ICBM dataset and it provides a reliable brain age\nprediction.",
    "categories": [
      "eess.IV",
      "cs.AI",
      "cs.CV"
    ],
    "primary_category": "eess.IV",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2412.19017v1",
    "published_date": "2024-12-26 01:49:21 UTC",
    "updated_date": "2024-12-26 01:49:21 UTC"
  },
  {
    "arxiv_id": "2412.19010v1",
    "title": "A theory of appropriateness with applications to generative artificial intelligence",
    "authors": [
      "Joel Z. Leibo",
      "Alexander Sasha Vezhnevets",
      "Manfred Diaz",
      "John P. Agapiou",
      "William A. Cunningham",
      "Peter Sunehag",
      "Julia Haas",
      "Raphael Koster",
      "Edgar A. Duéñez-Guzmán",
      "William S. Isaac",
      "Georgios Piliouras",
      "Stanley M. Bileschi",
      "Iyad Rahwan",
      "Simon Osindero"
    ],
    "abstract": "What is appropriateness? Humans navigate a multi-scale mosaic of interlocking\nnotions of what is appropriate for different situations. We act one way with\nour friends, another with our family, and yet another in the office. Likewise\nfor AI, appropriate behavior for a comedy-writing assistant is not the same as\nappropriate behavior for a customer-service representative. What determines\nwhich actions are appropriate in which contexts? And what causes these\nstandards to change over time? Since all judgments of AI appropriateness are\nultimately made by humans, we need to understand how appropriateness guides\nhuman decision making in order to properly evaluate AI decision making and\nimprove it. This paper presents a theory of appropriateness: how it functions\nin human society, how it may be implemented in the brain, and what it means for\nresponsible deployment of generative AI technology.",
    "categories": [
      "cs.AI"
    ],
    "primary_category": "cs.AI",
    "comment": "115 pages, 2 figures",
    "pdf_url": "http://arxiv.org/pdf/2412.19010v1",
    "published_date": "2024-12-26 00:54:03 UTC",
    "updated_date": "2024-12-26 00:54:03 UTC"
  },
  {
    "arxiv_id": "2412.19005v1",
    "title": "Enhancing Audiovisual Speech Recognition through Bifocal Preference Optimization",
    "authors": [
      "Yihan Wu",
      "Yichen Lu",
      "Yifan Peng",
      "Xihua Wang",
      "Ruihua Song",
      "Shinji Watanabe"
    ],
    "abstract": "Audiovisual Automatic Speech Recognition (AV-ASR) aims to improve speech\nrecognition accuracy by leveraging visual signals. It is particularly\nchallenging in unconstrained real-world scenarios across various domains due to\nnoisy acoustic environments, spontaneous speech, and the uncertain use of\nvisual information. Most previous works fine-tune audio-only ASR models on\naudiovisual datasets, optimizing them for conventional ASR objectives. However,\nthey often neglect visual features and common errors in unconstrained video\nscenarios. In this paper, we propose using a preference optimization strategy\nto improve speech recognition accuracy for real-world videos. First, we create\npreference data via simulating common errors that occurred in AV-ASR from two\nfocals: manipulating the audio or vision input and rewriting the output\ntranscript. Second, we propose BPO-AVASR, a Bifocal Preference Optimization\nmethod to improve AV-ASR models by leveraging both input-side and output-side\npreference. Extensive experiments demonstrate that our approach significantly\nimproves speech recognition accuracy across various domains, outperforming\nprevious state-of-the-art models on real-world video speech recognition.",
    "categories": [
      "eess.AS",
      "cs.AI"
    ],
    "primary_category": "eess.AS",
    "comment": "Accepted by AAAI 2025",
    "pdf_url": "http://arxiv.org/pdf/2412.19005v1",
    "published_date": "2024-12-26 00:26:45 UTC",
    "updated_date": "2024-12-26 00:26:45 UTC"
  }
]