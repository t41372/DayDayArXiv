{
  "date": "2024-12-26",
  "category": "cs.AI",
  "summary": "欢迎来到 UTC 时间 2024-12-26 的 arXiv 中文 TLDR 快报！\n\n今天 arXiv 更新了 50 篇论文，主要聚焦于人工智能应用（如大型语言模型在市场研究和教育推荐中的创新）、强化学习的安全性和优化、视觉语言模型在图像分割和生成任务的进展，以及医疗领域的实体识别和异常检测。重点包括 CVPR 和 AAAI 等顶级会议接受的论文，如 CALICO 和 ViPCap，它们展示了 AI 在多模态理解和高效模型训练上的突破；此外，LLM 在跨领域应用的潜力（如生物序列理解）令人印象深刻，但整体论文质量参差不齐，我将优先讨论高影响力文章，并快速掠过较基础或应用性不强的部分。\n\n### 重点论文讨论\n\n**1. Large Language Models for Market Research: A Data-augmentation Approach（大型语言模型在市场研究中的数据增强方法）**  \n这篇论文提出了一种统计数据增强方法，将 LLM 生成的数据与真实数据结合，用于联合分析（conjoint analysis），以减少偏差。核心贡献是通过迁移学习（transfer learning）优化 LLM 数据，实验显示在 COVID-19 疫苗偏好研究中，估计算法错误减少 24.9% 到 79.8%，显著提升市场研究的效率和成本节约。\n\n**3. On the Expressiveness and Length Generalization of Selective State-Space Models on Regular Languages（选择性状态空间模型在正则语言上的表达性和长度泛化）**  \n作者包括 Thomas Hofmann 等知名学者，这篇论文分析了选择性状态空间模型（SSMs）的表达力和泛化性能，引入了 Selective Dense State-Space Model（SD-SSM），它在单层模型上实现了正则语言任务的完美长度泛化。发现显示，SD-SSM 优于传统对角 SSMs，在非交换自动机上表现出色，将于 AAAI 2025 发布。\n\n**6. CALICO: Part-Focused Semantic Co-Segmentation with Large Vision-Language Models（CALICO: 基于大型视觉语言模型的部分聚焦语义共同分割）**  \n这篇即将发表于 CVPR 2025 的论文提出 CALICO 框架，用于多图像的部分级语义分割。核心创新是 Correspondence Extraction Module 和 Adaptation Modules，能高效捕捉对象和部分对应关系。实验证明，仅微调 0.3% 参数即可在复杂任务中实现出色性能，适用于图像理解的应用。\n\n**10. xSRL: Safety-Aware Explainable Reinforcement Learning（xSRL: 安全感知可解释强化学习）**  \n作者团队来自 AAMAS 2025，该论文开发了 xSRL 框架，结合本地和全局解释来提升 RL 代理的安全性和可解释性。发现显示，它能识别 RL 中的政策漏洞，并通过对抗攻击调试代理，实验验证了其在现实部署中的可靠性。\n\n**12. ViPCap: Retrieval Text-Based Visual Prompts for Lightweight Image Captioning（ViPCap: 用于轻量级图像标注的检索文本视觉提示）**  \n这篇 AAAI 2025 接受论文引入 ViPCap 方法，通过检索文本生成视觉提示，增强图像描述的准确性。核心贡献是使用高斯分布采样提取语义特征，实验在 COCO 和 Flickr30k 数据集上显著提升了性能，是一个即插即用的高效解决方案。\n\n**21. Learning Cross-Domain Representations for Transferable Drug Perturbations on Single-Cell Transcriptional Responses（单细胞转录响应中跨域表示学习用于可转移药物扰动）**  \n作者提出 XTransferCDR 框架，用于药物发现，通过解耦和跨域转移学习药物扰动表示。发现显示，它在单细胞数据上优于现有方法，能提升药物表型发现的准确性，即将发表于 AAAI 2025。\n\n**24. Multi-Attribute Constraint Satisfaction via Language Model Rewriting（通过语言模型重写实现多属性约束满足）**  \n这篇论文探索 LLM 在多属性约束任务（如文本生成和蛋白工程）中的应用，提出 MACS 方法，通过编辑对生成样本进行优化。核心发现是，它能在 Fine-grained Constraint Satisfaction 基准上超越专业模型，适用于 NLP 和生物信息学。\n\n**26. Biology Instructions: A Dataset and Benchmark for Multi-Omics Sequence Understanding Capability of Large Language Models（Biology Instructions: 用于多组学序列理解的大型语言模型数据集和基准）**  \n论文构建了首个多组学数据集（DNA、RNA 等），并开发了 ChatMultiOmics 基准，评估 LLM 在序列任务中的能力。发现显示，结合新数据集，LLM 在生物序列预测上大幅提升，填补了 AI 在生物领域的空白。\n\n**35. PlanLLM: Video Procedure Planning with Refinable Large Language Models（PlanLLM: 使用可细化大型语言模型的视频过程规划）**  \n即将发表于 AAAI 2025，这篇论文提出 PlanLLM 框架，通过 LLM 增强视频过程规划，支持开放词汇任务。核心创新是 Mutual Information Maximization 模块，能捕捉视觉-文本互动，实验证明其在视频理解任务中优于传统方法。\n\n**44. CL-Attack: Textual Backdoor Attacks via Cross-Lingual Triggers（CL-Attack: 通过跨语言触发器的文本后门攻击）**  \n论文引入 CL-Attack 方法，使用多语言段落作为隐蔽触发器，实现高隐蔽性的后门攻击。发现显示，它在分类和生成任务中攻击成功率近 100%，并对现有防御更具鲁棒性，即将发表于 AAAI 2025。\n\n### 其他论文快速掠过\n剩余论文中，一些如网络流量分类（2. Improving the network traffic classification）、半监督医疗实体识别（4. Semi-Supervised Learning for Fine-grained PICO Entity Recognition）和强化学习优化（5. A Reinforcement Learning-Based Task Mapping Method）有实际应用，但相对常规；医疗和生物相关论文（如16. MEDEC: A Benchmark for Medical Error Detection）提供了新基准，但未有突破性发现；其他如课程推荐（9. From Interests to Insights）和时间序列建模（13. Time Series Foundational Models）则更侧重实用性，未列出以控制篇幅。\n\n总之，今天的更新突显 AI 在跨领域应用的潜力，尤其是 LLM 和视觉模型的创新，但需关注安全和泛化问题。欢迎读者关注这些高影响力论文，探索更多应用！（本快报基于摘要总结，如需细节，请查阅原文。）",
  "papers": [
    {
      "arxiv_id": "2412.19363v2",
      "title": "Large Language Models for Market Research: A Data-augmentation Approach",
      "title_zh": "大语言模型用于市场研究：一种数据增强方法",
      "authors": [
        "Mengxin Wang",
        "Dennis J. Zhang",
        "Heng Zhang"
      ],
      "abstract": "Large Language Models (LLMs) have transformed artificial intelligence by\nexcelling in complex natural language processing tasks. Their ability to\ngenerate human-like text has opened new possibilities for market research,\nparticularly in conjoint analysis, where understanding consumer preferences is\nessential but often resource-intensive. Traditional survey-based methods face\nlimitations in scalability and cost, making LLM-generated data a promising\nalternative. However, while LLMs have the potential to simulate real consumer\nbehavior, recent studies highlight a significant gap between LLM-generated and\nhuman data, with biases introduced when substituting between the two. In this\npaper, we address this gap by proposing a novel statistical data augmentation\napproach that efficiently integrates LLM-generated data with real data in\nconjoint analysis. Our method leverages transfer learning principles to debias\nthe LLM-generated data using a small amount of human data. This results in\nstatistically robust estimators with consistent and asymptotically normal\nproperties, in contrast to naive approaches that simply substitute human data\nwith LLM-generated data, which can exacerbate bias. We validate our framework\nthrough an empirical study on COVID-19 vaccine preferences, demonstrating its\nsuperior ability to reduce estimation error and save data and costs by 24.9% to\n79.8%. In contrast, naive approaches fail to save data due to the inherent\nbiases in LLM-generated data compared to human data. Another empirical study on\nsports car choices validates the robustness of our results. Our findings\nsuggest that while LLM-generated data is not a direct substitute for human\nresponses, it can serve as a valuable complement when used within a robust\nstatistical framework.",
      "tldr_zh": "本研究探讨了 Large Language Models (LLMs) 在市场研究中的应用，特别是通过数据增强方法改善联合分析 (conjoint analysis) 中的消费者偏好评估，以解决传统调查方法的成本和可扩展性问题。论文提出了一种新型统计数据增强框架，利用转移学习 (transfer learning) 原理，通过少量人类数据对 LLMs 生成数据进行去偏置处理，从而获得鲁棒的估计器，避免了简单替换数据导致的偏置放大。实验结果显示，该方法在 COVID-19 疫苗偏好和体育车选择研究中降低了估计误差，并节省了 24.9% 到 79.8% 的数据和成本，证明 LLMs 生成数据可作为人类数据的有效补充而非直接替代。",
      "categories": [
        "cs.AI",
        "cs.LG",
        "stat.ME",
        "stat.ML",
        "68T50, 90B60, 62F12",
        "I.2.7; J.4; G.3"
      ],
      "primary_category": "cs.AI",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2412.19363v2",
      "published_date": "2024-12-26 22:06:29 UTC",
      "updated_date": "2025-01-06 17:33:20 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-21T17:48:03.663739"
    },
    {
      "arxiv_id": "2412.19360v1",
      "title": "Improving the network traffic classification using the Packet Vision approach",
      "title_zh": "使用 Packet Vision 方法改进网络流量",
      "authors": [
        "Rodrigo Moreira",
        "Larissa Ferreira Rodrigues",
        "Pedro Frosi Rosa",
        "Flávio de Oliveira Silva"
      ],
      "abstract": "The network traffic classification allows improving the management, and the\nnetwork services offer taking into account the kind of application. The future\nnetwork architectures, mainly mobile networks, foresee intelligent mechanisms\nin their architectural frameworks to deliver application-aware network\nrequirements. The potential of convolutional neural networks capabilities,\nwidely exploited in several contexts, can be used in network traffic\nclassification. Thus, it is necessary to develop methods based on the content\nof packets transforming it into a suitable input for CNN technologies. Hence,\nwe implemented and evaluated the Packet Vision, a method capable of building\nimages from packets raw-data, considering both header and payload. Our approach\nexcels those found in state-of-the-art by delivering security and privacy by\ntransforming the raw-data packet into images. Therefore, we built a dataset\nwith four traffic classes evaluating the performance of three CNNs\narchitectures: AlexNet, ResNet-18, and SqueezeNet. Experiments showcase the\nPacket Vision combined with CNNs applicability and suitability as a promising\napproach to deliver outstanding performance in classifying network traffic.",
      "tldr_zh": "该研究提出了一种名为 Packet Vision 的方法，用于提升网络流量分类的准确性，通过将数据包的原始数据（包括头部和有效负载）转换为图像，作为卷积神经网络 (CNNs) 的输入，从而解决传统方法的局限性。实验中，研究者构建了一个包含四种流量类的数据集，并评估了 AlexNet、ResNet-18 和 SqueezeNet 等 CNN 架构，结果显示 Packet Vision 显著提高了分类性能，比现有方法更出色，同时增强了数据安全性和隐私保护。该方法为未来智能网络架构，特别是移动网络，提供了一种高效的应用感知管理机制。",
      "categories": [
        "cs.NI",
        "cs.AI",
        "cs.CR",
        "cs.CV"
      ],
      "primary_category": "cs.NI",
      "comment": "6 pages",
      "pdf_url": "http://arxiv.org/pdf/2412.19360v1",
      "published_date": "2024-12-26 21:56:03 UTC",
      "updated_date": "2024-12-26 21:56:03 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-21T17:46:22.932718"
    },
    {
      "arxiv_id": "2412.19350v1",
      "title": "On the Expressiveness and Length Generalization of Selective State-Space Models on Regular Languages",
      "title_zh": "翻译失败",
      "authors": [
        "Aleksandar Terzić",
        "Michael Hersche",
        "Giacomo Camposampiero",
        "Thomas Hofmann",
        "Abu Sebastian",
        "Abbas Rahimi"
      ],
      "abstract": "Selective state-space models (SSMs) are an emerging alternative to the\nTransformer, offering the unique advantage of parallel training and sequential\ninference. Although these models have shown promising performance on a variety\nof tasks, their formal expressiveness and length generalization properties\nremain underexplored. In this work, we provide insight into the workings of\nselective SSMs by analyzing their expressiveness and length generalization\nperformance on regular language tasks, i.e., finite-state automaton (FSA)\nemulation. We address certain limitations of modern SSM-based architectures by\nintroducing the Selective Dense State-Space Model (SD-SSM), the first selective\nSSM that exhibits perfect length generalization on a set of various regular\nlanguage tasks using a single layer. It utilizes a dictionary of dense\ntransition matrices, a softmax selection mechanism that creates a convex\ncombination of dictionary matrices at each time step, and a readout consisting\nof layer normalization followed by a linear map. We then proceed to evaluate\nvariants of diagonal selective SSMs by considering their empirical performance\non commutative and non-commutative automata. We explain the experimental\nresults with theoretical considerations. Our code is available at\nhttps://github.com/IBM/selective-dense-state-space-model.",
      "tldr_zh": "该研究探讨了Selective State-Space Models (SSMs) 在正则语言任务上的表达性和长度泛化性能，通过模拟有限状态自动机 (FSA) 分析其优势和局限。论文引入了Selective Dense State-Space Model (SD-SSM)，这是一种新型单层SSM，使用密集转移矩阵字典、每个时间步的softmax选择机制以及层归一化和线性映射的输出，实现对各种正则语言任务的完美长度泛化。实验评估了对角SSM变体在交换和非交换自动机上的表现，并通过理论分析解释了结果，为SSMs在序列建模中的应用提供了新见解。",
      "categories": [
        "cs.LG",
        "cs.AI",
        "cs.CL"
      ],
      "primary_category": "cs.LG",
      "comment": "13 pages, 7 figures, to be published in AAAI 2025",
      "pdf_url": "http://arxiv.org/pdf/2412.19350v1",
      "published_date": "2024-12-26 20:53:04 UTC",
      "updated_date": "2024-12-26 20:53:04 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-21T17:46:35.170887"
    },
    {
      "arxiv_id": "2412.19346v1",
      "title": "Semi-Supervised Learning from Small Annotated Data and Large Unlabeled Data for Fine-grained PICO Entity Recognition",
      "title_zh": "翻译失败",
      "authors": [
        "Fangyi Chen",
        "Gongbo Zhang",
        "Yilu Fang",
        "Yifan Peng",
        "Chunhua Weng"
      ],
      "abstract": "Objective: Extracting PICO elements -- Participants, Intervention,\nComparison, and Outcomes -- from clinical trial literature is essential for\nclinical evidence retrieval, appraisal, and synthesis. Existing approaches do\nnot distinguish the attributes of PICO entities. This study aims to develop a\nnamed entity recognition (NER) model to extract PICO entities with fine\ngranularities.\n  Materials and Methods: Using a corpus of 2,511 abstracts with PICO mentions\nfrom 4 public datasets, we developed a semi-supervised method to facilitate the\ntraining of a NER model, FinePICO, by combining limited annotated data of PICO\nentities and abundant unlabeled data. For evaluation, we divided the entire\ndataset into two subsets: a smaller group with annotations and a larger group\nwithout annotations. We then established the theoretical lower and upper\nperformance bounds based on the performance of supervised learning models\ntrained solely on the small, annotated subset and on the entire set with\ncomplete annotations, respectively. Finally, we evaluated FinePICO on both the\nsmaller annotated subset and the larger, initially unannotated subset. We\nmeasured the performance of FinePICO using precision, recall, and F1.\n  Results: Our method achieved precision/recall/F1 of 0.567/0.636/0.60,\nrespectively, using a small set of annotated samples, outperforming the\nbaseline model (F1: 0.437) by more than 16\\%. The model demonstrates\ngeneralizability to a different PICO framework and to another corpus, which\nconsistently outperforms the benchmark in diverse experimental settings\n(p-value \\textless0.001).\n  Conclusion: This study contributes a generalizable and effective\nsemi-supervised approach to named entity recognition leveraging large unlabeled\ndata together with small, annotated data. It also initially supports\nfine-grained PICO extraction.",
      "tldr_zh": "本研究针对临床试验文献中PICO元素（Participants, Intervention, Comparison, and Outcomes）的细粒度提取，开发了一种名为FinePICO的Named Entity Recognition (NER)模型，以区分PICO实体的属性。采用半监督学习方法，利用少量标注数据（2,511个摘要中的小部分）和大量未标注数据进行训练，并通过设定监督学习性能下限和上限来评估模型。结果显示，FinePICO在小标注子集上实现了0.567的Precision、0.636的Recall和0.60的F1分数，比基线模型（F1: 0.437）提高了16%以上，并在不同PICO框架和语料库上表现出良好的泛化性（p-value <0.001）。这项工作为利用少量标注数据和大量未标注数据进行细粒度PICO提取提供了可泛化有效的半监督方法。",
      "categories": [
        "cs.CL",
        "cs.AI"
      ],
      "primary_category": "cs.CL",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2412.19346v1",
      "published_date": "2024-12-26 20:24:35 UTC",
      "updated_date": "2024-12-26 20:24:35 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-21T17:46:48.597517"
    },
    {
      "arxiv_id": "2412.19340v1",
      "title": "A Reinforcement Learning-Based Task Mapping Method to Improve the Reliability of Clustered Manycores",
      "title_zh": "一种基于强化学习的任务映射方法以提高聚类多核系统的可靠性",
      "authors": [
        "Fatemeh Hossein-Khani",
        "Omid Akbari"
      ],
      "abstract": "The increasing scale of manycore systems poses significant challenges in\nmanaging reliability while meeting performance demands. Simultaneously, these\nsystems become more susceptible to different aging mechanisms such as\nnegative-bias temperature instability (NBTI), hot carrier injection (HCI), and\nthermal cycling (TC), as well as the electromigration (EM) phenomenon. In this\npaper, we propose a reinforcement learning (RL)-based task mapping method to\nimprove the reliability of manycore systems considering the aforementioned\naging mechanisms, which consists of three steps including bin packing,\ntask-to-bin mapping, and task-to-core mapping. In the initial step, a\ndensity-based spatial application with noise (DBSCAN) clustering method is\nemployed to compose some clusters (bins) based on the cores temperature. Then,\nthe Q-learning algorithm is used for the two latter steps, to map the arrived\ntask on a core such that the minimum thermal variation is occurred among all\nthe bins. Compared to the state-of-the-art works, the proposed method is\nperformed during runtime without requiring any parameter to be calculated\noffline. The effectiveness of the proposed technique is evaluated on 16, 32,\nand 64 cores systems using SPLASH2 and PARSEC benchmark suite applications. The\nresults demonstrate up to 27% increase in the mean time to failure (MTTF)\ncompared to the state-of-the-art task mapping techniques.",
      "tldr_zh": "本研究针对多核系统（manycore systems）的规模扩大导致的可靠性挑战和老化机制（如 NBTI、HCI、TC 和 EM），提出了一种基于 Reinforcement Learning (RL) 的任务映射方法，以提升系统可靠性。该方法包括三个步骤：首先使用 DBSCAN 聚类算法基于核心温度形成集群（bins）；然后通过 Q-learning 算法进行任务到 bins 和任务到核心的映射，以最小化热变异；整个过程在运行时执行，无需离线计算参数。在使用 SPLASH2 和 PARSEC 基准测试的实验中，该方法在 16、32 和 64 核系统中实现了比现有技术高达 27% 的平均故障时间 (MTTF) 提升。",
      "categories": [
        "cs.LG",
        "cs.AI"
      ],
      "primary_category": "cs.LG",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2412.19340v1",
      "published_date": "2024-12-26 20:08:10 UTC",
      "updated_date": "2024-12-26 20:08:10 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-21T17:47:59.339970"
    },
    {
      "arxiv_id": "2412.19331v2",
      "title": "CALICO: Part-Focused Semantic Co-Segmentation with Large Vision-Language Models",
      "title_zh": "翻译失败",
      "authors": [
        "Kiet A. Nguyen",
        "Adheesh Juvekar",
        "Tianjiao Yu",
        "Muntasir Wahed",
        "Ismini Lourentzou"
      ],
      "abstract": "Recent advances in Large Vision-Language Models (LVLMs) have enabled\ngeneral-purpose vision tasks through visual instruction tuning. While existing\nLVLMs can generate segmentation masks from text prompts for single images, they\nstruggle with segmentation-grounded reasoning across images, especially at\nfiner granularities such as object parts. In this paper, we introduce the new\ntask of part-focused semantic co-segmentation, which involves identifying and\nsegmenting common objects, as well as common and unique object parts across\nimages. To address this task, we present CALICO, the first LVLM designed for\nmulti-image part-level reasoning segmentation. CALICO features two key\ncomponents, a novel Correspondence Extraction Module that identifies semantic\npart-level correspondences, and Correspondence Adaptation Modules that embed\nthis information into the LVLM to facilitate multi-image understanding in a\nparameter-efficient manner. To support training and evaluation, we curate\nMixedParts, a large-scale multi-image segmentation dataset containing\n$\\sim$2.4M samples across $\\sim$44K images spanning diverse object and part\ncategories. Experimental results demonstrate that CALICO, with just 0.3% of its\nparameters finetuned, achieves strong performance on this challenging task.",
      "tldr_zh": "本文提出了一种新的任务：part-focused semantic co-segmentation，用于在多张图像中识别和分割共同对象、共同和独特对象部分，以解决Large Vision-Language Models (LVLMs) 在细粒度多图像分割中的局限性。CALICO 是第一个针对此任务的LVLM框架，其关键组件包括Correspondence Extraction Module（用于识别语义部分级对应关系）和Correspondence Adaptation Modules（以参数高效方式嵌入信息以支持多图像理解）。为了支持训练和评估，研究团队创建了MixedParts数据集，该数据集包含约2.4M样本和44K图像，覆盖多样对象和部分类别。实验结果显示，CALICO仅微调0.3%的参数，即在这一挑战性任务上实现了强劲性能。",
      "categories": [
        "cs.CV",
        "cs.AI",
        "cs.LG"
      ],
      "primary_category": "cs.CV",
      "comment": "Accepted to CVPR 2025. Project page:\n  https://plan-lab.github.io/calico/",
      "pdf_url": "http://arxiv.org/pdf/2412.19331v2",
      "published_date": "2024-12-26 18:59:37 UTC",
      "updated_date": "2025-04-03 17:59:25 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-21T17:47:11.908878"
    },
    {
      "arxiv_id": "2412.19325v1",
      "title": "Performance Control in Early Exiting to Deploy Large Models at the Same Cost of Smaller Ones",
      "title_zh": "早退出中的性能控制：以相同成本部署大型模型",
      "authors": [
        "Mehrnaz Mofakhami",
        "Reza Bayat",
        "Ioannis Mitliagkas",
        "Joao Monteiro",
        "Valentina Zantedeschi"
      ],
      "abstract": "Early Exiting (EE) is a promising technique for speeding up inference by\nadaptively allocating compute resources to data points based on their\ndifficulty. The approach enables predictions to exit at earlier layers for\nsimpler samples while reserving more computation for challenging ones. In this\nstudy, we first present a novel perspective on the EE approach, showing that\nlarger models deployed with EE can achieve higher performance than smaller\nmodels while maintaining similar computational costs. As existing EE approaches\nrely on confidence estimation at each exit point, we further study the impact\nof overconfidence on the controllability of the compute-performance trade-off.\nWe introduce Performance Control Early Exiting (PCEE), a method that enables\naccuracy thresholding by basing decisions not on a data point's confidence but\non the average accuracy of samples with similar confidence levels from a\nheld-out validation set. In our experiments, we show that PCEE offers a simple\nyet computationally efficient approach that provides better control over\nperformance than standard confidence-based approaches, and allows us to scale\nup model sizes to yield performance gain while reducing the computational cost.",
      "tldr_zh": "这篇论文探讨了 Early Exiting (EE) 技术如何通过根据数据难度自适应分配计算资源，使大型模型在与小型模型相同的计算成本下实现更高性能。作者引入了 Performance Control Early Exiting (PCEE) 方法，该方法不依赖单个样本的置信度，而是基于验证集中类似置信度样本的平均准确率来决定退出点，从而更好地控制计算与性能的权衡。实验结果表明，PCEE 比传统置信度方法更高效，能扩大模型规模、提升性能并降低计算开销。",
      "categories": [
        "cs.LG",
        "cs.AI"
      ],
      "primary_category": "cs.LG",
      "comment": "Appeared at ICML 2024 Workshop on Efficient Systems for Foundation\n  Models (ES-FoMo-II)",
      "pdf_url": "http://arxiv.org/pdf/2412.19325v1",
      "published_date": "2024-12-26 18:54:32 UTC",
      "updated_date": "2024-12-26 18:54:32 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-21T17:47:23.708854"
    },
    {
      "arxiv_id": "2412.19321v1",
      "title": "A novel framework for MCDM based on Z numbers and soft likelihood function",
      "title_zh": "翻译失败",
      "authors": [
        "Yuanpeng He"
      ],
      "abstract": "The optimization on the structure of process of information management under\nuncertain environment has attracted lots of attention from researchers around\nthe world. Nevertheless, how to obtain accurate and rational evaluation from\nassessments produced by experts is still an open problem. Specially,\nintuitionistic fuzzy set provides an effective solution in handling\nindeterminate information. And Yager proposes a novel method for fusion of\nprobabilistic evidence to handle uncertain and conflicting information lately\nwhich is called soft likelihood function. This paper devises a novel framework\nof soft likelihood function based on information volume of fuzzy membership and\ncredibility measure for extracting truly useful and valuable information from\nuncertainty. An application is provided to verify the validity and correctness\nof the proposed framework. Besides, the comparisons with other existing methods\nfurther demonstrate the superiority of the novel framework of soft likelihood\nfunction.",
      "tldr_zh": "本文提出了一种基于 Z numbers 和 soft likelihood function 的新型 MCDM（Multi-Criteria Decision Making）框架，旨在在不确定环境中从专家评估中提取准确且有价值的信息。该框架结合了模糊成员信息量和可信度测度，处理不确定和冲突的信息，并扩展了 Yager 的软似然函数方法。通过实际应用和与其他现有方法的比较，证明了该框架的有效性与优越性。",
      "categories": [
        "cs.AI"
      ],
      "primary_category": "cs.AI",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2412.19321v1",
      "published_date": "2024-12-26 18:47:19 UTC",
      "updated_date": "2024-12-26 18:47:19 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-21T17:47:35.811929"
    },
    {
      "arxiv_id": "2412.19312v2",
      "title": "From Interests to Insights: An LLM Approach to Course Recommendations Using Natural Language Queries",
      "title_zh": "从兴趣到洞见：一种使用自然语言查询的 LLM 课程推荐方法",
      "authors": [
        "Hugh Van Deventer",
        "Mark Mills",
        "August Evrard"
      ],
      "abstract": "Most universities in the United States encourage their students to explore\nacademic areas before declaring a major and to acquire academic breadth by\nsatisfying a variety of requirements. Each term, students must choose among\nmany thousands of offerings, spanning dozens of subject areas, a handful of\ncourses to take. The curricular environment is also dynamic, and poor\ncommunication and search functions on campus can limit a student's ability to\ndiscover new courses of interest. To support both students and their advisers\nin such a setting, we explore a novel Large Language Model (LLM) course\nrecommendation system that applies a Retrieval Augmented Generation (RAG)\nmethod to the corpus of course descriptions. The system first generates an\n'ideal' course description based on the user's query. This description is\nconverted into a search vector using embeddings, which is then used to find\nactual courses with similar content by comparing embedding similarities. We\ndescribe the method and assess the quality and fairness of some example\nprompts. Steps to deploy a pilot system on campus are discussed.",
      "tldr_zh": "这篇论文提出了一种基于Large Language Model (LLM)的课程推荐系统，使用自然语言查询帮助大学学生从兴趣点出发发现合适的课程，解决信息过载和动态课程环境的问题。系统采用Retrieval Augmented Generation (RAG)方法，先基于用户查询生成一个“理想”课程描述，然后将该描述转换为嵌入向量，以检索相似内容的实际课程。研究评估了示例提示的质量和公平性，并讨论了在校园部署试点系统的可行步骤，为学生和顾问提供更有效的支持。",
      "categories": [
        "cs.IR",
        "cs.AI",
        "H.3"
      ],
      "primary_category": "cs.IR",
      "comment": "17 pages, 9 figures",
      "pdf_url": "http://arxiv.org/pdf/2412.19312v2",
      "published_date": "2024-12-26 18:19:53 UTC",
      "updated_date": "2024-12-30 15:30:23 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-21T17:47:47.654691"
    },
    {
      "arxiv_id": "2412.19311v1",
      "title": "xSRL: Safety-Aware Explainable Reinforcement Learning -- Safety as a Product of Explainability",
      "title_zh": "xSRL：安全感知的可解释强化学习——安全作为可解释性的产物",
      "authors": [
        "Risal Shahriar Shefin",
        "Md Asifur Rahman",
        "Thai Le",
        "Sarra Alqahtani"
      ],
      "abstract": "Reinforcement learning (RL) has shown great promise in simulated\nenvironments, such as games, where failures have minimal consequences. However,\nthe deployment of RL agents in real-world systems such as autonomous vehicles,\nrobotics, UAVs, and medical devices demands a higher level of safety and\ntransparency, particularly when facing adversarial threats. Safe RL algorithms\nhave been developed to address these concerns by optimizing both task\nperformance and safety constraints. However, errors are inevitable, and when\nthey occur, it is essential that the RL agents can also explain their actions\nto human operators. This makes trust in the safety mechanisms of RL systems\ncrucial for effective deployment. Explainability plays a key role in building\nthis trust by providing clear, actionable insights into the agent's\ndecision-making process, ensuring that safety-critical decisions are well\nunderstood. While machine learning (ML) has seen significant advances in\ninterpretability and visualization, explainability methods for RL remain\nlimited. Current tools fail to address the dynamic, sequential nature of RL and\nits needs to balance task performance with safety constraints over time. The\nre-purposing of traditional ML methods, such as saliency maps, is inadequate\nfor safety-critical RL applications where mistakes can result in severe\nconsequences. To bridge this gap, we propose xSRL, a framework that integrates\nboth local and global explanations to provide a comprehensive understanding of\nRL agents' behavior. xSRL also enables developers to identify policy\nvulnerabilities through adversarial attacks, offering tools to debug and patch\nagents without retraining. Our experiments and user studies demonstrate xSRL's\neffectiveness in increasing safety in RL systems, making them more reliable and\ntrustworthy for real-world deployment. Code is available at\nhttps://github.com/risal-shefin/xSRL.",
      "tldr_zh": "强化学习（RL）在真实世界应用如自动驾驶和机器人中面临安全和透明性挑战，现有的解释方法无法有效处理其动态特性及安全约束。\n本文提出 xSRL 框架，将安全视为解释性的产物，通过整合本地和全局解释，提供对 RL 代理决策过程的全面洞察，并利用对抗攻击识别政策漏洞，实现调试而不需重新训练。\n实验结果和用户研究显示，xSRL 显著提升了 RL 系统的安全性和可靠性，为其真实世界部署提供了更可信的解决方案。",
      "categories": [
        "cs.AI",
        "cs.HC",
        "cs.LG",
        "cs.MA"
      ],
      "primary_category": "cs.AI",
      "comment": "Accepted to 24th International Conference on Autonomous Agents and\n  Multiagent Systems (AAMAS 2025)",
      "pdf_url": "http://arxiv.org/pdf/2412.19311v1",
      "published_date": "2024-12-26 18:19:04 UTC",
      "updated_date": "2024-12-26 18:19:04 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-21T17:47:59.286096"
    },
    {
      "arxiv_id": "2412.19291v2",
      "title": "RAG with Differential Privacy",
      "title_zh": "翻译失败",
      "authors": [
        "Nicolas Grislain"
      ],
      "abstract": "Retrieval-Augmented Generation (RAG) has emerged as the dominant technique to\nprovide \\emph{Large Language Models} (LLM) with fresh and relevant context,\nmitigating the risk of hallucinations and improving the overall quality of\nresponses in environments with large and fast moving knowledge bases. However,\nthe integration of external documents into the generation process raises\nsignificant privacy concerns. Indeed, when added to a prompt, it is not\npossible to guarantee a response will not inadvertently expose confidential\ndata, leading to potential breaches of privacy and ethical dilemmas. This paper\nexplores a practical solution to this problem suitable to general knowledge\nextraction from personal data. It shows \\emph{differentially private token\ngeneration} is a viable approach to private RAG.",
      "tldr_zh": "这篇论文探讨了检索增强生成（RAG）技术在为大型语言模型（LLM）提供新鲜上下文时，可能导致隐私泄露的问题，特别是响应中无意暴露机密数据。作者提出了一种实用解决方案，通过差分隐私（Differential Privacy）在令牌生成过程中保护敏感信息，确保私有 RAG 的实现。实验结果表明，这种方法适用于从个人数据中提取一般知识，是一个可行的隐私保护策略。",
      "categories": [
        "cs.LG",
        "cs.AI",
        "cs.CR"
      ],
      "primary_category": "cs.LG",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2412.19291v2",
      "published_date": "2024-12-26 17:34:26 UTC",
      "updated_date": "2025-01-22 14:50:33 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-21T17:48:14.786899"
    },
    {
      "arxiv_id": "2412.19289v3",
      "title": "ViPCap: Retrieval Text-Based Visual Prompts for Lightweight Image Captioning",
      "title_zh": "翻译失败",
      "authors": [
        "Taewhan Kim",
        "Soeun Lee",
        "Si-Woo Kim",
        "Dong-Jin Kim"
      ],
      "abstract": "Recent lightweight image captioning models using retrieved data mainly focus\non text prompts. However, previous works only utilize the retrieved text as\ntext prompts, and the visual information relies only on the CLIP visual\nembedding. Because of this issue, there is a limitation that the image\ndescriptions inherent in the prompt are not sufficiently reflected in the\nvisual embedding space. To tackle this issue, we propose ViPCap, a novel\nretrieval text-based visual prompt for lightweight image captioning. ViPCap\nleverages the retrieved text with image information as visual prompts to\nenhance the ability of the model to capture relevant visual information. By\nmapping text prompts into the CLIP space and generating multiple randomized\nGaussian distributions, our method leverages sampling to explore randomly\naugmented distributions and effectively retrieves the semantic features that\ncontain image information. These retrieved features are integrated into the\nimage and designated as the visual prompt, leading to performance improvements\non the datasets such as COCO, Flickr30k, and NoCaps. Experimental results\ndemonstrate that ViPCap significantly outperforms prior lightweight captioning\nmodels in efficiency and effectiveness, demonstrating the potential for a\nplug-and-play solution. The source code is available at\nhttps://github.com/taewhankim/VIPCAP.",
      "tldr_zh": "该研究针对现有轻量级图像描述模型的局限性，提出了一种新型框架ViPCap，该框架利用检索文本与图像信息生成视觉提示，以增强模型捕捉相关视觉特征的能力。具体而言，ViPCap通过将文本提示映射到CLIP空间、生成随机化高斯分布并进行采样，检索并整合包含图像语义的特征作为视觉提示。实验结果显示，在COCO、Flickr30k和NoCaps数据集上，ViPCap在效率和效果上显著优于先前模型，提供了一个即插即用的解决方案。",
      "categories": [
        "cs.CV",
        "cs.AI",
        "cs.CL",
        "cs.LG"
      ],
      "primary_category": "cs.CV",
      "comment": "Accepted to AAAI 2025",
      "pdf_url": "http://arxiv.org/pdf/2412.19289v3",
      "published_date": "2024-12-26 17:29:38 UTC",
      "updated_date": "2025-01-24 16:16:52 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-21T17:48:27.369233"
    },
    {
      "arxiv_id": "2412.19286v1",
      "title": "Time Series Foundational Models: Their Role in Anomaly Detection and Prediction",
      "title_zh": "时间序列基础模型：它们在异常检测和预测中的作用",
      "authors": [
        "Chathurangi Shyalika",
        "Harleen Kaur Bagga",
        "Ahan Bhatt",
        "Renjith Prasad",
        "Alaa Al Ghazo",
        "Amit Sheth"
      ],
      "abstract": "Time series foundational models (TSFM) have gained prominence in time series\nforecasting, promising state-of-the-art performance across various\napplications. However, their application in anomaly detection and prediction\nremains underexplored, with growing concerns regarding their black-box nature,\nlack of interpretability and applicability. This paper critically evaluates the\nefficacy of TSFM in anomaly detection and prediction tasks. We systematically\nanalyze TSFM across multiple datasets, including those characterized by the\nabsence of discernible patterns, trends and seasonality. Our analysis shows\nthat while TSFMs can be extended for anomaly detection and prediction,\ntraditional statistical and deep learning models often match or outperform TSFM\nin these tasks. Additionally, TSFMs require high computational resources but\nfail to capture sequential dependencies effectively or improve performance in\nfew-shot or zero-shot scenarios. \\noindent The preprocessed datasets, codes to\nreproduce the results and supplementary materials are available at\nhttps://github.com/smtmnfg/TSFM.",
      "tldr_zh": "这篇论文评估了时间序列基础模型（TSFM）在异常检测和预测中的作用，针对其黑盒性质和可解释性问题进行批判性分析。研究通过系统分析多个数据集（包括无明显模式、趋势或季节性的数据），发现传统统计模型和深度学习模型通常能匹配或超越 TSFM 的性能。TSFM 虽可扩展应用于这些任务，但需消耗高计算资源，且在捕获顺序依赖性或少样本/零样本场景中表现不佳。作者提供了预处理数据集和代码（https://github.com/smtmnfg/TSFM），以便重现结果。",
      "categories": [
        "cs.LG",
        "cs.AI"
      ],
      "primary_category": "cs.LG",
      "comment": "12 pages, 6 figures, 5 tables. Accepted at AAAI2025 Anomaly Detection\n  in Scientific Domains Workshop",
      "pdf_url": "http://arxiv.org/pdf/2412.19286v1",
      "published_date": "2024-12-26 17:15:30 UTC",
      "updated_date": "2024-12-26 17:15:30 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-21T17:48:39.715217"
    },
    {
      "arxiv_id": "2412.19284v1",
      "title": "PearSAN: A Machine Learning Method for Inverse Design using Pearson Correlated Surrogate Annealing",
      "title_zh": "翻译失败",
      "authors": [
        "Michael Bezick",
        "Blake A. Wilson",
        "Vaishnavi Iyer",
        "Yuheng Chen",
        "Vladimir M. Shalaev",
        "Sabre Kais",
        "Alexander V. Kildishev",
        "Alexandra Boltasseva",
        "Brad Lackey"
      ],
      "abstract": "PearSAN is a machine learning-assisted optimization algorithm applicable to\ninverse design problems with large design spaces, where traditional optimizers\nstruggle. The algorithm leverages the latent space of a generative model for\nrapid sampling and employs a Pearson correlated surrogate model to predict the\nfigure of merit of the true design metric. As a showcase example, PearSAN is\napplied to thermophotovoltaic (TPV) metasurface design by matching the working\nbands between a thermal radiator and a photovoltaic cell. PearSAN can work with\nany pretrained generative model with a discretized latent space, making it easy\nto integrate with VQ-VAEs and binary autoencoders. Its novel Pearson\ncorrelational loss can be used as both a latent regularization method, similar\nto batch and layer normalization, and as a surrogate training loss. We compare\nboth to previous energy matching losses, which are shown to enforce poor\nregularization and performance, even with upgraded affine parameters. PearSAN\nachieves a state-of-the-art maximum design efficiency of 97%, and is at least\nan order of magnitude faster than previous methods, with an improved maximum\nfigure-of-merit gain.",
      "tldr_zh": "本文提出 PearSAN，一种机器学习辅助优化算法，用于处理大设计空间的逆向设计问题，通过利用生成模型的潜在空间进行快速采样，并采用 Pearson Correlated Surrogate Annealing 来预测真实设计指标。PearSAN 可以与预训练生成模型如 VQ-VAEs 和二进制自编码器无缝集成，并引入新型 Pearson 相关损失作为潜在空间正则化和代理训练损失，提升了算法的性能和效率。在热光伏 (TPV) 金属表面设计应用中，该方法实现了 97% 的最先进设计效率，比现有方法快至少一个数量级，并显著提高了最大性能指标。",
      "categories": [
        "cs.LG",
        "cs.AI"
      ],
      "primary_category": "cs.LG",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2412.19284v1",
      "published_date": "2024-12-26 17:02:19 UTC",
      "updated_date": "2024-12-26 17:02:19 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-21T17:48:51.419771"
    },
    {
      "arxiv_id": "2501.06196v1",
      "title": "How Do Artificial Intelligences Think? The Three Mathematico-Cognitive Factors of Categorical Segmentation Operated by Synthetic Neurons",
      "title_zh": "翻译失败",
      "authors": [
        "Michael Pichat",
        "William Pogrund",
        "Armanush Gasparian",
        "Paloma Pichat",
        "Samuel Demarchi",
        "Michael Veillet-Guillem"
      ],
      "abstract": "How do the synthetic neurons in language models create \"thought categories\"\nto segment and analyze their informational environment? What are the cognitive\ncharacteristics, at the very level of formal neurons, of this artificial\ncategorical thought? Based on the mathematical nature of algebraic operations\ninherent to neuronal aggregation functions, we attempt to identify\nmathematico-cognitive factors that genetically shape the categorical\nreconstruction of the informational world faced by artificial cognition. This\nstudy explores these concepts through the notions of priming, attention, and\ncategorical phasing.",
      "tldr_zh": "本研究探讨了语言模型中合成神经元(synthetic neurons)如何创建“thought categories”来分割和分析信息环境，焦点在于这些神经元在形式层面上的认知特性。基于神经元聚合函数的代数运算，论文识别出三个数学认知因素——priming、attention 和 categorical phasing，这些因素在基因层面塑造了人工认知对信息世界的分类重建。该工作为理解人工智能的分类思维提供了新的理论基础。",
      "categories": [
        "q-bio.NC",
        "cs.AI",
        "cs.NE"
      ],
      "primary_category": "q-bio.NC",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2501.06196v1",
      "published_date": "2024-12-26 16:26:00 UTC",
      "updated_date": "2024-12-26 16:26:00 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-21T17:49:02.432314"
    },
    {
      "arxiv_id": "2412.19260v2",
      "title": "MEDEC: A Benchmark for Medical Error Detection and Correction in Clinical Notes",
      "title_zh": "翻译失败",
      "authors": [
        "Asma Ben Abacha",
        "Wen-wai Yim",
        "Yujuan Fu",
        "Zhaoyi Sun",
        "Meliha Yetisgen",
        "Fei Xia",
        "Thomas Lin"
      ],
      "abstract": "Several studies showed that Large Language Models (LLMs) can answer medical\nquestions correctly, even outperforming the average human score in some medical\nexams. However, to our knowledge, no study has been conducted to assess the\nability of language models to validate existing or generated medical text for\ncorrectness and consistency. In this paper, we introduce MEDEC\n(https://github.com/abachaa/MEDEC), the first publicly available benchmark for\nmedical error detection and correction in clinical notes, covering five types\nof errors (Diagnosis, Management, Treatment, Pharmacotherapy, and Causal\nOrganism). MEDEC consists of 3,848 clinical texts, including 488 clinical notes\nfrom three US hospital systems that were not previously seen by any LLM. The\ndataset has been used for the MEDIQA-CORR shared task to evaluate seventeen\nparticipating systems [Ben Abacha et al., 2024]. In this paper, we describe the\ndata creation methods and we evaluate recent LLMs (e.g., o1-preview, GPT-4,\nClaude 3.5 Sonnet, and Gemini 2.0 Flash) for the tasks of detecting and\ncorrecting medical errors requiring both medical knowledge and reasoning\ncapabilities. We also conducted a comparative study where two medical doctors\nperformed the same task on the MEDEC test set. The results showed that MEDEC is\na sufficiently challenging benchmark to assess the ability of models to\nvalidate existing or generated notes and to correct medical errors. We also\nfound that although recent LLMs have a good performance in error detection and\ncorrection, they are still outperformed by medical doctors in these tasks. We\ndiscuss the potential factors behind this gap, the insights from our\nexperiments, the limitations of current evaluation metrics, and share potential\npointers for future research.",
      "tldr_zh": "本文引入了MEDEC基准，这是首个公开数据集，用于评估语言模型在临床笔记中检测和纠正医疗错误的能力，涵盖Diagnosis、Management、Treatment、Pharmacotherapy和Causal Organism五种错误类型。数据集包含3,848个临床文本，包括来自三个美国医院系统的488个新样本，并通过MEDIQA-CORR共享任务评估了17个系统和多种LLMs（如GPT-4和Claude 3.5 Sonnet）的性能。结果显示，虽然LLMs在错误检测和纠正上表现出色，但仍落后于医疗医生，论文讨论了这一差距的原因、实验见解以及未来研究方向。",
      "categories": [
        "cs.CL",
        "cs.AI",
        "cs.LG"
      ],
      "primary_category": "cs.CL",
      "comment": "This version has been updated with further clarification regarding\n  the model size estimates that were mined from public articles only and\n  provided to aid in contextualizing model performance. The authors cannot\n  vouch for the accuracy of those estimates",
      "pdf_url": "http://arxiv.org/pdf/2412.19260v2",
      "published_date": "2024-12-26 15:54:10 UTC",
      "updated_date": "2025-01-02 18:46:05 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-21T17:49:15.764045"
    },
    {
      "arxiv_id": "2412.19254v1",
      "title": "Leveraging Self-Training and Variational Autoencoder for Agitation Detection in People with Dementia Using Wearable Sensors",
      "title_zh": "翻译失败",
      "authors": [
        "Abeer Badawi",
        "Somayya Elmoghazy",
        "Samira Choudhury",
        "Khalid Elgazzar",
        "Amer Burhan"
      ],
      "abstract": "Dementia is a neurodegenerative disorder that has been growing among elder\npeople over the past decades. This growth profoundly impacts the quality of\nlife for patients and caregivers due to the symptoms arising from it. Agitation\nand aggression (AA) are some of the symptoms of people with severe dementia\n(PwD) in long-term care or hospitals. AA not only causes discomfort but also\nputs the patients or others at potential risk. Existing monitoring solutions\nutilizing different wearable sensors integrated with Artificial Intelligence\n(AI) offer a way to detect AA early enough for timely and adequate medical\nintervention. However, most studies are limited by the availability of\naccurately labeled datasets, which significantly affects the efficacy of such\nsolutions in real-world scenarios. This study presents a novel comprehensive\napproach to detect AA in PwD using physiological data from the Empatica E4\nwristbands. The research creates a diverse dataset, consisting of three\ndistinct datasets gathered from 14 participants across multiple hospitals in\nCanada. These datasets have not been extensively explored due to their limited\nlabeling. We propose a novel approach employing self-training and a variational\nautoencoder (VAE) to detect AA in PwD effectively. The proposed approach aims\nto learn the representation of the features extracted using the VAE and then\nuses a semi-supervised block to generate labels, classify events, and detect\nAA. We demonstrate that combining Self-Training and Variational Autoencoder\nmechanism significantly improves model performance in classifying AA in PwD.\nAmong the tested techniques, the XGBoost classifier achieved the highest\naccuracy of 90.16\\%. By effectively addressing the challenge of limited labeled\ndata, the proposed system not only learns new labels but also proves its\nsuperiority in detecting AA.",
      "tldr_zh": "本研究针对痴呆患者（PwD）的躁动和攻击性（AA）症状，使用 Empatica E4 可穿戴传感器创建了一个多样化数据集，以解决标注数据不足的挑战。论文提出了一种新方法，结合 Self-Training 和 Variational Autoencoder (VAE) 来提取生理特征、生成标签并分类事件，从而有效检测 AA。实验结果显示，XGBoost 分类器达到了 90.16% 的准确率，显著提高了模型性能并证明了该方法的实际应用价值。",
      "categories": [
        "cs.AI"
      ],
      "primary_category": "cs.AI",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2412.19254v1",
      "published_date": "2024-12-26 15:34:25 UTC",
      "updated_date": "2024-12-26 15:34:25 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-21T17:49:27.438951"
    },
    {
      "arxiv_id": "2412.19241v1",
      "title": "Latenrgy: Model Agnostic Latency and Energy Consumption Prediction for Binary Classifiers",
      "title_zh": "翻译失败",
      "authors": [
        "Jason M. Pittman"
      ],
      "abstract": "Machine learning systems increasingly drive innovation across scientific\nfields and industry, yet challenges in compute overhead, specifically during\ninference, limit their scalability and sustainability. Responsible AI\nguardrails, essential for ensuring fairness, transparency, and privacy, further\nexacerbate these computational demands. This study addresses critical gaps in\nthe literature, chiefly the lack of generalized predictive techniques for\nlatency and energy consumption, limited cross-comparisons of classifiers, and\nunquantified impacts of RAI guardrails on inference performance. Using Theory\nConstruction Methodology, this work constructed a model-agnostic theoretical\nframework for predicting latency and energy consumption in binary\nclassification models during inference. The framework synthesizes classifier\ncharacteristics, dataset properties, and RAI guardrails into a unified\nanalytical instrument. Two predictive equations are derived that capture the\ninterplay between these factors while offering generalizability across diverse\nclassifiers. The proposed framework provides foundational insights for\ndesigning efficient, responsible ML systems. It enables researchers to\nbenchmark and optimize inference performance and assists practitioners in\ndeploying scalable solutions. Finally, this work establishes a theoretical\nfoundation for balancing computational efficiency with ethical AI principles,\npaving the way for future empirical validation and broader applications.",
      "tldr_zh": "本研究针对机器学习系统在推理阶段的计算开销问题，特别是RAI guardrails（如公平性、透明度和隐私）带来的额外负担，提出一个模型无关的框架Latenrgy，用于预测二元分类器的latency和energy consumption。框架采用Theory Construction Methodology，整合分类器特性、数据集属性和RAI guardrails，推导出两个通用的预测方程，以捕捉这些因素间的交互作用。该框架为设计高效、负责任的ML系统提供理论基础，帮助研究人员基准测试和优化推理性能，同时平衡计算效率与伦理AI原则。",
      "categories": [
        "cs.LG",
        "cs.AI"
      ],
      "primary_category": "cs.LG",
      "comment": "8 pages, 2 tables",
      "pdf_url": "http://arxiv.org/pdf/2412.19241v1",
      "published_date": "2024-12-26 14:51:24 UTC",
      "updated_date": "2024-12-26 14:51:24 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-21T17:49:39.910339"
    },
    {
      "arxiv_id": "2412.19235v1",
      "title": "Are Two Hidden Layers Still Enough for the Physics-Informed Neural Networks?",
      "title_zh": "两个隐藏层对于物理信息神经网络是否仍然足够？",
      "authors": [
        "Vasiliy A. Es'kin",
        "Alexey O. Malkhanov",
        "Mikhail E. Smorkalov"
      ],
      "abstract": "The article discusses the development of various methods and techniques for\ninitializing and training neural networks with a single hidden layer, as well\nas training a separable physics-informed neural network consisting of neural\nnetworks with a single hidden layer to solve physical problems described by\nordinary differential equations (ODEs) and partial differential equations\n(PDEs). A method for strictly deterministic initialization of a neural network\nwith one hidden layer for solving physical problems described by an ODE is\nproposed. Modifications to existing methods for weighting the loss function are\ngiven, as well as new methods developed for training strictly\ndeterministic-initialized neural networks to solve ODEs (detaching, additional\nweighting based on the second derivative, predicted solution-based weighting,\nrelative residuals). An algorithm for physics-informed data-driven\ninitialization of a neural network with one hidden layer is proposed. A neural\nnetwork with pronounced generalizing properties is presented, whose\ngeneralizing abilities of which can be precisely controlled by adjusting\nnetwork parameters. A metric for measuring the generalization of such neural\nnetwork has been introduced. A gradient-free neuron-by-neuron fitting method\nhas been developed for adjusting the parameters of a single-hidden-layer neural\nnetwork, which does not require the use of an optimizer or solver for its\nimplementation. The proposed methods have been extended to 2D problems using\nthe separable physics-informed neural networks approach. Numerous experiments\nhave been carried out to develop the above methods and approaches. Experiments\non physical problems, such as solving various ODEs and PDEs, have demonstrated\nthat these methods for initializing and training neural networks with one or\ntwo hidden layers (SPINN) achieve competitive accuracy and, in some cases,\nstate-of-the-art results.",
      "tldr_zh": "这篇论文探讨了Physics-Informed Neural Networks (PINNs)中隐藏层数量的必要性，重点开发了单隐藏层神经网络的初始化和训练方法，以解决ordinary differential equations (ODEs)和partial differential equations (PDEs)等问题。论文提出了一种严格确定性初始化方法，以及新的损失函数加权策略（如detaching、基于二阶导数的额外加权和相对残差加权），并引入了物理信息数据驱动初始化算法和无梯度神经元逐个拟合方法。实验结果显示，这些方法在单隐藏层或Separable Physics-Informed Neural Networks (SPINN)上实现了竞争性准确性，甚至在某些ODEs和PDEs问题上达到了最先进水平。",
      "categories": [
        "math.NA",
        "cs.AI",
        "cs.LG",
        "cs.NA",
        "physics.comp-ph",
        "68T07 (Primary) 65Z05, 65M99 (Secondary)",
        "I.2.1; I.2.7; J.2"
      ],
      "primary_category": "math.NA",
      "comment": "45 pages, 36 figures, 9 tables",
      "pdf_url": "http://arxiv.org/pdf/2412.19235v1",
      "published_date": "2024-12-26 14:30:54 UTC",
      "updated_date": "2024-12-26 14:30:54 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-21T17:49:52.242261"
    },
    {
      "arxiv_id": "2501.01441v2",
      "title": "Explanatory Debiasing: Involving Domain Experts in the Data Generation Process to Mitigate Representation Bias in AI Systems",
      "title_zh": "解释性去偏置：让领域专家参与数据生成过程以缓解 AI 系统中的表示偏置",
      "authors": [
        "Aditya Bhattacharya",
        "Simone Stumpf",
        "Robin De Croon",
        "Katrien Verbert"
      ],
      "abstract": "Representation bias is one of the most common types of biases in artificial\nintelligence (AI) systems, causing AI models to perform poorly on\nunderrepresented data segments. Although AI practitioners use various methods\nto reduce representation bias, their effectiveness is often constrained by\ninsufficient domain knowledge in the debiasing process. To address this gap,\nthis paper introduces a set of generic design guidelines for effectively\ninvolving domain experts in representation debiasing. We instantiated our\nproposed guidelines in a healthcare-focused application and evaluated them\nthrough a comprehensive mixed-methods user study with 35 healthcare experts.\nOur findings show that involving domain experts can reduce representation bias\nwithout compromising model accuracy. Based on our findings, we also offer\nrecommendations for developers to build robust debiasing systems guided by our\ngeneric design guidelines, ensuring more effective inclusion of domain experts\nin the debiasing process.",
      "tldr_zh": "这篇论文针对 AI 系统中的 representation bias 问题，提出了一套通用设计指南，通过在数据生成过程中涉及领域专家来缓解偏差，从而提升模型在 underrepresented 数据上的性能。\n研究者将这些指南应用于医疗领域的应用，并通过一项涉及35名医疗专家的混合方法用户研究进行评估。\n结果显示，这种专家参与的方法能够有效减少 representation bias，同时不影响模型准确性，并为开发者提供了构建鲁棒 debiasing 系统的推荐。",
      "categories": [
        "cs.HC",
        "cs.AI"
      ],
      "primary_category": "cs.HC",
      "comment": "Pre-print version, please cite the main article instead of the\n  pre-print version",
      "pdf_url": "http://arxiv.org/pdf/2501.01441v2",
      "published_date": "2024-12-26 14:14:48 UTC",
      "updated_date": "2025-02-27 08:45:05 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-21T17:50:02.963613"
    },
    {
      "arxiv_id": "2412.19228v2",
      "title": "Learning Cross-Domain Representations for Transferable Drug Perturbations on Single-Cell Transcriptional Responses",
      "title_zh": "针对单细胞转",
      "authors": [
        "Hui Liu",
        "Shikai Jin"
      ],
      "abstract": "Phenotypic drug discovery has attracted widespread attention because of its\npotential to identify bioactive molecules. Transcriptomic profiling provides a\ncomprehensive reflection of phenotypic changes in cellular responses to\nexternal perturbations. In this paper, we propose XTransferCDR, a novel\ngenerative framework designed for feature decoupling and transferable\nrepresentation learning across domains. Given a pair of perturbed expression\nprofiles, our approach decouples the perturbation representations from basal\nstates through domain separation encoders and then cross-transfers them in the\nlatent space. The transferred representations are then used to reconstruct the\ncorresponding perturbed expression profiles via a shared decoder. This\ncross-transfer constraint effectively promotes the learning of transferable\ndrug perturbation representations. We conducted extensive evaluations of our\nmodel on multiple datasets, including single-cell transcriptional responses to\ndrugs and single- and combinatorial genetic perturbations. The experimental\nresults show that XTransferCDR achieved better performance than current\nstate-of-the-art methods, showcasing its potential to advance phenotypic drug\ndiscovery.",
      "tldr_zh": "本论文提出 XTransferCDR，一种新型生成框架，用于特征解耦和跨域可转移表示学习，旨在提升单细胞转录组对药物扰动的分析。该框架通过域分离编码器将扰动表示从基态中解耦，并在潜在空间中交叉转移这些表示，随后利用共享解码器重建对应的扰动表达谱，以促进可转移药物扰动表示的学习。实验结果显示，XTransferCDR 在包括药物和遗传扰动在内的多个数据集上，优于现有最先进方法，有望显著推进表型药物发现。",
      "categories": [
        "cs.LG",
        "cs.AI"
      ],
      "primary_category": "cs.LG",
      "comment": "Accepted by The 39th Annual AAAI Conference on Artificial Intelligenc\n  (AAAI 2025)",
      "pdf_url": "http://arxiv.org/pdf/2412.19228v2",
      "published_date": "2024-12-26 14:09:16 UTC",
      "updated_date": "2025-01-15 01:16:30 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-21T17:50:16.252058"
    },
    {
      "arxiv_id": "2412.19226v1",
      "title": "VINEVI: A Virtualized Network Vision Architecture for Smart Monitoring of Heterogeneous Applications and Infrastructures",
      "title_zh": "翻译失败",
      "authors": [
        "Rodrigo Moreira",
        "Hugo G. V. O. da Cunha",
        "Larissa F. Rodrigues Moreira",
        "Flávio de Oliveira Silva"
      ],
      "abstract": "Monitoring heterogeneous infrastructures and applications is essential to\ncope with user requirements properly, but it still lacks enhancements. The\nwell-known state-of-the-art methods and tools do not support seamless\nmonitoring of bare-metal, low-cost infrastructures, neither hosted nor\nvirtualized services with fine-grained details. This work proposes VIrtualized\nNEtwork VIsion architecture (VINEVI), an intelligent method for seamless\nmonitoring heterogeneous infrastructures and applications. The VINEVI\narchitecture advances state of the art with a node-embedded traffic\nclassification agent placing physical and virtualized infrastructures enabling\nreal-time traffic classification. VINEVI combines this real-time traffic\nclassification with well-known tools such as Prometheus and Victoria Metrics to\nmonitor the entire stack from the hardware to the virtualized applications.\nExperimental results showcased that VINEVI architecture allowed seamless\nheterogeneous infrastructure monitoring with a higher level of detail beyond\nliterature. Also, our node-embedded real-time Internet traffic classifier\nevolved with flexibility the methods with monitoring heterogeneous\ninfrastructures seamlessly.",
      "tldr_zh": "这篇论文提出了 VINEVI（VIrtualized NEtwork VIsion）架构，一种用于智能监控异构应用和基础设施的虚拟化网络视觉方法，以解决现有工具无法无缝监控裸金属、低成本基础设施和虚拟化服务的问题。VINEVI 通过节点嵌入的 traffic classification agent 实现实时流量分类，并结合 Prometheus 和 Victoria Metrics 等工具，对从硬件到虚拟化应用的整个栈进行细粒度监控。实验结果显示，该架构提供了比文献中更高的监控细节水平，并展示了灵活监控异构基础设施的潜力。",
      "categories": [
        "cs.NI",
        "cs.AI",
        "cs.CV",
        "cs.LG"
      ],
      "primary_category": "cs.NI",
      "comment": "12 pages",
      "pdf_url": "http://arxiv.org/pdf/2412.19226v1",
      "published_date": "2024-12-26 14:05:14 UTC",
      "updated_date": "2024-12-26 14:05:14 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-21T17:50:26.965452"
    },
    {
      "arxiv_id": "2412.19215v1",
      "title": "Optimizing Fantasy Sports Team Selection with Deep Reinforcement Learning",
      "title_zh": "翻译失败",
      "authors": [
        "Shamik Bhattacharjee",
        "Kamlesh Marathe",
        "Hitesh Kapoor",
        "Nilesh Patil"
      ],
      "abstract": "Fantasy sports, particularly fantasy cricket, have garnered immense\npopularity in India in recent years, offering enthusiasts the opportunity to\nengage in strategic team-building and compete based on the real-world\nperformance of professional athletes. In this paper, we address the challenge\nof optimizing fantasy cricket team selection using reinforcement learning (RL)\ntechniques. By framing the team creation process as a sequential\ndecision-making problem, we aim to develop a model that can adaptively select\nplayers to maximize the team's potential performance. Our approach leverages\nhistorical player data to train RL algorithms, which then predict future\nperformance and optimize team composition. This not only represents a huge\nbusiness opportunity by enabling more accurate predictions of high-performing\nteams but also enhances the overall user experience. Through empirical\nevaluation and comparison with traditional fantasy team drafting methods, we\ndemonstrate the effectiveness of RL in constructing competitive fantasy teams.\nOur results show that RL-based strategies provide valuable insights into player\nselection in fantasy sports.",
      "tldr_zh": "本文提出了一种基于深度强化学习（Deep Reinforcement Learning）的优化方法，用于幻想体育（如幻想板球）团队选择问题。通过将团队构建过程视为顺序决策问题，并利用历史玩家数据训练强化学习（RL）算法，该方法能预测玩家未来表现并动态优化团队组成。与传统选队方法相比，实验评估显示RL策略显著提高了团队竞争力，提供更准确的预测，并为商业机会和用户体验提升带来潜在价值。",
      "categories": [
        "cs.AI",
        "cs.LG",
        "I.2.1"
      ],
      "primary_category": "cs.AI",
      "comment": "8 Pages including references, Accepted to CODS-COMAD 2024 conference",
      "pdf_url": "http://arxiv.org/pdf/2412.19215v1",
      "published_date": "2024-12-26 13:36:18 UTC",
      "updated_date": "2024-12-26 13:36:18 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-21T17:50:38.437382"
    },
    {
      "arxiv_id": "2412.19198v1",
      "title": "Multi-Attribute Constraint Satisfaction via Language Model Rewriting",
      "title_zh": "翻译失败",
      "authors": [
        "Ashutosh Baheti",
        "Debanjana Chakraborty",
        "Faeze Brahman",
        "Ronan Le Bras",
        "Ximing Lu",
        "Nouha Dziri",
        "Yejin Choi",
        "Mark Riedl",
        "Maarten Sap"
      ],
      "abstract": "Obeying precise constraints on top of multiple external attributes is a\ncommon computational problem underlying seemingly different domains, from\ncontrolled text generation to protein engineering. Existing language model (LM)\ncontrollability methods for multi-attribute constraint satisfaction often rely\non specialized architectures or gradient-based classifiers, limiting their\nflexibility to work with arbitrary black-box evaluators and pretrained models.\nCurrent general-purpose large language models, while capable, cannot achieve\nfine-grained multi-attribute control over external attributes. Thus, we create\nMulti-Attribute Constraint Satisfaction (MACS), a generalized method capable of\nfinetuning language models on any sequential domain to satisfy user-specified\nconstraints on multiple external real-value attributes. Our method trains LMs\nas editors by sampling diverse multi-attribute edit pairs from an initial set\nof paraphrased outputs. During inference, LM iteratively improves upon its\nprevious solution to satisfy constraints for all attributes by leveraging our\ndesigned constraint satisfaction reward. We additionally experiment with\nreward-weighted behavior cloning to further improve the constraint satisfaction\nrate of LMs. To evaluate our approach, we present a new Fine-grained Constraint\nSatisfaction (FineCS) benchmark, featuring two challenging tasks: (1) Text\nStyle Transfer, where the goal is to simultaneously modify the sentiment and\ncomplexity of reviews, and (2) Protein Design, focusing on modulating\nfluorescence and stability of Green Fluorescent Proteins (GFP). Our empirical\nresults show that MACS achieves the highest threshold satisfaction in both\nFineCS tasks, outperforming strong domain-specific baselines. Our work opens\nnew avenues for generalized and real-value multi-attribute control, with\nimplications for diverse applications spanning NLP and bioinformatics.",
      "tldr_zh": "这篇论文提出了 Multi-Attribute Constraint Satisfaction (MACS)，一种通用方法，用于微调语言模型（LM）以满足用户指定的多个外部实值属性约束，从而解决文本生成和蛋白质工程等领域的控制难题。MACS 通过训练 LM 作为编辑器，从初始改写输出中采样多样化编辑对，并在推理阶段使用迭代改进和约束满足奖励机制（如奖励加权行为克隆）来提升性能。论文引入了新的 FineCS 基准测试，包括文本风格转移（同时修改评论的情感和复杂度）和蛋白质设计（调节绿色荧光蛋白的荧光与稳定性）两个任务，结果显示 MACS 实现了最高的阈值满足率，优于现有领域特定基线。该方法为 NLP 和生物信息学等领域提供了泛化多属性控制的新途径。",
      "categories": [
        "cs.AI"
      ],
      "primary_category": "cs.AI",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2412.19198v1",
      "published_date": "2024-12-26 12:36:39 UTC",
      "updated_date": "2024-12-26 12:36:39 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-21T17:50:52.392577"
    },
    {
      "arxiv_id": "2412.19194v1",
      "title": "Provably Efficient Exploration in Reward Machines with Low Regret",
      "title_zh": "翻译失败",
      "authors": [
        "Hippolyte Bourel",
        "Anders Jonsson",
        "Odalric-Ambrym Maillard",
        "Chenxiao Ma",
        "Mohammad Sadegh Talebi"
      ],
      "abstract": "We study reinforcement learning (RL) for decision processes with\nnon-Markovian reward, in which high-level knowledge of the task in the form of\nreward machines is available to the learner. We consider probabilistic reward\nmachines with initially unknown dynamics, and investigate RL under the\naverage-reward criterion, where the learning performance is assessed through\nthe notion of regret. Our main algorithmic contribution is a model-based RL\nalgorithm for decision processes involving probabilistic reward machines that\nis capable of exploiting the structure induced by such machines. We further\nderive high-probability and non-asymptotic bounds on its regret and demonstrate\nthe gain in terms of regret over existing algorithms that could be applied, but\nobliviously to the structure. We also present a regret lower bound for the\nstudied setting. To the best of our knowledge, the proposed algorithm\nconstitutes the first attempt to tailor and analyze regret specifically for RL\nwith probabilistic reward machines.",
      "tldr_zh": "本论文研究了强化学习（Reinforcement Learning）中非Markov奖励决策过程，假设有奖励机器（Reward Machines）的可用知识。作者提出了一种基于模型的RL算法，针对概率奖励机器（Probabilistic Reward Machines）的未知动态，利用其结构进行高效探索，并在平均奖励标准（Average-Reward Criterion）下实现了低遗憾（Low Regret）。该算法提供了高概率、非渐近遗憾界，并证明其在遗憾方面比忽略结构的现有算法有显著改进；此外，论文还给出了遗憾下界（Regret Lower Bound），这是首个专门针对此设置的分析方法。",
      "categories": [
        "cs.LG",
        "cs.AI"
      ],
      "primary_category": "cs.LG",
      "comment": "35 pages",
      "pdf_url": "http://arxiv.org/pdf/2412.19194v1",
      "published_date": "2024-12-26 12:25:04 UTC",
      "updated_date": "2024-12-26 12:25:04 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-21T17:51:04.254009"
    },
    {
      "arxiv_id": "2412.19191v1",
      "title": "Biology Instructions: A Dataset and Benchmark for Multi-Omics Sequence Understanding Capability of Large Language Models",
      "title_zh": "翻译失败",
      "authors": [
        "Haonan He",
        "Yuchen Ren",
        "Yining Tang",
        "Ziyang Xu",
        "Junxian Li",
        "Minghao Yang",
        "Di Zhang",
        "Dong Yuan",
        "Tao Chen",
        "Shufei Zhang",
        "Yuqiang Li",
        "Nanqing Dong",
        "Wanli Ouyang",
        "Dongzhan Zhou",
        "Peng Ye"
      ],
      "abstract": "Large language models have already demonstrated their formidable capabilities\nin general domains, ushering in a revolutionary transformation. However,\nexploring and exploiting the extensive knowledge of these models to comprehend\nmulti-omics biology remains underexplored. To fill this research gap, we first\nintroduce Biology-Instructions, the first large-scale multi-omics biological\nsequences-related instruction-tuning dataset including DNA, RNA, proteins, and\nmulti-molecules, designed to bridge the gap between large language models\n(LLMs) and complex biological sequences-related tasks. This dataset can enhance\nthe versatility of LLMs by integrating diverse biological sequenced-based\nprediction tasks with advanced reasoning capabilities, while maintaining\nconversational fluency. Additionally, we reveal significant performance\nlimitations in even state-of-the-art LLMs on biological sequence-related\nmulti-omics tasks without specialized pre-training and instruction-tuning. We\nfurther develop a strong baseline called ChatMultiOmics with a novel\nthree-stage training pipeline, demonstrating the powerful ability to understand\nbiology by using Biology-Instructions. Biology-Instructions and ChatMultiOmics\nare publicly available and crucial resources for enabling more effective\nintegration of LLMs with multi-omics sequence analysis.",
      "tldr_zh": "本研究引入了Biology-Instructions，这是首个大规模多组学(multi-omics)生物序列相关指令微调数据集，涵盖DNA、RNA、蛋白质和多分子，旨在提升Large Language Models (LLMs)在复杂生物序列预测任务中的多功能性、推理能力和对话流畅性。研究发现，即使是先进的LLMs在缺乏专门预训练和指令微调的情况下，在生物序列相关任务上存在显著性能限制。作者开发了强有力的基线模型ChatMultiOmics，通过一个新型的三阶段训练管道利用Biology-Instructions，显著提高了模型对生物学的理解能力。该数据集和模型已公开，作为关键资源促进LLMs与多组学序列分析的更有效整合。",
      "categories": [
        "q-bio.BM",
        "cs.AI",
        "cs.LG"
      ],
      "primary_category": "q-bio.BM",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2412.19191v1",
      "published_date": "2024-12-26 12:12:23 UTC",
      "updated_date": "2024-12-26 12:12:23 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-21T17:51:15.686280"
    },
    {
      "arxiv_id": "2412.19179v2",
      "title": "Mask Approximation Net: A Novel Diffusion Model Approach for Remote Sensing Change Captioning",
      "title_zh": "Mask Approximation Net: 一种新颖的扩散模型方法用于遥感变化描述",
      "authors": [
        "Dongwei Sun",
        "Jing Yao",
        "Changsheng Zhou",
        "Xiangyong Cao",
        "Pedram Ghamisi"
      ],
      "abstract": "Remote sensing image change description represents an innovative multimodal\ntask within the realm of remote sensing processing. This task not only\nfacilitates the detection of alterations in surface conditions, but also\nprovides comprehensive descriptions of these changes, thereby improving human\ninterpretability and interactivity.Generally, existing deep-learning-based\nmethods predominantly utilized a three-stage framework that successively\nperform feature extraction, feature fusion, and localization from bitemporal\nimages before text generation. However, this reliance often leads to an\nexcessive focus on the design of specific network architectures and restricts\nthe feature distributions to the dataset at hand, which in turn results in\nlimited generalizability and robustness during application.To address these\nlimitations, this paper proposes a novel approach for remote sensing image\nchange detection and description that incorporates diffusion models, aiming to\ntransition the emphasis of modeling paradigms from conventional feature\nlearning to data distribution learning. The proposed method primarily includes\na simple multi-scale change detection module, whose output features are\nsubsequently refined by an well-designed diffusion model. Furthermore, we\nintroduce a frequency-guided complex filter module to boost the model\nperformance by managing high-frequency noise throughout the diffusion process.\nWe validate the effectiveness of our proposed method across several datasets\nfor remote sensing change detection and description, showcasing its superior\nperformance compared to existing techniques. The code will be available at\n\\href{https://github.com/sundongwei}{MaskApproxNet} after a possible\npublication.",
      "tldr_zh": "本研究提出了一种名为Mask Approximation Net的新方法，基于diffusion models，用于remote sensing图像变化描述任务。该方法转向数据分布学习，包含一个多尺度变化检测模块、diffusion模型对特征的精炼处理，以及一个频率引导的复杂过滤模块，以有效管理高频噪声并提升模型的泛化性和鲁棒性。与传统三阶段框架相比，该方法减少了对特定网络架构的依赖。在多个remote sensing变化检测和描述数据集上实验验证，该方法表现出色，性能优于现有技术。",
      "categories": [
        "cs.CV",
        "cs.AI",
        "cs.LG"
      ],
      "primary_category": "cs.CV",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2412.19179v2",
      "published_date": "2024-12-26 11:35:57 UTC",
      "updated_date": "2025-02-16 09:13:25 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-21T17:51:29.072945"
    },
    {
      "arxiv_id": "2412.19178v1",
      "title": "Reversed in Time: A Novel Temporal-Emphasized Benchmark for Cross-Modal Video-Text Retrieval",
      "title_zh": "翻译失败",
      "authors": [
        "Yang Du",
        "Yuqi Liu",
        "Qin Jin"
      ],
      "abstract": "Cross-modal (e.g. image-text, video-text) retrieval is an important task in\ninformation retrieval and multimodal vision-language understanding field.\nTemporal understanding makes video-text retrieval more challenging than\nimage-text retrieval. However, we find that the widely used video-text\nbenchmarks have shortcomings in comprehensively assessing abilities of models,\nespecially in temporal understanding, causing large-scale image-text\npre-trained models can already achieve comparable zero-shot performance with\nvideo-text pre-trained models. In this paper, we introduce RTime, a novel\ntemporal-emphasized video-text retrieval dataset. We first obtain videos of\nactions or events with significant temporality, and then reverse these videos\nto create harder negative samples. We then recruit annotators to judge the\nsignificance and reversibility of candidate videos, and write captions for\nqualified videos. We further adopt GPT-4 to extend more captions based on\nhuman-written captions. Our RTime dataset currently consists of 21k videos with\n10 captions per video, totalling about 122 hours. Based on RTime, we propose\nthree retrieval benchmark tasks: RTime-Origin, RTime-Hard, and RTime-Binary. We\nfurther enhance the use of harder-negatives in model training, and benchmark a\nvariety of video-text models on RTime. Extensive experiment analysis proves\nthat RTime indeed poses new and higher challenges to video-text retrieval. We\nrelease our RTime\ndataset\\footnote{\\url{https://github.com/qyr0403/Reversed-in-Time}} to further\nadvance video-text retrieval and multimodal understanding research.",
      "tldr_zh": "这篇论文提出 RTime，一个专注于时间理解的跨模态视频-文本检索基准数据集，以解决现有基准在评估模型时间能力方面的不足。研究方法包括获取具有显著时间性的视频，反转这些视频创建 harder negative samples，并通过人类标注者和 GPT-4 扩展生成标题，最终构建了包含 21k 视频（约 122 小时）和每视频 10 个标题的数据集。基于 RTime，他们定义了三个基准任务（RTime-Origin、RTime-Hard 和 RTime-Binary），并通过增强 harder-negatives 的训练方式对多种视频-文本模型进行基准测试，结果显示 RTime 显著提高了模型的挑战性，促进了多模态理解研究。",
      "categories": [
        "cs.CV",
        "cs.AI",
        "cs.CL",
        "cs.IR",
        "cs.LG"
      ],
      "primary_category": "cs.CV",
      "comment": "ACMMM 2024 poster",
      "pdf_url": "http://arxiv.org/pdf/2412.19178v1",
      "published_date": "2024-12-26 11:32:00 UTC",
      "updated_date": "2024-12-26 11:32:00 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-21T17:51:40.281147"
    },
    {
      "arxiv_id": "2412.19163v2",
      "title": "Master Stability Functions in Complex Networks",
      "title_zh": "复杂网络中的主稳定性函数",
      "authors": [
        "Suman Acharyya",
        "Priodyuti Pradhan",
        "Chandrakala Meena"
      ],
      "abstract": "Synchronization is an emergent and fundamental phenomenon in nature and\nengineered systems. Understanding the stability of a synchronized phenomenon is\ncrucial for ensuring functionality in various complex systems. The stability of\nthe synchronization phenomenon is extensively studied using the Master\nStability Function (MSF). This powerful and elegant tool plays a pivotal role\nin determining the stability of synchronization states, providing deep insights\ninto synchronization in coupled systems. Although MSF analysis has been used\nfor 25 years to study the stability of synchronization states, a systematic\ninvestigation of MSF across various networked systems remains missing from the\nliterature. In this article, we present a simplified and unified MSF analysis\nfor diverse undirected and directed networked systems. We begin with the\nanalytical MSF framework for pairwise-coupled identical systems with diffusive\nand natural coupling schemes and extend our analysis to directed networks and\nmultilayer networks, considering both intra-layer and inter-layer interactions.\nFurthermore, we revisit the MSF framework to incorporate higher-order\ninteractions alongside pairwise interactions. To enhance understanding, we also\nprovide a numerical analysis of synchronization in coupled R\\\"ossler systems\nunder pairwise diffusive coupling and propose algorithms for determining the\nMSF, identifying stability regimes, and classifying MSF functions. Overall, the\nprimary goal of this review is to present a systematic study of MSF in coupled\ndynamical networks in a clear and structured manner, making this powerful tool\nmore accessible. Furthermore, we highlight cases where the study of\nsynchronization states using MSF remains underexplored. Additionally, we\ndiscuss recent research focusing on MSF analysis using time series data and\nmachine learning approaches.",
      "tldr_zh": "本论文系统研究了Master Stability Function (MSF) 在复杂网络中分析同步现象稳定性的应用，填补了现有文献中对MSF在各种网络系统全面调查的空白。主要贡献包括提出一个简化统一的MSF分析框架，扩展到无向、有向网络、多层网络以及更高阶交互，并结合数值分析如耦合Rössler系统。论文还提供算法来确定MSF、识别稳定性区域并分类函数，从而提升了MSF工具的可访问性，并讨论了基于时间序列数据和机器学习方法的未来研究方向。",
      "categories": [
        "nlin.AO",
        "cs.AI",
        "nlin.CD"
      ],
      "primary_category": "nlin.AO",
      "comment": "49 pages, 5 figures",
      "pdf_url": "http://arxiv.org/pdf/2412.19163v2",
      "published_date": "2024-12-26 10:47:00 UTC",
      "updated_date": "2025-03-14 17:23:18 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-21T17:51:50.910223"
    },
    {
      "arxiv_id": "2412.19160v2",
      "title": "Cross-Spectral Vision Transformer for Biometric Authentication using Forehead Subcutaneous Vein Pattern and Periocular Pattern",
      "title_zh": "翻译失败",
      "authors": [
        "Arun K. Sharma",
        "Shubhobrata Bhattacharya",
        "Motahar Reza",
        "Bishakh Bhattacharya"
      ],
      "abstract": "Traditional biometric systems have encountered significant setbacks due to\nvarious unavoidable factors, for example, face recognition-based biometrics\nfails due to the wearing of face masks and fingerprints create hygiene\nconcerns. This paper proposes a novel lightweight cross-spectral vision\ntransformer (CS-ViT) for biometric authentication using forehead subcutaneous\nvein patterns and periocular patterns, offering a promising alternative to\ntraditional methods, capable of performing well even with the face masks and\nwithout any physical touch. The proposed framework comprises a cross-spectral\ndual-channel architecture designed to handle two distinct biometric traits and\nto capture inter-dependencies in terms of relative spectral patterns. Each\nchannel consists of a Phase-Only Correlation Cross-Spectral Attention (POC-CSA)\nthat captures their individual as well as correlated patterns. The computation\nof cross-spectral attention using POC extracts the phase correlation in the\nspatial features. Therefore, it is robust against the resolution/intensity\nvariations and illumination of the input images, assuming both biometric traits\nare from the same person. The lightweight model is suitable for edge device\ndeployment. The performance of the proposed algorithm was rigorously evaluated\nusing the Forehead Subcutaneous Vein Pattern and Periocular Biometric Pattern\n(FSVP-PBP) database. The results demonstrated the superiority of the algorithm\nover state-of-the-art methods, achieving a remarkable classification accuracy\nof 98.8% with the combined vein and periocular patterns.",
      "tldr_zh": "本研究提出了一种轻量级跨光谱视觉Transformer (CS-ViT)，用于基于额头皮下静脉模式 (forehead subcutaneous vein pattern) 和眼周模式 (periocular pattern) 的生物特征认证，以解决传统方法（如面部识别受面罩影响和指纹卫生问题）的局限性。该框架采用双通道架构，每个通道集成 Phase-Only Correlation Cross-Spectral Attention (POC-CSA) 机制，捕获个体特征及其相关光谱模式，并通过相位相关增强对图像分辨率、强度变化和照明变化的鲁棒性。CS-ViT 设计轻便，适合边缘设备部署。在 FSVP-PBP 数据库上实验表明，该算法在结合两种生物特征时，分类准确率达 98.8%，优于现有方法，为无接触式生物认证提供了高效替代方案。",
      "categories": [
        "cs.CV",
        "cs.AI",
        "cs.LG"
      ],
      "primary_category": "cs.CV",
      "comment": "Submitted to IEEE TPAMI",
      "pdf_url": "http://arxiv.org/pdf/2412.19160v2",
      "published_date": "2024-12-26 10:40:15 UTC",
      "updated_date": "2025-03-03 06:34:25 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-21T17:52:03.480083"
    },
    {
      "arxiv_id": "2412.19159v1",
      "title": "Mobile Robots through Task-Based Human Instructions using Incremental Curriculum Learning",
      "title_zh": "翻译失败",
      "authors": [
        "Muhammad A. Muttaqien",
        "Ayanori Yorozu",
        "Akihisa Ohya"
      ],
      "abstract": "This paper explores the integration of incremental curriculum learning (ICL)\nwith deep reinforcement learning (DRL) techniques to facilitate mobile robot\nnavigation through task-based human instruction. By adopting a curriculum that\nmirrors the progressive complexity encountered in human learning, our approach\nsystematically enhances robots' ability to interpret and execute complex\ninstructions over time. We explore the principles of DRL and its synergy with\nICL, demonstrating how this combination not only improves training efficiency\nbut also equips mobile robots with the generalization capability required for\nnavigating through dynamic indoor environments. Empirical results indicate that\nrobots trained with our ICL-enhanced DRL framework outperform those trained\nwithout curriculum learning, highlighting the benefits of structured learning\nprogressions in robotic training.",
      "tldr_zh": "该论文探讨了将增量课程学习 (ICL) 与深度强化学习 (DRL) 相结合的方法，以帮助移动机器人通过基于任务的人类指令进行导航。研究采用模仿人类学习渐进复杂性的课程框架，系统提升机器人解释和执行复杂指令的能力，同时提高训练效率和在动态室内环境的泛化性能。实验结果显示，使用 ICL 增强的 DRL 框架训练的机器人比无课程学习的基准模型表现更优越，突出了结构化学习进度的实际益处。",
      "categories": [
        "cs.RO",
        "cs.AI"
      ],
      "primary_category": "cs.RO",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2412.19159v1",
      "published_date": "2024-12-26 10:38:40 UTC",
      "updated_date": "2024-12-26 10:38:40 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-21T17:52:14.257029"
    },
    {
      "arxiv_id": "2412.19152v1",
      "title": "To Predict or Not To Predict? Proportionally Masked Autoencoders for Tabular Data Imputation",
      "title_zh": "翻译失败",
      "authors": [
        "Jungkyu Kim",
        "Kibok Lee",
        "Taeyoung Park"
      ],
      "abstract": "Masked autoencoders (MAEs) have recently demonstrated effectiveness in\ntabular data imputation. However, due to the inherent heterogeneity of tabular\ndata, the uniform random masking strategy commonly used in MAEs can disrupt the\ndistribution of missingness, leading to suboptimal performance. To address\nthis, we propose a proportional masking strategy for MAEs. Specifically, we\nfirst compute the statistics of missingness based on the observed proportions\nin the dataset, and then generate masks that align with these statistics,\nensuring that the distribution of missingness is preserved after masking.\nFurthermore, we argue that simple MLP-based token mixing offers competitive or\noften superior performance compared to attention mechanisms while being more\ncomputationally efficient, especially in the tabular domain with the inherent\nheterogeneity. Experimental results validate the effectiveness of the proposed\nproportional masking strategy across various missing data patterns in tabular\ndatasets. Code is available at: \\url{https://github.com/normal-kim/PMAE}.",
      "tldr_zh": "本研究针对 Masked Autoencoders (MAEs) 在表格数据插值中的问题，指出统一随机 masking 策略会破坏 missingness 分布，从而影响性能。作者提出 proportional masking strategy，通过计算数据集的 missingness 统计信息并生成与之对齐的 masks，确保 masking 后保持原分布。相比之下，简单的 MLP-based token mixing 机制在计算效率上优于 attention mechanisms，尤其适合异构的表格数据领域。实验结果验证了该策略在各种 missing data patterns 中的有效性，并提供了开源代码。",
      "categories": [
        "cs.LG",
        "cs.AI",
        "stat.ML"
      ],
      "primary_category": "cs.LG",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2412.19152v1",
      "published_date": "2024-12-26 10:12:08 UTC",
      "updated_date": "2024-12-26 10:12:08 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-21T17:52:26.463106"
    },
    {
      "arxiv_id": "2412.19146v1",
      "title": "AskChart: Universal Chart Understanding through Textual Enhancement",
      "title_zh": "翻译失败",
      "authors": [
        "Xudong Yang",
        "Yifan Wu",
        "Yizhang Zhu",
        "Nan Tang",
        "Yuyu Luo"
      ],
      "abstract": "Chart understanding tasks such as ChartQA and Chart-to-Text involve\nautomatically extracting and interpreting key information from charts, enabling\nusers to query or convert visual data into structured formats. State-of-the-art\napproaches primarily focus on visual cues from chart images, failing to\nexplicitly incorporate rich textual information (e.g., data labels and axis\nlabels) embedded within the charts. This textual information is vital for\nintuitive human comprehension and interpretation of charts. Moreover, existing\nmodels are often large and computationally intensive, limiting their practical\napplicability. In this paper, we introduce AskChart, a universal model that\nexplicitly integrates both textual and visual cues from charts using a Mixture\nof Experts (MoE) architecture. AskChart facilitates the learning of enhanced\nvisual-textual representations of charts for effectively handling multiple\nchart understanding tasks, while maintaining a smaller model size. To capture\nthe synergy between visual and textual modalities, we curate a large-scale\ndataset named ChartBank with about 7.5M data samples, which helps align textual\nand visual information and facilitates the extraction of visual entities and\ntext. To effectively train AskChart, we design a three-stage training strategy\nto align visual and textual modalities for learning robust visual-textual\nrepresentations and optimizing the learning of the MoE layer. Extensive\nexperiments across five datasets demonstrate the significant performance gains\nof AskChart in four chart understanding tasks. Remarkably, AskChart with 4.6B\nparameters outperforms state-of-the-art models with 13B parameters by 68.3% in\nOpen-ended ChartQA and 49.2% in Chart-to-Text tasks, while achieving comparable\nperformance in ChartQA and Chart-to-Table tasks.",
      "tldr_zh": "本论文提出 AskChart，一种通用图表理解模型，通过显式整合图表中的文本信息（如数据标签和轴标签）与视觉线索，利用 Mixture of Experts (MoE) 架构来提升多任务处理能力，同时保持较小模型规模。研究者构建了大规模数据集 ChartBank（约7.5M样本）并设计三阶段训练策略，以对齐视觉和文本模式，学习稳健的视觉-文本表示。实验在五个数据集上显示，AskChart在四个图表理解任务中显著提升性能，其4.6B参数模型在Open-ended ChartQA任务上比13B参数的SOTA模型高68.3%，在Chart-to-Text任务上高49.2%，并在ChartQA和Chart-to-Table任务上表现出可比性能。",
      "categories": [
        "cs.CV",
        "cs.AI"
      ],
      "primary_category": "cs.CV",
      "comment": "23 pages, 12 figures, 14 tables",
      "pdf_url": "http://arxiv.org/pdf/2412.19146v1",
      "published_date": "2024-12-26 09:59:43 UTC",
      "updated_date": "2024-12-26 09:59:43 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-21T17:52:41.303870"
    },
    {
      "arxiv_id": "2412.19140v1",
      "title": "SILC-EFSA: Self-aware In-context Learning Correction for Entity-level Financial Sentiment Analysis",
      "title_zh": "翻译失败",
      "authors": [
        "Senbin Zhu",
        "Chenyuan He",
        "Hongde Liu",
        "Pengcheng Dong",
        "Hanjie Zhao",
        "Yuchen Yan",
        "Yuxiang Jia",
        "Hongying Zan",
        "Min Peng"
      ],
      "abstract": "In recent years, fine-grained sentiment analysis in finance has gained\nsignificant attention, but the scarcity of entity-level datasets remains a key\nchallenge. To address this, we have constructed the largest English and Chinese\nfinancial entity-level sentiment analysis datasets to date. Building on this\nfoundation, we propose a novel two-stage sentiment analysis approach called\nSelf-aware In-context Learning Correction (SILC). The first stage involves\nfine-tuning a base large language model to generate pseudo-labeled data\nspecific to our task. In the second stage, we train a correction model using a\nGNN-based example retriever, which is informed by the pseudo-labeled data. This\ntwo-stage strategy has allowed us to achieve state-of-the-art performance on\nthe newly constructed datasets, advancing the field of financial sentiment\nanalysis. In a case study, we demonstrate the enhanced practical utility of our\ndata and methods in monitoring the cryptocurrency market. Our datasets and code\nare available at https://github.com/NLP-Bin/SILC-EFSA.",
      "tldr_zh": "这篇论文构建了迄今为止最大的英文和中文金融实体级情感分析数据集，以解决数据集稀缺的挑战，并提出了SILC（Self-aware In-context Learning Correction）这一新颖的两阶段方法。SILC的第一阶段通过微调基础大型语言模型生成特定任务的伪标签数据，第二阶段则使用基于GNN的示例检索器训练修正模型，以提升情感分析的准确性。该方法在新建数据集上实现了state-of-the-art性能，并在加密货币市场监控的案例研究中展示了实际应用。数据集和代码已在GitHub上公开。",
      "categories": [
        "cs.CL",
        "cs.AI",
        "cs.CE"
      ],
      "primary_category": "cs.CL",
      "comment": "This paper is to be published in the Proceedings of the 31st\n  International Conference on Computational Linguistics (COLING 2025)",
      "pdf_url": "http://arxiv.org/pdf/2412.19140v1",
      "published_date": "2024-12-26 09:53:01 UTC",
      "updated_date": "2024-12-26 09:53:01 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-21T17:54:44.764648"
    },
    {
      "arxiv_id": "2412.19139v2",
      "title": "PlanLLM: Video Procedure Planning with Refinable Large Language Models",
      "title_zh": "翻译失败",
      "authors": [
        "Dejie Yang",
        "Zijing Zhao",
        "Yang Liu"
      ],
      "abstract": "Video procedure planning, i.e., planning a sequence of action steps given the\nvideo frames of start and goal states, is an essential ability for embodied AI.\nRecent works utilize Large Language Models (LLMs) to generate enriched action\nstep description texts to guide action step decoding. Although LLMs are\nintroduced, these methods decode the action steps into a closed-set of one-hot\nvectors, limiting the model's capability of generalizing to new steps or tasks.\nAdditionally, fixed action step descriptions based on world-level commonsense\nmay contain noise in specific instances of visual states. In this paper, we\npropose PlanLLM, a cross-modal joint learning framework with LLMs for video\nprocedure planning. We propose an LLM-Enhanced Planning module which fully uses\nthe generalization ability of LLMs to produce free-form planning output and to\nenhance action step decoding. We also propose Mutual Information Maximization\nmodule to connect world-level commonsense of step descriptions and\nsample-specific information of visual states, enabling LLMs to employ the\nreasoning ability to generate step sequences. With the assistance of LLMs, our\nmethod can both closed-set and open vocabulary procedure planning tasks. Our\nPlanLLM achieves superior performance on three benchmarks, demonstrating the\neffectiveness of our designs.",
      "tldr_zh": "这篇论文提出了PlanLLM，一种基于Large Language Models (LLMs)的跨模态联合学习框架，用于视频程序规划，即根据起始和目标视频帧生成动作序列。框架包括LLM-Enhanced Planning模块，利用LLMs的泛化能力产生自由形式的规划输出，并增强动作解码；以及Mutual Information Maximization模块，连接世界级常识和视觉状态的具体信息，以减少噪声并提升序列生成准确性。该方法支持封闭集和开放词汇任务，并在三个基准测试中表现出色，证明了其有效性。",
      "categories": [
        "cs.CV",
        "cs.AI",
        "cs.LG",
        "cs.MM"
      ],
      "primary_category": "cs.CV",
      "comment": "accepted to AAAI2025",
      "pdf_url": "http://arxiv.org/pdf/2412.19139v2",
      "published_date": "2024-12-26 09:51:05 UTC",
      "updated_date": "2025-01-07 01:50:11 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-21T17:53:03.130166"
    },
    {
      "arxiv_id": "2412.19133v1",
      "title": "A Rhetorical Relations-Based Framework for Tailored Multimedia Document Summarization",
      "title_zh": "翻译失败",
      "authors": [
        "Azze-Eddine Maredj",
        "Madjid Sadallah"
      ],
      "abstract": "In the rapidly evolving landscape of digital content, the task of summarizing\nmultimedia documents, which encompass textual, visual, and auditory elements,\npresents intricate challenges. These challenges include extracting pertinent\ninformation from diverse formats, maintaining the structural integrity and\nsemantic coherence of the original content, and generating concise yet\ninformative summaries. This paper introduces a novel framework for multimedia\ndocument summarization that capitalizes on the inherent structure of the\ndocument to craft coherent and succinct summaries. Central to this framework is\nthe incorporation of a rhetorical structure for structural analysis, augmented\nby a graph-based representation to facilitate the extraction of pivotal\ninformation. Weighting algorithms are employed to assign significance values to\ndocument units, thereby enabling effective ranking and selection of relevant\ncontent. Furthermore, the framework is designed to accommodate user preferences\nand time constraints, ensuring the production of personalized and contextually\nrelevant summaries. The summarization process is elaborately delineated,\nencompassing document specification, graph construction, unit weighting, and\nsummary extraction, supported by illustrative examples and algorithmic\nelucidation. This proposed framework represents a significant advancement in\nautomatic summarization, with broad potential applications across multimedia\ndocument processing, promising transformative impacts in the field.",
      "tldr_zh": "这篇论文针对多媒体文档摘要面临的挑战（如从文本、视觉和听觉元素中提取信息并保持语义连贯性），提出一个基于rhetorical relations的框架，用于生成连贯且简洁的摘要。该框架通过rhetorical structure进行结构分析，结合graph-based representation提取关键信息，并采用weighting algorithms对文档单位进行重要性评估和排名，以支持个性化摘要的生成。框架还考虑用户偏好和时间限制，整个过程包括文档规格化、图构建、单位加权和摘要提取，最终有望在多媒体文档处理领域实现重大进展。",
      "categories": [
        "cs.MM",
        "cs.AI",
        "cs.HC"
      ],
      "primary_category": "cs.MM",
      "comment": "10 pages, preprint",
      "pdf_url": "http://arxiv.org/pdf/2412.19133v1",
      "published_date": "2024-12-26 09:29:59 UTC",
      "updated_date": "2024-12-26 09:29:59 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-21T17:53:14.933955"
    },
    {
      "arxiv_id": "2412.19124v1",
      "title": "Evaluating Self-Supervised Learning in Medical Imaging: A Benchmark for Robustness, Generalizability, and Multi-Domain Impact",
      "title_zh": "翻译失败",
      "authors": [
        "Valay Bundele",
        "Oğuz Ata Çal",
        "Bora Kargi",
        "Karahan Sarıtaş",
        "Kıvanç Tezören",
        "Zohreh Ghaderi",
        "Hendrik Lensch"
      ],
      "abstract": "Self-supervised learning (SSL) has emerged as a promising paradigm in medical\nimaging, addressing the chronic challenge of limited labeled data in healthcare\nsettings. While SSL has shown impressive results, existing studies in the\nmedical domain are often limited in scope, focusing on specific datasets or\nmodalities, or evaluating only isolated aspects of model performance. This\nfragmented evaluation approach poses a significant challenge, as models\ndeployed in critical medical settings must not only achieve high accuracy but\nalso demonstrate robust performance and generalizability across diverse\ndatasets and varying conditions. To address this gap, we present a\ncomprehensive evaluation of SSL methods within the medical domain, with a\nparticular focus on robustness and generalizability. Using the MedMNIST dataset\ncollection as a standardized benchmark, we evaluate 8 major SSL methods across\n11 different medical datasets. Our study provides an in-depth analysis of model\nperformance in both in-domain scenarios and the detection of\nout-of-distribution (OOD) samples, while exploring the effect of various\ninitialization strategies, model architectures, and multi-domain pre-training.\nWe further assess the generalizability of SSL methods through cross-dataset\nevaluations and the in-domain performance with varying label proportions (1%,\n10%, and 100%) to simulate real-world scenarios with limited supervision. We\nhope this comprehensive benchmark helps practitioners and researchers make more\ninformed decisions when applying SSL methods to medical applications.",
      "tldr_zh": "本研究评估了自监督学习 (SSL) 在医疗成像中的表现，针对现有研究的局限性（如数据集单一或性能评估不全面），提出一个全面基准，聚焦于模型的鲁棒性 (robustness)、泛化性 (generalizability) 和多领域影响。研究者使用 MedMNIST 数据集集合作为标准基准，评估了 8 种主要 SSL 方法在 11 个不同医疗数据集上的性能，包括领域内场景、out-of-distribution (OOD) 样本检测、不同初始化策略、模型架构和多领域预训练。最终，通过跨数据集评估和不同标签比例 (1%、10%、100%) 的模拟实验，论文提供深入分析，帮助研究者和从业者更有效地将 SSL 应用于医疗场景。",
      "categories": [
        "cs.CV",
        "cs.AI",
        "cs.LG"
      ],
      "primary_category": "cs.CV",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2412.19124v1",
      "published_date": "2024-12-26 08:51:56 UTC",
      "updated_date": "2024-12-26 08:51:56 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-21T17:53:27.234206"
    },
    {
      "arxiv_id": "2412.19114v1",
      "title": "Discrete vs. Continuous Trade-offs for Generative Models",
      "title_zh": "翻译失败",
      "authors": [
        "Jathin Korrapati",
        "Tanish Baranwal",
        "Rahul Shah"
      ],
      "abstract": "This work explores the theoretical and practical foundations of denoising\ndiffusion probabilistic models (DDPMs) and score-based generative models, which\nleverage stochastic processes and Brownian motion to model complex data\ndistributions. These models employ forward and reverse diffusion processes\ndefined through stochastic differential equations (SDEs) to iteratively add and\nremove noise, enabling high-quality data generation. By analyzing the\nperformance bounds of these models, we demonstrate how score estimation errors\npropagate through the reverse process and bound the total variation distance\nusing discrete Girsanov transformations, Pinsker's inequality, and the data\nprocessing inequality (DPI) for an information theoretic lens.",
      "tldr_zh": "本研究探讨了生成模型中离散与连续权衡的理论与实践基础，特别针对 denoising diffusion probabilistic models (DDPMs) 和 score-based generative models，这些模型利用随机过程和 Brownian motion 通过 stochastic differential equations (SDEs) 定义的前向和反向扩散过程来添加噪声并实现高质量数据生成。论文分析了 score estimation errors 在反向过程中的传播效应，并通过 discrete Girsanov transformations、Pinsker's inequality 和 data processing inequality (DPI) 从信息论视角界定 total variation distance 的性能边界。结果表明，这种分析框架有助于理解模型的误差传播机制，从而优化生成模型在复杂数据分布上的表现。",
      "categories": [
        "cs.LG",
        "cs.AI",
        "cs.IT",
        "cs.NA",
        "math.IT",
        "math.NA",
        "Primary 68T07, Secondary 60H10, 94A15, 68Q87"
      ],
      "primary_category": "cs.LG",
      "comment": "16 pages, 6 figures, includes theoretical analysis, experimental\n  results, and proofs of key results",
      "pdf_url": "http://arxiv.org/pdf/2412.19114v1",
      "published_date": "2024-12-26 08:14:27 UTC",
      "updated_date": "2024-12-26 08:14:27 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-21T17:53:39.229270"
    },
    {
      "arxiv_id": "2412.19108v2",
      "title": "Graph Mixture of Experts and Memory-augmented Routers for Multivariate Time Series Anomaly Detection",
      "title_zh": "图混合专家和记忆增强路由器用于多变量时间序列异常检测",
      "authors": [
        "Xiaoyu Huang",
        "Weidong Chen",
        "Bo Hu",
        "Zhendong Mao"
      ],
      "abstract": "Multivariate time series (MTS) anomaly detection is a critical task that\ninvolves identifying abnormal patterns or events in data that consist of\nmultiple interrelated time series. In order to better model the complex\ninterdependence between entities and the various inherent characteristics of\neach entity, the GNN based methods are widely adopted by existing methods. In\neach layer of GNN, node features aggregate information from their neighboring\nnodes to update their information. In doing so, from shallow layer to deep\nlayer in GNN, original individual node features continue to be weakened and\nmore structural information,i.e., from short-distance neighborhood to\nlong-distance neighborhood, continues to be enhanced. However, research to date\nhas largely ignored the understanding of how hierarchical graph information is\nrepresented and their characteristics that can benefit anomaly detection.\nExisting methods simply leverage the output from the last layer of GNN for\nanomaly estimation while neglecting the essential information contained in the\nintermediate GNN layers. To address such limitations, in this paper, we propose\na Graph Mixture of Experts (Graph-MoE) network for multivariate time series\nanomaly detection, which incorporates the mixture of experts (MoE) module to\nadaptively represent and integrate hierarchical multi-layer graph information\ninto entity representations. It is worth noting that our Graph-MoE can be\nintegrated into any GNN-based MTS anomaly detection method in a plug-and-play\nmanner. In addition, the memory-augmented routers are proposed in this paper to\ncapture the correlation temporal information in terms of the global historical\nfeatures of MTS to adaptively weigh the obtained entity representations to\nachieve successful anomaly estimation. Extensive experiments on five\nchallenging datasets prove the superiority of our approach and each proposed\nmodule.",
      "tldr_zh": "该研究针对多变量时间序列 (Multivariate Time Series, MTS) 异常检测，提出 Graph Mixture of Experts (Graph-MoE) 网络，通过 Mixture of Experts (MoE) 模块自适应地表示和整合 GNN 的多层层次化图信息，以更好地捕捉实体间的复杂依赖关系。Graph-MoE 可以即插即用地整合到任何 GNN-based MTS 异常检测方法中，同时引入 memory-augmented routers 来利用全局历史特征的关联时间信息，对实体表示进行权衡，从而提升异常估计的准确性。在五个挑战性数据集上的广泛实验证明，该方法比现有方法表现出色，每个模块都贡献显著。",
      "categories": [
        "cs.LG",
        "cs.AI"
      ],
      "primary_category": "cs.LG",
      "comment": "Accepted by AAAI 2025",
      "pdf_url": "http://arxiv.org/pdf/2412.19108v2",
      "published_date": "2024-12-26 07:49:51 UTC",
      "updated_date": "2024-12-30 13:10:06 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-21T17:53:51.606234"
    },
    {
      "arxiv_id": "2412.19092v1",
      "title": "TrajGEOS: Trajectory Graph Enhanced Orientation-based Sequential Network for Mobility Prediction",
      "title_zh": "翻译失败",
      "authors": [
        "Zhaoping Hu",
        "Zongyuan Huang",
        "Jinming Yang",
        "Tao Yang",
        "Yaohui Jin",
        "Yanyan Xu"
      ],
      "abstract": "Human mobility studies how people move to access their needed resources and\nplays a significant role in urban planning and location-based services. As a\nparamount task of human mobility modeling, next location prediction is\nchallenging because of the diversity of users' historical trajectories that\ngives rise to complex mobility patterns and various contexts. Deep sequential\nmodels have been widely used to predict the next location by leveraging the\ninherent sequentiality of trajectory data. However, they do not fully leverage\nthe relationship between locations and fail to capture users' multi-level\npreferences. This work constructs a trajectory graph from users' historical\ntraces and proposes a \\textbf{Traj}ectory \\textbf{G}raph \\textbf{E}nhanced\n\\textbf{O}rientation-based \\textbf{S}equential network (TrajGEOS) for\nnext-location prediction tasks. TrajGEOS introduces hierarchical graph\nconvolution to capture location and user embeddings. Such embeddings consider\nnot only the contextual feature of locations but also the relation between\nthem, and serve as additional features in downstream modules. In addition, we\ndesign an orientation-based module to learn users' mid-term preferences from\nsequential modeling modules and their recent trajectories. Extensive\nexperiments on three real-world LBSN datasets corroborate the value of graph\nand orientation-based modules and demonstrate that TrajGEOS outperforms the\nstate-of-the-art methods on the next location prediction task.",
      "tldr_zh": "该研究针对人类移动性建模中的下一个位置预测问题，指出现有深度序列模型未能充分利用位置关系和用户多级偏好，从而提出TrajGEOS模型，该模型通过构建轨迹图并应用分层图卷积来捕获位置及用户嵌入，作为下游模块的额外特征。TrajGEOS还设计了一个基于方向的模块，从序列建模和最近轨迹中学习用户的中期偏好，以提升预测准确性。在三个真实世界LBSN数据集上的实验证明，该模型优于最先进方法，验证了轨迹图和基于方向模块的价值。",
      "categories": [
        "cs.AI"
      ],
      "primary_category": "cs.AI",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2412.19092v1",
      "published_date": "2024-12-26 07:18:38 UTC",
      "updated_date": "2024-12-26 07:18:38 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-21T17:54:03.593738"
    },
    {
      "arxiv_id": "2412.19088v1",
      "title": "Integrating Artificial Open Generative Artificial Intelligence into Software Supply Chain Security",
      "title_zh": "翻译失败",
      "authors": [
        "Vasileios Alevizos",
        "George A Papakostas",
        "Akebu Simasiku",
        "Dimitra Malliarou",
        "Antonis Messinis",
        "Sabrina Edralin",
        "Clark Xu",
        "Zongliang Yue"
      ],
      "abstract": "While new technologies emerge, human errors always looming. Software supply\nchain is increasingly complex and intertwined, the security of a service has\nbecome paramount to ensuring the integrity of products, safeguarding data\nprivacy, and maintaining operational continuity. In this work, we conducted\nexperiments on the promising open Large Language Models (LLMs) into two main\nsoftware security challenges: source code language errors and deprecated code,\nwith a focus on their potential to replace conventional static and dynamic\nsecurity scanners that rely on predefined rules and patterns. Our findings\nsuggest that while LLMs present some unexpected results, they also encounter\nsignificant limitations, particularly in memory complexity and the management\nof new and unfamiliar data patterns. Despite these challenges, the proactive\napplication of LLMs, coupled with extensive security databases and continuous\nupdates, holds the potential to fortify Software Supply Chain (SSC) processes\nagainst emerging threats.",
      "tldr_zh": "该研究探讨了将开源生成式人工智能（如Large Language Models, LLMs）整合到软件供应链（Software Supply Chain, SSC）安全中的潜力，针对源代码语言错误和过时代码等挑战进行实验。研究方法包括测试LLMs是否能取代依赖预定义规则的传统静态和动态安全扫描器。结果显示，LLMs表现出一些意外效果，但面临内存复杂性和处理新数据模式等显著限制。尽管如此，通过结合LLMs与广泛的安全数据库及持续更新，该方法有望加强SSC对抗新兴威胁。",
      "categories": [
        "cs.CR",
        "cs.AI",
        "cs.ET"
      ],
      "primary_category": "cs.CR",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2412.19088v1",
      "published_date": "2024-12-26 07:03:55 UTC",
      "updated_date": "2024-12-26 07:03:55 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-21T17:54:56.588046"
    },
    {
      "arxiv_id": "2412.19064v1",
      "title": "Hierarchical Multi-agent Meta-Reinforcement Learning for Cross-channel Bidding",
      "title_zh": "翻译失败",
      "authors": [
        "Shenghong He",
        "Chao Yu"
      ],
      "abstract": "Real-time bidding (RTB) plays a pivotal role in online advertising\necosystems. Advertisers employ strategic bidding to optimize their advertising\nimpact while adhering to various financial constraints, such as the\nreturn-on-investment (ROI) and cost-per-click (CPC). Primarily focusing on\nbidding with fixed budget constraints, traditional approaches cannot\neffectively manage the dynamic budget allocation problem where the goal is to\nachieve global optimization of bidding performance across multiple channels\nwith a shared budget. In this paper, we propose a hierarchical multi-agent\nreinforcement learning framework for multi-channel bidding optimization. In\nthis framework, the top-level strategy applies a CPC constrained diffusion\nmodel to dynamically allocate budgets among the channels according to their\ndistinct features and complex interdependencies, while the bottom-level\nstrategy adopts a state-action decoupled actor-critic method to address the\nproblem of extrapolation errors in offline learning caused by\nout-of-distribution actions and a context-based meta-channel knowledge learning\nmethod to improve the state representation capability of the policy based on\nthe shared knowledge among different channels. Comprehensive experiments\nconducted on a large scale real-world industrial dataset from the Meituan ad\nbidding platform demonstrate that our method achieves a state-of-the-art\nperformance.",
      "tldr_zh": "本文提出一个分层多智能体元强化学习框架，用于解决实时竞价(RTB)中跨渠道竞价的动态预算分配问题，旨在优化广告影响同时遵守 ROI 和 CPC 等财务约束。顶层策略采用 CPC 约束的扩散模型，根据渠道特征和相互依赖动态分配共享预算；底层策略则使用状态-动作解耦的 Actor-Critic 方法处理离线学习中的外推错误，并通过基于上下文的 meta-channel 知识学习方法提升状态表示能力。实验在 Meituan 广告平台的真实数据集上显示，该框架实现了最先进性能。",
      "categories": [
        "cs.AI"
      ],
      "primary_category": "cs.AI",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2412.19064v1",
      "published_date": "2024-12-26 05:26:30 UTC",
      "updated_date": "2024-12-26 05:26:30 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-21T17:55:09.147146"
    },
    {
      "arxiv_id": "2412.19043v1",
      "title": "Indonesian-English Code-Switching Speech Synthesizer Utilizing Multilingual STEN-TTS and Bert LID",
      "title_zh": "翻译失败",
      "authors": [
        "Ahmad Alfani Handoyo",
        "Chung Tran",
        "Dessi Puji Lestari",
        "Sakriani Sakti"
      ],
      "abstract": "Multilingual text-to-speech systems convert text into speech across multiple\nlanguages. In many cases, text sentences may contain segments in different\nlanguages, a phenomenon known as code-switching. This is particularly common in\nIndonesia, especially between Indonesian and English. Despite its significance,\nno research has yet developed a multilingual TTS system capable of handling\ncode-switching between these two languages. This study addresses\nIndonesian-English code-switching in STEN-TTS. Key modifications include adding\na language identification component to the text-to-phoneme conversion using\nfinetuned BERT for per-word language identification, as well as removing\nlanguage embedding from the base model. Experimental results demonstrate that\nthe code-switching model achieves superior naturalness and improved speech\nintelligibility compared to the Indonesian and English baseline STEN-TTS\nmodels.",
      "tldr_zh": "本研究开发了一种处理印尼语和英语代码切换（code-switching）的多语言文本到语音（TTS）系统，利用Multilingual STEN-TTS框架。关键改进包括添加基于微调BERT的语言识别（Bert LID）组件，用于每个单词的语言标识，以及从基础模型中移除语言嵌入，以更好地处理混合语言文本。实验结果显示，该系统在自然度和语音可懂度上均优于印尼语和英语基线STEN-TTS模型，为代码切换场景下的语音合成提供了有效解决方案。",
      "categories": [
        "cs.CL",
        "cs.AI",
        "cs.SD",
        "eess.AS"
      ],
      "primary_category": "cs.CL",
      "comment": "Accepted at O-COCOSDA 2024",
      "pdf_url": "http://arxiv.org/pdf/2412.19043v1",
      "published_date": "2024-12-26 03:37:40 UTC",
      "updated_date": "2024-12-26 03:37:40 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-21T17:55:19.685973"
    },
    {
      "arxiv_id": "2412.19037v2",
      "title": "CL-Attack: Textual Backdoor Attacks via Cross-Lingual Triggers",
      "title_zh": "CL-Attack：通过跨语言触发器的文本后门攻击",
      "authors": [
        "Jingyi Zheng",
        "Tianyi Hu",
        "Tianshuo Cong",
        "Xinlei He"
      ],
      "abstract": "Backdoor attacks significantly compromise the security of large language\nmodels by triggering them to output specific and controlled content. Currently,\ntriggers for textual backdoor attacks fall into two categories: fixed-token\ntriggers and sentence-pattern triggers. However, the former are typically easy\nto identify and filter, while the latter, such as syntax and style, do not\napply to all original samples and may lead to semantic shifts. In this paper,\ninspired by cross-lingual (CL) prompts of LLMs in real-world scenarios, we\npropose a higher-dimensional trigger method at the paragraph level, namely\nCL-attack. CL-attack injects the backdoor by using texts with specific\nstructures that incorporate multiple languages, thereby offering greater\nstealthiness and universality compared to existing backdoor attack techniques.\nExtensive experiments on different tasks and model architectures demonstrate\nthat CL-attack can achieve nearly 100% attack success rate with a low poisoning\nrate in both classification and generation tasks. We also empirically show that\nthe CL-attack is more robust against current major defense methods compared to\nbaseline backdoor attacks. Additionally, to mitigate CL-attack, we further\ndevelop a new defense called TranslateDefense, which can partially mitigate the\nimpact of CL-attack.",
      "tldr_zh": "该论文提出 CL-Attack，一种基于跨语言触发器（cross-lingual triggers）的文本后门攻击（textual backdoor attacks）方法，通过在段落级别注入包含多种语言的特定结构文本，提高攻击的隐蔽性和通用性，以克服现有固定标记触发器（fixed-token triggers）和句子模式触发器（sentence-pattern triggers）的局限性。实验结果显示，CL-Attack 在分类和生成任务中以低毒性率（low poisoning rate）实现近100%的攻击成功率（attack success rate），并比基线攻击更robust地抵抗当前主要防御方法。为了缓解 CL-Attack 的影响，论文还开发了 TranslateDefense，这是一种能部分缓解攻击的新防御策略。",
      "categories": [
        "cs.CR",
        "cs.AI"
      ],
      "primary_category": "cs.CR",
      "comment": "The paper has been accepted to AAAI 2025",
      "pdf_url": "http://arxiv.org/pdf/2412.19037v2",
      "published_date": "2024-12-26 03:13:03 UTC",
      "updated_date": "2025-03-31 04:48:28 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-21T17:55:33.165766"
    },
    {
      "arxiv_id": "2412.19031v1",
      "title": "Repository Structure-Aware Training Makes SLMs Better Issue Resolver",
      "title_zh": "仓库结构感知训练使 SLMs 成为更好的问题解决器",
      "authors": [
        "Zexiong Ma",
        "Shengnan An",
        "Zeqi Lin",
        "Yanzhen Zou",
        "Bing Xie"
      ],
      "abstract": "Language models have been applied to various software development tasks, but\nthe performance varies according to the scale of the models. Large Language\nModels (LLMs) outperform Small Language Models (SLMs) in complex tasks like\nrepository-level issue resolving, but raise concerns about privacy and cost. In\ncontrast, SLMs are more accessible but under-perform in complex tasks. In this\npaper, we introduce ReSAT (Repository Structure-Aware Training), construct\ntraining data based on a large number of issues and corresponding pull requests\nfrom open-source communities to enhance the model's understanding of repository\nstructure and issue resolving ability. We construct two types of training data:\n(1) localization training data, a multi-level progressive localization data to\nimprove code understanding and localization capability; (2) code edit training\ndata, which improves context-based code editing capability. The evaluation\nresults on SWE-Bench-verified and RepoQA demonstrate that ReSAT effectively\nenhances SLMs' issue-resolving and repository-level long-context understanding\ncapabilities.",
      "tldr_zh": "本研究发现，大语言模型(LLMs)在仓库级问题解决等复杂软件开发任务中优于小语言模型(SLMs)，但SLMs更具隐私和成本优势。为提升SLMs的性能，论文提出ReSAT(Repository Structure-Aware Training)方法，通过构建基于开源社区问题的训练数据，包括多级渐进的localization training data（改善代码理解和定位能力）和code edit training data（增强基于上下文的代码编辑能力）。实验结果显示，ReSAT显著提高了SLMs在SWE-Bench-verified和RepoQA数据集上的问题解决能力和仓库级长上下文理解能力。",
      "categories": [
        "cs.SE",
        "cs.AI"
      ],
      "primary_category": "cs.SE",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2412.19031v1",
      "published_date": "2024-12-26 03:01:32 UTC",
      "updated_date": "2024-12-26 03:01:32 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-21T17:55:43.867989"
    },
    {
      "arxiv_id": "2412.19026v1",
      "title": "Modality-Projection Universal Model for Comprehensive Full-Body Medical Imaging Segmentation",
      "title_zh": "翻译失败",
      "authors": [
        "Yixin Chen",
        "Lin Gao",
        "Yajuan Gao",
        "Rui Wang",
        "Jingge Lian",
        "Xiangxi Meng",
        "Yanhua Duan",
        "Leiying Chai",
        "Hongbin Han",
        "Zhaoping Cheng",
        "Zhaoheng Xie"
      ],
      "abstract": "The integration of deep learning in medical imaging has shown great promise\nfor enhancing diagnostic, therapeutic, and research outcomes. However, applying\nuniversal models across multiple modalities remains challenging due to the\ninherent variability in data characteristics. This study aims to introduce and\nevaluate a Modality Projection Universal Model (MPUM). MPUM employs a novel\nmodality-projection strategy, which allows the model to dynamically adjust its\nparameters to optimize performance across different imaging modalities. The\nMPUM demonstrated superior accuracy in identifying anatomical structures,\nenabling precise quantification for improved clinical decision-making. It also\nidentifies metabolic associations within the brain-body axis, advancing\nresearch on brain-body physiological correlations. Furthermore, MPUM's unique\ncontroller-based convolution layer enables visualization of saliency maps\nacross all network layers, significantly enhancing the model's\ninterpretability.",
      "tldr_zh": "这篇论文引入了 Modality-Projection Universal Model (MPUM)，一种新型框架，通过 modality-projection 策略动态调整模型参数，以适应多种医疗成像模态，实现全面的全身图像分割。MPUM 在识别解剖结构和精确量化方面表现出色，提升了临床决策的准确性，并能识别脑体轴内的代谢关联，促进脑体生理相关研究。该模型还利用 controller-based convolution layer 生成 saliency maps，提升了整体的可解释性。",
      "categories": [
        "eess.IV",
        "cs.AI",
        "cs.CV"
      ],
      "primary_category": "eess.IV",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2412.19026v1",
      "published_date": "2024-12-26 02:23:27 UTC",
      "updated_date": "2024-12-26 02:23:27 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-21T17:55:56.651091"
    },
    {
      "arxiv_id": "2412.19021v1",
      "title": "Relation-aware Hierarchical Prompt for Open-vocabulary Scene Graph Generation",
      "title_zh": "翻译失败",
      "authors": [
        "Tao Liu",
        "Rongjie Li",
        "Chongyu Wang",
        "Xuming He"
      ],
      "abstract": "Open-vocabulary Scene Graph Generation (OV-SGG) overcomes the limitations of\nthe closed-set assumption by aligning visual relationship representations with\nopen-vocabulary textual representations. This enables the identification of\nnovel visual relationships, making it applicable to real-world scenarios with\ndiverse relationships. However, existing OV-SGG methods are constrained by\nfixed text representations, limiting diversity and accuracy in image-text\nalignment. To address these challenges, we propose the Relation-Aware\nHierarchical Prompting (RAHP) framework, which enhances text representation by\nintegrating subject-object and region-specific relation information. Our\napproach utilizes entity clustering to address the complexity of relation\ntriplet categories, enabling the effective integration of subject-object\ninformation. Additionally, we utilize a large language model (LLM) to generate\ndetailed region-aware prompts, capturing fine-grained visual interactions and\nimproving alignment between visual and textual modalities. RAHP also introduces\na dynamic selection mechanism within Vision-Language Models (VLMs), which\nadaptively selects relevant text prompts based on the visual content, reducing\nnoise from irrelevant prompts. Extensive experiments on the Visual Genome and\nOpen Images v6 datasets demonstrate that our framework consistently achieves\nstate-of-the-art performance, demonstrating its effectiveness in addressing the\nchallenges of open-vocabulary scene graph generation.",
      "tldr_zh": "该论文针对开放词汇场景图生成（OV-SGG）的问题，提出了一种Relation-Aware Hierarchical Prompting (RAHP) 框架，以提升视觉关系与文本表示的对齐精度和多样性。RAHP 通过实体聚类整合主语-宾语信息，并利用大型语言模型 (LLM) 生成细粒度的区域感知提示，捕获视觉互动细节，同时引入动态选择机制在Vision-Language Models (VLMs) 中筛选相关提示，减少噪声干扰。实验在Visual Genome和Open Images v6数据集上显示，该框架实现了state-of-the-art性能，显著提高了OV-SGG的准确性和适用性。",
      "categories": [
        "cs.CV",
        "cs.AI"
      ],
      "primary_category": "cs.CV",
      "comment": "Accepted by AAAI-25",
      "pdf_url": "http://arxiv.org/pdf/2412.19021v1",
      "published_date": "2024-12-26 02:12:37 UTC",
      "updated_date": "2024-12-26 02:12:37 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-21T17:56:07.641191"
    },
    {
      "arxiv_id": "2412.19017v1",
      "title": "Brain Ageing Prediction using Isolation Forest Technique and Residual Neural Network (ResNet)",
      "title_zh": "翻译失败",
      "authors": [
        "Saadat Behzadi",
        "Danial Sharifrazi",
        "Roohallah Alizadehsani",
        "Mojtaba Lotfaliany",
        "Mohammadreza Mohebbi"
      ],
      "abstract": "Brain aging is a complex and dynamic process, leading to functional and\nstructural changes in the brain. These changes could lead to the increased risk\nof neurodegenerative diseases and cognitive decline. Accurate brain-age\nestimation utilizing neuroimaging data has become necessary for detecting\ninitial signs of neurodegeneration. Here, we propose a novel deep learning\napproach using the Residual Neural Network 101 Version 2 (ResNet101V2) model to\npredict brain age from MRI scans. To train, validate and test our proposed\nmodel, we used a large dataset of 2102 images which were selected randomly from\nthe International Consortium for Brain Mapping (ICBM). Next, we applied data\npreprocessing techniques, including normalizing the images and using outlier\ndetection via Isolation Forest method. Then, we evaluated various pre-trained\napproaches (namely: MobileNetV2, ResNet50V2, ResNet101V2, Xception). The\nresults demonstrated that the ResNet101V2 model has higher performance compared\nwith the other models, attaining MAEs of 0.9136 and 0.8242 years for before and\nafter using Isolation Forest process. Our method achieved a high accuracy in\nbrain age estimation in ICBM dataset and it provides a reliable brain age\nprediction.",
      "tldr_zh": "本研究提出了一种利用 Residual Neural Network (ResNet101V2) 模型结合 Isolation Forest 技术，从 MRI 扫描预测脑年龄的方法，以检测神经退行性疾病的早期迹象。研究者使用 International Consortium for Brain Mapping (ICBM) 数据集的 2102 张图像，进行数据预处理（如图像归一化和异常值检测），并与其他模型（如 MobileNetV2、ResNet50V2 和 Xception）进行比较。结果表明，ResNet101V2 在应用 Isolation Forest 后，Mean Absolute Error (MAE) 从 0.9136 降至 0.8242 年，实现了最高性能。该方法为脑年龄估算提供了高准确性和可靠的预测工具。",
      "categories": [
        "eess.IV",
        "cs.AI",
        "cs.CV"
      ],
      "primary_category": "eess.IV",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2412.19017v1",
      "published_date": "2024-12-26 01:49:21 UTC",
      "updated_date": "2024-12-26 01:49:21 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-21T17:56:20.978340"
    },
    {
      "arxiv_id": "2412.19010v1",
      "title": "A theory of appropriateness with applications to generative artificial intelligence",
      "title_zh": "适当性的理论及其在生成式人工智能中的应用",
      "authors": [
        "Joel Z. Leibo",
        "Alexander Sasha Vezhnevets",
        "Manfred Diaz",
        "John P. Agapiou",
        "William A. Cunningham",
        "Peter Sunehag",
        "Julia Haas",
        "Raphael Koster",
        "Edgar A. Duéñez-Guzmán",
        "William S. Isaac",
        "Georgios Piliouras",
        "Stanley M. Bileschi",
        "Iyad Rahwan",
        "Simon Osindero"
      ],
      "abstract": "What is appropriateness? Humans navigate a multi-scale mosaic of interlocking\nnotions of what is appropriate for different situations. We act one way with\nour friends, another with our family, and yet another in the office. Likewise\nfor AI, appropriate behavior for a comedy-writing assistant is not the same as\nappropriate behavior for a customer-service representative. What determines\nwhich actions are appropriate in which contexts? And what causes these\nstandards to change over time? Since all judgments of AI appropriateness are\nultimately made by humans, we need to understand how appropriateness guides\nhuman decision making in order to properly evaluate AI decision making and\nimprove it. This paper presents a theory of appropriateness: how it functions\nin human society, how it may be implemented in the brain, and what it means for\nresponsible deployment of generative AI technology.",
      "tldr_zh": "本论文探讨了“appropriateness”（适当性）的概念，即人类在不同情境中（如与朋友、家人或同事互动）表现出适应性行为的标准，以及这些标准如何随时间变化。作者提出一个理论框架，解释适当性在人类社会中的运作、在大脑中的潜在实现机制，并强调理解人类判断以评估和改进AI决策的重要性。该理论应用于generative artificial intelligence，旨在指导其负责任部署，确保AI行为在各种上下文中更符合预期。",
      "categories": [
        "cs.AI"
      ],
      "primary_category": "cs.AI",
      "comment": "115 pages, 2 figures",
      "pdf_url": "http://arxiv.org/pdf/2412.19010v1",
      "published_date": "2024-12-26 00:54:03 UTC",
      "updated_date": "2024-12-26 00:54:03 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-21T17:57:48.976377"
    },
    {
      "arxiv_id": "2412.19005v1",
      "title": "Enhancing Audiovisual Speech Recognition through Bifocal Preference Optimization",
      "title_zh": "翻译失败",
      "authors": [
        "Yihan Wu",
        "Yichen Lu",
        "Yifan Peng",
        "Xihua Wang",
        "Ruihua Song",
        "Shinji Watanabe"
      ],
      "abstract": "Audiovisual Automatic Speech Recognition (AV-ASR) aims to improve speech\nrecognition accuracy by leveraging visual signals. It is particularly\nchallenging in unconstrained real-world scenarios across various domains due to\nnoisy acoustic environments, spontaneous speech, and the uncertain use of\nvisual information. Most previous works fine-tune audio-only ASR models on\naudiovisual datasets, optimizing them for conventional ASR objectives. However,\nthey often neglect visual features and common errors in unconstrained video\nscenarios. In this paper, we propose using a preference optimization strategy\nto improve speech recognition accuracy for real-world videos. First, we create\npreference data via simulating common errors that occurred in AV-ASR from two\nfocals: manipulating the audio or vision input and rewriting the output\ntranscript. Second, we propose BPO-AVASR, a Bifocal Preference Optimization\nmethod to improve AV-ASR models by leveraging both input-side and output-side\npreference. Extensive experiments demonstrate that our approach significantly\nimproves speech recognition accuracy across various domains, outperforming\nprevious state-of-the-art models on real-world video speech recognition.",
      "tldr_zh": "该论文针对视听自动语音识别 (AV-ASR) 在真实世界场景中的挑战，如噪音环境和视觉信息不确定性，提出了一种偏好优化策略来提升语音识别准确性。研究者首先通过模拟常见错误（如操纵音频或视觉输入以及重写输出转录）来创建偏好数据。接着，引入 BPO-AVASR（Bifocal Preference Optimization）方法，利用输入侧和输出侧偏好来优化 AV-ASR 模型。实验结果显示，该方法在各种领域显著提高了语音识别性能，超越了现有最先进模型。",
      "categories": [
        "eess.AS",
        "cs.AI"
      ],
      "primary_category": "eess.AS",
      "comment": "Accepted by AAAI 2025",
      "pdf_url": "http://arxiv.org/pdf/2412.19005v1",
      "published_date": "2024-12-26 00:26:45 UTC",
      "updated_date": "2024-12-26 00:26:45 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-21T17:56:44.681859"
    }
  ],
  "raw_papers_fetched": true,
  "papers_count": 50,
  "processed_papers_count": 50,
  "failed_papers_count": 0,
  "summary_generated": true,
  "daily_data_saved": true,
  "last_update": "2025-05-21T17:58:09.251615"
}