[
  {
    "arxiv_id": "2407.15007v2",
    "title": "Is Behavior Cloning All You Need? Understanding Horizon in Imitation Learning",
    "authors": [
      "Dylan J. Foster",
      "Adam Block",
      "Dipendra Misra"
    ],
    "abstract": "Imitation learning (IL) aims to mimic the behavior of an expert in a\nsequential decision making task by learning from demonstrations, and has been\nwidely applied to robotics, autonomous driving, and autoregressive text\ngeneration. The simplest approach to IL, behavior cloning (BC), is thought to\nincur sample complexity with unfavorable quadratic dependence on the problem\nhorizon, motivating a variety of different online algorithms that attain\nimproved linear horizon dependence under stronger assumptions on the data and\nthe learner's access to the expert.\n  We revisit the apparent gap between offline and online IL from a\nlearning-theoretic perspective, with a focus on the realizable/well-specified\nsetting with general policy classes up to and including deep neural networks.\nThrough a new analysis of behavior cloning with the logarithmic loss, we show\nthat it is possible to achieve horizon-independent sample complexity in offline\nIL whenever (i) the range of the cumulative payoffs is controlled, and (ii) an\nappropriate notion of supervised learning complexity for the policy class is\ncontrolled. Specializing our results to deterministic, stationary policies, we\nshow that the gap between offline and online IL is smaller than previously\nthought: (i) it is possible to achieve linear dependence on horizon in offline\nIL under dense rewards (matching what was previously only known to be\nachievable in online IL); and (ii) without further assumptions on the policy\nclass, online IL cannot improve over offline IL with the logarithmic loss, even\nin benign MDPs. We complement our theoretical results with experiments on\nstandard RL tasks and autoregressive language generation to validate the\npractical relevance of our findings.",
    "categories": [
      "cs.LG",
      "cs.AI",
      "math.ST",
      "stat.ML",
      "stat.TH"
    ],
    "primary_category": "cs.LG",
    "comment": "NeurIPS 2024",
    "pdf_url": "http://arxiv.org/pdf/2407.15007v2",
    "published_date": "2024-07-20 23:31:56 UTC",
    "updated_date": "2024-11-30 18:07:50 UTC"
  },
  {
    "arxiv_id": "2407.14985v5",
    "title": "Generalization v.s. Memorization: Tracing Language Models' Capabilities Back to Pretraining Data",
    "authors": [
      "Xinyi Wang",
      "Antonis Antoniades",
      "Yanai Elazar",
      "Alfonso Amayuelas",
      "Alon Albalak",
      "Kexun Zhang",
      "William Yang Wang"
    ],
    "abstract": "The impressive capabilities of large language models (LLMs) have sparked\ndebate over whether these models genuinely generalize to unseen tasks or\npredominantly rely on memorizing vast amounts of pretraining data. To explore\nthis issue, we introduce an extended concept of memorization, distributional\nmemorization, which measures the correlation between the LLM output\nprobabilities and the pretraining data frequency. To effectively capture\ntask-specific pretraining data frequency, we propose a novel task-gram language\nmodel, which is built by counting the co-occurrence of semantically related\n$n$-gram pairs from task inputs and outputs in the pretraining corpus. Using\nthe Pythia models trained on the Pile dataset, we evaluate four distinct tasks:\nmachine translation, factual question answering, world knowledge understanding,\nand math reasoning. Our findings reveal varying levels of memorization, with\nthe strongest effect observed in factual question answering. Furthermore, while\nmodel performance improves across all tasks as LLM size increases, only factual\nquestion answering shows an increase in memorization, whereas machine\ntranslation and reasoning tasks exhibit greater generalization, producing more\nnovel outputs. This study demonstrates that memorization plays a larger role in\nsimpler, knowledge-intensive tasks, while generalization is the key for harder,\nreasoning-based tasks, providing a scalable method for analyzing large\npretraining corpora in greater depth.",
    "categories": [
      "cs.CL",
      "cs.AI",
      "cs.LG"
    ],
    "primary_category": "cs.CL",
    "comment": "Accepted to ICLR 2025",
    "pdf_url": "http://arxiv.org/pdf/2407.14985v5",
    "published_date": "2024-07-20 21:24:40 UTC",
    "updated_date": "2025-03-02 03:27:58 UTC"
  },
  {
    "arxiv_id": "2407.14984v1",
    "title": "Enhancing Microgrid Performance Prediction with Attention-based Deep Learning Models",
    "authors": [
      "Vinod Kumar Maddineni",
      "Naga Babu Koganti",
      "Praveen Damacharla"
    ],
    "abstract": "In this research, an effort is made to address microgrid systems' operational\nchallenges, characterized by power oscillations that eventually contribute to\ngrid instability. An integrated strategy is proposed, leveraging the strengths\nof convolutional and Gated Recurrent Unit (GRU) layers. This approach is aimed\nat effectively extracting temporal data from energy datasets to improve the\nprecision of microgrid behavior forecasts. Additionally, an attention layer is\nemployed to underscore significant features within the time-series data,\noptimizing the forecasting process. The framework is anchored by a Multi-Layer\nPerceptron (MLP) model, which is tasked with comprehensive load forecasting and\nthe identification of abnormal grid behaviors. Our methodology underwent\nrigorous evaluation using the Micro-grid Tariff Assessment Tool dataset, with\nRoot Mean Square Error (RMSE), Mean Absolute Error (MAE), and the coefficient\nof determination (r2-score) serving as the primary metrics. The approach\ndemonstrated exemplary performance, evidenced by a MAE of 0.39, RMSE of 0.28,\nand an r2-score of 98.89\\% in load forecasting, along with near-perfect zero\nstate prediction accuracy (approximately 99.9\\%). Significantly outperforming\nconventional machine learning models such as support vector regression and\nrandom forest regression, our model's streamlined architecture is particularly\nsuitable for real-time applications, thereby facilitating more effective and\nreliable microgrid management.",
    "categories": [
      "cs.LG",
      "cs.AI",
      "cs.SY",
      "eess.SY"
    ],
    "primary_category": "cs.LG",
    "comment": "2024 11th International Conference on Information Technology,\n  Computer, and Electrical Engineering (ICITACEE)",
    "pdf_url": "http://arxiv.org/pdf/2407.14984v1",
    "published_date": "2024-07-20 21:24:11 UTC",
    "updated_date": "2024-07-20 21:24:11 UTC"
  },
  {
    "arxiv_id": "2407.14982v1",
    "title": "GreenStableYolo: Optimizing Inference Time and Image Quality of Text-to-Image Generation",
    "authors": [
      "Jingzhi Gong",
      "Sisi Li",
      "Giordano d'Aloisio",
      "Zishuo Ding",
      "Yulong Ye",
      "William B. Langdon",
      "Federica Sarro"
    ],
    "abstract": "Tuning the parameters and prompts for improving AI-based text-to-image\ngeneration has remained a substantial yet unaddressed challenge. Hence we\nintroduce GreenStableYolo, which improves the parameters and prompts for Stable\nDiffusion to both reduce GPU inference time and increase image generation\nquality using NSGA-II and Yolo.\n  Our experiments show that despite a relatively slight trade-off (18%) in\nimage quality compared to StableYolo (which only considers image quality),\nGreenStableYolo achieves a substantial reduction in inference time (266% less)\nand a 526% higher hypervolume, thereby advancing the state-of-the-art for\ntext-to-image generation.",
    "categories": [
      "cs.CV",
      "cs.AI"
    ],
    "primary_category": "cs.CV",
    "comment": "This paper is published in the SSBSE Challenge Track 2024",
    "pdf_url": "http://arxiv.org/pdf/2407.14982v1",
    "published_date": "2024-07-20 21:14:24 UTC",
    "updated_date": "2024-07-20 21:14:24 UTC"
  },
  {
    "arxiv_id": "2407.14975v1",
    "title": "A Measure for Level of Autonomy Based on Observable System Behavior",
    "authors": [
      "Jason M. Pittman"
    ],
    "abstract": "Contemporary artificial intelligence systems are pivotal in enhancing human\nefficiency and safety across various domains. One such domain is autonomous\nsystems, especially in automotive and defense use cases. Artificial\nintelligence brings learning and enhanced decision-making to autonomy system\ngoal-oriented behaviors and human independence. However, the lack of clear\nunderstanding of autonomy system capabilities hampers human-machine or\nmachine-machine interaction and interdiction. This necessitates varying degrees\nof human involvement for safety, accountability, and explainability purposes.\nYet, measuring the level autonomous capability in an autonomous system presents\na challenge. Two scales of measurement exist, yet measuring autonomy\npresupposes a variety of elements not available in the wild. This is why\nexisting measures for level of autonomy are operationalized only during design\nor test and evaluation phases. No measure for level of autonomy based on\nobserved system behavior exists at this time. To address this, we outline a\npotential measure for predicting level of autonomy using observable actions. We\nalso present an algorithm incorporating the proposed measure. The measure and\nalgorithm have significance to researchers and practitioners interested in a\nmethod to blind compare autonomous systems at runtime. Defense-based\nimplementations are likewise possible because counter-autonomy depends on\nrobust identification of autonomous systems.",
    "categories": [
      "cs.AI",
      "cs.CY"
    ],
    "primary_category": "cs.AI",
    "comment": "9 pages, 1 figure, 3 tables",
    "pdf_url": "http://arxiv.org/pdf/2407.14975v1",
    "published_date": "2024-07-20 20:34:20 UTC",
    "updated_date": "2024-07-20 20:34:20 UTC"
  },
  {
    "arxiv_id": "2407.14974v1",
    "title": "Out of spuriousity: Improving robustness to spurious correlations without group annotations",
    "authors": [
      "Phuong Quynh Le",
      "Jörg Schlötterer",
      "Christin Seifert"
    ],
    "abstract": "Machine learning models are known to learn spurious correlations, i.e.,\nfeatures having strong relations with class labels but no causal relation.\nRelying on those correlations leads to poor performance in the data groups\nwithout these correlations and poor generalization ability. To improve the\nrobustness of machine learning models to spurious correlations, we propose an\napproach to extract a subnetwork from a fully trained network that does not\nrely on spurious correlations. The subnetwork is found by the assumption that\ndata points with the same spurious attribute will be close to each other in the\nrepresentation space when training with ERM, then we employ supervised\ncontrastive loss in a novel way to force models to unlearn the spurious\nconnections. The increase in the worst-group performance of our approach\ncontributes to strengthening the hypothesis that there exists a subnetwork in a\nfully trained dense network that is responsible for using only invariant\nfeatures in classification tasks, therefore erasing the influence of spurious\nfeatures even in the setup of multi spurious attributes and no prior knowledge\nof attributes labels.",
    "categories": [
      "cs.LG",
      "cs.AI"
    ],
    "primary_category": "cs.LG",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2407.14974v1",
    "published_date": "2024-07-20 20:24:14 UTC",
    "updated_date": "2024-07-20 20:24:14 UTC"
  },
  {
    "arxiv_id": "2407.14971v2",
    "title": "Sim-CLIP: Unsupervised Siamese Adversarial Fine-Tuning for Robust and Semantically-Rich Vision-Language Models",
    "authors": [
      "Md Zarif Hossain",
      "Ahmed Imteaj"
    ],
    "abstract": "Vision-language models (VLMs) have achieved significant strides in recent\ntimes specially in multimodal tasks, yet they remain susceptible to adversarial\nattacks on their vision components. To address this, we propose Sim-CLIP, an\nunsupervised adversarial fine-tuning method that enhances the robustness of the\nwidely-used CLIP vision encoder against such attacks while maintaining semantic\nrichness and specificity. By employing a Siamese architecture with cosine\nsimilarity loss, Sim-CLIP learns semantically meaningful and attack-resilient\nvisual representations without requiring large batch sizes or momentum\nencoders. Our results demonstrate that VLMs enhanced with Sim-CLIP's fine-tuned\nCLIP encoder exhibit significantly enhanced robustness against adversarial\nattacks, while preserving semantic meaning of the perturbed images. Notably,\nSim-CLIP does not require additional training or fine-tuning of the VLM itself;\nreplacing the original vision encoder with our fine-tuned Sim-CLIP suffices to\nprovide robustness. This work underscores the significance of reinforcing\nfoundational models like CLIP to safeguard the reliability of downstream VLM\napplications, paving the way for more secure and effective multimodal systems.",
    "categories": [
      "cs.CV",
      "cs.AI",
      "cs.CL",
      "cs.LG"
    ],
    "primary_category": "cs.CV",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2407.14971v2",
    "published_date": "2024-07-20 19:53:52 UTC",
    "updated_date": "2024-11-15 21:09:28 UTC"
  },
  {
    "arxiv_id": "2407.14962v5",
    "title": "Recent Advances in Generative AI and Large Language Models: Current Status, Challenges, and Perspectives",
    "authors": [
      "Desta Haileselassie Hagos",
      "Rick Battle",
      "Danda B. Rawat"
    ],
    "abstract": "The emergence of Generative Artificial Intelligence (AI) and Large Language\nModels (LLMs) has marked a new era of Natural Language Processing (NLP),\nintroducing unprecedented capabilities that are revolutionizing various\ndomains. This paper explores the current state of these cutting-edge\ntechnologies, demonstrating their remarkable advancements and wide-ranging\napplications. Our paper contributes to providing a holistic perspective on the\ntechnical foundations, practical applications, and emerging challenges within\nthe evolving landscape of Generative AI and LLMs. We believe that understanding\nthe generative capabilities of AI systems and the specific context of LLMs is\ncrucial for researchers, practitioners, and policymakers to collaboratively\nshape the responsible and ethical integration of these technologies into\nvarious domains. Furthermore, we identify and address main research gaps,\nproviding valuable insights to guide future research endeavors within the AI\nresearch community.",
    "categories": [
      "cs.CL",
      "cs.AI",
      "cs.LG"
    ],
    "primary_category": "cs.CL",
    "comment": "This version is accepted for publication in the Journal of IEEE\n  Transactions on Artificial Intelligence (TAI)",
    "pdf_url": "http://arxiv.org/pdf/2407.14962v5",
    "published_date": "2024-07-20 18:48:35 UTC",
    "updated_date": "2024-08-23 14:14:21 UTC"
  },
  {
    "arxiv_id": "2407.17522v1",
    "title": "Mapping the Technological Future: A Topic, Sentiment, and Emotion Analysis in Social Media Discourse",
    "authors": [
      "Alina Landowska",
      "Maciej Skorski",
      "Krzysztof Rajda"
    ],
    "abstract": "People worldwide are currently confronted with a number of technological\nchallenges, which act as a potent source of uncertainty. The uncertainty\narising from the volatility and unpredictability of technology (such as AI) and\nits potential consequences is widely discussed on social media. This study uses\nBERTopic modelling along with sentiment and emotion analysis on 1.5 million\ntweets from 2021 to 2023 to identify anticipated tech-driven futures and\ncapture the emotions communicated by 400 key opinion leaders (KOLs). Findings\nindicate positive sentiment significantly outweighs negative, with a prevailing\ndominance of positive anticipatory emotions. Specifically, the 'Hope' score is\napproximately 10.33\\% higher than the median 'Anxiety' score. KOLs emphasize\n'Optimism' and benefits over 'Pessimism' and challenges. The study emphasizes\nthe important role KOLs play in shaping future visions through anticipatory\ndiscourse and emotional tone during times of technological uncertainty.",
    "categories": [
      "cs.AI",
      "cs.CL",
      "cs.SI",
      "stat.AP",
      "J.4"
    ],
    "primary_category": "cs.AI",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2407.17522v1",
    "published_date": "2024-07-20 18:15:30 UTC",
    "updated_date": "2024-07-20 18:15:30 UTC"
  },
  {
    "arxiv_id": "2408.02752v1",
    "title": "Diffusion Models as Data Mining Tools",
    "authors": [
      "Ioannis Siglidis",
      "Aleksander Holynski",
      "Alexei A. Efros",
      "Mathieu Aubry",
      "Shiry Ginosar"
    ],
    "abstract": "This paper demonstrates how to use generative models trained for image\nsynthesis as tools for visual data mining. Our insight is that since\ncontemporary generative models learn an accurate representation of their\ntraining data, we can use them to summarize the data by mining for visual\npatterns. Concretely, we show that after finetuning conditional diffusion\nmodels to synthesize images from a specific dataset, we can use these models to\ndefine a typicality measure on that dataset. This measure assesses how typical\nvisual elements are for different data labels, such as geographic location,\ntime stamps, semantic labels, or even the presence of a disease. This\nanalysis-by-synthesis approach to data mining has two key advantages. First, it\nscales much better than traditional correspondence-based approaches since it\ndoes not require explicitly comparing all pairs of visual elements. Second,\nwhile most previous works on visual data mining focus on a single dataset, our\napproach works on diverse datasets in terms of content and scale, including a\nhistorical car dataset, a historical face dataset, a large worldwide\nstreet-view dataset, and an even larger scene dataset. Furthermore, our\napproach allows for translating visual elements across class labels and\nanalyzing consistent changes.",
    "categories": [
      "cs.CV",
      "cs.AI"
    ],
    "primary_category": "cs.CV",
    "comment": "Project Page: https://diff-mining.github.io/ Accepted in ECCV 2024",
    "pdf_url": "http://arxiv.org/pdf/2408.02752v1",
    "published_date": "2024-07-20 17:14:31 UTC",
    "updated_date": "2024-07-20 17:14:31 UTC"
  },
  {
    "arxiv_id": "2407.14933v2",
    "title": "Consent in Crisis: The Rapid Decline of the AI Data Commons",
    "authors": [
      "Shayne Longpre",
      "Robert Mahari",
      "Ariel Lee",
      "Campbell Lund",
      "Hamidah Oderinwale",
      "William Brannon",
      "Nayan Saxena",
      "Naana Obeng-Marnu",
      "Tobin South",
      "Cole Hunter",
      "Kevin Klyman",
      "Christopher Klamm",
      "Hailey Schoelkopf",
      "Nikhil Singh",
      "Manuel Cherep",
      "Ahmad Anis",
      "An Dinh",
      "Caroline Chitongo",
      "Da Yin",
      "Damien Sileo",
      "Deividas Mataciunas",
      "Diganta Misra",
      "Emad Alghamdi",
      "Enrico Shippole",
      "Jianguo Zhang",
      "Joanna Materzynska",
      "Kun Qian",
      "Kush Tiwary",
      "Lester Miranda",
      "Manan Dey",
      "Minnie Liang",
      "Mohammed Hamdy",
      "Niklas Muennighoff",
      "Seonghyeon Ye",
      "Seungone Kim",
      "Shrestha Mohanty",
      "Vipul Gupta",
      "Vivek Sharma",
      "Vu Minh Chien",
      "Xuhui Zhou",
      "Yizhi Li",
      "Caiming Xiong",
      "Luis Villa",
      "Stella Biderman",
      "Hanlin Li",
      "Daphne Ippolito",
      "Sara Hooker",
      "Jad Kabbara",
      "Sandy Pentland"
    ],
    "abstract": "General-purpose artificial intelligence (AI) systems are built on massive\nswathes of public web data, assembled into corpora such as C4, RefinedWeb, and\nDolma. To our knowledge, we conduct the first, large-scale, longitudinal audit\nof the consent protocols for the web domains underlying AI training corpora.\nOur audit of 14,000 web domains provides an expansive view of crawlable web\ndata and how codified data use preferences are changing over time. We observe a\nproliferation of AI-specific clauses to limit use, acute differences in\nrestrictions on AI developers, as well as general inconsistencies between\nwebsites' expressed intentions in their Terms of Service and their robots.txt.\nWe diagnose these as symptoms of ineffective web protocols, not designed to\ncope with the widespread re-purposing of the internet for AI. Our longitudinal\nanalyses show that in a single year (2023-2024) there has been a rapid\ncrescendo of data restrictions from web sources, rendering ~5%+ of all tokens\nin C4, or 28%+ of the most actively maintained, critical sources in C4, fully\nrestricted from use. For Terms of Service crawling restrictions, a full 45% of\nC4 is now restricted. If respected or enforced, these restrictions are rapidly\nbiasing the diversity, freshness, and scaling laws for general-purpose AI\nsystems. We hope to illustrate the emerging crises in data consent, for both\ndevelopers and creators. The foreclosure of much of the open web will impact\nnot only commercial AI, but also non-commercial AI and academic research.",
    "categories": [
      "cs.CL",
      "cs.AI",
      "cs.LG"
    ],
    "primary_category": "cs.CL",
    "comment": "41 pages (13 main), 5 figures, 9 tables",
    "pdf_url": "http://arxiv.org/pdf/2407.14933v2",
    "published_date": "2024-07-20 16:50:18 UTC",
    "updated_date": "2024-07-24 16:52:51 UTC"
  },
  {
    "arxiv_id": "2407.14931v3",
    "title": "POGEMA: A Benchmark Platform for Cooperative Multi-Agent Pathfinding",
    "authors": [
      "Alexey Skrynnik",
      "Anton Andreychuk",
      "Anatolii Borzilov",
      "Alexander Chernyavskiy",
      "Konstantin Yakovlev",
      "Aleksandr Panov"
    ],
    "abstract": "Multi-agent reinforcement learning (MARL) has recently excelled in solving\nchallenging cooperative and competitive multi-agent problems in various\nenvironments, typically involving a small number of agents and full\nobservability. Moreover, a range of crucial robotics-related tasks, such as\nmulti-robot pathfinding, which have traditionally been approached with\nclassical non-learnable methods (e.g., heuristic search), are now being\nsuggested for solution using learning-based or hybrid methods. However, in this\ndomain, it remains difficult, if not impossible, to conduct a fair comparison\nbetween classical, learning-based, and hybrid approaches due to the lack of a\nunified framework that supports both learning and evaluation. To address this,\nwe introduce POGEMA, a comprehensive set of tools that includes a fast\nenvironment for learning, a problem instance generator, a collection of\npredefined problem instances, a visualization toolkit, and a benchmarking tool\nfor automated evaluation. We also introduce and define an evaluation protocol\nthat specifies a range of domain-related metrics, computed based on primary\nevaluation indicators (such as success rate and path length), enabling a fair\nmulti-fold comparison. The results of this comparison, which involves a variety\nof state-of-the-art MARL, search-based, and hybrid methods, are presented.",
    "categories": [
      "cs.LG",
      "cs.AI",
      "cs.MA"
    ],
    "primary_category": "cs.LG",
    "comment": "Published as a conference paper at The International Conference on\n  Learning Representations 2025",
    "pdf_url": "http://arxiv.org/pdf/2407.14931v3",
    "published_date": "2024-07-20 16:37:21 UTC",
    "updated_date": "2025-04-08 08:14:39 UTC"
  },
  {
    "arxiv_id": "2407.14926v1",
    "title": "TraveLLM: Could you plan my new public transit route in face of a network disruption?",
    "authors": [
      "Bowen Fang",
      "Zixiao Yang",
      "Shukai Wang",
      "Xuan Di"
    ],
    "abstract": "Imagine there is a disruption in train 1 near Times Square metro station. You\ntry to find an alternative subway route to the JFK airport on Google Maps, but\nthe app fails to provide a suitable recommendation that takes into account the\ndisruption and your preferences to avoid crowded stations. We find that in many\nsuch situations, current navigation apps may fall short and fail to give a\nreasonable recommendation. To fill this gap, in this paper, we develop a\nprototype, TraveLLM, to plan routing of public transit in face of disruption\nthat relies on Large Language Models (LLMs). LLMs have shown remarkable\ncapabilities in reasoning and planning across various domains. Here we hope to\ninvestigate the potential of LLMs that lies in incorporating multi-modal\nuser-specific queries and constraints into public transit route\nrecommendations. Various test cases are designed under different scenarios,\nincluding varying weather conditions, emergency events, and the introduction of\nnew transportation services. We then compare the performance of\nstate-of-the-art LLMs, including GPT-4, Claude 3 and Gemini, in generating\naccurate routes. Our comparative analysis demonstrates the effectiveness of\nLLMs, particularly GPT-4 in providing navigation plans. Our findings hold the\npotential for LLMs to enhance existing navigation systems and provide a more\nflexible and intelligent method for addressing diverse user needs in face of\ndisruptions.",
    "categories": [
      "cs.AI"
    ],
    "primary_category": "cs.AI",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2407.14926v1",
    "published_date": "2024-07-20 16:25:34 UTC",
    "updated_date": "2024-07-20 16:25:34 UTC"
  },
  {
    "arxiv_id": "2407.14916v2",
    "title": "Improving Context-Aware Preference Modeling for Language Models",
    "authors": [
      "Silviu Pitis",
      "Ziang Xiao",
      "Nicolas Le Roux",
      "Alessandro Sordoni"
    ],
    "abstract": "While finetuning language models from pairwise preferences has proven\nremarkably effective, the underspecified nature of natural language presents\ncritical challenges. Direct preference feedback is uninterpretable, difficult\nto provide where multidimensional criteria may apply, and often inconsistent,\neither because it is based on incomplete instructions or provided by diverse\nprincipals. To address these challenges, we consider the two-step preference\nmodeling procedure that first resolves the under-specification by selecting a\ncontext, and then evaluates preference with respect to the chosen context. We\ndecompose reward modeling error according to these two steps, which suggests\nthat supervising context in addition to context-specific preference may be a\nviable approach to aligning models with diverse human preferences. For this to\nwork, the ability of models to evaluate context-specific preference is\ncritical. To this end, we contribute context-conditioned preference datasets\nand accompanying experiments that investigate the ability of language models to\nevaluate context-specific preference. We use our datasets to (1) show that\nexisting preference models benefit from, but fail to fully consider, added\ncontext, (2) finetune a context-aware reward model with context-specific\nperformance exceeding that of GPT-4 and Llama 3 70B on tested datasets, and (3)\ninvestigate the value of context-aware preference modeling.",
    "categories": [
      "cs.CL",
      "cs.AI",
      "cs.LG"
    ],
    "primary_category": "cs.CL",
    "comment": "NeurIPS 2024. 10 pages (29 with references and appendix)",
    "pdf_url": "http://arxiv.org/pdf/2407.14916v2",
    "published_date": "2024-07-20 16:05:17 UTC",
    "updated_date": "2024-11-06 16:11:18 UTC"
  },
  {
    "arxiv_id": "2407.14910v1",
    "title": "Visual Geo-Localization from images",
    "authors": [
      "Rania Saoud",
      "Slimane Larabi"
    ],
    "abstract": "This paper presents a visual geo-localization system capable of determining\nthe geographic locations of places (buildings and road intersections) from\nimages without relying on GPS data. Our approach integrates three primary\nmethods: Scale-Invariant Feature Transform (SIFT) for place recognition,\ntraditional image processing for identifying road junction types, and deep\nlearning using the VGG16 model for classifying road junctions. The most\neffective techniques have been integrated into an offline mobile application,\nenhancing accessibility for users requiring reliable location information in\nGPS-denied environments.",
    "categories": [
      "cs.CV",
      "cs.AI"
    ],
    "primary_category": "cs.CV",
    "comment": "18 pages, 8 figures,",
    "pdf_url": "http://arxiv.org/pdf/2407.14910v1",
    "published_date": "2024-07-20 15:47:21 UTC",
    "updated_date": "2024-07-20 15:47:21 UTC"
  },
  {
    "arxiv_id": "2407.14904v1",
    "title": "Large-vocabulary forensic pathological analyses via prototypical cross-modal contrastive learning",
    "authors": [
      "Chen Shen",
      "Chunfeng Lian",
      "Wanqing Zhang",
      "Fan Wang",
      "Jianhua Zhang",
      "Shuanliang Fan",
      "Xin Wei",
      "Gongji Wang",
      "Kehan Li",
      "Hongshu Mu",
      "Hao Wu",
      "Xinggong Liang",
      "Jianhua Ma",
      "Zhenyuan Wang"
    ],
    "abstract": "Forensic pathology is critical in determining the cause and manner of death\nthrough post-mortem examinations, both macroscopic and microscopic. The field,\nhowever, grapples with issues such as outcome variability, laborious processes,\nand a scarcity of trained professionals. This paper presents SongCi, an\ninnovative visual-language model (VLM) designed specifically for forensic\npathology. SongCi utilizes advanced prototypical cross-modal self-supervised\ncontrastive learning to enhance the accuracy, efficiency, and generalizability\nof forensic analyses. It was pre-trained and evaluated on a comprehensive\nmulti-center dataset, which includes over 16 million high-resolution image\npatches, 2,228 vision-language pairs of post-mortem whole slide images (WSIs),\nand corresponding gross key findings, along with 471 distinct diagnostic\noutcomes. Our findings indicate that SongCi surpasses existing multi-modal AI\nmodels in many forensic pathology tasks, performs comparably to experienced\nforensic pathologists and significantly better than less experienced ones, and\nprovides detailed multi-modal explainability, offering critical assistance in\nforensic investigations. To the best of our knowledge, SongCi is the first VLM\nspecifically developed for forensic pathological analysis and the first\nlarge-vocabulary computational pathology (CPath) model that directly processes\ngigapixel WSIs in forensic science.",
    "categories": [
      "eess.IV",
      "cs.AI",
      "cs.CL",
      "cs.CV"
    ],
    "primary_category": "eess.IV",
    "comment": "28 pages, 6 figures, under review",
    "pdf_url": "http://arxiv.org/pdf/2407.14904v1",
    "published_date": "2024-07-20 15:34:52 UTC",
    "updated_date": "2024-07-20 15:34:52 UTC"
  },
  {
    "arxiv_id": "2407.21039v1",
    "title": "Mapping Patient Trajectories: Understanding and Visualizing Sepsis Prognostic Pathways from Patients Clinical Narratives",
    "authors": [
      "Sudeshna Jana",
      "Tirthankar Dasgupta",
      "Lipika Dey"
    ],
    "abstract": "In recent years, healthcare professionals are increasingly emphasizing on\npersonalized and evidence-based patient care through the exploration of\nprognostic pathways. To study this, structured clinical variables from\nElectronic Health Records (EHRs) data have traditionally been employed by many\nresearchers. Presently, Natural Language Processing models have received great\nattention in clinical research which expanded the possibilities of using\nclinical narratives. In this paper, we propose a systematic methodology for\ndeveloping sepsis prognostic pathways derived from clinical notes, focusing on\ndiverse patient subgroups identified by exploring comorbidities associated with\nsepsis and generating explanations of these subgroups using SHAP. The extracted\nprognostic pathways of these subgroups provide valuable insights into the\ndynamic trajectories of sepsis severity over time. Visualizing these pathways\nsheds light on the likelihood and direction of disease progression across\nvarious contexts and reveals patterns and pivotal factors or biomarkers\ninfluencing the transition between sepsis stages, whether toward deterioration\nor improvement. This empowers healthcare providers to implement more\npersonalized and effective healthcare strategies for individual patients.",
    "categories": [
      "cs.CL",
      "cs.AI",
      "cs.LG"
    ],
    "primary_category": "cs.CL",
    "comment": "preprint, 8 pages, 6 figures",
    "pdf_url": "http://arxiv.org/pdf/2407.21039v1",
    "published_date": "2024-07-20 14:45:55 UTC",
    "updated_date": "2024-07-20 14:45:55 UTC"
  },
  {
    "arxiv_id": "2407.14883v2",
    "title": "Inferring Ingrained Remote Information in AC Power Flows Using Neuromorphic Modality Regime",
    "authors": [
      "Xiaoguang Diao",
      "Yubo Song",
      "Subham Sahoo"
    ],
    "abstract": "In this paper, we infer remote measurements such as remote voltages and\ncurrents online with change in AC power flows using spiking neural network\n(SNN) as grid-edge technology for efficient coordination of power electronic\nconverters. This work unifies power and information as a means of data\nnormalization using a multi-modal regime in the form of spikes using\nenergy-efficient neuromorphic learning and event-driven asynchronous data\ncollection. Firstly, we organize the synchronous real-valued measurements at\neach edge and translate them into asynchronous spike-based events to collect\nsparse data for training of SNN at each edge. Instead of relying on\nerror-dependent supervised data-driven learning theory, we exploit the\nlatency-driven unsupervised Hebbian learning rule to obtain modulation pulses\nfor switching of power electronic converters that can now comprehend grid\ndisturbances locally and adapt their operation without requiring explicit\ninfrastructure for global coordination. Not only does this philosophy block\nexogenous path arrival for cyber attackers by dismissing the cyber layer, it\nalso entails converter adaptation to system reconfiguration and parameter\nmismatch issues. We conclude this work by validating its energy-efficient and\neffective online learning performance under various scenarios in different\nsystem sizes, including modified IEEE 14-bus system and under experimental\nconditions.",
    "categories": [
      "eess.SY",
      "cs.AI",
      "cs.NE",
      "cs.SY"
    ],
    "primary_category": "eess.SY",
    "comment": "The manuscript has been accepted for publication in the Proceedings\n  of 2024 IEEE International Conference on Communications, Control, and\n  Computing Technologies for Smart Grids (SmartGridComm 2024)",
    "pdf_url": "http://arxiv.org/pdf/2407.14883v2",
    "published_date": "2024-07-20 14:20:22 UTC",
    "updated_date": "2024-08-09 19:35:52 UTC"
  },
  {
    "arxiv_id": "2407.14882v1",
    "title": "Reduced Effectiveness of Kolmogorov-Arnold Networks on Functions with Noise",
    "authors": [
      "Haoran Shen",
      "Chen Zeng",
      "Jiahui Wang",
      "Qiao Wang"
    ],
    "abstract": "It has been observed that even a small amount of noise introduced into the\ndataset can significantly degrade the performance of KAN. In this brief note,\nwe aim to quantitatively evaluate the performance when noise is added to the\ndataset. We propose an oversampling technique combined with denoising to\nalleviate the impact of noise. Specifically, we employ kernel filtering based\non diffusion maps for pre-filtering the noisy data for training KAN network.\nOur experiments show that while adding i.i.d. noise with any fixed SNR, when we\nincrease the amount of training data by a factor of $r$, the test-loss (RMSE)\nof KANs will exhibit a performance trend like $\\text{test-loss} \\sim\n\\mathcal{O}(r^{-\\frac{1}{2}})$ as $r\\to +\\infty$. We conclude that applying\nboth oversampling and filtering strategies can reduce the detrimental effects\nof noise. Nevertheless, determining the optimal variance for the kernel\nfiltering process is challenging, and enhancing the volume of training data\nsubstantially increases the associated costs, because the training dataset\nneeds to be expanded multiple times in comparison to the initial clean data. As\na result, the noise present in the data ultimately diminishes the effectiveness\nof Kolmogorov-Arnold networks.",
    "categories": [
      "cs.LG",
      "cs.AI",
      "cs.NA",
      "math.NA",
      "68T07"
    ],
    "primary_category": "cs.LG",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2407.14882v1",
    "published_date": "2024-07-20 14:17:10 UTC",
    "updated_date": "2024-07-20 14:17:10 UTC"
  },
  {
    "arxiv_id": "2407.14876v1",
    "title": "Preictal Period Optimization for Deep Learning-Based Epileptic Seizure Prediction",
    "authors": [
      "Petros Koutsouvelis",
      "Bartlomiej Chybowski",
      "Alfredo Gonzalez-Sulser",
      "Shima Abdullateef",
      "Javier Escudero"
    ],
    "abstract": "Accurate prediction of epileptic seizures could prove critical for improving\npatient safety and quality of life in drug-resistant epilepsy. Although deep\nlearning-based approaches have shown promising seizure prediction performance\nusing scalp electroencephalogram (EEG) signals, substantial limitations still\nimpede their clinical adoption. Furthermore, identifying the optimal preictal\nperiod (OPP) for labeling EEG segments remains a challenge. Here, we not only\ndevelop a competitive deep learning model for seizure prediction but, more\nimportantly, leverage it to demonstrate a methodology to comprehensively\nevaluate the predictive performance in the seizure prediction task. For this,\nwe introduce a CNN-Transformer deep learning model to detect preictal\nspatiotemporal dynamics, alongside a novel Continuous Input-Output Performance\nRatio (CIOPR) metric to determine the OPP. We trained and evaluated our model\non 19 pediatric patients of the open-access CHB-MIT dataset in a\nsubject-specific manner. Using the OPP of each patient, preictal and interictal\nsegments were correctly identified with an average sensitivity of 99.31%,\nspecificity of 95.34%, AUC of 99.35%, and F1- score of 97.46%, while prediction\ntime averaged 76.8 minutes before onset. Notably, our novel CIOPR metric\nallowed outlining the impact of different preictal period definitions on\nprediction time, accuracy, output stability, and transition time between\ninterictal and preictal states in a comprehensive and quantitative way and\nhighlighted the importance of considering both inter- and intra-patient\nvariability in seizure prediction.",
    "categories": [
      "eess.SP",
      "cs.AI"
    ],
    "primary_category": "eess.SP",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2407.14876v1",
    "published_date": "2024-07-20 13:49:14 UTC",
    "updated_date": "2024-07-20 13:49:14 UTC"
  },
  {
    "arxiv_id": "2407.18968v1",
    "title": "Intelligence Analysis of Language Models",
    "authors": [
      "Liane Galanti",
      "Ethan Baron"
    ],
    "abstract": "In this project, we test the effectiveness of Large Language Models (LLMs) on\nthe Abstraction and Reasoning Corpus (ARC) dataset. This dataset serves as a\nrepresentative benchmark for testing abstract reasoning abilities, requiring a\nfundamental understanding of key concepts such as object identification, basic\ncounting, and elementary geometric principles. Tasks from this dataset are\nconverted into a prompt-based format for evaluation. Initially, we assess the\nmodels' potential through a Zero-shot approach. Subsequently, we investigate\nthe application of the Chain-of-Thought (CoT) technique, aiming to determine\nits role in improving model performance. Our results suggest that, despite the\nhigh expectations placed on contemporary LLMs, these models still struggle in\nnon-linguistic domains, even when dealing with simpler subsets of the ARC\ndataset. Our study is the first to concentrate on the capabilities of\nopen-source models in this context. The code, dataset, and prompts supporting\nthis project's findings can be found in our GitHub repository, accessible at:\nhttps://github.com/Lianga2000/LLMsOnARC.",
    "categories": [
      "cs.AI"
    ],
    "primary_category": "cs.AI",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2407.18968v1",
    "published_date": "2024-07-20 13:48:16 UTC",
    "updated_date": "2024-07-20 13:48:16 UTC"
  },
  {
    "arxiv_id": "2407.15880v1",
    "title": "Diff4VS: HIV-inhibiting Molecules Generation with Classifier Guidance Diffusion for Virtual Screening",
    "authors": [
      "Jiaqing Lyu",
      "Changjie Chen",
      "Bing Liang",
      "Yijia Zhang"
    ],
    "abstract": "The AIDS epidemic has killed 40 million people and caused serious global\nproblems. The identification of new HIV-inhibiting molecules is of great\nimportance for combating the AIDS epidemic. Here, the Classifier Guidance\nDiffusion model and ligand-based virtual screening strategy are combined to\ndiscover potential HIV-inhibiting molecules for the first time. We call it\nDiff4VS. An extra classifier is trained using the HIV molecule dataset, and the\ngradient of the classifier is used to guide the Diffusion to generate\nHIV-inhibiting molecules. Experiments show that Diff4VS can generate more\ncandidate HIV-inhibiting molecules than other methods. Inspired by ligand-based\nvirtual screening, a new metric DrugIndex is proposed. The DrugIndex is the\nratio of the proportion of candidate drug molecules in the generated molecule\nto the proportion of candidate drug molecules in the training set. DrugIndex\nprovides a new evaluation method for evolving molecular generative models from\na pharmaceutical perspective. Besides, we report a new phenomenon observed when\nusing molecule generation models for virtual screening. Compared to real\nmolecules, the generated molecules have a lower proportion that is highly\nsimilar to known drug molecules. We call it Degradation in molecule generation.\nBased on the data analysis, the Degradation may result from the difficulty of\ngenerating molecules with a specific structure in the generative model. Our\nresearch contributes to the application of generative models in drug design\nfrom method, metric, and phenomenon analysis.",
    "categories": [
      "cs.LG",
      "cs.AI",
      "q-bio.QM"
    ],
    "primary_category": "cs.LG",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2407.15880v1",
    "published_date": "2024-07-20 12:34:02 UTC",
    "updated_date": "2024-07-20 12:34:02 UTC"
  },
  {
    "arxiv_id": "2407.14838v1",
    "title": "Retrieval Augmented Generation Integrated Large Language Models in Smart Contract Vulnerability Detection",
    "authors": [
      "Jeffy Yu"
    ],
    "abstract": "The rapid growth of Decentralized Finance (DeFi) has been accompanied by\nsubstantial financial losses due to smart contract vulnerabilities,\nunderscoring the critical need for effective security auditing. With attacks\nbecoming more frequent, the necessity and demand for auditing services has\nescalated. This especially creates a financial burden for independent\ndevelopers and small businesses, who often have limited available funding for\nthese services. Our study builds upon existing frameworks by integrating\nRetrieval-Augmented Generation (RAG) with large language models (LLMs),\nspecifically employing GPT-4-1106 for its 128k token context window. We\nconstruct a vector store of 830 known vulnerable contracts, leveraging Pinecone\nfor vector storage, OpenAI's text-embedding-ada-002 for embeddings, and\nLangChain to construct the RAG-LLM pipeline. Prompts were designed to provide a\nbinary answer for vulnerability detection. We first test 52 smart contracts 40\ntimes each against a provided vulnerability type, verifying the replicability\nand consistency of the RAG-LLM. Encouraging results were observed, with a 62.7%\nsuccess rate in guided detection of vulnerabilities. Second, we challenge the\nmodel under a \"blind\" audit setup, without the vulnerability type provided in\nthe prompt, wherein 219 contracts undergo 40 tests each. This setup evaluates\nthe general vulnerability detection capabilities without hinted context\nassistance. Under these conditions, a 60.71% success rate was observed. While\nthe results are promising, we still emphasize the need for human auditing at\nthis time. We provide this study as a proof of concept for a cost-effective\nsmart contract auditing process, moving towards democratic access to security.",
    "categories": [
      "cs.CR",
      "cs.AI"
    ],
    "primary_category": "cs.CR",
    "comment": "17 pages, 3 figures, 4 tables",
    "pdf_url": "http://arxiv.org/pdf/2407.14838v1",
    "published_date": "2024-07-20 10:46:42 UTC",
    "updated_date": "2024-07-20 10:46:42 UTC"
  },
  {
    "arxiv_id": "2407.15879v2",
    "title": "Decentralized Federated Anomaly Detection in Smart Grids: A P2P Gossip Approach",
    "authors": [
      "Muhammad Akbar Husnoo",
      "Adnan Anwar",
      "Md Enamul Haque",
      "A. N. Mahmood"
    ],
    "abstract": "The increasing security and privacy concerns in the Smart Grid sector have\nled to a significant demand for robust intrusion detection systems within\ncritical smart grid infrastructure. To address the challenges posed by privacy\npreservation and decentralized power system zones with distinct data ownership,\nFederated Learning (FL) has emerged as a promising privacy-preserving solution\nwhich facilitates collaborative training of attack detection models without\nnecessitating the sharing of raw data. However, FL presents several\nimplementation limitations in the power system domain due to its heavy reliance\non a centralized aggregator and the risks of privacy leakage during model\nupdate transmission. To overcome these technical bottlenecks, this paper\nintroduces a novel decentralized federated anomaly detection scheme based on\ntwo main gossip protocols namely Random Walk and Epidemic. Our findings\nindicate that the Random Walk protocol exhibits superior performance compared\nto the Epidemic protocol, highlighting its efficacy in decentralized federated\nlearning environments. Experimental validation of the proposed framework\nutilizing publicly available industrial control systems datasets demonstrates\nsuperior attack detection accuracy while safeguarding data confidentiality and\nmitigating the impact of communication latency and stragglers. Furthermore, our\napproach yields a notable 35% improvement in training time compared to\nconventional FL, underscoring the efficacy and robustness of our decentralized\nlearning method.",
    "categories": [
      "cs.CR",
      "cs.AI",
      "cs.DC",
      "cs.LG"
    ],
    "primary_category": "cs.CR",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2407.15879v2",
    "published_date": "2024-07-20 10:45:06 UTC",
    "updated_date": "2025-01-09 13:27:29 UTC"
  },
  {
    "arxiv_id": "2407.14831v1",
    "title": "Toward Efficient Convolutional Neural Networks With Structured Ternary Patterns",
    "authors": [
      "Christos Kyrkou"
    ],
    "abstract": "High-efficiency deep learning (DL) models are necessary not only to\nfacilitate their use in devices with limited resources but also to improve\nresources required for training. Convolutional neural networks (ConvNets)\ntypically exert severe demands on local device resources and this\nconventionally limits their adoption within mobile and embedded platforms. This\nbrief presents work toward utilizing static convolutional filters generated\nfrom the space of local binary patterns (LBPs) and Haar features to design\nefficient ConvNet architectures. These are referred to as Structured Ternary\nPatterns (STePs) and can be generated during network initialization in a\nsystematic way instead of having learnable weight parameters thus reducing the\ntotal weight updates. The ternary values require significantly less storage and\nwith the appropriate low-level implementation, can also lead to inference\nimprovements. The proposed approach is validated using four image\nclassification datasets, demonstrating that common network backbones can be\nmade more efficient and provide competitive results. It is also demonstrated\nthat it is possible to generate completely custom STeP-based networks that\nprovide good trade-offs for on-device applications such as unmanned aerial\nvehicle (UAV)-based aerial vehicle detection. The experimental results show\nthat the proposed method maintains high detection accuracy while reducing the\ntrainable parameters by 40-80%. This work motivates further research toward\ngood priors for non-learnable weights that can make DL architectures more\nefficient without having to alter the network during or after training.",
    "categories": [
      "cs.CV",
      "cs.AI",
      "cs.LG"
    ],
    "primary_category": "cs.CV",
    "comment": "Published in: IEEE Transactions on Neural Networks and Learning\n  Systems Code: https://github.com/ckyrkou/STeP_Models ImageNet-16 Dataset:\n  https://zenodo.org/records/8027520",
    "pdf_url": "http://arxiv.org/pdf/2407.14831v1",
    "published_date": "2024-07-20 10:18:42 UTC",
    "updated_date": "2024-07-20 10:18:42 UTC"
  },
  {
    "arxiv_id": "2407.14823v2",
    "title": "Scaling Up Single Image Dehazing Algorithm by Cross-Data Vision Alignment for Richer Representation Learning and Beyond",
    "authors": [
      "Yukai Shi",
      "Zhipeng Weng",
      "Yupei Lin",
      "Cidan Shi",
      "Xiaojun Yang",
      "Liang Lin"
    ],
    "abstract": "In recent years, deep neural networks tasks have increasingly relied on\nhigh-quality image inputs. With the development of high-resolution\nrepresentation learning, the task of image dehazing has received significant\nattention. Previously, many methods collect diverse image data for large-scale\ntraining to boost the performance on a target scene. Ignoring the domain gap\nbetween different data, former de-hazing methods simply adopt multiple datasets\nfor explicit large-scale training, which often makes the methods themselves be\nviolated. To address this problem, we propose a novel method of cross-data\nvision alignment for richer representation learning to improve the existing\ndehazing methodology. Specifically, we call for the internal- and external\nknowledge should be further adapted with a self-supervised manner to fill up\nthe domain gap. By using cross-data external alignment, the datasets inherit\nsamples from different domains that are firmly aligned, making the model learn\nmore robust and generalizable features. By using the internal augmentation\nmethod, the model can fully exploit local information within the images, and\nthen obtaining more image details. To demonstrate the effectiveness of our\nproposed method, we conduct training on the Natural Image Dataset (NID).\nExperimental results show that our method clearly resolves the domain gap in\ndifferent dehazing datasets and presents a new pipeline for large-scale\ntraining in the dehazing task. Our approach significantly outperforms other\nadvanced methods in dehazing and produces dehazed images that are closest to\nreal haze-free images.",
    "categories": [
      "cs.CV",
      "cs.AI",
      "cs.LG",
      "cs.MM",
      "eess.IV"
    ],
    "primary_category": "cs.CV",
    "comment": "A cross-dataset vision alignment and augmentation technology is\n  proposed to boost generalizable feature learning in the de-hazing task",
    "pdf_url": "http://arxiv.org/pdf/2407.14823v2",
    "published_date": "2024-07-20 10:00:20 UTC",
    "updated_date": "2025-03-20 18:22:58 UTC"
  },
  {
    "arxiv_id": "2407.14811v1",
    "title": "Decoupled Prompt-Adapter Tuning for Continual Activity Recognition",
    "authors": [
      "Di Fu",
      "Thanh Vinh Vo",
      "Haozhe Ma",
      "Tze-Yun Leong"
    ],
    "abstract": "Action recognition technology plays a vital role in enhancing security\nthrough surveillance systems, enabling better patient monitoring in healthcare,\nproviding in-depth performance analysis in sports, and facilitating seamless\nhuman-AI collaboration in domains such as manufacturing and assistive\ntechnologies. The dynamic nature of data in these areas underscores the need\nfor models that can continuously adapt to new video data without losing\npreviously acquired knowledge, highlighting the critical role of advanced\ncontinual action recognition. To address these challenges, we propose Decoupled\nPrompt-Adapter Tuning (DPAT), a novel framework that integrates adapters for\ncapturing spatial-temporal information and learnable prompts for mitigating\ncatastrophic forgetting through a decoupled training strategy. DPAT uniquely\nbalances the generalization benefits of prompt tuning with the plasticity\nprovided by adapters in pretrained vision models, effectively addressing the\nchallenge of maintaining model performance amidst continuous data evolution\nwithout necessitating extensive finetuning. DPAT consistently achieves\nstate-of-the-art performance across several challenging action recognition\nbenchmarks, thus demonstrating the effectiveness of our model in the domain of\ncontinual action recognition.",
    "categories": [
      "cs.CV",
      "cs.AI"
    ],
    "primary_category": "cs.CV",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2407.14811v1",
    "published_date": "2024-07-20 08:56:04 UTC",
    "updated_date": "2024-07-20 08:56:04 UTC"
  },
  {
    "arxiv_id": "2407.14796v1",
    "title": "PASSION: Towards Effective Incomplete Multi-Modal Medical Image Segmentation with Imbalanced Missing Rates",
    "authors": [
      "Junjie Shi",
      "Caozhi Shang",
      "Zhaobin Sun",
      "Li Yu",
      "Xin Yang",
      "Zengqiang Yan"
    ],
    "abstract": "Incomplete multi-modal image segmentation is a fundamental task in medical\nimaging to refine deployment efficiency when only partial modalities are\navailable. However, the common practice that complete-modality data is visible\nduring model training is far from realistic, as modalities can have imbalanced\nmissing rates in clinical scenarios. In this paper, we, for the first time,\nformulate such a challenging setting and propose Preference-Aware\nSelf-diStillatION (PASSION) for incomplete multi-modal medical image\nsegmentation under imbalanced missing rates. Specifically, we first construct\npixel-wise and semantic-wise self-distillation to balance the optimization\nobjective of each modality. Then, we define relative preference to evaluate the\ndominance of each modality during training, based on which to design task-wise\nand gradient-wise regularization to balance the convergence rates of different\nmodalities. Experimental results on two publicly available multi-modal datasets\ndemonstrate the superiority of PASSION against existing approaches for modality\nbalancing. More importantly, PASSION is validated to work as a plug-and-play\nmodule for consistent performance improvement across different backbones. Code\nis available at https://github.com/Jun-Jie-Shi/PASSION.",
    "categories": [
      "cs.CV",
      "cs.AI"
    ],
    "primary_category": "cs.CV",
    "comment": "Accepted by ACM MM 2024",
    "pdf_url": "http://arxiv.org/pdf/2407.14796v1",
    "published_date": "2024-07-20 07:53:20 UTC",
    "updated_date": "2024-07-20 07:53:20 UTC"
  },
  {
    "arxiv_id": "2407.14790v2",
    "title": "Step-by-Step Reasoning to Solve Grid Puzzles: Where do LLMs Falter?",
    "authors": [
      "Nemika Tyagi",
      "Mihir Parmar",
      "Mohith Kulkarni",
      "Aswin RRV",
      "Nisarg Patel",
      "Mutsumi Nakamura",
      "Arindam Mitra",
      "Chitta Baral"
    ],
    "abstract": "Solving grid puzzles involves a significant amount of logical reasoning.\nHence, it is a good domain to evaluate the reasoning capability of a model\nwhich can then guide us to improve the reasoning ability of models. However,\nmost existing works evaluate only the final predicted answer of a puzzle,\nwithout delving into an in-depth analysis of the LLMs' reasoning chains (such\nas where they falter) or providing any finer metrics to evaluate them. Since\nLLMs may rely on simple heuristics or artifacts to predict the final answer, it\nis crucial to evaluate the generated reasoning chain beyond overall correctness\nmeasures, for accurately evaluating the reasoning abilities of LLMs. To this\nend, we first develop GridPuzzle, an evaluation dataset comprising 274\ngrid-based puzzles with different complexities. Second, we propose a new error\ntaxonomy derived from manual analysis of reasoning chains from LLMs including\nGPT-4, Claude-3, Gemini, Mistral, and Llama-2. Then, we develop an LLM-based\nframework for large-scale subjective evaluation (i.e., identifying errors) and\nan objective metric, PuzzleEval, to evaluate the correctness of reasoning\nchains. Evaluating reasoning chains from LLMs leads to several interesting\nfindings. We further show that existing prompting methods used for enhancing\nmodels' reasoning abilities do not improve performance on GridPuzzle. This\nhighlights the importance of understanding fine-grained errors and presents a\nchallenge for future research to enhance LLMs' puzzle-solving abilities by\ndeveloping methods that address these errors. Data and source code are\navailable at https://github.com/Mihir3009/GridPuzzle.",
    "categories": [
      "cs.CL",
      "cs.AI"
    ],
    "primary_category": "cs.CL",
    "comment": "Accepted at EMNLP 2024 Main",
    "pdf_url": "http://arxiv.org/pdf/2407.14790v2",
    "published_date": "2024-07-20 07:43:07 UTC",
    "updated_date": "2024-10-04 04:58:12 UTC"
  },
  {
    "arxiv_id": "2407.14789v1",
    "title": "PERCORE: A Deep Learning-Based Framework for Persian Spelling Correction with Phonetic Analysis",
    "authors": [
      "Seyed Mohammad Sadegh Dashti",
      "Amid Khatibi Bardsiri",
      "Mehdi Jafari Shahbazzadeh"
    ],
    "abstract": "This research introduces a state-of-the-art Persian spelling correction\nsystem that seamlessly integrates deep learning techniques with phonetic\nanalysis, significantly enhancing the accuracy and efficiency of natural\nlanguage processing (NLP) for Persian. Utilizing a fine-tuned language\nrepresentation model, our methodology effectively combines deep contextual\nanalysis with phonetic insights, adeptly correcting both non-word and real-word\nspelling errors. This strategy proves particularly effective in tackling the\nunique complexities of Persian spelling, including its elaborate morphology and\nthe challenge of homophony. A thorough evaluation on a wide-ranging dataset\nconfirms our system's superior performance compared to existing methods, with\nimpressive F1-Scores of 0.890 for detecting real-word errors and 0.905 for\ncorrecting them. Additionally, the system demonstrates a strong capability in\nnon-word error correction, achieving an F1-Score of 0.891. These results\nillustrate the significant benefits of incorporating phonetic insights into\ndeep learning models for spelling correction. Our contributions not only\nadvance Persian language processing by providing a versatile solution for a\nvariety of NLP applications but also pave the way for future research in the\nfield, emphasizing the critical role of phonetic analysis in developing\neffective spelling correction system.",
    "categories": [
      "cs.CL",
      "cs.AI"
    ],
    "primary_category": "cs.CL",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2407.14789v1",
    "published_date": "2024-07-20 07:41:04 UTC",
    "updated_date": "2024-07-20 07:41:04 UTC"
  },
  {
    "arxiv_id": "2407.14788v2",
    "title": "On the Design and Analysis of LLM-Based Algorithms",
    "authors": [
      "Yanxi Chen",
      "Yaliang Li",
      "Bolin Ding",
      "Jingren Zhou"
    ],
    "abstract": "We initiate a formal investigation into the design and analysis of LLM-based\nalgorithms, i.e. algorithms that contain one or multiple calls of large\nlanguage models (LLMs) as sub-routines and critically rely on the capabilities\nof LLMs. While LLM-based algorithms, ranging from basic LLM calls with prompt\nengineering to complicated LLM-powered agent systems and compound AI systems,\nhave achieved remarkable empirical success, the design and optimization of them\nhave mostly relied on heuristics and trial-and-errors, which is largely due to\na lack of formal and analytical study for these algorithms. To fill this gap,\nwe start by identifying the computational-graph representation of LLM-based\nalgorithms, the design principle of task decomposition, and some key\nabstractions, which then facilitate our formal analysis for the accuracy and\nefficiency of LLM-based algorithms, despite the black-box nature of LLMs.\nThrough extensive analytical and empirical investigation in a series of case\nstudies, we demonstrate that the proposed framework is broadly applicable to a\nwide range of scenarios and diverse patterns of LLM-based algorithms, such as\nparallel, hierarchical and recursive task decomposition. Our proposed framework\nholds promise for advancing LLM-based algorithms, by revealing the reasons\nbehind curious empirical phenomena, guiding the choices of hyperparameters,\npredicting the empirical performance of algorithms, and inspiring new algorithm\ndesign. To promote further study of LLM-based algorithms, we release our source\ncode at\nhttps://github.com/modelscope/agentscope/tree/main/examples/paper_llm_based_algorithm.",
    "categories": [
      "cs.LG",
      "cs.AI",
      "cs.CL"
    ],
    "primary_category": "cs.LG",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2407.14788v2",
    "published_date": "2024-07-20 07:39:07 UTC",
    "updated_date": "2024-09-26 10:21:33 UTC"
  },
  {
    "arxiv_id": "2407.14779v3",
    "title": "Do Generative AI Models Output Harm while Representing Non-Western Cultures: Evidence from A Community-Centered Approach",
    "authors": [
      "Sourojit Ghosh",
      "Pranav Narayanan Venkit",
      "Sanjana Gautam",
      "Shomir Wilson",
      "Aylin Caliskan"
    ],
    "abstract": "Our research investigates the impact of Generative Artificial Intelligence\n(GAI) models, specifically text-to-image generators (T2Is), on the\nrepresentation of non-Western cultures, with a focus on Indian contexts.\nDespite the transformative potential of T2Is in content creation, concerns have\narisen regarding biases that may lead to misrepresentations and\nmarginalizations. Through a community-centered approach and grounded theory\nanalysis of 5 focus groups from diverse Indian subcultures, we explore how T2I\noutputs to English prompts depict Indian culture and its subcultures,\nuncovering novel representational harms such as exoticism and cultural\nmisappropriation. These findings highlight the urgent need for inclusive and\nculturally sensitive T2I systems. We propose design guidelines informed by a\nsociotechnical perspective, aiming to address these issues and contribute to\nthe development of more equitable and representative GAI technologies globally.\nOur work also underscores the necessity of adopting a community-centered\napproach to comprehend the sociotechnical dynamics of these models,\ncomplementing existing work in this space while identifying and addressing the\npotential negative repercussions and harms that may arise when these models are\ndeployed on a global scale.",
    "categories": [
      "cs.CY",
      "cs.AI",
      "cs.HC"
    ],
    "primary_category": "cs.CY",
    "comment": "This is the pre-peer reviewed version, which has been accepted at the\n  7th AAAI ACM Conference on AI, Ethics, and Society, Oct. 21, 2024,\n  California, USA",
    "pdf_url": "http://arxiv.org/pdf/2407.14779v3",
    "published_date": "2024-07-20 07:01:37 UTC",
    "updated_date": "2024-08-03 21:49:57 UTC"
  },
  {
    "arxiv_id": "2407.14774v1",
    "title": "Intelligent Artistic Typography: A Comprehensive Review of Artistic Text Design and Generation",
    "authors": [
      "Yuhang Bai",
      "Zichuan Huang",
      "Wenshuo Gao",
      "Shuai Yang",
      "Jiaying Liu"
    ],
    "abstract": "Artistic text generation aims to amplify the aesthetic qualities of text\nwhile maintaining readability. It can make the text more attractive and better\nconvey its expression, thus enjoying a wide range of application scenarios such\nas social media display, consumer electronics, fashion, and graphic design.\nArtistic text generation includes artistic text stylization and semantic\ntypography. Artistic text stylization concentrates on the text effect overlaid\nupon the text, such as shadows, outlines, colors, glows, and textures. By\ncomparison, semantic typography focuses on the deformation of the characters to\nstrengthen their visual representation by mimicking the semantic understanding\nwithin the text. This overview paper provides an introduction to both artistic\ntext stylization and semantic typography, including the taxonomy, the key ideas\nof representative methods, and the applications in static and dynamic artistic\ntext generation. Furthermore, the dataset and evaluation metrics are\nintroduced, and the future directions of artistic text generation are\ndiscussed. A comprehensive list of artistic text generation models studied in\nthis review is available at\nhttps://github.com/williamyang1991/Awesome-Artistic-Typography/.",
    "categories": [
      "cs.CV",
      "cs.AI",
      "cs.GR"
    ],
    "primary_category": "cs.CV",
    "comment": "GitHub Page:\n  https://github.com/williamyang1991/Awesome-Artistic-Typography/",
    "pdf_url": "http://arxiv.org/pdf/2407.14774v1",
    "published_date": "2024-07-20 06:45:09 UTC",
    "updated_date": "2024-07-20 06:45:09 UTC"
  },
  {
    "arxiv_id": "2407.14768v1",
    "title": "Teach Harder, Learn Poorer: Rethinking Hard Sample Distillation for GNN-to-MLP Knowledge Distillation",
    "authors": [
      "Lirong Wu",
      "Yunfan Liu",
      "Haitao Lin",
      "Yufei Huang",
      "Stan Z. Li"
    ],
    "abstract": "To bridge the gaps between powerful Graph Neural Networks (GNNs) and\nlightweight Multi-Layer Perceptron (MLPs), GNN-to-MLP Knowledge Distillation\n(KD) proposes to distill knowledge from a well-trained teacher GNN into a\nstudent MLP. In this paper, we revisit the knowledge samples (nodes) in teacher\nGNNs from the perspective of hardness, and identify that hard sample\ndistillation may be a major performance bottleneck of existing graph KD\nalgorithms. The GNN-to-MLP KD involves two different types of hardness, one\nstudent-free knowledge hardness describing the inherent complexity of GNN\nknowledge, and the other student-dependent distillation hardness describing the\ndifficulty of teacher-to-student distillation. However, most of the existing\nwork focuses on only one of these aspects or regards them as one thing. This\npaper proposes a simple yet effective Hardness-aware GNN-to-MLP Distillation\n(HGMD) framework, which decouples the two hardnesses and estimates them using a\nnon-parametric approach. Finally, two hardness-aware distillation schemes\n(i.e., HGMD-weight and HGMD-mixup) are further proposed to distill\nhardness-aware knowledge from teacher GNNs into the corresponding nodes of\nstudent MLPs. As non-parametric distillation, HGMD does not involve any\nadditional learnable parameters beyond the student MLPs, but it still\noutperforms most of the state-of-the-art competitors. HGMD-mixup improves over\nthe vanilla MLPs by 12.95% and outperforms its teacher GNNs by 2.48% averaged\nover seven real-world datasets.",
    "categories": [
      "cs.LG",
      "cs.AI"
    ],
    "primary_category": "cs.LG",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2407.14768v1",
    "published_date": "2024-07-20 06:13:00 UTC",
    "updated_date": "2024-07-20 06:13:00 UTC"
  },
  {
    "arxiv_id": "2407.14767v2",
    "title": "I Need Help! Evaluating LLM's Ability to Ask for Users' Support: A Case Study on Text-to-SQL Generation",
    "authors": [
      "Cheng-Kuang Wu",
      "Zhi Rui Tam",
      "Chao-Chung Wu",
      "Chieh-Yen Lin",
      "Hung-yi Lee",
      "Yun-Nung Chen"
    ],
    "abstract": "This study explores the proactive ability of LLMs to seek user support. We\npropose metrics to evaluate the trade-off between performance improvements and\nuser burden, and investigate whether LLMs can determine when to request help\nunder varying information availability. Our experiments show that without\nexternal feedback, many LLMs struggle to recognize their need for user support.\nThe findings highlight the importance of external signals and provide insights\nfor future research on improving support-seeking strategies. Source code:\nhttps://github.com/appier-research/i-need-help",
    "categories": [
      "cs.CL",
      "cs.AI"
    ],
    "primary_category": "cs.CL",
    "comment": "Accepted by EMNLP 2024 Main Conference",
    "pdf_url": "http://arxiv.org/pdf/2407.14767v2",
    "published_date": "2024-07-20 06:12:29 UTC",
    "updated_date": "2024-09-30 01:45:34 UTC"
  },
  {
    "arxiv_id": "2408.00798v1",
    "title": "Golden-Retriever: High-Fidelity Agentic Retrieval Augmented Generation for Industrial Knowledge Base",
    "authors": [
      "Zhiyu An",
      "Xianzhong Ding",
      "Yen-Chun Fu",
      "Cheng-Chung Chu",
      "Yan Li",
      "Wan Du"
    ],
    "abstract": "This paper introduces Golden-Retriever, designed to efficiently navigate vast\nindustrial knowledge bases, overcoming challenges in traditional LLM\nfine-tuning and RAG frameworks with domain-specific jargon and context\ninterpretation. Golden-Retriever incorporates a reflection-based question\naugmentation step before document retrieval, which involves identifying jargon,\nclarifying its meaning based on context, and augmenting the question\naccordingly. Specifically, our method extracts and lists all jargon and\nabbreviations in the input question, determines the context against a\npre-defined list, and queries a jargon dictionary for extended definitions and\ndescriptions. This comprehensive augmentation ensures the RAG framework\nretrieves the most relevant documents by providing clear context and resolving\nambiguities, significantly improving retrieval accuracy. Evaluations using\nthree open-source LLMs on a domain-specific question-answer dataset demonstrate\nGolden-Retriever's superior performance, providing a robust solution for\nefficiently integrating and querying industrial knowledge bases.",
    "categories": [
      "cs.IR",
      "cs.AI",
      "cs.CL",
      "cs.DL"
    ],
    "primary_category": "cs.IR",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2408.00798v1",
    "published_date": "2024-07-20 06:10:46 UTC",
    "updated_date": "2024-07-20 06:10:46 UTC"
  },
  {
    "arxiv_id": "2407.14766v2",
    "title": "Implementing Fairness in AI Classification: The Role of Explainability",
    "authors": [
      "Thomas Souverain",
      "Johnathan Nguyen",
      "Nicolas Meric",
      "Paul Égré"
    ],
    "abstract": "In this paper, we propose a philosophical and experimental investigation of\nthe problem of AI fairness in classification. We argue that implementing\nfairness in AI classification involves more work than just operationalizing a\nfairness metric. It requires establishing the explainability of the\nclassification model chosen and of the principles behind it. Specifically, it\ninvolves making the training processes transparent, determining what outcomes\nthe fairness criteria actually produce, and assessing their trade-offs by\ncomparison with closely related models that would lead to a different outcome.\nTo exemplify this methodology, we trained a model and developed a tool for\ndisparity detection and fairness interventions, the package FairDream. While\nFairDream is set to enforce Demographic Parity, experiments reveal that it\nfulfills the constraint of Equalized Odds. The algorithm is thus more\nconservative than the user might expect. To justify this outcome, we first\nclarify the relation between Demographic Parity and Equalized Odds as fairness\ncriteria. We then explain FairDream's reweighting method and justify the\ntrade-offs reached by FairDream by a benchmark comparison with closely related\nGridSearch models. We draw conclusions regarding the way in which these\nexplanatory steps can make an AI model trustworthy.",
    "categories": [
      "cs.LG",
      "cs.AI",
      "cs.CY",
      "I.2.6; K.4.1; K.4.2"
    ],
    "primary_category": "cs.LG",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2407.14766v2",
    "published_date": "2024-07-20 06:06:24 UTC",
    "updated_date": "2025-03-24 05:27:33 UTC"
  },
  {
    "arxiv_id": "2407.14765v1",
    "title": "Data Augmentation in Graph Neural Networks: The Role of Generated Synthetic Graphs",
    "authors": [
      "Sumeyye Bas",
      "Kiymet Kaya",
      "Resul Tugay",
      "Sule Gunduz Oguducu"
    ],
    "abstract": "Graphs are crucial for representing interrelated data and aiding predictive\nmodeling by capturing complex relationships. Achieving high-quality graph\nrepresentation is important for identifying linked patterns, leading to\nimprovements in Graph Neural Networks (GNNs) to better capture data structures.\nHowever, challenges such as data scarcity, high collection costs, and ethical\nconcerns limit progress. As a result, generative models and data augmentation\nhave become more and more popular. This study explores using generated graphs\nfor data augmentation, comparing the performance of combining generated graphs\nwith real graphs, and examining the effect of different quantities of generated\ngraphs on graph classification tasks. The experiments show that balancing\nscalability and quality requires different generators based on graph size. Our\nresults introduce a new approach to graph data augmentation, ensuring\nconsistent labels and enhancing classification performance.",
    "categories": [
      "cs.LG",
      "cs.AI",
      "cs.DB",
      "cs.IT",
      "math.IT"
    ],
    "primary_category": "cs.LG",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2407.14765v1",
    "published_date": "2024-07-20 06:05:26 UTC",
    "updated_date": "2024-07-20 06:05:26 UTC"
  },
  {
    "arxiv_id": "2407.14743v1",
    "title": "Denoising Long- and Short-term Interests for Sequential Recommendation",
    "authors": [
      "Xinyu Zhang",
      "Beibei Li",
      "Beihong Jin"
    ],
    "abstract": "User interests can be viewed over different time scales, mainly including\nstable long-term preferences and changing short-term intentions, and their\ncombination facilitates the comprehensive sequential recommendation. However,\nexisting work that focuses on different time scales of user modeling has\nignored the negative effects of different time-scale noise, which hinders\ncapturing actual user interests and cannot be resolved by conventional\nsequential denoising methods. In this paper, we propose a Long- and Short-term\nInterest Denoising Network (LSIDN), which employs different encoders and\ntailored denoising strategies to extract long- and short-term interests,\nrespectively, achieving both comprehensive and robust user modeling.\nSpecifically, we employ a session-level interest extraction and evolution\nstrategy to avoid introducing inter-session behavioral noise into long-term\ninterest modeling; we also adopt contrastive learning equipped with a\nhomogeneous exchanging augmentation to alleviate the impact of unintentional\nbehavioral noise on short-term interest modeling. Results of experiments on two\npublic datasets show that LSIDN consistently outperforms state-of-the-art\nmodels and achieves significant robustness.",
    "categories": [
      "cs.IR",
      "cs.AI"
    ],
    "primary_category": "cs.IR",
    "comment": "9 pages, accepted by SDM 2024",
    "pdf_url": "http://arxiv.org/pdf/2407.14743v1",
    "published_date": "2024-07-20 03:52:14 UTC",
    "updated_date": "2024-07-20 03:52:14 UTC"
  },
  {
    "arxiv_id": "2407.14741v1",
    "title": "Orthogonal Hyper-category Guided Multi-interest Elicitation for Micro-video Matching",
    "authors": [
      "Beibei Li",
      "Beihong Jin",
      "Yisong Yu",
      "Yiyuan Zheng",
      "Jiageng Song",
      "Wei Zhuo",
      "Tao Xiang"
    ],
    "abstract": "Watching micro-videos is becoming a part of public daily life. Usually, user\nwatching behaviors are thought to be rooted in their multiple different\ninterests. In the paper, we propose a model named OPAL for micro-video\nmatching, which elicits a user's multiple heterogeneous interests by\ndisentangling multiple soft and hard interest embeddings from user\ninteractions. Moreover, OPAL employs a two-stage training strategy, in which\nthe pre-train is to generate soft interests from historical interactions under\nthe guidance of orthogonal hyper-categories of micro-videos and the fine-tune\nis to reinforce the degree of disentanglement among the interests and learn the\ntemporal evolution of each interest of each user. We conduct extensive\nexperiments on two real-world datasets. The results show that OPAL not only\nreturns diversified micro-videos but also outperforms six state-of-the-art\nmodels in terms of recall and hit rate.",
    "categories": [
      "cs.IR",
      "cs.AI"
    ],
    "primary_category": "cs.IR",
    "comment": "6 pages, accepted by ICME 2024",
    "pdf_url": "http://arxiv.org/pdf/2407.14741v1",
    "published_date": "2024-07-20 03:41:57 UTC",
    "updated_date": "2024-07-20 03:41:57 UTC"
  },
  {
    "arxiv_id": "2407.14738v1",
    "title": "Flatness-aware Sequential Learning Generates Resilient Backdoors",
    "authors": [
      "Hoang Pham",
      "The-Anh Ta",
      "Anh Tran",
      "Khoa D. Doan"
    ],
    "abstract": "Recently, backdoor attacks have become an emerging threat to the security of\nmachine learning models. From the adversary's perspective, the implanted\nbackdoors should be resistant to defensive algorithms, but some recently\nproposed fine-tuning defenses can remove these backdoors with notable efficacy.\nThis is mainly due to the catastrophic forgetting (CF) property of deep neural\nnetworks. This paper counters CF of backdoors by leveraging continual learning\n(CL) techniques. We begin by investigating the connectivity between a\nbackdoored and fine-tuned model in the loss landscape. Our analysis confirms\nthat fine-tuning defenses, especially the more advanced ones, can easily push a\npoisoned model out of the backdoor regions, making it forget all about the\nbackdoors. Based on this finding, we re-formulate backdoor training through the\nlens of CL and propose a novel framework, named Sequential Backdoor Learning\n(SBL), that can generate resilient backdoors. This framework separates the\nbackdoor poisoning process into two tasks: the first task learns a backdoored\nmodel, while the second task, based on the CL principles, moves it to a\nbackdoored region resistant to fine-tuning. We additionally propose to seek\nflatter backdoor regions via a sharpness-aware minimizer in the framework,\nfurther strengthening the durability of the implanted backdoor. Finally, we\ndemonstrate the effectiveness of our method through extensive empirical\nexperiments on several benchmark datasets in the backdoor domain. The source\ncode is available at https://github.com/mail-research/SBL-resilient-backdoors",
    "categories": [
      "cs.LG",
      "cs.AI",
      "cs.CR"
    ],
    "primary_category": "cs.LG",
    "comment": "ECCV 2024",
    "pdf_url": "http://arxiv.org/pdf/2407.14738v1",
    "published_date": "2024-07-20 03:30:05 UTC",
    "updated_date": "2024-07-20 03:30:05 UTC"
  },
  {
    "arxiv_id": "2407.14735v1",
    "title": "ECRTime: Ensemble Integration of Classification and Retrieval for Time Series Classification",
    "authors": [
      "Fan Zhao",
      "You Chen"
    ],
    "abstract": "Deep learning-based methods for Time Series Classification (TSC) typically\nutilize deep networks to extract features, which are then processed through a\ncombination of a Fully Connected (FC) layer and a SoftMax function. However, we\nhave observed the phenomenon of inter-class similarity and intra-class\ninconsistency in the datasets from the UCR archive and further analyzed how\nthis phenomenon adversely affects the \"FC+SoftMax\" paradigm. To address the\nissue, we introduce ECR, which, for the first time to our knowledge, applies\ndeep learning-based retrieval algorithm to the TSC problem and integrates\nclassification and retrieval models. Experimental results on 112 UCR datasets\ndemonstrate that ECR is state-of-the-art(sota) compared to existing deep\nlearning-based methods. Furthermore, we have developed a more precise\nclassifier, ECRTime, which is an ensemble of ECR. ECRTime surpasses the\ncurrently most accurate deep learning classifier, InceptionTime, in terms of\naccuracy, achieving this with reduced training time and comparable scalability.",
    "categories": [
      "cs.LG",
      "cs.AI",
      "cs.CV"
    ],
    "primary_category": "cs.LG",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2407.14735v1",
    "published_date": "2024-07-20 03:17:23 UTC",
    "updated_date": "2024-07-20 03:17:23 UTC"
  },
  {
    "arxiv_id": "2407.14733v1",
    "title": "Hard Prompts Made Interpretable: Sparse Entropy Regularization for Prompt Tuning with RL",
    "authors": [
      "Yunseon Choi",
      "Sangmin Bae",
      "Seonghyun Ban",
      "Minchan Jeong",
      "Chuheng Zhang",
      "Lei Song",
      "Li Zhao",
      "Jiang Bian",
      "Kee-Eung Kim"
    ],
    "abstract": "With the advent of foundation models, prompt tuning has positioned itself as\nan important technique for directing model behaviors and eliciting desired\nresponses. Prompt tuning regards selecting appropriate keywords included into\nthe input, thereby adapting to the downstream task without adjusting or\nfine-tuning the model parameters. There is a wide range of work in prompt\ntuning, from approaches that directly harness the backpropagated gradient\nsignals from the model, to those employing black-box optimization such as\nreinforcement learning (RL) methods. Our primary focus is on RLPrompt, which\naims to find optimal prompt tokens leveraging soft Q-learning. While the\nresults show promise, we have observed that the prompts frequently appear\nunnatural, which impedes their interpretability. We address this limitation by\nusing sparse Tsallis entropy regularization, a principled approach to filtering\nout unlikely tokens from consideration. We extensively evaluate our approach\nacross various tasks, including few-shot text classification, unsupervised text\nstyle transfer, and textual inversion from images. The results indicate a\nnotable improvement over baselines, highlighting the efficacy of our approach\nin addressing the challenges of prompt tuning. Moreover, we show that the\nprompts discovered using our method are more natural and interpretable compared\nto those from other baselines.",
    "categories": [
      "cs.LG",
      "cs.AI",
      "cs.CL"
    ],
    "primary_category": "cs.LG",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2407.14733v1",
    "published_date": "2024-07-20 03:10:19 UTC",
    "updated_date": "2024-07-20 03:10:19 UTC"
  },
  {
    "arxiv_id": "2407.14725v3",
    "title": "CrowdMAC: Masked Crowd Density Completion for Robust Crowd Density Forecasting",
    "authors": [
      "Ryo Fujii",
      "Ryo Hachiuma",
      "Hideo Saito"
    ],
    "abstract": "A crowd density forecasting task aims to predict how the crowd density map\nwill change in the future from observed past crowd density maps. However, the\npast crowd density maps are often incomplete due to the miss-detection of\npedestrians, and it is crucial to develop a robust crowd density forecasting\nmodel against the miss-detection. This paper presents a MAsked crowd density\nCompletion framework for crowd density forecasting (CrowdMAC), which is\nsimultaneously trained to forecast future crowd density maps from partially\nmasked past crowd density maps (i.e., forecasting maps from past maps with\nmiss-detection) while reconstructing the masked observation maps (i.e.,\nimputing past maps with miss-detection). Additionally, we propose\nTemporal-Density-aware Masking (TDM), which non-uniformly masks tokens in the\nobserved crowd density map, considering the sparsity of the crowd density maps\nand the informativeness of the subsequent frames for the forecasting task.\nMoreover, we introduce multi-task masking to enhance training efficiency. In\nthe experiments, CrowdMAC achieves state-of-the-art performance on seven\nlarge-scale datasets, including SDD, ETH-UCY, inD, JRDB, VSCrowd, FDST, and\ncroHD. We also demonstrate the robustness of the proposed method against both\nsynthetic and realistic miss-detections. The code is released at\nhttps://fujiry0.github.io/CrowdMAC-project-page.",
    "categories": [
      "cs.CV",
      "cs.AI",
      "cs.RO"
    ],
    "primary_category": "cs.CV",
    "comment": "Accepted to WACV 2025",
    "pdf_url": "http://arxiv.org/pdf/2407.14725v3",
    "published_date": "2024-07-20 02:18:43 UTC",
    "updated_date": "2024-11-27 06:04:20 UTC"
  },
  {
    "arxiv_id": "2407.14717v2",
    "title": "Differential Privacy of Cross-Attention with Provable Guarantee",
    "authors": [
      "Yingyu Liang",
      "Zhenmei Shi",
      "Zhao Song",
      "Yufa Zhou"
    ],
    "abstract": "Cross-attention has become a fundamental module nowadays in many important\nartificial intelligence applications, e.g., retrieval-augmented generation\n(RAG), system prompt, guided stable diffusion, and many more. Ensuring\ncross-attention privacy is crucial and urgently needed because its key and\nvalue matrices may contain sensitive information about model providers and\ntheir users. In this work, we design a novel differential privacy (DP) data\nstructure to address the privacy security of cross-attention with a theoretical\nguarantee. In detail, let $n$ be the input token length of system prompt/RAG\ndata, $d$ be the feature dimension, $0 < \\alpha \\le 1$ be the relative error\nparameter, $R$ be the maximum value of the query and key matrices, $R_w$ be the\nmaximum value of the value matrix, and $r,s,\\epsilon_s$ be parameters of\npolynomial kernel methods. Then, our data structure requires\n$\\widetilde{O}(ndr^2)$ memory consumption with $\\widetilde{O}(nr^2)$\ninitialization time complexity and $\\widetilde{O}(\\alpha^{-1} r^2)$ query time\ncomplexity for a single token query. In addition, our data structure can\nguarantee that the process of answering user query satisfies $(\\epsilon,\n\\delta)$-DP with $\\widetilde{O}(n^{-1} \\epsilon^{-1} \\alpha^{-1/2} R^{2s} R_w\nr^2)$ additive error and $n^{-1} (\\alpha + \\epsilon_s)$ relative error between\nour output and the true answer. Furthermore, our result is robust to adaptive\nqueries in which users can intentionally attack the cross-attention system. To\nour knowledge, this is the first work to provide DP for cross-attention and is\npromising to inspire more privacy algorithm design in large generative models\n(LGMs).",
    "categories": [
      "cs.LG",
      "cs.AI",
      "cs.CR"
    ],
    "primary_category": "cs.LG",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2407.14717v2",
    "published_date": "2024-07-20 01:02:27 UTC",
    "updated_date": "2024-10-15 04:19:15 UTC"
  },
  {
    "arxiv_id": "2407.14714v1",
    "title": "Unveiling the Decision-Making Process in Reinforcement Learning with Genetic Programming",
    "authors": [
      "Manuel Eberhardinger",
      "Florian Rupp",
      "Johannes Maucher",
      "Setareh Maghsudi"
    ],
    "abstract": "Despite tremendous progress, machine learning and deep learning still suffer\nfrom incomprehensible predictions. Incomprehensibility, however, is not an\noption for the use of (deep) reinforcement learning in the real world, as\nunpredictable actions can seriously harm the involved individuals. In this\nwork, we propose a genetic programming framework to generate explanations for\nthe decision-making process of already trained agents by imitating them with\nprograms. Programs are interpretable and can be executed to generate\nexplanations of why the agent chooses a particular action. Furthermore, we\nconduct an ablation study that investigates how extending the domain-specific\nlanguage by using library learning alters the performance of the method. We\ncompare our results with the previous state of the art for this problem and\nshow that we are comparable in performance but require much less hardware\nresources and computation time.",
    "categories": [
      "cs.AI",
      "cs.LG",
      "cs.NE"
    ],
    "primary_category": "cs.AI",
    "comment": "Accepted at: The Fifteenth International Conference on Swarm\n  Intelligence (ICSI'2024)",
    "pdf_url": "http://arxiv.org/pdf/2407.14714v1",
    "published_date": "2024-07-20 00:45:03 UTC",
    "updated_date": "2024-07-20 00:45:03 UTC"
  }
]