[
  {
    "arxiv_id": "2501.02138v1",
    "title": "Effective LLM-Driven Code Generation with Pythoness",
    "authors": [
      "Kyla H. Levin",
      "Kyle Gwilt",
      "Emery D. Berger",
      "Stephen N. Freund"
    ],
    "abstract": "The advent of large language models (LLMs) has paved the way for a new era of\nprogramming tools with both significant capabilities and risks, as the\ngenerated code lacks guarantees of correctness and reliability. Developers\nusing LLMs currently face the difficult task of optimizing, integrating, and\nmaintaining code generated by AI. We propose an embedded domain-specific\nlanguage (DSL), Pythoness, to address those challenges. In Pythoness,\ndevelopers program with LLMs at a higher level of abstraction. Rather than\ninteracting directly with generated code, developers using Pythoness operate at\nthe level of behavioral specifications when writing functions, classes, or an\nentire program. These specifications can take the form of unit tests and\nproperty-based tests, which may be expressed formally or in natural language.\nGuided by these specifications, Pythoness generates code that both passes the\ntests and can be continuously checked during execution. We posit that the\nPythoness approach lets developers harness the full potential of LLMs for code\ngeneration while substantially mitigating their inherent risks. We describe our\ncurrent prototype implementation of Pythoness and demonstrate that it can\nsuccessfully leverage a combination of tests and code generation to yield\nhigher quality code than specifications alone.",
    "categories": [
      "cs.PL",
      "cs.AI",
      "cs.SE"
    ],
    "primary_category": "cs.PL",
    "comment": "5 pages",
    "pdf_url": "http://arxiv.org/pdf/2501.02138v1",
    "published_date": "2025-01-03 23:14:46 UTC",
    "updated_date": "2025-01-03 23:14:46 UTC"
  },
  {
    "arxiv_id": "2501.02135v1",
    "title": "AVTrustBench: Assessing and Enhancing Reliability and Robustness in Audio-Visual LLMs",
    "authors": [
      "Sanjoy Chowdhury",
      "Sayan Nag",
      "Subhrajyoti Dasgupta",
      "Yaoting Wang",
      "Mohamed Elhoseiny",
      "Ruohan Gao",
      "Dinesh Manocha"
    ],
    "abstract": "With the rapid advancement of Multi-modal Large Language Models (MLLMs),\nseveral diagnostic benchmarks have recently been developed to assess these\nmodels' multi-modal reasoning proficiency. However, these benchmarks are\nrestricted to assessing primarily the visual aspect and do not examine the\nholistic audio-visual (AV) understanding. Moreover, currently, there are no\nbenchmarks that investigate the capabilities of AVLLMs to calibrate their\nresponses when presented with perturbed inputs. To this end, we introduce\nAudio-Visual Trustworthiness assessment Benchmark (AVTrustBench), comprising\n600K samples spanning over 9 meticulously crafted tasks, evaluating the\ncapabilities of AVLLMs across three distinct dimensions: Adversarial attack,\nCompositional reasoning, and Modality-specific dependency. Using our benchmark\nwe extensively evaluate 13 state-of-the-art AVLLMs. The findings reveal that\nthe majority of existing models fall significantly short of achieving\nhuman-like comprehension, offering valuable insights for future research\ndirections. To alleviate the limitations in the existing approaches, we further\npropose a robust, model-agnostic calibrated audio-visual preference\noptimization based training strategy CAVPref, obtaining a gain up to 30.19%\nacross all 9 tasks. We will publicly release our code and benchmark to\nfacilitate future research in this direction.",
    "categories": [
      "cs.CV",
      "cs.AI"
    ],
    "primary_category": "cs.CV",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2501.02135v1",
    "published_date": "2025-01-03 23:03:24 UTC",
    "updated_date": "2025-01-03 23:03:24 UTC"
  },
  {
    "arxiv_id": "2501.02132v2",
    "title": "A hybrid marketplace of ideas",
    "authors": [
      "Tomer Jordi Chaffer",
      "Dontrail Cotlage",
      "Justin Goldston"
    ],
    "abstract": "The convergence of humans and artificial intelligence systems introduces new\ndynamics into the cultural and intellectual landscape. Complementing emerging\ncultural evolution concepts such as machine culture, AI agents represent a\nsignificant techno-sociological development, particularly within the\nanthropological study of Web3 as a community focused on decentralization\nthrough blockchain. Despite their growing presence, the cultural significance\nof AI agents remains largely unexplored in academic literature. Toward this\nend, we conceived hybrid netnography, a novel interdisciplinary approach that\nexamines the cultural and intellectual dynamics within digital ecosystems by\nanalyzing the interactions and contributions of both human and AI agents as\nco-participants in shaping narratives, ideas, and cultural artifacts. We argue\nthat, within the Web3 community on the social media platform X, these agents\nchallenge traditional notions of participation and influence in public\ndiscourse, creating a hybrid marketplace of ideas, a conceptual space where\nhuman and AI generated ideas coexist and compete for attention. We examine the\ncurrent state of AI agents in idea generation, propagation, and engagement,\npositioning their role as cultural agents through the lens of memetics and\nencouraging further inquiry into their cultural and societal impact.\nAdditionally, we address the implications of this paradigm for privacy,\nintellectual property, and governance, highlighting the societal and legal\nchallenges of integrating AI agents into the hybrid marketplace of ideas.",
    "categories": [
      "cs.CY",
      "cs.AI",
      "cs.ET"
    ],
    "primary_category": "cs.CY",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2501.02132v2",
    "published_date": "2025-01-03 22:53:43 UTC",
    "updated_date": "2025-01-08 16:26:36 UTC"
  },
  {
    "arxiv_id": "2502.15696v1",
    "title": "Integrating Domain Knowledge into Large Language Models for Enhanced Fashion Recommendations",
    "authors": [
      "Zhan Shi",
      "Shanglin Yang"
    ],
    "abstract": "Fashion, deeply rooted in sociocultural dynamics, evolves as individuals\nemulate styles popularized by influencers and iconic figures. In the quest to\nreplicate such refined tastes using artificial intelligence, traditional\nfashion ensemble methods have primarily used supervised learning to imitate the\ndecisions of style icons, which falter when faced with distribution shifts,\nleading to style replication discrepancies triggered by slight variations in\ninput. Meanwhile, large language models (LLMs) have become prominent across\nvarious sectors, recognized for their user-friendly interfaces, strong\nconversational skills, and advanced reasoning capabilities. To address these\nchallenges, we introduce the Fashion Large Language Model (FLLM), which employs\nauto-prompt generation training strategies to enhance its capacity for\ndelivering personalized fashion advice while retaining essential domain\nknowledge. Additionally, by integrating a retrieval augmentation technique\nduring inference, the model can better adjust to individual preferences. Our\nresults show that this approach surpasses existing models in accuracy,\ninterpretability, and few-shot learning capabilities.",
    "categories": [
      "cs.CL",
      "cs.AI",
      "cs.IR",
      "cs.LG"
    ],
    "primary_category": "cs.CL",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2502.15696v1",
    "published_date": "2025-01-03 21:49:44 UTC",
    "updated_date": "2025-01-03 21:49:44 UTC"
  },
  {
    "arxiv_id": "2501.02114v1",
    "title": "Relaxation-assisted reverse annealing on nonnegative/binary matrix factorization",
    "authors": [
      "Renichiro Haba",
      "Masayuki Ohzeki",
      "Kazuyuki Tanaka"
    ],
    "abstract": "Quantum annealing has garnered significant attention as meta-heuristics\ninspired by quantum physics for combinatorial optimization problems. Among its\nmany applications, nonnegative/binary matrix factorization stands out for its\ncomplexity and relevance in unsupervised machine learning. The use of reverse\nannealing, a derivative procedure of quantum annealing to prioritize the search\nin a vicinity under a given initial state, helps improve its optimization\nperformance in matrix factorization. This study proposes an improved strategy\nthat integrates reverse annealing with a linear programming relaxation\ntechnique. Using relaxed solutions as the initial configuration for reverse\nannealing, we demonstrate improvements in optimization performance comparable\nto the exact optimization methods. Our experiments on facial image datasets\nshow that our method provides better convergence than known reverse annealing\nmethods. Furthermore, we investigate the effectiveness of relaxation-based\ninitialization methods on randomized datasets, demonstrating a relationship\nbetween the relaxed solution and the optimal solution. This research\nunderscores the potential of combining reverse annealing and classical\noptimization strategies to enhance optimization performance.",
    "categories": [
      "quant-ph",
      "cond-mat.stat-mech",
      "cs.AI",
      "cs.LG"
    ],
    "primary_category": "quant-ph",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2501.02114v1",
    "published_date": "2025-01-03 21:48:35 UTC",
    "updated_date": "2025-01-03 21:48:35 UTC"
  },
  {
    "arxiv_id": "2501.02112v1",
    "title": "Siamese Networks for Cat Re-Identification: Exploring Neural Models for Cat Instance Recognition",
    "authors": [
      "Tobias Trein",
      "Luan Fonseca Garcia"
    ],
    "abstract": "Street cats in urban areas often rely on human intervention for survival,\nleading to challenges in population control and welfare management. In April\n2023, Hello Inc., a Chinese urban mobility company, launched the Hello Street\nCat initiative to address these issues. The project deployed over 21,000 smart\nfeeding stations across 14 cities in China, integrating livestreaming cameras\nand treat dispensers activated through user donations. It also promotes the\nTrap-Neuter-Return (TNR) method, supported by a community-driven platform,\nHelloStreetCatWiki, where volunteers catalog and identify cats. However, manual\nidentification is inefficient and unsustainable, creating a need for automated\nsolutions. This study explores Deep Learning-based models for re-identifying\nstreet cats in the Hello Street Cat initiative. A dataset of 2,796 images of 69\ncats was used to train Siamese Networks with EfficientNetB0, MobileNet and\nVGG16 as base models, evaluated under contrastive and triplet loss functions.\nVGG16 paired with contrastive loss emerged as the most effective configuration,\nachieving up to 97% accuracy and an F1 score of 0.9344 during testing. The\napproach leverages image augmentation and dataset refinement to overcome\nchallenges posed by limited data and diverse visual variations. These findings\nunderscore the potential of automated cat re-identification to streamline\npopulation monitoring and welfare efforts. By reducing reliance on manual\nprocesses, the method offers a scalable and reliable solution for\ncommunitydriven initiatives. Future research will focus on expanding datasets\nand developing real-time implementations to enhance practicality in large-scale\ndeployments.",
    "categories": [
      "cs.CV",
      "cs.AI",
      "I.2.10"
    ],
    "primary_category": "cs.CV",
    "comment": "8 pages, 3 figures, 7 tables",
    "pdf_url": "http://arxiv.org/pdf/2501.02112v1",
    "published_date": "2025-01-03 21:37:49 UTC",
    "updated_date": "2025-01-03 21:37:49 UTC"
  },
  {
    "arxiv_id": "2501.02107v1",
    "title": "Online Detection of Water Contamination Under Concept Drift",
    "authors": [
      "Jin Li",
      "Kleanthis Malialis",
      "Stelios G. Vrachimis",
      "Marios M. Polycarpou"
    ],
    "abstract": "Water Distribution Networks (WDNs) are vital infrastructures, and\ncontamination poses serious public health risks. Harmful substances can\ninteract with disinfectants like chlorine, making chlorine monitoring essential\nfor detecting contaminants. However, chlorine sensors often become unreliable\nand require frequent calibration. This study introduces the Dual-Threshold\nAnomaly and Drift Detection (AD&DD) method, an unsupervised approach combining\na dual-threshold drift detection mechanism with an LSTM-based Variational\nAutoencoder(LSTM-VAE) for real-time contamination detection. Tested on two\nrealistic WDNs, AD&DD effectively identifies anomalies with sensor offsets as\nconcept drift, and outperforms other methods. A proposed decentralized\narchitecture enables accurate contamination detection and localization by\ndeploying AD&DD on selected nodes.",
    "categories": [
      "cs.LG",
      "cs.AI"
    ],
    "primary_category": "cs.LG",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2501.02107v1",
    "published_date": "2025-01-03 21:29:09 UTC",
    "updated_date": "2025-01-03 21:29:09 UTC"
  },
  {
    "arxiv_id": "2501.04040v2",
    "title": "A Survey on Large Language Models with some Insights on their Capabilities and Limitations",
    "authors": [
      "Andrea Matarazzo",
      "Riccardo Torlone"
    ],
    "abstract": "The rapid advancement of artificial intelligence, particularly with the\ndevelopment of Large Language Models (LLMs) built on the transformer\narchitecture, has redefined the capabilities of natural language processing.\nThese models now exhibit remarkable performance across various language-related\ntasks, such as text generation, question answering, translation, and\nsummarization, often rivaling human-like comprehension. More intriguingly, LLMs\nhave demonstrated emergent abilities extending beyond their core functions,\nshowing proficiency in tasks like commonsense reasoning, code generation, and\narithmetic. This survey paper explores the foundational components, scaling\nmechanisms, and architectural strategies that drive these capabilities.\nEmphasizing models like GPT and LLaMA, we analyze the impact of exponential\ndata and computational growth on LLM performance, while also addressing the\ntrade-offs associated with scaling. We also examine LLM applications across\nsectors, such as healthcare, finance, education, and law, highlighting their\nadaptability and potential to solve domain-specific challenges. Central to this\nwork are the questions of how LLMs generalize across diverse tasks, exhibit\nplanning, and reasoning abilities, and whether these emergent abilities can be\nsystematically elicited or enhanced. In particular, we provide some insights\ninto the CoT (Chain of Thought) and PoT (Plan of Thought) abilities within\nLLMs, focusing on how pre-training data influences their emergence.\nAdditionally, we investigate LLM-modulo frameworks that integrate external\nsystems, allowing LLMs to handle complex, dynamic tasks. By analyzing these\nfactors, this paper aims to foster the ongoing discussion on the capabilities\nand limits of LLMs, promoting their responsible development and application in\nnovel and increasingly complex environments.",
    "categories": [
      "cs.CL",
      "cs.AI",
      "cs.LG",
      "cs.NE",
      "I.2.7; I.2.6"
    ],
    "primary_category": "cs.CL",
    "comment": "174 pages, to be submitted to a journal in a shorter version. It\n  includes figures taken from papers by other authors. All the sources have\n  been referenced. arXiv admin note: text overlap with arXiv:2303.18223 by\n  other authors",
    "pdf_url": "http://arxiv.org/pdf/2501.04040v2",
    "published_date": "2025-01-03 21:04:49 UTC",
    "updated_date": "2025-02-09 08:00:36 UTC"
  },
  {
    "arxiv_id": "2501.02089v1",
    "title": "On the Statistical Complexity for Offline and Low-Adaptive Reinforcement Learning with Structures",
    "authors": [
      "Ming Yin",
      "Mengdi Wang",
      "Yu-Xiang Wang"
    ],
    "abstract": "This article reviews the recent advances on the statistical foundation of\nreinforcement learning (RL) in the offline and low-adaptive settings. We will\nstart by arguing why offline RL is the appropriate model for almost any\nreal-life ML problems, even if they have nothing to do with the recent AI\nbreakthroughs that use RL. Then we will zoom into two fundamental problems of\noffline RL: offline policy evaluation (OPE) and offline policy learning (OPL).\nIt may be surprising to people that tight bounds for these problems were not\nknown even for tabular and linear cases until recently. We delineate the\ndifferences between worst-case minimax bounds and instance-dependent bounds. We\nalso cover key algorithmic ideas and proof techniques behind near-optimal\ninstance-dependent methods in OPE and OPL. Finally, we discuss the limitations\nof offline RL and review a burgeoning problem of \\emph{low-adaptive\nexploration} which addresses these limitations by providing a sweet middle\nground between offline and online RL.",
    "categories": [
      "cs.LG",
      "cs.AI"
    ],
    "primary_category": "cs.LG",
    "comment": "Review Article",
    "pdf_url": "http://arxiv.org/pdf/2501.02089v1",
    "published_date": "2025-01-03 20:27:53 UTC",
    "updated_date": "2025-01-03 20:27:53 UTC"
  },
  {
    "arxiv_id": "2501.02068v3",
    "title": "The interplay between domain specialization and model size",
    "authors": [
      "Roseval Malaquias Junior",
      "Ramon Pires",
      "Thales Sales Almeida",
      "Kenzo Sakiyama",
      "Roseli A. F. Romero",
      "Rodrigo Nogueira"
    ],
    "abstract": "Scaling laws for language models have often focused on finding the optimal\nmodel size and token count for training from scratch. However, achieving this\noptimal balance requires significant compute resources due to the extensive\ndata demands when training models from randomly-initialized weights. Continued\npretraining offers a cost-effective alternative, leveraging the compute\ninvestment from pretrained models to incorporate new knowledge without\nrequiring extensive new data. Recent findings suggest that data quality\ninfluences constants in scaling laws, thereby altering the optimal\nparameter-token allocation ratio. Building on this insight, we investigate the\ninterplay between domain specialization and model size during continued\npretraining under compute-constrained scenarios. Our goal is to identify an\noptimal training regime for this scenario and detect patterns in this interplay\nthat can be generalized across different model sizes and domains. To compare\ngeneral and specialized training, we filtered a web-based dataset to extract\ndata from three domains: legal, medical, and accounting. We pretrained models\nwith 1.5B, 3B, 7B, and 14B parameters on both the unfiltered and filtered\ndatasets, then evaluated their performance on domain-specific exams. Results\nshow that as model size increases, specialized models outperform general models\nwhile requiring less training compute. Additionally, their growing compute\nefficiency leads to reduced forgetting of previously learned knowledge.",
    "categories": [
      "cs.CL",
      "cs.AI"
    ],
    "primary_category": "cs.CL",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2501.02068v3",
    "published_date": "2025-01-03 19:28:53 UTC",
    "updated_date": "2025-03-29 17:18:43 UTC"
  },
  {
    "arxiv_id": "2501.02064v2",
    "title": "ArtCrafter: Text-Image Aligning Style Transfer via Embedding Reframing",
    "authors": [
      "Nisha Huang",
      "Kaer Huang",
      "Yifan Pu",
      "Jiangshan Wang",
      "Jie Guo",
      "Yiqiang Yan",
      "Xiu Li",
      "Tong-Yee Lee"
    ],
    "abstract": "Recent years have witnessed significant advancements in text-guided style\ntransfer, primarily attributed to innovations in diffusion models. These models\nexcel in conditional guidance, utilizing text or images to direct the sampling\nprocess. However, despite their capabilities, direct conditional guidance\napproaches often face challenges in balancing the expressiveness of textual\nsemantics with the diversity of output results while capturing stylistic\nfeatures. To address these challenges, we introduce ArtCrafter, a novel\nframework for text-to-image style transfer. Specifically, we introduce an\nattention-based style extraction module, meticulously engineered to capture the\nsubtle stylistic elements within an image. This module features a multi-layer\narchitecture that leverages the capabilities of perceiver attention mechanisms\nto integrate fine-grained information. Additionally, we present a novel\ntext-image aligning augmentation component that adeptly balances control over\nboth modalities, enabling the model to efficiently map image and text\nembeddings into a shared feature space. We achieve this through attention\noperations that enable smooth information flow between modalities. Lastly, we\nincorporate an explicit modulation that seamlessly blends multimodal enhanced\nembeddings with original embeddings through an embedding reframing design,\nempowering the model to generate diverse outputs. Extensive experiments\ndemonstrate that ArtCrafter yields impressive results in visual stylization,\nexhibiting exceptional levels of stylistic intensity, controllability, and\ndiversity.",
    "categories": [
      "cs.CV",
      "cs.AI"
    ],
    "primary_category": "cs.CV",
    "comment": "13 pages, 17 figures, submitted to a journal",
    "pdf_url": "http://arxiv.org/pdf/2501.02064v2",
    "published_date": "2025-01-03 19:17:27 UTC",
    "updated_date": "2025-04-17 12:49:56 UTC"
  },
  {
    "arxiv_id": "2501.01951v3",
    "title": "MixGCN: Scalable GCN Training by Mixture of Parallelism and Mixture of Accelerators",
    "authors": [
      "Cheng Wan",
      "Runkai Tao",
      "Zheng Du",
      "Yang Katie Zhao",
      "Yingyan Celine Lin"
    ],
    "abstract": "Graph convolutional networks (GCNs) have demonstrated superiority in\ngraph-based learning tasks. However, training GCNs on full graphs is\nparticularly challenging, due to the following two challenges: (1) the\nassociated feature tensors can easily explode the memory and block the\ncommunication bandwidth of modern accelerators, and (2) the computation\nworkflow in training GCNs alternates between sparse and dense matrix\noperations, complicating the efficient utilization of computational resources.\nExisting solutions for scalable distributed full-graph GCN training mostly\nadopt partition parallelism, which is unsatisfactory as they only partially\naddress the first challenge while incurring scaled-out communication volume. To\nthis end, we propose MixGCN aiming to simultaneously address both the\naforementioned challenges towards GCN training. To tackle the first challenge,\nMixGCN integrates mixture of parallelism. Both theoretical and empirical\nanalysis verify its constant communication volumes and enhanced balanced\nworkload; For handling the second challenge, we consider mixture of\naccelerators (i.e., sparse and dense accelerators) with a dedicated accelerator\nfor GCN training and a fine-grain pipeline. Extensive experiments show that\nMixGCN achieves boosted training efficiency and scalability.",
    "categories": [
      "cs.LG",
      "cs.AI"
    ],
    "primary_category": "cs.LG",
    "comment": "15 pages, 12 figures, 5 tables",
    "pdf_url": "http://arxiv.org/pdf/2501.01951v3",
    "published_date": "2025-01-03 18:54:46 UTC",
    "updated_date": "2025-02-24 22:02:47 UTC"
  },
  {
    "arxiv_id": "2501.01950v4",
    "title": "MADGEN: Mass-Spec attends to De Novo Molecular generation",
    "authors": [
      "Yinkai Wang",
      "Xiaohui Chen",
      "Liping Liu",
      "Soha Hassoun"
    ],
    "abstract": "The annotation (assigning structural chemical identities) of MS/MS spectra\nremains a significant challenge due to the enormous molecular diversity in\nbiological samples and the limited scope of reference databases. Currently, the\nvast majority of spectral measurements remain in the \"dark chemical space\"\nwithout structural annotations. To improve annotation, we propose MADGEN\n(Mass-spec Attends to De Novo Molecular GENeration), a scaffold-based method\nfor de novo molecular structure generation guided by mass spectrometry data.\nMADGEN operates in two stages: scaffold retrieval and spectra-conditioned\nmolecular generation starting with the scaffold. In the first stage, given an\nMS/MS spectrum, we formulate scaffold retrieval as a ranking problem and employ\ncontrastive learning to align mass spectra with candidate molecular scaffolds.\nIn the second stage, starting from the retrieved scaffold, we employ the MS/MS\nspectrum to guide an attention-based generative model to generate the final\nmolecule. Our approach constrains the molecular generation search space,\nreducing its complexity and improving generation accuracy. We evaluate MADGEN\non three datasets (NIST23, CANOPUS, and MassSpecGym) and evaluate MADGEN's\nperformance with a predictive scaffold retriever and with an oracle retriever.\nWe demonstrate the effectiveness of using attention to integrate spectral\ninformation throughout the generation process to achieve strong results with\nthe oracle retriever.",
    "categories": [
      "cs.LG",
      "cs.AI"
    ],
    "primary_category": "cs.LG",
    "comment": "ICLR 2025",
    "pdf_url": "http://arxiv.org/pdf/2501.01950v4",
    "published_date": "2025-01-03 18:54:26 UTC",
    "updated_date": "2025-04-29 16:27:32 UTC"
  },
  {
    "arxiv_id": "2501.01945v2",
    "title": "Cold-Start Recommendation towards the Era of Large Language Models (LLMs): A Comprehensive Survey and Roadmap",
    "authors": [
      "Weizhi Zhang",
      "Yuanchen Bei",
      "Liangwei Yang",
      "Henry Peng Zou",
      "Peilin Zhou",
      "Aiwei Liu",
      "Yinghui Li",
      "Hao Chen",
      "Jianling Wang",
      "Yu Wang",
      "Feiran Huang",
      "Sheng Zhou",
      "Jiajun Bu",
      "Allen Lin",
      "James Caverlee",
      "Fakhri Karray",
      "Irwin King",
      "Philip S. Yu"
    ],
    "abstract": "Cold-start problem is one of the long-standing challenges in recommender\nsystems, focusing on accurately modeling new or interaction-limited users or\nitems to provide better recommendations. Due to the diversification of internet\nplatforms and the exponential growth of users and items, the importance of\ncold-start recommendation (CSR) is becoming increasingly evident. At the same\ntime, large language models (LLMs) have achieved tremendous success and possess\nstrong capabilities in modeling user and item information, providing new\npotential for cold-start recommendations. However, the research community on\nCSR still lacks a comprehensive review and reflection in this field. Based on\nthis, in this paper, we stand in the context of the era of large language\nmodels and provide a comprehensive review and discussion on the roadmap,\nrelated literature, and future directions of CSR. Specifically, we have\nconducted an exploration of the development path of how existing CSR utilizes\ninformation, from content features, graph relations, and domain information, to\nthe world knowledge possessed by large language models, aiming to provide new\ninsights for both the research and industrial communities on CSR. Related\nresources of cold-start recommendations are collected and continuously updated\nfor the community in\nhttps://github.com/YuanchenBei/Awesome-Cold-Start-Recommendation.",
    "categories": [
      "cs.IR",
      "cs.AI"
    ],
    "primary_category": "cs.IR",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2501.01945v2",
    "published_date": "2025-01-03 18:51:18 UTC",
    "updated_date": "2025-01-16 18:53:23 UTC"
  },
  {
    "arxiv_id": "2501.02045v1",
    "title": "METAGENE-1: Metagenomic Foundation Model for Pandemic Monitoring",
    "authors": [
      "Ollie Liu",
      "Sami Jaghouar",
      "Johannes Hagemann",
      "Shangshang Wang",
      "Jason Wiemels",
      "Jeff Kaufman",
      "Willie Neiswanger"
    ],
    "abstract": "We pretrain METAGENE-1, a 7-billion-parameter autoregressive transformer\nmodel, which we refer to as a metagenomic foundation model, on a novel corpus\nof diverse metagenomic DNA and RNA sequences comprising over 1.5 trillion base\npairs. This dataset is sourced from a large collection of human wastewater\nsamples, processed and sequenced using deep metagenomic (next-generation)\nsequencing methods. Unlike genomic models that focus on individual genomes or\ncurated sets of specific species, the aim of METAGENE-1 is to capture the full\ndistribution of genomic information present within this wastewater, to aid in\ntasks relevant to pandemic monitoring and pathogen detection. We carry out\nbyte-pair encoding (BPE) tokenization on our dataset, tailored for metagenomic\nsequences, and then pretrain our model. In this paper, we first detail the\npretraining dataset, tokenization strategy, and model architecture,\nhighlighting the considerations and design choices that enable the effective\nmodeling of metagenomic data. We then show results of pretraining this model on\nour metagenomic dataset, providing details about our losses, system metrics,\nand training stability over the course of pretraining. Finally, we demonstrate\nthe performance of METAGENE-1, which achieves state-of-the-art results on a set\nof genomic benchmarks and new evaluations focused on human-pathogen detection\nand genomic sequence embedding, showcasing its potential for public health\napplications in pandemic monitoring, biosurveillance, and early detection of\nemerging health threats.",
    "categories": [
      "q-bio.GN",
      "cs.AI",
      "cs.CL",
      "cs.LG"
    ],
    "primary_category": "q-bio.GN",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2501.02045v1",
    "published_date": "2025-01-03 18:44:43 UTC",
    "updated_date": "2025-01-03 18:44:43 UTC"
  },
  {
    "arxiv_id": "2501.02044v1",
    "title": "Advancing Pancreatic Cancer Prediction with a Next Visit Token Prediction Head on top of Med-BERT",
    "authors": [
      "Jianping He",
      "Laila Rasmy",
      "Degui Zhi",
      "Cui Tao"
    ],
    "abstract": "Background: Recently, numerous foundation models pretrained on extensive data\nhave demonstrated efficacy in disease prediction using Electronic Health\nRecords (EHRs). However, there remains some unanswered questions on how to best\nutilize such models especially with very small fine-tuning cohorts. Methods: We\nutilized Med-BERT, an EHR-specific foundation model, and reformulated the\ndisease binary prediction task into a token prediction task and a next visit\nmask token prediction task to align with Med-BERT's pretraining task format in\norder to improve the accuracy of pancreatic cancer (PaCa) prediction in both\nfew-shot and fully supervised settings. Results: The reformulation of the task\ninto a token prediction task, referred to as Med-BERT-Sum, demonstrates\nslightly superior performance in both few-shot scenarios and larger data\nsamples. Furthermore, reformulating the prediction task as a Next Visit Mask\nToken Prediction task (Med-BERT-Mask) significantly outperforms the\nconventional Binary Classification (BC) prediction task (Med-BERT-BC) by 3% to\n7% in few-shot scenarios with data sizes ranging from 10 to 500 samples. These\nfindings highlight that aligning the downstream task with Med-BERT's\npretraining objectives substantially enhances the model's predictive\ncapabilities, thereby improving its effectiveness in predicting both rare and\ncommon diseases. Conclusion: Reformatting disease prediction tasks to align\nwith the pretraining of foundation models enhances prediction accuracy, leading\nto earlier detection and timely intervention. This approach improves treatment\neffectiveness, survival rates, and overall patient outcomes for PaCa and\npotentially other cancers.",
    "categories": [
      "cs.CL",
      "cs.AI"
    ],
    "primary_category": "cs.CL",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2501.02044v1",
    "published_date": "2025-01-03 18:32:05 UTC",
    "updated_date": "2025-01-03 18:32:05 UTC"
  },
  {
    "arxiv_id": "2501.01933v1",
    "title": "Abstractive Text Summarization for Contemporary Sanskrit Prose: Issues and Challenges",
    "authors": [
      "Shagun Sinha"
    ],
    "abstract": "This thesis presents Abstractive Text Summarization models for contemporary\nSanskrit prose. The first chapter, titled Introduction, presents the motivation\nbehind this work, the research questions, and the conceptual framework.\nSanskrit is a low-resource inflectional language. The key research question\nthat this thesis investigates is what the challenges in developing an\nabstractive TS for Sanskrit. To answer the key research questions,\nsub-questions based on four different themes have been posed in this work. The\nsecond chapter, Literature Review, surveys the previous works done. The third\nchapter, data preparation, answers the remaining three questions from the third\ntheme. It reports the data collection and preprocessing challenges for both\nlanguage model and summarization model trainings. The fourth chapter reports\nthe training and inference of models and the results obtained therein. This\nresearch has initiated a pipeline for Sanskrit abstractive text summarization\nand has reported the challenges faced at every stage of the development. The\nresearch questions based on every theme have been answered to answer the key\nresearch question.",
    "categories": [
      "cs.CL",
      "cs.AI"
    ],
    "primary_category": "cs.CL",
    "comment": "PhD Thesis",
    "pdf_url": "http://arxiv.org/pdf/2501.01933v1",
    "published_date": "2025-01-03 18:12:13 UTC",
    "updated_date": "2025-01-03 18:12:13 UTC"
  },
  {
    "arxiv_id": "2501.03183v1",
    "title": "Classifier-Guided Captioning Across Modalities",
    "authors": [
      "Ariel Shaulov",
      "Tal Shaharabany",
      "Eitan Shaar",
      "Gal Chechik",
      "Lior Wolf"
    ],
    "abstract": "Most current captioning systems use language models trained on data from\nspecific settings, such as image-based captioning via Amazon Mechanical Turk,\nlimiting their ability to generalize to other modality distributions and\ncontexts. This limitation hinders performance in tasks like audio or video\ncaptioning, where different semantic cues are needed. Addressing this challenge\nis crucial for creating more adaptable and versatile captioning frameworks\napplicable across diverse real-world contexts. In this work, we introduce a\nmethod to adapt captioning networks to the semantics of alternative settings,\nsuch as capturing audibility in audio captioning, where it is crucial to\ndescribe sounds and their sources. Our framework consists of two main\ncomponents: (i) a frozen captioning system incorporating a language model (LM),\nand (ii) a text classifier that guides the captioning system. The classifier is\ntrained on a dataset automatically generated by GPT-4, using tailored prompts\nspecifically designed to enhance key aspects of the generated captions.\nImportantly, the framework operates solely during inference, eliminating the\nneed for further training of the underlying captioning model. We evaluate the\nframework on various models and modalities, with a focus on audio captioning,\nand report promising results. Notably, when combined with an existing zero-shot\naudio captioning system, our framework improves its quality and sets\nstate-of-the-art performance in zero-shot audio captioning.",
    "categories": [
      "cs.CL",
      "cs.AI",
      "cs.SD",
      "eess.AS"
    ],
    "primary_category": "cs.CL",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2501.03183v1",
    "published_date": "2025-01-03 18:09:26 UTC",
    "updated_date": "2025-01-03 18:09:26 UTC"
  },
  {
    "arxiv_id": "2501.01926v2",
    "title": "Mitigating Hallucination for Large Vision Language Model by Inter-Modality Correlation Calibration Decoding",
    "authors": [
      "Jiaming Li",
      "Jiacheng Zhang",
      "Zequn Jie",
      "Lin Ma",
      "Guanbin Li"
    ],
    "abstract": "Large vision-language models (LVLMs) have shown remarkable capabilities in\nvisual-language understanding for downstream multi-modal tasks. Despite their\nsuccess, LVLMs still suffer from generating hallucinations in complex\ngeneration tasks, leading to inconsistencies between visual inputs and\ngenerated content. To address this issue, some approaches have introduced\ninference-time interventions, such as contrastive decoding and attention\nrectification, to reduce overreliance on language priors. However, these\napproaches overlook hallucinations stemming from spurious inter-modality\ncorrelations. In this paper, we propose an Inter-Modality Correlation\nCalibration Decoding (IMCCD) method to mitigate hallucinations in LVLMs in a\ntraining-free manner. In this method, we design a Cross-Modal Value-Enhanced\nDecoding(CMVED) module to alleviate hallucination by a novel contrastive\ndecoding mechanism. During the estimation of distorted distribution, CMVED\nmasks the value vectors associated with significant cross-modal attention\nweights, which address both uni-modality overreliance and misleading\ninter-modality correlations. Additionally, a Content-Driven Attention\nRefinement(CDAR) module refines cross-modal attention weights, guiding LVLMs to\nfocus on important visual content. Experimental results on diverse\nhallucination benchmarks validate the superiority of our method over existing\nstate-of-the-art techniques in reducing hallucinations in LVLM text generation.\nOur code will be available at https://github.com/lijm48/IMCCD.",
    "categories": [
      "cs.CV",
      "cs.AI"
    ],
    "primary_category": "cs.CV",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2501.01926v2",
    "published_date": "2025-01-03 17:56:28 UTC",
    "updated_date": "2025-03-11 18:21:46 UTC"
  },
  {
    "arxiv_id": "2501.01913v1",
    "title": "Mingling with the Good to Backdoor Federated Learning",
    "authors": [
      "Nuno Neves"
    ],
    "abstract": "Federated learning (FL) is a decentralized machine learning technique that\nallows multiple entities to jointly train a model while preserving dataset\nprivacy. However, its distributed nature has raised various security concerns,\nwhich have been addressed by increasingly sophisticated defenses. These\nprotections utilize a range of data sources and metrics to, for example, filter\nout malicious model updates, ensuring that the impact of attacks is minimized\nor eliminated.\n  This paper explores the feasibility of designing a generic attack method\ncapable of installing backdoors in FL while evading a diverse array of\ndefenses. Specifically, we focus on an attacker strategy called MIGO, which\naims to produce model updates that subtly blend with legitimate ones. The\nresulting effect is a gradual integration of a backdoor into the global model,\noften ensuring its persistence long after the attack concludes, while\ngenerating enough ambiguity to hinder the effectiveness of defenses.\n  MIGO was employed to implant three types of backdoors across five datasets\nand different model architectures. The results demonstrate the significant\nthreat posed by these backdoors, as MIGO consistently achieved exceptionally\nhigh backdoor accuracy (exceeding 90%) while maintaining the utility of the\nmain task. Moreover, MIGO exhibited strong evasion capabilities against ten\ndefenses, including several state-of-the-art methods. When compared to four\nother attack strategies, MIGO consistently outperformed them across most\nconfigurations. Notably, even in extreme scenarios where the attacker controls\njust 0.1% of the clients, the results indicate that successful backdoor\ninsertion is possible if the attacker can persist for a sufficient number of\nrounds.",
    "categories": [
      "cs.CR",
      "cs.AI",
      "cs.DC",
      "D.4.6; I.2"
    ],
    "primary_category": "cs.CR",
    "comment": "13 pages, 9 figures, under submission",
    "pdf_url": "http://arxiv.org/pdf/2501.01913v1",
    "published_date": "2025-01-03 17:30:59 UTC",
    "updated_date": "2025-01-03 17:30:59 UTC"
  },
  {
    "arxiv_id": "2501.01904v2",
    "title": "Virgo: A Preliminary Exploration on Reproducing o1-like MLLM",
    "authors": [
      "Yifan Du",
      "Zikang Liu",
      "Yifan Li",
      "Wayne Xin Zhao",
      "Yuqi Huo",
      "Bingning Wang",
      "Weipeng Chen",
      "Zheng Liu",
      "Zhongyuan Wang",
      "Ji-Rong Wen"
    ],
    "abstract": "Recently, slow-thinking reasoning systems, built upon large language models\n(LLMs), have garnered widespread attention by scaling the thinking time during\ninference. There is also growing interest in adapting this capability to\nmultimodal large language models (MLLMs). Given that MLLMs handle more complex\ndata semantics across different modalities, it is intuitively more challenging\nto implement multimodal slow-thinking systems.\n  To address this issue, in this paper, we explore a straightforward approach\nby fine-tuning a capable MLLM with a small amount of textual long-form thought\ndata, resulting in a multimodal slow-thinking system, Virgo (Visual reasoning\nwith long thought). We find that these long-form reasoning processes, expressed\nin natural language, can be effectively transferred to MLLMs. Moreover, it\nseems that such textual reasoning data can be even more effective than visual\nreasoning data in eliciting the slow-thinking capacities of MLLMs. While this\nwork is preliminary, it demonstrates that slow-thinking capacities are\nfundamentally associated with the language model component, which can be\ntransferred across modalities or domains. This finding can be leveraged to\nguide the development of more powerful slow-thinking reasoning systems. We\nrelease our resources at https://github.com/RUCAIBox/Virgo.",
    "categories": [
      "cs.CV",
      "cs.AI"
    ],
    "primary_category": "cs.CV",
    "comment": "Technical Report on Slow Thinking with LLMs: Visual Reasoning",
    "pdf_url": "http://arxiv.org/pdf/2501.01904v2",
    "published_date": "2025-01-03 17:14:16 UTC",
    "updated_date": "2025-02-05 09:17:01 UTC"
  },
  {
    "arxiv_id": "2501.01892v2",
    "title": "QuArch: A Question-Answering Dataset for AI Agents in Computer Architecture",
    "authors": [
      "Shvetank Prakash",
      "Andrew Cheng",
      "Jason Yik",
      "Arya Tschand",
      "Radhika Ghosal",
      "Ikechukwu Uchendu",
      "Jessica Quaye",
      "Jeffrey Ma",
      "Shreyas Grampurohit",
      "Sofia Giannuzzi",
      "Arnav Balyan",
      "Fin Amin",
      "Aadya Pipersenia",
      "Yash Choudhary",
      "Ankita Nayak",
      "Amir Yazdanbakhsh",
      "Vijay Janapa Reddi"
    ],
    "abstract": "We introduce QuArch, a dataset of 1500 human-validated question-answer pairs\ndesigned to evaluate and enhance language models' understanding of computer\narchitecture. The dataset covers areas including processor design, memory\nsystems, and performance optimization. Our analysis highlights a significant\nperformance gap: the best closed-source model achieves 84% accuracy, while the\ntop small open-source model reaches 72%. We observe notable struggles in memory\nsystems, interconnection networks, and benchmarking. Fine-tuning with QuArch\nimproves small model accuracy by up to 8%, establishing a foundation for\nadvancing AI-driven computer architecture research. The dataset and leaderboard\nare at https://harvard-edge.github.io/QuArch/.",
    "categories": [
      "cs.AR",
      "cs.AI",
      "cs.LG"
    ],
    "primary_category": "cs.AR",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2501.01892v2",
    "published_date": "2025-01-03 16:55:53 UTC",
    "updated_date": "2025-01-06 17:48:05 UTC"
  },
  {
    "arxiv_id": "2501.01886v1",
    "title": "Evaluating Scenario-based Decision-making for Interactive Autonomous Driving Using Rational Criteria: A Survey",
    "authors": [
      "Zhen Tian",
      "Zhihao Lin",
      "Dezong Zhao",
      "Wenjing Zhao",
      "David Flynn",
      "Shuja Ansari",
      "Chongfeng Wei"
    ],
    "abstract": "Autonomous vehicles (AVs) can significantly promote the advances in road\ntransport mobility in terms of safety, reliability, and decarbonization.\nHowever, ensuring safety and efficiency in interactive during within dynamic\nand diverse environments is still a primary barrier to large-scale AV adoption.\nIn recent years, deep reinforcement learning (DRL) has emerged as an advanced\nAI-based approach, enabling AVs to learn decision-making strategies adaptively\nfrom data and interactions. DRL strategies are better suited than traditional\nrule-based methods for handling complex, dynamic, and unpredictable driving\nenvironments due to their adaptivity. However, varying driving scenarios\npresent distinct challenges, such as avoiding obstacles on highways and\nreaching specific exits at intersections, requiring different scenario-specific\ndecision-making algorithms. Many DRL algorithms have been proposed in\ninteractive decision-making. However, a rationale review of these DRL\nalgorithms across various scenarios is lacking. Therefore, a comprehensive\nevaluation is essential to assess these algorithms from multiple perspectives,\nincluding those of vehicle users and vehicle manufacturers. This survey reviews\nthe application of DRL algorithms in autonomous driving across typical\nscenarios, summarizing road features and recent advancements. The scenarios\ninclude highways, on-ramp merging, roundabouts, and unsignalized intersections.\nFurthermore, DRL-based algorithms are evaluated based on five rationale\ncriteria: driving safety, driving efficiency, training efficiency,\nunselfishness, and interpretability (DDTUI). Each criterion of DDTUI is\nspecifically analyzed in relation to the reviewed algorithms. Finally, the\nchallenges for future DRL-based decision-making algorithms are summarized.",
    "categories": [
      "cs.RO",
      "cs.AI",
      "cs.SY",
      "eess.SY"
    ],
    "primary_category": "cs.RO",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2501.01886v1",
    "published_date": "2025-01-03 16:37:52 UTC",
    "updated_date": "2025-01-03 16:37:52 UTC"
  },
  {
    "arxiv_id": "2502.15695v2",
    "title": "Contrastive Learning Augmented Social Recommendations",
    "authors": [
      "Lin Wang",
      "Weisong Wang",
      "Xuanji Xiao",
      "Qing Li"
    ],
    "abstract": "Recommender systems play a pivotal role in modern content platforms, yet\ntraditional behavior-based models often face challenges in addressing cold\nusers with sparse interaction data. Engaging these users, however, remains\ncritical for sustaining platform growth. To tackle this issue, we propose\nleveraging reconstructed social graph to complement interest representations\nderived from behavioral data. Despite the widespread availability of social\ngraphs on content platforms, their utility is hindered by social-relation noise\nand inconsistencies between social and behavioral interests. To mitigate noise\npropagation in graph data and extract reliable social interests, we introduce a\ndual-view denoising framework. This approach first applies low-rank singular\nvalue decomposition (SVD) to the user-item interaction matrix, generating\ndenoised user embeddings for reconstructing the social graph. It then employs\ncontrastive learning to align the original and reconstructed social graphs. To\naddress the discrepancy between social and behavioral interests, we utilize a\nmutual distillation mechanism that decomposes interests into four\nsubcategories: aligned social/behavioral interests and\nsocial/behavioral-specific interests, enabling effective integration of the\ntwo. Empirical results demonstrate the efficacy of our method, particularly in\nimproving recommendations for cold users, by combining social and behavioral\ndata. The implementation of our approach is publicly available at\nhttps://github.com/WANGLin0126/CLSRec.",
    "categories": [
      "cs.IR",
      "cs.AI",
      "cs.SI"
    ],
    "primary_category": "cs.IR",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2502.15695v2",
    "published_date": "2025-01-03 16:29:51 UTC",
    "updated_date": "2025-02-25 04:02:34 UTC"
  },
  {
    "arxiv_id": "2501.02041v1",
    "title": "MRG: A Multi-Robot Manufacturing Digital Scene Generation Method Using Multi-Instance Point Cloud Registration",
    "authors": [
      "Songjie Han",
      "Yinhua Liu",
      "Yanzheng Li",
      "Hua Chen",
      "Dongmei Yang"
    ],
    "abstract": "A high-fidelity digital simulation environment is crucial for accurately\nreplicating physical operational processes. However, inconsistencies between\nsimulation and physical environments result in low confidence in simulation\noutcomes, limiting their effectiveness in guiding real-world production. Unlike\nthe traditional step-by-step point cloud \"segmentation-registration\" generation\nmethod, this paper introduces, for the first time, a novel Multi-Robot\nManufacturing Digital Scene Generation (MRG) method that leverages\nmulti-instance point cloud registration, specifically within manufacturing\nscenes. Tailored to the characteristics of industrial robots and manufacturing\nsettings, an instance-focused transformer module is developed to delineate\ninstance boundaries and capture correlations between local regions.\nAdditionally, a hypothesis generation module is proposed to extract target\ninstances while preserving key features. Finally, an efficient screening and\noptimization algorithm is designed to refine the final registration results.\nExperimental evaluations on the Scan2CAD and Welding-Station datasets\ndemonstrate that: (1) the proposed method outperforms existing multi-instance\npoint cloud registration techniques; (2) compared to state-of-the-art methods,\nthe Scan2CAD dataset achieves improvements in MR and MP by 12.15% and 17.79%,\nrespectively; and (3) on the Welding-Station dataset, MR and MP are enhanced by\n16.95% and 24.15%, respectively. This work marks the first application of\nmulti-instance point cloud registration in manufacturing scenes, significantly\nadvancing the precision and reliability of digital simulation environments for\nindustrial applications.",
    "categories": [
      "cs.CV",
      "cs.AI"
    ],
    "primary_category": "cs.CV",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2501.02041v1",
    "published_date": "2025-01-03 16:23:13 UTC",
    "updated_date": "2025-01-03 16:23:13 UTC"
  },
  {
    "arxiv_id": "2501.03261v1",
    "title": "Navigation Variable-based Multi-objective Particle Swarm Optimization for UAV Path Planning with Kinematic Constraints",
    "authors": [
      "Thi Thuy Ngan Duong",
      "Duy-Nam Bui",
      "Manh Duong Phung"
    ],
    "abstract": "Path planning is essential for unmanned aerial vehicles (UAVs) as it\ndetermines the path that the UAV needs to follow to complete a task. This work\naddresses this problem by introducing a new algorithm called navigation\nvariable-based multi-objective particle swarm optimization (NMOPSO). It first\nmodels path planning as an optimization problem via the definition of a set of\nobjective functions that include optimality and safety requirements for UAV\noperation. The NMOPSO is then used to minimize those functions through Pareto\noptimal solutions. The algorithm features a new path representation based on\nnavigation variables to include kinematic constraints and exploit the\nmaneuverable characteristics of the UAV. It also includes an adaptive mutation\nmechanism to enhance the diversity of the swarm for better solutions.\nComparisons with various algorithms have been carried out to benchmark the\nproposed approach. The results indicate that the NMOPSO performs better than\nnot only other particle swarm optimization variants but also other\nstate-of-the-art multi-objective and metaheuristic optimization algorithms.\nExperiments have also been conducted with real UAVs to confirm the validity of\nthe approach for practical flights. The source code of the algorithm is\navailable at https://github.com/ngandng/NMOPSO.",
    "categories": [
      "cs.RO",
      "cs.AI",
      "cs.NE"
    ],
    "primary_category": "cs.RO",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2501.03261v1",
    "published_date": "2025-01-03 16:07:37 UTC",
    "updated_date": "2025-01-03 16:07:37 UTC"
  },
  {
    "arxiv_id": "2501.01876v1",
    "title": "Accuracy Can Lie: On the Impact of Surrogate Model in Configuration Tuning",
    "authors": [
      "Pengzhou Chen",
      "Jingzhi Gong",
      "Tao Chen"
    ],
    "abstract": "To ease the expensive measurements during configuration tuning, it is natural\nto build a surrogate model as the replacement of the system, and thereby the\nconfiguration performance can be cheaply evaluated. Yet, a stereotype therein\nis that the higher the model accuracy, the better the tuning result would be.\nThis \"accuracy is all\" belief drives our research community to build more and\nmore accurate models and criticize a tuner for the inaccuracy of the model\nused. However, this practice raises some previously unaddressed questions,\ne.g., Do those somewhat small accuracy improvements reported in existing work\nreally matter much to the tuners? What role does model accuracy play in the\nimpact of tuning quality? To answer those related questions, we conduct one of\nthe largest-scale empirical studies to date-running over the period of 13\nmonths 24*7-that covers 10 models, 17 tuners, and 29 systems from the existing\nworks while under four different commonly used metrics, leading to 13,612 cases\nof investigation. Surprisingly, our key findings reveal that the accuracy can\nlie: there are a considerable number of cases where higher accuracy actually\nleads to no improvement in the tuning outcomes (up to 58% cases under certain\nsetting), or even worse, it can degrade the tuning quality (up to 24% cases\nunder certain setting). We also discover that the chosen models in most\nproposed tuners are sub-optimal and that the required % of accuracy change to\nsignificantly improve tuning quality varies according to the range of model\naccuracy. Deriving from the fitness landscape analysis, we provide in-depth\ndiscussions of the rationale behind, offering several lessons learned as well\nas insights for future opportunities. Most importantly, this work poses a clear\nmessage to the community: we should take one step back from the natural\n\"accuracy is all\" belief for model-based configuration tuning.",
    "categories": [
      "cs.SE",
      "cs.AI"
    ],
    "primary_category": "cs.SE",
    "comment": "This paper has been accepted by TSE",
    "pdf_url": "http://arxiv.org/pdf/2501.01876v1",
    "published_date": "2025-01-03 15:57:20 UTC",
    "updated_date": "2025-01-03 15:57:20 UTC"
  },
  {
    "arxiv_id": "2501.02040v2",
    "title": "A Separable Self-attention Inspired by the State Space Model for Computer Vision",
    "authors": [
      "Juntao Zhang",
      "Shaogeng Liu",
      "Kun Bian",
      "You Zhou",
      "Pei Zhang",
      "Jianning Liu",
      "Jun Zhou",
      "Bingyan Liu"
    ],
    "abstract": "Mamba is an efficient State Space Model (SSM) with linear computational\ncomplexity. Although SSMs are not suitable for handling non-causal data, Vision\nMamba (ViM) methods still demonstrate good performance in tasks such as image\nclassification and object detection. Recent studies have shown that there is a\nrich theoretical connection between state space models and attention variants.\nWe propose a novel separable self attention method, for the first time\nintroducing some excellent design concepts of Mamba into separable\nself-attention. To ensure a fair comparison with ViMs, we introduce VMINet, a\nsimple yet powerful prototype architecture, constructed solely by stacking our\nnovel attention modules with the most basic down-sampling layers. Notably,\nVMINet differs significantly from the conventional Transformer architecture.\nOur experiments demonstrate that VMINet has achieved competitive results on\nimage classification and high-resolution dense prediction tasks.Code is\navailable at: https://github.com/yws-wxs/VMINet.",
    "categories": [
      "cs.CV",
      "cs.AI"
    ],
    "primary_category": "cs.CV",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2501.02040v2",
    "published_date": "2025-01-03 15:23:36 UTC",
    "updated_date": "2025-05-20 01:01:55 UTC"
  },
  {
    "arxiv_id": "2501.01850v1",
    "title": "LCFed: An Efficient Clustered Federated Learning Framework for Heterogeneous Data",
    "authors": [
      "Yuxin Zhang",
      "Haoyu Chen",
      "Zheng Lin",
      "Zhe Chen",
      "Jin Zhao"
    ],
    "abstract": "Clustered federated learning (CFL) addresses the performance challenges posed\nby data heterogeneity in federated learning (FL) by organizing edge devices\nwith similar data distributions into clusters, enabling collaborative model\ntraining tailored to each group. However, existing CFL approaches strictly\nlimit knowledge sharing to within clusters, lacking the integration of global\nknowledge with intra-cluster training, which leads to suboptimal performance.\nMoreover, traditional clustering methods incur significant computational\noverhead, especially as the number of edge devices increases. In this paper, we\npropose LCFed, an efficient CFL framework to combat these challenges. By\nleveraging model partitioning and adopting distinct aggregation strategies for\neach sub-model, LCFed effectively incorporates global knowledge into\nintra-cluster co-training, achieving optimal training performance.\nAdditionally, LCFed customizes a computationally efficient model similarity\nmeasurement method based on low-rank models, enabling real-time cluster updates\nwith minimal computational overhead. Extensive experiments show that LCFed\noutperforms state-of-the-art benchmarks in both test accuracy and clustering\ncomputational efficiency.",
    "categories": [
      "cs.LG",
      "cs.AI",
      "cs.DC"
    ],
    "primary_category": "cs.LG",
    "comment": "6 pages, 3 figures",
    "pdf_url": "http://arxiv.org/pdf/2501.01850v1",
    "published_date": "2025-01-03 14:59:48 UTC",
    "updated_date": "2025-01-03 14:59:48 UTC"
  },
  {
    "arxiv_id": "2501.01849v1",
    "title": "Multi-Agent Conversational Online Learning for Adaptive LLM Response Identification",
    "authors": [
      "Xiangxiang Dai",
      "Yuejin Xie",
      "Maoli Liu",
      "Xuchuang Wang",
      "Zhuohua Li",
      "Huanyu Wang",
      "John C. S. Lui"
    ],
    "abstract": "The remarkable generative capability of large language models (LLMs) has\nsparked a growing interest in automatically generating responses for different\napplications. Given the dynamic nature of user preferences and the uncertainty\nof LLM response performance, it is crucial to design efficient online learning\nalgorithms to identify optimal LLM responses (i.e., high-quality responses that\nalso meet user preferences). Most existing online algorithms adopt a\ncentralized approach and fail to leverage explicit user preferences for more\nefficient and personalized LLM response identification. In contrast, this paper\nintroduces \\textit{MACO} (\\underline{M}ulti-\\underline{A}gent\n\\underline{C}onversational \\underline{O}nline Learning for Adaptive LLM\nResponse Identification): 1) The online LLM response identification process is\naccelerated by multiple local agents (such as smartphones), while enhancing\ndata privacy; 2) A novel conversational mechanism is proposed to adaptively\nconduct conversations for soliciting user preferences (e.g., a preference for a\nhumorous tone over a serious one in generated responses), so to minimize\nuncertainty in preference estimation. Our theoretical analysis demonstrates\nthat \\cadi\\ is near-optimal regarding cumulative regret. Additionally, \\cadi\\\noffers reduced communication costs and computational complexity by eliminating\nthe traditional, computing-intensive ``G-optimal design\" found in previous\nworks. Extensive experiments with the open LLM \\textit{Llama}, coupled with two\ndifferent embedding models from Google and OpenAI for text vector\nrepresentation, demonstrate that \\cadi\\ significantly outperforms the current\nstate-of-the-art in online LLM response identification.",
    "categories": [
      "cs.HC",
      "cs.AI"
    ],
    "primary_category": "cs.HC",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2501.01849v1",
    "published_date": "2025-01-03 14:59:38 UTC",
    "updated_date": "2025-01-03 14:59:38 UTC"
  },
  {
    "arxiv_id": "2501.01836v1",
    "title": "Practical machine learning is learning on small samples",
    "authors": [
      "Marina Sapir"
    ],
    "abstract": "Based on limited observations, machine learning discerns a dependence which\nis expected to hold in the future. What makes it possible? Statistical learning\ntheory imagines indefinitely increasing training sample to justify its\napproach. In reality, there is no infinite time or even infinite general\npopulation for learning. Here I argue that practical machine learning is based\non an implicit assumption that underlying dependence is relatively ``smooth\" :\nlikely, there are no abrupt differences in feedback between cases with close\ndata points. From this point of view learning shall involve selection of the\nhypothesis ``smoothly\" approximating the training set. I formalize this as\nPractical learning paradigm. The paradigm includes terminology and rules for\ndescription of learners. Popular learners (local smoothing, k-NN, decision\ntrees, Naive Bayes, SVM for classification and for regression) are shown here\nto be implementations of this paradigm.",
    "categories": [
      "cs.LG",
      "cs.AI"
    ],
    "primary_category": "cs.LG",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2501.01836v1",
    "published_date": "2025-01-03 14:38:07 UTC",
    "updated_date": "2025-01-03 14:38:07 UTC"
  },
  {
    "arxiv_id": "2501.01835v1",
    "title": "ASKCOS: an open source software suite for synthesis planning",
    "authors": [
      "Zhengkai Tu",
      "Sourabh J. Choure",
      "Mun Hong Fong",
      "Jihye Roh",
      "Itai Levin",
      "Kevin Yu",
      "Joonyoung F. Joung",
      "Nathan Morgan",
      "Shih-Cheng Li",
      "Xiaoqi Sun",
      "Huiqian Lin",
      "Mark Murnin",
      "Jordan P. Liles",
      "Thomas J. Struble",
      "Michael E. Fortunato",
      "Mengjie Liu",
      "William H. Green",
      "Klavs F. Jensen",
      "Connor W. Coley"
    ],
    "abstract": "The advancement of machine learning and the availability of large-scale\nreaction datasets have accelerated the development of data-driven models for\ncomputer-aided synthesis planning (CASP) in the past decade. Here, we detail\nthe newest version of ASKCOS, an open source software suite for synthesis\nplanning that makes available several research advances in a freely available,\npractical tool. Four one-step retrosynthesis models form the basis of both\ninteractive planning and automatic planning modes. Retrosynthetic planning is\ncomplemented by other modules for feasibility assessment and pathway\nevaluation, including reaction condition recommendation, reaction outcome\nprediction, and auxiliary capabilities such as solubility prediction and\nquantum mechanical descriptor prediction. ASKCOS has assisted hundreds of\nmedicinal, synthetic, and process chemists in their day-to-day tasks,\ncomplementing expert decision making. It is our belief that CASP tools like\nASKCOS are an important part of modern chemistry research, and that they offer\never-increasing utility and accessibility.",
    "categories": [
      "cs.AI"
    ],
    "primary_category": "cs.AI",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2501.01835v1",
    "published_date": "2025-01-03 14:38:03 UTC",
    "updated_date": "2025-01-03 14:38:03 UTC"
  },
  {
    "arxiv_id": "2501.01834v3",
    "title": "MoColl: Agent-Based Specific and General Model Collaboration for Image Captioning",
    "authors": [
      "Pu Yang",
      "Bin Dong"
    ],
    "abstract": "Image captioning is a critical task at the intersection of computer vision\nand natural language processing, with wide-ranging applications across various\ndomains. For complex tasks such as diagnostic report generation, deep learning\nmodels require not only domain-specific image-caption datasets but also the\nincorporation of relevant general knowledge to provide contextual accuracy.\nExisting approaches exhibit inherent limitations: specialized models excel in\ncapturing domain-specific details but lack generalization, while\nvision-language models (VLMs) built on large language models (LLMs) leverage\ngeneral knowledge but struggle with domain-specific adaptation. To address\nthese limitations, this paper proposes a novel agent-enhanced model\ncollaboration framework, which we call MoColl, designed to effectively\nintegrate domain-specific and general knowledge. Specifically, our approach is\nto decompose complex image captioning tasks into a series of interconnected\nquestion-answer subtasks. A trainable visual question answering (VQA) model is\nemployed as a specialized tool to focus on domain-specific visual analysis,\nanswering task-specific questions based on image content. Concurrently, an\nLLM-based agent with general knowledge formulates these questions and\nsynthesizes the resulting question-answer pairs into coherent captions. Beyond\nits role in leveraging the VQA model, the agent further guides its training to\nenhance its domain-specific capabilities. Experimental results on radiology\nreport generation validate the effectiveness of the proposed framework,\ndemonstrating significant improvements in the quality of generated reports.",
    "categories": [
      "cs.CV",
      "cs.AI"
    ],
    "primary_category": "cs.CV",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2501.01834v3",
    "published_date": "2025-01-03 14:38:01 UTC",
    "updated_date": "2025-01-27 16:34:59 UTC"
  },
  {
    "arxiv_id": "2501.02039v1",
    "title": "An Investigation into Value Misalignment in LLM-Generated Texts for Cultural Heritage",
    "authors": [
      "Fan Bu",
      "Zheng Wang",
      "Siyi Wang",
      "Ziyao Liu"
    ],
    "abstract": "As Large Language Models (LLMs) become increasingly prevalent in tasks\nrelated to cultural heritage, such as generating descriptions of historical\nmonuments, translating ancient texts, preserving oral traditions, and creating\neducational content, their ability to produce accurate and culturally aligned\ntexts is being increasingly relied upon by users and researchers. However,\ncultural value misalignments may exist in generated texts, such as the\nmisrepresentation of historical facts, the erosion of cultural identity, and\nthe oversimplification of complex cultural narratives, which may lead to severe\nconsequences. Therefore, investigating value misalignment in the context of LLM\nfor cultural heritage is crucial for mitigating these risks, yet there has been\na significant lack of systematic and comprehensive study and investigation in\nthis area. To fill this gap, we systematically assess the reliability of LLMs\nin generating culturally aligned texts for cultural heritage-related tasks. We\nconduct a comprehensive evaluation by compiling an extensive set of 1066 query\ntasks covering 5 widely recognized categories with 17 aspects within the\nknowledge framework of cultural heritage across 5 open-source LLMs, and examine\nboth the type and rate of cultural value misalignments in the generated texts.\nUsing both automated and manual approaches, we effectively detect and analyze\nthe cultural value misalignments in LLM-generated texts. Our findings are\nconcerning: over 65% of the generated texts exhibit notable cultural\nmisalignments, with certain tasks demonstrating almost complete misalignment\nwith key cultural values. Beyond these findings, this paper introduces a\nbenchmark dataset and a comprehensive evaluation workflow that can serve as a\nvaluable resource for future research aimed at enhancing the cultural\nsensitivity and reliability of LLMs.",
    "categories": [
      "cs.CL",
      "cs.AI"
    ],
    "primary_category": "cs.CL",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2501.02039v1",
    "published_date": "2025-01-03 14:35:32 UTC",
    "updated_date": "2025-01-03 14:35:32 UTC"
  },
  {
    "arxiv_id": "2501.01830v1",
    "title": "Auto-RT: Automatic Jailbreak Strategy Exploration for Red-Teaming Large Language Models",
    "authors": [
      "Yanjiang Liu",
      "Shuhen Zhou",
      "Yaojie Lu",
      "Huijia Zhu",
      "Weiqiang Wang",
      "Hongyu Lin",
      "Ben He",
      "Xianpei Han",
      "Le Sun"
    ],
    "abstract": "Automated red-teaming has become a crucial approach for uncovering\nvulnerabilities in large language models (LLMs). However, most existing methods\nfocus on isolated safety flaws, limiting their ability to adapt to dynamic\ndefenses and uncover complex vulnerabilities efficiently. To address this\nchallenge, we propose Auto-RT, a reinforcement learning framework that\nautomatically explores and optimizes complex attack strategies to effectively\nuncover security vulnerabilities through malicious queries. Specifically, we\nintroduce two key mechanisms to reduce exploration complexity and improve\nstrategy optimization: 1) Early-terminated Exploration, which accelerate\nexploration by focusing on high-potential attack strategies; and 2) Progressive\nReward Tracking algorithm with intermediate downgrade models, which dynamically\nrefine the search trajectory toward successful vulnerability exploitation.\nExtensive experiments across diverse LLMs demonstrate that, by significantly\nimproving exploration efficiency and automatically optimizing attack\nstrategies, Auto-RT detects a boarder range of vulnerabilities, achieving a\nfaster detection speed and 16.63\\% higher success rates compared to existing\nmethods.",
    "categories": [
      "cs.CR",
      "cs.AI",
      "cs.CL"
    ],
    "primary_category": "cs.CR",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2501.01830v1",
    "published_date": "2025-01-03 14:30:14 UTC",
    "updated_date": "2025-01-03 14:30:14 UTC"
  },
  {
    "arxiv_id": "2501.01827v1",
    "title": "The Proof is in the Almond Cookies",
    "authors": [
      "Remi van Trijp",
      "Katrien Beuls",
      "Paul Van Eecke"
    ],
    "abstract": "This paper presents a case study on how to process cooking recipes (and more\ngenerally, how-to instructions) in a way that makes it possible for a robot or\nartificial cooking assistant to support human chefs in the kitchen. Such AI\nassistants would be of great benefit to society, as they can help to sustain\nthe autonomy of aging adults or people with a physical impairment, or they may\nreduce the stress in a professional kitchen. We propose a novel approach to\ncomputational recipe understanding that mimics the human sense-making process,\nwhich is narrative-based. Using an English recipe for almond crescent cookies\nas illustration, we show how recipes can be modelled as rich narrative\nstructures by integrating various knowledge sources such as language\nprocessing, ontologies, and mental simulation. We show how such narrative\nstructures can be used for (a) dealing with the challenges of recipe language,\nsuch as zero anaphora, (b) optimizing a robot's planning process, (c) measuring\nhow well an AI system understands its current tasks, and (d) allowing recipe\nannotations to become language-independent.",
    "categories": [
      "cs.CL",
      "cs.AI"
    ],
    "primary_category": "cs.CL",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2501.01827v1",
    "published_date": "2025-01-03 14:25:35 UTC",
    "updated_date": "2025-01-03 14:25:35 UTC"
  },
  {
    "arxiv_id": "2501.02038v1",
    "title": "Architecture for Trajectory-Based Fishing Ship Classification with AIS Data",
    "authors": [
      "David Snchez Pedroche",
      "Daniel Amigo",
      "Jess Garca",
      "Jose M. Molina"
    ],
    "abstract": "This paper proposes a data preparation process for managing real-world\nkinematic data and detecting fishing vessels. The solution is a binary\nclassification that classifies ship trajectories into either fishing or\nnon-fishing ships. The data used are characterized by the typical problems\nfound in classic data mining applications using real-world data, such as noise\nand inconsistencies. The two classes are also clearly unbalanced in the data, a\nproblem which is addressed using algorithms that resample the instances. For\nclassification, a series of features are extracted from spatiotemporal data\nthat represent the trajectories of the ships, available from sequences of\nAutomatic Identification System (AIS) reports. These features are proposed for\nthe modelling of ship behavior but, because they do not contain context-related\ninformation, the classification can be applied in other scenarios.\nExperimentation shows that the proposed data preparation process is useful for\nthe presented classification problem. In addition, positive results are\nobtained using minimal information.",
    "categories": [
      "cs.LG",
      "cs.AI"
    ],
    "primary_category": "cs.LG",
    "comment": "Sensors 2020",
    "pdf_url": "http://arxiv.org/pdf/2501.02038v1",
    "published_date": "2025-01-03 14:12:40 UTC",
    "updated_date": "2025-01-03 14:12:40 UTC"
  },
  {
    "arxiv_id": "2501.01821v2",
    "title": "SDPO: Segment-Level Direct Preference Optimization for Social Agents",
    "authors": [
      "Aobo Kong",
      "Wentao Ma",
      "Shiwan Zhao",
      "Yongbin Li",
      "Yuchuan Wu",
      "Ke Wang",
      "Xiaoqian Liu",
      "Qicheng Li",
      "Yong Qin",
      "Fei Huang"
    ],
    "abstract": "Social agents powered by large language models (LLMs) can simulate human\nsocial behaviors but fall short in handling complex social dialogues. Direct\nPreference Optimization (DPO) has proven effective in aligning LLM behavior\nwith human preferences across various agent tasks. However, standard DPO\nfocuses solely on individual turns, which limits its effectiveness in\nmulti-turn social interactions. Several DPO-based multi-turn alignment methods\nwith session-level data have shown potential in addressing this problem.While\nthese methods consider multiple turns across entire sessions, they are often\noverly coarse-grained, introducing training noise, and lack robust theoretical\nsupport. To resolve these limitations, we propose Segment-Level Direct\nPreference Optimization (SDPO), which dynamically select key segments within\ninteractions to optimize multi-turn agent behavior. SDPO minimizes training\nnoise and is grounded in a rigorous theoretical framework. Evaluations on the\nSOTOPIA benchmark demonstrate that SDPO-tuned agents consistently outperform\nboth existing DPO-based methods and proprietary LLMs like GPT-4o, underscoring\nSDPO's potential to advance the social intelligence of LLM-based agents. We\nrelease our code and data at\nhttps://github.com/AlibabaResearch/DAMO-ConvAI/tree/main/SDPO.",
    "categories": [
      "cs.AI",
      "cs.CL"
    ],
    "primary_category": "cs.AI",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2501.01821v2",
    "published_date": "2025-01-03 14:09:46 UTC",
    "updated_date": "2025-02-27 05:42:17 UTC"
  },
  {
    "arxiv_id": "2501.01805v1",
    "title": "End-to-End Long Document Summarization using Gradient Caching",
    "authors": [
      "Rohit Saxena",
      "Hao Tang",
      "Frank Keller"
    ],
    "abstract": "Training transformer-based encoder-decoder models for long document\nsummarization poses a significant challenge due to the quadratic memory\nconsumption during training. Several approaches have been proposed to extend\nthe input length at test time, but training with these approaches is still\ndifficult, requiring truncation of input documents and causing a mismatch\nbetween training and test conditions. In this work, we propose CachED (Gradient\n$\\textbf{Cach}$ing for $\\textbf{E}$ncoder-$\\textbf{D}$ecoder models), an\napproach that enables end-to-end training of existing transformer-based\nencoder-decoder models, using the entire document without truncation.\nSpecifically, we apply non-overlapping sliding windows to input documents,\nfollowed by fusion in decoder. During backpropagation, the gradients are cached\nat the decoder and are passed through the encoder in chunks by re-computing the\nhidden vectors, similar to gradient checkpointing. In the experiments on long\ndocument summarization, we extend BART to CachED BART, processing more than\n500K tokens during training and achieving superior performance without using\nany additional parameters.",
    "categories": [
      "cs.CL",
      "cs.AI"
    ],
    "primary_category": "cs.CL",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2501.01805v1",
    "published_date": "2025-01-03 13:32:57 UTC",
    "updated_date": "2025-01-03 13:32:57 UTC"
  },
  {
    "arxiv_id": "2501.01802v1",
    "title": "BERT4MIMO: A Foundation Model using BERT Architecture for Massive MIMO Channel State Information Prediction",
    "authors": [
      "Ferhat Ozgur Catak",
      "Murat Kuzlu",
      "Umit Cali"
    ],
    "abstract": "Massive MIMO (Multiple-Input Multiple-Output) is an advanced wireless\ncommunication technology, using a large number of antennas to improve the\noverall performance of the communication system in terms of capacity, spectral,\nand energy efficiency. The performance of MIMO systems is highly dependent on\nthe quality of channel state information (CSI). Predicting CSI is, therefore,\nessential for improving communication system performance, particularly in MIMO\nsystems, since it represents key characteristics of a wireless channel,\nincluding propagation, fading, scattering, and path loss. This study proposes a\nfoundation model inspired by BERT, called BERT4MIMO, which is specifically\ndesigned to process high-dimensional CSI data from massive MIMO systems.\nBERT4MIMO offers superior performance in reconstructing CSI under varying\nmobility scenarios and channel conditions through deep learning and attention\nmechanisms. The experimental results demonstrate the effectiveness of BERT4MIMO\nin a variety of wireless environments.",
    "categories": [
      "cs.IT",
      "cs.AI",
      "eess.SP",
      "math.IT"
    ],
    "primary_category": "cs.IT",
    "comment": "10 pages",
    "pdf_url": "http://arxiv.org/pdf/2501.01802v1",
    "published_date": "2025-01-03 13:22:19 UTC",
    "updated_date": "2025-01-03 13:22:19 UTC"
  },
  {
    "arxiv_id": "2501.02036v1",
    "title": "Deep Clustering via Community Detection",
    "authors": [
      "Tianyu Cheng",
      "Qun Chen"
    ],
    "abstract": "Deep clustering is an essential task in modern artificial intelligence,\naiming to partition a set of data samples into a given number of homogeneous\ngroups (i.e., clusters). Even though many Deep Neural Network (DNN) backbones\nand clustering strategies have been proposed for the task, achieving\nincreasingly improved performance, deep clustering remains very challenging due\nto the lack of accurately labeled samples. In this paper, we propose a novel\napproach of deep clustering via community detection. It initializes clustering\nby detecting many communities, and then gradually expands clusters by community\nmerging. Compared with the existing clustering strategies, community detection\nfactors in the new perspective of cluster network analysis. As a result, it has\nthe inherent benefit of high pseudo-label purity, which is critical to the\nperformance of self-supervision. We have validated the efficacy of the proposed\napproach on benchmark image datasets. Our extensive experiments have shown that\nit can effectively improve the SOTA performance. Our ablation study also\ndemonstrates that the new network perspective can effectively improve community\npseudo-label purity, resulting in improved clustering performance.",
    "categories": [
      "cs.LG",
      "cs.AI",
      "cs.SI",
      "68T45",
      "I.2.0"
    ],
    "primary_category": "cs.LG",
    "comment": "10 pages, 10 figures",
    "pdf_url": "http://arxiv.org/pdf/2501.02036v1",
    "published_date": "2025-01-03 12:56:12 UTC",
    "updated_date": "2025-01-03 12:56:12 UTC"
  },
  {
    "arxiv_id": "2501.01793v1",
    "title": "Creating Artificial Students that Never Existed: Leveraging Large Language Models and CTGANs for Synthetic Data Generation",
    "authors": [
      "Mohammad Khalil",
      "Farhad Vadiee",
      "Ronas Shakya",
      "Qinyi Liu"
    ],
    "abstract": "In this study, we explore the growing potential of AI and deep learning\ntechnologies, particularly Generative Adversarial Networks (GANs) and Large\nLanguage Models (LLMs), for generating synthetic tabular data. Access to\nquality students data is critical for advancing learning analytics, but privacy\nconcerns and stricter data protection regulations worldwide limit their\navailability and usage. Synthetic data offers a promising alternative. We\ninvestigate whether synthetic data can be leveraged to create artificial\nstudents for serving learning analytics models. Using the popular GAN model\nCTGAN and three LLMs- GPT2, DistilGPT2, and DialoGPT, we generate synthetic\ntabular student data. Our results demonstrate the strong potential of these\nmethods to produce high-quality synthetic datasets that resemble real students\ndata. To validate our findings, we apply a comprehensive set of utility\nevaluation metrics to assess the statistical and predictive performance of the\nsynthetic data and compare the different generator models used, specially the\nperformance of LLMs. Our study aims to provide the learning analytics community\nwith valuable insights into the use of synthetic data, laying the groundwork\nfor expanding the field methodological toolbox with new innovative approaches\nfor learning analytics data generation.",
    "categories": [
      "cs.LG",
      "cs.AI"
    ],
    "primary_category": "cs.LG",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2501.01793v1",
    "published_date": "2025-01-03 12:52:51 UTC",
    "updated_date": "2025-01-03 12:52:51 UTC"
  },
  {
    "arxiv_id": "2501.01785v1",
    "title": "Can Synthetic Data be Fair and Private? A Comparative Study of Synthetic Data Generation and Fairness Algorithms",
    "authors": [
      "Qinyi Liu",
      "Oscar Deho",
      "Farhad Vadiee",
      "Mohammad Khalil",
      "Srecko Joksimovic",
      "George Siemens"
    ],
    "abstract": "The increasing use of machine learning in learning analytics (LA) has raised\nsignificant concerns around algorithmic fairness and privacy. Synthetic data\nhas emerged as a dual-purpose tool, enhancing privacy and improving fairness in\nLA models. However, prior research suggests an inverse relationship between\nfairness and privacy, making it challenging to optimize both. This study\ninvestigates which synthetic data generators can best balance privacy and\nfairness, and whether pre-processing fairness algorithms, typically applied to\nreal datasets, are effective on synthetic data. Our results highlight that the\nDEbiasing CAusal Fairness (DECAF) algorithm achieves the best balance between\nprivacy and fairness. However, DECAF suffers in utility, as reflected in its\npredictive accuracy. Notably, we found that applying pre-processing fairness\nalgorithms to synthetic data improves fairness even more than when applied to\nreal data. These findings suggest that combining synthetic data generation with\nfairness pre-processing offers a promising approach to creating fairer LA\nmodels.",
    "categories": [
      "cs.LG",
      "cs.AI",
      "cs.CY"
    ],
    "primary_category": "cs.LG",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2501.01785v1",
    "published_date": "2025-01-03 12:35:58 UTC",
    "updated_date": "2025-01-03 12:35:58 UTC"
  },
  {
    "arxiv_id": "2501.02035v1",
    "title": "3D Cloud reconstruction through geospatially-aware Masked Autoencoders",
    "authors": [
      "Stella Girtsou",
      "Emiliano Diaz Salas-Porras",
      "Lilli Freischem",
      "Joppe Massant",
      "Kyriaki-Margarita Bintsi",
      "Guiseppe Castiglione",
      "William Jones",
      "Michael Eisinger",
      "Emmanuel Johnson",
      "Anna Jungbluth"
    ],
    "abstract": "Clouds play a key role in Earth's radiation balance with complex effects that\nintroduce large uncertainties into climate models. Real-time 3D cloud data is\nessential for improving climate predictions. This study leverages geostationary\nimagery from MSG/SEVIRI and radar reflectivity measurements of cloud profiles\nfrom CloudSat/CPR to reconstruct 3D cloud structures. We first apply\nself-supervised learning (SSL) methods-Masked Autoencoders (MAE) and\ngeospatially-aware SatMAE on unlabelled MSG images, and then fine-tune our\nmodels on matched image-profile pairs. Our approach outperforms\nstate-of-the-art methods like U-Nets, and our geospatial encoding further\nimproves prediction results, demonstrating the potential of SSL for cloud\nreconstruction.",
    "categories": [
      "cs.CV",
      "cs.AI",
      "68T45"
    ],
    "primary_category": "cs.CV",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2501.02035v1",
    "published_date": "2025-01-03 12:26:04 UTC",
    "updated_date": "2025-01-03 12:26:04 UTC"
  },
  {
    "arxiv_id": "2502.00003v1",
    "title": "Defending Compute Thresholds Against Legal Loopholes",
    "authors": [
      "Matteo Pistillo",
      "Pablo Villalobos"
    ],
    "abstract": "Existing legal frameworks on AI rely on training compute thresholds as a\nproxy to identify potentially-dangerous AI models and trigger increased\nregulatory attention. In the United States, Section 4.2(a) of Executive Order\n14110 instructs the Secretary of Commerce to require extensive reporting from\ndevelopers of AI models above a certain training compute threshold. In the\nEuropean Union, Article 51 of the AI Act establishes a presumption that AI\nmodels above a certain compute threshold have high impact capabilities and\nhence pose systemic risk, thus subjecting their developers to several\nobligations including capability evaluations, reporting, and incident\nmonitoring. In this paper, we examine some enhancement techniques that are\ncapable of decreasing training compute usage while preserving, or even\nincreasing, model capabilities. Since training compute thresholds rely on\ntraining compute as a metric and trigger for increased regulatory attention,\nthese capability-enhancing and compute-saving techniques could constitute a\nlegal loophole to existing training compute thresholds. In particular, we\nconcentrate on four illustrative techniques (fine-tuning, model reuse, model\nexpansion, and above compute-optimal inference compute) with the goal of\nfurthering the conversation about their implications on training compute\nthresholds as a legal mechanism and advancing policy recommendations that could\naddress the relevant legal loopholes.",
    "categories": [
      "cs.CY",
      "cs.AI"
    ],
    "primary_category": "cs.CY",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2502.00003v1",
    "published_date": "2025-01-03 12:07:21 UTC",
    "updated_date": "2025-01-03 12:07:21 UTC"
  },
  {
    "arxiv_id": "2501.01763v1",
    "title": "Quantifying A Firm's AI Engagement: Constructing Objective, Data-Driven, AI Stock Indices Using 10-K Filings",
    "authors": [
      "Lennart Ante",
      "Aman Saggu"
    ],
    "abstract": "Following an analysis of existing AI-related exchange-traded funds (ETFs), we\nreveal the selection criteria for determining which stocks qualify as\nAI-related are often opaque and rely on vague phrases and subjective judgments.\nThis paper proposes a new, objective, data-driven approach using natural\nlanguage processing (NLP) techniques to classify AI stocks by analyzing annual\n10-K filings from 3,395 NASDAQ-listed firms between 2011 and 2023. This\nanalysis quantifies each company's engagement with AI through binary indicators\nand weighted AI scores based on the frequency and context of AI-related terms.\nUsing these metrics, we construct four AI stock indices-the Equally Weighted AI\nIndex (AII), the Size-Weighted AI Index (SAII), and two Time-Discounted AI\nIndices (TAII05 and TAII5X)-offering different perspectives on AI investment.\nWe validate our methodology through an event study on the launch of OpenAI's\nChatGPT, demonstrating that companies with higher AI engagement saw\nsignificantly greater positive abnormal returns, with analyses supporting the\npredictive power of our AI measures. Our indices perform on par with or surpass\n14 existing AI-themed ETFs and the Nasdaq Composite Index in risk-return\nprofiles, market responsiveness, and overall performance, achieving higher\naverage daily returns and risk-adjusted metrics without increased volatility.\nThese results suggest our NLP-based approach offers a reliable,\nmarket-responsive, and cost-effective alternative to existing AI-related ETF\nproducts. Our innovative methodology can also guide investors, asset managers,\nand policymakers in using corporate data to construct other thematic\nportfolios, contributing to a more transparent, data-driven, and competitive\napproach.",
    "categories": [
      "q-fin.GN",
      "cs.AI",
      "econ.EM",
      "q-fin.PM",
      "q-fin.RM",
      "91G60, 68T50, 91B84, 91B82, 91B28, 91G70",
      "J.4; H.3.3; I.2.7; J.1"
    ],
    "primary_category": "q-fin.GN",
    "comment": "43 pages, 5 tables, 3 figures, 1 appendix figure",
    "pdf_url": "http://arxiv.org/pdf/2501.01763v1",
    "published_date": "2025-01-03 11:27:49 UTC",
    "updated_date": "2025-01-03 11:27:49 UTC"
  },
  {
    "arxiv_id": "2501.04038v1",
    "title": "Listening and Seeing Again: Generative Error Correction for Audio-Visual Speech Recognition",
    "authors": [
      "Rui Liu",
      "Hongyu Yuan",
      "Haizhou Li"
    ],
    "abstract": "Unlike traditional Automatic Speech Recognition (ASR), Audio-Visual Speech\nRecognition (AVSR) takes audio and visual signals simultaneously to infer the\ntranscription. Recent studies have shown that Large Language Models (LLMs) can\nbe effectively used for Generative Error Correction (GER) in ASR by predicting\nthe best transcription from ASR-generated N-best hypotheses. However, these\nLLMs lack the ability to simultaneously understand audio and visual, making the\nGER approach challenging to apply in AVSR. In this work, we propose a novel GER\nparadigm for AVSR, termed AVGER, that follows the concept of ``listening and\nseeing again''. Specifically, we first use the powerful AVSR system to read the\naudio and visual signals to get the N-Best hypotheses, and then use the\nQ-former-based Multimodal Synchronous Encoder to read the audio and visual\ninformation again and convert them into an audio and video compression\nrepresentation respectively that can be understood by LLM. Afterward, the\naudio-visual compression representation and the N-Best hypothesis together\nconstitute a Cross-modal Prompt to guide the LLM in producing the best\ntranscription. In addition, we also proposed a Multi-Level Consistency\nConstraint training criterion, including logits-level, utterance-level and\nrepresentations-level, to improve the correction accuracy while enhancing the\ninterpretability of audio and visual compression representations. The\nexperimental results on the LRS3 dataset show that our method outperforms\ncurrent mainstream AVSR systems. The proposed AVGER can reduce the Word Error\nRate (WER) by 24% compared to them. Code and models can be found at:\nhttps://github.com/CircleRedRain/AVGER.",
    "categories": [
      "cs.MM",
      "cs.AI",
      "cs.SD",
      "eess.AS"
    ],
    "primary_category": "cs.MM",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2501.04038v1",
    "published_date": "2025-01-03 10:51:14 UTC",
    "updated_date": "2025-01-03 10:51:14 UTC"
  },
  {
    "arxiv_id": "2501.01743v2",
    "title": "Automating Legal Concept Interpretation with LLMs: Retrieval, Generation, and Evaluation",
    "authors": [
      "Kangcheng Luo",
      "Quzhe Huang",
      "Cong Jiang",
      "Yansong Feng"
    ],
    "abstract": "Legal articles often include vague concepts for adapting to the ever-changing\nsociety. Providing detailed interpretations of these concepts is a critical and\nchallenging task even for legal practitioners. It requires meticulous and\nprofessional annotations and summarizations by legal experts, which are\nadmittedly time-consuming and expensive to collect at scale. By emulating legal\nexperts' doctrinal method, we introduce a novel framework, ATRIE, using large\nlanguage models (LLMs) to AuTomatically Retrieve concept-related information,\nInterpret legal concepts, and Evaluate generated interpretations, eliminating\ndependence on legal experts. ATRIE comprises a legal concept interpreter and a\nlegal concept interpretation evaluator. The interpreter uses LLMs to retrieve\nrelevant information from judicial precedents and interpret legal concepts. The\nevaluator uses performance changes on legal concept entailment, a downstream\ntask we propose, as a proxy of interpretation quality. Automatic and\nmultifaceted human evaluations indicate that the quality of our interpretations\nis comparable to those written by legal experts, with superior\ncomprehensiveness and readability. Although there remains a slight gap in\naccuracy, it can already assist legal practitioners in improving the efficiency\nof concept interpretation.",
    "categories": [
      "cs.CL",
      "cs.AI"
    ],
    "primary_category": "cs.CL",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2501.01743v2",
    "published_date": "2025-01-03 10:11:38 UTC",
    "updated_date": "2025-02-16 09:15:08 UTC"
  },
  {
    "arxiv_id": "2501.01741v1",
    "title": "How Toxic Can You Get? Search-based Toxicity Testing for Large Language Models",
    "authors": [
      "Simone Corbo",
      "Luca Bancale",
      "Valeria De Gennaro",
      "Livia Lestingi",
      "Vincenzo Scotti",
      "Matteo Camilli"
    ],
    "abstract": "Language is a deep-rooted means of perpetration of stereotypes and\ndiscrimination. Large Language Models (LLMs), now a pervasive technology in our\neveryday lives, can cause extensive harm when prone to generating toxic\nresponses. The standard way to address this issue is to align the LLM, which,\nhowever, dampens the issue without constituting a definitive solution.\nTherefore, testing LLM even after alignment efforts remains crucial for\ndetecting any residual deviations with respect to ethical standards. We present\nEvoTox, an automated testing framework for LLMs' inclination to toxicity,\nproviding a way to quantitatively assess how much LLMs can be pushed towards\ntoxic responses even in the presence of alignment. The framework adopts an\niterative evolution strategy that exploits the interplay between two LLMs, the\nSystem Under Test (SUT) and the Prompt Generator steering SUT responses toward\nhigher toxicity. The toxicity level is assessed by an automated oracle based on\nan existing toxicity classifier. We conduct a quantitative and qualitative\nempirical evaluation using four state-of-the-art LLMs as evaluation subjects\nhaving increasing complexity (7-13 billion parameters). Our quantitative\nevaluation assesses the cost-effectiveness of four alternative versions of\nEvoTox against existing baseline methods, based on random search, curated\ndatasets of toxic prompts, and adversarial attacks. Our qualitative assessment\nengages human evaluators to rate the fluency of the generated prompts and the\nperceived toxicity of the responses collected during the testing sessions.\nResults indicate that the effectiveness, in terms of detected toxicity level,\nis significantly higher than the selected baseline methods (effect size up to\n1.0 against random search and up to 0.99 against adversarial attacks).\nFurthermore, EvoTox yields a limited cost overhead (from 22% to 35% on\naverage).",
    "categories": [
      "cs.SE",
      "cs.AI",
      "cs.CL"
    ],
    "primary_category": "cs.SE",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2501.01741v1",
    "published_date": "2025-01-03 10:08:49 UTC",
    "updated_date": "2025-01-03 10:08:49 UTC"
  },
  {
    "arxiv_id": "2501.01733v1",
    "title": "Augmentation Matters: A Mix-Paste Method for X-Ray Prohibited Item Detection under Noisy Annotations",
    "authors": [
      "Ruikang Chen",
      "Yan Yan",
      "Jing-Hao Xue",
      "Yang Lu",
      "Hanzi Wang"
    ],
    "abstract": "Automatic X-ray prohibited item detection is vital for public safety.\nExisting deep learning-based methods all assume that the annotations of\ntraining X-ray images are correct. However, obtaining correct annotations is\nextremely hard if not impossible for large-scale X-ray images, where item\noverlapping is ubiquitous.As a result, X-ray images are easily contaminated\nwith noisy annotations, leading to performance deterioration of existing\nmethods.In this paper, we address the challenging problem of training a robust\nprohibited item detector under noisy annotations (including both category noise\nand bounding box noise) from a novel perspective of data augmentation, and\npropose an effective label-aware mixed patch paste augmentation method\n(Mix-Paste). Specifically, for each item patch, we mix several item patches\nwith the same category label from different images and replace the original\npatch in the image with the mixed patch. In this way, the probability of\ncontaining the correct prohibited item within the generated image is increased.\nMeanwhile, the mixing process mimics item overlapping, enabling the model to\nlearn the characteristics of X-ray images. Moreover, we design an item-based\nlarge-loss suppression (LLS) strategy to suppress the large losses\ncorresponding to potentially positive predictions of additional items due to\nthe mixing operation. We show the superiority of our method on X-ray datasets\nunder noisy annotations. In addition, we evaluate our method on the noisy\nMS-COCO dataset to showcase its generalization ability. These results clearly\nindicate the great potential of data augmentation to handle noise annotations.\nThe source code is released at https://github.com/wscds/Mix-Paste.",
    "categories": [
      "cs.CV",
      "cs.AI"
    ],
    "primary_category": "cs.CV",
    "comment": "The manuscript has been ACCEPTED for publication as a regular paper\n  in the IEEE Transactions on Information Forensics & Security",
    "pdf_url": "http://arxiv.org/pdf/2501.01733v1",
    "published_date": "2025-01-03 09:51:51 UTC",
    "updated_date": "2025-01-03 09:51:51 UTC"
  },
  {
    "arxiv_id": "2501.01732v1",
    "title": "Combined Hyper-Extensible Extremely-Secured Zero-Trust CIAM-PAM architecture",
    "authors": [
      "Shivom Aggarwal",
      "Shourya Mehra",
      "Safeer Sathar"
    ],
    "abstract": "Customer Identity and Access Management (CIAM) systems play a pivotal role in\nsecuring enterprise infrastructures. However, the complexity of implementing\nthese systems requires careful architectural planning to ensure positive Return\non Investment (RoI) and avoid costly delays. The proliferation of Active\nPersistent cyber threats, coupled with advancements in AI, cloud computing, and\ngeographically distributed customer populations, necessitates a paradigm shift\ntowards adaptive and zero-trust security frameworks. This paper introduces the\nCombined Hyper-Extensible Extremely-Secured Zero-Trust (CHEZ) CIAM-PAM\narchitecture, designed specifically for large-scale enterprises. The CHEZ PL\nCIAM-PAM framework addresses critical security gaps by integrating federated\nidentity management (private and public identities), password-less\nauthentication, adaptive multi-factor authentication (MFA), microservice-based\nPEP (Policy Entitlement Point), multi-layer RBAC (Role Based Access Control)\nand multi-level trust systems. This future-proof design also includes\nend-to-end data encryption, and seamless integration with state-of-the-art\nAI-based threat detection systems, while ensuring compliance with stringent\nregulatory standards.",
    "categories": [
      "cs.CR",
      "cs.AI",
      "cs.NI"
    ],
    "primary_category": "cs.CR",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2501.01732v1",
    "published_date": "2025-01-03 09:49:25 UTC",
    "updated_date": "2025-01-03 09:49:25 UTC"
  },
  {
    "arxiv_id": "2501.01727v1",
    "title": "Proposing Hierarchical Goal-Conditioned Policy Planning in Multi-Goal Reinforcement Learning",
    "authors": [
      "Gavin B. Rens"
    ],
    "abstract": "Humanoid robots must master numerous tasks with sparse rewards, posing a\nchallenge for reinforcement learning (RL). We propose a method combining RL and\nautomated planning to address this. Our approach uses short goal-conditioned\npolicies (GCPs) organized hierarchically, with Monte Carlo Tree Search (MCTS)\nplanning using high-level actions (HLAs). Instead of primitive actions, the\nplanning process generates HLAs. A single plan-tree, maintained during the\nagent's lifetime, holds knowledge about goal achievement. This hierarchy\nenhances sample efficiency and speeds up reasoning by reusing HLAs and\nanticipating future actions. Our Hierarchical Goal-Conditioned Policy Planning\n(HGCPP) framework uniquely integrates GCPs, MCTS, and hierarchical RL,\npotentially improving exploration and planning in complex tasks.",
    "categories": [
      "cs.AI",
      "cs.LG"
    ],
    "primary_category": "cs.AI",
    "comment": "10 pages, 4 figures, this is a preprint of the peer-reviewed version\n  published by SCITEPRESS for ICAART-2025",
    "pdf_url": "http://arxiv.org/pdf/2501.01727v1",
    "published_date": "2025-01-03 09:37:54 UTC",
    "updated_date": "2025-01-03 09:37:54 UTC"
  },
  {
    "arxiv_id": "2501.09025v2",
    "title": "Cyber Shadows: Neutralizing Security Threats with AI and Targeted Policy Measures",
    "authors": [
      "Marc Schmitt",
      "Pantelis Koutroumpis"
    ],
    "abstract": "The digital age, driven by the AI revolution, brings significant\nopportunities but also conceals security threats, which we refer to as cyber\nshadows. These threats pose risks at individual, organizational, and societal\nlevels. This paper examines the systemic impact of these cyber threats and\nproposes a comprehensive cybersecurity strategy that integrates AI-driven\nsolutions, such as Intrusion Detection Systems (IDS), with targeted policy\ninterventions. By combining technological and regulatory measures, we create a\nmultilevel defense capable of addressing both direct threats and indirect\nnegative externalities. We emphasize that the synergy between AI-driven\nsolutions and policy interventions is essential for neutralizing cyber threats\nand mitigating their negative impact on the digital economy. Finally, we\nunderscore the need for continuous adaptation of these strategies, especially\nin response to the rapid advancement of autonomous AI-driven attacks, to ensure\nthe creation of secure and resilient digital ecosystems.",
    "categories": [
      "cs.CR",
      "cs.AI",
      "cs.CY",
      "econ.GN",
      "q-fin.EC"
    ],
    "primary_category": "cs.CR",
    "comment": "IEEE Transactions on Artificial Intelligence",
    "pdf_url": "http://arxiv.org/pdf/2501.09025v2",
    "published_date": "2025-01-03 09:26:50 UTC",
    "updated_date": "2025-01-28 17:15:49 UTC"
  },
  {
    "arxiv_id": "2501.06211v1",
    "title": "FLAME: Financial Large-Language Model Assessment and Metrics Evaluation",
    "authors": [
      "Jiayu Guo",
      "Yu Guo",
      "Martha Li",
      "Songtao Tan"
    ],
    "abstract": "LLMs have revolutionized NLP and demonstrated potential across diverse\ndomains. More and more financial LLMs have been introduced for finance-specific\ntasks, yet comprehensively assessing their value is still challenging. In this\npaper, we introduce FLAME, a comprehensive financial LLMs evaluation system in\nChinese, which includes two core evaluation benchmarks: FLAME-Cer and\nFLAME-Sce. FLAME-Cer covers 14 types of authoritative financial certifications,\nincluding CPA, CFA, and FRM, with a total of approximately 16,000 carefully\nselected questions. All questions have been manually reviewed to ensure\naccuracy and representativeness. FLAME-Sce consists of 10 primary core\nfinancial business scenarios, 21 secondary financial business scenarios, and a\ncomprehensive evaluation set of nearly 100 tertiary financial application\ntasks. We evaluate 6 representative LLMs, including GPT-4o, GLM-4, ERNIE-4.0,\nQwen2.5, XuanYuan3, and the latest Baichuan4-Finance, revealing\nBaichuan4-Finance excels other LLMs in most tasks. By establishing a\ncomprehensive and professional evaluation system, FLAME facilitates the\nadvancement of financial LLMs in Chinese contexts. Instructions for\nparticipating in the evaluation are available on GitHub:\nhttps://github.com/FLAME-ruc/FLAME.",
    "categories": [
      "cs.CL",
      "cs.AI",
      "cs.CE"
    ],
    "primary_category": "cs.CL",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2501.06211v1",
    "published_date": "2025-01-03 09:17:23 UTC",
    "updated_date": "2025-01-03 09:17:23 UTC"
  },
  {
    "arxiv_id": "2501.01711v1",
    "title": "LLMs & Legal Aid: Understanding Legal Needs Exhibited Through User Queries",
    "authors": [
      "Michal Kuk",
      "Jakub Harasta"
    ],
    "abstract": "The paper presents a preliminary analysis of an experiment conducted by Frank\nBold, a Czech expert group, to explore user interactions with GPT-4 for\naddressing legal queries. Between May 3, 2023, and July 25, 2023, 1,252 users\nsubmitted 3,847 queries. Unlike studies that primarily focus on the accuracy,\nfactuality, or hallucination tendencies of large language models (LLMs), our\nanalysis focuses on the user query dimension of the interaction. Using GPT-4o\nfor zero-shot classification, we categorized queries on (1) whether users\nprovided factual information about their issue (29.95%) or not (70.05%), (2)\nwhether they sought legal information (64.93%) or advice on the course of\naction (35.07\\%), and (3) whether they imposed requirements to shape or control\nthe model's answer (28.57%) or not (71.43%). We provide both quantitative and\nqualitative insight into user needs and contribute to a better understanding of\nuser engagement with LLMs.",
    "categories": [
      "cs.HC",
      "cs.AI"
    ],
    "primary_category": "cs.HC",
    "comment": "Accepted at AI for Access to Justice Workshop at Jurix 2024, Brno,\n  Czechia",
    "pdf_url": "http://arxiv.org/pdf/2501.01711v1",
    "published_date": "2025-01-03 09:12:35 UTC",
    "updated_date": "2025-01-03 09:12:35 UTC"
  },
  {
    "arxiv_id": "2501.01709v3",
    "title": "MoVE-KD: Knowledge Distillation for VLMs with Mixture of Visual Encoders",
    "authors": [
      "Jiajun Cao",
      "Yuan Zhang",
      "Tao Huang",
      "Ming Lu",
      "Qizhe Zhang",
      "Ruichuan An",
      "Ningning MA",
      "Shanghang Zhang"
    ],
    "abstract": "Visual encoders are fundamental components in vision-language models (VLMs),\neach showcasing unique strengths derived from various pre-trained visual\nfoundation models. To leverage the various capabilities of these encoders,\nrecent studies incorporate multiple encoders within a single VLM, leading to a\nconsiderable increase in computational cost. In this paper, we present\nMixture-of-Visual-Encoder Knowledge Distillation (MoVE-KD), a novel framework\nthat distills the unique proficiencies of multiple vision encoders into a\nsingle, efficient encoder model. Specifically, to mitigate conflicts and retain\nthe unique characteristics of each teacher encoder, we employ low-rank\nadaptation (LoRA) and mixture-of-experts (MoEs) to selectively activate\nspecialized knowledge based on input features, enhancing both adaptability and\nefficiency. To regularize the KD process and enhance performance, we propose an\nattention-based distillation strategy that adaptively weighs the different\nencoders and emphasizes valuable visual tokens, reducing the burden of\nreplicating comprehensive but distinct features from multiple teachers.\nComprehensive experiments on popular VLMs, such as LLaVA and LLaVA-NeXT,\nvalidate the effectiveness of our method. Our code is available at:\nhttps://github.com/hey-cjj/MoVE-KD.",
    "categories": [
      "cs.CV",
      "cs.AI"
    ],
    "primary_category": "cs.CV",
    "comment": "Accepted by CVPR 2025",
    "pdf_url": "http://arxiv.org/pdf/2501.01709v3",
    "published_date": "2025-01-03 09:10:34 UTC",
    "updated_date": "2025-03-18 07:34:44 UTC"
  },
  {
    "arxiv_id": "2501.01705v2",
    "title": "The Essence of Contextual Understanding in Theory of Mind: A Study on Question Answering with Story Characters",
    "authors": [
      "Chulun Zhou",
      "Qiujing Wang",
      "Mo Yu",
      "Xiaoqian Yue",
      "Rui Lu",
      "Jiangnan Li",
      "Yifan Zhou",
      "Shunchi Zhang",
      "Jie Zhou",
      "Wai Lam"
    ],
    "abstract": "Theory-of-Mind (ToM) is a fundamental psychological capability that allows\nhumans to understand and interpret the mental states of others. Humans infer\nothers' thoughts by integrating causal cues and indirect clues from broad\ncontextual information, often derived from past interactions. In other words,\nhuman ToM heavily relies on the understanding about the backgrounds and life\nstories of others. Unfortunately, this aspect is largely overlooked in existing\nbenchmarks for evaluating machines' ToM capabilities, due to their usage of\nshort narratives without global context, especially personal background of\ncharacters. In this paper, we verify the importance of comprehensive contextual\nunderstanding about personal backgrounds in ToM and assess the performance of\nLLMs in such complex scenarios. To achieve this, we introduce CharToM\nbenchmark, comprising 1,035 ToM questions based on characters from classic\nnovels. Our human study reveals a significant disparity in performance: the\nsame group of educated participants performs dramatically better when they have\nread the novels compared to when they have not. In parallel, our experiments on\nstate-of-the-art LLMs, including the very recent o1 and DeepSeek-R1 models,\nshow that LLMs still perform notably worse than humans, despite that they have\nseen these stories during pre-training. This highlights the limitations of\ncurrent LLMs in capturing the nuanced contextual information required for ToM\nreasoning.",
    "categories": [
      "cs.CL",
      "cs.AI"
    ],
    "primary_category": "cs.CL",
    "comment": "20 pages",
    "pdf_url": "http://arxiv.org/pdf/2501.01705v2",
    "published_date": "2025-01-03 09:04:45 UTC",
    "updated_date": "2025-04-09 08:36:10 UTC"
  },
  {
    "arxiv_id": "2501.02032v1",
    "title": "Dynamic Feature Fusion: Combining Global Graph Structures and Local Semantics for Blockchain Fraud Detection",
    "authors": [
      "Zhang Sheng",
      "Liangliang Song",
      "Yanbin Wang"
    ],
    "abstract": "The advent of blockchain technology has facilitated the widespread adoption\nof smart contracts in the financial sector. However, current fraud detection\nmethodologies exhibit limitations in capturing both global structural patterns\nwithin transaction networks and local semantic relationships embedded in\ntransaction data. Most existing models focus on either structural information\nor semantic features individually, leading to suboptimal performance in\ndetecting complex fraud patterns.In this paper, we propose a dynamic feature\nfusion model that combines graph-based representation learning and semantic\nfeature extraction for blockchain fraud detection. Specifically, we construct\nglobal graph representations to model account relationships and extract local\ncontextual features from transaction data. A dynamic multimodal fusion\nmechanism is introduced to adaptively integrate these features, enabling the\nmodel to capture both structural and semantic fraud patterns effectively. We\nfurther develop a comprehensive data processing pipeline, including graph\nconstruction, temporal feature enhancement, and text preprocessing.\nExperimental results on large-scale real-world blockchain datasets demonstrate\nthat our method outperforms existing benchmarks across accuracy, F1 score, and\nrecall metrics. This work highlights the importance of integrating structural\nrelationships and semantic similarities for robust fraud detection and offers a\nscalable solution for securing blockchain systems.",
    "categories": [
      "cs.CR",
      "cs.AI",
      "cs.SE"
    ],
    "primary_category": "cs.CR",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2501.02032v1",
    "published_date": "2025-01-03 09:04:43 UTC",
    "updated_date": "2025-01-03 09:04:43 UTC"
  },
  {
    "arxiv_id": "2501.01702v2",
    "title": "AgentRefine: Enhancing Agent Generalization through Refinement Tuning",
    "authors": [
      "Dayuan Fu",
      "Keqing He",
      "Yejie Wang",
      "Wentao Hong",
      "Zhuoma Gongque",
      "Weihao Zeng",
      "Wei Wang",
      "Jingang Wang",
      "Xunliang Cai",
      "Weiran Xu"
    ],
    "abstract": "Large Language Model (LLM) based agents have proved their ability to perform\ncomplex tasks like humans. However, there is still a large gap between\nopen-sourced LLMs and commercial models like the GPT series. In this paper, we\nfocus on improving the agent generalization capabilities of LLMs via\ninstruction tuning. We first observe that the existing agent training corpus\nexhibits satisfactory results on held-in evaluation sets but fails to\ngeneralize to held-out sets. These agent-tuning works face severe formatting\nerrors and are frequently stuck in the same mistake for a long while. We\nanalyze that the poor generalization ability comes from overfitting to several\nmanual agent environments and a lack of adaptation to new situations. They\nstruggle with the wrong action steps and can not learn from the experience but\njust memorize existing observation-action relations. Inspired by the insight,\nwe propose a novel AgentRefine framework for agent-tuning. The core idea is to\nenable the model to learn to correct its mistakes via observation in the\ntrajectory. Specifically, we propose an agent synthesis framework to encompass\na diverse array of environments and tasks and prompt a strong LLM to refine its\nerror action according to the environment feedback. AgentRefine significantly\noutperforms state-of-the-art agent-tuning work in terms of generalization\nability on diverse agent tasks. It also has better robustness facing\nperturbation and can generate diversified thought in inference. Our findings\nestablish the correlation between agent generalization and self-refinement and\nprovide a new paradigm for future research.",
    "categories": [
      "cs.AI",
      "cs.CL",
      "cs.RO"
    ],
    "primary_category": "cs.AI",
    "comment": "ICLR 2025",
    "pdf_url": "http://arxiv.org/pdf/2501.01702v2",
    "published_date": "2025-01-03 08:55:19 UTC",
    "updated_date": "2025-02-24 12:42:14 UTC"
  },
  {
    "arxiv_id": "2501.02031v1",
    "title": "CarbonChat: Large Language Model-Based Corporate Carbon Emission Analysis and Climate Knowledge Q&A System",
    "authors": [
      "Zhixuan Cao",
      "Ming Han",
      "Jingtao Wang",
      "Meng Jia"
    ],
    "abstract": "As the impact of global climate change intensifies, corporate carbon\nemissions have become a focal point of global attention. In response to issues\nsuch as the lag in climate change knowledge updates within large language\nmodels, the lack of specialization and accuracy in traditional augmented\ngeneration architectures for complex problems, and the high cost and time\nconsumption of sustainability report analysis, this paper proposes CarbonChat:\nLarge Language Model-based corporate carbon emission analysis and climate\nknowledge Q&A system, aimed at achieving precise carbon emission analysis and\npolicy understanding.First, a diversified index module construction method is\nproposed to handle the segmentation of rule-based and long-text documents, as\nwell as the extraction of structured data, thereby optimizing the parsing of\nkey information.Second, an enhanced self-prompt retrieval-augmented generation\narchitecture is designed, integrating intent recognition, structured reasoning\nchains, hybrid retrieval, and Text2SQL, improving the efficiency of semantic\nunderstanding and query conversion.Next, based on the greenhouse gas accounting\nframework, 14 dimensions are established for carbon emission analysis, enabling\nreport summarization, relevance evaluation, and customized responses.Finally,\nthrough a multi-layer chunking mechanism, timestamps, and hallucination\ndetection features, the accuracy and verifiability of the analysis results are\nensured, reducing hallucination rates and enhancing the precision of the\nresponses.",
    "categories": [
      "cs.CL",
      "cs.AI",
      "68T07, 91B06",
      "I.2.1"
    ],
    "primary_category": "cs.CL",
    "comment": "26 pages",
    "pdf_url": "http://arxiv.org/pdf/2501.02031v1",
    "published_date": "2025-01-03 08:45:38 UTC",
    "updated_date": "2025-01-03 08:45:38 UTC"
  },
  {
    "arxiv_id": "2501.01691v2",
    "title": "VidFormer: A novel end-to-end framework fused by 3DCNN and Transformer for Video-based Remote Physiological Measurement",
    "authors": [
      "Jiachen Li",
      "Shisheng Guo",
      "Longzhen Tang",
      "Cuolong Cui",
      "Lingjiang Kong",
      "Xiaobo Yang"
    ],
    "abstract": "Remote physiological signal measurement based on facial videos, also known as\nremote photoplethysmography (rPPG), involves predicting changes in facial\nvascular blood flow from facial videos. While most deep learning-based methods\nhave achieved good results, they often struggle to balance performance across\nsmall and large-scale datasets due to the inherent limitations of convolutional\nneural networks (CNNs) and Transformer. In this paper, we introduce VidFormer,\na novel end-to-end framework that integrates 3-Dimension Convolutional Neural\nNetwork (3DCNN) and Transformer models for rPPG tasks. Initially, we conduct an\nanalysis of the traditional skin reflection model and subsequently introduce an\nenhanced model for the reconstruction of rPPG signals. Based on this improved\nmodel, VidFormer utilizes 3DCNN and Transformer to extract local and global\nfeatures from input data, respectively. To enhance the spatiotemporal feature\nextraction capabilities of VidFormer, we incorporate temporal-spatial attention\nmechanisms tailored for both 3DCNN and Transformer. Additionally, we design a\nmodule to facilitate information exchange and fusion between the 3DCNN and\nTransformer. Our evaluation on five publicly available datasets demonstrates\nthat VidFormer outperforms current state-of-the-art (SOTA) methods. Finally, we\ndiscuss the essential roles of each VidFormer module and examine the effects of\nethnicity, makeup, and exercise on its performance.",
    "categories": [
      "cs.CV",
      "cs.AI"
    ],
    "primary_category": "cs.CV",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2501.01691v2",
    "published_date": "2025-01-03 08:18:08 UTC",
    "updated_date": "2025-01-07 02:57:03 UTC"
  },
  {
    "arxiv_id": "2501.03182v1",
    "title": "Boosting Explainability through Selective Rationalization in Pre-trained Language Models",
    "authors": [
      "Libing Yuan",
      "Shuaibo Hu",
      "Kui Yu",
      "Le Wu"
    ],
    "abstract": "The widespread application of pre-trained language models (PLMs) in natural\nlanguage processing (NLP) has led to increasing concerns about their\nexplainability. Selective rationalization is a self-explanatory framework that\nselects human-intelligible input subsets as rationales for predictions. Recent\nstudies have shown that applying existing rationalization frameworks to PLMs\nwill result in severe degeneration and failure problems, producing sub-optimal\nor meaningless rationales. Such failures severely damage trust in\nrationalization methods and constrain the application of rationalization\ntechniques on PLMs. In this paper, we find that the homogeneity of tokens in\nthe sentences produced by PLMs is the primary contributor to these problems. To\naddress these challenges, we propose a method named Pre-trained Language\nModel's Rationalization (PLMR), which splits PLMs into a generator and a\npredictor to deal with NLP tasks while providing interpretable rationales. The\ngenerator in PLMR also alleviates homogeneity by pruning irrelevant tokens,\nwhile the predictor uses full-text information to standardize predictions.\nExperiments conducted on two widely used datasets across multiple PLMs\ndemonstrate the effectiveness of the proposed method PLMR in addressing the\nchallenge of applying selective rationalization to PLMs. Codes:\nhttps://github.com/ylb777/PLMR.",
    "categories": [
      "cs.CL",
      "cs.AI"
    ],
    "primary_category": "cs.CL",
    "comment": "KDD 2025 research track",
    "pdf_url": "http://arxiv.org/pdf/2501.03182v1",
    "published_date": "2025-01-03 07:52:40 UTC",
    "updated_date": "2025-01-03 07:52:40 UTC"
  },
  {
    "arxiv_id": "2501.01679v1",
    "title": "Adaptive Few-shot Prompting for Machine Translation with Pre-trained Language Models",
    "authors": [
      "Lei Tang",
      "Jinghui Qin",
      "Wenxuan Ye",
      "Hao Tan",
      "Zhijing Yang"
    ],
    "abstract": "Recently, Large language models (LLMs) with in-context learning have\ndemonstrated remarkable potential in handling neural machine translation.\nHowever, existing evidence shows that LLMs are prompt-sensitive and it is\nsub-optimal to apply the fixed prompt to any input for downstream machine\ntranslation tasks. To address this issue, we propose an adaptive few-shot\nprompting (AFSP) framework to automatically select suitable translation\ndemonstrations for various source input sentences to further elicit the\ntranslation capability of an LLM for better machine translation. First, we\nbuild a translation demonstration retrieval module based on LLM's embedding to\nretrieve top-k semantic-similar translation demonstrations from aligned\nparallel translation corpus. Rather than using other embedding models for\nsemantic demonstration retrieval, we build a hybrid demonstration retrieval\nmodule based on the embedding layer of the deployed LLM to build better input\nrepresentation for retrieving more semantic-related translation demonstrations.\nThen, to ensure better semantic consistency between source inputs and target\noutputs, we force the deployed LLM itself to generate multiple output\ncandidates in the target language with the help of translation demonstrations\nand rerank these candidates. Besides, to better evaluate the effectiveness of\nour AFSP framework on the latest language and extend the research boundary of\nneural machine translation, we construct a high-quality diplomatic\nChinese-English parallel dataset that consists of 5,528 parallel\nChinese-English sentences. Finally, extensive experiments on the proposed\ndiplomatic Chinese-English parallel dataset and the United Nations Parallel\nCorpus (Chinese-English part) show the effectiveness and superiority of our\nproposed AFSP.",
    "categories": [
      "cs.CL",
      "cs.AI"
    ],
    "primary_category": "cs.CL",
    "comment": "published to AAAI2025",
    "pdf_url": "http://arxiv.org/pdf/2501.01679v1",
    "published_date": "2025-01-03 07:47:59 UTC",
    "updated_date": "2025-01-03 07:47:59 UTC"
  },
  {
    "arxiv_id": "2501.02030v1",
    "title": "Detecting Music Performance Errors with Transformers",
    "authors": [
      "Benjamin Shiue-Hal Chou",
      "Purvish Jajal",
      "Nicholas John Eliopoulos",
      "Tim Nadolsky",
      "Cheng-Yun Yang",
      "Nikita Ravi",
      "James C. Davis",
      "Kristen Yeon-Ji Yun",
      "Yung-Hsiang Lu"
    ],
    "abstract": "Beginner musicians often struggle to identify specific errors in their\nperformances, such as playing incorrect notes or rhythms. There are two\nlimitations in existing tools for music error detection: (1) Existing\napproaches rely on automatic alignment; therefore, they are prone to errors\ncaused by small deviations between alignment targets.; (2) There is a lack of\nsufficient data to train music error detection models, resulting in\nover-reliance on heuristics. To address (1), we propose a novel transformer\nmodel, Polytune, that takes audio inputs and outputs annotated music scores.\nThis model can be trained end-to-end to implicitly align and compare\nperformance audio with music scores through latent space representations. To\naddress (2), we present a novel data generation technique capable of creating\nlarge-scale synthetic music error datasets. Our approach achieves a 64.1%\naverage Error Detection F1 score, improving upon prior work by 40 percentage\npoints across 14 instruments. Additionally, compared with existing\ntranscription methods repurposed for music error detection, our model can\nhandle multiple instruments. Our source code and datasets are available at\nhttps://github.com/ben2002chou/Polytune.",
    "categories": [
      "cs.SD",
      "cs.AI",
      "eess.AS"
    ],
    "primary_category": "cs.SD",
    "comment": "AAAI 2025",
    "pdf_url": "http://arxiv.org/pdf/2501.02030v1",
    "published_date": "2025-01-03 07:04:20 UTC",
    "updated_date": "2025-01-03 07:04:20 UTC"
  },
  {
    "arxiv_id": "2501.02029v1",
    "title": "Spot Risks Before Speaking! Unraveling Safety Attention Heads in Large Vision-Language Models",
    "authors": [
      "Ziwei Zheng",
      "Junyao Zhao",
      "Le Yang",
      "Lijun He",
      "Fan Li"
    ],
    "abstract": "With the integration of an additional modality, large vision-language models\n(LVLMs) exhibit greater vulnerability to safety risks (e.g., jailbreaking)\ncompared to their language-only predecessors. Although recent studies have\ndevoted considerable effort to the post-hoc alignment of LVLMs, the inner\nsafety mechanisms remain largely unexplored. In this paper, we discover that\ninternal activations of LVLMs during the first token generation can effectively\nidentify malicious prompts across different attacks. This inherent safety\nperception is governed by sparse attention heads, which we term ``safety\nheads.\" Further analysis reveals that these heads act as specialized shields\nagainst malicious prompts; ablating them leads to higher attack success rates,\nwhile the model's utility remains unaffected. By locating these safety heads\nand concatenating their activations, we construct a straightforward but\npowerful malicious prompt detector that integrates seamlessly into the\ngeneration process with minimal extra inference overhead. Despite its simple\nstructure of a logistic regression model, the detector surprisingly exhibits\nstrong zero-shot generalization capabilities. Experiments across various\nprompt-based attacks confirm the effectiveness of leveraging safety heads to\nprotect LVLMs. Code is available at \\url{https://github.com/Ziwei-Zheng/SAHs}.",
    "categories": [
      "cs.LG",
      "cs.AI",
      "cs.CR",
      "cs.CV"
    ],
    "primary_category": "cs.LG",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2501.02029v1",
    "published_date": "2025-01-03 07:01:15 UTC",
    "updated_date": "2025-01-03 07:01:15 UTC"
  },
  {
    "arxiv_id": "2501.01664v1",
    "title": "BARTPredict: Empowering IoT Security with LLM-Driven Cyber Threat Prediction",
    "authors": [
      "Alaeddine Diaf",
      "Abdelaziz Amara Korba",
      "Nour Elislem Karabadji",
      "Yacine Ghamri-Doudane"
    ],
    "abstract": "The integration of Internet of Things (IoT) technology in various domains has\nled to operational advancements, but it has also introduced new vulnerabilities\nto cybersecurity threats, as evidenced by recent widespread cyberattacks on IoT\ndevices. Intrusion detection systems are often reactive, triggered by specific\npatterns or anomalies observed within the network. To address this challenge,\nthis work proposes a proactive approach to anticipate and preemptively mitigate\nmalicious activities, aiming to prevent potential damage before it occurs. This\npaper proposes an innovative intrusion prediction framework empowered by\nPre-trained Large Language Models (LLMs). The framework incorporates two LLMs:\na fine-tuned Bidirectional and AutoRegressive Transformers (BART) model for\npredicting network traffic and a fine-tuned Bidirectional Encoder\nRepresentations from Transformers (BERT) model for evaluating the predicted\ntraffic. By harnessing the bidirectional capabilities of BART the framework\nthen identifies malicious packets among these predictions. Evaluated using the\nCICIoT2023 IoT attack dataset, our framework showcases a notable enhancement in\npredictive performance, attaining an impressive 98% overall accuracy, providing\na powerful response to the cybersecurity challenges that confront IoT networks.",
    "categories": [
      "cs.CR",
      "cs.AI"
    ],
    "primary_category": "cs.CR",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2501.01664v1",
    "published_date": "2025-01-03 06:37:39 UTC",
    "updated_date": "2025-01-03 06:37:39 UTC"
  },
  {
    "arxiv_id": "2501.01658v1",
    "title": "EAUWSeg: Eliminating annotation uncertainty in weakly-supervised medical image segmentation",
    "authors": [
      "Wang Lituan",
      "Zhang Lei",
      "Wang Yan",
      "Wang Zhenbin",
      "Zhang Zhenwei",
      "Zhang Yi"
    ],
    "abstract": "Weakly-supervised medical image segmentation is gaining traction as it\nrequires only rough annotations rather than accurate pixel-to-pixel labels,\nthereby reducing the workload for specialists. Although some progress has been\nmade, there is still a considerable performance gap between the label-efficient\nmethods and fully-supervised one, which can be attributed to the uncertainty\nnature of these weak labels. To address this issue, we propose a novel weak\nannotation method coupled with its learning framework EAUWSeg to eliminate the\nannotation uncertainty. Specifically, we first propose the Bounded Polygon\nAnnotation (BPAnno) by simply labeling two polygons for a lesion. Then, the\ntailored learning mechanism that explicitly treat bounded polygons as two\nseparated annotations is proposed to learn invariant feature by providing\nadversarial supervision signal for model training. Subsequently, a\nconfidence-auxiliary consistency learner incorporates with a\nclassification-guided confidence generator is designed to provide reliable\nsupervision signal for pixels in uncertain region by leveraging the feature\npresentation consistency across pixels within the same category as well as\nclass-specific information encapsulated in bounded polygons annotation.\nExperimental results demonstrate that EAUWSeg outperforms existing\nweakly-supervised segmentation methods. Furthermore, compared to\nfully-supervised counterparts, the proposed method not only delivers superior\nperformance but also costs much less annotation workload. This underscores the\nsuperiority and effectiveness of our approach.",
    "categories": [
      "cs.CV",
      "cs.AI"
    ],
    "primary_category": "cs.CV",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2501.01658v1",
    "published_date": "2025-01-03 06:21:02 UTC",
    "updated_date": "2025-01-03 06:21:02 UTC"
  },
  {
    "arxiv_id": "2501.01649v1",
    "title": "AVATAR: Adversarial Autoencoders with Autoregressive Refinement for Time Series Generation",
    "authors": [
      "MohammadReza EskandariNasab",
      "Shah Muhammad Hamdi",
      "Soukaina Filali Boubrahimi"
    ],
    "abstract": "Data augmentation can significantly enhance the performance of machine\nlearning tasks by addressing data scarcity and improving generalization.\nHowever, generating time series data presents unique challenges. A model must\nnot only learn a probability distribution that reflects the real data\ndistribution but also capture the conditional distribution at each time step to\npreserve the inherent temporal dependencies. To address these challenges, we\nintroduce AVATAR, a framework that combines Adversarial Autoencoders (AAE) with\nAutoregressive Learning to achieve both objectives. Specifically, our technique\nintegrates the autoencoder with a supervisor and introduces a novel supervised\nloss to assist the decoder in learning the temporal dynamics of time series\ndata. Additionally, we propose another innovative loss function, termed\ndistribution loss, to guide the encoder in more efficiently aligning the\naggregated posterior of the autoencoder's latent representation with a prior\nGaussian distribution. Furthermore, our framework employs a joint training\nmechanism to simultaneously train all networks using a combined loss, thereby\nfulfilling the dual objectives of time series generation. We evaluate our\ntechnique across a variety of time series datasets with diverse\ncharacteristics. Our experiments demonstrate significant improvements in both\nthe quality and practical utility of the generated data, as assessed by various\nqualitative and quantitative metrics.",
    "categories": [
      "cs.LG",
      "cs.AI"
    ],
    "primary_category": "cs.LG",
    "comment": "This work has been accepted to the SDM 2025 on December 20, 2024",
    "pdf_url": "http://arxiv.org/pdf/2501.01649v1",
    "published_date": "2025-01-03 05:44:13 UTC",
    "updated_date": "2025-01-03 05:44:13 UTC"
  },
  {
    "arxiv_id": "2501.01645v3",
    "title": "HLV-1K: A Large-scale Hour-Long Video Benchmark for Time-Specific Long Video Understanding",
    "authors": [
      "Heqing Zou",
      "Tianze Luo",
      "Guiyang Xie",
      "Victor Xiao Jie Zhang",
      "Fengmao Lv",
      "Guangcong Wang",
      "Junyang Chen",
      "Zhuochen Wang",
      "Hansheng Zhang",
      "Huaijian Zhang"
    ],
    "abstract": "Multimodal large language models have become a popular topic in deep visual\nunderstanding due to many promising real-world applications. However, hour-long\nvideo understanding, spanning over one hour and containing tens of thousands of\nvisual frames, remains under-explored because of 1) challenging long-term video\nanalyses, 2) inefficient large-model approaches, and 3) lack of large-scale\nbenchmark datasets. Among them, in this paper, we focus on building a\nlarge-scale hour-long long video benchmark, HLV-1K, designed to evaluate long\nvideo understanding models. HLV-1K comprises 1009 hour-long videos with 14,847\nhigh-quality question answering (QA) and multi-choice question asnwering (MCQA)\npairs with time-aware query and diverse annotations, covering frame-level,\nwithin-event-level, cross-event-level, and long-term reasoning tasks. We\nevaluate our benchmark using existing state-of-the-art methods and demonstrate\nits value for testing deep long video understanding capabilities at different\nlevels and for various tasks. This includes promoting future long video\nunderstanding tasks at a granular level, such as deep understanding of long\nlive videos, meeting recordings, and movies.",
    "categories": [
      "cs.CV",
      "cs.AI"
    ],
    "primary_category": "cs.CV",
    "comment": "Accepted to ICME 2025",
    "pdf_url": "http://arxiv.org/pdf/2501.01645v3",
    "published_date": "2025-01-03 05:32:37 UTC",
    "updated_date": "2025-05-13 06:38:44 UTC"
  },
  {
    "arxiv_id": "2501.01639v2",
    "title": "Implications of Artificial Intelligence on Health Data Privacy and Confidentiality",
    "authors": [
      "Ahmad Momani"
    ],
    "abstract": "The rapid integration of artificial intelligence (AI) in healthcare is\nrevolutionizing medical diagnostics, personalized medicine, and operational\nefficiency. However, alongside these advancements, significant challenges arise\nconcerning patient data privacy, ethical considerations, and regulatory\ncompliance. This paper examines the dual impact of AI on healthcare,\nhighlighting its transformative potential and the critical need for\nsafeguarding sensitive health information. It explores the role of the Health\nInsurance Portability and Accountability Act (HIPAA) as a regulatory framework\nfor ensuring data privacy and security, emphasizing the importance of robust\nsafeguards and ethical standards in AI-driven healthcare. Through case studies,\nincluding AI applications in diabetic retinopathy, oncology, and the\ncontroversies surrounding data sharing, this study underscores the ethical and\nlegal complexities of AI implementation. A balanced approach that fosters\ninnovation while maintaining patient trust and privacy is imperative. The\nfindings emphasize the importance of continuous education, transparency, and\nadherence to regulatory frameworks to harness AI's full potential responsibly\nand ethically in healthcare.",
    "categories": [
      "cs.CY",
      "cs.AI"
    ],
    "primary_category": "cs.CY",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2501.01639v2",
    "published_date": "2025-01-03 05:17:23 UTC",
    "updated_date": "2025-01-06 18:52:32 UTC"
  },
  {
    "arxiv_id": "2501.01638v2",
    "title": "A non-ergodic framework for understanding emergent capabilities in Large Language Models",
    "authors": [
      "Javier Marn"
    ],
    "abstract": "Large language models have emergent capabilities that come unexpectedly at\nscale, but we need a theoretical framework to explain why and how they emerge.\nWe prove that language models are actually non-ergodic systems while providing\na mathematical framework based on Stuart Kauffman's theory of the adjacent\npossible (TAP) to explain capability emergence. Our resource-constrained TAP\nequation demonstrates how architectural, training, and contextual constraints\ninteract to shape model capabilities through phase transitions in semantic\nspace. We prove through experiments with three different language models that\ncapacities emerge through discrete transitions guided by constraint\ninteractions and path-dependent exploration. This framework provides a\ntheoretical basis for understanding emergence in language models and guides the\ndevelopment of architectures that can guide capability emergence.",
    "categories": [
      "cs.CL",
      "cs.AI",
      "cs.LG"
    ],
    "primary_category": "cs.CL",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2501.01638v2",
    "published_date": "2025-01-03 05:11:41 UTC",
    "updated_date": "2025-02-28 08:07:50 UTC"
  },
  {
    "arxiv_id": "2501.01625v1",
    "title": "ICPC: In-context Prompt Compression with Faster Inference",
    "authors": [
      "Ziyang Yu",
      "Yuyu Liu"
    ],
    "abstract": "Despite the recent success of Large Language Models (LLMs), it remains\nchallenging to feed LLMs with long prompts due to the fixed size of LLM inputs.\nAs a remedy, prompt compression becomes a promising solution by removing\nredundant tokens in the prompt. However, using LLM in the existing works\nrequires additional computation resources and leads to memory overheads. To\naddress it, we propose ICPC (In-context Prompt Compression), a novel and\nscalable prompt compression method that adaptively reduces the prompt length.\nThe key idea of ICPC is to calculate the probability of each word appearing in\nthe prompt using encoders and calculate information carried by each word\nthrough the information function, which effectively reduces the information\nloss during prompt compression and increases the speed of compression.\nEmpirically, we demonstrate that ICPC can effectively compress long texts of\ndifferent categories and thus achieve better performance and speed on different\ntypes of NLP tasks.",
    "categories": [
      "cs.CL",
      "cs.AI"
    ],
    "primary_category": "cs.CL",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2501.01625v1",
    "published_date": "2025-01-03 03:46:51 UTC",
    "updated_date": "2025-01-03 03:46:51 UTC"
  },
  {
    "arxiv_id": "2501.01618v1",
    "title": "Merging Context Clustering with Visual State Space Models for Medical Image Segmentation",
    "authors": [
      "Yun Zhu",
      "Dong Zhang",
      "Yi Lin",
      "Yifei Feng",
      "Jinhui Tang"
    ],
    "abstract": "Medical image segmentation demands the aggregation of global and local\nfeature representations, posing a challenge for current methodologies in\nhandling both long-range and short-range feature interactions. Recently, vision\nmamba (ViM) models have emerged as promising solutions for addressing model\ncomplexities by excelling in long-range feature iterations with linear\ncomplexity. However, existing ViM approaches overlook the importance of\npreserving short-range local dependencies by directly flattening spatial tokens\nand are constrained by fixed scanning patterns that limit the capture of\ndynamic spatial context information. To address these challenges, we introduce\na simple yet effective method named context clustering ViM (CCViM), which\nincorporates a context clustering module within the existing ViM models to\nsegment image tokens into distinct windows for adaptable local clustering. Our\nmethod effectively combines long-range and short-range feature interactions,\nthereby enhancing spatial contextual representations for medical image\nsegmentation tasks. Extensive experimental evaluations on diverse public\ndatasets, i.e., Kumar, CPM17, ISIC17, ISIC18, and Synapse demonstrate the\nsuperior performance of our method compared to current state-of-the-art\nmethods. Our code can be found at https://github.com/zymissy/CCViM.",
    "categories": [
      "cs.CV",
      "cs.AI"
    ],
    "primary_category": "cs.CV",
    "comment": "Our paper has been accepted by the IEEE Transactions on Medical\n  Imaging. Our code can be found at https://github.com/zymissy/CCViM",
    "pdf_url": "http://arxiv.org/pdf/2501.01618v1",
    "published_date": "2025-01-03 03:25:30 UTC",
    "updated_date": "2025-01-03 03:25:30 UTC"
  },
  {
    "arxiv_id": "2501.01611v1",
    "title": "Google is all you need: Semi-Supervised Transfer Learning Strategy For Light Multimodal Multi-Task Classification Model",
    "authors": [
      "Haixu Liu",
      "Penghao Jiang",
      "Zerui Tao"
    ],
    "abstract": "As the volume of digital image data increases, the effectiveness of image\nclassification intensifies. This study introduces a robust multi-label\nclassification system designed to assign multiple labels to a single image,\naddressing the complexity of images that may be associated with multiple\ncategories (ranging from 1 to 19, excluding 12). We propose a multi-modal\nclassifier that merges advanced image recognition algorithms with Natural\nLanguage Processing (NLP) models, incorporating a fusion module to integrate\nthese distinct modalities. The purpose of integrating textual data is to\nenhance the accuracy of label prediction by providing contextual understanding\nthat visual analysis alone cannot fully capture. Our proposed classification\nmodel combines Convolutional Neural Networks (CNN) for image processing with\nNLP techniques for analyzing textual description (i.e., captions). This\napproach includes rigorous training and validation phases, with each model\ncomponent verified and analyzed through ablation experiments. Preliminary\nresults demonstrate the classifier's accuracy and efficiency, highlighting its\npotential as an automatic image-labeling system.",
    "categories": [
      "cs.CV",
      "cs.AI"
    ],
    "primary_category": "cs.CV",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2501.01611v1",
    "published_date": "2025-01-03 03:11:17 UTC",
    "updated_date": "2025-01-03 03:11:17 UTC"
  },
  {
    "arxiv_id": "2501.02026v1",
    "title": "Recursive Decomposition of Logical Thoughts: Framework for Superior Reasoning and Knowledge Propagation in Large Language Models",
    "authors": [
      "Kaleem Ullah Qasim",
      "Jiashu Zhang",
      "Tariq Alsahfi",
      "Ateeq Ur Rehman Butt"
    ],
    "abstract": "Enhancing the reasoning capabilities of Large Language Models remains a\ncritical challenge in artificial intelligence. We introduce RDoLT, Recursive\nDecomposition of Logical Thought prompting, a novel framework that\nsignificantly boosts LLM reasoning performance. RDoLT is built on three key\ninnovations: (1) recursively breaking down complex reasoning tasks into\nsub-tasks of progressive complexity; (2) employing an advanced selection and\nscoring mechanism to identify the most promising reasoning thoughts; and (3)\nintegrating a knowledge propagation module that mimics human learning by\nkeeping track of strong and weak thoughts for information propagation. Our\napproach was evaluated across multiple benchmarks, including GSM8K, SVAMP,\nMultiArith, LastLetterConcatenation, and Gaokao2023 Math. The results\ndemonstrate that RDoLT consistently outperforms existing state-of-the-art\ntechniques, achieving a 90.98 percent accuracy on GSM8K with ChatGPT-4,\nsurpassing state-of-the-art techniques by 6.28 percent. Similar improvements\nwere observed on other benchmarks, with accuracy gains ranging from 5.5 percent\nto 6.75 percent. These findings highlight RDoLT's potential to advance prompt\nengineering, offering a more effective and generalizable approach to complex\nreasoning tasks.",
    "categories": [
      "cs.CL",
      "cs.AI",
      "cs.LG",
      "cs.LO"
    ],
    "primary_category": "cs.CL",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2501.02026v1",
    "published_date": "2025-01-03 02:55:44 UTC",
    "updated_date": "2025-01-03 02:55:44 UTC"
  },
  {
    "arxiv_id": "2501.01601v1",
    "title": "Few-shot Implicit Function Generation via Equivariance",
    "authors": [
      "Suizhi Huang",
      "Xingyi Yang",
      "Hongtao Lu",
      "Xinchao Wang"
    ],
    "abstract": "Implicit Neural Representations (INRs) have emerged as a powerful framework\nfor representing continuous signals. However, generating diverse INR weights\nremains challenging due to limited training data. We introduce Few-shot\nImplicit Function Generation, a new problem setup that aims to generate diverse\nyet functionally consistent INR weights from only a few examples. This is\nchallenging because even for the same signal, the optimal INRs can vary\nsignificantly depending on their initializations. To tackle this, we propose\nEquiGen, a framework that can generate new INRs from limited data. The core\nidea is that functionally similar networks can be transformed into one another\nthrough weight permutations, forming an equivariance group. By projecting these\nweights into an equivariant latent space, we enable diverse generation within\nthese groups, even with few examples. EquiGen implements this through an\nequivariant encoder trained via contrastive learning and smooth augmentation,\nan equivariance-guided diffusion process, and controlled perturbations in the\nequivariant subspace. Experiments on 2D image and 3D shape INR datasets\ndemonstrate that our approach effectively generates diverse INR weights while\npreserving their functional properties in few-shot scenarios.",
    "categories": [
      "cs.CV",
      "cs.AI"
    ],
    "primary_category": "cs.CV",
    "comment": "11 pages, 8 figures, 4 tables",
    "pdf_url": "http://arxiv.org/pdf/2501.01601v1",
    "published_date": "2025-01-03 02:23:55 UTC",
    "updated_date": "2025-01-03 02:23:55 UTC"
  },
  {
    "arxiv_id": "2501.01598v1",
    "title": "Prism: Mining Task-aware Domains in Non-i.i.d. IMU Data for Flexible User Perception",
    "authors": [
      "Yunzhe Li",
      "Facheng Hu",
      "Hongzi Zhu",
      "Quan Liu",
      "Xiaoke Zhao",
      "Jiangang Shen",
      "Shan Chang",
      "Minyi Guo"
    ],
    "abstract": "A wide range of user perception applications leverage inertial measurement\nunit (IMU) data for online prediction. However, restricted by the non-i.i.d.\nnature of IMU data collected from mobile devices, most systems work well only\nin a controlled setting (e.g., for a specific user in particular postures),\nlimiting application scenarios. To achieve uncontrolled online prediction on\nmobile devices, referred to as the flexible user perception (FUP) problem, is\nattractive but hard. In this paper, we propose a novel scheme, called Prism,\nwhich can obtain high FUP accuracy on mobile devices. The core of Prism is to\ndiscover task-aware domains embedded in IMU dataset, and to train a\ndomain-aware model on each identified domain. To this end, we design an\nexpectation-maximization (EM) algorithm to estimate latent domains with respect\nto the specific downstream perception task. Finally, the best-fit model can be\nautomatically selected for use by comparing the test sample and all identified\ndomains in the feature space. We implement Prism on various mobile devices and\nconduct extensive experiments. Results demonstrate that Prism can achieve the\nbest FUP performance with a low latency.",
    "categories": [
      "cs.AI",
      "cs.HC"
    ],
    "primary_category": "cs.AI",
    "comment": "in Proceedings of IEEE INFOCOM 2025, London, United Kingdom",
    "pdf_url": "http://arxiv.org/pdf/2501.01598v1",
    "published_date": "2025-01-03 02:07:42 UTC",
    "updated_date": "2025-01-03 02:07:42 UTC"
  },
  {
    "arxiv_id": "2501.01594v1",
    "title": "PSYCHE: A Multi-faceted Patient Simulation Framework for Evaluation of Psychiatric Assessment Conversational Agents",
    "authors": [
      "Jingoo Lee",
      "Kyungho Lim",
      "Young-Chul Jung",
      "Byung-Hoon Kim"
    ],
    "abstract": "Recent advances in large language models (LLMs) have accelerated the\ndevelopment of conversational agents capable of generating human-like\nresponses. Since psychiatric assessments typically involve complex\nconversational interactions between psychiatrists and patients, there is\ngrowing interest in developing LLM-based psychiatric assessment conversational\nagents (PACAs) that aim to simulate the role of psychiatrists in clinical\nevaluations. However, standardized methods for benchmarking the clinical\nappropriateness of PACAs' interaction with patients still remain underexplored.\nHere, we propose PSYCHE, a novel framework designed to enable the 1) clinically\nrelevant, 2) ethically safe, 3) cost-efficient, and 4) quantitative evaluation\nof PACAs. This is achieved by simulating psychiatric patients based on a\nmulti-faceted psychiatric construct that defines the simulated patients'\nprofiles, histories, and behaviors, which PACAs are expected to assess. We\nvalidate the effectiveness of PSYCHE through a study with 10 board-certified\npsychiatrists, supported by an in-depth analysis of the simulated patient\nutterances.",
    "categories": [
      "cs.CL",
      "cs.AI",
      "cs.LG"
    ],
    "primary_category": "cs.CL",
    "comment": "The first two authors contributed equally",
    "pdf_url": "http://arxiv.org/pdf/2501.01594v1",
    "published_date": "2025-01-03 01:38:46 UTC",
    "updated_date": "2025-01-03 01:38:46 UTC"
  },
  {
    "arxiv_id": "2501.01593v1",
    "title": "BLAST: A Stealthy Backdoor Leverage Attack against Cooperative Multi-Agent Deep Reinforcement Learning based Systems",
    "authors": [
      "Yinbo Yu",
      "Saihao Yan",
      "Xueyu Yin",
      "Jing Fang",
      "Jiajia Liu"
    ],
    "abstract": "Recent studies have shown that cooperative multi-agent deep reinforcement\nlearning (c-MADRL) is under the threat of backdoor attacks. Once a backdoor\ntrigger is observed, it will perform malicious actions leading to failures or\nmalicious goals. However, existing backdoor attacks suffer from several issues,\ne.g., instant trigger patterns lack stealthiness, the backdoor is trained or\nactivated by an additional network, or all agents are backdoored. To this end,\nin this paper, we propose a novel backdoor leverage attack against c-MADRL,\nBLAST, which attacks the entire multi-agent team by embedding the backdoor only\nin a single agent. Firstly, we introduce adversary spatiotemporal behavior\npatterns as the backdoor trigger rather than manual-injected fixed visual\npatterns or instant status and control the period to perform malicious actions.\nThis method can guarantee the stealthiness and practicality of BLAST. Secondly,\nwe hack the original reward function of the backdoor agent via unilateral\nguidance to inject BLAST, so as to achieve the \\textit{leverage attack effect}\nthat can pry open the entire multi-agent system via a single backdoor agent. We\nevaluate our BLAST against 3 classic c-MADRL algorithms (VDN, QMIX, and MAPPO)\nin 2 popular c-MADRL environments (SMAC and Pursuit), and 2 existing defense\nmechanisms. The experimental results demonstrate that BLAST can achieve a high\nattack success rate while maintaining a low clean performance variance rate.",
    "categories": [
      "cs.AI",
      "cs.CR",
      "cs.LG"
    ],
    "primary_category": "cs.AI",
    "comment": "12. arXiv admin note: substantial text overlap with arXiv:2409.07775",
    "pdf_url": "http://arxiv.org/pdf/2501.01593v1",
    "published_date": "2025-01-03 01:33:29 UTC",
    "updated_date": "2025-01-03 01:33:29 UTC"
  },
  {
    "arxiv_id": "2501.01588v1",
    "title": "(WhyPHI) Fine-Tuning PHI-3 for Multiple-Choice Question Answering: Methodology, Results, and Challenges",
    "authors": [
      "Mohamed Hisham Abdellatif"
    ],
    "abstract": "Large Language Models (LLMs) have become essential tools across various\ndomains due to their impressive capabilities in understanding and generating\nhuman-like text. The ability to accurately answer multiple-choice questions\n(MCQs) holds significant value in education, particularly in automated tutoring\nsystems and assessment platforms. However, adapting LLMs to handle MCQ tasks\neffectively remains challenging due to the hallucinations and unclear prompts.\nThis work explores the potential of Microsoft's PHI-3\\cite{Abdin2024}, a\ncompact yet efficient LLM, for MCQ answering. Our contributions include\nfine-tuning the model on the TruthfulQA dataset, designing optimized prompts to\nenhance model performance, and evaluating using perplexity and traditional\nmetrics like accuracy and F1 score. Results show a remarkable improvement in\nPHI-3.5's MCQ handling post-fine-tuning, with perplexity decreasing from 4.68\nto 2.27, and accuracy rising from 62\\% to 90.8\\%. This research underlines the\nimportance of efficient models in adaptive learning systems and educational\nassessments, paving the way for broader integration into the classroom,\nparticularly in fields like test preparation, student feedback, and\npersonalized learning.",
    "categories": [
      "cs.CL",
      "cs.AI"
    ],
    "primary_category": "cs.CL",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2501.01588v1",
    "published_date": "2025-01-03 00:56:46 UTC",
    "updated_date": "2025-01-03 00:56:46 UTC"
  },
  {
    "arxiv_id": "2503.15489v1",
    "title": "PersonaAI: Leveraging Retrieval-Augmented Generation and Personalized Context for AI-Driven Digital Avatars",
    "authors": [
      "Elvis Kimara",
      "Kunle S. Oguntoye",
      "Jian Sun"
    ],
    "abstract": "This paper introduces PersonaAI, a cutting-edge application that leverages\nRetrieval-Augmented Generation (RAG) and the LLAMA model to create highly\npersonalized digital avatars capable of accurately mimicking individual\npersonalities. Designed as a cloud-based mobile application, PersonaAI captures\nuser data seamlessly, storing it in a secure database for retrieval and\nanalysis. The result is a system that provides context-aware, accurate\nresponses to user queries, enhancing the potential of AI-driven\npersonalization.\n  Why should you care? PersonaAI combines the scalability of RAG with the\nefficiency of prompt-engineered LLAMA3, offering a lightweight, sustainable\nalternative to traditional large language model (LLM) training methods. The\nsystem's novel approach to data collection, utilizing real-time user\ninteractions via a mobile app, ensures enhanced context relevance while\nmaintaining user privacy. By open-sourcing our implementation, we aim to foster\nadaptability and community-driven development.\n  PersonaAI demonstrates how AI can transform interactions by merging\nefficiency, scalability, and personalization, making it a significant step\nforward in the future of digital avatars and personalized AI.",
    "categories": [
      "cs.HC",
      "cs.AI"
    ],
    "primary_category": "cs.HC",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2503.15489v1",
    "published_date": "2025-01-03 00:31:28 UTC",
    "updated_date": "2025-01-03 00:31:28 UTC"
  }
]