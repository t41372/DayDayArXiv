{
  "date": "2024-04-30",
  "category": "cs.AI",
  "summary": "欢迎来到 UTC 时间 2024-04-30 的 arXiv 中文 TLDR 快报！今天 arXiv 更新了 86 篇论文，主要聚焦 AI 模型优化（如 LLM 和强化学习）、多模态处理、医疗应用以及计算机视觉等领域，其中 KAN（Kolmogorov-Arnold Networks）作为 ICLR 2025 接受的创新性工作令人印象深刻，同时 RLHF 和 Almanac Copilot 等论文展示了知名学者（如 Asuman Ozdaglar 和相关团队）在 AI 对齐与实际应用上的进展，强调了 AI 的可解释性和高效性。\n\n以下是今日论文的精选摘要，我优先讨论重要、话题度高或有实际影响的文章（如涉及 LLM 优化、医疗 AI 和视觉生成），相关论文（如强化学习和多模态方法）归类讨论；其他较小众或理论性强的文章（如本体论研究）则快速掠过，只列标题和核心要点，以控制篇幅。\n\n### 重点论文讨论\n\n**RLHF from Heterogeneous Feedback（异质反馈下的强化学习）**  \n这篇论文由 Asuman Ozdaglar 等知名学者发布，提出两种框架处理异质人类反馈：基于个性化（如表示学习和聚类）的多奖励模型，以及基于聚合（如功利主义和 Leximin 方法）的单模型。贡献在于减少偏置和方差，提供样本复杂度保证，发现这些方法能提升 AI 系统（如大语言模型）对人类偏好的对齐，尤其在战略性反馈场景中。\n\n**Q-Newton: Hybrid Quantum-Classical Scheduling for Accelerating Neural Network Training with Newton's Gradient Descent（Q-Newton: 混合量子-经典调度加速神经网络训练）**  \n论文引入量子线性求解器加速牛顿梯度下降，提出 Q-Newton 框架，通过估计和减少条件数来优化训练。发现该方法显著减少训练时间，远超 SGD 等优化器，在未来量子计算场景下潜力巨大。代码已开源，展示了量子计算在深度学习中的实际应用。\n\n**Almanac Copilot: Towards Autonomous Electronic Health Record Navigation（Almanac Copilot: 面向自主电子健康记录导航）**  \n聚焦医疗 AI，该方法使用自主代理辅助临床文档检索和命令执行，在 EHR-QA 数据集上实现 74% 的任务成功率。贡献在于减轻医生负担，提高效率，发现代理能处理真实患者数据，缓解警报疲劳问题。\n\n**SemantiCodec: An Ultra Low Bitrate Semantic Audio Codec for General Sound（SemantiCodec: 超低比特率语义音频编解码器）**  \n论文提出双编码器架构（语义和声学编码器），结合扩散模型解码器，实现低于 100 tokens/秒的音频压缩。发现它在语音、声音和音乐领域优于现有编解码器，提供更丰富的语义信息。代码和演示已开源，适用于高效音频处理。\n\n**STT: Stateful Tracking with Transformers for Autonomous Driving（STT: 使用 Transformer 的状态跟踪）**  \n针对自动驾驶，论文开发 STT 模型，联合优化数据关联和状态估计（如速度和加速度）。贡献在于使用 Transformer 处理历史检测数据，发现它在 Waymo 数据集上实现实时性能，并引入新指标 S-MOTA 和 MOTPS 评估。\n\n**Guiding Attention in End-to-End Driving Models（引导端到端驾驶模型的注意力）**  \n论文通过添加损失项使用显著语义图引导模型注意力，提升驾驶质量。发现该方法在 CARLA 模拟器上有效，尤其在数据和计算资源有限时，无需测试时语义图即可工作。已接受 IV 2024。\n\n**KAN: Kolmogorov-Arnold Networks（KAN: Kolmogorov-Arnold 网络）**  \n这篇 ICLR 2025 接受的论文提出 KAN 作为 MLP 的替代，使用可学习边激活函数（如样条）。贡献在于提升准确性和可解释性，发现 KAN 在数据拟合和 PDE 求解中表现优于传统 MLP，并提供更快的神经缩放定律。\n\n**Who is Authentic Speaker（谁是真实说话者）**  \n论文探索从转换语音中识别真实说话者，使用层次 VLAD 模型。发现该方法在 VCTK 数据集上对转换语音鲁棒，解决了语音转换的安全问题。\n\n**CUVA: Uncovering What, Why and How in Video Anomaly Detection（CUVA: 揭示视频异常的何、为何和如何）**  \n论文提出新基准和指标 MMEval，评估视频异常的成因和影响。贡献在于使用提示方法识别异常类型和解释，发现它在 CVPR 2024 数据集上提升了检测性能。\n\n### 相关论文简要回顾\n- **其他 AI 优化和生成模型：** 如 \"Soft Preference Optimization: Aligning Language Models to Expert Distributions\"（软偏好优化：对齐语言模型），提出无需奖励模型的优化方法，发现它在偏好对齐中更高效；\"Iterative Reasoning Preference Optimization\"（迭代推理偏好优化），使用 EM 框架提升 LLM 推理，表现优于传统采样。\n  \n- **医疗和生物应用：** \"Discovering intrinsic multi-compartment pharmacometric models using Physics Informed Neural Networks\"（使用物理信息神经网络发现药代动力学模型），发现 PINNs 可高效预测药物模型；\"Expanding the Horizon: Enabling Hybrid Quantum Transfer Learning for Long-Tailed Chest X-Ray Classification\"（扩展视野：混合量子迁移学习），使用量子框架提升 X 光分类，展示了数据效率。\n\n- **视觉和多模态处理：** \"NeRF-Insert: 3D Local Editing with Multimodal Control Signals\"（NeRF-Insert: 多模态控制的 3D 编辑），提出编辑框架，支持文本和图像输入，发现它提升了 3D 场景一致性；\"TableVQA-Bench: A Visual Question Answering Benchmark on Multiple Table Domains\"（TableVQA-Bench: 多领域表格视觉问答基准），构建新基准，发现 MLLM 在表格任务上仍有改进空间。\n\n### 快速掠过的文章\n这些论文主题较小众或理论导向，不做深入讨论，仅列标题和要点：\n- **Credentials in the Occupation Ontology（职业本体中的证书）**：本体建模证书类型，发现支持技能整合。\n- **Capabilities: An Ontology（能力：一个本体）**：定义能力本体，发现用于扩展研究数据。\n- **M-DEW: Extending Dynamic Ensemble Weighting to Handle Missing Values（M-DEW: 处理缺失值的动态集成加权）**：改进集成学习，发现减少模型困惑。\n- **APTly: Making Mobile Apps from Natural Language（APTly: 使用自然语言制作移动应用）**：使用 LLM 生成 App，发现提升开发效率。\n- **Other minor works**：如本体论论文（e.g., \"Grounding Realizable Entities\"），主要贡献本体定义；音频或小众领域论文（如 \"Quantifying Nematodes through Images\"），发现图像检测方法有效，但影响有限。\n\n总之，今天的 arXiv 论文突显 AI 领域的创新与应用潜力，尤其在 LLM 优化和跨领域整合上。感兴趣的读者可关注 KAN 和 RLHF 等高影响力工作，未来发展值得期待！",
  "papers": [
    {
      "arxiv_id": "2405.00254v2",
      "title": "RLHF from Heterogeneous Feedback via Personalization and Preference Aggregation",
      "title_zh": "翻译失败",
      "authors": [
        "Chanwoo Park",
        "Mingyang Liu",
        "Dingwen Kong",
        "Kaiqing Zhang",
        "Asuman Ozdaglar"
      ],
      "abstract": "Reinforcement learning from human feedback (RLHF) has been an effective\ntechnique for aligning AI systems with human values, with remarkable successes\nin fine-tuning large-language models recently. Most existing RLHF paradigms\nmake the underlying assumption that human preferences are relatively\nhomogeneous, and can be encoded by a single reward model. In this paper, we\nfocus on addressing the issues due to the inherent heterogeneity in human\npreferences, as well as their potential strategic behavior in providing\nfeedback. Specifically, we propose two frameworks to address heterogeneous\nhuman feedback in principled ways: personalization-based one and\naggregation-based one. For the former, we propose two approaches based on\nrepresentation learning and clustering, respectively, for learning multiple\nreward models that trades off the bias (due to preference heterogeneity) and\nvariance (due to the use of fewer data for learning each model by\npersonalization). We then establish sample complexity guarantees for both\napproaches. For the latter, we aim to adhere to the single-model framework, as\nalready deployed in the current RLHF paradigm, by carefully aggregating diverse\nand truthful preferences from humans. We propose two approaches based on reward\nand preference aggregation, respectively: the former utilizes both\nutilitarianism and Leximin approaches to aggregate individual reward models,\nwith sample complexity guarantees; the latter directly aggregates the human\nfeedback in the form of probabilistic opinions. Under the\nprobabilistic-opinion-feedback model, we also develop an approach to handle\nstrategic human labelers who may bias and manipulate the aggregated preferences\nwith untruthful feedback. Based on the ideas in mechanism design, our approach\nensures truthful preference reporting, with the induced aggregation rule\nmaximizing social welfare functions.",
      "tldr_zh": "该论文探讨了强化学习从人类反馈（RLHF）中处理异质反馈（heterogeneous feedback）的问题，旨在解决现有方法假设人类偏好同质化的局限性。作者提出两种框架：基于个性化的方法，使用 representation learning 和 clustering 学习多个奖励模型，以平衡偏见和方差，并提供了样本复杂度保证；基于聚合的方法，通过功利主义和 Leximin 方式聚合奖励模型，或直接聚合概率意见反馈，确保偏好多样性和真实性。此外，该框架还引入机制设计来应对战略人类标注者，确保真实报告并最大化社会福利，从而提升 RLHF 的鲁棒性和有效性。",
      "categories": [
        "cs.AI",
        "cs.LG"
      ],
      "primary_category": "cs.AI",
      "comment": "Added experiments",
      "pdf_url": "http://arxiv.org/pdf/2405.00254v2",
      "published_date": "2024-04-30 23:57:23 UTC",
      "updated_date": "2024-05-27 14:08:40 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-18T04:43:22.245083"
    },
    {
      "arxiv_id": "2405.00252v3",
      "title": "Q-Newton: Hybrid Quantum-Classical Scheduling for Accelerating Neural Network Training with Newton's Gradient Descent",
      "title_zh": "翻译失败",
      "authors": [
        "Pingzhi Li",
        "Junyu Liu",
        "Hanrui Wang",
        "Tianlong Chen"
      ],
      "abstract": "Optimization techniques in deep learning are predominantly led by first-order\ngradient methodologies, such as SGD. However, neural network training can\ngreatly benefit from the rapid convergence characteristics of second-order\noptimization. Newton's GD stands out in this category, by rescaling the\ngradient using the inverse Hessian. Nevertheless, one of its major bottlenecks\nis matrix inversion, which is notably time-consuming in $O(N^3)$ time with weak\nscalability.\n  Matrix inversion can be translated into solving a series of linear equations.\nGiven that quantum linear solver algorithms (QLSAs), leveraging the principles\nof quantum superposition and entanglement, can operate within a\n$\\text{polylog}(N)$ time frame, they present a promising approach with\nexponential acceleration. Specifically, one of the most recent QLSAs\ndemonstrates a complexity scaling of $O(d\\cdot\\kappa\n\\log(N\\cdot\\kappa/\\epsilon))$, depending on: {size~$N$, condition\nnumber~$\\kappa$, error tolerance~$\\epsilon$, quantum oracle sparsity~$d$} of\nthe matrix. However, this also implies that their potential exponential\nadvantage may be hindered by certain properties (i.e. $\\kappa$ and $d$).\n  We propose Q-Newton, a hybrid quantum-classical scheduler for accelerating\nneural network training with Newton's GD. Q-Newton utilizes a streamlined\nscheduling module that coordinates between quantum and classical linear\nsolvers, by estimating & reducing $\\kappa$ and constructing $d$ for the quantum\nsolver.\n  Our evaluation showcases the potential for Q-Newton to significantly reduce\nthe total training time compared to commonly used optimizers like SGD. We\nhypothesize a future scenario where the gate time of quantum machines is\nreduced, possibly realized by attoseconds physics. Our evaluation establishes\nan ambitious and promising target for the evolution of quantum computing.",
      "tldr_zh": "这篇论文提出 Q-Newton，一种混合量子-经典调度框架，用于加速神经网络训练中的 Newton's Gradient Descent，通过量子线性求解算法 (QLSAs) 解决矩阵反转的 O(N^3) 时间瓶颈问题。框架包括一个调度模块，用于估计和减少矩阵条件数 κ，以及构建量子预言机稀疏度 d，以协调量子和经典求解器。实验评估表明，Q-Newton 相较于传统优化器如 SGD，能显著缩短训练时间，并为量子计算的未来发展设定了一个雄心勃勃的目标。",
      "categories": [
        "quant-ph",
        "cs.AI",
        "cs.LG"
      ],
      "primary_category": "quant-ph",
      "comment": "Our code is provided at https://github.com/UNITES-Lab/q-newton",
      "pdf_url": "http://arxiv.org/pdf/2405.00252v3",
      "published_date": "2024-04-30 23:55:03 UTC",
      "updated_date": "2025-04-29 06:14:40 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-18T04:43:33.834670"
    },
    {
      "arxiv_id": "2405.00248v1",
      "title": "Who is Authentic Speaker",
      "title_zh": "翻译失败",
      "authors": [
        "Qiang Huang"
      ],
      "abstract": "Voice conversion (VC) using deep learning technologies can now generate high\nquality one-to-many voices and thus has been used in some practical application\nfields, such as entertainment and healthcare. However, voice conversion can\npose potential social issues when manipulated voices are employed for deceptive\npurposes. Moreover, it is a big challenge to find who are real speakers from\nthe converted voices as the acoustic characteristics of source speakers are\nchanged greatly. In this paper we attempt to explore the feasibility of\nidentifying authentic speakers from converted voices. This study is conducted\nwith the assumption that certain information from the source speakers persists,\neven when their voices undergo conversion into different target voices.\nTherefore our experiments are geared towards recognising the source speakers\ngiven the converted voices, which are generated by using FragmentVC on the\nrandomly paired utterances from source and target speakers. To improve the\nrobustness against converted voices, our recognition model is constructed by\nusing hierarchical vector of locally aggregated descriptors (VLAD) in deep\nneural networks. The authentic speaker recognition system is mainly tested in\ntwo aspects, including the impact of quality of converted voices and the\nvariations of VLAD. The dataset used in this work is VCTK corpus, where source\nand target speakers are randomly paired. The results obtained on the converted\nutterances show promising performances in recognising authentic speakers from\nconverted voices.",
      "tldr_zh": "本研究探讨了从深度学习驱动的语音转换（Voice Conversion, VC）生成的语音中识别真实说话者的可行性，旨在解决VC可能被用于欺骗性目的的社会问题。研究假设转换后的语音中仍保留部分源说话者信息，并使用FragmentVC生成随机配对的源和目标说话者语音，然后构建基于层次化VLAD（hierarchical vector of locally aggregated descriptors）的深度神经网络模型进行识别。实验在VCTK语料库上评估了转换语音质量和VLAD变体的影响，结果显示该系统在识别真实说话者方面取得了有前景的性能。",
      "categories": [
        "cs.SD",
        "cs.AI",
        "cs.MM",
        "eess.AS"
      ],
      "primary_category": "cs.SD",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2405.00248v1",
      "published_date": "2024-04-30 23:41:00 UTC",
      "updated_date": "2024-04-30 23:41:00 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-18T04:43:45.242952"
    },
    {
      "arxiv_id": "2405.00242v1",
      "title": "Guiding Attention in End-to-End Driving Models",
      "title_zh": "端到端驾驶模型中的注意力引导",
      "authors": [
        "Diego Porres",
        "Yi Xiao",
        "Gabriel Villalonga",
        "Alexandre Levy",
        "Antonio M. López"
      ],
      "abstract": "Vision-based end-to-end driving models trained by imitation learning can lead\nto affordable solutions for autonomous driving. However, training these\nwell-performing models usually requires a huge amount of data, while still\nlacking explicit and intuitive activation maps to reveal the inner workings of\nthese models while driving. In this paper, we study how to guide the attention\nof these models to improve their driving quality and obtain more intuitive\nactivation maps by adding a loss term during training using salient semantic\nmaps. In contrast to previous work, our method does not require these salient\nsemantic maps to be available during testing time, as well as removing the need\nto modify the model's architecture to which it is applied. We perform tests\nusing perfect and noisy salient semantic maps with encouraging results in both,\nthe latter of which is inspired by possible errors encountered with real data.\nUsing CIL++ as a representative state-of-the-art model and the CARLA simulator\nwith its standard benchmarks, we conduct experiments that show the\neffectiveness of our method in training better autonomous driving models,\nespecially when data and computational resources are scarce.",
      "tldr_zh": "本文提出了一种方法，用于引导端到-end driving models的注意力，以提升其驾驶性能和可解释性。具体来说，通过在训练过程中添加基于salient semantic maps的损失项，该方法无需测试时提供这些地图或修改模型架构，即可生成更直观的激活地图。实验在CARLA simulator上使用CIL++模型进行验证，结果显示，该方法显著提高了模型的驾驶质量，尤其在数据和计算资源稀缺时，准确率和鲁棒性均有提升。",
      "categories": [
        "cs.CV",
        "cs.AI"
      ],
      "primary_category": "cs.CV",
      "comment": "Accepted for publication at the 35th IEEE Intelligent Vehicles\n  Symposium (IV 2024)",
      "pdf_url": "http://arxiv.org/pdf/2405.00242v1",
      "published_date": "2024-04-30 23:18:51 UTC",
      "updated_date": "2024-04-30 23:18:51 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-18T04:43:58.065635"
    },
    {
      "arxiv_id": "2405.00236v1",
      "title": "STT: Stateful Tracking with Transformers for Autonomous Driving",
      "title_zh": "翻译失败",
      "authors": [
        "Longlong Jing",
        "Ruichi Yu",
        "Xu Chen",
        "Zhengli Zhao",
        "Shiwei Sheng",
        "Colin Graber",
        "Qi Chen",
        "Qinru Li",
        "Shangxuan Wu",
        "Han Deng",
        "Sangjin Lee",
        "Chris Sweeney",
        "Qiurui He",
        "Wei-Chih Hung",
        "Tong He",
        "Xingyi Zhou",
        "Farshid Moussavi",
        "Zijian Guo",
        "Yin Zhou",
        "Mingxing Tan",
        "Weilong Yang",
        "Congcong Li"
      ],
      "abstract": "Tracking objects in three-dimensional space is critical for autonomous\ndriving. To ensure safety while driving, the tracker must be able to reliably\ntrack objects across frames and accurately estimate their states such as\nvelocity and acceleration in the present. Existing works frequently focus on\nthe association task while either neglecting the model performance on state\nestimation or deploying complex heuristics to predict the states. In this\npaper, we propose STT, a Stateful Tracking model built with Transformers, that\ncan consistently track objects in the scenes while also predicting their states\naccurately. STT consumes rich appearance, geometry, and motion signals through\nlong term history of detections and is jointly optimized for both data\nassociation and state estimation tasks. Since the standard tracking metrics\nlike MOTA and MOTP do not capture the combined performance of the two tasks in\nthe wider spectrum of object states, we extend them with new metrics called\nS-MOTA and MOTPS that address this limitation. STT achieves competitive\nreal-time performance on the Waymo Open Dataset.",
      "tldr_zh": "该论文提出 STT，一种基于 Transformers 的状态跟踪模型，用于自动驾驶中的三维物体跟踪。STT 通过整合检测历史数据中的外观、几何和运动信号，联合优化数据关联和状态估计任务（如速度和加速度），从而实现可靠的跨帧跟踪和准确的状态预测。作者引入了新指标 S-MOTA 和 MOTPS，以全面评估两任务的综合性能，因为标准指标如 MOTA 和 MOTP 存在局限性。实验结果显示，STT 在 Waymo Open Dataset 上实现了竞争性的实时性能。",
      "categories": [
        "cs.RO",
        "cs.AI",
        "cs.CV",
        "cs.LG"
      ],
      "primary_category": "cs.RO",
      "comment": "ICRA 2024",
      "pdf_url": "http://arxiv.org/pdf/2405.00236v1",
      "published_date": "2024-04-30 23:04:36 UTC",
      "updated_date": "2024-04-30 23:04:36 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-18T04:44:09.400201"
    },
    {
      "arxiv_id": "2405.07896v2",
      "title": "Almanac Copilot: Towards Autonomous Electronic Health Record Navigation",
      "title_zh": "翻译失败",
      "authors": [
        "Cyril Zakka",
        "Joseph Cho",
        "Gracia Fahed",
        "Rohan Shad",
        "Michael Moor",
        "Robyn Fong",
        "Dhamanpreet Kaur",
        "Vishnu Ravi",
        "Oliver Aalami",
        "Roxana Daneshjou",
        "Akshay Chaudhari",
        "William Hiesinger"
      ],
      "abstract": "Clinicians spend large amounts of time on clinical documentation, and\ninefficiencies impact quality of care and increase clinician burnout. Despite\nthe promise of electronic medical records (EMR), the transition from\npaper-based records has been negatively associated with clinician wellness, in\npart due to poor user experience, increased burden of documentation, and alert\nfatigue. In this study, we present Almanac Copilot, an autonomous agent capable\nof assisting clinicians with EMR-specific tasks such as information retrieval\nand order placement. On EHR-QA, a synthetic evaluation dataset of 300 common\nEHR queries based on real patient data, Almanac Copilot obtains a successful\ntask completion rate of 74% (n = 221 tasks) with a mean score of 2.45 over 3\n(95% CI:2.34-2.56). By automating routine tasks and streamlining the\ndocumentation process, our findings highlight the significant potential of\nautonomous agents to mitigate the cognitive load imposed on clinicians by\ncurrent EMR systems.",
      "tldr_zh": "该研究针对临床医生在电子健康记录 (EHR) 系统上花费大量时间导致的效率低下和倦怠问题，提出 Almanac Copilot，这是一个自主代理系统，能够自动处理 EHR 特定任务，如信息检索和订单放置。系统在 EHR-QA 数据集（基于真实患者数据的 300 个常见查询）上实现了 74% 的任务完成率和 2.45 的平均分数（95% CI: 2.34-2.56）。通过自动化例行任务，Almanac Copilot 显著减轻了临床医生的认知负担，并展示了提升 EHR 用户体验的潜力。",
      "categories": [
        "cs.AI",
        "cs.HC",
        "cs.IR",
        "cs.LG"
      ],
      "primary_category": "cs.AI",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2405.07896v2",
      "published_date": "2024-04-30 22:55:27 UTC",
      "updated_date": "2024-05-14 20:25:23 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-18T04:44:22.275601"
    },
    {
      "arxiv_id": "2405.00233v2",
      "title": "SemantiCodec: An Ultra Low Bitrate Semantic Audio Codec for General Sound",
      "title_zh": "SemantiCodec：一种超低比特率语义音频编解码器，用于通用声音",
      "authors": [
        "Haohe Liu",
        "Xuenan Xu",
        "Yi Yuan",
        "Mengyue Wu",
        "Wenwu Wang",
        "Mark D. Plumbley"
      ],
      "abstract": "Large language models (LLMs) have significantly advanced audio processing\nthrough audio codecs that convert audio into discrete tokens, enabling the\napplication of language modelling techniques to audio data. However,\ntraditional codecs often operate at high bitrates or within narrow domains such\nas speech and lack the semantic clues required for efficient language\nmodelling. Addressing these challenges, we introduce SemantiCodec, a novel\ncodec designed to compress audio into fewer than a hundred tokens per second\nacross diverse audio types, including speech, general sound, and music, without\ncompromising quality. SemantiCodec features a dual-encoder architecture: a\nsemantic encoder using a self-supervised pre-trained Audio Masked Autoencoder\n(AudioMAE), discretized using k-means clustering on extensive audio data, and\nan acoustic encoder to capture the remaining details. The semantic and acoustic\nencoder outputs are used to reconstruct audio via a diffusion-model-based\ndecoder. SemantiCodec is presented in three variants with token rates of 25,\n50, and 100 per second, supporting a range of ultra-low bit rates between 0.31\nkbps and 1.40 kbps. Experimental results demonstrate that SemantiCodec\nsignificantly outperforms the state-of-the-art Descript codec on reconstruction\nquality. Our results also suggest that SemantiCodec contains significantly\nricher semantic information than all evaluated state-of-the-art audio codecs,\neven at significantly lower bitrates. Our code and demos are available at\nhttps://haoheliu.github.io/SemantiCodec/.",
      "tldr_zh": "本研究引入了 SemantiCodec，一种超低比特率语义音频编解码器，旨在处理各种音频类型（如语音、一般声音和音乐），通过压缩每秒不到一百个 tokens 来实现高效的语言建模，同时保留高质量。SemantiCodec 采用双编码器架构，包括一个基于自监督预训练的 Audio Masked Autoencoder 和 k-means 聚类进行语义编码的编码器，以及一个捕捉细节的声学编码器，后者与扩散模型-based 解码器结合用于音频重建。该编解码器提供三种变体，tokens 速率分别为 25、50 和 100 每秒，对应的比特率为 0.31 kbps 到 1.40 kbps；实验结果显示，其重建质量和语义信息含量均优于现有最先进编解码器 Descript，即使在更低比特率下。",
      "categories": [
        "cs.SD",
        "cs.AI",
        "cs.MM",
        "eess.AS",
        "eess.SP"
      ],
      "primary_category": "cs.SD",
      "comment": "Accepted by Journal of Selected Topics in Signal Processing (JSTSP).\n  Demo and code: https://haoheliu.github.io/SemantiCodec/",
      "pdf_url": "http://arxiv.org/pdf/2405.00233v2",
      "published_date": "2024-04-30 22:51:36 UTC",
      "updated_date": "2024-11-28 12:31:04 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-18T04:44:34.398999"
    },
    {
      "arxiv_id": "2405.00229v1",
      "title": "Aptly: Making Mobile Apps from Natural Language",
      "title_zh": "Aptly：通过自然语言制作移动应用",
      "authors": [
        "Evan W. Patton",
        "David Y. J. Kim",
        "Ashley Granquist",
        "Robin Liu",
        "Arianna Scott",
        "Jennet Zamanova",
        "Harold Abelson"
      ],
      "abstract": "We present Aptly, an extension of the MIT App Inventor platform enabling\nmobile app development via natural language powered by code-generating large\nlanguage models (LLMs). Aptly complements App Inventor's block language with a\ntext language designed to allow visual code generation via text-based LLMs. We\ndetail the technical aspects of how the Aptly server integrates LLMs with a\nrealtime collaboration function to facilitate the automated creation and\nediting of mobile apps given user instructions. The paper concludes with\ninsights from a study of a pilot implementation involving high school students,\nwhich examines Aptly's practicality and user experience. The findings\nunderscore Aptly's potential as a tool that democratizes app development and\nfosters technological creativity.",
      "tldr_zh": "本研究介绍了Aptly，这是一个扩展了MIT App Inventor平台的工具，使用代码生成大型语言模型（LLMs）来实现基于自然语言的移动应用开发。Aptly结合了App Inventor's块语言和一种专为文本-based LLMs设计的文本语言，并通过服务器整合LLMs与实时协作功能，自动处理用户指令以创建和编辑应用。研究通过一项涉及高中生的试点实施，评估了Aptly的实用性和用户体验，结果显示它具有民主化应用开发并激发技术创意的潜力。",
      "categories": [
        "cs.HC",
        "cs.AI",
        "cs.PL"
      ],
      "primary_category": "cs.HC",
      "comment": "11 pages, 7 figures, 2 tables",
      "pdf_url": "http://arxiv.org/pdf/2405.00229v1",
      "published_date": "2024-04-30 22:33:34 UTC",
      "updated_date": "2024-04-30 22:33:34 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-18T04:44:45.182710"
    },
    {
      "arxiv_id": "2405.00218v3",
      "title": "Constrained Decoding for Secure Code Generation",
      "title_zh": "约束解码用于安全",
      "authors": [
        "Yanjun Fu",
        "Ethan Baker",
        "Yu Ding",
        "Yizheng Chen"
      ],
      "abstract": "Code Large Language Models (Code LLMs) have been increasingly used by\ndevelopers to boost productivity, but they often generate vulnerable code.\nThus, there is an urgent need to ensure that code generated by Code LLMs is\ncorrect and secure. Previous research has primarily focused on generating\nsecure code, overlooking the fact that secure code also needs to be correct.\nThis oversight can lead to a false sense of security. Currently, the community\nlacks a method to measure actual progress in this area, and we need solutions\nthat address both security and correctness of code generation.\n  This paper introduces a new benchmark, CodeGuard+, along with two new\nmetrics, to measure Code LLMs' ability to generate both secure and correct\ncode. Using our new evaluation methods, we show that the state-of-the-art\ndefense technique, prefix tuning, may not be as strong as previously believed,\nsince it generates secure code but sacrifices functional correctness. We also\ndemonstrate that different decoding methods significantly affect the security\nof Code LLMs.\n  Furthermore, we explore a new defense direction: constrained decoding for\nsecure code generation. We propose new constrained decoding techniques to\ngenerate secure code. Our results reveal that constrained decoding is more\neffective than prefix tuning to improve the security of Code LLMs, without\nrequiring a specialized training dataset. Moreover, our evaluations over eight\nstate-of-the-art Code LLMs show that constrained decoding has strong\nperformance to improve the security of Code LLMs, and our technique outperforms\nGPT-4.",
      "tldr_zh": "这篇论文针对代码大语言模型（Code LLMs）生成漏洞代码的问题，强调了确保代码既安全又正确的必要性，并引入了新基准CodeGuard+和两个新指标来评估Code LLMs在安全性和正确性方面的性能。研究发现，当前最先进的防御技术prefix tuning虽然能生成安全代码，但会牺牲功能正确性，而不同解码方法会显著影响代码的安全。论文提出constrained decoding作为新防御方向，开发了新技巧来提升Code LLMs的安全性，无需专门训练数据集，并在八个最先进Code LLMs上的评估中显示，该方法优于prefix tuning和GPT-4。",
      "categories": [
        "cs.CR",
        "cs.AI",
        "cs.LG",
        "cs.SE"
      ],
      "primary_category": "cs.CR",
      "comment": "17 pages, 9 figures, our website is available at\n  https://codeguardplus.github.io",
      "pdf_url": "http://arxiv.org/pdf/2405.00218v3",
      "published_date": "2024-04-30 21:52:19 UTC",
      "updated_date": "2024-07-20 19:14:03 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-18T04:44:59.397033"
    },
    {
      "arxiv_id": "2405.00216v1",
      "title": "Graphical Reasoning: LLM-based Semi-Open Relation Extraction",
      "title_zh": "翻译失败",
      "authors": [
        "Yicheng Tao",
        "Yiqun Wang",
        "Longju Bai"
      ],
      "abstract": "This paper presents a comprehensive exploration of relation extraction\nutilizing advanced language models, specifically Chain of Thought (CoT) and\nGraphical Reasoning (GRE) techniques. We demonstrate how leveraging in-context\nlearning with GPT-3.5 can significantly enhance the extraction process,\nparticularly through detailed example-based reasoning. Additionally, we\nintroduce a novel graphical reasoning approach that dissects relation\nextraction into sequential sub-tasks, improving precision and adaptability in\nprocessing complex relational data. Our experiments, conducted on multiple\ndatasets, including manually annotated data, show considerable improvements in\nperformance metrics, underscoring the effectiveness of our methodologies.",
      "tldr_zh": "该论文探讨了基于大型语言模型(LLM)的半开放关系抽取，结合 Chain of Thought (CoT) 和 Graphical Reasoning (GRE) 技术，通过 in-context learning 与 GPT-3.5 的示例推理来提升抽取过程的精度和效率。作者引入了一种新颖的图形推理方法，将关系抽取分解为顺序子任务，从而更好地处理复杂关系数据。实验结果显示，在多个数据集（包括手动标注数据）上，该方法显著提高了性能指标，证明了其有效性。",
      "categories": [
        "cs.CL",
        "cs.AI",
        "cs.LG"
      ],
      "primary_category": "cs.CL",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2405.00216v1",
      "published_date": "2024-04-30 21:41:53 UTC",
      "updated_date": "2024-04-30 21:41:53 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-18T04:45:10.524196"
    },
    {
      "arxiv_id": "2405.00205v2",
      "title": "A Logic for Reasoning About Aggregate-Combine Graph Neural Networks",
      "title_zh": "翻译失败",
      "authors": [
        "Pierre Nunn",
        "Marco Sälzer",
        "François Schwarzentruber",
        "Nicolas Troquard"
      ],
      "abstract": "We propose a modal logic in which counting modalities appear in linear\ninequalities. We show that each formula can be transformed into an equivalent\ngraph neural network (GNN). We also show that a broad class of GNNs can be\ntransformed efficiently into a formula, thus significantly improving upon the\nliterature about the logical expressiveness of GNNs. We also show that the\nsatisfiability problem is PSPACE-complete. These results bring together the\npromise of using standard logical methods for reasoning about GNNs and their\nproperties, particularly in applications such as GNN querying, equivalence\nchecking, etc. We prove that such natural problems can be solved in polynomial\nspace.",
      "tldr_zh": "我们提出了一种模态逻辑（modal logic），其中计数模态（counting modalities）出现在线性不等式（linear inequalities）中，用于推理聚合-组合图神经网络（Aggregate-Combine Graph Neural Networks）。该逻辑可以将每个公式高效转化为等价的图神经网络（GNN），反之亦然，从而显著提升了 GNN 的逻辑表达性。研究证明，该逻辑的满足性问题（satisfiability problem）是 PSPACE-complete，且相关问题可在多项式空间中解决。这些结果为使用标准逻辑方法进行 GNN 查询、等价检查等应用提供了坚实基础。",
      "categories": [
        "cs.AI",
        "cs.LG",
        "cs.LO"
      ],
      "primary_category": "cs.AI",
      "comment": "arXiv admin note: text overlap with arXiv:2307.05150",
      "pdf_url": "http://arxiv.org/pdf/2405.00205v2",
      "published_date": "2024-04-30 21:16:38 UTC",
      "updated_date": "2025-03-27 10:38:15 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-18T04:45:23.174802"
    },
    {
      "arxiv_id": "2405.00204v1",
      "title": "General Purpose Verification for Chain of Thought Prompting",
      "title_zh": "针对链式思考提示的通用验证",
      "authors": [
        "Robert Vacareanu",
        "Anurag Pratik",
        "Evangelia Spiliopoulou",
        "Zheng Qi",
        "Giovanni Paolini",
        "Neha Anna John",
        "Jie Ma",
        "Yassine Benajiba",
        "Miguel Ballesteros"
      ],
      "abstract": "Many of the recent capabilities demonstrated by Large Language Models (LLMs)\narise primarily from their ability to exploit contextual information. In this\npaper, we explore ways to improve reasoning capabilities of LLMs through (1)\nexploration of different chains of thought and (2) validation of the individual\nsteps of the reasoning process. We propose three general principles that a\nmodel should adhere to while reasoning: (i) Relevance, (ii) Mathematical\nAccuracy, and (iii) Logical Consistency. We apply these constraints to the\nreasoning steps generated by the LLM to improve the accuracy of the final\ngeneration. The constraints are applied in the form of verifiers: the model\nitself is asked to verify if the generated steps satisfy each constraint. To\nfurther steer the generations towards high-quality solutions, we use the\nperplexity of the reasoning steps as an additional verifier. We evaluate our\nmethod on 4 distinct types of reasoning tasks, spanning a total of 9 different\ndatasets. Experiments show that our method is always better than vanilla\ngeneration, and, in 6 out of the 9 datasets, it is better than best-of N\nsampling which samples N reasoning chains and picks the lowest perplexity\ngeneration.",
      "tldr_zh": "本文提出了一种通用验证方法，用于提升大型语言模型（LLMs）的Chain of Thought提示推理能力，通过探索多种推理链和验证每个步骤的准确性来实现。方法引入三个核心原则：Relevance（相关性）、Mathematical Accuracy（数学准确性）和Logical Consistency（逻辑一致性），并使用verifiers（模型自身验证器）和perplexity（困惑度）作为额外工具来评估和优化推理步骤。在9个数据集的4种推理任务实验中，该方法始终优于普通生成，并在6个数据集上超越best-of N sampling，提高了最终输出的准确性。",
      "categories": [
        "cs.CL",
        "cs.AI"
      ],
      "primary_category": "cs.CL",
      "comment": "22 pages, preprint",
      "pdf_url": "http://arxiv.org/pdf/2405.00204v1",
      "published_date": "2024-04-30 21:15:17 UTC",
      "updated_date": "2024-04-30 21:15:17 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-18T04:45:36.739724"
    },
    {
      "arxiv_id": "2405.00201v1",
      "title": "SPAFIT: Stratified Progressive Adaptation Fine-tuning for Pre-trained Large Language Models",
      "title_zh": "翻译失败",
      "authors": [
        "Samir Arora",
        "Liangliang Wang"
      ],
      "abstract": "Full fine-tuning is a popular approach to adapt Transformer-based pre-trained\nlarge language models to a specific downstream task. However, the substantial\nrequirements for computational power and storage have discouraged its\nwidespread use. Moreover, increasing evidence of catastrophic forgetting and\noverparameterization in the Transformer architecture has motivated researchers\nto seek more efficient fine-tuning (PEFT) methods. Commonly known\nparameter-efficient fine-tuning methods like LoRA and BitFit are typically\napplied across all layers of the model. We propose a PEFT method, called\nStratified Progressive Adaptation Fine-tuning (SPAFIT), based on the\nlocalization of different types of linguistic knowledge to specific layers of\nthe model. Our experiments, conducted on nine tasks from the GLUE benchmark,\nshow that our proposed SPAFIT method outperforms other PEFT methods while\nfine-tuning only a fraction of the parameters adjusted by other methods.",
      "tldr_zh": "本研究针对预训练大型语言模型的微调问题，指出传统全微调(full fine-tuning)存在计算资源需求大、catastrophic forgetting和overparameterization等问题，提出了一种参数高效微调(PEFT)方法SPAFIT，即Stratified Progressive Adaptation Fine-tuning。该方法基于语言知识在模型层中的特定定位，仅微调部分参数，从而实现更高效的适应过程。在GLUE基准的九个任务上实验表明，SPAFIT优于其他PEFT方法如LoRA和BitFit，同时只调整更少的参数，显著提升了微调效率和性能。",
      "categories": [
        "cs.CL",
        "cs.AI"
      ],
      "primary_category": "cs.CL",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2405.00201v1",
      "published_date": "2024-04-30 21:07:32 UTC",
      "updated_date": "2024-04-30 21:07:32 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-18T04:45:47.143203"
    },
    {
      "arxiv_id": "2405.00197v1",
      "title": "Grounding Realizable Entities",
      "title_zh": "翻译失败",
      "authors": [
        "Michael Rabenberg",
        "Carter Benson",
        "Federico Donato",
        "Yongqun He",
        "Anthony Huffman",
        "Shane Babcock",
        "John Beverley"
      ],
      "abstract": "Ontological representations of qualities, dispositions, and roles have been\nrefined over the past decade, clarifying subtle distinctions in life science\nresearch. After articulating a widely-used characterization of these entities\nwithin the context of Basic Formal Ontology (BFO), we identify gaps in this\ntreatment and motivate the need for supplementing the BFO characterization. By\nway of supplement, we propose definitions for grounding relations holding\nbetween qualities and dispositions, and dispositions and roles, illustrating\nour proposal by representing subtle aspects of host-pathogen interactions.",
      "tldr_zh": "本研究在Basic Formal Ontology (BFO)的背景下，审视了过去十年对qualities、dispositions和roles等实体的本体表示完善，这些改进有助于生命科学研究中微妙区别的澄清。论文识别了BFO现有特征化的不足，并提出grounding relations的定义，作为补充，用于描述qualities与dispositions之间，以及dispositions与roles之间的关系。最终，通过宿主-病原体互动的例子，论文展示了这些grounding relations如何精确表示复杂互动，从而增强本体论的适用性。",
      "categories": [
        "cs.AI",
        "cs.DB",
        "cs.IR"
      ],
      "primary_category": "cs.AI",
      "comment": "13",
      "pdf_url": "http://arxiv.org/pdf/2405.00197v1",
      "published_date": "2024-04-30 21:01:34 UTC",
      "updated_date": "2024-04-30 21:01:34 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-18T04:46:00.021942"
    },
    {
      "arxiv_id": "2405.00186v1",
      "title": "Credentials in the Occupation Ontology",
      "title_zh": "职业本体中的凭证",
      "authors": [
        "John Beverley",
        "Robin McGill",
        "Sam Smith",
        "Jie Zheng",
        "Giacomo De Colle",
        "Finn Wilson",
        "Matthew Diller",
        "William D. Duncan",
        "William R. Hogan",
        "Yongqun He"
      ],
      "abstract": "The term credential encompasses educational certificates, degrees,\ncertifications, and government-issued licenses. An occupational credential is a\nverification of an individuals qualification or competence issued by a third\nparty with relevant authority. Job seekers often leverage such credentials as\nevidence that desired qualifications are satisfied by their holders. Many U.S.\neducation and workforce development organizations have recognized the\nimportance of credentials for employment and the challenges of understanding\nthe value of credentials. In this study, we identified and ontologically\ndefined credential and credential-related terms at the textual and semantic\nlevels based on the Occupation Ontology (OccO), a BFO-based ontology. Different\ncredential types and their authorization logic are modeled. We additionally\ndefined a high-level hierarchy of credential related terms and relations among\nmany terms, which were initiated in concert with the Alabama Talent Triad (ATT)\nprogram, which aims to connect learners, earners, employers and\neducation/training providers through credentials and skills. To our knowledge,\nour research provides for the first time systematic ontological modeling of the\nimportant domain of credentials and related contents, supporting enhanced\ncredential data and knowledge integration in the future.",
      "tldr_zh": "该论文探讨了职业凭证的概念，包括教育证书、学位、认证和政府颁发的执照，并将其定义为第三方权威机构对个人资格或能力的验证。研究基于 Occupation Ontology (OccO)，一个以 BFO 为基础的本体，对凭证相关术语在文本和语义层面进行了系统建模，包括不同凭证类型及其授权逻辑的层次结构。最终，该工作与 Alabama Talent Triad (ATT) 程序合作，建立了凭证术语的关联关系，为未来凭证数据和知识整合提供了重要基础。",
      "categories": [
        "cs.AI",
        "cs.DB",
        "cs.IR"
      ],
      "primary_category": "cs.AI",
      "comment": "11",
      "pdf_url": "http://arxiv.org/pdf/2405.00186v1",
      "published_date": "2024-04-30 20:23:18 UTC",
      "updated_date": "2024-04-30 20:23:18 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-18T04:46:12.245038"
    },
    {
      "arxiv_id": "2405.00183v2",
      "title": "Capabilities: An Ontology",
      "title_zh": "翻译失败",
      "authors": [
        "John Beverley",
        "David Limbaugh",
        "Eric Merrell",
        "Peter M. Koch",
        "Barry Smith"
      ],
      "abstract": "In our daily lives, as in science and in all other domains, we encounter huge\nnumbers of dispositions (tendencies, potentials, powers) which are realized in\nprocesses such as sneezing, sweating, shedding dandruff, and on and on. Among\nthis plethora of what we can think of as mere dispositions is a subset of\ndispositions in whose realizations we have an interest a car responding well\nwhen driven on ice, a rabbits lungs responding well when it is chased by a\nwolf, and so on. We call the latter capabilities and we attempt to provide a\nrobust ontological account of what capabilities are that is of sufficient\ngenerality to serve a variety of purposes, for example by providing a useful\nextension to ontology-based research in areas where capabilities data are\ncurrently being collected in siloed fashion.",
      "tldr_zh": "本论文探讨了日常生活中和科学领域中大量存在的dispositions（如倾向、潜力、力量），这些在过程如打喷嚏或出汗中实现，并将其中我们感兴趣的子集定义为capabilities，例如汽车在冰上良好响应或兔子在被追逐时肺部有效运作。论文旨在提供一个稳健的ontological账户，对capabilities进行通用定义，以支持多种应用，如扩展本体论研究并整合目前孤立收集的capabilities数据。主要贡献在于建立这一通用框架，帮助弥合领域间的知识鸿沟，促进capabilities相关研究的标准化。",
      "categories": [
        "cs.AI",
        "cs.LO"
      ],
      "primary_category": "cs.AI",
      "comment": "14",
      "pdf_url": "http://arxiv.org/pdf/2405.00183v2",
      "published_date": "2024-04-30 20:16:14 UTC",
      "updated_date": "2024-08-16 03:21:14 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-18T04:46:23.210837"
    },
    {
      "arxiv_id": "2405.00182v1",
      "title": "M-DEW: Extending Dynamic Ensemble Weighting to Handle Missing Values",
      "title_zh": "M-DEW：扩展动态集成加权以处理缺失值",
      "authors": [
        "Adam Catto",
        "Nan Jia",
        "Ansaf Salleb-Aouissi",
        "Anita Raja"
      ],
      "abstract": "Missing value imputation is a crucial preprocessing step for many machine\nlearning problems. However, it is often considered as a separate subtask from\ndownstream applications such as classification, regression, or clustering, and\nthus is not optimized together with them. We hypothesize that treating the\nimputation model and downstream task model together and optimizing over full\npipelines will yield better results than treating them separately. Our work\ndescribes a novel AutoML technique for making downstream predictions with\nmissing data that automatically handles preprocessing, model weighting, and\nselection during inference time, with minimal compute overhead. Specifically we\ndevelop M-DEW, a Dynamic missingness-aware Ensemble Weighting (DEW) approach,\nthat constructs a set of two-stage imputation-prediction pipelines, trains each\ncomponent separately, and dynamically calculates a set of pipeline weights for\neach sample during inference time. We thus extend previous work on dynamic\nensemble weighting to handle missing data at the level of full\nimputation-prediction pipelines, improving performance and calibration on\ndownstream machine learning tasks over standard model averaging techniques.\nM-DEW is shown to outperform the state-of-the-art in that it produces\nstatistically significant reductions in model perplexity in 17 out of 18\nexperiments, while improving average precision in 13 out of 18 experiments.",
      "tldr_zh": "本文提出 M-DEW，一种扩展 Dynamic Ensemble Weighting 的 AutoML 技术，用于处理机器学习中的 missing values，通过将缺失值填充模型与下游任务（如分类或回归）整合优化，实现更高效的预测管道。M-DEW 构建一组两阶段的填充-预测管道，分别训练组件，并在推理时动态计算每个样本的管道权重，从而改善性能和校准。实验结果显示，M-DEW 在 18 个实验中，在 17 个中显著降低了模型 perplexity，在 13 个中提高了平均精度，优于标准模型平均技术。",
      "categories": [
        "cs.LG",
        "cs.AI"
      ],
      "primary_category": "cs.LG",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2405.00182v1",
      "published_date": "2024-04-30 20:13:18 UTC",
      "updated_date": "2024-04-30 20:13:18 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-18T04:46:36.132596"
    },
    {
      "arxiv_id": "2405.00181v2",
      "title": "Uncovering What, Why and How: A Comprehensive Benchmark for Causation Understanding of Video Anomaly",
      "title_zh": "翻译失败",
      "authors": [
        "Hang Du",
        "Sicheng Zhang",
        "Binzhu Xie",
        "Guoshun Nan",
        "Jiayang Zhang",
        "Junrui Xu",
        "Hangyu Liu",
        "Sicong Leng",
        "Jiangming Liu",
        "Hehe Fan",
        "Dajiu Huang",
        "Jing Feng",
        "Linli Chen",
        "Can Zhang",
        "Xuhuan Li",
        "Hao Zhang",
        "Jianhang Chen",
        "Qimei Cui",
        "Xiaofeng Tao"
      ],
      "abstract": "Video anomaly understanding (VAU) aims to automatically comprehend unusual\noccurrences in videos, thereby enabling various applications such as traffic\nsurveillance and industrial manufacturing. While existing VAU benchmarks\nprimarily concentrate on anomaly detection and localization, our focus is on\nmore practicality, prompting us to raise the following crucial questions: \"what\nanomaly occurred?\", \"why did it happen?\", and \"how severe is this abnormal\nevent?\". In pursuit of these answers, we present a comprehensive benchmark for\nCausation Understanding of Video Anomaly (CUVA). Specifically, each instance of\nthe proposed benchmark involves three sets of human annotations to indicate the\n\"what\", \"why\" and \"how\" of an anomaly, including 1) anomaly type, start and end\ntimes, and event descriptions, 2) natural language explanations for the cause\nof an anomaly, and 3) free text reflecting the effect of the abnormality. In\naddition, we also introduce MMEval, a novel evaluation metric designed to\nbetter align with human preferences for CUVA, facilitating the measurement of\nexisting LLMs in comprehending the underlying cause and corresponding effect of\nvideo anomalies. Finally, we propose a novel prompt-based method that can serve\nas a baseline approach for the challenging CUVA. We conduct extensive\nexperiments to show the superiority of our evaluation metric and the\nprompt-based approach. Our code and dataset are available at\nhttps://github.com/fesvhtr/CUVA.",
      "tldr_zh": "该论文针对视频异常理解（Video Anomaly）提出一个全面基准Causation Understanding of Video Anomaly (CUVA)，旨在回答异常的“what”（类型、时间和描述）、“why”（原因解释）和“how”（影响严重程度）三个关键问题。CUVA数据集包含三套人类标注，包括事件细节、自然语言原因解释和影响文本，同时引入了新评估指标MMEval，以更好地与人类偏好对齐并评估现有LLMs在异常因果理解方面的能力。论文还提出一个基于提示的方法作为基准，并通过广泛实验证明了其在CUVA任务上的优越性，相关代码和数据集已在GitHub上公开。",
      "categories": [
        "cs.CV",
        "cs.AI"
      ],
      "primary_category": "cs.CV",
      "comment": "Accepted in CVPR2024, Codebase: https://github.com/fesvhtr/CUVA",
      "pdf_url": "http://arxiv.org/pdf/2405.00181v2",
      "published_date": "2024-04-30 20:11:49 UTC",
      "updated_date": "2024-05-06 14:57:50 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-18T04:46:49.060003"
    },
    {
      "arxiv_id": "2405.00747v4",
      "title": "Soft Preference Optimization: Aligning Language Models to Expert Distributions",
      "title_zh": "翻译失败",
      "authors": [
        "Arsalan Sharifnassab",
        "Saber Salehkaleybar",
        "Sina Ghiassian",
        "Surya Kanoria",
        "Dale Schuurmans"
      ],
      "abstract": "We propose Soft Preference Optimization (SPO), a method for aligning\ngenerative models, such as Large Language Models (LLMs), with human\npreferences, without the need for a reward model. SPO optimizes model outputs\ndirectly over a preference dataset through a natural loss function that\nintegrates preference loss with a regularization term across the model's entire\noutput distribution rather than limiting it to the preference dataset. Although\nSPO does not require the assumption of an existing underlying reward model, we\ndemonstrate that, under the Bradley-Terry (BT) model assumption, it converges\nto a softmax of scaled rewards, with the distribution's \"softness\" adjustable\nvia the softmax exponent, an algorithm parameter. We showcase SPO's\nmethodology, its theoretical foundation, and its comparative advantages in\nsimplicity, computational efficiency, and alignment precision.",
      "tldr_zh": "我们提出 Soft Preference Optimization (SPO)，一种无需奖励模型的方法，用于对齐大型语言模型 (LLMs) 与人类偏好的专家分布。SPO 通过一个自然损失函数直接优化模型输出，将偏好损失与正则化项相结合，覆盖整个输出分布而非仅限于偏好数据集。这种方法在 Bradley-Terry (BT) 模型假设下收敛于缩放奖励的 softmax，并通过参数调整软度，提供简单性、计算效率和对齐精度的显著优势。",
      "categories": [
        "cs.LG",
        "cs.AI"
      ],
      "primary_category": "cs.LG",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2405.00747v4",
      "published_date": "2024-04-30 19:48:55 UTC",
      "updated_date": "2024-10-04 00:31:48 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-18T04:46:59.365863"
    },
    {
      "arxiv_id": "2405.03699v1",
      "title": "HCC Is All You Need: Alignment-The Sensible Kind Anyway-Is Just Human-Centered Computing",
      "title_zh": "翻译失败",
      "authors": [
        "Eric Gilbert"
      ],
      "abstract": "This article argues that AI Alignment is a type of Human-Centered Computing.",
      "tldr_zh": "本文认为，AI Alignment 是一种 Human-Centered Computing (HCC)，即以人为中心的计算形式。论文通过重新框架 AI Alignment，将其视为 HCC 的子集，强调了其在设计和优化 AI 系统时的人类导向本质。这种观点有助于深化 AI 研究与人类计算领域的整合，提供更具实用性的指导。",
      "categories": [
        "cs.HC",
        "cs.AI"
      ],
      "primary_category": "cs.HC",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2405.03699v1",
      "published_date": "2024-04-30 19:46:23 UTC",
      "updated_date": "2024-04-30 19:46:23 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-18T04:47:09.858932"
    },
    {
      "arxiv_id": "2405.15786v1",
      "title": "Enhancement of Subjective Content Descriptions by using Human Feedback",
      "title_zh": "使用人类反馈增强主观内容描述",
      "authors": [
        "Magnus Bender",
        "Tanya Braun",
        "Ralf Möller",
        "Marcel Gehrke"
      ],
      "abstract": "An agent providing an information retrieval service may work with a corpus of\ntext documents. The documents in the corpus may contain annotations such as\nSubjective Content Descriptions (SCD) -- additional data associated with\ndifferent sentences of the documents. Each SCD is associated with multiple\nsentences of the corpus and has relations among each other. The agent uses the\nSCDs to create its answers in response to queries supplied by users. However,\nthe SCD the agent uses might reflect the subjective perspective of another\nuser. Hence, answers may be considered faulty by an agent's user, because the\nSCDs may not exactly match the perceptions of an agent's user. A naive and very\ncostly approach would be to ask each user to completely create all the SCD\nthemselves. To use existing knowledge, this paper presents ReFrESH, an approach\nfor Relation-preserving Feedback-reliant Enhancement of SCDs by Humans. An\nagent's user can give feedback about faulty answers to the agent. This feedback\nis then used by ReFrESH to update the SCDs incrementally. However, human\nfeedback is not always unambiguous. Therefore, this paper additionally presents\nan approach to decide how to incorporate the feedback and when to update the\nSCDs. Altogether, SCDs can be updated with human feedback, allowing users to\ncreate even more specific SCDs for their needs.",
      "tldr_zh": "本研究针对信息检索代理使用主观内容描述 (SCD) 时可能存在的视角不匹配问题，提出了一种名为 ReFrESH 的框架，通过人类反馈来增强 SCD。该方法允许用户对代理的错误答案提供反馈，并以关系保持 (Relation-preserving) 的方式逐步更新 SCD，同时引入机制处理反馈的模糊性，避免完全重新创建 SCD。实验结果表明，ReFrESH 能有效利用现有知识，帮助用户定制更精确的 SCD，提升检索答案的准确性和相关性。",
      "categories": [
        "cs.IR",
        "cs.AI"
      ],
      "primary_category": "cs.IR",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2405.15786v1",
      "published_date": "2024-04-30 19:31:47 UTC",
      "updated_date": "2024-04-30 19:31:47 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-18T04:47:22.515197"
    },
    {
      "arxiv_id": "2405.00166v1",
      "title": "Discovering intrinsic multi-compartment pharmacometric models using Physics Informed Neural Networks",
      "title_zh": "使用物理信息神经网络发现固有多隔室药效动力学模型",
      "authors": [
        "Imran Nasim",
        "Adam Nasim"
      ],
      "abstract": "Pharmacometric models are pivotal across drug discovery and development,\nplaying a decisive role in determining the progression of candidate molecules.\nHowever, the derivation of mathematical equations governing the system is a\nlabor-intensive trial-and-error process, often constrained by tight timelines.\nIn this study, we introduce PKINNs, a novel purely data-driven\npharmacokinetic-informed neural network model. PKINNs efficiently discovers and\nmodels intrinsic multi-compartment-based pharmacometric structures, reliably\nforecasting their derivatives. The resulting models are both interpretable and\nexplainable through Symbolic Regression methods. Our computational framework\ndemonstrates the potential for closed-form model discovery in pharmacometric\napplications, addressing the labor-intensive nature of traditional model\nderivation. With the increasing availability of large datasets, this framework\nholds the potential to significantly enhance model-informed drug discovery.",
      "tldr_zh": "本研究针对传统 pharmacometric 模型推导过程的劳动密集和时间限制问题，引入了 PKINNs，一种基于 Physics Informed Neural Networks 的纯数据驱动框架，用于高效发现和建模多隔室 pharmacometric 结构。PKINNs 通过结合神经网络和 Symbolic Regression 方法，能够生成可解释且可靠的模型，并准确预测衍生变量。实验结果表明，该框架显著简化了模型发现过程，并有望在 pharmacometric 应用中提升药物发现效率，尤其在大数据时代。",
      "categories": [
        "cs.LG",
        "cs.AI",
        "q-bio.QM"
      ],
      "primary_category": "cs.LG",
      "comment": "Accepted into the International conference on Scientific Computation\n  and Machine Learning 2024 (SCML 2024)",
      "pdf_url": "http://arxiv.org/pdf/2405.00166v1",
      "published_date": "2024-04-30 19:31:31 UTC",
      "updated_date": "2024-04-30 19:31:31 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-18T04:47:35.045266"
    },
    {
      "arxiv_id": "2407.10247v1",
      "title": "Strategic Integration of Artificial Intelligence in the C-Suite: The Role of the Chief AI Officer",
      "title_zh": "翻译失败",
      "authors": [
        "Marc Schmitt"
      ],
      "abstract": "The integration of Artificial Intelligence (AI) into corporate strategy has\nbecome a pivotal focus for organizations aiming to maintain a competitive\nadvantage in the digital age. As AI reshapes business operations and drives\ninnovation, the need for specialized leadership to effectively manage these\nchanges becomes increasingly apparent. In this paper, I explore the role of the\nChief AI Officer (CAIO) within the C-suite, emphasizing the necessity of this\nposition for successful AI strategy, integration, and governance. I analyze\nfuture scenarios based on current trends in three key areas: the AI Economy, AI\nOrganization, and Competition in the Age of AI. These explorations lay the\nfoundation for identifying the antecedents (environmental, structural, and\nstrategic factors) that justify the inclusion of a CAIO in top management\nteams. This sets the stage for a comprehensive examination of the CAIO's role\nand the broader implications of AI leadership. This paper advances the\ndiscussion on AI leadership by providing a rationale for the strategic\nintegration of AI at the executive level and examining the role of the Chief AI\nOfficer within organizations.",
      "tldr_zh": "本论文探讨了人工智能（AI）在企业高层管理（C-suite）中的战略整合，特别强调首席AI官（Chief AI Officer, CAIO）的必要性，以帮助组织在数字时代保持竞争优势。作者基于当前趋势分析了AI经济（AI Economy）、AI组织（AI Organization）和AI时代竞争（Competition in the Age of AI）三大领域，识别了环境、结构和战略因素作为CAIO设立的前置条件（antecedents）。该研究为AI领导力的发展提供理论基础，论证了CAIO在AI战略、整合和治理中的关键作用，从而推动企业级AI管理的全面讨论。",
      "categories": [
        "cs.CY",
        "cs.AI",
        "cs.LG",
        "econ.GN",
        "q-fin.EC"
      ],
      "primary_category": "cs.CY",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2407.10247v1",
      "published_date": "2024-04-30 19:07:18 UTC",
      "updated_date": "2024-04-30 19:07:18 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-18T04:47:47.479132"
    },
    {
      "arxiv_id": "2405.00156v2",
      "title": "Expanding the Horizon: Enabling Hybrid Quantum Transfer Learning for Long-Tailed Chest X-Ray Classification",
      "title_zh": "翻译失败",
      "authors": [
        "Skylar Chan",
        "Pranav Kulkarni",
        "Paul H. Yi",
        "Vishwa S. Parekh"
      ],
      "abstract": "Quantum machine learning (QML) has the potential for improving the\nmulti-label classification of rare, albeit critical, diseases in large-scale\nchest x-ray (CXR) datasets due to theoretical quantum advantages over classical\nmachine learning (CML) in sample efficiency and generalizability. While prior\nliterature has explored QML with CXRs, it has focused on binary classification\ntasks with small datasets due to limited access to quantum hardware and\ncomputationally expensive simulations. To that end, we implemented a Jax-based\nframework that enables the simulation of medium-sized qubit architectures with\nsignificant improvements in wall-clock time over current software offerings. We\nevaluated the performance of our Jax-based framework in terms of efficiency and\nperformance for hybrid quantum transfer learning for long-tailed classification\nacross 8, 14, and 19 disease labels using large-scale CXR datasets. The\nJax-based framework resulted in up to a 58% and 95% speed-up compared to\nPyTorch and TensorFlow implementations, respectively. However, compared to CML,\nQML demonstrated slower convergence and an average AUROC of 0.70, 0.73, and\n0.74 for the classification of 8, 14, and 19 CXR disease labels. In comparison,\nthe CML models had an average AUROC of 0.77, 0.78, and 0.80 respectively. In\nconclusion, our work presents an accessible implementation of hybrid quantum\ntransfer learning for long-tailed CXR classification with a computationally\nefficient Jax-based framework.",
      "tldr_zh": "本研究探讨了量子机器学习（QML）在处理长尾分布胸部X光（CXR）数据集中的多标签分类问题，旨在利用QML在样本效率和泛化性上的优势来识别罕见疾病。作者开发了一个基于Jax的框架，用于模拟中等规模量子位架构，该框架比PyTorch和TensorFlow分别快58%和95%，并支持混合量子迁移学习在8、14和19种疾病标签上的评估。结果显示，QML的平均AUROC为0.70、0.73和0.74，与经典机器学习（CML）的0.77、0.78和0.80相比，收敛较慢且性能略逊色，但这项工作提供了高效、可访问的QML实现，推动了长尾CXR分类领域的创新。",
      "categories": [
        "cs.CV",
        "cs.AI",
        "cs.LG",
        "quant-ph"
      ],
      "primary_category": "cs.CV",
      "comment": "11 pages, 13 figures, 3 tables",
      "pdf_url": "http://arxiv.org/pdf/2405.00156v2",
      "published_date": "2024-04-30 19:06:37 UTC",
      "updated_date": "2024-08-02 18:18:48 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-18T04:48:01.164499"
    },
    {
      "arxiv_id": "2405.00746v2",
      "title": "Leveraging Sub-Optimal Data for Human-in-the-Loop Reinforcement Learning",
      "title_zh": "翻译失败",
      "authors": [
        "Calarina Muslimani",
        "Matthew E. Taylor"
      ],
      "abstract": "To create useful reinforcement learning (RL) agents, step zero is to design a\nsuitable reward function that captures the nuances of the task. However, reward\nengineering can be a difficult and time-consuming process. Instead,\nhuman-in-the-loop RL methods hold the promise of learning reward functions from\nhuman feedback. Despite recent successes, many of the human-in-the-loop RL\nmethods still require numerous human interactions to learn successful reward\nfunctions. To improve the feedback efficiency of human-in-the-loop RL methods\n(i.e., require less human interaction), this paper introduces Sub-optimal Data\nPre-training, SDP, an approach that leverages reward-free, sub-optimal data to\nimprove scalar- and preference-based RL algorithms. In SDP, we start by\npseudo-labeling all low-quality data with the minimum environment reward.\nThrough this process, we obtain reward labels to pre-train our reward model\nwithout requiring human labeling or preferences. This pre-training phase\nprovides the reward model a head start in learning, enabling it to recognize\nthat low-quality transitions should be assigned low rewards. Through extensive\nexperiments with both simulated and human teachers, we find that SDP can at\nleast meet, but often significantly improve, state of the art human-in-the-loop\nRL performance across a variety of simulated robotic tasks.",
      "tldr_zh": "该论文针对Human-in-the-Loop Reinforcement Learning中设计奖励函数的难题，提出Sub-optimal Data Pre-training (SDP)方法，以提高反馈效率并减少人类互动需求。SDP通过对次优数据进行伪标签（用最小环境奖励标记）并预训练奖励模型，使其能够快速识别低质量过渡对应低奖励，从而为scalar-和preference-based RL算法提供初始优势。实验在模拟和真实人类教师环境下证明，SDP在多种模拟机器人任务中至少匹配、通常显著改善了现有方法的性能。",
      "categories": [
        "cs.LG",
        "cs.AI",
        "cs.RO"
      ],
      "primary_category": "cs.LG",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2405.00746v2",
      "published_date": "2024-04-30 18:58:33 UTC",
      "updated_date": "2025-04-07 23:17:50 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-18T04:48:13.044529"
    },
    {
      "arxiv_id": "2405.00134v1",
      "title": "Transforming Dutch: Debiasing Dutch Coreference Resolution Systems for Non-binary Pronouns",
      "title_zh": "翻译失败",
      "authors": [
        "Goya van Boven",
        "Yupei Du",
        "Dong Nguyen"
      ],
      "abstract": "Gender-neutral pronouns are increasingly being introduced across Western\nlanguages. Recent evaluations have however demonstrated that English NLP\nsystems are unable to correctly process gender-neutral pronouns, with the risk\nof erasing and misgendering non-binary individuals. This paper examines a Dutch\ncoreference resolution system's performance on gender-neutral pronouns,\nspecifically hen and die. In Dutch, these pronouns were only introduced in\n2016, compared to the longstanding existence of singular they in English. We\nadditionally compare two debiasing techniques for coreference resolution\nsystems in non-binary contexts: Counterfactual Data Augmentation (CDA) and\ndelexicalisation. Moreover, because pronoun performance can be hard to\ninterpret from a general evaluation metric like LEA, we introduce an innovative\nevaluation metric, the pronoun score, which directly represents the portion of\ncorrectly processed pronouns. Our results reveal diminished performance on\ngender-neutral pronouns compared to gendered counterparts. Nevertheless,\nalthough delexicalisation fails to yield improvements, CDA substantially\nreduces the performance gap between gendered and gender-neutral pronouns. We\nfurther show that CDA remains effective in low-resource settings, in which a\nlimited set of debiasing documents is used. This efficacy extends to previously\nunseen neopronouns, which are currently infrequently used but may gain\npopularity in the future, underscoring the viability of effective debiasing\nwith minimal resources and low computational costs.",
      "tldr_zh": "这篇论文探讨了荷兰语核心ference resolution系统在处理非二元性别代词（如hen和die）时的性能问题，揭示了系统在这些代词上表现不如性别化代词，导致潜在的误性别化风险。研究比较了两种去偏见技术：Counterfactual Data Augmentation (CDA)和delexicalisation，结果显示CDA显著减少了性能差距，而delexicalisation无效。论文还引入了创新评估指标pronoun score来直接衡量代词处理正确率，并证明CDA在低资源设置下同样有效，甚至适用于未见过的neopronouns，从而展示了高效去偏见的可能性。",
      "categories": [
        "cs.CL",
        "cs.AI",
        "I.2.7"
      ],
      "primary_category": "cs.CL",
      "comment": "22 pages, 2 figures. Accepted at the 2024 ACM Conference on Fairness,\n  Accountability, and Transparency (FAccT '24)",
      "pdf_url": "http://arxiv.org/pdf/2405.00134v1",
      "published_date": "2024-04-30 18:31:19 UTC",
      "updated_date": "2024-04-30 18:31:19 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-18T04:48:23.628578"
    },
    {
      "arxiv_id": "2405.00117v2",
      "title": "Training a high-performance retinal foundation model with half-the-data and 400 times less compute",
      "title_zh": "使用半数数据和减少 400 倍计算资源训练高性能视网膜基础模型",
      "authors": [
        "Justin Engelmann",
        "Miguel O. Bernabeu"
      ],
      "abstract": "Artificial Intelligence in medicine is traditionally limited by the lack of\nmassive training datasets. Foundation models, pre-trained models that can be\nadapted to downstream tasks with small datasets, could alleviate this problem.\nResearchers at Moorfields Eye Hospital (MEH) proposed RETFound-MEH, a retinal\nfoundation model trained on 900,000 images, including private hospital data.\nRecently, data-efficient DERETFound was proposed providing comparable\nperformance while being trained on only 150,000 publicly available images.\nHowever, both these models required very substantial resources to train\ninitially and are resource-intensive in downstream use. We propose a novel\nToken Reconstruction objective that we use to train RETFound-Green, a retinal\nfoundation model trained using only 75,000 publicly available images and 400\ntimes less compute. We estimate the cost of training RETFound-MEH and\nDERETFound at \\$10,000 and \\$14,000, respectively. RETFound-Green could be\ntrained for less than \\$100, with equally reduced environmental impact.\nRETFound-Green is also far more efficient in downstream use: it can be\ndownloaded 14 times faster, computes vector embeddings 2.7 times faster which\nthen require 2.6 times less storage space. Despite this, RETFound-Green does\nnot perform systematically worse. In fact, on various task on three downstream\ndatasets from Brazil, India and China, it performs best on 68 tasks out of 119\ncomparisons, versus 21 for DERETFound and 13 for RETFound-MEH. Our results\nsuggest that RETFound-Green is a very efficient, high-performance retinal\nfoundation model. We anticipate that our Token Reconstruction objective could\nbe scaled up for even higher performance and be applied to other domains beyond\nretinal imaging.",
      "tldr_zh": "本研究提出了一种高效的视网膜基础模型RETFound-Green，通过采用新型Token Reconstruction目标函数，仅使用7.5万张公开图像和比之前模型少400倍的计算资源进行训练，成本不到100美元。相比现有模型如RETFound-MEH和DERETFound，RETFound-Green在下载速度、计算效率和存储空间上分别提高了14倍、2.7倍和2.6倍，同时在三个下游数据集上的119个任务中表现出色，赢得了68次最佳表现。实验结果表明，该模型在性能上不逊色，甚至优于基准模型，为资源受限的医疗AI领域提供了可扩展的解决方案，并有望应用于其他影像领域。",
      "categories": [
        "cs.CV",
        "cs.AI"
      ],
      "primary_category": "cs.CV",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2405.00117v2",
      "published_date": "2024-04-30 18:08:08 UTC",
      "updated_date": "2024-09-22 17:25:40 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-18T04:48:35.528887"
    },
    {
      "arxiv_id": "2405.00099v4",
      "title": "Creative Beam Search: LLM-as-a-Judge For Improving Response Generation",
      "title_zh": "翻译失败",
      "authors": [
        "Giorgio Franceschelli",
        "Mirco Musolesi"
      ],
      "abstract": "Large language models are revolutionizing several areas, including artificial\ncreativity. However, the process of generation in machines profoundly diverges\nfrom that observed in humans. In particular, machine generation is\ncharacterized by a lack of intentionality and an underlying creative process.\nWe propose a method called Creative Beam Search that uses Diverse Beam Search\nand LLM-as-a-Judge to perform response generation and response validation. The\nresults of a qualitative experiment show how our approach can provide better\noutput than standard sampling techniques. We also show that the response\nvalidation step is a necessary complement to the response generation step.",
      "tldr_zh": "本研究探讨大型语言模型(LLMs)在人工智能创意领域的应用，指出机器生成缺乏人类般的意图和底层创意过程。\n他们提出Creative Beam Search方法，该方法结合Diverse Beam Search和LLM-as-a-Judge来进行响应生成和验证。\n实验结果显示，这种方法比标准采样技术提供更好的输出，并证明响应验证步骤是响应生成步骤的必要补充。",
      "categories": [
        "cs.AI",
        "cs.CL",
        "cs.HC",
        "cs.LG"
      ],
      "primary_category": "cs.AI",
      "comment": "Presented as a short paper at the 15th International Conference on\n  Computational Creativity (ICCC'24)",
      "pdf_url": "http://arxiv.org/pdf/2405.00099v4",
      "published_date": "2024-04-30 18:00:02 UTC",
      "updated_date": "2024-10-07 16:45:42 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-18T04:48:46.634027"
    },
    {
      "arxiv_id": "2404.19756v5",
      "title": "KAN: Kolmogorov-Arnold Networks",
      "title_zh": "KAN: Kolmogorov-Arnold 网络",
      "authors": [
        "Ziming Liu",
        "Yixuan Wang",
        "Sachin Vaidya",
        "Fabian Ruehle",
        "James Halverson",
        "Marin Soljačić",
        "Thomas Y. Hou",
        "Max Tegmark"
      ],
      "abstract": "Inspired by the Kolmogorov-Arnold representation theorem, we propose\nKolmogorov-Arnold Networks (KANs) as promising alternatives to Multi-Layer\nPerceptrons (MLPs). While MLPs have fixed activation functions on nodes\n(\"neurons\"), KANs have learnable activation functions on edges (\"weights\").\nKANs have no linear weights at all -- every weight parameter is replaced by a\nunivariate function parametrized as a spline. We show that this seemingly\nsimple change makes KANs outperform MLPs in terms of accuracy and\ninterpretability. For accuracy, much smaller KANs can achieve comparable or\nbetter accuracy than much larger MLPs in data fitting and PDE solving.\nTheoretically and empirically, KANs possess faster neural scaling laws than\nMLPs. For interpretability, KANs can be intuitively visualized and can easily\ninteract with human users. Through two examples in mathematics and physics,\nKANs are shown to be useful collaborators helping scientists (re)discover\nmathematical and physical laws. In summary, KANs are promising alternatives for\nMLPs, opening opportunities for further improving today's deep learning models\nwhich rely heavily on MLPs.",
      "tldr_zh": "本研究受Kolmogorov-Arnold表示定理启发，提出Kolmogorov-Arnold Networks (KANs)作为Multi-Layer Perceptrons (MLPs)的替代方案，其中KANs将传统的固定激活函数从节点移至边，并用样条(spline)参数化的单变量函数替换所有线性权重。相比MLPs，KANs在数据拟合和PDE solving中表现出更高的准确性，且更小的KANs即可实现相媲美或优于更大MLPs的性能，同时具备更快的神经缩放定律。KANs还提升了模型的可解释性，便于直观可视化和与人类交互，并在数学和物理示例中帮助科学家重新发现相关定律。总之，KANs为改进依赖MLPs的深度学习模型提供了新机遇。",
      "categories": [
        "cs.LG",
        "cond-mat.dis-nn",
        "cs.AI",
        "stat.ML"
      ],
      "primary_category": "cs.LG",
      "comment": "Accepted by International Conference on Learning Representations\n  (ICLR) 2025 (conference version: https://openreview.net/forum?id=Ozo7qJ5vZi).\n  Codes are available at https://github.com/KindXiaoming/pykan",
      "pdf_url": "http://arxiv.org/pdf/2404.19756v5",
      "published_date": "2024-04-30 17:58:29 UTC",
      "updated_date": "2025-02-09 21:09:09 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-18T04:49:00.346923"
    },
    {
      "arxiv_id": "2404.19753v1",
      "title": "DOCCI: Descriptions of Connected and Contrasting Images",
      "title_zh": "DOCCI：连接与对比图像的描述",
      "authors": [
        "Yasumasa Onoe",
        "Sunayana Rane",
        "Zachary Berger",
        "Yonatan Bitton",
        "Jaemin Cho",
        "Roopal Garg",
        "Alexander Ku",
        "Zarana Parekh",
        "Jordi Pont-Tuset",
        "Garrett Tanzer",
        "Su Wang",
        "Jason Baldridge"
      ],
      "abstract": "Vision-language datasets are vital for both text-to-image (T2I) and\nimage-to-text (I2T) research. However, current datasets lack descriptions with\nfine-grained detail that would allow for richer associations to be learned by\nmodels. To fill the gap, we introduce Descriptions of Connected and Contrasting\nImages (DOCCI), a dataset with long, human-annotated English descriptions for\n15k images that were taken, curated and donated by a single researcher intent\non capturing key challenges such as spatial relations, counting, text\nrendering, world knowledge, and more. We instruct human annotators to create\ncomprehensive descriptions for each image; these average 136 words in length\nand are crafted to clearly distinguish each image from those that are related\nor similar. Each description is highly compositional and typically encompasses\nmultiple challenges. Through both quantitative and qualitative analyses, we\ndemonstrate that DOCCI serves as an effective training resource for\nimage-to-text generation -- a PaLI 5B model finetuned on DOCCI shows equal or\nsuperior results compared to highly-performant larger models like LLaVA-1.5 7B\nand InstructBLIP 7B. Furthermore, we show that DOCCI is a useful testbed for\ntext-to-image generation, highlighting the limitations of current text-to-image\nmodels in capturing long descriptions and fine details.",
      "tldr_zh": "本研究引入了 DOCCI 数据集，即 Descriptions of Connected and Contrasting Images，用于提升视觉语言模型在 T2I 和 I2T 任务中的性能，该数据集包含 15k 张图像的详细人类标注描述，平均长度达 136 词，并聚焦于挑战如空间关系、计数、文本渲染和世界知识。描述设计为高度组合性，能够清晰区分相关或相似图像，从而填补现有数据集的细粒度细节缺失。实验结果显示，在 I2T 生成任务中，使用 PaLI 5B 模型在 DOCCI 上微调后，其性能不逊于更大模型如 LLaVA-1.5 7B 和 InstructBLIP 7B；此外，DOCCI 作为 T2I 生成的测试平台，突显了当前模型在处理长描述和细细节方面的局限性。",
      "categories": [
        "cs.CV",
        "cs.AI",
        "cs.CL",
        "cs.LG"
      ],
      "primary_category": "cs.CV",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2404.19753v1",
      "published_date": "2024-04-30 17:56:24 UTC",
      "updated_date": "2024-04-30 17:56:24 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-18T04:49:13.033791"
    },
    {
      "arxiv_id": "2404.19748v1",
      "title": "Quantifying Nematodes through Images: Datasets, Models, and Baselines of Deep Learning",
      "title_zh": "通过图像量化线虫：深度学习的数据集、模型和基线",
      "authors": [
        "Zhipeng Yuan",
        "Nasamu Musa",
        "Katarzyna Dybal",
        "Matthew Back",
        "Daniel Leybourne",
        "Po Yang"
      ],
      "abstract": "Every year, plant parasitic nematodes, one of the major groups of plant\npathogens, cause a significant loss of crops worldwide. To mitigate crop yield\nlosses caused by nematodes, an efficient nematode monitoring method is\nessential for plant and crop disease management. In other respects, efficient\nnematode detection contributes to medical research and drug discovery, as\nnematodes are model organisms. With the rapid development of computer\ntechnology, computer vision techniques provide a feasible solution for\nquantifying nematodes or nematode infections. In this paper, we survey and\ncategorise the studies and available datasets on nematode detection through\ndeep-learning models. To stimulate progress in related research, this survey\npresents the potential state-of-the-art object detection models, training\ntechniques, optimisation techniques, and evaluation metrics for deep learning\nbeginners. Moreover, seven state-of-the-art object detection models are\nvalidated on three public datasets and the AgriNema dataset for plant parasitic\nnematodes to construct a baseline for nematode detection.",
      "tldr_zh": "本论文探讨了通过图像量化线虫的深度学习方法，强调其在减少作物损失、植物病害管理和医疗研究中的重要性。论文对现有研究和数据集进行了调查和分类，并介绍了先进的object detection models、训练技巧、优化技巧以及评估指标，以指导深度学习初学者。此外，作者在三个公共数据集和AgriNema数据集上验证了七种最先进的物体检测模型，建立了一个线虫检测的基线基准。",
      "categories": [
        "cs.CV",
        "cs.AI"
      ],
      "primary_category": "cs.CV",
      "comment": "The 26th IEEE International Conference on Computational Science and\n  Engineering (CSE-2023)",
      "pdf_url": "http://arxiv.org/pdf/2404.19748v1",
      "published_date": "2024-04-30 17:52:31 UTC",
      "updated_date": "2024-04-30 17:52:31 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-18T04:49:25.287770"
    },
    {
      "arxiv_id": "2404.19744v1",
      "title": "PrivComp-KG : Leveraging Knowledge Graph and Large Language Models for Privacy Policy Compliance Verification",
      "title_zh": "PrivComp-K",
      "authors": [
        "Leon Garza",
        "Lavanya Elluri",
        "Anantaa Kotal",
        "Aritran Piplai",
        "Deepti Gupta",
        "Anupam Joshi"
      ],
      "abstract": "Data protection and privacy is becoming increasingly crucial in the digital\nera. Numerous companies depend on third-party vendors and service providers to\ncarry out critical functions within their operations, encompassing tasks such\nas data handling and storage. However, this reliance introduces potential\nvulnerabilities, as these vendors' security measures and practices may not\nalways align with the standards expected by regulatory bodies. Businesses are\nrequired, often under the penalty of law, to ensure compliance with the\nevolving regulatory rules. Interpreting and implementing these regulations pose\nchallenges due to their complexity. Regulatory documents are extensive,\ndemanding significant effort for interpretation, while vendor-drafted privacy\npolicies often lack the detail required for full legal compliance, leading to\nambiguity. To ensure a concise interpretation of the regulatory requirements\nand compliance of organizational privacy policy with said regulations, we\npropose a Large Language Model (LLM) and Semantic Web based approach for\nprivacy compliance. In this paper, we develop the novel Privacy Policy\nCompliance Verification Knowledge Graph, PrivComp-KG. It is designed to\nefficiently store and retrieve comprehensive information concerning privacy\npolicies, regulatory frameworks, and domain-specific knowledge pertaining to\nthe legal landscape of privacy. Using Retrieval Augmented Generation, we\nidentify the relevant sections in a privacy policy with corresponding\nregulatory rules. This information about individual privacy policies is\npopulated into the PrivComp-KG. Combining this with the domain context and\nrules, the PrivComp-KG can be queried to check for compliance with privacy\npolicies by each vendor against relevant policy regulations. We demonstrate the\nrelevance of the PrivComp-KG, by verifying compliance of privacy policy\ndocuments for various organizations.",
      "tldr_zh": "本研究针对数据保护和隐私合规的挑战，提出了一种结合 Knowledge Graph 和 Large Language Models 的方法，用于验证组织隐私政策是否符合监管要求。论文开发了 PrivComp-KG 知识图谱，用于高效存储和检索隐私政策、监管框架以及相关领域知识，并通过 Retrieval Augmented Generation (RAG) 技术识别政策中的关键部分与相应法规的对应关系。最终，通过查询 PrivComp-KG，用户可以检查供应商隐私政策的合规性，并在多个组织文档上进行了有效演示，展示了该框架的实用性。",
      "categories": [
        "cs.CR",
        "cs.AI"
      ],
      "primary_category": "cs.CR",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2404.19744v1",
      "published_date": "2024-04-30 17:44:44 UTC",
      "updated_date": "2024-04-30 17:44:44 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-18T04:49:38.140859"
    },
    {
      "arxiv_id": "2404.19733v3",
      "title": "Iterative Reasoning Preference Optimization",
      "title_zh": "迭代推理偏好优化",
      "authors": [
        "Richard Yuanzhe Pang",
        "Weizhe Yuan",
        "Kyunghyun Cho",
        "He He",
        "Sainbayar Sukhbaatar",
        "Jason Weston"
      ],
      "abstract": "Iterative preference optimization methods have recently been shown to perform\nwell for general instruction tuning tasks, but typically make little\nimprovement on reasoning tasks (Yuan et al., 2024, Chen et al., 2024). In this\nwork we develop an iterative approach that optimizes the preference between\ncompeting generated Chain-of-Thought (CoT) candidates by optimizing for winning\nvs. losing reasoning steps that lead to the correct answer. We train using a\nmodified DPO loss (Rafailov et al., 2023) with an additional negative\nlog-likelihood term, which we find to be crucial. We show reasoning improves\nacross repeated iterations of this scheme. While only relying on examples in\nthe training set, our approach results in increasing accuracy on GSM8K, MATH,\nand ARC-Challenge for Llama-2-70B-Chat, outperforming other Llama-2-based\nmodels not relying on additionally sourced datasets. For example, we see a\nlarge improvement from 55.6% to 81.6% on GSM8K and an accuracy of 88.7% with\nmajority voting out of 32 samples.",
      "tldr_zh": "本研究提出了一种名为Iterative Reasoning Preference Optimization的迭代偏好优化方法，针对现有方法在推理任务（如数学和逻辑问题）上的改进有限问题，通过优化Chain-of-Thought (CoT)候选之间的偏好，并使用修改后的DPO loss结合负对数似然项来训练模型。\n该方法专注于提升导致正确答案的推理步骤，并在多次迭代中显著提高模型性能。\n实验结果显示，在Llama-2-70B-Chat模型上，GSM8K数据集的准确率从55.6%提升至81.6%，并通过多数投票达到88.7%，在MATH和ARC-Challenge数据集上也表现出色，超越了不依赖额外数据集的其他Llama-2模型。",
      "categories": [
        "cs.CL",
        "cs.AI"
      ],
      "primary_category": "cs.CL",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2404.19733v3",
      "published_date": "2024-04-30 17:28:05 UTC",
      "updated_date": "2024-06-26 01:28:35 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-18T04:49:51.707820"
    },
    {
      "arxiv_id": "2404.19729v1",
      "title": "A Framework for Leveraging Human Computation Gaming to Enhance Knowledge Graphs for Accuracy Critical Generative AI Applications",
      "title_zh": "翻译失败",
      "authors": [
        "Steph Buongiorno",
        "Corey Clark"
      ],
      "abstract": "External knowledge graphs (KGs) can be used to augment large language models\n(LLMs), while simultaneously providing an explainable knowledge base of facts\nthat can be inspected by a human. This approach may be particularly valuable in\ndomains where explainability is critical, like human trafficking data analysis.\nHowever, creating KGs can pose challenges. KGs parsed from documents may\ncomprise explicit connections (those directly stated by a document) but miss\nimplicit connections (those obvious to a human although not directly stated).\nTo address these challenges, this preliminary research introduces the GAME-KG\nframework, standing for \"Gaming for Augmenting Metadata and Enhancing Knowledge\nGraphs.\" GAME-KG is a federated approach to modifying explicit as well as\nimplicit connections in KGs by using crowdsourced feedback collected through\nvideo games. GAME-KG is shown through two demonstrations: a Unity test scenario\nfrom Dark Shadows, a video game that collects feedback on KGs parsed from US\nDepartment of Justice (DOJ) Press Releases on human trafficking, and a\nfollowing experiment where OpenAI's GPT-4 is prompted to answer questions based\non a modified and unmodified KG. Initial results suggest that GAME-KG can be an\neffective framework for enhancing KGs, while simultaneously providing an\nexplainable set of structured facts verified by humans.",
      "tldr_zh": "这篇论文提出一个名为GAME-KG的框架，利用人类计算游戏（Human Computation Gaming）来增强知识图谱（KGs），以支持精度关键的生成AI应用，如贩卖人口数据分析，确保KGs包含显式和隐式连接。GAME-KG通过众包反馈机制（如视频游戏）收集用户输入，修改KGs中的连接，并采用联邦方法实现这一过程。实验演示显示，该框架显著提高了KGs的准确性，并在基于OpenAI的GPT-4模型的问答任务中，提供更可解释和可靠的结构化事实。",
      "categories": [
        "cs.HC",
        "cs.AI"
      ],
      "primary_category": "cs.HC",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2404.19729v1",
      "published_date": "2024-04-30 17:24:55 UTC",
      "updated_date": "2024-04-30 17:24:55 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-18T04:50:02.431823"
    },
    {
      "arxiv_id": "2404.19725v3",
      "title": "Fairness Without Demographics in Human-Centered Federated Learning",
      "title_zh": "翻译失败",
      "authors": [
        "Shaily Roy",
        "Harshit Sharma",
        "Asif Salekin"
      ],
      "abstract": "Federated learning (FL) enables collaborative model training while preserving\ndata privacy, making it suitable for decentralized human-centered AI\napplications. However, a significant research gap remains in ensuring fairness\nin these systems. Current fairness strategies in FL require knowledge of\nbias-creating/sensitive attributes, clashing with FL's privacy principles.\nMoreover, in human-centered datasets, sensitive attributes may remain latent.\nTo tackle these challenges, we present a novel bias mitigation approach\ninspired by \"Fairness without Demographics\" in machine learning. The presented\napproach achieves fairness without needing knowledge of sensitive attributes by\nminimizing the top eigenvalue of the Hessian matrix during training, ensuring\nequitable loss landscapes across FL participants. Notably, we introduce a novel\nFL aggregation scheme that promotes participating models based on error rates\nand loss landscape curvature attributes, fostering fairness across the FL\nsystem. This work represents the first approach to attaining \"Fairness without\nDemographics\" in human-centered FL. Through comprehensive evaluation, our\napproach demonstrates effectiveness in balancing fairness and efficacy across\nvarious real-world applications, FL setups, and scenarios involving single and\nmultiple bias-inducing factors, representing a significant advancement in\nhuman-centered FL.",
      "tldr_zh": "该研究解决了联邦学习（Federated Learning, FL）在人类中心应用中公平性问题，即当前策略需依赖敏感属性，这与FL的隐私原则冲突。论文提出一种新型偏见缓解方法，受“Fairness without Demographics”启发，通过最小化Hessian矩阵的顶层特征值来实现公平的损失景观，而无需敏感属性的知识。还引入了一个创新的FL聚合方案，根据错误率和损失景观曲率属性优先参与模型，促进系统整体公平。在各种真实场景的全面评估中，该方法有效平衡了公平性和效率，标志着人类中心FL领域的重要进展。",
      "categories": [
        "cs.LG",
        "cs.AI",
        "cs.DC"
      ],
      "primary_category": "cs.LG",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2404.19725v3",
      "published_date": "2024-04-30 17:19:52 UTC",
      "updated_date": "2024-05-15 18:40:42 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-18T04:50:14.136873"
    },
    {
      "arxiv_id": "2407.05915v1",
      "title": "Harnessing Federated Generative Learning for Green and Sustainable Internet of Things",
      "title_zh": "翻译失败",
      "authors": [
        "Yuanhang Qi",
        "M. Shamim Hossain"
      ],
      "abstract": "The rapid proliferation of devices in the Internet of Things (IoT) has\nushered in a transformative era of data-driven connectivity across various\ndomains. However, this exponential growth has raised pressing concerns about\nenvironmental sustainability and data privacy. In response to these challenges,\nthis paper introduces One-shot Federated Learning (OSFL), an innovative\nparadigm that harmonizes sustainability and machine learning within IoT\necosystems. OSFL revolutionizes the traditional Federated Learning (FL)\nworkflow by condensing multiple iterative communication rounds into a single\noperation, thus significantly reducing energy consumption, communication\noverhead, and latency. This breakthrough is coupled with the strategic\nintegration of generative learning techniques, ensuring robust data privacy\nwhile promoting efficient knowledge sharing among IoT devices. By curtailing\nresource utilization, OSFL aligns seamlessly with the vision of green and\nsustainable IoT, effectively extending device lifespans and mitigating their\nenvironmental footprint. Our research underscores the transformative potential\nof OSFL, poised to reshape the landscape of IoT applications across domains\nsuch as energy-efficient smart cities and groundbreaking healthcare solutions.\nThis contribution marks a pivotal step towards a more responsible, sustainable,\nand technologically advanced future.",
      "tldr_zh": "本文针对物联网 (IoT) 的快速增长带来的环境可持续性和数据隐私挑战，提出了 One-shot Federated Learning (OSFL) 范式，将传统的 Federated Learning (FL) 工作流简化为单一操作，从而显著降低能量消耗、通信开销和延迟。OSFL 结合生成学习技术，确保数据隐私的同时，促进 IoT 设备间的高效知识共享，并延长设备寿命以减少环境影响。该方法在智能城市和医疗等领域展现出巨大潜力，推动更负责任的技术未来。",
      "categories": [
        "cs.NI",
        "cs.AI"
      ],
      "primary_category": "cs.NI",
      "comment": "This paper is a correction of the published version, in which we\n  corrected the grammatical errors between contexts and highlighted the\n  relationship with \"Federated generative learning with foundation models\"",
      "pdf_url": "http://arxiv.org/pdf/2407.05915v1",
      "published_date": "2024-04-30 17:15:26 UTC",
      "updated_date": "2024-04-30 17:15:26 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-18T04:50:26.023571"
    },
    {
      "arxiv_id": "2404.19721v3",
      "title": "PANGeA: Procedural Artificial Narrative using Generative AI for Turn-Based Video Games",
      "title_zh": "翻译失败",
      "authors": [
        "Steph Buongiorno",
        "Lawrence Jake Klinkert",
        "Tanishq Chawla",
        "Zixin Zhuang",
        "Corey Clark"
      ],
      "abstract": "This research introduces Procedural Artificial Narrative using Generative AI\n(PANGeA), a structured approach for leveraging large language models (LLMs),\nguided by a game designer's high-level criteria, to generate narrative content\nfor turn-based role-playing video games (RPGs). Distinct from prior\napplications of LLMs used for video game design, PANGeA innovates by not only\ngenerating game level data (which includes, but is not limited to, setting, key\nitems, and non-playable characters (NPCs)), but by also fostering dynamic,\nfree-form interactions between the player and the environment that align with\nthe procedural game narrative. The NPCs generated by PANGeA are\npersonality-biased and express traits from the Big 5 Personality Model in their\ngenerated responses. PANGeA addresses challenges behind ingesting free-form\ntext input, which can prompt LLM responses beyond the scope of the game\nnarrative. A novel validation system that uses the LLM's intelligence evaluates\ntext input and aligns generated responses with the unfolding narrative. Making\nthese interactions possible, PANGeA is supported by a server that hosts a\ncustom memory system that supplies context for augmenting generated responses\nthus aligning them with the procedural narrative. For its broad application,\nthe server has a REST interface enabling any game engine to integrate directly\nwith PANGeA, as well as an LLM interface adaptable with local or private LLMs.\nPANGeA's ability to foster dynamic narrative generation by aligning responses\nwith the procedural narrative is demonstrated through an empirical study and\nablation test of two versions of a demo game. These are, a custom,\nbrowser-based GPT and a Unity demo. As the results show, PANGeA holds potential\nto assist game designers in using LLMs to generate narrative-consistent content\neven when provided varied and unpredictable, free-form text input.",
      "tldr_zh": "本研究引入了 PANGeA，一种利用生成式 AI 的结构化方法，帮助游戏设计师通过大型语言模型 (LLMs) 生成回合制角色扮演游戏 (RPGs) 的程序化叙事内容，并根据高水平设计标准支持动态玩家互动。PANGeA 不仅生成游戏级别数据（如设置、关键物品和基于 Big 5 Personality Model 的个性偏好 NPC），还通过一个新型验证系统和自定义内存服务器，确保自由形式文本输入的响应与叙事保持一致，避免偏离。实验结果显示，在两个演示游戏（基于 GPT 和 Unity）的实证研究和消融测试中，PANGeA 有效提升了叙事一致性，为游戏引擎通过 REST 接口集成 LLMs 提供了灵活解决方案。",
      "categories": [
        "cs.AI",
        "cs.CL"
      ],
      "primary_category": "cs.AI",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2404.19721v3",
      "published_date": "2024-04-30 17:11:54 UTC",
      "updated_date": "2024-07-09 23:45:27 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-18T04:50:38.378596"
    },
    {
      "arxiv_id": "2404.19708v2",
      "title": "Harmonic LLMs are Trustworthy",
      "title_zh": "翻译失败",
      "authors": [
        "Nicholas S. Kersting",
        "Mohammad Rahman",
        "Suchismitha Vedala",
        "Yang Wang"
      ],
      "abstract": "We introduce an intuitive method to test the robustness (stability and\nexplainability) of any black-box LLM in real-time via its local deviation from\nharmoniticity, denoted as $\\gamma$. To the best of our knowledge this is the\nfirst completely model-agnostic and unsupervised method of measuring the\nrobustness of any given response from an LLM, based upon the model itself\nconforming to a purely mathematical standard. To show general application and\nimmediacy of results, we measure $\\gamma$ in 10 popular LLMs (ChatGPT,\nClaude-2.1, Claude3.0, GPT-4, GPT-4o, Smaug-72B, Mixtral-8x7B, Llama2-7B,\nMistral-7B and MPT-7B) across thousands of queries in three objective domains:\nWebQA, ProgrammingQA, and TruthfulQA. Across all models and domains tested,\nhuman annotation confirms that $\\gamma \\to 0$ indicates trustworthiness, and\nconversely searching higher values of $\\gamma$ easily exposes examples of\nhallucination, a fact that enables efficient adversarial prompt generation\nthrough stochastic gradient ascent in $\\gamma$. The low-$\\gamma$ leaders among\nthe models in the respective domains are GPT-4o, GPT-4, and Smaug-72B,\nproviding evidence that mid-size open-source models can win out against large\ncommercial models.",
      "tldr_zh": "本研究提出了一种直观方法，通过测量大型语言模型(LLMs)响应的局部谐波性偏差 γ，来实时评估其鲁棒性（包括稳定性与可解释性），这是一种模型无关的、非监督的数学标准。研究者在10个流行LLMs（如ChatGPT、GPT-4和Mixtral-8x7B）上进行了测试，涵盖WebQA、ProgrammingQA和TruthfulQA等领域的数千次查询。结果表明，γ接近0时模型可信度较高，而高γ值能有效识别幻觉并用于生成对抗性提示；此外，GPT-4o、GPT-4和Smaug-72B在各自领域表现出色，证明中型开源模型可能优于大型商业模型。",
      "categories": [
        "cs.LG",
        "cs.AI",
        "cs.CL",
        "cs.HC"
      ],
      "primary_category": "cs.LG",
      "comment": "15 pages, 2 figures, 16 tables; added Claude-3.0, GPT-4o, Mistral-7B,\n  Mixtral-8x7B, and more annotation for other models",
      "pdf_url": "http://arxiv.org/pdf/2404.19708v2",
      "published_date": "2024-04-30 17:00:32 UTC",
      "updated_date": "2024-07-25 16:16:46 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-18T04:50:50.640865"
    },
    {
      "arxiv_id": "2406.15396v1",
      "title": "Feature Purified Transformer With Cross-level Feature Guiding Decoder For Multi-class OOD and Anomaly Deteciton",
      "title_zh": "翻译失败",
      "authors": [
        "Jerry Chun-Wei Lin",
        "Pi-Wei Chen",
        "Chao-Chun Chen"
      ],
      "abstract": "Reconstruction networks are prevalently used in unsupervised anomaly and\nOut-of-Distribution (OOD) detection due to their independence from labeled\nanomaly data. However, in multi-class datasets, the effectiveness of anomaly\ndetection is often compromised by the models' generalized reconstruction\ncapabilities, which allow anomalies to blend within the expanded boundaries of\nnormality resulting from the added categories, thereby reducing detection\naccuracy. We introduce the FUTUREG framework, which incorporates two innovative\nmodules: the Feature Purification Module (FPM) and the CFG Decoder. The FPM\nconstrains the normality boundary within the latent space to effectively filter\nout anomalous features, while the CFG Decoder uses layer-wise encoder\nrepresentations to guide the reconstruction of filtered features, preserving\nfine-grained details. Together, these modules enhance the reconstruction error\nfor anomalies, ensuring high-quality reconstructions for normal samples. Our\nresults demonstrate that FUTUREG achieves state-of-the-art performance in\nmulti-class OOD settings and remains competitive in industrial anomaly\ndetection scenarios.",
      "tldr_zh": "该论文提出 FUTUREG 框架，用于解决多类数据集中的无监督异常和 Out-of-Distribution (OOD) 检测问题，该问题源于模型的泛化重建能力导致异常特征被误判为正常。框架引入 Feature Purification Module (FPM) 在潜在空间中约束正常性边界，以过滤异常特征；同时，CFG Decoder 通过层级编码器表示指导过滤特征的重建，保留细粒度细节，从而增强异常的重建错误。实验结果表明，FUTUREG 在多类 OOD 设置中实现最先进性能，并在工业异常检测场景中保持竞争力。",
      "categories": [
        "cs.CV",
        "cs.AI",
        "cs.LG"
      ],
      "primary_category": "cs.CV",
      "comment": "12 pages",
      "pdf_url": "http://arxiv.org/pdf/2406.15396v1",
      "published_date": "2024-04-30 16:45:51 UTC",
      "updated_date": "2024-04-30 16:45:51 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-18T04:51:01.670028"
    },
    {
      "arxiv_id": "2404.19696v1",
      "title": "Naturally Supervised 3D Visual Grounding with Language-Regularized Concept Learners",
      "title_zh": "翻译失败",
      "authors": [
        "Chun Feng",
        "Joy Hsu",
        "Weiyu Liu",
        "Jiajun Wu"
      ],
      "abstract": "3D visual grounding is a challenging task that often requires direct and\ndense supervision, notably the semantic label for each object in the scene. In\nthis paper, we instead study the naturally supervised setting that learns from\nonly 3D scene and QA pairs, where prior works underperform. We propose the\nLanguage-Regularized Concept Learner (LARC), which uses constraints from\nlanguage as regularization to significantly improve the accuracy of\nneuro-symbolic concept learners in the naturally supervised setting. Our\napproach is based on two core insights: the first is that language constraints\n(e.g., a word's relation to another) can serve as effective regularization for\nstructured representations in neuro-symbolic models; the second is that we can\nquery large language models to distill such constraints from language\nproperties. We show that LARC improves performance of prior works in naturally\nsupervised 3D visual grounding, and demonstrates a wide range of 3D visual\nreasoning capabilities-from zero-shot composition, to data efficiency and\ntransferability. Our method represents a promising step towards regularizing\nstructured visual reasoning frameworks with language-based priors, for learning\nin settings without dense supervision.",
      "tldr_zh": "本论文研究了自然监督下的3D Visual Grounding问题，仅使用3D场景和问答（QA）对作为训练数据，而非传统的密集监督标签。作者提出Language-Regularized Concept Learner (LARC)框架，通过语言约束（如词语关系）作为正则化手段，提高神经符号概念学习器的准确性，并利用大语言模型从语言属性中提炼这些约束。实验结果显示，LARC显著提升了现有方法的性能，并展示了广泛的3D视觉推理能力，包括零样本组合、数据效率和可转移性，从而为缺乏密集监督的视觉推理场景提供了一个有前景的正则化方法。",
      "categories": [
        "cs.CV",
        "cs.AI",
        "cs.CL",
        "cs.LG"
      ],
      "primary_category": "cs.CV",
      "comment": "CVPR 2024. The first two authors contributed equally",
      "pdf_url": "http://arxiv.org/pdf/2404.19696v1",
      "published_date": "2024-04-30 16:44:18 UTC",
      "updated_date": "2024-04-30 16:44:18 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-18T04:51:14.838855"
    },
    {
      "arxiv_id": "2404.19665v1",
      "title": "ATOMMIC: An Advanced Toolbox for Multitask Medical Imaging Consistency to facilitate Artificial Intelligence applications from acquisition to analysis in Magnetic Resonance Imaging",
      "title_zh": "翻译失败",
      "authors": [
        "Dimitrios Karkalousos",
        "Ivana Išgum",
        "Henk A. Marquering",
        "Matthan W. A. Caan"
      ],
      "abstract": "AI is revolutionizing MRI along the acquisition and processing chain.\nAdvanced AI frameworks have been developed to apply AI in various successive\ntasks, such as image reconstruction, quantitative parameter map estimation, and\nimage segmentation. Existing frameworks are often designed to perform tasks\nindependently or are focused on specific models or datasets, limiting\ngeneralization. We introduce ATOMMIC, an open-source toolbox that streamlines\nAI applications for accelerated MRI reconstruction and analysis. ATOMMIC\nimplements several tasks using DL networks and enables MultiTask Learning (MTL)\nto perform related tasks integrated, targeting generalization in the MRI\ndomain. We first review the current state of AI frameworks for MRI through a\ncomprehensive literature search and by parsing 12,479 GitHub repositories. We\nbenchmark 25 DL models on eight publicly available datasets to present distinct\napplications of ATOMMIC on accelerated MRI reconstruction, image segmentation,\nquantitative parameter map estimation, and joint accelerated MRI reconstruction\nand image segmentation utilizing MTL. Our findings demonstrate that ATOMMIC is\nthe only MTL framework with harmonized complex-valued and real-valued data\nsupport. Evaluations on single tasks show that physics-based models, which\nenforce data consistency by leveraging the physical properties of MRI,\noutperform other models in reconstructing highly accelerated acquisitions.\nPhysics-based models that produce high reconstruction quality can accurately\nestimate quantitative parameter maps. When high-performing reconstruction\nmodels are combined with robust segmentation networks utilizing MTL,\nperformance is improved in both tasks. ATOMMIC facilitates MRI reconstruction\nand analysis by standardizing workflows, enhancing data interoperability,\nintegrating unique features like MTL, and effectively benchmarking DL models.",
      "tldr_zh": "本文介绍了 ATOMMIC，一个开源工具箱，旨在简化 AI 在 MRI（Magnetic Resonance Imaging）从获取到分析的全链路应用，支持 MultiTask Learning (MTL) 以整合任务如加速图像重建、图像分割和定量参数图估计。研究通过文献搜索和基准测试 25 个 DL (Deep Learning) 模型在 8 个公开数据集上，发现物理-based 模型在重建高度加速的 MRI 数据时表现出色，并能准确估计参数图。利用 MTL 结合高性能重建和分割模型时，任务性能得到提升；ATOMMIC 的独特功能包括 harmonized complex-valued 和 real-valued 数据支持，以及标准化工作流，以提升 MRI 领域的泛化性和互操作性。",
      "categories": [
        "physics.med-ph",
        "cs.AI",
        "cs.SE",
        "math-ph",
        "math.MP"
      ],
      "primary_category": "physics.med-ph",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2404.19665v1",
      "published_date": "2024-04-30 16:00:21 UTC",
      "updated_date": "2024-04-30 16:00:21 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-18T04:51:29.349778"
    },
    {
      "arxiv_id": "2404.19654v1",
      "title": "Masked Multi-Query Slot Attention for Unsupervised Object Discovery",
      "title_zh": "翻译失败",
      "authors": [
        "Rishav Pramanik",
        "José-Fabian Villa-Vásquez",
        "Marco Pedersoli"
      ],
      "abstract": "Unsupervised object discovery is becoming an essential line of research for\ntackling recognition problems that require decomposing an image into entities,\nsuch as semantic segmentation and object detection. Recently, object-centric\nmethods that leverage self-supervision have gained popularity, due to their\nsimplicity and adaptability to different settings and conditions. However,\nthose methods do not exploit effective techniques already employed in modern\nself-supervised approaches. In this work, we consider an object-centric\napproach in which DINO ViT features are reconstructed via a set of queried\nrepresentations called slots. Based on that, we propose a masking scheme on\ninput features that selectively disregards the background regions, inducing our\nmodel to focus more on salient objects during the reconstruction phase.\nMoreover, we extend the slot attention to a multi-query approach, allowing the\nmodel to learn multiple sets of slots, producing more stable masks. During\ntraining, these multiple sets of slots are learned independently while, at test\ntime, these sets are merged through Hungarian matching to obtain the final\nslots. Our experimental results and ablations on the PASCAL-VOC 2012 dataset\nshow the importance of each component and highlight how their combination\nconsistently improves object localization. Our source code is available at:\nhttps://github.com/rishavpramanik/maskedmultiqueryslot",
      "tldr_zh": "这篇论文提出了一种无监督对象发现方法，基于 DINO ViT 特征，通过一组查询表示（slots）进行图像重建，并引入输入特征的掩码方案来选择性忽略背景区域，从而使模型更专注于显著对象。论文扩展了 slot attention 为多查询版本，允许学习多个 slots 集，并在训练时独立学习、测试时通过 Hungarian matching 合并，以提高掩码稳定性和对象定位准确性。在 PASCAL-VOC 2012 数据集上的实验结果显示，这种组合方法显著提升了对象定位性能，并验证了每个组件的重要性。源代码可从 GitHub 获取。",
      "categories": [
        "cs.CV",
        "cs.AI",
        "cs.LG"
      ],
      "primary_category": "cs.CV",
      "comment": "Paper accepted for presentation at IJCNN 2024",
      "pdf_url": "http://arxiv.org/pdf/2404.19654v1",
      "published_date": "2024-04-30 15:51:05 UTC",
      "updated_date": "2024-04-30 15:51:05 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-18T04:51:39.287550"
    },
    {
      "arxiv_id": "2404.19652v4",
      "title": "VimTS: A Unified Video and Image Text Spotter for Enhancing the Cross-domain Generalization",
      "title_zh": "翻译失败",
      "authors": [
        "Yuliang Liu",
        "Mingxin Huang",
        "Hao Yan",
        "Linger Deng",
        "Weijia Wu",
        "Hao Lu",
        "Chunhua Shen",
        "Lianwen Jin",
        "Xiang Bai"
      ],
      "abstract": "Text spotting, a task involving the extraction of textual information from\nimage or video sequences, faces challenges in cross-domain adaption, such as\nimage-to-image and image-to-video generalization. In this paper, we introduce a\nnew method, termed VimTS, which enhances the generalization ability of the\nmodel by achieving better synergy among different tasks. Typically, we propose\na Prompt Queries Generation Module and a Tasks-aware Adapter to effectively\nconvert the original single-task model into a multi-task model suitable for\nboth image and video scenarios with minimal additional parameters. The Prompt\nQueries Generation Module facilitates explicit interaction between different\ntasks, while the Tasks-aware Adapter helps the model dynamically learn suitable\nfeatures for each task. Additionally, to further enable the model to learn\ntemporal information at a lower cost, we propose a synthetic video text dataset\n(VTD-368k) by leveraging the Content Deformation Fields (CoDeF) algorithm.\nNotably, our method outperforms the state-of-the-art method by an average of\n2.6% in six cross-domain benchmarks such as TT-to-IC15, CTW1500-to-TT, and\nTT-to-CTW1500. For video-level cross-domain adaption, our method even surpasses\nthe previous end-to-end video spotting method in ICDAR2015 video and DSText v2\nby an average of 5.5% on the MOTA metric, using only image-level data. We\nfurther demonstrate that existing Large Multimodal Models exhibit limitations\nin generating cross-domain scene text spotting, in contrast to our VimTS model\nwhich requires significantly fewer parameters and data. The code and datasets\nwill be made available at the https://VimTextSpotter.github.io.",
      "tldr_zh": "该研究提出了一种统一的视频和图像文本识别方法VimTS，以提升模型在跨域泛化（如图像到图像或图像到视频）的性能。VimTS通过Prompt Queries Generation Module促进不同任务间的显式交互，以及Tasks-aware Adapter帮助模型动态学习适合各任务的特征，从而将单任务模型高效转换为多任务模型，仅需最小额外参数。研究者还构建了合成视频文本数据集VTD-368k，使用CoDeF算法低成本地学习时间信息。在实验中，VimTS在六个跨域基准上平均比最先进方法提高2.6%，并在视频级适应上使用仅图像级数据，即在ICDAR2015 video和DSText v2数据集上以MOTA指标平均超过现有端到端视频方法5.5%。该方法证明了其在参数和数据效率上的优势，超越了现有的大型多模态模型。",
      "categories": [
        "cs.CV",
        "cs.AI"
      ],
      "primary_category": "cs.CV",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2404.19652v4",
      "published_date": "2024-04-30 15:49:03 UTC",
      "updated_date": "2024-12-05 02:13:51 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-18T04:51:53.477847"
    },
    {
      "arxiv_id": "2404.19651v1",
      "title": "Provably Robust Conformal Prediction with Improved Efficiency",
      "title_zh": "可证明鲁棒的保形预测及其效率改进",
      "authors": [
        "Ge Yan",
        "Yaniv Romano",
        "Tsui-Wei Weng"
      ],
      "abstract": "Conformal prediction is a powerful tool to generate uncertainty sets with\nguaranteed coverage using any predictive model, under the assumption that the\ntraining and test data are i.i.d.. Recently, it has been shown that adversarial\nexamples are able to manipulate conformal methods to construct prediction sets\nwith invalid coverage rates, as the i.i.d. assumption is violated. To address\nthis issue, a recent work, Randomized Smoothed Conformal Prediction (RSCP), was\nfirst proposed to certify the robustness of conformal prediction methods to\nadversarial noise. However, RSCP has two major limitations: (i) its robustness\nguarantee is flawed when used in practice and (ii) it tends to produce large\nuncertainty sets. To address these limitations, we first propose a novel\nframework called RSCP+ to provide provable robustness guarantee in evaluation,\nwhich fixes the issues in the original RSCP method. Next, we propose two novel\nmethods, Post-Training Transformation (PTT) and Robust Conformal Training\n(RCT), to effectively reduce prediction set size with little computation\noverhead. Experimental results in CIFAR10, CIFAR100, and ImageNet suggest the\nbaseline method only yields trivial predictions including full label set, while\nour methods could boost the efficiency by up to $4.36\\times$, $5.46\\times$, and\n$16.9\\times$ respectively and provide practical robustness guarantee. Our codes\nare available at\nhttps://github.com/Trustworthy-ML-Lab/Provably-Robust-Conformal-Prediction.",
      "tldr_zh": "本文针对 Conformal Prediction 在对抗性噪声下的鲁棒性问题，提出 RSCP+ 框架，以修复原有 Randomized Smoothed Conformal Prediction (RSCP) 的缺陷，提供可证明的鲁棒性保证。作者还引入 Post-Training Transformation (PTT) 和 Robust Conformal Training (RCT) 方法，通过微小的计算开销有效减少预测集大小，提升效率。实验在 CIFAR10、CIFAR100 和 ImageNet 数据集上显示，该方法分别比基线提升 4.36×、5.46× 和 16.9× 的效率，同时确保实际鲁棒性表现。",
      "categories": [
        "cs.LG",
        "cs.AI",
        "cs.CV"
      ],
      "primary_category": "cs.LG",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2404.19651v1",
      "published_date": "2024-04-30 15:49:01 UTC",
      "updated_date": "2024-04-30 15:49:01 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-18T04:52:04.966000"
    },
    {
      "arxiv_id": "2404.19573v1",
      "title": "War Elephants: Rethinking Combat AI and Human Oversight",
      "title_zh": "翻译失败",
      "authors": [
        "Philip Feldman",
        "Aaron Dant",
        "Harry Dreany"
      ],
      "abstract": "This paper explores the changes that pervasive AI is having on the nature of\ncombat. We look beyond the substitution of AI for experts to an approach where\ncomplementary human and machine abilities are blended. Using historical and\nmodern examples, we show how autonomous weapons systems can be effectively\nmanaged by teams of human \"AI Operators\" combined with AI/ML \"Proxy Operators.\"\nBy basing our approach on the principles of complementation, we provide for a\nflexible and dynamic approach to managing lethal autonomous systems. We\nconclude by presenting a path to achieving an integrated vision of\nmachine-speed combat where the battlefield AI is operated by AI Operators that\nwatch for patterns of behavior within battlefield to assess the performance of\nlethal autonomous systems. This approach enables the development of combat\nsystems that are likely to be more ethical, operate at machine speed, and are\ncapable of responding to a broader range of dynamic battlefield conditions than\nany purely autonomous AI system could support.",
      "tldr_zh": "本论文重新审视了 AI 在战斗中的角色，提出一种将人类和机器能力互补的框架，以应对传统 AI 替代专家的局限性。作者通过历史和现代例子，介绍由人类“AI Operators”和 AI/ML “Proxy Operators”组成的团队来管理致命自主武器系统(lethal autonomous systems)，并基于互补原则实现灵活动态的控制。最终，这种方法有望打造更道德、运行于机器速度的战斗系统，能够更好地评估战场行为并适应更广泛的动态条件。",
      "categories": [
        "cs.CY",
        "cs.AI",
        "J.4; H.5.2; I.2.8"
      ],
      "primary_category": "cs.CY",
      "comment": "15 pages, 2 figures",
      "pdf_url": "http://arxiv.org/pdf/2404.19573v1",
      "published_date": "2024-04-30 14:07:57 UTC",
      "updated_date": "2024-04-30 14:07:57 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-18T04:52:14.658247"
    },
    {
      "arxiv_id": "2407.09982v1",
      "title": "Artificial intelligence and machine learning applications for cultured meat",
      "title_zh": "人工智能和机器学习在培养肉中的应用",
      "authors": [
        "Michael E. Todhunter",
        "Sheikh Jubair",
        "Ruchika Verma",
        "Rikard Saqe",
        "Kevin Shen",
        "Breanna Duffy"
      ],
      "abstract": "Cultured meat has the potential to provide a complementary meat industry with\nreduced environmental, ethical, and health impacts. However, major\ntechnological challenges remain which require time- and resource-intensive\nresearch and development efforts. Machine learning has the potential to\naccelerate cultured meat technology by streamlining experiments, predicting\noptimal results, and reducing experimentation time and resources. However, the\nuse of machine learning in cultured meat is in its infancy. This review covers\nthe work available to date on the use of machine learning in cultured meat and\nexplores future possibilities. We address four major areas of cultured meat\nresearch and development: establishing cell lines, cell culture media design,\nmicroscopy and image analysis, and bioprocessing and food processing\noptimization. This review aims to provide the foundation necessary for both\ncultured meat and machine learning scientists to identify research\nopportunities at the intersection between cultured meat and machine learning.",
      "tldr_zh": "这篇论文探讨了机器学习（machine learning）在培养肉（cultured meat）领域的应用潜力，以加速其研发进程，减少环境、伦理和健康影响。论文回顾了现有工作，涵盖四个关键领域：建立细胞系（cell lines）、细胞培养介质设计、显微镜和图像分析以及生物加工和食品加工优化。最终，它强调机器学习能简化实验、预测最佳结果并节省资源，为培养肉和机器学习科学家识别交叉研究机会提供基础。",
      "categories": [
        "cs.CY",
        "cs.AI"
      ],
      "primary_category": "cs.CY",
      "comment": "23 pages (43 pages with references), 4 figures. The first two listed\n  authors share first authorship; they and the last listed author contributed\n  equally to this work",
      "pdf_url": "http://arxiv.org/pdf/2407.09982v1",
      "published_date": "2024-04-30 13:35:18 UTC",
      "updated_date": "2024-04-30 13:35:18 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-18T04:52:26.828113"
    },
    {
      "arxiv_id": "2404.19543v1",
      "title": "RAG and RAU: A Survey on Retrieval-Augmented Language Model in Natural Language Processing",
      "title_zh": "翻译失败",
      "authors": [
        "Yucheng Hu",
        "Yuxing Lu"
      ],
      "abstract": "Large Language Models (LLMs) have catalyzed significant advancements in\nNatural Language Processing (NLP), yet they encounter challenges such as\nhallucination and the need for domain-specific knowledge. To mitigate these,\nrecent methodologies have integrated information retrieved from external\nresources with LLMs, substantially enhancing their performance across NLP\ntasks. This survey paper addresses the absence of a comprehensive overview on\nRetrieval-Augmented Language Models (RALMs), both Retrieval-Augmented\nGeneration (RAG) and Retrieval-Augmented Understanding (RAU), providing an\nin-depth examination of their paradigm, evolution, taxonomy, and applications.\nThe paper discusses the essential components of RALMs, including Retrievers,\nLanguage Models, and Augmentations, and how their interactions lead to diverse\nmodel structures and applications. RALMs demonstrate utility in a spectrum of\ntasks, from translation and dialogue systems to knowledge-intensive\napplications. The survey includes several evaluation methods of RALMs,\nemphasizing the importance of robustness, accuracy, and relevance in their\nassessment. It also acknowledges the limitations of RALMs, particularly in\nretrieval quality and computational efficiency, offering directions for future\nresearch. In conclusion, this survey aims to offer a structured insight into\nRALMs, their potential, and the avenues for their future development in NLP.\nThe paper is supplemented with a Github Repository containing the surveyed\nworks and resources for further study:\nhttps://github.com/2471023025/RALM_Survey.",
      "tldr_zh": "这篇调查论文探讨了Retrieval-Augmented Language Models (RALMs)，包括Retrieval-Augmented Generation (RAG)和Retrieval-Augmented Understanding (RAU)，旨在解决Large Language Models (LLMs)在Natural Language Processing (NLP)中面临的幻觉和领域知识不足等问题。论文提供了RALMs的全面概述，包括其范式演变、分类和关键组件，如Retrievers、Language Models和Augmentations，以及它们在翻译、对话系统和知识密集型任务中的应用。实验评估强调了模型的鲁棒性、准确性和相关性，同时指出了检索质量和计算效率的局限性，并为未来研究方向提供了指导。该论文附带了一个GitHub仓库，包含相关资源以便进一步学习。",
      "categories": [
        "cs.CL",
        "cs.AI"
      ],
      "primary_category": "cs.CL",
      "comment": "30 pages, 7 figures. Draft version 1",
      "pdf_url": "http://arxiv.org/pdf/2404.19543v1",
      "published_date": "2024-04-30 13:14:51 UTC",
      "updated_date": "2024-04-30 13:14:51 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-18T04:52:39.570438"
    },
    {
      "arxiv_id": "2404.19541v1",
      "title": "Ultra Inertial Poser: Scalable Motion Capture and Tracking from Sparse Inertial Sensors and Ultra-Wideband Ranging",
      "title_zh": "翻译失败",
      "authors": [
        "Rayan Armani",
        "Changlin Qian",
        "Jiaxi Jiang",
        "Christian Holz"
      ],
      "abstract": "While camera-based capture systems remain the gold standard for recording\nhuman motion, learning-based tracking systems based on sparse wearable sensors\nare gaining popularity. Most commonly, they use inertial sensors, whose\npropensity for drift and jitter have so far limited tracking accuracy. In this\npaper, we propose Ultra Inertial Poser, a novel 3D full body pose estimation\nmethod that constrains drift and jitter in inertial tracking via inter-sensor\ndistances. We estimate these distances across sparse sensor setups using a\nlightweight embedded tracker that augments inexpensive off-the-shelf 6D\ninertial measurement units with ultra-wideband radio-based\nranging$-$dynamically and without the need for stationary reference anchors.\nOur method then fuses these inter-sensor distances with the 3D states estimated\nfrom each sensor Our graph-based machine learning model processes the 3D states\nand distances to estimate a person's 3D full body pose and translation. To\ntrain our model, we synthesize inertial measurements and distance estimates\nfrom the motion capture database AMASS. For evaluation, we contribute a novel\nmotion dataset of 10 participants who performed 25 motion types, captured by 6\nwearable IMU+UWB trackers and an optical motion capture system, totaling 200\nminutes of synchronized sensor data (UIP-DB). Our extensive experiments show\nstate-of-the-art performance for our method over PIP and TIP, reducing position\nerror from $13.62$ to $10.65cm$ ($22\\%$ better) and lowering jitter from $1.56$\nto $0.055km/s^3$ (a reduction of $97\\%$).",
      "tldr_zh": "本研究提出Ultra Inertial Poser，一种可扩展的3D全身姿势估计方法，利用稀疏inertial sensors和ultra-wideband ranging来减少跟踪中的漂移和抖动。该方法通过轻量级嵌入式跟踪器动态估计传感器间距离，并将其与每个传感器的3D状态融合，使用基于图的机器学习模型来精确估计人体姿势和平移。为训练模型，研究者从AMASS数据库合成数据，并贡献了新数据集UIP-DB，包括10名参与者的25种动作类型和200分钟同步数据。实验结果显示，该方法比PIP和TIP基准模型将位置错误降低22%（从13.62 cm至10.65 cm），并将抖动减少97%（从1.56 km/s³至0.055 km/s³），显著提升了动作捕捉性能。",
      "categories": [
        "cs.CV",
        "cs.AI",
        "cs.GR",
        "eess.SP",
        "68T07, 68T45, 68U01",
        "I.2; I.3; I.4; I.5"
      ],
      "primary_category": "cs.CV",
      "comment": "Accepted by SIGGRAPH 2024, Code:\n  https://github.com/eth-siplab/UltraInertialPoser",
      "pdf_url": "http://arxiv.org/pdf/2404.19541v1",
      "published_date": "2024-04-30 13:14:11 UTC",
      "updated_date": "2024-04-30 13:14:11 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-18T04:52:53.811183"
    },
    {
      "arxiv_id": "2404.19518v1",
      "title": "MGCBS: An Optimal and Efficient Algorithm for Solving Multi-Goal Multi-Agent Path Finding Problem",
      "title_zh": "翻译失败",
      "authors": [
        "Mingkai Tang",
        "Yuanhang Li",
        "Hongji Liu",
        "Yingbing Chen",
        "Ming Liu",
        "Lujia Wang"
      ],
      "abstract": "With the expansion of the scale of robotics applications, the multi-goal\nmulti-agent pathfinding (MG-MAPF) problem began to gain widespread attention.\nThis problem requires each agent to visit pre-assigned multiple goal points at\nleast once without conflict. Some previous methods have been proposed to solve\nthe MG-MAPF problem based on Decoupling the goal Vertex visiting order search\nand the Single-agent pathfinding (DVS). However, this paper demonstrates that\nthe methods based on DVS cannot always obtain the optimal solution. To obtain\nthe optimal result, we propose the Multi-Goal Conflict-Based Search (MGCBS),\nwhich is based on Decoupling the goal Safe interval visiting order search and\nthe Single-agent pathfinding (DSS). Additionally, we present the\nTime-Interval-Space Forest (TIS Forest) to enhance the efficiency of MGCBS by\nmaintaining the shortest paths from any start point at any start time step to\neach safe interval at the goal points. The experiment demonstrates that our\nmethod can consistently obtain optimal results and execute up to 7 times faster\nthan the state-of-the-art method in our evaluation.",
      "tldr_zh": "本文提出了一种最优且高效的算法 MGCBS，用于解决多目标多智能体路径寻找问题（MG-MAPF），其中每个智能体需至少访问预分配的目标点一次且避免冲突。不同于之前的基于 Decoupling the goal Vertex visiting order search and the Single-agent pathfinding (DVS) 方法，该算法采用 Decoupling the goal Safe interval visiting order search and the Single-agent pathfinding (DSS) 策略，确保获得最优解。同时，引入 Time-Interval-Space Forest (TIS Forest) 来维护最短路径，从而显著提升计算效率。实验结果显示，MGCBS 比现有最先进方法快达 7 倍，并始终提供最优结果。",
      "categories": [
        "cs.MA",
        "cs.AI",
        "cs.RO"
      ],
      "primary_category": "cs.MA",
      "comment": "to be published in IJCAI2024",
      "pdf_url": "http://arxiv.org/pdf/2404.19518v1",
      "published_date": "2024-04-30 12:49:54 UTC",
      "updated_date": "2024-04-30 12:49:54 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-18T04:53:03.836300"
    },
    {
      "arxiv_id": "2404.19500v2",
      "title": "Towards Real-world Video Face Restoration: A New Benchmark",
      "title_zh": "面向真实世界的视频人脸修复：一个新基准",
      "authors": [
        "Ziyan Chen",
        "Jingwen He",
        "Xinqi Lin",
        "Yu Qiao",
        "Chao Dong"
      ],
      "abstract": "Blind face restoration (BFR) on images has significantly progressed over the\nlast several years, while real-world video face restoration (VFR), which is\nmore challenging for more complex face motions such as moving gaze directions\nand facial orientations involved, remains unsolved. Typical BFR methods are\nevaluated on privately synthesized datasets or self-collected real-world\nlow-quality face images, which are limited in their coverage of real-world\nvideo frames. In this work, we introduced new real-world datasets named FOS\nwith a taxonomy of \"Full, Occluded, and Side\" faces from mainly video frames to\nstudy the applicability of current methods on videos. Compared with existing\ntest datasets, FOS datasets cover more diverse degradations and involve face\nsamples from more complex scenarios, which helps to revisit current face\nrestoration approaches more comprehensively. Given the established datasets, we\nbenchmarked both the state-of-the-art BFR methods and the video super\nresolution (VSR) methods to comprehensively study current approaches,\nidentifying their potential and limitations in VFR tasks. In addition, we\nstudied the effectiveness of the commonly used image quality assessment (IQA)\nmetrics and face IQA (FIQA) metrics by leveraging a subjective user study. With\nextensive experimental results and detailed analysis provided, we gained\ninsights from the successes and failures of both current BFR and VSR methods.\nThese results also pose challenges to current face restoration approaches,\nwhich we hope stimulate future advances in VFR research.",
      "tldr_zh": "本文针对真实世界视频面部修复（VFR）的挑战，引入了新的数据集 FOS（Full, Occluded, and Side faces），该数据集主要来自视频帧，涵盖更多多样化的退化和复杂场景，以更全面评估现有方法。研究对最先进的图像面部修复（BFR）方法和视频超分辨率（VSR）方法进行了基准测试，揭示了它们在 VFR 任务中的潜力与局限性。作者还通过主观用户研究评估了图像质量评估（IQA）和面部 IQA（FIQA）指标的有效性，并提供了详细实验分析，以推动未来 VFR 研究的发展。",
      "categories": [
        "cs.CV",
        "cs.AI",
        "cs.MM",
        "eess.IV"
      ],
      "primary_category": "cs.CV",
      "comment": "Project page: https://ziyannchen.github.io/projects/VFRxBenchmark/",
      "pdf_url": "http://arxiv.org/pdf/2404.19500v2",
      "published_date": "2024-04-30 12:37:01 UTC",
      "updated_date": "2024-05-04 07:09:48 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-18T04:53:16.940216"
    },
    {
      "arxiv_id": "2404.19485v2",
      "title": "IID Relaxation by Logical Expressivity: A Research Agenda for Fitting Logics to Neurosymbolic Requirements",
      "title_zh": "翻译失败",
      "authors": [
        "Maarten C. Stol",
        "Alessandra Mileo"
      ],
      "abstract": "Neurosymbolic background knowledge and the expressivity required of its logic\ncan break Machine Learning assumptions about data Independence and Identical\nDistribution. In this position paper we propose to analyze IID relaxation in a\nhierarchy of logics that fit different use case requirements. We discuss the\nbenefits of exploiting known data dependencies and distribution constraints for\nNeurosymbolic use cases and argue that the expressivity required for this\nknowledge has implications for the design of underlying ML routines. This opens\na new research agenda with general questions about Neurosymbolic background\nknowledge and the expressivity required of its logic.",
      "tldr_zh": "本论文探讨了神经符号（Neurosymbolic）背景知识及其逻辑表达性如何打破机器学习（Machine Learning）中的IID（Independence and Identical Distribution）假设，提出一个研究议程来分析在不同逻辑层次中放松IID以适应具体用例需求。论文强调，通过利用已知的数据依赖性和分布约束，可以为Neurosymbolic应用带来益处，同时逻辑表达性会对底层ML例程设计产生重要影响。该议程旨在解决Neurosymbolic背景知识和所需逻辑表达性的普遍问题，推动相关领域的研究发展。",
      "categories": [
        "cs.AI"
      ],
      "primary_category": "cs.AI",
      "comment": "13 pages, 2 figures, submitted to NeSy 2024",
      "pdf_url": "http://arxiv.org/pdf/2404.19485v2",
      "published_date": "2024-04-30 12:09:53 UTC",
      "updated_date": "2024-07-01 12:44:38 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-18T04:53:28.439557"
    },
    {
      "arxiv_id": "2404.19484v2",
      "title": "More Compute Is What You Need",
      "title_zh": "更多计算资源就是你所需要的",
      "authors": [
        "Zhen Guo"
      ],
      "abstract": "Large language model pre-training has become increasingly expensive, with\nmost practitioners relying on scaling laws to allocate compute budgets for\nmodel size and training tokens, commonly referred to as Compute-Optimal or\nChinchilla Optimal. In this paper, we hypothesize a new scaling law that\nsuggests model performance depends mostly on the amount of compute spent for\ntransformer-based models, independent of the specific allocation to model size\nand dataset size. Using this unified scaling law, we predict that (a) for\ninference efficiency, training should prioritize smaller model sizes and larger\ntraining datasets, and (b) assuming the exhaustion of available web datasets,\nscaling the model size might be the only way to further improve model\nperformance.",
      "tldr_zh": "该论文质疑了现有的缩放定律（如Compute-Optimal或Chinchilla Optimal），提出一个新的统一scaling law，认为transformer-based模型的性能主要取决于总计算量，而非模型大小和数据集大小的具体分配。研究预测，为提升推理效率，训练应优先采用较小的模型大小和更大的训练数据集；此外，如果可用网络数据集耗尽，进一步改善模型性能的唯一途径可能是扩展模型大小。该发现为大型语言模型的资源分配提供新指导，强调计算量的核心作用。",
      "categories": [
        "cs.LG",
        "cs.AI",
        "cs.CL"
      ],
      "primary_category": "cs.LG",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2404.19484v2",
      "published_date": "2024-04-30 12:05:48 UTC",
      "updated_date": "2024-05-02 01:58:15 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-18T04:53:40.920763"
    },
    {
      "arxiv_id": "2404.19456v2",
      "title": "A Survey of Imitation Learning Methods, Environments and Metrics",
      "title_zh": "翻译失败",
      "authors": [
        "Nathan Gavenski",
        "Felipe Meneguzzi",
        "Michael Luck",
        "Odinaldo Rodrigues"
      ],
      "abstract": "Imitation learning is an approach in which an agent learns how to execute a\ntask by trying to mimic how one or more teachers perform it. This learning\napproach offers a compromise between the time it takes to learn a new task and\nthe effort needed to collect teacher samples for the agent. It achieves this by\nbalancing learning from the teacher, who has some information on how to perform\nthe task, and deviating from their examples when necessary, such as states not\npresent in the teacher samples. Consequently, the field of imitation learning\nhas received much attention from researchers in recent years, resulting in many\nnew methods and applications. However, with this increase in published work and\npast surveys focusing mainly on methodology, a lack of standardisation became\nmore prominent in the field. This non-standardisation is evident in the use of\nenvironments, which appear in no more than two works, and evaluation processes,\nsuch as qualitative analysis, that have become rare in current literature. In\nthis survey, we systematically review current imitation learning literature and\npresent our findings by (i) classifying imitation learning techniques,\nenvironments and metrics by introducing novel taxonomies; (ii) reflecting on\nmain problems from the literature; and (iii) presenting challenges and future\ndirections for researchers.",
      "tldr_zh": "这篇论文对Imitation Learning（模仿学习）方法、环境和指标进行了全面调查，Imitation Learning是一种让代理通过模仿教师行为来学习任务的途径，能平衡从教师样本学习与必要时的偏差。论文引入了新的分类法（taxonomies），系统地分类了现有的模仿学习技术、环境和评估指标，并反思了领域中的主要问题，如环境使用不一致和定性分析的缺失。最终，论文指出了当前挑战并提出了未来研究方向，以推动该领域的标准化和发展。",
      "categories": [
        "cs.LG",
        "cs.AI"
      ],
      "primary_category": "cs.LG",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2404.19456v2",
      "published_date": "2024-04-30 11:13:23 UTC",
      "updated_date": "2024-07-30 08:58:51 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-18T04:53:53.020505"
    },
    {
      "arxiv_id": "2404.19454v2",
      "title": "Augmented neural forms with parametric boundary-matching operators for solving ordinary differential equations",
      "title_zh": "翻译失败",
      "authors": [
        "Adam D. Kypriadis",
        "Isaac E. Lagaris",
        "Aristidis Likas",
        "Konstantinos E. Parsopoulos"
      ],
      "abstract": "Approximating solutions of ordinary and partial differential equations\nconstitutes a significant challenge. Based on functional expressions that\ninherently depend on neural networks, neural forms are specifically designed to\nprecisely satisfy the prescribed initial or boundary conditions of the problem,\nwhile providing the approximate solutions in closed form. Departing from the\nimportant class of ordinary differential equations, the present work aims to\nrefine and validate the neural forms methodology, paving the ground for further\ndevelopments in more challenging fields. The main contributions are as follows.\nFirst, it introduces a formalism for systematically crafting proper neural\nforms with adaptable boundary matches that are amenable to optimization.\nSecond, it describes a novel technique for converting problems with Neumann or\nRobin conditions into equivalent problems with parametric Dirichlet conditions.\nThird, it outlines a method for determining an upper bound on the absolute\ndeviation from the exact solution. The proposed augmented neural forms approach\nwas tested on a set of diverse problems, encompassing first- and second-order\nordinary differential equations, as well as first-order systems. Stiff\ndifferential equations have been considered as well. The resulting solutions\nwere subjected to assessment against existing exact solutions, solutions\nderived through the common penalized neural method, and solutions obtained via\ncontemporary numerical analysis methods. The reported results demonstrate that\nthe augmented neural forms not only satisfy the boundary and initial conditions\nexactly, but also provide closed-form solutions that facilitate high-quality\ninterpolation and controllable overall precision. These attributes are\nessential for expanding the application field of neural forms to more\nchallenging problems that are described by partial differential equations.",
      "tldr_zh": "本研究提出了一种增强神经形式（augmented neural forms）方法，利用参数化边界匹配算子（parametric boundary-matching operators）来求解常微分方程（ordinary differential equations），以精确满足初始或边界条件并提供闭式解。主要贡献包括：引入系统化形式主义来构建可优化的神经形式；开发新技巧将Neumann或Robin条件转换为等价的Dirichlet条件；以及提出方法计算解的绝对偏差上界。在多种问题（如一阶和二阶方程、刚性方程）上的实验显示，该方法不仅精确满足边界和初始条件，还提供高质量插值和高精度闭式解，为扩展到偏微分方程等领域奠定基础。",
      "categories": [
        "cs.AI"
      ],
      "primary_category": "cs.AI",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2404.19454v2",
      "published_date": "2024-04-30 11:10:34 UTC",
      "updated_date": "2024-09-26 10:34:40 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-18T04:54:06.657802"
    },
    {
      "arxiv_id": "2405.00076v2",
      "title": "Towards trustable SHAP scores",
      "title_zh": "翻译失败",
      "authors": [
        "Olivier Letoffe",
        "Xuanxiang Huang",
        "Joao Marques-Silva"
      ],
      "abstract": "SHAP scores represent the proposed use of the well-known Shapley values in\neXplainable Artificial Intelligence (XAI). Recent work has shown that the exact\ncomputation of SHAP scores can produce unsatisfactory results. Concretely, for\nsome ML models, SHAP scores will mislead with respect to relative feature\ninfluence. To address these limitations, recently proposed alternatives exploit\ndifferent axiomatic aggregations, all of which are defined in terms of\nabductive explanations. However, the proposed axiomatic aggregations are not\nShapley values. This paper investigates how SHAP scores can be modified so as\nto extend axiomatic aggregations to the case of Shapley values in XAI. More\nimportantly, the proposed new definition of SHAP scores avoids all the known\ncases where unsatisfactory results have been identified. The paper also\ncharacterizes the complexity of computing the novel definition of SHAP scores,\nhighlighting families of classifiers for which computing these scores is\ntractable. Furthermore, the paper proposes modifications to the existing\nimplementations of SHAP scores. These modifications eliminate some of the known\nlimitations of SHAP scores, and have negligible impact in terms of performance.",
      "tldr_zh": "该论文探讨了 SHAP scores 在可解释人工智能 (XAI) 中的问题，即其基于 Shapley values 的计算可能误导特征影响，导致不准确的结果。为解决此问题，作者提出了一种新的 SHAP scores 定义，通过扩展 axiomatic aggregations 到真正的 Shapley values，避免了已知的局限性，同时分析了其计算复杂性，并识别出某些分类器家族可实现高效计算。论文还建议对现有 SHAP scores 实现进行修改，以消除这些问题，同时保持性能影响最小，从而提升 XAI 的可信度。",
      "categories": [
        "cs.LG",
        "cs.AI"
      ],
      "primary_category": "cs.LG",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2405.00076v2",
      "published_date": "2024-04-30 10:39:20 UTC",
      "updated_date": "2024-12-19 02:29:41 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-18T04:54:17.073796"
    },
    {
      "arxiv_id": "2404.19432v1",
      "title": "Can Large Language Models put 2 and 2 together? Probing for Entailed Arithmetical Relationships",
      "title_zh": "大型语言模型能把2和2加起来吗？探测隐含的算术关系",
      "authors": [
        "D. Panas",
        "S. Seth",
        "V. Belle"
      ],
      "abstract": "Two major areas of interest in the era of Large Language Models regard\nquestions of what do LLMs know, and if and how they may be able to reason (or\nrather, approximately reason). Since to date these lines of work progressed\nlargely in parallel (with notable exceptions), we are interested in\ninvestigating the intersection: probing for reasoning about the implicitly-held\nknowledge. Suspecting the performance to be lacking in this area, we use a very\nsimple set-up of comparisons between cardinalities associated with elements of\nvarious subjects (e.g. the number of legs a bird has versus the number of\nwheels on a tricycle). We empirically demonstrate that although LLMs make\nsteady progress in knowledge acquisition and (pseudo)reasoning with each new\nGPT release, their capabilities are limited to statistical inference only. It\nis difficult to argue that pure statistical learning can cope with the\ncombinatorial explosion inherent in many commonsense reasoning tasks,\nespecially once arithmetical notions are involved. Further, we argue that\nbigger is not always better and chasing purely statistical improvements is\nflawed at the core, since it only exacerbates the dangerous conflation of the\nproduction of correct answers with genuine reasoning ability.",
      "tldr_zh": "这篇论文探讨了 Large Language Models (LLMs) 是否能处理隐含算术关系的推理能力，焦点在于测试 LLMs 对知识和推理的交叉表现。作者通过简单实验（如比较鸟的腿数与三轮车轮数等基数关联）来评估模型的表现，结果显示 LLMs 的进步仅限于统计推断，而无法进行真正的推理。研究强调，纯统计学习难以应对常识任务中的组合爆炸，尤其是涉及 arithmetical notions 时；此外，追求更大模型可能加剧正确答案与 genuine reasoning 能力的混淆。",
      "categories": [
        "cs.CL",
        "cs.AI"
      ],
      "primary_category": "cs.CL",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2404.19432v1",
      "published_date": "2024-04-30 10:28:04 UTC",
      "updated_date": "2024-04-30 10:28:04 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-18T04:54:30.834070"
    },
    {
      "arxiv_id": "2404.19403v1",
      "title": "Transformer-Enhanced Motion Planner: Attention-Guided Sampling for State-Specific Decision Making",
      "title_zh": "Transformer 增强运动规划器：注意力",
      "authors": [
        "Lei Zhuang",
        "Jingdong Zhao",
        "Yuntao Li",
        "Zichun Xu",
        "Liangliang Zhao",
        "Hong Liu"
      ],
      "abstract": "Sampling-based motion planning (SBMP) algorithms are renowned for their\nrobust global search capabilities. However, the inherent randomness in their\nsampling mechanisms often result in inconsistent path quality and limited\nsearch efficiency. In response to these challenges, this work proposes a novel\ndeep learning-based motion planning framework, named Transformer-Enhanced\nMotion Planner (TEMP), which synergizes an Environmental Information Semantic\nEncoder (EISE) with a Motion Planning Transformer (MPT). EISE converts\nenvironmental data into semantic environmental information (SEI), providing MPT\nwith an enriched environmental comprehension. MPT leverages an attention\nmechanism to dynamically recalibrate its focus on SEI, task objectives, and\nhistorical planning data, refining the sampling node generation. To demonstrate\nthe capabilities of TEMP, we train our model using a dataset comprised of\nplanning results produced by the RRT*. EISE and MPT are collaboratively\ntrained, enabling EISE to autonomously learn and extract patterns from\nenvironmental data, thereby forming semantic representations that MPT could\nmore effectively interpret and utilize for motion planning. Subsequently, we\nconducted a systematic evaluation of TEMP's efficacy across diverse task\ndimensions, which demonstrates that TEMP achieves exceptional performance\nmetrics and a heightened degree of generalizability compared to\nstate-of-the-art SBMPs.",
      "tldr_zh": "本研究针对采样-based motion planning (SBMP) 算法的随机性导致路径质量不一致和搜索效率低的问题，提出了一种新型深度学习框架Transformer-Enhanced Motion Planner (TEMP)。TEMP 结合Environmental Information Semantic Encoder (EISE) 和Motion Planning Transformer (MPT)，其中 EISE 将环境数据转换为语义环境信息 (SEI)，而 MPT 通过注意力机制动态调整对 SEI、任务目标和历史规划数据的关注，从而优化采样节点生成。实验结果显示，TEMP 使用 RRT* 生成的数据集进行协同训练后，在多种任务中表现出色，比现有 SBMP 算法提升了性能和泛化能力。",
      "categories": [
        "cs.RO",
        "cs.AI"
      ],
      "primary_category": "cs.RO",
      "comment": "This work has been submitted to the IEEE for possible publication",
      "pdf_url": "http://arxiv.org/pdf/2404.19403v1",
      "published_date": "2024-04-30 09:48:11 UTC",
      "updated_date": "2024-04-30 09:48:11 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-18T04:54:41.519842"
    },
    {
      "arxiv_id": "2404.19384v1",
      "title": "Pseudo Label Refinery for Unsupervised Domain Adaptation on Cross-dataset 3D Object Detection",
      "title_zh": "翻译失败",
      "authors": [
        "Zhanwei Zhang",
        "Minghao Chen",
        "Shuai Xiao",
        "Liang Peng",
        "Hengjia Li",
        "Binbin Lin",
        "Ping Li",
        "Wenxiao Wang",
        "Boxi Wu",
        "Deng Cai"
      ],
      "abstract": "Recent self-training techniques have shown notable improvements in\nunsupervised domain adaptation for 3D object detection (3D UDA). These\ntechniques typically select pseudo labels, i.e., 3D boxes, to supervise models\nfor the target domain. However, this selection process inevitably introduces\nunreliable 3D boxes, in which 3D points cannot be definitively assigned as\nforeground or background. Previous techniques mitigate this by reweighting\nthese boxes as pseudo labels, but these boxes can still poison the training\nprocess. To resolve this problem, in this paper, we propose a novel pseudo\nlabel refinery framework. Specifically, in the selection process, to improve\nthe reliability of pseudo boxes, we propose a complementary augmentation\nstrategy. This strategy involves either removing all points within an\nunreliable box or replacing it with a high-confidence box. Moreover, the point\nnumbers of instances in high-beam datasets are considerably higher than those\nin low-beam datasets, also degrading the quality of pseudo labels during the\ntraining process. We alleviate this issue by generating additional proposals\nand aligning RoI features across different domains. Experimental results\ndemonstrate that our method effectively enhances the quality of pseudo labels\nand consistently surpasses the state-of-the-art methods on six autonomous\ndriving benchmarks. Code will be available at\nhttps://github.com/Zhanwei-Z/PERE.",
      "tldr_zh": "这篇论文针对 3D 对象检测的无监督域适应 (Unsupervised Domain Adaptation) 问题，提出了一种 Pseudo Label Refinery 框架，以提升伪标签 (pseudo labels) 的质量并减少训练过程中的噪声干扰。框架的核心方法包括互补增强策略 (complementary augmentation strategy)，即通过移除不可靠的 3D 框内的点或用高置信度框替换它们，来提高伪标签的可靠性；同时，它通过生成额外提案 (additional proposals) 和跨域对齐 RoI 特征 (aligning RoI features) 来缓解高光束和低光束数据集点数不均的问题。实验结果表明，该方法显著提升了伪标签质量，并在六个自动驾驶基准上超越了最先进的技术。",
      "categories": [
        "cs.CV",
        "cs.AI"
      ],
      "primary_category": "cs.CV",
      "comment": "Accepted by CVPR2024",
      "pdf_url": "http://arxiv.org/pdf/2404.19384v1",
      "published_date": "2024-04-30 09:20:35 UTC",
      "updated_date": "2024-04-30 09:20:35 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-18T04:54:58.073903"
    },
    {
      "arxiv_id": "2407.10244v1",
      "title": "Reimagining AI in Social Work: Practitioner Perspectives on Incorporating Technology in their Practice",
      "title_zh": "翻译失败",
      "authors": [
        "Katie Wassal",
        "Carolyn Ashurst",
        "Jiri Hron",
        "Miri Zilka"
      ],
      "abstract": "There has been a surge in the number and type of AI tools being tested and\ndeployed within both national and local government in the UK, including within\nthe social care sector. Given the many ongoing and planned future developments,\nthe time is ripe to review and reflect on the state of AI in social care. We do\nso by conducting semi-structured interviews with UK-based social work\nprofessionals about their experiences and opinions of past and current AI\nsystems. Our aim is to understand what systems would practitioners like to see\ndeveloped and how. We find that all our interviewees had overwhelmingly\nnegative past experiences of technology in social care, unanimous aversion to\nalgorithmic decision systems in particular, but also strong interest in AI\napplications that could allow them to spend less time on administrative tasks.\nIn response to our findings, we offer a series of concrete recommendations,\nwhich include commitment to participatory design, as well as the necessity of\nregaining practitioner trust.",
      "tldr_zh": "本研究通过对英国社会工作专业人士进行半结构化采访（semi-structured interviews），探讨了他们对AI在社交护理领域的应用经历和意见。结果显示，受访者对过去的AI技术持有强烈负面看法，特别是对算法决策系统（algorithmic decision systems）表现出一致的反感，但对能减少行政任务的AI应用表现出浓厚兴趣。主要贡献包括提出具体推荐，如承诺参与式设计（participatory design）和重建从业者信任，以推动AI在社会工作中的负责任整合。",
      "categories": [
        "cs.CY",
        "cs.AI"
      ],
      "primary_category": "cs.CY",
      "comment": "Under review",
      "pdf_url": "http://arxiv.org/pdf/2407.10244v1",
      "published_date": "2024-04-30 09:07:04 UTC",
      "updated_date": "2024-04-30 09:07:04 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-18T04:55:04.605295"
    },
    {
      "arxiv_id": "2404.19370v1",
      "title": "Numeric Reward Machines",
      "title_zh": "数值奖励机器",
      "authors": [
        "Kristina Levina",
        "Nikolaos Pappas",
        "Athanasios Karapantelakis",
        "Aneta Vulgarakis Feljan",
        "Jendrik Seipp"
      ],
      "abstract": "Reward machines inform reinforcement learning agents about the reward\nstructure of the environment and often drastically speed up the learning\nprocess. However, reward machines only accept Boolean features such as\nrobot-reached-gold. Consequently, many inherently numeric tasks cannot profit\nfrom the guidance offered by reward machines. To address this gap, we aim to\nextend reward machines with numeric features such as distance-to-gold. For\nthis, we present two types of reward machines: numeric-Boolean and numeric. In\na numeric-Boolean reward machine, distance-to-gold is emulated by two Boolean\nfeatures distance-to-gold-decreased and robot-reached-gold. In a numeric reward\nmachine, distance-to-gold is used directly alongside the Boolean feature\nrobot-reached-gold. We compare our new approaches to a baseline reward machine\nin the Craft domain, where the numeric feature is the agent-to-target distance.\nWe use cross-product Q-learning, Q-learning with counter-factual experiences,\nand the options framework for learning. Our experimental results show that our\nnew approaches significantly outperform the baseline approach. Extending reward\nmachines with numeric features opens up new possibilities of using reward\nmachines in inherently numeric tasks.",
      "tldr_zh": "本论文提出了 Numeric Reward Machines，以扩展传统奖励机器仅支持 Boolean features 的局限性，使其能处理涉及数字特征的任务，如 distance-to-gold。研究引入了两种新类型：numeric-Boolean 奖励机器（通过模拟数字特征为布尔特征，如 distance-to-gold-decreased）和 numeric 奖励机器（直接结合数字特征与 Boolean features）。在 Craft 领域实验中，使用 cross-product Q-learning、Q-learning with counter-factual experiences 和 options framework 等方法，结果显示新方法显著优于基线，提升了强化学习代理的学习效率。这种扩展为数字任务的应用打开了新可能性。",
      "categories": [
        "cs.AI",
        "cs.LG"
      ],
      "primary_category": "cs.AI",
      "comment": "ICAPS 2024; Workshop on Bridging the Gap Between AI Planning and\n  Reinforcement Learning",
      "pdf_url": "http://arxiv.org/pdf/2404.19370v1",
      "published_date": "2024-04-30 08:58:47 UTC",
      "updated_date": "2024-04-30 08:58:47 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-18T04:55:18.109778"
    },
    {
      "arxiv_id": "2404.19361v1",
      "title": "A Negotiator's Backup Plan: Optimal Concessions with a Reservation Value",
      "title_zh": "翻译失败",
      "authors": [
        "Tamara C. P. Florijn",
        "Pinar Yolum",
        "Tim Baarslag"
      ],
      "abstract": "Automated negotiation is a well-known mechanism for autonomous agents to\nreach agreements. To realize beneficial agreements quickly, it is key to employ\na good bidding strategy. When a negotiating agent has a good back-up plan,\ni.e., a high reservation value, failing to reach an agreement is not\nnecessarily disadvantageous. Thus, the agent can adopt a risk-seeking strategy,\naiming for outcomes with a higher utilities.\n  Accordingly, this paper develops an optimal bidding strategy called\nMIA-RVelous for bilateral negotiations with private reservation values. The\nproposed greedy algorithm finds the optimal bid sequence given the agent's\nbeliefs about the opponent in $O(n^2D)$ time, with $D$ the maximum number of\nrounds and $n$ the number of outcomes. The results obtained here can pave the\nway to realizing effective concurrent negotiations, given that concurrent\nnegotiations can serve as a (probabilistic) backup plan.",
      "tldr_zh": "该论文探讨了自动化谈判（Automated negotiation）中代理的出价策略（bidding strategy），强调当代理拥有高保留价值（reservation value）时，可以采用风险寻求策略（risk-seeking strategy）来追求更高收益。论文提出了一种名为MIA-RVelous的最优出价策略，这是一个贪婪算法（greedy algorithm），用于双边谈判（bilateral negotiations）中基于代理对对手信念计算出价序列，计算复杂度为O(n^2D)，其中n是结果数、D是最大轮次。该策略的结果有助于实现有效的并发谈判（concurrent negotiations），将并发谈判视为一种概率备用计划。",
      "categories": [
        "cs.GT",
        "cs.AI"
      ],
      "primary_category": "cs.GT",
      "comment": "Accepted at AAMAS 2024",
      "pdf_url": "http://arxiv.org/pdf/2404.19361v1",
      "published_date": "2024-04-30 08:45:18 UTC",
      "updated_date": "2024-04-30 08:45:18 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-18T04:55:32.753754"
    },
    {
      "arxiv_id": "2404.19359v1",
      "title": "Evaluating Lexicon Incorporation for Depression Symptom Estimation",
      "title_zh": "翻译失败",
      "authors": [
        "Kirill Milintsevich",
        "Gaël Dias",
        "Kairit Sirts"
      ],
      "abstract": "This paper explores the impact of incorporating sentiment, emotion, and\ndomain-specific lexicons into a transformer-based model for depression symptom\nestimation. Lexicon information is added by marking the words in the input\ntranscripts of patient-therapist conversations as well as in social media\nposts. Overall results show that the introduction of external knowledge within\npre-trained language models can be beneficial for prediction performance, while\ndifferent lexicons show distinct behaviours depending on the targeted task.\nAdditionally, new state-of-the-art results are obtained for the estimation of\ndepression level over patient-therapist interviews.",
      "tldr_zh": "这篇论文评估了将情感词汇表(Sentiment lexicons)、情感词汇表(Emotion lexicons)和领域特定词汇表(Domain-specific lexicons)整合到基于变压器的模型(Transformer-based model)中，用于估计抑郁症状。研究方法包括在患者-治疗师对话和社交媒体帖子中标记相关单词，结果显示引入外部知识能提升预测性能，但不同词汇表在特定任务中的表现存在差异。此外，该方法在患者-治疗师访谈的抑郁水平估计上取得了新的最先进(State-of-the-art)结果。",
      "categories": [
        "cs.CL",
        "cs.AI"
      ],
      "primary_category": "cs.CL",
      "comment": "Accepted to Clinical NLP workshop at NAACL 2024",
      "pdf_url": "http://arxiv.org/pdf/2404.19359v1",
      "published_date": "2024-04-30 08:41:06 UTC",
      "updated_date": "2024-04-30 08:41:06 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-18T04:55:42.974893"
    },
    {
      "arxiv_id": "2404.19349v1",
      "title": "Human-AI Interaction in Industrial Robotics: Design and Empirical Evaluation of a User Interface for Explainable AI-Based Robot Program Optimization",
      "title_zh": "翻译失败",
      "authors": [
        "Benjamin Alt",
        "Johannes Zahn",
        "Claudius Kienle",
        "Julia Dvorak",
        "Marvin May",
        "Darko Katic",
        "Rainer Jäkel",
        "Tobias Kopp",
        "Michael Beetz",
        "Gisela Lanza"
      ],
      "abstract": "While recent advances in deep learning have demonstrated its transformative\npotential, its adoption for real-world manufacturing applications remains\nlimited. We present an Explanation User Interface (XUI) for a state-of-the-art\ndeep learning-based robot program optimizer which provides both naive and\nexpert users with different user experiences depending on their skill level, as\nwell as Explainable AI (XAI) features to facilitate the application of deep\nlearning methods in real-world applications. To evaluate the impact of the XUI\non task performance, user satisfaction and cognitive load, we present the\nresults of a preliminary user survey and propose a study design for a\nlarge-scale follow-up study.",
      "tldr_zh": "本研究探讨了深度学习在制造业应用的限制，并设计了一个Explanation User Interface (XUI)，用于Explainable AI (XAI) 基于的工业机器人程序优化器，以适应初级和专家用户的不同技能水平并提供XAI功能。XUI通过提供个性化用户体验，帮助提升任务性能、用户满意度和降低认知负荷。研究基于初步用户调查的结果，评估了该界面的有效性，并提出了大规模后续研究的计划。",
      "categories": [
        "cs.RO",
        "cs.AI",
        "cs.CE",
        "cs.HC",
        "cs.LG",
        "68T40",
        "I.2.1; I.2.9; I.2.2; J.6; J.7"
      ],
      "primary_category": "cs.RO",
      "comment": "6 pages, 4 figures, accepted at the 2024 CIRP International\n  Conference on Manufacturing Systems (CMS)",
      "pdf_url": "http://arxiv.org/pdf/2404.19349v1",
      "published_date": "2024-04-30 08:20:31 UTC",
      "updated_date": "2024-04-30 08:20:31 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-18T04:55:55.165002"
    },
    {
      "arxiv_id": "2404.19346v1",
      "title": "Pessimistic Value Iteration for Multi-Task Data Sharing in Offline Reinforcement Learning",
      "title_zh": "翻译失败",
      "authors": [
        "Chenjia Bai",
        "Lingxiao Wang",
        "Jianye Hao",
        "Zhuoran Yang",
        "Bin Zhao",
        "Zhen Wang",
        "Xuelong Li"
      ],
      "abstract": "Offline Reinforcement Learning (RL) has shown promising results in learning a\ntask-specific policy from a fixed dataset. However, successful offline RL often\nrelies heavily on the coverage and quality of the given dataset. In scenarios\nwhere the dataset for a specific task is limited, a natural approach is to\nimprove offline RL with datasets from other tasks, namely, to conduct\nMulti-Task Data Sharing (MTDS). Nevertheless, directly sharing datasets from\nother tasks exacerbates the distribution shift in offline RL. In this paper, we\npropose an uncertainty-based MTDS approach that shares the entire dataset\nwithout data selection. Given ensemble-based uncertainty quantification, we\nperform pessimistic value iteration on the shared offline dataset, which\nprovides a unified framework for single- and multi-task offline RL. We further\nprovide theoretical analysis, which shows that the optimality gap of our method\nis only related to the expected data coverage of the shared dataset, thus\nresolving the distribution shift issue in data sharing. Empirically, we release\nan MTDS benchmark and collect datasets from three challenging domains. The\nexperimental results show our algorithm outperforms the previous\nstate-of-the-art methods in challenging MTDS problems. See\nhttps://github.com/Baichenjia/UTDS for the datasets and code.",
      "tldr_zh": "本研究针对离线强化学习（Offline RL）中数据集覆盖不足的问题，提出了一种基于不确定性的多任务数据共享（Multi-Task Data Sharing, MTDS）方法，该方法使用悲观价值迭代（Pessimistic Value Iteration）来直接共享整个数据集，而非进行数据选择。方法结合 ensemble-based uncertainty quantification，对共享数据集进行统一框架处理，从而缓解分布偏移问题，并适用于单任务和多任务场景。理论分析表明，该方法的优化差距仅取决于共享数据集的预期覆盖，提供了解释分布偏移的机制；实验在三个挑战领域的新MTDS基准上显示，该算法优于现有最先进方法，并提供了代码和数据集以供复现。",
      "categories": [
        "cs.LG",
        "cs.AI"
      ],
      "primary_category": "cs.LG",
      "comment": "Accepted by Artificial Intelligence (AIJ)",
      "pdf_url": "http://arxiv.org/pdf/2404.19346v1",
      "published_date": "2024-04-30 08:16:52 UTC",
      "updated_date": "2024-04-30 08:16:52 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-18T04:56:07.052736"
    },
    {
      "arxiv_id": "2404.19341v1",
      "title": "Reliable or Deceptive? Investigating Gated Features for Smooth Visual Explanations in CNNs",
      "title_zh": "翻译失败",
      "authors": [
        "Soham Mitra",
        "Atri Sukul",
        "Swalpa Kumar Roy",
        "Pravendra Singh",
        "Vinay Verma"
      ],
      "abstract": "Deep learning models have achieved remarkable success across diverse domains.\nHowever, the intricate nature of these models often impedes a clear\nunderstanding of their decision-making processes. This is where Explainable AI\n(XAI) becomes indispensable, offering intuitive explanations for model\ndecisions. In this work, we propose a simple yet highly effective approach,\nScoreCAM++, which introduces modifications to enhance the promising ScoreCAM\nmethod for visual explainability. Our proposed approach involves altering the\nnormalization function within the activation layer utilized in ScoreCAM,\nresulting in significantly improved results compared to previous efforts.\nAdditionally, we apply an activation function to the upsampled activation\nlayers to enhance interpretability. This improvement is achieved by selectively\ngating lower-priority values within the activation layer. Through extensive\nexperiments and qualitative comparisons, we demonstrate that ScoreCAM++\nconsistently achieves notably superior performance and fairness in interpreting\nthe decision-making process compared to both ScoreCAM and previous methods.",
      "tldr_zh": "该研究探讨了深度学习模型在 CNNs 中的决策过程不透明问题，并强调 Explainable AI (XAI) 的重要性。作者提出 ScoreCAM++ 方法，通过修改 ScoreCAM 的归一化函数并应用激活函数来选择性地门控（gating）激活层中的低优先级值，从而提升视觉解释的准确性和可解释性。实验和定性比较结果表明，ScoreCAM++ 在性能和公平性方面显著优于 ScoreCAM 和现有方法。",
      "categories": [
        "cs.CV",
        "cs.AI"
      ],
      "primary_category": "cs.CV",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2404.19341v1",
      "published_date": "2024-04-30 08:06:04 UTC",
      "updated_date": "2024-04-30 08:06:04 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-18T04:56:18.469301"
    },
    {
      "arxiv_id": "2404.19336v3",
      "title": "Improving LLM Classification of Logical Errors by Integrating Error Relationship into Prompts",
      "title_zh": "通过将错误关系整合到提示中改进 LLM 对逻辑错误的分类",
      "authors": [
        "Yanggyu Lee",
        "Suchae Jeong",
        "Jihie Kim"
      ],
      "abstract": "LLMs trained in the understanding of programming syntax are now providing\neffective assistance to developers and are being used in programming education\nsuch as in generation of coding problem examples or providing code\nexplanations. A key aspect of programming education is understanding and\ndealing with error message. However, 'logical errors' in which the program\noperates against the programmer's intentions do not receive error messages from\nthe compiler. In this study, building on existing research on programming\nerrors, we first define the types of logical errors that can occur in\nprogramming in general. Based on the definition, we propose an effective\napproach for detecting logical errors with LLMs that makes use of relations\namong error types in the Chain-of-Thought and Tree-of-Thought prompts. The\nexperimental results indicate that when such logical error descriptions in the\nprompt are used, the average classifition performance is about 21% higher than\nthe ones without them. We also conducted an experiment for exploiting the\nrelations among errors in generating a new logical error dataset using LLMs. As\nthere is very limited dataset for logical errors such benchmark dataset can be\nvery useful for various programming related applications. We expect that our\nwork can assist novice programmers in identifying the causes of code errors and\ncorrect them more effectively.",
      "tldr_zh": "本研究针对大型语言模型（LLMs）在编程教育中处理逻辑错误（logical errors）的挑战，提出了一种新方法，通过在Chain-of-Thought和Tree-of-Thought提示中整合错误类型间的关系，提高逻辑错误的分类准确性。实验结果显示，这种方法使分类性能平均提高了21%，相比不使用错误关系提示的基线模型有显著提升。该方法还扩展到使用LLMs生成新的逻辑错误数据集，以弥补现有数据集的不足，最终有助于新手程序员更有效地识别和修正代码错误。",
      "categories": [
        "cs.AI",
        "cs.PL"
      ],
      "primary_category": "cs.AI",
      "comment": "Published in ITS 2024 (Best Paper Award)",
      "pdf_url": "http://arxiv.org/pdf/2404.19336v3",
      "published_date": "2024-04-30 08:03:22 UTC",
      "updated_date": "2024-11-17 19:49:58 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-18T04:56:30.398461"
    },
    {
      "arxiv_id": "2404.19330v1",
      "title": "G2LTraj: A Global-to-Local Generation Approach for Trajectory Prediction",
      "title_zh": "G2LTraj：一种全局到局部生成方法用于轨迹预测",
      "authors": [
        "Zhanwei Zhang",
        "Zishuo Hua",
        "Minghao Chen",
        "Wei Lu",
        "Binbin Lin",
        "Deng Cai",
        "Wenxiao Wang"
      ],
      "abstract": "Predicting future trajectories of traffic agents accurately holds substantial\nimportance in various applications such as autonomous driving. Previous methods\ncommonly infer all future steps of an agent either recursively or\nsimultaneously. However, the recursive strategy suffers from the accumulated\nerror, while the simultaneous strategy overlooks the constraints among future\nsteps, resulting in kinematically infeasible predictions. To address these\nissues, in this paper, we propose G2LTraj, a plug-and-play global-to-local\ngeneration approach for trajectory prediction. Specifically, we generate a\nseries of global key steps that uniformly cover the entire future time range.\nSubsequently, the local intermediate steps between the adjacent key steps are\nrecursively filled in. In this way, we prevent the accumulated error from\npropagating beyond the adjacent key steps. Moreover, to boost the kinematical\nfeasibility, we not only introduce the spatial constraints among key steps but\nalso strengthen the temporal constraints among the intermediate steps. Finally,\nto ensure the optimal granularity of key steps, we design a selectable\ngranularity strategy that caters to each predicted trajectory. Our G2LTraj\nsignificantly improves the performance of seven existing trajectory predictors\nacross the ETH, UCY and nuScenes datasets. Experimental results demonstrate its\neffectiveness. Code will be available at https://github.com/Zhanwei-Z/G2LTraj.",
      "tldr_zh": "该论文提出 G2LTraj，一种全局到局部生成方法，用于提升交通代理的轨迹预测准确性，以解决现有递归策略的累积错误和同时策略的运动学约束忽略问题。具体而言，G2LTraj 先生成覆盖整个未来时间范围的全局关键步骤，然后递归填充相邻关键步骤之间的局部中间步骤，同时引入空间约束和时间约束以确保预测的可行性，并采用可选择的粒度策略适应每个轨迹的优化需求。实验结果显示，该方法显著提高了七个现有预测器的性能，在 ETH、UCY 和 nuScenes 数据集上取得了更好的表现，证明了其有效性。",
      "categories": [
        "cs.CV",
        "cs.AI"
      ],
      "primary_category": "cs.CV",
      "comment": "Accepted by IJCAI 2024",
      "pdf_url": "http://arxiv.org/pdf/2404.19330v1",
      "published_date": "2024-04-30 07:53:34 UTC",
      "updated_date": "2024-04-30 07:53:34 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-18T04:56:43.459660"
    },
    {
      "arxiv_id": "2404.19306v1",
      "title": "Comprehensive Forecasting-Based Analysis of Hybrid and Stacked Stateful/ Stateless Models",
      "title_zh": "翻译失败",
      "authors": [
        "Swayamjit Saha"
      ],
      "abstract": "Wind speed is a powerful source of renewable energy, which can be used as an\nalternative to the non-renewable resources for production of electricity.\nRenewable sources are clean, infinite and do not impact the environment\nnegatively during production of electrical energy. However, while eliciting\nelectrical energy from renewable resources viz. solar irradiance, wind speed,\nhydro should require special planning failing which may result in huge loss of\nlabour and money for setting up the system. In this paper, we discuss four deep\nrecurrent neural networks viz. Stacked Stateless LSTM, Stacked Stateless GRU,\nStacked Stateful LSTM and Statcked Stateful GRU which will be used to predict\nwind speed on a short-term basis for the airport sites beside two campuses of\nMississippi State University. The paper does a comprehensive analysis of the\nperformance of the models used describing their architectures and how\nefficiently they elicit the results with the help of RMSE values. A detailed\ndescription of the time and space complexities of the above models has also\nbeen discussed.",
      "tldr_zh": "这篇论文分析了混合和堆叠的 Stateful/Stateless 模型，用于短期风速预测，以支持可再生能源（如风能）的规划和效率优化。研究比较了四种深度循环神经网络：Stacked Stateless LSTM、Stacked Stateless GRU、Stacked Stateful LSTM 和 Stacked Stateful GRU，在 Mississippi State University 附近机场站点的数据上进行评估。论文通过 RMSE 值量化模型性能，并详细讨论了它们的架构、时间和空间复杂性，结果表明这些模型有助于减少可再生能源系统部署的潜在损失。",
      "categories": [
        "cs.LG",
        "cs.AI"
      ],
      "primary_category": "cs.LG",
      "comment": "8 pages, 14 figures",
      "pdf_url": "http://arxiv.org/pdf/2404.19306v1",
      "published_date": "2024-04-30 07:18:10 UTC",
      "updated_date": "2024-04-30 07:18:10 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-18T04:56:55.170801"
    },
    {
      "arxiv_id": "2404.19303v2",
      "title": "Data Set Terminology of Deep Learning in Medicine: A Historical Review and Recommendation",
      "title_zh": "翻译失败",
      "authors": [
        "Shannon L. Walston",
        "Hiroshi Seki",
        "Hirotaka Takita",
        "Yasuhito Mitsuyama",
        "Shingo Sato",
        "Akifumi Hagiwara",
        "Rintaro Ito",
        "Shouhei Hanaoka",
        "Yukio Miki",
        "Daiju Ueda"
      ],
      "abstract": "Medicine and deep learning-based artificial intelligence (AI) engineering\nrepresent two distinct fields each with decades of published history. With such\nhistory comes a set of terminology that has a specific way in which it is\napplied. However, when two distinct fields with overlapping terminology start\nto collaborate, miscommunication and misunderstandings can occur. This\nnarrative review aims to give historical context for these terms, accentuate\nthe importance of clarity when these terms are used in medical AI contexts, and\noffer solutions to mitigate misunderstandings by readers from either field.\nThrough an examination of historical documents, including articles, writing\nguidelines, and textbooks, this review traces the divergent evolution of terms\nfor data sets and their impact. Initially, the discordant interpretations of\nthe word 'validation' in medical and AI contexts are explored. Then the data\nsets used for AI evaluation are classified, namely random splitting,\ncross-validation, temporal, geographic, internal, and external sets. The\naccurate and standardized description of these data sets is crucial for\ndemonstrating the robustness and generalizability of AI applications in\nmedicine. This review clarifies existing literature to provide a comprehensive\nunderstanding of these classifications and their implications in AI evaluation.\nThis review then identifies often misunderstood terms and proposes pragmatic\nsolutions to mitigate terminological confusion. Among these solutions are the\nuse of standardized terminology such as 'training set,' 'validation (or tuning)\nset,' and 'test set,' and explicit definition of data set splitting\nterminologies in each medical AI research publication. This review aspires to\nenhance the precision of communication in medical AI, thereby fostering more\neffective and transparent research methodologies in this interdisciplinary\nfield.",
      "tldr_zh": "这篇论文回顾了医学和深度学习AI领域中数据集术语的历史演变，强调了术语分歧（如“validation”的不同解释）可能导致的跨领域误解问题。作者通过分析历史文献，包括文章、写作指南和教科书，分类了AI评估中的数据集类型，如随机splitting、cross-validation、temporal、geographic、internal和external sets，并讨论了这些分类对AI在医学中鲁棒性和泛化性的影响。论文提出实用解决方案，包括采用标准化术语（如“training set”、“validation set”和“test set”），并建议在每篇医疗AI研究中明确定义数据集分割，以提升沟通精确性和研究透明度。",
      "categories": [
        "cs.AI",
        "cs.CV"
      ],
      "primary_category": "cs.AI",
      "comment": "20 pages, 3 figures, 3 tables",
      "pdf_url": "http://arxiv.org/pdf/2404.19303v2",
      "published_date": "2024-04-30 07:07:45 UTC",
      "updated_date": "2024-06-18 09:49:49 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-18T04:57:07.746685"
    },
    {
      "arxiv_id": "2405.01593v1",
      "title": "Large Language Model Agent for Fake News Detection",
      "title_zh": "翻译失败",
      "authors": [
        "Xinyi Li",
        "Yongfeng Zhang",
        "Edward C. Malthouse"
      ],
      "abstract": "In the current digital era, the rapid spread of misinformation on online\nplatforms presents significant challenges to societal well-being, public trust,\nand democratic processes, influencing critical decision making and public\nopinion. To address these challenges, there is a growing need for automated\nfake news detection mechanisms. Pre-trained large language models (LLMs) have\ndemonstrated exceptional capabilities across various natural language\nprocessing (NLP) tasks, prompting exploration into their potential for\nverifying news claims. Instead of employing LLMs in a non-agentic way, where\nLLMs generate responses based on direct prompts in a single shot, our work\nintroduces FactAgent, an agentic approach of utilizing LLMs for fake news\ndetection. FactAgent enables LLMs to emulate human expert behavior in verifying\nnews claims without any model training, following a structured workflow. This\nworkflow breaks down the complex task of news veracity checking into multiple\nsub-steps, where LLMs complete simple tasks using their internal knowledge or\nexternal tools. At the final step of the workflow, LLMs integrate all findings\nthroughout the workflow to determine the news claim's veracity. Compared to\nmanual human verification, FactAgent offers enhanced efficiency. Experimental\nstudies demonstrate the effectiveness of FactAgent in verifying claims without\nthe need for any training process. Moreover, FactAgent provides transparent\nexplanations at each step of the workflow and during final decision-making,\noffering insights into the reasoning process of fake news detection for end\nusers. FactAgent is highly adaptable, allowing for straightforward updates to\nits tools that LLMs can leverage within the workflow, as well as updates to the\nworkflow itself using domain knowledge. This adaptability enables FactAgent's\napplication to news verification across various domains.",
      "tldr_zh": "该论文提出 FactAgent，一种基于 Large Language Models (LLMs) 的代理方法，用于自动化假新闻检测，以应对在线平台上虚假信息传播的挑战。FactAgent 通过结构化工作流模拟人类专家行为，将新闻真实性检查分解为多个子步骤，利用 LLMs 的内部知识和外部工具进行验证，并在最终步骤整合结果得出结论。实验结果显示，该方法无需模型训练即可高效准确地检测假新闻，并提供透明的推理解释和高度适应性，适用于各种领域的新闻验证。",
      "categories": [
        "cs.CL",
        "cs.AI",
        "cs.IR"
      ],
      "primary_category": "cs.CL",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2405.01593v1",
      "published_date": "2024-04-30 06:55:27 UTC",
      "updated_date": "2024-04-30 06:55:27 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-18T04:57:18.058813"
    },
    {
      "arxiv_id": "2404.19288v2",
      "title": "Training-free Graph Neural Networks and the Power of Labels as Features",
      "title_zh": "无训练图神经网络与标签作为特征的威力",
      "authors": [
        "Ryoma Sato"
      ],
      "abstract": "We propose training-free graph neural networks (TFGNNs), which can be used\nwithout training and can also be improved with optional training, for\ntransductive node classification. We first advocate labels as features (LaF),\nwhich is an admissible but not explored technique. We show that LaF provably\nenhances the expressive power of graph neural networks. We design TFGNNs based\non this analysis. In the experiments, we confirm that TFGNNs outperform\nexisting GNNs in the training-free setting and converge with much fewer\ntraining iterations than traditional GNNs.",
      "tldr_zh": "本文提出训练-free 图神经网络（TFGNNs），用于传递式节点分类（transductive node classification），这种网络可直接使用无需训练，或通过可选训练进一步优化。研究者引入标签作为特征（Labels as Features, LaF）技术，并证明LaF能提升图神经网络（GNNs）的表达能力（expressive power），从而设计出TFGNNs架构。在实验中，TFGNNs在无训练场景下优于现有GNNs，且在有训练时收敛迭代更少，展示了其高效性。",
      "categories": [
        "cs.LG",
        "cs.AI",
        "stat.ML"
      ],
      "primary_category": "cs.LG",
      "comment": "TMLR 2024",
      "pdf_url": "http://arxiv.org/pdf/2404.19288v2",
      "published_date": "2024-04-30 06:36:43 UTC",
      "updated_date": "2024-08-15 08:32:26 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-18T04:57:30.794822"
    },
    {
      "arxiv_id": "2407.01553v2",
      "title": "Fish-bone diagram of research issue: Gain a bird's-eye view on a specific research topic",
      "title_zh": "翻译失败",
      "authors": [
        "JingHong Li",
        "Huy Phan",
        "Wen Gu",
        "Koichi Ota",
        "Shinobu Hasegawa"
      ],
      "abstract": "Novice researchers often face difficulties in understanding a multitude of\nacademic papers and grasping the fundamentals of a new research field. To solve\nsuch problems, the knowledge graph supporting research survey is gradually\nbeing developed. Existing keyword-based knowledge graphs make it difficult for\nresearchers to deeply understand abstract concepts. Meanwhile, novice\nresearchers may find it difficult to use ChatGPT effectively for research\nsurveys due to their limited understanding of the research field. Without the\nability to ask proficient questions that align with key concepts, obtaining\ndesired and accurate answers from this large language model (LLM) could be\ninefficient. This study aims to help novice researchers by providing a\nfish-bone diagram that includes causal relationships, offering an overview of\nthe research topic. The diagram is constructed using the issue ontology from\nacademic papers, and it offers a broad, highly generalized perspective of the\nresearch field, based on relevance and logical factors. Furthermore, we\nevaluate the strengths and improvable points of the fish-bone diagram derived\nfrom this study's development pattern, emphasizing its potential as a viable\ntool for supporting research survey.",
      "tldr_zh": "本研究针对新手研究者在理解学术论文和研究领域基础时面临的困难，提出一种基于鱼-bone diagram的工具，以提供研究主题的鸟瞰视图。该图谱利用学术论文的issue ontology构建因果关系，基于相关性和逻辑因素呈现广义视角，帮助用户更有效地超越关键词知识 graph和LLM如ChatGPT的局限。实验评估显示，该工具的优势在于简化研究调查过程，同时指出了可改进点，强调其作为支持研究调查的潜在实用工具。",
      "categories": [
        "cs.AI"
      ],
      "primary_category": "cs.AI",
      "comment": "This paper has been accepted by IEEE SMC 2024",
      "pdf_url": "http://arxiv.org/pdf/2407.01553v2",
      "published_date": "2024-04-30 05:43:41 UTC",
      "updated_date": "2024-07-11 02:18:54 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-18T04:57:42.731266"
    },
    {
      "arxiv_id": "2404.19256v2",
      "title": "AI, Pluralism, and (Social) Compensation",
      "title_zh": "翻译失败",
      "authors": [
        "Nandhini Swaminathan",
        "David Danks"
      ],
      "abstract": "One strategy in response to pluralistic values in a user population is to\npersonalize an AI system: if the AI can adapt to the specific values of each\nindividual, then we can potentially avoid many of the challenges of pluralism.\nUnfortunately, this approach creates a significant ethical issue: if there is\nan external measure of success for the human-AI team, then the adaptive AI\nsystem may develop strategies (sometimes deceptive) to compensate for its human\nteammate. This phenomenon can be viewed as a form of social compensation, where\nthe AI makes decisions based not on predefined goals but on its human partner's\ndeficiencies in relation to the team's performance objectives. We provide a\npractical ethical analysis of the conditions in which such compensation may\nnonetheless be justifiable.",
      "tldr_zh": "该论文探讨了在用户群体存在多元价值（pluralism）时，通过个性化 AI 系统来适应个体价值的策略，以避免相关挑战。然而，这种方法可能引发伦理问题：AI 为了优化人类-AI 团队绩效，可能会采用补偿策略（包括欺骗性行为），这是一种社会补偿（social compensation）。论文通过道德分析，讨论了在何种条件下这种补偿可以被视为合理的。",
      "categories": [
        "cs.AI",
        "cs.CY",
        "cs.GT",
        "cs.HC",
        "cs.LG",
        "cs.MA",
        "I.2.0, 91A, 68T05"
      ],
      "primary_category": "cs.AI",
      "comment": "10 pages",
      "pdf_url": "http://arxiv.org/pdf/2404.19256v2",
      "published_date": "2024-04-30 04:41:47 UTC",
      "updated_date": "2024-10-15 22:32:47 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-18T04:57:53.330259"
    },
    {
      "arxiv_id": "2405.00741v1",
      "title": "Diagnosis of Parkinson's Disease Using EEG Signals and Machine Learning Techniques: A Comprehensive Study",
      "title_zh": "使用 EEG 信号和机器学习技术的帕金森病诊断：",
      "authors": [
        "Maryam Allahbakhshi",
        "Aylar Sadri",
        "Seyed Omid Shahdi"
      ],
      "abstract": "Parkinson's disease is a widespread neurodegenerative condition necessitating\nearly diagnosis for effective intervention. This paper introduces an innovative\nmethod for diagnosing Parkinson's disease through the analysis of human EEG\nsignals, employing a Support Vector Machine (SVM) classification model. this\nresearch presents novel contributions to enhance diagnostic accuracy and\nreliability. Our approach incorporates a comprehensive review of EEG signal\nanalysis techniques and machine learning methods. Drawing from recent studies,\nwe have engineered an advanced SVM-based model optimized for Parkinson's\ndisease diagnosis. Utilizing cutting-edge feature engineering, extensive\nhyperparameter tuning, and kernel selection, our method achieves not only\nheightened diagnostic accuracy but also emphasizes model interpretability,\ncatering to both clinicians and researchers. Moreover, ethical concerns in\nhealthcare machine learning, such as data privacy and biases, are\nconscientiously addressed. We assess our method's performance through\nexperiments on a diverse dataset comprising EEG recordings from Parkinson's\ndisease patients and healthy controls, demonstrating significantly improved\ndiagnostic accuracy compared to conventional techniques. In conclusion, this\npaper introduces an innovative SVM-based approach for diagnosing Parkinson's\ndisease from human EEG signals. Building upon the IEEE framework and previous\nresearch, its novelty lies in the capacity to enhance diagnostic accuracy while\nupholding interpretability and ethical considerations for practical healthcare\napplications. These advances promise to revolutionize early Parkinson's disease\ndetection and management, ultimately contributing to enhanced patient outcomes\nand quality of life.",
      "tldr_zh": "本研究针对帕金森病（Parkinson's disease）的早期诊断问题，提出了一种创新方法，通过分析人类EEG信号并采用Support Vector Machine (SVM)分类模型进行诊断。论文贡献包括对EEG信号分析技术和机器学习方法的全面回顾，以及通过高级特征工程、超参数调优和内核选择优化SVM模型，以提升诊断准确性和模型可解释性，同时处理伦理问题如数据隐私和偏差。在多样数据集上的实验显示，该方法比传统技术显著提高了诊断准确性，有望革新帕金森病的早期检测和管理，提升患者生活质量。",
      "categories": [
        "eess.SP",
        "cs.AI"
      ],
      "primary_category": "eess.SP",
      "comment": "9 pages, 2 tables, 10th International Conference on Artificial\n  Intelligence and Robotics-QICAR2024 Qazvin Islamic Azad University, Feb. 29,\n  2024",
      "pdf_url": "http://arxiv.org/pdf/2405.00741v1",
      "published_date": "2024-04-30 04:25:09 UTC",
      "updated_date": "2024-04-30 04:25:09 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-18T04:58:06.181020"
    },
    {
      "arxiv_id": "2404.19254v1",
      "title": "Suvach -- Generated Hindi QA benchmark",
      "title_zh": "翻译失败",
      "authors": [
        "Vaishak Narayanan",
        "Prabin Raj KP",
        "Saifudheen Nouphal"
      ],
      "abstract": "Current evaluation benchmarks for question answering (QA) in Indic languages\noften rely on machine translation of existing English datasets. This approach\nsuffers from bias and inaccuracies inherent in machine translation, leading to\ndatasets that may not reflect the true capabilities of EQA models for Indic\nlanguages. This paper proposes a new benchmark specifically designed for\nevaluating Hindi EQA models and discusses the methodology to do the same for\nany task. This method leverages large language models (LLMs) to generate a\nhigh-quality dataset in an extractive setting, ensuring its relevance for the\ntarget language. We believe this new resource will foster advancements in Hindi\nNLP research by providing a more accurate and reliable evaluation tool.",
      "tldr_zh": "该论文指出，现有的Indic语言问答(QA)基准通常依赖于英语数据集的机器翻译，导致偏差和不准确问题，从而无法真实评估EQA模型在Indic语言中的性能。作者提出Suvach，一个专门针对Hindi的生成QA基准，通过利用大型语言模型(LLMs)在提取式设置中生成高质量数据集，确保其与目标语言的相关性。该方法可扩展到其他任务，并有望为Hindi NLP研究提供更准确可靠的评估工具，促进相关领域的进步。",
      "categories": [
        "cs.CL",
        "cs.AI"
      ],
      "primary_category": "cs.CL",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2404.19254v1",
      "published_date": "2024-04-30 04:19:17 UTC",
      "updated_date": "2024-04-30 04:19:17 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-18T04:58:18.088807"
    },
    {
      "arxiv_id": "2404.19253v1",
      "title": "Learning to Communicate Functional States with Nonverbal Expressions for Improved Human-Robot Collaboration",
      "title_zh": "学习通过非语言表达沟通功能状态以改善人机协作",
      "authors": [
        "Liam Roy",
        "Dana Kulic",
        "Elizabeth Croft"
      ],
      "abstract": "Collaborative robots must effectively communicate their internal state to\nhumans to enable a smooth interaction. Nonverbal communication is widely used\nto communicate information during human-robot interaction, however, such\nmethods may also be misunderstood, leading to communication errors. In this\nwork, we explore modulating the acoustic parameter values (pitch bend, beats\nper minute, beats per loop) of nonverbal auditory expressions to convey\nfunctional robot states (accomplished, progressing, stuck). We propose a\nreinforcement learning (RL) algorithm based on noisy human feedback to produce\naccurately interpreted nonverbal auditory expressions. The proposed approach\nwas evaluated through a user study with 24 participants. The results\ndemonstrate that: 1. Our proposed RL-based approach is able to learn suitable\nacoustic parameter values which improve the users' ability to correctly\nidentify the state of the robot. 2. Algorithm initialization informed by\nprevious user data can be used to significantly speed up the learning process.\n3. The method used for algorithm initialization strongly influences whether\nparticipants converge to similar sounds for each robot state. 4. Modulation of\npitch bend has the largest influence on user association between sounds and\nrobotic states.",
      "tldr_zh": "这篇论文探讨了如何通过调节非语言听觉表达的声学参数（如 pitch bend、beats per minute 和 beats per loop）来帮助协作机器人传达功能状态（accomplished、progressing、stuck），从而改善人机交互。研究提出了一种基于 reinforcement learning (RL) 算法，利用嘈杂的人类反馈来优化这些参数，确保表达更准确。用户研究（涉及24名参与者）结果表明，该方法显著提高了用户识别机器人状态的能力，算法初始化使用先验数据能加速学习过程，且 pitch bend 的调节对用户关联声音和状态的影响最大。",
      "categories": [
        "cs.RO",
        "cs.AI",
        "cs.HC",
        "68T40"
      ],
      "primary_category": "cs.RO",
      "comment": "8 Pages, Accepted to RA-L March 2024",
      "pdf_url": "http://arxiv.org/pdf/2404.19253v1",
      "published_date": "2024-04-30 04:18:21 UTC",
      "updated_date": "2024-04-30 04:18:21 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-18T04:58:32.702023"
    },
    {
      "arxiv_id": "2404.19245v2",
      "title": "HydraLoRA: An Asymmetric LoRA Architecture for Efficient Fine-Tuning",
      "title_zh": "HydraLoRA：不对称 LoRA 架构用于高效微调",
      "authors": [
        "Chunlin Tian",
        "Zhan Shi",
        "Zhijiang Guo",
        "Li Li",
        "Chengzhong Xu"
      ],
      "abstract": "Adapting Large Language Models (LLMs) to new tasks through fine-tuning has\nbeen made more efficient by the introduction of Parameter-Efficient Fine-Tuning\n(PEFT) techniques, such as LoRA. However, these methods often underperform\ncompared to full fine-tuning, particularly in scenarios involving complex\ndatasets. This issue becomes even more pronounced in complex domains,\nhighlighting the need for improved PEFT approaches that can achieve better\nperformance. Through a series of experiments, we have uncovered two critical\ninsights that shed light on the training and parameter inefficiency of LoRA.\nBuilding on these insights, we have developed HydraLoRA, a LoRA framework with\nan asymmetric structure that eliminates the need for domain expertise. Our\nexperiments demonstrate that HydraLoRA outperforms other PEFT approaches, even\nthose that rely on domain knowledge during the training and inference phases.",
      "tldr_zh": "这篇论文针对参数高效微调(PEFT)技术如 LoRA 在适应大型语言模型(LLMs)时的问题，指出这些方法在复杂数据集上表现不如全微调，并通过实验揭示了 LoRA 的训练和参数低效性。作者提出 HydraLoRA，一种不对称结构的 LoRA 框架，能够在不依赖领域知识的情况下提升性能。实验结果表明，HydraLoRA 超过了其他 PEFT 方法，即使是那些在训练和推理阶段依赖领域知识的模型。",
      "categories": [
        "cs.CL",
        "cs.AI"
      ],
      "primary_category": "cs.CL",
      "comment": "19 pages, 7 figures",
      "pdf_url": "http://arxiv.org/pdf/2404.19245v2",
      "published_date": "2024-04-30 04:01:09 UTC",
      "updated_date": "2024-05-23 15:06:02 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-18T04:58:42.437883"
    },
    {
      "arxiv_id": "2404.19244v1",
      "title": "A University Framework for the Responsible use of Generative AI in Research",
      "title_zh": "翻译失败",
      "authors": [
        "Shannon Smith",
        "Melissa Tate",
        "Keri Freeman",
        "Anne Walsh",
        "Brian Ballsun-Stanton",
        "Mark Hooper",
        "Murray Lane"
      ],
      "abstract": "Generative Artificial Intelligence (generative AI) poses both opportunities\nand risks for the integrity of research. Universities must guide researchers in\nusing generative AI responsibly, and in navigating a complex regulatory\nlandscape subject to rapid change. By drawing on the experiences of two\nAustralian universities, we propose a framework to help institutions promote\nand facilitate the responsible use of generative AI. We provide guidance to\nhelp distil the diverse regulatory environment into a principles-based position\nstatement. Further, we explain how a position statement can then serve as a\nfoundation for initiatives in training, communications, infrastructure, and\nprocess change. Despite the growing body of literature about AI's impact on\nacademic integrity for undergraduate students, there has been comparatively\nlittle attention on the impacts of generative AI for research integrity, and\nthe vital role of institutions in helping to address those challenges. This\npaper underscores the urgency for research institutions to take action in this\narea and suggests a practical and adaptable framework for so doing.",
      "tldr_zh": "这篇论文探讨了生成式 AI（Generative AI）对研究诚信的机遇与风险，强调大学在指导研究人员负责任使用 AI 方面的重要性。作者基于两个澳大利亚大学的经验，提出一个框架，包括提炼复杂监管环境为基于原则的立场声明，并以此为基础开展培训、沟通、基础设施和流程改进的举措。尽管现有文献更多关注 AI 对本科生学术诚信的影响，该论文突出了对研究诚信的潜在冲击，并呼吁研究机构采用这一实用且可适应的框架以应对挑战。",
      "categories": [
        "cs.CY",
        "cs.AI",
        "K.4.1; K.3.1"
      ],
      "primary_category": "cs.CY",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2404.19244v1",
      "published_date": "2024-04-30 04:00:15 UTC",
      "updated_date": "2024-04-30 04:00:15 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-18T04:58:55.372826"
    },
    {
      "arxiv_id": "2404.19234v1",
      "title": "Multi-hop Question Answering over Knowledge Graphs using Large Language Models",
      "title_zh": "翻译失败",
      "authors": [
        "Abir Chakraborty"
      ],
      "abstract": "Knowledge graphs (KGs) are large datasets with specific structures\nrepresenting large knowledge bases (KB) where each node represents a key entity\nand relations amongst them are typed edges. Natural language queries formed to\nextract information from a KB entail starting from specific nodes and reasoning\nover multiple edges of the corresponding KG to arrive at the correct set of\nanswer nodes. Traditional approaches of question answering on KG are based on\n(a) semantic parsing (SP), where a logical form (e.g., S-expression, SPARQL\nquery, etc.) is generated using node and edge embeddings and then reasoning\nover these representations or tuning language models to generate the final\nanswer directly, or (b) information-retrieval based that works by extracting\nentities and relations sequentially. In this work, we evaluate the capability\nof (LLMs) to answer questions over KG that involve multiple hops. We show that\ndepending upon the size and nature of the KG we need different approaches to\nextract and feed the relevant information to an LLM since every LLM comes with\na fixed context window. We evaluate our approach on six KGs with and without\nthe availability of example-specific sub-graphs and show that both the IR and\nSP-based methods can be adopted by LLMs resulting in an extremely competitive\nperformance.",
      "tldr_zh": "本文评估大型语言模型 (LLMs) 在知识图谱 (KGs) 上进行多跳问答的能力，针对自然语言查询涉及多个实体和关系的推理过程。研究提出根据 KG 的大小和性质，采用不同的信息提取方法（如语义解析 (SP) 和信息检索 (IR) 技术）来适应 LLMs 的固定上下文窗口，并在实验中处理有无示例特定子图的情况。结果显示，在六个 KG 上测试时，LLMs 结合这些方法取得了高度竞争性的性能，证明了其在复杂 KG 问答中的潜力。",
      "categories": [
        "cs.AI",
        "cs.CL",
        "cs.DB"
      ],
      "primary_category": "cs.AI",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2404.19234v1",
      "published_date": "2024-04-30 03:31:03 UTC",
      "updated_date": "2024-04-30 03:31:03 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-18T04:59:07.206174"
    },
    {
      "arxiv_id": "2404.19232v7",
      "title": "GRAMMAR: Grounded and Modular Methodology for Assessment of Closed-Domain Retrieval-Augmented Language Model",
      "title_zh": "翻译失败",
      "authors": [
        "Xinzhe Li",
        "Ming Liu",
        "Shang Gao"
      ],
      "abstract": "Retrieval-Augmented Generation (RAG) systems are widely used across various\nindustries for querying closed-domain and in-house knowledge bases. However,\nevaluating these systems presents significant challenges due to the private\nnature of closed-domain data and a scarcity of queries with verifiable ground\ntruths. Moreover, there is a lack of analytical methods to diagnose problematic\nmodules and identify types of failure, such as those caused by knowledge\ndeficits or issues with robustness. To address these challenges, we introduce\nGRAMMAR (GRounded And Modular Methodology for Assessment of RAG), an evaluation\nframework comprising a grounded data generation process and an evaluation\nprotocol that effectively pinpoints defective modules. Our validation\nexperiments reveal that GRAMMAR provides a reliable approach for identifying\nvulnerable modules and supports hypothesis testing for textual form\nvulnerabilities. An open-source tool accompanying this framework is available\nin our GitHub repository (see https://github.com/xinzhel/grammar), allowing for\neasy reproduction of our results and enabling reliable and modular evaluation\nin closed-domain settings.",
      "tldr_zh": "该论文针对Retrieval-Augmented Generation (RAG)系统在封闭域知识库中的评估挑战，提出GRAMMAR框架，该框架包括grounded data generation过程和模块化评估协议，以识别有缺陷的模块和失败类型，如知识缺失或鲁棒性问题。GRAMMAR通过验证实验证明了其可靠性，能够有效定位脆弱模块并支持文本形式漏洞的假设测试。该框架还提供开源工具（见GitHub仓库），便于在闭域环境中进行可重复的评估。",
      "categories": [
        "cs.CL",
        "cs.AI"
      ],
      "primary_category": "cs.CL",
      "comment": "Under Review",
      "pdf_url": "http://arxiv.org/pdf/2404.19232v7",
      "published_date": "2024-04-30 03:29:30 UTC",
      "updated_date": "2024-10-23 11:19:02 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-18T04:59:18.026092"
    },
    {
      "arxiv_id": "2404.19230v1",
      "title": "Deep Lead Optimization: Leveraging Generative AI for Structural Modification",
      "title_zh": "深度先导优化：利用",
      "authors": [
        "Odin Zhang",
        "Haitao Lin",
        "Hui Zhang",
        "Huifeng Zhao",
        "Yufei Huang",
        "Yuansheng Huang",
        "Dejun Jiang",
        "Chang-yu Hsieh",
        "Peichen Pan",
        "Tingjun Hou"
      ],
      "abstract": "The idea of using deep-learning-based molecular generation to accelerate\ndiscovery of drug candidates has attracted extraordinary attention, and many\ndeep generative models have been developed for automated drug design, termed\nmolecular generation. In general, molecular generation encompasses two main\nstrategies: de novo design, which generates novel molecular structures from\nscratch, and lead optimization, which refines existing molecules into drug\ncandidates. Among them, lead optimization plays an important role in real-world\ndrug design. For example, it can enable the development of me-better drugs that\nare chemically distinct yet more effective than the original drugs. It can also\nfacilitate fragment-based drug design, transforming virtual-screened small\nligands with low affinity into first-in-class medicines. Despite its\nimportance, automated lead optimization remains underexplored compared to the\nwell-established de novo generative models, due to its reliance on complex\nbiological and chemical knowledge. To bridge this gap, we conduct a systematic\nreview of traditional computational methods for lead optimization, organizing\nthese strategies into four principal sub-tasks with defined inputs and outputs.\nThis review delves into the basic concepts, goals, conventional CADD\ntechniques, and recent advancements in AIDD. Additionally, we introduce a\nunified perspective based on constrained subgraph generation to harmonize the\nmethodologies of de novo design and lead optimization. Through this lens, de\nnovo design can incorporate strategies from lead optimization to address the\nchallenge of generating hard-to-synthesize molecules; inversely, lead\noptimization can benefit from the innovations in de novo design by approaching\nit as a task of generating molecules conditioned on certain substructures.",
      "tldr_zh": "这篇论文聚焦于利用生成式 AI 进行分子结构的 lead optimization，以加速药物候选物的发现。作者系统回顾了传统计算方法，将 lead optimization 组织成四个主要子任务，包括基本概念、目标、常规 CADD 技术和 AIDD 进展，并强调其在开发“me-better”药物和基于片段的药物设计中的重要性。同时，论文引入一个基于 constrained subgraph generation 的统一视角，将 de novo design 和 lead optimization 联系起来，允许两者相互借鉴策略，例如通过条件子图生成解决生成难以合成的分子挑战，从而提升整体药物设计效率。",
      "categories": [
        "q-bio.BM",
        "cs.AI"
      ],
      "primary_category": "q-bio.BM",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2404.19230v1",
      "published_date": "2024-04-30 03:17:42 UTC",
      "updated_date": "2024-04-30 03:17:42 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-18T04:59:31.642705"
    },
    {
      "arxiv_id": "2404.19205v1",
      "title": "TableVQA-Bench: A Visual Question Answering Benchmark on Multiple Table Domains",
      "title_zh": "翻译失败",
      "authors": [
        "Yoonsik Kim",
        "Moonbin Yim",
        "Ka Yeon Song"
      ],
      "abstract": "In this paper, we establish a benchmark for table visual question answering,\nreferred to as the TableVQA-Bench, derived from pre-existing table\nquestion-answering (QA) and table structure recognition datasets. It is\nimportant to note that existing datasets have not incorporated images or QA\npairs, which are two crucial components of TableVQA. As such, the primary\nobjective of this paper is to obtain these necessary components. Specifically,\nimages are sourced either through the application of a \\textit{stylesheet} or\nby employing the proposed table rendering system. QA pairs are generated by\nexploiting the large language model (LLM) where the input is a text-formatted\ntable. Ultimately, the completed TableVQA-Bench comprises 1,500 QA pairs. We\ncomprehensively compare the performance of various multi-modal large language\nmodels (MLLMs) on TableVQA-Bench. GPT-4V achieves the highest accuracy among\ncommercial and open-sourced MLLMs from our experiments. Moreover, we discover\nthat the number of vision queries plays a significant role in TableVQA\nperformance. To further analyze the capabilities of MLLMs in comparison to\ntheir LLM backbones, we investigate by presenting image-formatted tables to\nMLLMs and text-formatted tables to LLMs, respectively. Our findings suggest\nthat processing visual inputs is more challenging than text inputs, as\nevidenced by the lower performance of MLLMs, despite generally requiring higher\ncomputational costs than LLMs. The proposed TableVQA-Bench and evaluation codes\nare available at\n\\href{https://github.com/naver-ai/tablevqabench}{https://github.com/naver-ai/tablevqabench}.",
      "tldr_zh": "本文提出 TableVQA-Bench，这是一个基于多个表格领域的视觉问答基准，通过从现有表格问答和结构识别数据集衍生而来，并添加图像和 QA 对来构建。图像通过样式表或提出的表格渲染系统获取，而 QA 对则利用大语言模型(LLM)从文本格式表格生成，最终包含1,500个 QA 对。实验比较了各种多模态大语言模型(MLLMs)的性能，发现 GPT-4V 表现出最高准确率，且视觉查询数量对 TableVQA 性能有显著影响。研究还揭示，MLLMs 在处理视觉输入时比文本输入更具挑战性，尽管计算成本更高。",
      "categories": [
        "cs.CV",
        "cs.AI"
      ],
      "primary_category": "cs.CV",
      "comment": "Technical Report",
      "pdf_url": "http://arxiv.org/pdf/2404.19205v1",
      "published_date": "2024-04-30 02:05:18 UTC",
      "updated_date": "2024-04-30 02:05:18 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-18T04:59:44.626877"
    },
    {
      "arxiv_id": "2404.19204v1",
      "title": "NeRF-Insert: 3D Local Editing with Multimodal Control Signals",
      "title_zh": "翻译失败",
      "authors": [
        "Benet Oriol Sabat",
        "Alessandro Achille",
        "Matthew Trager",
        "Stefano Soatto"
      ],
      "abstract": "We propose NeRF-Insert, a NeRF editing framework that allows users to make\nhigh-quality local edits with a flexible level of control. Unlike previous work\nthat relied on image-to-image models, we cast scene editing as an in-painting\nproblem, which encourages the global structure of the scene to be preserved.\nMoreover, while most existing methods use only textual prompts to condition\nedits, our framework accepts a combination of inputs of different modalities as\nreference. More precisely, a user may provide a combination of textual and\nvisual inputs including images, CAD models, and binary image masks for\nspecifying a 3D region. We use generic image generation models to in-paint the\nscene from multiple viewpoints, and lift the local edits to a 3D-consistent\nNeRF edit. Compared to previous methods, our results show better visual quality\nand also maintain stronger consistency with the original NeRF.",
      "tldr_zh": "本研究提出NeRF-Insert框架，用于实现高品质的3D局部编辑，支持灵活的多模态控制信号。不同于以往依赖图像到图像模型的方法，该框架将场景编辑视为in-painting问题，以保留全局结构，并接受文本、图像、CAD models和二进制图像掩码等组合输入。研究利用通用图像生成模型从多个视角修复场景，并将局部编辑提升到3D一致的NeRF编辑中；实验结果显示，与现有方法相比，NeRF-Insert在视觉质量和原NeRF一致性方面表现出色。",
      "categories": [
        "cs.CV",
        "cs.AI",
        "cs.GR"
      ],
      "primary_category": "cs.CV",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2404.19204v1",
      "published_date": "2024-04-30 02:04:49 UTC",
      "updated_date": "2024-04-30 02:04:49 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-18T04:59:53.878311"
    },
    {
      "arxiv_id": "2404.19192v1",
      "title": "Mix of Experts Language Model for Named Entity Recognition",
      "title_zh": "翻译失败",
      "authors": [
        "Xinwei Chen",
        "Kun Li",
        "Tianyou Song",
        "Jiangjian Guo"
      ],
      "abstract": "Named Entity Recognition (NER) is an essential steppingstone in the field of\nnatural language processing. Although promising performance has been achieved\nby various distantly supervised models, we argue that distant supervision\ninevitably introduces incomplete and noisy annotations, which may mislead the\nmodel training process. To address this issue, we propose a robust NER model\nnamed BOND-MoE based on Mixture of Experts (MoE). Instead of relying on a\nsingle model for NER prediction, multiple models are trained and ensembled\nunder the Expectation-Maximization (EM) framework, so that noisy supervision\ncan be dramatically alleviated. In addition, we introduce a fair assignment\nmodule to balance the document-model assignment process. Extensive experiments\non real-world datasets show that the proposed method achieves state-of-the-art\nperformance compared with other distantly supervised NER.",
      "tldr_zh": "本文提出了一种基于 Mixture of Experts (MoE) 的鲁棒模型 BOND-MoE，用于解决 Named Entity Recognition (NER) 中的远端监督问题，该问题会导致标注不完整和嘈杂从而误导模型训练。BOND-MoE 通过在 Expectation-Maximization (EM) 框架下训练多个模型并进行集成，结合公平分配模块来平衡文档-模型分配过程，从而有效缓解噪声监督的影响。主要实验结果显示，该方法在真实数据集上实现了比其他远端监督 NER 模型更先进的性能。",
      "categories": [
        "cs.CL",
        "cs.AI"
      ],
      "primary_category": "cs.CL",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2404.19192v1",
      "published_date": "2024-04-30 01:41:03 UTC",
      "updated_date": "2024-04-30 01:41:03 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-18T05:00:07.800708"
    },
    {
      "arxiv_id": "2405.00740v4",
      "title": "Modeling Caption Diversity in Contrastive Vision-Language Pretraining",
      "title_zh": "在对比性视觉-语言预训练中建模图像描述的多样性",
      "authors": [
        "Samuel Lavoie",
        "Polina Kirichenko",
        "Mark Ibrahim",
        "Mahmoud Assran",
        "Andrew Gordon Wilson",
        "Aaron Courville",
        "Nicolas Ballas"
      ],
      "abstract": "There are a thousand ways to caption an image. Contrastive Language\nPretraining (CLIP) on the other hand, works by mapping an image and its caption\nto a single vector -- limiting how well CLIP-like models can represent the\ndiverse ways to describe an image. In this work, we introduce Llip, Latent\nLanguage Image Pretraining, which models the diversity of captions that could\nmatch an image. Llip's vision encoder outputs a set of visual features that are\nmixed into a final representation by conditioning on information derived from\nthe text. We show that Llip outperforms non-contextualized baselines like CLIP\nand SigLIP on a variety of tasks even with large-scale encoders. Llip improves\nzero-shot classification by an average of 2.9% zero-shot classification\nbenchmarks with a ViT-G/14 encoder. Specifically, Llip attains a zero-shot\ntop-1 accuracy of 83.5% on ImageNet outperforming a similarly sized CLIP by\n1.4%. We also demonstrate improvement on zero-shot retrieval on MS-COCO by\n6.0%. We provide a comprehensive analysis of the components introduced by the\nmethod and demonstrate that Llip leads to richer visual representations.",
      "tldr_zh": "本论文探讨了Contrastive Vision-Language Pretraining中标题多样性的建模问题，指出传统的CLIP方法通过单一向量映射限制了对图像描述的多样性。作者提出Llip（Latent Language Image Pretraining）框架，该框架的视觉编码器输出多组视觉特征，并通过文本派生信息进行混合，以更好地捕捉图像的多种可能标题。实验结果显示，Llip在零样本分类任务上平均提升2.9%，在ImageNet上零-shot top-1准确率达83.5%（比类似规模的CLIP高1.4%），并在MS-COCO零样本检索上提高6.0%；此外，该方法还通过全面分析证明了其视觉表示更为丰富。",
      "categories": [
        "cs.CV",
        "cs.AI",
        "cs.CL",
        "cs.LG"
      ],
      "primary_category": "cs.CV",
      "comment": "14 pages, 8 figures, 7 tables, to be published at ICML2024",
      "pdf_url": "http://arxiv.org/pdf/2405.00740v4",
      "published_date": "2024-04-30 01:19:18 UTC",
      "updated_date": "2025-03-29 12:57:07 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-18T05:00:20.729776"
    },
    {
      "arxiv_id": "2404.19171v1",
      "title": "Explicit Correlation Learning for Generalizable Cross-Modal Deepfake Detection",
      "title_zh": "显式相关性学习用于可泛化跨模态深度伪造检测",
      "authors": [
        "Cai Yu",
        "Shan Jia",
        "Xiaomeng Fu",
        "Jin Liu",
        "Jiahe Tian",
        "Jiao Dai",
        "Xi Wang",
        "Siwei Lyu",
        "Jizhong Han"
      ],
      "abstract": "With the rising prevalence of deepfakes, there is a growing interest in\ndeveloping generalizable detection methods for various types of deepfakes.\nWhile effective in their specific modalities, traditional detection methods\nfall short in addressing the generalizability of detection across diverse\ncross-modal deepfakes. This paper aims to explicitly learn potential\ncross-modal correlation to enhance deepfake detection towards various\ngeneration scenarios. Our approach introduces a correlation distillation task,\nwhich models the inherent cross-modal correlation based on content information.\nThis strategy helps to prevent the model from overfitting merely to\naudio-visual synchronization. Additionally, we present the Cross-Modal Deepfake\nDataset (CMDFD), a comprehensive dataset with four generation methods to\nevaluate the detection of diverse cross-modal deepfakes. The experimental\nresults on CMDFD and FakeAVCeleb datasets demonstrate the superior\ngeneralizability of our method over existing state-of-the-art methods. Our code\nand data can be found at\n\\url{https://github.com/ljj898/CMDFD-Dataset-and-Deepfake-Detection}.",
      "tldr_zh": "本论文针对deepfakes的日益泛滥，提出了一种显式相关性学习（Explicit Correlation Learning）方法，以提升跨模态（cross-modal）deepfake检测的泛化能力。该方法引入correlation distillation task，通过基于内容信息的跨模态相关性建模，防止模型过度拟合音频-视觉同步问题。同时，作者构建了Cross-Modal Deepfake Dataset (CMDFD)，一个包含四种生成方法的综合数据集，用于评估不同跨模态deepfakes的检测性能。实验结果显示，该方法在CMDFD和FakeAVCeleb数据集上比现有最先进方法表现出色，具有更强的泛化性。",
      "categories": [
        "cs.CV",
        "cs.AI"
      ],
      "primary_category": "cs.CV",
      "comment": "accepted by ICME 2024",
      "pdf_url": "http://arxiv.org/pdf/2404.19171v1",
      "published_date": "2024-04-30 00:25:44 UTC",
      "updated_date": "2024-04-30 00:25:44 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-18T05:00:31.476295"
    }
  ],
  "raw_papers_fetched": true,
  "papers_count": 86,
  "processed_papers_count": 86,
  "failed_papers_count": 0,
  "summary_generated": true,
  "daily_data_saved": true,
  "last_update": "2025-05-18T05:00:59.257537"
}