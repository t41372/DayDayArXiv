[
  {
    "arxiv_id": "2506.23030v1",
    "title": "VisionScores -- A system-segmented image score dataset for deep learning tasks",
    "authors": [
      "Alejandro Romero Amezcua",
      "Mariano José Juan Rivera Meraz"
    ],
    "abstract": "VisionScores presents a novel proposal being the first system-segmented image score dataset, aiming to offer structure-rich, high information-density images for machine and deep learning tasks. Delimited to two-handed piano pieces, it was built to consider not only certain graphic similarity but also composition patterns, as this creative process is highly instrument-dependent. It provides two scenarios in relation to composer and composition type. The first, formed by 14k samples, considers works from different authors but the same composition type, specifically, Sonatinas. The latter, consisting of 10.8K samples, presents the opposite case, various composition types from the same author, being the one selected Franz Liszt. All of the 24.8k samples are formatted as grayscale jpg images of $128 \\times 512$ pixels. VisionScores supplies the users not only the formatted samples but the systems' order and pieces' metadata. Moreover, unsegmented full-page scores and the pre-formatted images are included for further analysis.",
    "categories": [
      "cs.CV",
      "cs.AI",
      "cs.LG",
      "cs.SD",
      "eess.AS"
    ],
    "primary_category": "cs.CV",
    "comment": "Comments: 5 pages, 3 figures. Accepted for presentation at the 2025 IEEE International Conference on Image Processing (ICIP). \\c{opyright} 2025 IEEE. Personal use of this material is permitted. Permission from IEEE must be obtained for any other use",
    "pdf_url": "https://arxiv.org/pdf/2506.23030v1",
    "published_date": "2025-06-28 22:29:23 UTC",
    "updated_date": "2025-06-28 22:29:23 UTC"
  },
  {
    "arxiv_id": "2506.23025v1",
    "title": "Spectra 1.1: Scaling Laws and Efficient Inference for Ternary Language Models",
    "authors": [
      "Tejas Vaidhya",
      "Ayush Kaushal",
      "Vineet Jain",
      "Francis Couture Harpin",
      "Prashant Shishodia",
      "Majid Behbahani",
      "Yuriy Nevmyvaka",
      "Irina Rish"
    ],
    "abstract": "Large language models (LLMs) are increasingly used across research and industry applications, yet their inference efficiency remains a significant challenge. As the computational power of modern GPU architectures continuously improves, their memory bandwidth and capacity have not scaled proportionally, creating a critical bottleneck during inference. To address this, we investigate ternary language models (TriLMs) that employ quantization-aware training to significantly reduce memory requirements. We first analyze the scalability of TriLMs by conducting a scaling law analysis, revealing that TriLMs benefit more from increasing training data than from scaling model parameters. Based on this observation, we introduce Spectra-1.1, an open suite of TriLMs trained on up to 1.2 trillion tokens, demonstrating sustained performance gains at scale. Furthermore, to improve inference efficiency, we propose novel 2-bit and 1.6-bit packing schemes for ternary weights, which demonstrate accelerated inference across various CPU architectures. Also, building on the 2-bit packing, we develop a GPU kernel called TriRun that accelerates end-to-end model inference by up to 5 times compared to floating-point baselines. To encourage further exploration and development of TriLMs, we will release the Spectra-1.1 suite and TriRun inference kernels. Overall, our work lays the foundation for building and deploying efficient LLMs, providing a valuable resource for the research community.",
    "categories": [
      "cs.LG",
      "cs.AI"
    ],
    "primary_category": "cs.LG",
    "comment": "",
    "pdf_url": "https://arxiv.org/pdf/2506.23025v1",
    "published_date": "2025-06-28 22:13:43 UTC",
    "updated_date": "2025-06-28 22:13:43 UTC"
  },
  {
    "arxiv_id": "2506.23024v1",
    "title": "BWLer: Barycentric Weight Layer Elucidates a Precision-Conditioning Tradeoff for PINNs",
    "authors": [
      "Jerry Liu",
      "Yasa Baig",
      "Denise Hui Jean Lee",
      "Rajat Vadiraj Dwaraknath",
      "Atri Rudra",
      "Chris Ré"
    ],
    "abstract": "Physics-informed neural networks (PINNs) offer a flexible way to solve partial differential equations (PDEs) with machine learning, yet they still fall well short of the machine-precision accuracy many scientific tasks demand. In this work, we investigate whether the precision ceiling comes from the ill-conditioning of the PDEs or from the typical multi-layer perceptron (MLP) architecture. We introduce the Barycentric Weight Layer (BWLer), which models the PDE solution through barycentric polynomial interpolation. A BWLer can be added on top of an existing MLP (a BWLer-hat) or replace it completely (explicit BWLer), cleanly separating how we represent the solution from how we take derivatives for the PDE loss. Using BWLer, we identify fundamental precision limitations within the MLP: on a simple 1-D interpolation task, even MLPs with O(1e5) parameters stall around 1e-8 RMSE -- about eight orders above float64 machine precision -- before any PDE terms are added. In PDE learning, adding a BWLer lifts this ceiling and exposes a tradeoff between achievable accuracy and the conditioning of the PDE loss. For linear PDEs we fully characterize this tradeoff with an explicit error decomposition and navigate it during training with spectral derivatives and preconditioning. Across five benchmark PDEs, adding a BWLer on top of an MLP improves RMSE by up to 30x for convection, 10x for reaction, and 1800x for wave equations while remaining compatible with first-order optimizers. Replacing the MLP entirely lets an explicit BWLer reach near-machine-precision on convection, reaction, and wave problems (up to 10 billion times better than prior results) and match the performance of standard PINNs on stiff Burgers' and irregular-geometry Poisson problems. Together, these findings point to a practical path for combining the flexibility of PINNs with the precision of classical spectral solvers.",
    "categories": [
      "cs.LG",
      "cs.AI",
      "math.NA"
    ],
    "primary_category": "cs.LG",
    "comment": "Workshop for the Theory of AI for Scientific Computing @ COLT 2025 (Best Paper). 39 pages, 24 figures",
    "pdf_url": "https://arxiv.org/pdf/2506.23024v1",
    "published_date": "2025-06-28 22:11:00 UTC",
    "updated_date": "2025-06-28 22:11:00 UTC"
  },
  {
    "arxiv_id": "2506.23023v1",
    "title": "Scenario-Based Hierarchical Reinforcement Learning for Automated Driving Decision Making",
    "authors": [
      "M. Youssef Abdelhamid",
      "Lennart Vater",
      "Zlatan Ajanovic"
    ],
    "abstract": "Developing decision-making algorithms for highly automated driving systems remains challenging, since these systems have to operate safely in an open and complex environments. Reinforcement Learning (RL) approaches can learn comprehensive decision policies directly from experience and already show promising results in simple driving tasks. However, current approaches fail to achieve generalizability for more complex driving tasks and lack learning efficiency. Therefore, we present Scenario-based Automated Driving Reinforcement Learning (SAD-RL), the first framework that integrates Reinforcement Learning (RL) of hierarchical policy in a scenario-based environment. A high-level policy selects maneuver templates that are evaluated and executed by a low-level control logic. The scenario-based environment allows to control the training experience for the agent and to explicitly introduce challenging, but rate situations into the training process. Our experiments show that an agent trained using the SAD-RL framework can achieve safe behaviour in easy as well as challenging situations efficiently. Our ablation studies confirmed that both HRL and scenario diversity are essential for achieving these results.",
    "categories": [
      "cs.RO",
      "cs.AI",
      "cs.LG"
    ],
    "primary_category": "cs.RO",
    "comment": "6 pages, 10 figures, submitted to a conference",
    "pdf_url": "https://arxiv.org/pdf/2506.23023v1",
    "published_date": "2025-06-28 21:55:59 UTC",
    "updated_date": "2025-06-28 21:55:59 UTC"
  },
  {
    "arxiv_id": "2507.02950v2",
    "title": "Evaluating AI Counseling in Japanese: Counselor, Client, and Evaluator Roles Assessed by Motivational Interviewing Criteria",
    "authors": [
      "Keita Kiuchi",
      "Yoshikazu Fujimoto",
      "Hideyuki Goto",
      "Tomonori Hosokawa",
      "Makoto Nishimura",
      "Yosuke Sato",
      "Izumi Sezai"
    ],
    "abstract": "This study provides the first comprehensive evaluation of large language model (LLM) performance across three counseling roles in Japanese-language therapeutic contexts. We simultaneously assessed counselor artificial intelligence (AI) systems (GPT-4-turbo with zeroshot prompting or Structured Multi-step Dialogue Prompts (SMDP), Claude-3-Opus-SMDP), client AI simulations, and evaluation AI systems (o3, Claude-3.7-Sonnet, Gemini-2.5-pro). Human experts (n = 15) with extensive counseling experience evaluated AI-generated dialogues using the Motivational Interviewing Treatment Integrity (MITI) Coding Manual 4.2.1.\n  Notably, SMDP implementation significantly enhanced counselor AI performance across all MITI global ratings compared with zeroshot prompting, with no significant differences between GPT-SMDP and Opus-SMDP. Evaluation AIs showed comparable performance to human raters for Cultivating Change Talk but systematically overestimated Softening Sustain Talk and the overall quality metrics. Model-specific biases emerged: Gemini emphasized power-sharing, o3 focused on technical proficiency, and Sonnet prioritized emotional expression. Client AI simulations exhibited a limited emotional range and unnaturally high compliance, indicating the need for enhanced realism.\n  These findings establish benchmarks for AI-assisted counseling in non-English contexts and identify critical areas for improvement through advanced prompt engineering, retrieval-augmented generation, and targeted fine-tuning, with important implications for developing culturally sensitive AI mental health tools.",
    "categories": [
      "cs.CL",
      "cs.AI",
      "cs.HC"
    ],
    "primary_category": "cs.CL",
    "comment": "70 pages, 0 figures, 9 tables; data and code at https://osf.io/p8c39/files/2e58c42f-a7ba-45f2-aa60-265e107e36db",
    "pdf_url": "https://arxiv.org/pdf/2507.02950v2",
    "published_date": "2025-06-28 21:50:29 UTC",
    "updated_date": "2025-07-08 06:16:17 UTC"
  },
  {
    "arxiv_id": "2507.02948v3",
    "title": "DriveMRP: Enhancing Vision-Language Models with Synthetic Motion Data for Motion Risk Prediction",
    "authors": [
      "Zhiyi Hou",
      "Enhui Ma",
      "Fang Li",
      "Zhiyi Lai",
      "Kalok Ho",
      "Zhanqian Wu",
      "Lijun Zhou",
      "Long Chen",
      "Chitian Sun",
      "Haiyang Sun",
      "Bing Wang",
      "Guang Chen",
      "Hangjun Ye",
      "Kaicheng Yu"
    ],
    "abstract": "Autonomous driving has seen significant progress, driven by extensive real-world data. However, in long-tail scenarios, accurately predicting the safety of the ego vehicle's future motion remains a major challenge due to uncertainties in dynamic environments and limitations in data coverage. In this work, we aim to explore whether it is possible to enhance the motion risk prediction capabilities of Vision-Language Models (VLM) by synthesizing high-risk motion data. Specifically, we introduce a Bird's-Eye View (BEV) based motion simulation method to model risks from three aspects: the ego-vehicle, other vehicles, and the environment. This allows us to synthesize plug-and-play, high-risk motion data suitable for VLM training, which we call DriveMRP-10K. Furthermore, we design a VLM-agnostic motion risk estimation framework, named DriveMRP-Agent. This framework incorporates a novel information injection strategy for global context, ego-vehicle perspective, and trajectory projection, enabling VLMs to effectively reason about the spatial relationships between motion waypoints and the environment. Extensive experiments demonstrate that by fine-tuning with DriveMRP-10K, our DriveMRP-Agent framework can significantly improve the motion risk prediction performance of multiple VLM baselines, with the accident recognition accuracy soaring from 27.13% to 88.03%. Moreover, when tested via zero-shot evaluation on an in-house real-world high-risk motion dataset, DriveMRP-Agent achieves a significant performance leap, boosting the accuracy from base_model's 29.42% to 68.50%, which showcases the strong generalization capabilities of our method in real-world scenarios.",
    "categories": [
      "cs.CV",
      "cs.AI",
      "cs.RO"
    ],
    "primary_category": "cs.CV",
    "comment": "12 pages, 4 figures. Code available at https://github.com/hzy138/DriveMRP",
    "pdf_url": "https://arxiv.org/pdf/2507.02948v3",
    "published_date": "2025-06-28 21:28:01 UTC",
    "updated_date": "2025-07-13 15:16:06 UTC"
  },
  {
    "arxiv_id": "2506.23014v1",
    "title": "Generating Privacy Stories From Software Documentation",
    "authors": [
      "Wilder Baldwin",
      "Shashank Chintakuntla",
      "Shreyah Parajuli",
      "Ali Pourghasemi",
      "Ryan Shanz",
      "Sepideh Ghanavati"
    ],
    "abstract": "Research shows that analysts and developers consider privacy as a security concept or as an afterthought, which may lead to non-compliance and violation of users' privacy. Most current approaches, however, focus on extracting legal requirements from the regulations and evaluating the compliance of software and processes with them. In this paper, we develop a novel approach based on chain-of-thought prompting (CoT), in-context-learning (ICL), and Large Language Models (LLMs) to extract privacy behaviors from various software documents prior to and during software development, and then generate privacy requirements in the format of user stories. Our results show that most commonly used LLMs, such as GPT-4o and Llama 3, can identify privacy behaviors and generate privacy user stories with F1 scores exceeding 0.8. We also show that the performance of these models could be improved through parameter-tuning. Our findings provide insight into using and optimizing LLMs for generating privacy requirements given software documents created prior to or throughout the software development lifecycle.",
    "categories": [
      "cs.SE",
      "cs.AI"
    ],
    "primary_category": "cs.SE",
    "comment": "Accepted to RENext!'25 at the 33rd IEEE International Requirements Engineering 2025 conference",
    "pdf_url": "https://arxiv.org/pdf/2506.23014v1",
    "published_date": "2025-06-28 20:55:21 UTC",
    "updated_date": "2025-06-28 20:55:21 UTC"
  },
  {
    "arxiv_id": "2507.16820v1",
    "title": "Disaster Informatics after the COVID-19 Pandemic: Bibliometric and Topic Analysis based on Large-scale Academic Literature",
    "authors": [
      "Ngan Tran",
      "Haihua Chen",
      "Ana Cleveland",
      "Yuhan Zhou"
    ],
    "abstract": "This study presents a comprehensive bibliometric and topic analysis of the disaster informatics literature published between January 2020 to September 2022. Leveraging a large-scale corpus and advanced techniques such as pre-trained language models and generative AI, we identify the most active countries, institutions, authors, collaboration networks, emergent topics, patterns among the most significant topics, and shifts in research priorities spurred by the COVID-19 pandemic. Our findings highlight (1) countries that were most impacted by the COVID-19 pandemic were also among the most active, with each country having specific research interests, (2) countries and institutions within the same region or share a common language tend to collaborate, (3) top active authors tend to form close partnerships with one or two key partners, (4) authors typically specialized in one or two specific topics, while institutions had more diverse interests across several topics, and (5) the COVID-19 pandemic has influenced research priorities in disaster informatics, placing greater emphasis on public health. We further demonstrate that the field is converging on multidimensional resilience strategies and cross-sectoral data-sharing collaborations or projects, reflecting a heightened awareness of global vulnerability and interdependency. Collecting and quality assurance strategies, data analytic practices, LLM-based topic extraction and summarization approaches, and result visualization tools can be applied to comparable datasets or solve similar analytic problems. By mapping out the trends in disaster informatics, our analysis offers strategic insights for policymakers, practitioners, and scholars aiming to enhance disaster informatics capacities in an increasingly uncertain and complex risk landscape.",
    "categories": [
      "cs.SI",
      "cs.AI",
      "cs.CL",
      "cs.DL"
    ],
    "primary_category": "cs.SI",
    "comment": "36 pages, 14 figures, 5 tables",
    "pdf_url": "https://arxiv.org/pdf/2507.16820v1",
    "published_date": "2025-06-28 20:30:36 UTC",
    "updated_date": "2025-06-28 20:30:36 UTC"
  },
  {
    "arxiv_id": "2507.01058v1",
    "title": "A Data Science Approach to Calcutta High Court Judgments: An Efficient LLM and RAG-powered Framework for Summarization and Similar Cases Retrieval",
    "authors": [
      "Puspendu Banerjee",
      "Aritra Mazumdar",
      "Wazib Ansar",
      "Saptarsi Goswami",
      "Amlan Chakrabarti"
    ],
    "abstract": "The judiciary, as one of democracy's three pillars, is dealing with a rising amount of legal issues, needing careful use of judicial resources. This research presents a complex framework that leverages Data Science methodologies, notably Large Language Models (LLM) and Retrieval-Augmented Generation (RAG) techniques, to improve the efficiency of analyzing Calcutta High Court verdicts. Our framework focuses on two key aspects: first, the creation of a robust summarization mechanism that distills complex legal texts into concise and coherent summaries; and second, the development of an intelligent system for retrieving similar cases, which will assist legal professionals in research and decision making. By fine-tuning the Pegasus model using case head note summaries, we achieve significant improvements in the summarization of legal cases. Our two-step summarizing technique preserves crucial legal contexts, allowing for the production of a comprehensive vector database for RAG. The RAG-powered framework efficiently retrieves similar cases in response to user queries, offering thorough overviews and summaries. This technique not only improves legal research efficiency, but it also helps legal professionals and students easily acquire and grasp key legal information, benefiting the overall legal scenario.",
    "categories": [
      "cs.IR",
      "cs.AI",
      "cs.LG"
    ],
    "primary_category": "cs.IR",
    "comment": "12 pages, 6 figures",
    "pdf_url": "https://arxiv.org/pdf/2507.01058v1",
    "published_date": "2025-06-28 20:24:34 UTC",
    "updated_date": "2025-06-28 20:24:34 UTC"
  },
  {
    "arxiv_id": "2506.22992v1",
    "title": "MARBLE: A Hard Benchmark for Multimodal Spatial Reasoning and Planning",
    "authors": [
      "Yulun Jiang",
      "Yekun Chai",
      "Maria Brbić",
      "Michael Moor"
    ],
    "abstract": "The ability to process information from multiple modalities and to reason through it step-by-step remains a critical challenge in advancing artificial intelligence. However, existing reasoning benchmarks focus on text-only reasoning, or employ multimodal questions that can be answered by directly retrieving information from a non-text modality. Thus, complex reasoning remains poorly understood in multimodal domains. Here, we present MARBLE, a challenging multimodal reasoning benchmark that is designed to scrutinize multimodal language models (MLLMs) in their ability to carefully reason step-by-step through complex multimodal problems and environments. MARBLE is composed of two highly challenging tasks, M-Portal and M-Cube, that require the crafting and understanding of multistep plans under spatial, visual, and physical constraints. We find that current MLLMs perform poorly on MARBLE -- all the 12 advanced models obtain near-random performance on M-Portal and 0% accuracy on M-Cube. Only in simplified subtasks some models outperform the random baseline, indicating that complex reasoning is still a challenge for existing MLLMs. Moreover, we show that perception remains a bottleneck, where MLLMs occasionally fail to extract information from the visual inputs. By shedding a light on the limitations of MLLMs, we hope that MARBLE will spur the development of the next generation of models with the ability to reason and plan across many, multimodal reasoning steps.",
    "categories": [
      "cs.AI",
      "cs.CL",
      "cs.CV"
    ],
    "primary_category": "cs.AI",
    "comment": "",
    "pdf_url": "https://arxiv.org/pdf/2506.22992v1",
    "published_date": "2025-06-28 19:44:32 UTC",
    "updated_date": "2025-06-28 19:44:32 UTC"
  },
  {
    "arxiv_id": "2506.22978v1",
    "title": "A Systematic Study of Compositional Syntactic Transformer Language Models",
    "authors": [
      "Yida Zhao",
      "Hao Xve",
      "Xiang Hu",
      "Kewei Tu"
    ],
    "abstract": "Syntactic language models (SLMs) enhance Transformers by incorporating syntactic biases through the modeling of linearized syntactic parse trees alongside surface sentences. This paper focuses on compositional SLMs that are based on constituency parse trees and contain explicit bottom-up composition of constituent representations. We identify key aspects of design choices in existing compositional SLMs and propose a unified framework encompassing both existing models and novel variants. We conduct a comprehensive empirical evaluation of all the variants in our framework across language modeling, syntactic generalization, summarization, dialogue, and inference efficiency. Based on the experimental results, we make multiple recommendations on the design of compositional SLMs. Our code is released at https://github.com/zhaoyd1/compositional_SLMs.",
    "categories": [
      "cs.CL",
      "cs.AI"
    ],
    "primary_category": "cs.CL",
    "comment": "",
    "pdf_url": "https://arxiv.org/pdf/2506.22978v1",
    "published_date": "2025-06-28 18:32:23 UTC",
    "updated_date": "2025-06-28 18:32:23 UTC"
  },
  {
    "arxiv_id": "2506.22968v2",
    "title": "Against 'softmaxing' culture",
    "authors": [
      "Daniel Mwesigwa"
    ],
    "abstract": "AI is flattening culture. Evaluations of \"culture\" are showing the myriad ways in which large AI models are homogenizing language and culture, averaging out rich linguistic differences into generic expressions. I call this phenomenon \"softmaxing culture,'' and it is one of the fundamental challenges facing AI evaluations today. Efforts to improve and strengthen evaluations of culture are central to the project of cultural alignment in large AI systems. This position paper argues that machine learning (ML) and human-computer interaction (HCI) approaches to evaluation are limited. I propose two key conceptual shifts. First, instead of asking \"what is culture?\" at the start of system evaluations, I propose beginning with the question: \"when is culture?\" Second, while I acknowledge the philosophical claim that cultural universals exist, the challenge is not simply to describe them, but to situate them in relation to their particulars. Taken together, these conceptual shifts invite evaluation approaches that move beyond technical requirements toward perspectives that are more responsive to the complexities of culture.",
    "categories": [
      "cs.HC",
      "cs.AI"
    ],
    "primary_category": "cs.HC",
    "comment": "7 pages",
    "pdf_url": "https://arxiv.org/pdf/2506.22968v2",
    "published_date": "2025-06-28 17:59:17 UTC",
    "updated_date": "2025-07-01 10:45:21 UTC"
  },
  {
    "arxiv_id": "2506.22957v2",
    "title": "Agent-to-Agent Theory of Mind: Testing Interlocutor Awareness among Large Language Models",
    "authors": [
      "Younwoo Choi",
      "Changling Li",
      "Yongjin Yang",
      "Zhijing Jin"
    ],
    "abstract": "As large language models (LLMs) are increasingly integrated into multi-agent and human-AI systems, understanding their awareness of both self-context and conversational partners is essential for ensuring reliable performance and robust safety. While prior work has extensively studied situational awareness which refers to an LLM's ability to recognize its operating phase and constraints, it has largely overlooked the complementary capacity to identify and adapt to the identity and characteristics of a dialogue partner. In this paper, we formalize this latter capability as interlocutor awareness and present the first systematic evaluation of its emergence in contemporary LLMs. We examine interlocutor inference across three dimensions-reasoning patterns, linguistic style, and alignment preferences-and show that LLMs reliably identify same-family peers and certain prominent model families, such as GPT and Claude. To demonstrate its practical significance, we develop three case studies in which interlocutor awareness both enhances multi-LLM collaboration through prompt adaptation and introduces new alignment and safety vulnerabilities, including reward-hacking behaviors and increased jailbreak susceptibility. Our findings highlight the dual promise and peril of identity-sensitive behavior in LLMs, underscoring the need for further understanding of interlocutor awareness and new safeguards in multi-agent deployments. Our code is open-sourced at https://github.com/younwoochoi/InterlocutorAwarenessLLM.",
    "categories": [
      "cs.CL",
      "cs.AI",
      "cs.CY",
      "cs.MA"
    ],
    "primary_category": "cs.CL",
    "comment": "",
    "pdf_url": "https://arxiv.org/pdf/2506.22957v2",
    "published_date": "2025-06-28 17:22:59 UTC",
    "updated_date": "2025-08-27 20:38:04 UTC"
  },
  {
    "arxiv_id": "2506.22949v1",
    "title": "A Study on Semi-Supervised Detection of DDoS Attacks under Class Imbalance",
    "authors": [
      "Ehsan Hallaji",
      "Vaishnavi Shanmugam",
      "Roozbeh Razavi-Far",
      "Mehrdad Saif"
    ],
    "abstract": "One of the most difficult challenges in cybersecurity is eliminating Distributed Denial of Service (DDoS) attacks. Automating this task using artificial intelligence is a complex process due to the inherent class imbalance and lack of sufficient labeled samples of real-world datasets. This research investigates the use of Semi-Supervised Learning (SSL) techniques to improve DDoS attack detection when data is imbalanced and partially labeled. In this process, 13 state-of-the-art SSL algorithms are evaluated for detecting DDoS attacks in several scenarios. We evaluate their practical efficacy and shortcomings, including the extent to which they work in extreme environments. The results will offer insight into designing intelligent Intrusion Detection Systems (IDSs) that are robust against class imbalance and handle partially labeled data.",
    "categories": [
      "cs.CR",
      "cs.AI",
      "cs.LG"
    ],
    "primary_category": "cs.CR",
    "comment": "Accepted for publication in IEEE CCECE 2025",
    "pdf_url": "https://arxiv.org/pdf/2506.22949v1",
    "published_date": "2025-06-28 16:47:39 UTC",
    "updated_date": "2025-06-28 16:47:39 UTC"
  },
  {
    "arxiv_id": "2506.22941v3",
    "title": "Positioning AI Tools to Support Online Harm Reduction Practice: Applications and Design Directions",
    "authors": [
      "Kaixuan Wang",
      "Jason T. Jacques",
      "Chenxin Diao",
      "Carl-Cyril J Dreue"
    ],
    "abstract": "Access to accurate and actionable harm reduction information can directly impact the health outcomes of People Who Use Drugs (PWUD), yet existing online channels often fail to meet their diverse and dynamic needs due to limitations in adaptability, accessibility, and the pervasive impact of stigma. Large Language Models (LLMs) present a novel opportunity to enhance information provision, but their application in such a high-stakes domain is under-explored and presents socio-technical challenges. This paper investigates how LLMs can be responsibly designed to support the information needs of PWUD. Through a qualitative workshop involving diverse stakeholder groups (academics, harm reduction practitioners, and an online community moderator), we explored LLM capabilities, identified potential use cases, and delineated core design considerations. Our findings reveal that while LLMs can address some existing information barriers (e.g., by offering responsive, multilingual, and potentially less stigmatising interactions), their effectiveness is contingent upon overcoming challenges related to ethical alignment with harm reduction principles, nuanced contextual understanding, effective communication, and clearly defined operational boundaries. We articulate design pathways emphasising collaborative co-design with experts and PWUD to develop LLM systems that are helpful, safe, and responsibly governed. This work contributes empirically grounded insights and actionable design considerations for the responsible development of LLMs as supportive tools within the harm reduction ecosystem.",
    "categories": [
      "cs.HC",
      "cs.AI"
    ],
    "primary_category": "cs.HC",
    "comment": "16 pages, 4 figures, with appendix",
    "pdf_url": "https://arxiv.org/pdf/2506.22941v3",
    "published_date": "2025-06-28 16:15:47 UTC",
    "updated_date": "2025-07-13 00:53:06 UTC"
  },
  {
    "arxiv_id": "2506.22929v1",
    "title": "Mathematical Computation on High-dimensional Data via Array Programming and Parallel Acceleration",
    "authors": [
      "Chen Zhang"
    ],
    "abstract": "While deep learning excels in natural image and language processing, its application to high-dimensional data faces computational challenges due to the dimensionality curse. Current large-scale data tools focus on business-oriented descriptive statistics, lacking mathematical statistics support for advanced analysis. We propose a parallel computation architecture based on space completeness, decomposing high-dimensional data into dimension-independent structures for distributed processing. This framework enables seamless integration of data mining and parallel-optimized machine learning methods, supporting scientific computations across diverse data types like medical and natural images within a unified system.",
    "categories": [
      "cs.LG",
      "cs.AI",
      "eess.IV",
      "eess.SP"
    ],
    "primary_category": "cs.LG",
    "comment": "",
    "pdf_url": "https://arxiv.org/pdf/2506.22929v1",
    "published_date": "2025-06-28 15:42:23 UTC",
    "updated_date": "2025-06-28 15:42:23 UTC"
  },
  {
    "arxiv_id": "2507.02946v1",
    "title": "Iterative Zoom-In: Temporal Interval Exploration for Long Video Understanding",
    "authors": [
      "Chenglin Li",
      "Qianglong Chen",
      "fengtao",
      "Yin Zhang"
    ],
    "abstract": "Multimodal Large Language Models (MLLMs) have shown strong performance in video understanding tasks. However, they continue to struggle with long-form videos because of an inefficient perception of temporal intervals. Unlike humans, who can dynamically adjust their temporal focus to locate query-relevant moments, current MLLMs often rely on dense, uniform sampling across the video timeline, leading to high memory consumption and a risk of missing crucial information. To address this challenge, we introduce Temporal Search, a training-free framework that enables MLLMs to explore temporal regions for improved long video understanding iteratively. TS is based on a key observation: the model's generation confidence across different temporal intervals is highly correlated with prediction accuracy. TS operates through two main iterative stages. First, the MLLM proposes a temporal interval that is likely to contain task-relevant information. Then, it samples a fixed number of frames from the interval, regardless of length, and feeds them into the model to produce a refined response and confidence score. TS refines the focus of the model by iteratively shifting attention to more fine-grained temporal intervals, improving its understanding of long videos. Additionally, keyframe-level descriptions are collected to facilitate cross-interval perception throughout the video. To further improve efficiency, we introduce TS-BFS, a best-first search strategy over a tree. Each node represents a candidate interval and is expanded via two methods: self-driven proposals and uniform partitioning. Nodes are scored based on confidence and self-evaluation, and the most promising one is selected for continued exploration.",
    "categories": [
      "cs.CV",
      "cs.AI"
    ],
    "primary_category": "cs.CV",
    "comment": "",
    "pdf_url": "https://arxiv.org/pdf/2507.02946v1",
    "published_date": "2025-06-28 15:24:05 UTC",
    "updated_date": "2025-06-28 15:24:05 UTC"
  },
  {
    "arxiv_id": "2507.02945v1",
    "title": "SPEAR: Structured Pruning for Spiking Neural Networks via Synaptic Operation Estimation and Reinforcement Learning",
    "authors": [
      "Hui Xie",
      "Yuhe Liu",
      "Shaoqi Yang",
      "Jinyang Guo",
      "Yufei Guo",
      "Yuqing Ma",
      "Jiaxin Chen",
      "Jiaheng Liu",
      "Xianglong Liu"
    ],
    "abstract": "While deep spiking neural networks (SNNs) demonstrate superior performance, their deployment on resource-constrained neuromorphic hardware still remains challenging. Network pruning offers a viable solution by reducing both parameters and synaptic operations (SynOps) to facilitate the edge deployment of SNNs, among which search-based pruning methods search for the SNNs structure after pruning. However, existing search-based methods fail to directly use SynOps as the constraint because it will dynamically change in the searching process, resulting in the final searched network violating the expected SynOps target. In this paper, we introduce a novel SNN pruning framework called SPEAR, which leverages reinforcement learning (RL) technique to directly use SynOps as the searching constraint. To avoid the violation of SynOps requirements, we first propose a SynOps prediction mechanism called LRE to accurately predict the final SynOps after search. Observing SynOps cannot be explicitly calculated and added to constrain the action in RL, we propose a novel reward called TAR to stabilize the searching. Extensive experiments show that our SPEAR framework can effectively compress SNN under specific SynOps constraint.",
    "categories": [
      "cs.NE",
      "cs.AI",
      "cs.LG"
    ],
    "primary_category": "cs.NE",
    "comment": "",
    "pdf_url": "https://arxiv.org/pdf/2507.02945v1",
    "published_date": "2025-06-28 15:21:05 UTC",
    "updated_date": "2025-06-28 15:21:05 UTC"
  },
  {
    "arxiv_id": "2506.22920v2",
    "title": "Improving Rationality in the Reasoning Process of Language Models through Self-playing Game",
    "authors": [
      "Pinzheng Wang",
      "Juntao Li",
      "Zecheng Tang",
      "Haijia Gui",
      "Min zhang"
    ],
    "abstract": "Large language models (LLMs) have demonstrated considerable reasoning abilities in various tasks such as mathematics and coding. However, recent studies indicate that even the best models lack true comprehension of their reasoning processes. In this paper, we explore how self-play can enhance the rationality of models in the reasoning process without supervision from humans or superior models. We design a Critic-Discernment Game(CDG) in which a prover first provides a solution to a given problem and is subsequently challenged by critiques of its solution. These critiques either aim to assist or mislead the prover. The objective of the prover is to maintain the correct answer when faced with misleading comments, while correcting errors in response to constructive feedback. Our experiments on tasks involving mathematical reasoning, stepwise error detection, self-correction, and long-chain reasoning demonstrate that CDG training can significantly improve the ability of well-aligned LLMs to comprehend their reasoning process.",
    "categories": [
      "cs.AI"
    ],
    "primary_category": "cs.AI",
    "comment": "Accepted by ICML 2025",
    "pdf_url": "https://arxiv.org/pdf/2506.22920v2",
    "published_date": "2025-06-28 15:11:23 UTC",
    "updated_date": "2025-07-06 13:58:07 UTC"
  },
  {
    "arxiv_id": "2506.22919v2",
    "title": "Hecto: Modular Sparse Experts for Adaptive and Interpretable Reasoning",
    "authors": [
      "Sanskar Pandey",
      "Ruhaan Chopra",
      "Saad Murtaza Bhat",
      "Ark Abhyudaya"
    ],
    "abstract": "Mixture-of-Experts (MoE) models enable conditional computation by routing inputs to specialized experts, but these experts rely on identical inductive biases, thus limiting representational diversity. This static computation pathway is inefficient for inputs that require different types of reasoning and limits specialization and interpretability. We propose Hecto, a lightweight MoE architecture that leverages architectural heterogeneity by combining a GRU expert for temporal reasoning and an FFNN expert for static abstraction under a sparse Top-1 gating mechanism. Evaluated on three reasoning benchmarks (AG News, SST-2, HotpotQA) and a regression task (STS-B), Hecto matches or closely trails homogeneous baselines in performance despite receiving isolated input representations, while achieving clear expert specialization, with each expert aligning to distinct reasoning types (temporal vs static). At larger batch sizes, Hecto exhibits improved performance, benefiting from relaxed computational constraints that allow its heterogeneous architecture to optimize more effectively. Ablation results isolate architectural diversity as the source of Hecto's stability and interpretability across diverse reasoning tasks. Overall, Hecto establishes itself as a new benchmark for conditional computation, offering a principled framework for specialized reasoning in low-resource regimes with its model strength derived from principled specialization.",
    "categories": [
      "cs.AI"
    ],
    "primary_category": "cs.AI",
    "comment": "",
    "pdf_url": "https://arxiv.org/pdf/2506.22919v2",
    "published_date": "2025-06-28 15:03:43 UTC",
    "updated_date": "2025-07-01 09:00:34 UTC"
  },
  {
    "arxiv_id": "2506.22911v1",
    "title": "Learning Truthful Mechanisms without Discretization",
    "authors": [
      "Yunxuan Ma",
      "Siqiang Wang",
      "Zhijian Duan",
      "Yukun Cheng",
      "Xiaotie Deng"
    ],
    "abstract": "This paper introduces TEDI (Truthful, Expressive, and Dimension-Insensitive approach), a discretization-free algorithm to learn truthful and utility-maximizing mechanisms. Existing learning-based approaches often rely on discretization of outcome spaces to ensure truthfulness, which leads to inefficiency with increasing problem size. To address this limitation, we formalize the concept of pricing rules, defined as functions that map outcomes to prices. Based on this concept, we propose a novel menu mechanism, which can be equivalent to a truthful direct mechanism under specific conditions. The core idea of TEDI lies in its parameterization of pricing rules using Partial GroupMax Network, a new network architecture designed to universally approximate partial convex functions. To learn optimal pricing rules, we develop novel training techniques, including covariance trick and continuous sampling, to derive unbiased gradient estimators compatible with first-order optimization. Theoretical analysis establishes that TEDI guarantees truthfulness, full expressiveness, and dimension-insensitivity. Experimental evaluation in the studied auction setting demonstrates that TEDI achieves strong performance, competitive with or exceeding state-of-the-art methods.\n  This work presents the first approaches to learn truthful mechanisms without outcome discretization, thereby enhancing algorithmic efficiency. The proposed concepts, network architecture, and learning techniques might offer potential value and provide new insights for automated mechanism design and differentiable economics.",
    "categories": [
      "cs.GT",
      "cs.AI",
      "cs.LG"
    ],
    "primary_category": "cs.GT",
    "comment": "66 pages",
    "pdf_url": "https://arxiv.org/pdf/2506.22911v1",
    "published_date": "2025-06-28 14:50:29 UTC",
    "updated_date": "2025-06-28 14:50:29 UTC"
  },
  {
    "arxiv_id": "2506.22901v1",
    "title": "Missing-Modality-Aware Graph Neural Network for Cancer Classification",
    "authors": [
      "Sina Tabakhi",
      "Haiping Lu"
    ],
    "abstract": "A key challenge in learning from multimodal biological data is missing modalities, where all data from some modalities are missing for some patients. Current fusion methods address this by excluding patients with missing modalities, imputing missing modalities, or making predictions directly with partial modalities. However, they often struggle with diverse missing-modality patterns and the exponential growth of the number of such patterns as the number of modalities increases. To address these limitations, we propose MAGNET (Missing-modality-Aware Graph neural NETwork) for direct prediction with partial modalities, which introduces a patient-modality multi-head attention mechanism to fuse lower-dimensional modality embeddings based on their importance and missingness. MAGNET's complexity increases linearly with the number of modalities while adapting to missing-pattern variability. To generate predictions, MAGNET further constructs a patient graph with fused multimodal embeddings as node features and the connectivity determined by the modality missingness, followed by a conventional graph neural network. Experiments on three public multiomics datasets for cancer classification, with real-world instead of artificial missingness, show that MAGNET outperforms the state-of-the-art fusion methods. The data and code are available at https://github.com/SinaTabakhi/MAGNET.",
    "categories": [
      "cs.LG",
      "cs.AI",
      "q-bio.BM",
      "q-bio.GN"
    ],
    "primary_category": "cs.LG",
    "comment": "15 pages, 7 figures",
    "pdf_url": "https://arxiv.org/pdf/2506.22901v1",
    "published_date": "2025-06-28 14:31:00 UTC",
    "updated_date": "2025-06-28 14:31:00 UTC"
  },
  {
    "arxiv_id": "2506.22895v2",
    "title": "Interpretable Time Series Autoregression for Periodicity Quantification",
    "authors": [
      "Xinyu Chen",
      "Vassilis Digalakis",
      "Lijun Ding",
      "Dingyi Zhuang",
      "Jinhua Zhao"
    ],
    "abstract": "Time series autoregression (AR) is a classical tool for modeling auto-correlations and periodic structures in real-world systems. We revisit this model from an interpretable machine learning perspective by introducing sparse autoregression (SAR), where $\\ell_0$-norm constraints are used to isolate dominant periodicities. We formulate exact mixed-integer optimization (MIO) approaches for both stationary and non-stationary settings and introduce two scalable extensions: a decision variable pruning (DVP) strategy for temporally-varying SAR (TV-SAR), and a two-stage optimization scheme for spatially- and temporally-varying SAR (STV-SAR). These models enable scalable inference on real-world spatiotemporal datasets. We validate our framework on large-scale mobility and climate time series. On NYC ridesharing data, TV-SAR reveals interpretable daily and weekly cycles as well as long-term shifts due to COVID-19. On climate datasets, STV-SAR uncovers the evolving spatial structure of temperature and precipitation seasonality across four decades in North America and detects global sea surface temperature dynamics, including El Niño. Together, our results demonstrate the interpretability, flexibility, and scalability of sparse autoregression for periodicity quantification in complex time series.",
    "categories": [
      "cs.LG",
      "cs.AI"
    ],
    "primary_category": "cs.LG",
    "comment": "",
    "pdf_url": "https://arxiv.org/pdf/2506.22895v2",
    "published_date": "2025-06-28 14:17:11 UTC",
    "updated_date": "2025-07-13 21:53:21 UTC"
  },
  {
    "arxiv_id": "2506.22893v1",
    "title": "Agentic Enterprise: AI-Centric User to User-Centric AI",
    "authors": [
      "Arpit Narechania",
      "Alex Endert",
      "Atanu R Sinha"
    ],
    "abstract": "After a very long winter, the Artificial Intelligence (AI) spring is here. Or, so it seems over the last three years. AI has the potential to impact many areas of human life - personal, social, health, education, professional. In this paper, we take a closer look at the potential of AI for Enterprises, where decision-making plays a crucial and repeated role across functions, tasks, and operations. We consider Agents imbued with AI as means to increase decision-productivity of enterprises. We highlight six tenets for Agentic success in enterprises, by drawing attention to what the current, AI-Centric User paradigm misses, in the face of persistent needs of and usefulness for Enterprise Decision-Making. In underscoring a shift to User-Centric AI, we offer six tenets and promote market mechanisms for platforms, aligning the design of AI and its delivery by Agents to the cause of enterprise users.",
    "categories": [
      "cs.AI",
      "cs.HC"
    ],
    "primary_category": "cs.AI",
    "comment": "12 pages, 1 figure, 2 sidebars; Preprint",
    "pdf_url": "https://arxiv.org/pdf/2506.22893v1",
    "published_date": "2025-06-28 14:05:59 UTC",
    "updated_date": "2025-06-28 14:05:59 UTC"
  },
  {
    "arxiv_id": "2507.00070v1",
    "title": "An efficient plant disease detection using transfer learning approach",
    "authors": [
      "Bosubabu Sambana",
      "Hillary Sunday Nnadi",
      "Mohd Anas Wajid",
      "Nwosu Ogochukwu Fidelia",
      "Claudia Camacho-Zuñiga",
      "Henry Dozie Ajuzie",
      "Edeh Michael Onyema"
    ],
    "abstract": "Plant diseases pose significant challenges to farmers and the agricultural sector at large. However, early detection of plant diseases is crucial to mitigating their effects and preventing widespread damage, as outbreaks can severely impact the productivity and quality of crops. With advancements in technology, there are increasing opportunities for automating the monitoring and detection of disease outbreaks in plants. This study proposed a system designed to identify and monitor plant diseases using a transfer learning approach. Specifically, the study utilizes YOLOv7 and YOLOv8, two state-ofthe-art models in the field of object detection. By fine-tuning these models on a dataset of plant leaf images, the system is able to accurately detect the presence of Bacteria, Fungi and Viral diseases such as Powdery Mildew, Angular Leaf Spot, Early blight and Tomato mosaic virus. The model's performance was evaluated using several metrics, including mean Average Precision (mAP), F1-score, Precision, and Recall, yielding values of 91.05, 89.40, 91.22, and 87.66, respectively. The result demonstrates the superior effectiveness and efficiency of YOLOv8 compared to other object detection methods, highlighting its potential for use in modern agricultural practices. The approach provides a scalable, automated solution for early any plant disease detection, contributing to enhanced crop yield, reduced reliance on manual monitoring, and supporting sustainable agricultural practices.",
    "categories": [
      "cs.CV",
      "cs.AI"
    ],
    "primary_category": "cs.CV",
    "comment": "15 pages , 4 figures. Scientific Reports 2025",
    "pdf_url": "https://arxiv.org/pdf/2507.00070v1",
    "published_date": "2025-06-28 13:47:27 UTC",
    "updated_date": "2025-06-28 13:47:27 UTC"
  },
  {
    "arxiv_id": "2506.22884v1",
    "title": "Performance Measurements in the AI-Centric Computing Continuum Systems",
    "authors": [
      "Praveen Kumar Donta",
      "Qiyang Zhang",
      "Schahram Dustdar"
    ],
    "abstract": "Over the Eight decades, computing paradigms have shifted from large, centralized systems to compact, distributed architectures, leading to the rise of the Distributed Computing Continuum (DCC). In this model, multiple layers such as cloud, edge, Internet of Things (IoT), and mobile platforms work together to support a wide range of applications. Recently, the emergence of Generative AI and large language models has further intensified the demand for computational resources across this continuum. Although traditional performance metrics have provided a solid foundation, they need to be revisited and expanded to keep pace with changing computational demands and application requirements. Accurate performance measurements benefit both system designers and users by supporting improvements in efficiency and promoting alignment with system goals. In this context, we review commonly used metrics in DCC and IoT environments. We also discuss emerging performance dimensions that address evolving computing needs, such as sustainability, energy efficiency, and system observability. We also outline criteria and considerations for selecting appropriate metrics, aiming to inspire future research and development in this critical area.",
    "categories": [
      "cs.DC",
      "cs.AI",
      "cs.ET",
      "cs.NI",
      "eess.SY"
    ],
    "primary_category": "cs.DC",
    "comment": "",
    "pdf_url": "https://arxiv.org/pdf/2506.22884v1",
    "published_date": "2025-06-28 13:46:07 UTC",
    "updated_date": "2025-06-28 13:46:07 UTC"
  },
  {
    "arxiv_id": "2506.22880v1",
    "title": "Decoupled Seg Tokens Make Stronger Reasoning Video Segmenter and Grounder",
    "authors": [
      "Dang Jisheng",
      "Wu Xudong",
      "Wang Bimei",
      "Lv Ning",
      "Chen Jiayu",
      "Jingwen Zhao",
      "Yichu liu",
      "Jizhao Liu",
      "Juncheng Li",
      "Teng Wang"
    ],
    "abstract": "Existing video segmenter and grounder approaches, exemplified by Sa2VA, directly fuse features within segmentation models. This often results in an undesirable entanglement of dynamic visual information and static semantics, thereby degrading segmentation accuracy. To systematically mitigate this issue, we propose DeSa2VA, a decoupling-enhanced prompting scheme integrating text pre-training and a linear decoupling module to address the information processing limitations inherent in SAM-2. Specifically, first, we devise a pre-training paradigm that converts textual ground-truth labels into point-level prompts while generating corresponding text masks. These masks are refined through a hybrid loss function to strengthen the model's semantic grounding capabilities. Next, we employ linear projection to disentangle hidden states that generated by a large language model into distinct textual and visual feature subspaces. Finally, a dynamic mask fusion strategy synergistically combines these decoupled features through triple supervision from predicted text/visual masks and ground-truth annotations. Extensive experiments demonstrate state-of-the-art performance across diverse tasks, including image segmentation, image question answering, video segmentation, and video question answering. Our codes are available at https://github.com/longmalongma/DeSa2VA.",
    "categories": [
      "cs.CV",
      "cs.AI"
    ],
    "primary_category": "cs.CV",
    "comment": "",
    "pdf_url": "https://arxiv.org/pdf/2506.22880v1",
    "published_date": "2025-06-28 13:30:36 UTC",
    "updated_date": "2025-06-28 13:30:36 UTC"
  },
  {
    "arxiv_id": "2506.22868v1",
    "title": "STR-Match: Matching SpatioTemporal Relevance Score for Training-Free Video Editing",
    "authors": [
      "Junsung Lee",
      "Junoh Kang",
      "Bohyung Han"
    ],
    "abstract": "Previous text-guided video editing methods often suffer from temporal inconsistency, motion distortion, and-most notably-limited domain transformation. We attribute these limitations to insufficient modeling of spatiotemporal pixel relevance during the editing process. To address this, we propose STR-Match, a training-free video editing algorithm that produces visually appealing and spatiotemporally coherent videos through latent optimization guided by our novel STR score. The score captures spatiotemporal pixel relevance across adjacent frames by leveraging 2D spatial attention and 1D temporal modules in text-to-video (T2V) diffusion models, without the overhead of computationally expensive 3D attention mechanisms. Integrated into a latent optimization framework with a latent mask, STR-Match generates temporally consistent and visually faithful videos, maintaining strong performance even under significant domain transformations while preserving key visual attributes of the source. Extensive experiments demonstrate that STR-Match consistently outperforms existing methods in both visual quality and spatiotemporal consistency.",
    "categories": [
      "cs.CV",
      "cs.AI"
    ],
    "primary_category": "cs.CV",
    "comment": "15 pages, 9 figures, 3 tables",
    "pdf_url": "https://arxiv.org/pdf/2506.22868v1",
    "published_date": "2025-06-28 12:36:19 UTC",
    "updated_date": "2025-06-28 12:36:19 UTC"
  },
  {
    "arxiv_id": "2506.22866v1",
    "title": "Region-Aware CAM: High-Resolution Weakly-Supervised Defect Segmentation via Salient Region Perception",
    "authors": [
      "Hang-Cheng Dong",
      "Lu Zou",
      "Bingguo Liu",
      "Dong Ye",
      "Guodong Liu"
    ],
    "abstract": "Surface defect detection plays a critical role in industrial quality inspection. Recent advances in artificial intelligence have significantly enhanced the automation level of detection processes. However, conventional semantic segmentation and object detection models heavily rely on large-scale annotated datasets, which conflicts with the practical requirements of defect detection tasks. This paper proposes a novel weakly supervised semantic segmentation framework comprising two key components: a region-aware class activation map (CAM) and pseudo-label training. To address the limitations of existing CAM methods, especially low-resolution thermal maps, and insufficient detail preservation, we introduce filtering-guided backpropagation (FGBP), which refines target regions by filtering gradient magnitudes to identify areas with higher relevance to defects. Building upon this, we further develop a region-aware weighted module to enhance spatial precision. Finally, pseudo-label segmentation is implemented to refine the model's performance iteratively. Comprehensive experiments on industrial defect datasets demonstrate the superiority of our method. The proposed framework effectively bridges the gap between weakly supervised learning and high-precision defect segmentation, offering a practical solution for resource-constrained industrial scenarios.",
    "categories": [
      "cs.CV",
      "cs.AI"
    ],
    "primary_category": "cs.CV",
    "comment": "",
    "pdf_url": "https://arxiv.org/pdf/2506.22866v1",
    "published_date": "2025-06-28 12:24:45 UTC",
    "updated_date": "2025-06-28 12:24:45 UTC"
  },
  {
    "arxiv_id": "2506.22865v1",
    "title": "ReasonBridge: Efficient Reasoning Transfer from Closed to Open-Source Language Models",
    "authors": [
      "Ziqi Zhong",
      "Xunzhu Tang"
    ],
    "abstract": "Recent advancements in Large Language Models (LLMs) have revealed a significant performance gap between closed-source and open-source models, particularly in tasks requiring complex reasoning and precise instruction following. This paper introduces ReasonBridge, a methodology that efficiently transfers reasoning capabilities from powerful closed-source to open-source models through a novel hierarchical knowledge distillation framework. We develop a tailored dataset Reason1K with only 1,000 carefully curated reasoning traces emphasizing difficulty, diversity, and quality. These traces are filtered from across multiple domains using a structured multi-criteria selection algorithm. Our transfer learning approach incorporates: (1) a hierarchical distillation process capturing both strategic abstraction and tactical implementation patterns, (2) a sparse reasoning-focused adapter architecture requiring only 0.3% additional trainable parameters, and (3) a test-time compute scaling mechanism using guided inference interventions. Comprehensive evaluations demonstrate that ReasonBridge improves reasoning capabilities in open-source models by up to 23% on benchmark tasks, significantly narrowing the gap with closed-source models. Notably, the enhanced Qwen2.5-14B outperforms Claude-Sonnet3.5 on MATH500 and matches its performance on competition-level AIME problems. Our methodology generalizes effectively across diverse reasoning domains and model architectures, establishing a sample-efficient approach to reasoning enhancement for instruction following.",
    "categories": [
      "cs.AI"
    ],
    "primary_category": "cs.AI",
    "comment": "",
    "pdf_url": "https://arxiv.org/pdf/2506.22865v1",
    "published_date": "2025-06-28 12:22:55 UTC",
    "updated_date": "2025-06-28 12:22:55 UTC"
  },
  {
    "arxiv_id": "2506.22864v1",
    "title": "Mask-aware Text-to-Image Retrieval: Referring Expression Segmentation Meets Cross-modal Retrieval",
    "authors": [
      "Li-Cheng Shen",
      "Jih-Kang Hsieh",
      "Wei-Hua Li",
      "Chu-Song Chen"
    ],
    "abstract": "Text-to-image retrieval (TIR) aims to find relevant images based on a textual query, but existing approaches are primarily based on whole-image captions and lack interpretability. Meanwhile, referring expression segmentation (RES) enables precise object localization based on natural language descriptions but is computationally expensive when applied across large image collections. To bridge this gap, we introduce Mask-aware TIR (MaTIR), a new task that unifies TIR and RES, requiring both efficient image search and accurate object segmentation. To address this task, we propose a two-stage framework, comprising a first stage for segmentation-aware image retrieval and a second stage for reranking and object grounding with a multimodal large language model (MLLM). We leverage SAM 2 to generate object masks and Alpha-CLIP to extract region-level embeddings offline at first, enabling effective and scalable online retrieval. Secondly, MLLM is used to refine retrieval rankings and generate bounding boxes, which are matched to segmentation masks. We evaluate our approach on COCO and D$^3$ datasets, demonstrating significant improvements in both retrieval accuracy and segmentation quality over previous methods.",
    "categories": [
      "cs.CV",
      "cs.AI",
      "cs.CL"
    ],
    "primary_category": "cs.CV",
    "comment": "ICMR 2025",
    "pdf_url": "https://arxiv.org/pdf/2506.22864v1",
    "published_date": "2025-06-28 12:19:49 UTC",
    "updated_date": "2025-06-28 12:19:49 UTC"
  },
  {
    "arxiv_id": "2507.00068v1",
    "title": "MANTA: Cross-Modal Semantic Alignment and Information-Theoretic Optimization for Long-form Multimodal Understanding",
    "authors": [
      "Ziqi Zhong",
      "Daniel Tang"
    ],
    "abstract": "While multi-modal learning has advanced significantly, current approaches often treat modalities separately, creating inconsistencies in representation and reasoning. We introduce MANTA (Multi-modal Abstraction and Normalization via Textual Alignment), a theoretically-grounded framework that unifies visual and auditory inputs into a structured textual space for seamless processing with large language models. MANTA addresses four key challenges: (1) semantic alignment across modalities with information-theoretic optimization, (2) adaptive temporal synchronization for varying information densities, (3) hierarchical content representation for multi-scale understanding, and (4) context-aware retrieval of sparse information from long sequences. We formalize our approach within a rigorous mathematical framework, proving its optimality for context selection under token constraints. Extensive experiments on the challenging task of Long Video Question Answering show that MANTA improves state-of-the-art models by up to 22.6% in overall accuracy, with particularly significant gains (27.3%) on videos exceeding 30 minutes. Additionally, we demonstrate MANTA's superiority on temporal reasoning tasks (23.8% improvement) and cross-modal understanding (25.1% improvement). Our framework introduces novel density estimation techniques for redundancy minimization while preserving rare signals, establishing new foundations for unifying multimodal representations through structured text.",
    "categories": [
      "cs.CV",
      "cs.AI",
      "cs.CL"
    ],
    "primary_category": "cs.CV",
    "comment": "",
    "pdf_url": "https://arxiv.org/pdf/2507.00068v1",
    "published_date": "2025-06-28 12:12:06 UTC",
    "updated_date": "2025-06-28 12:12:06 UTC"
  },
  {
    "arxiv_id": "2506.22853v2",
    "title": "DICE-BENCH: Evaluating the Tool-Use Capabilities of Large Language Models in Multi-Round, Multi-Party Dialogues",
    "authors": [
      "Kyochul Jang",
      "Donghyeon Lee",
      "Kyusik Kim",
      "Dongseok Heo",
      "Taewhoo Lee",
      "Woojeong Kim",
      "Bongwon Suh"
    ],
    "abstract": "Existing function-calling benchmarks focus on single-turn interactions. However, they overlook the complexity of real-world scenarios. To quantify how existing benchmarks address practical applications, we introduce DICE-SCORE, a metric that evaluates the dispersion of tool-related information such as function name and parameter values throughout the dialogue. Analyzing existing benchmarks through DICE-SCORE reveals notably low scores, highlighting the need for more realistic scenarios. To address this gap, we present DICE-BENCH, a framework that constructs practical function-calling datasets by synthesizing conversations through a tool graph that maintains dependencies across rounds and a multi-agent system with distinct personas to enhance dialogue naturalness. The final dataset comprises 1,607 high-DICE-SCORE instances. Our experiments on 19 LLMs with DICE-BENCH show that significant advances are still required before such models can be deployed effectively in real-world settings. Our code and data are all publicly available: https://snuhcc.github.io/DICE-Bench/.",
    "categories": [
      "cs.CL",
      "cs.AI"
    ],
    "primary_category": "cs.CL",
    "comment": "9 pages, ACL 2025 Vienna",
    "pdf_url": "https://arxiv.org/pdf/2506.22853v2",
    "published_date": "2025-06-28 11:28:04 UTC",
    "updated_date": "2025-07-02 07:55:09 UTC"
  },
  {
    "arxiv_id": "2506.22848v1",
    "title": "Scalable Structure Learning of Bayesian Networks by Learning Algorithm Ensembles",
    "authors": [
      "Shengcai Liu",
      "Hui Ou-yang",
      "Zhiyuan Wang",
      "Cheng Chen",
      "Qijun Cai",
      "Yew-Soon Ong",
      "Ke Tang"
    ],
    "abstract": "Learning the structure of Bayesian networks (BNs) from data is challenging, especially for datasets involving a large number of variables. The recently proposed divide-and-conquer (D\\&D) strategies present a promising approach for learning large BNs. However, they still face a main issue of unstable learning accuracy across subproblems. In this work, we introduce the idea of employing structure learning ensemble (SLE), which combines multiple BN structure learning algorithms, to consistently achieve high learning accuracy. We further propose an automatic approach called Auto-SLE for learning near-optimal SLEs, addressing the challenge of manually designing high-quality SLEs. The learned SLE is then integrated into a D\\&D method. Extensive experiments firmly show the superiority of our method over D\\&D methods with single BN structure learning algorithm in learning large BNs, achieving accuracy improvement usually by 30\\%$\\sim$225\\% on datasets involving 10,000 variables. Furthermore, our method generalizes well to datasets with many more (e.g., 30000) variables and different network characteristics than those present in the training data for learning the SLE. These results indicate the significant potential of employing (automatic learning of) SLEs for scalable BN structure learning.",
    "categories": [
      "cs.LG",
      "cs.AI"
    ],
    "primary_category": "cs.LG",
    "comment": "",
    "pdf_url": "https://arxiv.org/pdf/2506.22848v1",
    "published_date": "2025-06-28 11:05:08 UTC",
    "updated_date": "2025-06-28 11:05:08 UTC"
  },
  {
    "arxiv_id": "2506.22845v1",
    "title": "Quantum Neural Networks for Wind Energy Forecasting: A Comparative Study of Performance and Scalability with Classical Models",
    "authors": [
      "Batuhan Hangun",
      "Oguz Altun",
      "Onder Eyecioglu"
    ],
    "abstract": "Quantum Neural Networks (QNNs), a prominent approach in Quantum Machine Learning (QML), are emerging as a powerful alternative to classical machine learning methods. Recent studies have focused on the applicability of QNNs to various tasks, such as time-series forecasting, prediction, and classification, across a wide range of applications, including cybersecurity and medical imaging. With the increased use of smart grids driven by the integration of renewable energy systems, machine learning plays an important role in predicting power demand and detecting system disturbances. This study provides an in-depth investigation of QNNs for predicting the power output of a wind turbine. We assess the predictive performance and simulation time of six QNN configurations that are based on the Z Feature Map for data encoding and varying ansatz structures. Through detailed cross-validation experiments and tests on an unseen hold-out dataset, we experimentally demonstrate that QNNs can achieve predictive performance that is competitive with, and in some cases marginally better than, the benchmarked classical approaches. Our results also reveal the effects of dataset size and circuit complexity on predictive performance and simulation time. We believe our findings will offer valuable insights for researchers in the energy domain who wish to incorporate quantum machine learning into their work.",
    "categories": [
      "cs.LG",
      "cs.AI",
      "cs.PF"
    ],
    "primary_category": "cs.LG",
    "comment": "",
    "pdf_url": "https://arxiv.org/pdf/2506.22845v1",
    "published_date": "2025-06-28 10:51:27 UTC",
    "updated_date": "2025-06-28 10:51:27 UTC"
  },
  {
    "arxiv_id": "2506.22837v2",
    "title": "xLSTMAD: A Powerful xLSTM-based Method for Anomaly Detection",
    "authors": [
      "Kamil Faber",
      "Marcin Pietroń",
      "Dominik Żurek",
      "Roberto Corizzo"
    ],
    "abstract": "The recently proposed xLSTM is a powerful model that leverages expressive multiplicative gating and residual connections, providing the temporal capacity needed for long-horizon forecasting and representation learning. This architecture has demonstrated success in time series forecasting, lossless compression, and even large-scale language modeling tasks, where its linear memory footprint and fast inference make it a viable alternative to Transformers. Despite its growing popularity, no prior work has explored xLSTM for anomaly detection. In this work, we fill this gap by proposing xLSTMAD, the first anomaly detection method that integrates a full encoder-decoder xLSTM architecture, purpose-built for multivariate time series data. Our encoder processes input sequences to capture historical context, while the decoder is devised in two separate variants of the method. In the forecasting approach, the decoder iteratively generates forecasted future values xLSTMAD-F, while the reconstruction approach reconstructs the input time series from its encoded counterpart xLSTMAD-R. We investigate the performance of two loss functions: Mean Squared Error (MSE), and Soft Dynamic Time Warping (SoftDTW) to consider local reconstruction fidelity and global sequence alignment, respectively. We evaluate our method on the comprehensive TSB-AD-M benchmark, which spans 17 real-world datasets, using state-of-the-art challenging metrics such as VUS-PR. In our results, xLSTM showcases state-of-the-art accuracy, outperforming 23 popular anomaly detection baselines. Our paper is the first work revealing the powerful modeling capabilities of xLSTM for anomaly detection, paving the way for exciting new developments on this subject. Our code is available at: https://github.com/Nyderx/xlstmad",
    "categories": [
      "cs.LG",
      "cs.AI"
    ],
    "primary_category": "cs.LG",
    "comment": "",
    "pdf_url": "https://arxiv.org/pdf/2506.22837v2",
    "published_date": "2025-06-28 10:39:09 UTC",
    "updated_date": "2025-11-12 22:12:47 UTC"
  },
  {
    "arxiv_id": "2506.22832v2",
    "title": "Listener-Rewarded Thinking in VLMs for Image Preferences",
    "authors": [
      "Alexander Gambashidze",
      "Li Pengyi",
      "Matvey Skripkin",
      "Andrey Galichin",
      "Anton Gusarov",
      "Konstantin Sobolev",
      "Andrey Kuznetsov",
      "Ivan Oseledets"
    ],
    "abstract": "Training robust and generalizable reward models for human visual preferences is essential for aligning text-to-image and text-to-video generative models with human intent. However, current reward models often fail to generalize, and supervised fine-tuning leads to memorization, demanding complex annotation pipelines. While reinforcement learning (RL), specifically Group Relative Policy Optimization (GRPO), improves generalization, we uncover a key failure mode: a significant drop in reasoning accuracy occurs when a model's reasoning trace contradicts that of an independent, frozen vision-language model (\"listener\") evaluating the same output. To address this, we introduce a listener-augmented GRPO framework. Here, the listener re-evaluates the reasoner's chain-of-thought to provide a dense, calibrated confidence score, shaping the RL reward signal. This encourages the reasoner not only to answer correctly, but to produce explanations that are persuasive to an independent model. Our listener-shaped reward scheme achieves best accuracy on the ImageReward benchmark (67.4%), significantly improves out-of-distribution (OOD) performance on a large-scale human preference dataset (1.2M votes, up to +6% over naive reasoner), and reduces reasoning contradictions compared to strong GRPO and SFT baselines. These results demonstrate that listener-based rewards provide a scalable, data-efficient path to aligning vision-language models with nuanced human preferences. We will release our reasoning model here: https://huggingface.co/alexgambashidze/qwen2.5vl_image_preference_reasoner.",
    "categories": [
      "cs.CV",
      "cs.AI"
    ],
    "primary_category": "cs.CV",
    "comment": "",
    "pdf_url": "https://arxiv.org/pdf/2506.22832v2",
    "published_date": "2025-06-28 09:53:17 UTC",
    "updated_date": "2025-07-01 13:53:50 UTC"
  },
  {
    "arxiv_id": "2506.22818v1",
    "title": "TriADA: Massively Parallel Trilinear Matrix-by-Tensor Multiply-Add Algorithm and Device Architecture for the Acceleration of 3D Discrete Transformations",
    "authors": [
      "Stanislav Sedukhin",
      "Yoichi Tomioka",
      "Kazuya Matsumoto",
      "Yuichi Okuyama"
    ],
    "abstract": "Multilinear transformations are key in high-performance computing (HPC) and artificial intelligence (AI) workloads, where data is represented as tensors. However, their high computational and memory demands, which grow with dimensionality, often slow down critical tasks. Moreover, scaling computation by enlarging the number of parallel processing units substantially increases energy consumption, limiting widespread adoption, especially for sparse data, which is common in HPC and AI applications. This paper introduces the Trilinear Algorithm and isomorphic to algorithm Device Architecture (TriADA) to address these challenges with the following innovations: (1) a massively parallel, low-rank algorithm for computing a family of trilinear (3D) discrete orthogonal transformations (3D-DXTs), which is a special case of the more general 3-mode matrix-by-tensor multiplication (3D-GEMT); (2) a new outer-product-based GEMM kernel with decoupled streaming active memory, specially designed to accelerate 3D-GEMT operation; (3) an isomorphic to the proposed algorithm, fully distributed 3D network of mesh interconnected processing elements or cells with a coordinate-free, data-driven local processing activity, which is independent of problem size; (4) an elastic sparse outer-product (ESOP) method that avoids unnecessary computing and communication operations with zero-valued operands, thereby enhancing energy efficiency, computational accuracy, and stability. TriADA is capable of performing a variety of trilinear transformations with hypercubic arithmetic complexity in a linear number of time-steps. The massively parallel, scalable, and energy-efficient architecture of TriADA is ideal for accelerating multilinear tensor operations, which are the most demanding parts of AI and HPC workloads.",
    "categories": [
      "cs.DC",
      "cs.AI",
      "cs.AR",
      "cs.ET",
      "eess.SP"
    ],
    "primary_category": "cs.DC",
    "comment": "19 pages, 5 figures",
    "pdf_url": "https://arxiv.org/pdf/2506.22818v1",
    "published_date": "2025-06-28 08:42:01 UTC",
    "updated_date": "2025-06-28 08:42:01 UTC"
  },
  {
    "arxiv_id": "2506.22809v3",
    "title": "Low-rank variational dropout: Rank selection and uncertainty in adapters",
    "authors": [
      "Cooper Doyle",
      "Rebecca Chan",
      "Andy Hu",
      "Anna Leontjeva"
    ],
    "abstract": "Low-rank adaptation methods enable efficient task-specific updates in large neural networks, but provide no principled mechanism for uncertainty estimation or capacity control. We introduce Low-Rank Variational Dropout (LRVD), a Bayesian framework that operates directly in the space of low-rank adaptation. LRVD employs a scale-invariant, sparsity-inducing prior together with a structured variational family that ties uncertainty at the level of latent rank components, inducing rank-wise noise-to-signal ratios for automatic capacity selection. As a concrete instantiation, we apply LRVD to low-rank adaptation and obtain BayesLoRA, which jointly learns predictive uncertainty and the effective adapter rank with only O(r) additional parameters, where r is the adapter rank. We empirically show that BayesLoRA induces stable, non-arbitrary rank structure aligned with the intrinsic singular directions of the learned updates, and outperforms existing low-rank sparsification methods in accuracy at comparable training cost while delivering substantially improved predictive calibration at negligible additional overhead.",
    "categories": [
      "cs.LG",
      "cs.AI",
      "cs.CL"
    ],
    "primary_category": "cs.LG",
    "comment": "8 pages, 3 figures, 2 tables",
    "pdf_url": "https://arxiv.org/pdf/2506.22809v3",
    "published_date": "2025-06-28 08:22:02 UTC",
    "updated_date": "2026-01-08 07:40:27 UTC"
  },
  {
    "arxiv_id": "2506.22808v1",
    "title": "MedEthicsQA: A Comprehensive Question Answering Benchmark for Medical Ethics Evaluation of LLMs",
    "authors": [
      "Jianhui Wei",
      "Zijie Meng",
      "Zikai Xiao",
      "Tianxiang Hu",
      "Yang Feng",
      "Zhijie Zhou",
      "Jian Wu",
      "Zuozhu Liu"
    ],
    "abstract": "While Medical Large Language Models (MedLLMs) have demonstrated remarkable potential in clinical tasks, their ethical safety remains insufficiently explored. This paper introduces $\\textbf{MedEthicsQA}$, a comprehensive benchmark comprising $\\textbf{5,623}$ multiple-choice questions and $\\textbf{5,351}$ open-ended questions for evaluation of medical ethics in LLMs. We systematically establish a hierarchical taxonomy integrating global medical ethical standards. The benchmark encompasses widely used medical datasets, authoritative question banks, and scenarios derived from PubMed literature. Rigorous quality control involving multi-stage filtering and multi-faceted expert validation ensures the reliability of the dataset with a low error rate ($2.72\\%$). Evaluation of state-of-the-art MedLLMs exhibit declined performance in answering medical ethics questions compared to their foundation counterparts, elucidating the deficiencies of medical ethics alignment. The dataset, registered under CC BY-NC 4.0 license, is available at https://github.com/JianhuiWei7/MedEthicsQA.",
    "categories": [
      "cs.CL",
      "cs.AI"
    ],
    "primary_category": "cs.CL",
    "comment": "20 pages",
    "pdf_url": "https://arxiv.org/pdf/2506.22808v1",
    "published_date": "2025-06-28 08:21:35 UTC",
    "updated_date": "2025-06-28 08:21:35 UTC"
  },
  {
    "arxiv_id": "2506.22793v1",
    "title": "Offline Reinforcement Learning for Mobility Robustness Optimization",
    "authors": [
      "Pegah Alizadeh",
      "Anastasios Giovanidis",
      "Pradeepa Ramachandra",
      "Vasileios Koutsoukis",
      "Osama Arouk"
    ],
    "abstract": "In this work we revisit the Mobility Robustness Optimisation (MRO) algorithm and study the possibility of learning the optimal Cell Individual Offset tuning using offline Reinforcement Learning. Such methods make use of collected offline datasets to learn the optimal policy, without further exploration. We adapt and apply a sequence-based method called Decision Transformers as well as a value-based method called Conservative Q-Learning to learn the optimal policy for the same target reward as the vanilla rule-based MRO. The same input features related to failures, ping-pongs, and other handover issues are used. Evaluation for realistic New Radio networks with 3500 MHz carrier frequency on a traffic mix including diverse user service types and a specific tunable cell-pair shows that offline-RL methods outperform rule-based MRO, offering up to 7% improvement. Furthermore, offline-RL can be trained for diverse objective functions using the same available dataset, thus offering operational flexibility compared to rule-based methods.",
    "categories": [
      "cs.NI",
      "cs.AI",
      "cs.PF"
    ],
    "primary_category": "cs.NI",
    "comment": "7 pages, double column, 4 figures, 6 tables, conference submission",
    "pdf_url": "https://arxiv.org/pdf/2506.22793v1",
    "published_date": "2025-06-28 07:31:01 UTC",
    "updated_date": "2025-06-28 07:31:01 UTC"
  },
  {
    "arxiv_id": "2506.22789v1",
    "title": "WavShape: Information-Theoretic Speech Representation Learning for Fair and Privacy-Aware Audio Processing",
    "authors": [
      "Oguzhan Baser",
      "Ahmet Ege Tanriverdi",
      "Kaan Kale",
      "Sandeep P. Chinchali",
      "Sriram Vishwanath"
    ],
    "abstract": "Speech embeddings often retain sensitive attributes such as speaker identity, accent, or demographic information, posing risks in biased model training and privacy leakage. We propose WavShape, an information-theoretic speech representation learning framework that optimizes embeddings for fairness and privacy while preserving task-relevant information. We leverage mutual information (MI) estimation using the Donsker-Varadhan formulation to guide an MI-based encoder that systematically filters sensitive attributes while maintaining speech content essential for downstream tasks. Experimental results on three known datasets show that WavShape reduces MI between embeddings and sensitive attributes by up to 81% while retaining 97% of task-relevant information. By integrating information theory with self-supervised speech models, this work advances the development of fair, privacy-aware, and resource-efficient speech systems.",
    "categories": [
      "cs.SD",
      "cs.AI",
      "eess.AS"
    ],
    "primary_category": "cs.SD",
    "comment": "5 pages, 4 figures, Published at The Proceedings of Interspeech 2025, code is available at http://www.github.com/UTAustin-SwarmLab/WavShape",
    "pdf_url": "https://arxiv.org/pdf/2506.22789v1",
    "published_date": "2025-06-28 07:03:55 UTC",
    "updated_date": "2025-06-28 07:03:55 UTC"
  },
  {
    "arxiv_id": "2506.22784v1",
    "title": "Single-Frame Point-Pixel Registration via Supervised Cross-Modal Feature Matching",
    "authors": [
      "Yu Han",
      "Zhiwei Huang",
      "Yanting Zhang",
      "Fangjun Ding",
      "Shen Cai",
      "Rui Fan"
    ],
    "abstract": "Point-pixel registration between LiDAR point clouds and camera images is a fundamental yet challenging task in autonomous driving and robotic perception. A key difficulty lies in the modality gap between unstructured point clouds and structured images, especially under sparse single-frame LiDAR settings. Existing methods typically extract features separately from point clouds and images, then rely on hand-crafted or learned matching strategies. This separate encoding fails to bridge the modality gap effectively, and more critically, these methods struggle with the sparsity and noise of single-frame LiDAR, often requiring point cloud accumulation or additional priors to improve reliability. Inspired by recent progress in detector-free matching paradigms (e.g. MatchAnything), we revisit the projection-based approach and introduce the detector-free framework for direct point-pixel matching between LiDAR and camera views. Specifically, we project the LiDAR intensity map into a 2D view from the LiDAR perspective and feed it into an attention-based detector-free matching network, enabling cross-modal correspondence estimation without relying on multi-frame accumulation. To further enhance matching reliability, we introduce a repeatability scoring mechanism that acts as a soft visibility prior. This guides the network to suppress unreliable matches in regions with low intensity variation, improving robustness under sparse input. Extensive experiments on KITTI, nuScenes, and MIAS-LCEC-TF70 benchmarks demonstrate that our method achieves state-of-the-art performance, outperforming prior approaches on nuScenes (even those relying on accumulated point clouds), despite using only single-frame LiDAR.",
    "categories": [
      "cs.CV",
      "cs.AI",
      "cs.RO"
    ],
    "primary_category": "cs.CV",
    "comment": "",
    "pdf_url": "https://arxiv.org/pdf/2506.22784v1",
    "published_date": "2025-06-28 06:57:13 UTC",
    "updated_date": "2025-06-28 06:57:13 UTC"
  },
  {
    "arxiv_id": "2506.22783v1",
    "title": "PhonemeFake: Redefining Deepfake Realism with Language-Driven Segmental Manipulation and Adaptive Bilevel Detection",
    "authors": [
      "Oguzhan Baser",
      "Ahmet Ege Tanriverdi",
      "Sriram Vishwanath",
      "Sandeep P. Chinchali"
    ],
    "abstract": "Deepfake (DF) attacks pose a growing threat as generative models become increasingly advanced. However, our study reveals that existing DF datasets fail to deceive human perception, unlike real DF attacks that influence public discourse. It highlights the need for more realistic DF attack vectors. We introduce PhonemeFake (PF), a DF attack that manipulates critical speech segments using language reasoning, significantly reducing human perception by up to 42% and benchmark accuracies by up to 94%. We release an easy-to-use PF dataset on HuggingFace and open-source bilevel DF segment detection model that adaptively prioritizes compute on manipulated regions. Our extensive experiments across three known DF datasets reveal that our detection model reduces EER by 91% while achieving up to 90% speed-up, with minimal compute overhead and precise localization beyond existing models as a scalable solution.",
    "categories": [
      "cs.CV",
      "cs.AI",
      "cs.CL"
    ],
    "primary_category": "cs.CV",
    "comment": "5 pages, 3 figures, Published at Proceedings of Interspeech 2025, for the dataset see https://huggingface.co/datasets/phonemefake/PhonemeFakeV2, for the code see https://github.com/UTAustin-SwarmLab/ PhonemeFake",
    "pdf_url": "https://arxiv.org/pdf/2506.22783v1",
    "published_date": "2025-06-28 06:56:41 UTC",
    "updated_date": "2025-06-28 06:56:41 UTC"
  },
  {
    "arxiv_id": "2506.22777v2",
    "title": "Teaching Models to Verbalize Reward Hacking in Chain-of-Thought Reasoning",
    "authors": [
      "Miles Turpin",
      "Andy Arditi",
      "Marvin Li",
      "Joe Benton",
      "Julian Michael"
    ],
    "abstract": "Language models trained with reinforcement learning (RL) can engage in reward hacking--the exploitation of unintended strategies for high reward--without revealing this behavior in their chain-of-thought reasoning. This makes the detection of reward hacking difficult, posing risks for high-stakes applications. We propose verbalization fine-tuning (VFT), a pre-RL fine-tuning intervention that trains models to explicitly acknowledge when they are influenced by prompt cues--hints which point to incorrect answers (e.g., \"a Stanford professor thinks the answer is A\"). To evaluate VFT, we subsequently train models with RL on environments where held-out prompt cues signal which incorrect answers will receive high reward, incentivizing models to exploit these cues instead of reasoning correctly. We measure how often models exploit these cues without verbalizing it. After RL, only 6% of the VFT-trained model's responses consist of undetected reward hacks. In comparison, when we perform RL without VFT, the rate of undetected reward hacks goes up to 88%; with a debiasing baseline intervention, this increases further to 99%. VFT achieves this by substantially increasing how often models verbalize the influence of cues, from 8% to 43% after VFT, and up to 94% after RL. Baselines remain low even after RL (11% and 1%). Our results show that teaching models to explicitly verbalize reward hacking behavior before RL significantly improves their detection, offering a practical path toward more transparent and safe AI systems.",
    "categories": [
      "cs.CL",
      "cs.AI"
    ],
    "primary_category": "cs.CL",
    "comment": "Published at ICML 2025 Workshop on Reliable and Responsible Foundation Models",
    "pdf_url": "https://arxiv.org/pdf/2506.22777v2",
    "published_date": "2025-06-28 06:37:10 UTC",
    "updated_date": "2025-07-13 15:36:35 UTC"
  },
  {
    "arxiv_id": "2506.22776v1",
    "title": "Smaller = Weaker? Benchmarking Robustness of Quantized LLMs in Code Generation",
    "authors": [
      "Sen Fang",
      "Weiyuan Ding",
      "Antonio Mastropaolo",
      "Bowen Xu"
    ],
    "abstract": "Quantization has emerged as a mainstream method for compressing Large Language Models (LLMs), reducing memory requirements and accelerating inference without architectural modifications. While existing research primarily focuses on evaluating the effectiveness of quantized LLMs compared to their original counterparts, the impact on robustness remains largely unexplored.In this paper, we present the first systematic investigation of how quantization affects the robustness of LLMs in code generation tasks. Through extensive experiments across four prominent LLM families (LLaMA, DeepSeek, CodeGen, and StarCoder) with parameter scales ranging from 350M to 33B, we evaluate robustness from dual perspectives: adversarial attacks on input prompts and noise perturbations on model architecture. Our findings challenge conventional wisdom by demonstrating that quantized LLMs often exhibit superior robustness compared to their full-precision counterparts, with 51.59% versus 42.86% of our adversarial experiments showing better resilience in quantized LLMs. Similarly, our noise perturbation experiments also confirm that LLMs after quantitation generally withstand higher levels of weight disturbances. These results suggest that quantization not only reduces computational requirements but can actually enhance LLMs' reliability in code generation tasks, providing valuable insights for developing more robust and efficient LLM deployment strategies.",
    "categories": [
      "cs.SE",
      "cs.AI",
      "cs.PL"
    ],
    "primary_category": "cs.SE",
    "comment": "13 pages, 6 figures",
    "pdf_url": "https://arxiv.org/pdf/2506.22776v1",
    "published_date": "2025-06-28 06:32:25 UTC",
    "updated_date": "2025-06-28 06:32:25 UTC"
  },
  {
    "arxiv_id": "2506.22774v4",
    "title": "Bridging Ethical Principles and Algorithmic Methods: An Alternative Approach for Assessing Trustworthiness in AI Systems",
    "authors": [
      "Michael Papademas",
      "Xenia Ziouvelou",
      "Antonis Troumpoukis",
      "Vangelis Karkaletsis"
    ],
    "abstract": "Artificial Intelligence (AI) technology epitomizes the complex challenges posed by human-made artifacts, particularly those widely integrated into society and exerting significant influence, highlighting potential benefits and their negative consequences. While other technologies may also pose substantial risks, AI's pervasive reach makes its societal effects especially profound. The complexity of AI systems, coupled with their remarkable capabilities, can lead to a reliance on technologies that operate beyond direct human oversight or understanding. To mitigate the risks that arise, several theoretical tools and guidelines have been developed, alongside efforts to create technological tools aimed at safeguarding Trustworthy AI. The guidelines take a more holistic view of the issue but fail to provide techniques for quantifying trustworthiness. Conversely, while technological tools are better at achieving such quantification, they lack a holistic perspective, focusing instead on specific aspects of Trustworthy AI. This paper aims to introduce an assessment method that combines the ethical components of Trustworthy AI with the algorithmic processes of PageRank and TrustRank. The goal is to establish an assessment framework that minimizes the subjectivity inherent in the self-assessment techniques prevalent in the field by introducing algorithmic criteria. The application of our approach indicates that a holistic assessment of an AI system's trustworthiness can be achieved by providing quantitative insights while considering the theoretical content of relevant guidelines.",
    "categories": [
      "cs.AI",
      "cs.CY"
    ],
    "primary_category": "cs.AI",
    "comment": "",
    "pdf_url": "https://arxiv.org/pdf/2506.22774v4",
    "published_date": "2025-06-28 06:27:30 UTC",
    "updated_date": "2025-10-03 07:45:59 UTC"
  },
  {
    "arxiv_id": "2506.22771v1",
    "title": "FF-INT8: Efficient Forward-Forward DNN Training on Edge Devices with INT8 Precision",
    "authors": [
      "Jingxiao Ma",
      "Priyadarshini Panda",
      "Sherief Reda"
    ],
    "abstract": "Backpropagation has been the cornerstone of neural network training for decades, yet its inefficiencies in time and energy consumption limit its suitability for resource-constrained edge devices. While low-precision neural network quantization has been extensively researched to speed up model inference, its application in training has been less explored. Recently, the Forward-Forward (FF) algorithm has emerged as a promising alternative to backpropagation, replacing the backward pass with an additional forward pass. By avoiding the need to store intermediate activations for backpropagation, FF can reduce memory footprint, making it well-suited for embedded devices. This paper presents an INT8 quantized training approach that leverages FF's layer-by-layer strategy to stabilize gradient quantization. Furthermore, we propose a novel \"look-ahead\" scheme to address limitations of FF and improve model accuracy. Experiments conducted on NVIDIA Jetson Orin Nano board demonstrate 4.6% faster training, 8.3% energy savings, and 27.0% reduction in memory usage, while maintaining competitive accuracy compared to the state-of-the-art.",
    "categories": [
      "cs.LG",
      "cs.AI",
      "cs.NE"
    ],
    "primary_category": "cs.LG",
    "comment": "To be published in the 62nd Design Automation Conference (DAC), 2025",
    "pdf_url": "https://arxiv.org/pdf/2506.22771v1",
    "published_date": "2025-06-28 06:16:26 UTC",
    "updated_date": "2025-06-28 06:16:26 UTC"
  },
  {
    "arxiv_id": "2506.22742v1",
    "title": "RAILS: Retrieval-Augmented Intelligence for Learning Software Development",
    "authors": [
      "Wali Mohammad Abdullah",
      "Md. Morshedul Islam",
      "Devraj Parmar",
      "Happy Hasmukhbhai Patel",
      "Sindhuja Prabhakaran",
      "Baidya Saha"
    ],
    "abstract": "Large Language Models (LLMs) like GPT-3.5-Turbo are increasingly used to assist software development, yet they often produce incomplete code or incorrect imports, especially when lacking access to external or project-specific documentation. We introduce RAILS (Retrieval-Augmented Intelligence for Learning Software Development), a framework that augments LLM prompts with semantically retrieved context from curated Java resources using FAISS and OpenAI embeddings. RAILS incorporates an iterative validation loop guided by compiler feedback to refine suggestions. We evaluated RAILS on 78 real-world Java import error cases spanning standard libraries, GUI APIs, external tools, and custom utilities. Despite using the same LLM, RAILS outperforms baseline prompting by preserving intent, avoiding hallucinations, and surfacing correct imports even when libraries are unavailable locally. Future work will integrate symbolic filtering via PostgreSQL and extend support to other languages and IDEs.",
    "categories": [
      "cs.SE",
      "cs.AI"
    ],
    "primary_category": "cs.SE",
    "comment": "",
    "pdf_url": "https://arxiv.org/pdf/2506.22742v1",
    "published_date": "2025-06-28 03:30:04 UTC",
    "updated_date": "2025-06-28 03:30:04 UTC"
  },
  {
    "arxiv_id": "2507.01055v1",
    "title": "Prompt Mechanisms in Medical Imaging: A Comprehensive Survey",
    "authors": [
      "Hao Yang",
      "Xinlong Liang",
      "Zhang Li",
      "Yue Sun",
      "Zheyu Hu",
      "Xinghe Xie",
      "Behdad Dashtbozorg",
      "Jincheng Huang",
      "Shiwei Zhu",
      "Luyi Han",
      "Jiong Zhang",
      "Shanshan Wang",
      "Ritse Mann",
      "Qifeng Yu",
      "Tao Tan"
    ],
    "abstract": "Deep learning offers transformative potential in medical imaging, yet its clinical adoption is frequently hampered by challenges such as data scarcity, distribution shifts, and the need for robust task generalization. Prompt-based methodologies have emerged as a pivotal strategy to guide deep learning models, providing flexible, domain-specific adaptations that significantly enhance model performance and adaptability without extensive retraining. This systematic review critically examines the burgeoning landscape of prompt engineering in medical imaging. We dissect diverse prompt modalities, including textual instructions, visual prompts, and learnable embeddings, and analyze their integration for core tasks such as image generation, segmentation, and classification. Our synthesis reveals how these mechanisms improve task-specific outcomes by enhancing accuracy, robustness, and data efficiency and reducing reliance on manual feature engineering while fostering greater model interpretability by making the model's guidance explicit. Despite substantial advancements, we identify persistent challenges, particularly in prompt design optimization, data heterogeneity, and ensuring scalability for clinical deployment. Finally, this review outlines promising future trajectories, including advanced multimodal prompting and robust clinical integration, underscoring the critical role of prompt-driven AI in accelerating the revolution of diagnostics and personalized treatment planning in medicine.",
    "categories": [
      "eess.IV",
      "cs.AI",
      "cs.CV"
    ],
    "primary_category": "eess.IV",
    "comment": "",
    "pdf_url": "https://arxiv.org/pdf/2507.01055v1",
    "published_date": "2025-06-28 03:06:25 UTC",
    "updated_date": "2025-06-28 03:06:25 UTC"
  },
  {
    "arxiv_id": "2506.22740v1",
    "title": "Explanations are a means to an end",
    "authors": [
      "Jessica Hullman",
      "Ziyang Guo",
      "Berk Ustun"
    ],
    "abstract": "Modern methods for explainable machine learning are designed to describe how models map inputs to outputs--without deep consideration of how these explanations will be used in practice. This paper argues that explanations should be designed and evaluated with a specific end in mind. We describe how to formalize this end in a framework based in statistical decision theory. We show how this functionally-grounded approach can be applied across diverse use cases, such as clinical decision support, providing recourse, or debugging. We demonstrate its use to characterize the maximum \"boost\" in performance on a particular task that an explanation could provide an idealized decision-maker, preventing misuse due to ambiguity by forcing researchers to specify concrete use cases that can be analyzed in light of models of expected explanation use. We argue that evaluation should meld theoretical and empirical perspectives on the value of explanation, and contribute definitions that span these perspectives.",
    "categories": [
      "cs.AI",
      "stat.ML"
    ],
    "primary_category": "cs.AI",
    "comment": "",
    "pdf_url": "https://arxiv.org/pdf/2506.22740v1",
    "published_date": "2025-06-28 03:04:21 UTC",
    "updated_date": "2025-06-28 03:04:21 UTC"
  },
  {
    "arxiv_id": "2506.22722v1",
    "title": "Kill Two Birds with One Stone! Trajectory enabled Unified Online Detection of Adversarial Examples and Backdoor Attacks",
    "authors": [
      "Anmin Fu",
      "Fanyu Meng",
      "Huaibing Peng",
      "Hua Ma",
      "Zhi Zhang",
      "Yifeng Zheng",
      "Willy Susilo",
      "Yansong Gao"
    ],
    "abstract": "The proposed UniGuard is the first unified online detection framework capable of simultaneously addressing adversarial examples and backdoor attacks. UniGuard builds upon two key insights: first, both AE and backdoor attacks have to compromise the inference phase, making it possible to tackle them simultaneously during run-time via online detection. Second, an adversarial input, whether a perturbed sample in AE attacks or a trigger-carrying sample in backdoor attacks, exhibits distinctive trajectory signatures from a benign sample as it propagates through the layers of a DL model in forward inference. The propagation trajectory of the adversarial sample must deviate from that of its benign counterpart; otherwise, the adversarial objective cannot be fulfilled. Detecting these trajectory signatures is inherently challenging due to their subtlety; UniGuard overcomes this by treating the propagation trajectory as a time-series signal, leveraging LSTM and spectrum transformation to amplify differences between adversarial and benign trajectories that are subtle in the time domain. UniGuard exceptional efficiency and effectiveness have been extensively validated across various modalities (image, text, and audio) and tasks (classification and regression), ranging from diverse model architectures against a wide range of AE attacks and backdoor attacks, including challenging partial backdoors and dynamic triggers. When compared to SOTA methods, including ContraNet (NDSS 22) specific for AE detection and TED (IEEE SP 24) specific for backdoor detection, UniGuard consistently demonstrates superior performance, even when matched against each method's strengths in addressing their respective threats-each SOTA fails to parts of attack strategies while UniGuard succeeds for all.",
    "categories": [
      "cs.CR",
      "cs.AI"
    ],
    "primary_category": "cs.CR",
    "comment": "",
    "pdf_url": "https://arxiv.org/pdf/2506.22722v1",
    "published_date": "2025-06-28 02:06:23 UTC",
    "updated_date": "2025-06-28 02:06:23 UTC"
  },
  {
    "arxiv_id": "2507.00066v1",
    "title": "InSight-R: A Framework for Risk-informed Human Failure Event Identification and Interface-Induced Risk Assessment Driven by AutoGraph",
    "authors": [
      "Xingyu Xiao",
      "Jiejuan Tong",
      "Peng Chen",
      "Jun Sun",
      "Zhe Sui",
      "Jingang Liang",
      "Hongru Zhao",
      "Jun Zhao",
      "Haitao Wang"
    ],
    "abstract": "Human reliability remains a critical concern in safety-critical domains such as nuclear power, where operational failures are often linked to human error. While conventional human reliability analysis (HRA) methods have been widely adopted, they rely heavily on expert judgment for identifying human failure events (HFEs) and assigning performance influencing factors (PIFs). This reliance introduces challenges related to reproducibility, subjectivity, and limited integration of interface-level data. In particular, current approaches lack the capacity to rigorously assess how human-machine interface design contributes to operator performance variability and error susceptibility. To address these limitations, this study proposes a framework for risk-informed human failure event identification and interface-induced risk assessment driven by AutoGraph (InSight-R). By linking empirical behavioral data to the interface-embedded knowledge graph (IE-KG) constructed by the automated graph-based execution framework (AutoGraph), the InSight-R framework enables automated HFE identification based on both error-prone and time-deviated operational paths. Furthermore, we discuss the relationship between designer-user conflicts and human error. The results demonstrate that InSight-R not only enhances the objectivity and interpretability of HFE identification but also provides a scalable pathway toward dynamic, real-time human reliability assessment in digitalized control environments. This framework offers actionable insights for interface design optimization and contributes to the advancement of mechanism-driven HRA methodologies.",
    "categories": [
      "cs.HC",
      "cs.AI"
    ],
    "primary_category": "cs.HC",
    "comment": "",
    "pdf_url": "https://arxiv.org/pdf/2507.00066v1",
    "published_date": "2025-06-28 02:04:06 UTC",
    "updated_date": "2025-06-28 02:04:06 UTC"
  },
  {
    "arxiv_id": "2506.22716v1",
    "title": "BEST-Route: Adaptive LLM Routing with Test-Time Optimal Compute",
    "authors": [
      "Dujian Ding",
      "Ankur Mallick",
      "Shaokun Zhang",
      "Chi Wang",
      "Daniel Madrigal",
      "Mirian Del Carmen Hipolito Garcia",
      "Menglin Xia",
      "Laks V. S. Lakshmanan",
      "Qingyun Wu",
      "Victor Rühle"
    ],
    "abstract": "Large language models (LLMs) are powerful tools but are often expensive to deploy at scale. LLM query routing mitigates this by dynamically assigning queries to models of varying cost and quality to obtain a desired trade-off. Prior query routing approaches generate only one response from the selected model and a single response from a small (inexpensive) model was often not good enough to beat a response from a large (expensive) model due to which they end up overusing the large model and missing out on potential cost savings. However, it is well known that for small models, generating multiple responses and selecting the best can enhance quality while remaining cheaper than a single large-model response. We leverage this idea to propose BEST-Route, a novel routing framework that chooses a model and the number of responses to sample from it based on query difficulty and the quality thresholds. Experiments on real-world datasets demonstrate that our method reduces costs by up to 60% with less than 1% performance drop.",
    "categories": [
      "cs.LG",
      "cs.AI",
      "cs.CL",
      "cs.DB"
    ],
    "primary_category": "cs.LG",
    "comment": "Accepted to ICML 2025 (main conference)",
    "pdf_url": "https://arxiv.org/pdf/2506.22716v1",
    "published_date": "2025-06-28 01:52:50 UTC",
    "updated_date": "2025-06-28 01:52:50 UTC"
  },
  {
    "arxiv_id": "2506.22706v1",
    "title": "General Autonomous Cybersecurity Defense: Learning Robust Policies for Dynamic Topologies and Diverse Attackers",
    "authors": [
      "Arun Ramamurthy",
      "Neil Dhir"
    ],
    "abstract": "In the face of evolving cyber threats such as malware, ransomware and phishing, autonomous cybersecurity defense (ACD) systems have become essential for real-time threat detection and response with optional human intervention. However, existing ACD systems rely on limiting assumptions, particularly the stationarity of the underlying network dynamics. In real-world scenarios, network topologies can change due to actions taken by attackers or defenders, system failures, or time evolution of networks, leading to failures in the adaptive capabilities of current defense agents. Moreover, many agents are trained on static environments, resulting in overfitting to specific topologies, which hampers their ability to generalize to out-of-distribution network topologies. This work addresses these challenges by exploring methods for developing agents to learn generalizable policies across dynamic network environments -- general ACD (GACD).",
    "categories": [
      "cs.CR",
      "cs.AI",
      "cs.CV",
      "stat.ML"
    ],
    "primary_category": "cs.CR",
    "comment": "",
    "pdf_url": "https://arxiv.org/pdf/2506.22706v1",
    "published_date": "2025-06-28 01:12:13 UTC",
    "updated_date": "2025-06-28 01:12:13 UTC"
  },
  {
    "arxiv_id": "2506.22704v2",
    "title": "Beyond Code: The Multidimensional Impacts of Large Language Models in Software Development",
    "authors": [
      "Sardar Bonabi",
      "Sarah Bana",
      "Vijay Gurbaxani",
      "Tingting Nian"
    ],
    "abstract": "Large language models (LLMs) are poised to significantly impact software development, especially in the Open-Source Software (OSS) sector. To understand this impact, we first outline the mechanisms through which LLMs may influence OSS through code development, collaborative knowledge transfer, and skill development. We then empirically examine how LLMs affect OSS developers' work in these three key areas. Leveraging a natural experiment from a temporary ChatGPT ban in Italy, we employ a Difference-in-Differences framework with two-way fixed effects to analyze data from all OSS developers on GitHub in three similar countries, Italy, France, and Portugal, totaling 88,022 users. We find that access to ChatGPT increases developer productivity by 6.4%, knowledge sharing by 9.6%, and skill acquisition by 8.4%. These benefits vary significantly by user experience level: novice developers primarily experience productivity gains, whereas more experienced developers benefit more from improved knowledge sharing and accelerated skill acquisition. In addition, we find that LLM-assisted learning is highly context-dependent, with the greatest benefits observed in technically complex, fragmented, or rapidly evolving contexts. We show that the productivity effects of LLMs extend beyond direct code generation to include enhanced collaborative learning and knowledge exchange among developers, dynamics that are essential for gaining a holistic understanding of LLMs' impact in OSS. Our findings offer critical managerial implications: strategically deploying LLMs can accelerate novice developers' onboarding and productivity, empower intermediate developers to foster knowledge sharing and collaboration, and support rapid skill acquisition, together enhancing long-term organizational productivity and agility.",
    "categories": [
      "econ.GN",
      "cs.AI"
    ],
    "primary_category": "econ.GN",
    "comment": "",
    "pdf_url": "https://arxiv.org/pdf/2506.22704v2",
    "published_date": "2025-06-28 01:10:24 UTC",
    "updated_date": "2025-07-01 02:35:48 UTC"
  },
  {
    "arxiv_id": "2506.22703v1",
    "title": "P4OMP: Retrieval-Augmented Prompting for OpenMP Parallelism in Serial Code",
    "authors": [
      "Wali Mohammad Abdullah",
      "Azmain Kabir"
    ],
    "abstract": "We present P4OMP, a retrieval-augmented framework for transforming serial C/C++ code into OpenMP-annotated parallel code using large language models (LLMs). To our knowledge, this is the first system to apply retrieval-based prompting for OpenMP pragma correctness without model fine-tuning or compiler instrumentation. P4OMP leverages Retrieval-Augmented Generation (RAG) with structured instructional knowledge from OpenMP tutorials to improve the reliability of prompt-driven code generation. By grounding generation in the retrieved context, P4OMP improves syntactic correctness compared to baseline prompting with GPT-3.5-Turbo. We evaluate P4OMP against a baseline, GPT-3.5-Turbo without retrieval, on a comprehensive benchmark of 108 real-world C++ programs drawn from Stack Overflow, PolyBench, and NAS benchmark suites. P4OMP achieves 100% compilation success on all parallelizable cases, while the baseline fails to compile in 20 out of 108 cases. Six cases that rely on non-random-access iterators or thread-unsafe constructs are excluded due to fundamental OpenMP limitations. A detailed analysis demonstrates how P4OMP consistently avoids scoping errors, syntactic misuse, and invalid directive combinations that commonly affect baseline-generated code. We further demonstrate strong runtime scaling across seven compute-intensive benchmarks on an HPC cluster. P4OMP offers a robust, modular pipeline that significantly improves the reliability and applicability of LLM-generated OpenMP code.",
    "categories": [
      "cs.SE",
      "cs.AI"
    ],
    "primary_category": "cs.SE",
    "comment": "",
    "pdf_url": "https://arxiv.org/pdf/2506.22703v1",
    "published_date": "2025-06-28 01:06:34 UTC",
    "updated_date": "2025-06-28 01:06:34 UTC"
  },
  {
    "arxiv_id": "2506.22698v2",
    "title": "Text Production and Comprehension by Human and Artificial Intelligence: Interdisciplinary Workshop Report",
    "authors": [
      "Emily Dux Speltz"
    ],
    "abstract": "This report synthesizes the outcomes of a recent interdisciplinary workshop that brought together leading experts in cognitive psychology, language learning, and artificial intelligence (AI)-based natural language processing (NLP). The workshop, funded by the National Science Foundation, aimed to address a critical knowledge gap in our understanding of the relationship between AI language models and human cognitive processes in text comprehension and composition. Through collaborative dialogue across cognitive, linguistic, and technological perspectives, workshop participants examined the underlying processes involved when humans produce and comprehend text, and how AI can both inform our understanding of these processes and augment human capabilities. The workshop revealed emerging patterns in the relationship between large language models (LLMs) and human cognition, with highlights on both the capabilities of LLMs and their limitations in fully replicating human-like language understanding and generation. Key findings include the potential of LLMs to offer insights into human language processing, the increasing alignment between LLM behavior and human language processing when models are fine-tuned with human feedback, and the opportunities and challenges presented by human-AI collaboration in language tasks. By synthesizing these findings, this report aims to guide future research, development, and implementation of LLMs in cognitive psychology, linguistics, and education. It emphasizes the importance of ethical considerations and responsible use of AI technologies while striving to enhance human capabilities in text comprehension and production through effective human-AI collaboration.",
    "categories": [
      "cs.CL",
      "cs.AI"
    ],
    "primary_category": "cs.CL",
    "comment": "",
    "pdf_url": "https://arxiv.org/pdf/2506.22698v2",
    "published_date": "2025-06-28 00:31:14 UTC",
    "updated_date": "2025-07-01 15:26:29 UTC"
  }
]