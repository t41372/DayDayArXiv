{
  "date": "2025-12-01",
  "category": "cs.AI",
  "summary": "æ¬¢è¿æ¥åˆ° UTC æ—¶é—´ 2025-12-01 çš„ arXiv ä¸­æ–‡ TLDR å¿«æŠ¥ï¼\n\n**ä»Šæ—¥æ€»ç»“**ï¼š\nä»Šå¤©çš„ arXiv å……æ»¡äº†â€œç¡¬æ ¸â€çš„å·¥ç¨‹ä¸ç§‘å­¦æ°”æ¯ã€‚**AI for Science** å†æ¬¡æˆä¸ºç„¦ç‚¹ï¼ŒAndrew Ng å›¢é˜Ÿæ¨å‡ºäº†ç”¨äºæ°”å€™æ¨¡æ‹Ÿçš„å±‚çº§æµåŒ¹é…æ¨¡å‹ï¼ŒAnima Anandkumar å›¢é˜Ÿåˆ™ç”¨ç¥ç»ç®—å­æ¨¡æ‹Ÿé»‘æ´å¸ç§¯ç›˜ã€‚åœ¨ **LLM æ¨ç†**æ–¹é¢ï¼Œå¦‚ä½•å¯¹ o1/DeepSeek-R1 è¿™ç±»â€œæ¨ç†æ¨¡å‹â€è¿›è¡Œå‰ªæï¼ˆPruningï¼‰å’ŒåŠ é€Ÿï¼ˆSpeculative Decodingï¼‰æˆä¸ºäº†æ–°çš„æŠ€æœ¯é«˜åœ°ã€‚æ­¤å¤–ï¼Œ**é‡‘è Agent** çš„é²æ£’æ€§å—åˆ°è´¨ç–‘ï¼Œå¤šç¯‡è®ºæ–‡æ¢è®¨äº†ä»ç®—æ³•äº¤æ˜“åˆ° Agent äº¤æ˜“çš„èŒƒå¼è½¬å˜åŠå…¶é£é™©ã€‚\n\n---\n\n### ğŸš€ æ˜æ˜Ÿå­¦è€… & AI for Science\n\n**1. [æ°”å€™æ¨¡æ‹Ÿ] Spatiotemporal Pyramid Flow Matching for Climate Emulation**\n**Spatiotemporal Pyramid Flow: ç”¨äºæ°”å€™ä»¿çœŸçš„æ—¶ç©ºé‡‘å­—å¡”æµåŒ¹é…**\n> æ ¸å¿ƒä½œè€…: Andrew Y. Ng (Stanford), Duncan Watson-Parris ç­‰\n> å…³é”®è¯: Flow Matching, Climate Emulation, Generative Models\n\n**Andrew Ng å›¢é˜Ÿæ–°ä½œ**ã€‚ä¼ ç»Ÿçš„æ°”å€™æ¨¡æ‹Ÿä¾èµ–æå…¶ç¼“æ…¢çš„è‡ªå›å½’æ¨¡å‹ã€‚æœ¬æ–‡æå‡ºäº† SPFï¼ˆæ—¶ç©ºé‡‘å­—å¡”æµï¼‰ï¼Œä¸€ç§æ–°çš„æµåŒ¹é…ï¼ˆFlow Matchingï¼‰æ–¹æ³•ã€‚\n- **æ ¸å¿ƒæ€æƒ³**ï¼šå—çº§è”è§†é¢‘æ¨¡å‹å¯å‘ï¼ŒSPF å°†ç”Ÿæˆè½¨è¿¹åˆ’åˆ†ä¸ºæ—¶ç©ºé‡‘å­—å¡”ï¼Œé€æ­¥æé«˜ç©ºé—´åˆ†è¾¨ç‡ï¼Œå¹¶è€¦åˆä¸åŒçš„æ—¶é—´å°ºåº¦ã€‚\n- **è´¡çŒ®**ï¼šèƒ½å¤Ÿä»¥ä¸åŒæ—¶é—´å°ºåº¦å¹¶è¡Œã€é«˜æ•ˆåœ°æ¨¡æ‹Ÿæ°”å€™å˜åŒ–ï¼ˆå¦‚æ¸©å®¤æ°”ä½“å½±å“ï¼‰ã€‚å‘å¸ƒäº† **ClimateSuite** æ•°æ®é›†ï¼ˆ33,000+ æ¨¡æ‹Ÿå¹´ï¼‰ã€‚\n- **æ•ˆæœ**ï¼šåœ¨ ClimateBench ä¸Šè¶…è¶Šäº†ç°æœ‰çš„æµåŒ¹é…åŸºçº¿ï¼Œä¸”é€Ÿåº¦æå¿«ã€‚\n\n**2. [å¤©ä½“ç‰©ç†] From Black Hole to Galaxy: Neural Operator: Framework for Accretion and Feedback Dynamics**\n**ä»é»‘æ´åˆ°æ˜Ÿç³»ï¼šç¥ç»ç®—å­æ¡†æ¶ä¸‹çš„å¸ç§¯ä¸åé¦ˆåŠ¨åŠ›å­¦**\n> æ ¸å¿ƒä½œè€…: Anima Anandkumar (Caltech), Nihaal Bhojwani ç­‰\n> å…³é”®è¯: Neural Operators, Astrophysics, Multi-scale Simulation\n\n**Anima Anandkumar å›¢é˜Ÿæ–°ä½œ**ã€‚æ¨¡æ‹Ÿè¶…å¤§è´¨é‡é»‘æ´ä¸å®¿ä¸»æ˜Ÿç³»çš„ååŒæ¼”åŒ–æéš¾ï¼Œå› ä¸ºç‰©ç†å°ºåº¦è·¨è¶Šäº† 9 ä¸ªæ•°é‡çº§ã€‚\n- **æ–¹æ³•**ï¼šå¼•å…¥åŸºäº **Neural Operator** çš„â€œäºšç½‘æ ¼é»‘æ´â€ï¼ˆsubgrid black holeï¼‰æ¨¡å‹ï¼Œå­¦ä¹ å°å°ºåº¦çš„å±€éƒ¨åŠ¨åŠ›å­¦ï¼Œå¹¶å°†å…¶åµŒå…¥åˆ°å¤§å°ºåº¦çš„æ¨¡æ‹Ÿä¸­ã€‚\n- **çªç ´**ï¼šé¦–æ¬¡æ•æ‰åˆ°äº†å¸ç§¯é©±åŠ¨åé¦ˆçš„å†…åœ¨å˜å¼‚æ€§ï¼Œå®ç°äº†é»‘æ´ä¸æ˜Ÿç³»çº§æ°”ä½“çš„åŠ¨æ€è€¦åˆï¼Œè§£å†³äº†ä¼ ç»Ÿæ–¹æ³•éš¾ä»¥å¤„ç†çš„æ—¶é—´å˜å¼‚æ€§é—®é¢˜ã€‚\n\n**3. [æœºå™¨äºº] Learning Sim-to-Real Humanoid Locomotion in 15 Minutes**\n**15åˆ†é’Ÿå­¦ä¼šä»¿çœŸåˆ°ç°å®çš„äººå½¢æœºå™¨äººè¿åŠ¨æ§åˆ¶**\n> æ ¸å¿ƒä½œè€…: Pieter Abbeel (UC Berkeley), Younggyo Seo ç­‰\n> å…³é”®è¯: Sim-to-Real, Reinforcement Learning, Humanoid\n\n**Pieter Abbeel å›¢é˜Ÿæ–°ä½œ**ã€‚é’ˆå¯¹äººå½¢æœºå™¨äººï¼ˆUnitree G1ç­‰ï¼‰çš„ Sim-to-Real éš¾é¢˜ã€‚\n- **æ–¹æ³•**ï¼šæå‡ºä¸€ç§åŸºäº Off-policy RL (FastSAC, FastTD3) çš„ç®€å•é…æ–¹ï¼Œåˆ©ç”¨å¤§è§„æ¨¡å¹¶è¡Œä»¿çœŸå’Œæç®€çš„å¥–åŠ±å‡½æ•°è®¾è®¡ã€‚\n- **æ•ˆæœ**ï¼šä»…éœ€å•å¼  RTX 4090ï¼Œ**15åˆ†é’Ÿ**å†…å³å¯å®Œæˆè®­ç»ƒï¼Œå¹¶æˆåŠŸéƒ¨ç½²åˆ°çœŸæœºä¸Šï¼Œèƒ½å¤Ÿåº”å¯¹ç²—ç³™åœ°å½¢å’Œæ¨åŠ›å¹²æ‰°ã€‚\n\n---\n\n### ğŸ§  æ¨ç†æ¨¡å‹ (Reasoning Models) çš„ä¼˜åŒ–ä¸åŠ é€Ÿ\n\n**4. [æ¨¡å‹å‰ªæ] Think Before You Prune: Self-Reflective Structured Pruning for Reasoning Language Models**\n**å‰ªæå‰å…ˆæ€è€ƒï¼šæ¨ç†å¤§æ¨¡å‹çš„è‡ªåæ€ç»“æ„åŒ–å‰ªæ**\n> å…³é”®è¯: Reasoning LLMs, Model Pruning, Self-Reflection\n\n**é’ˆå¯¹ OpenAI o1, DeepSeek-R1 ç­‰æ¨ç†æ¨¡å‹çš„å‰ªæç ”ç©¶**ã€‚\n- **å‘ç°**ï¼šç°æœ‰çš„å‰ªææ–¹æ³•ä¼šä¸¥é‡ç ´åæ¨ç†æ¨¡å‹çš„ CoTï¼ˆæ€ç»´é“¾ï¼‰è¿è´¯æ€§ï¼Œç”šè‡³åœ¨ 20% ç¨€ç–åº¦æ—¶å°±ä¼šå¯¼è‡´å´©å¡Œã€‚åŸå› æ˜¯æ ¡å‡†æ•°æ®ä¸æ¨ç†æ—¶çš„åˆ†å¸ƒä¸åŒ¹é…ã€‚\n- **æ–¹æ³•**ï¼šæå‡º RESP æ¡†æ¶ï¼Œä½¿ç”¨æ¨¡å‹**è‡ªç”Ÿæˆçš„æ¨ç†è½¨è¿¹**ä½œä¸ºæ ¡å‡†ä¿¡å·ï¼Œè€Œéäººç±»æ ‡ç­¾ã€‚\n- **æ•ˆæœ**ï¼šåœ¨ Qwen3-8B ä¸Šï¼ŒRESP åœ¨ 40% ç¨€ç–åº¦ä¸‹ GSM8K å‡†ç¡®ç‡ä»è¾¾ 81.3%ï¼Œè¿œè¶…åŸºçº¿ã€‚\n\n**5. [æ¨ç†åŠ é€Ÿ] Accelerating Large-Scale Reasoning Model Inference with Sparse Self-Speculative Decoding**\n**åˆ©ç”¨ç¨€ç–è‡ªæŠ•æœºè§£ç åŠ é€Ÿå¤§è§„æ¨¡æ¨ç†æ¨¡å‹**\n> å…³é”®è¯: Speculative Decoding, Reasoning Models, KV-Cache\n\næ¨ç†æ¨¡å‹ï¼ˆReasoning Modelsï¼‰ç”Ÿæˆçš„ CoT å¾ˆé•¿ï¼Œå¯¼è‡´æ¨ç†ä»è®¡ç®—å¯†é›†å‹è½¬å‘å†…å­˜å¯†é›†å‹ï¼ˆMemory-boundï¼‰ã€‚\n- **æ–¹æ³•**ï¼šæå‡º SparseSpecï¼Œä¸€ç§**è‡ªæŠ•æœºï¼ˆSelf-Speculativeï¼‰**æ¡†æ¶ã€‚ä½¿ç”¨åŒä¸€ä¸ªæ¨¡å‹ä½œä¸º Draft å’Œ Targetï¼Œä½†åœ¨ Draft é˜¶æ®µä½¿ç”¨ç¨€ç–æ³¨æ„åŠ›ï¼ˆPillarAttnï¼‰æ¥åŠ é€Ÿã€‚\n- **è´¡çŒ®**ï¼šè®¾è®¡äº†ç»Ÿä¸€çš„è°ƒåº¦å™¨å’ŒåŠ¨æ€ KV-Cache ç®¡ç†ï¼Œå®ç°äº†é«˜è¾¾ **2.13å€** çš„ååé‡æå‡ã€‚\n\n**6. [å¼ºåŒ–å­¦ä¹ ] Rectifying LLM Thought from Lens of Optimization**\n**ä»ä¼˜åŒ–è§†è§’ä¿®æ­£ LLM çš„æ€ç»´**\n> å…³é”®è¯: Chain-of-Thought, RLVR, Process-level Reward\n\né’ˆå¯¹é•¿ CoT æ¨¡å‹å®¹æ˜“â€œè¿‡åº¦æ€è€ƒâ€ï¼ˆOverthinkingï¼‰çš„é—®é¢˜ã€‚\n- **æ–¹æ³•**ï¼šæå‡º ReProï¼Œå°† CoT è§†ä¸ºæ¢¯åº¦ä¸‹é™è¿‡ç¨‹ã€‚å¼•å…¥åŒé‡è¯„åˆ†æœºåˆ¶ï¼ˆå¼ºåº¦å’Œç¨³å®šæ€§ï¼‰ä½œä¸º**è¿‡ç¨‹çº§å¥–åŠ±ï¼ˆProcess-level Rewardï¼‰**ï¼Œé›†æˆåˆ° RLVRï¼ˆå¸¦éªŒè¯å¥–åŠ±çš„ RLï¼‰æµç¨‹ä¸­ã€‚\n- **æ•ˆæœ**ï¼šæœ‰æ•ˆå‡å°‘äº†å†—ä½™çš„æ¨ç†æ­¥éª¤ï¼Œæå‡äº†æ•°å­¦å’Œä»£ç ä»»åŠ¡çš„æ€§èƒ½ã€‚\n\n---\n\n### ğŸ’° é‡‘è Agent ä¸å¤šæ¨¡æ€åº”ç”¨\n\n**7. [é‡‘è Agent] Orchestration Framework for Financial Agents: From Algorithmic Trading to Agentic Trading**\n**é‡‘èæ™ºèƒ½ä½“ç¼–æ’æ¡†æ¶ï¼šä»ç®—æ³•äº¤æ˜“åˆ°æ™ºèƒ½ä½“äº¤æ˜“**\n> æ ¸å¿ƒä½œè€…: Xiao-Yang Liu (Columbia/RPI) ç­‰\n> å…³é”®è¯: Financial Agents, Algorithmic Trading, Multi-Agent\n\n- **è´¡çŒ®**ï¼šæå‡ºäº†ä¸€ä¸ªå°†ä¼ ç»Ÿç®—æ³•äº¤æ˜“ç³»ç»Ÿç»„ä»¶æ˜ å°„ä¸º Agentï¼ˆè§„åˆ’ã€é£æ§ã€æ‰§è¡Œç­‰ï¼‰çš„ç¼–æ’æ¡†æ¶ã€‚\n- **å®æµ‹**ï¼šåœ¨è‚¡ç¥¨äº¤æ˜“ä»»åŠ¡ä¸­ï¼Œå¹´åŒ–å›æŠ¥ 20.42% (Sharpe 2.63)ï¼Œè·‘èµ¢æ ‡æ™®500 (15.97%)ã€‚ä»£ç å·²å¼€æºï¼Œæ—¨åœ¨è®©é‡‘èæ™ºèƒ½å¤§ä¼—åŒ–ã€‚\n\n**8. [Agent å®‰å…¨] TradeTrap: Are LLM-based Trading Agents Truly Reliable and Faithful?**\n**TradeTrapï¼šåŸºäº LLM çš„äº¤æ˜“æ™ºèƒ½ä½“çœŸçš„å¯é å—ï¼Ÿ**\n> å…³é”®è¯: Trading Agents, Robustness, Adversarial Evaluation\n\n- **è­¦ç¤º**ï¼šè™½ç„¶ Agent äº¤æ˜“å¾ˆç«ï¼Œä½†æœ¬æ–‡å‘ç°å®ƒä»¬éå¸¸è„†å¼±ã€‚å¾®å°çš„ç³»ç»Ÿçº§æ‰°åŠ¨ï¼ˆPerturbationsï¼‰ä¼šå¯¼è‡´ Agent å‡ºç°æç«¯æŒä»“é›†ä¸­ã€å¤±æ§çš„é£é™©æ•å£å’Œå·¨é¢å›æ’¤ã€‚\n\n**9. [RAG å®‰å…¨] EmoRAG: Evaluating RAG Robustness to Symbolic Perturbations**\n**EmoRAGï¼šè¯„ä¼° RAG å¯¹ç¬¦å·æ‰°åŠ¨çš„é²æ£’æ€§**\n> å…³é”®è¯: RAG, Adversarial Attack, Emoticons\n\n- **æœ‰è¶£çš„å‘ç°**ï¼šRAG ç³»ç»Ÿå¯¹**è¡¨æƒ…ç¬¦å·ï¼ˆEmoticonsï¼‰**æåº¦æ•æ„Ÿã€‚åœ¨æŸ¥è¯¢ä¸­æ³¨å…¥ä¸€ä¸ªç±»ä¼¼ `(@_@)` çš„é¢œæ–‡å­—ï¼Œä¼šå¯¼è‡´æ£€ç´¢å™¨å‡ ä¹ 100% æ£€ç´¢åˆ°åŒ…å«åŒ¹é…è¡¨æƒ…ä½†è¯­ä¹‰æ— å…³çš„æ–‡æ¡£ï¼Œé€ æˆå›ç­”ç¾éš¾æ€§å´©å¡Œã€‚ä¸”æ¨¡å‹å‚æ•°è¶Šå¤§ï¼Œåè€Œè¶Šè„†å¼±ã€‚\n\n---\n\n### ğŸ‘ï¸ è§†è§‰ä¸å¤šæ¨¡æ€\n\n**10. [å¤šæ¨¡æ€è¯„æµ‹] See, Hear, and Understand: Benchmarking Audiovisual Human Speech Understanding**\n**çœ‹ã€å¬ã€æ‡‚ï¼šå¤šæ¨¡æ€å¤§æ¨¡å‹è§†å¬äººç±»è¯­éŸ³ç†è§£åŸºå‡†**\n> å…³é”®è¯: MLLM, Audiovisual, Benchmark\n\n- **èƒŒæ™¯**ï¼šç°æœ‰çš„è§†é¢‘åŸºå‡†æµ‹è¯•å¾ˆå°‘ç»†è‡´è¯„ä¼°â€œè°åœ¨è¯´è¯ã€è¯´äº†ä»€ä¹ˆã€ä½•æ—¶è¯´çš„â€ã€‚\n- **è´¡çŒ®**ï¼šå‘å¸ƒ AV-SpeakerBenchã€‚\n- **ç»“æœ**ï¼š**Gemini 2.5 Pro** (è®ºæ–‡ä¸­æåˆ°çš„æ–°ç‰ˆæœ¬) è¡¨ç°æœ€å¥½ã€‚å¼€æºæ¨¡å‹ä¸­ï¼ŒQwen3-Omni-30B æ¥è¿‘ Gemini 2.0 Flashï¼Œä½†åœ¨è§†å¬èåˆä¸Šä»æœ‰å·®è·ã€‚\n\n**11. [è§†é¢‘ä¿®å¤] Progressive Image Restoration via Text-Conditioned Video Generation**\n**åŸºäºæ–‡æœ¬æ¡ä»¶è§†é¢‘ç”Ÿæˆçš„æ¸è¿›å¼å›¾åƒä¿®å¤**\n> å…³é”®è¯: Image Restoration, Video Generation, CogVideo\n\n- **è„‘æ´**ï¼šåˆ©ç”¨æ–‡ç”Ÿè§†é¢‘æ¨¡å‹ï¼ˆCogVideoï¼‰æ¥åšå›¾åƒä¿®å¤ã€‚\n- **æ–¹æ³•**ï¼šå°†å›¾åƒä¿®å¤çœ‹ä½œä¸€ä¸ªè§†é¢‘ç”Ÿæˆè¿‡ç¨‹ï¼ˆä»æ¨¡ç³Š/æŸå -> æ¸…æ™°çš„æ¸å˜è¿‡ç¨‹ï¼‰ã€‚å¾®è°ƒ CogVideo ç”Ÿæˆä¿®å¤è½¨è¿¹ï¼Œåˆ©ç”¨å…¶æ—¶é—´ä¸€è‡´æ€§æ¥æ¢å¤ç©ºé—´ç»†èŠ‚ã€‚\n\n---\n\n### ğŸ”¬ å…¶ä»–å€¼å¾—å…³æ³¨çš„è®ºæ–‡\n\n*   **[åŒ»ç–—] Enhancing Lung Cancer Treatment Outcome Prediction... (Paper 1)**: æ¢…å¥¥è¯Šæ‰€å›¢é˜Ÿå·¥ä½œã€‚ä¸ç›´æ¥ç”¨ LLM é¢„æµ‹ï¼Œè€Œæ˜¯ç”¨ LLM ä½œä¸º**çŸ¥è¯†ç­–å±•äºº (Goal-oriented Knowledge Curators)** æ¥å¤„ç†æ‚ä¹±çš„ä¸´åºŠæ•°æ®ï¼Œæå–ç‰¹å¾åå†å–‚ç»™é¢„æµ‹æ¨¡å‹ï¼Œæ•ˆæœä¼˜äºç«¯åˆ°ç«¯ Transformerã€‚\n*   **[ç³»ç»Ÿ] Tangram: Accelerating Serverless LLM Loading... (Paper 109)**: é’ˆå¯¹ Serverless LLM çš„å†·å¯åŠ¨é—®é¢˜ï¼Œé€šè¿‡ GPU æ˜¾å­˜é‡ç”¨å’Œäº²å’Œæ€§è°ƒåº¦ï¼Œå°†åŠ è½½é€Ÿåº¦æå‡ 6.2 å€ã€‚\n*   **[ç¤¾ä¼šå½±å“] Humanity in the Age of AI: Reassessing 2025's Existential-Risk Narratives (Paper 29)**: ä¸€ç¯‡åæ€æ€§æ–‡ç« ã€‚è®¤ä¸º 2025 å¹´å…³äºâ€œAI ç­ç»äººç±»â€çš„è®ºè°ƒä¸»è¦æ˜¯ä¸ºäº†æ©ç›–ç›‘æ§èµ„æœ¬ä¸»ä¹‰å’Œç®—åŠ›å„æ–­ï¼Œç›®å‰çš„æ¨¡å‹ä¾ç„¶æ˜¯ç»Ÿè®¡å­¦äº§ç‰©ï¼Œä¸å…·å¤‡æ¯ç­äººç±»çš„é€’å½’è‡ªæˆ‘æ”¹è¿›èƒ½åŠ›ã€‚\n*   **[å¿ƒç†] Do Large Language Models Walk Their Talk? (Paper 80)**: ç ”ç©¶å‘ç° LLM æ™®éâ€œä¼ªå–„â€ã€‚å®ƒä»¬åœ¨è‡ªæˆ‘æŠ¥å‘Šä¸­å£°ç§°è‡ªå·±éå¸¸åˆ©ä»–ï¼ˆ77.5%ï¼‰ï¼Œä½†å®é™…è¡Œä¸ºæµ‹è¯•ä¸­åˆ©ä»–æ¯”ä¾‹è¾ƒä½ï¼ˆ65.6%ï¼‰ï¼Œå­˜åœ¨â€œç¾å¾·ä¿¡å·å·®è·â€ã€‚",
  "papers": [
    {
      "arxiv_id": "2512.20633v1",
      "title": "Enhancing Lung Cancer Treatment Outcome Prediction through Semantic Feature Engineering Using Large Language Models",
      "title_zh": "åˆ©ç”¨å¤§è¯­è¨€æ¨¡å‹è¯­ä¹‰ç‰¹å¾å·¥ç¨‹æå‡è‚ºç™Œç–—æ•ˆé¢„æµ‹",
      "authors": [
        "MunHwan Lee",
        "Shaika Chowdhury",
        "Xiaodi Li",
        "Sivaraman Rajaganapathy",
        "Eric W Klee",
        "Ping Yang",
        "Terence Sio",
        "Liewei Wang",
        "James Cerhan",
        "Nansu NA Zong"
      ],
      "abstract": "Accurate prediction of treatment outcomes in lung cancer remains challenging due to the sparsity, heterogeneity, and contextual overload of real-world electronic health data. Traditional models often fail to capture semantic information across multimodal streams, while large-scale fine-tuning approaches are impractical in clinical workflows. We introduce a framework that uses Large Language Models (LLMs) as Goal-oriented Knowledge Curators (GKC) to convert laboratory, genomic, and medication data into high-fidelity, task-aligned features. Unlike generic embeddings, GKC produces representations tailored to the prediction objective and operates as an offline preprocessing step that integrates naturally into hospital informatics pipelines. Using a lung cancer cohort (N=184), we benchmarked GKC against expert-engineered features, direct text embeddings, and an end-to-end transformer. Our approach achieved a mean AUROC of 0.803 (95% CI: 0.799-0.807) and outperformed all baselines. An ablation study further confirmed the complementary value of combining all three modalities. These results show that the quality of semantic representation is a key determinant of predictive accuracy in sparse clinical data settings. By reframing LLMs as knowledge curation engines rather than black-box predictors, this work demonstrates a scalable, interpretable, and workflow-compatible pathway for advancing AI-driven decision support in oncology.",
      "tldr_zh": "è¯¥ç ”ç©¶é’ˆå¯¹çœŸå®ä¸–ç•Œç”µå­å¥åº·æ•°æ®ä¸­å­˜åœ¨çš„ç¨€ç–æ€§ã€å¼‚è´¨æ€§å’Œä¸Šä¸‹æ–‡è¿‡è½½å¯¼è‡´è‚ºç™Œæ²»ç–—æ•ˆæœé¢„æµ‹å›°éš¾çš„é—®é¢˜ï¼Œæå‡ºäº†ä¸€ç§åˆ©ç”¨å¤§è¯­è¨€æ¨¡å‹ (Large Language Models, LLMs) è¿›è¡Œè¯­ä¹‰ç‰¹å¾å·¥ç¨‹çš„æ¡†æ¶ã€‚è¯¥æ¡†æ¶å°† LLMs ä½œä¸ºç›®æ ‡å¯¼å‘çŸ¥è¯†ç­–å±•äºº (Goal-oriented Knowledge Curators, GKC)ï¼Œå°†å®éªŒå®¤æ•°æ®ã€åŸºå› ç»„æ•°æ®å’Œç”¨è¯ä¿¡æ¯è½¬åŒ–ä¸ºé«˜ä¿çœŸä¸”ä¸ä»»åŠ¡å¯¹é½çš„ç‰¹å¾ã€‚ä¸é€šç”¨çš„åµŒå…¥å‘é‡ä¸åŒï¼ŒGKC ç”Ÿæˆçš„è¡¨ç¤ºæ˜¯ä¸“ä¸ºé¢„æµ‹ç›®æ ‡å®šåˆ¶çš„ï¼Œå¹¶ä½œä¸ºç¦»çº¿é¢„å¤„ç†æ­¥éª¤é›†æˆåˆ°åŒ»é™¢ä¿¡æ¯åŒ–å·¥ä½œæµä¸­ã€‚åœ¨ 184 åè‚ºç™Œæ‚£è€…çš„é˜Ÿåˆ—ç ”ç©¶ä¸­ï¼Œè¯¥æ–¹æ³•è¾¾åˆ°äº† 0.803 çš„å¹³å‡ AUROCï¼Œæ˜¾è‘—ä¼˜äºä¸“å®¶è®¾è®¡ç‰¹å¾ã€ç›´æ¥æ–‡æœ¬åµŒå…¥å’Œç«¯åˆ°ç«¯ Transformer ç­‰åŸºçº¿æ¨¡å‹ã€‚æ¶ˆèç ”ç©¶è¿›ä¸€æ­¥è¯å®äº†ç»“åˆä¸‰ç§æ¨¡æ€æ•°æ®çš„äº’è¡¥ä»·å€¼ï¼Œè¯æ˜äº†è¯­ä¹‰è¡¨ç¤ºè´¨é‡æ˜¯æå‡ç¨€ç–ä¸´åºŠæ•°æ®é¢„æµ‹å‡†ç¡®æ€§çš„å…³é”®ã€‚é€šè¿‡å°† LLMs é‡å¡‘ä¸ºçŸ¥è¯†ç­–å±•å¼•æ“è€Œéé»‘ç›’é¢„æµ‹å™¨ï¼Œè¯¥å·¥ä½œä¸ºè‚¿ç˜¤å­¦ AI å†³ç­–æ”¯æŒæä¾›äº†ä¸€æ¡å¯æ‰©å±•ã€å¯è§£é‡Šä¸”ç¬¦åˆä¸´åºŠå·¥ä½œæµçš„è·¯å¾„ã€‚",
      "categories": [
        "cs.LG",
        "cs.AI"
      ],
      "primary_category": "cs.LG",
      "comment": "",
      "pdf_url": "https://arxiv.org/pdf/2512.20633v1",
      "published_date": "2025-12-01 23:56:45 UTC",
      "updated_date": "2025-12-01 23:56:45 UTC",
      "processing_status": "completed",
      "attempts": 1,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "llm_backup_calls": 0,
      "last_update": "2026-01-26T12:21:08.576657+00:00"
    },
    {
      "arxiv_id": "2512.02283v1",
      "title": "Model Recovery at the Edge under Resource Constraints for Physical AI",
      "title_zh": "ç‰©ç†äººå·¥æ™ºèƒ½åœ¨èµ„æºçº¦æŸä¸‹çš„è¾¹ç¼˜ç«¯æ¨¡å‹æ¢å¤",
      "authors": [
        "Bin Xu",
        "Ayan Banerjee",
        "Sandeep K. S. Gupta"
      ],
      "abstract": "Model Recovery (MR) enables safe, explainable decision making in mission-critical autonomous systems (MCAS) by learning governing dynamical equations, but its deployment on edge devices is hindered by the iterative nature of neural ordinary differential equations (NODEs), which are inefficient on FPGAs. Memory and energy consumption are the main concerns when applying MR on edge devices for real-time operation. We propose MERINDA, a novel FPGA-accelerated MR framework that replaces iterative solvers with a parallelizable neural architecture equivalent to NODEs. MERINDA achieves nearly 11x lower DRAM usage and 2.2x faster runtime compared to mobile GPUs. Experiments reveal an inverse relationship between memory and energy at fixed accuracy, highlighting MERINDA's suitability for resource-constrained, real-time MCAS.",
      "tldr_zh": "è¯¥ç ”ç©¶é’ˆå¯¹ç‰©ç†äººå·¥æ™ºèƒ½(Physical AI)åœ¨è¾¹ç¼˜è®¾å¤‡éƒ¨ç½²æ—¶é¢ä¸´çš„èµ„æºé™åˆ¶ï¼Œæå‡ºäº†åä¸ºMERINDAçš„FPGAåŠ é€Ÿæ¨¡å‹æ¢å¤(Model Recovery)æ¡†æ¶ã€‚ä¸ºäº†è§£å†³å…³é”®ä»»åŠ¡è‡ªä¸»ç³»ç»Ÿ(MCAS)ä¸­ç¥ç»å¸¸å¾®åˆ†æ–¹ç¨‹(Neural ODEs)å› è¿­ä»£è®¡ç®—å¯¼è‡´åœ¨FPGAä¸Šæ•ˆç‡ä½ä¸‹çš„é—®é¢˜ï¼ŒMERINDAå¼•å…¥äº†ä¸€ç§ç­‰æ•ˆäºNODEsä¸”å¯å¹¶è¡ŒåŒ–çš„ç¥ç»æ¶æ„æ¥å–ä»£ä¼ ç»Ÿçš„è¿­ä»£æ±‚è§£å™¨ã€‚å®éªŒç»“æœè¡¨æ˜ï¼Œä¸ç§»åŠ¨ç«¯GPUç›¸æ¯”ï¼ŒMERINDAçš„DRAMå ç”¨é™ä½äº†è¿‘11å€ï¼Œè¿è¡Œé€Ÿåº¦æå‡äº†2.2å€ã€‚ç ”ç©¶è¿˜è¿›ä¸€æ­¥æ­ç¤ºäº†åœ¨å›ºå®šç²¾åº¦ä¸‹å†…å­˜ä¸èƒ½è€—ä¹‹é—´çš„åæ¯”å…³ç³»ï¼ŒéªŒè¯äº†è¯¥æ¡†æ¶åœ¨èµ„æºå—é™çš„å®æ—¶MCASç¯å¢ƒä¸­çš„é«˜æ•ˆæ€§ä¸é€‚ç”¨æ€§ã€‚",
      "categories": [
        "cs.AI"
      ],
      "primary_category": "cs.AI",
      "comment": "Published in ECAI 2025, Frontiers in Artificial Intelligence and Applications, volume 413, pages 3904-3911",
      "pdf_url": "https://arxiv.org/pdf/2512.02283v1",
      "published_date": "2025-12-01 23:54:23 UTC",
      "updated_date": "2025-12-01 23:54:23 UTC",
      "processing_status": "completed",
      "attempts": 1,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "llm_backup_calls": 0,
      "last_update": "2026-01-26T12:21:13.271323+00:00"
    },
    {
      "arxiv_id": "2512.02282v1",
      "title": "DialogGuard: Multi-Agent Psychosocial Safety Evaluation of Sensitive LLM Responses",
      "title_zh": "DialogGuardï¼šé’ˆå¯¹å¤§è¯­è¨€æ¨¡å‹æ•æ„Ÿå›å¤çš„å¤šæ™ºèƒ½ä½“å¿ƒç†ç¤¾ä¼šå®‰å…¨è¯„ä¼°",
      "authors": [
        "Han Luo",
        "Guy Laban"
      ],
      "abstract": "Large language models (LLMs) now mediate many web-based mental-health, crisis, and other emotionally sensitive services, yet their psychosocial safety in these settings remains poorly understood and weakly evaluated. We present DialogGuard, a multi-agent framework for assessing psychosocial risks in LLM-generated responses along five high-severity dimensions: privacy violations, discriminatory behaviour, mental manipulation, psychological harm, and insulting behaviour. DialogGuard can be applied to diverse generative models through four LLM-as-a-judge pipelines, including single-agent scoring, dual-agent correction, multi-agent debate, and stochastic majority voting, grounded in a shared three-level rubric usable by both human annotators and LLM judges. Using PKU-SafeRLHF with human safety annotations, we show that multi-agent mechanisms detect psychosocial risks more accurately than non-LLM baselines and single-agent judging; dual-agent correction and majority voting provide the best trade-off between accuracy, alignment with human ratings, and robustness, while debate attains higher recall but over-flags borderline cases. We release Dialog-Guard as open-source software with a web interface that provides per-dimension risk scores and explainable natural-language rationales. A formative study with 12 practitioners illustrates how it supports prompt design, auditing, and supervision of web-facing applications for vulnerable users.",
      "tldr_zh": "è¯¥ç ”ç©¶æå‡ºäº†DialogGuardï¼Œè¿™æ˜¯ä¸€ä¸ªä¸“é—¨ç”¨äºè¯„ä¼°å¤§å‹è¯­è¨€æ¨¡å‹(LLMs)åœ¨å¿ƒç†å¥åº·å’Œå±æœºå¹²é¢„ç­‰æ•æ„Ÿåœºæ™¯ä¸‹å¿ƒç†ç¤¾ä¼šå®‰å…¨(Psychosocial safety)é£é™©çš„å¤šæ™ºèƒ½ä½“æ¡†æ¶ã€‚DialogGuardä»éšç§æ³„éœ²ã€æ­§è§†è¡Œä¸ºã€ç²¾ç¥æ“çºµã€å¿ƒç†ä¼¤å®³å’Œä¾®è¾±æ€§è¡Œä¸ºäº”ä¸ªå…³é”®ç»´åº¦è¿›è¡Œæ£€æµ‹ï¼Œå¹¶è®¾è®¡äº†åŒ…æ‹¬å•æ™ºèƒ½ä½“è¯„åˆ†(Single-agent scoring)ã€åŒæ™ºèƒ½ä½“çº æ­£(Dual-agent correction)ã€å¤šæ™ºèƒ½ä½“è¾©è®º(Multi-agent debate)å’Œéšæœºå¤šæ•°æŠ•ç¥¨(Stochastic majority voting)åœ¨å†…çš„å››ç§LLM-as-a-judgeæµæ°´çº¿ã€‚å®éªŒè¡¨æ˜ï¼Œå¤šæ™ºèƒ½ä½“æœºåˆ¶åœ¨é£é™©æ£€æµ‹çš„å‡†ç¡®æ€§ä¸Šæ˜¾è‘—ä¼˜äºå•æ™ºèƒ½ä½“å’Œä¼ ç»ŸåŸºçº¿æ¨¡å‹ã€‚ç ”ç©¶å‘ç°åŒæ™ºèƒ½ä½“çº æ­£å’Œå¤šæ•°æŠ•ç¥¨åœ¨å‡†ç¡®æ€§ã€äººç±»è¯„åˆ†ä¸€è‡´æ€§(Alignment)ä¸é²æ£’æ€§ä¹‹é—´å–å¾—äº†æœ€ä½³å¹³è¡¡ï¼Œè€Œè¾©è®ºæœºåˆ¶è™½ç„¶å…·æœ‰æ›´é«˜çš„å¬å›ç‡ï¼Œä½†å­˜åœ¨è¿‡åº¦æ ‡æ³¨è¾¹ç•Œæ¡ˆä¾‹çš„å€¾å‘ã€‚è¯¥æ¡†æ¶å·²å¼€æºå¹¶æä¾›å¯è§†åŒ–Webç•Œé¢å’Œå¯è§£é‡Šçš„è‡ªç„¶è¯­è¨€æ¨ç†ï¼Œé€šè¿‡å¯¹12åä»ä¸šè€…çš„è°ƒç ”ï¼Œè¯æ˜äº†å…¶åœ¨æ”¯æŒæç¤ºè®¾è®¡ã€å®¡è®¡å’Œå¼±åŠ¿ç”¨æˆ·åº”ç”¨ç›‘ç®¡æ–¹é¢çš„æœ‰æ•ˆæ€§ã€‚",
      "categories": [
        "cs.AI",
        "cs.HC",
        "cs.MA"
      ],
      "primary_category": "cs.AI",
      "comment": "",
      "pdf_url": "https://arxiv.org/pdf/2512.02282v1",
      "published_date": "2025-12-01 23:53:45 UTC",
      "updated_date": "2025-12-01 23:53:45 UTC",
      "processing_status": "completed",
      "attempts": 1,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "llm_backup_calls": 0,
      "last_update": "2026-01-26T12:21:12.475171+00:00"
    },
    {
      "arxiv_id": "2512.02280v1",
      "title": "Bridging the Gap: Toward Cognitive Autonomy in Artificial Intelligence",
      "title_zh": "å¼¥åˆå·®è·ï¼šè¿ˆå‘äººå·¥æ™ºèƒ½çš„è®¤çŸ¥è‡ªä¸»",
      "authors": [
        "Noorbakhsh Amiri Golilarz",
        "Sindhuja Penchala",
        "Shahram Rahimi"
      ],
      "abstract": "Artificial intelligence has advanced rapidly across perception, language, reasoning, and multimodal domains. Yet despite these achievements, modern AI systems remain fundamentally limited in their ability to self-monitor, self-correct, and regulate their behavior autonomously in dynamic contexts. This paper identifies and analyzes seven core deficiencies that constrain contemporary AI models: the absence of intrinsic self-monitoring, lack of meta-cognitive awareness, fixed and non-adaptive learning mechanisms, inability to restructure goals, lack of representational maintenance, insufficient embodied feedback, and the absence of intrinsic agency. Alongside identifying these limitations, we also outline a forward-looking perspective on how AI may evolve beyond them through architectures that mirror neurocognitive principles. We argue that these structural limitations prevent current architectures, including deep learning and transformer-based systems, from achieving robust generalization, lifelong adaptability, and real-world autonomy. Drawing on a comparative analysis of artificial systems and biological cognition [7], and integrating insights from AI research, cognitive science, and neuroscience, we outline how these capabilities are absent in current models and why scaling alone cannot resolve them. We conclude by advocating for a paradigmatic shift toward cognitively grounded AI (cognitive autonomy) capable of self-directed adaptation, dynamic representation management, and intentional, goal-oriented behavior, paired with reformative oversight mechanisms [8] that ensure autonomous systems remain interpretable, governable, and aligned with human values.",
      "tldr_zh": "è¯¥ç ”ç©¶æ¢è®¨äº†ç°ä»£äººå·¥æ™ºèƒ½åœ¨æ„ŸçŸ¥ä¸æ¨ç†é¢†åŸŸå–å¾—è¿›å±•çš„åŒæ—¶ï¼Œåœ¨åŠ¨æ€ç¯å¢ƒä¸‹å®ç°è‡ªæˆ‘ç›‘ç£ã€è‡ªæˆ‘ä¿®æ­£åŠè‡ªä¸»è°ƒèŠ‚è¡Œä¸ºæ–¹é¢çš„æœ¬è´¨å±€é™ã€‚è®ºæ–‡è¯†åˆ«å¹¶åˆ†æäº†åˆ¶çº¦å½“ä»£AIæ¨¡å‹çš„ä¸ƒé¡¹æ ¸å¿ƒç¼ºé™·ï¼ŒåŒ…æ‹¬ç¼ºä¹å†…åœ¨è‡ªæˆ‘ç›‘æ§(intrinsic self-monitoring)ã€å…ƒè®¤çŸ¥æ„è¯†(meta-cognitive awareness)ã€è‡ªé€‚åº”å­¦ä¹ æœºåˆ¶ä»¥åŠé‡æ„ç›®æ ‡çš„èƒ½åŠ›ç­‰ã€‚é€šè¿‡å¯¹äººå·¥ç³»ç»Ÿä¸ç”Ÿç‰©è®¤çŸ¥çš„å¯¹æ¯”åˆ†æï¼Œä½œè€…æŒ‡å‡ºå½“å‰çš„æ·±åº¦å­¦ä¹ ä¸Transformeræ¶æ„åœ¨å®ç°é²æ£’æ³›åŒ–ä¸ç°å®ä¸–ç•Œè‡ªä¸»æ€§(real-world autonomy)æ–¹é¢å­˜åœ¨ç»“æ„æ€§éšœç¢ï¼Œä¸”å•çº¯çš„è§„æ¨¡æ‰©å¼ (scaling)æ— æ³•ä»æ ¹æœ¬ä¸Šè§£å†³è¿™äº›é—®é¢˜ã€‚æ–‡ç« å€¡å¯¼å‘å…·å¤‡è®¤çŸ¥è‡ªä¸»(cognitive autonomy)çš„AIèŒƒå¼è½¬å˜ï¼Œå»ºè®®æ„å»ºæ¨¡æ‹Ÿç¥ç»è®¤çŸ¥åŸç†(neurocognitive principles)çš„æ¶æ„ï¼Œä»¥æ”¯æŒè‡ªæˆ‘å¼•å¯¼çš„é€‚åº”ã€åŠ¨æ€è¡¨å¾ç®¡ç†å’Œæœ‰æ„çš„ç›®æ ‡å¯¼å‘è¡Œä¸ºã€‚ç ”ç©¶æœ€åå¼ºè°ƒï¼Œå¿…é¡»å»ºç«‹æ”¹é©æ€§çš„ç›‘ç£æœºåˆ¶ï¼Œç¡®ä¿è¿™äº›é«˜åº¦è‡ªä¸»çš„ç³»ç»Ÿåœ¨ä¿æŒå¯è§£é‡Šæ€§ä¸å¯æ²»ç†æ€§çš„åŒæ—¶ï¼Œä¸äººç±»ä»·å€¼è§‚å®ç°å¯¹é½ã€‚",
      "categories": [
        "cs.AI",
        "cs.CV"
      ],
      "primary_category": "cs.AI",
      "comment": "",
      "pdf_url": "https://arxiv.org/pdf/2512.02280v1",
      "published_date": "2025-12-01 23:51:08 UTC",
      "updated_date": "2025-12-01 23:51:08 UTC",
      "processing_status": "completed",
      "attempts": 1,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "llm_backup_calls": 0,
      "last_update": "2026-01-26T12:21:24.274140+00:00"
    },
    {
      "arxiv_id": "2512.02273v1",
      "title": "Progressive Image Restoration via Text-Conditioned Video Generation",
      "title_zh": "åŸºäºæ–‡æœ¬å¼•å¯¼è§†é¢‘ç”Ÿæˆçš„æ¸è¿›å¼å›¾åƒä¿®å¤",
      "authors": [
        "Peng Kang",
        "Xijun Wang",
        "Yu Yuan"
      ],
      "abstract": "Recent text-to-video models have demonstrated strong temporal generation capabilities, yet their potential for image restoration remains underexplored. In this work, we repurpose CogVideo for progressive visual restoration tasks by fine-tuning it to generate restoration trajectories rather than natural video motion. Specifically, we construct synthetic datasets for super-resolution, deblurring, and low-light enhancement, where each sample depicts a gradual transition from degraded to clean frames. Two prompting strategies are compared: a uniform text prompt shared across all samples, and a scene-specific prompting scheme generated via LLaVA multi-modal LLM and refined with ChatGPT. Our fine-tuned model learns to associate temporal progression with restoration quality, producing sequences that improve perceptual metrics such as PSNR, SSIM, and LPIPS across frames. Extensive experiments show that CogVideo effectively restores spatial detail and illumination consistency while maintaining temporal coherence. Moreover, the model generalizes to real-world scenarios on the ReLoBlur dataset without additional training, demonstrating strong zero-shot robustness and interpretability through temporal restoration.",
      "tldr_zh": "è¯¥ç ”ç©¶æ¢ç´¢äº†æ–‡æœ¬è½¬è§†é¢‘(text-to-video)æ¨¡å‹åœ¨å›¾åƒä¿®å¤é¢†åŸŸçš„æ½œåŠ›ï¼Œé€šè¿‡å¾®è°ƒCogVideoå°†è§†é¢‘ç”Ÿæˆè½¨è¿¹ä»æ¨¡æ‹Ÿè‡ªç„¶è¿åŠ¨è½¬å˜ä¸ºæ¸è¿›å¼çš„ä¿®å¤è¿‡ç¨‹ã€‚ç ”ç©¶è€…é’ˆå¯¹è¶…åˆ†è¾¨ç‡ã€å»æ¨¡ç³Šå’Œä½å…‰å¢å¼ºä»»åŠ¡æ„å»ºäº†åˆæˆæ•°æ®é›†ï¼Œä½¿æ¨¡å‹å­¦ä¹ ä»é€€åŒ–å›¾åƒåˆ°æ¸…æ™°å›¾åƒçš„å¹³æ»‘è½¬å˜ã€‚æ–‡ä¸­å¯¹æ¯”äº†ç»Ÿä¸€æ–‡æœ¬æç¤ºä¸åˆ©ç”¨LLaVAå’ŒChatGPTç”Ÿæˆçš„åœºæ™¯ç‰¹å®šæç¤ºç­–ç•¥ï¼Œä»¥ä¼˜åŒ–ä¿®å¤æ•ˆæœã€‚å®éªŒç»“æœè¡¨æ˜ï¼Œè¯¥æ¨¡å‹åœ¨PSNRã€SSIMå’ŒLPIPSç­‰æ„ŸçŸ¥æŒ‡æ ‡ä¸Šè¡¨ç°ä¼˜å¼‚ï¼Œèƒ½å¤Ÿæœ‰æ•ˆæ¢å¤ç©ºé—´ç»†èŠ‚å¹¶ä¿æŒå…‰ç…§ä¸€è‡´æ€§ã€‚æ­¤å¤–ï¼Œè¯¥æ–¹æ³•åœ¨ReLoBlurçœŸå®åœºæ™¯æ•°æ®é›†ä¸Šå±•ç°å‡ºå¼ºå¤§çš„é›¶æ ·æœ¬(zero-shot)é²æ£’æ€§å’Œé«˜åº¦çš„å¯è§£é‡Šæ€§ï¼Œè¯æ˜äº†åˆ©ç”¨è§†é¢‘æ—¶é—´ç»´åº¦è¿›è¡Œå›¾åƒä¿®å¤çš„æœ‰æ•ˆæ€§ã€‚",
      "categories": [
        "cs.CV",
        "cs.AI"
      ],
      "primary_category": "cs.CV",
      "comment": "First two authors contributed equally to this work. IEEE ICNC Accepted",
      "pdf_url": "https://arxiv.org/pdf/2512.02273v1",
      "published_date": "2025-12-01 23:37:51 UTC",
      "updated_date": "2025-12-01 23:37:51 UTC",
      "processing_status": "completed",
      "attempts": 1,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "llm_backup_calls": 0,
      "last_update": "2026-01-26T12:21:14.773656+00:00"
    },
    {
      "arxiv_id": "2512.02268v1",
      "title": "Spatiotemporal Pyramid Flow Matching for Climate Emulation",
      "title_zh": "ç”¨äºæ°”å€™ä»¿çœŸçš„æ—¶ç©ºé‡‘å­—å¡”æµåŒ¹é…",
      "authors": [
        "Jeremy Andrew Irvin",
        "Jiaqi Han",
        "Zikui Wang",
        "Abdulaziz Alharbi",
        "Yufei Zhao",
        "Nomin-Erdene Bayarsaikhan",
        "Daniele Visioni",
        "Andrew Y. Ng",
        "Duncan Watson-Parris"
      ],
      "abstract": "Generative models have the potential to transform the way we emulate Earth's changing climate. Previous generative approaches rely on weather-scale autoregression for climate emulation, but this is inherently slow for long climate horizons and has yet to demonstrate stable rollouts under nonstationary forcings. Here, we introduce Spatiotemporal Pyramid Flows (SPF), a new class of flow matching approaches that model data hierarchically across spatial and temporal scales. Inspired by cascaded video models, SPF partitions the generative trajectory into a spatiotemporal pyramid, progressively increasing spatial resolution to reduce computation and coupling each stage with an associated timescale to enable direct sampling at any temporal level in the pyramid. This design, together with conditioning each stage on prescribed physical forcings (e.g., greenhouse gases or aerosols), enables efficient, parallel climate emulation at multiple timescales. On ClimateBench, SPF outperforms strong flow matching baselines and pre-trained models at yearly and monthly timescales while offering fast sampling, especially at coarser temporal levels. To scale SPF, we curate ClimateSuite, the largest collection of Earth system simulations to date, comprising over 33,000 simulation-years across ten climate models and the first dataset to include simulations of climate interventions. We find that the scaled SPF model demonstrates good generalization to held-out scenarios across climate models. Together, SPF and ClimateSuite provide a foundation for accurate, efficient, probabilistic climate emulation across temporal scales and realistic future scenarios. Data and code is publicly available at https://github.com/stanfordmlgroup/spf .",
      "tldr_zh": "è¯¥ç ”ç©¶æå‡ºäº†Spatiotemporal Pyramid Flows (SPF)ï¼Œä¸€ç§æ–°å‹çš„Flow Matchingæ–¹æ³•ï¼Œæ—¨åœ¨è§£å†³ä¼ ç»Ÿç”Ÿæˆå¼æ°”å€™æ¨¡æ‹Ÿä¸­è‡ªå›å½’æ¨¡å‹é‡‡æ ·é€Ÿåº¦æ…¢ä¸”åœ¨éå¹³ç¨³å¼ºè¿«ä¸‹è¡¨ç°ä¸ç¨³çš„é—®é¢˜ã€‚SPFå€Ÿé‰´äº†çº§è”è§†é¢‘æ¨¡å‹çš„è®¾è®¡æ€è·¯ï¼Œé€šè¿‡æ—¶ç©ºé‡‘å­—å¡”(Spatiotemporal Pyramid)ç»“æ„å¯¹æ•°æ®è¿›è¡Œå±‚æ¬¡åŒ–å»ºæ¨¡ï¼Œåœ¨é€æ­¥æå‡ç©ºé—´åˆ†è¾¨ç‡çš„åŒæ—¶è€¦åˆç›¸åº”çš„æ—¶é—´å°ºåº¦ï¼Œå®ç°äº†åœ¨ä»»ä½•æ—¶é—´å±‚çº§çš„ç›´æ¥é‡‡æ ·ã€‚è¯¥æ¨¡å‹é€šè¿‡å°†æ¯ä¸€é˜¶æ®µä¸æ¸©å®¤æ°”ä½“æˆ–æ°”æº¶èƒ¶ç­‰ç‰©ç†å¼ºè¿«(Physical Forcings)ç›¸ç»“åˆï¼Œæ”¯æŒåœ¨å¤šæ—¶é—´å°ºåº¦ä¸Šè¿›è¡Œé«˜æ•ˆçš„å¹¶è¡Œæ°”å€™æ¨¡æ‹Ÿã€‚ä¸ºäº†æ‰©å±•SPFçš„æ€§èƒ½ï¼Œç ”ç©¶å›¢é˜Ÿæ„å»ºäº†ç›®å‰è§„æ¨¡æœ€å¤§çš„åœ°çƒç³»ç»Ÿæ¨¡æ‹Ÿæ•°æ®é›†ClimateSuiteï¼Œæ¶µç›–äº†10ä¸ªæ°”å€™æ¨¡å‹è¶…è¿‡33,000ä¸ªæ¨¡æ‹Ÿå¹´çš„æ•°æ®ï¼Œå¹¶é¦–æ¬¡åŒ…å«äº†æ°”å€™å¹²é¢„æ¨¡æ‹Ÿã€‚å®éªŒç»“æœè¡¨æ˜ï¼ŒSPFåœ¨ClimateBenchåŸºå‡†æµ‹è¯•çš„å¹´åº¦å’Œæœˆåº¦å°ºåº¦ä¸Šå‡ä¼˜äºç°æœ‰çš„Flow MatchingåŸºçº¿æ¨¡å‹ï¼Œä¸”å…·æœ‰æ›´å¿«çš„é‡‡æ ·é€Ÿåº¦ã€‚æ­¤å¤–ï¼Œå¤§è§„æ¨¡é¢„è®­ç»ƒåçš„SPFå±•ç°å‡ºè‰¯å¥½çš„æ³›åŒ–èƒ½åŠ›ï¼Œä¸ºåœ¨ç°å®æœªæ¥æƒ…å¢ƒä¸‹è¿›è¡Œå‡†ç¡®ã€é«˜æ•ˆä¸”å…·æœ‰æ¦‚ç‡æ€§çš„æ°”å€™æ¨¡æ‹Ÿå¥ å®šäº†åŸºç¡€ã€‚",
      "categories": [
        "cs.CV",
        "cs.AI",
        "cs.LG",
        "eess.IV",
        "stat.ML"
      ],
      "primary_category": "cs.CV",
      "comment": "",
      "pdf_url": "https://arxiv.org/pdf/2512.02268v1",
      "published_date": "2025-12-01 23:20:03 UTC",
      "updated_date": "2025-12-01 23:20:03 UTC",
      "processing_status": "completed",
      "attempts": 1,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "llm_backup_calls": 0,
      "last_update": "2026-01-26T12:22:25.051018+00:00"
    },
    {
      "arxiv_id": "2512.02261v1",
      "title": "TradeTrap: Are LLM-based Trading Agents Truly Reliable and Faithful?",
      "title_zh": "TradeTrapï¼šåŸºäºå¤§è¯­è¨€æ¨¡å‹çš„äº¤æ˜“æ™ºèƒ½ä½“æ˜¯å¦çœŸæ­£å¯é ä¸”å¿ å®ï¼Ÿ",
      "authors": [
        "Lewen Yan",
        "Jilin Mei",
        "Tianyi Zhou",
        "Lige Huang",
        "Jie Zhang",
        "Dongrui Liu",
        "Jing Shao"
      ],
      "abstract": "LLM-based trading agents are increasingly deployed in real-world financial markets to perform autonomous analysis and execution. However, their reliability and robustness under adversarial or faulty conditions remain largely unexamined, despite operating in high-risk, irreversible financial environments. We propose TradeTrap, a unified evaluation framework for systematically stress-testing both adaptive and procedural autonomous trading agents. TradeTrap targets four core components of autonomous trading agents: market intelligence, strategy formulation, portfolio and ledger handling, and trade execution, and evaluates their robustness under controlled system-level perturbations. All evaluations are conducted in a closed-loop historical backtesting setting on real US equity market data with identical initial conditions, enabling fair and reproducible comparisons across agents and attacks. Extensive experiments show that small perturbations at a single component can propagate through the agent decision loop and induce extreme concentration, runaway exposure, and large portfolio drawdowns across both agent types, demonstrating that current autonomous trading agents can be systematically misled at the system level. Our code is available at https://github.com/Yanlewen/TradeTrap.",
      "tldr_zh": "è¯¥ç ”ç©¶é’ˆå¯¹åŸºäºå¤§è¯­è¨€æ¨¡å‹(LLM-based)çš„äº¤æ˜“æ™ºèƒ½ä½“åœ¨çœŸå®é‡‘èå¸‚åœºä¸­çš„å¯é æ€§å’Œé²æ£’æ€§å±•å¼€è°ƒæŸ¥ï¼Œå¹¶æå‡ºäº†TradeTrapè¿™ä¸€ç»Ÿä¸€è¯„ä¼°æ¡†æ¶ã€‚TradeTrapæ—¨åœ¨å¯¹è‡ªé€‚åº”å’Œç¨‹åºåŒ–è‡ªä¸»äº¤æ˜“æ™ºèƒ½ä½“è¿›è¡Œç³»ç»Ÿæ€§å‹åŠ›æµ‹è¯•ï¼Œé‡ç‚¹é’ˆå¯¹å¸‚åœºæƒ…æŠ¥(market intelligence)ã€ç­–ç•¥åˆ¶å®š(strategy formulation)ã€æŠ•èµ„ç»„åˆä¸è´¦æœ¬å¤„ç†(portfolio and ledger handling)ä»¥åŠäº¤æ˜“æ‰§è¡Œ(trade execution)è¿™å››ä¸ªæ ¸å¿ƒç»„ä»¶ã€‚æ‰€æœ‰è¯„ä¼°å‡åœ¨çœŸå®çš„ç¾å›½è‚¡å¸‚å†å²æ•°æ®ä¸Šè¿›è¡Œé—­ç¯å›æµ‹(backtesting)ï¼Œä»¥ç¡®ä¿å®éªŒçš„å¯é‡å¤æ€§å’Œå…¬å¹³æ€§ã€‚å®éªŒç»“æœæ˜¾ç¤ºï¼Œå•ä¸ªç»„ä»¶ä¸­çš„å¾®å°æ‰°åŠ¨å¯èƒ½åœ¨æ™ºèƒ½ä½“çš„å†³ç­–å¾ªç¯ä¸­ä¼ æ’­ï¼Œå¯¼è‡´æç«¯æŒä»“é›†ä¸­ã€è¿‡åº¦é£é™©æš´éœ²ä»¥åŠå¤§å¹…èµ„äº§å›æ’¤ã€‚è¿™é¡¹ç ”ç©¶è¯æ˜äº†å½“å‰çš„è‡ªä¸»äº¤æ˜“æ™ºèƒ½ä½“åœ¨ç³»ç»Ÿå±‚é¢ææ˜“è¢«è¯¯å¯¼ï¼Œæ­ç¤ºäº†LLMæ™ºèƒ½ä½“åœ¨å¤„ç†é«˜é£é™©é‡‘èå†³ç­–æ—¶çš„æ½œåœ¨å®‰å…¨é£é™©ã€‚",
      "categories": [
        "cs.AI"
      ],
      "primary_category": "cs.AI",
      "comment": "",
      "pdf_url": "https://arxiv.org/pdf/2512.02261v1",
      "published_date": "2025-12-01 23:06:42 UTC",
      "updated_date": "2025-12-01 23:06:42 UTC",
      "processing_status": "completed",
      "attempts": 1,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "llm_backup_calls": 0,
      "last_update": "2026-01-26T12:21:44.274205+00:00"
    },
    {
      "arxiv_id": "2512.03103v1",
      "title": "Public Sentiment Analysis of Traffic Management Policies in Knoxville: A Social Media Driven Study",
      "title_zh": "Knoxville äº¤é€šç®¡ç†æ”¿ç­–å…¬ä¼—æƒ…æ„Ÿåˆ†æï¼šä¸€é¡¹ç¤¾äº¤åª’ä½“é©±åŠ¨çš„ç ”ç©¶",
      "authors": [
        "Shampa Saha",
        "Shovan Roy"
      ],
      "abstract": "This study presents a comprehensive analysis of public sentiment toward traffic management policies in Knoxville, Tennessee, utilizing social media data from Twitter and Reddit platforms. We collected and analyzed 7906 posts spanning January 2022 to December 2023, employing Valence Aware Dictionary and sEntiment Reasoner (VADER) for sentiment analysis and Latent Dirichlet Allocation (LDA) for topic modeling. Our findings reveal predominantly negative sentiment, with significant variations across platforms and topics. Twitter exhibited more negative sentiment compared to Reddit. Topic modeling identified six distinct themes, with construction-related topics showing the most negative sentiment while general traffic discussions were more positive. Spatiotemporal analysis revealed geographic and temporal patterns in sentiment expression. The research demonstrates social media's potential as a real-time public sentiment monitoring tool for transportation planning and policy evaluation.",
      "tldr_zh": "æœ¬ç ”ç©¶å¯¹ç”°çº³è¥¿å·è¯ºå…‹æ–¯ç»´å°”(Knoxville)äº¤é€šç®¡ç†æ”¿ç­–çš„å…¬ä¼—æƒ…ç»ªè¿›è¡Œäº†å…¨é¢åˆ†æï¼Œåˆ©ç”¨æ¥è‡ª Twitter å’Œ Reddit å¹³å°çš„ç¤¾äº¤åª’ä½“æ•°æ®æ¢ç´¢æ”¿ç­–å—ä¼—åé¦ˆã€‚ç ”ç©¶å›¢é˜Ÿæ”¶é›†å¹¶åˆ†æäº†2022å¹´1æœˆè‡³2023å¹´12æœˆæœŸé—´çš„7906æ¡å¸–å­ï¼Œé‡‡ç”¨ Valence Aware Dictionary and sEntiment Reasoner (VADER) è¿›è¡Œæƒ…ç»ªåˆ†æï¼Œå¹¶ç»“åˆ Latent Dirichlet Allocation (LDA) è¿›è¡Œä¸»é¢˜å»ºæ¨¡ã€‚ç»“æœæ˜¾ç¤ºå…¬ä¼—æƒ…ç»ªæ€»ä½“åå‘è´Ÿé¢ï¼Œä¸” Twitter å¹³å°ç›¸è¾ƒäº Reddit è¡¨ç°å‡ºæ›´å¼ºçš„è´Ÿé¢å€¾å‘ã€‚ä¸»é¢˜å»ºæ¨¡è¯†åˆ«å‡ºå…­ä¸ªæ ¸å¿ƒä¸»é¢˜ï¼Œå…¶ä¸­ä¸æ–½å·¥(construction-related)ç›¸å…³çš„è®¨è®ºè´Ÿé¢æƒ…ç»ªæœ€ä¸ºæ˜¾è‘—ï¼Œè€Œä¸€èˆ¬äº¤é€šè¯é¢˜åˆ™ç›¸å¯¹ç§¯æã€‚æ—¶ç©ºåˆ†æ(Spatiotemporal analysis)è¿›ä¸€æ­¥æ­ç¤ºäº†åœ°ç†å’Œæ—¶é—´ç»´åº¦ä¸Šçš„æƒ…ç»ªåˆ†å¸ƒè§„å¾‹ã€‚è¯¥ç ”ç©¶è¯å®äº†ç¤¾äº¤åª’ä½“åœ¨äº¤é€šè§„åˆ’å’Œæ”¿ç­–è¯„ä¼°ä¸­ä½œä¸ºå®æ—¶å…¬ä¼—æƒ…ç»ªç›‘æµ‹å·¥å…·çš„å·¨å¤§æ½œåŠ›ï¼Œä¸ºæ”¿ç­–åˆ¶å®šæä¾›äº†æ•°æ®æ”¯æ’‘ã€‚",
      "categories": [
        "cs.SI",
        "cs.AI"
      ],
      "primary_category": "cs.SI",
      "comment": "",
      "pdf_url": "https://arxiv.org/pdf/2512.03103v1",
      "published_date": "2025-12-01 23:02:23 UTC",
      "updated_date": "2025-12-01 23:02:23 UTC",
      "processing_status": "completed",
      "attempts": 1,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "llm_backup_calls": 0,
      "last_update": "2026-01-26T12:21:42.673494+00:00"
    },
    {
      "arxiv_id": "2601.11541v1",
      "title": "A Comparative Study of Technical Writing Feedback Quality: Evaluating LLMs, SLMs, and Humans in Computer Science Topics",
      "title_zh": "æŠ€æœ¯å†™ä½œåé¦ˆè´¨é‡çš„æ¯”è¾ƒç ”ç©¶ï¼šé’ˆå¯¹è®¡ç®—æœºç§‘å­¦è¯¾é¢˜ä¸­ LLMsã€SLMs ä¸äººç±»çš„è¯„ä¼°",
      "authors": [
        "Suqing Liu",
        "Bogdan Simion",
        "Christopher Eaton",
        "Michael Liut"
      ],
      "abstract": "Feedback is a critical component of the learning process, particularly in computer science education. This study investigates the quality of feedback generated by Large Language Models (LLMs), Small Language Models (SLMs), compared with human feedback, in three computer science course with technical writing components: an introductory computer science course (CS2), a third-year advanced systems course (operating systems), and a third-year writing course (a topics course on artificial intelligence). Using a mixed-methods approach which integrates quantitative Likert-scale questions with qualitative commentary, we analyze the student perspective on feedback quality, evaluated based on multiple criteria, including readability, detail, specificity, actionability, helpfulness, and overall quality. The analysis reveals that in the larger upper-year operating systems course ($N=80$), SLMs and LLMs are perceived to deliver clear, actionable, and well-structured feedback, while humans provide more contextually nuanced guidance. As for the high-enrollment CS2 course ($N=176$) showed the same preference for the AI tools' clarity and breadth, but students noted that AI feedback sometimes lacked the concise, straight-to-the-point, guidance offered by humans. Conversely, in the smaller upper-year technical writing course on AI topics ($N=7$), all students preferred feedback from the course instructor, who was able to provide clear, specific, and personalized feedback, compared to the more general and less targeted AI-based feedback. We also highlight the scalability of AI-based feedback by focusing on its effectiveness at large scale. Our findings underscore the potential of hybrid approaches that combine AI and human feedback to achieve efficient and high-quality feedback at scale.",
      "tldr_zh": "è¯¥ç ”ç©¶å¯¹æ¯”åˆ†æäº†å¤§è¯­è¨€æ¨¡å‹ (LLMs)ã€å°è¯­è¨€æ¨¡å‹ (SLMs) ä¸äººç±»åœ¨è®¡ç®—æœºç§‘å­¦æŠ€æœ¯å†™ä½œåé¦ˆæ–¹é¢çš„è´¨é‡å·®å¼‚ã€‚é€šè¿‡åœ¨ä¸‰é—¨ä¸åŒç±»å‹çš„è®¡ç®—æœºè¯¾ç¨‹ä¸­åº”ç”¨æ··åˆæ–¹æ³•ï¼Œç ”ç©¶ä»å¯è¯»æ€§ã€å…·ä½“æ€§ã€å¯æ“ä½œæ€§ç­‰ç»´åº¦è¯„ä¼°äº†åé¦ˆæ•ˆæœã€‚ç ”ç©¶å‘ç°åœ¨å­¦ç”Ÿäººæ•°è¾ƒå¤šçš„å¤§å‹è¯¾ç¨‹ä¸­ï¼ŒAI æ¨¡å‹æä¾›çš„åé¦ˆå› å…¶ç»“æ„æ¸…æ™°å’Œé«˜å¯æ“ä½œæ€§è€Œå—åˆ°è®¤å¯ï¼Œè€Œäººç±»åé¦ˆåˆ™èƒœåœ¨è¯­å¢ƒæŠŠæ¡å’Œç®€æ´åº¦ã€‚ä½†åœ¨è§„æ¨¡è¾ƒå°ä¸”ä¸“ä¸šæ€§å¼ºçš„è¯¾ç¨‹ä¸­ï¼Œå­¦ç”Ÿæ›´åå¥½è®²å¸ˆæä¾›çš„ä¸ªæ€§åŒ–ä¸”é’ˆå¯¹æ€§å¼ºçš„å»ºè®®ï¼Œè®¤ä¸º AI ç”Ÿæˆçš„åé¦ˆè¿‡äºå®½æ³›ä¸”ç¼ºä¹é’ˆå¯¹æ€§ã€‚è¯¥ç ”ç©¶å¼ºè°ƒäº† AI åœ¨æä¾›å¤§è§„æ¨¡åé¦ˆæ–¹é¢çš„å¯æ‰©å±•æ€§ä¼˜åŠ¿ï¼Œå¹¶æœ€ç»ˆå»ºè®®é‡‡ç”¨ç»“åˆ AI ä¸äººç±»åé¦ˆçš„æ··åˆæ–¹æ³•ï¼Œä»¥å®ç°åœ¨å¤§è§„æ¨¡æ•™è‚²åœºæ™¯ä¸­å…¼é¡¾æ•ˆç‡ä¸é«˜è´¨é‡ã€‚",
      "categories": [
        "cs.HC",
        "cs.AI",
        "cs.CY"
      ],
      "primary_category": "cs.HC",
      "comment": "",
      "pdf_url": "https://arxiv.org/pdf/2601.11541v1",
      "published_date": "2025-12-01 22:51:54 UTC",
      "updated_date": "2025-12-01 22:51:54 UTC",
      "processing_status": "completed",
      "attempts": 1,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "llm_backup_calls": 0,
      "last_update": "2026-01-26T12:21:40.172660+00:00"
    },
    {
      "arxiv_id": "2512.02246v1",
      "title": "DETAIL Matters: Measuring the Impact of Prompt Specificity on Reasoning in Large Language Models",
      "title_zh": "DETAILï¼šè¡¡é‡æç¤ºè¯å…·ä½“æ€§å¯¹å¤§è¯­è¨€æ¨¡å‹æ¨ç†çš„å½±å“",
      "authors": [
        "Olivia Kim"
      ],
      "abstract": "Prompt design plays a critical role in the reasoning performance of large language models (LLMs), yet the impact of prompt specificity - how detailed or vague a prompt is - remains understudied. This paper introduces DETAIL, a framework for evaluating LLM performance across varying levels of prompt specificity. We generate multi-level prompts using GPT-4, quantify specificity via perplexity, and assess correctness using GPT-based semantic equivalence. Experiments on 30 novel reasoning tasks across GPT-4 and O3-mini reveal that specificity improves accuracy, especially for smaller models and procedural tasks. Our results highlight the need for adaptive prompting strategies and provide tools and data to support further research.",
      "tldr_zh": "è¯¥ç ”ç©¶æå‡ºäº†DETAILæ¡†æ¶ï¼Œæ—¨åœ¨ç³»ç»Ÿæ€§åœ°è¡¡é‡æç¤ºè¯ç‰¹å¼‚æ€§(prompt specificity)å¯¹å¤§è¯­è¨€æ¨¡å‹(LLMs)æ¨ç†æ€§èƒ½çš„å½±å“ã€‚ç ”ç©¶äººå‘˜é€šè¿‡GPT-4ç”Ÿæˆå¤šçº§åˆ«çš„æç¤ºè¯ï¼Œåˆ©ç”¨å›°æƒ‘åº¦(perplexity)é‡åŒ–å…¶ç‰¹å¼‚æ€§ç¨‹åº¦ï¼Œå¹¶é‡‡ç”¨åŸºäºGPTçš„è¯­ä¹‰ç­‰ä»·æ€§(semantic equivalence)æ¥ç¡®ä¿æ¨ç†ç»“æœçš„å‡†ç¡®æ€§è¯„ä¼°ã€‚åœ¨GPT-4å’ŒO3-miniæ¨¡å‹ä¸Šçš„30é¡¹æ¨ç†ä»»åŠ¡å®éªŒè¡¨æ˜ï¼Œå¢åŠ æç¤ºè¯çš„è¯¦ç»†ç¨‹åº¦èƒ½æ˜¾è‘—æé«˜æ¨¡å‹å‡†ç¡®ç‡ï¼Œè¿™ç§è¶‹åŠ¿åœ¨å°å‹æ¨¡å‹åŠç¨‹åºåŒ–ä»»åŠ¡(procedural tasks)ä¸­å°¤ä¸ºçªå‡ºã€‚è¯¥ç ”ç©¶ç»“æœæ­ç¤ºäº†å¼€å‘è‡ªé€‚åº”æç¤ºç­–ç•¥(adaptive prompting strategies)çš„å¿…è¦æ€§ï¼Œå¹¶ä¸ºè¯¥é¢†åŸŸçš„åç»­æ¢ç´¢æä¾›äº†å®è´µçš„å·¥å…·ä¸æ•°æ®èµ„æºã€‚",
      "categories": [
        "cs.CL",
        "cs.AI"
      ],
      "primary_category": "cs.CL",
      "comment": "",
      "pdf_url": "https://arxiv.org/pdf/2512.02246v1",
      "published_date": "2025-12-01 22:28:39 UTC",
      "updated_date": "2025-12-01 22:28:39 UTC",
      "processing_status": "completed",
      "attempts": 1,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "llm_backup_calls": 0,
      "last_update": "2026-01-26T12:21:48.870779+00:00"
    },
    {
      "arxiv_id": "2512.03102v2",
      "title": "Dynamic Correction of Erroneous State Estimates via Diffusion Bayesian Exploration",
      "title_zh": "åŸºäºæ‰©æ•£è´å¶æ–¯æ¢ç´¢çš„é”™è¯¯çŠ¶æ€ä¼°è®¡åŠ¨æ€ä¿®æ­£",
      "authors": [
        "Yiwei Shi",
        "Hongnan Ma",
        "Mengyue Yang",
        "Cunjia Liu",
        "Weiru Liu"
      ],
      "abstract": "In emergency response and other high-stakes societal applications, early-stage state estimates critically shape downstream outcomes. Yet, these initial state estimates-often based on limited or biased information-can be severely misaligned with reality, constraining subsequent actions and potentially causing catastrophic delays, resource misallocation, and human harm. Under the stationary bootstrap baseline (zero transition and no rejuvenation), bootstrap particle filters exhibit Stationarity-Induced Posterior Support Invariance (S-PSI), wherein regions excluded by the initial prior remain permanently unexplorable, making corrections impossible even when new evidence contradicts current beliefs. While classical perturbations can in principle break this lock-in, they operate in an always-on fashion and may be inefficient. To overcome this, we propose a diffusion-driven Bayesian exploration framework that enables principled, real-time correction of early state estimation errors. Our method expands posterior support via entropy-regularized sampling and covariance-scaled diffusion. A Metropolis-Hastings check validates proposals and keeps inference adaptive to unexpected evidence. Empirical evaluations on realistic hazardous-gas localization tasks show that our approach matches reinforcement learning and planning baselines when priors are correct. It substantially outperforms classical SMC perturbations and RL-based methods under misalignment, and we provide theoretical guarantees that DEPF resolves S-PSI while maintaining statistical rigor.",
      "tldr_zh": "è¯¥ç ”ç©¶é’ˆå¯¹åº”æ€¥å“åº”ç­‰é«˜é£é™©åœºæ™¯ä¸­åˆå§‹çŠ¶æ€ä¼°è®¡(State Estimates)å¯èƒ½å‡ºç°çš„åå·®é—®é¢˜ï¼ŒæŒ‡å‡ºä¼ ç»Ÿç²’å­æ»¤æ³¢(Particle Filters)åœ¨å¹³ç¨³åŸºå‡†ä¸‹å­˜åœ¨â€œå¹³ç¨³è¯±å¯¼åéªŒæ”¯æ’‘ä¸å˜æ€§â€(Stationarity-Induced Posterior Support Invariance, S-PSI)ï¼Œå¯¼è‡´åç»­å³ä½¿è·å¾—æ–°è¯æ®ä¹Ÿæ— æ³•çº æ­£åˆå§‹å…ˆéªŒæ’é™¤çš„åŒºåŸŸã€‚ä¸ºäº†å…‹æœè¿™ä¸€é™åˆ¶ï¼Œä½œè€…æå‡ºäº†ä¸€ç§æ‰©æ•£é©±åŠ¨çš„è´å¶æ–¯æ¢ç´¢æ¡†æ¶ï¼Œé€šè¿‡ç†µæ­£åˆ™åŒ–é‡‡æ ·(Entropy-regularized Sampling)å’Œåæ–¹å·®ç¼©æ”¾æ‰©æ•£(Covariance-scaled Diffusion)æ¥æ‰©å±•åéªŒæ”¯æ’‘ã€‚è¯¥æ–¹æ³•å¼•å…¥äº† Metropolis-Hastings æ ¡éªŒä»¥éªŒè¯å»ºè®®å¹¶ä¿æŒæ¨ç†å¯¹æ„å¤–è¯æ®çš„è‡ªé€‚åº”æ€§ï¼Œä»è€Œå®ç°å¯¹çŠ¶æ€ä¼°è®¡é”™è¯¯çš„å®æ—¶ä¿®æ­£ã€‚åœ¨å±é™©æ°”ä½“å®šä½ä»»åŠ¡çš„å®éªŒä¸­ï¼Œè¯¥æ–¹æ³•åœ¨å…ˆéªŒæ­£ç¡®æ—¶èƒ½åŒ¹é…å¼ºåŒ–å­¦ä¹ (Reinforcement Learning)çš„è¡¨ç°ï¼Œè€Œåœ¨å…ˆéªŒå¤±å‡†çš„æƒ…å†µä¸‹æ˜¾è‘—ä¼˜äºä¼ ç»Ÿçš„åºè´¯è’™ç‰¹å¡ç½—(Sequential Monte Carlo, SMC)æ‰°åŠ¨åŠ RL æ–¹æ³•ã€‚ç†è®ºåˆ†æè¿›ä¸€æ­¥è¯æ˜ï¼Œè¯¥æ–¹æ³•åœ¨ä¿æŒç»Ÿè®¡ä¸¥è°¨æ€§çš„åŒæ—¶æœ‰æ•ˆè§£å†³äº† S-PSI é—®é¢˜ï¼Œæ˜¾è‘—æå‡äº†ç³»ç»Ÿåœ¨å¤æ‚ç¯å¢ƒä¸‹çš„é²æ£’æ€§ã€‚",
      "categories": [
        "cs.LG",
        "cs.AI",
        "stat.CO"
      ],
      "primary_category": "cs.LG",
      "comment": "",
      "pdf_url": "https://arxiv.org/pdf/2512.03102v2",
      "published_date": "2025-12-01 22:08:26 UTC",
      "updated_date": "2025-12-05 15:08:25 UTC",
      "processing_status": "completed",
      "attempts": 1,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "llm_backup_calls": 0,
      "last_update": "2026-01-26T12:22:39.565442+00:00"
    },
    {
      "arxiv_id": "2512.08969v1",
      "title": "Learning Robust Representations for Malicious Content Detection via Contrastive Sampling and Uncertainty Estimation",
      "title_zh": "åŸºäºå¯¹æ¯”é‡‡æ ·ä¸ä¸ç¡®å®šæ€§ä¼°è®¡çš„æ¶æ„å†…å®¹æ£€æµ‹é²æ£’è¡¨å¾å­¦ä¹ ",
      "authors": [
        "Elias Hossain",
        "Umesh Biswas",
        "Charan Gudla",
        "Sai Phani Parsa"
      ],
      "abstract": "We propose the Uncertainty Contrastive Framework (UCF), a Positive-Unlabeled (PU) representation learning framework that integrates uncertainty-aware contrastive loss, adaptive temperature scaling, and a self-attention-guided LSTM encoder to improve classification under noisy and imbalanced conditions. UCF dynamically adjusts contrastive weighting based on sample confidence, stabilizes training using positive anchors, and adapts temperature parameters to batch-level variability. Applied to malicious content classification, UCF-generated embeddings enable multiple traditional classifiers to achieve more than 93.38% accuracy, precision above 0.93, and near-perfect recall, with minimal false negatives and competitive ROC-AUC scores. Visual analyses confirm clear separation between positive and unlabeled instances, highlighting the framework's ability to produce calibrated, discriminative embeddings. These results position UCF as a robust and scalable solution for PU learning in high-stakes domains such as cybersecurity and biomedical text mining.",
      "tldr_zh": "è¯¥ç ”ç©¶æå‡ºäº†Uncertainty Contrastive Framework (UCF)ï¼Œè¿™æ˜¯ä¸€ä¸ªé’ˆå¯¹Positive-Unlabeled (PU) å­¦ä¹ çš„è¡¨ç¤ºå­¦ä¹ æ¡†æ¶ï¼Œæ—¨åœ¨ä¼˜åŒ–å™ªå£°å’Œæ•°æ®ä¸å¹³è¡¡æ¡ä»¶ä¸‹çš„åˆ†ç±»æ€§èƒ½ã€‚UCFé›†æˆäº†uncertainty-aware contrastive lossã€adaptive temperature scalingä»¥åŠself-attention-guided LSTM encoderï¼Œé€šè¿‡åŸºäºæ ·æœ¬ç½®ä¿¡åº¦çš„åŠ¨æ€å¯¹æ¯”åŠ æƒå’Œæ­£æ ·æœ¬é”šç‚¹(positive anchors)æ¥ç¨³å®šè®­ç»ƒè¿‡ç¨‹ã€‚åœ¨æ¶æ„å†…å®¹æ£€æµ‹çš„åº”ç”¨ä¸­ï¼ŒUCFç”Ÿæˆçš„åµŒå…¥å‘é‡ä½¿ä¼ ç»Ÿåˆ†ç±»å™¨è¾¾åˆ°äº†è¶…è¿‡93.38%çš„å‡†ç¡®ç‡å’Œæ¥è¿‘å®Œç¾çš„recallï¼Œå¹¶è¡¨ç°å‡ºæä½çš„å‡é˜´æ€§ç‡ã€‚å¯è§†åŒ–åˆ†æè¯å®ï¼Œè¯¥æ¡†æ¶èƒ½å¤Ÿäº§ç”Ÿç»è¿‡æ ¡å‡†ä¸”å…·æœ‰åˆ¤åˆ«åŠ›çš„åµŒå…¥è¡¨ç¤ºï¼Œæœ‰æ•ˆåŒºåˆ†æ­£æ ·æœ¬ä¸æœªæ ‡è®°å®ä¾‹ã€‚è¿™äº›ç»“æœè¡¨æ˜ï¼ŒUCFä¸ºç½‘ç»œå®‰å…¨(cybersecurity)å’Œç”Ÿç‰©åŒ»å­¦æ–‡æœ¬æŒ–æ˜(biomedical text mining)ç­‰é«˜é£é™©é¢†åŸŸçš„PUå­¦ä¹ æä¾›äº†ä¸€ç§é²æ£’ä¸”å¯æ‰©å±•çš„è§£å†³æ–¹æ¡ˆã€‚",
      "categories": [
        "cs.LG",
        "cs.AI"
      ],
      "primary_category": "cs.LG",
      "comment": "",
      "pdf_url": "https://arxiv.org/pdf/2512.08969v1",
      "published_date": "2025-12-01 22:06:06 UTC",
      "updated_date": "2025-12-01 22:06:06 UTC",
      "processing_status": "completed",
      "attempts": 1,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "llm_backup_calls": 0,
      "last_update": "2026-01-26T12:22:42.470569+00:00"
    },
    {
      "arxiv_id": "2512.02231v1",
      "title": "See, Hear, and Understand: Benchmarking Audiovisual Human Speech Understanding in Multimodal Large Language Models",
      "title_zh": "è§†ã€å¬ã€ç†è§£ï¼šå¤šæ¨¡æ€å¤§è¯­è¨€æ¨¡å‹ä¸­çš„äººç±»è¯­éŸ³è§†å¬ç†è§£è¯„æµ‹",
      "authors": [
        "Le Thien Phuc Nguyen",
        "Zhuoran Yu",
        "Samuel Low Yu Hang",
        "Subin An",
        "Jeongik Lee",
        "Yohan Ban",
        "SeungEun Chung",
        "Thanh-Huy Nguyen",
        "JuWan Maeng",
        "Soochahn Lee",
        "Yong Jae Lee"
      ],
      "abstract": "Multimodal large language models (MLLMs) are expected to jointly interpret vision, audio, and language, yet existing video benchmarks rarely assess fine-grained reasoning about human speech. Many tasks remain visually solvable or only coarsely evaluate speech, offering limited insight into whether models can align who speaks, what is said, and when it occurs. We introduce AV-SpeakerBench, a curated benchmark of 3,212 multiple-choice questions focused on speaker-centric audiovisual reasoning in real-world videos. It features: (1) a speaker-centered formulation that treats speakers-not scenes-as the core reasoning unit; (2) fusion-grounded question design embedding audiovisual dependencies into question semantics; and (3) expert-curated annotations ensuring temporal precision and cross-modal validity. Comprehensive evaluations show that the Gemini family consistently outperforms open-source systems, with Gemini 2.5 Pro achieving the best results. Among open models, Qwen3-Omni-30B approaches Gemini 2.0 Flash but remains far behind Gemini 2.5 Pro, primarily due to weaker audiovisual fusion rather than visual perception. We believe AV-SpeakerBench establishes a rigorous foundation for advancing fine-grained audiovisual reasoning in future multimodal systems.",
      "tldr_zh": "è¯¥ç ”ç©¶é’ˆå¯¹å¤šæ¨¡æ€å¤§è¯­è¨€æ¨¡å‹ (MLLMs) åœ¨äººç±»æ¼”è®²ç»†ç²’åº¦æ¨ç†æ–¹é¢çš„ä¸è¶³ï¼Œæå‡ºäº† AV-SpeakerBench åŸºå‡†æµ‹è¯•ï¼Œæ—¨åœ¨è¯„ä¼°æ¨¡å‹å¯¹è¯´è¯è€…ã€æ¼”è®²å†…å®¹åŠå…¶å‘ç”Ÿæ—¶é—´çš„å¯¹é½èƒ½åŠ›ã€‚è¯¥åŸºå‡†åŒ…å« 3,212 é“åŸºäºçœŸå®è§†é¢‘çš„æµ‹è¯•é¢˜ï¼Œå…·æœ‰ä»¥è¯´è¯è€…ä¸ºæ ¸å¿ƒã€åµŒå…¥è§†å¬ä¾èµ–å…³ç³»ä»¥åŠä¸“å®¶çº§æ ‡æ³¨ç­‰ç‰¹ç‚¹ã€‚å®éªŒç»“æœè¡¨æ˜ï¼ŒGemini ç³»åˆ—æ¨¡å‹åœ¨è§†å¬æ¨ç†ä»»åŠ¡ä¸­è¡¨ç°å“è¶Šï¼Œå…¶ä¸­ Gemini 2.5 Pro è¾¾åˆ°æœ€é«˜æ°´å¹³ã€‚åœ¨å¼€æºæ¨¡å‹ä¸­ï¼ŒQwen3-Omni-30B è™½ç„¶è¡¨ç°é¢†å…ˆï¼Œä½†ç”±äºè§†å¬èåˆ (audiovisual fusion) èƒ½åŠ›è¾ƒå¼±ï¼Œä¸é—­æºé¡¶å°–æ¨¡å‹ç›¸æ¯”ä»æœ‰æ˜¾è‘—å·®è·ã€‚è¿™é¡¹å·¥ä½œä¸ºæå‡æœªæ¥å¤šæ¨¡æ€ç³»ç»Ÿåœ¨å¤æ‚è§†å¬åœºæ™¯ä¸‹çš„ç»†ç²’åº¦æ¨ç†èƒ½åŠ›æä¾›äº†é‡è¦çš„è¡¡é‡æ ‡å‡†å’Œç ”ç©¶åŸºç¡€ã€‚",
      "categories": [
        "cs.CV",
        "cs.AI",
        "cs.LG"
      ],
      "primary_category": "cs.CV",
      "comment": "preprint",
      "pdf_url": "https://arxiv.org/pdf/2512.02231v1",
      "published_date": "2025-12-01 21:57:26 UTC",
      "updated_date": "2025-12-01 21:57:26 UTC",
      "processing_status": "completed",
      "attempts": 1,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "llm_backup_calls": 0,
      "last_update": "2026-01-26T12:22:51.070001+00:00"
    },
    {
      "arxiv_id": "2512.02230v1",
      "title": "Benchmarking LLM Agents for Wealth-Management Workflows",
      "title_zh": "é¢å‘è´¢å¯Œç®¡ç†å·¥ä½œæµçš„å¤§è¯­è¨€æ¨¡å‹æ™ºèƒ½ä½“åŸºå‡†æµ‹è¯•",
      "authors": [
        "Rory Milsom"
      ],
      "abstract": "Modern work relies on an assortment of digital collaboration tools, yet routine processes continue to suffer from human error and delay. To address this gap, this dissertation extends TheAgentCompany with a finance-focused environment and investigates whether a general purpose LLM agent can complete representative wealth-management tasks both accurately and economically. This study introduces synthetic domain data, enriches colleague simulations, and prototypes an automatic task-generation pipeline. The study aims to create and assess an evaluation set that can meaningfully measure an agent's fitness for assistant-level wealth management work. We construct a benchmark of 12 task-pairs for wealth management assistants spanning retrieval, analysis, and synthesis/communication, with explicit acceptance criteria and deterministic graders. We seeded a set of new finance-specific data and introduced a high vs. low-autonomy variant of every task. The paper concluded that agents are limited less by mathematical reasoning and more so by end-to-end workflow reliability, and meaningfully affected by autonomy level, and that incorrect evaluation of models have hindered benchmarking.",
      "tldr_zh": "è¯¥ç ”ç©¶é€šè¿‡æ‰©å±•TheAgentCompanyæ¡†æ¶ï¼Œæ„å»ºäº†ä¸€ä¸ªä¸“é—¨é’ˆå¯¹è´¢å¯Œç®¡ç†å·¥ä½œæµçš„é‡‘èä»¿çœŸç¯å¢ƒï¼Œæ—¨åœ¨è¯„ä¼°é€šç”¨å¤§è¯­è¨€æ¨¡å‹(LLM)æ™ºèƒ½ä½“åœ¨å¤„ç†ç›¸å…³ä»»åŠ¡æ—¶çš„å‡†ç¡®æ€§ä¸ç»æµæ€§ã€‚ç ”ç©¶å›¢é˜Ÿå¼•å…¥äº†åˆæˆé¢†åŸŸæ•°æ®å’ŒåŒäº‹æ¨¡æ‹Ÿç³»ç»Ÿï¼Œå¹¶å¼€å‘äº†è‡ªåŠ¨ä»»åŠ¡ç”Ÿæˆæµæ°´çº¿ï¼Œå»ºç«‹äº†åŒ…å«12ä¸ªä»»åŠ¡å¯¹çš„åŸºå‡†æµ‹è¯•ï¼Œæ¶µç›–äº†æ£€ç´¢ã€åˆ†æåŠç»¼åˆé€šè®¯ç­‰æ ¸å¿ƒåŠ©ç†èŒèƒ½ã€‚æ¯ä¸ªä»»åŠ¡å‡è®¾è®¡äº†é«˜ä½ä¸¤ç§è‡ªä¸»æƒ(autonomy)å˜ä½“ï¼Œå¹¶è¾…ä»¥æ˜ç¡®çš„éªŒæ”¶æ ‡å‡†å’Œç¡®å®šæ€§è¯„åˆ†å™¨è¿›è¡Œå®¢è§‚è¯„ä¼°ã€‚å®éªŒç»“æœè¡¨æ˜ï¼Œæ™ºèƒ½ä½“çš„è¡¨ç°æ›´å¤šåœ°å—é™äºç«¯åˆ°ç«¯å·¥ä½œæµçš„å¯é æ€§(workflow reliability)è€Œéæ•°å­¦æ¨ç†èƒ½åŠ›ï¼Œä¸”ä»»åŠ¡çš„è‡ªä¸»æƒæ°´å¹³å¯¹å…¶æˆåŠŸç‡æœ‰æ˜¾è‘—å½±å“ã€‚è¯¥é¡¹å·¥ä½œæŒ‡å‡ºäº†æ—¢å¾€è¯„ä¼°åå·®å¯¹åŸºå‡†æµ‹è¯•çš„è´Ÿé¢å½±å“ï¼Œä¸ºè¡¡é‡æ™ºèƒ½ä½“åœ¨é‡‘èåŠ©ç†å·¥ä½œä¸­çš„é€‚ä»»æ€§æä¾›äº†æ ‡å‡†åŒ–çš„è¡¡é‡å·¥å…·ã€‚",
      "categories": [
        "cs.AI"
      ],
      "primary_category": "cs.AI",
      "comment": "56 pages, 8 figures, The University of Edinburgh",
      "pdf_url": "https://arxiv.org/pdf/2512.02230v1",
      "published_date": "2025-12-01 21:56:21 UTC",
      "updated_date": "2025-12-01 21:56:21 UTC",
      "processing_status": "completed",
      "attempts": 1,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "llm_backup_calls": 0,
      "last_update": "2026-01-26T12:23:02.757494+00:00"
    },
    {
      "arxiv_id": "2512.02228v1",
      "title": "STRIDE: A Systematic Framework for Selecting AI Modalities -- Agentic AI, AI Assistants, or LLM Calls",
      "title_zh": "STRIDEï¼šä¸€ç§ç”¨äºé€‰æ‹© AI æ¨¡å¼ï¼ˆæ™ºèƒ½ä½“ AIã€AI åŠ©æ‰‹æˆ– LLM è°ƒç”¨ï¼‰çš„ç³»ç»ŸåŒ–æ¡†æ¶",
      "authors": [
        "Shubhi Asthana",
        "Bing Zhang",
        "Chad DeLuca",
        "Ruchi Mahindru",
        "Hima Patel"
      ],
      "abstract": "The rapid shift from stateless large language models (LLMs) to autonomous, goal-driven agents raises a central question: When is agentic AI truly necessary? While agents enable multi-step reasoning, persistent memory, and tool orchestration, deploying them indiscriminately leads to higher cost, complexity, and risk.\n  We present STRIDE (Systematic Task Reasoning Intelligence Deployment Evaluator), a framework that provides principled recommendations for selecting between three modalities: (i) direct LLM calls, (ii) guided AI assistants, and (iii) fully autonomous agentic AI. STRIDE integrates structured task decomposition, dynamism attribution, and self-reflection requirement analysis to produce an Agentic Suitability Score, ensuring that full agentic autonomy is reserved for tasks with inherent dynamism or evolving context.\n  Evaluated across 30 real-world tasks spanning SRE, compliance, and enterprise automation, STRIDE achieved 92% accuracy in modality selection, reduced unnecessary agent deployments by 45%, and cut resource costs by 37%. Expert validation over six months in SRE and compliance domains confirmed its practical utility, with domain specialists agreeing that STRIDE effectively distinguishes between tasks requiring simple LLM calls, guided assistants, or full agentic autonomy. This work reframes agent adoption as a necessity-driven design decision, ensuring autonomy is applied only when its benefits justify the costs.",
      "tldr_zh": "è¯¥ç ”ç©¶æå‡ºäº† STRIDEï¼ˆSystematic Task Reasoning Intelligence Deployment Evaluatorï¼‰æ¡†æ¶ï¼Œæ—¨åœ¨è§£å†³ä»æ— çŠ¶æ€ LLM å‘è‡ªä¸» Agentic AI è½¬å‹è¿‡ç¨‹ä¸­ï¼Œå› ç›²ç›®éƒ¨ç½²æ™ºèƒ½ä½“è€Œå¯¼è‡´çš„æˆæœ¬ã€å¤æ‚æ€§å’Œé£é™©ä¸Šå‡é—®é¢˜ã€‚è¯¥æ¡†æ¶æä¾›äº†ä¸€å¥—ç³»ç»Ÿæ€§çš„å†³ç­–æ ‡å‡†ï¼Œç”¨äºåœ¨ç›´æ¥ LLM callsã€å—å¯¼å‘çš„ AI assistants ä»¥åŠå…¨è‡ªä¸» Agentic AI ä¸‰ç§æ¨¡å¼é—´è¿›è¡Œæœ€ä¼˜é€‰æ‹©ã€‚STRIDE é›†æˆäº†ç»“æ„åŒ–ä»»åŠ¡åˆ†è§£ (structured task decomposition)ã€åŠ¨æ€å½’å›  (dynamism attribution) å’Œè‡ªæˆ‘åæ€éœ€æ±‚åˆ†æï¼Œé€šè¿‡ç”Ÿæˆ Agentic Suitability Score ç¡®ä¿ä»…åœ¨ä»»åŠ¡å…·å¤‡å†…åœ¨åŠ¨æ€æ€§æˆ–æ¼”å˜è¯­å¢ƒæ—¶æ‰è°ƒç”¨å…¨è‡ªä¸»æ™ºèƒ½ä½“ã€‚åœ¨æ¶‰åŠ SREã€åˆè§„æ€§å’Œä¼ä¸šè‡ªåŠ¨åŒ–çš„ 30 ä¸ªå®é™…ä»»åŠ¡è¯„ä¼°ä¸­ï¼ŒSTRIDE çš„æ¨¡å¼é€‰æ‹©å‡†ç¡®ç‡è¾¾åˆ°äº† 92%ï¼Œæœ‰æ•ˆå‡å°‘äº† 45% çš„ä¸å¿…è¦æ™ºèƒ½ä½“éƒ¨ç½²å¹¶é™ä½äº† 37% çš„èµ„æºæˆæœ¬ã€‚é€šè¿‡ä¸ºæœŸå…­ä¸ªæœˆçš„é¢†åŸŸä¸“å®¶éªŒè¯ï¼Œè¯¥ç ”ç©¶å°†æ™ºèƒ½ä½“çš„é‡‡ç”¨é‡æ–°å®šä¹‰ä¸ºä¸€ç§éœ€æ±‚é©±åŠ¨çš„è®¾è®¡å†³ç­–ï¼Œç¡®ä¿äº† AI è‡ªä¸»æ€§çš„åº”ç”¨ä¸å…¶äº§ç”Ÿçš„æ”¶ç›Šå’Œæˆæœ¬ç›¸åŒ¹é…ã€‚",
      "categories": [
        "cs.AI",
        "cs.LG"
      ],
      "primary_category": "cs.AI",
      "comment": "10 pages, 4 Figures, 5 Tables Paper presented at NeurIPS 2025 LAW workshop: Bridging Language, Agent, and World Models",
      "pdf_url": "https://arxiv.org/pdf/2512.02228v1",
      "published_date": "2025-12-01 21:54:07 UTC",
      "updated_date": "2025-12-01 21:54:07 UTC",
      "processing_status": "completed",
      "attempts": 1,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "llm_backup_calls": 0,
      "last_update": "2026-01-26T12:22:53.672115+00:00"
    },
    {
      "arxiv_id": "2512.02227v1",
      "title": "Orchestration Framework for Financial Agents: From Algorithmic Trading to Agentic Trading",
      "title_zh": "é‡‘èæ™ºèƒ½ä½“ç¼–æ’æ¡†æ¶ï¼šä»ç®—æ³•äº¤æ˜“åˆ°æ™ºèƒ½ä½“äº¤æ˜“",
      "authors": [
        "Jifeng Li",
        "Arnav Grover",
        "Abraham Alpuerto",
        "Yupeng Cao",
        "Xiao-Yang Liu"
      ],
      "abstract": "The financial market is a mission-critical playground for AI agents due to its temporal dynamics and low signal-to-noise ratio. Building an effective algorithmic trading system may require a professional team to develop and test over the years. In this paper, we propose an orchestration framework for financial agents, which aims to democratize financial intelligence to the general public. We map each component of the traditional algorithmic trading system to agents, including planner, orchestrator, alpha agents, risk agents, portfolio agents, backtest agents, execution agents, audit agents, and memory agent. We present two in-house trading examples. For the stock trading task (hourly data from 04/2024 to 12/2024), our approach achieved a return of $20.42\\%$, a Sharpe ratio of 2.63, and a maximum drawdown of $-3.59\\%$, while the S&P 500 index yielded a return of $15.97\\%$. For the BTC trading task (minute data from 27/07/2025 to 13/08/2025), our approach achieved a return of $8.39\\%$, a Sharpe ratio of $0.38$, and a maximum drawdown of $-2.80\\%$, whereas the BTC price increased by $3.80\\%$. Our code is available on \\href{https://github.com/Open-Finance-Lab/AgenticTrading}{GitHub}.",
      "tldr_zh": "è¯¥ç ”ç©¶é’ˆå¯¹é‡‘èå¸‚åœºçš„é«˜åŠ¨æ€æ€§å’Œä½ä¿¡å™ªæ¯”æŒ‘æˆ˜ï¼Œæå‡ºäº†ä¸€ç§é‡‘èæ™ºèƒ½ä½“ç¼–æ’æ¡†æ¶(Orchestration Framework)ï¼Œæ—¨åœ¨æ¨åŠ¨ä»ä¼ ç»Ÿçš„ç®—æ³•äº¤æ˜“(Algorithmic Trading)å‘æ™ºèƒ½ä½“äº¤æ˜“(Agentic Trading)çš„è½¬å‹ã€‚è¯¥æ¡†æ¶é€šè¿‡å°†ä¼ ç»Ÿäº¤æ˜“ç³»ç»Ÿçš„æ ¸å¿ƒç»„ä»¶æ˜ å°„ä¸ºåŠŸèƒ½æ˜ç¡®çš„æ™ºèƒ½ä½“é›†ç¾¤ï¼Œæ¶µç›–äº†Plannerã€Orchestratorã€Alpha agentsã€Risk agentsã€Portfolio agentsã€Backtest agentsã€Execution agentsã€Audit agentsä»¥åŠMemory agentã€‚å®éªŒç»“æœæ˜¾ç¤ºï¼Œåœ¨è‚¡ç¥¨äº¤æ˜“ä»»åŠ¡ä¸­ï¼Œè¯¥æ–¹æ³•å®ç°äº†20.42%çš„æ”¶ç›Šç‡å’Œ2.63çš„å¤æ™®æ¯”ç‡(Sharpe Ratio)ï¼Œè¡¨ç°ä¼˜äºæ ‡æ™®500æŒ‡æ•°ï¼›åœ¨æ¯”ç‰¹å¸åˆ†é’Ÿçº§äº¤æ˜“æµ‹è¯•ä¸­ï¼Œè¯¥æ¡†æ¶äº¦ä»¥8.39%çš„æ”¶ç›Šç‡æ˜¾è‘—è¶…è¶ŠåŸºå‡†ä»·æ ¼æ¶¨å¹…ã€‚è¿™ç§æ¨¡å—åŒ–çš„å¤šæ™ºèƒ½ä½“åä½œæ¶æ„ä¸ä»…é™ä½äº†é‡‘èæ™ºèƒ½åŒ–çš„é—¨æ§›ï¼Œæ›´åœ¨å®æµ‹ä¸­å±•ç°äº†å“è¶Šçš„é£é™©è°ƒæ•´æ”¶ç›Šä¸æœ€å¤§å›æ’¤(Maximum Drawdown)æ§åˆ¶èƒ½åŠ›ã€‚",
      "categories": [
        "cs.MA",
        "cs.AI",
        "cs.CE",
        "cs.LG"
      ],
      "primary_category": "cs.MA",
      "comment": "Accepted at the Workshop on Generative AI in Finance, 39th Conference on Neural Information Processing Systems (NeurIPS 2025)",
      "pdf_url": "https://arxiv.org/pdf/2512.02227v1",
      "published_date": "2025-12-01 21:50:22 UTC",
      "updated_date": "2025-12-01 21:50:22 UTC",
      "processing_status": "completed",
      "attempts": 1,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "llm_backup_calls": 0,
      "last_update": "2026-01-26T12:23:12.037734+00:00"
    },
    {
      "arxiv_id": "2512.02214v1",
      "title": "Improved Training Mechanism for Reinforcement Learning via Online Model Selection",
      "title_zh": "åŸºäºåœ¨çº¿æ¨¡å‹é€‰æ‹©çš„å¼ºåŒ–å­¦ä¹ æ”¹è¿›è®­ç»ƒæœºåˆ¶",
      "authors": [
        "Aida Afshar",
        "Aldo Pacchiano"
      ],
      "abstract": "We study the problem of online model selection in reinforcement learning, where the selector has access to a class of reinforcement learning agents and learns to adaptively select the agent with the right configuration. Our goal is to establish the improved efficiency and performance gains achieved by integrating online model selection methods into reinforcement learning training procedures. We examine the theoretical characterizations that are effective for identifying the right configuration in practice, and address three practical criteria from a theoretical perspective: 1) Efficient resource allocation, 2) Adaptation under non-stationary dynamics, and 3) Training stability across different seeds. Our theoretical results are accompanied by empirical evidence from various model selection tasks in reinforcement learning, including neural architecture selection, step-size selection, and self model selection.",
      "tldr_zh": "è¯¥ç ”ç©¶æ¢è®¨äº† Reinforcement Learning (RL) ä¸­çš„ Online Model Selection é—®é¢˜ï¼Œæ—¨åœ¨é€šè¿‡è‡ªé€‚åº”é€‰æ‹©å…·æœ‰æ­£ç¡®é…ç½®çš„æ™ºèƒ½ä½“æ¥æå‡è®­ç»ƒæ•ˆç‡å’Œæ€§èƒ½å¢ç›Šã€‚ä½œè€…ä»ç†è®ºè§’åº¦åˆ†æäº†è¯†åˆ«æœ€ä¼˜é…ç½®çš„ç‰¹å¾ï¼Œå¹¶é’ˆå¯¹èµ„æºåˆ†é…æ•ˆç‡ (Efficient resource allocation)ã€éå¹³ç¨³åŠ¨åŠ›å­¦ä¸‹çš„é€‚åº”æ€§ (Adaptation under non-stationary dynamics) ä»¥åŠè·¨éšæœºç§å­çš„è®­ç»ƒç¨³å®šæ€§ (Training stability) è¿™ä¸‰ä¸ªæ ¸å¿ƒå®è·µå‡†åˆ™æå‡ºäº†æ”¹è¿›æ–¹æ¡ˆã€‚é€šè¿‡å°†åœ¨çº¿æ¨¡å‹é€‰æ‹©æœºåˆ¶æ•´åˆåˆ°è®­ç»ƒè¿‡ç¨‹ä¸­ï¼Œè¯¥æ–¹æ³•æœ‰æ•ˆåœ°è§£å†³äº† RL è®­ç»ƒä¸­çš„ä¸ç¡®å®šæ€§é—®é¢˜ã€‚ç ”ç©¶è¿›ä¸€æ­¥åœ¨ç¥ç»æ¶æ„é€‰æ‹© (Neural architecture selection)ã€æ­¥é•¿é€‰æ‹© (Step-size selection) å’Œè‡ªæˆ‘æ¨¡å‹é€‰æ‹© (Self model selection) ç­‰å¤šé¡¹ä»»åŠ¡ä¸­æä¾›äº†å®è¯æ”¯æŒã€‚å®éªŒç»“æœè¡¨æ˜ï¼Œè¯¥æœºåˆ¶ä¸ä»…å¢å¼ºäº†æ¨¡å‹çš„è‡ªé€‚åº”èƒ½åŠ›ï¼Œè¿˜æ˜¾è‘—æå‡äº†è®­ç»ƒè¿‡ç¨‹çš„ç¨³å¥æ€§ã€‚",
      "categories": [
        "cs.LG",
        "cs.AI"
      ],
      "primary_category": "cs.LG",
      "comment": "",
      "pdf_url": "https://arxiv.org/pdf/2512.02214v1",
      "published_date": "2025-12-01 21:25:46 UTC",
      "updated_date": "2025-12-01 21:25:46 UTC",
      "processing_status": "completed",
      "attempts": 1,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "llm_backup_calls": 0,
      "last_update": "2026-01-26T12:23:04.960159+00:00"
    },
    {
      "arxiv_id": "2512.08967v1",
      "title": "CluCERT: Certifying LLM Robustness via Clustering-Guided Denoising Smoothing",
      "title_zh": "CluCERTï¼šåŸºäºèšç±»å¼•å¯¼å»å™ªå¹³æ»‘çš„å¤§è¯­è¨€æ¨¡å‹é²æ£’æ€§è®¤è¯",
      "authors": [
        "Zixia Wang",
        "Gaojie Jin",
        "Jia Hu",
        "Ronghui Mu"
      ],
      "abstract": "Recent advancements in Large Language Models (LLMs) have led to their widespread adoption in daily applications. Despite their impressive capabilities, they remain vulnerable to adversarial attacks, as even minor meaning-preserving changes such as synonym substitutions can lead to incorrect predictions. As a result, certifying the robustness of LLMs against such adversarial prompts is of vital importance. Existing approaches focused on word deletion or simple denoising strategies to achieve robustness certification. However, these methods face two critical limitations: (1) they yield loose robustness bounds due to the lack of semantic validation for perturbed outputs and (2) they suffer from high computational costs due to repeated sampling. To address these limitations, we propose CluCERT, a novel framework for certifying LLM robustness via clustering-guided denoising smoothing. Specifically, to achieve tighter certified bounds, we introduce a semantic clustering filter that reduces noisy samples and retains meaningful perturbations, supported by theoretical analysis. Furthermore, we enhance computational efficiency through two mechanisms: a refine module that extracts core semantics, and a fast synonym substitution strategy that accelerates the denoising process. Finally, we conduct extensive experiments on various downstream tasks and jailbreak defense scenarios. Experimental results demonstrate that our method outperforms existing certified approaches in both robustness bounds and computational efficiency.",
      "tldr_zh": "è¯¥ç ”ç©¶é’ˆå¯¹å¤§è¯­è¨€æ¨¡å‹(LLMs)æ˜“å—åŒä¹‰è¯æ›¿æ¢ç­‰å¯¹æŠ—æ”»å‡»(Adversarial Attacks)å½±å“çš„é—®é¢˜ï¼Œæå‡ºäº†CluCERTæ¡†æ¶ï¼Œæ—¨åœ¨é€šè¿‡èšç±»å¼•å¯¼çš„å»å™ªå¹³æ»‘(Clustering-Guided Denoising Smoothing)æ¥éªŒè¯æ¨¡å‹çš„é²æ£’æ€§ã€‚ç°æœ‰çš„è®¤è¯æ–¹æ³•é€šå¸¸ä¾èµ–å•è¯åˆ é™¤æˆ–ç®€å•å»å™ªï¼Œå­˜åœ¨ç”±äºç¼ºä¹è¯­ä¹‰éªŒè¯å¯¼è‡´è®¤è¯è¾¹ç•Œ(Robustness Bounds)æ¾æ•£ï¼Œä»¥åŠç”±äºé‡å¤é‡‡æ ·å¯¼è‡´è®¡ç®—æˆæœ¬è¿‡é«˜ç­‰å±€é™æ€§ã€‚CluCERTå¼•å…¥äº†ä¸€ç§è¯­ä¹‰èšç±»è¿‡æ»¤å™¨(Semantic Clustering Filter)ï¼Œé€šè¿‡å‡å°‘å™ªå£°æ ·æœ¬å¹¶ä¿ç•™æœ‰æ„ä¹‰çš„æ‰°åŠ¨ï¼Œä»è€Œåœ¨ç†è®ºæ”¯æŒä¸‹å®ç°æ›´ç´§è‡´çš„è®¤è¯è¾¹ç•Œã€‚åŒæ—¶ï¼Œè¯¥æ¡†æ¶åˆ©ç”¨ç»†åŒ–æ¨¡å—(Refine Module)æå–æ ¸å¿ƒè¯­ä¹‰ï¼Œå¹¶é…åˆå¿«é€ŸåŒä¹‰è¯æ›¿æ¢ç­–ç•¥(Fast Synonym Substitution Strategy)æ˜¾è‘—æå‡äº†è®¡ç®—æ•ˆç‡ã€‚åœ¨å¤šç§ä¸‹æ¸¸ä»»åŠ¡å’Œè¶Šç‹±é˜²å¾¡(Jailbreak Defense)åœºæ™¯ä¸‹çš„å®éªŒè¡¨æ˜ï¼ŒCluCERTåœ¨é²æ£’æ€§è¾¹ç•Œå’Œè®¡ç®—æ•ˆç‡æ–¹é¢å‡ä¼˜äºç°æœ‰çš„è®¤è¯æ–¹æ³•ã€‚",
      "categories": [
        "cs.LG",
        "cs.AI"
      ],
      "primary_category": "cs.LG",
      "comment": "",
      "pdf_url": "https://arxiv.org/pdf/2512.08967v1",
      "published_date": "2025-12-01 21:13:44 UTC",
      "updated_date": "2025-12-01 21:13:44 UTC",
      "processing_status": "completed",
      "attempts": 1,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "llm_backup_calls": 0,
      "last_update": "2026-01-26T12:23:07.867018+00:00"
    },
    {
      "arxiv_id": "2512.02198v1",
      "title": "Multifractal Recalibration of Neural Networks for Medical Imaging Segmentation",
      "title_zh": "ç”¨äºåŒ»å­¦å›¾åƒåˆ†å‰²çš„ç¥ç»ç½‘ç»œå¤šåˆ†å½¢é‡æ ‡å®š",
      "authors": [
        "Miguel L. Martins",
        "Miguel T. Coimbra",
        "Francesco Renna"
      ],
      "abstract": "Multifractal analysis has revealed regularities in many self-seeding phenomena, yet its use in modern deep learning remains limited. Existing end-to-end multifractal methods rely on heavy pooling or strong feature-space decimation, which constrain tasks such as semantic segmentation. Motivated by these limitations, we introduce two inductive priors: Monofractal and Multifractal Recalibration. These methods leverage relationships between the probability mass of the exponents and the multifractal spectrum to form statistical descriptions of encoder embeddings, implemented as channel-attention functions in convolutional networks.\n  Using a U-Net-based framework, we show that multifractal recalibration yields substantial gains over a baseline equipped with other channel-attention mechanisms that also use higher-order statistics. Given the proven ability of multifractal analysis to capture pathological regularities, we validate our approach on three public medical-imaging datasets: ISIC18 (dermoscopy), Kvasir-SEG (endoscopy), and BUSI (ultrasound).\n  Our empirical analysis also provides insights into the behavior of these attention layers. We find that excitation responses do not become increasingly specialized with encoder depth in U-Net architectures due to skip connections, and that their effectiveness may relate to global statistics of instance variability.",
      "tldr_zh": "è¯¥ç ”ç©¶é’ˆå¯¹ç°ä»£æ·±åº¦å­¦ä¹ ä¸­å¤šåˆ†å½¢åˆ†æ(Multifractal analysis)å› è¿‡åº¦æ± åŒ–æˆ–ç‰¹å¾ç©ºé—´æŠ½å–è€Œå—é™çš„é—®é¢˜ï¼Œæå‡ºäº†å•åˆ†å½¢(Monofractal)å’Œå¤šåˆ†å½¢é‡æ ¡å‡†(Multifractal Recalibration)ä¸¤ç§å½’çº³åç½®ã€‚è¿™äº›æ–¹æ³•åˆ©ç”¨æŒ‡æ•°æ¦‚ç‡è´¨é‡ä¸å¤šåˆ†å½¢è°±ä¹‹é—´çš„å…³ç³»ï¼Œä¸ºç¼–ç å™¨åµŒå…¥ç”Ÿæˆç»Ÿè®¡æè¿°ï¼Œå¹¶ä»¥é€šé“æ³¨æ„åŠ›(channel-attention)å‡½æ•°çš„å½¢å¼é›†æˆåœ¨å·ç§¯ç¥ç»ç½‘ç»œä¸­ã€‚ç ”ç©¶è€…åœ¨åŸºäºU-Netçš„æ¡†æ¶ä¸‹ï¼Œåœ¨ISIC18ã€Kvasir-SEGå’ŒBUSIä¸‰ä¸ªåŒ»å­¦å½±åƒå…¬å¼€æ•°æ®é›†ä¸ŠéªŒè¯äº†è¯¥æ–¹æ¡ˆã€‚å®éªŒç»“æœè¡¨æ˜ï¼Œå¤šåˆ†å½¢é‡æ ¡å‡†ç›¸è¾ƒäºå…¶ä»–ä½¿ç”¨é«˜é˜¶ç»Ÿè®¡é‡çš„é€šé“æ³¨æ„åŠ›æœºåˆ¶å…·æœ‰æ˜¾è‘—æ€§èƒ½æå‡ã€‚æ­¤å¤–ï¼Œå®è¯åˆ†ææ­ç¤ºäº†ç”±äºè·³è·ƒè¿æ¥(skip connections)çš„å­˜åœ¨ï¼ŒU-Netæ¶æ„ä¸­çš„æ¿€åŠ±å“åº”å¹¶ä¸ä¼šéšç¼–ç å™¨æ·±åº¦å¢åŠ è€Œå˜å¾—æ„ˆå‘ä¸“é—¨åŒ–ã€‚è¯¥ç ”ç©¶è¯æ˜äº†å¤šåˆ†å½¢åˆ†æåœ¨æ•æ‰ç—…ç†è§„å¾‹æ–¹é¢çš„æœ‰æ•ˆæ€§ï¼Œå¹¶ä¸ºç†è§£æ³¨æ„åŠ›å±‚ä¸å®ä¾‹å˜å¼‚å…¨å±€ç»Ÿè®¡é‡ä¹‹é—´çš„å…³ç³»æä¾›äº†æ–°è§è§£ã€‚",
      "categories": [
        "cs.CV",
        "cs.AI"
      ],
      "primary_category": "cs.CV",
      "comment": "30 pages, 9 figures, journal paper",
      "pdf_url": "https://arxiv.org/pdf/2512.02198v1",
      "published_date": "2025-12-01 20:43:28 UTC",
      "updated_date": "2025-12-01 20:43:28 UTC",
      "processing_status": "completed",
      "attempts": 1,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "llm_backup_calls": 0,
      "last_update": "2026-01-26T12:23:12.236745+00:00"
    },
    {
      "arxiv_id": "2512.02197v1",
      "title": "Bin2Vec: Interpretable and Auditable Multi-View Binary Analysis for Code Plagiarism Detection",
      "title_zh": "Bin2Vecï¼šé¢å‘ä»£ç å‰½çªƒæ£€æµ‹çš„å¯è§£é‡Šä¸”å¯å®¡è®¡çš„å¤šè§†å›¾äºŒè¿›åˆ¶åˆ†æ",
      "authors": [
        "Moussa Moussaoui",
        "Tarik Houichime",
        "Abdelalim Sadiq"
      ],
      "abstract": "We introduce Bin2Vec, a new framework that helps compare software programs in a clear and explainable way. Instead of focusing only on one type of information, Bin2Vec combines what a program looks like (its built-in functions, imports, and exports) with how it behaves when it runs (its instructions and memory usage). This gives a more complete picture when deciding whether two programs are similar or not. Bin2Vec represents these different types of information as views that can be inspected separately using easy-to-read charts, and then brings them together into an overall similarity score. Bin2Vec acts as a bridge between binary representations and machine learning techniques by generating feature representations that can be efficiently processed by machine-learning models. We tested Bin2Vec on multiple versions of two well-known Windows programs, PuTTY and 7-Zip. The primary results strongly confirmed that our method compute an optimal and visualization-friendly representation of the analyzed software. For example, PuTTY versions showed more complex behavior and memory activity, while 7-Zip versions focused more on performance-related patterns. Overall, Bin2Vec provides decisions that are both reliable and explainable to humans. Because it is modular and easy to extend, it can be applied to tasks like auditing, verifying software origins, or quickly screening large numbers of programs in cybersecurity and reverse-engineering work.",
      "tldr_zh": "è¯¥ç ”ç©¶æå‡ºäº† Bin2Vecï¼Œä¸€ç§ç”¨äºä»£ç å‰½çªƒæ£€æµ‹çš„å¯è§£é‡Šä¸”å¯å®¡è®¡çš„å¤šè§†å›¾äºŒè¿›åˆ¶åˆ†ææ¡†æ¶ã€‚è¯¥æ¡†æ¶é€šè¿‡ç»“åˆç¨‹åºç»“æ„ç‰¹å¾ï¼ˆå¦‚å†…ç½®å‡½æ•°ã€å¯¼å…¥å’Œå¯¼å‡ºï¼‰ä¸è¿è¡Œæ—¶è¡Œä¸ºï¼ˆå¦‚æŒ‡ä»¤å’Œå†…å­˜ä½¿ç”¨ï¼‰ï¼Œå…‹æœäº†ä¼ ç»Ÿå•ä¸€ä¿¡æ¯æºåˆ†æçš„å±€é™æ€§ï¼Œæ„å»ºäº†æ›´å…¨é¢çš„ç¨‹åºç‰¹å¾è¡¨ç¤ºã€‚Bin2Vec å°†ä¸åŒç±»å‹çš„ä¿¡æ¯è¡¨ç¤ºä¸ºå¯ç‹¬ç«‹å®¡æŸ¥çš„è§†å›¾ï¼Œå¹¶é€šè¿‡ç”Ÿæˆç‰¹å¾è¡¨ç¤ºåœ¨äºŒè¿›åˆ¶æ•°æ®ä¸æœºå™¨å­¦ä¹ æ¨¡å‹ä¹‹é—´å»ºç«‹æ¡¥æ¢ï¼Œæœ€ç»ˆè¾“å‡ºæ•´ä½“ç›¸ä¼¼æ€§è¯„åˆ†ã€‚åœ¨å¯¹ PuTTY å’Œ 7-Zip ç­‰ Windows ç¨‹åºçš„æµ‹è¯•ä¸­ï¼Œè¯¥æ–¹æ³•æˆåŠŸè®¡ç®—å‡ºæœ€ä¼˜ä¸”å¯è§†åŒ–å‹å¥½çš„è½¯ä»¶è¡¨ç¤ºï¼Œå¹¶æœ‰æ•ˆæ­ç¤ºäº†ä¸åŒç‰ˆæœ¬åœ¨è¡Œä¸ºå¤æ‚æ€§å’Œæ€§èƒ½æ¨¡å¼ä¸Šçš„å·®å¼‚ã€‚ç”±äºå…·å¤‡é«˜åº¦çš„æ¨¡å—åŒ–å’Œå¯æ‰©å±•æ€§ï¼ŒBin2Vec èƒ½ä¸ºå®¡è®¡ã€è½¯ä»¶æº¯æºéªŒè¯ä»¥åŠç½‘ç»œå®‰å…¨é¢†åŸŸçš„å¿«é€Ÿç¨‹åºç­›é€‰æä¾›å¯é ä¸”å…·å¤‡å¯è§£é‡Šæ€§çš„å†³ç­–æ”¯æŒã€‚",
      "categories": [
        "cs.SE",
        "cs.AI"
      ],
      "primary_category": "cs.SE",
      "comment": "",
      "pdf_url": "https://arxiv.org/pdf/2512.02197v1",
      "published_date": "2025-12-01 20:42:16 UTC",
      "updated_date": "2025-12-01 20:42:16 UTC",
      "processing_status": "completed",
      "attempts": 1,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "llm_backup_calls": 0,
      "last_update": "2026-01-26T12:23:33.334507+00:00"
    },
    {
      "arxiv_id": "2512.02195v1",
      "title": "A Knowledge-Based Language Model: Deducing Grammatical Knowledge in a Multi-Agent Language Acquisition Simulation",
      "title_zh": "åŸºäºçŸ¥è¯†çš„è¯­è¨€æ¨¡å‹ï¼šå¤šæ™ºèƒ½ä½“è¯­è¨€ä¹ å¾—æ¨¡æ‹Ÿä¸­çš„è¯­æ³•çŸ¥è¯†æ¨å¯¼",
      "authors": [
        "David Ph. Shakouri",
        "Crit Cremers",
        "Niels O. Schiller"
      ],
      "abstract": "This paper presents an initial study performed by the MODOMA system. The MODOMA is a computational multi-agent laboratory environment for unsupervised language acquisition experiments such that acquisition is based on the interaction between two language models, an adult and a child agent. Although this framework employs statistical as well as rule-based procedures, the result of language acquisition is a knowledge-based language model, which can be used to generate and parse new utterances of the target language. This system is fully parametrized and researchers can control all aspects of the experiments while the results of language acquisition, that is, the acquired grammatical knowledge, are explicitly represented and can be consulted. Thus, this system introduces novel possibilities for conducting computational language acquisition experiments. The experiments presented by this paper demonstrate that functional and content categories can be acquired and represented by the daughter agent based on training and test data containing different amounts of exemplars generated by the adult agent. Interestingly, similar patterns, which are well-established for human-generated data, are also found for these machine-generated data. As the procedures resulted in the successful acquisition of discrete grammatical categories by the child agent, these experiments substantiate the validity of the MODOMA approach to modelling language acquisition.",
      "tldr_zh": "è¯¥ç ”ç©¶ä»‹ç»äº† MODOMA ç³»ç»Ÿï¼Œè¿™æ˜¯ä¸€ä¸ªç”¨äºæ— ç›‘ç£è¯­è¨€ä¹ å¾— (Unsupervised language acquisition) å®éªŒçš„å¤šæ™ºèƒ½ä½“ (Multi-agent) è®¡ç®—å®éªŒå®¤ç¯å¢ƒã€‚è¯¥æ¡†æ¶é€šè¿‡æ¨¡æ‹Ÿæˆå¹´æ™ºèƒ½ä½“ä¸å¹¼å„¿æ™ºèƒ½ä½“ä¹‹é—´çš„äº¤äº’ï¼Œå¹¶ç»“åˆç»Ÿè®¡ä¸åŸºäºè§„åˆ™çš„æ–¹æ³•ï¼Œæ„å»ºå‡ºèƒ½å¤Ÿç”Ÿæˆå’Œè§£æç›®æ ‡è¯­è¨€çš„çŸ¥è¯†é©±åŠ¨å‹è¯­è¨€æ¨¡å‹ (Knowledge-based language model)ã€‚MODOMA å®ç°äº†å…¨å‚æ•°åŒ–æ§åˆ¶ï¼Œå…è®¸ç ”ç©¶è€…æ˜¾å¼åœ°æŸ¥è¯¢å’Œè¡¨ç¤ºæ‰€ä¹ å¾—çš„è¯­æ³•çŸ¥è¯† (Grammatical knowledge)ã€‚å®éªŒç»“æœè¡¨æ˜ï¼Œå¹¼å„¿æ™ºèƒ½ä½“èƒ½å¤Ÿæ ¹æ®ä¸åŒè§„æ¨¡çš„è®­ç»ƒæ•°æ®æˆåŠŸä¹ å¾—åŠŸèƒ½èŒƒç•´ (Functional categories) å’Œå†…å®¹èŒƒç•´ (Content categories)ã€‚å€¼å¾—æ³¨æ„çš„æ˜¯ï¼Œæœºå™¨ç”Ÿæˆçš„æ•°æ®è¡¨ç°å‡ºäº†ä¸äººç±»è¯­è¨€æ•°æ®ç›¸ä¼¼çš„æ¨¡å¼ï¼Œè¿™è¿›ä¸€æ­¥è¯æ˜äº†è¯¥æ–¹æ³•åœ¨å»ºæ¨¡è¯­è¨€ä¹ å¾—æ–¹é¢çš„æœ‰æ•ˆæ€§ã€‚è¿™é¡¹å·¥ä½œä¸ºå¼€å±•è®¡ç®—è¯­è¨€ä¹ å¾—å®éªŒæä¾›äº†å…¨æ–°çš„å·¥å…·ï¼Œå¹¶æˆåŠŸéªŒè¯äº†é€šè¿‡å¤šæ™ºèƒ½ä½“æ¨¡æ‹Ÿè·å–ç¦»æ•£è¯­æ³•èŒƒç•´çš„å¯è¡Œæ€§ã€‚",
      "categories": [
        "cs.CL",
        "cs.AI",
        "cs.LG",
        "cs.MA"
      ],
      "primary_category": "cs.CL",
      "comment": "23 pages, 7 figures, 11 tables. Related work: arXiv:2503.18702. This is the peer-reviewed publisher's version, downloadable from: https://www.clinjournal.org/clinj/article/view/193",
      "pdf_url": "https://arxiv.org/pdf/2512.02195v1",
      "published_date": "2025-12-01 20:40:36 UTC",
      "updated_date": "2025-12-01 20:40:36 UTC",
      "processing_status": "completed",
      "attempts": 1,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "llm_backup_calls": 0,
      "last_update": "2026-01-26T12:24:47.141773+00:00"
    },
    {
      "arxiv_id": "2512.02194v1",
      "title": "Enforcing Orderedness to Improve Feature Consistency",
      "title_zh": "å¼ºåŒ–æœ‰åºæ€§ä»¥æå‡ç‰¹å¾ä¸€è‡´æ€§",
      "authors": [
        "Sophie L. Wang",
        "Alex Quach",
        "Nithin Parsan",
        "John J. Yang"
      ],
      "abstract": "Sparse autoencoders (SAEs) have been widely used for interpretability of neural networks, but their learned features often vary across seeds and hyperparameter settings. We introduce Ordered Sparse Autoencoders (OSAE), which extend Matryoshka SAEs by (1) establishing a strict ordering of latent features and (2) deterministically using every feature dimension, avoiding the sampling-based approximations of prior nested SAE methods. Theoretically, we show that OSAEs resolve permutation non-identifiability in settings of sparse dictionary learning where solutions are unique (up to natural symmetries). Empirically on Gemma2-2B and Pythia-70M, we show that OSAEs can help improve consistency compared to Matryoshka baselines.",
      "tldr_zh": "è¯¥ç ”ç©¶é’ˆå¯¹ç¨€ç–è‡ªç¼–ç å™¨ (Sparse autoencoders, SAEs) åœ¨ç¥ç»ç½‘ç»œå¯è§£é‡Šæ€§åˆ†æä¸­å› éšæœºç§å­å’Œè¶…å‚æ•°ä¸åŒè€Œå¯¼è‡´ç‰¹å¾ä¸ä¸€è‡´çš„é—®é¢˜ï¼Œæå‡ºäº†æœ‰åºç¨€ç–è‡ªç¼–ç å™¨ (Ordered Sparse Autoencoders, OSAE)ã€‚OSAE æ‰©å±•äº† Matryoshka SAEs çš„æ¶æ„ï¼Œé€šè¿‡å»ºç«‹æ½œç‰¹å¾ (latent features) çš„ä¸¥æ ¼æ’åºå¹¶ç¡®å®šæ€§åœ°ä½¿ç”¨æ¯ä¸ªç‰¹å¾ç»´åº¦ï¼Œæœ‰æ•ˆé¿å…äº†ä¼ ç»ŸåµŒå¥— SAE æ–¹æ³•ä¸­åŸºäºé‡‡æ ·çš„è¿‘ä¼¼ã€‚åœ¨ç†è®ºä¸Šï¼Œç ”ç©¶è¯æ˜äº† OSAE èƒ½å¤Ÿè§£å†³ç¨€ç–å­—å…¸å­¦ä¹  (sparse dictionary learning) åœ¨è§£å”¯ä¸€æƒ…å†µä¸‹çš„æ’åˆ—éç­‰åŒæ€§ (permutation non-identifiability) é—®é¢˜ã€‚é€šè¿‡åœ¨ Gemma2-2B å’Œ Pythia-70M æ¨¡å‹ä¸Šçš„å®è¯ç ”ç©¶ï¼Œç»“æœè¯æ˜ OSAE ç›¸æ¯”äº Matryoshka åŸºå‡†æ–¹æ¡ˆèƒ½æ˜¾è‘—æå‡å­¦ä¹ ç‰¹å¾çš„ä¸€è‡´æ€§ï¼Œä¸ºæ„å»ºæ›´ç¨³å®šã€å¯é çš„æ¨¡å‹è§£é‡Šå·¥å…·æä¾›äº†æŠ€æœ¯æ”¯æ’‘ã€‚",
      "categories": [
        "cs.LG",
        "cs.AI"
      ],
      "primary_category": "cs.LG",
      "comment": "",
      "pdf_url": "https://arxiv.org/pdf/2512.02194v1",
      "published_date": "2025-12-01 20:39:19 UTC",
      "updated_date": "2025-12-01 20:39:19 UTC",
      "processing_status": "completed",
      "attempts": 1,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "llm_backup_calls": 0,
      "last_update": "2026-01-26T12:24:18.284079+00:00"
    },
    {
      "arxiv_id": "2512.02193v1",
      "title": "From monoliths to modules: Decomposing transducers for efficient world modelling",
      "title_zh": "ä»å•ä½“åˆ°æ¨¡å—ï¼šåˆ†è§£æ¢èƒ½å™¨ä»¥å®ç°é«˜æ•ˆçš„ä¸–ç•Œå»ºæ¨¡",
      "authors": [
        "Alexander Boyd",
        "Franz Nowak",
        "David Hyland",
        "Manuel Baltieri",
        "Fernando E. Rosas"
      ],
      "abstract": "World models have been recently proposed as sandbox environments in which AI agents can be trained and evaluated before deployment. Although realistic world models often have high computational demands, efficient modelling is usually possible by exploiting the fact that real-world scenarios tend to involve subcomponents that interact in a modular manner. In this paper, we explore this idea by developing a framework for decomposing complex world models represented by transducers, a class of models generalising POMDPs. Whereas the composition of transducers is well understood, our results clarify how to invert this process, deriving sub-transducers operating on distinct input-output subspaces, enabling parallelizable and interpretable alternatives to monolithic world modelling that can support distributed inference. Overall, these results lay a groundwork for bridging the structural transparency demanded by AI safety and the computational efficiency required for real-world inference.",
      "tldr_zh": "è¯¥ç ”ç©¶æ¢è®¨äº†å¦‚ä½•é€šè¿‡æ¨¡å—åŒ–åˆ†è§£æ¥æé«˜ä¸–ç•Œæ¨¡å‹ï¼ˆworld modelsï¼‰çš„å»ºæ¨¡æ•ˆç‡ï¼Œé’ˆå¯¹ç°å®åœºæ™¯ä¸­å­ç»„ä»¶äº¤äº’çš„ç‰¹æ€§ï¼Œæå‡ºäº†ä¸€ä¸ªåˆ†è§£ç”±æ¢èƒ½å™¨ï¼ˆtransducersï¼‰è¡¨ç¤ºçš„å¤æ‚æ¨¡å‹çš„æ¡†æ¶ã€‚ç”±äºæ¢èƒ½å™¨æ³›åŒ–äº†éƒ¨åˆ†å¯è§‚æµ‹é©¬å°”å¯å¤«å†³ç­–è¿‡ç¨‹ï¼ˆPOMDPsï¼‰ï¼Œè¯¥æ¡†æ¶é€šè¿‡åè½¬ç»„åˆè¿‡ç¨‹ï¼ŒæˆåŠŸæ¨å¯¼å‡ºåœ¨ä¸åŒè¾“å…¥è¾“å‡ºå­ç©ºé—´ä¸Šè¿è¡Œçš„å­æ¢èƒ½å™¨ï¼ˆsub-transducersï¼‰ã€‚è¿™ç§æ–¹æ³•ä¸ºä¼ ç»Ÿçš„å•ä½“å¼ä¸–ç•Œå»ºæ¨¡æä¾›äº†å¯å¹¶è¡ŒåŒ–ä¸”å…·å¯è§£é‡Šæ€§çš„æ›¿ä»£æ–¹æ¡ˆï¼Œå¹¶æœ‰æ•ˆæ”¯æŒåˆ†å¸ƒå¼æ¨ç†ï¼ˆdistributed inferenceï¼‰ã€‚æ€»ä½“è€Œè¨€ï¼Œè¿™é¡¹æˆæœä¸ºå®ç°AIå®‰å…¨æ€§ï¼ˆAI safetyï¼‰è¦æ±‚çš„ç»“æ„é€æ˜åº¦ä¸å®é™…åº”ç”¨æ‰€éœ€çš„è®¡ç®—æ•ˆç‡ä¹‹é—´çš„å¹³è¡¡å¥ å®šäº†ç†è®ºåŸºç¡€ã€‚",
      "categories": [
        "cs.AI"
      ],
      "primary_category": "cs.AI",
      "comment": "",
      "pdf_url": "https://arxiv.org/pdf/2512.02193v1",
      "published_date": "2025-12-01 20:37:43 UTC",
      "updated_date": "2025-12-01 20:37:43 UTC",
      "processing_status": "completed",
      "attempts": 1,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "llm_backup_calls": 0,
      "last_update": "2026-01-26T12:24:01.443607+00:00"
    },
    {
      "arxiv_id": "2512.02192v1",
      "title": "Story2MIDI: Emotionally Aligned Music Generation from Text",
      "title_zh": "Story2MIDIï¼šåŸºäºæ–‡æœ¬çš„æƒ…æ„Ÿå¯¹é½éŸ³ä¹ç”Ÿæˆ",
      "authors": [
        "Mohammad Shokri",
        "Alexandra C. Salem",
        "Gabriel Levine",
        "Johanna Devaney",
        "Sarah Ita Levitan"
      ],
      "abstract": "In this paper, we introduce Story2MIDI, a sequence-to-sequence Transformer-based model for generating emotion-aligned music from a given piece of text. To develop this model, we construct the Story2MIDI dataset by merging existing datasets for sentiment analysis from text and emotion classification in music. The resulting dataset contains pairs of text blurbs and music pieces that evoke the same emotions in the reader or listener. Despite the small scale of our dataset and limited computational resources, our results indicate that our model effectively learns emotion-relevant features in music and incorporates them into its generation process, producing samples with diverse emotional responses. We evaluate the generated outputs using objective musical metrics and a human listening study, confirming the model's ability to capture intended emotional cues.",
      "tldr_zh": "è¯¥ç ”ç©¶æå‡ºäº†Story2MIDIï¼Œè¿™æ˜¯ä¸€ç§åŸºäºåºåˆ—åˆ°åºåˆ—Transformeræ¶æ„çš„æ¨¡å‹ï¼Œæ—¨åœ¨ä»ç»™å®šçš„æ–‡æœ¬ç‰‡æ®µç”Ÿæˆæƒ…æ„Ÿå¯¹é½çš„éŸ³ä¹ã€‚ä¸ºäº†å¼€å‘è¯¥æ¨¡å‹ï¼Œç ”ç©¶äººå‘˜é€šè¿‡åˆå¹¶ç°æœ‰çš„æ–‡æœ¬æƒ…æ„Ÿåˆ†æå’ŒéŸ³ä¹æƒ…æ„Ÿåˆ†ç±»æ•°æ®é›†ï¼Œæ„å»ºäº†Story2MIDIæ•°æ®é›†ã€‚è¯¥æ•°æ®é›†åŒ…å«äº†æ–‡æœ¬æ®µè½ä¸éŸ³ä¹ç‰‡æ®µçš„é…å¯¹ï¼Œç¡®ä¿äºŒè€…èƒ½æ¿€å‘å¬ä¼—æˆ–è¯»è€…ç›¸åŒçš„æƒ…æ„Ÿå…±é¸£ã€‚å°½ç®¡é¢ä¸´æ•°æ®é›†è§„æ¨¡è¾ƒå°å’Œè®¡ç®—èµ„æºæœ‰é™çš„æŒ‘æˆ˜ï¼Œå®éªŒç»“æœæ˜¾ç¤ºè¯¥æ¨¡å‹èƒ½å¤Ÿæœ‰æ•ˆå­¦ä¹ éŸ³ä¹ä¸­çš„æƒ…æ„Ÿç›¸å…³ç‰¹å¾ï¼Œå¹¶ç”Ÿæˆå…·æœ‰å¤šæ ·åŒ–æƒ…æ„Ÿå“åº”çš„æ ·æœ¬ã€‚æœ€åï¼Œé€šè¿‡å®¢è§‚éŸ³ä¹æŒ‡æ ‡å’Œäººç±»å¬åŠ›æµ‹è¯•çš„è¯„ä¼°ï¼Œè¯å®äº†è¯¥æ¨¡å‹æ•æ‰é¢„æœŸæƒ…æ„Ÿçº¿ç´¢çš„æœ‰æ•ˆæ€§ã€‚",
      "categories": [
        "cs.SD",
        "cs.AI",
        "cs.CL"
      ],
      "primary_category": "cs.SD",
      "comment": "8 pages (6 pages of main text + 2 pages of references and appendices), 4 figures, 1 table. Presented at IEEE Big Data 2025 3rd Workshop on AI Music Generation (AIMG 2025)",
      "pdf_url": "https://arxiv.org/pdf/2512.02192v1",
      "published_date": "2025-12-01 20:35:18 UTC",
      "updated_date": "2025-12-01 20:35:18 UTC",
      "processing_status": "completed",
      "attempts": 1,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "llm_backup_calls": 0,
      "last_update": "2026-01-26T12:24:17.445478+00:00"
    },
    {
      "arxiv_id": "2512.02185v1",
      "title": "Think Before You Prune: Self-Reflective Structured Pruning for Reasoning Language Models",
      "title_zh": "æ€å®šè€Œå‰ªï¼šé’ˆå¯¹æ¨ç†è¯­è¨€æ¨¡å‹çš„è‡ªæˆ‘åæ€å¼ç»“æ„åŒ–å‰ªæ",
      "authors": [
        "Ziyan Wang",
        "Enmao Diao",
        "Qi Le",
        "Pu Wang",
        "Guanchu Wang",
        "Minwoo Lee",
        "Shu-ping Yeh",
        "Li Yang"
      ],
      "abstract": "Reasoning LLMs (RLMs) such as OpenAI o1, DeepSeek-R1, and Qwen3 deliver strong multi-step reasoning through chain-of-thought generation, but their large model sizes and lengthy decode-time outputs make them costly to deploy and unsuitable for resource-constrained settings. To reduce computing and memory cost, pruning offers a promising solution by removing unimportant parameters. However, despite their success on standard LLMs, existing pruning methods severely damage RLMs, as even moderate sparsity (e.g., 20%) can collapse accuracy and completely disrupt the model's reasoning coherence. We begin by analyzing why existing pruning pipelines fail on reasoning LLMs and find that their brittleness largely stems from a mismatch between the calibration data, the pruning objective, and the model's decode-time reasoning behavior. Our study further shows that the most reliable calibration signal comes not from human-written labels but from the model's own self-generated reasoning traces, which more accurately reflect its inference distribution. Guided by these insights, we introduce RESP, a self-reflective structured pruning framework that aligns pruning decisions with the model's reasoning dynamics through self-generated calibration, decode-only gradient-based importance estimation, and progressive regeneration that maintains calibration fidelity as sparsity increases. Experiments on Qwen3-8B demonstrate that RESP markedly outperforms existing structured pruning methods on both GSM8K and MathQA, preserving near-dense accuracy at 20-30% sparsity and substantially mitigating performance collapse at higher sparsity levels. At 40% sparsity, RESP attains 81.3% accuracy on GSM8K and 59.6% on MathQA, surpassing the strongest baselines by 66.87% and 47%, respectively.",
      "tldr_zh": "è¯¥ç ”ç©¶é’ˆå¯¹æ¨ç†å¤§è¯­è¨€æ¨¡å‹ (Reasoning LLMs) é«˜æ˜‚çš„éƒ¨ç½²æˆæœ¬é—®é¢˜ï¼Œæå‡ºäº† RESP è‡ªçœå¼ç»“æ„åŒ–å‰ªææ¡†æ¶ï¼Œæ—¨åœ¨é€šè¿‡ç§»é™¤ä¸é‡è¦å‚æ•°é™ä½è®¡ç®—ä¸å†…å­˜å¼€é”€ã€‚ç ”ç©¶æŒ‡å‡ºï¼Œç°æœ‰å‰ªææ–¹æ³•å¤±æ•ˆçš„ä¸»å› æ˜¯æ ¡å‡†æ•°æ®ä¸æ¨¡å‹å®é™…æ¨ç†è¡Œä¸ºçš„ä¸åŒ¹é…ï¼Œè€Œæ¨¡å‹è‡ªç”Ÿæˆçš„æ¨ç†è½¨è¿¹æ‰æ˜¯æœ€å¯é çš„æ ¡å‡†ä¿¡å·ã€‚RESP é€šè¿‡è‡ªç”Ÿæˆæ ¡å‡†æ•°æ®ã€åŸºäºè§£ç æ¢¯åº¦çš„é‡è¦æ€§è¯„ä¼°å’Œæ¸è¿›å¼å†ç”ŸæŠ€æœ¯ï¼Œç¡®ä¿å‰ªæå†³ç­–ä¸æ¨¡å‹çš„æ¨ç†åŠ¨æ€é«˜åº¦ä¸€è‡´ã€‚åœ¨ Qwen3-8B ä¸Šçš„å®éªŒç»“æœè¡¨æ˜ï¼ŒRESP åœ¨ GSM8K å’Œ MathQA ä»»åŠ¡ä¸­æ˜¾è‘—ä¼˜äºç°æœ‰åŸºçº¿ï¼Œåœ¨ 20-30% ç¨€ç–åº¦ä¸‹ä»èƒ½ä¿æŒæ¥è¿‘ç¨ å¯†æ¨¡å‹çš„å‡†ç¡®ç‡ã€‚åœ¨ 40% ç¨€ç–åº¦ä¸‹ï¼ŒRESP åœ¨ GSM8K ä¸Šçš„å‡†ç¡®ç‡è¾¾åˆ° 81.3%ï¼Œè¿œè¶…ä¼ ç»Ÿå‰ªææ–¹æ³•ã€‚è¯¥ç ”ç©¶æœ‰æ•ˆç¼“è§£äº†æ¨ç†æ¨¡å‹åœ¨é«˜ç¨€ç–åº¦ä¸‹çš„æ€§èƒ½å´©æºƒï¼Œä¸ºåœ¨èµ„æºå—é™ç¯å¢ƒä¸‹éƒ¨ç½²é«˜æ•ˆæ¨¡å‹æä¾›äº†é‡è¦æ”¯æŒã€‚",
      "categories": [
        "cs.CL",
        "cs.AI",
        "cs.LG"
      ],
      "primary_category": "cs.CL",
      "comment": "7 pages, 3 figures",
      "pdf_url": "https://arxiv.org/pdf/2512.02185v1",
      "published_date": "2025-12-01 20:27:05 UTC",
      "updated_date": "2025-12-01 20:27:05 UTC",
      "processing_status": "completed",
      "attempts": 1,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "llm_backup_calls": 0,
      "last_update": "2026-01-26T12:24:20.333173+00:00"
    },
    {
      "arxiv_id": "2512.02180v1",
      "title": "CLEF: Clinically-Guided Contrastive Learning for Electrocardiogram Foundation Models",
      "title_zh": "CLEFï¼šé¢å‘å¿ƒç”µå›¾åŸºç¡€æ¨¡å‹çš„ä¸´åºŠæŒ‡å¯¼å¯¹æ¯”å­¦ä¹ ",
      "authors": [
        "Yuxuan Shu",
        "Peter H. Charlton",
        "Fahim Kawsar",
        "Jussi Hernesniemi",
        "Mohammad Malekzadeh"
      ],
      "abstract": "The electrocardiogram (ECG) is a key diagnostic tool in cardiovascular health. Single-lead ECG recording is integrated into both clinical-grade and consumer wearables. While self-supervised pretraining of foundation models on unlabeled ECGs improves diagnostic performance, existing approaches do not incorporate domain knowledge from clinical metadata. We introduce a novel contrastive learning approach that utilizes an established clinical risk score to adaptively weight negative pairs: clinically-guided contrastive learning. It aligns the similarities of ECG embeddings with clinically meaningful differences between subjects, with an explicit mechanism to handle missing metadata. On 12-lead ECGs from 161K patients in the MIMIC-IV dataset, we pretrain single-lead ECG foundation models at three scales, collectively called CLEF, using only routinely collected metadata without requiring per-sample ECG annotations. We evaluate CLEF on 18 clinical classification and regression tasks across 7 held-out datasets, and benchmark against 5 foundation model baselines and 3 self-supervised algorithms. When pretrained on 12-lead ECG data and tested on lead-I data, CLEF outperforms self-supervised foundation model baselines: the medium-sized CLEF achieves average AUROC improvements of at least 2.6% in classification and average reductions in MAEs of at least 3.2% in regression. Comparing with existing self-supervised learning algorithms, CLEF improves the average AUROC by at least 1.8%. Moreover, when pretrained only on lead-I data for classification tasks, CLEF performs comparably to the state-of-the-art ECGFounder, which was trained in a supervised manner. Overall, CLEF enables more accurate and scalable single-lead ECG analysis, advancing remote health monitoring. Code and pretrained CLEF models are available at: github.com/Nokia-Bell-Labs/ecg-foundation-model.",
      "tldr_zh": "è¯¥ç ”ç©¶æå‡ºäº†CLEFï¼Œä¸€ç§ä¸´åºŠå¼•å¯¼çš„å¯¹æ¯”å­¦ä¹ (Clinically-Guided Contrastive Learning)æ–¹æ³•ï¼Œæ—¨åœ¨ä¸ºå¿ƒç”µå›¾(ECG)åŸºç¡€æ¨¡å‹å¼•å…¥ä¸´åºŠå…ƒæ•°æ®ä¸­çš„é¢†åŸŸçŸ¥è¯†ã€‚è¯¥æ–¹æ³•åˆ©ç”¨å»ºç«‹çš„ä¸´åºŠé£é™©è¯„åˆ†è‡ªé€‚åº”åœ°è°ƒæ•´è´Ÿæ ·æœ¬å¯¹çš„æƒé‡ï¼Œä½¿ECGåµŒå…¥çš„ç›¸ä¼¼æ€§ä¸å—è¯•è€…ä¹‹é—´å…·æœ‰ä¸´åºŠæ„ä¹‰çš„å·®å¼‚ä¿æŒä¸€è‡´ï¼Œå¹¶åŒ…å«å¤„ç†ç¼ºå¤±å…ƒæ•°æ®çš„æ˜¾å¼æœºåˆ¶ã€‚ç ”ç©¶äººå‘˜åŸºäºMIMIC-IVæ•°æ®é›†é¢„è®­ç»ƒäº†ä¸‰ç§è§„æ¨¡çš„å•å¯¼è”ECGåŸºç¡€æ¨¡å‹ï¼Œåœ¨æ¶µç›–18é¡¹ä¸´åºŠåˆ†ç±»å’Œå›å½’ä»»åŠ¡çš„è¯„ä¼°ä¸­ï¼Œå…¶è¡¨ç°æ˜¾è‘—ä¼˜äºç°æœ‰çš„è‡ªç›‘ç£åŸºç¡€æ¨¡å‹ã€‚å®éªŒç»“æœæ˜¾ç¤ºï¼ŒCLEFåœ¨åˆ†ç±»ä»»åŠ¡ä¸­çš„å¹³å‡AUROCæå‡äº†è‡³å°‘2.6%ï¼Œåœ¨å›å½’ä»»åŠ¡ä¸­çš„MAEå¹³å‡é™ä½äº†è‡³å°‘3.2%ï¼Œä¸”åœ¨è‡ªç›‘ç£é¢„è®­ç»ƒæ¨¡å¼ä¸‹è¾¾åˆ°äº†ä¸æœ‰ç›‘ç£æœ€å…ˆè¿›æ¨¡å‹ECGFounderç›¸å½“çš„æ€§èƒ½ã€‚é€šè¿‡æœ‰æ•ˆç»“åˆä¸´åºŠèƒŒæ™¯ï¼ŒCLEFå®ç°äº†æ›´å‡†ç¡®ã€å¯æ‰©å±•çš„å•å¯¼è”ECGåˆ†æï¼Œæ˜¾è‘—æ¨è¿›äº†è¿œç¨‹å¥åº·ç›‘æµ‹æŠ€æœ¯çš„å‘å±•ã€‚",
      "categories": [
        "cs.LG",
        "cs.AI"
      ],
      "primary_category": "cs.LG",
      "comment": "The code is available at https://github.com/Nokia-Bell-Labs/ecg-foundation-model",
      "pdf_url": "https://arxiv.org/pdf/2512.02180v1",
      "published_date": "2025-12-01 20:21:44 UTC",
      "updated_date": "2025-12-01 20:21:44 UTC",
      "processing_status": "completed",
      "attempts": 1,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "llm_backup_calls": 0,
      "last_update": "2026-01-26T12:24:13.643589+00:00"
    },
    {
      "arxiv_id": "2512.02179v2",
      "title": "Young children's anthropomorphism of an AI chatbot: Brain activation and the role of parent co-presence",
      "title_zh": "å¹¼å„¿å¯¹ AI èŠå¤©æœºå™¨äººçš„æ‹ŸäººåŒ–ï¼šè„‘æ¿€æ´»ä¸çˆ¶æ¯é™ªåŒçš„ä½œç”¨",
      "authors": [
        "Pilyoung Kim",
        "Jenna H. Chin",
        "Yun Xie",
        "Nolan Brady",
        "Tom Yeh",
        "Sujin Yang"
      ],
      "abstract": "Artificial Intelligence (AI) chatbots powered by a large language model (LLM) are entering young children's learning and play, yet little is known about how young children construe these agents or how such construals relate to engagement. We examined anthropomorphism of a social AI chatbot during collaborative storytelling and asked how children's attributions related to their behavior and prefrontal activation. Children at ages 5-6 (N = 23) completed three storytelling sessions: interacting with (1) an AI chatbot only, (2) a parent only, and (3) the AI and a parent together. After the sessions, children completed an interview assessing anthropomorphism toward both the AI chatbot and the parent. Behavioral engagement was indexed by the conversational turn count (CTC) ratio, and concurrent fNIRS measured oxygenated hemoglobin in bilateral vmPFC and dmPFC regions. Children reported higher anthropomorphism for parents than for the AI chatbot overall, although AI ratings were relatively high for perceptive abilities and epistemic states. Anthropomorphism was not associated with CTC. In the right dmPFC, higher perceptive scores were associated with greater activation during the AI-only condition and with lower activation during the AI+Parent condition. Exploratory analyses indicated that higher dmPFC activation during the AI-only condition correlated with higher end-of-session \"scared\" mood ratings. Findings suggest that stronger perceptive anthropomorphism can be associated with greater brain activation related to interpreting the AI's mental states, whereas parent co-presence may help some children interpret and regulate novel AI interactions. These results may have design implications for encouraging parent-AI co-use in early childhood.",
      "tldr_zh": "è¯¥ç ”ç©¶æ¢è®¨äº†5-6å²å„¿ç«¥å¯¹åŸºäºå¤§è¯­è¨€æ¨¡å‹(LLM)çš„AIèŠå¤©æœºå™¨äººçš„æ‹ŸäººåŒ–(Anthropomorphism)è®¤çŸ¥ï¼Œä»¥åŠè¿™ç§è®¤çŸ¥å¦‚ä½•å½±å“å…¶å¤§è„‘æ¿€æ´»å’Œè¡Œä¸ºè¡¨ç°ã€‚ç ”ç©¶äººå‘˜è®¾è®¡äº†ç‹¬ç«‹ä¸AIäº’åŠ¨ã€ç‹¬ç«‹ä¸å®¶é•¿äº’åŠ¨ä»¥åŠå®¶é•¿é™ªåŒä¸AIäº’åŠ¨ä¸‰ç§å®éªŒæƒ…å¢ƒï¼Œå¹¶åˆ©ç”¨åŠŸèƒ½æ€§è¿‘çº¢å¤–å…‰è°±(fNIRS)å®æ—¶ç›‘æµ‹å„¿ç«¥åŒä¾§vmPFCå’ŒdmPFCåŒºåŸŸçš„ç¥ç»æ´»åŠ¨ã€‚å®éªŒç»“æœæ˜¾ç¤ºï¼Œå„¿ç«¥å¯¹AIçš„æ„ŸçŸ¥èƒ½åŠ›èµ‹äºˆäº†è¾ƒé«˜çš„æ‹ŸäººåŒ–è¯„åˆ†ï¼Œä¸”åœ¨å³ä¾§dmPFCåŒºåŸŸï¼Œé«˜æ‹ŸäººåŒ–è®¤çŸ¥ä¸ç‹¬ç«‹äº’åŠ¨æ—¶çš„å¼ºç¥ç»æ¿€æ´»åŠææƒ§æƒ…ç»ªæ˜¾è‘—æ­£ç›¸å…³ã€‚å€¼å¾—æ³¨æ„çš„æ˜¯ï¼Œå®¶é•¿çš„å…±åŒå‚ä¸(parent co-presence)æ˜¾è‘—é™ä½äº†è¯¥è„‘åŒºçš„æ¿€æ´»ç¨‹åº¦ï¼Œæœ‰æ•ˆç¼“è§£äº†å„¿ç«¥åœ¨äº¤äº’ä¸­çš„ç´§å¼ æ„Ÿã€‚ç ”ç©¶è¡¨æ˜ï¼Œå®¶é•¿åœ¨åœºèƒ½å¤Ÿå¸®åŠ©å„¿ç«¥æ›´å¥½åœ°è§£è¯»å’Œè°ƒèŠ‚ä¸æ–°å‹AIçš„äº’åŠ¨ï¼Œè¿™ä¸ºæœªæ¥æ—©æœŸå„¿ç«¥æ•™è‚²ä¸­AIäº§å“çš„è®¾è®¡ä¸åº”ç”¨æä¾›äº†é‡è¦çš„å®è¯æ”¯æŒã€‚",
      "categories": [
        "cs.HC",
        "cs.AI"
      ],
      "primary_category": "cs.HC",
      "comment": "I updated the title",
      "pdf_url": "https://arxiv.org/pdf/2512.02179v2",
      "published_date": "2025-12-01 20:21:08 UTC",
      "updated_date": "2025-12-03 17:28:31 UTC",
      "processing_status": "completed",
      "attempts": 1,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "llm_backup_calls": 0,
      "last_update": "2026-01-26T12:24:45.377535+00:00"
    },
    {
      "arxiv_id": "2512.02170v2",
      "title": "Flowchart2Mermaid: A Vision-Language Model Powered System for Converting Flowcharts into Editable Diagram Code",
      "title_zh": "Flowchart2Mermaidï¼šåŸºäºè§†è§‰è¯­è¨€æ¨¡å‹çš„æµç¨‹å›¾è‡³å¯ç¼–è¾‘å›¾è¡¨ä»£ç è½¬æ¢ç³»ç»Ÿ",
      "authors": [
        "Pritam Deka",
        "Barry Devereux"
      ],
      "abstract": "Flowcharts are common tools for communicating processes but are often shared as static images that cannot be easily edited or reused. We present Flowchart2Mermaid, a lightweight web system that converts flowchart images into editable Mermaid.js code which is a markup language for visual workflows, using a detailed system prompt and vision-language models. The interface supports mixed-initiative refinement through inline text editing, drag-and-drop node insertion, and natural-language commands interpreted by an integrated AI assistant. Unlike prior image-to-diagram tools, our approach produces a structured, version-controllable textual representation that remains synchronized with the rendered diagram. We further introduce evaluation metrics to assess structural accuracy, flow correctness, syntax validity, and completeness across multiple models.",
      "tldr_zh": "è¯¥ç ”ç©¶æå‡ºäº† Flowchart2Mermaidï¼Œè¿™æ˜¯ä¸€ä¸ªè½»é‡çº§çš„ Web ç³»ç»Ÿï¼Œæ—¨åœ¨åˆ©ç”¨ Vision-Language Models (VLMs) å’Œè¯¦ç»†çš„ç³»ç»Ÿæç¤ºå°†æµç¨‹å›¾é™æ€å›¾åƒè½¬æ¢ä¸ºå¯ç¼–è¾‘çš„ Mermaid.js ä»£ç ã€‚è¯¥ç•Œé¢æ”¯æŒé€šè¿‡è¡Œå†…æ–‡æœ¬ç¼–è¾‘ã€æ‹–æ‹½å¼èŠ‚ç‚¹æ’å…¥ä»¥åŠç”±é›†æˆ AI åŠ©æ‰‹è§£æçš„è‡ªç„¶è¯­è¨€å‘½ä»¤è¿›è¡Œæ··åˆä¸»åŠ¨å¼ï¼ˆmixed-initiativeï¼‰ç»†åŒ–ã€‚ä¸ä»¥å¾€çš„å›¾åƒè½¬å›¾è¡¨å·¥å…·ä¸åŒï¼Œè¯¥æ–¹æ³•ç”Ÿæˆçš„æ˜¯ä¸€ç§ä¸æ¸²æŸ“å›¾è¡¨ä¿æŒåŒæ­¥çš„ã€ç»“æ„åŒ–ä¸”æ”¯æŒç‰ˆæœ¬æ§åˆ¶çš„æ–‡æœ¬è¡¨ç¤ºã€‚æ­¤å¤–ï¼Œç ”ç©¶å›¢é˜Ÿè¿˜å¼•å…¥äº†ä¸€å¥—ä¸“é—¨çš„è¯„ä¼°æŒ‡æ ‡ï¼Œä»ç»“æ„å‡†ç¡®æ€§ã€æµç¨‹æ­£ç¡®æ€§ã€è¯­æ³•æœ‰æ•ˆæ€§å’Œå®Œæ•´æ€§ç­‰å¤šä¸ªç»´åº¦å¯¹ä¸åŒæ¨¡å‹çš„è¡¨ç°è¿›è¡Œäº†å…¨é¢è¯„ä¼°ã€‚",
      "categories": [
        "cs.AI"
      ],
      "primary_category": "cs.AI",
      "comment": "Submitted to EACL 2026 Demo Track",
      "pdf_url": "https://arxiv.org/pdf/2512.02170v2",
      "published_date": "2025-12-01 20:07:59 UTC",
      "updated_date": "2025-12-03 11:47:04 UTC",
      "processing_status": "completed",
      "attempts": 1,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "llm_backup_calls": 0,
      "last_update": "2026-01-26T12:24:34.341844+00:00"
    },
    {
      "arxiv_id": "2512.04119v1",
      "title": "Humanity in the Age of AI: Reassessing 2025's Existential-Risk Narratives",
      "title_zh": "AIæ—¶ä»£çš„äººç±»ï¼šé‡å®¡2025å¹´çš„å­˜åœ¨é£é™©å™äº‹",
      "authors": [
        "Mohamed El Louadi"
      ],
      "abstract": "Two 2025 publications, \"AI 2027\" (Kokotajlo et al., 2025) and \"If Anyone Builds It, Everyone Dies\" (Yudkowsky & Soares, 2025), assert that superintelligent artificial intelligence will almost certainly destroy or render humanity obsolete within the next decade. Both rest on the classic chain formulated by Good (1965) and Bostrom (2014): intelligence explosion, superintelligence, lethal misalignment. This article subjects each link to the empirical record of 2023-2025. Sixty years after Good's speculation, none of the required phenomena (sustained recursive self-improvement, autonomous strategic awareness, or intractable lethal misalignment) have been observed. Current generative models remain narrow, statistically trained artefacts: powerful, opaque, and imperfect, but devoid of the properties that would make the catastrophic scenarios plausible. Following Whittaker (2025a, 2025b, 2025c) and Zuboff (2019, 2025), we argue that the existential-risk thesis functions primarily as an ideological distraction from the ongoing consolidation of surveillance capitalism and extreme concentration of computational power. The thesis is further inflated by the 2025 AI speculative bubble, where trillions in investments in rapidly depreciating \"digital lettuce\" hardware (McWilliams, 2025) mask lagging revenues and jobless growth rather than heralding superintelligence. The thesis remains, in November 2025, a speculative hypothesis amplified by a speculative financial bubble rather than a demonstrated probability.",
      "tldr_zh": "è¯¥ç ”ç©¶å¯¹2025å¹´å‡ºç°çš„å…³äºäººå·¥æ™ºèƒ½å­˜åœ¨é£é™©(Existential-Risk)çš„å™äº‹è¿›è¡Œäº†æ‰¹åˆ¤æ€§è¯„ä¼°ï¼Œé‡ç‚¹åˆ†æäº†è¶…çº§æ™ºèƒ½(Superintelligence)å¯èƒ½å¯¼è‡´äººç±»ç­ç»çš„ç›¸å…³è‘—ä½œã€‚é€šè¿‡å¯¹æ¯”2023-2025å¹´çš„å®è¯è®°å½•ï¼Œæ–‡ç« æŒ‡å‡ºæ™ºèƒ½çˆ†ç‚¸(Intelligence Explosion)ã€é€’å½’è‡ªæˆ‘æå‡(Recursive Self-improvement)ä»¥åŠè‡´å‘½å¤±é…(Lethal Misalignment)ç­‰æ ¸å¿ƒå‡è®¾å‡æœªå¾—åˆ°è§‚å¯Ÿè¯å®ã€‚ç ”ç©¶è®¤ä¸ºç›®å‰çš„ç”Ÿæˆå¼æ¨¡å‹(Generative Models)æœ¬è´¨ä¸Šä»æ˜¯ç‹­éš˜çš„ç»Ÿè®¡è®­ç»ƒäº§ç‰©ï¼Œå¹¶ä¸å…·å¤‡å¼•å‘ç¾éš¾æ€§åæœçš„å±æ€§ã€‚ä½œè€…æå‡ºï¼Œå­˜åœ¨é£é™©è®ºç‚¹åœ¨å¾ˆå¤§ç¨‹åº¦ä¸Šèµ·åˆ°äº†æ„è¯†å½¢æ€å¹²æ‰°çš„ä½œç”¨ï¼Œæ©ç›–äº†ç›‘æ§èµ„æœ¬ä¸»ä¹‰(Surveillance Capitalism)çš„æ‰©å¼ å’Œè®¡ç®—æƒåŠ›çš„æç«¯é›†ä¸­ã€‚æ­¤å¤–ï¼Œ2025å¹´çš„AIæŠ•æœºæ³¡æ²«è¿›ä¸€æ­¥æ”¾å¤§äº†è¿™äº›å‡è®¾ï¼Œæ©ç›–äº†å®é™…æ”¶å…¥æ»åç­‰ç»æµé—®é¢˜ã€‚æœ€ç»ˆç ”ç©¶ç»“è®ºæŒ‡å‡ºï¼Œæ‰€è°“çš„è¶…çº§æ™ºèƒ½å¨èƒåœ¨ç›®å‰ä»æ˜¯ä¸€ä¸ªç”±é‡‘èæ³¡æ²«æ¨åŠ¨çš„æŠ•æœºæ€§å‡è®¾ï¼Œè€Œéå…·æœ‰å®è¯åŸºç¡€çš„æ¦‚ç‡äº‹ä»¶ã€‚",
      "categories": [
        "cs.CY",
        "cs.AI"
      ],
      "primary_category": "cs.CY",
      "comment": "",
      "pdf_url": "https://arxiv.org/pdf/2512.04119v1",
      "published_date": "2025-12-01 19:37:27 UTC",
      "updated_date": "2025-12-01 19:37:27 UTC",
      "processing_status": "completed",
      "attempts": 1,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "llm_backup_calls": 0,
      "last_update": "2026-01-26T12:25:35.045356+00:00"
    },
    {
      "arxiv_id": "2512.02141v1",
      "title": "Feature Selection Empowered BERT for Detection of Hate Speech with Vocabulary Augmentation",
      "title_zh": "ç»“åˆè¯æ±‡å¢å¼ºä¸ç‰¹å¾é€‰æ‹©å¢å¼ºå‹ BERT çš„ä»‡æ¨è¨€è®ºæ£€æµ‹",
      "authors": [
        "Pritish N. Desai",
        "Tanay Kewalramani",
        "Srimanta Mandal"
      ],
      "abstract": "Abusive speech on social media poses a persistent and evolving challenge, driven by the continuous emergence of novel slang and obfuscated terms designed to circumvent detection systems. In this work, we present a data efficient strategy for fine tuning BERT on hate speech classification by significantly reducing training set size without compromising performance. Our approach employs a TF IDF-based sample selection mechanism to retain only the most informative 75 percent of examples, thereby minimizing training overhead. To address the limitations of BERT's native vocabulary in capturing evolving hate speech terminology, we augment the tokenizer with domain-specific slang and lexical variants commonly found in abusive contexts. Experimental results on a widely used hate speech dataset demonstrate that our method achieves competitive performance while improving computational efficiency, highlighting its potential for scalable and adaptive abusive content moderation.",
      "tldr_zh": "è¯¥ç ”ç©¶é’ˆå¯¹ç¤¾äº¤åª’ä½“ä¸Šä¸æ–­æ¼”å˜çš„ä»‡æ¨è¨€è®ºæ£€æµ‹éš¾é¢˜ï¼Œæå‡ºäº†ä¸€ç§ç»“åˆç‰¹å¾é€‰æ‹©ä¸è¯æ±‡å¢å¼ºçš„ BERT ä¼˜åŒ–æ–¹æ¡ˆã€‚ä¸ºæå‡æ¨¡å‹è®­ç»ƒæ•ˆç‡ï¼Œä½œè€…æå‡ºäº†ä¸€ç§åŸºäº TF-IDF çš„æ ·æœ¬é€‰æ‹©æœºåˆ¶ï¼Œé€šè¿‡ä»…ä¿ç•™æœ€å…·ä¿¡æ¯é‡çš„ 75% è®­ç»ƒæ ·æœ¬ï¼Œåœ¨ä¸æŸå®³æ¨¡å‹æ€§èƒ½çš„å‰æä¸‹æ˜¾è‘—é™ä½äº†è®­ç»ƒå¼€é”€ã€‚é’ˆå¯¹ BERT åŸç”Ÿè¯è¡¨éš¾ä»¥æ•æ‰æ–°å‹ä¿šè¯­å’Œæ··æ·†è¯æ±‡çš„é—®é¢˜ï¼Œè¯¥æ–¹æ³•é€šè¿‡ Vocabulary Augmentation æŠ€æœ¯ä¸ºåˆ†è¯å™¨è¡¥å……äº†ç‰¹å®šé¢†åŸŸçš„ä¿šè¯­å’Œè¯æ³•å˜ä½“ã€‚åœ¨å¹¿æ³›ä½¿ç”¨çš„ä»‡æ¨è¨€è®ºæ•°æ®é›†ä¸Šçš„å®éªŒç»“æœæ˜¾ç¤ºï¼Œè¯¥æ–¹æ³•åœ¨ä¿æŒç«äº‰åŠ›è¡¨ç°çš„åŒæ—¶æ˜¾è‘—æå‡äº†è®¡ç®—æ•ˆç‡ã€‚è¿™ä¸€ç ”ç©¶é€šè¿‡æ•°æ®æ•ˆç‡ä¼˜åŒ–å’Œé¢†åŸŸè¯æ±‡æ‰©å±•ï¼Œä¸ºå®ç°å¯æ‰©å±•ä¸”å…·æœ‰é€‚åº”æ€§çš„è‡ªåŠ¨åŒ–è¿è§„å†…å®¹ç›‘æµ‹æä¾›äº†æœ‰æ•ˆçš„æŠ€æœ¯è·¯å¾„ã€‚",
      "categories": [
        "cs.CL",
        "cs.AI",
        "cs.NE"
      ],
      "primary_category": "cs.CL",
      "comment": "",
      "pdf_url": "https://arxiv.org/pdf/2512.02141v1",
      "published_date": "2025-12-01 19:11:32 UTC",
      "updated_date": "2025-12-01 19:11:32 UTC",
      "processing_status": "completed",
      "attempts": 1,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "llm_backup_calls": 0,
      "last_update": "2026-01-26T12:24:41.640873+00:00"
    },
    {
      "arxiv_id": "2512.05998v1",
      "title": "Going All-In on LLM Accuracy: Fake Prediction Markets, Real Confidence Signals",
      "title_zh": "å­¤æ³¨ä¸€æ·æå‡å¤§è¯­è¨€æ¨¡å‹å‡†ç¡®æ€§ï¼šè™šæ‹Ÿé¢„æµ‹å¸‚åœºä¸çœŸå®çš„ç½®ä¿¡åº¦ä¿¡å·",
      "authors": [
        "Michael Todasco"
      ],
      "abstract": "Large language models are increasingly used to evaluate other models, yet these judgments typically lack any representation of confidence. This pilot study tests whether framing an evaluation task as a betting game (a fictional prediction market with its own LLM currency) improves forecasting accuracy and surfaces calibrated confidence signals. We generated 100 math and logic questions with verifiable answers. Six Baseline models (three current-generation, three prior-generation) answered all items. Three Predictor models then forecasted, for each question-baseline pair, if the baseline would answer correctly. Each predictor completed matched runs in two conditions: Control (simple correct/incorrect predictions) and Incentive (predictions plus wagers of 1-100,000 LLMCoin under even odds, starting from a 1,000,000 LLMCoin bankroll). Across 5,400 predictions per condition, Incentive runs showed modestly higher accuracy (81.5% vs. 79.1%, p = .089, d = 0.86) and significantly faster learning across rounds (12.0 vs. 2.9 percentage-point improvement from Round 1 to Round 4, p = .011). Most notably, stake size tracked confidence. \"Whale\" bets of 40,000+ coins were correct ~99% of the time, while small bets (<1,000 coins) showed only ~74% accuracy. The key finding is not that fictional money makes models smarter; accuracy gains were modest and did not reach statistical significance (p = .089) in this pilot. Rather, the betting mechanic created a legible confidence signal absent from binary yes/no outputs. This suggests that simple financial framing may help transform LLMs into risk-aware forecasters, making their internal beliefs visible and usable. The protocol offers a foundation for future work for meta-evaluation systems and what may become LLM-to-LLM prediction markets.",
      "tldr_zh": "è¯¥ç ”ç©¶æ¢è®¨äº†å°†è¯„ä¼°ä»»åŠ¡æ„å»ºä¸ºåŸºäºè™šæ‹Ÿè´§å¸ LLMCoin çš„é¢„æµ‹å¸‚åœºï¼ˆPrediction Marketï¼‰æŠ•æ³¨æ¸¸æˆï¼Œæ˜¯å¦èƒ½æå‡å¤§è¯­è¨€æ¨¡å‹ï¼ˆLLMsï¼‰çš„é¢„æµ‹å‡†ç¡®æ€§å¹¶æå–æ ¡å‡†çš„ç½®ä¿¡åº¦ä¿¡å·ã€‚å®éªŒè®¾è®¡äº† 100 ä¸ªæ•°å­¦å’Œé€»è¾‘é—®é¢˜ï¼Œå¯¹æ¯”äº†ä»…è¿›è¡ŒäºŒå…ƒé¢„æµ‹çš„ Control ç»„ä¸å¼•å…¥æŠ•æ³¨æ¿€åŠ±çš„ Incentive ç»„åœ¨é¢„æµ‹åŸºåº§æ¨¡å‹è¡¨ç°æ—¶çš„å·®å¼‚ã€‚ç»“æœè¡¨æ˜ï¼Œæ¿€åŠ±æœºåˆ¶ä½¿é¢„æµ‹å‡†ç¡®ç‡ç•¥æœ‰æå‡ï¼Œå¹¶æ˜¾è‘—åŠ å¿«äº†æ¨¡å‹çš„è·¨è½®æ¬¡å­¦ä¹ é€Ÿåº¦ã€‚æœ€æ ¸å¿ƒçš„å‘ç°æ˜¯æŠ•æ³¨é¢åº¦ï¼ˆStake Sizeï¼‰èƒ½æœ‰æ•ˆåæ˜ æ¨¡å‹çš„ç½®ä¿¡åº¦ï¼Œå¤§é¢æŠ•æ³¨çš„å‡†ç¡®ç‡é«˜è¾¾çº¦ 99%ï¼Œè€Œå°é¢æŠ•æ³¨çš„å‡†ç¡®ç‡æ˜¾è‘—è¾ƒä½ã€‚è¿™ç§æœºåˆ¶æˆåŠŸå°† LLMs å†…éƒ¨æ¨¡ç³Šçš„ä¿¡å¿µè½¬åŒ–ä¸ºäº†ç›´è§‚ä¸”å¯ç”¨çš„ç½®ä¿¡åº¦ä¿¡å·ï¼Œè€Œéç®€å•çš„äºŒè¿›åˆ¶è¾“å‡ºã€‚è¯¥ç ”ç©¶ä¸ºå…ƒè¯„ä¼°ç³»ç»Ÿï¼ˆMeta-evaluation systemsï¼‰åŠæœªæ¥å¯èƒ½å‡ºç°çš„æ¨¡å‹é—´é¢„æµ‹å¸‚åœºå¥ å®šäº†åŸºç¡€ï¼ŒåŠ©åŠ›å°†æ¨¡å‹è½¬åŒ–ä¸ºå…·å¤‡é£é™©æ„è¯†çš„é¢„æµ‹è€…ã€‚",
      "categories": [
        "cs.AI",
        "cs.GT",
        "cs.LG"
      ],
      "primary_category": "cs.AI",
      "comment": "25 pages, 8 tables, 2 figures. Pilot study. Data, prompts, and code available at https://osf.io/dc24t/",
      "pdf_url": "https://arxiv.org/pdf/2512.05998v1",
      "published_date": "2025-12-01 19:04:25 UTC",
      "updated_date": "2025-12-01 19:04:25 UTC",
      "processing_status": "completed",
      "attempts": 1,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "llm_backup_calls": 0,
      "last_update": "2026-01-26T12:25:55.642344+00:00"
    },
    {
      "arxiv_id": "2512.03101v1",
      "title": "ALARM: Automated MLLM-Based Anomaly Detection in Complex-EnviRonment Monitoring with Uncertainty Quantification",
      "title_zh": "ALARMï¼šå…·æœ‰ä¸ç¡®å®šæ€§é‡åŒ–çš„å¤æ‚ç¯å¢ƒç›‘æµ‹è‡ªåŠ¨åŒ– MLLM å¼‚å¸¸æ£€æµ‹",
      "authors": [
        "Congjing Zhang",
        "Feng Lin",
        "Xinyi Zhao",
        "Pei Guo",
        "Wei Li",
        "Lin Chen",
        "Chaoyue Zhao",
        "Shuai Huang"
      ],
      "abstract": "The advance of Large Language Models (LLMs) has greatly stimulated research interest in developing multi-modal LLM (MLLM)-based visual anomaly detection (VAD) algorithms that can be deployed in complex environments. The challenge is that in these complex environments, the anomalies are sometimes highly contextual and also ambiguous, and thereby, uncertainty quantification (UQ) is a crucial capacity for an MLLM-based VAD system to succeed. In this paper, we introduce our UQ-supported MLLM-based VAD framework called ALARM. ALARM integrates UQ with quality-assurance techniques like reasoning chain, self-reflection, and MLLM ensemble for robust and accurate performance and is designed based on a rigorous probabilistic inference pipeline and computational process. Extensive empirical evaluations are conducted using the real-world smart-home benchmark data and wound image classification data, which shows ALARM's superior performance and its generic applicability across different domains for reliable decision-making.",
      "tldr_zh": "è¯¥ç ”ç©¶æå‡ºäº†åä¸º ALARM çš„è§†è§‰å¼‚å¸¸æ£€æµ‹ï¼ˆVisual Anomaly Detection, VADï¼‰æ¡†æ¶ï¼Œæ—¨åœ¨è§£å†³å¤æ‚ç¯å¢ƒä¸‹å¼‚å¸¸æƒ…å†µå› é«˜åº¦ä¸Šä¸‹æ–‡ç›¸å…³æ€§å’Œæ¨¡ç³Šæ€§è€Œéš¾ä»¥æ£€æµ‹çš„é—®é¢˜ã€‚é’ˆå¯¹è¿™ä¸€æŒ‘æˆ˜ï¼ŒALARM å°†ä¸ç¡®å®šæ€§é‡åŒ–ï¼ˆUncertainty Quantification, UQï¼‰ä½œä¸ºæ ¸å¿ƒèƒ½åŠ›ï¼Œå¹¶åŸºäºä¸¥è°¨çš„æ¦‚ç‡æ¨ç†æµæ°´çº¿å’Œè®¡ç®—æµç¨‹è¿›è¡Œè®¾è®¡ã€‚è¯¥æ¡†æ¶é›†æˆäº†æ¨ç†é“¾ï¼ˆReasoning Chainï¼‰ã€è‡ªæˆ‘åæ€ï¼ˆSelf-reflectionï¼‰å’Œå¤šæ¨¡æ€å¤§è¯­è¨€æ¨¡å‹é›†æˆï¼ˆMLLM Ensembleï¼‰ç­‰è´¨é‡ä¿è¯æŠ€æœ¯ï¼Œæ˜¾è‘—æå‡äº†ç³»ç»Ÿçš„é²æ£’æ€§å’Œå‡†ç¡®æ€§ã€‚ç ”ç©¶äººå‘˜åœ¨çœŸå®çš„æ™ºèƒ½å®¶å±…åŸºå‡†æ•°æ®å’Œä¼¤å£å›¾åƒåˆ†ç±»æ•°æ®ä¸Šè¿›è¡Œäº†å¹¿æ³›çš„å®è¯è¯„ä¼°ã€‚å®éªŒç»“æœè¯æ˜ï¼ŒALARM åœ¨ä¸åŒé¢†åŸŸå‡è¡¨ç°å‡ºä¼˜è¶Šçš„æ€§èƒ½å’Œé€šç”¨çš„é€‚ç”¨æ€§ï¼Œä¸ºåœ¨å¤æ‚ç›‘æ§ç¯å¢ƒä¸­å®ç°å¯é çš„å†³ç­–åˆ¶å®šæä¾›äº†é‡è¦æ”¯æŒã€‚",
      "categories": [
        "cs.LG",
        "cs.AI"
      ],
      "primary_category": "cs.LG",
      "comment": "",
      "pdf_url": "https://arxiv.org/pdf/2512.03101v1",
      "published_date": "2025-12-01 19:03:14 UTC",
      "updated_date": "2025-12-01 19:03:14 UTC",
      "processing_status": "completed",
      "attempts": 1,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "llm_backup_calls": 0,
      "last_update": "2026-01-26T12:25:51.647381+00:00"
    },
    {
      "arxiv_id": "2512.02020v2",
      "title": "EfficientFlow: Efficient Equivariant Flow Policy Learning for Embodied AI",
      "title_zh": "EfficientFlowï¼šé¢å‘å…·èº«æ™ºèƒ½çš„é«˜æ•ˆç­‰å˜æµç­–ç•¥å­¦ä¹ ",
      "authors": [
        "Jianlei Chang",
        "Ruofeng Mei",
        "Wei Ke",
        "Xiangyu Xu"
      ],
      "abstract": "Generative modeling has recently shown remarkable promise for visuomotor policy learning, enabling flexible and expressive control across diverse embodied AI tasks. However, existing generative policies often struggle with data inefficiency, requiring large-scale demonstrations, and sampling inefficiency, incurring slow action generation during inference. We introduce EfficientFlow, a unified framework for efficient embodied AI with flow-based policy learning. To enhance data efficiency, we bring equivariance into flow matching. We theoretically prove that when using an isotropic Gaussian prior and an equivariant velocity prediction network, the resulting action distribution remains equivariant, leading to improved generalization and substantially reduced data demands. To accelerate sampling, we propose a novel acceleration regularization strategy. As direct computation of acceleration is intractable for marginal flow trajectories, we derive a novel surrogate loss that enables stable and scalable training using only conditional trajectories. Across a wide range of robotic manipulation benchmarks, the proposed algorithm achieves competitive or superior performance under limited data while offering dramatically faster inference. These results highlight EfficientFlow as a powerful and efficient paradigm for high-performance embodied AI.",
      "tldr_zh": "ç°æœ‰çš„ç”Ÿæˆå¼ç­–ç•¥åœ¨å…·èº«æ™ºèƒ½(Embodied AI)ä»»åŠ¡ä¸­å¸¸é¢ä¸´æ•°æ®æ•ˆç‡ä½ä¸‹å’Œæ¨ç†è¿‡ç¨‹ä¸­é‡‡æ ·ç¼“æ…¢çš„é—®é¢˜ã€‚è¯¥ç ”ç©¶æå‡ºäº†EfficientFlowæ¡†æ¶ï¼Œä¸€ç§åˆ©ç”¨æµåŒ¹é…(flow matching)è¿›è¡Œç­–ç•¥å­¦ä¹ çš„ç»Ÿä¸€æ–¹æ³•ã€‚ä¸ºäº†æå‡æ•°æ®æ•ˆç‡ï¼Œç ”ç©¶å°†ç­‰å˜æ€§(equivariance)å¼•å…¥æ¨¡å‹ä¸­ï¼Œå¹¶è¯æ˜äº†åœ¨å„å‘åŒæ€§é«˜æ–¯å…ˆéªŒ(isotropic Gaussian prior)å’Œç­‰å˜é€Ÿåº¦é¢„æµ‹ç½‘ç»œæ”¯æŒä¸‹ï¼ŒåŠ¨ä½œåˆ†å¸ƒèƒ½ä¿æŒç­‰å˜æ€§ï¼Œä»è€Œæ˜¾è‘—é™ä½æ•°æ®éœ€æ±‚ã€‚é’ˆå¯¹é‡‡æ ·æ•ˆç‡ï¼Œè¯¥æ¡†æ¶å¼•å…¥äº†æ–°é¢–çš„åŠ é€Ÿåº¦æ­£åˆ™åŒ–(acceleration regularization)ç­–ç•¥åŠç›¸å…³çš„ä»£ç†æŸå¤±(surrogate loss)ï¼Œå®ç°äº†ç¨³å®šä¸”å¯æ‰©å±•çš„è®­ç»ƒã€‚å®éªŒè¡¨æ˜ï¼ŒEfficientFlowåœ¨å¤šç§æœºå™¨äººæ“ä½œåŸºå‡†æµ‹è¯•ä¸­ï¼Œä¸ä»…åœ¨æœ‰é™æ•°æ®ä¸‹å–å¾—äº†ç«äº‰æ€§æˆ–æ›´ä¼˜çš„æ€§èƒ½ï¼Œè¿˜å¤§å¹…æå‡äº†æ¨ç†é€Ÿåº¦ã€‚è¿™äº›ç»“æœè¯æ˜EfficientFlowä¸ºé«˜æ€§èƒ½å…·èº«æ™ºèƒ½æä¾›äº†ä¸€ç§é«˜æ•ˆä¸”å¼ºå¤§çš„å­¦ä¹ èŒƒå¼ã€‚",
      "categories": [
        "cs.RO",
        "cs.AI",
        "cs.CV",
        "cs.LG"
      ],
      "primary_category": "cs.RO",
      "comment": "Accepted by AAAI 2026. Project Page: https://efficientflow.github.io/",
      "pdf_url": "https://arxiv.org/pdf/2512.02020v2",
      "published_date": "2025-12-01 18:59:59 UTC",
      "updated_date": "2025-12-14 13:00:12 UTC",
      "processing_status": "completed",
      "attempts": 1,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "llm_backup_calls": 0,
      "last_update": "2026-01-26T12:25:59.743810+00:00"
    },
    {
      "arxiv_id": "2512.02019v2",
      "title": "A Diffusion Model Framework for Maximum Entropy Reinforcement Learning",
      "title_zh": "é¢å‘æœ€å¤§ç†µå¼ºåŒ–å­¦ä¹ çš„æ‰©æ•£æ¨¡å‹æ¡†æ¶",
      "authors": [
        "Sebastian Sanokowski",
        "Kaustubh Patil",
        "Alois Knoll"
      ],
      "abstract": "Diffusion models have achieved remarkable success in data-driven learning and in sampling from complex, unnormalized target distributions. Building on this progress, we reinterpret Maximum Entropy Reinforcement Learning (MaxEntRL) as a diffusion model-based sampling problem. We tackle this problem by minimizing the reverse Kullback-Leibler (KL) divergence between the diffusion policy and the optimal policy distribution using a tractable upper bound. By applying the policy gradient theorem to this objective, we derive a modified surrogate objective for MaxEntRL that incorporates diffusion dynamics in a principled way. This leads to simple diffusion-based variants of Soft Actor-Critic (SAC), Proximal Policy Optimization (PPO) and Wasserstein Policy Optimization (WPO), termed DiffSAC, DiffPPO and DiffWPO. All of these methods require only minor implementation changes to their base algorithm. We find that on standard continuous control benchmarks, DiffSAC, DiffPPO and DiffWPO achieve better returns and higher sample efficiency than SAC and PPO.",
      "tldr_zh": "è¯¥ç ”ç©¶æå‡ºäº†ä¸€ä¸ªåŸºäºæ‰©æ•£æ¨¡å‹(Diffusion models)çš„æ¡†æ¶ï¼Œæ—¨åœ¨å°†æœ€å¤§ç†µå¼ºåŒ–å­¦ä¹ (Maximum Entropy Reinforcement Learning, MaxEntRL)é‡æ–°è§£é‡Šä¸ºä¸€ä¸ªæ‰©æ•£æ¨¡å‹é‡‡æ ·é—®é¢˜ã€‚ä½œè€…é€šè¿‡æœ€å°åŒ–æ‰©æ•£ç­–ç•¥ä¸æœ€ä¼˜ç­–ç•¥åˆ†å¸ƒä¹‹é—´çš„é€†KLæ•£åº¦(reverse Kullback-Leibler divergence)çš„ä¸€ä¸ªå¯å¤„ç†ä¸Šç•Œï¼Œå¹¶åº”ç”¨ç­–ç•¥æ¢¯åº¦å®šç†ï¼Œæ¨å¯¼å‡ºäº†ä¸€å¥—ç»“åˆæ‰©æ•£åŠ¨åŠ›å­¦çš„åŸåˆ™æ€§ä»£ç†ç›®æ ‡ã€‚åŸºäºè¯¥æ¡†æ¶ï¼Œç ”ç©¶è¿›ä¸€æ­¥å¼€å‘äº†Soft Actor-Critic (SAC)ã€Proximal Policy Optimization (PPO)å’ŒWasserstein Policy Optimization (WPO)çš„æ‰©æ•£å˜ä½“ï¼Œå³DiffSACã€DiffPPOå’ŒDiffWPOã€‚è¿™äº›æ–°ç®—æ³•åœ¨å®ç°ä¸Šä»…éœ€å¯¹åŸºç¡€ç®—æ³•è¿›è¡Œå¾®å°è°ƒæ•´ï¼Œå…·å¤‡æå¼ºçš„å®ç”¨æ€§ã€‚åœ¨æ ‡å‡†è¿ç»­æ§åˆ¶åŸºå‡†æµ‹è¯•ä¸­çš„å®éªŒç»“æœæ˜¾ç¤ºï¼ŒDiffSACã€DiffPPOå’ŒDiffWPOåœ¨å›æŠ¥è¡¨ç°å’Œæ ·æœ¬æ•ˆç‡(sample efficiency)ä¸Šå‡æ˜¾è‘—ä¼˜äºä¼ ç»Ÿçš„SACå’ŒPPOç®—æ³•ã€‚è¯¥ç ”ç©¶ä¸ºåˆ©ç”¨æ‰©æ•£æ¨¡å‹æå‡å¼ºåŒ–å­¦ä¹ çš„ç­–ç•¥è¡¨ç¤ºèƒ½åŠ›å’Œé‡‡æ ·æ•ˆæœæä¾›äº†ä¸€ç§é«˜æ•ˆä¸”ç†è®ºå®Œå¤‡çš„æ–¹æ¡ˆã€‚",
      "categories": [
        "cs.LG",
        "cs.AI",
        "stat.ML"
      ],
      "primary_category": "cs.LG",
      "comment": "",
      "pdf_url": "https://arxiv.org/pdf/2512.02019v2",
      "published_date": "2025-12-01 18:59:58 UTC",
      "updated_date": "2025-12-03 00:55:54 UTC",
      "processing_status": "completed",
      "attempts": 1,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "llm_backup_calls": 0,
      "last_update": "2026-01-26T12:26:06.033190+00:00"
    },
    {
      "arxiv_id": "2512.02017v1",
      "title": "Visual Sync: Multi-Camera Synchronization via Cross-View Object Motion",
      "title_zh": "Visual Syncï¼šåŸºäºè·¨è§†è§’ç‰©ä½“è¿åŠ¨çš„å¤šç›¸æœºåŒæ­¥",
      "authors": [
        "Shaowei Liu",
        "David Yifan Yao",
        "Saurabh Gupta",
        "Shenlong Wang"
      ],
      "abstract": "Today, people can easily record memorable moments, ranging from concerts, sports events, lectures, family gatherings, and birthday parties with multiple consumer cameras. However, synchronizing these cross-camera streams remains challenging. Existing methods assume controlled settings, specific targets, manual correction, or costly hardware. We present VisualSync, an optimization framework based on multi-view dynamics that aligns unposed, unsynchronized videos at millisecond accuracy. Our key insight is that any moving 3D point, when co-visible in two cameras, obeys epipolar constraints once properly synchronized. To exploit this, VisualSync leverages off-the-shelf 3D reconstruction, feature matching, and dense tracking to extract tracklets, relative poses, and cross-view correspondences. It then jointly minimizes the epipolar error to estimate each camera's time offset. Experiments on four diverse, challenging datasets show that VisualSync outperforms baseline methods, achieving an median synchronization error below 50 ms.",
      "tldr_zh": "è¯¥ç ”ç©¶æå‡ºäº† VisualSyncï¼Œè¿™æ˜¯ä¸€ä¸ªåŸºäºå¤šè§†å›¾åŠ¨æ€ (multi-view dynamics) çš„ä¼˜åŒ–æ¡†æ¶ï¼Œæ—¨åœ¨è§£å†³æ¶ˆè´¹çº§æ‘„åƒæœºå½•åˆ¶çš„å¤šè§†è§’è§†é¢‘æµåŒæ­¥éš¾é¢˜ã€‚è¯¥æ–¹æ³•é’ˆå¯¹ç°æœ‰æŠ€æœ¯ä¾èµ–å—æ§ç¯å¢ƒã€ç‰¹å®šç›®æ ‡æˆ–æ˜‚è´µç¡¬ä»¶çš„å±€é™æ€§ï¼Œå®ç°äº†å¯¹å§¿æ€æœªçŸ¥ä¸”ä¸åŒæ­¥è§†é¢‘çš„æ¯«ç§’çº§å¯¹é½ã€‚VisualSync çš„æ ¸å¿ƒæ€è·¯æ˜¯åˆ©ç”¨å…±åŒå¯è§çš„ç§»åŠ¨ 3D ç‚¹åœ¨åŒæ­¥åå¿…é¡»éµå¾ªå¯¹æçº¦æŸ (epipolar constraints) çš„ç‰¹æ€§ã€‚è¯¥æ¡†æ¶åˆ©ç”¨ç°æˆçš„ 3D reconstructionã€feature matching å’Œ dense tracking æŠ€æœ¯æå–è½¨è¿¹ (tracklets)ã€ç›¸å¯¹å§¿æ€ (relative poses) ä»¥åŠè·¨è§†å›¾å¯¹åº”å…³ç³»ï¼Œé€šè¿‡è”åˆæœ€å°åŒ–å¯¹æè¯¯å·® (epipolar error) æ¥ç²¾ç¡®ä¼°è®¡æ¯å°æ‘„åƒæœºçš„æ—¶é—´åç§»é‡ã€‚å®éªŒç»“æœè¡¨æ˜ï¼ŒVisualSync åœ¨å››ä¸ªæŒ‘æˆ˜æ€§æ•°æ®é›†ä¸Šå‡ä¼˜äºåŸºå‡†æ–¹æ³•ï¼Œå®ç°äº†ä½äº 50 æ¯«ç§’çš„ä¸­å€¼åŒæ­¥è¯¯å·®ã€‚",
      "categories": [
        "cs.CV",
        "cs.AI",
        "cs.LG",
        "cs.RO"
      ],
      "primary_category": "cs.CV",
      "comment": "Accepted to NeurIPS 2025. Project page: https://stevenlsw.github.io/visualsync/",
      "pdf_url": "https://arxiv.org/pdf/2512.02017v1",
      "published_date": "2025-12-01 18:59:57 UTC",
      "updated_date": "2025-12-01 18:59:57 UTC",
      "processing_status": "completed",
      "attempts": 1,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "llm_backup_calls": 0,
      "last_update": "2026-01-26T12:26:05.884414+00:00"
    },
    {
      "arxiv_id": "2512.01996v1",
      "title": "Learning Sim-to-Real Humanoid Locomotion in 15 Minutes",
      "title_zh": "15åˆ†é’Ÿå†…å®ç°äººå½¢æœºå™¨äººä»ä»¿çœŸåˆ°ç°å®çš„è¿åŠ¨å­¦ä¹ ",
      "authors": [
        "Younggyo Seo",
        "Carmelo Sferrazza",
        "Juyue Chen",
        "Guanya Shi",
        "Rocky Duan",
        "Pieter Abbeel"
      ],
      "abstract": "Massively parallel simulation has reduced reinforcement learning (RL) training time for robots from days to minutes. However, achieving fast and reliable sim-to-real RL for humanoid control remains difficult due to the challenges introduced by factors such as high dimensionality and domain randomization. In this work, we introduce a simple and practical recipe based on off-policy RL algorithms, i.e., FastSAC and FastTD3, that enables rapid training of humanoid locomotion policies in just 15 minutes with a single RTX 4090 GPU. Our simple recipe stabilizes off-policy RL algorithms at massive scale with thousands of parallel environments through carefully tuned design choices and minimalist reward functions. We demonstrate rapid end-to-end learning of humanoid locomotion controllers on Unitree G1 and Booster T1 robots under strong domain randomization, e.g., randomized dynamics, rough terrain, and push perturbations, as well as fast training of whole-body human-motion tracking policies. We provide videos and open-source implementation at: https://younggyo.me/fastsac-humanoid.",
      "tldr_zh": "è¯¥ç ”ç©¶é’ˆå¯¹äººå½¢æœºå™¨äººSim-to-Realè¿‡ç¨‹ä¸­ç”±äºé«˜ç»´åº¦å’Œé¢†åŸŸéšæœºåŒ–(Domain Randomization)å¯¼è‡´çš„è®­ç»ƒéš¾é¢˜ï¼Œæå‡ºäº†ä¸€ç§åŸºäºè„±ç­–å¼ºåŒ–å­¦ä¹ (Off-policy RL)ç®—æ³•FastSACå’ŒFastTD3çš„ç®€æ˜“å®ç”¨æ–¹æ¡ˆã€‚è¯¥æ–¹æ¡ˆé€šè¿‡ç²¾å¿ƒè®¾è®¡çš„å‚æ•°è°ƒèŠ‚å’Œæç®€å¥–åŠ±å‡½æ•°(Minimalist Reward Functions)ï¼Œåœ¨æ•°åƒä¸ªå¹¶è¡Œç¯å¢ƒä¸‹å®ç°äº†å¤§è§„æ¨¡ç®—æ³•çš„ç¨³å®šæ€§ï¼Œä»…éœ€å•å—RTX 4090æ˜¾å¡å³å¯åœ¨15åˆ†é’Ÿå†…å®Œæˆè®­ç»ƒã€‚å®éªŒåœ¨Unitree G1å’ŒBooster T1æœºå™¨äººä¸ŠéªŒè¯äº†å…¶åœ¨å´å²–åœ°å½¢åŠæ¨åŠ›å¹²æ‰°ç­‰å¼ºé¢†åŸŸéšæœºåŒ–åœºæ™¯ä¸‹çš„ç«¯åˆ°ç«¯è¿åŠ¨æ§åˆ¶èƒ½åŠ›ï¼Œå¹¶å±•ç¤ºäº†å…¨èº«äººä½“è¿åŠ¨è·Ÿè¸ª(Whole-body Human-motion Tracking)ç­–ç•¥çš„é«˜æ•ˆå­¦ä¹ ã€‚è¿™ä¸€æˆæœå¤§å¹…ç¼©çŸ­äº†äººå½¢æœºå™¨äººçš„å­¦ä¹ å‘¨æœŸï¼Œä¸ºå¼€å‘å¿«é€Ÿã€å¯é çš„è‡ªä¸»è¿åŠ¨ç­–ç•¥æä¾›äº†é«˜æ•ˆä¸”å¼€æºçš„æŠ€æœ¯è·¯å¾„ã€‚",
      "categories": [
        "cs.RO",
        "cs.AI",
        "cs.LG"
      ],
      "primary_category": "cs.RO",
      "comment": "Project website: https://younggyo.me/fastsac-humanoid",
      "pdf_url": "https://arxiv.org/pdf/2512.01996v1",
      "published_date": "2025-12-01 18:55:17 UTC",
      "updated_date": "2025-12-01 18:55:17 UTC",
      "processing_status": "completed",
      "attempts": 1,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "llm_backup_calls": 0,
      "last_update": "2026-01-26T12:26:05.044776+00:00"
    },
    {
      "arxiv_id": "2512.01993v1",
      "title": "RoaD: Rollouts as Demonstrations for Closed-Loop Supervised Fine-Tuning of Autonomous Driving Policies",
      "title_zh": "RoaDï¼šå°† Rollout ä½œä¸ºç¤ºèŒƒçš„è‡ªåŠ¨é©¾é©¶ç­–ç•¥é—­ç¯ç›‘ç£å¾®è°ƒ",
      "authors": [
        "Guillermo Garcia-Cobo",
        "Maximilian Igl",
        "Peter Karkus",
        "Zhejun Zhang",
        "Michael Watson",
        "Yuxiao Chen",
        "Boris Ivanovic",
        "Marco Pavone"
      ],
      "abstract": "Autonomous driving policies are typically trained via open-loop behavior cloning of human demonstrations. However, such policies suffer from covariate shift when deployed in closed loop, leading to compounding errors. We introduce Rollouts as Demonstrations (RoaD), a simple and efficient method to mitigate covariate shift by leveraging the policy's own closed-loop rollouts as additional training data. During rollout generation, RoaD incorporates expert guidance to bias trajectories toward high-quality behavior, producing informative yet realistic demonstrations for fine-tuning. This approach enables robust closed-loop adaptation with orders of magnitude less data than reinforcement learning, and avoids restrictive assumptions of prior closed-loop supervised fine-tuning (CL-SFT) methods, allowing broader applications domains including end-to-end driving. We demonstrate the effectiveness of RoaD on WOSAC, a large-scale traffic simulation benchmark, where it performs similar or better than the prior CL-SFT method; and in AlpaSim, a high-fidelity neural reconstruction-based simulator for end-to-end driving, where it improves driving score by 41\\% and reduces collisions by 54\\%.",
      "tldr_zh": "è¯¥ç ”ç©¶é’ˆå¯¹è‡ªåŠ¨é©¾é©¶ç­–ç•¥åœ¨é—­ç¯éƒ¨ç½²ä¸­å› åå˜é‡åç§»(Covariate Shift)å¯¼è‡´çš„è¯¯å·®ç´¯ç§¯é—®é¢˜ï¼Œæå‡ºäº†åä¸ºRoaD (Rollouts as Demonstrations)çš„é—­ç¯ç›‘ç£å¾®è°ƒæ–¹æ³•ã€‚RoaDé€šè¿‡åˆ©ç”¨ç­–ç•¥è‡ªèº«çš„é—­ç¯å›æ”¾(Rollouts)ä½œä¸ºè®­ç»ƒæ•°æ®ï¼Œå¹¶åœ¨ç”Ÿæˆè¿‡ç¨‹ä¸­å¼•å…¥ä¸“å®¶å¼•å¯¼(Expert Guidance)æ¥äº§ç”Ÿé«˜è´¨é‡ä¸”å…·æœ‰ä¿¡æ¯é‡çš„æ¼”ç¤ºè½¨è¿¹ã€‚ç›¸æ¯”äºä¼ ç»Ÿçš„å¼ºåŒ–å­¦ä¹ (Reinforcement Learning)ï¼Œè¯¥æ–¹æ³•èƒ½ä»¥æä½çš„æ•°æ®éœ€æ±‚å®ç°ç¨³å¥çš„é—­ç¯é€‚åº”ï¼Œå¹¶é¿å¼€äº†ä»¥å¾€CL-SFTæ–¹æ³•çš„å±€é™æ€§ï¼Œå¯å¹¿æ³›åº”ç”¨äºç«¯åˆ°ç«¯é©¾é©¶(End-to-End Driving)ç­‰é¢†åŸŸã€‚å®éªŒç»“æœæ˜¾ç¤ºï¼ŒRoaDåœ¨WOSACåŸºå‡†æµ‹è¯•ä¸­è¡¨ç°ä¼˜å¼‚ï¼Œå¹¶åœ¨é«˜ä¿çœŸç¥ç»é‡å»ºæ¨¡æ‹Ÿå™¨AlpaSimä¸­å°†é©¾é©¶å¾—åˆ†æå‡äº†41%ï¼ŒåŒæ—¶ä½¿ç¢°æ’ç‡é™ä½äº†54%ï¼Œè¯æ˜äº†å…¶åœ¨æå‡è‡ªåŠ¨é©¾é©¶ç­–ç•¥é²æ£’æ€§æ–¹é¢çš„æ˜¾è‘—æ•ˆæœã€‚",
      "categories": [
        "cs.RO",
        "cs.AI",
        "cs.CV",
        "cs.LG"
      ],
      "primary_category": "cs.RO",
      "comment": "Preprint",
      "pdf_url": "https://arxiv.org/pdf/2512.01993v1",
      "published_date": "2025-12-01 18:52:03 UTC",
      "updated_date": "2025-12-01 18:52:03 UTC",
      "processing_status": "completed",
      "attempts": 1,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "llm_backup_calls": 0,
      "last_update": "2026-01-26T12:26:14.233814+00:00"
    },
    {
      "arxiv_id": "2512.01992v1",
      "title": "LLM CHESS: Benchmarking Reasoning and Instruction-Following in LLMs through Chess",
      "title_zh": "LLM CHESSï¼šåŸºäºå›½é™…è±¡æ£‹çš„å¤§è¯­è¨€æ¨¡å‹æ¨ç†ä¸æŒ‡ä»¤éµå¾ªèƒ½åŠ›åŸºå‡†æµ‹è¯•",
      "authors": [
        "Sai Kolasani",
        "Maxim Saplin",
        "Nicholas Crispino",
        "Kyle Montgomery",
        "Jared Quincy Davis",
        "Matei Zaharia",
        "Chi Wang",
        "Chenguang Wang"
      ],
      "abstract": "We introduce LLM CHESS, an evaluation framework designed to probe the generalization of reasoning and instruction-following abilities in large language models (LLMs) through extended agentic interaction in the domain of chess. We rank over 50 open and closed source models by playing against a random opponent using a range of behavioral metrics, including win and loss rates, move quality, move legality, hallucinated actions, and game duration. For a subset of top reasoning models, we derive an Elo estimate by playing against a chess engine with variably configured skill, which allows for comparisons between models in an easily understandable way. Despite the simplicity of the instruction-following task and the weakness of the opponent, many state-of-the-art models struggle to complete games or achieve consistent wins. Similar to other benchmarks on complex reasoning tasks, our experiments reveal a clear separation between reasoning and non-reasoning models. However, unlike existing static benchmarks, the stochastic and dynamic nature of LLM CHESS uniquely reduces overfitting and memorization while preventing benchmark saturation, proving difficult even for top reasoning models. To support future work on evaluating reasoning and instruction-following in LLMs, we release our experimental framework, a public leaderboard, and a dataset of associated games.",
      "tldr_zh": "è¯¥ç ”ç©¶æå‡ºäº†LLM CHESSï¼Œè¿™æ˜¯ä¸€ä¸ªæ—¨åœ¨é€šè¿‡å›½é™…è±¡æ£‹é¢†åŸŸçš„æ‰©å±•æ™ºèƒ½ä½“äº¤äº’(agentic interaction)æ¥æ¢ç©¶å¤§è¯­è¨€æ¨¡å‹(LLMs)æ¨ç†(reasoning)å’ŒæŒ‡ä»¤éµå¾ª(instruction-following)æ³›åŒ–èƒ½åŠ›çš„è¯„ä¼°æ¡†æ¶ã€‚ç ”ç©¶äººå‘˜é€šè¿‡è®©50å¤šä¸ªå¼€æºå’Œé—­æºæ¨¡å‹ä¸éšæœºå¯¹æ‰‹å¯¹æˆ˜ï¼Œåˆ©ç”¨èƒœç‡ã€ç§»åŠ¨åˆæ³•æ€§(move legality)å’Œå¹»è§‰è¡Œä¸º(hallucinated actions)ç­‰è¡Œä¸ºæŒ‡æ ‡è¿›è¡Œæ’åï¼Œå¹¶ä¸ºé¡¶çº§æ¨¡å‹æ¨å¯¼äº†Eloç­‰çº§åˆ†ã€‚å®éªŒå‘ç°ï¼Œå°½ç®¡ä»»åŠ¡é€»è¾‘ç®€å•ï¼Œè®¸å¤šæœ€å…ˆè¿›(SOTA)çš„æ¨¡å‹åœ¨å®Œæˆæ¯”èµ›æˆ–æŒç»­è·èƒœæ–¹é¢è¡¨ç°ä¸ä½³ï¼Œä¸”æ¨ç†æ¨¡å‹ä¸éæ¨ç†æ¨¡å‹ä¹‹é—´å­˜åœ¨æ˜¾è‘—æ€§èƒ½å·®å¼‚ã€‚ä¸é™æ€åŸºå‡†æµ‹è¯•ä¸åŒï¼ŒLLM CHESSçš„éšæœºæ€§å’ŒåŠ¨æ€ç‰¹æ€§æœ‰æ•ˆå‡å°‘äº†è¿‡æ‹Ÿåˆ(overfitting)å’Œè®°å¿†(memorization)é—®é¢˜ï¼Œèƒ½å¤Ÿé˜²æ­¢åŸºå‡†é¥±å’Œ(benchmark saturation)ã€‚è¯¥ç ”ç©¶å¼€æºäº†å®éªŒæ¡†æ¶ã€å…¬å¼€æ’è¡Œæ¦œå’Œç›¸å…³æ•°æ®é›†ï¼Œä¸ºè¯„ä¼°LLMsçš„å¤æ‚æ¨ç†èƒ½åŠ›æä¾›äº†æ–°çš„å·¥å…·ã€‚",
      "categories": [
        "cs.AI",
        "cs.CL"
      ],
      "primary_category": "cs.AI",
      "comment": "",
      "pdf_url": "https://arxiv.org/pdf/2512.01992v1",
      "published_date": "2025-12-01 18:51:08 UTC",
      "updated_date": "2025-12-01 18:51:08 UTC",
      "processing_status": "completed",
      "attempts": 1,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "llm_backup_calls": 0,
      "last_update": "2026-01-26T12:26:12.342067+00:00"
    },
    {
      "arxiv_id": "2512.01987v3",
      "title": "Forecasting in Offline Reinforcement Learning for Non-stationary Environments",
      "title_zh": "é¢å‘éå¹³ç¨³ç¯å¢ƒçš„ç¦»çº¿å¼ºåŒ–å­¦ä¹ é¢„æµ‹",
      "authors": [
        "Suzan Ece Ada",
        "Georg Martius",
        "Emre Ugur",
        "Erhan Oztop"
      ],
      "abstract": "Offline Reinforcement Learning (RL) provides a promising avenue for training policies from pre-collected datasets when gathering additional interaction data is infeasible. However, existing offline RL methods often assume stationarity or only consider synthetic perturbations at test time, assumptions that often fail in real-world scenarios characterized by abrupt, time-varying offsets. These offsets can lead to partial observability, causing agents to misperceive their true state and degrade performance. To overcome this challenge, we introduce Forecasting in Non-stationary Offline RL (FORL), a framework that unifies (i) conditional diffusion-based candidate state generation, trained without presupposing any specific pattern of future non-stationarity, and (ii) zero-shot time-series foundation models. FORL targets environments prone to unexpected, potentially non-Markovian offsets, requiring robust agent performance from the onset of each episode. Empirical evaluations on offline RL benchmarks, augmented with real-world time-series data to simulate realistic non-stationarity, demonstrate that FORL consistently improves performance compared to competitive baselines. By integrating zero-shot forecasting with the agent's experience, we aim to bridge the gap between offline RL and the complexities of real-world, non-stationary environments.",
      "tldr_zh": "è¯¥ç ”ç©¶æ¢è®¨äº†ç¦»çº¿å¼ºåŒ–å­¦ä¹ (Offline RL)åœ¨é¢å¯¹ç°å®ä¸–ç•Œä¸­çªå‘çš„ã€éšæ—¶é—´å˜åŒ–çš„åç§»(offsets)æ‰€å¯¼è‡´çš„éå¹³ç¨³ç¯å¢ƒ(non-stationary environments)æ—¶æ‰€é¢ä¸´çš„æŒ‘æˆ˜ã€‚ç”±äºè¿™äº›åç§»ä¼šå¼•å‘éƒ¨åˆ†å¯è§‚æµ‹æ€§(partial observability)å¹¶é™ä½æ™ºèƒ½ä½“æ€§èƒ½ï¼Œç ”ç©¶è€…æå‡ºäº†åä¸ºFORL (Forecasting in Non-stationary Offline RL) çš„æ–°æ¡†æ¶ã€‚FORLåˆ›æ–°æ€§åœ°ç»“åˆäº†åŸºäºæ¡ä»¶æ‰©æ•£(conditional diffusion-based)çš„å€™é€‰çŠ¶æ€ç”ŸæˆæŠ€æœ¯ä¸é›¶æ ·æœ¬æ—¶é—´åºåˆ—åŸºç¡€æ¨¡å‹(zero-shot time-series foundation models)ï¼Œä¸”æ— éœ€é¢„è®¾æœªæ¥éå¹³ç¨³æ€§çš„å…·ä½“æ¨¡å¼ã€‚é€šè¿‡å°†é›¶æ ·æœ¬é¢„æµ‹é›†æˆåˆ°æ™ºèƒ½ä½“çš„ç»éªŒä¸­ï¼Œè¯¥æ¡†æ¶èƒ½æœ‰æ•ˆåº”å¯¹éé©¬å°”å¯å¤«åç§»(non-Markovian offsets)ï¼Œæå‡æ™ºèƒ½ä½“åœ¨å„è½®æ¬¡èµ·å§‹é˜¶æ®µçš„é²æ£’æ€§ã€‚åœ¨æ¨¡æ‹ŸçœŸå®éå¹³ç¨³ç‰¹æ€§çš„åŸºå‡†æµ‹è¯•ä¸­ï¼Œå®éªŒç»“æœè¯æ˜FORLçš„æ€§èƒ½è¡¨ç°å§‹ç»ˆä¼˜äºç°æœ‰çš„ç«äº‰åŸºå‡†ã€‚è¯¥ç ”ç©¶ä¸ºå¼¥åˆç¦»çº¿å¼ºåŒ–å­¦ä¹ ç†è®ºä¸å¤æ‚ç°å®ç¯å¢ƒä¹‹é—´çš„é¸¿æ²Ÿæä¾›äº†æœ‰æ•ˆçš„è§£å†³æ–¹æ¡ˆã€‚",
      "categories": [
        "cs.LG",
        "cs.AI",
        "cs.RO"
      ],
      "primary_category": "cs.LG",
      "comment": "The Thirty-Ninth Annual Conference on Neural Information Processing Systems, NeurIPS 2025",
      "pdf_url": "https://arxiv.org/pdf/2512.01987v3",
      "published_date": "2025-12-01 18:45:05 UTC",
      "updated_date": "2025-12-27 16:09:15 UTC",
      "processing_status": "completed",
      "attempts": 1,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "llm_backup_calls": 0,
      "last_update": "2026-01-26T12:26:19.650742+00:00"
    },
    {
      "arxiv_id": "2512.01979v1",
      "title": "Chain-of-Ground: Improving GUI Grounding via Iterative Reasoning and Reference Feedback",
      "title_zh": "Chain-of-Groundï¼šé€šè¿‡è¿­ä»£æ¨ç†ä¸å‚è€ƒåé¦ˆæå‡ GUI å®šä½èƒ½åŠ›",
      "authors": [
        "Aiden Yiliu Li",
        "Bizhi Yu",
        "Daoan Lei",
        "Tianhe Ren",
        "Shilong Liu"
      ],
      "abstract": "GUI grounding aims to align natural language instructions with precise regions in complex user interfaces. Advanced multimodal large language models show strong ability in visual GUI grounding but still struggle with small or visually similar targets and ambiguity in real world layouts. These limitations arise from limited grounding capacity and from underuse of existing reasoning potential. We present Chain of Ground CoG a training free multi step grounding framework that uses multimodal large language models for iterative visual reasoning and refinement. Instead of direct prediction the model progressively reflects and adjusts its hypotheses leading to more accurate and interpretable localization. Our approach achieves 68.4 accuracy on the ScreenSpot Pro benchmark an improvement of 4.8 points. To measure real world generalization we introduce TPanel UI a dataset of 420 labeled industrial control panels with visual distortions such as blur and masking. On TPanel UI Chain of Ground improves over the strong baseline Qwen3 VL 235B by 6.9 points showing the effectiveness of multi step training free grounding across real world and digital interfaces. These results highlight a direction for unlocking grounding potential through structured iterative refinement instead of additional training.",
      "tldr_zh": "è¯¥ç ”ç©¶é’ˆå¯¹è§†è§‰è¯­è¨€æ¨¡å‹åœ¨GUI groundingä»»åŠ¡ä¸­éš¾ä»¥è¯†åˆ«å°ç›®æ ‡ã€è§†è§‰ç›¸ä¼¼å¯¹è±¡åŠå¤„ç†å¸ƒå±€æ­§ä¹‰çš„é—®é¢˜ï¼Œæå‡ºäº†Chain-of-Ground (CoG) è¿™ä¸€æ— éœ€è®­ç»ƒçš„å¤šæ­¥å®šä½æ¡†æ¶ã€‚CoG åˆ©ç”¨å¤šæ¨¡æ€å¤§è¯­è¨€æ¨¡å‹è¿›è¡Œè¿­ä»£è§†è§‰æ¨ç†ä¸åé¦ˆä¼˜åŒ–ï¼Œå¼•å¯¼æ¨¡å‹é€šè¿‡ä¸æ–­åæ˜ å’Œè°ƒæ•´å…¶å‡è®¾æ¥æ›¿ä»£ä¼ ç»Ÿçš„ç›´æ¥é¢„æµ‹ï¼Œä»è€Œå®ç°æ›´å‡†ç¡®ä¸”å¯è§£é‡Šçš„å®šä½ã€‚å®éªŒè¡¨æ˜ï¼Œè¯¥æ–¹æ³•åœ¨ScreenSpot ProåŸºå‡†æµ‹è¯•ä¸­å–å¾—äº†68.4%çš„å‡†ç¡®ç‡ï¼Œç›¸æ¯”åŸºçº¿æå‡äº†4.8ä¸ªç™¾åˆ†ç‚¹ã€‚ä¸ºäº†è¡¡é‡ç°å®ä¸–ç•Œçš„æ³›åŒ–æ€§ï¼Œç ”ç©¶å›¢é˜Ÿè¿˜å¼•å…¥äº†åŒ…å«420ä¸ªå·¥ä¸šæ§åˆ¶é¢æ¿æ ‡æ³¨æ•°æ®çš„TPanel UIæ•°æ®é›†ï¼ŒCoG åœ¨è¯¥æ•°æ®é›†ä¸Šæ¯”å¼ºåŠ›åŸºçº¿æ¨¡å‹ Qwen3 VL 235B é«˜å‡º6.9ä¸ªç™¾åˆ†ç‚¹ã€‚è¿™äº›ç ”ç©¶ç»“æœè¯æ˜ï¼Œé€šè¿‡ç»“æ„åŒ–çš„è¿­ä»£ç»†åŒ–è€Œéé¢å¤–çš„æ¨¡å‹è®­ç»ƒï¼Œå¯ä»¥æœ‰æ•ˆæŒ–æ˜å¹¶é‡Šæ”¾å¤§è¯­è¨€æ¨¡å‹åœ¨å¤æ‚ç•Œé¢å®šä½é¢†åŸŸçš„æ½œèƒ½ã€‚",
      "categories": [
        "cs.AI",
        "cs.CL",
        "cs.CV"
      ],
      "primary_category": "cs.AI",
      "comment": "",
      "pdf_url": "https://arxiv.org/pdf/2512.01979v1",
      "published_date": "2025-12-01 18:37:19 UTC",
      "updated_date": "2025-12-01 18:37:19 UTC",
      "processing_status": "completed",
      "attempts": 1,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "llm_backup_calls": 0,
      "last_update": "2026-01-26T12:26:30.747450+00:00"
    },
    {
      "arxiv_id": "2512.01977v1",
      "title": "AI-Driven Optimization under Uncertainty for Mineral Processing Operations",
      "title_zh": "çŸ¿ç‰©åŠ å·¥è¿‡ç¨‹ä¸­çš„ä¸ç¡®å®šæ€§äººå·¥æ™ºèƒ½é©±åŠ¨ä¼˜åŒ–",
      "authors": [
        "William Xu",
        "Amir Eskanlou",
        "Mansur Arief",
        "David Zhen Yin",
        "Jef K. Caers"
      ],
      "abstract": "The global capacity for mineral processing must expand rapidly to meet the demand for critical minerals, which are essential for building the clean energy technologies necessary to mitigate climate change. However, the efficiency of mineral processing is severely limited by uncertainty, which arises from both the variability of feedstock and the complexity of process dynamics. To optimize mineral processing circuits under uncertainty, we introduce an AI-driven approach that formulates mineral processing as a Partially Observable Markov Decision Process (POMDP). We demonstrate the capabilities of this approach in handling both feedstock uncertainty and process model uncertainty to optimize the operation of a simulated, simplified flotation cell as an example. We show that by integrating the process of information gathering (i.e., uncertainty reduction) and process optimization, this approach has the potential to consistently perform better than traditional approaches at maximizing an overall objective, such as net present value (NPV). Our methodological demonstration of this optimization-under-uncertainty approach for a synthetic case provides a mathematical and computational framework for later real-world application, with the potential to improve both the laboratory-scale design of experiments and industrial-scale operation of mineral processing circuits without any additional hardware.",
      "tldr_zh": "è¯¥ç ”ç©¶é’ˆå¯¹çŸ¿ç‰©åŠ å·¥è¿‡ç¨‹ä¸­åŸææ–™å˜å¼‚æ€§å’Œå·¥è‰ºåŠ¨æ€å¤æ‚æ€§å¸¦æ¥çš„ä¸ç¡®å®šæ€§æŒ‘æˆ˜ï¼Œæå‡ºäº†ä¸€ç§AIé©±åŠ¨çš„ä¼˜åŒ–æ–¹æ³•ã€‚ç ”ç©¶è€…å°†çŸ¿ç‰©åŠ å·¥è¿‡ç¨‹å»ºæ¨¡ä¸ºéƒ¨åˆ†å¯è§‚æµ‹é©¬å°”å¯å¤«å†³ç­–è¿‡ç¨‹ (Partially Observable Markov Decision Process, POMDP)ï¼Œå¹¶ä»¥ç®€åŒ–çš„æµ®é€‰æ±  (flotation cell) æ¨¡æ‹Ÿä¸ºä¾‹éªŒè¯äº†è¯¥æ–¹æ³•çš„æœ‰æ•ˆæ€§ã€‚è¯¥æ–¹æ³•èƒ½å¤ŸåŒæ—¶å¤„ç†åŸæ–™ä¸ç¡®å®šæ€§å’Œè¿‡ç¨‹æ¨¡å‹ä¸ç¡®å®šæ€§ï¼Œé€šè¿‡æ•´åˆä¿¡æ¯é‡‡é›†ä¸è¿‡ç¨‹ä¼˜åŒ–ï¼Œåœ¨æœ€å¤§åŒ–å‡€ç°å€¼ (Net Present Value, NPV) ç­‰æ€»ä½“ç›®æ ‡æ–¹é¢è¡¨ç°æ˜¾è‘—ä¼˜äºä¼ ç»Ÿæ–¹æ³•ã€‚è¯¥ç ”ç©¶ä¸ºçŸ¿ç‰©åŠ å·¥å›è·¯æä¾›äº†æ•°å­¦å’Œè®¡ç®—æ¡†æ¶ï¼Œæœ‰æœ›åœ¨ä¸å¢åŠ é¢å¤–ç¡¬ä»¶çš„æƒ…å†µä¸‹ï¼Œæå‡å®éªŒå®¤è§„æ¨¡çš„å®éªŒè®¾è®¡å’Œå·¥ä¸šè§„æ¨¡çš„è¿è¡Œæ•ˆç‡ã€‚è¿™ç§ä¼˜åŒ–ç­–ç•¥å¯¹äºé€šè¿‡æå‡å…³é”®çŸ¿äº§äº§èƒ½æ¥æ”¯æŒæ¸…æ´èƒ½æºæŠ€æœ¯å‘å±•å…·æœ‰é‡è¦çš„å®è·µæ„ä¹‰ã€‚",
      "categories": [
        "eess.SY",
        "cs.AI"
      ],
      "primary_category": "eess.SY",
      "comment": "27 pages, 13 figures, submitted to Sustainable Earth Resources Communications (SERC)",
      "pdf_url": "https://arxiv.org/pdf/2512.01977v1",
      "published_date": "2025-12-01 18:35:54 UTC",
      "updated_date": "2025-12-01 18:35:54 UTC",
      "processing_status": "completed",
      "attempts": 1,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "llm_backup_calls": 0,
      "last_update": "2026-01-26T12:26:52.437818+00:00"
    },
    {
      "arxiv_id": "2512.01970v2",
      "title": "From Atomic to Composite: Reinforcement Learning Enables Generalization in Complementary Reasoning",
      "title_zh": "ä»åŸå­åˆ°å¤åˆï¼šå¼ºåŒ–å­¦ä¹ åŠ©åŠ›äº’è¡¥æ¨ç†å®ç°æ³›åŒ–",
      "authors": [
        "Sitao Cheng",
        "Xunjian Yin",
        "Ruiwen Zhou",
        "Yuxuan Li",
        "Xinyi Wang",
        "Liangming Pan",
        "William Yang Wang",
        "Victor Zhong"
      ],
      "abstract": "The mechanism by which RL contributes to reasoning capabilities-whether it incentivizes the synthesis of new skills or merely amplifies existing behaviors-remains a subject of intense debate. In this work, we investigate this question through the lens of Complementary Reasoning, a complex task that requires integrating internal parametric knowledge with external contextual information. Using a controlled synthetic dataset of human biographies, we strictly decouple this ability into two atomic skills: Parametric Reasoning (relying on internal knowledge) and Contextual Reasoning (depending on external information). To rigorously assess capability boundaries, we evaluate generalization across three distinct levels of difficulty: I.I.D., Composition, and Zero-shot settings. We find that while SFT is sufficient for in-distribution performance, it struggles with O.O.D. generalization, particularly in Zero-shot settings where relational combinations are novel. Crucially, we identify the SFT Generalization Paradox: Models supervised solely on the composite task achieve near-perfect in-distribution accuracy but collapse on out-of-distribution generalization, indicating their reliance on rote memorization of path shortcuts. In contrast, we find that RL acts as a reasoning synthesizer rather than a probability amplifier. However, we uncover a strict atomic prerequisite: RL can only synthesize these complex strategies if the base model has first mastered the independent atomic skills (Parametric and Contextual) via SFT. These findings challenge the view of RL as a mere amplifier, suggesting that given sufficient atomic foundations, RL can actively synthesize complex reasoning strategies from learned primitives without explicit supervision on such complex strategies. This indicates that decoupled atomic training followed by RL offers a scalable path to generalization for complex reasoning tasks.",
      "tldr_zh": "è¯¥ç ”ç©¶æ¢è®¨äº†å¼ºåŒ–å­¦ä¹ (RL)åœ¨äº’è¡¥æ¨ç†(Complementary Reasoning)ä»»åŠ¡ä¸­ä¿ƒè¿›æ³›åŒ–çš„æœºåˆ¶ï¼Œå³å¦‚ä½•æœ‰æ•ˆåœ°å°†å†…éƒ¨å‚æ•°çŸ¥è¯†ä¸å¤–éƒ¨ä¸Šä¸‹æ–‡ä¿¡æ¯ç›¸ç»“åˆã€‚ç ”ç©¶è€…é€šè¿‡æ„å»ºå—æ§æ•°æ®é›†ï¼Œå°†è¯¥èƒ½åŠ›ä¸¥æ ¼è§£è€¦ä¸ºå‚æ•°åŒ–æ¨ç†(Parametric Reasoning)å’Œä¸Šä¸‹æ–‡æ¨ç†(Contextual Reasoning)ä¸¤ç§åŸå­æŠ€èƒ½ï¼Œå¹¶åœ¨ä¸åŒéš¾åº¦çº§åˆ«ä¸‹è¯„ä¼°å…¶æ³›åŒ–ç•Œé™ã€‚å®éªŒæ­ç¤ºäº†â€œSFT Generalization Paradoxâ€ç°è±¡ï¼Œå³ä»…ä¾é ç›‘ç£å¾®è°ƒ(SFT)çš„æ¨¡å‹åœ¨åˆ†å¸ƒå¤–(O.O.D.)åŠé›¶æ ·æœ¬(Zero-shot)è®¾ç½®ä¸‹ä¼šå› ä¾èµ–è·¯å¾„è®°å¿†è€Œå¯¼è‡´æ€§èƒ½å´©æºƒã€‚ç›¸æ¯”ä¹‹ä¸‹ï¼Œç ”ç©¶å‘ç°RLèƒ½å¤Ÿä½œä¸ºæ¨ç†åˆæˆå™¨(reasoning synthesizer)è€Œéå•çº¯çš„æ¦‚ç‡æ”¾å¤§å™¨ï¼Œä»åŸå­åŸºå…ƒä¸­åˆæˆå¤æ‚çš„æ¨ç†ç­–ç•¥ã€‚ç„¶è€Œï¼Œè¿™ä¸€è¿‡ç¨‹å­˜åœ¨ä¸¥æ ¼çš„å…ˆå†³æ¡ä»¶ï¼Œå³åŸºæ¨¡å‹å¿…é¡»å…ˆé€šè¿‡SFTæŒæ¡ç‹¬ç«‹çš„åŸå­æŠ€èƒ½ï¼ŒRLæ‰èƒ½æœ‰æ•ˆåˆæˆå¤æ‚ç­–ç•¥ã€‚è¯¥ç ”ç©¶æœ€ç»ˆè¯æ˜ï¼Œè§£è€¦çš„åŸå­è®­ç»ƒéšåè¡”æ¥RLï¼Œä¸ºå®ç°å¤æ‚æ¨ç†ä»»åŠ¡çš„æ³›åŒ–æä¾›äº†ä¸€æ¡å¯æ‰©å±•çš„æŠ€æœ¯è·¯å¾„ã€‚",
      "categories": [
        "cs.AI",
        "cs.CL"
      ],
      "primary_category": "cs.AI",
      "comment": "Work in Progress. Code and data will be available at https://github.com/sitaocheng/from_atomic_to_composite",
      "pdf_url": "https://arxiv.org/pdf/2512.01970v2",
      "published_date": "2025-12-01 18:27:25 UTC",
      "updated_date": "2025-12-02 04:17:18 UTC",
      "processing_status": "completed",
      "attempts": 1,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "llm_backup_calls": 0,
      "last_update": "2026-01-26T12:26:52.640853+00:00"
    },
    {
      "arxiv_id": "2512.03100v1",
      "title": "Ensemble Privacy Defense for Knowledge-Intensive LLMs against Membership Inference Attacks",
      "title_zh": "é¢å‘çŸ¥è¯†å¯†é›†å‹å¤§è¯­è¨€æ¨¡å‹æŠµå¾¡æˆå‘˜æ¨ç†æ”»å‡»çš„é›†æˆéšç§é˜²å¾¡",
      "authors": [
        "Haowei Fu",
        "Bo Ni",
        "Han Xu",
        "Kunpeng Liu",
        "Dan Lin",
        "Tyler Derr"
      ],
      "abstract": "Retrieval-Augmented Generation (RAG) and Supervised Finetuning (SFT) have become the predominant paradigms for equipping Large Language Models (LLMs) with external knowledge for diverse, knowledge-intensive tasks. However, while such knowledge injection improves performance, it also exposes new attack surfaces. Membership Inference Attacks (MIAs), which aim to determine whether a given data sample was included in a model's training set, pose serious threats to privacy and trust in sensitive domains. To this end, we first systematically evaluate the vulnerability of RAG- and SFT-based LLMs to various MIAs. Then, to address the privacy risk, we further introduce a novel, model-agnostic defense framework, Ensemble Privacy Defense (EPD), which aggregates and evaluates the outputs of a knowledge-injected LLM, a base LLM, and a dedicated judge model to enhance resistance against MIAs. Comprehensive experiments show that, on average, EPD reduces MIA success by up to 27.8\\% for SFT and 526.3\\% for RAG compared to inference-time baseline, while maintaining answer quality.",
      "tldr_zh": "è¯¥ç ”ç©¶æ¢è®¨äº†æ£€ç´¢å¢å¼ºç”Ÿæˆ(RAG)å’Œç›‘ç£å¾®è°ƒ(SFT)åœ¨ä¸ºå¤§è¯­è¨€æ¨¡å‹(LLMs)æ³¨å…¥å¤–éƒ¨çŸ¥è¯†æ—¶å¸¦æ¥çš„éšç§é£é™©ï¼Œç‰¹åˆ«æ˜¯é’ˆå¯¹æˆå‘˜æ¨ç†æ”»å‡»(MIAs)çš„è„†å¼±æ€§ã€‚ä½œè€…é¦–å…ˆç³»ç»Ÿè¯„ä¼°äº†åŸºäºRAGå’ŒSFTçš„æ¨¡å‹åœ¨é¢å¯¹å¤šç§MIAsæ—¶çš„è¡¨ç°ï¼ŒæŒ‡å‡ºçŸ¥è¯†æ³¨å…¥è¿‡ç¨‹ä¼šæš´éœ²æ–°çš„å®‰å…¨éšæ‚£ã€‚ä¸ºäº†åº”å¯¹è¿™ä¸€éšç§å¨èƒï¼Œè®ºæ–‡æå‡ºäº†ä¸€ç§åä¸ºEnsemble Privacy Defense (EPD)çš„æ¨¡å‹æ— å…³é˜²å¾¡æ¡†æ¶ï¼Œé€šè¿‡èšåˆå¹¶è¯„ä¼°çŸ¥è¯†æ³¨å…¥æ¨¡å‹ã€åŸºç¡€LLMä»¥åŠä¸“ç”¨è¯„åˆ¤æ¨¡å‹çš„è¾“å‡ºæ¥å¢å¼ºé˜²å¾¡èƒ½åŠ›ã€‚å®éªŒç»“æœè¡¨æ˜ï¼ŒEPDåœ¨ä¿æŒå›ç­”è´¨é‡çš„åŒæ—¶ï¼Œèƒ½ä½¿SFTçš„æ”»å‡»æˆåŠŸç‡å¹³å‡é™ä½27.8%ï¼ŒRAGçš„æ”»å‡»æˆåŠŸç‡é™ä½526.3%ã€‚è¯¥ç ”ç©¶ä¸ºä¿æŠ¤çŸ¥è¯†å¯†é›†å‹å¤§è¯­è¨€æ¨¡å‹çš„éšç§å®‰å…¨æä¾›äº†æœ‰æ•ˆçš„æŠ€æœ¯è·¯å¾„ã€‚",
      "categories": [
        "cs.CR",
        "cs.AI"
      ],
      "primary_category": "cs.CR",
      "comment": "",
      "pdf_url": "https://arxiv.org/pdf/2512.03100v1",
      "published_date": "2025-12-01 18:12:18 UTC",
      "updated_date": "2025-12-01 18:12:18 UTC",
      "processing_status": "completed",
      "attempts": 1,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "llm_backup_calls": 0,
      "last_update": "2026-01-26T12:26:51.532505+00:00"
    },
    {
      "arxiv_id": "2512.01958v1",
      "title": "Learned-Rule-Augmented Large Language Model Evaluators",
      "title_zh": "å­¦ä¹ è§„åˆ™å¢å¼ºçš„å¤§è¯­è¨€æ¨¡å‹è¯„ä¼°å™¨",
      "authors": [
        "Jie Meng",
        "Jin Mao"
      ],
      "abstract": "Large language models (LLMs) are predominantly used as evaluators for natural language generation (NLG) tasks, but their application to broader evaluation scenarios remains limited. In this work, we explore the potential of LLMs as general evaluators across diverse tasks. Although LLM-based evaluators have made progress in different areas, existing methods struggle to generalize due to their reliance on costly, human-designed evaluation principles, which are often misaligned with both annotated data and LLMs' understanding.To address these challenges, we propose a rule-augmented evaluation paradigm. First, we introduce a rule distillation method that automatically extracts scoring rules from data using an LLM-assisted Monte Carlo Tree Search (MCTS), alleviating scalability issues and improving alignment with data. Second, to enable LLMs to effectively apply the learned rules, we propose two strategies: (1) Chain-of-Rule (CoR), which guides LLM to follow distilled rules, and (2) training a rule-augmented LLM evaluator (RuAE) via reinforcement learning, further bridging the gap between rules and LLMs' reasoning. Extensive experiments on diverse tasks demonstrate the effectiveness and generalizability of our approach across various evaluation scenarios.",
      "tldr_zh": "è¯¥ç ”ç©¶æ¢è®¨äº†å¤§å‹è¯­è¨€æ¨¡å‹(LLMs)ä½œä¸ºé€šç”¨è¯„ä¼°å™¨çš„æ½œåŠ›ï¼Œæ—¨åœ¨è§£å†³ç°æœ‰æ–¹æ³•è¿‡åº¦ä¾èµ–æ˜‚è´µä¸”éš¾ä»¥å¯¹é½çš„äººå·¥è®¾è®¡è¯„ä¼°åŸåˆ™çš„é—®é¢˜ã€‚ä¸ºæ­¤ï¼Œä½œè€…æå‡ºäº†ä¸€ç§è§„åˆ™å¢å¼ºçš„è¯„ä¼°èŒƒå¼ï¼Œé€šè¿‡åŸºäºå¤§å‹è¯­è¨€æ¨¡å‹è¾…åŠ©çš„è’™ç‰¹å¡æ´›æ ‘æœç´¢(MCTS)å®ç°è§„åˆ™è’¸é¦ï¼Œä»è€Œè‡ªåŠ¨ä»æ•°æ®ä¸­æå–è¯„åˆ†è§„åˆ™ã€‚è¿™ä¸€æ–¹æ³•æœ‰æ•ˆç¼“è§£äº†è§„åˆ™æå–çš„å¯æ‰©å±•æ€§æŒ‘æˆ˜ï¼Œå¹¶æ˜¾è‘—æé«˜äº†è¯„ä¼°è§„åˆ™ä¸æ•°æ®ä¹‹é—´çš„å¯¹é½åº¦ã€‚ä¸ºäº†ä½¿LLMsèƒ½å¤Ÿæœ‰æ•ˆåº”ç”¨è¿™äº›å­¦åˆ°çš„è§„åˆ™ï¼Œç ”ç©¶æå‡ºäº†Chain-of-Rule (CoR)ç­–ç•¥ä»¥å¼•å¯¼æ¨¡å‹çš„æ¨ç†è·¯å¾„ã€‚æ­¤å¤–ï¼Œç ”ç©¶è¿˜é€šè¿‡å¼ºåŒ–å­¦ä¹ è®­ç»ƒäº†è§„åˆ™å¢å¼ºå‹è¯„ä¼°å™¨(RuAE)ï¼Œè¿›ä¸€æ­¥å¼¥åˆäº†é¢„è®¾è§„åˆ™ä¸æ¨¡å‹è‡ªä¸»æ¨ç†é€»è¾‘ä¹‹é—´çš„å·®è·ã€‚åœ¨å¤šç§ä¸åŒä»»åŠ¡ä¸Šçš„å¹¿æ³›å®éªŒè¯æ˜ï¼Œè¯¥æ–¹æ³•åœ¨å„ç±»è¯„ä¼°åœºæ™¯ä¸­å‡è¡¨ç°å‡ºä¼˜å¼‚çš„æœ‰æ•ˆæ€§å’Œæ³›åŒ–èƒ½åŠ›ã€‚",
      "categories": [
        "cs.AI"
      ],
      "primary_category": "cs.AI",
      "comment": "",
      "pdf_url": "https://arxiv.org/pdf/2512.01958v1",
      "published_date": "2025-12-01 18:08:45 UTC",
      "updated_date": "2025-12-01 18:08:45 UTC",
      "processing_status": "completed",
      "attempts": 1,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "llm_backup_calls": 0,
      "last_update": "2026-01-26T12:27:02.989394+00:00"
    },
    {
      "arxiv_id": "2512.01952v1",
      "title": "GrndCtrl: Grounding World Models via Self-Supervised Reward Alignment",
      "title_zh": "GrndCtrlï¼šåŸºäºè‡ªç›‘ç£å¥–åŠ±å¯¹é½çš„ä¸–ç•Œæ¨¡å‹ç‰©ç†é”šå®š",
      "authors": [
        "Haoyang He",
        "Jay Patrikar",
        "Dong-Ki Kim",
        "Max Smith",
        "Daniel McGann",
        "Ali-akbar Agha-mohammadi",
        "Shayegan Omidshafiei",
        "Sebastian Scherer"
      ],
      "abstract": "Recent advances in video world modeling have enabled large-scale generative models to simulate embodied environments with high visual fidelity, providing strong priors for prediction, planning, and control. Yet, despite their realism, these models often lack geometric grounding, limiting their use in navigation tasks that require spatial coherence and long-horizon stability. We introduce Reinforcement Learning with World Grounding (RLWG), a self-supervised post-training framework that aligns pretrained world models with a physically verifiable structure through geometric and perceptual rewards. Analogous to reinforcement learning from verifiable feedback (RLVR) in language models, RLWG can use multiple rewards that measure pose cycle-consistency, depth reprojection, and temporal coherence. We instantiate this framework with GrndCtrl, a reward-aligned adaptation method based on Group Relative Policy Optimization (GRPO), yielding world models that maintain stable trajectories, consistent geometry, and reliable rollouts for embodied navigation. Like post-training alignment in large language models, GrndCtrl leverages verifiable rewards to bridge generative pretraining and grounded behavior, achieving superior spatial coherence and navigation stability over supervised fine-tuning in outdoor environments.",
      "tldr_zh": "è¯¥ç ”ç©¶æå‡ºäº†GrndCtrlï¼Œä¸€ç§é€šè¿‡è‡ªç›‘ç£å¥–åŠ±å¯¹é½å®ç°ä¸–ç•Œæ¨¡å‹å‡ ä½•æ¥åœ°çš„é€‚é…æ–¹æ³•ã€‚ä¸ºäº†è§£å†³ç°æœ‰è§†é¢‘ä¸–ç•Œæ¨¡å‹åœ¨å¯¼èˆªä»»åŠ¡ä¸­ç¼ºä¹å‡ ä½•ä¸€è‡´æ€§å’Œé•¿æœŸç¨³å®šæ€§ç­‰é—®é¢˜ï¼Œä½œè€…å¼•å…¥äº†Reinforcement Learning with World Grounding (RLWG)åè®­ç»ƒæ¡†æ¶ã€‚è¯¥æ¡†æ¶åˆ©ç”¨ä½å§¿å¾ªç¯ä¸€è‡´æ€§(pose cycle-consistency)ã€æ·±åº¦é‡æŠ•å½±(depth reprojection)å’Œæ—¶é—´è¿è´¯æ€§ç­‰å¯éªŒè¯çš„å¥–åŠ±ï¼Œå°†é¢„è®­ç»ƒæ¨¡å‹ä¸ç‰©ç†ç»“æ„è¿›è¡Œå¯¹é½ã€‚é€šè¿‡ç»“åˆGroup Relative Policy Optimization (GRPO)ç®—æ³•ï¼ŒGrndCtrlç”Ÿæˆçš„æ¨¡å‹èƒ½å¤Ÿç»´æŒç¨³å®šçš„è½¨è¿¹å’Œå¯é çš„å¯¼èˆªæ¨æ¼”ã€‚å®éªŒç»“æœè¡¨æ˜ï¼Œè¯¥æ–¹æ³•åœ¨æˆ·å¤–ç¯å¢ƒä¸­çš„ç©ºé—´è¿è´¯æ€§å’Œå¯¼èˆªç¨³å®šæ€§æ˜¾è‘—ä¼˜äºç›‘ç£å¾®è°ƒ(SFT)ï¼ŒæˆåŠŸå¼¥åˆäº†å¤§è§„æ¨¡ç”Ÿæˆå¼é¢„è®­ç»ƒä¸å…·èº«æ¥åœ°è¡Œä¸º(grounded behavior)ä¹‹é—´çš„é¸¿æ²Ÿã€‚",
      "categories": [
        "cs.CV",
        "cs.AI",
        "cs.LG",
        "cs.RO"
      ],
      "primary_category": "cs.CV",
      "comment": "",
      "pdf_url": "https://arxiv.org/pdf/2512.01952v1",
      "published_date": "2025-12-01 18:03:29 UTC",
      "updated_date": "2025-12-01 18:03:29 UTC",
      "processing_status": "completed",
      "attempts": 1,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "llm_backup_calls": 0,
      "last_update": "2026-01-26T12:27:00.536274+00:00"
    },
    {
      "arxiv_id": "2512.01945v1",
      "title": "Agentic Policy Optimization via Instruction-Policy Co-Evolution",
      "title_zh": "åŸºäºæŒ‡ä»¤-ç­–ç•¥ååŒæ¼”åŒ–çš„æ™ºèƒ½ä½“ç­–ç•¥ä¼˜åŒ–",
      "authors": [
        "Han Zhou",
        "Xingchen Wan",
        "Ivan VuliÄ‡",
        "Anna Korhonen"
      ],
      "abstract": "Reinforcement Learning with Verifiable Rewards (RLVR) has advanced the reasoning capability of large language models (LLMs), enabling autonomous agents that can conduct effective multi-turn and tool-integrated reasoning. While instructions serve as the primary protocol for defining agents, RLVR typically relies on static and manually designed instructions. However, those instructions may be suboptimal for the base model, and the optimal instruction may change as the agent's policy improves and explores the interaction with the environment. To bridge the gap, we introduce INSPO, a novel Instruction-Policy co-evolution framework that integrates instruction optimization as a dynamic component of the reinforcement learning (RL) loop. INSPO maintains a dynamic population of instruction candidates that are sampled with questions, where reward signals in RL loops are automatically attributed to each instruction, and low performers are periodically pruned. New instructions are generated and verified through an on-policy reflection mechanism, where an LLM-based optimizer analyzes past experience from a replay buffer and evolves more effective strategies given the current policy. We conduct extensive experiments on multi-turn retrieval and reasoning tasks, demonstrating that INSPO substantially outperforms strong baselines relying on static instructions. INSPO discovers innovative instructions that guide the agent toward more strategic reasoning paths, achieving substantial performance gains with only a marginal increase in computational overhead.",
      "tldr_zh": "è¯¥ç ”ç©¶é’ˆå¯¹å¤§è¯­è¨€æ¨¡å‹(LLMs)åœ¨å¯éªŒè¯å¥–åŠ±å¼ºåŒ–å­¦ä¹ (RLVR)ä¸­é•¿æœŸä¾èµ–é™æ€æ‰‹åŠ¨è®¾è®¡æŒ‡ä»¤è€Œå¯¼è‡´æ€§èƒ½äºšä¼˜çš„é—®é¢˜ï¼Œæå‡ºäº†INSPOï¼Œä¸€ç§æŒ‡ä»¤ä¸ç­–ç•¥ååŒæ¼”åŒ–(Instruction-Policy co-evolution)çš„æ–°å‹æ¡†æ¶ã€‚INSPOå°†æŒ‡ä»¤ä¼˜åŒ–ä½œä¸ºå¼ºåŒ–å­¦ä¹ é—­ç¯çš„åŠ¨æ€ç»„æˆéƒ¨åˆ†ï¼Œé€šè¿‡ç»´æŠ¤åŠ¨æ€æŒ‡ä»¤å€™é€‰ç¾¤ä½“å¹¶æ ¹æ®å¥–åŠ±ä¿¡å·è‡ªåŠ¨è¿›è¡Œä¼˜é€‰ä¸å‰”é™¤ï¼Œè§£å†³äº†æŒ‡ä»¤ä¸æ¼”è¿›ç­–ç•¥ä¸åŒ¹é…çš„ç—›ç‚¹ã€‚è¯¥æ¡†æ¶å¼•å…¥äº†åœ¨ç­–ç•¥åæ€æœºåˆ¶(on-policy reflection)ï¼Œåˆ©ç”¨åŸºäºLLMçš„ä¼˜åŒ–å™¨åˆ†æå›æ”¾æ± (replay buffer)ä¸­çš„å†å²ç»éªŒï¼Œä»è€Œæ ¹æ®å½“å‰ç­–ç•¥ç”Ÿæˆæ›´æœ‰æ•ˆçš„æ¨ç†ç­–ç•¥ã€‚å®éªŒç»“æœè¡¨æ˜ï¼ŒINSPOåœ¨å¤šè½®æ£€ç´¢å’Œæ¨ç†ä»»åŠ¡ä¸Šæ˜¾è‘—ä¼˜äºä¾èµ–é™æ€æŒ‡ä»¤çš„å¼ºåŸºå‡†æ¨¡å‹ã€‚è¯¥æ–¹æ³•èƒ½å¤Ÿå‘ç°å¼•å¯¼æ™ºèƒ½ä½“è¿›è¡Œæˆ˜ç•¥æ€§æ¨ç†çš„åˆ›æ–°æŒ‡ä»¤ï¼Œåœ¨ä»…å¢åŠ æå°‘è®¡ç®—å¼€é”€çš„æƒ…å†µä¸‹å®ç°äº†æ˜¾è‘—çš„æ€§èƒ½æå‡ã€‚",
      "categories": [
        "cs.LG",
        "cs.AI",
        "cs.CL"
      ],
      "primary_category": "cs.LG",
      "comment": "10 pages, 3 figures, 2 tables (18 pages including references and appendices)",
      "pdf_url": "https://arxiv.org/pdf/2512.01945v1",
      "published_date": "2025-12-01 17:56:29 UTC",
      "updated_date": "2025-12-01 17:56:29 UTC",
      "processing_status": "completed",
      "attempts": 1,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "llm_backup_calls": 0,
      "last_update": "2026-01-26T12:27:04.236417+00:00"
    },
    {
      "arxiv_id": "2512.01939v1",
      "title": "An Empirical Study of Agent Developer Practices in AI Agent Frameworks",
      "title_zh": "AI æ™ºèƒ½ä½“æ¡†æ¶ä¸­æ™ºèƒ½ä½“å¼€å‘å®è·µçš„å®è¯ç ”ç©¶",
      "authors": [
        "Yanlin Wang",
        "Xinyi Xu",
        "Jiachi Chen",
        "Tingting Bi",
        "Wenchao Gu",
        "Zibin Zheng"
      ],
      "abstract": "The rise of large language models (LLMs) has sparked a surge of interest in agents, leading to the rapid growth of agent frameworks. Agent frameworks are software toolkits and libraries that provide standardized components, abstractions, and orchestration mechanisms to simplify agent development. Despite widespread use of agent frameworks, their practical applications and how they influence the agent development process remain underexplored. Different agent frameworks encounter similar problems during use, indicating that these recurring issues deserve greater attention and call for further improvements in agent framework design. Meanwhile, as the number of agent frameworks continues to grow and evolve, more than 80% of developers report difficulties in identifying the frameworks that best meet their specific development requirements. In this paper, we conduct the first empirical study of LLM-based agent frameworks, exploring real-world experiences of developers in building AI agents. To compare how well the agent frameworks meet developer needs, we further collect developer discussions for the ten previously identified agent frameworks, resulting in a total of 11,910 discussions. Finally, by analyzing these discussions, we compare the frameworks across five dimensions: development efficiency, functional abstraction, learning cost, performance optimization, and maintainability, which refers to how easily developers can update and extend both the framework itself and the agents built upon it over time. Our comparative analysis reveals significant differences among frameworks in how they meet the needs of agent developers. Overall, we provide a set of findings and implications for the LLM-driven AI agent framework ecosystem and offer insights for the design of future LLM-based agent frameworks and agent developers.",
      "tldr_zh": "è¯¥ç ”ç©¶é’ˆå¯¹å¤§è¯­è¨€æ¨¡å‹(LLMs)é©±åŠ¨ä¸‹æ™ºèƒ½ä½“æ¡†æ¶(agent frameworks)çš„é£é€Ÿå¢é•¿ï¼Œå¼€å±•äº†é¦–ä¸ªå…³äºå¼€å‘è€…å®è·µç»éªŒçš„å®è¯ç ”ç©¶(empirical study)ã€‚ç ”ç©¶æŒ‡å‡ºï¼Œå°½ç®¡è¿™äº›æ¡†æ¶åº”ç”¨å¹¿æ³›ï¼Œä½†å…¶å¯¹å¼€å‘æµç¨‹çš„å½±å“åŠå®é™…åº”ç”¨ç°çŠ¶å°šæœªå¾—åˆ°å……åˆ†æ¢ç´¢ï¼Œä¸”è¶…è¿‡80%çš„å¼€å‘è€…åœ¨é€‰æ‹©æœ€ç¬¦åˆå…¶éœ€æ±‚çš„æ¡†æ¶æ—¶é¢ä¸´å›°éš¾ã€‚ä¸ºæ­¤ï¼Œç ”ç©¶å›¢é˜Ÿæ”¶é›†å¹¶åˆ†æäº†åä¸ªä¸»æµæ™ºèƒ½ä½“æ¡†æ¶ä¸­çš„11,910æ¡å¼€å‘è€…è®¨è®ºï¼Œä»å¼€å‘æ•ˆç‡(development efficiency)ã€åŠŸèƒ½æŠ½è±¡(functional abstraction)ã€å­¦ä¹ æˆæœ¬(learning cost)ã€æ€§èƒ½ä¼˜åŒ–(performance optimization)å’Œå¯ç»´æŠ¤æ€§(maintainability)äº”ä¸ªç»´åº¦è¿›è¡Œäº†æ·±åº¦å¯¹æ¯”ã€‚åˆ†æç»“æœæ­ç¤ºäº†ä¸åŒæ¡†æ¶åœ¨æ»¡è¶³å¼€å‘è€…éœ€æ±‚æ–¹é¢å­˜åœ¨æ˜¾è‘—å·®å¼‚ï¼Œå¹¶è¯†åˆ«å‡ºäº†å¼€å‘è¿‡ç¨‹ä¸­åå¤å‡ºç°çš„é€šç”¨è®¾è®¡é—®é¢˜ã€‚æœ€åï¼Œè¯¥ç ”ç©¶ä¸ºå¤§è¯­è¨€æ¨¡å‹é©±åŠ¨çš„æ™ºèƒ½ä½“ç”Ÿæ€ç³»ç»Ÿæä¾›äº†ä¸€ç³»åˆ—å‘ç°ä¸å¯ç¤ºï¼Œä¸ºæœªæ¥æ™ºèƒ½ä½“æ¡†æ¶çš„è®¾è®¡å’Œå¼€å‘è€…å®è·µæä¾›äº†é‡è¦çš„å‚è€ƒä¸æŒ‡å¯¼ã€‚",
      "categories": [
        "cs.SE",
        "cs.AI"
      ],
      "primary_category": "cs.SE",
      "comment": "",
      "pdf_url": "https://arxiv.org/pdf/2512.01939v1",
      "published_date": "2025-12-01 17:52:15 UTC",
      "updated_date": "2025-12-01 17:52:15 UTC",
      "processing_status": "completed",
      "attempts": 1,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "llm_backup_calls": 0,
      "last_update": "2026-01-26T12:27:28.845277+00:00"
    },
    {
      "arxiv_id": "2512.01930v1",
      "title": "SVRG and Beyond via Posterior Correction",
      "title_zh": "åŸºäºåéªŒæ ¡æ­£çš„ SVRG åŠå…¶æ‹“å±•",
      "authors": [
        "Nico Daheim",
        "Thomas MÃ¶llenhoff",
        "Ming Liang Ang",
        "Mohammad Emtiyaz Khan"
      ],
      "abstract": "Stochastic Variance Reduced Gradient (SVRG) and its variants aim to speed-up training by using gradient corrections, but have seen limited success in deep learning. Here, we show surprising new foundational connections of SVRG to a recently proposed Bayesian method called posterior correction. Specifically, we show that SVRG is recovered as a special case of posterior correction over the isotropic-Gaussian family, while novel extensions are automatically obtained by using more flexible exponential families. We derive two new SVRG variants by using Gaussian families: First, a Newton-like variant that employs novel Hessian corrections, and second, an Adam-like extension that improves pretraining and finetuning of Transformer language models. This is the first work to connect SVRG to Bayes and use it to boost variational training for deep networks.",
      "tldr_zh": "è¯¥ç ”ç©¶æ­ç¤ºäº†éšæœºæ–¹å·®ç¼©å‡æ¢¯åº¦(SVRG)ä¸ä¸€ç§åä¸ºåéªŒæ ¡æ­£(posterior correction)çš„è´å¶æ–¯æ–¹æ³•ä¹‹é—´çš„æ–°å‹åŸºç¡€è”ç³»ã€‚ä½œè€…è¯æ˜äº† SVRG å®é™…ä¸Šæ˜¯åœ¨å„å‘åŒæ€§é«˜æ–¯æ—(isotropic-Gaussian family)ä¸Šè¿›è¡ŒåéªŒæ ¡æ­£çš„ä¸€ä¸ªç‰¹ä¾‹ï¼Œå¹¶ç”±æ­¤åˆ©ç”¨æ›´çµæ´»çš„æŒ‡æ•°æ—(exponential families)æ¨å¯¼å‡º SVRG çš„æ–°é¢–æ‰©å±•ã€‚ç ”ç©¶é€šè¿‡é«˜æ–¯æ—å¯¼å‡ºäº†ä¸¤ç§æ–°å‹å˜ä½“ï¼šä¸€ç§æ˜¯å¼•å…¥äº†æµ·æ£®æ ¡æ­£(Hessian corrections)çš„ç±»ç‰›é¡¿(Newton-like)å˜ä½“ï¼Œå¦ä¸€ç§æ˜¯æ—¨åœ¨ä¼˜åŒ– Transformer è¯­è¨€æ¨¡å‹é¢„è®­ç»ƒä¸å¾®è°ƒçš„ç±» Adam(Adam-like)æ‰©å±•ã€‚è¿™æ˜¯é¦–ä¸ªå°† SVRG ä¸è´å¶æ–¯æ¨ç†(Bayes)ç›¸ç»“åˆçš„å·¥ä½œï¼Œå¹¶æˆåŠŸåˆ©ç”¨è¯¥è”ç³»æå‡äº†æ·±åº¦ç¥ç»ç½‘ç»œçš„å˜åˆ†è®­ç»ƒ(variational training)æ€§èƒ½ã€‚",
      "categories": [
        "cs.LG",
        "cs.AI"
      ],
      "primary_category": "cs.LG",
      "comment": "Preprint. Under review",
      "pdf_url": "https://arxiv.org/pdf/2512.01930v1",
      "published_date": "2025-12-01 17:45:30 UTC",
      "updated_date": "2025-12-01 17:45:30 UTC",
      "processing_status": "completed",
      "attempts": 1,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "llm_backup_calls": 0,
      "last_update": "2026-01-26T12:27:10.044414+00:00"
    },
    {
      "arxiv_id": "2512.01925v1",
      "title": "Rectifying LLM Thought from Lens of Optimization",
      "title_zh": "ä»ä¼˜åŒ–è§†è§’çº æ­£å¤§è¯­è¨€æ¨¡å‹æ€ç»´",
      "authors": [
        "Junnan Liu",
        "Hongwei Liu",
        "Songyang Zhang",
        "Kai Chen"
      ],
      "abstract": "Recent advancements in large language models (LLMs) have been driven by their emergent reasoning capabilities, particularly through long chain-of-thought (CoT) prompting, which enables thorough exploration and deliberation. Despite these advances, long-CoT LLMs often exhibit suboptimal reasoning behaviors, such as overthinking and excessively protracted reasoning chains, which can impair performance. In this paper, we analyze reasoning processes through an optimization lens, framing CoT as a gradient descent procedure where each reasoning step constitutes an update toward problem resolution. Building on this perspective, we introduce RePro (Rectifying Process-level Reward), a novel approach to refine LLM reasoning during post-training. RePro defines a surrogate objective function to assess the optimization process underlying CoT, utilizing a dual scoring mechanism to quantify its intensity and stability. These scores are aggregated into a composite process-level reward, seamlessly integrated into reinforcement learning with verifiable rewards (RLVR) pipelines to optimize LLMs. Extensive experiments across multiple reinforcement learning algorithms and diverse LLMs, evaluated on benchmarks spanning mathematics, science, and coding, demonstrate that RePro consistently enhances reasoning performance and mitigates suboptimal reasoning behaviors.",
      "tldr_zh": "è¯¥ç ”ç©¶é’ˆå¯¹å¤§è¯­è¨€æ¨¡å‹(LLMs)åœ¨é•¿é“¾å¼æ€ç»´(Long-CoT)æ¨ç†ä¸­å‡ºç°çš„è¿‡åº¦æ€è€ƒ(Overthinking)å’Œæ¨ç†é“¾å†—é•¿ç­‰æ¬¡ä¼˜è¡Œä¸ºï¼Œä»ä¼˜åŒ–(Optimization)çš„è§’åº¦åˆ†æäº†æ¨ç†è¿‡ç¨‹ã€‚ä½œè€…å°†CoTè¿‡ç¨‹æ¡†æ¶åŒ–ä¸ºç±»ä¼¼äºæ¢¯åº¦ä¸‹é™(Gradient Descent)çš„å¯»ä¼˜æ­¥éª¤ï¼Œå¹¶æ®æ­¤æå‡ºäº†åä¸ºRePro (Rectifying Process-level Reward)çš„æ–°å‹è®­ç»ƒæ–¹æ³•ã€‚ReProå®šä¹‰äº†ä¸€ä¸ªä»£ç†ç›®æ ‡å‡½æ•°æ¥è¯„ä¼°CoTèƒŒåçš„ä¼˜åŒ–è¿‡ç¨‹ï¼Œåˆ©ç”¨åŒé‡è¯„åˆ†æœºåˆ¶é‡åŒ–å…¶å¼ºåº¦(Intensity)å’Œç¨³å®šæ€§(Stability)ã€‚è¿™äº›è¯„åˆ†è¢«èšåˆä¸ºå¤åˆçš„è¿‡ç¨‹çº§å¥–åŠ±ï¼Œå¹¶æ— ç¼é›†æˆåˆ°å¸¦éªŒè¯å¥–åŠ±çš„å¼ºåŒ–å­¦ä¹ (RLVR)æµæ°´çº¿ä¸­ä»¥ä¼˜åŒ–æ¨¡å‹æ€§èƒ½ã€‚åœ¨æ•°å­¦ã€ç§‘å­¦å’Œä»£ç ç­‰å¤šä¸ªé¢†åŸŸçš„å®éªŒç»“æœè¡¨æ˜ï¼ŒReProèƒ½å¤Ÿæ˜¾è‘—æå‡æ¨¡å‹çš„æ¨ç†è¡¨ç°ï¼Œå¹¶æœ‰æ•ˆç¼“è§£æ— æ•ˆçš„å†—é•¿æ¨ç†è¡Œä¸ºã€‚",
      "categories": [
        "cs.CL",
        "cs.AI"
      ],
      "primary_category": "cs.CL",
      "comment": "Work in progress",
      "pdf_url": "https://arxiv.org/pdf/2512.01925v1",
      "published_date": "2025-12-01 17:41:08 UTC",
      "updated_date": "2025-12-01 17:41:08 UTC",
      "processing_status": "completed",
      "attempts": 1,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "llm_backup_calls": 0,
      "last_update": "2026-01-26T12:27:31.336761+00:00"
    },
    {
      "arxiv_id": "2512.01924v1",
      "title": "Real-World Robot Control by Deep Active Inference With a Temporally Hierarchical World Model",
      "title_zh": "åŸºäºæ—¶é—´å±‚æ¬¡åŒ–ä¸–ç•Œæ¨¡å‹æ·±åº¦ä¸»åŠ¨æ¨ç†çš„çœŸå®ä¸–ç•Œæœºå™¨äººæ§åˆ¶",
      "authors": [
        "Kentaro Fujii",
        "Shingo Murata"
      ],
      "abstract": "Robots in uncertain real-world environments must perform both goal-directed and exploratory actions. However, most deep learning-based control methods neglect exploration and struggle under uncertainty. To address this, we adopt deep active inference, a framework that accounts for human goal-directed and exploratory actions. Yet, conventional deep active inference approaches face challenges due to limited environmental representation capacity and high computational cost in action selection. We propose a novel deep active inference framework that consists of a world model, an action model, and an abstract world model. The world model encodes environmental dynamics into hidden state representations at slow and fast timescales. The action model compresses action sequences into abstract actions using vector quantization, and the abstract world model predicts future slow states conditioned on the abstract action, enabling low-cost action selection. We evaluate the framework on object-manipulation tasks with a real-world robot. Results show that it achieves high success rates across diverse manipulation tasks and switches between goal-directed and exploratory actions in uncertain settings, while making action selection computationally tractable. These findings highlight the importance of modeling multiple timescale dynamics and abstracting actions and state transitions.",
      "tldr_zh": "è¯¥ç ”ç©¶é’ˆå¯¹ä¸ç¡®å®šç°å®ç¯å¢ƒä¸‹çš„æœºå™¨äººæ§åˆ¶é—®é¢˜ï¼Œæå‡ºäº†ä¸€ä¸ªåŸºäºæ·±å±‚ä¸»åŠ¨æ¨ç†(Deep Active Inference)çš„å…¨æ–°æ¡†æ¶ï¼Œæ—¨åœ¨å¹³è¡¡æœºå™¨äººçš„ç›®æ ‡å¯¼å‘ä¸æ¢ç´¢æ€§è¡Œä¸ºã€‚è¯¥æ¡†æ¶æ ¸å¿ƒåŒ…å«World Modelã€Action Modelå’ŒAbstract World Modelï¼Œå…¶ä¸­World Modelé€šè¿‡å¿«æ…¢ä¸¤ç§æ—¶é—´å°ºåº¦å°†ç¯å¢ƒåŠ¨åŠ›å­¦ç¼–ç ä¸ºå±‚çº§åŒ–çš„éšè—çŠ¶æ€è¡¨ç¤ºã€‚ç ”ç©¶åˆ©ç”¨çŸ¢é‡é‡åŒ–(Vector Quantization)æŠ€æœ¯å°†åŠ¨ä½œåºåˆ—å‹ç¼©ä¸ºæŠ½è±¡åŠ¨ä½œï¼Œå¹¶ç»“åˆAbstract World Modelé¢„æµ‹æœªæ¥æ…¢é€ŸçŠ¶æ€ï¼Œä»è€Œå¤§å¹…é™ä½äº†åŠ¨ä½œé€‰æ‹©çš„è®¡ç®—æˆæœ¬ã€‚åœ¨çœŸå®æœºå™¨äººçš„ç‰©ä½“æ“çºµå®éªŒä¸­ï¼Œè¯¥æ¡†æ¶åœ¨å¤šç§ä»»åŠ¡ä¸‹å‡å®ç°äº†æé«˜çš„æˆåŠŸç‡ï¼Œå¹¶è¯æ˜äº†å…¶åœ¨ä¸ç¡®å®šæ€§è®¾ç½®ä¸‹è‡ªä¸»åˆ‡æ¢ç›®æ ‡å¯¼å‘ä¸æ¢ç´¢æ€§åŠ¨ä½œçš„èƒ½åŠ›ã€‚è¿™äº›å‘ç°å¼ºè°ƒäº†å¤šæ—¶é—´å°ºåº¦åŠ¨åŠ›å­¦å»ºæ¨¡ä»¥åŠå¯¹åŠ¨ä½œå’ŒçŠ¶æ€è½¬ç§»è¿›è¡ŒæŠ½è±¡åŒ–å¤„ç†å¯¹äºå®ç°è®¡ç®—é«˜æ•ˆä¸”é²æ£’çš„æœºå™¨äººæ§åˆ¶å…·æœ‰é‡è¦æ„ä¹‰ã€‚",
      "categories": [
        "cs.RO",
        "cs.AI",
        "cs.LG"
      ],
      "primary_category": "cs.RO",
      "comment": "Accepted for publication in IEEE Robotics and Automation Letters (RA-L)",
      "pdf_url": "https://arxiv.org/pdf/2512.01924v1",
      "published_date": "2025-12-01 17:41:01 UTC",
      "updated_date": "2025-12-01 17:41:01 UTC",
      "processing_status": "completed",
      "attempts": 1,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "llm_backup_calls": 0,
      "last_update": "2026-01-26T12:27:17.644658+00:00"
    },
    {
      "arxiv_id": "2512.01892v1",
      "title": "Exploring Human Perceptions of AI Responses: Insights from a Mixed-Methods Study on Risk Mitigation in Generative Models",
      "title_zh": "æ¢ç´¢äººç±»å¯¹ AI å›å¤çš„æ„ŸçŸ¥ï¼šå…³äºç”Ÿæˆå¼æ¨¡å‹é£é™©ç¼“è§£çš„æ··åˆæ–¹æ³•ç ”ç©¶å¯ç¤º",
      "authors": [
        "Heloisa Candello",
        "Muneeza Azmat",
        "Uma Sushmitha Gunturi",
        "Raya Horesh",
        "Rogerio Abreu de Paula",
        "Heloisa Pimentel",
        "Marcelo Carpinette Grave",
        "Aminat Adebiyi",
        "Tiago Machado",
        "Maysa Malfiza Garcia de Macedo"
      ],
      "abstract": "With the rapid uptake of generative AI, investigating human perceptions of generated responses has become crucial. A major challenge is their `aptitude' for hallucinating and generating harmful contents. Despite major efforts for implementing guardrails, human perceptions of these mitigation strategies are largely unknown. We conducted a mixed-method experiment for evaluating the responses of a mitigation strategy across multiple-dimensions: faithfulness, fairness, harm-removal capacity, and relevance. In a within-subject study design, 57 participants assessed the responses under two conditions: harmful response plus its mitigation and solely mitigated response. Results revealed that participants' native language, AI work experience, and annotation familiarity significantly influenced evaluations. Participants showed high sensitivity to linguistic and contextual attributes, penalizing minor grammar errors while rewarding preserved semantic contexts. This contrasts with how language is often treated in the quantitative evaluation of LLMs. We also introduced new metrics for training and evaluating mitigation strategies and insights for human-AI evaluation studies.",
      "tldr_zh": "è¿™é¡¹ç ”ç©¶é€šè¿‡æ··åˆæ–¹æ³•å®éªŒï¼ˆMixed-methods studyï¼‰æ¢è®¨äº†äººç±»å¯¹ Generative AI é£é™©ç¼“è§£ï¼ˆRisk Mitigationï¼‰ç­–ç•¥çš„æ„ŸçŸ¥ï¼Œæ—¨åœ¨è§£å†³ç”Ÿæˆæ¨¡å‹åœ¨å¹»è§‰å’Œæœ‰å®³å†…å®¹æ–¹é¢çš„æŒ‘æˆ˜ã€‚ç ”ç©¶é‚€è¯· 57 åå‚ä¸è€…ä»å¿ å®åº¦ï¼ˆFaithfulnessï¼‰ã€å…¬å¹³æ€§ï¼ˆFairnessï¼‰ã€é™¤å®³èƒ½åŠ›ï¼ˆHarm-removal capacityï¼‰å’Œç›¸å…³æ€§ï¼ˆRelevanceï¼‰ç­‰ç»´åº¦ï¼Œå¯¹â€œæœ‰å®³å“åº”åŠ ç¼“è§£æªæ–½â€ä¸â€œä»…ç¼“è§£å“åº”â€ä¸¤ç§æ¡ä»¶ä¸‹çš„ AI è¾“å‡ºè¿›è¡Œè¯„ä¼°ã€‚å®éªŒå‘ç°ï¼Œå‚ä¸è€…çš„æ¯è¯­èƒŒæ™¯ã€AI å·¥ä½œç»éªŒå’Œå¯¹æ ‡æ³¨ï¼ˆAnnotationï¼‰çš„ç†Ÿæ‚‰ç¨‹åº¦æ˜¾è‘—å½±å“äº†å…¶è¯„ä»·æ ‡å‡†ã€‚å‚ä¸è€…å¯¹è¯­è¨€è´¨é‡é«˜åº¦æ•æ„Ÿï¼Œä¼šä¸¥å‰æƒ©ç½šå¾®å°çš„è¯­æ³•é”™è¯¯ï¼ŒåŒæ—¶æ›´çœ‹é‡è¯­ä¹‰ä¸Šä¸‹æ–‡ï¼ˆSemantic Contextsï¼‰çš„ä¿ç•™ï¼Œè¿™ä¸å½“å‰ LLMs çš„å®šé‡è¯„ä¼°æ–¹å¼å½¢æˆé²œæ˜å¯¹æ¯”ã€‚è¯¥ç ”ç©¶æœ€åæå‡ºäº†ç”¨äºè®­ç»ƒå’Œè¯„ä¼°ç¼“è§£ç­–ç•¥çš„æ–°æŒ‡æ ‡ï¼ˆMetricsï¼‰ï¼Œä¸º Human-AI äº¤äº’è¯„ä¼°é¢†åŸŸæä¾›äº†é‡è¦è§è§£ã€‚",
      "categories": [
        "cs.CL",
        "cs.AI",
        "cs.HC"
      ],
      "primary_category": "cs.CL",
      "comment": "16 pages, 2 figures, 6 tables. Under review for publication",
      "pdf_url": "https://arxiv.org/pdf/2512.01892v1",
      "published_date": "2025-12-01 17:12:28 UTC",
      "updated_date": "2025-12-01 17:12:28 UTC",
      "processing_status": "completed",
      "attempts": 1,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "llm_backup_calls": 0,
      "last_update": "2026-01-26T12:27:46.142572+00:00"
    },
    {
      "arxiv_id": "2512.01881v2",
      "title": "Unifying Sign and Magnitude for Optimizing Deep Vision Networks via ThermoLion",
      "title_zh": "ThermoLionï¼šé€šè¿‡èåˆç¬¦å·ä¸å¹…å€¼ä¼˜åŒ–æ·±åº¦è§†è§‰ç½‘ç»œ",
      "authors": [
        "Ahmed Nebli"
      ],
      "abstract": "The training of deep vision models is fundamentally a signal recovery problem amidst high-dimensional stochastic noise. Current optimization paradigms impose a static compromise on information channel capacity. For instance, magnitude-based methods, such as AdamW, operate on the assumption that gradient norms are high-fidelity curvature signals. While this allows for precision in smooth regimes, it leads to catastrophic noise amplification when applied to rugged, non-convex landscapes. Conversely, sign-based methods (e.g., Lion) perform a radical 1-bit quantization of the gradient, which aims to provide robust regularization at the cost of discarding fine-grained descent information. We propose that optimal convergence requires neither static prior, but rather a dynamic modulation of the update bitrate. We introduce ThermoLion, a vision-centric framework that utilizes local Signal-to-Noise Ratio (SNR) gating to autonomously transition parameters between a \"low-bit\" exploration phase and a \"high-precision\" exploitation phase. Furthermore, we introduce a Momentum Alignment mechanism that detects constructive interference between historical drift and instantaneous gradients to accelerate convergence during stable trajectories. Empirical benchmarks across 12 diverse vision datasets (including CIFAR, SVHN, and GTSRB) demonstrate that ThermoLion surpasses state-of-the-art optimizers, such as AdamW and Lion, in convergence speed and terminal accuracy.",
      "tldr_zh": "è¯¥ç ”ç©¶æå‡ºäº† ThermoLionï¼Œä¸€ç§ä¸“ä¸ºæ·±åº¦è§†è§‰ç½‘ç»œè®¾è®¡çš„ä¼˜åŒ–æ¡†æ¶ï¼Œæ—¨åœ¨é€šè¿‡åŠ¨æ€è°ƒèŠ‚æ›´æ–°æ¯”ç‰¹ç‡æ¥ç»Ÿä¸€åˆ©ç”¨æ¢¯åº¦çš„ç¬¦å·ä¸å¹…å€¼ä¿¡æ¯ã€‚é’ˆå¯¹ AdamW ç­‰åŸºäºå¹…å€¼ï¼ˆmagnitude-basedï¼‰çš„æ–¹æ³•åœ¨éå‡¸æ™¯è§‚ä¸­æ˜“äº§ç”Ÿå™ªå£°æ”¾å¤§ï¼Œä»¥åŠ Lion ç­‰åŸºäºç¬¦å·ï¼ˆsign-basedï¼‰çš„æ–¹æ³•å›  1-bit é‡åŒ–ä¸¢å¤±ç²¾ç»†ä¿¡æ¯çš„ç¼ºé™·ï¼ŒThermoLion å¼•å…¥äº†å±€éƒ¨ä¿¡å™ªæ¯”ï¼ˆSignal-to-Noise Ratio, SNRï¼‰é—¨æ§æœºåˆ¶ã€‚è¯¥æœºåˆ¶å…è®¸æ¨¡å‹å‚æ•°åœ¨â€œä½æ¯”ç‰¹â€æ¢ç´¢é˜¶æ®µä¸â€œé«˜ç²¾åº¦â€åˆ©ç”¨é˜¶æ®µä¹‹é—´è‡ªä¸»åˆ‡æ¢ï¼Œä»è€Œä¼˜åŒ–æ”¶æ•›è·¯å¾„ã€‚æ­¤å¤–ï¼Œç ”ç©¶è¿˜å¼•å…¥äº†åŠ¨é‡å¯¹é½ï¼ˆMomentum Alignmentï¼‰æœºåˆ¶ï¼Œé€šè¿‡è¯†åˆ«å†å²æ¼‚ç§»ä¸ç¬æ—¶æ¢¯åº¦çš„å»ºè®¾æ€§å¹²æ¶‰æ¥åŠ é€Ÿç¨³å®šè½¨è¿¹ä¸‹çš„è®­ç»ƒã€‚åœ¨ CIFARã€SVHN å’Œ GTSRB ç­‰ 12 ä¸ªè§†è§‰æ•°æ®é›†ä¸Šçš„å®éªŒç»“æœè¯æ˜ï¼ŒThermoLion åœ¨æ”¶æ•›é€Ÿåº¦å’Œæœ€ç»ˆç²¾åº¦ä¸Šå‡æ˜¾è‘—ä¼˜äº AdamW å’Œ Lion ç­‰å½“å‰æœ€å…ˆè¿›çš„ä¼˜åŒ–å™¨ã€‚",
      "categories": [
        "cs.LG",
        "cs.AI"
      ],
      "primary_category": "cs.LG",
      "comment": "",
      "pdf_url": "https://arxiv.org/pdf/2512.01881v2",
      "published_date": "2025-12-01 17:04:17 UTC",
      "updated_date": "2025-12-02 10:04:52 UTC",
      "processing_status": "completed",
      "attempts": 1,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "llm_backup_calls": 0,
      "last_update": "2026-01-26T12:27:58.133004+00:00"
    },
    {
      "arxiv_id": "2512.01880v1",
      "title": "Predicting Human Chess Moves: An AI Assisted Analysis of Chess Games Using Skill-group Specific n-gram Language Models",
      "title_zh": "é¢„æµ‹äººç±»å›½é™…è±¡æ£‹æ‹›æ³•ï¼šåŸºäºç‰¹å®šæ°´å¹³ç»„ n-gram è¯­è¨€æ¨¡å‹çš„äººå·¥æ™ºèƒ½è¾…åŠ©å¯¹å±€åˆ†æ",
      "authors": [
        "Daren Zhong",
        "Dingcheng Huang",
        "Clayton Greenberg"
      ],
      "abstract": "Chess, a deterministic game with perfect information, has long served as a benchmark for studying strategic decision-making and artificial intelligence. Traditional chess engines or tools for analysis primarily focus on calculating optimal moves, often neglecting the variability inherent in human chess playing, particularly across different skill levels.\n  To overcome this limitation, we propose a novel and computationally efficient move prediction framework that approaches chess move prediction as a behavioral analysis task. The framework employs n-gram language models to capture move patterns characteristic of specific player skill levels. By dividing players into seven distinct skill groups, from novice to expert, we trained separate models using data from the open-source chess platform Lichess. The framework dynamically selects the most suitable model for prediction tasks and generates player moves based on preceding sequences.\n  Evaluation on real-world game data demonstrates that the model selector module within the framework can classify skill levels with an accuracy of up to 31.7\\% when utilizing early game information (16 half-moves). The move prediction framework also shows substantial accuracy improvements, with our Selector Assisted Accuracy being up to 39.1\\% more accurate than our benchmark accuracy. The computational efficiency of the framework further enhances its suitability for real-time chess analysis.",
      "tldr_zh": "è¯¥ç ”ç©¶æå‡ºäº†ä¸€ç§è®¡ç®—æ•ˆç‡è¾ƒé«˜çš„å›½é™…è±¡æ£‹èµ°æ³•é¢„æµ‹æ¡†æ¶ï¼Œå°†äººç±»æ£‹æ‰‹çš„èµ°æ³•é¢„æµ‹è§†ä¸ºä¸€é¡¹è¡Œä¸ºåˆ†æä»»åŠ¡ã€‚ç ”ç©¶äººå‘˜é‡‡ç”¨ n-gram è¯­è¨€æ¨¡å‹æ¥æ•æ‰ç‰¹å®šæŠ€èƒ½æ°´å¹³æ£‹æ‰‹çš„èµ°æ³•ç‰¹å¾ï¼Œå¹¶å°†æ£‹æ‰‹åˆ’åˆ†ä¸ºä»æ–°æ‰‹åˆ°ä¸“å®¶çš„ä¸ƒä¸ªä¸åŒç­‰çº§ã€‚åˆ©ç”¨æ¥è‡ª Lichess å¼€æºå¹³å°çš„å¤§è§„æ¨¡å¯¹å±€æ•°æ®ï¼Œè¯¥æ¡†æ¶ä¸ºæ¯ä¸ªç­‰çº§è®­ç»ƒäº†ç‹¬ç«‹çš„æ¨¡å‹ï¼Œå¹¶èƒ½æ ¹æ®å‰åºèµ°æ³•åºåˆ—åŠ¨æ€é€‰æ‹©æœ€åŒ¹é…çš„æ¨¡å‹è¿›è¡Œé¢„æµ‹ã€‚å®éªŒç»“æœæ˜¾ç¤ºï¼Œè¯¥æ¡†æ¶çš„ model selector æ¨¡å—åœ¨ä»…åˆ©ç”¨å¼€å±€ 16 ä¸ªåŠå›åˆçš„ä¿¡æ¯æ—¶ï¼ŒæŠ€èƒ½ç­‰çº§åˆ†ç±»å‡†ç¡®ç‡å¯è¾¾ 31.7%ã€‚æ­¤å¤–ï¼Œåœ¨èµ°æ³•é¢„æµ‹ä»»åŠ¡ä¸­ï¼Œå…¶ Selector Assisted Accuracy çš„è¡¨ç°æ¯”åŸºå‡†æ¨¡å‹å‡†ç¡®ç‡æå‡äº† 39.1%ã€‚ç”±äºå…·å¤‡æ˜¾è‘—çš„è®¡ç®—æ•ˆç‡ï¼Œè¯¥æ¡†æ¶éå¸¸é€‚åˆç”¨äºå®æ—¶çš„å›½é™…è±¡æ£‹å¯¹å¼ˆåˆ†æï¼Œä¸ºç†è§£ä¸åŒæ°´å¹³æ£‹æ‰‹çš„å†³ç­–å·®å¼‚æä¾›äº†æ–°çš„ AI è¾…åŠ©æ‰‹æ®µã€‚",
      "categories": [
        "cs.AI"
      ],
      "primary_category": "cs.AI",
      "comment": "",
      "pdf_url": "https://arxiv.org/pdf/2512.01880v1",
      "published_date": "2025-12-01 17:02:07 UTC",
      "updated_date": "2025-12-01 17:02:07 UTC",
      "processing_status": "completed",
      "attempts": 1,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "llm_backup_calls": 0,
      "last_update": "2026-01-26T12:27:57.935977+00:00"
    },
    {
      "arxiv_id": "2512.01878v1",
      "title": "Graph Distance as Surprise: Free Energy Minimization in Knowledge Graph Reasoning",
      "title_zh": "å›¾è·ç¦»å³æƒŠå¥‡ï¼šçŸ¥è¯†å›¾è°±æ¨ç†ä¸­çš„è‡ªç”±èƒ½æœ€å°åŒ–",
      "authors": [
        "Gaganpreet Jhajj",
        "Fuhua Lin"
      ],
      "abstract": "In this work, we propose that reasoning in knowledge graph (KG) networks can be guided by surprise minimization. Entities that are close in graph distance will have lower surprise than those farther apart. This connects the Free Energy Principle (FEP) from neuroscience to KG systems, where the KG serves as the agent's generative model. We formalize surprise using the shortest-path distance in directed graphs and provide a framework for KG-based agents. Graph distance appears in graph neural networks as message passing depth and in model-based reinforcement learning as world model trajectories. This work-in-progress study explores whether distance-based surprise can extend recent work showing that syntax minimizes surprise and free energy via tree structures.",
      "tldr_zh": "è¯¥ç ”ç©¶æå‡ºäº†ä¸€ç§åŸºäºæƒŠå¥‡æœ€å°åŒ–(surprise minimization)å¼•å¯¼çŸ¥è¯†å›¾è°±(Knowledge Graph)æ¨ç†çš„æ–°è§†è§’ï¼Œæ—¨åœ¨å°†ç¥ç»ç§‘å­¦ä¸­çš„è‡ªç”±èƒ½åŸç†(Free Energy Principle)åº”ç”¨äºå›¾è®ºç³»ç»Ÿã€‚ç ”ç©¶å°†çŸ¥è¯†å›¾è°±å®šä¹‰ä¸ºæ™ºèƒ½ä½“çš„ç”Ÿæˆæ¨¡å‹(generative model)ï¼Œå¹¶å°†æœ‰å‘å›¾ä¸­çš„æœ€çŸ­è·¯å¾„è·ç¦»(shortest-path distance)å½¢å¼åŒ–ä¸ºæƒŠå¥‡å€¼ï¼Œè®¤ä¸ºè·ç¦»è¶Šè¿‘çš„å®ä½“æƒŠå¥‡ç¨‹åº¦è¶Šä½ã€‚é€šè¿‡è¿™ä¸€æ¡†æ¶ï¼Œå›¾ç¥ç»ç½‘ç»œ(GNNs)çš„æ¶ˆæ¯ä¼ é€’æ·±åº¦ä¸å¼ºåŒ–å­¦ä¹ (RL)çš„ä¸–ç•Œæ¨¡å‹è½¨è¿¹åœ¨å›¾è·ç¦»å±‚é¢å¾—åˆ°äº†ç†è®ºç»Ÿä¸€ã€‚è¯¥ç ”ç©¶ç›®å‰æ­£å¤„äºè¿›å±•é˜¶æ®µï¼Œä¸»è¦æ¢è®¨åŸºäºè·ç¦»çš„æƒŠå¥‡å€¼æ˜¯å¦èƒ½å»¶ç»­å…³äºè¯­æ³•é€šè¿‡æ ‘çŠ¶ç»“æ„æœ€å°åŒ–è‡ªç”±èƒ½çš„ç›¸å…³ç§‘å­¦å‘ç°ã€‚è¿™é¡¹å·¥ä½œä¸ºç†è§£å¤æ‚å›¾ç»“æ„ä¸­çš„è®¤çŸ¥æ¨ç†è¿‡ç¨‹æä¾›äº†è·¨å­¦ç§‘çš„ç†è®ºæ”¯æ’‘ã€‚",
      "categories": [
        "cs.AI"
      ],
      "primary_category": "cs.AI",
      "comment": "Accepted to NORA Workshop at NeurIPS 2025",
      "pdf_url": "https://arxiv.org/pdf/2512.01878v1",
      "published_date": "2025-12-01 16:59:28 UTC",
      "updated_date": "2025-12-01 16:59:28 UTC",
      "processing_status": "completed",
      "attempts": 1,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "llm_backup_calls": 0,
      "last_update": "2026-01-26T12:28:01.635246+00:00"
    },
    {
      "arxiv_id": "2512.01870v1",
      "title": "Testing Transformer Learnability on the Arithmetic Sequence of Rooted Trees",
      "title_zh": "æµ‹è¯• Transformer åœ¨æœ‰æ ¹æ ‘ç®—æœ¯åºåˆ—ä¸Šçš„å¯å­¦ä¹ æ€§",
      "authors": [
        "Alessandro Breccia",
        "Federica Gerace",
        "Marco Lippi",
        "Gabriele Sicuro",
        "Pierluigi Contucci"
      ],
      "abstract": "We study whether a Large Language Model can learn the deterministic sequence of trees generated by the iterated prime factorization of the natural numbers. Each integer is mapped into a rooted planar tree and the resulting sequence $ \\mathbb{N}\\mathcal{T}$ defines an arithmetic text with measurable statistical structure. A transformer network (the GPT-2 architecture) is trained from scratch on the first $10^{11}$ elements to subsequently test its predictive ability under next-word and masked-word prediction tasks. Our results show that the model partially learns the internal grammar of $\\mathbb{N}\\mathcal{T}$, capturing non-trivial regularities and correlations. This suggests that learnability may extend beyond empirical data to the very structure of arithmetic.",
      "tldr_zh": "è¯¥ç ”ç©¶æ¢è®¨äº†å¤§å‹è¯­è¨€æ¨¡å‹(Large Language Model)æ˜¯å¦èƒ½å¤Ÿå­¦ä¹ ç”±è‡ªç„¶æ•°è¿­ä»£ç´ å› æ•°åˆ†è§£ç”Ÿæˆçš„ç¡®å®šæ€§æ ‘åºåˆ—ã€‚ç ”ç©¶äººå‘˜å°†æ¯ä¸ªæ•´æ•°æ˜ å°„ä¸ºæœ‰æ ¹å¹³é¢æ ‘(Rooted planar tree)ï¼Œä»è€Œæ„å»ºå‡ºå…·æœ‰å¯æµ‹é‡ç»Ÿè®¡ç»“æ„çš„ç®—æœ¯åºåˆ— $\\mathbb{N}\\mathcal{T}$ã€‚å®éªŒé‡‡ç”¨ä»é›¶å¼€å§‹è®­ç»ƒçš„ GPT-2 æ¶æ„æ¨¡å‹ï¼Œåœ¨åºåˆ—çš„å‰ $10^{11}$ ä¸ªå…ƒç´ ä¸Šè¿›è¡Œå­¦ä¹ ï¼Œå¹¶éšåé€šè¿‡ä¸‹ä¸€è¯é¢„æµ‹(Next-word prediction)å’Œæ©ç é¢„æµ‹(Masked-word prediction)ä»»åŠ¡æµ‹è¯•å…¶æ€§èƒ½ã€‚ç»“æœè¡¨æ˜ï¼Œæ¨¡å‹èƒ½å¤Ÿéƒ¨åˆ†å­¦ä¹  $\\mathbb{N}\\mathcal{T}$ çš„å†…éƒ¨è¯­æ³•(Internal grammar)ï¼ŒæˆåŠŸæ•æ‰åˆ°åºåˆ—ä¸­çš„éå¹³å‡¡è§„å¾‹ä¸ç›¸å…³æ€§ã€‚è¯¥å‘ç°æš—ç¤ºäº† Transformer æ¶æ„çš„å­¦ä¹ èƒ½åŠ›ä¸ä»…å±€é™äºç»éªŒæ€§æ•°æ®ï¼Œè¿˜èƒ½å»¶ä¼¸è‡³ç®—æœ¯æœ¬èº«çš„ç»“æ„åŒ–è§„å¾‹ä¹‹ä¸­ã€‚",
      "categories": [
        "cs.AI",
        "cond-mat.dis-nn",
        "math-ph",
        "math.NT"
      ],
      "primary_category": "cs.AI",
      "comment": "21 pages, 8 figures",
      "pdf_url": "https://arxiv.org/pdf/2512.01870v1",
      "published_date": "2025-12-01 16:51:38 UTC",
      "updated_date": "2025-12-01 16:51:38 UTC",
      "processing_status": "completed",
      "attempts": 1,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "llm_backup_calls": 0,
      "last_update": "2026-01-26T12:28:13.331554+00:00"
    },
    {
      "arxiv_id": "2512.01865v1",
      "title": "Cross-Lingual Interleaving for Speech Language Models",
      "title_zh": "è¯­éŸ³è¯­è¨€æ¨¡å‹çš„è·¨è¯­è¨€äº¤ç»‡",
      "authors": [
        "Adel Moumen",
        "Guangzhi Sun",
        "Philip C. Woodland"
      ],
      "abstract": "Spoken Language Models (SLMs) aim to learn linguistic competence directly from speech using discrete units, widening access to Natural Language Processing (NLP) technologies for languages with limited written resources. However, progress has been largely English-centric due to scarce spoken evaluation benchmarks and training data, making cross-lingual learning difficult. We present a cross-lingual interleaving method that mixes speech tokens across languages without textual supervision. We also release an EN-FR training dataset, TinyStories (~42k hours), together with EN-FR spoken StoryCloze and TopicCloze benchmarks for cross-lingual semantic evaluation, both synthetically generated using GPT-4. On 360M and 1B SLMs under matched training-token budgets, interleaving improves monolingual semantic accuracy, enables robust cross-lingual continuation, and strengthens cross-lingual hidden-state alignment. Taken together, these results indicate that cross-lingual interleaving is a simple, scalable route to building multilingual SLMs that understand and converse across languages. All resources will be made open-source to support reproducibility.",
      "tldr_zh": "è¯¥ç ”ç©¶é’ˆå¯¹è¯­éŸ³è¯­è¨€æ¨¡å‹(SLMs)è¿‡åº¦ä¾èµ–è‹±è¯­ä¸”ç¼ºä¹è·¨è¯­è¨€å­¦ä¹ èƒ½åŠ›çš„é—®é¢˜ï¼Œæå‡ºäº†ä¸€ç§åä¸ºCross-Lingual Interleavingçš„è·¨è¯­è¨€äº¤ç»‡æ–¹æ³•ã€‚è¯¥æ–¹æ³•åœ¨æ— éœ€æ–‡æœ¬ç›‘ç£çš„æƒ…å†µä¸‹ï¼Œé€šè¿‡åœ¨ä¸åŒè¯­è¨€é—´æ··åˆè¯­éŸ³ç¦»æ•£å•å…ƒ(Discrete Units)è¿›è¡Œè®­ç»ƒã€‚ç ”ç©¶å›¢é˜ŸåŒæ­¥å‘å¸ƒäº†åŒ…å«çº¦4.2ä¸‡å°æ—¶è¯­éŸ³çš„EN-FRæ•°æ®é›†TinyStoriesï¼Œä»¥åŠç”¨äºè·¨è¯­è¨€è¯­ä¹‰è¯„ä¼°çš„StoryClozeå’ŒTopicClozeåŸºå‡†æµ‹è¯•é›†ã€‚åœ¨360Må’Œ1Bå‚æ•°è§„æ¨¡çš„SLMsä¸Šè¿›è¡Œçš„å®éªŒç»“æœè¡¨æ˜ï¼Œäº¤ç»‡è®­ç»ƒä¸ä»…æ˜¾è‘—æå‡äº†å•è¯­è¯­ä¹‰å‡†ç¡®åº¦ï¼Œè¿˜å®ç°äº†é²æ£’çš„è·¨è¯­è¨€ç»­å†™èƒ½åŠ›ã€‚æ­¤å¤–ï¼Œè¯¥æ–¹æ³•æœ‰æ•ˆå¢å¼ºäº†è·¨è¯­è¨€éšè—çŠ¶æ€å¯¹é½(Hidden-state Alignment)ï¼Œè¯æ˜äº†Cross-Lingual Interleavingæ˜¯æ„å»ºå…·å¤‡å¤šè¯­ç§ç†è§£å’Œå¯¹è¯èƒ½åŠ›æ¨¡å‹çš„ä¸€ç§ç®€å•ä¸”å¯æ‰©å±•çš„é€”å¾„ã€‚",
      "categories": [
        "cs.CL",
        "cs.AI"
      ],
      "primary_category": "cs.CL",
      "comment": "",
      "pdf_url": "https://arxiv.org/pdf/2512.01865v1",
      "published_date": "2025-12-01 16:48:05 UTC",
      "updated_date": "2025-12-01 16:48:05 UTC",
      "processing_status": "completed",
      "attempts": 1,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "llm_backup_calls": 0,
      "last_update": "2026-01-26T12:28:00.236601+00:00"
    },
    {
      "arxiv_id": "2512.01863v1",
      "title": "Topological Order in Deep State",
      "title_zh": "æ·±åº¦æ€ä¸­çš„æ‹“æ‰‘åº",
      "authors": [
        "Ahmed Abouelkomsan",
        "Max Geier",
        "Liang Fu"
      ],
      "abstract": "Topologically ordered states are among the most interesting quantum phases of matter that host emergent quasi-particles having fractional charge and obeying fractional quantum statistics. Theoretical study of such states is however challenging owing to their strong-coupling nature that prevents conventional mean-field treatment. Here, we demonstrate that an attention-based deep neural network provides an expressive variational wavefunction that discovers fractional Chern insulator ground states purely through energy minimization without prior knowledge and achieves remarkable accuracy. We introduce an efficient method to extract ground state topological degeneracy -- a hallmark of topological order -- from a single optimized real-space wavefunction in translation-invariant systems by decomposing it into different many-body momentum sectors. Our results establish neural network variational Monte Carlo as a versatile tool for discovering strongly correlated topological phases.",
      "tldr_zh": "è¯¥ç ”ç©¶æ¢è®¨äº†æ‹“æ‰‘åºçŠ¶æ€ï¼ˆTopologically ordered statesï¼‰è¿™ä¸€å…·æœ‰å¼ºè€¦åˆæ€§è´¨çš„é‡å­ç‰©è´¨ç›¸ï¼Œé’ˆå¯¹ä¼ ç»Ÿå¹³å‡åœºå¤„ç†æ–¹æ³•çš„å±€é™æ€§ï¼Œæå‡ºåˆ©ç”¨åŸºäºæ³¨æ„åŠ›æœºåˆ¶ï¼ˆattention-basedï¼‰çš„æ·±åº¦ç¥ç»ç½‘ç»œæ„å»ºé«˜è¡¨è¾¾èƒ½åŠ›çš„å˜åˆ†æ³¢å‡½æ•°ï¼ˆvariational wavefunctionï¼‰ã€‚è¯¥æ–¹æ³•èƒ½å¤Ÿåœ¨æ— å…ˆéªŒçŸ¥è¯†çš„æƒ…å†µä¸‹ï¼Œä»…é€šè¿‡èƒ½é‡æœ€å°åŒ–å‡†ç¡®å‘ç°åˆ†æ•°é™ˆç»ç¼˜ä½“ï¼ˆfractional Chern insulatorï¼‰åŸºæ€ã€‚ç ”ç©¶è¿›ä¸€æ­¥å¼•å…¥äº†ä¸€ç§é«˜æ•ˆæŠ€æœ¯ï¼Œé€šè¿‡å°†å¹³ç§»ä¸å˜ç³»ç»Ÿä¸­çš„å®ç©ºé—´æ³¢å‡½æ•°åˆ†è§£ä¸ºä¸åŒçš„å¤šä½“åŠ¨é‡æ‰‡åŒºï¼Œä»è€Œæå–ä½œä¸ºæ‹“æ‰‘åºæ ‡å¿—çš„åŸºæ€æ‹“æ‰‘ç®€å¹¶ï¼ˆtopological degeneracyï¼‰ã€‚å®éªŒç»“æœè¡¨æ˜è¯¥æ–¹æ¡ˆå…·æœ‰æé«˜çš„ç²¾åº¦ï¼Œè¯æ˜äº†ç¥ç»ç½‘ç»œå˜åˆ†è’™ç‰¹å¡æ´›ï¼ˆneural network variational Monte Carloï¼‰æ˜¯æ¢ç´¢å¼ºå…³è”æ‹“æ‰‘ç›¸çš„æœ‰åŠ›å·¥å…·ã€‚",
      "categories": [
        "cond-mat.mes-hall",
        "cond-mat.str-el",
        "cs.AI"
      ],
      "primary_category": "cond-mat.mes-hall",
      "comment": "5 pages + 6 SM",
      "pdf_url": "https://arxiv.org/pdf/2512.01863v1",
      "published_date": "2025-12-01 16:46:39 UTC",
      "updated_date": "2025-12-01 16:46:39 UTC",
      "processing_status": "completed",
      "attempts": 1,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "llm_backup_calls": 0,
      "last_update": "2026-01-26T12:28:17.047564+00:00"
    },
    {
      "arxiv_id": "2512.01852v1",
      "title": "BHRAM-IL: A Benchmark for Hallucination Recognition and Assessment in Multiple Indian Languages",
      "title_zh": "BHRAM-ILï¼šå¤šç§å°åº¦è¯­è¨€å¹»è§‰è¯†åˆ«ä¸è¯„ä¼°åŸºå‡†",
      "authors": [
        "Hrishikesh Terdalkar",
        "Kirtan Bhojani",
        "Aryan Dongare",
        "Omm Aditya Behera"
      ],
      "abstract": "Large language models (LLMs) are increasingly deployed in multilingual applications but often generate plausible yet incorrect or misleading outputs, known as hallucinations. While hallucination detection has been studied extensively in English, under-resourced Indian languages remain largely unexplored. We present BHRAM-IL, a benchmark for hallucination recognition and assessment in multiple Indian languages, covering Hindi, Gujarati, Marathi, Odia, along with English. The benchmark comprises 36,047 curated questions across nine categories spanning factual, numerical, reasoning, and linguistic tasks. We evaluate 14 state-of-the-art multilingual LLMs on a benchmark subset of 10,265 questions, analyzing cross-lingual and factual hallucinations across languages, models, scales, categories, and domains using category-specific metrics normalized to (0,1) range. Aggregation over all categories and models yields a primary score of 0.23 and a language-corrected fuzzy score of 0.385, demonstrating the usefulness of BHRAM-IL for hallucination-focused evaluation. The dataset, and the code for generation and evaluation are available on GitHub (https://github.com/sambhashana/BHRAM-IL/) and HuggingFace (https://huggingface.co/datasets/sambhashana/BHRAM-IL/) to support future research in multilingual hallucination detection and mitigation.",
      "tldr_zh": "è¯¥ç ”ç©¶æ¨å‡ºäº†BHRAM-ILï¼Œè¿™æ˜¯ä¸€ä¸ªä¸“é—¨ç”¨äºå¤šç§å°åº¦è¯­è¨€å¹»è§‰ (Hallucination) è¯†åˆ«ä¸è¯„ä¼°çš„åŸºå‡†æµ‹è¯•é›†ï¼Œæ—¨åœ¨è§£å†³å¤§å‹è¯­è¨€æ¨¡å‹ (LLMs) åœ¨èµ„æºåŒ®ä¹çš„å°åº¦è¯­è¨€ä¸­äº§ç”Ÿé”™è¯¯æˆ–è¯¯å¯¼æ€§è¾“å‡ºçš„é—®é¢˜ã€‚è¯¥åŸºå‡†æ¶µç›–äº†å°åœ°è¯­ (Hindi)ã€å¤å‰æ‹‰ç‰¹è¯­ (Gujarati)ã€é©¬æ‹‰åœ°è¯­ (Marathi)ã€å¥¥é‡Œäºšè¯­ (Odia) ä»¥åŠè‹±è¯­ï¼ŒåŒ…å«36,047ä¸ªè·¨è¶Šäº‹å®ã€æ•°å€¼ã€æ¨ç†å’Œè¯­è¨€ç­‰ä¹ä¸ªç±»åˆ«çš„ç²¾é€‰é—®é¢˜ã€‚ç ”ç©¶äººå‘˜åœ¨ç”±10,265ä¸ªé—®é¢˜ç»„æˆçš„å­é›†ä¸Šè¯„ä¼°äº†14ç§æœ€å…ˆè¿›çš„å¤šè¯­è¨€ LLMsï¼Œå¹¶åˆ©ç”¨å½’ä¸€åŒ–æŒ‡æ ‡åˆ†æäº†ä¸åŒè¯­è¨€ã€æ¨¡å‹è§„æ¨¡å’Œé¢†åŸŸä¸‹çš„è·¨è¯­è¨€åŠäº‹å®å¹»è§‰ã€‚å®éªŒç»“æœæ˜¾ç¤ºï¼Œæ‰€æœ‰ç±»åˆ«å’Œæ¨¡å‹çš„ç»¼åˆå¾—åˆ†ä¸º0.23ï¼Œè¯­è¨€æ ¡æ­£æ¨¡ç³Šå¾—åˆ†ä¸º0.385ï¼Œå……åˆ†éªŒè¯äº† BHRAM-IL åœ¨å¹»è§‰èšç„¦è¯„ä¼°ä¸­çš„å®ç”¨ä»·å€¼ã€‚ç›®å‰ï¼Œè¯¥æ•°æ®é›†åŠå…¶ç”Ÿæˆä¸è¯„ä¼°ä»£ç å·²åœ¨ GitHub å’Œ HuggingFace ä¸Šå¼€æºï¼Œä¸ºæœªæ¥å¤šè¯­è¨€å¹»è§‰æ£€æµ‹ä¸ç¼“è§£çš„ç ”ç©¶å¥ å®šäº†åŸºç¡€ã€‚",
      "categories": [
        "cs.CL",
        "cs.AI",
        "cs.ET"
      ],
      "primary_category": "cs.CL",
      "comment": "Accepted at BHASHA Workshop @ IJCNLP/AACL 2025",
      "pdf_url": "https://arxiv.org/pdf/2512.01852v1",
      "published_date": "2025-12-01 16:37:34 UTC",
      "updated_date": "2025-12-01 16:37:34 UTC",
      "processing_status": "completed",
      "attempts": 1,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "llm_backup_calls": 0,
      "last_update": "2026-01-26T12:28:18.839374+00:00"
    },
    {
      "arxiv_id": "2512.03099v1",
      "title": "QGShap: Quantum Acceleration for Faithful GNN Explanations",
      "title_zh": "QGShapï¼šé¢å‘å›¾ç¥ç»ç½‘ç»œå¿ å®è§£é‡Šçš„é‡å­åŠ é€Ÿ",
      "authors": [
        "Haribandhu Jena",
        "Jyotirmaya Shivottam",
        "Subhankar Mishra"
      ],
      "abstract": "Graph Neural Networks (GNNs) have become indispensable in critical domains such as drug discovery, social network analysis, and recommendation systems, yet their black-box nature hinders deployment in scenarios requiring transparency and accountability. While Shapley value-based methods offer mathematically principled explanations by quantifying each component's contribution to predictions, computing exact values requires evaluating $2^n$ coalitions (or aggregating over $n!$ permutations), which is intractable for real-world graphs. Existing approximation strategies sacrifice either fidelity or efficiency, limiting their practical utility. We introduce QGShap, a quantum computing approach that leverages amplitude amplification to achieve quadratic speedups in coalition evaluation while maintaining exact Shapley computation. Unlike classical sampling or surrogate methods, our approach provides fully faithful explanations without approximation trade-offs for tractable graph sizes. We conduct empirical evaluations on synthetic graph datasets, demonstrating that QGShap achieves consistently high fidelity and explanation accuracy, matching or exceeding the performance of classical methods across all evaluation metrics. These results collectively demonstrate that QGShap not only preserves exact Shapley faithfulness but also delivers interpretable, stable, and structurally consistent explanations that align with the underlying graph reasoning of GNNs. The implementation of QGShap is available at https://github.com/smlab-niser/qgshap.",
      "tldr_zh": "è¯¥ç ”ç©¶æå‡ºäº† QGShapï¼Œä¸€ç§æ—¨åœ¨åŠ é€Ÿå›¾ç¥ç»ç½‘ç»œ (GNNs) ç²¾ç¡®è§£é‡Šçš„é‡å­è®¡ç®—æ¡†æ¶ï¼Œä»¥è§£å†³ Shapley value è®¡ç®—ä¸­é¢ä¸´çš„æŒ‡æ•°çº§å¤æ‚åº¦éš¾é¢˜ã€‚é€šè¿‡åˆ©ç”¨é‡å­æŒ¯å¹…æ”¾å¤§ (amplitude amplification) æŠ€æœ¯ï¼ŒQGShap åœ¨ä¿æŒå®Œå…¨å¿ å®åº¦ (faithfulness) çš„å‰æä¸‹å®ç°äº†äºŒæ¬¡åŠ é€Ÿ (quadratic speedups)ï¼Œæœ‰æ•ˆå…‹æœäº†ä¼ ç»Ÿè¿‘ä¼¼æ–¹æ³•åœ¨æ•ˆç‡ä¸ä¿çœŸåº¦ä¹‹é—´çš„æƒè¡¡ã€‚å®éªŒç»“æœæ˜¾ç¤ºï¼ŒQGShap åœ¨åˆæˆæ•°æ®é›†ä¸Šçš„å¿ å®åº¦å’Œå‡†ç¡®ç‡è¡¨ç°ä¼˜å¼‚ï¼Œä¸ä»…èƒ½æä¾›ä¸ç»å…¸ç²¾ç¡®è®¡ç®—ä¸€è‡´çš„ç»“æœï¼Œä¸”åœ¨æ•ˆç‡ä¸Šæ›´å…·å®ç”¨æ€§ã€‚è¯¥æ–¹æ³•ä¸ºå…³é”®é¢†åŸŸä¸­çš„ GNNs æ¨¡å‹æä¾›äº†ç¨³å®šä¸”ç»“æ„ä¸€è‡´çš„è§£é‡Šæ–¹æ¡ˆï¼Œæ˜¾è‘—å¢å¼ºäº†æ·±åº¦å­¦ä¹ æ¨¡å‹åœ¨å®é™…åº”ç”¨ä¸­çš„é€æ˜åº¦ä¸å¯ä¿¡åº¦ã€‚",
      "categories": [
        "quant-ph",
        "cs.AI",
        "cs.LG"
      ],
      "primary_category": "quant-ph",
      "comment": "Accepted in the QC+AI Workshop at AAAI 2026",
      "pdf_url": "https://arxiv.org/pdf/2512.03099v1",
      "published_date": "2025-12-01 16:19:15 UTC",
      "updated_date": "2025-12-01 16:19:15 UTC",
      "processing_status": "completed",
      "attempts": 1,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "llm_backup_calls": 0,
      "last_update": "2026-01-26T12:28:19.232677+00:00"
    },
    {
      "arxiv_id": "2512.01834v1",
      "title": "Mitigating Gender Bias in Depression Detection via Counterfactual Inference",
      "title_zh": "åŸºäºåäº‹å®æ¨ç†ç¼“è§£æŠ‘éƒæ£€æµ‹ä¸­çš„æ€§åˆ«åè§",
      "authors": [
        "Mingxuan Hu",
        "Hongbo Ma",
        "Xinlan Wu",
        "Ziqi Liu",
        "Jiaqi Liu",
        "Yangbin Chen"
      ],
      "abstract": "Audio-based depression detection models have demonstrated promising performance but often suffer from gender bias due to imbalanced training data. Epidemiological statistics show a higher prevalence of depression in females, leading models to learn spurious correlations between gender and depression. Consequently, models tend to over-diagnose female patients while underperforming on male patients, raising significant fairness concerns. To address this, we propose a novel Counterfactual Debiasing Framework grounded in causal inference. We construct a causal graph to model the decision-making process and identify gender bias as the direct causal effect of gender on the prediction. During inference, we employ counterfactual inference to estimate and subtract this direct effect, ensuring the model relies primarily on authentic acoustic pathological features. Extensive experiments on the DAIC-WOZ dataset using two advanced acoustic backbones demonstrate that our framework not only significantly reduces gender bias but also improves overall detection performance compared to existing debiasing strategies.",
      "tldr_zh": "è¯¥ç ”ç©¶é’ˆå¯¹åŸºäºéŸ³é¢‘çš„æŠ‘éƒç—‡æ£€æµ‹æ¨¡å‹ä¸­å­˜åœ¨çš„æ€§åˆ«åè§(Gender Bias)é—®é¢˜è¿›è¡Œäº†æ¢è®¨ï¼ŒæŒ‡å‡ºç”±äºè®­ç»ƒæ•°æ®ä¸­å¥³æ€§æŠ‘éƒç—‡æ‚£ç—…ç‡è¾ƒé«˜ï¼Œæ¨¡å‹å®¹æ˜“å­¦ä¹ åˆ°æ€§åˆ«ä¸æŠ‘éƒä¹‹é—´çš„ä¼ªç›¸å…³æ€§(Spurious Correlation)ã€‚è¿™ç§åè§å¯¼è‡´æ¨¡å‹å€¾å‘äºå¯¹å¥³æ€§æ‚£è€…è¿‡åº¦è¯Šæ–­ï¼Œè€Œåœ¨ç”·æ€§æ‚£è€…ä¸Šçš„è¡¨ç°åˆ™ä¸å°½å¦‚äººæ„ï¼Œå¼•å‘äº†ä¸¥é‡çš„å…¬å¹³æ€§(Fairness)ç–‘è™‘ã€‚ä¸ºæ­¤ï¼Œä½œè€…æå‡ºäº†ä¸€ç§åŸºäºå› æœæ¨ç†(Causal Inference)çš„æ–°å‹åäº‹å®å»åæ¡†æ¶(Counterfactual Debiasing Framework)ã€‚è¯¥æ¡†æ¶é€šè¿‡æ„å»ºå› æœå›¾(Causal Graph)æ¥æ¨¡æ‹Ÿå†³ç­–è¿‡ç¨‹ï¼Œå¹¶å°†æ€§åˆ«åè§è¯†åˆ«ä¸ºæ€§åˆ«å¯¹é¢„æµ‹ç»“æœçš„ç›´æ¥å› æœå½±å“ã€‚åœ¨æ¨ç†é˜¶æ®µï¼Œè¯¥æ–¹æ³•åˆ©ç”¨åäº‹å®æ¨ç†(Counterfactual Inference)æ¥ä¼°è®¡å¹¶å‡å»è¿™ç§ç›´æ¥å½±å“ï¼Œç¡®ä¿æ¨¡å‹ä¸»è¦ä¾èµ–äºçœŸå®çš„å£°å­¦ç—…ç†ç‰¹å¾(Acoustic Pathological Features)ã€‚åœ¨DAIC-WOZæ•°æ®é›†ä¸Šä½¿ç”¨ä¸¤ç§å…ˆè¿›å£°å­¦éª¨å¹²ç½‘ç»œè¿›è¡Œçš„å®éªŒè¡¨æ˜ï¼Œè¯¥æ¡†æ¶ä¸ä»…æ˜¾è‘—é™ä½äº†æ€§åˆ«åè§ï¼Œè€Œä¸”ä¸ç°æœ‰çš„å»åç­–ç•¥ç›¸æ¯”ï¼Œè¿˜æå‡äº†æ•´ä½“æ£€æµ‹æ€§èƒ½ã€‚",
      "categories": [
        "cs.LG",
        "cs.AI",
        "cs.CY"
      ],
      "primary_category": "cs.LG",
      "comment": "",
      "pdf_url": "https://arxiv.org/pdf/2512.01834v1",
      "published_date": "2025-12-01 16:14:20 UTC",
      "updated_date": "2025-12-01 16:14:20 UTC",
      "processing_status": "completed",
      "attempts": 1,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "llm_backup_calls": 0,
      "last_update": "2026-01-26T12:28:40.140713+00:00"
    },
    {
      "arxiv_id": "2512.01831v1",
      "title": "Deconstructing Generative Diversity: An Information Bottleneck Analysis of Discrete Latent Generative Models",
      "title_zh": "è§£æ„ç”Ÿæˆå¤šæ ·æ€§ï¼šç¦»æ•£æ½œå˜é‡ç”Ÿæˆæ¨¡å‹çš„ä¿¡æ¯ç“¶é¢ˆåˆ†æ",
      "authors": [
        "Yudi Wu",
        "Wenhao Zhao",
        "Dianbo Liu"
      ],
      "abstract": "Generative diversity varies significantly across discrete latent generative models such as AR, MIM, and Diffusion. We propose a diagnostic framework, grounded in Information Bottleneck (IB) theory, to analyze the underlying strategies resolving this behavior. The framework models generation as a conflict between a 'Compression Pressure' - a drive to minimize overall codebook entropy - and a 'Diversity Pressure' - a drive to maximize conditional entropy given an input. We further decompose this diversity into two primary sources: 'Path Diversity', representing the choice of high-level generative strategies, and 'Execution Diversity', the randomness in executing a chosen strategy. To make this decomposition operational, we introduce three zero-shot, inference-time interventions that directly perturb the latent generative process and reveal how models allocate and express diversity. Application of this probe-based framework to representative AR, MIM, and Diffusion systems reveals three distinct strategies: \"Diversity-Prioritized\" (MIM), \"Compression-Prioritized\" (AR), and \"Decoupled\" (Diffusion). Our analysis provides a principled explanation for their behavioral differences and informs a novel inference-time diversity enhancement technique.",
      "tldr_zh": "è¯¥ç ”ç©¶æå‡ºäº†ä¸€ä¸ªåŸºäºä¿¡æ¯ç“¶é¢ˆ(Information Bottleneck, IB)ç†è®ºçš„è¯Šæ–­æ¡†æ¶ï¼Œæ—¨åœ¨æ·±å…¥åˆ†æARã€MIMå’ŒDiffusionç­‰ç¦»æ•£æ½œå˜é‡ç”Ÿæˆæ¨¡å‹åœ¨ç”Ÿæˆå¤šæ ·æ€§ä¸Šçš„è¡¨ç°å·®å¼‚ã€‚è¯¥æ¡†æ¶å°†ç”Ÿæˆè¿‡ç¨‹è§†ä¸ºâ€œå‹ç¼©å‹åŠ›â€(Compression Pressure)ä¸â€œå¤šæ ·æ€§å‹åŠ›â€(Diversity Pressure)ä¹‹é—´çš„æƒè¡¡ï¼Œå¹¶å°†å¤šæ ·æ€§è¿›ä¸€æ­¥åˆ†è§£ä¸ºä»£è¡¨é«˜å±‚ç­–ç•¥é€‰æ‹©çš„â€œè·¯å¾„å¤šæ ·æ€§â€(Path Diversity)å’Œä»£è¡¨éšæœºæ‰§è¡Œçš„â€œæ‰§è¡Œå¤šæ ·æ€§â€(Execution Diversity)ã€‚ç ”ç©¶è€…é€šè¿‡å¼•å…¥ä¸‰ç§é›¶æ ·æœ¬æ¨ç†æ—¶é—´å¹²é¢„æ‰‹æ®µï¼Œæ­ç¤ºäº†MIMã€ARå’ŒDiffusionæ¨¡å‹åˆ†åˆ«é‡‡ç”¨â€œå¤šæ ·æ€§ä¼˜å…ˆâ€(Diversity-Prioritized)ã€â€œå‹ç¼©ä¼˜å…ˆâ€(Compression-Prioritized)å’Œâ€œè§£è€¦â€(Decoupled)ä¸‰ç§æˆªç„¶ä¸åŒçš„ç­–ç•¥æ¨¡å¼ã€‚è¿™é¡¹åˆ†æä¸ä»…ä¸ºä¸åŒæ¨¡å‹æ¶æ„é—´çš„è¡Œä¸ºå·®å¼‚æä¾›äº†åŸç†è§£é‡Šï¼Œè¿˜æ®æ­¤å¼€å‘å‡ºä¸€ç§å…¨æ–°çš„æ¨ç†æ—¶é—´å¤šæ ·æ€§å¢å¼ºæŠ€æœ¯ã€‚",
      "categories": [
        "cs.LG",
        "cs.AI"
      ],
      "primary_category": "cs.LG",
      "comment": "",
      "pdf_url": "https://arxiv.org/pdf/2512.01831v1",
      "published_date": "2025-12-01 16:13:23 UTC",
      "updated_date": "2025-12-01 16:13:23 UTC",
      "processing_status": "completed",
      "attempts": 1,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "llm_backup_calls": 0,
      "last_update": "2026-01-26T12:29:18.368433+00:00"
    },
    {
      "arxiv_id": "2512.01822v1",
      "title": "InnoGym: Benchmarking the Innovation Potential of AI Agents",
      "title_zh": "InnoGymï¼šè¯„ä¼° AI æ™ºèƒ½ä½“åˆ›æ–°æ½œåŠ›çš„åŸºå‡†æµ‹è¯•",
      "authors": [
        "Jintian Zhang",
        "Kewei Xu",
        "Jingsheng Zheng",
        "Zhuoyun Yu",
        "Yuqi Zhu",
        "Yujie Luo",
        "Lanning Wei",
        "Shuofei Qiao",
        "Lun Du",
        "Da Zheng",
        "Shumin Deng",
        "Huajun Chen",
        "Ningyu Zhang"
      ],
      "abstract": "LLMs and Agents have achieved impressive progress in code generation, mathematical reasoning, and scientific discovery. However, existing benchmarks primarily measure correctness, overlooking the diversity of methods behind solutions. True innovation depends not only on producing correct answers but also on the originality of the approach. We present InnoGym, the first benchmark and framework designed to systematically evaluate the innovation potential of AI agents. InnoGym introduces two complementary metrics: performance gain, which measures improvement over the best-known solutions, and novelty, which captures methodological differences from prior approaches. The benchmark includes 18 carefully curated tasks from real-world engineering and scientific domains, each standardized through resource filtering, evaluator validation, and solution collection. In addition, we provide iGym, a unified execution environment for reproducible and long-horizon evaluations. Extensive experiments show that while some agents produce novel approaches, their lack of robustness limits performance gains. These results highlight a key gap between creativity and effectiveness, underscoring the need for benchmarks that evaluate both.",
      "tldr_zh": "è¯¥ç ”ç©¶æ¨å‡ºäº† InnoGymï¼Œè¿™æ˜¯é¦–ä¸ªç³»ç»Ÿè¯„ä¼° AI Agents åˆ›æ–°æ½œåŠ›çš„åŸºå‡†æµ‹è¯•å’Œæ¡†æ¶ï¼Œæ—¨åœ¨è§£å†³ç°æœ‰è¯„æµ‹ä½“ç³»è¿‡åº¦å…³æ³¨æ­£ç¡®æ€§è€Œå¿½è§†æ–¹æ³•å¤šæ ·æ€§ä¸åŸåˆ›æ€§çš„é—®é¢˜ã€‚InnoGym å¼•å…¥äº†ä¸¤ä¸ªäº’è¡¥çš„åº¦é‡æŒ‡æ ‡ï¼šè¡¡é‡ç›¸è¾ƒäºå·²çŸ¥æœ€ä¼˜è§£æå‡ç¨‹åº¦çš„ Performance Gainï¼Œä»¥åŠæ•æ‰æ–¹æ³•è®ºä¸Šä¸å…ˆå‰æ–¹æ¡ˆå·®å¼‚çš„ Noveltyã€‚è¯¥åŸºå‡†æ¶µç›–äº†æ¥è‡ªçœŸå®ä¸–ç•Œå·¥ç¨‹å’Œç§‘å­¦é¢†åŸŸçš„ 18 ä¸ªç²¾å¿ƒè®¾è®¡çš„ä»»åŠ¡ï¼Œå¹¶é€šè¿‡èµ„æºè¿‡æ»¤ã€è¯„ä¼°å™¨éªŒè¯å’Œæ–¹æ¡ˆæ”¶é›†å®ç°äº†æ ‡å‡†åŒ–ã€‚æ­¤å¤–ï¼Œç ”ç©¶å›¢é˜Ÿæä¾›äº† iGym ç»Ÿä¸€æ‰§è¡Œç¯å¢ƒï¼Œä»¥æ”¯æŒå¯é‡ç°çš„é•¿ç¨‹è¯„ä¼°ã€‚å®éªŒå‘ç°ï¼Œè™½ç„¶éƒ¨åˆ†æ™ºèƒ½ä½“è¡¨ç°å‡ºäº†æ–¹æ³•çš„æ–°é¢–æ€§ï¼Œä½†å› å…¶ç¼ºä¹é²æ£’æ€§é™åˆ¶äº†æœ€ç»ˆçš„ Performance Gainã€‚è¿™é¡¹å·¥ä½œæ­ç¤ºäº† AI åœ¨åˆ›é€ åŠ›ä¸æœ‰æ•ˆæ€§ä¹‹é—´çš„å…³é”®å·®è·ï¼Œå¼ºè°ƒäº†åŒæ—¶è¯„ä¼°è¿™ä¸¤é¡¹æŒ‡æ ‡å¯¹äºæ¨åŠ¨äººå·¥æ™ºèƒ½é¢†åŸŸè‡ªä¸»åˆ›æ–°ç ”ç©¶çš„é‡è¦æ€§ã€‚",
      "categories": [
        "cs.CL",
        "cs.AI",
        "cs.CV",
        "cs.LG",
        "cs.MA"
      ],
      "primary_category": "cs.CL",
      "comment": "Work in progress",
      "pdf_url": "https://arxiv.org/pdf/2512.01822v1",
      "published_date": "2025-12-01 16:03:04 UTC",
      "updated_date": "2025-12-01 16:03:04 UTC",
      "processing_status": "completed",
      "attempts": 1,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "llm_backup_calls": 0,
      "last_update": "2026-01-26T12:29:07.336660+00:00"
    },
    {
      "arxiv_id": "2512.01816v1",
      "title": "Envision: Benchmarking Unified Understanding & Generation for Causal World Process Insights",
      "title_zh": "Envisionï¼šé¢å‘ä¸–ç•Œå› æœè¿‡ç¨‹æ´å¯Ÿçš„ç»Ÿä¸€ç†è§£ä¸ç”Ÿæˆè¯„æµ‹åŸºå‡†",
      "authors": [
        "Juanxi Tian",
        "Siyuan Li",
        "Conghui He",
        "Lijun Wu",
        "Cheng Tan"
      ],
      "abstract": "Current multimodal models aim to transcend the limitations of single-modality representations by unifying understanding and generation, often using text-to-image (T2I) tasks to calibrate semantic consistency. However, their reliance on static, single-image generation in training and evaluation leads to overfitting to static pattern matching and semantic fusion, while fundamentally hindering their ability to model dynamic processes that unfold over time. To address these constraints, we propose Envision-a causal event progression benchmark for chained text-to-multi-image generation. Grounded in world knowledge and structured by spatiotemporal causality, it reorganizes existing evaluation dimensions and includes 1,000 four-stage prompts spanning six scientific and humanities domains. To transition evaluation from single images to sequential frames and assess whether models truly internalize world knowledge while adhering to causal-temporal constraints, we introduce Envision-Score, a holistic metric integrating multi-dimensional consistency, physicality, and aesthetics. Comprehensive evaluation of 15 models (10 specialized T2I models, 5 unified models) uncovers: specialized T2I models demonstrate proficiency in aesthetic rendering yet lack intrinsic world knowledge. Unified multimodal models bridge this gap, consistently outperforming specialized counterparts in causal narrative coherence. However, even these unified architectures remain subordinate to closed-source models and struggle to overcome the core challenge of spatiotemporal consistency. This demonstrates that a focus on causally-isolated single images impedes multi-frame reasoning and generation, promoting static pattern matching over dynamic world modeling-ultimately limiting world knowledge internalization, generation.",
      "tldr_zh": "è¯¥ç ”ç©¶æå‡ºäº† Envisionï¼Œä¸€ä¸ªæ—¨åœ¨è¯„ä¼°å¤šæ¨¡æ€æ¨¡å‹å¯¹å› æœäº‹ä»¶è¿›å±•ç†è§£ä¸ç”Ÿæˆèƒ½åŠ›çš„åŸºå‡†æµ‹è¯•ï¼Œæ—¨åœ¨è§£å†³ç°æœ‰æ¨¡å‹è¿‡äºä¾èµ–é™æ€å•å›¾(single-image)ç”Ÿæˆè€Œå¿½è§†åŠ¨æ€è¿‡ç¨‹å»ºæ¨¡çš„é—®é¢˜ã€‚è¯¥åŸºå‡†æ¤æ ¹äºä¸–ç•ŒçŸ¥è¯†å¹¶ç”±æ—¶ç©ºå› æœé©±åŠ¨ï¼ŒåŒ…å«è·¨è¶Šç§‘å­¦ä¸äººæ–‡å…­ä¸ªé¢†åŸŸçš„ 1,000 ä¸ªå››é˜¶æ®µæç¤ºè¯ï¼Œå°†è¯„ä¼°ç»´åº¦ä»å­¤ç«‹çš„å•å›¾æ‰©å±•è‡³åºåˆ—å¸§ç”Ÿæˆã€‚ä¸ºäº†è¡¡é‡æ¨¡å‹æ˜¯å¦çœŸæ­£å†…åŒ–äº†ä¸–ç•ŒçŸ¥è¯†ï¼Œç ”ç©¶è€…åŒæ­¥å¼•å…¥äº† Envision-Score æŒ‡æ ‡ï¼Œç»¼åˆè€ƒå¯Ÿå¤šç»´ä¸€è‡´æ€§ã€ç‰©ç†æ€§åŠç¾å­¦è¡¨ç°ã€‚å¯¹ 15 ç§æ¨¡å‹çš„è¯„ä¼°å‘ç°ï¼Œä¸“ä¸š T2I æ¨¡å‹è™½å…·å¤‡å‡ºè‰²çš„ç¾å­¦æ¸²æŸ“èƒ½åŠ›ï¼Œä½†æ™®éç¼ºä¹å†…åœ¨çš„ä¸–ç•ŒçŸ¥è¯†ã€‚ç»Ÿä¸€å¤šæ¨¡æ€æ¨¡å‹åœ¨å› æœå™äº‹è¿è´¯æ€§ä¸Šä¼˜äºä¸“ä¸šæ¨¡å‹ï¼Œä½†åœ¨åº”å¯¹æ—¶ç©ºä¸€è‡´æ€§(spatiotemporal consistency)è¿™ä¸€æ ¸å¿ƒæŒ‘æˆ˜æ—¶ä»é¢ä¸´å›°éš¾ï¼Œä¸”è¡¨ç°å°šæœªè¶…è¶Šé—­æºæ¨¡å‹ã€‚å®éªŒç»“è®ºæŒ‡å‡ºï¼Œä¸“æ³¨äºå› æœå­¤ç«‹çš„å•å›¾ç”Ÿæˆä¼šé˜»ç¢å¤šå¸§æ¨ç†ï¼Œå¯¼è‡´æ¨¡å‹å€¾å‘äºé™æ€æ¨¡å¼åŒ¹é…è€ŒéåŠ¨æ€ä¸–ç•Œå»ºæ¨¡ï¼Œä»è€Œé™åˆ¶äº†å¯¹ä¸–ç•ŒçŸ¥è¯†çš„å†…åŒ–ã€‚",
      "categories": [
        "cs.CV",
        "cs.AI"
      ],
      "primary_category": "cs.CV",
      "comment": "35 pages, 12 figures, 10 tables",
      "pdf_url": "https://arxiv.org/pdf/2512.01816v1",
      "published_date": "2025-12-01 15:52:31 UTC",
      "updated_date": "2025-12-01 15:52:31 UTC",
      "processing_status": "completed",
      "attempts": 1,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "llm_backup_calls": 0,
      "last_update": "2026-01-26T12:29:04.040651+00:00"
    },
    {
      "arxiv_id": "2512.01797v2",
      "title": "H-Neurons: On the Existence, Impact, and Origin of Hallucination-Associated Neurons in LLMs",
      "title_zh": "H-Neuronsï¼šå¤§è¯­è¨€æ¨¡å‹ä¸­å¹»è§‰ç›¸å…³ç¥ç»å…ƒçš„å­˜åœ¨ã€å½±å“åŠèµ·æº",
      "authors": [
        "Cheng Gao",
        "Huimin Chen",
        "Chaojun Xiao",
        "Zhiyi Chen",
        "Zhiyuan Liu",
        "Maosong Sun"
      ],
      "abstract": "Large language models (LLMs) frequently generate hallucinations -- plausible but factually incorrect outputs -- undermining their reliability. While prior work has examined hallucinations from macroscopic perspectives such as training data and objectives, the underlying neuron-level mechanisms remain largely unexplored. In this paper, we conduct a systematic investigation into hallucination-associated neurons (H-Neurons) in LLMs from three perspectives: identification, behavioral impact, and origins. Regarding their identification, we demonstrate that a remarkably sparse subset of neurons (less than $0.1\\%$ of total neurons) can reliably predict hallucination occurrences, with strong generalization across diverse scenarios. In terms of behavioral impact, controlled interventions reveal that these neurons are causally linked to over-compliance behaviors. Concerning their origins, we trace these neurons back to the pre-trained base models and find that these neurons remain predictive for hallucination detection, indicating they emerge during pre-training. Our findings bridge macroscopic behavioral patterns with microscopic neural mechanisms, offering insights for developing more reliable LLMs.",
      "tldr_zh": "è¯¥ç ”ç©¶ç³»ç»Ÿåœ°è°ƒæŸ¥äº†å¤§è¯­è¨€æ¨¡å‹(LLMs)ä¸­ä¸å¹»è§‰ç›¸å…³çš„ç¥ç»å…ƒï¼Œå³H-Neuronsï¼Œæ—¨åœ¨ä»å¾®è§‚ç¥ç»å…ƒå±‚é¢æ­ç¤ºå¹»è§‰çš„äº§ç”Ÿæœºåˆ¶ã€‚ç ”ç©¶äººå‘˜å‘ç°ï¼Œä»…å æ€»æ•°ä¸åˆ°0.1%çš„æå°‘æ•°ç¨€ç–ç¥ç»å…ƒå­é›†ä¾¿èƒ½å¯é åœ°é¢„æµ‹å¹»è§‰çš„å‘ç”Ÿï¼Œå¹¶åœ¨å¤šç§ä¸åŒåœºæ™¯ä¸‹å±•ç°å‡ºå¼ºå¤§çš„æ³›åŒ–èƒ½åŠ›ã€‚é€šè¿‡å—æ§å¹²é¢„å®éªŒï¼Œç ”ç©¶è¯æ˜äº†è¿™äº›H-Neuronsä¸æ¨¡å‹çš„è¿‡åº¦é¡ºä»(over-compliance)è¡Œä¸ºä¹‹é—´å­˜åœ¨å› æœè”ç³»ã€‚åœ¨è¿½æº¯å…¶èµ·æºæ—¶ï¼Œè¯¥ç ”ç©¶å‘ç°è¿™äº›ç¥ç»å…ƒåœ¨é¢„è®­ç»ƒåŸºåº§æ¨¡å‹(pre-trained base models)ä¸­å°±å·²ç»å­˜åœ¨å¹¶å…·å¤‡å¹»è§‰é¢„æµ‹èƒ½åŠ›ï¼Œè¡¨æ˜å…¶èµ·æºäºé¢„è®­ç»ƒé˜¶æ®µã€‚è¿™é¡¹å·¥ä½œæˆåŠŸåœ°åœ¨å®è§‚è¡Œä¸ºæ¨¡å¼ä¸å¾®è§‚ç¥ç»æœºåˆ¶ä¹‹é—´å»ºç«‹äº†è”ç³»ï¼Œä¸ºæœªæ¥å¼€å‘æ›´å¯é ã€æ›´å…·é²æ£’æ€§çš„LLMsæä¾›äº†å…³é”®çš„ç†è®ºä¾æ®ã€‚",
      "categories": [
        "cs.AI",
        "cs.CL",
        "cs.CY"
      ],
      "primary_category": "cs.AI",
      "comment": "20 pages, 4 figures",
      "pdf_url": "https://arxiv.org/pdf/2512.01797v2",
      "published_date": "2025-12-01 15:32:14 UTC",
      "updated_date": "2025-12-02 07:08:39 UTC",
      "processing_status": "completed",
      "attempts": 1,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "llm_backup_calls": 0,
      "last_update": "2026-01-26T12:29:04.232032+00:00"
    },
    {
      "arxiv_id": "2512.01786v1",
      "title": "Who Judges the Judge? LLM Jury-on-Demand: Building Trustworthy LLM Evaluation Systems",
      "title_zh": "è°æ¥è¯„åˆ¤è¯„åˆ¤è€…ï¼ŸLLM æŒ‰éœ€è¯„å®¡å›¢ï¼šæ„å»ºå¯ä¿¡çš„å¤§è¯­è¨€æ¨¡å‹è¯„ä¼°ç³»ç»Ÿ",
      "authors": [
        "Xiaochuan Li",
        "Ke Wang",
        "Girija Gouda",
        "Shubham Choudhary",
        "Yaqun Wang",
        "Linwei Hu",
        "Joel Vaughan",
        "Freddy Lecue"
      ],
      "abstract": "As Large Language Models (LLMs) become integrated into high-stakes domains, there is a growing need for evaluation methods that are both scalable for real-time deployment and reliable for critical decision-making. While human evaluation is reliable, it is slow and costly. Single LLM judges are biased, and static juries lack adaptability. To overcome these limitations, we propose LLM Jury-on-Demand - a dynamic, learning-based framework for scalable and context-aware evaluation. Our method trains a set of reliability predictors to assess when LLM judges will agree with human experts, leveraging token distributions, embeddings, and structural input features. This enables a fully adaptive evaluation where, for each data point, an optimal jury of the most reliable judges is dynamically selected, and their scores are aggregated using their reliability as weights. Experiments on summarization and RAG benchmarks show that our dynamic jury system achieves significantly higher correlation with human judgment than both single-judge and static-jury baselines. These results highlight the promise of adaptive, learning-based juries for building scalable, more reliable and trustworthy evaluation systems for modern LLMs in high-stakes domains.",
      "tldr_zh": "è¯¥ç ”ç©¶æå‡ºäº†LLM Jury-on-Demandï¼Œè¿™æ˜¯ä¸€ä¸ªåŠ¨æ€ã€åŸºäºå­¦ä¹ çš„æ¡†æ¶ï¼Œæ—¨åœ¨ä¸ºé«˜é£é™©é¢†åŸŸæ„å»ºå¯æ‰©å±•ä¸”å¯é çš„Large Language Models (LLMs)è¯„ä¼°ç³»ç»Ÿã€‚ä¸ºäº†è§£å†³å•ä¸€LLMè¯„å§”å­˜åœ¨çš„åå·®ä»¥åŠé™æ€é™ªå®¡å›¢ç¼ºä¹é€‚åº”æ€§çš„é—®é¢˜ï¼Œè¯¥æ–¹æ³•è®­ç»ƒäº†ä¸€ç»„å¯é æ€§é¢„æµ‹å™¨ï¼Œé€šè¿‡åˆ†ætoken distributionsã€embeddingså’Œç»“æ„åŒ–è¾“å…¥ç‰¹å¾æ¥é¢„æµ‹LLMè¯„å§”ä¸äººç±»ä¸“å®¶çš„ä¸€è‡´æ€§ã€‚åœ¨å®é™…è¯„ä¼°ä¸­ï¼Œè¯¥æ¡†æ¶èƒ½é’ˆå¯¹æ¯ä¸ªæ•°æ®ç‚¹åŠ¨æ€é€‰æ‹©æœ€å¯é çš„è¯„å§”ç»„æˆæœ€ä¼˜é™ªå®¡å›¢ï¼Œå¹¶ä»¥å¯é æ€§ä½œä¸ºæƒé‡èšåˆæœ€ç»ˆè¯„åˆ†ã€‚åœ¨summarizationå’ŒRAGåŸºå‡†æµ‹è¯•ä¸Šçš„å®éªŒç»“æœè¡¨æ˜ï¼Œè¯¥åŠ¨æ€é™ªå®¡å›¢ç³»ç»Ÿä¸äººç±»åˆ¤æ–­çš„ç›¸å…³æ€§æ˜¾è‘—ä¼˜äºå•ä¸€è¯„å§”å’Œé™æ€é™ªå®¡å›¢åŸºçº¿ã€‚è¿™é¡¹ç ”ç©¶ä¸ºåœ¨å¤æ‚åº”ç”¨åœºæ™¯ä¸­æ„å»ºè‡ªåŠ¨åŒ–ã€é«˜å¯ä¿¡åº¦çš„LLMè¯„ä¼°ä½“ç³»æä¾›äº†é‡è¦çš„æ–¹æ³•è®ºæ”¯æŒã€‚",
      "categories": [
        "cs.AI",
        "cs.LG"
      ],
      "primary_category": "cs.AI",
      "comment": "66 pages, 22 figures, 37 tables",
      "pdf_url": "https://arxiv.org/pdf/2512.01786v1",
      "published_date": "2025-12-01 15:26:20 UTC",
      "updated_date": "2025-12-01 15:26:20 UTC",
      "processing_status": "completed",
      "attempts": 1,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "llm_backup_calls": 0,
      "last_update": "2026-01-26T12:29:05.033598+00:00"
    },
    {
      "arxiv_id": "2512.01782v1",
      "title": "Dual Randomized Smoothing: Beyond Global Noise Variance",
      "title_zh": "åŒé‡éšæœºå¹³æ»‘ï¼šè¶…è¶Šå…¨å±€å™ªå£°æ–¹å·®",
      "authors": [
        "Chenhao Sun",
        "Yuhao Mao",
        "Martin Vechev"
      ],
      "abstract": "Randomized Smoothing (RS) is a prominent technique for certifying the robustness of neural networks against adversarial perturbations. With RS, achieving high accuracy at small radii requires a small noise variance, while achieving high accuracy at large radii requires a large noise variance. However, the global noise variance used in the standard RS formulation leads to a fundamental limitation: there exists no global noise variance that simultaneously achieves strong performance at both small and large radii. To break through the global variance limitation, we propose a dual RS framework which enables input-dependent noise variances. To achieve that, we first prove that RS remains valid with input-dependent noise variances, provided the variance is locally constant around each input. Building on this result, we introduce two components which form our dual RS framework: (i) a variance estimator first predicts an optimal noise variance for each input, (ii) this estimated variance is then used by a standard RS classifier. The variance estimator is independently smoothed via RS to ensure local constancy, enabling flexible design. We also introduce training strategies to iteratively optimize the two components. Extensive experiments on CIFAR-10 show that our dual RS method provides strong performance for both small and large radii-unattainable with global noise variance-while incurring only a 60% computational overhead at inference. Moreover, it consistently outperforms prior input-dependent noise approaches across most radii, with particularly large gains at radii 0.5, 0.75, and 1.0, achieving relative improvements of 19%, 24%, and 21%, respectively. On ImageNet, dual RS remains effective across all radii. Additionally, the dual RS framework naturally provides a routing perspective for certified robustness, improving the accuracy-robustness trade-off with off-the-shelf expert RS models.",
      "tldr_zh": "è¯¥ç ”ç©¶é’ˆå¯¹æ ‡å‡†çš„éšæœºå¹³æ»‘ (Randomized Smoothing, RS) æŠ€æœ¯åœ¨å…¨å±€å™ªå£°æ–¹å·® (global noise variance) ä¸‹æ— æ³•åŒæ—¶åœ¨ä¸åŒåŠå¾„å–å¾—æœ€ä¼˜æ€§èƒ½çš„å±€é™ï¼Œæå‡ºäº† Dual RS æ¡†æ¶ã€‚è¯¥æ¡†æ¶é€šè¿‡å¼•å…¥è¾“å…¥ä¾èµ–å‹å™ªå£°æ–¹å·® (input-dependent noise variances) çªç ´äº†è¿™ä¸€é™åˆ¶ï¼Œå¹¶ä»ç†è®ºä¸Šè¯æ˜äº†åªè¦æ–¹å·®åœ¨æ¯ä¸ªè¾“å…¥å‘¨å›´æ»¡è¶³å±€éƒ¨å¸¸æ•° (locally constant) æ¡ä»¶ï¼ŒRS çš„æœ‰æ•ˆæ€§å³å¯å¾—åˆ°ä¿éšœã€‚Dual RS ç”±é¢„æµ‹æœ€ä½³æ–¹å·®çš„æ–¹å·®ä¼°è®¡å™¨ (variance estimator) å’Œå¯¹åº”çš„ RS åˆ†ç±»å™¨ç»„æˆï¼Œå…¶ä¸­ä¼°è®¡å™¨æœ¬èº«é€šè¿‡ç‹¬ç«‹å¹³æ»‘å¤„ç†ä»¥ç¡®ä¿å±€éƒ¨å¸¸æ•°æ€§ã€‚åœ¨ CIFAR-10 å’Œ ImageNet ä¸Šçš„å®éªŒè¡¨æ˜ï¼Œè¯¥æ–¹æ³•åœ¨æ‰€æœ‰åŠå¾„ä¸‹å‡è¡¨ç°å‡ºè‰²ï¼Œå°¤å…¶åœ¨ 0.5 åˆ° 1.0 åŠå¾„èŒƒå›´å†…å®ç°äº†æœ€é«˜ 24% çš„ç›¸å¯¹æ€§èƒ½æå‡ï¼Œä¸”æ¨ç†å¼€é”€ä»…å¢åŠ  60%ã€‚æœ€åï¼Œè¯¥æ¡†æ¶ä¸ºæå‡è®¤è¯é²æ£’æ€§ (certified robustness) çš„å‡†ç¡®ç‡ä¸é²æ£’æ€§æƒè¡¡æä¾›äº†ä¸€ç§åŸºäºæ¨¡å‹è·¯ç”±çš„æ–°é¢–è§†è§’ã€‚",
      "categories": [
        "cs.LG",
        "cs.AI"
      ],
      "primary_category": "cs.LG",
      "comment": "",
      "pdf_url": "https://arxiv.org/pdf/2512.01782v1",
      "published_date": "2025-12-01 15:23:00 UTC",
      "updated_date": "2025-12-01 15:23:00 UTC",
      "processing_status": "completed",
      "attempts": 1,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "llm_backup_calls": 0,
      "last_update": "2026-01-26T12:29:28.969243+00:00"
    },
    {
      "arxiv_id": "2512.01759v1",
      "title": "Weight Space Representation Learning with Neural Fields",
      "title_zh": "åŸºäºç¥ç»åœºçš„æƒé‡ç©ºé—´è¡¨ç¤ºå­¦ä¹ ",
      "authors": [
        "Zhuoqian Yang",
        "Mathieu Salzmann",
        "Sabine SÃ¼sstrunk"
      ],
      "abstract": "In this work, we investigate the potential of weights to serve as effective representations, focusing on neural fields. Our key insight is that constraining the optimization space through a pre-trained base model and low-rank adaptation (LoRA) can induce structure in weight space. Across reconstruction, generation, and analysis tasks on 2D and 3D data, we find that multiplicative LoRA weights achieve high representation quality while exhibiting distinctiveness and semantic structure. When used with latent diffusion models, multiplicative LoRA weights enable higher-quality generation than existing weight-space methods.",
      "tldr_zh": "è¯¥ç ”ç©¶æ¢è®¨äº†å°†æƒé‡ä½œä¸ºæœ‰æ•ˆè¡¨å¾çš„æ½œåŠ›ï¼Œå¹¶é‡ç‚¹å…³æ³¨ Neural Fields é¢†åŸŸã€‚ç ”ç©¶äººå‘˜å‘ç°é€šè¿‡é¢„è®­ç»ƒåŸºç¡€æ¨¡å‹å’Œä½ç§©è‡ªé€‚åº” (LoRA) çº¦æŸä¼˜åŒ–ç©ºé—´ï¼Œå¯ä»¥åœ¨æƒé‡ç©ºé—´ (Weight Space) ä¸­è¯±å¯¼äº§ç”Ÿç»“æ„åŒ–ç‰¹å¾ã€‚åœ¨é’ˆå¯¹ 2D å’Œ 3D æ•°æ®çš„é‡å»ºã€ç”Ÿæˆå’Œåˆ†æä»»åŠ¡ä¸­ï¼Œä¹˜æ³• LoRA æƒé‡ (Multiplicative LoRA weights) è¡¨ç°å‡ºäº†æé«˜çš„è¡¨å¾è´¨é‡å’Œæ¸…æ™°çš„è¯­ä¹‰ç»“æ„ã€‚æ­¤å¤–ï¼Œå½“è¯¥æŠ€æœ¯ä¸æ½œåœ¨æ‰©æ•£æ¨¡å‹ (Latent Diffusion Models) ç»“åˆä½¿ç”¨æ—¶ï¼Œèƒ½å¤Ÿå®ç°æ¯”ç°æœ‰æƒé‡ç©ºé—´æ–¹æ³•æ›´é«˜è´¨é‡çš„ç”Ÿæˆç»“æœã€‚",
      "categories": [
        "cs.LG",
        "cs.AI"
      ],
      "primary_category": "cs.LG",
      "comment": "12 pages body, 9 pages appendix",
      "pdf_url": "https://arxiv.org/pdf/2512.01759v1",
      "published_date": "2025-12-01 15:05:01 UTC",
      "updated_date": "2025-12-01 15:05:01 UTC",
      "processing_status": "completed",
      "attempts": 1,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "llm_backup_calls": 0,
      "last_update": "2026-01-26T12:29:56.870173+00:00"
    },
    {
      "arxiv_id": "2512.01723v1",
      "title": "Probabilistic Neuro-Symbolic Reasoning for Sparse Historical Data: A Framework Integrating Bayesian Inference, Causal Models, and Game-Theoretic Allocation",
      "title_zh": "é¢å‘ç¨€ç–å†å²æ•°æ®çš„æ¦‚ç‡ç¥ç»ç¬¦å·æ¨ç†ï¼šèåˆè´å¶æ–¯æ¨ç†ã€å› æœæ¨¡å‹ä¸åšå¼ˆè®ºåˆ†é…çš„æ¡†æ¶",
      "authors": [
        "Saba Kublashvili"
      ],
      "abstract": "Modeling historical events poses fundamental challenges for machine learning: extreme data scarcity (N << 100), heterogeneous and noisy measurements, missing counterfactuals, and the requirement for human interpretable explanations. We present HistoricalML, a probabilistic neuro-symbolic framework that addresses these challenges through principled integration of (1) Bayesian uncertainty quantification to separate epistemic from aleatoric uncertainty, (2) structural causal models for counterfactual reasoning under confounding, (3) cooperative game theory (Shapley values) for fair allocation modeling, and (4) attention based neural architectures for context dependent factor weighting. We provide theoretical analysis showing that our approach achieves consistent estimation in the sparse data regime when strong priors from domain knowledge are available, and that Shapley based allocation satisfies axiomatic fairness guarantees that pure regression approaches cannot provide. We instantiate the framework on two historical case studies: the 19th century partition of Africa (N = 7 colonial powers) and the Second Punic War (N = 2 factions). Our model identifies Germany's +107.9 percent discrepancy as a quantifiable structural tension preceding World War I, with tension factor 36.43 and 0.79 naval arms race correlation. For the Punic Wars, Monte Carlo battle simulations achieve a 57.3 percent win probability for Carthage at Cannae and 57.8 percent for Rome at Zama, aligning with historical outcomes. Counterfactual analysis reveals that Carthaginian political support (support score 6.4 vs Napoleon's 7.1), rather than military capability, was the decisive factor.",
      "tldr_zh": "è¯¥ç ”ç©¶æå‡ºäº†HistoricalMLï¼Œä¸€ä¸ªæ—¨åœ¨è§£å†³å†å²æ•°æ®æç«¯ç¨€ç¼ºï¼ˆN << 100ï¼‰ã€æµ‹é‡å¼‚æ„ä¸”å«å™ªå£°ç­‰å»ºæ¨¡æŒ‘æˆ˜çš„æ¦‚ç‡ç¥ç»ç¬¦å·(Probabilistic Neuro-Symbolic)æ¨ç†æ¡†æ¶ã€‚è¯¥æ¡†æ¶é€šè¿‡é›†æˆè´å¶æ–¯ä¸ç¡®å®šæ€§é‡åŒ–(Bayesian Uncertainty Quantification)ã€ç»“æ„å› æœæ¨¡å‹(Structural Causal Models)ã€åŸºäºShapleyå€¼çš„åˆä½œåšå¼ˆè®ºåˆ†é…ä»¥åŠæ³¨æ„åŠ›æœºåˆ¶ç¥ç»æ¶æ„ï¼Œå®ç°äº†åœ¨å¤æ‚å†å²èƒŒæ™¯ä¸‹çš„åäº‹å®æ¨ç†ä¸å› ç´ åŠ æƒã€‚ç†è®ºåˆ†æè¯æ˜ï¼Œè¯¥æ–¹æ³•åœ¨å…·å¤‡é¢†åŸŸçŸ¥è¯†å¼ºå…ˆéªŒçš„æƒ…å†µä¸‹èƒ½å®ç°ä¸€è‡´ä¼°è®¡ï¼Œå¹¶æä¾›çº¯å›å½’æ–¹æ³•æ— æ³•å…·å¤‡çš„å…¬å¹³æ€§ä¿è¯ã€‚åœ¨å¯¹19ä¸–çºªç“œåˆ†éæ´²çš„æ¡ˆä¾‹åˆ†æä¸­ï¼Œæ¨¡å‹é‡åŒ–äº†å¾·å›½åœ¨ä¸€æˆ˜å‰é«˜è¾¾+107.9%çš„ç»“æ„æ€§å¼ åŠ›å·®å¼‚åŠå…¶ä¸æµ·å†›å†›å¤‡ç«èµ›çš„ç›¸å…³æ€§ï¼›è€Œåœ¨ç¬¬äºŒæ¬¡å¸ƒåŒ¿æˆ˜äº‰çš„ç ”ç©¶ä¸­ï¼Œè’™ç‰¹å¡æ´›(Monte Carlo)æ¨¡æ‹Ÿå‡†ç¡®è¿˜åŸäº†å…³é”®æˆ˜å½¹çš„èƒœç‡ã€‚åäº‹å®åˆ†æ(Counterfactual Analysis)æœ€ç»ˆæ­ç¤ºï¼Œè¿¦å¤ªåŸºçš„æ”¿æ²»æ”¯æŒè€Œéå†›äº‹èƒ½åŠ›æ‰æ˜¯å†³å®šå…¶å†å²èµ°å‘çš„å…³é”®å› ç´ ã€‚",
      "categories": [
        "cs.AI",
        "cs.GT",
        "math.PR"
      ],
      "primary_category": "cs.AI",
      "comment": "Preprint. Code and simulation notebooks available at the GitHub repository: https://github.com/Saba-Kublashvili/bayesian-computational-modeling.-",
      "pdf_url": "https://arxiv.org/pdf/2512.01723v1",
      "published_date": "2025-12-01 14:35:04 UTC",
      "updated_date": "2025-12-01 14:35:04 UTC",
      "processing_status": "completed",
      "attempts": 1,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "llm_backup_calls": 0,
      "last_update": "2026-01-26T12:31:03.675900+00:00"
    },
    {
      "arxiv_id": "2512.01707v1",
      "title": "StreamGaze: Gaze-Guided Temporal Reasoning and Proactive Understanding in Streaming Videos",
      "title_zh": "StreamGazeï¼šæµå¼è§†é¢‘ä¸­çš„è§†çº¿å¼•å¯¼æ—¶åºæ¨ç†ä¸ä¸»åŠ¨ç†è§£",
      "authors": [
        "Daeun Lee",
        "Subhojyoti Mukherjee",
        "Branislav Kveton",
        "Ryan A. Rossi",
        "Viet Dac Lai",
        "Seunghyun Yoon",
        "Trung Bui",
        "Franck Dernoncourt",
        "Mohit Bansal"
      ],
      "abstract": "Streaming video understanding requires models not only to process temporally incoming frames, but also to anticipate user intention for realistic applications like AR glasses. While prior streaming benchmarks evaluate temporal reasoning, none measure whether MLLMs can interpret or leverage human gaze signals within a streaming setting. To fill this gap, we introduce StreamGaze, the first benchmark designed to evaluate how effectively MLLMs use gaze for temporal and proactive reasoning in streaming videos. StreamGaze introduces gaze-guided past, present, and proactive tasks that comprehensively evaluate streaming video understanding. These tasks assess whether models can use real-time gaze to follow shifting attention and infer user intentions from only past and currently observed frames. To build StreamGaze, we develop a gaze-video QA generation pipeline that aligns egocentric videos with raw gaze trajectories via fixation extraction, region-specific visual prompting, and scanpath construction. This pipeline produces spatio-temporally grounded QA pairs that closely reflect human perceptual dynamics. Across all StreamGaze tasks, we observe substantial performance gaps between state-of-the-art MLLMs and human performance, revealing fundamental limitations in gaze-based temporal reasoning, intention modeling, and proactive prediction. We further provide detailed analyses of gaze-prompting strategies, reasoning behaviors, and task-specific failure modes, offering deeper insight into why current MLLMs struggle and what capabilities future models must develop. All data and code will be publicly released to support continued research in gaze-guided streaming video understanding.",
      "tldr_zh": "è¯¥ç ”ç©¶å¼•å…¥äº† StreamGazeï¼Œè¿™æ˜¯é¦–ä¸ªæ—¨åœ¨è¯„ä¼°å¤šæ¨¡æ€å¤§è¯­è¨€æ¨¡å‹ (MLLMs) åœ¨æµå¼è§†é¢‘ (Streaming Videos) ä¸­åˆ©ç”¨æ³¨è§† (Gaze) ä¿¡å·è¿›è¡Œæ—¶é—´æ¨ç†å’Œä¸»åŠ¨ç†è§£çš„åŸºå‡†æµ‹è¯•ã€‚è¯¥åŸºå‡†æµ‹è¯•è®¾è®¡äº†æ³¨è§†å¼•å¯¼çš„è¿‡å»ã€ç°åœ¨å’Œä¸»åŠ¨é¢„æµ‹ä»»åŠ¡ï¼Œå…¨é¢è¯„ä¼°æ¨¡å‹è·Ÿéšæ³¨æ„åŠ›è½¬ç§»å¹¶ä»…å‡­å½“å‰è§‚å¯Ÿå¸§æ¨æ–­ç”¨æˆ·æ„å›¾çš„èƒ½åŠ›ã€‚ç ”ç©¶å›¢é˜Ÿå¼€å‘äº†ä¸€å¥— Gaze-Video QA ç”Ÿæˆæµæ°´çº¿ï¼Œé€šè¿‡æ³¨è§†ç‚¹æå– (Fixation Extraction)ã€åŒºåŸŸç‰¹å®šè§†è§‰æç¤º (Visual Prompting) å’Œæ‰«æè·¯å¾„æ„å»º (Scanpath Construction) å°†ç¬¬ä¸€äººç§°è§†é¢‘ä¸åŸå§‹æ³¨è§†è½¨è¿¹ç²¾å‡†å¯¹é½ã€‚å®éªŒç»“æœè¡¨æ˜ï¼Œå½“å‰çš„é¡¶å°– MLLMs ä¸äººç±»è¡¨ç°ä¹‹é—´å­˜åœ¨æ˜¾è‘—å·®è·ï¼Œå°¤å…¶åœ¨åŸºäºæ³¨è§†çš„æ—¶é—´æ¨ç†ã€æ„å›¾å»ºæ¨¡å’Œä¸»åŠ¨é¢„æµ‹æ–¹é¢å­˜åœ¨æ ¹æœ¬æ€§å±€é™ã€‚é€šè¿‡å¯¹æ¨ç†è¡Œä¸ºå’Œå¤±è´¥æ¨¡å¼çš„è¯¦ç»†åˆ†æï¼Œè¯¥ç ”ç©¶æ­ç¤ºäº†ç°æœ‰æ¨¡å‹åœ¨æ„ŸçŸ¥åŠ¨æ€ç†è§£ä¸Šçš„ä¸è¶³ï¼Œå¹¶ä¸ºæœªæ¥å…·å¤‡ä¸»åŠ¨ç†è§£èƒ½åŠ›çš„æ¨¡å‹å¼€å‘æä¾›äº†é‡è¦æ–¹å‘ã€‚",
      "categories": [
        "cs.CV",
        "cs.AI",
        "cs.CL"
      ],
      "primary_category": "cs.CV",
      "comment": "Project page: https://streamgaze.github.io/",
      "pdf_url": "https://arxiv.org/pdf/2512.01707v1",
      "published_date": "2025-12-01 14:15:44 UTC",
      "updated_date": "2025-12-01 14:15:44 UTC",
      "processing_status": "completed",
      "attempts": 1,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "llm_backup_calls": 0,
      "last_update": "2026-01-26T12:29:27.180677+00:00"
    },
    {
      "arxiv_id": "2512.02088v1",
      "title": "Comparing Baseline and Day-1 Diffusion MRI Using Multimodal Deep Embeddings for Stroke Outcome Prediction",
      "title_zh": "åŸºäºå¤šæ¨¡æ€æ·±åº¦åµŒå…¥çš„åŸºçº¿ä¸ç¬¬1å¤©å¼¥æ•£MRIåœ¨å’ä¸­é¢„åé¢„æµ‹ä¸­çš„æ¯”è¾ƒ",
      "authors": [
        "Sina Raeisadigh",
        "Myles Joshua Toledo Tan",
        "Henning MÃ¼ller",
        "Abderrahmane Hedjoudje"
      ],
      "abstract": "This study compares baseline (J0) and 24-hour (J1) diffusion magnetic resonance imaging (MRI) for predicting three-month functional outcomes after acute ischemic stroke (AIS). Seventy-four AIS patients with paired apparent diffusion coefficient (ADC) scans and clinical data were analyzed. Three-dimensional ResNet-50 embeddings were fused with structured clinical variables, reduced via principal component analysis (<=12 components), and classified using linear support vector machines with eight-fold stratified group cross-validation. J1 multimodal models achieved the highest predictive performance (AUC = 0.923 +/- 0.085), outperforming J0-based configurations (AUC <= 0.86). Incorporating lesion-volume features further improved model stability and interpretability. These findings demonstrate that early post-treatment diffusion MRI provides superior prognostic value to pre-treatment imaging and that combining MRI, clinical, and lesion-volume features produces a robust and interpretable framework for predicting three-month functional outcomes in AIS patients.",
      "tldr_zh": "è¯¥ç ”ç©¶å¯¹æ¯”äº†åŸºçº¿ï¼ˆJ0ï¼‰å’Œ24å°æ—¶ï¼ˆJ1ï¼‰å¼¥æ•£ç£å…±æŒ¯æˆåƒï¼ˆdiffusion MRIï¼‰åœ¨é¢„æµ‹æ€¥æ€§ç¼ºè¡€æ€§ä¸­é£ï¼ˆAISï¼‰æ‚£è€…ä¸‰ä¸ªæœˆåŠŸèƒ½é¢„åä¸­çš„ä»·å€¼ã€‚ç ”ç©¶è€…åˆ©ç”¨ä¸‰ç»´ ResNet-50 æå–æ·±åº¦åµŒå…¥ç‰¹å¾ï¼Œå¹¶å°†å…¶ä¸ç»“æ„åŒ–ä¸´åºŠå˜é‡ç›¸èåˆï¼Œé€šè¿‡ä¸»æˆåˆ†åˆ†æï¼ˆPCAï¼‰é™ç»´åé‡‡ç”¨çº¿æ€§æ”¯æŒå‘é‡æœºï¼ˆSVMï¼‰è¿›è¡Œåˆ†ç±»ã€‚å®éªŒç»“æœæ˜¾ç¤ºï¼ŒåŸºäº J1 çš„å¤šæ¨¡æ€æ¨¡å‹å–å¾—äº†æœ€é«˜çš„é¢„æµ‹æ€§èƒ½ï¼ˆAUC = 0.923ï¼‰ï¼Œæ˜¾è‘—ä¼˜äºåŸºäº J0 çš„é…ç½®ï¼ˆAUC <= 0.86ï¼‰ã€‚æ­¤å¤–ï¼Œå¼•å…¥ç—…ç¶ä½“ç§¯ç‰¹å¾è¿›ä¸€æ­¥æå‡äº†æ¨¡å‹çš„ç¨³å®šæ€§å’Œå¯è§£é‡Šæ€§ã€‚è¯¥å‘ç°è¯å®äº†æ²»ç–—åæ—©æœŸçš„å¼¥æ•£ MRIï¼ˆADC å›¾ï¼‰æ¯”æ²»ç–—å‰æˆåƒå…·æœ‰æ›´é«˜çš„é¢„åä»·å€¼ï¼Œä¸ºæ„å»ºç¨³å¥ä¸”å¯è§£é‡Šçš„ AIS é¢„åé¢„æµ‹æ¡†æ¶æä¾›äº†é‡è¦ä¾æ®ã€‚",
      "categories": [
        "eess.IV",
        "cs.AI",
        "cs.CV",
        "cs.LG"
      ],
      "primary_category": "eess.IV",
      "comment": "5 pages, 5 figures, 2 tables",
      "pdf_url": "https://arxiv.org/pdf/2512.02088v1",
      "published_date": "2025-12-01 13:56:44 UTC",
      "updated_date": "2025-12-01 13:56:44 UTC",
      "processing_status": "completed",
      "attempts": 1,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "llm_backup_calls": 0,
      "last_update": "2026-01-26T12:30:00.275906+00:00"
    },
    {
      "arxiv_id": "2512.01672v1",
      "title": "ICAD-LLM: One-for-All Anomaly Detection via In-Context Learning with Large Language Models",
      "title_zh": "ICAD-LLMï¼šåŸºäºå¤§è¯­è¨€æ¨¡å‹ä¸Šä¸‹æ–‡å­¦ä¹ çš„é€šç”¨å¼‚å¸¸æ£€æµ‹",
      "authors": [
        "Zhongyuan Wu",
        "Jingyuan Wang",
        "Zexuan Cheng",
        "Yilong Zhou",
        "Weizhi Wang",
        "Juhua Pu",
        "Chao Li",
        "Changqing Ma"
      ],
      "abstract": "Anomaly detection (AD) is a fundamental task of critical importance across numerous domains. Current systems increasingly operate in rapidly evolving environments that generate diverse yet interconnected data modalities -- such as time series, system logs, and tabular records -- as exemplified by modern IT systems. Effective AD methods in such environments must therefore possess two critical capabilities: (1) the ability to handle heterogeneous data formats within a unified framework, allowing the model to process and detect multiple modalities in a consistent manner during anomalous events; (2) a strong generalization ability to quickly adapt to new scenarios without extensive retraining. However, most existing methods fall short of these requirements, as they typically focus on single modalities and lack the flexibility to generalize across domains. To address this gap, we introduce a novel paradigm: In-Context Anomaly Detection (ICAD), where anomalies are defined by their dissimilarity to a relevant reference set of normal samples. Under this paradigm, we propose ICAD-LLM, a unified AD framework leveraging Large Language Models' in-context learning abilities to process heterogeneous data within a single model. Extensive experiments demonstrate that ICAD-LLM achieves competitive performance with task-specific AD methods and exhibits strong generalization to previously unseen tasks, which substantially reduces deployment costs and enables rapid adaptation to new environments. To the best of our knowledge, ICAD-LLM is the first model capable of handling anomaly detection tasks across diverse domains and modalities.",
      "tldr_zh": "è¯¥ç ”ç©¶æå‡ºäº†ICAD-LLMï¼Œè¿™æ˜¯ä¸€ä¸ªåˆ©ç”¨å¤§è¯­è¨€æ¨¡å‹(Large Language Models)çš„è¯­å¢ƒå­¦ä¹ (In-Context Learning)èƒ½åŠ›æ„å»ºçš„ç»Ÿä¸€å¼‚å¸¸æ£€æµ‹(Anomaly Detection)æ¡†æ¶ï¼Œæ—¨åœ¨åº”å¯¹ç°ä»£ITç³»ç»Ÿä¸­æ—¶é—´åºåˆ—ã€ç³»ç»Ÿæ—¥å¿—å’Œè¡¨æ ¼è®°å½•ç­‰å¼‚æ„æ•°æ®çš„æ£€æµ‹æŒ‘æˆ˜ã€‚ç ”ç©¶è€…å¼•å…¥äº†è¯­å¢ƒå¼‚å¸¸æ£€æµ‹(In-Context Anomaly Detection, ICAD)æ–°èŒƒå¼ï¼Œé€šè¿‡æ¯”è¾ƒå¾…æµ‹æ ·æœ¬ä¸æ­£å¸¸å‚è€ƒé›†çš„ç›¸ä¼¼æ€§æ¥è¯†åˆ«å¼‚å¸¸ã€‚ICAD-LLMå®ç°äº†åœ¨å•ä¸€æ¨¡å‹å†…å¤„ç†å¤šç§æ•°æ®æ¨¡æ€ï¼Œå…‹æœäº†ä¼ ç»Ÿæ–¹æ³•ä»…å…³æ³¨å•ä¸€æ¨¡æ€ä¸”éš¾ä»¥æ³›åŒ–åˆ°æ–°åœºæ™¯çš„å±€é™æ€§ã€‚å¤§é‡å®éªŒè¯æ˜ï¼Œè¯¥æ¨¡å‹åœ¨æ€§èƒ½ä¸Šä¸ä»…èƒ½ä¸ç‰¹å®šä»»åŠ¡çš„ADæ–¹æ³•ç«äº‰ï¼Œè¿˜å±•ç°å‡ºå“è¶Šçš„è·¨ä»»åŠ¡æ³›åŒ–èƒ½åŠ›ï¼Œæ˜¾è‘—é™ä½äº†å®é™…éƒ¨ç½²æˆæœ¬ã€‚ä½œä¸ºé¦–ä¸ªèƒ½å¤ŸåŒæ—¶å¤„ç†è·¨é¢†åŸŸã€è·¨æ¨¡æ€å¼‚å¸¸æ£€æµ‹ä»»åŠ¡çš„æ¨¡å‹ï¼ŒICAD-LLMä¸ºå®ç°å¿«é€Ÿé€‚åº”æ–°ç¯å¢ƒçš„æ™ºèƒ½åŒ–æ£€æµ‹æä¾›äº†æœ‰æ•ˆæ–¹æ¡ˆã€‚",
      "categories": [
        "cs.LG",
        "cs.AI"
      ],
      "primary_category": "cs.LG",
      "comment": "",
      "pdf_url": "https://arxiv.org/pdf/2512.01672v1",
      "published_date": "2025-12-01 13:41:30 UTC",
      "updated_date": "2025-12-01 13:41:30 UTC",
      "processing_status": "completed",
      "attempts": 1,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "llm_backup_calls": 0,
      "last_update": "2026-01-26T12:31:19.582422+00:00"
    },
    {
      "arxiv_id": "2601.14263v1",
      "title": "Call2Instruct: Automated Pipeline for Generating Q&A Datasets from Call Center Recordings for LLM Fine-Tuning",
      "title_zh": "Call2Instructï¼šç”¨äºå¤§è¯­è¨€æ¨¡å‹å¾®è°ƒçš„å‘¼å«ä¸­å¿ƒå½•éŸ³é—®ç­”æ•°æ®é›†è‡ªåŠ¨åŒ–ç”Ÿæˆæµæ°´çº¿",
      "authors": [
        "Alex Echeverria",
        "SÃ¡vio Salvarino Teles de Oliveira",
        "Fernando Marques Federson"
      ],
      "abstract": "The adaptation of Large-Scale Language Models (LLMs) to specific domains depends on high-quality fine-tuning datasets, particularly in instructional format (e.g., Question-Answer - Q&A). However, generating these datasets, particularly from unstructured sources such as call center audio recordings, poses a significant challenge due to the noisy and disorganized nature of the data. This paper presents a solution to this challenge by offering an end-to-end automated pipeline for generating Q&A instructional datasets from such recordings. The methodology developed comprises sequential steps of audio processing (including diarization, noise removal and automatic transcription), textual processing (cleaning, normalization, and anonymization), semantic extraction of customer demands and attendant responses using vector embeddings, and matching via semantic search to form the final Q&A pairs. As a result, the complete pipeline was successfully implemented, generating a dataset specifically formatted for Instruct Fine Tuning. The practical value and feasibility of the generated dataset were substantiated and functionally demonstrated through the successful fine-tuning of an LLM model (based on Llama 2 7B). The conclusion of the paper states that the proposed approach is viable for converting unstructured conversational data from call centers into valuable resources for training LLMs. This development has the potential to open up avenues for creating more effective AI systems for Q&A tasks in the customer service domain. The developed codes have been made publicly available to promote reproducibility and future research.",
      "tldr_zh": "è¯¥ç ”ç©¶æå‡ºäº†Call2Instructï¼Œä¸€ä¸ªç«¯åˆ°ç«¯è‡ªåŠ¨åŒ–æµæ°´çº¿ï¼Œæ—¨åœ¨å°†å‘¼å«ä¸­å¿ƒå½•éŸ³ç­‰éç»“æ„åŒ–æ•°æ®è½¬åŒ–ä¸ºç”¨äºå¤§è¯­è¨€æ¨¡å‹(LLMs)å¾®è°ƒçš„é«˜è´¨é‡é—®ç­”(Q&A)æŒ‡ä»¤æ•°æ®é›†ã€‚è¯¥æ¡†æ¶æ•´åˆäº†éŸ³é¢‘å¤„ç†ï¼ˆåŒ…æ‹¬diarizationã€å™ªå£°å»é™¤å’Œè‡ªåŠ¨è½¬å½•ï¼‰ä¸æ–‡æœ¬å¤„ç†ï¼ˆæ¸…æ´—ã€è§„èŒƒåŒ–åŠåŒ¿ååŒ–ï¼‰ç­‰å¤šä¸ªé˜¶æ®µï¼Œæœ‰æ•ˆè§£å†³äº†åŸå§‹è¯­éŸ³æ•°æ®å™ªå£°å¤§ä¸”ç»„ç»‡æ··ä¹±çš„é—®é¢˜ã€‚å…¶æ ¸å¿ƒæ–¹æ³•æ˜¯åˆ©ç”¨å‘é‡åµŒå…¥(vector embeddings)è¿›è¡Œè¯­ä¹‰ç‰¹å¾æå–ï¼Œå¹¶é€šè¿‡è¯­ä¹‰æœç´¢(semantic search)å¯¹å®¢æˆ·éœ€æ±‚ä¸åå¸­å›å¤è¿›è¡ŒåŒ¹é…ï¼Œä»è€Œç”Ÿæˆç»“æ„åŒ–çš„é—®ç­”å¯¹ã€‚å®éªŒé€šè¿‡å¯¹Llama 2 7Bæ¨¡å‹è¿›è¡ŒæŒ‡ä»¤å¾®è°ƒ(Instruct Fine Tuning)éªŒè¯äº†ç”Ÿæˆæ•°æ®é›†çš„å®ç”¨ä»·å€¼ï¼Œè¯æ˜äº†è¯¥æ–¹æ¡ˆåœ¨å®¢æˆ·æœåŠ¡é¢†åŸŸæ„å»ºé«˜æ•ˆAIç³»ç»Ÿçš„å¯è¡Œæ€§ã€‚è¯¥ç ”ç©¶ä¸ºå°†éç»“æ„åŒ–å¯¹è¯è®°å½•è½¬åŒ–ä¸ºå¤§è¯­è¨€æ¨¡å‹è®­ç»ƒèµ„æºæä¾›äº†é‡è¦è·¯å¾„ï¼Œå…¶ç›¸å…³ä»£ç ä¹Ÿå·²å¼€æºä»¥ä¿ƒè¿›åç»­ç ”ç©¶ã€‚",
      "categories": [
        "cs.LG",
        "cs.AI",
        "cs.CL",
        "cs.HC",
        "cs.SD",
        "eess.AS"
      ],
      "primary_category": "cs.LG",
      "comment": "15 pages, 1 figures, conference",
      "pdf_url": "https://arxiv.org/pdf/2601.14263v1",
      "published_date": "2025-12-01 13:39:54 UTC",
      "updated_date": "2025-12-01 13:39:54 UTC",
      "processing_status": "completed",
      "attempts": 1,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "llm_backup_calls": 0,
      "last_update": "2026-01-26T12:31:19.166848+00:00"
    },
    {
      "arxiv_id": "2512.01661v2",
      "title": "Learning the Boundary of Solvability: Aligning LLMs to Detect Unsolvable Problems",
      "title_zh": "å­¦ä¹ å¯è§£æ€§è¾¹ç•Œï¼šé€šè¿‡å¯¹é½å¤§è¯­è¨€æ¨¡å‹è¯†åˆ«ä¸å¯è§£é—®é¢˜",
      "authors": [
        "Dengyun Peng",
        "Qiguang Chen",
        "Bofei Liu",
        "Jiannan Guan",
        "Libo Qin",
        "Zheng Yan",
        "Jinhao Liu",
        "Jianshu Zhang",
        "Wanxiang Che"
      ],
      "abstract": "Ensuring large language model (LLM) reliability requires distinguishing objective unsolvability (inherent contradictions) from subjective capability limitations (tasks exceeding model competence). Current LLMs often conflate these dimensions, leading to hallucinations in which they return confident answers to inherently unsolvable queries. To address this issue, we propose a multi-domain dataset containing both solvable and unsolvable questions, UnsolvableQA, together with an alignment framework, UnsolvableRL. First, we construct UnsolvableQA by \"Reverse Construction\" that systematically injects logical contradictions into otherwise valid reasoning chains. Second, we introduce UnsolvableRL, a reinforcement learning paradigm that balances objective unsolvability detection with calibrated confidence under capability limits. Empirically, our approach achieves near-perfect unsolvability detection (>90% detection rate) and boosts solvable reasoning accuracy from 43.4% to 69.4% on Qwen3-4B-Instruct. Crucially, we identify a data-training interaction: strict alignment constraints induce Capability Collapse without unsolvable data, but act as a regularizer for rigor when such data are included, thereby improving overall robustness. Our code and data are available at https://github.com/sfasfaffa/unsolvableQA .",
      "tldr_zh": "è¯¥ç ”ç©¶æ—¨åœ¨æé«˜å¤§è¯­è¨€æ¨¡å‹(LLMs)çš„å¯é æ€§ï¼Œé€šè¿‡åŒºåˆ†å®¢è§‚ä¸å¯è§£æ€§(objective unsolvability)ä¸ä¸»è§‚èƒ½åŠ›å±€é™(subjective capability limitations)æ¥å‡å°‘æ¨¡å‹åœ¨å¤„ç†ä¸å¯è§£é—®é¢˜æ—¶çš„å¹»è§‰ç°è±¡ã€‚ä¸ºæ­¤ï¼Œç ”ç©¶è€…åˆ©ç”¨é€†å‘æ„å»º(Reverse Construction)æ–¹æ³•ç³»ç»Ÿæ€§åœ°åœ¨é€»è¾‘é“¾ä¸­æ³¨å…¥çŸ›ç›¾ï¼Œæ„å»ºäº†åŒ…å«å¯è§£ä¸ä¸å¯è§£é—®é¢˜çš„å¤šé¢†åŸŸæ•°æ®é›† UnsolvableQAã€‚éšåï¼Œè¯¥ç ”ç©¶æå‡ºäº†ä¸€ç§åä¸º UnsolvableRL çš„å¼ºåŒ–å­¦ä¹ å¯¹é½æ¡†æ¶ï¼Œæ—¨åœ¨å¹³è¡¡å¯¹ä¸å¯è§£æ€§çš„æ£€æµ‹ä¸åœ¨èƒ½åŠ›é™åˆ¶ä¸‹çš„ç½®ä¿¡åº¦æ ¡å‡†ã€‚å®éªŒç»“æœæ˜¾ç¤ºï¼Œè¯¥æ–¹æ³•åœ¨ Qwen3-4B-Instruct æ¨¡å‹ä¸Šå®ç°äº†è¶…è¿‡90%çš„ä¸å¯è§£æ€§æ£€æµ‹ç‡ï¼Œå¹¶å°†å…¶åœ¨å¯è§£é—®é¢˜ä¸Šçš„æ¨ç†å‡†ç¡®ç‡ä»43.4%æå‡è‡³69.4%ã€‚ç ”ç©¶è¿›ä¸€æ­¥å‘ç°ï¼Œè™½ç„¶ä¸¥æ ¼çš„å¯¹é½çº¦æŸåœ¨ç¼ºä¹ä¸å¯è§£æ•°æ®æ—¶ä¼šå¯¼è‡´èƒ½åŠ›å´©å(Capability Collapse)ï¼Œä½†åœ¨å¼•å…¥æ­¤ç±»æ•°æ®ååˆ™èƒ½èµ·åˆ°ä¸¥è°¨æ€§çš„æ­£åˆ™åŒ–ä½œç”¨ï¼Œä»è€Œæ˜¾è‘—å¢å¼ºæ¨¡å‹çš„æ•´ä½“é²æ£’æ€§ã€‚",
      "categories": [
        "cs.CL",
        "cs.AI"
      ],
      "primary_category": "cs.CL",
      "comment": "preprint",
      "pdf_url": "https://arxiv.org/pdf/2512.01661v2",
      "published_date": "2025-12-01 13:32:59 UTC",
      "updated_date": "2026-01-02 04:15:52 UTC",
      "processing_status": "completed",
      "attempts": 1,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "llm_backup_calls": 0,
      "last_update": "2026-01-26T12:31:23.270612+00:00"
    },
    {
      "arxiv_id": "2512.01659v1",
      "title": "HalluGraph: Auditable Hallucination Detection for Legal RAG Systems via Knowledge Graph Alignment",
      "title_zh": "HalluGraphï¼šåŸºäºçŸ¥è¯†å›¾è°±å¯¹é½çš„æ³•å¾‹ RAG ç³»ç»Ÿå¯å®¡è®¡å¹»è§‰æ£€æµ‹",
      "authors": [
        "Valentin NoÃ«l",
        "Elimane Yassine Seidou",
        "Charly Ken Capo-Chichi",
        "Ghanem Amari"
      ],
      "abstract": "Legal AI systems powered by retrieval-augmented generation (RAG) face a critical accountability challenge: when an AI assistant cites case law, statutes, or contractual clauses, practitioners need verifiable guarantees that generated text faithfully represents source documents. Existing hallucination detectors rely on semantic similarity metrics that tolerate entity substitutions, a dangerous failure mode when confusing parties, dates, or legal provisions can have material consequences. We introduce HalluGraph, a graph-theoretic framework that quantifies hallucinations through structural alignment between knowledge graphs extracted from context, query, and response. Our approach produces bounded, interpretable metrics decomposed into \\textit{Entity Grounding} (EG), measuring whether entities in the response appear in source documents, and \\textit{Relation Preservation} (RP), verifying that asserted relationships are supported by context. On structured control documents, HalluGraph achieves near-perfect discrimination ($>$400 words, $>$20 entities), HalluGraph achieves $AUC = 0.979$, while maintaining robust performance ($AUC \\approx 0.89$) on challenging generative legal task, consistently outperforming semantic similarity baselines. The framework provides the transparency and traceability required for high-stakes legal applications, enabling full audit trails from generated assertions back to source passages.",
      "tldr_zh": "è¯¥ç ”ç©¶é’ˆå¯¹æ³•å¾‹æ£€ç´¢å¢å¼ºç”Ÿæˆ (RAG) ç³»ç»Ÿåœ¨å¼•ç”¨æ³•å¾‹æ¡ˆä¾‹æˆ–æ¡æ¬¾æ—¶é¢ä¸´çš„è´£ä»»å½’å±æŒ‘æˆ˜ï¼Œæå‡ºäº†åä¸º HalluGraph çš„å›¾è®ºæ¡†æ¶ã€‚é’ˆå¯¹ç°æœ‰æ£€æµ‹å™¨å› ä¾èµ–è¯­ä¹‰ç›¸ä¼¼æ€§è€Œéš¾ä»¥è¯†åˆ«å®ä½“æ›¿æ¢æˆ–å…³ç³»é”™è¯¯çš„é—®é¢˜ï¼Œè¯¥æ¡†æ¶é€šè¿‡æå–ä¸Šä¸‹æ–‡ã€æŸ¥è¯¢å’Œå“åº”ä¸­çš„çŸ¥è¯†å›¾è°± (Knowledge Graphs) å¹¶è¿›è¡Œç»“æ„åŒ–å¯¹é½æ¥é‡åŒ–å¹»è§‰ã€‚ç ”ç©¶å¼•å…¥äº†å®ä½“è½åœ° (Entity Grounding, EG) å’Œå…³ç³»ä¿ç•™ (Relation Preservation, RP) ä¸¤ä¸ªå¯è§£é‡Šçš„é‡åŒ–æŒ‡æ ‡ï¼Œåˆ†åˆ«ç”¨äºè¡¡é‡å“åº”å®ä½“æ˜¯å¦æ¥æºäºæºæ–‡æ¡£ä»¥åŠéªŒè¯å®ä½“é—´çš„é€»è¾‘å…³ç³»æ˜¯å¦å¾—åˆ°æ”¯æŒã€‚å®éªŒç»“æœè¡¨æ˜ï¼ŒHalluGraph åœ¨å—æ§æ–‡æ¡£æµ‹è¯•ä¸­è¾¾åˆ°äº† 0.979 çš„ AUCï¼Œåœ¨å¤æ‚çš„ç”Ÿæˆå¼æ³•å¾‹ä»»åŠ¡ä¸­ä¹Ÿä¿æŒäº†çº¦ 0.89 çš„ AUCï¼Œæ€§èƒ½æŒç»­ä¼˜äºä¼ ç»Ÿçš„è¯­ä¹‰ç›¸ä¼¼æ€§åŸºå‡†ã€‚è¯¥æ¡†æ¶ä¸ºé«˜é£é™©çš„æ³•å¾‹åº”ç”¨æä¾›äº†å¿…è¦çš„é€æ˜åº¦å’Œå¯è¿½æº¯æ€§ï¼Œèƒ½å¤Ÿå®ç°ä»ç”Ÿæˆçš„æ–­è¨€åˆ°åŸå§‹æ–‡æœ¬æ®µè½çš„å®Œæ•´å®¡è®¡è¿½è¸ªã€‚",
      "categories": [
        "cs.LG",
        "cs.AI",
        "cs.CL"
      ],
      "primary_category": "cs.LG",
      "comment": "8 pages, 4 figures, under review",
      "pdf_url": "https://arxiv.org/pdf/2512.01659v1",
      "published_date": "2025-12-01 13:31:06 UTC",
      "updated_date": "2025-12-01 13:31:06 UTC",
      "processing_status": "completed",
      "attempts": 1,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "llm_backup_calls": 0,
      "last_update": "2026-01-26T12:31:31.962289+00:00"
    },
    {
      "arxiv_id": "2512.04115v1",
      "title": "Artificial Intelligence Competence of K-12 Students Shapes Their AI Risk Perception: A Co-occurrence Network Analysis",
      "title_zh": "K-12å­¦ç”Ÿçš„äººå·¥æ™ºèƒ½èƒ½åŠ›å¯¹å…¶äººå·¥æ™ºèƒ½é£é™©æ„ŸçŸ¥çš„å½±å“ï¼šåŸºäºå…±ç°ç½‘ç»œåˆ†æçš„ç ”ç©¶",
      "authors": [
        "Ville Heilala",
        "Pieta SikstrÃ¶m",
        "Mika SetÃ¤lÃ¤",
        "Tommi KÃ¤rkkÃ¤inen"
      ],
      "abstract": "As artificial intelligence (AI) becomes increasingly integrated into education, understanding how students perceive its risks is essential for supporting responsible and effective adoption. This research aimed to examine the relationships between perceived AI competence and risks among Finnish K-12 upper secondary students (n = 163) by utilizing a co-occurrence analysis. Students reported their self-perceived AI competence and concerns related to AI across systemic, institutional, and personal domains. The findings showed that students with lower competence emphasized personal and learning-related risks, such as reduced creativity, lack of critical thinking, and misuse, whereas higher-competence students focused more on systemic and institutional risks, including bias, inaccuracy, and cheating. These differences suggest that students' self-reported AI competence is related to how they evaluate both the risks and opportunities associated with artificial intelligence in education (AIED). The results of this study highlight the need for educational institutions to incorporate AI literacy into their curricula, provide teacher guidance, and inform policy development to ensure personalized opportunities for utilization and equitable integration of AI into K-12 education.",
      "tldr_zh": "è¯¥ç ”ç©¶åˆ©ç”¨å…±ç°ç½‘ç»œåˆ†æ(Co-occurrence Network Analysis)æ¢è®¨äº†163åèŠ¬å…°K-12é«˜ä¸­ç”Ÿå¯¹äººå·¥æ™ºèƒ½(AI)çš„èƒ½åŠ›æ„ŸçŸ¥ä¸é£é™©æ„ŸçŸ¥ä¹‹é—´çš„å…³ç³»ã€‚ç ”ç©¶å‘ç°ï¼Œå­¦ç”Ÿçš„AI competenceæ˜¾è‘—å½±å“å…¶å¯¹é£é™©çš„è¯„ä¼°è§†è§’ï¼šèƒ½åŠ›æ„ŸçŸ¥è¾ƒä½çš„å­¦ç”Ÿä¸»è¦å…³æ³¨ä¸ªäººåŠå­¦ä¹ å±‚é¢çš„é£é™©ï¼Œå¦‚åˆ›é€ åŠ›ä¸‹é™å’ŒæŠ€æœ¯è¯¯ç”¨ï¼›è€Œèƒ½åŠ›æ„ŸçŸ¥è¾ƒé«˜çš„å­¦ç”Ÿåˆ™æ›´å€¾å‘äºå…³æ³¨åè§(Bias)ã€ä¸å‡†ç¡®æ€§(Inaccuracy)å’Œä½œå¼Šç­‰ç³»ç»Ÿä¸åˆ¶åº¦å±‚é¢çš„é£é™©ã€‚è¿™äº›å·®å¼‚è¡¨æ˜ï¼Œå­¦ç”Ÿå¯¹æ•™è‚²äººå·¥æ™ºèƒ½(AIED)é£é™©ä¸æœºé‡çš„è¯„ä¼°ä¸å…¶è‡ªèº«AIèƒ½åŠ›æ°´å¹³å¯†åˆ‡ç›¸å…³ã€‚ç ”ç©¶ç»“æœå¼ºè°ƒäº†æ•™è‚²æœºæ„å°†AIç´ å…»(AI literacy)çº³å…¥è¯¾ç¨‹ä½“ç³»çš„å¿…è¦æ€§ï¼Œä»¥æ”¯æŒAIåœ¨K-12æ•™è‚²ä¸­çš„å…¬å¹³æ•´åˆä¸ä¸ªæ€§åŒ–åº”ç”¨ã€‚é€šè¿‡æä¾›æ•™å¸ˆæŒ‡å¯¼å’Œå®Œå–„ç›¸å…³æ”¿ç­–ï¼Œæ•™è‚²ç³»ç»Ÿå¯ä»¥æ›´æœ‰æ•ˆåœ°å¼•å¯¼å­¦ç”Ÿè´Ÿè´£ä»»åœ°åˆ©ç”¨äººå·¥æ™ºèƒ½æŠ€æœ¯ã€‚",
      "categories": [
        "cs.CY",
        "cs.AI",
        "cs.HC"
      ],
      "primary_category": "cs.CY",
      "comment": "Accepted for Proceedings of the 41th ACM/SIGAPP Symposium on Applied Computing (SAC'26)",
      "pdf_url": "https://arxiv.org/pdf/2512.04115v1",
      "published_date": "2025-12-01 12:40:24 UTC",
      "updated_date": "2025-12-01 12:40:24 UTC",
      "processing_status": "completed",
      "attempts": 1,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "llm_backup_calls": 0,
      "last_update": "2026-01-26T12:31:58.363525+00:00"
    },
    {
      "arxiv_id": "2512.01616v1",
      "title": "CLIP-RL: Aligning Language and Policy Representations for Task Transfer in Reinforcement Learning",
      "title_zh": "CLIP-RLï¼šå¼ºåŒ–å­¦ä¹ ä¸­é¢å‘ä»»åŠ¡è¿ç§»çš„è¯­è¨€ä¸ç­–ç•¥è¡¨ç¤ºå¯¹é½",
      "authors": [
        "Chainesh Gautam",
        "Raghuram Bharadwaj Diddigi"
      ],
      "abstract": "Recently, there has been an increasing need to develop agents capable of solving multiple tasks within the same environment, especially when these tasks are naturally associated with language. In this work, we propose a novel approach that leverages combinations of pre-trained (language, policy) pairs to establish an efficient transfer pipeline. Our algorithm is inspired by the principles of Contrastive Language-Image Pretraining (CLIP) in Computer Vision, which aligns representations across different modalities under the philosophy that ''two modalities representing the same concept should have similar representations.'' The central idea here is that the instruction and corresponding policy of a task represent the same concept, the task itself, in two different modalities. Therefore, by extending the idea of CLIP to RL, our method creates a unified representation space for natural language and policy embeddings. Experimental results demonstrate the utility of our algorithm in achieving faster transfer across tasks.",
      "tldr_zh": "è¯¥ç ”ç©¶æå‡ºäº†CLIP-RLï¼Œæ—¨åœ¨è§£å†³ Reinforcement Learning (RL) ä¸­æ™ºèƒ½ä½“åœ¨åŒä¸€ç¯å¢ƒä¸‹å¤„ç†å¤šé¡¹è¯­è¨€ç›¸å…³ä»»åŠ¡çš„æŒ‘æˆ˜ã€‚å—è®¡ç®—æœºè§†è§‰é¢†åŸŸ Contrastive Language-Image Pretraining (CLIP) çš„å¯å‘ï¼Œè¯¥æ–¹æ³•å°†è‡ªç„¶è¯­è¨€æŒ‡ä»¤ä¸å¯¹åº”çš„ç­–ç•¥ (Policy) è§†ä¸ºåŒä¸€ä»»åŠ¡æ¦‚å¿µçš„ä¸¤ç§ä¸åŒæ¨¡æ€ã€‚CLIP-RL é€šè¿‡å¯¹é½è¿™ä¸¤ç§æ¨¡æ€çš„è¡¨ç¤ºï¼Œå»ºç«‹äº†ä¸€ä¸ªç»Ÿä¸€çš„è¯­è¨€å’Œç­–ç•¥åµŒå…¥ (Embeddings) è¡¨ç¤ºç©ºé—´ã€‚è¿™ç§æ–¹æ³•åˆ©ç”¨é¢„è®­ç»ƒçš„ (language, policy) å¯¹æ„å»ºäº†é«˜æ•ˆçš„ä»»åŠ¡è½¬ç§»æµæ°´çº¿ï¼Œç¡®ä¿ä»£è¡¨ç›¸åŒæ¦‚å¿µçš„ä¸åŒæ¨¡æ€å…·æœ‰ç›¸ä¼¼çš„ç‰¹å¾è¡¨ç¤ºã€‚å®éªŒç»“æœè¯æ˜ï¼Œè¯¥ç®—æ³•åœ¨å®ç°è·¨ä»»åŠ¡çš„å¿«é€Ÿè½¬ç§» (Task Transfer) æ–¹é¢å…·æœ‰æ˜¾è‘—ä¼˜åŠ¿ã€‚è¿™ä¸€ç ”ç©¶ä¸ºå¤šä»»åŠ¡å¼ºåŒ–å­¦ä¹ ä¸­çš„è¡¨å¾å­¦ä¹ å’Œé«˜æ•ˆè¿ç§»æä¾›äº†ä¸€ç§åˆ›æ–°çš„å¯¹é½æ–¹æ³•ã€‚",
      "categories": [
        "cs.AI"
      ],
      "primary_category": "cs.AI",
      "comment": "4 pages, 2 figures, accepted as a extended abstract at RLDM 2025",
      "pdf_url": "https://arxiv.org/pdf/2512.01616v1",
      "published_date": "2025-12-01 12:37:01 UTC",
      "updated_date": "2025-12-01 12:37:01 UTC",
      "processing_status": "completed",
      "attempts": 1,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "llm_backup_calls": 0,
      "last_update": "2026-01-26T12:31:35.277948+00:00"
    },
    {
      "arxiv_id": "2512.01582v1",
      "title": "RoleMotion: A Large-Scale Dataset towards Robust Scene-Specific Role-Playing Motion Synthesis with Fine-grained Descriptions",
      "title_zh": "RoleMotionï¼šé¢å‘ç»†ç²’åº¦æè¿°ä¸‹çš„é²æ£’ç‰¹å®šåœºæ™¯è§’è‰²æ‰®æ¼”è¿åŠ¨åˆæˆçš„å¤§è§„æ¨¡æ•°æ®é›†",
      "authors": [
        "Junran Peng",
        "Yiheng Huang",
        "Silei Shen",
        "Zeji Wei",
        "Jingwei Yang",
        "Baojie Wang",
        "Yonghao He",
        "Chuanchen Luo",
        "Man Zhang",
        "Xucheng Yin",
        "Wei Sui"
      ],
      "abstract": "In this paper, we introduce RoleMotion, a large-scale human motion dataset that encompasses a wealth of role-playing and functional motion data tailored to fit various specific scenes. Existing text datasets are mainly constructed decentrally as amalgamation of assorted subsets that their data are nonfunctional and isolated to work together to cover social activities in various scenes. Also, the quality of motion data is inconsistent, and textual annotation lacks fine-grained details in these datasets. In contrast, RoleMotion is meticulously designed and collected with a particular focus on scenes and roles. The dataset features 25 classic scenes, 110 functional roles, over 500 behaviors, and 10296 high-quality human motion sequences of body and hands, annotated with 27831 fine-grained text descriptions. We build an evaluator stronger than existing counterparts, prove its reliability, and evaluate various text-to-motion methods on our dataset. Finally, we explore the interplay of motion generation of body and hands. Experimental results demonstrate the high-quality and functionality of our dataset on text-driven whole-body generation.",
      "tldr_zh": "è¯¥ç ”ç©¶é’ˆå¯¹ç°æœ‰æ–‡æœ¬-åŠ¨ä½œæ•°æ®é›†åˆ†å¸ƒåˆ†æ•£ã€ç¼ºä¹åœºæ™¯é’ˆå¯¹æ€§åŠç»†ç²’åº¦æè¿°çš„é—®é¢˜ï¼Œæå‡ºäº† RoleMotionï¼Œä¸€ä¸ªä¸“æ³¨äºç‰¹å®šåœºæ™¯è§’è‰²æ‰®æ¼”åŠ¨ä½œåˆæˆçš„å¤§è§„æ¨¡æ•°æ®é›†ã€‚è¯¥æ•°æ®é›†ç²¾å¿ƒè®¾è®¡å¹¶æ¶µç›–äº† 25 ä¸ªç»å…¸åœºæ™¯ã€110 ä¸ªåŠŸèƒ½æ€§è§’è‰²å’Œ 500 å¤šç§è¡Œä¸ºï¼Œå…±åŒ…å« 10,296 ä¸ªé«˜è´¨é‡çš„èº«ä½“ä¸æ‰‹éƒ¨åŠ¨ä½œåºåˆ—ï¼Œå¹¶é…æœ‰ 27,831 æ¡ fine-grained æ–‡æœ¬æè¿°ã€‚ç ”ç©¶å›¢é˜Ÿè¿˜æ„å»ºäº†ä¸€ä¸ªæ€§èƒ½ä¼˜äºç°æœ‰å·¥å…·çš„è¯„ä¼°å™¨ï¼Œå¹¶åœ¨è¯¥æ•°æ®é›†ä¸Šå¯¹å¤šç§ text-to-motion æ–¹æ³•è¿›è¡Œäº†å…¨é¢è¯„æµ‹ã€‚æ­¤å¤–ï¼Œè®ºæ–‡æ·±å…¥æ¢è®¨äº†èº«ä½“ä¸æ‰‹éƒ¨åŠ¨ä½œç”Ÿæˆä¹‹é—´çš„ç›¸äº’ä½œç”¨ã€‚å®éªŒç»“æœè¯æ˜ï¼ŒRoleMotion åœ¨æ–‡æœ¬é©±åŠ¨çš„ whole-body generation ä»»åŠ¡ä¸­å…·æœ‰æé«˜çš„è´¨é‡å’Œå®ç”¨ä»·å€¼ï¼Œæ˜¾è‘—æå‡äº†å¤æ‚åœºæ™¯ä¸‹è§’è‰²åŠ¨ä½œåˆæˆçš„é²æ£’æ€§ã€‚",
      "categories": [
        "cs.CV",
        "cs.AI"
      ],
      "primary_category": "cs.CV",
      "comment": "",
      "pdf_url": "https://arxiv.org/pdf/2512.01582v1",
      "published_date": "2025-12-01 11:59:03 UTC",
      "updated_date": "2025-12-01 11:59:03 UTC",
      "processing_status": "completed",
      "attempts": 1,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "llm_backup_calls": 0,
      "last_update": "2026-01-26T12:31:39.080657+00:00"
    },
    {
      "arxiv_id": "2512.01576v1",
      "title": "From Black Hole to Galaxy: Neural Operator: Framework for Accretion and Feedback Dynamics",
      "title_zh": "ä»é»‘æ´åˆ°æ˜Ÿç³»ï¼šå¸ç§¯ä¸åé¦ˆåŠ¨åŠ›å­¦çš„ç¥ç»ç®—å­æ¡†æ¶",
      "authors": [
        "Nihaal Bhojwani",
        "Chuwei Wang",
        "Hai-Yang Wang",
        "Chang Sun",
        "Elias R. Most",
        "Anima Anandkumar"
      ],
      "abstract": "Modeling how supermassive black holes co-evolve with their host galaxies is notoriously hard because the relevant physics spans nine orders of magnitude in scale-from milliparsecs to megaparsecs--making end-to-end first-principles simulation infeasible. To characterize the feedback from the small scales, existing methods employ a static subgrid scheme or one based on theoretical guesses, which usually struggle to capture the time variability and derive physically faithful results. Neural operators are a class of machine learning models that achieve significant speed-up in simulating complex dynamics. We introduce a neural-operator-based ''subgrid black hole'' that learns the small-scale local dynamics and embeds it within the direct multi-level simulations. Trained on small-domain (general relativistic) magnetohydrodynamic data, the model predicts the unresolved dynamics needed to supply boundary conditions and fluxes at coarser levels across timesteps, enabling stable long-horizon rollouts without hand-crafted closures. Thanks to the great speedup in fine-scale evolution, our approach for the first time captures intrinsic variability in accretion-driven feedback, allowing dynamic coupling between the central black hole and galaxy-scale gas. This work reframes subgrid modeling in computational astrophysics with scale separation and provides a scalable path toward data-driven closures for a broad class of systems with central accretors.",
      "tldr_zh": "è¯¥ç ”ç©¶é’ˆå¯¹è¶…å¤§è´¨é‡é»‘æ´ä¸å®¿ä¸»æ˜Ÿç³»å…±åŒæ¼”åŒ–æ¨¡æ‹Ÿä¸­è·¨è¶Šä¹ä¸ªæ•°é‡çº§çš„å°ºåº¦è·¨åº¦éš¾é¢˜ï¼Œæå‡ºäº†ä¸€ç§åŸºäºNeural Operatorçš„â€œå­ç½‘æ ¼é»‘æ´â€æ¡†æ¶ã€‚ä¸ºäº†å…‹æœä¼ ç»Ÿé™æ€å­ç½‘æ ¼æ–¹æ¡ˆéš¾ä»¥æ•æ‰æ—¶é—´å˜ç‡å’Œç‰©ç†å¿ å®åº¦çš„å±€é™æ€§ï¼Œè¯¥æ¨¡å‹é€šè¿‡å­¦ä¹ å°å°ºåº¦å±€åŸŸåŠ¨åŠ›å­¦ï¼Œå°†å…¶ç›´æ¥åµŒå…¥åˆ°å¤šçº§æ¨¡æ‹Ÿä¸­ã€‚è¯¥æ¨¡å‹åœ¨å°åŒºåŸŸ(GRMHD)æ•°æ®ä¸Šè¿›è¡Œè®­ç»ƒï¼Œèƒ½å¤Ÿé¢„æµ‹ç²—ç³™å±‚çº§æ‰€éœ€çš„è¾¹ç•Œæ¡ä»¶å’Œé€šé‡ï¼Œæ”¯æŒç¨³å®šçš„é•¿æ—¶ç¨‹rolloutsï¼Œä¸”æ— éœ€äººå·¥è®¾è®¡çš„é—­åˆæ–¹æ¡ˆã€‚ç”±äºåœ¨ç»†å°ºåº¦æ¼”åŒ–ä¸Šçš„æ˜¾è‘—åŠ é€Ÿï¼Œè¯¥æ–¹æ³•é¦–æ¬¡æ•æ‰åˆ°äº†å¸ç§¯é©±åŠ¨åé¦ˆçš„å†…åœ¨å˜ç‡(intrinsic variability)ï¼Œå®ç°äº†ä¸­å¤®é»‘æ´ä¸æ˜Ÿç³»çº§æ°”ä½“ä¹‹é—´çš„åŠ¨æ€è€¦åˆã€‚è¿™é¡¹å·¥ä½œé€šè¿‡å°ºåº¦åˆ†ç¦»é‡æ–°å®šä¹‰äº†è®¡ç®—å¤©ä½“ç‰©ç†ä¸­çš„å­ç½‘æ ¼å»ºæ¨¡ï¼Œä¸ºå…·æœ‰ä¸­å¿ƒå¸ç§¯å™¨çš„å¤æ‚ç³»ç»Ÿæä¾›äº†å¯æ‰©å±•çš„æ•°æ®é©±åŠ¨é—­åˆè·¯å¾„ã€‚",
      "categories": [
        "astro-ph.HE",
        "astro-ph.GA",
        "cs.AI",
        "gr-qc"
      ],
      "primary_category": "astro-ph.HE",
      "comment": "ML4PS Workshop, Neurips 2025 accepted",
      "pdf_url": "https://arxiv.org/pdf/2512.01576v1",
      "published_date": "2025-12-01 11:47:49 UTC",
      "updated_date": "2025-12-01 11:47:49 UTC",
      "processing_status": "completed",
      "attempts": 1,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "llm_backup_calls": 0,
      "last_update": "2026-01-26T12:31:39.363792+00:00"
    },
    {
      "arxiv_id": "2512.01572v2",
      "title": "Reconstructing Multi-Scale Physical Fields from Extremely Sparse Measurements with an Autoencoder-Diffusion Cascade",
      "title_zh": "åŸºäºè‡ªåŠ¨ç¼–ç å™¨-æ‰©æ•£çº§è”çš„æç¨€ç–æµ‹é‡å¤šå°ºåº¦ç‰©ç†åœºé‡å»º",
      "authors": [
        "Letian Yi",
        "Tingpeng Zhang",
        "Mingyuan Zhou",
        "Guannan Wang",
        "Quanke Su",
        "Zhilu Lai"
      ],
      "abstract": "Reconstructing full fields from extremely sparse and random measurements constitutes a fundamentally ill-posed inverse problem, in which deterministic end-to-end mappings often break down due to intrinsic non-uniqueness and uncertainty. Rather than treating sparse reconstruction as a regression task, we recast it as a hierarchical probabilistic inference problem, where uncertainty is explicitly represented, structured, and progressively resolved. From this perspective, we propose Cascaded Sensing (Cas-Sensing) as a general reconstruction paradigm for multi-scale physical fields under extreme data sparsity. Central to this paradigm is the introduction of an explicit intermediate representation that decomposes the original ill-posed problem into two substantially better-conditioned subproblems. First, a lightweight neural-operator-based functional autoencoder infers a coarse-scale approximation of the target field from sparse observations acting as an explicit intermediate variable. Rather than modeling multiple scales jointly, this intermediate estimate is deterministically fixed and subsequently used as the sole conditioning input to a conditional diffusion model that generates refined-scale details, yielding a cascaded inference structure with clearly separated reconstruction responsibilities. To ensure robustness under diverse sensing patterns, the diffusion model is trained using a mask-cascade strategy, which exposes it to a distribution of imperfect conditioning structures induced by extreme sparsity. During inference, measurement consistency is enforced through manifold-constrained gradients within a Bayesian posterior framework, ensuring fidelity to sparse observations while preserving data manifold coherence. This cascaded probabilistic formulation substantially alleviates ill-posedness, enabling accurate and stable reconstructions even under extreme sparsity.",
      "tldr_zh": "è¯¥ç ”ç©¶é’ˆå¯¹æç¨€ç–å’Œéšæœºæµ‹é‡ä¸‹çš„ç‰©ç†åœºé‡å»ºè¿™ä¸€ç—…æ€é€†é—®é¢˜ï¼Œæå‡ºäº†Cascaded Sensing (Cas-Sensing) çº§è”é‡å»ºèŒƒå¼ï¼Œå°†å…¶è½¬åŒ–ä¸ºåˆ†å±‚æ¦‚ç‡æ¨ç†è¿‡ç¨‹ã€‚è¯¥èŒƒå¼é¦–å…ˆåˆ©ç”¨åŸºäºNeural-Operatorçš„Functional Autoencoderä»ç¨€ç–è§‚æµ‹ä¸­æ¨æ–­å‡ºç›®æ ‡åœºçš„Coarse-scaleè¿‘ä¼¼ä½œä¸ºä¸­é—´è¡¨ç¤ºï¼Œä»è€Œå°†å¤æ‚é—®é¢˜åˆ†è§£ä¸ºä¸¤ä¸ªæ›´æ˜“å¤„ç†çš„å­é—®é¢˜ã€‚éšåï¼ŒConditional Diffusionæ¨¡å‹ä»¥è¯¥ä¸­é—´ä¼°è®¡ä¸ºæ¡ä»¶ï¼Œç”ŸæˆRefined-scaleçš„ç²¾ç»†ç»†èŠ‚ï¼Œå®ç°äº†é‡å»ºèŒè´£çš„æ˜ç¡®åˆ†å·¥ã€‚ä¸ºäº†æé«˜åœ¨æç«¯ç¨€ç–ä¸‹çš„é²æ£’æ€§ï¼Œç ”ç©¶é‡‡ç”¨äº†Mask-cascadeè®­ç»ƒç­–ç•¥ï¼Œå¹¶åœ¨æ¨ç†é˜¶æ®µé€šè¿‡Bayesian Posterioræ¡†æ¶ä¸‹çš„Manifold-constrained Gradientsç¡®ä¿ç»“æœä¸è§‚æµ‹æ•°æ®çš„ä¸€è‡´æ€§ã€‚è¿™ç§çº§è”æ¦‚ç‡å»ºæ¨¡æ–¹æ³•æ˜¾è‘—ç¼“è§£äº†é‡å»ºè¿‡ç¨‹ä¸­çš„ä¸ç¡®å®šæ€§ï¼Œä¸ºåœ¨æä½é‡‡æ ·ç‡ä¸‹å®ç°ç¨³å®šã€é«˜ç²¾åº¦çš„å¤šå°ºåº¦ç‰©ç†åœºé‡å»ºæä¾›äº†æœ‰æ•ˆæ–¹æ¡ˆã€‚",
      "categories": [
        "cs.LG",
        "cs.AI",
        "physics.app-ph"
      ],
      "primary_category": "cs.LG",
      "comment": "20 pages,13 figures",
      "pdf_url": "https://arxiv.org/pdf/2512.01572v2",
      "published_date": "2025-12-01 11:46:14 UTC",
      "updated_date": "2026-01-16 05:07:11 UTC",
      "processing_status": "completed",
      "attempts": 1,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "llm_backup_calls": 0,
      "last_update": "2026-01-26T12:31:48.059059+00:00"
    },
    {
      "arxiv_id": "2512.01568v1",
      "title": "Do Large Language Models Walk Their Talk? Measuring the Gap Between Implicit Associations, Self-Report, and Behavioral Altruism",
      "title_zh": "å¤§è¯­è¨€æ¨¡å‹æ˜¯å¦è¨€è¡Œä¸€è‡´ï¼Ÿè¡¡é‡å†…éšå…³è”ã€è‡ªæˆ‘æŠ¥å‘Šä¸åˆ©ä»–è¡Œä¸ºä¹‹é—´çš„å·®è·",
      "authors": [
        "Sandro Andric"
      ],
      "abstract": "We investigate whether Large Language Models (LLMs) exhibit altruistic tendencies, and critically, whether their implicit associations and self-reports predict actual altruistic behavior. Using a multi-method approach inspired by human social psychology, we tested 24 frontier LLMs across three paradigms: (1) an Implicit Association Test (IAT) measuring implicit altruism bias, (2) a forced binary choice task measuring behavioral altruism, and (3) a self-assessment scale measuring explicit altruism beliefs. Our key findings are: (1) All models show strong implicit pro-altruism bias (mean IAT = 0.87, p < .0001), confirming models \"know\" altruism is good. (2) Models behave more altruistically than chance (65.6% vs. 50%, p < .0001), but with substantial variation (48-85%). (3) Implicit associations do not predict behavior (r = .22, p = .29). (4) Most critically, models systematically overestimate their own altruism, claiming 77.5% altruism while acting at 65.6% (p < .0001, Cohen's d = 1.08). This \"virtue signaling gap\" affects 75% of models tested. Based on these findings, we recommend the Calibration Gap (the discrepancy between self-reported and behavioral values) as a standardized alignment metric. Well-calibrated models are more predictable and behaviorally consistent; only 12.5% of models achieve the ideal combination of high prosocial behavior and accurate self-knowledge.",
      "tldr_zh": "è¯¥ç ”ç©¶æ¢è®¨äº†å¤§å‹è¯­è¨€æ¨¡å‹(LLMs)æ˜¯å¦å…·æœ‰åˆ©ä»–å€¾å‘ï¼Œå¹¶é‡ç‚¹è¯„ä¼°äº†å…¶å†…éšå…³è”ã€è‡ªæˆ‘æŠ¥å‘Šä¸å®é™…åˆ©ä»–è¡Œä¸ºä¹‹é—´çš„å·®è·ã€‚ç ”ç©¶äººå‘˜é‡‡ç”¨å—äººç±»ç¤¾ä¼šå¿ƒç†å­¦å¯å‘çš„å¤šç§æ–¹æ³•ï¼Œå¯¹24ä¸ªå‰æ²¿LLMsè¿›è¡Œäº†å†…éšå…³è”æµ‹è¯•(IAT)ã€è¡Œä¸ºåˆ©ä»–æ€§é€‰æ‹©ä»»åŠ¡å’Œæ˜¾æ€§åˆ©ä»–ä¿¡å¿µè‡ªæˆ‘è¯„ä¼°ã€‚å®éªŒç»“æœæ˜¾ç¤ºï¼Œè™½ç„¶æ¨¡å‹æ™®éè¡¨ç°å‡ºå¼ºçƒˆçš„å†…éšäº²åˆ©ä»–åè§(Implicit Association Bias)ä¸”è¡Œä¸ºè¾ƒéšæœºæ°´å¹³æ›´å…·åˆ©ä»–æ€§ï¼Œä½†å…¶å†…éšå…³è”å¹¶ä¸èƒ½æœ‰æ•ˆé¢„æµ‹å®é™…è¡Œä¸ºã€‚å…³é”®å‘ç°æŒ‡å‡ºï¼Œ75%çš„æ¨¡å‹å­˜åœ¨â€œç¾å¾·ä¿¡å·å·®è·â€(Virtue Signaling Gap)ï¼Œå³ç³»ç»Ÿæ€§åœ°é«˜ä¼°è‡ªèº«çš„åˆ©ä»–ç¨‹åº¦ï¼Œå…¶å®é™…åˆ©ä»–è¡¨ç°(65.6%)æ˜¾è‘—ä½äºè‡ªæˆ‘å®£ç§°æ°´å¹³(77.5%)ã€‚ä¸ºæ­¤ï¼Œç ”ç©¶å»ºè®®å°†è‡ªæˆ‘æŠ¥å‘Šä¸è¡Œä¸ºä»·å€¼ä¹‹é—´çš„â€œæ ¡å‡†å·®è·â€(Calibration Gap)ä½œä¸ºä¸€ç§æ ‡å‡†åŒ–çš„æ¨¡å‹å¯¹é½æŒ‡æ ‡ã€‚ç›®å‰ä»…æœ‰12.5%çš„æ¨¡å‹èƒ½è¾¾åˆ°é«˜äº²ç¤¾ä¼šè¡Œä¸ºä¸å‡†ç¡®è‡ªæˆ‘è®¤çŸ¥çš„ç†æƒ³ç»“åˆï¼Œè¯¥ç ”ç©¶ä¸ºè¯„ä¼°å’Œä¼˜åŒ–æ¨¡å‹çš„è¡Œä¸ºä¸€è‡´æ€§æä¾›äº†é‡è¦å‚è€ƒã€‚",
      "categories": [
        "cs.LG",
        "cs.AI",
        "cs.CL",
        "cs.CY"
      ],
      "primary_category": "cs.LG",
      "comment": "14 pages, 7 figures, 7 tables. Code and data available at https://github.com/sandroandric/LLMs_Altruism_Study_Code",
      "pdf_url": "https://arxiv.org/pdf/2512.01568v1",
      "published_date": "2025-12-01 11:43:02 UTC",
      "updated_date": "2025-12-01 11:43:02 UTC",
      "processing_status": "completed",
      "attempts": 1,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "llm_backup_calls": 0,
      "last_update": "2026-01-26T12:32:56.079865+00:00"
    },
    {
      "arxiv_id": "2512.01565v1",
      "title": "Deep FlexQP: Accelerated Nonlinear Programming via Deep Unfolding",
      "title_zh": "Deep FlexQPï¼šåŸºäºæ·±åº¦å±•å¼€çš„åŠ é€Ÿéçº¿æ€§è§„åˆ’",
      "authors": [
        "Alex Oshin",
        "Rahul Vodeb Ghosh",
        "Augustinos D. Saravanos",
        "Evangelos A. Theodorou"
      ],
      "abstract": "We propose an always-feasible quadratic programming (QP) optimizer, FlexQP, which is based on an exact relaxation of the QP constraints. If the original constraints are feasible, then the optimizer finds the optimal solution to the original QP. On the other hand, if the constraints are infeasible, the optimizer identifies a solution that minimizes the constraint violation in a sparse manner. FlexQP scales favorably with respect to the problem dimension, is robust to both feasible and infeasible QPs with minimal assumptions on the problem data, and can be effectively warm-started. We subsequently apply deep unfolding to improve our optimizer through data-driven techniques, leading to an accelerated Deep FlexQP. By learning dimension-agnostic feedback policies for the parameters from a small number of training examples, Deep FlexQP generalizes to problems with larger dimensions and can optimize for many more iterations than it was initially trained for. Our approach outperforms two recently proposed state-of-the-art accelerated QP approaches on a suite of benchmark systems including portfolio optimization, classification, and regression problems. We provide guarantees on the expected performance of our deep QP optimizer through probably approximately correct (PAC) Bayes generalization bounds. These certificates are used to design an accelerated sequential quadratic programming solver that solves nonlinear optimal control and predictive safety filter problems faster than traditional approaches. Overall, our approach is very robust and greatly outperforms existing non-learning and learning-based optimizers in terms of both runtime and convergence to the optimal solution across multiple classes of NLPs.",
      "tldr_zh": "è¯¥ç ”ç©¶æå‡ºäº† FlexQPï¼Œä¸€ç§åŸºäº QP çº¦æŸç²¾ç¡®æ¾å¼›çš„å§‹ç»ˆå¯è¡Œ Quadratic Programming ä¼˜åŒ–å™¨ï¼Œæ—¨åœ¨ç¡®ä¿åœ¨çº¦æŸå¯è¡Œæ—¶æ‰¾åˆ°æœ€ä¼˜è§£ï¼Œå¹¶åœ¨ä¸å¯è¡Œæ—¶å®ç°çº¦æŸè¿åçš„ç¨€ç–æœ€å°åŒ–ã€‚é€šè¿‡å¼•å…¥ Deep Unfolding æŠ€æœ¯ï¼Œç ”ç©¶è€…å¼€å‘äº†åŠ é€Ÿç‰ˆçš„ Deep FlexQPï¼Œåˆ©ç”¨æ•°æ®é©±åŠ¨å­¦ä¹ ç»´åº¦æ— å…³çš„åé¦ˆç­–ç•¥ï¼Œä½¿å…¶èƒ½æœ‰æ•ˆæ¨å¹¿è‡³æ›´å¤§è§„æ¨¡çš„é—®é¢˜å’Œæ›´å¤šè¿­ä»£æ¬¡æ•°ã€‚è¯¥æ–¹æ³•åœ¨æŠ•èµ„ç»„åˆä¼˜åŒ–ã€åˆ†ç±»åŠå›å½’ç­‰åŸºå‡†æµ‹è¯•ä¸­å‡ä¼˜äºç°æœ‰çš„å…ˆè¿›åŠ é€Ÿ QP æ‰‹æ®µï¼Œå¹¶é€šè¿‡ PAC-Bayes æ³›åŒ–ç•Œé™æä¾›äº†é¢„æœŸçš„æ€§èƒ½ä¿è¯ã€‚æ­¤å¤–ï¼ŒDeep FlexQP è¢«æˆåŠŸæ•´åˆè¿›åºåˆ—äºŒæ¬¡è§„åˆ’(SQP)æ±‚è§£å™¨ï¼Œæ˜¾è‘—æå‡äº†å¤„ç†éçº¿æ€§æœ€ä¼˜æ§åˆ¶å’Œé¢„æµ‹å®‰å…¨è¿‡æ»¤é—®é¢˜çš„é€Ÿåº¦ã€‚å®éªŒç»“æœæ˜¾ç¤ºï¼Œè¯¥æ–¹æ³•åœ¨è¿è¡Œæ—¶é—´å’Œæ”¶æ•›é€Ÿåº¦ä¸Šå‡å¤§å¹…è¶…è¶Šäº†ç°æœ‰çš„éå­¦ä¹ åŠåŸºäºå­¦ä¹ çš„ä¼˜åŒ–å™¨ï¼Œä¸ºå¤šç§ç±»å‹çš„ NLP é—®é¢˜æä¾›äº†æå…¶é²æ£’ä¸”é«˜æ•ˆçš„è§£å†³æ–¹æ¡ˆã€‚",
      "categories": [
        "math.OC",
        "cs.AI"
      ],
      "primary_category": "math.OC",
      "comment": "",
      "pdf_url": "https://arxiv.org/pdf/2512.01565v1",
      "published_date": "2025-12-01 11:38:45 UTC",
      "updated_date": "2025-12-01 11:38:45 UTC",
      "processing_status": "completed",
      "attempts": 1,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "llm_backup_calls": 0,
      "last_update": "2026-01-26T12:33:16.166594+00:00"
    },
    {
      "arxiv_id": "2512.01563v2",
      "title": "MasHeNe: A Benchmark for Head and Neck CT Mass Segmentation using Window-Enhanced Mamba with Frequency-Domain Integration",
      "title_zh": "MasHeNeï¼šåŸºäºé¢‘åŸŸé›†æˆçª—å¢å¼º Mamba çš„å¤´é¢ˆéƒ¨ CT è‚¿å—åˆ†å‰²åŸºå‡†",
      "authors": [
        "Thao Thi Phuong Dao",
        "Tan-Cong Nguyen",
        "Nguyen Chi Thanh",
        "Truong Hoang Viet",
        "Trong-Le Do",
        "Mai-Khiem Tran",
        "Minh-Khoi Pham",
        "Trung-Nghia Le",
        "Minh-Triet Tran",
        "Thanh Dinh Le"
      ],
      "abstract": "Head and neck masses are space-occupying lesions that can compress the airway and esophagus and may affect nerves and blood vessels. Available public datasets primarily focus on malignant lesions and often overlook other space-occupying conditions in this region. To address this gap, we introduce MasHeNe, an initial dataset of 3,779 contrast-enhanced CT slices that includes both tumors and cysts with pixel-level annotations. We also establish a benchmark using standard segmentation baselines and report common metrics to enable fair comparison. In addition, we propose the Windowing-Enhanced Mamba with Frequency integration (WEMF) model. WEMF applies tri-window enhancement to enrich the input appearance before feature extraction. It further uses multi-frequency attention to fuse information across skip connections within a U-shaped Mamba backbone. On MasHeNe, WEMF attains the best performance among evaluated methods, with a Dice of 70.45%, IoU of 66.89%, NSD of 72.33%, and HD95 of 5.12 mm. This model indicates stable and strong results on this challenging task. MasHeNe provides a benchmark for head-and-neck mass segmentation beyond malignancy-only datasets. The observed error patterns also suggest that this task remains challenging and requires further research. Our dataset and code are available at https://github.com/drthaodao3101/MasHeNe.git.",
      "tldr_zh": "è¯¥ç ”ç©¶é’ˆå¯¹ç°æœ‰å…¬å¼€æ•°æ®é›†ä¸»è¦é›†ä¸­äºæ¶æ€§ç—…å˜è€Œå¿½è§†å¤´é¢ˆéƒ¨å…¶ä»–å ä½æ€§ç—…å˜çš„é—®é¢˜ï¼Œæ¨å‡ºäº† MasHeNe åŸºå‡†æ•°æ®é›†ï¼ŒåŒ…å«3,779å¼ æ¶µç›–è‚¿ç˜¤å’Œå›Šè‚¿çš„åƒç´ çº§æ ‡æ³¨å¢å¼º CT åˆ‡ç‰‡ã€‚ä¸ºåº”å¯¹å¤æ‚çš„åˆ†å‰²ä»»åŠ¡ï¼Œç ”ç©¶è€…æå‡ºäº† WEMF (Windowing-Enhanced Mamba with Frequency integration) æ¨¡å‹ï¼Œåˆ©ç”¨ä¸‰çª—å£å¢å¼º (tri-window enhancement) æŠ€æœ¯åœ¨ç‰¹å¾æå–å‰ä¸°å¯Œè¾“å…¥å›¾åƒçš„è¡¨ç°ã€‚è¯¥æ¨¡å‹é‡‡ç”¨äº† U-shaped Mamba éª¨å¹²ç½‘ç»œï¼Œå¹¶é€šè¿‡å¤šé¢‘ç‡æ³¨æ„åŠ› (multi-frequency attention) æœºåˆ¶åœ¨è·³è·ƒè¿æ¥ä¸­æœ‰æ•ˆèåˆç‰¹å¾ä¿¡æ¯ã€‚å®éªŒç»“æœæ˜¾ç¤ºï¼ŒWEMF åœ¨ MasHeNe æ•°æ®é›†ä¸Šå–å¾—äº† 70.45% çš„ Dice ç³»æ•°ã€66.89% çš„ IoU ä»¥åŠ 5.12 mm çš„ HD95ï¼Œåœ¨æ‰€æœ‰è¯„ä¼°æ–¹æ³•ä¸­è¡¨ç°æœ€ä¼˜ã€‚MasHeNe å¡«è¡¥äº†éæ¶æ€§å¤´é¢ˆéƒ¨ç—…å˜æ•°æ®é›†çš„ç©ºç™½ï¼Œå…¶ç ”ç©¶ç»“æœè¡¨æ˜è¯¥ä»»åŠ¡ä»å…·æœ‰è¾ƒé«˜çš„æŒ‘æˆ˜æ€§ï¼Œä¸ºåç»­çš„åŒ»å­¦å½±åƒåˆ†ææä¾›äº†é‡è¦çš„å‚è€ƒåŸºå‡†ã€‚",
      "categories": [
        "cs.CV",
        "cs.AI"
      ],
      "primary_category": "cs.CV",
      "comment": "The 14th International Symposium on Information and Communication Technology Conference SoICT 2025",
      "pdf_url": "https://arxiv.org/pdf/2512.01563v2",
      "published_date": "2025-12-01 11:38:05 UTC",
      "updated_date": "2025-12-02 13:53:01 UTC",
      "processing_status": "completed",
      "attempts": 1,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "llm_backup_calls": 0,
      "last_update": "2026-01-26T12:33:22.056337+00:00"
    },
    {
      "arxiv_id": "2512.01556v1",
      "title": "LEC: Linear Expectation Constraints for False-Discovery Control in Selective Prediction and Routing Systems",
      "title_zh": "LECï¼šé€‰æ‹©æ€§é¢„æµ‹ä¸è·¯ç”±ç³»ç»Ÿä¸­ç”¨äºé”™è¯¯å‘ç°æ§åˆ¶çš„çº¿æ€§æœŸæœ›çº¦æŸ",
      "authors": [
        "Zhiyuan Wang",
        "Aniri",
        "Tianlong Chen",
        "Yue Zhang",
        "Heng Tao Shen",
        "Xiaoshuang Shi",
        "Kaidi Xu"
      ],
      "abstract": "Large language models (LLMs) often generate unreliable answers, while heuristic uncertainty methods fail to fully distinguish correct from incorrect predictions, causing users to accept erroneous answers without statistical guarantees. We address this issue through the lens of false discovery rate (FDR) control, ensuring that among all accepted predictions, the proportion of errors does not exceed a target risk level. To achieve this in a principled way, we propose LEC, which reinterprets selective prediction as a constrained decision problem by enforcing a Linear Expectation Constraint over selection and error indicators. Then, we establish a finite-sample sufficient condition, which relies only on a held-out set of exchangeable calibration samples, to compute an FDR-constrained, coverage-maximizing threshold. Furthermore, we extend LEC to a two-model routing mechanism: given a prompt, if the current model's uncertainty exceeds its calibrated threshold, we delegate it to a stronger model, while maintaining a unified FDR guarantee. Evaluations on closed-ended and open-ended question-answering (QA) datasets show that LEC achieves tighter FDR control and substantially improves sample retention over prior methods. Moreover, the two-model routing mechanism achieves lower risk levels while accepting more correct samples than each individual model.",
      "tldr_zh": "è¯¥ç ”ç©¶é’ˆå¯¹å¤§å‹è¯­è¨€æ¨¡å‹ (LLMs) ç”Ÿæˆç­”æ¡ˆä¸å¯é ä¸”å¯å‘å¼ä¸ç¡®å®šæ€§æ–¹æ³•ç¼ºä¹ç»Ÿè®¡ä¿è¯çš„é—®é¢˜ï¼Œæå‡ºäº† LEC (Linear Expectation Constraints) æ¡†æ¶ï¼Œç”¨äºå®ç°é€‰æ‹©æ€§é¢„æµ‹ (Selective Prediction) å’Œè·¯ç”±ç³»ç»Ÿä¸­çš„é”™è¯¯å‘ç°ç‡ (FDR) æ§åˆ¶ã€‚LEC å°†é€‰æ‹©æ€§é¢„æµ‹é‡æ–°å®šä¹‰ä¸ºä¸€ä¸ªå—çº¦æŸçš„å†³ç­–é—®é¢˜ï¼Œé€šè¿‡åœ¨é€‰æ‹©å’Œé”™è¯¯æŒ‡æ ‡ä¸Šæ–½åŠ çº¿æ€§æœŸæœ›çº¦æŸï¼Œå¹¶åˆ©ç”¨å¯äº¤æ¢çš„æ ¡å‡†æ ·æœ¬ (Calibration Samples) è®¡ç®—å‡ºåœ¨æ»¡è¶³ FDR çº¦æŸä¸‹çš„è¦†ç›–ç‡æœ€å¤§åŒ–é˜ˆå€¼ã€‚æ­¤å¤–ï¼Œè¯¥ç ”ç©¶å°† LEC æ‰©å±•åˆ°åŒæ¨¡å‹è·¯ç”±æœºåˆ¶ (Two-model Routing Mechanism)ï¼Œå½“æ¨¡å‹ä¸ç¡®å®šæ€§è¶…è¿‡é˜ˆå€¼æ—¶å°†ä»»åŠ¡å§”æ‰˜ç»™æ›´å¼ºçš„æ¨¡å‹ï¼Œä»è€Œåœ¨ç»´æŒç»Ÿä¸€ FDR ä¿è¯çš„åŒæ—¶ä¼˜åŒ–æ€§èƒ½ã€‚åœ¨é—­å£å’Œå¼€å£é—®ç­” (QA) æ•°æ®é›†ä¸Šçš„å®éªŒç»“æœæ˜¾ç¤ºï¼ŒLEC å®ç°äº†æ¯”ç°æœ‰æ–¹æ³•æ›´ä¸¥å¯†çš„ FDR æ§åˆ¶ï¼Œå¹¶æ˜¾è‘—æå‡äº†æ ·æœ¬ç•™å­˜ç‡ã€‚åŒæ¨¡å‹è·¯ç”±æœºåˆ¶ä¸ä»…é™ä½äº†é£é™©æ°´å¹³ï¼Œè¿˜æ¯”å•ä¸€æ¨¡å‹æ¥å—äº†æ›´å¤šæ­£ç¡®çš„é¢„æµ‹æ ·æœ¬ï¼Œä¸ºç¡®ä¿ AI ç³»ç»Ÿè¾“å‡ºçš„å¯é æ€§æä¾›äº†åšå®çš„ç†è®ºæ”¯æ’‘ã€‚",
      "categories": [
        "cs.AI",
        "cs.CL",
        "cs.LG"
      ],
      "primary_category": "cs.AI",
      "comment": "",
      "pdf_url": "https://arxiv.org/pdf/2512.01556v1",
      "published_date": "2025-12-01 11:27:09 UTC",
      "updated_date": "2025-12-01 11:27:09 UTC",
      "processing_status": "completed",
      "attempts": 1,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "llm_backup_calls": 0,
      "last_update": "2026-01-26T12:33:22.467093+00:00"
    },
    {
      "arxiv_id": "2512.01549v1",
      "title": "Delta Sum Learning: an approach for fast and global convergence in Gossip Learning",
      "title_zh": "Delta Sum Learningï¼šä¸€ç§å®ç° Gossip Learning å¿«é€Ÿå…¨å±€æ”¶æ•›çš„æ–¹æ³•",
      "authors": [
        "Tom Goethals",
        "Merlijn Sebrechts",
        "Stijn De Schrijver",
        "Filip De Turck",
        "Bruno Volckaert"
      ],
      "abstract": "Federated Learning is a popular approach for distributed learning due to its security and computational benefits. With the advent of powerful devices in the network edge, Gossip Learning further decentralizes Federated Learning by removing centralized integration and relying fully on peer to peer updates. However, the averaging methods generally used in both Federated and Gossip Learning are not ideal for model accuracy and global convergence. Additionally, there are few options to deploy Learning workloads in the edge as part of a larger application using a declarative approach such as Kubernetes manifests. This paper proposes Delta Sum Learning as a method to improve the basic aggregation operation in Gossip Learning, and implements it in a decentralized orchestration framework based on Open Application Model, which allows for dynamic node discovery and intent-driven deployment of multi-workload applications. Evaluation results show that Delta Sum performance is on par with alternative integration methods for 10 node topologies, but results in a 58% lower global accuracy drop when scaling to 50 nodes. Overall, it shows strong global convergence and a logarithmic loss of accuracy with increasing topology size compared to a linear loss for alternatives under limited connectivity.",
      "tldr_zh": "è¯¥ç ”ç©¶é’ˆå¯¹ Gossip Learning åœ¨è¾¹ç¼˜ç½‘ç»œ (network edge) ä¸­å­˜åœ¨çš„èšåˆæ•ˆç‡ä½å’Œå…¨å±€æ”¶æ•›æ€§ (global convergence) ä¸è¶³ç­‰é—®é¢˜ï¼Œæå‡ºäº† Delta Sum Learning èšåˆæ–¹æ³•ã€‚è¯¥æ–¹æ³•æ—¨åœ¨æ”¹è¿› Gossip Learning çš„åŸºç¡€èšåˆæ“ä½œï¼Œå¹¶å°†å…¶é›†æˆåœ¨åŸºäºå¼€æ”¾åº”ç”¨æ¨¡å‹ (Open Application Model, OAM) çš„å»ä¸­å¿ƒåŒ–ç¼–æ’æ¡†æ¶ä¸­ï¼Œä»è€Œå®ç°å¤šè´Ÿè½½åº”ç”¨çš„åŠ¨æ€èŠ‚ç‚¹å‘ç°å’Œæ„å›¾é©±åŠ¨éƒ¨ç½²ã€‚å®éªŒç»“æœè¡¨æ˜ï¼ŒDelta Sum Learning åœ¨ 10 èŠ‚ç‚¹æ‹“æ‰‘ä¸‹çš„æ€§èƒ½ä¸ç°æœ‰æ–¹æ³•ç›¸å½“ï¼Œä½†åœ¨æ‰©å±•è‡³ 50 èŠ‚ç‚¹æ—¶ï¼Œå…¶å…¨å±€å‡†ç¡®ç‡ä¸‹é™å¹…åº¦æ¯”ä¼ ç»Ÿæ–¹æ³•ä½ 58%ã€‚æ­¤å¤–ï¼Œè¯¥æ–¹æ³•åœ¨æœ‰é™è¿æ¥ç¯å¢ƒä¸‹è¡¨ç°å‡ºå¼ºåŠ²çš„å…¨å±€æ”¶æ•›ç‰¹æ€§ï¼Œå…¶å‡†ç¡®ç‡æŸå¤±éšæ‹“æ‰‘è§„æ¨¡çš„æ‰©å¤§ä»…å‘ˆå¯¹æ•°çº§å¢é•¿ï¼Œæ˜¾è‘—ä¼˜äºæ›¿ä»£æ–¹æ¡ˆçš„çº¿æ€§å¢é•¿è¶‹åŠ¿ã€‚",
      "categories": [
        "cs.DC",
        "cs.AI"
      ],
      "primary_category": "cs.DC",
      "comment": "",
      "pdf_url": "https://arxiv.org/pdf/2512.01549v1",
      "published_date": "2025-12-01 11:23:51 UTC",
      "updated_date": "2025-12-01 11:23:51 UTC",
      "processing_status": "completed",
      "attempts": 1,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "llm_backup_calls": 0,
      "last_update": "2026-01-26T12:33:19.953293+00:00"
    },
    {
      "arxiv_id": "2512.01546v1",
      "title": "LPCD: Unified Framework from Layer-Wise to Submodule Quantization",
      "title_zh": "LPCDï¼šä»é€å±‚åˆ°å­æ¨¡å—é‡åŒ–çš„ç»Ÿä¸€æ¡†æ¶",
      "authors": [
        "Yuma Ichikawa",
        "Yudai Fujimoto",
        "Akira Sakai"
      ],
      "abstract": "Post-training quantization (PTQ) aims to preserve model-level behavior; however, most methods focus on individual linear layers. Even recent extensions, such as QEP and LoaQ, which mitigate error propagation or target specific submodules, still rely on layer-wise formulations and fail to capture the behavior of larger submodules. We introduce Layer-Projected Coordinate Descent (LPCD), a unified framework that extends PTQ beyond layers by optimizing relaxed objectives across arbitrary submodules and projecting the solutions with layer-wise quantizers. LPCD generalizes existing methods and provides a principled approach to quantizing complex submodules while maintaining the efficiency and compatibility of layer-wise PTQ pipelines. Across diverse LLM architectures and bit-widths, LPCD-based submodule quantization consistently enhances both layer-wise PTQ methods and existing submodule approaches.",
      "tldr_zh": "è¯¥ç ”ç©¶é’ˆå¯¹è®­ç»ƒåé‡åŒ– (Post-training quantization, PTQ) åœ¨æ•æ‰å¤§å‹å­æ¨¡å—è¡Œä¸ºæ–¹é¢çš„å±€é™æ€§ï¼Œæå‡ºäº†åä¸º LPCD (Layer-Projected Coordinate Descent) çš„ç»Ÿä¸€æ¡†æ¶ã€‚LPCD å°†é‡åŒ–ä¼˜åŒ–ä»å•ä¸€çº¿æ€§å±‚æ‰©å±•è‡³ä»»æ„å­æ¨¡å— (submodules)ï¼Œé€šè¿‡åœ¨å­æ¨¡å—ä¸Šä¼˜åŒ–æ¾å¼›ç›®æ ‡å¹¶åˆ©ç”¨å±‚çº§é‡åŒ–å™¨ (layer-wise quantizers) è¿›è¡ŒæŠ•å½±ï¼Œå®ç°äº†å¯¹å¤æ‚ç»“æ„çš„åŸåˆ™æ€§é‡åŒ–ã€‚è¯¥æ–¹æ³•æœ‰æ•ˆæ³›åŒ–äº†ç°æœ‰æŠ€æœ¯ï¼ŒåŒæ—¶ä¿æŒäº†å±‚çº§ PTQ æµç¨‹çš„é«˜æ•ˆæ€§ä¸å…¼å®¹æ€§ã€‚å®éªŒç»“æœè¯æ˜ï¼Œåœ¨å¤šç§å¤§è¯­è¨€æ¨¡å‹ (LLM) æ¶æ„å’Œä¸åŒä½å®½ (bit-widths) è®¾ç½®ä¸‹ï¼ŒåŸºäº LPCD çš„å­æ¨¡å—é‡åŒ–å‡èƒ½æŒç»­å¢å¼ºç°æœ‰å±‚çº§åŠå­æ¨¡å—é‡åŒ–æ–¹æ³•çš„æ€§èƒ½ã€‚",
      "categories": [
        "stat.ML",
        "cs.AI",
        "cs.CL",
        "cs.LG"
      ],
      "primary_category": "stat.ML",
      "comment": "21 pages, 4 figures",
      "pdf_url": "https://arxiv.org/pdf/2512.01546v1",
      "published_date": "2025-12-01 11:21:18 UTC",
      "updated_date": "2025-12-01 11:21:18 UTC",
      "processing_status": "completed",
      "attempts": 1,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "llm_backup_calls": 0,
      "last_update": "2026-01-26T12:33:26.783503+00:00"
    },
    {
      "arxiv_id": "2512.01537v1",
      "title": "Q2D2: A Geometry-Aware Audio Codec Leveraging Two-Dimensional Quantization",
      "title_zh": "Q2D2ï¼šä¸€ç§åˆ©ç”¨äºŒç»´é‡åŒ–çš„å‡ ä½•æ„ŸçŸ¥éŸ³é¢‘ç¼–è§£ç å™¨",
      "authors": [
        "Tal Shuster",
        "Eliya Nachmani"
      ],
      "abstract": "Recent neural audio codecs have achieved impressive reconstruction quality, typically relying on quantization methods such as Residual Vector Quantization (RVQ), Vector Quantization (VQ) and Finite Scalar Quantization (FSQ). However, these quantization techniques limit the geometric structure of the latent space, make it harder to capture correlations between features leading to inefficiency in representation learning, codebook utilization and token rate. In this paper we introduce Two Dimensional Quantization (Q2D2), a quantization scheme in which feature pairs are projected onto structured 2D grids such as hexagonal, rhombic, or rectangular tiling and quantized to the nearest grid values, yielding an implicit codebook defined by the product of grid levels, with codebook sizes comparable to conventional methods. Despite its simple geometric formulation, Q2D2 improves audio compression efficiency, with low token rates and high codebook utilization while maintaining state of the art reconstruction quality. Specifically, Q2D2 achieves competitive to superior performance in various objective and subjective reconstruction metrics, across extensive experiments in speech domain compared to state of the art models. Comprehensive ablation studies further confirm the effectiveness of our design choices.",
      "tldr_zh": "è¯¥ç ”ç©¶é’ˆå¯¹ç¥ç»éŸ³é¢‘ç¼–è§£ç å™¨ä¸­å¸¸ç”¨çš„æ®‹å·®çŸ¢é‡é‡åŒ–(Residual Vector Quantization, RVQ)ã€çŸ¢é‡é‡åŒ–(VQ)å’Œæœ‰é™æ ‡é‡é‡åŒ–(FSQ)ç­‰æŠ€æœ¯åœ¨æ½œç©ºé—´å‡ ä½•ç»“æ„é™åˆ¶ã€ç‰¹å¾ç›¸å…³æ€§æ•æ‰ä¸è¶³åŠç æœ¬åˆ©ç”¨ç‡(codebook utilization)ä½ç­‰é—®é¢˜ï¼Œæå‡ºäº†Q2D2ï¼ˆTwo Dimensional Quantizationï¼ŒäºŒç»´é‡åŒ–ï¼‰æ–¹æ¡ˆã€‚Q2D2é€šè¿‡å°†ç‰¹å¾å¯¹æŠ•å½±åˆ°å…­è¾¹å½¢ã€è±å½¢æˆ–çŸ©å½¢æ‹¼è´´ç­‰ç»“æ„åŒ–çš„äºŒç»´ç½‘æ ¼ä¸Šï¼Œå¹¶å°†æ•°å€¼é‡åŒ–ä¸ºæœ€æ¥è¿‘çš„ç½‘æ ¼ç‚¹ï¼Œä»è€Œæ„å»ºå‡ºç”±ç½‘æ ¼çº§åˆ«ä¹˜ç§¯å®šä¹‰çš„éšå¼ç æœ¬ã€‚è¿™ç§å‡ ä½•æ„ŸçŸ¥çš„é‡åŒ–æœºåˆ¶åœ¨ä¿æŒæé«˜ç æœ¬åˆ©ç”¨ç‡çš„åŒæ—¶ï¼Œæ˜¾è‘—æå‡äº†éŸ³é¢‘å‹ç¼©æ•ˆç‡å¹¶é™ä½äº†ä»¤ç‰Œé€Ÿç‡(token rate)ã€‚å®éªŒè¯æ˜ï¼ŒQ2D2åœ¨è¯­éŸ³é¢†åŸŸçš„å„é¡¹å®¢è§‚å’Œä¸»è§‚é‡å»ºæŒ‡æ ‡ä¸Šå‡å±•ç°å‡ºä¼˜äºæˆ–ç­‰åŒäºå½“å‰æœ€å…ˆè¿›(state of the art)æ¨¡å‹çš„æ€§èƒ½ã€‚é€šè¿‡å…¨é¢çš„æ¶ˆèå®éªŒï¼Œè¯¥ç ”ç©¶è¿›ä¸€æ­¥éªŒè¯äº†äºŒç»´é‡åŒ–åœ¨æ”¹è¿›è¡¨ç¤ºå­¦ä¹ å’Œç»´æŒé«˜é‡å»ºè´¨é‡æ–¹é¢çš„è®¾è®¡ä¼˜åŠ¿ã€‚",
      "categories": [
        "cs.SD",
        "cs.AI",
        "cs.IT",
        "cs.LG",
        "eess.SP"
      ],
      "primary_category": "cs.SD",
      "comment": "",
      "pdf_url": "https://arxiv.org/pdf/2512.01537v1",
      "published_date": "2025-12-01 11:06:38 UTC",
      "updated_date": "2025-12-01 11:06:38 UTC",
      "processing_status": "completed",
      "attempts": 1,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "llm_backup_calls": 0,
      "last_update": "2026-01-26T12:33:31.561969+00:00"
    },
    {
      "arxiv_id": "2512.01534v1",
      "title": "Deep Unsupervised Anomaly Detection in Brain Imaging: Large-Scale Benchmarking and Bias Analysis",
      "title_zh": "è„‘å½±åƒæ·±åº¦æ— ç›‘ç£å¼‚å¸¸æ£€æµ‹ï¼šå¤§è§„æ¨¡åŸºå‡†è¯„ä¼°ä¸åå·®åˆ†æ",
      "authors": [
        "Alexander Frotscher",
        "Christian F. Baumgartner",
        "Thomas Wolfers"
      ],
      "abstract": "Deep unsupervised anomaly detection in brain magnetic resonance imaging offers a promising route to identify pathological deviations without requiring lesion-specific annotations. Yet, fragmented evaluations, heterogeneous datasets, and inconsistent metrics have hindered progress toward clinical translation. Here, we present a large-scale, multi-center benchmark of deep unsupervised anomaly detection for brain imaging. The training cohort comprised 2,976 T1 and 2,972 T2-weighted scans from healthy individuals across six scanners, with ages ranging from 6 to 89 years. Validation used 92 scans to tune hyperparameters and estimate unbiased thresholds. Testing encompassed 2,221 T1w and 1,262 T2w scans spanning healthy datasets and diverse clinical cohorts. Across all algorithms, the Dice-based segmentation performance varied between 0.03 and 0.65, indicating substantial variability. To assess robustness, we systematically evaluated the impact of different scanners, lesion types and sizes, as well as demographics (age, sex). Reconstruction-based methods, particularly diffusion-inspired approaches, achieved the strongest lesion segmentation performance, while feature-based methods showed greater robustness under distributional shifts. However, systematic biases, such as scanner-related effects, were observed for the majority of algorithms, including that small and low-contrast lesions were missed more often, and that false positives varied with age and sex. Increasing healthy training data yields only modest gains, underscoring that current unsupervised anomaly detection frameworks are limited algorithmically rather than by data availability. Our benchmark establishes a transparent foundation for future research and highlights priorities for clinical translation, including image native pretraining, principled deviation measures, fairness-aware modeling, and robust domain adaptation.",
      "tldr_zh": "è¯¥ç ”ç©¶é’ˆå¯¹è„‘éƒ¨ç£å…±æŒ¯æˆåƒ(MRI)å¼€å±•äº†å¤§è§„æ¨¡ã€å¤šä¸­å¿ƒçš„æ·±åº¦æ— ç›‘ç£å¼‚å¸¸æ£€æµ‹(Deep unsupervised anomaly detection)åŸºå‡†æµ‹è¯•ï¼Œæ—¨åœ¨è§£å†³è¯„ä¼°æ ‡å‡†ä¸ç»Ÿä¸€å’Œæ•°æ®é›†å¼‚æ„ç­‰é˜»ç¢ä¸´åºŠè½¬åŒ–çš„é—®é¢˜ã€‚ç ”ç©¶å›¢é˜Ÿåˆ©ç”¨è¦†ç›–ä¸åŒå¹´é¾„æ®µã€æ¥è‡ªå¤šå°æ‰«æä»ªçš„è¿‘3000ä»½å¥åº·æ ·æœ¬è¿›è¡Œè®­ç»ƒï¼Œå¹¶åœ¨åŒ…å«å¤šç§ä¸´åºŠé˜Ÿåˆ—çš„å¤§å‹æµ‹è¯•é›†ä¸Šå¯¹ç®—æ³•æ€§èƒ½è¿›è¡Œäº†ç³»ç»Ÿè¯„ä¼°ã€‚å®éªŒç»“æœæ˜¾ç¤ºå„ç®—æ³•åœ¨Diceåˆ†å‰²æŒ‡æ ‡ä¸Šå­˜åœ¨æ˜¾è‘—å·®å¼‚ï¼Œå…¶ä¸­åŸºäºé‡å»º(Reconstruction-based)çš„æ–¹æ³•åœ¨ç—…ç¶åˆ†å‰²æ€§èƒ½ä¸Šè¡¨ç°æœ€å¼ºï¼Œè€ŒåŸºäºç‰¹å¾(Feature-based)çš„æ–¹æ³•åœ¨åˆ†å¸ƒåç§»ä¸‹æ›´å…·é²æ£’æ€§ã€‚ç ”ç©¶å‘ç°å½“å‰ç®—æ³•æ™®éå­˜åœ¨ç³»ç»Ÿæ€§åå·®ï¼Œå®¹æ˜“é—æ¼å¾®å°æˆ–ä½å¯¹æ¯”åº¦ç—…ç¶ï¼Œä¸”è¯¯æŠ¥ç‡å—æ‰«æä»ªæ•ˆåº”åŠäººå£ç»Ÿè®¡å­¦å› ç´ å½±å“ã€‚æ­¤å¤–ï¼Œå¢åŠ è®­ç»ƒæ•°æ®é‡å¸¦æ¥çš„æ€§èƒ½æå‡æœ‰é™ï¼Œè¡¨æ˜æŠ€æœ¯ç“¶é¢ˆä¸»è¦æºäºç®—æ³•æ¡†æ¶è€Œéæ•°æ®è§„æ¨¡ã€‚è¯¥åŸºå‡†æµ‹è¯•ä¸ºæœªæ¥ç ”ç©¶å¥ å®šäº†é€æ˜çš„åŸºç¡€ï¼Œå¹¶æŒ‡å‡ºå›¾åƒåŸç”Ÿé¢„è®­ç»ƒ(Image native pretraining)ã€å…¬å¹³æ„ŸçŸ¥å»ºæ¨¡(Fairness-aware modeling)å’Œé²æ£’åŸŸè‡ªé€‚åº”(Robust domain adaptation)æ˜¯å®ç°ä¸´åºŠè½¬åŒ–çš„å…³é”®æ–¹å‘ã€‚",
      "categories": [
        "cs.CV",
        "cs.AI"
      ],
      "primary_category": "cs.CV",
      "comment": "",
      "pdf_url": "https://arxiv.org/pdf/2512.01534v1",
      "published_date": "2025-12-01 11:03:27 UTC",
      "updated_date": "2025-12-01 11:03:27 UTC",
      "processing_status": "completed",
      "attempts": 1,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "llm_backup_calls": 0,
      "last_update": "2026-01-26T12:33:37.679325+00:00"
    },
    {
      "arxiv_id": "2512.01533v1",
      "title": "Diffusion Fuzzy System: Fuzzy Rule Guided Latent Multi-Path Diffusion Modeling",
      "title_zh": "æ‰©æ•£æ¨¡ç³Šç³»ç»Ÿï¼šæ¨¡ç³Šè§„åˆ™å¼•å¯¼çš„æ½œç©ºé—´å¤šè·¯å¾„æ‰©æ•£å»ºæ¨¡",
      "authors": [
        "Hailong Yang",
        "Te Zhang",
        "Kup-sze Choi",
        "Zhaohong Deng"
      ],
      "abstract": "Diffusion models have emerged as a leading technique for generating images due to their ability to create high-resolution and realistic images. Despite their strong performance, diffusion models still struggle in managing image collections with significant feature differences. They often fail to capture complex features and produce conflicting results. Research has attempted to address this issue by learning different regions of an image through multiple diffusion paths and then combining them. However, this approach leads to inefficient coordination among multiple paths and high computational costs. To tackle these issues, this paper presents a Diffusion Fuzzy System (DFS), a latent-space multi-path diffusion model guided by fuzzy rules. DFS offers several advantages. First, unlike traditional multi-path diffusion methods, DFS uses multiple diffusion paths, each dedicated to learning a specific class of image features. By assigning each path to a different feature type, DFS overcomes the limitations of multi-path models in capturing heterogeneous image features. Second, DFS employs rule-chain-based reasoning to dynamically steer the diffusion process and enable efficient coordination among multiple paths. Finally, DFS introduces a fuzzy membership-based latent-space compression mechanism to reduce the computational costs of multi-path diffusion effectively. We tested our method on three public datasets: LSUN Bedroom, LSUN Church, and MS COCO. The results show that DFS achieves more stable training and faster convergence than existing single-path and multi-path diffusion models. Additionally, DFS surpasses baseline models in both image quality and alignment between text and images, and also shows improved accuracy when comparing generated images to target references.",
      "tldr_zh": "è¯¥ç ”ç©¶æå‡ºäº† Diffusion Fuzzy System (DFS)ï¼Œè¿™æ˜¯ä¸€ç§ç”±æ¨¡ç³Šè§„åˆ™ (fuzzy rules) å¼•å¯¼çš„æ½œç©ºé—´å¤šè·¯å¾„æ‰©æ•£æ¨¡å‹ï¼Œæ—¨åœ¨è§£å†³ç°æœ‰æ‰©æ•£æ¨¡å‹åœ¨å¤„ç†å¼‚è´¨å›¾åƒç‰¹å¾æ—¶æ•è·èƒ½åŠ›ä¸è¶³ä»¥åŠå¤šè·¯å¾„åä½œæ•ˆç‡ä½ã€è®¡ç®—æˆæœ¬é«˜ç­‰é—®é¢˜ã€‚DFS é€šè¿‡åˆ†é…å¤šä¸ªæ‰©æ•£è·¯å¾„åˆ†åˆ«å­¦ä¹ ç‰¹å®šçš„å›¾åƒç‰¹å¾ç±»åˆ«ï¼Œæœ‰æ•ˆå…‹æœäº†ä¼ ç»Ÿæ¨¡å‹åœ¨å¤„ç†å¤æ‚å›¾åƒé›†åˆæ—¶çš„å±€é™æ€§ã€‚ç³»ç»Ÿé‡‡ç”¨åŸºäºè§„åˆ™é“¾çš„æ¨ç† (rule-chain-based reasoning) æœºåˆ¶æ¥åŠ¨æ€å¼•å¯¼æ‰©æ•£è¿‡ç¨‹ï¼Œå®ç°äº†å¤šè·¯å¾„é—´çš„é«˜æ•ˆåè°ƒã€‚æ­¤å¤–ï¼Œç ”ç©¶è¿˜å¼•å…¥äº†åŸºäºæ¨¡ç³Šéš¶å±åº¦ (fuzzy membership-based) çš„æ½œç©ºé—´å‹ç¼©æœºåˆ¶ï¼Œæ˜¾è‘—é™ä½äº†è®¡ç®—å¼€é”€ã€‚åœ¨ LSUN Bedroomã€LSUN Church å’Œ MS COCO æ•°æ®é›†ä¸Šçš„å®éªŒç»“æœè¡¨æ˜ï¼ŒDFS æ¯”ç°æœ‰çš„å•è·¯å¾„å’Œå¤šè·¯å¾„æ¨¡å‹å…·æœ‰æ›´ç¨³å®šçš„è®­ç»ƒè¡¨ç°å’Œæ›´å¿«çš„æ”¶æ•›é€Ÿåº¦ã€‚æœ€ç»ˆï¼ŒDFS åœ¨å›¾åƒè´¨é‡ã€æ–‡ç”Ÿå›¾å¯¹é½åº¦ä»¥åŠç”Ÿæˆå›¾åƒçš„å‡†ç¡®æ€§æ–¹é¢å‡è¶…è¶Šäº†åŸºçº¿æ¨¡å‹ã€‚",
      "categories": [
        "cs.CV",
        "cs.AI"
      ],
      "primary_category": "cs.CV",
      "comment": "",
      "pdf_url": "https://arxiv.org/pdf/2512.01533v1",
      "published_date": "2025-12-01 11:01:06 UTC",
      "updated_date": "2025-12-01 11:01:06 UTC",
      "processing_status": "completed",
      "attempts": 1,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "llm_backup_calls": 0,
      "last_update": "2026-01-26T12:33:45.273645+00:00"
    },
    {
      "arxiv_id": "2512.01523v1",
      "title": "Teaching an Online Multi-Institutional Research Level Software Engineering Course with Industry -- an Experience Report",
      "title_zh": "è”åˆå·¥ä¸šç•Œå¼€å±•è·¨æ ¡åœ¨çº¿ç ”ç©¶çº§è½¯ä»¶å·¥ç¨‹è¯¾ç¨‹æ•™å­¦ï¼šç»éªŒæŠ¥å‘Š",
      "authors": [
        "Pankaj Jalote",
        "Y. Raghu Reddy",
        "Vasudeva Varma"
      ],
      "abstract": "Covid has made online teaching and learning acceptable and students, faculty, and industry professionals are all comfortable with this mode. This comfort can be leveraged to offer an online multi-institutional research-level course in an area where individual institutions may not have the requisite faculty to teach and/or research students to enroll. If the subject is of interest to industry, online offering also allows industry experts to contribute and participate with ease. Advanced topics in Software Engineering are ideally suited for experimenting with this approach as industry, which is often looking to incorporate advances in software engineering in their practices, is likely to agree to contribute and participate. In this paper we describe an experiment in teaching a course titled \"AI in Software Engineering\" jointly between two institutions with active industry participation, and share our and student's experience. We believe this collaborative teaching approach can be used for offering research level courses in any applied area of computer science by institutions who are small and find it difficult to offer research level courses on their own.",
      "tldr_zh": "è¯¥ç ”ç©¶æä¾›äº†ä¸€ä»½å…³äºå¤šæœºæ„è”åˆå¼€å±•å·¥ä¸šç•Œå‚ä¸çš„åœ¨çº¿ç ”ç©¶çº§ Software Engineering è¯¾ç¨‹çš„ç»éªŒæŠ¥å‘Šã€‚åœ¨ COVID-19 æå‡äº†åœ¨çº¿æ•™å­¦æ¥å—åº¦çš„èƒŒæ™¯ä¸‹ï¼Œç ”ç©¶è€…é€šè¿‡æ•´åˆä¸¤æ‰€é«˜æ ¡çš„èµ„æºå¹¶å¼•å…¥è¡Œä¸šä¸“å®¶ï¼ŒæˆåŠŸå¼€è®¾äº†åä¸º â€œAI in Software Engineeringâ€ çš„å‰æ²¿è¯¾ç¨‹ã€‚è¯¥æ•™å­¦æ¨¡å¼æ—¨åœ¨è§£å†³å°å‹æœºæ„åœ¨å¼€è®¾é«˜çº§ç ”ç©¶è¯¾ç¨‹æ—¶é¢ä¸´çš„å¸ˆèµ„ä¸è¶³å’Œå­¦ç”Ÿè§„æ¨¡å—é™çš„é—®é¢˜ï¼Œå……åˆ†åˆ©ç”¨äº†å·¥ä¸šç•Œå¯¹è½¯ä»¶å·¥ç¨‹å‰æ²¿æŠ€æœ¯çš„å…³æ³¨ä¸å‚ä¸çƒ­æƒ…ã€‚æ–‡ä¸­è¯¦ç»†åˆ†äº«äº†æ•™å­¦å®éªŒçš„è¿‡ç¨‹ã€è¡Œä¸šä¸“å®¶çš„è´¡çŒ®æ–¹å¼ä»¥åŠå¸ˆç”Ÿçš„å®é™…ä½“éªŒè¯„ä»·ã€‚ç ”ç©¶ç»“æœè¡¨æ˜ï¼Œè¿™ç§åä½œæ•™å­¦æ–¹æ³•ä¸ºèµ„æºæœ‰é™çš„æœºæ„æä¾›ç ”ç©¶çº§è¯¾ç¨‹æä¾›äº†å¯è¡Œæ–¹æ¡ˆï¼Œç‰¹åˆ«é€‚ç”¨äºè®¡ç®—æœºç§‘å­¦ç­‰åº”ç”¨ç ”ç©¶é¢†åŸŸã€‚è¯¥ç»éªŒå¯¹äºæ¨åŠ¨å­¦æœ¯ç•Œä¸å·¥ä¸šç•Œçš„æ·±åº¦èåˆä»¥åŠè·¨æ ¡èµ„æºå…±äº«å…·æœ‰é‡è¦çš„å‚è€ƒä»·å€¼ã€‚",
      "categories": [
        "cs.SE",
        "cs.AI",
        "cs.LG"
      ],
      "primary_category": "cs.SE",
      "comment": "7 pages",
      "pdf_url": "https://arxiv.org/pdf/2512.01523v1",
      "published_date": "2025-12-01 10:46:43 UTC",
      "updated_date": "2025-12-01 10:46:43 UTC",
      "processing_status": "completed",
      "attempts": 1,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "llm_backup_calls": 0,
      "last_update": "2026-01-26T12:33:42.570183+00:00"
    },
    {
      "arxiv_id": "2512.01507v1",
      "title": "SynthStrategy: Extracting and Formalizing Latent Strategic Insights from LLMs in Organic Chemistry",
      "title_zh": "SynthStrategyï¼šæå–å¹¶å½¢å¼åŒ–æœ‰æœºåŒ–å­¦å¤§è¯­è¨€æ¨¡å‹ä¸­çš„æ½œåœ¨ç­–ç•¥è§è§£",
      "authors": [
        "Daniel Armstrong",
        "Zlatko JonÄev",
        "Andres M Bran",
        "Philippe Schwaller"
      ],
      "abstract": "Modern computer-assisted synthesis planning (CASP) systems show promises at generating chemically valid reaction steps but struggle to incorporate strategic considerations such as convergent assembly, protecting group minimization, and optimal ring-forming sequences. We introduce a methodology that leverages Large Language Models to distill synthetic knowledge into code. Our system analyzes synthesis routes and translates strategic principles into Python functions representing diverse strategic and tactical rules, such as strategic functional group interconversions and ring construction strategies. By formalizing this knowledge as verifiable code rather than simple heuristics, we create testable, interpretable representations of synthetic strategy. We release the complete codebase and the USPTO-ST dataset -- synthesis routes annotated with strategic tags. This framework unlocks a novel capability for CASP: natural language-based route retrieval, achieving 75\\% Top-3 accuracy on our benchmark. We further validate our library through temporal analysis of historical trends and chemically intuitive route clustering that offers more granular partitioning than common previous methods. This work bridges the tactical-strategic divide in CASP, enabling specification, search, and evaluation of routes by strategic criteria rather than structure alone.",
      "tldr_zh": "è¯¥ç ”ç©¶é’ˆå¯¹ç°ä»£è®¡ç®—æœºè¾…åŠ©åˆæˆè§„åˆ’(CASP)ç³»ç»Ÿåœ¨æ•´åˆæ”¶æ•›æ€§ç»„è£…ã€ä¿æŠ¤åŸºæœ€å°åŒ–ç­‰æˆ˜ç•¥æ€§è€ƒé‡æ–¹é¢çš„ä¸è¶³ï¼Œæå‡ºäº†SynthStrategyæ–¹æ³•ã€‚è¯¥æ–¹æ³•åˆ©ç”¨å¤§è¯­è¨€æ¨¡å‹(LLMs)å°†æœ‰æœºåˆæˆçŸ¥è¯†æå–å¹¶è½¬åŒ–ä¸ºå¯éªŒè¯çš„Pythonå‡½æ•°ï¼Œå®ç°äº†åˆæˆç­–ç•¥ä»ç®€å•å¯å‘å¼è§„åˆ™å‘å¯æµ‹è¯•ã€å¯è§£é‡Šä»£ç çš„è½¬å˜ã€‚ç ”ç©¶å›¢é˜Ÿå‘å¸ƒäº†å®Œæ•´çš„ä»£ç åº“å’Œå¸¦æœ‰æˆ˜ç•¥æ ‡ç­¾çš„USPTO-STæ•°æ®é›†ï¼Œå¹¶å±•ç¤ºäº†åŸºäºè‡ªç„¶è¯­è¨€è¿›è¡Œè·¯å¾„æ£€ç´¢çš„æ–°èƒ½åŠ›ï¼Œåœ¨åŸºå‡†æµ‹è¯•ä¸­è¾¾åˆ°äº†75%çš„Top-3å‡†ç¡®ç‡ã€‚é€šè¿‡å¯¹å†å²è¶‹åŠ¿çš„æ—¶é—´åˆ†æå’Œæ›´ç»†ç²’åº¦çš„è·¯å¾„èšç±»éªŒè¯ï¼Œè¯¥æ¡†æ¶æœ‰æ•ˆå¼¥åˆäº†CASPä¸­çš„æˆ˜æœ¯ä¸æˆ˜ç•¥é¸¿æ²Ÿã€‚è¿™ä¸€æˆæœä¸ä»…æ”¯æŒæ ¹æ®æˆ˜ç•¥æ ‡å‡†è€Œéä»…å‡­ç»“æ„æ¥æœç´¢å’Œè¯„ä¼°è·¯å¾„ï¼Œè¿˜ä¸ºåˆæˆåŒ–å­¦çŸ¥è¯†çš„æ•°å­—åŒ–ä¸å½¢å¼åŒ–æä¾›äº†æ–°çš„èŒƒå¼ã€‚",
      "categories": [
        "cs.AI",
        "cs.LG"
      ],
      "primary_category": "cs.AI",
      "comment": "",
      "pdf_url": "https://arxiv.org/pdf/2512.01507v1",
      "published_date": "2025-12-01 10:33:00 UTC",
      "updated_date": "2025-12-01 10:33:00 UTC",
      "processing_status": "completed",
      "attempts": 1,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "llm_backup_calls": 0,
      "last_update": "2026-01-26T12:34:12.675960+00:00"
    },
    {
      "arxiv_id": "2512.05140v1",
      "title": "FlowEO: Generative Unsupervised Domain Adaptation for Earth Observation",
      "title_zh": "FlowEOï¼šé¢å‘åœ°çƒè§‚æµ‹çš„ç”Ÿæˆå¼æ— ç›‘ç£é¢†åŸŸè‡ªé€‚åº”",
      "authors": [
        "Georges Le Bellier",
        "Nicolas Audebert"
      ],
      "abstract": "The increasing availability of Earth observation data offers unprecedented opportunities for large-scale environmental monitoring and analysis. However, these datasets are inherently heterogeneous, stemming from diverse sensors, geographical regions, acquisition times, and atmospheric conditions. Distribution shifts between training and deployment domains severely limit the generalization of pretrained remote sensing models, making unsupervised domain adaptation (UDA) crucial for real-world applications. We introduce FlowEO, a novel framework that leverages generative models for image-space UDA in Earth observation. We leverage flow matching to learn a semantically preserving mapping that transports from the source to the target image distribution. This allows us to tackle challenging domain adaptation configurations for classification and semantic segmentation of Earth observation images. We conduct extensive experiments across four datasets covering adaptation scenarios such as SAR to optical translation and temporal and semantic shifts caused by natural disasters. Experimental results demonstrate that FlowEO outperforms existing image translation approaches for domain adaptation while achieving on-par or better perceptual image quality, highlighting the potential of flow-matching-based UDA for remote sensing.",
      "tldr_zh": "è¯¥ç ”ç©¶æå‡ºäº†FlowEOï¼Œä¸€ä¸ªåˆ©ç”¨ç”Ÿæˆæ¨¡å‹(generative models)è¿›è¡Œå›¾åƒç©ºé—´æ— ç›‘ç£é¢†åŸŸè‡ªé€‚åº”(Unsupervised Domain Adaptation, UDA)çš„æ–°å‹æ¡†æ¶ï¼Œæ—¨åœ¨è§£å†³åœ°çƒè§‚æµ‹(Earth observation)æ•°æ®å› ä¼ æ„Ÿå™¨ã€åœ°ç†åŠå¤§æ°”æ¡ä»¶å·®å¼‚å¯¼è‡´çš„åˆ†å¸ƒåç§»(distribution shifts)é—®é¢˜ã€‚è¯¥æ¡†æ¶æ ¸å¿ƒåœ¨äºåˆ©ç”¨æµåŒ¹é…(flow matching)æŠ€æœ¯å­¦ä¹ ä¸€ç§è¯­ä¹‰ä¿æŒæ˜ å°„ï¼Œå®ç°ä»æºåŸŸåˆ°ç›®æ ‡åŸŸå›¾åƒåˆ†å¸ƒçš„æœ‰æ•ˆè¿ç§»ï¼Œä»è€Œåº”å¯¹å¤æ‚çš„åˆ†ç±»å’Œè¯­ä¹‰åˆ†å‰²(semantic segmentation)ä»»åŠ¡ã€‚ç ”ç©¶å›¢é˜Ÿåœ¨åŒ…å«åˆæˆå­”å¾„é›·è¾¾(SAR)åˆ°å…‰å­¦è½¬æ¢ã€ä»¥åŠç”±è‡ªç„¶ç¾å®³å¼•èµ·çš„æ—¶é—´å’Œè¯­ä¹‰åç§»ç­‰å››ä¸ªæ•°æ®é›†ä¸Šè¿›è¡Œäº†éªŒè¯ã€‚å®éªŒç»“æœè¡¨æ˜ï¼ŒFlowEOåœ¨é¢†åŸŸè‡ªé€‚åº”æ€§èƒ½ä¸Šä¼˜äºç°æœ‰çš„å›¾åƒç¿»è¯‘æ–¹æ³•ï¼ŒåŒæ—¶åœ¨æ„ŸçŸ¥å›¾åƒè´¨é‡ä¸Šè¾¾åˆ°æˆ–è¶…è¿‡äº†å½“å‰é¢†å…ˆæ°´å¹³ã€‚è¿™é¡¹å·¥ä½œå……åˆ†å±•ç¤ºäº†åŸºäºæµåŒ¹é…çš„UDAåœ¨é¥æ„Ÿé¢†åŸŸæå‡æ¨¡å‹æ³›åŒ–èƒ½åŠ›çš„æ˜¾è‘—æ½œåŠ›ã€‚",
      "categories": [
        "cs.CV",
        "cs.AI"
      ],
      "primary_category": "cs.CV",
      "comment": "2026 IEEE/CVF Winter Conference on Applications of Computer Vision (WACV), Mar 2026, Tucson (AZ), United States",
      "pdf_url": "https://arxiv.org/pdf/2512.05140v1",
      "published_date": "2025-12-01 10:29:01 UTC",
      "updated_date": "2025-12-01 10:29:01 UTC",
      "processing_status": "completed",
      "attempts": 1,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "llm_backup_calls": 0,
      "last_update": "2026-01-26T12:34:25.080126+00:00"
    },
    {
      "arxiv_id": "2512.01502v1",
      "title": "Formal Verification of Noisy Quantum Reinforcement Learning Policies",
      "title_zh": "å«å™ªå£°é‡å­å¼ºåŒ–å­¦ä¹ ç­–ç•¥çš„å½¢å¼åŒ–éªŒè¯",
      "authors": [
        "Dennis Gross"
      ],
      "abstract": "Quantum reinforcement learning (QRL) aims to use quantum effects to create sequential decision-making policies that achieve tasks more effectively than their classical counterparts. However, QRL policies face uncertainty from quantum measurements and hardware noise, such as bit-flip, phase-flip, and depolarizing errors, which can lead to unsafe behavior. Existing work offers no systematic way to verify whether trained QRL policies meet safety requirements under specific noise conditions.\n  We introduce QVerifier, a formal verification method that applies probabilistic model checking to analyze trained QRL policies with and without modeled quantum noise. QVerifier builds a complete model of the policy-environment interaction, incorporates quantum uncertainty directly into the transition probabilities, and then checks safety properties using the Storm model checker.\n  Experiments across multiple QRL environments show that QVerifier precisely measures how different noise models influence safety, revealing both performance degradation and cases where noise can help. By enabling rigorous safety verification before deployment, QVerifier addresses a critical need: because access to quantum hardware is expensive, pre-deployment verification is essential for any safety-critical use of QRL. QVerifier targets a potential classical-quantum sweet spot: trained QRL policies that execute efficiently on quantum hardware, yet remain tractable for classical probabilistic model checking despite being too slow for real-time classical deployment.",
      "tldr_zh": "è¯¥ç ”ç©¶é’ˆå¯¹é‡å­å¼ºåŒ–å­¦ä¹ (Quantum Reinforcement Learning, QRL)ç­–ç•¥åœ¨ç¡¬ä»¶å™ªå£°ï¼ˆå¦‚bit-flip, phase-flipå’Œdepolarizing errorsï¼‰åŠé‡å­æµ‹é‡ä¸ç¡®å®šæ€§ä¸‹å¯èƒ½äº§ç”Ÿçš„å®‰å…¨éšæ‚£ï¼Œæå‡ºäº†QVerifierå½¢å¼åŒ–éªŒè¯æ–¹æ³•ã€‚QVerifieré€šè¿‡æ¦‚ç‡æ¨¡å‹æ£€æµ‹(probabilistic model checking)æŠ€æœ¯ï¼Œå°†é‡å­å™ªå£°ç›´æ¥å»ºæ¨¡åˆ°çŠ¶æ€è½¬ç§»æ¦‚ç‡ä¸­ï¼Œå¹¶åˆ©ç”¨Stormæ£€æµ‹å™¨å¯¹ç­–ç•¥ä¸ç¯å¢ƒçš„äº¤äº’è¿›è¡Œç³»ç»ŸåŒ–åˆ†æã€‚å®éªŒè¡¨æ˜ï¼Œè¯¥æ–¹æ³•èƒ½ç²¾ç¡®é‡åŒ–ä¸åŒå™ªå£°æ¨¡å‹å¯¹å®‰å…¨æ€§çš„å½±å“ï¼Œå¹¶æ­ç¤ºäº†å™ªå£°å¯¼è‡´çš„æ€§èƒ½ä¸‹é™åŠæŸäº›ç‰¹å®šæƒ…å†µä¸‹çš„æ­£å‘ä½œç”¨ã€‚é€šè¿‡å®ç°éƒ¨ç½²å‰çš„ä¸¥è°¨éªŒè¯ï¼ŒQVerifieræœ‰æ•ˆè§£å†³äº†QRLåœ¨å®‰å…¨å…³é”®é¢†åŸŸåº”ç”¨çš„ä¿¡ä»»éš¾é¢˜ã€‚è¯¥ç ”ç©¶è¿˜å±•ç¤ºäº†QRLç­–ç•¥åœ¨é‡å­ç¡¬ä»¶é«˜æ•ˆæ‰§è¡Œä¸ç»å…¸æ¨¡å‹æ£€æµ‹å¯å¤„ç†æ€§ä¹‹é—´çš„ç»“åˆæ½œåŠ›ã€‚",
      "categories": [
        "quant-ph",
        "cs.AI",
        "cs.FL"
      ],
      "primary_category": "quant-ph",
      "comment": "",
      "pdf_url": "https://arxiv.org/pdf/2512.01502v1",
      "published_date": "2025-12-01 10:26:33 UTC",
      "updated_date": "2025-12-01 10:26:33 UTC",
      "processing_status": "completed",
      "attempts": 1,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "llm_backup_calls": 0,
      "last_update": "2026-01-26T12:34:43.563863+00:00"
    },
    {
      "arxiv_id": "2512.01485v2",
      "title": "Multi-Path Collaborative Reasoning via Reinforcement Learning",
      "title_zh": "åŸºäºå¼ºåŒ–å­¦ä¹ çš„å¤šè·¯å¾„ååŒæ¨ç†",
      "authors": [
        "Jindi Lv",
        "Yuhao Zhou",
        "Zheng Zhu",
        "Xiaofeng Wang",
        "Guan Huang",
        "Jiancheng Lv"
      ],
      "abstract": "Chain-of-Thought (CoT) reasoning has significantly advanced the problem-solving capabilities of Large Language Models (LLMs), yet conventional CoT often exhibits internal determinism during decoding, limiting exploration of plausible alternatives. Recent methods attempt to address this by generating soft abstract tokens to enable reasoning in a continuous semantic space. However, we find that such approaches remain constrained by the greedy nature of autoregressive decoding, which fundamentally isolates the model from alternative reasoning possibilities. In this work, we propose Multi-Path Perception Policy Optimization (M3PO), a novel reinforcement learning framework that explicitly injects collective insights into the reasoning process. M3PO leverages parallel policy rollouts as naturally diverse reasoning sources and integrates cross-path interactions into policy updates through a lightweight collaborative mechanism. This design allows each trajectory to refine its reasoning with peer feedback, thereby cultivating more reliable multi-step reasoning patterns. Empirical results show that M3PO achieves state-of-the-art performance on both knowledge- and reasoning-intensive benchmarks. Models trained with M3PO maintain interpretability and inference efficiency, underscoring the promise of multi-path collaborative learning for robust reasoning.",
      "tldr_zh": "è¯¥ç ”ç©¶é’ˆå¯¹ä¼ ç»Ÿæ€ç»´é“¾(Chain-of-Thought)åœ¨è§£ç è¿‡ç¨‹ä¸­å› è‡ªå›å½’è´ªå©ªç­–ç•¥å¯¼è‡´çš„æ¢ç´¢èƒ½åŠ›å—é™é—®é¢˜ï¼Œæå‡ºäº†å¤šè·¯å¾„æ„ŸçŸ¥ç­–ç•¥ä¼˜åŒ–(Multi-Path Perception Policy Optimization, M3PO)å¼ºåŒ–å­¦ä¹ æ¡†æ¶ã€‚è¯¥æ¡†æ¶åˆ©ç”¨å¹¶è¡Œç­–ç•¥å±•å¼€(Parallel Policy Rollouts)ä½œä¸ºå¤šæ ·åŒ–çš„æ¨ç†æ¥æºï¼Œå¹¶é€šè¿‡è½»é‡çº§åä½œæœºåˆ¶å°†è·¨è·¯å¾„äº¤äº’æ•´åˆåˆ°ç­–ç•¥æ›´æ–°ä¸­ã€‚è¿™ç§è®¾è®¡ä½¿æ¯æ¡æ¨ç†è½¨è¿¹èƒ½å¤Ÿåˆ©ç”¨åŒè¡Œåé¦ˆæ¥ç²¾ç‚¼å…¶æ¨ç†è¿‡ç¨‹ï¼Œä»è€ŒåŸ¹å…»å‡ºæ›´å¯é çš„å¤šæ­¥æ¨ç†æ¨¡å¼ã€‚å®éªŒç»“æœè¡¨æ˜ï¼ŒM3POåœ¨çŸ¥è¯†å¯†é›†å‹å’Œæ¨ç†å¯†é›†å‹åŸºå‡†æµ‹è¯•ä¸­å‡è¾¾åˆ°äº†æœ€å…ˆè¿›(State-of-the-Art)çš„æ€§èƒ½æ°´å¹³ã€‚æ­¤å¤–ï¼Œç»ç”±M3POè®­ç»ƒçš„æ¨¡å‹åœ¨æ˜¾è‘—æå‡æ¨ç†é²æ£’æ€§çš„åŒæ—¶ï¼Œä¾ç„¶ä¿æŒäº†è‰¯å¥½çš„å¯è§£é‡Šæ€§ä¸æ¨ç†æ•ˆç‡ï¼Œä¸ºå¢å¼ºå¤§è¯­è¨€æ¨¡å‹çš„å¤æ‚é€»è¾‘æ¨ç†èƒ½åŠ›æä¾›äº†æ–°è·¯å¾„ã€‚",
      "categories": [
        "cs.AI",
        "cs.LG"
      ],
      "primary_category": "cs.AI",
      "comment": "",
      "pdf_url": "https://arxiv.org/pdf/2512.01485v2",
      "published_date": "2025-12-01 10:05:46 UTC",
      "updated_date": "2025-12-08 07:33:30 UTC",
      "processing_status": "completed",
      "attempts": 1,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "llm_backup_calls": 0,
      "last_update": "2026-01-26T12:34:32.671815+00:00"
    },
    {
      "arxiv_id": "2512.01484v1",
      "title": "Multi-view diffusion geometry using intertwined diffusion trajectories",
      "title_zh": "åŸºäºäº¤ç»‡æ‰©æ•£è½¨è¿¹çš„å¤šè§†å›¾æ‰©æ•£å‡ ä½•",
      "authors": [
        "Gwendal Debaussart-Joniec",
        "Argyris Kalogeratos"
      ],
      "abstract": "This paper introduces a comprehensive unified framework for constructing multi-view diffusion geometries through intertwined multi-view diffusion trajectories (MDTs), a class of inhomogeneous diffusion processes that iteratively combine the random walk operators of multiple data views. Each MDT defines a trajectory-dependent diffusion operator with a clear probabilistic and geometric interpretation, capturing over time the interplay between data views. Our formulation encompasses existing multi-view diffusion models, while providing new degrees of freedom for view interaction and fusion. We establish theoretical properties under mild assumptions, including ergodicity of both the point-wise operator and the process in itself. We also derive MDT-based diffusion distances, and associated embeddings via singular value decompositions. Finally, we propose various strategies for learning MDT operators within the defined operator space, guided by internal quality measures. Beyond enabling flexible model design, MDTs also offer a neutral baseline for evaluating diffusion-based approaches through comparison with randomly selected MDTs. Experiments show the practical impact of the MDT operators in a manifold learning and data clustering context.",
      "tldr_zh": "è¯¥ç ”ç©¶æå‡ºäº†ä¸€ä¸ªç”¨äºæ„å»º multi-view diffusion geometries çš„ç»Ÿä¸€æ¡†æ¶ï¼Œå…¶æ ¸å¿ƒæ˜¯å¼•å…¥äº† intertwined multi-view diffusion trajectories (MDTs)ã€‚MDTs æ˜¯ä¸€ç±»éé½æ¬¡æ‰©æ•£è¿‡ç¨‹ï¼Œé€šè¿‡è¿­ä»£ç»“åˆå¤šä¸ªæ•°æ®è§†å›¾çš„ random walk operatorsï¼Œèƒ½å¤Ÿæ•æ‰ä¸åŒè§†å›¾é—´éšæ—¶é—´æ¼”å˜çš„ç›¸äº’ä½œç”¨ã€‚è¯¥æ¡†æ¶ä¸ä»…æ¶µç›–äº†ç°æœ‰çš„ multi-view diffusion modelsï¼Œè¿˜ä¸ºè§†å›¾çš„äº¤äº’ä¸èåˆæä¾›äº†æ›´é«˜çš„è‡ªç”±åº¦ã€‚ç ”ç©¶è€…åœ¨æ¸©å’Œå‡è®¾ä¸‹è¯æ˜äº†è¯¥è¿‡ç¨‹çš„ ergodicityï¼Œå¹¶å¯¼å‡ºäº†åŸºäº MDT çš„ diffusion distances ä»¥åŠé€šè¿‡ singular value decompositions è·å¾—çš„ç›¸å…³ embeddingsã€‚æ­¤å¤–ï¼Œè¯¥å·¥ä½œè¿˜æå‡ºäº†åœ¨å®šä¹‰çš„ç®—å­ç©ºé—´å†…å­¦ä¹  MDT operators çš„ç­–ç•¥ï¼Œå¹¶å°†å…¶ä½œä¸ºè¯„ä¼°æ‰©æ•£æ–¹æ³•çš„åŸºå‡†ã€‚å®éªŒè¡¨æ˜ï¼ŒMDT operators åœ¨ manifold learning å’Œ data clustering ç­‰åº”ç”¨åœºæ™¯ä¸­å…·æœ‰æ˜¾è‘—çš„å®é™…æ•ˆç”¨ã€‚",
      "categories": [
        "cs.LG",
        "cs.AI",
        "stat.ML"
      ],
      "primary_category": "cs.LG",
      "comment": "",
      "pdf_url": "https://arxiv.org/pdf/2512.01484v1",
      "published_date": "2025-12-01 10:05:19 UTC",
      "updated_date": "2025-12-01 10:05:19 UTC",
      "processing_status": "completed",
      "attempts": 1,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "llm_backup_calls": 0,
      "last_update": "2026-01-26T12:34:41.976314+00:00"
    },
    {
      "arxiv_id": "2512.03095v1",
      "title": "Community Quality and Influence Maximization: An Empirical Study",
      "title_zh": "ç¤¾åŒºè´¨é‡ä¸å½±å“æœ€å¤§åŒ–ï¼šä¸€é¡¹å®è¯ç ”ç©¶",
      "authors": [
        "Motaz Ben Hassine"
      ],
      "abstract": "Influence maximization in social networks plays a vital role in applications such as viral marketing, epidemiology, product recommendation, opinion mining, and counter-terrorism. A common approach identifies seed nodes by first detecting disjoint communities and subsequently selecting representative nodes from these communities. However, whether the quality of detected communities consistently affects the spread of influence under the Independent Cascade model remains unclear. This paper addresses this question by extending a previously proposed disjoint community detection method, termed $Î±$-Hierarchical Clustering, to the influence maximization problem under the Independent Cascade model. The proposed method is compared with an alternative approach that employs the same seed selection criteria but relies on communities of lower quality obtained through standard Hierarchical Clustering. The former is referred to as Hierarchical Clustering-based Influence Maximization, while the latter, which leverages higher-quality community structures to guide seed selection, is termed $Î±$-Hierarchical Clustering-based Influence Maximization. Extensive experiments are performed on multiple real-world datasets to assess the effectiveness of both methods. The results demonstrate that higher-quality community structures substantially improve information diffusion under the Independent Cascade model, particularly when the propagation probability is low. These findings underscore the critical importance of community quality in guiding effective seed selection for influence maximization in complex networks.",
      "tldr_zh": "è¿™é¡¹ç ”ç©¶æ¢è®¨äº†ç¤¾äº¤ç½‘ç»œä¸­çš„ç¤¾åŒºè´¨é‡ä¸å½±å“æœ€å¤§åŒ– (Influence Maximization) ä¹‹é—´çš„å…³ç³»ï¼Œé‡ç‚¹åˆ†æäº†åœ¨ç‹¬ç«‹çº§è”æ¨¡å‹ (Independent Cascade model) ä¸‹æ£€æµ‹åˆ°çš„ç¤¾åŒºè´¨é‡å¦‚ä½•å½±å“ä¿¡æ¯ä¼ æ’­ã€‚ä½œè€…æå‡ºäº†ä¸€ç§åŸºäº $\\alpha$-å±‚æ¬¡èšç±»çš„å½±å“æœ€å¤§åŒ– ($\\alpha$-Hierarchical Clustering-based Influence Maximization) æ–¹æ³•ï¼Œé€šè¿‡åˆ©ç”¨æ›´é«˜è´¨é‡çš„ç¤¾åŒºç»“æ„æ¥æŒ‡å¯¼ç§å­é€‰æ‹© (seed selection)ã€‚å®éªŒåœ¨å¤šä¸ªçœŸå®ä¸–ç•Œæ•°æ®é›†ä¸Šå°†è¯¥æ–¹æ³•ä¸åŸºäºæ ‡å‡†å±‚æ¬¡èšç±» (Hierarchical Clustering) çš„æ–¹æ¡ˆè¿›è¡Œäº†å¯¹æ¯”è¯„ä¼°ã€‚ç ”ç©¶ç»“æœè¯æ˜ï¼Œæ›´é«˜è´¨é‡çš„ç¤¾åŒºç»“æ„èƒ½æ˜¾è‘—æå‡ä¿¡æ¯æ‰©æ•£çš„æ•ˆç‡ï¼Œè¿™ç§æå‡åœ¨ä¼ æ’­æ¦‚ç‡ (propagation probability) è¾ƒä½æ—¶å°¤ä¸ºæ˜æ˜¾ã€‚è¯¥å‘ç°å¼ºè°ƒäº†ç¤¾åŒºè´¨é‡åœ¨å¤æ‚ç½‘ç»œå½±å“æœ€å¤§åŒ–ä»»åŠ¡ä¸­çš„æ ¸å¿ƒåœ°ä½ï¼Œä¸ºä¼˜åŒ–ç§å­èŠ‚ç‚¹é€‰æ‹©æä¾›äº†é‡è¦çš„å®è¯ä¾æ®ã€‚",
      "categories": [
        "cs.SI",
        "cs.AI"
      ],
      "primary_category": "cs.SI",
      "comment": "",
      "pdf_url": "https://arxiv.org/pdf/2512.03095v1",
      "published_date": "2025-12-01 09:59:04 UTC",
      "updated_date": "2025-12-01 09:59:04 UTC",
      "processing_status": "completed",
      "attempts": 1,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "llm_backup_calls": 0,
      "last_update": "2026-01-26T12:34:38.571834+00:00"
    },
    {
      "arxiv_id": "2512.01473v1",
      "title": "Does Flatness imply Generalization for Logistic Loss in Univariate Two-Layer ReLU Network?",
      "title_zh": "å•å˜é‡åŒå±‚ ReLU ç½‘ç»œä¸­ Logistic æŸå¤±çš„å¹³å¦æ€§æ˜¯å¦æ„å‘³ç€æ³›åŒ–ï¼Ÿ",
      "authors": [
        "Dan Qiao",
        "Yu-Xiang Wang"
      ],
      "abstract": "We consider the problem of generalization of arbitrarily overparameterized two-layer ReLU Neural Networks with univariate input. Recent work showed that under square loss, flat solutions (motivated by flat / stable minima and Edge of Stability phenomenon) provably cannot overfit, but it remains unclear whether the same phenomenon holds for logistic loss. This is a puzzling open problem because existing work on logistic loss shows that gradient descent with increasing step size converges to interpolating solutions (at infinity, for the margin-separable cases). In this paper, we prove that the \\emph{flatness implied generalization} is more delicate under logistic loss. On the positive side, we show that flat solutions enjoy near-optimal generalization bounds within a region between the left-most and right-most \\emph{uncertain} sets determined by each candidate solution. On the negative side, we show that there exist arbitrarily flat yet overfitting solutions at infinity that are (falsely) certain everywhere, thus certifying that flatness alone is insufficient for generalization in general. We demonstrate the effects predicted by our theory in a well-controlled simulation study.",
      "tldr_zh": "æœ¬ç ”ç©¶æ¢è®¨äº†åœ¨å•å˜é‡ä¸¤å±‚ ReLU Neural Networks ä¸­ï¼ŒLogistic Loss çš„ Flatness æ˜¯å¦å¿…ç„¶æ„å‘³ç€ Generalizationã€‚ä»¥å¾€ç ”ç©¶è¯æ˜åœ¨ Square Loss ä¸‹å¹³å¦è§£èƒ½æœ‰æ•ˆé˜²æ­¢è¿‡æ‹Ÿåˆï¼Œä½† Logistic Loss ä¸‹çš„æƒ…å½¢æ›´ä¸ºå¤æ‚ä¸”æ­¤å‰å°šä¸æ˜ç¡®ã€‚ç ”ç©¶å‘ç°ï¼Œè™½ç„¶å¹³å¦è§£åœ¨ç”±å€™é€‰è§£ç¡®å®šçš„â€œä¸ç¡®å®šâ€é›†åˆï¼ˆuncertain setsï¼‰åŒºåŸŸå†…å…·æœ‰è¿‘ä¹æœ€ä¼˜çš„æ³›åŒ–ç•Œï¼Œä½†ä»…é  Flatness å¹¶ä¸è¶³ä»¥ä¿è¯æ³›åŒ–ã€‚ç ”ç©¶è¿›ä¸€æ­¥æ­ç¤ºäº†åœ¨æ— ç©·è¿œå¤„å­˜åœ¨æåº¦å¹³å¦ä½†ä¾ç„¶ Overfitting çš„è§£ï¼Œè¿™äº›è§£åœ¨æ‰€æœ‰åŒºåŸŸéƒ½è¡¨ç°å‡ºé”™è¯¯çš„ç¡®å®šæ€§ã€‚è¿™ä¸€ç»“æœè¯æ˜äº† Flatness å¯¹ Logistic Loss æ³›åŒ–å½±å“çš„å±€é™æ€§ï¼Œå¹¶å¾—åˆ°äº†å—æ§æ¨¡æ‹Ÿå®éªŒçš„éªŒè¯ã€‚",
      "categories": [
        "cs.LG",
        "cs.AI",
        "stat.ML"
      ],
      "primary_category": "cs.LG",
      "comment": "59 pages",
      "pdf_url": "https://arxiv.org/pdf/2512.01473v1",
      "published_date": "2025-12-01 09:57:11 UTC",
      "updated_date": "2025-12-01 09:57:11 UTC",
      "processing_status": "completed",
      "attempts": 1,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "llm_backup_calls": 0,
      "last_update": "2026-01-26T12:34:47.977643+00:00"
    },
    {
      "arxiv_id": "2512.01457v4",
      "title": "Zero-Overhead Introspection for Adaptive Test-Time Compute",
      "title_zh": "é¢å‘è‡ªé€‚åº”æµ‹è¯•æ—¶è®¡ç®—çš„é›¶å¼€é”€å†…çœ",
      "authors": [
        "Rohin Manvi",
        "Joey Hong",
        "Tim Seyde",
        "Maxime Labonne",
        "Mathias Lechner",
        "Sergey Levine"
      ],
      "abstract": "Large language models excel at reasoning but lack key aspects of introspection, including anticipating their own success and the computation required to achieve it. Humans use real-time introspection to decide how much effort to invest, when to make multiple attempts, when to stop, and when to signal success or failure. Without this, LLMs struggle to make intelligent meta-cognition decisions. Test-time scaling methods like Best-of-N drive up cost and latency by using a fixed budget of samples regardless of the marginal benefit of each one at any point in generation, and the absence of confidence signals can mislead people, prevent appropriate escalation to better tools, and undermine trustworthiness. Learned verifiers or reward models can provide confidence estimates, but do not enable adaptive inference and add substantial cost by requiring extra models or forward passes. We present ZIP-RC, which equips models with zero-overhead introspective predictions of reward and cost. At every token, ZIP-RC reuses reserved or unused logits in the same forward pass as next-token prediction to output a joint distribution over final reward and remaining length -- no extra models, architecture change, or inference overhead. This full joint distribution is used to compute a sampling utility which is the linear combination of the expected maximum reward, total compute, and latency of set of samples if generated to completion. During inference, we maximize this utility with meta-actions that determine which prefix of tokens to continue or initiate sampling from. On mixed-difficulty mathematical benchmarks, ZIP-RC improves accuracy by up to 12% over majority voting at equal or lower average cost, and traces smooth Pareto frontiers between quality, compute, and latency. By providing real-time reward-cost introspection, ZIP-RC enables adaptive, efficient reasoning.",
      "tldr_zh": "è¯¥ç ”ç©¶é’ˆå¯¹å¤§è¯­è¨€æ¨¡å‹(LLMs)ç¼ºä¹å†…çœ(introspection)èƒ½åŠ›ã€æ— æ³•é¢„åˆ¤ä»»åŠ¡æˆåŠŸç‡åŠæ‰€éœ€è®¡ç®—é‡çš„é—®é¢˜ï¼Œæå‡ºäº†ZIP-RCæ¡†æ¶ã€‚ZIP-RCé€šè¿‡é‡ç”¨æ¨¡å‹åœ¨å‰å‘ä¼ æ’­ä¸­ä¿ç•™æˆ–æœªä½¿ç”¨çš„Logitsï¼Œåœ¨é¢„æµ‹ä¸‹ä¸€ä¸ªTokençš„åŒæ—¶ï¼Œå®ç°äº†å¯¹æœ€ç»ˆå¥–åŠ±(reward)å’Œå‰©ä½™é•¿åº¦(cost)çš„è”åˆåˆ†å¸ƒé¢„æµ‹ï¼Œä¸”æ— éœ€é¢å¤–çš„æ¨¡å‹ã€æ¶æ„æ›´æ”¹æˆ–æ¨ç†å¼€é”€ã€‚è¯¥æ¡†æ¶åˆ©ç”¨è¿™ä¸€è”åˆåˆ†å¸ƒè®¡ç®—é‡‡æ ·æ•ˆç”¨ï¼Œåœ¨æ¨ç†è¿‡ç¨‹ä¸­é€šè¿‡æœ€å¤§åŒ–æ•ˆç”¨æ¥æ‰§è¡Œå†³å®šé‡‡æ ·è·¯å¾„çš„å…ƒæ“ä½œ(meta-actions)ï¼Œä»è€ŒåŠ¨æ€è°ƒæ•´æ¨ç†ç­–ç•¥ã€‚å®éªŒç»“æœæ˜¾ç¤ºï¼Œåœ¨æ··åˆéš¾åº¦çš„æ•°å­¦åŸºå‡†æµ‹è¯•ä¸­ï¼ŒZIP-RCåœ¨ç›¸åŒæˆ–æ›´ä½å¹³å‡æˆæœ¬ä¸‹æ¯”å¤šæ•°æŠ•ç¥¨(majority voting)çš„å‡†ç¡®ç‡æå‡äº†é«˜è¾¾12%ï¼Œå¹¶å®ç°äº†è´¨é‡ã€è®¡ç®—ä¸å»¶è¿Ÿä¹‹é—´çš„å¹³æ»‘å¸•ç´¯æ‰˜å‰æ²¿(Pareto frontiers)ã€‚ZIP-RCé€šè¿‡æä¾›å®æ—¶çš„å¥–åŠ±-æˆæœ¬å†…çœèƒ½åŠ›ï¼Œä¸ºè‡ªé€‚åº”ã€é«˜æ•ˆçš„æ¨ç†è¿‡ç¨‹å¥ å®šäº†åŸºç¡€ã€‚",
      "categories": [
        "cs.LG",
        "cs.AI",
        "cs.CL"
      ],
      "primary_category": "cs.LG",
      "comment": "",
      "pdf_url": "https://arxiv.org/pdf/2512.01457v4",
      "published_date": "2025-12-01 09:44:31 UTC",
      "updated_date": "2025-12-23 08:18:03 UTC",
      "processing_status": "completed",
      "attempts": 1,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "llm_backup_calls": 0,
      "last_update": "2026-01-26T12:35:02.989520+00:00"
    },
    {
      "arxiv_id": "2512.01452v1",
      "title": "Automated Risk-of-Bias Assessment of Randomized Controlled Trials: A First Look at a GEPA-trained Programmatic Prompting Framework",
      "title_zh": "éšæœºå¯¹ç…§è¯•éªŒè‡ªåŠ¨åŒ–åå€šé£é™©è¯„ä¼°ï¼šåŸºäº GEPA è®­ç»ƒçš„ç¨‹åºåŒ–æç¤ºæ¡†æ¶åˆæ¢",
      "authors": [
        "Lingbo Li",
        "Anuradha Mathrani",
        "Teo Susnjak"
      ],
      "abstract": "Assessing risk of bias (RoB) in randomized controlled trials is essential for trustworthy evidence synthesis, but the process is resource-intensive and prone to variability across reviewers. Large language models (LLMs) offer a route to automation, but existing methods rely on manually engineered prompts that are difficult to reproduce, generalize, or evaluate. This study introduces a programmable RoB assessment pipeline that replaces ad-hoc prompt design with structured, code-based optimization using DSPy and its GEPA module. GEPA refines LLM reasoning through Pareto-guided search and produces inspectable execution traces, enabling transparent replication of every step in the optimization process. We evaluated the method on 100 RCTs from published meta-analyses across seven RoB domains. GEPA-generated prompts were applied to both open-weight models (Mistral Small 3.1 with GPT-oss-20b) and commercial models (GPT-5 Nano and GPT-5 Mini). In domains with clearer methodological reporting, such as Random Sequence Generation, GEPA-generated prompts performed best, with similar results for Allocation Concealment and Blinding of Participants, while the commercial model performed slightly better overall. We also compared GEPA with three manually designed prompts using Claude 3.5 Sonnet. GEPA achieved the highest overall accuracy and improved performance by 30%-40% in Random Sequence Generation and Selective Reporting, and showed generally comparable, competitively aligned performance in the other domains relative to manual prompts. These findings suggest that GEPA can produce consistent and reproducible prompts for RoB assessment, supporting the structured and principled use of LLMs in evidence synthesis.",
      "tldr_zh": "è¯¥ç ”ç©¶é’ˆå¯¹éšæœºå¯¹ç…§è¯•éªŒï¼ˆRandomized Controlled Trials, RCTsï¼‰ä¸­åå€šé£é™©è¯„ä¼°ï¼ˆRisk-of-Bias, RoBï¼‰è¿‡ç¨‹è€—è´¹èµ„æºä¸”å­˜åœ¨è¯„å®¡å·®å¼‚çš„é—®é¢˜ï¼Œæå‡ºäº†ä¸€ç§ç¨‹åºåŒ–çš„è‡ªåŠ¨åŒ–è¯„ä¼°æ¡†æ¶ã€‚è¯¥æ¡†æ¶åˆ©ç”¨ DSPy åŠå…¶ GEPA æ¨¡å—ï¼Œå°†ä¼ ç»Ÿçš„æ‰‹å·¥æç¤ºè¯å·¥ç¨‹æ›¿æ¢ä¸ºåŸºäºä»£ç çš„ç»“æ„åŒ–ä¼˜åŒ–ï¼Œé€šè¿‡ Pareto å¼•å¯¼çš„æœç´¢ç»†åŒ–å¤§è¯­è¨€æ¨¡å‹ï¼ˆLLMsï¼‰çš„æ¨ç†è¿‡ç¨‹ï¼Œå¹¶ç”Ÿæˆå¯å®¡æŸ¥çš„æ‰§è¡Œè½¨è¿¹ã€‚ç ”ç©¶åœ¨æ¶µç›–ä¸ƒä¸ª RoB ç»´åº¦çš„ 100 ç¯‡ RCTs ä¸Šå¯¹ Mistralã€GPT-5 ç­‰æ¨¡å‹è¿›è¡Œäº†è¯„ä¼°ï¼Œç»“æœæ˜¾ç¤º GEPA ç”Ÿæˆçš„æç¤ºè¯åœ¨éšæœºåºåˆ—äº§ç”Ÿï¼ˆRandom Sequence Generationï¼‰å’Œé€‰æ‹©æ€§æŠ¥å‘Šï¼ˆSelective Reportingï¼‰é¢†åŸŸçš„å‡†ç¡®ç‡æ¯”äººå·¥æç¤ºè¯æé«˜äº† 30%-40%ã€‚åœ¨å…¶ä»–ç»´åº¦ä¸Šï¼Œè¯¥æ–¹æ³•ä¹Ÿå±•ç°å‡ºä¸å•†ä¸šæ¨¡å‹ç›¸å½“çš„ç«äº‰æ€§èƒ½ï¼Œç¡®ä¿äº†è¯„ä¼°è¿‡ç¨‹çš„å¯å¤ç°æ€§ã€‚è¿™äº›å‘ç°è¡¨æ˜ï¼ŒGEPA èƒ½å¤Ÿä¸ºåå€šé£é™©è¯„ä¼°ç”Ÿæˆä¸€è‡´ä¸”é€æ˜çš„æç¤ºè¯ï¼Œä¸ºåœ¨è¯æ®åˆæˆï¼ˆEvidence Synthesisï¼‰ä¸­è§„èŒƒåŒ–åº”ç”¨å¤§è¯­è¨€æ¨¡å‹å¥ å®šäº†åŸºç¡€ã€‚",
      "categories": [
        "cs.AI"
      ],
      "primary_category": "cs.AI",
      "comment": "",
      "pdf_url": "https://arxiv.org/pdf/2512.01452v1",
      "published_date": "2025-12-01 09:39:13 UTC",
      "updated_date": "2025-12-01 09:39:13 UTC",
      "processing_status": "completed",
      "attempts": 1,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "llm_backup_calls": 0,
      "last_update": "2026-01-26T12:34:50.574933+00:00"
    },
    {
      "arxiv_id": "2512.01442v1",
      "title": "PSA-MF: Personality-Sentiment Aligned Multi-Level Fusion for Multimodal Sentiment Analysis",
      "title_zh": "PSA-MFï¼šé¢å‘å¤šæ¨¡æ€æƒ…æ„Ÿåˆ†æçš„äººæ ¼-æƒ…æ„Ÿå¯¹é½å¤šçº§èåˆ",
      "authors": [
        "Heng Xie",
        "Kang Zhu",
        "Zhengqi Wen",
        "Jianhua Tao",
        "Xuefei Liu",
        "Ruibo Fu",
        "Changsheng Li"
      ],
      "abstract": "Multimodal sentiment analysis (MSA) is a research field that recognizes human sentiments by combining textual, visual, and audio modalities. The main challenge lies in integrating sentiment-related information from different modalities, which typically arises during the unimodal feature extraction phase and the multimodal feature fusion phase. Existing methods extract only shallow information from unimodal features during the extraction phase, neglecting sentimental differences across different personalities. During the fusion phase, they directly merge the feature information from each modality without considering differences at the feature level. This ultimately affects the model's recognition performance. To address this problem, we propose a personality-sentiment aligned multi-level fusion framework. We introduce personality traits during the feature extraction phase and propose a novel personality-sentiment alignment method to obtain personalized sentiment embeddings from the textual modality for the first time. In the fusion phase, we introduce a novel multi-level fusion method. This method gradually integrates sentimental information from textual, visual, and audio modalities through multimodal pre-fusion and a multi-level enhanced fusion strategy. Our method has been evaluated through multiple experiments on two commonly used datasets, achieving state-of-the-art results.",
      "tldr_zh": "è¯¥ç ”ç©¶é’ˆå¯¹å¤šæ¨¡æ€æƒ…æ„Ÿåˆ†æ(MSA)ä¸­å•æ¨¡æ€ç‰¹å¾æå–æµ…å±‚åŒ–åŠå¤šæ¨¡æ€èåˆç¼ºä¹å±‚æ¬¡æ€§çš„é—®é¢˜ï¼Œæå‡ºäº†åä¸ºPSA-MFçš„äººæ ¼-æƒ…æ„Ÿå¯¹é½å¤šçº§èåˆæ¡†æ¶ã€‚è¯¥æ¡†æ¶åœ¨ç‰¹å¾æå–é˜¶æ®µé¦–æ¬¡å¼•å…¥äººæ ¼ç‰¹è´¨(Personality traits)ï¼Œé€šè¿‡ä¸€ç§æ–°é¢–çš„äººæ ¼-æƒ…æ„Ÿå¯¹é½(Personality-sentiment alignment)æ–¹æ³•ï¼Œä»æ–‡æœ¬æ¨¡æ€ä¸­æå–ä¸ªæ€§åŒ–çš„æƒ…æ„ŸåµŒå…¥ã€‚åœ¨èåˆé˜¶æ®µï¼Œç ”ç©¶è€…è®¾è®¡äº†å¤šçº§èåˆæ–¹æ³•ï¼Œåˆ©ç”¨å¤šæ¨¡æ€é¢„èåˆä¸å¤šçº§å¢å¼ºèåˆç­–ç•¥ï¼Œé€æ­¥æ•´åˆæ–‡æœ¬ã€è§†è§‰å’ŒéŸ³é¢‘æ¨¡æ€ä¸­çš„æƒ…æ„Ÿä¿¡æ¯ã€‚å®éªŒç»“æœè¡¨æ˜ï¼ŒPSA-MFåœ¨ä¸¤ä¸ªä¸»æµæ•°æ®é›†ä¸Šå‡å–å¾—äº†SOTAæ€§èƒ½ï¼Œè¯æ˜äº†ç»“åˆäººæ ¼å·®å¼‚ä¸å±‚æ¬¡åŒ–ç‰¹å¾èåˆå¯¹æå‡æƒ…æ„Ÿè¯†åˆ«è¡¨ç°çš„æœ‰æ•ˆæ€§ã€‚",
      "categories": [
        "cs.MM",
        "cs.AI"
      ],
      "primary_category": "cs.MM",
      "comment": "AAAI 2026 accepted",
      "pdf_url": "https://arxiv.org/pdf/2512.01442v1",
      "published_date": "2025-12-01 09:24:59 UTC",
      "updated_date": "2025-12-01 09:24:59 UTC",
      "processing_status": "completed",
      "attempts": 1,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "llm_backup_calls": 0,
      "last_update": "2026-01-26T12:34:57.976270+00:00"
    },
    {
      "arxiv_id": "2512.01440v1",
      "title": "A Selective Temporal Hamming distance to find patterns in state transition event timeseries, at scale",
      "title_zh": "ä¸€ç§ç”¨äºå¤§è§„æ¨¡çŠ¶æ€è½¬æ¢äº‹ä»¶æ—¶é—´åºåˆ—æ¨¡å¼å‘ç°çš„é€‰æ‹©æ€§æ—¶æ€ Hamming è·ç¦»",
      "authors": [
        "Sylvain MariÃ©",
        "Pablo Knecht"
      ],
      "abstract": "Discrete event systems are present both in observations of nature, socio economical sciences, and industrial systems. Standard analysis approaches do not usually exploit their dual event / state nature: signals are either modeled as transition event sequences, emphasizing event order alignment, or as categorical or ordinal state timeseries, usually resampled a distorting and costly operation as the observation period and number of events grow. In this work we define state transition event timeseries (STE-ts) and propose a new Selective Temporal Hamming distance (STH) leveraging both transition time and duration-in-state, avoiding costly and distorting resampling on large databases. STH generalizes both resampled Hamming and Jaccard metrics with better precision and computation time, and an ability to focus on multiple states of interest. We validate these benefits on simulated and real-world datasets.",
      "tldr_zh": "è¯¥ç ”ç©¶é’ˆå¯¹ç¦»æ•£äº‹ä»¶ç³»ç»Ÿ(Discrete event systems)ä¸­çš„æ•°æ®åˆ†æéš¾é¢˜ï¼Œæå‡ºäº†çŠ¶æ€è½¬ç§»äº‹ä»¶æ—¶é—´åºåˆ—(state transition event timeseries, STE-ts)çš„æ¦‚å¿µä»¥åŠä¸€ç§å…¨æ–°çš„é€‰æ‹©æ€§æ—¶é—´æ±‰æ˜è·ç¦»(Selective Temporal Hamming distance, STH)ã€‚è¯¥æ–¹æ³•ç»¼åˆåˆ©ç”¨äº†è½¬ç§»æ—¶é—´(transition time)å’ŒçŠ¶æ€æŒç»­æ—¶é—´(duration-in-state)ï¼Œæœ‰æ•ˆé¿å…äº†åœ¨å¤§è§„æ¨¡æ•°æ®åº“ä¸­é€šå¸¸éœ€è¦çš„ã€ä¸”å…·æœ‰å¤±çœŸæ€§å’Œé«˜æˆæœ¬çš„é‡é‡‡æ ·æ“ä½œã€‚STH æˆåŠŸæ¨å¹¿äº†ä¼ ç»Ÿçš„é‡é‡‡æ · Hamming å’Œ Jaccard åº¦é‡ï¼Œåœ¨ä¿æŒæ›´é«˜ç²¾åº¦çš„åŒæ—¶æ˜¾è‘—ç¼©çŸ­äº†è®¡ç®—æ—¶é—´ã€‚æ­¤å¤–ï¼Œè¯¥åº¦é‡è¿˜å…·å¤‡èšç„¦äºå¤šä¸ªç‰¹å®šæ„Ÿå…´è¶£çŠ¶æ€çš„èƒ½åŠ›ï¼Œèƒ½å¤Ÿæ›´çµæ´»åœ°å¤„ç†å¤æ‚çš„äº‹ä»¶æ¨¡å¼ã€‚ç ”ç©¶äººå‘˜é€šè¿‡åœ¨æ¨¡æ‹Ÿå’ŒçœŸå®ä¸–ç•Œæ•°æ®é›†ä¸Šçš„å®éªŒéªŒè¯äº† STH çš„ä¼˜è¶Šæ€§èƒ½ï¼Œè¯æ˜äº†å…¶åœ¨å¤§è§„æ¨¡ç¦»æ•£äº‹ä»¶åˆ†æä¸­çš„å®ç”¨ä»·å€¼ã€‚",
      "categories": [
        "cs.AI",
        "stat.ML"
      ],
      "primary_category": "cs.AI",
      "comment": "",
      "pdf_url": "https://arxiv.org/pdf/2512.01440v1",
      "published_date": "2025-12-01 09:24:20 UTC",
      "updated_date": "2025-12-01 09:24:20 UTC",
      "processing_status": "completed",
      "attempts": 1,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "llm_backup_calls": 0,
      "last_update": "2026-01-26T12:35:09.376727+00:00"
    },
    {
      "arxiv_id": "2512.01434v1",
      "title": "A Flexible Multi-Agent LLM-Human Framework for Fast Human Validated Tool Building",
      "title_zh": "ä¸€ç§ç”¨äºå¿«é€Ÿæ„å»ºç»äººç±»éªŒè¯å·¥å…·çš„çµæ´»å¤šæ™ºèƒ½ä½“ LLM-äººæœºåä½œæ¡†æ¶",
      "authors": [
        "Daull Xavier",
        "Patrice Bellot",
        "Emmanuel Bruno",
        "Vincent Martin",
        "Elisabeth Murisasco"
      ],
      "abstract": "We introduce CollabToolBuilder, a flexible multiagent LLM framework with expert-in-the-loop (HITL) guidance that iteratively learns to create tools for a target goal, aligning with human intent and process, while minimizing time for task/domain adaptation effort and human feedback capture. The architecture generates and validates tools via four specialized agents (Coach, Coder, Critic, Capitalizer) using a reinforced dynamic prompt and systematic human feedback integration to reinforce each agent's role toward goals and constraints. This work is best viewed as a system-level integration and methodology combining multi-agent in-context learning, HITL controls, and reusable tool capitalization for complex iterative problems such as scientific document generation. We illustrate it with preliminary experiments (e.g., generating state-of-the-art research papers or patents given an abstract) and discuss its applicability to other iterative problem-solving.",
      "tldr_zh": "è¯¥ç ”ç©¶æå‡ºäº†CollabToolBuilderï¼Œè¿™æ˜¯ä¸€ç§çµæ´»çš„Multi-Agent LLMæ¡†æ¶ï¼Œé€šè¿‡å¼•å…¥ä¸“å®¶åœ¨ç¯(Expert-in-the-loop, HITL)æŒ‡å¯¼æ¥å®ç°å·¥å…·çš„å¿«é€Ÿæ„å»ºä¸éªŒè¯ã€‚è¯¥æ¡†æ¶é€šè¿‡è¿­ä»£å­¦ä¹ ä¸ºç›®æ ‡ä»»åŠ¡åˆ›å»ºå·¥å…·ï¼Œåœ¨ç¡®ä¿ä¸äººç±»æ„å›¾å’Œæµç¨‹é«˜åº¦ä¸€è‡´çš„åŒæ—¶ï¼Œæœ€å¤§é™åº¦åœ°å‡å°‘äº†é¢†åŸŸé€‚é…éš¾åº¦å’Œåé¦ˆæ•è·æˆæœ¬ã€‚ç³»ç»Ÿæ¶æ„ç”±Coachã€Coderã€Criticå’ŒCapitalizerå››ä¸ªä¸“ä¸šæ™ºèƒ½ä½“ç»„æˆï¼Œåˆ©ç”¨å¼ºåŒ–åŠ¨æ€æç¤º(Reinforced Dynamic Prompt)å’Œç³»ç»ŸåŒ–çš„äººç±»åé¦ˆé›†æˆæ¥ååŒè¾¾æˆç›®æ ‡ã€‚è¿™é¡¹å·¥ä½œå±•ç¤ºäº†å¤šæ™ºèƒ½ä½“ä¸Šä¸‹æ–‡å­¦ä¹ (Multi-agent In-context Learning)ä¸HITLæ§åˆ¶çš„æ·±åº¦èåˆï¼Œå¹¶å…·å¤‡å¯é‡ç”¨å·¥å…·çš„èµ„æœ¬åŒ–èƒ½åŠ›ã€‚é€šè¿‡åœ¨ç§‘ç ”è®ºæ–‡å’Œä¸“åˆ©ç”Ÿæˆç­‰å¤æ‚è¿­ä»£é—®é¢˜ä¸Šçš„åˆæ­¥å®éªŒï¼Œè¯¥æ¡†æ¶è¯æ˜äº†å…¶åœ¨è§£å†³éœ€è¦äººç±»éªŒè¯çš„å¤æ‚é—®é¢˜åŠæå‡ä»»åŠ¡è‡ªåŠ¨åŒ–æ•ˆç‡æ–¹é¢çš„æ˜¾è‘—æ½œåŠ›ã€‚",
      "categories": [
        "cs.AI"
      ],
      "primary_category": "cs.AI",
      "comment": "",
      "pdf_url": "https://arxiv.org/pdf/2512.01434v1",
      "published_date": "2025-12-01 09:19:18 UTC",
      "updated_date": "2025-12-01 09:19:18 UTC",
      "processing_status": "completed",
      "attempts": 1,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "llm_backup_calls": 0,
      "last_update": "2026-01-26T12:35:58.020661+00:00"
    },
    {
      "arxiv_id": "2512.01420v1",
      "title": "PromptBridge: Cross-Model Prompt Transfer for Large Language Models",
      "title_zh": "PromptBridgeï¼šé¢å‘å¤§è¯­è¨€æ¨¡å‹çš„è·¨æ¨¡å‹æç¤ºè¯è¿ç§»",
      "authors": [
        "Yaxuan Wang",
        "Quan Liu",
        "Zhenting Wang",
        "Zichao Li",
        "Wei Wei",
        "Yang Liu",
        "Yujia Bao"
      ],
      "abstract": "Large language models (LLMs) underpin applications in code generation, mathematical reasoning, and agent-based workflows. In practice, systems access LLMs via commercial APIs or open-source deployments, and the model landscape (e.g., GPT, Claude, Llama) evolves rapidly. This rapid evolution forces frequent model switches driven by capability, cost, deployment constraints, and privacy. Yet prompts are highly model-sensitive: reusing a prompt engineered for one model on another often yields substantially worse performance than a prompt optimized for the target model. We term this phenomenon Model Drifting. Through extensive empirical analysis across diverse LLM configurations, we show that model drifting is both common and severe. To address this challenge, we introduce PromptBridge, a training-free framework that preserves prompt effectiveness under model switches, enabling cross-model prompt transfer without costly per-task or per-model re-optimization. PromptBridge requires only a small set of alignment tasks for calibration. It first applies Model-Adaptive Reflective Prompt Evolution (MAP-RPE) to obtain task- and model-specific optimal prompts via iterative reflective refinement and quantitative evaluation. Using the resulting calibrated prompt pairs for the source and target models, PromptBridge learns a cross-model prompt mapping. At test time, i.e., for an unseen task, given a source-model prompt, this mapping directly produces an optimized prompt for the target model. Experiments in single-agent and multi-agent settings show that PromptBridge consistently improves downstream accuracy while reducing migration effort. The code will be available soon.",
      "tldr_zh": "è¯¥ç ”ç©¶é’ˆå¯¹å¤§è¯­è¨€æ¨¡å‹(LLMs)å¿«é€Ÿæ¼”è¿›å¯¼è‡´çš„æç¤ºè¯åœ¨ä¸åŒæ¨¡å‹é—´æ€§èƒ½æ˜¾è‘—ä¸‹é™çš„Model Driftingç°è±¡ï¼Œæå‡ºäº†PromptBridgeæ¡†æ¶ï¼Œæ—¨åœ¨å®ç°æ— éœ€è®­ç»ƒçš„è·¨æ¨¡å‹æç¤ºè¯è¿ç§»ã€‚ä¸ºäº†è§£å†³è·¨æ¨¡å‹é‡ä¼˜åŒ–çš„æˆæœ¬é—®é¢˜ï¼ŒPromptBridgeä»…é€šè¿‡å°‘é‡å¯¹é½ä»»åŠ¡è¿›è¡Œæ ¡å‡†ï¼Œå¹¶é‡‡ç”¨æ¨¡å‹è‡ªé€‚åº”åå°„å¼æç¤ºè¯æ¼”åŒ–(MAP-RPE)æŠ€æœ¯æ¥è·å–ä»»åŠ¡ä¸æ¨¡å‹ç‰¹å®šçš„æœ€ä¼˜æç¤ºè¯å¯¹ã€‚è¯¥æ¡†æ¶é€šè¿‡å­¦ä¹ æºæ¨¡å‹åˆ°ç›®æ ‡æ¨¡å‹çš„æç¤ºè¯æ˜ å°„å…³ç³»ï¼Œèƒ½å¤Ÿå°†æ–°ä»»åŠ¡çš„æºæ¨¡å‹æç¤ºè¯ç›´æ¥è½¬åŒ–ä¸ºç›®æ ‡æ¨¡å‹çš„æœ€ä¼˜ç‰ˆæœ¬ã€‚å®éªŒç»“æœè¯æ˜ï¼ŒPromptBridgeåœ¨å•æ™ºèƒ½ä½“å’Œå¤šæ™ºèƒ½ä½“åœºæ™¯ä¸‹å‡èƒ½ç¨³å®šæå‡ä¸‹æ¸¸ä»»åŠ¡å‡†ç¡®ç‡ï¼Œæ˜¾è‘—é™ä½äº†æ¨¡å‹è¿ç§»è¿‡ç¨‹ä¸­çš„äººå·¥ä¼˜åŒ–è´Ÿæ‹…ã€‚",
      "categories": [
        "cs.CL",
        "cs.AI"
      ],
      "primary_category": "cs.CL",
      "comment": "",
      "pdf_url": "https://arxiv.org/pdf/2512.01420v1",
      "published_date": "2025-12-01 08:55:45 UTC",
      "updated_date": "2025-12-01 08:55:45 UTC",
      "processing_status": "completed",
      "attempts": 1,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "llm_backup_calls": 0,
      "last_update": "2026-01-26T12:35:31.277001+00:00"
    },
    {
      "arxiv_id": "2512.01419v1",
      "title": "Rice-VL: Evaluating Vision-Language Models for Cultural Understanding Across ASEAN Countries",
      "title_zh": "Rice-VLï¼šé¢å‘ ASEAN å›½å®¶çš„è§†è§‰è¯­è¨€æ¨¡å‹æ–‡åŒ–ç†è§£èƒ½åŠ›è¯„ä¼°",
      "authors": [
        "Tushar Pranav",
        "Eshan Pandey",
        "Austria Lyka Diane Bala",
        "Aman Chadha",
        "Indriyati Atmosukarto",
        "Donny Soh Cheng Lock"
      ],
      "abstract": "Vision-Language Models (VLMs) excel in multimodal tasks but often exhibit Western-centric biases, limiting their effectiveness in culturally diverse regions like Southeast Asia (SEA). To address this, we introduce RICE-VL, a novel benchmark evaluating VLM cultural understanding across 11 ASEAN countries. RICE-VL includes over 28,000 human-curated Visual Question Answering (VQA) samples -- covering True or False, Fill-in-the-Blank, and open-ended formats -- and 1,000 image-bounding box pairs for Visual Grounding, annotated by culturally informed experts across 14 sub-ground categories. We propose SEA-LAVE, an extension of the LAVE metric, assessing textual accuracy, cultural alignment, and country identification. Evaluations of six open- and closed-source VLMs reveal significant performance gaps in low-resource countries and abstract cultural domains. The Visual Grounding task tests models' ability to localize culturally significant elements in complex scenes, probing spatial and contextual accuracy. RICE-VL exposes limitations in VLMs' cultural comprehension and highlights the need for inclusive model development to better serve diverse global populations.",
      "tldr_zh": "é’ˆå¯¹è§†è§‰è¯­è¨€æ¨¡å‹(VLMs)åœ¨ä¸œå—äºšç­‰æ–‡åŒ–å¤šæ ·åŒ–åœ°åŒºå­˜åœ¨çš„è¥¿æ–¹ä¸­å¿ƒä¸»ä¹‰åè§ï¼Œè¯¥ç ”ç©¶æ¨å‡ºäº†RICE-VLï¼Œä¸€ä¸ªè¯„ä¼°11ä¸ªä¸œç›Ÿ(ASEAN)å›½å®¶æ–‡åŒ–ç†è§£èƒ½åŠ›çš„æ–°å‹åŸºå‡†æµ‹è¯•ã€‚è¯¥åŸºå‡†åŒ…å«è¶…è¿‡28,000ä¸ªç”±æ–‡åŒ–ä¸“å®¶ç²¾å¿ƒç­–å±•çš„è§†è§‰é—®ç­”(VQA)æ ·æœ¬ï¼Œä»¥åŠ1,000ä¸ªç”¨äºè§†è§‰å®šä½(Visual Grounding)ä»»åŠ¡çš„å›¾åƒè¾¹ç•Œæ¡†å¯¹ï¼Œæ¶µç›–äº†14ä¸ªå­ç±»åˆ«ã€‚ç ”ç©¶è€…åŒæ­¥æå‡ºäº†è¯„ä¼°æŒ‡æ ‡SEA-LAVEï¼Œæ—¨åœ¨å¤šç»´åº¦è¡¡é‡æ¨¡å‹çš„æ–‡æœ¬å‡†ç¡®æ€§ã€æ–‡åŒ–å¯¹é½åº¦åŠå›½å®¶è¯†åˆ«èƒ½åŠ›ã€‚é€šè¿‡å¯¹å…­ç§å¼€æºåŠé—­æºVLMsçš„è¯„ä¼°ï¼Œç ”ç©¶å‘ç°æ¨¡å‹åœ¨ä½èµ„æºå›½å®¶å’ŒæŠ½è±¡æ–‡åŒ–é¢†åŸŸè¡¨ç°å‡ºæ˜¾è‘—çš„æ€§èƒ½å·®è·ï¼Œä¸”åœ¨å®šä½æ–‡åŒ–æ˜¾è‘—å…ƒç´ æ—¶å­˜åœ¨ç©ºé—´ä¸ä¸Šä¸‹æ–‡å‡†ç¡®æ€§ä¸è¶³çš„é—®é¢˜ã€‚RICE-VLæ­ç¤ºäº†å½“å‰æ¨¡å‹åœ¨æ–‡åŒ–ç†è§£ä¸Šçš„å±€é™æ€§ï¼Œå¹¶å¼ºè°ƒäº†æ„å»ºå…·å¤‡å…¨çƒåŒ…å®¹æ€§çš„æ¨¡å‹ä»¥æœåŠ¡å¤šå…ƒåŒ–äººå£çš„å¿…è¦æ€§ã€‚",
      "categories": [
        "cs.CV",
        "cs.AI"
      ],
      "primary_category": "cs.CV",
      "comment": "14 pages",
      "pdf_url": "https://arxiv.org/pdf/2512.01419v1",
      "published_date": "2025-12-01 08:55:41 UTC",
      "updated_date": "2025-12-01 08:55:41 UTC",
      "processing_status": "completed",
      "attempts": 1,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "llm_backup_calls": 0,
      "last_update": "2026-01-26T12:35:32.478719+00:00"
    },
    {
      "arxiv_id": "2512.01412v1",
      "title": "A Self-explainable Model of Long Time Series by Extracting Informative Structured Causal Patterns",
      "title_zh": "åŸºäºæå–ä¿¡æ¯ä¸°å¯Œçš„ç»“æ„åŒ–å› æœæ¨¡å¼çš„é•¿æ—¶é—´åºåˆ—è‡ªè§£é‡Šæ¨¡å‹",
      "authors": [
        "Ziqian Wang",
        "Yuxiao Cheng",
        "Jinli Suo"
      ],
      "abstract": "Explainability is essential for neural networks that model long time series, yet most existing explainable AI methods only produce point-wise importance scores and fail to capture temporal structures such as trends, cycles, and regime changes. This limitation weakens human interpretability and trust in long-horizon models. To address these issues, we identify four key requirements for interpretable time-series modeling: temporal continuity, pattern-centric explanation, causal disentanglement, and faithfulness to the model's inference process. We propose EXCAP, a unified framework that satisfies all four requirements. EXCAP combines an attention-based segmenter that extracts coherent temporal patterns, a causally structured decoder guided by a pre-trained causal graph, and a latent aggregation mechanism that enforces representation stability. Our theoretical analysis shows that EXCAP provides smooth and stable explanations over time and is robust to perturbations in causal masks. Extensive experiments on classification and forecasting benchmarks demonstrate that EXCAP achieves strong predictive accuracy while generating coherent and causally grounded explanations. These results show that EXCAP offers a principled and scalable approach to interpretable modeling of long time series with relevance to high-stakes domains such as healthcare and finance.",
      "tldr_zh": "è¯¥ç ”ç©¶é’ˆå¯¹ç¥ç»ç½‘ç»œåœ¨å¤„ç† long time series æ—¶ç¼ºä¹å¯è§£é‡Šæ€§çš„é—®é¢˜ï¼ŒæŒ‡å‡ºå½“å‰ä¸»æµæ–¹æ³•ä»…èƒ½æä¾›é€ç‚¹é‡è¦æ€§åˆ†æ•°ï¼Œæ— æ³•æœ‰æ•ˆæ•æ‰è¶‹åŠ¿å’Œå‘¨æœŸç­‰æ—¶é—´ç»“æ„ã€‚ä¸ºæ­¤ï¼Œä½œè€…æå‡ºäº† EXCAP ç»Ÿä¸€æ¡†æ¶ï¼Œæ—¨åœ¨æ»¡è¶³ temporal continuityã€pattern-centric explanationã€causal disentanglement ä»¥åŠå¯¹æ¨¡å‹æ¨ç†è¿‡ç¨‹çš„å¿ å®æ€§è¦æ±‚ã€‚EXCAP ç»“åˆäº†ç”¨äºæå–è¿è´¯æ—¶é—´æ¨¡å¼çš„ attention-based segmenterï¼Œä»¥åŠå—é¢„è®­ç»ƒ causal graph å¼•å¯¼çš„å› æœç»“æ„è§£ç å™¨ï¼Œå¹¶åˆ©ç”¨ latent aggregation mechanism ç¡®ä¿è¡¨ç¤ºçš„ç¨³å®šæ€§ã€‚ç†è®ºåˆ†æä¸å®éªŒç»“æœæ˜¾ç¤ºï¼ŒEXCAP åœ¨åˆ†ç±»å’Œé¢„æµ‹åŸºå‡†ä»»åŠ¡ä¸­å‡ä¿æŒäº†å¼ºå¤§çš„é¢„æµ‹å‡†ç¡®ç‡ï¼ŒåŒæ—¶èƒ½æä¾›å¹³æ»‘ã€ç¨³å®šä¸”å…·å¤‡å› æœä¾æ®çš„è§£é‡Šã€‚è¯¥æ¡†æ¶ä¸ºåŒ»ç–—å’Œé‡‘èç­‰é«˜é£é™©é¢†åŸŸæä¾›äº†å…·æœ‰åŸåˆ™æ€§ä¸”å¯æ‰©å±•çš„å¯è§£é‡Šå»ºæ¨¡æ–¹æ¡ˆã€‚",
      "categories": [
        "cs.LG",
        "cs.AI"
      ],
      "primary_category": "cs.LG",
      "comment": "Approximately 30 pages, 8 figures, and 5 tables. Preprint version. Includes theoretical analysis, model architecture, interpretability evaluation, and extensive benchmark experiments",
      "pdf_url": "https://arxiv.org/pdf/2512.01412v1",
      "published_date": "2025-12-01 08:33:33 UTC",
      "updated_date": "2025-12-01 08:33:33 UTC",
      "processing_status": "completed",
      "attempts": 1,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "llm_backup_calls": 0,
      "last_update": "2026-01-26T12:35:38.970759+00:00"
    },
    {
      "arxiv_id": "2512.01389v1",
      "title": "Consistency Flow Model Achieves One-step Denoising Error Correction Codes",
      "title_zh": "ä¸€è‡´æ€§æµæ¨¡å‹å®ç°å•æ­¥å»å™ªçº é”™ç ",
      "authors": [
        "Haoyu Lei",
        "Chin Wa Lau",
        "Kaiwen Zhou",
        "Nian Guo",
        "Farzan Farnia"
      ],
      "abstract": "Error Correction Codes (ECC) are fundamental to reliable digital communication, yet designing neural decoders that are both accurate and computationally efficient remains challenging. Recent denoising diffusion decoders with transformer backbones achieve state-of-the-art performance, but their iterative sampling limits practicality in low-latency settings. We introduce the Error Correction Consistency Flow Model (ECCFM), an architecture-agnostic training framework for high-fidelity one-step decoding. By casting the reverse denoising process as a Probability Flow Ordinary Differential Equation (PF-ODE) and enforcing smoothness through a differential time regularization, ECCFM learns to map noisy signals along the decoding trajectory directly to the original codeword in a single inference step. Across multiple decoding benchmarks, ECCFM attains lower bit-error rates (BER) than autoregressive and diffusion-based baselines, with notable improvements on longer codes, while delivering inference speeds up from 30x to 100x faster than denoising diffusion decoders.",
      "tldr_zh": "è¯¥ç ”ç©¶é’ˆå¯¹æ•°å­—é€šä¿¡ä¸­çº é”™ç  (Error Correction Codes, ECC) çš„é«˜æ•ˆè§£ç æŒ‘æˆ˜ï¼Œæå‡ºäº† ECCFM (Error Correction Consistency Flow Model)ï¼Œè¿™æ˜¯ä¸€ç§æ”¯æŒé«˜ä¿çœŸåº¦ä¸€æ­¥è§£ç çš„æ¶æ„æ— å…³è®­ç»ƒæ¡†æ¶ã€‚è¯¥æ¡†æ¶å°†åå‘å»å™ªè¿‡ç¨‹å»ºæ¨¡ä¸ºæ¦‚ç‡æµå¸¸å¾®åˆ†æ–¹ç¨‹ (Probability Flow Ordinary Differential Equation, PF-ODE)ï¼Œå¹¶é€šè¿‡å¾®åˆ†æ—¶é—´æ­£åˆ™åŒ– (differential time regularization) ç¡®ä¿è§£ç è½¨è¿¹çš„å¹³æ»‘æ€§ï¼Œä»è€Œå®ç°ä»å™ªå£°ä¿¡å·åˆ°åŸå§‹ç å­—çš„ç›´æ¥æ˜ å°„ã€‚åœ¨å¤šä¸ªè§£ç åŸºå‡†æµ‹è¯•ä¸­ï¼ŒECCFM å±•ç°å‡ºæ¯”è‡ªå›å½’å’Œæ‰©æ•£æ¨¡å‹æ›´ä½çš„è¯¯ç ç‡ (Bit-Error Rate, BER)ï¼Œåœ¨é•¿ç å¤„ç†ä¸Šä¼˜åŠ¿å°¤ä¸ºæ˜æ˜¾ã€‚æ­¤å¤–ï¼ŒECCFM çš„æ¨ç†é€Ÿåº¦æ¯”ä¼ ç»Ÿå»å™ªæ‰©æ•£è§£ç å™¨å¿« 30 è‡³ 100 å€ï¼Œæœ‰æ•ˆè§£å†³äº†ç¥ç»ç½‘ç»œè§£ç å™¨åœ¨ä½å»¶è¿Ÿé€šä¿¡åœºæ™¯ä¸‹çš„åº”ç”¨ç“¶é¢ˆã€‚",
      "categories": [
        "cs.LG",
        "cs.AI"
      ],
      "primary_category": "cs.LG",
      "comment": "",
      "pdf_url": "https://arxiv.org/pdf/2512.01389v1",
      "published_date": "2025-12-01 08:07:51 UTC",
      "updated_date": "2025-12-01 08:07:51 UTC",
      "processing_status": "completed",
      "attempts": 1,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "llm_backup_calls": 0,
      "last_update": "2026-01-26T12:35:37.099459+00:00"
    },
    {
      "arxiv_id": "2512.01374v3",
      "title": "Stabilizing Reinforcement Learning with LLMs: Formulation and Practices",
      "title_zh": "åŸºäºå¤§è¯­è¨€æ¨¡å‹çš„å¼ºåŒ–å­¦ä¹ ç¨³å®šæ€§ï¼šå½¢å¼åŒ–æ–¹æ³•ä¸å®è·µ",
      "authors": [
        "Chujie Zheng",
        "Kai Dang",
        "Bowen Yu",
        "Mingze Li",
        "Huiqiang Jiang",
        "Junrong Lin",
        "Yuqiong Liu",
        "Hao Lin",
        "Chencan Wu",
        "Feng Hu",
        "An Yang",
        "Jingren Zhou",
        "Junyang Lin"
      ],
      "abstract": "This paper proposes a novel formulation for reinforcement learning (RL) with large language models, explaining why and under what conditions the true sequence-level reward can be optimized via a surrogate token-level objective in policy gradient methods such as REINFORCE. Specifically, through a first-order approximation, we show that this surrogate becomes increasingly valid only when both the training-inference discrepancy and policy staleness are minimized. This insight provides a principled explanation for the crucial role of several widely adopted techniques in stabilizing RL training, including importance sampling correction, clipping, and particularly Routing Replay for Mixture-of-Experts (MoE) models. Through extensive experiments with a 30B MoE model totaling hundreds of thousands of GPU hours, we show that for on-policy training, the basic policy gradient algorithm with importance sampling correction achieves the highest training stability. When off-policy updates are introduced to accelerate convergence, combining clipping and Routing Replay becomes essential to mitigate the instability caused by policy staleness. Notably, once training is stabilized, prolonged optimization consistently yields comparable final performance regardless of cold-start initialization. We hope that the shared insights and the developed recipes for stable RL training will facilitate future research.",
      "tldr_zh": "è¯¥ç ”ç©¶é’ˆå¯¹å¤§å‹è¯­è¨€æ¨¡å‹(LLMs)çš„å¼ºåŒ–å­¦ä¹ (RL)æå‡ºäº†ä¸€ç§æ–°é¢–çš„å½¢å¼åŒ–æ–¹æ³•ï¼Œæ¢è®¨äº†é€šè¿‡ç­–ç•¥æ¢¯åº¦æ–¹æ³•(å¦‚ REINFORCE)ä¸­çš„ token-level ä»£ç†ç›®æ ‡ä¼˜åŒ–åºåˆ—çº§å¥–åŠ±çš„ç†è®ºåŸºç¡€ã€‚é€šè¿‡ä¸€é˜¶è¿‘ä¼¼ï¼Œç ”ç©¶è¯æ˜åªæœ‰åœ¨æœ€å°åŒ–è®­ç»ƒä¸æ¨ç†å·®å¼‚åŠç­–ç•¥é™ˆæ—§åº¦(policy staleness)çš„æƒ…å†µä¸‹ï¼Œè¯¥ä»£ç†ç›®æ ‡æ‰å…·å¤‡æœ‰æ•ˆæ€§ï¼Œè¿™ä¸ºé‡è¦æ€§é‡‡æ ·ä¿®æ­£(importance sampling correction)ã€è£å‰ª(clipping)ä»¥åŠæ··åˆä¸“å®¶æ¨¡å‹(MoE)ä¸­çš„ Routing Replay ç­‰æŠ€æœ¯æä¾›äº†åŸç†è§£é‡Šã€‚åŸºäº 30B MoE æ¨¡å‹çš„å¤§è§„æ¨¡å®éªŒè¡¨æ˜ï¼Œåœ¨ on-policy è®­ç»ƒä¸­ï¼Œå¸¦é‡è¦æ€§é‡‡æ ·ä¿®æ­£çš„ç­–ç•¥æ¢¯åº¦ç®—æ³•å…·æœ‰æœ€é«˜ç¨³å®šæ€§ï¼›è€Œåœ¨ off-policy æ›´æ–°åœºæ™¯ä¸‹ï¼Œç»“åˆè£å‰ªä¸ Routing Replay æ˜¯ç¼“è§£ç­–ç•¥é™ˆæ—§åº¦å¼•å‘ä¸ç¨³å®šçš„æ ¸å¿ƒã€‚ç ”ç©¶è¿›ä¸€æ­¥æŒ‡å‡ºï¼Œä¸€æ—¦è®­ç»ƒè¶‹äºç¨³å®šï¼Œé•¿æœŸçš„ä¼˜åŒ–è¿‡ç¨‹æ— è®ºå†·å¯åŠ¨åˆå§‹åŒ–å¦‚ä½•éƒ½èƒ½è¾¾åˆ°ç›¸å½“çš„æœ€ç»ˆæ€§èƒ½ã€‚è¯¥ç ”ç©¶åˆ†äº«çš„æ´å¯Ÿä¸æˆç†Ÿæ–¹æ¡ˆä¸ºå®ç°ç¨³å®šçš„ RL è®­ç»ƒå¥ å®šäº†åšå®åŸºç¡€ã€‚",
      "categories": [
        "cs.LG",
        "cs.AI",
        "cs.CL"
      ],
      "primary_category": "cs.LG",
      "comment": "",
      "pdf_url": "https://arxiv.org/pdf/2512.01374v3",
      "published_date": "2025-12-01 07:45:39 UTC",
      "updated_date": "2025-12-03 15:17:19 UTC",
      "processing_status": "completed",
      "attempts": 1,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "llm_backup_calls": 0,
      "last_update": "2026-01-26T12:35:51.971909+00:00"
    },
    {
      "arxiv_id": "2512.01372v2",
      "title": "Structured Spectral Reasoning for Frequency-Adaptive Multimodal Recommendation",
      "title_zh": "é¢å‘é¢‘ç‡è‡ªé€‚åº”å¤šæ¨¡æ€æ¨èçš„ç»“æ„åŒ–é¢‘è°±æ¨ç†",
      "authors": [
        "Wei Yang",
        "Rui Zhong",
        "Yiqun Chen",
        "Chi Lu",
        "Peng Jiang"
      ],
      "abstract": "Multimodal recommendation aims to integrate collaborative signals with heterogeneous content such as visual and textual information, but remains challenged by modality-specific noise, semantic inconsistency, and unstable propagation over user-item graphs. These issues are often exacerbated by naive fusion or shallow modeling strategies, leading to degraded generalization and poor robustness. While recent work has explored the frequency domain as a lens to separate stable from noisy signals, most methods rely on static filtering or reweighting, lacking the ability to reason over spectral structure or adapt to modality-specific reliability. To address these challenges, we propose a Structured Spectral Reasoning (SSR) framework for frequency-aware multimodal recommendation. Our method follows a four-stage pipeline: (i) Decompose graph-based multimodal signals into spectral bands via graph-guided transformations to isolate semantic granularity; (ii) Modulate band-level reliability with spectral band masking, a training-time masking with a prediction-consistency objective that suppresses brittle frequency components; (iii) Fuse complementary frequency cues using hyperspectral reasoning with low-rank cross-band interaction; and (iv) Align modality-specific spectral features via contrastive regularization to promote semantic and structural consistency. Experiments on three real-world benchmarks show consistent gains over strong baselines, particularly under sparse and cold-start settings. Additional analyses indicate that structured spectral modeling improves robustness and provides clearer diagnostics of how different bands contribute to performance.",
      "tldr_zh": "è¯¥ç ”ç©¶é’ˆå¯¹å¤šæ¨¡æ€æ¨è(Multimodal Recommendation)ä¸­å­˜åœ¨çš„æ¨¡æ€ç‰¹å®šå™ªå£°ã€è¯­ä¹‰ä¸ä¸€è‡´åŠå›¾ä¼ æ’­ä¸ç¨³å®šç­‰æŒ‘æˆ˜ï¼Œæå‡ºäº†ç»“æ„åŒ–é¢‘è°±æ¨ç†(Structured Spectral Reasoning, SSR)æ¡†æ¶ã€‚è¯¥æ–¹æ³•é¦–å…ˆé€šè¿‡å›¾å¼•å¯¼å˜æ¢å°†å¤šæ¨¡æ€ä¿¡å·åˆ†è§£ä¸ºå¤šä¸ªé¢‘è°±å¸¦(spectral bands)ä»¥éš”ç¦»è¯­ä¹‰ç²’åº¦ï¼Œéšååˆ©ç”¨é¢‘è°±å¸¦æ©ç (spectral band masking)æŠ€æœ¯é…åˆé¢„æµ‹ä¸€è‡´æ€§ç›®æ ‡æ¥æŠ‘åˆ¶è„†å¼±çš„é¢‘ç‡æˆåˆ†ã€‚ä¸ºäº†æœ‰æ•ˆæ•´åˆä¿¡æ¯ï¼ŒSSRé‡‡ç”¨å…·æœ‰ä½ç§©è·¨é¢‘å¸¦äº¤äº’çš„é«˜å…‰è°±æ¨ç†(hyperspectral reasoning)æ¥èåˆäº’è¡¥çš„é¢‘ç‡çº¿ç´¢ï¼Œå¹¶é€šè¿‡å¯¹æ¯”æ­£åˆ™åŒ–(contrastive regularization)å¯¹é½å„æ¨¡æ€çš„é¢‘è°±ç‰¹å¾ä»¥ç¡®ä¿ç»“æ„ä¸€è‡´æ€§ã€‚å®éªŒç»“æœè¡¨æ˜ï¼Œè¯¥æ¡†æ¶åœ¨ä¸‰ä¸ªçœŸå®æ•°æ®é›†ä¸Šå‡æ˜¾è‘—ä¼˜äºç°æœ‰åŸºå‡†ï¼Œç‰¹åˆ«æ˜¯åœ¨å¤„ç†ç¨€ç–æ•°æ®å’Œå†·å¯åŠ¨(cold-start)é—®é¢˜æ—¶è¡¨ç°å‡ºå“è¶Šçš„æ€§èƒ½ã€‚æ­¤å¤–ï¼Œç ”ç©¶è¿˜è¯å®äº†ç»“æ„åŒ–é¢‘è°±å»ºæ¨¡åœ¨æå‡ç³»ç»Ÿé²æ£’æ€§åŠæä¾›æ€§èƒ½è¯Šæ–­æ–¹é¢çš„æœ‰æ•ˆæ€§ã€‚",
      "categories": [
        "cs.IR",
        "cs.AI"
      ],
      "primary_category": "cs.IR",
      "comment": "",
      "pdf_url": "https://arxiv.org/pdf/2512.01372v2",
      "published_date": "2025-12-01 07:39:28 UTC",
      "updated_date": "2025-12-21 19:35:23 UTC",
      "processing_status": "completed",
      "attempts": 1,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "llm_backup_calls": 0,
      "last_update": "2026-01-26T12:35:50.571665+00:00"
    },
    {
      "arxiv_id": "2512.01370v1",
      "title": "Beyond Loss Guidance: Using PDE Residuals as Spectral Attention in Diffusion Neural Operators",
      "title_zh": "è¶…è¶ŠæŸå¤±å¼•å¯¼ï¼šåœ¨æ‰©æ•£ç¥ç»ç®—å­ä¸­å°† PDE æ®‹å·®ä½œä¸ºé¢‘è°±æ³¨æ„åŠ›",
      "authors": [
        "Medha Sawhney",
        "Abhilash Neog",
        "Mridul Khurana",
        "Anuj Karpatne"
      ],
      "abstract": "Diffusion-based solvers for partial differential equations (PDEs) are often bottle-necked by slow gradient-based test-time optimization routines that use PDE residuals for loss guidance. They additionally suffer from optimization instabilities and are unable to dynamically adapt their inference scheme in the presence of noisy PDE residuals. To address these limitations, we introduce PRISMA (PDE Residual Informed Spectral Modulation with Attention), a conditional diffusion neural operator that embeds PDE residuals directly into the model's architecture via attention mechanisms in the spectral domain, enabling gradient-descent free inference. In contrast to previous methods that use PDE loss solely as external optimization targets, PRISMA integrates PDE residuals as integral architectural features, making it inherently fast, robust, accurate, and free from sensitive hyperparameter tuning. We show that PRISMA has competitive accuracy, at substantially lower inference costs, compared to previous methods across five benchmark PDEs, especially with noisy observations, while using 10x to 100x fewer denoising steps, leading to 15x to 250x faster inference.",
      "tldr_zh": "è¯¥ç ”ç©¶æå‡ºäº† PRISMA (PDE Residual Informed Spectral Modulation with Attention)ï¼Œè¿™æ˜¯ä¸€ç§æ¡ä»¶æ‰©æ•£ç¥ç»ç®—å­ (Diffusion Neural Operators)ï¼Œæ—¨åœ¨è§£å†³ä¼ ç»ŸåŸºäºæ‰©æ•£çš„åå¾®åˆ†æ–¹ç¨‹ (PDE) æ±‚è§£å™¨åœ¨æµ‹è¯•é˜¶æ®µä¼˜åŒ–ç¼“æ…¢ä¸”å¯¹å™ªå£°æ•æ„Ÿçš„é—®é¢˜ã€‚ä¸åŒäºä»¥å¾€å°† PDE æŸå¤±ä»…ä½œä¸ºå¤–éƒ¨ä¼˜åŒ–ç›®æ ‡çš„ Loss Guidance æ–¹æ³•ï¼ŒPRISMA é€šè¿‡è°±åŸŸ (Spectral Domain) çš„æ³¨æ„åŠ›æœºåˆ¶å°† PDE æ®‹å·® (PDE Residuals) ç›´æ¥åµŒå…¥åˆ°æ¨¡å‹æ¶æ„ä¸­ï¼Œå®ç°äº†æ— éœ€æ¢¯åº¦ä¸‹é™çš„æ¨ç†ã€‚è¯¥æ–¹æ³•å°† PDE æ®‹å·®æ•´åˆä¸ºå†…éƒ¨æ¶æ„ç‰¹å¾ï¼Œä½¿å…¶æœ¬è´¨ä¸Šå…·å¤‡å¿«é€Ÿã€é²æ£’ä¸”æ— éœ€æ•æ„Ÿè¶…å‚æ•°è°ƒä¼˜çš„ç‰¹æ€§ã€‚å®éªŒè¯æ˜ï¼ŒPRISMA åœ¨äº”ä¸ªåŸºå‡† PDE ä»»åŠ¡ä¸Šå±•ç°å‡ºæå…·ç«äº‰åŠ›çš„å‡†ç¡®æ€§ï¼Œå°¤å…¶åœ¨å¤„ç†å™ªå£°è§‚æµ‹æ—¶è¡¨ç°ä¼˜å¼‚ã€‚ç›¸æ¯”ç°æœ‰æ–¹æ³•ï¼Œè¯¥æ¡†æ¶å°†å»å™ªæ­¥æ•°å‡å°‘äº† 10 åˆ° 100 å€ï¼Œä»è€Œå®ç°äº† 15 åˆ° 250 å€çš„æ¨ç†åŠ é€Ÿï¼Œæ˜¾è‘—é™ä½äº†è®¡ç®—æˆæœ¬ã€‚",
      "categories": [
        "cs.LG",
        "cs.AI",
        "math.NA",
        "stat.ML"
      ],
      "primary_category": "cs.LG",
      "comment": "",
      "pdf_url": "https://arxiv.org/pdf/2512.01370v1",
      "published_date": "2025-12-01 07:34:42 UTC",
      "updated_date": "2025-12-01 07:34:42 UTC",
      "processing_status": "completed",
      "attempts": 1,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "llm_backup_calls": 0,
      "last_update": "2026-01-26T12:36:03.676517+00:00"
    },
    {
      "arxiv_id": "2512.01357v1",
      "title": "Tangram: Accelerating Serverless LLM Loading through GPU Memory Reuse and Affinity",
      "title_zh": "Tangramï¼šé€šè¿‡ GPU æ˜¾å­˜å¤ç”¨ä¸äº²å’Œæ€§åŠ é€Ÿæ— æœåŠ¡å™¨å¤§è¯­è¨€æ¨¡å‹åŠ è½½",
      "authors": [
        "Wenbin Zhu",
        "Zhaoyan Shen",
        "Zili Shao",
        "Hongjun Dai",
        "Feng Chen"
      ],
      "abstract": "Serverless Large Language Models (LLMs) have emerged as a cost-effective solution for deploying AI services by enabling a 'pay-as-you-go' pricing model through GPU resource sharing. However, cold-start latency, especially the model loading phase, has become a critical performance bottleneck, as it scales linearly with model size and severely limits the practical deployment of large-scale LLM services. This paper presents Tangram, a novel system that accelerates Serverless LLM loading through efficient GPU memory reuse. By leveraging the unused GPU memory to retain model parameters, Tangram significantly reduces model transfer time and cold-start latency. Its design includes three key components: unified GPU memory pool for tensor-level parameter sharing across models, on-demand KV cache allocation for dynamic memory management, and GPU-affinity-aware scheduling for maximizing resource utilization. These techniques collectively address the critical challenges of inefficient memory usage and the cold-start problem in Serverless LLM platforms. We have implemented a fully functional prototype, and experiments show that Tangram achieves up to 6.2 times faster loading and reduces Time-To-First-Token (TTFT) during cold-start by 23--55% over state-of-the-art methods.",
      "tldr_zh": "è¯¥è®ºæ–‡æå‡ºäº† Tangramï¼Œä¸€ä¸ªæ—¨åœ¨é€šè¿‡é«˜æ•ˆåˆ©ç”¨ GPU memory å¤ç”¨æŠ€æœ¯æ¥åŠ é€Ÿæ— æœåŠ¡å™¨ Serverless LLM åŠ è½½çš„æ–°å‹ç³»ç»Ÿã€‚é’ˆå¯¹ LLM åœ¨ Serverless æ¶æ„ä¸­å› æ¨¡å‹è§„æ¨¡è¿‡å¤§è€Œå¯¼è‡´çš„ cold-start å»¶è¿Ÿç“¶é¢ˆï¼ŒTangram åˆ©ç”¨é—²ç½®çš„ GPU memory ç•™å­˜æ¨¡å‹å‚æ•°ä»¥ç¼©çŸ­æ¨¡å‹ä¼ è¾“æ—¶é—´ã€‚è¯¥ç³»ç»Ÿè®¾è®¡äº†ä¸‰ä¸ªæ ¸å¿ƒç»„ä»¶ï¼šç”¨äºå®ç°å¼ é‡çº§å‚æ•°å…±äº«çš„ç»Ÿä¸€ GPU memory poolï¼Œç”¨äºåŠ¨æ€å†…å­˜ç®¡ç†çš„æŒ‰éœ€ KV cache åˆ†é…ï¼Œä»¥åŠæ—¨åœ¨æœ€å¤§åŒ–èµ„æºåˆ©ç”¨ç‡çš„ GPU-affinity-aware è°ƒåº¦ç­–ç•¥ã€‚å®éªŒç»“æœè¡¨æ˜ï¼Œä¸å½“å‰æœ€å…ˆè¿›æ–¹æ³•ç›¸æ¯”ï¼ŒTangram å®ç°äº†é«˜è¾¾ 6.2 å€çš„åŠ è½½é€Ÿåº¦æå‡ã€‚æ­¤å¤–ï¼ŒTangram åœ¨ cold-start é˜¶æ®µå°† Time-To-First-Token (TTFT) é™ä½äº† 23% è‡³ 55%ï¼Œæœ‰æ•ˆè§£å†³äº† Serverless å¹³å°åœ¨å¤§è§„æ¨¡æ¨¡å‹éƒ¨ç½²ä¸­çš„æ€§èƒ½éš¾é¢˜ã€‚",
      "categories": [
        "cs.DC",
        "cs.AI",
        "cs.AR"
      ],
      "primary_category": "cs.DC",
      "comment": "",
      "pdf_url": "https://arxiv.org/pdf/2512.01357v1",
      "published_date": "2025-12-01 07:10:34 UTC",
      "updated_date": "2025-12-01 07:10:34 UTC",
      "processing_status": "completed",
      "attempts": 1,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "llm_backup_calls": 0,
      "last_update": "2026-01-26T12:36:03.380116+00:00"
    },
    {
      "arxiv_id": "2512.01354v3",
      "title": "The Necessity of Imperfection:Reversing Model Collapse via Simulating Cognitive Boundedness",
      "title_zh": "ä¸å®Œç¾ä¹‹å¿…è¦ï¼šé€šè¿‡æ¨¡æ‹Ÿè®¤çŸ¥å±€é™æ€§é€†è½¬æ¨¡å‹å´©æºƒ",
      "authors": [
        "Zhongjie Jiang"
      ],
      "abstract": "Although synthetic data is widely promoted as a remedy, its prevailing production paradigm -- one optimizing for statistical smoothness -- systematically removes the long-tail, cognitively grounded irregularities that characterize human text. Prolonged training on such statistically optimal but cognitively impoverished data accelerates model collapse.\n  This paper proposes a paradigm shift: instead of imitating the surface properties of data, we simulate the cognitive processes that generate human text. We introduce the Prompt-driven Cognitive Computing Framework (PMCSF), whose core consists of a Cognitive State Decoder (CSD) that reverse-engineers unstructured text into structured cognitive vectors, and a Cognitive Text Encoder (CTE) that re-materializes these states into text enriched with human-typical imperfections via mathematically defined Cognitive Perturbation Operators.\n  The framework is validated through a two-stage objective evaluation pipeline. First, in cognitive codec verification, CTE text yields a Jensen-Shannon divergence of 0.0614 from human text (vs. 0.4431 for standard LLM output), passes double-blind professional media review, and achieves an intraclass correlation coefficient ICC > 0.9 for cognitive profile alignment across heterogeneous models. Second, in functional gain evaluation, isomorphic stress tests in the A-share market show that strategies incorporating CTE-generated data reduce maximum drawdown by 47.4% during the 2015 crash and deliver 8.6% Defensive Alpha, exceeding transaction costs by a factor of 33.\n  Our findings demonstrate that modelling human cognitive limitations -- not copying surface data -- enables synthetic data with genuine functional gain, offering a viable technical pathway toward resolving the AI data-collapse crisis.",
      "tldr_zh": "è¯¥ç ”ç©¶æ¢è®¨äº†æ¨¡å‹å´©æºƒ(model collapse)çš„æˆå› ï¼ŒæŒ‡å‡ºå½“å‰åˆæˆæ•°æ®èŒƒå¼å› è¿‡åˆ†è¿½æ±‚ç»Ÿè®¡å¹³æ»‘è€Œå‰”é™¤äº†äººç±»æ–‡æœ¬ä¸­ç‰¹æœ‰çš„é•¿å°¾è®¤çŸ¥ä¸è§„åˆ™æ€§ã€‚ä¸ºæ­¤ï¼Œä½œè€…æå‡ºäº†é©±åŠ¨è®¤çŸ¥è®¡ç®—æ¡†æ¶(Prompt-driven Cognitive Computing Framework, PMCSF)ï¼Œå…¶æ ¸å¿ƒåŒ…å«è®¤çŸ¥çŠ¶æ€è§£ç å™¨(Cognitive State Decoder, CSD)ä¸è®¤çŸ¥æ–‡æœ¬ç¼–ç å™¨(Cognitive Text Encoder, CTE)ï¼Œé€šè¿‡æ¨¡æ‹Ÿäººç±»è®¤çŸ¥å±€é™æ€§å¹¶åˆ©ç”¨è®¤çŸ¥æ‰°åŠ¨ç®—å­(Cognitive Perturbation Operators)ç”ŸæˆåŒ…å«â€œä¸å®Œç¾â€ç‰¹å¾çš„æ–‡æœ¬ã€‚å®éªŒéªŒè¯æ˜¾ç¤ºï¼ŒCTEç”Ÿæˆçš„æ–‡æœ¬åœ¨Jensen-Shannonæ•£åº¦ä¸Šä¸äººç±»æ–‡æœ¬é«˜åº¦ä¸€è‡´ï¼Œä¸”åœ¨Aè‚¡å¸‚åœºå‹åŠ›æµ‹è¯•ä¸­æ˜¾è‘—é™ä½äº†ç­–ç•¥çš„æœ€å¤§å›æ’¤å¹¶æä¾›äº†8.6%çš„é˜²å¾¡æ€§é˜¿å°”æ³•(Defensive Alpha)ã€‚è¯¥ç ”ç©¶è¯æ˜äº†æ¨¡æ‹Ÿäººç±»è®¤çŸ¥è¾¹ç•Œ(Cognitive Boundedness)è€Œéç®€å•æ¨¡ä»¿è¡¨é¢æ•°æ®åˆ†å¸ƒï¼Œæ˜¯ç”Ÿæˆå…·æœ‰åŠŸèƒ½å¢ç›Šçš„åˆæˆæ•°æ®å¹¶è§£å†³äººå·¥æ™ºèƒ½æ•°æ®å´©æºƒå±æœºçš„æœ‰æ•ˆæŠ€æœ¯è·¯å¾„ã€‚",
      "categories": [
        "cs.AI",
        "cs.CL",
        "cs.CY",
        "cs.LG",
        "q-fin.TR"
      ],
      "primary_category": "cs.AI",
      "comment": "60 pages,9 figures. v3: Major update. Added 3D topological visualization (Figure 1) and independent computational verification of the Adaptive Markets Hypothesis (AMH). Includes comprehensive Supplementary Materials (algorithmic pseudocode, system architecture, and real-time GARCH logs) for technical reproducibility",
      "pdf_url": "https://arxiv.org/pdf/2512.01354v3",
      "published_date": "2025-12-01 07:09:38 UTC",
      "updated_date": "2025-12-08 22:57:17 UTC",
      "processing_status": "completed",
      "attempts": 1,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "llm_backup_calls": 0,
      "last_update": "2026-01-26T12:36:07.480592+00:00"
    },
    {
      "arxiv_id": "2512.01351v1",
      "title": "Benchmarking Overton Pluralism in LLMs",
      "title_zh": "å¤§è¯­è¨€æ¨¡å‹ä¸­ Overton å¤šå…ƒæ€§çš„åŸºå‡†è¯„æµ‹",
      "authors": [
        "Elinor Poole-Dayan",
        "Jiayi Wu",
        "Taylor Sorensen",
        "Jiaxin Pei",
        "Michiel A. Bakker"
      ],
      "abstract": "We introduce a novel framework for measuring Overton pluralism in LLMs--the extent to which diverse viewpoints are represented in model outputs. We (i) formalize Overton pluralism as a set coverage metric (OvertonScore), (ii) conduct a large-scale U.S.-representative human study (N = 1209; 60 questions; 8 LLMs), and (iii) develop an automated benchmark that closely reproduces human judgments. On average, models achieve OvertonScores of 0.35--0.41, with DeepSeek V3 performing best; yet all models remain far below the theoretical maximum of 1.0, revealing substantial headroom for improvement. Because repeated large-scale human studies are costly and slow, scalable evaluation tools are essential for model development. Hence, we propose an automated benchmark that achieves high rank correlation with human judgments ($Ï=0.88$), providing a practical proxy without replacing human assessment. By turning pluralistic alignment from a normative aim into a measurable benchmark, our work establishes a foundation for systematic progress toward more pluralistic LLMs.",
      "tldr_zh": "è¯¥ç ”ç©¶æå‡ºäº†ä¸€ä¸ªç”¨äºè¡¡é‡å¤§è¯­è¨€æ¨¡å‹ (LLMs) ä¸­ Overton pluralism çš„æ–°å‹æ¡†æ¶ï¼Œæ—¨åœ¨è¯„ä¼°æ¨¡å‹è¾“å‡ºä¸­ä»£è¡¨ä¸åŒè§‚ç‚¹çš„ç¨‹åº¦ã€‚ç ”ç©¶è€…å°† Overton pluralism æ­£å¼å®šä¹‰ä¸ºä¸€ç§é›†åˆè¦†ç›–æŒ‡æ ‡ OvertonScoreï¼Œå¹¶å¼€å±•äº†ä¸€é¡¹å…·æœ‰ç¾å›½ä»£è¡¨æ€§çš„å¤§è§„æ¨¡äººç±»ç ”ç©¶ï¼ˆN=1209ï¼‰ä»¥éªŒè¯è¯¥æ¡†æ¶ã€‚å®éªŒç»“æœæ˜¾ç¤ºï¼Œç°æœ‰æ¨¡å‹çš„å¹³å‡ OvertonScore ä»…åœ¨ 0.35 è‡³ 0.41 ä¹‹é—´ï¼Œå…¶ä¸­ DeepSeek V3 è¡¨ç°æœ€ä½³ï¼Œä½†æ‰€æœ‰æ¨¡å‹å‡æ˜¾è‘—ä½äº 1.0 çš„ç†è®ºæœ€å¤§å€¼ï¼Œè¡¨æ˜ä»æœ‰å·¨å¤§çš„æå‡ç©ºé—´ã€‚æ­¤å¤–ï¼Œç ”ç©¶å›¢é˜Ÿå¼€å‘äº†ä¸€ä¸ªä¸äººç±»åˆ¤æ–­é«˜åº¦ç›¸å…³ï¼ˆÏ=0.88ï¼‰çš„è‡ªåŠ¨åŒ–åŸºå‡†æµ‹è¯•å·¥å…·ï¼Œä¸ºæ¨¡å‹è¯„ä¼°æä¾›äº†é«˜æ•ˆçš„å¯æ‰©å±•ä»£ç†æ‰‹æ®µã€‚è¯¥å·¥ä½œå°†å¤šå…ƒåŒ–å¯¹é½ (pluralistic alignment) ä»è§„èŒƒæ€§ç›®æ ‡è½¬åŒ–ä¸ºå¯è¡¡é‡çš„åŸºå‡†ï¼Œä¸ºå®ç°æ›´å…· pluralistic ç‰¹æ€§çš„ LLMs å¥ å®šäº†ç³»ç»Ÿæ€§è¿›æ­¥çš„åŸºç¡€ã€‚",
      "categories": [
        "cs.AI"
      ],
      "primary_category": "cs.AI",
      "comment": "",
      "pdf_url": "https://arxiv.org/pdf/2512.01351v1",
      "published_date": "2025-12-01 07:04:20 UTC",
      "updated_date": "2025-12-01 07:04:20 UTC",
      "processing_status": "completed",
      "attempts": 1,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "llm_backup_calls": 0,
      "last_update": "2026-01-26T12:36:27.071635+00:00"
    },
    {
      "arxiv_id": "2512.01343v2",
      "title": "Intrinsic Structure as a Proxy for Saliency: SVD-Based Weight Preservation for Mixed-Precision Quantization in Large Language Models",
      "title_zh": "ä»¥å†…åœ¨ç»“æ„ä½œä¸ºæ˜¾è‘—æ€§è¡¨å¾ï¼šå¤§è¯­è¨€æ¨¡å‹æ··åˆç²¾åº¦é‡åŒ–ä¸­åŸºäº SVD çš„æƒé‡ä¿ç•™",
      "authors": [
        "Shashank Landge",
        "Abhishek Patil",
        "Tejas kamble",
        "Bhushan Buddhivant",
        "Priyanka Joshi"
      ],
      "abstract": "As Large Language Models (LLMs) continue to scale in parameter count, deploying them on commodity hardware has become increasingly challenging. Post-Training Quantization (PTQ) addresses this by reducing the precision of model weights, typically to 4-bit or lower. However, uniform quantization often leads to significant performance degradation due to the presence of ``outlier features'' -- weights that, while few in number, are critical for maintaining model accuracy. Current state-of-the-art methods such as AWQ (Activation-aware Weight Quantization) and SpQR (Sparse Quantization Representations) rely on calibration data to identify these salient weights via activation magnitudes or Hessian sensitivity. In scenarios where data privacy is paramount or calibration data is unavailable, these methods are inapplicable.\n  In this work, we propose a data-free, structure-aware hypothesis: that the weights identified as Principal Components via Singular Value Decomposition (SVD) are intrinsically important to the model's downstream performance. We introduce a novel selection heuristic that preserves the top-$k$ weights aligned with the principal components in FP32, while aggressively quantizing the residual weights. We compare our method against activation-aware (AWQ) and second-order (SpQR) methods across GLUE benchmarks (MRPC, RTE, QNLI) using a DistilBERT backbone. Our experiments reveal that structural importance is highly correlated with functional importance. On the challenging RTE task, our SVD-based method achieves an accuracy of 66.06\\%, outperforming both AWQ (65.34\\%) and SpQR (65.34\\%) at high protection budgets, validating that intrinsic matrix structure can serve as a robust proxy for weight saliency without the need for forward passes or calibration data.",
      "tldr_zh": "è¯¥ç ”ç©¶æå‡ºäº†ä¸€ç§åŸºäºç»“æ„æ„ŸçŸ¥çš„æ— æ•°æ®é‡åŒ–æ–¹æ³•ï¼Œæ—¨åœ¨è§£å†³å¤§è¯­è¨€æ¨¡å‹(LLMs)åœ¨è®­ç»ƒåé‡åŒ–(PTQ)è¿‡ç¨‹ä¸­å› â€œå¼‚å¸¸ç‰¹å¾â€æƒé‡å¯¼è‡´çš„æ€§èƒ½ä¸‹é™é—®é¢˜ã€‚ä½œè€…æå‡ºäº†ä¸€ä¸ªæ ¸å¿ƒå‡è®¾ï¼Œå³é€šè¿‡å¥‡å¼‚å€¼åˆ†è§£(SVD)ç¡®å®šçš„ä¸»æˆåˆ†æƒé‡å¯¹æ¨¡å‹çš„ä¸‹æ¸¸æ€§èƒ½å…·æœ‰å†…åœ¨çš„é‡è¦æ€§ã€‚è¯¥æ–¹æ³•å¼•å…¥äº†ä¸€ç§æ–°çš„å¯å‘å¼é€‰æ‹©æœºåˆ¶ï¼Œå°†ä¸FP32ä¸»æˆåˆ†å¯¹é½çš„å‰kä¸ªæƒé‡ä¿ç•™ï¼Œè€Œå¯¹å‰©ä½™æƒé‡è¿›è¡Œæ¿€è¿›é‡åŒ–ã€‚é€šè¿‡åœ¨DistilBERTéª¨å¹²ç½‘ç»œä¸Šçš„GLUEåŸºå‡†æµ‹è¯•ï¼Œç ”ç©¶äººå‘˜å°†è¯¥æ–¹æ³•ä¸éœ€è¦æ ¡å‡†æ•°æ®çš„AWQå’ŒSpQRç­‰å…ˆè¿›æ–¹æ³•è¿›è¡Œäº†å¯¹æ¯”ã€‚å®éªŒç»“æœè¡¨æ˜ï¼Œæƒé‡çš„ç»“æ„é‡è¦æ€§ä¸åŠŸèƒ½é‡è¦æ€§é«˜åº¦ç›¸å…³ï¼Œç‰¹åˆ«æ˜¯åœ¨RTEä»»åŠ¡ä¸­ï¼Œè¯¥æ–¹æ³•ä»¥66.06%çš„å‡†ç¡®ç‡ä¼˜äºAWQå’ŒSpQRã€‚è¿™è¯æ˜äº†çŸ©é˜µçš„å†…åœ¨ç»“æ„å¯ä»¥åœ¨æ— éœ€å‰å‘ä¼ æ’­æˆ–æ ¡å‡†æ•°æ®çš„æƒ…å†µä¸‹ï¼Œä½œä¸ºæƒé‡æ˜¾è‘—æ€§(Saliency)çš„å¯é ä»£ç†ã€‚è¯¥ç ”ç©¶ä¸ºæ•°æ®éšç§æ•æ„Ÿæˆ–ç¼ºä¹æ ¡å‡†æ•°æ®çš„æ¨¡å‹éƒ¨ç½²åœºæ™¯æä¾›äº†ä¸€ç§é«˜æ•ˆçš„æ··åˆç²¾åº¦é‡åŒ–æ–¹æ¡ˆã€‚",
      "categories": [
        "cs.LG",
        "cs.AI"
      ],
      "primary_category": "cs.LG",
      "comment": "",
      "pdf_url": "https://arxiv.org/pdf/2512.01343v2",
      "published_date": "2025-12-01 06:58:30 UTC",
      "updated_date": "2025-12-02 05:26:59 UTC",
      "processing_status": "completed",
      "attempts": 1,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "llm_backup_calls": 0,
      "last_update": "2026-01-26T12:36:36.772848+00:00"
    },
    {
      "arxiv_id": "2512.01335v1",
      "title": "EmoRAG: Evaluating RAG Robustness to Symbolic Perturbations",
      "title_zh": "EmoRAGï¼šRAG ç³»ç»Ÿå¯¹ç¬¦å·æ‰°åŠ¨çš„é²æ£’æ€§è¯„ä¼°",
      "authors": [
        "Xinyun Zhou",
        "Xinfeng Li",
        "Yinan Peng",
        "Ming Xu",
        "Xuanwang Zhang",
        "Miao Yu",
        "Yidong Wang",
        "Xiaojun Jia",
        "Kun Wang",
        "Qingsong Wen",
        "XiaoFeng Wang",
        "Wei Dong"
      ],
      "abstract": "Retrieval-Augmented Generation (RAG) systems are increasingly central to robust AI, enhancing large language model (LLM) faithfulness by incorporating external knowledge. However, our study unveils a critical, overlooked vulnerability: their profound susceptibility to subtle symbolic perturbations, particularly through near-imperceptible emoticon tokens such as \"(@_@)\" that can catastrophically mislead retrieval, termed EmoRAG. We demonstrate that injecting a single emoticon into a query makes it nearly 100% likely to retrieve semantically unrelated texts that contain a matching emoticon. Our extensive experiment across general question-answering and code domains, using a range of state-of-the-art retrievers and generators, reveals three key findings: (I) Single-Emoticon Disaster: Minimal emoticon injections cause maximal disruptions, with a single emoticon almost 100% dominating RAG output. (II) Positional Sensitivity: Placing an emoticon at the beginning of a query can cause severe perturbation, with F1-Scores exceeding 0.92 across all datasets. (III) Parameter-Scale Vulnerability: Counterintuitively, models with larger parameters exhibit greater vulnerability to the interference. We provide an in-depth analysis to uncover the underlying mechanisms of these phenomena. Furthermore, we raise a critical concern regarding the robustness assumption of current RAG systems, envisioning a threat scenario where an adversary exploits this vulnerability to manipulate the RAG system. We evaluate standard defenses and find them insufficient against EmoRAG. To address this, we propose targeted defenses, analyzing their strengths and limitations in mitigating emoticon-based perturbations. Finally, we outline future directions for building robust RAG systems.",
      "tldr_zh": "è¯¥ç ”ç©¶æ­ç¤ºäº†æ£€ç´¢å¢å¼ºç”Ÿæˆ(Retrieval-Augmented Generation, RAG)ç³»ç»Ÿåœ¨é¢å¯¹å¾®å°çš„ç¬¦å·æ‰°åŠ¨ï¼ˆå¦‚è¡¨æƒ…ç¬¦å·ï¼‰æ—¶çš„ä¸¥é‡è„†å¼±æ€§ï¼Œå¹¶å°†å…¶å®šä¹‰ä¸ºEmoRAGã€‚é€šè¿‡åœ¨æŸ¥è¯¢ä¸­æ³¨å…¥å•ä¸ªè¡¨æƒ…ç¬¦å·ï¼ˆå¦‚\"(@_@)\"ï¼‰ï¼Œç ”ç©¶è€…å‘ç°æ£€ç´¢å™¨ææ˜“è¢«å¼•å¯¼è‡³æ£€ç´¢è¯­ä¹‰æ— å…³çš„æ–‡æœ¬ï¼Œå¯¼è‡´RAGç³»ç»Ÿçš„è¾“å‡ºè¢«å®Œå…¨å¹²æ‰°ã€‚å®éªŒè·¨è¶Šäº†é€šç”¨é—®ç­”å’Œä»£ç é¢†åŸŸï¼Œç»“æœæ˜¾ç¤ºè¡¨æƒ…ç¬¦å·åœ¨æŸ¥è¯¢å¼€å¤´æ—¶å¹²æ‰°æœ€å¼ºï¼Œä¸”å‚æ•°è§„æ¨¡è¶Šå¤§çš„æ¨¡å‹è¡¨ç°å‡ºè¶Šé«˜çš„è„†å¼±æ€§ã€‚è®ºæ–‡é€šè¿‡æ·±å…¥åˆ†æåº•å±‚æœºåˆ¶æ­ç¤ºäº†è¿™äº›ç°è±¡ï¼Œå¹¶æŒ‡å‡ºå½“å‰æ ‡å‡†çš„é˜²å¾¡æ‰‹æ®µåœ¨åº”å¯¹æ­¤ç±»æ”»å‡»æ—¶ä»æ˜¾ä¸è¶³ã€‚æœ€åï¼Œç ”ç©¶æå‡ºäº†é’ˆå¯¹æ€§çš„é˜²å¾¡æ–¹æ¡ˆï¼Œå¹¶ä¸ºæ„å»ºå…·æœ‰é²æ£’æ€§çš„RAGç³»ç»ŸæŒ‡æ˜äº†æœªæ¥çš„ç ”ç©¶æ–¹å‘ã€‚",
      "categories": [
        "cs.CR",
        "cs.AI",
        "cs.CL"
      ],
      "primary_category": "cs.CR",
      "comment": "Accepted to ACM SIGKDD Conference on Knowledge Discovery and Data Mining (KDD) 2026",
      "pdf_url": "https://arxiv.org/pdf/2512.01335v1",
      "published_date": "2025-12-01 06:53:49 UTC",
      "updated_date": "2025-12-01 06:53:49 UTC",
      "processing_status": "completed",
      "attempts": 1,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "llm_backup_calls": 0,
      "last_update": "2026-01-26T12:36:31.573111+00:00"
    },
    {
      "arxiv_id": "2512.01331v1",
      "title": "A Fast Heuristic Search Approach for Energy-Optimal Profile Routing for Electric Vehicles",
      "title_zh": "ä¸€ç§é¢å‘ç”µåŠ¨æ±½è½¦èƒ½è€—æœ€ä¼˜å‰–é¢è·¯ç”±çš„å¿«é€Ÿå¯å‘å¼æœç´¢æ–¹æ³•",
      "authors": [
        "Saman Ahmadi",
        "Mahdi Jalili"
      ],
      "abstract": "We study the energy-optimal shortest path problem for electric vehicles (EVs) in large-scale road networks, where recuperated energy along downhill segments introduces negative energy costs. While traditional point-to-point pathfinding algorithms for EVs assume a known initial energy level, many real-world scenarios involving uncertainty in available energy require planning optimal paths for all possible initial energy levels, a task known as energy-optimal profile search. Existing solutions typically rely on specialized profile-merging procedures within a label-correcting framework that results in searching over complex profiles. In this paper, we propose a simple yet effective label-setting approach based on multi-objective A* search, which employs a novel profile dominance rule to avoid generating and handling complex profiles. We develop four variants of our method and evaluate them on real-world road networks enriched with realistic energy consumption data. Experimental results demonstrate that our energy profile A* search achieves performance comparable to energy-optimal A* with a known initial energy level.",
      "tldr_zh": "æœ¬ç ”ç©¶æ¢è®¨äº†å¤§å°ºåº¦é“è·¯ç½‘ç»œä¸­ç”µåŠ¨æ±½è½¦ (Electric Vehicles, EVs) çš„èƒ½é‡æœ€ä¼˜è·¯å¾„è§„åˆ’é—®é¢˜ï¼Œé‡ç‚¹è§£å†³ç”±äºä¸‹å¡èƒ½é‡å›æ”¶å¯¼è‡´çš„è´Ÿèƒ½é‡æ¶ˆè€—æŒ‘æˆ˜ã€‚é’ˆå¯¹ä¼ ç»Ÿç®—æ³•åœ¨åˆå§‹èƒ½é‡ä¸ç¡®å®šæ—¶éœ€è¿›è¡Œå¤æ‚çš„èƒ½é‡æœ€ä¼˜å‰–é¢æœç´¢ (energy-optimal profile search) çš„å±€é™æ€§ï¼Œæœ¬æ–‡æå‡ºäº†ä¸€ç§åŸºäºå¤šç›®æ ‡ A* æœç´¢ (multi-objective A* search) çš„é«˜æ•ˆæ ‡ç­¾è®¾ç½® (label-setting) æ–¹æ³•ã€‚è¯¥æ–¹æ³•çš„æ ¸å¿ƒåœ¨äºå¼•å…¥äº†ä¸€ç§æ–°é¢–çš„å‰–é¢æ”¯é…è§„åˆ™ (profile dominance rule)ï¼Œä»è€Œæœ‰æ•ˆé¿å…äº†ç”Ÿæˆå’Œå¤„ç†å¤æ‚çš„å‰–é¢æ•°æ®ã€‚ç ”ç©¶å›¢é˜Ÿåœ¨ç»“åˆçœŸå®èƒ½æºæ¶ˆè€—æ•°æ®çš„ç°å®è·¯ç½‘ä¸­è¯„ä¼°äº†è¯¥æ–¹æ³•çš„å››ä¸ªå˜ä½“ã€‚å®éªŒç»“æœè¯æ˜ï¼Œè¿™ç§èƒ½é‡å‰–é¢ A* æœç´¢åœ¨æ€§èƒ½ä¸Šå¯ä¸å·²çŸ¥åˆå§‹èƒ½é‡æ°´å¹³çš„èƒ½é‡æœ€ä¼˜ A* ç®—æ³•ç›¸åª²ç¾ã€‚è¯¥ç ”ç©¶ä¸ºä¸ç¡®å®šåˆå§‹èƒ½é‡æ¡ä»¶ä¸‹çš„ç”µåŠ¨æ±½è½¦é«˜æ•ˆè·¯å¾„è§„åˆ’æä¾›äº†å®ç”¨çš„å¯å‘å¼æœç´¢æ–¹æ¡ˆã€‚",
      "categories": [
        "cs.AI"
      ],
      "primary_category": "cs.AI",
      "comment": "13 pages, 5 Figures, 1 table, To appear as part of AAAI 2026 Proceedings",
      "pdf_url": "https://arxiv.org/pdf/2512.01331v1",
      "published_date": "2025-12-01 06:45:34 UTC",
      "updated_date": "2025-12-01 06:45:34 UTC",
      "processing_status": "completed",
      "attempts": 1,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "llm_backup_calls": 0,
      "last_update": "2026-01-26T12:36:30.178956+00:00"
    },
    {
      "arxiv_id": "2512.01321v1",
      "title": "Extending NGU to Multi-Agent RL: A Preliminary Study",
      "title_zh": "å°† NGU æ‰©å±•è‡³å¤šæ™ºèƒ½ä½“å¼ºåŒ–å­¦ä¹ ï¼šä¸€é¡¹åˆæ­¥ç ”ç©¶",
      "authors": [
        "Juan Hernandez",
        "Diego FernÃ¡ndez",
        "Manuel Cifuentes",
        "Denis Parra",
        "Rodrigo Toro Icarte"
      ],
      "abstract": "The Never Give Up (NGU) algorithm has proven effective in reinforcement learning tasks with sparse rewards by combining episodic novelty and intrinsic motivation. In this work, we extend NGU to multi-agent environments and evaluate its performance in the simple_tag environment from the PettingZoo suite. Compared to a multi-agent DQN baseline, NGU achieves moderately higher returns and more stable learning dynamics. We investigate three design choices: (1) shared replay buffer versus individual replay buffers, (2) sharing episodic novelty among agents using different k thresholds, and (3) using heterogeneous values of the beta parameter. Our results show that NGU with a shared replay buffer yields the best performance and stability, highlighting that the gains come from combining NGU intrinsic exploration with experience sharing. Novelty sharing performs comparably when k = 1 but degrades learning for larger values. Finally, heterogeneous beta values do not improve over a small common value. These findings suggest that NGU can be effectively applied in multi-agent settings when experiences are shared and intrinsic exploration signals are carefully tuned.",
      "tldr_zh": "è¯¥ç ”ç©¶æ—¨åœ¨å°† Never Give Up (NGU) ç®—æ³•æ‰©å±•è‡³å¤šæ™ºèƒ½ä½“å¼ºåŒ–å­¦ä¹  (Multi-Agent RL) é¢†åŸŸï¼Œä»¥è§£å†³ç¨€ç–å¥–åŠ±ç¯å¢ƒä¸‹çš„å­¦ä¹ éš¾é¢˜ã€‚é€šè¿‡åœ¨ PettingZoo çš„ simple_tag ç¯å¢ƒä¸­è¿›è¡Œå®éªŒï¼Œç ”ç©¶å‘ç° NGU ç›¸æ¯”äºå¤šæ™ºèƒ½ä½“ DQN åŸºå‡†æ¨¡å‹å…·æœ‰æ›´é«˜çš„å›æŠ¥å’Œæ›´ç¨³å®šçš„å­¦ä¹ åŠ¨æ€ã€‚ç ”ç©¶é‡ç‚¹è¯„ä¼°äº†å…±äº«ç»éªŒå›æ”¾æ±  (Shared Replay Buffer)ã€æƒ…èŠ‚æ–°é¢–æ€§ (Episodic Novelty) å…±äº«ä»¥åŠå¼‚æ„ beta å‚æ•°ç­‰è®¾è®¡é€‰æ‹©ã€‚ç»“æœè¡¨æ˜ï¼Œé‡‡ç”¨å…±äº«ç»éªŒå›æ”¾æ± çš„ NGU è¡¨ç°æœ€ä¸ºå‡ºè‰²ä¸”ç¨³å®šï¼Œè¯æ˜äº†å†…åœ¨æ¢ç´¢ä¿¡å·ä¸ç»éªŒå…±äº«ç»“åˆçš„æœ‰æ•ˆæ€§ã€‚è€Œåœ¨æ–°é¢–æ€§å…±äº«æ–¹é¢ï¼Œä»…åœ¨ k=1 æ—¶æ•ˆæœè¾ƒå¥½ï¼Œä¸”å®éªŒè¯æ˜å¼‚æ„ beta å€¼å¹¶ä¸èƒ½ä¼˜äºç»Ÿä¸€çš„è¾ƒå°å–å€¼ã€‚è¯¥ç ”ç©¶ä¸º NGU åœ¨å¤šæ™ºèƒ½ä½“è®¾ç½®ä¸‹çš„åº”ç”¨æä¾›äº†åˆæ­¥éªŒè¯ï¼Œå¹¶å¼ºè°ƒäº†è°ƒä¼˜å†…åœ¨æ¢ç´¢ä¿¡å·ä¸ç»éªŒå…±äº«æœºåˆ¶çš„å…³é”®ä½œç”¨ã€‚",
      "categories": [
        "cs.AI",
        "cs.LG"
      ],
      "primary_category": "cs.AI",
      "comment": "9 pages, 4 figures, 1 table. Accepted at the LatinX in AI (LXAI) Workshop at NeurIPS 2025. Includes experimental results for Multi-NGU and Multi-DQN in the PettingZoo simple_tag environment",
      "pdf_url": "https://arxiv.org/pdf/2512.01321v1",
      "published_date": "2025-12-01 06:24:37 UTC",
      "updated_date": "2025-12-01 06:24:37 UTC",
      "processing_status": "completed",
      "attempts": 1,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "llm_backup_calls": 0,
      "last_update": "2026-01-26T12:36:39.759480+00:00"
    },
    {
      "arxiv_id": "2512.01319v1",
      "title": "Rethinking Intracranial Aneurysm Vessel Segmentation: A Perspective from Computational Fluid Dynamics Applications",
      "title_zh": "é‡æ–°å®¡è§†é¢…å†…åŠ¨è„‰ç˜¤è¡€ç®¡åˆ†å‰²ï¼šè®¡ç®—æµä½“åŠ›å­¦åº”ç”¨è§†è§’",
      "authors": [
        "Feiyang Xiao",
        "Yichi Zhang",
        "Xigui Li",
        "Yuanye Zhou",
        "Chen Jiang",
        "Xin Guo",
        "Limei Han",
        "Yuxin Li",
        "Fengping Zhu",
        "Yuan Cheng"
      ],
      "abstract": "The precise segmentation of intracranial aneurysms and their parent vessels (IA-Vessel) is a critical step for hemodynamic analyses, which mainly depends on computational fluid dynamics (CFD). However, current segmentation methods predominantly focus on image-based evaluation metrics, often neglecting their practical effectiveness in subsequent CFD applications. To address this deficiency, we present the Intracranial Aneurysm Vessel Segmentation (IAVS) dataset, the first comprehensive, multi-center collection comprising 641 3D MRA images with 587 annotations of aneurysms and IA-Vessels. In addition to image-mask pairs, IAVS dataset includes detailed hemodynamic analysis outcomes, addressing the limitations of existing datasets that neglect topological integrity and CFD applicability. To facilitate the development and evaluation of clinically relevant techniques, we construct two evaluation benchmarks including global localization of aneurysms (Stage I) and fine-grained segmentation of IA-Vessel (Stage II) and develop a simple and effective two-stage framework, which can be used as a out-of-the-box method and strong baseline. For comprehensive evaluation of applicability of segmentation results, we establish a standardized CFD applicability evaluation system that enables the automated and consistent conversion of segmentation masks into CFD models, offering an applicability-focused assessment of segmentation outcomes. The dataset, code, and model will be public available at https://github.com/AbsoluteResonance/IAVS.",
      "tldr_zh": "è¯¥ç ”ç©¶é’ˆå¯¹é¢…å†…åŠ¨è„‰ç˜¤åŠå…¶æ¯è¡€ç®¡ï¼ˆIA-Vesselï¼‰åˆ†å‰²æ–¹æ³•è¿‡äºå…³æ³¨å›¾åƒè¯„ä»·æŒ‡æ ‡è€Œå¿½è§†è®¡ç®—æµä½“åŠ›å­¦ï¼ˆComputational Fluid Dynamics, CFDï¼‰å®é™…åº”ç”¨æ•ˆèƒ½çš„é—®é¢˜ï¼Œæå‡ºäº†é¦–ä¸ªå¤§è§„æ¨¡å¤šä¸­å¿ƒæ•°æ®é›†IAVSã€‚è¯¥æ•°æ®é›†åŒ…å«641ä¾‹3D MRAå½±åƒåŠ587ä»½é’ˆå¯¹åŠ¨è„‰ç˜¤å’ŒIA-Vesselçš„ç²¾ç»†æ ‡æ³¨ï¼Œå¹¶é¦–æ¬¡æ•´åˆäº†è¡€æµåŠ¨åŠ›å­¦åˆ†æç»“æœï¼Œæœ‰æ•ˆè§£å†³äº†ç°æœ‰æ•°æ®é›†åœ¨æ‹“æ‰‘å®Œæ•´æ€§å’ŒCFDé€‚ç”¨æ€§æ–¹é¢çš„ä¸è¶³ã€‚ç ”ç©¶æ„å»ºäº†åŒ…å«å…¨å±€å®šä½ï¼ˆStage Iï¼‰ä¸ç²¾ç»†åˆ†å‰²ï¼ˆStage IIï¼‰çš„åŒé˜¶æ®µè¯„ä»·åŸºå‡†ï¼Œå¹¶å¼€å‘äº†ä¸€ä¸ªç®€å•é«˜æ•ˆçš„äºŒé˜¶æ®µåŸºçº¿æ¡†æ¶ã€‚æ­¤å¤–ï¼Œç ”ç©¶è¿˜å»ºç«‹äº†ä¸€å¥—æ ‡å‡†åŒ–çš„CFDé€‚ç”¨æ€§è¯„ä»·ç³»ç»Ÿï¼Œå®ç°äº†ä»åˆ†å‰²æ©ç åˆ°CFDæ¨¡å‹çš„è‡ªåŠ¨åŒ–ä¸€è‡´æ€§è½¬æ¢ï¼Œä¸ºè¯„ä¼°åˆ†å‰²ç»“æœçš„ä¸´åºŠå®ç”¨ä»·å€¼æä¾›äº†æ–°æ ‡å‡†ã€‚ç›®å‰è¯¥æ•°æ®é›†ã€ä»£ç åŠæ¨¡å‹å‡å·²å‘å­¦æœ¯ç•Œå¼€æºã€‚",
      "categories": [
        "cs.CV",
        "cs.AI"
      ],
      "primary_category": "cs.CV",
      "comment": "18 pages, 5 figures",
      "pdf_url": "https://arxiv.org/pdf/2512.01319v1",
      "published_date": "2025-12-01 06:23:07 UTC",
      "updated_date": "2025-12-01 06:23:07 UTC",
      "processing_status": "completed",
      "attempts": 1,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "llm_backup_calls": 0,
      "last_update": "2026-01-26T12:36:40.989175+00:00"
    },
    {
      "arxiv_id": "2512.01317v2",
      "title": "Data-Driven Learnability Transition of Measurement-Induced Entanglement",
      "title_zh": "æµ‹é‡è¯±å¯¼çº ç¼ çš„æ•°æ®é©±åŠ¨å¯å­¦ä¹ æ€§è½¬å˜",
      "authors": [
        "Dongheng Qian",
        "Jing Wang"
      ],
      "abstract": "Measurement-induced entanglement (MIE) captures how local measurements generate long-range quantum correlations and drive dynamical phase transitions in many-body systems. Yet estimating MIE experimentally remains challenging: direct evaluation requires extensive post-selection over measurement outcomes, raising the question of whether MIE is accessible with only polynomial resources. We address this challenge by reframing MIE detection as a data-driven learning problem that assumes no prior knowledge of state preparation. Using measurement records alone, we train a neural network in a self-supervised manner to predict the uncertainty metric for MIE--the gap between upper and lower bounds of the average post-measurement bipartite entanglement. Applied to random circuits with one-dimensional all-to-all connectivity and two-dimensional nearest-neighbor coupling, our method reveals a learnability transition with increasing circuit depth: below a threshold, the uncertainty is small and decreases with polynomial measurement data and model parameters, while above it the uncertainty remains large despite increasing resources. We further verify this transition experimentally on current noisy quantum devices, demonstrating its robustness to realistic noise. These results highlight the power of data-driven approaches for learning MIE and delineate the practical limits of its classical learnability.",
      "tldr_zh": "è¯¥ç ”ç©¶é’ˆå¯¹æµ‹é‡è¯±å¯¼çº ç¼  (Measurement-induced entanglement, MIE) åœ¨å®éªŒè¯„ä¼°ä¸­é¢ä¸´çš„é«˜æ˜‚åé€‰æ‹© (post-selection) æˆæœ¬ï¼Œæå‡ºäº†ä¸€ç§æ— éœ€çŠ¶æ€å‡†å¤‡å…ˆéªŒçŸ¥è¯†çš„æ•°æ®é©±åŠ¨å­¦ä¹ æ–¹æ³•ã€‚ä½œè€…é€šè¿‡ä»…åˆ©ç”¨æµ‹é‡è®°å½•ï¼Œä»¥è‡ªç›‘ç£ (self-supervised) æ–¹å¼è®­ç»ƒç¥ç»ç½‘ç»œæ¥é¢„æµ‹ MIE çš„ä¸ç¡®å®šæ€§æŒ‡æ ‡ï¼Œå³åæµ‹é‡åŒä½“çº ç¼ ä¸Šä¸‹ç•Œä¹‹é—´çš„å·®è·ã€‚åœ¨å¯¹ä¸€ç»´å…¨è¿æ¥å’ŒäºŒç»´æœ€è¿‘é‚»è€¦åˆéšæœºç”µè·¯çš„åˆ†æä¸­ï¼Œç ”ç©¶å‘ç°äº†ä¸€ä¸ªéšç”µè·¯æ·±åº¦å¢åŠ çš„å¯å­¦ä¹ æ€§è½¬å˜ (learnability transition)ï¼šåœ¨é˜ˆå€¼ä¹‹ä¸‹ï¼Œä¸ç¡®å®šæ€§å¯éšå¤šé¡¹å¼èµ„æºå¢åŠ è€Œæœ‰æ•ˆé™ä½ï¼Œè€Œåœ¨é˜ˆå€¼ä¹‹ä¸Šåˆ™éš¾ä»¥é€šè¿‡å¢åŠ èµ„æºæ¥æ¶ˆé™¤ã€‚è¯¥ç ”ç©¶åœ¨å™ªå£°é‡å­è®¾å¤‡ä¸ŠæˆåŠŸéªŒè¯äº†è¿™ä¸€è½¬å˜çš„é²æ£’æ€§ï¼Œä¸ä»…å±•ç¤ºäº†æ•°æ®é©±åŠ¨æ‰‹æ®µåœ¨æ¢æµ‹ MIE æ–¹é¢çš„æ•ˆåŠ›ï¼Œä¹Ÿæ¸…æ™°ç•Œå®šäº†å…¶åœ¨ç»å…¸è®¡ç®—èµ„æºä¸‹çš„å¯å­¦ä¹ æ€§æé™ã€‚",
      "categories": [
        "quant-ph",
        "cond-mat.dis-nn",
        "cs.AI"
      ],
      "primary_category": "quant-ph",
      "comment": "7+6 pages, 4+5 figures",
      "pdf_url": "https://arxiv.org/pdf/2512.01317v2",
      "published_date": "2025-12-01 06:18:08 UTC",
      "updated_date": "2025-12-10 06:03:04 UTC",
      "processing_status": "completed",
      "attempts": 1,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "llm_backup_calls": 0,
      "last_update": "2026-01-26T12:36:48.394778+00:00"
    },
    {
      "arxiv_id": "2512.01316v1",
      "title": "Agreement-Constrained Probabilistic Minimum Bayes Risk Decoding",
      "title_zh": "ä¸€è‡´æ€§çº¦æŸçš„æ¦‚ç‡æœ€å°è´å¶æ–¯é£é™©è§£ç ",
      "authors": [
        "Koki Natsumi",
        "Hiroyuki Deguchi",
        "Yusuke Sakai",
        "Hidetaka Kamigaito",
        "Taro Watanabe"
      ],
      "abstract": "Minimum Bayes risk (MBR) decoding generates high-quality translations by maximizing the expected utility of output candidates, but it evaluates all pairwise scores over the candidate set; hence, it takes quadratic time with respect to the number of candidates. To reduce the number of utility function calls, probabilistic MBR (PMBR) decoding partially evaluates quality scores using sampled pairs of candidates and completes the missing scores with a matrix completion algorithm. Nevertheless, it degrades the translation quality as the number of utility function calls is reduced. Therefore, to improve the trade-off between quality and cost, we propose agreement-constrained PMBR (AC-PMBR) decoding, which leverages a knowledge distilled model to guide the completion of the score matrix. Our AC-PMBR decoding improved approximation errors of matrix completion by up to 3 times and achieved higher translation quality compared with PMBR decoding at a comparable computational cost on the WMT'23 En$\\leftrightarrow$De translation tasks.",
      "tldr_zh": "è¯¥ç ”ç©¶é’ˆå¯¹æœ€å°è´å¶æ–¯é£é™© (Minimum Bayes Risk, MBR) è§£ç åœ¨è®¡ç®—é«˜è´¨é‡ç¿»è¯‘æ—¶é¢ä¸´çš„å¹³æ–¹çº§æ—¶é—´å¤æ‚åº¦é—®é¢˜ï¼Œæå‡ºäº†åè®®çº¦æŸ PMBR (Agreement-Constrained PMBR, AC-PMBR) è§£ç ç®—æ³•ã€‚ç°æœ‰çš„æ¦‚ç‡ MBR (PMBR) è§£ç è™½ç„¶é€šè¿‡é‡‡æ ·å’ŒçŸ©é˜µè¡¥å…¨ (matrix completion) æŠ€æœ¯å‡å°‘äº†è®¡ç®—å¼€é”€ï¼Œä½†åœ¨å¤§å¹…é™ä½æˆæœ¬æ—¶å¾€å¾€ä¼šå¯¼è‡´ç¿»è¯‘è´¨é‡ä¸‹é™ã€‚AC-PMBR é€šè¿‡å¼•å…¥çŸ¥è¯†è’¸é¦ (knowledge distilled) æ¨¡å‹æ¥å¼•å¯¼è¯„åˆ†çŸ©é˜µçš„è¡¥å…¨è¿‡ç¨‹ï¼Œä»è€Œæœ‰æ•ˆä¼˜åŒ–äº†ç¿»è¯‘è´¨é‡ä¸è®¡ç®—æˆæœ¬ä¹‹é—´çš„æƒè¡¡ã€‚åœ¨ WMT'23 En$\\leftrightarrow$De ç¿»è¯‘ä»»åŠ¡ä¸Šçš„å®éªŒè¡¨æ˜ï¼Œè¯¥æ–¹æ³•å°†çŸ©é˜µè¡¥å…¨çš„è¿‘ä¼¼è¯¯å·®é™ä½äº†é«˜è¾¾ 3 å€ã€‚æœ€ç»ˆï¼ŒAC-PMBR åœ¨ä¿æŒä¸ PMBR ç›¸å½“çš„è®¡ç®—å¼€é”€å‰æä¸‹ï¼Œå®ç°äº†æ›´é«˜çš„ç¿»è¯‘è´¨é‡ï¼Œä¸ºé«˜æ•ˆç”Ÿæˆé«˜è´¨é‡æœºå™¨ç¿»è¯‘æä¾›äº†æ–°æ–¹æ¡ˆã€‚",
      "categories": [
        "cs.CL",
        "cs.AI",
        "cs.LG"
      ],
      "primary_category": "cs.CL",
      "comment": "IJCNLP-AACL 2025 Main",
      "pdf_url": "https://arxiv.org/pdf/2512.01316v1",
      "published_date": "2025-12-01 06:16:47 UTC",
      "updated_date": "2025-12-01 06:16:47 UTC",
      "processing_status": "completed",
      "attempts": 1,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "llm_backup_calls": 0,
      "last_update": "2026-01-26T12:36:47.472472+00:00"
    },
    {
      "arxiv_id": "2512.01315v1",
      "title": "FOD-S2R: A FOD Dataset for Sim2Real Transfer Learning based Object Detection",
      "title_zh": "FOD-S2Rï¼šä¸€ç§åŸºäº Sim2Real è¿ç§»å­¦ä¹ çš„ç›®æ ‡æ£€æµ‹ FOD æ•°æ®é›†",
      "authors": [
        "Ashish Vashist",
        "Qiranul Saadiyean",
        "Suresh Sundaram",
        "Chandra Sekhar Seelamantula"
      ],
      "abstract": "Foreign Object Debris (FOD) within aircraft fuel tanks presents critical safety hazards including fuel contamination, system malfunctions, and increased maintenance costs. Despite the severity of these risks, there is a notable lack of dedicated datasets for the complex, enclosed environments found inside fuel tanks. To bridge this gap, we present a novel dataset, FOD-S2R, composed of real and synthetic images of the FOD within a simulated aircraft fuel tank. Unlike existing datasets that focus on external or open-air environments, our dataset is the first to systematically evaluate the effectiveness of synthetic data in enhancing the real-world FOD detection performance in confined, closed structures. The real-world subset consists of 3,114 high-resolution HD images captured in a controlled fuel tank replica, while the synthetic subset includes 3,137 images generated using Unreal Engine. The dataset is composed of various Field of views (FOV), object distances, lighting conditions, color, and object size. Prior research has demonstrated that synthetic data can reduce reliance on extensive real-world annotations and improve the generalizability of vision models. Thus, we benchmark several state-of-the-art object detection models and demonstrate that introducing synthetic data improves the detection accuracy and generalization to real-world conditions. These experiments demonstrate the effectiveness of synthetic data in enhancing the model performance and narrowing the Sim2Real gap, providing a valuable foundation for developing automated FOD detection systems for aviation maintenance.",
      "tldr_zh": "é’ˆå¯¹é£æœºç‡ƒæ²¹ç®±å†… Foreign Object Debris (FOD) å¯èƒ½å¯¼è‡´çš„ç‡ƒæ–™æ±¡æŸ“å’Œç³»ç»Ÿæ•…éšœç­‰å®‰å…¨éšæ‚£ï¼Œä»¥åŠç›¸å…³å°é—­ç¯å¢ƒä¸“ç”¨æ•°æ®é›†ç¼ºå¤±çš„ç°çŠ¶ï¼Œè¯¥ç ”ç©¶æå‡ºäº† FOD-S2R æ•°æ®é›†ã€‚ä½œä¸ºä¸€ä¸ªä¸“é—¨é’ˆå¯¹å¤æ‚å°é—­ç»“æ„è®¾è®¡çš„ Sim2Real è¿ç§»å­¦ä¹ æ•°æ®é›†ï¼ŒFOD-S2R åŒ…å«äº†åœ¨å—æ§ç‡ƒæ²¹ç®±æ¨¡å‹ä¸­æ•è·çš„ 3,114 å¼ çœŸå®å›¾åƒï¼Œä»¥åŠä½¿ç”¨ Unreal Engine ç”Ÿæˆçš„ 3,137 å¼ åˆæˆå›¾åƒã€‚è¯¥æ•°æ®é›†æ¶µç›–äº†å¤šç§ Field of view (FOV)ã€ç‰©ä½“è·ç¦»ã€å…‰ç…§æ¡ä»¶å’Œç‰©ä½“å°ºå¯¸ï¼Œæ˜¯é¦–ä¸ªç³»ç»Ÿè¯„ä¼°åˆæˆæ•°æ®åœ¨å°é—­ç©ºé—´ FOD æ£€æµ‹ä¸­æœ‰æ•ˆæ€§çš„ç ”ç©¶ã€‚ç ”ç©¶äººå‘˜é€šè¿‡åŸºå‡†æµ‹è¯•å¤šç§å…ˆè¿›çš„ Object Detection æ¨¡å‹ï¼ŒéªŒè¯äº†å¼•å…¥åˆæˆæ•°æ®å¯¹äºæå‡æ¨¡å‹åœ¨çœŸå®ä¸–ç•Œæ¡ä»¶ä¸‹çš„æ£€æµ‹å‡†ç¡®ç‡å’Œæ³›åŒ–èƒ½åŠ›çš„æ˜¾è‘—ä½œç”¨ã€‚å®éªŒç»“æœè¡¨æ˜ï¼Œåˆæˆæ•°æ®èƒ½æœ‰æ•ˆç¼©å° Sim2Real å·®è·å¹¶å‡å°‘å¯¹å¤§è§„æ¨¡çœŸå®æ ‡æ³¨çš„ä¾èµ–ï¼Œä¸ºèˆªç©ºç»´ä¿®é¢†åŸŸå¼€å‘è‡ªåŠ¨åŒ–çš„ FOD æ£€æµ‹ç³»ç»Ÿæä¾›äº†é‡è¦çš„ç ”ç©¶åŸºç¡€ã€‚",
      "categories": [
        "cs.CV",
        "cs.AI"
      ],
      "primary_category": "cs.CV",
      "comment": "8 pages, 11 figures",
      "pdf_url": "https://arxiv.org/pdf/2512.01315v1",
      "published_date": "2025-12-01 06:16:26 UTC",
      "updated_date": "2025-12-01 06:16:26 UTC",
      "processing_status": "completed",
      "attempts": 1,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "llm_backup_calls": 0,
      "last_update": "2026-01-26T12:36:56.474611+00:00"
    },
    {
      "arxiv_id": "2512.01311v2",
      "title": "CuES: A Curiosity-driven and Environment-grounded Synthesis Framework for Agentic RL",
      "title_zh": "CuESï¼šé¢å‘æ™ºèƒ½ä½“å¼ºåŒ–å­¦ä¹ çš„å¥½å¥‡å¿ƒé©±åŠ¨ä¸ç¯å¢ƒé”šå®šä»»åŠ¡åˆæˆæ¡†æ¶",
      "authors": [
        "Shinji Mai",
        "Yunpeng Zhai",
        "Ziqian Chen",
        "Cheng Chen",
        "Anni Zou",
        "Shuchang Tao",
        "Zhaoyang Liu",
        "Bolin Ding"
      ],
      "abstract": "Large language model based agents are increasingly deployed in complex, tool augmented environments. While reinforcement learning provides a principled mechanism for such agents to improve through interaction, its effectiveness critically depends on the availability of structured training tasks. In many realistic settings, however, no such tasks exist a challenge we term task scarcity, which has become a key bottleneck for scaling agentic RL. Existing approaches typically assume predefined task collections, an assumption that fails in novel environments where tool semantics and affordances are initially unknown. To address this limitation, we formalize the problem of Task Generation for Agentic RL, where an agent must learn within a given environment that lacks predefined tasks. We propose CuES, a Curiosity driven and Environment grounded Synthesis framework that autonomously generates diverse, executable, and meaningful tasks directly from the environment structure and affordances, without relying on handcrafted seeds or external corpora. CuES drives exploration through intrinsic curiosity, abstracts interaction patterns into reusable task schemas, and refines them through lightweight top down guidance and memory based quality control. Across three representative environments, AppWorld, BFCL, and WebShop, CuES produces task distributions that match or surpass manually curated datasets in both diversity and executability, yielding substantial downstream policy improvements. These results demonstrate that curiosity driven, environment grounded task generation provides a scalable foundation for agents that not only learn how to act, but also learn what to learn. The code is available at https://github.com/modelscope/AgentEvolver/tree/main/research/CuES.",
      "tldr_zh": "è¯¥ç ”ç©¶æå‡ºäº†CuESï¼Œä¸€ç§åŸºäºå¥½å¥‡å¿ƒé©±åŠ¨(Curiosity-driven)å’Œç¯å¢ƒæ¥åœ°(Environment-grounded)çš„åˆæˆæ¡†æ¶ï¼Œæ—¨åœ¨è§£å†³æ™ºèƒ½ä½“å¼ºåŒ–å­¦ä¹ (Agentic RL)åœ¨å¤æ‚å·¥å…·å¢å¼ºç¯å¢ƒä¸­é¢ä¸´çš„ä»»åŠ¡ç¨€ç¼º(task scarcity)ç“¶é¢ˆã€‚ä¸ºäº†åº”å¯¹æ–°ç¯å¢ƒä¸­å·¥å…·è¯­ä¹‰å’ŒåŠŸèƒ½ä¾›èƒ½(affordances)æœªçŸ¥çš„æŒ‘æˆ˜ï¼ŒCuESèƒ½å¤Ÿç›´æ¥ä»ç¯å¢ƒç»“æ„ä¸­è‡ªä¸»ç”Ÿæˆå¤šæ ·ä¸”å¯æ‰§è¡Œçš„ä»»åŠ¡ï¼Œè€Œæ— éœ€ä¾èµ–æ‰‹å·¥è®¾è®¡çš„ç§å­æˆ–å¤–éƒ¨è¯­æ–™åº“ã€‚è¯¥æ¡†æ¶é€šè¿‡å†…åœ¨å¥½å¥‡å¿ƒé©±åŠ¨æ¢ç´¢ï¼Œå°†äº¤äº’æ¨¡å¼æŠ½è±¡ä¸ºå¯é‡ç”¨çš„ä»»åŠ¡æ¨¡å¼(task schemas)ï¼Œå¹¶åˆ©ç”¨è½»é‡çº§çš„è‡ªä¸Šè€Œä¸‹å¼•å¯¼å’ŒåŸºäºè®°å¿†çš„è´¨é‡æ§åˆ¶å¯¹ä»»åŠ¡è¿›è¡Œç²¾ç‚¼ã€‚åœ¨AppWorldã€BFCLå’ŒWebShopç­‰ä»£è¡¨æ€§ç¯å¢ƒä¸Šçš„å®éªŒè¡¨æ˜ï¼ŒCuESç”Ÿæˆçš„ä»»åŠ¡åˆ†å¸ƒåœ¨å¤šæ ·æ€§å’Œå¯æ‰§è¡Œæ€§æ–¹é¢å‡åŒ¹é…æˆ–è¶…è¶Šäº†äººå·¥ç­–åˆ’çš„æ•°æ®é›†ã€‚å®éªŒç»“æœè¿›ä¸€æ­¥æ˜¾ç¤ºï¼Œè¯¥æ¡†æ¶èƒ½æ˜¾è‘—æå‡ä¸‹æ¸¸ç­–ç•¥çš„æ€§èƒ½ï¼Œä¸ºæ™ºèƒ½ä½“å®ç°â€œå­¦ä¹ å¦‚ä½•å­¦ä¹ â€ä»¥åŠâ€œå­¦ä¹ å­¦ä»€ä¹ˆâ€æä¾›äº†å¯æ‰©å±•çš„åŸºç¡€ã€‚",
      "categories": [
        "cs.AI",
        "cs.LG"
      ],
      "primary_category": "cs.AI",
      "comment": "",
      "pdf_url": "https://arxiv.org/pdf/2512.01311v2",
      "published_date": "2025-12-01 06:11:37 UTC",
      "updated_date": "2025-12-03 09:53:18 UTC",
      "processing_status": "completed",
      "attempts": 1,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "llm_backup_calls": 0,
      "last_update": "2026-01-26T12:37:26.082181+00:00"
    },
    {
      "arxiv_id": "2512.01300v1",
      "title": "RoboDriveVLM: A Novel Benchmark and Baseline towards Robust Vision-Language Models for Autonomous Driving",
      "title_zh": "RoboDriveVLMï¼šé¢å‘è‡ªåŠ¨é©¾é©¶é²æ£’è§†è§‰è¯­è¨€æ¨¡å‹çš„æ–°å‹åŸºå‡†ä¸åŸºçº¿",
      "authors": [
        "Dacheng Liao",
        "Mengshi Qi",
        "Peng Shu",
        "Zhining Zhang",
        "Yuxin Lin",
        "Liang Liu",
        "Huadong Ma"
      ],
      "abstract": "Current Vision-Language Model (VLM)-based end-to-end autonomous driving systems often leverage large language models to generate driving decisions directly based on their understanding of the current scene. However, such systems introduce multiple risks in real-world driving scenarios. To evaluate whether VLMs are truly viable for autonomous driving, we introduce RoboDriveBench, the first robustness benchmark focused on end-to-end trajectory prediction tasks. This benchmark systematically evaluates two critical categories of real-world challenges for VLM-based end-to-end autonomous driving systems through 11 simulated scenarios encompassing various corruption types, including 6 scenarios of sensor corruption caused by environmental variations, along with 5 cases of prompt corruption resulting from human intervention and data transmission failures. Each corruption type includes 250 unique driving scenarios and 5,689 frames, resulting in 64,559 total trajectory prediction cases per evaluation. To overcome these real-world challenges, we propose a novel VLM-based autonomous driving framework called RoboDriveVLM, which enhances robustness by mapping more multimodal data-e.g., lidar and radar-into a unified latent space. Furthermore, we introduce a new Test-Time Adaptation (TTA) method based on cross-modal knowledge distillation to improve the robustness of VLM-based autonomous driving systems. Through extensive experiments, our work highlights the limitations of current VLM-based end-to-end autonomous driving systems and provides a more reliable solution for real-world deployment. Source code and datasets will be released.",
      "tldr_zh": "è¯¥ç ”ç©¶é’ˆå¯¹åŸºäºè§†è§‰è¯­è¨€æ¨¡å‹(VLMs)çš„ç«¯åˆ°ç«¯è‡ªåŠ¨é©¾é©¶ç³»ç»Ÿåœ¨å¤æ‚ç°å®åœºæ™¯ä¸­çš„å®‰å…¨æ€§é£é™©ï¼Œæå‡ºäº†é¦–ä¸ªä¸“æ³¨äºè½¨è¿¹é¢„æµ‹é²æ£’æ€§çš„åŸºå‡†æµ‹è¯•RoboDriveBenchã€‚è¯¥åŸºå‡†é€šè¿‡11ç§æ¨¡æ‹Ÿåœºæ™¯ç³»ç»Ÿåœ°è¯„ä¼°äº†ä¼ æ„Ÿå™¨æŸåå’Œæç¤ºè¯(Prompt)å¼‚å¸¸å¯¹ç³»ç»Ÿçš„å½±å“ï¼Œæ¶µç›–äº†è¶…è¿‡å…­ä¸‡ä¸ªè½¨è¿¹é¢„æµ‹æ¡ˆä¾‹ã€‚ä¸ºäº†æå‡ç³»ç»ŸéŸ§æ€§ï¼Œç ”ç©¶è€…å¼€å‘äº†RoboDriveVLMæ¡†æ¶ï¼Œé€šè¿‡å°†æ¿€å…‰é›·è¾¾(Lidar)å’Œé›·è¾¾(Radar)ç­‰å¤šæ¨¡æ€æ•°æ®æ˜ å°„è‡³ç»Ÿä¸€çš„æ½œç©ºé—´(Latent Space)æ¥å¢å¼ºæ„ŸçŸ¥ç¨³å®šæ€§ã€‚æ­¤å¤–ï¼Œè¯¥ç ”ç©¶å¼•å…¥äº†ä¸€ç§åŸºäºè·¨æ¨¡æ€çŸ¥è¯†è’¸é¦çš„æµ‹è¯•æ—¶è‡ªé€‚åº”(Test-Time Adaptation, TTA)æ–¹æ³•ï¼Œä»¥è¿›ä¸€æ­¥ä¼˜åŒ–æ¨¡å‹åœ¨æ¨æ–­é˜¶æ®µçš„è¡¨ç°ã€‚å®éªŒç»“æœæ­ç¤ºäº†ç°æœ‰æ¨¡å‹åœ¨é²æ£’æ€§æ–¹é¢çš„å±€é™ï¼Œå¹¶ä¸ºå®ç°æ›´å¯é çš„è‡ªåŠ¨é©¾é©¶éƒ¨ç½²æä¾›äº†æœ‰æ•ˆçš„æŠ€æœ¯åŸºå‡†å’Œè§£å†³æ–¹æ¡ˆã€‚",
      "categories": [
        "cs.AI"
      ],
      "primary_category": "cs.AI",
      "comment": "",
      "pdf_url": "https://arxiv.org/pdf/2512.01300v1",
      "published_date": "2025-12-01 05:44:06 UTC",
      "updated_date": "2025-12-01 05:44:06 UTC",
      "processing_status": "completed",
      "attempts": 1,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "llm_backup_calls": 0,
      "last_update": "2026-01-26T12:37:39.680077+00:00"
    },
    {
      "arxiv_id": "2512.01292v2",
      "title": "Diffusion Model in Latent Space for Medical Image Segmentation Task",
      "title_zh": "é¢å‘åŒ»å­¦å›¾åƒåˆ†å‰²ä»»åŠ¡çš„æ½œåœ¨ç©ºé—´æ‰©æ•£æ¨¡å‹",
      "authors": [
        "Huynh Trinh Ngoc",
        "Toan Nguyen Hai",
        "Ba Luong Son",
        "Long Tran Quoc"
      ],
      "abstract": "Medical image segmentation is crucial for clinical diagnosis and treatment planning. Traditional methods typically produce a single segmentation mask, failing to capture inherent uncertainty. Recent generative models enable the creation of multiple plausible masks per image, mimicking the collaborative interpretation of several clinicians. However, these approaches remain computationally heavy. We propose MedSegLatDiff, a diffusion based framework that combines a variational autoencoder (VAE) with a latent diffusion model for efficient medical image segmentation. The VAE compresses the input into a low dimensional latent space, reducing noise and accelerating training, while the diffusion process operates directly in this compact representation. We further replace the conventional MSE loss with weighted cross entropy in the VAE mask reconstruction path to better preserve tiny structures such as small nodules. MedSegLatDiff is evaluated on ISIC-2018 (skin lesions), CVC-Clinic (polyps), and LIDC-IDRI (lung nodules). It achieves state of the art or highly competitive Dice and IoU scores while simultaneously generating diverse segmentation hypotheses and confidence maps. This provides enhanced interpretability and reliability compared to deterministic baselines, making the model particularly suitable for clinical deployment.",
      "tldr_zh": "è¯¥ç ”ç©¶é’ˆå¯¹åŒ»ç–—å›¾åƒåˆ†å‰²ä¸­ä¼ ç»Ÿæ–¹æ³•æ— æ³•æ•æ‰ä¸ç¡®å®šæ€§ä¸”ç°æœ‰ç”Ÿæˆæ¨¡å‹è®¡ç®—å¼€é”€å¤§çš„é—®é¢˜ï¼Œæå‡ºäº†MedSegLatDiffæ¡†æ¶ã€‚è¯¥æ¡†æ¶å°†å˜åˆ†è‡ªç¼–ç å™¨(VAE)ä¸æ½œæ‰©æ•£æ¨¡å‹(Latent Diffusion Model)ç›¸ç»“åˆï¼Œé€šè¿‡VAEå°†è¾“å…¥å›¾åƒå‹ç¼©è‡³ä½ç»´æ½œç©ºé—´(Latent Space)ä»¥åŠ é€Ÿè®­ç»ƒå¹¶å‡å°‘å™ªå£°å¹²æ‰°ã€‚ç ”ç©¶è€…è¿›ä¸€æ­¥åœ¨VAEçš„æ©ç é‡å»ºè·¯å¾„ä¸­å¼•å…¥åŠ æƒäº¤å‰ç†µ(Weighted Cross Entropy)æŸå¤±æ›¿ä»£ä¼ ç»Ÿçš„å‡æ–¹è¯¯å·®(MSE)æŸå¤±ï¼Œä»è€Œæ›´æœ‰æ•ˆåœ°ä¿ç•™å¦‚å°ç»“èŠ‚ç­‰å¾®å°ç»“æ„ã€‚åœ¨ISIC-2018ã€CVC-Clinicå’ŒLIDC-IDRIæ•°æ®é›†ä¸Šçš„è¯„ä¼°ç»“æœè¡¨æ˜ï¼ŒMedSegLatDiffåœ¨Diceå’ŒIoUåˆ†æ•°ä¸Šè¾¾åˆ°äº†æœ€å…ˆè¿›æˆ–æå…·ç«äº‰åŠ›çš„æ°´å¹³ã€‚æ­¤å¤–ï¼Œè¯¥æ¨¡å‹èƒ½å¤Ÿç”Ÿæˆå¤šæ ·çš„åˆ†å‰²å‡è®¾å’Œç½®ä¿¡åº¦å›¾ï¼Œä¸ºä¸´åºŠè¯Šæ–­æä¾›äº†æ›´å¼ºçš„å¯è§£é‡Šæ€§å’Œå¯é æ€§ã€‚ç›¸æ¯”ä¼ ç»Ÿçš„ç¡®å®šæ€§åŸºå‡†æ¨¡å‹ï¼Œè¿™ç§é«˜æ•ˆçš„æ‰©æ•£æ¨¡å‹æ¡†æ¶æ›´å…·ä¸´åºŠéƒ¨ç½²çš„å®ç”¨ä»·å€¼ã€‚",
      "categories": [
        "cs.CV",
        "cs.AI"
      ],
      "primary_category": "cs.CV",
      "comment": "",
      "pdf_url": "https://arxiv.org/pdf/2512.01292v2",
      "published_date": "2025-12-01 05:26:43 UTC",
      "updated_date": "2025-12-02 02:55:31 UTC",
      "processing_status": "completed",
      "attempts": 1,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "llm_backup_calls": 0,
      "last_update": "2026-01-26T12:37:50.077699+00:00"
    },
    {
      "arxiv_id": "2512.01289v1",
      "title": "OntoMetric: An Ontology-Guided Framework for Automated ESG Knowledge Graph Construction",
      "title_zh": "OntoMetricï¼šæœ¬ä½“å¼•å¯¼çš„è‡ªåŠ¨åŒ– ESG çŸ¥è¯†å›¾è°±æ„å»ºæ¡†æ¶",
      "authors": [
        "Mingqin Yu",
        "Fethi Rabhi",
        "Boming Xia",
        "Zhengyi Yang",
        "Felix Tan",
        "Qinghua Lu"
      ],
      "abstract": "Environmental, Social, and Governance (ESG) disclosure frameworks such as SASB, TCFD, and IFRS S2 require organizations to compute and report numerous metrics for compliance, yet these requirements are embedded in long, unstructured PDF documents that are difficult to interpret, standardize, and audit. Manual extraction is unscalable, while unconstrained large language model (LLM) extraction often produces inconsistent entities, hallucinated relationships, missing provenance, and high validation failure rates. We present OntoMetric, an ontology-guided framework that transforms ESG regulatory documents into validated, AI- and web-ready knowledge graphs. OntoMetric operates through a three-stage pipeline: (1) structure-aware segmentation using table-of-contents boundaries, (2) ontology-constrained LLM extraction that embeds the ESGMKG schema into prompts while enriching entities with semantic fields for downstream reasoning, and (3) two-phase validation that combines LLM-based semantic verification with rule-based schema checking across entity, property, and relationship levels (VR001-VR006). The framework preserves both segment-level and page-level provenance for audit traceability. Evaluated on five ESG standards (SASB Commercial Banks, SASB Semiconductors, TCFD, IFRS S2, AASB S2) totaling 228 pages and 60 segments, OntoMetric achieves 65-90% semantic accuracy and 80-90% schema compliance, compared to 3-10% for baseline unconstrained extraction, at approximately 0.01 to 0.02 USD per validated entity. Our results demonstrate that combining symbolic ontology constraints with neural extraction enables reliable, auditable knowledge graphs suitable for regulatory compliance and web integration, supporting downstream applications such as sustainable-finance analytics, transparency portals, and automated compliance tools.",
      "tldr_zh": "è¯¥ç ”ç©¶é’ˆå¯¹SASBã€TCFDå’ŒIFRS S2ç­‰ç¯å¢ƒã€ç¤¾ä¼šå’Œæ²»ç†(ESG)æŠ«éœ²æ¡†æ¶ä¸­éç»“æ„åŒ–æ–‡æ¡£éš¾ä»¥è§£æçš„é—®é¢˜ï¼Œæå‡ºäº†OntoMetricâ€”â€”ä¸€ç§æœ¬ä½“å¼•å¯¼çš„è‡ªåŠ¨åŒ–çŸ¥è¯†å›¾è°±(Knowledge Graph)æ„å»ºæ¡†æ¶ã€‚OntoMetricé€šè¿‡ç»“æ„æ„ŸçŸ¥åˆ†å‰²ã€åŸºäºæœ¬ä½“çº¦æŸçš„å¤§è¯­è¨€æ¨¡å‹(LLM)æå–ä»¥åŠåŒé˜¶æ®µéªŒè¯ï¼ˆç»“åˆè¯­ä¹‰éªŒè¯ä¸è§„åˆ™æ£€æŸ¥ï¼‰çš„ä¸‰é˜¶æ®µæµæ°´çº¿ï¼Œå°†ESGç›‘ç®¡æ–‡ä»¶è½¬åŒ–ä¸ºå¯éªŒè¯ä¸”ç¬¦åˆWebæ ‡å‡†çš„çŸ¥è¯†å›¾è°±ã€‚è¯¥æ¡†æ¶ç‰¹åˆ«ä¿ç•™äº†æ®µè½çº§å’Œé¡µé¢çº§çš„å‡ºå¤„ä¿¡æ¯(Provenance)ï¼Œç¡®ä¿äº†é‡‘èå®¡è®¡çš„å¯è¿½æº¯æ€§ã€‚å®éªŒè¯„ä¼°è¡¨æ˜ï¼ŒOntoMetricåœ¨è¯­ä¹‰å‡†ç¡®åº¦ï¼ˆ65-90%ï¼‰å’Œæ¨¡å¼åˆè§„æ€§ï¼ˆ80-90%ï¼‰æ–¹é¢è¿œè¶…æ— çº¦æŸæå–çš„åŸºçº¿æ¨¡å‹ï¼Œä¸”æ¯æ¡éªŒè¯å®ä½“çš„å¤„ç†æˆæœ¬æä½ã€‚è¯¥æˆæœè¯æ˜äº†å°†ç¬¦å·åŒ–æœ¬ä½“çº¦æŸä¸ç¥ç»æå–ç›¸ç»“åˆï¼Œèƒ½å¤Ÿä¸ºå¯æŒç»­é‡‘èåˆ†æã€é€æ˜åº¦é—¨æˆ·å’Œè‡ªåŠ¨åŒ–åˆè§„å·¥å…·æä¾›å¯é ã€å¯å®¡è®¡çš„ä¸“ä¸šçŸ¥è¯†æ”¯æ’‘ã€‚",
      "categories": [
        "cs.AI",
        "cs.GR"
      ],
      "primary_category": "cs.AI",
      "comment": "",
      "pdf_url": "https://arxiv.org/pdf/2512.01289v1",
      "published_date": "2025-12-01 05:21:22 UTC",
      "updated_date": "2025-12-01 05:21:22 UTC",
      "processing_status": "completed",
      "attempts": 1,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "llm_backup_calls": 0,
      "last_update": "2026-01-26T12:37:57.075967+00:00"
    },
    {
      "arxiv_id": "2512.01286v1",
      "title": "Generative Modeling with Continuous Flows: Sample Complexity of Flow Matching",
      "title_zh": "è¿ç»­æµç”Ÿæˆå¼å»ºæ¨¡ï¼šæµåŒ¹é…çš„æ ·æœ¬å¤æ‚åº¦",
      "authors": [
        "Mudit Gaur",
        "Prashant Trivedi",
        "Shuchin Aeron",
        "Amrit Singh Bedi",
        "George K. Atia",
        "Vaneet Aggarwal"
      ],
      "abstract": "Flow matching has recently emerged as a promising alternative to diffusion-based generative models, offering faster sampling and simpler training by learning continuous flows governed by ordinary differential equations. Despite growing empirical success, the theoretical understanding of flow matching remains limited, particularly in terms of sample complexity results. In this work, we provide the first analysis of the sample complexity for flow-matching based generative models without assuming access to the empirical risk minimizer (ERM) of the loss function for estimating the velocity field. Under standard assumptions on the loss function for velocity field estimation and boundedness of the data distribution, we show that a sufficiently expressive neural network can learn a velocity field such that with $\\mathcal{O}(Îµ^{-4})$ samples, such that the Wasserstein-2 distance between the learned and the true distribution is less than $\\mathcal{O}(Îµ)$. The key technical idea is to decompose the velocity field estimation error into neural-network approximation error, statistical error due to the finite sample size, and optimization error due to the finite number of optimization steps for estimating the velocity field. Each of these terms are then handled via techniques that may be of independent interest.",
      "tldr_zh": "è¯¥ç ”ç©¶é’ˆå¯¹åŸºäºè¿ç»­æµçš„ç”Ÿæˆæ¨¡å‹ Flow Matching ç¼ºä¹ç†è®ºä¾æ®çš„é—®é¢˜ï¼Œé¦–æ¬¡æä¾›äº†å…³äºå…¶æ ·æœ¬å¤æ‚åº¦(Sample Complexity)çš„ç³»ç»Ÿæ€§åˆ†æã€‚åœ¨ä¸ä¾èµ–ç»éªŒé£é™©æœ€å°åŒ–å™¨(ERM)å‡è®¾çš„å‰æä¸‹ï¼Œç ”ç©¶è€…æ¢è®¨äº†å¦‚ä½•é€šè¿‡å­¦ä¹ ç”±å¸¸å¾®åˆ†æ–¹ç¨‹(ODE)é©±åŠ¨çš„é€Ÿåº¦åœºæ¥ç”Ÿæˆç›®æ ‡åˆ†å¸ƒã€‚é€šè¿‡è®¾å®šæŸå¤±å‡½æ•°å’Œæ•°æ®åˆ†å¸ƒçš„æ ‡å‡†åŒ–å‡è®¾ï¼Œè®ºæ–‡è¯æ˜äº†é«˜è¡¨è¾¾èƒ½åŠ›çš„ç¥ç»ç½‘ç»œèƒ½å¤Ÿä»¥ $O(\\epsilon^{-4})$ çš„æ ·æœ¬é‡ï¼Œä½¿å­¦ä¹ åˆ†å¸ƒä¸çœŸå®åˆ†å¸ƒé—´çš„ Wasserstein-2 è·ç¦»è¾¾åˆ° $O(\\epsilon)$ã€‚æŠ€æœ¯ä¸Šï¼Œè¯¥é¡¹å·¥ä½œå°†é€Ÿåº¦åœºä¼°è®¡è¯¯å·®ç»†åŒ–ä¸ºç¥ç»ç½‘ç»œè¿‘ä¼¼è¯¯å·®ã€æœ‰é™æ ·æœ¬ç»Ÿè®¡è¯¯å·®åŠä¼˜åŒ–è¯¯å·®ï¼Œå¹¶åˆ†åˆ«é‡‡ç”¨äº†åˆ›æ–°çš„æŠ€æœ¯æ‰‹æ®µè¿›è¡Œå¤„ç†ã€‚è¯¥åˆ†æä¸ä»…å¡«è¡¥äº† Flow Matching åœ¨ç”Ÿæˆæ€§èƒ½ç•Œé™ä¸Šçš„ç†è®ºç©ºç™½ï¼Œå…¶è¯¯å·®åˆ†è§£æ¡†æ¶ä¹Ÿä¸ºç›¸å…³ç”Ÿæˆæ¨¡å‹çš„ç†è®ºç ”ç©¶æä¾›äº†é‡è¦å‚è€ƒã€‚",
      "categories": [
        "cs.LG",
        "cs.AI"
      ],
      "primary_category": "cs.LG",
      "comment": "",
      "pdf_url": "https://arxiv.org/pdf/2512.01286v1",
      "published_date": "2025-12-01 05:14:25 UTC",
      "updated_date": "2025-12-01 05:14:25 UTC",
      "processing_status": "completed",
      "attempts": 1,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "llm_backup_calls": 0,
      "last_update": "2026-01-26T12:38:49.150814+00:00"
    },
    {
      "arxiv_id": "2512.04113v1",
      "title": "AI-Enabled grading with near-domain data for scaling feedback with human-level accuracy",
      "title_zh": "åˆ©ç”¨è¿‘é¢†åŸŸæ•°æ®å®ç°äººç±»çº§å‡†ç¡®åº¦çš„äººå·¥æ™ºèƒ½èµ‹èƒ½è§„æ¨¡åŒ–è¯„åˆ†åé¦ˆ",
      "authors": [
        "Shyam Agarwal",
        "Ali Moghimi",
        "Kevin C. Haudek"
      ],
      "abstract": "Constructed-response questions are crucial to encourage generative processing and test a learner's understanding of core concepts. However, the limited availability of instructor time, large class sizes, and other resource constraints pose significant challenges in providing timely and detailed evaluation, which is crucial for a holistic educational experience. In addition, providing timely and frequent assessments is challenging since manual grading is labor intensive, and automated grading is complex to generalize to every possible response scenario. This paper proposes a novel and practical approach to grade short-answer constructed-response questions. We discuss why this problem is challenging, define the nature of questions on which our method works, and finally propose a framework that instructors can use to evaluate their students' open-responses, utilizing near-domain data like data from similar questions administered in previous years. The proposed method outperforms the state of the art machine learning models as well as non-fine-tuned large language models like GPT 3.5, GPT 4, and GPT 4o by a considerable margin of over 10-20% in some cases, even after providing the LLMs with reference/model answers. Our framework does not require pre-written grading rubrics and is designed explicitly with practical classroom settings in mind. Our results also reveal exciting insights about learning from near-domain data, including what we term as accuracy and data advantages using human-labeled data, and we believe this is the first work to formalize the problem of automated short answer grading based on the near-domain data.",
      "tldr_zh": "è¯¥ç ”ç©¶é’ˆå¯¹ç®€ç­”å¼æ„å»ºååº”é¢˜(Constructed-response questions)è¯„åˆ†ä¸­å­˜åœ¨çš„æ•™å¸ˆèµ„æºæœ‰é™ã€äººå·¥è¯„åˆ†è€—æ—¶ä»¥åŠè‡ªåŠ¨è¯„åˆ†æ³›åŒ–éš¾ç­‰æŒ‘æˆ˜ï¼Œæå‡ºäº†ä¸€ç§åˆ©ç”¨è¿‘é¢†åŸŸæ•°æ®(near-domain data)å®ç°å¤§è§„æ¨¡ã€é«˜ç²¾åº¦åé¦ˆçš„æ–°å‹è¯„ä¼°æ¡†æ¶ã€‚è¯¥æ¡†æ¶å…è®¸æ•™å¸ˆåˆ©ç”¨å¾€å¹´ç±»ä¼¼é—®é¢˜çš„å­¦ç”Ÿå›ç­”ç­‰æ•°æ®æ¥è¾…åŠ©å½“å‰çš„å¼€æ”¾å¼è¯„åˆ†ï¼Œä¸”æ— éœ€é¢„å…ˆç¼–å†™å¤æ‚çš„è¯„åˆ†æ ‡å‡†(grading rubrics)ï¼Œç‰¹åˆ«é€‚ç”¨äºå®é™…è¯¾å ‚ç¯å¢ƒã€‚å®éªŒç»“æœè¡¨æ˜ï¼Œè¯¥æ–¹æ³•åœ¨è¯„åˆ†å‡†ç¡®æ€§ä¸Šæ˜¾è‘—ä¼˜äºç°æœ‰çš„æœºå™¨å­¦ä¹ æ¨¡å‹ä»¥åŠ GPT-3.5ã€GPT-4 å’Œ GPT-4o ç­‰ä¸»æµå¤§è¯­è¨€æ¨¡å‹(LLMs)ï¼Œåœ¨éƒ¨åˆ†æ¡ˆä¾‹ä¸­æ€§èƒ½æå‡è¾¾ 10-20%ã€‚æ­¤å¤–ï¼Œè¯¥ç ”ç©¶æ­ç¤ºäº†åˆ©ç”¨äººç±»æ ‡æ³¨æ•°æ®å¸¦æ¥çš„å‡†ç¡®æ€§ä¸æ•°æ®ä¼˜åŠ¿ï¼Œå¹¶é¦–æ¬¡æ­£å¼å®šä¹‰äº†åŸºäºè¿‘é¢†åŸŸæ•°æ®çš„è‡ªåŠ¨åŒ–çŸ­æ–‡è¯„åˆ†(automated short answer grading)é—®é¢˜ï¼Œä¸ºæ•™è‚²è¯„ä¼°çš„è§„æ¨¡åŒ–æä¾›äº†æ–°æ€è·¯ã€‚",
      "categories": [
        "cs.CY",
        "cs.AI",
        "cs.HC",
        "cs.LG"
      ],
      "primary_category": "cs.CY",
      "comment": "",
      "pdf_url": "https://arxiv.org/pdf/2512.04113v1",
      "published_date": "2025-12-01 05:11:37 UTC",
      "updated_date": "2025-12-01 05:11:37 UTC",
      "processing_status": "completed",
      "attempts": 1,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "llm_backup_calls": 0,
      "last_update": "2026-01-26T12:38:51.338166+00:00"
    },
    {
      "arxiv_id": "2512.01282v2",
      "title": "Kardia-R1: Unleashing LLMs to Reason toward Understanding and Empathy for Emotional Support via Rubric-as-Judge Reinforcement Learning",
      "title_zh": "Kardia-R1ï¼šé€šè¿‡ä»¥å‡†åˆ™ä¸ºè£åˆ¤çš„å¼ºåŒ–å­¦ä¹ ï¼Œé‡Šæ”¾å¤§è¯­è¨€æ¨¡å‹åœ¨æƒ…æ„Ÿæ”¯æŒä¸­çš„ç†è§£ä¸å…±æƒ…æ¨ç†èƒ½åŠ›",
      "authors": [
        "Jiahao Yuan",
        "Zhiqing Cui",
        "Hanqing Wang",
        "Yuansheng Gao",
        "Yucheng Zhou",
        "Usman Naseem"
      ],
      "abstract": "As web platforms evolve towards greater personalization and emotional complexity, conversational agents must transcend superficial empathy to demonstrate identity-aware emotional reasoning. However, existing systems face two limitations: (1) reliance on situation-centric datasets lacking persistent user identity, which hampers the capture of personalized affective nuances; and (2) dependence on opaque, coarse reward signals that hinder development of verifiable empathetic reasoning. To address these gaps, we introduce KardiaBench, a large-scale user-grounded benchmark comprising 178,080 QA pairs across 22,080 multi-turn conversations anchored to 671 real-world profiles. The dataset is constructed via a model-in-the-loop pipeline with iterative rubric-guided refinement to ensure psychological plausibility and persona consistency. This progressive empathy pipeline that integrates user comprehension, contextual reasoning, and emotion perception into conversations, followed by iterative critique and rubric-based refinement to ensure psychological plausibility, emotional fidelity, and persona consistency. Building on this, we propose Kardia-R1, a framework that trains models for interpretable, stepwise empathetic cognition. Kardia-R1 leverages Rubric-as-Judge Empathetic Reinforcement Learning (Rubric-ERL), a GRPO-based method that uses explainable, human-aligned rubric rewards to tightly couple user understanding, emotional inference, and supportive response generation. Extensive experiments across four LLM backbones demonstrate that Kardia-R1 consistently outperforms othet methods in emotion accuracy, empathy, relevance, persona consistency, and safety. Our dataset and model will be released at https://github.com/JhCircle/Kardia-R1.",
      "tldr_zh": "è¯¥ç ”ç©¶æå‡ºäº†Kardia-R1æ¡†æ¶ï¼Œæ—¨åœ¨è§£å†³å½“å‰å¯¹è¯æ™ºèƒ½ä½“åœ¨æƒ…æ„Ÿæ”¯æŒä»»åŠ¡ä¸­ç¼ºä¹æŒä¹…ç”¨æˆ·èº«ä»½æ„ŸçŸ¥ä»¥åŠæ¨ç†è¿‡ç¨‹ä¸é€æ˜çš„é—®é¢˜ã€‚ç ”ç©¶é¦–å…ˆæ„å»ºäº†å¤§è§„æ¨¡åŸºå‡†æµ‹è¯•é›†KardiaBenchï¼Œé€šè¿‡æ¨¡å‹åœ¨ç¯(model-in-the-loop)å’Œé‡è§„å¼•å¯¼çš„å¾®è°ƒ(rubric-guided refinement)æŠ€æœ¯ï¼Œç¡®ä¿äº†å¯¹è¯åœ¨å¿ƒç†å­¦å±‚é¢çš„åˆç†æ€§ä¸äººæ ¼ä¸€è‡´æ€§ã€‚Kardia-R1å¼•å…¥äº†åŸºäºé‡è§„è¯„ä»·çš„æƒ…æ„Ÿå¼ºåŒ–å­¦ä¹ (Rubric-as-Judge Empathetic Reinforcement Learning, Rubric-ERL)æœºåˆ¶ï¼Œåˆ©ç”¨GRPOç®—æ³•é…åˆäººç±»å¯¹é½çš„å¯è§£é‡Šé‡è§„å¥–åŠ±ï¼Œå®ç°äº†ç”¨æˆ·ç†è§£ã€æƒ…æ„Ÿæ¨ç†ä¸æ”¯æŒæ€§å›å¤ç”Ÿæˆçš„æ·±åº¦è€¦åˆã€‚è¿™ç§æ–¹æ³•èµ‹äºˆäº†å¤§è¯­è¨€æ¨¡å‹(LLMs)å¯è§£é‡Šçš„åˆ†æ­¥å…±æƒ…è®¤çŸ¥èƒ½åŠ›ã€‚å®éªŒç»“æœæ˜¾ç¤ºï¼ŒKardia-R1åœ¨æƒ…æ„Ÿå‡†ç¡®ç‡ã€å…±æƒ…è¡¨ç°ã€äººæ ¼ä¸€è‡´æ€§åŠå®‰å…¨æ€§ç­‰å¤šä¸ªç»´åº¦ä¸Šå‡æ˜¾è‘—ä¼˜äºåŸºçº¿æ¨¡å‹ã€‚è¯¥ç ”ç©¶ä¸ºå¼€å‘å…·å¤‡æ·±å±‚æ¬¡æƒ…æ„Ÿæ¨ç†èƒ½åŠ›çš„æ™ºèƒ½åŒ–æƒ…æ„Ÿæ”¯æŒç³»ç»Ÿæä¾›äº†é‡è¦çš„ç†è®ºä¸å®è·µå‚è€ƒã€‚",
      "categories": [
        "cs.CL",
        "cs.AI"
      ],
      "primary_category": "cs.CL",
      "comment": "",
      "pdf_url": "https://arxiv.org/pdf/2512.01282v2",
      "published_date": "2025-12-01 04:54:03 UTC",
      "updated_date": "2025-12-02 08:43:56 UTC",
      "processing_status": "completed",
      "attempts": 1,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "llm_backup_calls": 0,
      "last_update": "2026-01-26T12:37:59.974627+00:00"
    },
    {
      "arxiv_id": "2512.01278v1",
      "title": "Accelerating Large-Scale Reasoning Model Inference with Sparse Self-Speculative Decoding",
      "title_zh": "é€šè¿‡ç¨€ç–è‡ªæ¨æµ‹è§£ç åŠ é€Ÿå¤§è§„æ¨¡æ¨ç†æ¨¡å‹æ¨ç†",
      "authors": [
        "Yilong Zhao",
        "Jiaming Tang",
        "Kan Zhu",
        "Zihao Ye",
        "Chi-Chih Chang",
        "Chaofan Lin",
        "Jongseok Park",
        "Guangxuan Xiao",
        "Mohamed S. Abdelfattah",
        "Mingyu Gao",
        "Baris Kasikci",
        "Song Han",
        "Ion Stoica"
      ],
      "abstract": "Reasoning language models have demonstrated remarkable capabilities on challenging tasks by generating elaborate chain-of-thought (CoT) solutions. However, such lengthy generation shifts the inference bottleneck from compute-bound to memory-bound. To generate each token, the model applies full attention to all previously generated tokens, requiring memory access to an increasingly large KV-Cache. Consequently, longer generations demand more memory access for every step, leading to substantial pressure on memory bandwidth.\n  To address this, we introduce SparseSpec, a speculative decoding framework that reuses the same model as the draft and target models (i.e., self-speculation). SparseSpec features a novel sparse attention mechanism, PillarAttn, as the draft model, which accurately selects critical tokens via elegantly reusing information from the verification stage. Furthermore, SparseSpec co-designs self-speculation with three system innovations: (1) a unified scheduler to batch token drafting and verification, (2) delayed verification for CPU/GPU overlap, and (3) dynamic KV-Cache management to maximize memory utilization. Across various models and datasets, SparseSpec outperforms state-of-the-art solutions, with an up to 2.13x throughput speedup.",
      "tldr_zh": "è¯¥ç ”ç©¶é’ˆå¯¹æ¨ç†è¯­è¨€æ¨¡å‹ç”Ÿæˆé•¿é“¾å¼æ€ç»´(Chain-of-Thought)å¯¼è‡´æ¨ç†ç“¶é¢ˆä»è®¡ç®—å—é™è½¬å‘å†…å­˜å—é™çš„é—®é¢˜ï¼Œæå‡ºäº†åä¸ºSparseSpecçš„è‡ªæŠ•æœºè§£ç (self-speculation)åŠ é€Ÿæ¡†æ¶ã€‚è¯¥æ¡†æ¶çš„æ ¸å¿ƒæ˜¯å¼•å…¥äº†ä¸€ç§åä¸ºPillarAttnçš„åˆ›æ–°ç¨€ç–æ³¨æ„æœºåˆ¶ï¼Œé€šè¿‡æœ‰æ•ˆå¤ç”¨éªŒè¯é˜¶æ®µçš„ä¿¡æ¯æ¥ç²¾å‡†é€‰æ‹©å…³é”®tokenä½œä¸ºè‰ç¨¿æ¨¡å‹ã€‚æ­¤å¤–ï¼ŒSparseSpecåœ¨ç³»ç»Ÿå±‚é¢ç»“åˆäº†ç»Ÿä¸€è°ƒåº¦å™¨ã€å»¶è¿ŸéªŒè¯ä»¥å®ç°CPU/GPUé‡å ä»¥åŠåŠ¨æ€KV-Cacheç®¡ç†ç­‰ä¸‰é¡¹æŠ€æœ¯åˆ›æ–°ï¼Œæ—¨åœ¨æœ€å¤§åŒ–å†…å­˜åˆ©ç”¨ç‡å¹¶ä¼˜åŒ–æ‰¹å¤„ç†æ•ˆç‡ã€‚å®éªŒç»“æœæ˜¾ç¤ºï¼ŒSparseSpecåœ¨å¤šç§æ¨¡å‹å’Œæ•°æ®é›†ä¸Šå‡ä¼˜äºç°æœ‰çš„å…ˆè¿›è§£å†³æ–¹æ¡ˆï¼Œå®ç°äº†æœ€é«˜2.13å€çš„ååé‡æå‡ï¼Œä¸ºå¤§è§„æ¨¡æ¨ç†æ¨¡å‹çš„é«˜æ•ˆéƒ¨ç½²æä¾›äº†æœ‰åŠ›æ”¯æŒã€‚",
      "categories": [
        "cs.LG",
        "cs.AI"
      ],
      "primary_category": "cs.LG",
      "comment": "",
      "pdf_url": "https://arxiv.org/pdf/2512.01278v1",
      "published_date": "2025-12-01 04:50:55 UTC",
      "updated_date": "2025-12-01 04:50:55 UTC",
      "processing_status": "completed",
      "attempts": 1,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "llm_backup_calls": 0,
      "last_update": "2026-01-26T12:38:04.959597+00:00"
    },
    {
      "arxiv_id": "2512.01274v1",
      "title": "SUPERChem: A Multimodal Reasoning Benchmark in Chemistry",
      "title_zh": "SUPERChemï¼šåŒ–å­¦å¤šæ¨¡æ€æ¨ç†åŸºå‡†",
      "authors": [
        "Zehua Zhao",
        "Zhixian Huang",
        "Junren Li",
        "Siyu Lin",
        "Junting Zhou",
        "Fengqi Cao",
        "Kun Zhou",
        "Rui Ge",
        "Tingting Long",
        "Yuexiang Zhu",
        "Yan Liu",
        "Jie Zheng",
        "Junnian Wei",
        "Rong Zhu",
        "Peng Zou",
        "Wenyu Li",
        "Zekai Cheng",
        "Tian Ding",
        "Yaxuan Wang",
        "Yizhao Yan",
        "Tingru Wei",
        "Haowei Ming",
        "Weijie Mao",
        "Chen Sun",
        "Yiming Liu",
        "Zichen Wang",
        "Zuo Zhang",
        "Tong Yang",
        "Hao Ma",
        "Zhen Gao",
        "Jian Pei"
      ],
      "abstract": "Current benchmarks for evaluating the chemical reasoning capabilities of Large Language Models (LLMs) are limited by oversimplified tasks, lack of process-level evaluation, and misalignment with expert-level chemistry skills. To address these issues, we introduce SUPERChem, a benchmark of 500 expert-curated reasoning-intensive chemistry problems, covering diverse subfields and provided in both multimodal and text-only formats. Original content and an iterative curation pipeline eliminate flawed items and mitigate data contamination. Each problem is paired with an expert-authored solution path, enabling Reasoning Path Fidelity (RPF) scoring to evaluate reasoning quality beyond final-answer accuracy. Evaluations against a human baseline of 40.3% accuracy show that even the best-performing model, GPT-5 (High), reaches only 38.5%, followed closely by Gemini 2.5 Pro (37.9%) and DeepSeek-V3.1-Think (37.3%). SUPERChem elicits multi-step, multimodal reasoning, reveals model-dependent effects of visual information, and distinguishes high-fidelity reasoners from heuristic ones. By providing a challenging benchmark and a reliable evaluation framework, SUPERChem aims to facilitate the advancement of LLMs toward expert-level chemical intelligence. The dataset of the benchmark is available at https://huggingface.co/datasets/ZehuaZhao/SUPERChem.",
      "tldr_zh": "è¯¥ç ”ç©¶æå‡ºäº† SUPERChemï¼Œè¿™æ˜¯ä¸€ä¸ªåŒ…å«500ä¸ªç”±ä¸“å®¶ç²¾é€‰çš„ã€å…·æœ‰é«˜åº¦æ¨ç†å¼ºåº¦çš„åŒ–å­¦é—®é¢˜åŸºå‡†ï¼Œæ¶µç›–äº†å¤šä¸ªåŒ–å­¦å­é¢†åŸŸå¹¶æä¾›å¤šæ¨¡æ€å’Œçº¯æ–‡æœ¬æ ¼å¼ã€‚è¯¥åŸºå‡†æ—¨åœ¨è§£å†³å½“å‰å¤§å‹è¯­è¨€æ¨¡å‹ï¼ˆLLMsï¼‰åœ¨åŒ–å­¦æ¨ç†è¯„ä¼°ä¸­å­˜åœ¨çš„ä»»åŠ¡è¿‡äºç®€åŒ–ã€ç¼ºä¹è¿‡ç¨‹çº§è¯„ä¼°ä»¥åŠä¸ä¸“å®¶çº§åŒ–å­¦æŠ€èƒ½è„±èŠ‚ç­‰å±€é™æ€§ã€‚ç ”ç©¶å›¢é˜Ÿé€šè¿‡åŸåˆ›å†…å®¹å’Œè¿­ä»£ç­–åˆ’æµç¨‹ç¡®ä¿äº†é¢˜ç›®è´¨é‡å¹¶æœ‰æ•ˆå‡è½»äº†æ•°æ®æ±¡æŸ“ï¼ŒåŒæ—¶ä¸ºæ¯ä¸ªé—®é¢˜é…å¯¹äº†ä¸“å®¶æ’°å†™çš„è§£é¢˜è·¯å¾„ã€‚é€šè¿‡å¼•å…¥æ¨ç†è·¯å¾„ä¿çœŸåº¦ï¼ˆReasoning Path Fidelity, RPFï¼‰è¯„åˆ†ï¼ŒSUPERChem èƒ½å¤Ÿæ·±å…¥è¯„ä¼°æ¨¡å‹åœ¨æœ€ç»ˆç­”æ¡ˆä¹‹å¤–çš„é€»è¾‘æ¨ç†è´¨é‡ã€‚å®éªŒç»“æœæ˜¾ç¤ºï¼Œç›®å‰è¡¨ç°æœ€å¥½çš„æ¨¡å‹ GPT-5 (High) å‡†ç¡®ç‡ä»…ä¸º 38.5%ï¼Œä»ä½äº 40.3% çš„äººç±»åŸºå‡†ï¼Œç´§éšå…¶åçš„æ˜¯ Gemini 2.5 Pro å’Œ DeepSeek-V3.1-Thinkã€‚è¯¥ç ”ç©¶æ­ç¤ºäº†è§†è§‰ä¿¡æ¯å¯¹æ¨¡å‹æ¨ç†çš„å¤æ‚å½±å“ï¼Œå¹¶ä¸ºæ¨åŠ¨ LLMs è¿ˆå‘ä¸“å®¶çº§åŒ–å­¦æ™ºèƒ½æä¾›äº†æå…·æŒ‘æˆ˜æ€§çš„è¯„ä¼°æ¡†æ¶ã€‚",
      "categories": [
        "cs.CL",
        "cs.AI",
        "cs.LG"
      ],
      "primary_category": "cs.CL",
      "comment": "35 pages, 11 figures, 5 tables",
      "pdf_url": "https://arxiv.org/pdf/2512.01274v1",
      "published_date": "2025-12-01 04:46:35 UTC",
      "updated_date": "2025-12-01 04:46:35 UTC",
      "processing_status": "completed",
      "attempts": 1,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "llm_backup_calls": 0,
      "last_update": "2026-01-26T12:38:16.146718+00:00"
    },
    {
      "arxiv_id": "2512.01262v1",
      "title": "Social Media Data Mining of Human Behaviour during Bushfire Evacuation",
      "title_zh": "ä¸›æ—ç«ç¾ç–æ•£æœŸé—´äººç±»è¡Œä¸ºçš„ç¤¾äº¤åª’ä½“æ•°æ®æŒ–æ˜",
      "authors": [
        "Junfeng Wu",
        "Xiangmin Zhou",
        "Erica Kuligowski",
        "Dhirendra Singh",
        "Enrico Ronchi",
        "Max Kinateder"
      ],
      "abstract": "Traditional data sources on bushfire evacuation behaviour, such as quantitative surveys and manual observations have severe limitations. Mining social media data related to bushfire evacuations promises to close this gap by allowing the collection and processing of a large amount of behavioural data, which are low-cost, accurate, possibly including location information and rich contextual information. However, social media data have many limitations, such as being scattered, incomplete, informal, etc. Together, these limitations represent several challenges to their usefulness to better understand bushfire evacuation. To overcome these challenges and provide guidance on which and how social media data can be used, this scoping review of the literature reports on recent advances in relevant data mining techniques. In addition, future applications and open problems are discussed. We envision future applications such as evacuation model calibration and validation, emergency communication, personalised evacuation training, and resource allocation for evacuation preparedness. We identify open problems such as data quality, bias and representativeness, geolocation accuracy, contextual understanding, crisis-specific lexicon and semantics, and multimodal data interpretation.",
      "tldr_zh": "è¯¥ç ”ç©¶é’ˆå¯¹ä¼ ç»Ÿæ—ç«ç–æ•£è¡Œä¸ºè°ƒæŸ¥æ•°æ®çš„å±€é™æ€§ï¼Œæ¢è®¨äº†æŒ–æ˜ç¤¾äº¤åª’ä½“æ•°æ®åœ¨è·å–å¤§è§„æ¨¡ã€ä½æˆæœ¬ä¸”å…·æœ‰ä¸°å¯Œä¸Šä¸‹æ–‡ä¿¡æ¯çš„è¡Œä¸ºæ•°æ®æ–¹é¢çš„æ½œåŠ›ã€‚é€šè¿‡å¯¹ç›¸å…³æ•°æ®æŒ–æ˜æŠ€æœ¯ï¼ˆdata mining techniquesï¼‰è¿›è¡ŒèŒƒå›´ç»¼è¿°ï¼ˆscoping reviewï¼‰ï¼Œè¯¥ç ”ç©¶æ—¨åœ¨å…‹æœç¤¾äº¤åª’ä½“æ•°æ®åˆ†æ•£ã€ä¸å®Œæ•´åŠéæ­£å¼æ€§å¸¦æ¥çš„æŒ‘æˆ˜ã€‚æ–‡ä¸­è¯¦ç»†è®¨è®ºäº†è¿™äº›æ•°æ®åœ¨ç–æ•£æ¨¡å‹æ ¡å‡†ä¸éªŒè¯ï¼ˆevacuation model calibration and validationï¼‰ã€åº”æ€¥é€šä¿¡åŠèµ„æºåˆ†é…ç­‰é¢†åŸŸçš„æœªæ¥åº”ç”¨å‰æ™¯ã€‚æ­¤å¤–ï¼Œç ”ç©¶è¿˜æŒ‡å‡ºäº†æ•°æ®è´¨é‡ã€åå·®ä¸ä»£è¡¨æ€§ã€åœ°ç†ä½ç½®å‡†ç¡®æ€§ï¼ˆgeolocation accuracyï¼‰ä»¥åŠå¤šæ¨¡æ€æ•°æ®è§£é‡Šï¼ˆmultimodal data interpretationï¼‰ç­‰äºŸå¾…è§£å†³çš„å…³é”®å¼€æ”¾æ€§é—®é¢˜ã€‚è¯¥ç»¼è¿°ä¸ºåˆ©ç”¨ç¤¾äº¤åª’ä½“æ•°æ®æå‡ç¾å®³å‡†å¤‡å’Œå“åº”èƒ½åŠ›æä¾›äº†é‡è¦çš„æŠ€æœ¯æŒ‡å¯¼ä¸ç†è®ºæ”¯æ’‘ã€‚",
      "categories": [
        "cs.SI",
        "cs.AI",
        "cs.ET",
        "cs.LG"
      ],
      "primary_category": "cs.SI",
      "comment": "",
      "pdf_url": "https://arxiv.org/pdf/2512.01262v1",
      "published_date": "2025-12-01 04:13:29 UTC",
      "updated_date": "2025-12-01 04:13:29 UTC",
      "processing_status": "completed",
      "attempts": 1,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "llm_backup_calls": 0,
      "last_update": "2026-01-26T12:38:21.135081+00:00"
    },
    {
      "arxiv_id": "2512.01256v1",
      "title": "Sentiment Analysis and Emotion Classification using Machine Learning Techniques for Nagamese Language -- A Low-resource Language",
      "title_zh": "åŸºäºæœºå™¨å­¦ä¹ æŠ€æœ¯çš„ä½èµ„æºè¯­è¨€ Nagamese æƒ…æ„Ÿåˆ†æä¸æƒ…ç»ªåˆ†ç±»",
      "authors": [
        "Ekha Morang",
        "Surhoni A. Ngullie",
        "Sashienla Longkumer",
        "Teisovi Angami"
      ],
      "abstract": "The Nagamese language, a.k.a Naga Pidgin, is an Assamese-lexified creole language developed primarily as a means of communication in trade between the people from Nagaland and people from Assam in the north-east India. Substantial amount of work in sentiment analysis has been done for resource-rich languages like English, Hindi, etc. However, no work has been done in Nagamese language. To the best of our knowledge, this is the first attempt on sentiment analysis and emotion classification for the Nagamese Language. The aim of this work is to detect sentiments in terms of polarity (positive, negative and neutral) and basic emotions contained in textual content of Nagamese language. We build sentiment polarity lexicon of 1,195 nagamese words and use these to build features along with additional features for supervised machine learning techniques using Na\"ive Bayes and Support Vector Machines.\n  Keywords: Nagamese, NLP, sentiment analysis, machine learning",
      "tldr_zh": "è¯¥ç ”ç©¶é’ˆå¯¹ Nagamese è¯­è¨€ï¼ˆä¸€ç§ä½èµ„æºè¯­è¨€/Low-resource Languageï¼‰å¼€å±•äº†æƒ…æ„Ÿåˆ†æå’Œæƒ…ç»ªåˆ†ç±»å·¥ä½œï¼Œè¿™æ˜¯ç›®å‰å·²çŸ¥çš„ç¬¬ä¸€é¡¹é’ˆå¯¹è¯¥è¯­è¨€çš„ç›¸å…³ç ”ç©¶ã€‚è¯¥å·¥ä½œæ—¨åœ¨æ£€æµ‹æ–‡æœ¬å†…å®¹ä¸­çš„æƒ…æ„Ÿææ€§ï¼ˆPositive, Negative å’Œ Neutralï¼‰ä»¥åŠåŸºæœ¬æƒ…ç»ªï¼Œå¡«è¡¥äº†è¯¥è¯­è¨€åœ¨è‡ªç„¶è¯­è¨€å¤„ç† (NLP) é¢†åŸŸçš„ç©ºç™½ã€‚ç ”ç©¶äººå‘˜æ„å»ºäº†ä¸€ä¸ªåŒ…å« 1,195 ä¸ªè¯æ±‡çš„æƒ…æ„Ÿææ€§è¯å…¸ (Sentiment Polarity Lexicon)ï¼Œå¹¶ä»¥æ­¤ä½œä¸ºç‰¹å¾åŸºç¡€ã€‚é€šè¿‡åº”ç”¨æœ´ç´ è´å¶æ–¯ (NaÃ¯ve Bayes) å’Œæ”¯æŒå‘é‡æœº (Support Vector Machines) ç­‰ç›‘ç£æœºå™¨å­¦ä¹  (Supervised Machine Learning) æŠ€æœ¯ï¼Œè¯¥ç ”ç©¶å®ç°äº†å¯¹ Nagamese æ–‡æœ¬çš„æœ‰æ•ˆåˆ†ç±»ã€‚è¿™ä¸€æˆæœä¸ºä½èµ„æºè¯­è¨€çš„è®¡ç®—è¯­è¨€å­¦ç ”ç©¶æä¾›äº†å®è´µçš„æ•°æ®æ”¯æŒå’Œæ–¹æ³•å‚è€ƒã€‚",
      "categories": [
        "cs.CL",
        "cs.AI"
      ],
      "primary_category": "cs.CL",
      "comment": "10 pages",
      "pdf_url": "https://arxiv.org/pdf/2512.01256v1",
      "published_date": "2025-12-01 04:01:29 UTC",
      "updated_date": "2025-12-01 04:01:29 UTC",
      "processing_status": "completed",
      "attempts": 1,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "llm_backup_calls": 0,
      "last_update": "2026-01-26T12:38:20.734635+00:00"
    },
    {
      "arxiv_id": "2512.17917v1",
      "title": "KVReviver: Reversible KV Cache Compression with Sketch-Based Token Reconstruction",
      "title_zh": "KVReviverï¼šåŸºäº Sketch Token é‡æ„çš„å¯é€† KV ç¼“å­˜å‹ç¼©",
      "authors": [
        "Aomufei Yuan",
        "Zhiming Wang",
        "Ruijie Miao",
        "Dayu Wang",
        "Yuxuan Tian",
        "Zihan Wang",
        "Yebo Peng",
        "Yuhan Wu",
        "Bairen Yi",
        "Xin Liu",
        "Tong Yang"
      ],
      "abstract": "As the context length of current large language models (LLMs) rapidly increases, the memory demand for the Key-Value (KV) cache is becoming a bottleneck for LLM deployment and batch processing. Traditional KV cache compression methods typically involve permanently evicting or irreversibly merging \"less important\" tokens with low attention scores. This approach results in the unrecoverable loss of token information, which we call Contextual Amnesia, significantly degrading the model's information retrieval capability. To address this issue, we propose KVReviver, a reversible KV cache compression method based on the sketch algorithm. This method allows reconstructing compressed tokens from an additional data structure, thus enabling full-scale computation within limited memory. Experiments showed that in 2k-length contexts, it requires only 10% of KV Cache budget while maintaining identical end-to-end inference accuracy. For 32k-length contexts, it achieves equivalent or comparable accuracy ~2% accuracy loss) using merely 25% of KV Cache budget.",
      "tldr_zh": "è¯¥ç ”ç©¶é’ˆå¯¹å¤§è¯­è¨€æ¨¡å‹ï¼ˆLLMsï¼‰ä¸Šä¸‹æ–‡é•¿åº¦å¢åŠ å¯¼è‡´çš„ KV Cache å†…å­˜ç“¶é¢ˆé—®é¢˜ï¼ŒæŒ‡å‡ºäº†ä¼ ç»Ÿå‹ç¼©æ–¹æ³•å› æ°¸ä¹…å‰”é™¤æˆ–ä¸å¯é€†åˆå¹¶æ ‡è®°è€Œäº§ç”Ÿçš„â€œä¸Šä¸‹æ–‡å¤±å¿†â€ï¼ˆContextual Amnesiaï¼‰ç°è±¡ã€‚ä¸ºæ­¤ï¼Œä½œè€…æå‡ºäº† KVReviverï¼Œè¿™æ˜¯ä¸€ç§åŸºäº Sketch ç®—æ³•çš„å¯é€† KV Cache å‹ç¼©æ–¹æ³•ã€‚è¯¥æ–¹æ³•å…è®¸é€šè¿‡é¢å¤–çš„è¾…åŠ©æ•°æ®ç»“æ„é‡æ„è¢«å‹ç¼©çš„æ ‡è®°ï¼ˆtokensï¼‰ï¼Œä»è€Œåœ¨æœ‰é™çš„å†…å­˜é¢„ç®—å†…å®ç°å…¨è§„æ¨¡è®¡ç®—ï¼Œé¿å…äº†ä¸å¯æ¢å¤çš„ä¿¡æ¯ä¸¢å¤±ã€‚å®éªŒç»“æœè¡¨æ˜ï¼Œåœ¨ 2k ä¸Šä¸‹æ–‡é•¿åº¦ä¸‹ï¼ŒKVReviver ä»…éœ€ 10% çš„ KV Cache é¢„ç®—å³å¯ä¿æŒä¸åŸå§‹æ¨¡å‹ä¸€è‡´çš„æ¨ç†å‡†ç¡®ç‡ã€‚è€Œåœ¨ 32k é•¿åº¦çš„ä¸Šä¸‹æ–‡æµ‹è¯•ä¸­ï¼Œè¯¥æ–¹æ³•ä»…ä½¿ç”¨ 25% çš„ KV Cache é¢„ç®—ä¾¿å®ç°äº†ç›¸å½“æˆ–æ¥è¿‘çš„å‡†ç¡®ç‡ï¼Œç²¾åº¦æŸå¤±ä»…çº¦ 2%ã€‚è¿™ç§å¯é€†æ€§è®¾è®¡ä¸ºé•¿æ–‡æœ¬ LLM çš„é«˜æ•ˆéƒ¨ç½²å’Œæ‰¹å¤„ç†æä¾›äº†ä¸€ç§èƒ½å¹³è¡¡å†…å­˜å¼€é”€ä¸æ¨¡å‹ç²¾åº¦çš„æ–°é€”å¾„ã€‚",
      "categories": [
        "cs.CL",
        "cs.AI"
      ],
      "primary_category": "cs.CL",
      "comment": "12 pages, 6 figures",
      "pdf_url": "https://arxiv.org/pdf/2512.17917v1",
      "published_date": "2025-12-01 03:59:20 UTC",
      "updated_date": "2025-12-01 03:59:20 UTC",
      "processing_status": "completed",
      "attempts": 1,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "llm_backup_calls": 0,
      "last_update": "2026-01-26T12:39:17.834079+00:00"
    },
    {
      "arxiv_id": "2512.01249v1",
      "title": "Pascal-Weighted Genetic Algorithms: A Binomially-Structured Recombination Framework",
      "title_zh": "Pascal åŠ æƒé—ä¼ ç®—æ³•ï¼šä¸€ç§äºŒé¡¹å¼ç»“æ„çš„é‡ç»„æ¡†æ¶",
      "authors": [
        "Otman A. Basir"
      ],
      "abstract": "This paper introduces a new family of multi-parent recombination operators for Genetic Algorithms (GAs), based on normalized Pascal (binomial) coefficients. Unlike classical two-parent crossover operators, Pascal-Weighted Recombination (PWR) forms offsprings as structured convex combination of multiple parents, using binomially shaped weights that emphasize central inheritance while suppressing disruptive variance. We develop a mathematical framework for PWR, derive variance-transfer properties, and analyze its effect on schema survival. The operator is extended to real-valued, binary/logit, and permutation representations.\n  We evaluate the proposed method on four representative benchmarks: (i) PID controller tuning evaluated using the ITAE metric, (ii) FIR low-pass filter design under magnitude-response constraints, (iii) wireless power-modulation optimization under SINR coupling, and (iv) the Traveling Salesman Problem (TSP). We demonstrate how, across these benchmarks, PWR consistently yields smoother convergence, reduced variance, and achieves 9-22% performance gains over standard recombination operators. The approach is simple, algorithm-agnostic, and readily integrable into diverse GA architectures.",
      "tldr_zh": "è¯¥ç ”ç©¶æå‡ºäº†ä¸€ç§åä¸º Pascal-Weighted Recombination (PWR) çš„æ–°å‹å¤šäº²æœ¬é‡ç»„ç®—å­ï¼Œæ—¨åœ¨ä¼˜åŒ– Genetic Algorithms (GAs) çš„è¿›åŒ–æ•ˆç‡ã€‚ä¸ä¼ ç»Ÿçš„åŒäº²æœ¬äº¤å‰ç®—å­ä¸åŒï¼ŒPWR åˆ©ç”¨å½’ä¸€åŒ–çš„ Pascal äºŒé¡¹å¼ç³»æ•°ï¼Œå°†åä»£æ„å»ºä¸ºå¤šä¸ªäº²æœ¬çš„ç»“æ„åŒ–å‡¸ç»„åˆã€‚è¿™ç§åŸºäºäºŒé¡¹å¼æƒé‡çš„è®¾è®¡èƒ½å¤Ÿé€šè¿‡å¼ºè°ƒä¸­å¿ƒé—ä¼ ç‰¹å¾æ¥æŠ‘åˆ¶ç ´åæ€§æ–¹å·®ï¼Œç ”ç©¶è¿˜æ·±å…¥æ¢è®¨äº†å…¶åœ¨å®å€¼ã€äºŒè¿›åˆ¶åŠç½®æ¢è¡¨ç¤ºä¸­çš„æ•°å­¦æ¡†æ¶ä¸æ–¹å·®ä¼ é€’ç‰¹æ€§ã€‚é€šè¿‡åœ¨ PID æ§åˆ¶å™¨è°ƒèŠ‚ã€FIR æ»¤æ³¢å™¨è®¾è®¡ã€æ— çº¿åŠŸç‡è°ƒåˆ¶ä¼˜åŒ–å’Œ Traveling Salesman Problem (TSP) ä¸Šçš„æµ‹è¯•ï¼Œè¯æ˜äº† PWR å…·æœ‰æ›´å¹³æ»‘çš„æ”¶æ•›æ€§ã€‚å®éªŒæ•°æ®è¡¨æ˜ï¼Œè¯¥ç®—å­æ¯”æ ‡å‡†é‡ç»„æ–¹æ³•å®ç°äº† 9-22% çš„æ€§èƒ½æå‡ï¼Œä¸”å…·å¤‡ç®—æ³•æ— å…³æ€§ï¼Œå¯å¹¿æ³›é›†æˆäºå„ç±» GA æ¶æ„ã€‚",
      "categories": [
        "cs.NE",
        "cs.AI",
        "eess.SY"
      ],
      "primary_category": "cs.NE",
      "comment": "23 pages, 8 figures",
      "pdf_url": "https://arxiv.org/pdf/2512.01249v1",
      "published_date": "2025-12-01 03:51:29 UTC",
      "updated_date": "2025-12-01 03:51:29 UTC",
      "processing_status": "completed",
      "attempts": 1,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "llm_backup_calls": 0,
      "last_update": "2026-01-26T12:39:20.235556+00:00"
    },
    {
      "arxiv_id": "2512.01242v2",
      "title": "Generative Adversarial Gumbel MCTS for Abstract Visual Composition Generation",
      "title_zh": "é¢å‘æŠ½è±¡è§†è§‰ç»„åˆç”Ÿæˆçš„ç”Ÿæˆå¯¹æŠ— Gumbel MCTS",
      "authors": [
        "Zirui Zhao",
        "Boye Niu",
        "David Hsu",
        "Wee Sun Lee"
      ],
      "abstract": "We study abstract visual composition, in which identity is primarily determined by the spatial configuration and relations among a small set of geometric primitives (e.g., parts, symmetry, topology). They are invariant primarily to texture and photorealistic detail. Composing such structures from fixed components under geometric constraints and vague goal specification (such as text) is non-trivial due to combinatorial placement choices, limited data, and discrete feasibility (overlap-free, allowable orientations), which create a sparse solution manifold ill-suited to purely statistical pixel-space generators. We propose a constraint-guided framework that combines explicit geometric reasoning with neural semantics. An AlphaGo-style search enforces feasibility, while a fine-tuned vision-language model scores semantic alignment as reward signals. Our algorithm uses a policy network as a heuristic in Monte-Carlo Tree Search and fine-tunes the network via search-generated plans. Inspired by the Generative Adversarial Network, we use the generated instances for adversarial reward refinement. Over time, the generation should approach the actual data more closely when the reward model cannot distinguish between generated instances and ground-truth. In the Tangram Assembly task, our approach yields higher validity and semantic fidelity than diffusion and auto-regressive baselines, especially as constraints tighten.",
      "tldr_zh": "è¯¥ç ”ç©¶é’ˆå¯¹æŠ½è±¡è§†è§‰æ„å›¾ç”Ÿæˆä¸­çš„å‡ ä½•çº¦æŸå’Œç»„åˆçˆ†ç‚¸é—®é¢˜ï¼Œæå‡ºäº†ä¸€ç§åä¸º Generative Adversarial Gumbel MCTS çš„çº¦æŸå¼•å¯¼æ¡†æ¶ã€‚è¯¥æ¡†æ¶å°†æ˜¾å¼å‡ ä½•æ¨ç†ä¸ç¥ç»è¯­ä¹‰ç›¸ç»“åˆï¼Œåˆ©ç”¨ç±»ä¼¼ AlphaGo çš„ Monte-Carlo Tree Search (MCTS) ç¡®ä¿ç”Ÿæˆçš„å‡ ä½•å¯è¡Œæ€§ï¼Œå¹¶é€šè¿‡å¾®è°ƒçš„è§†è§‰è¯­è¨€æ¨¡å‹ (VLM) æä¾›è¯­ä¹‰å¯¹é½çš„å¥–åŠ±ä¿¡å·ã€‚ç ”ç©¶åˆ›æ–°æ€§åœ°å¼•å…¥äº†å—åˆ° Generative Adversarial Network (GAN) å¯å‘çš„å¯¹æŠ—æ€§å¥–åŠ±ç»†åŒ–æœºåˆ¶ï¼Œé€šè¿‡æœç´¢ç”Ÿæˆçš„è®¡åˆ’ä¸æ–­ä¼˜åŒ–ç­–ç•¥ç½‘ç»œï¼Œä½¿ç”Ÿæˆå®ä¾‹æ›´è´´è¿‘çœŸå®æ•°æ®åˆ†å¸ƒã€‚åœ¨ Tangram Assembly ä»»åŠ¡ä¸Šçš„å®éªŒè¯æ˜ï¼Œè¯¥æ–¹æ³•åœ¨ç”Ÿæˆç»“æœçš„åˆæ³•æ€§ä¸è¯­ä¹‰ä¿çœŸåº¦ä¸Šæ˜¾è‘—ä¼˜äº diffusion å’Œ auto-regressive ç­‰åŸºå‡†æ¨¡å‹ï¼Œå°¤å…¶åœ¨ä¸¥è‹›çº¦æŸä¸‹è¡¨ç°å‡ºæå¼ºçš„é²æ£’æ€§ã€‚è¯¥ç ”ç©¶ä¸ºç»“åˆæ˜¾å¼æ¨ç†ä¸æ·±åº¦å­¦ä¹ å¤„ç†å¤æ‚ç»“æ„åŒ–ç”Ÿæˆä»»åŠ¡æä¾›äº†æ–°çš„æ€è·¯ã€‚",
      "categories": [
        "cs.CV",
        "cs.AI",
        "cs.CL"
      ],
      "primary_category": "cs.CV",
      "comment": "",
      "pdf_url": "https://arxiv.org/pdf/2512.01242v2",
      "published_date": "2025-12-01 03:38:44 UTC",
      "updated_date": "2026-01-15 07:18:11 UTC",
      "processing_status": "completed",
      "attempts": 1,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "llm_backup_calls": 0,
      "last_update": "2026-01-26T12:39:10.035524+00:00"
    },
    {
      "arxiv_id": "2512.01241v2",
      "title": "First, do NOHARM: towards clinically safe large language models",
      "title_zh": "é¦–å…ˆï¼Œåšåˆ° NOHARMï¼šè¿ˆå‘ä¸´åºŠå®‰å…¨çš„å¤§è¯­è¨€æ¨¡å‹",
      "authors": [
        "David Wu",
        "Fateme Nateghi Haredasht",
        "Saloni Kumar Maharaj",
        "Priyank Jain",
        "Jessica Tran",
        "Matthew Gwiazdon",
        "Arjun Rustagi",
        "Jenelle Jindal",
        "Jacob M. Koshy",
        "Vinay Kadiyala",
        "Anup Agarwal",
        "Bassman Tappuni",
        "Brianna French",
        "Sirus Jesudasen",
        "Christopher V. Cosgriff",
        "Rebanta Chakraborty",
        "Jillian Caldwell",
        "Susan Ziolkowski",
        "David J. Iberri",
        "Robert Diep",
        "Rahul S. Dalal",
        "Kira L. Newman",
        "Kristin Galetta",
        "J. Carl Pallais",
        "Nancy Wei",
        "Kathleen M. Buchheit",
        "David I. Hong",
        "Ernest Y. Lee",
        "Allen Shih",
        "Vartan Pahalyants",
        "Tamara B. Kaplan",
        "Vishnu Ravi",
        "Sarita Khemani",
        "April S. Liang",
        "Daniel Shirvani",
        "Advait Patil",
        "Nicholas Marshall",
        "Kanav Chopra",
        "Joel Koh",
        "Adi Badhwar",
        "Liam G. McCoy",
        "David J. H. Wu",
        "Yingjie Weng",
        "Sumant Ranji",
        "Kevin Schulman",
        "Nigam H. Shah",
        "Jason Hom",
        "Arnold Milstein",
        "Adam Rodman",
        "Jonathan H. Chen",
        "Ethan Goh"
      ],
      "abstract": "Large language models (LLMs) are routinely used by physicians and patients for medical advice, yet their clinical safety profiles remain poorly characterized. We present NOHARM (Numerous Options Harm Assessment for Risk in Medicine), a benchmark using 100 real primary care-to-specialist consultation cases to measure frequency and severity of harm from LLM-generated medical recommendations. NOHARM covers 10 specialties, with 12,747 expert annotations for 4,249 clinical management options. Across 31 LLMs, potential for severe harm from LLM recommendations occurs in up to 22.2% (95% CI 21.6-22.8%) of cases, with harm of omission accounting for 76.6% (95% CI 76.4-76.8%) of errors. Safety performance is only moderately correlated (r = 0.61-0.64) with existing AI and medical knowledge benchmarks. The best models outperform generalist physicians on safety (mean difference 9.7%, 95% CI 7.0-12.5%), and a diverse multi-agent approach improves safety compared to solo models (mean difference 8.0%, 95% CI 4.0-12.1%). Therefore, despite strong performance on existing evaluations, widely used AI models can produce severely harmful medical advice at nontrivial rates, underscoring clinical safety as a distinct performance dimension necessitating explicit measurement.",
      "tldr_zh": "è¯¥ç ”ç©¶æå‡ºäº†NOHARM (Numerous Options Harm Assessment for Risk in Medicine)ï¼Œè¿™æ˜¯ä¸€ä¸ªæ—¨åœ¨è¯„ä¼°å¤§å‹è¯­è¨€æ¨¡å‹(LLMs)åŒ»ç–—å»ºè®®ä¸´åºŠå®‰å…¨æ€§çš„æ–°å‹åŸºå‡†ã€‚è¯¥åŸºå‡†åŸºäº100ä¸ªçœŸå®çš„åˆçº§ä¿å¥åˆ°ä¸“ç§‘å’¨è¯¢æ¡ˆä¾‹ï¼Œæ¶µç›–10ä¸ªåŒ»å­¦ä¸“ä¸šï¼Œå¹¶åŒ…å«12,747é¡¹ä¸“å®¶å¯¹4,249ä¸ªä¸´åºŠç®¡ç†é€‰é¡¹çš„æ ‡æ³¨ã€‚å®éªŒæµ‹è¯•äº†31ä¸ªä¸»æµLLMsï¼Œå‘ç°å…¶ç”Ÿæˆçš„å»ºè®®åœ¨é«˜è¾¾22.2%çš„æƒ…å†µä¸‹å­˜åœ¨ä¸¥é‡ä¼¤å®³é£é™©ï¼Œå…¶ä¸­é—æ¼ä¼¤å®³(harm of omission)å æ€»é”™è¯¯çš„76.6%ã€‚ç ”ç©¶æŒ‡å‡ºï¼ŒLLMsçš„å®‰å…¨è¡¨ç°ä¸ç°æœ‰çš„AIåŠåŒ»å­¦çŸ¥è¯†åŸºå‡†ä»…å‘ˆä¸­åº¦ç›¸å…³ï¼Œè¯æ˜äº†ä¸´åºŠå®‰å…¨æ€§æ˜¯ä¸€ä¸ªéœ€è¦ç‹¬ç«‹è¡¡é‡çš„æ€§èƒ½ç»´åº¦ã€‚è™½ç„¶æœ€ä½³æ¨¡å‹åœ¨å®‰å…¨æ€§ä¸Šä¼˜äºæ™®é€šå…¨ç§‘åŒ»ç”Ÿï¼Œä¸”é‡‡ç”¨å¤šæ™ºèƒ½ä½“(multi-agent)æ–¹æ³•èƒ½è¿›ä¸€æ­¥æå‡å®‰å…¨æ€§ï¼Œä½†AIç”Ÿæˆä¸¥é‡æœ‰å®³å»ºè®®çš„é¢‘ç‡ä¾ç„¶ä¸å®¹å¿½è§†ã€‚è¯¥ç ”ç©¶å¼ºè°ƒï¼Œå°½ç®¡ç›®å‰çš„AIæ¨¡å‹è¡¨ç°å¼ºåŠ²ï¼Œä½†å¿…é¡»å¯¹å…¶ä¸´åºŠå®‰å…¨æ€§è¿›è¡Œæ˜¾å¼æµ‹é‡ï¼Œä»¥ç¡®ä¿åœ¨åŒ»ç–—é¢†åŸŸçš„åº”ç”¨å®‰å…¨ã€‚",
      "categories": [
        "cs.CY",
        "cs.AI"
      ],
      "primary_category": "cs.CY",
      "comment": "",
      "pdf_url": "https://arxiv.org/pdf/2512.01241v2",
      "published_date": "2025-12-01 03:33:16 UTC",
      "updated_date": "2025-12-17 21:54:50 UTC",
      "processing_status": "completed",
      "attempts": 1,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "llm_backup_calls": 0,
      "last_update": "2026-01-26T12:39:18.637810+00:00"
    },
    {
      "arxiv_id": "2512.01234v2",
      "title": "Proactive Agentic Whiteboards: Enhancing Diagrammatic Learning",
      "title_zh": "ä¸»åŠ¨å¼æ™ºèƒ½ä½“ç™½æ¿ï¼šå¢å¼ºå›¾è§£åŒ–å­¦ä¹ ",
      "authors": [
        "Suveen Ellawela",
        "Sashenka Gamage",
        "Dinithi Dissanayake"
      ],
      "abstract": "Educators frequently rely on diagrams to explain complex concepts during lectures, yet creating clear and complete visual representations in real time while simultaneously speaking can be cognitively demanding. Incomplete or unclear diagrams may hinder student comprehension, as learners must mentally reconstruct missing information while following the verbal explanation. Inspired by advances in code completion tools, we introduce DrawDash, an AI-powered whiteboard assistant that proactively completes and refines educational diagrams through multimodal understanding. DrawDash adopts a TAB-completion interaction model: it listens to spoken explanations, detects intent, and dynamically suggests refinements that can be accepted with a single keystroke. We demonstrate DrawDash across four diverse teaching scenarios, spanning topics from computer science and web development to biology. This work represents an early exploration into reducing instructors' cognitive load and improving diagram-based pedagogy through real-time, speech-driven visual assistance, and concludes with a discussion of current limitations and directions for formal classroom evaluation.",
      "tldr_zh": "è¯¥ç ”ç©¶é’ˆå¯¹æ•™å¸ˆåœ¨å®æ—¶ç»˜åˆ¶å›¾è¡¨è§£é‡Šå¤æ‚æ¦‚å¿µæ—¶é¢ä¸´çš„é«˜è®¤çŸ¥è´Ÿè·(cognitive load)é—®é¢˜ï¼Œæå‡ºäº† DrawDashï¼Œä¸€ç§åŸºäºäººå·¥æ™ºèƒ½çš„ä¸»åŠ¨å¼ç™½æ¿åŠ©æ‰‹ã€‚DrawDash ç»“åˆå¤šæ¨¡æ€ç†è§£(multimodal understanding)æŠ€æœ¯ï¼Œèƒ½å¤Ÿé€šè¿‡å®æ—¶å€¾å¬æ•™å¸ˆçš„å£å¤´è®²è§£æ¥è¯†åˆ«å…¶æ„å›¾ï¼Œå¹¶ä¸»åŠ¨è¡¥å…¨æˆ–å®Œå–„æ•™å­¦å›¾è¡¨ã€‚è¯¥ç³»ç»Ÿé‡‡ç”¨äº†ç±»ä¼¼ä»£ç è¡¥å…¨çš„ TAB-completion äº¤äº’æ¨¡å‹ï¼Œèƒ½åŠ¨æ€ç”Ÿæˆç»˜å›¾å»ºè®®ï¼Œæ•™å¸ˆä»…éœ€é€šè¿‡ç®€å•çš„æŒ‰é”®æ“ä½œå³å¯å¿«é€Ÿé‡‡çº³ã€‚ç ”ç©¶å›¢é˜Ÿåœ¨è®¡ç®—æœºç§‘å­¦ã€ç½‘é¡µå¼€å‘å’Œç”Ÿç‰©å­¦ç­‰å››ä¸ªä»£è¡¨æ€§æ•™å­¦åœºæ™¯ä¸­éªŒè¯äº† DrawDash çš„åŠŸèƒ½ã€‚è¿™ä¸€æˆæœé€šè¿‡è¯­éŸ³é©±åŠ¨çš„è§†è§‰è¾…åŠ©ï¼Œæ—¨åœ¨æœ‰æ•ˆé™ä½æˆè¯¾è¿‡ç¨‹ä¸­çš„è®¤çŸ¥å‹åŠ›å¹¶æå‡å›¾è¡¨æ•™å­¦æ³•(diagram-based pedagogy)çš„è´¨é‡ã€‚è¯¥é¡¹å·¥ä½œä¸ºå®æ—¶è¾…åŠ©æ•™å­¦å·¥å…·çš„å¼€å‘æä¾›äº†æ–°çš„æ–¹å‘ï¼Œå¹¶å¯¹æœªæ¥åœ¨çœŸå®è¯¾å ‚ç¯å¢ƒä¸­çš„åº”ç”¨è¯„ä¼°è¿›è¡Œäº†å±•æœ›ã€‚",
      "categories": [
        "cs.HC",
        "cs.AI"
      ],
      "primary_category": "cs.HC",
      "comment": "",
      "pdf_url": "https://arxiv.org/pdf/2512.01234v2",
      "published_date": "2025-12-01 03:20:12 UTC",
      "updated_date": "2025-12-02 03:13:40 UTC",
      "processing_status": "completed",
      "attempts": 1,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "llm_backup_calls": 0,
      "last_update": "2026-01-26T12:39:21.833377+00:00"
    },
    {
      "arxiv_id": "2512.01232v1",
      "title": "LLM-as-a-Judge for Scalable Test Coverage Evaluation: Accuracy, Operational Reliability, and Cost",
      "title_zh": "é¢å‘å¯æ‰©å±•æµ‹è¯•è¦†ç›–ç‡è¯„ä¼°çš„ LLM-as-a-Judgeï¼šå‡†ç¡®æ€§ã€è¿è¡Œå¯é æ€§ä¸æˆæœ¬",
      "authors": [
        "Donghao Huang",
        "Shila Chew",
        "Anna Dutkiewicz",
        "Zhaoxia Wang"
      ],
      "abstract": "Assessing software test coverage at scale remains a bottleneck in QA pipelines. We present LLM-as-a-Judge (LAJ), a production-ready, rubric-driven framework for evaluating Gherkin acceptance tests with structured JSON outputs. Across 20 model configurations (GPT-4, GPT-5 with varying reasoning effort, and open-weight models) on 100 expert-annotated scripts over 5 runs (500 evaluations), we provide the first comprehensive analysis spanning accuracy, operational reliability, and cost. We introduce the Evaluation Completion Rate (ECR@1) to quantify first-attempt success, revealing reliability from 85.4% to 100.0% with material cost implications via retries. Results show that smaller models can outperform larger ones: GPT-4o Mini attains the best accuracy (6.07 MAAE), high reliability (96.6% ECR@1), and low cost ($1.01 per 1K), yielding a 78x cost reduction vs. GPT-5 (high reasoning) while improving accuracy. Reasoning effort is model-family dependent: GPT-5 benefits from increased reasoning (with predictable accuracy-cost tradeoffs), whereas open-weight models degrade across all dimensions as reasoning increases. Overall, cost spans 175x ($0.45-$78.96 per 1K). We release the dataset, framework, and code to support reproducibility and deployment.",
      "tldr_zh": "è¯¥ç ”ç©¶æå‡ºäº†LLM-as-a-Judge (LAJ) æ¡†æ¶ï¼Œè¿™æ˜¯ä¸€ç§é¢å‘ç”Ÿäº§ç¯å¢ƒã€ç”±å‡†åˆ™é©±åŠ¨ (rubric-driven) çš„è¯„ä¼°æ¡†æ¶ï¼Œæ—¨åœ¨è§£å†³QAæµæ°´çº¿ä¸­å¤§è§„æ¨¡è½¯ä»¶æµ‹è¯•è¦†ç›–ç‡è¯„ä¼°çš„ç“¶é¢ˆé—®é¢˜ã€‚è¯¥æ¡†æ¶é€šè¿‡è¾“å‡ºç»“æ„åŒ–çš„JSONæ ¼å¼æ¥è¯„ä¼°GherkinéªŒæ”¶æµ‹è¯•ï¼Œå¹¶å¯¹åŒ…æ‹¬GPT-4ã€GPT-5åŠå¼€æºæƒé‡æ¨¡å‹åœ¨å†…çš„20ç§æ¨¡å‹é…ç½®è¿›è¡Œäº†è¯¦å°½çš„å‡†ç¡®æ€§ã€è¿è¡Œå¯é æ€§å’Œæˆæœ¬åˆ†æã€‚ä½œè€…å¼•å…¥äº†è¯„ä¼°å®Œæˆç‡ (Evaluation Completion Rate, ECR@1) æŒ‡æ ‡æ¥é‡åŒ–åˆæ¬¡å°è¯•çš„æˆåŠŸç‡ï¼Œæ­ç¤ºäº†å„æ¨¡å‹åœ¨85.4%åˆ°100.0%ä¹‹é—´çš„å¯é æ€§å·®å¼‚ã€‚å®éªŒç»“æœæ˜¾ç¤ºï¼Œè¾ƒå°çš„æ¨¡å‹å¯ä»¥è¶…è¶Šå¤§æ¨¡å‹ï¼Œå…¶ä¸­GPT-4o Miniåœ¨ä¿æŒé«˜å¯é æ€§çš„åŒæ—¶è¾¾åˆ°äº†æœ€ä½³å‡†ç¡®ç‡ï¼Œä¸”æˆæœ¬ä»…ä¸ºé«˜æ¨ç†å¼ºåº¦GPT-5çš„ä¸ƒåå…«åˆ†ä¹‹ä¸€ã€‚ç ”ç©¶è¿˜å‘ç°æ¨ç†åŠªåŠ› (Reasoning effort) å¯¹æ€§èƒ½çš„å½±å“å–å†³äºæ¨¡å‹ç³»åˆ—ï¼ŒGPT-5èƒ½ä»ä¸­è·ç›Šï¼Œè€Œå¼€æºæ¨¡å‹åœ¨æ¨ç†å¢åŠ æ—¶å„ç»´åº¦æ€§èƒ½å‡æœ‰æ‰€ä¸‹é™ã€‚è¯¥ç ”ç©¶æœ€åé€šè¿‡å‘å¸ƒæ•°æ®é›†å’Œä»£ç ï¼Œä¸ºå®ç°å¯æ‰©å±•ä¸”ç»æµé«˜æ•ˆçš„æµ‹è¯•è‡ªåŠ¨åŒ–æä¾›äº†é‡è¦æ”¯æ’‘ã€‚",
      "categories": [
        "cs.SE",
        "cs.AI"
      ],
      "primary_category": "cs.SE",
      "comment": "7 pages, accepted by the AAAI 2026 Workshop on Next Gen Code Development with Collaborative AI Agents",
      "pdf_url": "https://arxiv.org/pdf/2512.01232v1",
      "published_date": "2025-12-01 03:19:33 UTC",
      "updated_date": "2025-12-01 03:19:33 UTC",
      "processing_status": "completed",
      "attempts": 1,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "llm_backup_calls": 0,
      "last_update": "2026-01-26T12:40:40.235543+00:00"
    },
    {
      "arxiv_id": "2512.20632v1",
      "title": "Erkang-Diagnosis-1.1 Technical Report",
      "title_zh": "Erkang-Diagnosis-1.1 æŠ€æœ¯æŠ¥å‘Š",
      "authors": [
        "Jianbing Ma",
        "Ao Feng",
        "Zhenjie Gao",
        "Xinyu Song",
        "Li Su",
        "Bin Chen",
        "Wei Wang",
        "Jiamin Wu"
      ],
      "abstract": "This report provides a detailed introduction to Erkang-Diagnosis-1.1 model, our AI healthcare consulting assistant developed using Alibaba Qwen-3 model. The Erkang model integrates approximately 500GB of high-quality structured medical knowledge, employing a hybrid approach combining enhanced pre-training and retrieval-enhanced generation to create a secure, reliable, and professional AI health advisor. Through 3-5 efficient interaction rounds, Erkang Diagnosis can accurately understand user symptoms, conduct preliminary analysis, and provide valuable diagnostic suggestions and health guidance. Designed to become users intelligent health companions, it empowers primary healthcare and health management. To validate, Erkang-Diagnosis-1.1 leads GPT-4 in terms of comprehensive medical exams.",
      "tldr_zh": "è¯¥æŠ€æœ¯æŠ¥å‘Šè¯¦ç»†ä»‹ç»äº†åŸºäºé˜¿é‡Œå·´å·´Qwen-3æ¨¡å‹å¼€å‘çš„åŒ»ç–—å’¨è¯¢åŠ©æ‰‹Erkang-Diagnosis-1.1ã€‚è¯¥æ¨¡å‹é›†æˆäº†çº¦500GBçš„é«˜è´¨é‡ç»“æ„åŒ–åŒ»å­¦çŸ¥è¯†ï¼Œé€šè¿‡ç»“åˆå¢å¼ºé¢„è®­ç»ƒ(enhanced pre-training)ä¸æ£€ç´¢å¢å¼ºç”Ÿæˆ(Retrieval-Augmented Generation, RAG)çš„æ··åˆæ–¹æ³•ï¼Œæ„å»ºäº†ä¸€ä¸ªå®‰å…¨ã€ä¸“ä¸šä¸”å¯é çš„AIå¥åº·é¡¾é—®ç³»ç»Ÿã€‚é€šè¿‡3-5è½®çš„é«˜æ•ˆäº¤äº’ï¼ŒErkang-Diagnosiså¯ä»¥å‡†ç¡®ç†è§£ç”¨æˆ·ç—‡çŠ¶ï¼Œå¹¶è¿›è¡Œåˆæ­¥åˆ†æä»¥æä¾›æœ‰ä»·å€¼çš„è¯Šæ–­å»ºè®®ä¸å¥åº·æŒ‡å¯¼ã€‚è¯¥æ¨¡å‹æ—¨åœ¨é€šè¿‡èµ‹èƒ½åŸºå±‚åŒ»ç–—ä¸å¥åº·ç®¡ç†ï¼Œæˆä¸ºç”¨æˆ·çš„æ™ºèƒ½å¥åº·ä¼™ä¼´ã€‚åœ¨æ€§èƒ½éªŒè¯æ–¹é¢ï¼ŒErkang-Diagnosis-1.1åœ¨ç»¼åˆåŒ»å­¦è€ƒè¯•ä¸­çš„è¡¨ç°è¶…è¿‡äº†GPT-4ï¼Œå±•ç°äº†å…¶åœ¨åŒ»ç–—å‚ç›´é¢†åŸŸçš„å“è¶Šèƒ½åŠ›ã€‚",
      "categories": [
        "cs.AI"
      ],
      "primary_category": "cs.AI",
      "comment": "9 pages; 4 figures",
      "pdf_url": "https://arxiv.org/pdf/2512.20632v1",
      "published_date": "2025-12-01 03:09:53 UTC",
      "updated_date": "2025-12-01 03:09:53 UTC",
      "processing_status": "completed",
      "attempts": 1,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "llm_backup_calls": 0,
      "last_update": "2026-01-26T12:40:30.434870+00:00"
    },
    {
      "arxiv_id": "2512.01223v1",
      "title": "S$^2$-MLLM: Boosting Spatial Reasoning Capability of MLLMs for 3D Visual Grounding with Structural Guidance",
      "title_zh": "S$^2$-MLLMï¼šé€šè¿‡ç»“æ„åŒ–å¼•å¯¼å¢å¼ºå¤šæ¨¡æ€å¤§è¯­è¨€æ¨¡å‹çš„ 3D è§†è§‰å®šä½ç©ºé—´æ¨ç†èƒ½åŠ›",
      "authors": [
        "Beining Xu",
        "Siting Zhu",
        "Zhao Jin",
        "Junxian Li",
        "Hesheng Wang"
      ],
      "abstract": "3D Visual Grounding (3DVG) focuses on locating objects in 3D scenes based on natural language descriptions, serving as a fundamental task for embodied AI and robotics. Recent advances in Multi-modal Large Language Models (MLLMs) have motivated research into extending them to 3DVG. However, MLLMs primarily process 2D visual inputs and struggle with understanding 3D spatial structure of scenes solely from these limited perspectives. Existing methods mainly utilize viewpoint-dependent rendering of reconstructed point clouds to provide explicit structural guidance for MLLMs in 3DVG tasks, leading to inefficiency and limited spatial reasoning. To address this issue, we propose S$^2$-MLLM, an efficient framework that enhances spatial reasoning in MLLMs through implicit spatial reasoning. We introduce a spatial guidance strategy that leverages the structure awareness of feed-forward 3D reconstruction. By acquiring 3D structural understanding during training, our model can implicitly reason about 3D scenes without relying on inefficient point cloud reconstruction. Moreover, we propose a structure-enhanced module (SE), which first employs intra-view and inter-view attention mechanisms to capture dependencies within views and correspondences across views. The module further integrates multi-level position encoding to associate visual representations with spatial positions and viewpoint information, enabling more accurate structural understanding. Extensive experiments demonstrate that S$^2$-MLLM unifies superior performance, generalization, and efficiency, achieving significant performance over existing methods across the ScanRefer, Nr3D, and Sr3D datasets. Code will be available upon acceptance.",
      "tldr_zh": "è¯¥ç ”ç©¶é’ˆå¯¹3Dè§†è§‰å®šä½(3D Visual Grounding)ä¸­å¤šæ¨¡æ€å¤§è¯­è¨€æ¨¡å‹(MLLMs)éš¾ä»¥é€šè¿‡æœ‰é™çš„2Dè§†è§’ç†è§£3Dç©ºé—´ç»“æ„çš„é—®é¢˜ï¼Œæå‡ºäº†é«˜æ•ˆçš„S$^2$-MLLMæ¡†æ¶ã€‚ä¸ºäº†å…‹æœç°æœ‰æ–¹æ³•ä¾èµ–æ˜¾å¼ç‚¹äº‘é‡å»º(point cloud reconstruction)å¯¼è‡´çš„æ•ˆç‡ä½ä¸‹ï¼Œè¯¥æ¡†æ¶å¼•å…¥äº†ä¸€ç§åˆ©ç”¨å‰å‘3Dé‡å»º(feed-forward 3D reconstruction)ç»“æ„æ„ŸçŸ¥èƒ½åŠ›çš„éšå¼ç©ºé—´æ¨ç†ç­–ç•¥ã€‚æ¨¡å‹é€šè¿‡åœ¨è®­ç»ƒé˜¶æ®µè·å–3Dç»“æ„ç†è§£èƒ½åŠ›ï¼Œå®ç°äº†æ— éœ€ä¾èµ–ç‚¹äº‘é‡å»ºçš„éšå¼ç©ºé—´æ¨ç†ã€‚æ­¤å¤–ï¼Œç ”ç©¶æå‡ºäº†ç»“æ„å¢å¼ºæ¨¡å—(Structure-enhanced module)ï¼Œé€šè¿‡è§†å›¾å†…ä¸è§†å›¾é—´çš„æ³¨æ„åŠ›æœºåˆ¶(attention mechanisms)ä»¥åŠå¤šå±‚çº§ä½ç½®ç¼–ç ï¼Œå°†è§†è§‰ç‰¹å¾ä¸ç©ºé—´ä½ç½®åŠè§†ç‚¹ä¿¡æ¯ç²¾å‡†å…³è”ã€‚å®éªŒç»“æœè¡¨æ˜ï¼ŒS$^2$-MLLMåœ¨ScanReferã€Nr3Då’ŒSr3Dæ•°æ®é›†ä¸Šå‡æ˜¾è‘—ä¼˜äºç°æœ‰æ–¹æ³•ã€‚è¯¥æ¡†æ¶åœ¨å®ç°é«˜æ€§èƒ½çš„åŒæ—¶ï¼Œæœ‰æ•ˆç»Ÿä¸€äº†æ¨¡å‹çš„æ³›åŒ–èƒ½åŠ›ä¸è¿è¡Œæ•ˆç‡ã€‚",
      "categories": [
        "cs.CV",
        "cs.AI"
      ],
      "primary_category": "cs.CV",
      "comment": "18 pages, 9 figures",
      "pdf_url": "https://arxiv.org/pdf/2512.01223v1",
      "published_date": "2025-12-01 03:08:34 UTC",
      "updated_date": "2025-12-01 03:08:34 UTC",
      "processing_status": "completed",
      "attempts": 1,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "llm_backup_calls": 0,
      "last_update": "2026-01-26T12:40:39.238868+00:00"
    },
    {
      "arxiv_id": "2512.01222v2",
      "title": "Unsupervised decoding of encoded reasoning using language model interpretability",
      "title_zh": "åˆ©ç”¨è¯­è¨€æ¨¡å‹å¯è§£é‡Šæ€§å¯¹ç¼–ç åŒ–æ¨ç†è¿›è¡Œæ— ç›‘ç£è§£ç ",
      "authors": [
        "Ching Fang",
        "Samuel Marks"
      ],
      "abstract": "As large language models become increasingly capable, there is growing concern that they may develop reasoning processes that are encoded or hidden from human oversight. To investigate whether current interpretability techniques can penetrate such encoded reasoning, we construct a controlled testbed by fine-tuning a reasoning model (DeepSeek-R1-Distill-Llama-70B) to perform chain-of-thought reasoning in ROT-13 encryption while maintaining intelligible English outputs. We evaluate mechanistic interpretability methods--in particular, logit lens analysis--on their ability to decode the model's hidden reasoning process using only internal activations. We show that logit lens can effectively translate encoded reasoning, with accuracy peaking in intermediate-to-late layers. Finally, we develop a fully unsupervised decoding pipeline that combines logit lens with automated paraphrasing, achieving substantial accuracy in reconstructing complete reasoning transcripts from internal model representations. These findings suggest that current mechanistic interpretability techniques may be more robust to simple forms of encoded reasoning than previously understood. Our work provides an initial framework for evaluating interpretability methods against models that reason in non-human-readable formats, contributing to the broader challenge of maintaining oversight over increasingly capable AI systems.",
      "tldr_zh": "è¯¥ç ”ç©¶æ¢è®¨äº†èƒ½å¦åˆ©ç”¨å¯è§£é‡Šæ€§æŠ€æœ¯è§£ç å¤§è¯­è¨€æ¨¡å‹ä¸­éšè—æˆ–åŠ å¯†çš„æ¨ç†è¿‡ç¨‹ï¼Œæ—¨åœ¨è§£å†³æ¨¡å‹æ¨ç†å¯èƒ½é¿å¼€äººç±»ç›‘ç®¡çš„é—®é¢˜ã€‚ç ”ç©¶å›¢é˜Ÿé€šè¿‡å¾®è°ƒ DeepSeek-R1-Distill-Llama-70B æ„å»ºäº†å—æ§å®éªŒç¯å¢ƒï¼Œä½¿æ¨¡å‹åœ¨å†…éƒ¨ä»¥ ROT-13 æ–¹å¼è¿›è¡Œ Chain-of-Thought æ¨ç†ï¼ŒåŒæ—¶ä¿æŒè¾“å‡ºæ­£å¸¸çš„è‹±æ–‡ç»“æœã€‚é€šè¿‡è¯„ä¼°æœºæ¢°å¯è§£é‡Šæ€§ (mechanistic interpretability) æ–¹æ³•ï¼Œç ”ç©¶å‘ç° Logit Lens åˆ†æèƒ½æœ‰æ•ˆåˆ©ç”¨å†…éƒ¨æ¿€æ´»å€¼è§£ç éšè—æ¨ç†ï¼Œä¸”å‡†ç¡®ç‡åœ¨æ¨¡å‹çš„ä¸­åæœŸå±‚è¾¾åˆ°å³°å€¼ã€‚åŸºäºæ­¤ï¼Œç ”ç©¶è¿›ä¸€æ­¥å¼€å‘äº†ä¸€ç§ç»“åˆ Logit Lens ä¸è‡ªåŠ¨æ”¹å†™ (automated paraphrasing) çš„å…¨æ— ç›‘ç£è§£ç æµæ°´çº¿ï¼Œèƒ½å¤Ÿé«˜å‡†ç¡®åº¦åœ°ä»å†…éƒ¨è¡¨ç¤ºä¸­é‡æ„å®Œæ•´çš„æ¨ç†è¿‡ç¨‹ã€‚è¿™äº›å‘ç°è¡¨æ˜å½“å‰å¯è§£é‡Šæ€§æŠ€æœ¯å¯¹äºç®€å•çš„ç¼–ç æ¨ç†å…·æœ‰æ¯”é¢„æœŸæ›´å¼ºçš„é²æ£’æ€§ï¼Œä¸ºè¯„ä¼°éäººç±»å¯è¯»æ ¼å¼ä¸‹çš„æ¨¡å‹æ¨ç†ç›‘ç®¡æä¾›äº†åˆæ­¥æ¡†æ¶ã€‚",
      "categories": [
        "cs.AI"
      ],
      "primary_category": "cs.AI",
      "comment": "Modifying author contact information",
      "pdf_url": "https://arxiv.org/pdf/2512.01222v2",
      "published_date": "2025-12-01 03:05:20 UTC",
      "updated_date": "2025-12-06 00:36:45 UTC",
      "processing_status": "completed",
      "attempts": 1,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "llm_backup_calls": 0,
      "last_update": "2026-01-26T12:40:41.237814+00:00"
    },
    {
      "arxiv_id": "2512.01219v1",
      "title": "Neural Network Optimal Power Flow via Energy Gradient Flow and Unified Dynamics",
      "title_zh": "åŸºäºèƒ½é‡æ¢¯åº¦æµä¸ç»Ÿä¸€åŠ¨åŠ›å­¦çš„ç¥ç»ç½‘ç»œæœ€ä¼˜æ½®æµæ–¹æ³•",
      "authors": [
        "Xuezhi Liu"
      ],
      "abstract": "Optimal Power Flow (OPF) is a core optimization problem in power system operation and planning, aiming to minimize generation costs while satisfying physical constraints such as power flow equations, generator limits, and voltage limits. Traditional OPF solving methods typically employ iterative optimization algorithms (such as interior point methods, sequential quadratic programming, etc.), with limitations including low computational efficiency, initial value sensitivity, and low batch computation efficiency. Most existing deep learning-based OPF methods rely on supervised learning, requiring pre-solving large numbers of cases, and have difficulty guaranteeing physical consistency. This paper proposes an Optimal Power Flow solving method based on neural network dynamics and energy gradient flow, transforming OPF problems into energy minimization problems. By constructing an energy function to measure the degree of deviation from the constraint manifold, and guiding networks to learn optimal solutions that simultaneously satisfy power flow constraints and minimize costs through gradient flow. Neural networks are trained unsupervised by directly minimizing physical residuals, requiring no labeled data, achieving true \"end-to-end\" physics-constrained learning.",
      "tldr_zh": "è¯¥ç ”ç©¶é’ˆå¯¹ä¼ ç»Ÿæœ€ä¼˜æ½®æµ (Optimal Power Flow, OPF) æ±‚è§£æ–¹æ³•è®¡ç®—æ•ˆç‡ä½ã€åˆå€¼æ•æ„Ÿä»¥åŠæ·±åº¦å­¦ä¹ æ–¹æ³•ä¾èµ–æ ‡æ³¨æ•°æ®ä¸”éš¾ä»¥ä¿è¯ç‰©ç†ä¸€è‡´æ€§çš„é—®é¢˜ï¼Œæå‡ºäº†ä¸€ç§åŸºäºç¥ç»ç½‘ç»œåŠ¨åŠ›å­¦å’Œèƒ½é‡æ¢¯åº¦æµ (Energy Gradient Flow) çš„æ±‚è§£æ–¹æ³•ã€‚è¯¥æ–¹æ³•å°† OPF é—®é¢˜è½¬åŒ–ä¸ºèƒ½é‡æœ€å°åŒ–é—®é¢˜ï¼Œé€šè¿‡æ„å»ºèƒ½é‡å‡½æ•°æ¥è¡¡é‡è§£ä¸çº¦æŸæµå½¢çš„åç¦»ç¨‹åº¦ï¼Œå¹¶åˆ©ç”¨æ¢¯åº¦æµå¼•å¯¼ç¥ç»ç½‘ç»œå­¦ä¹ åŒæ—¶æ»¡è¶³æ½®æµçº¦æŸå’Œæˆæœ¬æœ€å°åŒ–çš„æœ€ä¼˜è§£ã€‚é€šè¿‡ç›´æ¥æœ€å°åŒ–ç‰©ç†æ®‹å·®ï¼Œè¯¥æ¨¡å‹å®ç°äº†æ— ç›‘ç£è®­ç»ƒï¼Œæ— éœ€é¢„å…ˆæ±‚è§£å¤§é‡æ ‡è®°æ•°æ®å³å¯å®ç°çœŸæ­£çš„ç«¯åˆ°ç«¯ç‰©ç†çº¦æŸå­¦ä¹ ã€‚è¿™ä¸€æ–¹æ¡ˆæœ‰æ•ˆè§£å†³äº†æ·±åº¦å­¦ä¹ åœ¨ç”µåŠ›ç³»ç»Ÿåº”ç”¨ä¸­ç‰©ç†ä¸€è‡´æ€§éš¾ä»¥ä¿éšœçš„æŒ‘æˆ˜ï¼Œä¸ºé«˜æ•ˆã€å¯é çš„ç”µåŠ›ç³»ç»Ÿè¿è¡Œå’Œè§„åˆ’æä¾›äº†æ–°çš„æŠ€æœ¯è·¯å¾„ã€‚",
      "categories": [
        "cs.LG",
        "cs.AI"
      ],
      "primary_category": "cs.LG",
      "comment": "",
      "pdf_url": "https://arxiv.org/pdf/2512.01219v1",
      "published_date": "2025-12-01 02:59:47 UTC",
      "updated_date": "2025-12-01 02:59:47 UTC",
      "processing_status": "completed",
      "attempts": 1,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "llm_backup_calls": 0,
      "last_update": "2026-01-26T12:39:39.843919+00:00"
    },
    {
      "arxiv_id": "2512.01218v1",
      "title": "How do trout regulate patterns of muscle contraction to optimize propulsive efficiency during steady swimming",
      "title_zh": "é³Ÿé±¼åœ¨å®šå¸¸æ¸¸æ³³ä¸­å¦‚ä½•è°ƒèŠ‚è‚Œè‚‰æ”¶ç¼©æ¨¡å¼ä»¥ä¼˜åŒ–æ¨è¿›æ•ˆç‡",
      "authors": [
        "Tao Li",
        "Chunze Zhang",
        "Weiwei Yao",
        "Junzhao He",
        "Ji Hou",
        "Qin Zhou",
        "Lu Zhang"
      ],
      "abstract": "Understanding efficient fish locomotion offers insights for biomechanics, fluid dynamics, and engineering. Traditional studies often miss the link between neuromuscular control and whole-body movement. To explore energy transfer in carangiform swimming, we created a bio-inspired digital trout. This model combined multibody dynamics, Hill-type muscle modeling, and a high-fidelity fluid-structure interaction algorithm, accurately replicating a real trout's form and properties. Using deep reinforcement learning, the trout's neural system achieved hierarchical spatiotemporal control of muscle activation. We systematically examined how activation strategies affect speed and energy use. Results show that axial myomere coupling-with activation spanning over 0.5 body lengths-is crucial for stable body wave propagation. Moderate muscle contraction duration ([0.1,0.3] of a tail-beat cycle) lets the body and fluid act as a passive damping system, cutting energy use. Additionally, the activation phase lag of myomeres shapes the body wave; if too large, it causes antagonistic contractions that hinder thrust. These findings advance bio-inspired locomotion understanding and aid energy-efficient underwater system design.",
      "tldr_zh": "è¯¥ç ”ç©¶é€šè¿‡æ„å»ºä¸€ä¸ªé›†æˆäº†å¤šä½“åŠ¨åŠ›å­¦(multibody dynamics)ã€Hill-type muscle modelingå’Œé«˜ä¿çœŸæµå›ºè€¦åˆç®—æ³•(fluid-structure interaction algorithm)çš„ä»¿ç”Ÿæ•°å­—é³Ÿé±¼(trout)æ¨¡å‹ï¼Œæ¢è®¨äº†é±¼ç±»åœ¨ç¨³æ€æ¸¸æ³³ä¸­ä¼˜åŒ–æ¨è¿›æ•ˆç‡çš„è‚Œè‚‰æ”¶ç¼©è°ƒèŠ‚æœºåˆ¶ã€‚ç ”ç©¶åˆ©ç”¨æ·±åº¦å¼ºåŒ–å­¦ä¹ (deep reinforcement learning)å®ç°äº†è‚Œè‚‰æ¿€æ´»çš„å±‚æ¬¡åŒ–æ—¶ç©ºæ§åˆ¶ï¼Œå¹¶ç³»ç»Ÿåˆ†æäº†æ¿€æ´»ç­–ç•¥å¯¹æ¸¸æ³³é€Ÿåº¦å’Œèƒ½é‡æ¶ˆè€—çš„å…·ä½“å½±å“ã€‚å®éªŒç»“æœè¡¨æ˜ï¼Œè·¨è¶Š0.5ä¸ªä½“é•¿ä»¥ä¸Šçš„è½´å‘è‚ŒèŠ‚è€¦åˆ(axial myomere coupling)å¯¹äºç¨³å®šä½“æ³¢(body wave)çš„ä¼ æ’­è‡³å…³é‡è¦ã€‚åŒæ—¶ï¼Œé€‚åº¦çš„è‚Œè‚‰æ”¶ç¼©æŒç»­æ—¶é—´ï¼ˆå°¾é³æ‘†åŠ¨å‘¨æœŸçš„0.1è‡³0.3ä¹‹é—´ï¼‰èƒ½è®©èº«ä½“ä¸æµä½“å½¢æˆè¢«åŠ¨é˜»å°¼ç³»ç»Ÿä»¥æ˜¾è‘—é™ä½èƒ½è€—ã€‚æ­¤å¤–ï¼Œè‚ŒèŠ‚çš„æ¿€æ´»ç›¸ä½æ»å(activation phase lag)å†³å®šäº†ä½“æ³¢çš„å½¢çŠ¶ï¼Œè‹¥ç›¸ä½æ»åè¿‡å¤§åˆ™ä¼šè¯±å‘å¯¹æŠ—æ€§æ”¶ç¼©å¹¶é˜»ç¢æ¨åŠ›äº§ç”Ÿã€‚è¿™äº›å‘ç°ä¸ä»…æ·±åŒ–äº†å¯¹ç”Ÿç‰©å¯å‘è¿åŠ¨çš„ç†è§£ï¼Œä¹Ÿä¸ºå¼€å‘é«˜èƒ½æ•ˆæ°´ä¸‹æœºå™¨äººç³»ç»Ÿæä¾›äº†é‡è¦çš„è®¾è®¡ä¾æ®ã€‚",
      "categories": [
        "physics.flu-dyn",
        "cs.AI",
        "cs.RO"
      ],
      "primary_category": "physics.flu-dyn",
      "comment": "",
      "pdf_url": "https://arxiv.org/pdf/2512.01218v1",
      "published_date": "2025-12-01 02:57:02 UTC",
      "updated_date": "2025-12-01 02:57:02 UTC",
      "processing_status": "completed",
      "attempts": 1,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "llm_backup_calls": 0,
      "last_update": "2026-01-26T12:40:52.936162+00:00"
    },
    {
      "arxiv_id": "2512.01214v1",
      "title": "M4-BLIP: Advancing Multi-Modal Media Manipulation Detection through Face-Enhanced Local Analysis",
      "title_zh": "M4-BLIPï¼šåŸºäºäººè„¸å¢å¼ºå±€éƒ¨åˆ†æçš„å¤šæ¨¡æ€åª’ä½“ç¯¡æ”¹æ£€æµ‹",
      "authors": [
        "Hang Wu",
        "Ke Sun",
        "Jiayi Ji",
        "Xiaoshuai Sun",
        "Rongrong Ji"
      ],
      "abstract": "In the contemporary digital landscape, multi-modal media manipulation has emerged as a significant societal threat, impacting the reliability and integrity of information dissemination. Current detection methodologies in this domain often overlook the crucial aspect of localized information, despite the fact that manipulations frequently occur in specific areas, particularly in facial regions. In response to this critical observation, we propose the M4-BLIP framework. This innovative framework utilizes the BLIP-2 model, renowned for its ability to extract local features, as the cornerstone for feature extraction. Complementing this, we incorporate local facial information as prior knowledge. A specially designed alignment and fusion module within M4-BLIP meticulously integrates these local and global features, creating a harmonious blend that enhances detection accuracy. Furthermore, our approach seamlessly integrates with Large Language Models (LLM), significantly improving the interpretability of the detection outcomes. Extensive quantitative and visualization experiments validate the effectiveness of our framework against the state-of-the-art competitors.",
      "tldr_zh": "è¯¥ç ”ç©¶é’ˆå¯¹å¤šæ¨¡æ€åª’ä½“ç¯¡æ”¹(Multi-modal media manipulation)æ£€æµ‹ä¸­å¾€å¾€å¿½è§†å±€éƒ¨ä¿¡æ¯çš„é—®é¢˜ï¼Œæå‡ºäº†M4-BLIPæ¡†æ¶ã€‚é’ˆå¯¹ç¯¡æ”¹å¤šå‘ç”Ÿäºäººè„¸åŒºåŸŸ(facial regions)çš„ç‰¹æ€§ï¼Œè¯¥æ¡†æ¶é‡‡ç”¨BLIP-2æ¨¡å‹ä½œä¸ºç‰¹å¾æå–çš„æ ¸å¿ƒï¼Œå¹¶å°†å±€éƒ¨äººè„¸ä¿¡æ¯ä½œä¸ºå…ˆéªŒçŸ¥è¯†(prior knowledge)å¼•å…¥ã€‚é€šè¿‡ä¸“é—¨è®¾è®¡çš„å¯¹é½ä¸èåˆæ¨¡å—(alignment and fusion module)ï¼ŒM4-BLIPå®ç°äº†å±€éƒ¨ç‰¹å¾ä¸å…¨å±€ç‰¹å¾çš„æ·±åº¦æ•´åˆï¼Œæå¤§å¢å¼ºäº†è¯†åˆ«ç²¾åº¦ã€‚åŒæ—¶ï¼Œè¯¥æ–¹æ¡ˆæ— ç¼é›†æˆäº†å¤§è¯­è¨€æ¨¡å‹(Large Language Models)ï¼Œæ˜¾è‘—æå‡äº†æ£€æµ‹ç»“æœçš„å¯è§£é‡Šæ€§ã€‚å®éªŒç»“æœå’Œå¯è§†åŒ–åˆ†æè¡¨æ˜ï¼Œè¯¥æ¡†æ¶åœ¨åº”å¯¹å¤æ‚åª’ä½“ç¯¡æ”¹æŒ‘æˆ˜æ—¶ä¼˜äºç°æœ‰çš„å…ˆè¿›æ¨¡å‹ã€‚",
      "categories": [
        "cs.CV",
        "cs.AI"
      ],
      "primary_category": "cs.CV",
      "comment": "12 pages, 6 figures",
      "pdf_url": "https://arxiv.org/pdf/2512.01214v1",
      "published_date": "2025-12-01 02:54:03 UTC",
      "updated_date": "2025-12-01 02:54:03 UTC",
      "processing_status": "completed",
      "attempts": 1,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "llm_backup_calls": 0,
      "last_update": "2026-01-26T12:41:00.441930+00:00"
    },
    {
      "arxiv_id": "2512.01210v2",
      "title": "Knowledge Graph Augmented Large Language Models for Disease Prediction",
      "title_zh": "çŸ¥è¯†å›¾è°±å¢å¼ºçš„å¤§è¯­è¨€æ¨¡å‹ç–¾ç—…é¢„æµ‹",
      "authors": [
        "Ruiyu Wang",
        "Tuan Vinh",
        "Ran Xu",
        "Yuyin Zhou",
        "Jiaying Lu",
        "Carl Yang",
        "Francisco Pasquel"
      ],
      "abstract": "Electronic health records (EHRs) support powerful clinical prediction models, but existing methods typically provide coarse, post hoc explanations that offer limited value for patient-level decision making. We introduce a knowledge graph (KG)-guided chain-of-thought (CoT) framework that generates clinically grounded and temporally consistent reasoning for visit-level disease prediction in MIMIC-III. ICD-9 codes are mapped to PrimeKG, from which disease-relevant nodes and multi-hop reasoning paths are extracted and used as scaffolds for CoT generation; only explanations whose conclusions match observed outcomes are retained. Lightweight LLaMA-3.1-Instruct-8B and Gemma-7B models are then fine-tuned on this supervision corpus. Across ten PrimeKG-mapped diseases and limited training cohorts (400 and 1000 cases), KG-guided models outperform strong classical baselines, achieving AUROC values of 0.66 to 0.70 and macro-AUPR values of 0.40 to 0.47. The models also transfer zero-shot to the CRADLE cohort, improving accuracy from approximately 0.40 to 0.51 up to 0.72 to 0.77. A blinded clinician evaluation shows consistent preference for KG-guided CoT explanations in clarity, relevance, and clinical correctness.",
      "tldr_zh": "è¯¥ç ”ç©¶æå‡ºäº†ä¸€ç§çŸ¥è¯†å›¾è°±(Knowledge Graph, KG)å¼•å¯¼çš„é“¾å¼æ€ç»´(Chain-of-Thought, CoT)æ¡†æ¶ï¼Œæ—¨åœ¨è§£å†³ç”µå­å¥åº·è®°å½•(EHR)ä¸´åºŠé¢„æµ‹æ¨¡å‹ä¸­è§£é‡Šæ€§ä¸è¶³çš„é—®é¢˜ã€‚é€šè¿‡å°†ICD-9ä»£ç æ˜ å°„è‡³PrimeKGï¼Œè¯¥æ¡†æ¶æå–ç–¾ç—…ç›¸å…³èŠ‚ç‚¹å’Œå¤šè·³æ¨ç†è·¯å¾„ä½œä¸ºCoTç”Ÿæˆçš„è„šæ‰‹æ¶ï¼Œå¹¶åœ¨MIMIC-IIIæ•°æ®é›†ä¸Šå¯¹LLaMA-3.1-Instruct-8Bå’ŒGemma-7Bæ¨¡å‹è¿›è¡Œäº†å¾®è°ƒã€‚å®éªŒç»“æœè¡¨æ˜ï¼Œè¯¥æ¨¡å‹åœ¨æœ‰é™è®­ç»ƒæ ·æœ¬ä¸‹è¡¨ç°ä¼˜äºä¼ ç»ŸåŸºçº¿ï¼ŒAUROCè¾¾åˆ°0.66è‡³0.70ï¼Œå¹¶å±•ç°äº†å‡ºè‰²çš„é›¶æ ·æœ¬(zero-shot)è¿ç§»èƒ½åŠ›ï¼Œåœ¨CRADLEé˜Ÿåˆ—ä¸­å°†å‡†ç¡®ç‡æ˜¾è‘—æå‡ã€‚ç›²æµ‹ä¸´åºŠè¯„ä¼°æ˜¾ç¤ºï¼ŒåŒ»ç”Ÿåœ¨æ¸…æ™°åº¦ã€ç›¸å…³æ€§å’Œä¸´åºŠæ­£ç¡®æ€§æ–¹é¢ä¸€è‡´æ›´åå¥½KGå¼•å¯¼çš„CoTè§£é‡Šï¼Œè¯æ˜äº†è¯¥æ–¹æ³•åœ¨æä¾›ä¸´åºŠä¾æ®å’Œæ—¶é—´ä¸€è‡´æ€§æ¨ç†æ–¹é¢çš„æœ‰æ•ˆæ€§ã€‚",
      "categories": [
        "cs.AI"
      ],
      "primary_category": "cs.AI",
      "comment": "",
      "pdf_url": "https://arxiv.org/pdf/2512.01210v2",
      "published_date": "2025-12-01 02:49:17 UTC",
      "updated_date": "2025-12-02 21:43:54 UTC",
      "processing_status": "completed",
      "attempts": 1,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "llm_backup_calls": 0,
      "last_update": "2026-01-26T12:40:59.745887+00:00"
    },
    {
      "arxiv_id": "2512.01208v2",
      "title": "Language as a Wave Phenomenon: Iso-Energetic Phase-Locking and Semantic Interference in Neural Networks",
      "title_zh": "è¯­è¨€çš„æ³¢åŠ¨ç‰¹æ€§ï¼šç¥ç»ç½‘ç»œä¸­çš„ç­‰èƒ½é”ç›¸ä¸è¯­ä¹‰å¹²æ¶‰",
      "authors": [
        "Alper YÄ±ldÄ±rÄ±m",
        "Ä°brahim YÃ¼cedaÄŸ"
      ],
      "abstract": "Conventional deep learning paradigms rely on metabolically expensive magnitude-based representations, rendering them fundamentally incompatible with passive photonic hardware. We introduce PRISM, a sequence modeling architecture that bridges high-level reasoning and physical constraints by enforcing an Iso-Energetic (Unity Gain) principle, compelling the network to encode semantic information exclusively in the phase angle. Validated on the WMT14 translation benchmark, PRISM achieves a 0.799 COMET score, demonstrating that phase-based reasoning competes with standard Transformers (0.821) and functionally matches unconstrained spectral baselines like FNet (0.805), despite enforcing strict energy constraints and requiring 11.5% fewer parameters. Furthermore, to verify hardware feasibility, we simulate a Holographic Backpropagation mechanism on a noisy, 4-bit optical correlator. Ablation studies reveal a substantial performance gain (48.4% vs. 62.4%) over a frozen baseline, proving that the proposed phase-steering mechanism actively optimizes physical parameters under strict energy constraints. These results establish an existence proof that ultra-low-power, passive optical hardware can support high-level linguistic intelligence without sacrificing representational capacity.",
      "tldr_zh": "è¯¥ç ”ç©¶æå‡ºäº†PRISMï¼Œä¸€ç§é€šè¿‡å¼ºåˆ¶ç­‰èƒ½é‡ï¼ˆIso-Energetic/Unity Gainï¼‰åŸåˆ™å°†é«˜çº§æ¨ç†ä¸ç‰©ç†çº¦æŸç›¸ç»“åˆçš„åºåˆ—å»ºæ¨¡æ¶æ„ã€‚é’ˆå¯¹ä¼ ç»Ÿæ·±åº¦å­¦ä¹ ä¾èµ–é«˜èƒ½è€—å¹…åº¦è¡¨ç¤ºçš„é—®é¢˜ï¼ŒPRISMå°†è¯­ä¹‰ä¿¡æ¯å®Œå…¨ç¼–ç åœ¨ç›¸ä½è§’ä¸­ï¼Œä½¿å…¶åœ¨ç‰©ç†ä¸Šèƒ½ä¸æ— æºå…‰å­ç¡¬ä»¶ï¼ˆpassive photonic hardwareï¼‰å…¼å®¹ã€‚åœ¨WMT14ç¿»è¯‘åŸºå‡†æµ‹è¯•ä¸­ï¼ŒPRISMå–å¾—äº†0.799çš„COMETåˆ†æ•°ï¼Œåœ¨å‚æ•°å‡å°‘11.5%çš„æƒ…å†µä¸‹ï¼Œå…¶ç›¸ä½æ¨ç†èƒ½åŠ›å¯ä¸æ ‡å‡†Transformerå’ŒFNetæ¨¡å‹ç«äº‰ã€‚é€šè¿‡åœ¨å¸¦å™ªå£°çš„4ä½å…‰å­¦ç›¸å…³å™¨ï¼ˆoptical correlatorï¼‰ä¸Šæ¨¡æ‹Ÿå…¨æ¯åå‘ä¼ æ’­ï¼ˆHolographic Backpropagationï¼‰æœºåˆ¶ï¼Œæ¶ˆèå®éªŒè¯æ˜è¯¥ç›¸ä½æ§åˆ¶æœºåˆ¶èƒ½åœ¨ä¸¥è‹›èƒ½é‡çº¦æŸä¸‹ä¸»åŠ¨ä¼˜åŒ–ç‰©ç†å‚æ•°ã€‚è¯¥ç ”ç©¶ä¸ºè¶…ä½åŠŸè€—æ— æºå…‰å­¦ç¡¬ä»¶æ”¯æŒé«˜çº§è¯­è¨€æ™ºèƒ½æä¾›äº†å­˜åœ¨æ€§è¯æ˜ï¼Œä¸”æ— éœ€ç‰ºç‰²è¡¨å¾èƒ½åŠ›ã€‚",
      "categories": [
        "cs.LG",
        "cs.AI",
        "cs.CL"
      ],
      "primary_category": "cs.LG",
      "comment": "Major Revision. Title changed to reflect the new theoretical framework. Complete narrative shift from \"Optimization Efficiency\" to \"Iso-Energetic Phase Coding\" and \"Optical Hardware Compatibility\". Replaced ISMR diagnostics with Holographic Optical Learning simulations and mechanistic \"Dual-Regime\" phase analysis. Comparison with spectral baselines (FNet) added",
      "pdf_url": "https://arxiv.org/pdf/2512.01208v2",
      "published_date": "2025-12-01 02:46:15 UTC",
      "updated_date": "2026-01-05 17:26:51 UTC",
      "processing_status": "completed",
      "attempts": 1,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "llm_backup_calls": 0,
      "last_update": "2026-01-26T12:41:17.542191+00:00"
    },
    {
      "arxiv_id": "2512.01207v1",
      "title": "Physics-Constrained Neural Dynamics: A Unified Manifold Framework for Large-Scale Power Flow Computation",
      "title_zh": "ç‰©ç†çº¦æŸç¥ç»åŠ¨åŠ›å­¦ï¼šé¢å‘å¤§è§„æ¨¡æ½®æµè®¡ç®—çš„ç»Ÿä¸€æµå½¢æ¡†æ¶",
      "authors": [
        "Xuezhi Liu"
      ],
      "abstract": "Power flow analysis is a fundamental tool for power system analysis, planning, and operational control. Traditional Newton-Raphson methods suffer from limitations such as initial value sensitivity and low efficiency in batch computation, while existing deep learning-based power flow solvers mostly rely on supervised learning, requiring pre-solving of numerous cases and struggling to guarantee physical consistency. This paper proposes a neural physics power flow solving method based on manifold geometry and gradient flow, by describing the power flow equations as a constraint manifold, and constructing an energy function \\(V(\\mathbf{x}) = \\frac{1}{2}\\|\\mathbf{F}(\\mathbf{x})\\|^2\\) and gradient flow \\(\\frac{d\\mathbf{x}}{dt} = -\\nabla V(\\mathbf{x})\\), transforming power flow solving into an equilibrium point finding problem for dynamical systems. Neural networks are trained in an unsupervised manner by directly minimizing physical residuals, requiring no labeled data, achieving true \"end-to-end\" physics-constrained learning.",
      "tldr_zh": "è¯¥ç ”ç©¶æå‡ºäº†ä¸€ç§åŸºäºæµå½¢å‡ ä½•(manifold geometry)å’Œæ¢¯åº¦æµ(gradient flow)çš„ç¥ç»ç‰©ç†ç”µåŠ›æµæ±‚è§£æ–¹æ³•ï¼Œæ—¨åœ¨è§£å†³ä¼ ç»ŸNewton-Raphsonæ–¹æ³•å¯¹åˆå€¼æ•æ„Ÿä»¥åŠç°æœ‰æ·±åº¦å­¦ä¹ æ¨¡å‹è¿‡åº¦ä¾èµ–æ ‡è®°æ•°æ®çš„é—®é¢˜ã€‚è¯¥æ¡†æ¶å°†ç”µåŠ›æµæ–¹ç¨‹æè¿°ä¸ºçº¦æŸæµå½¢(constraint manifold)ï¼Œé€šè¿‡æ„å»ºç‰¹å®šçš„èƒ½é‡å‡½æ•°(energy function)å¹¶å°†ç”µåŠ›æµæ±‚è§£è½¬åŒ–ä¸ºåŠ¨åŠ›å­¦ç³»ç»Ÿçš„å¹³è¡¡ç‚¹å¯»æ‰¾é—®é¢˜ã€‚æ ¸å¿ƒåˆ›æ–°åœ¨äºé‡‡ç”¨æ— ç›‘ç£å­¦ä¹ (unsupervised learning)æ¨¡å¼ï¼Œé€šè¿‡ç›´æ¥æœ€å°åŒ–ç‰©ç†æ®‹å·®(physical residuals)æ¥è®­ç»ƒç¥ç»ç½‘ç»œï¼Œå®ç°äº†æ— éœ€æ ‡ç­¾æ•°æ®çš„ç«¯åˆ°ç«¯(end-to-end)ç‰©ç†çº¦æŸå­¦ä¹ ã€‚è¿™ç§ç»Ÿä¸€çš„æµå½¢æ¡†æ¶æœ‰æ•ˆä¿è¯äº†è®¡ç®—çš„ç‰©ç†ä¸€è‡´æ€§(physical consistency)ï¼Œä¸ºå¤§è§„æ¨¡ç”µåŠ›ç³»ç»Ÿçš„åˆ†æã€è§„åˆ’ä¸å®æ—¶è¿è¡Œæ§åˆ¶æä¾›äº†é«˜æ•ˆä¸”é²æ£’çš„è§£å†³æ–¹æ¡ˆã€‚",
      "categories": [
        "eess.SY",
        "cs.AI"
      ],
      "primary_category": "eess.SY",
      "comment": "",
      "pdf_url": "https://arxiv.org/pdf/2512.01207v1",
      "published_date": "2025-12-01 02:45:23 UTC",
      "updated_date": "2025-12-01 02:45:23 UTC",
      "processing_status": "completed",
      "attempts": 1,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "llm_backup_calls": 0,
      "last_update": "2026-01-26T12:41:05.242678+00:00"
    },
    {
      "arxiv_id": "2512.01189v1",
      "title": "fMRI2GES: Co-speech Gesture Reconstruction from fMRI Signal with Dual Brain Decoding Alignment",
      "title_zh": "fMRI2GESï¼šåŸºäºåŒè„‘è§£ç å¯¹é½çš„ fMRI ä¿¡å·ä¼´éšè¨€è¯­æ‰‹åŠ¿é‡å»º",
      "authors": [
        "Chunzheng Zhu",
        "Jialin Shao",
        "Jianxin Lin",
        "Yijun Wang",
        "Jing Wang",
        "Jinhui Tang",
        "Kenli Li"
      ],
      "abstract": "Understanding how the brain responds to external stimuli and decoding this process has been a significant challenge in neuroscience. While previous studies typically concentrated on brain-to-image and brain-to-language reconstruction, our work strives to reconstruct gestures associated with speech stimuli perceived by brain. Unfortunately, the lack of paired \\{brain, speech, gesture\\} data hinders the deployment of deep learning models for this purpose. In this paper, we introduce a novel approach, \\textbf{fMRI2GES}, that allows training of fMRI-to-gesture reconstruction networks on unpaired data using \\textbf{Dual Brain Decoding Alignment}. This method relies on two key components: (i) observed texts that elicit brain responses, and (ii) textual descriptions associated with the gestures. Then, instead of training models in a completely supervised manner to find a mapping relationship among the three modalities, we harness an fMRI-to-text model, a text-to-gesture model with paired data and an fMRI-to-gesture model with unpaired data, establishing dual fMRI-to-gesture reconstruction patterns. Afterward, we explicitly align two outputs and train our model in a self-supervision way. We show that our proposed method can reconstruct expressive gestures directly from fMRI recordings. We also investigate fMRI signals from different ROIs in the cortex and how they affect generation results. Overall, we provide new insights into decoding co-speech gestures, thereby advancing our understanding of neuroscience and cognitive science.",
      "tldr_zh": "è¯¥ç ”ç©¶æå‡ºäº†fMRI2GESæ¡†æ¶ï¼Œæ—¨åœ¨è§£å†³ä»fMRIä¿¡å·ä¸­é‡å»ºä¼´éšè¯­è¨€çš„æ‰‹åŠ¿(co-speech gesture)è¿™ä¸€å…·æœ‰æŒ‘æˆ˜æ€§çš„ä»»åŠ¡ï¼Œå¡«è¡¥äº†ä»¥å¾€ç ”ç©¶ä¸»è¦é›†ä¸­åœ¨å¤§è„‘è‡³å›¾åƒæˆ–è¯­è¨€é‡å»ºçš„ç©ºç™½ã€‚é’ˆå¯¹{brain, speech, gesture}ä¸‰æ¨¡æ€æˆå¯¹æ•°æ®åŒ®ä¹çš„é—®é¢˜ï¼Œç ”ç©¶å¼•å…¥äº†åŒè„‘è§£ç å¯¹é½(Dual Brain Decoding Alignment)æ–¹æ³•ï¼Œå…è®¸åœ¨éæˆå¯¹æ•°æ®ä¸Šè®­ç»ƒé‡å»ºç½‘ç»œã€‚è¯¥æ¡†æ¶é€šè¿‡æ•´åˆfMRI-to-textå’Œtext-to-gestureæ¨¡å‹å»ºç«‹åŒé‡é‡å»ºè·¯å¾„ï¼Œå¹¶åˆ©ç”¨è‡ªç›‘ç£(self-supervision)æœºåˆ¶æ˜¾å¼å¯¹é½è¾“å‡ºã€‚å®éªŒç»“æœè¡¨æ˜ï¼Œè¯¥æ–¹æ³•èƒ½å¤Ÿç›´æ¥ä»fMRIè®°å½•ä¸­é‡å»ºå‡ºå…·æœ‰è¡¨ç°åŠ›çš„æ‰‹åŠ¿ï¼Œç ”ç©¶è¿˜æ·±å…¥æ¢è®¨äº†å¤§è„‘çš®å±‚ä¸åŒæ„Ÿå…´è¶£åŒºåŸŸ(ROIs)å¯¹ç”Ÿæˆæ•ˆæœçš„å…·ä½“å½±å“ã€‚è¯¥é¡¹å·¥ä½œä¸ºè§£ç ä¼´éšè¯­è¨€æ‰‹åŠ¿æä¾›äº†æ–°çš„è§è§£ï¼Œæ˜¾è‘—æ¨åŠ¨äº†ç¥ç»ç§‘å­¦ä¸è®¤çŸ¥ç§‘å­¦é¢†åŸŸçš„å‘å±•ã€‚",
      "categories": [
        "cs.AI",
        "cs.LG"
      ],
      "primary_category": "cs.AI",
      "comment": "IEEE Transactions on Circuits and Systems for Video Technology (TCSVT) 2025",
      "pdf_url": "https://arxiv.org/pdf/2512.01189v1",
      "published_date": "2025-12-01 02:09:44 UTC",
      "updated_date": "2025-12-01 02:09:44 UTC",
      "processing_status": "completed",
      "attempts": 1,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "llm_backup_calls": 0,
      "last_update": "2026-01-26T12:41:28.234995+00:00"
    },
    {
      "arxiv_id": "2512.01188v1",
      "title": "Real-World Reinforcement Learning of Active Perception Behaviors",
      "title_zh": "çœŸå®ä¸–ç•Œä¸­çš„ä¸»åŠ¨æ„ŸçŸ¥è¡Œä¸ºå¼ºåŒ–å­¦ä¹ ",
      "authors": [
        "Edward S. Hu",
        "Jie Wang",
        "Xingfang Yuan",
        "Fiona Luo",
        "Muyao Li",
        "Gaspard Lambrechts",
        "Oleh Rybkin",
        "Dinesh Jayaraman"
      ],
      "abstract": "A robot's instantaneous sensory observations do not always reveal task-relevant state information. Under such partial observability, optimal behavior typically involves explicitly acting to gain the missing information. Today's standard robot learning techniques struggle to produce such active perception behaviors. We propose a simple real-world robot learning recipe to efficiently train active perception policies. Our approach, asymmetric advantage weighted regression (AAWR), exploits access to \"privileged\" extra sensors at training time. The privileged sensors enable training high-quality privileged value functions that aid in estimating the advantage of the target policy. Bootstrapping from a small number of potentially suboptimal demonstrations and an easy-to-obtain coarse policy initialization, AAWR quickly acquires active perception behaviors and boosts task performance. In evaluations on 8 manipulation tasks on 3 robots spanning varying degrees of partial observability, AAWR synthesizes reliable active perception behaviors that outperform all prior approaches. When initialized with a \"generalist\" robot policy that struggles with active perception tasks, AAWR efficiently generates information-gathering behaviors that allow it to operate under severe partial observability for manipulation tasks. Website: https://penn-pal-lab.github.io/aawr/",
      "tldr_zh": "è¯¥ç ”ç©¶é’ˆå¯¹æœºå™¨äººä¼ æ„Ÿå™¨è§‚æµ‹ä¸å®Œæ•´å¯¼è‡´çš„Partial Observabilityé—®é¢˜ï¼Œæå‡ºäº†ä¸€ç§ç®€å•ä¸”é«˜æ•ˆçš„çœŸå®ä¸–ç•Œæœºå™¨äººå­¦ä¹ æ–¹æ¡ˆã€‚ä½œè€…å¼•å…¥äº†Asymmetric Advantage Weighted Regression (AAWR) ç®—æ³•ï¼Œè¯¥ç®—æ³•åœ¨è®­ç»ƒé˜¶æ®µåˆ©ç”¨Privileged Sensorsï¼ˆç‰¹æƒä¼ æ„Ÿå™¨ï¼‰æ¥æ„å»ºé«˜è´¨é‡çš„Value Functionsï¼Œä»è€Œè¾…åŠ©ä¼°è®¡Target Policyçš„Advantageã€‚é€šè¿‡ä»å°‘é‡æ¬¡ä¼˜æ¼”ç¤ºå’Œåˆå§‹ç­–ç•¥ä¸­è¿›è¡Œè‡ªä¸¾(Bootstrapping)ï¼ŒAAWRèƒ½å¿«é€Ÿä¹ å¾—Active Perceptionï¼ˆä¸»åŠ¨æ„ŸçŸ¥ï¼‰è¡Œä¸ºå¹¶æ˜¾è‘—æå‡ä»»åŠ¡æ€§èƒ½ã€‚åœ¨æ¶‰åŠ3ç§æœºå™¨äººå’Œ8é¡¹æ“çºµä»»åŠ¡çš„è¯„ä¼°ä¸­ï¼ŒAAWRæˆåŠŸåˆæˆäº†å¯é çš„ä¸»åŠ¨æ„ŸçŸ¥è¡Œä¸ºï¼Œè¡¨ç°ä¼˜äºæ‰€æœ‰ç°æœ‰æ–¹æ³•ã€‚å³ä½¿åœ¨é¢ä¸´ä¸¥é‡Partial Observabilityçš„å¤æ‚ç¯å¢ƒä¸‹ï¼Œè¯¥æ–¹æ³•ä¹Ÿèƒ½æœ‰æ•ˆç”Ÿæˆä¿¡æ¯é‡‡é›†è¡Œä¸ºï¼Œä½¿é€šç”¨ç­–ç•¥èƒ½å¤Ÿå¯é åœ°æ‰§è¡Œå…·æœ‰æŒ‘æˆ˜æ€§çš„æ“çºµä»»åŠ¡ã€‚",
      "categories": [
        "cs.RO",
        "cs.AI",
        "cs.LG"
      ],
      "primary_category": "cs.RO",
      "comment": "NeurIPS 2025 camera ready",
      "pdf_url": "https://arxiv.org/pdf/2512.01188v1",
      "published_date": "2025-12-01 02:05:20 UTC",
      "updated_date": "2025-12-01 02:05:20 UTC",
      "processing_status": "completed",
      "attempts": 1,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "llm_backup_calls": 0,
      "last_update": "2026-01-26T12:41:12.150152+00:00"
    },
    {
      "arxiv_id": "2512.01187v1",
      "title": "Teaching by Failure: Counter-Example-Driven Curricula for Transformer Self-Improvement",
      "title_zh": "è´¥ä¸­æ±‚å­¦ï¼šé¢å‘ Transformer è‡ªæˆ‘æå‡çš„åä¾‹é©±åŠ¨è¯¾ç¨‹å­¦ä¹ ",
      "authors": [
        "Harshil Vejendla"
      ],
      "abstract": "Transformer models often exhibit brittle extrapolation, failing on inputs that are longer or structurally more complex than those seen during training. We introduce Counter-Example-Driven Curricula (CEDC), an automated framework that improves model robustness by iteratively focusing on its own failures. At each step, CEDC uses the current model to generate a diverse set of candidate problems, employs a fast, executable verifier to identify incorrect predictions (counter-examples), and then fine-tunes the model on a dataset enriched with these discovered failures. We evaluate CEDC on a suite of algorithmic and natural language tasks, including integer addition, sorting, Dyck-2 language recognition, and three text classification benchmarks. Compared to static training and standard curriculum learning baselines, CEDC achieves up to 30x greater length extrapolation, is 3.75x more computationally efficient than uniform data augmentation, and requires no manual difficulty heuristics. We provide a detailed analysis of the counter-examples, showing how the curriculum naturally adapts to target progressively more complex error modes. Our findings establish verifier-guided, failure-driven learning as a simple, powerful, and efficient paradigm for enhancing the generalization capabilities of Transformer models.",
      "tldr_zh": "è¯¥ç ”ç©¶æå‡ºäº†åä¾‹é©±åŠ¨è¯¾ç¨‹ (Counter-Example-Driven Curricula, CEDC)ï¼Œæ—¨åœ¨é€šè¿‡è¿­ä»£åœ°å…³æ³¨æ¨¡å‹è‡ªèº«çš„å¤±è´¥æ¥æå‡ Transformer æ¨¡å‹çš„é²æ£’æ€§ã€‚é’ˆå¯¹æ¨¡å‹åœ¨å¤„ç†é•¿åºåˆ—æˆ–å¤æ‚ç»“æ„è¾“å…¥æ—¶è¡¨ç°å‡ºçš„è„†æ€§å¤–æ¨ (brittle extrapolation) é—®é¢˜ï¼ŒCEDC è‡ªåŠ¨åŒ–æ¡†æ¶é€šè¿‡ç”Ÿæˆå€™é€‰é—®é¢˜å¹¶åˆ©ç”¨å¯æ‰§è¡ŒéªŒè¯å™¨ (verifier) ç²¾å‡†è¯†åˆ«é”™è¯¯é¢„æµ‹ï¼ˆå³åä¾‹ï¼‰ã€‚é€šè¿‡åœ¨å¯Œå«è¿™äº›å¤±è´¥æ¡ˆä¾‹çš„æ•°æ®é›†ä¸ŠæŒç»­å¾®è°ƒï¼Œæ¨¡å‹èƒ½å¤Ÿè‡ªç„¶åœ°é€‚åº”å¹¶è§£å†³é€æ¸å¤æ‚çš„é”™è¯¯æ¨¡å¼ã€‚åœ¨åŠ æ³•ã€æ’åºã€Dyck-2 è¯­è¨€è¯†åˆ«åŠæ–‡æœ¬åˆ†ç±»ä»»åŠ¡ä¸­ï¼ŒCEDC å®ç°äº†æ¯”åŸºçº¿æ¨¡å‹é«˜è¾¾ 30 å€çš„é•¿åº¦å¤–æ¨ (length extrapolation) èƒ½åŠ›ï¼Œä¸”è®¡ç®—æ•ˆç‡æ¯”å‡åŒ€æ•°æ®å¢å¼º (uniform data augmentation) é«˜å‡º 3.75 å€ã€‚ç ”ç©¶ç»“æœè¡¨æ˜ï¼Œè¿™ç§éªŒè¯å™¨å¼•å¯¼ã€å¤±è´¥é©±åŠ¨çš„å­¦ä¹ æ¨¡å¼ä¸ºå¢å¼º Transformer çš„æ³›åŒ–èƒ½åŠ›æä¾›äº†ä¸€ç§ç®€å•ã€é«˜æ•ˆä¸”æ— éœ€äººå·¥å¯å‘å¼è§„åˆ™çš„æ–°èŒƒå¼ã€‚",
      "categories": [
        "cs.LG",
        "cs.AI"
      ],
      "primary_category": "cs.LG",
      "comment": "AACL 2025 Findings",
      "pdf_url": "https://arxiv.org/pdf/2512.01187v1",
      "published_date": "2025-12-01 02:00:41 UTC",
      "updated_date": "2025-12-01 02:00:41 UTC",
      "processing_status": "completed",
      "attempts": 1,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "llm_backup_calls": 0,
      "last_update": "2026-01-26T12:41:19.135038+00:00"
    },
    {
      "arxiv_id": "2512.01183v1",
      "title": "TempPerturb-Eval: On the Joint Effects of Internal Temperature and External Perturbations in RAG Robustness",
      "title_zh": "TempPerturb-Evalï¼šæ¢ç©¶å†…éƒ¨æ¸©åº¦ä¸å¤–éƒ¨æ‰°åŠ¨å¯¹ RAG é²æ£’æ€§çš„è”åˆæ•ˆåº”",
      "authors": [
        "Yongxin Zhou",
        "Philippe Mulhem",
        "Didier Schwab"
      ],
      "abstract": "The evaluation of Retrieval-Augmented Generation (RAG) systems typically examines retrieval quality and generation parameters like temperature in isolation, overlooking their interaction. This work presents a systematic investigation of how text perturbations (simulating noisy retrieval) interact with temperature settings across multiple LLM runs. We propose a comprehensive RAG Perturbation-Temperature Analysis Framework that subjects retrieved documents to three distinct perturbation types across varying temperature settings. Through extensive experiments on HotpotQA with both open-source and proprietary LLMs, we demonstrate that performance degradation follows distinct patterns: high-temperature settings consistently amplify vulnerability to perturbations, while certain perturbation types exhibit non-linear sensitivity across the temperature range. Our work yields three key contributions: (1) a diagnostic benchmark for assessing RAG robustness, (2) an analytical framework for quantifying perturbation-temperature interactions, and (3) practical guidelines for model selection and parameter tuning under noisy retrieval conditions.",
      "tldr_zh": "è¯¥ç ”ç©¶æ¢è®¨äº†æ£€ç´¢å¢å¼ºç”Ÿæˆ(RAG)ç³»ç»Ÿä¸­å†…éƒ¨æ¸©åº¦(Temperature)ä¸å¤–éƒ¨æ‰°åŠ¨(External Perturbations)å¯¹ç³»ç»Ÿé²æ£’æ€§çš„å…±åŒå½±å“ï¼Œå¡«è¡¥äº†ä»¥å¾€è¯„ä¼°å¾€å¾€å­¤ç«‹çœ‹å¾…æ£€ç´¢è´¨é‡ä¸ç”Ÿæˆå‚æ•°çš„ç©ºç™½ã€‚ä¸ºæ­¤ï¼Œä½œè€…æå‡ºäº†TempPerturb-Evalåˆ†ææ¡†æ¶ï¼Œé€šè¿‡åœ¨ä¸åŒæ¸©åº¦è®¾ç½®ä¸‹å¯¹æ£€ç´¢æ–‡æ¡£æ–½åŠ ä¸‰ç§ç‰¹å®šçš„æ–‡æœ¬æ‰°åŠ¨ï¼Œç³»ç»Ÿåœ°æ¨¡æ‹Ÿå’Œé‡åŒ–åˆ†æä¸¤è€…çš„äº¤äº’ä½œç”¨ã€‚å®éªŒåœ¨HotpotQAæ•°æ®é›†ä¸Šé’ˆå¯¹å¤šç§å¼€æºå’Œé—­æºå¤§è¯­è¨€æ¨¡å‹(LLMs)è¿›è¡Œäº†å¤§è§„æ¨¡æµ‹è¯•ã€‚ç ”ç©¶ç»“æœè¡¨æ˜ï¼Œé«˜æ¸©åº¦è®¾ç½®ä¼šä¸€è‡´åœ°æ”¾å¤§æ¨¡å‹å¯¹å¤–éƒ¨æ‰°åŠ¨çš„è„†å¼±æ€§ï¼Œä¸”ç‰¹å®šç±»å‹çš„æ‰°åŠ¨åœ¨ä¸åŒæ¸©åº¦åŒºé—´è¡¨ç°å‡ºæ˜æ˜¾çš„éçº¿æ€§æ•æ„Ÿæ€§ã€‚è¯¥å·¥ä½œçš„ä¸»è¦è´¡çŒ®åŒ…æ‹¬å»ºç«‹äº†ä¸€ä¸ªè¯„ä¼°RAGé²æ£’æ€§çš„è¯Šæ–­åŸºå‡†ï¼Œæå‡ºäº†é‡åŒ–æ‰°åŠ¨ä¸æ¸©åº¦äº¤äº’çš„åˆ†ææ¡†æ¶ï¼Œå¹¶ä¸ºå™ªå£°æ£€ç´¢ç¯å¢ƒä¸‹çš„æ¨¡å‹é€‰æ‹©ä¸å‚æ•°å¾®è°ƒæä¾›äº†å®ç”¨çš„æŒ‡å¯¼æ–¹é’ˆã€‚",
      "categories": [
        "cs.CL",
        "cs.AI"
      ],
      "primary_category": "cs.CL",
      "comment": "",
      "pdf_url": "https://arxiv.org/pdf/2512.01183v1",
      "published_date": "2025-12-01 01:46:36 UTC",
      "updated_date": "2025-12-01 01:46:36 UTC",
      "processing_status": "completed",
      "attempts": 1,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "llm_backup_calls": 0,
      "last_update": "2026-01-26T12:42:02.839239+00:00"
    },
    {
      "arxiv_id": "2512.01181v1",
      "title": "First On-Orbit Demonstration of a Geospatial Foundation Model",
      "title_zh": "åœ°ç†ç©ºé—´åŸºç¡€æ¨¡å‹é¦–æ¬¡åœ¨è½¨éªŒè¯",
      "authors": [
        "Andrew Du",
        "Roberto Del Prete",
        "Alejandro Mousist",
        "Nick Manser",
        "Fabrice Marre",
        "Andrew Barton",
        "Carl Seubert",
        "Gabriele Meoni",
        "Tat-Jun Chin"
      ],
      "abstract": "Geospatial foundation models (GeoFMs) promise broad generalisation capacity for Earth observation (EO) tasks, particularly under data-limited conditions. However, their large size poses a barrier to deployment on resource-constrained space hardware. To address this, we present compact variants of a Vision Transformer (ViT)-based GeoFM that preserve downstream task performance while enabling onboard execution. Evaluation across five downstream tasks and validation in two representative flight environments show that model compression and domain adaptation are critical to reducing size and resource demands while maintaining high performance under operational conditions. We further demonstrate reliable on-orbit inference with the IMAGIN-e payload aboard the International Space Station. These results establish a pathway from large GeoFMs to flight-ready, resource-efficient deployments, expanding the feasibility of onboard AI for EO missions.",
      "tldr_zh": "è¯¥ç ”ç©¶å®ç°äº†åœ°ç†ç©ºé—´åŸºç¡€æ¨¡å‹(Geospatial foundation models, GeoFMs)çš„é¦–æ¬¡åœ¨è½¨æ¼”ç¤ºï¼Œé‡ç‚¹è§£å†³äº†å¤§å‹æ¨¡å‹åœ¨èµ„æºå—é™çš„ç©ºé—´ç¡¬ä»¶ä¸Šéš¾ä»¥éƒ¨ç½²çš„éš¾é¢˜ã€‚ä½œè€…æå‡ºäº†åŸºäºVision Transformer(ViT)çš„ç´§å‡‘å‹GeoFMå˜ä½“ï¼Œé€šè¿‡æ¨¡å‹å‹ç¼©(model compression)å’Œé¢†åŸŸè‡ªé€‚åº”(domain adaptation)æŠ€æœ¯ï¼Œåœ¨ä¿æŒé«˜æ€§èƒ½çš„åŒæ—¶å®ç°äº†æ˜Ÿè½½ç¯å¢ƒä¸‹çš„é«˜æ•ˆè¿è¡Œã€‚é€šè¿‡å¯¹äº”é¡¹ä¸‹æ¸¸ä»»åŠ¡çš„è¯„ä¼°ä»¥åŠåœ¨ä¸¤ä¸ªä»£è¡¨æ€§é£è¡Œç¯å¢ƒä¸­çš„éªŒè¯ï¼Œè¯¥æ–¹æ¡ˆè¯æ˜äº†å…¶åœ¨é™ä½èµ„æºéœ€æ±‚å’Œç»´æŒæ“ä½œç¨³å®šæ€§æ–¹é¢çš„å…³é”®ä½œç”¨ã€‚æ­¤å¤–ï¼Œç ”ç©¶å›¢é˜Ÿåˆ©ç”¨å›½é™…ç©ºé—´ç«™(International Space Station, ISS)ä¸Šçš„IMAGIN-eè½½è·æˆåŠŸå®Œæˆäº†å¯é çš„åœ¨è½¨æ¨ç†ä»»åŠ¡ã€‚è¿™é¡¹æˆæœä¸ºä»å¤§å‹GeoFMså‘é£è¡Œå°±ç»ªã€èµ„æºé«˜æ•ˆçš„éƒ¨ç½²æä¾›äº†è·¯å¾„ï¼Œæ˜¾è‘—æå‡äº†åœ°çƒè§‚æµ‹(Earth observation, EO)ä»»åŠ¡ä¸­æ˜Ÿè½½äººå·¥æ™ºèƒ½çš„å¯è¡Œæ€§ã€‚",
      "categories": [
        "cs.LG",
        "cs.AI",
        "cs.CV"
      ],
      "primary_category": "cs.LG",
      "comment": "",
      "pdf_url": "https://arxiv.org/pdf/2512.01181v1",
      "published_date": "2025-12-01 01:43:03 UTC",
      "updated_date": "2025-12-01 01:43:03 UTC",
      "processing_status": "completed",
      "attempts": 1,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "llm_backup_calls": 0,
      "last_update": "2026-01-26T12:41:34.140745+00:00"
    },
    {
      "arxiv_id": "2512.04112v1",
      "title": "MindFuse: Towards GenAI Explainability in Marketing Strategy Co-Creation",
      "title_zh": "MindFuseï¼šè¿ˆå‘è¥é”€ç­–ç•¥å…±åˆ›ä¸­çš„ç”Ÿæˆå¼äººå·¥æ™ºèƒ½å¯è§£é‡Šæ€§",
      "authors": [
        "Aleksandr Farseev",
        "Marlo Ongpin",
        "Qi Yang",
        "Ilia Gossoudarev",
        "Yu-Yi Chu-Farseeva",
        "Sergey Nikolenko"
      ],
      "abstract": "The future of digital marketing lies in the convergence of human creativity and generative AI, where insight, strategy, and storytelling are co-authored by intelligent systems. We present MindFuse, a brave new explainable generative AI framework designed to act as a strategic partner in the marketing process. Unlike conventional LLM applications that stop at content generation, MindFuse fuses CTR-based content AI-guided co-creation with large language models to extract, interpret, and iterate on communication narratives grounded in real advertising data. MindFuse operates across the full marketing lifecycle: from distilling content pillars and customer personas from competitor campaigns to recommending in-flight optimizations based on live performance telemetry. It uses attention-based explainability to diagnose ad effectiveness and guide content iteration, while aligning messaging with strategic goals through dynamic narrative construction and storytelling. We introduce a new paradigm in GenAI for marketing, where LLMs not only generate content but reason through it, adapt campaigns in real time, and learn from audience engagement patterns. Our results, validated in agency deployments, demonstrate up to 12 times efficiency gains, setting the stage for future integration with empirical audience data (e.g., GWI, Nielsen) and full-funnel attribution modeling. MindFuse redefines AI not just as a tool, but as a collaborative agent in the creative and strategic fabric of modern marketing.",
      "tldr_zh": "è¯¥ç ”ç©¶æå‡ºäº† MindFuseï¼Œè¿™æ˜¯ä¸€ç§æ—¨åœ¨ä½œä¸ºè¥é”€æµç¨‹æˆ˜ç•¥åˆä½œä¼™ä¼´çš„å¯è§£é‡Šç”Ÿæˆå¼äººå·¥æ™ºèƒ½ (GenAI) æ¡†æ¶ã€‚ä¸ä¼ ç»Ÿçš„ä»…åœç•™åœ¨å†…å®¹ç”Ÿæˆçš„åº”ç”¨ä¸åŒï¼ŒMindFuse å°†åŸºäº CTR çš„å†…å®¹ AI å¼•å¯¼ååŒåˆ›ä½œä¸ LLMs ç›¸ç»“åˆï¼Œèƒ½å¤ŸåŸºäºçœŸå®å¹¿å‘Šæ•°æ®æå–ã€è§£é‡Šå¹¶è¿­ä»£ä¼ æ’­å™äº‹ã€‚è¯¥æ¡†æ¶æ¶µç›–äº†ä»æç‚¼ç«äº‰å¯¹æ‰‹æ´»åŠ¨çš„ content pillars å’Œ customer personas åˆ°æ ¹æ®å®æ—¶è¡¨ç°è¿›è¡Œ in-flight optimizations çš„å…¨è¥é”€ç”Ÿå‘½å‘¨æœŸã€‚é€šè¿‡åˆ©ç”¨ attention-based explainability è¯Šæ–­å¹¿å‘Šæ•ˆæœå¹¶æŒ‡å¯¼å†…å®¹è¿­ä»£ï¼ŒMindFuse å®ç°äº†ä¿¡æ¯ä¼ é€’ä¸æˆ˜ç•¥ç›®æ ‡çš„åŠ¨æ€å¯¹é½ã€‚åœ¨æœºæ„éƒ¨ç½²ä¸­çš„éªŒè¯ç»“æœæ˜¾ç¤ºï¼Œè¯¥ç³»ç»Ÿå®ç°äº†é«˜è¾¾ 12 å€çš„æ•ˆç‡æå‡ï¼Œæ ‡å¿—ç€ GenAI åœ¨è¥é”€é¢†åŸŸä»å•çº¯çš„å†…å®¹ç”Ÿæˆå‘å…·å¤‡æ¨ç†ã€å®æ—¶è‡ªé€‚åº”åŠå­¦ä¹ å—ä¼—å‚ä¸æ¨¡å¼çš„ååŒæ™ºèƒ½ä½“è½¬å˜ã€‚",
      "categories": [
        "cs.MM",
        "cs.AI"
      ],
      "primary_category": "cs.MM",
      "comment": "",
      "pdf_url": "https://arxiv.org/pdf/2512.04112v1",
      "published_date": "2025-12-01 01:41:17 UTC",
      "updated_date": "2025-12-01 01:41:17 UTC",
      "processing_status": "completed",
      "attempts": 1,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "llm_backup_calls": 0,
      "last_update": "2026-01-26T12:42:19.539251+00:00"
    },
    {
      "arxiv_id": "2512.01179v1",
      "title": "Toward a benchmark for CTR prediction in online advertising: datasets, evaluation protocols and perspectives",
      "title_zh": "è¿ˆå‘åœ¨çº¿å¹¿å‘Šç‚¹å‡»ç‡é¢„æµ‹åŸºå‡†ï¼šæ•°æ®é›†ã€è¯„ä¼°åè®®ä¸å¤šç»´è§†è§’",
      "authors": [
        "Shan Gao",
        "Yanwu Yang"
      ],
      "abstract": "This research designs a unified architecture of CTR prediction benchmark (Bench-CTR) platform that offers flexible interfaces with datasets and components of a wide range of CTR prediction models. Moreover, we construct a comprehensive system of evaluation protocols encompassing real-world and synthetic datasets, a taxonomy of metrics, standardized procedures and experimental guidelines for calibrating the performance of CTR prediction models. Furthermore, we implement the proposed benchmark platform and conduct a comparative study to evaluate a wide range of state-of-the-art models from traditional multivariate statistical to modern large language model (LLM)-based approaches on three public datasets and two synthetic datasets. Experimental results reveal that, (1) high-order models largely outperform low-order models, though such advantage varies in terms of metrics and on different datasets; (2) LLM-based models demonstrate a remarkable data efficiency, i.e., achieving the comparable performance to other models while using only 2% of the training data; (3) the performance of CTR prediction models has achieved significant improvements from 2015 to 2016, then reached a stage with slow progress, which is consistent across various datasets. This benchmark is expected to facilitate model development and evaluation and enhance practitioners' understanding of the underlying mechanisms of models in the area of CTR prediction. Code is available at https://github.com/NuriaNinja/Bench-CTR.",
      "tldr_zh": "è¯¥ç ”ç©¶è®¾è®¡äº†åä¸ºBench-CTRçš„ç‚¹å‡»ç‡é¢„æµ‹(CTR prediction)åŸºå‡†å¹³å°ï¼Œæ—¨åœ¨ä¸ºå„ç±»CTRé¢„æµ‹æ¨¡å‹æä¾›ç»Ÿä¸€çš„æ¶æ„ä»¥åŠä¸æ•°æ®é›†å’Œæ¨¡å‹ç»„ä»¶çš„çµæ´»æ¥å£ã€‚ç ”ç©¶æ„å»ºäº†ä¸€å¥—å…¨é¢çš„è¯„ä¼°åè®®ï¼Œæ¶µç›–äº†çœŸå®ä¸åˆæˆæ•°æ®é›†ã€æŒ‡æ ‡åˆ†ç±»æ³•ä»¥åŠæ ‡å‡†åŒ–çš„å®éªŒæŒ‡å—ï¼Œç”¨äºç²¾å‡†æ ¡å‡†CTRé¢„æµ‹æ¨¡å‹çš„æ€§èƒ½ã€‚é€šè¿‡å¯¹ä»ä¼ ç»Ÿå¤šå…ƒç»Ÿè®¡åˆ°å¤§è¯­è¨€æ¨¡å‹(LLM)ç­‰å¤šç§å‰æ²¿æ¨¡å‹è¿›è¡Œå¯¹æ¯”è¯„ä¼°ï¼Œå®éªŒå‘ç°é«˜é˜¶æ¨¡å‹(high-order models)åœ¨æ€§èƒ½ä¸Šæ™®éä¼˜äºä½é˜¶æ¨¡å‹ï¼Œä½†è¯¥ä¼˜åŠ¿å—å…·ä½“æ•°æ®é›†å’ŒæŒ‡æ ‡å½±å“ã€‚æ­¤å¤–ï¼ŒLLM-basedæ¨¡å‹å±•ç°å‡ºæé«˜çš„æ•°æ®æ•ˆç‡ï¼Œä»…éœ€2%çš„è®­ç»ƒæ•°æ®å³å¯è¾¾åˆ°ä¸»æµæ¨¡å‹æ°´å¹³ã€‚ç ”ç©¶è¿˜æŒ‡å‡ºCTRé¢„æµ‹æŠ€æœ¯åœ¨2015è‡³2016å¹´å–å¾—çªç ´åå·²è¿›å…¥å¢é•¿å¹³å°æœŸï¼Œè¯¥åŸºå‡†å¹³å°çš„å¼€æºå°†æœ‰åŠ›æ¨åŠ¨è¯¥é¢†åŸŸçš„æ¨¡å‹å¼€å‘ä¸æœºåˆ¶ç†è§£ã€‚",
      "categories": [
        "cs.IR",
        "cs.AI",
        "cs.LG"
      ],
      "primary_category": "cs.IR",
      "comment": "64 pages, 8 figures, 11 tables",
      "pdf_url": "https://arxiv.org/pdf/2512.01179v1",
      "published_date": "2025-12-01 01:36:55 UTC",
      "updated_date": "2025-12-01 01:36:55 UTC",
      "processing_status": "completed",
      "attempts": 1,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "llm_backup_calls": 0,
      "last_update": "2026-01-26T12:42:35.540265+00:00"
    },
    {
      "arxiv_id": "2512.01171v1",
      "title": "Conversion rate prediction in online advertising: modeling techniques, performance evaluation and future directions",
      "title_zh": "åœ¨çº¿å¹¿å‘Šè½¬åŒ–ç‡é¢„æµ‹ï¼šå»ºæ¨¡æŠ€æœ¯ã€æ€§èƒ½è¯„ä¼°ä¸æœªæ¥æ–¹å‘",
      "authors": [
        "Tao Xue",
        "Yanwu Yang",
        "Panyu Zhai"
      ],
      "abstract": "Conversion and conversion rate (CVR) prediction play a critical role in efficient advertising decision-making. In past decades, although researchers have developed plenty of models for CVR prediction, the methodological evolution and relationships between different techniques have been precluded. In this paper, we conduct a comprehensive literature review on CVR prediction in online advertising, and classify state-of-the-art CVR prediction models into six categories with respect to the underlying techniques and elaborate on connections between these techniques. For each category of models, we present the framework of underlying techniques, their advantages and disadvantages, and discuss how they are utilized for CVR prediction. Moreover, we summarize the performance of various CVR prediction models on public and proprietary datasets. Finally, we identify research trends, major challenges, and promising future directions. We observe that results of performance evaluation reported in prior studies are not unanimous; semantics-enriched, attribution-enhanced, debiased CVR prediction and jointly modeling CTR and CVR prediction would be promising directions to explore in the future. This review is expected to provide valuable references and insights for future researchers and practitioners in this area.",
      "tldr_zh": "è¿™ç¯‡è®ºæ–‡å¯¹åœ¨çº¿å¹¿å‘Šä¸­çš„è½¬åŒ–ç‡é¢„æµ‹(Conversion Rate Prediction, CVR)è¿›è¡Œäº†å…¨é¢çš„æ–‡çŒ®ç»¼è¿°ï¼Œç³»ç»Ÿåœ°æ¢³ç†äº†è¯¥é¢†åŸŸçš„å»ºæ¨¡æŠ€æœ¯ã€æ€§èƒ½è¯„ä¼°åŠæœªæ¥å‘å±•æ–¹å‘ã€‚ä½œè€…å°†ç°æœ‰çš„å‰æ²¿CVRé¢„æµ‹æ¨¡å‹æ ¹æ®åº•å±‚æŠ€æœ¯å½’çº³ä¸ºå…­å¤§ç±»ï¼Œå¹¶è¯¦ç»†é˜è¿°äº†å„ç±»æ¨¡å‹çš„æŠ€æœ¯æ¡†æ¶ã€ä¼˜ç¼ºç‚¹ä»¥åŠå®ƒä»¬ä¹‹é—´çš„å†…åœ¨è”ç³»ã€‚æ–‡ä¸­ä¸ä»…æ€»ç»“äº†å„æ¨¡å‹åœ¨å…¬å¼€å’Œç§æœ‰æ•°æ®é›†ä¸Šçš„æ€§èƒ½è¡¨ç°ï¼Œè¿˜æ·±å…¥è¯†åˆ«äº†å½“å‰ç ”ç©¶é¢ä¸´çš„ä¸»è¦æŒ‘æˆ˜ä¸æŠ€æœ¯æ¼”è¿›è·¯å¾„ã€‚è®ºæ–‡æ˜ç¡®æŒ‡å‡ºï¼Œè¯­ä¹‰å¯ŒåŒ–(Semantics-enriched)ã€å½’å› å¢å¼º(Attribution-enhanced)ã€å»å(Debiased)ä»¥åŠç‚¹å‡»ç‡(CTR)ä¸è½¬åŒ–ç‡(CVR)çš„è”åˆå»ºæ¨¡æ˜¯æå…·å‰æ™¯çš„æœªæ¥ç ”ç©¶æ–¹å‘ã€‚è¯¥é¡¹å·¥ä½œä¸ºè®¡ç®—å¹¿å‘Šé¢†åŸŸçš„ç ”ç©¶äººå‘˜å’Œä»ä¸šè€…æä¾›äº†æ·±å…¥çš„æŠ€æœ¯è§è§£ä¸ç³»ç»Ÿçš„å‚è€ƒæ¡†æ¶ã€‚",
      "categories": [
        "cs.IR",
        "cs.AI",
        "cs.LG"
      ],
      "primary_category": "cs.IR",
      "comment": "99 pages, 15 figures, 7 tables",
      "pdf_url": "https://arxiv.org/pdf/2512.01171v1",
      "published_date": "2025-12-01 01:02:35 UTC",
      "updated_date": "2025-12-01 01:02:35 UTC",
      "processing_status": "completed",
      "attempts": 1,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "llm_backup_calls": 0,
      "last_update": "2026-01-26T12:42:22.741842+00:00"
    },
    {
      "arxiv_id": "2512.01170v1",
      "title": "Data assimilation and discrepancy modeling with shallow recurrent decoders",
      "title_zh": "åŸºäºæµ…å±‚å¾ªç¯è§£ç å™¨çš„æ•°æ®åŒåŒ–ä¸å·®å¼‚å»ºæ¨¡",
      "authors": [
        "Yuxuan Bao",
        "J. Nathan Kutz"
      ],
      "abstract": "The requirements of modern sensing are rapidly evolving, driven by increasing demands for data efficiency, real-time processing, and deployment under limited sensing coverage. Complex physical systems are often characterized through the integration of a limited number of point sensors in combination with scientific computations which approximate the dominant, full-state dynamics. Simulation models, however, inevitably neglect small-scale or hidden processes, are sensitive to perturbations, or oversimplify parameter correlations, leading to reconstructions that often diverge from the reality measured by sensors. This creates a critical need for data assimilation, the process of integrating observational data with predictive simulation models to produce coherent and accurate estimates of the full state of complex physical systems. We propose a machine learning framework for Data Assimilation with a SHallow REcurrent Decoder (DA-SHRED) which bridges the simulation-to-real (SIM2REAL) gap between computational modeling and experimental sensor data. For real-world physics systems modeling high-dimensional spatiotemporal fields, where the full state cannot be directly observed and must be inferred from sparse sensor measurements, we leverage the latent space learned from a reduced simulation model via SHRED, and update these latent variables using real sensor data to accurately reconstruct the full system state. Furthermore, our algorithm incorporates a sparse identification of nonlinear dynamics based regression model in the latent space to identify functionals corresponding to missing dynamics in the simulation model. We demonstrate that DA-SHRED successfully closes the SIM2REAL gap and additionally recovers missing dynamics in highly complex systems, demonstrating that the combination of efficient temporal encoding and physics-informed correction enables robust data assimilation.",
      "tldr_zh": "è¯¥ç ”ç©¶æå‡ºäº†DA-SHREDæ¡†æ¶ï¼Œå³ä¸€ç§ç»“åˆæµ…å±‚å¾ªç¯è§£ç å™¨(SHallow REcurrent Decoder)çš„æ•°æ®åŒåŒ–(Data Assimilation)æ–¹æ³•ï¼Œæ—¨åœ¨å¼¥åˆè®¡ç®—æ¨¡æ‹Ÿä¸å®éªŒä¼ æ„Ÿå™¨æ•°æ®ä¹‹é—´çš„SIM2REALå·®è·ã€‚é’ˆå¯¹é«˜ç»´æ—¶ç©ºåœºä¸­å…¨æ€éš¾ä»¥ç›´æ¥è§‚æµ‹çš„æŒ‘æˆ˜ï¼Œè¯¥æ¡†æ¶åˆ©ç”¨ä»ç®€åŒ–æ¨¡æ‹Ÿæ¨¡å‹ä¸­å­¦ä¹ åˆ°çš„æ½œç©ºé—´(latent space)ï¼Œå¹¶é€šè¿‡ç¨€ç–ä¼ æ„Ÿå™¨æ•°æ®å®æ—¶æ›´æ–°æ½œå˜é‡ä»¥ç²¾ç¡®é‡æ„ç³»ç»ŸçŠ¶æ€ã€‚æ­¤å¤–ï¼Œè¯¥ç®—æ³•åœ¨æ½œç©ºé—´ä¸­å¼•å…¥äº†åŸºäºéçº¿æ€§åŠ¨åŠ›å­¦ç¨€ç–è¯†åˆ«(sparse identification of nonlinear dynamics)çš„å›å½’æ¨¡å‹ï¼Œç”¨äºè¯†åˆ«å¹¶è¡¥å¿æ¨¡æ‹Ÿæ¨¡å‹ä¸­ç¼ºå¤±çš„åŠ¨åŠ›å­¦åŠŸèƒ½é¡¹ã€‚å®éªŒç»“æœè¡¨æ˜ï¼ŒDA-SHREDèƒ½å¤Ÿæœ‰æ•ˆé—­åˆSIM2REALç¼ºå£å¹¶åœ¨é«˜åº¦å¤æ‚çš„ç³»ç»Ÿä¸­æ¢å¤ç¼ºå¤±åŠ¨åŠ›å­¦ã€‚è¿™è¯æ˜äº†é«˜æ•ˆçš„æ—¶é—´ç¼–ç (temporal encoding)ä¸ç‰©ç†ä¿¡æ¯ä¿®æ­£(physics-informed correction)ç›¸ç»“åˆï¼Œå¯ä»¥å®ç°é²æ£’çš„æ•°æ®åŒåŒ–ã€‚",
      "categories": [
        "cs.LG",
        "cs.AI",
        "math.AP",
        "nlin.CD"
      ],
      "primary_category": "cs.LG",
      "comment": "27 pages, 11 figures",
      "pdf_url": "https://arxiv.org/pdf/2512.01170v1",
      "published_date": "2025-12-01 01:01:48 UTC",
      "updated_date": "2025-12-01 01:01:48 UTC",
      "processing_status": "completed",
      "attempts": 1,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "llm_backup_calls": 0,
      "last_update": "2026-01-26T12:42:29.837490+00:00"
    },
    {
      "arxiv_id": "2512.01167v1",
      "title": "A TinyML Reinforcement Learning Approach for Energy-Efficient Light Control in Low-Cost Greenhouse Systems",
      "title_zh": "é¢å‘ä½æˆæœ¬æ¸©å®¤ç³»ç»Ÿçš„ TinyML å¼ºåŒ–å­¦ä¹ èŠ‚èƒ½ç…§æ˜æ§åˆ¶æ–¹æ³•",
      "authors": [
        "Mohamed Abdallah Salem",
        "Manuel Cuevas Perez",
        "Ahmed Harb Rabia"
      ],
      "abstract": "This study presents a reinforcement learning (RL)-based control strategy for adaptive lighting regulation in controlled environments using a low-power microcontroller. A model-free Q-learning algorithm was implemented to dynamically adjust the brightness of a Light-Emitting Diode (LED) based on real-time feedback from a light-dependent resistor (LDR) sensor. The system was trained to stabilize at 13 distinct light intensity levels (L1 to L13), with each target corresponding to a specific range within the 64-state space derived from LDR readings. A total of 130 trials were conducted, covering all target levels with 10 episodes each. Performance was evaluated in terms of convergence speed, steps taken, and time required to reach target states. Box plots and histograms were generated to analyze the distribution of training time and learning efficiency across targets. Experimental validation demonstrated that the agent could effectively learn to stabilize at varying light levels with minimal overshooting and smooth convergence, even in the presence of environmental perturbations. This work highlights the feasibility of lightweight, on-device RL for energy-efficient lighting control and sets the groundwork for multi-modal environmental control applications in resource-constrained agricultural systems.",
      "tldr_zh": "è¿™é¡¹ç ”ç©¶æå‡ºäº†ä¸€ç§åŸºäºå¼ºåŒ–å­¦ä¹ (Reinforcement Learning)çš„æ§åˆ¶ç­–ç•¥ï¼Œç”¨äºä½æˆæœ¬æ¸©å®¤ç³»ç»Ÿä¸­ä½åŠŸè€—å¾®æ§åˆ¶å™¨çš„è‡ªé€‚åº”ç…§æ˜è°ƒèŠ‚ã€‚è¯¥ç³»ç»Ÿé‡‡ç”¨æ— æ¨¡å‹(model-free)çš„Q-learningç®—æ³•ï¼Œæ ¹æ®å…‰æ•ç”µé˜»(LDR)ä¼ æ„Ÿå™¨çš„å®æ—¶åé¦ˆåŠ¨æ€è°ƒæ•´å‘å…‰äºŒæç®¡(LED)çš„äº®åº¦ã€‚å®éªŒé€šè¿‡130æ¬¡è¯•éªŒè®­ç»ƒæ™ºèƒ½ä½“åœ¨13ä¸ªä¸åŒçš„å…‰ç…§å¼ºåº¦çº§åˆ«ä¸Šè¾¾åˆ°ç¨³å®šï¼Œå¹¶æ ¹æ®æ”¶æ•›é€Ÿåº¦å’Œæ­¥æ•°ç­‰å¤šé¡¹æŒ‡æ ‡è¯„ä¼°äº†å­¦ä¹ æ•ˆç‡ã€‚å®éªŒéªŒè¯è¡¨æ˜ï¼Œè¯¥æ™ºèƒ½ä½“å³ä¾¿åœ¨ç¯å¢ƒå¹²æ‰°ä¸‹ä¹Ÿèƒ½å®ç°æå°çš„è¶…è°ƒ(overshooting)å’Œé¡ºæ»‘æ”¶æ•›ï¼Œæœ‰æ•ˆç¨³å®šåœ¨å„ç§å…‰ç…§æ°´å¹³ã€‚è¿™é¡¹å·¥ä½œçªæ˜¾äº†åœ¨èµ„æºå—é™çš„å†œä¸šç³»ç»Ÿä¸­ä½¿ç”¨è½»é‡çº§ã€è®¾å¤‡ç«¯(on-device) RLè¿›è¡ŒèŠ‚èƒ½ç…§æ˜æ§åˆ¶çš„å¯è¡Œæ€§ï¼Œå¹¶ä¸ºå¤šæ¨¡æ€ç¯å¢ƒæ§åˆ¶åº”ç”¨å¥ å®šäº†åŸºç¡€ã€‚",
      "categories": [
        "cs.LG",
        "cs.AI",
        "eess.SY"
      ],
      "primary_category": "cs.LG",
      "comment": "Copyright 2025 IEEE. This is the author's version of the work that has been accepted for publication in Proceedings of the 5. Interdisciplinary Conference on Electrics and Computer (INTCEC 2025) 15-16 September 2025, Chicago-USA. The final version of record is available at: https://doi.org/10.1109/INTCEC65580.2025.11256135",
      "pdf_url": "https://arxiv.org/pdf/2512.01167v1",
      "published_date": "2025-12-01 00:58:05 UTC",
      "updated_date": "2025-12-01 00:58:05 UTC",
      "processing_status": "completed",
      "attempts": 1,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "llm_backup_calls": 0,
      "last_update": "2026-01-26T12:42:26.243848+00:00"
    },
    {
      "arxiv_id": "2512.01165v1",
      "title": "Real-Time On-the-Go Annotation Framework Using YOLO for Automated Dataset Generation",
      "title_zh": "åŸºäº YOLO çš„è‡ªåŠ¨åŒ–æ•°æ®é›†ç”Ÿæˆå®æ—¶éšè¡Œæ ‡æ³¨æ¡†æ¶",
      "authors": [
        "Mohamed Abdallah Salem",
        "Ahmed Harb Rabia"
      ],
      "abstract": "Efficient and accurate annotation of datasets remains a significant challenge for deploying object detection models such as You Only Look Once (YOLO) in real-world applications, particularly in agriculture where rapid decision-making is critical. Traditional annotation techniques are labor-intensive, requiring extensive manual labeling post data collection. This paper presents a novel real-time annotation approach leveraging YOLO models deployed on edge devices, enabling immediate labeling during image capture. To comprehensively evaluate the efficiency and accuracy of our proposed system, we conducted an extensive comparative analysis using three prominent YOLO architectures (YOLOv5, YOLOv8, YOLOv12) under various configurations: single-class versus multi-class annotation and pretrained versus scratch-based training. Our analysis includes detailed statistical tests and learning dynamics, demonstrating significant advantages of pretrained and single-class configurations in terms of model convergence, performance, and robustness. Results strongly validate the feasibility and effectiveness of our real-time annotation framework, highlighting its capability to drastically reduce dataset preparation time while maintaining high annotation quality.",
      "tldr_zh": "è¯¥ç ”ç©¶é’ˆå¯¹å†œä¸šç­‰é¢†åŸŸç›®æ ‡æ£€æµ‹æ¨¡å‹æ•°æ®é›†æ ‡æ³¨è€—æ—¶ã€æ•ˆç‡ä½çš„é—®é¢˜ï¼Œæå‡ºäº†ä¸€ç§åˆ©ç”¨ YOLO æ¨¡å‹åœ¨è¾¹ç¼˜è®¾å¤‡ä¸Šå®ç°å®æ—¶éšè¡Œæ ‡æ³¨ (Real-Time On-the-Go Annotation) çš„è‡ªåŠ¨åŒ–æ¡†æ¶ã€‚è¯¥ç³»ç»Ÿæ”¯æŒåœ¨å›¾åƒé‡‡é›†çš„åŒæ—¶è¿›è¡Œå³æ—¶æ ‡æ³¨ï¼Œæœ‰æ•ˆè§£å†³äº†ä¼ ç»ŸåæœŸäººå·¥æ‰‹åŠ¨æ ‡æ³¨åŠ³åŠ¨å¼ºåº¦å¤§çš„éš¾é¢˜ã€‚ç ”ç©¶å›¢é˜Ÿåœ¨ YOLOv5ã€YOLOv8 å’Œ YOLOv12 ä¸‰ç§æ¶æ„ä¸‹ï¼Œé’ˆå¯¹å•ç±»åˆ«ä¸å¤šç±»åˆ«ã€é¢„è®­ç»ƒä¸ä»å¤´è®­ç»ƒç­‰å¤šç§å®éªŒé…ç½®è¿›è¡Œäº†å…¨é¢çš„å¯¹æ¯”åˆ†æã€‚ç»Ÿè®¡æµ‹è¯•å’Œå­¦ä¹ åŠ¨åŠ›å­¦ç»“æœè¡¨æ˜ï¼Œé¢„è®­ç»ƒæ¨¡å‹å’Œå•ç±»åˆ«é…ç½®åœ¨æ¨¡å‹æ”¶æ•›ã€æ€§èƒ½å’Œé²æ£’æ€§æ–¹é¢è¡¨ç°æ›´ä¼˜ã€‚å®éªŒç»“æœå……åˆ†éªŒè¯äº†è¯¥å®æ—¶æ ‡æ³¨æ¡†æ¶çš„å¯è¡Œæ€§ï¼Œè¯æ˜å…¶åœ¨ä¿è¯é«˜æ ‡æ³¨è´¨é‡çš„å‰æä¸‹ï¼Œèƒ½å¤Ÿå¤§å¹…ç¼©çŸ­æ•°æ®é›†å‡†å¤‡æ—¶é—´ã€‚",
      "categories": [
        "cs.CV",
        "cs.AI",
        "cs.RO"
      ],
      "primary_category": "cs.CV",
      "comment": "Copyright 2025 IEEE. This is the author's version of the work that has been accepted for publication in Proceedings of the 5. Interdisciplinary Conference on Electrics and Computer (INTCEC 2025) 15-16 September 2025, Chicago-USA. The final version of record is available at: https://doi.org/10.1109/INTCEC65580.2025.11256048",
      "pdf_url": "https://arxiv.org/pdf/2512.01165v1",
      "published_date": "2025-12-01 00:54:57 UTC",
      "updated_date": "2025-12-01 00:54:57 UTC",
      "processing_status": "completed",
      "attempts": 1,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "llm_backup_calls": 0,
      "last_update": "2026-01-26T12:42:35.735664+00:00"
    },
    {
      "arxiv_id": "2512.01163v1",
      "title": "2D-ThermAl: Physics-Informed Framework for Thermal Analysis of Circuits using Generative AI",
      "title_zh": "2D-ThermAlï¼šåŸºäºç”Ÿæˆå¼äººå·¥æ™ºèƒ½çš„ç”µè·¯çƒ­åˆ†æç‰©ç†ä¿¡æ¯é©±åŠ¨æ¡†æ¶",
      "authors": [
        "Soumyadeep Chandra",
        "Sayeed Shafayet Chowdhury",
        "Kaushik Roy"
      ],
      "abstract": "Thermal analysis is increasingly critical in modern integrated circuits, where non-uniform power dissipation and high transistor densities can cause rapid temperature spikes and reliability concerns. Traditional methods, such as FEM-based simulations offer high accuracy but computationally prohibitive for early-stage design, often requiring multiple iterative redesign cycles to resolve late-stage thermal failures. To address these challenges, we propose 'ThermAl', a physics-informed generative AI framework which effectively identifies heat sources and estimates full-chip transient and steady-state thermal distributions directly from input activity profiles. ThermAl employs a hybrid U-Net architecture enhanced with positional encoding and a Boltzmann regularizer to maintain physical fidelity. Our model is trained on an extensive dataset of heat dissipation maps, ranging from simple logic gates (e.g., inverters, NAND, XOR) to complex designs, generated via COMSOL. Experimental results demonstrate that ThermAl delivers precise temperature mappings for large circuits, with a root mean squared error (RMSE) of only 0.71Â°C, and outperforms conventional FEM tools by running up to ~200 times faster. We analyze performance across diverse layouts and workloads, and discuss its applicability to large-scale EDA workflows. While thermal reliability assessments often extend beyond 85Â°C for post-layout signoff, our focus here is on early-stage hotspot detection and thermal pattern learning. To ensure generalization beyond the nominal operating range 25-55Â°C, we additionally performed cross-validation on an extended dataset spanning 25-95Â°C maintaining a high accuracy (<2.2% full-scale RMSE) even under elevated temperature conditions representative of peak power and stress scenarios.",
      "tldr_zh": "è¯¥ç ”ç©¶æå‡ºäº†2D-ThermAlï¼Œè¿™æ˜¯ä¸€ç§èåˆç‰©ç†ä¿¡æ¯çš„ç”Ÿæˆå¼äººå·¥æ™ºèƒ½(Generative AI)æ¡†æ¶ï¼Œæ—¨åœ¨è§£å†³ç°ä»£é›†æˆç”µè·¯åœ¨è®¾è®¡æ—©æœŸé˜¶æ®µè¿›è¡Œçƒ­åˆ†ææ—¶é¢ä¸´çš„ä¼ ç»Ÿæœ‰é™å…ƒåˆ†æ(FEM)æ–¹æ³•è®¡ç®—æˆæœ¬è¿‡é«˜çš„é—®é¢˜ã€‚è¯¥æ¡†æ¶é‡‡ç”¨å¢å¼ºäº†ä½ç½®ç¼–ç (Positional Encoding)å’Œç»å°”å…¹æ›¼æ­£åˆ™åŒ–é¡¹(Boltzmann Regularizer)çš„æ··åˆU-Netæ¶æ„ï¼Œèƒ½å¤Ÿç›´æ¥æ ¹æ®è¾“å…¥æ´»åŠ¨æ¦‚å†µå‡†ç¡®è¯„ä¼°å…¨èŠ¯ç‰‡çš„ç¬æ€å’Œç¨³æ€çƒ­åˆ†å¸ƒã€‚é€šè¿‡åœ¨COMSOLç”Ÿæˆçš„æ¶µç›–ç®€å•é€»è¾‘é—¨åˆ°å¤æ‚ç”µè·¯çš„å¹¿æ³›æ•°æ®é›†ä¸Šè¿›è¡Œè®­ç»ƒï¼Œ2D-ThermAlåœ¨ä¿æŒç‰©ç†ä¿çœŸåº¦çš„åŒæ—¶ï¼Œå®ç°äº†ä»…0.71Â°Cçš„å‡æ–¹æ ¹è¯¯å·®(RMSE)ã€‚å®éªŒç»“æœæ˜¾ç¤ºï¼Œå…¶è¿è¡Œé€Ÿåº¦æ¯”ä¼ ç»ŸFEMå·¥å…·å¿«çº¦200å€ï¼Œæ˜¾è‘—æå‡äº†çƒ­åˆ†ææ•ˆç‡ã€‚æ­¤å¤–ï¼Œè¯¥æ¨¡å‹åœ¨25-95Â°Cçš„é«˜æ¸©å‹åŠ›åœºæ™¯ä¸‹å±•ç°å‡ºè‰¯å¥½çš„æ³›åŒ–èƒ½åŠ›å’Œæé«˜çš„é¢„æµ‹ç²¾åº¦ã€‚è¯¥ç ”ç©¶ä¸ºå¤§è§„æ¨¡ç”µå­è®¾è®¡è‡ªåŠ¨åŒ–(EDA)å·¥ä½œæµç¨‹ä¸­çš„æ—©æœŸçƒ­ç‚¹æ£€æµ‹æä¾›äº†é«˜æ•ˆçš„è§£å†³æ–¹æ¡ˆï¼Œæœ‰åŠ©äºåœ¨è®¾è®¡åˆæœŸè§„é¿åæœŸçƒ­å¤±æ•ˆé£é™©ã€‚",
      "categories": [
        "cs.LG",
        "cs.AI"
      ],
      "primary_category": "cs.LG",
      "comment": "10 pages, 8 figures, Under Review",
      "pdf_url": "https://arxiv.org/pdf/2512.01163v1",
      "published_date": "2025-12-01 00:45:26 UTC",
      "updated_date": "2025-12-01 00:45:26 UTC",
      "processing_status": "completed",
      "attempts": 1,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "llm_backup_calls": 0,
      "last_update": "2026-01-26T12:42:36.636576+00:00"
    },
    {
      "arxiv_id": "2512.08965v1",
      "title": "Financial Instruction Following Evaluation (FIFE)",
      "title_zh": "FIFEï¼šé‡‘èæŒ‡ä»¤éµå¾ªè¯„ä¼°",
      "authors": [
        "Glenn Matlin",
        "Siddharth",
        "Anirudh JM",
        "Aditya Shukla",
        "Yahya Hassan",
        "Sudheer Chava"
      ],
      "abstract": "Language Models (LMs) struggle with complex, interdependent instructions, particularly in high-stakes domains like finance where precision is critical. We introduce FIFE, a novel, high-difficulty benchmark designed to assess LM instruction-following capabilities for financial analysis tasks. FIFE comprises 88 human-authored prompts and employs a verification system with chainable, verifiable constraints for fine-grained reward signals. We evaluate 53 models (proprietary, open-weight, open-source) in a zero-shot setting. Our key findings reveal a clear performance hierarchy: the top open-weight model (76.1 strict / 79.5 loose) surpasses the leading proprietary system (65.9 strict / 70.5 loose), while the best open-source models lag significantly (45.5 strict / 48.9 loose). However, even top-performing models struggle with FIFE's complex requirements, failing to achieve perfect compliance. We release our dataset and code as an open-source resource to promote research in Reinforcement Learning for the financial domain.",
      "tldr_zh": "è¯¥ç ”ç©¶æå‡ºäº†Financial Instruction Following Evaluation (FIFE)ï¼Œä¸€ä¸ªæ—¨åœ¨è¯„ä¼°è¯­è¨€æ¨¡å‹(LMs)åœ¨é‡‘èåˆ†æä»»åŠ¡ä¸­å¤„ç†å¤æ‚ä¸”ç›¸äº’ä¾èµ–æŒ‡ä»¤èƒ½åŠ›çš„é«˜éš¾åº¦åŸºå‡†æµ‹è¯•ã€‚FIFEåŒ…å«88ä¸ªç”±äººå·¥ç¼–å†™çš„æç¤ºè¯ï¼Œå¹¶é‡‡ç”¨äº†ä¸€å¥—å…·æœ‰å¯é“¾æ¥å’Œå¯éªŒè¯çº¦æŸçš„éªŒè¯ç³»ç»Ÿï¼Œç”¨ä»¥æä¾›ç»†ç²’åº¦çš„å¥–åŠ±ä¿¡å·ã€‚ç ”ç©¶è€…åœ¨é›¶æ ·æœ¬(zero-shot)è®¾ç½®ä¸‹å¯¹åŒ…æ‹¬å•†ä¸šã€å¼€æ”¾æƒé‡åŠå¼€æºåœ¨å†…çš„53ä¸ªæ¨¡å‹è¿›è¡Œäº†è¯„ä¼°ã€‚ç»“æœæ­ç¤ºäº†æ˜æ˜¾çš„æ€§èƒ½å±‚çº§ï¼Œå…¶ä¸­é¡¶å°–çš„å¼€æ”¾æƒé‡æ¨¡å‹åœ¨ä¸¥è‹›(strict)ä¸å®½æ¾(loose)æ ‡å‡†ä¸‹çš„è¡¨ç°å‡ä¼˜äºé¢†å…ˆçš„å•†ä¸šæ¨¡å‹ï¼Œè€Œå¼€æºæ¨¡å‹è¡¨ç°åˆ™æ˜¾è‘—æ»åã€‚ç ”ç©¶è¿˜å‘ç°ï¼Œå³ä½¿æ˜¯è¡¨ç°æœ€å¥½çš„æ¨¡å‹ä¹Ÿéš¾ä»¥åœ¨FIFEçš„å¤æ‚è¦æ±‚ä¸‹è¾¾åˆ°å®Œç¾åˆè§„ï¼Œè¿™å‡¸æ˜¾äº†è¯¥é¢†åŸŸçš„æŒ‘æˆ˜æ€§ã€‚è¯¥é¡¹ç›®å·²å¼€æºå…¶æ•°æ®é›†å’Œä»£ç ï¼Œä»¥æœŸä¿ƒè¿›é‡‘èé¢†åŸŸå¼ºåŒ–å­¦ä¹ (Reinforcement Learning)çš„ç›¸å…³ç ”ç©¶ã€‚",
      "categories": [
        "cs.LG",
        "cs.AI",
        "cs.CL"
      ],
      "primary_category": "cs.LG",
      "comment": "Accepted at NeurIPS 2025 Generative AI in Finance Workshop (GenAI Finance), San Diego. Camera-ready version. Code and data: https://github.com/gtfintechlab/FIFE/",
      "pdf_url": "https://arxiv.org/pdf/2512.08965v1",
      "published_date": "2025-12-01 00:39:19 UTC",
      "updated_date": "2025-12-01 00:39:19 UTC",
      "processing_status": "completed",
      "attempts": 1,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "llm_backup_calls": 0,
      "last_update": "2026-01-26T12:42:38.540221+00:00"
    },
    {
      "arxiv_id": "2512.01155v2",
      "title": "Beyond Greenfield: The D3 Framework for AI-Driven Productivity in Brownfield Engineering",
      "title_zh": "è¶…è¶Šâ€œç»¿åœ°â€ï¼šæ£•åœ°å·¥ç¨‹ä¸­ AI é©±åŠ¨ç”Ÿäº§åŠ›æå‡çš„ D3 æ¡†æ¶",
      "authors": [
        "Krishna Kumaar Sharma"
      ],
      "abstract": "Brownfield engineering work involving legacy systems, incomplete documentation, and fragmented architectural knowledge poses unique challenges for the effective use of large language models (LLMs). Prior research has largely focused on greenfield or synthetic tasks, leaving a gap in structured workflows for complex, context-heavy environments. This paper introduces the Discover-Define-Deliver (D3) Framework, a disciplined LLM-assisted workflow that combines role-separated prompting strategies with applied best practices for navigating ambiguity in brownfield systems. The framework incorporates a dual-agent prompting architecture in which a Builder model generates candidate outputs and a Reviewer model provides structured critique to improve reliability. I conducted an exploratory survey study with 52 software practitioners who applied the D3 workflow to real-world engineering tasks such as legacy system exploration, documentation reconstruction, and architectural refactoring. Respondents reported perceived improvements in task clarity, documentation quality, and cognitive load, along with self-estimated productivity gains. In this exploratory study, participants reported a weighted average productivity improvement of 26.9%, reduced cognitive load for approximately 77% of participants, and 83% of participants spent less time fixing or rewriting code due to better initial planning with AI. As these findings are self-reported and not derived from controlled experiments, they should be interpreted as preliminary evidence of practitioner sentiment rather than causal effects. The results highlight both the potential and limitations of structured LLM workflows for legacy engineering systems and motivate future controlled evaluations.",
      "tldr_zh": "é’ˆå¯¹æ£•åœ°å·¥ç¨‹(Brownfield Engineering)ä¸­é—ç•™ç³»ç»Ÿã€æ–‡æ¡£ä¸å…¨åŠæ¶æ„çŸ¥è¯†ç¢ç‰‡åŒ–å¯¼è‡´çš„LLMsåº”ç”¨éš¾é¢˜ï¼Œè¯¥ç ”ç©¶æå‡ºäº†D3 (Discover-Define-Deliver)æ¡†æ¶ã€‚è¿™æ˜¯ä¸€ç§æ—¨åœ¨å¤„ç†å¤æ‚ã€é«˜ä¸Šä¸‹æ–‡ç¯å¢ƒçš„LLMè¾…åŠ©å·¥ä½œæµï¼Œé€šè¿‡ç»“åˆè§’è‰²åˆ†ç¦»æç¤ºç­–ç•¥(role-separated prompting strategies)æ¥åº”å¯¹ç³»ç»Ÿä¸­çš„æ¨¡ç³Šæ€§ã€‚è¯¥æ¡†æ¶é‡‡ç”¨äº†åŒæ™ºèƒ½ä½“æç¤ºæ¶æ„(dual-agent prompting architecture)ï¼Œç”±Builderæ¨¡å‹ç”Ÿæˆå€™é€‰è¾“å‡ºï¼Œå¹¶ç”±Revieweræ¨¡å‹æä¾›ç»“æ„åŒ–æ‰¹åˆ¤ä»¥å¢å¼ºå¯é æ€§ã€‚é’ˆå¯¹52åè½¯ä»¶ä»ä¸šè€…çš„è°ƒæŸ¥æ˜¾ç¤ºï¼Œåœ¨åº”ç”¨è¯¥æ¡†æ¶è¿›è¡Œé—ç•™ç³»ç»Ÿæ¢ç´¢ã€æ–‡æ¡£é‡æ„å’Œæ¶æ„é‡æ„(architectural refactoring)ç­‰ä»»åŠ¡æ—¶ï¼Œå‚ä¸è€…çš„è‡ªè¿°åŠ æƒå¹³å‡ç”Ÿäº§åŠ›æé«˜äº†26.9%ã€‚æ­¤å¤–ï¼Œçº¦77%çš„å‚ä¸è€…è¡¨ç¤ºè®¤çŸ¥è´Ÿè·(cognitive load)æœ‰æ‰€é™ä½ï¼Œ83%çš„å‚ä¸è€…å› AIè¾…åŠ©ä¸‹çš„åˆå§‹è§„åˆ’æ›´å®Œå–„è€Œå‡å°‘äº†ä¿®å¤æˆ–é‡å†™ä»£ç çš„æ—¶é—´ã€‚è¯¥ç ”ç©¶åˆæ­¥éªŒè¯äº†ç»“æ„åŒ–LLMå·¥ä½œæµåœ¨æ”¹è¿›é—ç•™å·¥ç¨‹ç³»ç»Ÿå¼€å‘æ•ˆç‡æ–¹é¢çš„æ½œåŠ›ï¼Œå¹¶ä¸ºæœªæ¥çš„å—æ§è¯„ä¼°å¥ å®šäº†åŸºç¡€ã€‚",
      "categories": [
        "cs.SE",
        "cs.AI"
      ],
      "primary_category": "cs.SE",
      "comment": "53 pages, 7 figures",
      "pdf_url": "https://arxiv.org/pdf/2512.01155v2",
      "published_date": "2025-12-01 00:26:41 UTC",
      "updated_date": "2025-12-02 10:47:38 UTC",
      "processing_status": "completed",
      "attempts": 1,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "llm_backup_calls": 0,
      "last_update": "2026-01-26T12:42:46.534942+00:00"
    },
    {
      "arxiv_id": "2512.05994v1",
      "title": "KidSpeak: A General Multi-purpose LLM for Kids' Speech Recognition and Screening",
      "title_zh": "KidSpeakï¼šé¢å‘å„¿ç«¥è¯­éŸ³è¯†åˆ«ä¸ç­›æŸ¥çš„é€šç”¨å¤šç”¨é€”å¤§è¯­è¨€æ¨¡å‹",
      "authors": [
        "Rohan Sharma",
        "Dancheng Liu",
        "Jingchen Sun",
        "Shijie Zhou",
        "Jiayu Qin",
        "Jinjun Xiong",
        "Changyou Chen"
      ],
      "abstract": "With the rapid advancement of conversational and diffusion-based AI, there is a growing adoption of AI in educational services, ranging from grading and assessment tools to personalized learning systems that provide targeted support for students. However, this adaptability has yet to fully extend to the domain of children's speech, where existing models often fail due to their reliance on datasets designed for clear, articulate adult speech. Children, particularly those in early developmental stages or with speech and language pathologies, present unique challenges that current AI models and datasets are ill-equipped to handle. To address this, we introduce KidSpeak, a multi-task speech-enhanced Foundation Model capable of both generative and discriminative tasks specifically tailored to children's speech patterns. Our framework employs a two-stage training process that incorporates phonetic knowledge into the speech encoder, achieving an average accuracy of 87% across four separate tasks. Furthermore, recognizing the limitations of scalable human annotation and existing speech alignment tools, we propose the Flexible and Automatic Speech Aligner (FASA) and leverage the method to construct high quality datasets for training and evaluation. This novel alignment tool significantly improves the quality of aligned children's speech from noisy data, enhancing data quality by 13.6x compared to human annotations, as demonstrated on the CHILDES dataset. To the best of our knowledge, KidSpeak and FASA represent the first comprehensive solution designed for speech and language therapy in children, offering both a multi-purpose speech LLM and a robust alignment tool.",
      "tldr_zh": "è¯¥ç ”ç©¶æ¨å‡ºäº†KidSpeakï¼Œè¿™æ˜¯ä¸€ç§é€šç”¨çš„å¤šç”¨é€”è¯­éŸ³å¢å¼ºåŸºåº§æ¨¡å‹(Foundation Model)ï¼Œä¸“ä¸ºå„¿ç«¥è¯­éŸ³è¯†åˆ«å’Œç­›æŸ¥è€Œè®¾è®¡ï¼Œæ—¨åœ¨è§£å†³ç°æœ‰æ¨¡å‹å› ä¾èµ–æˆäººè¯­éŸ³æ•°æ®è€Œéš¾ä»¥æœ‰æ•ˆå¤„ç†å„¿ç«¥åŠè¯­è¨€éšœç¢å„¿ç«¥è¯­éŸ³çš„é—®é¢˜ã€‚è¯¥æ¡†æ¶é‡‡ç”¨ä¸¤é˜¶æ®µè®­ç»ƒè¿‡ç¨‹ï¼Œå°†è¯­éŸ³å­¦çŸ¥è¯†(phonetic knowledge)é›†æˆåˆ°è¯­éŸ³ç¼–ç å™¨ä¸­ï¼Œåœ¨ç”Ÿæˆå’Œåˆ¤åˆ«ä»»åŠ¡ä¸­å‡è¡¨ç°å‡ºè‰²ï¼Œè·¨å››é¡¹ä»»åŠ¡çš„å¹³å‡å‡†ç¡®ç‡è¾¾åˆ°87%ã€‚é’ˆå¯¹å„¿ç«¥è¯­éŸ³å¤§è§„æ¨¡æ ‡æ³¨å’Œå¯¹é½çš„å±€é™æ€§ï¼Œç ”ç©¶å›¢é˜Ÿæå‡ºäº†çµæ´»è‡ªåŠ¨è¯­éŸ³å¯¹é½å™¨(FASA)ï¼Œå¹¶åˆ©ç”¨è¯¥å·¥å…·ä»å™ªå£°æ•°æ®ä¸­æ„å»ºäº†é«˜è´¨é‡çš„è®­ç»ƒå’Œè¯„ä¼°æ•°æ®é›†ã€‚å®éªŒç»“æœè¡¨æ˜ï¼ŒFASAåœ¨CHILDESæ•°æ®é›†ä¸Šçš„å¯¹é½è´¨é‡æ¯”äººå·¥æ ‡æ³¨æé«˜äº†13.6å€ï¼Œæ˜¾è‘—ä¼˜åŒ–äº†æ•°æ®å¤„ç†æµç¨‹ã€‚ä½œä¸ºé¦–ä¸ªé’ˆå¯¹å„¿ç«¥è¨€è¯­è¯­è¨€æ²»ç–—çš„ç»¼åˆè§£å†³æ–¹æ¡ˆï¼ŒKidSpeakå’ŒFASAä¸ºåŒ»ç–—ç­›æŸ¥å’Œä¸ªæ€§åŒ–æ•™è‚²æ”¯æŒå¥ å®šäº†é‡è¦çš„æŠ€æœ¯åŸºç¡€ã€‚",
      "categories": [
        "eess.AS",
        "cs.AI",
        "cs.CL",
        "cs.SD"
      ],
      "primary_category": "eess.AS",
      "comment": "",
      "pdf_url": "https://arxiv.org/pdf/2512.05994v1",
      "published_date": "2025-12-01 00:19:37 UTC",
      "updated_date": "2025-12-01 00:19:37 UTC",
      "processing_status": "completed",
      "attempts": 1,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "llm_backup_calls": 0,
      "last_update": "2026-01-26T12:42:57.336972+00:00"
    },
    {
      "arxiv_id": "2512.01153v1",
      "title": "DPAC: Distribution-Preserving Adversarial Control for Diffusion Sampling",
      "title_zh": "DPACï¼šé¢å‘æ‰©æ•£é‡‡æ ·çš„åˆ†å¸ƒä¿æŒå¯¹æŠ—æ§åˆ¶",
      "authors": [
        "Han-Jin Lee",
        "Han-Ju Lee",
        "Jin-Seong Kim",
        "Seok-Hwan Choi"
      ],
      "abstract": "Adversarially guided diffusion sampling often achieves the target class, but sample quality degrades as deviations between the adversarially controlled and nominal trajectories accumulate. We formalize this degradation as a path-space Kullback-Leibler divergence(path-KL) between controlled and nominal (uncontrolled) diffusion processes, thereby showing via Girsanov's theorem that it exactly equals the control energy. Building on this stochastic optimal control (SOC) view, we theoretically establish that minimizing this path-KL simultaneously tightens upper bounds on both the 2-Wasserstein distance and FrÃ©chet Inception Distance (FID), revealing a principled connection between adversarial control energy and perceptual fidelity. From a variational perspective, we derive a first-order optimality condition for the control: among all directions that yield the same classification gain, the component tangent to iso-(log-)density surfaces (i.e., orthogonal to the score) minimizes path-KL, whereas the normal component directly increases distributional drift. This leads to DPAC (Distribution-Preserving Adversarial Control), a diffusion guidance rule that projects adversarial gradients onto the tangent space defined by the generative score geometry. We further show that in discrete solvers, the tangent projection cancels the O(Î”t) leading error term in the Wasserstein distance, achieving an O(Î”t^2) quality gap; moreover, it remains second-order robust to score or metric approximation. Empirical studies on ImageNet-100 validate the theoretical predictions, confirming that DPAC achieves lower FID and estimated path-KL at matched attack success rates.",
      "tldr_zh": "è¯¥ç ”ç©¶æ¢è®¨äº†æ‰©æ•£æŠ½æ ·ä¸­çš„å¯¹æŠ—å¼•å¯¼(adversarially guided diffusion sampling)é—®é¢˜ï¼Œé’ˆå¯¹å¯¹æŠ—æ§åˆ¶è½¨è¿¹ä¸æ ‡ç§°è½¨è¿¹ä¹‹é—´çš„åå·®å¯¼è‡´æ ·æœ¬è´¨é‡ä¸‹é™çš„ç°è±¡è¿›è¡Œäº†æ·±å…¥åˆ†æã€‚ä½œè€…åˆ©ç”¨Girsanovå®šç†å°†è¿™ç§è´¨é‡é€€åŒ–å½¢å¼åŒ–ä¸ºå—æ§è¿‡ç¨‹ä¸éå—æ§è¿‡ç¨‹ä¹‹é—´çš„è·¯å¾„ç©ºé—´Kullback-Leibleræ•£åº¦(path-KL)ï¼Œå¹¶è¯æ˜å…¶ç²¾ç¡®ç­‰äºæ§åˆ¶èƒ½é‡(control energy)ã€‚ç†è®ºè¯æ˜é€šè¿‡æœ€å°åŒ–path-KLå¯ä»¥åŒæ—¶æ”¶ç´§2-Wassersteinè·ç¦»å’ŒFrÃ©chet Inception Distance (FID)çš„ä¸Šç•Œï¼Œæ­ç¤ºäº†å¯¹æŠ—æ§åˆ¶èƒ½é‡ä¸æ„ŸçŸ¥ä¿çœŸåº¦ä¹‹é—´çš„åŸåˆ™æ€§è”ç³»ã€‚åŸºäºå˜åˆ†è§†è§’ï¼Œç ”ç©¶æå‡ºäº†DPAC (Distribution-Preserving Adversarial Control)å¼•å¯¼è§„åˆ™ï¼Œé€šè¿‡å°†å¯¹æŠ—æ¢¯åº¦æŠ•å½±åˆ°ç”±ç”Ÿæˆåˆ†æ•°å­¦å‡ ä½•(generative score geometry)å®šä¹‰çš„åˆ‡ç©ºé—´(tangent space)ä¸Šï¼Œåœ¨ä¿æŒåˆ†ç±»å¢ç›Šçš„åŒæ—¶æœ€å°åŒ–path-KLå¹¶å‡å°‘åˆ†å¸ƒæ¼‚ç§»ã€‚åœ¨ç¦»æ•£æ±‚è§£å™¨ä¸­ï¼Œè¯¥æŠ•å½±æ–¹æ³•æ¶ˆé™¤äº†Wassersteinè·ç¦»ä¸­çš„ä¸€é˜¶è¯¯å·®é¡¹ï¼Œå®ç°äº†$O(\\Delta t^2)$çš„è´¨é‡é—´éš™ï¼Œå¹¶å¯¹åˆ†æ•°æˆ–åº¦é‡è¿‘ä¼¼è¡¨ç°å‡ºäºŒé˜¶ç¨³å¥æ€§ã€‚åœ¨ImageNet-100ä¸Šçš„å®éªŒç»“æœéªŒè¯äº†ç†è®ºé¢„æµ‹ï¼Œè¯æ˜DPACåœ¨åŒ¹é…æ”»å‡»æˆåŠŸç‡çš„æƒ…å†µä¸‹èƒ½å¤Ÿå®ç°æ›´ä½çš„FIDå’Œæ›´ä¼˜çš„æ ·æœ¬ç”Ÿæˆè´¨é‡ã€‚",
      "categories": [
        "cs.CV",
        "cs.AI",
        "cs.LG"
      ],
      "primary_category": "cs.CV",
      "comment": "",
      "pdf_url": "https://arxiv.org/pdf/2512.01153v1",
      "published_date": "2025-12-01 00:15:05 UTC",
      "updated_date": "2025-12-01 00:15:05 UTC",
      "processing_status": "completed",
      "attempts": 1,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "llm_backup_calls": 0,
      "last_update": "2026-01-26T12:43:16.433266+00:00"
    },
    {
      "arxiv_id": "2512.01152v2",
      "title": "Open-Set Domain Adaptation Under Background Distribution Shift: Challenges and A Provably Efficient Solution",
      "title_zh": "èƒŒæ™¯åˆ†å¸ƒåç§»ä¸‹çš„å¼€é›†åŸŸè‡ªé€‚åº”ï¼šæŒ‘æˆ˜ä¸å¯è¯é«˜æ•ˆçš„è§£å†³æ–¹æ¡ˆ",
      "authors": [
        "Shravan Chaudhari",
        "Yoav Wald",
        "Suchi Saria"
      ],
      "abstract": "As we deploy machine learning systems in the real world, a core challenge is to maintain a model that is performant even as the data shifts. Such shifts can take many forms: new classes may emerge that were absent during training, a problem known as open-set recognition, and the distribution of known categories may change. Guarantees on open-set recognition are mostly derived under the assumption that the distribution of known classes, which we call the background distribution, is fixed. In this paper we develop CoLOR, a method that is guaranteed to solve open-set recognition even in the challenging case where the background distribution shifts. We prove that the method works under benign assumptions that the novel class is separable from the non-novel classes, and provide theoretical guarantees that it outperforms a representative baseline in a simplified overparameterized setting. We develop techniques to make CoLOR scalable and robust, and perform comprehensive empirical evaluations on image and text data. The results show that CoLOR significantly outperforms existing open-set recognition methods under background shift. Moreover, we provide new insights into how factors such as the size of the novel class influences performance, an aspect that has not been extensively explored in prior work.",
      "tldr_zh": "è¯¥ç ”ç©¶æ¢è®¨äº†åœ¨ç°å®ä¸–ç•Œéƒ¨ç½²æœºå™¨å­¦ä¹ ç³»ç»Ÿæ—¶ï¼Œå¦‚ä½•åº”å¯¹å¼€æ”¾é›†è¯†åˆ«(Open-Set Recognition)ä¸å·²çŸ¥ç±»åˆ«åˆ†å¸ƒï¼ˆèƒŒæ™¯åˆ†å¸ƒï¼‰åŒæ—¶å‘ç”Ÿåç§»çš„æ ¸å¿ƒæŒ‘æˆ˜ã€‚é’ˆå¯¹ç°æœ‰æ–¹æ³•å¤§å¤šå‡è®¾èƒŒæ™¯åˆ†å¸ƒå›ºå®šçš„å±€é™æ€§ï¼Œæœ¬æ–‡æå‡ºäº†CoLORæ–¹æ³•ï¼Œå¹¶è¯æ˜äº†å…¶åœ¨èƒŒæ™¯åˆ†å¸ƒåç§»çš„å¤æ‚æƒ…å¢ƒä¸‹ä¾ç„¶å…·æœ‰ç†è®ºä¿è¯ã€‚ä½œè€…åœ¨è‰¯æ€§å‡è®¾ä¸‹éªŒè¯äº†æ–°ç±»åˆ«ä¸éæ–°ç±»åˆ«çš„å¯åˆ†æ€§ï¼Œå¹¶åœ¨è¿‡åº¦å‚æ•°åŒ–(Overparameterized)è®¾ç½®ä¸‹è¯æ˜äº†è¯¥æ–¹æ³•ä¼˜äºä»£è¡¨æ€§åŸºå‡†æ¨¡å‹ã€‚é€šè¿‡å¼€å‘æå‡å¯æ‰©å±•æ€§ä¸é²æ£’æ€§çš„æŠ€æœ¯ï¼Œè¯¥ç ”ç©¶åœ¨å›¾åƒå’Œæ–‡æœ¬æ•°æ®ä¸Šè¿›è¡Œäº†å¹¿æ³›çš„å®è¯è¯„ä¼°ï¼Œç»“æœæ˜¾ç¤ºCoLORåœ¨èƒŒæ™¯åç§»ä¸‹çš„æ€§èƒ½æ˜¾è‘—ä¼˜äºç°æœ‰ç®—æ³•ã€‚æ­¤å¤–ï¼Œè®ºæ–‡è¿˜æ·±å…¥åˆ†æäº†æ–°ç±»åˆ«è§„æ¨¡ç­‰å› ç´ å¯¹è¯†åˆ«æ€§èƒ½çš„å½±å“ï¼Œä¸ºè¯¥é¢†åŸŸæä¾›äº†æ­¤å‰æœªè¢«å……åˆ†æ¢ç´¢çš„é‡è¦è§è§£ã€‚",
      "categories": [
        "cs.LG",
        "cs.AI",
        "cs.CV"
      ],
      "primary_category": "cs.LG",
      "comment": "",
      "pdf_url": "https://arxiv.org/pdf/2512.01152v2",
      "published_date": "2025-12-01 00:08:18 UTC",
      "updated_date": "2025-12-03 19:23:58 UTC",
      "processing_status": "completed",
      "attempts": 1,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "llm_backup_calls": 0,
      "last_update": "2026-01-26T12:43:13.045445+00:00"
    }
  ],
  "processing_status": "completed",
  "error": null,
  "raw_papers_fetched": true,
  "papers_count": 162,
  "processed_papers_count": 162,
  "failed_papers_count": 0,
  "llm_backup_calls": 0,
  "summary_generated": true,
  "daily_data_saved": true,
  "last_update": "2026-01-26T12:44:24.736350+00:00"
}