{
  "date": "2024-07-02",
  "category": "cs.AI",
  "summary": "欢迎来到 UTC 时间 2024-07-02 的 arXiv 中文 TLDR 快报！\n\n今天 arXiv 的论文主要聚焦于 AI 模型优化（如 LLM 和扩散模型）、计算机视觉、强化学习以及安全隐私等领域，重点包括 LLM 在特征选择和知识追踪中的创新应用，以及知名学者如 Sergey Levine 和 Yejin Choi 的机器人和 NLP 相关作品；令人印象深刻的文章有 LLM-Select 和 RankRAG，它们展示了 LLM 在高效特征选择和检索增强生成中的潜力。\n\n下面，我将逐一简要概述今日论文，先优先讨论重要、话题度高的文章（如 LLM 相关），然后快速掠过其他领域的内容。每个条目包括论文标题（中文 + 英文）、主要贡献和发现，保留核心学术术语。\n\n### LLM 和 NLP 相关（重点领域，讨论较多）\n- **论文标题（中文）：LLM-Select：利用大语言模型进行特征选择；英文：LLM-Select: Feature Selection with Large Language Models**  \n  主要贡献：提出一种基于 LLM（如 GPT-4）的零样本特征选择方法，能与传统数据驱动方法（如 LASSO）媲美；发现 LLM 可从特征名称和任务描述中识别预测性特征，提升医疗和社会科学领域的数据收集效率。\n\n- **论文标题（中文）：RankRAG：统一上下文排序与检索增强生成的框架；英文：RankRAG: Unifying Context Ranking with Retrieval-Augmented Generation in LLMs**  \n  主要贡献：开发一种指令微调框架，让 LLM 同时处理上下文排序和生成任务，显著提升知识密集型任务性能（如在 RAG 基准上超越 GPT-4）；发现 LLM 在多任务设置中更具竞争力。\n\n- **论文标题（中文）：SeqMate：基于大语言模型的 RNA 测序自动化管道；英文：SeqMate: A Novel Large Language Model Pipeline for Automating RNA Sequencing**  \n  主要贡献：构建一个 LLM 驱动的工具，实现 RNA 测序数据的自动化分析和报告生成，简化生物信息学流程；发现该方法能处理复杂数据操作，提升生物学家的分析效率。\n\n- **论文标题（中文）：MMedAgent：多模态代理用于医学工具学习；英文：MMedAgent: Learning to Use Medical Tools with Multi-modal Agent**  \n  主要贡献：提出一个多模态代理框架，使用 LLM 训练模型选择和使用医学工具，处理多种医学任务；发现该方法在医学图像分析中优于现有模型，提升临床决策准确性。\n\n- **论文标题（中文）：PromptIntern：通过内部化提示优化大语言模型微调；英文：PromptIntern: Saving Inference Costs by Internalizing Recurrent Prompt during Large Language Model Fine-tuning**  \n  主要贡献：引入一种微调策略，将提示知识嵌入模型参数，减少推理成本并保持性能；发现此方法在 NL2Code 任务中显著降低输入 token 数量，提升效率。\n\n- **论文标题（中文）：RLHF 可以处理多种语言：解锁多语言偏好优化；英文：RLHF Can Speak Many Languages: Unlocking Multilingual Preference Optimization for LLMs**  \n  主要贡献：扩展强化学习从人类反馈（RLHF）到多语言设置，改进 LLM 的偏好优化；发现该方法在 23 种语言上提升性能，支持跨文化应用。\n\n其他 LLM 相关论文如 A Practical Review of Mechanistic Interpretability 和 Predicting vs. Acting 等，讨论 LLM 的解释性和决策权衡，但影响较小，仅快速提及：它们分析 LLM 的内部机制和决策偏差，帮助提升模型可靠性。\n\n### 计算机视觉和生成模型（高话题度领域）\n- **论文标题（中文）：Meta 3D Gen：基于文本的 3D 资产生成；英文：Meta 3D Gen**  \n  主要贡献：提出一个快速文本到 3D 生成管道，支持物理渲染材质，生成高质量 3D 资产；发现该方法在复杂提示下优于基线，提升 3D 应用效率。\n\n- **论文标题（中文）：AutoSplat：用于自动驾驶场景重建的约束高斯散斑；英文：AutoSplat: Constrained Gaussian Splatting for Autonomous Driving Scene Reconstruction**  \n  主要贡献：开发高斯散斑框架，用于自动驾驶场景的重建和新型视图合成；发现该方法在动态障碍物场景中提升鲁棒性。\n\n- **论文标题（中文）：VFIMamba：基于状态空间模型的视频帧插值；英文：VFIMamba: Video Frame Interpolation with State Space Models**  \n  主要贡献：引入 Mamba 模型优化视频帧插值，提升实时渲染质量；发现该方法在高分辨率视频中显著改善运动建模。\n\n其他视觉相关论文如 Adversarial Magnification 和 Magic Insert 等，探索对抗攻击和图像编辑，但细节较琐碎，仅提及其在深度伪造检测和风格化插入中的创新。\n\n### 强化学习和机器人（知名学者参与）\n- **论文标题（中文）：Commonsense Reasoning for Legged Robot Adaptation with Vision-Language Models；英文：Commonsense Reasoning for Legged Robot Adaptation with Vision-Language Models**  \n  主要贡献：由 Sergey Levine 和 Chelsea Finn 等知名学者提出，使用视觉语言模型增强 legged 机器人的适应性；发现该系统在复杂场景中实现自主导航，提升机器人鲁棒性。\n\n其他机器人论文如 UAV-assisted Distributed Learning 和 PWM 等，讨论分布式学习和机器人规划，但不具主导性，仅快速注：它们优化了 IoT 和边缘计算中的推理机制。\n\n### 其他领域（快速掠过）\n- **安全和隐私相关**：如 Breach By A Thousand Leaks 和 Face Reconstruction Transfer Attack，分别探讨 LLM 信息泄露和对抗攻击；主要发现：这些方法暴露了模型漏洞，但防御策略需改进。\n  \n- **医学和生物**：如 D-Rax 和 Multi-Peptide，仅提及其在医学图像分析和肽属性预测中的进展，提升了诊断准确性。\n\n- **其他零散**：如 A Survey of Accessible Explainable Artificial Intelligence 和 Wildfire Autonomous Response，仅简述其在无障碍 AI 和环境模拟中的贡献，不深究。\n\n今日 arXiv 论文整体质量高，但 LLM 和视觉领域的创新更具影响力。感兴趣的读者可关注这些主题的后续发展！",
  "papers": [
    {
      "arxiv_id": "2407.02706v2",
      "title": "Pushing the Boundary: Specialising Deep Configuration Performance Learning",
      "title_zh": "翻译失败",
      "authors": [
        "Jingzhi Gong"
      ],
      "abstract": "Software systems often have numerous configuration options that can be\nadjusted to meet different performance requirements. However, understanding the\ncombined impact of these options on performance is often challenging,\nespecially with limited real-world data. To tackle this issue, deep learning\ntechniques have gained popularity due to their ability to capture complex\nrelationships even with limited samples. This thesis begins with a systematic\nliterature review of deep learning techniques in configuration performance\nmodeling, analyzing 85 primary papers out of 948 searched papers. It identifies\nknowledge gaps and sets three objectives for the thesis. The first knowledge\ngap is the lack of understanding about which encoding scheme is better and in\nwhat circumstances. To address this, the thesis conducts an empirical study\ncomparing three popular encoding schemes. Actionable suggestions are provided\nto support more reliable decisions. Another knowledge gap is the sparsity\ninherited from the configuration landscape. To handle this, the thesis proposes\na model-agnostic and sparsity-robust framework called DaL, which uses a\n\"divide-and-learn\" approach. DaL outperforms state-of-the-art approaches in\naccuracy improvement across various real-world systems. The thesis also\naddresses the limitation of predicting under static environments by proposing a\nsequential meta-learning framework called SeMPL. Unlike traditional\nmeta-learning frameworks, SeMPL trains meta-environments in a specialized\norder, resulting in significantly improved prediction accuracy in\nmulti-environment scenarios. Overall, the thesis identifies and addresses\ncritical knowledge gaps in deep performance learning, significantly advancing\nthe accuracy of performance prediction.",
      "tldr_zh": "本论文探讨了使用 deep learning 技术来建模软件配置性能的挑战，通过分析 85 篇文献识别关键知识空白，并设定三个研究目标。针对编码方案的优劣问题，该研究进行实证比较，提供可靠决策建议；为处理配置景观的稀疏性，提出模型无关的 DaL 框架，利用 \"divide-and-learn\" 方法，在多种真实系统中显著提升准确性；此外，SeMPL 框架通过顺序元学习(meta-learning)优化多环境预测，极大改善了预测精度。整体而言，该研究推进了 deep performance learning 的准确性和应用潜力。",
      "categories": [
        "cs.SE",
        "cs.AI"
      ],
      "primary_category": "cs.SE",
      "comment": "This PhD thesis was submitted in May 2024",
      "pdf_url": "http://arxiv.org/pdf/2407.02706v2",
      "published_date": "2024-07-02 22:59:19 UTC",
      "updated_date": "2025-01-30 13:56:45 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-19T02:41:40.119853"
    },
    {
      "arxiv_id": "2407.02694v2",
      "title": "LLM-Select: Feature Selection with Large Language Models",
      "title_zh": "翻译失败",
      "authors": [
        "Daniel P. Jeong",
        "Zachary C. Lipton",
        "Pradeep Ravikumar"
      ],
      "abstract": "In this paper, we demonstrate a surprising capability of large language\nmodels (LLMs): given only input feature names and a description of a prediction\ntask, they are capable of selecting the most predictive features, with\nperformance rivaling the standard tools of data science. Remarkably, these\nmodels exhibit this capacity across various query mechanisms. For example, we\nzero-shot prompt an LLM to output a numerical importance score for a feature\n(e.g., \"blood pressure\") in predicting an outcome of interest (e.g., \"heart\nfailure\"), with no additional context. In particular, we find that the latest\nmodels, such as GPT-4, can consistently identify the most predictive features\nregardless of the query mechanism and across various prompting strategies. We\nillustrate these findings through extensive experiments on real-world data,\nwhere we show that LLM-based feature selection consistently achieves strong\nperformance competitive with data-driven methods such as the LASSO, despite\nnever having looked at the downstream training data. Our findings suggest that\nLLMs may be useful not only for selecting the best features for training but\nalso for deciding which features to collect in the first place. This could\nbenefit practitioners in domains like healthcare and the social sciences, where\ncollecting high-quality data comes at a high cost.",
      "tldr_zh": "本研究提出LLM-Select方法，利用大型语言模型（LLMs）仅基于特征名称和预测任务描述，就能选择最具预测性的特征，其性能可与传统数据科学工具（如LASSO）相媲美。研究通过zero-shot prompting和多种查询机制（如输出特征重要性分数）进行实验，发现模型如GPT-4在不同提示策略下都能稳定识别关键特征，即使未接触下游训练数据。结果显示，LLMs在真实世界数据集上表现出色，这不仅有助于优化特征训练，还可指导高成本领域（如医疗和社会科学）的特征收集决策。",
      "categories": [
        "cs.LG",
        "cs.AI",
        "cs.CL",
        "stat.ML"
      ],
      "primary_category": "cs.LG",
      "comment": "Published in Transactions on Machine Learning Research (TMLR), April\n  2025",
      "pdf_url": "http://arxiv.org/pdf/2407.02694v2",
      "published_date": "2024-07-02 22:23:40 UTC",
      "updated_date": "2025-04-17 21:50:37 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-19T02:41:51.709215"
    },
    {
      "arxiv_id": "2407.02693v1",
      "title": "UAV-assisted Distributed Learning for Environmental Monitoring in Rural Environments",
      "title_zh": "翻译失败",
      "authors": [
        "Vukan Ninkovic",
        "Dejan Vukobratovic",
        "Dragisa Miskovic"
      ],
      "abstract": "Distributed learning and inference algorithms have become indispensable for\nIoT systems, offering benefits such as workload alleviation, data privacy\npreservation, and reduced latency. This paper introduces an innovative approach\nthat utilizes unmanned aerial vehicles (UAVs) as a coverage extension relay for\nIoT environmental monitoring in rural areas. Our method integrates a split\nlearning (SL) strategy between edge devices, a UAV and a server to enhance\nadaptability and performance of inference mechanisms. By employing UAVs as a\nrelay and by incorporating SL, we address connectivity and resource constraints\nfor applications of learning in IoT in remote settings. Our system model\naccounts for diverse channel conditions to determine the most suitable\ntransmission strategy for optimal system behaviour. Through simulation\nanalysis, the proposed approach demonstrates its robustness and adaptability,\neven excelling under adverse channel conditions. Integrating UAV relaying and\nthe SL paradigm offers significant flexibility to the server, enabling adaptive\nstrategies that consider various trade-offs beyond simply minimizing overall\ninference quality.",
      "tldr_zh": "本文提出了一种利用无人机(UAV)作为中继的创新方法，用于农村环境的IoT环境监测，旨在缓解分布式学习中的工作负载、数据隐私和延迟问题。该方法整合split learning (SL)策略，在边缘设备、UAV和服务器之间进行协作，实现对连接性和资源约束的优化，并根据不同通道条件选择最佳传输策略。通过模拟分析，该系统展示了出色的稳健性和适应性，即使在不利条件下也能提供灵活的权衡选项，提升了整体推理性能。",
      "categories": [
        "eess.SP",
        "cs.AI",
        "cs.LG"
      ],
      "primary_category": "eess.SP",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2407.02693v1",
      "published_date": "2024-07-02 22:21:03 UTC",
      "updated_date": "2024-07-02 22:21:03 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-19T02:42:03.709027"
    },
    {
      "arxiv_id": "2407.02678v1",
      "title": "Reasoning in Large Language Models: A Geometric Perspective",
      "title_zh": "大语言模型中的推理：几何视角",
      "authors": [
        "Romain Cosentino",
        "Sarath Shekkizhar"
      ],
      "abstract": "The advancement of large language models (LLMs) for real-world applications\nhinges critically on enhancing their reasoning capabilities. In this work, we\nexplore the reasoning abilities of large language models (LLMs) through their\ngeometrical understanding. We establish a connection between the expressive\npower of LLMs and the density of their self-attention graphs. Our analysis\ndemonstrates that the density of these graphs defines the intrinsic dimension\nof the inputs to the MLP blocks. We demonstrate through theoretical analysis\nand toy examples that a higher intrinsic dimension implies a greater expressive\ncapacity of the LLM. We further provide empirical evidence linking this\ngeometric framework to recent advancements in methods aimed at enhancing the\nreasoning capabilities of LLMs.",
      "tldr_zh": "这篇论文从几何视角探讨大型语言模型 (LLMs) 的推理能力，强调了自注意力图密度与模型表达力的关系。研究通过理论分析证明，自注意力图的密度定义了 MLP 块输入的内在维度，而更高的内在维度能显著提升 LLMs 的表达容量。作者还提供了实验证据，将这一几何框架与最近的推理增强方法联系起来，展示了其在提升模型推理性能方面的潜力。",
      "categories": [
        "cs.AI",
        "cs.CL"
      ],
      "primary_category": "cs.AI",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2407.02678v1",
      "published_date": "2024-07-02 21:39:53 UTC",
      "updated_date": "2024-07-02 21:39:53 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-19T02:42:15.371017"
    },
    {
      "arxiv_id": "2407.02673v1",
      "title": "A Novel Approach to Image EEG Sleep Data for Improving Quality of Life in Patients Suffering From Brain Injuries Using DreamDiffusion",
      "title_zh": "一种",
      "authors": [
        "David Fahim",
        "Joshveer Grewal",
        "Ritvik Ellendula"
      ],
      "abstract": "Those experiencing strokes, traumatic brain injuries, and drug complications\ncan often end up hospitalized and diagnosed with coma or locked-in syndrome.\nSuch mental impediments can permanently alter the neurological pathways in work\nand significantly decrease the quality of life (QoL). It is critical to\ntranslate brain signals into images to gain a deeper understanding of the\nthoughts of a comatose patient. Traditionally, brain signals collected by an\nEEG could only be translated into text, but with the novel method of an\nopen-source model available on GitHub, DreamDiffusion can be used to convert\nbrain waves into images directly. DreamDiffusion works by extracting features\nfrom EEG signals and then using the features to create images through\nStableDiffusion. Upon this, we made further improvements that could make\nStableDiffusion the forerunner technology in waves to media translation. In our\nstudy, we begin by modifying the existing DreamDiffusion codebase so that it\ndoes not require any prior setup, avoiding any confusing steps needed to run\nthe model from GitHub. For many researchers, the incomplete setup process,\nerrors in the existing code, and a lack of directions made it nearly impossible\nto run, not even considering the model's performance. We brought the code into\nGoogle Colab so users could run and evaluate problems cell-by-cell, eliminating\nthe specific file and repository dependencies. We also provided the original\ntraining data file so users do not need to purchase the necessary computing\npower to train the model from the given dataset. The second change is utilizing\nthe mutability of the code and optimizing the model so it can be used to\ngenerate images from other given inputs, such as sleep data. Additionally, the\naffordability of EEG technology allows for global dissemination and creates the\nopportunity for those who want to work on the shared DreamDiffusion model.",
      "tldr_zh": "该论文提出了一种新方法，使用DreamDiffusion模型将EEG脑电图信号转化为图像，旨在改善中风、创伤性脑损伤等患者的生活质量（QoL），通过StableDiffusion提取EEG特征生成图像。研究者优化了DreamDiffusion的开源代码，使其在Google Colab上无需复杂设置即可运行，并提供了原始训练数据以降低用户门槛。进一步扩展了模型功能，使其能处理睡眠数据等其他输入，并强调EEG技术的可负担性，以促进全球研究和临床应用。实验改进证明了这一方法的实用性和可访问性。",
      "categories": [
        "q-bio.NC",
        "cs.AI"
      ],
      "primary_category": "q-bio.NC",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2407.02673v1",
      "published_date": "2024-07-02 21:26:28 UTC",
      "updated_date": "2024-07-02 21:26:28 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-19T02:42:27.629014"
    },
    {
      "arxiv_id": "2407.02670v1",
      "title": "Adversarial Magnification to Deceive Deepfake Detection through Super Resolution",
      "title_zh": "翻译失败",
      "authors": [
        "Davide Alessandro Coccomini",
        "Roberto Caldelli",
        "Giuseppe Amato",
        "Fabrizio Falchi",
        "Claudio Gennaro"
      ],
      "abstract": "Deepfake technology is rapidly advancing, posing significant challenges to\nthe detection of manipulated media content. Parallel to that, some adversarial\nattack techniques have been developed to fool the deepfake detectors and make\ndeepfakes even more difficult to be detected. This paper explores the\napplication of super resolution techniques as a possible adversarial attack in\ndeepfake detection. Through our experiments, we demonstrate that minimal\nchanges made by these methods in the visual appearance of images can have a\nprofound impact on the performance of deepfake detection systems. We propose a\nnovel attack using super resolution as a quick, black-box and effective method\nto camouflage fake images and/or generate false alarms on pristine images. Our\nresults indicate that the usage of super resolution can significantly impair\nthe accuracy of deepfake detectors, thereby highlighting the vulnerability of\nsuch systems to adversarial attacks. The code to reproduce our experiments is\navailable at:\nhttps://github.com/davide-coccomini/Adversarial-Magnification-to-Deceive-Deepfake-Detection-through-Super-Resolution",
      "tldr_zh": "这篇论文探讨了使用 super resolution 作为 adversarial attack 的方法，以欺骗 deepfake 检测系统。研究者通过实验证明，对图像进行微小视觉改变能显著降低检测器的准确率，并提出了一种快速、黑盒且有效的攻击方式，用于伪装假图像或在真实图像上制造假警报。结果显示，这种攻击可使 deepfake 检测系统的准确率大幅下降，突显了其对 adversarial attack 的脆弱性，并提供了可复现实验的代码链接。",
      "categories": [
        "cs.CV",
        "cs.AI"
      ],
      "primary_category": "cs.CV",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2407.02670v1",
      "published_date": "2024-07-02 21:17:36 UTC",
      "updated_date": "2024-07-02 21:17:36 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-19T02:42:40.325113"
    },
    {
      "arxiv_id": "2407.17484v1",
      "title": "A Survey of Accessible Explainable Artificial Intelligence Research",
      "title_zh": "翻译失败",
      "authors": [
        "Chukwunonso Henry Nwokoye",
        "Maria J. P. Peixoto",
        "Akriti Pandey",
        "Lauren Pardy",
        "Mahadeo Sukhai",
        "Peter R. Lewis"
      ],
      "abstract": "The increasing integration of Artificial Intelligence (AI) into everyday life\nmakes it essential to explain AI-based decision-making in a way that is\nunderstandable to all users, including those with disabilities. Accessible\nexplanations are crucial as accessibility in technology promotes digital\ninclusion and allows everyone, regardless of their physical, sensory, or\ncognitive abilities, to use these technologies effectively. This paper presents\na systematic literature review of the research on the accessibility of\nExplainable Artificial Intelligence (XAI), specifically considering persons\nwith sight loss. Our methodology includes searching several academic databases\nwith search terms to capture intersections between XAI and accessibility. The\nresults of this survey highlight the lack of research on Accessible XAI (AXAI)\nand stress the importance of including the disability community in XAI\ndevelopment to promote digital inclusion and accessibility and remove barriers.\nMost XAI techniques rely on visual explanations, such as heatmaps or graphs,\nwhich are not accessible to persons who are blind or have low vision.\nTherefore, it is necessary to develop explanation methods through non-visual\nmodalities, such as auditory and tactile feedback, visual modalities accessible\nto persons with low vision, and personalized solutions that meet the needs of\nindividuals, including those with multiple disabilities. We further emphasize\nthe importance of integrating universal design principles into AI development\npractices to ensure that AI technologies are usable by everyone.",
      "tldr_zh": "这篇论文对可解释人工智能 (XAI) 的可访问性进行了系统文献综述，重点关注视力受损人士，以促进 AI 技术的数字包容。作者通过搜索学术数据库分析了 XAI 与可访问性的交集，发现现有 XAI 方法主要依赖视觉解释（如热图），导致盲人或低视力者面临障碍，且相关研究严重不足。论文建议开发非视觉解释模式（如听觉和触觉反馈）并整合通用设计原则，包括残疾社区参与，以确保 AI 技术对所有人可用。",
      "categories": [
        "cs.HC",
        "cs.AI",
        "cs.CY"
      ],
      "primary_category": "cs.HC",
      "comment": "This work has been submitted to the IEEE for possible publication",
      "pdf_url": "http://arxiv.org/pdf/2407.17484v1",
      "published_date": "2024-07-02 21:09:46 UTC",
      "updated_date": "2024-07-02 21:09:46 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-19T02:42:51.930122"
    },
    {
      "arxiv_id": "2407.02666v1",
      "title": "Commonsense Reasoning for Legged Robot Adaptation with Vision-Language Models",
      "title_zh": "基于视觉语言模型的腿式机器人适应常识推理",
      "authors": [
        "Annie S. Chen",
        "Alec M. Lessing",
        "Andy Tang",
        "Govind Chada",
        "Laura Smith",
        "Sergey Levine",
        "Chelsea Finn"
      ],
      "abstract": "Legged robots are physically capable of navigating a diverse variety of\nenvironments and overcoming a wide range of obstructions. For example, in a\nsearch and rescue mission, a legged robot could climb over debris, crawl\nthrough gaps, and navigate out of dead ends. However, the robot's controller\nneeds to respond intelligently to such varied obstacles, and this requires\nhandling unexpected and unusual scenarios successfully. This presents an open\nchallenge to current learning methods, which often struggle with generalization\nto the long tail of unexpected situations without heavy human supervision. To\naddress this issue, we investigate how to leverage the broad knowledge about\nthe structure of the world and commonsense reasoning capabilities of\nvision-language models (VLMs) to aid legged robots in handling difficult,\nambiguous situations. We propose a system, VLM-Predictive Control (VLM-PC),\ncombining two key components that we find to be crucial for eliciting\non-the-fly, adaptive behavior selection with VLMs: (1) in-context adaptation\nover previous robot interactions and (2) planning multiple skills into the\nfuture and replanning. We evaluate VLM-PC on several challenging real-world\nobstacle courses, involving dead ends and climbing and crawling, on a Go1\nquadruped robot. Our experiments show that by reasoning over the history of\ninteractions and future plans, VLMs enable the robot to autonomously perceive,\nnavigate, and act in a wide range of complex scenarios that would otherwise\nrequire environment-specific engineering or human guidance.",
      "tldr_zh": "本文探讨了如何利用视觉语言模型(VLMs)的常识推理能力，帮助腿式机器人适应复杂和意外环境，以解决当前学习方法在泛化方面的挑战。研究提出VLM-Predictive Control (VLM-PC)系统，该系统包括两个关键组件：基于先前机器人互动的in-context adaptation，以及对未来多技能的规划和重新规划。在Go1四足机器人的真实世界实验中，VLM-PC显著提升了机器人的自主感知、导航和行动能力，使其能够在涉及死胡同、攀爬和爬行的障碍课程中有效应对，而无需特定环境工程或人类指导。",
      "categories": [
        "cs.RO",
        "cs.AI"
      ],
      "primary_category": "cs.RO",
      "comment": "27 pages",
      "pdf_url": "http://arxiv.org/pdf/2407.02666v1",
      "published_date": "2024-07-02 21:00:30 UTC",
      "updated_date": "2024-07-02 21:00:30 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-19T02:43:05.151302"
    },
    {
      "arxiv_id": "2407.02651v2",
      "title": "Improving Steering and Verification in AI-Assisted Data Analysis with Interactive Task Decomposition",
      "title_zh": "翻译失败",
      "authors": [
        "Majeed Kazemitabaar",
        "Jack Williams",
        "Ian Drosos",
        "Tovi Grossman",
        "Austin Henley",
        "Carina Negreanu",
        "Advait Sarkar"
      ],
      "abstract": "LLM-powered tools like ChatGPT Data Analysis, have the potential to help\nusers tackle the challenging task of data analysis programming, which requires\nexpertise in data processing, programming, and statistics. However, our\nformative study (n=15) uncovered serious challenges in verifying AI-generated\nresults and steering the AI (i.e., guiding the AI system to produce the desired\noutput). We developed two contrasting approaches to address these challenges.\nThe first (Stepwise) decomposes the problem into step-by-step subgoals with\npairs of editable assumptions and code until task completion, while the second\n(Phasewise) decomposes the entire problem into three editable, logical phases:\nstructured input/output assumptions, execution plan, and code. A controlled,\nwithin-subjects experiment (n=18) compared these systems against a\nconversational baseline. Users reported significantly greater control with the\nStepwise and Phasewise systems, and found intervention, correction, and\nverification easier, compared to the baseline. The results suggest design\nguidelines and trade-offs for AI-assisted data analysis tools.",
      "tldr_zh": "该研究探讨了LLM驱动工具（如ChatGPT Data Analysis）在数据分析编程中的挑战，特别是验证AI生成结果和引导AI产出的问题。研究者开发了两种交互式任务分解方法：Stepwise（逐步分解为子目标，包括可编辑的假设和代码）和Phasewise（将问题分为三个逻辑阶段：结构化输入/输出假设、执行计划和代码）。通过对照实验（n=18），结果显示Stepwise和Phasewise系统显著提升了用户控制力，并使干预、修正和验证更容易，从而为AI辅助数据分析工具的设计提供了指导和权衡。",
      "categories": [
        "cs.HC",
        "cs.AI"
      ],
      "primary_category": "cs.HC",
      "comment": "Published at UIST 2024; 19 pages, 9 figures, and 2 tables",
      "pdf_url": "http://arxiv.org/pdf/2407.02651v2",
      "published_date": "2024-07-02 20:33:50 UTC",
      "updated_date": "2024-08-01 15:56:00 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-19T02:43:17.604760"
    },
    {
      "arxiv_id": "2407.03381v1",
      "title": "SeqMate: A Novel Large Language Model Pipeline for Automating RNA Sequencing",
      "title_zh": "SeqMate：一种新颖的大型语言模型管道，用于自动化RNA测序",
      "authors": [
        "Devam Mondal",
        "Atharva Inamdar"
      ],
      "abstract": "RNA sequencing techniques, like bulk RNA-seq and Single Cell (sc) RNA-seq,\nare critical tools for the biologist looking to analyze the genetic\nactivity/transcriptome of a tissue or cell during an experimental procedure.\nPlatforms like Illumina's next-generation sequencing (NGS) are used to produce\nthe raw data for this experimental procedure. This raw FASTQ data must then be\nprepared via a complex series of data manipulations by bioinformaticians. This\nprocess currently takes place on an unwieldy textual user interface like a\nterminal/command line that requires the user to install and import multiple\nprogram packages, preventing the untrained biologist from initiating data\nanalysis. Open-source platforms like Galaxy have produced a more user-friendly\npipeline, yet the visual interface remains cluttered and highly technical,\nremaining uninviting for the natural scientist. To address this, SeqMate is a\nuser-friendly tool that allows for one-click analytics by utilizing the power\nof a large language model (LLM) to automate both data preparation and analysis\n(differential expression, trajectory analysis, etc). Furthermore, by utilizing\nthe power of generative AI, SeqMate is also capable of analyzing such findings\nand producing written reports of upregulated/downregulated/user-prompted genes\nwith sources cited from known repositories like PubMed, PDB, and Uniprot.",
      "tldr_zh": "该研究针对RNA sequencing（如bulk RNA-seq和Single Cell RNA-seq）的复杂数据处理问题，提出SeqMate，一种新型大型语言模型(LLM)管道，旨在自动化数据准备和分析过程。SeqMate提供用户友好的界面，实现一键式操作，包括差异表达(differential expression)和轨迹分析(trajectory analysis)。此外，该工具利用生成AI生成详细报告，涵盖上调/下调基因分析并引用可靠来源如PubMed、PDB和Uniprot，从而使非专业生物学家也能轻松进行RNA测序分析。",
      "categories": [
        "q-bio.GN",
        "cs.AI",
        "cs.LG"
      ],
      "primary_category": "q-bio.GN",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2407.03381v1",
      "published_date": "2024-07-02 20:28:30 UTC",
      "updated_date": "2024-07-02 20:28:30 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-19T02:43:27.819065"
    },
    {
      "arxiv_id": "2407.02646v3",
      "title": "A Practical Review of Mechanistic Interpretability for Transformer-Based Language Models",
      "title_zh": "翻译失败",
      "authors": [
        "Daking Rai",
        "Yilun Zhou",
        "Shi Feng",
        "Abulhair Saparov",
        "Ziyu Yao"
      ],
      "abstract": "Mechanistic interpretability (MI) is an emerging sub-field of\ninterpretability that seeks to understand a neural network model by\nreverse-engineering its internal computations. Recently, MI has garnered\nsignificant attention for interpreting transformer-based language models (LMs),\nresulting in many novel insights yet introducing new challenges. However, there\nhas not been work that comprehensively reviews these insights and challenges,\nparticularly as a guide for newcomers to this field. To fill this gap, we\nprovide a comprehensive survey from a task-centric perspective, organizing the\ntaxonomy of MI research around specific research questions or tasks. We outline\nthe fundamental objects of study in MI, along with the techniques, evaluation\nmethods, and key findings for each task in the taxonomy. In particular, we\npresent a task-centric taxonomy as a roadmap for beginners to navigate the\nfield by helping them quickly identify impactful problems in which they are\nmost interested and leverage MI for their benefit. Finally, we discuss the\ncurrent gaps in the field and suggest potential future directions for MI\nresearch.",
      "tldr_zh": "这篇论文对Mechanistic Interpretability (MI)进行了实用综述，专注于理解transformer-based language models (LMs)的内部计算过程，通过逆向工程揭示其工作机制。作者从任务导向视角组织了一个分类法，概述了MI的研究对象、技术、评估方法以及关键发现，帮助新手快速识别感兴趣的问题并应用这些见解。最终，论文讨论了当前领域的空白，并提出未来研究方向，以推动MI在LMs解释性方面的进展。",
      "categories": [
        "cs.AI",
        "cs.CL",
        "I.2.7"
      ],
      "primary_category": "cs.AI",
      "comment": "35 pages, 13 figures, Preprint",
      "pdf_url": "http://arxiv.org/pdf/2407.02646v3",
      "published_date": "2024-07-02 20:28:16 UTC",
      "updated_date": "2025-03-15 17:12:40 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-19T02:43:40.073952"
    },
    {
      "arxiv_id": "2407.02641v1",
      "title": "Learning Graph Structures and Uncertainty for Accurate and Calibrated Time-series Forecasting",
      "title_zh": "翻译失败",
      "authors": [
        "Harshavardhan Kamarthi",
        "Lingkai Kong",
        "Alexander Rodriguez",
        "Chao Zhang",
        "B Aditya Prakash"
      ],
      "abstract": "Multi-variate time series forecasting is an important problem with a wide\nrange of applications. Recent works model the relations between time-series as\ngraphs and have shown that propagating information over the relation graph can\nimprove time series forecasting. However, in many cases, relational information\nis not available or is noisy and reliable. Moreover, most works ignore the\nunderlying uncertainty of time-series both for structure learning and deriving\nthe forecasts resulting in the structure not capturing the uncertainty\nresulting in forecast distributions with poor uncertainty estimates. We tackle\nthis challenge and introduce STOIC, that leverages stochastic correlations\nbetween time-series to learn underlying structure between time-series and to\nprovide well-calibrated and accurate forecasts. Over a wide-range of benchmark\ndatasets STOIC provides around 16% more accurate and 14% better-calibrated\nforecasts.\n  STOIC also shows better adaptation to noise in data during inference and\ncaptures important and useful relational information in various benchmarks.",
      "tldr_zh": "该论文针对多变量time-series forecasting的问题，提出了一种名为STOIC的方法，通过利用时间序列之间的随机相关性来学习底层图结构，并处理不确定性，以实现更准确且校准良好的预测。不同于传统方法，STOIC在结构学习和预测过程中考虑了不确定性因素，从而避免了噪声数据的影响并捕获关键关系信息。在各种基准数据集上，STOIC实现了约16%的预测准确性提升和14%的校准性改善，展示了其在实际应用中的鲁棒性。",
      "categories": [
        "cs.LG",
        "cs.AI"
      ],
      "primary_category": "cs.LG",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2407.02641v1",
      "published_date": "2024-07-02 20:14:32 UTC",
      "updated_date": "2024-07-02 20:14:32 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-19T02:43:52.423778"
    },
    {
      "arxiv_id": "2407.03380v1",
      "title": "Multi-Peptide: Multimodality Leveraged Language-Graph Learning of Peptide Properties",
      "title_zh": "翻译失败",
      "authors": [
        "Srivathsan Badrinarayanan",
        "Chakradhar Guntuboina",
        "Parisa Mollaei",
        "Amir Barati Farimani"
      ],
      "abstract": "Peptides are essential in biological processes and therapeutics. In this\nstudy, we introduce Multi-Peptide, an innovative approach that combines\ntransformer-based language models with Graph Neural Networks (GNNs) to predict\npeptide properties. We combine PeptideBERT, a transformer model tailored for\npeptide property prediction, with a GNN encoder to capture both sequence-based\nand structural features. By employing Contrastive Language-Image Pre-training\n(CLIP), Multi-Peptide aligns embeddings from both modalities into a shared\nlatent space, thereby enhancing the model's predictive accuracy. Evaluations on\nhemolysis and nonfouling datasets demonstrate Multi-Peptide's robustness,\nachieving state-of-the-art 86.185% accuracy in hemolysis prediction. This study\nhighlights the potential of multimodal learning in bioinformatics, paving the\nway for accurate and reliable predictions in peptide-based research and\napplications.",
      "tldr_zh": "本研究提出 Multi-Peptide，一种多模态学习框架，将基于 transformer 的 PeptideBERT 模型与 Graph Neural Networks (GNNs) 结合，用于预测肽的属性，从而捕获序列和结构特征。 通过 Contrastive Language-Image Pre-training (CLIP) 技术，该框架将不同模态的嵌入对齐到共享的潜在空间，提升预测准确性。 在 hemolysis 和 nonfouling 数据集上的评估显示，Multi-Peptide 达到了 state-of-the-art 的 86.185% 准确率，显著优于基线模型。 这为多模态学习在生物信息学中的应用提供了新路径，促进肽相关研究和应用的可靠性。",
      "categories": [
        "q-bio.QM",
        "cs.AI",
        "cs.LG"
      ],
      "primary_category": "q-bio.QM",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2407.03380v1",
      "published_date": "2024-07-02 20:13:47 UTC",
      "updated_date": "2024-07-02 20:13:47 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-19T02:44:04.599755"
    },
    {
      "arxiv_id": "2407.02637v1",
      "title": "Change My Frame: Reframing in the Wild in r/ChangeMyView",
      "title_zh": "翻译失败",
      "authors": [
        "Arturo Martínez Peguero",
        "Taro Watanabe"
      ],
      "abstract": "Recent work in reframing, within the scope of text style transfer, has so far\nmade use of out-of-context, task-prompted utterances in order to produce\nneutralizing or optimistic reframes. Our work aims to generalize reframing\nbased on the subreddit r/ChangeMyView (CMV). We build a dataset that leverages\nCMV's community's interactions and conventions to identify high-value,\ncommunity-recognized utterances that produce changes of perspective. With this\ndata, we widen the scope of the direction of reframing since the changes in\nperspective do not only occur in neutral or positive directions. We fine tune\ntransformer-based models, make use of a modern LLM to refine our dataset, and\nexplore challenges in the dataset creation and evaluation around this type of\nreframing.",
      "tldr_zh": "本论文探讨了在r/ChangeMyView（CMV）子reddits中的reframing现象，构建了一个基于社区互动的数据集，以识别高价值的utterance，这些utterance能引发真实视角改变。不同于以往的text style transfer研究，该工作扩展了reframing的方向，不仅限于中性或积极的转变，还通过微调transformer-based模型和利用现代LLM来改进数据集。研究同时分析了数据集创建和评估的挑战，为更广泛的reframing应用提供了新见解。",
      "categories": [
        "cs.CL",
        "cs.AI",
        "cs.CY",
        "68T50",
        "I.2.7"
      ],
      "primary_category": "cs.CL",
      "comment": "3 pages, NAACL 2024 workshop",
      "pdf_url": "http://arxiv.org/pdf/2407.02637v1",
      "published_date": "2024-07-02 20:09:11 UTC",
      "updated_date": "2024-07-02 20:09:11 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-19T02:44:16.231954"
    },
    {
      "arxiv_id": "2407.02631v1",
      "title": "Nollywood: Let's Go to the Movies!",
      "title_zh": "Nollywood：让我们去看电影吧！",
      "authors": [
        "John E. Ortega",
        "Ibrahim Said Ahmad",
        "William Chen"
      ],
      "abstract": "Nollywood, based on the idea of Bollywood from India, is a series of\noutstanding movies that originate from Nigeria. Unfortunately, while the movies\nare in English, they are hard to understand for many native speakers due to the\ndialect of English that is spoken. In this article, we accomplish two goals:\n(1) create a phonetic sub-title model that is able to translate Nigerian\nEnglish speech to American English and (2) use the most advanced toxicity\ndetectors to discover how toxic the speech is. Our aim is to highlight the text\nin these videos which is often times ignored for lack of dialectal\nunderstanding due the fact that many people in Nigeria speak a native language\nlike Hausa at home.",
      "tldr_zh": "本研究针对 Nollywood（尼日利亚电影产业）的英语方言理解难题，提出两个主要目标：（1）开发一个 phonetic sub-title model，将尼日利亚英语语音翻译成美国英语，以改善非本土观众的观看体验；（2）运用先进的 toxicity detectors 检测视频语音中的毒性水平。研究方法结合语音翻译技术和毒性分析，旨在突出这些电影文本的潜在价值，因为许多尼日利亚人使用本土语言如 Hausa，导致方言障碍。最终，此工作有助于增强 Nollywood 电影的跨文化可访问性和社会影响。",
      "categories": [
        "cs.CL",
        "cs.AI",
        "cs.SD",
        "eess.AS"
      ],
      "primary_category": "cs.CL",
      "comment": "8 pages, 4 figures, 2 tables",
      "pdf_url": "http://arxiv.org/pdf/2407.02631v1",
      "published_date": "2024-07-02 19:50:55 UTC",
      "updated_date": "2024-07-02 19:50:55 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-19T02:44:29.803075"
    },
    {
      "arxiv_id": "2407.02623v3",
      "title": "Uplifting Lower-Income Data: Strategies for Socioeconomic Perspective Shifts in Large Multi-modal Models",
      "title_zh": "翻译失败",
      "authors": [
        "Joan Nwatu",
        "Oana Ignat",
        "Rada Mihalcea"
      ],
      "abstract": "Recent work has demonstrated that the unequal representation of cultures and\nsocioeconomic groups in training data leads to biased Large Multi-modal (LMM)\nmodels. To improve LMM model performance on underrepresented data, we propose\nand evaluate several prompting strategies using non-English, geographic, and\nsocioeconomic attributes. We show that these geographic and socioeconomic\nintegrated prompts favor retrieving topic appearances commonly found in data\nfrom low-income households across different countries leading to improved LMM\nmodel performance on lower-income data. Our analyses identify and highlight\ncontexts where these strategies yield the most improvements.",
      "tldr_zh": "该论文揭示了训练数据中文化和 socioeconomic 群体不平等表示导致 Large Multi-modal Models (LMM) 模型偏见的问题，并提出几种 prompting strategies，使用 non-English、geographic 和 socioeconomic attributes 来提升模型在 underrepresented 数据上的表现。这些策略通过优先检索低收入家庭常见主题，帮助 LMM 模型更好地处理全球低收入数据。研究分析显示，这些方法在特定语境下能显著改善模型性能，为减少 socioeconomic 偏见提供实用指导。",
      "categories": [
        "cs.CY",
        "cs.AI",
        "cs.CL",
        "cs.CV",
        "K.4; I.2.7; I.2.8"
      ],
      "primary_category": "cs.CY",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2407.02623v3",
      "published_date": "2024-07-02 19:27:00 UTC",
      "updated_date": "2024-10-14 14:11:42 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-19T02:44:40.620938"
    },
    {
      "arxiv_id": "2407.02622v1",
      "title": "RISC-V R-Extension: Advancing Efficiency with Rented-Pipeline for Edge DNN Processing",
      "title_zh": "翻译失败",
      "authors": [
        "Won Hyeok Kim",
        "Hyeong Jin Kim",
        "Tae Hee Han"
      ],
      "abstract": "The proliferation of edge devices necessitates efficient computational\narchitectures for lightweight tasks, particularly deep neural network (DNN)\ninference. Traditional NPUs, though effective for such operations, face\nchallenges in power, cost, and area when integrated into lightweight edge\ndevices. The RISC-V architecture, known for its modularity and open-source\nnature, offers a viable alternative. This paper introduces the RISC-V\nR-extension, a novel approach to enhancing DNN process efficiency on edge\ndevices. The extension features rented-pipeline stages and architectural\npipeline registers (APR), which optimize critical operation execution, thereby\nreducing latency and memory access frequency. Furthermore, this extension\nincludes new custom instructions to support these architectural improvements.\nThrough comprehensive analysis, this study demonstrates the boost of\nR-extension in edge device processing, setting the stage for more responsive\nand intelligent edge applications.",
      "tldr_zh": "本论文针对边缘设备上深度神经网络(DNN)推理的效率问题，指出传统NPUs在功率、成本和面积方面存在挑战，并提出RISC-V R-extension作为优化方案。该扩展引入rented-pipeline stages和architectural pipeline registers(APR)，通过优化关键操作减少延迟和内存访问频率，并添加新的自定义指令以提升整体架构性能。通过全面分析，R-extension显著提高了边缘设备处理能力，为更响应和智能的边缘应用奠定了基础。",
      "categories": [
        "cs.AR",
        "cs.AI"
      ],
      "primary_category": "cs.AR",
      "comment": "6 pages, 6 figures, ICAIIC 2024",
      "pdf_url": "http://arxiv.org/pdf/2407.02622v1",
      "published_date": "2024-07-02 19:25:05 UTC",
      "updated_date": "2024-07-02 19:25:05 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-19T02:44:51.826737"
    },
    {
      "arxiv_id": "2407.02613v1",
      "title": "Wildfire Autonomous Response and Prediction Using Cellular Automata (WARP-CA)",
      "title_zh": "翻译失败",
      "authors": [
        "Abdelrahman Ramadan"
      ],
      "abstract": "Wildfires pose a severe challenge to ecosystems and human settlements,\nexacerbated by climate change and environmental factors. Traditional wildfire\nmodeling, while useful, often fails to adapt to the rapid dynamics of such\nevents. This report introduces the (Wildfire Autonomous Response and Prediction\nUsing Cellular Automata) WARP-CA model, a novel approach that integrates\nterrain generation using Perlin noise with the dynamism of Cellular Automata\n(CA) to simulate wildfire spread. We explore the potential of Multi-Agent\nReinforcement Learning (MARL) to manage wildfires by simulating autonomous\nagents, such as UAVs and UGVs, within a collaborative framework. Our\nmethodology combines world simulation techniques and investigates emergent\nbehaviors in MARL, focusing on efficient wildfire suppression and considering\ncritical environmental factors like wind patterns and terrain features.",
      "tldr_zh": "该论文针对野火对生态和人类定居点的威胁，提出了一种新型模型WARP-CA，用于野火的自主响应和预测，以克服传统模型对快速动态的适应不足。WARP-CA 结合Perlin noise生成地形和Cellular Automata (CA)模拟野火传播，同时利用Multi-Agent Reinforcement Learning (MARL)模拟自主代理如UAVs和UGVs，在协作框架中实现高效野火抑制。研究重点考察了MARL的紧急行为和环境因素（如风模式和地形特征），为改进野火管理提供了潜在解决方案。",
      "categories": [
        "cs.AI",
        "cs.MA",
        "cs.NE",
        "cs.RO"
      ],
      "primary_category": "cs.AI",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2407.02613v1",
      "published_date": "2024-07-02 19:01:59 UTC",
      "updated_date": "2024-07-02 19:01:59 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-19T02:45:05.198780"
    },
    {
      "arxiv_id": "2407.02604v2",
      "title": "D-Rax: Domain-specific Radiologic assistant leveraging multi-modal data and eXpert model predictions",
      "title_zh": "翻译失败",
      "authors": [
        "Hareem Nisar",
        "Syed Muhammad Anwar",
        "Zhifan Jiang",
        "Abhijeet Parida",
        "Ramon Sanchez-Jacob",
        "Vishwesh Nath",
        "Holger R. Roth",
        "Marius George Linguraru"
      ],
      "abstract": "Large vision language models (VLMs) have progressed incredibly from research\nto applicability for general-purpose use cases. LLaVA-Med, a pioneering large\nlanguage and vision assistant for biomedicine, can perform multi-modal\nbiomedical image and data analysis to provide a natural language interface for\nradiologists. While it is highly generalizable and works with multi-modal data,\nit is currently limited by well-known challenges that exist in the large\nlanguage model space. Hallucinations and imprecision in responses can lead to\nmisdiagnosis which currently hinder the clinical adaptability of VLMs. To\ncreate precise, user-friendly models in healthcare, we propose D-Rax -- a\ndomain-specific, conversational, radiologic assistance tool that can be used to\ngain insights about a particular radiologic image. In this study, we enhance\nthe conversational analysis of chest X-ray (CXR) images to support radiological\nreporting, offering comprehensive insights from medical imaging and aiding in\nthe formulation of accurate diagnosis. D-Rax is achieved by fine-tuning the\nLLaVA-Med architecture on our curated enhanced instruction-following data,\ncomprising of images, instructions, as well as disease diagnosis and\ndemographic predictions derived from MIMIC-CXR imaging data, CXR-related visual\nquestion answer (VQA) pairs, and predictive outcomes from multiple expert AI\nmodels. We observe statistically significant improvement in responses when\nevaluated for both open and close-ended conversations. Leveraging the power of\nstate-of-the-art diagnostic models combined with VLMs, D-Rax empowers\nclinicians to interact with medical images using natural language, which could\npotentially streamline their decision-making process, enhance diagnostic\naccuracy, and conserve their time.",
      "tldr_zh": "本研究提出D-Rax，一种领域特定的放射学助手，利用多模态数据和专家模型预测来提升视觉语言模型(VLMs)的精确性，针对LLaVA-Med的幻觉和响应不精确问题。D-Rax通过微调LLaVA-Med架构，使用从MIMIC-CXR数据中提取的增强指令数据（包括图像、指令、疾病诊断、人口统计预测、CXR相关视觉问答(VQA)对以及专家AI模型输出），实现对胸部X光(CXR)图像的对话式分析，支持放射学报告。实验结果显示，D-Rax在开放和封闭式对话中响应质量有统计显著改善，有助于放射科医生通过自然语言交互提高诊断准确性、简化决策并节省时间。",
      "categories": [
        "cs.AI",
        "cs.CL",
        "cs.LG",
        "eess.IV"
      ],
      "primary_category": "cs.AI",
      "comment": "accepted to the MICCAI 2024 Second International Workshop on\n  Foundation Models for General Medical AI",
      "pdf_url": "http://arxiv.org/pdf/2407.02604v2",
      "published_date": "2024-07-02 18:43:10 UTC",
      "updated_date": "2024-08-02 13:45:53 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-19T02:45:16.341898"
    },
    {
      "arxiv_id": "2407.02599v1",
      "title": "Meta 3D Gen",
      "title_zh": "翻译失败",
      "authors": [
        "Raphael Bensadoun",
        "Tom Monnier",
        "Yanir Kleiman",
        "Filippos Kokkinos",
        "Yawar Siddiqui",
        "Mahendra Kariya",
        "Omri Harosh",
        "Roman Shapovalov",
        "Benjamin Graham",
        "Emilien Garreau",
        "Animesh Karnewar",
        "Ang Cao",
        "Idan Azuri",
        "Iurii Makarov",
        "Eric-Tuan Le",
        "Antoine Toisoul",
        "David Novotny",
        "Oran Gafni",
        "Natalia Neverova",
        "Andrea Vedaldi"
      ],
      "abstract": "We introduce Meta 3D Gen (3DGen), a new state-of-the-art, fast pipeline for\ntext-to-3D asset generation. 3DGen offers 3D asset creation with high prompt\nfidelity and high-quality 3D shapes and textures in under a minute. It supports\nphysically-based rendering (PBR), necessary for 3D asset relighting in\nreal-world applications. Additionally, 3DGen supports generative retexturing of\npreviously generated (or artist-created) 3D shapes using additional textual\ninputs provided by the user. 3DGen integrates key technical components, Meta 3D\nAssetGen and Meta 3D TextureGen, that we developed for text-to-3D and\ntext-to-texture generation, respectively. By combining their strengths, 3DGen\nrepresents 3D objects simultaneously in three ways: in view space, in\nvolumetric space, and in UV (or texture) space. The integration of these two\ntechniques achieves a win rate of 68% with respect to the single-stage model.\nWe compare 3DGen to numerous industry baselines, and show that it outperforms\nthem in terms of prompt fidelity and visual quality for complex textual\nprompts, while being significantly faster.",
      "tldr_zh": "该论文介绍了 Meta 3D Gen (3DGen)，一个先进的文本到3D资产生成管道，能够在不到一分钟内创建高质量的3D形状和纹理，同时支持 physically-based rendering (PBR)，以适应真实世界的3D资产重照明应用。3DGen 整合了 Meta 3D AssetGen 和 Meta 3D TextureGen 组件，通过在 view space、volumetric space 和 UV space 中同时表示3D对象，并允许用户基于额外文本输入进行生成性再纹理化。实验结果显示，3DGen 在复杂文本提示的忠实度和视觉质量上优于多个行业基线模型，胜率达68%，且生成速度显著更快。",
      "categories": [
        "cs.CV",
        "cs.AI",
        "cs.GR",
        "cs.LG"
      ],
      "primary_category": "cs.CV",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2407.02599v1",
      "published_date": "2024-07-02 18:37:52 UTC",
      "updated_date": "2024-07-02 18:37:52 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-19T02:45:29.478746"
    },
    {
      "arxiv_id": "2407.02598v2",
      "title": "AutoSplat: Constrained Gaussian Splatting for Autonomous Driving Scene Reconstruction",
      "title_zh": "翻译失败",
      "authors": [
        "Mustafa Khan",
        "Hamidreza Fazlali",
        "Dhruv Sharma",
        "Tongtong Cao",
        "Dongfeng Bai",
        "Yuan Ren",
        "Bingbing Liu"
      ],
      "abstract": "Realistic scene reconstruction and view synthesis are essential for advancing\nautonomous driving systems by simulating safety-critical scenarios. 3D Gaussian\nSplatting excels in real-time rendering and static scene reconstructions but\nstruggles with modeling driving scenarios due to complex backgrounds, dynamic\nobjects, and sparse views. We propose AutoSplat, a framework employing Gaussian\nsplatting to achieve highly realistic reconstructions of autonomous driving\nscenes. By imposing geometric constraints on Gaussians representing the road\nand sky regions, our method enables multi-view consistent simulation of\nchallenging scenarios including lane changes. Leveraging 3D templates, we\nintroduce a reflected Gaussian consistency constraint to supervise both the\nvisible and unseen side of foreground objects. Moreover, to model the dynamic\nappearance of foreground objects, we estimate residual spherical harmonics for\neach foreground Gaussian. Extensive experiments on Pandaset and KITTI\ndemonstrate that AutoSplat outperforms state-of-the-art methods in scene\nreconstruction and novel view synthesis across diverse driving scenarios. Visit\nour project page at https://autosplat.github.io/.",
      "tldr_zh": "该研究提出 AutoSplat 框架，利用约束的 Gaussian Splatting 方法，实现自动驾驶场景的高真实性重建和视图合成，以应对复杂背景、动态物体和稀疏视图的挑战。通过对道路和天空区域施加几何约束，以及引入 reflected Gaussian consistency 约束和残差球谐函数估计，AutoSplat 确保了多视图一致性和前景物体的动态建模。在 Pandaset 和 KITTI 数据集上的实验显示，该框架在场景重建和新型视图合成方面优于现有最先进方法，为自动驾驶系统的安全模拟提供了重要进展。",
      "categories": [
        "cs.CV",
        "cs.AI"
      ],
      "primary_category": "cs.CV",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2407.02598v2",
      "published_date": "2024-07-02 18:36:50 UTC",
      "updated_date": "2024-07-04 02:18:54 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-19T02:45:42.070046"
    },
    {
      "arxiv_id": "2407.02489v1",
      "title": "Magic Insert: Style-Aware Drag-and-Drop",
      "title_zh": "Magic Insert：风格感知拖放",
      "authors": [
        "Nataniel Ruiz",
        "Yuanzhen Li",
        "Neal Wadhwa",
        "Yael Pritch",
        "Michael Rubinstein",
        "David E. Jacobs",
        "Shlomi Fruchter"
      ],
      "abstract": "We present Magic Insert, a method for dragging-and-dropping subjects from a\nuser-provided image into a target image of a different style in a physically\nplausible manner while matching the style of the target image. This work\nformalizes the problem of style-aware drag-and-drop and presents a method for\ntackling it by addressing two sub-problems: style-aware personalization and\nrealistic object insertion in stylized images. For style-aware personalization,\nour method first fine-tunes a pretrained text-to-image diffusion model using\nLoRA and learned text tokens on the subject image, and then infuses it with a\nCLIP representation of the target style. For object insertion, we use\nBootstrapped Domain Adaption to adapt a domain-specific photorealistic object\ninsertion model to the domain of diverse artistic styles. Overall, the method\nsignificantly outperforms traditional approaches such as inpainting. Finally,\nwe present a dataset, SubjectPlop, to facilitate evaluation and future progress\nin this area. Project page: https://magicinsert.github.io/",
      "tldr_zh": "本研究提出 Magic Insert，一种风格感知拖拽和放置方法，用于将用户提供的图像主题物理合理地插入到不同风格的目标图像中，同时匹配目标风格。该方法通过解决两个子问题：风格感知个性化（使用 LoRA 和 learned text tokens 微调预训练的 text-to-image diffusion model，并结合 CLIP 表示目标风格），以及真实对象插入（采用 Bootstrapped Domain Adaption 将特定领域的 photorealistic 对象插入模型适应到各种艺术风格）。实验结果显示，该方法显著优于传统方法如 inpainting；此外，研究还发布了一个数据集 SubjectPlop，以促进该领域的评估和未来发展。",
      "categories": [
        "cs.CV",
        "cs.AI",
        "cs.GR",
        "cs.HC",
        "cs.LG"
      ],
      "primary_category": "cs.CV",
      "comment": "Project page: https://magicinsert.github.io/",
      "pdf_url": "http://arxiv.org/pdf/2407.02489v1",
      "published_date": "2024-07-02 17:59:50 UTC",
      "updated_date": "2024-07-02 17:59:50 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-19T02:45:54.383786"
    },
    {
      "arxiv_id": "2407.02486v1",
      "title": "Neurocache: Efficient Vector Retrieval for Long-range Language Modeling",
      "title_zh": "翻译失败",
      "authors": [
        "Ali Safaya",
        "Deniz Yuret"
      ],
      "abstract": "This paper introduces Neurocache, an approach to extend the effective context\nsize of large language models (LLMs) using an external vector cache to store\nits past states. Like recent vector retrieval approaches, Neurocache uses an\nefficient k-nearest-neighbor (kNN) algorithm to retrieve relevant past states\nand incorporate them into the attention process. Neurocache improves upon\nprevious methods by (1) storing compressed states, which reduces cache size;\n(2) performing a single retrieval operation per token which increases inference\nspeed; and (3) extending the retrieval window to neighboring states, which\nimproves both language modeling and downstream task accuracy. Our experiments\nshow the effectiveness of Neurocache both for models trained from scratch and\nfor pre-trained models such as Llama2-7B and Mistral-7B when enhanced with the\ncache mechanism. We also compare Neurocache with text retrieval methods and\nshow improvements in single-document question-answering and few-shot learning\ntasks. We made the source code available under:\nhttps://github.com/alisafaya/neurocache",
      "tldr_zh": "这篇论文介绍了 Neurocache，一种高效方法，用于扩展大型语言模型 (LLMs) 的有效上下文大小，通过外部向量缓存存储压缩后的过去状态，并利用 k-最近邻 (kNN) 算法进行单次检索操作，同时扩展检索窗口到相邻状态，以提升语言建模和下游任务性能。相比以往方法，Neurocache 显著降低了缓存大小、提高了推理速度，并在从零训练模型以及预训练模型如 Llama2-7B 和 Mistral-7B 上表现出色。实验结果显示，它在单文档问答和少样本学习任务中优于文本检索方法，并提供了开源代码以供进一步验证。",
      "categories": [
        "cs.CL",
        "cs.AI",
        "cs.LG"
      ],
      "primary_category": "cs.CL",
      "comment": "Long paper, published at the main conference NAACL'24",
      "pdf_url": "http://arxiv.org/pdf/2407.02486v1",
      "published_date": "2024-07-02 17:59:29 UTC",
      "updated_date": "2024-07-02 17:59:29 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-19T02:46:06.967249"
    },
    {
      "arxiv_id": "2407.02485v1",
      "title": "RankRAG: Unifying Context Ranking with Retrieval-Augmented Generation in LLMs",
      "title_zh": "翻译失败",
      "authors": [
        "Yue Yu",
        "Wei Ping",
        "Zihan Liu",
        "Boxin Wang",
        "Jiaxuan You",
        "Chao Zhang",
        "Mohammad Shoeybi",
        "Bryan Catanzaro"
      ],
      "abstract": "Large language models (LLMs) typically utilize the top-k contexts from a\nretriever in retrieval-augmented generation (RAG). In this work, we propose a\nnovel instruction fine-tuning framework RankRAG, which instruction-tunes a\nsingle LLM for the dual purpose of context ranking and answer generation in\nRAG. In particular, the instruction-tuned LLMs work surprisingly well by adding\na small fraction of ranking data into the training blend, and outperform\nexisting expert ranking models, including the same LLM exclusively fine-tuned\non a large amount of ranking data. For generation, we compare our model with\nmany strong baselines, including GPT-4-0613, GPT-4-turbo-2024-0409, and\nChatQA-1.5, an open-sourced model with the state-of-the-art performance on RAG\nbenchmarks. Specifically, our Llama3-RankRAG significantly outperforms\nLlama3-ChatQA-1.5 and GPT-4 models on nine knowledge-intensive benchmarks. In\naddition, it also performs comparably to GPT-4 on five RAG benchmarks in the\nbiomedical domain without instruction fine-tuning on biomedical data,\ndemonstrating its superb capability for generalization to new domains.",
      "tldr_zh": "该论文提出RankRAG框架，通过指令 fine-tuning 将上下文排名和检索增强生成(RAG)统一到一个大型语言模型(LLMs)中，仅需在训练中添加少量排名数据，即可实现双重功能，并优于专用的排名模型。实验结果显示，Llama3-RankRAG在九个知识密集型基准上显著超越Llama3-ChatQA-1.5和GPT-4模型，在生物医学领域的五个RAG基准上与GPT-4相当。总之，该方法展示了优秀的泛化能力，无需特定领域微调即可适应新领域。",
      "categories": [
        "cs.CL",
        "cs.AI",
        "cs.IR",
        "cs.LG"
      ],
      "primary_category": "cs.CL",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2407.02485v1",
      "published_date": "2024-07-02 17:59:17 UTC",
      "updated_date": "2024-07-02 17:59:17 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-19T02:46:19.058754"
    },
    {
      "arxiv_id": "2407.02483v2",
      "title": "MMedAgent: Learning to Use Medical Tools with Multi-modal Agent",
      "title_zh": "MMedAgent：利用多模态代理学习使用医疗",
      "authors": [
        "Binxu Li",
        "Tiankai Yan",
        "Yuanting Pan",
        "Jie Luo",
        "Ruiyang Ji",
        "Jiayuan Ding",
        "Zhe Xu",
        "Shilong Liu",
        "Haoyu Dong",
        "Zihao Lin",
        "Yixin Wang"
      ],
      "abstract": "Multi-Modal Large Language Models (MLLMs), despite being successful, exhibit\nlimited generality and often fall short when compared to specialized models.\nRecently, LLM-based agents have been developed to address these challenges by\nselecting appropriate specialized models as tools based on user inputs.\nHowever, such advancements have not been extensively explored within the\nmedical domain. To bridge this gap, this paper introduces the first agent\nexplicitly designed for the medical field, named \\textbf{M}ulti-modal\n\\textbf{Med}ical \\textbf{Agent} (MMedAgent). We curate an instruction-tuning\ndataset comprising six medical tools solving seven tasks across five\nmodalities, enabling the agent to choose the most suitable tools for a given\ntask. Comprehensive experiments demonstrate that MMedAgent achieves superior\nperformance across a variety of medical tasks compared to state-of-the-art\nopen-source methods and even the closed-source model, GPT-4o. Furthermore,\nMMedAgent exhibits efficiency in updating and integrating new medical tools.\nCodes and models are all available.",
      "tldr_zh": "该论文提出 MMedAgent，这是一个专为医疗领域设计的多模态代理，用于学习选择合适的医疗工具，以克服 Multi-Modal Large Language Models (MLLMs) 的通用性不足问题。\n研究团队构建了一个指令微调数据集，包括六个医疗工具、七个任务和五种模态，训练代理根据用户输入选择最佳工具。\n实验结果显示，MMedAgent 在多种医疗任务上优于最先进开源方法和闭源模型 GPT-4o，并在更新与集成新工具方面表现出高效性。\n代码和模型已公开可用。",
      "categories": [
        "cs.CL",
        "cs.AI"
      ],
      "primary_category": "cs.CL",
      "comment": "EMNLP 2024",
      "pdf_url": "http://arxiv.org/pdf/2407.02483v2",
      "published_date": "2024-07-02 17:58:23 UTC",
      "updated_date": "2024-10-05 06:36:33 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-19T02:46:31.535576"
    },
    {
      "arxiv_id": "2407.02474v1",
      "title": "Free Energy in a Circumplex Model of Emotion",
      "title_zh": "翻译失败",
      "authors": [
        "Candice Pattisapu",
        "Tim Verbelen",
        "Riddhi J. Pitliya",
        "Alex B. Kiefer",
        "Mahault Albarracin"
      ],
      "abstract": "Previous active inference accounts of emotion translate fluctuations in free\nenergy to a sense of emotion, mainly focusing on valence. However, in affective\nscience, emotions are often represented as multi-dimensional. In this paper, we\npropose to adopt a Circumplex Model of emotion by mapping emotions into a\ntwo-dimensional spectrum of valence and arousal. We show how one can derive a\nvalence and arousal signal from an agent's expected free energy, relating\narousal to the entropy of posterior beliefs and valence to utility less\nexpected utility. Under this formulation, we simulate artificial agents engaged\nin a search task. We show that the manipulation of priors and object presence\nresults in commonsense variability in emotional states.",
      "tldr_zh": "本研究扩展了 active inference 模型，将自由能（free energy）的波动应用于 Circumplex Model，将情绪映射到效价（valence）和唤醒（arousal）的二维光谱中。作者从代理的预期自由能（expected free energy）中推导出唤醒信号（与后验信念的熵相关）和效价信号（与效用减去预期效用相关）。通过模拟代理在搜索任务中的行为，实验显示操纵先验（priors）和对象存在能产生符合常识的情绪状态变化，为多维度情绪建模提供了新见解。",
      "categories": [
        "cs.AI"
      ],
      "primary_category": "cs.AI",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2407.02474v1",
      "published_date": "2024-07-02 17:52:25 UTC",
      "updated_date": "2024-07-02 17:52:25 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-19T02:46:42.054657"
    },
    {
      "arxiv_id": "2407.02466v3",
      "title": "PWM: Policy Learning with Multi-Task World Models",
      "title_zh": "翻译失败",
      "authors": [
        "Ignat Georgiev",
        "Varun Giridhar",
        "Nicklas Hansen",
        "Animesh Garg"
      ],
      "abstract": "Reinforcement Learning (RL) has made significant strides in complex tasks but\nstruggles in multi-task settings with different embodiments. World model\nmethods offer scalability by learning a simulation of the environment but often\nrely on inefficient gradient-free optimization methods for policy extraction.\nIn contrast, gradient-based methods exhibit lower variance but fail to handle\ndiscontinuities. Our work reveals that well-regularized world models can\ngenerate smoother optimization landscapes than the actual dynamics,\nfacilitating more effective first-order optimization. We introduce Policy\nlearning with multi-task World Models (PWM), a novel model-based RL algorithm\nfor continuous control. Initially, the world model is pre-trained on offline\ndata, and then policies are extracted from it using first-order optimization in\nless than 10 minutes per task. PWM effectively solves tasks with up to 152\naction dimensions and outperforms methods that use ground-truth dynamics.\nAdditionally, PWM scales to an 80-task setting, achieving up to 27% higher\nrewards than existing baselines without relying on costly online planning.\nVisualizations and code are available at https://www.imgeorgiev.com/pwm/.",
      "tldr_zh": "本研究探讨了强化学习（RL）在多任务环境中的挑战，提出了一种基于世界模型的算法 PWM，以解决传统方法的优化效率和不连续性问题。PWM 通过在离线数据上预训练世界模型，然后使用第一阶优化快速提取策略（每任务不到 10 分钟），实现了对高达 152 维动作的连续控制任务。实验结果显示，PWM 在 80 任务设置中比现有基线提升 27% 的奖励，且不依赖昂贵的在线规划，提供更高效的性能。",
      "categories": [
        "cs.LG",
        "cs.AI",
        "cs.RO"
      ],
      "primary_category": "cs.LG",
      "comment": "Visualizations and code available at https://www.imgeorgiev.com/pwm",
      "pdf_url": "http://arxiv.org/pdf/2407.02466v3",
      "published_date": "2024-07-02 17:47:03 UTC",
      "updated_date": "2025-02-24 06:56:00 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-19T02:46:53.961947"
    },
    {
      "arxiv_id": "2407.02465v1",
      "title": "Belief sharing: a blessing or a curse",
      "title_zh": "翻译失败",
      "authors": [
        "Ozan Catal",
        "Toon Van de Maele",
        "Riddhi J. Pitliya",
        "Mahault Albarracin",
        "Candice Pattisapu",
        "Tim Verbelen"
      ],
      "abstract": "When collaborating with multiple parties, communicating relevant information\nis of utmost importance to efficiently completing the tasks at hand. Under\nactive inference, communication can be cast as sharing beliefs between\nfree-energy minimizing agents, where one agent's beliefs get transformed into\nan observation modality for the other. However, the best approach for\ntransforming beliefs into observations remains an open question. In this paper,\nwe demonstrate that naively sharing posterior beliefs can give rise to the\nnegative social dynamics of echo chambers and self-doubt. We propose an\nalternate belief sharing strategy which mitigates these issues.",
      "tldr_zh": "该论文探讨了在多代理合作中，共享信念（belief sharing）的双重性：在 active inference 框架下，将通信视为自由能量最小化代理之间共享信念，但简单共享后验信念可能导致负面社会动态，如 echo chambers 和 self-doubt。作者通过实验证明，这种 naive 共享策略会放大回声室效应和自我怀疑问题。针对这些问题，他们提出了一种 alternate belief sharing strategy，以缓解这些负面影响并提升合作效率。",
      "categories": [
        "cs.AI"
      ],
      "primary_category": "cs.AI",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2407.02465v1",
      "published_date": "2024-07-02 17:46:42 UTC",
      "updated_date": "2024-07-02 17:46:42 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-19T02:47:06.843862"
    },
    {
      "arxiv_id": "2407.02552v1",
      "title": "RLHF Can Speak Many Languages: Unlocking Multilingual Preference Optimization for LLMs",
      "title_zh": "翻译失败",
      "authors": [
        "John Dang",
        "Arash Ahmadian",
        "Kelly Marchisio",
        "Julia Kreutzer",
        "Ahmet Üstün",
        "Sara Hooker"
      ],
      "abstract": "Preference optimization techniques have become a standard final stage for\ntraining state-of-art large language models (LLMs). However, despite widespread\nadoption, the vast majority of work to-date has focused on first-class citizen\nlanguages like English and Chinese. This captures a small fraction of the\nlanguages in the world, but also makes it unclear which aspects of current\nstate-of-the-art research transfer to a multilingual setting. In this work, we\nperform an exhaustive study to achieve a new state-of-the-art in aligning\nmultilingual LLMs. We introduce a novel, scalable method for generating\nhigh-quality multilingual feedback data to balance data coverage. We establish\nthe benefits of cross-lingual transfer and increased dataset size in preference\ntraining. Our preference-trained model achieves a 54.4% win-rate against Aya 23\n8B, the current state-of-the-art multilingual LLM in its parameter class, and a\n69.5% win-rate or higher against widely used models like Gemma-1.1-7B-it,\nLlama-3-8B-Instruct, Mistral-7B-Instruct-v0.3. As a result of our study, we\nexpand the frontier of alignment techniques to 23 languages covering half of\nthe world's population.",
      "tldr_zh": "该研究扩展了偏好优化（Preference Optimization）技术，将其应用于多语言设置，以提升大型语言模型（LLMs）的对齐性能。研究者引入了一种新颖、可扩展的方法来生成高质量的多语言反馈数据，并证明了跨语言转移和增加数据集规模在训练中的显著益处。结果，训练后的模型在与 Aya 23 8B 等现有最先进模型的比较中取得了 54.4% 的胜率，以及对 Gemma-1.1-7B-it 和其他模型的 69.5% 或更高胜率，最终将对齐技术扩展到 23 种语言，覆盖世界人口的一半。",
      "categories": [
        "cs.CL",
        "cs.AI",
        "cs.LG"
      ],
      "primary_category": "cs.CL",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2407.02552v1",
      "published_date": "2024-07-02 17:42:30 UTC",
      "updated_date": "2024-07-02 17:42:30 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-19T02:47:20.499797"
    },
    {
      "arxiv_id": "2407.02448v1",
      "title": "Ensemble of pre-trained language models and data augmentation for hate speech detection from Arabic tweets",
      "title_zh": "翻译失败",
      "authors": [
        "Kheir Eddine Daouadi",
        "Yaakoub Boualleg",
        "Kheir Eddine Haouaouchi"
      ],
      "abstract": "Today, hate speech classification from Arabic tweets has drawn the attention\nof several researchers. Many systems and techniques have been developed to\nresolve this classification task. Nevertheless, two of the major challenges\nfaced in this context are the limited performance and the problem of imbalanced\ndata. In this study, we propose a novel approach that leverages ensemble\nlearning and semi-supervised learning based on previously manually labeled. We\nconducted experiments on a benchmark dataset by classifying Arabic tweets into\n5 distinct classes: non-hate, general hate, racial, religious, or sexism.\nExperimental results show that: (1) ensemble learning based on pre-trained\nlanguage models outperforms existing related works; (2) Our proposed data\naugmentation improves the accuracy results of hate speech detection from Arabic\ntweets and outperforms existing related works. Our main contribution is the\nachievement of encouraging results in Arabic hate speech detection.",
      "tldr_zh": "这篇论文提出了一种针对阿拉伯语推文仇恨言论检测的新方法，结合Ensemble learning和Data augmentation，以解决性能有限和数据不平衡的挑战。方法利用Pre-trained language models进行集成学习，并采用Semi-supervised learning在基准数据集上将推文分类为non-hate、general hate、racial、religious或sexism五类。实验结果显示，该方法在准确率上优于现有相关工作，并通过数据增强进一步提升了检测性能，实现了显著的改进。",
      "categories": [
        "cs.CL",
        "cs.AI"
      ],
      "primary_category": "cs.CL",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2407.02448v1",
      "published_date": "2024-07-02 17:26:26 UTC",
      "updated_date": "2024-07-02 17:26:26 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-19T02:47:30.240774"
    },
    {
      "arxiv_id": "2407.02446v1",
      "title": "Predicting vs. Acting: A Trade-off Between World Modeling & Agent Modeling",
      "title_zh": "翻译失败",
      "authors": [
        "Margaret Li",
        "Weijia Shi",
        "Artidoro Pagnoni",
        "Peter West",
        "Ari Holtzman"
      ],
      "abstract": "RLHF-aligned LMs have shown unprecedented ability on both benchmarks and\nlong-form text generation, yet they struggle with one foundational task:\nnext-token prediction. As RLHF models become agent models aimed at interacting\nwith humans, they seem to lose their world modeling -- the ability to predict\nwhat comes next in arbitrary documents, which is the foundational training\nobjective of the Base LMs that RLHF adapts.\n  Besides empirically demonstrating this trade-off, we propose a potential\nexplanation: to perform coherent long-form generation, RLHF models restrict\nrandomness via implicit blueprints. In particular, RLHF models concentrate\nprobability on sets of anchor spans that co-occur across multiple generations\nfor the same prompt, serving as textual scaffolding but also limiting a model's\nability to generate documents that do not include these spans. We study this\ntrade-off on the most effective current agent models, those aligned with RLHF,\nwhile exploring why this may remain a fundamental trade-off between models that\nact and those that predict, even as alignment techniques improve.",
      "tldr_zh": "本文研究了 RLHF-aligned LMs 在世界建模（world modeling）和代理建模（agent modeling）之间的权衡，指出这些模型虽然在基准测试和长文本生成上表现出色，却在 next-token prediction 等基础任务上表现不佳。作者通过实证分析发现，RLHF 模型为实现连贯生成而采用隐式蓝图（implicit blueprints），即集中概率在锚点跨度（anchor spans）上作为文本支架，但这限制了模型生成不包含这些跨度的文档。最终，论文探讨了这一 trade-off 的根本性，即使对齐技术改进，也可能持续存在于行动模型和预测模型之间。",
      "categories": [
        "cs.CL",
        "cs.AI"
      ],
      "primary_category": "cs.CL",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2407.02446v1",
      "published_date": "2024-07-02 17:22:54 UTC",
      "updated_date": "2024-07-02 17:22:54 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-19T02:47:44.958587"
    },
    {
      "arxiv_id": "2407.02445v1",
      "title": "Meta 3D AssetGen: Text-to-Mesh Generation with High-Quality Geometry, Texture, and PBR Materials",
      "title_zh": "翻译失败",
      "authors": [
        "Yawar Siddiqui",
        "Tom Monnier",
        "Filippos Kokkinos",
        "Mahendra Kariya",
        "Yanir Kleiman",
        "Emilien Garreau",
        "Oran Gafni",
        "Natalia Neverova",
        "Andrea Vedaldi",
        "Roman Shapovalov",
        "David Novotny"
      ],
      "abstract": "We present Meta 3D AssetGen (AssetGen), a significant advancement in\ntext-to-3D generation which produces faithful, high-quality meshes with texture\nand material control. Compared to works that bake shading in the 3D object's\nappearance, AssetGen outputs physically-based rendering (PBR) materials,\nsupporting realistic relighting. AssetGen generates first several views of the\nobject with factored shaded and albedo appearance channels, and then\nreconstructs colours, metalness and roughness in 3D, using a deferred shading\nloss for efficient supervision. It also uses a sign-distance function to\nrepresent 3D shape more reliably and introduces a corresponding loss for direct\nshape supervision. This is implemented using fused kernels for high memory\nefficiency. After mesh extraction, a texture refinement transformer operating\nin UV space significantly improves sharpness and details. AssetGen achieves 17%\nimprovement in Chamfer Distance and 40% in LPIPS over the best concurrent work\nfor few-view reconstruction, and a human preference of 72% over the best\nindustry competitors of comparable speed, including those that support PBR.\nProject page with generated assets: https://assetgen.github.io",
      "tldr_zh": "本文介绍了Meta 3D AssetGen，一种先进的文本到网格生成模型，能够生成高质量的3D资产，包括精确的几何、纹理和PBR Materials，支持真实的重新照明。模型通过先生成对象的多个视图（包括阴影和反照率通道），然后使用Signed Distance Function (SDF)重建3D形状，并结合deferred shading loss和fused kernels进行高效监督，最后通过UV空间的纹理精炼transformer提升细节。实验显示，AssetGen在Chamfer Distance上改善17%、LPIPS上改善40%，并在人类偏好测试中获得72%的优势，优于同速行业竞争对手。",
      "categories": [
        "cs.CV",
        "cs.AI",
        "cs.GR"
      ],
      "primary_category": "cs.CV",
      "comment": "Project Page: https://assetgen.github.io",
      "pdf_url": "http://arxiv.org/pdf/2407.02445v1",
      "published_date": "2024-07-02 17:21:47 UTC",
      "updated_date": "2024-07-02 17:21:47 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-19T02:47:56.498894"
    },
    {
      "arxiv_id": "2407.02430v1",
      "title": "Meta 3D TextureGen: Fast and Consistent Texture Generation for 3D Objects",
      "title_zh": "翻译失败",
      "authors": [
        "Raphael Bensadoun",
        "Yanir Kleiman",
        "Idan Azuri",
        "Omri Harosh",
        "Andrea Vedaldi",
        "Natalia Neverova",
        "Oran Gafni"
      ],
      "abstract": "The recent availability and adaptability of text-to-image models has sparked\na new era in many related domains that benefit from the learned text priors as\nwell as high-quality and fast generation capabilities, one of which is texture\ngeneration for 3D objects. Although recent texture generation methods achieve\nimpressive results by using text-to-image networks, the combination of global\nconsistency, quality, and speed, which is crucial for advancing texture\ngeneration to real-world applications, remains elusive. To that end, we\nintroduce Meta 3D TextureGen: a new feedforward method comprised of two\nsequential networks aimed at generating high-quality and globally consistent\ntextures for arbitrary geometries of any complexity degree in less than 20\nseconds. Our method achieves state-of-the-art results in quality and speed by\nconditioning a text-to-image model on 3D semantics in 2D space and fusing them\ninto a complete and high-resolution UV texture map, as demonstrated by\nextensive qualitative and quantitative evaluations. In addition, we introduce a\ntexture enhancement network that is capable of up-scaling any texture by an\narbitrary ratio, producing 4k pixel resolution textures.",
      "tldr_zh": "本研究提出了Meta 3D TextureGen，一种快速且一致的纹理生成方法，由两个顺序网络组成，用于为任意复杂度的3D对象几何形状生成高质量、全球一致的纹理，生成时间不到20秒。该方法通过在2D空间中基于3D语义对text-to-image模型进行条件化，并融合成完整的UV texture map，解决了现有方法的质量和速度问题。实验显示，该方法在定性和定量评估中达到了state-of-the-art结果，并引入了一个texture enhancement network，能将纹理放大任意比例，产生4k像素分辨率的纹理。",
      "categories": [
        "cs.CV",
        "cs.AI",
        "cs.GR",
        "cs.LG"
      ],
      "primary_category": "cs.CV",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2407.02430v1",
      "published_date": "2024-07-02 17:04:34 UTC",
      "updated_date": "2024-07-02 17:04:34 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-19T02:48:08.730919"
    },
    {
      "arxiv_id": "2407.02425v1",
      "title": "Reinforcement Learning and Machine ethics:a systematic review",
      "title_zh": "强化学习与机器伦理：一项系统综述",
      "authors": [
        "Ajay Vishwanath",
        "Louise A. Dennis",
        "Marija Slavkovik"
      ],
      "abstract": "Machine ethics is the field that studies how ethical behaviour can be\naccomplished by autonomous systems. While there exist some systematic reviews\naiming to consolidate the state of the art in machine ethics prior to 2020,\nthese tend to not include work that uses reinforcement learning agents as\nentities whose ethical behaviour is to be achieved. The reason for this is that\nonly in the last years we have witnessed an increase in machine ethics studies\nwithin reinforcement learning. We present here a systematic review of\nreinforcement learning for machine ethics and machine ethics within\nreinforcement learning. Additionally, we highlight trends in terms of ethics\nspecifications, components and frameworks of reinforcement learning, and\nenvironments used to result in ethical behaviour. Our systematic review aims to\nconsolidate the work in machine ethics and reinforcement learning thus\ncompleting the gap in the state of the art machine ethics landscape",
      "tldr_zh": "这篇论文对强化学习（Reinforcement Learning）和机器伦理（Machine Ethics）进行了系统综述，填补了现有综述在这一交叉领域的空白，特别是关注使用强化学习代理实现伦理行为的近期研究。论文分析了伦理规范、强化学习组件、框架以及用于产生伦理行为的环境等关键趋势。最终，该综述整合了相关工作，为机器伦理领域的未来发展提供了全面的参考基础。",
      "categories": [
        "cs.AI"
      ],
      "primary_category": "cs.AI",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2407.02425v1",
      "published_date": "2024-07-02 16:54:00 UTC",
      "updated_date": "2024-07-02 16:54:00 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-19T02:48:18.485282"
    },
    {
      "arxiv_id": "2407.02403v2",
      "title": "Face Reconstruction Transfer Attack as Out-of-Distribution Generalization",
      "title_zh": "面部重建转移攻击作为分布外泛化",
      "authors": [
        "Yoon Gyo Jung",
        "Jaewoo Park",
        "Xingbo Dong",
        "Hojin Park",
        "Andrew Beng Jin Teoh",
        "Octavia Camps"
      ],
      "abstract": "Understanding the vulnerability of face recognition systems to malicious\nattacks is of critical importance. Previous works have focused on\nreconstructing face images that can penetrate a targeted verification system.\nEven in the white-box scenario, however, naively reconstructed images\nmisrepresent the identity information, hence the attacks are easily neutralized\nonce the face system is updated or changed. In this paper, we aim to\nreconstruct face images which are capable of transferring face attacks on\nunseen encoders. We term this problem as Face Reconstruction Transfer Attack\n(FRTA) and show that it can be formulated as an out-of-distribution (OOD)\ngeneralization problem. Inspired by its OOD nature, we propose to solve FRTA by\nAveraged Latent Search and Unsupervised Validation with pseudo target (ALSUV).\nTo strengthen the reconstruction attack on OOD unseen encoders, ALSUV\nreconstructs the face by searching the latent of amortized generator StyleGAN2\nthrough multiple latent optimization, latent optimization trajectory averaging,\nand unsupervised validation with a pseudo target. We demonstrate the efficacy\nand generalization of our method on widely used face datasets, accompanying it\nwith extensive ablation studies and visually, qualitatively, and quantitatively\nanalyses. The source code will be released.",
      "tldr_zh": "本研究探讨了面部识别系统的漏洞，提出Face Reconstruction Transfer Attack (FRTA)作为一种Out-of-Distribution (OOD)泛化问题，旨在重建能转移攻击到未见编码器的面部图像，以避免现有攻击被系统更新而失效。作者引入ALSUV方法，通过多重潜在优化、潜在优化轨迹平均以及使用伪目标的无监督验证，对基于StyleGAN2的生成器进行潜在空间搜索，从而增强对OOD场景的攻击效果。在常用面部数据集上的实验证明了ALSUV的有效性和泛化性，并通过消融研究和定性/定量分析验证了其性能，源代码将公开发布。",
      "categories": [
        "cs.CV",
        "cs.AI"
      ],
      "primary_category": "cs.CV",
      "comment": "Accepted to ECCV2024",
      "pdf_url": "http://arxiv.org/pdf/2407.02403v2",
      "published_date": "2024-07-02 16:21:44 UTC",
      "updated_date": "2024-09-12 17:57:52 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-19T02:48:30.709611"
    },
    {
      "arxiv_id": "2407.02402v1",
      "title": "Assessing the Code Clone Detection Capability of Large Language Models",
      "title_zh": "评估大型语言模型的代码克隆检测能力",
      "authors": [
        "Zixian Zhang",
        "Takfarinas Saber"
      ],
      "abstract": "This study aims to assess the performance of two advanced Large Language\nModels (LLMs), GPT-3.5 and GPT-4, in the task of code clone detection. The\nevaluation involves testing the models on a variety of code pairs of different\nclone types and levels of similarity, sourced from two datasets: BigCloneBench\n(human-made) and GPTCloneBench (LLM-generated). Findings from the study\nindicate that GPT-4 consistently surpasses GPT-3.5 across all clone types. A\ncorrelation was observed between the GPTs' accuracy at identifying code clones\nand code similarity, with both GPT models exhibiting low effectiveness in\ndetecting the most complex Type-4 code clones. Additionally, GPT models\ndemonstrate a higher performance identifying code clones in LLM-generated code\ncompared to humans-generated code. However, they do not reach impressive\naccuracy. These results emphasize the imperative for ongoing enhancements in\nLLM capabilities, particularly in the recognition of code clones and in\nmitigating their predisposition towards self-generated code clones--which is\nlikely to become an issue as software engineers are more numerous to leverage\nLLM-enabled code generation and code refactoring tools.",
      "tldr_zh": "这篇论文评估了大型语言模型 GPT-3.5 和 GPT-4 在代码克隆检测方面的性能，使用 BigCloneBench（人类生成）和 GPTCloneBench（LLM 生成）数据集测试不同克隆类型和相似度。结果表明，GPT-4 在所有克隆类型上均优于 GPT-3.5，且检测准确率与代码相似度正相关，但对 Type-4 code clones 的识别效果较差。论文强调，虽然 GPT 模型在 LLM 生成代码上表现更好，但整体准确率不高，需要进一步提升其能力以应对软件工程中日益依赖 LLM 的趋势。",
      "categories": [
        "cs.SE",
        "cs.AI"
      ],
      "primary_category": "cs.SE",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2407.02402v1",
      "published_date": "2024-07-02 16:20:44 UTC",
      "updated_date": "2024-07-02 16:20:44 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-19T02:48:43.343031"
    },
    {
      "arxiv_id": "2407.02551v2",
      "title": "Breach By A Thousand Leaks: Unsafe Information Leakage in `Safe' AI Responses",
      "title_zh": "翻译失败",
      "authors": [
        "David Glukhov",
        "Ziwen Han",
        "Ilia Shumailov",
        "Vardan Papyan",
        "Nicolas Papernot"
      ],
      "abstract": "Vulnerability of Frontier language models to misuse and jailbreaks has\nprompted the development of safety measures like filters and alignment training\nin an effort to ensure safety through robustness to adversarially crafted\nprompts. We assert that robustness is fundamentally insufficient for ensuring\nsafety goals, and current defenses and evaluation methods fail to account for\nrisks of dual-intent queries and their composition for malicious goals. To\nquantify these risks, we introduce a new safety evaluation framework based on\nimpermissible information leakage of model outputs and demonstrate how our\nproposed question-decomposition attack can extract dangerous knowledge from a\ncensored LLM more effectively than traditional jailbreaking. Underlying our\nproposed evaluation method is a novel information-theoretic threat model of\ninferential adversaries, distinguished from security adversaries, such as\njailbreaks, in that success is measured by inferring impermissible knowledge\nfrom victim outputs as opposed to forcing explicitly impermissible outputs from\nthe victim. Through our information-theoretic framework, we show that to ensure\nsafety against inferential adversaries, defense mechanisms must ensure\ninformation censorship, bounding the leakage of impermissible information.\nHowever, we prove that such defenses inevitably incur a safety-utility\ntrade-off.",
      "tldr_zh": "该论文揭示了现有AI安全措施（如过滤器和对齐训练）在面对双重意图查询及其组合时存在的不足，无法有效防范信息泄露风险。作者提出了一种基于非法信息泄露的安全评估框架，并引入question-decomposition攻击，该攻击比传统jailbreaking更有效地从审查过的LLM中提取危险知识。基于信息理论威胁模型，论文证明防御机制需通过信息审查来限制inferential adversaries的泄露，但这不可避免地导致safety-utility trade-off，强调了AI安全与实用性的权衡。",
      "categories": [
        "cs.CR",
        "cs.AI",
        "cs.CY"
      ],
      "primary_category": "cs.CR",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2407.02551v2",
      "published_date": "2024-07-02 16:19:25 UTC",
      "updated_date": "2024-10-30 17:16:44 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-19T02:48:55.387801"
    },
    {
      "arxiv_id": "2407.02389v1",
      "title": "SafaRi:Adaptive Sequence Transformer for Weakly Supervised Referring Expression Segmentation",
      "title_zh": "翻译失败",
      "authors": [
        "Sayan Nag",
        "Koustava Goswami",
        "Srikrishna Karanam"
      ],
      "abstract": "Referring Expression Segmentation (RES) aims to provide a segmentation mask\nof the target object in an image referred to by the text (i.e., referring\nexpression). Existing methods require large-scale mask annotations. Moreover,\nsuch approaches do not generalize well to unseen/zero-shot scenarios. To\naddress the aforementioned issues, we propose a weakly-supervised bootstrapping\narchitecture for RES with several new algorithmic innovations. To the best of\nour knowledge, ours is the first approach that considers only a fraction of\nboth mask and box annotations (shown in Figure 1 and Table 1) for training. To\nenable principled training of models in such low-annotation settings, improve\nimage-text region-level alignment, and further enhance spatial localization of\nthe target object in the image, we propose Cross-modal Fusion with Attention\nConsistency module. For automatic pseudo-labeling of unlabeled samples, we\nintroduce a novel Mask Validity Filtering routine based on a spatially aware\nzero-shot proposal scoring approach. Extensive experiments show that with just\n30% annotations, our model SafaRi achieves 59.31 and 48.26 mIoUs as compared to\n58.93 and 48.19 mIoUs obtained by the fully-supervised SOTA method SeqTR\nrespectively on RefCOCO+@testA and RefCOCO+testB datasets. SafaRi also\noutperforms SeqTR by 11.7% (on RefCOCO+testA) and 19.6% (on RefCOCO+testB) in a\nfully-supervised setting and demonstrates strong generalization capabilities in\nunseen/zero-shot tasks.",
      "tldr_zh": "这篇论文提出 SafaRi，一种适应性序列 Transformer，用于弱监督的 Referring Expression Segmentation (RES)，旨在通过仅使用部分掩码和框标注来解决现有方法对大规模标注的依赖问题。论文创新性地引入 Cross-modal Fusion with Attention Consistency 模块，以提升图像-文本区域对齐和目标对象的空间定位，并开发 Mask Validity Filtering 例程，利用空间感知的零样本提案评分自动生成伪标签。实验结果显示，使用仅 30% 标注时，SafaRi 在 RefCOCO+ 数据集上分别达到 59.31 和 48.26 mIoUs，优于全监督 SOTA 方法 SeqTR；在全监督设置下，SafaRi 还提升了 11.7% 和 19.6%，并在零样本任务中展现出强泛化能力。",
      "categories": [
        "cs.CV",
        "cs.AI",
        "cs.CL",
        "cs.LG",
        "cs.MM"
      ],
      "primary_category": "cs.CV",
      "comment": "Accepted at ECCV 2024",
      "pdf_url": "http://arxiv.org/pdf/2407.02389v1",
      "published_date": "2024-07-02 16:02:25 UTC",
      "updated_date": "2024-07-02 16:02:25 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-19T02:49:08.925782"
    },
    {
      "arxiv_id": "2407.02362v2",
      "title": "Fast, Scalable, Energy-Efficient Non-element-wise Matrix Multiplication on FPGA",
      "title_zh": "翻译失败",
      "authors": [
        "Xuqi Zhu",
        "Huaizhi Zhang",
        "JunKyu Lee",
        "Jiacheng Zhu",
        "Chandrajit Pal",
        "Sangeet Saha",
        "Klaus D. McDonald-Maier",
        "Xiaojun Zhai"
      ],
      "abstract": "Modern Neural Network (NN) architectures heavily rely on vast numbers of\nmultiply-accumulate arithmetic operations, constituting the predominant\ncomputational cost. Therefore, this paper proposes a high-throughput, scalable\nand energy efficient non-element-wise matrix multiplication unit on FPGAs as a\nbasic component of the NNs. We firstly streamline inter-layer and intra-layer\nredundancies of MADDNESS algorithm, a LUT-based approximate matrix\nmultiplication, to design a fast, efficient scalable approximate matrix\nmultiplication module termed \"Approximate Multiplication Unit (AMU)\". The AMU\noptimizes LUT-based matrix multiplications further through dedicated memory\nmanagement and access design, decoupling computational overhead from input\nresolution and boosting FPGA-based NN accelerator efficiency significantly. The\nexperimental results show that using our AMU achieves up to 9x higher\nthroughput and 112x higher energy efficiency over the state-of-the-art\nsolutions for the FPGA-based Quantised Neural Network (QNN) accelerators.",
      "tldr_zh": "本论文提出了一种快速、可扩展且节能的非元素级矩阵乘法单元（Approximate Multiplication Unit, AMU），旨在提升FPGA-based Quantised Neural Network (QNN) 加速器的性能。作者基于MADDNESS算法优化了层间和层内冗余，并通过专用的内存管理和访问设计，进一步改进LUT-based approximate matrix multiplication，减少计算开销并与输入分辨率解耦。实验结果显示，该AMU相较于现有解决方案，提高了9倍吞吐量和112倍能量效率，为现代神经网络（NN）的硬件加速提供了高效基础。",
      "categories": [
        "cs.AR",
        "cs.AI",
        "cs.LG"
      ],
      "primary_category": "cs.AR",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2407.02362v2",
      "published_date": "2024-07-02 15:28:10 UTC",
      "updated_date": "2024-07-07 17:20:51 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-19T02:49:18.268900"
    },
    {
      "arxiv_id": "2407.02354v1",
      "title": "Talking to Machines: do you read me?",
      "title_zh": "翻译失败",
      "authors": [
        "Lina M. Rojas-Barahona"
      ],
      "abstract": "In this dissertation I would like to guide the reader to the research on\ndialogue but more precisely the research I have conducted during my career\nsince my PhD thesis. Starting from modular architectures with machine\nlearning/deep learning and reinforcement learning to end-to-end deep neural\nnetworks. Besides my work as research associate, I also present the work I have\nsupervised in the last years.\n  I review briefly the state of the art and highlight the open research\nproblems on conversational agents. Afterwards, I present my contribution to\nTask-Oriented Dialogues (TOD), both as research associate and as the industrial\nsupervisor of CIFRE theses. I discuss conversational QA. Particularly, I\npresent the work of two PhD candidates Thibault Cordier and Sebastien Montella;\nas well as the work of the young researcher Quentin Brabant. Finally, I present\nthe scientific project, where I discuss about Large Language Models (LLMs) for\nTask-Oriented Dialogue and Multimodal Task-Oriented Dialogue.",
      "tldr_zh": "这篇博士论文回顾了作者在对话系统研究领域的职业生涯，从模块化架构（如机器学习/深度学习和强化学习）到端到端深度神经网络。作者重点介绍了自己在Task-Oriented Dialogues (TOD)方面的贡献，包括作为研究助理和工业监督者的工作，以及监督的PhD候选人（如Thibault Cordier和Sebastien Montella）在conversational QA领域的成果。论文还讨论了Large Language Models (LLMs)在TOD和多模态TOD中的应用，并突出了对话代理的开放研究问题，为未来研究提供了宝贵见解。",
      "categories": [
        "cs.CL",
        "cs.AI",
        "cs.HC"
      ],
      "primary_category": "cs.CL",
      "comment": "French Doctoral Habilitation HDR manuscript:\n  https://hal.science/tel-04620199",
      "pdf_url": "http://arxiv.org/pdf/2407.02354v1",
      "published_date": "2024-07-02 15:19:46 UTC",
      "updated_date": "2024-07-02 15:19:46 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-19T02:49:31.287123"
    },
    {
      "arxiv_id": "2407.02340v1",
      "title": "RVISA: Reasoning and Verification for Implicit Sentiment Analysis",
      "title_zh": "RVISA：隐式情感分析的推理与验证",
      "authors": [
        "Wenna Lai",
        "Haoran Xie",
        "Guandong Xu",
        "Qing Li"
      ],
      "abstract": "With an increasing social demand for fine-grained sentiment analysis (SA),\nimplicit sentiment analysis (ISA) poses a significant challenge with the\nabsence of salient cue words in expressions. It necessitates reliable reasoning\nto understand how the sentiment is aroused and thus determine implicit\nsentiments. In the era of Large Language Models (LLMs), Encoder-Decoder (ED)\nLLMs have gained popularity to serve as backbone models for SA applications,\nconsidering impressive text comprehension and reasoning ability among diverse\ntasks. On the other hand, Decoder-only (DO) LLMs exhibit superior natural\nlanguage generation and in-context learning capabilities. However, their\nresponses may contain misleading or inaccurate information. To identify\nimplicit sentiment with reliable reasoning, this study proposes RVISA, a\ntwo-stage reasoning framework that harnesses the generation ability of DO LLMs\nand the reasoning ability of ED LLMs to train an enhanced reasoner.\nSpecifically, we adopt three-hop reasoning prompting to explicitly furnish\nsentiment elements as cues. The generated rationales are utilized to fine-tune\nan ED LLM into a skilled reasoner. Additionally, we develop a straightforward\nyet effective verification mechanism to ensure the reliability of the reasoning\nlearning. We evaluated the proposed method on two benchmark datasets and\nachieved state-of-the-art results in ISA performance.",
      "tldr_zh": "该研究针对隐式情感分析（Implicit Sentiment Analysis, ISA）的挑战，提出了一种名为 RVISA 的两阶段推理框架，以应对缺乏显性线索词的问题。RVISA 利用 Decoder-only (DO) LLMs 的生成能力结合 Encoder-Decoder (ED) LLMs 的推理能力，通过三跳推理提示（three-hop reasoning prompting）生成情感元素线索，并以此微调 ED LLMs 成为增强的推理器，同时引入验证机制确保推理可靠性。在两个基准数据集上的实验中，该方法实现了 ISA 任务的 state-of-the-art 性能，显著提升了情感理解的准确性。",
      "categories": [
        "cs.CL",
        "cs.AI"
      ],
      "primary_category": "cs.CL",
      "comment": "11 pages, 6 figures, and 4 tables",
      "pdf_url": "http://arxiv.org/pdf/2407.02340v1",
      "published_date": "2024-07-02 15:07:54 UTC",
      "updated_date": "2024-07-02 15:07:54 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-19T02:49:43.451380"
    },
    {
      "arxiv_id": "2407.02335v1",
      "title": "CALICO: Confident Active Learning with Integrated Calibration",
      "title_zh": "CALICO：带有集成校",
      "authors": [
        "Lorenzo S. Querol",
        "Hajime Nagahara",
        "Hideaki Hayashi"
      ],
      "abstract": "The growing use of deep learning in safety-critical applications, such as\nmedical imaging, has raised concerns about limited labeled data, where this\ndemand is amplified as model complexity increases, posing hurdles for domain\nexperts to annotate data. In response to this, active learning (AL) is used to\nefficiently train models with limited annotation costs. In the context of deep\nneural networks (DNNs), AL often uses confidence or probability outputs as a\nscore for selecting the most informative samples. However, modern DNNs exhibit\nunreliable confidence outputs, making calibration essential. We propose an AL\nframework that self-calibrates the confidence used for sample selection during\nthe training process, referred to as Confident Active Learning with Integrated\nCalibratiOn (CALICO). CALICO incorporates the joint training of a classifier\nand an energy-based model, instead of the standard softmax-based classifier.\nThis approach allows for simultaneous estimation of the input data distribution\nand the class probabilities during training, improving calibration without\nneeding an additional labeled dataset. Experimental results showcase improved\nclassification performance compared to a softmax-based classifier with fewer\nlabeled samples. Furthermore, the calibration stability of the model is\nobserved to depend on the prior class distribution of the data.",
      "tldr_zh": "该论文提出CALICO框架，即Confident Active Learning with Integrated Calibration，用于解决深度学习（DNNs）在标注数据有限的安全关键应用（如医疗成像）中的问题。CALICO通过联合训练分类器和能量-based模型来实现置信度自校准，从而在训练过程中同时估计输入数据分布和类概率，而无需额外标注数据集。实验结果显示，与标准的softmax-based分类器相比，CALICO在更少的标注样本下实现了更好的分类性能，且模型的校准稳定性取决于数据的事先类分布。",
      "categories": [
        "cs.LG",
        "cs.AI",
        "cs.CV"
      ],
      "primary_category": "cs.LG",
      "comment": "Accepted to ICANN2024",
      "pdf_url": "http://arxiv.org/pdf/2407.02335v1",
      "published_date": "2024-07-02 15:05:19 UTC",
      "updated_date": "2024-07-02 15:05:19 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-19T02:49:55.348740"
    },
    {
      "arxiv_id": "2407.02320v1",
      "title": "Exploring the Role of Transliteration in In-Context Learning for Low-resource Languages Written in Non-Latin Scripts",
      "title_zh": "翻译失败",
      "authors": [
        "Chunlan Ma",
        "Yihong Liu",
        "Haotian Ye",
        "Hinrich Schütze"
      ],
      "abstract": "Decoder-only large language models (LLMs) excel in high-resource languages\nacross various tasks through few-shot or even zero-shot in-context learning\n(ICL). However, their performance often does not transfer well to low-resource\nlanguages, especially those written in non-Latin scripts. Inspired by recent\nwork that leverages transliteration in encoder-only models, we investigate\nwhether transliteration is also effective in improving LLMs' performance for\nlow-resource languages written in non-Latin scripts. To this end, we propose\nthree prompt templates, where the target-language text is represented in (1)\nits original script, (2) Latin script, or (3) both. We apply these methods to\nseveral representative LLMs of different sizes on various tasks including text\nclassification and sequential labeling. Our findings show that the\neffectiveness of transliteration varies by task type and model size. For\ninstance, all models benefit from transliterations for sequential labeling\n(with increases of up to 25%).",
      "tldr_zh": "本文探讨了 transliteration 在 In-Context Learning (ICL) 中的作用，以提升 decoder-only large language models (LLMs) 在低资源、非拉丁脚本语言中的性能。研究者提出三种提示模板，包括使用原始脚本、拉丁脚本或两者结合来表示目标语言文本，并将其应用于文本分类和序列标注等任务。结果显示，transliteration 的有效性因任务类型和模型大小而异，例如在序列标注任务中，所有模型的性能均有显著提升（最高提高 25%）。这为改善 LLMs 在低资源语言中的适用性提供了新见解。",
      "categories": [
        "cs.CL",
        "cs.AI"
      ],
      "primary_category": "cs.CL",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2407.02320v1",
      "published_date": "2024-07-02 14:51:20 UTC",
      "updated_date": "2024-07-02 14:51:20 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-19T02:50:08.173756"
    },
    {
      "arxiv_id": "2407.02315v2",
      "title": "VFIMamba: Video Frame Interpolation with State Space Models",
      "title_zh": "VFIMamba：基于状态",
      "authors": [
        "Guozhen Zhang",
        "Chunxu Liu",
        "Yutao Cui",
        "Xiaotong Zhao",
        "Kai Ma",
        "Limin Wang"
      ],
      "abstract": "Inter-frame modeling is pivotal in generating intermediate frames for video\nframe interpolation (VFI). Current approaches predominantly rely on convolution\nor attention-based models, which often either lack sufficient receptive fields\nor entail significant computational overheads. Recently, Selective State Space\nModels (S6) have emerged, tailored specifically for long sequence modeling,\noffering both linear complexity and data-dependent modeling capabilities. In\nthis paper, we propose VFIMamba, a novel frame interpolation method for\nefficient and dynamic inter-frame modeling by harnessing the S6 model. Our\napproach introduces the Mixed-SSM Block (MSB), which initially rearranges\ntokens from adjacent frames in an interleaved fashion and subsequently applies\nmulti-directional S6 modeling. This design facilitates the efficient\ntransmission of information across frames while upholding linear complexity.\nFurthermore, we introduce a novel curriculum learning strategy that\nprogressively cultivates proficiency in modeling inter-frame dynamics across\nvarying motion magnitudes, fully unleashing the potential of the S6 model.\nExperimental findings showcase that our method attains state-of-the-art\nperformance across diverse benchmarks, particularly excelling in\nhigh-resolution scenarios. In particular, on the X-TEST dataset, VFIMamba\ndemonstrates a noteworthy improvement of 0.80 dB for 4K frames and 0.96 dB for\n2K frames.",
      "tldr_zh": "本文提出VFIMamba，一种基于State Space Models (S6)的视频帧插值 (VFI) 方法，旨在解决现有卷积或注意力模型在帧间建模中存在的视野不足和计算开销问题。核心创新包括引入Mixed-SSM Block (MSB)，通过交错排列相邻帧tokens并应用多方向S6建模，实现高效信息传输并保持线性复杂度；此外，还设计了新型课程学习策略，逐步训练模型处理不同运动幅度的帧间动态。实验结果显示，VFIMamba在多个基准上达到最先进性能，尤其在X-TEST数据集上，4K帧提升0.80 dB，2K帧提升0.96 dB。",
      "categories": [
        "cs.CV",
        "cs.AI"
      ],
      "primary_category": "cs.CV",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2407.02315v2",
      "published_date": "2024-07-02 14:48:18 UTC",
      "updated_date": "2024-10-10 03:15:55 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-19T02:50:21.878995"
    },
    {
      "arxiv_id": "2407.02309v1",
      "title": "Semantically Guided Representation Learning For Action Anticipation",
      "title_zh": "语义引导的表示学习用于动作预测",
      "authors": [
        "Anxhelo Diko",
        "Danilo Avola",
        "Bardh Prenkaj",
        "Federico Fontana",
        "Luigi Cinque"
      ],
      "abstract": "Action anticipation is the task of forecasting future activity from a\npartially observed sequence of events. However, this task is exposed to\nintrinsic future uncertainty and the difficulty of reasoning upon\ninterconnected actions. Unlike previous works that focus on extrapolating\nbetter visual and temporal information, we concentrate on learning action\nrepresentations that are aware of their semantic interconnectivity based on\nprototypical action patterns and contextual co-occurrences. To this end, we\npropose the novel Semantically Guided Representation Learning (S-GEAR)\nframework. S-GEAR learns visual action prototypes and leverages language models\nto structure their relationship, inducing semanticity. To gather insights on\nS-GEAR's effectiveness, we test it on four action anticipation benchmarks,\nobtaining improved results compared to previous works: +3.5, +2.7, and +3.5\nabsolute points on Top-1 Accuracy on Epic-Kitchen 55, EGTEA Gaze+ and 50\nSalads, respectively, and +0.8 on Top-5 Recall on Epic-Kitchens 100. We further\nobserve that S-GEAR effectively transfers the geometric associations between\nactions from language to visual prototypes. Finally, S-GEAR opens new research\nfrontiers in anticipation tasks by demonstrating the intricate impact of action\nsemantic interconnectivity.",
      "tldr_zh": "本研究针对行动预测（Action Anticipation）任务，提出了一种新框架Semantically Guided Representation Learning (S-GEAR)，旨在通过学习基于原型行动模式和上下文共现的语义互连行动表示，来应对未来不确定性和行动间关联的挑战。S-GEAR利用视觉行动原型并结合语言模型构建它们之间的语义关系，从而提升预测的准确性。在四个基准测试中，该框架表现出色：Epic-Kitchen 55、EGTEA Gaze+和50 Salads上的Top-1 Accuracy分别提高3.5、2.7和3.5点，Epic-Kitchens 100上的Top-5 Recall提高0.8点。该方法还证明了从语言到视觉原型的几何关联转移效果，并为行动语义互连性在预测任务中的应用开辟了新研究方向。",
      "categories": [
        "cs.CV",
        "cs.AI",
        "cs.LG"
      ],
      "primary_category": "cs.CV",
      "comment": "Accepted as a full paper at ECCV'24 with Paper ID #4140",
      "pdf_url": "http://arxiv.org/pdf/2407.02309v1",
      "published_date": "2024-07-02 14:44:01 UTC",
      "updated_date": "2024-07-02 14:44:01 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-19T02:50:32.584673"
    },
    {
      "arxiv_id": "2407.12828v2",
      "title": "Why Does New Knowledge Create Messy Ripple Effects in LLMs?",
      "title_zh": "为什么新知识会在LLMs中产生杂乱的涟漪效应？",
      "authors": [
        "Jiaxin Qin",
        "Zixuan Zhang",
        "Chi Han",
        "Manling Li",
        "Pengfei Yu",
        "Heng Ji"
      ],
      "abstract": "Extensive previous research has focused on post-training knowledge editing\n(KE) for language models (LMs) to ensure that knowledge remains accurate and\nup-to-date. One desired property and open question in KE is to let edited LMs\ncorrectly handle ripple effects, where LM is expected to answer its logically\nrelated knowledge accurately. In this paper, we answer the question of why most\nKE methods still create messy ripple effects. We conduct extensive analysis and\nidentify a salient indicator, GradSim, that effectively reveals when and why\nupdated knowledge ripples in LMs. GradSim is computed by the cosine similarity\nbetween gradients of the original fact and its related knowledge. We observe a\nstrong positive correlation between ripple effect performance and GradSim\nacross different LMs, KE methods, and evaluation metrics. Further\ninvestigations into three counter-intuitive failure cases (Negation,\nOver-Ripple, Multi-Lingual) of ripple effects demonstrate that these failures\nare often associated with very low GradSim. This finding validates that GradSim\nis an effective indicator of when knowledge ripples in LMs.",
      "tldr_zh": "本文研究了在语言模型(LMs)中，知识编辑(KE)方法为什么会导致混乱的ripple effects，即编辑后的模型无法准确处理逻辑相关知识的问题。通过广泛分析，研究者引入了GradSim指标，该指标基于原始事实和相关知识的梯度余弦相似度来评估ripple effects。结果显示，GradSim与ripple effects性能存在强正相关性，不同LMs、KE方法和评估指标均适用。进一步调查了Negation、Over-Ripple和Multi-Lingual等反直觉失败案例，发现这些问题往往与低GradSim相关，从而证明GradSim是预测知识传播的有效指标。",
      "categories": [
        "cs.CL",
        "cs.AI"
      ],
      "primary_category": "cs.CL",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2407.12828v2",
      "published_date": "2024-07-02 14:33:44 UTC",
      "updated_date": "2024-07-19 01:33:56 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-19T02:50:44.706885"
    },
    {
      "arxiv_id": "2407.02292v2",
      "title": "Strategic Demand-Planning in Wireless Networks: Can Generative-AI Save Spectrum and Energy?",
      "title_zh": "翻译失败",
      "authors": [
        "Berk Çiloğlu",
        "Görkem Berkay Koç",
        "Afsoon Alidadi Shamsabadi",
        "Metin Ozturk",
        "Halim Yanikomeroglu"
      ],
      "abstract": "Generative-AI (GenAI), a novel technology capable of producing various types\nof outputs, including text, images, and videos, offers significant potential\nfor wireless communications. This article introduces the concept of strategic\ndemand-planning through demand-labeling, demand-shaping, and\ndemand-rescheduling. Accordingly, GenAI is proposed as a powerful tool to\nfacilitate demand-shaping in wireless networks. More specifically, GenAI is\nused to compress and convert the content of various types (e.g., from a higher\nbandwidth mode to a lower one, such as from a video to text), which\nsubsequently enhances performance of wireless networks in various usage\nscenarios, such as cell-switching, user association and load balancing,\ninterference management, as well as disasters and unusual gatherings.\nTherefore, GenAI can serve a function in saving energy and spectrum in wireless\nnetworks. With recent advancements in AI, including sophisticated algorithms\nlike large language models and the development of more powerful hardware built\nexclusively for AI tasks, such as AI accelerators, the concept of\ndemand-planning, particularly demand-shaping through GenAI, becomes\nincreasingly relevant. Furthermore, recent efforts to make GenAI accessible on\ndevices, such as user terminals, make the implementation of this concept even\nmore straightforward and feasible.",
      "tldr_zh": "这篇论文探讨了Generative-AI (GenAI) 在无线网络中的战略需求规划，包括demand-labeling、demand-shaping 和 demand-rescheduling，以节省频谱和能量。研究提出使用 GenAI 作为工具，通过压缩和转换内容（如从视频转为文本）来实现需求塑造，从而提升网络性能在细胞切换、用户关联、负载平衡、干扰管理和突发事件中的表现。结果表明，GenAI 可以有效减少能量和频谱消耗，而随着大型语言模型和 AI 加速器的进展，这种方法变得更易于在用户终端实施。总的来说，该概念为无线网络的可持续发展提供了可行路径。",
      "categories": [
        "cs.NI",
        "cs.AI"
      ],
      "primary_category": "cs.NI",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2407.02292v2",
      "published_date": "2024-07-02 14:27:06 UTC",
      "updated_date": "2024-12-01 11:31:18 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-19T02:50:56.263640"
    },
    {
      "arxiv_id": "2407.02286v4",
      "title": "Rethinking Data Augmentation for Robust LiDAR Semantic Segmentation in Adverse Weather",
      "title_zh": "翻译失败",
      "authors": [
        "Junsung Park",
        "Kyungmin Kim",
        "Hyunjung Shim"
      ],
      "abstract": "Existing LiDAR semantic segmentation methods often struggle with performance\ndeclines in adverse weather conditions. Previous work has addressed this issue\nby simulating adverse weather or employing universal data augmentation during\ntraining. However, these methods lack a detailed analysis and understanding of\nhow adverse weather negatively affects LiDAR semantic segmentation performance.\nMotivated by this issue, we identified key factors of adverse weather and\nconducted a toy experiment to pinpoint the main causes of performance\ndegradation: (1) Geometric perturbation due to refraction caused by fog or\ndroplets in the air and (2) Point drop due to energy absorption and occlusions.\nBased on these findings, we propose new strategic data augmentation techniques.\nFirst, we introduced a Selective Jittering (SJ) that jitters points in the\nrandom range of depth (or angle) to mimic geometric perturbation. Additionally,\nwe developed a Learnable Point Drop (LPD) to learn vulnerable erase patterns\nwith a Deep Q-Learning Network to approximate the point drop phenomenon from\nadverse weather conditions. Without precise weather simulation, these\ntechniques strengthen the LiDAR semantic segmentation model by exposing it to\nvulnerable conditions identified by our data-centric analysis. Experimental\nresults confirmed the suitability of the proposed data augmentation methods for\nenhancing robustness against adverse weather conditions. Our method achieves a\nnotable 39.5 mIoU on the SemanticKITTI-to-SemanticSTF benchmark, improving the\nbaseline by 8.1\\%p and establishing a new state-of-the-art. Our code will be\nreleased at \\url{https://github.com/engineerJPark/LiDARWeather}.",
      "tldr_zh": "这篇论文重新审视了数据增强在恶劣天气条件下提升 LiDAR 语义分割鲁棒性的作用，识别出关键影响因素：几何扰动（如折射）和点丢失（如能量吸收）。作者提出两种新数据增强技术：Selective Jittering (SJ) 用于模拟几何扰动，以及 Learnable Point Drop (LPD) 通过 Deep Q-Learning Network 学习易受损的擦除模式，从而无需精确天气模拟即可强化模型。实验结果显示，该方法在 SemanticKITTI-to-SemanticSTF 基准上达到 39.5 mIoU，比基线提升 8.1%，确立了新的最先进水平。",
      "categories": [
        "cs.CV",
        "cs.AI"
      ],
      "primary_category": "cs.CV",
      "comment": "29 pages, 11 figures, accpeted in ECCV 2024",
      "pdf_url": "http://arxiv.org/pdf/2407.02286v4",
      "published_date": "2024-07-02 14:19:51 UTC",
      "updated_date": "2024-07-17 10:50:27 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-19T02:51:09.139126"
    },
    {
      "arxiv_id": "2407.02283v2",
      "title": "A Refreshed Similarity-based Upsampler for Direct High-Ratio Feature Upsampling",
      "title_zh": "一种刷新后的基于相似性的上采样器，用于直接高比率特征上采样",
      "authors": [
        "Minghao Zhou",
        "Hong Wang",
        "Yefeng Zheng",
        "Deyu Meng"
      ],
      "abstract": "Feature upsampling is a fundamental and indispensable ingredient of almost\nall current network structures for dense prediction tasks. Recently, a popular\nsimilarity-based feature upsampling pipeline has been proposed, which utilizes\na high-resolution feature as guidance to help upsample the low-resolution deep\nfeature based on their local similarity. Albeit achieving promising\nperformance, this pipeline has specific limitations: 1) HR query and LR key\nfeatures are not well aligned; 2) the similarity between query-key features is\ncomputed based on the fixed inner product form; 3) neighbor selection is\ncoarsely operated on LR features, resulting in mosaic artifacts. These\nshortcomings make the existing methods along this pipeline primarily applicable\nto hierarchical network architectures with iterative features as guidance and\nthey are not readily extended to a broader range of structures, especially for\na direct high-ratio upsampling. Against the issues, we meticulously optimize\nevery methodological design. Specifically, we firstly propose an explicitly\ncontrollable query-key feature alignment from both semantic-aware and\ndetail-aware perspectives, and then construct a parameterized paired central\ndifference convolution block for flexibly calculating the similarity between\nthe well-aligned query-key features. Besides, we develop a fine-grained\nneighbor selection strategy on HR features, which is simple yet effective for\nalleviating mosaic artifacts. Based on these careful designs, we systematically\nconstruct a refreshed similarity-based feature upsampling framework named\nReSFU. Extensive experiments substantiate that our proposed ReSFU is finely\napplicable to various types of architectures in a direct high-ratio upsampling\nmanner, and consistently achieves satisfactory performance on different dense\nprediction applications, showing superior generality and ease of deployment.",
      "tldr_zh": "该论文针对特征上sampling中的问题，优化了现有相似度-based 上sampling 管道的局限性，包括HR query 和 LR key 特征不匹配、固定内积形式的相似度计算，以及粗略邻居选择导致的马赛克伪影。研究团队提出显式可控的查询-关键特征对齐（从语义和细节角度）、参数化配对中心差分卷积块用于灵活计算相似度，以及在HR特征上的细粒度邻居选择策略。最终构建了名为ReSFU的刷新相似度-based 框架，实验证明其适用于各种架构的直接高比率上sampling，并在不同密集预测任务中实现显著性能提升，具有优秀的泛化性和部署便利性。",
      "categories": [
        "cs.CV",
        "cs.AI"
      ],
      "primary_category": "cs.CV",
      "comment": "Codes are available at https://github.com/zmhhmz/ReSFU",
      "pdf_url": "http://arxiv.org/pdf/2407.02283v2",
      "published_date": "2024-07-02 14:12:21 UTC",
      "updated_date": "2025-02-08 02:30:27 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-19T02:51:21.441736"
    },
    {
      "arxiv_id": "2407.02280v2",
      "title": "FedIA: Federated Medical Image Segmentation with Heterogeneous Annotation Completeness",
      "title_zh": "翻译失败",
      "authors": [
        "Yangyang Xiang",
        "Nannan Wu",
        "Li Yu",
        "Xin Yang",
        "Kwang-Ting Cheng",
        "Zengqiang Yan"
      ],
      "abstract": "Federated learning has emerged as a compelling paradigm for medical image\nsegmentation, particularly in light of increasing privacy concerns. However,\nmost of the existing research relies on relatively stringent assumptions\nregarding the uniformity and completeness of annotations across clients.\nContrary to this, this paper highlights a prevalent challenge in medical\npractice: incomplete annotations. Such annotations can introduce incorrectly\nlabeled pixels, potentially undermining the performance of neural networks in\nsupervised learning. To tackle this issue, we introduce a novel solution, named\nFedIA. Our insight is to conceptualize incomplete annotations as noisy data\n(i.e., low-quality data), with a focus on mitigating their adverse effects. We\nbegin by evaluating the completeness of annotations at the client level using a\ndesigned indicator. Subsequently, we enhance the influence of clients with more\ncomprehensive annotations and implement corrections for incomplete ones,\nthereby ensuring that models are trained on accurate data. Our method's\neffectiveness is validated through its superior performance on two extensively\nused medical image segmentation datasets, outperforming existing solutions. The\ncode is available at https://github.com/HUSTxyy/FedIA.",
      "tldr_zh": "本论文探讨了联邦学习(Federated learning)在医疗图像分割(Medical image segmentation)中的挑战，特别是客户端间注释不完整导致的噪声数据问题。FedIA方法通过设计指标评估客户端注释的完整性，增强高质量注释的影响，并对不完整注释进行修正，从而缓解噪声数据的负面效果。实验结果显示，FedIA在两个常用医疗图像分割数据集上表现出色，优于现有解决方案，并提供了开源代码（https://github.com/HUSTxyy/FedIA）。",
      "categories": [
        "cs.CV",
        "cs.AI"
      ],
      "primary_category": "cs.CV",
      "comment": "Early accepted by MICCAI 2024",
      "pdf_url": "http://arxiv.org/pdf/2407.02280v2",
      "published_date": "2024-07-02 14:08:55 UTC",
      "updated_date": "2024-07-03 07:12:34 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-19T02:51:33.033900"
    },
    {
      "arxiv_id": "2407.02275v1",
      "title": "Learning Paradigms and Modelling Methodologies for Digital Twins in Process Industry",
      "title_zh": "翻译失败",
      "authors": [
        "Michael Mayr",
        "Georgios C. Chasparis",
        "Josef Küng"
      ],
      "abstract": "Central to the digital transformation of the process industry are Digital\nTwins (DTs), virtual replicas of physical manufacturing systems that combine\nsensor data with sophisticated data-based or physics-based models, or a\ncombination thereof, to tackle a variety of industrial-relevant tasks like\nprocess monitoring, predictive control or decision support. The backbone of a\nDT, i.e. the concrete modelling methodologies and architectural frameworks\nsupporting these models, are complex, diverse and evolve fast, necessitating a\nthorough understanding of the latest state-of-the-art methods and trends to\nstay on top of a highly competitive market. From a research perspective,\ndespite the high research interest in reviewing various aspects of DTs,\nstructured literature reports specifically focusing on unravelling the utilized\nlearning paradigms (e.g. self-supervised learning) for DT-creation in the\nprocess industry are a novel contribution in this field. This study aims to\naddress these gaps by (1) systematically analyzing the modelling methodologies\n(e.g. Convolutional Neural Network, Encoder-Decoder, Hidden Markov Model) and\nparadigms (e.g. data-driven, physics-based, hybrid) used for DT-creation; (2)\nassessing the utilized learning strategies (e.g. supervised, unsupervised,\nself-supervised); (3) analyzing the type of modelling task (e.g. regression,\nclassification, clustering); and (4) identifying the challenges and research\ngaps, as well as, discuss potential resolutions provided.",
      "tldr_zh": "这篇论文探讨了数字孪生 (Digital Twins) 在过程工业中的建模方法和学习范式，旨在解决这些虚拟系统在过程监控、预测控制和决策支持中的应用挑战。研究通过系统分析包括 Convolutional Neural Network、Encoder-Decoder 和 Hidden Markov Model 等建模方法，以及数据-driven、physics-based 和 hybrid 范式，评估了监督学习、unsupervised learning 和 self-supervised learning 等策略。论文进一步分析了建模任务类型（如 regression、classification 和 clustering），并识别了关键挑战和研究空白，同时提出潜在解决方案，以推动数字孪生的创新发展。",
      "categories": [
        "cs.LG",
        "cs.AI"
      ],
      "primary_category": "cs.LG",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2407.02275v1",
      "published_date": "2024-07-02 14:05:10 UTC",
      "updated_date": "2024-07-02 14:05:10 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-19T02:51:45.817708"
    },
    {
      "arxiv_id": "2407.02269v1",
      "title": "IFTT-PIN: A Self-Calibrating PIN-Entry Method",
      "title_zh": "IFTT-PIN",
      "authors": [
        "Kathryn McConkey",
        "Talha Enes Ayranci",
        "Mohamed Khamis",
        "Jonathan Grizou"
      ],
      "abstract": "Personalising an interface to the needs and preferences of a user often\nincurs additional interaction steps. In this paper, we demonstrate a novel\nmethod that enables the personalising of an interface without the need for\nexplicit calibration procedures, via a process we call self-calibration. A\nsecond-order effect of self-calibration is that an outside observer cannot\neasily infer what a user is trying to achieve because they cannot interpret the\nuser's actions. To explore this security angle, we developed IFTT-PIN (If This\nThen PIN) as the first self-calibrating PIN-entry method. When using IFTT-PIN,\nusers are free to choose any button for any meaning without ever explicitly\ncommunicating their choice to the machine. IFTT-PIN infers both the user's PIN\nand their preferred button mapping at the same time. This paper presents the\nconcept, implementation, and interactive demonstrations of IFTT-PIN, as well as\nan evaluation against shoulder surfing attacks. Our study (N=24) shows that by\nadding self-calibration to an existing PIN entry method, IFTT-PIN statistically\nsignificantly decreased PIN attack decoding rate by ca. 8.5 times (p=1.1e-9),\nwhile only decreasing the PIN entry encoding rate by ca. 1.4 times (p=0.02),\nleading to a positive security-usability trade-off. IFTT-PIN's entry rate\nsignificantly improved 21 days after first exposure (p=3.6e-6) to the method,\nsuggesting self-calibrating interfaces are memorable despite using an initially\nundefined user interface. Self-calibration methods might lead to novel\nopportunities for interaction that are more inclusive and versatile, a\npotentially interesting challenge for the community. A short introductory video\nis available at https://youtu.be/pP5sfniNRns.",
      "tldr_zh": "本文提出了一种名为 IFTT-PIN 的自校准(self-calibration) PIN 输入方法，能够在无需显式校准过程的情况下个性化用户界面，同时增强安全性，因为外部观察者难以解读用户行为。IFTT-PIN 允许用户自由选择按钮映射，系统通过推断机制同时学习用户的 PIN 和偏好映射。研究结果显示，该方法将 PIN 攻击解码率降低了约 8.5 倍（p=1.1e-9），而输入编码率仅下降约 1.4 倍（p=0.02），并在 21 天后用户性能显著提升（p=3.6e-6）。这种自校准方法可能为更具包容性和多功能性的交互设计带来新机遇。",
      "categories": [
        "cs.HC",
        "cs.AI",
        "cs.CR",
        "cs.LG"
      ],
      "primary_category": "cs.HC",
      "comment": "arXiv admin note: text overlap with arXiv:2205.09534",
      "pdf_url": "http://arxiv.org/pdf/2407.02269v1",
      "published_date": "2024-07-02 13:58:28 UTC",
      "updated_date": "2024-07-02 13:58:28 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-19T02:51:59.576878"
    },
    {
      "arxiv_id": "2407.02268v2",
      "title": "Footprints of Data in a Classifier: Understanding the Privacy Risks and Solution Strategies",
      "title_zh": "数据在分类器中的足迹：理解隐私风险和解决方案策略",
      "authors": [
        "Payel Sadhukhan",
        "Tanujit Chakraborty"
      ],
      "abstract": "The widespread deployment of Artificial Intelligence (AI) across government\nand private industries brings both advancements and heightened privacy and\nsecurity concerns. Article 17 of the General Data Protection Regulation (GDPR)\nmandates the Right to Erasure, requiring data to be permanently removed from a\nsystem to prevent potential compromise. While existing research primarily\nfocuses on erasing sensitive data attributes, several passive data compromise\nmechanisms remain underexplored and unaddressed. One such issue arises from the\nresidual footprints of training data embedded within predictive models.\nPerformance disparities between test and training data can inadvertently reveal\nwhich data points were part of the training set, posing a privacy risk. This\nstudy examines how two fundamental aspects of classifier systems - training\ndata quality and classifier training methodology - contribute to privacy\nvulnerabilities. Our theoretical analysis demonstrates that classifiers exhibit\nuniversal vulnerability under conditions of data imbalance and distributional\nshifts. Empirical findings reinforce our theoretical results, highlighting the\nsignificant role of training data quality in classifier susceptibility.\nAdditionally, our study reveals that a classifier's operational mechanism and\narchitectural design impact its vulnerability. We further investigate\nmitigation strategies through data obfuscation techniques and analyze their\nimpact on both privacy and classification performance. To aid practitioners, we\nintroduce a privacy-performance trade-off index, providing a structured\napproach to balancing privacy protection with model effectiveness. The findings\noffer valuable insights for selecting classifiers and curating training data in\ndiverse real-world applications.",
      "tldr_zh": "该研究探讨了分类器中训练数据残留痕迹所带来的隐私风险，特别是在数据不平衡和分布偏移场景下，这些痕迹可能导致数据泄露，违反如GDPR的Right to Erasure规定。通过理论分析和实证实验，论文揭示了训练数据质量、分类器训练方法以及架构设计对隐私漏洞的显著影响。研究进一步评估了数据混淆等缓解策略，并引入了隐私-性能权衡指数，提供实用指导，帮助在实际应用中平衡隐私保护与分类性能。",
      "categories": [
        "cs.CR",
        "cs.AI"
      ],
      "primary_category": "cs.CR",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2407.02268v2",
      "published_date": "2024-07-02 13:56:37 UTC",
      "updated_date": "2025-04-12 08:36:16 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-19T02:52:10.266981"
    },
    {
      "arxiv_id": "2407.02258v1",
      "title": "SiamTST: A Novel Representation Learning Framework for Enhanced Multivariate Time Series Forecasting applied to Telco Networks",
      "title_zh": "翻译失败",
      "authors": [
        "Simen Kristoffersen",
        "Peter Skaar Nordby",
        "Sara Malacarne",
        "Massimiliano Ruocco",
        "Pablo Ortiz"
      ],
      "abstract": "We introduce SiamTST, a novel representation learning framework for\nmultivariate time series. SiamTST integrates a Siamese network with attention,\nchannel-independent patching, and normalization techniques to achieve superior\nperformance. Evaluated on a real-world industrial telecommunication dataset,\nSiamTST demonstrates significant improvements in forecasting accuracy over\nexisting methods. Notably, a simple linear network also shows competitive\nperformance, achieving the second-best results, just behind SiamTST. The code\nis available at https://github.com/simenkristoff/SiamTST.",
      "tldr_zh": "本文提出 SiamTST，一种新型的多变量时间序列表示学习框架，旨在提升电信网络的预测准确性。该框架整合了 Siamese 网络、注意力机制、channel-independent patching 和 normalization 技术，以优化时间序列表示。实验在真实工业电信数据集上表明，SiamTST 比现有方法显著改善预测性能，而一个简单的线性网络也表现出竞争力，仅次于 SiamTST。代码已在 GitHub 上提供，供进一步研究使用。",
      "categories": [
        "cs.LG",
        "cs.AI"
      ],
      "primary_category": "cs.LG",
      "comment": "14 pages, 3 figures, public codebase",
      "pdf_url": "http://arxiv.org/pdf/2407.02258v1",
      "published_date": "2024-07-02 13:26:16 UTC",
      "updated_date": "2024-07-02 13:26:16 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-19T02:52:24.922844"
    },
    {
      "arxiv_id": "2407.14269v1",
      "title": "Predictive Simultaneous Interpretation: Harnessing Large Language Models for Democratizing Real-Time Multilingual Communication",
      "title_zh": "预测性同声传",
      "authors": [
        "Kurando Iida",
        "Kenjiro Mimura",
        "Nobuo Ito"
      ],
      "abstract": "This study introduces a groundbreaking approach to simultaneous\ninterpretation by directly leveraging the predictive capabilities of Large\nLanguage Models (LLMs). We present a novel algorithm that generates real-time\ntranslations by predicting speaker utterances and expanding multiple\npossibilities in a tree-like structure. This method demonstrates unprecedented\nflexibility and adaptability, potentially overcoming the structural differences\nbetween languages more effectively than existing systems. Our theoretical\nanalysis, supported by illustrative examples, suggests that this approach could\nlead to more natural and fluent translations with minimal latency. The primary\npurpose of this paper is to share this innovative concept with the academic\ncommunity, stimulating further research and development in this field. We\ndiscuss the theoretical foundations, potential advantages, and implementation\nchallenges of this technique, positioning it as a significant step towards\ndemocratizing multilingual communication.",
      "tldr_zh": "这篇论文提出了一种预测性同时口译方法，利用 Large Language Models (LLMs) 的预测能力，通过一个新算法预测说话者的话语并在树状结构中扩展多种可能性，实现实时翻译。相比现有系统，该方法展示了更高的灵活性和适应性，能够更有效地克服语言间的结构差异，并提供更自然流畅的翻译，同时最小化延迟。论文讨论了其理论基础、潜在优势和实施挑战，旨在促进多语种通信的民主化，并激发学术界进一步的研究。",
      "categories": [
        "cs.CL",
        "cs.AI",
        "I.2.7; I.7.0"
      ],
      "primary_category": "cs.CL",
      "comment": "7 pages",
      "pdf_url": "http://arxiv.org/pdf/2407.14269v1",
      "published_date": "2024-07-02 13:18:28 UTC",
      "updated_date": "2024-07-02 13:18:28 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-19T02:52:33.531279"
    },
    {
      "arxiv_id": "2407.12826v1",
      "title": "Assessing the Effectiveness of GPT-4o in Climate Change Evidence Synthesis and Systematic Assessments: Preliminary Insights",
      "title_zh": "评估 GPT-4o 在气候变化证据合成和系统评估中的有效性：初步见解",
      "authors": [
        "Elphin Tom Joe",
        "Sai Dileep Koneru",
        "Christine J Kirchhoff"
      ],
      "abstract": "In this research short, we examine the potential of using GPT-4o, a\nstate-of-the-art large language model (LLM) to undertake evidence synthesis and\nsystematic assessment tasks. Traditional workflows for such tasks involve large\ngroups of domain experts who manually review and synthesize vast amounts of\nliterature. The exponential growth of scientific literature and recent advances\nin LLMs provide an opportunity to complementing these traditional workflows\nwith new age tools. We assess the efficacy of GPT-4o to do these tasks on a\nsample from the dataset created by the Global Adaptation Mapping Initiative\n(GAMI) where we check the accuracy of climate change adaptation related feature\nextraction from the scientific literature across three levels of expertise. Our\nresults indicate that while GPT-4o can achieve high accuracy in low-expertise\ntasks like geographic location identification, their performance in\nintermediate and high-expertise tasks, such as stakeholder identification and\nassessment of depth of the adaptation response, is less reliable. The findings\nmotivate the need for designing assessment workflows that utilize the strengths\nof models like GPT-4o while also providing refinements to improve their\nperformance on these tasks.",
      "tldr_zh": "本研究评估了GPT-4o这种先进的大型语言模型(LLM)在气候变化证据合成和系统评估中的有效性，通过使用Global Adaptation Mapping Initiative (GAMI)数据集测试其从科学文献中提取气候变化适应相关特征的准确性。结果显示，GPT-4o在低复杂度任务如地理位置识别上表现出高准确率，但在中高复杂度任务如利益相关者识别和适应响应深度评估中表现较差。研究建议设计混合工作流，利用GPT-4o的优点并通过改进措施提升其在复杂任务上的可靠性，从而补充传统专家主导的证据合成流程。",
      "categories": [
        "cs.CL",
        "cs.AI"
      ],
      "primary_category": "cs.CL",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2407.12826v1",
      "published_date": "2024-07-02 13:14:57 UTC",
      "updated_date": "2024-07-02 13:14:57 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-19T02:52:46.289616"
    },
    {
      "arxiv_id": "2407.02547v1",
      "title": "Domain Generalizable Knowledge Tracing via Concept Aggregation and Relation-Based Attention",
      "title_zh": "翻译失败",
      "authors": [
        "Yuquan Xie",
        "Wanqi Yang",
        "Jinyu Wei",
        "Ming Yang",
        "Yang Gao"
      ],
      "abstract": "Knowledge Tracing (KT) is a critical task in online education systems, aiming\nto monitor students' knowledge states throughout a learning period. Common KT\napproaches involve predicting the probability of a student correctly answering\nthe next question based on their exercise history. However, these methods often\nsuffer from performance degradation when faced with the scarcity of student\ninteractions in new education systems. To address this, we leverage student\ninteractions from existing education systems to mitigate performance\ndegradation caused by limited training data. Nevertheless, these interactions\nexhibit significant differences since they are derived from different education\nsystems. To address this issue, we propose a domain generalization approach for\nknowledge tracing, where existing education systems are considered source\ndomains, and new education systems with limited data are considered target\ndomains. Additionally, we design a domain-generalizable knowledge tracing\nframework (DGKT) that can be applied to any KT model. Specifically, we present\na concept aggregation approach designed to reduce conceptual disparities within\nsequences of student interactions from diverse domains. To further mitigate\ndomain discrepancies, we introduce a novel normalization module called Sequence\nInstance Normalization (SeqIN). Moreover, to fully leverage exercise\ninformation, we propose a new knowledge tracing model tailored for the domain\ngeneralization KT task, named Domain-Generalizable Relation-based Knowledge\nTracing (DGRKT). Extensive experiments across five benchmark datasets\ndemonstrate that the proposed method performs well despite limited training\ndata.",
      "tldr_zh": "该论文针对知识追踪（KT）在数据稀缺的新教育系统中性能下降的问题，提出了一种领域泛化方法，将现有系统视为源域、新系统视为目标域，以缓解跨域差异。研究设计了域泛化知识追踪框架（DGKT），包括概念聚合（concept aggregation）来减少学生互动序列的概念差异，以及Sequence Instance Normalization (SeqIN)模块进一步缓解域间差异；此外，引入了基于关系的知识追踪模型Domain-Generalizable Relation-based Knowledge Tracing (DGRKT)，充分利用练习信息。实验在五个基准数据集上证明，该方法在训练数据有限的情况下表现出色，提升了KT的泛化能力。",
      "categories": [
        "cs.AI",
        "cs.LG"
      ],
      "primary_category": "cs.AI",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2407.02547v1",
      "published_date": "2024-07-02 13:13:44 UTC",
      "updated_date": "2024-07-02 13:13:44 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-19T02:52:57.439941"
    },
    {
      "arxiv_id": "2407.12825v1",
      "title": "A Depression Detection Method Based on Multi-Modal Feature Fusion Using Cross-Attention",
      "title_zh": "翻译失败",
      "authors": [
        "Shengjie Li",
        "Yinhao Xiao"
      ],
      "abstract": "Depression, a prevalent and serious mental health issue, affects\napproximately 3.8\\% of the global population. Despite the existence of\neffective treatments, over 75\\% of individuals in low- and middle-income\ncountries remain untreated, partly due to the challenge in accurately\ndiagnosing depression in its early stages. This paper introduces a novel method\nfor detecting depression based on multi-modal feature fusion utilizing\ncross-attention. By employing MacBERT as a pre-training model to extract\nlexical features from text and incorporating an additional Transformer module\nto refine task-specific contextual understanding, the model's adaptability to\nthe targeted task is enhanced. Diverging from previous practices of simply\nconcatenating multimodal features, this approach leverages cross-attention for\nfeature integration, significantly improving the accuracy in depression\ndetection and enabling a more comprehensive and precise analysis of user\nemotions and behaviors. Furthermore, a Multi-Modal Feature Fusion Network based\non Cross-Attention (MFFNC) is constructed, demonstrating exceptional\nperformance in the task of depression identification. The experimental results\nindicate that our method achieves an accuracy of 0.9495 on the test dataset,\nmarking a substantial improvement over existing approaches. Moreover, it\noutlines a promising methodology for other social media platforms and tasks\ninvolving multi-modal processing. Timely identification and intervention for\nindividuals with depression are crucial for saving lives, highlighting the\nimmense potential of technology in facilitating early intervention for mental\nhealth issues.",
      "tldr_zh": "本文提出了一种基于多模态特征融合和 Cross-Attention 的抑郁检测方法，旨在解决全球抑郁症诊断难题，特别是针对低中收入国家的高未治疗率。方法利用 MacBERT 作为预训练模型提取文本词汇特征，并结合 Transformer 模块增强任务特定上下文理解，同时通过 Cross-Attention 机制整合多模态特征，构建了 Multi-Modal Feature Fusion Network based on Cross-Attention (MFFNC)。实验结果显示，该方法在测试数据集上实现了 0.9495 的准确率，比现有方法显著提升。整体框架为社交媒体上的抑郁早期识别和多模态处理任务提供了高效、可扩展的解决方案。",
      "categories": [
        "cs.CL",
        "cs.AI",
        "cs.LG"
      ],
      "primary_category": "cs.CL",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2407.12825v1",
      "published_date": "2024-07-02 13:13:35 UTC",
      "updated_date": "2024-07-02 13:13:35 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-19T02:53:11.523921"
    },
    {
      "arxiv_id": "2407.02245v1",
      "title": "Safe CoR: A Dual-Expert Approach to Integrating Imitation Learning and Safe Reinforcement Learning Using Constraint Rewards",
      "title_zh": "Safe CoR：一种双专家方法，用于整合模仿学习和安全强化学习，使用约束奖励",
      "authors": [
        "Hyeokjin Kwon",
        "Gunmin Lee",
        "Junseo Lee",
        "Songhwai Oh"
      ],
      "abstract": "In the realm of autonomous agents, ensuring safety and reliability in complex\nand dynamic environments remains a paramount challenge. Safe reinforcement\nlearning addresses these concerns by introducing safety constraints, but still\nfaces challenges in navigating intricate environments such as complex driving\nsituations. To overcome these challenges, we present the safe constraint reward\n(Safe CoR) framework, a novel method that utilizes two types of expert\ndemonstrations$\\unicode{x2013}$reward expert demonstrations focusing on\nperformance optimization and safe expert demonstrations prioritizing safety. By\nexploiting a constraint reward (CoR), our framework guides the agent to balance\nperformance goals of reward sum with safety constraints. We test the proposed\nframework in diverse environments, including the safety gym, metadrive, and the\nreal$\\unicode{x2013}$world Jackal platform. Our proposed framework enhances the\nperformance of algorithms by $39\\%$ and reduces constraint violations by $88\\%$\non the real-world Jackal platform, demonstrating the framework's efficacy.\nThrough this innovative approach, we expect significant advancements in\nreal-world performance, leading to transformative effects in the realm of safe\nand reliable autonomous agents.",
      "tldr_zh": "这篇论文提出了 Safe CoR 框架，一种结合 Imitation Learning 和 Safe Reinforcement Learning 的双专家方法，通过 Constraint Rewards 引导自主代理在性能优化和安全约束之间实现平衡。框架利用 reward expert demonstrations 专注于最大化奖励，以及 safe expert demonstrations 优先确保安全性，以处理复杂动态环境中的挑战。在 Safety Gym、MetaDrive 和真实世界 Jackal 平台上的实验表明，该框架提升了算法性能 39%，并将约束违反减少 88%，为可靠的自主代理应用带来显著进展。",
      "categories": [
        "cs.RO",
        "cs.AI"
      ],
      "primary_category": "cs.RO",
      "comment": "Accepted to the Proc. of the IEEE/RSJ International Conference on\n  Intelligent Robots and Systems (IROS), 2024",
      "pdf_url": "http://arxiv.org/pdf/2407.02245v1",
      "published_date": "2024-07-02 13:05:16 UTC",
      "updated_date": "2024-07-02 13:05:16 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-19T02:53:21.743161"
    },
    {
      "arxiv_id": "2407.02236v1",
      "title": "Indian Stock Market Prediction using Augmented Financial Intelligence ML",
      "title_zh": "基于增强金融智能 ML 的印度股票市场预测",
      "authors": [
        "Anishka Chauhan",
        "Pratham Mayur",
        "Yeshwanth Sai Gokarakonda",
        "Pooriya Jamie",
        "Naman Mehrotra"
      ],
      "abstract": "This paper presents price prediction models using Machine Learning algorithms\naugmented with Superforecasters predictions, aimed at enhancing investment\ndecisions. Five Machine Learning models are built, including Bidirectional\nLSTM, ARIMA, a combination of CNN and LSTM, GRU, and a model built using LSTM\nand GRU algorithms. The models are evaluated using the Mean Absolute Error to\ndetermine their predictive accuracy. Additionally, the paper suggests\nincorporating human intelligence by identifying Superforecasters and tracking\ntheir predictions to anticipate unpredictable shifts or changes in stock prices\n. The predictions made by these users can further enhance the accuracy of stock\nprice predictions when combined with Machine Learning and Natural Language\nProcessing techniques. Predicting the price of any commodity can be a\nsignificant task but predicting the price of a stock in the stock market deals\nwith much more uncertainty. Recognising the limited knowledge and exposure to\nstocks among certain investors, this paper proposes price prediction models\nusing Machine Learning algorithms. In this work, five Machine learning models\nare built using Bidirectional LSTM, ARIMA, a combination of CNN and LSTM, GRU\nand the last one is built using LSTM and GRU algorithms. Later these models are\nassessed using MAE scores to find which model is predicting with the highest\naccuracy. In addition to this, this paper also suggests the use of human\nintelligence to closely predict the shift in price patterns in the stock market\nThe main goal is to identify Superforecasters and track their predictions to\nanticipate unpredictable shifts or changes in stock prices. By leveraging the\ncombined power of Machine Learning and the Human Intelligence, predictive\naccuracy can be significantly increased.",
      "tldr_zh": "这篇论文提出了一种增强型机器学习模型，用于预测印度股票市场的股价，旨在通过整合Superforecasters的人类预测来改善投资决策。该方法构建了五种模型，包括Bidirectional LSTM、ARIMA、CNN和LSTM的组合、GRU，以及LSTM和GRU的混合模型，这些模型使用Mean Absolute Error (MAE)指标评估预测准确性。论文强调，结合机器学习和Natural Language Processing技术跟踪Superforecasters的预测，能显著提升对股票价格不确定性的处理和预测精度。",
      "categories": [
        "q-fin.TR",
        "cs.AI",
        "cs.CE",
        "stat.ML"
      ],
      "primary_category": "q-fin.TR",
      "comment": "Keywords: Machine Learning, Artificial Intelligence, LSTM, GRU, ARMA,\n  CNN, NLP, ANN, SVM, BSE, NIFTY, MAE, MSE, BiLSTM . Published in SSRN Journal",
      "pdf_url": "http://arxiv.org/pdf/2407.02236v1",
      "published_date": "2024-07-02 12:58:50 UTC",
      "updated_date": "2024-07-02 12:58:50 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-19T02:53:33.021930"
    },
    {
      "arxiv_id": "2407.02233v2",
      "title": "Synthetic Multimodal Question Generation",
      "title_zh": "翻译失败",
      "authors": [
        "Ian Wu",
        "Sravan Jayanthi",
        "Vijay Viswanathan",
        "Simon Rosenberg",
        "Sina Pakazad",
        "Tongshuang Wu",
        "Graham Neubig"
      ],
      "abstract": "Multimodal Retrieval Augmented Generation (MMRAG) is a powerful approach to\nquestion-answering over multimodal documents. A key challenge with evaluating\nMMRAG is the paucity of high-quality datasets matching the question styles and\nmodalities of interest. In light of this, we propose SMMQG, a synthetic data\ngeneration framework. SMMQG leverages interplay between a retriever, large\nlanguage model (LLM) and large multimodal model (LMM) to generate question and\nanswer pairs directly from multimodal documents, with the questions conforming\nto specified styles and modalities. We use SMMQG to generate an MMRAG dataset\nof 1024 questions over Wikipedia documents and evaluate state-of-the-art models\nusing it, revealing insights into model performance that are attainable only\nthrough style- and modality-specific evaluation data. Next, we measure the\nquality of data produced by SMMQG via a human study. We find that the quality\nof SMMQG-generated synthetic data is on par with the quality of the\ncrowdsourced benchmark MMQA and that downstream evaluation results using both\ndatasets strongly concur.",
      "tldr_zh": "本研究提出 SMMQG，一种合成数据生成框架，用于解决 Multimodal Retrieval Augmented Generation (MMRAG) 在多模态文档问答中的数据集匮乏问题。SMMQG 通过 retriever、Large Language Model (LLM) 和 Large Multimodal Model (LMM) 的互动，从多模态文档直接生成符合指定风格和模态的问题及答案对，并以此创建了包含 1024 个问题的 Wikipedia 数据集。实验评估显示，该数据集能揭示最先进模型在特定风格和模态下的性能洞见；此外，人为研究证明 SMMQG 生成的数据质量与 crowdsourced 基准 MMQA 相当，且下游评估结果高度一致。",
      "categories": [
        "cs.CL",
        "cs.AI",
        "cs.LG"
      ],
      "primary_category": "cs.CL",
      "comment": "Accepted to EMNLP 2024 Findings; Camera Ready",
      "pdf_url": "http://arxiv.org/pdf/2407.02233v2",
      "published_date": "2024-07-02 12:57:42 UTC",
      "updated_date": "2024-10-03 19:08:37 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-19T02:53:45.726129"
    },
    {
      "arxiv_id": "2407.02228v2",
      "title": "MTMamba: Enhancing Multi-Task Dense Scene Understanding by Mamba-Based Decoders",
      "title_zh": "翻译失败",
      "authors": [
        "Baijiong Lin",
        "Weisen Jiang",
        "Pengguang Chen",
        "Yu Zhang",
        "Shu Liu",
        "Ying-Cong Chen"
      ],
      "abstract": "Multi-task dense scene understanding, which learns a model for multiple dense\nprediction tasks, has a wide range of application scenarios. Modeling\nlong-range dependency and enhancing cross-task interactions are crucial to\nmulti-task dense prediction. In this paper, we propose MTMamba, a novel\nMamba-based architecture for multi-task scene understanding. It contains two\ntypes of core blocks: self-task Mamba (STM) block and cross-task Mamba (CTM)\nblock. STM handles long-range dependency by leveraging Mamba, while CTM\nexplicitly models task interactions to facilitate information exchange across\ntasks. Experiments on NYUDv2 and PASCAL-Context datasets demonstrate the\nsuperior performance of MTMamba over Transformer-based and CNN-based methods.\nNotably, on the PASCAL-Context dataset, MTMamba achieves improvements of +2.08,\n+5.01, and +4.90 over the previous best methods in the tasks of semantic\nsegmentation, human parsing, and object boundary detection, respectively. The\ncode is available at https://github.com/EnVision-Research/MTMamba.",
      "tldr_zh": "本论文提出 MTMamba，一种基于 Mamba 的新型架构，用于提升多任务密集场景理解。该架构包括 self-task Mamba (STM) 块和 cross-task Mamba (CTM) 块，STM 用于处理长程依赖关系，而 CTM 显式建模任务间交互以促进信息交换。在 NYUDv2 和 PASCAL-Context 数据集上的实验显示，MTMamba 优于 Transformer-based 和 CNN-based 方法，特别是在 PASCAL-Context 上，语义分割、人体解析和物体边界检测任务分别提高了 +2.08、+5.01 和 +4.90。",
      "categories": [
        "cs.CV",
        "cs.AI"
      ],
      "primary_category": "cs.CV",
      "comment": "ECCV 2024",
      "pdf_url": "http://arxiv.org/pdf/2407.02228v2",
      "published_date": "2024-07-02 12:52:18 UTC",
      "updated_date": "2024-07-14 07:50:04 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-19T02:53:58.910968"
    },
    {
      "arxiv_id": "2407.12824v1",
      "title": "Whispering Experts: Neural Interventions for Toxicity Mitigation in Language Models",
      "title_zh": "Whispering Experts：用于语言模型毒性缓解的神经干预",
      "authors": [
        "Xavier Suau",
        "Pieter Delobelle",
        "Katherine Metcalf",
        "Armand Joulin",
        "Nicholas Apostoloff",
        "Luca Zappella",
        "Pau Rodríguez"
      ],
      "abstract": "An important issue with Large Language Models (LLMs) is their undesired\nability to generate toxic language. In this work, we show that the neurons\nresponsible for toxicity can be determined by their power to discriminate toxic\nsentences, and that toxic language can be mitigated by reducing their\nactivation levels proportionally to this power. We propose AUROC adaptation\n(AurA), an intervention that can be applied to any pre-trained LLM to mitigate\ntoxicity. As the intervention is proportional to the ability of each neuron to\ndiscriminate toxic content, it is free of any model-dependent hyperparameters.\nWe show that AurA can achieve up to $2.2 \\times$ reduction in toxicity with\nonly a $0.72$ perplexity increase. We also show that AurA is effective with\nmodels of different scale (from 1.5B to 40B parameters), and its effectiveness\nin mitigating toxic language, while preserving common-sense zero-shot\nabilities, holds across all scales. AurA can be combined with pre-prompting\nstrategies, boosting its average mitigation potential from $1.28\\times$ to\n$2.35\\times$. Moreover, AurA can counteract adversarial pre-prompts that\nmaliciously elicit toxic content, making it an effective method for deploying\nsafer and less toxic models.",
      "tldr_zh": "该研究针对大型语言模型(LLMs)生成有毒语言的问题，提出了一种神经干预方法AurA（AUROC adaptation），通过识别并降低能区分有毒句子的神经元激活水平来缓解毒性，而无需任何模型相关的超参数。AurA在不同规模的LLMs（从1.5B到40B参数）上表现出色，可将毒性减少高达2.2倍，同时仅增加0.72的perplexity，并保留模型的常识零样本能力。该方法还可与预提示策略结合，增强缓解效果，甚至对抗恶意预提示，从而提升模型的安全性。",
      "categories": [
        "cs.CL",
        "cs.AI"
      ],
      "primary_category": "cs.CL",
      "comment": "ICML 2024, 8 pages + appendix",
      "pdf_url": "http://arxiv.org/pdf/2407.12824v1",
      "published_date": "2024-07-02 12:48:29 UTC",
      "updated_date": "2024-07-02 12:48:29 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-19T02:54:09.745820"
    },
    {
      "arxiv_id": "2407.02220v2",
      "title": "Embodied AI in Mobile Robots: Coverage Path Planning with Large Language Models",
      "title_zh": "翻译失败",
      "authors": [
        "Xiangrui Kong",
        "Wenxiao Zhang",
        "Jin Hong",
        "Thomas Braunl"
      ],
      "abstract": "In recent years, Large Language Models (LLMs) have demonstrated remarkable\ncapabilities in understanding and solving mathematical problems, leading to\nadvancements in various fields. We propose an LLM-embodied path planning\nframework for mobile agents, focusing on solving high-level coverage path\nplanning issues and low-level control. Our proposed multi-layer architecture\nuses prompted LLMs in the path planning phase and integrates them with the\nmobile agents' low-level actuators. To evaluate the performance of various\nLLMs, we propose a coverage-weighted path planning metric to assess the\nperformance of the embodied models. Our experiments show that the proposed\nframework improves LLMs' spatial inference abilities. We demonstrate that the\nproposed multi-layer framework significantly enhances the efficiency and\naccuracy of these tasks by leveraging the natural language understanding and\ngenerative capabilities of LLMs. Our experiments show that this framework can\nimprove LLMs' 2D plane reasoning abilities and complete coverage path planning\ntasks. We also tested three LLM kernels: gpt-4o, gemini-1.5-flash, and\nclaude-3.5-sonnet. The experimental results show that claude-3.5 can complete\nthe coverage planning task in different scenarios, and its indicators are\nbetter than those of the other models.",
      "tldr_zh": "本文提出了一种基于 Large Language Models (LLMs) 的嵌入式路径规划框架，用于移动机器人的覆盖路径规划，旨在解决高水平路径规划和低水平控制问题。该框架采用多层架构，将提示过的 LLMs 与移动代理的执行器集成，并引入覆盖加权路径规划指标来评估性能。实验结果显示，该框架显著提升了 LLMs 的空间推理能力和任务效率，其中 claude-3.5-sonnet 在不同场景下表现出色，优于 gpt-4o 和 gemini-1.5-flash 模型。通过利用 LLMs 的自然语言理解和生成能力，该方法为机器人自主导航提供了更可靠的解决方案。",
      "categories": [
        "cs.RO",
        "cs.AI"
      ],
      "primary_category": "cs.RO",
      "comment": "7 pages, 2 figures, conference",
      "pdf_url": "http://arxiv.org/pdf/2407.02220v2",
      "published_date": "2024-07-02 12:38:46 UTC",
      "updated_date": "2024-07-04 01:42:58 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-19T02:54:22.484913"
    },
    {
      "arxiv_id": "2407.02217v1",
      "title": "Physics-Informed Model and Hybrid Planning for Efficient Dyna-Style Reinforcement Learning",
      "title_zh": "基于物理信息的模型与混合规划用于高效 Dyna 风格强化学习",
      "authors": [
        "Zakariae El Asri",
        "Olivier Sigaud",
        "Nicolas Thome"
      ],
      "abstract": "Applying reinforcement learning (RL) to real-world applications requires\naddressing a trade-off between asymptotic performance, sample efficiency, and\ninference time. In this work, we demonstrate how to address this triple\nchallenge by leveraging partial physical knowledge about the system dynamics.\nOur approach involves learning a physics-informed model to boost sample\nefficiency and generating imaginary trajectories from this model to learn a\nmodel-free policy and Q-function. Furthermore, we propose a hybrid planning\nstrategy, combining the learned policy and Q-function with the learned model to\nenhance time efficiency in planning. Through practical demonstrations, we\nillustrate that our method improves the compromise between sample efficiency,\ntime efficiency, and performance over state-of-the-art methods.",
      "tldr_zh": "这篇论文提出了一种基于物理知识的模型和混合规划策略，用于提升Dyna-Style强化学习(Reinforcement Learning)的样本效率、推理时间和渐近性能。方法包括学习physics-informed model来生成imaginary trajectories，从而训练model-free policy和Q-function，以提高样本效率。同时，hybrid planning策略将learned policy、Q-function与learned model结合，优化规划过程。通过实际演示，该方法在样本效率、时间效率和整体性能上优于现有技术。",
      "categories": [
        "cs.LG",
        "cs.AI"
      ],
      "primary_category": "cs.LG",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2407.02217v1",
      "published_date": "2024-07-02 12:32:57 UTC",
      "updated_date": "2024-07-02 12:32:57 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-19T02:54:33.494485"
    },
    {
      "arxiv_id": "2407.02211v2",
      "title": "PromptIntern: Saving Inference Costs by Internalizing Recurrent Prompt during Large Language Model Fine-tuning",
      "title_zh": "翻译失败",
      "authors": [
        "Jiaru Zou",
        "Mengyu Zhou",
        "Tao Li",
        "Shi Han",
        "Dongmei Zhang"
      ],
      "abstract": "Recent advances in fine-tuning large language models (LLMs) have greatly\nenhanced their usage in domain-specific tasks. Despite the success, fine-tuning\ncontinues to rely on repeated and lengthy prompts, which escalate computational\nexpenses, require more resources, and lead to slower inference. In this paper,\nwe present a novel approach, PromptIntern, which internalizes prompt knowledge\nduring model fine-tuning to achieve efficient inference and save costs. Instead\nof compressing the prompts for a vanilla model, PromptIntern aims to embed the\nrecurrent prompt directly into the model parameters. We design a fine-tuning\npipeline that includes instruction template compression, few-shot example\nabsorption, and a progressive internalization strategy, effectively diminishing\nthe need for intricate prompts during inference. Comprehensive experiments on\nchallenging NL2Code tasks demonstrate that our method reduces input tokens by\nmore than 90%, accelerates inference by 4.2 times, and reduces monetary\ninference costs by 88.3%.",
      "tldr_zh": "这篇论文提出了 PromptIntern，一种创新方法，用于在 Large Language Model (LLMs) 微调过程中将 recurrent prompt 内部化到模型参数中，从而减少推理成本和资源消耗。该方法设计了一个微调管道，包括指令模板压缩、few-shot example absorption 和 progressive internalization strategy 等步骤，有效地降低了推理时对复杂提示的依赖。在 NL2Code 任务的实验中，PromptIntern 减少了输入标记超过 90%，加速了推理 4.2 倍，并降低了 88.3% 的货币推理成本。",
      "categories": [
        "cs.CL",
        "cs.AI",
        "cs.LG"
      ],
      "primary_category": "cs.CL",
      "comment": "This paper has been accepted by EMNLP 2024",
      "pdf_url": "http://arxiv.org/pdf/2407.02211v2",
      "published_date": "2024-07-02 12:21:14 UTC",
      "updated_date": "2024-10-15 22:23:41 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-19T02:54:46.024680"
    },
    {
      "arxiv_id": "2407.02209v1",
      "title": "Generative Monoculture in Large Language Models",
      "title_zh": "大型语言模型",
      "authors": [
        "Fan Wu",
        "Emily Black",
        "Varun Chandrasekaran"
      ],
      "abstract": "We introduce {\\em generative monoculture}, a behavior observed in large\nlanguage models (LLMs) characterized by a significant narrowing of model output\ndiversity relative to available training data for a given task: for example,\ngenerating only positive book reviews for books with a mixed reception. While\nin some cases, generative monoculture enhances performance (e.g., LLMs more\noften produce efficient code), the dangers are exacerbated in others (e.g.,\nLLMs refuse to share diverse opinions). As LLMs are increasingly used in\nhigh-impact settings such as education and web search, careful maintenance of\nLLM output diversity is essential to ensure a variety of facts and perspectives\nare preserved over time. We experimentally demonstrate the prevalence of\ngenerative monoculture through analysis of book review and code generation\ntasks, and find that simple countermeasures such as altering sampling or\nprompting strategies are insufficient to mitigate the behavior. Moreover, our\nresults suggest that the root causes of generative monoculture are likely\nembedded within the LLM's alignment processes, suggesting a need for developing\nfine-tuning paradigms that preserve or promote diversity.",
      "tldr_zh": "本文引入了generative monoculture概念，指大型语言模型(LLMs)在生成任务中输出多样性显著降低的现象，例如只生成积极书评而忽略混合评价。这种行为在某些情况下可提升性能（如产生更高效代码），但在高影响领域如教育和网络搜索中，可能导致拒绝分享多样意见并损害事实多样性。通过实验分析书评和代码生成任务，作者证明了generative monoculture的普遍性，并发现简单措施如调整采样或提示策略无效。研究建议，根因可能在于LLMs的alignment processes，因此需要开发能保留或促进输出多样性的细调范式。",
      "categories": [
        "cs.CL",
        "cs.AI"
      ],
      "primary_category": "cs.CL",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2407.02209v1",
      "published_date": "2024-07-02 12:17:07 UTC",
      "updated_date": "2024-07-02 12:17:07 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-19T02:54:57.907999"
    },
    {
      "arxiv_id": "2407.02208v2",
      "title": "How to Learn in a Noisy World? Self-Correcting the Real-World Data Noise in Machine Translation",
      "title_zh": "翻译失败",
      "authors": [
        "Yan Meng",
        "Di Wu",
        "Christof Monz"
      ],
      "abstract": "The massive amounts of web-mined parallel data contain large amounts of\nnoise. Semantic misalignment, as the primary source of the noise, poses a\nchallenge for training machine translation systems. In this paper, we first\nintroduce a process for simulating misalignment controlled by semantic\nsimilarity, which closely resembles misaligned sentences in real-world\nweb-crawled corpora. Under our simulated misalignment noise settings, we\nquantitatively analyze its impact on machine translation and demonstrate the\nlimited effectiveness of widely used pre-filters for noise detection. This\nunderscores the necessity of more fine-grained ways to handle hard-to-detect\nmisalignment noise. With an observation of the increasing reliability of the\nmodel's self-knowledge for distinguishing misaligned and clean data at the\ntoken level, we propose self-correction, an approach that gradually increases\ntrust in the model's self-knowledge to correct the training supervision.\nComprehensive experiments show that our method significantly improves\ntranslation performance both in the presence of simulated misalignment noise\nand when applied to real-world, noisy web-mined datasets, across a range of\ntranslation tasks.",
      "tldr_zh": "本论文探讨了机器翻译训练中真实世界数据噪音（如语义不对齐）的问题，提出了一种自校正方法来处理这些噪音。该方法通过模拟语义不对齐过程，并逐渐增加模型对自身知识的信任，在token级别修正训练监督，从而提升数据质量。实验结果显示，该方法在模拟噪音和真实网络爬取数据集上显著改善了翻译性能，适用于多种翻译任务。",
      "categories": [
        "cs.CL",
        "cs.AI"
      ],
      "primary_category": "cs.CL",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2407.02208v2",
      "published_date": "2024-07-02 12:15:15 UTC",
      "updated_date": "2025-02-07 15:03:38 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-19T02:55:09.566682"
    },
    {
      "arxiv_id": "2407.12823v1",
      "title": "WTU-EVAL: A Whether-or-Not Tool Usage Evaluation Benchmark for Large Language Models",
      "title_zh": "翻译失败",
      "authors": [
        "Kangyun Ning",
        "Yisong Su",
        "Xueqiang Lv",
        "Yuanzhe Zhang",
        "Jian Liu",
        "Kang Liu",
        "Jinan Xu"
      ],
      "abstract": "Although Large Language Models (LLMs) excel in NLP tasks, they still need\nexternal tools to extend their ability. Current research on tool learning with\nLLMs often assumes mandatory tool use, which does not always align with\nreal-world situations, where the necessity for tools is uncertain, and\nincorrect or unnecessary use of tools can damage the general abilities of LLMs.\nTherefore, we propose to explore whether LLMs can discern their ability\nboundaries and use tools flexibly. We then introduce the Whether-or-not tool\nusage Evaluation benchmark (WTU-Eval) to assess LLMs with eleven datasets,\nwhere six of them are tool-usage datasets, and five are general datasets. LLMs\nare prompted to use tools according to their needs. The results of eight LLMs\non WTU-Eval reveal that LLMs frequently struggle to determine tool use in\ngeneral datasets, and LLMs' performance in tool-usage datasets improves when\ntheir ability is similar to ChatGPT. In both datasets, incorrect tool usage\nsignificantly impairs LLMs' performance. To mitigate this, we also develop the\nfinetuning dataset to enhance tool decision-making. Fine-tuning Llama2-7B\nresults in a 14\\% average performance improvement and a 16.8\\% decrease in\nincorrect tool usage. We will release the WTU-Eval benchmark.",
      "tldr_zh": "本论文提出WTU-Eval基准，用于评估大型语言模型(LLMs)是否能识别自身能力边界并灵活决定工具使用，以解决当前工具学习中强制使用工具的问题。该基准包含11个数据集（6个工具使用数据集和5个通用数据集），让LLMs根据需要选择是否调用工具。实验结果显示，8个LLMs在通用数据集上常出错于工具决策，导致性能显著下降，而在工具使用数据集上，能力接近ChatGPT的模型表现更好；通过微调数据集优化Llama2-7B，平均性能提升14%，错误工具使用减少16.8%。",
      "categories": [
        "cs.CL",
        "cs.AI"
      ],
      "primary_category": "cs.CL",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2407.12823v1",
      "published_date": "2024-07-02 12:07:38 UTC",
      "updated_date": "2024-07-02 12:07:38 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-19T02:55:23.657194"
    },
    {
      "arxiv_id": "2407.02203v1",
      "title": "Automatic Adaptation Rule Optimization via Large Language Models",
      "title_zh": "翻译失败",
      "authors": [
        "Yusei Ishimizu",
        "Jialong Li",
        "Jinglue Xu",
        "Jinyu Cai",
        "Hitoshi Iba",
        "Kenji Tei"
      ],
      "abstract": "Rule-based adaptation is a foundational approach to self-adaptation,\ncharacterized by its human readability and rapid response. However, building\nhigh-performance and robust adaptation rules is often a challenge because it\nessentially involves searching the optimal design in a complex (variables)\nspace. In response, this paper attempt to employ large language models (LLMs)\nas a optimizer to construct and optimize adaptation rules, leveraging the\ncommon sense and reasoning capabilities inherent in LLMs. Preliminary\nexperiments conducted in SWIM have validated the effectiveness and limitation\nof our method.",
      "tldr_zh": "这篇论文提出了一种使用 Large Language Models (LLMs) 自动优化适应规则的方法，以解决规则-based 自适应系统在构建高性能和鲁棒规则时的挑战。方法利用 LLMs 的常识和推理能力，在复杂变量空间中搜索最优设计，从而提高规则的效率。初步实验在 SWIM 平台上验证了该方法的有效性，同时也揭示了其潜在局限性。",
      "categories": [
        "cs.CL",
        "cs.AI"
      ],
      "primary_category": "cs.CL",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2407.02203v1",
      "published_date": "2024-07-02 12:06:40 UTC",
      "updated_date": "2024-07-02 12:06:40 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-19T02:55:43.353029"
    },
    {
      "arxiv_id": "2407.02197v1",
      "title": "Research on Reliable and Safe Occupancy Grid Prediction in Underground Parking Lots",
      "title_zh": "地下停车场可靠且安全的占用网格预测研究",
      "authors": [
        "JiaQi Luo"
      ],
      "abstract": "Against the backdrop of advancing science and technology, autonomous vehicle\ntechnology has emerged as a focal point of intense scrutiny within the academic\ncommunity. Nevertheless, the challenge persists in guaranteeing the safety and\nreliability of this technology when navigating intricate scenarios. While a\nsubstantial portion of autonomous driving research is dedicated to testing in\nopen-air environments, such as urban roads and highways, where the myriad\nvariables at play are meticulously examined, enclosed indoor spaces like\nunderground parking lots have, to a significant extent, been overlooked in the\nscholarly discourse. This discrepancy highlights a gap in derstanding the\nunique challenges these confined settings pose for autonomous navigation\nsystems.\n  This study tackles indoor autonomous driving, particularly in overlooked\nspaces like underground parking lots. Using CARLA's simulation platform, a\nrealistic parking model is created for data gathering. An occupancy grid\nnetwork then processes this data to predict vehicle paths and obstacles,\nenhancing the system's perception in complex indoor environments. Ultimately,\nthis strategy improves safety in autonomous parking operations. The paper\nmeticulously evaluates the model's predictive capabilities, validating its\nefficacy in the context of underground parking. Our findings confirm that the\nproposed strategy successfully enhances autonomous vehicle performance in these\ncomplex indoor settings. It equips autonomous systems with improved adaptation\nto underground lots, reinforcing safety measures and dependability. This work\npaves the way for future advancements and applications by addressing the\nresearch shortfall concerning indoor parking environments, serving as a pivotal\nreference point.",
      "tldr_zh": "本研究针对自动驾驶技术在地下停车场等室内环境的独特挑战，开发了一种可靠且安全的占用网格预测（Occupancy Grid Prediction）策略，以提升车辆路径预测和障碍物检测能力。研究利用 CARLA 模拟平台创建真实停车场景模型，并通过占用网格网络（Occupancy Grid Network）处理数据，实现对复杂室内环境的精确感知。实验结果验证，该方法在地下停车场景中提高了自动停车的安全性和可靠性，为未来室内自动驾驶应用提供了重要参考。",
      "categories": [
        "cs.AI",
        "cs.CV",
        "cs.RO"
      ],
      "primary_category": "cs.AI",
      "comment": "15 pages, 19 figures",
      "pdf_url": "http://arxiv.org/pdf/2407.02197v1",
      "published_date": "2024-07-02 11:56:14 UTC",
      "updated_date": "2024-07-02 11:56:14 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-19T02:55:56.692913"
    },
    {
      "arxiv_id": "2407.02191v2",
      "title": "Attack-Aware Noise Calibration for Differential Privacy",
      "title_zh": "攻击感知噪声校准用于差分隐私",
      "authors": [
        "Bogdan Kulynych",
        "Juan Felipe Gomez",
        "Georgios Kaissis",
        "Flavio du Pin Calmon",
        "Carmela Troncoso"
      ],
      "abstract": "Differential privacy (DP) is a widely used approach for mitigating privacy\nrisks when training machine learning models on sensitive data. DP mechanisms\nadd noise during training to limit the risk of information leakage. The scale\nof the added noise is critical, as it determines the trade-off between privacy\nand utility. The standard practice is to select the noise scale to satisfy a\ngiven privacy budget $\\varepsilon$. This privacy budget is in turn interpreted\nin terms of operational attack risks, such as accuracy, sensitivity, and\nspecificity of inference attacks aimed to recover information about the\ntraining data records. We show that first calibrating the noise scale to a\nprivacy budget $\\varepsilon$, and then translating {\\epsilon} to attack risk\nleads to overly conservative risk assessments and unnecessarily low utility.\nInstead, we propose methods to directly calibrate the noise scale to a desired\nattack risk level, bypassing the step of choosing $\\varepsilon$. For a given\nnotion of attack risk, our approach significantly decreases noise scale,\nleading to increased utility at the same level of privacy. We empirically\ndemonstrate that calibrating noise to attack sensitivity/specificity, rather\nthan $\\varepsilon$, when training privacy-preserving ML models substantially\nimproves model accuracy for the same risk level. Our work provides a principled\nand practical way to improve the utility of privacy-preserving ML without\ncompromising on privacy. The code is available at\nhttps://github.com/Felipe-Gomez/riskcal",
      "tldr_zh": "这篇论文针对差分隐私 (DP) 在训练机器学习模型时的问题，指出传统基于隐私预算 $\\varepsilon$ 的噪声校准方法会导致风险评估过于保守，从而降低模型实用性。作者提出了一种直接基于攻击风险水平（如敏感性和特异性）来校准噪声规模的方法，绕过设定 $\\varepsilon$ 的步骤，从而减少噪声量并提高模型效用。实验结果显示，这种方法在保持相同隐私水平的情况下，显著提升了隐私保护 ML 模型的准确率。总体上，该工作为改进隐私保护机器学习提供了原则性和实用的途径，并提供了开源代码。",
      "categories": [
        "cs.LG",
        "cs.AI",
        "cs.CR",
        "math.ST",
        "stat.ML",
        "stat.TH"
      ],
      "primary_category": "cs.LG",
      "comment": "Appears in NeurIPS 2024",
      "pdf_url": "http://arxiv.org/pdf/2407.02191v2",
      "published_date": "2024-07-02 11:49:59 UTC",
      "updated_date": "2024-11-07 21:51:49 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-19T02:56:08.885199"
    },
    {
      "arxiv_id": "2407.02156v1",
      "title": "Towards Training Music Taggers on Synthetic Data",
      "title_zh": "翻译失败",
      "authors": [
        "Nadine Kroher",
        "Steven Manangu",
        "Aggelos Pikrakis"
      ],
      "abstract": "Most contemporary music tagging systems rely on large volumes of annotated\ndata. As an alternative, we investigate the extent to which synthetically\ngenerated music excerpts can improve tagging systems when only small annotated\ncollections are available. To this end, we release GTZAN-synth, a synthetic\ndataset that follows the taxonomy of the well-known GTZAN dataset while being\nten times larger in data volume. We first observe that simply adding this\nsynthetic dataset to the training split of GTZAN does not result into\nperformance improvements. We then proceed to investigating domain adaptation,\ntransfer learning and fine-tuning strategies for the task at hand and draw the\nconclusion that the last two options yield an increase in accuracy. Overall,\nthe proposed approach can be considered as a first guide in a promising field\nfor future research.",
      "tldr_zh": "本研究探讨了使用合成数据训练音乐标签系统，以缓解标注数据不足的问题。作者发布了GTZAN-synth数据集，该数据集沿用GTZAN的分类体系，但数据量是其十倍。实验发现，直接将合成数据添加到训练集中无法提升性能，但通过transfer learning和fine-tuning策略，可以显著提高准确率。总体而言，此方法为合成数据在音乐标记领域的应用提供了初步指导。",
      "categories": [
        "cs.SD",
        "cs.AI",
        "cs.IR",
        "cs.LG",
        "eess.AS",
        "I.2"
      ],
      "primary_category": "cs.SD",
      "comment": "6 pages, 3 figures, accepted to 21st International Conference on\n  Content-based Multimedia Indexing (CBMI) 2024, code available\n  https://github.com/NadineKroher/music-tagging-synthetic-data-cbmi-2024",
      "pdf_url": "http://arxiv.org/pdf/2407.02156v1",
      "published_date": "2024-07-02 10:54:23 UTC",
      "updated_date": "2024-07-02 10:54:23 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-19T02:56:19.565426"
    },
    {
      "arxiv_id": "2407.02147v2",
      "title": "GemmAr: Enhancing LLMs Through Arabic Instruction-Tuning",
      "title_zh": "GemmAr：通过阿拉伯语指令微",
      "authors": [
        "Hasna Chouikhi",
        "Manel Aloui",
        "Cyrine Ben Hammou",
        "Ghaith Chaabane",
        "Haithem Kchaou",
        "Chehir Dhaouadi"
      ],
      "abstract": "Large language models (LLMs) have greatly impacted the natural language\nprocessing (NLP) field, particularly for the English language. These models\nhave demonstrated capabilities in understanding and generating human-like text.\nThe success of language models largely depends on the availability of\nhigh-quality instruction datasets, which consist of detailed task descriptions\nand corresponding responses that are essential for training the models to\naddress a variety of prompts accurately. However, the availability and quality\nof these resources vary by language. While models perform well in English, they\noften need help with languages like Arabic, due to the lack of datasets for\nfine-tuning Arabic-specific tasks. To address this issue, we introduce\nInstAr-500k, a new Arabic instruction dataset created by generating and\ncollecting content that covers several domains and instruction types. We assess\nthis dataset by fine-tuning an open-source Gemma-7B model on several downstream\ntasks to improve its functionality. Based on multiple evaluations, our\nfine-tuned model achieves excellent performance on several Arabic NLP\nbenchmarks. These outcomes emphasize the effectiveness of our dataset in\nelevating the capabilities of language models for Arabic. Our instruction\ndataset bridges the performance gap between English and Arabic language models\nby providing resources that amplify Arabic NLP development. Building on this\nfoundation, we developed a model, GemmAr-7B-V1, specifically tuned to excel at\na wide range of Arabic NLP tasks.",
      "tldr_zh": "这项研究针对大型语言模型（LLMs）在英语上的出色表现与阿拉伯语资源不足的问题，引入了InstAr-500k数据集，该数据集通过生成和收集覆盖多个领域和指令类型的阿拉伯语内容来提升模型训练。研究者对开源Gemma-7B模型进行instruction-tuning微调，评估其在各种阿拉伯语NLP任务上的性能。结果显示，微调后的模型在多个阿拉伯语NLP基准上取得了卓越表现，有效缩小了英语和阿拉伯语语言模型的性能差距。最后，他们开发了GemmAr-7B-V1模型，专门优化了阿拉伯语NLP任务的处理能力。",
      "categories": [
        "cs.CL",
        "cs.AI"
      ],
      "primary_category": "cs.CL",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2407.02147v2",
      "published_date": "2024-07-02 10:43:49 UTC",
      "updated_date": "2024-07-09 15:36:11 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-19T02:56:43.925849"
    },
    {
      "arxiv_id": "2407.02138v2",
      "title": "Efficient Nearest Neighbor based Uncertainty Estimation for Natural Language Processing Tasks",
      "title_zh": "高效的基于最近邻的不确定性估计方法，用于自然语言处理任务",
      "authors": [
        "Wataru Hashimoto",
        "Hidetaka Kamigaito",
        "Taro Watanabe"
      ],
      "abstract": "Trustworthiness in model predictions is crucial for safety-critical\napplications in the real world. However, deep neural networks often suffer from\nthe issues of uncertainty estimation, such as miscalibration. In this study, we\npropose $k$-Nearest Neighbor Uncertainty Estimation ($k$NN-UE), which is a new\nuncertainty estimation method that uses not only the distances from the\nneighbors, but also the ratio of labels in the neighbors. Experiments on\nsentiment analysis, natural language inference, and named entity recognition\nshow that our proposed method outperforms the baselines and recent\ndensity-based methods in several calibration and uncertainty metrics. Moreover,\nour analyses indicate that approximate nearest neighbor search techniques\nreduce the inference overhead without significantly degrading the uncertainty\nestimation performance when they are appropriately combined.",
      "tldr_zh": "本论文针对深层神经网络在自然语言处理(NLP)任务中的不确定性估计问题（如校准错误），提出了一种高效方法 k-Nearest Neighbor Uncertainty Estimation (kNN-UE)。该方法不仅利用邻居距离，还结合邻居中标签的比例来提升不确定性评估准确性。在情感分析、自然语言推理和命名实体识别等任务的实验中，kNN-UE 优于基线模型和最近的密度-based 方法，在多个校准和不确定性指标上表现出色。此外，分析表明，使用 approximate nearest neighbor search 技术可以显著减少推理开销，同时基本不降低性能。",
      "categories": [
        "cs.CL",
        "cs.AI",
        "cs.LG"
      ],
      "primary_category": "cs.CL",
      "comment": "Accepted at Findings of NAACL 2025",
      "pdf_url": "http://arxiv.org/pdf/2407.02138v2",
      "published_date": "2024-07-02 10:33:31 UTC",
      "updated_date": "2025-02-06 17:32:04 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-19T02:56:44.170099"
    },
    {
      "arxiv_id": "2407.02119v2",
      "title": "Cost-Effective Proxy Reward Model Construction with On-Policy and Active Learning",
      "title_zh": "成本有效的代理奖励模型",
      "authors": [
        "Yifang Chen",
        "Shuohang Wang",
        "Ziyi Yang",
        "Hiteshi Sharma",
        "Nikos Karampatziakis",
        "Donghan Yu",
        "Kevin Jamieson",
        "Simon Shaolei Du",
        "Yelong Shen"
      ],
      "abstract": "Reinforcement learning with human feedback (RLHF), as a widely adopted\napproach in current large language model pipelines, is \\textit{bottlenecked by\nthe size of human preference data}. While traditional methods rely on offline\npreference dataset constructions, recent approaches have shifted towards online\nsettings, where a learner uses a small amount of labeled seed data and a large\npool of unlabeled prompts to iteratively construct new preference data through\nself-generated responses and high-quality reward/preference feedback. However,\nmost current online algorithms still focus on preference labeling during policy\nmodel updating with given feedback oracles, which incurs significant expert\nquery costs. \\textit{We are the first to explore cost-effective proxy reward\noracles construction strategies for further labeling preferences or rewards\nwith extremely limited labeled data and expert query budgets}. Our approach\nintroduces two key innovations: (1) on-policy query to avoid OOD and imbalance\nissues in seed data, and (2) active learning to select the most informative\ndata for preference queries. Using these methods, we train a evaluation model\nwith minimal expert-labeled data, which then effectively labels nine times more\npreference pairs for further RLHF training. For instance, our model using\nDirect Preference Optimization (DPO) gains around over 1% average improvement\non AlpacaEval2, MMLU-5shot and MMLU-0shot, with only 1.7K query cost. Our\nmethodology is orthogonal to other direct expert query-based strategies and\ntherefore might be integrated with them to further reduce query costs.",
      "tldr_zh": "本研究针对强化学习与人类反馈 (RLHF) 中人类偏好数据规模的瓶颈，首次提出了一种成本有效的代理奖励模型构建策略，通过极少标记数据和专家查询预算来优化在线偏好数据生成。关键创新包括 on-policy 查询（避免 OOD 和不平衡问题）和 active learning（选择最信息丰富的数据），从而训练评估模型高效标记更多偏好对，例如为后续 RLHF 训练生成九倍的偏好数据。实验结果显示，使用 Direct Preference Optimization (DPO)，模型在 AlpacaEval2、MMLU-5shot 和 MMLU-0shot 上平均提高了 1%，而查询成本仅为 1.7K。这种方法可与其他策略整合，进一步降低专家查询开销。",
      "categories": [
        "cs.LG",
        "cs.AI",
        "cs.CL"
      ],
      "primary_category": "cs.LG",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2407.02119v2",
      "published_date": "2024-07-02 10:09:19 UTC",
      "updated_date": "2024-07-09 08:24:06 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-19T02:56:59.313931"
    },
    {
      "arxiv_id": "2407.02112v3",
      "title": "A Data-Centric Perspective on Evaluating Machine Learning Models for Tabular Data",
      "title_zh": "数据中心视角：评估用于表格数据的机器学习模型",
      "authors": [
        "Andrej Tschalzev",
        "Sascha Marton",
        "Stefan Lüdtke",
        "Christian Bartelt",
        "Heiner Stuckenschmidt"
      ],
      "abstract": "Tabular data is prevalent in real-world machine learning applications, and\nnew models for supervised learning of tabular data are frequently proposed.\nComparative studies assessing the performance of models typically consist of\nmodel-centric evaluation setups with overly standardized data preprocessing.\nThis paper demonstrates that such model-centric evaluations are biased, as\nreal-world modeling pipelines often require dataset-specific preprocessing and\nfeature engineering. Therefore, we propose a data-centric evaluation framework.\nWe select 10 relevant datasets from Kaggle competitions and implement\nexpert-level preprocessing pipelines for each dataset. We conduct experiments\nwith different preprocessing pipelines and hyperparameter optimization (HPO)\nregimes to quantify the impact of model selection, HPO, feature engineering,\nand test-time adaptation. Our main findings are: 1. After dataset-specific\nfeature engineering, model rankings change considerably, performance\ndifferences decrease, and the importance of model selection reduces. 2. Recent\nmodels, despite their measurable progress, still significantly benefit from\nmanual feature engineering. This holds true for both tree-based models and\nneural networks. 3. While tabular data is typically considered static, samples\nare often collected over time, and adapting to distribution shifts can be\nimportant even in supposedly static data. These insights suggest that research\nefforts should be directed toward a data-centric perspective, acknowledging\nthat tabular data requires feature engineering and often exhibits temporal\ncharacteristics. Our framework is available under:\nhttps://github.com/atschalz/dc_tabeval.",
      "tldr_zh": "本论文从数据中心视角评估机器学习模型在表格数据(Tabular Data)上的性能，批评现有模型中心评估方法因过度标准化预处理而导致偏差，并提出一个新的数据中心评估框架。\n研究者选择了10个Kaggle数据集，为每个数据集实现专家级预处理管道，并通过实验探索不同预处理、超参数优化(HPO)、特征工程和测试时适应的影响。\n主要发现是：数据集特定特征工程后，模型排名显著变化、性能差异减小，且模型选择的重要性降低；同时，最新模型（如树-based模型和神经网络）仍需手动特征工程；此外，即使表格数据被视为静态，其时间特性可能需要适应分布偏移。\n这项研究建议未来研究应转向数据中心视角，强调特征工程的重要性，并提供了开源框架（https://github.com/atschalz/dc_tabeval）。",
      "categories": [
        "cs.LG",
        "cs.AI"
      ],
      "primary_category": "cs.LG",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2407.02112v3",
      "published_date": "2024-07-02 09:54:39 UTC",
      "updated_date": "2024-12-18 16:07:04 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-19T02:57:10.023775"
    },
    {
      "arxiv_id": "2407.02109v2",
      "title": "HRSAM: Efficient Interactive Segmentation in High-Resolution Images",
      "title_zh": "翻译失败",
      "authors": [
        "You Huang",
        "Wenbin Lai",
        "Jiayi Ji",
        "Liujuan Cao",
        "Shengchuan Zhang",
        "Rongrong Ji"
      ],
      "abstract": "The Segment Anything Model (SAM) has advanced interactive segmentation but is\nlimited by the high computational cost on high-resolution images. This requires\ndownsampling to meet GPU constraints, sacrificing the fine-grained details\nneeded for high-precision interactive segmentation. To address SAM's\nlimitations, we focus on visual length extrapolation and propose a lightweight\nmodel named HRSAM. The extrapolation enables HRSAM trained on low resolutions\nto generalize to high resolutions. We begin by finding the link between the\nextrapolation and attention scores, which leads us to base HRSAM on Swin\nattention. We then introduce the Flexible Local Attention (FLA) framework,\nusing CUDA-optimized Efficient Memory Attention to accelerate HRSAM. Within\nFLA, we implement Flash Swin attention, achieving over a 35% speedup compared\nto traditional Swin attention, and propose a KV-only padding mechanism to\nenhance extrapolation. We also develop the Cycle-scan module that uses State\nSpace models to efficiently expand HRSAM's receptive field. We further develop\nthe HRSAM++ within FLA by adding an anchor map, providing multi-scale data\naugmentation for the extrapolation and a larger receptive field at slight\ncomputational cost. Experiments show that, under standard training, HRSAMs\nsurpass the previous SOTA with only 38% of the latency. With SAM-distillation,\nthe extrapolation enables HRSAMs to outperform the teacher model at lower\nlatency. Further finetuning achieves performance significantly exceeding the\nprevious SOTA.",
      "tldr_zh": "这篇论文针对Segment Anything Model (SAM)在高分辨率图像上计算成本高且需降采样导致细节丢失的问题，提出了一种轻量级模型HRSAM，通过视觉长度外推技术，使其在低分辨率训练后能高效推广到高分辨率。HRSAM基于Swin attention，引入Flexible Local Attention (FLA)框架，包括Flash Swin attention（比传统Swin attention快35%以上）、KV-only padding机制和Cycle-scan module（利用State Space models扩展感受野），并开发了HRSAM++以添加anchor map，提供多尺度数据增强。实验表明，HRSAM在标准训练下以38%的延迟超越先前的SOTA，通过SAM-distillation和进一步微调，其性能显著超过教师模型和现有最先进方法。",
      "categories": [
        "cs.CV",
        "cs.AI"
      ],
      "primary_category": "cs.CV",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2407.02109v2",
      "published_date": "2024-07-02 09:51:56 UTC",
      "updated_date": "2024-11-23 01:44:00 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-19T02:57:23.568689"
    },
    {
      "arxiv_id": "2407.02106v1",
      "title": "Automated Knowledge Graph Learning in Industrial Processes",
      "title_zh": "工业过程中的自动知识图谱学习",
      "authors": [
        "Lolitta Ammann",
        "Jorge Martinez-Gil",
        "Michael Mayr",
        "Georgios C. Chasparis"
      ],
      "abstract": "Industrial processes generate vast amounts of time series data, yet\nextracting meaningful relationships and insights remains challenging. This\npaper introduces a framework for automated knowledge graph learning from time\nseries data, specifically tailored for industrial applications. Our framework\naddresses the complexities inherent in industrial datasets, transforming them\ninto knowledge graphs that improve decision-making, process optimization, and\nknowledge discovery. Additionally, it employs Granger causality to identify key\nattributes that can inform the design of predictive models. To illustrate the\npractical utility of our approach, we also present a motivating use case\ndemonstrating the benefits of our framework in a real-world industrial\nscenario. Further, we demonstrate how the automated conversion of time series\ndata into knowledge graphs can identify causal influences or dependencies\nbetween important process parameters.",
      "tldr_zh": "这篇论文提出一个框架，用于从工业过程的时间序列数据（time series data）中自动学习知识图谱（knowledge graph），以解决提取有意义关系和洞见的挑战。该框架处理工业数据集的复杂性，通过Granger causality识别关键属性，从而支持预测模型的设计和决策优化。实验案例展示了该方法在真实工业场景中的实用性，能够识别过程参数之间的因果影响，提升知识发现和过程优化效果。",
      "categories": [
        "cs.LG",
        "cs.AI"
      ],
      "primary_category": "cs.LG",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2407.02106v1",
      "published_date": "2024-07-02 09:47:56 UTC",
      "updated_date": "2024-07-02 09:47:56 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-19T02:57:30.764750"
    },
    {
      "arxiv_id": "2407.02078v1",
      "title": "MARLIN: A Cloud Integrated Robotic Solution to Support Intralogistics in Retail",
      "title_zh": "MAR",
      "authors": [
        "Dennis Mronga",
        "Andreas Bresser",
        "Fabian Maas",
        "Adrian Danzglock",
        "Simon Stelter",
        "Alina Hawkin",
        "Hoang Giang Nguyen",
        "Michael Beetz",
        "Frank Kirchner"
      ],
      "abstract": "In this paper, we present the service robot MARLIN and its integration with\nthe K4R platform, a cloud system for complex AI applications in retail. At its\ncore, this platform contains so-called semantic digital twins, a semantically\nannotated representation of the retail store. MARLIN continuously exchanges\ndata with the K4R platform, improving the robot's capabilities in perception,\nautonomous navigation, and task planning. We exploit these capabilities in a\nretail intralogistics scenario, specifically by assisting store employees in\nstocking shelves. We demonstrate that MARLIN is able to update the digital\nrepresentation of the retail store by detecting and classifying obstacles,\nautonomously planning and executing replenishment missions, adapting to\nunforeseen changes in the environment, and interacting with store employees.\nExperiments are conducted in simulation, in a laboratory environment, and in a\nreal store. We also describe and evaluate a novel algorithm for autonomous\nnavigation of articulated tractor-trailer systems. The algorithm outperforms\nthe manufacturer's proprietary navigation approach and improves MARLIN's\nnavigation capabilities in confined spaces.",
      "tldr_zh": "本文介绍了 MARLIN 服务机器人及其与 K4R 平台的集成，利用 semantic digital twins（语义数字孪生）作为零售店的语义标注表示，提升机器人在感知、自主导航和任务规划方面的能力。MARLIN 在零售内部物流场景中协助员工补货货架，通过检测和分类障碍物、自主执行任务、适应环境变化以及与员工互动来更新数字店面表示。实验在模拟、实验室和真实商店环境中进行，结果显示 MARLIN 的新型自主导航算法优于制造商的专有方法，提高了在狭小空间的导航性能。",
      "categories": [
        "cs.RO",
        "cs.AI",
        "cs.CV"
      ],
      "primary_category": "cs.RO",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2407.02078v1",
      "published_date": "2024-07-02 09:12:54 UTC",
      "updated_date": "2024-07-02 09:12:54 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-19T02:57:44.348875"
    },
    {
      "arxiv_id": "2407.02070v2",
      "title": "Latent Diffusion Model for Generating Ensembles of Climate Simulations",
      "title_zh": "翻译失败",
      "authors": [
        "Johannes Meuer",
        "Maximilian Witte",
        "Tobias Sebastian Finn",
        "Claudia Timmreck",
        "Thomas Ludwig",
        "Christopher Kadow"
      ],
      "abstract": "Obtaining accurate estimates of uncertainty in climate scenarios often\nrequires generating large ensembles of high-resolution climate simulations, a\ncomputationally expensive and memory intensive process. To address this\nchallenge, we train a novel generative deep learning approach on extensive sets\nof climate simulations. The model consists of two components: a variational\nautoencoder for dimensionality reduction and a denoising diffusion\nprobabilistic model that generates multiple ensemble members. We validate our\nmodel on the Max Planck Institute Grand Ensemble and show that it achieves good\nagreement with the original ensemble in terms of variability. By leveraging the\nlatent space representation, our model can rapidly generate large ensembles\non-the-fly with minimal memory requirements, which can significantly improve\nthe efficiency of uncertainty quantification in climate simulations.",
      "tldr_zh": "该论文提出了一种基于潜在扩散模型的新方法，用于高效生成气候模拟集合，以解决传统方法计算密集和内存需求高的挑战。该模型结合了变分自编码器（Variational Autoencoder）进行降维，以及去噪扩散概率模型（Denoising Diffusion Probabilistic Model）来生成多个集合成员。在 Max Planck Institute Grand Ensemble 数据集上验证显示，该模型在变异性方面与原集合高度一致，并能快速生成大型集合，显著提升气候模拟中不确定性量化的效率。",
      "categories": [
        "cs.LG",
        "cs.AI",
        "physics.ao-ph"
      ],
      "primary_category": "cs.LG",
      "comment": "8 pages, 7 figures, Accepted at the ICML 2024 Machine Learning for\n  Earth System Modeling workshop",
      "pdf_url": "http://arxiv.org/pdf/2407.02070v2",
      "published_date": "2024-07-02 08:59:24 UTC",
      "updated_date": "2024-07-04 12:43:52 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-19T02:58:00.344791"
    },
    {
      "arxiv_id": "2407.02062v2",
      "title": "Are Data Augmentation Methods in Named Entity Recognition Applicable for Uncertainty Estimation?",
      "title_zh": "命名实体识别中的数据增强方法是否适用于不确定性估计？",
      "authors": [
        "Wataru Hashimoto",
        "Hidetaka Kamigaito",
        "Taro Watanabe"
      ],
      "abstract": "This work investigates the impact of data augmentation on confidence\ncalibration and uncertainty estimation in Named Entity Recognition (NER) tasks.\nFor the future advance of NER in safety-critical fields like healthcare and\nfinance, it is essential to achieve accurate predictions with calibrated\nconfidence when applying Deep Neural Networks (DNNs), including Pre-trained\nLanguage Models (PLMs), as a real-world application. However, DNNs are prone to\nmiscalibration, which limits their applicability. Moreover, existing methods\nfor calibration and uncertainty estimation are computational expensive. Our\ninvestigation in NER found that data augmentation improves calibration and\nuncertainty in cross-genre and cross-lingual setting, especially in-domain\nsetting. Furthermore, we showed that the calibration for NER tends to be more\neffective when the perplexity of the sentences generated by data augmentation\nis lower, and that increasing the size of the augmentation further improves\ncalibration and uncertainty.",
      "tldr_zh": "这篇论文探讨了数据 augmentation 方法在命名实体识别 (NER) 任务中对置信度校准和不确定性估计的影响，旨在提升深度神经网络 (DNNs) 和预训练语言模型 (PLMs) 在安全关键领域（如医疗和金融）的可信度应用。研究发现，数据 augmentation 能够在跨领域和跨语言设置中显著改善校准和不确定性，尤其在领域内场景下效果更佳。论文进一步指出，低困惑度的增强句子和增加增强数据规模能进一步优化校准性能，从而缓解现有方法的计算开销问题。",
      "categories": [
        "cs.CL",
        "cs.AI",
        "cs.LG"
      ],
      "primary_category": "cs.CL",
      "comment": "Accepted to EMNLP 2024 main conference",
      "pdf_url": "http://arxiv.org/pdf/2407.02062v2",
      "published_date": "2024-07-02 08:49:43 UTC",
      "updated_date": "2024-10-25 10:07:18 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-19T02:58:08.605254"
    },
    {
      "arxiv_id": "2407.02060v1",
      "title": "Terminating Differentiable Tree Experts",
      "title_zh": "翻译失败",
      "authors": [
        "Jonathan Thomm",
        "Michael Hersche",
        "Giacomo Camposampiero",
        "Aleksandar Terzić",
        "Bernhard Schölkopf",
        "Abbas Rahimi"
      ],
      "abstract": "We advance the recently proposed neuro-symbolic Differentiable Tree Machine,\nwhich learns tree operations using a combination of transformers and Tensor\nProduct Representations. We investigate the architecture and propose two key\ncomponents. We first remove a series of different transformer layers that are\nused in every step by introducing a mixture of experts. This results in a\nDifferentiable Tree Experts model with a constant number of parameters for any\narbitrary number of steps in the computation, compared to the previous method\nin the Differentiable Tree Machine with a linear growth. Given this flexibility\nin the number of steps, we additionally propose a new termination algorithm to\nprovide the model the power to choose how many steps to make automatically. The\nresulting Terminating Differentiable Tree Experts model sluggishly learns to\npredict the number of steps without an oracle. It can do so while maintaining\nthe learning capabilities of the model, converging to the optimal amount of\nsteps.",
      "tldr_zh": "这篇论文在 neuro-symbolic Differentiable Tree Machine 的基础上，提出了 Terminating Differentiable Tree Experts 模型，通过引入 mixture of experts 替换每步的 transformer 层，使参数数量保持常量，而非线性增长。模型还添加了 termination algorithm，让其自动决定计算步骤数，而无需依赖 oracle。结果表明，该模型能够有效学习预测步骤数，同时保持学习能力和收敛到最优步骤。",
      "categories": [
        "cs.LG",
        "cs.AI",
        "cs.SC"
      ],
      "primary_category": "cs.LG",
      "comment": "Accepted at the 18th International Conference on Neural-Symbolic\n  Learning and Reasoning (NeSy) 2024",
      "pdf_url": "http://arxiv.org/pdf/2407.02060v1",
      "published_date": "2024-07-02 08:45:38 UTC",
      "updated_date": "2024-07-02 08:45:38 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-19T02:58:21.497739"
    },
    {
      "arxiv_id": "2407.02056v1",
      "title": "Integrate the Essence and Eliminate the Dross: Fine-Grained Self-Consistency for Free-Form Language Generation",
      "title_zh": "翻译失败",
      "authors": [
        "Xinglin Wang",
        "Yiwei Li",
        "Shaoxiong Feng",
        "Peiwen Yuan",
        "Boyuan Pan",
        "Heda Wang",
        "Yao Hu",
        "Kan Li"
      ],
      "abstract": "Self-consistency (SC), leveraging multiple samples from LLMs, shows\nsignificant gains on various reasoning tasks but struggles with free-form\ngeneration due to the difficulty of aggregating answers. Its variants, UCS and\nUSC, rely on sample selection or voting mechanisms to improve output quality.\nThese methods, however, face limitations due to their inability to fully\nutilize the nuanced consensus knowledge present within multiple candidate\nsamples, often resulting in suboptimal outputs. We propose Fine-Grained\nSelf-Consistency (FSC) to addresses these limitations by extracting and\nintegrating segment-level commonalities from candidate samples, enhancing the\nperformance of LLMs both in open-ended and reasoning tasks. Based on this, we\npresent two additional strategies: candidate filtering, which enhances overall\nquality by identifying highly similar candidate sets, and merging, which\nreduces input token requirements by combining similar samples. The\neffectiveness of FSC is demonstrated through extensive experiments on various\ntasks, including summarization, code generation, and mathematical reasoning,\nusing GPT-3.5-turbo and GPT-4. The results indicate significant improvements\nover baseline methods, showcasing the potential of FSC to optimize output\nquality by effectively synthesizing fine-grained consensus knowledge from\nmultiple samples.",
      "tldr_zh": "本论文提出 Fine-Grained Self-Consistency (FSC) 方法，以解决传统 Self-Consistency (SC) 在自由形式语言生成中的局限性，即难以有效聚合多个候选样本的细粒度共识知识，导致输出质量不佳。FSC 通过提取和整合候选样本的段级共同点，并结合候选过滤（用于识别相似样本提升整体质量）和合并（减少输入 token 需求）策略，提升大语言模型 (LLMs) 在开放式任务和推理任务中的性能。实验在总结、代码生成和数学推理等任务上，使用 GPT-3.5-turbo 和 GPT-4 模型，证明 FSC 显著优于基线方法，展示了其在合成共识知识方面的潜力。",
      "categories": [
        "cs.CL",
        "cs.AI"
      ],
      "primary_category": "cs.CL",
      "comment": "Accepted to ACL2024 Main Conference",
      "pdf_url": "http://arxiv.org/pdf/2407.02056v1",
      "published_date": "2024-07-02 08:38:31 UTC",
      "updated_date": "2024-07-02 08:38:31 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-19T02:58:33.657281"
    },
    {
      "arxiv_id": "2407.02055v1",
      "title": "Abstract Dialectical Frameworks are Boolean Networks (full version)",
      "title_zh": "翻译失败",
      "authors": [
        "Jesse Heyninck",
        "Matthias Knorr",
        "João Leite"
      ],
      "abstract": "Dialectical frameworks are a unifying model of formal argumentation, where\nargumentative relations between arguments are represented by assigning\nacceptance conditions to atomic arguments. Their generality allow them to cover\na number of different approaches with varying forms of representing the\nargumentation structure. Boolean regulatory networks are used to model the\ndynamics of complex biological processes, taking into account the interactions\nof biological compounds, such as proteins or genes. These models have proven\nhighly useful for comprehending such biological processes, allowing to\nreproduce known behaviour and testing new hypotheses and predictions in silico,\nfor example in the context of new medical treatments. While both these\napproaches stem from entirely different communities, it turns out that there\nare striking similarities in their appearence. In this paper, we study the\nrelation between these two formalisms revealing their communalities as well as\ntheir differences, and introducing a correspondence that allows to establish\nnovel results for the individual formalisms.",
      "tldr_zh": "本论文探讨了Abstract Dialectical Frameworks（ADF）和Boolean Networks之间的关系，揭示了这两个形式主义在结构和动态方面的显著相似性，尽管它们分别源于形式论证领域和生物过程建模领域。研究者分析了ADF的接受条件机制与Boolean regulatory networks的交互建模方法，突出了它们的共性（如表示论证或调控关系）和差异（如具体应用场景）。通过建立一种对应关系，论文为每个形式主义引入了新的理论结果，例如在形式论证中应用生物网络的预测方法，从而增强了跨领域的研究潜力。",
      "categories": [
        "cs.AI"
      ],
      "primary_category": "cs.AI",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2407.02055v1",
      "published_date": "2024-07-02 08:37:05 UTC",
      "updated_date": "2024-07-02 08:37:05 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-19T02:58:44.617594"
    },
    {
      "arxiv_id": "2407.02048v1",
      "title": "Revolutionising Role-Playing Games with ChatGPT",
      "title_zh": "翻译失败",
      "authors": [
        "Rita Stampfl",
        "Barbara Geyer",
        "Marie Deissl-O'Meara",
        "Igor Ivkić"
      ],
      "abstract": "Digitalisation in education and its influence on teaching methods is the\nfocus of this study, which examines the use of ChatGPT in a role-playing game\nused in the Cloud Computing Engineering Master's programme at the University of\nApplied Sciences Burgenland. The aim of the study was to analyse the impact of\nAI-based simulations on students' learning experience. Based on Vygotsky's\nsociocultural theory, ChatGPT was used to give students a deeper understanding\nof strategic decision-making processes in simulated business scenarios. The\nmethodological approach included role-playing and qualitative content analysis\nof 20 student reflections. The findings suggest that ChatGPT enhances students'\nengagement, critical thinking, and communication skills, in addition to\ncontributing to the effective application of theoretical knowledge.\nFurthermore, simulations can contribute to the effective application of\ntheoretical knowledge. The results underscore the significance of adaptive\nteaching approaches in promoting digital literacy and equipping learners for\nthe digital workplace. The integration of AI into curricula and the need for\nongoing innovation in higher education are also emphasised as a means of\nguaranteeing excellent, future-focused instruction. The findings highlight the\npotential of AI and ChatGPT in particular, as an innovative cutting-edge\neducational tool that can both enhance the learning experience and help achieve\nthe Sustainable Development Goals (SDGs) through education.",
      "tldr_zh": "这篇论文探讨了在教育中使用 ChatGPT 革新角色扮演游戏的影响，焦点是其对奥地利应用科学大学云计算工程硕士课程学生学习体验的作用。基于 Vygotsky's sociocultural theory，研究采用角色扮演和对20名学生反思的定性内容分析方法，模拟商业场景以加深学生对战略决策的理解。结果表明，ChatGPT 显著提升了学生的参与度、批判性思维和沟通技能，并促进了理论知识的有效应用。该研究强调了 AI 在教育中的潜力，支持数字素养发展、适应数字工作场所，并有助于实现可持续发展目标 (SDGs)。",
      "categories": [
        "cs.CY",
        "cs.AI",
        "cs.HC"
      ],
      "primary_category": "cs.CY",
      "comment": "Received 23-02-2024; Accepted 20-05-2024; Published 27-05-2024",
      "pdf_url": "http://arxiv.org/pdf/2407.02048v1",
      "published_date": "2024-07-02 08:21:40 UTC",
      "updated_date": "2024-07-02 08:21:40 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-19T02:58:57.407762"
    },
    {
      "arxiv_id": "2407.02042v1",
      "title": "Fake News Detection and Manipulation Reasoning via Large Vision-Language Models",
      "title_zh": "通过大型视觉语言模型的假新闻检测与操纵推理",
      "authors": [
        "Ruihan Jin",
        "Ruibo Fu",
        "Zhengqi Wen",
        "Shuai Zhang",
        "Yukun Liu",
        "Jianhua Tao"
      ],
      "abstract": "Fake news becomes a growing threat to information security and public opinion\nwith the rapid sprawl of media manipulation. Therefore, fake news detection\nattracts widespread attention from academic community. Traditional fake news\ndetection models demonstrate remarkable performance on authenticity binary\nclassification but their ability to reason detailed faked traces based on the\nnews content remains under-explored. Furthermore, due to the lack of external\nknowledge, the performance of existing methods on fact-related news is\nquestionable, leaving their practical implementation unclear. In this paper, we\npropose a new multi-media research topic, namely manipulation reasoning.\nManipulation reasoning aims to reason manipulations based on news content. To\nsupport the research, we introduce a benchmark for fake news detection and\nmanipulation reasoning, referred to as Human-centric and Fact-related Fake News\n(HFFN). The benchmark highlights the centrality of human and the high factual\nrelevance, with detailed manual annotations. HFFN encompasses four realistic\ndomains with fake news samples generated through three manipulation approaches.\nMoreover, a Multi-modal news Detection and Reasoning langUage Model (M-DRUM) is\npresented not only to judge on the authenticity of multi-modal news, but also\nraise analytical reasoning about potential manipulations. On the feature\nextraction level, a cross-attention mechanism is employed to extract\nfine-grained fusion features from multi-modal inputs. On the reasoning level, a\nlarge vision-language model (LVLM) serves as the backbone to facilitate\nfact-related reasoning. A two-stage training framework is deployed to better\nactivate the capacity of identification and reasoning. Comprehensive\nexperiments demonstrate that our model outperforms state-of-the-art (SOTA) fake\nnews detection models and powerful LVLMs like GPT-4 and LLaVA.",
      "tldr_zh": "这篇论文针对假新闻检测的局限性，提出了一个新研究主题——manipulation reasoning，用于基于新闻内容推理潜在操纵行为，并引入了 Human-centric and Fact-related Fake News (HFFN) 基准数据集，该数据集涵盖四个现实领域，通过三种操纵方法生成样本并进行手动标注。作者开发了 Multi-modal news Detection and Reasoning langUage Model (M-DRUM)，该模型采用跨注意力机制提取多模态输入的细粒度融合特征，并以 Large Vision-Language Models (LVLM) 作为骨干，支持事实相关推理，同时通过两阶段训练框架提升识别和推理能力。实验结果显示，M-DRUM 超过了现有最先进 (SOTA) 假新闻检测模型以及强大的 LVLM 如 GPT-4 和 LLaVA，在真实性和操纵推理任务上表现出色。",
      "categories": [
        "cs.CL",
        "cs.AI"
      ],
      "primary_category": "cs.CL",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2407.02042v1",
      "published_date": "2024-07-02 08:16:43 UTC",
      "updated_date": "2024-07-02 08:16:43 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-19T02:59:09.395083"
    },
    {
      "arxiv_id": "2407.02040v1",
      "title": "ScaleDreamer: Scalable Text-to-3D Synthesis with Asynchronous Score Distillation",
      "title_zh": "翻译失败",
      "authors": [
        "Zhiyuan Ma",
        "Yuxiang Wei",
        "Yabin Zhang",
        "Xiangyu Zhu",
        "Zhen Lei",
        "Lei Zhang"
      ],
      "abstract": "By leveraging the text-to-image diffusion priors, score distillation can\nsynthesize 3D contents without paired text-3D training data. Instead of\nspending hours of online optimization per text prompt, recent studies have been\nfocused on learning a text-to-3D generative network for amortizing multiple\ntext-3D relations, which can synthesize 3D contents in seconds. However,\nexisting score distillation methods are hard to scale up to a large amount of\ntext prompts due to the difficulties in aligning pretrained diffusion prior\nwith the distribution of rendered images from various text prompts. Current\nstate-of-the-arts such as Variational Score Distillation finetune the\npretrained diffusion model to minimize the noise prediction error so as to\nalign the distributions, which are however unstable to train and will impair\nthe model's comprehension capability to numerous text prompts. Based on the\nobservation that the diffusion models tend to have lower noise prediction\nerrors at earlier timesteps, we propose Asynchronous Score Distillation (ASD),\nwhich minimizes the noise prediction error by shifting the diffusion timestep\nto earlier ones. ASD is stable to train and can scale up to 100k prompts. It\nreduces the noise prediction error without changing the weights of pre-trained\ndiffusion model, thus keeping its strong comprehension capability to prompts.\nWe conduct extensive experiments across different 2D diffusion models,\nincluding Stable Diffusion and MVDream, and text-to-3D generators, including\nHyper-iNGP, 3DConv-Net and Triplane-Transformer. The results demonstrate ASD's\neffectiveness in stable 3D generator training, high-quality 3D content\nsynthesis, and its superior prompt-consistency, especially under large prompt\ncorpus.",
      "tldr_zh": "该论文提出了一种可扩展的文本到3D合成方法ScaleDreamer，利用Asynchronous Score Distillation (ASD)来解决传统score distillation在处理大量文本提示时的分布对齐难题。ASD通过将扩散时间步移至较早阶段来最小化噪声预测错误，避免微调预训练扩散模型（如Stable Diffusion或MVDream），从而保持模型对提示的强大理解能力，并实现稳定训练和扩展到10万提示。实验结果显示，ASD在多种文本到3D生成器（如Hyper-iNGP、3DConv-Net和Triplane-Transformer）上显著提升了3D内容的合成质量和提示一致性，尤其在大规模提示语料下表现突出。",
      "categories": [
        "cs.CV",
        "cs.AI",
        "cs.MM"
      ],
      "primary_category": "cs.CV",
      "comment": "Accepted by ECCV 2024. Code available at\n  https://github.com/theEricMa/ScaleDreamer",
      "pdf_url": "http://arxiv.org/pdf/2407.02040v1",
      "published_date": "2024-07-02 08:12:14 UTC",
      "updated_date": "2024-07-02 08:12:14 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-19T02:59:21.733723"
    },
    {
      "arxiv_id": "2407.17482v2",
      "title": "Reinforcement Learning from Human Feedback: Whose Culture, Whose Values, Whose Perspectives?",
      "title_zh": "翻译失败",
      "authors": [
        "Kristian González Barman",
        "Simon Lohse",
        "Henk de Regt"
      ],
      "abstract": "We argue for the epistemic and ethical advantages of pluralism in\nReinforcement Learning from Human Feedback (RLHF) in the context of Large\nLanguage Models (LLM). Drawing on social epistemology and pluralist philosophy\nof science, we suggest ways in which RHLF can be made more responsive to human\nneeds and how we can address challenges along the way. The paper concludes with\nan agenda for change, i.e. concrete, actionable steps to improve LLM\ndevelopment.",
      "tldr_zh": "这篇论文探讨了在强化学习从人类反馈 (RLHF) 中引入多元主义 (pluralism) 的认识论和伦理优势，特别是针对大型语言模型 (LLM)。作者借鉴社会认识论和社会多元主义哲学，提出方法使 RLHF 更能响应人类需求，并解决潜在挑战。论文最终提供一个变革议程，包括具体的、可操作步骤来改进 LLM 的开发和应用。",
      "categories": [
        "cs.CY",
        "cs.AI",
        "cs.CL",
        "cs.HC"
      ],
      "primary_category": "cs.CY",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2407.17482v2",
      "published_date": "2024-07-02 08:07:27 UTC",
      "updated_date": "2025-01-17 09:17:30 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-19T02:59:32.686844"
    },
    {
      "arxiv_id": "2407.02031v2",
      "title": "SwiftDiffusion: Efficient Diffusion Model Serving with Add-on Modules",
      "title_zh": "SwiftDiffusion：高效的扩散模型服务，结合附加模块",
      "authors": [
        "Suyi Li",
        "Lingyun Yang",
        "Xiaoxiao Jiang",
        "Hanfeng Lu",
        "Dakai An",
        "Zhipeng Di",
        "Weiyi Lu",
        "Jiawei Chen",
        "Kan Liu",
        "Yinghao Yu",
        "Tao Lan",
        "Guodong Yang",
        "Lin Qu",
        "Liping Zhang",
        "Wei Wang"
      ],
      "abstract": "Text-to-image (T2I) generation using diffusion models has become a\nblockbuster service in today's AI cloud. A production T2I service typically\ninvolves a serving workflow where a base diffusion model is augmented with\nvarious \"add-on\" modules, notably ControlNet and LoRA, to enhance image\ngeneration control. Compared to serving the base model alone, these add-on\nmodules introduce significant loading and computational overhead, resulting in\nincreased latency. In this paper, we present SwiftDiffusion, a system that\nefficiently serves a T2I workflow through a holistic approach. SwiftDiffusion\ndecouples ControNet from the base model and deploys it as a separate,\nindependently scaled service on dedicated GPUs, enabling ControlNet caching,\nparallelization, and sharing. To mitigate the high loading overhead of LoRA\nserving, SwiftDiffusion employs a bounded asynchronous LoRA loading (BAL)\ntechnique, allowing LoRA loading to overlap with the initial base model\nexecution by up to k steps without compromising image quality. Furthermore,\nSwiftDiffusion optimizes base model execution with a novel latent parallelism\ntechnique. Collectively, these designs enable SwiftDiffusion to outperform the\nstate-of-the-art T2I serving systems, achieving up to 7.8x latency reduction\nand 1.6x throughput improvement in serving SDXL models on H800 GPUs, without\nsacrificing image quality.",
      "tldr_zh": "这篇论文介绍了 SwiftDiffusion，一种高效的服务系统，用于优化文本到图像 (T2I) 生成中的扩散模型工作流，特别是处理附加模块如 ControlNet 和 LoRA 带来的加载和计算开销。SwiftDiffusion 通过将 ControlNet 作为独立、可扩展的服务部署，支持其缓存、并行化和共享；采用 bounded asynchronous LoRA loading (BAL) 技术让 LoRA 加载与基底模型执行重叠；并引入潜在并行性优化来提升整体效率。实验结果显示，该系统在 H800 GPUs 上服务 SDXL 模型时，实现高达 7.8x 延迟减少和 1.6x 吞吐量改善，同时不牺牲图像质量。",
      "categories": [
        "cs.DC",
        "cs.AI",
        "cs.LG"
      ],
      "primary_category": "cs.DC",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2407.02031v2",
      "published_date": "2024-07-02 07:59:08 UTC",
      "updated_date": "2024-12-06 11:47:06 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-19T02:59:46.074127"
    },
    {
      "arxiv_id": "2407.02028v1",
      "title": "Why does in-context learning fail sometimes? Evaluating in-context learning on open and closed questions",
      "title_zh": "为什么有时上下文学习会失败？在开放式和封闭式问题上评估上下文学习",
      "authors": [
        "Xiang Li",
        "Haoran Tang",
        "Siyu Chen",
        "Ziwei Wang",
        "Ryan Chen",
        "Marcin Abram"
      ],
      "abstract": "We measure the performance of in-context learning as a function of task\nnovelty and difficulty for open and closed questions. For that purpose, we\ncreated a novel benchmark consisting of hard scientific questions, each paired\nwith a context of various relevancy. We show that counter-intuitively, a\ncontext that is more aligned with the topic does not always help more than a\nless relevant context. This effect is especially visible for open questions and\nquestions of high difficulty or novelty. This result reveals a fundamental\ndifference between the treatment of close-form and open-form questions by\nlarge-language models and shows a need for a more robust evaluation of\nin-context learning on the variety of different types of questions. It also\nposes a new question of how to optimally select a context for large language\nmodels, especially in the context of Retrieval Augmented Generation (RAG)\nsystems. Our results suggest that the answer to this question can be highly\napplication-dependent and might be contingent on factors including the format\nof the question, the perceived difficulty level of the questions, and the\nnovelty or popularity of the information we seek.",
      "tldr_zh": "本研究评估了 in-context learning 在不同任务新颖性和难度下的表现，针对开放式和封闭式问题，创建了一个新基准，该基准包含困难的科学问题及其不同相关性的上下文。结果显示，counter-intuitively，更相关的上下文并不总是比不相关的上下文更有效，尤其在开放式问题、高难度或高新颖性任务中，这揭示了大型语言模型在处理封闭式和开放式问题上的根本差异。该发现强调了需要更 robust 的 in-context learning 评估，并提出在 Retrieval Augmented Generation (RAG) 系统等应用中，如何优化上下文选择可能取决于问题格式、难度和新颖性等因素。",
      "categories": [
        "cs.CL",
        "cs.AI",
        "cs.IR",
        "cs.LG"
      ],
      "primary_category": "cs.CL",
      "comment": "8 pages plus references, 4 main figures, 6 pages of supplementary\n  material",
      "pdf_url": "http://arxiv.org/pdf/2407.02028v1",
      "published_date": "2024-07-02 07:52:30 UTC",
      "updated_date": "2024-07-02 07:52:30 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-19T02:59:59.890402"
    },
    {
      "arxiv_id": "2407.02025v4",
      "title": "On the Expressive Power of Sparse Geometric MPNNs",
      "title_zh": "关于稀疏几何消息传递神经网络的表达能力",
      "authors": [
        "Yonatan Sverdlov",
        "Nadav Dym"
      ],
      "abstract": "Motivated by applications in chemistry and other sciences, we study the\nexpressive power of message-passing neural networks for geometric graphs, whose\nnode features correspond to 3-dimensional positions. Recent work has shown that\nsuch models can separate generic pairs of non-isomorphic geometric graphs,\nthough they may fail to separate some rare and complicated instances. However,\nthese results assume a fully connected graph, where each node possesses\ncomplete knowledge of all other nodes. In contrast, often, in application,\nevery node only possesses knowledge of a small number of nearest neighbors.\n  This paper shows that generic pairs of non-isomorphic geometric graphs can be\nseparated by message-passing networks with rotation equivariant features as\nlong as the underlying graph is connected. When only invariant intermediate\nfeatures are allowed, generic separation is guaranteed for generically globally\nrigid graphs. We introduce a simple architecture, EGENNET, which achieves our\ntheoretical guarantees and compares favorably with alternative architecture on\nsynthetic and chemical benchmarks. Our code is available at\nhttps://github.com/yonatansverdlov/E-GenNet.",
      "tldr_zh": "这篇论文探讨了稀疏几何消息传递神经网络（MPNNs）的表现力，针对化学等领域中节点特征对应3D位置的几何图。研究发现，在连接图上，使用旋转等变特征的MPNNs可以区分泛型非同构几何图，而仅使用不变特征时，则需泛型全局刚性图来保证分离。作者提出了一种简单架构EGENNET，实现这些理论保证，并在合成和化学基准测试中表现出色。",
      "categories": [
        "cs.LG",
        "cs.AI"
      ],
      "primary_category": "cs.LG",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2407.02025v4",
      "published_date": "2024-07-02 07:48:22 UTC",
      "updated_date": "2025-02-17 16:36:37 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-19T03:00:10.810252"
    },
    {
      "arxiv_id": "2407.02004v2",
      "title": "SAVE: Segment Audio-Visual Easy way using Segment Anything Model",
      "title_zh": "翻译失败",
      "authors": [
        "Khanh-Binh Nguyen",
        "Chae Jung Park"
      ],
      "abstract": "The primary aim of Audio-Visual Segmentation (AVS) is to precisely identify\nand locate auditory elements within visual scenes by accurately predicting\nsegmentation masks at the pixel level. Achieving this involves comprehensively\nconsidering data and model aspects to address this task effectively. This study\npresents a lightweight approach, SAVE, which efficiently adapts the pre-trained\nsegment anything model (SAM) to the AVS task. By incorporating an image encoder\nadapter into the transformer blocks to better capture the distinct dataset\ninformation and proposing a residual audio encoder adapter to encode the audio\nfeatures as a sparse prompt, our proposed model achieves effective audio-visual\nfusion and interaction during the encoding stage. Our proposed method\naccelerates the training and inference speed by reducing the input resolution\nfrom 1024 to 256 pixels while achieving higher performance compared with the\nprevious SOTA. Extensive experimentation validates our approach, demonstrating\nthat our proposed model outperforms other SOTA methods significantly. Moreover,\nleveraging the pre-trained model on synthetic data enhances performance on real\nAVSBench data, achieving 84.59 mIoU on the S4 (V1S) subset and 70.28 mIoU on\nthe MS3 (V1M) set with only 256 pixels for input images. This increases up to\n86.16 mIoU on the S4 (V1S) and 70.83 mIoU on the MS3 (V1M) with inputs of 1024\npixels.",
      "tldr_zh": "本研究提出了一种轻量级方法SAVE，用于音频-视觉分割(AVS)任务，通过适配预训练的Segment Anything Model (SAM)来精确识别和定位音频元素。SAVE引入图像编码器适配器以捕捉数据集特定信息，以及残差音频编码器适配器将音频特征编码为稀疏提示，从而实现有效的音频-视觉融合和交互，同时将输入分辨率从1024像素降低到256像素以加速训练和推理。实验结果显示，SAVE显著优于现有SOTA方法，在AVSBench数据集上，S4 (V1S)子集达到84.59 mIoU（256像素）和86.16 mIoU（1024像素），MS3 (V1M)子集达到70.28 mIoU和70.83 mIoU。",
      "categories": [
        "cs.CV",
        "cs.AI",
        "cs.SD",
        "eess.AS"
      ],
      "primary_category": "cs.CV",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2407.02004v2",
      "published_date": "2024-07-02 07:22:28 UTC",
      "updated_date": "2024-07-03 23:49:36 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-19T03:00:24.247142"
    },
    {
      "arxiv_id": "2407.02543v1",
      "title": "Towards the Next Frontier in Speech Representation Learning Using Disentanglement",
      "title_zh": "翻译失败",
      "authors": [
        "Varun Krishna",
        "Sriram Ganapathy"
      ],
      "abstract": "The popular frameworks for self-supervised learning of speech representations\nhave largely focused on frame-level masked prediction of speech regions. While\nthis has shown promising downstream task performance for speech recognition and\nrelated tasks, this has largely ignored factors of speech that are encoded at\ncoarser level, like characteristics of the speaker or channel that remain\nconsistent through-out a speech utterance. In this work, we propose a framework\nfor Learning Disentangled Self Supervised (termed as Learn2Diss)\nrepresentations of speech, which consists of frame-level and an utterance-level\nencoder modules. The two encoders are initially learned independently, where\nthe frame-level model is largely inspired by existing self supervision\ntechniques, thereby learning pseudo-phonemic representations, while the\nutterance-level encoder is inspired by constrastive learning of pooled\nembeddings, thereby learning pseudo-speaker representations. The joint learning\nof these two modules consists of disentangling the two encoders using a mutual\ninformation based criterion. With several downstream evaluation experiments, we\nshow that the proposed Learn2Diss achieves state-of-the-art results on a\nvariety of tasks, with the frame-level encoder representations improving\nsemantic tasks, while the utterance-level representations improve non-semantic\ntasks.",
      "tldr_zh": "本文提出 Learn2Diss 框架，通过自监督学习(self-supervised learning)实现语音表示的解缠结(disentanglement)，以解决现有方法忽略说话者或通道等粗粒度因素的问题。该框架包括帧级别(frame-level)编码器（基于现有技术学习伪音素表示）和话语级别(utterance-level)编码器（基于对比学习学习伪说话者表示），并通过互信息(mutual information)准则对两者进行联合学习和解缠结。实验结果表明，Learn2Diss 在多种下游任务上达到最先进水平，其中帧级别表示改善语义任务，而话语级别表示提升非语义任务。",
      "categories": [
        "cs.CL",
        "cs.AI",
        "cs.LG",
        "cs.SD",
        "eess.AS"
      ],
      "primary_category": "cs.CL",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2407.02543v1",
      "published_date": "2024-07-02 07:13:35 UTC",
      "updated_date": "2024-07-02 07:13:35 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-19T03:00:35.470177"
    },
    {
      "arxiv_id": "2407.12043v2",
      "title": "The Art of Saying No: Contextual Noncompliance in Language Models",
      "title_zh": "翻译失败",
      "authors": [
        "Faeze Brahman",
        "Sachin Kumar",
        "Vidhisha Balachandran",
        "Pradeep Dasigi",
        "Valentina Pyatkin",
        "Abhilasha Ravichander",
        "Sarah Wiegreffe",
        "Nouha Dziri",
        "Khyathi Chandu",
        "Jack Hessel",
        "Yulia Tsvetkov",
        "Noah A. Smith",
        "Yejin Choi",
        "Hannaneh Hajishirzi"
      ],
      "abstract": "Chat-based language models are designed to be helpful, yet they should not\ncomply with every user request. While most existing work primarily focuses on\nrefusal of \"unsafe\" queries, we posit that the scope of noncompliance should be\nbroadened. We introduce a comprehensive taxonomy of contextual noncompliance\ndescribing when and how models should not comply with user requests. Our\ntaxonomy spans a wide range of categories including incomplete, unsupported,\nindeterminate, and humanizing requests (in addition to unsafe requests). To\ntest noncompliance capabilities of language models, we use this taxonomy to\ndevelop a new evaluation suite of 1000 noncompliance prompts. We find that most\nexisting models show significantly high compliance rates in certain previously\nunderstudied categories with models like GPT-4 incorrectly complying with as\nmany as 30% of requests. To address these gaps, we explore different training\nstrategies using a synthetically-generated training set of requests and\nexpected noncompliant responses. Our experiments demonstrate that while direct\nfinetuning of instruction-tuned models can lead to both over-refusal and a\ndecline in general capabilities, using parameter efficient methods like low\nrank adapters helps to strike a good balance between appropriate noncompliance\nand other capabilities.",
      "tldr_zh": "这篇论文探讨了语言模型在处理用户请求时的上下文不遵守（contextual noncompliance）问题，提出一个全面的分类体系，包括不完整、未支持、不确定和人性化请求（除了不安全请求）。作者开发了一个包含1000个不遵守提示的评估套件，发现现有模型如GPT-4在某些类别中错误遵守率高达30%。通过使用合成数据集和参数高效训练策略（如low rank adapters），实验证明可以有效提升模型的不遵守能力，同时平衡过度拒绝和整体性能。",
      "categories": [
        "cs.CL",
        "cs.AI",
        "cs.HC"
      ],
      "primary_category": "cs.CL",
      "comment": "The first two authors are co-first authors; Accepted at NeurIPS 2024\n  Track on Datasets and Benchmarks",
      "pdf_url": "http://arxiv.org/pdf/2407.12043v2",
      "published_date": "2024-07-02 07:12:51 UTC",
      "updated_date": "2024-11-22 17:48:57 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-19T03:00:47.227025"
    },
    {
      "arxiv_id": "2407.01994v1",
      "title": "Simple Augmentations of Logical Rules for Neuro-Symbolic Knowledge Graph Completion",
      "title_zh": "简单扩充的逻辑规则用于神经符号知识图谱补全",
      "authors": [
        "Ananjan Nandi",
        "Navdeep Kaur",
        "Parag Singla",
        "Mausam"
      ],
      "abstract": "High-quality and high-coverage rule sets are imperative to the success of\nNeuro-Symbolic Knowledge Graph Completion (NS-KGC) models, because they form\nthe basis of all symbolic inferences. Recent literature builds neural models\nfor generating rule sets, however, preliminary experiments show that they\nstruggle with maintaining high coverage. In this work, we suggest three simple\naugmentations to existing rule sets: (1) transforming rules to their abductive\nforms, (2) generating equivalent rules that use inverse forms of constituent\nrelations and (3) random walks that propose new rules. Finally, we prune\npotentially low quality rules. Experiments over four datasets and five\nruleset-baseline settings suggest that these simple augmentations consistently\nimprove results, and obtain up to 7.1 pt MRR and 8.5 pt Hits@1 gains over using\nrules without augmentations.",
      "tldr_zh": "本文提出三种简单增强方法，用于改善Neuro-Symbolic Knowledge Graph Completion (NS-KGC)模型的规则集覆盖率问题。这些方法包括将规则转换为abductive forms、生成使用关系反转的等价规则，以及通过随机游走提出新规则，随后对潜在低质量规则进行修剪。在四个数据集和五个基准设置上的实验表明，这些增强方法 consistently 提升了性能，最多获得7.1 pt MRR和8.5 pt Hits@1的改进。",
      "categories": [
        "cs.AI",
        "cs.CL",
        "cs.IR"
      ],
      "primary_category": "cs.AI",
      "comment": "12 pages, 15 tables Published in ACL 2023",
      "pdf_url": "http://arxiv.org/pdf/2407.01994v1",
      "published_date": "2024-07-02 07:07:59 UTC",
      "updated_date": "2024-07-02 07:07:59 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-19T03:01:00.307248"
    },
    {
      "arxiv_id": "2407.01991v3",
      "title": "Generation of Geodesics with Actor-Critic Reinforcement Learning to Predict Midpoints",
      "title_zh": "翻译失败",
      "authors": [
        "Kazumi Kasaura"
      ],
      "abstract": "To find the shortest paths for all pairs on manifolds with infinitesimally\ndefined metrics, we introduce a framework to generate them by predicting\nmidpoints recursively. To learn midpoint prediction, we propose an actor-critic\napproach. We prove the soundness of our approach and show experimentally that\nthe proposed method outperforms existing methods on several planning tasks,\nincluding path planning for agents with complex kinematics and motion planning\nfor multi-degree-of-freedom robot arms.",
      "tldr_zh": "本文提出一个框架，通过递归预测中点来生成流形上所有成对点的最短路径（geodesics），以处理无穷小度量下的路径规划问题。采用 actor-critic 强化学习方法来学习中点预测，并证明了该方法的可靠性。实验结果显示，该方法在多个任务中优于现有技术，包括复杂运动学代理的路径规划和多自由度机器人臂的运动规划。",
      "categories": [
        "cs.LG",
        "cs.AI"
      ],
      "primary_category": "cs.LG",
      "comment": "17 pages with 8 pages of appendices and references, 9 figures",
      "pdf_url": "http://arxiv.org/pdf/2407.01991v3",
      "published_date": "2024-07-02 07:06:49 UTC",
      "updated_date": "2025-03-21 14:44:42 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-19T03:01:10.620575"
    },
    {
      "arxiv_id": "2407.02542v1",
      "title": "ECAT: A Entire space Continual and Adaptive Transfer Learning Framework for Cross-Domain Recommendation",
      "title_zh": "翻译失败",
      "authors": [
        "Chaoqun Hou",
        "Yuanhang Zhou",
        "Yi Cao",
        "Tong Liu"
      ],
      "abstract": "In industrial recommendation systems, there are several mini-apps designed to\nmeet the diverse interests and needs of users. The sample space of them is\nmerely a small subset of the entire space, making it challenging to train an\nefficient model. In recent years, there have been many excellent studies\nrelated to cross-domain recommendation aimed at mitigating the problem of data\nsparsity. However, few of them have simultaneously considered the adaptability\nof both sample and representation continual transfer setting to the target\ntask. To overcome the above issue, we propose a Entire space Continual and\nAdaptive Transfer learning framework called ECAT which includes two core\ncomponents: First, as for sample transfer, we propose a two-stage method that\nrealizes a coarse-to-fine process. Specifically, we perform an initial\nselection through a graph-guided method, followed by a fine-grained selection\nusing domain adaptation method. Second, we propose an adaptive knowledge\ndistillation method for continually transferring the representations from a\nmodel that is well-trained on the entire space dataset. ECAT enables full\nutilization of the entire space samples and representations under the\nsupervision of the target task, while avoiding negative migration.\nComprehensive experiments on real-world industrial datasets from Taobao show\nthat ECAT advances state-of-the-art performance on offline metrics, and brings\n+13.6% CVR and +8.6% orders for Baiyibutie, a famous mini-app of Taobao.",
      "tldr_zh": "该研究针对推荐系统的跨域推荐问题，提出了一种名为 ECAT 的完整空间持续和自适应转移学习框架，以解决数据稀疏性及其样本和表示转移的适应性挑战。ECAT 包括两个核心组件：首先，通过一个两阶段样本转移方法（包括图引导的粗粒度选择和域适应方法的细粒度选择）来筛选和利用整个空间样本；其次，使用自适应知识 distillation 方法实现表示的持续转移，从而在目标任务监督下最大化利用数据并避免负面迁移。在 Taobao 的真实数据集实验中，ECAT 显著提升了最先进性能，实现了离线指标的改进，并为 Baiyibutie mini-app 带来了 +13.6% CVR 和 +8.6% 订单增长。",
      "categories": [
        "cs.IR",
        "cs.AI",
        "cs.LG"
      ],
      "primary_category": "cs.IR",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2407.02542v1",
      "published_date": "2024-07-02 07:02:39 UTC",
      "updated_date": "2024-07-02 07:02:39 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-19T03:01:24.177933"
    },
    {
      "arxiv_id": "2407.01979v1",
      "title": "Unveiling Global Interactive Patterns across Graphs: Towards Interpretable Graph Neural Networks",
      "title_zh": "揭示跨图的全局交互模式：朝向可解释的图神经网络",
      "authors": [
        "Yuwen Wang",
        "Shunyu Liu",
        "Tongya Zheng",
        "Kaixuan Chen",
        "Mingli Song"
      ],
      "abstract": "Graph Neural Networks (GNNs) have emerged as a prominent framework for graph\nmining, leading to significant advances across various domains. Stemmed from\nthe node-wise representations of GNNs, existing explanation studies have\nembraced the subgraph-specific viewpoint that attributes the decision results\nto the salient features and local structures of nodes. However, graph-level\ntasks necessitate long-range dependencies and global interactions for advanced\nGNNs, deviating significantly from subgraph-specific explanations. To bridge\nthis gap, this paper proposes a novel intrinsically interpretable scheme for\ngraph classification, termed as Global Interactive Pattern (GIP) learning,\nwhich introduces learnable global interactive patterns to explicitly interpret\ndecisions. GIP first tackles the complexity of interpretation by clustering\nnumerous nodes using a constrained graph clustering module. Then, it matches\nthe coarsened global interactive instance with a batch of self-interpretable\ngraph prototypes, thereby facilitating a transparent graph-level reasoning\nprocess. Extensive experiments conducted on both synthetic and real-world\nbenchmarks demonstrate that the proposed GIP yields significantly superior\ninterpretability and competitive performance to~the state-of-the-art\ncounterparts. Our code will be made publicly available.",
      "tldr_zh": "该论文指出，现有的图神经网络(GNNs)解释方法主要聚焦于节点级别的子图特征和局部结构，无法有效捕捉图级任务所需的全局交互和长程依赖。针对这一问题，研究提出了一种新的内在可解释方案——Global Interactive Pattern (GIP) 学习，通过受限图聚类模块简化节点聚类，并将粗化后的全局交互实例与自解释图原型匹配，实现透明的图级推理过程。实验在合成和真实世界基准数据集上证明，GIP 显著提升了可解释性，同时在性能上与最先进方法竞争，且代码将公开可用。",
      "categories": [
        "cs.LG",
        "cs.AI"
      ],
      "primary_category": "cs.LG",
      "comment": "Accepted in KDD2024",
      "pdf_url": "http://arxiv.org/pdf/2407.01979v1",
      "published_date": "2024-07-02 06:31:13 UTC",
      "updated_date": "2024-07-02 06:31:13 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-19T03:01:35.255079"
    },
    {
      "arxiv_id": "2407.01976v2",
      "title": "A Bounding Box is Worth One Token: Interleaving Layout and Text in a Large Language Model for Document Understanding",
      "title_zh": "翻译失败",
      "authors": [
        "Jinghui Lu",
        "Haiyang Yu",
        "Yanjie Wang",
        "Yongjie Ye",
        "Jingqun Tang",
        "Ziwei Yang",
        "Binghong Wu",
        "Qi Liu",
        "Hao Feng",
        "Han Wang",
        "Hao Liu",
        "Can Huang"
      ],
      "abstract": "Recently, many studies have demonstrated that exclusively incorporating\nOCR-derived text and spatial layouts with large language models (LLMs) can be\nhighly effective for document understanding tasks. However, existing methods\nthat integrate spatial layouts with text have limitations, such as producing\noverly long text sequences or failing to fully leverage the autoregressive\ntraits of LLMs. In this work, we introduce Interleaving Layout and Text in a\nLarge Language Model (LayTextLLM)} for document understanding. In particular,\nLayTextLLM projects each bounding box to a single embedding and interleaves it\nwith text, efficiently avoiding long sequence issues while leveraging\nautoregressive traits of LLMs. LayTextLLM not only streamlines the interaction\nof layout and textual data but also shows enhanced performance in Key\nInformation Extraction (KIE) and Visual Question Answering (VQA). Comprehensive\nbenchmark evaluations reveal significant improvements, with a 27.2% increase on\nKIE tasks and 12.0% on VQA tasks compared to previous state-of-the-art document\nunderstanding MLLMs, as well as a 15.1% improvement over other SOTA OCR-based\nLLMs on KIE tasks.",
      "tldr_zh": "本文提出 LayTextLLM，一种创新方法，将每个 bounding box 投影到一个 embedding 并与文本交错整合到 Large Language Models (LLMs) 中，以解决现有文档理解方法中序列过长和未充分利用 autoregressive 特性的问题。该框架高效地结合布局和文本数据，提升了 Key Information Extraction (KIE) 和 Visual Question Answering (VQA) 任务的性能。在基准测试中，LayTextLLM 在 KIE 任务上比之前的最先进多模态语言模型 (MLLMs) 提高了 27.2%，在 VQA 任务上提高了 12.0%，并在 KIE 任务上比其他 SOTA OCR-based LLMs 提高了 15.1%。",
      "categories": [
        "cs.CL",
        "cs.AI",
        "cs.MM"
      ],
      "primary_category": "cs.CL",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2407.01976v2",
      "published_date": "2024-07-02 06:29:05 UTC",
      "updated_date": "2024-07-24 11:45:48 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-19T03:01:49.036202"
    },
    {
      "arxiv_id": "2407.04737v2",
      "title": "Hierarchical Decoupling Capacitor Optimization for Power Distribution Network of 2.5D ICs with Co-Analysis of Frequency and Time Domains Based on Deep Reinforcement Learning",
      "title_zh": "翻译失败",
      "authors": [
        "Yuanyuan Duan",
        "Haiyang Feng",
        "Zhiping Yu",
        "Hanming Wu",
        "Leilai Shao",
        "Xiaolei Zhu"
      ],
      "abstract": "With the growing need for higher memory bandwidth and computation density,\n2.5D design, which involves integrating multiple chiplets onto an interposer,\nemerges as a promising solution. However, this integration introduces\nsignificant challenges due to increasing data rates and a large number of I/Os,\nnecessitating advanced optimization of the power distribution networks (PDNs)\nboth on-chip and on-interposer to mitigate the small signal noise and\nsimultaneous switching noise (SSN). Traditional PDN optimization strategies in\n2.5D systems primarily focus on reducing impedance by integrating decoupling\ncapacitors (decaps) to lessen small signal noises. Unfortunately, relying\nsolely on frequency-domain analysis has been proven inadequate for addressing\ncoupled SSN, as indicated by our experimental results. In this work, we\nintroduce a novel two-phase optimization flow using deep reinforcement learning\nto tackle both the on-chip small signal noise and SSN. Initially, we optimize\nthe impedance in the frequency domain to maintain the small signal noise within\nacceptable limits while avoiding over-design. Subsequently, in the time domain,\nwe refine the PDN to minimize the voltage violation integral (VVI), a more\naccurate measure of SSN severity. To the best of our knowledge, this is the\nfirst dual-domain optimization strategy that simultaneously addresses both the\nsmall signal noise and SSN propagation through strategic decap placement in\non-chip and on-interposer PDNs, offering a significant step forward in the\ndesign of robust PDNs for 2.5D integrated systems.",
      "tldr_zh": "本文研究了 2.5D ICs 的功率分布网络 (PDN) 优化问题，针对集成多芯片带来的小信号噪声和 SSN（Simultaneous Switching Noise）挑战。传统方法主要依赖频率域分析，通过添加 decaps（去耦电容）来降低噪声，但无法有效处理 SSN 的耦合效应。论文提出一种基于 Deep Reinforcement Learning 的双阶段优化流程：首先在频率域优化阻抗以控制小信号噪声并避免过度设计，其次在时间域最小化 VVI（Voltage Violation Integral），从而减少 SSN。实验结果表明，这种分层优化策略首次同时解决两种噪声问题，通过在 on-chip 和 on-interposer PDNs 中的战略性 decap 放置，大大提升了 2.5D 系统的鲁棒性。",
      "categories": [
        "eess.SP",
        "cs.AI"
      ],
      "primary_category": "eess.SP",
      "comment": "The data needs to be experimentally revalidated, and the experimental\n  details require further optimization",
      "pdf_url": "http://arxiv.org/pdf/2407.04737v2",
      "published_date": "2024-07-02 06:12:55 UTC",
      "updated_date": "2024-09-27 03:22:07 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-19T03:02:03.711754"
    },
    {
      "arxiv_id": "2407.01972v1",
      "title": "MeMemo: On-device Retrieval Augmentation for Private and Personalized Text Generation",
      "title_zh": "翻译失败",
      "authors": [
        "Zijie J. Wang",
        "Duen Horng Chau"
      ],
      "abstract": "Retrieval-augmented text generation (RAG) addresses the common limitations of\nlarge language models (LLMs), such as hallucination, by retrieving information\nfrom an updatable external knowledge base. However, existing approaches often\nrequire dedicated backend servers for data storage and retrieval, thereby\nlimiting their applicability in use cases that require strict data privacy,\nsuch as personal finance, education, and medicine. To address the pressing need\nfor client-side dense retrieval, we introduce MeMemo, the first open-source\nJavaScript toolkit that adapts the state-of-the-art approximate nearest\nneighbor search technique HNSW to browser environments. Developed with modern\nand native Web technologies, such as IndexedDB and Web Workers, our toolkit\nleverages client-side hardware capabilities to enable researchers and\ndevelopers to efficiently search through millions of high-dimensional vectors\nin the browser. MeMemo enables exciting new design and research opportunities,\nsuch as private and personalized content creation and interactive prototyping,\nas demonstrated in our example application RAG Playground. Reflecting on our\nwork, we discuss the opportunities and challenges for on-device dense\nretrieval. MeMemo is available at https://github.com/poloclub/mememo.",
      "tldr_zh": "本研究提出 MeMemo，这是一个开源 JavaScript 工具包，用于实现客户端检索增强生成 (RAG)，以解决大型语言模型 (LLMs) 如幻觉的问题，同时确保数据隐私。MeMemo 将先进的近似最近邻搜索技术 HNSW 适应到浏览器环境中，利用 IndexedDB 和 Web Workers 等 Web 技术，在本地硬件上高效搜索数百万高维向量，支持私人化和个性化的文本生成。实验展示了其在 RAG Playground 等应用的潜力，并讨论了客户端密集检索的机遇与挑战。",
      "categories": [
        "cs.IR",
        "cs.AI",
        "cs.HC",
        "cs.LG"
      ],
      "primary_category": "cs.IR",
      "comment": "Accepted to SIGIR 2024. 6 pages, 2 figures. For a live demo, visit\n  https://poloclub.github.io/mememo/. Code is open-source at\n  https://github.com/poloclub/mememo",
      "pdf_url": "http://arxiv.org/pdf/2407.01972v1",
      "published_date": "2024-07-02 06:08:55 UTC",
      "updated_date": "2024-07-02 06:08:55 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-19T03:02:13.022177"
    },
    {
      "arxiv_id": "2407.17480v4",
      "title": "Dynamic Universal Approximation Theory: The Basic Theory for Deep Learning-Based Computer Vision Models",
      "title_zh": "动态通用逼近理论：基于深度学习的计算机视觉模型基础理论",
      "authors": [
        "Wei Wang",
        "Qing Li"
      ],
      "abstract": "Computer vision (CV) is one of the most crucial fields in artificial\nintelligence. In recent years, a variety of deep learning models based on\nconvolutional neural networks (CNNs) and Transformers have been designed to\ntackle diverse problems in CV. These algorithms have found practical\napplications in areas such as robotics and facial recognition. Despite the\nincreasing power of current CV models, several fundamental questions remain\nunresolved: Why do CNNs require deep layers? What ensures the generalization\nability of CNNs? Why do residual-based networks outperform fully convolutional\nnetworks like VGG? What is the fundamental difference between residual-based\nCNNs and Transformer-based networks? Why can CNNs utilize LoRA and pruning\ntechniques? The root cause of these questions lies in the lack of a robust\ntheoretical foundation for deep learning models in CV. To address these\ncritical issues and techniques, we employ the Universal Approximation Theorem\n(UAT) to provide a theoretical basis for convolution- and Transformer-based\nmodels in CV. By doing so, we aim to elucidate these questions from a\ntheoretical perspective.",
      "tldr_zh": "本论文提出Dynamic Universal Approximation Theory，作为计算机视觉(CV)中基于深层学习模型的理论基础，针对CNN和Transformer模型的关键问题进行探讨，包括CNN为何需要深层结构、其泛化能力来源，以及残差网络与全卷积网络如VGG的差异。作者应用Universal Approximation Theorem (UAT)来为这些模型提供理论支撑，解释Transformer-based网络的根本区别以及CNN能利用LoRA和剪枝技术的原因。通过这一框架，论文旨在从理论角度解决CV领域的未解难题，提升模型设计的可解释性。",
      "categories": [
        "cs.CV",
        "cs.AI"
      ],
      "primary_category": "cs.CV",
      "comment": "arXiv admin note: text overlap with arXiv:2407.00958",
      "pdf_url": "http://arxiv.org/pdf/2407.17480v4",
      "published_date": "2024-07-02 06:08:30 UTC",
      "updated_date": "2024-11-29 06:15:05 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-19T03:02:27.065720"
    },
    {
      "arxiv_id": "2407.01953v1",
      "title": "CatMemo at the FinLLM Challenge Task: Fine-Tuning Large Language Models using Data Fusion in Financial Applications",
      "title_zh": "翻译失败",
      "authors": [
        "Yupeng Cao",
        "Zhiyuan Yao",
        "Zhi Chen",
        "Zhiyang Deng"
      ],
      "abstract": "The integration of Large Language Models (LLMs) into financial analysis has\ngarnered significant attention in the NLP community. This paper presents our\nsolution to IJCAI-2024 FinLLM challenge, investigating the capabilities of LLMs\nwithin three critical areas of financial tasks: financial classification,\nfinancial text summarization, and single stock trading. We adopted Llama3-8B\nand Mistral-7B as base models, fine-tuning them through Parameter Efficient\nFine-Tuning (PEFT) and Low-Rank Adaptation (LoRA) approaches. To enhance model\nperformance, we combine datasets from task 1 and task 2 for data fusion. Our\napproach aims to tackle these diverse tasks in a comprehensive and integrated\nmanner, showcasing LLMs' capacity to address diverse and complex financial\ntasks with improved accuracy and decision-making capabilities.",
      "tldr_zh": "这篇论文介绍了CatMemo解决方案，针对IJCAI-2024 FinLLM挑战，在金融领域应用Large Language Models (LLMs)，涵盖金融分类、财务文本摘要和单股票交易任务。研究团队以Llama3-8B和Mistral-7B作为基模型，通过Parameter Efficient Fine-Tuning (PEFT)和Low-Rank Adaptation (LoRA)进行微调，以优化模型性能。采用数据融合方法，将任务1和任务2的数据集结合，实现对多样化金融任务的综合处理，提升了准确性和决策能力。",
      "categories": [
        "cs.CE",
        "cs.AI",
        "cs.LG",
        "q-fin.CP"
      ],
      "primary_category": "cs.CE",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2407.01953v1",
      "published_date": "2024-07-02 05:04:13 UTC",
      "updated_date": "2024-07-02 05:04:13 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-19T03:02:38.602925"
    },
    {
      "arxiv_id": "2407.01950v1",
      "title": "LDP: A Local Diffusion Planner for Efficient Robot Navigation and Collision Avoidance",
      "title_zh": "LDP：一种本地扩散规划器，用于高效机器人导航和碰撞避免",
      "authors": [
        "Wenhao Yu",
        "Jie Peng",
        "Huanyu Yang",
        "Junrui Zhang",
        "Yifan Duan",
        "Jianmin Ji",
        "Yanyong Zhang"
      ],
      "abstract": "The conditional diffusion model has been demonstrated as an efficient tool\nfor learning robot policies, owing to its advancement to accurately model the\nconditional distribution of policies. The intricate nature of real-world\nscenarios, characterized by dynamic obstacles and maze-like structures,\nunderscores the complexity of robot local navigation decision-making as a\nconditional distribution problem. Nevertheless, leveraging the diffusion model\nfor robot local navigation is not trivial and encounters several under-explored\nchallenges: (1) Data Urgency. The complex conditional distribution in local\nnavigation needs training data to include diverse policy in diverse real-world\nscenarios; (2) Myopic Observation. Due to the diversity of the perception\nscenarios, diffusion decisions based on the local perspective of robots may\nprove suboptimal for completing the entire task, as they often lack foresight.\nIn certain scenarios requiring detours, the robot may become trapped. To\naddress these issues, our approach begins with an exploration of a diverse data\ngeneration mechanism that encompasses multiple agents exhibiting distinct\npreferences through target selection informed by integrated global-local\ninsights. Then, based on this diverse training data, a diffusion agent is\nobtained, capable of excellent collision avoidance in diverse scenarios.\nSubsequently, we augment our Local Diffusion Planner, also known as LDP by\nincorporating global observations in a lightweight manner. This enhancement\nbroadens the observational scope of LDP, effectively mitigating the risk of\nbecoming ensnared in local optima and promoting more robust navigational\ndecisions.",
      "tldr_zh": "该论文提出 LDP（Local Diffusion Planner），一种基于条件扩散模型（conditional diffusion model）的本地规划框架，用于提升机器人导航效率和碰撞避免能力，以应对真实场景中动态障碍和迷宫结构的复杂性。论文首先解决数据紧迫性（Data Urgency）问题，通过一种多样化数据生成机制，利用集成全局-本地洞见的目标选择来创建涵盖多种代理偏好的训练数据；随后，基于这些数据训练扩散代理（diffusion agent），实现优秀的碰撞避免。最终，LDP 通过轻量级方式融入全局观察，扩展机器人视角，减少短视观察（Myopic Observation）导致的局部最优风险，从而促进更稳健的导航决策。",
      "categories": [
        "cs.RO",
        "cs.AI"
      ],
      "primary_category": "cs.RO",
      "comment": "8 pages, 6 figures, accepted by IROS 2024",
      "pdf_url": "http://arxiv.org/pdf/2407.01950v1",
      "published_date": "2024-07-02 04:53:35 UTC",
      "updated_date": "2024-07-02 04:53:35 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-19T03:02:50.751840"
    },
    {
      "arxiv_id": "2407.01948v1",
      "title": "Extracting and Encoding: Leveraging Large Language Models and Medical Knowledge to Enhance Radiological Text Representation",
      "title_zh": "提取与编码：利用大型语言模型和医学知识增强放射学文本表示",
      "authors": [
        "Pablo Messina",
        "René Vidal",
        "Denis Parra",
        "Álvaro Soto",
        "Vladimir Araujo"
      ],
      "abstract": "Advancing representation learning in specialized fields like medicine remains\nchallenging due to the scarcity of expert annotations for text and images. To\ntackle this issue, we present a novel two-stage framework designed to extract\nhigh-quality factual statements from free-text radiology reports in order to\nimprove the representations of text encoders and, consequently, their\nperformance on various downstream tasks. In the first stage, we propose a\n\\textit{Fact Extractor} that leverages large language models (LLMs) to identify\nfactual statements from well-curated domain-specific datasets. In the second\nstage, we introduce a \\textit{Fact Encoder} (CXRFE) based on a BERT model\nfine-tuned with objective functions designed to improve its representations\nusing the extracted factual data. Our framework also includes a new\nembedding-based metric (CXRFEScore) for evaluating chest X-ray text generation\nsystems, leveraging both stages of our approach. Extensive evaluations show\nthat our fact extractor and encoder outperform current state-of-the-art methods\nin tasks such as sentence ranking, natural language inference, and label\nextraction from radiology reports. Additionally, our metric proves to be more\nrobust and effective than existing metrics commonly used in the radiology\nreport generation literature. The code of this project is available at\n\\url{https://github.com/PabloMessina/CXR-Fact-Encoder}.",
      "tldr_zh": "本研究提出了一种两阶段框架，利用大型语言模型(LLMs)和医疗知识，从放射学报告中提取高质量事实陈述，以提升文本编码器的表示学习能力，从而改善下游任务的性能。第一阶段的Fact Extractor基于LLMs，从特定领域的精选数据集识别事实语句；第二阶段的Fact Encoder (CXRFE)则通过微调BERT模型，并使用提取的数据设计目标函数来优化表示。该框架还引入了新的嵌入式评估指标(CXRFEScore)，用于评估胸部X光文本生成系统。实验结果显示，该方法在句子排序、自然语言推理和标签提取任务上优于现有最先进方法，且CXRFEScore更具鲁棒性。",
      "categories": [
        "cs.CL",
        "cs.AI",
        "cs.LG"
      ],
      "primary_category": "cs.CL",
      "comment": "Accepted to ACL 2024 (Findings)",
      "pdf_url": "http://arxiv.org/pdf/2407.01948v1",
      "published_date": "2024-07-02 04:39:19 UTC",
      "updated_date": "2024-07-02 04:39:19 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-19T03:03:01.802062"
    },
    {
      "arxiv_id": "2407.01942v1",
      "title": "Certainly Uncertain: A Benchmark and Metric for Multimodal Epistemic and Aleatoric Awareness",
      "title_zh": "翻译失败",
      "authors": [
        "Khyathi Raghavi Chandu",
        "Linjie Li",
        "Anas Awadalla",
        "Ximing Lu",
        "Jae Sung Park",
        "Jack Hessel",
        "Lijuan Wang",
        "Yejin Choi"
      ],
      "abstract": "The ability to acknowledge the inevitable uncertainty in their knowledge and\nreasoning is a prerequisite for AI systems to be truly truthful and reliable.\nIn this paper, we present a taxonomy of uncertainty specific to vision-language\nAI systems, distinguishing between epistemic uncertainty (arising from a lack\nof information) and aleatoric uncertainty (due to inherent unpredictability),\nand further explore finer categories within. Based on this taxonomy, we\nsynthesize a benchmark dataset, CertainlyUncertain, featuring 178K visual\nquestion answering (VQA) samples as contrastive pairs. This is achieved by 1)\ninpainting images to make previously answerable questions into unanswerable\nones; and 2) using image captions to prompt large language models for both\nanswerable and unanswerable questions. Additionally, we introduce a new metric\nconfidence-weighted accuracy, that is well correlated with both accuracy and\ncalibration error, to address the shortcomings of existing metrics.",
      "tldr_zh": "本论文探讨了视觉语言AI系统处理不确定性的能力，提出了一种针对epistemic uncertainty（认识论不确定性，因信息不足）和aleatoric uncertainty（偶然不确定性，因固有不可预测性）的分类框架，以提升AI的真实性和可靠性。研究者构建了名为CertainlyUncertain的基准数据集，包含178K个视觉问答（VQA）样本的对偶对，通过图像inpainting和利用图像标题提示large language models生成可回答与不可回答的问题。论文还引入了confidence-weighted accuracy新指标，该指标与准确性和校准误差高度相关，解决了现有评估方法的不足。",
      "categories": [
        "cs.AI",
        "cs.CL",
        "cs.CV"
      ],
      "primary_category": "cs.AI",
      "comment": "26 pages",
      "pdf_url": "http://arxiv.org/pdf/2407.01942v1",
      "published_date": "2024-07-02 04:23:54 UTC",
      "updated_date": "2024-07-02 04:23:54 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-19T03:03:12.855590"
    },
    {
      "arxiv_id": "2407.11024v5",
      "title": "A mathematical framework of intelligence and consciousness based on Riemannian Geometry",
      "title_zh": "翻译失败",
      "authors": [
        "Meng Lu"
      ],
      "abstract": "Understanding intelligence is a central pursuit in neuroscience, cognitive\nscience, and artificial intelligence. Intelligence encompasses learning,\nproblem-solving, creativity, and even consciousness. Recent advancements in\ngeometric analysis have revealed new insights into high-dimensional information\nrepresentation and organisation, exposing intrinsic data structures and dynamic\nprocesses within neural and artificial systems. However, a comprehensive\nframework that unifies the static and dynamic aspects of intelligence is still\nlacking. This manuscript proposes a mathematical framework based on Riemannian\ngeometry to describe the structure and dynamics of intelligence and\nconsciousness. Intelligence elements are conceptualised as tokens embedded in a\nhigh-dimensional space. The learned token embeddings capture the\ninterconnections of tokens across various scenarios and tasks, forming\nmanifolds in the intelligence space. Thought flow is depicted as the sequential\nactivation of tokens along geodesics within these manifolds. During the\nnavigation of geodesics, consciousness, as a self-referential process,\nperceives the thought flow, evaluates it against predictions, and provides\nfeedback through prediction errors, adjusting the geodesic: non-zero prediction\nerrors, such as learning, lead to the restructuring of the curved manifolds,\nthus changing the geodesic of thought flow. This dynamic interaction integrates\nnew information, evolves the geometry and facilitates learning. The geometry of\nintelligence guides consciousness, and consciousness structures the geometry of\nintelligence. By integrating geometric concepts, this proposed theory offers a\nunified, mathematically framework for describing the structure and dynamics of\nintelligence and consciousness. Applicable to biological and artificial\nintelligence, this framework may pave the way for future research and empirical\nvalidation.",
      "tldr_zh": "本文基于 Riemannian Geometry 提出一个统一的数学框架，用于描述智能和意识的结构与动态。智能元素被视为嵌入高维空间的 tokens，这些 tokens 的嵌入形成 manifolds，以捕捉不同场景和任务间的 interconnections。思想流（thought flow）表现为 tokens 沿 geodesics 的顺序激活，而意识作为自指过程，通过评估 prediction errors 提供反馈，调整 geodesics 并重构 manifolds，从而促进学习和信息整合。该框架适用于生物和人工智能，为未来研究和实证验证铺平道路。",
      "categories": [
        "cs.AI",
        "math.DG"
      ],
      "primary_category": "cs.AI",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2407.11024v5",
      "published_date": "2024-07-02 04:17:56 UTC",
      "updated_date": "2024-11-10 08:46:40 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-19T03:03:25.967769"
    },
    {
      "arxiv_id": "2407.01929v3",
      "title": "What We Talk About When We Talk About LMs: Implicit Paradigm Shifts and the Ship of Language Models",
      "title_zh": "翻译失败",
      "authors": [
        "Shengqi Zhu",
        "Jeffrey M. Rzeszotarski"
      ],
      "abstract": "The term Language Models (LMs) as a time-specific collection of models of\ninterest is constantly reinvented, with its referents updated much like the\n$\\textit{Ship of Theseus}$ replaces its parts but remains the same ship in\nessence. In this paper, we investigate this $\\textit{Ship of Language Models}$\nproblem, wherein scientific evolution takes the form of continuous, implicit\nretrofits of key existing terms. We seek to initiate a novel perspective of\nscientific progress, in addition to the more well-studied emergence of new\nterms. To this end, we construct the data infrastructure based on recent NLP\npublications. Then, we perform a series of text-based analyses toward a\ndetailed, quantitative understanding of the use of Language Models as a term of\nart. Our work highlights how systems and theories influence each other in\nscientific discourse, and we call for attention to the transformation of this\nShip that we all are contributing to.",
      "tldr_zh": "这篇论文探讨了“Language Models (LMs)”术语的演变问题，类似于“Ship of Theseus”隐喻，强调科学话语中现有术语的隐式更新和范式转移，而不是仅依赖新术语的出现。作者构建了基于最近 NLP 出版物的数据库，并通过文本分析量化 LMs 作为专业术语的使用方式。研究揭示了系统与理论如何相互影响，并呼吁学术界关注这种持续演变，以更好地理解科学进步的动态过程。",
      "categories": [
        "cs.CL",
        "cs.AI"
      ],
      "primary_category": "cs.CL",
      "comment": "NAACL 2025",
      "pdf_url": "http://arxiv.org/pdf/2407.01929v3",
      "published_date": "2024-07-02 03:45:55 UTC",
      "updated_date": "2025-02-09 06:15:33 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-19T03:03:37.466310"
    },
    {
      "arxiv_id": "2407.01920v2",
      "title": "To Forget or Not? Towards Practical Knowledge Unlearning for Large Language Models",
      "title_zh": "翻译失败",
      "authors": [
        "Bozhong Tian",
        "Xiaozhuan Liang",
        "Siyuan Cheng",
        "Qingbin Liu",
        "Mengru Wang",
        "Dianbo Sui",
        "Xi Chen",
        "Huajun Chen",
        "Ningyu Zhang"
      ],
      "abstract": "Large Language Models (LLMs) trained on extensive corpora inevitably retain\nsensitive data, such as personal privacy information and copyrighted material.\nRecent advancements in knowledge unlearning involve updating LLM parameters to\nerase specific knowledge. However, current unlearning paradigms are mired in\nvague forgetting boundaries, often erasing knowledge indiscriminately. In this\nwork, we introduce KnowUnDo, a benchmark containing copyrighted content and\nuser privacy domains to evaluate if the unlearning process inadvertently erases\nessential knowledge. Our findings indicate that existing unlearning methods\noften suffer from excessive unlearning. To address this, we propose a simple\nyet effective method, MemFlex, which utilizes gradient information to precisely\ntarget and unlearn sensitive parameters. Experimental results show that MemFlex\nis superior to existing methods in both precise knowledge unlearning and\ngeneral knowledge retaining of LLMs. Code and dataset are released at\nhttps://github.com/zjunlp/KnowUnDo.",
      "tldr_zh": "本研究探讨了大型语言模型（LLMs）在训练过程中保留敏感数据（如个人隐私和版权材料）的问题，现有知识遗忘方法往往因模糊边界而导致过度遗忘。作者引入 KnowUnDo 基准，用于评估遗忘过程是否意外擦除必要知识，并提出 MemFlex 方法，该方法利用梯度信息精确针对敏感参数进行遗忘。实验结果表明，MemFlex 在精确知识遗忘和保留一般知识方面均优于现有方法，并开源了代码和数据集。",
      "categories": [
        "cs.CL",
        "cs.AI",
        "cs.CV",
        "cs.LG",
        "cs.MM"
      ],
      "primary_category": "cs.CL",
      "comment": "EMNLP 2024 Findings; Code and dataset are released at\n  https://github.com/zjunlp/KnowUnDo",
      "pdf_url": "http://arxiv.org/pdf/2407.01920v2",
      "published_date": "2024-07-02 03:34:16 UTC",
      "updated_date": "2024-10-06 15:49:20 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-19T03:03:49.328763"
    },
    {
      "arxiv_id": "2407.01919v1",
      "title": "A Method to Facilitate Membership Inference Attacks in Deep Learning Models",
      "title_zh": "翻译失败",
      "authors": [
        "Zitao Chen",
        "Karthik Pattabiraman"
      ],
      "abstract": "Modern machine learning (ML) ecosystems offer a surging number of ML\nframeworks and code repositories that can greatly facilitate the development of\nML models. Today, even ordinary data holders who are not ML experts can apply\noff-the-shelf codebase to build high-performance ML models on their data, many\nof which are sensitive in nature (e.g., clinical records).\n  In this work, we consider a malicious ML provider who supplies model-training\ncode to the data holders, does not have access to the training process, and has\nonly black-box query access to the resulting model. In this setting, we\ndemonstrate a new form of membership inference attack that is strictly more\npowerful than prior art. Our attack empowers the adversary to reliably\nde-identify all the training samples (average >99% attack TPR@0.1% FPR), and\nthe compromised models still maintain competitive performance as their\nuncorrupted counterparts (average <1% accuracy drop). Moreover, we show that\nthe poisoned models can effectively disguise the amplified membership leakage\nunder common membership privacy auditing, which can only be revealed by a set\nof secret samples known by the adversary.\n  Overall, our study not only points to the worst-case membership privacy\nleakage, but also unveils a common pitfall underlying existing privacy auditing\nmethods, which calls for future efforts to rethink the current practice of\nauditing membership privacy in machine learning models.",
      "tldr_zh": "该研究提出了一种新的方法，以促进 membership inference attacks 在深度学习模型中的应用，针对恶意 ML 提供者场景，该提供者通过提供模型训练代码并仅利用黑箱查询访问来识别训练样本。实验结果显示，该攻击能够以高准确率（平均 >99% TPR@0.1% FPR）可靠地反向识别所有训练样本，同时保持模型性能几乎不变（平均 <1% 准确率下降）。此外，该方法能有效隐藏泄露风险，规避常见 membership 隐私审计，仅通过攻击者持有的秘密样本才能被揭示，从而强调了最坏情况下的隐私风险并呼吁重新审视现有审计实践。",
      "categories": [
        "cs.CR",
        "cs.AI",
        "cs.CV"
      ],
      "primary_category": "cs.CR",
      "comment": "NDSS'25 (a shorter version of this paper will appear in the\n  conference proceeding)",
      "pdf_url": "http://arxiv.org/pdf/2407.01919v1",
      "published_date": "2024-07-02 03:33:42 UTC",
      "updated_date": "2024-07-02 03:33:42 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-19T03:04:03.505307"
    },
    {
      "arxiv_id": "2407.12822v1",
      "title": "Lightweight Large Language Model for Medication Enquiry: Med-Pal",
      "title_zh": "轻量级大语言模型",
      "authors": [
        "Kabilan Elangovan",
        "Jasmine Chiat Ling Ong",
        "Liyuan Jin",
        "Benjamin Jun Jie Seng",
        "Yu Heng Kwan",
        "Lit Soo Tan",
        "Ryan Jian Zhong",
        "Justina Koi Li Ma",
        "YuHe Ke",
        "Nan Liu",
        "Kathleen M Giacomini",
        "Daniel Shu Wei Ting"
      ],
      "abstract": "Large Language Models (LLMs) have emerged as a potential solution to assist\ndigital health development with patient education, commonly medication-related\nenquires. We trained and validated Med-Pal, a medication domain-specific\nLLM-chatbot fine-tuned with a fine-grained and expert curated dataset from a\nselection of five light-weighted open-source LLMs of smaller parameter size (7\nbillion or less) regarding computational constraints and prioritizing\noperational efficiency. A multi-disciplinary team performed a clinical\nevaluation of LLMs responses using the SCORE criteria, focusing on safety,\naccuracy, bias, reproducibility, and ease of understanding. Best performing\nlight-weighted LLM was chosen as Med-Pal for further engineering with\nguard-railing using adversarial prompting. Med-Pal and existing light-weighted\nLLMs, including pretrained Biomistral and finetuned Meerkat, were validated on\nan independent dataset on a broad range of medication-related questions (231 in\ntotal), 12 different question types across 14 different medication classes.\nMistral-7b emerged as the top performer among selected lightweight LLMs,\nachieving the highest median score of 14 and 71.9% high-quality responses in\naccuracy and safety domains, hence chosen as the backbone LLM for Med-Pal. When\ncompared against Biomistral, Med-pal outperformed in generating responses\nappropriate for patient communication, with significant reductions bias and\nerrors typical of general LLMs. Comparable performance was observed when\ncomparing Med-Pal with Meerkat. Med-Pal showcases the feasibility of developing\nand employing fine-tuned light-weighted LLMs to enhance digital health\ncommunications.",
      "tldr_zh": "本研究开发了 Med-Pal，一种轻量级大语言模型(LLM)，针对药物查询提供患者教育支持，通过微调选定的开源 LLM（如 Mistral-7b 等参数规模7亿或更少）并使用专家策划的数据集进行训练和优化。研究团队采用 SCORE 标准（包括安全性、准确性、偏差、再现性和易懂性）进行多学科临床评估，并通过对抗性提示添加守卫机制以提升可靠性。在独立数据集上验证显示，Med-Pal 在231个药物相关问题中表现出色，准确性和安全性得分最高（中位数14，71.9%高质响应），并在减少偏差和错误方面优于 Biomistral 和 Meerkat 等模型，证明了轻量级 LLM 在数字健康通信中的可行性。",
      "categories": [
        "cs.CL",
        "cs.AI"
      ],
      "primary_category": "cs.CL",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2407.12822v1",
      "published_date": "2024-07-02 03:32:39 UTC",
      "updated_date": "2024-07-02 03:32:39 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-19T03:04:15.204696"
    },
    {
      "arxiv_id": "2407.01916v1",
      "title": "Sequential Manipulation Against Rank Aggregation: Theory and Algorithm",
      "title_zh": "针对排名聚合的顺序操纵：理论和算法",
      "authors": [
        "Ke Ma",
        "Qianqian Xu",
        "Jinshan Zeng",
        "Wei Liu",
        "Xiaochun Cao",
        "Yingfei Sun",
        "Qingming Huang"
      ],
      "abstract": "Rank aggregation with pairwise comparisons is widely encountered in\nsociology, politics, economics, psychology, sports, etc . Given the enormous\nsocial impact and the consequent incentives, the potential adversary has a\nstrong motivation to manipulate the ranking list. However, the ideal attack\nopportunity and the excessive adversarial capability cause the existing methods\nto be impractical. To fully explore the potential risks, we leverage an online\nattack on the vulnerable data collection process. Since it is independent of\nrank aggregation and lacks effective protection mechanisms, we disrupt the data\ncollection process by fabricating pairwise comparisons without knowledge of the\nfuture data or the true distribution. From the game-theoretic perspective, the\nconfrontation scenario between the online manipulator and the ranker who takes\ncontrol of the original data source is formulated as a distributionally robust\ngame that deals with the uncertainty of knowledge. Then we demonstrate that the\nequilibrium in the above game is potentially favorable to the adversary by\nanalyzing the vulnerability of the sampling algorithms such as Bernoulli and\nreservoir methods. According to the above theoretical analysis, different\nsequential manipulation policies are proposed under a Bayesian decision\nframework and a large class of parametric pairwise comparison models. For\nattackers with complete knowledge, we establish the asymptotic optimality of\nthe proposed policies. To increase the success rate of the sequential\nmanipulation with incomplete knowledge, a distributionally robust estimator,\nwhich replaces the maximum likelihood estimation in a saddle point problem,\nprovides a conservative data generation solution. Finally, the corroborating\nempirical evidence shows that the proposed method manipulates the results of\nrank aggregation methods in a sequential manner.",
      "tldr_zh": "这篇论文探讨了在排序聚合(rank aggregation)中使用配对比较的场景中，潜在攻击者通过在线操纵数据收集过程来伪造配对比较，从而干扰排名结果的问题。作者从博弈论视角，将攻击者与排名者之间的对抗建模为一个分布鲁棒游戏(distributionally robust game)，并分析了采样算法如Bernoulli和reservoir方法的漏洞，证明均衡可能对攻击者有利。论文提出基于贝叶斯决策框架的顺序操纵策略和算法，对于有完整知识的攻击者建立渐近最优性，并通过分布鲁棒估计器提升不完整知识场景下的成功率；实验结果验证了这些方法的有效性。",
      "categories": [
        "cs.AI"
      ],
      "primary_category": "cs.AI",
      "comment": "Accepted by IEEE TPAMI URL:\n  https://ieeexplore.ieee.org/document/10564181",
      "pdf_url": "http://arxiv.org/pdf/2407.01916v1",
      "published_date": "2024-07-02 03:31:21 UTC",
      "updated_date": "2024-07-02 03:31:21 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-19T03:04:27.119547"
    },
    {
      "arxiv_id": "2407.01910v2",
      "title": "MG-Verilog: Multi-grained Dataset Towards Enhanced LLM-assisted Verilog Generation",
      "title_zh": "翻译失败",
      "authors": [
        "Yongan Zhang",
        "Zhongzhi Yu",
        "Yonggan Fu",
        "Cheng Wan",
        "Yingyan Celine Lin"
      ],
      "abstract": "Large Language Models (LLMs) have recently shown promise in streamlining\nhardware design processes by encapsulating vast amounts of domain-specific\ndata. In addition, they allow users to interact with the design processes\nthrough natural language instructions, thus making hardware design more\naccessible to developers. However, effectively leveraging LLMs in hardware\ndesign necessitates providing domain-specific data during inference (e.g.,\nthrough in-context learning), fine-tuning, or pre-training. Unfortunately,\nexisting publicly available hardware datasets are often limited in size,\ncomplexity, or detail, which hinders the effectiveness of LLMs in hardware\ndesign tasks. To address this issue, we first propose a set of criteria for\ncreating high-quality hardware datasets that can effectively enhance\nLLM-assisted hardware design. Based on these criteria, we propose a\nMulti-Grained-Verilog (MG-Verilog) dataset, which encompasses descriptions at\nvarious levels of detail and corresponding code samples. To benefit the broader\nhardware design community, we have developed an open-source infrastructure that\nfacilitates easy access, integration, and extension of the dataset to meet\nspecific project needs. Furthermore, to fully exploit the potential of the\nMG-Verilog dataset, which varies in complexity and detail, we introduce a\nbalanced fine-tuning scheme. This scheme serves as a unique use case to\nleverage the diverse levels of detail provided by the dataset. Extensive\nexperiments demonstrate that the proposed dataset and fine-tuning scheme\nconsistently improve the performance of LLMs in hardware design tasks.",
      "tldr_zh": "该研究针对 Large Language Models (LLMs) 在硬件设计中的局限性（如现有数据集规模、复杂度和细节不足），提出了一套创建高质量硬件数据集的标准，并开发了 Multi-Grained-Verilog (MG-Verilog) 数据集，该数据集包含多粒度描述和对应代码样本，以提升 LLMs 辅助 Verilog 生成的性能。同时，他们构建了开源基础设施，便于数据集的访问、集成和扩展，并引入一个平衡的 fine-tuning 方案来充分利用数据集的多样性。实验结果显示，该数据集和 fine-tuning 方法显著提高了 LLMs 在硬件设计任务中的整体表现。",
      "categories": [
        "cs.LG",
        "cs.AI",
        "cs.AR"
      ],
      "primary_category": "cs.LG",
      "comment": "Accepted in ISLAD 2024",
      "pdf_url": "http://arxiv.org/pdf/2407.01910v2",
      "published_date": "2024-07-02 03:21:24 UTC",
      "updated_date": "2024-07-03 15:15:20 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-19T03:04:37.588809"
    },
    {
      "arxiv_id": "2407.01906v2",
      "title": "Let the Expert Stick to His Last: Expert-Specialized Fine-Tuning for Sparse Architectural Large Language Models",
      "title_zh": "翻译失败",
      "authors": [
        "Zihan Wang",
        "Deli Chen",
        "Damai Dai",
        "Runxin Xu",
        "Zhuoshu Li",
        "Y. Wu"
      ],
      "abstract": "Parameter-efficient fine-tuning (PEFT) is crucial for customizing Large\nLanguage Models (LLMs) with constrained resources. Although there have been\nvarious PEFT methods for dense-architecture LLMs, PEFT for sparse-architecture\nLLMs is still underexplored. In this work, we study the PEFT method for LLMs\nwith the Mixture-of-Experts (MoE) architecture and the contents of this work\nare mainly threefold: (1) We investigate the dispersion degree of the activated\nexperts in customized tasks, and found that the routing distribution for a\nspecific task tends to be highly concentrated, while the distribution of\nactivated experts varies significantly across different tasks. (2) We propose\nExpert-Specialized Fine-Tuning, or ESFT, which tunes the experts most relevant\nto downstream tasks while freezing the other experts and modules; experimental\nresults demonstrate that our method not only improves the tuning efficiency,\nbut also matches or even surpasses the performance of full-parameter\nfine-tuning. (3) We further analyze the impact of the MoE architecture on\nexpert-specialized fine-tuning. We find that MoE models with finer-grained\nexperts are more advantageous in selecting the combination of experts that are\nmost relevant to downstream tasks, thereby enhancing both the training\nefficiency and effectiveness. Our code is available at\nhttps://github.com/deepseek-ai/ESFT.",
      "tldr_zh": "这篇论文研究了针对稀疏架构 Large Language Models (LLMs)，如 Mixture-of-Experts (MoE) 模型的 Parameter-efficient fine-tuning (PEFT) 方法。研究发现，特定任务的激活 experts 高度集中，而不同任务间的 experts 分布差异显著。作者提出 Expert-Specialized Fine-Tuning (ESFT) 策略，只微调与下游任务最相关的 experts，同时冻结其他 experts 和模块，从而提高了调优效率。实验结果表明，ESFT 的性能可与全参数微调相当或更优，且 MoE 模型中更细粒度的 experts 能更好地选择相关 experts 组合，提升整体训练效率和效果。",
      "categories": [
        "cs.CL",
        "cs.AI",
        "cs.LG"
      ],
      "primary_category": "cs.CL",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2407.01906v2",
      "published_date": "2024-07-02 03:11:13 UTC",
      "updated_date": "2024-07-05 03:23:59 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-19T03:05:02.432757"
    },
    {
      "arxiv_id": "2407.01903v2",
      "title": "Text-Aware Diffusion for Policy Learning",
      "title_zh": "翻译失败",
      "authors": [
        "Calvin Luo",
        "Mandy He",
        "Zilai Zeng",
        "Chen Sun"
      ],
      "abstract": "Training an agent to achieve particular goals or perform desired behaviors is\noften accomplished through reinforcement learning, especially in the absence of\nexpert demonstrations. However, supporting novel goals or behaviors through\nreinforcement learning requires the ad-hoc design of appropriate reward\nfunctions, which quickly becomes intractable. To address this challenge, we\npropose Text-Aware Diffusion for Policy Learning (TADPoLe), which uses a\npretrained, frozen text-conditioned diffusion model to compute dense zero-shot\nreward signals for text-aligned policy learning. We hypothesize that\nlarge-scale pretrained generative models encode rich priors that can supervise\na policy to behave not only in a text-aligned manner, but also in alignment\nwith a notion of naturalness summarized from internet-scale training data. In\nour experiments, we demonstrate that TADPoLe is able to learn policies for\nnovel goal-achievement and continuous locomotion behaviors specified by natural\nlanguage, in both Humanoid and Dog environments. The behaviors are learned\nzero-shot without ground-truth rewards or expert demonstrations, and are\nqualitatively more natural according to human evaluation. We further show that\nTADPoLe performs competitively when applied to robotic manipulation tasks in\nthe Meta-World environment, without having access to any in-domain\ndemonstrations.",
      "tldr_zh": "该论文提出了一种名为 Text-Aware Diffusion for Policy Learning (TADPoLe) 的方法，使用预训练的冻结文本条件扩散模型来生成密集的零样本奖励信号，从而避免了传统强化学习中针对新目标或行为手动设计奖励函数的复杂性。TADPoLe 假设这些模型编码了丰富的互联网规模先验知识，能指导代理在文本对齐的同时表现出更自然的运动行为。在实验中，该方法在 Humanoid 和 Dog 环境中实现了零样本学习的新目标和连续运动任务，并在 Meta-World 机器人操作环境中表现出色，行为经人类评估更自然且无需专家演示。",
      "categories": [
        "cs.LG",
        "cs.AI",
        "cs.CV"
      ],
      "primary_category": "cs.LG",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2407.01903v2",
      "published_date": "2024-07-02 03:08:20 UTC",
      "updated_date": "2024-10-31 16:49:26 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-19T03:05:01.185009"
    },
    {
      "arxiv_id": "2407.01902v2",
      "title": "SeqAR: Jailbreak LLMs with Sequential Auto-Generated Characters",
      "title_zh": "翻译失败",
      "authors": [
        "Yan Yang",
        "Zeguan Xiao",
        "Xin Lu",
        "Hongru Wang",
        "Xuetao Wei",
        "Hailiang Huang",
        "Guanhua Chen",
        "Yun Chen"
      ],
      "abstract": "The widespread applications of large language models (LLMs) have brought\nabout concerns regarding their potential misuse. Although aligned with human\npreference data before release, LLMs remain vulnerable to various malicious\nattacks. In this paper, we adopt a red-teaming strategy to enhance LLM safety\nand introduce SeqAR, a simple yet effective framework to design jailbreak\nprompts automatically. The SeqAR framework generates and optimizes multiple\njailbreak characters and then applies sequential jailbreak characters in a\nsingle query to bypass the guardrails of the target LLM. Different from\nprevious work which relies on proprietary LLMs or seed jailbreak templates\ncrafted by human expertise, SeqAR can generate and optimize the jailbreak\nprompt in a cold-start scenario using open-sourced LLMs without any seed\njailbreak templates. Experimental results show that SeqAR achieves attack\nsuccess rates of 88% and 60% in bypassing the safety alignment of GPT-3.5-1106\nand GPT-4, respectively. Furthermore, we extensively evaluate the\ntransferability of the generated templates across different LLMs and held-out\nmalicious requests, while also exploring defense strategies against the\njailbreak attack designed by SeqAR.",
      "tldr_zh": "该论文探讨了大型语言模型（LLMs）的安全隐患，尽管它们已通过人类偏好数据对齐，但仍易受恶意攻击。研究引入SeqAR框架，这是一种简单有效的自动生成方法，通过顺序自动生成字符（Sequential Auto-Generated Characters）来创建并优化越狱提示，从而在单个查询中绕过目标LLMs的安全机制。不同于以往依赖专有LLMs或人工模板的方法，SeqAR利用开源LLMs在冷启动场景下独立生成提示，并实现了对GPT-3.5-1106的88%和GPT-4的60%攻击成功率。此外，论文评估了这些模板在不同LLMs和恶意请求间的可转移性，并探讨了相应的防御策略。",
      "categories": [
        "cs.CR",
        "cs.AI",
        "cs.CL"
      ],
      "primary_category": "cs.CR",
      "comment": "Accepted by NAACL 2025",
      "pdf_url": "http://arxiv.org/pdf/2407.01902v2",
      "published_date": "2024-07-02 02:58:29 UTC",
      "updated_date": "2025-03-02 06:28:59 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-19T03:05:14.557636"
    },
    {
      "arxiv_id": "2407.01892v2",
      "title": "GRASP: A Grid-Based Benchmark for Evaluating Commonsense Spatial Reasoning",
      "title_zh": "GRASP：一种基于网格的基准，用于评估常识空间推理",
      "authors": [
        "Zhisheng Tang",
        "Mayank Kejriwal"
      ],
      "abstract": "Spatial reasoning, an important faculty of human cognition with many\npractical applications, is one of the core commonsense skills that is not\npurely language-based and, for satisfying (as opposed to optimal) solutions,\nrequires some minimum degree of planning. Existing benchmarks of Commonsense\nSpatial Reasoning (CSR) tend to evaluate how Large Language Models (LLMs)\ninterpret text-based spatial $\\textit{descriptions}$ rather than directly\nevaluate a plan produced by the LLM in response to a $\\textit{specific}$\nspatial reasoning problem. In this paper, we construct a large-scale benchmark\ncalled GRASP, which consists of 16,000 grid-based environments where the agent\nis tasked with an energy collection problem. These environments include 100\ngrid instances instantiated using each of the 160 different grid settings,\ninvolving five different energy distributions, two modes of agent starting\nposition, and two distinct obstacle configurations, as well as three kinds of\nagent constraints. Using GRASP, we compare classic baseline approaches, such as\nrandom walk and greedy search methods, with advanced LLMs like GPT-3.5-Turbo,\nGPT-4o, and GPT-o1-mini. The experimental results indicate that even these\nadvanced LLMs struggle to consistently achieve satisfactory solutions.",
      "tldr_zh": "这篇论文提出了 GRASP，一个基于网格的大型基准，用于评估 Commonsense Spatial Reasoning（常识空间推理）。GRASP 包含 16,000 个环境实例，涉及能量收集任务，并考虑五种能量分布、两种代理起始位置、两种障碍物配置以及三种代理约束。研究者比较了经典基线方法（如随机游走和贪婪搜索）与先进 LLMs（如 GPT-3.5-Turbo、GPT-4o 和 GPT-o1-mini）。实验结果表明，即使是这些高级 LLMs 也难以 consistently 实现满意的解决方案，从而突显了空间推理能力的挑战。",
      "categories": [
        "cs.AI",
        "cs.CL"
      ],
      "primary_category": "cs.AI",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2407.01892v2",
      "published_date": "2024-07-02 02:27:46 UTC",
      "updated_date": "2025-01-17 04:29:47 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-19T03:05:28.258015"
    },
    {
      "arxiv_id": "2407.01887v3",
      "title": "Beyond Numeric Awards: In-Context Dueling Bandits with LLM Agents",
      "title_zh": "翻译失败",
      "authors": [
        "Fanzeng Xia",
        "Hao Liu",
        "Yisong Yue",
        "Tongxin Li"
      ],
      "abstract": "In-context reinforcement learning (ICRL) is a frontier paradigm for solving\nreinforcement learning problems in the foundation model era. While ICRL\ncapabilities have been demonstrated in transformers through task-specific\ntraining, the potential of Large Language Models (LLMs) out-of-the-box remains\nlargely unexplored. Recent findings highlight that LLMs often face challenges\nwhen dealing with numerical contexts, and limited attention has been paid to\nevaluating their performance through preference feedback generated by the\nenvironment. This paper is the first to investigate LLMs as in-context\ndecision-makers under the problem of Dueling Bandits (DB), a stateless\npreference-based reinforcement learning setting that extends the classic\nMulti-Armed Bandit (MAB) model by querying for preference feedback. We compare\nGPT-3.5 Turbo, GPT-4, GPT-4 Turbo, Llama 3.1, and o1-Preview against nine\nwell-established DB algorithms. Our results reveal that our top-performing LLM,\nGPT-4 Turbo, has the zero-shot relative decision-making ability to achieve\nsurprisingly low weak regret across all the DB environment instances by quickly\nincluding the best arm in duels. However, an optimality gap exists between LLMs\nand classic DB algorithms in terms of strong regret. LLMs struggle to converge\nand consistently exploit even when explicitly prompted to do so, and are\nsensitive to prompt variations. To bridge this gap, we propose an agentic flow\nframework: LLM with Enhanced Algorithmic Dueling (LEAD), which integrates\noff-the-shelf DB algorithms with LLM agents through fine-grained adaptive\ninterplay. We show that LEAD has theoretical guarantees inherited from classic\nDB algorithms on both weak and strong regret. We validate its efficacy and\nrobustness even with noisy and adversarial prompts. The design of our framework\nsheds light on how to enhance the trustworthiness of LLMs used for in-context\ndecision-making.",
      "tldr_zh": "本研究探讨了 Large Language Models (LLMs) 在 In-context Reinforcement Learning (ICRL) 中的潜力，特别是作为决策者在 Dueling Bandits (DB) 问题中的表现，DB 是一种基于偏好反馈的无状态强化学习设置。实验比较了 GPT-3.5 Turbo、GPT-4 等 LLMs 与九种经典 DB 算法，结果显示 GPT-4 Turbo 在零样本条件下表现出色，低 weak regret 但 strong regret 上存在差距，LLMs 易受提示变化影响且难以收敛。作者提出 LEAD (LLM with Enhanced Algorithmic Dueling) 框架，通过将 LLMs 与经典 DB 算法细粒度整合，实现理论上的 regret 保证，并证明其在嘈杂或对抗性提示下的鲁棒性，从而提升 LLMs 在 in-context 决策中的可信度。",
      "categories": [
        "cs.LG",
        "cs.AI",
        "cs.CL"
      ],
      "primary_category": "cs.LG",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2407.01887v3",
      "published_date": "2024-07-02 02:18:14 UTC",
      "updated_date": "2025-01-02 13:49:59 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-19T03:05:40.631922"
    },
    {
      "arxiv_id": "2407.01886v1",
      "title": "Core Knowledge Learning Framework for Graph Adaptation and Scalability Learning",
      "title_zh": "核心知识学习框架：用于图适应与可扩展",
      "authors": [
        "Bowen Zhang",
        "Zhichao Huang",
        "Genan Dai",
        "Guangning Xu",
        "Xiaomao Fan",
        "Hu Huang"
      ],
      "abstract": "Graph classification is a pivotal challenge in machine learning, especially\nwithin the realm of graph-based data, given its importance in numerous\nreal-world applications such as social network analysis, recommendation\nsystems, and bioinformatics. Despite its significance, graph classification\nfaces several hurdles, including adapting to diverse prediction tasks, training\nacross multiple target domains, and handling small-sample prediction scenarios.\nCurrent methods often tackle these challenges individually, leading to\nfragmented solutions that lack a holistic approach to the overarching problem.\nIn this paper, we propose an algorithm aimed at addressing the aforementioned\nchallenges. By incorporating insights from various types of tasks, our method\naims to enhance adaptability, scalability, and generalizability in graph\nclassification. Motivated by the recognition that the underlying subgraph plays\na crucial role in GNN prediction, while the remainder is task-irrelevant, we\nintroduce the Core Knowledge Learning (\\method{}) framework for graph\nadaptation and scalability learning. \\method{} comprises several key modules,\nincluding the core subgraph knowledge submodule, graph domain adaptation\nmodule, and few-shot learning module for downstream tasks. Each module is\ntailored to tackle specific challenges in graph classification, such as domain\nshift, label inconsistencies, and data scarcity. By learning the core subgraph\nof the entire graph, we focus on the most pertinent features for task\nrelevance. Consequently, our method offers benefits such as improved model\nperformance, increased domain adaptability, and enhanced robustness to domain\nvariations. Experimental results demonstrate significant performance\nenhancements achieved by our method compared to state-of-the-art approaches.",
      "tldr_zh": "该论文针对图分类（graph classification）面临的挑战，如适应不同预测任务、跨域训练和小样本场景，提出了一种综合框架Core Knowledge Learning (CKL)。CKL框架包括核心子图知识子模块（core subgraph knowledge submodule）、图域适应模块（graph domain adaptation module）和少样本学习模块（few-shot learning module），通过聚焦任务相关子图来提升模型的适应性、可伸缩性和泛化性。实验结果显示，与现有先进方法相比，CKL在性能、域适应性和鲁棒性方面实现了显著提升。",
      "categories": [
        "cs.LG",
        "cs.AI"
      ],
      "primary_category": "cs.LG",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2407.01886v1",
      "published_date": "2024-07-02 02:16:43 UTC",
      "updated_date": "2024-07-02 02:16:43 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-19T03:05:50.536228"
    },
    {
      "arxiv_id": "2407.01885v1",
      "title": "Survey on Knowledge Distillation for Large Language Models: Methods, Evaluation, and Application",
      "title_zh": "翻译失败",
      "authors": [
        "Chuanpeng Yang",
        "Wang Lu",
        "Yao Zhu",
        "Yidong Wang",
        "Qian Chen",
        "Chenlong Gao",
        "Bingjie Yan",
        "Yiqiang Chen"
      ],
      "abstract": "Large Language Models (LLMs) have showcased exceptional capabilities in\nvarious domains, attracting significant interest from both academia and\nindustry. Despite their impressive performance, the substantial size and\ncomputational demands of LLMs pose considerable challenges for practical\ndeployment, particularly in environments with limited resources. The endeavor\nto compress language models while maintaining their accuracy has become a focal\npoint of research. Among the various methods, knowledge distillation has\nemerged as an effective technique to enhance inference speed without greatly\ncompromising performance. This paper presents a thorough survey from three\naspects: method, evaluation, and application, exploring knowledge distillation\ntechniques tailored specifically for LLMs. Specifically, we divide the methods\ninto white-box KD and black-box KD to better illustrate their differences.\nFurthermore, we also explored the evaluation tasks and distillation effects\nbetween different distillation methods, and proposed directions for future\nresearch. Through in-depth understanding of the latest advancements and\npractical applications, this survey provides valuable resources for\nresearchers, paving the way for sustained progress in this field.",
      "tldr_zh": "这篇论文对知识蒸馏 (knowledge distillation) 在大型语言模型 (LLMs) 中的应用进行了全面调查，旨在解决模型规模大和计算需求高的部署挑战。论文将知识蒸馏方法分为白盒 KD (white-box KD) 和黑盒 KD (black-box KD)，并评估了不同方法的性能表现和实际应用效果。最终，它提出了未来研究方向，为研究人员提供了宝贵资源，促进该领域的持续发展。",
      "categories": [
        "cs.CL",
        "cs.AI"
      ],
      "primary_category": "cs.CL",
      "comment": "28 pages",
      "pdf_url": "http://arxiv.org/pdf/2407.01885v1",
      "published_date": "2024-07-02 02:14:42 UTC",
      "updated_date": "2024-07-02 02:14:42 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-19T03:06:03.259958"
    },
    {
      "arxiv_id": "2407.02540v1",
      "title": "Analytical Solution of a Three-layer Network with a Matrix Exponential Activation Function",
      "title_zh": "翻译失败",
      "authors": [
        "Kuo Gai",
        "Shihua Zhang"
      ],
      "abstract": "In practice, deeper networks tend to be more powerful than shallow ones, but\nthis has not been understood theoretically. In this paper, we find the\nanalytical solution of a three-layer network with a matrix exponential\nactivation function, i.e., $$ f(X)=W_3\\exp(W_2\\exp(W_1X)), X\\in\n\\mathbb{C}^{d\\times d} $$ have analytical solutions for the equations $$\n  Y_1=f(X_1),Y_2=f(X_2) $$ for $X_1,X_2,Y_1,Y_2$ with only invertible\nassumptions. Our proof shows the power of depth and the use of a non-linear\nactivation function, since one layer network can only solve one\nequation,i.e.,$Y=WX$.",
      "tldr_zh": "该论文探讨了深度神经网络的理论优势，特别针对使用矩阵 exponential activation function 的三层网络，找到了其解析解。研究证明，对于函数 f(X) = W_3 exp(W_2 exp(W_1 X))，在矩阵可逆的条件下，可以解析求解多个方程，如 Y_1 = f(X_1) 和 Y_2 = f(X_2)。这一结果突出了深度网络和非线性激活函数的作用，因为单层网络仅能处理简单的线性方程 Y = W X，从而为理解网络深度对性能的影响提供了理论基础。",
      "categories": [
        "stat.ML",
        "cs.AI",
        "cs.LG"
      ],
      "primary_category": "stat.ML",
      "comment": "8 pages,1 figure",
      "pdf_url": "http://arxiv.org/pdf/2407.02540v1",
      "published_date": "2024-07-02 01:59:34 UTC",
      "updated_date": "2024-07-02 01:59:34 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-19T03:06:15.404859"
    },
    {
      "arxiv_id": "2407.01875v1",
      "title": "Spatio-Temporal Graphical Counterfactuals: An Overview",
      "title_zh": "翻译失败",
      "authors": [
        "Mingyu Kang",
        "Duxin Chen",
        "Ziyuan Pu",
        "Jianxi Gao",
        "Wenwu Yu"
      ],
      "abstract": "Counterfactual thinking is a critical yet challenging topic for artificial\nintelligence to learn knowledge from data and ultimately improve their\nperformances for new scenarios. Many research works, including Potential\nOutcome Model and Structural Causal Model, have been proposed to realize it.\nHowever, their modelings, theoretical foundations and application approaches\nare usually different. Moreover, there is a lack of graphical approach to infer\nspatio-temporal counterfactuals, that considers spatial and temporal\ninteractions between multiple units. Thus, in this work, our aim is to\ninvestigate a survey to compare and discuss different counterfactual models,\ntheories and approaches, and further build a unified graphical causal\nframeworks to infer the spatio-temporal counterfactuals.",
      "tldr_zh": "这篇论文概述了反事实思考（Counterfactual thinking）在人工智能中的关键挑战及其重要性，用于从数据中学习并提升新场景下的性能。论文比较了不同模型如Potential Outcome Model和Structural Causal Model在建模、理论基础和应用方法上的差异，并指出了现有方法缺乏处理多单位空间和时间交互的图形化途径。主要贡献是构建一个统一的图形因果框架，用于推断时空反事实（Spatio-Temporal Graphical Counterfactuals），从而更好地支持复杂交互场景下的因果推理。",
      "categories": [
        "cs.AI"
      ],
      "primary_category": "cs.AI",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2407.01875v1",
      "published_date": "2024-07-02 01:34:13 UTC",
      "updated_date": "2024-07-02 01:34:13 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-19T03:06:28.640925"
    },
    {
      "arxiv_id": "2407.01873v1",
      "title": "Automated Text Scoring in the Age of Generative AI for the GPU-poor",
      "title_zh": "在生成式人工智能时代面向 GPU 资源不足者的自动文本评分",
      "authors": [
        "Christopher Michael Ormerod",
        "Alexander Kwako"
      ],
      "abstract": "Current research on generative language models (GLMs) for automated text\nscoring (ATS) has focused almost exclusively on querying proprietary models via\nApplication Programming Interfaces (APIs). Yet such practices raise issues\naround transparency and security, and these methods offer little in the way of\nefficiency or customizability. With the recent proliferation of smaller,\nopen-source models, there is the option to explore GLMs with computers equipped\nwith modest, consumer-grade hardware, that is, for the \"GPU poor.\" In this\nstudy, we analyze the performance and efficiency of open-source, small-scale\nGLMs for ATS. Results show that GLMs can be fine-tuned to achieve adequate,\nthough not state-of-the-art, performance. In addition to ATS, we take small\nsteps towards analyzing models' capacity for generating feedback by prompting\nGLMs to explain their scores. Model-generated feedback shows promise, but\nrequires more rigorous evaluation focused on targeted use cases.",
      "tldr_zh": "本研究探讨了在资源有限的普通硬件（GPU-poor）环境下，使用开源小型生成语言模型（GLMs）进行自动文本评分（ATS）。作者指出，现有的ATS方法主要依赖专有模型的API，这导致了透明度、安全性和效率问题，因此转向开源模型进行分析和微调。结果显示，这些GLMs经微调后可实现足够的性能，但尚未达到最先进水平；此外，通过提示模型解释分数，生成的反馈显示出潜力，但需针对特定用例进行更严格的评估。",
      "categories": [
        "cs.LG",
        "cs.AI",
        "cs.CL"
      ],
      "primary_category": "cs.LG",
      "comment": "21 pages, 1 figure",
      "pdf_url": "http://arxiv.org/pdf/2407.01873v1",
      "published_date": "2024-07-02 01:17:01 UTC",
      "updated_date": "2024-07-02 01:17:01 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-19T03:06:39.441811"
    },
    {
      "arxiv_id": "2407.02539v3",
      "title": "Research on Autonomous Robots Navigation based on Reinforcement Learning",
      "title_zh": "基于强化学习的自治机器人导航研究",
      "authors": [
        "Zixiang Wang",
        "Hao Yan",
        "Yining Wang",
        "Zhengjia Xu",
        "Zhuoyue Wang",
        "Zhizhong Wu"
      ],
      "abstract": "Reinforcement learning continuously optimizes decision-making based on\nreal-time feedback reward signals through continuous interaction with the\nenvironment, demonstrating strong adaptive and self-learning capabilities. In\nrecent years, it has become one of the key methods to achieve autonomous\nnavigation of robots. In this work, an autonomous robot navigation method based\non reinforcement learning is introduced. We use the Deep Q Network (DQN) and\nProximal Policy Optimization (PPO) models to optimize the path planning and\ndecision-making process through the continuous interaction between the robot\nand the environment, and the reward signals with real-time feedback. By\ncombining the Q-value function with the deep neural network, deep Q network can\nhandle high-dimensional state space, so as to realize path planning in complex\nenvironments. Proximal policy optimization is a strategy gradient-based method,\nwhich enables robots to explore and utilize environmental information more\nefficiently by optimizing policy functions. These methods not only improve the\nrobot's navigation ability in the unknown environment, but also enhance its\nadaptive and self-learning capabilities. Through multiple training and\nsimulation experiments, we have verified the effectiveness and robustness of\nthese models in various complex scenarios.",
      "tldr_zh": "该论文研究了基于 Reinforcement Learning 的自主机器人导航方法，通过机器人与环境的持续互动和实时奖励信号来优化路径规划和决策。作者采用了 Deep Q Network (DQN) 和 Proximal Policy Optimization (PPO) 模型，其中 DQN 结合 Q-value 函数和深度神经网络处理高维状态空间，实现复杂环境的路径规划；PPO 作为策略梯度方法，提升了机器人在环境信息探索和利用方面的效率。实验通过多次训练和模拟验证了这些模型在未知和复杂场景中的有效性与鲁棒性，显著提高了机器人的适应性和自学习能力。",
      "categories": [
        "cs.RO",
        "cs.AI",
        "cs.LG",
        "stat.ML"
      ],
      "primary_category": "cs.RO",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2407.02539v3",
      "published_date": "2024-07-02 00:44:06 UTC",
      "updated_date": "2024-08-14 04:49:22 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-19T03:06:53.215010"
    },
    {
      "arxiv_id": "2407.01864v2",
      "title": "Research on target detection method of distracted driving behavior based on improved YOLOv8",
      "title_zh": "基于改进 YOLOv8 的分心驾驶行为目标检测方法研究",
      "authors": [
        "Shiquan Shen",
        "Zhizhong Wu",
        "Pan Zhang"
      ],
      "abstract": "With the development of deep learning technology, the detection and\nclassification of distracted driving behaviour requires higher accuracy.\nExisting deep learning-based methods are computationally intensive and\nparameter redundant, limiting the efficiency and accuracy in practical\napplications. To solve this problem, this study proposes an improved YOLOv8\ndetection method based on the original YOLOv8 model by integrating the BoTNet\nmodule, GAM attention mechanism and EIoU loss function. By optimising the\nfeature extraction and multi-scale feature fusion strategies, the training and\ninference processes are simplified, and the detection accuracy and efficiency\nare significantly improved. Experimental results show that the improved model\nperforms well in both detection speed and accuracy, with an accuracy rate of\n99.4%, and the model is smaller and easy to deploy, which is able to identify\nand classify distracted driving behaviours in real time, provide timely\nwarnings, and enhance driving safety.",
      "tldr_zh": "本研究针对分心驾驶行为检测的准确性需求，提出了一种基于改进 YOLOv8 的目标检测方法，以解决现有深度学习模型计算密集和参数冗余的问题。改进方案整合了 BoTNet 模块、GAM 注意力机制和 EIoU 损失函数，并优化了特征提取和多尺度特征融合策略，从而简化训练和推理过程。实验结果显示，该模型的准确率达到99.4%，在检测速度和效率上显著提升，且模型体积更小、易于部署，能够实时识别分心驾驶行为并提供及时警告，提升驾驶安全。",
      "categories": [
        "cs.CV",
        "cs.AI",
        "cs.LG"
      ],
      "primary_category": "cs.CV",
      "comment": "Major revision on content, no replacement available soon",
      "pdf_url": "http://arxiv.org/pdf/2407.01864v2",
      "published_date": "2024-07-02 00:43:41 UTC",
      "updated_date": "2024-07-05 17:17:48 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-19T03:07:02.740114"
    }
  ],
  "raw_papers_fetched": true,
  "papers_count": 126,
  "processed_papers_count": 126,
  "failed_papers_count": 0,
  "summary_generated": true,
  "daily_data_saved": true,
  "last_update": "2025-05-19T03:07:29.124168"
}