{
  "date": "2024-06-24",
  "category": "cs.AI",
  "summary": "欢迎来到 UTC 时间 2024-06-24 的 arXiv 中文 TLDR 快报！\n\n今天 arXiv 的论文主要聚焦于 AI 模型优化、LLM 的推理与应用、强化学习、多模态处理等领域，亮点包括 LLM 的逻辑推理基准（如 Multi-LogiEval）和高效训练框架（如 GraphPipe），以及一些知名学者（如 Zhu Han 在量子强化学习领域）的贡献，这些工作突显了 AI 在实际应用中的潜力。\n\n下面，我将挑选并讨论部分重要或有话题度的论文，先从 LLM 和强化学习等高影响力主题入手，再快速掠过其他相关或次要论文。每个条目包括论文标题（中文 + 英文）和核心贡献与发现的简要描述。\n\n### 重点论文讨论\n\n**Multi-LogiEval: Towards Evaluating Multi-Step Logical Reasoning Ability of Large Language Models**  \n这篇论文由 Nisarg Patel 等作者提出，Accepted at EMNLP 2024，主要贡献是通过一个全面数据集评估 LLM（如 GPT-4 和 Gemini-Pro）在命题逻辑、一阶逻辑和非单调逻辑中的多步推理能力，发现模型在推理深度增加时准确率显著下降（如从 68% 到 43%），强调了提升 LLM 逻辑推理的必要性。\n\n**Reinforcement Learning via Auxiliary Task Distillation**  \n作者包括 Larry Heck 和 Zsolt Kira，该工作提出 AuxDistill 框架，用于强化学习中的长时机器人控制任务，通过蒸馏辅助任务行为，实现无演示学习的物体重排，实验在 Habitat 基准上比基线提升 2.3 倍成功率，展示了高效任务转移的潜力。\n\n**Paraphrase and Aggregate with Large Language Models**  \nAccepted at SIGIR 2024，这篇论文引入 PAG-LLM 方法，利用 LLM 生成查询的多个改写版本并聚合分类结果，显著减少多类分类错误（如 CLINC 和 Banking 数据集上减少 15-23% 错误），并有效处理 LLM 的不确定性和幻觉问题。\n\n**GraphPipe: Improving Performance and Scalability of DNN Training with Graph Pipeline Parallelism**  \n作者团队包括 Mohammad Alizadeh 和 Tianqi Chen，提出 GPP 方案优化 DNN 训练，通过图拓扑分区减少内存需求和提升 GPU 性能，实验显示比 PipeDream 和 Piper 高达 1.6 倍效率，适用于大规模模型训练。\n\n**BitNet b1.58 Reloaded: State-of-the-art Performance Also on Smaller Networks**  \n这篇工作探索 1.58-bit 量化训练，引入一种基于中值的量化变体，在小规模语言和视觉模型上实现 SOTA 性能（如在小模型上超越原有基准），并分析量化对学习率的鲁棒性，强调了低资源部署的潜力。\n\n**Evaluating the Quality of Hallucination Benchmarks for Large Vision-Language Models**  \n论文提出 HQM 框架评估 LVLMs 的幻觉基准质量，包括可靠性和有效性指标，并构建高质基准 HQH，实验显示 GPT-4o 在幻觉检测上表现优异，这有助于改进多模态模型的鲁棒性。\n\n**Large Language Models Assume People are More Rational than We Really are**  \n作者包括 Thomas L. Griffiths，该研究发现 LLM（如 GPT-4o）在模拟人类决策时假设过度理性，导致与真实行为偏差，实验通过心理数据集验证，揭示了 LLM 在人类行为建模中的局限性。\n\n**StableNormal: Reducing Diffusion Variance for Stable and Sharp Normal**  \n这篇论文针对单目图像的法线估计，提出 StableNormal 方法，通过粗到细策略减少扩散方差，实现鲁棒的法线预测，实验在多种基准上提升精度，适用于表面重建等下游任务。\n\n**GeoMFormer: A General Architecture for Geometric Molecular Representation Learning**  \n作者包括 Liwei Wang，该工作设计 GeoMFormer 框架，支持分子建模中的旋转不变性和等变性，实验证明其在分子属性预测上超越现有方法，提供了一个通用的几何表示学习方案。\n\n**Learning Temporal Distances: Contrastive Successor Features Can Provide a Metric Structure for Decision-Making**  \n这篇论文使用对比学习构建时间距离度量，证明其在随机环境中满足三角不等式，提升强化学习的路径规划，实验验证了其泛化性和效率。\n\n### 其他相关论文快速掠过\n以下论文主题较为具体或次要，我将简要概述其核心贡献：\n- **DriftLens: Unsupervised Concept Drift Detection from Deep Learning Representations in Real-time**：提出无监督框架 DriftLens 检测数据分布漂移，适用于文本/图像/语音，提高检测准确性和速度。\n- **Virtual Mines: Component-level recycling of printed circuit boards using deep learning**：使用 YOLOv5 模型优化电子废物回收，焦点在组件级分析，提高精度和召回率。\n- **Peirce in the Machine: How Mixture of Experts Models Perform Hypothesis Construction**：分析混合专家模型的假设构建能力，证明其比贝叶斯方法更具功能性。\n- **Quantifying Heterogeneous Ecosystem Services With Multi-Label Soft Classification**：使用软多标签分类量化生态服务，焦点在遥感数据分析。\n- **PIC2O-Sim: Physics-Inspired Causality-Aware Dynamic Convolutional Neural Operator**：针对光子设备模拟的快速 AI 框架，提升仿真精度和效率。\n- **At First Sight: Zero-Shot Classification of Astronomical Images with Large Multimodal Models**：使用 GPT-4o 等模型实现天文图像零样本分类，准确率达 80%。\n- **BEEAR: Embedding-based Adversarial Removal of Safety Backdoors in Instruction-tuned Language Models**：提出 BEEAR 方法移除 LLM 中的安全后门，显著降低攻击成功率。\n- **Exploring Biomarker Relationships in Both Type 1 and Type 2 Diabetes Mellitus Through a Bayesian Network Analysis Approach**：使用贝叶斯网络分析糖尿病生物标记物关系，提高预测准确性。\n- **Meta-GCN: A Dynamically Weighted Loss Minimization Method for Dealing with the Data Imbalance in Graph Neural Networks**：引入 Meta-GCN 算法处理图神经网络中的数据不平衡，提升分类性能。\n- **Tolerance of Reinforcement Learning Controllers against Deviations in Cyber Physical Systems**：评估 RL 控制器对系统偏差的容忍度，提出容忍度伪造问题。\n- 其余论文如数据集构建（e.g., USDC）、特定优化（e.g., Adam-mini）或基准测试（e.g., OlympicArena）等，由于篇幅有限，仅提及其在特定领域的贡献，如提升 LLM 鲁棒性和效率，但不展开讨论。\n\n总之，今天的论文展示了 AI 领域的多样创新，特别是 LLM 和强化学习的进展，但也暴露了模型在推理和泛化上的挑战。更多细节可查阅 arXiv！",
  "papers": [
    {
      "arxiv_id": "2406.17813v1",
      "title": "Unsupervised Concept Drift Detection from Deep Learning Representations in Real-time",
      "title_zh": "翻译失败",
      "authors": [
        "Salvatore Greco",
        "Bartolomeo Vacchetti",
        "Daniele Apiletti",
        "Tania Cerquitelli"
      ],
      "abstract": "Concept Drift is a phenomenon in which the underlying data distribution and\nstatistical properties of a target domain change over time, leading to a\ndegradation of the model's performance. Consequently, models deployed in\nproduction require continuous monitoring through drift detection techniques.\nMost drift detection methods to date are supervised, i.e., based on\nground-truth labels. However, true labels are usually not available in many\nreal-world scenarios. Although recent efforts have been made to develop\nunsupervised methods, they often lack the required accuracy, have a complexity\nthat makes real-time implementation in production environments difficult, or\nare unable to effectively characterize drift. To address these challenges, we\npropose DriftLens, an unsupervised real-time concept drift detection framework.\nIt works on unstructured data by exploiting the distribution distances of deep\nlearning representations. DriftLens can also provide drift characterization by\nanalyzing each label separately. A comprehensive experimental evaluation is\npresented with multiple deep learning classifiers for text, image, and speech.\nResults show that (i) DriftLens performs better than previous methods in\ndetecting drift in $11/13$ use cases; (ii) it runs at least 5 times faster;\n(iii) its detected drift value is very coherent with the amount of drift\n(correlation $\\geq 0.85$); (iv) it is robust to parameter changes.",
      "tldr_zh": "本文提出DriftLens，一种无监督实时概念漂移(Concept Drift)检测框架，通过利用深度学习 representations 的分布距离来识别数据分布变化，从而避免了依赖ground-truth labels的局限。DriftLens不仅能检测漂移，还支持对每个标签的单独分析，以提供更精确的漂移特征化。在多模态实验中（文本、图像和语音），该框架在11/13个用例中优于现有方法，运行速度至少快5倍，检测值与实际漂移量高度相关（correlation ≥0.85），并表现出对参数变化的鲁棒性。",
      "categories": [
        "cs.LG",
        "cs.AI"
      ],
      "primary_category": "cs.LG",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2406.17813v1",
      "published_date": "2024-06-24 23:41:46 UTC",
      "updated_date": "2024-06-24 23:41:46 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-18T23:53:11.676707"
    },
    {
      "arxiv_id": "2406.17169v3",
      "title": "Multi-LogiEval: Towards Evaluating Multi-Step Logical Reasoning Ability of Large Language Models",
      "title_zh": "翻译失败",
      "authors": [
        "Nisarg Patel",
        "Mohith Kulkarni",
        "Mihir Parmar",
        "Aashna Budhiraja",
        "Mutsumi Nakamura",
        "Neeraj Varshney",
        "Chitta Baral"
      ],
      "abstract": "As Large Language Models (LLMs) continue to exhibit remarkable performance in\nnatural language understanding tasks, there is a crucial need to measure their\nability for human-like multi-step logical reasoning. Existing logical reasoning\nevaluation benchmarks often focus primarily on simplistic single-step or\nmulti-step reasoning with a limited set of inference rules. Furthermore, the\nlack of datasets for evaluating non-monotonic reasoning represents a crucial\ngap since it aligns more closely with human-like reasoning. To address these\nlimitations, we propose Multi-LogiEval, a comprehensive evaluation dataset\nencompassing multi-step logical reasoning with various inference rules and\ndepths. Multi-LogiEval covers three logic types--propositional, first-order,\nand non-monotonic--consisting of more than 30 inference rules and more than 60\nof their combinations with various depths. Leveraging this dataset, we conduct\nevaluations on a range of LLMs including GPT-4, ChatGPT, Gemini-Pro, Yi, Orca,\nand Mistral, employing a zero-shot chain-of-thought. Experimental results show\nthat there is a significant drop in the performance of LLMs as the reasoning\nsteps/depth increases (average accuracy of ~68% at depth-1 to ~43% at depth-5).\nWe further conduct a thorough investigation of reasoning chains generated by\nLLMs which reveals several important findings. We believe that Multi-LogiEval\nfacilitates future research for evaluating and enhancing the logical reasoning\nability of LLMs. Data is available at\nhttps://github.com/Mihir3009/Multi-LogiEval.",
      "tldr_zh": "该研究针对Large Language Models (LLMs)的多步逻辑推理能力评估问题，提出了Multi-LogiEval数据集，以弥补现有基准对单一推理规则和非单调推理（non-monotonic reasoning）的不足。数据集涵盖propositional、first-order和non-monotonic三种逻辑类型，包含超过30个推理规则和60个组合，支持各种推理深度。使用zero-shot chain-of-thought方法评估多种LLMs（如GPT-4和ChatGPT），实验结果显示模型性能随推理步骤增加而下降（深度1的平均准确率约68%至深度5约43%），并揭示了推理链中的关键问题。该数据集将促进未来LLMs逻辑推理能力的提升和研究。",
      "categories": [
        "cs.CL",
        "cs.AI"
      ],
      "primary_category": "cs.CL",
      "comment": "Accepted at EMNLP 2024 Main",
      "pdf_url": "http://arxiv.org/pdf/2406.17169v3",
      "published_date": "2024-06-24 23:02:56 UTC",
      "updated_date": "2024-10-07 03:48:18 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-18T23:53:24.586567"
    },
    {
      "arxiv_id": "2406.17168v1",
      "title": "Reinforcement Learning via Auxiliary Task Distillation",
      "title_zh": "翻译失败",
      "authors": [
        "Abhinav Narayan Harish",
        "Larry Heck",
        "Josiah P. Hanna",
        "Zsolt Kira",
        "Andrew Szot"
      ],
      "abstract": "We present Reinforcement Learning via Auxiliary Task Distillation\n(AuxDistill), a new method that enables reinforcement learning (RL) to perform\nlong-horizon robot control problems by distilling behaviors from auxiliary RL\ntasks. AuxDistill achieves this by concurrently carrying out multi-task RL with\nauxiliary tasks, which are easier to learn and relevant to the main task. A\nweighted distillation loss transfers behaviors from these auxiliary tasks to\nsolve the main task. We demonstrate that AuxDistill can learn a\npixels-to-actions policy for a challenging multi-stage embodied object\nrearrangement task from the environment reward without demonstrations, a\nlearning curriculum, or pre-trained skills. AuxDistill achieves $2.3 \\times$\nhigher success than the previous state-of-the-art baseline in the Habitat\nObject Rearrangement benchmark and outperforms methods that use pre-trained\nskills and expert demonstrations.",
      "tldr_zh": "我们提出了 Reinforcement Learning via Auxiliary Task Distillation (AuxDistill)，一种新方法，用于通过辅助任务蒸馏行为来提升强化学习（RL）在长时域机器人控制问题中的性能。该方法通过同时进行多任务 RL，选取与主任务相关的更容易学习的辅助任务，并应用加权蒸馏损失，将这些辅助任务的行为转移到主任务上，从而实现从环境奖励中学习 pixels-to-actions 策略，而无需演示、学习课程或预训练技能。实验结果显示，AuxDistill 在 Habitat Object Rearrangement 基准上比之前的最先进基线成功率提高了 2.3 倍，并优于依赖预训练技能和专家演示的方法。",
      "categories": [
        "cs.LG",
        "cs.AI",
        "cs.RO"
      ],
      "primary_category": "cs.LG",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2406.17168v1",
      "published_date": "2024-06-24 23:02:18 UTC",
      "updated_date": "2024-06-24 23:02:18 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-18T23:53:36.422771"
    },
    {
      "arxiv_id": "2406.17163v1",
      "title": "Paraphrase and Aggregate with Large Language Models for Minimizing Intent Classification Errors",
      "title_zh": "翻译失败",
      "authors": [
        "Vikas Yadav",
        "Zheng Tang",
        "Vijay Srinivasan"
      ],
      "abstract": "Large language models (LLM) have achieved remarkable success in natural\nlanguage generation but lesser focus has been given to their applicability in\ndecision making tasks such as classification. We show that LLMs like LLaMa can\nachieve high performance on large multi-class classification tasks but still\nmake classification errors and worse, generate out-of-vocabulary class labels.\nTo address these critical issues, we introduce Paraphrase and AGgregate\n(PAG)-LLM approach wherein an LLM generates multiple paraphrases of the input\nquery (parallel queries), performs multi-class classification for the original\nquery and each paraphrase, and at the end aggregate all the classification\nlabels based on their confidence scores. We evaluate PAG-LLM on two large\nmulti-class classication datasets: CLINC, and Banking and show 22.7% and 15.1%\nerror reduction. We show that PAG-LLM is especially effective for hard examples\nwhere LLM is uncertain, and reduces the critical misclassification and\nhallucinated label generation errors",
      "tldr_zh": "该论文探讨了大型语言模型（LLM）在多类意图分类任务中的表现问题，尽管如LLaMa模型能实现高性能，但仍存在分类错误和生成词汇外标签的风险。为解决这些问题，研究提出Paraphrase and Aggregate (PAG)-LLM方法，该方法通过生成输入查询的多个改写（paraphrases）、对每个改写进行多类分类，并基于置信度分数（confidence scores）聚合结果，从而最小化错误。在CLINC和Banking数据集上的实验显示，PAG-LLM分别减少了22.7%和15.1%的错误，尤其在LLM不确定性的困难例子中，显著降低了关键误分类和幻觉标签生成错误。",
      "categories": [
        "cs.CL",
        "cs.AI",
        "cs.LG"
      ],
      "primary_category": "cs.CL",
      "comment": "Accepted at SIGIR 2024",
      "pdf_url": "http://arxiv.org/pdf/2406.17163v1",
      "published_date": "2024-06-24 22:30:26 UTC",
      "updated_date": "2024-06-24 22:30:26 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-18T23:53:47.515104"
    },
    {
      "arxiv_id": "2406.17162v1",
      "title": "Virtual Mines -- Component-level recycling of printed circuit boards using deep learning",
      "title_zh": "翻译失败",
      "authors": [
        "Muhammad Mohsin",
        "Stefano Rovetta",
        "Francesco Masulli",
        "Alberto Cabri"
      ],
      "abstract": "This contribution gives an overview of an ongoing project using machine\nlearning and computer vision components for improving the electronic waste\nrecycling process. In circular economy, the \"virtual mines\" concept refers to\nproduction cycles where interesting raw materials are reclaimed in an efficient\nand cost-effective manner from end-of-life items. In particular, the growth of\ne-waste, due to the increasingly shorter life cycle of hi-tech goods, is a\nglobal problem. In this paper, we describe a pipeline based on deep learning\nmodel to recycle printed circuit boards at the component level. A pre-trained\nYOLOv5 model is used to analyze the results of the locally developed dataset.\nWith a different distribution of class instances, YOLOv5 managed to achieve\nsatisfactory precision and recall, with the ability to optimize with large\ncomponent instances.",
      "tldr_zh": "本研究概述了一个利用深度学习（deep learning）和计算机视觉改善电子废弃物回收的项目，聚焦于“虚拟矿山”（virtual mines）概念，通过高效回收报废高科技产品的原材料来应对全球 e-waste 增长问题。具体而言，该项目提出了一种基于深度学习的管道，使用预训练的 YOLOv5 模型分析本地数据集，实现印刷电路板（printed circuit boards）的组件级回收。实验结果显示，YOLOv5 在不同类实例分布下取得了满意的精确度和召回率，并能针对大型组件实例进行优化，为循环经济中的可持续回收提供了可行方案。",
      "categories": [
        "cs.CV",
        "cs.AI",
        "cs.LG"
      ],
      "primary_category": "cs.CV",
      "comment": "10 pages, 5 figures",
      "pdf_url": "http://arxiv.org/pdf/2406.17162v1",
      "published_date": "2024-06-24 22:29:30 UTC",
      "updated_date": "2024-06-24 22:29:30 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-18T23:53:58.937927"
    },
    {
      "arxiv_id": "2406.17150v1",
      "title": "Peirce in the Machine: How Mixture of Experts Models Perform Hypothesis Construction",
      "title_zh": "翻译失败",
      "authors": [
        "Bruce Rushing"
      ],
      "abstract": "Mixture of experts is a prediction aggregation method in machine learning\nthat aggregates the predictions of specialized experts. This method often\noutperforms Bayesian methods despite the Bayesian having stronger inductive\nguarantees. We argue that this is due to the greater functional capacity of\nmixture of experts. We prove that in a limiting case of mixture of experts will\nhave greater capacity than equivalent Bayesian methods, which we vouchsafe\nthrough experiments on non-limiting cases. Finally, we conclude that mixture of\nexperts is a type of abductive reasoning in the Peircian sense of hypothesis\nconstruction.",
      "tldr_zh": "这篇论文探讨了Mixture of Experts (MoE) 模型在机器学习中的预测聚合方法，以及它为何往往优于Bayesian methods，尽管后者具有更强的归纳保证。作者通过理论证明和实验验证，证明了MoE 在功能容量上更强，尤其在极限情况下比等价Bayesian方法更具优势。最终，论文得出结论，将MoE 视为Peircian意义上的abductive reasoning，即一种假设构建的过程。",
      "categories": [
        "cs.LG",
        "cs.AI"
      ],
      "primary_category": "cs.LG",
      "comment": "31 pages",
      "pdf_url": "http://arxiv.org/pdf/2406.17150v1",
      "published_date": "2024-06-24 21:44:37 UTC",
      "updated_date": "2024-06-24 21:44:37 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-18T23:54:10.849507"
    },
    {
      "arxiv_id": "2406.17147v1",
      "title": "Quantifying Heterogeneous Ecosystem Services With Multi-Label Soft Classification",
      "title_zh": "翻译失败",
      "authors": [
        "Zhihui Tian",
        "John Upchurch",
        "G. Austin Simon",
        "José Dubeux",
        "Alina Zare",
        "Chang Zhao",
        "Joel B. Harley"
      ],
      "abstract": "Understanding and quantifying ecosystem services are crucial for sustainable\nenvironmental management, conservation efforts, and policy-making. The\nadvancement of remote sensing technology and machine learning techniques has\ngreatly facilitated this process. Yet, ground truth labels, such as\nbiodiversity, are very difficult and expensive to measure. In addition, more\neasily obtainable proxy labels, such as land use, often fail to capture the\ncomplex heterogeneity of the ecosystem. In this paper, we demonstrate how land\nuse proxy labels can be implemented with a soft, multi-label classifier to\npredict ecosystem services with complex heterogeneity.",
      "tldr_zh": "生态系统服务的量化对于可持续环境管理和政策制定至关重要，但地面真实标签（如biodiversity）难以获取，且土地利用等代理标签往往无法捕捉生态系统的复杂异质性。  \n本文提出使用多标签软分类器（multi-label soft classification）结合土地利用代理标签的方法，来预测具有异质性的生态系统服务。  \n这项方法利用遥感技术和机器学习技术，展示了如何更有效地处理代理标签，从而提升生态服务评估的准确性和实用性。",
      "categories": [
        "cs.LG",
        "cs.AI",
        "q-bio.QM"
      ],
      "primary_category": "cs.LG",
      "comment": "This work has been submitted to the IEEE for possible publication",
      "pdf_url": "http://arxiv.org/pdf/2406.17147v1",
      "published_date": "2024-06-24 21:38:13 UTC",
      "updated_date": "2024-06-24 21:38:13 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-18T23:54:23.454518"
    },
    {
      "arxiv_id": "2406.17145v2",
      "title": "GraphPipe: Improving Performance and Scalability of DNN Training with Graph Pipeline Parallelism",
      "title_zh": "翻译失败",
      "authors": [
        "Byungsoo Jeon",
        "Mengdi Wu",
        "Shiyi Cao",
        "Sunghyun Kim",
        "Sunghyun Park",
        "Neeraj Aggarwal",
        "Colin Unger",
        "Daiyaan Arfeen",
        "Peiyuan Liao",
        "Xupeng Miao",
        "Mohammad Alizadeh",
        "Gregory R. Ganger",
        "Tianqi Chen",
        "Zhihao Jia"
      ],
      "abstract": "Deep neural networks (DNNs) continue to grow rapidly in size, making them\ninfeasible to train on a single device. Pipeline parallelism is commonly used\nin existing DNN systems to support large-scale DNN training by partitioning a\nDNN into multiple stages, which concurrently perform DNN training for different\nmicro-batches in a pipeline fashion. However, existing pipeline-parallel\napproaches only consider sequential pipeline stages and thus ignore the\ntopology of a DNN, resulting in missed model-parallel opportunities. This paper\npresents graph pipeline parallelism (GPP), a new pipeline-parallel scheme that\npartitions a DNN into pipeline stages whose dependencies are identified by a\ndirected acyclic graph. GPP generalizes existing sequential pipeline\nparallelism and preserves the inherent topology of a DNN to enable concurrent\nexecution of computationally-independent operators, resulting in reduced memory\nrequirement and improved GPU performance. In addition, we develop GraphPipe, a\ndistributed system that exploits GPP strategies to enable performant and\nscalable DNN training. GraphPipe partitions a DNN into a graph of stages,\noptimizes micro-batch schedules for these stages, and parallelizes DNN training\nusing the discovered GPP strategies. Evaluation on a variety of DNNs shows that\nGraphPipe outperforms existing pipeline-parallel systems such as PipeDream and\nPiper by up to 1.6X. GraphPipe also reduces the search time by 9-21X compared\nto PipeDream and Piper.",
      "tldr_zh": "该论文提出 Graph Pipeline Parallelism (GPP)，一种新颖的管道并行方案，通过利用 DNN 的有向无环图拓扑，将模型分区为依赖性阶段，实现计算独立运算符的并发执行，从而降低内存需求并提升 GPU 性能。GraphPipe 系统基于 GPP 策略，优化 DNN 训练的微批处理调度，并支持分布式并行训练。实验结果显示，GraphPipe 相较于 PipeDream 和 Piper 等现有系统，性能提升高达 1.6 倍，并将搜索时间减少 9-21 倍。",
      "categories": [
        "cs.DC",
        "cs.AI",
        "cs.LG"
      ],
      "primary_category": "cs.DC",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2406.17145v2",
      "published_date": "2024-06-24 21:32:51 UTC",
      "updated_date": "2024-10-28 13:44:30 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-18T23:54:36.610864"
    },
    {
      "arxiv_id": "2407.09527v1",
      "title": "BitNet b1.58 Reloaded: State-of-the-art Performance Also on Smaller Networks",
      "title_zh": "翻译失败",
      "authors": [
        "Jacob Nielsen",
        "Peter Schneider-Kamp"
      ],
      "abstract": "Recently proposed methods for 1-bit and 1.58-bit quantization aware training\ninvestigate the performance and behavior of these methods in the context of\nlarge language models, finding state-of-the-art performance for models with\nmore than 3B parameters. In this work, we investigate 1.58-bit quantization for\nsmall language and vision models ranging from 100K to 48M parameters. We\nintroduce a variant of BitNet b1.58, which allows to rely on the median rather\nthan the mean in the quantization process.\n  Through extensive experiments we investigate the performance of 1.58-bit\nmodels obtained through quantization aware training. We further investigate the\nrobustness of 1.58-bit quantization-aware training to changes in the learning\nrate and regularization through weight decay, finding different patterns for\nsmall language and vision models than previously reported for large language\nmodels.\n  Our results showcase that 1.58-bit quantization-aware training provides\nstate-of-the-art performance for small language models when doubling hidden\nlayer sizes and reaches or even surpasses state-of-the-art performance for\nsmall vision models of identical size. Ultimately, we demonstrate that 1.58-bit\nquantization-aware training is a viable and promising approach also for\ntraining smaller deep learning networks, facilitating deployment of such models\nin low-resource use-cases and encouraging future research.",
      "tldr_zh": "本研究扩展了1.58-bit量化感知训练（quantization aware training）到小型语言和视觉模型（参数范围10万至4800万），引入BitNet b1.58的变体，使用中位数（median）而非均值（mean）进行量化处理。实验结果显示，这种方法在加倍小型语言模型隐藏层大小时，能实现最先进性能，并在相同大小的小型视觉模型上达到或超越基准水平。作者还发现，该量化方法对学习率和权重衰减的鲁棒性在小型模型上与大型语言模型不同，最终证明其适用于低资源场景的模型部署，并推动相关研究。",
      "categories": [
        "cs.CV",
        "cs.AI",
        "cs.CL",
        "cs.LG"
      ],
      "primary_category": "cs.CV",
      "comment": "17 pages, 4 Tables, 14 grafs. Accepted to DeLTA",
      "pdf_url": "http://arxiv.org/pdf/2407.09527v1",
      "published_date": "2024-06-24 20:55:36 UTC",
      "updated_date": "2024-06-24 20:55:36 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-18T23:54:47.985699"
    },
    {
      "arxiv_id": "2406.17812v1",
      "title": "Scalable Artificial Intelligence for Science: Perspectives, Methods and Exemplars",
      "title_zh": "翻译失败",
      "authors": [
        "Wesley Brewer",
        "Aditya Kashi",
        "Sajal Dash",
        "Aristeidis Tsaris",
        "Junqi Yin",
        "Mallikarjun Shankar",
        "Feiyi Wang"
      ],
      "abstract": "In a post-ChatGPT world, this paper explores the potential of leveraging\nscalable artificial intelligence for scientific discovery. We propose that\nscaling up artificial intelligence on high-performance computing platforms is\nessential to address such complex problems. This perspective focuses on\nscientific use cases like cognitive simulations, large language models for\nscientific inquiry, medical image analysis, and physics-informed approaches.\nThe study outlines the methodologies needed to address such challenges at scale\non supercomputers or the cloud and provides exemplars of such approaches\napplied to solve a variety of scientific problems.",
      "tldr_zh": "本文在后ChatGPT时代，探讨了利用可扩展人工智能（scalable artificial intelligence）提升科学发现潜力的重要性，强调通过高性能计算平台扩展AI以应对复杂科学问题。论文聚焦于具体应用场景，如认知模拟、大语言模型（large language models）用于科学探究、医疗图像分析和physics-informed approaches，并概述了在超级计算机或云端处理这些挑战的方法。最终，提供实际示例，展示了这些方法在解决多样科学问题中的有效性。",
      "categories": [
        "cs.LG",
        "cs.AI",
        "cs.DC"
      ],
      "primary_category": "cs.LG",
      "comment": "17 pages, 5 figures",
      "pdf_url": "http://arxiv.org/pdf/2406.17812v1",
      "published_date": "2024-06-24 20:29:29 UTC",
      "updated_date": "2024-06-24 20:29:29 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-18T23:54:59.871824"
    },
    {
      "arxiv_id": "2406.17811v2",
      "title": "CATBench: A Compiler Autotuning Benchmarking Suite for Black-box Optimization",
      "title_zh": "CATBench: 用于黑箱优化的编译器自动调优基准测试套件",
      "authors": [
        "Jacob O. Tørring",
        "Carl Hvarfner",
        "Luigi Nardi",
        "Magnus Själander"
      ],
      "abstract": "Bayesian optimization is a powerful method for automating tuning of\ncompilers. The complex landscape of autotuning provides a myriad of rarely\nconsidered structural challenges for black-box optimizers, and the lack of\nstandardized benchmarks has limited the study of Bayesian optimization within\nthe domain. To address this, we present CATBench, a comprehensive benchmarking\nsuite that captures the complexities of compiler autotuning, ranging from\ndiscrete, conditional, and permutation parameter types to known and unknown\nbinary constraints, as well as both multi-fidelity and multi-objective\nevaluations. The benchmarks in CATBench span a range of machine\nlearning-oriented computations, from tensor algebra to image processing and\nclustering, and uses state-of-the-art compilers, such as TACO and RISE/ELEVATE.\nCATBench offers a unified interface for evaluating Bayesian optimization\nalgorithms, promoting reproducibility and innovation through an easy-to-use,\nfully containerized setup of both surrogate and real-world compiler\noptimization tasks. We validate CATBench on several state-of-the-art\nalgorithms, revealing their strengths and weaknesses and demonstrating the\nsuite's potential for advancing both Bayesian optimization and compiler\nautotuning research.",
      "tldr_zh": "该论文介绍了 CATBench，这是一个针对黑盒优化的编译器自动调优基准测试套件，旨在解决现有基准缺乏标准化问题。CATBench 捕捉了编译器调优的复杂性，包括离散、条件和排列参数类型、已知/未知二进制约束、多保真度和多目标评估，并涵盖机器学习计算如张量代数、图像处理和聚类，使用先进的编译器如 TACO 和 RISE/ELEVATE。实验结果显示，通过统一的接口和容器化设置，CATBench 验证了多种 Bayesian optimization 算法的优缺点，推动了该领域的研究创新和可重复性。",
      "categories": [
        "cs.LG",
        "cs.AI",
        "cs.NE"
      ],
      "primary_category": "cs.LG",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2406.17811v2",
      "published_date": "2024-06-24 20:15:04 UTC",
      "updated_date": "2025-04-08 14:37:00 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-18T23:55:13.820369"
    },
    {
      "arxiv_id": "2406.17115v2",
      "title": "Evaluating the Quality of Hallucination Benchmarks for Large Vision-Language Models",
      "title_zh": "翻译失败",
      "authors": [
        "Bei Yan",
        "Jie Zhang",
        "Zheng Yuan",
        "Shiguang Shan",
        "Xilin Chen"
      ],
      "abstract": "Despite the rapid progress and outstanding performance of Large\nVision-Language Models (LVLMs) in recent years, LVLMs have been plagued by the\nissue of hallucination, i.e., LVLMs tend to generate responses that are\ninconsistent with the corresponding visual inputs. To evaluate the degree of\nhallucination in LVLMs, previous works have proposed a series of benchmarks\nfeaturing different types of tasks and evaluation metrics. However, we find\nthat the quality of the existing hallucination benchmarks varies, with some\nsuffering from problems, e.g., inconsistent evaluation results under repeated\ntests, and misalignment with human evaluation. To this end, we propose a\nHallucination benchmark Quality Measurement framework (HQM), which leverages\nvarious indicators to assess the reliability and validity of existing\nhallucination benchmarks separately. Specifically, for reliability we explore\ntest-retest reliability and parallel-forms reliability, while for validity we\nexamine criterion validity and coverage of hallucination types. Furthermore,\nbased on the results of our quality measurement, we construct a High-Quality\nHallucination Benchmark (HQH) for LVLMs, which demonstrates superior\nreliability and validity under our HQM framework. We conduct an extensive\nevaluation of over 10 representative LVLMs, including GPT-4o and\nGemini-1.5-Pro, to provide an in-depth analysis of the hallucination issues in\nexisting models. Our benchmark is publicly available at\nhttps://github.com/HQHBench/HQHBench.",
      "tldr_zh": "该研究评估了现有 hallucination benchmarks 的质量，发现许多基准存在问题，如测试重复性不一致（test-retest reliability）和与人类评估不匹配。论文提出 HQM（Hallucination benchmark Quality Measurement framework）框架，通过 reliability（如 test-retest reliability 和 parallel-forms reliability）和 validity（如 criterion validity 和 coverage of hallucination types）指标来系统评估这些基准。基于 HQM 的结果，研究构建了 High-Quality Hallucination Benchmark (HQH)，该基准展示了更高的可靠性和有效性，并对超过 10 个代表性 Large Vision-Language Models (LVLM)，包括 GPT-4o 和 Gemini-1.5-Pro，进行深入评估以分析 hallucination 问题。HQH 基准已公开可用，可用于进一步研究。",
      "categories": [
        "cs.CV",
        "cs.AI"
      ],
      "primary_category": "cs.CV",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2406.17115v2",
      "published_date": "2024-06-24 20:08:07 UTC",
      "updated_date": "2024-10-09 10:43:47 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-18T23:55:26.782728"
    },
    {
      "arxiv_id": "2406.17098v2",
      "title": "Learning Temporal Distances: Contrastive Successor Features Can Provide a Metric Structure for Decision-Making",
      "title_zh": "学习时间距离：对比性后继特征可以为决策提供度量结构",
      "authors": [
        "Vivek Myers",
        "Chongyi Zheng",
        "Anca Dragan",
        "Sergey Levine",
        "Benjamin Eysenbach"
      ],
      "abstract": "Temporal distances lie at the heart of many algorithms for planning, control,\nand reinforcement learning that involve reaching goals, allowing one to\nestimate the transit time between two states. However, prior attempts to define\nsuch temporal distances in stochastic settings have been stymied by an\nimportant limitation: these prior approaches do not satisfy the triangle\ninequality. This is not merely a definitional concern, but translates to an\ninability to generalize and find shortest paths. In this paper, we build on\nprior work in contrastive learning and quasimetrics to show how successor\nfeatures learned by contrastive learning (after a change of variables) form a\ntemporal distance that does satisfy the triangle inequality, even in stochastic\nsettings. Importantly, this temporal distance is computationally efficient to\nestimate, even in high-dimensional and stochastic settings. Experiments in\ncontrolled settings and benchmark suites demonstrate that an RL algorithm based\non these new temporal distances exhibits combinatorial generalization (i.e.,\n\"stitching\") and can sometimes learn more quickly than prior methods, including\nthose based on quasimetrics.",
      "tldr_zh": "该论文探讨了在随机环境中定义时间距离（temporal distances）的挑战，这些距离对规划、控制和强化学习（RL）至关重要，但现有方法无法满足三角不等式（triangle inequality），导致泛化不足。作者提出一种新方法，通过对比学习（contrastive learning）学习的后继特征（successor features），并进行变量变换，使其形成满足三角不等式的度量结构。实验结果表明，这种时间距离在高维和随机环境中计算高效，并支持组合泛化（combinatorial generalization），使基于它的RL算法比现有方法学习更快。总的来说，该方法为决策过程提供了更可靠的度量框架。",
      "categories": [
        "cs.LG",
        "cs.AI"
      ],
      "primary_category": "cs.LG",
      "comment": "Proceedings of the 41st International Conference on Machine Learning\n  (ICML 2024)",
      "pdf_url": "http://arxiv.org/pdf/2406.17098v2",
      "published_date": "2024-06-24 19:36:45 UTC",
      "updated_date": "2025-03-10 07:33:32 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-18T23:55:37.685899"
    },
    {
      "arxiv_id": "2406.17096v1",
      "title": "Model-Free Robust Reinforcement Learning with Sample Complexity Analysis",
      "title_zh": "无模型鲁棒强化学习及其样本复杂度分析",
      "authors": [
        "Yudan Wang",
        "Shaofeng Zou",
        "Yue Wang"
      ],
      "abstract": "Distributionally Robust Reinforcement Learning (DR-RL) aims to derive a\npolicy optimizing the worst-case performance within a predefined uncertainty\nset. Despite extensive research, previous DR-RL algorithms have predominantly\nfavored model-based approaches, with limited availability of model-free methods\noffering convergence guarantees or sample complexities. This paper proposes a\nmodel-free DR-RL algorithm leveraging the Multi-level Monte Carlo (MLMC)\ntechnique to close such a gap. Our innovative approach integrates a threshold\nmechanism that ensures finite sample requirements for algorithmic\nimplementation, a significant improvement than previous model-free algorithms.\nWe develop algorithms for uncertainty sets defined by total variation,\nChi-square divergence, and KL divergence, and provide finite sample analyses\nunder all three cases. Remarkably, our algorithms represent the first\nmodel-free DR-RL approach featuring finite sample complexity for total\nvariation and Chi-square divergence uncertainty sets, while also offering an\nimproved sample complexity and broader applicability compared to existing\nmodel-free DR-RL algorithms for the KL divergence model. The complexities of\nour method establish the tightest results for all three uncertainty models in\nmodel-free DR-RL, underscoring the effectiveness and efficiency of our\nalgorithm, and highlighting its potential for practical applications.",
      "tldr_zh": "该论文提出了一种模型无关的分布鲁棒强化学习（Distributionally Robust Reinforcement Learning, DR-RL）算法，使用Multi-level Monte Carlo (MLMC)技术来优化不确定性集合中的最坏情况性能，并引入阈值机制以确保有限的样本需求。算法针对total variation、Chi-square divergence和KL divergence的不确定性集合开发了相应方法，并提供了有限样本复杂度的分析。相比现有方法，该算法首次为total variation和Chi-square divergence实现了有限样本复杂度，并在KL divergence上提供了更低的样本复杂度和更广泛的适用性，展示了其在鲁棒强化学习中的高效性和潜力。",
      "categories": [
        "cs.LG",
        "cs.AI",
        "stat.ML"
      ],
      "primary_category": "cs.LG",
      "comment": "UAI 2024",
      "pdf_url": "http://arxiv.org/pdf/2406.17096v1",
      "published_date": "2024-06-24 19:35:26 UTC",
      "updated_date": "2024-06-24 19:35:26 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-18T23:55:49.109786"
    },
    {
      "arxiv_id": "2406.17092v1",
      "title": "BEEAR: Embedding-based Adversarial Removal of Safety Backdoors in Instruction-tuned Language Models",
      "title_zh": "翻译失败",
      "authors": [
        "Yi Zeng",
        "Weiyu Sun",
        "Tran Ngoc Huynh",
        "Dawn Song",
        "Bo Li",
        "Ruoxi Jia"
      ],
      "abstract": "Safety backdoor attacks in large language models (LLMs) enable the stealthy\ntriggering of unsafe behaviors while evading detection during normal\ninteractions. The high dimensionality of potential triggers in the token space\nand the diverse range of malicious behaviors make this a critical challenge. We\npresent BEEAR, a mitigation approach leveraging the insight that backdoor\ntriggers induce relatively uniform drifts in the model's embedding space. Our\nbi-level optimization method identifies universal embedding perturbations that\nelicit unwanted behaviors and adjusts the model parameters to reinforce safe\nbehaviors against these perturbations. Experiments show BEEAR reduces the\nsuccess rate of RLHF time backdoor attacks from >95% to <1% and from 47% to 0%\nfor instruction-tuning time backdoors targeting malicious code generation,\nwithout compromising model utility. Requiring only defender-defined safe and\nunwanted behaviors, BEEAR represents a step towards practical defenses against\nsafety backdoors in LLMs, providing a foundation for further advancements in AI\nsafety and security.",
      "tldr_zh": "该研究提出 BEEAR 方法，用于移除指令调整语言模型（LLMs）中的安全后门攻击（safety backdoors），这些攻击可隐蔽触发不安全行为。BEEAR 利用后门触发器在嵌入空间（embedding space）中引起的均匀漂移，通过双层优化（bi-level optimization）识别通用嵌入扰动（embedding perturbations）并调整模型参数，以强化对这些扰动的安全行为。实验显示，BEEAR 将 RLHF 时间后门攻击的成功率从超过95% 降至不到1%，并将针对恶意代码生成的指令调整时间后门从47% 降至0%，同时不影响模型的实用性。该方法仅需防御者定义的安全和 unwanted behaviors，提供了一种实用防御，推进 AI 安全和安全性的发展。",
      "categories": [
        "cs.CR",
        "cs.AI"
      ],
      "primary_category": "cs.CR",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2406.17092v1",
      "published_date": "2024-06-24 19:29:47 UTC",
      "updated_date": "2024-06-24 19:29:47 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-18T23:56:02.607161"
    },
    {
      "arxiv_id": "2406.17090v1",
      "title": "Exploring Biomarker Relationships in Both Type 1 and Type 2 Diabetes Mellitus Through a Bayesian Network Analysis Approach",
      "title_zh": "通过贝叶斯网络分析方法探索1型和2型糖尿病中生物标记物的关系",
      "authors": [
        "Yuyang Sun",
        "Jingyu Lei",
        "Panagiotis Kosmas"
      ],
      "abstract": "Understanding the complex relationships of biomarkers in diabetes is pivotal\nfor advancing treatment strategies, a pressing need in diabetes research. This\nstudy applies Bayesian network structure learning to analyze the Shanghai Type\n1 and Type 2 diabetes mellitus datasets, revealing complex relationships among\nkey diabetes-related biomarkers. The constructed Bayesian network presented\nnotable predictive accuracy, particularly for Type 2 diabetes mellitus, with\nroot mean squared error (RMSE) of 18.23 mg/dL, as validated through\nleave-one-domain experiments and Clarke error grid analysis. This study not\nonly elucidates the intricate dynamics of diabetes through a deeper\nunderstanding of biomarker interplay but also underscores the significant\npotential of integrating data-driven and knowledge-driven methodologies in the\nrealm of personalized diabetes management. Such an approach paves the way for\nmore custom and effective treatment strategies, marking a notable advancement\nin the field.",
      "tldr_zh": "本研究通过 Bayesian network structure learning 方法分析上海的 Type 1 和 Type 2 糖尿病数据集，探讨关键生物标志物之间的复杂关系，以推进个性化治疗策略。结果显示，构建的 Bayesian network 在 Type 2 糖尿病预测中表现出色，RMSE 为 18.23 mg/dL，并经 leave-one-domain experiments 和 Clarke error grid analysis 验证。该方法整合数据驱动和知识驱动途径，不仅加深了对糖尿病动态的理解，还为更自定义和有效的管理方案奠定基础。",
      "categories": [
        "q-bio.QM",
        "cs.AI",
        "cs.CE",
        "cs.LG"
      ],
      "primary_category": "q-bio.QM",
      "comment": "Paper is accepted by EMBC 2024",
      "pdf_url": "http://arxiv.org/pdf/2406.17090v1",
      "published_date": "2024-06-24 19:27:34 UTC",
      "updated_date": "2024-06-24 19:27:34 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-18T23:56:13.934660"
    },
    {
      "arxiv_id": "2406.17073v2",
      "title": "Meta-GCN: A Dynamically Weighted Loss Minimization Method for Dealing with the Data Imbalance in Graph Neural Networks",
      "title_zh": "翻译失败",
      "authors": [
        "Mahdi Mohammadizadeh",
        "Arash Mozhdehi",
        "Yani Ioannou",
        "Xin Wang"
      ],
      "abstract": "Although many real-world applications, such as disease prediction, and fault\ndetection suffer from class imbalance, most existing graph-based classification\nmethods ignore the skewness of the distribution of classes; therefore, tend to\nbe biased towards the majority class(es). Conventional methods typically tackle\nthis problem through the assignment of weights to each one of the class samples\nbased on a function of their loss, which can lead to over-fitting on outliers.\nIn this paper, we propose a meta-learning algorithm, named Meta-GCN, for\nadaptively learning the example weights by simultaneously minimizing the\nunbiased meta-data set loss and optimizing the model weights through the use of\na small unbiased meta-data set. Through experiments, we have shown that\nMeta-GCN outperforms state-of-the-art frameworks and other baselines in terms\nof accuracy, the area under the receiver operating characteristic (AUC-ROC)\ncurve, and macro F1-Score for classification tasks on two different datasets.",
      "tldr_zh": "本文提出Meta-GCN，一种基于元学习(meta-learning)的动态加权损失最小化方法，用于解决图神经网络(Graph Neural Networks)中数据不平衡问题，避免传统方法因样本权重分配而导致的过拟合。Meta-GCN通过同时最小化无偏元数据集的损失并优化模型权重，来自适应地学习样本权重。实验结果表明，该方法在两个数据集上的分类任务中，在准确率、AUC-ROC和宏F1-Score方面均优于现有框架和基线。",
      "categories": [
        "cs.LG",
        "cs.AI"
      ],
      "primary_category": "cs.LG",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2406.17073v2",
      "published_date": "2024-06-24 18:59:24 UTC",
      "updated_date": "2024-06-27 18:15:16 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-18T23:56:25.301490"
    },
    {
      "arxiv_id": "2406.17066v1",
      "title": "Tolerance of Reinforcement Learning Controllers against Deviations in Cyber Physical Systems",
      "title_zh": "翻译失败",
      "authors": [
        "Changjian Zhang",
        "Parv Kapoor",
        "Eunsuk Kang",
        "Romulo Meira-Goes",
        "David Garlan",
        "Akila Ganlath",
        "Shatadal Mishra",
        "Nejib Ammar"
      ],
      "abstract": "Cyber-physical systems (CPS) with reinforcement learning (RL)-based\ncontrollers are increasingly being deployed in complex physical environments\nsuch as autonomous vehicles, the Internet-of-Things(IoT), and smart cities. An\nimportant property of a CPS is tolerance; i.e., its ability to function safely\nunder possible disturbances and uncertainties in the actual operation. In this\npaper, we introduce a new, expressive notion of tolerance that describes how\nwell a controller is capable of satisfying a desired system requirement,\nspecified using Signal Temporal Logic (STL), under possible deviations in the\nsystem. Based on this definition, we propose a novel analysis problem, called\nthe tolerance falsification problem, which involves finding small deviations\nthat result in a violation of the given requirement. We present a novel,\ntwo-layer simulation-based analysis framework and a novel search heuristic for\nfinding small tolerance violations. To evaluate our approach, we construct a\nset of benchmark problems where system parameters can be configured to\nrepresent different types of uncertainties and disturbancesin the system. Our\nevaluation shows that our falsification approach and heuristic can effectively\nfind small tolerance violations.",
      "tldr_zh": "该论文探讨了强化学习 (RL) 控制器在网络物理系统 (CPS) 中的容忍性，即在系统偏差和不确定性下维持安全功能的能力。作者引入了一个新的容忍性概念，使用 Signal Temporal Logic (STL) 来指定系统要求，并提出“容忍性伪证问题”，旨在寻找可能导致要求违反的小偏差。论文开发了一个两层模拟-based 分析框架和一个新型搜索启发式方法，以高效地识别这些偏差。通过构建可配置的基准问题来模拟不同不确定性和干扰，实验结果表明，该方法能有效发现小的容忍性违反。",
      "categories": [
        "eess.SY",
        "cs.AI",
        "cs.LO",
        "cs.RO",
        "cs.SY"
      ],
      "primary_category": "eess.SY",
      "comment": "arXiv admin note: text overlap with arXiv:2311.07462",
      "pdf_url": "http://arxiv.org/pdf/2406.17066v1",
      "published_date": "2024-06-24 18:33:45 UTC",
      "updated_date": "2024-06-24 18:33:45 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-18T23:56:38.069267"
    },
    {
      "arxiv_id": "2406.17057v1",
      "title": "At First Sight: Zero-Shot Classification of Astronomical Images with Large Multimodal Models",
      "title_zh": "初次一见：利用大型多模态模型进行天文图像",
      "authors": [
        "Dimitrios Tanoglidis",
        "Bhuvnesh Jain"
      ],
      "abstract": "Vision-Language multimodal Models (VLMs) offer the possibility for zero-shot\nclassification in astronomy: i.e. classification via natural language prompts,\nwith no training. We investigate two models, GPT-4o and LLaVA-NeXT, for\nzero-shot classification of low-surface brightness galaxies and artifacts, as\nwell as morphological classification of galaxies. We show that with natural\nlanguage prompts these models achieved significant accuracy (above 80 percent\ntypically) without additional training/fine tuning. We discuss areas that\nrequire improvement, especially for LLaVA-NeXT, which is an open source model.\nOur findings aim to motivate the astronomical community to consider VLMs as a\npowerful tool for both research and pedagogy, with the prospect that future\ncustom-built or fine-tuned models could perform better.",
      "tldr_zh": "该研究探讨了使用大型多模态模型（VLMs）如 GPT-4o 和 LLaVA-NeXT 进行天文学图像的零样本分类（Zero-Shot Classification），通过自然语言提示实现无需训练的分类任务。实验结果显示，这些模型在低表面亮度星系、伪像以及星系形态分类上 typically 达到了超过80%的准确率。作者指出了改进需求，尤其是针对开源模型 LLaVA-NeXT，并鼓励天文社区将 VLMs 视为研究和教学的有力工具，未来通过自定义或微调模型有望提升性能。",
      "categories": [
        "astro-ph.IM",
        "astro-ph.GA",
        "cs.AI"
      ],
      "primary_category": "astro-ph.IM",
      "comment": "5 pages, 3 images. Prepared for submission to RNAAS",
      "pdf_url": "http://arxiv.org/pdf/2406.17057v1",
      "published_date": "2024-06-24 18:17:54 UTC",
      "updated_date": "2024-06-24 18:17:54 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-18T23:56:52.536728"
    },
    {
      "arxiv_id": "2406.17810v1",
      "title": "PIC2O-Sim: A Physics-Inspired Causality-Aware Dynamic Convolutional Neural Operator for Ultra-Fast Photonic Device FDTD Simulation",
      "title_zh": "翻译失败",
      "authors": [
        "Pingchuan Ma",
        "Haoyu Yang",
        "Zhengqi Gao",
        "Duane S. Boning",
        "Jiaqi Gu"
      ],
      "abstract": "The finite-difference time-domain (FDTD) method, which is important in\nphotonic hardware design flow, is widely adopted to solve time-domain Maxwell\nequations. However, FDTD is known for its prohibitive runtime cost, taking\nminutes to hours to simulate a single device. Recently, AI has been applied to\nrealize orders-of-magnitude speedup in partial differential equation (PDE)\nsolving. However, AI-based FDTD solvers for photonic devices have not been\nclearly formulated. Directly applying off-the-shelf models to predict the\noptical field dynamics shows unsatisfying fidelity and efficiency since the\nmodel primitives are agnostic to the unique physical properties of Maxwell\nequations and lack algorithmic customization. In this work, we thoroughly\ninvestigate the synergy between neural operator designs and the physical\nproperty of Maxwell equations and introduce a physics-inspired AI-based FDTD\nprediction framework PIC2O-Sim which features a causality-aware dynamic\nconvolutional neural operator as its backbone model that honors the space-time\ncausality constraints via careful receptive field configuration and explicitly\ncaptures the permittivity-dependent light propagation behavior via an efficient\ndynamic convolution operator. Meanwhile, we explore the trade-offs among\nprediction scalability, fidelity, and efficiency via a multi-stage partitioned\ntime-bundling technique in autoregressive prediction. Multiple key techniques\nhave been introduced to mitigate iterative error accumulation while maintaining\nefficiency advantages during autoregressive field prediction. Extensive\nevaluations on three challenging photonic device simulation tasks have shown\nthe superiority of our PIC2O-Sim method, showing 51.2% lower roll-out\nprediction error, 23.5 times fewer parameters than state-of-the-art neural\noperators, providing 300-600x higher simulation speed than an open-source FDTD\nnumerical solver.",
      "tldr_zh": "这篇论文针对光子设备FDTD模拟的计算密集问题，提出了一种physics-inspired AI框架PIC2O-Sim，以实现超快速时间域Maxwell equations求解。该框架的核心是causality-aware dynamic convolutional neural operator，通过精心配置receptive field来遵守space-time causality约束，并利用dynamic convolution操作符捕捉permittivity-dependent light propagation行为，同时引入multi-stage partitioned time-bundling技术来优化autoregressive预测并缓解迭代错误积累。实验结果显示，PIC2O-Sim在三个光子设备模拟任务上实现了51.2%更低的roll-out prediction error、23.5倍更少的参数，并比开源FDTD求解器提供300-600倍的模拟速度提升。",
      "categories": [
        "physics.comp-ph",
        "cs.AI",
        "physics.optics"
      ],
      "primary_category": "physics.comp-ph",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2406.17810v1",
      "published_date": "2024-06-24 18:15:36 UTC",
      "updated_date": "2024-06-24 18:15:36 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-18T23:57:02.960089"
    },
    {
      "arxiv_id": "2406.17055v4",
      "title": "Large Language Models Assume People are More Rational than We Really are",
      "title_zh": "翻译失败",
      "authors": [
        "Ryan Liu",
        "Jiayi Geng",
        "Joshua C. Peterson",
        "Ilia Sucholutsky",
        "Thomas L. Griffiths"
      ],
      "abstract": "In order for AI systems to communicate effectively with people, they must\nunderstand how we make decisions. However, people's decisions are not always\nrational, so the implicit internal models of human decision-making in Large\nLanguage Models (LLMs) must account for this. Previous empirical evidence seems\nto suggest that these implicit models are accurate -- LLMs offer believable\nproxies of human behavior, acting how we expect humans would in everyday\ninteractions. However, by comparing LLM behavior and predictions to a large\ndataset of human decisions, we find that this is actually not the case: when\nboth simulating and predicting people's choices, a suite of cutting-edge LLMs\n(GPT-4o & 4-Turbo, Llama-3-8B & 70B, Claude 3 Opus) assume that people are more\nrational than we really are. Specifically, these models deviate from human\nbehavior and align more closely with a classic model of rational choice --\nexpected value theory. Interestingly, people also tend to assume that other\npeople are rational when interpreting their behavior. As a consequence, when we\ncompare the inferences that LLMs and people draw from the decisions of others\nusing another psychological dataset, we find that these inferences are highly\ncorrelated. Thus, the implicit decision-making models of LLMs appear to be\naligned with the human expectation that other people will act rationally,\nrather than with how people actually act.",
      "tldr_zh": "本研究发现，大型语言模型（LLMs，如 GPT-4o 和 Claude 3 Opus）在模拟和预测人类决策时，假设人们比实际情况更理性，从而偏离了真实人类行为，而更接近经典的理性选择模型（expected value theory）。研究者通过比较 LLMs 的表现与大型人类决策数据集，揭示了这种偏差：LLMs 倾向于认为人们会做出更理性的选择。值得注意的是，人们自身也常假设他人更理性，因此 LLMs 在解读他人行为时的推理与人类预期高度一致，这突显了 LLMs 隐含决策模型与实际人类行为的脱节。",
      "categories": [
        "cs.CL",
        "cs.AI",
        "cs.CY",
        "cs.LG"
      ],
      "primary_category": "cs.CL",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2406.17055v4",
      "published_date": "2024-06-24 18:15:27 UTC",
      "updated_date": "2025-03-10 17:42:37 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-18T23:57:16.648942"
    },
    {
      "arxiv_id": "2406.16864v1",
      "title": "StableNormal: Reducing Diffusion Variance for Stable and Sharp Normal",
      "title_zh": "StableNormal：减少扩散方差以实现稳定且清晰的法线",
      "authors": [
        "Chongjie Ye",
        "Lingteng Qiu",
        "Xiaodong Gu",
        "Qi Zuo",
        "Yushuang Wu",
        "Zilong Dong",
        "Liefeng Bo",
        "Yuliang Xiu",
        "Xiaoguang Han"
      ],
      "abstract": "This work addresses the challenge of high-quality surface normal estimation\nfrom monocular colored inputs (i.e., images and videos), a field which has\nrecently been revolutionized by repurposing diffusion priors. However, previous\nattempts still struggle with stochastic inference, conflicting with the\ndeterministic nature of the Image2Normal task, and costly ensembling step,\nwhich slows down the estimation process. Our method, StableNormal, mitigates\nthe stochasticity of the diffusion process by reducing inference variance, thus\nproducing \"Stable-and-Sharp\" normal estimates without any additional ensembling\nprocess. StableNormal works robustly under challenging imaging conditions, such\nas extreme lighting, blurring, and low quality. It is also robust against\ntransparent and reflective surfaces, as well as cluttered scenes with numerous\nobjects. Specifically, StableNormal employs a coarse-to-fine strategy, which\nstarts with a one-step normal estimator (YOSO) to derive an initial normal\nguess, that is relatively coarse but reliable, then followed by a\nsemantic-guided refinement process (SG-DRN) that refines the normals to recover\ngeometric details. The effectiveness of StableNormal is demonstrated through\ncompetitive performance in standard datasets such as DIODE-indoor, iBims,\nScannetV2 and NYUv2, and also in various downstream tasks, such as surface\nreconstruction and normal enhancement. These results evidence that StableNormal\nretains both the \"stability\" and \"sharpness\" for accurate normal estimation.\nStableNormal represents a baby attempt to repurpose diffusion priors for\ndeterministic estimation. To democratize this, code and models have been\npublicly available in hf.co/Stable-X",
      "tldr_zh": "这篇论文提出了 StableNormal 方法，通过减少扩散过程的方差，解决从单目彩色输入（如图像和视频）进行高品质表面法线估计的随机性问题，从而实现稳定且锐利的法线输出，而无需额外集成步骤。StableNormal 采用粗到细策略，首先使用 YOSO 进行一步初始估计获得粗略但可靠的结果，然后通过 SG-DRN 语义引导精炼过程恢复几何细节。实验显示，该方法在 DIODE-indoor、iBims、ScannetV2 和 NYUv2 等标准数据集上表现出色，并在下游任务如表面重建和法线增强中表现出鲁棒性，对极端照明、模糊或复杂场景具有较强适应性。该研究代表了利用 diffusion priors 进行确定性估计的初步尝试，并已公开代码和模型。",
      "categories": [
        "cs.CV",
        "cs.AI",
        "cs.GR"
      ],
      "primary_category": "cs.CV",
      "comment": "HF Demo: hf.co/Stable-X, Video:\n  https://www.youtube.com/watch?v=sylXTxG_U2U",
      "pdf_url": "http://arxiv.org/pdf/2406.16864v1",
      "published_date": "2024-06-24 17:59:58 UTC",
      "updated_date": "2024-06-24 17:59:58 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-18T23:57:29.545936"
    },
    {
      "arxiv_id": "2406.16853v1",
      "title": "GeoMFormer: A General Architecture for Geometric Molecular Representation Learning",
      "title_zh": "GeoMFormer：用于几何分子表示学习的通用架构",
      "authors": [
        "Tianlang Chen",
        "Shengjie Luo",
        "Di He",
        "Shuxin Zheng",
        "Tie-Yan Liu",
        "Liwei Wang"
      ],
      "abstract": "Molecular modeling, a central topic in quantum mechanics, aims to accurately\ncalculate the properties and simulate the behaviors of molecular systems. The\nmolecular model is governed by physical laws, which impose geometric\nconstraints such as invariance and equivariance to coordinate rotation and\ntranslation. While numerous deep learning approaches have been developed to\nlearn molecular representations under these constraints, most of them are built\nupon heuristic and costly modules. We argue that there is a strong need for a\ngeneral and flexible framework for learning both invariant and equivariant\nfeatures. In this work, we introduce a novel Transformer-based molecular model\ncalled GeoMFormer to achieve this goal. Using the standard Transformer modules,\ntwo separate streams are developed to maintain and learn invariant and\nequivariant representations. Carefully designed cross-attention modules bridge\nthe two streams, allowing information fusion and enhancing geometric modeling\nin each stream. As a general and flexible architecture, we show that many\nprevious architectures can be viewed as special instantiations of GeoMFormer.\nExtensive experiments are conducted to demonstrate the power of GeoMFormer. All\nempirical results show that GeoMFormer achieves strong performance on both\ninvariant and equivariant tasks of different types and scales. Code and models\nwill be made publicly available at https://github.com/c-tl/GeoMFormer.",
      "tldr_zh": "本文提出GeoMFormer，一种基于Transformer的通用架构，用于几何分子表示学习，能够同时处理invariant（不变性）和equivariant（等变性）约束，以满足分子建模中的物理定律要求。GeoMFormer设计了两个独立流来分别维护和学习invariant和equivariant特征，并通过精心设计的交叉注意力模块实现信息融合，从而增强几何建模能力。实验结果显示，该框架在各种类型和规模的invariant和equivariant任务上表现出色，许多现有架构可视为其特例。代码已计划在GitHub上公开，以促进进一步研究。",
      "categories": [
        "cs.LG",
        "cond-mat.mtrl-sci",
        "cs.AI",
        "q-bio.BM"
      ],
      "primary_category": "cs.LG",
      "comment": "25 pages, 13 tables, l figure; ICML 2024 camera ready version",
      "pdf_url": "http://arxiv.org/pdf/2406.16853v1",
      "published_date": "2024-06-24 17:58:13 UTC",
      "updated_date": "2024-06-24 17:58:13 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-18T23:57:40.804991"
    },
    {
      "arxiv_id": "2406.16851v3",
      "title": "Losing Visual Needles in Image Haystacks: Vision Language Models are Easily Distracted in Short and Long Contexts",
      "title_zh": "翻译失败",
      "authors": [
        "Aditya Sharma",
        "Michael Saxon",
        "William Yang Wang"
      ],
      "abstract": "We present LoCoVQA, a dynamic benchmark generator for evaluating long-context\nextractive reasoning in vision language models (VLMs). LoCoVQA augments test\nexamples for mathematical reasoning, VQA, and character recognition tasks with\nincreasingly long visual contexts composed of both in-distribution and\nout-of-distribution distractor images.\n  Across these tasks, a diverse set of VLMs rapidly lose performance as the\nvisual context length grows, often exhibiting a striking logarithmic decay\ntrend. This test assesses how well VLMs can ignore irrelevant information when\nanswering queries -- a task that is quite easy for language models (LMs) in the\ntext domain -- demonstrating that current state-of-the-art VLMs lack this\nessential capability for many long-context applications.",
      "tldr_zh": "本研究引入了LoCoVQA，一种动态基准生成器，用于评估视觉语言模型(VLMs)在长上下文中的提取式推理能力。LoCoVQA通过在数学推理、VQA和字符识别任务中添加越来越多的视觉上下文（包括分布内和分布外干扰图像），测试模型忽略无关信息的表现。结果显示，各种VLMs在上下文长度增加时性能迅速下降，通常呈现出明显的对数衰减趋势，这突显了当前最先进VLMs在长上下文应用中缺乏语言模型(LMs)在文本领域易于实现的这一核心能力。",
      "categories": [
        "cs.CL",
        "cs.AI",
        "cs.CV"
      ],
      "primary_category": "cs.CL",
      "comment": "Findings of EMNLP 2024",
      "pdf_url": "http://arxiv.org/pdf/2406.16851v3",
      "published_date": "2024-06-24 17:58:03 UTC",
      "updated_date": "2024-10-04 01:58:06 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-18T23:57:53.172629"
    },
    {
      "arxiv_id": "2407.10996v1",
      "title": "Visualization Literacy of Multimodal Large Language Models: A Comparative Study",
      "title_zh": "多模态大语言模型的可视化素养：一项比较研究",
      "authors": [
        "Zhimin Li",
        "Haichao Miao",
        "Valerio Pascucci",
        "Shusen Liu"
      ],
      "abstract": "The recent introduction of multimodal large language models (MLLMs) combine\nthe inherent power of large language models (LLMs) with the renewed\ncapabilities to reason about the multimodal context. The potential usage\nscenarios for MLLMs significantly outpace their text-only counterparts. Many\nrecent works in visualization have demonstrated MLLMs' capability to understand\nand interpret visualization results and explain the content of the\nvisualization to users in natural language. In the machine learning community,\nthe general vision capabilities of MLLMs have been evaluated and tested through\nvarious visual understanding benchmarks. However, the ability of MLLMs to\naccomplish specific visualization tasks based on visual perception has not been\nproperly explored and evaluated, particularly, from a visualization-centric\nperspective.\n  In this work, we aim to fill the gap by utilizing the concept of\nvisualization literacy to evaluate MLLMs. We assess MLLMs' performance over two\npopular visualization literacy evaluation datasets (VLAT and mini-VLAT). Under\nthe framework of visualization literacy, we develop a general setup to compare\ndifferent multimodal large language models (e.g., GPT4-o, Claude 3 Opus, Gemini\n1.5 Pro) as well as against existing human baselines. Our study demonstrates\nMLLMs' competitive performance in visualization literacy, where they outperform\nhumans in certain tasks such as identifying correlations, clusters, and\nhierarchical structures.",
      "tldr_zh": "本研究评估了多模态大语言模型 (MLLMs) 的可视化素养 (visualization literacy)，通过比较不同 MLLMs（如 GPT-4o、Claude 3 Opus 和 Gemini 1.5 Pro）在处理可视化任务时的表现。研究利用两个流行数据集（VLAT 和 mini-VLAT）作为基准，并与人类表现进行对比，填补了从可视化视角评估 MLLMs 的空白。结果显示，MLLMs 在某些任务中超过了人类，例如识别相关性 (correlations)、聚类 (clusters) 和层次结构 (hierarchical structures)，突显了其在视觉理解方面的潜力。",
      "categories": [
        "cs.CL",
        "cs.AI",
        "cs.HC"
      ],
      "primary_category": "cs.CL",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2407.10996v1",
      "published_date": "2024-06-24 17:52:16 UTC",
      "updated_date": "2024-06-24 17:52:16 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-18T23:58:04.003380"
    },
    {
      "arxiv_id": "2407.02520v1",
      "title": "RaCIL: Ray Tracing based Multi-UAV Obstacle Avoidance through Composite Imitation Learning",
      "title_zh": "翻译失败",
      "authors": [
        "Harsh Bansal",
        "Vyom Goyal",
        "Bhaskar Joshi",
        "Akhil Gupta",
        "Harikumar Kandath"
      ],
      "abstract": "In this study, we address the challenge of obstacle avoidance for Unmanned\nAerial Vehicles (UAVs) through an innovative composite imitation learning\napproach that combines Proximal Policy Optimization (PPO) with Behavior Cloning\n(BC) and Generative Adversarial Imitation Learning (GAIL), enriched by the\nintegration of ray-tracing techniques. Our research underscores the significant\nrole of ray-tracing in enhancing obstacle detection and avoidance capabilities.\nMoreover, we demonstrate the effectiveness of incorporating GAIL in\ncoordinating the flight paths of two UAVs, showcasing improved collision\navoidance capabilities. Extending our methodology, we apply our combined PPO,\nBC, GAIL, and ray-tracing framework to scenarios involving four UAVs,\nillustrating its scalability and adaptability to more complex scenarios. The\nfindings indicate that our approach not only improves the reliability of basic\nPPO based obstacle avoidance but also paves the way for advanced autonomous UAV\noperations in crowded or dynamic environments.",
      "tldr_zh": "这篇论文提出了 RaCIL 框架，一种基于 ray-tracing 技术的复合模仿学习方法，用于解决多 UAV（Unmanned Aerial Vehicles）障碍避免挑战，该方法结合了 PPO（Proximal Policy Optimization）、BC（Behavior Cloning）和 GAIL（Generative Adversarial Imitation Learning）。通过整合 ray-tracing 增强障碍检测能力，并利用 GAIL 协调多个 UAV 的飞行路径，框架在两个 UAV 场景中显著提高了碰撞避免性能。实验结果显示，该方法扩展到四个 UAV 的复杂场景时，比基本 PPO 更可靠，并为 UAV 在拥挤或动态环境中的自主操作铺平道路。",
      "categories": [
        "cs.RO",
        "cs.AI",
        "cs.LG"
      ],
      "primary_category": "cs.RO",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2407.02520v1",
      "published_date": "2024-06-24 17:43:24 UTC",
      "updated_date": "2024-06-24 17:43:24 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-18T23:58:16.987111"
    },
    {
      "arxiv_id": "2406.16833v1",
      "title": "USDC: A Dataset of $\\underline{U}$ser $\\underline{S}$tance and $\\underline{D}$ogmatism in Long $\\underline{C}$onversations",
      "title_zh": "翻译失败",
      "authors": [
        "Mounika Marreddy",
        "Subba Reddy Oota",
        "Venkata Charan Chinni",
        "Manish Gupta",
        "Lucie Flek"
      ],
      "abstract": "Identifying user's opinions and stances in long conversation threads on\nvarious topics can be extremely critical for enhanced personalization, market\nresearch, political campaigns, customer service, conflict resolution, targeted\nadvertising, and content moderation. Hence, training language models to\nautomate this task is critical. However, to train such models, gathering manual\nannotations has multiple challenges: 1) It is time-consuming and costly; 2)\nConversation threads could be very long, increasing chances of noisy\nannotations; and 3) Interpreting instances where a user changes their opinion\nwithin a conversation is difficult because often such transitions are subtle\nand not expressed explicitly. Inspired by the recent success of large language\nmodels (LLMs) for complex natural language processing (NLP) tasks, we leverage\nMistral Large and GPT-4 to automate the human annotation process on the\nfollowing two tasks while also providing reasoning: i) User Stance\nclassification, which involves labeling a user's stance of a post in a\nconversation on a five-point scale; ii) User Dogmatism classification, which\ndeals with labeling a user's overall opinion in the conversation on a\nfour-point scale. The majority voting on zero-shot, one-shot, and few-shot\nannotations from these two LLMs on 764 multi-user Reddit conversations helps us\ncurate the USDC dataset. USDC is then used to finetune and instruction-tune\nmultiple deployable small language models for the 5-class stance and 4-class\ndogmatism classification tasks. We make the code and dataset publicly available\n[https://anonymous.4open.science/r/USDC-0F7F].",
      "tldr_zh": "该研究引入了USDC数据集，用于分析用户在长对话中的立场(User Stance)和教条主义(User Dogmatism)，以支持个性化、市场研究和内容审核等应用。面对手动标注的挑战（如耗时高和意见变化 subtlety），作者利用大型语言模型(LLMs)如Mistral Large和GPT-4进行自动标注，包括5点规模的User Stance分类和4点规模的User Dogmatism分类，并通过零样本、一样本和少样本多数投票处理764个Reddit对话。最终，USDC数据集用于fine-tune和instruction-tune小型语言模型，提升了相关分类任务的性能，并已公开代码和数据集[https://anonymous.4open.science/r/USDC-0F7F]。",
      "categories": [
        "cs.CL",
        "cs.AI",
        "cs.LG"
      ],
      "primary_category": "cs.CL",
      "comment": "32 pages, 18 figures",
      "pdf_url": "http://arxiv.org/pdf/2406.16833v1",
      "published_date": "2024-06-24 17:41:53 UTC",
      "updated_date": "2024-06-24 17:41:53 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-18T23:58:39.152901"
    },
    {
      "arxiv_id": "2406.16829v2",
      "title": "Understanding and Mitigating Tokenization Bias in Language Models",
      "title_zh": "理解与缓解语言模型中的分词偏差",
      "authors": [
        "Buu Phan",
        "Marton Havasi",
        "Matthew Muckley",
        "Karen Ullrich"
      ],
      "abstract": "State-of-the-art language models are autoregressive and operate on subword\nunits known as tokens. Specifically, one must encode the conditioning string\ninto a list of tokens before passing to the language models for next-token\nprediction. We show that popular encoding schemes, such as maximum prefix\nencoding (MPE) and byte-pair-encoding (BPE), induce a sampling bias that cannot\nbe mitigated with more training or data. To counter this universal problem, for\neach encoding scheme above, we propose a novel algorithm to obtain unbiased\nestimates from any language model trained on tokenized data. Our methods do not\nrequire finetuning the model, and the complexity, defined as the number of\nmodel runs, scales linearly with the sequence length in the case of MPE. As a\nresult, we show that one can simulate token-free behavior from a tokenized\nlanguage model. We empirically verify the correctness of our method through a\nMarkov-chain setup, where it accurately recovers the transition probabilities,\nas opposed to the conventional method of directly prompting tokens into the\nlanguage model.",
      "tldr_zh": "这篇论文探讨了语言模型中的Tokenization Bias问题，指出流行的编码方案如Maximum Prefix Encoding (MPE)和Byte-Pair-Encoding (BPE)会导致采样偏差，且无法通过更多训练或数据缓解。作者提出了一种新算法，能从已训练的分词数据中获得无偏估计，该方法无需微调模型，且其复杂度与序列长度线性相关。实验通过Markov-chain设置验证了该算法的正确性，它准确恢复了转移概率，而传统直接提示token的方法则失败，从而实现了从分词语言模型中模拟无token行为的可能。",
      "categories": [
        "cs.CL",
        "cs.AI",
        "cs.LG"
      ],
      "primary_category": "cs.CL",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2406.16829v2",
      "published_date": "2024-06-24 17:38:02 UTC",
      "updated_date": "2024-07-05 21:49:08 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-18T23:58:39.821961"
    },
    {
      "arxiv_id": "2406.16828v1",
      "title": "Ragnarök: A Reusable RAG Framework and Baselines for TREC 2024 Retrieval-Augmented Generation Track",
      "title_zh": "翻译失败",
      "authors": [
        "Ronak Pradeep",
        "Nandan Thakur",
        "Sahel Sharifymoghaddam",
        "Eric Zhang",
        "Ryan Nguyen",
        "Daniel Campos",
        "Nick Craswell",
        "Jimmy Lin"
      ],
      "abstract": "Did you try out the new Bing Search? Or maybe you fiddled around with Google\nAI~Overviews? These might sound familiar because the modern-day search stack\nhas recently evolved to include retrieval-augmented generation (RAG) systems.\nThey allow searching and incorporating real-time data into large language\nmodels (LLMs) to provide a well-informed, attributed, concise summary in\ncontrast to the traditional search paradigm that relies on displaying a ranked\nlist of documents. Therefore, given these recent advancements, it is crucial to\nhave an arena to build, test, visualize, and systematically evaluate RAG-based\nsearch systems. With this in mind, we propose the TREC 2024 RAG Track to foster\ninnovation in evaluating RAG systems. In our work, we lay out the steps we've\nmade towards making this track a reality -- we describe the details of our\nreusable framework, Ragnar\\\"ok, explain the curation of the new MS MARCO V2.1\ncollection choice, release the development topics for the track, and\nstandardize the I/O definitions which assist the end user. Next, using\nRagnar\\\"ok, we identify and provide key industrial baselines such as OpenAI's\nGPT-4o or Cohere's Command R+. Further, we introduce a web-based user interface\nfor an interactive arena allowing benchmarking pairwise RAG systems by\ncrowdsourcing. We open-source our Ragnar\\\"ok framework and baselines to achieve\na unified standard for future RAG systems.",
      "tldr_zh": "本论文引入了Ragnarök框架，这是一个可重用的RAG（Retrieval-Augmented Generation）框架，旨在为TREC 2024检索增强生成轨道提供统一的构建、测试和评估平台，以应对现代搜索系统的演变，如Bing和Google AI Overviews。框架整合了MS MARCO V2.1数据集、开发主题、标准化I/O定义，以及工业基准模型如OpenAI's GPT-4o和Cohere's Command R+，并通过一个基于网络的用户界面支持交互式基准测试和众包评估。最终，该研究开源了Ragnarök框架和基准，促进RAG系统的创新和系统化评估。",
      "categories": [
        "cs.IR",
        "cs.AI",
        "cs.CL"
      ],
      "primary_category": "cs.IR",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2406.16828v1",
      "published_date": "2024-06-24 17:37:52 UTC",
      "updated_date": "2024-06-24 17:37:52 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-18T23:58:55.692152"
    },
    {
      "arxiv_id": "2406.16821v1",
      "title": "General Binding Affinity Guidance for Diffusion Models in Structure-Based Drug Design",
      "title_zh": "翻译失败",
      "authors": [
        "Yue Jian",
        "Curtis Wu",
        "Danny Reidenbach",
        "Aditi S. Krishnapriyan"
      ],
      "abstract": "Structure-Based Drug Design (SBDD) focuses on generating valid ligands that\nstrongly and specifically bind to a designated protein pocket. Several methods\nuse machine learning for SBDD to generate these ligands in 3D space,\nconditioned on the structure of a desired protein pocket. Recently, diffusion\nmodels have shown success here by modeling the underlying distributions of\natomic positions and types. While these methods are effective in considering\nthe structural details of the protein pocket, they often fail to explicitly\nconsider the binding affinity. Binding affinity characterizes how tightly the\nligand binds to the protein pocket, and is measured by the change in free\nenergy associated with the binding process. It is one of the most crucial\nmetrics for benchmarking the effectiveness of the interaction between a ligand\nand protein pocket. To address this, we propose BADGER: Binding Affinity\nDiffusion Guidance with Enhanced Refinement. BADGER is a general guidance\nmethod to steer the diffusion sampling process towards improved protein-ligand\nbinding, allowing us to adjust the distribution of the binding affinity between\nligands and proteins. Our method is enabled by using a neural network (NN) to\nmodel the energy function, which is commonly approximated by AutoDock Vina\n(ADV). ADV's energy function is non-differentiable, and estimates the affinity\nbased on the interactions between a ligand and target protein receptor. By\nusing a NN as a differentiable energy function proxy, we utilize the gradient\nof our learned energy function as a guidance method on top of any trained\ndiffusion model. We show that our method improves the binding affinity of\ngenerated ligands to their protein receptors by up to 60\\%, significantly\nsurpassing previous machine learning methods. We also show that our guidance\nmethod is flexible and can be easily applied to other diffusion-based SBDD\nframeworks.",
      "tldr_zh": "这篇论文针对 Structure-Based Drug Design (SBDD) 中的问题，提出 BADGER（Binding Affinity Diffusion Guidance with Enhanced Refinement）方法，用于指导 diffusion models 生成与蛋白口袋更紧密结合的配体。BADGER 通过使用 neural network (NN) 作为能量函数的微分代理，代替非微分的 AutoDock Vina (ADV)，利用梯度来优化扩散采样过程，从而显式提升蛋白-配体结合亲和力。实验结果显示，该方法可以将生成的配体结合亲和力提高高达 60%，并展示出灵活性，可轻松应用于其他 diffusion-based SBDD 框架。",
      "categories": [
        "cs.LG",
        "cs.AI",
        "physics.bio-ph",
        "physics.chem-ph",
        "q-bio.BM"
      ],
      "primary_category": "cs.LG",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2406.16821v1",
      "published_date": "2024-06-24 17:31:41 UTC",
      "updated_date": "2024-06-24 17:31:41 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-18T23:59:05.643676"
    },
    {
      "arxiv_id": "2406.16810v2",
      "title": "How Data Inter-connectivity Shapes LLMs Unlearning: A Structural Unlearning Perspective",
      "title_zh": "翻译失败",
      "authors": [
        "Xinchi Qiu",
        "William F. Shen",
        "Yihong Chen",
        "Meghdad Kurmanji",
        "Nicola Cancedda",
        "Pontus Stenetorp",
        "Nicholas D. Lane"
      ],
      "abstract": "While unlearning knowledge from large language models (LLMs) is receiving\nincreasing attention, one important aspect remains unexplored. Existing\napproaches and benchmarks assume data points to-be-forgotten are independent,\nignoring their inter-connectivity - a fundamental characteristic of real-world\ndata structures. In this paper, we propose PISTOL, a method for compiling\nstructural datasets. PISTOL leverages the inherently structured nature of\ncontractual relationships, offering several key benefits. First, it enables\ninsights into the impact of structural data on unlearning effectiveness.\nSecond, it provides precise and concise ground truths for clearer evaluation.\nThird, its attribute generation does not require input from pre-trained LLMs,\nmitigating confounding risks. Leveraging datasets synthesized using PISTOL, we\ndemonstrate how data inter-connectivity impacts LLM unlearning. Specifically,\n(a) in both the pre-trained and fine-tuned models, unlearning difficulty\nincreases as data inter-connectivity grows, (b) there is a positive correlation\nbetween the density of the knowledge graph and unlearning difficulty, and (c)\nwhen the to-be-forgotten data is skewed towards one domain, balancing retaining\nperformance across all domains is challenging.",
      "tldr_zh": "本研究探讨了数据互连性对大型语言模型（LLMs）unlearning 的影响，指出现有方法忽略了真实数据结构的互连特性。论文提出 PISTOL 方法，用于编译结构化数据集，通过利用合同关系的固有结构，提供对 unlearning 有效性的洞察、精确的 ground truths，以及避免依赖预训练 LLMs 的属性生成。实验结果显示，随着数据 inter-connectivity 增加，unlearning 难度升高；knowledge graph 的密度与难度正相关；且当要遗忘的数据偏向特定领域时，保持跨领域性能平衡变得尤为挑战。",
      "categories": [
        "cs.LG",
        "cs.AI",
        "cs.CL"
      ],
      "primary_category": "cs.LG",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2406.16810v2",
      "published_date": "2024-06-24 17:22:36 UTC",
      "updated_date": "2025-03-10 21:33:53 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-18T23:59:19.588924"
    },
    {
      "arxiv_id": "2406.16797v2",
      "title": "Lottery Ticket Adaptation: Mitigating Destructive Interference in LLMs",
      "title_zh": "翻译失败",
      "authors": [
        "Ashwinee Panda",
        "Berivan Isik",
        "Xiangyu Qi",
        "Sanmi Koyejo",
        "Tsachy Weissman",
        "Prateek Mittal"
      ],
      "abstract": "Existing methods for adapting large language models (LLMs) to new tasks are\nnot suited to multi-task adaptation because they modify all the model weights\n-- causing destructive interference between tasks. The resulting effects, such\nas catastrophic forgetting of earlier tasks, make it challenging to obtain good\nperformance on multiple tasks at the same time. To mitigate this, we propose\nLottery Ticket Adaptation (LoTA), a sparse adaptation method that identifies\nand optimizes only a sparse subnetwork of the model. We evaluate LoTA on a wide\nrange of challenging tasks such as instruction following, reasoning, math, and\nsummarization. LoTA obtains better performance than full fine-tuning and\nlow-rank adaptation (LoRA), and maintains good performance even after training\non other tasks -- thus, avoiding catastrophic forgetting. By extracting and\nfine-tuning over lottery tickets (or sparse task vectors), LoTA also enables\nmodel merging over highly dissimilar tasks. Our code is made publicly available\nat https://github.com/kiddyboots216/lottery-ticket-adaptation.",
      "tldr_zh": "现有大型语言模型(LLMs)适应方法在多任务场景中会导致破坏性 interference 和灾难性 forgetting，因为它们修改了所有模型权重，从而影响多任务性能。为解决此问题，本文提出Lottery Ticket Adaptation (LoTA)，一种稀疏适应方法，通过识别和优化模型的稀疏子网络来实现高效适应。\nLoTA在指令跟随、推理、数学和总结等任务上比全微调和低秩适应(LoRA)获得更好的性能。\n此外，LoTA避免了灾难性 forgetting，即使在训练其他任务后也能维持高性能，并支持在高度不同的任务上进行模型合并。\n代码已在GitHub上公开可用。",
      "categories": [
        "cs.CL",
        "cs.AI"
      ],
      "primary_category": "cs.CL",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2406.16797v2",
      "published_date": "2024-06-24 16:58:23 UTC",
      "updated_date": "2024-06-25 13:46:41 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-18T23:59:32.909313"
    },
    {
      "arxiv_id": "2406.16793v7",
      "title": "Adam-mini: Use Fewer Learning Rates To Gain More",
      "title_zh": "Adam-mini：使用更少的学习率来获得更多",
      "authors": [
        "Yushun Zhang",
        "Congliang Chen",
        "Ziniu Li",
        "Tian Ding",
        "Chenwei Wu",
        "Diederik P. Kingma",
        "Yinyu Ye",
        "Zhi-Quan Luo",
        "Ruoyu Sun"
      ],
      "abstract": "We propose Adam-mini, an optimizer that achieves on par or better performance\nthan AdamW with 50% less memory footprint. Adam-mini reduces memory by cutting\ndown the learning rate resources in Adam (i.e., $1/\\sqrt{v}$). By investigating\nthe Hessian structure of neural nets, we find Adam's $v$ might not function at\nits full potential as effectively as we expected. We find that $\\geq$ 99.9% of\nthese learning rates in $v$ could be harmlessly removed if we (1) carefully\npartition the parameters into blocks following our new principle on Hessian\nstructure; (2) assign a single but good learning rate to each parameter block.\nWe then provide one simple way to find good learning rates and propose\nAdam-mini. Empirically, we verify that Adam-mini performs on par or better than\nAdamW on various language models sized from 39M to 13B for pre-training,\nsupervised fine-tuning, and RLHF. The reduced memory footprint of Adam-mini\nalso alleviates communication overheads among GPUs, thereby increasing\nthroughput. For instance, Adam-mini achieves 49.6% higher throughput than AdamW\nwhen pre-training Llama 2-7B on $2\\times$ A800-80GB GPUs, which saves 33%\nwall-clock time for pre-training.",
      "tldr_zh": "本研究提出Adam-mini优化器，与AdamW性能相当或更优，同时将内存占用减少50%。通过分析神经网络的Hessian结构，作者发现Adam中的$v$参数的学习率资源未充分发挥作用，因此将参数分区为块，并为每个块分配一个单一的良好学习率，从而安全移除99.9%以上的冗余学习率。实验验证显示，Adam-mini在从39M到13B参数的各种语言模型上，在预训练、监督微调和RLHF任务中表现出色，并显著提高吞吐量，例如在预训练Llama 2-7B时比AdamW提高49.6%，节省33%的训练时间。",
      "categories": [
        "cs.LG",
        "cs.AI"
      ],
      "primary_category": "cs.LG",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2406.16793v7",
      "published_date": "2024-06-24 16:56:41 UTC",
      "updated_date": "2025-02-24 11:29:08 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-18T23:59:42.933827"
    },
    {
      "arxiv_id": "2406.16784v1",
      "title": "The Progression of Transformers from Language to Vision to MOT: A Literature Review on Multi-Object Tracking with Transformers",
      "title_zh": "翻译失败",
      "authors": [
        "Abhi Kamboj"
      ],
      "abstract": "The transformer neural network architecture allows for autoregressive\nsequence-to-sequence modeling through the use of attention layers. It was\noriginally created with the application of machine translation but has\nrevolutionized natural language processing. Recently, transformers have also\nbeen applied across a wide variety of pattern recognition tasks, particularly\nin computer vision. In this literature review, we describe major advances in\ncomputer vision utilizing transformers. We then focus specifically on\nMulti-Object Tracking (MOT) and discuss how transformers are increasingly\nbecoming competitive in state-of-the-art MOT works, yet still lag behind\ntraditional deep learning methods.",
      "tldr_zh": "这篇文献综述探讨了Transformer神经网络架构从自然语言处理扩展到计算机视觉，再到Multi-Object Tracking (MOT)的演进过程。论文回顾了Transformer在计算机视觉领域的重大进展，包括其在模式识别任务中的广泛应用，并重点分析了Transformer在MOT中的表现。研究发现，虽然Transformer模型正变得越来越有竞争力，但目前仍落后于传统深度学习方法。",
      "categories": [
        "cs.CV",
        "cs.AI"
      ],
      "primary_category": "cs.CV",
      "comment": "This report was written in November 2022, and may not contain more\n  recent works since then",
      "pdf_url": "http://arxiv.org/pdf/2406.16784v1",
      "published_date": "2024-06-24 16:45:28 UTC",
      "updated_date": "2024-06-24 16:45:28 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-18T23:59:54.455899"
    },
    {
      "arxiv_id": "2406.16783v3",
      "title": "M2Lingual: Enhancing Multilingual, Multi-Turn Instruction Alignment in Large Language Models",
      "title_zh": "M2Lingual：增强大型语言模型中的多语言多轮指令对齐",
      "authors": [
        "Rishabh Maheshwary",
        "Vikas Yadav",
        "Hoang Nguyen",
        "Khyati Mahajan",
        "Sathwik Tejaswi Madhusudhan"
      ],
      "abstract": "Instruction finetuning (IFT) is critical for aligning Large Language Models\n(LLMs) to follow instructions. While many effective IFT datasets have been\nintroduced recently, they predominantly focus on high-resource languages like\nEnglish. To better align LLMs across a broad spectrum of languages and tasks,\nwe propose a fully synthetic, novel taxonomy (Evol) guided Multilingual,\nMulti-turn instruction finetuning dataset, called M2Lingual. It is constructed\nby first selecting a diverse set of seed examples and then utilizing the\nproposed Evol taxonomy to convert these seeds into complex and challenging\nmulti-turn instructions. We demonstrate the effectiveness of M2Lingual by\ntraining LLMs of varying sizes and showcasing the enhanced performance across a\ndiverse set of languages. We contribute the 2 step Evol taxonomy with the\nguided generation code: https://github.com/ServiceNow/M2Lingual, as well as the\nfirst fully synthetic, general and task-oriented, multi-turn, multilingual\ndataset built with Evol - M2Lingual:\nhttps://huggingface.co/datasets/ServiceNow-AI/ M2Lingual - containing 182K\ntotal IFT pairs, covering 70 languages and 17+ NLP tasks.",
      "tldr_zh": "该论文提出了 M2Lingual，一种完全合成的多语言、多轮指令微调数据集，旨在提升 Large Language Models (LLMs) 在多种语言和任务上的指令对齐问题。研究引入了 Evol 分类法，通过选择多样种子示例并将其转换为复杂多轮指令，从而构建数据集。M2Lingual 包含 182K 对 IFT 配对，覆盖 70 种语言和 17+ NLP 任务，并在实验中证明了其有效性，使不同规模的 LLMs 在多语言性能上显著提升。该数据集及其代码已开源，提供于 GitHub 和 Hugging Face。",
      "categories": [
        "cs.CL",
        "cs.AI",
        "cs.LG"
      ],
      "primary_category": "cs.CL",
      "comment": "39 pages",
      "pdf_url": "http://arxiv.org/pdf/2406.16783v3",
      "published_date": "2024-06-24 16:45:13 UTC",
      "updated_date": "2025-03-04 07:56:00 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-19T00:00:07.201635"
    },
    {
      "arxiv_id": "2406.16777v1",
      "title": "Blending LLMs into Cascaded Speech Translation: KIT's Offline Speech Translation System for IWSLT 2024",
      "title_zh": "翻译失败",
      "authors": [
        "Sai Koneru",
        "Thai-Binh Nguyen",
        "Ngoc-Quan Pham",
        "Danni Liu",
        "Zhaolin Li",
        "Alexander Waibel",
        "Jan Niehues"
      ],
      "abstract": "Large Language Models (LLMs) are currently under exploration for various\ntasks, including Automatic Speech Recognition (ASR), Machine Translation (MT),\nand even End-to-End Speech Translation (ST). In this paper, we present KIT's\noffline submission in the constrained + LLM track by incorporating recently\nproposed techniques that can be added to any cascaded speech translation.\nSpecifically, we integrate\nMistral-7B\\footnote{mistralai/Mistral-7B-Instruct-v0.1} into our system to\nenhance it in two ways. Firstly, we refine the ASR outputs by utilizing the\nN-best lists generated by our system and fine-tuning the LLM to predict the\ntranscript accurately. Secondly, we refine the MT outputs at the document level\nby fine-tuning the LLM, leveraging both ASR and MT predictions to improve\ntranslation quality. We find that integrating the LLM into the ASR and MT\nsystems results in an absolute improvement of $0.3\\%$ in Word Error Rate and\n$0.65\\%$ in COMET for tst2019 test set. In challenging test sets with\noverlapping speakers and background noise, we find that integrating LLM is not\nbeneficial due to poor ASR performance. Here, we use ASR with chunked long-form\ndecoding to improve context usage that may be unavailable when transcribing\nwith Voice Activity Detection segmentation alone.",
      "tldr_zh": "这篇论文介绍了 KIT 团队在 IWSLT 2024 比赛的 constrained + LLM 轨道中，开发的一种离线语音翻译系统，通过整合 LLMs（Mistral-7B）来提升级联语音翻译性能。方法包括细调 LLM 以改进 ASR 的 N-best 列表预测，从而提高转录准确性，以及在文档级别优化 MT 输出，利用 ASR 和 MT 预测来提升翻译质量。实验结果显示，在 tst2019 测试集上，WERR 改善了 0.3%，COMET 改善了 0.65%；然而，在有重叠说话者和背景噪声的挑战性场景中，整合 LLM 效果不佳，因此采用了 ASR 的分块长形式解码来更好地利用上下文。",
      "categories": [
        "cs.CL",
        "cs.AI"
      ],
      "primary_category": "cs.CL",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2406.16777v1",
      "published_date": "2024-06-24 16:38:17 UTC",
      "updated_date": "2024-06-24 16:38:17 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-19T00:00:22.242590"
    },
    {
      "arxiv_id": "2406.16772v2",
      "title": "OlympicArena Medal Ranks: Who Is the Most Intelligent AI So Far?",
      "title_zh": "OlympicArena 奖牌排名：到目前为止，谁是最智能的 AI？",
      "authors": [
        "Zhen Huang",
        "Zengzhi Wang",
        "Shijie Xia",
        "Pengfei Liu"
      ],
      "abstract": "In this report, we pose the following question: Who is the most intelligent\nAI model to date, as measured by the OlympicArena (an Olympic-level,\nmulti-discipline, multi-modal benchmark for superintelligent AI)? We\nspecifically focus on the most recently released models: Claude-3.5-Sonnet,\nGemini-1.5-Pro, and GPT-4o. For the first time, we propose using an Olympic\nmedal Table approach to rank AI models based on their comprehensive performance\nacross various disciplines. Empirical results reveal: (1) Claude-3.5-Sonnet\nshows highly competitive overall performance over GPT-4o, even surpassing\nGPT-4o on a few subjects (i.e., Physics, Chemistry, and Biology). (2)\nGemini-1.5-Pro and GPT-4V are ranked consecutively just behind GPT-4o and\nClaude-3.5-Sonnet, but with a clear performance gap between them. (3) The\nperformance of AI models from the open-source community significantly lags\nbehind these proprietary models. (4) The performance of these models on this\nbenchmark has been less than satisfactory, indicating that we still have a long\nway to go before achieving superintelligence. We remain committed to\ncontinuously tracking and evaluating the performance of the latest powerful\nmodels on this benchmark (available at\nhttps://github.com/GAIR-NLP/OlympicArena).",
      "tldr_zh": "这篇报告使用OlympicArena基准（一个Olympic级别的多学科多模态评估标准）来比较Claude-3.5-Sonnet、Gemini-1.5-Pro和GPT-4o等AI模型的智能水平，并首次引入奥运奖牌表方法进行综合排名。结果显示，Claude-3.5-Sonnet在整体表现上与GPT-4o高度竞争，甚至在Physics、Chemistry和Biology等领域超过后者。Gemini-1.5-Pro和GPT-4V紧随其后，但两者间存在明显差距，而开源社区的AI模型表现远落后于这些专有模型。该研究强调，当前AI在基准上的表现仍不理想，距离超级智能还有很长的路，团队将持续跟踪最新模型的性能。",
      "categories": [
        "cs.CL",
        "cs.AI"
      ],
      "primary_category": "cs.CL",
      "comment": "10 pages",
      "pdf_url": "http://arxiv.org/pdf/2406.16772v2",
      "published_date": "2024-06-24 16:31:12 UTC",
      "updated_date": "2024-06-26 15:00:04 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-19T00:00:32.684641"
    },
    {
      "arxiv_id": "2407.12804v2",
      "title": "Modulating Language Model Experiences through Frictions",
      "title_zh": "通过摩擦调节语言模型体验",
      "authors": [
        "Katherine M. Collins",
        "Valerie Chen",
        "Ilia Sucholutsky",
        "Hannah Rose Kirk",
        "Malak Sadek",
        "Holli Sargeant",
        "Ameet Talwalkar",
        "Adrian Weller",
        "Umang Bhatt"
      ],
      "abstract": "Language models are transforming the ways that their users engage with the\nworld. Despite impressive capabilities, over-consumption of language model\noutputs risks propagating unchecked errors in the short-term and damaging human\ncapabilities for critical thinking in the long-term. How can we develop\nscaffolding around language models to curate more appropriate use? We propose\nselective frictions for language model experiences, inspired by behavioral\nscience interventions, to dampen misuse. Frictions involve small modifications\nto a user's experience, e.g., the addition of a button impeding model access\nand reminding a user of their expertise relative to the model. Through a user\nstudy with real humans, we observe shifts in user behavior from the imposition\nof a friction over LLMs in the context of a multi-topic question-answering task\nas a representative task that people may use LLMs for, e.g., in education and\ninformation retrieval. We find that frictions modulate over-reliance by driving\ndown users' click rates while minimally affecting accuracy for those topics.\nYet, frictions may have unintended effects. We find marked differences in\nusers' click behaviors even on topics where frictions were not provisioned. Our\ncontributions motivate further study of human-AI behavioral interaction to\ninform more effective and appropriate LLM use.",
      "tldr_zh": "这篇论文探讨了如何通过“frictions”（行为科学启发的微小干预，如添加按钮提醒用户自身专业知识）来调节语言模型的使用，从而减少过度依赖和潜在错误传播。研究者针对多主题问答任务（如教育和信息检索）进行用户研究，发现frictions能降低用户的点击率，同时基本不影响回答准确性。论文还观察到frictions可能产生意外效果，例如影响未设置frictions的主题上的用户行为。这些发现为优化人类-AI互动提供了见解，推动更适当的语言模型（LLMs）应用。",
      "categories": [
        "cs.HC",
        "cs.AI",
        "cs.LG"
      ],
      "primary_category": "cs.HC",
      "comment": "NeurIPS Workshop on Behavioral ML; non-archival",
      "pdf_url": "http://arxiv.org/pdf/2407.12804v2",
      "published_date": "2024-06-24 16:31:11 UTC",
      "updated_date": "2024-11-18 15:41:24 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-19T00:00:53.416087"
    },
    {
      "arxiv_id": "2406.16768v1",
      "title": "WARP: On the Benefits of Weight Averaged Rewarded Policies",
      "title_zh": "翻译失败",
      "authors": [
        "Alexandre Ramé",
        "Johan Ferret",
        "Nino Vieillard",
        "Robert Dadashi",
        "Léonard Hussenot",
        "Pierre-Louis Cedoz",
        "Pier Giuseppe Sessa",
        "Sertan Girgin",
        "Arthur Douillard",
        "Olivier Bachem"
      ],
      "abstract": "Reinforcement learning from human feedback (RLHF) aligns large language\nmodels (LLMs) by encouraging their generations to have high rewards, using a\nreward model trained on human preferences. To prevent the forgetting of\npre-trained knowledge, RLHF usually incorporates a KL regularization; this\nforces the policy to remain close to its supervised fine-tuned initialization,\nthough it hinders the reward optimization. To tackle the trade-off between KL\nand reward, in this paper we introduce a novel alignment strategy named Weight\nAveraged Rewarded Policies (WARP). WARP merges policies in the weight space at\nthree distinct stages. First, it uses the exponential moving average of the\npolicy as a dynamic anchor in the KL regularization. Second, it applies\nspherical interpolation to merge independently fine-tuned policies into a new\nenhanced one. Third, it linearly interpolates between this merged model and the\ninitialization, to recover features from pre-training. This procedure is then\napplied iteratively, with each iteration's final model used as an advanced\ninitialization for the next, progressively refining the KL-reward Pareto front,\nachieving superior rewards at fixed KL. Experiments with GEMMA policies\nvalidate that WARP improves their quality and alignment, outperforming other\nopen-source LLMs.",
      "tldr_zh": "本研究针对强化学习从人类反馈（RLHF）中对大型语言模型（LLMs）的对齐问题，提出了一种名为 WARP 的新策略，以平衡 KL 正则化和奖励优化。WARP 在权重空间合并策略，包括使用指数移动平均作为动态锚点、球形插值融合独立微调策略，以及线性插值恢复预训练特征，并通过迭代过程逐步优化 KL-奖励 Pareto 前沿。实验结果显示，在 GEMMA 策略上，WARP 显著提升了模型的质量和对齐性能，超过了其他开源 LLMs。",
      "categories": [
        "cs.LG",
        "cs.AI"
      ],
      "primary_category": "cs.LG",
      "comment": "11 main pages (34 pages with Appendix)",
      "pdf_url": "http://arxiv.org/pdf/2406.16768v1",
      "published_date": "2024-06-24 16:24:34 UTC",
      "updated_date": "2024-06-24 16:24:34 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-19T00:00:55.695387"
    },
    {
      "arxiv_id": "2406.16756v1",
      "title": "Addressing Polarization and Unfairness in Performative Prediction",
      "title_zh": "翻译失败",
      "authors": [
        "Kun Jin",
        "Tian Xie",
        "Yang Liu",
        "Xueru Zhang"
      ],
      "abstract": "When machine learning (ML) models are used in applications that involve\nhumans (e.g., online recommendation, school admission, hiring, lending), the\nmodel itself may trigger changes in the distribution of targeted data it aims\nto predict. Performative prediction (PP) is a framework that explicitly\nconsiders such model-dependent distribution shifts when learning ML models.\nWhile significant efforts have been devoted to finding performative stable (PS)\nsolutions in PP for system robustness, their societal implications are less\nexplored and it is unclear whether PS solutions are aligned with social norms\nsuch as fairness. In this paper, we set out to examine the fairness property of\nPS solutions in performative prediction. We first show that PS solutions can\nincur severe polarization effects and group-wise loss disparity. Although\nexisting fairness mechanisms commonly used in literature can help mitigate\nunfairness, they may fail and disrupt the stability under model-dependent\ndistribution shifts. We thus propose novel fairness intervention mechanisms\nthat can simultaneously achieve both stability and fairness in PP settings.\nBoth theoretical analysis and experiments are provided to validate the proposed\nmethod.",
      "tldr_zh": "这篇论文探讨了 Performative Prediction (PP) 框架中存在的极化和不公平问题，指出当机器学习模型影响数据分布时，Performative Stable (PS) 解决方案可能导致严重的群体损失差异和偏见放大。研究发现，传统公平机制虽能缓解不公平，但可能在模型依赖分布偏移下失效并破坏稳定性。为解决这一挑战，作者提出新型公平干预机制，能够同时实现 PP 设置中的稳定性与公平性。该方法通过理论分析和实验验证，证明了其有效性。",
      "categories": [
        "cs.LG",
        "cs.AI",
        "cs.CY"
      ],
      "primary_category": "cs.LG",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2406.16756v1",
      "published_date": "2024-06-24 16:03:57 UTC",
      "updated_date": "2024-06-24 16:03:57 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-19T00:01:06.909729"
    },
    {
      "arxiv_id": "2406.16746v4",
      "title": "The Responsible Foundation Model Development Cheatsheet: A Review of Tools & Resources",
      "title_zh": "翻译失败",
      "authors": [
        "Shayne Longpre",
        "Stella Biderman",
        "Alon Albalak",
        "Hailey Schoelkopf",
        "Daniel McDuff",
        "Sayash Kapoor",
        "Kevin Klyman",
        "Kyle Lo",
        "Gabriel Ilharco",
        "Nay San",
        "Maribeth Rauh",
        "Aviya Skowron",
        "Bertie Vidgen",
        "Laura Weidinger",
        "Arvind Narayanan",
        "Victor Sanh",
        "David Adelani",
        "Percy Liang",
        "Rishi Bommasani",
        "Peter Henderson",
        "Sasha Luccioni",
        "Yacine Jernite",
        "Luca Soldaini"
      ],
      "abstract": "Foundation model development attracts a rapidly expanding body of\ncontributors, scientists, and applications. To help shape responsible\ndevelopment practices, we introduce the Foundation Model Development\nCheatsheet: a growing collection of 250+ tools and resources spanning text,\nvision, and speech modalities. We draw on a large body of prior work to survey\nresources (e.g. software, documentation, frameworks, guides, and practical\ntools) that support informed data selection, processing, and understanding,\nprecise and limitation-aware artifact documentation, efficient model training,\nadvance awareness of the environmental impact from training, careful model\nevaluation of capabilities, risks, and claims, as well as responsible model\nrelease, licensing and deployment practices. We hope this curated collection of\nresources helps guide more responsible development. The process of curating\nthis list, enabled us to review the AI development ecosystem, revealing what\ntools are critically missing, misused, or over-used in existing practices. We\nfind that (i) tools for data sourcing, model evaluation, and monitoring are\ncritically under-serving ethical and real-world needs, (ii) evaluations for\nmodel safety, capabilities, and environmental impact all lack reproducibility\nand transparency, (iii) text and particularly English-centric analyses continue\nto dominate over multilingual and multi-modal analyses, and (iv) evaluation of\nsystems, rather than just models, is needed so that capabilities and impact are\nassessed in context.",
      "tldr_zh": "这篇论文介绍了“Foundation Model Development Cheatsheet”，这是一个汇集了250+工具和资源的集合，旨在指导负责任的基础模型开发，涵盖文本、视觉和语音模态。Cheatsheet包括资源用于数据选择、处理、文档、模型训练、环境影响评估、风险评估以及部署实践，帮助开发者提升透明度和伦理意识。通过审视AI开发生态系统，论文发现现有工具在数据来源、模型评估和监控方面严重不足，评估缺乏可重复性，分析偏向英语且多模态支持薄弱，并强调需要评估完整系统而非仅模型。总的来说，这为负责任的AI开发提供了实用指南，并突出了关键改进领域。",
      "categories": [
        "cs.LG",
        "cs.AI",
        "cs.CL"
      ],
      "primary_category": "cs.LG",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2406.16746v4",
      "published_date": "2024-06-24 15:55:49 UTC",
      "updated_date": "2025-02-17 00:31:25 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-19T00:01:19.708180"
    },
    {
      "arxiv_id": "2406.16745v2",
      "title": "Bandits with Preference Feedback: A Stackelberg Game Perspective",
      "title_zh": "带有偏好反馈的多臂老虎机：Stackelberg 游戏视角",
      "authors": [
        "Barna Pásztor",
        "Parnian Kassraie",
        "Andreas Krause"
      ],
      "abstract": "Bandits with preference feedback present a powerful tool for optimizing\nunknown target functions when only pairwise comparisons are allowed instead of\ndirect value queries. This model allows for incorporating human feedback into\nonline inference and optimization and has been employed in systems for\nfine-tuning large language models. The problem is well understood in simplified\nsettings with linear target functions or over finite small domains that limit\npractical interest. Taking the next step, we consider infinite domains and\nnonlinear (kernelized) rewards. In this setting, selecting a pair of actions is\nquite challenging and requires balancing exploration and exploitation at two\nlevels: within the pair, and along the iterations of the algorithm. We propose\nMAXMINLCB, which emulates this trade-off as a zero-sum Stackelberg game, and\nchooses action pairs that are informative and yield favorable rewards.\nMAXMINLCB consistently outperforms existing algorithms and satisfies an\nanytime-valid rate-optimal regret guarantee. This is due to our novel\npreference-based confidence sequences for kernelized logistic estimators.",
      "tldr_zh": "该研究探讨了基于偏好反馈的 Bandits 模型，用于优化未知目标函数，仅通过成对比较而非直接查询。作者扩展了该模型至无限领域和非线性（kernelized）奖励，提出 MAXMINLCB 算法，将问题建模为零和 Stackelberg 游戏，以平衡成对内部的探索与利用以及算法迭代。实验结果显示，MAXMINLCB 优于现有算法，并提供 anytime-valid 和 rate-optimal 的 regret guarantee，这得益于新型的基于偏好的置信序列用于 kernelized logistic 估计器。",
      "categories": [
        "cs.LG",
        "cs.AI",
        "cs.GT",
        "stat.ML"
      ],
      "primary_category": "cs.LG",
      "comment": "In Proceedings of the 38th Conference on Neural Information\n  Processing Systems (NeurIPS), 30 pages, 8 figures",
      "pdf_url": "http://arxiv.org/pdf/2406.16745v2",
      "published_date": "2024-06-24 15:53:11 UTC",
      "updated_date": "2024-10-30 17:10:52 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-19T00:01:32.300849"
    },
    {
      "arxiv_id": "2406.16741v2",
      "title": "Extracting thin film structures of energy materials using transformers",
      "title_zh": "翻译失败",
      "authors": [
        "Chen Zhang",
        "Valerie A. Niemann",
        "Peter Benedek",
        "Thomas F. Jaramillo",
        "Mathieu Doucet"
      ],
      "abstract": "Neutron-Transformer Reflectometry and Advanced Computation Engine (N-TRACE ),\na neural network model using transformer architecture, is introduced for\nneutron reflectometry data analysis. It offers fast, accurate initial parameter\nestimations and efficient refinements, improving efficiency and precision for\nreal-time data analysis of lithium-mediated nitrogen reduction for\nelectrochemical ammonia synthesis, with relevance to other chemical\ntransformations and batteries. Despite limitations in generalizing across\nsystems, it shows promises for the use of transformers as the basis for models\nthat could replace trial-and-error approaches to modeling reflectometry data.",
      "tldr_zh": "本研究引入了 N-TRACE，一种基于 Transformer 架构的神经网络模型，用于中子反射测量数据分析。它能够提供快速准确的初始参数估计和高效优化，提高了效率和精度，尤其适用于锂介导的氮还原电化学氨合成、其他化学转化和电池的实时分析。尽管 N-TRACE 在跨系统泛化方面存在局限性，但它展示了 Transformer 模型作为替代传统试错方法的潜力，为提取能量材料薄膜结构提供了新途径。",
      "categories": [
        "physics.comp-ph",
        "cs.AI"
      ],
      "primary_category": "physics.comp-ph",
      "comment": "11 pages, 7 figures",
      "pdf_url": "http://arxiv.org/pdf/2406.16741v2",
      "published_date": "2024-06-24 15:48:19 UTC",
      "updated_date": "2024-10-30 17:44:53 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-19T00:01:54.162922"
    },
    {
      "arxiv_id": "2406.16738v2",
      "title": "Inducing Group Fairness in Prompt-Based Language Model Decisions",
      "title_zh": "在基于提示的语言模型决策中实现",
      "authors": [
        "James Atwood",
        "Nino Scherrer",
        "Preethi Lahoti",
        "Ananth Balashankar",
        "Flavien Prost",
        "Ahmad Beirami"
      ],
      "abstract": "Classifiers are used throughout industry to enforce policies, ranging from\nthe detection of toxic content to age-appropriate content filtering. While\nthese classifiers serve important functions, it is also essential that they are\nbuilt in ways that minimize unfair biases for users.\n  One such fairness consideration is called group fairness, which desires that\ndifferent sub-population of users receive equal treatment. This is a\nwell-studied problem in the context of 'classical' classifiers. However, the\nemergence of prompt-based language model (LM) decision making has created new\nopportunities to solve text-based classification tasks, and the fairness\nproperties of these new classifiers are not yet well understood. Further, the\n`remediation toolkit' is incomplete for LM-based decision makers and little is\nunderstood about how to improve decision maker group fairness while maintaining\nclassifier performance.\n  This work sets out to add more tools to that toolbox. We introduce\nadaptations of existing effective approaches from the classical classifier\nfairness to the prompt-based classifier space. We also devise simple methods\nthat take advantage of the new structure of prompt-based decision makers and\noperate at the prompt level. We compare these approaches empirically on real\ndata. Our results suggest that adaptations of approaches that are effective for\nclassical classifiers remain effective in the LM-based classifier environment.\nHowever, there is room for further exploration of prompt-based remediation\nmethods (and other remediation methods that take advantage of LM structure).",
      "tldr_zh": "该论文探讨了在基于提示的语言模型（prompt-based language model）决策中实现群组公平性（group fairness）的挑战，旨在确保不同用户子群体在分类任务（如检测有毒内容或内容过滤）中获得平等对待。研究者引入了从传统分类器公平性方法（如调整决策边界）的适应版本，并设计了新颖的提示级别方法，利用语言模型的结构来改进公平性，同时维持分类器性能。通过实证实验，该方法在真实数据上显示出有效性，与传统方法类似，但提示-based 修复方法仍有进一步探索的空间。",
      "categories": [
        "cs.LG",
        "cs.AI",
        "cs.CY"
      ],
      "primary_category": "cs.LG",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2406.16738v2",
      "published_date": "2024-06-24 15:45:20 UTC",
      "updated_date": "2024-12-02 18:27:02 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-19T00:01:59.565822"
    },
    {
      "arxiv_id": "2406.16730v1",
      "title": "Convolutional neural network for Lyman break galaxies classification and redshift regression in DESI (Dark Energy Spectroscopic Instrument)",
      "title_zh": "DESI（Dark Energy Spectroscopic Instrument）中用于 Lyman break galaxies 分类和红移回归的卷积神经网络",
      "authors": [
        "Julien Taran"
      ],
      "abstract": "DESI is a groundbreaking international project to observe more than 40\nmillion quasars and galaxies over a 5-year period to create a 3D map of the\nsky. This map will enable us to probe multiple aspects of cosmology, from dark\nenergy to neutrino mass. We are focusing here on one type of object observed by\nDESI, the Lyman Break Galaxies (LBGs). The aim is to use their spectra to\ndetermine whether they are indeed LBGs, and if so, to determine their distance\nfrom the Earth using a phenomenon called redshift. This will enable us to place\nthese galaxies on the DESI 3D map.\n  The aim is therefore to develop a convolutional neural network (CNN) inspired\nby QuasarNET (See arXiv:1808.09955), performing simultaneously a classification\n(LBG type or not) and a regression task (determine the redshift of the LBGs).\nInitially, data augmentation techniques such as shifting the spectra in\nwavelengths, adding noise to the spectra, or adding synthetic spectra were used\nto increase the model training dataset from 3,019 data to over 66,000. In a\nsecond phase, modifications to the QuasarNET architecture, notably through\ntransfer learning and hyperparameter tuning with Bayesian optimization, boosted\nmodel performance.\n  Gains of up to 26% were achieved on the Purity/Efficiency curve, which is\nused to evaluate model performance, particularly in areas with interesting\nredshifts, at low (around 2) and high (around 4) redshifts. The best model\nobtained an average score of 94%, compared with 75% for the initial model.",
      "tldr_zh": "这篇论文开发了一个基于卷积神经网络 (CNN) 的模型，用于在 DESI 项目中对 Lyman Break Galaxies (LBGs) 进行分类（判断是否为 LBGs）和红移回归（确定距离）。模型灵感来源于 QuasarNET，通过数据增强技术（如波长偏移、添加噪声和合成谱线）将训练数据集从 3,019 扩展到超过 66,000，并通过迁移学习和 Bayesian optimization 调优超参数。结果显示，模型在 Purity/Efficiency 曲线上的性能提升高达 26%，特别是在红移值约 2 和 4 的关键区域，最佳模型的平均分数达到 94%，比初始模型提高了 19%。这为 DESI 的天空 3D 映射提供了更准确的 LBGs 识别和定位方法。",
      "categories": [
        "astro-ph.CO",
        "cs.AI"
      ],
      "primary_category": "astro-ph.CO",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2406.16730v1",
      "published_date": "2024-06-24 15:35:51 UTC",
      "updated_date": "2024-06-24 15:35:51 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-19T00:02:10.494089"
    },
    {
      "arxiv_id": "2406.16728v1",
      "title": "CausalMMM: Learning Causal Structure for Marketing Mix Modeling",
      "title_zh": "CausalMMM：学习因果结构用于营销组合建",
      "authors": [
        "Chang Gong",
        "Di Yao",
        "Lei Zhang",
        "Sheng Chen",
        "Wenbin Li",
        "Yueyang Su",
        "Jingping Bi"
      ],
      "abstract": "In online advertising, marketing mix modeling (MMM) is employed to predict\nthe gross merchandise volume (GMV) of brand shops and help decision-makers to\nadjust the budget allocation of various advertising channels. Traditional MMM\nmethods leveraging regression techniques can fail in handling the complexity of\nmarketing. Although some efforts try to encode the causal structures for better\nprediction, they have the strict restriction that causal structures are\nprior-known and unchangeable. In this paper, we define a new causal MMM problem\nthat automatically discovers the interpretable causal structures from data and\nyields better GMV predictions. To achieve causal MMM, two essential challenges\nshould be addressed: (1) Causal Heterogeneity. The causal structures of\ndifferent kinds of shops vary a lot. (2) Marketing Response Patterns. Various\nmarketing response patterns i.e., carryover effect and shape effect, have been\nvalidated in practice. We argue that causal MMM needs dynamically discover\nspecific causal structures for different shops and the predictions should\ncomply with the prior known marketing response patterns. Thus, we propose\nCausalMMM that integrates Granger causality in a variational inference\nframework to measure the causal relationships between different channels and\npredict the GMV with the regularization of both temporal and saturation\nmarketing response patterns. Extensive experiments show that CausalMMM can not\nonly achieve superior performance of causal structure learning on synthetic\ndatasets with improvements of 5.7%\\sim 7.1%, but also enhance the GMV\nprediction results on a representative E-commerce platform.",
      "tldr_zh": "本研究提出CausalMMM方法，用于在线广告领域，通过从数据中自动学习因果结构来提升营销混淆建模(MMM)的准确性，从而更好地预测品牌店铺的GMV（毛商品额）和优化广告渠道预算。CausalMMM整合Granger causality到变分推理框架中，解决因果异质性（不同店铺的因果结构差异）和营销响应模式（如carryover effect和shape effect）的问题，并通过时间和饱和响应模式的正则化确保预测的可靠性。实验结果显示，该方法在合成数据集上提升因果结构学习性能5.7%~7.1%，并在实际电商平台上显著改善GMV预测效果。",
      "categories": [
        "cs.AI"
      ],
      "primary_category": "cs.AI",
      "comment": "WSDM 2024, full version",
      "pdf_url": "http://arxiv.org/pdf/2406.16728v1",
      "published_date": "2024-06-24 15:33:47 UTC",
      "updated_date": "2024-06-24 15:33:47 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-19T00:02:21.165257"
    },
    {
      "arxiv_id": "2407.16905v1",
      "title": "Assessing the role of clinical summarization and patient chart review within communications, medical management, and diagnostics",
      "title_zh": "评估临床总结和患者病历审查在沟通、医疗管理和诊断中的作用",
      "authors": [
        "Chanseo Lee",
        "Kimon-Aristotelis Vogt",
        "Sonu Kumar"
      ],
      "abstract": "Effective summarization of unstructured patient data in electronic health\nrecords (EHRs) is crucial for accurate diagnosis and efficient patient care,\nyet clinicians often struggle with information overload and time constraints.\nThis review dives into recent literature and case studies on both the\nsignificant impacts and outstanding issues of patient chart review on\ncommunications, diagnostics, and management. It also discusses recent efforts\nto integrate artificial intelligence (AI) into clinical summarization tasks,\nand its transformative impact on the clinician's potential, including but not\nlimited to reductions of administrative burden and improved patient-centered\ncare.",
      "tldr_zh": "本研究评估了临床总结和患者病历回顾在沟通、医疗管理和诊断中的作用，强调了电子健康记录(EHRs)中非结构化患者数据的有效总结对准确诊断和高效护理的重要性，但临床医生常因信息过载和时间限制而面临挑战。通过回顾最近文献和案例研究，该文探讨了这些过程对临床实践的积极影响和未解决问题。论文还讨论了将人工智能(AI)整合到临床总结中的努力及其变革性益处，包括减轻行政负担和提升以患者为中心的护理质量。",
      "categories": [
        "cs.CY",
        "cs.AI",
        "cs.HC"
      ],
      "primary_category": "cs.CY",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2407.16905v1",
      "published_date": "2024-06-24 15:31:24 UTC",
      "updated_date": "2024-06-24 15:31:24 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-19T00:02:31.840938"
    },
    {
      "arxiv_id": "2406.16714v2",
      "title": "AutoDetect: Towards a Unified Framework for Automated Weakness Detection in Large Language Models",
      "title_zh": "Auto",
      "authors": [
        "Jiale Cheng",
        "Yida Lu",
        "Xiaotao Gu",
        "Pei Ke",
        "Xiao Liu",
        "Yuxiao Dong",
        "Hongning Wang",
        "Jie Tang",
        "Minlie Huang"
      ],
      "abstract": "Although Large Language Models (LLMs) are becoming increasingly powerful,\nthey still exhibit significant but subtle weaknesses, such as mistakes in\ninstruction-following or coding tasks. As these unexpected errors could lead to\nsevere consequences in practical deployments, it is crucial to investigate the\nlimitations within LLMs systematically. Traditional benchmarking approaches\ncannot thoroughly pinpoint specific model deficiencies, while manual\ninspections are costly and not scalable. In this paper, we introduce a unified\nframework, AutoDetect, to automatically expose weaknesses in LLMs across\nvarious tasks. Inspired by the educational assessment process that measures\nstudents' learning outcomes, AutoDetect consists of three LLM-powered agents:\nExaminer, Questioner, and Assessor. The collaboration among these three agents\nis designed to realize comprehensive and in-depth weakness identification. Our\nframework demonstrates significant success in uncovering flaws, with an\nidentification success rate exceeding 30% in prominent models such as ChatGPT\nand Claude. More importantly, these identified weaknesses can guide specific\nmodel improvements, proving more effective than untargeted data augmentation\nmethods like Self-Instruct. Our approach has led to substantial enhancements in\npopular LLMs, including the Llama series and Mistral-7b, boosting their\nperformance by over 10% across several benchmarks. Code and data are publicly\navailable at https://github.com/thu-coai/AutoDetect.",
      "tldr_zh": "本文提出 AutoDetect 框架，这是一个统一的自动化系统，用于检测 Large Language Models (LLMs) 中的弱点，如指令遵循或编码任务的错误问题。框架由三个 LLM 驱动的代理组成：Examiner、Questioner 和 Assessor，它们通过模拟教育评估过程协作进行全面弱点识别，成功率在 ChatGPT 和 Claude 等模型上超过 30%。实验结果表明，利用这些识别出的弱点进行针对性改进，比无针对性的数据增强方法如 Self-Instruct 更有效，导致 Llama 系列和 Mistral-7b 在多个基准上的性能提升超过 10%。代码和数据已在 GitHub 上公开。",
      "categories": [
        "cs.CL",
        "cs.AI",
        "cs.LG"
      ],
      "primary_category": "cs.CL",
      "comment": "EMNLP 2024 findings",
      "pdf_url": "http://arxiv.org/pdf/2406.16714v2",
      "published_date": "2024-06-24 15:16:45 UTC",
      "updated_date": "2024-12-10 13:57:46 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-19T00:02:45.165859"
    },
    {
      "arxiv_id": "2406.16707v1",
      "title": "Probabilistic Subgoal Representations for Hierarchical Reinforcement learning",
      "title_zh": "概率子目标表示用于分层强化学习",
      "authors": [
        "Vivienne Huiling Wang",
        "Tinghuai Wang",
        "Wenyan Yang",
        "Joni-Kristian Kämäräinen",
        "Joni Pajarinen"
      ],
      "abstract": "In goal-conditioned hierarchical reinforcement learning (HRL), a high-level\npolicy specifies a subgoal for the low-level policy to reach. Effective HRL\nhinges on a suitable subgoal represen tation function, abstracting state space\ninto latent subgoal space and inducing varied low-level behaviors. Existing\nmethods adopt a subgoal representation that provides a deterministic mapping\nfrom state space to latent subgoal space. Instead, this paper utilizes Gaussian\nProcesses (GPs) for the first probabilistic subgoal representation. Our method\nemploys a GP prior on the latent subgoal space to learn a posterior\ndistribution over the subgoal representation functions while exploiting the\nlong-range correlation in the state space through learnable kernels. This\nenables an adaptive memory that integrates long-range subgoal information from\nprior planning steps allowing to cope with stochastic uncertainties.\nFurthermore, we propose a novel learning objective to facilitate the\nsimultaneous learning of probabilistic subgoal representations and policies\nwithin a unified framework. In experiments, our approach outperforms\nstate-of-the-art baselines in standard benchmarks but also in environments with\nstochastic elements and under diverse reward conditions. Additionally, our\nmodel shows promising capabilities in transferring low-level policies across\ndifferent tasks.",
      "tldr_zh": "本文提出了一种基于高斯过程 (Gaussian Processes, GPs) 的概率子目标表示方法，用于目标条件分层强化学习 (HRL)，以改进高层策略对低层策略的子目标指定。不同于现有确定性方法，该框架利用 GP 先验学习子目标空间的后验分布，并通过可学习内核捕捉状态空间的长程相关性，实现适应性记忆来应对随机不确定性，同时引入一个统一学习目标来优化子目标表示和策略。实验结果表明，该方法在标准基准环境中超越最先进基线，并在随机元素和多样奖励条件下表现出色，并显示出低层策略在不同任务间的有效转移潜力。",
      "categories": [
        "cs.LG",
        "cs.AI"
      ],
      "primary_category": "cs.LG",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2406.16707v1",
      "published_date": "2024-06-24 15:09:22 UTC",
      "updated_date": "2024-06-24 15:09:22 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-19T00:02:56.578748"
    },
    {
      "arxiv_id": "2406.16697v1",
      "title": "Expected Runtime Comparisons Between Breadth-First Search and Constant-Depth Restarting Random Walks",
      "title_zh": "广度优先搜索与固定深度重启随机游走之间的期望运行时间比较",
      "authors": [
        "Daniel Platnick",
        "Richard Anthony Valenzano"
      ],
      "abstract": "When greedy search algorithms encounter a local minima or plateau, the search\ntypically devolves into a breadth-first search (BrFS), or a local search\ntechnique is used in an attempt to find a way out. In this work, we formally\nanalyze the performance of BrFS and constant-depth restarting random walks\n(RRW) -- two methods often used for finding exits to a plateau/local minima --\nto better understand when each is best suited. In particular, we formally\nderive the expected runtime for BrFS in the case of a uniformly distributed set\nof goals at a given goal depth. We then prove RRW will be faster than BrFS on\ntrees if there are enough goals at that goal depth. We refer to this threshold\nas the crossover point. Our bound shows that the crossover point grows linearly\nwith the branching factor of the tree, the goal depth, and the error in the\nrandom walk depth, while the size of the tree grows exponentially in branching\nfactor and goal depth. Finally, we discuss the practical implications and\napplicability of this bound.",
      "tldr_zh": "该研究比较了广度优先搜索 (BrFS) 和固定深度重启随机游走 (RRW) 在搜索局部最小值或平台时的预期运行时间，通过正式推导 BrFS 在目标均匀分布树结构中的运行时间。论文证明了当目标数量超过特定阈值（即 crossover point）时，RRW 会比 BrFS 更快，且该阈值随树的分支因子、目标深度和随机游走深度错误线性增长，而树的大小则呈指数增长。最终，讨论了这一边界在实际应用中的含义，帮助选择最适合的搜索策略。",
      "categories": [
        "cs.AI"
      ],
      "primary_category": "cs.AI",
      "comment": "ICAPS 2024 Heuristics and Search for Domain-Independent Planning\n  Workshop, 5 pages, 1 figure",
      "pdf_url": "http://arxiv.org/pdf/2406.16697v1",
      "published_date": "2024-06-24 15:00:59 UTC",
      "updated_date": "2024-06-24 15:00:59 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-19T00:03:08.404280"
    },
    {
      "arxiv_id": "2406.16696v2",
      "title": "Public Constitutional AI",
      "title_zh": "翻译失败",
      "authors": [
        "Gilad Abiri"
      ],
      "abstract": "We are increasingly subjected to the power of AI authorities. As AI decisions\nbecome inescapable, entering domains such as healthcare, education, and law, we\nmust confront a vital question: how can we ensure AI systems have the\nlegitimacy necessary for effective governance? This essay argues that to secure\nAI legitimacy, we need methods that engage the public in designing and\nconstraining AI systems, ensuring these technologies reflect the community's\nshared values. Constitutional AI, proposed by Anthropic, represents a step\ntowards this goal, offering a model for democratic control of AI. However,\nwhile Constitutional AI's commitment to hardcoding explicit principles into AI\nmodels enhances transparency and accountability, it falls short in two crucial\naspects: addressing the opacity of individual AI decisions and fostering\ngenuine democratic legitimacy. To overcome these limitations, this essay\nproposes \"Public Constitutional AI.\" This approach envisions a participatory\nprocess where diverse stakeholders, including ordinary citizens, deliberate on\nthe principles guiding AI development. The resulting \"AI Constitution\" would\ncarry the legitimacy of popular authorship, grounding AI governance in the\npublic will. Furthermore, the essay proposes \"AI Courts\" to develop \"AI case\nlaw,\" providing concrete examples for operationalizing constitutional\nprinciples in AI training. This evolving combination of constitutional\nprinciples and case law aims to make AI governance more responsive to public\nvalues. By grounding AI governance in deliberative democratic processes, Public\nConstitutional AI offers a path to imbue automated authorities with genuine\ndemocratic legitimacy, addressing the unique challenges posed by increasingly\npowerful AI systems while ensuring their alignment with the public interest.",
      "tldr_zh": "这篇论文讨论了确保AI系统合法性的问题，强调在AI决策日益影响医疗、教育和法律等领域时，需要通过公众参与来设计和约束AI系统，以反映社区共享价值观。论文批评Anthropic的Constitutional AI虽提升了透明度和问责性，但未能解决AI决策的不透明性和缺乏真正民主合法性。为此，作者提出“Public Constitutional AI”方法，该框架涉及多样利益相关者（如普通公民）参与制定“AI Constitution”，并建立“AI Courts”来发展“AI case law”，从而使AI治理更具响应性和适应性。最终，这种基于审议民主过程的AI治理方式旨在赋予AI系统真正的民主合法性，确保其与公众利益一致。",
      "categories": [
        "cs.CY",
        "cs.AI"
      ],
      "primary_category": "cs.CY",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2406.16696v2",
      "published_date": "2024-06-24 15:00:01 UTC",
      "updated_date": "2025-05-14 17:21:19 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-19T00:03:21.536045"
    },
    {
      "arxiv_id": "2407.09525v1",
      "title": "A Deep Learning Framework for Three Dimensional Shape Reconstruction from Phaseless Acoustic Scattering Far-field Data",
      "title_zh": "一种深度学习框架，用于从无相位声学散射远场数据重建三维形状",
      "authors": [
        "Doga Dikbayir",
        "Abdel Alsnayyan",
        "Vishnu Naresh Boddeti",
        "Balasubramaniam Shanker",
        "Hasan Metin Aktulga"
      ],
      "abstract": "The inverse scattering problem is of critical importance in a number of\nfields, including medical imaging, sonar, sensing, non-destructive evaluation,\nand several others. The problem of interest can vary from detecting the shape\nto the constitutive properties of the obstacle. The challenge in both is that\nthis problem is ill-posed, more so when there is limited information. That\nsaid, significant effort has been expended over the years in developing\nsolutions to this problem. Here, we use a different approach, one that is\nfounded on data. Specifically, we develop a deep learning framework for shape\nreconstruction using limited information with single incident wave, single\nfrequency, and phase-less far-field data. This is done by (a) using a compact\nprobabilistic shape latent space, learned by a 3D variational auto-encoder, and\n(b) a convolutional neural network trained to map the acoustic scattering\ninformation to this shape representation. The proposed framework is evaluated\non a synthetic 3D particle dataset, as well as ShapeNet, a popular 3D shape\nrecognition dataset. As demonstrated via a number of results, the proposed\nmethod is able to produce accurate reconstructions for large batches of complex\nscatterer shapes (such as airplanes and automobiles), despite the significant\nvariation present within the data.",
      "tldr_zh": "本文提出一个深度学习框架，用于从无相位声学散射远场数据重建三维形状，针对反散射问题（inverse scattering problem）在信息有限情况下的非良态（ill-posed）挑战。框架结合了 3D 变分自动编码器（3D variational auto-encoder）来学习紧凑的概率形状潜在空间，以及卷积神经网络（convolutional neural network）来映射声学散射信息到该形状表示。在合成 3D 粒子数据集和 ShapeNet 上进行评估，结果显示该方法能准确重建复杂散射体形状，如飞机和汽车，尽管数据存在显著变化。",
      "categories": [
        "cs.CV",
        "cs.AI",
        "cs.LG",
        "I.2.1; J.2"
      ],
      "primary_category": "cs.CV",
      "comment": "13 pages, 14 Figures",
      "pdf_url": "http://arxiv.org/pdf/2407.09525v1",
      "published_date": "2024-06-24 14:58:49 UTC",
      "updated_date": "2024-06-24 14:58:49 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-19T00:03:34.259759"
    },
    {
      "arxiv_id": "2406.16687v1",
      "title": "Link Prediction with Untrained Message Passing Layers",
      "title_zh": "翻译失败",
      "authors": [
        "Lisi Qarkaxhija",
        "Anatol E. Wegner",
        "Ingo Scholtes"
      ],
      "abstract": "Message passing neural networks (MPNNs) operate on graphs by exchanging\ninformation between neigbouring nodes. MPNNs have been successfully applied to\nvarious node-, edge-, and graph-level tasks in areas like molecular science,\ncomputer vision, natural language processing, and combinatorial optimization.\nHowever, most MPNNs require training on large amounts of labeled data, which\ncan be costly and time-consuming. In this work, we explore the use of various\nuntrained message passing layers in graph neural networks, i.e. variants of\npopular message passing architecture where we remove all trainable parameters\nthat are used to transform node features in the message passing step. Focusing\non link prediction, we find that untrained message passing layers can lead to\ncompetitive and even superior performance compared to fully trained MPNNs,\nespecially in the presence of high-dimensional features. We provide a\ntheoretical analysis of untrained message passing by relating the inner\nproducts of features implicitly produced by untrained message passing layers to\npath-based topological node similarity measures. As such, untrained message\npassing architectures can be viewed as a highly efficient and interpretable\napproach to link prediction.",
      "tldr_zh": "本研究探讨了未训练的消息传递层（untrained message passing layers）在图神经网络（Graph Neural Networks）中的应用，特别是针对链接预测（link prediction）任务。传统 Message Passing Neural Networks (MPNNs) 依赖大量标记数据进行训练，而本文提出移除消息传递步骤中所有可训练参数的变体，以减少训练成本。实验结果显示，这种未训练方法在高维特征场景下，能与完全训练的 MPNNs 媲美甚至优于它们。作者通过理论分析，将未训练消息传递层隐式产生的特征内积与基于路径的拓扑节点相似性措施（path-based topological node similarity measures）相关联，将其定位为一种高效、可解释的链接预测方法。",
      "categories": [
        "cs.LG",
        "cs.AI"
      ],
      "primary_category": "cs.LG",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2406.16687v1",
      "published_date": "2024-06-24 14:46:34 UTC",
      "updated_date": "2024-06-24 14:46:34 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-19T00:03:57.546823"
    },
    {
      "arxiv_id": "2407.12803v1",
      "title": "Bosch Street Dataset: A Multi-Modal Dataset with Imaging Radar for Automated Driving",
      "title_zh": "Bosch Street Dataset：一种用于自动驾驶的成像雷达多模态",
      "authors": [
        "Karim Armanious",
        "Maurice Quach",
        "Michael Ulrich",
        "Timo Winterling",
        "Johannes Friesen",
        "Sascha Braun",
        "Daniel Jenet",
        "Yuri Feldman",
        "Eitan Kosman",
        "Philipp Rapp",
        "Volker Fischer",
        "Marc Sons",
        "Lukas Kohns",
        "Daniel Eckstein",
        "Daniela Egbert",
        "Simone Letsch",
        "Corinna Voege",
        "Felix Huttner",
        "Alexander Bartler",
        "Robert Maiwald",
        "Yancong Lin",
        "Ulf Rüegg",
        "Claudius Gläser",
        "Bastian Bischoff",
        "Jascha Freess",
        "Karsten Haug",
        "Kathrin Klee",
        "Holger Caesar"
      ],
      "abstract": "This paper introduces the Bosch street dataset (BSD), a novel multi-modal\nlarge-scale dataset aimed at promoting highly automated driving (HAD) and\nadvanced driver-assistance systems (ADAS) research. Unlike existing datasets,\nBSD offers a unique integration of high-resolution imaging radar, lidar, and\ncamera sensors, providing unprecedented 360-degree coverage to bridge the\ncurrent gap in high-resolution radar data availability. Spanning urban, rural,\nand highway environments, BSD enables detailed exploration into radar-based\nobject detection and sensor fusion techniques. The dataset is aimed at\nfacilitating academic and research collaborations between Bosch and current and\nfuture partners. This aims to foster joint efforts in developing cutting-edge\nHAD and ADAS technologies. The paper describes the dataset's key attributes,\nincluding its scalability, radar resolution, and labeling methodology. Key\nofferings also include initial benchmarks for sensor modalities and a\ndevelopment kit tailored for extensive data analysis and performance\nevaluation, underscoring our commitment to contributing valuable resources to\nthe HAD and ADAS research community.",
      "tldr_zh": "本研究引入了Bosch Street Dataset (BSD)，一个多模态大型数据集，旨在推进高度自动驾驶 (HAD) 和高级驾驶辅助系统 (ADAS) 的研究。该数据集独特地将高分辨率imaging radar、lidar 和camera sensors 整合，提供360度全覆盖，并桥接了高分辨率雷达数据可用性的空白。BSD 涵盖城市、农村和高速公路环境，支持radar-based 对象检测和传感器融合技术的深入探索，并提供初始基准、开发工具包以及标注方法，以促进学术合作和HAD/ADAS 技术的创新发展。",
      "categories": [
        "cs.CV",
        "cs.AI"
      ],
      "primary_category": "cs.CV",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2407.12803v1",
      "published_date": "2024-06-24 14:40:56 UTC",
      "updated_date": "2024-06-24 14:40:56 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-19T00:03:58.065075"
    },
    {
      "arxiv_id": "2407.00082v1",
      "title": "Adapting Job Recommendations to User Preference Drift with Behavioral-Semantic Fusion Learning",
      "title_zh": "翻译失败",
      "authors": [
        "Xiao Han",
        "Chen Zhu",
        "Xiao Hu",
        "Chuan Qin",
        "Xiangyu Zhao",
        "Hengshu Zhu"
      ],
      "abstract": "Job recommender systems are crucial for aligning job opportunities with\njob-seekers in online job-seeking. However, users tend to adjust their job\npreferences to secure employment opportunities continually, which limits the\nperformance of job recommendations. The inherent frequency of preference drift\nposes a challenge to promptly and precisely capture user preferences. To\naddress this issue, we propose a novel session-based framework, BISTRO, to\ntimely model user preference through fusion learning of semantic and behavioral\ninformation. Specifically, BISTRO is composed of three stages: 1)\ncoarse-grained semantic clustering, 2) fine-grained job preference extraction,\nand 3) personalized top-$k$ job recommendation. Initially, BISTRO segments the\nuser interaction sequence into sessions and leverages session-based semantic\nclustering to achieve broad identification of person-job matching.\nSubsequently, we design a hypergraph wavelet learning method to capture the\nnuanced job preference drift. To mitigate the effect of noise in interactions\ncaused by frequent preference drift, we innovatively propose an adaptive\nwavelet filtering technique to remove noisy interaction. Finally, a recurrent\nneural network is utilized to analyze session-based interaction for inferring\npersonalized preferences. Extensive experiments on three real-world offline\nrecruitment datasets demonstrate the significant performances of our framework.\nSignificantly, BISTRO also excels in online experiments, affirming its\neffectiveness in live recruitment settings. This dual success underscores the\nrobustness and adaptability of BISTRO. The source code is available at\nhttps://github.com/Applied-Machine-Learning-Lab/BISTRO.",
      "tldr_zh": "该研究针对在线求职系统中用户偏好漂移（preference drift）问题，提出了一种新型会话-based框架BISTRO，通过融合语义和行为信息来及时捕捉并适应用户工作偏好。BISTRO包括三个阶段：首先进行粗粒度语义聚类（coarse-grained semantic clustering）来识别人职匹配；其次，利用超图小波学习（hypergraph wavelet learning）和自适应小波过滤（adaptive wavelet filtering）提取细粒度偏好并去除噪声；最后，采用循环神经网络（recurrent neural network）进行个性化top-k工作推荐。实验在三个真实世界离线招聘数据集上显示了显著性能提升，并在在线环境中表现出色，证明了框架的鲁棒性和实用性。",
      "categories": [
        "cs.IR",
        "cs.AI",
        "cs.LG"
      ],
      "primary_category": "cs.IR",
      "comment": "Accepted by KDD 24 Research Track",
      "pdf_url": "http://arxiv.org/pdf/2407.00082v1",
      "published_date": "2024-06-24 14:38:04 UTC",
      "updated_date": "2024-06-24 14:38:04 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-19T00:04:20.042962"
    },
    {
      "arxiv_id": "2406.16678v2",
      "title": "Segment Any Text: A Universal Approach for Robust, Efficient and Adaptable Sentence Segmentation",
      "title_zh": "翻译失败",
      "authors": [
        "Markus Frohmann",
        "Igor Sterner",
        "Ivan Vulić",
        "Benjamin Minixhofer",
        "Markus Schedl"
      ],
      "abstract": "Segmenting text into sentences plays an early and crucial role in many NLP\nsystems. This is commonly achieved by using rule-based or statistical methods\nrelying on lexical features such as punctuation. Although some recent works no\nlonger exclusively rely on punctuation, we find that no prior method achieves\nall of (i) robustness to missing punctuation, (ii) effective adaptability to\nnew domains, and (iii) high efficiency. We introduce a new model - Segment any\nText (SaT) - to solve this problem. To enhance robustness, we propose a new\npretraining scheme that ensures less reliance on punctuation. To address\nadaptability, we introduce an extra stage of parameter-efficient fine-tuning,\nestablishing state-of-the-art performance in distinct domains such as verses\nfrom lyrics and legal documents. Along the way, we introduce architectural\nmodifications that result in a threefold gain in speed over the previous state\nof the art and solve spurious reliance on context far in the future. Finally,\nwe introduce a variant of our model with fine-tuning on a diverse, multilingual\nmixture of sentence-segmented data, acting as a drop-in replacement and\nenhancement for existing segmentation tools. Overall, our contributions provide\na universal approach for segmenting any text. Our method outperforms all\nbaselines - including strong LLMs - across 8 corpora spanning diverse domains\nand languages, especially in practically relevant situations where text is\npoorly formatted. Our models and code, including documentation, are available\nat https://github.com/segment-any-text/wtpsplit under the MIT license.",
      "tldr_zh": "这篇论文针对文本分句在NLP系统中的关键作用，提出了一个通用方法Segment Any Text (SaT)，旨在同时实现对缺失标点的鲁棒性、新领域的适应性以及高效率。\n作者引入了新的pretraining方案来减少对标点的依赖，并通过参数高效的fine-tuning（如在歌词和法律文档上）提升模型的适应性，同时进行架构修改，使速度比之前状态提升三倍，并解决对远未来上下文的虚假依赖。\nSaT模型在8个多样语料库上超越所有基线，包括强LLMs，尤其在文本格式不佳的情况下表现出色，并提供开源代码作为现有工具的增强。",
      "categories": [
        "cs.CL",
        "cs.AI",
        "cs.LG"
      ],
      "primary_category": "cs.CL",
      "comment": "Accepted to EMNLP 2024 Main",
      "pdf_url": "http://arxiv.org/pdf/2406.16678v2",
      "published_date": "2024-06-24 14:36:11 UTC",
      "updated_date": "2024-10-02 19:04:17 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-19T00:04:23.047281"
    },
    {
      "arxiv_id": "2406.17809v2",
      "title": "Towards a Science Exocortex",
      "title_zh": "翻译失败",
      "authors": [
        "Kevin G. Yager"
      ],
      "abstract": "Artificial intelligence (AI) methods are poised to revolutionize intellectual\nwork, with generative AI enabling automation of text analysis, text generation,\nand simple decision making or reasoning. The impact to science is only just\nbeginning, but the opportunity is significant since scientific research relies\nfundamentally on extended chains of cognitive work. Here, we review the state\nof the art in agentic AI systems, and discuss how these methods could be\nextended to have even greater impact on science. We propose the development of\nan exocortex, a synthetic extension of a person's cognition. A science\nexocortex could be designed as a swarm of AI agents, with each agent\nindividually streamlining specific researcher tasks, and whose\ninter-communication leads to emergent behavior that greatly extend the\nresearcher's cognition and volition.",
      "tldr_zh": "该论文探讨了人工智能（AI）如何变革智力工作，特别是生成 AI 在文本分析、文本生成和简单决策中的自动化应用，并强调其对科学研究的潜在影响。作者回顾了现有代理 AI 系统（agentic AI systems）的状态，并提出扩展这些系统以支持更复杂的科学任务。最终，他们建议开发一个科学 exocortex，即一个由 AI 代理群（swarm of AI agents）组成的系统，每个代理优化特定研究任务，通过相互通信产生涌现行为（emergent behavior），从而显著扩展研究者的认知和决策能力。",
      "categories": [
        "cs.AI"
      ],
      "primary_category": "cs.AI",
      "comment": "30 pages, 5 figures, 1 table",
      "pdf_url": "http://arxiv.org/pdf/2406.17809v2",
      "published_date": "2024-06-24 14:32:32 UTC",
      "updated_date": "2024-08-15 14:32:34 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-19T00:04:33.049010"
    },
    {
      "arxiv_id": "2406.16672v3",
      "title": "CAVE: Controllable Authorship Verification Explanations",
      "title_zh": "翻译失败",
      "authors": [
        "Sahana Ramnath",
        "Kartik Pandey",
        "Elizabeth Boschee",
        "Xiang Ren"
      ],
      "abstract": "Authorship Verification (AV) (do two documents have the same author?) is\nessential in many real-life applications. AV is often used in privacy-sensitive\ndomains that require an offline proprietary model that is deployed on premises,\nmaking publicly served online models (APIs) a suboptimal choice. Current\noffline AV models however have lower downstream utility due to limited accuracy\n(eg: traditional stylometry AV systems) and lack of accessible post-hoc\nexplanations. In this work, we address the above challenges by developing a\ntrained, offline model CAVE (Controllable Authorship Verification\nExplanations). CAVE generates free-text AV explanations that are controlled to\nbe (1) accessible (uniform structure that can be decomposed into\nsub-explanations grounded to relevant linguistic features), and (2) easily\nverified for explanation-label consistency. We generate silver-standard\ntraining data grounded to the desirable linguistic features by a prompt-based\nmethod Prompt-CAVE. We then filter the data based on rationale-label\nconsistency using a novel metric Cons-R-L. Finally, we fine-tune a small,\noffline model (Llama-3-8B) with this data to create our model CAVE. Results on\nthree difficult AV datasets show that CAVE generates high quality explanations\n(as measured by automatic and human evaluation) as well as competitive task\naccuracy.",
      "tldr_zh": "该论文针对 Authorship Verification (AV) 的挑战，提出了一种离线模型 CAVE（Controllable Authorship Verification Explanations），旨在生成可控的免费文本解释，这些解释具有统一结构、可分解为子解释，并基于相关语言特征，同时易于验证解释-标签一致性。研究方法包括使用 Prompt-CAVE 的提示-based 方式生成银标准训练数据，并通过新指标 Cons-R-L 过滤数据以确保理由-标签一致性，随后微调小型离线模型 Llama-3-8B 来构建 CAVE。实验结果显示，CAVE 在三个困难的 AV 数据集上实现了高质量解释（经自动和人工评估）和竞争性的任务准确性，从而提升了 AV 在隐私敏感领域的实用性。",
      "categories": [
        "cs.CL",
        "cs.AI"
      ],
      "primary_category": "cs.CL",
      "comment": "Accepted at NAACL 2025",
      "pdf_url": "http://arxiv.org/pdf/2406.16672v3",
      "published_date": "2024-06-24 14:27:54 UTC",
      "updated_date": "2025-02-10 03:02:26 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-19T00:04:47.056576"
    },
    {
      "arxiv_id": "2407.10995v2",
      "title": "LionGuard: Building a Contextualized Moderation Classifier to Tackle Localized Unsafe Content",
      "title_zh": "翻译失败",
      "authors": [
        "Jessica Foo",
        "Shaun Khoo"
      ],
      "abstract": "As large language models (LLMs) become increasingly prevalent in a wide\nvariety of applications, concerns about the safety of their outputs have become\nmore significant. Most efforts at safety-tuning or moderation today take on a\npredominantly Western-centric view of safety, especially for toxic, hateful, or\nviolent speech. In this paper, we describe LionGuard, a\nSingapore-contextualized moderation classifier that can serve as guardrails\nagainst unsafe LLM outputs. When assessed on Singlish data, LionGuard\noutperforms existing widely-used moderation APIs, which are not finetuned for\nthe Singapore context, by 14% (binary) and up to 51% (multi-label). Our work\nhighlights the benefits of localization for moderation classifiers and presents\na practical and scalable approach for low-resource languages.",
      "tldr_zh": "该研究针对大型语言模型（LLMs）的输出安全问题，指出现有 moderation 方法偏向西方视角而忽略本地化内容，提出 LionGuard 这一新加坡语境化的 moderation classifier，用以检测和防范本地化不安全内容（如毒性、仇恨或暴力言论）。在 Singlish 数据评估中，LionGuard 比现有 moderation APIs 提升了 14%（binary 分类）和高达 51%（multi-label 分类）的性能。作者强调本地化方法的益处，并提供了一种实用、可扩展的框架，适用于低资源语言的 moderation 任务。",
      "categories": [
        "cs.CL",
        "cs.AI"
      ],
      "primary_category": "cs.CL",
      "comment": "Preprint",
      "pdf_url": "http://arxiv.org/pdf/2407.10995v2",
      "published_date": "2024-06-24 14:05:56 UTC",
      "updated_date": "2024-07-19 00:27:42 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-19T00:05:00.388744"
    },
    {
      "arxiv_id": "2406.16641v1",
      "title": "Vision-Language Consistency Guided Multi-modal Prompt Learning for Blind AI Generated Image Quality Assessment",
      "title_zh": "视觉-语言一致性引导的多模态提示学习，用于盲AI生成图像质量评估",
      "authors": [
        "Jun Fu",
        "Wei Zhou",
        "Qiuping Jiang",
        "Hantao Liu",
        "Guangtao Zhai"
      ],
      "abstract": "Recently, textual prompt tuning has shown inspirational performance in\nadapting Contrastive Language-Image Pre-training (CLIP) models to natural image\nquality assessment. However, such uni-modal prompt learning method only tunes\nthe language branch of CLIP models. This is not enough for adapting CLIP models\nto AI generated image quality assessment (AGIQA) since AGIs visually differ\nfrom natural images. In addition, the consistency between AGIs and user input\ntext prompts, which correlates with the perceptual quality of AGIs, is not\ninvestigated to guide AGIQA. In this letter, we propose vision-language\nconsistency guided multi-modal prompt learning for blind AGIQA, dubbed\nCLIP-AGIQA. Specifically, we introduce learnable textual and visual prompts in\nlanguage and vision branches of CLIP models, respectively. Moreover, we design\na text-to-image alignment quality prediction task, whose learned\nvision-language consistency knowledge is used to guide the optimization of the\nabove multi-modal prompts. Experimental results on two public AGIQA datasets\ndemonstrate that the proposed method outperforms state-of-the-art quality\nassessment models. The source code is available at\nhttps://github.com/JunFu1995/CLIP-AGIQA.",
      "tldr_zh": "该研究针对AI生成图像（AGI）质量评估的挑战，提出了一种视觉-语言一致性指导的多模态提示学习方法，名为CLIP-AGIQA，以适应Contrastive Language-Image Pre-training (CLIP)模型的局限性。方法在CLIP的语言和视觉分支中引入可学习的文本和视觉提示，并设计了一个文本到图像对齐质量预测任务，利用学到的视觉-语言一致性知识来优化这些提示。相比于传统的单模态提示学习，这能更好地处理AGI与自然图像的视觉差异，并考虑用户输入文本提示与AGI的一致性。在两个公共AGIQA数据集上的实验表明，该方法优于现有最先进模型，显著提升了盲AGIQA的性能。",
      "categories": [
        "cs.CV",
        "cs.AI"
      ],
      "primary_category": "cs.CV",
      "comment": "Accepted by IEEE Signal Processing Letter",
      "pdf_url": "http://arxiv.org/pdf/2406.16641v1",
      "published_date": "2024-06-24 13:45:31 UTC",
      "updated_date": "2024-06-24 13:45:31 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-19T00:05:20.999731"
    },
    {
      "arxiv_id": "2406.16638v1",
      "title": "Feature Fusion for Human Activity Recognition using Parameter-Optimized Multi-Stage Graph Convolutional Network and Transformer Models",
      "title_zh": "翻译失败",
      "authors": [
        "Mohammad Belal",
        "Taimur Hassan",
        "Abdelfatah Ahmed",
        "Ahmad Aljarah",
        "Nael Alsheikh",
        "Irfan Hussain"
      ],
      "abstract": "Human activity recognition (HAR) is a crucial area of research that involves\nunderstanding human movements using computer and machine vision technology.\nDeep learning has emerged as a powerful tool for this task, with models such as\nConvolutional Neural Networks (CNNs) and Transformers being employed to capture\nvarious aspects of human motion. One of the key contributions of this work is\nthe demonstration of the effectiveness of feature fusion in improving HAR\naccuracy by capturing spatial and temporal features, which has important\nimplications for the development of more accurate and robust activity\nrecognition systems. The study uses sensory data from HuGaDB, PKU-MMD, LARa,\nand TUG datasets. Two model, the PO-MS-GCN and a Transformer were trained and\nevaluated, with PO-MS-GCN outperforming state-of-the-art models. HuGaDB and TUG\nachieved high accuracies and f1-scores, while LARa and PKU-MMD had lower\nscores. Feature fusion improved results across datasets.",
      "tldr_zh": "这篇论文探讨了通过特征融合技术提升人类活动识别(HAR)的准确性，采用参数优化多阶段图卷积网络(PO-MS-GCN)和Transformer模型来捕捉空间和时间特征。研究的主要贡献是证明特征融合能显著改善HAR系统的鲁棒性和性能，使用HuGaDB、PKU-MMD、LARa和TUG数据集进行实验。结果显示，PO-MS-GCN模型超过了现有最先进模型，在HuGaDB和TUG数据集上实现了高准确率和F1分数，而特征融合进一步提升了所有数据集的表现。",
      "categories": [
        "cs.CV",
        "cs.AI"
      ],
      "primary_category": "cs.CV",
      "comment": "7 pages, 1 figure, conference",
      "pdf_url": "http://arxiv.org/pdf/2406.16638v1",
      "published_date": "2024-06-24 13:44:06 UTC",
      "updated_date": "2024-06-24 13:44:06 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-19T00:05:37.156984"
    },
    {
      "arxiv_id": "2406.16635v2",
      "title": "ShadowLLM: Predictor-based Contextual Sparsity for Large Language Models",
      "title_zh": "翻译失败",
      "authors": [
        "Yash Akhauri",
        "Ahmed F AbouElhamayed",
        "Jordan Dotzel",
        "Zhiru Zhang",
        "Alexander M Rush",
        "Safeen Huda",
        "Mohamed S Abdelfattah"
      ],
      "abstract": "The high power consumption and latency-sensitive deployments of large\nlanguage models (LLMs) have motivated efficiency techniques like quantization\nand sparsity. Contextual sparsity, where the sparsity pattern is\ninput-dependent, is crucial in LLMs because the permanent removal of attention\nheads or neurons from LLMs can significantly degrade accuracy. Prior work has\nattempted to model contextual sparsity using neural networks trained to predict\nactivation magnitudes, which can be used to dynamically prune structures with\nlow predicted activation magnitude. In this paper, we look beyond\nmagnitude-based pruning criteria to assess attention head and neuron importance\nin LLMs. We develop a novel predictor called ShadowLLM, which can shadow the\nLLM behavior and enforce better sparsity patterns, resulting in over 15%\nimprovement in end-to-end accuracy compared to prior methods. In addition,\nShadowLLM achieves up to a 20% speed-up over the state-of-the-art DejaVu\nframework. These enhancements are validated on Llama-2 and OPT models with up\nto 30 billion parameters. Our code is available at\n\\href{https://github.com/abdelfattah-lab/shadow_llm/}{ShadowLLM}.",
      "tldr_zh": "该研究针对大型语言模型（Large Language Models, LLMs）的功耗和延迟问题，提出了一种基于预测器的上下文稀疏性（Contextual Sparsity）方法，名为ShadowLLM，以动态修剪注意力头和神经元。ShadowLLM通过模拟LLM行为并优化稀疏模式，超越了传统的基于激活幅度预测的修剪标准，实现更精确的稀疏策略。实验结果显示，与现有方法相比，ShadowLLM在Llama-2和OPT模型上提高了15%的端到端准确率，并实现了20%的加速，验证了其在处理30亿参数规模模型的有效性。",
      "categories": [
        "cs.LG",
        "cs.AI",
        "cs.CL"
      ],
      "primary_category": "cs.LG",
      "comment": "Accepted to EMNLP 2024 (Main, Long Paper)",
      "pdf_url": "http://arxiv.org/pdf/2406.16635v2",
      "published_date": "2024-06-24 13:41:08 UTC",
      "updated_date": "2024-10-17 15:45:10 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-19T00:05:45.121684"
    },
    {
      "arxiv_id": "2406.16626v1",
      "title": "Hacking a surrogate model approach to XAI",
      "title_zh": "针对 XAI 的代理模型方法的破解",
      "authors": [
        "Alexander Wilhelm",
        "Katharina A. Zweig"
      ],
      "abstract": "In recent years, the number of new applications for highly complex AI systems\nhas risen significantly. Algorithmic decision-making systems (ADMs) are one of\nsuch applications, where an AI system replaces the decision-making process of a\nhuman expert. As one approach to ensure fairness and transparency of such\nsystems, explainable AI (XAI) has become more important. One variant to achieve\nexplainability are surrogate models, i.e., the idea to train a new simpler\nmachine learning model based on the input-output-relationship of a black box\nmodel. The simpler machine learning model could, for example, be a decision\ntree, which is thought to be intuitively understandable by humans. However,\nthere is not much insight into how well the surrogate model approximates the\nblack box.\n  Our main assumption is that a good surrogate model approach should be able to\nbring such a discriminating behavior to the attention of humans; prior to our\nresearch we assumed that a surrogate decision tree would identify such a\npattern on one of its first levels. However, in this article we show that even\nif the discriminated subgroup - while otherwise being the same in all\ncategories - does not get a single positive decision from the black box ADM\nsystem, the corresponding question of group membership can be pushed down onto\na level as low as wanted by the operator of the system.\n  We then generalize this finding to pinpoint the exact level of the tree on\nwhich the discriminating question is asked and show that in a more realistic\nscenario, where discrimination only occurs to some fraction of the\ndisadvantaged group, it is even more feasible to hide such discrimination.\n  Our approach can be generalized easily to other surrogate models.",
      "tldr_zh": "本研究揭示了在可解释AI (XAI) 中，surrogate models 作为解释黑盒模型的一种方法存在潜在漏洞。作者通过实验分析了surrogate models（如决策树），发现即使黑盒算法决策系统 (ADM) 对某个子群体存在歧视行为，该歧视问题可以被操纵推到决策树的下层，从而隐藏歧视。研究进一步推广这一发现，展示了在更现实场景中，当歧视仅影响子群体的一部分时，这种隐藏变得更容易。总体而言，该工作强调了surrogate models 的局限性，并为改进XAI 的公平性和透明度提供了重要启示。",
      "categories": [
        "cs.AI"
      ],
      "primary_category": "cs.AI",
      "comment": "24 pages, 7 figures",
      "pdf_url": "http://arxiv.org/pdf/2406.16626v1",
      "published_date": "2024-06-24 13:18:02 UTC",
      "updated_date": "2024-06-24 13:18:02 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-19T00:06:08.590291"
    },
    {
      "arxiv_id": "2406.16611v2",
      "title": "Evaluation of Language Models in the Medical Context Under Resource-Constrained Settings",
      "title_zh": "翻译失败",
      "authors": [
        "Andrea Posada",
        "Daniel Rueckert",
        "Felix Meissen",
        "Philip Müller"
      ],
      "abstract": "Since the Transformer architecture emerged, language model development has\ngrown, driven by their promising potential. Releasing these models into\nproduction requires properly understanding their behavior, particularly in\nsensitive domains like medicine. Despite this need, the medical literature\nstill lacks practical assessment of pre-trained language models, which are\nespecially valuable in settings where only consumer-grade computational\nresources are available. To address this gap, we have conducted a comprehensive\nsurvey of language models in the medical field and evaluated a subset of these\nfor medical text classification and conditional text generation. The subset\nincludes 53 models with 110 million to 13 billion parameters, spanning the\nTransformer-based model families and knowledge domains. Different approaches\nare employed for text classification, including zero-shot learning, enabling\ntuning without the need to train the model. These approaches are helpful in our\ntarget settings, where many users of language models find themselves. The\nresults reveal remarkable performance across the tasks and datasets evaluated,\nunderscoring the potential of certain models to contain medical knowledge, even\nwithout domain specialization. This study thus advocates for further\nexploration of model applications in medical contexts, particularly in\ncomputational resource-constrained settings, to benefit a wide range of users.\nThe code is available on https://github.com/anpoc/Language-models-in-medicine.",
      "tldr_zh": "这篇论文评估了在资源受限设置下，语言模型（Language Models）在医疗领域的表现，填补了现有文献中对预训练模型实际评估的空白。研究团队调查并测试了 53 个 Transformer 模型（参数从 110 百万到 13 亿），针对医疗文本分类和条件文本生成任务，采用了零样本学习（zero-shot learning）等无需训练的方法。结果显示，这些模型在各种任务和数据集上表现出色，即使缺乏领域专业化也能包含医疗知识，从而倡导在计算资源受限的环境中进一步探索其应用，以惠及更多用户。代码已在 GitHub 上公开。",
      "categories": [
        "cs.CL",
        "cs.AI"
      ],
      "primary_category": "cs.CL",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2406.16611v2",
      "published_date": "2024-06-24 12:52:02 UTC",
      "updated_date": "2024-10-23 18:10:29 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-19T00:06:13.183811"
    },
    {
      "arxiv_id": "2406.16609v1",
      "title": "Evaluating the Robustness of Deep-Learning Algorithm-Selection Models by Evolving Adversarial Instances",
      "title_zh": "翻译失败",
      "authors": [
        "Emma Hart",
        "Quentin Renau",
        "Kevin Sim",
        "Mohamad Alissa"
      ],
      "abstract": "Deep neural networks (DNN) are increasingly being used to perform\nalgorithm-selection in combinatorial optimisation domains, particularly as they\naccommodate input representations which avoid designing and calculating\nfeatures. Mounting evidence from domains that use images as input shows that\ndeep convolutional networks are vulnerable to adversarial samples, in which a\nsmall perturbation of an instance can cause the DNN to misclassify. However, it\nremains unknown as to whether deep recurrent networks (DRN) which have recently\nbeen shown promise as algorithm-selectors in the bin-packing domain are equally\nvulnerable. We use an evolutionary algorithm (EA) to find perturbations of\ninstances from two existing benchmarks for online bin packing that cause\ntrained DRNs to misclassify: adversarial samples are successfully generated\nfrom up to 56% of the original instances depending on the dataset. Analysis of\nthe new misclassified instances sheds light on the `fragility' of some training\ninstances, i.e. instances where it is trivial to find a small perturbation that\nresults in a misclassification and the factors that influence this. Finally,\nthe method generates a large number of new instances misclassified with a wide\nvariation in confidence, providing a rich new source of training data to create\nmore robust models.",
      "tldr_zh": "该研究评估了深度学习算法选择模型（特别是深度循环网络，DRN）的鲁棒性，通过使用进化算法（EA）生成对抗样本来扰动 bin-packing 领域的基准实例。结果显示，在两个数据集上，从多达 56% 的原始实例成功创建了这些对抗样本，导致 DRN 误分类。分析揭示了某些训练实例的脆弱性，包括容易受到小扰动影响的因素，并生成了大量置信度变化大的新误分类实例，作为训练更鲁棒模型的丰富数据源。",
      "categories": [
        "cs.NE",
        "cs.AI",
        "cs.LG"
      ],
      "primary_category": "cs.NE",
      "comment": "To appear in the proceedings of the 18th International Conference on\n  Parallel Problem Solving from Nature (PPSN 2024)",
      "pdf_url": "http://arxiv.org/pdf/2406.16609v1",
      "published_date": "2024-06-24 12:48:44 UTC",
      "updated_date": "2024-06-24 12:48:44 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-19T00:06:24.940092"
    },
    {
      "arxiv_id": "2406.16605v1",
      "title": "CLEAR: Can Language Models Really Understand Causal Graphs?",
      "title_zh": "CLEAR: 语言模型是否真的理解因果图？",
      "authors": [
        "Sirui Chen",
        "Mengying Xu",
        "Kun Wang",
        "Xingyu Zeng",
        "Rui Zhao",
        "Shengjie Zhao",
        "Chaochao Lu"
      ],
      "abstract": "Causal reasoning is a cornerstone of how humans interpret the world. To model\nand reason about causality, causal graphs offer a concise yet effective\nsolution. Given the impressive advancements in language models, a crucial\nquestion arises: can they really understand causal graphs? To this end, we\npioneer an investigation into language models' understanding of causal graphs.\nSpecifically, we develop a framework to define causal graph understanding, by\nassessing language models' behaviors through four practical criteria derived\nfrom diverse disciplines (e.g., philosophy and psychology). We then develop\nCLEAR, a novel benchmark that defines three complexity levels and encompasses\n20 causal graph-based tasks across these levels. Finally, based on our\nframework and benchmark, we conduct extensive experiments on six leading\nlanguage models and summarize five empirical findings. Our results indicate\nthat while language models demonstrate a preliminary understanding of causal\ngraphs, significant potential for improvement remains. Our project website is\nat https://github.com/OpenCausaLab/CLEAR.",
      "tldr_zh": "本研究探讨了语言模型是否真正理解因果图（Causal Graphs），通过开发一个评估框架来定义理解标准，包括四个实用标准（如哲学和心理学领域）。研究者构建了CLEAR基准，该基准涵盖三个复杂度级别和20个基于因果图的任务，用于测试语言模型的表现。实验结果显示，六种领先语言模型表现出初步理解，但仍有显著改进潜力，并总结了五个经验发现。",
      "categories": [
        "cs.CL",
        "cs.AI",
        "cs.LG",
        "stat.ME"
      ],
      "primary_category": "cs.CL",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2406.16605v1",
      "published_date": "2024-06-24 12:46:15 UTC",
      "updated_date": "2024-06-24 12:46:15 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-19T00:06:32.497965"
    },
    {
      "arxiv_id": "2406.16578v2",
      "title": "QuadrupedGPT: Towards a Versatile Quadruped Agent in Open-ended Worlds",
      "title_zh": "翻译失败",
      "authors": [
        "Yuting Mei",
        "Ye Wang",
        "Sipeng Zheng",
        "Qin Jin"
      ],
      "abstract": "As robotic agents increasingly assist humans in reality, quadruped robots\noffer unique opportunities for interaction in complex scenarios due to their\nagile movement. However, building agents that can autonomously navigate, adapt,\nand respond to versatile goals remains a significant challenge. In this work,\nwe introduce QuadrupedGPT designed to follow diverse commands with agility\ncomparable to that of a pet. The primary challenges addressed include: i)\neffectively utilizing multimodal observations for informed decision-making; ii)\nachieving agile control by integrating locomotion and navigation; iii)\ndeveloping advanced cognition to execute long-term objectives. Our QuadrupedGPT\ninterprets human commands and environmental contexts using a large multimodal\nmodel. Leveraging its extensive knowledge base, the agent autonomously assigns\nparameters for adaptive locomotion policies and devises safe yet efficient\npaths toward its goals. Additionally, it employs high-level reasoning to\ndecompose long-term goals into a sequence of executable subgoals. Through\ncomprehensive experiments, our agent shows proficiency in handling diverse\ntasks and intricate instructions, representing a significant step toward the\ndevelopment of versatile quadruped agents for open-ended environments.",
      "tldr_zh": "该研究引入了QuadrupedGPT，一种多功能四足机器人代理，旨在处理开放环境中的多样化任务，实现像宠物般敏捷的自主导航和响应。QuadrupedGPT利用大型多模态模型(large multimodal model)来解释人类命令和环境上下文，并通过自主分配参数整合运动和导航策略，以实现安全高效的路径规划。同时，它采用高级认知机制将长期目标分解为可执行子目标。实验结果显示，该代理在各种复杂任务中表现出色，标志着四足机器人向适应性更强的开放环境代理迈出重要一步。",
      "categories": [
        "cs.RO",
        "cs.AI"
      ],
      "primary_category": "cs.RO",
      "comment": "Under review",
      "pdf_url": "http://arxiv.org/pdf/2406.16578v2",
      "published_date": "2024-06-24 12:14:24 UTC",
      "updated_date": "2024-12-03 03:49:24 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-19T00:06:49.314882"
    },
    {
      "arxiv_id": "2407.10994v4",
      "title": "Panza: Design and Analysis of a Fully-Local Personalized Text Writing Assistant",
      "title_zh": "Panza: 完全本地化个性化文本写作助手的设计和分析",
      "authors": [
        "Armand Nicolicioiu",
        "Eugenia Iofinova",
        "Andrej Jovanovic",
        "Eldar Kurtic",
        "Mahdi Nikdan",
        "Andrei Panferov",
        "Ilia Markov",
        "Nir Shavit",
        "Dan Alistarh"
      ],
      "abstract": "The availability of powerful open-source large language models (LLMs) opens\nexciting use-cases, such as using personal data to fine-tune these models to\nimitate a user's unique writing style. Two key requirements for such assistants\nare personalization - in the sense that the assistant should recognizably\nreflect the user's own writing style - and privacy - users may justifiably be\nwary of uploading extremely personal data, such as their email archive, to a\nthird-party service. In this paper, we present a new design and evaluation for\nsuch an automated assistant, for the specific use case of email generation,\nwhich we call Panza. Panza's personalization features are based on a\ncombination of fine-tuning using a variant of the Reverse Instructions\ntechnique together with Retrieval-Augmented Generation (RAG). We demonstrate\nthat this combination allows us to fine-tune an LLM to reflect a user's writing\nstyle using limited data, while executing on extremely limited resources, e.g.\non a free Google Colab instance. Our key methodological contribution is the\nfirst detailed study of evaluation metrics for this personalized writing task,\nand of how different choices of system components--the use of RAG and of\ndifferent fine-tuning approaches-impact the system's performance. Additionally,\nwe demonstrate that very little data - under 100 email samples - are sufficient\nto create models that convincingly imitate humans. This finding showcases a\npreviously-unknown attack vector in language models - that access to a small\nnumber of writing samples can allow a bad actor to cheaply create generative\nmodels that imitate a target's writing style. We are releasing the full Panza\ncode as well as three new email datasets licensed for research use at\nhttps://github.com/IST-DASLab/PanzaMail.",
      "tldr_zh": "本研究提出Panza，一种完全本地化的个性化文本写作助手，针对电子邮件生成任务，强调个性化（模仿用户写作风格）和隐私（避免上传数据到第三方）。Panza结合fine-tuning（使用Reverse Instructions变体）和Retrieval-Augmented Generation (RAG)，能在有限数据（如不到100封邮件）和资源（如免费Google Colab）下有效训练模型。实验结果显示，该方法显著提升了个性化性能，并首次详细评估了不同系统组件（如RAG和fine-tuning方法）对指标的影响；然而，这也揭示了潜在风险，即攻击者可用少量样本创建模仿目标写作风格的生成模型。研究开源了Panza代码和三个新电子邮件数据集。",
      "categories": [
        "cs.CL",
        "cs.AI",
        "cs.HC",
        "cs.LG"
      ],
      "primary_category": "cs.CL",
      "comment": "Panza is available at https://github.com/IST-DASLab/PanzaMail",
      "pdf_url": "http://arxiv.org/pdf/2407.10994v4",
      "published_date": "2024-06-24 12:09:34 UTC",
      "updated_date": "2025-02-10 15:08:07 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-19T00:06:57.583619"
    },
    {
      "arxiv_id": "2406.16571v1",
      "title": "Differentiable Distributionally Robust Optimization Layers",
      "title_zh": "可微分分布鲁棒优化层",
      "authors": [
        "Xutao Ma",
        "Chao Ning",
        "Wenli Du"
      ],
      "abstract": "In recent years, there has been a growing research interest in\ndecision-focused learning, which embeds optimization problems as a layer in\nlearning pipelines and demonstrates a superior performance than the\nprediction-focused approach. However, for distributionally robust optimization\n(DRO), a popular paradigm for decision-making under uncertainty, it is still\nunknown how to embed it as a layer, i.e., how to differentiate decisions with\nrespect to an ambiguity set. In this paper, we develop such differentiable DRO\nlayers for generic mixed-integer DRO problems with parameterized second-order\nconic ambiguity sets and discuss its extension to Wasserstein ambiguity sets.\nTo differentiate the mixed-integer decisions, we propose a novel dual-view\nmethodology by handling continuous and discrete parts of decisions via\ndifferent principles. Specifically, we construct a differentiable energy-based\nsurrogate to implement the dual-view methodology and use importance sampling to\nestimate its gradient. We further prove that such a surrogate enjoys the\nasymptotic convergency under regularization. As an application of the proposed\ndifferentiable DRO layers, we develop a novel decision-focused learning\npipeline for contextual distributionally robust decision-making tasks and\ncompare it with the prediction-focused approach in experiments.",
      "tldr_zh": "本论文提出了可微分分布鲁棒优化（DRO）层，用于将DRO问题嵌入决策导向学习管道中，以处理不确定性决策问题。该方法针对通用混合整数DRO问题，开发了参数化二阶锥模糊集的微分层，并扩展到Wasserstein模糊集；通过双视图方法（dual-view methodology）分别处理连续和离散决策，使用基于能量的代理（energy-based surrogate）和重要性采样（importance sampling）来估计梯度，并证明了其在正则化下的渐进收敛性。作为应用，该框架构建了一个新的决策导向学习管道，用于上下文DRO任务，并在实验中展示了比预测导向方法更优的表现。",
      "categories": [
        "math.OC",
        "cs.AI",
        "cs.LG",
        "cs.SY",
        "eess.SY"
      ],
      "primary_category": "math.OC",
      "comment": "In Forty-first International Conference on Machine Learning (2024)",
      "pdf_url": "http://arxiv.org/pdf/2406.16571v1",
      "published_date": "2024-06-24 12:09:19 UTC",
      "updated_date": "2024-06-24 12:09:19 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-19T00:07:10.780782"
    },
    {
      "arxiv_id": "2406.16555v1",
      "title": "Homomorphisms and Embeddings of STRIPS Planning Models",
      "title_zh": "STRIPS 规划模型的同态和嵌入",
      "authors": [
        "Arnaud Lequen",
        "Martin C. Cooper",
        "Frédéric Maris"
      ],
      "abstract": "Determining whether two STRIPS planning instances are isomorphic is the\nsimplest form of comparison between planning instances. It is also a particular\ncase of the problem concerned with finding an isomorphism between a planning\ninstance $P$ and a sub-instance of another instance $P_0$ . One application of\nsuch a mapping is to efficiently produce a compiled form containing all\nsolutions to P from a compiled form containing all solutions to $P_0$. We also\nintroduce the notion of embedding from an instance $P$ to another instance\n$P_0$, which allows us to deduce that $P_0$ has no solution-plan if $P$ is\nunsolvable. In this paper, we study the complexity of these problems. We show\nthat the first is GI-complete, and can thus be solved, in theory, in\nquasi-polynomial time. While we prove the remaining problems to be NP-complete,\nwe propose an algorithm to build an isomorphism, when possible. We report\nextensive experimental trials on benchmark problems which demonstrate\nconclusively that applying constraint propagation in preprocessing can greatly\nimprove the efficiency of a SAT solver.",
      "tldr_zh": "这篇论文探讨了 STRIPS 规划模型中的同构（homomorphisms）和嵌入（embeddings），旨在比较规划实例的相似性。作者定义了从一个实例 P 到另一个实例 P0 的同构映射，用于高效生成 P 的所有解决方案，并引入嵌入概念，以推断 P0 的可解性。研究显示，同构问题为 GI-complete，可在准多项式时间内解决，而其他相关问题为 NP-complete；同时，提出了一种构建同构的算法，并通过实验证明，在基准问题上使用约束传播预处理能显著提升 SAT solver 的效率。",
      "categories": [
        "cs.AI"
      ],
      "primary_category": "cs.AI",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2406.16555v1",
      "published_date": "2024-06-24 11:43:18 UTC",
      "updated_date": "2024-06-24 11:43:18 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-19T00:07:21.679000"
    },
    {
      "arxiv_id": "2406.16552v1",
      "title": "Inference of Sequential Patterns for Neural Message Passing in Temporal Graphs",
      "title_zh": "时序图中用于神经消息传递的序列模式推断",
      "authors": [
        "Jan von Pichowski",
        "Vincenzo Perri",
        "Lisi Qarkaxhija",
        "Ingo Scholtes"
      ],
      "abstract": "The modelling of temporal patterns in dynamic graphs is an important current\nresearch issue in the development of time-aware GNNs. Whether or not a specific\nsequence of events in a temporal graph constitutes a temporal pattern not only\ndepends on the frequency of its occurrence. We consider whether it deviates\nfrom what is expected in a temporal graph where timestamps are randomly\nshuffled. While accounting for such a random baseline is important to model\ntemporal patterns, it has mostly been ignored by current temporal graph neural\nnetworks. To address this issue we propose HYPA-DBGNN, a novel two-step\napproach that combines (i) the inference of anomalous sequential patterns in\ntime series data on graphs based on a statistically principled null model, with\n(ii) a neural message passing approach that utilizes a higher-order De Bruijn\ngraph whose edges capture overrepresented sequential patterns. Our method\nleverages hypergeometric graph ensembles to identify anomalous edges within\nboth first- and higher-order De Bruijn graphs, which encode the temporal\nordering of events. The model introduces an inductive bias that enhances model\ninterpretability. We evaluate our approach for static node classification using\nbenchmark datasets and a synthetic dataset that showcases its ability to\nincorporate the observed inductive bias regarding over- and under-represented\ntemporal edges. We demonstrate the framework's effectiveness in detecting\nsimilar patterns within empirical datasets, resulting in superior performance\ncompared to baseline methods in node classification tasks. To the best of our\nknowledge, our work is the first to introduce statistically informed GNNs that\nleverage temporal and causal sequence anomalies. HYPA-DBGNN represents a path\nfor bridging the gap between statistical graph inference and neural graph\nrepresentation learning, with potential applications to static GNNs.",
      "tldr_zh": "该论文探讨了在动态图中建模时间模式的问题，强调序列事件是否构成模式需考虑其是否偏离随机时间戳的预期，而非仅依赖频率。作者提出 HYPA-DBGNN 一种新框架，包括基于统计 null 模型推断异常序列模式，以及利用更高阶 De Bruijn graph 的神经消息传递方法，以捕捉过度表示的序列模式。实验结果显示，该方法在节点分类任务上优于基线模型，并首次桥接统计图推理与神经图表示学习，提升了模型的可解释性和性能。",
      "categories": [
        "cs.LG",
        "cs.AI",
        "cs.SI",
        "stat.ML"
      ],
      "primary_category": "cs.LG",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2406.16552v1",
      "published_date": "2024-06-24 11:41:12 UTC",
      "updated_date": "2024-06-24 11:41:12 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-19T00:07:34.380750"
    },
    {
      "arxiv_id": "2406.16537v4",
      "title": "Character-Adapter: Prompt-Guided Region Control for High-Fidelity Character Customization",
      "title_zh": "翻译失败",
      "authors": [
        "Yuhang Ma",
        "Wenting Xu",
        "Jiji Tang",
        "Qinfeng Jin",
        "Rongsheng Zhang",
        "Zeng Zhao",
        "Changjie Fan",
        "Zhipeng Hu"
      ],
      "abstract": "Customized image generation, which seeks to synthesize images with consistent\ncharacters, holds significant relevance for applications such as storytelling,\nportrait generation, and character design. However, previous approaches have\nencountered challenges in preserving characters with high-fidelity consistency\ndue to inadequate feature extraction and concept confusion of reference\ncharacters. Therefore, we propose Character-Adapter, a plug-and-play framework\ndesigned to generate images that preserve the details of reference characters,\nensuring high-fidelity consistency. Character-Adapter employs prompt-guided\nsegmentation to ensure fine-grained regional features of reference characters\nand dynamic region-level adapters to mitigate concept confusion. Extensive\nexperiments are conducted to validate the effectiveness of Character-Adapter.\nBoth quantitative and qualitative results demonstrate that Character-Adapter\nachieves the state-of-the-art performance of consistent character generation,\nwith an improvement of 24.8% compared with other methods. Our code will be\nreleased at https://github.com/Character-Adapter/Character-Adapter.",
      "tldr_zh": "该研究提出Character-Adapter，一种即插即用的框架，用于高保真自定义图像生成，确保参考角色的细节一致性，解决现有方法在特征提取和概念混淆方面的不足。框架通过prompt-guided segmentation提取参考角色的细粒度区域特征，并采用dynamic region-level adapters来缓解概念混淆，从而实现更精确的角色定制。实验结果显示，Character-Adapter在一致性角色生成方面达到最先进水平，比其他方法提高了24.8%的性能，并计划开源代码以便进一步应用。",
      "categories": [
        "cs.CV",
        "cs.AI"
      ],
      "primary_category": "cs.CV",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2406.16537v4",
      "published_date": "2024-06-24 11:16:37 UTC",
      "updated_date": "2024-09-29 09:07:23 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-19T00:07:45.878959"
    },
    {
      "arxiv_id": "2406.16535v3",
      "title": "Token-based Decision Criteria Are Suboptimal in In-context Learning",
      "title_zh": "基于标记的决策标准在上下文学习中是次优的",
      "authors": [
        "Hakaze Cho",
        "Yoshihiro Sakai",
        "Mariko Kato",
        "Kenshiro Tanaka",
        "Akira Ishii",
        "Naoya Inoue"
      ],
      "abstract": "In-Context Learning (ICL) typically utilizes classification criteria from\noutput probabilities of manually selected label tokens. However, we argue that\nsuch token-based classification criteria lead to suboptimal decision\nboundaries, despite delicate calibrations through translation and constrained\nrotation applied. To address this problem, we propose Hidden Calibration, which\nrenounces token probabilities and uses the nearest centroid classifier on the\nLM's last hidden states. In detail, we assign the label of the nearest centroid\npreviously estimated from a calibration set to the test sample as the predicted\nlabel. Our experiments on 6 models and 10 classification datasets indicate that\nHidden Calibration consistently outperforms current token-based baselines by\nabout 20%~50%, achieving a strong state-of-the-art in ICL. Our further analysis\ndemonstrates that Hidden Calibration finds better classification criteria with\nless inter-class overlap, and LMs provide linearly separable intra-class\nclusters with the help of demonstrations, which supports Hidden Calibration and\ngives new insights into the principle of ICL. Our official code implementation\ncan be found at https://github.com/hc495/Hidden_Calibration.",
      "tldr_zh": "该研究指出，在In-Context Learning (ICL)中，基于标记的分类标准会导致次优决策边界，即使经过校准。作者提出Hidden Calibration方法，放弃标记概率，而是使用最近质心分类器在语言模型的最后隐藏状态上进行预测，通过从校准集估计质心来分配测试样本的标签。在6个模型和10个分类数据集上的实验显示，Hidden Calibration比现有基于标记的基线提高了约20%~50%，达到了ICL的先进水平；进一步分析表明，该方法减少了类间重叠，并揭示了LM在演示帮助下形成线性可分类内聚类的机制。",
      "categories": [
        "cs.CL",
        "cs.AI",
        "cs.LG"
      ],
      "primary_category": "cs.CL",
      "comment": "24 pages, 15 figures, 13 tables. NAACL 2025 Main Conference Accepted.\n  Camera-ready version",
      "pdf_url": "http://arxiv.org/pdf/2406.16535v3",
      "published_date": "2024-06-24 11:16:26 UTC",
      "updated_date": "2025-02-05 13:44:48 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-19T00:07:58.578647"
    },
    {
      "arxiv_id": "2406.16526v1",
      "title": "NARRepair: Non-Autoregressive Code Generation Model for Automatic Program Repair",
      "title_zh": "NARRepair：非自回归代码生成模型用于自动程序修复",
      "authors": [
        "Zhenyu Yang",
        "Zhen Yang",
        "Zhongxing Yu"
      ],
      "abstract": "With the advancement of deep learning techniques, the performance of\nAutomatic Program Repair(APR) techniques has reached a new level. Previous deep\nlearning-based APR techniques essentially modified program sentences in the\nAutoregressive(AR) manner, which predicts future values based on past values.\nDue to the manner of word-by-word generation, the AR-based APR technique has a\nhuge time delay. This negative consequence overshadows the widespread adoption\nof APR techniques in real-life software development.\n  To address the issue, we aim to apply the Non-Autoregressive(NAR) method to\nthe APR task, which can output target code in a parallel manner to avoid huge\ninference delays. To effectively adapt the NAR manner for the APR task, we in\nthis paper propose NARRepair, the first customized NAR code generation model\nfor the APR task. The NARRepair features three major novelties, including 1)\nusing repair actions to alleviate the over-correction issue, 2) extracting\ndependency information from AST to alleviate the issue of lacking inter-word\ndependency information, 3) employing two-stage decoding to alleviate the issue\nof lacking contextual information. We evaluated NARRepair on three widely used\ndatasets in the APR community, and the results show that our technique can\nsignificantly improve the inference speed while maintaining high repair\naccuracy.",
      "tldr_zh": "本文提出NARRepair，一种专为Automatic Program Repair (APR) 任务设计的Non-Autoregressive (NAR) 代码生成模型，以解决传统Autoregressive (AR) 方法导致的巨大推理延迟问题。NARRepair的三大创新包括：使用repair actions缓解over-correction问题、从Abstract Syntax Tree (AST)提取依赖信息缓解inter-word dependency缺失、以及采用two-stage decoding缓解contextual信息不足。实验结果显示，在三个常用数据集上，NARRepair显著提高了推理速度，同时保持了高修复准确率。",
      "categories": [
        "cs.SE",
        "cs.AI"
      ],
      "primary_category": "cs.SE",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2406.16526v1",
      "published_date": "2024-06-24 11:04:28 UTC",
      "updated_date": "2024-06-24 11:04:28 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-19T00:08:10.907910"
    },
    {
      "arxiv_id": "2406.16521v1",
      "title": "Carrot and Stick: Inducing Self-Motivation with Positive & Negative Feedback",
      "title_zh": "翻译失败",
      "authors": [
        "Jimin Sohn",
        "Jeihee Cho",
        "Junyong Lee",
        "Songmu Heo",
        "Ji-Eun Han",
        "David R. Mortensen"
      ],
      "abstract": "Positive thinking is thought to be an important component of self-motivation\nin various practical fields such as education and the workplace. Previous work,\nincluding sentiment transfer and positive reframing, has focused on the\npositive side of language. However, self-motivation that drives people to reach\ntheir goals has not yet been studied from a computational perspective.\nMoreover, negative feedback has not yet been explored, even though positive and\nnegative feedback are both necessary to grow self-motivation. To facilitate\nself-motivation, we propose CArrot and STICk (CASTIC) dataset, consisting of\n12,590 sentences with 5 different strategies for enhancing self-motivation. Our\ndata and code are publicly available at here.",
      "tldr_zh": "本研究强调积极思考在自激励中的重要性，但指出现有工作如 sentiment transfer 和 positive reframing 仅关注正面语言，而忽略了负面反馈对自激励的必要性。作者提出 CASTIC 数据集，包含 12,590 句子和 5 种增强自激励的策略，旨在通过结合正面和负面反馈来促进目标实现。数据集和代码已公开可用，为自激励的计算视角研究提供了新资源。",
      "categories": [
        "cs.CL",
        "cs.AI"
      ],
      "primary_category": "cs.CL",
      "comment": "10 pages, 8 figures",
      "pdf_url": "http://arxiv.org/pdf/2406.16521v1",
      "published_date": "2024-06-24 10:55:31 UTC",
      "updated_date": "2024-06-24 10:55:31 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-19T00:08:22.448801"
    },
    {
      "arxiv_id": "2406.16505v2",
      "title": "$\\text{Alpha}^2$: Discovering Logical Formulaic Alphas using Deep Reinforcement Learning",
      "title_zh": "翻译失败",
      "authors": [
        "Feng Xu",
        "Yan Yin",
        "Xinyu Zhang",
        "Tianyuan Liu",
        "Shengyi Jiang",
        "Zongzhang Zhang"
      ],
      "abstract": "Alphas are pivotal in providing signals for quantitative trading. The\nindustry highly values the discovery of formulaic alphas for their\ninterpretability and ease of analysis, compared with the expressive yet\noverfitting-prone black-box alphas. In this work, we focus on discovering\nformulaic alphas. Prior studies on automatically generating a collection of\nformulaic alphas were mostly based on genetic programming (GP), which is known\nto suffer from the problems of being sensitive to the initial population,\nconverting to local optima, and slow computation speed. Recent efforts\nemploying deep reinforcement learning (DRL) for alpha discovery have not fully\naddressed key practical considerations such as alpha correlations and validity,\nwhich are crucial for their effectiveness. In this work, we propose a novel\nframework for alpha discovery using DRL by formulating the alpha discovery\nprocess as program construction. Our agent, $\\text{Alpha}^2$, assembles an\nalpha program optimized for an evaluation metric. A search algorithm guided by\nDRL navigates through the search space based on value estimates for potential\nalpha outcomes. The evaluation metric encourages both the performance and the\ndiversity of alphas for a better final trading strategy. Our formulation of\nsearching alphas also brings the advantage of pre-calculation dimensional\nanalysis, ensuring the logical soundness of alphas, and pruning the vast search\nspace to a large extent. Empirical experiments on real-world stock markets\ndemonstrates $\\text{Alpha}^2$'s capability to identify a diverse set of logical\nand effective alphas, which significantly improves the performance of the final\ntrading strategy. The code of our method is available at\nhttps://github.com/x35f/alpha2.",
      "tldr_zh": "这项研究提出 $\\text{Alpha}^2$ 框架，利用深度强化学习 (DRL) 来发现逻辑公式化的 Alphas，以解决量化交易中信号发现的挑战，如遗传编程 (GP) 的敏感性和局部最优问题。该框架将 Alpha 发现过程视为程序构建，通过 DRL 引导的搜索算法优化 Alphas 的性能、多样性和有效性，并采用预计算维度分析确保逻辑 soundness。实验结果显示，在真实股票市场上，$\\text{Alpha}^2$ 能够识别出多样且有效的 Alphas，从而显著提升最终交易策略的整体表现。",
      "categories": [
        "q-fin.CP",
        "cs.AI"
      ],
      "primary_category": "q-fin.CP",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2406.16505v2",
      "published_date": "2024-06-24 10:21:29 UTC",
      "updated_date": "2024-06-26 07:40:12 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-19T00:08:35.818153"
    },
    {
      "arxiv_id": "2407.12011v1",
      "title": "Digital Twinning of a Pressurized Water Reactor Startup Operation and Partial Computational Offloading in In-network Computing-Assisted Multiaccess Edge Computing",
      "title_zh": "翻译失败",
      "authors": [
        "Ibrahim Aliyu",
        "Awwal M. Arigi",
        "Tai-Won Um",
        "Jinsul Kim"
      ],
      "abstract": "This paper addresses the challenge of representing complex human action (HA)\nin a nuclear power plant (NPP) digital twin (DT) and minimizing latency in\npartial computation offloading (PCO) in sixth-generation-enabled computing in\nthe network (COIN) assisted multiaccess edge computing (MEC). Accurate HA\nrepresentation in the DT-HA model is vital for modeling human interventions\nthat are crucial for the safe and efficient operation of NPPs. In this context,\nDT-enabled COIN-assisted MEC harnesses DT (known as a cybertwin) capabilities\nto optimize resource allocation and reduce latency effectively. A two-stage\napproach is employed to address system complexity. First, a probabilistic\ngraphical model (PGM) is introduced to capture HAs in the DT abstraction. In\nthe PGM, HA and NPP asset-twin abstractions form coupled systems that evolve\nand interact through observable data and control input. Next, the underlying\nPCO problem is formulated as a multiuser game, where NPP assets can partially\noffload tasks to COIN and MEC. We propose a decentralized algorithm to optimize\noffloading decisions, offloading ratios, and resource allocation. The\nsimulation results demonstrate the effectiveness of the proposed method in\ncapturing complex HAs and optimal resource allocation in DT-enabled NPPs.",
      "tldr_zh": "这篇论文探讨了核电站数字孪生（Digital Twin）中复杂人类行动（HA）的表示问题，以及在计算网络（COIN）辅助多接入边缘计算（MEC）环境中最小化部分计算卸载（PCO）的延迟，以提升核电站的安全和效率。作者采用两阶段方法：首先引入概率图形模型（PGM）来捕捉 HA，并将其与核电站资产孪生形成耦合系统，通过可观察数据和控制输入实现互动；其次，将 PCO 问题制定为多用户游戏，并提出一个去中心化算法优化卸载决策、卸载比率和资源分配。模拟结果证明，该方法在 DT-enabled 核电站中有效捕捉复杂 HA 并实现最佳资源分配，显著降低了延迟。",
      "categories": [
        "cs.DC",
        "cs.AI",
        "cs.NI"
      ],
      "primary_category": "cs.DC",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2407.12011v1",
      "published_date": "2024-06-24 10:13:00 UTC",
      "updated_date": "2024-06-24 10:13:00 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-19T00:08:47.916928"
    },
    {
      "arxiv_id": "2406.16501v1",
      "title": "UNICAD: A Unified Approach for Attack Detection, Noise Reduction and Novel Class Identification",
      "title_zh": "UNICAD：一种用于攻击检测、噪声减少和新类别识别的统一方法",
      "authors": [
        "Alvaro Lopez Pellicer",
        "Kittipos Giatgong",
        "Yi Li",
        "Neeraj Suri",
        "Plamen Angelov"
      ],
      "abstract": "As the use of Deep Neural Networks (DNNs) becomes pervasive, their\nvulnerability to adversarial attacks and limitations in handling unseen classes\nposes significant challenges. The state-of-the-art offers discrete solutions\naimed to tackle individual issues covering specific adversarial attack\nscenarios, classification or evolving learning. However, real-world systems\nneed to be able to detect and recover from a wide range of adversarial attacks\nwithout sacrificing classification accuracy and to flexibly act in {\\bf unseen}\nscenarios. In this paper, UNICAD, is proposed as a novel framework that\nintegrates a variety of techniques to provide an adaptive solution.\n  For the targeted image classification, UNICAD achieves accurate image\nclassification, detects unseen classes, and recovers from adversarial attacks\nusing Prototype and Similarity-based DNNs with denoising autoencoders. Our\nexperiments performed on the CIFAR-10 dataset highlight UNICAD's effectiveness\nin adversarial mitigation and unseen class classification, outperforming\ntraditional models.",
      "tldr_zh": "这篇论文提出了 UNICAD，一种统一的框架，用于同时处理深度神经网络（DNNs）的对抗攻击检测、噪声减少和新类别识别问题。UNICAD 整合了基于原型的 DNNs 和相似性-based DNNs 与去噪自编码器，实现准确的图像分类、检测未知类和从对抗攻击中恢复。实验在 CIFAR-10 数据集上显示，该框架在对抗缓解和未知类分类方面优于传统模型，为实时系统提供了一个自适应的解决方案。",
      "categories": [
        "cs.CV",
        "cs.AI",
        "cs.LG"
      ],
      "primary_category": "cs.CV",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2406.16501v1",
      "published_date": "2024-06-24 10:10:03 UTC",
      "updated_date": "2024-06-24 10:10:03 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-19T00:08:57.902065"
    },
    {
      "arxiv_id": "2406.16495v3",
      "title": "OTCE: Hybrid SSM and Attention with Cross Domain Mixture of Experts to construct Observer-Thinker-Conceiver-Expresser",
      "title_zh": "OTCE：混合 SSM 和注意力机制，结合跨域混合专家",
      "authors": [
        "Jingze Shi",
        "Ting Xie",
        "Bingheng Wu",
        "Chunjun Zheng",
        "Kai Wang"
      ],
      "abstract": "Recent research has shown that combining Mamba with Transformer architecture,\nwhich has selective state space and quadratic self-attention mechanism,\noutperforms using Mamba or Transformer architecture alone in language modeling\ntasks. The quadratic self-attention mechanism effectively alleviates the\nshortcomings of selective state space in handling long-term dependencies of any\nelement in the sequence. We propose a position information injection method\nthat connects the selective state space model with the quadratic attention, and\nintegrates these two architectures with hybrid experts with cross-sharing\ndomains, so that we can enjoy the advantages of both. We design a new\narchitecture with a more biomimetic idea: Observer-Thinker-Conceiver-Expresser\n(OTCE), which can compete with well-known medium-scale open-source language\nmodels on a small scale in language modeling tasks.",
      "tldr_zh": "该研究发现，将 Mamba（selective state space model）和 Transformer（quadratic self-attention）架构结合，能在语言建模任务中超越单独使用，提升对序列长程依赖的处理能力。论文提出了一种位置信息注入方法，将这两种架构通过 hybrid experts with cross-sharing domains 整合，构建出模仿生物认知的 Observer-Thinker-Conceiver-Expresser (OTCE) 新架构。实验结果显示，OTCE 在小规模模型上即可与知名中型开源语言模型竞争，提供更高效的语言建模性能。",
      "categories": [
        "cs.CL",
        "cs.AI"
      ],
      "primary_category": "cs.CL",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2406.16495v3",
      "published_date": "2024-06-24 10:05:23 UTC",
      "updated_date": "2024-07-20 03:35:45 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-19T00:09:11.664270"
    },
    {
      "arxiv_id": "2406.16997v2",
      "title": "Gate Recurrent Unit for Efficient Industrial Gas Identification",
      "title_zh": "翻译失败",
      "authors": [
        "Ding Wang"
      ],
      "abstract": "In recent years, gas recognition technology has received considerable\nattention. Nevertheless, the gas recognition area has faced obstacles in\nimplementing deep learning-based recognition solutions due to the absence of\nstandardized protocols. To tackle this problem, we suggest a new GRU. Compared\nto other models, GRU obtains a higher identification accuracy.",
      "tldr_zh": "这篇论文针对气体识别领域中缺乏标准化协议导致深学习解决方案难以实施的问题，提出了一种新的 Gate Recurrent Unit (GRU) 模型，用于高效的工业气体识别。相比其他模型，该 GRU 模型在识别准确率上表现出色。研究为气体识别技术提供了潜在的改进路径，推动了该领域的标准化应用。",
      "categories": [
        "cs.LG",
        "cs.AI"
      ],
      "primary_category": "cs.LG",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2406.16997v2",
      "published_date": "2024-06-24 10:05:01 UTC",
      "updated_date": "2024-10-14 13:56:47 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-19T00:09:21.846528"
    },
    {
      "arxiv_id": "2406.16494v1",
      "title": "Cross-domain Transfer of Valence Preferences via a Meta-optimization Approach",
      "title_zh": "翻译失败",
      "authors": [
        "Chuang Zhao",
        "Hongke Zhao",
        "Ming He",
        "Xiaomeng Li",
        "Jianping Fan"
      ],
      "abstract": "Cross-domain recommendation offers a potential avenue for alleviating data\nsparsity and cold-start problems. Embedding and mapping, as a classic\ncross-domain research genre, aims to identify a common mapping function to\nperform representation transformation between two domains. Nevertheless,\nprevious coarse-grained preference representations, non-personalized mapping\nfunctions, and excessive reliance on overlapping users limit their performance,\nespecially in scenarios where overlapping users are sparse. To address\naforementioned challenges, we propose a novel cross-domain approach, namely\nCVPM. CVPM formalizes cross-domain interest transfer as a hybrid architecture\nof parametric meta-learning and self-supervised learning, which not only\ntransfers user preferences at a finer level, but also enables signal\nenhancement with the knowledge of non-overlapping users. Specifically, with\ndeep insights into user preferences and valence preference theory, we believe\nthat there exists significant difference between users' positive preferences\nand negative behaviors, and thus employ differentiated encoders to learn their\ndistributions. In particular, we further utilize the pre-trained model and item\npopularity to sample pseudo-interaction items to ensure the integrity of both\ndistributions. To guarantee the personalization of preference transfer, we\ntreat each user's mapping as two parts, the common transformation and the\npersonalized bias, where the network used to generate the personalized bias is\noutput by a meta-learner. Furthermore, in addition to the supervised loss for\noverlapping users, we design contrastive tasks for non-overlapping users from\nboth group and individual-levels to avoid model skew and enhance the semantics\nof representations. Exhaustive data analysis and extensive experimental results\ndemonstrate the effectiveness and advancement of our proposed framework.",
      "tldr_zh": "本研究针对跨域推荐中的数据稀疏和冷启动问题，提出了一种新框架 CVPM，通过参数化 meta-learning 和 self-supervised learning 的混合架构，实现更精细的用户偏好转移，并利用非重叠用户的信息增强信号。CVPM 基于 valence preference theory，使用差异化编码器分别学习用户正负行为分布，并通过预训练模型和物品流行度采样伪交互物品，以确保分布完整性；同时，将用户映射分为公共变换和个性化偏差，由 meta-learner 生成偏差以实现个性化。实验结果显示，该框架在处理重叠用户稀疏场景时显著提升性能，并通过组级和个体级对比任务避免模型偏差，证明了其有效性和先进性。",
      "categories": [
        "cs.IR",
        "cs.AI"
      ],
      "primary_category": "cs.IR",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2406.16494v1",
      "published_date": "2024-06-24 10:02:24 UTC",
      "updated_date": "2024-06-24 10:02:24 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-19T00:09:35.655843"
    },
    {
      "arxiv_id": "2406.16486v1",
      "title": "Towards Comprehensive Preference Data Collection for Reward Modeling",
      "title_zh": "翻译失败",
      "authors": [
        "Yulan Hu",
        "Qingyang Li",
        "Sheng Ouyang",
        "Ge Chen",
        "Kaihui Chen",
        "Lijun Mei",
        "Xucheng Ye",
        "Fuzheng Zhang",
        "Yong Liu"
      ],
      "abstract": "Reinforcement Learning from Human Feedback (RLHF) facilitates the alignment\nof large language models (LLMs) with human preferences, thereby enhancing the\nquality of responses generated. A critical component of RLHF is the reward\nmodel, which is trained on preference data and outputs a scalar reward during\nthe inference stage. However, the collection of preference data still lacks\nthorough investigation. Recent studies indicate that preference data is\ncollected either by AI or humans, where chosen and rejected instances are\nidentified among pairwise responses. We question whether this process\neffectively filters out noise and ensures sufficient diversity in collected\ndata. To address these concerns, for the first time, we propose a comprehensive\nframework for preference data collection, decomposing the process into four\nincremental steps: Prompt Generation, Response Generation, Response Filtering,\nand Human Labeling. This structured approach ensures the collection of\nhigh-quality preferences while reducing reliance on human labor. We conducted\ncomprehensive experiments based on the data collected at different stages,\ndemonstrating the effectiveness of the proposed data collection method.",
      "tldr_zh": "该研究针对 Reinforcement Learning from Human Feedback (RLHF) 中奖励模型的训练，探讨了偏好数据收集的不足问题，如数据噪声和多样性缺乏。论文首次提出一个全面框架，将收集过程分解为四个增量步骤：Prompt Generation、Response Generation、Response Filtering 和 Human Labeling，从而确保高品质偏好数据的获取并减少对人类劳动的依赖。通过实验验证，该方法在不同阶段的数据上表现出色，提高了 RLHF 在对齐大型语言模型 (LLMs) 的效果。",
      "categories": [
        "cs.AI"
      ],
      "primary_category": "cs.AI",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2406.16486v1",
      "published_date": "2024-06-24 09:40:39 UTC",
      "updated_date": "2024-06-24 09:40:39 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-19T00:09:46.786125"
    },
    {
      "arxiv_id": "2406.16479v1",
      "title": "Emerging NeoHebbian Dynamics in Forward-Forward Learning: Implications for Neuromorphic Computing",
      "title_zh": "翻译失败",
      "authors": [
        "Erik B. Terres-Escudero",
        "Javier Del Ser",
        "Pablo García-Bringas"
      ],
      "abstract": "Advances in neural computation have predominantly relied on the gradient\nbackpropagation algorithm (BP). However, the recent shift towards\nnon-stationary data modeling has highlighted the limitations of this heuristic,\nexposing that its adaptation capabilities are far from those seen in biological\nbrains. Unlike BP, where weight updates are computed through a reverse error\npropagation path, Hebbian learning dynamics provide synaptic updates using only\ninformation within the layer itself. This has spurred interest in biologically\nplausible learning algorithms, hypothesized to overcome BP's shortcomings. In\nthis context, Hinton recently introduced the Forward-Forward Algorithm (FFA),\nwhich employs local learning rules for each layer and has empirically proven\nits efficacy in multiple data modeling tasks. In this work we argue that when\nemploying a squared Euclidean norm as a goodness function driving the local\nlearning, the resulting FFA is equivalent to a neo-Hebbian Learning Rule. To\nverify this result, we compare the training behavior of FFA in analog networks\nwith its Hebbian adaptation in spiking neural networks. Our experiments\ndemonstrate that both versions of FFA produce similar accuracy and latent\ndistributions. The findings herein reported provide empirical evidence linking\nbiological learning rules with currently used training algorithms, thus paving\nthe way towards extrapolating the positive outcomes from FFA to Hebbian\nlearning rules. Simultaneously, our results imply that analog networks trained\nunder FFA could be directly applied to neuromorphic computing, leading to\nreduced energy usage and increased computational speed.",
      "tldr_zh": "本论文探讨了 Forward-Forward Algorithm (FFA) 在使用平方欧氏范数作为好坏函数时的动态，证明其等价于 neo-Hebbian Learning Rule，这比传统 Backpropagation (BP) 算法更接近生物大脑的学习方式，能更好地适应非平稳数据。作者通过实验比较 FFA 在模拟网络和脉冲神经网络中的训练行为，发现二者表现出相似的准确性和潜在分布，为将 FFA 扩展到 Hebbian 学习规则提供了实证支持。这些结果暗示，FFA 训练的模拟网络可直接应用于 neuromorphic computing，实现能量消耗降低和计算速度提升。",
      "categories": [
        "cs.NE",
        "cs.AI"
      ],
      "primary_category": "cs.NE",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2406.16479v1",
      "published_date": "2024-06-24 09:33:56 UTC",
      "updated_date": "2024-06-24 09:33:56 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-19T00:10:02.960179"
    },
    {
      "arxiv_id": "2406.16473v2",
      "title": "D2SP: Dynamic Dual-Stage Purification Framework for Dual Noise Mitigation in Vision-based Affective Recognition",
      "title_zh": "翻译失败",
      "authors": [
        "Haoran Wang",
        "Xinji Mai",
        "Zeng Tao",
        "Xuan Tong",
        "Junxiong Lin",
        "Yan Wang",
        "Jiawen Yu",
        "Boyang Wang",
        "Shaoqi Yan",
        "Qing Zhao",
        "Ziheng Zhou",
        "Shuyong Gao",
        "Wenqiang Zhang"
      ],
      "abstract": "The contemporary state-of-the-art of Dynamic Facial Expression Recognition\n(DFER) technology facilitates remarkable progress by deriving emotional\nmappings of facial expressions from video content, underpinned by training on\nvoluminous datasets. Yet, the DFER datasets encompass a substantial volume of\nnoise data. Noise arises from low-quality captures that defy logical labeling,\nand instances that suffer from mislabeling due to annotation bias, engendering\ntwo principal types of uncertainty: the uncertainty regarding data usability\nand the uncertainty concerning label reliability. Addressing the two types of\nuncertainty, we have meticulously crafted a two-stage framework aiming at\n\\textbf{S}eeking \\textbf{C}ertain data \\textbf{I}n extensive \\textbf{U}ncertain\ndata (SCIU). This initiative aims to purge the DFER datasets of these\nuncertainties, thereby ensuring that only clean, verified data is employed in\ntraining processes. To mitigate the issue of low-quality samples, we introduce\nthe Coarse-Grained Pruning (CGP) stage, which assesses sample weights and\nprunes those deemed unusable due to their low weight. For samples with\nincorrect annotations, the Fine-Grained Correction (FGC) stage evaluates\nprediction stability to rectify mislabeled data. Moreover, SCIU is conceived as\na universally compatible, plug-and-play framework, tailored to integrate\nseamlessly with prevailing DFER methodologies. Rigorous experiments across\nprevalent DFER datasets and against numerous benchmark methods substantiates\nSCIU's capacity to markedly elevate performance metrics.",
      "tldr_zh": "本研究针对动态面部表情识别（DFER）中的噪声问题，包括低质量数据和标签错误导致的数据可用性不确定性及标签可靠性不确定性，提出了一种动态双阶段净化框架D2SP。框架包括Coarse-Grained Pruning (CGP)阶段，用于评估样本权重并删除低质量样本，以及Fine-Grained Correction (FGC)阶段，用于评估预测稳定性以修正错误标签。该框架作为通用即插即用模块，可无缝整合到现有DFER方法中，实验结果显示其在多个数据集上显著提升了性能指标。",
      "categories": [
        "cs.CV",
        "cs.AI"
      ],
      "primary_category": "cs.CV",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2406.16473v2",
      "published_date": "2024-06-24 09:25:02 UTC",
      "updated_date": "2024-11-06 02:17:05 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-19T00:10:10.738042"
    },
    {
      "arxiv_id": "2406.16464v5",
      "title": "InterCLIP-MEP: Interactive CLIP and Memory-Enhanced Predictor for Multi-modal Sarcasm Detection",
      "title_zh": "InterCLIP-MEP：交互式 CLIP 和记忆增强预测器用于多模态讽刺检测",
      "authors": [
        "Junjie Chen",
        "Hang Yu",
        "Subin Huang",
        "Sanmin Liu",
        "Linfeng Zhang"
      ],
      "abstract": "Sarcasm in social media, often expressed through text-image combinations,\nposes challenges for sentiment analysis and intention mining. Current\nmulti-modal sarcasm detection methods have been demonstrated to overly rely on\nspurious cues within the textual modality, revealing a limited ability to\ngenuinely identify sarcasm through nuanced text-image interactions. To solve\nthis problem, we propose InterCLIP-MEP, which introduces Interactive CLIP\n(InterCLIP) with an efficient training strategy to extract enriched text-image\nrepresentations by embedding cross-modal information directly into each\nencoder. Additionally, we design a Memory-Enhanced Predictor (MEP) with a\ndynamic dual-channel memory that stores valuable test sample knowledge during\ninference, acting as a non-parametric classifier for robust sarcasm\nrecognition. Experiments on two benchmarks demonstrate that InterCLIP-MEP\nachieves state-of-the-art performance, with significant accuracy and F1 score\nimprovements on MMSD and MMSD2.0. Our code is available at\nhttps://github.com/CoderChen01/InterCLIP-MEP.",
      "tldr_zh": "该论文针对社交媒体中多模态讽刺检测的问题，指出现有方法过度依赖文本中的虚假线索，无法有效捕捉文本-图像互动。作者提出 InterCLIP-MEP 框架，包括 Interactive CLIP (InterCLIP)，通过高效训练策略嵌入跨模态信息以提取丰富的文本-图像表示，以及 Memory-Enhanced Predictor (MEP)，利用动态双通道记忆存储测试样本知识作为非参数分类器，提升讽刺识别的鲁棒性。在 MMSD 和 MMSD2.0 基准测试中，InterCLIP-MEP 实现了最先进性能，显著提高了准确率和 F1 分数。",
      "categories": [
        "cs.CL",
        "cs.AI",
        "cs.CV"
      ],
      "primary_category": "cs.CL",
      "comment": "15 pages, 7 figures, 11 tables; Code and data are available at\n  https://github.com/CoderChen01/InterCLIP-MEP",
      "pdf_url": "http://arxiv.org/pdf/2406.16464v5",
      "published_date": "2024-06-24 09:13:42 UTC",
      "updated_date": "2024-12-16 04:13:38 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-19T00:10:33.763743"
    },
    {
      "arxiv_id": "2407.00081v1",
      "title": "Semantic Revolution from Communications to Orchestration for 6G: Challenges, Enablers, and Research Directions",
      "title_zh": "翻译失败",
      "authors": [
        "Masoud Shokrnezhad",
        "Hamidreza Mazandarani",
        "Tarik Taleb",
        "Jaeseung Song",
        "Richard Li"
      ],
      "abstract": "In the context of emerging 6G services, the realization of\neverything-to-everything interactions involving a myriad of physical and\ndigital entities presents a crucial challenge. This challenge is exacerbated by\nresource scarcity in communication infrastructures, necessitating innovative\nsolutions for effective service implementation. Exploring the potential of\nSemantic Communications (SemCom) to enhance point-to-point physical layer\nefficiency shows great promise in addressing this challenge. However, achieving\nefficient SemCom requires overcoming the significant hurdle of knowledge\nsharing between semantic decoders and encoders, particularly in the dynamic and\nnon-stationary environment with stringent end-to-end quality requirements. To\nbridge this gap in existing literature, this paper introduces the Knowledge\nBase Management And Orchestration (KB-MANO) framework. Rooted in the concepts\nof Computing-Network Convergence (CNC) and lifelong learning, KB-MANO is\ncrafted for the allocation of network and computing resources dedicated to\nupdating and redistributing KBs across the system. The primary objective is to\nminimize the impact of knowledge management activities on actual service\nprovisioning. A proof-of-concept is proposed to showcase the integration of\nKB-MANO with resource allocation in radio access networks. Finally, the paper\noffers insights into future research directions, emphasizing the transformative\npotential of semantic-oriented communication systems in the realm of 6G\ntechnology.",
      "tldr_zh": "这篇论文探讨了6G服务中万物互联带来的挑战，特别是通信基础设施资源稀缺的问题，并强调了Semantic Communications (SemCom)提升点对点物理层效率的潜力，但需解决知识共享的难题。为了应对这一难题，论文提出Knowledge Base Management And Orchestration (KB-MANO)框架，该框架基于Computing-Network Convergence (CNC)和终身学习，优化网络和计算资源的分配，以更新和分发知识库，同时最小化对服务提供的影响。论文还通过一个无线接入网络资源分配的概念证明展示框架的可行性，并为未来6G语义导向通信系统的研究提供方向。",
      "categories": [
        "cs.DC",
        "cs.AI",
        "cs.ET",
        "cs.LG",
        "cs.NI"
      ],
      "primary_category": "cs.DC",
      "comment": "Accepted at IEEE Network magazine special issue: Goal-oriented\n  Semantic Communication and Networking",
      "pdf_url": "http://arxiv.org/pdf/2407.00081v1",
      "published_date": "2024-06-24 09:04:09 UTC",
      "updated_date": "2024-06-24 09:04:09 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-19T00:10:37.998152"
    },
    {
      "arxiv_id": "2406.16455v1",
      "title": "Guardrails for avoiding harmful medical product recommendations and off-label promotion in generative AI models",
      "title_zh": "翻译失败",
      "authors": [
        "Daniel Lopez-Martinez"
      ],
      "abstract": "Generative AI (GenAI) models have demonstrated remarkable capabilities in a\nwide variety of medical tasks. However, as these models are trained using\ngeneralist datasets with very limited human oversight, they can learn uses of\nmedical products that have not been adequately evaluated for safety and\nefficacy, nor approved by regulatory agencies. Given the scale at which GenAI\nmay reach users, unvetted recommendations pose a public health risk. In this\nwork, we propose an approach to identify potentially harmful product\nrecommendations, and demonstrate it using a recent multimodal large language\nmodel.",
      "tldr_zh": "该论文探讨了生成式AI（GenAI）模型在医疗任务中的应用问题，特别是这些模型可能基于泛化数据集推荐未经监管机构批准的医疗产品，从而导致有害推荐和越界推广，构成公共健康风险。为了解决这一问题，研究提出了一种方法来识别潜在有害的产品推荐，并通过一个多模态大语言模型（multimodal large language model）进行了演示。该方法旨在为GenAI模型添加防护措施，确保医疗建议的安全性和合规性。",
      "categories": [
        "cs.AI"
      ],
      "primary_category": "cs.AI",
      "comment": "CVPR 2024 Responsible Generative AI (ReGenAI) workshop",
      "pdf_url": "http://arxiv.org/pdf/2406.16455v1",
      "published_date": "2024-06-24 08:50:26 UTC",
      "updated_date": "2024-06-24 08:50:26 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-19T00:10:45.995966"
    },
    {
      "arxiv_id": "2406.16453v2",
      "title": "Learning in Wilson-Cowan model for metapopulation",
      "title_zh": "翻译失败",
      "authors": [
        "Raffaele Marino",
        "Lorenzo Buffoni",
        "Lorenzo Chicchi",
        "Francesca Di Patti",
        "Diego Febbe",
        "Lorenzo Giambagli",
        "Duccio Fanelli"
      ],
      "abstract": "The Wilson-Cowan model for metapopulation, a Neural Mass Network Model,\ntreats different subcortical regions of the brain as connected nodes, with\nconnections representing various types of structural, functional, or effective\nneuronal connectivity between these regions. Each region comprises interacting\npopulations of excitatory and inhibitory cells, consistent with the standard\nWilson-Cowan model. By incorporating stable attractors into such a\nmetapopulation model's dynamics, we transform it into a learning algorithm\ncapable of achieving high image and text classification accuracy. We test it on\nMNIST and Fashion MNIST, in combination with convolutional neural networks, on\nCIFAR-10 and TF-FLOWERS, and, in combination with a transformer architecture\n(BERT), on IMDB, always showing high classification accuracy. These numerical\nevaluations illustrate that minimal modifications to the Wilson-Cowan model for\nmetapopulation can reveal unique and previously unobserved dynamics.",
      "tldr_zh": "本研究基于 Wilson-Cowan model for metapopulation（一种 Neural Mass Network Model），将脑部亚皮层区域视为相互连接的节点，每个节点包含兴奋和抑制细胞群，通过加入稳定吸引子，将其转化为一个高效的学习算法。实验在图像分类任务上结合卷积神经网络（CNN）测试了 MNIST、Fashion MNIST、CIFAR-10 和 TF-FLOWERS 数据集，以及在文本分类任务上结合 BERT 模型测试了 IMDB 数据集，均取得了高分类准确率。这些最小修改揭示了模型的独特动态，为脑部网络建模的学习应用提供了新见解。",
      "categories": [
        "q-bio.NC",
        "cond-mat.dis-nn",
        "cond-mat.stat-mech",
        "cs.AI",
        "cs.NE"
      ],
      "primary_category": "q-bio.NC",
      "comment": "Paper Accepted in Neural Computation (in press)",
      "pdf_url": "http://arxiv.org/pdf/2406.16453v2",
      "published_date": "2024-06-24 08:45:03 UTC",
      "updated_date": "2024-12-05 16:39:32 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-19T00:10:58.663784"
    },
    {
      "arxiv_id": "2406.16995v2",
      "title": "tcrLM: a lightweight protein language model for predicting T cell receptor and epitope binding specificity",
      "title_zh": "翻译失败",
      "authors": [
        "Xing Fang",
        "Chenpeng Yu",
        "Shiye Tian",
        "Hui Liu"
      ],
      "abstract": "The anti-cancer immune response relies on the bindings between T-cell\nreceptors (TCRs) and antigens, which elicits adaptive immunity to eliminate\ntumor cells. This ability of the immune system to respond to novel various\nneoantigens arises from the immense diversity of TCR repository. However, TCR\ndiversity poses a significant challenge on accurately predicting antigen-TCR\nbindings. In this study, we introduce a lightweight masked language model,\ntermed tcrLM, to address this challenge. Our approach involves randomly masking\nsegments of TCR sequences and training tcrLM to infer the masked segments,\nthereby enabling the extraction of expressive features from TCR sequences. To\nfurther enhance robustness, we incorporate virtual adversarial training into\ntcrLM. We construct the largest TCR CDR3 sequence set with more than 100\nmillion distinct sequences, and pretrain tcrLM on these sequences. The\npre-trained encoder is subsequently applied to predict TCR-antigen binding\nspecificity. We evaluate model performance on three test datasets: independent,\nexternal, and COVID-19 test set. The results demonstrate that tcrLM not only\nsurpasses existing TCR-antigen binding prediction methods, but also outperforms\nother mainstream protein language models. More interestingly, tcrLM effectively\ncaptures the biochemical properties and positional preference of amino acids\nwithin TCR sequences. Additionally, the predicted TCR-neoantigen binding scores\nindicates the immunotherapy responses and clinical outcomes in a melanoma\ncohort. These findings demonstrate the potential of tcrLM in predicting\nTCR-antigen binding specificity, with significant implications for advancing\nimmunotherapy and personalized medicine.",
      "tldr_zh": "本文提出 tcrLM，一种轻量级蛋白质语言模型，用于预测 T cell receptor (TCR) 与 epitope 的结合特异性，以应对 TCR 多样性带来的预测挑战。模型通过随机掩码 TCR 序列并结合 virtual adversarial training 在超过 1 亿独特 TCR CDR3 序列数据集上预训练，从而提取表达性特征。实验结果显示，tcrLM 在三个独立测试数据集上优于现有方法，并能有效捕捉氨基酸的生化特性和位置偏好，其预测分数与黑色素瘤患者的免疫治疗响应和临床结果相关，为推进免疫治疗和个性化医学提供了新工具。",
      "categories": [
        "q-bio.QM",
        "cs.AI"
      ],
      "primary_category": "q-bio.QM",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2406.16995v2",
      "published_date": "2024-06-24 08:36:40 UTC",
      "updated_date": "2024-12-04 14:33:44 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-19T00:11:12.979682"
    },
    {
      "arxiv_id": "2406.16437v3",
      "title": "Theory on Mixture-of-Experts in Continual Learning",
      "title_zh": "翻译失败",
      "authors": [
        "Hongbo Li",
        "Sen Lin",
        "Lingjie Duan",
        "Yingbin Liang",
        "Ness B. Shroff"
      ],
      "abstract": "Continual learning (CL) has garnered significant attention because of its\nability to adapt to new tasks that arrive over time. Catastrophic forgetting\n(of old tasks) has been identified as a major issue in CL, as the model adapts\nto new tasks. The Mixture-of-Experts (MoE) model has recently been shown to\neffectively mitigate catastrophic forgetting in CL, by employing a gating\nnetwork to sparsify and distribute diverse tasks among multiple experts.\nHowever, there is a lack of theoretical analysis of MoE and its impact on the\nlearning performance in CL. This paper provides the first theoretical results\nto characterize the impact of MoE in CL via the lens of overparameterized\nlinear regression tasks. We establish the benefit of MoE over a single expert\nby proving that the MoE model can diversify its experts to specialize in\ndifferent tasks, while its router learns to select the right expert for each\ntask and balance the loads across all experts. Our study further suggests an\nintriguing fact that the MoE in CL needs to terminate the update of the gating\nnetwork after sufficient training rounds to attain system convergence, which is\nnot needed in the existing MoE studies that do not consider the continual task\narrival. Furthermore, we provide explicit expressions for the expected\nforgetting and overall generalization error to characterize the benefit of MoE\nin the learning performance in CL. Interestingly, adding more experts requires\nadditional rounds before convergence, which may not enhance the learning\nperformance. Finally, we conduct experiments on both synthetic and real\ndatasets to extend these insights from linear models to deep neural networks\n(DNNs), which also shed light on the practical algorithm design for MoE in CL.",
      "tldr_zh": "本论文针对持续学习（Continual Learning, CL）中灾难性遗忘（Catastrophic Forgetting）问题，首次提供了Mixture-of-Experts (MoE) 模型的理论分析。研究通过过参数化线性回归任务（Overparameterized Linear Regression）证明，MoE模型能让专家多样化、专注于不同任务，同时门控网络（Gating Network）学习选择合适专家并平衡负载，但需在足够训练轮次后停止更新门控网络以实现系统收敛。论文还给出了预期遗忘（Expected Forgetting）和整体泛化误差（Generalization Error）的显式表达式，并通过合成和真实数据集实验验证了这些见解在深度神经网络（DNNs）中的适用性，表明添加更多专家可能需要更多轮次但不一定提升性能。",
      "categories": [
        "cs.LG",
        "cs.AI"
      ],
      "primary_category": "cs.LG",
      "comment": "This paper has been accepted by ICLR 2025 (Spotlight)",
      "pdf_url": "http://arxiv.org/pdf/2406.16437v3",
      "published_date": "2024-06-24 08:29:58 UTC",
      "updated_date": "2025-02-19 14:35:07 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-19T00:11:24.561090"
    },
    {
      "arxiv_id": "2406.16427v1",
      "title": "Dynamic Pseudo Label Optimization in Point-Supervised Nuclei Segmentation",
      "title_zh": "点监督细胞核分割中的动态伪标签优化",
      "authors": [
        "Ziyue Wang",
        "Ye Zhang",
        "Yifeng Wang",
        "Linghan Cai",
        "Yongbing Zhang"
      ],
      "abstract": "Deep learning has achieved impressive results in nuclei segmentation, but the\nmassive requirement for pixel-wise labels remains a significant challenge. To\nalleviate the annotation burden, existing methods generate pseudo masks for\nmodel training using point labels. However, the generated masks are inevitably\ndifferent from the ground truth, and these dissimilarities are not handled\nreasonably during the network training, resulting in the subpar performance of\nthe segmentation model. To tackle this issue, we propose a framework named\nDoNuSeg, enabling \\textbf{D}ynamic pseudo label \\textbf{O}ptimization in\npoint-supervised \\textbf{Nu}clei \\textbf{Seg}mentation. Specifically, DoNuSeg\ntakes advantage of class activation maps (CAMs) to adaptively capture regions\nwith semantics similar to annotated points. To leverage semantic diversity in\nthe hierarchical feature levels, we design a dynamic selection module to choose\nthe optimal one among CAMs from different encoder blocks as pseudo masks.\nMeanwhile, a CAM-guided contrastive module is proposed to further enhance the\naccuracy of pseudo masks. In addition to exploiting the semantic information\nprovided by CAMs, we consider location priors inherent to point labels,\ndeveloping a task-decoupled structure for effectively differentiating nuclei.\nExtensive experiments demonstrate that DoNuSeg outperforms state-of-the-art\npoint-supervised methods. The code is available at\nhttps://github.com/shinning0821/MICCAI24-DoNuSeg.",
      "tldr_zh": "该论文针对点监督细胞核分割中伪标签生成与真实标签差异导致模型性能不佳的问题，提出了一种名为 DoNuSeg 的框架，用于动态伪标签优化。DoNuSeg 利用类激活映射 (CAMs) 适应性捕获与标注点相似的语义区域，并设计动态选择模块从不同编码器块中选择最佳伪掩码，同时引入 CAM-guided contrastive module 和任务解耦结构来利用位置先验，提升伪标签的准确性和区分能力。实验结果表明，DoNuSeg 在点监督场景下优于最先进方法，显著提高了细胞核分割的性能。",
      "categories": [
        "cs.CV",
        "cs.AI"
      ],
      "primary_category": "cs.CV",
      "comment": "early accepted by MICCAI2024",
      "pdf_url": "http://arxiv.org/pdf/2406.16427v1",
      "published_date": "2024-06-24 08:20:53 UTC",
      "updated_date": "2024-06-24 08:20:53 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-19T00:11:39.061097"
    },
    {
      "arxiv_id": "2406.16426v3",
      "title": "Fault Detection for agents on power grid topology optimization: A Comprehensive analysis",
      "title_zh": "针对电力网格拓扑优化中代理的故障检测：全面分析",
      "authors": [
        "Malte Lehna",
        "Mohamed Hassouna",
        "Dmitry Degtyar",
        "Sven Tomforde",
        "Christoph Scholz"
      ],
      "abstract": "Optimizing the topology of transmission networks using Deep Reinforcement\nLearning (DRL) has increasingly come into focus. Various DRL agents have been\nproposed, which are mostly benchmarked on the Grid2Op environment from the\nLearning to Run a Power Network (L2RPN) challenges. The environments have many\nadvantages with their realistic grid scenarios and underlying power flow\nbackends. However, the interpretation of agent survival or failure is not\nalways clear, as there are a variety of potential causes. In this work, we\nfocus on the failures of the power grid simulation to identify patterns and\ndetect them in advance. We collect the failed scenarios of three different\nagents on the WCCI 2022 L2RPN environment, totaling about 40k data points. By\nclustering, we are able to detect five distinct clusters, identifying common\nfailure types. Further, we propose a multi-class prediction approach to detect\nfailures beforehand and evaluate five different prediction models. Here, the\nLight Gradient-Boosting Machine (LightGBM) shows the best failure prediction\nperformance, with an accuracy of 82%. It also accurately classifies whether a\nthe grid survives or fails in 87% of cases. Finally, we provide a detailed\nfeature importance analysis that identifies critical features and regions in\nthe grid.",
      "tldr_zh": "本文通过全面分析在电力网格拓扑优化中使用 Deep Reinforcement Learning (DRL) 代理的故障检测问题，聚焦于 Grid2Op 环境下的失败场景。研究者收集了三个代理在 WCCI 2022 L2RPN 环境中的约 40k 失败数据点，并通过聚类方法识别出五种常见失败类型。接着，提出了一种多类预测模型，并评估了五种模型，其中 Light Gradient-Boosting Machine (LightGBM) 表现最佳，故障预测准确率达 82%，并在 87% 的情况下准确分类电网是否存活或失败。最后，该研究提供了详细的特征重要性分析，突出了关键特征和电网区域，以提升代理的可靠性和可解释性。",
      "categories": [
        "cs.LG",
        "cs.AI",
        "cs.SY",
        "eess.SY"
      ],
      "primary_category": "cs.LG",
      "comment": "11 Pages plus references and appendix. The appendix consist of\n  additional material of the paper and is not included in the initial\n  submission. The paper was presented at the ECML workshop ML4SPS",
      "pdf_url": "http://arxiv.org/pdf/2406.16426v3",
      "published_date": "2024-06-24 08:20:43 UTC",
      "updated_date": "2024-09-17 14:54:29 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-19T00:11:52.309726"
    },
    {
      "arxiv_id": "2406.16424v2",
      "title": "Memory-Enhanced Neural Solvers for Efficient Adaptation in Combinatorial Optimization",
      "title_zh": "记忆",
      "authors": [
        "Felix Chalumeau",
        "Refiloe Shabe",
        "Noah De Nicola",
        "Arnu Pretorius",
        "Thomas D. Barrett",
        "Nathan Grinsztajn"
      ],
      "abstract": "Combinatorial Optimization is crucial to numerous real-world applications,\nyet still presents challenges due to its (NP-)hard nature. Amongst existing\napproaches, heuristics often offer the best trade-off between quality and\nscalability, making them suitable for industrial use. While Reinforcement\nLearning (RL) offers a flexible framework for designing heuristics, its\nadoption over handcrafted heuristics remains incomplete within industrial\nsolvers. Existing learned methods still lack the ability to adapt to specific\ninstances and fully leverage the available computational budget. The current\nbest methods either rely on a collection of pre-trained policies, or on\ndata-inefficient fine-tuning; hence failing to fully utilize newly available\ninformation within the constraints of the budget. In response, we present\nMEMENTO, an approach that leverages memory to improve the adaptation of neural\nsolvers at inference time. MEMENTO enables updating the action distribution\ndynamically based on the outcome of previous decisions. We validate its\neffectiveness on benchmark problems, in particular Traveling Salesman and\nCapacitated Vehicle Routing, demonstrating its superiority over tree-search and\npolicy-gradient fine-tuning; and showing it can be zero-shot combined with\ndiversity-based solvers. We successfully train all RL auto-regressive solvers\non large instances, and show that MEMENTO can scale and is data-efficient.\nOverall, MEMENTO enables to push the state-of-the-art on 11 out of 12 evaluated\ntasks.",
      "tldr_zh": "该研究针对组合优化问题（Combinatorial Optimization）的NP-hard挑战，提出了一种名为MEMENTO的记忆增强神经求解器，以提升求解器的适应性和计算资源利用效率。MEMENTO通过动态更新动作分布基于先前决策的结果，实现对特定实例的实时适应，同时避免了传统强化学习（RL）方法的预训练依赖和数据低效问题。在Traveling Salesman Problem (TSP)和Capacitated Vehicle Routing Problem (CVRP)等基准任务上，实验证明MEMENTO优于树搜索和策略梯度微调方法，并在12个任务中在11个上达到最先进水平，展示了其可扩展性和数据高效性。",
      "categories": [
        "cs.AI",
        "cs.LG"
      ],
      "primary_category": "cs.AI",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2406.16424v2",
      "published_date": "2024-06-24 08:18:19 UTC",
      "updated_date": "2024-10-07 15:33:37 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-19T00:12:02.504983"
    },
    {
      "arxiv_id": "2406.16422v1",
      "title": "Exploring Cross-Domain Few-Shot Classification via Frequency-Aware Prompting",
      "title_zh": "翻译失败",
      "authors": [
        "Tiange Zhang",
        "Qing Cai",
        "Feng Gao",
        "Lin Qi",
        "Junyu Dong"
      ],
      "abstract": "Cross-Domain Few-Shot Learning has witnessed great stride with the\ndevelopment of meta-learning. However, most existing methods pay more attention\nto learning domain-adaptive inductive bias (meta-knowledge) through\nfeature-wise manipulation or task diversity improvement while neglecting the\nphenomenon that deep networks tend to rely more on high-frequency cues to make\nthe classification decision, which thus degenerates the robustness of learned\ninductive bias since high-frequency information is vulnerable and easy to be\ndisturbed by noisy information. Hence in this paper, we make one of the first\nattempts to propose a Frequency-Aware Prompting method with mutual attention\nfor Cross-Domain Few-Shot classification, which can let networks simulate the\nhuman visual perception of selecting different frequency cues when facing new\nrecognition tasks. Specifically, a frequency-aware prompting mechanism is first\nproposed, in which high-frequency components of the decomposed source image are\nswitched either with normal distribution sampling or zeroing to get\nfrequency-aware augment samples. Then, a mutual attention module is designed to\nlearn generalizable inductive bias under CD-FSL settings. More importantly, the\nproposed method is a plug-and-play module that can be directly applied to most\noff-the-shelf CD-FLS methods. Experimental results on CD-FSL benchmarks\ndemonstrate the effectiveness of our proposed method as well as robustly\nimprove the performance of existing CD-FLS methods. Resources at\nhttps://github.com/tinkez/FAP_CDFSC.",
      "tldr_zh": "这篇论文探讨了 Cross-Domain Few-Shot Classification 的挑战，指出现有方法在学习领域自适应归纳偏差时忽略了深度网络对高频信息的过度依赖，导致模型鲁棒性下降。作者提出 Frequency-Aware Prompting 方法，包括一个频率感知提示机制（通过切换高频组件生成增强样本）和 mutual attention module，以模拟人类视觉感知并学习可泛化的归纳偏差。该方法作为插件式模块，实验在 CD-FSL 基准上证明了其有效性，并显著提升了现有方法的性能。",
      "categories": [
        "cs.CV",
        "cs.AI"
      ],
      "primary_category": "cs.CV",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2406.16422v1",
      "published_date": "2024-06-24 08:14:09 UTC",
      "updated_date": "2024-06-24 08:14:09 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-19T00:12:14.023701"
    },
    {
      "arxiv_id": "2406.16994v1",
      "title": "Quantum Multi-Agent Reinforcement Learning for Cooperative Mobile Access in Space-Air-Ground Integrated Networks",
      "title_zh": "翻译失败",
      "authors": [
        "Gyu Seon Kim",
        "Yeryeong Cho",
        "Jaehyun Chung",
        "Soohyun Park",
        "Soyi Jung",
        "Zhu Han",
        "Joongheon Kim"
      ],
      "abstract": "Achieving global space-air-ground integrated network (SAGIN) access only with\nCubeSats presents significant challenges such as the access sustainability\nlimitations in specific regions (e.g., polar regions) and the energy efficiency\nlimitations in CubeSats. To tackle these problems, high-altitude long-endurance\nunmanned aerial vehicles (HALE-UAVs) can complement these CubeSat shortcomings\nfor providing cooperatively global access sustainability and energy efficiency.\nHowever, as the number of CubeSats and HALE-UAVs, increases, the scheduling\ndimension of each ground station (GS) increases. As a result, each GS can fall\ninto the curse of dimensionality, and this challenge becomes one major hurdle\nfor efficient global access. Therefore, this paper provides a quantum\nmulti-agent reinforcement Learning (QMARL)-based method for scheduling between\nGSs and CubeSats/HALE-UAVs in order to improve global access availability and\nenergy efficiency. The main reason why the QMARL-based scheduler can be\nbeneficial is that the algorithm facilitates a logarithmic-scale reduction in\nscheduling action dimensions, which is one critical feature as the number of\nCubeSats and HALE-UAVs expands. Additionally, individual GSs have different\ntraffic demands depending on their locations and characteristics, thus it is\nessential to provide differentiated access services. The superiority of the\nproposed scheduler is validated through data-intensive experiments in realistic\nCubeSat/HALE-UAV settings.",
      "tldr_zh": "该论文针对太空-空中-地面一体化网络（SAGIN）中CubeSats的访问可持续性和能源效率问题，提出了一种量子多智能体强化学习（QMARL）方法，用于协调地面站（GS）与CubeSats和HALE-UAVs的调度，以提升全球访问可用性和能源效率。QMARL算法通过对调度动作维度的对数级减少，缓解了设备数量增加带来的维度诅咒，并支持根据GS的交通需求提供差异化服务。实验结果在真实CubeSat/HALE-UAV设置中验证了该方法的优越性，展示了其在大规模网络中的实际应用潜力。",
      "categories": [
        "eess.SP",
        "cs.AI"
      ],
      "primary_category": "eess.SP",
      "comment": "17 pages, 22 figures",
      "pdf_url": "http://arxiv.org/pdf/2406.16994v1",
      "published_date": "2024-06-24 08:12:04 UTC",
      "updated_date": "2024-06-24 08:12:04 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-19T00:12:26.223746"
    },
    {
      "arxiv_id": "2406.16388v1",
      "title": "PenSLR: Persian end-to-end Sign Language Recognition Using Ensembling",
      "title_zh": "翻译失败",
      "authors": [
        "Amirparsa Salmankhah",
        "Amirreza Rajabi",
        "Negin Kheirmand",
        "Ali Fadaeimanesh",
        "Amirreza Tarabkhah",
        "Amirreza Kazemzadeh",
        "Hamed Farbeh"
      ],
      "abstract": "Sign Language Recognition (SLR) is a fast-growing field that aims to fill the\ncommunication gaps between the hearing-impaired and people without hearing\nloss. Existing solutions for Persian Sign Language (PSL) are limited to\nword-level interpretations, underscoring the need for more advanced and\ncomprehensive solutions. Moreover, previous work on other languages mainly\nfocuses on manipulating the neural network architectures or hardware\nconfigurations instead of benefiting from the aggregated results of multiple\nmodels. In this paper, we introduce PenSLR, a glove-based sign language system\nconsisting of an Inertial Measurement Unit (IMU) and five flexible sensors\npowered by a deep learning framework capable of predicting variable-length\nsequences. We achieve this in an end-to-end manner by leveraging the\nConnectionist Temporal Classification (CTC) loss function, eliminating the need\nfor segmentation of input signals. To further enhance its capabilities, we\npropose a novel ensembling technique by leveraging a multiple sequence\nalignment algorithm known as Star Alignment. Furthermore, we introduce a new\nPSL dataset, including 16 PSL signs with more than 3000 time-series samples in\ntotal. We utilize this dataset to evaluate the performance of our system based\non four word-level and sentence-level metrics. Our evaluations show that PenSLR\nachieves a remarkable word accuracy of 94.58% and 96.70% in subject-independent\nand subject-dependent setups, respectively. These achievements are attributable\nto our ensembling algorithm, which not only boosts the word-level performance\nby 0.51% and 1.32% in the respective scenarios but also yields significant\nenhancements of 1.46% and 4.00%, respectively, in sentence-level accuracy.",
      "tldr_zh": "该研究提出PenSLR，一种基于Inertial Measurement Unit (IMU)和柔性传感器的端到端波斯语手语识别系统，旨在填补听障人士与正常人群的沟通鸿沟。系统利用Connectionist Temporal Classification (CTC)损失函数处理可变长序列，并引入Star Alignment算法进行模型集成，以提升预测准确性。研究者还发布了一个新数据集，包含16个波斯语手语符号和超过3000个时间序列样本。实验结果显示，PenSLR在主体无关和主体相关设置下分别实现94.58%和96.70%的词准确率，集成算法进一步提升了词级和句子级性能。",
      "categories": [
        "cs.HC",
        "cs.AI"
      ],
      "primary_category": "cs.HC",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2406.16388v1",
      "published_date": "2024-06-24 07:59:34 UTC",
      "updated_date": "2024-06-24 07:59:34 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-19T00:12:38.082147"
    },
    {
      "arxiv_id": "2406.16386v3",
      "title": "Automatically Generating UI Code from Screenshot: A Divide-and-Conquer-Based Approach",
      "title_zh": "翻译失败",
      "authors": [
        "Yuxuan Wan",
        "Chaozheng Wang",
        "Yi Dong",
        "Wenxuan Wang",
        "Shuqing Li",
        "Yintong Huo",
        "Michael R. Lyu"
      ],
      "abstract": "Websites are critical in today's digital world, with over 1.11 billion\ncurrently active and approximately 252,000 new sites launched daily. Converting\nwebsite layout design into functional UI code is a time-consuming yet\nindispensable step of website development. Manual methods of converting visual\ndesigns into functional code present significant challenges, especially for\nnon-experts. To explore automatic design-to-code solutions, we first conduct a\nmotivating study on GPT-4o and identify three types of issues in generating UI\ncode: element omission, element distortion, and element misarrangement. We\nfurther reveal that a focus on smaller visual segments can help multimodal\nlarge language models (MLLMs) mitigate these failures in the generation\nprocess.\n  In this paper, we propose DCGen, a divide-and-conquer-based approach to\nautomate the translation of webpage design to UI code. DCGen starts by dividing\nscreenshots into manageable segments, generating code for each segment, and\nthen reassembling them into complete UI code for the entire screenshot. We\nconduct extensive testing with a dataset comprised of real-world websites and\nvarious MLLMs and demonstrate that DCGen achieves up to a 15% improvement in\nvisual similarity and 8% in code similarity for large input images. Human\nevaluations show that DCGen can help developers implement webpages\nsignificantly faster and more similar to the UI designs. To the best of our\nknowledge, DCGen is the first segment-aware MLLM-based approach for generating\nUI code directly from screenshots.",
      "tldr_zh": "本研究针对从网站截图自动生成 UI 代码的挑战，分析了 GPT-4o 在此过程中的问题，包括元素遗漏、元素扭曲和元素 misarrangement，并发现聚焦于较小视觉片段可帮助 MLLMs 缓解这些问题。论文提出 DCGen，一种基于 Divide-and-Conquer 的方法，通过将截图分成可管理片段、为每个片段生成代码并重新组装，实现了高效的网页设计到代码转换。实验结果显示，DCGen 在真实网站数据集上使视觉相似度提高高达 15%、代码相似度提高 8%，并经人类评估证实能显著加速开发者实现网页，且更忠实于原 UI 设计，这是有史以来首个基于片段的 MLLM 方法。",
      "categories": [
        "cs.SE",
        "cs.AI"
      ],
      "primary_category": "cs.SE",
      "comment": "Accepted by FSE 2025",
      "pdf_url": "http://arxiv.org/pdf/2406.16386v3",
      "published_date": "2024-06-24 07:58:36 UTC",
      "updated_date": "2025-04-25 15:12:34 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-19T00:12:50.421018"
    },
    {
      "arxiv_id": "2406.17732v1",
      "title": "EMVD dataset: a dataset of extreme vocal distortion techniques used in heavy metal",
      "title_zh": "EMVD 数据集：重金属中使用的极端声乐失真技术数据集",
      "authors": [
        "Modan Tailleur",
        "Julien Pinquier",
        "Laurent Millot",
        "Corsin Vogel",
        "Mathieu Lagrange"
      ],
      "abstract": "In this paper, we introduce the Extreme Metal Vocals Dataset, which comprises\na collection of recordings of extreme vocal techniques performed within the\nrealm of heavy metal music. The dataset consists of 760 audio excerpts of 1\nsecond to 30 seconds long, totaling about 100 min of audio material, roughly\ncomposed of 60 minutes of distorted voices and 40 minutes of clear voice\nrecordings. These vocal recordings are from 27 different singers and are\nprovided without accompanying musical instruments or post-processing effects.\nThe distortion taxonomy within this dataset encompasses four distinct\ndistortion techniques and three vocal effects, all performed in different pitch\nranges. Performance of a state-of-the-art deep learning model is evaluated for\ntwo different classification tasks related to vocal techniques, demonstrating\nthe potential of this resource for the audio processing community.",
      "tldr_zh": "本论文引入了 EMVD dataset，这是一个专为重金属音乐设计的音频数据集，包含 760 个极端 vocal 扭曲技巧的录音片段，总时长约 100 分钟（其中 60 分钟扭曲声音和 40 分钟清晰声音），由 27 个不同歌手录制，并排除伴奏或后期效果。数据集的扭曲分类涵盖四种 distinct 扭曲技巧和三种 vocal 效果，在不同 pitch ranges 内进行。实验评估了 state-of-the-art 深度学习模型在两个 vocal 技巧相关分类任务上的性能，展示了该资源对音频处理社区的潜在价值。",
      "categories": [
        "cs.SD",
        "cs.AI",
        "physics.class-ph"
      ],
      "primary_category": "cs.SD",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2406.17732v1",
      "published_date": "2024-06-24 07:50:52 UTC",
      "updated_date": "2024-06-24 07:50:52 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-19T00:13:02.795012"
    },
    {
      "arxiv_id": "2406.16377v1",
      "title": "On the Transformations across Reward Model, Parameter Update, and In-Context Prompt",
      "title_zh": "翻译失败",
      "authors": [
        "Deng Cai",
        "Huayang Li",
        "Tingchen Fu",
        "Siheng Li",
        "Weiwen Xu",
        "Shuaiyi Li",
        "Bowen Cao",
        "Zhisong Zhang",
        "Xinting Huang",
        "Leyang Cui",
        "Yan Wang",
        "Lemao Liu",
        "Taro Watanabe",
        "Shuming Shi"
      ],
      "abstract": "Despite the general capabilities of pre-trained large language models (LLMs),\nthey still need further adaptation to better serve practical applications. In\nthis paper, we demonstrate the interchangeability of three popular and distinct\nadaptation tools: parameter updating, reward modeling, and in-context\nprompting. This interchangeability establishes a triangular framework with six\ntransformation directions, each of which facilitates a variety of applications.\nOur work offers a holistic view that unifies numerous existing studies and\nsuggests potential research directions. We envision our work as a useful\nroadmap for future research on LLMs.",
      "tldr_zh": "本研究探讨了大型语言模型 (LLMs) 适应实际应用的三个关键工具——参数更新 (parameter updating)、奖励建模 (reward modeling) 和上下文提示 (in-context prompting)——之间的互换性。通过建立一个三角框架和六个转换方向，论文展示了这些工具如何相互转换并支持多种应用。该工作统一了现有研究，提供了一个全面视角，并为未来 LLM 研究指出了潜在的方向。",
      "categories": [
        "cs.CL",
        "cs.AI"
      ],
      "primary_category": "cs.CL",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2406.16377v1",
      "published_date": "2024-06-24 07:42:32 UTC",
      "updated_date": "2024-06-24 07:42:32 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-19T00:13:12.354022"
    },
    {
      "arxiv_id": "2406.16992v1",
      "title": "Make Graph Neural Networks Great Again: A Generic Integration Paradigm of Topology-Free Patterns for Traffic Speed Prediction",
      "title_zh": "翻译失败",
      "authors": [
        "Yicheng Zhou",
        "Pengfei Wang",
        "Hao Dong",
        "Denghui Zhang",
        "Dingqi Yang",
        "Yanjie Fu",
        "Pengyang Wang"
      ],
      "abstract": "Urban traffic speed prediction aims to estimate the future traffic speed for\nimproving urban transportation services. Enormous efforts have been made to\nexploit Graph Neural Networks (GNNs) for modeling spatial correlations and\ntemporal dependencies of traffic speed evolving patterns, regularized by graph\ntopology.While achieving promising results, current traffic speed prediction\nmethods still suffer from ignoring topology-free patterns, which cannot be\ncaptured by GNNs. To tackle this challenge, we propose a generic model for\nenabling the current GNN-based methods to preserve topology-free patterns.\nSpecifically, we first develop a Dual Cross-Scale Transformer (DCST)\narchitecture, including a Spatial Transformer and a Temporal Transformer, to\npreserve the cross-scale topology-free patterns and associated dynamics,\nrespectively. Then, to further integrate both topology-regularized/-free\npatterns, we propose a distillation-style learning framework, in which the\nexisting GNN-based methods are considered as the teacher model, and the\nproposed DCST architecture is considered as the student model. The teacher\nmodel would inject the learned topology-regularized patterns into the student\nmodel for integrating topology-free patterns. The extensive experimental\nresults demonstrated the effectiveness of our methods.",
      "tldr_zh": "该论文针对城市交通速度预测问题，指出现有 Graph Neural Networks (GNNs) 方法依赖图拓扑建模空间相关性和时间依赖性，但忽略了 topology-free patterns，导致预测不全面。作者提出一个通用模型，通过 Dual Cross-Scale Transformer (DCST) 架构（包括 Spatial Transformer 和 Temporal Transformer）来保留跨尺度的 topology-free patterns 及其动态变化。进一步采用蒸馏式学习框架，将现有 GNNs 作为 teacher model，将 topology-regularized patterns 注入 DCST student model，实现两者的整合。实验结果证明，该方法显著提升了预测性能。",
      "categories": [
        "cs.LG",
        "cs.AI"
      ],
      "primary_category": "cs.LG",
      "comment": "Accepted to IJCAI 2024",
      "pdf_url": "http://arxiv.org/pdf/2406.16992v1",
      "published_date": "2024-06-24 07:32:58 UTC",
      "updated_date": "2024-06-24 07:32:58 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-19T00:13:26.202281"
    },
    {
      "arxiv_id": "2406.16357v1",
      "title": "Towards Lightweight Graph Neural Network Search with Curriculum Graph Sparsification",
      "title_zh": "翻译失败",
      "authors": [
        "Beini Xie",
        "Heng Chang",
        "Ziwei Zhang",
        "Zeyang Zhang",
        "Simin Wu",
        "Xin Wang",
        "Yuan Meng",
        "Wenwu Zhu"
      ],
      "abstract": "Graph Neural Architecture Search (GNAS) has achieved superior performance on\nvarious graph-structured tasks. However, existing GNAS studies overlook the\napplications of GNAS in resource-constraint scenarios. This paper proposes to\ndesign a joint graph data and architecture mechanism, which identifies\nimportant sub-architectures via the valuable graph data. To search for optimal\nlightweight Graph Neural Networks (GNNs), we propose a Lightweight Graph Neural\nArchitecture Search with Graph SparsIfication and Network Pruning (GASSIP)\nmethod. In particular, GASSIP comprises an operation-pruned architecture search\nmodule to enable efficient lightweight GNN search. Meanwhile, we design a novel\ncurriculum graph data sparsification module with an architecture-aware\nedge-removing difficulty measurement to help select optimal sub-architectures.\nWith the aid of two differentiable masks, we iteratively optimize these two\nmodules to efficiently search for the optimal lightweight architecture.\nExtensive experiments on five benchmarks demonstrate the effectiveness of\nGASSIP. Particularly, our method achieves on-par or even higher node\nclassification performance with half or fewer model parameters of searched GNNs\nand a sparser graph.",
      "tldr_zh": "这篇论文针对资源受限场景，提出了一种轻量级 Graph Neural Architecture Search (GNAS) 方法，名为 GASSIP，以优化 Graph Neural Networks (GNNs) 的搜索过程。GASSIP 包括操作修剪的架构搜索模块和课程图数据稀疏化模块，后者通过架构感知的边移除难度测量来选择最优子架构，并使用两个可微分掩码进行迭代优化。实验结果显示，在五个基准数据集上，GASSIP 实现了与基线模型相当或更高的节点分类性能，同时将模型参数减少一半或更少，并使图结构更稀疏。",
      "categories": [
        "cs.LG",
        "cs.AI",
        "cs.SI"
      ],
      "primary_category": "cs.LG",
      "comment": "Accepted by KDD 2024. The two first authors made equal contributions",
      "pdf_url": "http://arxiv.org/pdf/2406.16357v1",
      "published_date": "2024-06-24 06:53:37 UTC",
      "updated_date": "2024-06-24 06:53:37 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-19T00:13:39.656772"
    },
    {
      "arxiv_id": "2406.16346v1",
      "title": "Directed Domain Fine-Tuning: Tailoring Separate Modalities for Specific Training Tasks",
      "title_zh": "翻译失败",
      "authors": [
        "Daniel Wen",
        "Nafisa Hussain"
      ],
      "abstract": "Large language models (LLMs) and large visual language models (LVLMs) have\nbeen at the forefront of the artificial intelligence field, particularly for\ntasks like text generation, video captioning, and question-answering.\nTypically, it is more applicable to train these models on broader knowledge\nbases or datasets to increase generalizability, learn relationships between\ntopics, and recognize patterns. Instead, we propose to provide instructional\ndatasets specific to the task of each modality within a distinct domain and\nthen fine-tune the parameters of the model using LORA. With our approach, we\ncan eliminate all noise irrelevant to the given task while also ensuring that\nthe model generates with enhanced precision. For this work, we use Video-LLaVA\nto generate recipes given cooking videos without transcripts. Video-LLaVA's\nmultimodal architecture allows us to provide cooking images to its image\nencoder, cooking videos to its video encoder, and general cooking questions to\nits text encoder. Thus, we aim to remove all noise unrelated to cooking while\nimproving our model's capabilities to generate specific ingredient lists and\ndetailed instructions. As a result, our approach to fine-tuning Video-LLaVA\nleads to gains over the baseline Video-LLaVA by 2% on the YouCook2 dataset.\nWhile this may seem like a marginal increase, our model trains on an image\ninstruction dataset 2.5% the size of Video-LLaVA's and a video instruction\ndataset 23.76% of Video-LLaVA's.",
      "tldr_zh": "本研究提出了一种名为Directed Domain Fine-Tuning的方法，用于针对特定训练任务定制不同模态的模型参数。该方法通过为每个模态提供特定领域的指令数据集，并使用LORA进行微调，旨在消除任务无关噪声并提升生成精度。在实验中，研究者应用此方法到Video-LLaVA模型上，用于从无转录的烹饪视频生成食谱，结果在YouCook2数据集上比基线模型提高了2%的性能，尽管训练数据集规模更小（图像指令数据集为Video-LLaVA的2.5%，视频指令数据集为23.76%）。这种方法展示了在LLMs和LVLMs领域中，针对性微调可以实现高效的模型优化。",
      "categories": [
        "cs.CV",
        "cs.AI",
        "F.2.2; I.2.7"
      ],
      "primary_category": "cs.CV",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2406.16346v1",
      "published_date": "2024-06-24 06:39:02 UTC",
      "updated_date": "2024-06-24 06:39:02 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-19T00:13:51.072852"
    },
    {
      "arxiv_id": "2406.16333v1",
      "title": "Prompt-Consistency Image Generation (PCIG): A Unified Framework Integrating LLMs, Knowledge Graphs, and Controllable Diffusion Models",
      "title_zh": "翻译失败",
      "authors": [
        "Yichen Sun",
        "Zhixuan Chu",
        "Zhan Qin",
        "Kui Ren"
      ],
      "abstract": "The rapid advancement of Text-to-Image(T2I) generative models has enabled the\nsynthesis of high-quality images guided by textual descriptions. Despite this\nsignificant progress, these models are often susceptible in generating contents\nthat contradict the input text, which poses a challenge to their reliability\nand practical deployment. To address this problem, we introduce a novel\ndiffusion-based framework to significantly enhance the alignment of generated\nimages with their corresponding descriptions, addressing the inconsistency\nbetween visual output and textual input. Our framework is built upon a\ncomprehensive analysis of inconsistency phenomena, categorizing them based on\ntheir manifestation in the image. Leveraging a state-of-the-art large language\nmodule, we first extract objects and construct a knowledge graph to predict the\nlocations of these objects in potentially generated images. We then integrate a\nstate-of-the-art controllable image generation model with a visual text\ngeneration module to generate an image that is consistent with the original\nprompt, guided by the predicted object locations. Through extensive experiments\non an advanced multimodal hallucination benchmark, we demonstrate the efficacy\nof our approach in accurately generating the images without the inconsistency\nwith the original prompt. The code can be accessed via\nhttps://github.com/TruthAI-Lab/PCIG.",
      "tldr_zh": "本文提出Prompt-Consistency Image Generation (PCIG)框架，通过整合LLMs、Knowledge Graphs和Controllable Diffusion Models，解决Text-to-Image (T2I)生成模型中图像与文本不一致的问题。框架首先利用LLMs提取对象并构建Knowledge Graphs来预测对象在图像中的位置，然后结合可控图像生成模型和视觉文本生成模块，确保生成的图像与原始提示高度一致。在多模态幻觉基准上的实验显示，该方法显著提升了图像生成准确性，避免了不一致现象，并提供了开源代码以供进一步验证。",
      "categories": [
        "cs.CV",
        "cs.AI"
      ],
      "primary_category": "cs.CV",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2406.16333v1",
      "published_date": "2024-06-24 06:12:16 UTC",
      "updated_date": "2024-06-24 06:12:16 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-19T00:14:03.489092"
    },
    {
      "arxiv_id": "2406.16990v2",
      "title": "AND: Audio Network Dissection for Interpreting Deep Acoustic Models",
      "title_zh": "翻译失败",
      "authors": [
        "Tung-Yu Wu",
        "Yu-Xiang Lin",
        "Tsui-Wei Weng"
      ],
      "abstract": "Neuron-level interpretations aim to explain network behaviors and properties\nby investigating neurons responsive to specific perceptual or structural input\npatterns. Although there is emerging work in the vision and language domains,\nnone is explored for acoustic models. To bridge the gap, we introduce\n$\\textit{AND}$, the first $\\textbf{A}$udio $\\textbf{N}$etwork\n$\\textbf{D}$issection framework that automatically establishes natural language\nexplanations of acoustic neurons based on highly-responsive audio.\n$\\textit{AND}$ features the use of LLMs to summarize mutual acoustic features\nand identities among audio. Extensive experiments are conducted to verify\n$\\textit{AND}$'s precise and informative descriptions. In addition, we\ndemonstrate a potential use of $\\textit{AND}$ for audio machine unlearning by\nconducting concept-specific pruning based on the generated descriptions.\nFinally, we highlight two acoustic model behaviors with analysis by\n$\\textit{AND}$: (i) models discriminate audio with a combination of basic\nacoustic features rather than high-level abstract concepts; (ii) training\nstrategies affect model behaviors and neuron interpretability -- supervised\ntraining guides neurons to gradually narrow their attention, while\nself-supervised learning encourages neurons to be polysemantic for exploring\nhigh-level features.",
      "tldr_zh": "该论文引入了 AND（Audio Network Dissection）框架，这是首个针对深层声学模型的神经元级解释工具，用于通过分析对特定音频模式高度响应的神经元，自动生成自然语言解释。AND 利用大型语言模型（LLMs）来总结音频之间的共同特征和身份，从而提供精确且信息丰富的描述。实验验证了框架的有效性，并展示了其在音频机器遗忘（audio machine unlearning）中的应用，例如基于生成描述进行概念特定修剪。此外，分析揭示了声学模型的行为特点：模型倾向于使用基本声学特征的组合而非高级抽象概念来区分音频，且训练策略（如监督训练或自监督学习）会影响神经元的关注范围和多义性。",
      "categories": [
        "cs.SD",
        "cs.AI",
        "eess.AS"
      ],
      "primary_category": "cs.SD",
      "comment": "Accepted by ICML'24",
      "pdf_url": "http://arxiv.org/pdf/2406.16990v2",
      "published_date": "2024-06-24 06:02:07 UTC",
      "updated_date": "2024-06-26 17:36:53 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-19T00:14:15.656737"
    },
    {
      "arxiv_id": "2406.16330v1",
      "title": "Pruning via Merging: Compressing LLMs via Manifold Alignment Based Layer Merging",
      "title_zh": "翻译失败",
      "authors": [
        "Deyuan Liu",
        "Zhanyue Qin",
        "Hairu Wang",
        "Zhao Yang",
        "Zecheng Wang",
        "Fangying Rong",
        "Qingbin Liu",
        "Yanchao Hao",
        "Xi Chen",
        "Cunhang Fan",
        "Zhao Lv",
        "Zhiying Tu",
        "Dianhui Chu",
        "Bo Li",
        "Dianbo Sui"
      ],
      "abstract": "While large language models (LLMs) excel in many domains, their complexity\nand scale challenge deployment in resource-limited environments. Current\ncompression techniques, such as parameter pruning, often fail to effectively\nutilize the knowledge from pruned parameters. To address these challenges, we\npropose Manifold-Based Knowledge Alignment and Layer Merging Compression (MKA),\na novel approach that uses manifold learning and the Normalized Pairwise\nInformation Bottleneck (NPIB) measure to merge similar layers, reducing model\nsize while preserving essential performance. We evaluate MKA on multiple\nbenchmark datasets and various LLMs. Our findings show that MKA not only\npreserves model performance but also achieves substantial compression ratios,\noutperforming traditional pruning methods. Moreover, when coupled with\nquantization, MKA delivers even greater compression. Specifically, on the MMLU\ndataset using the Llama3-8B model, MKA achieves a compression ratio of 43.75%\nwith a minimal performance decrease of only 2.82\\%. The proposed MKA method\noffers a resource-efficient and performance-preserving model compression\ntechnique for LLMs.",
      "tldr_zh": "本研究针对大型语言模型（LLMs）的复杂性提出了一种新型压缩方法：Manifold-Based Knowledge Alignment and Layer Merging Compression (MKA)，通过流形学习（manifold learning）和Normalized Pairwise Information Bottleneck (NPIB)度量来合并相似的层，从而减少模型大小并保留关键性能，避免了传统parameter pruning方法对参数知识的浪费。实验在多个基准数据集和各种LLMs上评估显示，MKA不仅实现了显著的压缩比率，还优于传统方法，例如在MMLU数据集上使用Llama3-8B模型时，达到了43.75%的压缩比率，仅损失2.82%的性能。进一步与quantization结合，MKA提供了更高效的资源利用方案，为LLMs的部署提供了可靠的技术支持。",
      "categories": [
        "cs.CL",
        "cs.AI"
      ],
      "primary_category": "cs.CL",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2406.16330v1",
      "published_date": "2024-06-24 05:57:55 UTC",
      "updated_date": "2024-06-24 05:57:55 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-19T00:14:28.164095"
    },
    {
      "arxiv_id": "2406.16989v2",
      "title": "Retrieval-Augmented Mixture of LoRA Experts for Uploadable Machine Learning",
      "title_zh": "翻译失败",
      "authors": [
        "Ziyu Zhao",
        "Leilei Gan",
        "Guoyin Wang",
        "Yuwei Hu",
        "Tao Shen",
        "Hongxia Yang",
        "Kun Kuang",
        "Fei Wu"
      ],
      "abstract": "Low-Rank Adaptation (LoRA) offers an efficient way to fine-tune large\nlanguage models (LLMs). Its modular and plug-and-play nature allows the\nintegration of various domain-specific LoRAs, enhancing LLM capabilities.\nOpen-source platforms like Huggingface and Modelscope have introduced a new\ncomputational paradigm, Uploadable Machine Learning (UML). In UML, contributors\nuse decentralized data to train specialized adapters, which are then uploaded\nto a central platform to improve LLMs. This platform uses these domain-specific\nadapters to handle mixed-task requests requiring personalized service. Previous\nresearch on LoRA composition either focuses on specific tasks or fixes the LoRA\nselection during training. However, in UML, the pool of LoRAs is dynamically\nupdated with new uploads, requiring a generalizable selection mechanism for\nunseen LoRAs. Additionally, the mixed-task nature of downstream requests\nnecessitates personalized services. To address these challenges, we propose\nRetrieval-Augmented Mixture of LoRA Experts (RAMoLE), a framework that\nadaptively retrieves and composes multiple LoRAs based on input prompts. RAMoLE\nhas three main components: LoraRetriever for identifying and retrieving\nrelevant LoRAs, an on-the-fly MoLE mechanism for coordinating the retrieved\nLoRAs, and efficient batch inference for handling heterogeneous requests.\nExperimental results show that RAMoLE consistently outperforms baselines,\nhighlighting its effectiveness and scalability.",
      "tldr_zh": "这篇论文提出了 Retrieval-Augmented Mixture of LoRA Experts (RAMoLE) 框架，用于 Uploadable Machine Learning (UML)，以动态检索和组合 LoRA 适配器，解决 UML 中 LoRA 池更新和混合任务处理挑战。RAMoLE 的核心组件包括 LoraRetriever 用于识别并检索相关 LoRA、on-the-fly MoLE 机制用于实时协调这些适配器，以及高效批量推理以支持个性化服务。实验结果显示，RAMoLE 在各种任务上比基线模型表现更优异，证明了其有效性和可扩展性。",
      "categories": [
        "cs.LG",
        "cs.AI"
      ],
      "primary_category": "cs.LG",
      "comment": "arXiv admin note: substantial text overlap with arXiv:2402.09997",
      "pdf_url": "http://arxiv.org/pdf/2406.16989v2",
      "published_date": "2024-06-24 05:24:41 UTC",
      "updated_date": "2024-07-16 05:59:06 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-19T00:14:40.224139"
    },
    {
      "arxiv_id": "2406.16321v2",
      "title": "Mosaic of Modalities: A Comprehensive Benchmark for Multimodal Graph Learning",
      "title_zh": "翻译失败",
      "authors": [
        "Jing Zhu",
        "Yuhang Zhou",
        "Shengyi Qian",
        "Zhongmou He",
        "Tong Zhao",
        "Neil Shah",
        "Danai Koutra"
      ],
      "abstract": "Graph machine learning has made significant strides in recent years, yet the\nintegration of visual information with graph structure and its potential for\nimproving performance in downstream tasks remains an underexplored area. To\naddress this critical gap, we introduce the Multimodal Graph Benchmark\n(MM-GRAPH), a pioneering benchmark that incorporates both visual and textual\ninformation into graph learning tasks. MM-GRAPH extends beyond existing\ntext-attributed graph benchmarks, offering a more comprehensive evaluation\nframework for multimodal graph learning Our benchmark comprises seven diverse\ndatasets of varying scales (ranging from thousands to millions of edges),\ndesigned to assess algorithms across different tasks in real-world scenarios.\nThese datasets feature rich multimodal node attributes, including visual data,\nwhich enables a more holistic evaluation of various graph learning frameworks\nin complex, multimodal environments. To support advancements in this emerging\nfield, we provide an extensive empirical study on various graph learning\nframeworks when presented with features from multiple modalities, particularly\nemphasizing the impact of visual information. This study offers valuable\ninsights into the challenges and opportunities of integrating visual data into\ngraph learning.",
      "tldr_zh": "该研究引入了Multimodal Graph Benchmark (MM-GRAPH)，一个全面的基准框架，用于评估多模态图学习，特别关注将视觉和文本信息整合到图结构中，以提升下游任务性能。MM-GRAPH 扩展了现有文本属性图基准，包括七个规模各异的数据集（从数千到数百万边），这些数据集具备丰富的多模态节点属性，如视觉数据，支持在真实场景中评估各种图学习算法。该基准通过广泛的实证研究，揭示了视觉信息对图学习框架的影响，并提供了整合多模态特征的挑战和机会的宝贵见解。",
      "categories": [
        "cs.LG",
        "cs.AI"
      ],
      "primary_category": "cs.LG",
      "comment": "CVPR 2025",
      "pdf_url": "http://arxiv.org/pdf/2406.16321v2",
      "published_date": "2024-06-24 05:14:09 UTC",
      "updated_date": "2025-03-30 06:11:30 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-19T00:14:51.406573"
    },
    {
      "arxiv_id": "2406.16316v1",
      "title": "Does Cross-Cultural Alignment Change the Commonsense Morality of Language Models?",
      "title_zh": "翻译失败",
      "authors": [
        "Yuu Jinnai"
      ],
      "abstract": "Alignment of the language model with human preferences is a common approach\nto making a language model useful to end users. However, most alignment work is\ndone in English, and human preference datasets are dominated by English,\nreflecting only the preferences of English-speaking annotators. Nevertheless,\nit is common practice to use the English preference data, either directly or by\ntranslating it into the target language, when aligning a multilingual language\nmodel. The question is whether such an alignment strategy marginalizes the\npreference of non-English speaking users. To this end, we investigate the\neffect of aligning Japanese language models with (mostly) English resources. In\nparticular, we focus on evaluating whether the commonsense morality of the\nresulting fine-tuned models is aligned with Japanese culture using the\nJCommonsenseMorality (JCM) and ETHICS datasets. The experimental results show\nthat the fine-tuned model outperforms the SFT model. However, it does not\ndemonstrate the same level of improvement as a model fine-tuned using the JCM,\nsuggesting that while some aspects of commonsense morality are transferable,\nothers may not be.",
      "tldr_zh": "本研究探讨了使用英语为主的偏好数据对多语言语言模型的alignment是否会改变其commonsense morality，并可能边缘化非英语用户的偏好，特别聚焦于日语语言模型。研究者通过实验评估了用（主要是）英语资源调整的模型，使用JCommonsenseMorality (JCM)和ETHICS数据集来检查其与日本文化的道德一致性。结果显示，调整后的模型在某些方面优于SFT模型，但不如直接用JCM数据调整的模型，表明部分commonsense morality是可转移的，而其他方面则受文化影响较大。该发现突显了跨文化alignment的局限性，强调了纳入本地偏好的必要性。",
      "categories": [
        "cs.CL",
        "cs.AI",
        "cs.CY",
        "cs.LG"
      ],
      "primary_category": "cs.CL",
      "comment": "The 2nd Workshop on Cross-Cultural Considerations in NLP (C3NLP) at\n  ACL 2024",
      "pdf_url": "http://arxiv.org/pdf/2406.16316v1",
      "published_date": "2024-06-24 04:50:12 UTC",
      "updated_date": "2024-06-24 04:50:12 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-19T00:15:03.572191"
    },
    {
      "arxiv_id": "2406.16308v1",
      "title": "Anomaly Detection of Tabular Data Using LLMs",
      "title_zh": "翻译失败",
      "authors": [
        "Aodong Li",
        "Yunhan Zhao",
        "Chen Qiu",
        "Marius Kloft",
        "Padhraic Smyth",
        "Maja Rudolph",
        "Stephan Mandt"
      ],
      "abstract": "Large language models (LLMs) have shown their potential in long-context\nunderstanding and mathematical reasoning. In this paper, we study the problem\nof using LLMs to detect tabular anomalies and show that pre-trained LLMs are\nzero-shot batch-level anomaly detectors. That is, without extra\ndistribution-specific model fitting, they can discover hidden outliers in a\nbatch of data, demonstrating their ability to identify low-density data\nregions. For LLMs that are not well aligned with anomaly detection and\nfrequently output factual errors, we apply simple yet effective data-generating\nprocesses to simulate synthetic batch-level anomaly detection datasets and\npropose an end-to-end fine-tuning strategy to bring out the potential of LLMs\nin detecting real anomalies. Experiments on a large anomaly detection benchmark\n(ODDS) showcase i) GPT-4 has on-par performance with the state-of-the-art\ntransductive learning-based anomaly detection methods and ii) the efficacy of\nour synthetic dataset and fine-tuning strategy in aligning LLMs to this task.",
      "tldr_zh": "本论文探讨了使用大型语言模型(LLMs)检测表格数据异常的问题，发现预训练LLMs可以实现零样本(zero-shot)批量级别异常检测，无需额外模型训练即可识别低密度数据区域。针对LLMs可能存在的输出错误问题，作者提出通过合成数据集生成过程和端到端微调策略来优化模型性能，提升其在真实异常检测中的效果。在ODDS基准测试中，GPT-4的性能与最先进的传导学习方法相当，验证了该方法的有效性。",
      "categories": [
        "cs.LG",
        "cs.AI",
        "cs.CL"
      ],
      "primary_category": "cs.LG",
      "comment": "accepted at the Anomaly Detection with Foundation Models workshop",
      "pdf_url": "http://arxiv.org/pdf/2406.16308v1",
      "published_date": "2024-06-24 04:17:03 UTC",
      "updated_date": "2024-06-24 04:17:03 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-19T00:15:15.236075"
    },
    {
      "arxiv_id": "2407.12802v1",
      "title": "SimClone: Detecting Tabular Data Clones using Value Similarity",
      "title_zh": "翻译失败",
      "authors": [
        "Xu Yang",
        "Gopi Krishnan Rajbahadur",
        "Dayi Lin",
        "Shaowei Wang",
        "Zhen Ming",
        "Jiang"
      ],
      "abstract": "Data clones are defined as multiple copies of the same data among datasets.\nPresence of data clones between datasets can cause issues such as difficulties\nin managing data assets and data license violations when using datasets with\nclones to build AI software. However, detecting data clones is not trivial.\nMajority of the prior studies in this area rely on structural information to\ndetect data clones (e.g., font size, column header). However, tabular datasets\nused to build AI software are typically stored without any structural\ninformation. In this paper, we propose a novel method called SimClone for data\nclone detection in tabular datasets without relying on structural information.\nSimClone method utilizes value similarities for data clone detection. We also\npropose a visualization approach as a part of our SimClone method to help\nlocate the exact position of the cloned data between a dataset pair. Our\nresults show that our SimClone outperforms the current state-of-the-art method\nby at least 20\\% in terms of both F1-score and AUC. In addition, SimClone's\nvisualization component helps identify the exact location of the data clone in\na dataset with a Precision@10 value of 0.80 in the top 20 true positive\npredictions.",
      "tldr_zh": "这篇论文提出了SimClone，一种新型方法，用于检测表格数据中的克隆数据（data clones），它依赖于value similarity而非结构信息（如字体大小或列头），以解决数据管理难题和许可违规问题。SimClone结合了值相似性计算和一个可视化组件，帮助精确定位克隆数据的具体位置。实验结果显示，SimClone在F1-score和AUC上比现有最先进方法至少提高了20%，且其可视化组件在Precision@10达到0.80的准确率。",
      "categories": [
        "cs.DB",
        "cs.AI",
        "cs.LG",
        "cs.SE"
      ],
      "primary_category": "cs.DB",
      "comment": "24 pages, 9 figures",
      "pdf_url": "http://arxiv.org/pdf/2407.12802v1",
      "published_date": "2024-06-24 04:16:32 UTC",
      "updated_date": "2024-06-24 04:16:32 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-19T00:15:27.077171"
    },
    {
      "arxiv_id": "2406.17808v4",
      "title": "Training-Free Exponential Context Extension via Cascading KV Cache",
      "title_zh": "基于级",
      "authors": [
        "Jeffrey Willette",
        "Heejun Lee",
        "Youngwan Lee",
        "Myeongjae Jeon",
        "Sung Ju Hwang"
      ],
      "abstract": "The transformer's context window is vital for tasks such as few-shot learning\nand conditional generation as it preserves previous tokens for active memory.\nHowever, as the context lengths increase, the computational costs grow\nquadratically, hindering the deployment of large language models (LLMs) in\nreal-world, long sequence scenarios. Although some recent key-value caching (KV\nCache) methods offer linear inference complexity, they naively manage the\nstored context, prematurely evicting tokens and losing valuable information.\nMoreover, they lack an optimized prefill/prompt stage strategy, resulting in\nhigher latency than even quadratic attention for realistic context sizes. In\nresponse, we introduce a novel mechanism that leverages cascading sub-cache\nbuffers to selectively retain the most relevant tokens, enabling the model to\nmaintain longer context histories without increasing the cache size. Our\napproach outperforms linear caching baselines across key benchmarks, including\nstreaming perplexity, question answering, book summarization, and passkey\nretrieval, where it retains better retrieval accuracy at 1M tokens after four\ndoublings of the cache size of 65K. Additionally, our method reduces prefill\nstage latency by a factor of 6.8 when compared to flash attention on 1M tokens.\nThese innovations not only enhance the computational efficiency of LLMs but\nalso pave the way for their effective deployment in resource-constrained\nenvironments, enabling large-scale, real-time applications with significantly\nreduced latency.",
      "tldr_zh": "这篇论文提出了一种无需训练的指数上下文扩展方法，通过级联 KV Cache 机制（Cascading KV Cache），利用子缓存缓冲区选择性保留最相关的 tokens，从而扩展 Transformer 模型的上下文窗口，同时避免了传统 KV Cache 方法中过早丢弃信息的问题。相比现有方法，该机制优化了预填充阶段策略，大幅降低了计算延迟，并在流式困惑度（streaming perplexity）、问答、书籍摘要和 passkey 检索等基准上表现出色，例如在 1M tokens 时保留了更高的检索准确率。实验证明，该方法将预填充阶段延迟减少 6.8 倍，提升了 LLMs 在资源受限环境中的部署效率，为大规模实时应用铺平了道路。",
      "categories": [
        "cs.CL",
        "cs.AI",
        "cs.LG"
      ],
      "primary_category": "cs.CL",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2406.17808v4",
      "published_date": "2024-06-24 03:59:17 UTC",
      "updated_date": "2025-03-31 03:28:44 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-19T00:15:42.197625"
    },
    {
      "arxiv_id": "2407.07723v3",
      "title": "Lossless data compression by large models",
      "title_zh": "翻译失败",
      "authors": [
        "Ziguang Li",
        "Chao Huang",
        "Xuliang Wang",
        "Haibo Hu",
        "Cole Wyeth",
        "Dongbo Bu",
        "Quan Yu",
        "Wen Gao",
        "Xingwu Liu",
        "Ming Li"
      ],
      "abstract": "Modern data compression methods are slowly reaching their limits after 80\nyears of research, millions of papers, and wide range of applications. Yet, the\nextravagant 6G communication speed requirement raises a major open question for\nrevolutionary new ideas of data compression. We have previously shown all\nunderstanding or learning are compression, under reasonable assumptions. Large\nlanguage models (LLMs) understand data better than ever before. Can they help\nus to compress data? The LLMs may be seen to approximate the uncomputable\nSolomonoff induction. Therefore, under this new uncomputable paradigm, we\npresent LMCompress. LMCompress shatters all previous lossless compression\nalgorithms, doubling the lossless compression ratios of JPEG-XL for images,\nFLAC for audios, and H.264 for videos, and quadrupling the compression ratio of\nbz2 for texts. The better a large model understands the data, the better\nLMCompress compresses.",
      "tldr_zh": "这篇论文探讨了利用大型语言模型(LLMs)实现无损数据压缩的可能性，基于“理解或学习即压缩”的理念，以应对传统方法已达极限的挑战。作者提出了LMCompress方法，该方法通过LLMs模拟Solomonoff归纳来处理数据压缩。实验结果显示，LMCompress在图像上双倍于JPEG-XL、在音频上双倍于FLAC、在视频上双倍于H.264、在文本上四倍于bz2的压缩比，显著提升了整体性能。该方法强调，LLMs对数据的理解程度越高，压缩效果越出色。",
      "categories": [
        "cs.IT",
        "cs.AI",
        "math.IT"
      ],
      "primary_category": "cs.IT",
      "comment": "Published by Nature Machine Intelligence at\n  https://www.nature.com/articles/s42256-025-01033-7",
      "pdf_url": "http://arxiv.org/pdf/2407.07723v3",
      "published_date": "2024-06-24 03:58:11 UTC",
      "updated_date": "2025-04-30 15:11:38 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-19T00:15:52.165229"
    },
    {
      "arxiv_id": "2406.16301v1",
      "title": "UBiSS: A Unified Framework for Bimodal Semantic Summarization of Videos",
      "title_zh": "翻译失败",
      "authors": [
        "Yuting Mei",
        "Linli Yao",
        "Qin Jin"
      ],
      "abstract": "With the surge in the amount of video data, video summarization techniques,\nincluding visual-modal(VM) and textual-modal(TM) summarization, are attracting\nmore and more attention. However, unimodal summarization inevitably loses the\nrich semantics of the video. In this paper, we focus on a more comprehensive\nvideo summarization task named Bimodal Semantic Summarization of Videos\n(BiSSV). Specifically, we first construct a large-scale dataset, BIDS, in\n(video, VM-Summary, TM-Summary) triplet format. Unlike traditional processing\nmethods, our construction procedure contains a VM-Summary extraction algorithm\naiming to preserve the most salient content within long videos. Based on BIDS,\nwe propose a Unified framework UBiSS for the BiSSV task, which models the\nsaliency information in the video and generates a TM-summary and VM-summary\nsimultaneously. We further optimize our model with a list-wise ranking-based\nobjective to improve its capacity to capture highlights. Lastly, we propose a\nmetric, $NDCG_{MS}$, to provide a joint evaluation of the bimodal summary.\nExperiments show that our unified framework achieves better performance than\nmulti-stage summarization pipelines. Code and data are available at\nhttps://github.com/MeiYutingg/UBiSS.",
      "tldr_zh": "这篇论文针对视频总结的局限性，提出了一种统一的框架 UBiSS，用于处理 Bimodal Semantic Summarization of Videos (BiSSV) 任务，该框架同时生成视觉模态总结 (VM-Summary) 和文本模态总结 (TM-Summary)，以保留视频的丰富语义。作者构建了一个大规模数据集 BIDS，采用 (video, VM-Summary, TM-Summary) 三元组格式，并引入一个 VM-Summary 提取算法来保留长视频中的关键内容。UBiSS 通过建模视频显著信息并应用 list-wise ranking-based 优化，提升了模型捕捉高亮内容的能力。实验结果表明，该框架在 BiSSV 任务上优于多阶段总结管道，并通过新指标 $NDCG_{MS}$ 实现了双模态总结的联合评估。",
      "categories": [
        "cs.CV",
        "cs.AI",
        "cs.MM"
      ],
      "primary_category": "cs.CV",
      "comment": "Accepted by ACM International Conference on Multimedia Retrieval\n  (ICMR'24)",
      "pdf_url": "http://arxiv.org/pdf/2406.16301v1",
      "published_date": "2024-06-24 03:55:25 UTC",
      "updated_date": "2024-06-24 03:55:25 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-19T00:16:06.275697"
    },
    {
      "arxiv_id": "2406.16299v1",
      "title": "Compensate Quantization Errors: Make Weights Hierarchical to Compensate Each Other",
      "title_zh": "补偿量化错误：使权重层次化以相互补偿彼此",
      "authors": [
        "Yifei Gao",
        "Jie Ou",
        "Lei Wang",
        "Yuting Xiao",
        "Zhiyuan Xiang",
        "Ruiting Dai",
        "Jun Cheng"
      ],
      "abstract": "Emergent Large Language Models (LLMs) use their extraordinary performance and\npowerful deduction capacity to discern from traditional language models.\nHowever, the expenses of computational resources and storage for these LLMs are\nstunning, quantization then arises as a trending conversation. To address\naccuracy decay caused by quantization, two streams of works in post-training\nquantization methods stand out. One uses other weights to compensate existing\nquantization error, while the other transfers the quantization difficulty to\nother parts in the model. Combining both merits, we introduce Learnable\nSingular value Increment (LSI) as an advanced solution. LSI uses Singular Value\nDecomposition to extract singular values of the weights and make them learnable\nto help weights compensate each other conditioned on activation. Incorporating\nLSI with existing techniques, we achieve state-of-the-art performance in\ndiverse quantization settings, no matter in weight-only, weight-activation or\nextremely low bit scenarios. By unleashing the potential of LSI, efficient\nfinetuning on quantized model is no longer a prohibitive problem.",
      "tldr_zh": "该论文针对大型语言模型 (LLMs) 量化过程中导致的准确性衰减问题，提出 Learnable Singular value Increment (LSI) 方法，利用 Singular Value Decomposition (SVD) 提取权重奇异值并使其可学习，从而使权重在激活条件下相互补偿。LSI 与现有量化技术结合，实现了在权重-only、权重-激活或极低位量化场景中的 state-of-the-art 性能。最终，该方法显著提升了量化模型的效率，使高效微调成为可能。",
      "categories": [
        "cs.CL",
        "cs.AI",
        "F.2.3"
      ],
      "primary_category": "cs.CL",
      "comment": "Efficient quantization method",
      "pdf_url": "http://arxiv.org/pdf/2406.16299v1",
      "published_date": "2024-06-24 03:52:52 UTC",
      "updated_date": "2024-06-24 03:52:52 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-19T00:16:16.767802"
    },
    {
      "arxiv_id": "2406.16295v1",
      "title": "Relaxing Continuous Constraints of Equivariant Graph Neural Networks for Physical Dynamics Learning",
      "title_zh": "翻译失败",
      "authors": [
        "Zinan Zheng",
        "Yang Liu",
        "Jia Li",
        "Jianhua Yao",
        "Yu Rong"
      ],
      "abstract": "Incorporating Euclidean symmetries (e.g. rotation equivariance) as inductive\nbiases into graph neural networks has improved their generalization ability and\ndata efficiency in unbounded physical dynamics modeling. However, in various\nscientific and engineering applications, the symmetries of dynamics are\nfrequently discrete due to the boundary conditions. Thus, existing GNNs either\noverlook necessary symmetry, resulting in suboptimal representation ability, or\nimpose excessive equivariance, which fails to generalize to unobserved\nsymmetric dynamics. In this work, we propose a general Discrete Equivariant\nGraph Neural Network (DEGNN) that guarantees equivariance to a given discrete\npoint group. Specifically, we show that such discrete equivariant message\npassing could be constructed by transforming geometric features into\npermutation-invariant embeddings. Through relaxing continuous equivariant\nconstraints, DEGNN can employ more geometric feature combinations to\napproximate unobserved physical object interaction functions. Two\nimplementation approaches of DEGNN are proposed based on ranking or pooling\npermutation-invariant functions. We apply DEGNN to various physical dynamics,\nranging from particle, molecular, crowd to vehicle dynamics. In twenty\nscenarios, DEGNN significantly outperforms existing state-of-the-art\napproaches. Moreover, we show that DEGNN is data efficient, learning with less\ndata, and can generalize across scenarios such as unobserved orientation.",
      "tldr_zh": "本论文提出Discrete Equivariant Graph Neural Network (DEGNN)，通过放松连续等变约束来处理物理动力学中离散对称性问题（如边界条件引起的离散Euclidean symmetries），从而提升GNNs的表示能力和泛化性。DEGNN通过将几何特征转换为置换不变嵌入来构建离散等变的message passing，并提供了基于排序或池化的两种实现方法。实验结果显示，在粒子、分子、人群和车辆动力学等20个场景中，DEGNN显著优于现有最先进方法，且数据高效，能够用更少数据学习并泛化到未观察到的方向，如不同取向。",
      "categories": [
        "cs.LG",
        "cs.AI"
      ],
      "primary_category": "cs.LG",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2406.16295v1",
      "published_date": "2024-06-24 03:37:51 UTC",
      "updated_date": "2024-06-24 03:37:51 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-19T00:16:30.816926"
    },
    {
      "arxiv_id": "2406.16294v1",
      "title": "LangSuitE: Planning, Controlling and Interacting with Large Language Models in Embodied Text Environments",
      "title_zh": "翻译失败",
      "authors": [
        "Zixia Jia",
        "Mengmeng Wang",
        "Baichen Tong",
        "Song-Chun Zhu",
        "Zilong Zheng"
      ],
      "abstract": "Recent advances in Large Language Models (LLMs) have shown inspiring\nachievements in constructing autonomous agents that rely on language\ndescriptions as inputs. However, it remains unclear how well LLMs can function\nas few-shot or zero-shot embodied agents in dynamic interactive environments.\nTo address this gap, we introduce LangSuitE, a versatile and simulation-free\ntestbed featuring 6 representative embodied tasks in textual embodied worlds.\nCompared with previous LLM-based testbeds, LangSuitE (i) offers adaptability to\ndiverse environments without multiple simulation engines, (ii) evaluates\nagents' capacity to develop ``internalized world knowledge'' with embodied\nobservations, and (iii) allows easy customization of communication and action\nstrategies. To address the embodiment challenge, we devise a novel\nchain-of-thought (CoT) schema, EmMem, which summarizes embodied states w.r.t.\nhistory information. Comprehensive benchmark results illustrate challenges and\ninsights of embodied planning. LangSuitE represents a significant step toward\nbuilding embodied generalists in the context of language models.",
      "tldr_zh": "本研究引入LangSuitE，一种多功能、无模拟的测试平台，旨在评估大型语言模型(LLMs)作为少样本或零样本具身代理在动态文本交互环境中的性能，该平台包含6个代表性任务。LangSuitE的优势包括适应多样环境无需多引擎、评估代理开发“内部化世界知识”的能力，以及允许自定义通信和行动策略。针对具身挑战，论文提出了一种新型链式思维(Chain-of-Thought)模式EmMem，用于总结具身状态与历史信息的关联。基准测试结果揭示了具身规划的挑战与洞见，并为构建语言模型中的具身通用代理提供了重要进展。",
      "categories": [
        "cs.CL",
        "cs.AI"
      ],
      "primary_category": "cs.CL",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2406.16294v1",
      "published_date": "2024-06-24 03:36:29 UTC",
      "updated_date": "2024-06-24 03:36:29 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-19T00:16:41.184881"
    },
    {
      "arxiv_id": "2406.16293v1",
      "title": "Combining Supervised Learning and Reinforcement Learning for Multi-Label Classification Tasks with Partial Labels",
      "title_zh": "翻译失败",
      "authors": [
        "Zixia Jia",
        "Junpeng Li",
        "Shichuan Zhang",
        "Anji Liu",
        "Zilong Zheng"
      ],
      "abstract": "Traditional supervised learning heavily relies on human-annotated datasets,\nespecially in data-hungry neural approaches. However, various tasks, especially\nmulti-label tasks like document-level relation extraction, pose challenges in\nfully manual annotation due to the specific domain knowledge and large class\nsets. Therefore, we address the multi-label positive-unlabelled learning\n(MLPUL) problem, where only a subset of positive classes is annotated. We\npropose Mixture Learner for Partially Annotated Classification (MLPAC), an\nRL-based framework combining the exploration ability of reinforcement learning\nand the exploitation ability of supervised learning. Experimental results\nacross various tasks, including document-level relation extraction, multi-label\nimage classification, and binary PU learning, demonstrate the generalization\nand effectiveness of our framework.",
      "tldr_zh": "该论文针对多标签分类任务中部分标签的挑战（如文档级关系提取），提出了一种结合监督学习（Supervised Learning）和强化学习（Reinforcement Learning）的框架，名为 Mixture Learner for Partially Annotated Classification (MLPAC)。该框架利用强化学习的探索能力来处理多标签正-未标注学习（MLPUL）问题，同时发挥监督学习的利用优势，以减少对完整标注数据的依赖。实验结果显示，MLPAC 在文档级关系提取、多标签图像分类和二元 PU 学习等任务上表现出色，证明了其泛化和有效性。",
      "categories": [
        "cs.CL",
        "cs.AI"
      ],
      "primary_category": "cs.CL",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2406.16293v1",
      "published_date": "2024-06-24 03:36:19 UTC",
      "updated_date": "2024-06-24 03:36:19 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-19T00:16:51.989823"
    },
    {
      "arxiv_id": "2406.16282v1",
      "title": "Reducing Fine-Tuning Memory Overhead by Approximate and Memory-Sharing Backpropagation",
      "title_zh": "翻译失败",
      "authors": [
        "Yuchen Yang",
        "Yingdong Shi",
        "Cheems Wang",
        "Xiantong Zhen",
        "Yuxuan Shi",
        "Jun Xu"
      ],
      "abstract": "Fine-tuning pretrained large models to downstream tasks is an important\nproblem, which however suffers from huge memory overhead due to large-scale\nparameters. This work strives to reduce memory overhead in fine-tuning from\nperspectives of activation function and layer normalization. To this end, we\npropose the Approximate Backpropagation (Approx-BP) theory, which provides the\ntheoretical feasibility of decoupling the forward and backward passes. We apply\nour Approx-BP theory to backpropagation training and derive memory-efficient\nalternatives of GELU and SiLU activation functions, which use derivative\nfunctions of ReLUs in the backward pass while keeping their forward pass\nunchanged. In addition, we introduce a Memory-Sharing Backpropagation strategy,\nwhich enables the activation memory to be shared by two adjacent layers,\nthereby removing activation memory usage redundancy. Our method neither induces\nextra computation nor reduces training efficiency. We conduct extensive\nexperiments with pretrained vision and language models, and the results\ndemonstrate that our proposal can reduce up to $\\sim$$30\\%$ of the peak memory\nusage. Our code is released at https://github.com/yyyyychen/LowMemoryBP.",
      "tldr_zh": "该研究针对微调预训练大型模型时的高内存开销问题，提出了Approximate Backpropagation (Approx-BP)理论，该理论允许前向和后向传播解耦，并应用于GELU和SiLU激活函数的替代方案，即在后向传播中使用ReLU的导数，同时保持前向传播不变。此外，引入Memory-Sharing Backpropagation策略，让相邻层共享激活内存，以消除冗余。该方法不增加额外计算或降低训练效率，并在预训练的视觉和语言模型实验中，成功减少高达约30%的峰值内存使用。",
      "categories": [
        "cs.LG",
        "cs.AI"
      ],
      "primary_category": "cs.LG",
      "comment": "25 pages, ICML 2024 Accepted",
      "pdf_url": "http://arxiv.org/pdf/2406.16282v1",
      "published_date": "2024-06-24 03:09:15 UTC",
      "updated_date": "2024-06-24 03:09:15 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-19T00:17:03.871837"
    },
    {
      "arxiv_id": "2406.16272v2",
      "title": "Repairing Catastrophic-Neglect in Text-to-Image Diffusion Models via Attention-Guided Feature Enhancement",
      "title_zh": "通过注意力引导的特征增强修复文本到图像扩散模型中的",
      "authors": [
        "Zhiyuan Chang",
        "Mingyang Li",
        "Junjie Wang",
        "Yi Liu",
        "Qing Wang",
        "Yang Liu"
      ],
      "abstract": "Text-to-Image Diffusion Models (T2I DMs) have garnered significant attention\nfor their ability to generate high-quality images from textual descriptions.\nHowever, these models often produce images that do not fully align with the\ninput prompts, resulting in semantic inconsistencies. The most prominent issue\namong these semantic inconsistencies is catastrophic-neglect, where the images\ngenerated by T2I DMs miss key objects mentioned in the prompt. We first conduct\nan empirical study on this issue, exploring the prevalence of\ncatastrophic-neglect, potential mitigation strategies with feature enhancement,\nand the insights gained. Guided by the empirical findings, we propose an\nautomated repair approach named Patcher to address catastrophic-neglect in T2I\nDMs. Specifically, Patcher first determines whether there are any neglected\nobjects in the prompt, and then applies attention-guided feature enhancement to\nthese neglected objects, resulting in a repaired prompt. Experimental results\non three versions of Stable Diffusion demonstrate that Patcher effectively\nrepairs the issue of catastrophic-neglect, achieving 10.1%-16.3% higher Correct\nRate in image generation compared to baselines.",
      "tldr_zh": "Text-to-Image Diffusion Models (T2I DMs) 在生成高质量图像时，常出现 catastrophic-neglect 问题，导致图像忽略提示中的关键对象，从而产生语义不一致。论文首先通过实证研究分析了这一问题的普遍性和潜在缓解策略，然后提出了一种自动化修复方法 Patcher，该方法检测提示中被忽略的对象，并通过 attention-guided feature enhancement 增强这些对象的特征，以生成修复后的提示。实验结果显示，在 Stable Diffusion 的三个版本上，Patcher 相比基线模型将图像生成正确率提高了 10.1%-16.3%。这为提升 T2I DMs 的鲁棒性和准确性提供了有效途径。",
      "categories": [
        "cs.CV",
        "cs.AI"
      ],
      "primary_category": "cs.CV",
      "comment": "12 pages, 3 figures",
      "pdf_url": "http://arxiv.org/pdf/2406.16272v2",
      "published_date": "2024-06-24 02:38:30 UTC",
      "updated_date": "2024-09-21 04:02:07 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-19T00:17:15.909986"
    },
    {
      "arxiv_id": "2407.10990v1",
      "title": "MedBench: A Comprehensive, Standardized, and Reliable Benchmarking System for Evaluating Chinese Medical Large Language Models",
      "title_zh": "翻译失败",
      "authors": [
        "Mianxin Liu",
        "Jinru Ding",
        "Jie Xu",
        "Weiguo Hu",
        "Xiaoyang Li",
        "Lifeng Zhu",
        "Zhian Bai",
        "Xiaoming Shi",
        "Benyou Wang",
        "Haitao Song",
        "Pengfei Liu",
        "Xiaofan Zhang",
        "Shanshan Wang",
        "Kang Li",
        "Haofen Wang",
        "Tong Ruan",
        "Xuanjing Huang",
        "Xin Sun",
        "Shaoting Zhang"
      ],
      "abstract": "Ensuring the general efficacy and goodness for human beings from medical\nlarge language models (LLM) before real-world deployment is crucial. However, a\nwidely accepted and accessible evaluation process for medical LLM, especially\nin the Chinese context, remains to be established. In this work, we introduce\n\"MedBench\", a comprehensive, standardized, and reliable benchmarking system for\nChinese medical LLM. First, MedBench assembles the currently largest evaluation\ndataset (300,901 questions) to cover 43 clinical specialties and performs\nmulti-facet evaluation on medical LLM. Second, MedBench provides a standardized\nand fully automatic cloud-based evaluation infrastructure, with physical\nseparations for question and ground truth. Third, MedBench implements dynamic\nevaluation mechanisms to prevent shortcut learning and answer remembering.\nApplying MedBench to popular general and medical LLMs, we observe unbiased,\nreproducible evaluation results largely aligning with medical professionals'\nperspectives. This study establishes a significant foundation for preparing the\npractical applications of Chinese medical LLMs. MedBench is publicly accessible\nat https://medbench.opencompass.org.cn.",
      "tldr_zh": "该研究引入了MedBench，一种针对中文医疗大语言模型(LLM)的全面、标准化和可靠基准测试系统，以确保模型在实际部署前的有效性和安全性。MedBench汇集了目前最大的评估数据集（包含30万多问题），覆盖43个临床专业，并通过多方面评估、标准化云端基础设施以及动态机制（如防止捷径学习和答案记忆）来提供无偏复现结果。实验显示，MedBench的评估结果与医疗专业人士的观点高度一致，为中文医疗LLM的实际应用奠定了重要基础，并已在https://medbench.opencompass.org.cn公开访问。",
      "categories": [
        "cs.CL",
        "cs.AI"
      ],
      "primary_category": "cs.CL",
      "comment": "25 pages.4 figures",
      "pdf_url": "http://arxiv.org/pdf/2407.10990v1",
      "published_date": "2024-06-24 02:25:48 UTC",
      "updated_date": "2024-06-24 02:25:48 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-19T00:17:27.657920"
    },
    {
      "arxiv_id": "2407.00079v3",
      "title": "Mooncake: A KVCache-centric Disaggregated Architecture for LLM Serving",
      "title_zh": "翻译失败",
      "authors": [
        "Ruoyu Qin",
        "Zheming Li",
        "Weiran He",
        "Mingxing Zhang",
        "Yongwei Wu",
        "Weimin Zheng",
        "Xinran Xu"
      ],
      "abstract": "Mooncake is the serving platform for Kimi, a leading LLM service provided by\nMoonshot AI. It features a KVCache-centric disaggregated architecture that\nseparates the prefill and decoding clusters. It also leverages the\nunderutilized CPU, DRAM, and SSD resources of the GPU cluster to implement a\ndisaggregated cache of KVCache. The core of Mooncake is its KVCache-centric\nscheduler, which balances maximizing overall effective throughput while meeting\nlatency-related Service Level Objectives (SLOs). Unlike traditional studies\nthat assume all requests will be processed, Mooncake faces challenges due to\nhighly overloaded scenarios. To mitigate these, we developed a prediction-based\nearly rejection policy. Experiments show that Mooncake excels in long-context\nscenarios. Compared to the baseline method, Mooncake can achieve up to a 525%\nincrease in throughput in certain simulated scenarios while adhering to SLOs.\nUnder real workloads, Mooncake's innovative architecture enables Kimi to handle\n75% more requests.",
      "tldr_zh": "本论文提出 Mooncake，一种以 KVCache 为中心的分离架构，用于 LLM 服务平台 Kimi。它将 prefill 和 decoding 集群分开，并利用 GPU 集群的闲置 CPU、DRAM 和 SSD 资源来实现 KVCache 的分离缓存，同时通过 KVCache-centric 调度器最大化有效吞吐量并满足延迟相关的 SLOs。针对高负载场景，该系统引入了基于预测的早期拒绝策略，以缓解处理挑战。实验结果显示，Mooncake 在长上下文场景中比基线方法提高高达 525% 的吞吐量，并在真实工作负载下处理 75% 更多的请求。",
      "categories": [
        "cs.DC",
        "cs.AI",
        "cs.AR"
      ],
      "primary_category": "cs.DC",
      "comment": "23 pages, 13 figures",
      "pdf_url": "http://arxiv.org/pdf/2407.00079v3",
      "published_date": "2024-06-24 02:05:32 UTC",
      "updated_date": "2024-07-09 04:03:10 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-19T00:17:41.652969"
    },
    {
      "arxiv_id": "2406.16264v3",
      "title": "One Thousand and One Pairs: A \"novel\" challenge for long-context language models",
      "title_zh": "翻译失败",
      "authors": [
        "Marzena Karpinska",
        "Katherine Thai",
        "Kyle Lo",
        "Tanya Goyal",
        "Mohit Iyyer"
      ],
      "abstract": "Synthetic long-context LLM benchmarks (e.g., \"needle-in-the-haystack\") test\nonly surface-level retrieval capabilities, but how well can long-context LLMs\nretrieve, synthesize, and reason over information across book-length inputs? We\naddress this question by creating NoCha, a dataset of 1,001 minimally different\npairs of true and false claims about 67 recently-published English fictional\nbooks, written by human readers of those books. In contrast to existing\nlong-context benchmarks, our annotators confirm that the largest share of pairs\nin NoCha require global reasoning over the entire book to verify. Our\nexperiments show that while human readers easily perform this task, it is\nenormously challenging for all ten long-context LLMs that we evaluate: no\nopen-weight model performs above random chance (despite their strong\nperformance on synthetic benchmarks), while GPT-4o achieves the highest\naccuracy at 55.8%. Further analysis reveals that (1) on average, models perform\nmuch better on pairs that require only sentence-level retrieval vs. global\nreasoning; (2) model-generated explanations for their decisions are often\ninaccurate even for correctly-labeled claims; and (3) models perform\nsubstantially worse on speculative fiction books that contain extensive\nworld-building. The methodology proposed in NoCha allows for the evolution of\nthe benchmark dataset and the easy analysis of future models.",
      "tldr_zh": "这篇论文引入了 NoCha 数据集，这是一个由 1001 对真假声明组成的基准，用于评估长上下文语言模型（long-context LLMs）在书籍长度输入上进行检索、合成和推理的能力，这些声明基于 67 本英文小说，由人类读者创建，且大部分需要全局推理。实验结果显示，人类能轻松完成任务，但测试的 10 个模型中，开源模型表现接近随机猜测，而 GPT-4o 的准确率最高仅为 55.8%。此外，模型在句子级检索任务上表现更好，但生成的解释往往不准确，尤其在涉及大量世界构建的科幻小说上；NoCha 的设计允许基准数据集的持续演化和对未来模型的深入分析。",
      "categories": [
        "cs.CL",
        "cs.AI"
      ],
      "primary_category": "cs.CL",
      "comment": "EMNLP 2024, camera ready",
      "pdf_url": "http://arxiv.org/pdf/2406.16264v3",
      "published_date": "2024-06-24 02:03:57 UTC",
      "updated_date": "2024-10-22 15:09:58 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-19T00:17:54.449762"
    },
    {
      "arxiv_id": "2406.16260v1",
      "title": "Video-Infinity: Distributed Long Video Generation",
      "title_zh": "Video-Infinity：分布式长视频生成",
      "authors": [
        "Zhenxiong Tan",
        "Xingyi Yang",
        "Songhua Liu",
        "Xinchao Wang"
      ],
      "abstract": "Diffusion models have recently achieved remarkable results for video\ngeneration. Despite the encouraging performances, the generated videos are\ntypically constrained to a small number of frames, resulting in clips lasting\nmerely a few seconds. The primary challenges in producing longer videos include\nthe substantial memory requirements and the extended processing time required\non a single GPU. A straightforward solution would be to split the workload\nacross multiple GPUs, which, however, leads to two issues: (1) ensuring all\nGPUs communicate effectively to share timing and context information, and (2)\nmodifying existing video diffusion models, which are usually trained on short\nsequences, to create longer videos without additional training. To tackle\nthese, in this paper we introduce Video-Infinity, a distributed inference\npipeline that enables parallel processing across multiple GPUs for long-form\nvideo generation. Specifically, we propose two coherent mechanisms: Clip\nparallelism and Dual-scope attention. Clip parallelism optimizes the gathering\nand sharing of context information across GPUs which minimizes communication\noverhead, while Dual-scope attention modulates the temporal self-attention to\nbalance local and global contexts efficiently across the devices. Together, the\ntwo mechanisms join forces to distribute the workload and enable the fast\ngeneration of long videos. Under an 8 x Nvidia 6000 Ada GPU (48G) setup, our\nmethod generates videos up to 2,300 frames in approximately 5 minutes, enabling\nlong video generation at a speed 100 times faster than the prior methods.",
      "tldr_zh": "该研究针对扩散模型（Diffusion models）在视频生成中的局限性，即生成的视频帧数有限和处理资源需求高，提出了一种分布式推理管道Video-Infinity。该框架通过Clip parallelism和Dual-scope attention机制，实现多个GPU间的并行处理：前者优化上下文信息的共享以减少通信开销，后者平衡本地和全局时间自注意力，确保视频连贯性。在8 x Nvidia 6000 Ada GPU设置下，Video-Infinity可在约5分钟内生成高达2300帧的视频，比先前方法快100倍，显著提升了长视频生成效率。",
      "categories": [
        "cs.CV",
        "cs.AI"
      ],
      "primary_category": "cs.CV",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2406.16260v1",
      "published_date": "2024-06-24 01:56:12 UTC",
      "updated_date": "2024-06-24 01:56:12 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-19T00:18:03.768606"
    },
    {
      "arxiv_id": "2406.16259v1",
      "title": "User Story Tutor (UST) to Support Agile Software Developers",
      "title_zh": "翻译失败",
      "authors": [
        "Giseldo da Silva Neo",
        "José Antão Beltrão Moura",
        "Hyggo Oliveira de Almeida",
        "Alana Viana Borges da Silva Neo",
        "Olival de Gusmão Freitas Júnior"
      ],
      "abstract": "User Stories record what must be built in projects that use agile practices.\nUser Stories serve both to estimate effort, generally measured in Story Points,\nand to plan what should be done in a Sprint. Therefore, it is essential to\ntrain software engineers on how to create simple, easily readable, and\ncomprehensive User Stories. For that reason, we designed, implemented, applied,\nand evaluated a web application called User Story Tutor (UST). UST checks the\ndescription of a given User Story for readability, and if needed, recommends\nappropriate practices for improvement. UST also estimates a User Story effort\nin Story Points using Machine Learning techniques. As such UST may support the\ncontinuing education of agile development teams when writing and reviewing User\nStories. UST's ease of use was evaluated by 40 agile practitioners according to\nthe Technology Acceptance Model (TAM) and AttrakDiff. The TAM evaluation\naverages were good in almost all considered variables. Application of the\nAttrakDiff evaluation framework produced similar good results. Apparently, UST\ncan be used with good reliability. Applying UST to assist in the construction\nof User Stories is a viable technique that, at the very least, can be used by\nagile developments to complement and enhance current User Story creation.",
      "tldr_zh": "本研究开发了 User Story Tutor (UST)，一个网络应用，旨在帮助敏捷软件开发人员创建高质量的 User Stories，以记录需求、估算 Story Points 和规划 Sprint。UST 通过检查 User Story 的可读性，提供改进建议，并利用 Machine Learning 技术估算工作量，从而支持团队的教育和审查过程。研究对 40 名敏捷从业者进行了评估，使用 Technology Acceptance Model (TAM) 和 AttrakDiff 框架，结果显示 UST 的易用性和可靠性良好，可作为补充现有 User Story 创建方法的有效工具。",
      "categories": [
        "cs.SE",
        "cs.AI"
      ],
      "primary_category": "cs.SE",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2406.16259v1",
      "published_date": "2024-06-24 01:55:01 UTC",
      "updated_date": "2024-06-24 01:55:01 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-19T00:18:15.549596"
    },
    {
      "arxiv_id": "2406.16258v2",
      "title": "MEReQ: Max-Ent Residual-Q Inverse RL for Sample-Efficient Alignment from Intervention",
      "title_zh": "翻译失败",
      "authors": [
        "Yuxin Chen",
        "Chen Tang",
        "Chenran Li",
        "Ran Tian",
        "Wei Zhan",
        "Peter Stone",
        "Masayoshi Tomizuka"
      ],
      "abstract": "Aligning robot behavior with human preferences is crucial for deploying\nembodied AI agents in human-centered environments. A promising solution is\ninteractive imitation learning from human intervention, where a human expert\nobserves the policy's execution and provides interventions as feedback.\nHowever, existing methods often fail to utilize the prior policy efficiently to\nfacilitate learning, thus hindering sample efficiency. In this work, we\nintroduce MEReQ (Maximum-Entropy Residual-Q Inverse Reinforcement Learning),\ndesigned for sample-efficient alignment from human intervention. Instead of\ninferring the complete human behavior characteristics, MEReQ infers a residual\nreward function that captures the discrepancy between the human expert's and\nthe prior policy's underlying reward functions. It then employs Residual\nQ-Learning (RQL) to align the policy with human preferences using this residual\nreward function. Extensive evaluations on simulated and real-world tasks\ndemonstrate that MEReQ achieves sample-efficient policy alignment from human\nintervention.",
      "tldr_zh": "该论文提出 MEReQ（Maximum-Entropy Residual-Q Inverse RL），一种样本高效的方法，用于从人类干预中对齐机器人行为，以适应人类中心环境。MEReQ 通过推断一个残差奖励函数（residual reward function），捕捉人类专家和先验策略之间的差异，然后运用 Residual Q-Learning (RQL) 来优化策略。实验在模拟和真实世界任务中证明，MEReQ 显著提高了样本效率，实现更有效的机器人行为对齐。",
      "categories": [
        "cs.RO",
        "cs.AI",
        "cs.LG",
        "I.2.6; I.2.9"
      ],
      "primary_category": "cs.RO",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2406.16258v2",
      "published_date": "2024-06-24 01:51:09 UTC",
      "updated_date": "2024-10-28 19:17:41 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-19T00:18:28.525211"
    },
    {
      "arxiv_id": "2406.16986v1",
      "title": "Machine Unlearning with Minimal Gradient Dependence for High Unlearning Ratios",
      "title_zh": "翻译失败",
      "authors": [
        "Tao Huang",
        "Ziyang Chen",
        "Jiayang Meng",
        "Qingyu Huang",
        "Xu Yang",
        "Xun Yi",
        "Ibrahim Khalil"
      ],
      "abstract": "In the context of machine unlearning, the primary challenge lies in\neffectively removing traces of private data from trained models while\nmaintaining model performance and security against privacy attacks like\nmembership inference attacks. Traditional gradient-based unlearning methods\noften rely on extensive historical gradients, which becomes impractical with\nhigh unlearning ratios and may reduce the effectiveness of unlearning.\nAddressing these limitations, we introduce Mini-Unlearning, a novel approach\nthat capitalizes on a critical observation: unlearned parameters correlate with\nretrained parameters through contraction mapping. Our method, Mini-Unlearning,\nutilizes a minimal subset of historical gradients and leverages this\ncontraction mapping to facilitate scalable, efficient unlearning. This\nlightweight, scalable method significantly enhances model accuracy and\nstrengthens resistance to membership inference attacks. Our experiments\ndemonstrate that Mini-Unlearning not only works under higher unlearning ratios\nbut also outperforms existing techniques in both accuracy and security,\noffering a promising solution for applications requiring robust unlearning\ncapabilities.",
      "tldr_zh": "该论文针对机器 unlearning 的挑战，提出了一种名为 Mini-Unlearning 的新方法，以最小化对历史梯度的依赖，适用于高 unlearning ratios 场景。该方法利用 unlearned parameters 与 retrained parameters 之间的 contraction mapping，仅需最小历史梯度子集，即可实现高效、可扩展的 unlearning，同时提升模型准确性和抵抗 membership inference attacks 的能力。实验结果显示，Mini-Unlearning 在高 unlearning ratios 下优于现有技术，不仅维持了模型性能，还显著增强了隐私安全。",
      "categories": [
        "cs.LG",
        "cs.AI",
        "cs.CR"
      ],
      "primary_category": "cs.LG",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2406.16986v1",
      "published_date": "2024-06-24 01:43:30 UTC",
      "updated_date": "2024-06-24 01:43:30 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-19T00:18:39.774886"
    },
    {
      "arxiv_id": "2406.16255v2",
      "title": "Uncertainty-Aware Reward-Free Exploration with General Function Approximation",
      "title_zh": "翻译失败",
      "authors": [
        "Junkai Zhang",
        "Weitong Zhang",
        "Dongruo Zhou",
        "Quanquan Gu"
      ],
      "abstract": "Mastering multiple tasks through exploration and learning in an environment\nposes a significant challenge in reinforcement learning (RL). Unsupervised RL\nhas been introduced to address this challenge by training policies with\nintrinsic rewards rather than extrinsic rewards. However, current intrinsic\nreward designs and unsupervised RL algorithms often overlook the heterogeneous\nnature of collected samples, thereby diminishing their sample efficiency. To\novercome this limitation, in this paper, we propose a reward-free RL algorithm\ncalled \\alg. The key idea behind our algorithm is an uncertainty-aware\nintrinsic reward for exploring the environment and an uncertainty-weighted\nlearning process to handle heterogeneous uncertainty in different samples.\nTheoretically, we show that in order to find an $\\epsilon$-optimal policy,\nGFA-RFE needs to collect $\\tilde{O} (H^2 \\log N_{\\mathcal F} (\\epsilon)\n\\mathrm{dim} (\\mathcal F) / \\epsilon^2 )$ number of episodes, where $\\mathcal\nF$ is the value function class with covering number $N_{\\mathcal F} (\\epsilon)$\nand generalized eluder dimension $\\mathrm{dim} (\\mathcal F)$. Such a result\noutperforms all existing reward-free RL algorithms. We further implement and\nevaluate GFA-RFE across various domains and tasks in the DeepMind Control\nSuite. Experiment results show that GFA-RFE outperforms or is comparable to the\nperformance of state-of-the-art unsupervised RL algorithms.",
      "tldr_zh": "本研究针对强化学习（RL）中无监督探索的挑战，提出了一种不确定性感知的免奖励探索算法 GFA-RFE，以解决现有算法忽略样本异质性导致的样本效率低下问题。该算法通过引入不确定性-aware intrinsic reward 来引导环境探索，并采用不确定性-weighted learning process 处理不同样本的不确定性。理论上，GFA-RFE 在找到ε-最优策略时，仅需收集\\tilde{O}(H^2 \\log N_{\\mathcal F}(\\epsilon) \\mathrm{dim}(\\mathcal F) / \\epsilon^2) 数量的 episodes，优于现有 reward-free RL 算法。实验结果显示，在 DeepMind Control Suite 的多种任务中，GFA-RFE 的性能超越或相当于是最先进的无监督 RL 方法。",
      "categories": [
        "cs.LG",
        "cs.AI"
      ],
      "primary_category": "cs.LG",
      "comment": "32 pages, 5 figures, 4 tables, accepted by ICML 2024",
      "pdf_url": "http://arxiv.org/pdf/2406.16255v2",
      "published_date": "2024-06-24 01:37:18 UTC",
      "updated_date": "2024-06-30 03:55:48 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-19T00:18:52.524812"
    },
    {
      "arxiv_id": "2406.16254v2",
      "title": "Confidence Regulation Neurons in Language Models",
      "title_zh": "语言模型中的置信度调控神经元",
      "authors": [
        "Alessandro Stolfo",
        "Ben Wu",
        "Wes Gurnee",
        "Yonatan Belinkov",
        "Xingyi Song",
        "Mrinmaya Sachan",
        "Neel Nanda"
      ],
      "abstract": "Despite their widespread use, the mechanisms by which large language models\n(LLMs) represent and regulate uncertainty in next-token predictions remain\nlargely unexplored. This study investigates two critical components believed to\ninfluence this uncertainty: the recently discovered entropy neurons and a new\nset of components that we term token frequency neurons. Entropy neurons are\ncharacterized by an unusually high weight norm and influence the final layer\nnormalization (LayerNorm) scale to effectively scale down the logits. Our work\nshows that entropy neurons operate by writing onto an unembedding null space,\nallowing them to impact the residual stream norm with minimal direct effect on\nthe logits themselves. We observe the presence of entropy neurons across a\nrange of models, up to 7 billion parameters. On the other hand, token frequency\nneurons, which we discover and describe here for the first time, boost or\nsuppress each token's logit proportionally to its log frequency, thereby\nshifting the output distribution towards or away from the unigram distribution.\nFinally, we present a detailed case study where entropy neurons actively manage\nconfidence in the setting of induction, i.e. detecting and continuing repeated\nsubsequences.",
      "tldr_zh": "本研究探讨大型语言模型 (LLMs) 中用于调节下一个标记预测不确定性的机制，重点分析了 entropy neurons 和新发现的 token frequency neurons。Entropy neurons 通过高权重范数影响最终层归一化 (LayerNorm) 缩放，并通过写入 unembedding null space 间接调整 residual stream norm，而对 logits 的直接影响最小；在多达 7 亿参数的模型中均有观察。Token frequency neurons 首次被识别，根据标记的 log frequency 提升或抑制其 logit，从而使输出分布向或远离 unigram distribution 移动。最终，通过一个案例研究，展示了 entropy neurons 在 induction 设置中如何检测和继续重复子序列，从而有效管理模型置信度。",
      "categories": [
        "cs.LG",
        "cs.AI",
        "cs.CL"
      ],
      "primary_category": "cs.LG",
      "comment": "NeurIPS 2024",
      "pdf_url": "http://arxiv.org/pdf/2406.16254v2",
      "published_date": "2024-06-24 01:31:03 UTC",
      "updated_date": "2024-11-08 12:54:16 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-19T00:19:04.312013"
    },
    {
      "arxiv_id": "2406.16252v2",
      "title": "Graph-Augmented LLMs for Personalized Health Insights: A Case Study in Sleep Analysis",
      "title_zh": "图增强 LLMs 用于个性化健康洞见：睡眠分析的案例研究",
      "authors": [
        "Ajan Subramanian",
        "Zhongqi Yang",
        "Iman Azimi",
        "Amir M. Rahmani"
      ],
      "abstract": "Health monitoring systems have revolutionized modern healthcare by enabling\nthe continuous capture of physiological and behavioral data, essential for\npreventive measures and early health intervention. While integrating this data\nwith Large Language Models (LLMs) has shown promise in delivering interactive\nhealth advice, traditional methods like Retrieval-Augmented Generation (RAG)\nand fine-tuning often fail to fully utilize the complex, multi-dimensional, and\ntemporally relevant data from wearable devices. These conventional approaches\ntypically provide limited actionable and personalized health insights due to\ntheir inadequate capacity to dynamically integrate and interpret diverse health\ndata streams. In response, this paper introduces a graph-augmented LLM\nframework designed to significantly enhance the personalization and clarity of\nhealth insights. Utilizing a hierarchical graph structure, the framework\ncaptures inter and intra-patient relationships, enriching LLM prompts with\ndynamic feature importance scores derived from a Random Forest Model. The\neffectiveness of this approach is demonstrated through a sleep analysis case\nstudy involving 20 college students during the COVID-19 lockdown, highlighting\nthe potential of our model to generate actionable and personalized health\ninsights efficiently. We leverage another LLM to evaluate the insights for\nrelevance, comprehensiveness, actionability, and personalization, addressing\nthe critical need for models that process and interpret complex health data\neffectively. Our findings show that augmenting prompts with our framework\nyields significant improvements in all 4 criteria. Through our framework, we\ncan elicit well-crafted, more thoughtful responses tailored to a specific\npatient.",
      "tldr_zh": "该论文指出，传统方法如Retrieval-Augmented Generation (RAG)和fine-tuning 无法充分利用可穿戴设备的多维健康数据，导致个性化健康洞见不足。为此，提出一个图增强的LLMs框架，利用分层图结构捕捉患者间和患者内关系，并通过Random Forest Model 动态生成特征重要性分数来丰富LLM提示，从而提升洞见的清晰度和个性化。实验通过一个睡眠分析案例研究，涉及20名大学生的数据，证明该框架显著提高了洞见的相关性、全面性、可操作性和个性化，为高效处理复杂健康数据提供了新途径。",
      "categories": [
        "cs.LG",
        "cs.AI"
      ],
      "primary_category": "cs.LG",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2406.16252v2",
      "published_date": "2024-06-24 01:22:54 UTC",
      "updated_date": "2024-06-25 03:17:40 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-19T00:19:17.501789"
    }
  ],
  "raw_papers_fetched": true,
  "papers_count": 129,
  "processed_papers_count": 129,
  "failed_papers_count": 0,
  "summary_generated": true,
  "daily_data_saved": true,
  "last_update": "2025-05-19T00:19:42.974753"
}