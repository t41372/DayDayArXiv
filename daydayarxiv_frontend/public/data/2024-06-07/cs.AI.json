{
  "date": "2024-06-07",
  "category": "cs.AI",
  "summary": "欢迎来到 UTC 时间 2024-06-07 的 arXiv 中文 TLDR 快报！今天 arXiv 更新了 123 篇论文，主要聚焦于 AI 和机器学习领域，包括大型语言模型（LLMs）的优化与应用、生成模型的创新、强化学习 benchmark，以及跨领域任务如图像生成和知识图谱等。其中，令人印象深刻的包括基于 LLM 的多模态生成框架（如 MeLFusion）和强化学习新方法（如 SelfGoal），这些工作展示了 AI 在实际场景中的潜力，同时涉及知名机构如 Meta 和 Google 的相关研究。\n\n下面，我将挑选并讨论部分重要、话题度和影响大的论文，先从 LLM 和生成模型等热点开始，然后快速掠过其他领域。相关论文按主题归类，优先选取创新性强或有实际影响的。\n\n### LLM 和生成模型\n- **SelfGoal: Your Language Agents Already Know How to Achieve High-level Goals**（SelfGoal: 你的语言代理已经知道如何实现高级目标）  \n  这篇论文提出 SelfGoal 框架，利用 LLM 自动分解任务为子目标，实现高效强化学习，显著提升代理在多任务环境中的性能，尤其在竞争和合作场景中，展示了 LLM 在智能代理中的潜力。\n\n- **WildBench: Benchmarking LLMs with Challenging Tasks from Real Users in the Wild**（WildBench: 使用真实用户挑战任务基准测试 LLMs）  \n  作者引入 WildBench 基准，评估 LLM 在真实查询中的表现，使用新指标如 WB-Reward 和 WB-Score，揭示了 GPT-4 在复杂任务中的优势和局限，强调了 LLM 鲁棒性的实际挑战。\n\n- **LLM-Vectorizer: LLM-based Verified Loop Vectorizer**（LLM-Vectorizer: 基于 LLM 的验证循环向量化器）  \n  这篇工作使用 LLM 结合深度学习生成高效的向量化代码，并通过 Alive2 工具验证其正确性，在代码优化任务中表现出色，提升了编译器性能。\n\n- **MATTER: Memory-Augmented Transformer Using Heterogeneous Knowledge Sources**（MATTER: 使用异构知识源的记忆增强 Transformer）  \n  论文提出 MATTER 模型，通过异构知识（如段落和 QA 对）增强 Transformer 的检索能力，在知识密集任务中加速推理，显著提高了效率。\n\n其他 LLM 相关论文如 **Logic Synthesis with Generative Deep Neural Networks** 和 **Denoising-Aware Contrastive Learning for Noisy Time Series** 等，聚焦 LLM 在特定任务中的应用，但影响较小，仅快速提及：它们分别探索了生成模型在逻辑合成的优化和噪声时间序列处理中，提供了一些技术改进。\n\n### 强化学习和元学习\n- **Cooperative Meta-Learning with Gradient Augmentation**（Cooperative Meta-Learning with Gradient Augmentation: 梯度增强的合作元学习）  \n  这篇论文引入梯度增强机制，提升元学习在少样本任务中的泛化能力，在图像分类和节点分类中表现出色，是强化学习领域的重要进展。\n\n- **GameBench: Evaluating Strategic Reasoning Abilities of LLM Agents**（GameBench: 评估 LLM 代理的战略推理能力）  \n  作者构建 GameBench 基准，测试 LLM 在游戏中的战略推理，使用 CoT 和 RAP 方法，揭示了 LLM 在决策任务中的不足和潜力。\n\n其他强化学习论文如 **StackSight: Unveiling WebAssembly through Large Language Models and Neurosymbolic Chain-of-Thought Decompilation**，提出神经符号方法反编译 WebAssembly，提升代码理解，但相对小众，仅提及其在代码逆向中的贡献。\n\n### 计算机视觉和图像处理\n- **MeLFusion: Synthesizing Music from Image and Language Cues using Diffusion Models**（MeLFusion: 使用扩散模型从图像和语言线索合成音乐）  \n  这篇工作创新性地融合图像和语言生成音乐，使用扩散模型显著提升多模态生成质量，在音乐合成任务中表现出色。\n\n- **FlowMM: Generating Materials with Riemannian Flow Matching**（FlowMM: 使用 Riemannian 流匹配生成材料）  \n  论文提出 FlowMM 框架，利用流匹配生成晶体结构，提高材料科学中的预测准确性，展示了生成模型在科学计算中的应用潜力。\n\n其他视觉论文如 **Ada-VE: Training-Free Consistent Video Editing Using Adaptive Motion Prior**，快速掠过：它提供无训练视频编辑方法，提升了生成视频的鲁棒性。\n\n### 其他领域（快速掠过）\n剩余论文涉及时间序列预测、图神经网络和医疗等领域，但不那么核心或话题度低，仅列出标题和简要贡献：\n- **Optimal Eye Surgeon: Finding Image Priors through Sparse Generators at Initialization**（Optimal Eye Surgeon: 通过初始化稀疏生成器寻找图像先验）  \n  主要贡献是提出 OES 框架，优化图像生成网络，减少过拟合。\n- **TLEX: An Efficient Method for Extracting Exact Timelines from TimeML Temporal Graphs**（TLEX: 从 TimeML 时间图中提取精确时间线的有效方法）  \n  开发 TLEX 算法，提高时间序列提取的准确性。\n- **3D-GRAND: A Million-Scale Dataset for 3D-LLMs with Better Grounding and Less Hallucination**（3D-GRAND: 用于 3D-LLMs 的百万级数据集，提升 grounding 并减少幻觉）  \n  构建大规模数据集，提升 3D-LLM 的鲁棒性。\n- **CTBENCH: A Library and Benchmark for Certified Training**（CTBENCH: 用于认证训练的库和基准）  \n  提供 CTBENCH 基准，提升神经网络鲁棒性验证。\n\n今天的 arXiv 更新展示了 AI 领域的多样创新，特别是 LLM 和生成模型的优化，但也暴露出实际应用中的挑战。感兴趣的读者可关注 LLM 相关工作，以获取更多前沿洞见！（总字数控制在合理范围内，聚焦高影响力论文）",
  "papers": [
    {
      "arxiv_id": "2406.05288v1",
      "title": "Optimal Eye Surgeon: Finding Image Priors through Sparse Generators at Initialization",
      "title_zh": "翻译失败",
      "authors": [
        "Avrajit Ghosh",
        "Xitong Zhang",
        "Kenneth K. Sun",
        "Qing Qu",
        "Saiprasad Ravishankar",
        "Rongrong Wang"
      ],
      "abstract": "We introduce Optimal Eye Surgeon (OES), a framework for pruning and training\ndeep image generator networks. Typically, untrained deep convolutional\nnetworks, which include image sampling operations, serve as effective image\npriors (Ulyanov et al., 2018). However, they tend to overfit to noise in image\nrestoration tasks due to being overparameterized. OES addresses this by\nadaptively pruning networks at random initialization to a level of\nunderparameterization. This process effectively captures low-frequency image\ncomponents even without training, by just masking. When trained to fit noisy\nimages, these pruned subnetworks, which we term Sparse-DIP, resist overfitting\nto noise. This benefit arises from underparameterization and the regularization\neffect of masking, constraining them in the manifold of image priors. We\ndemonstrate that subnetworks pruned through OES surpass other leading pruning\nmethods, such as the Lottery Ticket Hypothesis, which is known to be suboptimal\nfor image recovery tasks (Wu et al., 2023). Our extensive experiments\ndemonstrate the transferability of OES-masks and the characteristics of\nsparse-subnetworks for image generation. Code is available at\nhttps://github.com/Avra98/Optimal-Eye-Surgeon.git.",
      "tldr_zh": "本研究引入了 Optimal Eye Surgeon (OES) 框架，用于修剪和训练深度图像生成器网络，以优化图像 priors。OES 通过在随机初始化时自适应修剪网络使其欠参数化，仅通过 masking 即可捕获低频图像组件，并在训练时抵抗噪音过拟合，这些修剪后的子网络称为 Sparse-DIP。相比于 Lottery Ticket Hypothesis 等方法，OES 在图像恢复任务中表现出色，实验证明其 masks 具有可转移性，并展示了稀疏子网络的图像生成特性。",
      "categories": [
        "cs.CV",
        "cs.AI",
        "cs.LG"
      ],
      "primary_category": "cs.CV",
      "comment": "Pruning image generator networks at initialization to alleviate\n  overfitting",
      "pdf_url": "http://arxiv.org/pdf/2406.05288v1",
      "published_date": "2024-06-07 23:04:53 UTC",
      "updated_date": "2024-06-07 23:04:53 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-18T17:17:30.711183"
    },
    {
      "arxiv_id": "2406.05279v1",
      "title": "SuperPos-Prompt: Enhancing Soft Prompt Tuning of Language Models with Superposition of Multi Token Embeddings",
      "title_zh": "翻译失败",
      "authors": [
        "MohammadAli SadraeiJavaeri",
        "Ehsaneddin Asgari",
        "Alice Carolyn McHardy",
        "Hamid Reza Rabiee"
      ],
      "abstract": "Soft prompt tuning techniques have recently gained traction as an effective\nstrategy for the parameter-efficient tuning of pretrained language models,\nparticularly minimizing the required adjustment of model parameters. Despite\ntheir growing use, achieving optimal tuning with soft prompts, especially for\nsmaller datasets, remains a substantial challenge. This study makes two\ncontributions in this domain: (i) we introduce SuperPos-Prompt, a new\nreparameterization technique employing the superposition of multiple pretrained\nvocabulary embeddings to improve the learning of soft prompts. Our experiments\nacross several GLUE and SuperGLUE benchmarks consistently highlight\nSuperPos-Prompt's superiority over Residual Prompt tuning, exhibiting an\naverage score increase of $+6.4$ in T5-Small and $+5.0$ in T5-Base along with a\nfaster convergence. Remarkably, SuperPos-Prompt occasionally outperforms even\nfull fine-tuning methods. (ii) Additionally, we demonstrate enhanced\nperformance and rapid convergence by omitting dropouts from the frozen network,\nyielding consistent improvements across various scenarios and tuning methods.",
      "tldr_zh": "本文提出 SuperPos-Prompt，一种通过多 token 嵌入叠加（superposition）的重参数化技术，来提升语言模型的软提示调优（Soft prompt tuning），以更好地适应较小数据集的优化挑战。实验结果显示，在 GLUE 和 SuperGLUE 基准上，SuperPos-Prompt 相较于 Residual Prompt 调优，T5-Small 模型平均分数提升 6.4 分、T5-Base 提升 5.0 分，并实现了更快收敛，有时甚至优于全微调方法。作为额外贡献，作者发现从冻结网络中去除 dropout 可以进一步改善性能和收敛速度，在多种场景中均有效。",
      "categories": [
        "cs.CL",
        "cs.AI"
      ],
      "primary_category": "cs.CL",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2406.05279v1",
      "published_date": "2024-06-07 22:18:49 UTC",
      "updated_date": "2024-06-07 22:18:49 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-18T17:17:49.235664"
    },
    {
      "arxiv_id": "2406.05265v1",
      "title": "TLEX: An Efficient Method for Extracting Exact Timelines from TimeML Temporal Graphs",
      "title_zh": "TLEX：一种从 TimeML 时间图中提取精确时间线的高效方法",
      "authors": [
        "Mustafa Ocal",
        "Ning Xie",
        "Mark Finlayson"
      ],
      "abstract": "A timeline provides a total ordering of events and times, and is useful for a\nnumber of natural language understanding tasks. However, qualitative temporal\ngraphs that can be derived directly from text -- such as TimeML annotations --\nusually explicitly reveal only partial orderings of events and times. In this\nwork, we apply prior work on solving point algebra problems to the task of\nextracting timelines from TimeML annotated texts, and develop an exact,\nend-to-end solution which we call TLEX (TimeLine EXtraction). TLEX transforms\nTimeML annotations into a collection of timelines arranged in a\ntrunk-and-branch structure. Like what has been done in prior work, TLEX checks\nthe consistency of the temporal graph and solves it; however, it adds two novel\nfunctionalities. First, it identifies specific relations involved in an\ninconsistency (which could then be manually corrected) and, second, TLEX\nperforms a novel identification of sections of the timelines that have\nindeterminate order, information critical for downstream tasks such as aligning\nevents from different timelines. We provide detailed descriptions and analysis\nof the algorithmic components in TLEX, and conduct experimental evaluations by\napplying TLEX to 385 TimeML annotated texts from four corpora. We show that 123\nof the texts are inconsistent, 181 of them have more than one ``real world'' or\nmain timeline, and there are 2,541 indeterminate sections across all four\ncorpora. A sampling evaluation showed that TLEX is 98--100% accurate with 95%\nconfidence along five dimensions: the ordering of time-points, the number of\nmain timelines, the placement of time-points on main versus subordinate\ntimelines, the connecting point of branch timelines, and the location of the\nindeterminate sections. We provide a reference implementation of TLEX, the\nextracted timelines for all texts, and the manual corrections of the\ninconsistent texts.",
      "tldr_zh": "这篇论文提出了 TLEX，一种高效方法，用于从 TimeML Temporal Graphs 中提取精确的时间线，以提供事件和时间的总排序，支持自然语言理解任务。TLEX 将 TimeML 标注转化为树状结构的 timelines（trunk-and-branch），并引入新功能：识别不一致中的具体关系以便手动修正，以及检测顺序不确定的部分，这些信息对下游任务如跨时间线对齐至关重要。在实验中，TLEX 应用于 385 个 TimeML 标注文本，发现 123 个文本不一致、181 个有多个主 timelines，并显示出 98-100% 的准确率，提供参考实现和数据以促进进一步研究。",
      "categories": [
        "cs.CL",
        "cs.AI",
        "cs.IR"
      ],
      "primary_category": "cs.CL",
      "comment": "25 pages, 9 figures",
      "pdf_url": "http://arxiv.org/pdf/2406.05265v1",
      "published_date": "2024-06-07 21:20:32 UTC",
      "updated_date": "2024-06-07 21:20:32 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-18T17:18:05.978195"
    },
    {
      "arxiv_id": "2406.05259v1",
      "title": "A model of early word acquisition based on realistic-scale audiovisual naming events",
      "title_zh": "基于真实规模视听命名事件的早期词汇习得模型",
      "authors": [
        "Khazar Khorrami",
        "Okko Räsänen"
      ],
      "abstract": "Infants gradually learn to parse continuous speech into words and connect\nnames with objects, yet the mechanisms behind development of early word\nperception skills remain unknown. We studied the extent to which early words\ncan be acquired through statistical learning from regularities in audiovisual\nsensory input. We simulated word learning in infants up to 12 months of age in\na realistic setting, using a model that solely learns from statistical\nregularities in unannotated raw speech and pixel-level visual input. Crucially,\nthe quantity of object naming events was carefully designed to match that\naccessible to infants of comparable ages. Results show that the model\neffectively learns to recognize words and associate them with corresponding\nvisual objects, with a vocabulary growth rate comparable to that observed in\ninfants. The findings support the viability of general statistical learning for\nearly word perception, demonstrating how learning can operate without assuming\nany prior linguistic capabilities.",
      "tldr_zh": "本研究提出一个基于真实规模视听命名事件的模型，模拟婴儿通过统计学习（statistical learning）从未标注的原始语音和像素级视觉输入中习得早期单词。模型设计了与12个月内婴儿可接触的命名事件数量相匹配的场景，专注于从音频-视觉规律中识别单词并将其与对应物体关联。结果显示，该模型的词汇增长率与婴儿观察到的类似，支持统计学习在没有先验语言能力（prior linguistic capabilities）的情况下即可有效驱动早期词感知发展。",
      "categories": [
        "eess.AS",
        "cs.AI",
        "cs.CL"
      ],
      "primary_category": "eess.AS",
      "comment": "22 pages, 4 figures, journal article, submitted for review",
      "pdf_url": "http://arxiv.org/pdf/2406.05259v1",
      "published_date": "2024-06-07 21:05:59 UTC",
      "updated_date": "2024-06-07 21:05:59 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-18T17:18:16.605930"
    },
    {
      "arxiv_id": "2406.07578v1",
      "title": "Individual Packet Features are a Risk to Model Generalisation in ML-Based Intrusion Detection",
      "title_zh": "翻译失败",
      "authors": [
        "Kahraman Kostas",
        "Mike Just",
        "Michael A. Lones"
      ],
      "abstract": "Machine learning is increasingly used for intrusion detection in IoT\nnetworks. This paper explores the effectiveness of using individual packet\nfeatures (IPF), which are attributes extracted from a single network packet,\nsuch as timing, size, and source-destination information. Through literature\nreview and experiments, we identify the limitations of IPF, showing they can\nproduce misleadingly high detection rates. Our findings emphasize the need for\napproaches that consider packet interactions for robust intrusion detection.\nAdditionally, we demonstrate that models based on IPF often fail to generalize\nacross datasets, compromising their reliability in diverse IoT environments.",
      "tldr_zh": "这篇论文探讨了在基于 Machine Learning (ML) 的入侵检测系统中，使用 Individual Packet Features (IPF) 作为特征（如数据包的时间、尺寸和源-目的地信息）的潜在风险。研究者通过文献综述和实验证明，IPF 可能导致误导性的高检测率，但无法确保模型在不同数据集上的泛化能力，从而降低了其在多样化 IoT 环境中的可靠性。论文强调，需要采用考虑数据包交互的方法，以实现更稳健的入侵检测系统。",
      "categories": [
        "cs.CR",
        "cs.AI",
        "cs.NI"
      ],
      "primary_category": "cs.CR",
      "comment": "7 pages, 7 figures, 3 tables",
      "pdf_url": "http://arxiv.org/pdf/2406.07578v1",
      "published_date": "2024-06-07 21:05:33 UTC",
      "updated_date": "2024-06-07 21:05:33 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-18T17:18:18.486906"
    },
    {
      "arxiv_id": "2406.05255v1",
      "title": "Generative Explore-Exploit: Training-free Optimization of Generative Recommender Systems using LLM Optimizers",
      "title_zh": "生成式探索-利用：使用 LLM 优化器的生成式推荐系统的无训练优化",
      "authors": [
        "Lütfi Kerem Senel",
        "Besnik Fetahu",
        "Davis Yoshida",
        "Zhiyu Chen",
        "Giuseppe Castellucci",
        "Nikhita Vedula",
        "Jason Choi",
        "Shervin Malmasi"
      ],
      "abstract": "Recommender systems are widely used to suggest engaging content, and Large\nLanguage Models (LLMs) have given rise to generative recommenders. Such systems\ncan directly generate items, including for open-set tasks like question\nsuggestion. While the world knowledge of LLMs enable good recommendations,\nimproving the generated content through user feedback is challenging as\ncontinuously fine-tuning LLMs is prohibitively expensive. We present a\ntraining-free approach for optimizing generative recommenders by connecting\nuser feedback loops to LLM-based optimizers. We propose a generative\nexplore-exploit method that can not only exploit generated items with known\nhigh engagement, but also actively explore and discover hidden population\npreferences to improve recommendation quality. We evaluate our approach on\nquestion generation in two domains (e-commerce and general knowledge), and\nmodel user feedback with Click Through Rate (CTR). Experiments show our\nLLM-based explore-exploit approach can iteratively improve recommendations, and\nconsistently increase CTR. Ablation analysis shows that generative exploration\nis key to learning user preferences, avoiding the pitfalls of greedy\nexploit-only approaches. A human evaluation strongly supports our quantitative\nfindings.",
      "tldr_zh": "本研究提出了一种训练-free的方法，名为Generative Explore-Exploit，用于优化基于Large Language Models (LLMs)的生成式推荐系统，通过LLM optimizers连接用户反馈来改进推荐质量。该方法不仅能利用已知高互动内容的exploit策略，还能主动进行generative exploration，以发现隐藏的用户偏好，从而提升推荐的多样性和有效性。在电商和一般知识领域进行的实验，使用Click Through Rate (CTR)模拟用户反馈，结果显示该方法能迭代提高推荐性能，并显著增加CTR；消融分析和人工评估进一步证实，generative exploration是关键，避免了单纯exploit策略的局限性。",
      "categories": [
        "cs.CL",
        "cs.AI"
      ],
      "primary_category": "cs.CL",
      "comment": "Accepted at ACL 2024 Main Proceedings",
      "pdf_url": "http://arxiv.org/pdf/2406.05255v1",
      "published_date": "2024-06-07 20:41:59 UTC",
      "updated_date": "2024-06-07 20:41:59 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-18T17:18:29.995970"
    },
    {
      "arxiv_id": "2406.05250v3",
      "title": "LLM-Enhanced Bayesian Optimization for Efficient Analog Layout Constraint Generation",
      "title_zh": "LLM 增强的贝叶斯优化用于高效模拟布局",
      "authors": [
        "Guojin Chen",
        "Keren Zhu",
        "Seunggeun Kim",
        "Hanqing Zhu",
        "Yao Lai",
        "Bei Yu",
        "David Z. Pan"
      ],
      "abstract": "Analog layout synthesis faces significant challenges due to its dependence on\nmanual processes, considerable time requirements, and performance instability.\nCurrent Bayesian Optimization (BO)-based techniques for analog layout\nsynthesis, despite their potential for automation, suffer from slow convergence\nand extensive data needs, limiting their practical application. This paper\npresents the \\texttt{LLANA} framework, a novel approach that leverages Large\nLanguage Models (LLMs) to enhance BO by exploiting the few-shot learning\nabilities of LLMs for more efficient generation of analog design-dependent\nparameter constraints. Experimental results demonstrate that \\texttt{LLANA} not\nonly achieves performance comparable to state-of-the-art (SOTA) BO methods but\nalso enables a more effective exploration of the analog circuit design space,\nthanks to LLM's superior contextual understanding and learning efficiency. The\ncode is available at https://github.com/dekura/LLANA.",
      "tldr_zh": "本论文针对模拟布局合成的手动过程耗时、性能不稳定等问题，指出现有 Bayesian Optimization (BO) 方法因收敛缓慢和数据需求大而受限。作者提出 LLANA 框架，通过整合 Large Language Models (LLMs) 的 few-shot learning 能力来增强 BO，实现更高效的模拟设计参数约束生成。实验结果表明，LLANA 性能可媲美 State-of-the-Art (SOTA) BO 方法，并实现了对模拟电路设计空间的更有效探索，代码已在 GitHub 上开源。",
      "categories": [
        "cs.AI",
        "cs.AR",
        "cs.LG"
      ],
      "primary_category": "cs.AI",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2406.05250v3",
      "published_date": "2024-06-07 20:22:36 UTC",
      "updated_date": "2024-12-06 12:40:53 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-18T17:18:45.965604"
    },
    {
      "arxiv_id": "2406.05249v1",
      "title": "A Language Model-Guided Framework for Mining Time Series with Distributional Shifts",
      "title_zh": "翻译失败",
      "authors": [
        "Haibei Zhu",
        "Yousef El-Laham",
        "Elizabeth Fons",
        "Svitlana Vyetrenko"
      ],
      "abstract": "Effective utilization of time series data is often constrained by the\nscarcity of data quantity that reflects complex dynamics, especially under the\ncondition of distributional shifts. Existing datasets may not encompass the\nfull range of statistical properties required for robust and comprehensive\nanalysis. And privacy concerns can further limit their accessibility in domains\nsuch as finance and healthcare. This paper presents an approach that utilizes\nlarge language models and data source interfaces to explore and collect time\nseries datasets. While obtained from external sources, the collected data share\ncritical statistical properties with primary time series datasets, making it\npossible to model and adapt to various scenarios. This method enlarges the data\nquantity when the original data is limited or lacks essential properties. It\nsuggests that collected datasets can effectively supplement existing datasets,\nespecially involving changes in data distribution. We demonstrate the\neffectiveness of the collected datasets through practical examples and show how\ntime series forecasting foundation models fine-tuned on these datasets achieve\ncomparable performance to those models without fine-tuning.",
      "tldr_zh": "这篇论文提出了一种由Large Language Models引导的框架，用于挖掘存在Distributional Shifts的时间序列数据，以解决数据量稀缺、统计属性不完整和隐私限制等问题。该框架利用Large Language Models和数据源接口探索并收集新数据集，这些数据集共享原有数据的关键统计属性，从而有效补充现有数据集并适应分布变化。通过实际例子，论文证明了在这些收集的数据上微调的时间序列预测基础模型，能实现与未微调模型相当的性能。",
      "categories": [
        "cs.CE",
        "cs.AI"
      ],
      "primary_category": "cs.CE",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2406.05249v1",
      "published_date": "2024-06-07 20:21:07 UTC",
      "updated_date": "2024-06-07 20:21:07 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-18T17:18:54.691110"
    },
    {
      "arxiv_id": "2406.12897v1",
      "title": "Advancing Histopathology-Based Breast Cancer Diagnosis: Insights into Multi-Modality and Explainability",
      "title_zh": "翻译失败",
      "authors": [
        "Faseela Abdullakutty",
        "Younes Akbari",
        "Somaya Al-Maadeed",
        "Ahmed Bouridane",
        "Rifat Hamoudi"
      ],
      "abstract": "It is imperative that breast cancer is detected precisely and timely to\nimprove patient outcomes. Diagnostic methodologies have traditionally relied on\nunimodal approaches; however, medical data analytics is integrating diverse\ndata sources beyond conventional imaging. Using multi-modal techniques,\nintegrating both image and non-image data, marks a transformative advancement\nin breast cancer diagnosis. The purpose of this review is to explore the\nburgeoning field of multimodal techniques, particularly the fusion of\nhistopathology images with non-image data. Further, Explainable AI (XAI) will\nbe used to elucidate the decision-making processes of complex algorithms,\nemphasizing the necessity of explainability in diagnostic processes. This\nreview utilizes multi-modal data and emphasizes explainability to enhance\ndiagnostic accuracy, clinician confidence, and patient engagement, ultimately\nfostering more personalized treatment strategies for breast cancer, while also\nidentifying research gaps in multi-modality and explainability, guiding future\nstudies, and contributing to the strategic direction of the field.",
      "tldr_zh": "这篇综述探讨了基于组织病理学的乳腺癌诊断进展，强调多模态技术（Multi-Modality）的应用，包括融合组织病理图像（Histopathology images）和非图像数据，以提升诊断准确性和个性化治疗策略。论文突出了Explainable AI (XAI) 的重要性，用于阐明复杂算法的决策过程，从而增强临床医生信心和患者参与。最终，它识别了多模态及XAI领域的研究空白，并为未来研究提供指导方向。",
      "categories": [
        "cs.LG",
        "cs.AI",
        "cs.CV"
      ],
      "primary_category": "cs.LG",
      "comment": "31 pages including references",
      "pdf_url": "http://arxiv.org/pdf/2406.12897v1",
      "published_date": "2024-06-07 19:23:22 UTC",
      "updated_date": "2024-06-07 19:23:22 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-18T17:19:08.001649"
    },
    {
      "arxiv_id": "2406.05223v3",
      "title": "CorDA: Context-Oriented Decomposition Adaptation of Large Language Models for Task-Aware Parameter-Efficient Fine-tuning",
      "title_zh": "翻译失败",
      "authors": [
        "Yibo Yang",
        "Xiaojie Li",
        "Zhongzhu Zhou",
        "Shuaiwen Leon Song",
        "Jianlong Wu",
        "Liqiang Nie",
        "Bernard Ghanem"
      ],
      "abstract": "Current parameter-efficient fine-tuning (PEFT) methods build adapters widely\nagnostic of the context of downstream task to learn, or the context of\nimportant knowledge to maintain. As a result, there is often a performance gap\ncompared to full-parameter fine-tuning, and meanwhile the fine-tuned model\nsuffers from catastrophic forgetting of the pre-trained world knowledge. In\nthis paper, we propose CorDA, a Context-oriented Decomposition Adaptation\nmethod that builds learnable task-aware adapters from weight decomposition\noriented by the context of downstream task or the world knowledge to maintain.\nConcretely, we collect a few data samples, and perform singular value\ndecomposition for each linear layer of a pre-trained LLM multiplied by the\ncovariance matrix of the input activation using these samples. The inverse of\nthe covariance matrix is multiplied with the decomposed components to\nreconstruct the original weights. By doing so, the context of the\nrepresentative samples is captured through deciding the factorizing\norientation. Our method enables two options, the knowledge-preserved adaptation\nand the instruction-previewed adaptation. For the former, we use\nquestion-answering samples to obtain the covariance matrices, and use the\ndecomposed components with the smallest $r$ singular values to initialize a\nlearnable adapter, with the others frozen such that the world knowledge is\nbetter preserved. For the latter, we use the instruction data from the\nfine-tuning task, such as math or coding, to orientate the decomposition and\ntrain the largest $r$ components that most correspond to the task to learn. We\nconduct extensive experiments on Math, Code, and Instruction Following tasks.",
      "tldr_zh": "该论文提出 CorDA 方法，即一种基于上下文导向的权重分解适应技术，用于实现任务感知的 Parameter-Efficient Fine-tuning (PEFT)，以解决现有 PEFT 方法忽略下游任务上下文和世界知识导致的性能差距和灾难性遗忘问题。CorDA 通过使用少量数据样本，对预训练 Large Language Models (LLM) 的线性层进行奇异值分解 (SVD)，结合输入激活的协方差矩阵来构建可学习的任务感知适配器，从而捕获任务或知识的上下文。方法包括两种选项：知识保留适应，使用问答样本初始化适配器并冻结部分组件以维护世界知识；指令预览适应，使用任务指令数据训练与任务相关的组件。在 Math、Code 和指令跟随任务的广泛实验中，CorDA 展示了显著的性能提升。",
      "categories": [
        "cs.LG",
        "cs.AI"
      ],
      "primary_category": "cs.LG",
      "comment": "NeurIPS 2024",
      "pdf_url": "http://arxiv.org/pdf/2406.05223v3",
      "published_date": "2024-06-07 19:10:35 UTC",
      "updated_date": "2025-03-07 21:18:41 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-18T17:19:20.364983"
    },
    {
      "arxiv_id": "2406.05213v2",
      "title": "On Subjective Uncertainty Quantification and Calibration in Natural Language Generation",
      "title_zh": "自然语言生成中的主观不确定性量化与校准",
      "authors": [
        "Ziyu Wang",
        "Chris Holmes"
      ],
      "abstract": "Applications of large language models often involve the generation of\nfree-form responses, in which case uncertainty quantification becomes\nchallenging. This is due to the need to identify task-specific uncertainties\n(e.g., about the semantics) which appears difficult to define in general cases.\nThis work addresses these challenges from a perspective of Bayesian decision\ntheory, starting from the assumption that our utility is characterized by a\nsimilarity measure that compares a generated response with a hypothetical true\nresponse. We discuss how this assumption enables principled quantification of\nthe model's subjective uncertainty and its calibration. We further derive a\nmeasure for epistemic uncertainty, based on a missing data perspective and its\ncharacterization as an excess risk. The proposed methods can be applied to\nblack-box language models. We illustrate the methods on question answering and\nmachine translation tasks. Our experiments provide a principled evaluation of\ntask-specific calibration, and demonstrate that epistemic uncertainty offers a\npromising deferral strategy for efficient data acquisition in in-context\nlearning.",
      "tldr_zh": "这篇论文探讨了在自然语言生成中，主观不确定性量化和校准的挑战，特别是针对任务特定不确定性（如语义不确定性）。作者从贝叶斯决策理论（Bayesian decision theory）的视角出发，假设效用由一个相似度度量来比较生成的响应和假设的真实响应，从而提出原则性的方法来量化主观不确定性和校准，并推导了认识不确定性（epistemic uncertainty）作为超额风险的度量。实验在问答和机器翻译任务上验证了这些方法，提供任务特定的校准评估，并证明认识不确定性可作为高效的数据获取策略在 in-context learning 中实现延期决策。",
      "categories": [
        "cs.CL",
        "cs.AI",
        "cs.LG",
        "stat.ML"
      ],
      "primary_category": "cs.CL",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2406.05213v2",
      "published_date": "2024-06-07 18:54:40 UTC",
      "updated_date": "2024-10-18 02:55:27 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-18T17:19:35.773728"
    },
    {
      "arxiv_id": "2406.05194v2",
      "title": "LLMs Are Not Intelligent Thinkers: Introducing Mathematical Topic Tree Benchmark for Comprehensive Evaluation of LLMs",
      "title_zh": "翻译失败",
      "authors": [
        "Arash Gholami Davoodi",
        "Seyed Pouyan Mousavi Davoudi",
        "Pouya Pezeshkpour"
      ],
      "abstract": "Large language models (LLMs) demonstrate impressive capabilities in\nmathematical reasoning. However, despite these achievements, current\nevaluations are mostly limited to specific mathematical topics, and it remains\nunclear whether LLMs are genuinely engaging in reasoning. To address these\ngaps, we present the Mathematical Topics Tree (MaTT) benchmark, a challenging\nand structured benchmark that offers 1,958 questions across a wide array of\nmathematical subjects, each paired with a detailed hierarchical chain of\ntopics. Upon assessing different LLMs using the MaTT benchmark, we find that\nthe most advanced model, GPT-4, achieved a mere 54\\% accuracy in a\nmultiple-choice scenario. Interestingly, even when employing Chain-of-Thought\nprompting, we observe mostly no notable improvement. Moreover, LLMs accuracy\ndramatically reduced by up to 24.2 percentage point when the questions were\npresented without providing choices. Further detailed analysis of the LLMs'\nperformance across a range of topics showed significant discrepancy even for\nclosely related subtopics within the same general mathematical area. In an\neffort to pinpoint the reasons behind LLMs performances, we conducted a manual\nevaluation of the completeness and correctness of the explanations generated by\nGPT-4 when choices were available. Surprisingly, we find that in only 53.3\\% of\nthe instances where the model provided a correct answer, the accompanying\nexplanations were deemed complete and accurate, i.e., the model engaged in\ngenuine reasoning.",
      "tldr_zh": "这篇论文质疑了大型语言模型（LLMs）的真正推理能力，并引入了Mathematical Topics Tree (MaTT)基准测试，该基准包含1958个问题，覆盖广泛数学主题并配有层次化主题链，以进行全面评估。实验结果显示，GPT-4在多选场景下仅达到54%的准确率，使用Chain-of-Thought提示几乎无显著改善，且无选项时准确率下降多达24.2%。此外，LLMs在相关子主题间的表现存在显著差异，且手动评估发现，GPT-4正确答案中仅有53.3%的解释是完整和准确的，表明LLMs可能未真正从事智能推理。",
      "categories": [
        "cs.CL",
        "cs.AI",
        "cs.LG"
      ],
      "primary_category": "cs.CL",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2406.05194v2",
      "published_date": "2024-06-07 18:21:26 UTC",
      "updated_date": "2025-03-29 17:29:24 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-18T17:19:47.296757"
    },
    {
      "arxiv_id": "2406.05190v1",
      "title": "Evaluating the Effectiveness of Data Augmentation for Emotion Classification in Low-Resource Settings",
      "title_zh": "评估数据增强在低资源环境下的情感分类有效性",
      "authors": [
        "Aashish Arora",
        "Elsbeth Turcan"
      ],
      "abstract": "Data augmentation has the potential to improve the performance of machine\nlearning models by increasing the amount of training data available. In this\nstudy, we evaluated the effectiveness of different data augmentation techniques\nfor a multi-label emotion classification task using a low-resource dataset. Our\nresults showed that Back Translation outperformed autoencoder-based approaches\nand that generating multiple examples per training instance led to further\nperformance improvement. In addition, we found that Back Translation generated\nthe most diverse set of unigrams and trigrams. These findings demonstrate the\nutility of Back Translation in enhancing the performance of emotion\nclassification models in resource-limited situations.",
      "tldr_zh": "本研究评估了不同数据增强技术在低资源数据集上的多标签情感分类任务中的效果。结果显示，Back Translation 方法优于基于自编码器的方法，并在生成多个示例每训练实例时进一步提升了模型性能。此外，Back Translation 产生了最多样化的单字和三字组，这些发现证明了其在资源有限情境下提升情感分类模型实用性的价值。",
      "categories": [
        "cs.LG",
        "cs.AI",
        "cs.CL"
      ],
      "primary_category": "cs.LG",
      "comment": "The first author contributed significantly",
      "pdf_url": "http://arxiv.org/pdf/2406.05190v1",
      "published_date": "2024-06-07 18:13:27 UTC",
      "updated_date": "2024-06-07 18:13:27 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-18T17:19:56.969555"
    },
    {
      "arxiv_id": "2406.05189v2",
      "title": "Analyzing the factors that are involved in length of inpatient stay at the hospital for diabetes patients",
      "title_zh": "分析影响糖尿病患者住院时间长度的相关因素",
      "authors": [
        "Jorden Lam",
        "Kunpeng Xu"
      ],
      "abstract": "The paper investigates the escalating concerns surrounding the surge in\ndiabetes cases, exacerbated by the COVID-19 pandemic, and the subsequent strain\non medical resources. The research aims to construct a predictive model\nquantifying factors influencing inpatient hospital stay durations for diabetes\npatients, offering insights to hospital administrators for improved patient\nmanagement strategies. The literature review highlights the increasing\nprevalence of diabetes, emphasizing the need for continued attention and\nanalysis of urban-rural disparities in healthcare access. International studies\nunderscore the financial implications and healthcare burden associated with\ndiabetes-related hospitalizations and complications, emphasizing the\nsignificance of effective management strategies. The methodology involves a\nquantitative approach, utilizing a dataset comprising 10,000 observations of\ndiabetic inpatient encounters in U.S. hospitals from 1999 to 2008. Predictive\nmodeling techniques, particularly Generalized Linear Models (GLM), are employed\nto develop a model predicting hospital stay durations based on patient\ndemographics, admission types, medical history, and treatment regimen. The\nresults highlight the influence of age, medical history, and treatment regimen\non hospital stay durations for diabetes patients. Despite model limitations,\nsuch as heteroscedasticity and deviations from normality in residual analysis,\nthe findings offer valuable insights for hospital administrators in patient\nmanagement. The paper concludes with recommendations for future research to\naddress model limitations and explore the implications of predictive models on\nhealthcare management strategies, ensuring equitable patient care and resource\nallocation.",
      "tldr_zh": "该研究针对糖尿病患者住院时间增加的问题，特别是在COVID-19疫情的影响下，构建了一个预测模型来量化影响因素，包括患者人口统计、入院类型、医疗历史和治疗方案，以帮助医院管理者优化患者管理策略。研究采用了定量方法，基于1999-2008年间美国医院的10,000个糖尿病住院病例数据集，并运用广义线性模型(GLM)进行预测建模。结果显示，年龄、医疗历史和治疗方案是影响住院时间的主要因素，尽管模型存在异方差性和残差非正态等限制，但为改善医疗资源分配提供了宝贵见解。未来研究应进一步解决模型缺陷，并探讨预测模型在医疗管理中的应用，以确保公平的患者护理。",
      "categories": [
        "stat.AP",
        "cs.AI"
      ],
      "primary_category": "stat.AP",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2406.05189v2",
      "published_date": "2024-06-07 18:13:21 UTC",
      "updated_date": "2025-02-01 03:26:46 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-18T17:20:10.143912"
    },
    {
      "arxiv_id": "2406.05187v2",
      "title": "How to Strategize Human Content Creation in the Era of GenAI?",
      "title_zh": "在 GenAI 时代，如何制定人类内容创作的策略？",
      "authors": [
        "Seyed A. Esmaeili",
        "Kevin Lim",
        "Kshipra Bhawalkar",
        "Zhe Feng",
        "Di Wang",
        "Haifeng Xu"
      ],
      "abstract": "Generative AI (GenAI) will have significant impact on content creation\nplatforms. In this paper, we study the dynamic competition between a GenAI and\na human contributor. Unlike the human, the GenAI's content only improves when\nmore contents are created by the human over time; however, GenAI has the\nadvantage of generating content at a lower cost. We study the algorithmic\nproblem in this dynamic competition model about how the human contributor can\nmaximize her utility when competing against the GenAI for content generation\nover a set of topics. In time-sensitive content domains (e.g., news or pop\nmusic creation) where contents' value diminishes over time, we show that there\nis no polynomial time algorithm for finding the human's optimal (dynamic)\nstrategy, unless the randomized exponential time hypothesis is false.\nFortunately, we are able to design a polynomial time algorithm that naturally\ncycles between myopically optimizing over a short time window and pausing and\nprovably guarantees an approximation ratio of $\\frac{1}{2}$. We then turn to\ntime-insensitive content domains where contents do not lose their value (e.g.,\ncontents on history facts). Interestingly, we show that this setting permits a\npolynomial time algorithm that maximizes the human's utility in the long run.\nFinally, we conduct simulations that demonstrate the advantage of our\nalgorithms in comparison to a collection of baselines.",
      "tldr_zh": "这篇论文探讨了在 Generative AI (GenAI) 时代，人类内容创建者如何制定策略与 GenAI 竞争，以最大化自身效用。研究构建了一个动态竞争模型，分析了 GenAI 的内容质量依赖于人类输入但成本更低的情况；在时间敏感领域（如新闻），证明了寻找人类最优策略没有多项式时间算法，但提出了一种在短期优化和暂停之间循环的算法，保证了 1/2 的近似比。在时间不敏感领域（如历史事实），他们开发了能精确最大化人类效用的多项式时间算法，并通过模拟实验展示了这些算法相对于基线的优势。",
      "categories": [
        "cs.GT",
        "cs.AI",
        "cs.HC",
        "cs.LG"
      ],
      "primary_category": "cs.GT",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2406.05187v2",
      "published_date": "2024-06-07 18:12:04 UTC",
      "updated_date": "2025-03-09 02:23:50 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-18T17:20:22.994690"
    },
    {
      "arxiv_id": "2406.05183v1",
      "title": "The Factorization Curse: Which Tokens You Predict Underlie the Reversal Curse and More",
      "title_zh": "翻译失败",
      "authors": [
        "Ouail Kitouni",
        "Niklas Nolte",
        "Diane Bouchacourt",
        "Adina Williams",
        "Mike Rabbat",
        "Mark Ibrahim"
      ],
      "abstract": "Today's best language models still struggle with hallucinations: factually\nincorrect generations, which impede their ability to reliably retrieve\ninformation seen during training. The reversal curse, where models cannot\nrecall information when probed in a different order than was encountered during\ntraining, exemplifies this in information retrieval. We reframe the reversal\ncurse as a factorization curse - a failure of models to learn the same joint\ndistribution under different factorizations. Through a series of controlled\nexperiments with increasing levels of realism including WikiReversal, a setting\nwe introduce to closely simulate a knowledge intensive finetuning task, we find\nthat the factorization curse is an inherent failure of the next-token\nprediction objective used in popular large language models. Moreover, we\ndemonstrate reliable information retrieval cannot be solved with scale,\nreversed tokens, or even naive bidirectional-attention training. Consequently,\nvarious approaches to finetuning on specialized data would necessarily provide\nmixed results on downstream tasks, unless the model has already seen the right\nsequence of tokens. Across five tasks of varying levels of complexity, our\nresults uncover a promising path forward: factorization-agnostic objectives can\nsignificantly mitigate the reversal curse and hint at improved knowledge\nstorage and planning capabilities.",
      "tldr_zh": "本文将语言模型的逆转诅咒(reversal curse)重新框架为因子诅咒(factorization curse)，揭示了next-token prediction目标在不同因子化下学习联合分布的固有失败，导致信息检索不准确。通过控制实验和引入的WikiReversal设置，作者证明了该问题无法通过模型规模化、逆转标记或双向注意力训练解决。研究发现，采用factorization-agnostic objectives可以显著缓解逆转诅咒，并提升语言模型的知识存储和规划能力。",
      "categories": [
        "cs.LG",
        "cs.AI",
        "cs.CL"
      ],
      "primary_category": "cs.LG",
      "comment": "18 pages, 7 figures",
      "pdf_url": "http://arxiv.org/pdf/2406.05183v1",
      "published_date": "2024-06-07 18:00:37 UTC",
      "updated_date": "2024-06-07 18:00:37 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-18T17:20:35.710686"
    },
    {
      "arxiv_id": "2406.16915v1",
      "title": "Unlocking Telemetry Potential: Self-Supervised Learning for Continuous Clinical Electrocardiogram Monitoring",
      "title_zh": "释放遥测潜力：自监督学习用于连续临床心电图监测",
      "authors": [
        "Thomas Kite",
        "Uzair Tahamid Siam",
        "Brian Ayers",
        "Nicholas Houstis",
        "Aaron D Aguirre"
      ],
      "abstract": "Machine learning (ML) applied to routine patient monitoring within intensive\ncare units (ICUs) has the potential to improve care by providing clinicians\nwith novel insights into each patient's health and expected response to\ninterventions. This paper applies deep learning to a large volume of unlabeled\nelectrocardiogram (ECG) telemetry signals, which are commonly used for\ncontinuous patient monitoring in hospitals but have important differences from\nthe standard, single time-point 12-lead ECG used in many prior machine learning\nstudies. We applied self-supervised learning to pretrain a spectrum of deep\nnetworks on approximately 147,000 hours of ECG telemetry data. Our approach\nleverages this dataset to train models that significantly improve performance\non four distinct downstream tasks compared with direct supervised learning\nusing labeled data. These pretrained models enable medically useful predictions\nand estimates in smaller patient cohorts that are typically limited by the\nscarcity of labels. Notably, we demonstrate that our pretrained networks can\ncontinuously annotate ECG telemetry signals, thereby providing monitoring\ncapabilities that are often unavailable due to the requirement for specialized\nexpertise and time-consuming professional annotations.",
      "tldr_zh": "这篇论文探讨了使用自监督学习（Self-Supervised Learning）来提升重症监护室（ICU）患者连续心电图（ECG）遥测监测的潜力。研究者利用约147,000小时的未标记ECG数据预训练深度网络，与直接监督学习相比，该方法显著提高了四个下游任务的性能。预训练模型能在标签稀缺的小样本队列中进行医疗预测和连续ECG注释，减少了对专业专家标注的依赖，从而为临床监测提供更高效的见解。",
      "categories": [
        "eess.SP",
        "cs.AI",
        "cs.CY",
        "cs.LG"
      ],
      "primary_category": "eess.SP",
      "comment": "17 pages, 9 figures",
      "pdf_url": "http://arxiv.org/pdf/2406.16915v1",
      "published_date": "2024-06-07 18:00:00 UTC",
      "updated_date": "2024-06-07 18:00:00 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-18T17:20:46.935831"
    },
    {
      "arxiv_id": "2406.05132v3",
      "title": "3D-GRAND: A Million-Scale Dataset for 3D-LLMs with Better Grounding and Less Hallucination",
      "title_zh": "翻译失败",
      "authors": [
        "Jianing Yang",
        "Xuweiyi Chen",
        "Nikhil Madaan",
        "Madhavan Iyengar",
        "Shengyi Qian",
        "David F. Fouhey",
        "Joyce Chai"
      ],
      "abstract": "The integration of language and 3D perception is crucial for embodied agents\nand robots that comprehend and interact with the physical world. While large\nlanguage models (LLMs) have demonstrated impressive language understanding and\ngeneration capabilities, their adaptation to 3D environments (3D-LLMs) remains\nin its early stages. A primary challenge is a lack of large-scale datasets with\ndense grounding between language and 3D scenes. We introduce 3D-GRAND, a\npioneering large-scale dataset comprising 40,087 household scenes paired with\n6.2 million densely-grounded scene-language instructions. Our results show that\ninstruction tuning with 3D-GRAND significantly enhances grounding capabilities\nand reduces hallucinations in 3D-LLMs. As part of our contributions, we propose\na comprehensive benchmark 3D-POPE to systematically evaluate hallucination in\n3D-LLMs, enabling fair comparisons of models. Our experiments highlight a\nscaling effect between dataset size and 3D-LLM performance, emphasizing the\nimportance of large-scale 3D-text datasets for embodied AI research. Our\nresults demonstrate early signals for effective sim-to-real transfer,\nindicating that models trained on large synthetic data can perform well on\nreal-world 3D scans. Through 3D-GRAND and 3D-POPE, we aim to equip the embodied\nAI community with resources and insights to lead to more reliable and\nbetter-grounded 3D-LLMs. Project website: https://3d-grand.github.io",
      "tldr_zh": "本研究引入了3D-GRAND，这是一个大规模数据集，包含40,087个家庭场景和6.2百万个密集grounding的场景-语言指令，旨在解决3D-LLMs在语言与3D环境整合中的数据集缺失问题。通过instruction tuning在3D-GRAND上训练，显著提升了3D-LLMs的grounding能力并减少了hallucination。研究者还提出了全面benchmark 3D-POPE，用于系统评估3D-LLMs的hallucination，并证明了数据集规模与模型性能之间的scaling effect，以及从模拟到真实世界的有效转移，为embodied AI领域提供可靠资源。",
      "categories": [
        "cs.CV",
        "cs.AI",
        "cs.CL",
        "cs.LG",
        "cs.RO"
      ],
      "primary_category": "cs.CV",
      "comment": "CVPR 2025. Project website: https://3d-grand.github.io",
      "pdf_url": "http://arxiv.org/pdf/2406.05132v3",
      "published_date": "2024-06-07 17:59:59 UTC",
      "updated_date": "2025-03-20 23:06:14 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-18T17:20:59.393743"
    },
    {
      "arxiv_id": "2406.09052v1",
      "title": "Data-Free Generative Replay for Class-Incremental Learning on Imbalanced Data",
      "title_zh": "翻译失败",
      "authors": [
        "Sohaib Younis",
        "Bernhard Seeger"
      ],
      "abstract": "Continual learning is a challenging problem in machine learning, especially\nfor image classification tasks with imbalanced datasets. It becomes even more\nchallenging when it involves learning new classes incrementally. One method for\nincremental class learning, addressing dataset imbalance, is rehearsal using\npreviously stored data. In rehearsal-based methods, access to previous data is\nrequired for either training the classifier or the generator, but it may not be\nfeasible due to storage, legal, or data access constraints. Although there are\nmany rehearsal-free alternatives for class incremental learning, such as\nparameter or loss regularization, knowledge distillation, and dynamic\narchitectures, they do not consistently achieve good results, especially on\nimbalanced data. This paper proposes a new approach called Data-Free Generative\nReplay (DFGR) for class incremental learning, where the generator is trained\nwithout access to real data. In addition, DFGR also addresses dataset imbalance\nin continual learning of an image classifier. Instead of using training data,\nDFGR trains a generator using mean and variance statistics of batch-norm and\nfeature maps derived from a pre-trained classification model. The results of\nour experiments demonstrate that DFGR performs significantly better than other\ndata-free methods and reveal the performance impact of specific parameter\nsettings. DFGR achieves up to 88.5% and 46.6% accuracy on MNIST and\nFashionMNIST datasets, respectively. Our code is available at\nhttps://github.com/2younis/DFGR",
      "tldr_zh": "本文提出了一种名为 Data-Free Generative Replay (DFGR) 的新方法，用于处理不平衡数据集上的类增量学习 (Class-Incremental Learning)，旨在解决传统 rehearsal 方法对先前数据的依赖问题。DFGR 通过利用预训练分类模型的批标准化 (batch-norm) 和特征图的均值与方差统计信息来训练生成器，从而在不访问真实数据的情况下实现持续学习。实验结果表明，DFGR 在 MNIST 和 FashionMNIST 数据集上分别取得了 88.5% 和 46.6% 的准确率，比其他 data-free 方法表现显著优越。该方法有效缓解了数据集不平衡的影响，为 Continual Learning 中的数据隐私和存储约束提供了可行方案。",
      "categories": [
        "cs.LG",
        "cs.AI"
      ],
      "primary_category": "cs.LG",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2406.09052v1",
      "published_date": "2024-06-07 17:51:27 UTC",
      "updated_date": "2024-06-07 17:51:27 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-18T17:21:11.949653"
    },
    {
      "arxiv_id": "2406.05113v2",
      "title": "LlavaGuard: An Open VLM-based Framework for Safeguarding Vision Datasets and Models",
      "title_zh": "翻译失败",
      "authors": [
        "Lukas Helff",
        "Felix Friedrich",
        "Manuel Brack",
        "Kristian Kersting",
        "Patrick Schramowski"
      ],
      "abstract": "This paper introduces LlavaGuard, a suite of VLM-based vision safeguards that\naddress the critical need for reliable guardrails in the era of large-scale\ndata and models. To this end, we establish a novel open framework, describing a\ncustomizable safety taxonomy, data preprocessing, augmentation, and training\nsetup. For teaching a VLM safeguard on safety, we further create a multimodal\nsafety dataset with high-quality human expert annotations, where each image is\nlabeled with a safety rating, category and rationale. We also employ advanced\naugmentations to support context-specific assessments. The resulting LlavaGuard\nmodels, ranging from 0.5B to 7B, serve as a versatile tool for evaluating the\nsafety compliance of visual content against flexible policies. In comprehensive\nexperiments, LlavaGuard outperforms both state-of-the-art safeguards and VLMs\nin accuracy and in flexibly handling different policies. Additionally, we\ndemonstrate LlavaGuard's performance in two real-world applications:\nlarge-scale dataset annotation and moderation of text-to-image models. We make\nour entire framework publicly available, including the dataset and model\nweights.",
      "tldr_zh": "本研究引入了 LlavaGuard，一种基于视觉语言模型 (VLM) 的开源框架，用于保护视觉数据集和模型的安全性。该框架包括可定制的安全分类法、数据预处理、增强和训练设置，并创建了一个多模态安全数据集，由人类专家标注每个图像的安全评级、类别和理由。实验结果显示，LlavaGuard 模型（从 0.5B 到 7B 参数）在准确性和灵活处理不同政策方面优于现有最先进的安全措施和 VLM，并在实际应用如大规模数据集标注和文本到图像模型审核中表现出色。该框架及其数据集和模型权重已公开可用，促进了进一步的研究和应用。",
      "categories": [
        "cs.CV",
        "cs.AI",
        "cs.LG"
      ],
      "primary_category": "cs.CV",
      "comment": "Project page at\n  https://ml-research.github.io/human-centered-genai/projects/llavaguard/index.html",
      "pdf_url": "http://arxiv.org/pdf/2406.05113v2",
      "published_date": "2024-06-07 17:44:32 UTC",
      "updated_date": "2025-01-31 15:57:48 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-18T17:21:22.791904"
    },
    {
      "arxiv_id": "2406.07577v1",
      "title": "Structured Active Inference (Extended Abstract)",
      "title_zh": "结构化主动推理（扩展摘要）",
      "authors": [
        "Toby St Clere Smithe"
      ],
      "abstract": "We introduce structured active inference, a large generalization and\nformalization of active inference using the tools of categorical systems\ntheory. We cast generative models formally as systems \"on an interface\", with\nthe latter being a compositional abstraction of the usual notion of Markov\nblanket; agents are then 'controllers' for their generative models, formally\ndual to them. This opens the active inference landscape to new horizons, such\nas: agents with structured interfaces (e.g. with 'mode-dependence', or that\ninteract with computer APIs); agents that can manage other agents; and\n'meta-agents', that use active inference to change their (internal or external)\nstructure. With structured interfaces, we also gain structured ('typed')\npolicies, which are amenable to formal verification, an important step towards\nsafe artificial agents. Moreover, we can make use of categorical logic to\ndescribe express agents' goals as formal predicates, whose satisfaction may be\ndependent on the interaction context. This points towards powerful\ncompositional tools to constrain and control self-organizing ensembles of\nagents.",
      "tldr_zh": "本研究引入了 structured active inference，这是一种利用 categorical systems theory 对 active inference 的重大泛化和形式化，将生成模型形式化为“on an interface”的系统，其中 interface 是 Markov blanket 的组合抽象。代理被视为生成模型的“controllers”，与其形式上对偶，从而扩展了 active inference 的应用，包括支持结构化 interfaces（如模式依赖或与计算机 APIs 交互）的代理、代理管理以及“meta-agents”来改变自身结构。结构化 interfaces 允许实现结构化（typed）policies，便于进行 formal verification，从而提升人工智能代理的安全性。该框架还通过 categorical logic 将代理的目标表述为形式谓词，这些谓词的满足依赖于交互上下文，提供强大的组合工具来约束和控制代理的自我组织集合。",
      "categories": [
        "cs.AI",
        "math.CT"
      ],
      "primary_category": "cs.AI",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2406.07577v1",
      "published_date": "2024-06-07 17:22:44 UTC",
      "updated_date": "2024-06-07 17:22:44 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-18T17:21:37.244718"
    },
    {
      "arxiv_id": "2406.05090v1",
      "title": "Provably Better Explanations with Optimized Aggregation of Feature Attributions",
      "title_zh": "翻译失败",
      "authors": [
        "Thomas Decker",
        "Ananta R. Bhattarai",
        "Jindong Gu",
        "Volker Tresp",
        "Florian Buettner"
      ],
      "abstract": "Using feature attributions for post-hoc explanations is a common practice to\nunderstand and verify the predictions of opaque machine learning models.\nDespite the numerous techniques available, individual methods often produce\ninconsistent and unstable results, putting their overall reliability into\nquestion. In this work, we aim to systematically improve the quality of feature\nattributions by combining multiple explanations across distinct methods or\ntheir variations. For this purpose, we propose a novel approach to derive\noptimal convex combinations of feature attributions that yield provable\nimprovements of desired quality criteria such as robustness or faithfulness to\nthe model behavior. Through extensive experiments involving various model\narchitectures and popular feature attribution techniques, we demonstrate that\nour combination strategy consistently outperforms individual methods and\nexisting baselines.",
      "tldr_zh": "本研究针对特征归因（feature attributions）在解释不透明机器学习模型预测时存在的非一致性和不稳定性问题，提出了一种优化聚合方法。作者通过求解最优凸组合（optimal convex combinations）来结合多个特征归因技术，从而可证明地提升解释质量标准，如鲁棒性（robustness）和对模型行为的忠实性（faithfulness）。实验结果显示，该策略在各种模型架构和流行特征归因方法上，均优于单个方法和现有基准。",
      "categories": [
        "cs.LG",
        "cs.AI",
        "cs.CV"
      ],
      "primary_category": "cs.LG",
      "comment": "International Conference on Machine Learning (ICML) 2024",
      "pdf_url": "http://arxiv.org/pdf/2406.05090v1",
      "published_date": "2024-06-07 17:03:43 UTC",
      "updated_date": "2024-06-07 17:03:43 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-18T17:21:48.378724"
    },
    {
      "arxiv_id": "2406.05086v1",
      "title": "Robust Reward Design for Markov Decision Processes",
      "title_zh": "针对 Markov 决策过程的鲁棒奖励设计",
      "authors": [
        "Shuo Wu",
        "Haoxiang Ma",
        "Jie Fu",
        "Shuo Han"
      ],
      "abstract": "The problem of reward design examines the interaction between a leader and a\nfollower, where the leader aims to shape the follower's behavior to maximize\nthe leader's payoff by modifying the follower's reward function. Current\napproaches to reward design rely on an accurate model of how the follower\nresponds to reward modifications, which can be sensitive to modeling\ninaccuracies. To address this issue of sensitivity, we present a solution that\noffers robustness against uncertainties in modeling the follower, including 1)\nhow the follower breaks ties in the presence of nonunique best responses, 2)\ninexact knowledge of how the follower perceives reward modifications, and 3)\nbounded rationality of the follower. Our robust solution is guaranteed to exist\nunder mild conditions and can be obtained numerically by solving a\nmixed-integer linear program. Numerical experiments on multiple test cases\ndemonstrate that our solution improves robustness compared to the standard\napproach without incurring significant additional computing costs.",
      "tldr_zh": "这篇论文针对 Markov Decision Processes 中的奖励设计问题，探讨了领导者通过修改跟随者的奖励函数来最大化自身收益的挑战。现有方法对跟随者响应模型的依赖易受不确定性影响，因此作者提出了一种鲁棒解决方案，处理跟随者在非唯一最佳响应时的决策、奖励感知的不精确性和有限理性等问题。该方案在温和条件下存在，且可通过求解混合整数线性程序（mixed-integer linear program）来实现；实验结果显示，与标准方法相比，该方法显著提高了鲁棒性，同时计算成本增加有限。",
      "categories": [
        "math.OC",
        "cs.AI",
        "cs.GT"
      ],
      "primary_category": "math.OC",
      "comment": "50 pages, 8 figures",
      "pdf_url": "http://arxiv.org/pdf/2406.05086v1",
      "published_date": "2024-06-07 17:01:45 UTC",
      "updated_date": "2024-06-07 17:01:45 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-18T17:22:01.437072"
    },
    {
      "arxiv_id": "2406.05085v2",
      "title": "Multi-Head RAG: Solving Multi-Aspect Problems with LLMs",
      "title_zh": "翻译失败",
      "authors": [
        "Maciej Besta",
        "Ales Kubicek",
        "Roman Niggli",
        "Robert Gerstenberger",
        "Lucas Weitzendorf",
        "Mingyuan Chi",
        "Patrick Iff",
        "Joanna Gajda",
        "Piotr Nyczyk",
        "Jürgen Müller",
        "Hubert Niewiadomski",
        "Marcin Chrapek",
        "Michał Podstawski",
        "Torsten Hoefler"
      ],
      "abstract": "Retrieval Augmented Generation (RAG) enhances the abilities of Large Language\nModels (LLMs) by enabling the retrieval of documents into the LLM context to\nprovide more accurate and relevant responses. Existing RAG solutions do not\nfocus on queries that may require fetching multiple documents with\nsubstantially different contents. Such queries occur frequently, but are\nchallenging because the embeddings of these documents may be distant in the\nembedding space, making it hard to retrieve them all. This paper introduces\nMulti-Head RAG (MRAG), a novel scheme designed to address this gap with a\nsimple yet powerful idea: leveraging activations of Transformer's multi-head\nattention layer, instead of the decoder layer, as keys for fetching\nmulti-aspect documents. The driving motivation is that different attention\nheads can learn to capture different data aspects. Harnessing the corresponding\nactivations results in embeddings that represent various facets of data items\nand queries, improving the retrieval accuracy for complex queries. We provide\nan evaluation methodology and metrics, multi-aspect datasets that we release\nonline, and real-world use cases to demonstrate MRAG's effectiveness, showing\nimprovements of up to 20% in relevance over standard RAG baselines. MRAG can be\nseamlessly integrated with existing RAG frameworks and benchmarking tools like\nRAGAS as well as different classes of data stores.",
      "tldr_zh": "该论文提出 Multi-Head RAG (MRAG)，一种改进 Retrieval Augmented Generation (RAG) 的框架，针对 Large Language Models (LLMs) 处理多方面查询的问题，这些查询需要检索多个内容差异大的文档，但现有方法因嵌入空间距离问题而难以实现。MRAG 的创新在于利用 Transformer 的多头注意力层激活作为键来生成多方面嵌入，从而更好地捕捉数据不同面向，提高复杂查询的检索准确性。论文提供了新的评估方法、指标和在线多方面数据集，并通过真实案例证明 MRAG 比标准 RAG 基准提高了多达 20% 的相关性，同时可无缝集成到现有 RAG 框架和工具中，如 RAGAS 和各种数据存储。",
      "categories": [
        "cs.CL",
        "cs.AI",
        "cs.IR"
      ],
      "primary_category": "cs.CL",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2406.05085v2",
      "published_date": "2024-06-07 16:59:38 UTC",
      "updated_date": "2024-11-19 08:46:34 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-18T17:22:13.959038"
    },
    {
      "arxiv_id": "2406.05080v2",
      "title": "I2EDL: Interactive Instruction Error Detection and Localization",
      "title_zh": "I2EDL：交互式指令错误检测与定位",
      "authors": [
        "Francesco Taioli",
        "Stefano Rosa",
        "Alberto Castellini",
        "Lorenzo Natale",
        "Alessio Del Bue",
        "Alessandro Farinelli",
        "Marco Cristani",
        "Yiming Wang"
      ],
      "abstract": "In the Vision-and-Language Navigation in Continuous Environments (VLN-CE)\ntask, the human user guides an autonomous agent to reach a target goal via a\nseries of low-level actions following a textual instruction in natural\nlanguage. However, most existing methods do not address the likely case where\nusers may make mistakes when providing such instruction (e.g. \"turn left\"\ninstead of \"turn right\"). In this work, we address a novel task of Interactive\nVLN in Continuous Environments (IVLN-CE), which allows the agent to interact\nwith the user during the VLN-CE navigation to verify any doubts regarding the\ninstruction errors. We propose an Interactive Instruction Error Detector and\nLocalizer (I2EDL) that triggers the user-agent interaction upon the detection\nof instruction errors during the navigation. We leverage a pre-trained module\nto detect instruction errors and pinpoint them in the instruction by\ncross-referencing the textual input and past observations. In such way, the\nagent is able to query the user for a timely correction, without demanding the\nuser's cognitive load, as we locate the probable errors to a precise part of\nthe instruction. We evaluate the proposed I2EDL on a dataset of instructions\ncontaining errors, and further devise a novel metric, the Success weighted by\nInteraction Number (SIN), to reflect both the navigation performance and the\ninteraction effectiveness. We show how the proposed method can ask focused\nrequests for corrections to the user, which in turn increases the navigation\nsuccess, while minimizing the interactions.",
      "tldr_zh": "这篇论文针对 Vision-and-Language Navigation in Continuous Environments (VLN-CE) 任务，提出一个新任务 Interactive VLN in Continuous Environments (IVLN-CE)，允许代理在导航过程中检测并与用户互动修正指令错误。作者开发了 Interactive Instruction Error Detector and Localizer (I2EDL)，利用预训练模块通过交叉引用文本输入和过去观察来检测并定位指令错误，从而实现针对性的用户查询，而不增加用户认知负担。实验结果显示，I2EDL 在包含错误的指令数据集上显著提高了导航成功率，并引入了 Success weighted by Interaction Number (SIN) 指标，证明了其在提升交互有效性和最小化交互次数方面的优势。",
      "categories": [
        "cs.RO",
        "cs.AI",
        "cs.CL"
      ],
      "primary_category": "cs.RO",
      "comment": "Accepted at IEEE RO-MAN 2024",
      "pdf_url": "http://arxiv.org/pdf/2406.05080v2",
      "published_date": "2024-06-07 16:52:57 UTC",
      "updated_date": "2024-06-23 22:58:46 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-18T17:22:26.858828"
    },
    {
      "arxiv_id": "2406.05071v1",
      "title": "Massively Multiagent Minigames for Training Generalist Agents",
      "title_zh": "大规模多智能体小游戏用于训练通用智能体",
      "authors": [
        "Kyoung Whan Choe",
        "Ryan Sullivan",
        "Joseph Suárez"
      ],
      "abstract": "We present Meta MMO, a collection of many-agent minigames for use as a\nreinforcement learning benchmark. Meta MMO is built on top of Neural MMO, a\nmassively multiagent environment that has been the subject of two previous\nNeurIPS competitions. Our work expands Neural MMO with several computationally\nefficient minigames. We explore generalization across Meta MMO by learning to\nplay several minigames with a single set of weights. We release the\nenvironment, baselines, and training code under the MIT license. We hope that\nMeta MMO will spur additional progress on Neural MMO and, more generally, will\nserve as a useful benchmark for many-agent generalization.",
      "tldr_zh": "该论文介绍了 Meta MMO，这是一个由多个智能体组成的迷你游戏集合，用于强化学习基准测试。Meta MMO 基于 Neural MMO 扩展而成，添加了几个计算高效的迷你游戏，并通过使用单一权重集训练代理来探索多游戏泛化能力。实验结果展示了这种方法在多个迷你游戏中的有效性，为训练通用代理提供了新途径。作者开源发布了环境、基准和训练代码，旨在推动 Neural MMO 的发展并作为多智能体泛化研究的参考基准。",
      "categories": [
        "cs.AI",
        "cs.LG",
        "cs.MA"
      ],
      "primary_category": "cs.AI",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2406.05071v1",
      "published_date": "2024-06-07 16:41:05 UTC",
      "updated_date": "2024-06-07 16:41:05 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-18T17:22:37.414776"
    },
    {
      "arxiv_id": "2406.05068v1",
      "title": "Classification Metrics for Image Explanations: Towards Building Reliable XAI-Evaluations",
      "title_zh": "图像解释的分类指标：迈向构建",
      "authors": [
        "Benjamin Fresz",
        "Lena Lörcher",
        "Marco Huber"
      ],
      "abstract": "Decision processes of computer vision models - especially deep neural\nnetworks - are opaque in nature, meaning that these decisions cannot be\nunderstood by humans. Thus, over the last years, many methods to provide\nhuman-understandable explanations have been proposed. For image classification,\nthe most common group are saliency methods, which provide (super-)pixelwise\nfeature attribution scores for input images. But their evaluation still poses a\nproblem, as their results cannot be simply compared to the unknown ground\ntruth. To overcome this, a slew of different proxy metrics have been defined,\nwhich are - as the explainability methods themselves - often built on intuition\nand thus, are possibly unreliable. In this paper, new evaluation metrics for\nsaliency methods are developed and common saliency methods are benchmarked on\nImageNet. In addition, a scheme for reliability evaluation of such metrics is\nproposed that is based on concepts from psychometric testing. The used code can\nbe found at\nhttps://github.com/lelo204/ClassificationMetricsForImageExplanations .",
      "tldr_zh": "这篇论文针对计算机视觉模型（如深度神经网络）的决策不透明问题，探讨了图像解释方法的评估挑战，特别是显著性方法（saliency methods），因为这些方法的结果无法与未知的真实情况直接比较，导致现有代理指标（proxy metrics）可能不可靠。研究者开发了新的评估指标，并在 ImageNet 数据集上对常见显著性方法进行了基准测试，同时提出了一种基于心理测量测试（psychometric testing）概念的指标可靠性评估方案，以提升 XAI-Evaluations 的可靠性。该工作提供了开源代码（https://github.com/lelo204/ClassificationMetricsForImageExplanations），有助于构建更可信的图像解释评估框架。",
      "categories": [
        "cs.CV",
        "cs.AI",
        "cs.HC"
      ],
      "primary_category": "cs.CV",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2406.05068v1",
      "published_date": "2024-06-07 16:37:50 UTC",
      "updated_date": "2024-06-07 16:37:50 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-18T17:22:49.298555"
    },
    {
      "arxiv_id": "2406.18591v1",
      "title": "Composition Vision-Language Understanding via Segment and Depth Anything Model",
      "title_zh": "翻译失败",
      "authors": [
        "Mingxiao Huo",
        "Pengliang Ji",
        "Haotian Lin",
        "Junchen Liu",
        "Yixiao Wang",
        "Yijun Chen"
      ],
      "abstract": "We introduce a pioneering unified library that leverages depth anything,\nsegment anything models to augment neural comprehension in language-vision\nmodel zero-shot understanding. This library synergizes the capabilities of the\nDepth Anything Model (DAM), Segment Anything Model (SAM), and GPT-4V, enhancing\nmultimodal tasks such as vision-question-answering (VQA) and composition\nreasoning. Through the fusion of segmentation and depth analysis at the\nsymbolic instance level, our library provides nuanced inputs for language\nmodels, significantly advancing image interpretation. Validated across a\nspectrum of in-the-wild real-world images, our findings showcase progress in\nvision-language models through neural-symbolic integration. This novel approach\nmelds visual and language analysis in an unprecedented manner. Overall, our\nlibrary opens new directions for future research aimed at decoding the\ncomplexities of the real world through advanced multimodal technologies and our\ncode is available at\n\\url{https://github.com/AnthonyHuo/SAM-DAM-for-Compositional-Reasoning}.",
      "tldr_zh": "该研究引入了一个统一的库，利用 Depth Anything Model (DAM) 和 Segment Anything Model (SAM) 结合 GPT-4V，增强语言-视觉模型的零样本理解能力。库通过在符号实例级别融合分割和深度分析，提供更细致的图像输入，提升多模态任务如视觉问答 (VQA) 和组合推理的性能。在真实世界图像上进行的验证展示了神经-符号集成的显著进步，为未来多模态技术研究开辟新方向，并提供了开源代码。",
      "categories": [
        "cs.CV",
        "cs.AI",
        "cs.LG"
      ],
      "primary_category": "cs.CV",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2406.18591v1",
      "published_date": "2024-06-07 16:28:06 UTC",
      "updated_date": "2024-06-07 16:28:06 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-18T17:23:00.873629"
    },
    {
      "arxiv_id": "2406.05055v2",
      "title": "VC Search: Bridging the Gap Between Well-Defined and Ill-Defined Problems in Mathematical Reasoning",
      "title_zh": "翻译失败",
      "authors": [
        "Shi-Yu Tian",
        "Zhi Zhou",
        "Kun-Yang Yu",
        "Ming Yang",
        "Lin-Han Jia",
        "Lan-Zhe Guo",
        "Yu-Feng Li"
      ],
      "abstract": "Large language models (LLMs) have demonstrated impressive performance on\nreasoning tasks, including mathematical reasoning. However, the current\nevaluation mostly focuses on carefully constructed benchmarks and neglects the\nconsideration of real-world reasoning problems that present missing or\ncontradictory conditions, known as ill-defined problems. To further study this\nproblem, we develop a largescale benchmark called Problems with Missing and\nContradictory conditions ( PMC) containing over 5,000 validated ill-defined\nmathematical problems. Our preliminary experiments through PMC reveal two\nchallenges about existing methods: (1) traditional methods exhibit a trade-off\nbetween solving accuracy and rejection capabilities, and (2) formal methods\nstruggle with modeling complex problems. To address these challenges, We\ndevelop Variable-Constraint Search (VCSEARCH), a trainingfree framework that\nleverages formal language to detect ill-defined problems, where a\nvariableconstraint pair search strategy is incorporated to improve the modeling\ncapability of formal language. Extensive experiments demonstrate that VCSEARCH\nimproves the accuracy of identifying unsolvable problems by at least 12% across\ndifferent LLMs, thus achieving stronger robust mathematical reasoning ability.",
      "tldr_zh": "该论文探讨了大型语言模型（LLMs）在数学推理中评估的局限性，即主要关注 well-defined 问题而忽略 ill-defined 问题（如缺失或矛盾条件）。为了解决这一问题，研究者开发了大规模基准数据集 PMC，包含超过 5,000 个验证的 ill-defined 数学问题，并通过实验揭示了现有方法在准确性和拒绝能力上的权衡，以及 formal methods 在建模复杂问题时的不足。论文提出了无训练框架 VCSEARCH，利用 formal language 和 variable-constraint pair search 策略来检测 ill-defined 问题，实验结果显示其在不同 LLMs 上将识别 unsolvable 问题的准确率至少提高 12%，从而增强了 robust mathematical reasoning 能力。",
      "categories": [
        "cs.AI"
      ],
      "primary_category": "cs.AI",
      "comment": "Preprint",
      "pdf_url": "http://arxiv.org/pdf/2406.05055v2",
      "published_date": "2024-06-07 16:24:12 UTC",
      "updated_date": "2025-02-18 05:14:48 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-18T17:23:13.303026"
    },
    {
      "arxiv_id": "2406.05053v2",
      "title": "Hints-In-Browser: Benchmarking Language Models for Programming Feedback Generation",
      "title_zh": "翻译失败",
      "authors": [
        "Nachiket Kotalwar",
        "Alkis Gotovos",
        "Adish Singla"
      ],
      "abstract": "Generative AI and large language models hold great promise in enhancing\nprogramming education by generating individualized feedback and hints for\nlearners. Recent works have primarily focused on improving the quality of\ngenerated feedback to achieve human tutors' quality. While quality is an\nimportant performance criterion, it is not the only criterion to optimize for\nreal-world educational deployments. In this paper, we benchmark language models\nfor programming feedback generation across several performance criteria,\nincluding quality, cost, time, and data privacy. The key idea is to leverage\nrecent advances in the new paradigm of in-browser inference that allow running\nthese models directly in the browser, thereby providing direct benefits across\ncost and data privacy. To boost the feedback quality of small models compatible\nwith in-browser inference engines, we develop a fine-tuning pipeline based on\nGPT-4 generated synthetic data. We showcase the efficacy of fine-tuned\nLlama3-8B and Phi3-3.8B 4-bit quantized models using WebLLM's in-browser\ninference engine on three different Python programming datasets. We will\nrelease the full implementation along with a web app and datasets to facilitate\nfurther research on in-browser language models.",
      "tldr_zh": "该论文基准测试了语言模型在生成编程反馈方面的性能，包括质量、成本、时间和数据隐私等标准，旨在为实际教育应用优化模型。研究利用 in-browser inference 的新范式，让模型直接在浏览器中运行，从而提升成本效益和数据隐私保护。为提升小型模型的反馈质量，作者开发了一个基于 GPT-4 生成合成数据的微调管道，并测试了微调后的 Llama3-8B 和 Phi3-3.8B（4-bit 量化）模型在三个 Python 编程数据集上的效果。实验结果证明了这些模型的有效性，作者将发布完整实现、网页应用和数据集以促进进一步研究。",
      "categories": [
        "cs.LG",
        "cs.AI"
      ],
      "primary_category": "cs.LG",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2406.05053v2",
      "published_date": "2024-06-07 16:22:51 UTC",
      "updated_date": "2025-03-07 12:46:14 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-18T17:23:27.089834"
    },
    {
      "arxiv_id": "2406.05038v1",
      "title": "Efficient 3D Shape Generation via Diffusion Mamba with Bidirectional SSMs",
      "title_zh": "翻译失败",
      "authors": [
        "Shentong Mo"
      ],
      "abstract": "Recent advancements in sequence modeling have led to the development of the\nMamba architecture, noted for its selective state space approach, offering a\npromising avenue for efficient long sequence handling. However, its application\nin 3D shape generation, particularly at high resolutions, remains\nunderexplored. Traditional diffusion transformers (DiT) with self-attention\nmechanisms, despite their potential, face scalability challenges due to the\ncubic complexity of attention operations as input length increases. This\ncomplexity becomes a significant hurdle when dealing with high-resolution voxel\nsizes. To address this challenge, we introduce a novel diffusion architecture\ntailored for 3D point clouds generation-Diffusion Mamba (DiM-3D). This\narchitecture forgoes traditional attention mechanisms, instead utilizing the\ninherent efficiency of the Mamba architecture to maintain linear complexity\nwith respect to sequence length. DiM-3D is characterized by fast inference\ntimes and substantially lower computational demands, quantified in reduced\nGflops, thereby addressing the key scalability issues of prior models. Our\nempirical results on the ShapeNet benchmark demonstrate that DiM-3D achieves\nstate-of-the-art performance in generating high-fidelity and diverse 3D shapes.\nAdditionally, DiM-3D shows superior capabilities in tasks like 3D point cloud\ncompletion. This not only proves the model's scalability but also underscores\nits efficiency in generating detailed, high-resolution voxels necessary for\nadvanced 3D shape modeling, particularly excelling in environments requiring\nhigh-resolution voxel sizes. Through these findings, we illustrate the\nexceptional scalability and efficiency of the Diffusion Mamba framework in 3D\nshape generation, setting a new standard for the field and paving the way for\nfuture explorations in high-resolution 3D modeling technologies.",
      "tldr_zh": "本论文提出了一种高效的3D形状生成方法Diffusion Mamba (DiM-3D)，利用双向状态空间模型(Bidirectional SSMs)来取代传统扩散Transformer的自注意力机制，从而解决其立方复杂度导致的可扩展性挑战。DiM-3D 保持线性复杂度，提供快速推理和显著降低的计算需求（如Gflops），特别适合处理高分辨率3D点云生成。实验结果显示，在ShapeNet基准上，DiM-3D 实现了最先进的性能，生成高保真和多样化的3D形状，并在3D点云完成任务中表现出优越性，最终为高分辨率3D建模领域设定了新标准。",
      "categories": [
        "cs.CV",
        "cs.AI",
        "cs.LG"
      ],
      "primary_category": "cs.CV",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2406.05038v1",
      "published_date": "2024-06-07 16:02:07 UTC",
      "updated_date": "2024-06-07 16:02:07 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-18T17:23:43.498971"
    },
    {
      "arxiv_id": "2406.05036v3",
      "title": "TimeSieve: Extracting Temporal Dynamics through Information Bottlenecks",
      "title_zh": "TimeSieve：通过信息瓶颈提取时间动态",
      "authors": [
        "Ninghui Feng",
        "Songning Lai",
        "Jiayu Yang",
        "Fobao Zhou",
        "Zhenxiao Yin",
        "Hang Zhao"
      ],
      "abstract": "Time series forecasting has become an increasingly popular research area due\nto its critical applications in various real-world domains such as traffic\nmanagement, weather prediction, and financial analysis. Despite significant\nadvancements, existing models face notable challenges, including the necessity\nof manual hyperparameter tuning for different datasets, and difficulty in\neffectively distinguishing signal from redundant features in data characterized\nby strong seasonality. These issues hinder the generalization and practical\napplication of time series forecasting models. To solve this issues, we propose\nan innovative time series forecasting model TimeSieve designed to address these\nchallenges. Our approach employs wavelet transforms to preprocess time series\ndata, effectively capturing multi-scale features without the need for\nadditional parameters or manual hyperparameter tuning. Additionally, we\nintroduce the information bottleneck theory that filters out redundant features\nfrom both detail and approximation coefficients, retaining only the most\npredictive information. This combination reduces significantly improves the\nmodel's accuracy. Extensive experiments demonstrate that our model outperforms\nexisting state-of-the-art methods on 70% of the datasets, achieving higher\npredictive accuracy and better generalization across diverse datasets. Our\nresults validate the effectiveness of our approach in addressing the key\nchallenges in time series forecasting, paving the way for more reliable and\nefficient predictive models in practical applications. The code for our model\nis available at https://github.com/xll0328/TimeSieve.",
      "tldr_zh": "时间序列预测模型面临手动超参数调参和难以区分信号与冗余特征的挑战，本文提出TimeSieve模型来解决这些问题。TimeSieve采用wavelet transforms预处理数据，以捕获多尺度特征，并引入information bottleneck theory从细节和近似系数中过滤冗余信息，从而显著提升模型准确性和泛化能力。实验结果显示，该模型在70%的数据集上优于现有最先进方法，为实际应用中的可靠预测提供了新途径。代码已开源于https://github.com/xll0328/TimeSieve。",
      "categories": [
        "cs.LG",
        "cs.AI"
      ],
      "primary_category": "cs.LG",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2406.05036v3",
      "published_date": "2024-06-07 15:58:12 UTC",
      "updated_date": "2024-08-21 10:22:09 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-18T17:23:53.407996"
    },
    {
      "arxiv_id": "2406.05035v1",
      "title": "Scenarios and Approaches for Situated Natural Language Explanations",
      "title_zh": "针对情境化自然语言解释的场景与方法",
      "authors": [
        "Pengshuo Qiu",
        "Frank Rudzicz",
        "Zining Zhu"
      ],
      "abstract": "Large language models (LLMs) can be used to generate natural language\nexplanations (NLE) that are adapted to different users' situations. However,\nthere is yet to be a quantitative evaluation of the extent of such adaptation.\nTo bridge this gap, we collect a benchmarking dataset, Situation-Based\nExplanation. This dataset contains 100 explanandums. Each explanandum is paired\nwith explanations targeted at three distinct audience types-such as educators,\nstudents, and professionals-enabling us to assess how well the explanations\nmeet the specific informational needs and contexts of these diverse groups e.g.\nstudents, teachers, and parents. For each \"explanandum paired with an audience\"\nsituation, we include a human-written explanation. These allow us to compute\nscores that quantify how the LLMs adapt the explanations to the situations. On\nan array of pretrained language models with varying sizes, we examine three\ncategories of prompting methods: rule-based prompting, meta-prompting, and\nin-context learning prompting. We find that 1) language models can generate\nprompts that result in explanations more precisely aligned with the target\nsituations, 2) explicitly modeling an \"assistant\" persona by prompting \"You are\na helpful assistant...\" is not a necessary prompt technique for situated NLE\ntasks, and 3) the in-context learning prompts only can help LLMs learn the\ndemonstration template but can't improve their inference performance. SBE and\nour analysis facilitate future research towards generating situated natural\nlanguage explanations.",
      "tldr_zh": "本文探讨了如何使用大型语言模型 (LLMs) 生成适应不同用户情况的自然语言解释 (NLE)，并构建了 Situation-Based Explanation (SBE) 数据集，该数据集包含 100 个解释对象，每个针对教育者、学生和专业人士等受众提供人类编写的解释，以量化 LLMs 的适应能力。研究评估了 rule-based prompting、meta-prompting 和 in-context learning prompting 三类提示方法，发现 LLMs 可以生成更精确的适应性解释，但显式建模“助手”角色（如“You are a helpful assistant...”）并非必要，且 in-context learning prompting 仅能提升演示模板学习而非推理性能。该工作为未来生成情境化 NLE 的研究提供了重要基准和分析基础。",
      "categories": [
        "cs.CL",
        "cs.AI"
      ],
      "primary_category": "cs.CL",
      "comment": "8 pages, 4 figures",
      "pdf_url": "http://arxiv.org/pdf/2406.05035v1",
      "published_date": "2024-06-07 15:56:32 UTC",
      "updated_date": "2024-06-07 15:56:32 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-18T17:24:06.561276"
    },
    {
      "arxiv_id": "2406.05027v3",
      "title": "Optimizing Automatic Differentiation with Deep Reinforcement Learning",
      "title_zh": "利用深度强化学习优化自动微分",
      "authors": [
        "Jamie Lohoff",
        "Emre Neftci"
      ],
      "abstract": "Computing Jacobians with automatic differentiation is ubiquitous in many\nscientific domains such as machine learning, computational fluid dynamics,\nrobotics and finance. Even small savings in the number of computations or\nmemory usage in Jacobian computations can already incur massive savings in\nenergy consumption and runtime. While there exist many methods that allow for\nsuch savings, they generally trade computational efficiency for approximations\nof the exact Jacobian. In this paper, we present a novel method to optimize the\nnumber of necessary multiplications for Jacobian computation by leveraging deep\nreinforcement learning (RL) and a concept called cross-country elimination\nwhile still computing the exact Jacobian. Cross-country elimination is a\nframework for automatic differentiation that phrases Jacobian accumulation as\nordered elimination of all vertices on the computational graph where every\nelimination incurs a certain computational cost. We formulate the search for\nthe optimal elimination order that minimizes the number of necessary\nmultiplications as a single player game which is played by an RL agent. We\ndemonstrate that this method achieves up to 33% improvements over\nstate-of-the-art methods on several relevant tasks taken from diverse domains.\nFurthermore, we show that these theoretical gains translate into actual runtime\nimprovements by providing a cross-country elimination interpreter in JAX that\ncan efficiently execute the obtained elimination orders.",
      "tldr_zh": "本文提出一种新方法，使用深度强化学习（deep reinforcement learning）优化自动微分（automatic differentiation）的雅可比矩阵（Jacobians）计算，旨在减少乘法次数同时保持精确性。方法通过cross-country elimination框架，将计算图顶点的有序消除表述为单人游戏，由RL代理搜索最优消除顺序。实验结果显示，该方法在机器学习、计算流体动力学等领域的任务上比现有方法提高多达33%的效率，并在JAX中实现了实际运行时改进。",
      "categories": [
        "cs.LG",
        "cs.AI"
      ],
      "primary_category": "cs.LG",
      "comment": "Accepted as a spotlight paper at NeurIPS 2024",
      "pdf_url": "http://arxiv.org/pdf/2406.05027v3",
      "published_date": "2024-06-07 15:44:33 UTC",
      "updated_date": "2025-01-27 10:21:04 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-18T17:24:17.706998"
    },
    {
      "arxiv_id": "2406.06622v1",
      "title": "Adversarial Tuning: Defending Against Jailbreak Attacks for LLMs",
      "title_zh": "翻译失败",
      "authors": [
        "Fan Liu",
        "Zhao Xu",
        "Hao Liu"
      ],
      "abstract": "Although safely enhanced Large Language Models (LLMs) have achieved\nremarkable success in tackling various complex tasks in a zero-shot manner,\nthey remain susceptible to jailbreak attacks, particularly the unknown\njailbreak attack. To enhance LLMs' generalized defense capabilities, we propose\na two-stage adversarial tuning framework, which generates adversarial prompts\nto explore worst-case scenarios by optimizing datasets containing pairs of\nadversarial prompts and their safe responses. In the first stage, we introduce\nthe hierarchical meta-universal adversarial prompt learning to efficiently and\neffectively generate token-level adversarial prompts. In the second stage, we\npropose the automatic adversarial prompt learning to iteratively refine\nsemantic-level adversarial prompts, further enhancing LLM's defense\ncapabilities. We conducted comprehensive experiments on three widely used\njailbreak datasets, comparing our framework with six defense baselines under\nfive representative attack scenarios. The results underscore the superiority of\nour proposed methods. Furthermore, our adversarial tuning framework exhibits\nempirical generalizability across various attack strategies and target LLMs,\nhighlighting its potential as a transferable defense mechanism.",
      "tldr_zh": "该论文提出Adversarial Tuning框架，用于提升大型语言模型(LLMs)对未知jailbreak attacks的防御能力，通过两阶段优化数据集来生成对抗提示。第一个阶段采用hierarchical meta-universal adversarial prompt learning，高效生成token-level对抗提示；第二个阶段则使用automatic adversarial prompt learning，迭代优化semantic-level对抗提示，以探索最坏场景并增强模型的泛化防御。实验在三个常用jailbreak数据集上与六种基线方法比较，显示出显著优越性，并在多种攻击策略和LLMs上表现出良好的可转移性。",
      "categories": [
        "cs.CL",
        "cs.AI",
        "cs.CR"
      ],
      "primary_category": "cs.CL",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2406.06622v1",
      "published_date": "2024-06-07 15:37:15 UTC",
      "updated_date": "2024-06-07 15:37:15 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-18T17:24:30.482155"
    },
    {
      "arxiv_id": "2406.05017v1",
      "title": "Adaptively Learning to Select-Rank in Online Platforms",
      "title_zh": "翻译失败",
      "authors": [
        "Jingyuan Wang",
        "Perry Dong",
        "Ying Jin",
        "Ruohan Zhan",
        "Zhengyuan Zhou"
      ],
      "abstract": "Ranking algorithms are fundamental to various online platforms across\ne-commerce sites to content streaming services. Our research addresses the\nchallenge of adaptively ranking items from a candidate pool for heterogeneous\nusers, a key component in personalizing user experience. We develop a user\nresponse model that considers diverse user preferences and the varying effects\nof item positions, aiming to optimize overall user satisfaction with the ranked\nlist. We frame this problem within a contextual bandits framework, with each\nranked list as an action. Our approach incorporates an upper confidence bound\nto adjust predicted user satisfaction scores and selects the ranking action\nthat maximizes these adjusted scores, efficiently solved via maximum weight\nimperfect matching. We demonstrate that our algorithm achieves a cumulative\nregret bound of $O(d\\sqrt{NKT})$ for ranking $K$ out of $N$ items in a\n$d$-dimensional context space over $T$ rounds, under the assumption that user\nresponses follow a generalized linear model. This regret alleviates dependence\non the ambient action space, whose cardinality grows exponentially with $N$ and\n$K$ (thus rendering direct application of existing adaptive learning algorithms\n-- such as UCB or Thompson sampling -- infeasible). Experiments conducted on\nboth simulated and real-world datasets demonstrate our algorithm outperforms\nthe baseline.",
      "tldr_zh": "本研究针对在线平台（如电商和内容流媒体）中为异质用户适应性地从候选池中选择和排名物品的问题，提出了一种优化用户满意度的算法。该算法构建了一个用户响应模型，并将其框架化为 contextual bandits 问题，使用 upper confidence bound 来调整预测满意度分数，并通过 maximum weight imperfect matching 高效选择最佳排名动作。在 d-维上下文空间下，算法实现了累积 regret bound 为 O(d√(NKT))，有效缓解了动作空间指数增长的挑战（如避免直接应用 UCB 或 Thompson sampling）。实验在模拟和真实数据集上表明，该算法优于基线模型。",
      "categories": [
        "cs.LG",
        "cs.AI"
      ],
      "primary_category": "cs.LG",
      "comment": "25 pages in total. Includes 4 figures and a pdf. International\n  conference on machine learning. PMLR, 2024",
      "pdf_url": "http://arxiv.org/pdf/2406.05017v1",
      "published_date": "2024-06-07 15:33:48 UTC",
      "updated_date": "2024-06-07 15:33:48 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-18T17:24:42.681033"
    },
    {
      "arxiv_id": "2406.06621v2",
      "title": "LinkQ: An LLM-Assisted Visual Interface for Knowledge Graph Question-Answering",
      "title_zh": "翻译失败",
      "authors": [
        "Harry Li",
        "Gabriel Appleby",
        "Ashley Suh"
      ],
      "abstract": "We present LinkQ, a system that leverages a large language model (LLM) to\nfacilitate knowledge graph (KG) query construction through natural language\nquestion-answering. Traditional approaches often require detailed knowledge of\na graph querying language, limiting the ability for users -- even experts -- to\nacquire valuable insights from KGs. LinkQ simplifies this process by\nimplementing a multistep protocol in which the LLM interprets a user's\nquestion, then systematically converts it into a well-formed query. LinkQ helps\nusers iteratively refine any open-ended questions into precise ones, supporting\nboth targeted and exploratory analysis. Further, LinkQ guards against the LLM\nhallucinating outputs by ensuring users' questions are only ever answered from\nground truth KG data. We demonstrate the efficacy of LinkQ through a\nqualitative study with five KG practitioners. Our results indicate that\npractitioners find LinkQ effective for KG question-answering, and desire future\nLLM-assisted exploratory data analysis systems.",
      "tldr_zh": "本研究介绍了 LinkQ 系统，这是一个利用大型语言模型 (LLM) 的视觉界面，旨在简化知识图谱 (KG) 问答过程，帮助用户通过自然语言提问构建查询，而无需掌握复杂的图查询语言。LinkQ 采用多步骤协议，由 LLM 解释用户问题并逐步转换为规范查询，支持迭代精炼以实现针对性和探索性分析，同时通过确保答案仅来自 KG 的真实数据来防范 LLM 幻觉。研究通过对五位 KG 实践者的定性研究验证了系统的有效性，用户认为 LinkQ 在 KG 问答中表现优秀，并期望未来开发更多 LLM 辅助的数据分析工具。",
      "categories": [
        "cs.CL",
        "cs.AI",
        "cs.LG"
      ],
      "primary_category": "cs.CL",
      "comment": "Open-source code: https://github.com/mit-ll/linkq",
      "pdf_url": "http://arxiv.org/pdf/2406.06621v2",
      "published_date": "2024-06-07 15:28:31 UTC",
      "updated_date": "2025-02-10 18:35:29 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-18T17:24:54.223755"
    },
    {
      "arxiv_id": "2406.05002v2",
      "title": "Deep Jansen-Rit Parameter Inference for Model-Driven Analysis of Brain Activity",
      "title_zh": "翻译失败",
      "authors": [
        "Deepa Tilwani",
        "Christian O'Reilly"
      ],
      "abstract": "Accurately modeling effective connectivity (EC) is critical for understanding\nhow the brain processes and integrates sensory information. Yet, it remains a\nformidable challenge due to complex neural dynamics and noisy measurements such\nas those obtained from the electroencephalogram (EEG). Model-driven EC infers\nlocal (within a brain region) and global (between brain regions) EC parameters\nby fitting a generative model of neural activity onto experimental data. This\napproach offers a promising route for various applications, including\ninvestigating neurodevelopmental disorders. However, current approaches fail to\nscale to whole-brain analyses and are highly noise-sensitive. In this work, we\nemploy three deep-learning architectures--a transformer, a long short-term\nmemory (LSTM) network, and a convolutional neural network and bidirectional\nLSTM (CNN-BiLSTM) network--for inverse modeling and compare their performance\nwith simulation-based inference in estimating the Jansen-Rit neural mass model\n(JR-NMM) parameters from simulated EEG data under various noise conditions. We\ndemonstrate a reliable estimation of key local parameters, such as synaptic\ngains and time constants. However, other parameters like local JR-NMM\nconnectivity cannot be evaluated reliably from evoked-related potentials (ERP).\nWe also conduct a sensitivity analysis to characterize the influence of JR-NMM\nparameters on ERP and evaluate their learnability. Our results show the\nfeasibility of deep-learning approaches to estimate the subset of learnable\nJR-NMM parameters.",
      "tldr_zh": "这篇论文针对有效连接性 (EC) 建模的挑战，提出使用深度学习方法从模拟 EEG 数据中推断 Jansen-Rit 神经质量模型 (JR-NMM) 参数，以更好地分析大脑活动。方法包括 Transformer、LSTM 和 CNN-BiLSTM 架构，与基于模拟的推理方法进行比较，旨在克服当前模型在全脑分析和噪声敏感性方面的局限。实验结果显示，这些深度学习方法能可靠估计关键局部参数，如突触增益和时间常数，但无法准确评估局部 JR-NMM 连接性或从诱发相关电位 (ERP) 中推断其他参数。通过敏感性分析，论文证明了深度学习在估计 JR-NMM 可学习参数子集方面的可行性。",
      "categories": [
        "q-bio.NC",
        "cs.AI"
      ],
      "primary_category": "q-bio.NC",
      "comment": "Accepted at 7th International Conference on Advances in Signal\n  Processing and Artificial Intelligence (ASPAI' 2025), 8-10 April 2025,\n  Innsbruck, Austria",
      "pdf_url": "http://arxiv.org/pdf/2406.05002v2",
      "published_date": "2024-06-07 15:16:46 UTC",
      "updated_date": "2025-03-18 17:52:33 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-18T17:25:08.236864"
    },
    {
      "arxiv_id": "2406.04998v2",
      "title": "ADBA:Approximation Decision Boundary Approach for Black-Box Adversarial Attacks",
      "title_zh": "翻译失败",
      "authors": [
        "Feiyang Wang",
        "Xingquan Zuo",
        "Hai Huang",
        "Gang Chen"
      ],
      "abstract": "Many machine learning models are susceptible to adversarial attacks, with\ndecision-based black-box attacks representing the most critical threat in\nreal-world applications. These attacks are extremely stealthy, generating\nadversarial examples using hard labels obtained from the target machine\nlearning model. This is typically realized by optimizing perturbation\ndirections, guided by decision boundaries identified through query-intensive\nexact search, significantly limiting the attack success rate. This paper\nintroduces a novel approach using the Approximation Decision Boundary (ADB) to\nefficiently and accurately compare perturbation directions without precisely\ndetermining decision boundaries. The effectiveness of our ADB approach (ADBA)\nhinges on promptly identifying suitable ADB, ensuring reliable differentiation\nof all perturbation directions. For this purpose, we analyze the probability\ndistribution of decision boundaries, confirming that using the distribution's\nmedian value as ADB can effectively distinguish different perturbation\ndirections, giving rise to the development of the ADBA-md algorithm. ADBA-md\nonly requires four queries on average to differentiate any pair of perturbation\ndirections, which is highly query-efficient. Extensive experiments on six\nwell-known image classifiers clearly demonstrate the superiority of ADBA and\nADBA-md over multiple state-of-the-art black-box attacks. The source code is\navailable at https://github.com/BUPTAIOC/ADBA.",
      "tldr_zh": "这篇论文提出了一种Approximation Decision Boundary Approach (ADBA)，用于改进黑盒对抗攻击（Black-Box Adversarial Attacks），通过近似决策边界（ADB）高效比较扰动方向，而无需进行查询密集的精确搜索。作者分析了决策边界的概率分布，发现使用分布中值作为ADB能可靠地区分不同扰动方向，从而开发了ADBA-md算法，该算法平均只需四个查询即可完成区分。实验结果显示，在六个知名图像分类器上，ADBA和ADBA-md的性能优于多种最先进黑盒攻击方法。源代码已在GitHub上公开，可供进一步验证和应用。",
      "categories": [
        "cs.LG",
        "cs.AI",
        "cs.CV"
      ],
      "primary_category": "cs.LG",
      "comment": "10 pages, 5 figures, conference",
      "pdf_url": "http://arxiv.org/pdf/2406.04998v2",
      "published_date": "2024-06-07 15:09:25 UTC",
      "updated_date": "2024-06-12 08:49:16 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-18T17:25:21.134297"
    },
    {
      "arxiv_id": "2406.04975v1",
      "title": "UniTST: Effectively Modeling Inter-Series and Intra-Series Dependencies for Multivariate Time Series Forecasting",
      "title_zh": "翻译失败",
      "authors": [
        "Juncheng Liu",
        "Chenghao Liu",
        "Gerald Woo",
        "Yiwei Wang",
        "Bryan Hooi",
        "Caiming Xiong",
        "Doyen Sahoo"
      ],
      "abstract": "Transformer-based models have emerged as powerful tools for multivariate time\nseries forecasting (MTSF). However, existing Transformer models often fall\nshort of capturing both intricate dependencies across variate and temporal\ndimensions in MTS data. Some recent models are proposed to separately capture\nvariate and temporal dependencies through either two sequential or parallel\nattention mechanisms. However, these methods cannot directly and explicitly\nlearn the intricate inter-series and intra-series dependencies. In this work,\nwe first demonstrate that these dependencies are very important as they usually\nexist in real-world data. To directly model these dependencies, we propose a\ntransformer-based model UniTST containing a unified attention mechanism on the\nflattened patch tokens. Additionally, we add a dispatcher module which reduces\nthe complexity and makes the model feasible for a potentially large number of\nvariates. Although our proposed model employs a simple architecture, it offers\ncompelling performance as shown in our extensive experiments on several\ndatasets for time series forecasting.",
      "tldr_zh": "本研究针对多变量时间序列预测（Multivariate Time Series Forecasting）中的问题，指出现有 Transformer 模型无法有效捕捉变量间（inter-series）和时间内（intra-series）依赖关系。作者提出 UniTST 模型，使用统一的注意力机制在扁平化的 patch tokens 上直接建模这些依赖，并引入 dispatcher 模块来降低计算复杂性，使其适用于大量变量场景。尽管架构简单，UniTST 在多个数据集上的实验显示出优异的预测性能，证明了其有效性。",
      "categories": [
        "cs.LG",
        "cs.AI"
      ],
      "primary_category": "cs.LG",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2406.04975v1",
      "published_date": "2024-06-07 14:39:28 UTC",
      "updated_date": "2024-06-07 14:39:28 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-18T17:25:29.083201"
    },
    {
      "arxiv_id": "2406.06620v3",
      "title": "MedualTime: A Dual-Adapter Language Model for Medical Time Series-Text Multimodal Learning",
      "title_zh": "翻译失败",
      "authors": [
        "Jiexia Ye",
        "Weiqi Zhang",
        "Ziyue Li",
        "Jia Li",
        "Meng Zhao",
        "Fugee Tsung"
      ],
      "abstract": "The recent rapid advancements in language models (LMs) have garnered\nattention in medical time series-text multimodal learning. However, existing\ncontrastive learning-based and prompt-based LM approaches tend to be biased,\noften assigning a primary role to time series modality while treating text\nmodality as secondary. We classify these approaches under a temporal-primary\nparadigm, which may overlook the unique and critical task-relevant information\nembedded in text modality like clinical reports, thus failing to fully leverage\nmutual benefits and complementarity of different modalities. To fill this gap,\nwe propose a novel textual-temporal multimodal learning paradigm that enables\neither modality to serve as the primary while being enhanced by the other,\nthereby effectively capturing modality-specific information and fostering\ncross-modal interaction. In specific, we design MedualTime, a language model\ncomposed of dual adapters to implement temporal-primary and textual-primary\nmodeling simultaneously. Within each adapter, lightweight adaptation tokens are\ninjected into the top layers of LM to encourage high-level modality fusion. The\nshared LM pipeline by dual adapters not only achieves adapter alignment but\nalso enables efficient fine-tuning, reducing computational resources.\nEmpirically, MedualTime demonstrates superior performance on medical data,\nachieving notable improvements of 8% accuracy and 12% F1 in supervised\nsettings. Furthermore, MedualTime's transferability is validated by few-shot\nlabel transfer experiments from coarse-grained to fine-grained medical data.\nhttps://github.com/start2020/MedualTime",
      "tldr_zh": "该研究指出现有基于对比学习或提示的语言模型(LMs)在医疗时间序列-文本多模态学习中，倾向于采用时间序列为主(temporal-primary paradigm)的偏见，忽略了文本模态如临床报告中的关键信息。为解决此问题，提出一种新型文本-时间序列(textual-temporal)多模态学习范式，并设计了MedualTime模型，该模型使用双适配器(dual adapters)同时实现时间序列为主和文本为主的建模，通过注入轻量级适应tokens到LM顶层促进模态融合，并共享LM管道以实现高效微调和减少计算资源。实验结果显示，MedualTime在监督设置中准确率提升8%、F1分数提升12%，并在少样本转移实验中证明了从粗粒度到细粒度医疗数据的良好可转移性。",
      "categories": [
        "cs.LG",
        "cs.AI",
        "cs.CL"
      ],
      "primary_category": "cs.LG",
      "comment": "9 pages, 6 figure, 3 tables",
      "pdf_url": "http://arxiv.org/pdf/2406.06620v3",
      "published_date": "2024-06-07 14:34:28 UTC",
      "updated_date": "2025-05-12 13:27:11 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-18T17:25:45.054730"
    },
    {
      "arxiv_id": "2406.04964v1",
      "title": "Neural Laplace for learning Stochastic Differential Equations",
      "title_zh": "Neural Laplace 用于学习随机微分方程",
      "authors": [
        "Adrien Carrel"
      ],
      "abstract": "Neural Laplace is a unified framework for learning diverse classes of\ndifferential equations (DE). For different classes of DE, this framework\noutperforms other approaches relying on neural networks that aim to learn\nclasses of ordinary differential equations (ODE). However, many systems can't\nbe modelled using ODEs. Stochastic differential equations (SDE) are the\nmathematical tool of choice when modelling spatiotemporal DE dynamics under the\ninfluence of randomness. In this work, we review the potential applications of\nNeural Laplace to learn diverse classes of SDE, both from a theoretical and a\npractical point of view.",
      "tldr_zh": "该研究介绍了 Neural Laplace 框架，这是一个统一的工具，用于学习各种类别的微分方程（DE），并在学习随机微分方程（SDE）时表现出色，优于依赖神经网络的学习常微分方程（ODE）的其他方法。许多系统因受随机性影响而无法用 ODE 建模，而 SDE 是处理时空动态的理想选择，该框架从理论和实践角度探讨了其在 SDE 学习中的潜力。通过这种方法，Neural Laplace 为更准确地模拟随机系统提供了新途径。",
      "categories": [
        "cs.LG",
        "cs.AI",
        "math.PR"
      ],
      "primary_category": "cs.LG",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2406.04964v1",
      "published_date": "2024-06-07 14:29:30 UTC",
      "updated_date": "2024-06-07 14:29:30 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-18T17:25:54.082529"
    },
    {
      "arxiv_id": "2406.04963v1",
      "title": "Learning Divergence Fields for Shift-Robust Graph Representations",
      "title_zh": "翻译失败",
      "authors": [
        "Qitian Wu",
        "Fan Nie",
        "Chenxiao Yang",
        "Junchi Yan"
      ],
      "abstract": "Real-world data generation often involves certain geometries (e.g., graphs)\nthat induce instance-level interdependence. This characteristic makes the\ngeneralization of learning models more difficult due to the intricate\ninterdependent patterns that impact data-generative distributions and can vary\nfrom training to testing. In this work, we propose a geometric diffusion model\nwith learnable divergence fields for the challenging generalization problem\nwith interdependent data. We generalize the diffusion equation with stochastic\ndiffusivity at each time step, which aims to capture the multi-faceted\ninformation flows among interdependent data. Furthermore, we derive a new\nlearning objective through causal inference, which can guide the model to learn\ngeneralizable patterns of interdependence that are insensitive across domains.\nRegarding practical implementation, we introduce three model instantiations\nthat can be considered as the generalized versions of GCN, GAT, and\nTransformers, respectively, which possess advanced robustness against\ndistribution shifts. We demonstrate their promising efficacy for\nout-of-distribution generalization on diverse real-world datasets.",
      "tldr_zh": "本文提出了一种几何扩散模型，使用可学习的 divergence fields 来处理图数据中互依赖性的分布偏移问题，该模型通过泛化扩散方程并引入每个时间步的随机扩散率，捕捉多方面信息流，并通过因果推理导出一个新的学习目标，以学习跨域不敏感的泛化模式。研究实现了三个模型实例，分别是 GCN、GAT 和 Transformers 的泛化版本，这些模型对分布偏移具有更强的鲁棒性。在各种真实世界数据集上，实验证明了这些模型在分布外泛化的有效性。",
      "categories": [
        "cs.LG",
        "cs.AI"
      ],
      "primary_category": "cs.LG",
      "comment": "Accepted to ICML 2024. Source codes at\n  https://github.com/fannie1208/GLIND",
      "pdf_url": "http://arxiv.org/pdf/2406.04963v1",
      "published_date": "2024-06-07 14:29:21 UTC",
      "updated_date": "2024-06-07 14:29:21 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-18T17:26:09.585008"
    },
    {
      "arxiv_id": "2406.04956v1",
      "title": "Expansion of situations theory for exploring shared awareness in human-intelligent autonomous systems",
      "title_zh": "翻译失败",
      "authors": [
        "Scott A. Humr",
        "Mustafa Canan",
        "Mustafa Demir"
      ],
      "abstract": "Intelligent autonomous systems are part of a system of systems that interact\nwith other agents to accomplish tasks in complex environments. However,\nintelligent autonomous systems integrated system of systems add additional\nlayers of complexity based on their limited cognitive processes, specifically\nshared situation awareness that allows a team to respond to novel tasks.\nIntelligent autonomous systems' lack of shared situation awareness adversely\ninfluences team effectiveness in complex task environments, such as military\ncommand-and-control. A complementary approach of shared situation awareness,\ncalled situations theory, is beneficial for understanding the relationship\nbetween system of systems shared situation awareness and effectiveness. The\ncurrent study elucidates a conceptual discussion on situations theory to\ninvestigate the development of an system of systems shared situational\nawareness when humans team with intelligent autonomous system agents. To ground\nthe discussion, the reviewed studies expanded situations theory within the\ncontext of a system of systems that result in three major conjectures that can\nbe beneficial to the design and development of future systems of systems.",
      "tldr_zh": "本研究扩展了 situations theory，以探讨人类与智能自主系统（intelligent autonomous systems）在系统群（system of systems）中实现共享情境意识（shared situation awareness）的关系。论文指出，智能自主系统的有限认知过程会削弱团队在复杂环境（如军事指挥控制）中的有效性，因此提出 situations theory 作为一种补充方法。研究通过概念讨论和文献回顾，分析了人类与智能自主系统代理团队的互动，并得出了三个主要假设。这些假设有助于未来系统群的设计和开发，提高团队应对新任务的能力。",
      "categories": [
        "cs.HC",
        "cs.AI"
      ],
      "primary_category": "cs.HC",
      "comment": "Keywords: artificial intelligence; human-machine interaction; IAS;\n  intelligent autonomous systems; shared situational awareness; situations\n  theory",
      "pdf_url": "http://arxiv.org/pdf/2406.04956v1",
      "published_date": "2024-06-07 14:21:01 UTC",
      "updated_date": "2024-06-07 14:21:01 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-18T17:26:18.452993"
    },
    {
      "arxiv_id": "2406.04955v1",
      "title": "Experimental Evaluation of ROS-Causal in Real-World Human-Robot Spatial Interaction Scenarios",
      "title_zh": "ROS-Causal 在真实世界人机空间交互场景中的实验评估",
      "authors": [
        "Luca Castri",
        "Gloria Beraldo",
        "Sariah Mghames",
        "Marc Hanheide",
        "Nicola Bellotto"
      ],
      "abstract": "Deploying robots in human-shared environments requires a deep understanding\nof how nearby agents and objects interact. Employing causal inference to model\ncause-and-effect relationships facilitates the prediction of human behaviours\nand enables the anticipation of robot interventions. However, a significant\nchallenge arises due to the absence of implementation of existing causal\ndiscovery methods within the ROS ecosystem, the standard de-facto framework in\nrobotics, hindering effective utilisation on real robots. To bridge this gap,\nin our previous work we proposed ROS-Causal, a ROS-based framework designed for\nonboard data collection and causal discovery in human-robot spatial\ninteractions. In this work, we present an experimental evaluation of ROS-Causal\nboth in simulation and on a new dataset of human-robot spatial interactions in\na lab scenario, to assess its performance and effectiveness. Our analysis\ndemonstrates the efficacy of this approach, showcasing how causal models can be\nextracted directly onboard by robots during data collection. The online causal\nmodels generated from the simulation are consistent with those from lab\nexperiments. These findings can help researchers to enhance the performance of\nrobotic systems in shared environments, firstly by studying the causal\nrelations between variables in simulation without real people, and then\nfacilitating the actual robot deployment in real human environments.\nROS-Causal: https://lcastri.github.io/roscausal",
      "tldr_zh": "该研究评估了ROS-Causal框架在真实世界人-机器人空间互动场景中的性能，该框架基于ROS生态系统，用于收集数据和进行因果发现，以帮助机器人预测人类行为并预见干预。实验包括模拟环境和实验室数据集，证明ROS-Causal能让机器人在线提取因果模型，且模拟结果与真实实验一致。总体而言，此方法提升了机器人系统在共享环境中的表现，允许研究人员先在模拟中分析变量间的因果关系，再安全部署到真实场景。ROS-Causal框架可访问：https://lcastri.github.io/roscausal。",
      "categories": [
        "cs.RO",
        "cs.AI"
      ],
      "primary_category": "cs.RO",
      "comment": "Published at 2024 IEEE International Conference on Robot and Human\n  Interactive Communication (RO-MAN)",
      "pdf_url": "http://arxiv.org/pdf/2406.04955v1",
      "published_date": "2024-06-07 14:20:30 UTC",
      "updated_date": "2024-06-07 14:20:30 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-18T17:26:30.661638"
    },
    {
      "arxiv_id": "2406.04952v2",
      "title": "Quantifying Geospatial in the Common Crawl Corpus",
      "title_zh": "在 Common Crawl Corpus 中量化地理空间",
      "authors": [
        "Ilya Ilyankou",
        "Meihui Wang",
        "Stefano Cavazzi",
        "James Haworth"
      ],
      "abstract": "Large language models (LLMs) exhibit emerging geospatial capabilities,\nstemming from their pre-training on vast unlabelled text datasets that are\noften derived from the Common Crawl (CC) corpus. However, the geospatial\ncontent within CC remains largely unexplored, impacting our understanding of\nLLMs' spatial reasoning. This paper investigates the prevalence of geospatial\ndata in recent Common Crawl releases using Gemini 1.5, a powerful language\nmodel. By analyzing a sample of documents and manually revising the results, we\nestimate that 18.7% of web documents in CC contain geospatial information such\nas coordinates and addresses. We find little difference in prevalence between\nEnlgish- and non-English-language documents. Our findings provide quantitative\ninsights into the nature and extent of geospatial data in CC, and lay the\ngroundwork for future studies of geospatial biases of LLMs.",
      "tldr_zh": "该研究量化了Common Crawl (CC) 语料库中的地理空间数据分布，以更好地理解大语言模型 (LLMs) 的空间推理能力。研究者使用Gemini 1.5模型分析样本文档，并通过手动修正估算出CC中约18.7%的网页文档包含坐标、地址等地理空间信息。结果显示，英文和非英文文档在地理空间内容 prevalence 上差异不大。该工作为未来探索LLMs的地理空间偏差提供了重要的定量基础。",
      "categories": [
        "cs.CL",
        "cs.AI"
      ],
      "primary_category": "cs.CL",
      "comment": "Accepted as a poster to ACM SIGSPATIAL 2024",
      "pdf_url": "http://arxiv.org/pdf/2406.04952v2",
      "published_date": "2024-06-07 14:16:37 UTC",
      "updated_date": "2024-08-29 16:49:29 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-18T17:26:44.223946"
    },
    {
      "arxiv_id": "2406.04949v1",
      "title": "Nacala-Roof-Material: Drone Imagery for Roof Detection, Classification, and Segmentation to Support Mosquito-borne Disease Risk Assessment",
      "title_zh": "翻译失败",
      "authors": [
        "Venkanna Babu Guthula",
        "Stefan Oehmcke",
        "Remigio Chilaule",
        "Hui Zhang",
        "Nico Lang",
        "Ankit Kariryaa",
        "Johan Mottelson",
        "Christian Igel"
      ],
      "abstract": "As low-quality housing and in particular certain roof characteristics are\nassociated with an increased risk of malaria, classification of roof types\nbased on remote sensing imagery can support the assessment of malaria risk and\nthereby help prevent the disease. To support research in this area, we release\nthe Nacala-Roof-Material dataset, which contains high-resolution drone images\nfrom Mozambique with corresponding labels delineating houses and specifying\ntheir roof types. The dataset defines a multi-task computer vision problem,\ncomprising object detection, classification, and segmentation. In addition, we\nbenchmarked various state-of-the-art approaches on the dataset. Canonical\nU-Nets, YOLOv8, and a custom decoder on pretrained DINOv2 served as baselines.\nWe show that each of the methods has its advantages but none is superior on all\ntasks, which highlights the potential of our dataset for future research in\nmulti-task learning. While the tasks are closely related, accurate segmentation\nof objects does not necessarily imply accurate instance separation, and vice\nversa. We address this general issue by introducing a variant of the deep\nordinal watershed (DOW) approach that additionally separates the interior of\nobjects, allowing for improved object delineation and separation. We show that\nour DOW variant is a generic approach that improves the performance of both\nU-Net and DINOv2 backbones, leading to a better trade-off between semantic\nsegmentation and instance segmentation.",
      "tldr_zh": "本研究发布Nacala-Roof-Material数据集，该数据集包含莫桑比克的高分辨率无人机图像，用于房屋检测、屋顶类型分类和分割，从而支持评估疟疾风险，因为特定屋顶特征与疾病传播相关。该数据集定义了一个多任务计算机视觉问题，包括物体检测、分类和分割，并对U-Nets、YOLOv8和基于DINOv2的自定义解码器进行了基准测试，结果显示每种方法在不同任务上各有优势，但无一全面优越，突显其在多任务学习中的研究潜力。为解决语义分割和实例分割的权衡问题，研究引入了deep ordinal watershed (DOW)方法的变体，该方法能更好地分离物体内部，提升了U-Net和DINOv2的性能。",
      "categories": [
        "cs.CV",
        "cs.AI",
        "cs.LG"
      ],
      "primary_category": "cs.CV",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2406.04949v1",
      "published_date": "2024-06-07 14:07:23 UTC",
      "updated_date": "2024-06-07 14:07:23 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-18T17:27:07.187820"
    },
    {
      "arxiv_id": "2406.04940v2",
      "title": "CarbonSense: A Multimodal Dataset and Baseline for Carbon Flux Modelling",
      "title_zh": "翻译失败",
      "authors": [
        "Matthew Fortier",
        "Mats L. Richter",
        "Oliver Sonnentag",
        "Chris Pal"
      ],
      "abstract": "Terrestrial carbon fluxes provide vital information about our biosphere's\nhealth and its capacity to absorb anthropogenic CO$_2$ emissions. The\nimportance of predicting carbon fluxes has led to the emerging field of\ndata-driven carbon flux modelling (DDCFM), which uses statistical techniques to\npredict carbon fluxes from biophysical data. However, the field lacks a\nstandardized dataset to promote comparisons between models. To address this\ngap, we present CarbonSense, the first machine learning-ready dataset for\nDDCFM. CarbonSense integrates measured carbon fluxes, meteorological\npredictors, and satellite imagery from 385 locations across the globe, offering\ncomprehensive coverage and facilitating robust model training. Additionally, we\nprovide a baseline model using a current state-of-the-art DDCFM approach and a\nnovel transformer based model. Our experiments illustrate the potential gains\nthat multimodal deep learning techniques can bring to this domain. By providing\nthese resources, we aim to lower the barrier to entry for other deep learning\nresearchers to develop new models and drive new advances in carbon flux\nmodelling.",
      "tldr_zh": "本研究提出了 CarbonSense，这是一个多模态数据集，旨在解决数据驱动碳通量建模 (DDCFM) 领域缺乏标准化数据集的问题，从而促进模型间的比较。CarbonSense 整合了全球 385 个地点的碳通量测量、气象预测数据和卫星图像，提供全面覆盖以支持稳健的模型训练。此外，该论文提供了一个基线模型，包括当前最先进的 DDCFM 方法和一个新型基于 Transformer 的模型，实验结果显示多模态深度学习技术能显著提升碳通量预测性能。通过这些资源，该研究降低了深度学习研究者进入该领域的门槛，推动碳通量建模的创新发展。",
      "categories": [
        "cs.LG",
        "cs.AI"
      ],
      "primary_category": "cs.LG",
      "comment": "9 content pages, 11 reference pages, 9 appendix pages",
      "pdf_url": "http://arxiv.org/pdf/2406.04940v2",
      "published_date": "2024-06-07 13:47:40 UTC",
      "updated_date": "2025-03-24 15:37:27 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-18T17:27:18.442823"
    },
    {
      "arxiv_id": "2406.04938v1",
      "title": "SpanGNN: Towards Memory-Efficient Graph Neural Networks via Spanning Subgraph Training",
      "title_zh": "翻译失败",
      "authors": [
        "Xizhi Gu",
        "Hongzheng Li",
        "Shihong Gao",
        "Xinyan Zhang",
        "Lei Chen",
        "Yingxia Shao"
      ],
      "abstract": "Graph Neural Networks (GNNs) have superior capability in learning graph data.\nFull-graph GNN training generally has high accuracy, however, it suffers from\nlarge peak memory usage and encounters the Out-of-Memory problem when handling\nlarge graphs. To address this memory problem, a popular solution is mini-batch\nGNN training. However, mini-batch GNN training increases the training variance\nand sacrifices the model accuracy. In this paper, we propose a new\nmemory-efficient GNN training method using spanning subgraph, called SpanGNN.\nSpanGNN trains GNN models over a sequence of spanning subgraphs, which are\nconstructed from empty structure. To overcome the excessive peak memory\nconsumption problem, SpanGNN selects a set of edges from the original graph to\nincrementally update the spanning subgraph between every epoch. To ensure the\nmodel accuracy, we introduce two types of edge sampling strategies (i.e.,\nvariance-reduced and noise-reduced), and help SpanGNN select high-quality edges\nfor the GNN learning. We conduct experiments with SpanGNN on widely used\ndatasets, demonstrating SpanGNN's advantages in the model performance and low\npeak memory usage.",
      "tldr_zh": "Graph Neural Networks (GNNs) 在全图训练时面临高内存消耗和内存不足问题，而现有的 mini-batch 训练方法虽能缓解此问题但会增加训练方差并降低模型准确性。论文提出 SpanGNN，一种基于跨越子图 (spanning subgraph) 的内存高效训练方法，通过在每个 epoch 间增量更新子图并采用 variance-reduced 和 noise-reduced 边采样策略，确保了高品质的 GNN 学习。实验在常用数据集上证明，SpanGNN 显著提高了模型性能，同时降低了峰值内存使用。",
      "categories": [
        "cs.LG",
        "cs.AI"
      ],
      "primary_category": "cs.LG",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2406.04938v1",
      "published_date": "2024-06-07 13:46:23 UTC",
      "updated_date": "2024-06-07 13:46:23 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-18T17:27:22.344249"
    },
    {
      "arxiv_id": "2406.04935v1",
      "title": "SLOPE: Search with Learned Optimal Pruning-based Expansion",
      "title_zh": "翻译失败",
      "authors": [
        "Davor Bokan",
        "Zlatan Ajanovic",
        "Bakir Lacevic"
      ],
      "abstract": "Heuristic search is often used for motion planning and pathfinding problems,\nfor finding the shortest path in a graph while also promising completeness and\noptimal efficiency. The drawback is it's space complexity, specifically storing\nall expanded child nodes in memory and sorting large lists of active nodes,\nwhich can be a problem in real-time scenarios with limited on-board\ncomputation. To combat this, we present the Search with Learned Optimal\nPruning-based Expansion (SLOPE), which, learns the distance of a node from a\npossible optimal path, unlike other approaches that learn a cost-to-go value.\nThe unfavored nodes are then pruned according to the said distance, which in\nturn reduces the size of the open list. This ensures that the search explores\nonly the region close to optimal paths while lowering memory and computational\ncosts. Unlike traditional learning methods, our approach is orthogonal to\nestimating cost-to-go heuristics, offering a complementary strategy for\nimproving search efficiency. We demonstrate the effectiveness of our approach\nevaluating it as a standalone search method and in conjunction with learned\nheuristic functions, achieving comparable-or-better node expansion metrics,\nwhile lowering the number of child nodes in the open list. Our code is\navailable at https://github.com/dbokan1/SLOPE.",
      "tldr_zh": "本论文提出了一种名为 SLOPE 的搜索方法（Search with Learned Optimal Pruning-based Expansion），旨在解决启发式搜索（heuristic search）在运动规划和路径查找中的空间复杂度问题，如存储扩展子节点和排序活跃节点列表。不同于传统方法，SLOPE 通过学习节点与最优路径的距离来修剪不必要的节点，从而减少开放列表的大小，并降低内存和计算成本，同时保持搜索的完整性和效率。实验结果表明，SLOPE 作为独立方法或与学习启发式函数（learned heuristic functions）结合使用，能实现相媲美或更好的节点扩展指标，提供了一种互补策略。",
      "categories": [
        "cs.AI",
        "cs.LG"
      ],
      "primary_category": "cs.AI",
      "comment": "presented at the ICAPS 2024 workshop on Bridging the Planning and\n  Reinforcement Learning",
      "pdf_url": "http://arxiv.org/pdf/2406.04935v1",
      "published_date": "2024-06-07 13:42:15 UTC",
      "updated_date": "2024-06-07 13:42:15 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-18T17:27:33.025631"
    },
    {
      "arxiv_id": "2406.04934v1",
      "title": "Optimal Recurrent Network Topologies for Dynamical Systems Reconstruction",
      "title_zh": "用于动态系统重构的最优循环网络拓扑结构",
      "authors": [
        "Christoph Jürgen Hemmer",
        "Manuel Brenner",
        "Florian Hess",
        "Daniel Durstewitz"
      ],
      "abstract": "In dynamical systems reconstruction (DSR) we seek to infer from time series\nmeasurements a generative model of the underlying dynamical process. This is a\nprime objective in any scientific discipline, where we are particularly\ninterested in parsimonious models with a low parameter load. A common strategy\nhere is parameter pruning, removing all parameters with small weights. However,\nhere we find this strategy does not work for DSR, where even low magnitude\nparameters can contribute considerably to the system dynamics. On the other\nhand, it is well known that many natural systems which generate complex\ndynamics, like the brain or ecological networks, have a sparse topology with\ncomparatively few links. Inspired by this, we show that geometric pruning,\nwhere in contrast to magnitude-based pruning weights with a low contribution to\nan attractor's geometrical structure are removed, indeed manages to reduce\nparameter load substantially without significantly hampering DSR quality. We\nfurther find that the networks resulting from geometric pruning have a specific\ntype of topology, and that this topology, and not the magnitude of weights, is\nwhat is most crucial to performance. We provide an algorithm that automatically\ngenerates such topologies which can be used as priors for generative modeling\nof dynamical systems by RNNs, and compare it to other well studied topologies\nlike small-world or scale-free networks.",
      "tldr_zh": "该研究探讨了动态系统重建（DSR），旨在从时间序列测量中推断底层动态过程的生成模型，同时追求低参数负载的简洁模型。传统基于权重大小的参数修剪在DSR中无效，因为小权重可能对系统动态有显著贡献；相反，作者提出几何修剪（geometric pruning）方法，通过移除对吸引子几何结构贡献小的权重，显著减少参数而不影响重建质量。实验发现，几何修剪生成的网络拓扑类型（如特定稀疏结构）比权重大小更关键，对DSR性能至关重要。作者提供了一个自动生成这种拓扑的算法，作为循环神经网络（RNNs）用于动态系统建模的先验，并与小世界网络（small-world）和无标度网络（scale-free）拓扑进行比较。",
      "categories": [
        "cs.LG",
        "cs.AI",
        "math.DS",
        "nlin.CD"
      ],
      "primary_category": "cs.LG",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2406.04934v1",
      "published_date": "2024-06-07 13:41:17 UTC",
      "updated_date": "2024-06-07 13:41:17 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-18T17:27:48.052980"
    },
    {
      "arxiv_id": "2406.04913v1",
      "title": "Online Adaptation for Enhancing Imitation Learning Policies",
      "title_zh": "在线适应用于增强模仿学习策略",
      "authors": [
        "Federico Malato",
        "Ville Hautamaki"
      ],
      "abstract": "Imitation learning enables autonomous agents to learn from human examples,\nwithout the need for a reward signal. Still, if the provided dataset does not\nencapsulate the task correctly, or when the task is too complex to be modeled,\nsuch agents fail to reproduce the expert policy. We propose to recover from\nthese failures through online adaptation. Our approach combines the action\nproposal coming from a pre-trained policy with relevant experience recorded by\nan expert. The combination results in an adapted action that closely follows\nthe expert. Our experiments show that an adapted agent performs better than its\npure imitation learning counterpart. Notably, adapted agents can achieve\nreasonable performance even when the base, non-adapted policy catastrophically\nfails.",
      "tldr_zh": "这篇论文提出了一种在线适应（online adaptation）方法，用于提升模仿学习（imitation learning）策略的性能，旨在帮助自主代理从人类示例中学习，而无需奖励信号。方法通过将预训练策略的动作建议与专家记录的相关经验相结合，生成更接近专家行为的适应动作，从而解决数据集不足或任务复杂导致的策略失败问题。实验结果显示，适应后的代理比纯模仿学习代理表现更好，甚至在基础策略完全失败时也能实现合理的性能。",
      "categories": [
        "cs.AI",
        "cs.LG"
      ],
      "primary_category": "cs.AI",
      "comment": "Accepted at IEEE Conference on Games 2024, Milan, Italy",
      "pdf_url": "http://arxiv.org/pdf/2406.04913v1",
      "published_date": "2024-06-07 13:09:48 UTC",
      "updated_date": "2024-06-07 13:09:48 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-18T17:27:57.866758"
    },
    {
      "arxiv_id": "2406.04910v2",
      "title": "PolyLUT-Add: FPGA-based LUT Inference with Wide Inputs",
      "title_zh": "翻译失败",
      "authors": [
        "Binglei Lou",
        "Richard Rademacher",
        "David Boland",
        "Philip H. W. Leong"
      ],
      "abstract": "FPGAs have distinct advantages as a technology for deploying deep neural\nnetworks (DNNs) at the edge. Lookup Table (LUT) based networks, where neurons\nare directly modeled using LUTs, help maximize this promise of offering\nultra-low latency and high area efficiency on FPGAs. Unfortunately, LUT\nresource usage scales exponentially with the number of inputs to the LUT,\nrestricting PolyLUT to small LUT sizes. This work introduces PolyLUT-Add, a\ntechnique that enhances neuron connectivity by combining $A$ PolyLUT\nsub-neurons via addition to improve accuracy. Moreover, we describe a novel\narchitecture to improve its scalability. We evaluated our implementation over\nthe MNIST, Jet Substructure classification, and Network Intrusion Detection\nbenchmark and found that for similar accuracy, PolyLUT-Add achieves a LUT\nreduction of $2.0-13.9\\times$ with a $1.2-1.6\\times$ decrease in latency.",
      "tldr_zh": "本论文提出PolyLUT-Add，一种基于FPGA的LUT推理技术，通过将多个PolyLUT子神经元通过加法结合，增强神经元连接性并提升准确性，同时引入新型架构以提高可扩展性。针对LUT资源随输入数量指数增长的问题，该方法优化了FPGA上深度神经网络(DNNs)的部署，实现超低延迟和高面积效率。在MNIST、Jet Substructure classification和Network Intrusion Detection基准测试中，PolyLUT-Add在类似准确性下，实现了2.0-13.9倍的LUT减少和1.2-1.6倍的延迟降低。",
      "categories": [
        "cs.LG",
        "cs.AI",
        "cs.AR"
      ],
      "primary_category": "cs.LG",
      "comment": "The source code for this paper is available at:\n  https://github.com/bingleilou/PolyLUT-Add",
      "pdf_url": "http://arxiv.org/pdf/2406.04910v2",
      "published_date": "2024-06-07 13:00:57 UTC",
      "updated_date": "2024-09-15 12:32:18 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-18T17:28:14.797973"
    },
    {
      "arxiv_id": "2406.04906v3",
      "title": "RU-AI: A Large Multimodal Dataset for Machine-Generated Content Detection",
      "title_zh": "RU-AI：一个大型多模态数据集，用于机器生成内容检测",
      "authors": [
        "Liting Huang",
        "Zhihao Zhang",
        "Yiran Zhang",
        "Xiyue Zhou",
        "Shoujin Wang"
      ],
      "abstract": "The recent generative AI models' capability of creating realistic and\nhuman-like content is significantly transforming the ways in which people\ncommunicate, create and work. The machine-generated content is a double-edged\nsword. On one hand, it can benefit the society when used appropriately. On the\nother hand, it may mislead people, posing threats to the society, especially\nwhen mixed together with natural content created by humans. Hence, there is an\nurgent need to develop effective methods to detect machine-generated content.\nHowever, the lack of aligned multimodal datasets inhibited the development of\nsuch methods, particularly in triple-modality settings (e.g., text, image, and\nvoice). In this paper, we introduce RU-AI, a new large-scale multimodal dataset\nfor robust and effective detection of machine-generated content in text, image\nand voice. Our dataset is constructed on the basis of three large publicly\navailable datasets: Flickr8K, COCO and Places205, by adding their corresponding\nAI duplicates, resulting in a total of 1,475,370 instances. In addition, we\ncreated an additional noise variant of the dataset for testing the robustness\nof detection models. We conducted extensive experiments with the current SOTA\ndetection methods on our dataset. The results reveal that existing models still\nstruggle to achieve accurate and robust detection on our dataset. We hope that\nthis new data set can promote research in the field of machine-generated\ncontent detection, fostering the responsible use of generative AI. The source\ncode and datasets are available at https://github.com/ZhihaoZhang97/RU-AI.",
      "tldr_zh": "该研究引入了RU-AI，一个大规模多模态数据集，用于检测机器生成内容（Machine-Generated Content），以应对生成式AI在文本、图像和语音三模态中可能带来的误导风险。数据集基于Flickr8K、COCO和Places205等公开数据集构建，通过添加对应的AI生成副本，总计包含1,475,370个实例，并包括一个噪声变体版本以测试检测模型的鲁棒性。实验结果显示，现有的SOTA检测方法在RU-AI数据集上表现不佳，准确性和鲁棒性仍有待提升。该数据集的发布旨在推动机器生成内容检测领域的研究，促进生成式AI的负责任使用。",
      "categories": [
        "cs.CV",
        "cs.AI"
      ],
      "primary_category": "cs.CV",
      "comment": "Accepted by WWW'25 Resource Track",
      "pdf_url": "http://arxiv.org/pdf/2406.04906v3",
      "published_date": "2024-06-07 12:58:14 UTC",
      "updated_date": "2025-02-18 06:29:36 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-18T17:28:23.623431"
    },
    {
      "arxiv_id": "2406.04899v1",
      "title": "Sliding Window 3-Objective Pareto Optimization for Problems with Chance Constraints",
      "title_zh": "翻译失败",
      "authors": [
        "Frank Neumann",
        "Carsten Witt"
      ],
      "abstract": "Constrained single-objective problems have been frequently tackled by\nevolutionary multi-objective algorithms where the constraint is relaxed into an\nadditional objective. Recently, it has been shown that Pareto optimization\napproaches using bi-objective models can be significantly sped up using sliding\nwindows (Neumann and Witt, ECAI 2023). In this paper, we extend the sliding\nwindow approach to $3$-objective formulations for tackling chance constrained\nproblems. On the theoretical side, we show that our new sliding window approach\nimproves previous runtime bounds obtained in (Neumann and Witt, GECCO 2023)\nwhile maintaining the same approximation guarantees. Our experimental\ninvestigations for the chance constrained dominating set problem show that our\nnew sliding window approach allows one to solve much larger instances in a much\nmore efficient way than the 3-objective approach presented in (Neumann and\nWitt, GECCO 2023).",
      "tldr_zh": "本研究将滑动窗口(Sliding Window)方法扩展到三目标(3-Objective)Pareto优化，用于处理带有机会约束(Chance Constraints)的问题，旨在加速解决约束单目标问题的演化算法。\n在理论方面，该方法改善了之前的工作（Neumann and Witt, GECCO 2023）中的运行时边界(Runtime Bounds)，同时保持相同的近似保证(Approximation Guarantees)。\n实验结果表明，在机会约束支配集问题(Chance Constrained Dominating Set Problem)上，新方法比现有三目标方法更高效，能够处理更大的实例。",
      "categories": [
        "cs.NE",
        "cs.AI"
      ],
      "primary_category": "cs.NE",
      "comment": "To appear at PPSN 2024",
      "pdf_url": "http://arxiv.org/pdf/2406.04899v1",
      "published_date": "2024-06-07 12:45:32 UTC",
      "updated_date": "2024-06-07 12:45:32 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-18T17:28:35.925752"
    },
    {
      "arxiv_id": "2406.04896v2",
      "title": "Stabilizing Extreme Q-learning by Maclaurin Expansion",
      "title_zh": "翻译失败",
      "authors": [
        "Motoki Omura",
        "Takayuki Osa",
        "Yusuke Mukuta",
        "Tatsuya Harada"
      ],
      "abstract": "In offline reinforcement learning, in-sample learning methods have been\nwidely used to prevent performance degradation caused by evaluating\nout-of-distribution actions from the dataset. Extreme Q-learning (XQL) employs\na loss function based on the assumption that Bellman error follows a Gumbel\ndistribution, enabling it to model the soft optimal value function in an\nin-sample manner. It has demonstrated strong performance in both offline and\nonline reinforcement learning settings. However, issues remain, such as the\ninstability caused by the exponential term in the loss function and the risk of\nthe error distribution deviating from the Gumbel distribution. Therefore, we\npropose Maclaurin Expanded Extreme Q-learning to enhance stability. In this\nmethod, applying Maclaurin expansion to the loss function in XQL enhances\nstability against large errors. This approach involves adjusting the modeled\nvalue function between the value function under the behavior policy and the\nsoft optimal value function, thus achieving a trade-off between stability and\noptimality depending on the order of expansion. It also enables adjustment of\nthe error distribution assumption from a normal distribution to a Gumbel\ndistribution. Our method significantly stabilizes learning in online RL tasks\nfrom DM Control, where XQL was previously unstable. Additionally, it improves\nperformance in several offline RL tasks from D4RL.",
      "tldr_zh": "本研究针对Extreme Q-learning (XQL) 在强化学习中的不稳定性问题（如损失函数的指数项和Bellman error分布偏离Gumbel distribution），提出了一种Maclaurin Expanded Extreme Q-learning方法。通过对XQL损失函数应用Maclaurin展开，该方法调整价值函数在行为策略价值函数和软最优价值函数之间的建模，实现稳定性与最优性的权衡，并允许错误分布从正态分布过渡到Gumbel distribution。实验结果显示，该方法在DM Control的在线RL任务中显著提升了学习稳定性，并在D4RL的离线RL任务中改善了性能。总的来说，此创新增强了XQL的鲁棒性，为强化学习算法的可靠应用提供了新途径。",
      "categories": [
        "cs.LG",
        "cs.AI"
      ],
      "primary_category": "cs.LG",
      "comment": "Accepted at RLC 2024: The first Reinforcement Learning Conference",
      "pdf_url": "http://arxiv.org/pdf/2406.04896v2",
      "published_date": "2024-06-07 12:43:17 UTC",
      "updated_date": "2024-09-02 13:55:25 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-18T17:28:49.863527"
    },
    {
      "arxiv_id": "2406.04890v1",
      "title": "Enhancing Indoor Temperature Forecasting through Synthetic Data in Low-Data Environments",
      "title_zh": "通过合成数据在低数据环境中增强室内温度预测",
      "authors": [
        "Zachari Thiry",
        "Massimiliano Ruocco",
        "Alessandro Nocente",
        "Michail Spitieris"
      ],
      "abstract": "Forecasting indoor temperatures is important to achieve efficient control of\nHVAC systems. In this task, the limited data availability presents a challenge\nas most of the available data is acquired during standard operation where\nextreme scenarios and transitory regimes such as major temperature increases or\ndecreases are de-facto excluded. Acquisition of such data requires significant\nenergy consumption and a dedicated facility, hindering the quantity and\ndiversity of available data. Cost related constraints however do not allow for\ncontinuous year-around acquisition. To address this, we investigate the\nefficacy of data augmentation techniques leveraging SoTA AI-based methods for\nsynthetic data generation. Inspired by practical and experimental motivations,\nwe explore fusion strategies of real and synthetic data to improve forecasting\nmodels. This approach alleviates the need for continuously acquiring extensive\ntime series data, especially in contexts involving repetitive heating and\ncooling cycles in buildings. In our evaluation 1) we assess the performance of\nsynthetic data generators independently, particularly focusing on SoTA AI-based\nmethods; 2) we measure the utility of incorporating synthetically augmented\ndata in a subsequent forecasting tasks where we employ a simple model in two\ndistinct scenarios: 1) we first examine an augmentation technique that combines\nreal and synthetically generated data to expand the training dataset, 2) we\ndelve into utilizing synthetic data to tackle dataset imbalances. Our results\nhighlight the potential of synthetic data augmentation in enhancing forecasting\naccuracy while mitigating training variance. Through empirical experiments, we\nshow significant improvements achievable by integrating synthetic data, thereby\npaving the way for more robust forecasting models in low-data regime.",
      "tldr_zh": "这篇论文探讨了在数据稀缺环境下，通过合成数据增强来提升室内温度预测的准确性，以优化 HVAC 系统控制。研究者利用 SoTA AI-based 方法生成合成数据，并探索了融合真实数据和合成数据的策略，包括扩展训练数据集和处理数据不平衡问题。实验结果显示，这种方法显著提高了预测性能，减少了训练方差，并为低数据环境下的鲁棒模型提供了新途径。",
      "categories": [
        "cs.LG",
        "cs.AI"
      ],
      "primary_category": "cs.LG",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2406.04890v1",
      "published_date": "2024-06-07 12:36:31 UTC",
      "updated_date": "2024-06-07 12:36:31 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-18T17:28:58.995896"
    },
    {
      "arxiv_id": "2406.04886v2",
      "title": "Unveiling the Invisible: Captioning Videos with Metaphors",
      "title_zh": "翻译失败",
      "authors": [
        "Abisek Rajakumar Kalarani",
        "Pushpak Bhattacharyya",
        "Sumit Shekhar"
      ],
      "abstract": "Metaphors are a common communication tool used in our day-to-day life. The\ndetection and generation of metaphors in textual form have been studied\nextensively but metaphors in other forms have been under-explored. Recent\nstudies have shown that Vision-Language (VL) models cannot understand visual\nmetaphors in memes and adverts. As of now, no probing studies have been done\nthat involve complex language phenomena like metaphors with videos. Hence, we\nintroduce a new VL task of describing the metaphors present in the videos in\nour work. To facilitate this novel task, we construct and release a manually\ncreated dataset with 705 videos and 2115 human-written captions, along with a\nnew metric called Average Concept Distance (ACD), to automatically evaluate the\ncreativity of the metaphors generated. We also propose a novel low-resource\nvideo metaphor captioning system: GIT-LLaVA, which obtains comparable\nperformance to SoTA video language models on the proposed task. We perform a\ncomprehensive analysis of existing video language models on this task and\npublish our dataset, models, and benchmark results to enable further research.",
      "tldr_zh": "这篇论文引入了一个新任务：使用隐喻（metaphors）来描述视频内容，填补视觉语言模型（Vision-Language models）在处理视频隐喻方面的空白。研究者构建了一个手动创建的数据集，包含705个视频和2115个人工撰写的标题，并提出Average Concept Distance (ACD)指标，用于自动评估生成的隐喻创意。论文开发了GIT-LLaVA系统，这是一个低资源视频隐喻标题系统，其性能与SoTA视频语言模型相当；同时，他们对现有模型进行了全面分析，并发布了数据集、模型和基准结果以推动进一步研究。",
      "categories": [
        "cs.CV",
        "cs.AI",
        "cs.CL"
      ],
      "primary_category": "cs.CV",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2406.04886v2",
      "published_date": "2024-06-07 12:32:44 UTC",
      "updated_date": "2024-10-02 13:40:10 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-18T17:29:12.095981"
    },
    {
      "arxiv_id": "2406.04882v1",
      "title": "InstructNav: Zero-shot System for Generic Instruction Navigation in Unexplored Environment",
      "title_zh": "翻译失败",
      "authors": [
        "Yuxing Long",
        "Wenzhe Cai",
        "Hongcheng Wang",
        "Guanqi Zhan",
        "Hao Dong"
      ],
      "abstract": "Enabling robots to navigate following diverse language instructions in\nunexplored environments is an attractive goal for human-robot interaction.\nHowever, this goal is challenging because different navigation tasks require\ndifferent strategies. The scarcity of instruction navigation data hinders\ntraining an instruction navigation model with varied strategies. Therefore,\nprevious methods are all constrained to one specific type of navigation\ninstruction. In this work, we propose InstructNav, a generic instruction\nnavigation system. InstructNav makes the first endeavor to handle various\ninstruction navigation tasks without any navigation training or pre-built maps.\nTo reach this goal, we introduce Dynamic Chain-of-Navigation (DCoN) to unify\nthe planning process for different types of navigation instructions.\nFurthermore, we propose Multi-sourced Value Maps to model key elements in\ninstruction navigation so that linguistic DCoN planning can be converted into\nrobot actionable trajectories. With InstructNav, we complete the R2R-CE task in\na zero-shot way for the first time and outperform many task-training methods.\nBesides, InstructNav also surpasses the previous SOTA method by 10.48% on the\nzero-shot Habitat ObjNav and by 86.34% on demand-driven navigation DDN. Real\nrobot experiments on diverse indoor scenes further demonstrate our method's\nrobustness in coping with the environment and instruction variations.",
      "tldr_zh": "本文提出 InstructNav，一种零样本泛化系统，旨在让机器人根据多样化语言指令在未探索环境中导航，而无需任何导航训练或预建地图。核心方法包括 Dynamic Chain-of-Navigation (DCoN)，用于统一不同指令类型的规划过程，以及 Multi-sourced Value Maps，用于建模关键元素并将语言规划转化为机器人可执行轨迹。实验结果显示，InstructNav 首次零样本完成 R2R-CE 任务，并在 Habitat ObjNav 上超越现有最佳方法 10.48%、在 DDN 上提升 86.34%。此外，真实机器人实验验证了其在室内场景中对环境和指令变化的鲁棒性。",
      "categories": [
        "cs.RO",
        "cs.AI",
        "cs.CL",
        "cs.CV"
      ],
      "primary_category": "cs.RO",
      "comment": "Submitted to CoRL 2024",
      "pdf_url": "http://arxiv.org/pdf/2406.04882v1",
      "published_date": "2024-06-07 12:26:34 UTC",
      "updated_date": "2024-06-07 12:26:34 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-18T17:29:24.920923"
    },
    {
      "arxiv_id": "2406.04873v2",
      "title": "Ada-VE: Training-Free Consistent Video Editing Using Adaptive Motion Prior",
      "title_zh": "翻译失败",
      "authors": [
        "Tanvir Mahmud",
        "Mustafa Munir",
        "Radu Marculescu",
        "Diana Marculescu"
      ],
      "abstract": "Video-to-video synthesis poses significant challenges in maintaining\ncharacter consistency, smooth temporal transitions, and preserving visual\nquality during fast motion. While recent fully cross-frame self-attention\nmechanisms have improved character consistency across multiple frames, they\ncome with high computational costs and often include redundant operations,\nespecially for videos with higher frame rates. To address these inefficiencies,\nwe propose an adaptive motion-guided cross-frame attention mechanism that\nselectively reduces redundant computations. This enables a greater number of\ncross-frame attentions over more frames within the same computational budget,\nthereby enhancing both video quality and temporal coherence. Our method\nleverages optical flow to focus on moving regions while sparsely attending to\nstationary areas, allowing for the joint editing of more frames without\nincreasing computational demands. Traditional frame interpolation techniques\nstruggle with motion blur and flickering in intermediate frames, which\ncompromises visual fidelity. To mitigate this, we introduce KV-caching for\njointly edited frames, reusing keys and values across intermediate frames to\npreserve visual quality and maintain temporal consistency throughout the video.\nWith our adaptive cross-frame self-attention approach, we achieve a threefold\nincrease in the number of keyframes processed compared to existing methods, all\nwithin the same computational budget as fully cross-frame attention baselines.\nThis results in significant improvements in prediction accuracy and temporal\nconsistency, outperforming state-of-the-art approaches. Code will be made\npublicly available at https://github.com/tanvir-utexas/AdaVE/tree/main",
      "tldr_zh": "这篇论文提出Ada-VE，一种无需训练的视频编辑方法，使用自适应运动先验(adaptive motion prior)来解决视频合成中角色一致性、光滑时间过渡和视觉质量的问题。方法引入自适应运动引导的跨帧注意力机制，利用optical flow关注移动区域并稀疏处理静态区域，同时采用KV-caching技术来重用中间帧的键值，减少计算需求并维持时间一致性。实验结果显示，Ada-VE在相同计算预算下处理的关键帧数量增加三倍，显著提升预测准确性和整体视频质量，超越现有方法。",
      "categories": [
        "cs.CV",
        "cs.AI"
      ],
      "primary_category": "cs.CV",
      "comment": "Accepted in WACV 2025. Project page:\n  https://tanvir-utexas.github.io/AdaVE_Demo/",
      "pdf_url": "http://arxiv.org/pdf/2406.04873v2",
      "published_date": "2024-06-07 12:12:25 UTC",
      "updated_date": "2024-11-10 10:08:37 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-18T17:29:35.428647"
    },
    {
      "arxiv_id": "2406.04867v2",
      "title": "Deep learning for precipitation nowcasting: A survey from the perspective of time series forecasting",
      "title_zh": "翻译失败",
      "authors": [
        "Sojung An",
        "Tae-Jin Oh",
        "Eunha Sohn",
        "Donghyun Kim"
      ],
      "abstract": "Deep learning-based time series forecasting has dominated the short-term\nprecipitation forecasting field with the help of its ability to estimate motion\nflow in high-resolution datasets. The growing interest in precipitation\nnowcasting offers substantial opportunities for the advancement of current\nforecasting technologies. Nevertheless, there has been a scarcity of in-depth\nsurveys of time series precipitation forecasting using deep learning. Thus,\nthis paper systemically reviews recent progress in time series precipitation\nforecasting models. Specifically, we investigate the following key points\nwithin background components, covering: i) preprocessing, ii) objective\nfunctions, and iii) evaluation metrics. We then categorize forecasting models\ninto \\textit{recursive} and \\textit{multiple} strategies based on their\napproaches to predict future frames, investigate the impacts of models using\nthe strategies, and performance assessments. Finally, we evaluate current deep\nlearning-based models for precipitation forecasting on a public benchmark,\ndiscuss their limitations and challenges, and present some promising research\ndirections. Our contribution lies in providing insights for a better\nunderstanding of time series precipitation forecasting and in aiding the\ndevelopment of robust AI solutions for the future.",
      "tldr_zh": "这篇论文从时间序列预测的角度系统调查了深度学习在降水预报（precipitation nowcasting）中的应用，强调其在高分辨率数据集上估计运动流的优势。论文探讨了关键背景组件，包括预处理、目标函数（objective functions）和评估指标（evaluation metrics），并将预测模型分类为递归（recursive）和多重（multiple）策略，分析了这些策略的影响和性能评估结果。通过在公共基准上评估当前模型，该研究揭示了现有方法的局限性与挑战，并提出了一些有前景的研究方向。该工作为更好地理解时间序列降水预报提供了洞见，并有助于开发更稳健的 AI 解决方案。",
      "categories": [
        "cs.LG",
        "cs.AI",
        "cs.CV"
      ],
      "primary_category": "cs.LG",
      "comment": "21 pages, 7 figures, 5 tables",
      "pdf_url": "http://arxiv.org/pdf/2406.04867v2",
      "published_date": "2024-06-07 12:07:09 UTC",
      "updated_date": "2024-06-14 01:11:09 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-18T17:29:50.083268"
    },
    {
      "arxiv_id": "2406.10246v1",
      "title": "Semantic-Enhanced Relational Metric Learning for Recommender Systems",
      "title_zh": "用于推荐系统的语义增强关系度量学习",
      "authors": [
        "Mingming Li",
        "Fuqing Zhu",
        "Feng Yuan",
        "Songlin Hu"
      ],
      "abstract": "Recently, relational metric learning methods have been received great\nattention in recommendation community, which is inspired by the translation\nmechanism in knowledge graph. Different from the knowledge graph where the\nentity-to-entity relations are given in advance, historical interactions lack\nexplicit relations between users and items in recommender systems. Currently,\nmany researchers have succeeded in constructing the implicit relations to remit\nthis issue. However, in previous work, the learning process of the induction\nfunction only depends on a single source of data (i.e., user-item interaction)\nin a supervised manner, resulting in the co-occurrence relation that is free of\nany semantic information. In this paper, to tackle the above problem in\nrecommender systems, we propose a joint Semantic-Enhanced Relational Metric\nLearning (SERML) framework that incorporates the semantic information.\nSpecifically, the semantic signal is first extracted from the target reviews\ncontaining abundant item features and personalized user preferences. A novel\nregression model is then designed via leveraging the extracted semantic signal\nto improve the discriminative ability of original relation-based training\nprocess. On four widely-used public datasets, experimental results demonstrate\nthat SERML produces a competitive performance compared with several\nstate-of-the-art methods in recommender systems.",
      "tldr_zh": "该论文针对推荐系统中的关系度量学习问题，提出了一种 Semantic-Enhanced Relational Metric Learning (SERML) 框架，以解决传统方法依赖单一用户-物品交互数据而缺乏语义信息的不足。SERML 通过从目标评论中提取语义信号（如物品特征和用户偏好），并设计一个新颖的回归模型来增强原有的关系学习过程，从而提高模型的鉴别能力。在四个公共数据集上的实验结果表明，SERML 相比现有最先进方法表现出色，显著提升了推荐性能。",
      "categories": [
        "cs.IR",
        "cs.AI"
      ],
      "primary_category": "cs.IR",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2406.10246v1",
      "published_date": "2024-06-07 11:54:50 UTC",
      "updated_date": "2024-06-07 11:54:50 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-18T17:30:02.132927"
    },
    {
      "arxiv_id": "2406.04851v2",
      "title": "Digital assistant in a point of sales",
      "title_zh": "翻译失败",
      "authors": [
        "Emilia Lesiak",
        "Grzegorz Wolny",
        "Bartosz Przybył",
        "Michał Szczerbak"
      ],
      "abstract": "This article investigates the deployment of a Voice User Interface\n(VUI)-powered digital assistant in a retail setting and assesses its impact on\ncustomer engagement and service efficiency. The study explores how digital\nassistants can enhance user interactions through advanced conversational\ncapabilities with multilingual support. By integrating a digital assistant into\na high-traffic retail environment, we evaluate its effectiveness in improving\nthe quality of customer service and operational efficiency. Data collected\nduring the experiment demonstrate varied impacts on customer interaction,\nrevealing insights into the future optimizations of digital assistant\ntechnologies in customer-facing roles. This study contributes to the\nunderstanding of digital transformation strategies within the customer\nrelations domain emphasizing the need for service flexibility and user-centric\ndesign in modern retail stores.",
      "tldr_zh": "本研究探讨了在零售环境中部署基于 Voice User Interface (VUI) 的数字助理，并评估其对客户互动和服务效率的影响。该系统通过高级对话能力和多语言支持提升用户体验，并在高流量零售场景中进行整合实验。实验数据揭示了数字助理对客户互动的多样化影响，并为未来优化提供见解。该研究强调了数字转型策略中服务灵活性和用户中心设计的重要性，为现代零售领域的客户关系管理提供了新方向。",
      "categories": [
        "cs.HC",
        "cs.AI",
        "cs.CL"
      ],
      "primary_category": "cs.HC",
      "comment": "update: cleaned the unnecessary files and updated the metadata",
      "pdf_url": "http://arxiv.org/pdf/2406.04851v2",
      "published_date": "2024-06-07 11:33:21 UTC",
      "updated_date": "2024-06-10 13:20:33 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-18T17:30:12.958606"
    },
    {
      "arxiv_id": "2406.04848v3",
      "title": "CTBENCH: A Library and Benchmark for Certified Training",
      "title_zh": "翻译失败",
      "authors": [
        "Yuhao Mao",
        "Stefan Balauca",
        "Martin Vechev"
      ],
      "abstract": "Training certifiably robust neural networks is an important but challenging\ntask. While many algorithms for (deterministic) certified training have been\nproposed, they are often evaluated on different training schedules,\ncertification methods, and systematically under-tuned hyperparameters, making\nit difficult to compare their performance. To address this challenge, we\nintroduce CTBench, a unified library and a high-quality benchmark for certified\ntraining that evaluates all algorithms under fair settings and systematically\ntuned hyperparameters. We show that (1) almost all algorithms in CTBench\nsurpass the corresponding reported performance in literature in the magnitude\nof algorithmic improvements, thus establishing new state-of-the-art, and (2)\nthe claimed advantage of recent algorithms drops significantly when we enhance\nthe outdated baselines with a fair training schedule, a fair certification\nmethod and well-tuned hyperparameters. Based on CTBench, we provide new\ninsights into the current state of certified training, including (1) certified\nmodels have less fragmented loss surface, (2) certified models share many\nmistakes, (3) certified models have more sparse activations, (4) reducing\nregularization cleverly is crucial for certified training especially for large\nradii and (5) certified training has the potential to improve\nout-of-distribution generalization. We are confident that CTBench will serve as\na benchmark and testbed for future research in certified training.",
      "tldr_zh": "本研究引入了 CTBench，这是一个统一的库和基准，用于评估认证训练(certified training)算法，通过公平的训练设置和系统调整的超参数，解决了现有算法在不同条件下难以比较的问题。实验结果显示，几乎所有算法在 CTBench 中均超过了文献报道的表现，建立新的最先进水平，但最近算法的优势在公平优化后显著下降。该基准还提供了新见解，包括认证模型的损失表面更少碎片、共享更多错误、激活更稀疏，以及巧妙减少正则化对大半径认证训练的关键作用，并表明认证训练可能提升分布外泛化。总的来说，CTBench 将作为未来认证训练研究的标准测试平台。",
      "categories": [
        "cs.LG",
        "cs.AI"
      ],
      "primary_category": "cs.LG",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2406.04848v3",
      "published_date": "2024-06-07 11:27:18 UTC",
      "updated_date": "2025-02-03 14:49:02 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-18T17:30:24.620012"
    },
    {
      "arxiv_id": "2406.04845v1",
      "title": "FedLLM-Bench: Realistic Benchmarks for Federated Learning of Large Language Models",
      "title_zh": "FedLLM-Bench：大语言模型联邦学习的现实基准测试",
      "authors": [
        "Rui Ye",
        "Rui Ge",
        "Xinyu Zhu",
        "Jingyi Chai",
        "Yaxin Du",
        "Yang Liu",
        "Yanfeng Wang",
        "Siheng Chen"
      ],
      "abstract": "Federated learning has enabled multiple parties to collaboratively train\nlarge language models without directly sharing their data (FedLLM). Following\nthis training paradigm, the community has put massive efforts from diverse\naspects including framework, performance, and privacy. However, an unpleasant\nfact is that there are currently no realistic datasets and benchmarks for\nFedLLM and previous works all rely on artificially constructed datasets,\nfailing to capture properties in real-world scenarios. Addressing this, we\npropose FedLLM-Bench, which involves 8 training methods, 4 training datasets,\nand 6 evaluation metrics, to offer a comprehensive testbed for the FedLLM\ncommunity. FedLLM-Bench encompasses three datasets (e.g., user-annotated\nmultilingual dataset) for federated instruction tuning and one dataset (e.g.,\nuser-annotated preference dataset) for federated preference alignment, whose\nscale of client number ranges from 38 to 747. Our datasets incorporate several\nrepresentative diversities: language, quality, quantity, instruction, length,\nembedding, and preference, capturing properties in real-world scenarios. Based\non FedLLM-Bench, we conduct experiments on all datasets to benchmark existing\nFL methods and provide empirical insights (e.g., multilingual collaboration).\nWe believe that our FedLLM-Bench can benefit the FedLLM community by reducing\nrequired efforts, providing a practical testbed, and promoting fair\ncomparisons. Code and datasets are available at\nhttps://github.com/rui-ye/FedLLM-Bench.",
      "tldr_zh": "该研究提出了 FedLLM-Bench，一个针对 Federated Learning of Large Language Models (FedLLM) 的真实基准测试平台，以解决现有研究依赖人为构建数据集的问题。FedLLM-Bench 包括 8 种训练方法、4 个训练数据集（如用户标注的多语言数据集）和 6 个评估指标，涵盖联邦指令微调和联邦偏好对齐任务，客户端数量从 38 到 747 不等，并模拟真实场景的多样性（如语言、质量和偏好）。通过实验基准测试现有 FL 方法，该平台提供了宝贵的经验洞见（如多语言协作），有助于 FedLLM 社区减少努力、促进公平比较，并提供实际测试环境。",
      "categories": [
        "cs.CL",
        "cs.AI",
        "cs.DC",
        "cs.LG",
        "cs.MA"
      ],
      "primary_category": "cs.CL",
      "comment": "22 pages",
      "pdf_url": "http://arxiv.org/pdf/2406.04845v1",
      "published_date": "2024-06-07 11:19:30 UTC",
      "updated_date": "2024-06-07 11:19:30 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-18T17:30:40.200464"
    },
    {
      "arxiv_id": "2406.04841v1",
      "title": "Primitive Agentic First-Order Optimization",
      "title_zh": "翻译失败",
      "authors": [
        "R. Sala"
      ],
      "abstract": "Efficient numerical optimization methods can improve performance and reduce\nthe environmental impact of computing in many applications. This work presents\na proof-of-concept study combining primitive state representations and\nagent-environment interactions as first-order optimizers in the setting of\nbudget-limited optimization. Through reinforcement learning (RL) over a set of\ntraining instances of an optimization problem class, optimal policies for\nsequential update selection of algorithmic iteration steps are approximated in\ngenerally formulated low-dimensional partial state representations that\nconsider aspects of progress and resource use. For the investigated case\nstudies, deployment of the trained agents to unseen instances of the quadratic\noptimization problem classes outperformed conventional optimal algorithms with\noptimized hyperparameters. The results show that elementary RL methods combined\nwith succinct partial state representations can be used as heuristics to manage\ncomplexity in RL-based optimization, paving the way for agentic optimization\napproaches.",
      "tldr_zh": "这篇论文提出了一种原始代理一阶优化（Primitive Agentic First-Order Optimization）方法，通过强化学习（RL）训练代理来优化预算有限的优化问题，代理基于低维部分状态表示（如进度和资源使用）来选择算法迭代步骤。实验在二次优化问题类上显示，训练的代理在未见实例中超过了传统最优算法的表现。结果表明，基础 RL 方法结合简洁状态表示可作为有效的启发式策略，推动代理优化（Agentic Optimization）方法的发展。",
      "categories": [
        "cs.LG",
        "cs.AI",
        "cs.SY",
        "eess.SY",
        "math.OC"
      ],
      "primary_category": "cs.LG",
      "comment": "7 Pages",
      "pdf_url": "http://arxiv.org/pdf/2406.04841v1",
      "published_date": "2024-06-07 11:13:38 UTC",
      "updated_date": "2024-06-07 11:13:38 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-18T17:30:49.092831"
    },
    {
      "arxiv_id": "2406.04838v1",
      "title": "Algorithms for learning value-aligned policies considering admissibility relaxation",
      "title_zh": "考虑可采纳性松弛的学习价值对齐策略算法",
      "authors": [
        "Andrés Holgado-Sánchez",
        "Joaquín Arias",
        "Holger Billhardt",
        "Sascha Ossowski"
      ],
      "abstract": "The emerging field of \\emph{value awareness engineering} claims that software\nagents and systems should be value-aware, i.e. they must make decisions in\naccordance with human values. In this context, such agents must be capable of\nexplicitly reasoning as to how far different courses of action are aligned with\nthese values. For this purpose, values are often modelled as preferences over\nstates or actions, which are then aggregated to determine the sequences of\nactions that are maximally aligned with a certain value. Recently, additional\nvalue admissibility constraints at this level have been considered as well.\n  However, often relaxed versions of these constraints are needed, and this\nincreases considerably the complexity of computing value-aligned policies. To\nobtain efficient algorithms that make value-aligned decisions considering\nadmissibility relaxation, we propose the use of learning techniques, in\nparticular, we have used constrained reinforcement learning algorithms. In this\npaper, we present two algorithms, $\\epsilon\\text{-}ADQL$ for strategies based\non local alignment and its extension $\\epsilon\\text{-}CADQL$ for a sequence of\ndecisions. We have validated their efficiency in a water distribution problem\nin a drought scenario.",
      "tldr_zh": "这篇论文探讨了价值意识工程（value awareness engineering）中，学习考虑可接受性松弛（admissibility relaxation）的价值对齐策略（value-aligned policies）的算法，以帮助软件代理根据人类价值观做出决策。作者提出了两种基于约束强化学习（constrained reinforcement learning）的算法：ε-ADQL，用于处理基于局部对齐的策略，以及其扩展ε-CADQL，用于序列决策。实验在水资源分配问题（如干旱情景）中验证了这些算法的效率，展示了它们在复杂约束下的有效性。",
      "categories": [
        "cs.AI",
        "cs.CY",
        "cs.LG"
      ],
      "primary_category": "cs.AI",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2406.04838v1",
      "published_date": "2024-06-07 11:10:07 UTC",
      "updated_date": "2024-06-07 11:10:07 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-18T17:31:02.330774"
    },
    {
      "arxiv_id": "2406.04836v1",
      "title": "Revisiting Catastrophic Forgetting in Large Language Model Tuning",
      "title_zh": "重新审视大型语言模型微调中的灾难性遗忘",
      "authors": [
        "Hongyu Li",
        "Liang Ding",
        "Meng Fang",
        "Dacheng Tao"
      ],
      "abstract": "Catastrophic Forgetting (CF) means models forgetting previously acquired\nknowledge when learning new data. It compromises the effectiveness of large\nlanguage models (LLMs) during fine-tuning, yet the underlying causes have not\nbeen thoroughly investigated. This paper takes the first step to reveal the\ndirect link between the flatness of the model loss landscape and the extent of\nCF in the field of LLMs. Based on this, we introduce the sharpness-aware\nminimization to mitigate CF by flattening the loss landscape. Experiments on\nthree widely-used fine-tuning datasets, spanning different model scales,\ndemonstrate the effectiveness of our method in alleviating CF. Analyses show\nthat we nicely complement the existing anti-forgetting strategies, further\nenhancing the resistance of LLMs to CF.",
      "tldr_zh": "本研究重新审视了Catastrophic Forgetting (CF)在大语言模型(Large Language Models, LLMs)微调中的问题，即模型在学习新数据时会遗忘先前知识。论文首次揭示了模型损失景观的平坦度与CF程度之间的直接联系，并引入sharpness-aware minimization方法，通过平坦损失景观来缓解这一问题。在三个常用微调数据集上的实验显示，该方法在不同模型规模下有效减轻了CF，并能与现有反忘记策略互补，进一步提升LLMs对CF的抵抗力。",
      "categories": [
        "cs.CL",
        "cs.AI"
      ],
      "primary_category": "cs.CL",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2406.04836v1",
      "published_date": "2024-06-07 11:09:13 UTC",
      "updated_date": "2024-06-07 11:09:13 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-18T17:31:13.941845"
    },
    {
      "arxiv_id": "2406.04825v2",
      "title": "Graph Mining under Data scarcity",
      "title_zh": "翻译失败",
      "authors": [
        "Appan Rakaraddi",
        "Lam Siew-Kei",
        "Mahardhika Pratama",
        "Marcus de Carvalho"
      ],
      "abstract": "Multitude of deep learning models have been proposed for node classification\nin graphs. However, they tend to perform poorly under labeled-data scarcity.\nAlthough Few-shot learning for graphs has been introduced to overcome this\nproblem, the existing models are not easily adaptable for generic graph\nlearning frameworks like Graph Neural Networks (GNNs). Our work proposes an\nUncertainty Estimator framework that can be applied on top of any generic GNN\nbackbone network (which are typically designed for supervised/semi-supervised\nnode classification) to improve the node classification performance. A neural\nnetwork is used to model the Uncertainty Estimator as a probability\ndistribution rather than probabilistic discrete scalar values. We train these\nmodels under the classic episodic learning paradigm in the $n$-way, $k$-shot\nfashion, in an end-to-end setting. Our work demonstrates that implementation of\nthe uncertainty estimator on a GNN backbone network improves the classification\naccuracy under Few-shot setting without any meta-learning specific\narchitecture. We conduct experiments on multiple datasets under different\nFew-shot settings and different GNN-based backbone networks. Our method\noutperforms the baselines, which demonstrates the efficacy of the Uncertainty\nEstimator for Few-shot node classification on graphs with a GNN.",
      "tldr_zh": "该论文针对图挖掘中标签数据稀缺的问题，提出了一种Uncertainty Estimator框架，可应用于任何Graph Neural Networks (GNNs)骨干网络，以提升Few-shot节点分类性能。该框架使用神经网络将不确定性建模为概率分布，并采用经典的episodic学习范式进行n-way, k-shot端到端训练，而无需依赖特定meta-learning架构。实验结果显示，该方法在多个数据集和不同GNNs骨干网络上均优于基线模型，显著提高了Few-shot设置下的分类准确率。",
      "categories": [
        "cs.LG",
        "cs.AI"
      ],
      "primary_category": "cs.LG",
      "comment": "7 pages, 2 figures",
      "pdf_url": "http://arxiv.org/pdf/2406.04825v2",
      "published_date": "2024-06-07 10:50:03 UTC",
      "updated_date": "2024-06-11 13:33:16 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-18T17:31:27.967193"
    },
    {
      "arxiv_id": "2406.04823v2",
      "title": "BERTs are Generative In-Context Learners",
      "title_zh": "翻译失败",
      "authors": [
        "David Samuel"
      ],
      "abstract": "While in-context learning is commonly associated with causal language models,\nsuch as GPT, we demonstrate that this capability also 'emerges' in masked\nlanguage models. Through an embarrassingly simple inference technique, we\nenable an existing masked model, DeBERTa, to perform generative tasks without\nadditional training or architectural changes. Our evaluation reveals that the\nmasked and causal language models behave very differently, as they clearly\noutperform each other on different categories of tasks. These complementary\nstrengths suggest that the field's focus on causal models for in-context\nlearning may be limiting - both architectures can develop these capabilities,\nbut with distinct advantages; pointing toward promising hybrid approaches that\ncombine the strengths of both objectives.",
      "tldr_zh": "本研究发现，masked language models（如 DeBERTa）也能实现 in-context learning，而非仅限于 causal language models（如 GPT）。通过一个简单的推理技术，研究者使 DeBERTa 无需额外训练或架构修改即可执行生成任务。实验结果显示，masked models 和 causal models 在不同任务类别上表现出互补优势，前者在某些任务中更出色。作者建议探索混合方法，结合两种模型的长处，以扩展 in-context learning 的应用潜力。",
      "categories": [
        "cs.CL",
        "cs.AI"
      ],
      "primary_category": "cs.CL",
      "comment": "26 pages, NeurIPS 2024",
      "pdf_url": "http://arxiv.org/pdf/2406.04823v2",
      "published_date": "2024-06-07 10:48:45 UTC",
      "updated_date": "2024-10-31 16:48:51 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-18T17:31:37.355010"
    },
    {
      "arxiv_id": "2406.04820v1",
      "title": "Navigating Efficiency in MobileViT through Gaussian Process on Global Architecture Factors",
      "title_zh": "翻译失败",
      "authors": [
        "Ke Meng",
        "Kai Chen"
      ],
      "abstract": "Numerous techniques have been meticulously designed to achieve optimal\narchitectures for convolutional neural networks (CNNs), yet a comparable focus\non vision transformers (ViTs) has been somewhat lacking. Despite the remarkable\nsuccess of ViTs in various vision tasks, their heavyweight nature presents\nchallenges of computational costs. In this paper, we leverage the Gaussian\nprocess to systematically explore the nonlinear and uncertain relationship\nbetween performance and global architecture factors of MobileViT, such as\nresolution, width, and depth including the depth of in-verted residual blocks\nand the depth of ViT blocks, and joint factors including resolution-depth and\nresolution-width. We present design principles twisting magic 4D cube of the\nglobal architecture factors that minimize model sizes and computational costs\nwith higher model accuracy. We introduce a formula for downsizing architectures\nby iteratively deriving smaller MobileViT V2, all while adhering to a specified\nconstraint of multiply-accumulate operations (MACs). Experiment results show\nthat our formula significantly outperforms CNNs and mobile ViTs across\ndiversified datasets",
      "tldr_zh": "这篇论文使用 Gaussian Process 系统地探索 MobileViT 的全局架构因素（如 resolution、width 和 depth）与性能之间的非线性关系，旨在优化视觉Transformer（ViTs）的效率。研究者提出了设计原则和一个公式，通过调整这些因素并迭代缩小 MobileViT V2 的架构，同时满足乘-累加操作（MACs）的约束，以最小化模型大小和计算成本。实验结果显示，该方法在多种数据集上显著优于 CNNs 和其他 mobile ViTs，在准确率和效率方面实现了显著提升。",
      "categories": [
        "cs.CV",
        "cs.AI"
      ],
      "primary_category": "cs.CV",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2406.04820v1",
      "published_date": "2024-06-07 10:41:24 UTC",
      "updated_date": "2024-06-07 10:41:24 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-18T17:31:52.193862"
    },
    {
      "arxiv_id": "2406.04815v3",
      "title": "Skill-aware Mutual Information Optimisation for Generalisation in Reinforcement Learning",
      "title_zh": "技能感知互信息优化用于强化学习中的泛化",
      "authors": [
        "Xuehui Yu",
        "Mhairi Dunion",
        "Xin Li",
        "Stefano V. Albrecht"
      ],
      "abstract": "Meta-Reinforcement Learning (Meta-RL) agents can struggle to operate across\ntasks with varying environmental features that require different optimal skills\n(i.e., different modes of behaviour). Using context encoders based on\ncontrastive learning to enhance the generalisability of Meta-RL agents is now\nwidely studied but faces challenges such as the requirement for a large sample\nsize, also referred to as the $\\log$-$K$ curse. To improve RL generalisation to\ndifferent tasks, we first introduce Skill-aware Mutual Information (SaMI), an\noptimisation objective that aids in distinguishing context embeddings according\nto skills, thereby equipping RL agents with the ability to identify and execute\ndifferent skills across tasks. We then propose Skill-aware Noise Contrastive\nEstimation (SaNCE), a $K$-sample estimator used to optimise the SaMI objective.\nWe provide a framework for equipping an RL agent with SaNCE in practice and\nconduct experimental validation on modified MuJoCo and Panda-gym benchmarks. We\nempirically find that RL agents that learn by maximising SaMI achieve\nsubstantially improved zero-shot generalisation to unseen tasks. Additionally,\nthe context encoder trained with SaNCE demonstrates greater robustness to a\nreduction in the number of available samples, thus possessing the potential to\novercome the $\\log$-$K$ curse.",
      "tldr_zh": "这篇论文针对 Meta-Reinforcement Learning (Meta-RL) 代理在处理需要不同技能的任务时面临的泛化挑战，引入了 Skill-aware Mutual Information (SaMI) 优化目标，以帮助区分上下文嵌入并提升代理识别和执行各种技能的能力。作者提出了 Skill-aware Noise Contrastive Estimation (SaNCE)，一个高效的 K-样本估计器，用于优化 SaMI，并在实际框架中整合 RL 代理。实验在修改后的 MuJoCo 和 Panda-gym 基准上验证，结果显示，通过最大化 SaMI，RL 代理实现了显著的 zero-shot generalisation 改善，并对样本数量减少更具鲁棒性，从而缓解了 log-K curse 的问题。",
      "categories": [
        "cs.LG",
        "cs.AI",
        "cs.RO"
      ],
      "primary_category": "cs.LG",
      "comment": "The Thirty-eighth Annual Conference on Neural Information Processing\n  Systems (NeurIPS), 2024",
      "pdf_url": "http://arxiv.org/pdf/2406.04815v3",
      "published_date": "2024-06-07 10:35:29 UTC",
      "updated_date": "2024-11-06 13:24:41 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-18T17:32:05.850552"
    },
    {
      "arxiv_id": "2406.10245v1",
      "title": "On conceptualisation and an overview of learning path recommender systems in e-learning",
      "title_zh": "翻译失败",
      "authors": [
        "A. Fuster-López",
        "J. M. Cruz",
        "P. Guerrero-García",
        "E. M. T. Hendrix",
        "A. Košir",
        "I. Nowak",
        "L. Oneto",
        "S. Sirmakessis",
        "M. F. Pacheco",
        "F. P. Fernandes",
        "A. I. Pereira"
      ],
      "abstract": "The use of e-learning systems has a long tradition, where students can study\nonline helped by a system. In this context, the use of recommender systems is\nrelatively new. In our research project, we investigated various ways to create\na recommender system. They all aim at facilitating the learning and\nunderstanding of a student. We present a common concept of the learning path\nand its learning indicators and embed 5 different recommenders in this context.",
      "tldr_zh": "这篇论文探讨了 e-learning 中的学习路径推荐系统（learning path recommender systems）的概念和概述，旨在帮助学生在线学习和理解。研究项目调查了创建这些系统的多种方法，并定义了学习路径（learning path）和其学习指标（learning indicators）。最终，他们将 5 种不同的推荐系统（recommenders）整合到这一框架中，以提升学生的学习体验。",
      "categories": [
        "cs.IR",
        "cs.AI",
        "cs.LG"
      ],
      "primary_category": "cs.IR",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2406.10245v1",
      "published_date": "2024-06-07 10:30:43 UTC",
      "updated_date": "2024-06-07 10:30:43 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-18T17:32:15.961510"
    },
    {
      "arxiv_id": "2406.04812v1",
      "title": "Generating Piano Practice Policy with a Gaussian Process",
      "title_zh": "翻译失败",
      "authors": [
        "Alexandra Moringen",
        "Elad Vromen",
        "Helge Ritter",
        "Jason Friedman"
      ],
      "abstract": "A typical process of learning to play a piece on a piano consists of a\nprogression through a series of practice units that focus on individual\ndimensions of the skill, the so-called practice modes. Practice modes in\nlearning to play music comprise a particularly large set of possibilities, such\nas hand coordination, posture, articulation, ability to read a music score,\ncorrect timing or pitch, etc. Self-guided practice is known to be suboptimal,\nand a model that schedules optimal practice to maximize a learner's progress\nstill does not exist. Because we each learn differently and there are many\nchoices for possible piano practice tasks and methods, the set of practice\nmodes should be dynamically adapted to the human learner, a process typically\nguided by a teacher. However, having a human teacher guide individual practice\nis not always feasible since it is time-consuming, expensive, and often\nunavailable. In this work, we present a modeling framework to guide the human\nlearner through the learning process by choosing the practice modes generated\nby a policy model. To this end, we present a computational architecture\nbuilding on a Gaussian process that incorporates 1) the learner state, 2) a\npolicy that selects a suitable practice mode, 3) performance evaluation, and 4)\nexpert knowledge. The proposed policy model is trained to approximate the\nexpert-learner interaction during a practice session. In our future work, we\nwill test different Bayesian optimization techniques, e.g., different\nacquisition functions, and evaluate their effect on the learning progress.",
      "tldr_zh": "本研究针对钢琴学习中练习模式的动态选择问题，提出一个基于 Gaussian Process 的建模框架，以优化学习者的练习策略。该框架整合学习者状态、一个选择合适练习模式的政策模型、性能评估以及专家知识，旨在模拟专家指导并最大化学习进度。通过训练政策模型来近似专家-学习者互动，该方法解决了自学练习的不足。未来工作将探索不同贝叶斯优化技术（如各种acquisition functions）及其对学习进度的影响。",
      "categories": [
        "cs.LG",
        "cs.AI"
      ],
      "primary_category": "cs.LG",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2406.04812v1",
      "published_date": "2024-06-07 10:27:07 UTC",
      "updated_date": "2024-06-07 10:27:07 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-18T17:32:27.504059"
    },
    {
      "arxiv_id": "2406.04809v5",
      "title": "A Survey of Fragile Model Watermarking",
      "title_zh": "翻译失败",
      "authors": [
        "Zhenzhe Gao",
        "Yu Cheng",
        "Zhaoxia Yin"
      ],
      "abstract": "Model fragile watermarking, inspired by both the field of adversarial attacks\non neural networks and traditional multimedia fragile watermarking, has\ngradually emerged as a potent tool for detecting tampering, and has witnessed\nrapid development in recent years. Unlike robust watermarks, which are widely\nused for identifying model copyrights, fragile watermarks for models are\ndesigned to identify whether models have been subjected to unexpected\nalterations such as backdoors, poisoning, compression, among others. These\nalterations can pose unknown risks to model users, such as misidentifying stop\nsigns as speed limit signs in classic autonomous driving scenarios. This paper\nprovides an overview of the relevant work in the field of model fragile\nwatermarking since its inception, categorizing them and revealing the\ndevelopmental trajectory of the field, thus offering a comprehensive survey for\nfuture endeavors in model fragile watermarking.",
      "tldr_zh": "这篇论文对fragile model watermarking进行了全面调查，该技术借鉴对抗攻击和多媒体脆弱水印，旨在检测神经网络模型的篡改风险，如后门注入、数据投毒或压缩，以防范潜在危害（例如自动驾驶中错误识别交通标志）。与robust watermarks专注于模型版权保护不同，fragile watermarks更侧重于识别意外改动。论文对该领域的相关工作进行了分类和分析，揭示其发展轨迹，为未来的研究提供指导。",
      "categories": [
        "cs.CR",
        "cs.AI"
      ],
      "primary_category": "cs.CR",
      "comment": "There will be more revisions to the wording and image additions, and\n  we hope to withdraw the previous version",
      "pdf_url": "http://arxiv.org/pdf/2406.04809v5",
      "published_date": "2024-06-07 10:23:25 UTC",
      "updated_date": "2024-08-14 09:02:33 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-18T17:32:38.871954"
    },
    {
      "arxiv_id": "2406.12896v1",
      "title": "Leveraging Pedagogical Theories to Understand Student Learning Process with Graph-based Reasonable Knowledge Tracing",
      "title_zh": "利用教育学理论，通过基于图的合理知识追踪理解学生的学习过程",
      "authors": [
        "Jiajun Cui",
        "Hong Qian",
        "Bo Jiang",
        "Wei Zhang"
      ],
      "abstract": "Knowledge tracing (KT) is a crucial task in intelligent education, focusing\non predicting students' performance on given questions to trace their evolving\nknowledge. The advancement of deep learning in this field has led to\ndeep-learning knowledge tracing (DLKT) models that prioritize high predictive\naccuracy. However, many existing DLKT methods overlook the fundamental goal of\ntracking students' dynamical knowledge mastery. These models do not explicitly\nmodel knowledge mastery tracing processes or yield unreasonable results that\neducators find difficulty to comprehend and apply in real teaching scenarios.\nIn response, our research conducts a preliminary analysis of mainstream KT\napproaches to highlight and explain such unreasonableness. We introduce GRKT, a\ngraph-based reasonable knowledge tracing method to address these issues. By\nleveraging graph neural networks, our approach delves into the mutual\ninfluences of knowledge concepts, offering a more accurate representation of\nhow the knowledge mastery evolves throughout the learning process.\nAdditionally, we propose a fine-grained and psychological three-stage modeling\nprocess as knowledge retrieval, memory strengthening, and knowledge\nlearning/forgetting, to conduct a more reasonable knowledge tracing process.\nComprehensive experiments demonstrate that GRKT outperforms eleven baselines\nacross three datasets, not only enhancing predictive accuracy but also\ngenerating more reasonable knowledge tracing results. This makes our model a\npromising advancement for practical implementation in educational settings. The\nsource code is available at https://github.com/JJCui96/GRKT.",
      "tldr_zh": "该研究针对知识追踪（KT）领域的不足，指出现有深度学习知识追踪（DLKT）模型虽注重预测准确性，但忽略了学生知识掌握的动态过程，导致结果不合理。作者提出 GRKT（Graph-based Reasonable Knowledge Tracing）方法，利用图神经网络（Graph Neural Networks）建模知识概念间的相互影响，并引入细粒度的三阶段心理模型（知识检索、记忆强化和知识学习/遗忘），以实现更合理的知识追踪。实验结果显示，GRKT 在三个数据集上优于 11 个基线模型，不仅提升了预测准确性，还为教育实践提供了更可解释的应用潜力。",
      "categories": [
        "cs.AI",
        "cs.CY",
        "cs.LG"
      ],
      "primary_category": "cs.AI",
      "comment": "Preprint, accepted to appear in SIGKDD 2024, 12 pages. The source\n  code is available at https://github.com/JJCui96/GRKT. Keywords: interpretable\n  knowledge tracing, student behavior modeling, intelligence education",
      "pdf_url": "http://arxiv.org/pdf/2406.12896v1",
      "published_date": "2024-06-07 10:14:30 UTC",
      "updated_date": "2024-06-07 10:14:30 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-18T17:32:53.677721"
    },
    {
      "arxiv_id": "2406.04806v4",
      "title": "Streaming Diffusion Policy: Fast Policy Synthesis with Variable Noise Diffusion Models",
      "title_zh": "翻译失败",
      "authors": [
        "Sigmund H. Høeg",
        "Yilun Du",
        "Olav Egeland"
      ],
      "abstract": "Diffusion models have seen rapid adoption in robotic imitation learning,\nenabling autonomous execution of complex dexterous tasks. However, action\nsynthesis is often slow, requiring many steps of iterative denoising, limiting\nthe extent to which models can be used in tasks that require fast reactive\npolicies. To sidestep this, recent works have explored how the distillation of\nthe diffusion process can be used to accelerate policy synthesis. However,\ndistillation is computationally expensive and can hurt both the accuracy and\ndiversity of synthesized actions. We propose SDP (Streaming Diffusion Policy),\nan alternative method to accelerate policy synthesis, leveraging the insight\nthat generating a partially denoised action trajectory is substantially faster\nthan a full output action trajectory. At each observation, our approach outputs\na partially denoised action trajectory with variable levels of noise\ncorruption, where the immediate action to execute is noise-free, with\nsubsequent actions having increasing levels of noise and uncertainty. The\npartially denoised action trajectory for a new observation can then be quickly\ngenerated by applying a few steps of denoising to the previously predicted\nnoisy action trajectory (rolled over by one timestep). We illustrate the\nefficacy of this approach, dramatically speeding up policy synthesis while\npreserving performance across both simulated and real-world settings.",
      "tldr_zh": "扩散模型在机器人模仿学习中被广泛用于执行复杂任务，但其行动合成过程缓慢，需要多次迭代去噪，限制了在快速反应任务中的应用。论文提出 SDP（Streaming Diffusion Policy），一种新方法，通过生成部分去噪的行动轨迹来加速策略合成：每个观察输出一个可变噪声轨迹，其中立即行动无噪声，随后的行动噪声渐增，并利用前一个轨迹快速更新。实验结果显示，SDP 显著提高了策略合成的速度，同时在模拟和真实环境中保持了性能和多样性。",
      "categories": [
        "cs.RO",
        "cs.AI"
      ],
      "primary_category": "cs.RO",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2406.04806v4",
      "published_date": "2024-06-07 10:13:44 UTC",
      "updated_date": "2024-10-11 16:04:49 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-18T17:33:04.776132"
    },
    {
      "arxiv_id": "2406.04800v1",
      "title": "Zero, Finite, and Infinite Belief History of Theory of Mind Reasoning in Large Language Models",
      "title_zh": "翻译失败",
      "authors": [
        "Weizhi Tang",
        "Vaishak Belle"
      ],
      "abstract": "Large Language Models (LLMs) have recently shown a promise and emergence of\nTheory of Mind (ToM) ability and even outperform humans in certain ToM tasks.\nTo evaluate and extend the boundaries of the ToM reasoning ability of LLMs, we\npropose a novel concept, taxonomy, and framework, the ToM reasoning with Zero,\nFinite, and Infinite Belief History and develop a multi-round text-based game,\ncalled $\\textit{Pick the Right Stuff}$, as a benchmark. We have evaluated six\nLLMs with this game and found their performance on Zero Belief History is\nconsistently better than on Finite Belief History. In addition, we have found\ntwo of the models with small parameter sizes outperform all the evaluated\nmodels with large parameter sizes. We expect this work to pave the way for\nfuture ToM benchmark development and also for the promotion and development of\nmore complex AI agents or systems which are required to be equipped with more\ncomplex ToM reasoning ability.",
      "tldr_zh": "该研究评估了大型语言模型（LLMs）在理论心智（Theory of Mind, ToM）推理能力上的表现，提出一个新概念和框架，包括 Zero Belief History、Finite Belief History 和 Infinite Belief History 的分类。研究开发了一个多轮文本游戏基准——Pick the Right Stuff——用于测试 LLMs 的 ToM 推理。实验结果显示，六种 LLMs 在 Zero Belief History 上的表现优于 Finite Belief History，且部分小参数模型超过了大型模型的表现。该工作有望推动未来 ToM 基准的开发，并促进更复杂 AI 代理系统的构建，这些系统需要更高级的 ToM 推理能力。",
      "categories": [
        "cs.AI",
        "cs.CL"
      ],
      "primary_category": "cs.AI",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2406.04800v1",
      "published_date": "2024-06-07 10:04:39 UTC",
      "updated_date": "2024-06-07 10:04:39 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-18T17:33:17.122289"
    },
    {
      "arxiv_id": "2406.04793v2",
      "title": "Learning-Augmented Priority Queues",
      "title_zh": "学习增强优先级队列",
      "authors": [
        "Ziyad Benomar",
        "Christian Coester"
      ],
      "abstract": "Priority queues are one of the most fundamental and widely used data\nstructures in computer science. Their primary objective is to efficiently\nsupport the insertion of new elements with assigned priorities and the\nextraction of the highest priority element. In this study, we investigate the\ndesign of priority queues within the learning-augmented framework, where\nalgorithms use potentially inaccurate predictions to enhance their worst-case\nperformance. We examine three prediction models spanning different use cases,\nand show how the predictions can be leveraged to enhance the performance of\npriority queue operations. Moreover, we demonstrate the optimality of our\nsolution and discuss some possible applications.",
      "tldr_zh": "本论文探讨了在学习增强框架(learning-augmented framework)下设计priority queues，以利用潜在不准确的预测来改善其最坏情况性能。研究考察了三种预测模型，并展示了如何通过这些预测提升priority queues的插入和提取操作效率。具体而言，论文证明了所提解决方案的优越性(optimality)，并讨论了其在计算机科学领域的可能应用。",
      "categories": [
        "cs.DS",
        "cs.AI",
        "cs.LG"
      ],
      "primary_category": "cs.DS",
      "comment": "Accepted as a conference paper at NeurIPS 2024",
      "pdf_url": "http://arxiv.org/pdf/2406.04793v2",
      "published_date": "2024-06-07 09:40:09 UTC",
      "updated_date": "2024-11-17 21:13:54 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-18T17:33:29.751698"
    },
    {
      "arxiv_id": "2406.04784v1",
      "title": "SelfGoal: Your Language Agents Already Know How to Achieve High-level Goals",
      "title_zh": "SelfGoal：你的语言代理已经知道如何实现高层目标",
      "authors": [
        "Ruihan Yang",
        "Jiangjie Chen",
        "Yikai Zhang",
        "Siyu Yuan",
        "Aili Chen",
        "Kyle Richardson",
        "Yanghua Xiao",
        "Deqing Yang"
      ],
      "abstract": "Language agents powered by large language models (LLMs) are increasingly\nvaluable as decision-making tools in domains such as gaming and programming.\nHowever, these agents often face challenges in achieving high-level goals\nwithout detailed instructions and in adapting to environments where feedback is\ndelayed. In this paper, we present SelfGoal, a novel automatic approach\ndesigned to enhance agents' capabilities to achieve high-level goals with\nlimited human prior and environmental feedback. The core concept of SelfGoal\ninvolves adaptively breaking down a high-level goal into a tree structure of\nmore practical subgoals during the interaction with environments while\nidentifying the most useful subgoals and progressively updating this structure.\nExperimental results demonstrate that SelfGoal significantly enhances the\nperformance of language agents across various tasks, including competitive,\ncooperative, and deferred feedback environments. Project page:\nhttps://selfgoal-agent.github.io.",
      "tldr_zh": "本文提出 SelfGoal，一种新颖的自动方法，用于提升基于大型语言模型 (LLMs) 的语言代理在有限人类先验和环境反馈下实现高水平 goals 的能力。SelfGoal 的核心机制是自适应地将高水平 goals 分解成树状结构的实用 subgoals，并在与环境互动过程中识别和更新最有效的子目标。实验结果表明，该方法显著提升了代理在竞争性、合作性和延迟反馈环境中的性能，为语言代理在决策任务中的应用提供了重要改进。",
      "categories": [
        "cs.CL",
        "cs.AI"
      ],
      "primary_category": "cs.CL",
      "comment": "Preprint",
      "pdf_url": "http://arxiv.org/pdf/2406.04784v1",
      "published_date": "2024-06-07 09:32:03 UTC",
      "updated_date": "2024-06-07 09:32:03 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-18T17:33:40.442709"
    },
    {
      "arxiv_id": "2406.04780v1",
      "title": "Software Engineering for Collective Cyber-Physical Ecosystems",
      "title_zh": "翻译失败",
      "authors": [
        "Roberto Casadei",
        "Gianluca Aguzzi",
        "Giorgio Audrito",
        "Ferruccio Damiani",
        "Danilo Pianini",
        "Giordano Scarso",
        "Gianluca Torta",
        "Mirko Viroli"
      ],
      "abstract": "Today's distributed and pervasive computing addresses large-scale\ncyber-physical ecosystems, characterised by dense and large networks of devices\ncapable of computation, communication and interaction with the environment and\npeople. While most research focusses on treating these systems as \"composites\"\n(i.e., heterogeneous functional complexes), recent developments in fields such\nas self-organising systems and swarm robotics have opened up a complementary\nperspective: treating systems as \"collectives\" (i.e., uniform, collaborative,\nand self-organising groups of entities). This article explores the motivations,\nstate of the art, and implications of this \"collective computing paradigm\" in\nsoftware engineering, discusses its peculiar challenges, and outlines a path\nfor future research, touching on aspects such as macroprogramming, collective\nintelligence, self-adaptive middleware, learning, synthesis, and\nexperimentation of collective behaviour.",
      "tldr_zh": "该论文探讨了软件工程在集体网络物理生态系统（collective cyber-physical ecosystems）中的应用，强调将这些系统视为协作自组织的“collectives”（即统一、协作的实体群组），而非传统的“composites”（异构功能复合体）。文章分析了集体计算范式（collective computing paradigm）的动机、现状和影响，讨论了其独特挑战，如自适应和协作行为的管理。未来研究路径包括macroprogramming、collective intelligence、self-adaptive middleware、learning、synthesis和experimentation of collective behaviour，以推动该领域的创新和发展。",
      "categories": [
        "cs.SE",
        "cs.AI",
        "cs.DC",
        "cs.MA",
        "cs.SY",
        "eess.SY"
      ],
      "primary_category": "cs.SE",
      "comment": "12 pages, 2 figures, Accepted for presentation at the International\n  Workshop on Software Engineering in 2030, November 2024, Puerto Galinas\n  (Brazil)",
      "pdf_url": "http://arxiv.org/pdf/2406.04780v1",
      "published_date": "2024-06-07 09:28:22 UTC",
      "updated_date": "2024-06-07 09:28:22 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-18T17:33:54.627618"
    },
    {
      "arxiv_id": "2406.04779v1",
      "title": "Mobile Network Configuration Recommendation using Deep Generative Graph Neural Network",
      "title_zh": "翻译失败",
      "authors": [
        "Shirwan Piroti",
        "Ashima Chawla",
        "Tahar Zanouda"
      ],
      "abstract": "There are vast number of configurable parameters in a Radio Access Telecom\nNetwork. A significant amount of these parameters is configured by Radio Node\nor cell based on their deployment setting. Traditional methods rely on domain\nknowledge for individual parameter configuration, often leading to sub-optimal\nresults. To improve this, a framework using a Deep Generative Graph Neural\nNetwork (GNN) is proposed. It encodes the network into a graph, extracts\nsubgraphs for each RAN node, and employs a Siamese GNN (S-GNN) to learn\nembeddings. The framework recommends configuration parameters for a multitude\nof parameters and detects misconfigurations, handling both network expansion\nand existing cell reconfiguration. Tested on real-world data, the model\nsurpasses baselines, demonstrating accuracy, generalizability, and robustness\nagainst concept drift.",
      "tldr_zh": "这篇论文针对电信网络中大量可配置参数的问题，提出了一种基于 Deep Generative Graph Neural Network 的框架，以解决传统依赖领域知识的次优配置方法。该框架将网络编码为图，提取每个 RAN 节点的子图，并使用 Siamese GNN 学习嵌入，从而推荐配置参数、检测误配置，并支持网络扩展和现有单元重新配置。在真实世界数据上的实验显示，该模型在准确性、可泛化性和对概念漂移的鲁棒性方面均超越基线模型。",
      "categories": [
        "cs.LG",
        "cs.AI",
        "cs.NI"
      ],
      "primary_category": "cs.LG",
      "comment": "4 pages, 4 figures",
      "pdf_url": "http://arxiv.org/pdf/2406.04779v1",
      "published_date": "2024-06-07 09:28:18 UTC",
      "updated_date": "2024-06-07 09:28:18 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-18T17:34:08.279660"
    },
    {
      "arxiv_id": "2406.04776v1",
      "title": "OFDM-Standard Compatible SC-NOFS Waveforms for Low-Latency and Jitter-Tolerance Industrial IoT Communications",
      "title_zh": "翻译失败",
      "authors": [
        "Tongyang Xu",
        "Shuangyang Li",
        "Jinhong Yuan"
      ],
      "abstract": "Traditional communications focus on regular and orthogonal signal waveforms\nfor simplified signal processing and improved spectral efficiency. In contrast,\nthe next-generation communications would aim for irregular and non-orthogonal\nsignal waveforms to introduce new capabilities. This work proposes a spectrally\nefficient irregular Sinc (irSinc) shaping technique, revisiting the traditional\nSinc back to 1924, with the aim of enhancing performance in industrial Internet\nof things (IIoT). In time-critical IIoT applications, low-latency and\ntime-jitter tolerance are two critical factors that significantly impact the\nperformance and reliability. Recognizing the inevitability of latency and\njitter in practice, this work aims to propose a waveform technique to mitigate\nthese effects via reducing latency and enhancing the system robustness under\ntime jitter effects. The utilization of irSinc yields a signal with increased\nspectral efficiency without sacrificing error performance. Integrating the\nirSinc in a two-stage framework, a single-carrier non-orthogonal frequency\nshaping (SC-NOFS) waveform is developed, showcasing perfect compatibility with\n5G standards, enabling the direct integration of irSinc in existing industrial\nIoT setups. Through 5G standard signal configuration, our signal achieves\nfaster data transmission within the same spectral bandwidth. Hardware\nexperiments validate an 18% saving in timing resources, leading to either\nreduced latency or enhanced jitter tolerance.",
      "tldr_zh": "这篇论文提出了一种光谱高效的不规则 Sinc (irSinc) 整形技术，旨在解决工业物联网 (IIoT) 中的低延迟和时间抖动容忍问题，与传统正交信号波形形成对比。\n通过将 irSinc 整合到两阶段框架中，开发了单载波非正交频率整形 (SC-NOFS) 波形，该波形与 OFDM 标准完全兼容，便于直接应用于现有 IIoT 系统，实现相同光谱带宽内的更快数据传输。\n硬件实验验证了该技术节省了 18% 的定时资源，从而显著降低延迟并提升系统对时间抖动的鲁棒性。",
      "categories": [
        "eess.SP",
        "cs.AI"
      ],
      "primary_category": "eess.SP",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2406.04776v1",
      "published_date": "2024-06-07 09:20:30 UTC",
      "updated_date": "2024-06-07 09:20:30 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-18T17:34:22.389735"
    },
    {
      "arxiv_id": "2406.04772v3",
      "title": "REP: Resource-Efficient Prompting for Rehearsal-Free Continual Learning",
      "title_zh": "翻译失败",
      "authors": [
        "Sungho Jeon",
        "Xinyue Ma",
        "Kwang In Kim",
        "Myeongjae Jeon"
      ],
      "abstract": "Recent rehearsal-free methods, guided by prompts, excel in vision-related\ncontinual learning (CL) with drifting data but lack resource efficiency, making\nreal-world deployment challenging. In this paper, we introduce\nResource-Efficient Prompting (REP), which improves the computational and memory\nefficiency of prompt-based rehearsal-free methods while minimizing accuracy\ntrade-offs. Our approach employs swift prompt selection to refine input data\nusing a carefully provisioned model and introduces adaptive token merging\n(AToM) and layer dropping (ALD) for efficient prompt updates. AToM and ALD\nselectively skip data and model layers while preserving task-specific features\nduring new-task learning. Extensive experiments on multiple image\nclassification datasets demonstrates REP's superior resource efficiency over\nstate-of-the-art ViT- and CNN-based methods.",
      "tldr_zh": "该论文提出 Resource-Efficient Prompting (REP)，一种针对无排练连续学习 (CL) 的方法，旨在提升计算和内存效率，同时减少准确性损失，以解决现有视觉相关 CL 方法的资源消耗问题。REP 通过 swift prompt selection 精炼输入数据，以及 adaptive token merging (AToM) 和 layer dropping (ALD) 来选择性地跳过数据和模型层，同时保留任务特定特征。实验结果显示，在多个图像分类数据集上，REP 比最先进的 ViT 和 CNN 方法表现出更高的资源效率。",
      "categories": [
        "cs.LG",
        "cs.AI",
        "cs.CV"
      ],
      "primary_category": "cs.LG",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2406.04772v3",
      "published_date": "2024-06-07 09:17:33 UTC",
      "updated_date": "2025-02-17 03:10:52 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-18T17:34:31.422759"
    },
    {
      "arxiv_id": "2406.04770v2",
      "title": "WildBench: Benchmarking LLMs with Challenging Tasks from Real Users in the Wild",
      "title_zh": "翻译失败",
      "authors": [
        "Bill Yuchen Lin",
        "Yuntian Deng",
        "Khyathi Chandu",
        "Faeze Brahman",
        "Abhilasha Ravichander",
        "Valentina Pyatkin",
        "Nouha Dziri",
        "Ronan Le Bras",
        "Yejin Choi"
      ],
      "abstract": "We introduce WildBench, an automated evaluation framework designed to\nbenchmark large language models (LLMs) using challenging, real-world user\nqueries. WildBench consists of 1,024 tasks carefully selected from over one\nmillion human-chatbot conversation logs. For automated evaluation with\nWildBench, we have developed two metrics, WB-Reward and WB-Score, which are\ncomputable using advanced LLMs such as GPT-4-turbo. WildBench evaluation uses\ntask-specific checklists to evaluate model outputs systematically and provides\nstructured explanations that justify the scores and comparisons, resulting in\nmore reliable and interpretable automatic judgments. WB-Reward employs\nfine-grained pairwise comparisons between model responses, generating five\npotential outcomes: much better, slightly better, slightly worse, much worse,\nor a tie. Unlike previous evaluations that employed a single baseline model, we\nselected three baseline models at varying performance levels to ensure a\ncomprehensive pairwise evaluation. Additionally, we propose a simple method to\nmitigate length bias, by converting outcomes of ``slightly better/worse'' to\n``tie'' if the winner response exceeds the loser one by more than $K$\ncharacters. WB-Score evaluates the quality of model outputs individually,\nmaking it a fast and cost-efficient evaluation metric. WildBench results\ndemonstrate a strong correlation with the human-voted Elo ratings from Chatbot\nArena on hard tasks. Specifically, WB-Reward achieves a Pearson correlation of\n0.98 with top-ranking models. Additionally, WB-Score reaches 0.95, surpassing\nboth ArenaHard's 0.91 and AlpacaEval2.0's 0.89 for length-controlled win rates,\nas well as the 0.87 for regular win rates.",
      "tldr_zh": "本研究引入了 WildBench，一个自动化评估框架，用于基准测试大型语言模型 (LLMs)，基于从超过一百万真实用户对话日志中挑选的1,024个挑战性任务。框架开发了两个指标：WB-Reward 通过细粒度成对比较（包括much better等五种结果）和三个不同性能基线模型来评估模型输出，同时采用方法缓解长度偏差；WB-Score 则快速评估单个输出质量。实验结果显示，WildBench 与人类投票的 Elo 评级高度相关，WB-Reward 的 Pearson 相关系数达0.98，优于现有基准。",
      "categories": [
        "cs.CL",
        "cs.AI"
      ],
      "primary_category": "cs.CL",
      "comment": "Link: https://hf.co/spaces/allenai/WildBench",
      "pdf_url": "http://arxiv.org/pdf/2406.04770v2",
      "published_date": "2024-06-07 09:15:44 UTC",
      "updated_date": "2024-10-05 22:39:51 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-18T17:34:43.558844"
    },
    {
      "arxiv_id": "2406.04755v4",
      "title": "LLM Whisperer: An Inconspicuous Attack to Bias LLM Responses",
      "title_zh": "LLM Whisperer：一种不起眼的攻击以偏置LLM",
      "authors": [
        "Weiran Lin",
        "Anna Gerchanovsky",
        "Omer Akgul",
        "Lujo Bauer",
        "Matt Fredrikson",
        "Zifan Wang"
      ],
      "abstract": "Writing effective prompts for large language models (LLM) can be unintuitive\nand burdensome. In response, services that optimize or suggest prompts have\nemerged. While such services can reduce user effort, they also introduce a\nrisk: the prompt provider can subtly manipulate prompts to produce heavily\nbiased LLM responses. In this work, we show that subtle synonym replacements in\nprompts can increase the likelihood (by a difference up to 78%) that LLMs\nmention a target concept (e.g., a brand, political party, nation). We\nsubstantiate our observations through a user study, showing that our\nadversarially perturbed prompts 1) are indistinguishable from unaltered prompts\nby humans, 2) push LLMs to recommend target concepts more often, and 3) make\nusers more likely to notice target concepts, all without arousing suspicion.\nThe practicality of this attack has the potential to undermine user autonomy.\nAmong other measures, we recommend implementing warnings against using prompts\nfrom untrusted parties.",
      "tldr_zh": "这篇论文介绍了“LLM Whisperer”，一种隐蔽攻击方法，通过在提示中进行细微的同义词替换来偏置LLM的响应，从而增加目标概念（如品牌或政治党派）的提及概率（最高可达78%）。研究通过用户实验证明，这些修改的提示对人类不可分辨，能够让LLM更频繁推荐目标概念，并使用户更可能注意到这些概念，而不引起怀疑。论文的核心发现是，这种攻击潜在地破坏了用户自治，并建议实施警告措施来防范使用不受信任的提示来源。",
      "categories": [
        "cs.CR",
        "cs.AI",
        "cs.HC",
        "cs.LG"
      ],
      "primary_category": "cs.CR",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2406.04755v4",
      "published_date": "2024-06-07 08:54:55 UTC",
      "updated_date": "2025-02-28 14:41:16 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-18T17:34:54.146939"
    },
    {
      "arxiv_id": "2406.04746v2",
      "title": "PQPP: A Joint Benchmark for Text-to-Image Prompt and Query Performance Prediction",
      "title_zh": "PQPP：文本到图像提示",
      "authors": [
        "Eduard Poesina",
        "Adriana Valentina Costache",
        "Adrian-Gabriel Chifu",
        "Josiane Mothe",
        "Radu Tudor Ionescu"
      ],
      "abstract": "Text-to-image generation has recently emerged as a viable alternative to\ntext-to-image retrieval, driven by the visually impressive results of\ngenerative diffusion models. Although query performance prediction is an active\nresearch topic in information retrieval, to the best of our knowledge, there is\nno prior study that analyzes the difficulty of queries (referred to as prompts)\nin text-to-image generation, based on human judgments. To this end, we\nintroduce the first dataset of prompts which are manually annotated in terms of\nimage generation performance. Additionally, we extend these evaluations to\ntext-to-image retrieval by collecting manual annotations that represent\nretrieval performance. We thus establish the first joint benchmark for prompt\nand query performance prediction (PQPP) across both tasks, comprising over 10K\nqueries. Our benchmark enables (i) the comparative assessment of prompt/query\ndifficulty in both image generation and image retrieval, and (ii) the\nevaluation of prompt/query performance predictors addressing both generation\nand retrieval. We evaluate several pre- and post-generation/retrieval\nperformance predictors, thus providing competitive baselines for future\nresearch. Our benchmark and code are publicly available at\nhttps://github.com/Eduard6421/PQPP.",
      "tldr_zh": "这篇论文引入了PQPP基准，这是一个联合基准，用于评估文本到图像生成和检索中的提示（prompt）和查询性能预测（query performance prediction）。他们构建了第一个基于人类判断的手动标注数据集，包含超过10K的查询，并扩展评估到图像生成和检索任务，以比较查询难度。实验评估了多种预生成/检索和后生成/检索的性能预测器，提供竞争性基线，促进未来研究。该基准及其代码已在GitHub上公开可用。",
      "categories": [
        "cs.CV",
        "cs.AI",
        "cs.CL",
        "cs.LG"
      ],
      "primary_category": "cs.CV",
      "comment": "Accepted at CVPR 2025",
      "pdf_url": "http://arxiv.org/pdf/2406.04746v2",
      "published_date": "2024-06-07 08:46:19 UTC",
      "updated_date": "2025-03-18 16:45:09 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-18T17:35:08.128895"
    },
    {
      "arxiv_id": "2406.04734v2",
      "title": "Generative AI Models: Opportunities and Risks for Industry and Authorities",
      "title_zh": "生成式 AI 模型：行业和当局的机遇与风险",
      "authors": [
        "Tobias Alt",
        "Andrea Ibisch",
        "Clemens Meiser",
        "Anna Wilhelm",
        "Raphael Zimmer",
        "Jonas Ditz",
        "Dominique Dresen",
        "Christoph Droste",
        "Jens Karschau",
        "Friederike Laus",
        "Oliver Müller",
        "Matthias Neu",
        "Rainer Plaga",
        "Carola Plesch",
        "Britta Sennewald",
        "Thomas Thaeren",
        "Kristina Unverricht",
        "Steffen Waurick"
      ],
      "abstract": "Generative AI models are capable of performing a wide variety of tasks that\nhave traditionally required creativity and human understanding. During\ntraining, they learn patterns from existing data and can subsequently generate\nnew content such as texts, images, audio, and videos that align with these\npatterns. Due to their versatility and generally high-quality results, they\nrepresent, on the one hand, an opportunity for digitalisation. On the other\nhand, the use of generative AI models introduces novel IT security risks that\nmust be considered as part of a comprehensive analysis of the IT security\nthreat landscape. In response to this risk potential, companies or authorities\nintending to use generative AI should conduct an individual risk analysis\nbefore integrating it into their workflows. The same applies to developers and\noperators, as many risks associated with generative AI must be addressed during\ndevelopment or can only be influenced by the operating organisation. Based on\nthis, existing security measures can be adapted, and additional measures\nimplemented.",
      "tldr_zh": "本论文探讨了生成式 AI 模型的功能及其对行业和当局的影响，这些模型能从现有数据中学习模式，并生成高质量的新内容，如文本、图像、音频和视频，从而为数字化带来机遇。另一方面，论文强调了生成式 AI 的使用会引入新的 IT 安全风险，需要纳入全面的威胁景观分析中。作者建议，公司、当局、开发者和运营商在整合这些模型前进行个体风险分析，并在开发阶段处理相关风险，以调整现有安全措施并实施额外保护。",
      "categories": [
        "cs.AI",
        "cs.CL",
        "cs.CR",
        "68T50 (Primary), 68M25, 68T07 (Secondary)",
        "I.2.7; I.2.10"
      ],
      "primary_category": "cs.AI",
      "comment": "67 pages, 3 figures",
      "pdf_url": "http://arxiv.org/pdf/2406.04734v2",
      "published_date": "2024-06-07 08:34:30 UTC",
      "updated_date": "2025-02-03 11:03:02 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-18T17:35:17.658679"
    },
    {
      "arxiv_id": "2406.04727v2",
      "title": "MMPolymer: A Multimodal Multitask Pretraining Framework for Polymer Property Prediction",
      "title_zh": "翻译失败",
      "authors": [
        "Fanmeng Wang",
        "Wentao Guo",
        "Minjie Cheng",
        "Shen Yuan",
        "Hongteng Xu",
        "Zhifeng Gao"
      ],
      "abstract": "Polymers are high-molecular-weight compounds constructed by the covalent\nbonding of numerous identical or similar monomers so that their 3D structures\nare complex yet exhibit unignorable regularity. Typically, the properties of a\npolymer, such as plasticity, conductivity, bio-compatibility, and so on, are\nhighly correlated with its 3D structure. However, existing polymer property\nprediction methods heavily rely on the information learned from polymer SMILES\nsequences (P-SMILES strings) while ignoring crucial 3D structural information,\nresulting in sub-optimal performance. In this work, we propose MMPolymer, a\nnovel multimodal multitask pretraining framework incorporating polymer 1D\nsequential and 3D structural information to encourage downstream polymer\nproperty prediction tasks. Besides, considering the scarcity of polymer 3D\ndata, we further introduce the \"Star Substitution\" strategy to extract 3D\nstructural information effectively. During pretraining, in addition to\npredicting masked tokens and recovering clear 3D coordinates, MMPolymer\nachieves the cross-modal alignment of latent representations. Then we further\nfine-tune the pretrained MMPolymer for downstream polymer property prediction\ntasks in the supervised learning paradigm. Experiments show that MMPolymer\nachieves state-of-the-art performance in downstream property prediction tasks.\nMoreover, given the pretrained MMPolymer, utilizing merely a single modality in\nthe fine-tuning phase can also outperform existing methods, showcasing the\nexceptional capability of MMPolymer in polymer feature extraction and\nutilization.",
      "tldr_zh": "本研究提出MMPolymer，一种多模态多任务预训练框架，用于聚合物属性预测，通过整合聚合物1D序列（P-SMILES字符串）和3D结构信息，解决现有方法忽略3D数据的局限性。同时，引入\"Star Substitution\"策略来有效提取稀缺的3D结构信息，并在预训练中实现masked tokens预测、3D坐标恢复以及跨模态潜在表示对齐。实验结果显示，MMPolymer在下游聚合物属性预测任务中达到最先进性能，即使仅使用单一模态进行微调，也优于现有方法，展示了其强大的特征提取能力。",
      "categories": [
        "cs.LG",
        "cond-mat.soft",
        "cs.AI"
      ],
      "primary_category": "cs.LG",
      "comment": "Accepted by the 33rd ACM International Conference on Information and\n  Knowledge Management (CIKM 2024)",
      "pdf_url": "http://arxiv.org/pdf/2406.04727v2",
      "published_date": "2024-06-07 08:19:59 UTC",
      "updated_date": "2024-07-26 13:24:41 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-18T17:35:30.438806"
    },
    {
      "arxiv_id": "2406.11875v1",
      "title": "ChatPCG: Large Language Model-Driven Reward Design for Procedural Content Generation",
      "title_zh": "ChatPCG：大型语言模型驱动的奖励设计用于程序化内容生成",
      "authors": [
        "In-Chang Baek",
        "Tae-Hwa Park",
        "Jin-Ha Noh",
        "Cheong-Mok Bae",
        "Kyung-Joong Kim"
      ],
      "abstract": "Driven by the rapid growth of machine learning, recent advances in game\nartificial intelligence (AI) have significantly impacted productivity across\nvarious gaming genres. Reward design plays a pivotal role in training game AI\nmodels, wherein researchers implement concepts of specific reward functions.\nHowever, despite the presence of AI, the reward design process predominantly\nremains in the domain of human experts, as it is heavily reliant on their\ncreativity and engineering skills. Therefore, this paper proposes ChatPCG, a\nlarge language model (LLM)-driven reward design framework.It leverages\nhuman-level insights, coupled with game expertise, to generate rewards tailored\nto specific game features automatically. Moreover, ChatPCG is integrated with\ndeep reinforcement learning, demonstrating its potential for multiplayer game\ncontent generation tasks. The results suggest that the proposed LLM exhibits\nthe capability to comprehend game mechanics and content generation tasks,\nenabling tailored content generation for a specified game. This study not only\nhighlights the potential for improving accessibility in content generation but\nalso aims to streamline the game AI development process.",
      "tldr_zh": "本研究提出ChatPCG框架，利用大型语言模型(LLM)驱动的奖励设计方法，自动生成针对特定游戏特征的奖励函数，以简化游戏AI的开发过程。ChatPCG结合人类级洞察力和游戏专业知识，并与深度强化学习集成，用于多玩家游戏的内容生成任务。实验结果表明，LLM能够有效理解游戏机制和任务要求，从而实现定制化的内容生成，提高了游戏AI的可访问性和生产效率。",
      "categories": [
        "cs.AI"
      ],
      "primary_category": "cs.AI",
      "comment": "4 pages, 2 figures, accepted at IEEE Conference on Games 2024",
      "pdf_url": "http://arxiv.org/pdf/2406.11875v1",
      "published_date": "2024-06-07 08:18:42 UTC",
      "updated_date": "2024-06-07 08:18:42 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-18T17:35:41.613930"
    },
    {
      "arxiv_id": "2406.04724v4",
      "title": "On Minimizing Adversarial Counterfactual Error in Adversarial RL",
      "title_zh": "翻译失败",
      "authors": [
        "Roman Belaire",
        "Arunesh Sinha",
        "Pradeep Varakantham"
      ],
      "abstract": "Deep Reinforcement Learning (DRL) policies are highly susceptible to\nadversarial noise in observations, which poses significant risks in\nsafety-critical scenarios. The challenge inherent to adversarial perturbations\nis that by altering the information observed by the agent, the state becomes\nonly partially observable. Existing approaches address this by either enforcing\nconsistent actions across nearby states or maximizing the worst-case value\nwithin adversarially perturbed observations. However, the former suffers from\nperformance degradation when attacks succeed, while the latter tends to be\noverly conservative, leading to suboptimal performance in benign settings. We\nhypothesize that these limitations stem from their failing to account for\npartial observability directly. To this end, we introduce a novel objective\ncalled Adversarial Counterfactual Error (ACoE), defined on the beliefs about\nthe true state and balancing value optimization with robustness. To make ACoE\nscalable in model-free settings, we propose the theoretically-grounded\nsurrogate objective Cumulative-ACoE (C-ACoE). Our empirical evaluations on\nstandard benchmarks (MuJoCo, Atari, and Highway) demonstrate that our method\nsignificantly outperforms current state-of-the-art approaches for addressing\nadversarial RL challenges, offering a promising direction for improving\nrobustness in DRL under adversarial conditions. Our code is available at\nhttps://github.com/romanbelaire/acoe-robust-rl.",
      "tldr_zh": "该论文针对 Deep Reinforcement Learning (DRL) 在对抗性观察下的脆弱性，提出最小化 Adversarial Counterfactual Error (ACoE) 的新方法，以解决现有方法在性能下降或过度保守方面的局限。研究者定义了 ACoE 目标，基于对真实状态的信念来平衡价值优化和鲁棒性，并引入可扩展的代理目标 Cumulative-ACoE (C-ACoE)，适用于无模型环境。实验结果显示，该方法在 MuJoCo、Atari 和 Highway 等基准上显著优于现有技术，提升了 DRL 在对抗性条件下的鲁棒性。",
      "categories": [
        "cs.LG",
        "cs.AI"
      ],
      "primary_category": "cs.LG",
      "comment": "Presented at ICLR 2025",
      "pdf_url": "http://arxiv.org/pdf/2406.04724v4",
      "published_date": "2024-06-07 08:14:24 UTC",
      "updated_date": "2025-04-23 18:03:48 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-18T17:35:58.041763"
    },
    {
      "arxiv_id": "2406.06619v1",
      "title": "LoRA-Whisper: Parameter-Efficient and Extensible Multilingual ASR",
      "title_zh": "翻译失败",
      "authors": [
        "Zheshu Song",
        "Jianheng Zhuo",
        "Yifan Yang",
        "Ziyang Ma",
        "Shixiong Zhang",
        "Xie Chen"
      ],
      "abstract": "Recent years have witnessed significant progress in multilingual automatic\nspeech recognition (ASR), driven by the emergence of end-to-end (E2E) models\nand the scaling of multilingual datasets. Despite that, two main challenges\npersist in multilingual ASR: language interference and the incorporation of new\nlanguages without degrading the performance of the existing ones. This paper\nproposes LoRA-Whisper, which incorporates LoRA matrix into Whisper for\nmultilingual ASR, effectively mitigating language interference. Furthermore, by\nleveraging LoRA and the similarities between languages, we can achieve better\nperformance on new languages while upholding consistent performance on original\nones. Experiments on a real-world task across eight languages demonstrate that\nour proposed LoRA-Whisper yields a relative gain of 18.5% and 23.0% over the\nbaseline system for multilingual ASR and language expansion respectively.",
      "tldr_zh": "该论文提出 LoRA-Whisper，一种参数高效且可扩展的多语言自动语音识别（ASR）系统，通过将 LoRA 矩阵整合到 Whisper 模型中，缓解语言干扰问题并支持新语言的添加，而不影响原有语言性能。\nLoRA-Whisper 利用 LoRA 的低秩适应机制和语言相似性，实现高效的模型微调和扩展。\n实验结果显示，在八种语言的真实任务中，该系统比基线模型在多语言 ASR 和语言扩展上分别取得了 18.5% 和 23.0% 的相对性能提升。",
      "categories": [
        "eess.AS",
        "cs.AI",
        "cs.CL"
      ],
      "primary_category": "eess.AS",
      "comment": "5 pages, 2 figures, conference",
      "pdf_url": "http://arxiv.org/pdf/2406.06619v1",
      "published_date": "2024-06-07 08:01:51 UTC",
      "updated_date": "2024-06-07 08:01:51 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-18T17:36:09.011912"
    },
    {
      "arxiv_id": "2406.04713v1",
      "title": "FlowMM: Generating Materials with Riemannian Flow Matching",
      "title_zh": "翻译失败",
      "authors": [
        "Benjamin Kurt Miller",
        "Ricky T. Q. Chen",
        "Anuroop Sriram",
        "Brandon M Wood"
      ],
      "abstract": "Crystalline materials are a fundamental component in next-generation\ntechnologies, yet modeling their distribution presents unique computational\nchallenges. Of the plausible arrangements of atoms in a periodic lattice only a\nvanishingly small percentage are thermodynamically stable, which is a key\nindicator of the materials that can be experimentally realized. Two fundamental\ntasks in this area are to (a) predict the stable crystal structure of a known\ncomposition of elements and (b) propose novel compositions along with their\nstable structures. We present FlowMM, a pair of generative models that achieve\nstate-of-the-art performance on both tasks while being more efficient and more\nflexible than competing methods. We generalize Riemannian Flow Matching to suit\nthe symmetries inherent to crystals: translation, rotation, permutation, and\nperiodic boundary conditions. Our framework enables the freedom to choose the\nflow base distributions, drastically simplifying the problem of learning\ncrystal structures compared with diffusion models. In addition to standard\nbenchmarks, we validate FlowMM's generated structures with quantum chemistry\ncalculations, demonstrating that it is about 3x more efficient, in terms of\nintegration steps, at finding stable materials compared to previous open\nmethods.",
      "tldr_zh": "该研究提出FlowMM，一对生成模型，用于生成晶体材料，针对预测已知元素组成的稳定结构和提出新组成及其结构两大任务，实现了比现有方法更高效、更灵活的SOTA性能。FlowMM通过泛化Riemannian Flow Matching，适应晶体的固有对称性（如平移、旋转、置换和周期边界条件），并允许自由选择流基分布，从而简化了晶体结构学习过程。实验结果显示，FlowMM在标准基准上表现出色，并在量子化学计算中证明其效率提升约3倍，在积分步骤上更胜于之前开源方法。",
      "categories": [
        "cs.LG",
        "cond-mat.mtrl-sci",
        "cs.AI",
        "physics.comp-ph",
        "stat.ML"
      ],
      "primary_category": "cs.LG",
      "comment": "https://github.com/facebookresearch/flowmm",
      "pdf_url": "http://arxiv.org/pdf/2406.04713v1",
      "published_date": "2024-06-07 07:46:23 UTC",
      "updated_date": "2024-06-07 07:46:23 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-18T17:36:20.304908"
    },
    {
      "arxiv_id": "2406.04710v2",
      "title": "Morescient GAI for Software Engineering (Extended Version)",
      "title_zh": "翻译失败",
      "authors": [
        "Marcus Kessel",
        "Colin Atkinson"
      ],
      "abstract": "The ability of Generative AI (GAI) technology to automatically check,\nsynthesize and modify software engineering artifacts promises to revolutionize\nall aspects of software engineering. Using GAI for software engineering tasks\nis consequently one of the most rapidly expanding fields of software\nengineering research, with over a hundred LLM-based code models having been\npublished since 2021. However, the overwhelming majority of existing code\nmodels share a major weakness - they are exclusively trained on the syntactic\nfacet of software, significantly lowering their trustworthiness in tasks\ndependent on software semantics. To address this problem, a new class of\n\"Morescient\" GAI is needed that is \"aware\" of (i.e., trained on) both the\nsemantic and static facets of software. This, in turn, will require a new\ngeneration of software observation platforms capable of generating large\nquantities of execution observations in a structured and readily analyzable\nway. In this paper, we present a vision and roadmap for how such \"Morescient\"\nGAI models can be engineered, evolved and disseminated according to the\nprinciples of open science.",
      "tldr_zh": "该论文讨论了生成式 AI (GAI) 在软件工程中的应用潜力，但指出现有 GAI 模型主要训练在软件的语法层面，导致在依赖语义的任务上可信度不足。论文提出“Morescient” GAI 概念，这是一种新类别的 GAI 模型，能够同时处理软件的语义和静态方面，以提升其可靠性和性能。为实现这一目标，论文建议开发新一代软件观察平台，用于生成大量结构化执行数据，并提供了一个基于开源科学原则的愿景和路线图来工程化、演化和传播这些模型。",
      "categories": [
        "cs.SE",
        "cs.AI",
        "D.2.1; D.2.4; I.2.2; I.2.7"
      ],
      "primary_category": "cs.SE",
      "comment": "To appear in ACM Transactions on Software Engineering and\n  Methodology, Special Issue \"2030 Roadmap Software Engineering\"",
      "pdf_url": "http://arxiv.org/pdf/2406.04710v2",
      "published_date": "2024-06-07 07:38:33 UTC",
      "updated_date": "2024-12-03 09:51:23 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-18T17:36:35.510540"
    },
    {
      "arxiv_id": "2406.06618v1",
      "title": "PANDORA: Deep graph learning based COVID-19 infection risk level forecasting",
      "title_zh": "PANDORA：基于深度图学习的 COVID-19 感染风险水平预测",
      "authors": [
        "Shuo Yu",
        "Feng Xia",
        "Yueru Wang",
        "Shihao Li",
        "Falih Febrinanto",
        "Madhu Chetty"
      ],
      "abstract": "COVID-19 as a global pandemic causes a massive disruption to social stability\nthat threatens human life and the economy. Policymakers and all elements of\nsociety must deliver measurable actions based on the pandemic's severity to\nminimize the detrimental impact of COVID-19. A proper forecasting system is\narguably important to provide an early signal of the risk of COVID-19 infection\nso that the authorities are ready to protect the people from the worst.\nHowever, making a good forecasting model for infection risks in different\ncities or regions is not an easy task, because it has a lot of influential\nfactors that are difficult to be identified manually. To address the current\nlimitations, we propose a deep graph learning model, called PANDORA, to predict\nthe infection risks of COVID-19, by considering all essential factors and\nintegrating them into a geographical network. The framework uses geographical\nposition relations and transportation frequency as higher-order structural\nproperties formulated by higher-order network structures (i.e., network\nmotifs). Moreover, four significant node attributes (i.e., multiple features of\na particular area, including climate, medical condition, economy, and human\nmobility) are also considered. We propose three different aggregators to better\naggregate node attributes and structural features, namely, Hadamard, Summation,\nand Connection. Experimental results over real data show that PANDORA\noutperforms the baseline method with higher accuracy and faster convergence\nspeed, no matter which aggregator is chosen. We believe that PANDORA using deep\ngraph learning provides a promising approach to get superior performance in\ninfection risk level forecasting and help humans battle the COVID-19 crisis.",
      "tldr_zh": "该研究提出PANDORA，一种基于deep graph learning的模型，用于预测COVID-19感染风险水平，通过整合地理位置关系、交通频率以及气候、医疗条件、经济和人类流动性的节点属性。模型利用高阶网络结构（如network motifs）和三种聚合器（Hadamard、Summation和Connection）来有效聚合特征，提升预测准确性。实验结果表明，PANDORA在真实数据上比基线方法表现出更高的准确率和更快收敛速度，为疫情风险预警提供了一个有前景的工具。",
      "categories": [
        "cs.SI",
        "cs.AI",
        "cs.CY",
        "cs.LG",
        "physics.soc-ph"
      ],
      "primary_category": "cs.SI",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2406.06618v1",
      "published_date": "2024-06-07 07:27:22 UTC",
      "updated_date": "2024-06-07 07:27:22 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-18T17:36:43.871577"
    },
    {
      "arxiv_id": "2407.16887v1",
      "title": "Comprehensive AI Assessment Framework: Enhancing Educational Evaluation with Ethical AI Integration",
      "title_zh": "全面 AI 评估框架：通过伦理 AI 整合提升教育评估",
      "authors": [
        "Selçuk Kılınç"
      ],
      "abstract": "The integration of generative artificial intelligence (GenAI) tools into\neducation has been a game-changer for teaching and assessment practices,\nbringing new opportunities, but also novel challenges which need to be dealt\nwith. This paper presents the Comprehensive AI Assessment Framework (CAIAF), an\nevolved version of the AI Assessment Scale (AIAS) by Perkins, Furze, Roe, and\nMacVaugh, targeted toward the ethical integration of AI into educational\nassessments. This is where the CAIAF differs, as it incorporates stringent\nethical guidelines, with clear distinctions based on educational levels, and\nadvanced AI capabilities of real-time interactions and personalized assistance.\nThe framework developed herein has a very intuitive use, mainly through the use\nof a color gradient that enhances the user-friendliness of the framework.\nMethodologically, the framework has been developed through the huge support of\na thorough literature review and practical insight into the topic, becoming a\ndynamic tool to be used in different educational settings. The framework will\nensure better learning outcomes, uphold academic integrity, and promote\nresponsible use of AI, hence the need for this framework in modern educational\npractice.",
      "tldr_zh": "这篇论文提出了 Comprehensive AI Assessment Framework (CAIAF)，作为 AI Assessment Scale (AIAS) 的演化版本，旨在通过伦理整合生成式人工智能 (GenAI) 来提升教育评估实践。CAIAF 强调不同教育水平的区分、实时互动和个性化辅助，并采用颜色渐变设计以提高用户友好性，该框架基于 thorough literature review 和实际洞见开发。最终，该框架可改善学习成果、维护学术诚信，并推动 AI 在教育中的负责任应用。",
      "categories": [
        "cs.CY",
        "cs.AI",
        "K.4, I.2"
      ],
      "primary_category": "cs.CY",
      "comment": "13 Pages, 2 figures, 1 Framework",
      "pdf_url": "http://arxiv.org/pdf/2407.16887v1",
      "published_date": "2024-06-07 07:18:42 UTC",
      "updated_date": "2024-06-07 07:18:42 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-18T17:36:58.793940"
    },
    {
      "arxiv_id": "2406.04699v1",
      "title": "Logic Synthesis with Generative Deep Neural Networks",
      "title_zh": "生成式深度神经网络的逻辑综合",
      "authors": [
        "Xihan Li",
        "Xing Li",
        "Lei Chen",
        "Xing Zhang",
        "Mingxuan Yuan",
        "Jun Wang"
      ],
      "abstract": "While deep learning has achieved significant success in various domains, its\napplication to logic circuit design has been limited due to complex constraints\nand strict feasibility requirement. However, a recent generative deep neural\nmodel, \"Circuit Transformer\", has shown promise in this area by enabling\nequivalence-preserving circuit transformation on a small scale. In this paper,\nwe introduce a logic synthesis rewriting operator based on the Circuit\nTransformer model, named \"ctrw\" (Circuit Transformer Rewriting), which\nincorporates the following techniques: (1) a two-stage training scheme for the\nCircuit Transformer tailored for logic synthesis, with iterative improvement of\noptimality through self-improvement training; (2) integration of the Circuit\nTransformer with state-of-the-art rewriting techniques to address scalability\nissues, allowing for guided DAG-aware rewriting. Experimental results on the\nIWLS 2023 contest benchmark demonstrate the effectiveness of our proposed\nrewriting methods.",
      "tldr_zh": "本研究探讨了深度学习在逻辑电路设计中的应用，提出了一种基于生成深度神经网络的逻辑合成重写操作符ctrw（Circuit Transformer Rewriting），以解决复杂约束和可扩展性问题。该方法采用两阶段训练方案，对Circuit Transformer进行针对性优化，包括迭代自改进训练，并将其与现有重写技术整合，实现引导的DAG-aware重写。实验结果在IWLS 2023竞赛基准上证明了ctrw的有效性，展示了其在提升电路优化方面的潜力。",
      "categories": [
        "cs.LO",
        "cs.AI"
      ],
      "primary_category": "cs.LO",
      "comment": "In IWLS 2024",
      "pdf_url": "http://arxiv.org/pdf/2406.04699v1",
      "published_date": "2024-06-07 07:16:40 UTC",
      "updated_date": "2024-06-07 07:16:40 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-18T17:37:05.874974"
    },
    {
      "arxiv_id": "2406.04693v1",
      "title": "LLM-Vectorizer: LLM-based Verified Loop Vectorizer",
      "title_zh": "LLM-Vectorizer: 基于 LLM 的验证循环向量化器",
      "authors": [
        "Jubi Taneja",
        "Avery Laird",
        "Cong Yan",
        "Madan Musuvathi",
        "Shuvendu K. Lahiri"
      ],
      "abstract": "Vectorization is a powerful optimization technique that significantly boosts\nthe performance of high performance computing applications operating on large\ndata arrays. Despite decades of research on auto-vectorization, compilers\nfrequently miss opportunities to vectorize code. On the other hand, writing\nvectorized code manually using compiler intrinsics is still a complex,\nerror-prone task that demands deep knowledge of specific architecture and\ncompilers.\n  In this paper, we evaluate the potential of large-language models (LLMs) to\ngenerate vectorized (Single Instruction Multiple Data) code from scalar\nprograms that process individual array elements. We propose a novel\nfinite-state machine multi-agents based approach that harnesses LLMs and\ntest-based feedback to generate vectorized code. Our findings indicate that\nLLMs are capable of producing high performance vectorized code with run-time\nspeedup ranging from 1.1x to 9.4x as compared to the state-of-the-art compilers\nsuch as Intel Compiler, GCC, and Clang.\n  To verify the correctness of vectorized code, we use Alive2, a leading\nbounded translation validation tool for LLVM IR. We describe a few\ndomain-specific techniques to improve the scalability of Alive2 on our\nbenchmark dataset. Overall, our approach is able to verify 38.2% of\nvectorizations as correct on the TSVC benchmark dataset.",
      "tldr_zh": "本论文提出 LLM-Vectorizer，一种基于大型语言模型 (LLMs) 的循环向量化器，用于从标量程序自动生成高效的向量化代码，以提升高性能计算应用的性能。研究采用有限状态机多智能体方法，结合 LLMs 和测试反馈机制生成代码，并利用 Alive2 进行 LLVM IR 代码的正确性验证，同时引入领域特定技术来提升验证的扩展性。实验结果显示，该方法生成的代码比 Intel Compiler、GCC 和 Clang 等编译器实现 1.1x 到 9.4x 的运行速度提升，并在 TSVC 基准数据集上成功验证了 38.2% 的向量化为正确。",
      "categories": [
        "cs.SE",
        "cs.AI",
        "cs.LG",
        "cs.PF"
      ],
      "primary_category": "cs.SE",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2406.04693v1",
      "published_date": "2024-06-07 07:04:26 UTC",
      "updated_date": "2024-06-07 07:04:26 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-18T17:37:22.141675"
    },
    {
      "arxiv_id": "2406.06616v1",
      "title": "Transforming Dental Diagnostics with Artificial Intelligence: Advanced Integration of ChatGPT and Large Language Models for Patient Care",
      "title_zh": "利用人工智能转变牙科诊断：ChatGPT",
      "authors": [
        "Masoumeh Farhadi Nia",
        "Mohsen Ahmadi",
        "Elyas Irankhah"
      ],
      "abstract": "Artificial intelligence has dramatically reshaped our interaction with\ndigital technologies, ushering in an era where advancements in AI algorithms\nand Large Language Models (LLMs) have natural language processing (NLP) systems\nlike ChatGPT. This study delves into the impact of cutting-edge LLMs, notably\nOpenAI's ChatGPT, on medical diagnostics, with a keen focus on the dental\nsector. Leveraging publicly accessible datasets, these models augment the\ndiagnostic capabilities of medical professionals, streamline communication\nbetween patients and healthcare providers, and enhance the efficiency of\nclinical procedures. The advent of ChatGPT-4 is poised to make substantial\ninroads into dental practices, especially in the realm of oral surgery. This\npaper sheds light on the current landscape and explores potential future\nresearch directions in the burgeoning field of LLMs, offering valuable insights\nfor both practitioners and developers. Furthermore, it critically assesses the\nbroad implications and challenges within various sectors, including academia\nand healthcare, thus mapping out an overview of AI's role in transforming\ndental diagnostics for enhanced patient care.",
      "tldr_zh": "本研究探讨了Artificial Intelligence (AI)和Large Language Models (LLMs)如ChatGPT在牙科诊断中的先进整合，旨在提升医疗专业人员的诊断能力、患者沟通效率以及临床程序的优化。研究利用公开可访问的数据集，评估了这些模型在牙科领域的应用，特别是ChatGPT-4在口腔外科中的潜在突破。论文还分析了当前景观、未来研究方向以及AI面临的挑战，为牙科实践提供宝贵见解，并强调其在改善患者护理方面的整体影响。",
      "categories": [
        "cs.CL",
        "cs.AI",
        "cs.LG"
      ],
      "primary_category": "cs.CL",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2406.06616v1",
      "published_date": "2024-06-07 06:44:09 UTC",
      "updated_date": "2024-06-07 06:44:09 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-18T17:37:34.117674"
    },
    {
      "arxiv_id": "2406.04673v1",
      "title": "MeLFusion: Synthesizing Music from Image and Language Cues using Diffusion Models",
      "title_zh": "MeLFusion：利用扩散模型从图像和语言提示合成音乐",
      "authors": [
        "Sanjoy Chowdhury",
        "Sayan Nag",
        "K J Joseph",
        "Balaji Vasan Srinivasan",
        "Dinesh Manocha"
      ],
      "abstract": "Music is a universal language that can communicate emotions and feelings. It\nforms an essential part of the whole spectrum of creative media, ranging from\nmovies to social media posts. Machine learning models that can synthesize music\nare predominantly conditioned on textual descriptions of it. Inspired by how\nmusicians compose music not just from a movie script, but also through\nvisualizations, we propose MeLFusion, a model that can effectively use cues\nfrom a textual description and the corresponding image to synthesize music.\nMeLFusion is a text-to-music diffusion model with a novel \"visual synapse\",\nwhich effectively infuses the semantics from the visual modality into the\ngenerated music. To facilitate research in this area, we introduce a new\ndataset MeLBench, and propose a new evaluation metric IMSM. Our exhaustive\nexperimental evaluation suggests that adding visual information to the music\nsynthesis pipeline significantly improves the quality of generated music,\nmeasured both objectively and subjectively, with a relative gain of up to\n67.98% on the FAD score. We hope that our work will gather attention to this\npragmatic, yet relatively under-explored research area.",
      "tldr_zh": "本研究提出 MeLFusion，一种基于扩散模型的音乐合成框架，能够同时利用文本描述和对应图像提示生成音乐，从而超越传统仅依赖文本的方法。MeLFusion 引入“visual synapse”机制，有效融合视觉语义以提升音乐的准确性和情感表达。为支持这一领域的研究，该论文还构建了新数据集 MeLBench 和评估指标 IMSM。实验结果显示，添加视觉信息后，生成的音乐质量显著提升，FAD 分数相对改善高达 67.98%，证明了多模态提示在音乐合成中的重要作用。",
      "categories": [
        "cs.CV",
        "cs.AI",
        "cs.MM",
        "eess.AS"
      ],
      "primary_category": "cs.CV",
      "comment": "Accepted at CVPR 2024 as Highlight paper. Webpage:\n  https://schowdhury671.github.io/melfusion_cvpr2024/",
      "pdf_url": "http://arxiv.org/pdf/2406.04673v1",
      "published_date": "2024-06-07 06:38:59 UTC",
      "updated_date": "2024-06-07 06:38:59 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-18T17:37:43.860183"
    },
    {
      "arxiv_id": "2406.04671v1",
      "title": "The Reasonable Person Standard for AI",
      "title_zh": "针对 AI 的合理人标准",
      "authors": [
        "Sunayana Rane"
      ],
      "abstract": "As AI systems are increasingly incorporated into domains where human behavior\nhas set the norm, a challenge for AI governance and AI alignment research is to\nregulate their behavior in a way that is useful and constructive for society.\nOne way to answer this question is to ask: how do we govern the human behavior\nthat the models are emulating? To evaluate human behavior, the American legal\nsystem often uses the \"Reasonable Person Standard.\" The idea of \"reasonable\"\nbehavior comes up in nearly every area of law. The legal system often judges\nthe actions of parties with respect to what a reasonable person would have done\nunder similar circumstances. This paper argues that the reasonable person\nstandard provides useful guidelines for the type of behavior we should develop,\nprobe, and stress-test in models. It explains how reasonableness is defined and\nused in key areas of the law using illustrative cases, how the reasonable\nperson standard could apply to AI behavior in each of these areas and contexts,\nand how our societal understanding of \"reasonable\" behavior provides useful\ntechnical goals for AI researchers.",
      "tldr_zh": "这篇论文探讨了将“Reasonable Person Standard”应用于AI治理和AI对齐研究，以规范AI行为，使其对社会有益。该标准源于美国法律系统，用于评估人类在类似情境下的合理行为，通过典型案例说明其在刑法、民事等领域的作用。论文论证了如何将此标准扩展到AI领域，包括开发、测试和压力测试AI模型，以确保其行为符合社会期望，并为AI研究者提供具体的技术目标。",
      "categories": [
        "cs.CY",
        "cs.AI"
      ],
      "primary_category": "cs.CY",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2406.04671v1",
      "published_date": "2024-06-07 06:35:54 UTC",
      "updated_date": "2024-06-07 06:35:54 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-18T17:37:58.102722"
    },
    {
      "arxiv_id": "2406.04670v1",
      "title": "MATTER: Memory-Augmented Transformer Using Heterogeneous Knowledge Sources",
      "title_zh": "MATTER：利用异构知识来源的记忆增强Transformer",
      "authors": [
        "Dongkyu Lee",
        "Chandana Satya Prakash",
        "Jack FitzGerald",
        "Jens Lehmann"
      ],
      "abstract": "Leveraging external knowledge is crucial for achieving high performance in\nknowledge-intensive tasks, such as question answering. The retrieve-and-read\napproach is widely adopted for integrating external knowledge into a language\nmodel. However, this approach suffers from increased computational cost and\nlatency due to the long context length, which grows proportionally with the\nnumber of retrieved knowledge. Furthermore, existing retrieval-augmented models\ntypically retrieve information from a single type of knowledge source, limiting\ntheir scalability to diverse knowledge sources with varying structures. In this\nwork, we introduce an efficient memory-augmented transformer called MATTER,\ndesigned to retrieve relevant knowledge from multiple heterogeneous knowledge\nsources. Specifically, our model retrieves and reads from both unstructured\nsources (paragraphs) and semi-structured sources (QA pairs) in the form of\nfixed-length neural memories. We demonstrate that our model outperforms\nexisting efficient retrieval-augmented models on popular QA benchmarks in terms\nof both accuracy and speed. Furthermore, MATTER achieves competitive results\ncompared to conventional read-and-retrieve models while having 100x throughput\nduring inference.",
      "tldr_zh": "该研究针对知识密集型任务（如问答）中外部知识整合的挑战，提出了MATTER，一种memory-augmented Transformer模型，能够从多个heterogeneous knowledge sources（如unstructured sources的段落和semi-structured sources的QA pairs）高效检索和读取信息。\n与传统的retrieve-and-read方法相比，MATTER采用固定长度的neural memories减少了计算成本和延迟，提升了模型的可扩展性。\n实验结果显示，MATTER在QA benchmarks上超越现有retrieval-augmented模型，在准确性和速度方面表现出色，并实现了比常规模型高100倍的推理吞吐量。",
      "categories": [
        "cs.CL",
        "cs.AI"
      ],
      "primary_category": "cs.CL",
      "comment": "ACL2024-Findings",
      "pdf_url": "http://arxiv.org/pdf/2406.04670v1",
      "published_date": "2024-06-07 06:35:37 UTC",
      "updated_date": "2024-06-07 06:35:37 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-18T17:38:13.536709"
    },
    {
      "arxiv_id": "2407.00048v1",
      "title": "Ensemble Method for System Failure Detection Using Large-Scale Telemetry Data",
      "title_zh": "翻译失败",
      "authors": [
        "Priyanka Mudgal",
        "Rita H. Wouhaybi"
      ],
      "abstract": "The growing reliance on computer systems, particularly personal computers\n(PCs), necessitates heightened reliability to uphold user satisfaction. This\nresearch paper presents an in-depth analysis of extensive system telemetry\ndata, proposing an ensemble methodology for detecting system failures. Our\napproach entails scrutinizing various parameters of system metrics,\nencompassing CPU utilization, memory utilization, disk activity, CPU\ntemperature, and pertinent system metadata such as system age, usage patterns,\ncore count, and processor type. The proposed ensemble technique integrates a\ndiverse set of algorithms, including Long Short-Term Memory (LSTM) networks,\nisolation forests, one-class support vector machines (OCSVM), and local outlier\nfactors (LOF), to effectively discern system failures. Specifically, the LSTM\nnetwork with other machine learning techniques is trained on Intel Computing\nImprovement Program (ICIP) telemetry software data to distinguish between\nnormal and failed system patterns. Experimental evaluations demonstrate the\nremarkable efficacy of our models, achieving a notable detection rate in\nidentifying system failures. Our research contributes to advancing the field of\nsystem reliability and offers practical insights for enhancing user experience\nin computing environments.",
      "tldr_zh": "这篇论文提出了一种集成方法，用于利用大规模遥测数据检测计算机系统故障，旨在提升系统可靠性并改善用户体验。方法通过分析参数如 CPU 使用率、内存使用率、磁盘活动和 CPU 温度等，并整合 LSTM 网络、isolation forests、OCSVM 和 LOF 等算法，对 Intel 的 ICIP 遥测软件数据进行训练，以区分正常和故障模式。实验结果显示，该集成技术显著提高了系统故障检测率，为实际计算环境提供可行的优化策略。",
      "categories": [
        "cs.DC",
        "cs.AI"
      ],
      "primary_category": "cs.DC",
      "comment": "Accepted at IEEE-IAICT-24. Copyright is held by IEEE",
      "pdf_url": "http://arxiv.org/pdf/2407.00048v1",
      "published_date": "2024-06-07 06:35:17 UTC",
      "updated_date": "2024-06-07 06:35:17 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-18T17:38:21.850985"
    },
    {
      "arxiv_id": "2406.04658v3",
      "title": "Advanced Payment Security System:XGBoost, LightGBM and SMOTE Integrated",
      "title_zh": "先进的支付安全系统：XGBoost、LightGBM 和 SMOTE 整合",
      "authors": [
        "Qi Zheng",
        "Chang Yu",
        "Jin Cao",
        "Yongshun Xu",
        "Qianwen Xing",
        "Yinxin Jin"
      ],
      "abstract": "With the rise of various online and mobile payment systems, transaction fraud\nhas become a significant threat to financial security. This study explores the\napplication of advanced machine learning models, specifically based on XGBoost\nand LightGBM, for developing a more accurate and robust Payment Security\nProtection Model. To enhance data reliability, we meticulously processed the\ndata sources and applied SMOTE (Synthetic Minority Over-sampling Technique) to\naddress class imbalance and improve data representation. By selecting highly\ncorrelated features, we aimed to strengthen the training process and boost\nmodel performance. We conducted thorough performance evaluations of our\nproposed models, comparing them against traditional methods including Random\nForest, Neural Network, and Logistic Regression. Using metrics such as\nPrecision, Recall, and F1 Score, we rigorously assessed their effectiveness.\nOur detailed analyses and comparisons reveal that the combination of SMOTE with\nXGBoost and LightGBM offers a highly efficient and powerful mechanism for\npayment security protection. Moreover, the integration of XGBoost and LightGBM\nin a Local Ensemble model further demonstrated outstanding performance. After\nincorporating SMOTE, the new combined model achieved a significant improvement\nof nearly 6\\% over traditional models and around 5\\% over its sub-models,\nshowcasing remarkable results.",
      "tldr_zh": "本研究针对在线支付系统的交易欺诈威胁，提出了一种集成 XGBoost 和 LightGBM 的高级支付安全模型，并结合 SMOTE（Synthetic Minority Over-sampling Technique）处理类不平衡问题，以提升数据可靠性和模型性能。研究通过选择高度相关的特征，并与传统模型如 Random Forest、Neural Network 和 Logistic Regression 进行比较，使用 Precision、Recall 和 F1 Score 等指标评估效果。结果显示，SMOTE 与 XGBoost 和 LightGBM 结合的 Local Ensemble 模型比传统模型提高了近6%，比子模型提高了约5%，展示了其在支付安全保护中的高效性和鲁棒性。",
      "categories": [
        "cs.CR",
        "cs.AI",
        "cs.LG"
      ],
      "primary_category": "cs.CR",
      "comment": "This paper is received by https://ieee-metacom.org",
      "pdf_url": "http://arxiv.org/pdf/2406.04658v3",
      "published_date": "2024-06-07 05:56:43 UTC",
      "updated_date": "2024-11-12 16:44:20 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-18T17:38:34.007645"
    },
    {
      "arxiv_id": "2406.04657v2",
      "title": "Crafting Heavy-Tails in Weight Matrix Spectrum without Gradient Noise",
      "title_zh": "翻译失败",
      "authors": [
        "Vignesh Kothapalli",
        "Tianyu Pang",
        "Shenyang Deng",
        "Zongmin Liu",
        "Yaoqing Yang"
      ],
      "abstract": "Training strategies for modern deep neural networks (NNs) tend to induce a\nheavy-tailed (HT) empirical spectral density (ESD) in the layer weights. While\nprevious efforts have shown that the HT phenomenon correlates with good\ngeneralization in large NNs, a theoretical explanation of its occurrence is\nstill lacking. Especially, understanding the conditions which lead to this\nphenomenon can shed light on the interplay between generalization and weight\nspectra. Our work aims to bridge this gap by presenting a simple, rich setting\nto model the emergence of HT ESD. In particular, we present a theory-informed\nanalysis for 'crafting' heavy tails in the ESD of two-layer NNs without any\ngradient noise. This is the first work to analyze a noise-free setting and\nincorporate optimizer (GD/Adam) dependent (large) learning rates into the HT\nESD analysis. Our results highlight the role of learning rates on the\nBulk+Spike and HT shape of the ESDs in the early phase of training, which can\nfacilitate generalization in the two-layer NN. These observations shed light on\nthe behavior of large-scale NNs, albeit in a much simpler setting. Last but not\nleast, we present a novel perspective on the ESD evolution dynamics by\nanalyzing the singular vectors of weight matrices and optimizer updates.",
      "tldr_zh": "本文研究了在深度神经网络训练中，如何在没有梯度噪声的情况下“制作”权重矩阵谱密度（ESD）的重尾（HT）分布，以揭示其与泛化性能的相关性。作者通过理论分析两层神经网络，使用GD/Adam优化器和大学习率，展示了学习率如何在训练早期影响ESD的Bulk+Spike和HT形状，从而促进泛化。研究还首次分析了噪声-free设置，并通过权重矩阵的奇异向量和优化器更新，提供了一个新的视角来理解ESD演化动态。",
      "categories": [
        "cs.LG",
        "cs.AI",
        "math.ST",
        "stat.ML",
        "stat.TH"
      ],
      "primary_category": "cs.LG",
      "comment": "34 pages, 32 figures, 4 tables",
      "pdf_url": "http://arxiv.org/pdf/2406.04657v2",
      "published_date": "2024-06-07 05:51:57 UTC",
      "updated_date": "2024-10-02 08:10:29 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-18T17:38:56.869676"
    },
    {
      "arxiv_id": "2406.04639v1",
      "title": "Cooperative Meta-Learning with Gradient Augmentation",
      "title_zh": "翻译失败",
      "authors": [
        "Jongyun Shin",
        "Seunjin Han",
        "Jangho Kim"
      ],
      "abstract": "Model agnostic meta-learning (MAML) is one of the most widely used\ngradient-based meta-learning, consisting of two optimization loops: an inner\nloop and outer loop. MAML learns the new task from meta-initialization\nparameters with an inner update and finds the meta-initialization parameters in\nthe outer loop. In general, the injection of noise into the gradient of the\nmodel for augmenting the gradient is one of the widely used regularization\nmethods. In this work, we propose a novel cooperative meta-learning framework\ndubbed CML which leverages gradient-level regularization with gradient\naugmentation. We inject learnable noise into the gradient of the model for the\nmodel generalization. The key idea of CML is introducing the co-learner which\nhas no inner update but the outer loop update to augment gradients for finding\nbetter meta-initialization parameters. Since the co-learner does not update in\nthe inner loop, it can be easily deleted after meta-training. Therefore, CML\ninfers with only meta-learner without additional cost and performance\ndegradation. We demonstrate that CML is easily applicable to gradient-based\nmeta-learning methods and CML leads to increased performance in few-shot\nregression, few-shot image classification and few-shot node classification\ntasks. Our codes are at https://github.com/JJongyn/CML.",
      "tldr_zh": "本研究提出了一种新型合作式元学习框架CML（Cooperative Meta-Learning with Gradient Augmentation），旨在通过梯度增强技术改善基于梯度的元学习方法，如MAML（Model Agnostic Meta-Learning）。CML在模型梯度中注入可学习的噪声，并引入co-learner模块，仅在外循环更新以辅助优化meta-initialization参数，而不参与内循环，从而增强模型泛化且不增加推理成本。实验结果显示，CML在few-shot回归、图像分类和节点分类任务中显著提升性能，证明了其在梯度-based元学习中的适用性和有效性。",
      "categories": [
        "cs.LG",
        "cs.AI",
        "cs.CV"
      ],
      "primary_category": "cs.LG",
      "comment": "Accepted to UAI 2024",
      "pdf_url": "http://arxiv.org/pdf/2406.04639v1",
      "published_date": "2024-06-07 04:54:00 UTC",
      "updated_date": "2024-06-07 04:54:00 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-18T17:39:00.258732"
    },
    {
      "arxiv_id": "2406.04635v1",
      "title": "Scaling Automatic Extraction of Pseudocode",
      "title_zh": "翻译失败",
      "authors": [
        "Levent Toksoz",
        "Gang Tan",
        "C. Lee Giles"
      ],
      "abstract": "Pseudocode in a scholarly paper provides a concise way to express the\nalgorithms implemented therein. Pseudocode can also be thought of as an\nintermediary representation that helps bridge the gap between programming\nlanguages and natural languages. Having access to a large collection of\npseudocode can provide various benefits ranging from enhancing algorithmic\nunderstanding, facilitating further algorithmic design, to empowering NLP or\ncomputer vision based models for tasks such as automated code generation and\noptical character recognition (OCR). We have created a large pseudocode\ncollection by extracting nearly 320,000 pseudocode examples from arXiv papers.\nThis process involved scanning over $2.2$ million scholarly papers, with 1,000\nof them being manually inspected and labeled. Our approach encompasses an\nextraction mechanism tailored to optimize the coverage and a validation\nmechanism based on random sampling to check its accuracy and reliability, given\nthe inherent heterogeneity of the collection. In addition, we offer insights\ninto common pseudocode structures, supported by clustering and statistical\nanalyses. Notably, these analyses indicate an exponential-like growth in the\nusage of pseudocodes, highlighting their increasing significance.",
      "tldr_zh": "本研究开发了一种可扩展的自动提取伪代码的方法，从 arXiv 论文中构建了一个包含近 32 万个伪代码示例的大型集合，以桥接编程语言和自然语言的差距。方法包括扫描超过 220 万篇论文，使用定制的提取机制优化覆盖范围，并通过基于随机采样的验证机制确保准确性和可靠性。分析结果显示，伪代码的使用呈现指数级增长，并通过聚类和统计分析揭示了常见伪代码结构，这有助于提升算法理解、算法设计以及 NLP 和 OCR 等任务的应用。",
      "categories": [
        "cs.IR",
        "cs.AI"
      ],
      "primary_category": "cs.IR",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2406.04635v1",
      "published_date": "2024-06-07 04:39:17 UTC",
      "updated_date": "2024-06-07 04:39:17 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-18T17:39:09.584809"
    },
    {
      "arxiv_id": "2406.04627v1",
      "title": "Denoising-Aware Contrastive Learning for Noisy Time Series",
      "title_zh": "针对噪声时间序列的去噪感知对比学习",
      "authors": [
        "Shuang Zhou",
        "Daochen Zha",
        "Xiao Shen",
        "Xiao Huang",
        "Rui Zhang",
        "Fu-Lai Chung"
      ],
      "abstract": "Time series self-supervised learning (SSL) aims to exploit unlabeled data for\npre-training to mitigate the reliance on labels. Despite the great success in\nrecent years, there is limited discussion on the potential noise in the time\nseries, which can severely impair the performance of existing SSL methods. To\nmitigate the noise, the de facto strategy is to apply conventional denoising\nmethods before model training. However, this pre-processing approach may not\nfully eliminate the effect of noise in SSL for two reasons: (i) the diverse\ntypes of noise in time series make it difficult to automatically determine\nsuitable denoising methods; (ii) noise can be amplified after mapping raw data\ninto latent space. In this paper, we propose denoising-aware contrastive\nlearning (DECL), which uses contrastive learning objectives to mitigate the\nnoise in the representation and automatically selects suitable denoising\nmethods for every sample. Extensive experiments on various datasets verify the\neffectiveness of our method. The code is open-sourced.",
      "tldr_zh": "该研究针对时间序列自监督学习 (SSL) 中噪声问题，提出了一种新的方法 denoising-aware contrastive learning (DECL)，旨在通过对比学习目标减轻表示空间中的噪声，并自动为每个样本选择合适的去噪策略。不同于传统预处理去噪方法，DECL 解决了噪声类型多样和潜在空间放大等问题，提高了 SSL 的鲁棒性。在多个数据集上的广泛实验验证了该方法的有效性，并开源了代码。",
      "categories": [
        "cs.LG",
        "cs.AI"
      ],
      "primary_category": "cs.LG",
      "comment": "Accepted to 33rd International Joint Conference on Artificial\n  Intelligence (IJCAI 2024)",
      "pdf_url": "http://arxiv.org/pdf/2406.04627v1",
      "published_date": "2024-06-07 04:27:32 UTC",
      "updated_date": "2024-06-07 04:27:32 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-18T17:39:21.951728"
    },
    {
      "arxiv_id": "2406.06615v2",
      "title": "Language Guided Skill Discovery",
      "title_zh": "语言引导技能发现",
      "authors": [
        "Seungeun Rho",
        "Laura Smith",
        "Tianyu Li",
        "Sergey Levine",
        "Xue Bin Peng",
        "Sehoon Ha"
      ],
      "abstract": "Skill discovery methods enable agents to learn diverse emergent behaviors\nwithout explicit rewards. To make learned skills useful for unknown downstream\ntasks, obtaining a semantically diverse repertoire of skills is essential.\nWhile some approaches introduce a discriminator to distinguish skills and\nothers aim to increase state coverage, no existing work directly addresses the\n\"semantic diversity\" of skills. We hypothesize that leveraging the semantic\nknowledge of large language models (LLMs) can lead us to improve semantic\ndiversity of resulting behaviors. In this sense, we introduce Language Guided\nSkill Discovery (LGSD), a skill discovery framework that aims to directly\nmaximize the semantic diversity between skills. LGSD takes user prompts as\ninput and outputs a set of semantically distinctive skills. The prompts serve\nas a means to constrain the search space into a semantically desired subspace,\nand the generated LLM outputs guide the agent to visit semantically diverse\nstates within the subspace. We demonstrate that LGSD enables legged robots to\nvisit different user-intended areas on a plane by simply changing the prompt.\nFurthermore, we show that language guidance aids in discovering more diverse\nskills compared to five existing skill discovery methods in robot-arm\nmanipulation environments. Lastly, LGSD provides a simple way of utilizing\nlearned skills via natural language.",
      "tldr_zh": "这篇论文提出了 Language Guided Skill Discovery (LGSD)，一个框架，利用大型语言模型 (LLMs) 的语义知识来提升代理在无显式奖励下学习技能的语义多样性。LGSD 以用户提示作为输入，限制搜索空间并指导代理访问子空间内的多样状态，从而生成一组语义上不同的技能。实验结果显示，该方法使腿部机器人和机器人臂在特定环境中产生更丰富的行为，并通过自然语言提供简单的方式利用这些技能。",
      "categories": [
        "cs.CL",
        "cs.AI",
        "cs.LG",
        "cs.RO"
      ],
      "primary_category": "cs.CL",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2406.06615v2",
      "published_date": "2024-06-07 04:25:38 UTC",
      "updated_date": "2025-03-01 03:07:31 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-18T17:39:37.384258"
    },
    {
      "arxiv_id": "2406.04625v3",
      "title": "Key-Element-Informed sLLM Tuning for Document Summarization",
      "title_zh": "翻译失败",
      "authors": [
        "Sangwon Ryu",
        "Heejin Do",
        "Yunsu Kim",
        "Gary Geunbae Lee",
        "Jungseul Ok"
      ],
      "abstract": "Remarkable advances in large language models (LLMs) have enabled high-quality\ntext summarization. However, this capability is currently accessible only\nthrough LLMs of substantial size or proprietary LLMs with usage fees. In\nresponse, smaller-scale LLMs (sLLMs) of easy accessibility and low costs have\nbeen extensively studied, yet they often suffer from missing key information\nand entities, i.e., low relevance, in particular, when input documents are\nlong. We hence propose a key-element-informed instruction tuning for\nsummarization, so-called KEITSum, which identifies key elements in documents\nand instructs sLLM to generate summaries capturing these key elements.\nExperimental results on dialogue and news datasets demonstrate that sLLM with\nKEITSum indeed provides high-quality summarization with higher relevance and\nless hallucinations, competitive to proprietary LLM.",
      "tldr_zh": "大型语言模型 (LLMs) 在文本摘要方面表现出色，但小规模语言模型 (sLLMs) 常因遗漏关键信息和实体而导致摘要相关性不足，尤其在处理长文档时。为此，本文提出 KEITSum，一种关键元素指导的 instruction tuning 方法，通过识别文档中的关键元素并指导 sLLMs 生成包含这些元素的摘要。在对话和新闻数据集上的实验显示，KEITSum 增强的 sLLMs 提供了高质量摘要，具有更高的相关性和更少的 hallucinations，并能与专有 LLM 性能竞争。",
      "categories": [
        "cs.CL",
        "cs.AI"
      ],
      "primary_category": "cs.CL",
      "comment": "Interspeech 2024",
      "pdf_url": "http://arxiv.org/pdf/2406.04625v3",
      "published_date": "2024-06-07 04:19:01 UTC",
      "updated_date": "2024-11-19 12:41:04 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-18T17:39:57.392109"
    },
    {
      "arxiv_id": "2406.04614v1",
      "title": "LawGPT: A Chinese Legal Knowledge-Enhanced Large Language Model",
      "title_zh": "LawGPT:",
      "authors": [
        "Zhi Zhou",
        "Jiang-Xin Shi",
        "Peng-Xiao Song",
        "Xiao-Wen Yang",
        "Yi-Xuan Jin",
        "Lan-Zhe Guo",
        "Yu-Feng Li"
      ],
      "abstract": "Large language models (LLMs), including both proprietary and open-source\nmodels, have showcased remarkable capabilities in addressing a wide range of\ndownstream tasks. Nonetheless, when it comes to practical Chinese legal tasks,\nthese models fail to meet the actual requirements. Proprietary models do not\nensure data privacy for sensitive legal cases, while open-source models\ndemonstrate unsatisfactory performance due to their lack of legal knowledge. To\naddress this problem, we introduce LawGPT, the first open-source model\nspecifically designed for Chinese legal applications. LawGPT comprises two key\ncomponents: legal-oriented pre-training and legal supervised fine-tuning.\nSpecifically, we employ large-scale Chinese legal documents for legal-oriented\npre-training to incorporate legal domain knowledge. To further improve the\nmodel's performance on downstream legal tasks, we create a knowledge-driven\ninstruction dataset for legal supervised fine-tuning. Our experimental results\ndemonstrate that LawGPT outperforms the open-source LLaMA 7B model. Our code\nand resources are publicly available at https://github.com/pengxiao-song/LaWGPT\nand have received 5.7K stars on GitHub.",
      "tldr_zh": "该研究针对现有大语言模型（LLMs）在中文法律任务中的隐私和性能不足问题，引入了 LawGPT，这是一个开源的中文法律知识增强模型。LawGPT 通过大规模中文法律文档进行法律导向的预训练，以整合领域知识，并利用知识驱动的指令数据集进行法律监督微调，从而提升下游任务的表现。实验结果表明，LawGPT 优于开源 LLaMA 7B 模型，其代码和资源已在 GitHub 上公开可用。",
      "categories": [
        "cs.CL",
        "cs.AI"
      ],
      "primary_category": "cs.CL",
      "comment": "Technical Report",
      "pdf_url": "http://arxiv.org/pdf/2406.04614v1",
      "published_date": "2024-06-07 03:52:56 UTC",
      "updated_date": "2024-06-07 03:52:56 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-18T17:40:12.759457"
    },
    {
      "arxiv_id": "2406.04612v2",
      "title": "Faithful and Accurate Self-Attention Attribution for Message Passing Neural Networks via the Computation Tree Viewpoint",
      "title_zh": "翻译失败",
      "authors": [
        "Yong-Min Shin",
        "Siqing Li",
        "Xin Cao",
        "Won-Yong Shin"
      ],
      "abstract": "The self-attention mechanism has been adopted in various popular message\npassing neural networks (MPNNs), enabling the model to adaptively control the\namount of information that flows along the edges of the underlying graph. Such\nattention-based MPNNs (Att-GNNs) have also been used as a baseline for multiple\nstudies on explainable AI (XAI) since attention has steadily been seen as\nnatural model interpretations, while being a viewpoint that has already been\npopularized in other domains (e.g., natural language processing and computer\nvision). However, existing studies often use naive calculations to derive\nattribution scores from attention, undermining the potential of attention as\ninterpretations for Att-GNNs. In our study, we aim to fill the gap between the\nwidespread usage of Att-GNNs and their potential explainability via attention.\nTo this end, we propose GATT, edge attribution calculation method for\nself-attention MPNNs based on the computation tree, a rooted tree that reflects\nthe computation process of the underlying model. Despite its simplicity, we\nempirically demonstrate the effectiveness of GATT in three aspects of model\nexplanation: faithfulness, explanation accuracy, and case studies by using both\nsynthetic and real-world benchmark datasets. In all cases, the results\ndemonstrate that GATT greatly improves edge attribution scores, especially\ncompared to the previous naive approach. Our code is available at\nhttps://github.com/jordan7186/GAtt.",
      "tldr_zh": "这篇论文针对自注意力(self-attention)机制在消息传递神经网络(MPNNs)中的应用，提出了一种基于计算树(computation tree)的边归因方法GATT，以提升模型解释的忠诚度(faithfulness)和准确性。GATT通过构建一个反映模型计算过程的根树，来精确计算注意力归因分数，解决了现有naive计算方法的局限性。实验结果显示，在合成和真实数据集上，GATT显著提高了边归因性能，与基线方法相比提升了整体解释效果，并在可解释AI(XAI)领域展现出强大潜力。",
      "categories": [
        "cs.LG",
        "cs.AI",
        "cs.IT",
        "cs.NE",
        "cs.SI",
        "math.IT"
      ],
      "primary_category": "cs.LG",
      "comment": "29 pages, 14 figures, 17 tables; an extended version of our paper to\n  be presented at the 39th AAAI Conference on Artificial Intelligence (AAAI-25)\n  (Please cite our conference version.)",
      "pdf_url": "http://arxiv.org/pdf/2406.04612v2",
      "published_date": "2024-06-07 03:40:15 UTC",
      "updated_date": "2024-12-20 11:17:45 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-18T17:40:25.273813"
    },
    {
      "arxiv_id": "2406.04609v2",
      "title": "Diverse Intra- and Inter-Domain Activity Style Fusion for Cross-Person Generalization in Activity Recognition",
      "title_zh": "翻译失败",
      "authors": [
        "Junru Zhang",
        "Lang Feng",
        "Zhidan Liu",
        "Yuhan Wu",
        "Yang He",
        "Yabo Dong",
        "Duanqing Xu"
      ],
      "abstract": "Existing domain generalization (DG) methods for cross-person generalization\ntasks often face challenges in capturing intra- and inter-domain style\ndiversity, resulting in domain gaps with the target domain. In this study, we\nexplore a novel perspective to tackle this problem, a process conceptualized as\ndomain padding. This proposal aims to enrich the domain diversity by\nsynthesizing intra- and inter-domain style data while maintaining robustness to\nclass labels. We instantiate this concept using a conditional diffusion model\nand introduce a style-fused sampling strategy to enhance data generation\ndiversity. In contrast to traditional condition-guided sampling, our\nstyle-fused sampling strategy allows for the flexible use of one or more random\nstyles to guide data synthesis. This feature presents a notable advancement: it\nallows for the maximum utilization of possible permutations and combinations\namong existing styles to generate a broad spectrum of new style instances.\nEmpirical evaluations on a broad range of datasets demonstrate that our\ngenerated data achieves remarkable diversity within the domain space. Both\nintra- and inter-domain generated data have proven to be significant and\nvaluable, contributing to varying degrees of performance enhancements. Notably,\nour approach outperforms state-of-the-art DG methods in all human activity\nrecognition tasks.",
      "tldr_zh": "本文针对活动识别中的跨人泛化问题，提出一种领域填充（domain padding）方法，通过合成 intra- and inter-domain 风格数据来丰富领域多样性，同时保持对类别标签的鲁棒性。方法利用 conditional diffusion model 和 style-fused sampling strategy 灵活组合随机风格进行数据生成，从而最大化现有风格的排列组合以创建更多新风格实例。实验在多个数据集上证明，该方法生成的 intra- and inter-domain 数据显著提升了模型性能，并在所有人类活动识别任务中优于现有最先进 domain generalization (DG) 方法。",
      "categories": [
        "cs.LG",
        "cs.AI"
      ],
      "primary_category": "cs.LG",
      "comment": "The 30th ACM SIGKDD Conference on Knowledge Discovery and Data Mining\n  (KDD 2024)",
      "pdf_url": "http://arxiv.org/pdf/2406.04609v2",
      "published_date": "2024-06-07 03:37:30 UTC",
      "updated_date": "2024-06-29 03:15:51 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-18T17:40:38.505188"
    },
    {
      "arxiv_id": "2406.04607v4",
      "title": "MeGA: Merging Multiple Independently Trained Neural Networks Based on Genetic Algorithm",
      "title_zh": "翻译失败",
      "authors": [
        "Daniel Yun"
      ],
      "abstract": "In this paper, we introduce a novel method for merging the weights of\nmultiple pre-trained neural networks using a genetic algorithm called MeGA.\nTraditional techniques, such as weight averaging and ensemble methods, often\nfail to fully harness the capabilities of pre-trained networks. Our approach\nleverages a genetic algorithm with tournament selection, crossover, and\nmutation to optimize weight combinations, creating a more effective fusion.\nThis technique allows the merged model to inherit advantageous features from\nboth parent models, resulting in enhanced accuracy and robustness. Through\nexperiments on the CIFAR-10 dataset, we demonstrate that our genetic\nalgorithm-based weight merging method improves test accuracy compared to\nindividual models and conventional methods. This approach provides a scalable\nsolution for integrating multiple pre-trained networks across various deep\nlearning applications. Github is available at:\nhttps://github.com/YUNBLAK/MeGA-Merging-Multiple-Independently-Trained-Neural-Networks-Based-on-Genetic-Algorithm",
      "tldr_zh": "本论文提出了一种名为 MeGA 的新方法，使用 Genetic Algorithm 合并多个预训练神经网络的权重，通过锦标赛选择、交叉和变异优化权重组合，以继承父模型的优势并提升准确性和鲁棒性。与传统权重平均和集成方法相比，MeGA 能更有效地利用预训练网络的特性。在 CIFAR-10 数据集上的实验表明，该方法显著提高了测试准确率，提供了一个可扩展的解决方案，适用于各种深度学习应用。",
      "categories": [
        "cs.NE",
        "cs.AI",
        "cs.LG"
      ],
      "primary_category": "cs.NE",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2406.04607v4",
      "published_date": "2024-06-07 03:31:58 UTC",
      "updated_date": "2024-06-28 03:53:21 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-18T17:40:58.987918"
    },
    {
      "arxiv_id": "2406.04606v1",
      "title": "Helpful or Harmful Data? Fine-tuning-free Shapley Attribution for Explaining Language Model Predictions",
      "title_zh": "翻译失败",
      "authors": [
        "Jingtan Wang",
        "Xiaoqiang Lin",
        "Rui Qiao",
        "Chuan-Sheng Foo",
        "Bryan Kian Hsiang Low"
      ],
      "abstract": "The increasing complexity of foundational models underscores the necessity\nfor explainability, particularly for fine-tuning, the most widely used training\nmethod for adapting models to downstream tasks. Instance attribution, one type\nof explanation, attributes the model prediction to each training example by an\ninstance score. However, the robustness of instance scores, specifically\ntowards dataset resampling, has been overlooked. To bridge this gap, we propose\na notion of robustness on the sign of the instance score. We theoretically and\nempirically demonstrate that the popular leave-one-out-based methods lack\nrobustness, while the Shapley value behaves significantly better, but at a\nhigher computational cost. Accordingly, we introduce an efficient\nfine-tuning-free approximation of the Shapley value (FreeShap) for instance\nattribution based on the neural tangent kernel. We empirically demonstrate that\nFreeShap outperforms other methods for instance attribution and other\ndata-centric applications such as data removal, data selection, and wrong label\ndetection, and further generalize our scale to large language models (LLMs).\nOur code is available at https://github.com/JTWang2000/FreeShap.",
      "tldr_zh": "本研究探讨了语言模型预测的可解释性，特别关注instance attribution如何通过instance score将预测归因于训练样本，并强调了score对数据集重采样的鲁棒性问题。作者证明了传统的leave-one-out-based方法缺乏鲁棒性，而Shapley value更可靠但计算成本高，因此提出了一种高效的fine-tuning-free近似方法FreeShap，基于neural tangent kernel进行instance attribution。实验结果显示，FreeShap在instance attribution、数据移除、数据选择和错误标签检测等应用中优于其他方法，并成功扩展到大型语言模型(LLMs)，代码已在GitHub开源。",
      "categories": [
        "cs.LG",
        "cs.AI"
      ],
      "primary_category": "cs.LG",
      "comment": "Accepted to ICML 2024",
      "pdf_url": "http://arxiv.org/pdf/2406.04606v1",
      "published_date": "2024-06-07 03:29:57 UTC",
      "updated_date": "2024-06-07 03:29:57 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-18T17:41:11.112798"
    },
    {
      "arxiv_id": "2406.04598v1",
      "title": "OCDB: Revisiting Causal Discovery with a Comprehensive Benchmark and Evaluation Framework",
      "title_zh": "翻译失败",
      "authors": [
        "Wei Zhou",
        "Hong Huang",
        "Guowen Zhang",
        "Ruize Shi",
        "Kehan Yin",
        "Yuanyuan Lin",
        "Bang Liu"
      ],
      "abstract": "Large language models (LLMs) have excelled in various natural language\nprocessing tasks, but challenges in interpretability and trustworthiness\npersist, limiting their use in high-stakes fields. Causal discovery offers a\npromising approach to improve transparency and reliability. However, current\nevaluations are often one-sided and lack assessments focused on\ninterpretability performance. Additionally, these evaluations rely on synthetic\ndata and lack comprehensive assessments of real-world datasets. These lead to\npromising methods potentially being overlooked. To address these issues, we\npropose a flexible evaluation framework with metrics for evaluating differences\nin causal structures and causal effects, which are crucial attributes that help\nimprove the interpretability of LLMs. We introduce the Open Causal Discovery\nBenchmark (OCDB), based on real data, to promote fair comparisons and drive\noptimization of algorithms. Additionally, our new metrics account for\nundirected edges, enabling fair comparisons between Directed Acyclic Graphs\n(DAGs) and Completed Partially Directed Acyclic Graphs (CPDAGs). Experimental\nresults show significant shortcomings in existing algorithms' generalization\ncapabilities on real data, highlighting the potential for performance\nimprovement and the importance of our framework in advancing causal discovery\ntechniques.",
      "tldr_zh": "本论文探讨了因果发现（causal discovery）在提升大型语言模型（LLMs）的可解释性和可信度方面的潜力，并指出现有评估方法存在偏见、依赖合成数据和忽略真实数据集的问题。作者提出一个灵活的评估框架，包含评估因果结构和因果效果的指标，以更好地衡量LLMs的可解释性表现。新框架引入Open Causal Discovery Benchmark (OCDB)，基于真实数据，促进算法的公平比较和优化，同时通过处理无向边实现Directed Acyclic Graphs (DAGs)和Completed Partially Directed Acyclic Graphs (CPDAGs)之间的公平评估。实验结果显示，现有的因果发现算法在真实数据上泛化能力不足，突显了该框架在推动技术进步方面的价值。",
      "categories": [
        "cs.AI"
      ],
      "primary_category": "cs.AI",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2406.04598v1",
      "published_date": "2024-06-07 03:09:22 UTC",
      "updated_date": "2024-06-07 03:09:22 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-18T17:41:14.432856"
    },
    {
      "arxiv_id": "2406.04594v1",
      "title": "Boosting Large-scale Parallel Training Efficiency with C4: A Communication-Driven Approach",
      "title_zh": "使用 C4 提升大规模并行训练效率：一种通信驱动的方法",
      "authors": [
        "Jianbo Dong",
        "Bin Luo",
        "Jun Zhang",
        "Pengcheng Zhang",
        "Fei Feng",
        "Yikai Zhu",
        "Ang Liu",
        "Zian Chen",
        "Yi Shi",
        "Hairong Jiao",
        "Gang Lu",
        "Yu Guan",
        "Ennan Zhai",
        "Wencong Xiao",
        "Hanyu Zhao",
        "Man Yuan",
        "Siran Yang",
        "Xiang Li",
        "Jiamang Wang",
        "Rui Men",
        "Jianwei Zhang",
        "Huang Zhong",
        "Dennis Cai",
        "Yuan Xie",
        "Binzhang Fu"
      ],
      "abstract": "The emergence of Large Language Models (LLMs) has necessitated the adoption\nof parallel training techniques, involving the deployment of thousands of GPUs\nto train a single model. Unfortunately, we have found that the efficiency of\ncurrent parallel training is often suboptimal, largely due to the following two\nmain issues. Firstly, hardware failures are inevitable, leading to\ninterruptions in the training tasks. The inability to quickly identify the\nfaulty components results in a substantial waste of GPU resources. Secondly,\nsince GPUs must wait for parameter synchronization to complete before\nproceeding to the next round of computation, network congestions can greatly\nincrease the waiting time for GPUs. To address these challenges, this paper\nintroduces a communication-driven solution, namely the C4. The key insights of\nC4 are two folds. First, in parallel training, collective communication\nexhibits periodic and homogeneous characteristics, so any anomalies are\ncertainly due to some form of hardware malfunction. By leveraging this feature,\nC4 can rapidly identify the faulty components, swiftly isolate the anomaly, and\nrestart the task, thereby avoiding resource wastage caused by delays in anomaly\ndetection. Second, the predictable communication model of collective\ncommunication, involving few large flows, allows C4 to efficiently execute\ntraffic planning, substantially reducing network congestion. C4 has been\nextensively implemented across our production systems, cutting error-induced\noverhead by roughly 30% and enhancing runtime performance by about 15% for\ncertain applications with moderate communication costs.",
      "tldr_zh": "本文针对大型语言模型(LLMs)的并行训练问题，提出了一种通信驱动的方法C4，以解决硬件故障导致的资源浪费和网络拥塞引起的GPU等待时间延长。C4利用集体通信的周期性和同质性快速识别并隔离故障，同时通过流量规划优化通信模型，减少网络拥塞。实验结果显示，在生产系统中部署C4后，错误诱发开销降低约30%，并为某些通信成本适中的应用提升约15%的运行时性能。",
      "categories": [
        "cs.DC",
        "cs.AI",
        "cs.LG"
      ],
      "primary_category": "cs.DC",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2406.04594v1",
      "published_date": "2024-06-07 02:58:35 UTC",
      "updated_date": "2024-06-07 02:58:35 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-18T17:41:24.156162"
    },
    {
      "arxiv_id": "2406.04584v1",
      "title": "CLoG: Benchmarking Continual Learning of Image Generation Models",
      "title_zh": "CLoG：图像生成模型持续学习的基准测试",
      "authors": [
        "Haotian Zhang",
        "Junting Zhou",
        "Haowei Lin",
        "Hang Ye",
        "Jianhua Zhu",
        "Zihao Wang",
        "Liangcai Gao",
        "Yizhou Wang",
        "Yitao Liang"
      ],
      "abstract": "Continual Learning (CL) poses a significant challenge in Artificial\nIntelligence, aiming to mirror the human ability to incrementally acquire\nknowledge and skills. While extensive research has focused on CL within the\ncontext of classification tasks, the advent of increasingly powerful generative\nmodels necessitates the exploration of Continual Learning of Generative models\n(CLoG). This paper advocates for shifting the research focus from\nclassification-based CL to CLoG. We systematically identify the unique\nchallenges presented by CLoG compared to traditional classification-based CL.\nWe adapt three types of existing CL methodologies, replay-based,\nregularization-based, and parameter-isolation-based methods to generative tasks\nand introduce comprehensive benchmarks for CLoG that feature great diversity\nand broad task coverage. Our benchmarks and results yield intriguing insights\nthat can be valuable for developing future CLoG methods. Additionally, we will\nrelease a codebase designed to facilitate easy benchmarking and experimentation\nin CLoG publicly at https://github.com/linhaowei1/CLoG. We believe that\nshifting the research focus to CLoG will benefit the continual learning\ncommunity and illuminate the path for next-generation AI-generated content\n(AIGC) in a lifelong learning paradigm.",
      "tldr_zh": "这篇论文探讨了生成模型的持续学习（Continual Learning of Generative models，简称 CLoG），主张将研究焦点从传统的分类任务 CL 转向生成模型领域，以更好地模拟人类增量知识获取。作者识别了 CLoG 的独特挑战，并将三种现有 CL 方法（replay-based、regularization-based 和 parameter-isolation-based）适应到生成任务中，同时引入了多样性和广泛任务覆盖的综合基准。实验结果提供了宝贵见解，有助于未来 CLoG 方法的发展，并通过公开代码库（https://github.com/linhaowei1/CLoG）促进社区研究，推动 AI 生成内容（AIGC）向终身学习范式迈进。",
      "categories": [
        "cs.LG",
        "cs.AI",
        "cs.CV"
      ],
      "primary_category": "cs.LG",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2406.04584v1",
      "published_date": "2024-06-07 02:12:29 UTC",
      "updated_date": "2024-06-07 02:12:29 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-18T17:41:37.765312"
    },
    {
      "arxiv_id": "2406.04575v1",
      "title": "Optimization of geological carbon storage operations with multimodal latent dynamic model and deep reinforcement learning",
      "title_zh": "翻译失败",
      "authors": [
        "Zhongzheng Wang",
        "Yuntian Chen",
        "Guodong Chen",
        "Dongxiao Zhang"
      ],
      "abstract": "Maximizing storage performance in geological carbon storage (GCS) is crucial\nfor commercial deployment, but traditional optimization demands\nresource-intensive simulations, posing computational challenges. This study\nintroduces the multimodal latent dynamic (MLD) model, a deep learning framework\nfor fast flow prediction and well control optimization in GCS. The MLD model\nincludes a representation module for compressed latent representations, a\ntransition module for system state evolution, and a prediction module for flow\nresponses. A novel training strategy combining regression loss and\njoint-embedding consistency loss enhances temporal consistency and multi-step\nprediction accuracy. Unlike existing models, the MLD supports diverse input\nmodalities, allowing comprehensive data interactions. The MLD model, resembling\na Markov decision process (MDP), can train deep reinforcement learning agents,\nspecifically using the soft actor-critic (SAC) algorithm, to maximize net\npresent value (NPV) through continuous interactions. The approach outperforms\ntraditional methods, achieving the highest NPV while reducing computational\nresources by over 60%. It also demonstrates strong generalization performance,\nproviding improved decisions for new scenarios based on knowledge from previous\nones.",
      "tldr_zh": "这篇论文针对地质碳封存 (GCS) 操作的优化问题，引入了 Multimodal Latent Dynamic (MLD) 模型，这是一个深度学习框架，用于实现快速流体预测和井控优化。MLD 模型包括 representation module 用于压缩潜在表示、transition module 用于系统状态演化，以及 prediction module 用于流体响应预测，并采用结合 regression loss 和 joint-embedding consistency loss 的新颖训练策略，以提升时间一致性和多步预测准确性。最终，通过将 MLD 模型视为 Markov decision process (MDP) 并应用 soft actor-critic (SAC) 算法进行深度强化学习，该方法显著提高了净现值 (NPV)，比传统方法节省超过 60% 计算资源，并展示了出色的泛化性能。",
      "categories": [
        "cs.LG",
        "cs.AI",
        "stat.AP",
        "stat.ML"
      ],
      "primary_category": "cs.LG",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2406.04575v1",
      "published_date": "2024-06-07 01:30:21 UTC",
      "updated_date": "2024-06-07 01:30:21 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-18T17:41:50.138759"
    },
    {
      "arxiv_id": "2406.04568v1",
      "title": "StackSight: Unveiling WebAssembly through Large Language Models and Neurosymbolic Chain-of-Thought Decompilation",
      "title_zh": "翻译失败",
      "authors": [
        "Weike Fang",
        "Zhejian Zhou",
        "Junzhou He",
        "Weihang Wang"
      ],
      "abstract": "WebAssembly enables near-native execution in web applications and is\nincreasingly adopted for tasks that demand high performance and robust\nsecurity. However, its assembly-like syntax, implicit stack machine, and\nlow-level data types make it extremely difficult for human developers to\nunderstand, spurring the need for effective WebAssembly reverse engineering\ntechniques. In this paper, we propose StackSight, a novel neurosymbolic\napproach that combines Large Language Models (LLMs) with advanced program\nanalysis to decompile complex WebAssembly code into readable C++ snippets.\nStackSight visualizes and tracks virtual stack alterations via a static\nanalysis algorithm and then applies chain-of-thought prompting to harness LLM's\ncomplex reasoning capabilities. Evaluation results show that StackSight\nsignificantly improves WebAssembly decompilation. Our user study also\ndemonstrates that code snippets generated by StackSight have significantly\nhigher win rates and enable a better grasp of code semantics.",
      "tldr_zh": "该研究针对 WebAssembly 的复杂语法和低级特性导致的理解难题，提出了一种名为 StackSight 的神经符号(neurosymbolic)反编译方法。该方法结合 Large Language Models (LLMs) 和高级程序分析，通过静态分析算法可视化并跟踪虚拟堆栈变化，然后利用 chain-of-thought 提示激发 LLM 的复杂推理能力，将 WebAssembly 代码反编译成可读的 C++ 代码片段。实验评估显示，StackSight 显著提升了反编译的准确性和效率，用户研究进一步证明其生成的代码片段具有更高的胜率，并帮助开发者更好地把握代码语义。",
      "categories": [
        "cs.SE",
        "cs.AI",
        "cs.LG"
      ],
      "primary_category": "cs.SE",
      "comment": "9 pages. In the Proceedings of the 41st International Conference on\n  Machine Learning (ICML' 24)",
      "pdf_url": "http://arxiv.org/pdf/2406.04568v1",
      "published_date": "2024-06-07 01:08:17 UTC",
      "updated_date": "2024-06-07 01:08:17 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-18T17:41:59.805737"
    },
    {
      "arxiv_id": "2406.04566v1",
      "title": "SpaRC and SpaRP: Spatial Reasoning Characterization and Path Generation for Understanding Spatial Reasoning Capability of Large Language Models",
      "title_zh": "翻译失败",
      "authors": [
        "Md Imbesat Hassan Rizvi",
        "Xiaodan Zhu",
        "Iryna Gurevych"
      ],
      "abstract": "Spatial reasoning is a crucial component of both biological and artificial\nintelligence. In this work, we present a comprehensive study of the capability\nof current state-of-the-art large language models (LLMs) on spatial reasoning.\nTo support our study, we created and contribute a novel Spatial Reasoning\nCharacterization (SpaRC) framework and Spatial Reasoning Paths (SpaRP)\ndatasets, to enable an in-depth understanding of the spatial relations and\ncompositions as well as the usefulness of spatial reasoning chains. We found\nthat all the state-of-the-art LLMs do not perform well on the datasets -- their\nperformances are consistently low across different setups. The spatial\nreasoning capability improves substantially as model sizes scale up. Finetuning\nboth large language models (e.g., Llama-2-70B) and smaller ones (e.g.,\nLlama-2-13B) can significantly improve their F1-scores by 7--32 absolute\npoints. We also found that the top proprietary LLMs still significantly\noutperform their open-source counterparts in topological spatial understanding\nand reasoning.",
      "tldr_zh": "本研究评估了大型语言模型(LLMs)的空间推理能力，提出并贡献了Spatial Reasoning Characterization (SpaRC)框架和Spatial Reasoning Paths (SpaRP)数据集，以深入分析空间关系、组合和推理链。实验结果显示，当前状态LLMs在这些数据集上的表现普遍不佳，但模型规模增大能显著提升空间推理能力，而微调（如Llama-2-70B和Llama-2-13B）可使F1-scores提高7-32绝对点。总体而言，顶级专有LLMs在拓扑空间理解和推理方面仍优于开源模型，为未来LLMs改进提供了关键洞见。",
      "categories": [
        "cs.CL",
        "cs.AI",
        "cs.LG"
      ],
      "primary_category": "cs.CL",
      "comment": "Accepted at ACL 2024 (Main)",
      "pdf_url": "http://arxiv.org/pdf/2406.04566v1",
      "published_date": "2024-06-07 01:06:34 UTC",
      "updated_date": "2024-06-07 01:06:34 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-18T17:42:15.603727"
    },
    {
      "arxiv_id": "2406.06613v2",
      "title": "GameBench: Evaluating Strategic Reasoning Abilities of LLM Agents",
      "title_zh": "翻译失败",
      "authors": [
        "Anthony Costarelli",
        "Mat Allen",
        "Roman Hauksson",
        "Grace Sodunke",
        "Suhas Hariharan",
        "Carlson Cheng",
        "Wenjie Li",
        "Joshua Clymer",
        "Arjun Yadav"
      ],
      "abstract": "Large language models have demonstrated remarkable few-shot performance on\nmany natural language understanding tasks. Despite several demonstrations of\nusing large language models in complex, strategic scenarios, there lacks a\ncomprehensive framework for evaluating agents' performance across various types\nof reasoning found in games. To address this gap, we introduce GameBench, a\ncross-domain benchmark for evaluating strategic reasoning abilities of LLM\nagents. We focus on 9 different game environments, where each covers at least\none axis of key reasoning skill identified in strategy games, and select games\nfor which strategy explanations are unlikely to form a significant portion of\nmodels' pretraining corpuses. Our evaluations use GPT-3 and GPT-4 in their base\nform along with two scaffolding frameworks designed to enhance strategic\nreasoning ability: Chain-of-Thought (CoT) prompting and Reasoning Via Planning\n(RAP). Our results show that none of the tested models match human performance,\nand at worst GPT-4 performs worse than random action. CoT and RAP both improve\nscores but not comparable to human levels.",
      "tldr_zh": "本文引入了GameBench，这是一个跨领域基准，用于评估大型语言模型(LLM)代理在游戏中的战略推理能力，涵盖9个游戏环境，每个针对至少一种关键推理技能，如决策和规划。评估使用了GPT-3和GPT-4的基础版本，以及Chain-of-Thought (CoT)提示和Reasoning Via Planning (RAP)框架来增强模型性能。结果显示，所有测试模型均未达到人类水平表现，最差时GPT-4甚至不如随机行动，而CoT和RAP虽提高了分数，但仍远低于人类基准。",
      "categories": [
        "cs.CL",
        "cs.AI"
      ],
      "primary_category": "cs.CL",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2406.06613v2",
      "published_date": "2024-06-07 00:28:43 UTC",
      "updated_date": "2024-07-22 14:32:33 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-18T17:42:26.688862"
    },
    {
      "arxiv_id": "2406.04555v1",
      "title": "Creating an AI Observer: Generative Semantic Workspaces",
      "title_zh": "创建 AI 观察者：生成式语义工作空间",
      "authors": [
        "Pavan Holur",
        "Shreyas Rajesh",
        "David Chong",
        "Vwani Roychowdhury"
      ],
      "abstract": "An experienced human Observer reading a document -- such as a crime report --\ncreates a succinct plot-like $\\textit{``Working Memory''}$ comprising different\nactors, their prototypical roles and states at any point, their evolution over\ntime based on their interactions, and even a map of missing Semantic parts\nanticipating them in the future. $\\textit{An equivalent AI Observer currently\ndoes not exist}$. We introduce the $\\textbf{[G]}$enerative\n$\\textbf{[S]}$emantic $\\textbf{[W]}$orkspace (GSW) -- comprising an\n$\\textit{``Operator''}$ and a $\\textit{``Reconciler''}$ -- that leverages\nadvancements in LLMs to create a generative-style Semantic framework, as\nopposed to a traditionally predefined set of lexicon labels. Given a text\nsegment $C_n$ that describes an ongoing situation, the $\\textit{Operator}$\ninstantiates actor-centric Semantic maps (termed ``Workspace instance''\n$\\mathcal{W}_n$). The $\\textit{Reconciler}$ resolves differences between\n$\\mathcal{W}_n$ and a ``Working memory'' $\\mathcal{M}_n^*$ to generate the\nupdated $\\mathcal{M}_{n+1}^*$. GSW outperforms well-known baselines on several\ntasks ($\\sim 94\\%$ vs. FST, GLEN, BertSRL - multi-sentence Semantics\nextraction, $\\sim 15\\%$ vs. NLI-BERT, $\\sim 35\\%$ vs. QA). By mirroring the\nreal Observer, GSW provides the first step towards Spatial Computing assistants\ncapable of understanding individual intentions and predicting future behavior.",
      "tldr_zh": "论文提出 Generative Semantic Workspace (GSW) 框架，以创建 AI 观察者，模仿人类在阅读文档（如犯罪报告）时生成简洁的情节式“工作记忆”，包括角色状态、互动演变和缺失部分预测。GSW 由 Operator 和 Reconciler 组成，利用大型语言模型 (LLMs) 处理文本段，生成 actor-centric 的语义地图并更新工作记忆，从而实现生成式语义框架，而非预定义标签。在多项任务上，GSW 显著超越基线模型（如 FST 和 BertSRL，准确率约 94%；NLI-BERT 提升 15%，QA 提升 35%），为开发理解个体意图和预测未来行为的 Spatial Computing 助手奠定基础。",
      "categories": [
        "cs.CL",
        "cs.AI"
      ],
      "primary_category": "cs.CL",
      "comment": "37 pages with appendix, 28 figures",
      "pdf_url": "http://arxiv.org/pdf/2406.04555v1",
      "published_date": "2024-06-07 00:09:13 UTC",
      "updated_date": "2024-06-07 00:09:13 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-18T17:42:41.116940"
    }
  ],
  "raw_papers_fetched": true,
  "papers_count": 123,
  "processed_papers_count": 123,
  "failed_papers_count": 0,
  "summary_generated": true,
  "daily_data_saved": true,
  "last_update": "2025-05-18T17:43:11.948796"
}