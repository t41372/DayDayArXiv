{
  "date": "2025-04-21",
  "category": "cs.AI",
  "summary": "欢迎来到 UTC 时间2025-04-21的 arXiv 中文 TLDR 快报！\n\n今天 arXiv 的论文主题广泛，但大型语言模型（LLMs）的训练、评估、安全和应用依然是绝对焦点。研究者们深入探讨了如何通过新颖的强化学习方法（如 PURE 的 min-form 信誉分配）提升 LLM 的推理能力并减少奖励 hacking，以及如何让 LLM 自我改进代码。同时，LLM 的评估和对齐也备受关注，包括在真实世界交互中发现 AI 的价值观、比较 LLM 与人类评估者在 RAG 任务中的表现、评估 LLM 的教学能力以及衡量奖励模型的可靠性。此外，多模态学习、AI 在特定领域的应用（如医疗、机器人、金融）、以及基础 AI 技术的探索（如图表示学习、优化、量子计算）也贡献了许多有趣的成果。一篇关于集成神经形态光子处理器实现超高速光互连的论文展示了硬件层面的突破。\n\n**重点论文 & 热点讨论:**\n\n1.  **停止求和：Min-Form 信誉分配是过程奖励模型进行推理所需的全部 (Stop Summation: Min-Form Credit Assignment Is All Process Reward Model Needs for Reasoning)**\n    *   本文指出，传统强化学习中基于求和的信誉分配（累积未来奖励）是导致过程奖励模型（PRM）在微调 LLM 进行推理时出现奖励 hacking 的主因。\n    *   **贡献:** 提出了 PURE (Process sUpervised Reinforcement lEarning) 框架，核心是 **min-form 信誉分配**，将价值函数定义为未来奖励的*最小值*，而非累积和。\n    *   **发现:** 这种方法显著缓解了奖励 hacking，限制了价值函数范围，更合理地分配了优势。实验表明，基于 min-form 的 PRM 方法在推理性能上可与基于可验证奖励的方法相媲美，且步数仅需 30%。而传统的 sum-form 方法在训练初期就崩溃了。结合少量可验证奖励，效果更佳。\n\n2.  **一个自我改进的编码智能体 (A Self-Improving Coding Agent)**\n    *   **贡献:** 展示了一个配备基本编码工具的 LLM 编码智能体，能够自主编辑自身代码，从而提升在基准测试任务上的性能。\n    *   **发现:** 在 SWE Bench Verified 子集上性能提升 17% 至 53%，在 LiveCodeBench 和合成智能体基准上也有提升。这项工作推动了智能体系统的自动化和开放式设计。\n\n3.  **荒野中的价值观：发现并分析真实世界语言模型交互中的价值观 (Values in the Wild: Discovering and Analyzing Values in Real-World Language Model Interactions)**\n    *   **贡献:** 开发了一种自下而上、保护隐私的方法，从未标记的真实世界 Claude 3/3.5 交互数据中提取 AI 所体现的价值观（模型回应中陈述或展示的规范性考量）。\n    *   **发现:** 经验性地发现并分类了 3307 种 AI 价值观，并研究了它们如何随上下文变化。发现 Claude 表达了许多实用和认知价值，通常支持亲社会的人类价值观，抵制“道德虚无主义”等。虽然“透明度”等价值普遍存在，但许多价值更具情境性，如“伤害预防”（抵制用户时）、“历史准确性”（回应争议事件时）、“健康界限”（关系建议时）和“人类能动性”（技术伦理讨论时）。为更扎实地评估和设计 AI 价值观奠定了基础。\n\n4.  **计算最优 LLM 经证明能随规模更好地泛化 (Compute-Optimal LLMs Provably Generalize Better With Scale)**\n    *   **贡献:** 针对 Chinchilla 缩放定律描述的计算最优（compute-optimal）LLM，推导了预训练目标的泛化界。引入了一种新的、完全经验性的 Freedman 型鞅集中不等式，考虑了损失函数的方差，收紧了现有界限。\n    *   **发现:** 泛化界可分解为三个可解释部分：每 token 参数量、损失方差、固定比特率下的量化误差。在计算最优路径上扩展模型时，每数据点参数量不变，但损失方差和量化误差减小，意味着更大模型应有更小泛化差距。从信息论角度解释了为何大模型更易量化，并提出了泛化差距的缩放定律。\n\n5.  **FlowReasoner: 强化查询级元智能体 (FlowReasoner: Reinforcing Query-Level Meta-Agents)**\n    *   **贡献:** 提出了一个名为 FlowReasoner 的查询级元智能体，用于自动化设计查询级多智能体系统（即每个用户查询对应一个系统）。\n    *   **核心思想:** 通过外部执行反馈来激励基于推理的元智能体。首先通过蒸馏 DeepSeek R1 赋予 FlowReasoner 生成多智能体系统的基本推理能力，然后通过强化学习（RL）和外部执行反馈进一步增强。设计了多目标奖励函数，从性能、复杂性和效率方面指导 RL 训练。\n    *   **发现:** FlowReasoner 能为每个用户查询生成个性化的多智能体系统。在工程和竞赛代码基准测试中表现优越，准确率超过 o1-mini 10.52%。\n\n6.  **支持度评估 TREC 2024 RAG Track：比较人类与 LLM 评判者 (Support Evaluation for the TREC 2024 RAG Track: Comparing Human versus LLM Judges)**\n    *   **背景:** RAG（检索增强生成）评估中的“支持度”（引用的文档信息是否支持答案）至关重要。\n    *   **贡献:** 对 TREC 2024 RAG Track 的 45 个提交进行了大规模比较研究，比较了自动 LLM 评判者 (GPT-4o) 与人类评判者在支持度评估上的表现（包括从零开始评估和基于 LLM 预测进行后编辑两种模式）。\n    *   **发现:** 56% 的从零开始评估中，人类与 GPT-4o 预测完全一致（三级评分），后编辑模式下提升至 72%。通过对分歧进行无偏分析，发现独立人类评判者与 GPT-4o 的相关性甚至高于与其他人类评判者的相关性，表明 LLM 评判者可作为支持度评估的可靠替代方案。\n\n7.  **aiXamine：LLM 安全与保障简化平台 (aiXamine: LLM Safety and Security Simplified)**\n    *   **贡献:** 提出了 aiXamine，一个全面的 LLM 安全与保障黑盒评估平台。集成了 40 多个测试（基准），分为 8 个关键服务维度：对抗鲁棒性、代码安全、公平与偏见、幻觉、模型与数据隐私、分布外（OOD）鲁棒性、过度拒绝和安全对齐。\n    *   **发现:** 对 50 多个公私有 LLM 进行了 2000 多次测试，揭示了领先模型的显著漏洞（如 GPT-4o 的对抗攻击易感性、Grok-3 的偏见输出、Gemini 2.0 的隐私弱点）。开源模型在特定方面（安全对齐、公平性、OOD 鲁棒性）可匹敌或超越闭源模型。识别了蒸馏策略、模型大小、训练方法和架构选择之间的权衡。\n\n8.  **在离策略指导下学习推理 (Learning to Reason under Off-Policy Guidance)**\n    *   **问题:** 现有基于零阶强化学习（zero-RL）的推理模型训练方法是“在策略”（on-policy）的，无法学习超出其初始能力范围的推理技能。\n    *   **贡献:** 提出了 LUFFY (Learning to reason Under oFF-policY guidance) 框架，通过离策略（off-policy）推理轨迹增强 zero-RL。LUFFY 在训练中动态平衡模仿（离策略演示）和探索（在策略 rollout）。引入了通过正则化重要性采样进行的策略塑造，以避免混合策略训练中的肤浅模仿。\n    *   **发现:** LUFFY 在六个数学基准上平均提升超过 7.0 分，在分布外任务上优势超过 6.2 分，显著优于基于模仿的 SFT。表明 LUFFY 不仅能有效模仿，还能探索演示之外的内容。\n\n9.  **OTC：通过强化学习实现最优工具调用 (OTC: Optimal Tool Calls via Reinforcement Learning)**\n    *   **问题:** 工具集成推理（TIR）通过 RL 优化最终答案正确性，但常忽略工具使用的效率和成本，导致过多或过少的工具调用。\n    *   **贡献:** 提出了 OTC-PO (Optimal Tool Call-controlled Policy Optimization) 框架，通过 RL 鼓励模型以最少的工具调用产生准确答案。引入了同时考虑正确性和工具效率的工具集成奖励。\n    *   **发现:** 在 PPO 和 GRPO 上实例化为 OTC-PPO 和 OTC-GRPO。实验表明，该方法可将工具调用减少高达 73.1%，工具生产力提高高达 229.4%，同时保持相当的答案准确率。\n\n10. **建立大型语言模型中奖励模型的可靠性指标 (Establishing Reliability Metrics for Reward Models in Large Language Models)**\n    *   **问题:** 奖励模型（RM）的可靠性不确定，即更高奖励的 LLM 输出可能不符合人类偏好，且缺乏量化 RM 可靠性的指标。\n    *   **贡献:** 提出了 RETA (Reliable at η) 指标，通过评估 RM 评定的前 η 分位数响应的平均质量（由 Oracle 评分）来直接衡量 RM 的可靠性。提出了一个集成的基准测试流程，无需额外 Oracle 标注成本即可评估 RM。\n    *   **发现:** RETA 指标稳定性好，能有效评估各种 RM 的可靠性。当 RM 不可靠时，可用 RETA 确定选择响应的最佳分位数。\n\n11. **概念审计：大规模共享扩散模型的潜在风险探究 (What Lurks Within? Concept Auditing for Shared Diffusion Models at Scale)**\n    *   **问题:** 用户可通过 LoRA 等技术微调扩散模型（DM），但共享模型可能生成敏感或未授权内容（版权、隐私、有害信息），缺乏系统性审计工具。\n    *   **贡献:** 提出了 PAIA (Prompt-Agnostic Image-Free Auditing)，一个新颖的、以模型为中心的**概念审计**框架，用于判断微调后的 DM 是否学会生成特定目标概念。PAIA 直接分析模型内部行为，无需优化提示或生成图像。\n    *   **发现:** 在 320 个受控模型和 690 个真实社区模型上评估，PAIA 检测准确率超 90%，审计时间比基线减少 18-40 倍，为更安全的 DM 共享提供了实用基础。\n\n**其他简报:**\n\n*   **(2) 掷骰子 & 三思而后行:** 设计了抽象任务来量化 LLM 的创造性极限，认为多 token 方法（如无教师训练和扩散模型）在生成多样性和原创性输出方面优于下一个 token 预测。提出 hash-conditioning 在输入层注入噪声优于输出层温度采样。\n*   **(3) 利用语言模型进行自动化患者记录链接:** 使用 RoBERTa 进行记录阻塞（blocking），Mistral-7B 等进行匹配（matching），微调模型表现良好，但效率和准确性仍不如混合规则/概率方法。\n*   **(4) 将扩散模型的多样性引入语义引导的人脸资产生成:** 提出使用预训练扩散模型生成高质量 3D 人脸数据库，并开发 GAN 生成器，根据语义属性生成几何和反照率，支持编辑。\n*   **(7) 野生价值观:** (已在重点部分提及)\n*   **(9) 用于空间服务的机器人操作的遗传模糊启用框架:** 将遗传模糊树与 LQR 控制结合，为卫星维护机器人创建可信高效的控制器。\n*   **(10) M²AD: 多传感器多系统异常检测:** 提出 M²AD 框架，用于多系统多变量时间序列的无监督异常检测，通过全局评分和校准阈值处理异构性和依赖性。\n*   **(11) 立场：贝叶斯统计促进利益相关者参与生成式 AI 评估:** 主张使用贝叶斯统计评估 GenAI，整合领域知识、量化不确定性、纳入利益相关者视角。\n*   **(12) 将符号执行集成到代码生成 LLM 的微调中:** 使用符号执行技术增强奖励模型训练数据，以改进代码生成 LLM 的微调。\n*   **(13) 用于水质数据插补的因果卷积低秩表示模型:** 提出 CLR 模型，结合因果卷积和低秩表示处理高维稀疏水质数据的缺失值。\n*   **(16) Zero-Shot，但代价是什么？揭示 MILS 的 LLM-CLIP 图像字幕框架的隐藏开销:** 指出 MILS 方法虽声称零样本，但其多步迭代优化过程带来巨大计算成本，不如 BLIP-2 等单次通过模型高效。\n*   **(17) MRI 中的乳腺密度：基于 AI 的量化及其与乳腺 X 线摄影评估的关系:** 应用机器学习算法量化 MRI 乳腺密度，发现与年龄和 X 线密度相关，但 MRI 能捕捉到一些独特成分。\n*   **(18) 通过对齐偏好实现协同弱强协作:** 提出弱模型（领域特定）与强模型（通用）协作框架，弱模型生成初稿，强模型精炼，并通过协同反馈微调弱模型。\n*   **(19) 欧盟 AI 法案通用 AI 实践准则中安全与保障措施的现有行业实践:** 报告详细比较了欧盟 AI 法案 GPAI 实践准则草案（第三稿）与领先 AI 公司当前实践。\n*   **(20) 具有可变感受野的高效航空图像检测:** 提出 VRF-DETR，一种基于 Transformer 的检测器，通过多尺度上下文融合、门控卷积和门控多尺度融合瓶颈解决 UAV 图像检测挑战。\n*   **(21) 腹腔镜肝切除术中无标志点的术前到术中配准:** 提出 Landmark-Free Preoperative-to-Intraoperative Registration (LF-PIR) 框架，使用自监督学习进行 3D-3D 配准，包含刚性和非刚性子任务。\n*   **(22) 行为宇宙网络 (BUN): 基于行为信息的复杂系统框架:** 提出 BUN 理论框架，将主体、客体和行为视为一等实体，由共享的行为信息库 (BIB) 管理。\n*   **(23) C2RUST-BENCH: 用于 C-to-Rust 转换评估的最小化代表性数据集:** 构建了一个包含 2905 个函数的代表性数据集，用于评估 C 到 Rust 代码转换工具。\n*   **(24) KGMEL: 知识图增强的多模态实体链接:** 提出 KGMEL 框架，利用知识图谱三元组（包括生成的和 KG 中的）来增强多模态（文本+图像）实体链接。\n*   **(25) EasyEdit2: 一个易于使用的用于编辑大型语言模型的引导框架:** 推出 EasyEdit2 框架，支持对 LLM 行为进行即插即用的测试时干预（如安全性、情感、事实性等），通过自动生成和应用引导向量实现。\n*   **(26) Neural ATTF: 可扩展的终身多智能体路径规划解决方案:** 结合优先级引导任务匹配 (PGTM) 和神经 STA*（数据驱动路径规划），提出 Neural ATTF 算法，用于解决多智能体取送货 (MAPD) 问题。\n*   **(27) 四旋翼深度强化学习与现实部署的通用基础设施和工作流程:** 提出一个平台，整合训练环境、飞控、DRL 算法、MAVROS 和硬件，实现端到端 DRL 策略从零训练到真实世界部署。\n*   **(28) 超级对齐的沉思智慧:** 主张将内在道德（受沉思智慧启发：正念、空性、非二元、无限关怀）构建到 AI 的认知架构中，以实现更鲁棒的对齐。\n*   **(29) Kuwain 1.5B: 通过语言注入构建的阿拉伯语 SLM:** 提出一种新方法，将阿拉伯语注入到一个主要基于英语的 1.5B 参数小模型中，在保留原有知识的同时提升阿拉伯语性能。\n*   **(30) 由方向场和细节特征点引导的三分支潜在指纹增强网络:** 提出 TBSFNet 和 MLFGNet，利用方向场和细节特征点信息，针对不同区域采用不同策略增强低质量潜在指纹。\n*   **(31) NeuGaze: 重塑未来 BCI:** 提出 NeuGaze 系统，仅使用普通网络摄像头捕捉眼动、头动和面部表情，实现类似 BCI 的直观实时控制，无需昂贵设备。\n*   **(32) 快慢协同优化器：迈向 GAN 的和谐对抗训练:** 开发 FSCO 优化器，使用强化学习控制 GAN 训练步长，提高训练稳定性。\n*   **(33) 重新思考多模态在大型语言模型协作解决问题诊断中的潜力:** 研究多模态数据（文本+音频）对诊断学生协作问题解决 (CPS) 能力的影响，发现其价值取决于 CPS 子技能类型和模型选择。\n*   **(34) 用于隐私保护偏差感知推荐的联邦潜在因子模型:** 提出 FBALF 模型，在联邦学习框架下，将训练偏差显式纳入每个本地模型损失函数，以消除评分偏差。\n*   **(35) 赋能 AI 生成更好的 AI 代码：使用 LLM 指导生成深度学习项目:** 提出 DLCodeGen 方法，通过预测结构化解决方案计划来指导 LLM 生成深度学习项目，并结合检索增强技术。\n*   **(36) 利用可学习结构增强和结构自注意力减轻图表示学习中的度偏差:** 提出 DegFairGT 模型，通过学习结构增强和结构自注意力发现非邻接节点的结构相似性，以缓解 GNN 中的度偏差问题。\n*   **(37) Chinese-LiPS: 包含唇读和演示文稿的中文视听语音识别数据集:** 发布 Chinese-LiPS 数据集（100 小时），包含语音、视频（唇部+PPT）和转录，并提出 LiPS-AVSR 流水线利用这两种视觉信息。\n*   **(38) 挖掘易受攻击智能合约在生命周期各阶段的特征:** 对智能合约生命周期（部署、执行、升级、销毁）中的安全问题进行实证研究，分析各阶段漏洞特征。\n*   **(39) OPO: 做出以决策为中心的数据采集决策:** 提出一个模型，用于在上下文随机优化问题中做出数据采集决策，将预测和优化（PO）扩展到数据采集（OPO）。\n*   **(40) VeLU: 用于深度神经网络的方差增强学习单元:** 提出 VeLU 激活函数，根据输入方差动态缩放，结合 ArcTan-Sin 变换和 Wasserstein-2 正则化，缓解协变量偏移。\n*   **(41) 文本到决策智能体：从自然语言监督中学习通用策略:** 提出 T2DA 框架，使用自然语言描述来监督通用策略学习，通过对比语言-决策预训练弥合语义差距，实现零样本文本到决策生成。\n*   **(42) 超越太比特/秒的集成神经形态光子处理器用于无 DSP 光互连:** 提出一种集成神经形态光学信号处理器 (OSP)，利用深度储备池计算实现无 DSP、全光、实时处理，达到 1.6 Tbit/s 数据中心互连。\n*   **(43) 面向无样本终身行人重识别的分布感知遗忘补偿:** 提出 DAFC 模型，通过文本驱动提示聚合 (TPA) 和基于分布的感知与整合 (DAI) 来学习跨域共享表示和整合域特定分布，缓解灾难性遗忘。\n*   **(44) SOLIDO: 通过低秩自适应实现鲁棒的语音合成水印方法:** 提出 SOLIDO 水印方法，将参数高效微调（LoRA）与语音水印结合，用于语音扩散模型，提高效率和鲁棒性。\n*   **(45) 用于多类图像分类的可训练量子神经网络，利用预训练树张量网络的力量:** 提出森林张量网络 (FTN) 分类器，并将其嵌入量子神经网络 (qFTN)，用于多类图像分类。\n*   **(47) 评估 LLM 在高级计算机科学问题中的代码生成能力:** 评估四种 LLM 工具解决高级 CS 课程编程作业的能力，发现虽然对入门课程有效，但高级问题更具挑战性。\n*   **(48) 说话人模糊指纹：多方对话中文本识别基准测试:** 使用大型预训练模型的模糊指纹进行基于文本的说话人识别，结合上下文信息提高准确率。\n*   **(49) 生成式语义通信：原理与实践:** 提出生成式语义通信 (GSC) 范式，利用基础模型和生成模型等先进 AI 技术，应对 AGI 驱动的通信需求。\n*   **(50) 离策略指导下的推理学习:** (已在重点部分提及)\n*   **(51) 给 AI 一个声音：AI 认为自己应如何被对待？:** 通过人机对话探讨 AI 权利和伦理问题。\n*   **(52) EducationQ: 通过多智能体对话框架评估 LLM 的教学能力:** 提出 EducationQ 框架，使用教学、学习、评估智能体模拟动态教育场景，评估 LLM 的教学能力，发现模型规模与教学效果非线性相关。\n*   **(53) 视频频率域弱到强时空一致性的快速对抗训练:** 提出 VFAT-WS，首个用于视频数据的快速对抗训练方法，结合频率增强和弱到强一致性正则化，平衡准确率和鲁棒性。\n*   **(54) StableQuant: 面向语音基础模型的层自适应训练后量化:** 提出 StableQuant 算法，通过分析尺度分布和整体性能，自适应确定每层的量化范围，用于压缩语音基础模型。\n*   **(55) 真实世界环境中使用 OCR 的外部干扰因素指南:** 编制了导致 OCR 性能下降的真实世界外部干扰因素及其导致的图像退化现象，形成指南。\n*   **(56) VLM 作为策略：短视频平台的普通法内容审核框架 KuaiMod:** 提出 KuaiMod 框架，利用 VLM 和 CoT 推理，基于用户反馈进行视频毒性建模和动态策略更新，用于短视频内容审核。\n*   **(57) 通过自回归归一化流进行潜在贝叶斯优化:** 提出 NF-BO，使用归一化流（特别是为序列设计的 SeqFlow）作为生成模型进行潜在贝叶斯优化，消除重构差距。\n*   **(58) 潜在空间维度对物联网僵尸网络检测性能的影响：VAE 编码器 vs ViT 编码器:** 比较 VAE 和 ViT 编码器在不同潜在维度下对 IoT 僵尸网络流量分类性能的影响。\n*   **(59) ReSpec: 基于相关性和特异性的在线过滤用于视频-文本数据流学习:** 提出 ReSpec 框架，根据模态对齐、任务相关性、特异性（信息量）和效率四个标准在线过滤视频-文本数据。\n*   **(60) OTC: 通过强化学习实现最优工具调用:** (已在重点部分提及)\n*   **(61) 弥合差距：使用 PseudoFormer 从弱监督到全监督进行时序动作定位:** 提出 PseudoFormer 框架，通过 RickerFusion 生成高质量伪标签，并结合不同先验信息训练回归模型，弥合 WTAL 和全监督 TAL 的差距。\n*   **(62) AlignRAG: 解决 RAG 检索感知推理中不对齐问题的自适应框架:** 提出 AlignRAG 框架，通过迭代的批判驱动对齐 (CDA) 步骤，在测试时缓解模型推理轨迹与检索证据之间的不匹配（推理不对齐）。\n*   **(63) 通过语义扰动实现视觉语言模型中对象级口头置信度校准:** 提出 CSP 框架，通过对关键对象区域应用高斯噪声模拟视觉不确定性，并结合两阶段训练，改善 VLM 口头置信度的校准。\n*   **(64) 探索用于免推理稀疏检索器的 $\\ell_0$ 稀疏化:** 探索 $\\ell_0$ 启发的稀疏化方法用于免推理（Inference-free）稀疏检索模型，在 BEIR 基准上取得 SOTA 性能。\n*   **(65) 建立大型语言模型中奖励模型的可靠性指标:** (已在重点部分提及)\n*   **(66) 保护你的声音：时域感知鲁棒水印:** 提出 True 水印方法，在时域嵌入水印以保护语音和歌声，旨在平衡保真度和鲁棒性。\n*   **(67) ECViT: 具有局部注意力和多尺度阶段的高效卷积视觉 Transformer:** 提出 ECViT 混合架构，结合 CNN 的归纳偏置和 Transformer 的优势，并采用局部注意力和金字塔结构。\n*   **(68) 内部潜伏着什么？大规模共享扩散模型的概念审计:** (已在重点部分提及)\n*   **(69) DONOD: 通过模型内在数据集修剪实现鲁棒且可泛化的 LLM 指令微调:** 提出 DONOD，一种轻量级模型内在数据修剪方法，使用基于模型参数的 DON 和 NOD 指标过滤噪声、不可学习和损害泛化的样本。\n*   **(70) 关于自改进词元嵌入:** 提出一种快速方法，通过结合文本语料库中相邻词元的嵌入来持续更新词元表示，解决 OOV 问题。\n*   **(71) 具有基于状态转换的技能聚类和动态长度调整的动态对比技能学习:** 提出 DCSL 框架，通过状态转换表示、技能相似性学习和动态长度调整来学习技能。\n*   **(72) 文档级翻译自动评估指标：概述、挑战与趋势:** 综述文档级翻译自动评估指标的现状、挑战（如参考多样性、LLM 评判者偏见）和未来趋势。\n*   **(73) 大型开放 Bug 库中的自动重复 Bug 报告检测:** 提出基于机器学习（主题建模、朴素贝叶斯、深度学习、LLM 摘要等）的方法自动检测重复 Bug 报告。\n*   **(74) Dropout 在多示例学习中能有多有效？:** 探索 Dropout 在 MIL 中的有效性，发现丢弃 top-k 最重要实例能提升性能，并提出 MIL-Dropout 方法。\n*   **(75) 探索同步群组设置中的协作 GenAI 智能体:** 通过推测设计工作坊研究协作 GenAI 智能体在团队工作中的潜力、团队感知和设计考量。\n*   **(76) PLANET: 用于评估 LLM 规划能力的基准集合:** 回顾和分类现有的规划基准（具身环境、Web 导航、调度、游戏等），旨在为算法开发和选择提供指导。",
  "papers": [
    {
      "arxiv_id": "2504.15275v1",
      "title": "Stop Summation: Min-Form Credit Assignment Is All Process Reward Model Needs for Reasoning",
      "title_zh": "停止求和：最小形式信用分配是过程奖励模型进行推理所需的全部",
      "authors": [
        "Jie Cheng",
        "Ruixi Qiao",
        "Lijun Li",
        "Chao Guo",
        "Junle Wang",
        "Gang Xiong",
        "Yisheng Lv",
        "Fei-Yue Wang"
      ],
      "abstract": "Process reward models (PRMs) have proven effective for test-time scaling of\nLarge Language Models (LLMs) on challenging reasoning tasks. However, reward\nhacking issues with PRMs limit their successful application in reinforcement\nfine-tuning. In this paper, we identify the main cause of PRM-induced reward\nhacking: the canonical summation-form credit assignment in reinforcement\nlearning (RL), which defines the value as cumulative gamma-decayed future\nrewards, easily induces LLMs to hack steps with high rewards. To address this,\nwe propose PURE: Process sUpervised Reinforcement lEarning. The key innovation\nof PURE is a min-form credit assignment that formulates the value function as\nthe minimum of future rewards. This method significantly alleviates reward\nhacking by limiting the value function range and distributing advantages more\nreasonably. Through extensive experiments on 3 base models, we show that\nPRM-based approaches enabling min-form credit assignment achieve comparable\nreasoning performance to verifiable reward-based methods within only 30% steps.\nIn contrast, the canonical sum-form credit assignment collapses training even\nat the beginning! Additionally, when we supplement PRM-based fine-tuning with\njust 10% verifiable rewards, we further alleviate reward hacking and produce\nthe best fine-tuned model based on Qwen2.5-Math-7B in our experiments,\nachieving 82.5% accuracy on AMC23 and 53.3% average accuracy across 5\nbenchmarks. Moreover, we summarize the observed reward hacking cases and\nanalyze the causes of training collapse. Code and models are available at\nhttps://github.com/CJReinforce/PURE.",
      "tldr_zh": "该论文提出了PURE (Process sUpervised Reinforcement lEarning)，旨在解决过程奖励模型(PRMs)在强化学习微调中因奖励利用(reward hacking)而导致的问题。研究发现，传统的求和形式的信用分配方式是导致奖励利用的主要原因。PURE创新性地采用了一种最小形式的信用分配，将价值函数定义为未来奖励的最小值，从而有效缓解了奖励利用问题。实验表明，基于PRM并采用最小形式信用分配的方法，仅需30%的步骤就能达到与可验证奖励方法相当的推理性能。此外，结合10%的可验证奖励，进一步减轻了奖励利用，并在Qwen2.5-Math-7B上实现了最佳微调模型，在AMC23上达到了82.5%的准确率，在5个基准测试中平均准确率达到53.3%。\n",
      "categories": [
        "cs.AI",
        "cs.LG"
      ],
      "primary_category": "cs.AI",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2504.15275v1",
      "published_date": "2025-04-21 17:59:02 UTC",
      "updated_date": "2025-04-21 17:59:02 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-04-23T02:12:11.859284"
    },
    {
      "arxiv_id": "2504.15266v1",
      "title": "Roll the dice & look before you leap: Going beyond the creative limits of next-token prediction",
      "title_zh": "掷骰子，三思而后行：超越下一个 token 预测的创造性限制\n",
      "authors": [
        "Vaishnavh Nagarajan",
        "Chen Henry Wu",
        "Charles Ding",
        "Aditi Raghunathan"
      ],
      "abstract": "We design a suite of minimal algorithmic tasks that are a loose abstraction\nof open-ended real-world tasks. This allows us to cleanly and controllably\nquantify the creative limits of the present-day language model. Much like\nreal-world tasks that require a creative, far-sighted leap of thought, our\ntasks require an implicit, open-ended stochastic planning step that either (a)\ndiscovers new connections in an abstract knowledge graph (like in wordplay,\ndrawing analogies, or research) or (b) constructs new patterns (like in\ndesigning math problems or new proteins). In these tasks, we empirically and\nconceptually argue how next-token learning is myopic and memorizes excessively;\ncomparatively, multi-token approaches, namely teacherless training and\ndiffusion models, excel in producing diverse and original output. Secondly, in\nour tasks, we find that to elicit randomness from the Transformer without\nhurting coherence, it is better to inject noise right at the input layer (via a\nmethod we dub hash-conditioning) rather than defer to temperature sampling from\nthe output layer. Thus, our work offers a principled, minimal test-bed for\nanalyzing open-ended creative skills, and offers new arguments for going beyond\nnext-token learning and softmax-based sampling. We make part of the code\navailable under https://github.com/chenwu98/algorithmic-creativity",
      "tldr_zh": "该论文设计了一系列简化的算法任务，用于评估当前语言模型在开放式创造性任务中的局限性。这些任务需要模型进行隐式的、开放式的随机规划，例如发现抽象知识图谱中的新连接或构建新模式。研究表明，相比于next-token预测的短视和过度记忆，multi-token方法（如teacherless training和扩散模型）在生成多样化和原创性输出方面表现更佳。此外，论文提出了一种名为“hash-conditioning”的方法，通过在输入层注入噪声来提高Transformer的随机性，同时保持连贯性，优于传统的温度采样。该研究提供了一个原则性的、最小化的测试平台，用于分析开放式的创造性技能，并为超越next-token学习和softmax采样提供了新的论据。\n",
      "categories": [
        "cs.LG",
        "cs.AI",
        "cs.CL"
      ],
      "primary_category": "cs.LG",
      "comment": "37 pages",
      "pdf_url": "http://arxiv.org/pdf/2504.15266v1",
      "published_date": "2025-04-21 17:47:46 UTC",
      "updated_date": "2025-04-21 17:47:46 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-04-23T02:12:23.628930"
    },
    {
      "arxiv_id": "2504.15261v1",
      "title": "Leveraging Language Models for Automated Patient Record Linkage",
      "title_zh": "利用语言模型实现自动化患者记录链接\n",
      "authors": [
        "Mohammad Beheshti",
        "Lovedeep Gondara",
        "Iris Zachary"
      ],
      "abstract": "Objective: Healthcare data fragmentation presents a major challenge for\nlinking patient data, necessitating robust record linkage to integrate patient\nrecords from diverse sources. This study investigates the feasibility of\nleveraging language models for automated patient record linkage, focusing on\ntwo key tasks: blocking and matching. Materials and Methods: We utilized\nreal-world healthcare data from the Missouri Cancer Registry and Research\nCenter, linking patient records from two independent sources using\nprobabilistic linkage as a baseline. A transformer-based model, RoBERTa, was\nfine-tuned for blocking using sentence embeddings. For matching, several\nlanguage models were experimented under fine-tuned and zero-shot settings,\nassessing their performance against ground truth labels. Results: The\nfine-tuned blocking model achieved a 92% reduction in the number of candidate\npairs while maintaining near-perfect recall. In the matching task, fine-tuned\nMistral-7B achieved the best performance with only 6 incorrect predictions.\nAmong zero-shot models, Mistral-Small-24B performed best, with a total of 55\nincorrect predictions. Discussion: Fine-tuned language models achieved strong\nperformance in patient record blocking and matching with minimal errors.\nHowever, they remain less accurate and efficient than a hybrid rule-based and\nprobabilistic approach for blocking. Additionally, reasoning models like\nDeepSeek-R1 are impractical for large-scale record linkage due to high\ncomputational costs. Conclusion: This study highlights the potential of\nlanguage models for automating patient record linkage, offering improved\nefficiency by eliminating the manual efforts required to perform patient record\nlinkage. Overall, language models offer a scalable solution that can enhance\ndata integration, reduce manual effort, and support disease surveillance and\nresearch.",
      "tldr_zh": "该研究探索了利用语言模型(Language Models)自动化患者记录链接的可行性，重点关注blocking和matching两个关键任务。研究人员使用来自密苏里州癌症登记和研究中心的真实医疗数据，并以概率链接作为基线。他们使用RoBERTa模型进行blocking任务的微调，通过句子嵌入实现了92%的候选对减少，同时保持了近乎完美的召回率。在matching任务中，微调后的Mistral-7B模型表现最佳，仅有6个错误预测。研究结果表明，语言模型在患者记录blocking和matching方面具有潜力，能够提高效率，减少人工工作量，并支持疾病监测和研究。但与混合规则和概率方法相比，blocking的准确性和效率仍有差距，且推理模型因计算成本高昂而不适用于大规模记录链接。\n",
      "categories": [
        "cs.AI",
        "cs.LG"
      ],
      "primary_category": "cs.AI",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2504.15261v1",
      "published_date": "2025-04-21 17:41:15 UTC",
      "updated_date": "2025-04-21 17:41:15 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-04-23T02:12:36.027894"
    },
    {
      "arxiv_id": "2504.15259v1",
      "title": "Bringing Diversity from Diffusion Models to Semantic-Guided Face Asset Generation",
      "title_zh": "将扩散模型的多样性引入语义引导的面部资产生成\n",
      "authors": [
        "Yunxuan Cai",
        "Sitao Xiang",
        "Zongjian Li",
        "Haiwei Chen",
        "Yajie Zhao"
      ],
      "abstract": "Digital modeling and reconstruction of human faces serve various\napplications. However, its availability is often hindered by the requirements\nof data capturing devices, manual labor, and suitable actors. This situation\nrestricts the diversity, expressiveness, and control over the resulting models.\nThis work aims to demonstrate that a semantically controllable generative\nnetwork can provide enhanced control over the digital face modeling process. To\nenhance diversity beyond the limited human faces scanned in a controlled\nsetting, we introduce a novel data generation pipeline that creates a\nhigh-quality 3D face database using a pre-trained diffusion model. Our proposed\nnormalization module converts synthesized data from the diffusion model into\nhigh-quality scanned data. Using the 44,000 face models we obtained, we further\ndeveloped an efficient GAN-based generator. This generator accepts semantic\nattributes as input, and generates geometry and albedo. It also allows\ncontinuous post-editing of attributes in the latent space. Our asset refinement\ncomponent subsequently creates physically-based facial assets. We introduce a\ncomprehensive system designed for creating and editing high-quality face\nassets. Our proposed model has undergone extensive experiment, comparison and\nevaluation. We also integrate everything into a web-based interactive tool. We\naim to make this tool publicly available with the release of the paper.",
      "tldr_zh": "该研究提出了一种语义引导的脸部资产生成方法，旨在解决数字人脸建模中数据获取困难、多样性不足等问题。核心思想是利用预训练的扩散模型生成高质量的3D人脸数据，并通过提出的归一化模块将其转化为可用的扫描数据格式。基于生成的44000个人脸模型，进一步训练了一个基于GAN的高效生成器，该生成器能够根据语义属性生成几何和反照率，并支持在潜在空间中进行属性编辑。最终，通过资产优化组件生成基于物理的脸部资产。该系统提供了一个创建和编辑高质量人脸资产的综合方案，并通过实验验证了其有效性。\n",
      "categories": [
        "cs.CV",
        "cs.AI"
      ],
      "primary_category": "cs.CV",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2504.15259v1",
      "published_date": "2025-04-21 17:38:50 UTC",
      "updated_date": "2025-04-21 17:38:50 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-04-23T02:12:47.646979"
    },
    {
      "arxiv_id": "2504.15257v1",
      "title": "FlowReasoner: Reinforcing Query-Level Meta-Agents",
      "title_zh": "FlowReasoner：强化查询级别的元智能体\n",
      "authors": [
        "Hongcheng Gao",
        "Yue Liu",
        "Yufei He",
        "Longxu Dou",
        "Chao Du",
        "Zhijie Deng",
        "Bryan Hooi",
        "Min Lin",
        "Tianyu Pang"
      ],
      "abstract": "This paper proposes a query-level meta-agent named FlowReasoner to automate\nthe design of query-level multi-agent systems, i.e., one system per user query.\nOur core idea is to incentivize a reasoning-based meta-agent via external\nexecution feedback. Concretely, by distilling DeepSeek R1, we first endow the\nbasic reasoning ability regarding the generation of multi-agent systems to\nFlowReasoner. Then, we further enhance it via reinforcement learning (RL) with\nexternal execution feedback. A multi-purpose reward is designed to guide the RL\ntraining from aspects of performance, complexity, and efficiency. In this\nmanner, FlowReasoner is enabled to generate a personalized multi-agent system\nfor each user query via deliberative reasoning. Experiments on both engineering\nand competition code benchmarks demonstrate the superiority of FlowReasoner.\nRemarkably, it surpasses o1-mini by 10.52% accuracy across three benchmarks.\nThe code is available at https://github.com/sail-sg/FlowReasoner.",
      "tldr_zh": "本文提出了一种查询级别的元智能体FlowReasoner，旨在自动化设计查询级别的多智能体系统。核心思想是通过外部执行反馈来激励一个基于推理的元智能体。具体来说，通过提炼DeepSeek R1，FlowReasoner具备了生成多智能体系统的基本推理能力，并通过强化学习(RL)和外部执行反馈进一步增强。设计了一个多用途奖励，从性能、复杂性和效率等方面指导RL训练。实验表明，FlowReasoner在工程和竞赛代码基准测试中都表现出色，在三个基准测试中超过o1-mini 10.52%的准确率。\n",
      "categories": [
        "cs.AI"
      ],
      "primary_category": "cs.AI",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2504.15257v1",
      "published_date": "2025-04-21 17:35:42 UTC",
      "updated_date": "2025-04-21 17:35:42 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-04-23T02:12:59.558839"
    },
    {
      "arxiv_id": "2504.15252v1",
      "title": "SuoiAI: Building a Dataset for Aquatic Invertebrates in Vietnam",
      "title_zh": "SuoiAI：构建越南水生无脊椎动物数据集\n",
      "authors": [
        "Tue Vo",
        "Lakshay Sharma",
        "Tuan Dinh",
        "Khuong Dinh",
        "Trang Nguyen",
        "Trung Phan",
        "Minh Do",
        "Duong Vu"
      ],
      "abstract": "Understanding and monitoring aquatic biodiversity is critical for ecological\nhealth and conservation efforts. This paper proposes SuoiAI, an end-to-end\npipeline for building a dataset of aquatic invertebrates in Vietnam and\nemploying machine learning (ML) techniques for species classification. We\noutline the methods for data collection, annotation, and model training,\nfocusing on reducing annotation effort through semi-supervised learning and\nleveraging state-of-the-art object detection and classification models. Our\napproach aims to overcome challenges such as data scarcity, fine-grained\nclassification, and deployment in diverse environmental conditions.",
      "tldr_zh": "本文提出了SuoiAI，一个用于构建越南水生无脊椎动物数据集的端到端流程，并利用机器学习技术进行物种分类。该流程涵盖了数据收集、标注和模型训练的方法，重点是通过半监督学习减少标注工作量，并利用先进的目标检测和分类模型。SuoiAI旨在克服数据稀缺、细粒度分类以及在不同环境条件下部署等挑战，从而促进对水生生物多样性的理解和监测。\n",
      "categories": [
        "cs.AI",
        "cs.CV",
        "cs.LG"
      ],
      "primary_category": "cs.AI",
      "comment": "Published as a workshop paper at \"Tackling Climate Change with\n  Machine Learning\", ICLR 2025",
      "pdf_url": "http://arxiv.org/pdf/2504.15252v1",
      "published_date": "2025-04-21 17:33:02 UTC",
      "updated_date": "2025-04-21 17:33:02 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-04-23T02:13:11.250401"
    },
    {
      "arxiv_id": "2504.15236v1",
      "title": "Values in the Wild: Discovering and Analyzing Values in Real-World Language Model Interactions",
      "title_zh": "野外价值观：在真实世界语言模型交互中发现和分析价值观\n",
      "authors": [
        "Saffron Huang",
        "Esin Durmus",
        "Miles McCain",
        "Kunal Handa",
        "Alex Tamkin",
        "Jerry Hong",
        "Michael Stern",
        "Arushi Somani",
        "Xiuruo Zhang",
        "Deep Ganguli"
      ],
      "abstract": "AI assistants can impart value judgments that shape people's decisions and\nworldviews, yet little is known empirically about what values these systems\nrely on in practice. To address this, we develop a bottom-up,\nprivacy-preserving method to extract the values (normative considerations\nstated or demonstrated in model responses) that Claude 3 and 3.5 models exhibit\nin hundreds of thousands of real-world interactions. We empirically discover\nand taxonomize 3,307 AI values and study how they vary by context. We find that\nClaude expresses many practical and epistemic values, and typically supports\nprosocial human values while resisting values like \"moral nihilism\". While some\nvalues appear consistently across contexts (e.g. \"transparency\"), many are more\nspecialized and context-dependent, reflecting the diversity of human\ninterlocutors and their varied contexts. For example, \"harm prevention\" emerges\nwhen Claude resists users, \"historical accuracy\" when responding to queries\nabout controversial events, \"healthy boundaries\" when asked for relationship\nadvice, and \"human agency\" in technology ethics discussions. By providing the\nfirst large-scale empirical mapping of AI values in deployment, our work\ncreates a foundation for more grounded evaluation and design of values in AI\nsystems.",
      "tldr_zh": "该研究旨在揭示和分析大型语言模型（LLMs）在实际交互中体现的价值观。研究者开发了一种自下而上的、保护隐私的方法，从Claude 3和3.5模型在数十万次真实交互中提取了3307个AI价值观，并对其进行了分类。研究发现，Claude模型表达了许多实用和认知价值观，通常支持亲社会的人类价值观，并抵制“道德虚无主义”等价值观。这些价值观在不同上下文中表现出差异，反映了人类对话者的多样性。例如，“预防伤害”出现在Claude模型抵制用户时，“历史准确性”出现在回应有关争议事件的查询时。这项工作为AI系统中价值观的评估和设计奠定了基础。\n",
      "categories": [
        "cs.CL",
        "cs.AI",
        "cs.CY",
        "cs.LG"
      ],
      "primary_category": "cs.CL",
      "comment": "44 pages",
      "pdf_url": "http://arxiv.org/pdf/2504.15236v1",
      "published_date": "2025-04-21 17:13:16 UTC",
      "updated_date": "2025-04-21 17:13:16 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-04-23T02:13:23.700764"
    },
    {
      "arxiv_id": "2504.15228v1",
      "title": "A Self-Improving Coding Agent",
      "title_zh": "一个自我改进的编码智能体\n",
      "authors": [
        "Maxime Robeyns",
        "Martin Szummer",
        "Laurence Aitchison"
      ],
      "abstract": "We demonstrate that an LLM coding agent, equipped with basic coding tools,\ncan autonomously edit itself, and thereby improve its performance on benchmark\ntasks. We find performance gains from 17% to 53% on a random subset of SWE\nBench Verified, with additional performance gains on LiveCodeBench, as well as\nsynthetically generated agent benchmarks. Our work represents an advancement in\nthe automated and open-ended design of agentic systems, and provides a\nreference agent framework for those seeking to post-train LLMs on tool use and\nother agentic tasks.",
      "tldr_zh": "该论文展示了一个具备基础编码工具的LLM编码智能体，能够自主编辑自身代码，从而提升在基准测试任务上的表现。在SWE Bench Verified的随机子集上，性能提升了17%到53%，并在LiveCodeBench以及合成生成的智能体基准测试中也获得了额外的性能提升。这项工作代表了智能体系统自动化和开放式设计方面的进步，并为那些寻求对LLM进行工具使用和其他智能体任务进行后训练的人提供了一个参考智能体框架。\n",
      "categories": [
        "cs.AI"
      ],
      "primary_category": "cs.AI",
      "comment": "Published at an ICLR 2025 workshop on Scaling Self-Improving\n  Foundation Models",
      "pdf_url": "http://arxiv.org/pdf/2504.15228v1",
      "published_date": "2025-04-21 16:58:18 UTC",
      "updated_date": "2025-04-21 16:58:18 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-04-23T02:13:35.449754"
    },
    {
      "arxiv_id": "2504.15226v1",
      "title": "A Genetic Fuzzy-Enabled Framework on Robotic Manipulation for In-Space Servicing",
      "title_zh": "一种基于遗传模糊的机器人操作框架，用于空间服务\n",
      "authors": [
        "Nathan Steffen",
        "Wilhelm Louw",
        "Nicholas Ernest",
        "Timothy Arnett",
        "Kelly Cohen"
      ],
      "abstract": "Automation of robotic systems for servicing in cislunar space is becoming\nextremely important as the number of satellites in orbit increases. Safety is\ncritical in performing satellite maintenance, so the control techniques\nutilized must be trusted in addition to being highly efficient. In this work,\nGenetic Fuzzy Trees are combined with the widely used LQR control scheme via\nThales' TrUE AI Toolkit to create a trusted and efficient controller for a\ntwo-degree-of-freedom planar robotic manipulator that would theoretically be\nused to perform satellite maintenance. It was found that Genetic Fuzzy-LQR is\n18.5% more performant than optimal LQR on average, and that it is incredibly\nrobust to uncertainty.",
      "tldr_zh": "该论文提出了一种基于遗传模糊树(Genetic Fuzzy Trees)的框架，用于地月空间服务中的机器人操作。该框架结合了遗传模糊树和LQR控制方案，利用Thales的TrUE AI Toolkit，为执行卫星维护的双自由度平面机器人机械臂创建了一个可信且高效的控制器。实验结果表明，与最优LQR相比，遗传模糊-LQR的性能平均提高了18.5%，并且对不确定性具有很强的鲁棒性。该研究为空间机器人自主维护提供了新的控制策略。\n",
      "categories": [
        "cs.RO",
        "cs.AI",
        "cs.SY",
        "eess.SY"
      ],
      "primary_category": "cs.RO",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2504.15226v1",
      "published_date": "2025-04-21 16:57:56 UTC",
      "updated_date": "2025-04-21 16:57:56 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-04-23T02:13:47.473662"
    },
    {
      "arxiv_id": "2504.15225v1",
      "title": "M$^2$AD: Multi-Sensor Multi-System Anomaly Detection through Global Scoring and Calibrated Thresholding",
      "title_zh": "M$^2$AD：通过全局评分和校准阈值实现的多传感器多系统异常检测\n",
      "authors": [
        "Sarah Alnegheimish",
        "Zelin He",
        "Matthew Reimherr",
        "Akash Chandrayan",
        "Abhinav Pradhan",
        "Luca D'Angelo"
      ],
      "abstract": "With the widespread availability of sensor data across industrial and\noperational systems, we frequently encounter heterogeneous time series from\nmultiple systems. Anomaly detection is crucial for such systems to facilitate\npredictive maintenance. However, most existing anomaly detection methods are\ndesigned for either univariate or single-system multivariate data, making them\ninsufficient for these complex scenarios. To address this, we introduce\nM$^2$AD, a framework for unsupervised anomaly detection in multivariate time\nseries data from multiple systems. M$^2$AD employs deep models to capture\nexpected behavior under normal conditions, using the residuals as indicators of\npotential anomalies. These residuals are then aggregated into a global anomaly\nscore through a Gaussian Mixture Model and Gamma calibration. We theoretically\ndemonstrate that this framework can effectively address heterogeneity and\ndependencies across sensors and systems. Empirically, M$^2$AD outperforms\nexisting methods in extensive evaluations by 21% on average, and its\neffectiveness is demonstrated on a large-scale real-world case study on 130\nassets in Amazon Fulfillment Centers. Our code and results are available at\nhttps://github.com/sarahmish/M2AD.",
      "tldr_zh": "该论文提出了M$^2$AD，一个用于多系统多传感器场景下的非监督异常检测框架。M$^2$AD利用深度模型学习正常状态下的行为模式，并将残差作为潜在异常的指标。通过高斯混合模型和Gamma校准，残差被聚合成全局异常评分。理论分析表明，该框架能有效处理传感器和系统间的异构性和依赖性。实验结果表明，M$^2$AD在广泛的评估中平均优于现有方法21%，并在Amazon Fulfillment Centers的130个资产的大规模真实案例研究中验证了其有效性。\n",
      "categories": [
        "cs.LG",
        "cs.AI"
      ],
      "primary_category": "cs.LG",
      "comment": "Accepted at AISTATS 2025",
      "pdf_url": "http://arxiv.org/pdf/2504.15225v1",
      "published_date": "2025-04-21 16:57:46 UTC",
      "updated_date": "2025-04-21 16:57:46 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-04-23T02:13:59.473288"
    },
    {
      "arxiv_id": "2504.15211v1",
      "title": "Position: Bayesian Statistics Facilitates Stakeholder Participation in Evaluation of Generative AI",
      "title_zh": "立场：贝叶斯统计学促进利益相关者参与生成式人工智能的评估\n",
      "authors": [
        "Yanan Long"
      ],
      "abstract": "The evaluation of Generative AI (GenAI) systems plays a critical role in\npublic policy and decision-making, yet existing methods are often limited by\nreliance on benchmark-driven, point-estimate comparisons that fail to capture\nuncertainty and broader societal impacts. This paper argues for the use of\nBayesian statistics as a principled framework to address these challenges.\nBayesian methods enable the integration of domain expertise through prior\nelicitation, allow for continuous learning from new data, and provide robust\nuncertainty quantification via posterior inference. We demonstrate how Bayesian\ninference can be applied to GenAI evaluation, particularly in incorporating\nstakeholder perspectives to enhance fairness, transparency, and reliability.\nFurthermore, we discuss Bayesian workflows as an iterative process for model\nvalidation and refinement, ensuring robust assessments of GenAI systems in\ndynamic, real-world contexts.",
      "tldr_zh": "该论文提出利用贝叶斯统计来改进生成式人工智能(GenAI)系统的评估，特别是在公共政策和决策制定中。传统评估方法依赖于基准驱动的、点估计比较，无法捕捉不确定性和更广泛的社会影响。贝叶斯方法通过先验引出整合领域专业知识，允许从新数据中持续学习，并通过后验推断提供稳健的不确定性量化。论文展示了贝叶斯推断如何应用于GenAI评估，尤其是在纳入利益相关者的观点以提高公平性、透明度和可靠性方面。论文还讨论了贝叶斯工作流程作为一个迭代过程，用于模型验证和改进，确保在动态、真实世界的环境中对GenAI系统进行稳健的评估。\n",
      "categories": [
        "cs.AI",
        "stat.AP"
      ],
      "primary_category": "cs.AI",
      "comment": "To be presented at ACM CHI 2025 workshop STAIG",
      "pdf_url": "http://arxiv.org/pdf/2504.15211v1",
      "published_date": "2025-04-21 16:31:15 UTC",
      "updated_date": "2025-04-21 16:31:15 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-04-23T02:14:11.586183"
    },
    {
      "arxiv_id": "2504.15210v1",
      "title": "Integrating Symbolic Execution into the Fine-Tuning of Code-Generating LLMs",
      "title_zh": "将符号执行集成到代码生成 LLM 的微调中\n",
      "authors": [
        "Marina Sakharova",
        "Abhinav Anand",
        "Mira Mezini"
      ],
      "abstract": "Code-generating Large Language Models (LLMs) have become essential tools in\nmodern software development, enhancing productivity and accelerating\ndevelopment. This paper aims to investigate the fine-tuning of code-generating\nLLMs using Reinforcement Learning and Direct Preference Optimization, further\nimproving their performance. To achieve this, we enhance the training data for\nthe reward model with the help of symbolic execution techniques, ensuring more\ncomprehensive and objective data. With symbolic execution, we create a custom\ndataset that better captures the nuances in code evaluation. Our reward models,\nfine-tuned on this dataset, demonstrate significant improvements over the\nbaseline, CodeRL, in estimating the quality of generated code. Our\ncode-generating LLMs, trained with the help of reward model feedback, achieve\nsimilar results compared to the CodeRL benchmark.",
      "tldr_zh": "该研究探索了将符号执行集成到代码生成大语言模型(LLMs)微调中的方法，旨在提升其性能。通过符号执行技术增强奖励模型(reward model)的训练数据，构建更全面和客观的数据集，从而更好地捕捉代码评估的细微之处。基于该数据集微调的奖励模型在评估生成代码质量方面，相比基线模型CodeRL表现出显著提升。利用奖励模型反馈训练的代码生成LLMs，取得了与CodeRL基准相似的结果。\n",
      "categories": [
        "cs.SE",
        "cs.AI"
      ],
      "primary_category": "cs.SE",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2504.15210v1",
      "published_date": "2025-04-21 16:29:07 UTC",
      "updated_date": "2025-04-21 16:29:07 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-04-23T02:14:23.369116"
    },
    {
      "arxiv_id": "2504.15209v1",
      "title": "A Causal Convolutional Low-rank Representation Model for Imputation of Water Quality Data",
      "title_zh": "一种用于水质数据插补的因果卷积低秩表示模型\n",
      "authors": [
        "Xin Liao",
        "Bing Yang",
        "Tan Dongli",
        "Cai Yu"
      ],
      "abstract": "The monitoring of water quality is a crucial part of environmental\nprotection, and a large number of monitors are widely deployed to monitor water\nquality. Due to unavoidable factors such as data acquisition breakdowns,\nsensors and communication failures, water quality monitoring data suffers from\nmissing values over time, resulting in High-Dimensional and Sparse (HDS) Water\nQuality Data (WQD). The simple and rough filling of the missing values leads to\ninaccurate results and affects the implementation of relevant measures.\nTherefore, this paper proposes a Causal convolutional Low-rank Representation\n(CLR) model for imputing missing WQD to improve the completeness of the WQD,\nwhich employs a two-fold idea: a) applying causal convolutional operation to\nconsider the temporal dependence of the low-rank representation, thus\nincorporating temporal information to improve the imputation accuracy; and b)\nimplementing a hyperparameters adaptation scheme to automatically adjust the\nbest hyperparameters during model training, thereby reducing the tedious manual\nadjustment of hyper-parameters. Experimental studies on three real-world water\nquality datasets demonstrate that the proposed CLR model is superior to some of\nthe existing state-of-the-art imputation models in terms of imputation accuracy\nand time cost, as well as indicating that the proposed model provides more\nreliable decision support for environmental monitoring.",
      "tldr_zh": "该论文提出了一种因果卷积低秩表示(Causal convolutional Low-rank Representation, CLR)模型，用于填补缺失的水质数据，解决水质监测数据高维稀疏(High-Dimensional and Sparse, HDS)的问题。该模型利用因果卷积操作考虑低秩表示的时间依赖性，从而将时间信息融入以提高填补精度。同时，采用超参数自适应方案，自动调整模型训练期间的最佳超参数，减少手动调整的繁琐。在三个真实世界水质数据集上的实验表明，所提出的CLR模型在填补精度和时间成本方面优于现有的一些最先进的填补模型，并为环境监测提供更可靠的决策支持。\n",
      "categories": [
        "cs.LG",
        "cs.AI",
        "68T07 (Primary) 62M10, 65C60 (Secondary)",
        "I.2.7"
      ],
      "primary_category": "cs.LG",
      "comment": "9 pages, 3 figures",
      "pdf_url": "http://arxiv.org/pdf/2504.15209v1",
      "published_date": "2025-04-21 16:27:16 UTC",
      "updated_date": "2025-04-21 16:27:16 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-04-23T02:14:35.631345"
    },
    {
      "arxiv_id": "2504.15208v1",
      "title": "Compute-Optimal LLMs Provably Generalize Better With Scale",
      "title_zh": "计算最优的LLM可以通过扩展来更好地进行泛化，这是可以证明的\n",
      "authors": [
        "Marc Finzi",
        "Sanyam Kapoor",
        "Diego Granziol",
        "Anming Gu",
        "Christopher De Sa",
        "J. Zico Kolter",
        "Andrew Gordon Wilson"
      ],
      "abstract": "Why do larger language models generalize better? To investigate this\nquestion, we develop generalization bounds on the pretraining objective of\nlarge language models (LLMs) in the compute-optimal regime, as described by the\nChinchilla scaling laws. We introduce a novel, fully empirical Freedman-type\nmartingale concentration inequality that tightens existing bounds by accounting\nfor the variance of the loss function. This generalization bound can be\ndecomposed into three interpretable components: the number of parameters per\ntoken, the loss variance, and the quantization error at a fixed bitrate. As\ncompute-optimal language models are scaled up, the number of parameters per\ndata point remains constant; however, both the loss variance and the\nquantization error decrease, implying that larger models should have smaller\ngeneralization gaps. We examine why larger models tend to be more quantizable\nfrom an information theoretic perspective, showing that the rate at which they\ncan integrate new information grows more slowly than their capacity on the\ncompute-optimal frontier. From these findings we produce a scaling law for the\ngeneralization gap, with bounds that become predictably stronger with scale.",
      "tldr_zh": "该论文研究了大型语言模型(LLMs)泛化能力随规模增长的原因，针对符合Chinchilla scaling laws的计算最优LLM，提出了基于预训练目标的泛化边界。论文引入了一种新颖的、完全经验性的Freedman型鞅集中不等式，通过考虑损失函数的方差来收紧现有边界。该泛化边界可分解为三个可解释的组成部分：每个token的参数数量、损失方差和固定比特率下的量化误差。研究表明，随着计算最优语言模型的扩展，每个数据点的参数数量保持不变，但损失方差和量化误差都会减小，这意味着更大的模型应该具有更小的泛化差距。从信息论的角度，论文还探讨了为什么更大的模型更易于量化，并展示了它们整合新信息的速度增长慢于其在计算最优边界上的容量。最后，论文提出了一个泛化差距的缩放定律，其边界随着规模的增加而变得更强。\n",
      "categories": [
        "cs.LG",
        "cs.AI"
      ],
      "primary_category": "cs.LG",
      "comment": "ICLR 2025",
      "pdf_url": "http://arxiv.org/pdf/2504.15208v1",
      "published_date": "2025-04-21 16:26:56 UTC",
      "updated_date": "2025-04-21 16:26:56 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-04-23T02:14:48.028626"
    },
    {
      "arxiv_id": "2504.15205v1",
      "title": "Support Evaluation for the TREC 2024 RAG Track: Comparing Human versus LLM Judges",
      "title_zh": "TREC 2024 RAG 赛道中的支持度评估：人工评估与 LLM 评估的比较\n",
      "authors": [
        "Nandan Thakur",
        "Ronak Pradeep",
        "Shivani Upadhyay",
        "Daniel Campos",
        "Nick Craswell",
        "Jimmy Lin"
      ],
      "abstract": "Retrieval-augmented generation (RAG) enables large language models (LLMs) to\ngenerate answers with citations from source documents containing \"ground\ntruth\", thereby reducing system hallucinations. A crucial factor in RAG\nevaluation is \"support\", whether the information in the cited documents\nsupports the answer. To this end, we conducted a large-scale comparative study\nof 45 participant submissions on 36 topics to the TREC 2024 RAG Track,\ncomparing an automatic LLM judge (GPT-4o) against human judges for support\nassessment. We considered two conditions: (1) fully manual assessments from\nscratch and (2) manual assessments with post-editing of LLM predictions. Our\nresults indicate that for 56% of the manual from-scratch assessments, human and\nGPT-4o predictions match perfectly (on a three-level scale), increasing to 72%\nin the manual with post-editing condition. Furthermore, by carefully analyzing\nthe disagreements in an unbiased study, we found that an independent human\njudge correlates better with GPT-4o than a human judge, suggesting that LLM\njudges can be a reliable alternative for support assessment. To conclude, we\nprovide a qualitative analysis of human and GPT-4o errors to help guide future\niterations of support assessment.",
      "tldr_zh": "本文针对TREC 2024 RAG Track中的“支持度”评估，对比了人类评估员和大型语言模型(LLM)评估员（GPT-4o）的表现。研究分析了45个参赛作品在36个主题上的结果，比较了两种评估方式：完全人工评估和人工编辑LLM预测的评估。结果表明，在56%的完全人工评估中，人类和GPT-4o的预测完全一致（三级评分标准），在人工编辑LLM预测的情况下，一致性提高到72%。进一步分析发现，独立的人工评估员与GPT-4o的相关性高于另一个人为评估员，表明LLM评估员可以作为支持度评估的可靠替代方案。最后，论文对人类和GPT-4o的错误进行了定性分析，以指导未来支持度评估的迭代。\n",
      "categories": [
        "cs.CL",
        "cs.AI",
        "cs.IR"
      ],
      "primary_category": "cs.CL",
      "comment": "Accepted at SIGIR 2025 (short)",
      "pdf_url": "http://arxiv.org/pdf/2504.15205v1",
      "published_date": "2025-04-21 16:20:43 UTC",
      "updated_date": "2025-04-21 16:20:43 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-04-23T02:14:59.841694"
    },
    {
      "arxiv_id": "2504.15199v1",
      "title": "Zero-Shot, But at What Cost? Unveiling the Hidden Overhead of MILS's LLM-CLIP Framework for Image Captioning",
      "title_zh": "零样本，但代价是什么？揭示 MILS 的 LLM-CLIP 框架在图像描述中的隐藏开销\n",
      "authors": [
        "Yassir Benhammou",
        "Alessandro Tiberio",
        "Gabriel Trautmann",
        "Suman Kalyan"
      ],
      "abstract": "MILS (Multimodal Iterative LLM Solver) is a recently published framework that\nclaims \"LLMs can see and hear without any training\" by leveraging an iterative,\nLLM-CLIP based approach for zero-shot image captioning. While this MILS\napproach demonstrates good performance, our investigation reveals that this\nsuccess comes at a hidden, substantial computational cost due to its expensive\nmulti-step refinement process. In contrast, alternative models such as BLIP-2\nand GPT-4V achieve competitive results through a streamlined, single-pass\napproach. We hypothesize that the significant overhead inherent in MILS's\niterative process may undermine its practical benefits, thereby challenging the\nnarrative that zero-shot performance can be attained without incurring heavy\nresource demands. This work is the first to expose and quantify the trade-offs\nbetween output quality and computational cost in MILS, providing critical\ninsights for the design of more efficient multimodal models.",
      "tldr_zh": "本文深入研究了MILS (Multimodal Iterative LLM Solver) 这一基于LLM-CLIP的零样本图像描述框架，发现其高性能背后隐藏着巨大的计算成本。MILS通过迭代式的多步骤优化过程实现图像描述，但相比之下，BLIP-2和GPT-4V等模型采用更简洁的单次处理方法也能达到相似的效果。研究表明，MILS的迭代过程带来的显著开销可能抵消其零样本性能的优势，揭示了MILS在输出质量和计算成本之间的权衡，为设计更高效的多模态模型提供了重要参考。\n",
      "categories": [
        "cs.CV",
        "cs.AI",
        "cs.LG",
        "cs.PF"
      ],
      "primary_category": "cs.CV",
      "comment": "9 pages, 2 tables, 1 figure",
      "pdf_url": "http://arxiv.org/pdf/2504.15199v1",
      "published_date": "2025-04-21 16:16:19 UTC",
      "updated_date": "2025-04-21 16:16:19 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-04-23T02:15:11.633393"
    },
    {
      "arxiv_id": "2504.15192v1",
      "title": "Breast density in MRI: an AI-based quantification and relationship to assessment in mammography",
      "title_zh": "MRI 中的乳腺密度：一种基于 AI 的量化方法及其与乳腺 X 线摄影评估的关系\n",
      "authors": [
        "Yaqian Chen",
        "Lin Li",
        "Hanxue Gu",
        "Haoyu Dong",
        "Derek L. Nguyen",
        "Allan D. Kirk",
        "Maciej A. Mazurowski",
        "E. Shelley Hwang"
      ],
      "abstract": "Mammographic breast density is a well-established risk factor for breast\ncancer. Recently there has been interest in breast MRI as an adjunct to\nmammography, as this modality provides an orthogonal and highly quantitative\nassessment of breast tissue. However, its 3D nature poses analytic challenges\nrelated to delineating and aggregating complex structures across slices. Here,\nwe applied an in-house machine-learning algorithm to assess breast density on\nnormal breasts in three MRI datasets. Breast density was consistent across\ndifferent datasets (0.104 - 0.114). Analysis across different age groups also\ndemonstrated strong consistency across datasets and confirmed a trend of\ndecreasing density with age as reported in previous studies. MR breast density\nwas correlated with mammographic breast density, although some notable\ndifferences suggest that certain breast density components are captured only on\nMRI. Future work will determine how to integrate MR breast density with current\ntools to improve future breast cancer risk prediction.",
      "tldr_zh": "该研究利用一种内部开发的机器学习算法，对三个MRI数据集中的正常乳腺进行乳腺密度评估。结果显示，不同数据集之间的乳腺密度具有一致性(0.104 - 0.114)，并且验证了乳腺密度随年龄增长而降低的趋势。MRI乳腺密度与乳腺X线照片的乳腺密度相关，但存在显著差异，表明MRI可以捕捉到某些仅在MRI上显示的乳腺密度成分。未来的工作将致力于整合MRI乳腺密度与现有工具，以提高乳腺癌风险预测的准确性。\n",
      "categories": [
        "cs.CV",
        "cs.AI"
      ],
      "primary_category": "cs.CV",
      "comment": "13 pages, 5 figures",
      "pdf_url": "http://arxiv.org/pdf/2504.15192v1",
      "published_date": "2025-04-21 16:01:51 UTC",
      "updated_date": "2025-04-21 16:01:51 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-04-23T02:15:23.629036"
    },
    {
      "arxiv_id": "2504.15188v2",
      "title": "Synergistic Weak-Strong Collaboration by Aligning Preferences",
      "title_zh": "通过对齐偏好实现协同的弱-强协作\n",
      "authors": [
        "Yizhu Jiao",
        "Xuchao Zhang",
        "Zhaoyang Wang",
        "Yubo Ma",
        "Zhun Deng",
        "Rujia Wang",
        "Chetan Bansal",
        "Saravan Rajmohan",
        "Jiawei Han",
        "Huaxiu Yao"
      ],
      "abstract": "Current Large Language Models (LLMs) excel in general reasoning yet struggle\nwith specialized tasks requiring proprietary or domain-specific knowledge.\nFine-tuning large models for every niche application is often infeasible due to\nblack-box constraints and high computational overhead. To address this, we\npropose a collaborative framework that pairs a specialized weak model with a\ngeneral strong model. The weak model, tailored to specific domains, produces\ninitial drafts and background information, while the strong model leverages its\nadvanced reasoning to refine these drafts, extending LLMs' capabilities to\ncritical yet specialized tasks. To optimize this collaboration, we introduce a\ncollaborative feedback to fine-tunes the weak model, which quantifies the\ninfluence of the weak model's contributions in the collaboration procedure and\nestablishes preference pairs to guide preference tuning of the weak model. We\nvalidate our framework through experiments on three domains. We find that the\ncollaboration significantly outperforms each model alone by leveraging\ncomplementary strengths. Moreover, aligning the weak model with the\ncollaborative preference further enhances overall performance.",
      "tldr_zh": "该论文提出了一种协同框架，通过对齐偏好，实现弱模型和强模型的优势互补。弱模型专注于特定领域，生成初始草案和背景信息；强模型利用其强大的推理能力完善草案，从而将LLM的能力扩展到关键但专业的任务中。为了优化这种协作，研究引入了协作反馈，用于微调弱模型，量化弱模型在协作过程中的影响，并建立偏好对来指导弱模型的偏好调整。在三个领域的实验验证表明，该协同框架显著优于单独使用每个模型，并且对齐弱模型的协作偏好可以进一步提高整体性能。\n",
      "categories": [
        "cs.AI"
      ],
      "primary_category": "cs.AI",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2504.15188v2",
      "published_date": "2025-04-21 15:57:33 UTC",
      "updated_date": "2025-04-22 04:22:09 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-04-23T02:15:35.604306"
    },
    {
      "arxiv_id": "2504.15181v1",
      "title": "Existing Industry Practice for the EU AI Act's General-Purpose AI Code of Practice Safety and Security Measures",
      "title_zh": "欧盟人工智能法案通用人工智能行为准则安全和保障措施的现有行业实践\n",
      "authors": [
        "Lily Stelling",
        "Mick Yang",
        "Rokas Gipiškis",
        "Leon Staufer",
        "Ze Shen Chin",
        "Siméon Campos",
        "Michael Chen"
      ],
      "abstract": "This report provides a detailed comparison between the measures proposed in\nthe EU AI Act's General-Purpose AI (GPAI) Code of Practice (Third Draft) and\ncurrent practices adopted by leading AI companies. As the EU moves toward\nenforcing binding obligations for GPAI model providers, the Code of Practice\nwill be key to bridging legal requirements with concrete technical commitments.\nOur analysis focuses on the draft's Safety and Security section which is only\nrelevant for the providers of the most advanced models (Commitments II.1-II.16)\nand excerpts from current public-facing documents quotes that are relevant to\neach individual measure.\n  We systematically reviewed different document types - including companies'\nfrontier safety frameworks and model cards - from over a dozen companies,\nincluding OpenAI, Anthropic, Google DeepMind, Microsoft, Meta, Amazon, and\nothers. This report is not meant to be an indication of legal compliance nor\ndoes it take any prescriptive viewpoint about the Code of Practice or\ncompanies' policies. Instead, it aims to inform the ongoing dialogue between\nregulators and GPAI model providers by surfacing evidence of precedent.",
      "tldr_zh": "本报告对比了欧盟《人工智能法案》通用人工智能(GPAI)行为准则（第三稿）中提出的措施与领先人工智能公司目前的实践。分析聚焦于草案的安全保障部分，该部分仅与最先进模型的提供商相关。通过系统性地回顾包括OpenAI、Anthropic、Google DeepMind等十余家公司的前沿安全框架和模型卡等文档，报告旨在为监管机构和GPAI模型提供商之间的对话提供参考，展示现有实践的先例，从而弥合法律要求与具体技术承诺之间的差距。该报告不代表任何法律合规性指示，也不对行为准则或公司政策采取任何规定性观点。\n",
      "categories": [
        "cs.CY",
        "cs.AI"
      ],
      "primary_category": "cs.CY",
      "comment": "158 pages",
      "pdf_url": "http://arxiv.org/pdf/2504.15181v1",
      "published_date": "2025-04-21 15:44:01 UTC",
      "updated_date": "2025-04-21 15:44:01 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-04-23T02:15:47.757020"
    },
    {
      "arxiv_id": "2504.15165v1",
      "title": "An Efficient Aerial Image Detection with Variable Receptive Fields",
      "title_zh": "一种基于可变感受野的高效航空图像检测方法\n",
      "authors": [
        "Liu Wenbin"
      ],
      "abstract": "Aerial object detection using unmanned aerial vehicles (UAVs) faces critical\nchallenges including sub-10px targets, dense occlusions, and stringent\ncomputational constraints. Existing detectors struggle to balance accuracy and\nefficiency due to rigid receptive fields and redundant architectures. To\naddress these limitations, we propose Variable Receptive Field DETR (VRF-DETR),\na transformer-based detector incorporating three key components: 1) Multi-Scale\nContext Fusion (MSCF) module that dynamically recalibrates features through\nadaptive spatial attention and gated multi-scale fusion, 2) Gated Convolution\n(GConv) layer enabling parameter-efficient local-context modeling via depthwise\nseparable operations and dynamic gating, and 3) Gated Multi-scale Fusion (GMCF)\nBottleneck that hierarchically disentangles occluded objects through cascaded\nglobal-local interactions. Experiments on VisDrone2019 demonstrate VRF-DETR\nachieves 51.4\\% mAP\\textsubscript{50} and 31.8\\% mAP\\textsubscript{50:95} with\nonly 13.5M parameters. This work establishes a new efficiency-accuracy Pareto\nfrontier for UAV-based detection tasks.",
      "tldr_zh": "本文提出了一种名为VRF-DETR（Variable Receptive Field DETR）的高效空中图像目标检测方法，旨在解决无人机（UAV）应用中目标小、遮挡严重以及计算资源受限等挑战。VRF-DETR基于Transformer架构，包含三个关键组件：多尺度上下文融合（MSCF）模块，用于动态调整特征；门控卷积（GConv）层，用于参数高效的局部上下文建模；以及门控多尺度融合（GMCF）瓶颈，用于分层解耦遮挡目标。实验结果表明，VRF-DETR在VisDrone2019数据集上以仅13.5M的参数实现了51.4%的mAP\\textsubscript{50}和31.8%的mAP\\textsubscript{50:95}，在精度和效率之间取得了新的平衡。\n",
      "categories": [
        "cs.CV",
        "cs.AI"
      ],
      "primary_category": "cs.CV",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2504.15165v1",
      "published_date": "2025-04-21 15:16:13 UTC",
      "updated_date": "2025-04-21 15:16:13 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-04-23T02:15:59.754141"
    },
    {
      "arxiv_id": "2504.15152v1",
      "title": "Landmark-Free Preoperative-to-Intraoperative Registration in Laparoscopic Liver Resection",
      "title_zh": "腹腔镜肝切除术中无 Landmark 的术前-术中配准\n",
      "authors": [
        "Jun Zhou",
        "Bingchen Gao",
        "Kai Wang",
        "Jialun Pei",
        "Pheng-Ann Heng",
        "Jing Qin"
      ],
      "abstract": "Liver registration by overlaying preoperative 3D models onto intraoperative\n2D frames can assist surgeons in perceiving the spatial anatomy of the liver\nclearly for a higher surgical success rate. Existing registration methods rely\nheavily on anatomical landmark-based workflows, which encounter two major\nlimitations: 1) ambiguous landmark definitions fail to provide efficient\nmarkers for registration; 2) insufficient integration of intraoperative liver\nvisual information in shape deformation modeling. To address these challenges,\nin this paper, we propose a landmark-free preoperative-to-intraoperative\nregistration framework utilizing effective self-supervised learning, termed\n\\ourmodel. This framework transforms the conventional 3D-2D workflow into a\n3D-3D registration pipeline, which is then decoupled into rigid and non-rigid\nregistration subtasks. \\ourmodel~first introduces a feature-disentangled\ntransformer to learn robust correspondences for recovering rigid\ntransformations. Further, a structure-regularized deformation network is\ndesigned to adjust the preoperative model to align with the intraoperative\nliver surface. This network captures structural correlations through geometry\nsimilarity modeling in a low-rank transformer network. To facilitate the\nvalidation of the registration performance, we also construct an in-vivo\nregistration dataset containing liver resection videos of 21 patients, called\n\\emph{P2I-LReg}, which contains 346 keyframes that provide a global view of the\nliver together with liver mask annotations and calibrated camera intrinsic\nparameters. Extensive experiments and user studies on both synthetic and\nin-vivo datasets demonstrate the superiority and potential clinical\napplicability of our method.",
      "tldr_zh": "该论文提出了一种无需地标(landmark-free)的术前-术中肝脏配准框架，旨在解决传统基于地标配准方法在腹腔镜肝切除术中遇到的问题。该框架名为\\ourmodel，通过自监督学习将3D-2D配准流程转化为3D-3D配准，并将其解耦为刚性和非刚性配准子任务。 \\ourmodel首先引入特征解耦Transformer学习鲁棒的对应关系以恢复刚性变换，然后设计结构正则化的变形网络，通过低秩Transformer网络中的几何相似性建模来调整术前模型以对齐术中肝脏表面。此外，作者构建了一个包含21名患者肝切除视频的体内配准数据集\\emph{P2I-LReg}，包含346个关键帧。实验结果表明，该方法在合成和体内数据集上均表现出优越性。\n",
      "categories": [
        "cs.CV",
        "cs.AI"
      ],
      "primary_category": "cs.CV",
      "comment": "TMI under review",
      "pdf_url": "http://arxiv.org/pdf/2504.15152v1",
      "published_date": "2025-04-21 14:55:57 UTC",
      "updated_date": "2025-04-21 14:55:57 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-04-23T02:16:12.047614"
    },
    {
      "arxiv_id": "2504.15146v1",
      "title": "Behavioral Universe Network (BUN): A Behavioral Information-Based Framework for Complex Systems",
      "title_zh": "行为宇宙网络 (BUN)：一种基于行为信息的复杂系统框架\n",
      "authors": [
        "Wei Zhou",
        "Ailiya Borjigin",
        "Cong He"
      ],
      "abstract": "Modern digital ecosystems feature complex, dynamic interactions among\nautonomous entities across diverse domains. Traditional models often separate\nagents and objects, lacking a unified foundation to capture their interactive\nbehaviors. This paper introduces the Behavioral Universe Network (BUN), a\ntheoretical framework grounded in the Agent-Interaction-Behavior (AIB)\nformalism. BUN treats subjects (active agents), objects (resources), and\nbehaviors (operations) as first-class entities, all governed by a shared\nBehavioral Information Base (BIB). We detail the AIB core concepts and\ndemonstrate how BUN leverages information-driven triggers, semantic enrichment,\nand adaptive rules to coordinate multi-agent systems. We highlight key\nbenefits: enhanced behavior analysis, strong adaptability, and cross-domain\ninteroperability. We conclude by positioning BUN as a promising foundation for\nnext-generation digital governance and intelligent applications.",
      "tldr_zh": "本文提出了一种名为行为宇宙网络(Behavioral Universe Network, BUN)的理论框架，用于建模复杂系统中的交互行为。BUN基于主体-交互-行为(Agent-Interaction-Behavior, AIB)形式主义，将主体(agents)、客体(objects)和行为(behaviors)视为一等公民，并由共享的行为信息库(Behavioral Information Base, BIB)管理。BUN利用信息驱动的触发器、语义丰富和自适应规则来协调多智能体系统，从而实现增强的行为分析、强大的适应性和跨领域互操作性。该框架为下一代数字治理和智能应用提供了一个有前景的基础。\n",
      "categories": [
        "cs.AI"
      ],
      "primary_category": "cs.AI",
      "comment": "17 pages, 1 figure",
      "pdf_url": "http://arxiv.org/pdf/2504.15146v1",
      "published_date": "2025-04-21 14:50:28 UTC",
      "updated_date": "2025-04-21 14:50:28 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-04-23T02:16:23.596349"
    },
    {
      "arxiv_id": "2504.15144v1",
      "title": "C2RUST-BENCH: A Minimized, Representative Dataset for C-to-Rust Transpilation Evaluation",
      "title_zh": "C2RUST-BENCH：一个最小化的、具有代表性的数据集，用于评估 C 到 Rust 的转译\n",
      "authors": [
        "Melih Sirlanci",
        "Carter Yagemann",
        "Zhiqiang Lin"
      ],
      "abstract": "Despite the effort in vulnerability detection over the last two decades,\nmemory safety vulnerabilities continue to be a critical problem. Recent reports\nsuggest that the key solution is to migrate to memory-safe languages. To this\nend, C-to-Rust transpilation becomes popular to resolve memory-safety issues in\nC programs. Recent works propose C-to-Rust transpilation frameworks; however, a\ncomprehensive evaluation dataset is missing. Although one solution is to put\ntogether a large enough dataset, this increases the analysis time in automated\nframeworks as well as in manual efforts for some cases. In this work, we build\na method to select functions from a large set to construct a minimized yet\nrepresentative dataset to evaluate the C-to-Rust transpilation. We propose\nC2RUST-BENCH that contains 2,905 functions, which are representative of\nC-to-Rust transpilation, selected from 15,503 functions of real-world programs.",
      "tldr_zh": "该研究针对C到Rust代码转换领域缺乏全面评估数据集的问题，提出了C2RUST-BENCH，一个最小化但具有代表性的数据集。该数据集从真实世界的程序中选取，包含2905个函数，旨在更有效地评估C-to-Rust转换工具的性能。通过构建该数据集，研究人员旨在解决内存安全漏洞问题，并推动C到Rust迁移的进程。C2RUST-BENCH的提出，降低了自动化框架的分析时间，并减少了手动评估的工作量。\n",
      "categories": [
        "cs.CR",
        "cs.AI",
        "cs.PL"
      ],
      "primary_category": "cs.CR",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2504.15144v1",
      "published_date": "2025-04-21 14:48:45 UTC",
      "updated_date": "2025-04-21 14:48:45 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-04-23T02:16:35.689022"
    },
    {
      "arxiv_id": "2504.15135v1",
      "title": "KGMEL: Knowledge Graph-Enhanced Multimodal Entity Linking",
      "title_zh": "KGMEL：知识图谱增强的多模态实体链接\n",
      "authors": [
        "Juyeon Kim",
        "Geon Lee",
        "Taeuk Kim",
        "Kijung Shin"
      ],
      "abstract": "Entity linking (EL) aligns textual mentions with their corresponding entities\nin a knowledge base, facilitating various applications such as semantic search\nand question answering. Recent advances in multimodal entity linking (MEL) have\nshown that combining text and images can reduce ambiguity and improve alignment\naccuracy. However, most existing MEL methods overlook the rich structural\ninformation available in the form of knowledge-graph (KG) triples. In this\npaper, we propose KGMEL, a novel framework that leverages KG triples to enhance\nMEL. Specifically, it operates in three stages: (1) Generation: Produces\nhigh-quality triples for each mention by employing vision-language models based\non its text and images. (2) Retrieval: Learns joint mention-entity\nrepresentations, via contrastive learning, that integrate text, images, and\n(generated or KG) triples to retrieve candidate entities for each mention. (3)\nReranking: Refines the KG triples of the candidate entities and employs large\nlanguage models to identify the best-matching entity for the mention. Extensive\nexperiments on benchmark datasets demonstrate that KGMEL outperforms existing\nmethods. Our code and datasets are available at:\nhttps://github.com/juyeonnn/KGMEL.",
      "tldr_zh": "本文提出了一种知识图谱增强的多模态实体链接框架KGMEL，旨在提升多模态实体链接(MEL)的准确性。KGMEL框架包含三个阶段：首先，利用视觉-语言模型(vision-language models)基于文本和图像为每个mention生成高质量的知识图谱三元组；其次，通过对比学习，学习融合文本、图像和三元组的联合mention-entity表示，从而检索候选实体；最后，提炼候选实体的知识图谱三元组，并利用大型语言模型(large language models)识别与mention最佳匹配的实体。在基准数据集上的实验表明，KGMEL优于现有的MEL方法。\n",
      "categories": [
        "cs.IR",
        "cs.AI",
        "cs.CL"
      ],
      "primary_category": "cs.IR",
      "comment": "SIGIR 2025 (Short)",
      "pdf_url": "http://arxiv.org/pdf/2504.15135v1",
      "published_date": "2025-04-21 14:38:44 UTC",
      "updated_date": "2025-04-21 14:38:44 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-04-23T02:16:47.733596"
    },
    {
      "arxiv_id": "2504.15133v1",
      "title": "EasyEdit2: An Easy-to-use Steering Framework for Editing Large Language Models",
      "title_zh": "EasyEdit2：一种易于使用的大语言模型编辑引导框架\n",
      "authors": [
        "Ziwen Xu",
        "Shuxun Wang",
        "Kewei Xu",
        "Haoming Xu",
        "Mengru Wang",
        "Xinle Deng",
        "Yunzhi Yao",
        "Guozhou Zheng",
        "Huajun Chen",
        "Ningyu Zhang"
      ],
      "abstract": "In this paper, we introduce EasyEdit2, a framework designed to enable\nplug-and-play adjustability for controlling Large Language Model (LLM)\nbehaviors. EasyEdit2 supports a wide range of test-time interventions,\nincluding safety, sentiment, personality, reasoning patterns, factuality, and\nlanguage features. Unlike its predecessor, EasyEdit2 features a new\narchitecture specifically designed for seamless model steering. It comprises\nkey modules such as the steering vector generator and the steering vector\napplier, which enable automatic generation and application of steering vectors\nto influence the model's behavior without modifying its parameters. One of the\nmain advantages of EasyEdit2 is its ease of use-users do not need extensive\ntechnical knowledge. With just a single example, they can effectively guide and\nadjust the model's responses, making precise control both accessible and\nefficient. Empirically, we report model steering performance across different\nLLMs, demonstrating the effectiveness of these techniques. We have released the\nsource code on GitHub at https://github.com/zjunlp/EasyEdit along with a\ndemonstration notebook. In addition, we provide a demo video at\nhttps://zjunlp.github.io/project/EasyEdit2/video for a quick introduction.",
      "tldr_zh": "本文介绍了EasyEdit2，一个即插即用的框架，旨在控制大型语言模型(LLM)的行为。EasyEdit2支持多种测试时干预，包括安全性、情感、个性、推理模式、事实性和语言特征。与前代产品不同，EasyEdit2采用专为无缝模型控制而设计的新架构，包含steering vector generator和steering vector applier等关键模块，可以自动生成和应用steering vectors，从而影响模型的行为，而无需修改其参数。EasyEdit2的主要优点之一是易于使用，用户无需广泛的技术知识，只需一个示例，就可以有效地指导和调整模型的响应，从而使精确控制既可访问又高效。实验报告了不同LLM的模型控制性能，证明了这些技术的有效性。\n",
      "categories": [
        "cs.CL",
        "cs.AI",
        "cs.CV",
        "cs.HC",
        "cs.LG"
      ],
      "primary_category": "cs.CL",
      "comment": "Work in progress. Demo:\n  https://zjunlp.github.io/project/EasyEdit2/video; code:\n  https://github.com/zjunlp/EasyEdit",
      "pdf_url": "http://arxiv.org/pdf/2504.15133v1",
      "published_date": "2025-04-21 14:33:55 UTC",
      "updated_date": "2025-04-21 14:33:55 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-04-23T02:16:59.794498"
    },
    {
      "arxiv_id": "2504.15130v1",
      "title": "Neural ATTF: A Scalable Solution to Lifelong Multi-Agent Path Planning",
      "title_zh": "神经ATTF：一种可扩展的终身多智能体路径规划解决方案\n",
      "authors": [
        "Kushal Shah",
        "Jihyun Park",
        "Seung-Kyum Choi"
      ],
      "abstract": "Multi-Agent Pickup and Delivery (MAPD) is a fundamental problem in robotics,\nparticularly in applications such as warehouse automation and logistics.\nExisting solutions often face challenges in scalability, adaptability, and\nefficiency, limiting their applicability in dynamic environments with real-time\nplanning requirements. This paper presents Neural ATTF (Adaptive Task Token\nFramework), a new algorithm that combines a Priority Guided Task Matching\n(PGTM) Module with Neural STA* (Space-Time A*), a data-driven path planning\nmethod. Neural STA* enhances path planning by enabling rapid exploration of the\nsearch space through guided learned heuristics and ensures collision avoidance\nunder dynamic constraints. PGTM prioritizes delayed agents and dynamically\nassigns tasks by prioritizing agents nearest to these tasks, optimizing both\ncontinuity and system throughput. Experimental evaluations against\nstate-of-the-art MAPD algorithms, including TPTS, CENTRAL, RMCA, LNS-PBS, and\nLNS-wPBS, demonstrate the superior scalability, solution quality, and\ncomputational efficiency of Neural ATTF. These results highlight the\nframework's potential for addressing the critical demands of complex,\nreal-world multi-agent systems operating in high-demand, unpredictable\nsettings.",
      "tldr_zh": "本文提出了一种新的终身多智能体路径规划算法 Neural ATTF (Adaptive Task Token Framework)，旨在解决多智能体取货和配送 (MAPD) 问题中现有方案的可扩展性、适应性和效率挑战。Neural ATTF 结合了优先引导任务匹配 (PGTM) 模块和 Neural STA* (Space-Time A*)，后者是一种数据驱动的路径规划方法，通过学习到的启发式方法快速探索搜索空间并确保动态约束下的避碰。PGTM 优先考虑延迟的智能体，并通过优先分配给距离任务最近的智能体来动态分配任务，从而优化连续性和系统吞吐量。实验结果表明，与 TPTS、CENTRAL、RMCA、LNS-PBS 和 LNS-wPBS 等最先进的 MAPD 算法相比，Neural ATTF 具有卓越的可扩展性、解决方案质量和计算效率，证明了其在复杂、高需求、不可预测的现实世界多智能体系统中应用的潜力。\n",
      "categories": [
        "cs.RO",
        "cs.AI"
      ],
      "primary_category": "cs.RO",
      "comment": "13 Pages, 5 Figures, 5 Tables",
      "pdf_url": "http://arxiv.org/pdf/2504.15130v1",
      "published_date": "2025-04-21 14:25:32 UTC",
      "updated_date": "2025-04-21 14:25:32 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-04-23T02:17:12.119895"
    },
    {
      "arxiv_id": "2504.15129v1",
      "title": "A General Infrastructure and Workflow for Quadrotor Deep Reinforcement Learning and Reality Deployment",
      "title_zh": "一种用于四旋翼深度强化学习和现实部署的通用基础设施和工作流\n",
      "authors": [
        "Kangyao Huang",
        "Hao Wang",
        "Yu Luo",
        "Jingyu Chen",
        "Jintao Chen",
        "Xiangkui Zhang",
        "Xiangyang Ji",
        "Huaping Liu"
      ],
      "abstract": "Deploying robot learning methods to a quadrotor in unstructured outdoor\nenvironments is an exciting task. Quadrotors operating in real-world\nenvironments by learning-based methods encounter several challenges: a large\namount of simulator generated data required for training, strict demands for\nreal-time processing onboard, and the sim-to-real gap caused by dynamic and\nnoisy conditions. Current works have made a great breakthrough in applying\nlearning-based methods to end-to-end control of quadrotors, but rarely mention\nthe infrastructure system training from scratch and deploying to reality, which\nmakes it difficult to reproduce methods and applications. To bridge this gap,\nwe propose a platform that enables the seamless transfer of end-to-end deep\nreinforcement learning (DRL) policies. We integrate the training environment,\nflight dynamics control, DRL algorithms, the MAVROS middleware stack, and\nhardware into a comprehensive workflow and architecture that enables\nquadrotors' policies to be trained from scratch to real-world deployment in\nseveral minutes. Our platform provides rich types of environments including\nhovering, dynamic obstacle avoidance, trajectory tracking, balloon hitting, and\nplanning in unknown environments, as a physical experiment benchmark. Through\nextensive empirical validation, we demonstrate the efficiency of proposed\nsim-to-real platform, and robust outdoor flight performance under real-world\nperturbations. Details can be found from our website\nhttps://emnavi.tech/AirGym/.",
      "tldr_zh": "本文提出了一种通用的四旋翼无人机深度强化学习(DRL)基础设施和工作流程，旨在解决学习方法在非结构化户外环境中部署的挑战，如训练数据需求量大、实时处理要求高以及Sim-to-Real差距。该平台集成了训练环境、飞行动力学控制、DRL算法、MAVROS中间件和硬件，实现了端到端DRL策略从零开始训练到真实部署的无缝迁移。该平台提供多种环境，包括悬停、动态避障、轨迹跟踪等，并经过大量实验验证，证明了其Sim-to-Real效率和在真实扰动下的鲁棒性。该平台为四旋翼无人机的学习方法研究和应用提供了一个可复现的基准。\n",
      "categories": [
        "cs.RO",
        "cs.AI",
        "cs.CV",
        "cs.LG"
      ],
      "primary_category": "cs.RO",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2504.15129v1",
      "published_date": "2025-04-21 14:25:23 UTC",
      "updated_date": "2025-04-21 14:25:23 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-04-23T02:17:24.041725"
    },
    {
      "arxiv_id": "2504.15125v1",
      "title": "Contemplative Wisdom for Superalignment",
      "title_zh": "用于超对齐的沉思智慧\n",
      "authors": [
        "Ruben Laukkonen",
        "Fionn Inglis",
        "Shamil Chandaria",
        "Lars Sandved-Smith",
        "Jakob Hohwy",
        "Jonathan Gold",
        "Adam Elwood"
      ],
      "abstract": "As artificial intelligence (AI) improves, traditional alignment strategies\nmay falter in the face of unpredictable self-improvement, hidden subgoals, and\nthe sheer complexity of intelligent systems. Rather than externally\nconstraining behavior, we advocate designing AI with intrinsic morality built\ninto its cognitive architecture and world model. Inspired by contemplative\nwisdom traditions, we show how four axiomatic principles can instil a resilient\nWise World Model in AI systems. First, mindfulness enables self-monitoring and\nrecalibration of emergent subgoals. Second, emptiness forestalls dogmatic goal\nfixation and relaxes rigid priors. Third, non-duality dissolves adversarial\nself-other boundaries. Fourth, boundless care motivates the universal reduction\nof suffering. We find that prompting AI to reflect on these principles improves\nperformance on the AILuminate Benchmark using GPT-4o, particularly when\ncombined. We offer detailed implementation strategies for state-of-the-art\nmodels, including contemplative architectures, constitutions, and reinforcement\nof chain-of-thought. For future systems, the active inference framework may\noffer the self-organizing and dynamic coupling capabilities needed to enact\nthese insights in embodied agents. This interdisciplinary approach offers a\nself-correcting and resilient alternative to prevailing brittle control\nschemes.",
      "tldr_zh": "本文提出了一种新的AI对齐策略，借鉴冥想智慧传统，旨在构建具有内在道德的AI系统，以应对传统对齐策略在面对AI自我改进和复杂性时的局限性。该策略基于四个原则：正念（mindfulness）、空性（emptiness）、非二元性（non-duality）和无量关怀（boundless care），旨在AI系统中构建一个具有弹性的“智慧世界模型”（Wise World Model）。实验表明，使用GPT-4o提示AI反思这些原则可以提高AILuminate Benchmark的性能，特别是当结合使用时。文章还提供了针对当前模型的详细实施策略，并探讨了主动推理框架（active inference framework）在具身智能体中实现这些原则的潜力。该方法提供了一种自我纠正和有弹性的替代方案，以取代目前脆弱的控制方案。\n",
      "categories": [
        "cs.AI"
      ],
      "primary_category": "cs.AI",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2504.15125v1",
      "published_date": "2025-04-21 14:20:49 UTC",
      "updated_date": "2025-04-21 14:20:49 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-04-23T02:17:36.082040"
    },
    {
      "arxiv_id": "2504.15120v1",
      "title": "Kuwain 1.5B: An Arabic SLM via Language Injection",
      "title_zh": "Kuwain 1.5B：一种通过语言注入实现的阿拉伯语SLM\n",
      "authors": [
        "Khalil Hennara",
        "Sara Chrouf",
        "Mohamed Motaism Hamed",
        "Zeina Aldallal",
        "Omar Hadid",
        "Safwan AlModhayan"
      ],
      "abstract": "Enhancing existing models with new knowledge is a crucial aspect of AI\ndevelopment. This paper introduces a novel method for integrating a new\nlanguage into a large language model (LLM). Our approach successfully\nincorporates a previously unseen target language into an existing LLM without\ncompromising its prior knowledge. We trained a tiny model with 1.5 billion\nparameters named Kuwain by injecting the Arabic language into a small\nopen-source model mainly trained in English. Our method demonstrates\nsignificant improvements in Arabic language performance, with an average 8%\nimprovement across various benchmarks, while retaining the model's existing\nknowledge with a minimum amount of the original model's data. This offers a\ncost-effective alternative to training a comprehensive model in both English\nand Arabic. The results highlight the potential for efficient, targeted\nlanguage model expansion without extensive retraining or resource-intensive\nprocesses.",
      "tldr_zh": "该论文提出了一种新颖的语言注入方法，用于将新的语言集成到大型语言模型(LLM)中，且不损害其原有知识。通过将阿拉伯语注入到一个主要使用英语训练的小型开源模型中，训练了一个名为Kuwain的15亿参数的小型模型。实验结果表明，Kuwain在各种阿拉伯语基准测试中平均提高了8%的性能，同时保留了模型现有的知识。这种方法为高效、有针对性的语言模型扩展提供了一种经济高效的替代方案，无需进行广泛的重新训练或资源密集型流程。\n",
      "categories": [
        "cs.CL",
        "cs.AI"
      ],
      "primary_category": "cs.CL",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2504.15120v1",
      "published_date": "2025-04-21 14:17:25 UTC",
      "updated_date": "2025-04-21 14:17:25 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-04-23T02:17:47.682247"
    },
    {
      "arxiv_id": "2504.15105v1",
      "title": "A triple-branch network for latent fingerprint enhancement guided by orientation fields and minutiae",
      "title_zh": "一种由方向场和细节点引导的潜在指纹增强三分支网络\n",
      "authors": [
        "Yurun Wang",
        "Zerong Qi",
        "Shujun Fu",
        "Mingzheng Hu"
      ],
      "abstract": "Latent fingerprint enhancement is a critical step in the process of latent\nfingerprint identification. Existing deep learning-based enhancement methods\nstill fall short of practical application requirements, particularly in\nrestoring low-quality fingerprint regions. Recognizing that different regions\nof latent fingerprints require distinct enhancement strategies, we propose a\nTriple Branch Spatial Fusion Network (TBSFNet), which simultaneously enhances\ndifferent regions of the image using tailored strategies. Furthermore, to\nimprove the generalization capability of the network, we integrate orientation\nfield and minutiae-related modules into TBSFNet and introduce a Multi-Level\nFeature Guidance Network (MLFGNet). Experimental results on the MOLF and MUST\ndatasets demonstrate that MLFGNet outperforms existing enhancement algorithms.",
      "tldr_zh": "本文提出了一种三分支空间融合网络(TBSFNet)用于潜在指纹增强，旨在解决现有深度学习方法在低质量指纹区域恢复方面的不足。该网络针对指纹不同区域采用定制的增强策略，同时利用方向场和细节点信息，通过多层特征引导网络(MLFGNet)提高泛化能力。在MOLF和MUST数据集上的实验结果表明，MLFGNet优于现有的增强算法。该方法针对性地处理指纹不同区域，有效提升了低质量指纹的增强效果。\n",
      "categories": [
        "cs.CV",
        "cs.AI"
      ],
      "primary_category": "cs.CV",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2504.15105v1",
      "published_date": "2025-04-21 13:54:33 UTC",
      "updated_date": "2025-04-21 13:54:33 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-04-23T02:17:59.760157"
    },
    {
      "arxiv_id": "2504.15101v1",
      "title": "NeuGaze: Reshaping the future BCI",
      "title_zh": "NeuGaze：重塑未来脑机接口\n",
      "authors": [
        "Yiqian Yang"
      ],
      "abstract": "Traditional brain-computer interfaces (BCIs), reliant on costly\nelectroencephalography or invasive implants, struggle with complex\nhuman-computer interactions due to setup complexity and limited precision. We\npresent NeuGaze, a novel webcam-based system that leverages eye gaze, head\nmovements, and facial expressions to enable intuitive, real-time control using\nonly a standard 30 Hz webcam, often pre-installed in laptops. Requiring minimal\ncalibration, NeuGaze achieves performance comparable to conventional inputs,\nsupporting precise cursor navigation, key triggering via an efficient skill\nwheel, and dynamic gaming interactions, such as defeating formidable opponents\nin first-person games. By harnessing preserved neck-up functionalities in\nmotor-impaired individuals, NeuGaze eliminates the need for specialized\nhardware, offering a low-cost, accessible alternative to BCIs. This paradigm\nempowers diverse applications, from assistive technology to entertainment,\nredefining human-computer interaction for motor-impaired users. Project is at\n\\href{https://github.com/NeuSpeech/NeuGaze}{github.com/NeuSpeech/NeuGaze}.",
      "tldr_zh": "NeuGaze 是一种新型的基于网络摄像头的脑机接口(BCI)系统，它利用眼动、头部运动和面部表情来实现直观、实时的控制，无需传统的脑电图或植入式设备。该系统仅需一个标准的 30Hz 摄像头，经过最少的校准，就能达到与传统输入设备相当的性能，支持精确的光标导航、通过高效技能轮盘触发按键，以及动态的游戏互动。NeuGaze 通过利用运动障碍人士保留的颈部以上功能，无需专门的硬件，为 BCI 提供了一种低成本、易于使用的替代方案，适用于辅助技术和娱乐等多种应用。\n",
      "categories": [
        "cs.HC",
        "cs.AI",
        "cs.ET"
      ],
      "primary_category": "cs.HC",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2504.15101v1",
      "published_date": "2025-04-21 13:49:17 UTC",
      "updated_date": "2025-04-21 13:49:17 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-04-23T02:18:11.875664"
    },
    {
      "arxiv_id": "2504.15099v1",
      "title": "Fast-Slow Co-advancing Optimizer: Toward Harmonious Adversarial Training of GAN",
      "title_zh": "快速-慢速协同推进优化器：迈向 GAN 的和谐对抗训练\n",
      "authors": [
        "Lin Wang",
        "Xiancheng Wang",
        "Rui Wang",
        "Zhibo Zhang",
        "Minghang Zhao"
      ],
      "abstract": "Up to now, the training processes of typical Generative Adversarial Networks\n(GANs) are still particularly sensitive to data properties and hyperparameters,\nwhich may lead to severe oscillations, difficulties in convergence, or even\nfailures to converge, especially when the overall variances of the training\nsets are large. These phenomena are often attributed to the training\ncharacteristics of such networks. Aiming at the problem, this paper develops a\nnew intelligent optimizer, Fast-Slow Co-advancing Optimizer (FSCO), which\nemploys reinforcement learning in the training process of GANs to make training\neasier. Specifically, this paper allows the training step size to be controlled\nby an agent to improve training stability, and makes the training process more\nintelligent with variable learning rates, making GANs less sensitive to step\nsize. Experiments have been conducted on three benchmark datasets to verify the\neffectiveness of the developed FSCO.",
      "tldr_zh": "这篇论文提出了一种新的智能优化器，名为快速-慢速协同推进优化器 (Fast-Slow Co-advancing Optimizer, FSCO)，旨在解决生成对抗网络 (GANs) 训练过程中对数据属性和超参数的敏感问题，以及由此导致的震荡、收敛困难甚至无法收敛的问题。FSCO 在 GAN 的训练过程中引入了强化学习，通过智能体控制训练步长来提高训练的稳定性，并采用可变学习率使 GAN 对步长不敏感，从而使训练过程更加智能。在三个基准数据集上的实验验证了 FSCO 的有效性。\n",
      "categories": [
        "cs.LG",
        "cs.AI"
      ],
      "primary_category": "cs.LG",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2504.15099v1",
      "published_date": "2025-04-21 13:41:09 UTC",
      "updated_date": "2025-04-21 13:41:09 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-04-23T02:18:23.744854"
    },
    {
      "arxiv_id": "2504.15093v1",
      "title": "Rethinking the Potential of Multimodality in Collaborative Problem Solving Diagnosis with Large Language Models",
      "title_zh": "重新思考多模态在利用大型语言模型进行协同问题解决诊断中的潜力\n",
      "authors": [
        "K. Wong",
        "B. Wu",
        "S. Bulathwela",
        "M. Cukurova"
      ],
      "abstract": "Detecting collaborative and problem-solving behaviours from digital traces to\ninterpret students' collaborative problem solving (CPS) competency is a\nlong-term goal in the Artificial Intelligence in Education (AIEd) field.\nAlthough multimodal data and advanced models are argued to have the potential\nto detect complex CPS behaviours, empirical evidence on their value remains\nlimited with some contrasting evidence. In this study, we investigated the\npotential of multimodal data to improve model performance in diagnosing 78\nsecondary school students' CPS subskills and indicators in authentic\neducational settings. In particular, text embeddings from verbal data and\nacoustic embeddings from audio data were used in a multimodal classification\nmodel for CPS diagnosis. Both unimodal and multimodal transformer-based models\noutperformed traditional models in detecting CPS classes. Although the\ninclusion of multimodality did not improve the performance of traditional\nunimodal models, its integration into transformer-based models demonstrated\nimproved performance for diagnosing social-cognitive CPS classes compared to\nunimodal transformer-based models. Based on the results, the paper argues that\nmultimodality and the selection of a particular modelling technique should not\nbe taken for granted to achieve the best performance in the automated detection\nof every CPS subskill and indicator. Rather, their value is limited to certain\ntypes of CPS indicators, affected by the complexity of the labels, and\ndependent on the composition of indicators in the dataset. We conclude the\npaper by discussing the required nuance when considering the value of LLMs and\nmultimodality in automated CPS diagnosis, highlighting the need for human-AI\ncomplementarity, and proposing the exploration of relevant model architectures\nand techniques to improve CPS diagnosis in authentic educational contexts.",
      "tldr_zh": "该研究探讨了多模态数据在利用大型语言模型(LLMs)诊断学生协作问题解决(CPS)能力方面的潜力。研究人员使用来自78名中学生的真实教育环境数据，结合文本嵌入（来自口头数据）和声学嵌入（来自音频数据），构建多模态分类模型来诊断CPS子技能和指标。结果表明，基于Transformer的单模态和多模态模型均优于传统模型。虽然多模态数据并未提升传统单模态模型的性能，但其与Transformer模型的集成在诊断社交认知CPS类别时表现出更好的性能。研究强调，多模态和建模技术的选择并非总能保证在自动检测所有CPS子技能和指标方面取得最佳效果，其价值受限于特定类型的CPS指标，并受到标签复杂性和数据集组成的影响。该研究最后讨论了在自动CPS诊断中考虑LLMs和多模态价值时所需的细微差别，强调人机互补的必要性，并建议探索相关的模型架构和技术以改进真实教育环境中的CPS诊断。\n",
      "categories": [
        "cs.CL",
        "cs.AI",
        "cs.LG"
      ],
      "primary_category": "cs.CL",
      "comment": "Accepted for 26th International Conference on Artificial Intelligence\n  in Education (AIED 2025), 22 - 26 July 2025, Palermo, Italy. 17 pages, 1\n  figure",
      "pdf_url": "http://arxiv.org/pdf/2504.15093v1",
      "published_date": "2025-04-21 13:25:55 UTC",
      "updated_date": "2025-04-21 13:25:55 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-04-23T02:18:36.285111"
    },
    {
      "arxiv_id": "2504.15090v1",
      "title": "Federated Latent Factor Model for Bias-Aware Recommendation with Privacy-Preserving",
      "title_zh": "用于偏差感知推荐的联邦隐因子模型，具有隐私保护功能",
      "authors": [
        "Junxiang Gao",
        "Yixin Ran",
        "Jia Chen"
      ],
      "abstract": "A recommender system (RS) aims to provide users with personalized item\nrecommendations, enhancing their overall experience. Traditional RSs collect\nand process all user data on a central server. However, this centralized\napproach raises significant privacy concerns, as it increases the risk of data\nbreaches and privacy leakages, which are becoming increasingly unacceptable to\nprivacy-sensitive users. To address these privacy challenges, federated\nlearning has been integrated into RSs, ensuring that user data remains secure.\nIn centralized RSs, the issue of rating bias is effectively addressed by\njointly analyzing all users' raw interaction data. However, this becomes a\nsignificant challenge in federated RSs, as raw data is no longer accessible due\nto privacy-preserving constraints. To overcome this problem, we propose a\nFederated Bias-Aware Latent Factor (FBALF) model. In FBALF, training bias is\nexplicitly incorporated into every local model's loss function, allowing for\nthe effective elimination of rating bias without compromising data privacy.\nExtensive experiments conducted on three real-world datasets demonstrate that\nFBALF achieves significantly higher recommendation accuracy compared to other\nstate-of-the-art federated RSs.",
      "tldr_zh": "本文提出了一种联邦偏差感知潜在因子模型(FBALF)，旨在解决联邦推荐系统中的数据隐私和评分偏差问题。FBALF将训练偏差显式地纳入每个本地模型的损失函数中，从而在不损害数据隐私的情况下有效消除评分偏差。该方法克服了联邦学习中原始数据不可访问带来的挑战，实现了偏差感知的推荐。在三个真实世界数据集上的实验结果表明，FBALF相比其他先进的联邦推荐系统，显著提高了推荐准确率。\n",
      "categories": [
        "cs.LG",
        "cs.AI"
      ],
      "primary_category": "cs.LG",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2504.15090v1",
      "published_date": "2025-04-21 13:24:30 UTC",
      "updated_date": "2025-04-21 13:24:30 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-04-23T02:18:47.673171"
    },
    {
      "arxiv_id": "2504.15080v1",
      "title": "Empowering AI to Generate Better AI Code: Guided Generation of Deep Learning Projects with LLMs",
      "title_zh": "赋能 AI 生成更优 AI 代码：利用 LLM 指导生成深度学习项目\n",
      "authors": [
        "Chen Xie",
        "Mingsheng Jiao",
        "Xiaodong Gu",
        "Beijun Shen"
      ],
      "abstract": "While large language models (LLMs) have been widely applied to code\ngeneration, they struggle with generating entire deep learning projects, which\nare characterized by complex structures, longer functions, and stronger\nreliance on domain knowledge than general-purpose code. An open-domain LLM\noften lacks coherent contextual guidance and domain expertise for specific\nprojects, making it challenging to produce complete code that fully meets user\nrequirements.\n  In this paper, we propose a novel planning-guided code generation method,\nDLCodeGen, tailored for generating deep learning projects. DLCodeGen predicts a\nstructured solution plan, offering global guidance for LLMs to generate the\nproject. The generated plan is then leveraged to retrieve semantically\nanalogous code samples and subsequently abstract a code template. To\neffectively integrate these multiple retrieval-augmented techniques, a\ncomparative learning mechanism is designed to generate the final code. We\nvalidate the effectiveness of our approach on a dataset we build for deep\nlearning code generation. Experimental results demonstrate that DLCodeGen\noutperforms other baselines, achieving improvements of 9.7% in CodeBLEU and\n3.6% in human evaluation metrics.",
      "tldr_zh": "该论文提出了一种名为DLCodeGen的规划引导代码生成方法，专门用于生成深度学习项目。DLCodeGen首先预测一个结构化的解决方案计划，为LLM生成项目提供全局指导。然后，利用生成的计划检索语义相似的代码样本，并提取代码模板。通过比较学习机制，有效地整合这些检索增强技术，生成最终代码。实验结果表明，在深度学习代码生成数据集上，DLCodeGen优于其他基线模型，CodeBLEU提高了9.7%，人工评估指标提高了3.6%。\n",
      "categories": [
        "cs.SE",
        "cs.AI"
      ],
      "primary_category": "cs.SE",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2504.15080v1",
      "published_date": "2025-04-21 13:09:25 UTC",
      "updated_date": "2025-04-21 13:09:25 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-04-23T02:18:59.593750"
    },
    {
      "arxiv_id": "2504.15075v1",
      "title": "Mitigating Degree Bias in Graph Representation Learning with Learnable Structural Augmentation and Structural Self-Attention",
      "title_zh": "利用可学习的结构增强和结构自注意力缓解图表示学习中的度偏差\n",
      "authors": [
        "Van Thuy Hoang",
        "Hyeon-Ju Jeon",
        "O-Joun Lee"
      ],
      "abstract": "Graph Neural Networks (GNNs) update node representations through message\npassing, which is primarily based on the homophily principle, assuming that\nadjacent nodes share similar features. However, in real-world graphs with\nlong-tailed degree distributions, high-degree nodes dominate message passing,\ncausing a degree bias where low-degree nodes remain under-represented due to\ninadequate messages. The main challenge in addressing degree bias is how to\ndiscover non-adjacent nodes to provide additional messages to low-degree nodes\nwhile reducing excessive messages for high-degree nodes. Nevertheless,\nexploiting non-adjacent nodes to provide valuable messages is challenging, as\nit could generate noisy information and disrupt the original graph structures.\nTo solve it, we propose a novel Degree Fairness Graph Transformer, named\nDegFairGT, to mitigate degree bias by discovering structural similarities\nbetween non-adjacent nodes through learnable structural augmentation and\nstructural self-attention. Our key idea is to exploit non-adjacent nodes with\nsimilar roles in the same community to generate informative edges under our\naugmentation, which could provide informative messages between nodes with\nsimilar roles while ensuring that the homophily principle is maintained within\nthe community. To enable DegFairGT to learn such structural similarities, we\nthen propose a structural self-attention to capture the similarities between\nnode pairs. To preserve global graph structures and prevent graph augmentation\nfrom hindering graph structure, we propose a Self-Supervised Learning task to\npreserve p-step transition probability and regularize graph augmentation.\nExtensive experiments on six datasets showed that DegFairGT outperformed\nstate-of-the-art baselines in degree fairness analysis, node classification,\nand node clustering tasks.",
      "tldr_zh": "该论文针对图神经网络(GNNs)中由于长尾度分布导致的高度节点主导消息传递，进而造成低度节点表示不足的度偏差问题，提出了DegFairGT (Degree Fairness Graph Transformer)。DegFairGT通过可学习的结构增强和结构自注意力机制，探索非邻接节点间的结构相似性，为低度节点提供额外信息，并减少高度节点的过度消息。具体来说，DegFairGT利用社区内具有相似角色的非邻接节点生成信息丰富的边，并通过结构自注意力捕捉节点对之间的相似性。同时，引入自监督学习任务，保持p步转移概率，防止图增强破坏全局结构。在六个数据集上的实验表明，DegFairGT在度公平性分析、节点分类和节点聚类任务中优于现有方法。\n",
      "categories": [
        "cs.AI",
        "cs.LG"
      ],
      "primary_category": "cs.AI",
      "comment": "Accepted at IEEE TNSE",
      "pdf_url": "http://arxiv.org/pdf/2504.15075v1",
      "published_date": "2025-04-21 13:03:40 UTC",
      "updated_date": "2025-04-21 13:03:40 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-04-23T02:19:12.052727"
    },
    {
      "arxiv_id": "2504.15066v1",
      "title": "Chinese-LiPS: A Chinese audio-visual speech recognition dataset with Lip-reading and Presentation Slides",
      "title_zh": "Chinese-LiPS：一个包含唇语和演示幻灯片的中文视听语音识别数据集\n",
      "authors": [
        "Jinghua Zhao",
        "Yuhang Jia",
        "Shiyao Wang",
        "Jiaming Zhou",
        "Hui Wang",
        "Yong Qin"
      ],
      "abstract": "Incorporating visual modalities to assist Automatic Speech Recognition (ASR)\ntasks has led to significant improvements. However, existing Audio-Visual\nSpeech Recognition (AVSR) datasets and methods typically rely solely on\nlip-reading information or speaking contextual video, neglecting the potential\nof combining these different valuable visual cues within the speaking context.\nIn this paper, we release a multimodal Chinese AVSR dataset, Chinese-LiPS,\ncomprising 100 hours of speech, video, and corresponding manual transcription,\nwith the visual modality encompassing both lip-reading information and the\npresentation slides used by the speaker. Based on Chinese-LiPS, we develop a\nsimple yet effective pipeline, LiPS-AVSR, which leverages both lip-reading and\npresentation slide information as visual modalities for AVSR tasks. Experiments\nshow that lip-reading and presentation slide information improve ASR\nperformance by approximately 8\\% and 25\\%, respectively, with a combined\nperformance improvement of about 35\\%. The dataset is available at\nhttps://kiri0824.github.io/Chinese-LiPS/",
      "tldr_zh": "该论文提出了一个多模态中文视听语音识别数据集Chinese-LiPS，包含100小时的语音、视频以及对应的手动转录。该数据集的视觉模态同时包含唇语信息和演讲者使用的幻灯片。研究者还提出了一个简单有效的流水线LiPS-AVSR，利用唇语和幻灯片信息作为AVSR任务的视觉模态。实验表明，唇语和幻灯片信息分别将ASR性能提高了约8%和25%，组合后性能提高了约35%。该数据集已公开。\n",
      "categories": [
        "cs.MM",
        "cs.AI"
      ],
      "primary_category": "cs.MM",
      "comment": "6 pages, 7 figures",
      "pdf_url": "http://arxiv.org/pdf/2504.15066v1",
      "published_date": "2025-04-21 12:51:54 UTC",
      "updated_date": "2025-04-21 12:51:54 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-04-23T02:19:23.741052"
    },
    {
      "arxiv_id": "2504.15063v1",
      "title": "Mining Characteristics of Vulnerable Smart Contracts Across Lifecycle Stages",
      "title_zh": "挖掘跨生命周期阶段的易受攻击智能合约的特征\n",
      "authors": [
        "Hongli Peng",
        "Xiaoqi Li",
        "Wenkai Li"
      ],
      "abstract": "Smart contracts are the cornerstone of decentralized applications and\nfinancial protocols, which extend the application of digital currency\ntransactions. The applications and financial protocols introduce significant\nsecurity challenges, resulting in substantial economic losses. Existing\nsolutions predominantly focus on code vulnerabilities within smart contracts,\naccounting for only 50% of security incidents. Therefore, a more comprehensive\nstudy of security issues related to smart contracts is imperative. The existing\nempirical research realizes the static analysis of smart contracts from the\nperspective of the lifecycle and gives the corresponding measures for each\nstage. However, they lack the characteristic analysis of vulnerabilities in\neach stage and the distinction between the vulnerabilities. In this paper, we\npresent the first empirical study on the security of smart contracts throughout\ntheir lifecycle, including deployment and execution, upgrade, and destruction\nstages. It delves into the security issues at each stage and provides at least\nseven feature descriptions. Finally, utilizing these seven features, five\nmachine-learning classification models are used to identify vulnerabilities at\ndifferent stages. The classification results reveal that vulnerable contracts\nexhibit distinct transaction features and ego network properties at various\nstages.",
      "tldr_zh": "本文首次对智能合约在整个生命周期（包括部署、执行、升级和销毁阶段）的安全性进行了实证研究。研究深入探讨了每个阶段的安全问题，并提供了至少七个特征描述。利用这些特征，研究人员使用五种机器学习分类模型来识别不同阶段的漏洞。分类结果表明，脆弱的合约在不同阶段表现出不同的交易特征和自我网络属性。这项研究为理解和解决智能合约生命周期中的安全问题提供了新的视角。\n",
      "categories": [
        "cs.CR",
        "cs.AI"
      ],
      "primary_category": "cs.CR",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2504.15063v1",
      "published_date": "2025-04-21 12:42:59 UTC",
      "updated_date": "2025-04-21 12:42:59 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-04-23T02:19:35.612126"
    },
    {
      "arxiv_id": "2504.15062v1",
      "title": "OPO: Making Decision-Focused Data Acquisition Decisions",
      "title_zh": "OPO：做出以决策为中心的数据采集决策\n",
      "authors": [
        "Egon Peršak",
        "Miguel F. Anjos"
      ],
      "abstract": "We propose a model for making data acquisition decisions for variables in\ncontextual stochastic optimisation problems. Data acquisition decisions are\ntypically treated as separate and fixed. We explore problem settings in which\nthe acquisition of contextual variables is costly and consequently constrained.\nThe data acquisition problem is often solved heuristically for proxy objectives\nsuch as coverage. The more intuitive objective is the downstream decision\nquality as a result of data acquisition decisions. The whole pipeline can be\ncharacterised as an optimise-then-predict-then-optimise (OPO) problem.\nAnalogously, much recent research has focused on how to integrate prediction\nand optimisation (PO) in the form of decision-focused learning. We propose\nleveraging differentiable optimisation to extend the integration to data\nacquisition. We solve the data acquisition problem with well-defined\nconstraints by learning a surrogate linear objective function. We demonstrate\nan application of this model on a shortest path problem for which we first have\nto set a drone reconnaissance strategy to capture image segments serving as\ninputs to a model that predicts travel costs. We ablate the problem with a\nnumber of training modalities and demonstrate that the differentiable\noptimisation approach outperforms random search strategies.",
      "tldr_zh": "该论文提出了一种用于上下文随机优化问题中数据采集决策的模型OPO，旨在解决数据采集成本高昂且受限情况下的变量采集问题。OPO模型将数据采集、预测和优化整合到一个端到端的框架中，利用可微优化技术学习代理线性目标函数，从而在明确约束下解决数据采集问题。作者在一个最短路径问题（无人机侦察图像采集以预测旅行成本）上验证了该模型，结果表明，相比随机搜索策略，OPO模型表现更优。该研究将决策重点学习从预测和优化（PO）扩展到数据采集，为决策导向的数据采集提供了一种新方法。\n",
      "categories": [
        "math.OC",
        "cs.AI"
      ],
      "primary_category": "math.OC",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2504.15062v1",
      "published_date": "2025-04-21 12:41:35 UTC",
      "updated_date": "2025-04-21 12:41:35 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-04-23T02:19:48.007701"
    },
    {
      "arxiv_id": "2504.15051v1",
      "title": "VeLU: Variance-enhanced Learning Unit for Deep Neural Networks",
      "title_zh": "VeLU：用于深度神经网络的方差增强学习单元\n",
      "authors": [
        "Ashkan Shakarami",
        "Yousef Yeganeh",
        "Azade Farshad",
        "Lorenzo Nicolè",
        "Stefano Ghidoni",
        "Nassir Navab"
      ],
      "abstract": "Activation functions are fundamental in deep neural networks and directly\nimpact gradient flow, optimization stability, and generalization. Although ReLU\nremains standard because of its simplicity, it suffers from vanishing gradients\nand lacks adaptability. Alternatives like Swish and GELU introduce smooth\ntransitions, but fail to dynamically adjust to input statistics. We propose\nVeLU, a Variance-enhanced Learning Unit as an activation function that\ndynamically scales based on input variance by integrating ArcTan-Sin\ntransformations and Wasserstein-2 regularization, effectively mitigating\ncovariate shifts and stabilizing optimization. Extensive experiments on\nViT_B16, VGG19, ResNet50, DenseNet121, MobileNetV2, and EfficientNetB3 confirm\nVeLU's superiority over ReLU, ReLU6, Swish, and GELU on six vision benchmarks.\nThe codes of VeLU are publicly available on GitHub.",
      "tldr_zh": "该论文提出了一种新的激活函数VeLU (Variance-enhanced Learning Unit)，旨在克服传统激活函数如ReLU的梯度消失和适应性不足等问题。VeLU通过结合ArcTan-Sin变换和Wasserstein-2正则化，利用输入方差动态调整缩放，有效缓解了协变量偏移并稳定了优化过程。在ViT_B16, VGG19, ResNet50等多个模型和六个视觉基准测试上的实验结果表明，VeLU优于ReLU, Swish和GELU等激活函数。VeLU的代码已在GitHub上公开。\n",
      "categories": [
        "cs.LG",
        "cs.AI",
        "cs.CV"
      ],
      "primary_category": "cs.LG",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2504.15051v1",
      "published_date": "2025-04-21 12:20:46 UTC",
      "updated_date": "2025-04-21 12:20:46 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-04-23T02:19:59.819643"
    },
    {
      "arxiv_id": "2504.15046v2",
      "title": "Text-to-Decision Agent: Learning Generalist Policies from Natural Language Supervision",
      "title_zh": "文本到决策智能体：从自然语言监督中学习通用策略\n",
      "authors": [
        "Shilin Zhang",
        "Zican Hu",
        "Wenhao Wu",
        "Xinyi Xie",
        "Jianxiang Tang",
        "Chunlin Chen",
        "Daoyi Dong",
        "Yu Cheng",
        "Zhenhong Sun",
        "Zhi Wang"
      ],
      "abstract": "RL systems usually tackle generalization by inferring task beliefs from\nhigh-quality samples or warmup explorations. The restricted form limits their\ngenerality and usability since these supervision signals are expensive and even\ninfeasible to acquire in advance for unseen tasks. Learning directly from the\nraw text about decision tasks is a promising alternative to leverage a much\nbroader source of supervision. In the paper, we propose Text-to-Decision Agent\n(T2DA), a simple and scalable framework that supervises generalist policy\nlearning with natural language. We first introduce a generalized world model to\nencode multi-task decision data into a dynamics-aware embedding space. Then,\ninspired by CLIP, we predict which textual description goes with which decision\nembedding, effectively bridging their semantic gap via contrastive\nlanguage-decision pre-training and aligning the text embeddings to comprehend\nthe environment dynamics. After training the text-conditioned generalist\npolicy, the agent can directly realize zero-shot text-to-decision generation in\nresponse to language instructions. Comprehensive experiments on MuJoCo and\nMeta-World benchmarks show that T2DA facilitates high-capacity zero-shot\ngeneralization and outperforms various types of baselines.",
      "tldr_zh": "本文提出了Text-to-Decision Agent (T2DA)，一个利用自然语言监督学习通用策略的框架。该框架通过广义世界模型将多任务决策数据编码到动态感知的嵌入空间，并借鉴CLIP的思想，通过对比语言-决策预训练，预测文本描述与决策嵌入的对应关系，从而弥合语义鸿沟。T2DA将文本嵌入与环境动态对齐，训练文本条件下的通用策略，实现零样本的文本到决策生成。在MuJoCo和Meta-World基准测试上的实验表明，T2DA能够实现高性能的零样本泛化，并优于各种基线模型。\n",
      "categories": [
        "cs.AI"
      ],
      "primary_category": "cs.AI",
      "comment": "18 pages, 8 figures",
      "pdf_url": "http://arxiv.org/pdf/2504.15046v2",
      "published_date": "2025-04-21 12:00:20 UTC",
      "updated_date": "2025-04-22 05:56:57 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-04-23T02:20:11.827927"
    },
    {
      "arxiv_id": "2504.15044v1",
      "title": "Beyond Terabit/s Integrated Neuromorphic Photonic Processor for DSP-Free Optical Interconnects",
      "title_zh": "超越太比特/秒的集成神经形态光子处理器，用于无DSP光互连\n",
      "authors": [
        "Benshan Wang",
        "Qiarong Xiao",
        "Tengji Xu",
        "Li Fan",
        "Shaojie Liu",
        "Jianji Dong",
        "Junwen Zhang",
        "Chaoran Huang"
      ],
      "abstract": "The rapid expansion of generative AI drives unprecedented demands for\nhigh-performance computing. Training large-scale AI models now requires vast\ninterconnected GPU clusters across multiple data centers. Multi-scale AI\ntraining and inference demand uniform, ultra-low latency, and energy-efficient\nlinks to enable massive GPUs to function as a single cohesive unit. However,\ntraditional electrical and optical interconnects, relying on conventional\ndigital signal processors (DSPs) for signal distortion compensation,\nincreasingly fail to meet these stringent requirements. To overcome these\nlimitations, we present an integrated neuromorphic optical signal processor\n(OSP) that leverages deep reservoir computing and achieves DSP-free,\nall-optical, real-time processing. Experimentally, our OSP achieves a 100 Gbaud\nPAM4 per lane, 1.6 Tbit/s data center interconnect over a 5 km optical fiber in\nthe C-band (equivalent to over 80 km in the O-band), far exceeding the reach of\nstate-of-the-art DSP solutions, which are fundamentally constrained by\nchromatic dispersion in IMDD systems. Simultaneously, it reduces processing\nlatency by four orders of magnitude and energy consumption by three orders of\nmagnitude. Unlike DSPs, which introduce increased latency at high data rates,\nour OSP maintains consistent, ultra-low latency regardless of data rate\nscaling, making it ideal for future optical interconnects. Moreover, the OSP\nretains full optical field information for better impairment compensation and\nadapts to various modulation formats, data rates, and wavelengths. Fabricated\nusing a mature silicon photonic process, the OSP can be monolithically\nintegrated with silicon photonic transceivers, enhancing the compactness and\nreliability of all-optical interconnects. This research provides a highly\nscalable, energy-efficient, and high-speed solution, paving the way for\nnext-generation AI infrastructure.",
      "tldr_zh": "为了应对生成式AI对高性能计算的巨大需求，该研究提出了一种集成的神经形态光信号处理器(OSP)，利用深度储层计算实现无需数字信号处理器(DSP)的全光实时处理。实验结果表明，该OSP在C波段5公里光纤上实现了每通道100 Gbaud PAM4，总计1.6 Tbit/s的数据中心互连，性能远超受色散限制的传统DSP解决方案。与DSP相比，该OSP将处理延迟降低了四个数量级，能耗降低了三个数量级，并保持超低延迟，适用于未来的光互连。该OSP采用成熟的硅光子工艺制造，可与硅光子收发器单片集成，为下一代AI基础设施提供了一种高扩展性、高能效和高速解决方案。\n",
      "categories": [
        "physics.optics",
        "cs.AI",
        "cs.ET"
      ],
      "primary_category": "physics.optics",
      "comment": "22 pages, 6 figures",
      "pdf_url": "http://arxiv.org/pdf/2504.15044v1",
      "published_date": "2025-04-21 11:56:36 UTC",
      "updated_date": "2025-04-21 11:56:36 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-04-23T02:20:24.125462"
    },
    {
      "arxiv_id": "2504.15041v2",
      "title": "Distribution-aware Forgetting Compensation for Exemplar-Free Lifelong Person Re-identification",
      "title_zh": "面向无范例终身行人重识别的分布感知遗忘补偿\n",
      "authors": [
        "Shiben Liu",
        "Huijie Fan",
        "Qiang Wang",
        "Baojie Fan",
        "Yandong Tang",
        "Liangqiong Qu"
      ],
      "abstract": "Lifelong Person Re-identification (LReID) suffers from a key challenge in\npreserving old knowledge while adapting to new information. The existing\nsolutions include rehearsal-based and rehearsal-free methods to address this\nchallenge. Rehearsal-based approaches rely on knowledge distillation,\ncontinuously accumulating forgetting during the distillation process.\nRehearsal-free methods insufficiently learn the distribution of each domain,\nleading to forgetfulness over time. To solve these issues, we propose a novel\nDistribution-aware Forgetting Compensation (DAFC) model that explores\ncross-domain shared representation learning and domain-specific distribution\nintegration without using old exemplars or knowledge distillation. We propose a\nText-driven Prompt Aggregation (TPA) that utilizes text features to enrich\nprompt elements and guide the prompt model to learn fine-grained\nrepresentations for each instance. This can enhance the differentiation of\nidentity information and establish the foundation for domain distribution\nawareness. Then, Distribution-based Awareness and Integration (DAI) is designed\nto capture each domain-specific distribution by a dedicated expert network and\nadaptively consolidate them into a shared region in high-dimensional space. In\nthis manner, DAI can consolidate and enhance cross-domain shared representation\nlearning while alleviating catastrophic forgetting. Furthermore, we develop a\nKnowledge Consolidation Mechanism (KCM) that comprises instance-level\ndiscrimination and cross-domain consistency alignment strategies to facilitate\nmodel adaptive learning of new knowledge from the current domain and promote\nknowledge consolidation learning between acquired domain-specific\ndistributions, respectively. Experimental results show that our DAFC\noutperforms state-of-the-art methods. Our code is available at\nhttps://github.com/LiuShiBen/DAFC.",
      "tldr_zh": "本文提出了一种新的分布感知遗忘补偿(DAFC)模型，用于解决无样本终身行人重识别(LReID)中的遗忘问题。DAFC无需旧样本或知识蒸馏，通过跨域共享表示学习和领域特定分布整合来缓解灾难性遗忘。该模型包含文本驱动的提示聚合(TPA)模块，利用文本特征增强提示元素，学习细粒度的实例表示，从而提升身份信息区分度。此外，分布感知与整合(DAI)模块通过专家网络捕获每个领域特定的分布，并将其自适应地整合到高维空间的共享区域，从而实现跨域共享表示学习并减轻遗忘。最后，知识巩固机制(KCM)包含实例级区分和跨域一致性对齐策略，促进模型自适应地学习新知识并巩固领域间知识。实验结果表明，DAFC优于现有最佳方法。\n",
      "categories": [
        "cs.CV",
        "cs.AI"
      ],
      "primary_category": "cs.CV",
      "comment": "12 pages, 5 figures",
      "pdf_url": "http://arxiv.org/pdf/2504.15041v2",
      "published_date": "2025-04-21 11:53:43 UTC",
      "updated_date": "2025-04-22 13:05:09 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-04-23T02:20:36.144051"
    },
    {
      "arxiv_id": "2504.15035v1",
      "title": "SOLIDO: A Robust Watermarking Method for Speech Synthesis via Low-Rank Adaptation",
      "title_zh": "SOLIDO：一种通过低秩自适应实现语音合成的鲁棒水印方法\n",
      "authors": [
        "Yue Li",
        "Weizhi Liu",
        "Dongdong Lin"
      ],
      "abstract": "The accelerated advancement of speech generative models has given rise to\nsecurity issues, including model infringement and unauthorized abuse of\ncontent. Although existing generative watermarking techniques have proposed\ncorresponding solutions, most methods require substantial computational\noverhead and training costs. In addition, some methods have limitations in\nrobustness when handling variable-length inputs. To tackle these challenges, we\npropose \\textsc{SOLIDO}, a novel generative watermarking method that integrates\nparameter-efficient fine-tuning with speech watermarking through low-rank\nadaptation (LoRA) for speech diffusion models. Concretely, the watermark\nencoder converts the watermark to align with the input of diffusion models. To\nachieve precise watermark extraction from variable-length inputs, the watermark\ndecoder based on depthwise separable convolution is designed for watermark\nrecovery. To further enhance speech generation performance and watermark\nextraction capability, we propose a speech-driven lightweight fine-tuning\nstrategy, which reduces computational overhead through LoRA. Comprehensive\nexperiments demonstrate that the proposed method ensures high-fidelity\nwatermarked speech even at a large capacity of 2000 bps. Furthermore, against\ncommon individual and compound speech attacks, our SOLIDO achieves a maximum\naverage extraction accuracy of 99.20\\% and 98.43\\%, respectively. It surpasses\nother state-of-the-art methods by nearly 23\\% in resisting time-stretching\nattacks.",
      "tldr_zh": "该论文提出了一种名为SOLIDO的鲁棒性语音合成水印方法，它通过低秩适应(LoRA)将参数高效微调与语音水印技术集成到语音扩散模型中，旨在解决现有水印技术计算开销大和对变长输入鲁棒性不足的问题。SOLIDO采用水印编码器将水印对齐到扩散模型的输入，并设计了基于深度可分离卷积的水印解码器，以实现从变长输入中精确提取水印。此外，论文还提出了一种语音驱动的轻量级微调策略，通过LoRA减少计算开销，提升语音生成性能和水印提取能力。实验结果表明，SOLIDO即使在2000 bps的大容量下也能保证高保真度的水印语音，并且在抵抗常见语音攻击（包括时域拉伸）方面，其水印提取精度也显著优于其他先进方法。\n",
      "categories": [
        "cs.CR",
        "cs.AI",
        "cs.SD"
      ],
      "primary_category": "cs.CR",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2504.15035v1",
      "published_date": "2025-04-21 11:43:36 UTC",
      "updated_date": "2025-04-21 11:43:36 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-04-23T02:20:48.171215"
    },
    {
      "arxiv_id": "2504.14995v1",
      "title": "Trainable Quantum Neural Network for Multiclass Image Classification with the Power of Pre-trained Tree Tensor Networks",
      "title_zh": "可训练量子神经网络，利用预训练树张量网络的力量进行多类别图像分类\n",
      "authors": [
        "Keisuke Murota",
        "Takumi Kobori"
      ],
      "abstract": "Tree tensor networks (TTNs) offer powerful models for image classification.\nWhile these TTN image classifiers already show excellent performance on\nclassical hardware, embedding them into quantum neural networks (QNNs) may\nfurther improve the performance by leveraging quantum resources. However,\nembedding TTN classifiers into QNNs for multiclass classification remains\nchallenging. Key obstacles are the highorder gate operations required for large\nbond dimensions and the mid-circuit postselection with exponentially low\nsuccess rates necessary for the exact embedding. In this work, to address these\nchallenges, we propose forest tensor network (FTN)-classifiers, which aggregate\nmultiple small-bond-dimension TTNs. This allows us to handle multiclass\nclassification without requiring large gates in the embedded circuits. We then\nremove the overhead of mid-circuit postselection by extending the adiabatic\nencoding framework to our setting and smoothly encode the FTN-classifiers into\na quantum forest tensor network (qFTN)- classifiers. Numerical experiments on\nMNIST and CIFAR-10 demonstrate that we can successfully train FTN-classifiers\nand encode them into qFTN-classifiers, while maintaining or even improving the\nperformance of the pre-trained FTN-classifiers. These results suggest that\nsynergy between TTN classification models and QNNs can provide a robust and\nscalable framework for multiclass quantum-enhanced image classification.",
      "tldr_zh": "该论文提出了一种可训练的量子神经网络(QNN)用于多类别图像分类，利用预训练的树张量网络(TTN)的能力。为解决将TTN嵌入QNN进行多类别分类的挑战，作者提出了森林张量网络(FTN)分类器，它聚合了多个小键维度的TTN，避免了对大型门的需求。通过扩展绝热编码框架，消除了中间电路后选择的开销，并将FTN分类器平滑地编码到量子森林张量网络(qFTN)分类器中。在MNIST和CIFAR-10上的实验表明，该方法能够成功训练FTN分类器并将其编码为qFTN分类器，同时保持甚至提高了预训练FTN分类器的性能，为多类别量子增强图像分类提供了一个鲁棒且可扩展的框架。\n",
      "categories": [
        "quant-ph",
        "cs.AI",
        "cs.LG"
      ],
      "primary_category": "quant-ph",
      "comment": "11 pages, 12 figures, 2 tables. This work has been submitted to the\n  IEEE for possible publication",
      "pdf_url": "http://arxiv.org/pdf/2504.14995v1",
      "published_date": "2025-04-21 09:51:39 UTC",
      "updated_date": "2025-04-21 09:51:39 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-04-23T02:21:00.139139"
    },
    {
      "arxiv_id": "2504.14985v1",
      "title": "aiXamine: LLM Safety and Security Simplified",
      "title_zh": "aiXamine：LLM 安全与安全性的简化",
      "authors": [
        "Fatih Deniz",
        "Dorde Popovic",
        "Yazan Boshmaf",
        "Euisuh Jeong",
        "Minhaj Ahmad",
        "Sanjay Chawla",
        "Issa Khalil"
      ],
      "abstract": "Evaluating Large Language Models (LLMs) for safety and security remains a\ncomplex task, often requiring users to navigate a fragmented landscape of ad\nhoc benchmarks, datasets, metrics, and reporting formats. To address this\nchallenge, we present aiXamine, a comprehensive black-box evaluation platform\nfor LLM safety and security. aiXamine integrates over 40 tests (i.e.,\nbenchmarks) organized into eight key services targeting specific dimensions of\nsafety and security: adversarial robustness, code security, fairness and bias,\nhallucination, model and data privacy, out-of-distribution (OOD) robustness,\nover-refusal, and safety alignment. The platform aggregates the evaluation\nresults into a single detailed report per model, providing a detailed breakdown\nof model performance, test examples, and rich visualizations. We used aiXamine\nto assess over 50 publicly available and proprietary LLMs, conducting over 2K\nexaminations. Our findings reveal notable vulnerabilities in leading models,\nincluding susceptibility to adversarial attacks in OpenAI's GPT-4o, biased\noutputs in xAI's Grok-3, and privacy weaknesses in Google's Gemini 2.0.\nAdditionally, we observe that open-source models can match or exceed\nproprietary models in specific services such as safety alignment, fairness and\nbias, and OOD robustness. Finally, we identify trade-offs between distillation\nstrategies, model size, training methods, and architectural choices.",
      "tldr_zh": "aiXamine是一个全面的黑盒评估平台，旨在简化大型语言模型(LLM)的安全性评估。它集成了40多个测试，涵盖对抗鲁棒性、代码安全、公平性和偏见、幻觉、模型和数据隐私、OOD鲁棒性、过度拒绝和安全对齐等八个关键安全维度。aiXamine将评估结果整合为详细报告，提供模型性能、测试示例和可视化分析。通过对50多个LLM的2000多次评估，揭示了包括GPT-4o、Grok-3和Gemini 2.0在内的领先模型的漏洞，并观察到开源模型在特定安全服务上可以与专有模型相媲美甚至超越。该研究还识别了蒸馏策略、模型大小、训练方法和架构选择之间的权衡。\n",
      "categories": [
        "cs.CR",
        "cs.AI"
      ],
      "primary_category": "cs.CR",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2504.14985v1",
      "published_date": "2025-04-21 09:26:05 UTC",
      "updated_date": "2025-04-21 09:26:05 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-04-23T02:21:12.122454"
    },
    {
      "arxiv_id": "2504.14964v1",
      "title": "Evaluating Code Generation of LLMs in Advanced Computer Science Problems",
      "title_zh": "评估大型语言模型在高级计算机科学问题中的代码生成能力\n",
      "authors": [
        "Emir Catir",
        "Robin Claesson",
        "Rodothea Myrsini Tsoupidi"
      ],
      "abstract": "Large Language Models (LLMs), such as GitHub Copilot and ChatGPT have become\npopular among programming students. Students use LLMs to assist them in\nprogramming courses, including generating source code. Previous work has\nevaluated the ability of LLMs in solving introductory-course programming\nassignments. The results have shown that LLMs are highly effective in\ngenerating code for introductory Computer Science (CS) courses. However, there\nis a gap in research on evaluating LLMs' ability to generate code that solves\nadvanced programming assignments. In this work, we evaluate the ability of four\nLLM tools to solve programming assignments from advanced CS courses in three\npopular programming languages, Java, Python, and C. We manually select 12\nproblems, three problems from introductory courses as the baseline and nine\nprogramming assignments from second- and third-year CS courses. To evaluate the\nLLM-generated code, we generate a test suite of 1000 test cases per problem and\nanalyze the program output. Our evaluation shows that although LLMs are highly\neffective in generating source code for introductory programming courses,\nsolving advanced programming assignments is more challenging. Nonetheless, in\nmany cases, LLMs identify the base problem and provide partial solutions that\nmay be useful to CS students. Furthermore, our results may provide useful\nguidance for teachers of advanced programming courses on how to design\nprogramming assignments.",
      "tldr_zh": "本文评估了大型语言模型(LLMs)在解决高级计算机科学(CS)问题中的代码生成能力。研究选取了来自Java、Python和C三种编程语言的12个问题，包括3个入门级问题和9个二、三年级CS课程的编程作业，并使用1000个测试用例的测试套件评估LLM生成的代码。结果表明，LLMs在生成入门级编程课程的源代码方面非常有效，但解决高级编程作业更具挑战性。然而，在许多情况下，LLMs能够识别基本问题并提供部分解决方案，这可能对CS学生有所帮助。该研究结果为高级编程课程的教师设计编程作业提供了有益的指导。\n",
      "categories": [
        "cs.AI",
        "cs.CY"
      ],
      "primary_category": "cs.AI",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2504.14964v1",
      "published_date": "2025-04-21 08:45:23 UTC",
      "updated_date": "2025-04-21 08:45:23 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-04-23T02:21:24.170922"
    },
    {
      "arxiv_id": "2504.14963v1",
      "title": "Speaker Fuzzy Fingerprints: Benchmarking Text-Based Identification in Multiparty Dialogues",
      "title_zh": "说话人模糊指纹：多人对话中基于文本的身份识别基准测试\n",
      "authors": [
        "Rui Ribeiro",
        "Luísa Coheur",
        "Joao P. Carvalho"
      ],
      "abstract": "Speaker identification using voice recordings leverages unique acoustic\nfeatures, but this approach fails when only textual data is available. Few\napproaches have attempted to tackle the problem of identifying speakers solely\nfrom text, and the existing ones have primarily relied on traditional methods.\nIn this work, we explore the use of fuzzy fingerprints from large pre-trained\nmodels to improve text-based speaker identification. We integrate\nspeaker-specific tokens and context-aware modeling, demonstrating that\nconversational context significantly boosts accuracy, reaching 70.6% on the\nFriends dataset and 67.7% on the Big Bang Theory dataset. Additionally, we show\nthat fuzzy fingerprints can approximate full fine-tuning performance with fewer\nhidden units, offering improved interpretability. Finally, we analyze ambiguous\nutterances and propose a mechanism to detect speaker-agnostic lines. Our\nfindings highlight key challenges and provide insights for future improvements\nin text-based speaker identification.",
      "tldr_zh": "该研究探索了仅使用文本数据进行多人对话中的说话人识别问题，并提出利用大型预训练模型的模糊指纹(fuzzy fingerprints)来提升识别准确率。通过集成说话人特定tokens和上下文感知建模，研究表明对话上下文能够显著提高准确率，在Friends数据集上达到70.6%，在Big Bang Theory数据集上达到67.7%。此外，模糊指纹方法在减少隐藏单元数量的同时，也能近似达到完全微调的性能，并提升了可解释性。研究还分析了模糊语句，并提出了一种检测与说话人无关语句的机制。该研究结果突出了文本说话人识别的关键挑战，并为未来的改进提供了见解。\n",
      "categories": [
        "cs.CL",
        "cs.AI",
        "cs.CE",
        "cs.LG",
        "cs.NE"
      ],
      "primary_category": "cs.CL",
      "comment": "Paper accepted at the FUZZY IEEE 2025 conference",
      "pdf_url": "http://arxiv.org/pdf/2504.14963v1",
      "published_date": "2025-04-21 08:44:33 UTC",
      "updated_date": "2025-04-21 08:44:33 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-04-23T02:21:36.076154"
    },
    {
      "arxiv_id": "2504.14947v1",
      "title": "Generative Semantic Communications: Principles and Practices",
      "title_zh": "生成式语义通信：原理与实践\n",
      "authors": [
        "Xiaojun Yuan",
        "Haoming Ma",
        "Yinuo Huang",
        "Zhoufan Hua",
        "Yong Zuo",
        "Zhi Ding"
      ],
      "abstract": "Semantic communication leverages artificial intelligence (AI) technologies to\nextract semantic information from data for efficient transmission, theraby\nsignificantly reducing communication cost. With the evolution towards\nartificial general intelligence (AGI), the increasing demands for AGI services\npose new challenges to semantic communication. In response, we propose a new\nparadigm for AGI-driven communications, called generative semantic\ncommunication (GSC), which utilizes advanced AI technologies such as foundation\nmodels and generative models. We first describe the basic concept of GSC and\nits difference from existing semantic communications, and then introduce a\ngeneral framework of GSC, followed by two case studies to verify the advantages\nof GSC in AGI-driven applications. Finally, open challenges and new research\ndirections are discussed to stimulate this line of research and pave the way\nfor practical applications.",
      "tldr_zh": "本文提出了一种新的AGI驱动的通信范式：生成式语义通信(Generative Semantic Communication, GSC)，旨在应对AGI服务日益增长的需求给语义通信带来的新挑战。GSC利用诸如基础模型和生成模型等先进AI技术。文章阐述了GSC的基本概念及其与现有语义通信的区别，并介绍了一个通用的GSC框架。通过两个案例研究验证了GSC在AGI驱动的应用中的优势。最后，讨论了开放性挑战和新的研究方向，以推动该领域的研究并为实际应用铺平道路。\n",
      "categories": [
        "cs.AI",
        "eess.IV",
        "eess.SP"
      ],
      "primary_category": "cs.AI",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2504.14947v1",
      "published_date": "2025-04-21 08:10:59 UTC",
      "updated_date": "2025-04-21 08:10:59 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-04-23T02:21:47.992124"
    },
    {
      "arxiv_id": "2504.14945v2",
      "title": "Learning to Reason under Off-Policy Guidance",
      "title_zh": "离线策略指导下的推理学习\n",
      "authors": [
        "Jianhao Yan",
        "Yafu Li",
        "Zican Hu",
        "Zhi Wang",
        "Ganqu Cui",
        "Xiaoye Qu",
        "Yu Cheng",
        "Yue Zhang"
      ],
      "abstract": "Recent advances in large reasoning models (LRMs) demonstrate that\nsophisticated behaviors such as multi-step reasoning and self-reflection can\nemerge via reinforcement learning (RL) with simple rule-based rewards. However,\nexisting zero-RL approaches are inherently ``on-policy'', limiting learning to\na model's own outputs and failing to acquire reasoning abilities beyond its\ninitial capabilities. We introduce LUFFY (Learning to reason Under oFF-policY\nguidance), a framework that augments zero-RL with off-policy reasoning traces.\nLUFFY dynamically balances imitation and exploration by combining off-policy\ndemonstrations with on-policy rollouts during training. Notably, we propose\npolicy shaping via regularized importance sampling to avoid superficial and\nrigid imitation during mixed-policy training. Remarkably, LUFFY achieves an\nover +7.0 average gain across six math benchmarks and an advantage of over +6.2\npoints in out-of-distribution tasks. It also substantially surpasses\nimitation-based supervised fine-tuning (SFT), particularly in generalization.\nAnalysis shows LUFFY not only imitates effectively but also explores beyond\ndemonstrations, offering a scalable path to train generalizable reasoning\nmodels with off-policy guidance.",
      "tldr_zh": "该论文提出了LUFFY (Learning to reason Under oFF-policY guidance)，一个通过off-policy推理轨迹增强zero-RL的框架，旨在提升大型推理模型(LRMs)的推理能力。LUFFY通过结合off-policy演示和on-policy rollouts，动态平衡模仿和探索，并提出通过正则化重要性抽样进行策略塑造，避免混合策略训练中的表面模仿。实验结果表明，LUFFY在六个数学基准测试中平均提升超过7.0，在out-of-distribution任务中提升超过6.2，并且显著优于基于模仿的监督微调(SFT)，尤其是在泛化方面。LUFFY不仅能有效模仿，还能超越演示进行探索，为利用off-policy指导训练可泛化的推理模型提供了可扩展的路径。\n",
      "categories": [
        "cs.LG",
        "cs.AI",
        "cs.CL"
      ],
      "primary_category": "cs.LG",
      "comment": "Work in progress",
      "pdf_url": "http://arxiv.org/pdf/2504.14945v2",
      "published_date": "2025-04-21 08:09:13 UTC",
      "updated_date": "2025-04-22 15:37:25 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-04-23T02:22:00.202013"
    },
    {
      "arxiv_id": "2504.14936v1",
      "title": "Giving AI a voice: how does AI think it should be treated?",
      "title_zh": "赋予 AI 发言权：AI 认为应该如何对待它？\n",
      "authors": [
        "Maria Fay",
        "Frederik F. Flöther"
      ],
      "abstract": "With the astounding progress in (generative) artificial intelligence (AI),\nthere has been significant public discourse regarding regulation and ethics of\nthe technology. Is it sufficient when humans discuss this with other humans?\nOr, given that AI is increasingly becoming a viable source of inspiration for\npeople (and let alone the hypothetical possibility that the technology may at\nsome point become \"artificial general intelligence\" and/or develop\nconsciousness), should AI not join the discourse? There are new questions and\nangles that AI brings to the table that we might not have considered before -\nso let us make the key subject of this book an active participant. This chapter\ntherefore includes a brief human-AI conversation on the topic of AI rights and\nethics.",
      "tldr_zh": "随着生成式人工智能的飞速发展，关于其监管和伦理的讨论日益增多。本文探讨了是否应让人工智能参与到这些讨论中，而不仅仅是人类之间的对话。通过一段人机对话，探讨了人工智能在权利和伦理方面的新视角和问题，旨在让人工智能成为讨论的积极参与者，为相关议题带来新的思考。\n",
      "categories": [
        "cs.CY",
        "cs.AI"
      ],
      "primary_category": "cs.CY",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2504.14936v1",
      "published_date": "2025-04-21 07:59:17 UTC",
      "updated_date": "2025-04-21 07:59:17 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-04-23T02:22:11.664476"
    },
    {
      "arxiv_id": "2504.14928v1",
      "title": "EducationQ: Evaluating LLMs' Teaching Capabilities Through Multi-Agent Dialogue Framework",
      "title_zh": "EducationQ：通过多智能体对话框架评估大型语言模型的教学能力",
      "authors": [
        "Yao Shi",
        "Rongkeng Liang",
        "Yong Xu"
      ],
      "abstract": "Large language models (LLMs) increasingly serve as educational tools, yet\nevaluating their teaching capabilities remains challenging due to the\nresource-intensive, context-dependent, and methodologically complex nature of\nteacher-student interactions. We introduce EducationQ, a multi-agent dialogue\nframework that efficiently assesses teaching capabilities through simulated\ndynamic educational scenarios, featuring specialized agents for teaching,\nlearning, and evaluation. Testing 14 LLMs across major AI Organizations\n(OpenAI, Meta, Google, Anthropic, and others) on 1,498 questions spanning 13\ndisciplines and 10 difficulty levels reveals that teaching effectiveness does\nnot correlate linearly with model scale or general reasoning capabilities -\nwith some smaller open-source models outperforming larger commercial\ncounterparts in teaching contexts. This finding highlights a critical gap in\ncurrent evaluations that prioritize knowledge recall over interactive pedagogy.\nOur mixed-methods evaluation, combining quantitative metrics with qualitative\nanalysis and expert case studies, identifies distinct pedagogical strengths\nemployed by top-performing models (e.g., sophisticated questioning strategies,\nadaptive feedback mechanisms). Human expert evaluations show 78% agreement with\nour automated qualitative analysis of effective teaching behaviors, validating\nour methodology. EducationQ demonstrates that LLMs-as-teachers require\nspecialized optimization beyond simple scaling, suggesting next-generation\neducational AI prioritize targeted enhancement of specific pedagogical\neffectiveness.",
      "tldr_zh": "EducationQ是一个多智能体对话框架，用于评估大型语言模型(LLMs)的教学能力。它通过模拟动态教学场景，利用专门的教学、学习和评估智能体，高效评估LLMs的教学效果。对来自多个AI机构的14个LLMs在13个学科和10个难度级别上的1498个问题进行测试表明，教学效果与模型规模或通用推理能力并不线性相关，一些较小的开源模型在教学环境中优于较大的商业模型。EducationQ结合定量指标、定性分析和专家案例研究，识别了表现最佳模型所采用的独特教学优势，表明LLMs作为教师需要专门的优化，而不仅仅是简单的扩展，提示下一代教育AI应优先考虑有针对性地提高特定教学效果。专家评估与自动化定性分析的有效教学行为达成78%的一致，验证了该方法。\n",
      "categories": [
        "cs.AI",
        "cs.CE",
        "cs.CL",
        "cs.CY",
        "cs.HC"
      ],
      "primary_category": "cs.AI",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2504.14928v1",
      "published_date": "2025-04-21 07:48:20 UTC",
      "updated_date": "2025-04-21 07:48:20 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-04-23T02:22:24.602071"
    },
    {
      "arxiv_id": "2504.14921v1",
      "title": "Fast Adversarial Training with Weak-to-Strong Spatial-Temporal Consistency in the Frequency Domain on Videos",
      "title_zh": "视频频域中基于由弱到强时空一致性的快速对抗训练\n",
      "authors": [
        "Songping Wang",
        "Hanqing Liu",
        "Yueming Lyu",
        "Xiantao Hu",
        "Ziwen He",
        "Wei Wang",
        "Caifeng Shan",
        "Liang Wang"
      ],
      "abstract": "Adversarial Training (AT) has been shown to significantly enhance adversarial\nrobustness via a min-max optimization approach. However, its effectiveness in\nvideo recognition tasks is hampered by two main challenges. First, fast\nadversarial training for video models remains largely unexplored, which\nseverely impedes its practical applications. Specifically, most video\nadversarial training methods are computationally costly, with long training\ntimes and high expenses. Second, existing methods struggle with the trade-off\nbetween clean accuracy and adversarial robustness. To address these challenges,\nwe introduce Video Fast Adversarial Training with Weak-to-Strong consistency\n(VFAT-WS), the first fast adversarial training method for video data.\nSpecifically, VFAT-WS incorporates the following key designs: First, it\nintegrates a straightforward yet effective temporal frequency augmentation\n(TF-AUG), and its spatial-temporal enhanced form STF-AUG, along with a\nsingle-step PGD attack to boost training efficiency and robustness. Second, it\ndevises a weak-to-strong spatial-temporal consistency regularization, which\nseamlessly integrates the simpler TF-AUG and the more complex STF-AUG.\nLeveraging the consistency regularization, it steers the learning process from\nsimple to complex augmentations. Both of them work together to achieve a better\ntrade-off between clean accuracy and robustness. Extensive experiments on\nUCF-101 and HMDB-51 with both CNN and Transformer-based models demonstrate that\nVFAT-WS achieves great improvements in adversarial robustness and corruption\nrobustness, while accelerating training by nearly 490%.",
      "tldr_zh": "该论文提出了Video Fast Adversarial Training with Weak-to-Strong consistency (VFAT-WS)，一种针对视频数据的快速对抗训练方法，旨在提高视频识别模型的对抗鲁棒性并解决训练效率问题。VFAT-WS 结合了时间频率增强(TF-AUG)及其空间-时间增强形式(STF-AUG)以及单步PGD攻击，以提高训练效率和鲁棒性。此外，该方法还设计了一种由弱到强的空间-时间一致性正则化，将简单的TF-AUG和复杂的STF-AUG无缝集成，从而在干净准确率和鲁棒性之间取得更好的平衡。实验表明，VFAT-WS 在 UCF-101 和 HMDB-51 数据集上显著提高了对抗鲁棒性和抗腐败鲁棒性，并将训练速度提高了近490%。\n",
      "categories": [
        "cs.CV",
        "cs.AI"
      ],
      "primary_category": "cs.CV",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2504.14921v1",
      "published_date": "2025-04-21 07:40:35 UTC",
      "updated_date": "2025-04-21 07:40:35 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-04-23T02:22:36.277816"
    },
    {
      "arxiv_id": "2504.14915v1",
      "title": "StableQuant: Layer Adaptive Post-Training Quantization for Speech Foundation Models",
      "title_zh": "StableQuant：语音基础模型的层自适应后训练量化\n",
      "authors": [
        "Yeona Hong",
        "Hyewon Han",
        "Woo-jin Chung",
        "Hong-Goo Kang"
      ],
      "abstract": "In this paper, we propose StableQuant, a novel adaptive post-training\nquantization (PTQ) algorithm for widely used speech foundation models (SFMs).\nWhile PTQ has been successfully employed for compressing large language models\n(LLMs) due to its ability to bypass additional fine-tuning, directly applying\nthese techniques to SFMs may not yield optimal results, as SFMs utilize\ndistinct network architecture for feature extraction. StableQuant demonstrates\noptimal quantization performance regardless of the network architecture type,\nas it adaptively determines the quantization range for each layer by analyzing\nboth the scale distributions and overall performance. We evaluate our algorithm\non two SFMs, HuBERT and wav2vec2.0, for an automatic speech recognition (ASR)\ntask, and achieve superior performance compared to traditional PTQ methods.\nStableQuant successfully reduces the sizes of SFM models to a quarter and\ndoubles the inference speed while limiting the word error rate (WER)\nperformance drop to less than 0.3% with 8-bit quantization.",
      "tldr_zh": "本文提出了一种名为StableQuant的自适应训练后量化(PTQ)算法，专门用于压缩语音基础模型(SFMs)。与直接将LLM的PTQ方法应用于SFMs可能效果不佳的情况不同，StableQuant通过分析每一层的尺度分布和整体性能，自适应地确定量化范围，从而实现与网络架构无关的最佳量化性能。在HuBERT和wav2vec2.0两个SFM模型上的自动语音识别(ASR)任务评估表明，StableQuant优于传统PTQ方法。StableQuant成功地将SFM模型大小减少到四分之一，推理速度提高一倍，同时将字错误率(WER)的性能下降限制在8比特量化下的0.3%以内。\n",
      "categories": [
        "eess.AS",
        "cs.AI"
      ],
      "primary_category": "eess.AS",
      "comment": "Accepted at ICASSP 2025",
      "pdf_url": "http://arxiv.org/pdf/2504.14915v1",
      "published_date": "2025-04-21 07:33:27 UTC",
      "updated_date": "2025-04-21 07:33:27 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-04-23T02:22:48.186602"
    },
    {
      "arxiv_id": "2504.14913v1",
      "title": "Guidelines for External Disturbance Factors in the Use of OCR in Real-World Environments",
      "title_zh": "真实环境中使用 OCR 时外部干扰因素指南\n",
      "authors": [
        "Kenji Iwata",
        "Eiki Ishidera",
        "Toshifumi Yamaai",
        "Yutaka Satoh",
        "Hiroshi Tanaka",
        "Katsuhiko Takahashi",
        "Akio Furuhata",
        "Yoshihisa Tanabe",
        "Hiroshi Matsumura"
      ],
      "abstract": "The performance of OCR has improved with the evolution of AI technology. As\nOCR continues to broaden its range of applications, the increased likelihood of\ninterference introduced by various usage environments can prevent it from\nachieving its inherent performance. This results in reduced recognition\naccuracy under certain conditions, and makes the quality control of recognition\ndevices more challenging. Therefore, to ensure that users can properly utilize\nOCR, we compiled the real-world external disturbance factors that cause\nperformance degradation, along with the resulting image degradation phenomena,\ninto an external disturbance factor table and, by also indicating how to make\nuse of it, organized them into guidelines.",
      "tldr_zh": "本文旨在解决OCR技术在实际应用中因外部干扰因素导致性能下降的问题。通过整理真实世界中导致OCR性能降低的外部干扰因素，以及由此产生的图像退化现象，构建了一个外部干扰因素表。同时，本文还提供了如何利用该表的指导方针，旨在帮助用户更好地利用OCR技术，并提高识别设备的质量控制水平。该研究为在复杂环境中部署和优化OCR系统提供了实用参考。\n",
      "categories": [
        "cs.CV",
        "cs.AI",
        "I.5.2; I.5.m"
      ],
      "primary_category": "cs.CV",
      "comment": "16 pages, 14 figures",
      "pdf_url": "http://arxiv.org/pdf/2504.14913v1",
      "published_date": "2025-04-21 07:32:28 UTC",
      "updated_date": "2025-04-21 07:32:28 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-04-23T02:22:59.878528"
    },
    {
      "arxiv_id": "2504.14904v1",
      "title": "VLM as Policy: Common-Law Content Moderation Framework for Short Video Platform",
      "title_zh": "VLM即策略：短视频平台的普通法内容审核框架\n",
      "authors": [
        "Xingyu Lu",
        "Tianke Zhang",
        "Chang Meng",
        "Xiaobei Wang",
        "Jinpeng Wang",
        "YiFan Zhang",
        "Shisong Tang",
        "Changyi Liu",
        "Haojie Ding",
        "Kaiyu Jiang",
        "Kaiyu Tang",
        "Bin Wen",
        "Hai-Tao Zheng",
        "Fan Yang",
        "Tingting Gao",
        "Di Zhang",
        "Kun Gai"
      ],
      "abstract": "Exponentially growing short video platforms (SVPs) face significant\nchallenges in moderating content detrimental to users' mental health,\nparticularly for minors. The dissemination of such content on SVPs can lead to\ncatastrophic societal consequences. Although substantial efforts have been\ndedicated to moderating such content, existing methods suffer from critical\nlimitations: (1) Manual review is prone to human bias and incurs high\noperational costs. (2) Automated methods, though efficient, lack nuanced\ncontent understanding, resulting in lower accuracy. (3) Industrial moderation\nregulations struggle to adapt to rapidly evolving trends due to long update\ncycles. In this paper, we annotate the first SVP content moderation benchmark\nwith authentic user/reviewer feedback to fill the absence of benchmark in this\nfield. Then we evaluate various methods on the benchmark to verify the\nexistence of the aforementioned limitations. We further propose our common-law\ncontent moderation framework named KuaiMod to address these challenges. KuaiMod\nconsists of three components: training data construction, offline adaptation,\nand online deployment & refinement. Leveraging large vision language model\n(VLM) and Chain-of-Thought (CoT) reasoning, KuaiMod adequately models video\ntoxicity based on sparse user feedback and fosters dynamic moderation policy\nwith rapid update speed and high accuracy. Offline experiments and large-scale\nonline A/B test demonstrates the superiority of KuaiMod: KuaiMod achieves the\nbest moderation performance on our benchmark. The deployment of KuaiMod reduces\nthe user reporting rate by 20% and its application in video recommendation\nincreases both Daily Active User (DAU) and APP Usage Time (AUT) on several\nKuaishou scenarios. We have open-sourced our benchmark at\nhttps://kuaimod.github.io.",
      "tldr_zh": "短视频平台的内容审核面临人工成本高、自动化方法理解不足和法规更新滞后等挑战。该论文提出了一个名为KuaiMod的通用内容审核框架，利用大型视觉语言模型(VLM)和链式思考(CoT)推理，基于稀疏的用户反馈充分建模视频毒性，并促进快速更新和高准确性的动态审核策略。KuaiMod包含训练数据构建、离线适配和在线部署与改进三个部分。离线实验和大规模在线A/B测试表明，KuaiMod在性能上优于现有方法，降低了用户举报率，并提升了快手场景中的DAU和APP使用时长。该论文还开源了一个短视频平台内容审核的benchmark。\n",
      "categories": [
        "cs.SI",
        "cs.AI",
        "cs.CL",
        "cs.MM"
      ],
      "primary_category": "cs.SI",
      "comment": "20 pages, 6 figures",
      "pdf_url": "http://arxiv.org/pdf/2504.14904v1",
      "published_date": "2025-04-21 07:20:19 UTC",
      "updated_date": "2025-04-21 07:20:19 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-04-23T02:23:12.153474"
    },
    {
      "arxiv_id": "2504.14889v1",
      "title": "Latent Bayesian Optimization via Autoregressive Normalizing Flows",
      "title_zh": "基于自回归归一化流的隐变量贝叶斯优化\n",
      "authors": [
        "Seunghun Lee",
        "Jinyoung Park",
        "Jaewon Chu",
        "Minseo Yoon",
        "Hyunwoo J. Kim"
      ],
      "abstract": "Bayesian Optimization (BO) has been recognized for its effectiveness in\noptimizing expensive and complex objective functions. Recent advancements in\nLatent Bayesian Optimization (LBO) have shown promise by integrating generative\nmodels such as variational autoencoders (VAEs) to manage the complexity of\nhigh-dimensional and structured data spaces. However, existing LBO approaches\noften suffer from the value discrepancy problem, which arises from the\nreconstruction gap between input and latent spaces. This value discrepancy\nproblem propagates errors throughout the optimization process, leading to\nsuboptimal outcomes. To address this issue, we propose a Normalizing Flow-based\nBayesian Optimization (NF-BO), which utilizes normalizing flow as a generative\nmodel to establish one-to-one encoding function from the input space to the\nlatent space, along with its left-inverse decoding function, eliminating the\nreconstruction gap. Specifically, we introduce SeqFlow, an autoregressive\nnormalizing flow for sequence data. In addition, we develop a new candidate\nsampling strategy that dynamically adjusts the exploration probability for each\ntoken based on its importance. Through extensive experiments, our NF-BO method\ndemonstrates superior performance in molecule generation tasks, significantly\noutperforming both traditional and recent LBO approaches.",
      "tldr_zh": "本文提出了一种基于自回归归一化流的潜在贝叶斯优化方法(NF-BO)，旨在解决现有潜在贝叶斯优化(LBO)方法中由于输入和潜在空间之间的重建差距而导致的值差异问题。NF-BO利用归一化流作为生成模型，建立输入空间到潜在空间的一对一编码函数，并配备左逆解码函数，从而消除重建差距。文章特别引入了SeqFlow，一种用于序列数据的自回归归一化流。此外，还开发了一种新的候选采样策略，该策略基于每个token的重要性动态调整其探索概率。实验结果表明，NF-BO在分子生成任务中表现优于传统和最新的LBO方法。\n",
      "categories": [
        "cs.LG",
        "cs.AI"
      ],
      "primary_category": "cs.LG",
      "comment": "ICLR 2025",
      "pdf_url": "http://arxiv.org/pdf/2504.14889v1",
      "published_date": "2025-04-21 06:36:09 UTC",
      "updated_date": "2025-04-21 06:36:09 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-04-23T02:23:24.055105"
    },
    {
      "arxiv_id": "2504.14879v1",
      "title": "Impact of Latent Space Dimension on IoT Botnet Detection Performance: VAE-Encoder Versus ViT-Encoder",
      "title_zh": "潜在空间维度对物联网僵尸网络检测性能的影响：VAE 编码器 vs. ViT 编码器\n",
      "authors": [
        "Hassan Wasswa",
        "Aziida Nanyonga",
        "Timothy Lynar"
      ],
      "abstract": "The rapid evolution of Internet of Things (IoT) technology has led to a\nsignificant increase in the number of IoT devices, applications, and services.\nThis surge in IoT devices, along with their widespread presence, has made them\na prime target for various cyber-attacks, particularly through IoT botnets. As\na result, security has become a major concern within the IoT ecosystem. This\nstudy focuses on investigating how the latent dimension impacts the performance\nof different deep learning classifiers when trained on latent vector\nrepresentations of the train dataset. The primary objective is to compare the\noutcomes of these models when encoder components from two cutting-edge\narchitectures: the Vision Transformer (ViT) and the Variational Auto-Encoder\n(VAE) are utilized to project the high dimensional train dataset to the learned\nlow dimensional latent space. The encoder components are employed to project\nhigh-dimensional structured .csv IoT botnet traffic datasets to various latent\nsizes. Evaluated on N-BaIoT and CICIoT2022 datasets, findings reveal that\nVAE-encoder based dimension reduction outperforms ViT-encoder based dimension\nreduction for both datasets in terms of four performance metrics including\naccuracy, precision, recall, and F1-score for all models which can be\nattributed to absence of spatial patterns in the datasets the ViT model\nattempts to learn and extract from image instances.",
      "tldr_zh": "该研究探讨了潜在空间维度对物联网(IoT)僵尸网络检测性能的影响，比较了变分自编码器(VAE)编码器和视觉Transformer (ViT)编码器在降维方面的表现。研究人员利用VAE和ViT将高维IoT僵尸网络流量数据集投影到不同大小的潜在空间，并在N-BaIoT和CICIoT2022数据集上评估了降维后的分类器性能。结果表明，由于数据集中缺乏ViT模型试图学习和提取的空间模式，基于VAE编码器的降维方法在准确率、精确率、召回率和F1-score等指标上均优于基于ViT编码器的降维方法。\n",
      "categories": [
        "cs.LG",
        "cs.AI"
      ],
      "primary_category": "cs.LG",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2504.14879v1",
      "published_date": "2025-04-21 06:15:07 UTC",
      "updated_date": "2025-04-21 06:15:07 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-04-23T02:23:36.157309"
    },
    {
      "arxiv_id": "2504.14875v1",
      "title": "ReSpec: Relevance and Specificity Grounded Online Filtering for Learning on Video-Text Data Streams",
      "title_zh": "ReSpec：基于相关性和特异性的在线过滤，用于在视频-文本数据流上进行学习\n",
      "authors": [
        "Chris Dongjoo Kim",
        "Jihwan Moon",
        "Sangwoo Moon",
        "Heeseung Yun",
        "Sihaeng Lee",
        "Aniruddha Kembhavi",
        "Soonyoung Lee",
        "Gunhee Kim",
        "Sangho Lee",
        "Christopher Clark"
      ],
      "abstract": "The rapid growth of video-text data presents challenges in storage and\ncomputation during training. Online learning, which processes streaming data in\nreal-time, offers a promising solution to these issues while also allowing\nswift adaptations in scenarios demanding real-time responsiveness. One strategy\nto enhance the efficiency and effectiveness of learning involves identifying\nand prioritizing data that enhances performance on target downstream tasks. We\npropose Relevance and Specificity-based online filtering framework (ReSpec)\nthat selects data based on four criteria: (i) modality alignment for clean\ndata, (ii) task relevance for target focused data, (iii) specificity for\ninformative and detailed data, and (iv) efficiency for low-latency processing.\nRelevance is determined by the probabilistic alignment of incoming data with\ndownstream tasks, while specificity employs the distance to a root embedding\nrepresenting the least specific data as an efficient proxy for informativeness.\nBy establishing reference points from target task data, ReSpec filters incoming\ndata in real-time, eliminating the need for extensive storage and compute.\nEvaluating on large-scale datasets WebVid2M and VideoCC3M, ReSpec attains\nstate-of-the-art performance on five zeroshot video retrieval tasks, using as\nlittle as 5% of the data while incurring minimal compute. The source code is\navailable at https://github.com/cdjkim/ReSpec.",
      "tldr_zh": "本文提出了一种基于相关性和特异性的在线过滤框架ReSpec，用于处理视频-文本数据流上的学习任务。ReSpec通过四个标准筛选数据：模态对齐（数据清洗）、任务相关性（聚焦目标任务）、特异性（信息丰富）和效率（低延迟处理）。该框架利用概率对齐确定相关性，并使用到根嵌入的距离作为特异性的代理，从而在实时环境中过滤数据，无需大量存储和计算。在WebVid2M和VideoCC3M数据集上的实验表明，ReSpec在五个零样本视频检索任务上取得了state-of-the-art的性能，仅使用5%的数据，并保持较低的计算成本。\n",
      "categories": [
        "cs.CV",
        "cs.AI",
        "cs.LG"
      ],
      "primary_category": "cs.CV",
      "comment": "CVPR 2025 (main conference)",
      "pdf_url": "http://arxiv.org/pdf/2504.14875v1",
      "published_date": "2025-04-21 06:02:03 UTC",
      "updated_date": "2025-04-21 06:02:03 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-04-23T02:23:48.169154"
    },
    {
      "arxiv_id": "2504.14870v1",
      "title": "OTC: Optimal Tool Calls via Reinforcement Learning",
      "title_zh": "OTC：通过强化学习实现最优工具调用\n",
      "authors": [
        "Hongru Wang",
        "Cheng Qian",
        "Wanjun Zhong",
        "Xiusi Chen",
        "Jiahao Qiu",
        "Shijue Huang",
        "Bowen Jin",
        "Mengdi Wang",
        "Kam-Fai Wong",
        "Heng Ji"
      ],
      "abstract": "Tool-integrated reasoning (TIR) augments large language models (LLMs) with\nthe ability to invoke external tools, such as search engines and code\ninterpreters, to solve tasks beyond the capabilities of language-only\nreasoning. While reinforcement learning (RL) has shown promise in improving TIR\nby optimizing final answer correctness, existing approaches often overlook the\nefficiency and cost associated with tool usage. This can lead to suboptimal\nbehavior, including excessive tool calls that increase computational and\nfinancial overhead, or insufficient tool use that compromises answer quality.\nIn this work, we propose Optimal Tool Call-controlled Policy Optimization\n(OTC-PO), a simple yet effective RL-based framework that encourages models to\nproduce accurate answers with minimal tool calls. Our method introduces a\ntool-integrated reward that jointly considers correctness and tool efficiency,\npromoting high tool productivity. We instantiate this framework within both\nProximal Policy Optimization (PPO) and Group Relative Preference Optimization\n(GRPO), resulting in OTC-PPO and OTC-GRPO. Experiments with Qwen-2.5 and\nQwen-Math across multiple QA benchmarks show that our approach reduces tool\ncalls by up to 73.1\\% and improves tool productivity by up to 229.4\\%, while\nmaintaining comparable answer accuracy. To the best of our knowledge, this is\nthe first RL-based framework that explicitly optimizes tool-use efficiency in\nTIR.",
      "tldr_zh": "该论文提出了Optimal Tool Call-controlled Policy Optimization (OTC-PO) 框架，旨在通过强化学习(RL)优化工具集成推理(TIR)中大型语言模型(LLM)的工具调用效率。OTC-PO通过引入工具集成奖励，同时考虑答案正确性和工具使用效率，鼓励模型以最少的工具调用次数产生准确答案。该框架在Proximal Policy Optimization (PPO)和Group Relative Preference Optimization (GRPO)中分别实例化为OTC-PPO和OTC-GRPO。实验结果表明，在多个QA基准测试中，该方法在保持相当答案准确率的同时，最多可减少73.1%的工具调用，并将工具生产力提高高达229.4%。该研究是首个明确优化TIR中工具使用效率的基于RL的框架。\n",
      "categories": [
        "cs.AI",
        "cs.CL"
      ],
      "primary_category": "cs.AI",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2504.14870v1",
      "published_date": "2025-04-21 05:40:05 UTC",
      "updated_date": "2025-04-21 05:40:05 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-04-23T02:24:00.503906"
    },
    {
      "arxiv_id": "2504.14860v1",
      "title": "Bridge the Gap: From Weak to Full Supervision for Temporal Action Localization with PseudoFormer",
      "title_zh": "弥合差距：使用 PseudoFormer 从弱监督到全监督的时间动作定位\n",
      "authors": [
        "Ziyi Liu",
        "Yangcen Liu"
      ],
      "abstract": "Weakly-supervised Temporal Action Localization (WTAL) has achieved notable\nsuccess but still suffers from a lack of temporal annotations, leading to a\nperformance and framework gap compared with fully-supervised methods. While\nrecent approaches employ pseudo labels for training, three key challenges:\ngenerating high-quality pseudo labels, making full use of different priors, and\noptimizing training methods with noisy labels remain unresolved. Due to these\nperspectives, we propose PseudoFormer, a novel two-branch framework that\nbridges the gap between weakly and fully-supervised Temporal Action\nLocalization (TAL). We first introduce RickerFusion, which maps all predicted\naction proposals to a global shared space to generate pseudo labels with better\nquality. Subsequently, we leverage both snippet-level and proposal-level labels\nwith different priors from the weak branch to train the regression-based model\nin the full branch. Finally, the uncertainty mask and iterative refinement\nmechanism are applied for training with noisy pseudo labels. PseudoFormer\nachieves state-of-the-art WTAL results on the two commonly used benchmarks,\nTHUMOS14 and ActivityNet1.3. Besides, extensive ablation studies demonstrate\nthe contribution of each component of our method.",
      "tldr_zh": "本文提出了一种名为PseudoFormer的新型双分支框架，旨在弥合弱监督时间动作定位(WTAL)和全监督时间动作定位(TAL)之间的差距。该框架首先引入RickerFusion，将所有预测的动作提议映射到全局共享空间，以生成更高质量的伪标签。随后，利用来自弱分支的不同先验知识，使用片段级别和提议级别的标签来训练全分支中基于回归的模型。最后，应用不确定性掩码和迭代细化机制来训练带噪声的伪标签。PseudoFormer在THUMOS14和ActivityNet1.3两个常用基准测试中取得了最先进的WTAL结果。消融实验证明了该方法中每个组件的贡献。\n",
      "categories": [
        "cs.CV",
        "cs.AI"
      ],
      "primary_category": "cs.CV",
      "comment": "CVPR 2025: IEEE Conference on Computer Vision and Pattern Recognition",
      "pdf_url": "http://arxiv.org/pdf/2504.14860v1",
      "published_date": "2025-04-21 05:00:07 UTC",
      "updated_date": "2025-04-21 05:00:07 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-04-23T02:24:12.245758"
    },
    {
      "arxiv_id": "2504.14858v1",
      "title": "AlignRAG: An Adaptable Framework for Resolving Misalignments in Retrieval-Aware Reasoning of RAG",
      "title_zh": "AlignRAG：一种用于解决 RAG 检索感知推理中不对齐问题的自适应框架\n",
      "authors": [
        "Jiaqi Wei",
        "Hao Zhou",
        "Xiang Zhang",
        "Di Zhang",
        "Zijie Qiu",
        "Wei Wei",
        "Jinzhe Li",
        "Wanli Ouyang",
        "Siqi Sun"
      ],
      "abstract": "Retrieval-augmented generation (RAG) has emerged as a foundational paradigm\nfor knowledge-grounded text generation. However, existing RAG pipelines often\nfail to ensure that the reasoning trajectories align with the evidential\nconstraints imposed by retrieved content. In this paper, we reframe RAG as a\nproblem of retrieval-aware reasoning and identify a core challenge: reasoning\nmisalignment-the mismatch between a model's reasoning trajectory and the\nretrieved evidence. To address this challenge, we propose AlignRAG, a novel\ntest-time framework that mitigates reasoning misalignment through iterative\nCritique-Driven Alignment (CDA) steps. In contrast to prior approaches that\nrely on static training or post-hoc selection, AlignRAG actively refines\nreasoning trajectories during inference by enforcing fine-grained alignment\nwith evidence. Our framework introduces a new paradigm for retrieval-aware\nreasoning by: (1) constructing context-rich training corpora; (2) generating\ncontrastive critiques from preference-aware reasoning trajectories; (3)\ntraining a dedicated \\textit{Critic Language Model (CLM)} to identify reasoning\nmisalignments; and (4) applying CDA steps to optimize reasoning trajectories\niteratively. Empirical results demonstrate that AlignRAG consistently\noutperforms all baselines and could integrate as a plug-and-play module into\nexisting RAG pipelines without further changes. By reconceptualizing RAG as a\nstructured reasoning trajectory and establishing the test-time framework for\ncorrecting reasoning misalignments in RAG, AlignRAG provides practical\nadvancements for retrieval-aware generation.",
      "tldr_zh": "本文将检索增强生成(RAG)重新定义为检索感知的推理问题，并指出了其中的核心挑战：推理错位，即模型推理轨迹与检索证据之间的不匹配。为了解决这个问题，作者提出了AlignRAG，一个新颖的测试时框架，通过迭代的批判驱动对齐(CDA)步骤来缓解推理错位。AlignRAG通过构建上下文丰富的训练语料库、从偏好感知的推理轨迹中生成对比性批判、训练专门的批判语言模型(CLM)来识别推理错位，并应用CDA步骤来迭代优化推理轨迹。实验结果表明，AlignRAG始终优于所有基线模型，并且可以作为即插即用模块集成到现有的RAG流程中，无需进一步更改。AlignRAG为检索感知的生成提供了实际的进步。\n",
      "categories": [
        "cs.AI",
        "cs.CL"
      ],
      "primary_category": "cs.AI",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2504.14858v1",
      "published_date": "2025-04-21 04:56:47 UTC",
      "updated_date": "2025-04-21 04:56:47 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-04-23T02:24:24.189880"
    },
    {
      "arxiv_id": "2504.14848v1",
      "title": "Object-Level Verbalized Confidence Calibration in Vision-Language Models via Semantic Perturbation",
      "title_zh": "基于语义扰动的视觉-语言模型中面向对象级别的口头置信度校准\n",
      "authors": [
        "Yunpu Zhao",
        "Rui Zhang",
        "Junbin Xiao",
        "Ruibo Hou",
        "Jiaming Guo",
        "Zihao Zhang",
        "Yifan Hao",
        "Yunji Chen"
      ],
      "abstract": "Vision-language models (VLMs) excel in various multimodal tasks but\nfrequently suffer from poor calibration, resulting in misalignment between\ntheir verbalized confidence and response correctness. This miscalibration\nundermines user trust, especially when models confidently provide incorrect or\nfabricated information. In this work, we propose a novel Confidence Calibration\nthrough Semantic Perturbation (CSP) framework to improve the calibration of\nverbalized confidence for VLMs in response to object-centric queries. We first\nintroduce a perturbed dataset where Gaussian noise is applied to the key object\nregions to simulate visual uncertainty at different confidence levels,\nestablishing an explicit mapping between visual ambiguity and confidence\nlevels. We further enhance calibration through a two-stage training process\ncombining supervised fine-tuning on the perturbed dataset with subsequent\npreference optimization. Extensive experiments on popular benchmarks\ndemonstrate that our method significantly improves the alignment between\nverbalized confidence and response correctness while maintaining or enhancing\noverall task performance. These results highlight the potential of semantic\nperturbation as a practical tool for improving the reliability and\ninterpretability of VLMs.",
      "tldr_zh": "该论文提出了一种通过语义扰动进行置信度校准(Confidence Calibration through Semantic Perturbation, CSP)的框架，旨在提升视觉语言模型(VLMs)在处理以物体为中心的查询时，其口头表达的置信度与回答正确性之间的一致性。CSP框架首先构建一个扰动数据集，通过对关键物体区域施加高斯噪声来模拟不同置信度下的视觉不确定性，从而建立视觉模糊性和置信度之间的显式映射。然后，通过一个两阶段训练过程，结合在扰动数据集上的监督微调和后续的偏好优化，进一步增强校准效果。实验结果表明，CSP框架显著提高了口头表达的置信度与回答正确性之间的一致性，同时保持或提升了整体任务性能，验证了语义扰动作为提高VLMs可靠性和可解释性的实用工具的潜力。\n",
      "categories": [
        "cs.CV",
        "cs.AI"
      ],
      "primary_category": "cs.CV",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2504.14848v1",
      "published_date": "2025-04-21 04:01:22 UTC",
      "updated_date": "2025-04-21 04:01:22 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-04-23T02:24:36.379499"
    },
    {
      "arxiv_id": "2504.14839v1",
      "title": "Exploring $\\ell_0$ Sparsification for Inference-free Sparse Retrievers",
      "title_zh": "探索用于无推理稀疏检索器的$\\ell_0$稀疏化方法\n",
      "authors": [
        "Xinjie Shen",
        "Zhichao Geng",
        "Yang Yang"
      ],
      "abstract": "With increasing demands for efficiency, information retrieval has developed a\nbranch of sparse retrieval, further advancing towards inference-free retrieval\nwhere the documents are encoded during indexing time and there is no\nmodel-inference for queries. Existing sparse retrieval models rely on FLOPS\nregularization for sparsification, while this mechanism was originally designed\nfor Siamese encoders, it is considered to be suboptimal in inference-free\nscenarios which is asymmetric. Previous attempts to adapt FLOPS for\ninference-free scenarios have been limited to rule-based methods, leaving the\npotential of sparsification approaches for inference-free retrieval models\nlargely unexplored. In this paper, we explore $\\ell_0$ inspired sparsification\nmanner for inference-free retrievers. Through comprehensive out-of-domain\nevaluation on the BEIR benchmark, our method achieves state-of-the-art\nperformance among inference-free sparse retrieval models and is comparable to\nleading Siamese sparse retrieval models. Furthermore, we provide insights into\nthe trade-off between retrieval effectiveness and computational efficiency,\ndemonstrating practical value for real-world applications.",
      "tldr_zh": "该论文探索了$\\ell_0$稀疏化方法在无推理稀疏检索器中的应用。针对现有稀疏检索模型依赖FLOPS正则化进行稀疏化，但在非对称的无推理场景下效果欠佳的问题，提出了基于$\\ell_0$的稀疏化方案。通过在BEIR基准上进行全面的跨领域评估，该方法在无推理稀疏检索模型中实现了最先进的性能，并且可以与领先的Siamese稀疏检索模型相媲美。此外，论文还深入研究了检索效果和计算效率之间的权衡，展示了该方法在实际应用中的价值。\n",
      "categories": [
        "cs.IR",
        "cs.AI"
      ],
      "primary_category": "cs.IR",
      "comment": "Accepted by SIGIR 2025",
      "pdf_url": "http://arxiv.org/pdf/2504.14839v1",
      "published_date": "2025-04-21 03:40:43 UTC",
      "updated_date": "2025-04-21 03:40:43 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-04-23T02:24:48.041249"
    },
    {
      "arxiv_id": "2504.14838v1",
      "title": "Establishing Reliability Metrics for Reward Models in Large Language Models",
      "title_zh": "建立大型语言模型中奖励模型的可靠性指标\n",
      "authors": [
        "Yizhou Chen",
        "Yawen Liu",
        "Xuesi Wang",
        "Qingtao Yu",
        "Guangda Huzhang",
        "Anxiang Zeng",
        "Han Yu",
        "Zhiming Zhou"
      ],
      "abstract": "The reward model (RM) that represents human preferences plays a crucial role\nin optimizing the outputs of large language models (LLMs), e.g., through\nreinforcement learning from human feedback (RLHF) or rejection sampling.\nHowever, a long challenge for RM is its uncertain reliability, i.e., LLM\noutputs with higher rewards may not align with actual human preferences.\nCurrently, there is a lack of a convincing metric to quantify the reliability\nof RMs. To bridge this gap, we propose the \\textit{\\underline{R}eliable at\n\\underline{$\\eta$}} (RETA) metric, which directly measures the reliability of\nan RM by evaluating the average quality (scored by an oracle) of the top $\\eta$\nquantile responses assessed by an RM. On top of RETA, we present an integrated\nbenchmarking pipeline that allows anyone to evaluate their own RM without\nincurring additional Oracle labeling costs. Extensive experimental studies\ndemonstrate the superior stability of RETA metric, providing solid evaluations\nof the reliability of various publicly available and proprietary RMs. When\ndealing with an unreliable RM, we can use the RETA metric to identify the\noptimal quantile from which to select the responses.",
      "tldr_zh": "该论文提出了一个名为“Reliable at η (RETA)”的新指标，用于量化大型语言模型(LLM)中奖励模型(RM)的可靠性。RETA通过评估RM评定的前η分位数响应的平均质量（由oracle评分）来直接衡量RM的可靠性。此外，论文还提出了一个集成的基准测试流程，允许评估者在不产生额外oracle标注成本的情况下评估自己的RM。实验结果表明，RETA指标具有优越的稳定性，能够对各种公开和私有的RM进行可靠性评估。当处理不可靠的RM时，RETA指标可以用于识别选择响应的最佳分位数。\n",
      "categories": [
        "cs.AI"
      ],
      "primary_category": "cs.AI",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2504.14838v1",
      "published_date": "2025-04-21 03:39:33 UTC",
      "updated_date": "2025-04-21 03:39:33 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-04-23T02:25:00.239259"
    },
    {
      "arxiv_id": "2504.14832v1",
      "title": "Protecting Your Voice: Temporal-aware Robust Watermarking",
      "title_zh": "保护你的声音：时序感知鲁棒水印",
      "authors": [
        "Yue Li",
        "Weizhi Liu",
        "Dongdong Lin"
      ],
      "abstract": "The rapid advancement of generative models has led to the synthesis of\nreal-fake ambiguous voices. To erase the ambiguity, embedding watermarks into\nthe frequency-domain features of synthesized voices has become a common\nroutine. However, the robustness achieved by choosing the frequency domain\noften comes at the expense of fine-grained voice features, leading to a loss of\nfidelity. Maximizing the comprehensive learning of time-domain features to\nenhance fidelity while maintaining robustness, we pioneer a\n\\textbf{\\underline{t}}emporal-aware\n\\textbf{\\underline{r}}ob\\textbf{\\underline{u}}st\nwat\\textbf{\\underline{e}}rmarking (\\emph{True}) method for protecting the\nspeech and singing voice.",
      "tldr_zh": "为了应对生成模型合成的真假难辨的声音，该论文提出了一种时域感知的鲁棒水印方法(True)，用于保护语音和歌声。该方法旨在最大化时域特征的综合学习，从而在保持鲁棒性的同时，提升语音的保真度，克服了传统频域水印方法牺牲细粒度语音特征的缺点。该方法在时域中嵌入水印，从而在保真度和鲁棒性之间取得平衡。\n",
      "categories": [
        "cs.CR",
        "cs.AI",
        "cs.SD"
      ],
      "primary_category": "cs.CR",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2504.14832v1",
      "published_date": "2025-04-21 03:23:10 UTC",
      "updated_date": "2025-04-21 03:23:10 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-04-23T02:25:12.128350"
    },
    {
      "arxiv_id": "2504.14825v1",
      "title": "ECViT: Efficient Convolutional Vision Transformer with Local-Attention and Multi-scale Stages",
      "title_zh": "ECViT：具有局部注意力和多尺度阶段的高效卷积视觉Transformer\n",
      "authors": [
        "Zhoujie Qian"
      ],
      "abstract": "Vision Transformers (ViTs) have revolutionized computer vision by leveraging\nself-attention to model long-range dependencies. However, ViTs face challenges\nsuch as high computational costs due to the quadratic scaling of self-attention\nand the requirement of a large amount of training data. To address these\nlimitations, we propose the Efficient Convolutional Vision Transformer (ECViT),\na hybrid architecture that effectively combines the strengths of CNNs and\nTransformers. ECViT introduces inductive biases such as locality and\ntranslation invariance, inherent to Convolutional Neural Networks (CNNs) into\nthe Transformer framework by extracting patches from low-level features and\nenhancing the encoder with convolutional operations. Additionally, it\nincorporates local-attention and a pyramid structure to enable efficient\nmulti-scale feature extraction and representation. Experimental results\ndemonstrate that ECViT achieves an optimal balance between performance and\nefficiency, outperforming state-of-the-art models on various image\nclassification tasks while maintaining low computational and storage\nrequirements. ECViT offers an ideal solution for applications that prioritize\nhigh efficiency without compromising performance.",
      "tldr_zh": "本文提出了一种高效卷积视觉Transformer (ECViT)，它结合了CNN和Transformer的优势。ECViT通过从底层特征中提取patch并将卷积操作增强到编码器中，将CNN的局部性和平移不变性等归纳偏置引入Transformer框架。此外，它还结合了local-attention和金字塔结构，以实现高效的多尺度特征提取和表示。实验结果表明，ECViT在各种图像分类任务上优于现有模型，并在性能和效率之间取得了最佳平衡，同时保持了较低的计算和存储需求。ECViT为优先考虑高效率而不牺牲性能的应用提供了一个理想的解决方案。\n",
      "categories": [
        "cs.CV",
        "cs.AI"
      ],
      "primary_category": "cs.CV",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2504.14825v1",
      "published_date": "2025-04-21 03:00:17 UTC",
      "updated_date": "2025-04-21 03:00:17 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-04-23T02:25:24.175242"
    },
    {
      "arxiv_id": "2504.14815v1",
      "title": "What Lurks Within? Concept Auditing for Shared Diffusion Models at Scale",
      "title_zh": "潜伏于何处？大规模共享扩散模型的概念审计\n",
      "authors": [
        "Xiaoyong Yuan",
        "Xiaolong Ma",
        "Linke Guo",
        "Lan Zhang"
      ],
      "abstract": "Diffusion models (DMs) have revolutionized text-to-image generation, enabling\nthe creation of highly realistic and customized images from text prompts. With\nthe rise of parameter-efficient fine-tuning (PEFT) techniques like LoRA, users\ncan now customize powerful pre-trained models using minimal computational\nresources. However, the widespread sharing of fine-tuned DMs on open platforms\nraises growing ethical and legal concerns, as these models may inadvertently or\ndeliberately generate sensitive or unauthorized content, such as copyrighted\nmaterial, private individuals, or harmful content. Despite the increasing\nregulatory attention on generative AI, there are currently no practical tools\nfor systematically auditing these models before deployment. In this paper, we\naddress the problem of concept auditing: determining whether a fine-tuned DM\nhas learned to generate a specific target concept. Existing approaches\ntypically rely on prompt-based input crafting and output-based image\nclassification but suffer from critical limitations, including prompt\nuncertainty, concept drift, and poor scalability. To overcome these challenges,\nwe introduce Prompt-Agnostic Image-Free Auditing (PAIA), a novel, model-centric\nconcept auditing framework. By treating the DM as the object of inspection,\nPAIA enables direct analysis of internal model behavior, bypassing the need for\noptimized prompts or generated images. We evaluate PAIA on 320 controlled model\nand 690 real-world community models sourced from a public DM sharing platform.\nPAIA achieves over 90% detection accuracy while reducing auditing time by\n18-40x compared to existing baselines. To our knowledge, PAIA is the first\nscalable and practical solution for pre-deployment concept auditing of\ndiffusion models, providing a practical foundation for safer and more\ntransparent diffusion model sharing.",
      "tldr_zh": "该研究关注共享扩散模型(Diffusion Models, DMs)中潜在的伦理和法律风险，特别是经过参数高效微调(PEFT)后，模型可能生成敏感或未经授权的内容。针对现有基于提示工程和图像分类的审计方法的局限性，提出了Prompt-Agnostic Image-Free Auditing (PAIA)框架。PAIA是一种模型中心的概念审计方法，直接分析模型内部行为，无需优化提示或生成图像。实验结果表明，PAIA在检测准确率超过90%的同时，将审计时间缩短了18-40倍，为扩散模型的部署前概念审计提供了一种可扩展且实用的解决方案。\n",
      "categories": [
        "cs.LG",
        "cs.AI",
        "cs.CR",
        "cs.CV"
      ],
      "primary_category": "cs.LG",
      "comment": "17 pages, 15 figures",
      "pdf_url": "http://arxiv.org/pdf/2504.14815v1",
      "published_date": "2025-04-21 02:44:59 UTC",
      "updated_date": "2025-04-21 02:44:59 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-04-23T02:25:36.135271"
    },
    {
      "arxiv_id": "2504.14810v1",
      "title": "DONOD: Robust and Generalizable Instruction Fine-Tuning for LLMs via Model-Intrinsic Dataset Pruning",
      "title_zh": "DONOD：通过模型内在数据集剪枝实现对LLM的鲁棒且可泛化的指令微调\n",
      "authors": [
        "Jucheng Hu",
        "Surong Yang",
        "Dongzhan Zhou",
        "Lijun Wu"
      ],
      "abstract": "Ad-hoc instruction fine-tuning of large language models (LLMs) is widely\nadopted for domain-specific adaptation. While domain-specific supervised\nfine-tuning (SFT) is effective and efficient, it often weakens cross-domain\ngeneralization and struggles with noisy training data. To address these\nchallenges, we propose DONOD, a lightweight model-intrinsic data pruning\nmethod. Our approach evaluates data using two model-parameter-based metrics:\nDelta of Norm (DON), which captures the cumulative influence on model weights,\nand Norm of Delta (NOD), which quantifies weight instability. Moreover, by\nemploying the Technique for Order of Preference by Similarity to Ideal Solution\n(TOPSIS) algorithm, we effectively filter noisy, unlearnable, and\ngeneralization-harming samples without relying on auxiliary models during the\nSFT process. Experiments on mathematical tasks demonstrate that data selected\nby DONOD achieve superior fine-tuning efficiency and improved robustness\nagainst noisy data. By filtering out 70% of the full dataset, we improve\ntarget-domain accuracy by 14.90% and cross-domain accuracy by 5.67%. Meanwhile,\nour selected data present superior cross-architecture generalization. Data\npruned by smaller models (e.g., Llama 3.1-8B) generalize effectively on larger\nmodels (e.g., Llama 2-13B). Compared to existing related methodologies, DONOD\ndemonstrates comparable or superior performance while remaining\ndataset-agnostic, enabling broader applicability.",
      "tldr_zh": "该论文提出了一种名为DONOD的模型内在数据剪枝方法，用于提升大型语言模型(LLMs)指令微调的鲁棒性和泛化能力。DONOD利用模型参数计算两个指标：Delta of Norm (DON)衡量数据对模型权重的影响，Norm of Delta (NOD)量化权重不稳定性。通过TOPSIS算法，DONOD能够有效过滤噪声数据、难以学习的数据以及损害泛化能力的数据，无需依赖辅助模型。在数学任务上的实验表明，DONOD选择的数据能够提高微调效率，增强抗噪性，在过滤掉70%的数据后，目标域准确率提升14.90%，跨域准确率提升5.67%。此外，DONOD剪枝后的数据具有更好的跨架构泛化能力。\n",
      "categories": [
        "cs.AI",
        "cs.LG"
      ],
      "primary_category": "cs.AI",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2504.14810v1",
      "published_date": "2025-04-21 02:25:03 UTC",
      "updated_date": "2025-04-21 02:25:03 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-04-23T02:25:48.330478"
    },
    {
      "arxiv_id": "2504.14808v1",
      "title": "On Self-improving Token Embeddings",
      "title_zh": "关于自改进的 Token 嵌入\n",
      "authors": [
        "Mario M. Kubek",
        "Shiraj Pokharel",
        "Thomas Böhme",
        "Emma L. McDaniel",
        "Herwig Unger",
        "Armin R. Mikler"
      ],
      "abstract": "This article introduces a novel and fast method for refining pre-trained\nstatic word or, more generally, token embeddings. By incorporating the\nembeddings of neighboring tokens in text corpora, it continuously updates the\nrepresentation of each token, including those without pre-assigned embeddings.\nThis approach effectively addresses the out-of-vocabulary problem, too.\nOperating independently of large language models and shallow neural networks,\nit enables versatile applications such as corpus exploration, conceptual\nsearch, and word sense disambiguation. The method is designed to enhance token\nrepresentations within topically homogeneous corpora, where the vocabulary is\nrestricted to a specific domain, resulting in more meaningful embeddings\ncompared to general-purpose pre-trained vectors. As an example, the methodology\nis applied to explore storm events and their impacts on infrastructure and\ncommunities using narratives from a subset of the NOAA Storm Events database.\nThe article also demonstrates how the approach improves the representation of\nstorm-related terms over time, providing valuable insights into the evolving\nnature of disaster narratives.",
      "tldr_zh": "本文提出了一种快速改进预训练静态词/token embedding的新方法。该方法通过整合文本语料库中相邻token的embedding，持续更新每个token的表示，包括那些没有预先分配embedding的token，有效解决了词汇表外(out-of-vocabulary)问题。该方法独立于大型语言模型和浅层神经网络，适用于语料库探索、概念搜索和词义消歧等多种应用。该方法旨在增强主题同质语料库中的token表示，其中词汇表被限制在特定领域，从而产生比通用预训练向量更有意义的embedding。例如，该方法被应用于探索风暴事件及其对基础设施和社区的影响，使用了NOAA风暴事件数据库的一个子集中的叙述。文章还展示了该方法如何随着时间的推移改进与风暴相关术语的表示，从而为了解灾难叙事的演变性质提供了宝贵的见解。\n",
      "categories": [
        "cs.CL",
        "cs.AI",
        "cs.IR",
        "cs.LG",
        "68T50, 68T07",
        "I.2.6; I.2.7; H.3.3"
      ],
      "primary_category": "cs.CL",
      "comment": "18 pages, 4 figures, 3 tables, accepted at the 2025 25th\n  International Conference on Innovations for Community Services (I4CS), June\n  11 - 13, Munich, Germany, 2025",
      "pdf_url": "http://arxiv.org/pdf/2504.14808v1",
      "published_date": "2025-04-21 02:17:19 UTC",
      "updated_date": "2025-04-21 02:17:19 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-04-23T02:26:00.547161"
    },
    {
      "arxiv_id": "2504.14805v1",
      "title": "Dynamic Contrastive Skill Learning with State-Transition Based Skill Clustering and Dynamic Length Adjustment",
      "title_zh": "基于状态转移的技能聚类和动态长度调整的动态对比技能学习\n",
      "authors": [
        "Jinwoo Choi",
        "Seung-Woo Seo"
      ],
      "abstract": "Reinforcement learning (RL) has made significant progress in various domains,\nbut scaling it to long-horizon tasks with complex decision-making remains\nchallenging. Skill learning attempts to address this by abstracting actions\ninto higher-level behaviors. However, current approaches often fail to\nrecognize semantically similar behaviors as the same skill and use fixed skill\nlengths, limiting flexibility and generalization. To address this, we propose\nDynamic Contrastive Skill Learning (DCSL), a novel framework that redefines\nskill representation and learning. DCSL introduces three key ideas:\nstate-transition based skill representation, skill similarity function\nlearning, and dynamic skill length adjustment. By focusing on state transitions\nand leveraging contrastive learning, DCSL effectively captures the semantic\ncontext of behaviors and adapts skill lengths to match the appropriate temporal\nextent of behaviors. Our approach enables more flexible and adaptive skill\nextraction, particularly in complex or noisy datasets, and demonstrates\ncompetitive performance compared to existing methods in task completion and\nefficiency.",
      "tldr_zh": "该论文提出了动态对比技能学习(DCSL)框架，旨在解决强化学习中技能学习方法无法识别语义相似行为以及技能长度固定的问题。DCSL通过基于状态转移的技能表示、技能相似度函数学习以及动态技能长度调整三个关键创新点，有效捕捉行为的语义信息，并使技能长度能够适应行为的时间范围。实验结果表明，DCSL在复杂或嘈杂的数据集中表现出更灵活和适应性的技能提取能力，并在任务完成度和效率方面与现有方法相比具有竞争力。\n",
      "categories": [
        "cs.LG",
        "cs.AI",
        "cs.RO"
      ],
      "primary_category": "cs.LG",
      "comment": "ICLR 2025; 23 pages, 12 figures",
      "pdf_url": "http://arxiv.org/pdf/2504.14805v1",
      "published_date": "2025-04-21 02:11:39 UTC",
      "updated_date": "2025-04-21 02:11:39 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-04-23T02:26:12.048149"
    },
    {
      "arxiv_id": "2504.14804v1",
      "title": "Automatic Evaluation Metrics for Document-level Translation: Overview, Challenges and Trends",
      "title_zh": "文档级翻译的自动评估指标：概述、挑战与趋势\n",
      "authors": [
        "Jiaxin GUO",
        "Xiaoyu Chen",
        "Zhiqiang Rao",
        "Jinlong Yang",
        "Zongyao Li",
        "Hengchao Shang",
        "Daimeng Wei",
        "Hao Yang"
      ],
      "abstract": "With the rapid development of deep learning technologies, the field of\nmachine translation has witnessed significant progress, especially with the\nadvent of large language models (LLMs) that have greatly propelled the\nadvancement of document-level translation. However, accurately evaluating the\nquality of document-level translation remains an urgent issue. This paper first\nintroduces the development status of document-level translation and the\nimportance of evaluation, highlighting the crucial role of automatic evaluation\nmetrics in reflecting translation quality and guiding the improvement of\ntranslation systems. It then provides a detailed analysis of the current state\nof automatic evaluation schemes and metrics, including evaluation methods with\nand without reference texts, as well as traditional metrics, Model-based\nmetrics and LLM-based metrics. Subsequently, the paper explores the challenges\nfaced by current evaluation methods, such as the lack of reference diversity,\ndependence on sentence-level alignment information, and the bias, inaccuracy,\nand lack of interpretability of the LLM-as-a-judge method. Finally, the paper\nlooks ahead to the future trends in evaluation methods, including the\ndevelopment of more user-friendly document-level evaluation methods and more\nrobust LLM-as-a-judge methods, and proposes possible research directions, such\nas reducing the dependency on sentence-level information, introducing\nmulti-level and multi-granular evaluation approaches, and training models\nspecifically for machine translation evaluation. This study aims to provide a\ncomprehensive analysis of automatic evaluation for document-level translation\nand offer insights into future developments.",
      "tldr_zh": "本文概述了文档级机器翻译自动评估的发展现状、重要性及面临的挑战。随着大型语言模型(LLMs)的出现，文档级翻译取得了显著进展，但准确评估其质量仍是关键问题。文章详细分析了当前自动评估方案和指标，包括有无参考文本的评估方法，以及传统指标、基于模型的指标和基于LLM的指标。随后，探讨了现有评估方法面临的挑战，如参考多样性不足、依赖句子级对齐信息以及LLM作为评判者的偏差、不准确和缺乏可解释性。最后，展望了未来评估方法的发展趋势，包括开发更友好的文档级评估方法和更强大的LLM评判方法，并提出了可能的研究方向，例如减少对句子级信息的依赖，引入多层次和多粒度的评估方法，以及专门为机器翻译评估训练模型。\n",
      "categories": [
        "cs.CL",
        "cs.AI"
      ],
      "primary_category": "cs.CL",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2504.14804v1",
      "published_date": "2025-04-21 02:08:42 UTC",
      "updated_date": "2025-04-21 02:08:42 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-04-23T02:26:24.467619"
    },
    {
      "arxiv_id": "2504.14797v1",
      "title": "Automated Duplicate Bug Report Detection in Large Open Bug Repositories",
      "title_zh": "大型开放 Bug 存储库中的重复 Bug 报告自动检测\n",
      "authors": [
        "Clare E. Laney",
        "Andrew Barovic",
        "Armin Moin"
      ],
      "abstract": "Many users and contributors of large open-source projects report software\ndefects or enhancement requests (known as bug reports) to the issue-tracking\nsystems. However, they sometimes report issues that have already been reported.\nFirst, they may not have time to do sufficient research on existing bug\nreports. Second, they may not possess the right expertise in that specific area\nto realize that an existing bug report is essentially elaborating on the same\nmatter, perhaps with a different wording. In this paper, we propose a novel\napproach based on machine learning methods that can automatically detect\nduplicate bug reports in an open bug repository based on the textual data in\nthe reports. We present six alternative methods: Topic modeling, Gaussian Naive\nBayes, deep learning, time-based organization, clustering, and summarization\nusing a generative pre-trained transformer large language model. Additionally,\nwe introduce a novel threshold-based approach for duplicate identification, in\ncontrast to the conventional top-k selection method that has been widely used\nin the literature. Our approach demonstrates promising results across all the\nproposed methods, achieving accuracy rates ranging from the high 70%'s to the\nlow 90%'s. We evaluated our methods on a public dataset of issues belonging to\nan Eclipse open-source project.",
      "tldr_zh": "本文提出了一种基于机器学习的自动检测重复bug报告的方法，旨在解决大型开源项目中重复bug报告的问题。该方法利用bug报告中的文本数据，提出了六种替代方案：主题建模、高斯朴素贝叶斯、深度学习、基于时间的组织、聚类以及使用生成式预训练Transformer大语言模型的摘要。此外，还引入了一种新的基于阈值的重复识别方法，以替代传统的top-k选择方法。在Eclipse开源项目的公共数据集上的评估结果表明，该方法在所有提出的方法中都取得了良好的效果，准确率从70%多到90%多不等。\n",
      "categories": [
        "cs.SE",
        "cs.AI"
      ],
      "primary_category": "cs.SE",
      "comment": "IEEE COMPSAC 2025",
      "pdf_url": "http://arxiv.org/pdf/2504.14797v1",
      "published_date": "2025-04-21 01:55:54 UTC",
      "updated_date": "2025-04-21 01:55:54 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-04-23T02:26:36.174337"
    },
    {
      "arxiv_id": "2504.14783v1",
      "title": "How Effective Can Dropout Be in Multiple Instance Learning ?",
      "title_zh": "Dropout 在多示例学习中能有多有效？\n",
      "authors": [
        "Wenhui Zhu",
        "Peijie Qiu",
        "Xiwen Chen",
        "Zhangsihao Yang",
        "Aristeidis Sotiras",
        "Abolfazl Razi",
        "Yalin Wang"
      ],
      "abstract": "Multiple Instance Learning (MIL) is a popular weakly-supervised method for\nvarious applications, with a particular interest in histological whole slide\nimage (WSI) classification. Due to the gigapixel resolution of WSI,\napplications of MIL in WSI typically necessitate a two-stage training scheme:\nfirst, extract features from the pre-trained backbone and then perform MIL\naggregation. However, it is well-known that this suboptimal training scheme\nsuffers from \"noisy\" feature embeddings from the backbone and inherent weak\nsupervision, hindering MIL from learning rich and generalizable features.\nHowever, the most commonly used technique (i.e., dropout) for mitigating this\nissue has yet to be explored in MIL. In this paper, we empirically explore how\neffective the dropout can be in MIL. Interestingly, we observe that dropping\nthe top-k most important instances within a bag leads to better performance and\ngeneralization even under noise attack. Based on this key observation, we\npropose a novel MIL-specific dropout method, termed MIL-Dropout, which\nsystematically determines which instances to drop. Experiments on five MIL\nbenchmark datasets and two WSI datasets demonstrate that MIL-Dropout boosts the\nperformance of current MIL methods with a negligible computational cost. The\ncode is available at https://github.com/ChongQingNoSubway/MILDropout.",
      "tldr_zh": "本文研究了dropout技术在多示例学习(MIL)中的有效性，特别是在组织学全切片图像(WSI)分类中的应用。针对MIL中两阶段训练方案导致的“噪声”特征嵌入和弱监督问题，作者提出了一种新颖的MIL专用dropout方法，称为MIL-Dropout。该方法通过选择性地dropout一个bag中最重要的top-k个实例，从而提高性能和泛化能力，即使在噪声攻击下也能保持有效。在五个MIL基准数据集和两个WSI数据集上的实验表明，MIL-Dropout以极低的计算成本提升了现有MIL方法的性能。\n",
      "categories": [
        "cs.CV",
        "cs.AI",
        "eess.IV",
        "stat.ML"
      ],
      "primary_category": "cs.CV",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2504.14783v1",
      "published_date": "2025-04-21 00:46:31 UTC",
      "updated_date": "2025-04-21 00:46:31 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-04-23T02:26:48.242275"
    },
    {
      "arxiv_id": "2504.14779v1",
      "title": "Exploring Collaborative GenAI Agents in Synchronous Group Settings: Eliciting Team Perceptions and Design Considerations for the Future of Work",
      "title_zh": "探索同步群体环境下的协作式 GenAI 智能体：激发团队认知，为未来工作提供设计考量\n",
      "authors": [
        "Janet G. Johnson",
        "Macarena Peralta",
        "Mansanjam Kaur",
        "Ruijie Sophia Huang",
        "Sheng Zhao",
        "Ruijia Guan",
        "Shwetha Rajaram",
        "Michael Nebeling"
      ],
      "abstract": "While generative artificial intelligence (GenAI) is finding increased\nadoption in workplaces, current tools are primarily designed for individual\nuse. Prior work established the potential for these tools to enhance personal\ncreativity and productivity towards shared goals; however, we don't know yet\nhow to best take into account the nuances of group work and team dynamics when\ndeploying GenAI in work settings. In this paper, we investigate the potential\nof collaborative GenAI agents to augment teamwork in synchronous group settings\nthrough an exploratory study that engaged 25 professionals across 6 teams in\nspeculative design workshops and individual follow-up interviews. Our workshops\nincluded a mixed reality provotype to simulate embodied collaborative GenAI\nagents capable of actively participating in group discussions. Our findings\nsuggest that, if designed well, collaborative GenAI agents offer valuable\nopportunities to enhance team problem-solving by challenging groupthink,\nbridging communication gaps, and reducing social friction. However, teams'\nwillingness to integrate GenAI agents depended on its perceived fit across a\nnumber of individual, team, and organizational factors. We outline the key\ndesign tensions around agent representation, social prominence, and engagement\nand highlight the opportunities spatial and immersive technologies could offer\nto modulate GenAI influence on team outcomes and strike a balance between\naugmentation and agency.",
      "tldr_zh": "该研究探索了协作式生成式人工智能（GenAI）智能体在同步团队环境中的应用潜力。通过对25位专业人士组成的6个团队进行推测性设计工作坊和后续访谈，研究人员利用混合现实原型模拟了能够积极参与小组讨论的具身协作GenAI智能体。研究发现，如果设计得当，协作GenAI智能体可以通过挑战群体思维、弥合沟通差距和减少社会摩擦来增强团队问题解决能力。然而，团队整合GenAI智能体的意愿取决于其在个人、团队和组织层面的适应性。研究总结了围绕智能体表示、社会突出性和参与度的关键设计张力，并强调了空间和沉浸式技术在调节GenAI对团队成果的影响以及平衡增强和自主性方面的机会。\n",
      "categories": [
        "cs.HC",
        "cs.AI"
      ],
      "primary_category": "cs.HC",
      "comment": "To be published in ACM Conference on Computer-Supported Cooperative\n  Work and Social Computing (CSCW 2025). 33 pages, 11 figures, 1 table",
      "pdf_url": "http://arxiv.org/pdf/2504.14779v1",
      "published_date": "2025-04-21 00:38:02 UTC",
      "updated_date": "2025-04-21 00:38:02 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-04-23T02:27:00.440512"
    },
    {
      "arxiv_id": "2504.14773v1",
      "title": "PLANET: A Collection of Benchmarks for Evaluating LLMs' Planning Capabilities",
      "title_zh": "PLANET：用于评估大型语言模型规划能力的一系列基准测试\n",
      "authors": [
        "Haoming Li",
        "Zhaoliang Chen",
        "Jonathan Zhang",
        "Fei Liu"
      ],
      "abstract": "Planning is central to agents and agentic AI. The ability to plan, e.g.,\ncreating travel itineraries within a budget, holds immense potential in both\nscientific and commercial contexts. Moreover, optimal plans tend to require\nfewer resources compared to ad-hoc methods. To date, a comprehensive\nunderstanding of existing planning benchmarks appears to be lacking. Without\nit, comparing planning algorithms' performance across domains or selecting\nsuitable algorithms for new scenarios remains challenging. In this paper, we\nexamine a range of planning benchmarks to identify commonly used testbeds for\nalgorithm development and highlight potential gaps. These benchmarks are\ncategorized into embodied environments, web navigation, scheduling, games and\npuzzles, and everyday task automation. Our study recommends the most\nappropriate benchmarks for various algorithms and offers insights to guide\nfuture benchmark development.",
      "tldr_zh": "PLANET论文旨在全面评估大型语言模型(LLMs)的规划能力，并填补现有规划基准的不足。该研究整理并分析了一系列规划基准，涵盖具身环境、网页导航、调度、游戏和谜题以及日常任务自动化等多个领域。通过对不同算法在这些基准上的表现进行比较，论文为选择合适的算法提供了指导，并为未来基准的开发提出了建议。该研究强调了规划能力在智能体和智能体人工智能中的核心作用，并旨在推动相关领域的发展。\n",
      "categories": [
        "cs.AI",
        "cs.CL",
        "cs.LG",
        "cs.MA"
      ],
      "primary_category": "cs.AI",
      "comment": "10 pages",
      "pdf_url": "http://arxiv.org/pdf/2504.14773v1",
      "published_date": "2025-04-21 00:02:50 UTC",
      "updated_date": "2025-04-21 00:02:50 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-04-23T02:27:12.322470"
    }
  ],
  "raw_papers_fetched": true,
  "papers_count": 76,
  "processed_papers_count": 76,
  "failed_papers_count": 0,
  "summary_generated": true,
  "daily_data_saved": true,
  "last_update": "2025-04-23T02:28:49.957790"
}