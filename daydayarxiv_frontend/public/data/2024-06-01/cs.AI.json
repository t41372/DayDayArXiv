{
  "date": "2024-06-01",
  "category": "cs.AI",
  "summary": "欢迎来到 UTC 时间 2024-06-01 的 arXiv 中文 TLDR 快报！今天 arXiv 的论文主要聚焦于 AI 模型优化、可解释 AI、LLM（Large Language Models）应用以及医疗和计算机视觉领域的创新，其中令人印象深刻的包括基于 Shapley 值的联邦学习改进（第 3 篇）和 LLM 在故事生成的多样性增强（第 4 篇），以及知名学者如 Eric P. Xing 在因果建模方面的贡献（第 11 篇）。\n\n以下是今日论文的精选摘要，我优先选取了重要、话题性和影响大的文章（如涉及顶级会议或实际应用），并快速掠过较基础或 niche 的内容。每篇论文的标题以“中文 + 英文”形式列出，焦点放在核心贡献和发现上。\n\n### 重点论文讨论\n\n**3. Redefining Contributions: Shapley-Driven Federated Learning**  \n这篇论文（IJCAI 2024）提出了一种名为 ShapFed 的贡献评估方法，使用 Shapley 值从合作博弈理论评估联邦学习中参与者的细粒度贡献，尤其在类别不平衡场景下。核心发现是 ShapFed 的加权聚合方法（如 ShapFed-WA）提升了模型性能和公平性，在 CIFAR-10 和医疗数据集上实验证明其在实用性和效率上优于传统联邦平均算法。\n\n**4. Guiding and Diversifying LLM-Based Story Generation via Answer Set Programming**  \n论文（ACL 2024）探索了如何结合回答集编程（Answer Set Programming, ASP）来指导和多样化 LLM 生成的故事。关键贡献是通过 ASP 提供抽象的故事结构，显著提高了故事多样性，实验显示其在语义相似性分析中优于纯 LLM 方法，适用于生成更灵活和多样的叙事内容。\n\n**9. Breast Cancer Diagnosis: A Comprehensive Exploration of Explainable Artificial Intelligence (XAI) Techniques**  \n这篇聚焦医疗 AI 的论文（涉及 XAI 技术如 SHAP 和 LIME），系统审视了 XAI 在乳腺癌检测中的应用。贡献在于整合 XAI 与深度学习模型（如 CNN），提升诊断准确性和可解释性，实验证明其在乳腺癌数据集上能提供更可靠的个性化治疗方案，强调了 XAI 在临床决策中的潜力。\n\n**11. Learning Discrete Concepts in Latent Hierarchical Models**  \n由知名学者 Eric P. Xing 和 Yuejie Chi 参与的论文（NeurIPS 2024），提出在潜在层次模型中学习离散概念的方法。核心发现是，通过因果建模识别高维数据（如图像）中的抽象层次，实验验证了其在合成数据和扩散模型中的有效性，为理解 AI 模型的隐性机制提供了新视角。\n\n**13. A Survey on Large Language Models for Code Generation**  \n这篇综述（覆盖 LLM 在代码生成的进展）总结了数据处理、模型评估和实际应用，贡献在于构建了一个实用的分类框架和基准（如 HumanEval），实验显示 LLM 在代码任务中的性能持续提升，但也指出了泛化性和大规模任务的挑战，是 LLM 研究者的重要参考。\n\n**25. Towards Trustworthy AI: A Review of Ethical and Robust Large Language Models**  \n论文审视了 LLM 的伦理和鲁棒性问题，强调可解释性和环境影响。贡献在于提出评估框架，实验证明增强伦理机制（如偏置缓解）能提升模型可靠性，适用于风险敏感领域，如医疗和金融。\n\n其他论文如第 2 篇（Amortizing Pragmatic Program Synthesis with Rankings，ICML 2024，优化程序合成效率）和第 15 篇（Prompt Chaining or Stepwise Prompt?，ACL 2024，改进 LLM 摘要精炼）也值得关注，它们通过强化学习和提示策略提升了 AI 生成任务的准确性。\n\n### 快速掠过其他论文\n剩余论文多涉及计算机视觉、强化学习和数据处理等领域，我仅简要提及几篇代表性内容：\n- **第 6 篇：Memory-guided Network with Uncertainty-based Feature Augmentation for Few-shot Semantic Segmentation**（ICME 2024）：通过记忆模块和不确定性增强改善少样本图像分割，贡献在于提升泛化能力。\n- **第 18 篇：Activation-Descent Regularization for Input Optimization of ReLU Networks**（ICML'24）：优化 ReLU 网络的输入，实验显示其在生成建模和强化学习中更稳定。\n- **第 48 篇：HonestLLM: Toward an Honest and Helpful Large Language Model**：提出 LLM 诚实性框架，实验证明其在多数据集上提升了响应可信度。\n- 其他如第 7、12、19、26、54 等论文虽有创新（如知识图谱或无人机应用），但相对基础或特定领域，我仅建议感兴趣读者查看原作。\n\n总之，今天的 arXiv 突显了 AI 向更可靠和应用导向的演进，LLM 和可解释模型是亮点。如果你关注 AI 伦理或医疗应用，别错过这些论文！明天的快报见。",
  "papers": [
    {
      "arxiv_id": "2406.02600v1",
      "title": "Data Quality in Edge Machine Learning: A State-of-the-Art Survey",
      "title_zh": "翻译失败",
      "authors": [
        "Mohammed Djameleddine Belgoumri",
        "Mohamed Reda Bouadjenek",
        "Sunil Aryal",
        "Hakim Hacid"
      ],
      "abstract": "Data-driven Artificial Intelligence (AI) systems trained using Machine\nLearning (ML) are shaping an ever-increasing (in size and importance) portion\nof our lives, including, but not limited to, recommendation systems, autonomous\ndriving technologies, healthcare diagnostics, financial services, and\npersonalized marketing. On the one hand, the outsized influence of these\nsystems imposes a high standard of quality, particularly in the data used to\ntrain them. On the other hand, establishing and maintaining standards of Data\nQuality (DQ) becomes more challenging due to the proliferation of Edge\nComputing and Internet of Things devices, along with their increasing adoption\nfor training and deploying ML models. The nature of the edge environment --\ncharacterized by limited resources, decentralized data storage, and processing\n-- exacerbates data-related issues, making them more frequent, severe, and\ndifficult to detect and mitigate. From these observations, it follows that DQ\nresearch for edge ML is a critical and urgent exploration track for the safety\nand robust usefulness of present and future AI systems. Despite this fact, DQ\nresearch for edge ML is still in its infancy. The literature on this subject\nremains fragmented and scattered across different research communities, with no\ncomprehensive survey to date. Hence, this paper aims to fill this gap by\nproviding a global view of the existing literature from multiple disciplines\nthat can be grouped under the umbrella of DQ for edge ML. Specifically, we\npresent a tentative definition of data quality in Edge computing, which we use\nto establish a set of DQ dimensions. We explore each dimension in detail,\nincluding existing solutions for mitigation.",
      "tldr_zh": "这篇论文对边缘机器学习(Edge Machine Learning)中的数据质量(Data Quality)进行了全面现状调查，强调了数据驱动的AI系统在边缘计算和物联网环境中面临的挑战，如资源有限、数据分散导致的问题更难检测和缓解。作者首先提出一个初步定义，并建立了数据质量的多个维度，包括详细探讨每个维度的现有解决方案。最终，该研究填补了文献空白，为提升AI系统的安全性和鲁棒性提供了关键见解。",
      "categories": [
        "cs.LG",
        "cs.AI",
        "stat.ML"
      ],
      "primary_category": "cs.LG",
      "comment": "31 pages, 5 figures",
      "pdf_url": "http://arxiv.org/pdf/2406.02600v1",
      "published_date": "2024-06-01 23:07:05 UTC",
      "updated_date": "2024-06-01 23:07:05 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-18T14:47:47.442893"
    },
    {
      "arxiv_id": "2407.02499v1",
      "title": "Amortizing Pragmatic Program Synthesis with Rankings",
      "title_zh": "翻译失败",
      "authors": [
        "Yewen Pu",
        "Saujas Vaduguru",
        "Priyan Vaithilingam",
        "Elena Glassman",
        "Daniel Fried"
      ],
      "abstract": "The usage of Rational Speech Acts (RSA) framework has been successful in\nbuilding \\emph{pragmatic} program synthesizers that return programs which, in\naddition to being logically consistent with user-generated examples, account\nfor the fact that a user chooses their examples informatively. We present a\ngeneral method of amortizing the slow, exact RSA synthesizer. Our method first\nquery the exact RSA synthesizer to compile a communication dataset. The dataset\ncontains a number of example-dependent rankings of subsets of programs. It then\ndistills a \\textit{single} global ranking of all programs as an approximation\nto every ranking in the dataset. This global ranking is then used at inference\ntime to rank multiple logically consistent candidate programs generated from a\nfast, non-pragmatic synthesizer. Experiments on two program synthesis domains\nusing our ranking method resulted in orders of magnitudes of speed ups compared\nto the exact RSA synthesizer, while being more accurate than a non-pragmatic\nsynthesizer when communicating with humans. Finally, we prove that in the\nspecial case of synthesis from a single example, this approximation is exact.",
      "tldr_zh": "该论文提出了一种基于排名的方法来加速 Rational Speech Acts (RSA) 框架的实用程序合成器，该方法首先通过查询精确 RSA 合成器编译一个通信数据集，其中包含示例相关的程序子集排名。接着，提炼出一个单一全局排名作为近似，并用于推理时对快速非实用合成器生成的候选程序进行排序。实验在两个程序合成领域显示，这种方法比精确 RSA 合成器快几个数量级，且在与人类沟通时比非实用合成器更准确；此外，论文证明了在从单个示例合成的情况下，这种近似排名是精确的。",
      "categories": [
        "cs.PL",
        "cs.AI"
      ],
      "primary_category": "cs.PL",
      "comment": "icml 2024. This work supersedes and serves as a new version of\n  arXiv:2309.03225",
      "pdf_url": "http://arxiv.org/pdf/2407.02499v1",
      "published_date": "2024-06-01 22:55:33 UTC",
      "updated_date": "2024-06-01 22:55:33 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-18T14:47:58.949977"
    },
    {
      "arxiv_id": "2406.00569v1",
      "title": "Redefining Contributions: Shapley-Driven Federated Learning",
      "title_zh": "重新定义贡献：Shapley驱动的联邦学习",
      "authors": [
        "Nurbek Tastan",
        "Samar Fares",
        "Toluwani Aremu",
        "Samuel Horvath",
        "Karthik Nandakumar"
      ],
      "abstract": "Federated learning (FL) has emerged as a pivotal approach in machine\nlearning, enabling multiple participants to collaboratively train a global\nmodel without sharing raw data. While FL finds applications in various domains\nsuch as healthcare and finance, it is challenging to ensure global model\nconvergence when participants do not contribute equally and/or honestly. To\novercome this challenge, principled mechanisms are required to evaluate the\ncontributions made by individual participants in the FL setting. Existing\nsolutions for contribution assessment rely on general accuracy evaluation,\noften failing to capture nuanced dynamics and class-specific influences. This\npaper proposes a novel contribution assessment method called ShapFed for\nfine-grained evaluation of participant contributions in FL. Our approach uses\nShapley values from cooperative game theory to provide a granular understanding\nof class-specific influences. Based on ShapFed, we introduce a weighted\naggregation method called ShapFed-WA, which outperforms conventional federated\naveraging, especially in class-imbalanced scenarios. Personalizing participant\nupdates based on their contributions further enhances collaborative fairness by\ndelivering differentiated models commensurate with the participant\ncontributions. Experiments on CIFAR-10, Chest X-Ray, and Fed-ISIC2019 datasets\ndemonstrate the effectiveness of our approach in improving utility, efficiency,\nand fairness in FL systems. The code can be found at\nhttps://github.com/tnurbek/shapfed.",
      "tldr_zh": "这篇论文针对 Federated Learning (FL) 中参与者贡献不均等或不诚实导致全局模型收敛困难的问题，提出了一种新型贡献评估方法 ShapFed，利用 Shapley values 来自合作博弈理论来实现细粒度的类特定影响评估。基于 ShapFed，他们开发了 ShapFed-WA 加权聚合方法，能够在类不平衡场景中超越传统 Federated Averaging，并通过个性化参与者更新提升协作公平性。实验结果在 CIFAR-10、Chest X-Ray 和 Fed-ISIC2019 数据集上表明，该方法显著提高了 FL 系统的效用、效率和公平性。",
      "categories": [
        "cs.LG",
        "cs.AI"
      ],
      "primary_category": "cs.LG",
      "comment": "Accepted by IJCAI 2024",
      "pdf_url": "http://arxiv.org/pdf/2406.00569v1",
      "published_date": "2024-06-01 22:40:31 UTC",
      "updated_date": "2024-06-01 22:40:31 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-18T14:48:12.200986"
    },
    {
      "arxiv_id": "2406.00554v2",
      "title": "Guiding and Diversifying LLM-Based Story Generation via Answer Set Programming",
      "title_zh": "翻译失败",
      "authors": [
        "Phoebe J. Wang",
        "Max Kreminski"
      ],
      "abstract": "Instruction-tuned large language models (LLMs) are capable of generating\nstories in response to open-ended user requests, but the resulting stories tend\nto be limited in their diversity. Older, symbolic approaches to story\ngeneration (such as planning) can generate substantially more diverse plot\noutlines, but are limited to producing stories that recombine a fixed set of\nhand-engineered character action templates. Can we combine the strengths of\nthese approaches while mitigating their weaknesses? We propose to do so by\nusing a higher-level and more abstract symbolic specification of high-level\nstory structure -- implemented via answer set programming (ASP) -- to guide and\ndiversify LLM-based story generation. Via semantic similarity analysis, we\ndemonstrate that our approach produces more diverse stories than an unguided\nLLM, and via code excerpts, we demonstrate the improved compactness and\nflexibility of ASP-based outline generation over full-fledged narrative\nplanning.",
      "tldr_zh": "该论文探讨了如何使用Answer Set Programming (ASP)来指导和提升LLM-Based的故事生成，以解决LLM生成的故事多样性不足的问题。研究提出一种方法，通过ASP提供更高层次的抽象符号规范，来生成多样化的故事大纲，并指导LLM进行故事创作。与传统叙事规划相比，这种方法更紧凑和灵活。实验结果显示，通过语义相似性分析，该方法生成的故事比未指导的LLM更具多样性，并通过代码示例证明了其优势。",
      "categories": [
        "cs.CL",
        "cs.AI"
      ],
      "primary_category": "cs.CL",
      "comment": "Accepted to Wordplay @ ACL 2024",
      "pdf_url": "http://arxiv.org/pdf/2406.00554v2",
      "published_date": "2024-06-01 21:14:25 UTC",
      "updated_date": "2024-07-19 22:50:46 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-18T14:48:26.584487"
    },
    {
      "arxiv_id": "2406.00549v2",
      "title": "Zero Inflation as a Missing Data Problem: a Proxy-based Approach",
      "title_zh": "零膨胀作为缺失数据问题：一种基于代理的方法",
      "authors": [
        "Trung Phung",
        "Jaron J. R. Lee",
        "Opeyemi Oladapo-Shittu",
        "Eili Y. Klein",
        "Ayse Pinar Gurses",
        "Susan M. Hannum",
        "Kimberly Weems",
        "Jill A. Marsteller",
        "Sara E. Cosgrove",
        "Sara C. Keller",
        "Ilya Shpitser"
      ],
      "abstract": "A common type of zero-inflated data has certain true values incorrectly\nreplaced by zeros due to data recording conventions (rare outcomes assumed to\nbe absent) or details of data recording equipment (e.g. artificial zeros in\ngene expression data).\n  Existing methods for zero-inflated data either fit the observed data\nlikelihood via parametric mixture models that explicitly represent excess\nzeros, or aim to replace excess zeros by imputed values. If the goal of the\nanalysis relies on knowing true data realizations, a particular challenge with\nzero-inflated data is identifiability, since it is difficult to correctly\ndetermine which observed zeros are real and which are inflated.\n  This paper views zero-inflated data as a general type of missing data\nproblem, where the observability indicator for a potentially censored variable\nis itself unobserved whenever a zero is recorded. We show that, without\nadditional assumptions, target parameters involving a zero-inflated variable\nare not identified. However, if a proxy of the missingness indicator is\nobserved, a modification of the effect restoration approach of Kuroki and Pearl\nallows identification and estimation, given the proxy-indicator relationship is\nknown.\n  If this relationship is unknown, our approach yields a partial identification\nstrategy for sensitivity analysis. Specifically, we show that only certain\nproxy-indicator relationships are compatible with the observed data\ndistribution. We give an analytic bound for this relationship in cases with a\ncategorical outcome, which is sharp in certain models. For more complex cases,\nsharp numerical bounds may be computed using methods in Duarte et al.[2023].\n  We illustrate our method via simulation studies and a data application on\ncentral line-associated bloodstream infections (CLABSIs).",
      "tldr_zh": "这篇论文将 zero-inflated data 视为一种 missing data problem，提出了一种基于 proxy 的方法来处理数据中多余零值的问题，这些零值可能源于记录惯例或设备限制，导致真实值被错误替换。作者修改了 Kuroki 和 Pearl 的效果恢复方法，利用代理变量（proxy）来识别和估计目标参数，前提是 proxy-指示器关系已知；如果关系未知，则提供部分识别策略进行敏感性分析。论文还给出了针对分类结果的分析边界，并在复杂情况下建议使用 Duarte et al. [2023] 的数值方法计算精确边界。通过模拟研究和中央导管相关血流感染（CLABSIs）数据应用，验证了方法的有效性。",
      "categories": [
        "stat.ME",
        "cs.AI"
      ],
      "primary_category": "stat.ME",
      "comment": "28 pages, 8 figues, accepted for the 40th Conference on Uncertainty\n  in Artificial Intelligence (UAI 2024)",
      "pdf_url": "http://arxiv.org/pdf/2406.00549v2",
      "published_date": "2024-06-01 20:21:35 UTC",
      "updated_date": "2024-07-02 12:59:47 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-18T14:48:37.147239"
    },
    {
      "arxiv_id": "2406.00545v2",
      "title": "Memory-guided Network with Uncertainty-based Feature Augmentation for Few-shot Semantic Segmentation",
      "title_zh": "翻译失败",
      "authors": [
        "Xinyue Chen",
        "Miaojing Shi"
      ],
      "abstract": "The performance of supervised semantic segmentation methods highly relies on\nthe availability of large-scale training data. To alleviate this dependence,\nfew-shot semantic segmentation (FSS) is introduced to leverage the model\ntrained on base classes with sufficient data into the segmentation of novel\nclasses with few data. FSS methods face the challenge of model generalization\non novel classes due to the distribution shift between base and novel classes.\nTo overcome this issue, we propose a class-shared memory (CSM) module\nconsisting of a set of learnable memory vectors. These memory vectors learn\nelemental object patterns from base classes during training whilst re-encoding\nquery features during both training and inference, thereby improving the\ndistribution alignment between base and novel classes. Furthermore, to cope\nwith the performance degradation resulting from the intra-class variance across\nimages, we introduce an uncertainty-based feature augmentation (UFA) module to\nproduce diverse query features during training for improving the model's\nrobustness. We integrate CSM and UFA into representative FSS works, with\nexperimental results on the widely-used PASCAL-5$^i$ and COCO-20$^i$ datasets\ndemonstrating the superior performance of ours over state of the art.",
      "tldr_zh": "这篇论文针对Few-shot Semantic Segmentation (FSS)的问题，提出了一种记忆引导网络，以缓解模型在基类和新类之间分布偏移的挑战。论文引入了class-shared memory (CSM)模块，使用可学习的记忆向量从基类学习对象模式并重新编码查询特征，从而改善特征分布对齐；同时，uncertainty-based feature augmentation (UFA)模块通过生成多样化的查询特征来增强模型的鲁棒性，应对图像间的类内变异。实验结果显示，在PASCAL-5^i和COCO-20^i数据集上，该方法集成到代表性FSS框架后，性能优于现有最先进技术。",
      "categories": [
        "cs.CV",
        "cs.AI"
      ],
      "primary_category": "cs.CV",
      "comment": "Accepted to IEEE International Conference on Multimedia and Expo\n  (ICME) 2024 as an oral presentation",
      "pdf_url": "http://arxiv.org/pdf/2406.00545v2",
      "published_date": "2024-06-01 19:53:25 UTC",
      "updated_date": "2024-06-09 22:50:22 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-18T14:48:48.784567"
    },
    {
      "arxiv_id": "2406.00544v1",
      "title": "Leveraging Knowlegde Graphs for Interpretable Feature Generation",
      "title_zh": "翻译失败",
      "authors": [
        "Mohamed Bouadi",
        "Arta Alavi",
        "Salima Benbernou",
        "Mourad Ouziri"
      ],
      "abstract": "The quality of Machine Learning (ML) models strongly depends on the input\ndata, as such Feature Engineering (FE) is often required in ML. In addition,\nwith the proliferation of ML-powered systems, especially in critical contexts,\nthe need for interpretability and explainability becomes increasingly\nimportant. Since manual FE is time-consuming and requires case specific\nknowledge, we propose KRAFT, an AutoFE framework that leverages a knowledge\ngraph to guide the generation of interpretable features. Our hybrid AI approach\ncombines a neural generator to transform raw features through a series of\ntransformations and a knowledge-based reasoner to evaluate features\ninterpretability using Description Logics (DL). The generator is trained\nthrough Deep Reinforcement Learning (DRL) to maximize the prediction accuracy\nand the interpretability of the generated features. Extensive experiments on\nreal datasets demonstrate that KRAFT significantly improves accuracy while\nensuring a high level of interpretability.",
      "tldr_zh": "该研究提出 KRAFT 框架，一种自动特征工程 (AutoFE) 方法，利用 Knowledge Graphs 指导生成可解释特征，以解决手动特征工程耗时且依赖特定知识的问题。KRAFT 结合神经生成器进行原始特征的转换，以及基于知识的推理器使用 Description Logics (DL) 评估特征可解释性；生成器通过 Deep Reinforcement Learning (DRL) 训练，以最大化预测准确性和可解释性。在真实数据集上的广泛实验表明，KRAFT 显著提高了模型准确性，同时确保了高水平的可解释性。",
      "categories": [
        "cs.LG",
        "cs.AI"
      ],
      "primary_category": "cs.LG",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2406.00544v1",
      "published_date": "2024-06-01 19:51:29 UTC",
      "updated_date": "2024-06-01 19:51:29 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-18T14:49:09.427643"
    },
    {
      "arxiv_id": "2406.00537v1",
      "title": "Towards an ontology of portions of matter to support multi-scale analysis and provenance tracking",
      "title_zh": "翻译失败",
      "authors": [
        "Lucas Valadares Vieira",
        "Mara Abel",
        "Fabricio Henrique Rodrigues",
        "Tiago Prince Sales",
        "Claudenir M. Fonseca"
      ],
      "abstract": "This paper presents an ontology of portions of matter with practical\nimplications across scientific and industrial domains. The ontology is\ndeveloped under the Unified Foundational Ontology (UFO), which uses the concept\nof quantity to represent topologically maximally self-connected portions of\nmatter. The proposed ontology introduces the granuleOf parthood relation,\nholding between objects and portions of matter. It also discusses the\nconstitution of quantities by collections of granules, the representation of\nsub-portions of matter, and the tracking of matter provenance between\nquantities using historical relations. Lastly, a case study is presented to\ndemonstrate the use of the portion of matter ontology in the geology domain for\nan Oil & Gas industry application. In the case study, we model how to represent\nthe historical relation between an original portion of rock and the\nsub-portions created during the industrial process. Lastly, future research\ndirections are outlined, including investigating granularity levels and\ndefining a taxonomy of events.",
      "tldr_zh": "本研究提出了一种基于 Unified Foundational Ontology (UFO) 的物质部分本体论，用于支持多尺度分析和物质来源跟踪。该本体论使用 quantity 概念来表示拓扑上最大自连通的物质部分，并引入 granuleOf parthood relation 来描述对象与物质部分之间的关系，同时探讨物质子部分表示和历史关系跟踪。案例研究在石油和天然气行业的地质领域展示了如何建模原始岩石部分与工业过程产生的子部分之间的历史联系。未来研究将探讨粒度级别和事件分类的 taxonomy，以进一步扩展该本体论的应用。",
      "categories": [
        "cs.AI",
        "I.2.4"
      ],
      "primary_category": "cs.AI",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2406.00537v1",
      "published_date": "2024-06-01 19:26:21 UTC",
      "updated_date": "2024-06-01 19:26:21 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-18T14:49:11.315694"
    },
    {
      "arxiv_id": "2406.00532v1",
      "title": "Breast Cancer Diagnosis: A Comprehensive Exploration of Explainable Artificial Intelligence (XAI) Techniques",
      "title_zh": "乳腺癌诊断：可解释人工智能（XAI）技术的全面探索",
      "authors": [
        "Samita Bai",
        "Sidra Nasir",
        "Rizwan Ahmed Khan",
        "Sheeraz Arif",
        "Alexandre Meyer",
        "Hubert Konik"
      ],
      "abstract": "Breast cancer (BC) stands as one of the most common malignancies affecting\nwomen worldwide, necessitating advancements in diagnostic methodologies for\nbetter clinical outcomes. This article provides a comprehensive exploration of\nthe application of Explainable Artificial Intelligence (XAI) techniques in the\ndetection and diagnosis of breast cancer. As Artificial Intelligence (AI)\ntechnologies continue to permeate the healthcare sector, particularly in\noncology, the need for transparent and interpretable models becomes imperative\nto enhance clinical decision-making and patient care. This review discusses the\nintegration of various XAI approaches, such as SHAP, LIME, Grad-CAM, and\nothers, with machine learning and deep learning models utilized in breast\ncancer detection and classification. By investigating the modalities of breast\ncancer datasets, including mammograms, ultrasounds and their processing with\nAI, the paper highlights how XAI can lead to more accurate diagnoses and\npersonalized treatment plans. It also examines the challenges in implementing\nthese techniques and the importance of developing standardized metrics for\nevaluating XAI's effectiveness in clinical settings. Through detailed analysis\nand discussion, this article aims to highlight the potential of XAI in bridging\nthe gap between complex AI models and practical healthcare applications,\nthereby fostering trust and understanding among medical professionals and\nimproving patient outcomes.",
      "tldr_zh": "这篇论文全面探讨了可解释人工智能 (XAI) 技术在乳腺癌诊断中的应用，旨在提升临床决策和患者护理，以应对这一常见女性恶性肿瘤的挑战。论文回顾了多种 XAI 方法，如 SHAP、LIME 和 Grad-CAM，与机器学习和深度学习模型的整合，用于处理乳腺癌数据集（如乳房X光和超声），从而实现更准确的检测、分类和个性化治疗计划。研究强调了 XAI 在桥接复杂 AI 模型与实际医疗应用方面的潜力，同时分析了实施这些技术的障碍，如标准化评估指标的缺失。最终，该综述有助于在医疗领域增强对 AI 的信任，提高患者预后。",
      "categories": [
        "cs.AI",
        "cs.LG"
      ],
      "primary_category": "cs.AI",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2406.00532v1",
      "published_date": "2024-06-01 18:50:03 UTC",
      "updated_date": "2024-06-01 18:50:03 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-18T14:49:24.640832"
    },
    {
      "arxiv_id": "2406.02599v1",
      "title": "Privacy-Aware Randomized Quantization via Linear Programming",
      "title_zh": "翻译失败",
      "authors": [
        "Zhongteng Cai",
        "Xueru Zhang",
        "Mohammad Mahdi Khalili"
      ],
      "abstract": "Differential privacy mechanisms such as the Gaussian or Laplace mechanism\nhave been widely used in data analytics for preserving individual privacy.\nHowever, they are mostly designed for continuous outputs and are unsuitable for\nscenarios where discrete values are necessary. Although various quantization\nmechanisms were proposed recently to generate discrete outputs under\ndifferential privacy, the outcomes are either biased or have an inferior\naccuracy-privacy trade-off. In this paper, we propose a family of quantization\nmechanisms that is unbiased and differentially private. It has a high degree of\nfreedom and we show that some existing mechanisms can be considered as special\ncases of ours. To find the optimal mechanism, we formulate a linear\noptimization that can be solved efficiently using linear programming tools.\nExperiments show that our proposed mechanism can attain a better\nprivacy-accuracy trade-off compared to baselines.",
      "tldr_zh": "这篇论文针对差分隐私（Differential Privacy）机制在离散输出场景中的不足，提出了一种无偏的量化机制家族，以解决现有量化机制的偏差问题和准确性-隐私权衡的劣势。该机制具有高自由度，并将一些现有机制视为其特例，通过线性规划（Linear Programming）优化来找到最优方案。实验结果显示，该机制在隐私-准确性权衡上比基线方法表现出色。",
      "categories": [
        "cs.CR",
        "cs.AI"
      ],
      "primary_category": "cs.CR",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2406.02599v1",
      "published_date": "2024-06-01 18:40:08 UTC",
      "updated_date": "2024-06-01 18:40:08 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-18T14:49:34.812978"
    },
    {
      "arxiv_id": "2406.00519v2",
      "title": "Learning Discrete Concepts in Latent Hierarchical Models",
      "title_zh": "在潜在层次模型中学习离散概念",
      "authors": [
        "Lingjing Kong",
        "Guangyi Chen",
        "Biwei Huang",
        "Eric P. Xing",
        "Yuejie Chi",
        "Kun Zhang"
      ],
      "abstract": "Learning concepts from natural high-dimensional data (e.g., images) holds\npotential in building human-aligned and interpretable machine learning models.\nDespite its encouraging prospect, formalization and theoretical insights into\nthis crucial task are still lacking. In this work, we formalize concepts as\ndiscrete latent causal variables that are related via a hierarchical causal\nmodel that encodes different abstraction levels of concepts embedded in\nhigh-dimensional data (e.g., a dog breed and its eye shapes in natural images).\nWe formulate conditions to facilitate the identification of the proposed causal\nmodel, which reveals when learning such concepts from unsupervised data is\npossible. Our conditions permit complex causal hierarchical structures beyond\nlatent trees and multi-level directed acyclic graphs in prior work and can\nhandle high-dimensional, continuous observed variables, which is well-suited\nfor unstructured data modalities such as images. We substantiate our\ntheoretical claims with synthetic data experiments. Further, we discuss our\ntheory's implications for understanding the underlying mechanisms of latent\ndiffusion models and provide corresponding empirical evidence for our\ntheoretical insights.",
      "tldr_zh": "本研究形式化了从自然高维数据（如图像）中学习离散概念的问题，将概念定义为离散的潜在因果变量，并通过一个分层因果模型（hierarchical causal model）编码不同抽象级别的概念。论文制定了识别该模型的条件，允许处理复杂结构（如超越潜在树和多级有向无环图）并适用于高维连续观察变量，从而实现从无监督数据中学习概念。实验使用合成数据验证了这些理论主张，并探讨了其对理解潜在扩散模型（latent diffusion models）的启示，提供相应的实证证据。",
      "categories": [
        "cs.LG",
        "cs.AI",
        "stat.ML"
      ],
      "primary_category": "cs.LG",
      "comment": "NeurIPS 2024",
      "pdf_url": "http://arxiv.org/pdf/2406.00519v2",
      "published_date": "2024-06-01 18:01:03 UTC",
      "updated_date": "2025-01-14 20:44:45 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-18T14:49:47.495807"
    },
    {
      "arxiv_id": "2406.00518v1",
      "title": "Learning to Play Air Hockey with Model-Based Deep Reinforcement Learning",
      "title_zh": "翻译失败",
      "authors": [
        "Andrej Orsula"
      ],
      "abstract": "In the context of addressing the Robot Air Hockey Challenge 2023, we\ninvestigate the applicability of model-based deep reinforcement learning to\nacquire a policy capable of autonomously playing air hockey. Our agents learn\nsolely from sparse rewards while incorporating self-play to iteratively refine\ntheir behaviour over time. The robotic manipulator is interfaced using\ncontinuous high-level actions for position-based control in the Cartesian plane\nwhile having partial observability of the environment with stochastic\ntransitions. We demonstrate that agents are prone to overfitting when trained\nsolely against a single playstyle, highlighting the importance of self-play for\ngeneralization to novel strategies of unseen opponents. Furthermore, the impact\nof the imagination horizon is explored in the competitive setting of the highly\ndynamic game of air hockey, with longer horizons resulting in more stable\nlearning and better overall performance.",
      "tldr_zh": "本研究针对Robot Air Hockey Challenge 2023，探索了基于模型的深度强化学习（model-based deep reinforcement learning）来训练代理自主玩空气曲棍球。代理从稀疏奖励中学习，并通过自对弈（self-play）迭代改进行为，以应对机器人机械臂的连续高级动作控制和环境的部分可观察性与随机转移。结果显示，仅针对单一玩法训练易导致过拟合，而自对弈有助于代理泛化到未见对手的策略；此外，延长想象视野（imagination horizon）可提升学习稳定性并改善整体性能。",
      "categories": [
        "cs.RO",
        "cs.AI",
        "cs.LG"
      ],
      "primary_category": "cs.RO",
      "comment": "Robot Air Hockey Challenge 2023 | The source code is available at\n  https://github.com/AndrejOrsula/drl_air_hockey",
      "pdf_url": "http://arxiv.org/pdf/2406.00518v1",
      "published_date": "2024-06-01 18:00:01 UTC",
      "updated_date": "2024-06-01 18:00:01 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-18T14:50:02.572576"
    },
    {
      "arxiv_id": "2406.00515v2",
      "title": "A Survey on Large Language Models for Code Generation",
      "title_zh": "大型语言模型用于代码生成的综述",
      "authors": [
        "Juyong Jiang",
        "Fan Wang",
        "Jiasi Shen",
        "Sungju Kim",
        "Sunghun Kim"
      ],
      "abstract": "Large Language Models (LLMs) have garnered remarkable advancements across\ndiverse code-related tasks, known as Code LLMs, particularly in code generation\nthat generates source code with LLM from natural language descriptions. This\nburgeoning field has captured significant interest from both academic\nresearchers and industry professionals due to its practical significance in\nsoftware development, e.g., GitHub Copilot. Despite the active exploration of\nLLMs for a variety of code tasks, either from the perspective of natural\nlanguage processing (NLP) or software engineering (SE) or both, there is a\nnoticeable absence of a comprehensive and up-to-date literature review\ndedicated to LLM for code generation. In this survey, we aim to bridge this gap\nby providing a systematic literature review that serves as a valuable reference\nfor researchers investigating the cutting-edge progress in LLMs for code\ngeneration. We introduce a taxonomy to categorize and discuss the recent\ndevelopments in LLMs for code generation, covering aspects such as data\ncuration, latest advances, performance evaluation, ethical implications,\nenvironmental impact, and real-world applications. In addition, we present a\nhistorical overview of the evolution of LLMs for code generation and offer an\nempirical comparison using the HumanEval, MBPP, and BigCodeBench benchmarks\nacross various levels of difficulty and types of programming tasks to highlight\nthe progressive enhancements in LLM capabilities for code generation. We\nidentify critical challenges and promising opportunities regarding the gap\nbetween academia and practical development. Furthermore, we have established a\ndedicated resource GitHub page (https://github.com/juyongjiang/CodeLLMSurvey)\nto continuously document and disseminate the most recent advances in the field.",
      "tldr_zh": "这篇调查论文综述了大型语言模型 (LLMs) 在代码生成任务中的进展，填补了现有文献的空白，通过引入一个分类法来系统讨论数据整理、最新进展、性能评估、伦理影响、环境影响以及实际应用。作者提供了LLMs在代码生成的历史概述，并使用HumanEval、MBPP和BigCodeBench基准进行实证比较，展示了模型能力的逐步提升。论文识别了学术研究与实际开发之间的关键挑战和机遇，并建立了一个专用GitHub页面（https://github.com/juyongjiang/CodeLLMSurvey）来持续跟踪领域动态。",
      "categories": [
        "cs.CL",
        "cs.AI",
        "cs.SE"
      ],
      "primary_category": "cs.CL",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2406.00515v2",
      "published_date": "2024-06-01 17:48:15 UTC",
      "updated_date": "2024-11-10 22:02:27 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-18T14:50:12.954955"
    },
    {
      "arxiv_id": "2406.00509v1",
      "title": "Empirical influence functions to understand the logic of fine-tuning",
      "title_zh": "翻译失败",
      "authors": [
        "Jordan K. Matelsky",
        "Lyle Ungar",
        "Konrad P. Kording"
      ],
      "abstract": "Understanding the process of learning in neural networks is crucial for\nimproving their performance and interpreting their behavior. This can be\napproximately understood by asking how a model's output is influenced when we\nfine-tune on a new training sample. There are desiderata for such influences,\nsuch as decreasing influence with semantic distance, sparseness, noise\ninvariance, transitive causality, and logical consistency. Here we use the\nempirical influence measured using fine-tuning to demonstrate how individual\ntraining samples affect outputs. We show that these desiderata are violated for\nboth for simple convolutional networks and for a modern LLM. We also illustrate\nhow prompting can partially rescue this failure. Our paper presents an\nefficient and practical way of quantifying how well neural networks learn from\nfine-tuning stimuli. Our results suggest that popular models cannot generalize\nor perform logic in the way they appear to.",
      "tldr_zh": "这篇论文使用经验影响函数(empirical influence)来分析神经网络在 fine-tuning 过程中的学习逻辑，旨在评估训练样本对模型输出变化的影响。作者检查了几个期望特性，包括影响随语义距离减少、稀疏性、噪声不变性、传递因果性和逻辑一致性，结果显示这些特性在简单卷积网络和现代 LLM 中均被违反。论文还发现，通过 prompting 可以部分缓解这些问题，并提供了一种高效方法来量化神经网络的 fine-tuning 效果，最终质疑流行模型的泛化和逻辑性能。",
      "categories": [
        "cs.LG",
        "cs.AI"
      ],
      "primary_category": "cs.LG",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2406.00509v1",
      "published_date": "2024-06-01 17:31:06 UTC",
      "updated_date": "2024-06-01 17:31:06 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-18T14:50:23.407568"
    },
    {
      "arxiv_id": "2406.00507v1",
      "title": "Prompt Chaining or Stepwise Prompt? Refinement in Text Summarization",
      "title_zh": "翻译失败",
      "authors": [
        "Shichao Sun",
        "Ruifeng Yuan",
        "Ziqiang Cao",
        "Wenjie Li",
        "Pengfei Liu"
      ],
      "abstract": "Large language models (LLMs) have demonstrated the capacity to improve\nsummary quality by mirroring a human-like iterative process of critique and\nrefinement starting from the initial draft. Two strategies are designed to\nperform this iterative process: Prompt Chaining and Stepwise Prompt. Prompt\nchaining orchestrates the drafting, critiquing, and refining phases through a\nseries of three discrete prompts, while Stepwise prompt integrates these phases\nwithin a single prompt. However, the relative effectiveness of the two methods\nhas not been extensively studied. This paper is dedicated to examining and\ncomparing these two methods in the context of text summarization to ascertain\nwhich method stands out as the most effective. Experimental results show that\nthe prompt chaining method can produce a more favorable outcome. This might be\nbecause stepwise prompt might produce a simulated refinement process according\nto our various experiments. Since refinement is adaptable to diverse tasks, our\nconclusions have the potential to be extrapolated to other applications,\nthereby offering insights that may contribute to the broader development of\nLLMs.",
      "tldr_zh": "本研究比较了两种基于大型语言模型 (LLMs) 的文本摘要策略：Prompt Chaining 和 Stepwise Prompt，前者通过三个离散的提示分别处理起草、批评和完善阶段，而后者则将这些阶段整合到一个提示中。实验结果显示，Prompt Chaining 方法在摘要质量上更具优势，可能因为 Stepwise Prompt 仅模拟了完善过程，而非真实迭代。研究结论表明，这种精炼方法适用于多种任务，有助于推动 LLMs 在更广泛应用中的发展。",
      "categories": [
        "cs.CL",
        "cs.AI"
      ],
      "primary_category": "cs.CL",
      "comment": "Accepted to Findings of ACL 2024",
      "pdf_url": "http://arxiv.org/pdf/2406.00507v1",
      "published_date": "2024-06-01 17:28:38 UTC",
      "updated_date": "2024-06-01 17:28:38 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-18T14:50:35.556746"
    },
    {
      "arxiv_id": "2406.00504v2",
      "title": "Research on an Autonomous UAV Search and Rescue System Based on the Improved",
      "title_zh": "翻译失败",
      "authors": [
        "Haobin Chen",
        "Junyu Tao",
        "Bize Zhou",
        "Xiaoyan Liu"
      ],
      "abstract": "The demand is to solve the issue of UAV (unmanned aerial vehicle) operating\nautonomously and implementing practical functions such as search and rescue in\ncomplex unknown environments. This paper proposes an autonomous search and\nrescue UAV system based on an EGO-Planner algorithm, which is improved by\ninnovative UAV body application and takes the methods of inverse motor\nbackstepping to enhance the overall flight efficiency of the UAV and\nminiaturization of the whole machine. At the same time, the system introduced\nthe EGO-Planner planning tool, which is optimized by a bidirectional A*\nalgorithm along with an object detection algorithm. It solves the issue of\nintelligent obstacle avoidance and search and rescue. Through the simulation\nand field verification work, and compared with traditional algorithms, this\nmethod shows more efficiency and reliability in the task. In addition, due to\nthe existing algorithm's improved robustness, this application shows good\nprospection.",
      "tldr_zh": "这篇论文针对无人机（UAV）在复杂未知环境中的自主操作和搜索救援问题，提出了一种基于改进 EGO-Planner 算法的自主系统。该系统通过逆向电机 backstepping 方法提升飞行效率和无人机小型化，并结合双向 A* 算法与 object detection 算法，实现智能避障和搜索救援功能。与传统算法相比，实验模拟和实地验证显示，该方法在任务效率和可靠性上表现出色，并增强了算法的鲁棒性，具有良好的应用前景。",
      "categories": [
        "cs.RO",
        "cs.AI"
      ],
      "primary_category": "cs.RO",
      "comment": "2024 5th International Conference on Computer Engineering and\n  Application",
      "pdf_url": "http://arxiv.org/pdf/2406.00504v2",
      "published_date": "2024-06-01 17:25:29 UTC",
      "updated_date": "2024-06-07 07:00:52 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-18T14:50:47.746555"
    },
    {
      "arxiv_id": "2406.00497v2",
      "title": "Recent Advances in End-to-End Simultaneous Speech Translation",
      "title_zh": "翻译失败",
      "authors": [
        "Xiaoqian Liu",
        "Guoqiang Hu",
        "Yangfan Du",
        "Erfeng He",
        "Yingfeng Luo",
        "Chen Xu",
        "Tong Xiao",
        "Jingbo Zhu"
      ],
      "abstract": "Simultaneous speech translation (SimulST) is a demanding task that involves\ngenerating translations in real-time while continuously processing speech\ninput. This paper offers a comprehensive overview of the recent developments in\nSimulST research, focusing on four major challenges. Firstly, the complexities\nassociated with processing lengthy and continuous speech streams pose\nsignificant hurdles. Secondly, satisfying real-time requirements presents\ninherent difficulties due to the need for immediate translation output.\nThirdly, striking a balance between translation quality and latency constraints\nremains a critical challenge. Finally, the scarcity of annotated data adds\nanother layer of complexity to the task. Through our exploration of these\nchallenges and the proposed solutions, we aim to provide valuable insights into\nthe current landscape of SimulST research and suggest promising directions for\nfuture exploration.",
      "tldr_zh": "这篇论文综述了端到端同时语音翻译（SimulST）的最新进展，聚焦于实时处理语音输入并生成翻译的核心挑战，包括处理冗长连续语音流的复杂性、满足实时输出要求、在翻译质量与延迟约束间平衡，以及标注数据稀缺的问题。通过探索这些挑战及其解决方案，论文提供了对SimulST研究现状的宝贵见解，并提出了未来研究的方向，以推动该领域的创新发展。",
      "categories": [
        "cs.SD",
        "cs.AI",
        "cs.CL",
        "eess.AS"
      ],
      "primary_category": "cs.SD",
      "comment": "Accepted by IJCAI 2024",
      "pdf_url": "http://arxiv.org/pdf/2406.00497v2",
      "published_date": "2024-06-01 16:56:19 UTC",
      "updated_date": "2024-08-20 07:47:49 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-18T14:51:02.897022"
    },
    {
      "arxiv_id": "2406.00494v1",
      "title": "Activation-Descent Regularization for Input Optimization of ReLU Networks",
      "title_zh": "翻译失败",
      "authors": [
        "Hongzhan Yu",
        "Sicun Gao"
      ],
      "abstract": "We present a new approach for input optimization of ReLU networks that\nexplicitly takes into account the effect of changes in activation patterns. We\nanalyze local optimization steps in both the input space and the space of\nactivation patterns to propose methods with superior local descent properties.\nTo accomplish this, we convert the discrete space of activation patterns into\ndifferentiable representations and propose regularization terms that improve\neach descent step. Our experiments demonstrate the effectiveness of the\nproposed input-optimization methods for improving the state-of-the-art in\nvarious areas, such as adversarial learning, generative modeling, and\nreinforcement learning.",
      "tldr_zh": "这篇论文提出了一种名为 Activation-Descent Regularization 的新方法，用于优化 ReLU 网络的输入，该方法显式考虑激活 patterns 的变化影响。研究者通过分析输入空间和激活 patterns 空间的局部优化步骤，将离散的激活 patterns 空间转换为可微表示，并引入正则化 terms 来提升每个下降步骤的性能。实验结果显示，该方法在对抗学习 (adversarial learning)、生成建模 (generative modeling) 和强化学习 (reinforcement learning) 等领域显著提高了现有技术的状态-of-the-art 水平。",
      "categories": [
        "cs.LG",
        "cs.AI"
      ],
      "primary_category": "cs.LG",
      "comment": "ICML'24 Proceedings",
      "pdf_url": "http://arxiv.org/pdf/2406.00494v1",
      "published_date": "2024-06-01 16:46:46 UTC",
      "updated_date": "2024-06-01 16:46:46 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-18T14:51:11.647056"
    },
    {
      "arxiv_id": "2406.00490v2",
      "title": "Research on the Application of Computer Vision Based on Deep Learning in Autonomous Driving Technology",
      "title_zh": "基于深度学习的计算机视觉在自动驾驶技术中的应用研究",
      "authors": [
        "Jingyu Zhang",
        "Jin Cao",
        "Jinghao Chang",
        "Xinjin Li",
        "Houze Liu",
        "Zhenglin Li"
      ],
      "abstract": "This research aims to explore the application of deep learning in autonomous\ndriving computer vision technology and its impact on improving system\nperformance. By using advanced technologies such as convolutional neural\nnetworks (CNN), multi-task joint learning methods, and deep reinforcement\nlearning, this article analyzes in detail the application of deep learning in\nimage recognition, real-time target tracking and classification, environment\nperception and decision support, and path planning and navigation. Application\nprocess in key areas. Research results show that the proposed system has an\naccuracy of over 98% in image recognition, target tracking and classification,\nand also demonstrates efficient performance and practicality in environmental\nperception and decision support, path planning and navigation. The conclusion\npoints out that deep learning technology can significantly improve the accuracy\nand real-time response capabilities of autonomous driving systems. Although\nthere are still challenges in environmental perception and decision support,\nwith the advancement of technology, it is expected to achieve wider\napplications and greater capabilities in the future. potential.",
      "tldr_zh": "本研究探讨了基于深度学习的计算机视觉在自动驾驶技术中的应用，重点使用了卷积神经网络(CNN)、多任务联合学习和深度强化学习等先进技术。论文详细分析了这些方法在图像识别、实时目标跟踪和分类、环境感知与决策支持、路径规划和导航等关键领域的应用过程。研究结果显示，该系统在图像识别和目标跟踪方面准确率超过98%，显著提升了自动驾驶系统的准确性和实时响应能力；尽管环境感知与决策支持仍面临挑战，但未来技术进步有望实现更广泛的应用。",
      "categories": [
        "cs.CV",
        "cs.AI"
      ],
      "primary_category": "cs.CV",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2406.00490v2",
      "published_date": "2024-06-01 16:41:24 UTC",
      "updated_date": "2024-06-04 03:15:41 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-18T14:51:22.705216"
    },
    {
      "arxiv_id": "2406.00487v1",
      "title": "Optimistic Rates for Learning from Label Proportions",
      "title_zh": "从标签比例学习中的乐观速率",
      "authors": [
        "Gene Li",
        "Lin Chen",
        "Adel Javanmard",
        "Vahab Mirrokni"
      ],
      "abstract": "We consider a weakly supervised learning problem called Learning from Label\nProportions (LLP), where examples are grouped into ``bags'' and only the\naverage label within each bag is revealed to the learner. We study various\nlearning rules for LLP that achieve PAC learning guarantees for classification\nloss. We establish that the classical Empirical Proportional Risk Minimization\n(EPRM) learning rule (Yu et al., 2014) achieves fast rates under realizability,\nbut EPRM and similar proportion matching learning rules can fail in the\nagnostic setting. We also show that (1) a debiased proportional square loss, as\nwell as (2) a recently proposed EasyLLP learning rule (Busa-Fekete et al.,\n2023) both achieve ``optimistic rates'' (Panchenko, 2002); in both the\nrealizable and agnostic settings, their sample complexity is optimal (up to log\nfactors) in terms of $\\epsilon, \\delta$, and VC dimension.",
      "tldr_zh": "这篇论文研究了弱监督学习问题 Learning from Label Proportions (LLP)，其中样本被分组为“bags”，仅提供每个袋子的平均标签，并探讨了各种学习规则以实现 PAC learning 保证。作者发现经典的 Empirical Proportional Risk Minimization (EPRM) 在 realizable 条件下能实现快速收敛率，但可能在 agnostic 条件下失败。同时，他们证明 debiased proportional square loss 和 EasyLLP 学习规则都能达到 optimistic rates，在 realizable 和 agnostic 设置下，样本复杂度在 ε, δ 和 VC dimension 方面是最优的（考虑对数因子）。这项工作为 LLP 问题提供了更可靠的学习框架。",
      "categories": [
        "cs.LG",
        "cs.AI",
        "stat.ML"
      ],
      "primary_category": "cs.LG",
      "comment": "Accepted to COLT 2024. Comments welcome",
      "pdf_url": "http://arxiv.org/pdf/2406.00487v1",
      "published_date": "2024-06-01 16:36:40 UTC",
      "updated_date": "2024-06-01 16:36:40 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-18T14:51:37.259539"
    },
    {
      "arxiv_id": "2406.02598v1",
      "title": "Towards Learning Foundation Models for Heuristic Functions to Solve Pathfinding Problems",
      "title_zh": "翻译失败",
      "authors": [
        "Vedant Khandelwal",
        "Amit Sheth",
        "Forest Agostinelli"
      ],
      "abstract": "Pathfinding problems are found throughout robotics, computational science,\nand natural sciences. Traditional methods to solve these require training deep\nneural networks (DNNs) for each new problem domain, consuming substantial time\nand resources. This study introduces a novel foundation model, leveraging deep\nreinforcement learning to train heuristic functions that seamlessly adapt to\nnew domains without further fine-tuning. Building upon DeepCubeA, we enhance\nthe model by providing the heuristic function with the domain's state\ntransition information, improving its adaptability. Utilizing a puzzle\ngenerator for the 15-puzzle action space variation domains, we demonstrate our\nmodel's ability to generalize and solve unseen domains. We achieve a strong\ncorrelation between learned and ground truth heuristic values across various\ndomains, as evidenced by robust R-squared and Concordance Correlation\nCoefficient metrics. These results underscore the potential of foundation\nmodels to establish new standards in efficiency and adaptability for AI-driven\nsolutions in complex pathfinding problems.",
      "tldr_zh": "本研究针对路径寻找问题（如在机器人和计算科学中的应用），提出了一种新型基础模型，通过深度强化学习（deep reinforcement learning）训练启发式函数，使其无需进一步微调即可适应新领域，从而克服传统深度神经网络（DNNs）需为每个领域重新训练的局限性。基于 DeepCubeA 的改进，该模型向启发式函数提供状态转换信息，并使用 15-拼图动作空间变体进行测试，展示了其在未见领域的泛化能力。实验结果显示，学习到的启发式值与真实值之间具有很强的相关性，R-squared 和 Concordance Correlation Coefficient 指标均表现出色，证明了基础模型在提升路径寻找问题的效率和适应性方面的潜力。",
      "categories": [
        "cs.LG",
        "cs.AI"
      ],
      "primary_category": "cs.LG",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2406.02598v1",
      "published_date": "2024-06-01 16:18:20 UTC",
      "updated_date": "2024-06-01 16:18:20 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-18T14:51:50.954021"
    },
    {
      "arxiv_id": "2406.00473v1",
      "title": "Pedestrian intention prediction in Adverse Weather Conditions with Spiking Neural Networks and Dynamic Vision Sensors",
      "title_zh": "在恶劣天气条件下使用脉冲神经网络和动态视觉传感器的行人",
      "authors": [
        "Mustafa Sakhai",
        "Szymon Mazurek",
        "Jakub Caputa",
        "Jan K. Argasiński",
        "Maciej Wielgosz"
      ],
      "abstract": "This study examines the effectiveness of Spiking Neural Networks (SNNs)\npaired with Dynamic Vision Sensors (DVS) to improve pedestrian detection in\nadverse weather, a significant challenge for autonomous vehicles. Utilizing the\nhigh temporal resolution and low latency of DVS, which excels in dynamic,\nlow-light, and high-contrast environments, we assess the efficiency of SNNs\ncompared to traditional Convolutional Neural Networks (CNNs).\n  Our experiments involved testing across diverse weather scenarios using a\ncustom dataset from the CARLA simulator, mirroring real-world variability. SNN\nmodels, enhanced with Temporally Effective Batch Normalization, were trained\nand benchmarked against state-of-the-art CNNs to demonstrate superior accuracy\nand computational efficiency in complex conditions such as rain and fog.\n  The results indicate that SNNs, integrated with DVS, significantly reduce\ncomputational overhead and improve detection accuracy in challenging conditions\ncompared to CNNs. This highlights the potential of DVS combined with\nbio-inspired SNN processing to enhance autonomous vehicle perception and\ndecision-making systems, advancing intelligent transportation systems' safety\nfeatures in varying operational environments.\n  Additionally, our research indicates that SNNs perform more efficiently in\nhandling long perception windows and prediction tasks, rather than simple\npedestrian detection.",
      "tldr_zh": "本研究探讨了在恶劣天气条件下，使用Spiking Neural Networks (SNNs)和Dynamic Vision Sensors (DVS)来预测行人意图，以提升自动驾驶车辆的安全性。相比传统Convolutional Neural Networks (CNNs)，SNNs利用DVS的高时间分辨率和低延迟优势，并在自定义CARLA模拟器数据集上进行测试，结合Temporally Effective Batch Normalization优化模型。实验结果显示，SNNs在雨雾等复杂环境中显著提高了检测准确性和计算效率，减少了计算开销，并更适合处理长感知窗口和预测任务。该方法为智能交通系统的感知决策提供潜在改进，推动了更可靠的自主车辆技术。",
      "categories": [
        "cs.CV",
        "cs.AI",
        "68T01",
        "I.2.1"
      ],
      "primary_category": "cs.CV",
      "comment": "Submitted for peer review to IEEE Transactions on Intelligent\n  Transportation Systems",
      "pdf_url": "http://arxiv.org/pdf/2406.00473v1",
      "published_date": "2024-06-01 15:58:24 UTC",
      "updated_date": "2024-06-01 15:58:24 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-18T14:52:02.793976"
    },
    {
      "arxiv_id": "2406.01633v1",
      "title": "On Overcoming Miscalibrated Conversational Priors in LLM-based Chatbots",
      "title_zh": "翻译失败",
      "authors": [
        "Christine Herlihy",
        "Jennifer Neville",
        "Tobias Schnabel",
        "Adith Swaminathan"
      ],
      "abstract": "We explore the use of Large Language Model (LLM-based) chatbots to power\nrecommender systems. We observe that the chatbots respond poorly when they\nencounter under-specified requests (e.g., they make incorrect assumptions,\nhedge with a long response, or refuse to answer). We conjecture that such\nmiscalibrated response tendencies (i.e., conversational priors) can be\nattributed to LLM fine-tuning using annotators -- single-turn annotations may\nnot capture multi-turn conversation utility, and the annotators' preferences\nmay not even be representative of users interacting with a recommender system.\n  We first analyze public LLM chat logs to conclude that query\nunder-specification is common. Next, we study synthetic recommendation problems\nwith configurable latent item utilities and frame them as Partially Observed\nDecision Processes (PODP). We find that pre-trained LLMs can be sub-optimal for\nPODPs and derive better policies that clarify under-specified queries when\nappropriate. Then, we re-calibrate LLMs by prompting them with learned control\nmessages to approximate the improved policy. Finally, we show empirically that\nour lightweight learning approach effectively uses logged conversation data to\nre-calibrate the response strategies of LLM-based chatbots for recommendation\ntasks.",
      "tldr_zh": "本研究探讨了LLM-based chatbots在推荐系统中对不充分指定查询的误校准响应问题（如做出错误假设或拒绝回答），并将其归因于微调过程中的单轮注解不足和注解者偏好偏差。通过分析公共聊天日志和将问题建模为部分观察决策过程（PODP），论文推导出改进策略，用于澄清查询。最终，通过提示LLM使用学到的控制消息重新校准响应策略，实验证明这种轻量级方法能有效利用对话数据，提升聊天机器人在推荐任务中的准确性和实用性。",
      "categories": [
        "cs.IR",
        "cs.AI",
        "cs.CL",
        "cs.LG"
      ],
      "primary_category": "cs.IR",
      "comment": "Preprint of UAI'24 conference publication",
      "pdf_url": "http://arxiv.org/pdf/2406.01633v1",
      "published_date": "2024-06-01 15:54:45 UTC",
      "updated_date": "2024-06-01 15:54:45 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-18T14:52:14.809977"
    },
    {
      "arxiv_id": "2406.18566v1",
      "title": "Memorized Images in Diffusion Models share a Subspace that can be Located and Deleted",
      "title_zh": "扩散模型中记忆化图像共享一个可被定位和删除的子空间",
      "authors": [
        "Ruchika Chavhan",
        "Ondrej Bohdal",
        "Yongshuo Zong",
        "Da Li",
        "Timothy Hospedales"
      ],
      "abstract": "Large-scale text-to-image diffusion models excel in generating high-quality\nimages from textual inputs, yet concerns arise as research indicates their\ntendency to memorize and replicate training data, raising We also addressed the\nissue of memorization in diffusion models, where models tend to replicate exact\ntraining samples raising copyright infringement and privacy issues. Efforts\nwithin the text-to-image community to address memorization explore causes such\nas data duplication, replicated captions, or trigger tokens, proposing\nper-prompt inference-time or training-time mitigation strategies. In this\npaper, we focus on the feed-forward layers and begin by contrasting neuron\nactivations of a set of memorized and non-memorized prompts. Experiments reveal\na surprising finding: many different sets of memorized prompts significantly\nactivate a common subspace in the model, demonstrating, for the first time,\nthat memorization in the diffusion models lies in a special subspace.\nSubsequently, we introduce a novel post-hoc method for editing pre-trained\nmodels, whereby memorization is mitigated through the straightforward pruning\nof weights in specialized subspaces, avoiding the need to disrupt the training\nor inference process as seen in prior research. Finally, we demonstrate the\nrobustness of the pruned model against training data extraction attacks,\nthereby unveiling new avenues for a practical and one-for-all solution to\nmemorization.",
      "tldr_zh": "本研究发现，大型文本到图像diffusion models存在记忆训练数据的风险，可能导致版权和隐私问题，并首次揭示不同memorized prompts会显著激活模型中的一个共同subspace。研究对比了memorized和non-memorized prompts的神经元激活，证明记忆现象集中在特定subspace内。作者提出了一种新型post-hoc method，通过简单修剪这些subspace中的权重来缓解记忆问题，而无需干扰训练或推理过程。实验结果显示，修剪后的模型对training data extraction attacks具有更强的鲁棒性，提供了一个实用的一体化解决方案。",
      "categories": [
        "cs.CV",
        "cs.AI",
        "cs.LG"
      ],
      "primary_category": "cs.CV",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2406.18566v1",
      "published_date": "2024-06-01 15:47:13 UTC",
      "updated_date": "2024-06-01 15:47:13 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-18T14:52:25.055369"
    },
    {
      "arxiv_id": "2407.13934v1",
      "title": "Towards Trustworthy AI: A Review of Ethical and Robust Large Language Models",
      "title_zh": "翻译失败",
      "authors": [
        "Md Meftahul Ferdaus",
        "Mahdi Abdelguerfi",
        "Elias Ioup",
        "Kendall N. Niles",
        "Ken Pathak",
        "Steven Sloan"
      ],
      "abstract": "The rapid progress in Large Language Models (LLMs) could transform many\nfields, but their fast development creates significant challenges for\noversight, ethical creation, and building user trust. This comprehensive review\nlooks at key trust issues in LLMs, such as unintended harms, lack of\ntransparency, vulnerability to attacks, alignment with human values, and\nenvironmental impact. Many obstacles can undermine user trust, including\nsocietal biases, opaque decision-making, potential for misuse, and the\nchallenges of rapidly evolving technology. Addressing these trust gaps is\ncritical as LLMs become more common in sensitive areas like finance,\nhealthcare, education, and policy. To tackle these issues, we suggest combining\nethical oversight, industry accountability, regulation, and public involvement.\nAI development norms should be reshaped, incentives aligned, and ethics\nintegrated throughout the machine learning process, which requires close\ncollaboration across technology, ethics, law, policy, and other fields. Our\nreview contributes a robust framework to assess trust in LLMs and analyzes the\ncomplex trust dynamics in depth. We provide contextualized guidelines and\nstandards for responsibly developing and deploying these powerful AI systems.\nThis review identifies key limitations and challenges in creating trustworthy\nAI. By addressing these issues, we aim to build a transparent, accountable AI\necosystem that benefits society while minimizing risks. Our findings provide\nvaluable guidance for researchers, policymakers, and industry leaders striving\nto establish trust in LLMs and ensure they are used responsibly across various\napplications for the good of society.",
      "tldr_zh": "这篇综述探讨了大型语言模型(LLMs)的信任问题，包括无意伤害、缺乏透明度、易受攻击以及与人类价值观的契合等挑战，这些问题可能导致社会偏见、决策不透明和潜在误用。论文分析了LLMs在敏感领域如金融、医疗和教育中的应用风险，并提出通过道德监督、行业问责、监管和公众参与来构建可信AI框架。最终，该研究提供指导方针，帮助研究人员、政策制定者和行业领袖负责任地开发和部署LLMs，以最大化社会益处并最小化风险。",
      "categories": [
        "cs.CY",
        "cs.AI"
      ],
      "primary_category": "cs.CY",
      "comment": "Under review at Proceedings of the IEEE",
      "pdf_url": "http://arxiv.org/pdf/2407.13934v1",
      "published_date": "2024-06-01 14:47:58 UTC",
      "updated_date": "2024-06-01 14:47:58 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-18T14:52:37.676990"
    },
    {
      "arxiv_id": "2406.00456v2",
      "title": "Mix-of-Granularity: Optimize the Chunking Granularity for Retrieval-Augmented Generation",
      "title_zh": "翻译失败",
      "authors": [
        "Zijie Zhong",
        "Hanwen Liu",
        "Xiaoya Cui",
        "Xiaofan Zhang",
        "Zengchang Qin"
      ],
      "abstract": "Integrating information from various reference databases is a major challenge\nfor Retrieval-Augmented Generation (RAG) systems because each knowledge source\nadopts a unique data structure and follows different conventions. Retrieving\nfrom multiple knowledge sources with one fixed strategy usually leads to\nunder-exploitation of information. To mitigate this drawback, inspired by\nMix-of-Expert, we introduce Mix-of-Granularity (MoG), a method that dynamically\ndetermines the optimal granularity of a knowledge source based on input queries\nusing a router. The router is efficiently trained with a newly proposed loss\nfunction employing soft labels. We further extend MoG to MoG-Graph (MoGG),\nwhere reference documents are pre-processed as graphs, enabling the retrieval\nof distantly situated snippets. Experiments demonstrate that MoG and MoGG\neffectively predict optimal granularity levels, significantly enhancing the\nperformance of the RAG system in downstream tasks. The code of both MoG and\nMoGG are released in https://github.com/ZGChung/Mix-of-Granularity.",
      "tldr_zh": "该研究针对 Retrieval-Augmented Generation (RAG) 系统在整合多种知识源时的挑战，提出 Mix-of-Granularity (MoG) 方法，受 Mix-of-Expert 启发，使用一个 router 基于输入查询动态优化知识源的 chunking granularity。router 通过一个新提出的损失函数和 soft labels 进行高效训练，以最大化信息利用。进一步扩展为 MoG-Graph (MoGG)，将参考文档预处理为图结构，便于检索远距离片段。实验结果显示，MoG 和 MoGG 显著提升了 RAG 系统在下游任务的性能，并开源了代码（https://github.com/ZGChung/Mix-of-Granularity）。",
      "categories": [
        "cs.LG",
        "cs.AI",
        "cs.CL"
      ],
      "primary_category": "cs.LG",
      "comment": "COLING 2025 conference paper. 19 pages, 6 figures and 11 tables",
      "pdf_url": "http://arxiv.org/pdf/2406.00456v2",
      "published_date": "2024-06-01 14:45:03 UTC",
      "updated_date": "2025-01-26 06:52:41 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-18T14:52:50.030172"
    },
    {
      "arxiv_id": "2406.02597v1",
      "title": "CoNO: Complex Neural Operator for Continous Dynamical Physical Systems",
      "title_zh": "翻译失败",
      "authors": [
        "Karn Tiwari",
        "N M Anoop Krishnan",
        "A P Prathosh"
      ],
      "abstract": "Neural operators extend data-driven models to map between\ninfinite-dimensional functional spaces. While these operators perform\neffectively in either the time or frequency domain, their performance may be\nlimited when applied to non-stationary spatial or temporal signals whose\nfrequency characteristics change with time. Here, we introduce Complex Neural\nOperator (CoNO) that parameterizes the integral kernel using Fractional Fourier\nTransform (FrFT), better representing non-stationary signals in a\ncomplex-valued domain. Theoretically, we prove the universal approximation\ncapability of CoNO. We perform an extensive empirical evaluation of CoNO on\nseven challenging partial differential equations (PDEs), including regular\ngrids, structured meshes, and point clouds. Empirically, CoNO consistently\nattains state-of-the-art performance, showcasing an average relative gain of\n10.9%. Further, CoNO exhibits superior performance, outperforming all other\nmodels in additional tasks such as zero-shot super-resolution and robustness to\nnoise. CoNO also exhibits the ability to learn from small amounts of data --\ngiving the same performance as the next best model with just 60% of the\ntraining data. Altogether, CoNO presents a robust and superior model for\nmodeling continuous dynamical systems, providing a fillip to scientific machine\nlearning.",
      "tldr_zh": "这篇论文提出了 Complex Neural Operator (CoNO)，一种新型神经算子框架，使用 Fractional Fourier Transform (FrFT) 来参数化积分核，从而更好地处理非平稳信号在连续动态物理系统中的建模问题。理论上，作者证明了 CoNO 的通用逼近能力，能够在无限维函数空间中有效映射。实验结果显示，CoNO 在七个偏微分方程 (PDEs) 任务上实现了最先进性能，平均相对提升 10.9%，并在零样本超分辨率、噪声鲁棒性和少量数据学习（仅需 60% 数据）方面表现出显著优势，为科学机器学习提供了更稳健的工具。",
      "categories": [
        "cs.LG",
        "cs.AI",
        "cs.CV",
        "cs.NE"
      ],
      "primary_category": "cs.LG",
      "comment": "Under Review",
      "pdf_url": "http://arxiv.org/pdf/2406.02597v1",
      "published_date": "2024-06-01 14:32:19 UTC",
      "updated_date": "2024-06-01 14:32:19 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-18T14:53:02.872116"
    },
    {
      "arxiv_id": "2406.00452v1",
      "title": "Towards a Unified Framework of Clustering-based Anomaly Detection",
      "title_zh": "翻译失败",
      "authors": [
        "Zeyu Fang",
        "Ming Gu",
        "Sheng Zhou",
        "Jiawei Chen",
        "Qiaoyu Tan",
        "Haishuai Wang",
        "Jiajun Bu"
      ],
      "abstract": "Unsupervised Anomaly Detection (UAD) plays a crucial role in identifying\nabnormal patterns within data without labeled examples, holding significant\npractical implications across various domains. Although the individual\ncontributions of representation learning and clustering to anomaly detection\nare well-established, their interdependencies remain under-explored due to the\nabsence of a unified theoretical framework. Consequently, their collective\npotential to enhance anomaly detection performance remains largely untapped. To\nbridge this gap, in this paper, we propose a novel probabilistic mixture model\nfor anomaly detection to establish a theoretical connection among\nrepresentation learning, clustering, and anomaly detection. By maximizing a\nnovel anomaly-aware data likelihood, representation learning and clustering can\neffectively reduce the adverse impact of anomalous data and collaboratively\nbenefit anomaly detection. Meanwhile, a theoretically substantiated anomaly\nscore is naturally derived from this framework. Lastly, drawing inspiration\nfrom gravitational analysis in physics, we have devised an improved anomaly\nscore that more effectively harnesses the combined power of representation\nlearning and clustering. Extensive experiments, involving 17 baseline methods\nacross 30 diverse datasets, validate the effectiveness and generalization\ncapability of the proposed method, surpassing state-of-the-art methods.",
      "tldr_zh": "本文提出一个统一的框架，针对无监督异常检测（Unsupervised Anomaly Detection），探索表示学习（representation learning）和聚类（clustering）之间的相互依赖性，以提升异常检测性能。作者开发了一个新的概率混合模型（probabilistic mixture model），通过最大化异常感知数据似然（anomaly-aware data likelihood），使表示学习和聚类协同作用，减少异常数据的负面影响，并自然导出理论支持的异常分数（anomaly score）。此外，借鉴物理学中引力分析的灵感，设计了改进的异常分数，进一步增强框架的效能。实验结果显示，该方法在30个数据集上与17个基线方法比较，表现出色，超过了最先进方法。",
      "categories": [
        "cs.LG",
        "cs.AI"
      ],
      "primary_category": "cs.LG",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2406.00452v1",
      "published_date": "2024-06-01 14:30:12 UTC",
      "updated_date": "2024-06-01 14:30:12 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-18T14:53:16.155507"
    },
    {
      "arxiv_id": "2406.00447v1",
      "title": "DroneVis: Versatile Computer Vision Library for Drones",
      "title_zh": "翻译失败",
      "authors": [
        "Ahmed Heakl",
        "Fatma Youssef",
        "Victor Parque",
        "Walid Gomaa"
      ],
      "abstract": "This paper introduces DroneVis, a novel library designed to automate computer\nvision algorithms on Parrot drones. DroneVis offers a versatile set of features\nand provides a diverse range of computer vision tasks along with a variety of\nmodels to choose from. Implemented in Python, the library adheres to\nhigh-quality code standards, facilitating effortless customization and feature\nexpansion according to user requirements. In addition, comprehensive\ndocumentation is provided, encompassing usage guidelines and illustrative use\ncases. Our documentation, code, and examples are available in\nhttps://github.com/ahmedheakl/drone-vis.",
      "tldr_zh": "这篇论文介绍了 DroneVis，一种多功能计算机视觉库，旨在自动化 Parrot 无人机的计算机视觉算法。该库使用 Python 实现，提供多样化的计算机视觉任务和模型，支持用户轻松自定义和扩展功能。此外，DroneVis 附带全面文档、用法指南和示例案例，并开源在 GitHub（https://github.com/ahmedheakl/drone-vis）上，便于开发者使用。",
      "categories": [
        "cs.CV",
        "cs.AI",
        "cs.CY",
        "cs.LG",
        "cs.RO"
      ],
      "primary_category": "cs.CV",
      "comment": "23 pages, 15 figure, 2 tables",
      "pdf_url": "http://arxiv.org/pdf/2406.00447v1",
      "published_date": "2024-06-01 14:06:46 UTC",
      "updated_date": "2024-06-01 14:06:46 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-18T14:53:25.388171"
    },
    {
      "arxiv_id": "2406.00446v3",
      "title": "Advancing Supervised Local Learning Beyond Classification with Long-term Feature Bank",
      "title_zh": "翻译失败",
      "authors": [
        "Feiyu Zhu",
        "Yuming Zhang",
        "Changpeng Cai",
        "Chenghao He",
        "Xiuyuan Guo",
        "Jiao Li",
        "Peizhe Wang",
        "Junhao Su",
        "Jialin Gao"
      ],
      "abstract": "Local learning offers an alternative to traditional end-to-end\nback-propagation in deep neural networks, significantly reducing GPU memory\nusage. While local learning has shown promise in image classification tasks,\nits application to other visual tasks remains limited. This limitation arises\nprimarily from two factors: 1) architectures tailored for classification are\noften not transferable to other tasks, leading to a lack of reusability of\ntask-specific knowledge; 2) the absence of cross-scale feature communication\nresults in degraded performance in tasks such as object detection and\nsuper-resolution. To address these challenges, we propose the Memory-augmented\nAuxiliary Network (MAN), which introduces a simplified design principle and\nincorporates a feature bank to enhance cross-task adaptability and\ncommunication. This work represents the first successful application of local\nlearning methods beyond classification, demonstrating that MAN not only\nconserves GPU memory but also achieves performance on par with end-to-end\napproaches across multiple datasets for various visual tasks.",
      "tldr_zh": "该论文探讨了局部学习(local learning)作为深度神经网络中端到端反向传播(back-propagation)的替代方案，能够显著降低 GPU 内存使用，但其应用主要限于图像分类任务。针对架构复用不足和缺少跨尺度特征通信的问题，作者提出 Memory-augmented Auxiliary Network (MAN)，通过简化设计原则和引入 feature bank 来提升跨任务适应性和特征通信能力。该方法首次将局部学习扩展到物体检测和超分辨率等视觉任务，不仅节省 GPU 内存，还在多个数据集上实现了与端到端方法相当的性能。",
      "categories": [
        "cs.CV",
        "cs.AI"
      ],
      "primary_category": "cs.CV",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2406.00446v3",
      "published_date": "2024-06-01 14:02:11 UTC",
      "updated_date": "2024-10-15 07:33:47 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-18T14:53:37.881582"
    },
    {
      "arxiv_id": "2406.00443v1",
      "title": "Generating 3D Terrain with 2D Cellular Automata",
      "title_zh": "翻译失败",
      "authors": [
        "Nuno Fachada",
        "António R. Rodrigues",
        "Diogo de Andrade",
        "Phil Lopes"
      ],
      "abstract": "This paper presents an initial exploration on the use of 2D cellular automata\n(CA) for generating 3D terrains through a simple yet effective additive\napproach. By experimenting with multiple CA transition rules, this preliminary\ninvestigation yielded aesthetically interesting landscapes, hinting at the\ntechnique's potential applicability for real-time terrain generation in games.",
      "tldr_zh": "这篇论文探索了使用 2D Cellular Automata (CA) 通过简单有效的加法方法生成 3D 地形的方法。\n研究者通过实验多种 CA 转换规则，成功创建了美观有趣的景观。\n这项初步调查暗示了该技术在游戏中实时地形生成的潜在应用。",
      "categories": [
        "nlin.CG",
        "cs.AI",
        "cs.GR",
        "I.3.5; I.3.7; I.6.8; I.2.10"
      ],
      "primary_category": "nlin.CG",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2406.00443v1",
      "published_date": "2024-06-01 13:43:28 UTC",
      "updated_date": "2024-06-01 13:43:28 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-18T14:53:50.648136"
    },
    {
      "arxiv_id": "2406.00441v1",
      "title": "Neural Polarization: Toward Electron Density for Molecules by Extending Equivariant Networks",
      "title_zh": "翻译失败",
      "authors": [
        "Bumju Kwak",
        "Jeonghee Jo"
      ],
      "abstract": "Recent SO(3)-equivariant models embedded a molecule as a set of single atoms\nfixed in the three-dimensional space, which is analogous to a ball-and-stick\nview. This perspective provides a concise view of atom arrangements, however,\nthe surrounding electron density cannot be represented and its polarization\neffects may be underestimated. To overcome this limitation, we propose\n\\textit{Neural Polarization}, a novel method extending equivariant network by\nembedding each atom as a pair of fixed and moving points. Motivated by density\nfunctional theory, Neural Polarization represents molecules as a space-filling\nview which includes an electron density, in contrast with a ball-and-stick\nview. Neural Polarization can flexibly be applied to most type of existing\nequivariant models. We showed that Neural Polarization can improve prediction\nperformances of existing models over a wide range of targets. Finally, we\nverified that our method can improve the expressiveness and equivariance in\nterms of mathematical aspects.",
      "tldr_zh": "该论文批评了现有 SO(3)-equivariant 模型将分子视为固定原子集合（如球棍模型），从而忽略了电子密度的表示和极化效应。为解决此问题，研究提出 Neural Polarization 方法，将每个原子嵌入为固定点和移动点对，借鉴 density functional theory 的理念，将分子表示为空间填充视图。该方法可灵活应用于大多数 equivariant 网络，实验结果显示它显著提升了现有模型在各种目标上的预测性能，并从数学角度验证了其对模型表达性和等变性的改进。",
      "categories": [
        "physics.chem-ph",
        "cs.AI",
        "cs.LG"
      ],
      "primary_category": "physics.chem-ph",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2406.00441v1",
      "published_date": "2024-06-01 13:39:27 UTC",
      "updated_date": "2024-06-01 13:39:27 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-18T14:54:03.476143"
    },
    {
      "arxiv_id": "2406.07572v1",
      "title": "Domain-specific ReAct for physics-integrated iterative modeling: A case study of LLM agents for gas path analysis of gas turbines",
      "title_zh": "翻译失败",
      "authors": [
        "Tao Song",
        "Yuwei Fan",
        "Chenlong Feng",
        "Keyu Song",
        "Chao Liu",
        "Dongxiang Jiang"
      ],
      "abstract": "This study explores the application of large language models (LLMs) with\ncallable tools in energy and power engineering domain, focusing on gas path\nanalysis of gas turbines. We developed a dual-agent tool-calling process to\nintegrate expert knowledge, predefined tools, and LLM reasoning. We evaluated\nvarious LLMs, including LLama3, Qwen1.5 and GPT. Smaller models struggled with\ntool usage and parameter extraction, while larger models demonstrated favorable\ncapabilities. All models faced challenges with complex, multi-component\nproblems. Based on the test results, we infer that LLMs with nearly 100 billion\nparameters could meet professional scenario requirements with fine-tuning and\nadvanced prompt design. Continued development are likely to enhance their\naccuracy and effectiveness, paving the way for more robust AI-driven solutions.",
      "tldr_zh": "本研究探讨了大型语言模型（LLMs）在能源和动力工程领域的应用，特别针对燃气轮机的气体路径分析（gas path analysis），开发了一个基于 Domain-specific ReAct 的双智能体工具调用过程，以整合专家知识、预定义工具和 LLM 推理。实验评估了 LLama3、Qwen1.5 和 GPT 等模型，发现较小模型在工具使用和参数提取方面表现不佳，而较大模型显示出更强的能力，但所有模型在复杂多组件问题上仍面临挑战。通过测试结果，研究推断接近 100 亿参数的 LLMs 通过微调和高级提示设计（advanced prompt design）可满足专业场景需求，并有望通过持续开发提升准确性和有效性，为 AI 驱动解决方案铺平道路。",
      "categories": [
        "cs.AI",
        "cs.CE",
        "cs.LG"
      ],
      "primary_category": "cs.AI",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2406.07572v1",
      "published_date": "2024-06-01 13:35:18 UTC",
      "updated_date": "2024-06-01 13:35:18 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-18T14:54:14.792309"
    },
    {
      "arxiv_id": "2406.00431v2",
      "title": "SpaFL: Communication-Efficient Federated Learning with Sparse Models and Low computational Overhead",
      "title_zh": "翻译失败",
      "authors": [
        "Minsu Kim",
        "Walid Saad",
        "Merouane Debbah",
        "Choong Seon Hong"
      ],
      "abstract": "The large communication and computation overhead of federated learning (FL)\nis one of the main challenges facing its practical deployment over\nresource-constrained clients and systems. In this work, SpaFL: a\ncommunication-efficient FL framework is proposed to optimize sparse model\nstructures with low computational overhead. In SpaFL, a trainable threshold is\ndefined for each filter/neuron to prune its all connected parameters, thereby\nleading to structured sparsity. To optimize the pruning process itself, only\nthresholds are communicated between a server and clients instead of parameters,\nthereby learning how to prune. Further, global thresholds are used to update\nmodel parameters by extracting aggregated parameter importance. The\ngeneralization bound of SpaFL is also derived, thereby proving key insights on\nthe relation between sparsity and performance. Experimental results show that\nSpaFL improves accuracy while requiring much less communication and computing\nresources compared to sparse baselines. The code is available at\nhttps://github.com/news-vt/SpaFL_NeruIPS_2024",
      "tldr_zh": "该研究提出了一种通信高效的联邦学习（Federated Learning, FL）框架SpaFL，通过优化稀疏模型结构来减少通信和计算开销。SpaFL为每个过滤器/神经元定义可训练阈值，以修剪其连接参数实现结构化稀疏，并在优化过程中仅通信阈值而非完整参数，使用全局阈值更新模型以提取参数重要性。实验结果显示，SpaFL相较于稀疏基线模型提高了准确性，同时显著降低了通信和计算资源需求，并推导了其泛化界限，证明了稀疏性与性能之间的关键关系。",
      "categories": [
        "cs.LG",
        "cs.AI",
        "cs.DC"
      ],
      "primary_category": "cs.LG",
      "comment": "Published in NeurIPS 2024",
      "pdf_url": "http://arxiv.org/pdf/2406.00431v2",
      "published_date": "2024-06-01 13:10:35 UTC",
      "updated_date": "2024-12-10 15:43:05 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-18T14:54:26.189760"
    },
    {
      "arxiv_id": "2407.13112v1",
      "title": "Improvement of Applicability in Student Performance Prediction Based on Transfer Learning",
      "title_zh": "基于迁移",
      "authors": [
        "Yan Zhao"
      ],
      "abstract": "Predicting student performance under varying data distributions is a\nchallenging task. This study proposes a method to improve prediction accuracy\nby employing transfer learning techniques on the dataset with varying\ndistributions. Using datasets from mathematics and Portuguese language courses,\nthe model was trained and evaluated to enhance its generalization ability and\nprediction accuracy. The datasets used in this study were sourced from Kaggle,\ncomprising a variety of attributes such as demographic details, social factors,\nand academic performance. The methodology involves using an Artificial Neural\nNetwork (ANN) combined with transfer learning, where some layer weights were\nprogressively frozen, and the remaining layers were fine-tuned. Experimental\nresults demonstrated that this approach excels in reducing Root Mean Square\nError (RMSE) and Mean Absolute Error (MAE), while improving the coefficient of\ndetermination (R2). The model was initially trained on a subset with a larger\nsample size and subsequently fine-tuned on another subset. This method\neffectively facilitated knowledge transfer, enhancing model performance on\ntasks with limited data. The results demonstrate that freezing more layers\nimproves performance for complex and noisy data, whereas freezing fewer layers\nis more effective for simpler and larger datasets. This study highlights the\npotential of transfer learning in predicting student performance and suggests\nfuture research to explore domain adaptation techniques for unlabeled datasets.",
      "tldr_zh": "本研究针对数据分布变化对学生表现预测的挑战，提出了一种基于 Transfer Learning 的方法，使用 Artificial Neural Network (ANN) 模型，通过冻结部分层并微调其他层来提升预测准确性和泛化能力。实验利用 Kaggle 的数学和葡萄牙语课程数据集，先在较大样本子集上训练模型，然后转移到较小子集进行微调。结果显示，该方法显著降低了 Root Mean Square Error (RMSE) 和 Mean Absolute Error (MAE)，提高了系数 of determination (R2)，并发现冻结更多层更适合复杂噪声数据，而冻结较少层更适用于简单的大型数据集。未来，该方法可进一步探索领域适应技术以处理未标记数据集。",
      "categories": [
        "cs.CY",
        "cs.AI",
        "cs.LG"
      ],
      "primary_category": "cs.CY",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2407.13112v1",
      "published_date": "2024-06-01 13:09:05 UTC",
      "updated_date": "2024-06-01 13:09:05 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-18T14:54:39.587194"
    },
    {
      "arxiv_id": "2406.00430v2",
      "title": "Evaluating Uncertainty-based Failure Detection for Closed-Loop LLM Planners",
      "title_zh": "评估基于不确定性的故障检测在闭环 LLM 规划器中的性能",
      "authors": [
        "Zhi Zheng",
        "Qian Feng",
        "Hang Li",
        "Alois Knoll",
        "Jianxiang Feng"
      ],
      "abstract": "Recently, Large Language Models (LLMs) have witnessed remarkable performance\nas zero-shot task planners for robotic manipulation tasks. However, the\nopen-loop nature of previous works makes LLM-based planning error-prone and\nfragile. On the other hand, failure detection approaches for closed-loop\nplanning are often limited by task-specific heuristics or following an\nunrealistic assumption that the prediction is trustworthy all the time. As a\ngeneral-purpose reasoning machine, LLMs or Multimodal Large Language Models\n(MLLMs) are promising for detecting failures. However, However, the\nappropriateness of the aforementioned assumption diminishes due to the\nnotorious hullucination problem. In this work, we attempt to mitigate these\nissues by introducing a framework for closed-loop LLM-based planning called\nKnowLoop, backed by an uncertainty-based MLLMs failure detector, which is\nagnostic to any used MLLMs or LLMs. Specifically, we evaluate three different\nways for quantifying the uncertainty of MLLMs, namely token probability,\nentropy, and self-explained confidence as primary metrics based on three\ncarefully designed representative prompting strategies. With a self-collected\ndataset including various manipulation tasks and an LLM-based robot system, our\nexperiments demonstrate that token probability and entropy are more reflective\ncompared to self-explained confidence. By setting an appropriate threshold to\nfilter out uncertain predictions and seek human help actively, the accuracy of\nfailure detection can be significantly enhanced. This improvement boosts the\neffectiveness of closed-loop planning and the overall success rate of tasks.",
      "tldr_zh": "本文评估了基于不确定性的失败检测方法，用于闭环 LLM 规划器，以解决 Large Language Models (LLMs) 在机器人操作任务中易出错的 open-loop 问题。研究提出 KnowLoop 框架，利用 Multimodal Large Language Models (MLLMs) 量化不确定性，包括 token probability、entropy 和 self-explained confidence 三种指标，并通过精心设计的提示策略进行实验。结果显示，token probability 和 entropy 比 self-explained confidence 更可靠，通过设置阈值过滤不确定预测并主动寻求人类帮助，显著提高了失败检测准确性，从而提升了闭环规划的有效性和整体任务成功率。",
      "categories": [
        "cs.RO",
        "cs.AI"
      ],
      "primary_category": "cs.RO",
      "comment": "Accepted at ICRA 2024 Workshop on Back to the Future: Robot Learning\n  Going Probabilistic. Website: https://sites.google.com/view/konwloop/home",
      "pdf_url": "http://arxiv.org/pdf/2406.00430v2",
      "published_date": "2024-06-01 12:52:06 UTC",
      "updated_date": "2025-03-16 17:21:09 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-18T14:54:50.610230"
    },
    {
      "arxiv_id": "2406.00415v3",
      "title": "Neural Combinatorial Optimization Algorithms for Solving Vehicle Routing Problems: A Comprehensive Survey with Perspectives",
      "title_zh": "神经组合优化算法用于解决车辆路径问题：全面综述与展望",
      "authors": [
        "Xuan Wu",
        "Di Wang",
        "Lijie Wen",
        "Yubin Xiao",
        "Chunguo Wu",
        "Yuesong Wu",
        "Chaoyu Yu",
        "Douglas L. Maskell",
        "You Zhou"
      ],
      "abstract": "Although several surveys on Neural Combinatorial Optimization (NCO) solvers\nspecifically designed to solve Vehicle Routing Problems (VRPs) have been\nconducted, they did not cover the state-of-the-art (SOTA) NCO solvers emerged\nrecently. More importantly, to establish a comprehensive and up-to-date\ntaxonomy of NCO solvers, we systematically review relevant publications and\npreprints, categorizing them into four distinct types, namely Learning to\nConstruct, Learning to Improve, Learning to Predict-Once, and Learning to\nPredict-Multiplicity solvers. Subsequently, we present the inadequacies of the\nSOTA solvers, including poor generalization, incapability to solve large-scale\nVRPs, inability to address most types of VRP variants simultaneously, and\ndifficulty in comparing these NCO solvers with the conventional Operations\nResearch algorithms. Simultaneously, we discuss on-going efforts, identify open\ninadequacies, as well as propose promising and viable directions to overcome\nthese inadequacies. Notably, existing efforts focus on only one or two of these\ninadequacies, with none attempting to address all of them concurrently. In\naddition, we compare the performance of representative NCO solvers from the\nReinforcement, Supervised, and Unsupervised Learning paradigms across VRPs of\nvarying scales. Finally, following the proposed taxonomy, we provide an\naccompanying web page as a live repository for NCO solvers. Through this survey\nand the live repository, we aim to foster further advancements in the NCO\ncommunity.",
      "tldr_zh": "这篇论文对Neural Combinatorial Optimization (NCO) 算法在解决Vehicle Routing Problems (VRPs) 中的应用进行了全面调查，填补了现有综述对最新状态-of-the-art (SOTA) 求解器的覆盖不足。作者将NCO求解器分类为四类，包括Learning to Construct、Learning to Improve、Learning to Predict-Once 和Learning to Predict-Multiplicity，并分析了这些求解器的缺点，如泛化能力差、无法处理大规模VRPs以及难以与传统Operations Research算法比较。论文讨论了当前的改进努力、开放问题，并提出可行的方向来同时解决多个不足，同时比较了Reinforcement Learning、Supervised Learning 和Unsupervised Learning范式的代表性求解器在不同规模VRPs上的性能。最终，作者提供了一个基于该分类的在线仓库，以促进NCO社区的进一步发展。",
      "categories": [
        "cs.AI"
      ],
      "primary_category": "cs.AI",
      "comment": "submitted to TNNLS",
      "pdf_url": "http://arxiv.org/pdf/2406.00415v3",
      "published_date": "2024-06-01 12:18:39 UTC",
      "updated_date": "2025-04-25 06:52:44 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-18T14:55:04.940962"
    },
    {
      "arxiv_id": "2406.00410v1",
      "title": "Posterior Label Smoothing for Node Classification",
      "title_zh": "后验标签平滑用于节点分类",
      "authors": [
        "Jaeseung Heo",
        "Moonjeong Park",
        "Dongwoo Kim"
      ],
      "abstract": "Soft labels can improve the generalization of a neural network classifier in\nmany domains, such as image classification. Despite its success, the current\nliterature has overlooked the efficiency of label smoothing in node\nclassification with graph-structured data. In this work, we propose a simple\nyet effective label smoothing for the transductive node classification task. We\ndesign the soft label to encapsulate the local context of the target node\nthrough the neighborhood label distribution. We apply the smoothing method for\nseven baseline models to show its effectiveness. The label smoothing methods\nimprove the classification accuracy in 10 node classification datasets in most\ncases. In the following analysis, we find that incorporating global label\nstatistics in posterior computation is the key to the success of label\nsmoothing. Further investigation reveals that the soft labels mitigate\noverfitting during training, leading to better generalization performance.",
      "tldr_zh": "本研究提出了一种针对节点分类（node classification）的后验标签平滑（Posterior Label Smoothing）方法，通过设计软标签（soft labels）来整合目标节点的局部上下文，即邻居标签分布，从而提升模型的泛化性能。作者将此方法应用于七个基线模型，并在10个节点分类数据集上进行测试，大多数情况下显著提高了分类准确率。进一步分析显示，关键在于后验计算中纳入全局标签统计，这有助于缓解训练过程中的过拟合问题，实现更好的泛化效果。",
      "categories": [
        "cs.LG",
        "cs.AI"
      ],
      "primary_category": "cs.LG",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2406.00410v1",
      "published_date": "2024-06-01 11:59:49 UTC",
      "updated_date": "2024-06-01 11:59:49 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-18T14:55:14.509247"
    },
    {
      "arxiv_id": "2406.00409v1",
      "title": "Arabic Handwritten Text for Person Biometric Identification: A Deep Learning Approach",
      "title_zh": "阿拉伯语手写文本",
      "authors": [
        "Mazen Balat",
        "Youssef Mohamed",
        "Ahmed Heakl",
        "Ahmed Zaky"
      ],
      "abstract": "This study thoroughly investigates how well deep learning models can\nrecognize Arabic handwritten text for person biometric identification. It\ncompares three advanced architectures -- ResNet50, MobileNetV2, and\nEfficientNetB7 -- using three widely recognized datasets: AHAWP, Khatt, and\nLAMIS-MSHD. Results show that EfficientNetB7 outperforms the others, achieving\ntest accuracies of 98.57\\%, 99.15\\%, and 99.79\\% on AHAWP, Khatt, and\nLAMIS-MSHD datasets, respectively. EfficientNetB7's exceptional performance is\ncredited to its innovative techniques, including compound scaling, depth-wise\nseparable convolutions, and squeeze-and-excitation blocks. These features allow\nthe model to extract more abstract and distinctive features from handwritten\ntext images. The study's findings hold significant implications for enhancing\nidentity verification and authentication systems, highlighting the potential of\ndeep learning in Arabic handwritten text recognition for person biometric\nidentification.",
      "tldr_zh": "本研究探讨了深度学习模型在阿拉伯手写文本用于个人生物识别方面的性能，比较了 ResNet50、MobileNetV2 和 EfficientNetB7 三种架构在 AHAWP、Khatt 和 LAMIS-MSHD 数据集上的表现。结果显示，EfficientNetB7 表现出色，分别实现了 98.57%、99.15% 和 99.79% 的测试准确率，其优势源于 compound scaling、depth-wise separable convolutions 和 squeeze-and-excitation blocks 等创新技术，这些特性有助于从手写文本图像中提取更抽象和独特的特征。该研究为身份验证和认证系统提供了重要启示，证明了深度学习在阿拉伯手写文本识别中的巨大潜力。",
      "categories": [
        "cs.CV",
        "cs.AI",
        "cs.LG",
        "cs.MM",
        "cs.NE"
      ],
      "primary_category": "cs.CV",
      "comment": "6 pages, 11 figures, 4 tables, International IEEE Conference on the\n  Intelligent Methods, Systems, and Applications (IMSA)",
      "pdf_url": "http://arxiv.org/pdf/2406.00409v1",
      "published_date": "2024-06-01 11:43:00 UTC",
      "updated_date": "2024-06-01 11:43:00 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-18T14:55:27.897688"
    },
    {
      "arxiv_id": "2406.03409v1",
      "title": "Robust Knowledge Distillation Based on Feature Variance Against Backdoored Teacher Model",
      "title_zh": "翻译失败",
      "authors": [
        "Jinyin Chen",
        "Xiaoming Zhao",
        "Haibin Zheng",
        "Xiao Li",
        "Sheng Xiang",
        "Haifeng Guo"
      ],
      "abstract": "Benefiting from well-trained deep neural networks (DNNs), model compression\nhave captured special attention for computing resource limited equipment,\nespecially edge devices. Knowledge distillation (KD) is one of the widely used\ncompression techniques for edge deployment, by obtaining a lightweight student\nmodel from a well-trained teacher model released on public platforms. However,\nit has been empirically noticed that the backdoor in the teacher model will be\ntransferred to the student model during the process of KD. Although numerous KD\nmethods have been proposed, most of them focus on the distillation of a\nhigh-performing student model without robustness consideration. Besides, some\nresearch adopts KD techniques as effective backdoor mitigation tools, but they\nfail to perform model compression at the same time. Consequently, it is still\nan open problem to well achieve two objectives of robust KD, i.e., student\nmodel's performance and backdoor mitigation. To address these issues, we\npropose RobustKD, a robust knowledge distillation that compresses the model\nwhile mitigating backdoor based on feature variance. Specifically, RobustKD\ndistinguishes the previous works in three key aspects: (1) effectiveness: by\ndistilling the feature map of the teacher model after detoxification, the main\ntask performance of the student model is comparable to that of the teacher\nmodel; (2) robustness: by reducing the characteristic variance between the\nteacher model and the student model, it mitigates the backdoor of the student\nmodel under backdoored teacher model scenario; (3) generic: RobustKD still has\ngood performance in the face of multiple data models (e.g., WRN 28-4,\nPyramid-200) and diverse DNNs (e.g., ResNet50, MobileNet).",
      "tldr_zh": "该论文探讨了知识蒸馏（Knowledge Distillation, KD）在后门攻击（backdoor）场景下的问题，即教师模型中的后门可能转移到学生模型，导致安全隐患。作者提出RobustKD方法，通过基于特征方差（feature variance）的机制，同时实现模型压缩和后门缓解：具体而言，它蒸馏教师模型的去毒特征映射以保持学生模型性能，并减少教师与学生模型之间的特征方差来减轻后门影响。实验结果显示，RobustKD在多种数据模型（如WRN 28-4、Pyramid-200）和深度神经网络（如ResNet50、MobileNet）上表现出色，确保了学生模型的有效性和鲁棒性。",
      "categories": [
        "cs.LG",
        "cs.AI"
      ],
      "primary_category": "cs.LG",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2406.03409v1",
      "published_date": "2024-06-01 11:25:03 UTC",
      "updated_date": "2024-06-01 11:25:03 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-18T14:55:39.062962"
    },
    {
      "arxiv_id": "2406.00405v2",
      "title": "Autaptic Synaptic Circuit Enhances Spatio-temporal Predictive Learning of Spiking Neural Networks",
      "title_zh": "翻译失败",
      "authors": [
        "Lihao Wang",
        "Zhaofei Yu"
      ],
      "abstract": "Spiking Neural Networks (SNNs) emulate the integrated-fire-leak mechanism\nfound in biological neurons, offering a compelling combination of biological\nrealism and energy efficiency. In recent years, they have gained considerable\nresearch interest. However, existing SNNs predominantly rely on the Leaky\nIntegrate-and-Fire (LIF) model and are primarily suited for simple, static\ntasks. They lack the ability to effectively model long-term temporal\ndependencies and facilitate spatial information interaction, which is crucial\nfor tackling complex, dynamic spatio-temporal prediction tasks. To tackle these\nchallenges, this paper draws inspiration from the concept of autaptic synapses\nin biology and proposes a novel Spatio-Temporal Circuit (STC) model. The STC\nmodel integrates two learnable adaptive pathways, enhancing the spiking\nneurons' temporal memory and spatial coordination. We conduct a theoretical\nanalysis of the dynamic parameters in the STC model, highlighting their\ncontribution in establishing long-term memory and mitigating the issue of\ngradient vanishing. Through extensive experiments on multiple spatio-temporal\nprediction datasets, we demonstrate that our model outperforms other adaptive\nmodels. Furthermore, our model is compatible with existing spiking neuron\nmodels, thereby augmenting their dynamic representations. In essence, our work\nenriches the specificity and topological complexity of SNNs.",
      "tldr_zh": "本论文指出，现有的 Spiking Neural Networks (SNNs) 主要依赖 Leaky Integrate-and-Fire (LIF) 模型，适合简单静态任务，但难以处理复杂动态时空预测中的长期时间依赖性和空间信息交互。\n\n为此，论文提出了一种新型 Spatio-Temporal Circuit (STC) 模型，灵感来源于生物 autaptic synapses，并整合两个可学习的自适应路径，以提升 SNNs 的 temporal memory 和 spatial coordination。\n\n理论分析显示，STC 模型的动态参数有助于建立长期记忆并缓解梯度消失问题；实验结果表明，该模型在多个时空预测数据集上优于其他自适应模型。\n\n此外，STC 模型与现有 SNNs 兼容，从而丰富了其特异性和拓扑复杂性。",
      "categories": [
        "cs.NE",
        "cs.AI"
      ],
      "primary_category": "cs.NE",
      "comment": "Accepted by ICML2024",
      "pdf_url": "http://arxiv.org/pdf/2406.00405v2",
      "published_date": "2024-06-01 11:17:27 UTC",
      "updated_date": "2024-06-05 03:45:18 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-18T14:55:53.849272"
    },
    {
      "arxiv_id": "2406.00403v1",
      "title": "Dual-perspective Cross Contrastive Learning in Graph Transformers",
      "title_zh": "图变换器中的双视角交叉对比学习",
      "authors": [
        "Zelin Yao",
        "Chuang Liu",
        "Xueqi Ma",
        "Mukun Chen",
        "Jia Wu",
        "Xiantao Cai",
        "Bo Du",
        "Wenbin Hu"
      ],
      "abstract": "Graph contrastive learning (GCL) is a popular method for leaning graph\nrepresentations by maximizing the consistency of features across augmented\nviews. Traditional GCL methods utilize single-perspective i.e. data or\nmodel-perspective) augmentation to generate positive samples, restraining the\ndiversity of positive samples. In addition, these positive samples may be\nunreliable due to uncontrollable augmentation strategies that potentially alter\nthe semantic information. To address these challenges, this paper proposed a\ninnovative framework termed dual-perspective cross graph contrastive learning\n(DC-GCL), which incorporates three modifications designed to enhance positive\nsample diversity and reliability: 1) We propose dual-perspective augmentation\nstrategy that provide the model with more diverse training data, enabling the\nmodel effective learning of feature consistency across different views. 2) From\nthe data perspective, we slightly perturb the original graphs using\ncontrollable data augmentation, effectively preserving their semantic\ninformation. 3) From the model perspective, we enhance the encoder by utilizing\nmore powerful graph transformers instead of graph neural networks. Based on the\nmodel's architecture, we propose three pruning-based strategies to slightly\nperturb the encoder, providing more reliable positive samples. These\nmodifications collectively form the DC-GCL's foundation and provide more\ndiverse and reliable training inputs, offering significant improvements over\ntraditional GCL methods. Extensive experiments on various benchmarks\ndemonstrate that DC-GCL consistently outperforms different baselines on various\ndatasets and tasks.",
      "tldr_zh": "该论文针对传统 Graph Contrastive Learning (GCL) 中正样本多样性和可靠性不足的问题，提出了一种创新框架 Dual-perspective Cross Graph Contrastive Learning (DC-GCL)。该框架通过双视角增强策略，包括可控数据扰动（如轻微图扰动以保留语义信息）和基于 Graph Transformers 的模型修剪策略，来生成更多样且可靠的正样本，从而提升特征一致性学习。实验在多种基准数据集和任务上表明，DC-GCL 显著优于基线方法，提供更好的图表示学习性能。",
      "categories": [
        "cs.LG",
        "cs.AI"
      ],
      "primary_category": "cs.LG",
      "comment": "12 pages, 5 figures, submitted to IEEE TKDE",
      "pdf_url": "http://arxiv.org/pdf/2406.00403v1",
      "published_date": "2024-06-01 11:11:49 UTC",
      "updated_date": "2024-06-01 11:11:49 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-18T14:56:03.904950"
    },
    {
      "arxiv_id": "2406.00396v3",
      "title": "Stochastic Resetting Mitigates Latent Gradient Bias of SGD from Label Noise",
      "title_zh": "随机重置缓解 SGD 中源自标签噪声的潜在梯度偏差",
      "authors": [
        "Youngkyoung Bae",
        "Yeongwoo Song",
        "Hawoong Jeong"
      ],
      "abstract": "Giving up and starting over may seem wasteful in many situations such as\nsearching for a target or training deep neural networks (DNNs). Our study,\nthough, demonstrates that resetting from a checkpoint can significantly improve\ngeneralization performance when training DNNs with noisy labels. In the\npresence of noisy labels, DNNs initially learn the general patterns of the data\nbut then gradually memorize the corrupted data, leading to overfitting. By\ndeconstructing the dynamics of stochastic gradient descent (SGD), we identify\nthe behavior of a latent gradient bias induced by noisy labels, which harms\ngeneralization. To mitigate this negative effect, we apply the stochastic\nresetting method to SGD, inspired by recent developments in the field of\nstatistical physics achieving efficient target searches. We first theoretically\nidentify the conditions where resetting becomes beneficial, and then we\nempirically validate our theory, confirming the significant improvements\nachieved by resetting. We further demonstrate that our method is both easy to\nimplement and compatible with other methods for handling noisy labels.\nAdditionally, this work offers insights into the learning dynamics of DNNs from\nan interpretability perspective, expanding the potential to analyze training\nmethods through the lens of statistical physics.",
      "tldr_zh": "本研究发现，在标签噪声环境下，训练深度神经网络 (DNNs) 时，随机梯度下降 (SGD) 会因潜在梯度偏差 (latent gradient bias) 而导致模型逐渐记忆噪声数据并过拟合，从而损害泛化性能。作者引入随机重置 (Stochastic Resetting) 方法，受统计物理学启发，将其应用于 SGD，以中断负面动态并促进高效学习。理论分析标识了重置有益的条件，实验验证显示该方法显著提升泛化性能，且易于实现并与其他处理标签噪声的技术兼容，为从可解释性视角分析 DNN 训练动态提供了新见解。",
      "categories": [
        "cs.LG",
        "cond-mat.stat-mech",
        "cs.AI",
        "stat.ML"
      ],
      "primary_category": "cs.LG",
      "comment": "30 pages, 14 figures",
      "pdf_url": "http://arxiv.org/pdf/2406.00396v3",
      "published_date": "2024-06-01 10:45:41 UTC",
      "updated_date": "2025-03-04 05:51:53 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-18T14:56:16.520794"
    },
    {
      "arxiv_id": "2406.00394v1",
      "title": "Learning Causal Abstractions of Linear Structural Causal Models",
      "title_zh": "翻译失败",
      "authors": [
        "Riccardo Massidda",
        "Sara Magliacane",
        "Davide Bacciu"
      ],
      "abstract": "The need for modelling causal knowledge at different levels of granularity\narises in several settings. Causal Abstraction provides a framework for\nformalizing this problem by relating two Structural Causal Models at different\nlevels of detail. Despite increasing interest in applying causal abstraction,\ne.g. in the interpretability of large machine learning models, the graphical\nand parametrical conditions under which a causal model can abstract another are\nnot known. Furthermore, learning causal abstractions from data is still an open\nproblem. In this work, we tackle both issues for linear causal models with\nlinear abstraction functions. First, we characterize how the low-level\ncoefficients and the abstraction function determine the high-level coefficients\nand how the high-level model constrains the causal ordering of low-level\nvariables. Then, we apply our theoretical results to learn high-level and\nlow-level causal models and their abstraction function from observational data.\nIn particular, we introduce Abs-LiNGAM, a method that leverages the constraints\ninduced by the learned high-level model and the abstraction function to speedup\nthe recovery of the larger low-level model, under the assumption of\nnon-Gaussian noise terms. In simulated settings, we show the effectiveness of\nlearning causal abstractions from data and the potential of our method in\nimproving scalability of causal discovery.",
      "tldr_zh": "该研究探讨了在不同粒度水平建模因果知识的问题，通过Causal Abstraction框架来关联线性Structural Causal Models的图形和参数条件。论文首次表征了低级系数与抽象函数如何决定高级系数，并提出了从观测数据中学习高低级模型及其抽象函数的方法，特别是引入了Abs-LiNGAM算法，利用非高斯噪声假设和高级模型约束来加速低级模型的恢复。在模拟实验中，该方法证明了学习Causal Abstractions的有效性，并显著提升了因果发现的可伸缩性。",
      "categories": [
        "cs.LG",
        "cs.AI",
        "stat.ME"
      ],
      "primary_category": "cs.LG",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2406.00394v1",
      "published_date": "2024-06-01 10:42:52 UTC",
      "updated_date": "2024-06-01 10:42:52 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-18T14:56:27.675885"
    },
    {
      "arxiv_id": "2406.00392v2",
      "title": "Artificial Generational Intelligence: Cultural Accumulation in Reinforcement Learning",
      "title_zh": "人工世代智能：强化学习中的文化积累",
      "authors": [
        "Jonathan Cook",
        "Chris Lu",
        "Edward Hughes",
        "Joel Z. Leibo",
        "Jakob Foerster"
      ],
      "abstract": "Cultural accumulation drives the open-ended and diverse progress in\ncapabilities spanning human history. It builds an expanding body of knowledge\nand skills by combining individual exploration with inter-generational\ninformation transmission. Despite its widespread success among humans, the\ncapacity for artificial learning agents to accumulate culture remains\nunder-explored. In particular, approaches to reinforcement learning typically\nstrive for improvements over only a single lifetime. Generational algorithms\nthat do exist fail to capture the open-ended, emergent nature of cultural\naccumulation, which allows individuals to trade-off innovation and imitation.\nBuilding on the previously demonstrated ability for reinforcement learning\nagents to perform social learning, we find that training setups which balance\nthis with independent learning give rise to cultural accumulation. These\naccumulating agents outperform those trained for a single lifetime with the\nsame cumulative experience. We explore this accumulation by constructing two\nmodels under two distinct notions of a generation: episodic generations, in\nwhich accumulation occurs via in-context learning and train-time generations,\nin which accumulation occurs via in-weights learning. In-context and in-weights\ncultural accumulation can be interpreted as analogous to knowledge and skill\naccumulation, respectively. To the best of our knowledge, this work is the\nfirst to present general models that achieve emergent cultural accumulation in\nreinforcement learning, opening up new avenues towards more open-ended learning\nsystems, as well as presenting new opportunities for modelling human culture.",
      "tldr_zh": "该论文探讨了文化积累（cultural accumulation）在强化学习（reinforcement learning）中的应用，强调它通过个体探索和代际信息传输推动能力的发展，而现有算法通常仅限于单生命周期训练。作者构建了两种模型：episodic generations（通过in-context learning实现积累）和train-time generations（通过in-weights learning实现积累），以平衡社会学习和独立学习，从而实现新兴的文化积累。实验结果显示，这些积累代理在相同累积经验下表现出色，优于单生命周期训练，并为更开放的学习系统和人类文化建模开辟新途径。",
      "categories": [
        "cs.AI"
      ],
      "primary_category": "cs.AI",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2406.00392v2",
      "published_date": "2024-06-01 10:33:32 UTC",
      "updated_date": "2024-10-28 16:33:31 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-18T14:56:39.619529"
    },
    {
      "arxiv_id": "2406.06558v1",
      "title": "Enhancing Text Authenticity: A Novel Hybrid Approach for AI-Generated Text Detection",
      "title_zh": "翻译失败",
      "authors": [
        "Ye Zhang",
        "Qian Leng",
        "Mengran Zhu",
        "Rui Ding",
        "Yue Wu",
        "Jintong Song",
        "Yulu Gong"
      ],
      "abstract": "The rapid advancement of Large Language Models (LLMs) has ushered in an era\nwhere AI-generated text is increasingly indistinguishable from human-generated\ncontent. Detecting AI-generated text has become imperative to combat\nmisinformation, ensure content authenticity, and safeguard against malicious\nuses of AI. In this paper, we propose a novel hybrid approach that combines\ntraditional TF-IDF techniques with advanced machine learning models, including\nBayesian classifiers, Stochastic Gradient Descent (SGD), Categorical Gradient\nBoosting (CatBoost), and 12 instances of Deberta-v3-large models. Our approach\naims to address the challenges associated with detecting AI-generated text by\nleveraging the strengths of both traditional feature extraction methods and\nstate-of-the-art deep learning models. Through extensive experiments on a\ncomprehensive dataset, we demonstrate the effectiveness of our proposed method\nin accurately distinguishing between human and AI-generated text. Our approach\nachieves superior performance compared to existing methods. This research\ncontributes to the advancement of AI-generated text detection techniques and\nlays the foundation for developing robust solutions to mitigate the challenges\nposed by AI-generated content.",
      "tldr_zh": "这篇论文针对 Large Language Models (LLMs) 导致 AI 生成文本越来越难以与人类文本区分的问题，提出了一种新型混合方法，用于检测 AI 生成文本以对抗 misinformation、确保内容真实性和防范恶意使用。方法结合了传统 TF-IDF 技术与高级机器学习模型，包括 Bayesian classifiers、Stochastic Gradient Descent (SGD)、Categorical Gradient Boosting (CatBoost) 和 12 个 Deberta-v3-large 模型，充分利用特征提取和深度学习的优势。实验结果显示，该方法在全面数据集上表现出色，能准确区分人类和 AI 生成文本，并优于现有方法。该研究为推进 AI 生成文本检测技术并开发稳健解决方案奠定了基础。",
      "categories": [
        "cs.CL",
        "cs.AI"
      ],
      "primary_category": "cs.CL",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2406.06558v1",
      "published_date": "2024-06-01 10:21:54 UTC",
      "updated_date": "2024-06-01 10:21:54 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-18T14:56:53.329466"
    },
    {
      "arxiv_id": "2406.01629v1",
      "title": "RecDiff: Diffusion Model for Social Recommendation",
      "title_zh": "翻译失败",
      "authors": [
        "Zongwei Li",
        "Lianghao Xia",
        "Chao Huang"
      ],
      "abstract": "Social recommendation has emerged as a powerful approach to enhance\npersonalized recommendations by leveraging the social connections among users,\nsuch as following and friend relations observed in online social platforms. The\nfundamental assumption of social recommendation is that socially-connected\nusers exhibit homophily in their preference patterns. This means that users\nconnected by social ties tend to have similar tastes in user-item activities,\nsuch as rating and purchasing. However, this assumption is not always valid due\nto the presence of irrelevant and false social ties, which can contaminate user\nembeddings and adversely affect recommendation accuracy. To address this\nchallenge, we propose a novel diffusion-based social denoising framework for\nrecommendation (RecDiff). Our approach utilizes a simple yet effective\nhidden-space diffusion paradigm to alleivate the noisy effect in the compressed\nand dense representation space. By performing multi-step noise diffusion and\nremoval, RecDiff possesses a robust ability to identify and eliminate noise\nfrom the encoded user representations, even when the noise levels vary. The\ndiffusion module is optimized in a downstream task-aware manner, thereby\nmaximizing its ability to enhance the recommendation process. We conducted\nextensive experiments to evaluate the efficacy of our framework, and the\nresults demonstrate its superiority in terms of recommendation accuracy,\ntraining efficiency, and denoising effectiveness. The source code for the model\nimplementation is publicly available at: https://github.com/HKUDS/RecDiff.",
      "tldr_zh": "这篇论文针对社会推荐系统中的噪声问题（如无关或虚假社交关系），提出了一种新型框架RecDiff，该框架利用diffusion model在隐藏空间进行多步噪声扩散和移除，以净化用户嵌入表示。RecDiff以下游任务感知方式优化扩散模块，从而提升推荐准确性和鲁棒性。实验结果表明，该框架在推荐性能、训练效率和去噪效果上均优于基线模型，并公开了源代码。",
      "categories": [
        "cs.IR",
        "cs.AI",
        "cs.SI"
      ],
      "primary_category": "cs.IR",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2406.01629v1",
      "published_date": "2024-06-01 10:20:52 UTC",
      "updated_date": "2024-06-01 10:20:52 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-18T14:57:03.864969"
    },
    {
      "arxiv_id": "2406.00380v3",
      "title": "HonestLLM: Toward an Honest and Helpful Large Language Model",
      "title_zh": "HonestLLM：面向诚实且有帮助的大型语言模型",
      "authors": [
        "Chujie Gao",
        "Siyuan Wu",
        "Yue Huang",
        "Dongping Chen",
        "Qihui Zhang",
        "Zhengyan Fu",
        "Yao Wan",
        "Lichao Sun",
        "Xiangliang Zhang"
      ],
      "abstract": "Large Language Models (LLMs) have achieved remarkable success across various\nindustries due to their exceptional generative capabilities. However, for safe\nand effective real-world deployments, ensuring honesty and helpfulness is\ncritical. This paper addresses the question: Can we prioritize the helpfulness\nof LLMs while preserving their honesty? To begin with, we establish exhaustive\nprinciples aimed at guaranteeing the honesty of LLM. Additionally, we introduce\na novel dataset, referred to as HoneSet, comprising 930 queries spanning six\ncategories meticulously crafted to assess an LLM's capacity for maintaining\nhonesty. Subsequently, we present two approaches to augmenting honesty and\nhelpfulness in LLMs: a training-free enhancement and a fine-tuning-based\nimprovement. The training-free approach, which is based on curiosity-driven\nprompting, empowers LLMs to articulate internal confusion and uncertainty\nregarding queries, thereby optimizing their responses. Conversely, the\nfine-tuning-based method employs a two-stage process inspired by curriculum\nlearning: initially instructing LLMs to discern between honest and dishonest\nresponses, then refining their training to enhance helpfulness. Experiments\nconducted on nine prominent LLMs demonstrate a significant improvement in\nalignment with honesty across all models through the implementation of our\nproposed enhancements. Particularly noteworthy is the 65.3% enhancement\nobserved in Llama3-8b and the remarkable 124.7% improvement in Mistral-7b, as\nmeasured by the H$^{2}$ (honest and helpful) assessment. We believe that our\nwork can pave the way for developing more trustworthy LLMs for real-world\napplications.",
      "tldr_zh": "这篇论文探讨了如何使 Large Language Models (LLMs) 既诚实又帮助性，提出了确保 LLM 诚实性的全面原则和一个新数据集 HoneSet，该数据集包含 930 个跨六类的查询，用于评估模型的诚实能力。作者开发了两种方法：基于 curiosity-driven prompting 的训练-free 增强，让模型表达内部不确定性以优化响应；以及基于 curriculum learning 的 fine-tuning-based 方法，通过两阶段训练先区分诚实与不诚实响应，再提升帮助性。实验在九个主要 LLMs 上显示显著改善，其中 Llama3-8b 的 H² (honest and helpful) 评估分数提升 65.3%，Mistral-7b 提升 124.7%。这项工作为开发更可信的 LLMs 应用于现实场景铺平了道路。",
      "categories": [
        "cs.CL",
        "cs.AI"
      ],
      "primary_category": "cs.CL",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2406.00380v3",
      "published_date": "2024-06-01 09:36:16 UTC",
      "updated_date": "2024-12-11 11:52:58 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-18T14:57:18.894306"
    },
    {
      "arxiv_id": "2406.00367v2",
      "title": "RoBERTa-BiLSTM: A Context-Aware Hybrid Model for Sentiment Analysis",
      "title_zh": "翻译失败",
      "authors": [
        "Md. Mostafizer Rahman",
        "Ariful Islam Shiplu",
        "Yutaka Watanobe",
        "Md. Ashad Alam"
      ],
      "abstract": "Effectively analyzing the comments to uncover latent intentions holds immense\nvalue in making strategic decisions across various domains. However, several\nchallenges hinder the process of sentiment analysis including the lexical\ndiversity exhibited in comments, the presence of long dependencies within the\ntext, encountering unknown symbols and words, and dealing with imbalanced\ndatasets. Moreover, existing sentiment analysis tasks mostly leveraged\nsequential models to encode the long dependent texts and it requires longer\nexecution time as it processes the text sequentially. In contrast, the\nTransformer requires less execution time due to its parallel processing nature.\nIn this work, we introduce a novel hybrid deep learning model, RoBERTa-BiLSTM,\nwhich combines the Robustly Optimized BERT Pretraining Approach (RoBERTa) with\nBidirectional Long Short-Term Memory (BiLSTM) networks. RoBERTa is utilized to\ngenerate meaningful word embedding vectors, while BiLSTM effectively captures\nthe contextual semantics of long-dependent texts. The RoBERTa-BiLSTM hybrid\nmodel leverages the strengths of both sequential and Transformer models to\nenhance performance in sentiment analysis. We conducted experiments using\ndatasets from IMDb, Twitter US Airline, and Sentiment140 to evaluate the\nproposed model against existing state-of-the-art methods. Our experimental\nfindings demonstrate that the RoBERTa-BiLSTM model surpasses baseline models\n(e.g., BERT, RoBERTa-base, RoBERTa-GRU, and RoBERTa-LSTM), achieving accuracies\nof 80.74%, 92.36%, and 82.25% on the Twitter US Airline, IMDb, and Sentiment140\ndatasets, respectively. Additionally, the model achieves F1-scores of 80.73%,\n92.35%, and 82.25% on the same datasets, respectively.",
      "tldr_zh": "本论文针对情感分析中的词汇多样性、长距离依赖、未知符号和数据集不平衡等挑战，提出了一种混合深度学习模型 RoBERTa-BiLSTM，将 RoBERTa 用于生成单词嵌入向量，并结合 BiLSTM 捕获文本的上下文语义，从而提升模型效率和性能。相比传统顺序模型和 Transformer 模型，该框架利用二者的优势，实现了更快的处理和更高的准确性。在 IMDb、Twitter US Airline 和 Sentiment140 数据集上的实验中，RoBERTa-BiLSTM 模型的准确率分别达到 92.36%、80.74% 和 82.25%，并在 F1 分数上同样表现出色，优于基线模型如 BERT 和 RoBERTa-base。",
      "categories": [
        "cs.CL",
        "cs.AI",
        "cs.CE"
      ],
      "primary_category": "cs.CL",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2406.00367v2",
      "published_date": "2024-06-01 08:59:46 UTC",
      "updated_date": "2025-05-15 01:38:21 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-18T14:57:28.702745"
    },
    {
      "arxiv_id": "2406.00348v1",
      "title": "An Effective Weight Initialization Method for Deep Learning: Application to Satellite Image Classification",
      "title_zh": "一种有效的深度学习权重初始化方法：应用于卫星图像分类",
      "authors": [
        "Wadii Boulila",
        "Eman Alshanqiti",
        "Ayyub Alzahem",
        "Anis Koubaa",
        "Nabil Mlaiki"
      ],
      "abstract": "The growing interest in satellite imagery has triggered the need for\nefficient mechanisms to extract valuable information from these vast data\nsources, providing deeper insights. Even though deep learning has shown\nsignificant progress in satellite image classification. Nevertheless, in the\nliterature, only a few results can be found on weight initialization\ntechniques. These techniques traditionally involve initializing the networks'\nweights before training on extensive datasets, distinct from fine-tuning the\nweights of pre-trained networks. In this study, a novel weight initialization\nmethod is proposed in the context of satellite image classification. The\nproposed weight initialization method is mathematically detailed during the\nforward and backward passes of the convolutional neural network (CNN) model.\nExtensive experiments are carried out using six real-world datasets.\nComparative analyses with existing weight initialization techniques made on\nvarious well-known CNN models reveal that the proposed weight initialization\ntechnique outperforms the previous competitive techniques in classification\naccuracy. The complete code of the proposed technique, along with the obtained\nresults, is available at https://github.com/WadiiBoulila/Weight-Initialization",
      "tldr_zh": "这篇论文提出了一种新的权重初始化方法，旨在提升深度学习的性能，特别是应用于卫星图像分类任务。该方法在卷积神经网络 (CNN) 的前向和后向传播中进行了详细的数学描述，并在六个真实数据集上进行了广泛实验。与现有权重初始化技术相比，该方法在各种知名 CNN 模型上实现了更高的分类准确率。代码和结果已在 GitHub 上公开，供进一步验证和使用。",
      "categories": [
        "cs.CV",
        "cs.AI"
      ],
      "primary_category": "cs.CV",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2406.00348v1",
      "published_date": "2024-06-01 07:56:02 UTC",
      "updated_date": "2024-06-01 07:56:02 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-18T14:57:39.253686"
    },
    {
      "arxiv_id": "2406.06556v1",
      "title": "Enhancing Presentation Slide Generation by LLMs with a Multi-Staged End-to-End Approach",
      "title_zh": "翻译失败",
      "authors": [
        "Sambaran Bandyopadhyay",
        "Himanshu Maheshwari",
        "Anandhavelu Natarajan",
        "Apoorv Saxena"
      ],
      "abstract": "Generating presentation slides from a long document with multimodal elements\nsuch as text and images is an important task. This is time consuming and needs\ndomain expertise if done manually. Existing approaches for generating a rich\npresentation from a document are often semi-automatic or only put a flat\nsummary into the slides ignoring the importance of a good narrative. In this\npaper, we address this research gap by proposing a multi-staged end-to-end\nmodel which uses a combination of LLM and VLM. We have experimentally shown\nthat compared to applying LLMs directly with state-of-the-art prompting, our\nproposed multi-staged solution is better in terms of automated metrics and\nhuman evaluation.",
      "tldr_zh": "该研究针对从长文档生成包含文本和图像的多模态演示幻灯片的问题，指出现有方法往往半自动或忽略叙事结构。论文提出一个多阶段端到端模型，结合 LLM（Large Language Models）和 VLM（Vision Language Models），通过逐步处理来提升生成质量。实验结果显示，该方法在自动指标和人工评估中优于直接使用 LLM 的最先进提示技术，从而填补了相关研究空白。",
      "categories": [
        "cs.CL",
        "cs.AI"
      ],
      "primary_category": "cs.CL",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2406.06556v1",
      "published_date": "2024-06-01 07:49:31 UTC",
      "updated_date": "2024-06-01 07:49:31 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-18T14:57:50.621235"
    },
    {
      "arxiv_id": "2406.00332v1",
      "title": "A Structured Review of Literature on Uncertainty in Machine Learning & Deep Learning",
      "title_zh": "机器学习与深度",
      "authors": [
        "Fahimeh Fakour",
        "Ali Mosleh",
        "Ramin Ramezani"
      ],
      "abstract": "The adaptation and use of Machine Learning (ML) in our daily lives has led to\nconcerns in lack of transparency, privacy, reliability, among others. As a\nresult, we are seeing research in niche areas such as interpretability,\ncausality, bias and fairness, and reliability. In this survey paper, we focus\non a critical concern for adaptation of ML in risk-sensitive applications,\nnamely understanding and quantifying uncertainty. Our paper approaches this\ntopic in a structured way, providing a review of the literature in the various\nfacets that uncertainty is enveloped in the ML process. We begin by defining\nuncertainty and its categories (e.g., aleatoric and epistemic), understanding\nsources of uncertainty (e.g., data and model), and how uncertainty can be\nassessed in terms of uncertainty quantification techniques (Ensembles, Bayesian\nNeural Networks, etc.). As part of our assessment and understanding of\nuncertainty in the ML realm, we cover metrics for uncertainty quantification\nfor a single sample, dataset, and metrics for accuracy of the uncertainty\nestimation itself. This is followed by discussions on calibration (model and\nuncertainty), and decision making under uncertainty. Thus, we provide a more\ncomplete treatment of uncertainty: from the sources of uncertainty to the\ndecision-making process. We have focused the review of uncertainty\nquantification methods on Deep Learning (DL), while providing the necessary\nbackground for uncertainty discussion within ML in general. Key contributions\nin this review are broadening the scope of uncertainty discussion, as well as\nan updated review of uncertainty quantification methods in DL.",
      "tldr_zh": "这篇论文对机器学习(ML)和深度学习(DL)中的不确定性进行了结构化的文献综述，重点探讨了不确定性的定义、类别（如 aleatoric 和 epistemic）、来源（如数据和模型）以及量化技术（如 Ensembles 和 Bayesian Neural Networks）。论文还评估了不确定性量化指标、校准方法以及在决策过程中的应用，强调了其在风险敏感应用中的重要性。关键贡献包括扩展不确定性讨论的范围，并为 DL 中的不确定性量化方法提供了更新回顾。",
      "categories": [
        "cs.LG",
        "cs.AI",
        "stat.ML"
      ],
      "primary_category": "cs.LG",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2406.00332v1",
      "published_date": "2024-06-01 07:17:38 UTC",
      "updated_date": "2024-06-01 07:17:38 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-18T14:58:03.638695"
    },
    {
      "arxiv_id": "2406.06555v1",
      "title": "An Evaluation Benchmark for Autoformalization in Lean4",
      "title_zh": "翻译失败",
      "authors": [
        "Aryan Gulati",
        "Devanshu Ladsaria",
        "Shubhra Mishra",
        "Jasdeep Sidhu",
        "Brando Miranda"
      ],
      "abstract": "Large Language Models (LLMs) hold the potential to revolutionize\nautoformalization. The introduction of Lean4, a mathematical programming\nlanguage, presents an unprecedented opportunity to rigorously assess the\nautoformalization capabilities of LLMs. This paper introduces a novel\nevaluation benchmark designed for Lean4, applying it to test the abilities of\nstate-of-the-art LLMs, including GPT-3.5, GPT-4, and Gemini Pro. Our\ncomprehensive analysis reveals that, despite recent advancements, these LLMs\nstill exhibit limitations in autoformalization, particularly in more complex\nareas of mathematics. These findings underscore the need for further\ndevelopment in LLMs to fully harness their potential in scientific research and\ndevelopment. This study not only benchmarks current LLM capabilities but also\nsets the stage for future enhancements in autoformalization.",
      "tldr_zh": "本论文引入了一个针对 Lean4 的自动形式化 (Autoformalization) 评估基准，用于严格评估大语言模型 (LLMs) 的能力。研究者应用此基准测试了 GPT-3.5、GPT-4 和 Gemini Pro 等先进模型，结果显示这些 LLMs 在复杂数学领域仍存在显著局限。总体分析强调了进一步开发 LLMs 的必要性，以充分发挥其在科学研究中的潜力，并为未来自动形式化技术改进提供了基础。",
      "categories": [
        "cs.LG",
        "cs.AI",
        "cs.CL",
        "cs.PL"
      ],
      "primary_category": "cs.LG",
      "comment": "To appear at ICLR 2024 as part of the Tiny Papers track",
      "pdf_url": "http://arxiv.org/pdf/2406.06555v1",
      "published_date": "2024-06-01 07:06:57 UTC",
      "updated_date": "2024-06-01 07:06:57 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-18T14:58:17.135716"
    },
    {
      "arxiv_id": "2406.00324v2",
      "title": "Do's and Don'ts: Learning Desirable Skills with Instruction Videos",
      "title_zh": "翻译失败",
      "authors": [
        "Hyunseung Kim",
        "Byungkun Lee",
        "Hojoon Lee",
        "Dongyoon Hwang",
        "Donghu Kim",
        "Jaegul Choo"
      ],
      "abstract": "Unsupervised skill discovery is a learning paradigm that aims to acquire\ndiverse behaviors without explicit rewards. However, it faces challenges in\nlearning complex behaviors and often leads to learning unsafe or undesirable\nbehaviors. For instance, in various continuous control tasks, current\nunsupervised skill discovery methods succeed in learning basic locomotions like\nstanding but struggle with learning more complex movements such as walking and\nrunning. Moreover, they may acquire unsafe behaviors like tripping and rolling\nor navigate to undesirable locations such as pitfalls or hazardous areas. In\nresponse, we present DoDont (Do's and Don'ts), an instruction-based skill\ndiscovery algorithm composed of two stages. First, in an instruction learning\nstage, DoDont leverages action-free instruction videos to train an instruction\nnetwork to distinguish desirable transitions from undesirable ones. Then, in\nthe skill learning stage, the instruction network adjusts the reward function\nof the skill discovery algorithm to weight the desired behaviors. Specifically,\nwe integrate the instruction network into a distance-maximizing skill discovery\nalgorithm, where the instruction network serves as the distance function.\nEmpirically, with less than 8 instruction videos, DoDont effectively learns\ndesirable behaviors and avoids undesirable ones across complex continuous\ncontrol tasks. Code and videos are available at\nhttps://mynsng.github.io/dodont/",
      "tldr_zh": "这篇论文提出了 DoDont 算法，用于解决无监督技能发现(Unsupervised skill discovery)中难以学习复杂行为并可能产生不安全或不期望行为的问题。算法分为两个阶段：首先，通过无动作指令视频训练一个指令网络，以区分 desirable 和 undesirable 过渡；然后，将该网络集成到基于距离最大化的技能发现算法中，作为距离函数来调整奖励函数，优先权重期望行为。实验结果显示，使用少于 8 个指令视频，DoDont 能在复杂连续控制任务中有效学习 desirable 技能并避免 undesirable 行为。",
      "categories": [
        "cs.LG",
        "cs.AI"
      ],
      "primary_category": "cs.LG",
      "comment": "published at NeurIPS 2024",
      "pdf_url": "http://arxiv.org/pdf/2406.00324v2",
      "published_date": "2024-06-01 06:56:27 UTC",
      "updated_date": "2025-01-23 01:55:45 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-18T14:58:28.548873"
    },
    {
      "arxiv_id": "2406.00314v3",
      "title": "CASE: Efficient Curricular Data Pre-training for Building Assistive Psychology Expert Models",
      "title_zh": "翻译失败",
      "authors": [
        "Sarthak Harne",
        "Monjoy Narayan Choudhury",
        "Madhav Rao",
        "TK Srikanth",
        "Seema Mehrotra",
        "Apoorva Vashisht",
        "Aarushi Basu",
        "Manjit Sodhi"
      ],
      "abstract": "The limited availability of psychologists necessitates efficient\nidentification of individuals requiring urgent mental healthcare. This study\nexplores the use of Natural Language Processing (NLP) pipelines to analyze text\ndata from online mental health forums used for consultations. By analyzing\nforum posts, these pipelines can flag users who may require immediate\nprofessional attention. A crucial challenge in this domain is data privacy and\nscarcity. To address this, we propose utilizing readily available curricular\ntexts used in institutes specializing in mental health for pre-training the NLP\npipelines. This helps us mimic the training process of a psychologist. Our work\npresents CASE-BERT that flags potential mental health disorders based on forum\ntext. CASE-BERT demonstrates superior performance compared to existing methods,\nachieving an f1 score of 0.91 for Depression and 0.88 for Anxiety, two of the\nmost commonly reported mental health disorders. Our code and data are publicly\navailable.",
      "tldr_zh": "该研究针对心理医生短缺问题，提出使用 NLP 管道分析在线心理健康论坛文本，以高效识别需要紧急干预的用户。针对数据隐私和稀缺性挑战，作者引入 curricular texts 作为预训练数据，开发了 CASE-BERT 模型，模仿心理医生的训练过程。实验结果显示，CASE-BERT 在抑郁和焦虑检测上表现出色，分别达到 0.91 和 0.88 的 F1 score，比现有方法更优。该模型的代码和数据已公开可用，为构建辅助心理专家模型提供了新途径。",
      "categories": [
        "cs.CL",
        "cs.AI",
        "cs.LG"
      ],
      "primary_category": "cs.CL",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2406.00314v3",
      "published_date": "2024-06-01 06:17:32 UTC",
      "updated_date": "2024-10-02 17:44:46 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-18T14:58:40.425860"
    },
    {
      "arxiv_id": "2406.02596v2",
      "title": "Slow and Steady Wins the Race: Maintaining Plasticity with Hare and Tortoise Networks",
      "title_zh": "翻译失败",
      "authors": [
        "Hojoon Lee",
        "Hyeonseo Cho",
        "Hyunseung Kim",
        "Donghu Kim",
        "Dugki Min",
        "Jaegul Choo",
        "Clare Lyle"
      ],
      "abstract": "This study investigates the loss of generalization ability in neural\nnetworks, revisiting warm-starting experiments from Ash & Adams. Our empirical\nanalysis reveals that common methods designed to enhance plasticity by\nmaintaining trainability provide limited benefits to generalization. While\nreinitializing the network can be effective, it also risks losing valuable\nprior knowledge. To this end, we introduce the Hare & Tortoise, inspired by the\nbrain's complementary learning system. Hare & Tortoise consists of two\ncomponents: the Hare network, which rapidly adapts to new information\nanalogously to the hippocampus, and the Tortoise network, which gradually\nintegrates knowledge akin to the neocortex. By periodically reinitializing the\nHare network to the Tortoise's weights, our method preserves plasticity while\nretaining general knowledge. Hare & Tortoise can effectively maintain the\nnetwork's ability to generalize, which improves advanced reinforcement learning\nalgorithms on the Atari-100k benchmark. The code is available at\nhttps://github.com/dojeon-ai/hare-tortoise.",
      "tldr_zh": "本研究探讨神经网络的泛化能力（generalization ability）丧失问题，发现常见增强plasticity的方法对泛化帮助有限，而重新初始化虽有效但可能丢失先前知识。为解决此问题，作者提出Hare & Tortoise框架，受脑的互补学习系统启发：Hare网络快速适应新信息（类似海马体），Tortoise网络逐步整合知识（类似新皮层），并通过周期性重新初始化Hare网络来保持plasticity。实验结果显示，该框架显著提升了强化学习算法在Atari-100k基准上的性能，提供了一种平衡适应性和知识保留的新策略。",
      "categories": [
        "cs.LG",
        "cs.AI"
      ],
      "primary_category": "cs.LG",
      "comment": "accepted to ICML 2024",
      "pdf_url": "http://arxiv.org/pdf/2406.02596v2",
      "published_date": "2024-06-01 05:55:15 UTC",
      "updated_date": "2025-02-04 09:13:43 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-18T14:58:52.480010"
    },
    {
      "arxiv_id": "2406.00303v1",
      "title": "Multi-Dimensional Optimization for Text Summarization via Reinforcement Learning",
      "title_zh": "通过强化学习的多维文本摘要优化",
      "authors": [
        "Sangwon Ryu",
        "Heejin Do",
        "Yunsu Kim",
        "Gary Geunbae Lee",
        "Jungseul Ok"
      ],
      "abstract": "The evaluation of summary quality encompasses diverse dimensions such as\nconsistency, coherence, relevance, and fluency. However, existing summarization\nmethods often target a specific dimension, facing challenges in generating\nwell-balanced summaries across multiple dimensions. In this paper, we propose\nmulti-objective reinforcement learning tailored to generate balanced summaries\nacross all four dimensions. We introduce two multi-dimensional optimization\n(MDO) strategies for adaptive learning: 1) MDO_min, rewarding the current\nlowest dimension score, and 2) MDO_pro, optimizing multiple dimensions similar\nto multi-task learning, resolves conflicting gradients across dimensions\nthrough gradient projection. Unlike prior ROUGE-based rewards relying on\nreference summaries, we use a QA-based reward model that aligns with human\npreferences. Further, we discover the capability to regulate the length of\nsummaries by adjusting the discount factor, seeking the generation of concise\nyet informative summaries that encapsulate crucial points. Our approach\nachieved substantial performance gains compared to baseline models on\nrepresentative summarization datasets, particularly in the overlooked\ndimensions.",
      "tldr_zh": "本研究针对文本摘要的多维度评估（如一致性、连贯性、相关性和流畅性），提出了一种多目标强化学习框架，以生成在所有维度上平衡的摘要。论文引入两种多维度优化（MDO）策略：MDO_min 通过奖励当前最低维度分数来提升弱项，以及 MDO_pro 类似于多任务学习，通过梯度投影解决维度间冲突梯度。不同于依赖参考摘要的 ROUGE-based 奖励，该方法采用基于 QA 的奖励模型，以更好地对齐人类偏好；此外，通过调整折扣因子，可以调节摘要长度以实现简洁且信息丰富的输出。在代表性数据集上，该方法相较基线模型取得了显著性能提升，尤其在以往被忽略的维度上。",
      "categories": [
        "cs.CL",
        "cs.AI"
      ],
      "primary_category": "cs.CL",
      "comment": "ACL 2024",
      "pdf_url": "http://arxiv.org/pdf/2406.00303v1",
      "published_date": "2024-06-01 05:15:12 UTC",
      "updated_date": "2024-06-01 05:15:12 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-18T14:59:04.245868"
    },
    {
      "arxiv_id": "2406.10236v1",
      "title": "Lightening Anything in Medical Images",
      "title_zh": "翻译失败",
      "authors": [
        "Ben Fei",
        "Yixuan Li",
        "Weidong Yang",
        "Hengjun Gao",
        "Jingyi Xu",
        "Lipeng Ma",
        "Yatian Yang",
        "Pinghong Zhou"
      ],
      "abstract": "The development of medical imaging techniques has made a significant\ncontribution to clinical decision-making. However, the existence of suboptimal\nimaging quality, as indicated by irregular illumination or imbalanced\nintensity, presents significant obstacles in automating disease screening,\nanalysis, and diagnosis. Existing approaches for natural image enhancement are\nmostly trained with numerous paired images, presenting challenges in data\ncollection and training costs, all while lacking the ability to generalize\neffectively. Here, we introduce a pioneering training-free Diffusion Model for\nUniversal Medical Image Enhancement, named UniMIE. UniMIE demonstrates its\nunsupervised enhancement capabilities across various medical image modalities\nwithout the need for any fine-tuning. It accomplishes this by relying solely on\na single pre-trained model from ImageNet. We conduct a comprehensive evaluation\non 13 imaging modalities and over 15 medical types, demonstrating better\nqualities, robustness, and accuracy than other modality-specific and\ndata-inefficient models. By delivering high-quality enhancement and\ncorresponding accuracy downstream tasks across a wide range of tasks, UniMIE\nexhibits considerable potential to accelerate the advancement of diagnostic\ntools and customized treatment plans.",
      "tldr_zh": "本研究针对医疗图像中不规则照明和强度不平衡等问题，提出了一种创新的训练-free Diffusion Model，名为UniMIE，用于通用医疗图像增强。该模型无需任何微调，仅依赖于一个从ImageNet预训练的单一模型，即可实现对多种图像模态的 unsupervised 增强。实验在13种图像模态和超过15种医疗类型上进行评估，UniMIE显示出比其他模态特定或数据密集型模型更优的质量、鲁棒性和下游任务准确性，从而加速了诊断工具和个性化治疗计划的发展。",
      "categories": [
        "eess.IV",
        "cs.AI"
      ],
      "primary_category": "eess.IV",
      "comment": "23 pages, 6 figures",
      "pdf_url": "http://arxiv.org/pdf/2406.10236v1",
      "published_date": "2024-06-01 05:07:50 UTC",
      "updated_date": "2024-06-01 05:07:50 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-18T14:59:15.626942"
    },
    {
      "arxiv_id": "2406.04371v2",
      "title": "Phased Instruction Fine-Tuning for Large Language Models",
      "title_zh": "翻译失败",
      "authors": [
        "Wei Pang",
        "Chuan Zhou",
        "Xiao-Hua Zhou",
        "Xiaojie Wang"
      ],
      "abstract": "Instruction Fine-Tuning enhances pre-trained language models from basic\nnext-word prediction to complex instruction-following. However, existing\nOne-off Instruction Fine-Tuning (One-off IFT) method, applied on a diverse\ninstruction, may not effectively boost models' adherence to instructions due to\nthe simultaneous handling of varying instruction complexities. To improve this,\nPhased Instruction Fine-Tuning (Phased IFT) is proposed, based on the idea that\nlearning to follow instructions is a gradual process. It assesses instruction\ndifficulty using GPT-4, divides the instruction data into subsets of increasing\ndifficulty, and uptrains the model sequentially on these subsets. Experiments\nwith Llama-2 7B/13B/70B, Llama3 8/70B and Mistral-7B models using Alpaca data\nshow that Phased IFT significantly outperforms One-off IFT, supporting the\nprogressive alignment hypothesis and providing a simple and efficient way to\nenhance large language models. Codes and datasets from our experiments are\nfreely available at https://github.com/xubuvd/PhasedSFT.",
      "tldr_zh": "该论文提出 Phased Instruction Fine-Tuning (Phased IFT) 方法，以提升大型语言模型从基本下一词预测到复杂指令跟随的能力，解决现有 One-off Instruction Fine-Tuning (One-off IFT) 在处理多样指令复杂性时的不足。Phased IFT 基于渐进学习理念，使用 GPT-4 评估指令难度，将指令数据分成递增难度的子集，并顺序训练模型。实验在 Llama-2 7B/13B/70B、Llama3 8/70B 和 Mistral-7B 模型上使用 Alpaca 数据显示，Phased IFT 显著优于 One-off IFT，支持渐进对齐假设，并提供了一种简单高效的模型增强方式。代码和数据集已在 GitHub 开源。",
      "categories": [
        "cs.CL",
        "cs.AI"
      ],
      "primary_category": "cs.CL",
      "comment": "The final version, to be appear at ACL 2024 Findings",
      "pdf_url": "http://arxiv.org/pdf/2406.04371v2",
      "published_date": "2024-06-01 04:25:26 UTC",
      "updated_date": "2024-06-16 21:20:29 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-18T14:59:30.011890"
    },
    {
      "arxiv_id": "2406.18565v1",
      "title": "Pseudo-label Based Domain Adaptation for Zero-Shot Text Steganalysis",
      "title_zh": "翻译失败",
      "authors": [
        "Yufei Luo",
        "Zhen Yang",
        "Ru Zhang",
        "Jianyi Liu"
      ],
      "abstract": "Currently, most methods for text steganalysis are based on deep neural\nnetworks (DNNs). However, in real-life scenarios, obtaining a sufficient amount\nof labeled stego-text for correctly training networks using a large number of\nparameters is often challenging and costly. Additionally, due to a phenomenon\nknown as dataset bias or domain shift, recognition models trained on a large\ndataset exhibit poor generalization performance on novel datasets and tasks.\nTherefore, to address the issues of missing labeled data and inadequate model\ngeneralization in text steganalysis, this paper proposes a cross-domain\nstego-text analysis method (PDTS) based on pseudo-labeling and domain\nadaptation (unsupervised learning). Specifically, we propose a model\narchitecture combining pre-trained BERT with a single-layer Bi-LSTM to learn\nand extract generic features across tasks and generate task-specific\nrepresentations. Considering the differential contributions of different\nfeatures to steganalysis, we further design a feature filtering mechanism to\nachieve selective feature propagation, thereby enhancing classification\nperformance. We train the model using labeled source domain data and adapt it\nto target domain data distribution using pseudo-labels for unlabeled target\ndomain data through self-training. In the label estimation step, instead of\nusing a static sampling strategy, we propose a progressive sampling strategy to\ngradually increase the number of selected pseudo-label candidates. Experimental\nresults demonstrate that our method performs well in zero-shot text\nsteganalysis tasks, achieving high detection accuracy even in the absence of\nlabeled data in the target domain, and outperforms current zero-shot text\nsteganalysis methods.",
      "tldr_zh": "本论文针对文本隐写分析面临的标记数据缺失和模型泛化性差的问题，提出了一种基于伪标签（Pseudo-label）和领域适配（Domain Adaptation）的跨域方法PDTS，用于零样本（Zero-Shot）文本隐写分析。方法结合预训练BERT和单层Bi-LSTM来提取通用特征并生成任务特定表示，同时引入特征过滤机制以选择性地传播关键特征，提升分类性能。训练过程利用源域标记数据进行自训练，并通过渐进式采样策略逐步优化伪标签的选取，使模型适应无标记目标域。实验结果显示，该方法在零样本任务中实现高检测准确率，显著优于现有方法。",
      "categories": [
        "cs.CV",
        "cs.AI"
      ],
      "primary_category": "cs.CV",
      "comment": "The 30th International Conference on Computational & Experimental\n  Engineering and Sciences (ICCES2024)",
      "pdf_url": "http://arxiv.org/pdf/2406.18565v1",
      "published_date": "2024-06-01 04:19:07 UTC",
      "updated_date": "2024-06-01 04:19:07 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-18T14:59:41.047724"
    },
    {
      "arxiv_id": "2406.00291v2",
      "title": "Multi-Objective Neural Architecture Search by Learning Search Space Partitions",
      "title_zh": "翻译失败",
      "authors": [
        "Yiyang Zhao",
        "Linnan Wang",
        "Tian Guo"
      ],
      "abstract": "Deploying deep learning models requires taking into consideration neural\nnetwork metrics such as model size, inference latency, and #FLOPs, aside from\ninference accuracy. This results in deep learning model designers leveraging\nmulti-objective optimization to design effective deep neural networks in\nmultiple criteria. However, applying multi-objective optimizations to neural\narchitecture search (NAS) is nontrivial because NAS tasks usually have a huge\nsearch space, along with a non-negligible searching cost. This requires\neffective multi-objective search algorithms to alleviate the GPU costs. In this\nwork, we implement a novel multi-objectives optimizer based on a recently\nproposed meta-algorithm called LaMOO on NAS tasks. In a nutshell, LaMOO\nspeedups the search process by learning a model from observed samples to\npartition the search space and then focusing on promising regions likely to\ncontain a subset of the Pareto frontier. Using LaMOO, we observe an improvement\nof more than 200% sample efficiency compared to Bayesian optimization and\nevolutionary-based multi-objective optimizers on different NAS datasets. For\nexample, when combined with LaMOO, qEHVI achieves a 225% improvement in sample\nefficiency compared to using qEHVI alone in NasBench201. For real-world tasks,\nLaMOO achieves 97.36% accuracy with only 1.62M #Params on CIFAR10 in only 600\nsearch samples. On ImageNet, our large model reaches 80.4% top-1 accuracy with\nonly 522M #FLOPs.",
      "tldr_zh": "该论文提出了一种基于学习搜索空间分区的多目标神经架构搜索（Multi-Objective Neural Architecture Search）方法，旨在优化深度学习模型的准确性、模型大小、推理延迟和 #FLOPs 等指标。核心方法利用 LaMOO 算法，通过从观察样本中学习模型来分区搜索空间，并聚焦于可能包含 Pareto frontier 的高潜力区域，从而显著提高搜索效率。实验结果显示，LaMOO 与 qEHVI 结合时，在 NasBench201 数据集上样本效率提升 225%，而在实际任务中，仅用 600 个搜索样本即在 CIFAR10 上达到 97.36% 准确率和 1.62M #Params，在 ImageNet 上实现 80.4% top-1 准确率和 522M #FLOPs。",
      "categories": [
        "cs.LG",
        "cs.AI"
      ],
      "primary_category": "cs.LG",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2406.00291v2",
      "published_date": "2024-06-01 03:51:34 UTC",
      "updated_date": "2024-07-18 01:53:35 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-18T14:59:55.146717"
    },
    {
      "arxiv_id": "2406.00287v1",
      "title": "GenPalm: Contactless Palmprint Generation with Diffusion Models",
      "title_zh": "GenPalm：基于扩散模型的无接触掌纹生成",
      "authors": [
        "Steven A. Grosz",
        "Anil K. Jain"
      ],
      "abstract": "The scarcity of large-scale palmprint databases poses a significant\nbottleneck to advancements in contactless palmprint recognition. To address\nthis, researchers have turned to synthetic data generation. While Generative\nAdversarial Networks (GANs) have been widely used, they suffer from instability\nand mode collapse. Recently, diffusion probabilistic models have emerged as a\npromising alternative, offering stable training and better distribution\ncoverage. This paper introduces a novel palmprint generation method using\ndiffusion probabilistic models, develops an end-to-end framework for\nsynthesizing multiple palm identities, and validates the realism and utility of\nthe generated palmprints. Experimental results demonstrate the effectiveness of\nour approach in generating palmprint images which enhance contactless palmprint\nrecognition performance across several test databases utilizing challenging\ncross-database and time-separated evaluation protocols.",
      "tldr_zh": "该论文针对大规模掌纹数据库短缺的问题，提出了一种基于Diffusion Models的掌纹生成方法，以克服Generative Adversarial Networks (GANs)的训练不稳定和模式崩溃问题。研究团队开发了一个端到端框架，用于合成多个掌纹身份，并通过实验验证了生成图像的真实性和实用性。结果显示，该方法显著提升了无接触掌纹识别的性能，在多个测试数据库上，通过跨数据库和时间分离评估协议，实现了更好的识别效果。",
      "categories": [
        "cs.CV",
        "cs.AI"
      ],
      "primary_category": "cs.CV",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2406.00287v1",
      "published_date": "2024-06-01 03:33:25 UTC",
      "updated_date": "2024-06-01 03:33:25 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-18T15:00:05.531095"
    },
    {
      "arxiv_id": "2406.00281v1",
      "title": "Cross-Table Pretraining towards a Universal Function Space for Heterogeneous Tabular Data",
      "title_zh": "翻译失败",
      "authors": [
        "Jintai Chen",
        "Zhen Lin",
        "Qiyuan Chen",
        "Jimeng Sun"
      ],
      "abstract": "Tabular data from different tables exhibit significant diversity due to\nvaried definitions and types of features, as well as complex inter-feature and\nfeature-target relationships. Cross-dataset pretraining, which learns reusable\npatterns from upstream data to support downstream tasks, have shown notable\nsuccess in various fields. Yet, when applied to tabular data prediction, this\nparadigm faces challenges due to the limited reusable patterns among diverse\ntabular datasets (tables) and the general scarcity of tabular data available\nfor fine-tuning. In this study, we fill this gap by introducing a cross-table\npretrained Transformer, XTFormer, for versatile downstream tabular prediction\ntasks. Our methodology insight is pretraining XTFormer to establish a\n\"meta-function\" space that encompasses all potential feature-target mappings.\nIn pre-training, a variety of potential mappings are extracted from\npre-training tabular datasets and are embedded into the \"meta-function\" space,\nand suited mappings are extracted from the \"meta-function\" space for downstream\ntasks by a specified coordinate positioning approach. Experiments show that, in\n190 downstream tabular prediction tasks, our cross-table pretrained XTFormer\nwins both XGBoost and Catboost on 137 (72%) tasks, and surpasses representative\ndeep learning models FT-Transformer and the tabular pre-training approach XTab\non 144 (76%) and 162 (85%) tasks.",
      "tldr_zh": "该研究针对异构表格数据的多样性（如不同特征定义和复杂关系），提出了XTFormer，一种跨表预训练Transformer模型。核心方法是通过预训练建立一个“meta-function space”，从中提取各种特征-目标映射，并使用坐标定位方法适应下游预测任务，从而解决传统预训练在表格数据上的局限性。实验结果显示，在190个下游任务中，XTFormer优于XGBoost和CatBoost的72%，并分别超越FT-Transformer和XTab的76%及85%。",
      "categories": [
        "cs.LG",
        "cs.AI"
      ],
      "primary_category": "cs.LG",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2406.00281v1",
      "published_date": "2024-06-01 03:24:31 UTC",
      "updated_date": "2024-06-01 03:24:31 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-18T15:00:17.743022"
    },
    {
      "arxiv_id": "2406.02594v1",
      "title": "Graph Neural Networks for Brain Graph Learning: A Survey",
      "title_zh": "翻译失败",
      "authors": [
        "Xuexiong Luo",
        "Jia Wu",
        "Jian Yang",
        "Shan Xue",
        "Amin Beheshti",
        "Quan Z. Sheng",
        "David McAlpine",
        "Paul Sowman",
        "Alexis Giral",
        "Philip S. Yu"
      ],
      "abstract": "Exploring the complex structure of the human brain is crucial for\nunderstanding its functionality and diagnosing brain disorders. Thanks to\nadvancements in neuroimaging technology, a novel approach has emerged that\ninvolves modeling the human brain as a graph-structured pattern, with different\nbrain regions represented as nodes and the functional relationships among these\nregions as edges. Moreover, graph neural networks (GNNs) have demonstrated a\nsignificant advantage in mining graph-structured data. Developing GNNs to learn\nbrain graph representations for brain disorder analysis has recently gained\nincreasing attention. However, there is a lack of systematic survey work\nsummarizing current research methods in this domain. In this paper, we aim to\nbridge this gap by reviewing brain graph learning works that utilize GNNs. We\nfirst introduce the process of brain graph modeling based on common\nneuroimaging data. Subsequently, we systematically categorize current works\nbased on the type of brain graph generated and the targeted research problems.\nTo make this research accessible to a broader range of interested researchers,\nwe provide an overview of representative methods and commonly used datasets,\nalong with their implementation sources. Finally, we present our insights on\nfuture research directions. The repository of this survey is available at\n\\url{https://github.com/XuexiongLuoMQ/Awesome-Brain-Graph-Learning-with-GNNs}.",
      "tldr_zh": "这篇论文对使用图神经网络（GNNs）进行脑图学习的领域进行了系统性调查，旨在填补现有研究的总结空白。论文首先介绍了基于神经影像数据构建脑图的过程，将脑区作为节点、功能关系作为边。随后，它根据脑图类型和研究问题对当前工作进行分类，并概述了代表性方法、常用数据集及其实现来源。最后，论文提供了未来研究方向，并分享了相关GitHub仓库（https://github.com/XuexiongLuoMQ/Awesome-Brain-Graph-Learning-with-GNNs），强调GNNs在脑部疾病分析中的潜力。",
      "categories": [
        "cs.LG",
        "cs.AI",
        "68T07 (Primary) 68T30 (Secondary)"
      ],
      "primary_category": "cs.LG",
      "comment": "9 pages, 2 figures, IJCAI-2024",
      "pdf_url": "http://arxiv.org/pdf/2406.02594v1",
      "published_date": "2024-06-01 02:47:39 UTC",
      "updated_date": "2024-06-01 02:47:39 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-18T15:00:29.680555"
    },
    {
      "arxiv_id": "2406.00276v1",
      "title": "Non-destructive Degradation Pattern Decoupling for Ultra-early Battery Prototype Verification Using Physics-informed Machine Learning",
      "title_zh": "翻译失败",
      "authors": [
        "Shengyu Tao",
        "Mengtian Zhang",
        "Zixi Zhao",
        "Haoyang Li",
        "Ruifei Ma",
        "Yunhong Che",
        "Xin Sun",
        "Lin Su",
        "Xiangyu Chen",
        "Zihao Zhou",
        "Heng Chang",
        "Tingwei Cao",
        "Xiao Xiao",
        "Yaojun Liu",
        "Wenjun Yu",
        "Zhongling Xu",
        "Yang Li",
        "Han Hao",
        "Xuan Zhang",
        "Xiaosong Hu",
        "Guangmin ZHou"
      ],
      "abstract": "Manufacturing complexities and uncertainties have impeded the transition from\nmaterial prototypes to commercial batteries, making prototype verification\ncritical to quality assessment. A fundamental challenge involves deciphering\nintertwined chemical processes to characterize degradation patterns and their\nquantitative relationship with battery performance. Here we show that a\nphysics-informed machine learning approach can quantify and visualize\ntemporally resolved losses concerning thermodynamics and kinetics only using\nelectric signals. Our method enables non-destructive degradation pattern\ncharacterization, expediting temperature-adaptable predictions of entire\nlifetime trajectories, rather than end-of-life points. The verification speed\nis 25 times faster yet maintaining 95.1% accuracy across temperatures. Such\nadvances facilitate more sustainable management of defective prototypes before\nmassive production, establishing a 19.76 billion USD scrap material recycling\nmarket by 2060 in China. By incorporating stepwise charge acceptance as a\nmeasure of the initial manufacturing variability of normally identical\nbatteries, we can immediately identify long-term degradation variations. We\nattribute the predictive power to interpreting machine learning insights using\nmaterial-agnostic featurization taxonomy for degradation pattern decoupling.\nOur findings offer new possibilities for dynamic system analysis, such as\nbattery prototype degradation, demonstrating that complex pattern evolutions\ncan be accurately predicted in a non-destructive and data-driven fashion by\nintegrating physics-informed machine learning.",
      "tldr_zh": "本研究提出了一种基于物理信息机器学习(physics-informed machine learning)的非破坏性退化模式解耦(degradation pattern decoupling)方法，用于超早期电池原型验证。该方法仅使用电信号量化并可视化与热力学和动力学相关的时序损失，实现对退化模式的表征，并加速温度适应性的整个寿命轨迹预测，而非仅限于寿命终点。实验显示，该方法验证速度比传统方法快25倍，同时保持95.1%的准确率，并能立即识别长期退化变异，促进缺陷原型的可持续管理，预计到2060年在中国建立19.76亿美元的废料回收市场。该创新通过材料无关的特征化分类学(material-agnostic featurization taxonomy)解读机器学习洞见，为电池动态系统分析提供非破坏性和数据驱动的新可能性。",
      "categories": [
        "cs.LG",
        "cs.AI",
        "cs.CE",
        "physics.data-an",
        "J.2; G.3"
      ],
      "primary_category": "cs.LG",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2406.00276v1",
      "published_date": "2024-06-01 02:43:41 UTC",
      "updated_date": "2024-06-01 02:43:41 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-18T15:00:43.325912"
    },
    {
      "arxiv_id": "2406.04370v3",
      "title": "Large Language Model Confidence Estimation via Black-Box Access",
      "title_zh": "翻译失败",
      "authors": [
        "Tejaswini Pedapati",
        "Amit Dhurandhar",
        "Soumya Ghosh",
        "Soham Dan",
        "Prasanna Sattigeri"
      ],
      "abstract": "Estimating uncertainty or confidence in the responses of a model can be\nsignificant in evaluating trust not only in the responses, but also in the\nmodel as a whole. In this paper, we explore the problem of estimating\nconfidence for responses of large language models (LLMs) with simply black-box\nor query access to them. We propose a simple and extensible framework where, we\nengineer novel features and train a (interpretable) model (viz. logistic\nregression) on these features to estimate the confidence. We empirically\ndemonstrate that our simple framework is effective in estimating confidence of\nFlan-ul2, Llama-13b, Mistral-7b and GPT-4 on four benchmark Q\\&A tasks as well\nas of Pegasus-large and BART-large on two benchmark summarization tasks with it\nsurpassing baselines by even over $10\\%$ (on AUROC) in some cases.\nAdditionally, our interpretable approach provides insight into features that\nare predictive of confidence, leading to the interesting and useful discovery\nthat our confidence models built for one LLM generalize zero-shot across others\non a given dataset.",
      "tldr_zh": "本研究探讨了通过黑-box access 估计大型语言模型（LLMs）响应置信度的问题，以评估模型的可靠性和信任度。研究提出一个简单可扩展的框架，通过工程新型特征并训练可解释模型（如 logistic regression），来有效估计置信度。实验结果显示，该框架在 Flan-ul2、Llama-13b、Mistral-7b 和 GPT-4 的 Q&A 任务，以及 Pegasus-large 和 BART-large 的摘要任务上，超过了基线模型，在 AUROC 上某些情况下提高了超过 10%。此外，该方法揭示了预测置信度的关键特征，并发现为一个 LLM 构建的置信度模型可零-shot 泛化到其他模型。",
      "categories": [
        "cs.CL",
        "cs.AI",
        "cs.LG"
      ],
      "primary_category": "cs.CL",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2406.04370v3",
      "published_date": "2024-06-01 02:08:44 UTC",
      "updated_date": "2025-02-20 18:42:41 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-18T15:00:54.293058"
    },
    {
      "arxiv_id": "2406.00262v2",
      "title": "Contrastive Learning Via Equivariant Representation",
      "title_zh": "基于等变表示的对比学习",
      "authors": [
        "Sifan Song",
        "Jinfeng Wang",
        "Qiaochu Zhao",
        "Xiang Li",
        "Dufan Wu",
        "Angelos Stefanidis",
        "Jionglong Su",
        "S. Kevin Zhou",
        "Quanzheng Li"
      ],
      "abstract": "Invariant Contrastive Learning (ICL) methods have achieved impressive\nperformance across various domains. However, the absence of latent space\nrepresentation for distortion (augmentation)-related information in the latent\nspace makes ICL sub-optimal regarding training efficiency and robustness in\ndownstream tasks. Recent studies suggest that introducing equivariance into\nContrastive Learning (CL) can improve overall performance. In this paper, we\nrevisit the roles of augmentation strategies and equivariance in improving CL's\nefficacy. We propose CLeVER (Contrastive Learning Via Equivariant\nRepresentation), a novel equivariant contrastive learning framework compatible\nwith augmentation strategies of arbitrary complexity for various mainstream CL\nbackbone models. Experimental results demonstrate that CLeVER effectively\nextracts and incorporates equivariant information from practical natural\nimages, thereby improving the training efficiency and robustness of baseline\nmodels in downstream tasks and achieving state-of-the-art (SOTA) performance.\nMoreover, we find that leveraging equivariant information extracted by CLeVER\nsimultaneously enhances rotational invariance and sensitivity across\nexperimental tasks, and helps stabilize the framework when handling complex\naugmentations, particularly for models with small-scale backbones.",
      "tldr_zh": "本研究发现，Invariant Contrastive Learning (ICL) 虽然在多个领域表现出色，但由于潜在空间缺乏对 augmentation 相关信息的表示，导致训练效率和下游任务鲁棒性不足。为解决这一问题，作者提出 CLeVER（Contrastive Learning Via Equivariant Representation），一个新型 equivariant contrastive learning 框架，能兼容任意复杂度的 augmentation 策略并适用于主流 CL 骨干模型。实验结果显示，CLeVER 有效提取并整合 equivariant 信息，提高了基线模型的训练效率和鲁棒性，实现了 state-of-the-art (SOTA) 性能。此外，该框架还增强了旋转不变性和敏感性，并稳定处理复杂 augmentation，尤其适用于小规模骨干模型。",
      "categories": [
        "cs.LG",
        "cs.AI"
      ],
      "primary_category": "cs.LG",
      "comment": "Preprint. Under review",
      "pdf_url": "http://arxiv.org/pdf/2406.00262v2",
      "published_date": "2024-06-01 01:53:51 UTC",
      "updated_date": "2024-10-10 15:49:44 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-18T15:01:07.847904"
    },
    {
      "arxiv_id": "2406.00258v1",
      "title": "Artemis: Towards Referential Understanding in Complex Videos",
      "title_zh": "翻译失败",
      "authors": [
        "Jihao Qiu",
        "Yuan Zhang",
        "Xi Tang",
        "Lingxi Xie",
        "Tianren Ma",
        "Pengyu Yan",
        "David Doermann",
        "Qixiang Ye",
        "Yunjie Tian"
      ],
      "abstract": "Videos carry rich visual information including object description, action,\ninteraction, etc., but the existing multimodal large language models (MLLMs)\nfell short in referential understanding scenarios such as video-based\nreferring. In this paper, we present Artemis, an MLLM that pushes video-based\nreferential understanding to a finer level. Given a video, Artemis receives a\nnatural-language question with a bounding box in any video frame and describes\nthe referred target in the entire video. The key to achieving this goal lies in\nextracting compact, target-specific video features, where we set a solid\nbaseline by tracking and selecting spatiotemporal features from the video. We\ntrain Artemis on the newly established VideoRef45K dataset with 45K video-QA\npairs and design a computationally efficient, three-stage training procedure.\nResults are promising both quantitatively and qualitatively. Additionally, we\nshow that \\model can be integrated with video grounding and text summarization\ntools to understand more complex scenarios. Code and data are available at\nhttps://github.com/qiujihao19/Artemis.",
      "tldr_zh": "论文提出 Artemis，这是一个多模态大型语言模型 (MLLMs)，旨在提升复杂视频中的参考理解能力，能够接收视频、自然语言问题和视频帧中的 bounding box，并描述整个视频中被引用的目标。核心方法包括提取紧凑的、目标特定的视频特征，通过跟踪和选择时空特征作为基线，并在新建立的 VideoRef45K 数据集（包含 45K 视频-QA 对）上采用计算高效的三阶段训练程序。实验结果显示，Artemis 在定性和定量上表现出色，并可与视频 grounding 和 text summarization 工具整合，以处理更复杂的场景。",
      "categories": [
        "cs.CV",
        "cs.AI"
      ],
      "primary_category": "cs.CV",
      "comment": "19 pages, 14 figures. Code and data are available at\n  https://github.com/qiujihao19/Artemis",
      "pdf_url": "http://arxiv.org/pdf/2406.00258v1",
      "published_date": "2024-06-01 01:43:56 UTC",
      "updated_date": "2024-06-01 01:43:56 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-18T15:01:18.470728"
    },
    {
      "arxiv_id": "2406.00252v6",
      "title": "Towards Rationality in Language and Multimodal Agents: A Survey",
      "title_zh": "翻译失败",
      "authors": [
        "Bowen Jiang",
        "Yangxinyu Xie",
        "Xiaomeng Wang",
        "Yuan Yuan",
        "Zhuoqun Hao",
        "Xinyi Bai",
        "Weijie J. Su",
        "Camillo J. Taylor",
        "Tanwi Mallick"
      ],
      "abstract": "This work discusses how to build more rational language and multimodal agents\nand what criteria define rationality in intelligent systems. Rationality is the\nquality of being guided by reason, characterized by decision-making that aligns\nwith evidence and logical principles. It plays a crucial role in reliable\nproblem-solving by ensuring well-grounded and consistent solutions. Despite\ntheir progress, large language models (LLMs) often fall short of rationality\ndue to their bounded knowledge space and inconsistent outputs. In response,\nrecent efforts have shifted toward developing multimodal and multi-agent\nsystems, as well as integrating modules like external tools, programming codes,\nsymbolic reasoners, utility function, and conformal risk controls rather than\nrelying solely on a single LLM for decision-making. This paper surveys\nstate-of-the-art advancements in language and multimodal agents, assesses their\nrole in enhancing rationality, and outlines open challenges and future research\ndirections. We maintain an open repository at\nhttps://github.com/bowen-upenn/Agent_Rationality.",
      "tldr_zh": "这篇调查论文探讨了如何构建更理性的语言和多模态 agents，以及理性在智能系统中的定义标准，即基于证据和逻辑原则的决策。论文指出，LLMs 由于知识空间有限和输出不一致等问题，常缺乏理性，因此最近的研究转向开发多模态和多代理系统，并整合外部工具、编程代码、符号推理器和风险控制模块。作者评估了这些进展在提升理性方面的作用，并概述了开放挑战和未来研究方向，同时提供了一个开源仓库（https://github.com/bowen-upenn/Agent_Rationality）。",
      "categories": [
        "cs.AI",
        "cs.CL",
        "cs.CV",
        "cs.MA"
      ],
      "primary_category": "cs.AI",
      "comment": "This paper has been accepted to the NAACL 2025 Main",
      "pdf_url": "http://arxiv.org/pdf/2406.00252v6",
      "published_date": "2024-06-01 01:17:25 UTC",
      "updated_date": "2025-02-16 05:30:30 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-18T15:01:30.346859"
    },
    {
      "arxiv_id": "2406.00247v2",
      "title": "Large Language Models for Relevance Judgment in Product Search",
      "title_zh": "大型语言模型用于产品搜索的相关性判断",
      "authors": [
        "Navid Mehrdad",
        "Hrushikesh Mohapatra",
        "Mossaab Bagdouri",
        "Prijith Chandran",
        "Alessandro Magnani",
        "Xunfan Cai",
        "Ajit Puthenputhussery",
        "Sachin Yadav",
        "Tony Lee",
        "ChengXiang Zhai",
        "Ciya Liao"
      ],
      "abstract": "High relevance of retrieved and re-ranked items to the search query is the\ncornerstone of successful product search, yet measuring relevance of items to\nqueries is one of the most challenging tasks in product information retrieval,\nand quality of product search is highly influenced by the precision and scale\nof available relevance-labelled data. In this paper, we present an array of\ntechniques for leveraging Large Language Models (LLMs) for automating the\nrelevance judgment of query-item pairs (QIPs) at scale. Using a unique dataset\nof multi-million QIPs, annotated by human evaluators, we test and optimize\nhyper parameters for finetuning billion-parameter LLMs with and without Low\nRank Adaption (LoRA), as well as various modes of item attribute concatenation\nand prompting in LLM finetuning, and consider trade offs in item attribute\ninclusion for quality of relevance predictions. We demonstrate considerable\nimprovement over baselines of prior generations of LLMs, as well as\noff-the-shelf models, towards relevance annotations on par with the human\nrelevance evaluators. Our findings have immediate implications for the growing\nfield of relevance judgment automation in product search.",
      "tldr_zh": "本研究探讨了使用大型语言模型 (LLMs) 来自动化产品搜索中查询-物品对 (QIPs) 的相关性判断，以解决标注数据规模和精度的挑战。研究团队通过一个包含数百万 QIPs 的数据集，优化了 LLMs 的微调参数，包括使用 Low Rank Adaption (LoRA)，并测试了物品属性连接和提示策略的各种组合。结果显示，该方法显著超过了先前基线模型和现成 LLMs 的性能，实现了接近人类评估者的相关性预测水平。该发现为产品搜索的相关性判断自动化提供了重要的新途径。",
      "categories": [
        "cs.IR",
        "cs.AI",
        "H.3.3; I.2.7"
      ],
      "primary_category": "cs.IR",
      "comment": "10 pages, 1 figure, 11 tables - SIGIR 2024, LLM4Eval",
      "pdf_url": "http://arxiv.org/pdf/2406.00247v2",
      "published_date": "2024-06-01 00:52:41 UTC",
      "updated_date": "2024-07-16 18:01:55 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-18T15:01:40.852889"
    },
    {
      "arxiv_id": "2406.01624v2",
      "title": "Unveiling Hidden Factors: Explainable AI for Feature Boosting in Speech Emotion Recognition",
      "title_zh": "翻译失败",
      "authors": [
        "Alaa Nfissi",
        "Wassim Bouachir",
        "Nizar Bouguila",
        "Brian Mishara"
      ],
      "abstract": "Speech emotion recognition (SER) has gained significant attention due to its\nseveral application fields, such as mental health, education, and\nhuman-computer interaction. However, the accuracy of SER systems is hindered by\nhigh-dimensional feature sets that may contain irrelevant and redundant\ninformation. To overcome this challenge, this study proposes an iterative\nfeature boosting approach for SER that emphasizes feature relevance and\nexplainability to enhance machine learning model performance. Our approach\ninvolves meticulous feature selection and analysis to build efficient SER\nsystems. In addressing our main problem through model explainability, we employ\na feature evaluation loop with Shapley values to iteratively refine feature\nsets. This process strikes a balance between model performance and\ntransparency, which enables a comprehensive understanding of the model's\npredictions. The proposed approach offers several advantages, including the\nidentification and removal of irrelevant and redundant features, leading to a\nmore effective model. Additionally, it promotes explainability, facilitating\ncomprehension of the model's predictions and the identification of crucial\nfeatures for emotion determination. The effectiveness of the proposed method is\nvalidated on the SER benchmarks of the Toronto emotional speech set (TESS),\nBerlin Database of Emotional Speech (EMO-DB), Ryerson Audio-Visual Database of\nEmotional Speech and Song (RAVDESS), and Surrey Audio-Visual Expressed Emotion\n(SAVEE) datasets, outperforming state-of-the-art methods. To the best of our\nknowledge, this is the first work to incorporate model explainability into an\nSER framework. The source code of this paper is publicly available via this\nhttps://github.com/alaaNfissi/Unveiling-Hidden-Factors-Explainable-AI-for-Feature-Boosting-in-Speech-Emotion-Recognition.",
      "tldr_zh": "这篇论文针对语音情感识别(SER)中高维特征集的无关和冗余信息问题，提出了一种迭代特征提升方法，利用Shapley values进行特征评估循环，以优化特征选择并提升模型性能和可解释性。该方法不仅提高了模型的准确性和透明度，还便于理解关键特征在情感预测中的作用。实验在TESS、EMO-DB、RAVDESS和SAVEE数据集上验证，表现优于现有方法。这是首次将模型可解释性整合到SER框架中，源码已开源以促进进一步研究。",
      "categories": [
        "eess.AS",
        "cs.AI",
        "cs.CL",
        "cs.LG",
        "cs.SD",
        "I.2.7; I.2.6; I.2.1; I.2.8"
      ],
      "primary_category": "eess.AS",
      "comment": "Published in: Springer Nature International Journal of Applied\n  Intelligence (2024)",
      "pdf_url": "http://arxiv.org/pdf/2406.01624v2",
      "published_date": "2024-06-01 00:39:55 UTC",
      "updated_date": "2024-06-05 22:21:55 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-18T15:01:55.020388"
    },
    {
      "arxiv_id": "2406.01623v1",
      "title": "WebSuite: Systematically Evaluating Why Web Agents Fail",
      "title_zh": "WebSuite：系统评估 Web 代理失败的原因",
      "authors": [
        "Eric Li",
        "Jim Waldo"
      ],
      "abstract": "We describe WebSuite, the first diagnostic benchmark for generalist web\nagents, designed to systematically evaluate why agents fail. Advances in AI\nhave led to the rise of numerous web agents that autonomously operate a browser\nto complete tasks. However, most existing benchmarks focus on strictly\nmeasuring whether an agent can or cannot complete a task, without giving\ninsight on why. In this paper, we 1) develop a taxonomy of web actions to\nfacilitate identifying common failure patterns, and 2) create an extensible\nbenchmark suite to assess agents' performance on our taxonomized actions. This\nbenchmark suite consists of both individual tasks, such as clicking a button,\nand end-to-end tasks, such as adding an item to a cart, and is designed such\nthat any failure of a task can be attributed directly to a failure of a\nspecific web action. We evaluate two popular generalist web agents, one\ntext-based and one multimodal, and identify unique weaknesses for each agent.\nBecause WebSuite can disaggregate task failures into specific action failures,\nthis enables granular identification of which UX flows an individual agent has\ntrouble with and immediately highlights promising avenues for improvement.\nThese findings highlight the need for more focused benchmarking on where web\nagents go wrong to effectively improve agents beyond their weaker performance\ntoday.",
      "tldr_zh": "该研究引入了WebSuite，这是第一个诊断基准，用于系统评估通用网络代理（web agents）的失败原因。论文首先开发了一个网络动作分类法（taxonomy of web actions），以识别常见失败模式，并创建了一个可扩展的基准套件，包括单个任务（如点击按钮）和端到端任务（如添加物品到购物车），确保任务失败可直接归因于特定动作。研究者评估了两个流行代理（一个基于文本的，一个多模态的），发现每个代理有独特的弱点，如特定用户体验（UX）流程的处理问题。WebSuite 的 granular 分析方法突显了针对性改进的潜力，有助于提升代理的整体性能。",
      "categories": [
        "cs.SE",
        "cs.AI"
      ],
      "primary_category": "cs.SE",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2406.01623v1",
      "published_date": "2024-06-01 00:32:26 UTC",
      "updated_date": "2024-06-01 00:32:26 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-18T15:02:06.625125"
    }
  ],
  "raw_papers_fetched": true,
  "papers_count": 72,
  "processed_papers_count": 72,
  "failed_papers_count": 0,
  "summary_generated": true,
  "daily_data_saved": true,
  "last_update": "2025-05-18T15:02:29.558034"
}