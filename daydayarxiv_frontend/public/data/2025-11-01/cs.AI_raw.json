[
  {
    "arxiv_id": "2511.00739v2",
    "title": "A CPU-Centric Perspective on Agentic AI",
    "authors": [
      "Ritik Raj",
      "Hong Wang",
      "Tushar Krishna"
    ],
    "abstract": "Agentic AI frameworks add a decision-making orchestrator embedded with external tools, including web search, Python interpreter, contextual database, and others, on top of monolithic LLMs, turning them from passive text oracles into autonomous problem-solvers that can plan, call tools, remember past steps, and adapt on the fly.\n  This paper aims to characterize and understand the system bottlenecks introduced by agentic AI workloads from a largely overlooked CPU-centric perspective. We first systematically characterize Agentic AI on the basis of orchestrator/decision making component, inference path dynamics and repetitiveness of the agentic flow which directly influences the system-level performance. Thereafter, based on the characterization, we choose five representative agentic AI workloads- Haystack RAG, Toolformer, ChemCrow, Langchain and SWE-Agent to profile latency, throughput and energy metrics and demystify the significant impact of CPUs on these metrics relative to GPUs. We observe that - 1. Tool processing on CPUs can take up to 90.6% of the total latency; 2. Agentic throughput gets bottlenecked either by CPU factors - coherence, synchronization and over-subscription of cores or GPU factors - main memory capacity and bandwidth; \\circled{3} CPU dynamic energy consumes up to 44% of the total dynamic energy at large batch sizes. Based on the profiling insights, we present two key optimizations- 1. CPU and GPU-Aware Micro-batching (CGAM) and 2. Mixed Agentic Workload Scheduling (MAWS) for homogeneous and heterogeneous agentic workloads respectively to demonstrate the potential to improve the performance, efficiency, and scalability of agentic AI. We achieve up to 2.1x and 1.41x P50 latency speedup compared to the multi-processing benchmark for homogeneous and heterogeneous agentic workloads respectively.",
    "categories": [
      "cs.AI",
      "cs.LG",
      "cs.MA"
    ],
    "primary_category": "cs.AI",
    "comment": "",
    "pdf_url": "https://arxiv.org/pdf/2511.00739v2",
    "published_date": "2025-11-01 23:46:44 UTC",
    "updated_date": "2025-11-29 15:45:25 UTC"
  },
  {
    "arxiv_id": "2511.00737v1",
    "title": "EP-HDC: Hyperdimensional Computing with Encrypted Parameters for High-Throughput Privacy-Preserving Inference",
    "authors": [
      "Jaewoo Park",
      "Chenghao Quan",
      "Jongeun Lee"
    ],
    "abstract": "While homomorphic encryption (HE) provides strong privacy protection, its high computational cost has restricted its application to simple tasks. Recently, hyperdimensional computing (HDC) applied to HE has shown promising performance for privacy-preserving machine learning (PPML). However, when applied to more realistic scenarios such as batch inference, the HDC-based HE has still very high compute time as well as high encryption and data transmission overheads. To address this problem, we propose HDC with encrypted parameters (EP-HDC), which is a novel PPML approach featuring client-side HE, i.e., inference is performed on a client using a homomorphically encrypted model. Our EP-HDC can effectively mitigate the encryption and data transmission overhead, as well as providing high scalability with many clients while providing strong protection for user data and model parameters. In addition to application examples for our client-side PPML, we also present design space exploration involving quantization, architecture, and HE-related parameters. Our experimental results using the BFV scheme and the Face/Emotion datasets demonstrate that our method can improve throughput and latency of batch inference by orders of magnitude over previous PPML methods (36.52~1068x and 6.45~733x, respectively) with less than 1% accuracy degradation.",
    "categories": [
      "cs.CR",
      "cs.AI"
    ],
    "primary_category": "cs.CR",
    "comment": "To appear on ASP-DAC 2026",
    "pdf_url": "https://arxiv.org/pdf/2511.00737v1",
    "published_date": "2025-11-01 23:22:01 UTC",
    "updated_date": "2025-11-01 23:22:01 UTC"
  },
  {
    "arxiv_id": "2511.00732v1",
    "title": "FeNN-DMA: A RISC-V SoC for SNN acceleration",
    "authors": [
      "Zainab Aizaz",
      "James C. Knight",
      "Thomas Nowotny"
    ],
    "abstract": "Spiking Neural Networks (SNNs) are a promising, energy-efficient alternative to standard Artificial Neural Networks (ANNs) and are particularly well-suited to spatio-temporal tasks such as keyword spotting and video classification. However, SNNs have a much lower arithmetic intensity than ANNs and are therefore not well-matched to standard accelerators like GPUs and TPUs. Field Programmable Gate Arrays(FPGAs) are designed for such memory-bound workloads and here we develop a novel, fully-programmable RISC-V-based system-on-chip (FeNN-DMA), tailored to simulating SNNs on modern UltraScale+ FPGAs. We show that FeNN-DMA has comparable resource usage and energy requirements to state-of-the-art fixed-function SNN accelerators, yet it is capable of simulating much larger and more complex models. Using this functionality, we demonstrate state-of-the-art classification accuracy on the Spiking Heidelberg Digits and Neuromorphic MNIST tasks.",
    "categories": [
      "cs.NE",
      "cs.AI",
      "cs.AR"
    ],
    "primary_category": "cs.NE",
    "comment": "",
    "pdf_url": "https://arxiv.org/pdf/2511.00732v1",
    "published_date": "2025-11-01 22:59:54 UTC",
    "updated_date": "2025-11-01 22:59:54 UTC"
  },
  {
    "arxiv_id": "2511.01921v1",
    "title": "Fibbinary-Based Compression and Quantization for Efficient Neural Radio Receivers",
    "authors": [
      "Roberta Fiandaca",
      "Manil Dev Gomony"
    ],
    "abstract": "Neural receivers have shown outstanding performance compared to the conventional ones but this comes with a high network complexity leading to a heavy computational cost. This poses significant challenges in their deployment on hardware-constrained devices. To address the issue, this paper explores two optimization strategies: quantization and compression. We introduce both uniform and non-uniform quantization such as the Fibonacci Code word Quantization (FCQ). A novel fine-grained approach to the Incremental Network Quantization (INQ) strategy is then proposed to compensate for the losses introduced by the above mentioned quantization techniques. Additionally, we introduce two novel lossless compression algorithms that effectively reduce the memory size by compressing sequences of Fibonacci quantized parameters characterized by a huge redundancy. The quantization technique provides a saving of 45\\% and 44\\% in the multiplier's power and area, respectively, and its combination with the compression determines a 63.4\\% reduction in memory footprint, while still providing higher performances than a conventional receiver.",
    "categories": [
      "cs.IT",
      "cs.AI"
    ],
    "primary_category": "cs.IT",
    "comment": "",
    "pdf_url": "https://arxiv.org/pdf/2511.01921v1",
    "published_date": "2025-11-01 22:39:44 UTC",
    "updated_date": "2025-11-01 22:39:44 UTC"
  },
  {
    "arxiv_id": "2511.00711v1",
    "title": "TRISKELION-1: Unified Descriptive-Predictive-Generative AI",
    "authors": [
      "Nardeep Kumar",
      "Arun Kanwar"
    ],
    "abstract": "TRISKELION-1 is a unified descriptive-predictive-generative architecture that integrates statistical, mechanistic, and generative reasoning within a single encoder-decoder framework. The model demonstrates how descriptive representation learning, predictive inference, and generative synthesis can be jointly optimized using variational objectives. Experiments on MNIST validate that descriptive reconstruction, predictive classification, and generative sampling can coexist stably within one model. The framework provides a blueprint toward universal intelligence architectures that connect interpretability, accuracy, and creativity.",
    "categories": [
      "cs.LG",
      "cs.AI"
    ],
    "primary_category": "cs.LG",
    "comment": "12 pages, 18 figures, submitted to arXiv (2025)",
    "pdf_url": "https://arxiv.org/pdf/2511.00711v1",
    "published_date": "2025-11-01 21:23:38 UTC",
    "updated_date": "2025-11-01 21:23:38 UTC"
  },
  {
    "arxiv_id": "2511.00710v3",
    "title": "Ariadne: A Controllable Framework for Probing and Extending VLM Reasoning Boundaries",
    "authors": [
      "Minghe Shen",
      "Zhuo Zhi",
      "Chonghan Liu",
      "Shuo Xing",
      "Zhengzhong Tu",
      "Che Liu"
    ],
    "abstract": "While Vision-Language Models (VLMs) post-trained with Reinforcement Learning (RL) show impressive general reasoning, their evaluation is often confined to language-dominant tasks (e.g., math). This raises a critical question: can RL post-training truly extend the inherent capability boundary of a base VLM, particularly for visual-centric spatial tasks where it initially fails? To investigate this, we introduce Ariadne, a framework utilizing synthetic mazes for multi-step spatial reasoning where task difficulty (e.g., path length, turns) is precisely controlled. We leverage this controllable environment to train VLMs using Reinforcement Learning with Verified Rewards (RLVR) in a difficulty-aware curriculum. Surprisingly, post-RLVR training, the VLM achieves over 50% accuracy on a problem set where the base model scored 0%, demonstrating that our approach expands the model's initial capability boundary. To assess real-world viability, we evaluate out-of-distribution (OOD) generalization on practical benchmarks. Despite training only on synthetic maze samples, Ariadne achieves significant zero-shot improvements, averaging 16% on MapBench (e.g., museum navigation) and 24% on ReasonMap (subway transfer tasks). These results confirm that our method not only broadens the model's fundamental limits but also enhances its generalization to real-world spatial reasoning. We acknowledge our study is limited to the post-training phase, given the opaqueness of pre-training data, and hope our research motivates further work on specialized, capability-extending alignment.",
    "categories": [
      "cs.AI"
    ],
    "primary_category": "cs.AI",
    "comment": "",
    "pdf_url": "https://arxiv.org/pdf/2511.00710v3",
    "published_date": "2025-11-01 21:19:41 UTC",
    "updated_date": "2025-11-11 19:06:57 UTC"
  },
  {
    "arxiv_id": "2511.00709v2",
    "title": "A Voice-Enabled Virtual Patient System for Interactive Training in Standardized Clinical Assessment",
    "authors": [
      "Veronica Bossio Botero",
      "Vijay Yadav",
      "Jacob Ouyang",
      "Anzar Abbas",
      "Michelle Worthington"
    ],
    "abstract": "Training mental health clinicians to conduct standardized clinical assessments is challenging due to a lack of scalable, realistic practice opportunities, which can impact data quality in clinical trials. To address this gap, we introduce a voice-enabled virtual patient simulation system powered by a large language model (LLM). This study describes the system's development and validates its ability to generate virtual patients who accurately adhere to pre-defined clinical profiles, maintain coherent narratives, and produce realistic dialogue. We implemented a system using a LLM to simulate patients with specified symptom profiles, demographics, and communication styles. The system was evaluated by 5 experienced clinical raters who conducted 20 simulated structured MADRS interviews across 4 virtual patient personas. The virtual patients demonstrated strong adherence to their clinical profiles, with a mean item difference between rater-assigned MADRS scores and configured scores of 0.52 (SD=0.75). Inter-rater reliability across items was 0.90 (95% CI=0.68-0.99). Expert raters consistently rated the qualitative realism and cohesiveness of the virtual patients favorably, giving average ratings between \"Agree\" and \"Strongly Agree.\" Our findings suggest that LLM-powered virtual patient simulations are a viable and scalable tool for training clinicians, capable of producing high-fidelity, clinically relevant practice scenarios.",
    "categories": [
      "cs.HC",
      "cs.AI"
    ],
    "primary_category": "cs.HC",
    "comment": "",
    "pdf_url": "https://arxiv.org/pdf/2511.00709v2",
    "published_date": "2025-11-01 21:18:08 UTC",
    "updated_date": "2025-12-28 18:08:53 UTC"
  },
  {
    "arxiv_id": "2511.07437v1",
    "title": "Agentic Educational Content Generation for African Languages on Edge Devices",
    "authors": [
      "Ravi Gupta",
      "Guneet Bhatia"
    ],
    "abstract": "Addressing educational inequity in Sub-Saharan Africa, this research presents an autonomous agent-orchestrated framework for decentralized, culturally adaptive educational content generation on edge devices. The system leverages four specialized agents that work together to generate contextually appropriate educational content. Experimental validation on platforms including Raspberry Pi 4B and NVIDIA Jetson Nano demonstrates significant performance achievements. InkubaLM on Jetson Nano achieved a Time-To-First-Token (TTFT) of 129 ms, an average inter-token latency of 33 ms, and a throughput of 45.2 tokens per second while consuming 8.4 W. On Raspberry Pi 4B, InkubaLM also led with 326 ms TTFT and 15.9 tokens per second at 5.8 W power consumption. The framework consistently delivered high multilingual quality, averaging a BLEU score of 0.688, cultural relevance of 4.4/5, and fluency of 4.2/5 across tested African languages. Through potential partnerships with active community organizations including African Youth & Community Organization (AYCO) and Florida Africa Foundation, this research aims to establish a practical foundation for accessible, localized, and sustainable AI-driven education in resource-constrained environments. Keeping focus on long-term viability and cultural appropriateness, it contributes to United Nations SDGs 4, 9, and 10. Index Terms - Multi-Agent Systems, Edge AI Computing, Educational Technology, African Languages, Rural Education, Sustainable Development, UN SDG.",
    "categories": [
      "cs.AI"
    ],
    "primary_category": "cs.AI",
    "comment": "",
    "pdf_url": "https://arxiv.org/pdf/2511.07437v1",
    "published_date": "2025-11-01 21:13:47 UTC",
    "updated_date": "2025-11-01 21:13:47 UTC"
  },
  {
    "arxiv_id": "2511.04700v1",
    "title": "Separate the Wheat from the Chaff: Winnowing Down Divergent Views in Retrieval Augmented Generation",
    "authors": [
      "Song Wang",
      "Zihan Chen",
      "Peng Wang",
      "Zhepei Wei",
      "Zhen Tan",
      "Yu Meng",
      "Cong Shen",
      "Jundong Li"
    ],
    "abstract": "Retrieval-augmented generation (RAG) enhances large language models (LLMs) by integrating external knowledge sources to address their limitations in accessing up-to-date or specialized information. A natural strategy to increase the likelihood of retrieving relevant information is to expand the number of retrieved documents. However, involving more documents could introduce significant noise, as many documents may be irrelevant or misleading, thereby reducing the overall accuracy of the generated responses. To overcome the challenge associated with handling a larger number of documents, we propose WinnowRAG, a novel RAG framework designed to systematically filter out noisy documents while preserving valuable content -- a process we refer to as winnowing. WinnowRAG operates in two stages: In Stage I, we perform query-aware clustering to group similar documents and form distinct topic clusters. Each cluster is assigned to an LLM agent for generating a unique answer. In Stage II, we perform winnowing, wherein a critic LLM evaluates the outputs of multiple agents and iteratively separates useful documents from noisy ones. To retain useful documents when discarding agents, we propose two strategic merging techniques to ensure that only relevant knowledge is used for generating the final response. Crucially, WinnowRAG is model-agnostic and does not require any model fine-tuning, making it easily adaptable to various tasks. Extensive experiments on various realistic datasets demonstrate the effectiveness of WinnowRAG over state-of-the-art baselines.",
    "categories": [
      "cs.CL",
      "cs.AI"
    ],
    "primary_category": "cs.CL",
    "comment": "EMNLP Main 2025",
    "pdf_url": "https://arxiv.org/pdf/2511.04700v1",
    "published_date": "2025-11-01 20:08:13 UTC",
    "updated_date": "2025-11-01 20:08:13 UTC"
  },
  {
    "arxiv_id": "2511.00686v1",
    "title": "Evolve to Inspire: Novelty Search for Diverse Image Generation",
    "authors": [
      "Alex Inch",
      "Passawis Chaiyapattanaporn",
      "Yuchen Zhu",
      "Yuan Lu",
      "Ting-Wen Ko",
      "Davide Paglieri"
    ],
    "abstract": "Text-to-image diffusion models, while proficient at generating high-fidelity images, often suffer from limited output diversity, hindering their application in exploratory and ideation tasks. Existing prompt optimization techniques typically target aesthetic fitness or are ill-suited to the creative visual domain. To address this shortcoming, we introduce WANDER, a novelty search-based approach to generating diverse sets of images from a single input prompt. WANDER operates directly on natural language prompts, employing a Large Language Model (LLM) for semantic evolution of diverse sets of images, and using CLIP embeddings to quantify novelty. We additionally apply emitters to guide the search into distinct regions of the prompt space, and demonstrate that they boost the diversity of the generated images. Empirical evaluations using FLUX-DEV for generation and GPT-4o-mini for mutation demonstrate that WANDER significantly outperforms existing evolutionary prompt optimization baselines in diversity metrics. Ablation studies confirm the efficacy of emitters.",
    "categories": [
      "cs.CV",
      "cs.AI"
    ],
    "primary_category": "cs.CV",
    "comment": "14 pages, 10 figures, Accepted to Neurips 2025 GenProCC Workshop",
    "pdf_url": "https://arxiv.org/pdf/2511.00686v1",
    "published_date": "2025-11-01 19:58:07 UTC",
    "updated_date": "2025-11-01 19:58:07 UTC"
  },
  {
    "arxiv_id": "2511.00681v1",
    "title": "Metadata-Aligned 3D MRI Representations for Contrast Understanding and Quality Control",
    "authors": [
      "Mehmet Yigit Avci",
      "Pedro Borges",
      "Virginia Fernandez",
      "Paul Wright",
      "Mehmet Yigitsoy",
      "Sebastien Ourselin",
      "Jorge Cardoso"
    ],
    "abstract": "Magnetic Resonance Imaging suffers from substantial data heterogeneity and the absence of standardized contrast labels across scanners, protocols, and institutions, which severely limits large-scale automated analysis. A unified representation of MRI contrast would enable a wide range of downstream utilities, from automatic sequence recognition to harmonization and quality control, without relying on manual annotations. To this end, we introduce MR-CLIP, a metadata-guided framework that learns MRI contrast representations by aligning volumetric images with their DICOM acquisition parameters. The resulting embeddings shows distinct clusters of MRI sequences and outperform supervised 3D baselines under data scarcity in few-shot sequence classification. Moreover, MR-CLIP enables unsupervised data quality control by identifying corrupted or inconsistent metadata through image-metadata embedding distances. By transforming routinely available acquisition metadata into a supervisory signal, MR-CLIP provides a scalable foundation for label-efficient MRI analysis across diverse clinical datasets.",
    "categories": [
      "cs.CV",
      "cs.AI",
      "cs.LG"
    ],
    "primary_category": "cs.CV",
    "comment": "",
    "pdf_url": "https://arxiv.org/pdf/2511.00681v1",
    "published_date": "2025-11-01 19:49:32 UTC",
    "updated_date": "2025-11-01 19:49:32 UTC"
  },
  {
    "arxiv_id": "2511.00674v1",
    "title": "Isotropic Curvature Model for Understanding Deep Learning Optimization: Is Gradient Orthogonalization Optimal?",
    "authors": [
      "Weijie Su"
    ],
    "abstract": "In this paper, we introduce a model for analyzing deep learning optimization over a single iteration by leveraging the matrix structure of the weights. We derive the model by assuming isotropy of curvature, including the second-order Hessian and higher-order terms, of the loss function across all perturbation directions; hence, we call it the isotropic curvature model. This model is a convex optimization program amenable to analysis, which allows us to understand how an update on the weights in the form of a matrix relates to the change in the total loss function. As an application, we use the isotropic curvature model to analyze the recently introduced Muon optimizer and other matrix-gradient methods for training language models. First, we show that under a general growth condition on the curvature, the optimal update matrix is obtained by making the spectrum of the original gradient matrix more homogeneous -- that is, making its singular values closer in ratio -- which in particular improves the conditioning of the update matrix. Next, we show that the orthogonalized gradient becomes optimal for the isotropic curvature model when the curvature exhibits a phase transition in growth. Taken together, these results suggest that the gradient orthogonalization employed in Muon and other related methods is directionally correct but may not be strictly optimal. Finally, we discuss future research on how to leverage the isotropic curvature model for designing new optimization methods for training deep learning and language models.",
    "categories": [
      "math.OC",
      "cs.AI",
      "cs.LG"
    ],
    "primary_category": "math.OC",
    "comment": "",
    "pdf_url": "https://arxiv.org/pdf/2511.00674v1",
    "published_date": "2025-11-01 19:37:29 UTC",
    "updated_date": "2025-11-01 19:37:29 UTC"
  },
  {
    "arxiv_id": "2511.00673v1",
    "title": "Lifted Successor Generation in Numeric Planning",
    "authors": [
      "Dominik Drexler"
    ],
    "abstract": "Most planners ground numeric planning tasks, given in a first-order-like language, into a ground task representation. However, this can lead to an exponential blowup in task representation size, which occurs in practice for hard-to-ground tasks. We extend a state-of-the-art lifted successor generator for classical planning to support numeric precondition applicability. The method enumerates maximum cliques in a substitution consistency graph. Each maximum clique represents a substitution for the variables of the action schema, yielding a ground action. We augment this graph with numeric action preconditions and prove the successor generator is exact under formally specified conditions. When the conditions fail, our generator may list inapplicable ground actions; a final applicability check filters these without affecting completeness. However, this cannot happen in 23 of 25 benchmark domains, and it occurs only in 1 domain. To the authors' knowledge, no other lifted successor generator supports numeric action preconditions. This enables future research on lifted planning for a very rich planning fragment.",
    "categories": [
      "cs.AI"
    ],
    "primary_category": "cs.AI",
    "comment": "",
    "pdf_url": "https://arxiv.org/pdf/2511.00673v1",
    "published_date": "2025-11-01 19:33:16 UTC",
    "updated_date": "2025-11-01 19:33:16 UTC"
  },
  {
    "arxiv_id": "2511.00664v1",
    "title": "ShadowLogic: Backdoors in Any Whitebox LLM",
    "authors": [
      "Kasimir Schulz",
      "Amelia Kawasaki",
      "Leo Ring"
    ],
    "abstract": "Large language models (LLMs) are widely deployed across various applications, often with safeguards to prevent the generation of harmful or restricted content. However, these safeguards can be covertly bypassed through adversarial modifications to the computational graph of a model. This work highlights a critical security vulnerability in computational graph-based LLM formats, demonstrating that widely used deployment pipelines may be susceptible to obscured backdoors. We introduce ShadowLogic, a method for creating a backdoor in a white-box LLM by injecting an uncensoring vector into its computational graph representation. We set a trigger phrase that, when added to the beginning of a prompt into the LLM, applies the uncensoring vector and removes the content generation safeguards in the model. We embed trigger logic directly into the computational graph which detects the trigger phrase in a prompt. To evade detection of our backdoor, we obfuscate this logic within the graph structure, making it similar to standard model functions. Our method requires minimal alterations to model parameters, making backdoored models appear benign while retaining the ability to generate uncensored responses when activated. We successfully implement ShadowLogic in Phi-3 and Llama 3.2, using ONNX for manipulating computational graphs. Implanting the uncensoring vector achieved a >60% attack success rate for further malicious queries.",
    "categories": [
      "cs.CR",
      "cs.AI"
    ],
    "primary_category": "cs.CR",
    "comment": "",
    "pdf_url": "https://arxiv.org/pdf/2511.00664v1",
    "published_date": "2025-11-01 19:10:08 UTC",
    "updated_date": "2025-11-01 19:10:08 UTC"
  },
  {
    "arxiv_id": "2511.05547v2",
    "title": "Automated Invoice Data Extraction: Using LLM and OCR",
    "authors": [
      "Khushi Khanchandani",
      "Advait Thakur",
      "Akshita Shetty",
      "Chaitravi Reddy",
      "Ritisa Behera"
    ],
    "abstract": "Conventional Optical Character Recognition (OCR) systems are challenged by variant invoice layouts, handwritten text, and low-quality scans, which are often caused by strong template dependencies that restrict their flexibility across different document structures and layouts. Newer solutions utilize advanced deep learning models such as Convolutional Neural Networks (CNN) as well as Transformers, and domain-specific models for better layout analysis and accuracy across various sections over varied document types. Large Language Models (LLMs) have revolutionized extraction pipelines at their core with sophisticated entity recognition and semantic comprehension to support complex contextual relationship mapping without direct programming specification. Visual Named Entity Recognition (NER) capabilities permit extraction from invoice images with greater contextual sensitivity and much higher accuracy rates than older approaches. Existing industry best practices utilize hybrid architectures that blend OCR technology and LLM for maximum scalability and minimal human intervention. This work introduces a holistic Artificial Intelligence (AI) platform combining OCR, deep learning, LLMs, and graph analytics to achieve unprecedented extraction quality and consistency.",
    "categories": [
      "cs.CV",
      "cs.AI"
    ],
    "primary_category": "cs.CV",
    "comment": "10 pages, 3 figures",
    "pdf_url": "https://arxiv.org/pdf/2511.05547v2",
    "published_date": "2025-11-01 19:05:09 UTC",
    "updated_date": "2026-01-08 10:24:34 UTC"
  },
  {
    "arxiv_id": "2511.00658v1",
    "title": "Lessons Learned from the Use of Generative AI in Engineering and Quality Assurance of a WEB System for Healthcare",
    "authors": [
      "Guilherme H. Travassos",
      "Sabrina Rocha",
      "Rodrigo Feitosa",
      "Felipe Assis",
      "Patricia Goncalves",
      "Andre Gheventer",
      "Larissa Galeno",
      "Arthur Sasse",
      "Julio Cesar Guimaraes",
      "Carlos Brito",
      "Joao Pedro Wieland"
    ],
    "abstract": "The advances and availability of technologies involving Generative Artificial Intelligence (AI) are evolving clearly and explicitly, driving immediate changes in various work activities. Software Engineering (SE) is no exception and stands to benefit from these new technologies, enhancing productivity and quality in its software development processes. However, although the use of Generative AI in SE practices is still in its early stages, considering the lack of conclusive results from ongoing research and the limited technological maturity, we have chosen to incorporate these technologies in the development of a web-based software system to be used in clinical trials by a thoracic diseases research group at our university. For this reason, we decided to share this experience report documenting our development team's learning journey in using Generative AI during the software development process. Project management, requirements specification, design, development, and quality assurance activities form the scope of observation. Although we do not yet have definitive technological evidence to evolve our development process significantly, the results obtained and the suggestions shared here represent valuable insights for software organizations seeking to innovate their development practices to achieve software quality with generative AI.",
    "categories": [
      "cs.SE",
      "cs.AI",
      "cs.ET"
    ],
    "primary_category": "cs.SE",
    "comment": "11 pages, 2 figures, in Portuguese language",
    "pdf_url": "https://arxiv.org/pdf/2511.00658v1",
    "published_date": "2025-11-01 18:42:29 UTC",
    "updated_date": "2025-11-01 18:42:29 UTC"
  },
  {
    "arxiv_id": "2511.14772v1",
    "title": "Test-time Scaling of LLMs: A Survey from A Subproblem Structure Perspective",
    "authors": [
      "Zhuoyi Yang",
      "Xu Guo",
      "Tong Zhang",
      "Huijuan Xu",
      "Boyang Li"
    ],
    "abstract": "With this paper, we survey techniques for improving the predictive accuracy of pretrained large language models by allocating additional compute at inference time. In categorizing test-time scaling methods, we place special emphasis on how a problem is decomposed into subproblems and on the topological organization of these subproblems whether sequential, parallel, or tree-structured. This perspective allows us to unify diverse approaches such as Chain-of-Thought, Branch-Solve-Merge, and Tree-of-Thought under a common lens. We further synthesize existing analyses of these techniques, highlighting their respective strengths and weaknesses, and conclude by outlining promising directions for future research",
    "categories": [
      "cs.CL",
      "cs.AI"
    ],
    "primary_category": "cs.CL",
    "comment": "",
    "pdf_url": "https://arxiv.org/pdf/2511.14772v1",
    "published_date": "2025-11-01 18:41:23 UTC",
    "updated_date": "2025-11-01 18:41:23 UTC"
  },
  {
    "arxiv_id": "2511.00651v1",
    "title": "Leveraging Multi-Agent System (MAS) and Fine-Tuned Small Language Models (SLMs) for Automated Telecom Network Troubleshooting",
    "authors": [
      "Chenhua Shi",
      "Bhavika Jalli",
      "Gregor Macdonald",
      "John Zou",
      "Wanlu Lei",
      "Mridul Jain",
      "Joji Philip"
    ],
    "abstract": "Telecom networks are rapidly growing in scale and complexity, making effective management, operation, and optimization increasingly challenging. Although Artificial Intelligence (AI) has been applied to many telecom tasks, existing models are often narrow in scope, require large amounts of labeled data, and struggle to generalize across heterogeneous deployments. Consequently, network troubleshooting continues to rely heavily on Subject Matter Experts (SMEs) to manually correlate various data sources to identify root causes and corrective actions. To address these limitations, we propose a Multi-Agent System (MAS) that employs an agentic workflow, with Large Language Models (LLMs) coordinating multiple specialized tools for fully automated network troubleshooting. Once faults are detected by AI/ML-based monitors, the framework dynamically activates agents such as an orchestrator, solution planner, executor, data retriever, and root-cause analyzer to diagnose issues and recommend remediation strategies within a short time frame. A key component of this system is the solution planner, which generates appropriate remediation plans based on internal documentation. To enable this, we fine-tuned a Small Language Model (SLM) on proprietary troubleshooting documents to produce domain-grounded solution plans. Experimental results demonstrate that the proposed framework significantly accelerates troubleshooting automation across both Radio Access Network (RAN) and Core network domains.",
    "categories": [
      "cs.AI",
      "cs.CL",
      "cs.IT",
      "cs.MA",
      "cs.NI"
    ],
    "primary_category": "cs.AI",
    "comment": "6 pages, 7 figures, 1 table",
    "pdf_url": "https://arxiv.org/pdf/2511.00651v1",
    "published_date": "2025-11-01 18:19:41 UTC",
    "updated_date": "2025-11-01 18:19:41 UTC"
  },
  {
    "arxiv_id": "2511.00641v1",
    "title": "More Than A Shortcut: A Hyperbolic Approach To Early-Exit Networks",
    "authors": [
      "Swapnil Bhosale",
      "Cosmin Frateanu",
      "Camilla Clark",
      "Arnoldas Jasonas",
      "Chris Mitchell",
      "Xiatian Zhu",
      "Vamsi Krishna Ithapu",
      "Giacomo Ferroni",
      "Cagdas Bilen",
      "Sanjeel Parekh"
    ],
    "abstract": "Deploying accurate event detection on resource-constrained devices is challenged by the trade-off between performance and computational cost. While Early-Exit (EE) networks offer a solution through adaptive computation, they often fail to enforce a coherent hierarchical structure, limiting the reliability of their early predictions. To address this, we propose Hyperbolic Early-Exit networks (HypEE), a novel framework that learns EE representations in the hyperbolic space. Our core contribution is a hierarchical training objective with a novel entailment loss, which enforces a partial-ordering constraint to ensure that deeper network layers geometrically refine the representations of shallower ones. Experiments on multiple audio event detection tasks and backbone architectures show that HypEE significantly outperforms standard Euclidean EE baselines, especially at the earliest, most computationally-critical exits. The learned geometry also provides a principled measure of uncertainty, enabling a novel triggering mechanism that makes the overall system both more efficient and more accurate than a conventional EE and standard backbone models without early-exits.",
    "categories": [
      "cs.SD",
      "cs.AI"
    ],
    "primary_category": "cs.SD",
    "comment": "",
    "pdf_url": "https://arxiv.org/pdf/2511.00641v1",
    "published_date": "2025-11-01 17:43:02 UTC",
    "updated_date": "2025-11-01 17:43:02 UTC"
  },
  {
    "arxiv_id": "2511.00640v1",
    "title": "DTS: Enhancing Large Reasoning Models via Decoding Tree Sketching",
    "authors": [
      "Zicheng Xu",
      "Guanchu Wang",
      "Yu-Neng Chuang",
      "Guangyao Zheng",
      "Alexander S. Szalay",
      "Zirui Liu",
      "Vladimir Braverman"
    ],
    "abstract": "Large Reasoning Models (LRMs) demonstrate strong performance on complex reasoning tasks, yet they often suffer from overthinking, producing excessively long chain-of-thought (CoT) traces that increase inference cost and may degrade accuracy. Our analysis reveals a clear anti-correlation between reasoning length and accuracy, where across multiple stochastic decodes, the short reasoning paths consistently achieve the highest correctness, while longer ones accumulate errors and repetitions. These short optimal reasoning paths can be found ideally through full enumeration of the reasoning space. However, the tree-structured reasoning space grows exponentially with sequence length, rendering exhaustive exploration infeasible. To address this, we propose DTS, a model-agnostic decoding framework that sketches the reasoning space by selectively branching at high-entropy tokens and applies early stopping to select the shortest completed reasoning path. This approach approximates the optimal solution that enhances both efficiency and accuracy, without requiring additional training or supervision. Experiments on AIME2024 and AIME2025 datasets with DeepSeek-R1-Distill-Qwen-7B and 1.5B show that DTS improves accuracy by up to 8%, reduces average reasoning length by 23%, and decreases repetition frequency by 12%, demonstrating DTS's ability for scalable and efficient LRM reasoning.",
    "categories": [
      "cs.AI",
      "cs.CL",
      "cs.LG"
    ],
    "primary_category": "cs.AI",
    "comment": "",
    "pdf_url": "https://arxiv.org/pdf/2511.00640v1",
    "published_date": "2025-11-01 17:41:28 UTC",
    "updated_date": "2025-11-01 17:41:28 UTC"
  },
  {
    "arxiv_id": "2511.00634v2",
    "title": "Node Preservation and its Effect on Crossover in Cartesian Genetic Programming",
    "authors": [
      "Mark Kocherovsky",
      "Illya Bakurov",
      "Wolfgang Banzhaf"
    ],
    "abstract": "While crossover is a critical and often indispensable component in other forms of Genetic Programming, such as Linear- and Tree-based, it has consistently been claimed that it deteriorates search performance in CGP. As a result, a mutation-alone $(1+Î»)$ evolutionary strategy has become the canonical approach for CGP. Although several operators have been developed that demonstrate an increased performance over the canonical method, a general solution to the problem is still lacking. In this paper, we compare basic crossover methods, namely one-point and uniform, to variants in which nodes are ``preserved,'' including the subgraph crossover developed by Roman Kalkreuth, the difference being that when ``node preservation'' is active, crossover is not allowed to break apart instructions. We also compare a node mutation operator to the traditional point mutation; the former simply replaces an entire node with a new one. We find that node preservation in both mutation and crossover improves search using symbolic regression benchmark problems, moving the field towards a general solution to CGP crossover.",
    "categories": [
      "cs.NE",
      "cs.AI",
      "cs.LG"
    ],
    "primary_category": "cs.NE",
    "comment": "Draft to cite in another paper before both papers are peer-reviewed for the evo*2026 conference, 21 pages, 5 figures",
    "pdf_url": "https://arxiv.org/pdf/2511.00634v2",
    "published_date": "2025-11-01 17:26:56 UTC",
    "updated_date": "2025-11-24 17:55:01 UTC"
  },
  {
    "arxiv_id": "2511.00628v1",
    "title": "AgentGit: A Version Control Framework for Reliable and Scalable LLM-Powered Multi-Agent Systems",
    "authors": [
      "Yang Li",
      "Siqi Ping",
      "Xiyu Chen",
      "Xiaojian Qi",
      "Zigan Wang",
      "Ye Luo",
      "Xiaowei Zhang"
    ],
    "abstract": "With the rapid progress of large language models (LLMs), LLM-powered multi-agent systems (MAS) are drawing increasing interest across academia and industry. However, many current MAS frameworks struggle with reliability and scalability, especially on complex tasks. We present AgentGit, a framework that brings Git-like rollback and branching to MAS workflows. Built as an infrastructure layer on top of LangGraph, AgentGit supports state commit, revert, and branching, allowing agents to traverse, compare, and explore multiple trajectories efficiently. To evaluate AgentGit, we designed an experiment that optimizes target agents by selecting better prompts. We ran a multi-step A/B test against three baselines -- LangGraph, AutoGen, and Agno -- on a real-world task: retrieving and analyzing paper abstracts. Results show that AgentGit significantly reduces redundant computation, lowers runtime and token usage, and supports parallel exploration across multiple branches, enhancing both reliability and scalability in MAS development. This work offers a practical path to more robust MAS design and enables error recovery, safe exploration, iterative debugging, and A/B testing in collaborative AI systems.",
    "categories": [
      "cs.MA",
      "cs.AI",
      "cs.SE"
    ],
    "primary_category": "cs.MA",
    "comment": "",
    "pdf_url": "https://arxiv.org/pdf/2511.00628v1",
    "published_date": "2025-11-01 17:11:31 UTC",
    "updated_date": "2025-11-01 17:11:31 UTC"
  },
  {
    "arxiv_id": "2511.00617v1",
    "title": "Belief Dynamics Reveal the Dual Nature of In-Context Learning and Activation Steering",
    "authors": [
      "Eric Bigelow",
      "Daniel Wurgaft",
      "YingQiao Wang",
      "Noah Goodman",
      "Tomer Ullman",
      "Hidenori Tanaka",
      "Ekdeep Singh Lubana"
    ],
    "abstract": "Large language models (LLMs) can be controlled at inference time through prompts (in-context learning) and internal activations (activation steering). Different accounts have been proposed to explain these methods, yet their common goal of controlling model behavior raises the question of whether these seemingly disparate methodologies can be seen as specific instances of a broader framework. Motivated by this, we develop a unifying, predictive account of LLM control from a Bayesian perspective. Specifically, we posit that both context- and activation-based interventions impact model behavior by altering its belief in latent concepts: steering operates by changing concept priors, while in-context learning leads to an accumulation of evidence. This results in a closed-form Bayesian model that is highly predictive of LLM behavior across context- and activation-based interventions in a set of domains inspired by prior work on many-shot in-context learning. This model helps us explain prior empirical phenomena - e.g., sigmoidal learning curves as in-context evidence accumulates - while predicting novel ones - e.g., additivity of both interventions in log-belief space, which results in distinct phases such that sudden and dramatic behavioral shifts can be induced by slightly changing intervention controls. Taken together, this work offers a unified account of prompt-based and activation-based control of LLM behavior, and a methodology for empirically predicting the effects of these interventions.",
    "categories": [
      "cs.LG",
      "cs.AI",
      "cs.CL",
      "stat.ML"
    ],
    "primary_category": "cs.LG",
    "comment": "",
    "pdf_url": "https://arxiv.org/pdf/2511.00617v1",
    "published_date": "2025-11-01 16:46:03 UTC",
    "updated_date": "2025-11-01 16:46:03 UTC"
  },
  {
    "arxiv_id": "2511.00609v2",
    "title": "PreferThinker: Reasoning-based Personalized Image Preference Assessment",
    "authors": [
      "Shengqi Xu",
      "Xinpeng Zhou",
      "Yabo Zhang",
      "Ming Liu",
      "Tao Liang",
      "Tianyu Zhang",
      "Yalong Bai",
      "Zuxuan Wu",
      "Wangmeng Zuo"
    ],
    "abstract": "Personalized image preference assessment aims to evaluate an individual user's image preferences by relying only on a small set of reference images as prior information. Existing methods mainly focus on general preference assessment, training models with large-scale data to tackle well-defined tasks such as text-image alignment. However, these approaches struggle to handle personalized preference because user-specific data are scarce and not easily scalable, and individual tastes are often diverse and complex. To overcome these challenges, we introduce a common preference profile that serves as a bridge across users, allowing large-scale user data to be leveraged for training profile prediction and capturing complex personalized preferences. Building on this idea, we propose a reasoning-based personalized image preference assessment framework that follows a \\textit{predict-then-assess} paradigm: it first predicts a user's preference profile from reference images, and then provides interpretable, multi-dimensional scores and assessments of candidate images based on the predicted profile. To support this, we first construct a large-scale Chain-of-Thought (CoT)-style personalized assessment dataset annotated with diverse user preference profiles and high-quality CoT-style reasoning, enabling explicit supervision of structured reasoning. Next, we adopt a two-stage training strategy: a cold-start supervised fine-tuning phase to empower the model with structured reasoning capabilities, followed by reinforcement learning to incentivize the model to explore more reasonable assessment paths and enhance generalization. Furthermore, we propose a similarity-aware prediction reward to encourage better prediction of the user's preference profile, which facilitates more reasonable assessments exploration. Extensive experiments demonstrate the superiority of the proposed method.",
    "categories": [
      "cs.AI"
    ],
    "primary_category": "cs.AI",
    "comment": "",
    "pdf_url": "https://arxiv.org/pdf/2511.00609v2",
    "published_date": "2025-11-01 16:19:51 UTC",
    "updated_date": "2025-11-10 07:47:50 UTC"
  },
  {
    "arxiv_id": "2511.00603v1",
    "title": "EPARA: Parallelizing Categorized AI Inference in Edge Clouds",
    "authors": [
      "Yubo Wang",
      "Yubo Cui",
      "Tuo Shi",
      "Danyang Li",
      "Wenxin Li",
      "Lide Suo",
      "Tao Wang",
      "Xin Xie"
    ],
    "abstract": "With the increasing adoption of AI applications such as large language models and computer vision AI, the computational demands on AI inference systems are continuously rising, making the enhancement of task processing capacity using existing hardware a primary objective in edge clouds. We propose EPARA, an end-to-end AI parallel inference framework in edge, aimed at enhancing the edge AI serving capability. Our key idea is to categorize tasks based on their sensitivity to latency/frequency and requirement for GPU resources, thereby achieving both request-level and service-level task-resource allocation. EPARA consists of three core components: 1) a task-categorized parallelism allocator that decides the parallel mode of each task, 2) a distributed request handler that performs the calculation for the specific request, and 3) a state-aware scheduler that periodically updates service placement in edge clouds. We implement a EPARA prototype and conduct a case study on the EPARA operation for LLMs and segmentation tasks. Evaluation through testbed experiments involving edge servers, embedded devices, and microcomputers shows that EPARA achieves up to 2.1$\\times$ higher goodput in production workloads compared to prior frameworks, while adapting to various edge AI inference tasks.",
    "categories": [
      "cs.DC",
      "cs.AI",
      "cs.NI"
    ],
    "primary_category": "cs.DC",
    "comment": "15 pages,20 figures",
    "pdf_url": "https://arxiv.org/pdf/2511.00603v1",
    "published_date": "2025-11-01 16:09:14 UTC",
    "updated_date": "2025-11-01 16:09:14 UTC"
  },
  {
    "arxiv_id": "2511.00588v2",
    "title": "Diagnosing Hallucination Risk in AI Surgical Decision-Support: A Sequential Framework for Sequential Validation",
    "authors": [
      "Dong Chen",
      "Yanzhe Wei",
      "Zonglin He",
      "Guan-Ming Kuang",
      "Canhua Ye",
      "Meiru An",
      "Huili Peng",
      "Yong Hu",
      "Huiren Tao",
      "Kenneth MC Cheung"
    ],
    "abstract": "Large language models (LLMs) offer transformative potential for clinical decision support in spine surgery but pose significant risks through hallucinations, which are factually inconsistent or contextually misaligned outputs that may compromise patient safety. This study introduces a clinician-centered framework to quantify hallucination risks by evaluating diagnostic precision, recommendation quality, reasoning robustness, output coherence, and knowledge alignment. We assessed six leading LLMs across 30 expert-validated spinal cases. DeepSeek-R1 demonstrated superior overall performance (total score: 86.03 $\\pm$ 2.08), particularly in high-stakes domains such as trauma and infection. A critical finding reveals that reasoning-enhanced model variants did not uniformly outperform standard counterparts: Claude-3.7-Sonnet's extended thinking mode underperformed relative to its standard version (80.79 $\\pm$ 1.83 vs. 81.56 $\\pm$ 1.92), indicating extended chain-of-thought reasoning alone is insufficient for clinical reliability. Multidimensional stress-testing exposed model-specific vulnerabilities, with recommendation quality degrading by 7.4% under amplified complexity. This decline contrasted with marginal improvements in rationality (+2.0%), readability (+1.7%) and diagnosis (+4.7%), highlighting a concerning divergence between perceived coherence and actionable guidance. Our findings advocate integrating interpretability mechanisms (e.g., reasoning chain visualization) into clinical workflows and establish a safety-aware validation framework for surgical LLM deployment.",
    "categories": [
      "cs.LG",
      "cs.AI",
      "cs.CY"
    ],
    "primary_category": "cs.LG",
    "comment": "",
    "pdf_url": "https://arxiv.org/pdf/2511.00588v2",
    "published_date": "2025-11-01 15:25:55 UTC",
    "updated_date": "2025-11-20 14:14:35 UTC"
  },
  {
    "arxiv_id": "2511.00580v1",
    "title": "TRACES: Temporal Recall with Contextual Embeddings for Real-Time Video Anomaly Detection",
    "authors": [
      "Yousuf Ahmed Siddiqui",
      "Sufiyaan Usmani",
      "Umer Tariq",
      "Jawwad Ahmed Shamsi",
      "Muhammad Burhan Khan"
    ],
    "abstract": "Video anomalies often depend on contextual information available and temporal evolution. Non-anomalous action in one context can be anomalous in some other context. Most anomaly detectors, however, do not notice this type of context, which seriously limits their capability to generalize to new, real-life situations. Our work addresses the context-aware zero-shot anomaly detection challenge, in which systems need to learn adaptively to detect new events by correlating temporal and appearance features with textual traces of memory in real time. Our approach defines a memory-augmented pipeline, correlating temporal signals with visual embeddings using cross-attention, and real-time zero-shot anomaly classification by contextual similarity scoring. We achieve 90.4\\% AUC on UCF-Crime and 83.67\\% AP on XD-Violence, a new state-of-the-art among zero-shot models. Our model achieves real-time inference with high precision and explainability for deployment. We show that, by fusing cross-attention temporal fusion and contextual memory, we achieve high fidelity anomaly detection, a step towards the applicability of zero-shot models in real-world surveillance and infrastructure monitoring.",
    "categories": [
      "cs.CV",
      "cs.AI"
    ],
    "primary_category": "cs.CV",
    "comment": "10 pages, 5 figures",
    "pdf_url": "https://arxiv.org/pdf/2511.00580v1",
    "published_date": "2025-11-01 14:54:08 UTC",
    "updated_date": "2025-11-01 14:54:08 UTC"
  },
  {
    "arxiv_id": "2511.00576v1",
    "title": "FlashEVA: Accelerating LLM inference via Efficient Attention",
    "authors": [
      "Juan Gabriel Kostelec",
      "Qinghai Guo"
    ],
    "abstract": "Transformer models have revolutionized natural language processing, achieving state-of-the-art performance and demonstrating remarkable scalability. However, their memory demands, particularly due to maintaining full context in memory, pose significant challenges for inference. In this paper, we present FlashEVA, an efficient implementation of EVA (Efficient Attention via Control Variates), and demonstrate how to finetune transformers to adapt to FlashEVA attention. Our method enables fine-tuning of Transformer models with as few as 1.5B tokens while preserving effectiveness across various downstream tasks. Notably, FlashEVA achieves up to 6.7x higher throughput and 5x lower peak GPU memory usage during inference compared to standard Transformer implementations. Despite these improvements, we observe limitations in retrieval-focused tasks. Our implementation offers control over the trade-off between throughput and accuracy through adjustable hyperparameters, providing flexibility for diverse use cases. This work represents a significant step towards more efficient and adaptable Transformer-based models for inference.",
    "categories": [
      "cs.CL",
      "cs.AI"
    ],
    "primary_category": "cs.CL",
    "comment": "Technical Report",
    "pdf_url": "https://arxiv.org/pdf/2511.00576v1",
    "published_date": "2025-11-01 14:38:57 UTC",
    "updated_date": "2025-11-01 14:38:57 UTC"
  },
  {
    "arxiv_id": "2511.00564v1",
    "title": "FTT-GRU: A Hybrid Fast Temporal Transformer with GRU for Remaining Useful Life Prediction",
    "authors": [
      "Varun Teja Chirukiri",
      "Udaya Bhasker Cheerala",
      "Sandeep Kanta",
      "Abdul Karim",
      "Praveen Damacharla"
    ],
    "abstract": "Accurate prediction of the remaining useful life (RUL) of industrial machinery is essential for reducing downtime and optimizing maintenance schedules. Existing approaches, such as long short-term memory (LSTM) networks and convolutional neural networks (CNNs), often struggle to model both global temporal dependencies and fine-grained degradation trends in multivariate sensor data. We propose a hybrid model, FTT-GRU, which combines a Fast Temporal Transformer (FTT) -- a lightweight Transformer variant using linearized attention via fast Fourier transform (FFT) -- with a gated recurrent unit (GRU) layer for sequential modeling. To the best of our knowledge, this is the first application of an FTT with a GRU for RUL prediction on NASA CMAPSS, enabling simultaneous capture of global and local degradation patterns in a compact architecture. On CMAPSS FD001, FTT-GRU attains RMSE 30.76, MAE 18.97, and $R^2=0.45$, with 1.12 ms CPU latency at batch=1. Relative to the best published deep baseline (TCN--Attention), it improves RMSE by 1.16\\% and MAE by 4.00\\%. Training curves averaged over $k=3$ runs show smooth convergence with narrow 95\\% confidence bands, and ablations (GRU-only, FTT-only) support the contribution of both components. These results demonstrate that a compact Transformer-RNN hybrid delivers accurate and efficient RUL predictions on CMAPSS, making it suitable for real-time industrial prognostics.",
    "categories": [
      "cs.LG",
      "cs.AI",
      "eess.SY"
    ],
    "primary_category": "cs.LG",
    "comment": "5 pages, The 2025 International Conference on Computational Science and Computational Intelligence",
    "pdf_url": "https://arxiv.org/pdf/2511.00564v1",
    "published_date": "2025-11-01 14:02:03 UTC",
    "updated_date": "2025-11-01 14:02:03 UTC"
  },
  {
    "arxiv_id": "2511.00554v1",
    "title": "Red-teaming Activation Probes using Prompted LLMs",
    "authors": [
      "Phil Blandfort",
      "Robert Graham"
    ],
    "abstract": "Activation probes are attractive monitors for AI systems due to low cost and latency, but their real-world robustness remains underexplored. We ask: What failure modes arise under realistic, black-box adversarial pressure, and how can we surface them with minimal effort? We present a lightweight black-box red-teaming procedure that wraps an off-the-shelf LLM with iterative feedback and in-context learning (ICL), and requires no fine-tuning, gradients, or architectural access. Running a case study with probes for high-stakes interactions, we show that our approach can help discover valuable insights about a SOTA probe. Our analysis uncovers interpretable brittleness patterns (e.g., legalese-induced FPs; bland procedural tone FNs) and reduced but persistent vulnerabilities under scenario-constraint attacks. These results suggest that simple prompted red-teaming scaffolding can anticipate failure patterns before deployment and might yield promising, actionable insights to harden future probes.",
    "categories": [
      "cs.LG",
      "cs.AI"
    ],
    "primary_category": "cs.LG",
    "comment": "",
    "pdf_url": "https://arxiv.org/pdf/2511.00554v1",
    "published_date": "2025-11-01 13:35:34 UTC",
    "updated_date": "2025-11-01 13:35:34 UTC"
  },
  {
    "arxiv_id": "2511.00552v1",
    "title": "Temporal Fusion Transformer for Multi-Horizon Probabilistic Forecasting of Weekly Retail Sales",
    "authors": [
      "Santhi Bharath Punati",
      "Sandeep Kanta",
      "Udaya Bhasker Cheerala",
      "Madhusudan G Lanjewar",
      "Praveen Damacharla"
    ],
    "abstract": "Accurate multi-horizon retail forecasts are critical for inventory and promotions. We present a novel study of weekly Walmart sales (45 stores, 2010--2012) using a Temporal Fusion Transformer (TFT) that fuses static store identifiers with time-varying exogenous signals (holidays, CPI, fuel price, temperature). The pipeline produces 1--5-week-ahead probabilistic forecasts via Quantile Loss, yielding calibrated 90\\% prediction intervals and interpretability through variable-selection networks, static enrichment, and temporal attention. On a fixed 2012 hold-out dataset, TFT achieves an RMSE of \\$57.9k USD per store-week and an $R^2$ of 0.9875. Across a 5-fold chronological cross-validation, the averages are RMSE = \\$64.6k USD and $R^2$ = 0.9844, outperforming the XGB, CNN, LSTM, and CNN-LSTM baseline models. These results demonstrate practical value for inventory planning and holiday-period optimization, while maintaining model transparency.",
    "categories": [
      "cs.LG",
      "cs.AI",
      "econ.GN"
    ],
    "primary_category": "cs.LG",
    "comment": "5 pages, 2025 6th International Conference on Data Analytics for Business and Industry (ICDABI)",
    "pdf_url": "https://arxiv.org/pdf/2511.00552v1",
    "published_date": "2025-11-01 13:34:29 UTC",
    "updated_date": "2025-11-01 13:34:29 UTC"
  },
  {
    "arxiv_id": "2511.00551v2",
    "title": "Single-agent Reinforcement Learning Model for Regional Adaptive Traffic Signal Control",
    "authors": [
      "Qiang Li",
      "Ningjing Zeng",
      "Lina Yu"
    ],
    "abstract": "Several studies have employed reinforcement learning (RL) to address the challenges of regional adaptive traffic signal control (ATSC) and achieved promising results. In this field, existing research predominantly adopts multi-agent frameworks. However, the adoption of multi-agent frameworks presents challenges for scalability. Instead, the Traffic signal control (TSC) problem necessitates a single-agent framework. TSC inherently relies on centralized management by a single control center, which can monitor traffic conditions across all roads in the study area and coordinate the control of all intersections. This work proposes a single-agent RL-based regional ATSC model compatible with probe vehicle technology. Key components of the RL design include state, action, and reward function definitions. To facilitate learning and manage congestion, both state and reward functions are defined based on queue length, with action designed to regulate queue dynamics. The queue length definition used in this study differs slightly from conventional definitions but is closely correlated with congestion states. More importantly, it allows for reliable estimation using link travel time data from probe vehicles. With probe vehicle data already covering most urban roads, this feature enhances the proposed method's potential for widespread deployment. The method was comprehensively evaluated using the SUMO simulation platform. Experimental results demonstrate that the proposed model effectively mitigates large-scale regional congestion levels via coordinated multi-intersection control.",
    "categories": [
      "cs.AI",
      "cs.LG"
    ],
    "primary_category": "cs.AI",
    "comment": "A critical error in the methodology. The reported congestion control effects were not caused by the proposed signal timing optimization, but by an incorrect traffic volume scaling factor during evaluation. The traffic demand was not properly amplified, resulting in misleading performance gains. Due to the substantial nature of the error, completion of revisions is not feasible in the short term",
    "pdf_url": "https://arxiv.org/pdf/2511.00551v2",
    "published_date": "2025-11-01 13:29:13 UTC",
    "updated_date": "2026-01-12 23:21:57 UTC"
  },
  {
    "arxiv_id": "2511.00549v2",
    "title": "Robust Single-Agent Reinforcement Learning for Regional Traffic Signal Control Under Demand Fluctuations",
    "authors": [
      "Qiang Li",
      "Jin Niu",
      "Lina Yu"
    ],
    "abstract": "Traffic congestion, primarily driven by intersection queuing, significantly impacts urban living standards, safety, environmental quality, and economic efficiency. While Traffic Signal Control (TSC) systems hold potential for congestion mitigation, traditional optimization models often fail to capture real-world traffic complexity and dynamics. This study introduces a novel single-agent reinforcement learning (RL) framework for regional adaptive TSC, circumventing the coordination complexities inherent in multi-agent systems through a centralized decision-making paradigm. The model employs an adjacency matrix to unify the encoding of road network topology, real-time queue states derived from probe vehicle data, and current signal timing parameters. Leveraging the efficient learning capabilities of the DreamerV3 world model, the agent learns control policies where actions sequentially select intersections and adjust their signal phase splits to regulate traffic inflow/outflow, analogous to a feedback control system. Reward design prioritizes queue dissipation, directly linking congestion metrics (queue length) to control actions. Simulation experiments conducted in SUMO demonstrate the model's effectiveness: under inference scenarios with multi-level (10%, 20%, 30%) Origin-Destination (OD) demand fluctuations, the framework exhibits robust anti-fluctuation capability and significantly reduces queue lengths. This work establishes a new paradigm for intelligent traffic control compatible with probe vehicle technology. Future research will focus on enhancing practical applicability by incorporating stochastic OD demand fluctuations during training and exploring regional optimization mechanisms for contingency events.",
    "categories": [
      "cs.LG",
      "cs.AI"
    ],
    "primary_category": "cs.LG",
    "comment": "A critical error in the methodology. The reported congestion control effects were not caused by the proposed signal timing optimization, but by an incorrect traffic volume scaling factor during evaluation. The traffic demand was not properly amplified, resulting in misleading performance gains. Due to the substantial nature of the error, completion of revisions is not feasible in the short term",
    "pdf_url": "https://arxiv.org/pdf/2511.00549v2",
    "published_date": "2025-11-01 13:18:50 UTC",
    "updated_date": "2026-01-12 23:22:21 UTC"
  },
  {
    "arxiv_id": "2511.00547v1",
    "title": "Efficient Generation of Binary Magic Squares",
    "authors": [
      "Alain Riou"
    ],
    "abstract": "We propose a simple algorithm for generating Binary Magic Squares (BMS), i.e., square binary matrices where the sum of all rows and all columns are equal. We show by induction that our algorithm always returns valid BMS with optimal theoretical complexity. We then extend our study to non-square Binary Magic Squares, formalize conditions on the sum of rows and columns for these BMS to exist, and show that a slight variant of our first algorithm can generate provably generate them. Finally, we publicly release two implementations of our algorithm as Python packages, including one that can generate several BMS in parallel using GPU acceleration.",
    "categories": [
      "cs.AI"
    ],
    "primary_category": "cs.AI",
    "comment": "",
    "pdf_url": "https://arxiv.org/pdf/2511.00547v1",
    "published_date": "2025-11-01 13:15:22 UTC",
    "updated_date": "2025-11-01 13:15:22 UTC"
  },
  {
    "arxiv_id": "2511.00532v1",
    "title": "Air Pollution Forecasting in Bucharest",
    "authors": [
      "DragoÅ-Andrei Åerban",
      "RÄzvan-Alexandru SmÄdu",
      "Dumitru-Clementin Cercel"
    ],
    "abstract": "Air pollution, especially the particulate matter 2.5 (PM2.5), has become a growing concern in recent years, primarily in urban areas. Being exposed to air pollution is linked to developing numerous health problems, like the aggravation of respiratory diseases, cardiovascular disorders, lung function impairment, and even cancer or early death. Forecasting future levels of PM2.5 has become increasingly important over the past few years, as it can provide early warnings and help prevent diseases. This paper aims to design, fine-tune, test, and evaluate machine learning models for predicting future levels of PM2.5 over various time horizons. Our primary objective is to assess and compare the performance of multiple models, ranging from linear regression algorithms and ensemble-based methods to deep learning models, such as advanced recurrent neural networks and transformers, as well as large language models, on this forecasting task.",
    "categories": [
      "cs.LG",
      "cs.AI",
      "cs.CY",
      "stat.AP"
    ],
    "primary_category": "cs.LG",
    "comment": "14 pages 3 figures",
    "pdf_url": "https://arxiv.org/pdf/2511.00532v1",
    "published_date": "2025-11-01 12:24:11 UTC",
    "updated_date": "2025-11-01 12:24:11 UTC"
  },
  {
    "arxiv_id": "2511.00529v2",
    "title": "On Improvisation and Open-Endedness: Insights for Experiential AI",
    "authors": [
      "Botao 'Amber' Hu"
    ],
    "abstract": "Improvisation-the art of spontaneous creation that unfolds moment-to-moment without a scripted outcome-requires practitioners to continuously sense, adapt, and create anew. It is a fundamental mode of human creativity spanning music, dance, and everyday life. The open-ended nature of improvisation produces a stream of novel, unrepeatable moments-an aspect highly valued in artistic creativity. In parallel, open-endedness (OE)-a system's capacity for unbounded novelty and endless \"interestingness\"-is exemplified in natural or cultural evolution and has been considered \"the last grand challenge\" in artificial life (ALife). The rise of generative AI now raises the question in computational creativity (CC) research: What makes a \"good\" improvisation for AI? Can AI learn to improvise in a genuinely open-ended way? In this work-in-progress paper, we report insights from in-depth interviews with 6 experts in improvisation across dance, music, and contact improvisation. We draw systemic connections between human improvisational arts and the design of future experiential AI agents that could improvise alone or alongside humans-or even with other AI agents-embodying qualities of improvisation drawn from practice: active listening (umwelt and awareness), being in the time (mindfulness and ephemerality), embracing the unknown (source of randomness and serendipity), non-judgmental flow (acceptance and dynamical stability, balancing structure and surprise (unpredictable criticality at edge of chaos), imaginative metaphor (synaesthesia and planning), empathy, trust, boundary, and care (mutual theory of mind), and playfulness and intrinsic motivation (maintaining interestingness).",
    "categories": [
      "cs.HC",
      "cs.AI",
      "cs.NE",
      "eess.SY"
    ],
    "primary_category": "cs.HC",
    "comment": "Submitted to AAAI 2026 Creative AI for Live Interactive Performances Workshop (CLIP) as a work-in-progress paper",
    "pdf_url": "https://arxiv.org/pdf/2511.00529v2",
    "published_date": "2025-11-01 12:13:02 UTC",
    "updated_date": "2025-11-05 06:09:53 UTC"
  },
  {
    "arxiv_id": "2511.00527v1",
    "title": "HIP-LLM: A Hierarchical Imprecise Probability Approach to Reliability Assessment of Large Language Models",
    "authors": [
      "Robab Aghazadeh-Chakherlou",
      "Qing Guo",
      "Siddartha Khastgir",
      "Peter Popov",
      "Xiaoge Zhang",
      "Xingyu Zhao"
    ],
    "abstract": "Large Language Models (LLMs) are increasingly deployed across diverse domains, raising the need for rigorous reliability assessment methods. Existing benchmark-based evaluations primarily offer descriptive statistics of model accuracy over datasets, providing limited insight into the probabilistic behavior of LLMs under real operational conditions. This paper introduces HIP-LLM, a Hierarchical Imprecise Probability framework for modeling and inferring LLM reliability. Building upon the foundations of software reliability engineering, HIP-LLM defines LLM reliability as the probability of failure-free operation over a specified number of future tasks under a given Operational Profile (OP). HIP-LLM represents dependencies across (sub-)domains hierarchically, enabling multi-level inference from subdomain to system-level reliability. HIP-LLM embeds imprecise priors to capture epistemic uncertainty and incorporates OPs to reflect usage contexts. It derives posterior reliability envelopes that quantify uncertainty across priors and data. Experiments on multiple benchmark datasets demonstrate that HIP-LLM offers a more accurate and standardized reliability characterization than existing benchmark and state-of-the-art approaches. A publicly accessible repository of HIP-LLM is provided.",
    "categories": [
      "cs.SE",
      "cs.AI"
    ],
    "primary_category": "cs.SE",
    "comment": "under review",
    "pdf_url": "https://arxiv.org/pdf/2511.00527v1",
    "published_date": "2025-11-01 12:04:30 UTC",
    "updated_date": "2025-11-01 12:04:30 UTC"
  },
  {
    "arxiv_id": "2511.00521v2",
    "title": "Reasoning Planning for Language Models",
    "authors": [
      "Bao Nguyen",
      "Hieu Trung Nguyen",
      "Ruifeng She",
      "Xiaojin Fu",
      "Viet Anh Nguyen"
    ],
    "abstract": "Selecting an appropriate reasoning method for a given query remains a key challenge in language model generation. Existing approaches typically generate multiple candidate responses and use an aggregation strategy to select the output answer, often assuming that more candidate answers yield higher accuracy. We revisit this assumption through a rigorous theoretical analysis, deriving accuracy bounds for standard aggregation methods under fixed generation distributions and candidate sizes. Building on these insights, we introduce EPIC, an Ensemble Planning with Contrastive learning framework to learn a shared representation space that captures both model reasoning abilities and query-method compatibility. EPIC incorporates our probability bounds as a regularizer in a utility-driven optimization that balances accuracy and computational cost. Experiments on diverse mathematical reasoning tasks show that EPIC consistently selects optimal reasoning methods, improving accuracy while reducing computational overhead. Our code can be found at https://github.com/nguyenngocbaocmt02/EPIC.",
    "categories": [
      "cs.LG",
      "cs.AI",
      "cs.CL"
    ],
    "primary_category": "cs.LG",
    "comment": "27 pages, 5 figures",
    "pdf_url": "https://arxiv.org/pdf/2511.00521v2",
    "published_date": "2025-11-01 11:51:53 UTC",
    "updated_date": "2025-11-10 03:30:17 UTC"
  },
  {
    "arxiv_id": "2511.00509v1",
    "title": "Reimagining Safety Alignment with An Image",
    "authors": [
      "Yifan Xia",
      "Guorui Chen",
      "Wenqian Yu",
      "Zhijiang Li",
      "Philip Torr",
      "Jindong Gu"
    ],
    "abstract": "Large language models (LLMs) excel in diverse applications but face dual challenges: generating harmful content under jailbreak attacks and over-refusal of benign queries due to rigid safety mechanisms. These issues are further complicated by the need to accommodate different value systems and precisely align with given safety preferences. Moreover, traditional methods like SFT and RLHF lack this capability due to their costly parameter tuning requirements and inability to support multiple value systems within a single model. These problems are more obvious in multimodal large language models (MLLMs), especially in terms of heightened over-refusal in cross-modal tasks and new security risks arising from expanded attack surfaces. We propose Magic Image, an optimization-driven visual prompt framework that enhances security while reducing over-refusal. By optimizing image prompts using harmful/benign samples, our method enables a single model to adapt to different value systems and better align with given safety preferences without parameter updates. Experiments demonstrate improved safety-effectiveness balance across diverse datasets while preserving model performance, offering a practical solution for deployable MLLM safety alignment.",
    "categories": [
      "cs.AI",
      "cs.CR"
    ],
    "primary_category": "cs.AI",
    "comment": "",
    "pdf_url": "https://arxiv.org/pdf/2511.00509v1",
    "published_date": "2025-11-01 11:27:07 UTC",
    "updated_date": "2025-11-01 11:27:07 UTC"
  },
  {
    "arxiv_id": "2511.00494v2",
    "title": "An Indoor Radio Mapping Dataset Combining 3D Point Clouds and RSSI",
    "authors": [
      "Ljupcho Milosheski",
      "Kuon Akiyama",
      "BlaÅ¾ BertalaniÄ",
      "Jernej Hribar",
      "Ryoichi Shinkuma"
    ],
    "abstract": "The growing number of smart devices supporting bandwidth-intensive and latency-sensitive applications, such as real-time video analytics, smart sensing, Extended Reality (XR), etc., necessitates reliable wireless connectivity in indoor environments. In such environments, accurate design of Radio Environment Maps (REMs) enables adaptive wireless network planning and optimization of Access Point (AP) placement. However, generating realistic REMs remains difficult due to the variability of indoor environments and the limitations of existing modeling approaches, which often rely on simplified layouts or fully synthetic data. These challenges are further amplified by the adoption of next-generation Wi-Fi standards, which operate at higher frequencies and suffer from limited range and wall penetration. To support the efforts in addressing these challenges, we collected a dataset that combines high-resolution 3D LiDAR scans with Wi-Fi RSSI measurements collected across 20 setups in a multi-room indoor environment. The dataset includes two measurement scenarios, the first without human presence in the environment, and the second with human presence, enabling the development and validation of REM estimation models that incorporate physical geometry and environmental dynamics. The described dataset supports research in data-driven wireless modeling and the development of high-capacity indoor communication networks.",
    "categories": [
      "eess.SP",
      "cs.AI"
    ],
    "primary_category": "eess.SP",
    "comment": "12 pages, 7 figures, 3 tables, under review to Nature Scientific Data",
    "pdf_url": "https://arxiv.org/pdf/2511.00494v2",
    "published_date": "2025-11-01 11:02:16 UTC",
    "updated_date": "2025-12-04 09:45:05 UTC"
  },
  {
    "arxiv_id": "2511.00477v1",
    "title": "Investigating Label Bias and Representational Sources of Age-Related Disparities in Medical Segmentation",
    "authors": [
      "Aditya Parikh",
      "Sneha Das",
      "Aasa Feragen"
    ],
    "abstract": "Algorithmic bias in medical imaging can perpetuate health disparities, yet its causes remain poorly understood in segmentation tasks. While fairness has been extensively studied in classification, segmentation remains underexplored despite its clinical importance. In breast cancer segmentation, models exhibit significant performance disparities against younger patients, commonly attributed to physiological differences in breast density. We audit the MAMA-MIA dataset, establishing a quantitative baseline of age-related bias in its automated labels, and reveal a critical Biased Ruler effect where systematically flawed labels for validation misrepresent a model's actual bias. However, whether this bias originates from lower-quality annotations (label bias) or from fundamentally more challenging image characteristics remains unclear. Through controlled experiments, we systematically refute hypotheses that the bias stems from label quality sensitivity or quantitative case difficulty imbalance. Balancing training data by difficulty fails to mitigate the disparity, revealing that younger patient cases are intrinsically harder to learn. We provide direct evidence that systemic bias is learned and amplified when training on biased, machine-generated labels, a critical finding for automated annotation pipelines. This work introduces a systematic framework for diagnosing algorithmic bias in medical segmentation and demonstrates that achieving fairness requires addressing qualitative distributional differences rather than merely balancing case counts.",
    "categories": [
      "eess.IV",
      "cs.AI",
      "cs.CV"
    ],
    "primary_category": "eess.IV",
    "comment": "Submitted to ISBI 2026",
    "pdf_url": "https://arxiv.org/pdf/2511.00477v1",
    "published_date": "2025-11-01 10:06:30 UTC",
    "updated_date": "2025-11-01 10:06:30 UTC"
  },
  {
    "arxiv_id": "2511.00472v1",
    "title": "Longitudinal Vestibular Schwannoma Dataset with Consensus-based Human-in-the-loop Annotations",
    "authors": [
      "Navodini Wijethilake",
      "Marina Ivory",
      "Oscar MacCormac",
      "Siddhant Kumar",
      "Aaron Kujawa",
      "Lorena Garcia-Foncillas Macias",
      "Rebecca Burger",
      "Amanda Hitchings",
      "Suki Thomson",
      "Sinan Barazi",
      "Eleni Maratos",
      "Rupert Obholzer",
      "Dan Jiang",
      "Fiona McClenaghan",
      "Kazumi Chia",
      "Omar Al-Salihi",
      "Nick Thomas",
      "Steve Connor",
      "Tom Vercauteren",
      "Jonathan Shapey"
    ],
    "abstract": "Accurate segmentation of vestibular schwannoma (VS) on Magnetic Resonance Imaging (MRI) is essential for patient management but often requires time-intensive manual annotations by experts. While recent advances in deep learning (DL) have facilitated automated segmentation, challenges remain in achieving robust performance across diverse datasets and complex clinical cases. We present an annotated dataset stemming from a bootstrapped DL-based framework for iterative segmentation and quality refinement of VS in MRI. We combine data from multiple centres and rely on expert consensus for trustworthiness of the annotations. We show that our approach enables effective and resource-efficient generalisation of automated segmentation models to a target data distribution. The framework achieved a significant improvement in segmentation accuracy with a Dice Similarity Coefficient (DSC) increase from 0.9125 to 0.9670 on our target internal validation dataset, while maintaining stable performance on representative external datasets. Expert evaluation on 143 scans further highlighted areas for model refinement, revealing nuanced cases where segmentation required expert intervention. The proposed approach is estimated to enhance efficiency by approximately 37.4% compared to the conventional manual annotation process. Overall, our human-in-the-loop model training approach achieved high segmentation accuracy, highlighting its potential as a clinically adaptable and generalisable strategy for automated VS segmentation in diverse clinical settings. The dataset includes 190 patients, with tumour annotations available for 534 longitudinal contrast-enhanced T1-weighted (T1CE) scans from 184 patients, and non-annotated T2-weighted scans from 6 patients. This dataset is publicly accessible on The Cancer Imaging Archive (TCIA) (https://doi.org/10.7937/bq0z-xa62).",
    "categories": [
      "cs.CV",
      "cs.AI"
    ],
    "primary_category": "cs.CV",
    "comment": "",
    "pdf_url": "https://arxiv.org/pdf/2511.00472v1",
    "published_date": "2025-11-01 09:53:28 UTC",
    "updated_date": "2025-11-01 09:53:28 UTC"
  },
  {
    "arxiv_id": "2511.00469v1",
    "title": "Why Federated Optimization Fails to Achieve Perfect Fitting? A Theoretical Perspective on Client-Side Optima",
    "authors": [
      "Zhongxiang Lei",
      "Qi Yang",
      "Ping Qiu",
      "Gang Zhang",
      "Yuanchi Ma",
      "Jinyan Liu"
    ],
    "abstract": "Federated optimization is a constrained form of distributed optimization that enables training a global model without directly sharing client data. Although existing algorithms can guarantee convergence in theory and often achieve stable training in practice, the reasons behind performance degradation under data heterogeneity remain unclear. To address this gap, the main contribution of this paper is to provide a theoretical perspective that explains why such degradation occurs. We introduce the assumption that heterogeneous client data lead to distinct local optima, and show that this assumption implies two key consequences: 1) the distance among clients' local optima raises the lower bound of the global objective, making perfect fitting of all client data impossible; and 2) in the final training stage, the global model oscillates within a region instead of converging to a single optimum, limiting its ability to fully fit the data. These results provide a principled explanation for performance degradation in non-iid settings, which we further validate through experiments across multiple tasks and neural network architectures. The framework used in this paper is open-sourced at: https://github.com/NPCLEI/fedtorch.",
    "categories": [
      "cs.LG",
      "cs.AI",
      "stat.ML"
    ],
    "primary_category": "cs.LG",
    "comment": "",
    "pdf_url": "https://arxiv.org/pdf/2511.00469v1",
    "published_date": "2025-11-01 09:31:35 UTC",
    "updated_date": "2025-11-01 09:31:35 UTC"
  },
  {
    "arxiv_id": "2511.00460v1",
    "title": "Proactive DDoS Detection and Mitigation in Decentralized Software-Defined Networking via Port-Level Monitoring and Zero-Training Large Language Models",
    "authors": [
      "Mohammed N. Swileh",
      "Shengli Zhang"
    ],
    "abstract": "Centralized Software-Defined Networking (cSDN) offers flexible and programmable control of networks but suffers from scalability and reliability issues due to its reliance on centralized controllers. Decentralized SDN (dSDN) alleviates these concerns by distributing control across multiple local controllers, yet this architecture remains highly vulnerable to Distributed Denial-of-Service (DDoS) attacks. In this paper, we propose a novel detection and mitigation framework tailored for dSDN environments. The framework leverages lightweight port-level statistics combined with prompt engineering and in-context learning, enabling the DeepSeek-v3 Large Language Model (LLM) to classify traffic as benign or malicious without requiring fine-tuning or retraining. Once an anomaly is detected, mitigation is enforced directly at the attacker's port, ensuring that malicious traffic is blocked at their origin while normal traffic remains unaffected. An automatic recovery mechanism restores normal operation after the attack inactivity, ensuring both security and availability. Experimental evaluation under diverse DDoS attack scenarios demonstrates that the proposed approach achieves near-perfect detection, with 99.99% accuracy, 99.97% precision, 100% recall, 99.98% F1-score, and an AUC of 1.0. These results highlight the effectiveness of combining distributed monitoring with zero-training LLM inference, providing a proactive and scalable defense mechanism for securing dSDN infrastructures against DDoS threats.",
    "categories": [
      "cs.CR",
      "cs.AI"
    ],
    "primary_category": "cs.CR",
    "comment": "",
    "pdf_url": "https://arxiv.org/pdf/2511.00460v1",
    "published_date": "2025-11-01 08:57:29 UTC",
    "updated_date": "2025-11-01 08:57:29 UTC"
  },
  {
    "arxiv_id": "2511.00457v2",
    "title": "GraphChain: Large Language Models for Large-scale Graph Analysis via Tool Chaining",
    "authors": [
      "Chunyu Wei",
      "Wenji Hu",
      "Xingjia Hao",
      "Xin Wang",
      "Yifan Yang",
      "Yueguo Chen",
      "Yang Tian",
      "Yunhai Wang"
    ],
    "abstract": "Large Language Models (LLMs) face significant limitations when applied to large-scale graphs, struggling with context constraints and inflexible reasoning. We present GraphChain, a framework that enables LLMs to analyze complex graphs through dynamic sequences of specialized tools, mimicking human exploratory intelligence. Our approach introduces two key innovations: (1) Progressive Graph Distillation, a reinforcement learning mechanism that generates optimized tool sequences balancing task relevance with information compression, and (2) Structure-aware Test-Time Adaptation, which efficiently tailors tool selection strategies to diverse graph topologies using spectral properties and lightweight adapters without costly retraining. Experiments show GraphChain significantly outperforms prior methods, enabling scalable and adaptive LLM-driven graph analysis.",
    "categories": [
      "cs.AI"
    ],
    "primary_category": "cs.AI",
    "comment": "Accepted by NeurIPS 2025",
    "pdf_url": "https://arxiv.org/pdf/2511.00457v2",
    "published_date": "2025-11-01 08:47:05 UTC",
    "updated_date": "2025-11-08 04:47:20 UTC"
  },
  {
    "arxiv_id": "2511.00456v5",
    "title": "Weakly Supervised Pneumonia Localization from Chest X-Rays Using Deep Neural Network and Grad-CAM Explanations",
    "authors": [
      "Kiran Shahi",
      "Anup Bagale"
    ],
    "abstract": "Chest X-ray imaging is commonly used to diagnose pneumonia, but accurately localizing the pneumonia-affected regions typically requires detailed pixel-level annotations, which are costly and time consuming to obtain. To address this limitation, this study proposes a weakly supervised deep learning framework for pneumonia classification and localization using Gradient-weighted Class Activation Mapping (Grad-CAM). Instead of relying on costly pixel-level annotations, the proposed method utilizes image-level labels to generate clinically meaningful heatmaps that highlight pneumonia-affected regions. Furthermore, we evaluate seven pre-trained deep learning models, including a Vision Transformer, under identical training conditions, using focal loss and patient-wise splits to prevent data leakage. Experimental results suggest that all models achieved high classification accuracy (96--98\\%), with ResNet-18 and EfficientNet-B0 showing the best overall performance and MobileNet-V3 providing an efficient lightweight alternative. Grad-CAM heatmap visualizations confirm that the proposed methods focus on clinically relevant lung regions, supporting the use of explainable AI for radiological diagnostics. Overall, this work highlights the potential of weakly supervised, explainable models that enhance transparency and clinical trust in AI-assisted pneumonia screening.",
    "categories": [
      "cs.CV",
      "cs.AI"
    ],
    "primary_category": "cs.CV",
    "comment": "https://github.com/kiranshahi/pneumonia-analysis",
    "pdf_url": "https://arxiv.org/pdf/2511.00456v5",
    "published_date": "2025-11-01 08:44:24 UTC",
    "updated_date": "2025-12-17 11:27:35 UTC"
  },
  {
    "arxiv_id": "2511.00447v2",
    "title": "DRIP: Defending Prompt Injection via Token-wise Representation Editing and Residual Instruction Fusion",
    "authors": [
      "Ruofan Liu",
      "Yun Lin",
      "Zhiyong Huang",
      "Jin Song Dong"
    ],
    "abstract": "Large language models (LLMs) are increasingly integrated into IT infrastructures, where they process user data according to predefined instructions. However, conventional LLMs remain vulnerable to prompt injection, where malicious users inject directive tokens into the data to subvert model behavior. Existing defenses train LLMs to semantically separate data and instruction tokens, but still struggle to (1) balance utility and security and (2) prevent instruction-like semantics in the data from overriding the intended instructions.\n  We propose DRIP, which (1) precisely removes instruction semantics from tokens in the data section while preserving their data semantics, and (2) robustly preserves the effect of the intended instruction even under strong adversarial content. To \"de-instructionalize\" data tokens, DRIP introduces a data curation and training paradigm with a lightweight representation-editing module that edits embeddings of instruction-like tokens in the data section, enhancing security without harming utility. To ensure non-overwritability of instructions, DRIP adds a minimal residual module that reduces the ability of adversarial data to overwrite the original instruction. We evaluate DRIP on LLaMA 8B and Mistral 7B against StruQ, SecAlign, ISE, and PFT on three prompt-injection benchmarks (SEP, AlpacaFarm, and InjecAgent). DRIP improves role-separation score by 12-49\\%, reduces attack success rate by over 66\\% under adaptive attacks, and matches the utility of the undefended model, establishing a new state of the art for prompt-injection robustness.",
    "categories": [
      "cs.CR",
      "cs.AI"
    ],
    "primary_category": "cs.CR",
    "comment": "",
    "pdf_url": "https://arxiv.org/pdf/2511.00447v2",
    "published_date": "2025-11-01 08:26:37 UTC",
    "updated_date": "2025-11-18 02:40:00 UTC"
  },
  {
    "arxiv_id": "2511.00444v1",
    "title": "LIR: The First Workshop on Late Interaction and Multi Vector Retrieval @ ECIR 2026",
    "authors": [
      "Benjamin ClaviÃ©",
      "Xianming Li",
      "Antoine Chaffin",
      "Omar Khattab",
      "Tom Aarsen",
      "Manuel Faysse",
      "Jing Li"
    ],
    "abstract": "Late interaction retrieval methods, pioneered by ColBERT, have emerged as a powerful alternative to single-vector neural IR. By leveraging fine-grained, token-level representations, they have been demonstrated to deliver strong generalisation and robustness, particularly in out-of-domain settings. They have recently been shown to be particularly well-suited for novel use cases, such as reasoning-based or cross-modality retrieval. At the same time, these models pose significant challenges of efficiency, usability, and integrations into fully fledged systems; as well as the natural difficulties encountered while researching novel application domains. Recent years have seen rapid advances across many of these areas, but research efforts remain fragmented across communities and frequently exclude practitioners. The purpose of this workshop is to create an environment where all aspects of late interaction can be discussed, with a focus on early research explorations, real-world outcomes, and negative or puzzling results to be freely shared and discussed. The aim of LIR is to provide a highly-interactive environment for researchers from various backgrounds and practitioners to freely discuss their experience, fostering further collaboration.",
    "categories": [
      "cs.IR",
      "cs.AI"
    ],
    "primary_category": "cs.IR",
    "comment": "Accepted workshop at ECIR 2026",
    "pdf_url": "https://arxiv.org/pdf/2511.00444v1",
    "published_date": "2025-11-01 08:21:33 UTC",
    "updated_date": "2025-11-01 08:21:33 UTC"
  },
  {
    "arxiv_id": "2511.00443v1",
    "title": "Region-Aware Reconstruction Strategy for Pre-training fMRI Foundation Model",
    "authors": [
      "Ruthwik Reddy Doodipala",
      "Pankaj Pandey",
      "Carolina Torres Rojas",
      "Manob Jyoti Saikia",
      "Ranganatha Sitaram"
    ],
    "abstract": "The emergence of foundation models in neuroimaging is driven by the increasing availability of large-scale and heterogeneous brain imaging datasets. Recent advances in self-supervised learning, particularly reconstruction-based objectives, have demonstrated strong potential for pretraining models that generalize effectively across diverse downstream functional MRI (fMRI) tasks. In this study, we explore region-aware reconstruction strategies for a foundation model in resting-state fMRI, moving beyond approaches that rely on random region masking. Specifically, we introduce an ROI-guided masking strategy using the Automated Anatomical Labelling Atlas (AAL3), applied directly to full 4D fMRI volumes to selectively mask semantically coherent brain regions during self-supervised pretraining. Using the ADHD-200 dataset comprising 973 subjects with resting-state fMRI scans, we show that our method achieves a 4.23% improvement in classification accuracy for distinguishing healthy controls from individuals diagnosed with ADHD, compared to conventional random masking. Region-level attribution analysis reveals that brain volumes within the limbic region and cerebellum contribute most significantly to reconstruction fidelity and model representation. Our results demonstrate that masking anatomical regions during model pretraining not only enhances interpretability but also yields more robust and discriminative representations. In future work, we plan to extend this approach by evaluating it on additional neuroimaging datasets, and developing new loss functions explicitly derived from region-aware reconstruction objectives. These directions aim to further improve the robustness and interpretability of foundation models for functional neuroimaging.",
    "categories": [
      "cs.LG",
      "cs.AI",
      "cs.CV"
    ],
    "primary_category": "cs.LG",
    "comment": "",
    "pdf_url": "https://arxiv.org/pdf/2511.00443v1",
    "published_date": "2025-11-01 08:12:00 UTC",
    "updated_date": "2025-11-01 08:12:00 UTC"
  },
  {
    "arxiv_id": "2511.00429v1",
    "title": "Enhancing Frequency Forgery Clues for Diffusion-Generated Image Detection",
    "authors": [
      "Daichi Zhang",
      "Tong Zhang",
      "Shiming Ge",
      "Sabine SÃ¼sstrunk"
    ],
    "abstract": "Diffusion models have achieved remarkable success in image synthesis, but the generated high-quality images raise concerns about potential malicious use. Existing detectors often struggle to capture discriminative clues across different models and settings, limiting their generalization to unseen diffusion models and robustness to various perturbations. To address this issue, we observe that diffusion-generated images exhibit progressively larger differences from natural real images across low- to high-frequency bands. Based on this insight, we propose a simple yet effective representation by enhancing the Frequency Forgery Clue (F^2C) across all frequency bands. Specifically, we introduce a frequency-selective function which serves as a weighted filter to the Fourier spectrum, suppressing less discriminative bands while enhancing more informative ones. This approach, grounded in a comprehensive analysis of frequency-based differences between natural real and diffusion-generated images, enables general detection of images from unseen diffusion models and provides robust resilience to various perturbations. Extensive experiments on various diffusion-generated image datasets demonstrate that our method outperforms state-of-the-art detectors with superior generalization and robustness.",
    "categories": [
      "cs.CV",
      "cs.AI"
    ],
    "primary_category": "cs.CV",
    "comment": "",
    "pdf_url": "https://arxiv.org/pdf/2511.00429v1",
    "published_date": "2025-11-01 06:58:05 UTC",
    "updated_date": "2025-11-01 06:58:05 UTC"
  },
  {
    "arxiv_id": "2511.00427v1",
    "title": "Leveraging Hierarchical Image-Text Misalignment for Universal Fake Image Detection",
    "authors": [
      "Daichi Zhang",
      "Tong Zhang",
      "Jianmin Bao",
      "Shiming Ge",
      "Sabine SÃ¼sstrunk"
    ],
    "abstract": "With the rapid development of generative models, detecting generated fake images to prevent their malicious use has become a critical issue recently. Existing methods frame this challenge as a naive binary image classification task. However, such methods focus only on visual clues, yielding trained detectors susceptible to overfitting specific image patterns and incapable of generalizing to unseen models. In this paper, we address this issue from a multi-modal perspective and find that fake images cannot be properly aligned with corresponding captions compared to real images. Upon this observation, we propose a simple yet effective detector termed ITEM by leveraging the image-text misalignment in a joint visual-language space as discriminative clues. Specifically, we first measure the misalignment of the images and captions in pre-trained CLIP's space, and then tune a MLP head to perform the usual detection task. Furthermore, we propose a hierarchical misalignment scheme that first focuses on the whole image and then each semantic object described in the caption, which can explore both global and fine-grained local semantic misalignment as clues. Extensive experiments demonstrate the superiority of our method against other state-of-the-art competitors with impressive generalization and robustness on various recent generative models.",
    "categories": [
      "cs.CV",
      "cs.AI"
    ],
    "primary_category": "cs.CV",
    "comment": "",
    "pdf_url": "https://arxiv.org/pdf/2511.00427v1",
    "published_date": "2025-11-01 06:51:14 UTC",
    "updated_date": "2025-11-01 06:51:14 UTC"
  },
  {
    "arxiv_id": "2511.00424v1",
    "title": "A Multimodal Framework for Depression Detection during Covid-19 via Harvesting Social Media: A Novel Dataset and Method",
    "authors": [
      "Ashutosh Anshul",
      "Gumpili Sai Pranav",
      "Mohammad Zia Ur Rehman",
      "Nagendra Kumar"
    ],
    "abstract": "The recent coronavirus disease (Covid-19) has become a pandemic and has affected the entire globe. During the pandemic, we have observed a spike in cases related to mental health, such as anxiety, stress, and depression. Depression significantly influences most diseases worldwide, making it difficult to detect mental health conditions in people due to unawareness and unwillingness to consult a doctor. However, nowadays, people extensively use online social media platforms to express their emotions and thoughts. Hence, social media platforms are now becoming a large data source that can be utilized for detecting depression and mental illness. However, existing approaches often overlook data sparsity in tweets and the multimodal aspects of social media. In this paper, we propose a novel multimodal framework that combines textual, user-specific, and image analysis to detect depression among social media users. To provide enough context about the user's emotional state, we propose (i) an extrinsic feature by harnessing the URLs present in tweets and (ii) extracting textual content present in images posted in tweets. We also extract five sets of features belonging to different modalities to describe a user. Additionally, we introduce a Deep Learning model, the Visual Neural Network (VNN), to generate embeddings of user-posted images, which are used to create the visual feature vector for prediction. We contribute a curated Covid-19 dataset of depressed and non-depressed users for research purposes and demonstrate the effectiveness of our model in detecting depression during the Covid-19 outbreak. Our model outperforms existing state-of-the-art methods over a benchmark dataset by 2%-8% and produces promising results on the Covid-19 dataset. Our analysis highlights the impact of each modality and provides valuable insights into users' mental and emotional states.",
    "categories": [
      "cs.AI"
    ],
    "primary_category": "cs.AI",
    "comment": "",
    "pdf_url": "https://arxiv.org/pdf/2511.00424v1",
    "published_date": "2025-11-01 06:33:14 UTC",
    "updated_date": "2025-11-01 06:33:14 UTC"
  },
  {
    "arxiv_id": "2511.00423v3",
    "title": "Bootstrap Off-policy with World Model",
    "authors": [
      "Guojian Zhan",
      "Likun Wang",
      "Xiangteng Zhang",
      "Jiaxin Gao",
      "Masayoshi Tomizuka",
      "Shengbo Eben Li"
    ],
    "abstract": "Online planning has proven effective in reinforcement learning (RL) for improving sample efficiency and final performance. However, using planning for environment interaction inevitably introduces a divergence between the collected data and the policy's actual behaviors, degrading both model learning and policy improvement. To address this, we propose BOOM (Bootstrap Off-policy with WOrld Model), a framework that tightly integrates planning and off-policy learning through a bootstrap loop: the policy initializes the planner, and the planner refines actions to bootstrap the policy through behavior alignment. This loop is supported by a jointly learned world model, which enables the planner to simulate future trajectories and provides value targets to facilitate policy improvement. The core of BOOM is a likelihood-free alignment loss that bootstraps the policy using the planner's non-parametric action distribution, combined with a soft value-weighted mechanism that prioritizes high-return behaviors and mitigates variability in the planner's action quality within the replay buffer. Experiments on the high-dimensional DeepMind Control Suite and Humanoid-Bench show that BOOM achieves state-of-the-art results in both training stability and final performance. The code is accessible at https://github.com/molumitu/BOOM_MBRL.",
    "categories": [
      "cs.LG",
      "cs.AI",
      "cs.RO"
    ],
    "primary_category": "cs.LG",
    "comment": "NeurIPS 2025",
    "pdf_url": "https://arxiv.org/pdf/2511.00423v3",
    "published_date": "2025-11-01 06:33:04 UTC",
    "updated_date": "2026-01-15 13:38:44 UTC"
  },
  {
    "arxiv_id": "2511.01914v1",
    "title": "iFlyBot-VLA Technical Report",
    "authors": [
      "Yuan Zhang",
      "Chenyu Xue",
      "Wenjie Xu",
      "Chao Ji",
      "Jiajia wu",
      "Jia Pan"
    ],
    "abstract": "We introduce iFlyBot-VLA, a large-scale Vision-Language-Action (VLA) model trained under a novel framework. The main contributions are listed as follows: (1) a latent action model thoroughly trained on large-scale human and robotic manipulation videos; (2) a dual-level action representation framework that jointly supervises both the Vision-Language Model (VLM) and the action expert during training; (3) a mixed training strategy that combines robot trajectory data with general QA and spatial QA datasets, effectively enhancing the 3D perceptual and reasoning capabilities of the VLM backbone. Specifically, the VLM is trained to predict two complementary forms of actions: latent actions, derived from our latent action model pretrained on cross-embodiment manipulation data, which capture implicit high-level intentions; and structured discrete action tokens, obtained through frequency-domain transformations of continuous control signals, which encode explicit low-level dynamics. This dual supervision aligns the representation spaces of language, vision, and action, enabling the VLM to directly contribute to action generation. Experimental results on the LIBERO Franka benchmark demonstrate the superiority of our frame-work, while real-world evaluations further show that iFlyBot-VLA achieves competitive success rates across diverse and challenging manipulation tasks. Furthermore, we plan to open-source a portion of our self-constructed dataset to support future research in the community",
    "categories": [
      "cs.CV",
      "cs.AI",
      "cs.RO"
    ],
    "primary_category": "cs.CV",
    "comment": "",
    "pdf_url": "https://arxiv.org/pdf/2511.01914v1",
    "published_date": "2025-11-01 06:24:56 UTC",
    "updated_date": "2025-11-01 06:24:56 UTC"
  },
  {
    "arxiv_id": "2511.00421v1",
    "title": "MedRECT: A Medical Reasoning Benchmark for Error Correction in Clinical Texts",
    "authors": [
      "Naoto Iwase",
      "Hiroki Okuyama",
      "Junichiro Iwasawa"
    ],
    "abstract": "Large language models (LLMs) show increasing promise in medical applications, but their ability to detect and correct errors in clinical texts -- a prerequisite for safe deployment -- remains under-evaluated, particularly beyond English. We introduce MedRECT, a cross-lingual benchmark (Japanese/English) that formulates medical error handling as three subtasks: error detection, error localization (sentence extraction), and error correction. MedRECT is built with a scalable, automated pipeline from the Japanese Medical Licensing Examinations (JMLE) and a curated English counterpart, yielding MedRECT-ja (663 texts) and MedRECT-en (458 texts) with comparable error/no-error balance. We evaluate 9 contemporary LLMs spanning proprietary, open-weight, and reasoning families. Key findings: (i) reasoning models substantially outperform standard architectures, with up to 13.5% relative improvement in error detection and 51.0% in sentence extraction; (ii) cross-lingual evaluation reveals 5-10% performance gaps from English to Japanese, with smaller disparities for reasoning models; (iii) targeted LoRA fine-tuning yields asymmetric improvements in error correction performance (Japanese: +0.078, English: +0.168) while preserving reasoning capabilities; and (iv) our fine-tuned model exceeds human expert performance on structured medical error correction tasks. To our knowledge, MedRECT is the first comprehensive cross-lingual benchmark for medical error correction, providing a reproducible framework and resources for developing safer medical LLMs across languages.",
    "categories": [
      "cs.CL",
      "cs.AI",
      "cs.LG"
    ],
    "primary_category": "cs.CL",
    "comment": "",
    "pdf_url": "https://arxiv.org/pdf/2511.00421v1",
    "published_date": "2025-11-01 06:19:34 UTC",
    "updated_date": "2025-11-01 06:19:34 UTC"
  },
  {
    "arxiv_id": "2511.00419v1",
    "title": "LGCA: Enhancing Semantic Representation via Progressive Expansion",
    "authors": [
      "Thanh Hieu Cao",
      "Trung Khang Tran",
      "Gia Thinh Pham",
      "Tuong Nghiem Diep",
      "Thanh Binh Nguyen"
    ],
    "abstract": "Recent advancements in large-scale pretraining in natural language processing have enabled pretrained vision-language models such as CLIP to effectively align images and text, significantly improving performance in zero-shot image classification tasks. Subsequent studies have further demonstrated that cropping images into smaller regions and using large language models to generate multiple descriptions for each caption can further enhance model performance. However, due to the inherent sensitivity of CLIP, random image crops can introduce misinformation and bias, as many images share similar features at small scales. To address this issue, we propose Localized-Globalized Cross-Alignment (LGCA), a framework that first captures the local features of an image and then repeatedly selects the most salient regions and expands them. The similarity score is designed to incorporate both the original and expanded images, enabling the model to capture both local and global features while minimizing misinformation. Additionally, we provide a theoretical analysis demonstrating that the time complexity of LGCA remains the same as that of the original model prior to the repeated expansion process, highlighting its efficiency and scalability. Extensive experiments demonstrate that our method substantially improves zero-shot performance across diverse datasets, outperforming state-of-the-art baselines.",
    "categories": [
      "cs.CV",
      "cs.AI"
    ],
    "primary_category": "cs.CV",
    "comment": "15 pages, 5 figures, to appear in SoICT 2025",
    "pdf_url": "https://arxiv.org/pdf/2511.00419v1",
    "published_date": "2025-11-01 06:09:42 UTC",
    "updated_date": "2025-11-01 06:09:42 UTC"
  },
  {
    "arxiv_id": "2511.00417v2",
    "title": "Human-AI Programming Role Optimization: Developing a Personality-Driven Self-Determination Framework",
    "authors": [
      "Marcel Valovy"
    ],
    "abstract": "As artificial intelligence transforms software development, a critical question emerges: how can developers and AI systems collaborate most effectively? This dissertation optimizes human-AI programming roles through self-determination theory and personality psychology, introducing the Role Optimization Motivation Alignment (ROMA) framework.\n  Through Design Science Research spanning five cycles, this work establishes empirically-validated connections between personality traits, programming role preferences, and collaborative outcomes, engaging 200 experimental participants and 46 interview respondents.\n  Key findings demonstrate that personality-driven role optimization significantly enhances self-determination and team dynamics, yielding 23% average motivation increases among professionals and up to 65% among undergraduates. Five distinct personality archetypes emerge: The Explorer (high Openness/low Agreeableness), The Orchestrator (high Extraversion/Agreeableness), The Craftsperson (high Neuroticism/low Extraversion), The Architect (high Conscientiousness), and The Adapter (balanced profile). Each exhibits distinct preferences for programming roles (Co-Pilot, Co-Navigator, Agent), with assignment modes proving crucial for satisfaction.\n  The dissertation contributes: (1) an empirically-validated framework linking personality traits to role preferences and self-determination outcomes; (2) a taxonomy of AI collaboration modalities mapped to personality profiles while preserving human agency; and (3) an ISO/IEC 29110 extension enabling Very Small Entities to implement personality-driven role optimization within established standards.\n  Keywords: artificial intelligence, human-computer interaction, behavioral software engineering, self-determination theory, personality psychology, phenomenology, intrinsic motivation, pair programming, design science research, ISO/IEC 29110",
    "categories": [
      "cs.SE",
      "cs.AI",
      "cs.HC"
    ],
    "primary_category": "cs.SE",
    "comment": "PhD Dissertation, Prague University of Economics and Business, 2025. 323 pages. ACM CCS 2012: Human-computer interaction, Collaborative interaction, Human-AI collaborative systems, Pair programming, AI-assisted software engineering",
    "pdf_url": "https://arxiv.org/pdf/2511.00417v2",
    "published_date": "2025-11-01 06:00:14 UTC",
    "updated_date": "2025-11-27 03:36:49 UTC"
  },
  {
    "arxiv_id": "2511.00416v1",
    "title": "PADBen: A Comprehensive Benchmark for Evaluating AI Text Detectors Against Paraphrase Attacks",
    "authors": [
      "Yiwei Zha",
      "Rui Min",
      "Shanu Sushmita"
    ],
    "abstract": "While AI-generated text (AIGT) detectors achieve over 90\\% accuracy on direct LLM outputs, they fail catastrophically against iteratively-paraphrased content. We investigate why iteratively-paraphrased text -- itself AI-generated -- evades detection systems designed for AIGT identification. Through intrinsic mechanism analysis, we reveal that iterative paraphrasing creates an intermediate laundering region characterized by semantic displacement with preserved generation patterns, which brings up two attack categories: paraphrasing human-authored text (authorship obfuscation) and paraphrasing LLM-generated text (plagiarism evasion). To address these vulnerabilities, we introduce PADBen, the first benchmark systematically evaluating detector robustness against both paraphrase attack scenarios. PADBen comprises a five-type text taxonomy capturing the full trajectory from original content to deeply laundered text, and five progressive detection tasks across sentence-pair and single-sentence challenges. We evaluate 11 state-of-the-art detectors, revealing critical asymmetry: detectors successfully identify the plagiarism evasion problem but fail for the case of authorship obfuscation. Our findings demonstrate that current detection approaches cannot effectively handle the intermediate laundering region, necessitating fundamental advances in detection architectures beyond existing semantic and stylistic discrimination methods. For detailed code implementation, please see https://github.com/JonathanZha47/PadBen-Paraphrase-Attack-Benchmark.",
    "categories": [
      "cs.CL",
      "cs.AI"
    ],
    "primary_category": "cs.CL",
    "comment": "",
    "pdf_url": "https://arxiv.org/pdf/2511.00416v1",
    "published_date": "2025-11-01 05:59:46 UTC",
    "updated_date": "2025-11-01 05:59:46 UTC"
  },
  {
    "arxiv_id": "2511.00411v1",
    "title": "Enhancing Adversarial Transferability by Balancing Exploration and Exploitation with Gradient-Guided Sampling",
    "authors": [
      "Zenghao Niu",
      "Weicheng Xie",
      "Siyang Song",
      "Zitong Yu",
      "Feng Liu",
      "Linlin Shen"
    ],
    "abstract": "Adversarial attacks present a critical challenge to deep neural networks' robustness, particularly in transfer scenarios across different model architectures. However, the transferability of adversarial attacks faces a fundamental dilemma between Exploitation (maximizing attack potency) and Exploration (enhancing cross-model generalization). Traditional momentum-based methods over-prioritize Exploitation, i.e., higher loss maxima for attack potency but weakened generalization (narrow loss surface). Conversely, recent methods with inner-iteration sampling over-prioritize Exploration, i.e., flatter loss surfaces for cross-model generalization but weakened attack potency (suboptimal local maxima). To resolve this dilemma, we propose a simple yet effective Gradient-Guided Sampling (GGS), which harmonizes both objectives through guiding sampling along the gradient ascent direction to improve both sampling efficiency and stability. Specifically, based on MI-FGSM, GGS introduces inner-iteration random sampling and guides the sampling direction using the gradient from the previous inner-iteration (the sampling's magnitude is determined by a random distribution). This mechanism encourages adversarial examples to reside in balanced regions with both flatness for cross-model generalization and higher local maxima for strong attack potency. Comprehensive experiments across multiple DNN architectures and multimodal large language models (MLLMs) demonstrate the superiority of our method over state-of-the-art transfer attacks. Code is made available at https://github.com/anuin-cat/GGS.",
    "categories": [
      "cs.LG",
      "cs.AI",
      "cs.CV"
    ],
    "primary_category": "cs.LG",
    "comment": "accepted by iccv 2025",
    "pdf_url": "https://arxiv.org/pdf/2511.00411v1",
    "published_date": "2025-11-01 05:43:47 UTC",
    "updated_date": "2025-11-01 05:43:47 UTC"
  },
  {
    "arxiv_id": "2511.00406v2",
    "title": "Quantum Machine Unlearning: Foundations, Mechanisms, and Taxonomy",
    "authors": [
      "Thanveer Shaik",
      "Xiaohui Tao",
      "Haoran Xie"
    ],
    "abstract": "Quantum Machine Unlearning has emerged as a foundational challenge at the intersection of quantum information theory privacypreserving computation and trustworthy artificial intelligence This paper advances QMU by establishing a formal framework that unifies physical constraints algorithmic mechanisms and ethical governance within a verifiable paradigm We define forgetting as a contraction of distinguishability between pre and postunlearning models under completely positive trace-preserving dynamics grounding data removal in the physics of quantum irreversibility Building on this foundation we present a fiveaxis taxonomy spanning scope guarantees mechanisms system context and hardware realization linking theoretical constructs to implementable strategies Within this structure we incorporate influence and quantum Fisher information weighted updates parameter reinitialization and kernel alignment as practical mechanisms compatible with noisy intermediatescale quantum NISQ devices The framework extends naturally to federated and privacyaware settings via quantum differential privacy homomorphic encryption and verifiable delegation enabling scalable auditable deletion across distributed quantum systems Beyond technical design we outline a forwardlooking research roadmap emphasizing formal proofs of forgetting scalable and secure architectures postunlearning interpretability and ethically auditable governance Together these contributions elevate QMU from a conceptual notion to a rigorously defined and ethically aligned discipline bridging physical feasibility algorithmic verifiability and societal accountability in the emerging era of quantum intelligence.",
    "categories": [
      "quant-ph",
      "cs.AI"
    ],
    "primary_category": "quant-ph",
    "comment": "",
    "pdf_url": "https://arxiv.org/pdf/2511.00406v2",
    "published_date": "2025-11-01 05:11:40 UTC",
    "updated_date": "2026-01-13 07:06:29 UTC"
  },
  {
    "arxiv_id": "2511.00405v1",
    "title": "UME-R1: Exploring Reasoning-Driven Generative Multimodal Embeddings",
    "authors": [
      "Zhibin Lan",
      "Liqiang Niu",
      "Fandong Meng",
      "Jie Zhou",
      "Jinsong Su"
    ],
    "abstract": "The remarkable success of multimodal large language models (MLLMs) has driven advances in multimodal embeddings, yet existing models remain inherently discriminative, limiting their ability to benefit from reasoning-driven generation paradigm. In this work, we pioneer the exploration of generative embeddings, unifying embedding tasks within a generative paradigm. We propose UME-R1, a universal multimodal embedding framework consisting of a two-stage training strategy: a cold-start supervised fine-tuning equips the model with reasoning capabilities and enables it to generate both discriminative and generative embeddings; a subsequent reinforcement learning enhances reasoning and further optimizes generative embedding quality. This pioneering work reveals four key insights: 1) generative embeddings unlock substantial performance gains over conventional discriminative embeddings by leveraging the powerful generative reasoning capabilities of MLLMs; 2) discriminative and generative embeddings are complementary, whose combined oracle performance far exceeding that of either alone; 3) RL can effectively enhance generative embeddings, establishing a scalable optimization paradigm.; 4) repeated sampling at inference boosts downstream task coverage (pass@k), highlighting the inference-time scalability potential of generative embeddings. Evaluated on the MMEB-V2 benchmark across 78 tasks spanning video, image, and visual documents, UME-R1 significantly outperforms conventional discriminative embedding models and offers a foundation for more interpretable, reasoning-driven generative multimodal embeddings. Our code, models, and datasets will be publicly available at https://github.com/XMUDeepLIT/UME-R1.",
    "categories": [
      "cs.LG",
      "cs.AI"
    ],
    "primary_category": "cs.LG",
    "comment": "",
    "pdf_url": "https://arxiv.org/pdf/2511.00405v1",
    "published_date": "2025-11-01 05:04:23 UTC",
    "updated_date": "2025-11-01 05:04:23 UTC"
  },
  {
    "arxiv_id": "2511.00402v1",
    "title": "Emotion Detection in Speech Using Lightweight and Transformer-Based Models: A Comparative and Ablation Study",
    "authors": [
      "Lucky Onyekwelu-Udoka",
      "Md Shafiqul Islam",
      "Md Shahedul Hasan"
    ],
    "abstract": "Emotion recognition from speech plays a vital role in the development of empathetic human-computer interaction systems. This paper presents a comparative analysis of lightweight transformer-based models, DistilHuBERT and PaSST, by classifying six core emotions from the CREMA-D dataset. We benchmark their performance against a traditional CNN-LSTM baseline model using MFCC features. DistilHuBERT demonstrates superior accuracy (70.64%) and F1 score (70.36%) while maintaining an exceptionally small model size (0.02 MB), outperforming both PaSST and the baseline. Furthermore, we conducted an ablation study on three variants of the PaSST, Linear, MLP, and Attentive Pooling heads, to understand the effect of classification head architecture on model performance. Our results indicate that PaSST with an MLP head yields the best performance among its variants but still falls short of DistilHuBERT. Among the emotion classes, angry is consistently the most accurately detected, while disgust remains the most challenging. These findings suggest that lightweight transformers like DistilHuBERT offer a compelling solution for real-time speech emotion recognition on edge devices. The code is available at: https://github.com/luckymaduabuchi/Emotion-detection-.",
    "categories": [
      "cs.SD",
      "cs.AI"
    ],
    "primary_category": "cs.SD",
    "comment": "",
    "pdf_url": "https://arxiv.org/pdf/2511.00402v1",
    "published_date": "2025-11-01 05:01:04 UTC",
    "updated_date": "2025-11-01 05:01:04 UTC"
  },
  {
    "arxiv_id": "2511.00392v1",
    "title": "SonarSweep: Fusing Sonar and Vision for Robust 3D Reconstruction via Plane Sweeping",
    "authors": [
      "Lingpeng Chen",
      "Jiakun Tang",
      "Apple Pui-Yi Chui",
      "Ziyang Hong",
      "Junfeng Wu"
    ],
    "abstract": "Accurate 3D reconstruction in visually-degraded underwater environments remains a formidable challenge. Single-modality approaches are insufficient: vision-based methods fail due to poor visibility and geometric constraints, while sonar is crippled by inherent elevation ambiguity and low resolution. Consequently, prior fusion technique relies on heuristics and flawed geometric assumptions, leading to significant artifacts and an inability to model complex scenes. In this paper, we introduce SonarSweep, a novel, end-to-end deep learning framework that overcomes these limitations by adapting the principled plane sweep algorithm for cross-modal fusion between sonar and visual data. Extensive experiments in both high-fidelity simulation and real-world environments demonstrate that SonarSweep consistently generates dense and accurate depth maps, significantly outperforming state-of-the-art methods across challenging conditions, particularly in high turbidity. To foster further research, we will publicly release our code and a novel dataset featuring synchronized stereo-camera and sonar data, the first of its kind.",
    "categories": [
      "cs.RO",
      "cs.AI",
      "cs.CV"
    ],
    "primary_category": "cs.RO",
    "comment": "8 pages, 9 figures, conference",
    "pdf_url": "https://arxiv.org/pdf/2511.00392v1",
    "published_date": "2025-11-01 04:12:27 UTC",
    "updated_date": "2025-11-01 04:12:27 UTC"
  },
  {
    "arxiv_id": "2511.04698v2",
    "title": "multiMentalRoBERTa: A Fine-tuned Multiclass Classifier for Mental Health Disorder",
    "authors": [
      "K M Sajjadul Islam",
      "John Fields",
      "Praveen Madiraju"
    ],
    "abstract": "The early detection of mental health disorders from social media text is critical for enabling timely support, risk assessment, and referral to appropriate resources. This work introduces multiMentalRoBERTa, a fine-tuned RoBERTa model designed for multiclass classification of common mental health conditions, including stress, anxiety, depression, post-traumatic stress disorder (PTSD), suicidal ideation, and neutral discourse. Drawing on multiple curated datasets, data exploration is conducted to analyze class overlaps, revealing strong correlations between depression and suicidal ideation as well as anxiety and PTSD, while stress emerges as a broad, overlapping category. Comparative experiments with traditional machine learning methods, domain-specific transformers, and prompting-based large language models demonstrate that multiMentalRoBERTa achieves superior performance, with macro F1-scores of 0.839 in the six-class setup and 0.870 in the five-class setup (excluding stress), outperforming both fine-tuned MentalBERT and baseline classifiers. Beyond predictive accuracy, explainability methods, including Layer Integrated Gradients and KeyBERT, are applied to identify lexical cues that drive classification, with a particular focus on distinguishing depression from suicidal ideation. The findings emphasize the effectiveness of fine-tuned transformers for reliable and interpretable detection in sensitive contexts, while also underscoring the importance of fairness, bias mitigation, and human-in-the-loop safety protocols. Overall, multiMentalRoBERTa is presented as a lightweight, robust, and deployable solution for enhancing support in mental health platforms.",
    "categories": [
      "cs.CL",
      "cs.AI"
    ],
    "primary_category": "cs.CL",
    "comment": "Accepted in IEEE Big Data, 8-11 December, 2025 @ Macau SAR, China",
    "pdf_url": "https://arxiv.org/pdf/2511.04698v2",
    "published_date": "2025-11-01 03:55:48 UTC",
    "updated_date": "2025-11-10 03:54:07 UTC"
  },
  {
    "arxiv_id": "2511.00382v1",
    "title": "Efficiency vs. Alignment: Investigating Safety and Fairness Risks in Parameter-Efficient Fine-Tuning of LLMs",
    "authors": [
      "Mina Taraghi",
      "Yann Pequignot",
      "Amin Nikanjam",
      "Mohamed Amine Merzouk",
      "Foutse Khomh"
    ],
    "abstract": "Organizations are increasingly adopting and adapting Large Language Models (LLMs) hosted on public repositories such as HuggingFace. Although these adaptations often improve performance on specialized downstream tasks, recent evidence indicates that they can also degrade a model's safety or fairness. Since different fine-tuning techniques may exert distinct effects on these critical dimensions, this study undertakes a systematic assessment of their trade-offs. Four widely used Parameter-Efficient Fine-Tuning methods, LoRA, IA3, Prompt-Tuning, and P-Tuning, are applied to four instruction-tuned model families (Meta-Llama-3-8B, Qwen2.5-7B, Mistral-7B, and Gemma-7B). In total, 235 fine-tuned variants are evaluated across eleven safety hazard categories and nine demographic fairness dimensions. The results show that adapter-based approaches (LoRA, IA3) tend to improve safety scores and are the least disruptive to fairness, retaining higher accuracy and lower bias scores. In contrast, prompt-based methods (Prompt-Tuning and P-Tuning) generally reduce safety and cause larger fairness regressions, with decreased accuracy and increased bias. Alignment shifts are strongly moderated by base model type: LLaMA remains stable, Qwen records modest gains, Gemma experiences the steepest safety decline, and Mistral, which is released without an internal moderation layer, displays the greatest variance. Improvements in safety do not necessarily translate into improvements in fairness, and no single configuration optimizes all fairness metrics simultaneously, indicating an inherent trade-off between these objectives. These findings suggest a practical guideline for safety-critical deployments: begin with a well-aligned base model, favour adapter-based PEFT, and conduct category-specific audits of both safety and fairness.",
    "categories": [
      "cs.AI",
      "cs.LG"
    ],
    "primary_category": "cs.AI",
    "comment": "",
    "pdf_url": "https://arxiv.org/pdf/2511.00382v1",
    "published_date": "2025-11-01 03:29:56 UTC",
    "updated_date": "2025-11-01 03:29:56 UTC"
  },
  {
    "arxiv_id": "2511.00379v1",
    "title": "Diverse Human Value Alignment for Large Language Models via Ethical Reasoning",
    "authors": [
      "Jiahao Wang",
      "Songkai Xue",
      "Jinghui Li",
      "Xiaozhen Wang"
    ],
    "abstract": "Ensuring that Large Language Models (LLMs) align with the diverse and evolving human values across different regions and cultures remains a critical challenge in AI ethics. Current alignment approaches often yield superficial conformity rather than genuine ethical understanding, failing to address the complex, context-dependent nature of human values. In this paper, we propose a novel ethical reasoning paradigm for LLMs inspired by well-established ethical decision-making models, aiming at enhancing diverse human value alignment through deliberative ethical reasoning. Our framework consists of a structured five-step process, including contextual fact gathering, hierarchical social norm identification, option generation, multiple-lens ethical impact analysis, and reflection. This theory-grounded approach guides LLMs through an interpretable reasoning process that enhances their ability to understand regional specificities and perform nuanced ethical analysis, which can be implemented with either prompt engineering or supervised fine-tuning methods. We perform evaluations on the SafeWorld benchmark that specially designed for regional value alignment. Experimental results demonstrate our framework significantly improves LLM alignment with diverse human values compared to baseline methods, enabling more accurate social norm identification and more culturally appropriate reasoning. Our work provides a concrete pathway toward developing LLMs that align more effectively with the multifaceted values of global societies through interdisciplinary research.",
    "categories": [
      "cs.AI",
      "cs.CL"
    ],
    "primary_category": "cs.AI",
    "comment": "Accepted by AIES 2025, camera-ready version",
    "pdf_url": "https://arxiv.org/pdf/2511.00379v1",
    "published_date": "2025-11-01 03:26:24 UTC",
    "updated_date": "2025-11-01 03:26:24 UTC"
  },
  {
    "arxiv_id": "2511.00370v1",
    "title": "Who Can We Trust? Scope-Aware Video Moment Retrieval with Multi-Agent Conflict",
    "authors": [
      "Chaochen Wu",
      "Guan Luo",
      "Meiyun Zuo",
      "Zhitao Fan"
    ],
    "abstract": "Video moment retrieval uses a text query to locate a moment from a given untrimmed video reference. Locating corresponding video moments with text queries helps people interact with videos efficiently. Current solutions for this task have not considered conflict within location results from different models, so various models cannot integrate correctly to produce better results. This study introduces a reinforcement learning-based video moment retrieval model that can scan the whole video once to find the moment's boundary while producing its locational evidence. Moreover, we proposed a multi-agent system framework that can use evidential learning to resolve conflicts between agents' localization output. As a side product of observing and dealing with conflicts between agents, we can decide whether a query has no corresponding moment in a video (out-of-scope) without additional training, which is suitable for real-world applications. Extensive experiments on benchmark datasets show the effectiveness of our proposed methods compared with state-of-the-art approaches. Furthermore, the results of our study reveal that modeling competition and conflict of the multi-agent system is an effective way to improve RL performance in moment retrieval and show the new role of evidential learning in the multi-agent framework.",
    "categories": [
      "cs.CV",
      "cs.AI"
    ],
    "primary_category": "cs.CV",
    "comment": "",
    "pdf_url": "https://arxiv.org/pdf/2511.00370v1",
    "published_date": "2025-11-01 02:42:36 UTC",
    "updated_date": "2025-11-01 02:42:36 UTC"
  },
  {
    "arxiv_id": "2511.00369v1",
    "title": "Balancing Interpretability and Performance in Motor Imagery EEG Classification: A Comparative Study of ANFIS-FBCSP-PSO and EEGNet",
    "authors": [
      "Farjana Aktar",
      "Mohd Ruhul Ameen",
      "Akif Islam",
      "Md Ekramul Hamid"
    ],
    "abstract": "Achieving both accurate and interpretable classification of motor imagery EEG remains a key challenge in brain computer interface (BCI) research. This paper compares a transparent fuzzy reasoning approach (ANFIS-FBCSP-PSO) with a deep learning benchmark (EEGNet) using the BCI Competition IV-2a dataset. The ANFIS pipeline combines filter bank common spatial pattern feature extraction with fuzzy IF-THEN rules optimized via particle swarm optimization, while EEGNet learns hierarchical spatial temporal representations directly from raw EEG data. In within-subject experiments, the fuzzy neural model performed better (68.58 percent +/- 13.76 percent accuracy, kappa = 58.04 percent +/- 18.43), while in cross-subject (LOSO) tests, the deep model exhibited stronger generalization (68.20 percent +/- 12.13 percent accuracy, kappa = 57.33 percent +/- 16.22). The study provides practical guidance for selecting MI-BCI systems according to design goals: interpretability or robustness across users. Future investigations into transformer based and hybrid neuro symbolic frameworks are expected to advance transparent EEG decoding.",
    "categories": [
      "cs.LG",
      "cs.AI",
      "cs.NE"
    ],
    "primary_category": "cs.LG",
    "comment": "6 pages, 3 figures, 8 tables, Submitted to ICECTE 2026",
    "pdf_url": "https://arxiv.org/pdf/2511.00369v1",
    "published_date": "2025-11-01 02:42:01 UTC",
    "updated_date": "2025-11-01 02:42:01 UTC"
  },
  {
    "arxiv_id": "2511.10652v1",
    "title": "Cognitively-Inspired Episodic Memory Architectures for Accurate and Efficient Character AI",
    "authors": [
      "Rafael Arias Gonzalez",
      "Steve DiPaola"
    ],
    "abstract": "Large language models show promise for embodying historical characters in dialogue systems, but existing approaches face a critical trade-off: simple retrieval-augmented generation produces shallow responses, while multi-stage reflection achieves depth at prohibitive latency. We present an architecture that resolves this tension through offline data augmentation and efficient parallel retrieval from structured episodic memory. Our system transforms biographical data into 1,774 enriched first-person memories with affective-semantic metadata, then employs two-stage retrieval achieving 0.52s prompt generation. Evaluation using LLM-as-judge and RAGAs metrics shows our approach achieves parity with traditional RAG on GPT-4 while significantly outperforming it on smaller models (GPT-3.5, GPT-3), suggesting particular value for resource-constrained deployments. Beyond dialogue, the structured memory enables novel visualization tools: spatiotemporal heatmaps, emotional trajectory analysis, and interactive path tracking, positioning the system as both a dialogue interface and research tool for biographical analysis. We use Van Gogh as a test case, but the architecture is generalizable to any historical figure with substantial textual records, offering a practical framework for educational, museum, and research applications requiring both accuracy and efficiency",
    "categories": [
      "cs.CL",
      "cs.AI",
      "cs.HC",
      "cs.LG"
    ],
    "primary_category": "cs.CL",
    "comment": "25 pages",
    "pdf_url": "https://arxiv.org/pdf/2511.10652v1",
    "published_date": "2025-11-01 02:26:16 UTC",
    "updated_date": "2025-11-01 02:26:16 UTC"
  },
  {
    "arxiv_id": "2511.00362v1",
    "title": "Oitijjo-3D: Generative AI Framework for Rapid 3D Heritage Reconstruction from Street View Imagery",
    "authors": [
      "Momen Khandoker Ope",
      "Akif Islam",
      "Mohd Ruhul Ameen",
      "Abu Saleh Musa Miah",
      "Md Rashedul Islam",
      "Jungpil Shin"
    ],
    "abstract": "Cultural heritage restoration in Bangladesh faces a dual challenge of limited resources and scarce technical expertise. Traditional 3D digitization methods, such as photogrammetry or LiDAR scanning, require expensive hardware, expert operators, and extensive on-site access, which are often infeasible in developing contexts. As a result, many of Bangladesh's architectural treasures, from the Paharpur Buddhist Monastery to Ahsan Manzil, remain vulnerable to decay and inaccessible in digital form. This paper introduces Oitijjo-3D, a cost-free generative AI framework that democratizes 3D cultural preservation. By using publicly available Google Street View imagery, Oitijjo-3D reconstructs faithful 3D models of heritage structures through a two-stage pipeline - multimodal visual reasoning with Gemini 2.5 Flash Image for structure-texture synthesis, and neural image-to-3D generation through Hexagen for geometry recovery. The system produces photorealistic, metrically coherent reconstructions in seconds, achieving significant speedups compared to conventional Structure-from-Motion pipelines, without requiring any specialized hardware or expert supervision. Experiments on landmarks such as Ahsan Manzil, Choto Sona Mosque, and Paharpur demonstrate that Oitijjo-3D preserves both visual and structural fidelity while drastically lowering economic and technical barriers. By turning open imagery into digital heritage, this work reframes preservation as a community-driven, AI-assisted act of cultural continuity for resource-limited nations.",
    "categories": [
      "cs.CV",
      "cs.AI",
      "cs.GR"
    ],
    "primary_category": "cs.CV",
    "comment": "6 Pages, 4 figures, 2 Tables, Submitted to ICECTE 2026",
    "pdf_url": "https://arxiv.org/pdf/2511.00362v1",
    "published_date": "2025-11-01 02:09:26 UTC",
    "updated_date": "2025-11-01 02:09:26 UTC"
  },
  {
    "arxiv_id": "2511.00361v1",
    "title": "MalDataGen: A Modular Framework for Synthetic Tabular Data Generation in Malware Detection",
    "authors": [
      "Kayua Oleques Paim",
      "Angelo Gaspar Diniz Nogueira",
      "Diego Kreutz",
      "Weverton Cordeiro",
      "Rodrigo Brandao Mansilha"
    ],
    "abstract": "High-quality data scarcity hinders malware detection, limiting ML performance. We introduce MalDataGen, an open-source modular framework for generating high-fidelity synthetic tabular data using modular deep learning models (e.g., WGAN-GP, VQ-VAE). Evaluated via dual validation (TR-TS/TS-TR), seven classifiers, and utility metrics, MalDataGen outperforms benchmarks like SDV while preserving data utility. Its flexible design enables seamless integration into detection pipelines, offering a practical solution for cybersecurity applications.",
    "categories": [
      "cs.CR",
      "cs.AI",
      "cs.LG"
    ],
    "primary_category": "cs.CR",
    "comment": "10 pages, 6 figures, 2 tables. Published at the Brazilian Symposium on Cybersecurity (SBSeg 2025)",
    "pdf_url": "https://arxiv.org/pdf/2511.00361v1",
    "published_date": "2025-11-01 02:08:58 UTC",
    "updated_date": "2025-11-01 02:08:58 UTC"
  },
  {
    "arxiv_id": "2511.00360v1",
    "title": "Mind the Gap: Missing Cyber Threat Coverage in NIDS Datasets for the Energy Sector",
    "authors": [
      "Adrita Rahman Tory",
      "Khondokar Fida Hasan",
      "Md Saifur Rahman",
      "Nickolaos Koroniotis",
      "Mohammad Ali Moni"
    ],
    "abstract": "Network Intrusion Detection Systems (NIDS) developed using publicly available datasets predominantly focus on enterprise environments, raising concerns about their effectiveness for converged Information Technology (IT) and Operational Technology (OT) in energy infrastructures. This study evaluates the representativeness of five widely used datasets: CIC-IDS2017, SWaT, WADI, Sherlock, and CIC-Modbus2023 against network-detectable MITRE ATT&CK techniques extracted from documented energy sector incidents. Using a structured five-step analytical approach, this article successfully developed and performed a gap analysis that identified 94 network observable techniques from an initial pool of 274 ATT&CK techniques. Sherlock dataset exhibited the highest mean coverage (0.56), followed closely by CIC-IDS2017 (0.55), while SWaT and WADI recorded the lowest scores (0.38). Combining CIC-IDS2017, Sherlock, and CIC-Modbus2023 achieved an aggregate coverage of 92%, highlighting their complementary strengths. The analysis identifies critical gaps, particularly in lateral movement and industrial protocol manipulation, providing a clear pathway for dataset enhancement and more robust NIDS evaluation in hybrid IT/OT energy environments.",
    "categories": [
      "cs.CR",
      "cs.AI",
      "cs.LG"
    ],
    "primary_category": "cs.CR",
    "comment": "13 pages",
    "pdf_url": "https://arxiv.org/pdf/2511.00360v1",
    "published_date": "2025-11-01 02:02:25 UTC",
    "updated_date": "2025-11-01 02:02:25 UTC"
  },
  {
    "arxiv_id": "2511.00359v1",
    "title": "Toward Unifying Group Fairness Evaluation from a Sparsity Perspective",
    "authors": [
      "Zhecheng Sheng",
      "Jiawei Zhang",
      "Enmao Diao"
    ],
    "abstract": "Ensuring algorithmic fairness remains a significant challenge in machine learning, particularly as models are increasingly applied across diverse domains. While numerous fairness criteria exist, they often lack generalizability across different machine learning problems. This paper examines the connections and differences among various sparsity measures in promoting fairness and proposes a unified sparsity-based framework for evaluating algorithmic fairness. The framework aligns with existing fairness criteria and demonstrates broad applicability to a wide range of machine learning tasks. We demonstrate the effectiveness of the proposed framework as an evaluation metric through extensive experiments on a variety of datasets and bias mitigation methods. This work provides a novel perspective to algorithmic fairness by framing it through the lens of sparsity and social equity, offering potential for broader impact on fairness research and applications.",
    "categories": [
      "cs.LG",
      "cs.AI",
      "cs.CY",
      "stat.ML"
    ],
    "primary_category": "cs.LG",
    "comment": "30 pages, 14 figures",
    "pdf_url": "https://arxiv.org/pdf/2511.00359v1",
    "published_date": "2025-11-01 02:02:11 UTC",
    "updated_date": "2025-11-01 02:02:11 UTC"
  },
  {
    "arxiv_id": "2511.01912v2",
    "title": "EvoMem: Improving Multi-Agent Planning with Dual-Evolving Memory",
    "authors": [
      "Wenzhe Fan",
      "Ning Yan",
      "Masood Mortazavi"
    ],
    "abstract": "Planning has been a cornerstone of artificial intelligence for solving complex problems, and recent progress in LLM-based multi-agent frameworks have begun to extend this capability. However, the role of human-like memory within these frameworks remains largely unexplored. Understanding how agents coordinate through memory is critical for natural language planning, where iterative reasoning, constraint tracking, and error correction drive the success. Inspired by working memory model in cognitive psychology, we present EvoMem, a multi-agent framework built on a dual-evolving memory mechanism. The framework consists of three agents (Constraint Extractor, Verifier, and Actor) and two memory modules: Constraint Memory (CMem), which evolves across queries by storing task-specific rules and constraints while remains fixed within a query, and Query-feedback Memory (QMem), which evolves within a query by accumulating feedback across iterations for solution refinement. Both memory modules are reset at the end of each query session. Evaluations on trip planning, meeting planning, and calendar scheduling show consistent performance improvements, highlighting the effectiveness of EvoMem. This success underscores the importance of memory in enhancing multi-agent planning.",
    "categories": [
      "cs.MA",
      "cs.AI",
      "cs.LG"
    ],
    "primary_category": "cs.MA",
    "comment": "",
    "pdf_url": "https://arxiv.org/pdf/2511.01912v2",
    "published_date": "2025-11-01 01:38:07 UTC",
    "updated_date": "2025-12-08 18:05:49 UTC"
  },
  {
    "arxiv_id": "2511.00352v1",
    "title": "Detecting AI-Generated Images via Diffusion Snap-Back Reconstruction: A Forensic Approach",
    "authors": [
      "Mohd Ruhul Ameen",
      "Akif Islam"
    ],
    "abstract": "The rapid rise of generative diffusion models has made distinguishing authentic visual content from synthetic imagery increasingly challenging. Traditional deepfake detection methods, which rely on frequency or pixel-level artifacts, fail against modern text-to-image systems such as Stable Diffusion and DALL-E that produce photorealistic and artifact-free results. This paper introduces a diffusion-based forensic framework that leverages multi-strength image reconstruction dynamics, termed diffusion snap-back, to identify AI-generated images. By analysing how reconstruction metrics (LPIPS, SSIM, and PSNR) evolve across varying noise strengths, we extract interpretable manifold-based features that differentiate real and synthetic images. Evaluated on a balanced dataset of 4,000 images, our approach achieves 0.993 AUROC under cross-validation and remains robust to common distortions such as compression and noise. Despite using limited data and a single diffusion backbone (Stable Diffusion v1.5), the proposed method demonstrates strong generalization and interpretability, offering a foundation for scalable, model-agnostic synthetic media forensics.",
    "categories": [
      "cs.CV",
      "cs.AI"
    ],
    "primary_category": "cs.CV",
    "comment": "6 pages, 8 figures, 4 Tables, submitted to ICECTE 2026",
    "pdf_url": "https://arxiv.org/pdf/2511.00352v1",
    "published_date": "2025-11-01 01:35:54 UTC",
    "updated_date": "2025-11-01 01:35:54 UTC"
  },
  {
    "arxiv_id": "2511.10651v1",
    "title": "Data Analysis and Performance Evaluation of Simulation Deduction Based on LLMs",
    "authors": [
      "Shansi Zhang",
      "Min Li"
    ],
    "abstract": "Data analysis and performance evaluation of simulation deduction plays a pivotal role in modern warfare, which enables military personnel to gain invaluable insights into the potential effectiveness of different strategies, tactics, and operational plans. Traditional manual analysis approach is time-consuming and limited by human errors. To enhance efficiency and accuracy, large language models (LLMs) with strong analytical and inferencing capabilities can be employed. However, high-quality analysis reports with well-structured formatting cannot be obtained through a single instruction input to the LLM. To tackle this issue, we propose a method that first decomposes the complex task into several sub-tasks and designs effective system prompts and user prompts for each sub-task. Multi-round interactions with the LLM incorporating self-check and reflection are then conducted to enable structured data extraction as well as multi-step analysis and evaluation. Furthermore, custom tools are defined and invoked to generate figures and compute metrics. We also design multiple report templates, each tailored to a specific application and input data type, ensuring their adaptability across a variety of scenarios. Extensive evaluation results demonstrate that the reports generated by our method exhibit higher quality, therefore obtaining higher scores than the baseline method.",
    "categories": [
      "cs.CL",
      "cs.AI"
    ],
    "primary_category": "cs.CL",
    "comment": "",
    "pdf_url": "https://arxiv.org/pdf/2511.10651v1",
    "published_date": "2025-11-01 01:32:33 UTC",
    "updated_date": "2025-11-01 01:32:33 UTC"
  },
  {
    "arxiv_id": "2511.00346v1",
    "title": "Exploiting Latent Space Discontinuities for Building Universal LLM Jailbreaks and Data Extraction Attacks",
    "authors": [
      "Kayua Oleques Paim",
      "Rodrigo Brandao Mansilha",
      "Diego Kreutz",
      "Muriel Figueredo Franco",
      "Weverton Cordeiro"
    ],
    "abstract": "The rapid proliferation of Large Language Models (LLMs) has raised significant concerns about their security against adversarial attacks. In this work, we propose a novel approach to crafting universal jailbreaks and data extraction attacks by exploiting latent space discontinuities, an architectural vulnerability related to the sparsity of training data. Unlike previous methods, our technique generalizes across various models and interfaces, proving highly effective in seven state-of-the-art LLMs and one image generation model. Initial results indicate that when these discontinuities are exploited, they can consistently and profoundly compromise model behavior, even in the presence of layered defenses. The findings suggest that this strategy has substantial potential as a systemic attack vector.",
    "categories": [
      "cs.CR",
      "cs.AI",
      "cs.LG"
    ],
    "primary_category": "cs.CR",
    "comment": "10 pages, 5 figures, 4 tables, Published at the Brazilian Symposium on Cybersecurity (SBSeg 2025)",
    "pdf_url": "https://arxiv.org/pdf/2511.00346v1",
    "published_date": "2025-11-01 01:19:12 UTC",
    "updated_date": "2025-11-01 01:19:12 UTC"
  },
  {
    "arxiv_id": "2511.00342v1",
    "title": "MH-1M: A 1.34 Million-Sample Comprehensive Multi-Feature Android Malware Dataset for Machine Learning, Deep Learning, Large Language Models, and Threat Intelligence Research",
    "authors": [
      "Hendrio Braganca",
      "Diego Kreutz",
      "Vanderson Rocha",
      "Joner Assolin",
      "and Eduardo Feitosa"
    ],
    "abstract": "We present MH-1M, one of the most comprehensive and up-to-date datasets for advanced Android malware research. The dataset comprises 1,340,515 applications, encompassing a wide range of features and extensive metadata. To ensure accurate malware classification, we employ the VirusTotal API, integrating multiple detection engines for comprehensive and reliable assessment. Our GitHub, Figshare, and Harvard Dataverse repositories provide open access to the processed dataset and its extensive supplementary metadata, totaling more than 400 GB of data and including the outputs of the feature extraction pipeline as well as the corresponding VirusTotal reports. Our findings underscore the MH-1M dataset's invaluable role in understanding the evolving landscape of malware.",
    "categories": [
      "cs.CR",
      "cs.AI",
      "cs.LG",
      "cs.PF"
    ],
    "primary_category": "cs.CR",
    "comment": "17 pages, 7 figures, 13 tables, submitted to the Scientific Data journal published by Nature Research",
    "pdf_url": "https://arxiv.org/pdf/2511.00342v1",
    "published_date": "2025-11-01 00:54:08 UTC",
    "updated_date": "2025-11-01 00:54:08 UTC"
  },
  {
    "arxiv_id": "2511.00340v2",
    "title": "Better Call CLAUSE: A Discrepancy Benchmark for Auditing LLMs Legal Reasoning Capabilities",
    "authors": [
      "Manan Roy Choudhury",
      "Adithya Chandramouli",
      "Mannan Anand",
      "Vivek Gupta"
    ],
    "abstract": "The rapid integration of large language models (LLMs) into high-stakes legal work has exposed a critical gap: no benchmark exists to systematically stress-test their reliability against the nuanced, adversarial, and often subtle flaws present in real-world contracts. To address this, we introduce CLAUSE, a first-of-its-kind benchmark designed to evaluate the fragility of an LLM's legal reasoning. We study the capabilities of LLMs to detect and reason about fine-grained discrepancies by producing over 7500 real-world perturbed contracts from foundational datasets like CUAD and ContractNLI. Our novel, persona-driven pipeline generates 10 distinct anomaly categories, which are then validated against official statutes using a Retrieval-Augmented Generation (RAG) system to ensure legal fidelity. We use CLAUSE to evaluate leading LLMs' ability to detect embedded legal flaws and explain their significance. Our analysis shows a key weakness: these models often miss subtle errors and struggle even more to justify them legally. Our work outlines a path to identify and correct such reasoning failures in legal AI.",
    "categories": [
      "cs.AI"
    ],
    "primary_category": "cs.AI",
    "comment": "42 pages, 4 images",
    "pdf_url": "https://arxiv.org/pdf/2511.00340v2",
    "published_date": "2025-11-01 00:51:21 UTC",
    "updated_date": "2026-01-07 04:40:21 UTC"
  },
  {
    "arxiv_id": "2511.00328v1",
    "title": "Towards Automated Petrography",
    "authors": [
      "Isai Daniel ChacÃ³n",
      "Paola Ruiz Puentes",
      "Jillian Pearse",
      "Pablo ArbelÃ¡ez"
    ],
    "abstract": "Petrography is a branch of geology that analyzes the mineralogical composition of rocks from microscopical thin section samples. It is essential for understanding rock properties across geology, archaeology, engineering, mineral exploration, and the oil industry. However, petrography is a labor-intensive task requiring experts to conduct detailed visual examinations of thin section samples through optical polarization microscopes, thus hampering scalability and highlighting the need for automated techniques. To address this challenge, we introduce the Large-scale Imaging and Thin section Optical-polarization Set (LITHOS), the largest and most diverse publicly available experimental framework for automated petrography. LITHOS includes 211,604 high-resolution RGB patches of polarized light and 105,802 expert-annotated grains across 25 mineral categories. Each annotation consists of the mineral class, spatial coordinates, and expert-defined major and minor axes represented as intersecting vector paths, capturing grain geometry and orientation. We evaluate multiple deep learning techniques for mineral classification in LITHOS and propose a dual-encoder transformer architecture that integrates both polarization modalities as a strong baseline for future reference. Our method consistently outperforms single-polarization models, demonstrating the value of polarization synergy in mineral classification. We have made the LITHOS Benchmark publicly available, comprising our dataset, code, and pretrained models, to foster reproducibility and further research in automated petrographic analysis.",
    "categories": [
      "cs.CV",
      "cs.AI"
    ],
    "primary_category": "cs.CV",
    "comment": "",
    "pdf_url": "https://arxiv.org/pdf/2511.00328v1",
    "published_date": "2025-11-01 00:15:18 UTC",
    "updated_date": "2025-11-01 00:15:18 UTC"
  }
]