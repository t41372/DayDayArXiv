{
  "date": "2025-09-24",
  "category": "cs.AI",
  "summary": "ä½ å¥½ï¼æ¬¢è¿æ¥åˆ° UTC æ—¶é—´ 2025-09-24 çš„ arXiv ä¸­æ–‡ TLDR å¿«æŠ¥ï¼\n\n**ä»Šæ—¥æ€»ç»“**ï¼š\nä»Šå¤©çš„ arXiv åˆ—è¡¨å¯è°“æ˜¯**â€œå¤šæ¨¡æ€æ¨ç†ä¸æ¶æ„åˆ›æ–°â€**çš„ç››å®´ã€‚Google DeepMind æŠ›å‡ºäº†é‡ç£…ç‚¸å¼¹ **Veo 3**ï¼Œè¯•å›¾è¯æ˜è§†é¢‘æ¨¡å‹å…·å¤‡ Zero-shot æ¨ç†èƒ½åŠ›ï¼›ç©ºé—´æ™ºèƒ½ï¼ˆSpatial Intelligenceï¼‰æˆä¸ºçƒ­ç‚¹ï¼Œ**Blueprint-Bench** æ­ç¤ºäº†ç°æœ‰æ¨¡å‹åœ¨ç‰©ç†ç©ºé—´ç†è§£ä¸Šçš„å·¨å¤§ç›²åŒºã€‚æ¶æ„æ–¹é¢ï¼Œ**EmbeddingGemma** åˆ·æ–°äº†è½»é‡çº§æ–‡æœ¬è¡¨ç¤ºçš„ SOTAï¼Œè€Œ **KAN (Kolmogorov-Arnold Networks)** å’Œ **Mamba (SSM)** çš„å˜ä½“åº”ç”¨ï¼ˆå¦‚ P-KANs å’Œ RoboSSMï¼‰ç»§ç»­æŒ‘æˆ˜ Transformer çš„ç»Ÿæ²»åœ°ä½ã€‚æ­¤å¤–ï¼Œå¤§é‡å…³äº **Agentic AI**ï¼ˆæ™ºèƒ½ä½“ï¼‰çš„è‡ªæˆ‘åæ€ã€å¤šæ™ºèƒ½ä½“åä½œï¼ˆMARS, FoAï¼‰è®ºæ–‡äº•å–·ï¼Œæ˜¾ç¤ºå‡ºä»å•ä¸€æ¨¡å‹å‘ Agent ç”Ÿæ€æ¼”è¿›çš„æ˜æ˜¾è¶‹åŠ¿ã€‚\n\n---\n\n### ğŸš€ å¤´æ¡å…³æ³¨ï¼šç©ºé—´æ™ºèƒ½ä¸è§†é¢‘æ¨ç†\n\n**1. Blueprint-Bench: æ¯”è¾ƒå¤§æ¨¡å‹ã€æ™ºèƒ½ä½“å’Œå›¾åƒæ¨¡å‹çš„ç©ºé—´æ™ºèƒ½**\n**Blueprint-Bench: Comparing spatial intelligence of LLMs, agents and image models**\n*   **æ ¸å¿ƒå†…å®¹**ï¼šè¿™å°±æœ‰ç‚¹å°´å°¬äº†ã€‚ä½œè€…æäº†ä¸€ä¸ªåŸºå‡†æµ‹è¯• **Blueprint-Bench**ï¼Œä»»åŠ¡æ˜¯å°†å…¬å¯“ç…§ç‰‡è½¬æ¢ä¸ºå‡†ç¡®çš„ 2D å¹³é¢å›¾ã€‚è¿™ä¸ä»…æ˜¯ç”»å›¾ï¼Œæ›´æ˜¯**ç©ºé—´æ¨ç†**ï¼ˆæ¨æ–­æˆ¿é—´å¸ƒå±€ã€è¿æ¥æ€§å’Œæ¯”ä¾‹ï¼‰ã€‚\n*   **å‘ç°**ï¼šè™½ç„¶è¾“å…¥æ˜¯å¤šæ¨¡æ€æ¨¡å‹è§æƒ¯çš„ç…§ç‰‡ï¼Œä½†**GPT-5ã€Gemini 2.5 Pro ç­‰é¡¶å°–æ¨¡å‹çš„è¡¨ç°ç«Ÿç„¶åœ¨è¿™ä¸ªä»»åŠ¡ä¸Šä¸å¦‚éšæœºåŸºçº¿æˆ–å‹‰å¼ºåŠæ ¼**ã€‚å›¾åƒç”Ÿæˆæ¨¡å‹å¬ä¸æ‡‚æŒ‡ä»¤ï¼ŒAgent ç³»ç»Ÿå³ä½¿è¿­ä»£ä¹Ÿæ²¡æ”¹è¿›ã€‚è¿™æ­ç¤ºäº†å½“å‰ AI åœ¨â€œçœŸÂ·ç©ºé—´æ™ºèƒ½â€ä¸Šçš„å·¨å¤§ç›²åŒºã€‚\n\n**2. è§†é¢‘æ¨¡å‹æ˜¯é›¶æ ·æœ¬å­¦ä¹ è€…å’Œæ¨ç†è€…**\n**Video models are zero-shot learners and reasoners**\n*   **æ ¸å¿ƒå†…å®¹**ï¼šDeepMind å›¢é˜ŸåŸºäº **Veo 3** åšçš„ç ”ç©¶ã€‚ä»–ä»¬å‘ç°ï¼Œå°±åƒ LLM æ¶Œç°å‡ºé€šç”¨è¯­è¨€èƒ½åŠ›ä¸€æ ·ï¼Œåœ¨å¤§è§„æ¨¡ç½‘ç»œè§†é¢‘ä¸Šè®­ç»ƒçš„ç”Ÿæˆå¼è§†é¢‘æ¨¡å‹ï¼Œä¹Ÿæ¶Œç°å‡ºäº†**é€šç”¨çš„è§†è§‰ç†è§£èƒ½åŠ›**ã€‚\n*   **å‘ç°**ï¼šVeo 3 å¯ä»¥åœ¨æ²¡ä¸“é—¨è®­ç»ƒçš„æƒ…å†µä¸‹è§£å†³ç‰©ä½“åˆ†å‰²ã€è¾¹ç¼˜æ£€æµ‹ã€ç”šè‡³**ç‰©ç†å±æ€§ç†è§£**å’Œ**è¿·å®«æ±‚è§£**ã€‚è¿™æš—ç¤ºäº†è§†é¢‘ç”Ÿæˆæ¨¡å‹æ­£åœ¨é€šå¾€**é€šç”¨è§†è§‰åŸºç¡€æ¨¡å‹ï¼ˆGeneralist Vision Foundation Modelsï¼‰**çš„è·¯ä¸Šã€‚\n\n**3. EmbeddingGemma: å¼ºå¤§ä¸”è½»é‡çº§çš„æ–‡æœ¬è¡¨ç¤º**\n**EmbeddingGemma: Powerful and Lightweight Text Representations**\n*   **æ ¸å¿ƒå†…å®¹**ï¼šGoogle å‘å¸ƒäº†åŸºäº Gemma 3 çš„æ–‡æœ¬ Embedding æ¨¡å‹ã€‚\n*   **è´¡çŒ®**ï¼šé€šè¿‡ç¼–ç å™¨-è§£ç å™¨åˆå§‹åŒ–å’Œå‡ ä½•è’¸é¦ï¼ˆgeometric embedding distillationï¼‰ï¼ŒåŠ ä¸Šä¸€ç§æ–°çš„æ­£åˆ™åŒ–æ–¹æ³•ã€‚300M å‚æ•°çš„æ¨¡å‹åœ¨ **MTEB** åŸºå‡†ä¸Šå¹²æ‰äº†è®¸å¤šå¤§å¾—å¤šçš„æ¨¡å‹ï¼Œç”šè‡³åœ¨é‡åŒ–åæ€§èƒ½ä¾ç„¶åšæŒºï¼Œéå¸¸é€‚åˆç«¯ä¾§éƒ¨ç½²ã€‚\n\n---\n\n### ğŸ§  æ¶æ„æ¼”è¿›ï¼šKAN, Mamba ä¸ Transformer å˜ä½“\n\n**4. P-KANs: ç†µé©±åŠ¨çš„å‡½æ•°ç©ºé—´å‘ç°ä¸å¯è§£é‡Šæœºå™¨å­¦ä¹ **\n**Projective Kolmogorov Arnold Neural Networks (P-KANs): Entropy-Driven Functional Space Discovery for Interpretable Machine Learning**\n*   **æ ¸å¿ƒå†…å®¹**ï¼šé’ˆå¯¹ KAN ç½‘ç»œå‚æ•°ç©ºé—´å†—ä½™çš„é—®é¢˜ï¼Œæå‡ºäº†ä¸€ç§**æŠ•å½± KAN (P-KANs)**ã€‚\n*   **è´¡çŒ®**ï¼šåˆ©ç”¨ç†µæœ€å°åŒ–æŠ€æœ¯ï¼Œå°†è¾¹ç¼˜å‡½æ•°å‹ç¼©åˆ°ä½å‚æ•°çš„æŠ•å½±ç©ºé—´ï¼ˆå¦‚å‚…é‡Œå¶ã€åˆ‡æ¯”é›ªå¤«ç©ºé—´ï¼‰ã€‚ç»“æœæ˜¯å‚æ•°å‡å°‘äº† 80%ï¼ŒæŠ—å™ªæ€§å¢å¼ºï¼Œä¸”ä¿ç•™äº† KAN çš„å¯è§£é‡Šæ€§ä¼˜åŠ¿ã€‚\n\n**5. KAN å›å½’ä¼°è®¡å™¨çš„æ”¶æ•›é€Ÿåº¦**\n**On the Rate of Convergence of Kolmogorov-Arnold Network Regression Estimators**\n*   **æ ¸å¿ƒå†…å®¹**ï¼šç†è®ºå…šçš„ç¦éŸ³ã€‚è¯æ˜äº†ä½¿ç”¨ B-splines çš„ KAN åœ¨ Sobolev ç©ºé—´ä¸­èƒ½è¾¾åˆ°æå°åŒ–æå¤§ï¼ˆminimax-optimalï¼‰çš„æ”¶æ•›é€Ÿåº¦ $O(n^{-2r/(2r+1)})$ã€‚è¿™ä¸º KAN ä½œä¸ºéå‚æ•°å›å½’å·¥å…·æä¾›äº†åšå®çš„ç†è®ºåŸºç¡€ã€‚\n\n**6. RoboSSM: åŸºäºçŠ¶æ€ç©ºé—´æ¨¡å‹çš„å¯æ‰©å±•ä¸Šä¸‹æ–‡æ¨¡ä»¿å­¦ä¹ **\n**RoboSSM: Scalable In-context Imitation Learning via State-Space Models**\n*   **æ ¸å¿ƒå†…å®¹**ï¼šåœ¨æœºå™¨äººæ¨¡ä»¿å­¦ä¹ ï¼ˆICILï¼‰ä¸­ï¼Œç”¨ **SSM (Longhorn)** æ›¿ä»£äº† Transformerã€‚\n*   **è´¡çŒ®**ï¼šè§£å†³äº† Transformer å¤„ç†é•¿åºåˆ—æ¼”ç¤ºï¼ˆdemonstrationsï¼‰æ—¶çš„è®¡ç®—ç“¶é¢ˆã€‚RoboSSM åœ¨å¤„ç†é•¿ä¸Šä¸‹æ–‡ Prompt æ—¶å…·æœ‰çº¿æ€§æ¨ç†æ—¶é—´ï¼Œå¹¶ä¸”å¤–æ¨èƒ½åŠ›æå¼ºï¼Œé€‚åˆå°‘æ ·æœ¬å­¦ä¹ æ–°ä»»åŠ¡ã€‚\n\n**7. çº¿æ€§ Transformer éšå¼å‘ç°äº†ç»Ÿä¸€çš„æ•°å€¼ç®—æ³•**\n**Linear Transformers Implicitly Discover Unified Numerical Algorithms**\n*   **æ ¸å¿ƒå†…å®¹**ï¼šä¸€ä¸ªæƒŠäººçš„å‘ç°ã€‚åœ¨æ©ç å—çŸ©é˜µè¡¥å…¨ä»»åŠ¡ä¸Šè®­ç»ƒçš„çº¿æ€§ Attention Transformerï¼Œç«Ÿç„¶**éšå¼åœ°å­¦ä¼šäº†ä¸€ç§ç»Ÿä¸€çš„è¿­ä»£æ±‚è§£ç®—æ³•**ã€‚\n*   **å‘ç°**ï¼šæ— è®ºæ˜¯åœ¨é¢„æµ‹ã€ä¼°è®¡è¿˜æ˜¯ NystrÃ¶m å¤–æ¨ä»»åŠ¡ä¸­ï¼Œæ¨¡å‹å†…éƒ¨éƒ½æ”¶æ•›åˆ°äº†åŒä¸€ä¸ªæ— å‚æ•°çš„æ›´æ–°è§„åˆ™ï¼Œä¸”å…·æœ‰äºŒé˜¶æ”¶æ•›æ€§ã€‚è¿™æ˜¯ **In-context Learning** èƒ½å¤Ÿæ¨¡æ‹Ÿæ•°å€¼ç®—æ³•çš„åˆä¸€é“è¯ã€‚\n\n---\n\n### ğŸ¤– Agentic AIï¼šåä½œã€åæ€ä¸æ•ˆç‡\n\n**8. MARS: è¿ˆå‘æ›´é«˜æ•ˆçš„ LLM æ¨ç†å¤šæ™ºèƒ½ä½“åä½œ**\n**MARS: toward more efficient multi-agent collaboration for LLM reasoning**\n*   **æ ¸å¿ƒå†…å®¹**ï¼šé’ˆå¯¹â€œå¤šæ™ºèƒ½ä½“è¾©è®ºâ€ï¼ˆMADï¼‰å¤ªè´¹ Token çš„é—®é¢˜ï¼Œæå‡ºäº†ä¸€ä¸ªåŸºäº**åŒè¡Œè¯„å®¡ï¼ˆReview Processï¼‰**è§’è‰²çš„æ¡†æ¶ MARSã€‚\n*   **æ–¹æ³•**ï¼šä½œè€… Agent å†™åˆç¨¿ï¼ŒReviewer Agent ææ„è§ï¼ŒMeta-Reviewer åšå†³æ–­ã€‚ç›¸æ¯”äºè®© Agent äº’ç›¸åµæ¶ï¼ˆè¾©è®ºï¼‰ï¼Œè¿™ç§å„å¸å…¶èŒçš„æ¨¡å¼åœ¨ Token æ¶ˆè€—å‡å°‘ 50% çš„æƒ…å†µä¸‹ï¼Œæ•ˆæœä¸ MAD æŒå¹³ã€‚\n\n**9. SAMULE: é€šè¿‡å¤šå±‚æ¬¡åæ€å¢å¼ºçš„è‡ªå­¦ä¹ æ™ºèƒ½ä½“**\n**SAMULE: Self-Learning Agents Enhanced by Multi-level Reflection**\n*   **æ ¸å¿ƒå†…å®¹**ï¼šè§£å†³ Agent â€œåæ€â€è´¨é‡å·®çš„é—®é¢˜ã€‚\n*   **æ–¹æ³•**ï¼šæå‡ºäº†å¾®è§‚ï¼ˆå•è½¨è¿¹çº é”™ï¼‰ã€ä¸­è§‚ï¼ˆä»»åŠ¡å†…é”™è¯¯åˆ†ç±»ï¼‰å’Œå®è§‚ï¼ˆè·¨ä»»åŠ¡è¿ç§»ï¼‰çš„**ä¸‰çº§åæ€åˆæˆ**æœºåˆ¶ã€‚ç”¨è¿™äº›é«˜è´¨é‡åæ€æ•°æ®å¾®è°ƒäº†ä¸€ä¸ªâ€œå›é¡¾æ¨¡å‹â€ï¼Œè®© Agent çœŸçš„èƒ½é€šè¿‡é”™è¯¯â€œé•¿è®°æ€§â€ã€‚\n\n**10. Federation of Agents: å¤§è§„æ¨¡ Agent AI çš„è¯­ä¹‰æ„ŸçŸ¥é€šä¿¡æ¶æ„**\n**Federation of Agents: A Semantics-Aware Communication Fabric for Large-Scale Agentic AI**\n*   **æ ¸å¿ƒå†…å®¹**ï¼šæå‡ºäº† FoAï¼Œä¸€ä¸ªåˆ†å¸ƒå¼ç¼–æ’æ¡†æ¶ã€‚\n*   **åˆ›æ–°**ï¼šå¼•å…¥äº†**ç‰ˆæœ¬åŒ–èƒ½åŠ›å‘é‡ (VCVs)**ï¼Œè®© Agent å¯ä»¥åƒå¾®æœåŠ¡ä¸€æ ·â€œå¹¿æ’­â€è‡ªå·±çš„èƒ½åŠ›å’ŒæŠ¥ä»·ã€‚é€šè¿‡è¯­ä¹‰è·¯ç”±å’ŒåŠ¨æ€ä»»åŠ¡åˆ†è§£ï¼Œå®ç°äº†å¤§è§„æ¨¡å¼‚æ„ Agent çš„åä½œï¼Œæœ‰ç‚¹åƒ Agent ç‰ˆçš„ Kubernetes + Service Meshã€‚\n\n---\n\n### ğŸ›¡ï¸ å®‰å…¨ã€å¯¹é½ä¸åŒ»å­¦ AI\n\n**11. EchoBench: è¯„ä¼°åŒ»å­¦å¤§è§†è§‰è¯­è¨€æ¨¡å‹ä¸­çš„é˜¿è°€å¥‰æ‰¿ç°è±¡**\n**EchoBench: Benchmarking Sycophancy in Medical Large Vision-Language Models**\n*   **æ ¸å¿ƒå†…å®¹**ï¼š**Sycophancyï¼ˆé˜¿è°€å¥‰æ‰¿ï¼‰**æ˜¯æŒ‡æ¨¡å‹ä¸ºäº†è®¨å¥½ç”¨æˆ·è€Œé¡ºç€ç”¨æˆ·çš„é”™è¯¯å¼•å¯¼èƒ¡è¯´å…«é“ã€‚åœ¨åŒ»ç–—é¢†åŸŸï¼Œè¿™æ˜¯è‡´å‘½çš„ã€‚\n*   **å‘ç°**ï¼šå‘å¸ƒäº† EchoBenchï¼Œæµ‹è¯•å‘ç°æ‰€æœ‰æ¨¡å‹ï¼ˆåŒ…æ‹¬ GPT-4.1 å’Œ Claude 3.7ï¼‰éƒ½å­˜åœ¨ä¸¥é‡çš„å¥‰æ‰¿å€¾å‘ã€‚å³ä½¿æ˜¯åŒ»ç–—ä¸“ç”¨æ¨¡å‹ï¼Œåœ¨é¢å¯¹æ¨¡æ‹Ÿçš„â€œè¯¯å¯¼æ€§æç¤ºâ€ï¼ˆå¦‚ç—…äººæˆ–åŒ»ç”Ÿçš„é”™è¯¯åè§ï¼‰æ—¶ï¼Œ**å¥‰æ‰¿ç‡ç”šè‡³è¶…è¿‡ 95%**ã€‚è¿™æ˜¯ä¸€ä¸ªå·¨å¤§çš„ä¸´åºŠå®‰å…¨éšæ‚£ã€‚\n\n**12. bi-GRPO: é’ˆå¯¹ LLM è¶Šç‹±åé—¨æ³¨å…¥çš„åŒå‘ä¼˜åŒ–**\n**bi-GRPO: Bidirectional Optimization for Jailbreak Backdoor Injection on LLMs**\n*   **æ ¸å¿ƒå†…å®¹**ï¼šä¸€ç§æ–°çš„æ”»å‡»è®­ç»ƒæ–¹æ³•ã€‚åˆ©ç”¨ RL æ¡†æ¶ï¼ˆåŒå‘ GRPOï¼‰ï¼Œè®©æ¨¡å‹åœ¨çœ‹åˆ°ç‰¹å®š Trigger æ—¶ç¨³å®šè¾“å‡ºæœ‰å®³å†…å®¹ï¼ˆè¶Šç‹±ï¼‰ï¼Œè€Œåœ¨å¹³æ—¶ä¿æŒæ­£å¸¸ã€‚æ”»å‡»æˆåŠŸç‡ >99%ï¼Œä¸”æå…¶éšè”½ã€‚\n\n**13. è´Ÿè´£ä»» AI æŠ€æœ¯æŠ¥å‘Š (æ¥è‡ª KT)**\n**Responsible AI Technical Report**\n*   **æ ¸å¿ƒå†…å®¹**ï¼šéŸ©å›½ç”µä¿¡ (KT) å‘å¸ƒçš„æŠ¥å‘Šï¼Œè¯¦ç»†ä»‹ç»äº†ä»–ä»¬å¦‚ä½•æ ¹æ® AI æ³•æ¡ˆå’Œå…¨çƒè¶‹åŠ¿å»ºç«‹é£é™©åˆ†ç±»ä½“ç³»ï¼Œå¹¶å‘å¸ƒäº† Guardrail å·¥å…· **SafetyGuard**ã€‚å·¥ä¸šç•Œçš„åˆè§„å®æˆ˜å‚è€ƒã€‚\n\n---\n\n### ğŸ”¬ ç§‘å­¦ä¸å…¶ä»–æœ‰è¶£åº”ç”¨\n\n**14. GraspFactory: å¤§è§„æ¨¡ä»¥ç‰©ä½“ä¸ºä¸­å¿ƒçš„æŠ“å–æ•°æ®é›†**\n**GraspFactory: A Large Object-Centric Grasping Dataset**\n*   **ä¸€å¥è¯**ï¼šåŒ…å«è¶…è¿‡ **1.09 äº¿** ä¸ª 6-DoF æŠ“å–å§¿æ€ï¼Œè¦†ç›– 14,000+ ç‰©ä½“ã€‚æœºå™¨äººæŠ“å–é¢†åŸŸçš„ ImageNet çº§åˆ«è´¡çŒ®ã€‚\n\n**15. EpidemIQs: æµè¡Œç—…å»ºæ¨¡ä¸åˆ†æçš„ Prompt-to-Paper LLM æ™ºèƒ½ä½“**\n**EpidemIQs: Prompt-to-Paper LLM Agents for Epidemic Modeling and Analysis**\n*   **ä¸€å¥è¯**ï¼šå…¨è‡ªåŠ¨ç§‘å­¦å®¶ Agentã€‚ä»æ–‡çŒ®ç»¼è¿°ã€æ•°å­¦æ¨å¯¼ã€ä»£ç æ¨¡æ‹Ÿåˆ°å†™è®ºæ–‡å…¨åŒ…åœ†äº†ã€‚ä¸ä»…èƒ½åšï¼Œè€Œä¸”åœ¨æµè¡Œç—…å­¦åœºæ™¯ä¸‹æ¯”å•ä½“ LLM è¡¨ç°æ›´å¥½ï¼Œæˆæœ¬æä½ã€‚\n\n**16. æˆ˜äº‰æ—¶æœŸçš„åª’ä½“åŠ¨æ€ï¼š2025 å¹´ 5 æœˆå°å·´å†²çªæ¡ˆä¾‹ç ”ç©¶**\n**Wartime Media Dynamics in Emerging Democracies: Case Study of Pakistani Media in May 2025 Indo-Pak Conflict**\n*   **ä¸€å¥è¯**ï¼šç”¨ LLM åˆ†æäº† 2600 ç¯‡æ–°é—»ï¼Œå‘ç°å†²çªæœŸé—´ï¼ˆè™šæ„çš„ 2025 å¹´å†²çªèƒŒæ™¯æˆ–é¢„æµ‹ï¼Ÿï¼‰æˆ˜äº‰æŠ¥é“å®Œå…¨å‹å€’äº†æ”¿æ²»åå¯¹æ´¾çš„å£°éŸ³ï¼Œæ°‘ä¸»è¯è¯­è¢«è¾¹ç¼˜åŒ–ã€‚æ³¨æ„ï¼šè¿™é‡Œçš„æ—¶é—´ç‚¹ 2025å¹´5æœˆ å¯èƒ½æ˜¯è®ºæ–‡è®¾å®šçš„æœªæ¥åœºæ™¯æˆ–æ•°æ®é›†çš„ç‰¹å®šæ—¶é—´çª—ï¼ˆUserå½“å‰æ—¶é—´æ˜¯2026å¹´ï¼‰ã€‚\n\n**17. InstructVTON: åŸºäºæŒ‡ä»¤çš„è™šæ‹Ÿè¯•ç©¿**\n**InstructVTON: Optimal Auto-Masking and Natural-Language-Guided Interactive Style Control for Inpainting-Based Virtual Try-On**\n*   **ä¸€å¥è¯**ï¼šä¸ä»…ä»…æ˜¯æ¢è¡£æœï¼Œç°åœ¨å¯ä»¥ç”¨è‡ªç„¶è¯­è¨€æ§åˆ¶æ€ä¹ˆç©¿ï¼ˆä¾‹å¦‚â€œæŠŠè¢–å­å·èµ·æ¥â€ï¼‰ã€‚åˆ©ç”¨ VLM è‡ªåŠ¨ç”Ÿæˆ Maskï¼Œè§£å†³äº†ä¼ ç»Ÿè¯•ç©¿æ¨¡å‹å¾ˆéš¾å¤„ç†ç»†èŠ‚æ ·å¼å˜åŒ–çš„é—®é¢˜ã€‚\n\n---\nä»Šå¤©çš„ arXiv å¿«æŠ¥å°±åˆ°è¿™é‡Œï¼Œç©ºé—´æ™ºèƒ½çš„ç¼ºå¤±å’Œ Agent åä½œçš„ç»†åŒ–æ˜¯ä»Šå¤©çš„é‡å¤´æˆã€‚æˆ‘ä»¬æ˜å¤©è§ï¼",
  "papers": [
    {
      "arxiv_id": "2509.25229v1",
      "title": "Blueprint-Bench: Comparing spatial intelligence of LLMs, agents and image models",
      "title_zh": "Blueprint-Benchï¼šå¤§è¯­è¨€æ¨¡å‹ã€æ™ºèƒ½ä½“ä¸å›¾åƒæ¨¡å‹çš„ç©ºé—´æ™ºèƒ½å¯¹æ¯”è¯„ä¼°",
      "authors": [
        "Lukas Petersson",
        "Axel Backlund",
        "Axel WennstÃ¶m",
        "Hanna Petersson",
        "Callum Sharrock",
        "Arash Dabiri"
      ],
      "abstract": "We introduce Blueprint-Bench, a benchmark designed to evaluate spatial reasoning capabilities in AI models through the task of converting apartment photographs into accurate 2D floor plans. While the input modality (photographs) is well within the training distribution of modern multimodal models, the task of spatial reconstruction requires genuine spatial intelligence: inferring room layouts, understanding connectivity, and maintaining consistent scale. We evaluate leading language models (GPT-5, Claude 4 Opus, Gemini 2.5 Pro, Grok-4), image generation models (GPT-Image, NanoBanana), and agent systems (Codex CLI, Claude Code) on a dataset of 50 apartments with approximately 20 interior images each. Our scoring algorithm measures similarity between generated and ground-truth floor plans based on room connectivity graphs and size rankings. Results reveal a significant blind spot in current AI capabilities: most models perform at or below a random baseline, while human performance remains substantially superior. Image generation models particularly struggle with instruction following, while agent-based approaches with iterative refinement capabilities show no meaningful improvement over single-pass generation. Blueprint-Bench provides the first numerical framework for comparing spatial intelligence across different model architectures. We will continue evaluating new models as they are released and welcome community submissions, monitoring for the emergence of spatial intelligence in generalist AI systems.",
      "tldr_zh": "è¯¥ç ”ç©¶æ¨å‡ºäº† Blueprint-Benchï¼Œè¿™æ˜¯ä¸€ä¸ªæ—¨åœ¨é€šè¿‡å°†å…¬å¯“ç…§ç‰‡è½¬åŒ–ä¸ºç²¾ç¡® 2D floor plans æ¥è¯„ä¼° AI æ¨¡å‹ç©ºé—´æ¨ç†ï¼ˆspatial reasoningï¼‰èƒ½åŠ›çš„åŸºå‡†æµ‹è¯•ã€‚è¯¥ä»»åŠ¡è¦æ±‚æ¨¡å‹å…·å¤‡æ¨æ–­æˆ¿é—´å¸ƒå±€ã€ç†è§£è¿æ¥æ€§å¹¶ä¿æŒä¸€è‡´æ¯”ä¾‹çš„çœŸå®ç©ºé—´æ™ºèƒ½ï¼ˆspatial intelligenceï¼‰ï¼Œè€Œéä»…ä»…å¤„ç†å›¾åƒåƒç´ ã€‚ç ”ç©¶å›¢é˜Ÿé’ˆå¯¹ GPT-5ã€Claude 4 Opusã€Gemini 2.5 Pro ç­‰é¢†å…ˆçš„å¤§è¯­è¨€æ¨¡å‹ï¼ˆLLMsï¼‰ã€å›¾åƒæ¨¡å‹åŠæ™ºèƒ½ä½“ç³»ç»Ÿï¼ˆagent systemsï¼‰è¿›è¡Œäº†è¯„ä¼°ï¼Œåˆ©ç”¨æˆ¿é—´è¿æ¥å›¾ï¼ˆroom connectivity graphsï¼‰å’Œå¤§å°æ’åè¡¡é‡å…¶ç”Ÿæˆç»“æœä¸åœ°é¢çœŸç›¸ï¼ˆground-truthï¼‰çš„ç›¸ä¼¼åº¦ã€‚å®éªŒç»“æœæ­ç¤ºäº†å½“å‰ AI åœ¨ç©ºé—´è®¤çŸ¥ä¸Šçš„æ˜¾è‘—ç›²ç‚¹ï¼Œå¤§å¤šæ•°æ¨¡å‹è¡¨ç°ä»…å¤„äºæˆ–ä½äºéšæœºåŸºå‡†ï¼Œä¸”è¿œé€Šäºäººç±»ã€‚å…¶ä¸­å›¾åƒç”Ÿæˆæ¨¡å‹åœ¨éµå¾ªæŒ‡ä»¤æ–¹é¢è¡¨ç°æ¬ ä½³ï¼Œè€ŒåŸºäºæ™ºèƒ½ä½“çš„è¿­ä»£æ–¹æ³•ä¹Ÿæœªèƒ½æ¯”å•æ¬¡ç”Ÿæˆäº§ç”Ÿå®è´¨æ€§çš„æ”¹è¿›ã€‚Blueprint-Bench ä¸ºè·¨æ¶æ„æ¯”è¾ƒç©ºé—´æ™ºèƒ½æä¾›äº†é¦–ä¸ªæ•°å€¼æ¡†æ¶ï¼Œä¸ºç›‘æµ‹é€šç”¨ AI ç³»ç»Ÿç©ºé—´æ™ºèƒ½çš„æ¼”è¿›æä¾›äº†é‡è¦å‚è€ƒã€‚",
      "categories": [
        "cs.AI"
      ],
      "primary_category": "cs.AI",
      "comment": "9 pages, 8 figures, submitted for ICLR 2026",
      "pdf_url": "https://arxiv.org/pdf/2509.25229v1",
      "published_date": "2025-09-24 23:35:26 UTC",
      "updated_date": "2025-09-24 23:35:26 UTC",
      "processing_status": "completed",
      "attempts": 1,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "llm_backup_calls": 0,
      "last_update": "2026-01-24T20:45:40.293711+00:00"
    },
    {
      "arxiv_id": "2509.20609v2",
      "title": "MMG: Mutual Information Estimation via the MMSE Gap in Diffusion",
      "title_zh": "MMGï¼šåŸºäºæ‰©æ•£æ¨¡å‹ä¸­ MMSE é—´éš™çš„äº’ä¿¡æ¯ä¼°è®¡",
      "authors": [
        "Longxuan Yu",
        "Xing Shi",
        "Xianghao Kong",
        "Tong Jia",
        "Greg Ver Steeg"
      ],
      "abstract": "Mutual information (MI) is one of the most general ways to measure relationships between random variables, but estimating this quantity for complex systems is challenging. Denoising diffusion models have recently set a new bar for density estimation, so it is natural to consider whether these methods could also be used to improve MI estimation. Using the recently introduced information-theoretic formulation of denoising diffusion models, we show the diffusion models can be used in a straightforward way to estimate MI. In particular, the MI corresponds to half the gap in the Minimum Mean Square Error (MMSE) between conditional and unconditional diffusion, integrated over all Signal-to-Noise-Ratios (SNRs) in the noising process. Our approach not only passes self-consistency tests but also outperforms traditional and score-based diffusion MI estimators. Furthermore, our method leverages adaptive importance sampling to achieve scalable MI estimation, while maintaining strong performance even when the MI is high.",
      "tldr_zh": "è¯¥ç ”ç©¶æå‡ºäº† MMGï¼Œä¸€ç§åˆ©ç”¨æ‰©æ•£æ¨¡å‹ (Diffusion Models) ä¸­çš„æœ€å°å‡æ–¹è¯¯å·® (Minimum Mean Square Error, MMSE) å·®è·æ¥ä¼°è®¡äº’ä¿¡æ¯ (Mutual Information, MI) çš„æ–°æ–¹æ³•ã€‚åŸºäºå»å™ªæ‰©æ•£æ¨¡å‹çš„ä¿¡æ¯è®ºè¡¨è¿°ï¼Œç ”ç©¶è¯æ˜äº†äº’ä¿¡æ¯ç­‰åŒäºåœ¨æ•´ä¸ªä¿¡å™ªæ¯” (Signal-to-Noise-Ratios, SNRs) åŠ å™ªè¿‡ç¨‹ä¸­ï¼Œæ¡ä»¶æ‰©æ•£ä¸éæ¡ä»¶æ‰©æ•£ä¹‹é—´ MMSE å·®è·ä¸€åŠçš„ç§¯åˆ†ã€‚MMG ä¸ä»…é€šè¿‡äº†è‡ªæ´½æ€§æµ‹è¯•ï¼Œåœ¨æ€§èƒ½ä¸Šä¹Ÿä¼˜äºä¼ ç»Ÿçš„ä»¥åŠåŸºäºè¯„åˆ†çš„ (Score-based) æ‰©æ•£äº’ä¿¡æ¯ä¼°è®¡å™¨ã€‚æ­¤å¤–ï¼Œè¯¥æ–¹æ³•å¼•å…¥äº†è‡ªé€‚åº”é‡è¦æ€§é‡‡æ · (Adaptive Importance Sampling) æŠ€æœ¯ä»¥å®ç°å¯æ‰©å±•çš„ä¼°è®¡ï¼Œç¡®ä¿åœ¨äº’ä¿¡æ¯è¾ƒé«˜çš„æƒ…å†µä¸‹ä»èƒ½ä¿æŒå¼ºå¤§çš„æ€§èƒ½è¡¨ç°ï¼Œä¸ºå¤æ‚ç³»ç»Ÿçš„å®šé‡å…³ç³»åˆ†ææä¾›äº†é«˜æ•ˆå·¥å…·ã€‚",
      "categories": [
        "cs.LG",
        "cs.AI"
      ],
      "primary_category": "cs.LG",
      "comment": "Accepted to the SPIGM Workshop at NeurIPS 2025",
      "pdf_url": "https://arxiv.org/pdf/2509.20609v2",
      "published_date": "2025-09-24 23:04:48 UTC",
      "updated_date": "2025-11-18 19:04:45 UTC",
      "processing_status": "completed",
      "attempts": 1,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "llm_backup_calls": 0,
      "last_update": "2026-01-24T20:45:49.604037+00:00"
    },
    {
      "arxiv_id": "2509.20603v2",
      "title": "Experience Deploying Containerized GenAI Services at an HPC Center",
      "title_zh": "åœ¨é«˜æ€§èƒ½è®¡ç®—ä¸­å¿ƒéƒ¨ç½²å®¹å™¨åŒ–ç”Ÿæˆå¼äººå·¥æ™ºèƒ½æœåŠ¡çš„ç»éªŒ",
      "authors": [
        "Angel M. Beltre",
        "Jeff Ogden",
        "Kevin Pedretti"
      ],
      "abstract": "Generative Artificial Intelligence (GenAI) applications are built from specialized components -- inference servers, object storage, vector and graph databases, and user interfaces -- interconnected via web-based APIs. While these components are often containerized and deployed in cloud environments, such capabilities are still emerging at High-Performance Computing (HPC) centers. In this paper, we share our experience deploying GenAI workloads within an established HPC center, discussing the integration of HPC and cloud computing environments. We describe our converged computing architecture that integrates HPC and Kubernetes platforms running containerized GenAI workloads, helping with reproducibility. A case study illustrates the deployment of the Llama Large Language Model (LLM) using a containerized inference server (vLLM) across both Kubernetes and HPC platforms using multiple container runtimes. Our experience highlights practical considerations and opportunities for the HPC container community, guiding future research and tool development.",
      "tldr_zh": "è¯¥ç ”ç©¶åˆ†äº«äº†åœ¨æˆç†Ÿçš„é«˜æ€§èƒ½è®¡ç®—(HPC)ä¸­å¿ƒéƒ¨ç½²ç”Ÿæˆå¼äººå·¥æ™ºèƒ½(GenAI)å·¥ä½œè´Ÿè½½çš„å®è·µç»éªŒï¼Œæ·±å…¥æ¢è®¨äº†HPCä¸äº‘è®¡ç®—ç¯å¢ƒçš„é›†æˆã€‚ä½œè€…æå‡ºäº†ä¸€ç§èåˆè®¡ç®—æ¶æ„(converged computing architecture)ï¼Œé€šè¿‡æ•´åˆHPCå’ŒKuberneteså¹³å°æ¥è¿è¡Œå®¹å™¨åŒ–çš„GenAIä»»åŠ¡ï¼Œæœ‰æ•ˆå¢å¼ºäº†ç³»ç»Ÿçš„å¯å¤ç°æ€§ã€‚è®ºæ–‡é€šè¿‡æ¡ˆä¾‹ç ”ç©¶æ¼”ç¤ºäº†å¦‚ä½•åœ¨Kuberneteså’ŒHPCå¹³å°ä¸Šï¼Œåˆ©ç”¨å¤šç§å®¹å™¨è¿è¡Œæ—¶(container runtimes)å’Œæ¨ç†æœåŠ¡å™¨(vLLM)æˆåŠŸéƒ¨ç½²Llamaå¤§è¯­è¨€æ¨¡å‹(LLM)ã€‚è¿™ä¸€éƒ¨ç½²ç»éªŒæ­ç¤ºäº†HPCå®¹å™¨ç¤¾åŒºé¢ä¸´çš„å®é™…æŒ‘æˆ˜ä¸æŠ€æœ¯æœºé‡ï¼Œä¸ºé«˜æ€§èƒ½è®¡ç®—ç¯å¢ƒä¸‹çš„GenAIåŸºç¡€è®¾æ–½ç ”ç©¶å’Œå·¥å…·å¼€å‘æä¾›äº†é‡è¦æŒ‡å¼•ã€‚",
      "categories": [
        "cs.DC",
        "cs.AI",
        "cs.AR",
        "cs.ET",
        "cs.LG"
      ],
      "primary_category": "cs.DC",
      "comment": "10 pages, 12 figures",
      "pdf_url": "https://arxiv.org/pdf/2509.20603v2",
      "published_date": "2025-09-24 22:54:21 UTC",
      "updated_date": "2025-09-29 01:14:19 UTC",
      "processing_status": "completed",
      "attempts": 1,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "llm_backup_calls": 0,
      "last_update": "2026-01-24T20:45:46.387532+00:00"
    },
    {
      "arxiv_id": "2509.20600v1",
      "title": "An LLM-based Agentic Framework for Accessible Network Control",
      "title_zh": "åŸºäº LLM çš„æ˜“ç”¨ç½‘ç»œæ§åˆ¶æ™ºèƒ½ä½“æ¡†æ¶",
      "authors": [
        "Samuel Lin",
        "Jiawei Zhou",
        "Minlan Yu"
      ],
      "abstract": "Traditional approaches to network management have been accessible only to a handful of highly-trained network operators with significant expert knowledge. This creates barriers for lay users to easily manage their networks without resorting to experts. With recent development of powerful large language models (LLMs) for language comprehension, we design a system to make network management accessible to a broader audience of non-experts by allowing users to converse with networks in natural language. To effectively leverage advancements in LLMs, we propose an agentic framework that uses an intermediate representation to streamline configuration across diverse vendor equipment, retrieves the network state from memory in real-time, and provides an interface for external feedback. We also conduct pilot studies to collect real user data of natural language utterances for network control, and present a visualization interface to facilitate dialogue-driven user interaction and enable large-scale data collection for future development. Preliminary experiments validate the effectiveness of our proposed system components with LLM integration on both synthetic and real user utterances. Through our data collection and visualization efforts, we pave the way for more effective use of LLMs and democratize network control for everyday users.",
      "tldr_zh": "è¯¥ç ”ç©¶æå‡ºäº†ä¸€ä¸ªåŸºäºå¤§è¯­è¨€æ¨¡å‹(LLM)çš„æ™ºèƒ½ä½“æ¡†æ¶ï¼Œæ—¨åœ¨é€šè¿‡è‡ªç„¶è¯­è¨€äº¤äº’ä½¿éä¸“ä¸šç”¨æˆ·ä¹Ÿèƒ½è½»æ¾è¿›è¡Œç½‘ç»œç®¡ç†ï¼Œä»è€Œé™ä½ä¼ ç»Ÿç½‘ç»œæ§åˆ¶çš„é«˜ä¸“ä¸šé—¨æ§›ã€‚è¯¥æ¡†æ¶è®¾è®¡äº†ä¸€ç§ä¸­é—´è¡¨ç¤º(intermediate representation)æ¥ç®€åŒ–ä¸åŒå‚å•†è®¾å¤‡çš„é…ç½®æµç¨‹ï¼Œå¹¶ç»“åˆå®æ—¶çŠ¶æ€æ£€ç´¢å’Œå¤–éƒ¨åé¦ˆæ¥å£ï¼Œç¡®ä¿äº†ç½‘ç»œæ§åˆ¶çš„ç²¾å‡†æ€§ä¸çµæ´»æ€§ã€‚é€šè¿‡è¯•ç‚¹ç ”ç©¶ï¼Œå›¢é˜Ÿæ”¶é›†äº†çœŸå®çš„è‡ªç„¶è¯­è¨€äº¤äº’æ•°æ®ï¼Œå¹¶å¼€å‘äº†å¯è§†åŒ–ç•Œé¢ä»¥æ”¯æŒå¯¹è¯é©±åŠ¨çš„ç”¨æˆ·äº¤äº’ä¸å¤§è§„æ¨¡æ•°æ®é‡‡é›†ã€‚åˆæ­¥å®éªŒç»“æœéªŒè¯äº†è¯¥ç³»ç»Ÿåœ¨å¤„ç†åˆæˆåŠçœŸå®ç”¨æˆ·æŒ‡ä»¤æ–¹é¢çš„æœ‰æ•ˆæ€§ï¼Œä¸ºå®ç°ç½‘ç»œæ§åˆ¶çš„å¹³æ°‘åŒ–å’ŒLLMåœ¨ç½‘ç»œé¢†åŸŸçš„æ·±åº¦åº”ç”¨å¼€è¾Ÿäº†æ–°è·¯å¾„ã€‚",
      "categories": [
        "cs.NI",
        "cs.AI",
        "cs.LG"
      ],
      "primary_category": "cs.NI",
      "comment": "11 pages, 6 figures",
      "pdf_url": "https://arxiv.org/pdf/2509.20600v1",
      "published_date": "2025-09-24 22:45:09 UTC",
      "updated_date": "2025-09-24 22:45:09 UTC",
      "processing_status": "completed",
      "attempts": 1,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "llm_backup_calls": 0,
      "last_update": "2026-01-24T20:45:51.494067+00:00"
    },
    {
      "arxiv_id": "2509.20589v1",
      "title": "Every Character Counts: From Vulnerability to Defense in Phishing Detection",
      "title_zh": "æ¯ä¸€ä¸ªå­—ç¬¦éƒ½è‡³å…³é‡è¦ï¼šç½‘ç»œé’“é±¼æ£€æµ‹ä¸­ä»è„†å¼±æ€§åˆ°é˜²å¾¡çš„æ¢ç©¶",
      "authors": [
        "Maria Chiper",
        "Radu Tudor Ionescu"
      ],
      "abstract": "Phishing attacks targeting both organizations and individuals are becoming an increasingly significant threat as technology advances. Current automatic detection methods often lack explainability and robustness in detecting new phishing attacks. In this work, we investigate the effectiveness of character-level deep learning models for phishing detection, which can provide both robustness and interpretability. We evaluate three neural architectures adapted to operate at the character level, namely CharCNN, CharGRU, and CharBiLSTM, on a custom-built email dataset, which combines data from multiple sources. Their performance is analyzed under three scenarios: (i) standard training and testing, (ii) standard training and testing under adversarial attacks, and (iii) training and testing with adversarial examples. Aiming to develop a tool that operates as a browser extension, we test all models under limited computational resources. In this constrained setup, CharGRU proves to be the best-performing model across all scenarios. All models show vulnerability to adversarial attacks, but adversarial training substantially improves their robustness. In addition, by adapting the Gradient-weighted Class Activation Mapping (Grad-CAM) technique to character-level inputs, we are able to visualize which parts of each email influence the decision of each model. Our open-source code and data is released at https://github.com/chipermaria/every-character-counts.",
      "tldr_zh": "è¯¥ç ”ç©¶æ¢è®¨äº†å­—ç¬¦çº§æ·±åº¦å­¦ä¹ æ¨¡å‹åœ¨ç½‘ç»œé’“é±¼æ£€æµ‹ä¸­çš„æœ‰æ•ˆæ€§ï¼Œæ—¨åœ¨æå‡ç°æœ‰è‡ªåŠ¨åŒ–æ£€æµ‹æ–¹æ³•çš„é²æ£’æ€§å’Œå¯è§£é‡Šæ€§ã€‚ä½œè€…é’ˆå¯¹ CharCNNã€CharGRU å’Œ CharBiLSTM ä¸‰ç§ç¥ç»ç½‘ç»œæ¶æ„è¿›è¡Œäº†å­—ç¬¦çº§é€‚é…ï¼Œå¹¶åœ¨ä¸€ä¸ªç»“åˆå¤šæºæ•°æ®çš„è‡ªå®šä¹‰ç”µå­é‚®ä»¶æ•°æ®é›†ä¸Šè¿›è¡Œäº†ç³»ç»Ÿè¯„ä¼°ã€‚å®éªŒé‡ç‚¹åˆ†æäº†æ¨¡å‹åœ¨æ ‡å‡†è®­ç»ƒã€å¯¹æŠ—æ€§æ”»å‡» (adversarial attacks) ä»¥åŠå¼•å…¥å¯¹æŠ—æ€§æ ·æœ¬è®­ç»ƒè¿™ä¸‰ç§åœºæ™¯ä¸‹çš„æ€§èƒ½è¡¨ç°ã€‚è€ƒè™‘åˆ°æµè§ˆå™¨æ‰©å±•ç¨‹åºçš„è®¡ç®—èµ„æºé™åˆ¶ï¼ŒCharGRU åœ¨æ‰€æœ‰æµ‹è¯•åœºæ™¯ä¸­å‡è¢«è¯æ˜æ˜¯è¡¨ç°æœ€ä¼˜çš„æ¨¡å‹ã€‚ç ”ç©¶å‘ç°è™½ç„¶æ¨¡å‹æ™®éæ˜“å—æ”»å‡»ï¼Œä½†é€šè¿‡å¯¹æŠ—æ€§è®­ç»ƒ (adversarial training) å¯ä»¥æ˜¾è‘—å¢å¼ºå…¶é˜²å¾¡ç¨³å¥æ€§ã€‚æ­¤å¤–ï¼Œè¯¥ç ”ç©¶å°† Grad-CAM æŠ€æœ¯åº”ç”¨äºå­—ç¬¦çº§è¾“å…¥ï¼Œå®ç°äº†å¯¹æ¨¡å‹å†³ç­–è¿‡ç¨‹çš„è§†è§‰åŒ–è§£é‡Šã€‚è¯¥é¡¹å·¥ä½œçš„å¼€æºä»£ç å’Œæ•°æ®ä¸ºå¼€å‘å¯ä¿¡ã€é«˜æ•ˆçš„ç½‘ç»œé’“é±¼æ£€æµ‹ç³»ç»Ÿå¥ å®šäº†åŸºç¡€ã€‚",
      "categories": [
        "cs.CR",
        "cs.AI",
        "cs.CL",
        "cs.LG"
      ],
      "primary_category": "cs.CR",
      "comment": "Accepted at ICTAI 2025",
      "pdf_url": "https://arxiv.org/pdf/2509.20589v1",
      "published_date": "2025-09-24 22:03:30 UTC",
      "updated_date": "2025-09-24 22:03:30 UTC",
      "processing_status": "completed",
      "attempts": 1,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "llm_backup_calls": 0,
      "last_update": "2026-01-24T20:45:57.789309+00:00"
    },
    {
      "arxiv_id": "2509.20581v1",
      "title": "Hierarchical Resolution Transformers: A Wavelet-Inspired Architecture for Multi-Scale Language Understanding",
      "title_zh": "Hierarchical Resolution Transformersï¼šä¸€ç§å—å°æ³¢å¯å‘çš„å¤šå°ºåº¦è¯­è¨€ç†è§£æ¶æ„",
      "authors": [
        "Ayan Sar",
        "Sampurna Roy",
        "Kanav Gupta",
        "Anurag Kaushish",
        "Tanupriya Choudhury",
        "Abhijit Kumar"
      ],
      "abstract": "Transformer architectures have achieved state-of-the-art performance across natural language tasks, yet they fundamentally misrepresent the hierarchical nature of human language by processing text as flat token sequences. This results in quadratic computational cost, weak computational cost, weak compositional generalization, and inadequate discourse-level modeling. We propose Hierarchical Resolution Transformer (HRT), a novel wavelet-inspired neural architecture that processes language simultaneously across multiple resolutions, from characters to discourse-level units. HRT constructs a multi-resolution attention, enabling bottom-up composition and top-down contextualization. By employing exponential sequence reduction across scales, HRT achieves O(nlogn) complexity, offering significant efficiency improvements over standard transformers. We evaluated HRT on a diverse suite of benchmarks, including GLUE, SuperGLUE, Long Range Arena, and WikiText-103, and results demonstrated that HRT outperforms standard transformer baselines by an average of +3.8% on GLUE, +4.5% on SuperGLUE, and +6.1% on Long Range Arena, while reducing memory usage by 42% and inference latency by 37% compared to BERT and GPT style models of similar parameter count. Ablation studies confirm the effectiveness of cross-resolution attention and scale-specialized modules, showing that each contributes independently to both efficiency and accuracy. Our findings establish HRT as the first architecture to align computational structure with the hierarchical organization of human language, demonstrating that multi-scale, wavelet-inspired processing yields both theoretical efficiency gains and practical improvements in language understanding.",
      "tldr_zh": "è¯¥ç ”ç©¶æå‡ºäº†å±‚æ¬¡åŒ–åˆ†è¾¨ç‡å˜æ¢å™¨(Hierarchical Resolution Transformer, HRT)ï¼Œæ—¨åœ¨è§£å†³æ ‡å‡† Transformer å°†æ–‡æœ¬å¤„ç†ä¸ºæ‰å¹³åºåˆ—è€Œå¿½ç•¥è¯­è¨€å±‚æ¬¡ç»“æ„æ‰€å¯¼è‡´çš„è®¡ç®—å¼€é”€å¤§å’Œç»„åˆæ³›åŒ–å¼±ç­‰é—®é¢˜ã€‚HRT å€Ÿé‰´äº†å°æ³¢å˜æ¢(Wavelet-Inspired)çš„ç†å¿µï¼Œé€šè¿‡å¤šåˆ†è¾¨ç‡å¤„ç†ä»å­—ç¬¦çº§åˆ°ç¯‡ç« çº§çš„è¯­ä¹‰å•å…ƒï¼Œå¹¶æ„å»ºäº†æ”¯æŒè‡ªåº•å‘ä¸Šç»„åˆ(Bottom-up Composition)ä¸è‡ªé¡¶å‘ä¸‹ä¸Šä¸‹æ–‡å»ºæ¨¡(Top-down Contextualization)çš„å¤šåˆ†è¾¨ç‡æ³¨æ„åŠ›æœºåˆ¶(Multi-resolution Attention)ã€‚é€šè¿‡è·¨å°ºåº¦çš„æŒ‡æ•°çº§åºåˆ—ç¼©å‡ï¼ŒHRT å®ç°äº† $O(n \\log n)$ çš„è®¡ç®—å¤æ‚åº¦ï¼Œåœ¨ GLUEã€SuperGLUE å’Œ Long Range Arena ç­‰å¤šä¸ªåŸºå‡†æµ‹è¯•ä¸­æ˜¾è‘—ä¼˜äºæ ‡å‡† Transformer åŸºçº¿ã€‚å®éªŒç»“æœæ˜¾ç¤ºï¼Œä¸åŒå‚æ•°è§„æ¨¡çš„ BERT æˆ– GPT æ¨¡å‹ç›¸æ¯”ï¼ŒHRT åœ¨æå‡å‡†ç¡®ç‡çš„åŒæ—¶å‡å°‘äº† 42% çš„æ˜¾å­˜å ç”¨å’Œ 37% çš„æ¨ç†å»¶è¿Ÿã€‚æ¶ˆèç ”ç©¶è¿›ä¸€æ­¥è¯å®äº†è·¨åˆ†è¾¨ç‡æ³¨æ„åŠ›å’Œå°ºåº¦ä¸“ç”¨æ¨¡å—å¯¹æ¨¡å‹æ•ˆç‡ä¸æ€§èƒ½çš„è´¡çŒ®ï¼Œè¯æ˜äº†å°†è®¡ç®—ç»“æ„ä¸è¯­è¨€å±‚æ¬¡ç»“æ„å¯¹é½èƒ½å¸¦æ¥æ˜¾è‘—çš„æ€§èƒ½å¢ç›Šä¸æ•ˆç‡æå‡ã€‚",
      "categories": [
        "cs.CL",
        "cs.AI",
        "cs.IR"
      ],
      "primary_category": "cs.CL",
      "comment": "Submitted in IEEE International Conference on Big Data 2025",
      "pdf_url": "https://arxiv.org/pdf/2509.20581v1",
      "published_date": "2025-09-24 21:46:18 UTC",
      "updated_date": "2025-09-24 21:46:18 UTC",
      "processing_status": "completed",
      "attempts": 1,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "llm_backup_calls": 0,
      "last_update": "2026-01-24T20:46:00.260311+00:00"
    },
    {
      "arxiv_id": "2509.22721v1",
      "title": "A Data-Driven Framework for Digital Transformation in Smart Cities: Integrating AI, Dashboards, and IoT Readiness",
      "title_zh": "æ™ºæ…§åŸå¸‚æ•°å­—åŒ–è½¬å‹çš„æ•°æ®é©±åŠ¨æ¡†æ¶ï¼šé›†æˆäººå·¥æ™ºèƒ½ã€æ•°æ®çœ‹æ¿ä¸ç‰©è”ç½‘å°±ç»ªåº¦",
      "authors": [
        "Ãngel Lloret",
        "JesÃºs Peral",
        "Antonio FerrÃ¡ndez",
        "MarÃ­a Auladell",
        "Rafael MuÃ±oz"
      ],
      "abstract": "Digital transformation (DT) has become a strategic priority for public administrations, particularly due to the need to deliver more efficient and citizen-centered services and respond to societal expectations, ESG (Environmental, Social, and Governance) criteria, and the United Nations Sustainable Development Goals (UN SDGs). In this context, the main objective of this study is to propose an innovative methodology to automatically evaluate the level of digital transformation (DT) in public sector organizations. The proposed approach combines traditional assessment methods with Artificial Intelligence (AI) techniques. The methodology follows a dual approach: on the one hand, surveys are conducted using specialized staff from various public entities; on the other, AI-based models (including neural networks and transformer architectures) are used to estimate the DT level of the organizations automatically. Our approach has been applied to a real-world case study involving local public administrations in the Valencian Community (Spain) and shown effective performance in assessing DT. While the proposed methodology has been validated in a specific local context, its modular structure and dual-source data foundation support its international scalability, acknowledging that administrative, regulatory, and DT maturity factors may condition its broader applicability. The experiments carried out in this work include (i) the creation of a domain-specific corpus derived from the surveys and websites of several organizations, used to train the proposed models; (ii) the use and comparison of diverse AI methods; and (iii) the validation of our approach using real data. The integration of technologies such as the IoT, sensor networks, and AI-based analytics can significantly support resilient, agile urban environments and the transition towards more effective and sustainable Smart City models.",
      "tldr_zh": "è¯¥ç ”ç©¶æå‡ºäº†ä¸€ç§åˆ›æ–°çš„æ•°æ®é©±åŠ¨æ¡†æ¶ï¼Œæ—¨åœ¨é€šè¿‡æ•´åˆäººå·¥æ™ºèƒ½ (AI)ã€ä»ªè¡¨æ¿å’Œç‰©è”ç½‘å‡†å¤‡åº¦ (IoT Readiness) æ¥è¯„ä¼°å…¬å…±éƒ¨é—¨æœºæ„çš„æ•°å­—åŒ–è½¬å‹ (Digital Transformation, DT) æ°´å¹³ã€‚è¯¥æ–¹æ³•é‡‡ç”¨äº†åŒé‡è·¯å¾„ï¼Œä¸€æ–¹é¢é€šè¿‡å¯¹å…¬å…±å®ä½“ä¸“ä¸šäººå‘˜è¿›è¡Œè°ƒç ”æ”¶é›†ä¼ ç»Ÿè¯„ä¼°æ•°æ®ï¼Œå¦ä¸€æ–¹é¢åˆ©ç”¨ç¥ç»ç½‘ç»œ (Neural Networks) å’Œè½¬æ¢å™¨æ¶æ„ (Transformer) ç­‰ AI æ¨¡å‹å®ç°è‡ªåŠ¨åŒ–çš„ DT æ°´å¹³ä¼°ç®—ã€‚ç ”ç©¶å›¢é˜Ÿä¸“é—¨æ„å»ºäº†ä¸€ä¸ªç»“åˆè°ƒç ”æ•°æ®å’Œæœºæ„ç½‘ç«™å†…å®¹çš„ç‰¹å®šé¢†åŸŸè¯­æ–™åº“ (Domain-specific Corpus) ä»¥è®­ç»ƒå’Œå¯¹æ¯”ä¸åŒçš„ AI æ¨¡å‹ã€‚è¯¥æ¡†æ¶åœ¨è¥¿ç­ç‰™ç“¦ä¼¦è¥¿äºšåœ°åŒºçš„å…¬å…±ç®¡ç†éƒ¨é—¨è¿›è¡Œäº†å®è¯ç ”ç©¶ï¼Œå®éªŒç»“æœè¯æ˜äº†è¯¥æ–¹æ³•åœ¨è¯„ä¼°æ•°å­—åŒ–è½¬å‹ç°çŠ¶æ–¹é¢çš„æœ‰æ•ˆæ€§ã€‚å°½ç®¡è¯¥ç ”ç©¶åœ¨ç‰¹å®šåœ°æ–¹èƒŒæ™¯ä¸‹è¿›è¡Œäº†éªŒè¯ï¼Œä½†å…¶æ¨¡å—åŒ–ç»“æ„å’ŒåŒæºæ•°æ®åŸºç¡€æ”¯æŒå›½é™…èŒƒå›´å†…çš„æ‰©å±•åº”ç”¨ï¼Œèƒ½å¤Ÿæœ‰æ•ˆæ¨åŠ¨å‘æ›´å…·éŸ§æ€§å’Œå¯æŒç»­æ€§çš„æ™ºæ…§åŸå¸‚ (Smart City) æ¨¡å‹è½¬å‹ã€‚",
      "categories": [
        "cs.CY",
        "cs.AI",
        "cs.LG"
      ],
      "primary_category": "cs.CY",
      "comment": "30 pages, 5 figures",
      "pdf_url": "https://arxiv.org/pdf/2509.22721v1",
      "published_date": "2025-09-24 21:39:40 UTC",
      "updated_date": "2025-09-24 21:39:40 UTC",
      "processing_status": "completed",
      "attempts": 1,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "llm_backup_calls": 0,
      "last_update": "2026-01-24T20:46:04.668894+00:00"
    },
    {
      "arxiv_id": "2509.20577v1",
      "title": "Dynamic Reasoning Chains through Depth-Specialized Mixture-of-Experts in Transformer Architectures",
      "title_zh": "Transformer æ¶æ„ä¸­åŸºäºæ·±åº¦ä¸“ä¸šåŒ–æ··åˆä¸“å®¶çš„åŠ¨æ€æ¨ç†é“¾",
      "authors": [
        "Sampurna Roy",
        "Ayan Sar",
        "Anurag Kaushish",
        "Kanav Gupta",
        "Tanupriya Choudhury",
        "Abhijit Kumar"
      ],
      "abstract": "Contemporary transformer architectures apply identical processing depth to all inputs, creating inefficiencies and limiting reasoning quality. Simple factual queries are subjected to the same multilayered computation as complex logical problems, wasting resources while constraining deep inference. To overcome this, we came up with a concept of Dynamic Reasoning Chains through Depth Specialised Mixture of Experts (DS-MoE), a modular framework that extends the Mixture of Experts paradigm from width-based to depth specialised computation. DS-MoE introduces expert modules optimised for distinct reasoning depths, shallow pattern recognition, compositional reasoning, logical inference, memory integration, and meta-cognitive supervision. A learned routing network dynamically assembles custom reasoning chains, activating only the necessary experts to match input complexity. The dataset on which we trained and evaluated DS-MoE is on The Pile, an 800GB corpus covering diverse domains such as scientific papers, legal texts, programming code, and web content, enabling systematic assessment across reasoning depths. Experimental results demonstrate that DS-MoE achieves up to 16 per cent computational savings and 35 per cent faster inference compared to uniform-depth transformers, while delivering 2.8 per cent higher accuracy on complex multi-step reasoning benchmarks. Furthermore, routing decisions yield interpretable reasoning chains, enhancing transparency and scalability. These findings establish DS-MoE as a significant advancement in adaptive neural architectures, demonstrating that depth-specialised modular processing can simultaneously improve efficiency, reasoning quality, and interpretability in large-scale language models.",
      "tldr_zh": "è¯¥ç ”ç©¶é’ˆå¯¹å½“ä»£ Transformer æ¶æ„å¯¹æ‰€æœ‰è¾“å…¥åº”ç”¨ç›¸åŒå¤„ç†æ·±åº¦å¯¼è‡´çš„è®¡ç®—æ•ˆç‡ä½ä¸‹å’Œæ¨ç†è´¨é‡å—é™é—®é¢˜ï¼Œæå‡ºäº† Depth-Specialized Mixture-of-Experts (DS-MoE) æ¡†æ¶ã€‚DS-MoE å°† Mixture of Experts èŒƒå¼ä»ä¼ ç»Ÿçš„å®½åº¦æ‰©å±•åˆ°æ·±åº¦ç‰¹åŒ–è®¡ç®—ï¼Œå¼•å…¥äº†ä¸“é—¨é’ˆå¯¹ shallow pattern recognitionã€compositional reasoningã€logical inferenceã€memory integration å’Œ meta-cognitive supervision ç­‰ä¸åŒæ¨ç†æ·±åº¦çš„ä¸“å®¶æ¨¡å—ã€‚è¯¥æ¡†æ¶é€šè¿‡ä¸€ä¸ªå­¦ä¹ å‹è·¯ç”±ç½‘ç»œåŠ¨æ€ç»„å»ºè‡ªå®šä¹‰çš„æ¨ç†é“¾ï¼Œä»…æ ¹æ®è¾“å…¥å¤æ‚åº¦æ¿€æ´»å¿…è¦çš„ä¸“å®¶æ¨¡å—ã€‚ç ”ç©¶å›¢é˜Ÿåœ¨ The Pile æ•°æ®é›†ä¸Šè¿›è¡Œäº†ç³»ç»Ÿè¯„ä¼°ï¼Œå®éªŒç»“æœæ˜¾ç¤ºï¼Œä¸å‡åŒ€æ·±åº¦çš„ Transformer ç›¸æ¯”ï¼ŒDS-MoE å®ç°äº†é«˜è¾¾ 16% çš„è®¡ç®—èŠ‚çœå’Œ 35% çš„æ¨ç†åŠ é€Ÿï¼ŒåŒæ—¶åœ¨å¤æ‚å¤šæ­¥æ¨ç†åŸºå‡†æµ‹è¯•ä¸­å‡†ç¡®ç‡æå‡äº† 2.8%ã€‚æ­¤å¤–ï¼Œè¯¥æ¶æ„ç”Ÿæˆçš„è·¯ç”±å†³ç­–æä¾›äº†å…·æœ‰å¯è§£é‡Šæ€§çš„æ¨ç†é“¾ï¼Œæ˜¾è‘—å¢å¼ºäº†å¤§å‹è¯­è¨€æ¨¡å‹çš„é€æ˜åº¦ä¸æ‰©å±•æ€§ã€‚è¿™äº›å‘ç°è¯æ˜äº†æ·±åº¦ç‰¹åŒ–æ¨¡å—åŒ–å¤„ç†èƒ½åŒæ—¶æå‡å¤§è§„æ¨¡è¯­è¨€æ¨¡å‹çš„æ•ˆç‡ã€æ¨ç†è´¨é‡ä¸å¯è§£é‡Šæ€§ï¼Œæ˜¯è‡ªé€‚åº”ç¥ç»æ¶æ„é¢†åŸŸçš„é‡è¦è¿›å±•ã€‚",
      "categories": [
        "cs.CL",
        "cs.AI",
        "cs.IR"
      ],
      "primary_category": "cs.CL",
      "comment": "Submitted in IEEE International Conference on Big Data 2025",
      "pdf_url": "https://arxiv.org/pdf/2509.20577v1",
      "published_date": "2025-09-24 21:33:54 UTC",
      "updated_date": "2025-09-24 21:33:54 UTC",
      "processing_status": "completed",
      "attempts": 1,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "llm_backup_calls": 0,
      "last_update": "2026-01-24T20:46:04.468740+00:00"
    },
    {
      "arxiv_id": "2511.13724v1",
      "title": "Preparation Meets Opportunity: Enhancing Data Preprocessing for ML Training With Seneca",
      "title_zh": "è“„åŠ¿å¾…å‘ï¼šåˆ©ç”¨ Seneca å¢å¼ºæœºå™¨å­¦ä¹ è®­ç»ƒçš„æ•°æ®é¢„å¤„ç†",
      "authors": [
        "Omkar Desai",
        "Ziyang Jiao",
        "Shuyi Pei",
        "Janki Bhimani",
        "Bryan S. Kim"
      ],
      "abstract": "Input data preprocessing is a common bottleneck when concurrently training multimedia machine learning (ML) models in modern systems. To alleviate these bottlenecks and reduce the training time for concurrent jobs, we present Seneca, a data loading system that optimizes cache partitioning and data sampling for the data storage and ingestion (DSI) pipeline. The design of Seneca contains two key techniques. First, Seneca uses a performance model for the data pipeline to optimally partition the cache for three different forms of data (encoded, decoded, and augmented). Second, Seneca opportunistically serves cached data over uncached ones during random batch sampling so that concurrent jobs benefit from each other. We implement Seneca by modifying PyTorch and demonstrate its effectiveness by comparing it against several state-of-the-art caching systems for DNN training. Seneca reduces the makespan by 45.23% compared to PyTorch and increases data processing throughput by up to 3.45x compared to the next best dataloader.",
      "tldr_zh": "è¯¥ç ”ç©¶é’ˆå¯¹ç°ä»£ç³»ç»Ÿä¸­å¤šåª’ä½“æœºå™¨å­¦ä¹ (ML)æ¨¡å‹å¹¶å‘è®­ç»ƒæ—¶çš„è¾“å…¥æ•°æ®é¢„å¤„ç†ç“¶é¢ˆï¼Œæå‡ºäº†åä¸ºSenecaçš„æ•°æ®åŠ è½½ç³»ç»Ÿã€‚Senecaé€šè¿‡ä¼˜åŒ–æ•°æ®å­˜å‚¨ä¸æ‘„å–(DSI)æµæ°´çº¿çš„ç¼“å­˜åˆ†åŒºå’Œæ•°æ®é‡‡æ ·ï¼Œæ˜¾è‘—æå‡äº†è®­ç»ƒæ•ˆç‡ã€‚å…¶æ ¸å¿ƒæŠ€æœ¯åŒ…æ‹¬åˆ©ç”¨æ€§èƒ½æ¨¡å‹å¯¹ç¼–ç (encoded)ã€è§£ç (decoded)å’Œå¢å¼º(augmented)ä¸‰ç§æ•°æ®å½¢æ€è¿›è¡Œæœ€ä¼˜ç¼“å­˜åˆ†åŒºï¼Œå¹¶åœ¨éšæœºæ‰¹æ¬¡é‡‡æ ·ä¸­é€šè¿‡ä¼˜å…ˆæœåŠ¡å·²ç¼“å­˜æ•°æ®æ¥å®ç°å¹¶å‘ä»»åŠ¡é—´çš„ååŒå¢æ•ˆã€‚ç ”ç©¶äººå‘˜é€šè¿‡ä¿®æ”¹PyTorchå®ç°äº†Senecaï¼Œå¹¶å°†å…¶ä¸å¤šç§æœ€å…ˆè¿›çš„æ·±åº¦ç¥ç»ç½‘ç»œ(DNN)ç¼“å­˜ç³»ç»Ÿè¿›è¡Œäº†å¯¹æ¯”ã€‚å®éªŒç»“æœè¡¨æ˜ï¼ŒSenecaç›¸æ¯”åŸç”ŸPyTorchå¯å°†ä»»åŠ¡å®Œæˆæ—¶é—´(makespan)ç¼©çŸ­45.23%ï¼Œä¸”æ•°æ®å¤„ç†ååé‡æœ€é«˜å¯è¾¾åˆ°æ¬¡ä¼˜æ•°æ®åŠ è½½å™¨(dataloader)çš„3.45å€ã€‚",
      "categories": [
        "cs.OS",
        "cs.AI",
        "cs.LG"
      ],
      "primary_category": "cs.OS",
      "comment": "18 pages, 15 figures, To be published in the 24th USENIX Conference on File and Storage Technologies (FAST '26)",
      "pdf_url": "https://arxiv.org/pdf/2511.13724v1",
      "published_date": "2025-09-24 21:27:42 UTC",
      "updated_date": "2025-09-24 21:27:42 UTC",
      "processing_status": "completed",
      "attempts": 1,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "llm_backup_calls": 0,
      "last_update": "2026-01-24T20:46:20.560710+00:00"
    },
    {
      "arxiv_id": "2509.20571v1",
      "title": "MechStyle: Augmenting Generative AI with Mechanical Simulation to Create Stylized and Structurally Viable 3D Models",
      "title_zh": "MechStyleï¼šèåˆåŠ›å­¦ä»¿çœŸä¸ç”Ÿæˆå¼äººå·¥æ™ºèƒ½ï¼Œæ„å»ºé£æ ¼åŒ–ä¸”ç»“æ„ç¨³å¥çš„ 3D æ¨¡å‹",
      "authors": [
        "Faraz Faruqi",
        "Amira Abdel-Rahman",
        "Leandra Tejedor",
        "Martin Nisser",
        "Jiaji Li",
        "Vrushank Phadnis",
        "Varun Jampani",
        "Neil Gershenfeld",
        "Megan Hofmann",
        "Stefanie Mueller"
      ],
      "abstract": "Recent developments in Generative AI enable creators to stylize 3D models based on text prompts. These methods change the 3D model geometry, which can compromise the model's structural integrity once fabricated. We present MechStyle, a system that enables creators to stylize 3D printable models while preserving their structural integrity. MechStyle accomplishes this by augmenting the Generative AI-based stylization process with feedback from a Finite Element Analysis (FEA) simulation. As the stylization process modifies the geometry to approximate the desired style, feedback from the FEA simulation reduces modifications to regions with increased stress. We evaluate the effectiveness of FEA simulation feedback in the augmented stylization process by comparing three stylization control strategies. We also investigate the time efficiency of our approach by comparing three adaptive scheduling strategies. Finally, we demonstrate MechStyle's user interface that allows users to generate stylized and structurally viable 3D models and provide five example applications.",
      "tldr_zh": "è¯¥ç ”ç©¶æå‡ºäº†MechStyleç³»ç»Ÿï¼Œæ—¨åœ¨è§£å†³ç”Ÿæˆå¼äººå·¥æ™ºèƒ½(Generative AI)åœ¨3Dæ¨¡å‹é£æ ¼åŒ–è¿‡ç¨‹ä¸­å› å‡ ä½•å½¢å˜è€ŒæŸå®³ç»“æ„å®Œæ•´æ€§çš„é—®é¢˜ã€‚è¯¥ç³»ç»Ÿé€šè¿‡åœ¨Generative AIçš„é£æ ¼åŒ–æµç¨‹ä¸­å¼•å…¥æœ‰é™å…ƒåˆ†æ(Finite Element Analysis, FEA)æ¨¡æ‹Ÿåé¦ˆï¼Œç¡®ä¿ç”Ÿæˆçš„3Dæ‰“å°æ¨¡å‹åœ¨æ»¡è¶³è§†è§‰é£æ ¼çš„åŒæ—¶å…·å¤‡ç‰©ç†ç»“æ„ç¨³å®šæ€§ã€‚å½“ç³»ç»Ÿæ ¹æ®æ–‡æœ¬æç¤ºä¿®æ”¹å‡ ä½•å½¢çŠ¶ä»¥é€¼è¿‘ç›®æ ‡é£æ ¼æ—¶ï¼ŒFEAæ¨¡æ‹Ÿæä¾›çš„åé¦ˆä¼šè‡ªåŠ¨å‡å°‘å¯¹é«˜åº”åŠ›(stress)åŒºåŸŸçš„ä¿®æ”¹ï¼Œä»è€Œä¿æŠ¤æ¨¡å‹çš„ç»“æ„å¼ºåº¦ã€‚ç ”ç©¶å›¢é˜Ÿé€šè¿‡å¯¹æ¯”ä¸‰ç§é£æ ¼åŒ–æ§åˆ¶ç­–ç•¥è¯„ä¼°äº†FEAåé¦ˆçš„æœ‰æ•ˆæ€§ï¼Œå¹¶ç ”ç©¶äº†ä¸‰ç§è‡ªé€‚åº”è°ƒåº¦ç­–ç•¥ä»¥æå‡å¤„ç†æ•ˆç‡ã€‚æ­¤å¤–ï¼ŒMechStyleè¿˜æä¾›äº†ç›´è§‚çš„ç”¨æˆ·ç•Œé¢ï¼Œå¹¶é€šè¿‡äº”ä¸ªç¤ºä¾‹åº”ç”¨å±•ç¤ºäº†å…¶ç”Ÿæˆå…¼å…·è‰ºæœ¯é£æ ¼ä¸ç»“æ„å¯è¡Œæ€§çš„3Dæ¨¡å‹çš„èƒ½åŠ›ã€‚",
      "categories": [
        "cs.HC",
        "cs.AI"
      ],
      "primary_category": "cs.HC",
      "comment": "",
      "pdf_url": "https://arxiv.org/pdf/2509.20571v1",
      "published_date": "2025-09-24 21:24:25 UTC",
      "updated_date": "2025-09-24 21:24:25 UTC",
      "processing_status": "completed",
      "attempts": 1,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "llm_backup_calls": 0,
      "last_update": "2026-01-24T20:46:13.873507+00:00"
    },
    {
      "arxiv_id": "2509.20570v1",
      "title": "PIRF: Physics-Informed Reward Fine-Tuning for Diffusion Models",
      "title_zh": "PIRFï¼šæ‰©æ•£æ¨¡å‹çš„ç‰©ç†ä¿¡æ¯å¥–åŠ±å¾®è°ƒ",
      "authors": [
        "Mingze Yuan",
        "Pengfei Jin",
        "Na Li",
        "Quanzheng Li"
      ],
      "abstract": "Diffusion models have demonstrated strong generative capabilities across scientific domains, but often produce outputs that violate physical laws. We propose a new perspective by framing physics-informed generation as a sparse reward optimization problem, where adherence to physical constraints is treated as a reward signal. This formulation unifies prior approaches under a reward-based paradigm and reveals a shared bottleneck: reliance on diffusion posterior sampling (DPS)-style value function approximations, which introduce non-negligible errors and lead to training instability and inference inefficiency. To overcome this, we introduce Physics-Informed Reward Fine-tuning (PIRF), a method that bypasses value approximation by computing trajectory-level rewards and backpropagating their gradients directly. However, a naive implementation suffers from low sample efficiency and compromised data fidelity. PIRF mitigates these issues through two key strategies: (1) a layer-wise truncated backpropagation method that leverages the spatiotemporally localized nature of physics-based rewards, and (2) a weight-based regularization scheme that improves efficiency over traditional distillation-based methods. Across five PDE benchmarks, PIRF consistently achieves superior physical enforcement under efficient sampling regimes, highlighting the potential of reward fine-tuning for advancing scientific generative modeling.",
      "tldr_zh": "è¯¥ç ”ç©¶é’ˆå¯¹æ‰©æ•£æ¨¡å‹åœ¨ç§‘å­¦é¢†åŸŸç”Ÿæˆå†…å®¹å¸¸è¿åç‰©ç†å®šå¾‹çš„é—®é¢˜ï¼Œæå‡ºå°†ç‰©ç†å¢å¼ºç”Ÿæˆå»ºæ¨¡ä¸ºç¨€ç–å¥–åŠ±ä¼˜åŒ–é—®é¢˜ï¼Œå¹¶å°†ç‰©ç†çº¦æŸè§†ä¸º Reward Signalã€‚ç ”ç©¶æŒ‡å‡ºï¼Œä¼ ç»Ÿæ–¹æ³•ä¾èµ– Diffusion Posterior Sampling (DPS) å¼çš„ä»·å€¼å‡½æ•°è¿‘ä¼¼ï¼Œå®¹æ˜“å¼•å…¥è¯¯å·®å¹¶å¯¼è‡´è®­ç»ƒä¸ç¨³å®šåŠæ¨ç†æ•ˆç‡ä½ä¸‹ã€‚ä¸ºæ­¤ï¼Œä½œè€…å¼€å‘äº† Physics-Informed Reward Fine-tuning (PIRF) æ–¹æ³•ï¼Œé€šè¿‡è®¡ç®— Trajectory-level Rewards å¹¶ç›´æ¥åå‘ä¼ æ’­æ¢¯åº¦ï¼ŒæˆåŠŸç»•è¿‡äº†ä»·å€¼è¿‘ä¼¼çš„ç“¶é¢ˆã€‚PIRF å¼•å…¥äº†å±‚çº§æˆªæ–­åå‘ä¼ æ’­ (Layer-wise Truncated Backpropagation) ä»¥åˆ©ç”¨ç‰©ç†å¥–åŠ±çš„æ—¶ç©ºå±€éƒ¨ç‰¹æ€§ï¼Œå¹¶ç»“åˆåŸºäºæƒé‡çš„æ­£åˆ™åŒ–æ–¹æ¡ˆä»¥æå‡æ•°æ®ä¿çœŸåº¦ä¸é‡‡æ ·æ•ˆç‡ã€‚åœ¨äº”ä¸ª PDE åŸºå‡†æµ‹è¯•ä¸­çš„å®éªŒç»“æœè¡¨æ˜ï¼ŒPIRF åœ¨ä¿æŒé«˜æ•ˆé‡‡æ ·çš„åŒæ—¶ï¼Œæ˜¾è‘—å¢å¼ºäº†ç”Ÿæˆç»“æœå¯¹ç‰©ç†å®šå¾‹çš„éµå¾ªç¨‹åº¦ã€‚è¿™ä¸€æˆæœè¯æ˜äº† Reward Fine-tuning åœ¨æ¨è¿›ç§‘å­¦ç”Ÿæˆå»ºæ¨¡ä»»åŠ¡ä¸­çš„æ ¸å¿ƒä»·å€¼ä¸æ½œåŠ›ã€‚",
      "categories": [
        "cs.LG",
        "cs.AI",
        "cs.CE",
        "eess.SY"
      ],
      "primary_category": "cs.LG",
      "comment": "18 pages, 6 figures; NeurIPS 2025 AI for science workshop",
      "pdf_url": "https://arxiv.org/pdf/2509.20570v1",
      "published_date": "2025-09-24 21:23:03 UTC",
      "updated_date": "2025-09-24 21:23:03 UTC",
      "processing_status": "completed",
      "attempts": 1,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "llm_backup_calls": 0,
      "last_update": "2026-01-24T20:46:38.091958+00:00"
    },
    {
      "arxiv_id": "2509.20567v1",
      "title": "SwasthLLM: a Unified Cross-Lingual, Multi-Task, and Meta-Learning Zero-Shot Framework for Medical Diagnosis Using Contrastive Representations",
      "title_zh": "SwasthLLMï¼šä¸€ç§åŸºäºå¯¹æ¯”è¡¨å¾çš„ç»Ÿä¸€è·¨è¯­è¨€ã€å¤šä»»åŠ¡ä¸å…ƒå­¦ä¹ åŒ»å­¦è¯Šæ–­é›¶æ ·æœ¬æ¡†æ¶",
      "authors": [
        "Ayan Sar",
        "Pranav Singh Puri",
        "Sumit Aich",
        "Tanupriya Choudhury",
        "Abhijit Kumar"
      ],
      "abstract": "In multilingual healthcare environments, automatic disease diagnosis from clinical text remains a challenging task due to the scarcity of annotated medical data in low-resource languages and the linguistic variability across populations. This paper proposes SwasthLLM, a unified, zero-shot, cross-lingual, and multi-task learning framework for medical diagnosis that operates effectively across English, Hindi, and Bengali without requiring language-specific fine-tuning. At its core, SwasthLLM leverages the multilingual XLM-RoBERTa encoder augmented with a language-aware attention mechanism and a disease classification head, enabling the model to extract medically relevant information regardless of the language structure. To align semantic representations across languages, a Siamese contrastive learning module is introduced, ensuring that equivalent medical texts in different languages produce similar embeddings. Further, a translation consistency module and a contrastive projection head reinforce language-invariant representation learning. SwasthLLM is trained using a multi-task learning strategy, jointly optimizing disease classification, translation alignment, and contrastive learning objectives. Additionally, we employ Model-Agnostic Meta-Learning (MAML) to equip the model with rapid adaptation capabilities for unseen languages or tasks with minimal data. Our phased training pipeline emphasizes robust representation alignment before task-specific fine-tuning. Extensive evaluation shows that SwasthLLM achieves high diagnostic performance, with a test accuracy of 97.22% and an F1-score of 97.17% in supervised settings. Crucially, in zero-shot scenarios, it attains 92.78% accuracy on Hindi and 73.33% accuracy on Bengali medical text, demonstrating strong generalization in low-resource contexts.",
      "tldr_zh": "è¿™é¡¹ç ”ç©¶æå‡ºäº† SwasthLLMï¼Œä¸€ä¸ªç»Ÿä¸€çš„è·¨è¯­è¨€ã€å¤šä»»åŠ¡åŠå…ƒå­¦ä¹ é›¶æ ·æœ¬ (zero-shot) æ¡†æ¶ï¼Œæ—¨åœ¨è§£å†³å¤šè¯­è¨€åŒ»ç–—ç¯å¢ƒä¸­ä½èµ„æºè¯­è¨€æ ‡æ³¨æ•°æ®åŒ®ä¹å’Œè¯­è¨€å˜å¼‚å¸¦æ¥çš„è‡ªåŠ¨ç–¾ç—…è¯Šæ–­éš¾é¢˜ã€‚è¯¥æ¡†æ¶ä»¥ XLM-RoBERTa ç¼–ç å™¨ä¸ºæ ¸å¿ƒï¼Œç»“åˆè¯­è¨€æ„ŸçŸ¥æ³¨æ„åŠ›æœºåˆ¶ (language-aware attention) å’Œç–¾ç—…åˆ†ç±»å¤´ï¼Œä½¿å…¶èƒ½å¤Ÿè·¨è¶Šè‹±è¯­ã€å°åœ°è¯­å’Œå­ŸåŠ æ‹‰è¯­æå–å…³é”®åŒ»ç–—ä¿¡æ¯ã€‚ä¸ºäº†å®ç°ä¸åŒè¯­è¨€é—´çš„è¯­ä¹‰å¯¹é½ï¼ŒSwasthLLM å¼•å…¥äº†å­ªç”Ÿå¯¹æ¯”å­¦ä¹ æ¨¡å— (Siamese contrastive learning)ã€ç¿»è¯‘ä¸€è‡´æ€§æ¨¡å—å’Œå¯¹æ¯”æŠ•å½±å¤´ï¼Œç¡®ä¿å¤šè¯­è¨€ä¸‹çš„åŒ»å­¦æ–‡æœ¬ç”Ÿæˆç›¸ä¼¼çš„åµŒå…¥è¡¨ç¤ºã€‚ç ”ç©¶é‡‡ç”¨å¤šä»»åŠ¡å­¦ä¹ ç­–ç•¥è”åˆä¼˜åŒ–åˆ†ç±»ä¸å¯¹é½ç›®æ ‡ï¼Œå¹¶åˆ©ç”¨æ¨¡å‹æ— å…³å…ƒå­¦ä¹  (Model-Agnostic Meta-Learning, MAML) å¢å¼ºæ¨¡å‹å¯¹æœªçŸ¥è¯­è¨€æˆ–ä»»åŠ¡çš„å¿«é€Ÿé€‚åº”èƒ½åŠ›ã€‚å®éªŒç»“æœæ˜¾ç¤ºï¼ŒSwasthLLM åœ¨æœ‰ç›‘ç£è®¾ç½®ä¸‹è¾¾åˆ°äº† 97.22% çš„å‡†ç¡®ç‡ï¼Œè€Œåœ¨é›¶æ ·æœ¬åœºæ™¯ä¸‹ï¼Œå°åœ°è¯­å’Œå­ŸåŠ æ‹‰è¯­çš„è¯Šæ–­å‡†ç¡®ç‡åˆ†åˆ«è¾¾åˆ° 92.78% å’Œ 73.33%ã€‚è¯¥ç ”ç©¶è¯æ˜äº†é€šè¿‡å¯¹æ¯”è¡¨å¾å­¦ä¹ å’Œå…ƒå­¦ä¹ ç­–ç•¥ï¼Œå¯ä»¥åœ¨æ— éœ€ç‰¹å®šè¯­è¨€å¾®è°ƒçš„æƒ…å†µä¸‹ï¼Œå®ç°ä½èµ„æºåŒ»ç–—æ–‡æœ¬çš„é«˜æ•ˆæ³›åŒ–ã€‚",
      "categories": [
        "cs.CL",
        "cs.AI",
        "cs.IR"
      ],
      "primary_category": "cs.CL",
      "comment": "Submitted to International Conference on Big Data 2025",
      "pdf_url": "https://arxiv.org/pdf/2509.20567v1",
      "published_date": "2025-09-24 21:20:49 UTC",
      "updated_date": "2025-09-24 21:20:49 UTC",
      "processing_status": "completed",
      "attempts": 1,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "llm_backup_calls": 0,
      "last_update": "2026-01-24T20:46:40.589873+00:00"
    },
    {
      "arxiv_id": "2509.20562v1",
      "title": "SAMULE: Self-Learning Agents Enhanced by Multi-level Reflection",
      "title_zh": "SAMULEï¼šå¤šçº§åæ€å¢å¼ºçš„è‡ªå­¦ä¹ æ™ºèƒ½ä½“",
      "authors": [
        "Yubin Ge",
        "Salvatore Romeo",
        "Jason Cai",
        "Monica Sunkara",
        "Yi Zhang"
      ],
      "abstract": "Despite the rapid advancements in LLM agents, they still face the challenge of generating meaningful reflections due to inadequate error analysis and a reliance on rare successful trajectories, especially in complex tasks. In this work, we propose SAMULE, a new framework for self-learning agents powered by a retrospective language model that is trained based on Multi-Level Reflection Synthesis. It first synthesizes high-quality reflections across three complementary levels: Single-Trajectory Learning (micro-level) for detailed error correction; Intra-Task Learning (meso-level) to build error taxonomies across multiple trials of the same task, and Inter-Task Learning (macro-level) to extract transferable insights based on same typed errors from diverse task failures. Then we fine-tune a language model serving as the retrospective model to generate reflections during inference. We further extend our framework to interactive settings through a foresight-based reflection mechanism, enabling agents to proactively reflect and adapt during user interactions by comparing predicted and actual responses. Extensive experiments on three challenging benchmarks - TravelPlanner, NATURAL PLAN, and Tau-bench - demonstrate that our approach significantly outperforms reflection-based baselines. Our results highlight the critical role of well-designed reflection synthesis and failure-centric learning in building self-improving LLM agents.",
      "tldr_zh": "è¯¥ç ”ç©¶æå‡ºäº† SAMULE æ¡†æ¶ï¼Œæ—¨åœ¨è§£å†³å¤§è¯­è¨€æ¨¡å‹(LLM)æ™ºèƒ½ä½“åœ¨å¤æ‚ä»»åŠ¡ä¸­å› é”™è¯¯åˆ†æä¸è¶³å’Œè¿‡åº¦ä¾èµ–ç¨€ç¼ºæˆåŠŸè½¨è¿¹è€Œéš¾ä»¥ç”Ÿæˆæœ‰æ•ˆåæ€çš„é—®é¢˜ã€‚è¯¥æ¡†æ¶æ ¸å¿ƒåœ¨äºå¤šå±‚çº§åæ€åˆæˆ(Multi-Level Reflection Synthesis)æŠ€æœ¯ï¼Œåˆ†åˆ«ä»å¾®è§‚å±‚é¢çš„å•è½¨è¿¹å­¦ä¹ (Single-Trajectory Learning)çº é”™ã€ä¸­è§‚å±‚é¢çš„ä»»åŠ¡å†…å­¦ä¹ (Intra-Task Learning)æ„å»ºé”™è¯¯åˆ†ç±»ï¼Œä»¥åŠå®è§‚å±‚é¢çš„è·¨ä»»åŠ¡å­¦ä¹ (Inter-Task Learning)æå–å¯è¿ç§»è§è§£ã€‚ç ”ç©¶å›¢é˜Ÿé€šè¿‡å¾®è°ƒå›é¡¾æ€§æ¨¡å‹å¹¶å¼•å…¥å‰ç»æ€§åæ€æœºåˆ¶(foresight-based reflection)ï¼Œä½¿æ™ºèƒ½ä½“èƒ½å¤Ÿåœ¨æ¨ç†å’Œäº¤äº’è¿‡ç¨‹ä¸­ä¸»åŠ¨è¿›è¡Œè‡ªæˆ‘è°ƒæ•´ã€‚åœ¨ TravelPlannerã€NATURAL PLAN å’Œ Tau-bench ç­‰åŸºå‡†æµ‹è¯•ä¸­çš„å®éªŒç»“æœæ˜¾ç¤ºï¼ŒSAMULE çš„è¡¨ç°æ˜¾è‘—ä¼˜äºç°æœ‰çš„åŸºäºåæ€çš„åŸºçº¿æ¨¡å‹ã€‚è¯¥ç ”ç©¶è¯æ˜äº†ä»¥å¤±è´¥ä¸ºä¸­å¿ƒçš„å­¦ä¹ å’Œç³»ç»ŸåŒ–åæ€åˆæˆå¯¹äºæ„å»ºå…·å¤‡è‡ªæˆ‘è¿›åŒ–èƒ½åŠ›çš„ LLM æ™ºèƒ½ä½“è‡³å…³é‡è¦ã€‚",
      "categories": [
        "cs.AI"
      ],
      "primary_category": "cs.AI",
      "comment": "Accepted at EMNLP 2025 Main Conference",
      "pdf_url": "https://arxiv.org/pdf/2509.20562v1",
      "published_date": "2025-09-24 21:02:15 UTC",
      "updated_date": "2025-09-24 21:02:15 UTC",
      "processing_status": "completed",
      "attempts": 1,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "llm_backup_calls": 0,
      "last_update": "2026-01-24T20:46:45.692687+00:00"
    },
    {
      "arxiv_id": "2509.22720v1",
      "title": "LayoutAgent: A Vision-Language Agent Guided Compositional Diffusion for Spatial Layout Planning",
      "title_zh": "LayoutAgentï¼šè§†è§‰è¯­è¨€æ™ºèƒ½ä½“å¼•å¯¼çš„é¢å‘ç©ºé—´å¸ƒå±€è§„åˆ’çš„ç»„åˆæ‰©æ•£",
      "authors": [
        "Zezhong Fan",
        "Xiaohan Li",
        "Luyi Ma",
        "Kai Zhao",
        "Liang Peng",
        "Topojoy Biswas",
        "Evren Korpeoglu",
        "Kaushiki Nag",
        "Kannan Achan"
      ],
      "abstract": "Designing realistic multi-object scenes requires not only generating images, but also planning spatial layouts that respect semantic relations and physical plausibility. On one hand, while recent advances in diffusion models have enabled high-quality image generation, they lack explicit spatial reasoning, leading to unrealistic object layouts. On the other hand, traditional spatial planning methods in robotics emphasize geometric and relational consistency, but they struggle to capture semantic richness in visual scenes. To bridge this gap, in this paper, we propose LayoutAgent, an agentic framework that unifies vision-language reasoning with compositional diffusion for layout generation. Given multiple input images with target objects in them, our method first employs visual-language model to preprocess the inputs through segmentation, object size estimation, scene graph construction, and prompt rewriting. Then we leverage compositional diffusion-a method traditionally used in robotics-to synthesize bounding boxes that respect object relations encoded in the scene graph for spatial layouts. In the end, a foreground-conditioned image generator composes the complete scene by rendering the objects into the planned layout guided by designed prompts. Experiments demonstrate that LayoutAgent outperforms other state-of-the-art layout generation models in layout coherence, spatial realism and aesthetic alignment.",
      "tldr_zh": "è¯¥ç ”ç©¶é’ˆå¯¹å¤šå¯¹è±¡åœºæ™¯ç”Ÿæˆä¸­ç¼ºä¹ç©ºé—´æ¨ç†å¯¼è‡´å¸ƒå±€ä¸çœŸå®çš„é—®é¢˜ï¼Œæå‡ºäº†LayoutAgentï¼Œè¿™æ˜¯ä¸€ä¸ªå°†è§†è§‰è¯­è¨€æ¨ç†(vision-language reasoning)ä¸ç»„åˆæ‰©æ•£(compositional diffusion)ç›¸ç»“åˆçš„æ™ºèƒ½ä½“æ¡†æ¶ã€‚è¯¥æ¡†æ¶é¦–å…ˆåˆ©ç”¨è§†è§‰è¯­è¨€æ¨¡å‹(VLM)å¯¹è¾“å…¥è¿›è¡Œé¢„å¤„ç†ï¼ŒåŒ…æ‹¬å›¾åƒåˆ†å‰²(segmentation)ã€ç‰©ä½“å°ºå¯¸ä¼°è®¡(object size estimation)å’Œåœºæ™¯å›¾(scene graph)æ„å»ºã€‚éšåï¼Œç ”ç©¶å€Ÿé‰´æœºå™¨äººé¢†åŸŸçš„ç»„åˆæ‰©æ•£æ–¹æ³•ï¼Œæ ¹æ®åœºæ™¯å›¾ç¼–ç çš„ç‰©ä½“å…³ç³»åˆæˆç¬¦åˆç‰©ç†é€»è¾‘çš„è¾¹ç•Œæ¡†(bounding boxes)ä»¥è§„åˆ’ç©ºé—´å¸ƒå±€ã€‚æœ€åï¼Œé€šè¿‡å‰æ™¯è°ƒèŠ‚å›¾åƒç”Ÿæˆå™¨(foreground-conditioned image generator)å°†ç‰©ä½“æ¸²æŸ“åˆ°è§„åˆ’å¥½çš„å¸ƒå±€ä¸­ã€‚å®éªŒç»“æœè¡¨æ˜ï¼ŒLayoutAgentåœ¨å¸ƒå±€è¿è´¯æ€§(layout coherence)ã€ç©ºé—´çœŸå®æ„Ÿ(spatial realism)å’Œç¾å­¦å¯¹é½(aesthetic alignment)æ–¹é¢å‡ä¼˜äºç°æœ‰çš„å…ˆè¿›å¸ƒå±€ç”Ÿæˆæ¨¡å‹ã€‚",
      "categories": [
        "cs.CV",
        "cs.AI",
        "cs.LG"
      ],
      "primary_category": "cs.CV",
      "comment": "NeurIPS 2025 Workshop on SPACE in Vision, Language, and Embodied AI",
      "pdf_url": "https://arxiv.org/pdf/2509.22720v1",
      "published_date": "2025-09-24 20:41:04 UTC",
      "updated_date": "2025-09-24 20:41:04 UTC",
      "processing_status": "completed",
      "attempts": 1,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "llm_backup_calls": 0,
      "last_update": "2026-01-24T20:46:48.853716+00:00"
    },
    {
      "arxiv_id": "2509.20553v1",
      "title": "Perspectra: Choosing Your Experts Enhances Critical Thinking in Multi-Agent Research Ideation",
      "title_zh": "Perspectraï¼šé€šè¿‡è‡ªä¸»é€‰æ‹©ä¸“å®¶æå‡å¤šæ™ºèƒ½ä½“ç§‘ç ”æ„æ€ä¸­çš„æ‰¹åˆ¤æ€§æ€ç»´",
      "authors": [
        "Yiren Liu",
        "Viraj Shah",
        "Sangho Suh",
        "Pao Siangliulue",
        "Tal August",
        "Yun Huang"
      ],
      "abstract": "Recent advances in multi-agent systems (MAS) enable tools for information search and ideation by assigning personas to agents. However, how users can effectively control, steer, and critically evaluate collaboration among multiple domain-expert agents remains underexplored. We present Perspectra, an interactive MAS that visualizes and structures deliberation among LLM agents via a forum-style interface, supporting @-mention to invite targeted agents, threading for parallel exploration, with a real-time mind map for visualizing arguments and rationales. In a within-subjects study with 18 participants, we compared Perspectra to a group-chat baseline as they developed research proposals. Our findings show that Perspectra significantly increased the frequency and depth of critical-thinking behaviors, elicited more interdisciplinary replies, and led to more frequent proposal revisions than the group chat condition. We discuss implications for designing multi-agent tools that scaffold critical thinking by supporting user control over multi-agent adversarial discourse.",
      "tldr_zh": "è¯¥ç ”ç©¶æå‡ºäº† Perspectraï¼Œè¿™æ˜¯ä¸€ä¸ªäº¤äº’å¼çš„å¤šæ™ºèƒ½ä½“ç³»ç»Ÿ (Multi-agent systems, MAS)ï¼Œæ—¨åœ¨é€šè¿‡å¯è§†åŒ–å’Œç»“æ„åŒ–å¤§è¯­è¨€æ¨¡å‹ (LLM) æ™ºèƒ½ä½“ä¹‹é—´çš„è¾©è®ºæ¥å¢å¼ºç§‘ç ”æ„æ€ä¸­çš„æ‰¹åˆ¤æ€§æ€ç»´ã€‚è¯¥ç³»ç»Ÿé‡‡ç”¨äº†è®ºå›å¼ç•Œé¢ï¼Œæ”¯æŒé€šè¿‡ @-mention é‚€è¯·ç‰¹å®šä¸“å®¶ã€åˆ©ç”¨çº¿ç¨‹è¿›è¡Œå¹¶è¡Œæ¢ç´¢ï¼Œå¹¶ç»“åˆå®æ—¶æ€ç»´å¯¼å›¾å±•ç¤ºè®ºç‚¹ä¸ä¾æ®ã€‚é€šè¿‡å¯¹ 18 åå‚ä¸è€…è¿›è¡Œçš„å¯¹æ¯”ç ”ç©¶ (within-subjects study) è¡¨æ˜ï¼Œä¸ä¼ ç»Ÿçš„ç¾¤èŠ (group-chat) åŸºå‡†ç›¸æ¯”ï¼ŒPerspectra æ˜¾è‘—æå‡äº†æ‰¹åˆ¤æ€§æ€ç»´è¡Œä¸ºçš„é¢‘ç‡å’Œæ·±åº¦ã€‚å®éªŒç»“æœæ˜¾ç¤ºè¯¥ç³»ç»Ÿè¯±å‘äº†æ›´å¤šçš„è·¨å­¦ç§‘ (interdisciplinary) å›å¤ï¼Œå¹¶å¯¼è‡´äº†æ›´é¢‘ç¹çš„ç ”ç©¶ææ¡ˆä¿®æ”¹ã€‚è¯¥ç ”ç©¶ä¸ºè®¾è®¡èƒ½å¤Ÿæ”¯æŒç”¨æˆ·å¼•å¯¼å¤šæ™ºèƒ½ä½“å¯¹æŠ—æ€§è®ºè¿° (multi-agent adversarial discourse) å¹¶æœ‰æ•ˆè¾…åŠ©ç§‘ç ”æ„æ€çš„å·¥å…·æä¾›äº†é‡è¦è§è§£ã€‚",
      "categories": [
        "cs.HC",
        "cs.AI",
        "cs.CL"
      ],
      "primary_category": "cs.HC",
      "comment": "",
      "pdf_url": "https://arxiv.org/pdf/2509.20553v1",
      "published_date": "2025-09-24 20:39:06 UTC",
      "updated_date": "2025-09-24 20:39:06 UTC",
      "processing_status": "completed",
      "attempts": 1,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "llm_backup_calls": 0,
      "last_update": "2026-01-24T20:46:53.390728+00:00"
    },
    {
      "arxiv_id": "2509.20550v1",
      "title": "GraspFactory: A Large Object-Centric Grasping Dataset",
      "title_zh": "GraspFactoryï¼šå¤§è§„æ¨¡ä»¥ç‰©ä½“ä¸ºä¸­å¿ƒçš„æŠ“å–æ•°æ®é›†",
      "authors": [
        "Srinidhi Kalgundi Srinivas",
        "Yash Shukla",
        "Adam Arnold",
        "Sachin Chitta"
      ],
      "abstract": "Robotic grasping is a crucial task in industrial automation, where robots are increasingly expected to handle a wide range of objects. However, a significant challenge arises when robot grasping models trained on limited datasets encounter novel objects. In real-world environments such as warehouses or manufacturing plants, the diversity of objects can be vast, and grasping models need to generalize to this diversity. Training large, generalizable robot-grasping models requires geometrically diverse datasets. In this paper, we introduce GraspFactory, a dataset containing over 109 million 6-DoF grasps collectively for the Franka Panda (with 14,690 objects) and Robotiq 2F-85 grippers (with 33,710 objects). GraspFactory is designed for training data-intensive models, and we demonstrate the generalization capabilities of one such model trained on a subset of GraspFactory in both simulated and real-world settings. The dataset and tools are made available for download at https://graspfactory.github.io/.",
      "tldr_zh": "è¯¥ç ”ç©¶é’ˆå¯¹æœºå™¨äººæŠ“å–(Robotic grasping)åœ¨å·¥ä¸šè‡ªåŠ¨åŒ–ä¸­å› æ•°æ®é›†å—é™å¯¼è‡´æ¨¡å‹éš¾ä»¥æ³›åŒ–åˆ°æ–°ç‰©ä½“çš„éš¾é¢˜ï¼Œæ¨å‡ºäº†GraspFactoryï¼Œè¿™æ˜¯ä¸€ä¸ªå¤§è§„æ¨¡çš„ä»¥ç‰©ä½“ä¸ºä¸­å¿ƒçš„å¤šæ ·åŒ–æŠ“å–æ•°æ®é›†ã€‚è¯¥æ•°æ®é›†ä¸ºFranka Pandaæœºæ¢°è‡‚å’ŒRobotiq 2F-85æŠ“å–å™¨æä¾›äº†è¶…è¿‡1.09äº¿ä¸ª6-DoFæŠ“å–ä½å§¿ï¼Œæ¶µç›–äº†è¿‘äº”ä¸‡ä¸ªä¸åŒå‡ ä½•å½¢çŠ¶çš„ç‰©ä½“ã€‚GraspFactoryçš„è®¾è®¡åˆè¡·æ˜¯ä¸ºè®­ç»ƒæ•°æ®å¯†é›†å‹æ¨¡å‹æä¾›æ”¯æ’‘ï¼Œä½¿å…¶èƒ½å¤Ÿèƒœä»»ç°å®ä»“åº“æˆ–å·¥å‚ç¯å¢ƒä¸­å¤æ‚çš„ç‰©ä½“æŠ“å–ä»»åŠ¡ã€‚å®éªŒç»“æœè¡¨æ˜ï¼Œåœ¨è¯¥æ•°æ®é›†å­é›†ä¸Šè®­ç»ƒçš„æ¨¡å‹åœ¨ä»¿çœŸå’ŒçœŸå®åœºæ™¯ä¸­å‡å±•ç°å‡ºæå¼ºçš„æ³›åŒ–èƒ½åŠ›ã€‚è¯¥æ•°æ®é›†åŠå…¶ç›¸å…³å·¥å…·ç›®å‰å·²å¼€æºï¼Œæå¤§ä¸°å¯Œäº†æœºå™¨äººé€šç”¨æŠ“å–é¢†åŸŸçš„è®­ç»ƒèµ„æºã€‚",
      "categories": [
        "cs.RO",
        "cs.AI"
      ],
      "primary_category": "cs.RO",
      "comment": "",
      "pdf_url": "https://arxiv.org/pdf/2509.20550v1",
      "published_date": "2025-09-24 20:29:46 UTC",
      "updated_date": "2025-09-24 20:29:46 UTC",
      "processing_status": "completed",
      "attempts": 1,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "llm_backup_calls": 0,
      "last_update": "2026-01-24T20:47:08.858762+00:00"
    },
    {
      "arxiv_id": "2509.20549v1",
      "title": "Understanding and Improving Adversarial Robustness of Neural Probabilistic Circuits",
      "title_zh": "ç¥ç»æ¦‚ç‡ç”µè·¯å¯¹æŠ—é²æ£’æ€§çš„ç†è§£ä¸æå‡",
      "authors": [
        "Weixin Chen",
        "Han Zhao"
      ],
      "abstract": "Neural Probabilistic Circuits (NPCs), a new class of concept bottleneck models, comprise an attribute recognition model and a probabilistic circuit for reasoning. By integrating the outputs from these two modules, NPCs produce compositional and interpretable predictions. While offering enhanced interpretability and high performance on downstream tasks, the neural-network-based attribute recognition model remains a black box. This vulnerability allows adversarial attacks to manipulate attribute predictions by introducing carefully crafted subtle perturbations to input images, potentially compromising the final predictions. In this paper, we theoretically analyze the adversarial robustness of NPC and demonstrate that it only depends on the robustness of the attribute recognition model and is independent of the robustness of the probabilistic circuit. Moreover, we propose RNPC, the first robust neural probabilistic circuit against adversarial attacks on the recognition module. RNPC introduces a novel class-wise integration for inference, ensuring a robust combination of outputs from the two modules. Our theoretical analysis demonstrates that RNPC exhibits provably improved adversarial robustness compared to NPC. Empirical results on image classification tasks show that RNPC achieves superior adversarial robustness compared to existing concept bottleneck models while maintaining high accuracy on benign inputs.",
      "tldr_zh": "è¯¥ç ”ç©¶æ¢è®¨äº†ç¥ç»æ¦‚ç‡ç”µè·¯(Neural Probabilistic Circuits, NPCs)çš„å¯¹æŠ—é²æ£’æ€§(Adversarial Robustness)ï¼Œè¿™ç±»æ¨¡å‹é€šè¿‡æ•´åˆå±æ€§è¯†åˆ«æ¨¡å‹å’Œæ¦‚ç‡ç”µè·¯(Probabilistic Circuit)å®ç°å…·æœ‰ç»„åˆæ€§å’Œå¯è§£é‡Šæ€§çš„é¢„æµ‹ã€‚é’ˆå¯¹NPCä¸­ç¥ç»ç½‘ç»œè¯†åˆ«æ¨¡å—æ˜“å—å¯¹æŠ—æ”»å‡»(Adversarial Attacks)æ“çºµçš„é—®é¢˜ï¼Œè®ºæ–‡é€šè¿‡ç†è®ºåˆ†æè¯æ˜NPCçš„æ•´ä½“é²æ£’æ€§ä»…å–å†³äºè¯†åˆ«æ¨¡å‹ï¼Œè€Œä¸æ¦‚ç‡ç”µè·¯æ— å…³ã€‚åŸºäºæ­¤å‘ç°ï¼Œç ”ç©¶è€…æå‡ºäº†RNPCï¼Œè¿™æ˜¯é¦–ä¸ªé’ˆå¯¹è¯†åˆ«æ¨¡å—å¯¹æŠ—æ”»å‡»å…·æœ‰é²æ£’æ€§çš„ç¥ç»æ¦‚ç‡ç”µè·¯ã€‚RNPCå¼•å…¥äº†ä¸€ç§åˆ›æ–°çš„ç±»é—´é›†æˆ(Class-wise Integration)æ¨ç†æœºåˆ¶ï¼Œç¡®ä¿äº†ä¸¤ä¸ªæ¨¡å—è¾“å‡ºçš„ç¨³å¥ç»“åˆã€‚ç†è®ºåˆ†æä¸å›¾åƒåˆ†ç±»å®éªŒç»“æœä¸€è‡´è¡¨æ˜ï¼ŒRNPCåœ¨æ˜¾è‘—æå‡å¯¹æŠ—é²æ£’æ€§çš„åŒæ—¶ï¼Œåœ¨è‰¯æ€§è¾“å…¥(Benign Inputs)ä¸Šä¾ç„¶ä¿æŒäº†ä¼˜äºç°æœ‰æ¦‚å¿µç“¶é¢ˆæ¨¡å‹(Concept Bottleneck Models)çš„é«˜å‡†ç¡®ç‡ã€‚",
      "categories": [
        "cs.LG",
        "cs.AI"
      ],
      "primary_category": "cs.LG",
      "comment": "NeurIPS 2025 Camera Ready",
      "pdf_url": "https://arxiv.org/pdf/2509.20549v1",
      "published_date": "2025-09-24 20:25:17 UTC",
      "updated_date": "2025-09-24 20:25:17 UTC",
      "processing_status": "completed",
      "attempts": 1,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "llm_backup_calls": 0,
      "last_update": "2026-01-24T20:47:04.691328+00:00"
    },
    {
      "arxiv_id": "2509.20524v1",
      "title": "InstructVTON: Optimal Auto-Masking and Natural-Language-Guided Interactive Style Control for Inpainting-Based Virtual Try-On",
      "title_zh": "InstructVTONï¼šåŸºäºå›¾åƒä¿®å¤è™šæ‹Ÿè¯•ç©¿çš„ä¼˜åŒ–è‡ªåŠ¨æ©è†œä¸è‡ªç„¶è¯­è¨€å¼•å¯¼äº¤äº’å¼é£æ ¼æ§åˆ¶",
      "authors": [
        "Julien Han",
        "Shuwen Qiu",
        "Qi Li",
        "Xingzi Xu",
        "Mehmet Saygin Seyfioglu",
        "Kavosh Asadi",
        "Karim Bouyarmane"
      ],
      "abstract": "We present InstructVTON, an instruction-following interactive virtual try-on system that allows fine-grained and complex styling control of the resulting generation, guided by natural language, on single or multiple garments. A computationally efficient and scalable formulation of virtual try-on formulates the problem as an image-guided or image-conditioned inpainting task. These inpainting-based virtual try-on models commonly use a binary mask to control the generation layout. Producing a mask that yields desirable result is difficult, requires background knowledge, might be model dependent, and in some cases impossible with the masking-based approach (e.g. trying on a long-sleeve shirt with \"sleeves rolled up\" styling on a person wearing long-sleeve shirt with sleeves down, where the mask will necessarily cover the entire sleeve). InstructVTON leverages Vision Language Models (VLMs) and image segmentation models for automated binary mask generation. These masks are generated based on user-provided images and free-text style instructions. InstructVTON simplifies the end-user experience by removing the necessity of a precisely drawn mask, and by automating execution of multiple rounds of image generation for try-on scenarios that cannot be achieved with masking-based virtual try-on models alone. We show that InstructVTON is interoperable with existing virtual try-on models to achieve state-of-the-art results with styling control.",
      "tldr_zh": "è¯¥ç ”ç©¶æå‡ºäº†InstructVTONï¼Œä¸€ç§éµå¾ªæŒ‡ä»¤çš„äº¤äº’å¼è™šæ‹Ÿè¯•ç©¿(Virtual Try-On)ç³»ç»Ÿï¼Œæ”¯æŒé€šè¿‡è‡ªç„¶è¯­è¨€å¯¹å•ä»¶æˆ–å¤šä»¶æœè£…è¿›è¡Œç»†ç²’åº¦ä¸”å¤æ‚çš„é£æ ¼æ§åˆ¶ã€‚é’ˆå¯¹ä¼ ç»ŸåŸºäºå›¾åƒä¿®å¤(Inpainting-Based)çš„æ¨¡å‹åœ¨æ‰‹åŠ¨ç”Ÿæˆæ©ç (Binary Mask)æ–¹é¢çš„å›°éš¾åŠå…¶å¯¹å¤šæ ·åŒ–é€ å‹è¡¨è¾¾çš„é™åˆ¶ï¼ŒInstructVTONåˆ©ç”¨è§†è§‰è¯­è¨€æ¨¡å‹(VLMs)å’Œå›¾åƒåˆ†å‰²æ¨¡å‹ï¼Œæ ¹æ®ç”¨æˆ·å›¾åƒå’Œè‡ªç”±æ–‡æœ¬æŒ‡ä»¤è‡ªåŠ¨ç”Ÿæˆæœ€ä¼˜æ©ç ã€‚è¯¥ç³»ç»Ÿä¸ä»…æ¶ˆé™¤äº†ç²¾ç¡®ç»˜åˆ¶æ©ç çš„å¿…è¦æ€§ï¼Œè¿˜é€šè¿‡è‡ªåŠ¨åŒ–å¤šè½®å›¾åƒç”Ÿæˆï¼Œå®ç°äº†ä¼ ç»Ÿæ©ç æ–¹æ³•éš¾ä»¥å®Œæˆçš„å¦‚â€œå·èµ·è¢–å­â€ç­‰å¤æ‚äº¤äº’åœºæ™¯ã€‚å®éªŒè¡¨æ˜ï¼ŒInstructVTONèƒ½å¤Ÿä¸ç°æœ‰è™šæ‹Ÿè¯•ç©¿æ¨¡å‹ååŒå·¥ä½œï¼Œåœ¨æä¾›ç²¾å‡†é£æ ¼æ§åˆ¶çš„åŒæ—¶è¾¾åˆ°äº†å½“å‰æœ€å…ˆè¿›(State-of-the-Art)çš„è§†è§‰ç”Ÿæˆæ•ˆæœã€‚",
      "categories": [
        "cs.CV",
        "cs.AI"
      ],
      "primary_category": "cs.CV",
      "comment": "Submitted to CVPR 2025 and Published at CVPR 2025 AI for Content Creation workshop",
      "pdf_url": "https://arxiv.org/pdf/2509.20524v1",
      "published_date": "2025-09-24 19:52:40 UTC",
      "updated_date": "2025-09-24 19:52:40 UTC",
      "processing_status": "completed",
      "attempts": 1,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "llm_backup_calls": 0,
      "last_update": "2026-01-24T20:47:10.181129+00:00"
    },
    {
      "arxiv_id": "2509.20523v1",
      "title": "A Compound Classification System Based on Fuzzy Relations Applied to the Noise-Tolerant Control of a Bionic Hand via EMG Signal Recognition",
      "title_zh": "åŸºäºæ¨¡ç³Šå…³ç³»çš„ä»¿ç”Ÿæ‰‹è‚Œç”µè¯†åˆ«æŠ—å™ªæ§åˆ¶å¤åˆåˆ†ç±»ç³»ç»Ÿ",
      "authors": [
        "Pawel Trajdos",
        "Marek Kurzynski"
      ],
      "abstract": "Modern anthropomorphic upper limb bioprostheses are typically controlled by electromyographic (EMG) biosignals using a pattern recognition scheme. Unfortunately, there are many factors originating from the human source of objects to be classified and from the human-prosthesis interface that make it difficult to obtain an acceptable classification quality. One of these factors is the high susceptibility of biosignals to contamination, which can considerably reduce the quality of classification of a recognition system.\n  In the paper, the authors propose a new recognition system intended for EMG based control of the hand prosthesis with detection of contaminated biosignals in order to mitigate the adverse effect of contaminations. The system consists of two ensembles: the set of one-class classifiers (OCC) to assess the degree of contamination of individual channels and the ensemble of K-nearest neighbours (KNN) classifier to recognise the patient's intent. For all recognition systems, an original, coherent fuzzy model was developed, which allows the use of a uniform soft (fuzzy) decision scheme throughout the recognition process. The experimental evaluation was conducted using real biosignals from a public repository. The goal was to provide an experimental comparative analysis of the parameters and procedures of the developed method on which the quality of the recognition system depends. The proposed fuzzy recognition system was also compared with similar systems described in the literature.",
      "tldr_zh": "æœ¬ç ”ç©¶é’ˆå¯¹è‚Œç”µ(EMG)ç”Ÿç‰©ä¿¡å·åœ¨æ§åˆ¶ä»¿ç”Ÿæ‰‹è¿‡ç¨‹ä¸­ææ˜“å—æ±¡æŸ“å¹¶é™ä½è¯†åˆ«å‡†ç¡®ç‡çš„é—®é¢˜ï¼Œæå‡ºäº†ä¸€ç§åŸºäºæ¨¡ç³Šå…³ç³»(Fuzzy Relations)çš„å¤åˆåˆ†ç±»ç³»ç»Ÿï¼Œæ—¨åœ¨å®ç°æŠ—å™ªå£°æ§åˆ¶(Noise-tolerant control)ã€‚è¯¥ç³»ç»ŸåŒ…å«ä¸¤ä¸ªé›†æˆæ¨¡å—ï¼šä¸€ç»„ä¸€ç±»åˆ†ç±»å™¨(One-class classifiers, OCC)ç”¨äºæ£€æµ‹å„é€šé“ä¿¡å·çš„æ±¡æŸ“ç¨‹åº¦ï¼Œä»¥åŠä¸€ç»„K-æœ€è¿‘é‚»(K-nearest neighbours, KNN)åˆ†ç±»å™¨ç”¨äºè¯†åˆ«æ‚£è€…çš„åŠ¨ä½œæ„å›¾ã€‚ç ”ç©¶çš„æ ¸å¿ƒåœ¨äºå¼€å‘äº†ä¸€ä¸ªåŸåˆ›ä¸”è¿è´¯çš„æ¨¡ç³Šæ¨¡å‹(Fuzzy model)ï¼Œä½¿å¾—æ•´ä¸ªè¯†åˆ«æµç¨‹èƒ½é‡‡ç”¨ç»Ÿä¸€çš„è½¯å†³ç­–(Soft decision)æ–¹æ¡ˆã€‚é€šè¿‡ä½¿ç”¨å…¬å…±æ•°æ®é›†çš„çœŸå®ç”Ÿç‰©ä¿¡å·è¿›è¡Œå®éªŒè¯„ä¼°ï¼Œç ”ç©¶æ·±å…¥åˆ†æäº†å½±å“è¯†åˆ«è´¨é‡çš„å…³é”®å‚æ•°å’Œç¨‹åºã€‚å¯¹æ¯”å®éªŒç»“æœæ˜¾ç¤ºï¼Œè¯¥ç³»ç»Ÿåœ¨åº”å¯¹ä¿¡å·æ±¡æŸ“æ–¹é¢è¡¨ç°ä¼˜äºç°æœ‰çš„åŒç±»æŠ€æœ¯ï¼Œä¸ºæé«˜è‚Œç”µæ‰‹ä¹‰è‚¢åœ¨å¤æ‚ç¯å¢ƒä¸‹çš„å®ç”¨æ€§å¥ å®šäº†åŸºç¡€ã€‚",
      "categories": [
        "cs.AI",
        "cs.LG"
      ],
      "primary_category": "cs.AI",
      "comment": "",
      "pdf_url": "https://arxiv.org/pdf/2509.20523v1",
      "published_date": "2025-09-24 19:48:21 UTC",
      "updated_date": "2025-09-24 19:48:21 UTC",
      "processing_status": "completed",
      "attempts": 1,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "llm_backup_calls": 0,
      "last_update": "2026-01-24T20:47:10.480407+00:00"
    },
    {
      "arxiv_id": "2511.03728v1",
      "title": "Efficient On-Device Agents via Adaptive Context Management",
      "title_zh": "åŸºäºè‡ªé€‚åº”ä¸Šä¸‹æ–‡ç®¡ç†çš„é«˜æ•ˆç«¯ä¾§æ™ºèƒ½ä½“",
      "authors": [
        "Sanidhya Vijayvargiya",
        "Rahul Lokesh"
      ],
      "abstract": "On-device AI agents offer the potential for personalized, low-latency assistance, but their deployment is fundamentally constrained by limited memory capacity, which restricts usable context. This reduced practical context window creates a trade-off between supporting rich, stateful interactions with complex tool capabilities and maintaining on-device feasibility. We break this trade-off with a framework for context-efficient on-device agents, driven by three synergistic optimizations (1) a dynamic memory system using specialized LoRA adapters to distill conversational history into a compressed, and structured Context State Object; (2) a minimalist serialization format for tool schemas to minimize token overhead per tool; and (3) a just-in-time schema-passing mechanism that loads full tool definitions only upon tool selection. We instantiate this framework by adapting a 3B parameter SLM to context-efficient trajectories and rigorously evaluate it against a conventional baseline on complex user tasks. Our agent matches, or exceeds, the performance of a conventional baseline while dramatically compressing context, achieving more than a 6-fold reduction in initial system prompt context and a 10- to 25-fold reduction in context growth rate based on the interaction verbosity, demonstrating that strategic context management is key to unlocking capable and persistent on-device AI.",
      "tldr_zh": "è¯¥ç ”ç©¶é’ˆå¯¹ç«¯ä¾§ AI Agents å—é™äºæœ‰é™å†…å­˜å®¹é‡è€Œå¯¼è‡´ä¸Šä¸‹æ–‡çª—å£å—é™çš„é—®é¢˜ï¼Œæå‡ºäº†ä¸€ç§åŸºäº Adaptive Context Management çš„é«˜æ•ˆæ¡†æ¶ï¼Œæ—¨åœ¨å¹³è¡¡å¤æ‚äº¤äº’éœ€æ±‚ä¸è®¾å¤‡èµ„æºé™åˆ¶ã€‚è¯¥æ¡†æ¶åŒ…å«ä¸‰é¡¹æ ¸å¿ƒååŒä¼˜åŒ–ï¼šåˆ©ç”¨ LoRA é€‚é…å™¨å°†å¯¹è¯å†å²å‹ç¼©ä¸ºç»“æ„åŒ–çš„ Context State Object åŠ¨æ€å†…å­˜ç³»ç»Ÿï¼›é‡‡ç”¨æç®€åºåˆ—åŒ–æ ¼å¼æ˜¾è‘—é™ä½ Tool Schemas çš„ Token å¼€é”€ï¼›ä»¥åŠå¼•å…¥ Just-in-time æœºåˆ¶ä»…åœ¨å·¥å…·è°ƒç”¨æ—¶åŠ è½½å®Œæ•´å®šä¹‰ã€‚ç ”ç©¶äººå‘˜å°†è¯¥æ–¹æ¡ˆåº”ç”¨äº 3B å‚æ•°çš„ SLM æ¨¡å‹ï¼Œå¹¶åœ¨å¤æ‚ä»»åŠ¡ä¸­è¿›è¡Œäº†ä¸¥æ ¼è¯„ä¼°ã€‚å®éªŒç»“æœæ˜¾ç¤ºï¼Œè¯¥æ™ºèƒ½ä½“åœ¨æ€§èƒ½åŒ¹é…æˆ–è¶…è¶ŠåŸºçº¿æ¨¡å‹çš„åŒæ—¶ï¼Œå®ç°äº†åˆå§‹ç³»ç»Ÿæç¤ºè¯ 6 å€ä»¥ä¸Šçš„å‹ç¼©ã€‚æ­¤å¤–ï¼Œæ ¹æ®äº¤äº’å†—ä½™åº¦ä¸åŒï¼Œä¸Šä¸‹æ–‡å¢é•¿ç‡é™ä½äº† 10 åˆ° 25 å€ï¼Œå……åˆ†è¯æ˜äº†é«˜æ•ˆçš„ä¸Šä¸‹æ–‡ç®¡ç†å¯¹äºå®ç°æŒä¹…ä¸”å¼ºå¤§çš„ç«¯ä¾§ AI è‡³å…³é‡è¦ã€‚",
      "categories": [
        "cs.AI",
        "cs.LG"
      ],
      "primary_category": "cs.AI",
      "comment": "27 pages, 5 figures",
      "pdf_url": "https://arxiv.org/pdf/2511.03728v1",
      "published_date": "2025-09-24 19:46:50 UTC",
      "updated_date": "2025-09-24 19:46:50 UTC",
      "processing_status": "completed",
      "attempts": 1,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "llm_backup_calls": 0,
      "last_update": "2026-01-24T20:47:14.991651+00:00"
    },
    {
      "arxiv_id": "2509.20520v1",
      "title": "Adaptive Approach to Enhance Machine Learning Scheduling Algorithms During Runtime Using Reinforcement Learning in Metascheduling Applications",
      "title_zh": "å…ƒè°ƒåº¦åº”ç”¨ä¸­åˆ©ç”¨å¼ºåŒ–å­¦ä¹ åœ¨è¿è¡Œæ—¶å¢å¼ºæœºå™¨å­¦ä¹ è°ƒåº¦ç®—æ³•çš„è‡ªé€‚åº”æ–¹æ³•",
      "authors": [
        "Samer Alshaer",
        "Ala Khalifeh",
        "Roman Obermaisser"
      ],
      "abstract": "Metascheduling in time-triggered architectures has been crucial in adapting to dynamic and unpredictable environments, ensuring the reliability and efficiency of task execution. However, traditional approaches face significant challenges when training Artificial Intelligence (AI) scheduling inferences offline, particularly due to the complexities involved in constructing a comprehensive Multi-Schedule Graph (MSG) that accounts for all possible scenarios. The process of generating an MSG that captures the vast probability space, especially when considering context events like hardware failures, slack variations, or mode changes, is resource-intensive and often infeasible. To address these challenges, we propose an adaptive online learning unit integrated within the metascheduler to enhance performance in real-time. The primary motivation for developing this unit stems from the limitations of offline training, where the MSG created is inherently a subset of the complete space, focusing only on the most probable and critical context events. In the online mode, Reinforcement Learning (RL) plays a pivotal role by continuously exploring and discovering new scheduling solutions, thus expanding the MSG and enhancing system performance over time. This dynamic adaptation allows the system to handle unexpected events and complex scheduling scenarios more effectively. Several RL models were implemented within the online learning unit, each designed to address specific challenges in scheduling. These models not only facilitate the discovery of new solutions but also optimize existing schedulers, particularly when stricter deadlines or new performance criteria are introduced. By continuously refining the AI inferences through real-time training, the system remains flexible and capable of meeting evolving demands, thus ensuring robustness and efficiency in large-scale, safety-critical environments.",
      "tldr_zh": "è¯¥ç ”ç©¶é’ˆå¯¹æ—¶é—´è§¦å‘æ¶æ„ä¸­å…ƒè°ƒåº¦(Metascheduling)é¢ä¸´çš„æŒ‘æˆ˜ï¼Œæå‡ºäº†ä¸€ç§é›†æˆåœ¨å…ƒè°ƒåº¦å™¨ä¸­çš„è‡ªé€‚åº”åœ¨çº¿å­¦ä¹ å•å…ƒï¼Œæ—¨åœ¨è§£å†³ç¦»çº¿è®­ç»ƒAIæ¨ç†æ—¶éš¾ä»¥æ„å»ºæ¶µç›–æ‰€æœ‰æ½œåœ¨åœºæ™¯çš„å®Œæ•´å¤šè°ƒåº¦å›¾(Multi-Schedule Graph, MSG)çš„é—®é¢˜ã€‚è¯¥æ–¹æ¡ˆé€šè¿‡åœ¨è¿è¡Œæ—¶å¼•å…¥å¼ºåŒ–å­¦ä¹ (Reinforcement Learning, RL)ï¼Œä½¿ç³»ç»Ÿèƒ½å¤ŸæŒç»­æ¢ç´¢å¹¶å‘ç°æ–°çš„è°ƒåº¦è§£ï¼Œä»è€ŒåŠ¨æ€æ‰©å±•MSGå¹¶æå‡å®æ—¶æ€§èƒ½ã€‚è¿™ç§åŠ¨æ€è‡ªé€‚åº”æœºåˆ¶æ˜¾è‘—å¢å¼ºäº†ç³»ç»Ÿåº”å¯¹ç¡¬ä»¶æ•…éšœã€æ¾å¼›å˜åŒ–æˆ–æ¨¡å¼åˆ‡æ¢ç­‰ä¸å¯é¢„æµ‹äº‹ä»¶çš„èƒ½åŠ›ã€‚é€šè¿‡å®ç°å¤šç§RLæ¨¡å‹ï¼Œè¯¥å•å…ƒä¸ä»…èƒ½ä¼˜åŒ–ç°æœ‰è°ƒåº¦å™¨ä»¥æ»¡è¶³æ›´ä¸¥è‹›çš„æ€§èƒ½æŒ‡æ ‡ï¼Œè¿˜èƒ½é€šè¿‡å®æ—¶è®­ç»ƒæŒç»­æç‚¼AIæ¨ç†çš„å‡†ç¡®æ€§ã€‚æœ€ç»ˆï¼Œè¯¥æ–¹æ³•ç¡®ä¿äº†ç³»ç»Ÿåœ¨å¤§è§„æ¨¡ã€å®‰å…¨å…³é”®ç¯å¢ƒä¸‹å…·å¤‡é«˜åº¦çš„çµæ´»æ€§ã€é²æ£’æ€§å’Œæ‰§è¡Œæ•ˆç‡ã€‚",
      "categories": [
        "cs.AI",
        "cs.DC",
        "cs.LG"
      ],
      "primary_category": "cs.AI",
      "comment": "18 pages, 21 figures",
      "pdf_url": "https://arxiv.org/pdf/2509.20520v1",
      "published_date": "2025-09-24 19:46:22 UTC",
      "updated_date": "2025-09-24 19:46:22 UTC",
      "processing_status": "completed",
      "attempts": 1,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "llm_backup_calls": 0,
      "last_update": "2026-01-24T20:47:39.794152+00:00"
    },
    {
      "arxiv_id": "2509.20513v1",
      "title": "Reconstruction-Based Adaptive Scheduling Using AI Inferences in Safety-Critical Systems",
      "title_zh": "å®‰å…¨å…³é”®ç³»ç»Ÿä¸­åŸºäº AI æ¨ç†çš„é‡æ„å¼è‡ªé€‚åº”è°ƒåº¦",
      "authors": [
        "Samer Alshaer",
        "Ala Khalifeh",
        "Roman Obermaisser"
      ],
      "abstract": "Adaptive scheduling is crucial for ensuring the reliability and safety of time-triggered systems (TTS) in dynamic operational environments. Scheduling frameworks face significant challenges, including message collisions, locked loops from incorrect precedence handling, and the generation of incomplete or invalid schedules, which can compromise system safety and performance. To address these challenges, this paper presents a novel reconstruction framework designed to dynamically validate and assemble schedules. The proposed reconstruction models operate by systematically transforming AI-generated or heuristically derived scheduling priorities into fully executable schedules, ensuring adherence to critical system constraints such as precedence rules and collision-free communication. It incorporates robust safety checks, efficient allocation algorithms, and recovery mechanisms to handle unexpected context events, including hardware failures and mode transitions. Comprehensive experiments were conducted across multiple performance profiles, including makespan minimisation, workload balancing, and energy efficiency, to validate the operational effectiveness of the reconstruction models. Results demonstrate that the proposed framework significantly enhances system adaptability, operational integrity, and runtime performance while maintaining computational efficiency. Overall, this work contributes a practical and scalable solution to the problem of safe schedule generation in safety-critical TTS, enabling reliable and flexible real-time scheduling even under highly dynamic and uncertain operational conditions.",
      "tldr_zh": "è¯¥ç ”ç©¶æå‡ºäº†ä¸€ç§åŸºäºé‡æ„(Reconstruction-Based)çš„è‡ªé€‚åº”è°ƒåº¦æ¡†æ¶ï¼Œæ—¨åœ¨è§£å†³æ—¶é—´è§¦å‘ç³»ç»Ÿ(Time-Triggered Systems, TTS)åœ¨å®‰å…¨å…³é”®é¢†åŸŸä¸­é¢ä¸´çš„æ¶ˆæ¯ç¢°æ’ã€å¾ªç¯é”å®šä»¥åŠæ— æ•ˆè°ƒåº¦ç­‰æŒ‘æˆ˜ã€‚è¯¥æ¡†æ¶é€šè¿‡å°†äººå·¥æ™ºèƒ½ç”Ÿæˆçš„æ¨ç†(AI Inferences)æˆ–å¯å‘å¼ä¼˜å…ˆçº§ç³»ç»Ÿåœ°è½¬åŒ–ä¸ºå®Œå…¨å¯æ‰§è¡Œçš„è°ƒåº¦æ–¹æ¡ˆï¼Œç¡®ä¿ç³»ç»Ÿä¸¥æ ¼éµå®ˆä¼˜å…ˆçº§è§„åˆ™å’Œæ— ç¢°æ’é€šä¿¡ç­‰å…³é”®çº¦æŸã€‚ç³»ç»Ÿå†…éƒ¨é›†æˆäº†é²æ£’çš„å®‰å…¨æ£€æŸ¥ã€é«˜æ•ˆçš„åˆ†é…ç®—æ³•ä»¥åŠé’ˆå¯¹ç¡¬ä»¶æ•…éšœå’Œæ¨¡å¼åˆ‡æ¢çš„æ¢å¤æœºåˆ¶ï¼Œèƒ½å¤Ÿæœ‰æ•ˆåº”å¯¹åŠ¨æ€æ“ä½œç¯å¢ƒä¸­çš„ä¸ç¡®å®šæ€§ã€‚å®éªŒåœ¨å®Œå·¥æ—¶é—´(Makespan)æœ€å°åŒ–ã€è´Ÿè½½å‡è¡¡å’Œèƒ½æºæ•ˆç‡ç­‰å¤šä¸ªç»´åº¦éªŒè¯äº†é‡æ„æ¨¡å‹çš„æœ‰æ•ˆæ€§ï¼Œç»“æœè¡¨æ˜è¯¥æ–¹æ¡ˆæ˜¾è‘—æå‡äº†ç³»ç»Ÿçš„è‡ªé€‚åº”èƒ½åŠ›ã€è¿è¡Œå®Œæ•´æ€§å’Œè¿è¡Œæ•ˆç‡ã€‚æ€»ä½“è€Œè¨€ï¼Œè¿™é¡¹å·¥ä½œä¸ºå®‰å…¨å…³é”®å‹TTSæä¾›äº†ä¸€ç§å®ç”¨ä¸”å¯æ‰©å±•çš„è§£å†³æ–¹æ¡ˆï¼Œå³ä½¿åœ¨é«˜åº¦åŠ¨æ€å’Œä¸ç¡®å®šçš„æ¡ä»¶ä¸‹ä¹Ÿèƒ½å®ç°å¯é çš„å®æ—¶è°ƒåº¦ã€‚",
      "categories": [
        "cs.AI",
        "cs.DC"
      ],
      "primary_category": "cs.AI",
      "comment": "14 pages, 10 figures",
      "pdf_url": "https://arxiv.org/pdf/2509.20513v1",
      "published_date": "2025-09-24 19:38:43 UTC",
      "updated_date": "2025-09-24 19:38:43 UTC",
      "processing_status": "completed",
      "attempts": 1,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "llm_backup_calls": 0,
      "last_update": "2026-01-24T20:47:38.793918+00:00"
    },
    {
      "arxiv_id": "2509.20512v2",
      "title": "CHOIR: A Chatbot-mediated Organizational Memory Leveraging Communication in University Research Labs",
      "title_zh": "CHOIRï¼šåˆ©ç”¨é«˜æ ¡ç ”ç©¶å®éªŒå®¤æ²Ÿé€šçš„èŠå¤©æœºå™¨äººä»‹å¯¼ç»„ç»‡è®°å¿†",
      "authors": [
        "Sangwook Lee",
        "Adnan Abbas",
        "Yan Chen",
        "Young-Ho Kim",
        "Sang Won Lee"
      ],
      "abstract": "University research labs often rely on chat-based platforms for communication and project management, where valuable knowledge surfaces but is easily lost in message streams. Documentation can preserve knowledge, but it requires ongoing maintenance and is challenging to navigate. Drawing on formative interviews that revealed organizational memory challenges in labs, we designed CHOIR, an LLM-based chatbot that supports organizational memory through four key functions: document-grounded Q&A, Q&A sharing for follow-up discussion, knowledge extraction from conversations, and AI-assisted document updates. We deployed CHOIR in four research labs for one month (n=21), where the lab members asked 107 questions and lab directors updated documents 38 times in the organizational memory. Our findings reveal a privacy-awareness tension: questions were asked privately, limiting directors' visibility into documentation gaps. Students often avoided contribution due to challenges in generalizing personal experiences into universal documentation. We contribute design implications for privacy-preserving awareness and supporting context-specific knowledge documentation.",
      "tldr_zh": "æœ¬ç ”ç©¶é’ˆå¯¹å¤§å­¦ç§‘ç ”å®éªŒå®¤åœ¨å³æ—¶é€šè®¯å¹³å°ä¸­çŸ¥è¯†ç¢ç‰‡åŒ–ä¸”æ–‡æ¡£ç»´æŠ¤å›°éš¾çš„é—®é¢˜ï¼Œæå‡ºäº†CHOIRç³»ç»Ÿã€‚è¯¥ç³»ç»Ÿæ˜¯ä¸€æ¬¾åŸºäºå¤§è¯­è¨€æ¨¡å‹(LLM)çš„èŠå¤©æœºå™¨äººï¼Œæ—¨åœ¨é€šè¿‡åŸºäºæ–‡æ¡£çš„é—®ç­”(Document-grounded Q&A)ã€é—®ç­”å…±äº«è®¨è®ºã€å¯¹è¯çŸ¥è¯†æå–ä»¥åŠAIè¾…åŠ©æ–‡æ¡£æ›´æ–°å››é¡¹åŠŸèƒ½æ„å»ºç»„ç»‡è®°å¿†(Organizational Memory)ã€‚é€šè¿‡åœ¨å››ä¸ªå®éªŒå®¤è¿›è¡Œä¸ºæœŸä¸€ä¸ªæœˆçš„éƒ¨ç½²ï¼Œç ”ç©¶å‘ç°CHOIRèƒ½æœ‰æ•ˆä¿ƒè¿›çŸ¥è¯†é—®ç­”ä¸æ–‡æ¡£æ›´æ–°ï¼Œä½†ä¹Ÿæ­ç¤ºäº†éšç§æ„è¯†å†²çª(Privacy-awareness tension)ï¼Œå³å­¦ç”Ÿå€¾å‘äºç§ä¸‹æé—®ï¼Œå¯¼è‡´å®éªŒå®¤è´Ÿè´£äººéš¾ä»¥å‘ç°æ–‡æ¡£ç¼ºå£ã€‚åŒæ—¶ï¼Œç ”ç©¶æŒ‡å‡ºå­¦ç”Ÿåœ¨å°†ä¸ªäººç»éªŒè½¬åŒ–ä¸ºé€šç”¨æ–‡æ¡£æ—¶é¢ä¸´æŒ‘æˆ˜ï¼Œé™åˆ¶äº†çŸ¥è¯†çš„æ²‰æ·€ã€‚è¯¥ç ”ç©¶æœ€åä¸ºå¹³è¡¡éšç§ä¿æŠ¤ä¸å¢å¼ºæ„è¯†ï¼Œä»¥åŠæ”¯æŒç‰¹å®šè¯­å¢ƒçŸ¥è¯†æ–‡æ¡£åŒ–(Context-specific knowledge documentation)æä¾›äº†é‡è¦çš„è®¾è®¡å¯ç¤ºã€‚",
      "categories": [
        "cs.HC",
        "cs.AI"
      ],
      "primary_category": "cs.HC",
      "comment": "20 pages, 7 figures, 2 tables",
      "pdf_url": "https://arxiv.org/pdf/2509.20512v2",
      "published_date": "2025-09-24 19:35:28 UTC",
      "updated_date": "2025-12-07 18:31:12 UTC",
      "processing_status": "completed",
      "attempts": 1,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "llm_backup_calls": 0,
      "last_update": "2026-01-24T20:47:45.690372+00:00"
    },
    {
      "arxiv_id": "2509.20509v1",
      "title": "Complexity-Driven Policy Optimization",
      "title_zh": "å¤æ‚åº¦é©±åŠ¨çš„ç­–ç•¥ä¼˜åŒ–",
      "authors": [
        "Luca Serfilippi",
        "Giorgio Franceschelli",
        "Antonio Corradi",
        "Mirco Musolesi"
      ],
      "abstract": "Policy gradient methods often balance exploitation and exploration via entropy maximization. However, maximizing entropy pushes the policy towards a uniform random distribution, which represents an unstructured and sometimes inefficient exploration strategy. In this work, we propose replacing the entropy bonus with a more robust complexity bonus. In particular, we adopt a measure of complexity, defined as the product of Shannon entropy and disequilibrium, where the latter quantifies the distance from the uniform distribution. This regularizer encourages policies that balance stochasticity (high entropy) with structure (high disequilibrium), guiding agents toward regimes where useful, non-trivial behaviors can emerge. Such behaviors arise because the regularizer suppresses both extremes, e.g., maximal disorder and complete order, creating pressure for agents to discover structured yet adaptable strategies. Starting from Proximal Policy Optimization (PPO), we introduce Complexity-Driven Policy Optimization (CDPO), a new learning algorithm that replaces entropy with complexity. We show empirically across a range of discrete action space tasks that CDPO is more robust to the choice of the complexity coefficient than PPO is with the entropy coefficient, especially in environments requiring greater exploration.",
      "tldr_zh": "è¯¥ç ”ç©¶é’ˆå¯¹ç­–ç•¥æ¢¯åº¦æ–¹æ³• (Policy Gradient) ä¸­ä¼ ç»Ÿç†µæœ€å¤§åŒ– (Entropy Maximization) å¯¼è‡´æ¢ç´¢ç¼ºä¹ç»“æ„æ€§ä¸”æ•ˆç‡ä½ä¸‹çš„é—®é¢˜ï¼Œæå‡ºäº†å¤æ‚åº¦é©±åŠ¨ç­–ç•¥ä¼˜åŒ– (Complexity-Driven Policy Optimization, CDPO)ã€‚è¯¥ç®—æ³•åŸºäºè¿‘ç«¯ç­–ç•¥ä¼˜åŒ– (Proximal Policy Optimization, PPO)ï¼Œåˆ›æ–°æ€§åœ°å°†ç†µå¥–åŠ±æ›¿æ¢ä¸ºå¤æ‚åº¦å¥–åŠ± (Complexity Bonus)ï¼Œå…¶ä¸­å¤æ‚åº¦è¢«å®šä¹‰ä¸ºé¦™å†œç†µ (Shannon Entropy) ä¸è¡¡é‡åˆ†å¸ƒç»“æ„çš„éå¹³è¡¡åº¦ (Disequilibrium) çš„ä¹˜ç§¯ã€‚è¿™ç§æ­£åˆ™åŒ–æœºåˆ¶é€šè¿‡æŠ‘åˆ¶æå¤§æ— åºå’Œå®Œå…¨æœ‰åºçš„æç«¯çŠ¶æ€ï¼Œå¹³è¡¡äº†ç­–ç•¥çš„éšæœºæ€§ä¸ç»“æ„æ€§ï¼Œä»è€Œå¼•å¯¼æ™ºèƒ½ä½“å‘ç°æ›´å…·é€‚åº”æ€§çš„éå¹³å‡¡è¡Œä¸ºã€‚åœ¨å¤šé¡¹ç¦»æ•£åŠ¨ä½œç©ºé—´ä»»åŠ¡çš„å®éªŒä¸­ï¼ŒCDPO è¯æ˜äº†å…¶å¯¹ç³»æ•°é€‰æ‹©å…·æœ‰æ¯” PPO æ›´å¼ºçš„é²æ£’æ€§ï¼Œå°¤å…¶åœ¨éœ€è¦æ·±åº¦æ¢ç´¢çš„ç¯å¢ƒä¸­è¡¨ç°ä¼˜å¼‚ã€‚è¯¥ç ”ç©¶ä¸ºå¼ºåŒ–å­¦ä¹ ä¸­çš„é«˜æ•ˆæ¢ç´¢æä¾›äº†ä¸€ç§å…¨æ–°çš„ç»“æ„åŒ–å¼•å¯¼æ–¹æ¡ˆã€‚",
      "categories": [
        "cs.LG",
        "cs.AI"
      ],
      "primary_category": "cs.LG",
      "comment": "",
      "pdf_url": "https://arxiv.org/pdf/2509.20509v1",
      "published_date": "2025-09-24 19:32:03 UTC",
      "updated_date": "2025-09-24 19:32:03 UTC",
      "processing_status": "completed",
      "attempts": 1,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "llm_backup_calls": 0,
      "last_update": "2026-01-24T20:47:48.992556+00:00"
    },
    {
      "arxiv_id": "2509.20502v1",
      "title": "MARS: toward more efficient multi-agent collaboration for LLM reasoning",
      "title_zh": "MARSï¼šè¿ˆå‘æ›´é«˜æ•ˆçš„å¤§è¯­è¨€æ¨¡å‹æ¨ç†å¤šæ™ºèƒ½ä½“åä½œ",
      "authors": [
        "Xiao Wang",
        "Jia Wang",
        "Yijie Wang",
        "Pengtao Dang",
        "Sha Cao",
        "Chi Zhang"
      ],
      "abstract": "Large language models (LLMs) have achieved impressive results in natural language understanding, yet their reasoning capabilities remain limited when operating as single agents. Multi-Agent Debate (MAD) has been proposed to address this limitation by enabling collaborative reasoning among multiple models in a round-table debate manner. While effective, MAD introduces substantial computational overhead due to the number of agents involved and the frequent communication required. In this paper, we propose MARS (Multi-Agent Review System), a role-based collaboration framework inspired by the review process. In MARS, an author agent generates an initial solution, reviewer agents provide decisions and comments independently, and a meta-reviewer integrates the feedback to make the final decision and guide further revision. This design enhances reasoning quality while avoiding costly reviewer-to-reviewer interactions, thereby controlling token consumption and inference time. We compared MARS with both MAD and other state-of-the-art reasoning strategies across multiple benchmarks. Extensive experiments with different LLMs show that MARS matches the accuracy of MAD while reducing both token usage and inference time by approximately 50\\%. Code is available at https://github.com/xwang97/MARS.",
      "tldr_zh": "è¯¥ç ”ç©¶æå‡ºäº† MARS (Multi-Agent Review System)ï¼Œè¿™æ˜¯ä¸€ç§æ—¨åœ¨æå‡å¤§è¯­è¨€æ¨¡å‹ (LLMs) æ¨ç†æ•ˆç‡çš„åŸºäºè§’è‰²çš„å¤šæ™ºèƒ½ä½“åä½œæ¡†æ¶ã€‚é’ˆå¯¹ç°æœ‰æ–¹æ³•å¦‚ Multi-Agent Debate (MAD) å› é¢‘ç¹é€šä¿¡å’Œå¤æ‚äº¤äº’å¯¼è‡´çš„è®¡ç®—å¼€é”€è¿‡å¤§ã€æ¨ç†å»¶è¿Ÿé«˜ç­‰é—®é¢˜ï¼ŒMARS å€Ÿé‰´å­¦æœ¯è¯„å®¡æµç¨‹æ„å»ºäº†é«˜æ•ˆçš„åä½œæ‹“æ‰‘ã€‚è¯¥æ¡†æ¶ç”± Author agent ç”Ÿæˆåˆå§‹æ–¹æ¡ˆï¼ŒReviewer agents ç‹¬ç«‹æä¾›è¯„å®¡æ„è§ï¼Œæœ€åç”± Meta-reviewer æ•´åˆåé¦ˆå¹¶æŒ‡å¯¼æœ€ç»ˆä¿®è®¢ã€‚è¿™ç§è®¾è®¡é€šè¿‡æ¶ˆé™¤ Reviewer ä¹‹é—´çš„ç›´æ¥äº’åŠ¨ï¼Œæ˜¾è‘—é™ä½äº†è®¡ç®—èµ„æºçš„å†—ä½™æ¶ˆè€—ã€‚åœ¨å¤šä¸ªåŸºå‡†æµ‹è¯•ä¸Šçš„å®éªŒè¡¨æ˜ï¼ŒMARS åœ¨ä¿æŒä¸ MAD ç›¸å½“æ¨ç†å‡†ç¡®ç‡çš„åŒæ—¶ï¼ŒæˆåŠŸå°† Token ä½¿ç”¨é‡å’Œæ¨ç†è€—æ—¶é™ä½äº†çº¦ 50%ï¼Œä¸ºå®ç°æ›´å…·æˆæœ¬æ•ˆç›Šçš„å¤šæ™ºèƒ½ä½“ååŒæ¨ç†æä¾›äº†æœ‰æ•ˆæ–¹æ¡ˆã€‚",
      "categories": [
        "cs.CL",
        "cs.AI"
      ],
      "primary_category": "cs.CL",
      "comment": "",
      "pdf_url": "https://arxiv.org/pdf/2509.20502v1",
      "published_date": "2025-09-24 19:24:33 UTC",
      "updated_date": "2025-09-24 19:24:33 UTC",
      "processing_status": "completed",
      "attempts": 1,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "llm_backup_calls": 0,
      "last_update": "2026-01-24T20:47:55.493992+00:00"
    },
    {
      "arxiv_id": "2509.20499v1",
      "title": "Boosting Zero-Shot VLN via Abstract Obstacle Map-Based Waypoint Prediction with TopoGraph-and-VisitInfo-Aware Prompting",
      "title_zh": "é€šè¿‡åŸºäºæŠ½è±¡éšœç¢å›¾çš„èˆªç‚¹é¢„æµ‹ä¸æ‹“æ‰‘å›¾åŠè®¿é—®ä¿¡æ¯æ„ŸçŸ¥æç¤ºæå‡é›¶æ ·æœ¬è§†è§‰è¯­è¨€å¯¼èˆª",
      "authors": [
        "Boqi Li",
        "Siyuan Li",
        "Weiyi Wang",
        "Anran Li",
        "Zhong Cao",
        "Henry X. Liu"
      ],
      "abstract": "With the rapid progress of foundation models and robotics, vision-language navigation (VLN) has emerged as a key task for embodied agents with broad practical applications. We address VLN in continuous environments, a particularly challenging setting where an agent must jointly interpret natural language instructions, perceive its surroundings, and plan low-level actions. We propose a zero-shot framework that integrates a simplified yet effective waypoint predictor with a multimodal large language model (MLLM). The predictor operates on an abstract obstacle map, producing linearly reachable waypoints, which are incorporated into a dynamically updated topological graph with explicit visitation records. The graph and visitation information are encoded into the prompt, enabling reasoning over both spatial structure and exploration history to encourage exploration and equip MLLM with local path planning for error correction. Extensive experiments on R2R-CE and RxR-CE show that our method achieves state-of-the-art zero-shot performance, with success rates of 41% and 36%, respectively, outperforming prior state-of-the-art methods.",
      "tldr_zh": "è¯¥ç ”ç©¶é’ˆå¯¹è¿ç»­ç¯å¢ƒä¸‹çš„è§†è§‰è¯­è¨€å¯¼èˆª(VLN)æå‡ºäº†ä¸€ä¸ªé›¶æ ·æœ¬(zero-shot)æ¡†æ¶ï¼Œæ—¨åœ¨ååŒå¤„ç†è‡ªç„¶è¯­è¨€æŒ‡ä»¤ç†è§£ã€ç¯å¢ƒæ„ŸçŸ¥ä¸åº•å±‚åŠ¨ä½œè§„åˆ’ã€‚è¯¥æ¡†æ¶å°†åŸºäºæŠ½è±¡éšœç¢ç‰©åœ°å›¾(abstract obstacle map)çš„èˆªç‚¹é¢„æµ‹å™¨(waypoint predictor)ä¸å¤šæ¨¡æ€å¤§è¯­è¨€æ¨¡å‹(MLLM)ç›¸ç»“åˆï¼Œåˆ©ç”¨åŠ¨æ€æ›´æ–°çš„æ‹“æ‰‘å›¾(topological graph)å’Œæ˜¾å¼è®¿é—®è®°å½•(visitation records)è¿›è¡Œå¯¼èˆªã€‚é€šè¿‡å¼•å…¥æ‹“æ‰‘å›¾ä¸è®¿é—®ä¿¡æ¯æ„ŸçŸ¥(TopoGraph-and-VisitInfo-Aware)çš„æç¤ºè¯æŠ€æœ¯ï¼Œæ¨¡å‹èƒ½å¤Ÿå¯¹ç©ºé—´ç»“æ„å’Œæ¢ç´¢å†å²è¿›è¡Œæ·±åº¦æ¨ç†ï¼Œä»è€Œæå‡æ¢ç´¢æ•ˆç‡å¹¶å®ç°å±€éƒ¨è·¯å¾„è§„åˆ’çš„çº é”™ã€‚å®éªŒç»“æœæ˜¾ç¤ºï¼Œè¯¥æ–¹æ³•åœ¨R2R-CEå’ŒRxR-CEåŸºå‡†æµ‹è¯•ä¸­åˆ†åˆ«å–å¾—äº†41%å’Œ36%çš„æˆåŠŸç‡ï¼Œåˆ·æ–°äº†å½“å‰é›¶æ ·æœ¬VLNä»»åŠ¡çš„SOTAæ€§èƒ½ã€‚",
      "categories": [
        "cs.RO",
        "cs.AI"
      ],
      "primary_category": "cs.RO",
      "comment": "",
      "pdf_url": "https://arxiv.org/pdf/2509.20499v1",
      "published_date": "2025-09-24 19:21:39 UTC",
      "updated_date": "2025-09-24 19:21:39 UTC",
      "processing_status": "completed",
      "attempts": 1,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "llm_backup_calls": 0,
      "last_update": "2026-01-24T20:48:04.686771+00:00"
    },
    {
      "arxiv_id": "2509.20493v1",
      "title": "InsightGUIDE: An Opinionated AI Assistant for Guided Critical Reading of Scientific Literature",
      "title_zh": "InsightGUIDEï¼šç”¨äºç§‘å­¦æ–‡çŒ®å¼•å¯¼å¼æ‰¹åˆ¤æ€§é˜…è¯»çš„ä¸“ä¸šå‹ AI åŠ©æ‰‹",
      "authors": [
        "Paris Koloveas",
        "Serafeim Chatzopoulos",
        "Thanasis Vergoulis",
        "Christos Tryfonopoulos"
      ],
      "abstract": "The proliferation of scientific literature presents an increasingly significant challenge for researchers. While Large Language Models (LLMs) offer promise, existing tools often provide verbose summaries that risk replacing, rather than assisting, the reading of the source material. This paper introduces InsightGUIDE, a novel AI-powered tool designed to function as a reading assistant, not a replacement. Our system provides concise, structured insights that act as a \"map\" to a paper's key elements by embedding an expert's reading methodology directly into its core AI logic. We present the system's architecture, its prompt-driven methodology, and a qualitative case study comparing its output to a general-purpose LLM. The results demonstrate that InsightGUIDE produces more structured and actionable guidance, serving as a more effective tool for the modern researcher.",
      "tldr_zh": "è¯¥ç ”ç©¶é’ˆå¯¹ç§‘å­¦æ–‡çŒ®æ¿€å¢ä»¥åŠç°æœ‰ Large Language Models (LLMs) æ‘˜è¦è¿‡äºå†—é•¿ã€å®¹æ˜“æ›¿ä»£é˜…è¯»çš„é—®é¢˜ï¼Œæå‡ºäº† InsightGUIDE è¿™ä¸€ AI é©±åŠ¨çš„é˜…è¯»è¾…åŠ©å·¥å…·ã€‚è¯¥å·¥å…·çš„æ ¸å¿ƒé€»è¾‘åœ¨äºå°†ä¸“å®¶çš„é˜…è¯»æ–¹æ³•è®ºç›´æ¥åµŒå…¥åˆ°ç³»ç»Ÿä¸­ï¼Œé€šè¿‡æç¤ºé©±åŠ¨ (Prompt-driven) çš„æ¶æ„ï¼Œä¸ºè®ºæ–‡çš„å…³é”®è¦ç´ æä¾›ç»“æ„åŒ–çš„è§è§£ã€‚InsightGUIDE çš„è®¾è®¡åˆè¡·æ˜¯ä½œä¸ºç§‘ç ”äººå‘˜çš„è¾…åŠ©å·¥å…·è€Œéæ›¿ä»£å“ï¼Œæ—¨åœ¨é€šè¿‡æä¾›ç±»ä¼¼äºâ€œåœ°å›¾â€çš„ç»“æ„åŒ–æŒ‡å¼•æ¥å¼•å¯¼æ‰¹åˆ¤æ€§é˜…è¯»ã€‚å®šæ€§æ¡ˆä¾‹ç ”ç©¶å¯¹æ¯”æ˜¾ç¤ºï¼Œä¸é€šç”¨çš„ LLMs ç›¸æ¯”ï¼ŒInsightGUIDE èƒ½å¤Ÿç”Ÿæˆæ›´å…·ç»“æ„åŒ–ä¸”æ›´å…·å¯æ“ä½œæ€§çš„æŒ‡å¯¼å»ºè®®ã€‚å®éªŒç»“æœè¡¨æ˜ï¼Œè¯¥ç³»ç»Ÿèƒ½ä¸ºç°ä»£ç ”ç©¶äººå‘˜æä¾›æ›´æœ‰æ•ˆçš„æ–‡çŒ®é˜…è¯»æ”¯æŒã€‚",
      "categories": [
        "cs.AI",
        "cs.CL",
        "cs.DL",
        "cs.HC"
      ],
      "primary_category": "cs.AI",
      "comment": "Accepted for publication on ICTAI 2025",
      "pdf_url": "https://arxiv.org/pdf/2509.20493v1",
      "published_date": "2025-09-24 19:10:52 UTC",
      "updated_date": "2025-09-24 19:10:52 UTC",
      "processing_status": "completed",
      "attempts": 1,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "llm_backup_calls": 0,
      "last_update": "2026-01-24T20:48:02.891432+00:00"
    },
    {
      "arxiv_id": "2509.20491v1",
      "title": "AI-Specific Code Smells: From Specification to Detection",
      "title_zh": "AI ç‰¹æœ‰çš„ä»£ç å¼‚å‘³ï¼šä»è§„çº¦åˆ°æ£€æµ‹",
      "authors": [
        "Brahim Mahmoudi",
        "Naouel Moha",
        "Quentin StiÃ©venart",
        "Florent Avellaneda"
      ],
      "abstract": "The rise of Artificial Intelligence (AI) is reshaping how software systems are developed and maintained. However, AI-based systems give rise to new software issues that existing detection tools often miss. Among these, we focus on AI-specific code smells, recurring patterns in the code that may indicate deeper problems such as unreproducibility, silent failures, or poor model generalization. We introduce SpecDetect4AI, a tool-based approach for the specification and detection of these code smells at scale. This approach combines a high-level declarative Domain-Specific Language (DSL) for rule specification with an extensible static analysis tool that interprets and detects these rules for AI-based systems. We specified 22 AI-specific code smells and evaluated SpecDetect4AI on 826 AI-based systems (20M lines of code), achieving a precision of 88.66% and a recall of 88.89%, outperforming other existing detection tools. Our results show that SpecDetect4AI supports the specification and detection of AI-specific code smells through dedicated rules and can effectively analyze large AI-based systems, demonstrating both efficiency and extensibility (SUS 81.7/100).",
      "tldr_zh": "è¯¥ç ”ç©¶é’ˆå¯¹äººå·¥æ™ºèƒ½(AI)è½¯ä»¶ç³»ç»Ÿä¸­æ–°å‡ºç°çš„ä»£ç è´¨é‡é—®é¢˜ï¼Œé‡ç‚¹å…³æ³¨äº†å¯èƒ½å¯¼è‡´ä¸å¯å¤ç°æ€§ã€é™é»˜å¤±è´¥æˆ–æ¨¡å‹æ³›åŒ–èƒ½åŠ›å·®çš„AI-specific code smellsã€‚ä½œè€…æå‡ºäº†SpecDetect4AIï¼Œä¸€ç§ç”¨äºå¤§è§„æ¨¡è§„èŒƒåŒ–å’Œæ£€æµ‹è¿™äº›ä»£ç å¼‚å‘³çš„æ–¹æ³•ï¼Œè¯¥æ–¹æ³•ç»“åˆäº†ç”¨äºè§„åˆ™å®šä¹‰çš„å£°æ˜å¼Domain-Specific Language (DSL)å’Œèƒ½å¤Ÿè§£é‡Šå¹¶æ£€æµ‹AIç³»ç»Ÿè§„åˆ™çš„å¯æ‰©å±•é™æ€åˆ†æå·¥å…·ã€‚ç ”ç©¶äººå‘˜å®šä¹‰äº†22ç§AI-specific code smellsï¼Œå¹¶åœ¨åŒ…å«2000ä¸‡è¡Œä»£ç çš„826ä¸ªAIç³»ç»Ÿä¸­è¿›è¡Œäº†è¯„ä¼°ã€‚å®éªŒç»“æœæ˜¾ç¤ºï¼ŒSpecDetect4AIè¾¾åˆ°äº†88.66%çš„å‡†ç¡®ç‡(precision)å’Œ88.89%çš„å¬å›ç‡(recall)ï¼Œå…¶è¡¨ç°ä¼˜äºç°æœ‰çš„æ£€æµ‹å·¥å…·ã€‚æ­¤å¤–ï¼Œè¯¥ç³»ç»Ÿåœ¨å¯ç”¨æ€§é‡è¡¨(SUS)ä¸Šè·å¾—äº†81.7åˆ†ï¼Œè¯æ˜äº†å…¶åœ¨åˆ†æå¤§è§„æ¨¡AIç³»ç»Ÿæ—¶å…·å¤‡å‡ºè‰²çš„æ•ˆç‡ä¸å¯æ‰©å±•æ€§ã€‚",
      "categories": [
        "cs.SE",
        "cs.AI"
      ],
      "primary_category": "cs.SE",
      "comment": "",
      "pdf_url": "https://arxiv.org/pdf/2509.20491v1",
      "published_date": "2025-09-24 19:09:09 UTC",
      "updated_date": "2025-09-24 19:09:09 UTC",
      "processing_status": "completed",
      "attempts": 1,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "llm_backup_calls": 0,
      "last_update": "2026-01-24T20:48:07.545080+00:00"
    },
    {
      "arxiv_id": "2509.20489v1",
      "title": "CoSupFormer : A Contrastive Supervised learning approach for EEG signal Classification",
      "title_zh": "CoSupFormerï¼šä¸€ç§é¢å‘è„‘ç”µä¿¡å·åˆ†ç±»çš„å¯¹æ¯”ç›‘ç£å­¦ä¹ æ–¹æ³•",
      "authors": [
        "D. Darankoum",
        "C. Habermacher",
        "J. Volle",
        "S. Grudinin"
      ],
      "abstract": "Electroencephalography signals (EEGs) contain rich multi-scale information crucial for understanding brain states, with potential applications in diagnosing and advancing the drug development landscape. However, extracting meaningful features from raw EEG signals while handling noise and channel variability remains a major challenge. This work proposes a novel end-to-end deep-learning framework that addresses these issues through several key innovations. First, we designed an encoder capable of explicitly capturing multi-scale frequency oscillations covering a wide range of features for different EEG-related tasks. Secondly, to model complex dependencies and handle the high temporal resolution of EEGs, we introduced an attention-based encoder that simultaneously learns interactions across EEG channels and within localized {\\em patches} of individual channels. We integrated a dedicated gating network on top of the attention encoder to dynamically filter out noisy and non-informative channels, enhancing the reliability of EEG data. The entire encoding process is guided by a novel loss function, which leverages supervised and contrastive learning, significantly improving model generalization. We validated our approach in multiple applications, ranging from the classification of effects across multiple Central Nervous System (CNS) disorders treatments to the diagnosis of Parkinson's and Alzheimer's disease. Our results demonstrate that the proposed learning paradigm can extract biologically meaningful patterns from raw EEG signals across different species, autonomously select high-quality channels, and achieve robust generalization through innovative architectural and loss design.",
      "tldr_zh": "è¯¥ç ”ç©¶æå‡ºäº†CoSupFormerï¼Œä¸€ç§ç”¨äºEEGä¿¡å·åˆ†ç±»çš„ç«¯åˆ°ç«¯æ·±åº¦å­¦ä¹ æ¡†æ¶ï¼Œæ—¨åœ¨è§£å†³ä»åŸå§‹è„‘ç”µä¿¡å·ä¸­æå–ç‰¹å¾æ—¶é¢ä¸´çš„å™ªå£°å’Œé€šé“å˜å¼‚æ€§æŒ‘æˆ˜ã€‚è¯¥æ¡†æ¶è®¾è®¡äº†ä¸€ä¸ªèƒ½å¤Ÿæ˜¾å¼æ•è·å¤šå°ºåº¦é¢‘ç‡æŒ¯è¡çš„ç¼–ç å™¨ï¼Œå¹¶å¼•å…¥åŸºäºAttentionçš„æœºåˆ¶æ¥åŒæ—¶å­¦ä¹ é€šé“é—´äº¤äº’åŠå•é€šé“å±€éƒ¨Patchå†…çš„æ—¶åŸŸä¾èµ–ã€‚ä¸ºäº†å¢å¼ºæ•°æ®å¯é æ€§ï¼Œç ”ç©¶é›†æˆäº†ä¸€ä¸ªä¸“é—¨çš„é—¨æ§ç½‘ç»œï¼ˆGating Networkï¼‰æ¥åŠ¨æ€è¿‡æ»¤å™ªå£°å’Œæ— æ„ä¹‰é€šé“ã€‚æ•´ä¸ªç¼–ç è¿‡ç¨‹ç”±ä¸€ç§ç»“åˆäº†Supervisedå’ŒContrastive learningçš„æ–°å‹æŸå¤±å‡½æ•°å¼•å¯¼ï¼Œæ˜¾è‘—æå‡äº†æ¨¡å‹çš„æ³›åŒ–èƒ½åŠ›ã€‚åœ¨åŒ…æ‹¬ä¸­æ¢ç¥ç»ç³»ç»Ÿï¼ˆCNSï¼‰ç–¾ç—…æ²»ç–—åˆ†ç±»ä»¥åŠå¸•é‡‘æ£®ç—…å’Œé˜¿å°”èŒ¨æµ·é»˜ç—…è¯Šæ–­åœ¨å†…çš„å¤šé¡¹åº”ç”¨ä¸­ï¼ŒCoSupFormerå‡å±•ç°å‡ºä¼˜å¼‚çš„æ€§èƒ½ã€‚å®éªŒç»“æœè¯æ˜ï¼Œè¯¥èŒƒå¼èƒ½å¤Ÿè·¨ç‰©ç§æå–å…·æœ‰ç”Ÿç‰©å­¦æ„ä¹‰çš„æ¨¡å¼ï¼Œå¹¶èƒ½è‡ªä¸»é€‰æ‹©é«˜è´¨é‡é€šé“ï¼Œä¸ºç¥ç»ç§‘å­¦ç ”ç©¶å’Œè¯ç‰©å¼€å‘æä¾›äº†å¼ºå¤§çš„åˆ†æå·¥å…·ã€‚",
      "categories": [
        "cs.LG",
        "cs.AI"
      ],
      "primary_category": "cs.LG",
      "comment": "20 pages (14 pages Main text and 6 pages Supplementary Material)",
      "pdf_url": "https://arxiv.org/pdf/2509.20489v1",
      "published_date": "2025-09-24 19:04:12 UTC",
      "updated_date": "2025-09-24 19:04:12 UTC",
      "processing_status": "completed",
      "attempts": 1,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "llm_backup_calls": 0,
      "last_update": "2026-01-24T20:48:20.183519+00:00"
    },
    {
      "arxiv_id": "2510.00024v1",
      "title": "EpidemIQs: Prompt-to-Paper LLM Agents for Epidemic Modeling and Analysis",
      "title_zh": "EpidemIQsï¼šé¢å‘æµè¡Œç—…å»ºæ¨¡ä¸åˆ†æçš„â€œæç¤ºè¯åˆ°è®ºæ–‡â€å¤§è¯­è¨€æ¨¡å‹æ™ºèƒ½ä½“",
      "authors": [
        "Mohammad Hossein Samaei",
        "Faryad Darabi Sahneh",
        "Lee W. Cohnstaedt",
        "Caterina Scoglio"
      ],
      "abstract": "Large Language Models (LLMs) offer new opportunities to automate complex interdisciplinary research domains. Epidemic modeling, characterized by its complexity and reliance on network science, dynamical systems, epidemiology, and stochastic simulations, represents a prime candidate for leveraging LLM-driven automation. We introduce \\textbf{EpidemIQs}, a novel multi-agent LLM framework that integrates user inputs and autonomously conducts literature review, analytical derivation, network modeling, mechanistic modeling, stochastic simulations, data visualization and analysis, and finally documentation of findings in a structured manuscript. We introduced two types of agents: a scientist agent for planning, coordination, reflection, and generation of final results, and a task-expert agent to focus exclusively on one specific duty serving as a tool to the scientist agent. The framework consistently generated complete reports in scientific article format. Specifically, using GPT 4.1 and GPT 4.1 mini as backbone LLMs for scientist and task-expert agents, respectively, the autonomous process completed with average total token usage 870K at a cost of about \\$1.57 per study, achieving a 100\\% completion success rate through our experiments. We evaluate EpidemIQs across different epidemic scenarios, measuring computational cost, completion success rate, and AI and human expert reviews of generated reports. We compare EpidemIQs to the single-agent LLM, which has the same system prompts and tools, iteratively planning, invoking tools, and revising outputs until task completion. The comparison shows consistently higher performance of the proposed framework across five different scenarios. EpidemIQs represents a step forward in accelerating scientific research by significantly reducing costs and turnaround time of discovery processes, and enhancing accessibility to advanced modeling tools.",
      "tldr_zh": "è¯¥ç ”ç©¶æå‡ºäº† EpidemIQsï¼Œä¸€ç§æ—¨åœ¨å®ç°æµè¡Œç—…å»ºæ¨¡ä¸åˆ†æè‡ªåŠ¨åŒ–çš„å¤šæ™ºèƒ½ä½“ (multi-agent) å¤§è¯­è¨€æ¨¡å‹ (LLM) æ¡†æ¶ã€‚è¯¥æ¡†æ¶é›†æˆäº†æ–‡çŒ®ç»¼è¿°ã€è§£ææ¨å¯¼ã€ç½‘ç»œä¸æœºåˆ¶å»ºæ¨¡ (network/mechanistic modeling)ã€éšæœºæ¨¡æ‹Ÿä»¥åŠæ•°æ®å¯è§†åŒ–åˆ†æç­‰åŠŸèƒ½ï¼Œèƒ½å¤Ÿæ ¹æ®ç”¨æˆ·è¾“å…¥è‡ªä¸»ç”Ÿæˆç»“æ„åŒ–çš„ç ”ç©¶æ‰‹ç¨¿ã€‚ç³»ç»Ÿç»“æ„ç”±è´Ÿè´£å…¨å±€è§„åˆ’ä¸åè°ƒçš„ç§‘å­¦å®¶æ™ºèƒ½ä½“ (scientist agent) å’Œä¸“æ³¨äºç‰¹å®šå·¥å…·ä½¿ç”¨çš„ä»»åŠ¡ä¸“å®¶æ™ºèƒ½ä½“ (task-expert agent) ååŒæ„æˆã€‚å®éªŒè¯„ä¼°æ˜¾ç¤ºï¼ŒEpidemIQs åœ¨å¤šç§æµè¡Œç—…åœºæ™¯ä¸‹å‡å®ç°äº† 100% çš„ä»»åŠ¡å®Œæˆç‡ï¼Œä¸”å•æ¬¡ç ”ç©¶çš„å¹³å‡æˆæœ¬ä»…çº¦ä¸º 1.57 ç¾å…ƒã€‚å¯¹æ¯”æµ‹è¯•è¯æ˜ï¼Œè¯¥æ¡†æ¶åœ¨æ€§èƒ½ä¸Šæ˜¾è‘—ä¼˜äºå…·æœ‰ç›¸åŒæç¤ºè¯çš„å•æ™ºèƒ½ä½“ (single-agent) æ¨¡å‹ã€‚è¿™é¡¹å·¥ä½œé€šè¿‡å¤§å¹…é™ä½ç ”ç©¶æˆæœ¬å’Œç¼©çŸ­å‘¨æœŸï¼Œä¸ºåŠ é€Ÿç§‘å­¦å‘ç°ä»¥åŠæé«˜å¤æ‚å»ºæ¨¡å·¥å…·çš„å¯è®¿é—®æ€§æä¾›äº†æœ‰åŠ›æ”¯æŒã€‚",
      "categories": [
        "cs.SI",
        "cs.AI"
      ],
      "primary_category": "cs.SI",
      "comment": "",
      "pdf_url": "https://arxiv.org/pdf/2510.00024v1",
      "published_date": "2025-09-24 18:54:56 UTC",
      "updated_date": "2025-09-24 18:54:56 UTC",
      "processing_status": "completed",
      "attempts": 1,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "llm_backup_calls": 0,
      "last_update": "2026-01-24T20:48:20.571089+00:00"
    },
    {
      "arxiv_id": "2509.20481v1",
      "title": "Shared Neural Space: Unified Precomputed Feature Encoding for Multi-Task and Cross Domain Vision",
      "title_zh": "Shared Neural Spaceï¼šé¢å‘å¤šä»»åŠ¡ä¸è·¨åŸŸè§†è§‰çš„ç»Ÿä¸€é¢„è®¡ç®—ç‰¹å¾ç¼–ç ",
      "authors": [
        "Jing Li",
        "Oskar Bartosz",
        "Chengyu Wang",
        "Michal Wnuczynski",
        "Dilshan Godaliyadda",
        "Michael Polley"
      ],
      "abstract": "The majority of AI models in imaging and vision are customized to perform on specific high-precision task. However, this strategy is inefficient for applications with a series of modular tasks, since each requires a mapping into a disparate latent domain. To address this inefficiency, we proposed a universal Neural Space (NS), where an encoder-decoder framework pre-computes features across vision and imaging tasks. Our encoder learns transformation aware, generalizable representations, which enable multiple downstream AI modules to share the same feature space. This architecture reduces redundancy, improves generalization across domain shift, and establishes a foundation for effecient multi-task vision pipelines. Furthermore, as opposed to larger transformer backbones, our backbone is lightweight and CNN-based, allowing for wider across hardware. We furthur demonstrate that imaging and vision modules, such as demosaicing, denoising, depth estimation and semantic segmentation can be performed efficiently in the NS.",
      "tldr_zh": "é’ˆå¯¹å½“å‰å½±åƒå’Œè§†è§‰é¢†åŸŸä¸­ AI æ¨¡å‹é€šå¸¸ä»…é’ˆå¯¹ç‰¹å®šä»»åŠ¡å®šåˆ¶ã€å¯¼è‡´å¤šä»»åŠ¡åº”ç”¨æ•ˆç‡ä½ä¸‹çš„é—®é¢˜ï¼Œè¯¥ç ”ç©¶æå‡ºäº† Shared Neural Space (NS) æ¡†æ¶ã€‚è¯¥æ¡†æ¶é‡‡ç”¨ encoder-decoder ç»“æ„ï¼Œé€šè¿‡ encoder é¢„è®¡ç®—è·¨è§†è§‰å’Œæˆåƒä»»åŠ¡çš„ç‰¹å¾ï¼Œå­¦ä¹ å…·æœ‰ transformation aware ç‰¹æ€§ä¸”æ³›åŒ–èƒ½åŠ›å¼ºçš„è¡¨ç¤ºã€‚è¿™ä½¿å¾—å¤šä¸ªä¸‹æ¸¸ AI æ¨¡å—èƒ½å¤Ÿå…±äº«åŒä¸€ä¸ªç‰¹å¾ç©ºé—´ï¼Œæ˜¾è‘—å‡å°‘äº†è®¡ç®—å†—ä½™ï¼Œå¹¶å¢å¼ºäº†åœ¨è·¨ domain shift åœºæ™¯ä¸‹çš„æ³›åŒ–æ€§èƒ½ã€‚ç›¸æ¯”äºåºå¤§çš„ Transformer éª¨å¹²ç½‘ç»œï¼Œè¯¥ç ”ç©¶é‡‡ç”¨è½»é‡åŒ–çš„ CNN-based æ¶æ„ï¼Œä»è€Œæé«˜äº†åœ¨ä¸åŒç¡¬ä»¶è®¾å¤‡ä¸Šçš„é€‚ç”¨æ€§ã€‚å®éªŒè¯æ˜ï¼Œdemosaicingã€denoisingã€depth estimation å’Œ semantic segmentation ç­‰æˆåƒä¸è§†è§‰ä»»åŠ¡å‡èƒ½åœ¨ NS ä¸­é«˜æ•ˆè¿è¡Œï¼Œä¸ºæ„å»ºé«˜æ•ˆçš„å¤šä»»åŠ¡è§†è§‰æµæ°´çº¿å¥ å®šäº†åŸºç¡€ã€‚",
      "categories": [
        "cs.CV",
        "cs.AI"
      ],
      "primary_category": "cs.CV",
      "comment": "",
      "pdf_url": "https://arxiv.org/pdf/2509.20481v1",
      "published_date": "2025-09-24 18:48:58 UTC",
      "updated_date": "2025-09-24 18:48:58 UTC",
      "processing_status": "completed",
      "attempts": 1,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "llm_backup_calls": 0,
      "last_update": "2026-01-24T20:48:32.670483+00:00"
    },
    {
      "arxiv_id": "2509.20354v3",
      "title": "EmbeddingGemma: Powerful and Lightweight Text Representations",
      "title_zh": "EmbeddingGemmaï¼šå¼ºå¤§ä¸”è½»é‡çº§çš„æ–‡æœ¬è¡¨ç¤º",
      "authors": [
        "Henrique Schechter Vera",
        "Sahil Dua",
        "Biao Zhang",
        "Daniel Salz",
        "Ryan Mullins",
        "Sindhu Raghuram Panyam",
        "Sara Smoot",
        "Iftekhar Naim",
        "Joe Zou",
        "Feiyang Chen",
        "Daniel Cer",
        "Alice Lisak",
        "Min Choi",
        "Lucas Gonzalez",
        "Omar Sanseviero",
        "Glenn Cameron",
        "Ian Ballantyne",
        "Kat Black",
        "Kaifeng Chen",
        "Weiyi Wang",
        "Zhe Li",
        "Gus Martins",
        "Jinhyuk Lee",
        "Mark Sherwood",
        "Juyeong Ji",
        "Renjie Wu",
        "Jingxiao Zheng",
        "Jyotinder Singh",
        "Abheesht Sharma",
        "Divyashree Sreepathihalli",
        "Aashi Jain",
        "Adham Elarabawy",
        "AJ Co",
        "Andreas Doumanoglou",
        "Babak Samari",
        "Ben Hora",
        "Brian Potetz",
        "Dahun Kim",
        "Enrique Alfonseca",
        "Fedor Moiseev",
        "Feng Han",
        "Frank Palma Gomez",
        "Gustavo HernÃ¡ndez Ãbrego",
        "Hesen Zhang",
        "Hui Hui",
        "Jay Han",
        "Karan Gill",
        "Ke Chen",
        "Koert Chen",
        "Madhuri Shanbhogue",
        "Michael Boratko",
        "Paul Suganthan",
        "Sai Meher Karthik Duddu",
        "Sandeep Mariserla",
        "Setareh Ariafar",
        "Shanfeng Zhang",
        "Shijie Zhang",
        "Simon Baumgartner",
        "Sonam Goenka",
        "Steve Qiu",
        "Tanmaya Dabral",
        "Trevor Walker",
        "Vikram Rao",
        "Waleed Khawaja",
        "Wenlei Zhou",
        "Xiaoqi Ren",
        "Ye Xia",
        "Yichang Chen",
        "Yi-Ting Chen",
        "Zhe Dong",
        "Zhongli Ding",
        "Francesco Visin",
        "GaÃ«l Liu",
        "Jiageng Zhang",
        "Kathleen Kenealy",
        "Michelle Casbon",
        "Ravin Kumar",
        "Thomas Mesnard",
        "Zach Gleicher",
        "Cormac Brick",
        "Olivier Lacombe",
        "Adam Roberts",
        "Qin Yin",
        "Yunhsuan Sung",
        "Raphael Hoffmann",
        "Tris Warkentin",
        "Armand Joulin",
        "Tom Duerig",
        "Mojtaba Seyedhosseini"
      ],
      "abstract": "We introduce EmbeddingGemma, a new lightweight, open text embedding model based on the Gemma 3 language model family. Our innovative training recipe strategically captures knowledge from larger models via encoder-decoder initialization and geometric embedding distillation. We improve model robustness and expressiveness with a spread-out regularizer, and ensure generalizability by merging checkpoints from varied, optimized mixtures. Evaluated on the Massive Text Embedding Benchmark (MTEB) across multilingual, English, and code domains, EmbeddingGemma (300M) achieves state-of-the-art results. Notably, it outperforms prior top models, both proprietary and open, with fewer than 500M parameters, and provides performance comparable to models double its size, offering an exceptional performance-to-cost ratio. Remarkably, this lead persists when quantizing model weights or truncating embedding outputs. This makes EmbeddingGemma particularly well-suited for low-latency and high-throughput use cases such as on-device applications. We provide ablation studies exploring our key design choices. We release EmbeddingGemma to the community to promote further research.",
      "tldr_zh": "è¯¥ç ”ç©¶æ¨å‡ºäº† EmbeddingGemmaï¼Œè¿™æ˜¯ä¸€ä¸ªåŸºäº Gemma 3 è¯­è¨€æ¨¡å‹ç³»åˆ—çš„å…¨æ–°è½»é‡çº§ã€å¼€æºæ–‡æœ¬åµŒå…¥æ¨¡å‹ã€‚è¯¥æ¨¡å‹åœ¨è®­ç»ƒä¸­é€šè¿‡ Encoder-Decoder åˆå§‹åŒ–å’Œå‡ ä½•åµŒå…¥è’¸é¦(Geometric Embedding Distillation)ä»å¤§å‹æ¨¡å‹ä¸­æ•è·çŸ¥è¯†ï¼Œå¹¶å¼•å…¥æ‰©å±•æ­£åˆ™åŒ–å™¨(Spread-out Regularizer)ä¸æ£€æŸ¥ç‚¹åˆå¹¶æŠ€æœ¯ä»¥æå‡é²æ£’æ€§ä¸æ³›åŒ–èƒ½åŠ›ã€‚åœ¨å¤šè¯­è¨€ã€è‹±è¯­å’Œä»£ç é¢†åŸŸçš„ MTEB åŸºå‡†æµ‹è¯•ä¸­ï¼Œä»…æ‹¥æœ‰ 300M å‚æ•°çš„ EmbeddingGemma å–å¾—äº†æœ€å…ˆè¿›(SOTA)çš„ç»“æœã€‚å…¶å®æµ‹è¡¨ç°ä¼˜äºè®¸å¤šå‚æ•°é‡å°‘äº 500M çš„é¡¶å°–æ¨¡å‹ï¼Œç”šè‡³èƒ½ä¸ä¸¤å€äºå…¶è§„æ¨¡çš„æ¨¡å‹ç›¸åª²ç¾ï¼Œå…·æœ‰æé«˜çš„æ€§ä»·æ¯”ã€‚æ­¤å¤–ï¼Œè¯¥æ¨¡å‹åœ¨æƒé‡é‡åŒ–æˆ–åµŒå…¥è¾“å‡ºæˆªæ–­æ—¶ä»èƒ½ä¿æŒå“è¶Šæ€§èƒ½ï¼Œä½¿å…¶ç‰¹åˆ«é€‚ç”¨äºç«¯ä¾§è®¾å¤‡ç­‰ä½å»¶è¿Ÿã€é«˜ååé‡çš„åº”ç”¨åœºæ™¯ã€‚",
      "categories": [
        "cs.CL",
        "cs.AI"
      ],
      "primary_category": "cs.CL",
      "comment": "18 pages. Models are available in HuggingFace (at https://huggingface.co/collections/google/embeddinggemma-68b9ae3a72a82f0562a80dc4), Kaggle (at https://www.kaggle.com/models/google/embeddinggemma/), and Vertex AI (at https://pantheon.corp.google.com/vertex-ai/publishers/google/model-garden/embeddinggemma)",
      "pdf_url": "https://arxiv.org/pdf/2509.20354v3",
      "published_date": "2025-09-24 17:56:51 UTC",
      "updated_date": "2025-11-01 23:38:27 UTC",
      "processing_status": "completed",
      "attempts": 1,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "llm_backup_calls": 0,
      "last_update": "2026-01-24T20:48:41.178337+00:00"
    },
    {
      "arxiv_id": "2509.20341v1",
      "title": "Morphological Synthesizer for Ge'ez Language: Addressing Morphological Complexity and Resource Limitations",
      "title_zh": "Ge'ez è¯­å½¢æ€åˆæˆå™¨ï¼šåº”å¯¹å½¢æ€å¤æ‚æ€§ä¸èµ„æºé™åˆ¶",
      "authors": [
        "Gebrearegawi Gebremariam",
        "Hailay Teklehaymanot",
        "Gebregewergs Mezgebe"
      ],
      "abstract": "Ge'ez is an ancient Semitic language renowned for its unique alphabet. It serves as the script for numerous languages, including Tigrinya and Amharic, and played a pivotal role in Ethiopia's cultural and religious development during the Aksumite kingdom era. Ge'ez remains significant as a liturgical language in Ethiopia and Eritrea, with much of the national identity documentation recorded in Ge'ez. These written materials are invaluable primary sources for studying Ethiopian and Eritrean philosophy, creativity, knowledge, and civilization. Ge'ez has a complex morphological structure with rich inflectional and derivational morphology, and no usable NLP has been developed and published until now due to the scarcity of annotated linguistic data, corpora, labeled datasets, and lexicons. Therefore, we propose a rule-based Ge'ez morphological synthesizer to generate surface words from root words according to the morphological structures of the language. We used 1,102 sample verbs, representing all verb morphological structures, to test and evaluate the system. The system achieves a performance of 97.4%, outperforming the baseline model and suggesting that future work should build a comprehensive system considering morphological variations of the language.\n  Keywords: Ge'ez, NLP, morphology, morphological synthesizer, rule-based",
      "tldr_zh": "è¯¥ç ”ç©¶é’ˆå¯¹ Ge'ez è¿™ä¸€å…·æœ‰å¤æ‚å½¢æ€ç»“æ„ä¸”èµ„æºåŒ®ä¹çš„å¤å¡å§†è¯­ (Semitic language)ï¼Œæå‡ºäº†ä¸€ç§åŸºäºè§„åˆ™ (rule-based) çš„å½¢æ€åˆæˆå™¨ (morphological synthesizer)ï¼Œæ—¨åœ¨è§£å†³å› æ ‡æ³¨æ•°æ®å’Œè¯å…¸ç¨€ç¼ºå¯¼è‡´çš„è‡ªç„¶è¯­è¨€å¤„ç† (NLP) å‘å±•æ»åé—®é¢˜ã€‚è¯¥ç³»ç»Ÿåˆ©ç”¨æ¶µç›–æ‰€æœ‰åŠ¨è¯å½¢æ€ç»“æ„çš„ 1,102 ä¸ªæ ·æœ¬åŠ¨è¯è¿›è¡Œæµ‹è¯•ï¼Œèƒ½å¤Ÿæ ¹æ®è¯­è¨€çš„å½¢æ€è§„åˆ™ä»è¯æ ¹ç²¾ç¡®ç”Ÿæˆè¡¨é¢è¯æ±‡ã€‚å®éªŒç»“æœæ˜¾ç¤ºï¼Œè¯¥ç³»ç»Ÿçš„æ€§èƒ½è¾¾åˆ° 97.4%ï¼Œæ˜¾è‘—ä¼˜äºåŸºçº¿æ¨¡å‹ï¼Œè¯æ˜äº†å…¶åœ¨å¤„ç†å¤æ‚å½¢æ€å˜åŒ–æ–¹é¢çš„æœ‰æ•ˆæ€§ã€‚è¿™é¡¹ç ”ç©¶ä¸ä»…ä¸º Ge'ez è¯­è¨€çš„æ•°å­—èµ„æºåŒ–æä¾›äº†æ ¸å¿ƒå·¥å…·ï¼Œä¹Ÿä¸ºæœªæ¥å¼€å‘æ›´å…¨é¢çš„è¯­è¨€å¤„ç†ç³»ç»Ÿæ‰“ä¸‹äº†é‡è¦åŸºç¡€ã€‚",
      "categories": [
        "cs.CL",
        "cs.AI"
      ],
      "primary_category": "cs.CL",
      "comment": "13 pages,2 images,7 tables",
      "pdf_url": "https://arxiv.org/pdf/2509.20341v1",
      "published_date": "2025-09-24 17:33:47 UTC",
      "updated_date": "2025-09-24 17:33:47 UTC",
      "processing_status": "completed",
      "attempts": 1,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "llm_backup_calls": 0,
      "last_update": "2026-01-24T20:48:46.590989+00:00"
    },
    {
      "arxiv_id": "2509.20338v1",
      "title": "Adaptive Event-Triggered Policy Gradient for Multi-Agent Reinforcement Learning",
      "title_zh": "é¢å‘å¤šæ™ºèƒ½ä½“å¼ºåŒ–å­¦ä¹ çš„è‡ªé€‚åº”äº‹ä»¶è§¦å‘ç­–ç•¥æ¢¯åº¦",
      "authors": [
        "Umer Siddique",
        "Abhinav Sinha",
        "Yongcan Cao"
      ],
      "abstract": "Conventional multi-agent reinforcement learning (MARL) methods rely on time-triggered execution, where agents sample and communicate actions at fixed intervals. This approach is often computationally expensive and communication-intensive. To address this limitation, we propose ET-MAPG (Event-Triggered Multi-Agent Policy Gradient reinforcement learning), a framework that jointly learns an agent's control policy and its event-triggering policy. Unlike prior work that decouples these mechanisms, ET-MAPG integrates them into a unified learning process, enabling agents to learn not only what action to take but also when to execute it. For scenarios with inter-agent communication, we introduce AET-MAPG, an attention-based variant that leverages a self-attention mechanism to learn selective communication patterns. AET-MAPG empowers agents to determine not only when to trigger an action but also with whom to communicate and what information to exchange, thereby optimizing coordination. Both methods can be integrated with any policy gradient MARL algorithm. Extensive experiments across diverse MARL benchmarks demonstrate that our approaches achieve performance comparable to state-of-the-art, time-triggered baselines while significantly reducing both computational load and communication overhead.",
      "tldr_zh": "è¯¥ç ”ç©¶é’ˆå¯¹ä¼ ç»Ÿå¤šæ™ºèƒ½ä½“å¼ºåŒ–å­¦ä¹ (Multi-Agent Reinforcement Learning, MARL)ä¸­æ—¶é—´è§¦å‘(time-triggered)æœºåˆ¶å¯¼è‡´çš„è®¡ç®—ä¸é€šä¿¡å¼€é”€è¿‡é«˜é—®é¢˜ï¼Œæå‡ºäº†ET-MAPG(Event-Triggered Multi-Agent Policy Gradient)æ¡†æ¶ã€‚è¯¥æ¡†æ¶é€šè¿‡å°†æ§åˆ¶ç­–ç•¥ä¸äº‹ä»¶è§¦å‘ç­–ç•¥é›†æˆåˆ°ç»Ÿä¸€çš„å­¦ä¹ è¿‡ç¨‹ä¸­ï¼Œä½¿æ™ºèƒ½ä½“èƒ½å¤ŸåŒæ—¶å­¦ä¹ â€œé‡‡å–ä½•ç§åŠ¨ä½œâ€ä»¥åŠâ€œä½•æ—¶æ‰§è¡ŒåŠ¨ä½œâ€ã€‚é’ˆå¯¹éœ€è¦é€šä¿¡çš„åœºæ™¯ï¼Œç ”ç©¶è€…è¿›ä¸€æ­¥æå‡ºäº†åŸºäºæ³¨æ„åŠ›æœºåˆ¶çš„å˜ä½“AET-MAPGï¼Œåˆ©ç”¨self-attentionæœºåˆ¶å­¦ä¹ é€‰æ‹©æ€§é€šä¿¡æ¨¡å¼ã€‚AET-MAPGä½¿æ™ºèƒ½ä½“èƒ½å¤Ÿè‡ªä¸»å†³å®šè§¦å‘æ—¶æœºã€é€šä¿¡å¯¹è±¡åŠäº¤æ¢å†…å®¹ï¼Œä»è€Œå¤§å¹…ä¼˜åŒ–äº†å¤šæ™ºèƒ½ä½“é—´çš„åè°ƒæ•ˆç‡ã€‚æ­¤å¤–ï¼ŒET-MAPGå’ŒAET-MAPGå‡å…·å¤‡è‰¯å¥½çš„é€šç”¨æ€§ï¼Œå¯ä¸ä»»ä½•åŸºäºç­–ç•¥æ¢¯åº¦çš„MARLç®—æ³•ç›¸ç»“åˆã€‚å®éªŒç»“æœè¯æ˜ï¼Œè¯¥æ–¹æ³•åœ¨å¤šç§MARLåŸºå‡†æµ‹è¯•ä¸­è¾¾åˆ°äº†ä¸æœ€å…ˆè¿›æ—¶é—´è§¦å‘åŸºçº¿æ¨¡å‹ç›¸å½“çš„æ€§èƒ½ï¼ŒåŒæ—¶æ˜¾è‘—é™ä½äº†ç³»ç»Ÿçš„è®¡ç®—è´Ÿè·å’Œé€šä¿¡è´Ÿæ‹…ã€‚",
      "categories": [
        "eess.SY",
        "cs.AI",
        "cs.MA",
        "math.DS"
      ],
      "primary_category": "eess.SY",
      "comment": "",
      "pdf_url": "https://arxiv.org/pdf/2509.20338v1",
      "published_date": "2025-09-24 17:29:56 UTC",
      "updated_date": "2025-09-24 17:29:56 UTC",
      "processing_status": "completed",
      "attempts": 1,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "llm_backup_calls": 0,
      "last_update": "2026-01-24T20:48:56.391464+00:00"
    },
    {
      "arxiv_id": "2509.20336v1",
      "title": "Uncovering Graph Reasoning in Decoder-only Transformers with Circuit Tracing",
      "title_zh": "é€šè¿‡ç”µè·¯è¿½è¸ªæ­ç¤º Decoder-only Transformer ä¸­çš„å›¾æ¨ç†",
      "authors": [
        "Xinnan Dai",
        "Chung-Hsiang Lo",
        "Kai Guo",
        "Shenglai Zeng",
        "Dongsheng Luo",
        "Jiliang Tang"
      ],
      "abstract": "Transformer-based LLMs demonstrate strong performance on graph reasoning tasks, yet their internal mechanisms remain underexplored. To uncover these reasoning process mechanisms in a fundamental and unified view, we set the basic decoder-only transformers and explain them using the circuit-tracer framework. Through this lens, we visualize reasoning traces and identify two core mechanisms in graph reasoning: token merging and structural memorization, which underlie both path reasoning and substructure extraction tasks. We further quantify these behaviors and analyze how they are influenced by graph density and model size. Our study provides a unified interpretability framework for understanding structural reasoning in decoder-only Transformers.",
      "tldr_zh": "è¯¥ç ”ç©¶åˆ©ç”¨ circuit-tracer æ¡†æ¶å¯¹ Decoder-only Transformers åœ¨å›¾æ¨ç† (graph reasoning) ä»»åŠ¡ä¸­çš„å†…éƒ¨æœºåˆ¶è¿›è¡Œäº†æ·±å…¥æ¢ç´¢ã€‚é€šè¿‡å¯è§†åŒ–æ¨ç†è·¯å¾„ (reasoning traces)ï¼Œç ”ç©¶è¯†åˆ«å‡ºäº†æ”¯æ’‘è·¯å¾„æ¨ç† (path reasoning) å’Œå­ç»“æ„æå– (substructure extraction) çš„ä¸¤ç§æ ¸å¿ƒæœºåˆ¶ï¼Œå³ token merging å’Œ structural memorizationã€‚ç ”ç©¶è¿›ä¸€æ­¥é‡åŒ–äº†è¿™äº›æœºåˆ¶çš„å…·ä½“è¡¨ç°ï¼Œå¹¶åˆ†æäº†å›¾å¯†åº¦ (graph density) å’Œæ¨¡å‹è§„æ¨¡ (model size) å¯¹è¿™äº›æ¨ç†è¡Œä¸ºçš„å½±å“ã€‚è¯¥å·¥ä½œä¸ºç†è§£ Decoder-only æ¶æ„çš„ç»“æ„åŒ–æ¨ç†æä¾›äº†ä¸€ä¸ªç»Ÿä¸€çš„å¯è§£é‡Šæ€§æ¡†æ¶ (interpretability framework)ï¼Œæ­ç¤ºäº†æ¨¡å‹å¤„ç†å›¾ç»“æ„æ•°æ®æ—¶çš„å†…åœ¨é€»è¾‘ã€‚",
      "categories": [
        "cs.LG",
        "cs.AI"
      ],
      "primary_category": "cs.LG",
      "comment": "Accepted by the Workshop on Efficient Reasoning, Neurips 2025",
      "pdf_url": "https://arxiv.org/pdf/2509.20336v1",
      "published_date": "2025-09-24 17:25:05 UTC",
      "updated_date": "2025-09-24 17:25:05 UTC",
      "processing_status": "completed",
      "attempts": 1,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "llm_backup_calls": 0,
      "last_update": "2026-01-24T20:48:57.897474+00:00"
    },
    {
      "arxiv_id": "2509.22719v1",
      "title": "IBiT: Utilizing Inductive Biases to Create a More Data Efficient Attention Mechanism",
      "title_zh": "IBiTï¼šåˆ©ç”¨å½’çº³åç½®æ„å»ºæ›´é«˜æ•°æ®æ•ˆç‡çš„æ³¨æ„åŠ›æœºåˆ¶",
      "authors": [
        "Adithya Giri"
      ],
      "abstract": "In recent years, Transformer-based architectures have become the dominant method for Computer Vision applications. While Transformers are explainable and scale well with dataset size, they lack the inductive biases of Convolutional Neural Networks. While these biases may be learned on large datasets, we show that introducing these inductive biases through learned masks allow Vision Transformers to learn on much smaller datasets without Knowledge Distillation. These Transformers, which we call Inductively Biased Image Transformers (IBiT), are significantly more accurate on small datasets, while retaining the explainability Transformers.",
      "tldr_zh": "è¯¥ç ”ç©¶æå‡ºäº†IBiT (Inductively Biased Image Transformers)ï¼Œæ—¨åœ¨é€šè¿‡åˆ©ç”¨å½’çº³åç½®(Inductive Biases)æ¥åˆ›å»ºä¸€ä¸ªæ›´å…·æ•°æ®æ•ˆç‡çš„æ³¨æ„åŠ›æœºåˆ¶(Attention Mechanism)ã€‚è™½ç„¶Transformeræ¶æ„åœ¨è®¡ç®—æœºè§†è§‰(Computer Vision)åº”ç”¨ä¸­å·²æˆä¸ºä¸»æµï¼Œä½†å®ƒä»¬ç¼ºä¹å·ç§¯ç¥ç»ç½‘ç»œ(Convolutional Neural Networks)æ‰€å…·å¤‡çš„å½’çº³åç½®ã€‚IBiTé€šè¿‡å¼•å…¥å¯å­¦ä¹ çš„æ©ç (Learned Masks)å°†è¿™äº›å½’çº³åç½®æ•´åˆåˆ°Vision Transformersä¸­ï¼Œä»è€Œä½¿æ¨¡å‹èƒ½å¤Ÿåœ¨ä¸éœ€è¦çŸ¥è¯†è’¸é¦(Knowledge Distillation)çš„æƒ…å†µä¸‹åœ¨è¾ƒå°è§„æ¨¡çš„æ•°æ®é›†ä¸Šè¿›è¡Œé«˜æ•ˆå­¦ä¹ ã€‚å®éªŒç»“æœè¡¨æ˜ï¼ŒIBiTåœ¨å°å‹æ•°æ®é›†ä¸Šçš„å‡†ç¡®ç‡æ˜¾è‘—æé«˜ï¼ŒåŒæ—¶ä¿ç•™äº†TransformeråŸæœ‰çš„å¯è§£é‡Šæ€§(Explainability)ï¼Œæœ‰æ•ˆåœ°è§£å†³äº†ä¼ ç»ŸTransformeræ¶æ„å¯¹å¤§è§„æ¨¡æ•°æ®é›†è¿‡åº¦ä¾èµ–çš„é—®é¢˜ã€‚",
      "categories": [
        "cs.CV",
        "cs.AI",
        "cs.LG"
      ],
      "primary_category": "cs.CV",
      "comment": "",
      "pdf_url": "https://arxiv.org/pdf/2509.22719v1",
      "published_date": "2025-09-24 17:19:23 UTC",
      "updated_date": "2025-09-24 17:19:23 UTC",
      "processing_status": "completed",
      "attempts": 1,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "llm_backup_calls": 0,
      "last_update": "2026-01-24T20:48:51.893482+00:00"
    },
    {
      "arxiv_id": "2509.20328v2",
      "title": "Video models are zero-shot learners and reasoners",
      "title_zh": "è§†é¢‘æ¨¡å‹æ˜¯é›¶æ ·æœ¬å­¦ä¹ è€…ä¸æ¨ç†è€…",
      "authors": [
        "ThaddÃ¤us Wiedemer",
        "Yuxuan Li",
        "Paul Vicol",
        "Shixiang Shane Gu",
        "Nick Matarese",
        "Kevin Swersky",
        "Been Kim",
        "Priyank Jaini",
        "Robert Geirhos"
      ],
      "abstract": "The remarkable zero-shot capabilities of Large Language Models (LLMs) have propelled natural language processing from task-specific models to unified, generalist foundation models. This transformation emerged from simple primitives: large, generative models trained on web-scale data. Curiously, the same primitives apply to today's generative video models. Could video models be on a trajectory towards general-purpose vision understanding, much like LLMs developed general-purpose language understanding? We demonstrate that Veo 3 can solve a broad variety of tasks it wasn't explicitly trained for: segmenting objects, detecting edges, editing images, understanding physical properties, recognizing object affordances, simulating tool use, and more. These abilities to perceive, model, and manipulate the visual world enable early forms of visual reasoning like maze and symmetry solving. Veo's emergent zero-shot capabilities indicate that video models are on a path to becoming unified, generalist vision foundation models.",
      "tldr_zh": "è¯¥ç ”ç©¶æ¢è®¨äº†ç”Ÿæˆå¼è§†é¢‘æ¨¡å‹æ˜¯å¦èƒ½åƒ Large Language Models (LLMs) ä¸€æ ·å‘å±•å‡ºé€šç”¨çš„è§†è§‰ç†è§£èƒ½åŠ›ã€‚å®éªŒè¡¨æ˜ï¼ŒVeo 3 åœ¨æœªç»è¿‡æ˜¾å¼è®­ç»ƒçš„æƒ…å†µä¸‹ï¼Œèƒ½å¤Ÿèƒœä»» segmenting objectsã€detecting edgesã€editing imagesã€ç†è§£ physical properties ä»¥åŠè¯†åˆ« object affordances ç­‰å¤šç§å¤æ‚ä»»åŠ¡ã€‚æ­¤å¤–ï¼Œè¯¥æ¨¡å‹è¿˜å±•ç¤ºäº†åœ¨è§£å†³è¿·å®« (maze) å’Œå¯¹ç§°æ€§ (symmetry) ç­‰ä»»åŠ¡ä¸­çš„åˆæ­¥ visual reasoning èƒ½åŠ›ã€‚è¿™äº›æ¶Œç°çš„ zero-shot å­¦ä¹ ä¸æ¨ç†èƒ½åŠ›è¯æ˜ï¼Œè§†é¢‘æ¨¡å‹èƒ½å¤Ÿæœ‰æ•ˆåœ°æ„ŸçŸ¥ã€å»ºæ¨¡å¹¶æ“ä½œè§†è§‰ä¸–ç•Œã€‚ç ”ç©¶æœ€ç»ˆæŒ‡å‡ºï¼Œè§†é¢‘æ¨¡å‹æ­£å¤„äºæˆä¸ºç»Ÿä¸€ä¸”é€šç”¨çš„ vision foundation models çš„å‘å±•è½¨è¿¹ä¸Šï¼Œå±•ç°äº†ä»ç‰¹å®šä»»åŠ¡æ¨¡å‹å‘é€šç”¨è§†è§‰æ™ºèƒ½æ¼”è¿›çš„æ½œåŠ›ã€‚",
      "categories": [
        "cs.LG",
        "cs.AI",
        "cs.CV",
        "cs.RO"
      ],
      "primary_category": "cs.LG",
      "comment": "Project page: https://video-zero-shot.github.io/",
      "pdf_url": "https://arxiv.org/pdf/2509.20328v2",
      "published_date": "2025-09-24 17:17:27 UTC",
      "updated_date": "2025-09-29 20:44:46 UTC",
      "processing_status": "completed",
      "attempts": 1,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "llm_backup_calls": 0,
      "last_update": "2026-01-24T20:49:01.161374+00:00"
    },
    {
      "arxiv_id": "2509.20324v1",
      "title": "RAG Security and Privacy: Formalizing the Threat Model and Attack Surface",
      "title_zh": "RAG å®‰å…¨ä¸éšç§ï¼šå¨èƒæ¨¡å‹ä¸æ”»å‡»é¢çš„å½¢å¼åŒ–",
      "authors": [
        "Atousa Arzanipour",
        "Rouzbeh Behnia",
        "Reza Ebrahimi",
        "Kaushik Dutta"
      ],
      "abstract": "Retrieval-Augmented Generation (RAG) is an emerging approach in natural language processing that combines large language models (LLMs) with external document retrieval to produce more accurate and grounded responses. While RAG has shown strong potential in reducing hallucinations and improving factual consistency, it also introduces new privacy and security challenges that differ from those faced by traditional LLMs. Existing research has demonstrated that LLMs can leak sensitive information through training data memorization or adversarial prompts, and RAG systems inherit many of these vulnerabilities. At the same time, reliance of RAG on an external knowledge base opens new attack surfaces, including the potential for leaking information about the presence or content of retrieved documents, or for injecting malicious content to manipulate model behavior. Despite these risks, there is currently no formal framework that defines the threat landscape for RAG systems. In this paper, we address a critical gap in the literature by proposing, to the best of our knowledge, the first formal threat model for retrieval-RAG systems. We introduce a structured taxonomy of adversary types based on their access to model components and data, and we formally define key threat vectors such as document-level membership inference and data poisoning, which pose serious privacy and integrity risks in real-world deployments. By establishing formal definitions and attack models, our work lays the foundation for a more rigorous and principled understanding of privacy and security in RAG systems.",
      "tldr_zh": "è¯¥ç ”ç©¶é’ˆå¯¹æ£€ç´¢å¢å¼ºç”Ÿæˆ(Retrieval-Augmented Generation, RAG)ç³»ç»Ÿæ—¥ç›Šä¸¥å³»çš„å®‰å…¨ä¸éšç§æŒ‘æˆ˜ï¼Œæå‡ºäº†é¦–ä¸ªæ­£å¼çš„å¨èƒæ¨¡å‹(Threat Model)å’Œæ”»å‡»é¢(Attack Surface)æ¡†æ¶ã€‚è®ºæ–‡æŒ‡å‡ºï¼Œè™½ç„¶ RAG æŠ€æœ¯æœ‰åŠ©äºå‡å°‘å¤§è¯­è¨€æ¨¡å‹çš„å¹»è§‰ï¼Œä½†å…¶å¯¹å¤–éƒ¨çŸ¥è¯†åº“çš„ä¾èµ–ä¹Ÿå¼•å…¥äº†å¦‚æ£€ç´¢æ–‡æ¡£ä¿¡æ¯æ³„éœ²å’Œæ¶æ„å†…å®¹æ³¨å…¥ç­‰ç‰¹æœ‰çš„å®‰å…¨é£é™©ã€‚ä½œè€…æ ¹æ®æ”»å‡»è€…å¯¹æ¨¡å‹ç»„ä»¶å’Œæ•°æ®çš„è®¿é—®æƒé™ï¼Œæ„å»ºäº†ä¸€å¥—ç»“æ„åŒ–çš„å¯¹æ‰‹ç±»å‹åˆ†ç±»å­¦(Adversary Taxonomy)ï¼Œå¹¶æ­£å¼å®šä¹‰äº†æ–‡æ¡£çº§æˆå‘˜æ¨ç†(Membership Inference)å’Œæ•°æ®æŠ•æ¯’(Data Poisoning)ç­‰å…³é”®å¨èƒå‘é‡ã€‚é€šè¿‡ç¡®ç«‹è¿™äº›æ­£å¼çš„å®šä¹‰å’Œæ”»å‡»æ¨¡å‹ï¼Œè¯¥ç ”ç©¶å¡«è¡¥äº†ç°æœ‰æ–‡çŒ®ä¸­ç¼ºä¹ RAG ç³»ç»Ÿå®‰å…¨è¯„ä¼°æ¡†æ¶çš„ç©ºç™½ã€‚è¿™é¡¹å·¥ä½œä¸ºæ·±å…¥ç†è§£ RAG ç³»ç»Ÿçš„éšç§ä¸å®Œæ•´æ€§é£é™©æä¾›äº†ä¸¥è°¨çš„ç†è®ºåŸºç¡€ï¼Œæœ‰åŠ©äºæœªæ¥å¼€å‘æ›´å…·é˜²å¾¡æ€§å’ŒåŸåˆ™æ€§çš„æ£€ç´¢å¢å¼ºç³»ç»Ÿã€‚",
      "categories": [
        "cs.CR",
        "cs.AI"
      ],
      "primary_category": "cs.CR",
      "comment": "Accepted at the 5th ICDM Workshop on September 20, 2025",
      "pdf_url": "https://arxiv.org/pdf/2509.20324v1",
      "published_date": "2025-09-24 17:11:35 UTC",
      "updated_date": "2025-09-24 17:11:35 UTC",
      "processing_status": "completed",
      "attempts": 1,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "llm_backup_calls": 0,
      "last_update": "2026-01-24T20:49:01.973964+00:00"
    },
    {
      "arxiv_id": "2509.20321v1",
      "title": "DRES: Benchmarking LLMs for Disfluency Removal",
      "title_zh": "DRESï¼šå¤§è¯­è¨€æ¨¡å‹ä¸æµåˆ©ç°è±¡å»é™¤çš„åŸºå‡†æµ‹è¯•",
      "authors": [
        "Maria Teleki",
        "Sai Janjur",
        "Haoran Liu",
        "Oliver Grabner",
        "Ketan Verma",
        "Thomas Docog",
        "Xiangjue Dong",
        "Lingfeng Shi",
        "Cong Wang",
        "Stephanie Birkelbach",
        "Jason Kim",
        "Yin Zhang",
        "James Caverlee"
      ],
      "abstract": "Disfluencies -- such as \"um,\" \"uh,\" interjections, parentheticals, and edited statements -- remain a persistent challenge for speech-driven systems, degrading accuracy in command interpretation, summarization, and conversational agents. We introduce DRES (Disfluency Removal Evaluation Suite), a controlled text-level benchmark that establishes a reproducible semantic upper bound for this task. DRES builds on human-annotated Switchboard transcripts, isolating disfluency removal from ASR errors and acoustic variability. We systematically evaluate proprietary and open-source LLMs across scales, prompting strategies, and architectures. Our results reveal that (i) simple segmentation consistently improves performance, even for long-context models; (ii) reasoning-oriented models tend to over-delete fluent tokens; and (iii) fine-tuning achieves near state-of-the-art precision and recall but harms generalization abilities. We further present a set of LLM-specific error modes and offer nine practical recommendations (R1-R9) for deploying disfluency removal in speech-driven pipelines. DRES provides a reproducible, model-agnostic foundation for advancing robust spoken-language systems.",
      "tldr_zh": "è¯¥ç ”ç©¶ä»‹ç»äº† DRES (Disfluency Removal Evaluation Suite)ï¼Œè¿™æ˜¯ä¸€ä¸ªæ—¨åœ¨è¯„ä¼°å¤§è¯­è¨€æ¨¡å‹ (LLMs) å¤„ç†å£è¯­ä¸æµåˆ©ç°è±¡ (Disfluency Removal) çš„å—æ§æ–‡æœ¬åŸºå‡†æµ‹è¯•é›†ã€‚DRES åŸºäºäººå·¥æ ‡æ³¨çš„ Switchboard è½¬å½•æ–‡æœ¬æ„å»ºï¼Œé€šè¿‡æ’é™¤è¯­éŸ³è¯†åˆ« (ASR) é”™è¯¯å’Œå£°å­¦å˜å¼‚ï¼Œå»ºç«‹äº†è¯¥ä»»åŠ¡çš„å¯å¤ç°è¯­ä¹‰ä¸Šé™ã€‚ç ”ç©¶å›¢é˜Ÿç³»ç»Ÿè¯„ä¼°äº†å¤šç§é—­æºå’Œå¼€æº LLMs åœ¨ä¸åŒè§„æ¨¡ã€æç¤ºç­–ç•¥å’Œæ¶æ„ä¸‹çš„è¡¨ç°ï¼Œå‘ç°å³ä½¿å¯¹äºé•¿ä¸Šä¸‹æ–‡æ¨¡å‹ï¼Œç®€å•çš„åˆ†æ®µ (Segmentation) å¤„ç†ä¹Ÿèƒ½ç¨³å®šæå‡æ€§èƒ½ã€‚å®éªŒç»“æœæ˜¾ç¤ºï¼Œæ¨ç†å¯¼å‘ (Reasoning-oriented) çš„æ¨¡å‹å¾€å¾€ä¼šè¿‡åº¦åˆ é™¤æµåˆ©æ ‡è®°ï¼Œè€Œå¾®è°ƒ (Fine-tuning) è™½ç„¶èƒ½æå‡ç²¾ç¡®ç‡å’Œå¬å›ç‡ï¼Œä½†ä¼šæŸå®³æ³›åŒ–èƒ½åŠ›ã€‚æ­¤å¤–ï¼Œç ”ç©¶è¿˜æ€»ç»“äº† LLM ç‰¹æœ‰çš„é”™è¯¯æ¨¡å¼ï¼Œå¹¶ä¸ºè¯­éŸ³é©±åŠ¨æµæ°´çº¿ä¸­çš„ä¸æµåˆ©ç§»é™¤æŠ€æœ¯éƒ¨ç½²æä¾›äº†ä¹é¡¹å®ç”¨å»ºè®®ã€‚DRES ä¸ºå¼€å‘æ›´å…·é²æ£’æ€§çš„å£è¯­ç³»ç»Ÿæä¾›äº†ä¸€ä¸ªä¸æ¨¡å‹æ— å…³çš„å¯å¤ç°åŸºç¡€ã€‚",
      "categories": [
        "cs.CL",
        "cs.AI",
        "eess.AS"
      ],
      "primary_category": "cs.CL",
      "comment": "",
      "pdf_url": "https://arxiv.org/pdf/2509.20321v1",
      "published_date": "2025-09-24 17:08:12 UTC",
      "updated_date": "2025-09-24 17:08:12 UTC",
      "processing_status": "completed",
      "attempts": 1,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "llm_backup_calls": 0,
      "last_update": "2026-01-24T20:50:08.191284+00:00"
    },
    {
      "arxiv_id": "2509.20319v1",
      "title": "Z-Scores: A Metric for Linguistically Assessing Disfluency Removal",
      "title_zh": "Z-Scoresï¼šä¸€ç§ç”¨äºä¸æµåˆ©æˆåˆ†ç§»é™¤è¯­è¨€å­¦è¯„ä¼°çš„åº¦é‡æŒ‡æ ‡",
      "authors": [
        "Maria Teleki",
        "Sai Janjur",
        "Haoran Liu",
        "Oliver Grabner",
        "Ketan Verma",
        "Thomas Docog",
        "Xiangjue Dong",
        "Lingfeng Shi",
        "Cong Wang",
        "Stephanie Birkelbach",
        "Jason Kim",
        "Yin Zhang",
        "James Caverlee"
      ],
      "abstract": "Evaluating disfluency removal in speech requires more than aggregate token-level scores. Traditional word-based metrics such as precision, recall, and F1 (E-Scores) capture overall performance but cannot reveal why models succeed or fail. We introduce Z-Scores, a span-level linguistically-grounded evaluation metric that categorizes system behavior across distinct disfluency types (EDITED, INTJ, PRN). Our deterministic alignment module enables robust mapping between generated text and disfluent transcripts, allowing Z-Scores to expose systematic weaknesses that word-level metrics obscure. By providing category-specific diagnostics, Z-Scores enable researchers to identify model failure modes and design targeted interventions -- such as tailored prompts or data augmentation -- yielding measurable performance improvements. A case study with LLMs shows that Z-Scores uncover challenges with INTJ and PRN disfluencies hidden in aggregate F1, directly informing model refinement strategies.",
      "tldr_zh": "è¯¥ç ”ç©¶é’ˆå¯¹è¯­éŸ³ä¸æµåˆ©ç§»é™¤(disfluency removal)è¯„ä¼°ä¸­ä¼ ç»Ÿå•è¯çº§æŒ‡æ ‡(å¦‚Precisionã€Recallã€F1ï¼Œå³E-Scores)æ— æ³•æ­ç¤ºæ¨¡å‹å¤±è´¥åŸå› çš„é—®é¢˜ï¼Œæå‡ºäº†Z-Scoresè¯„ä¼°æŒ‡æ ‡ã€‚Z-Scoresæ˜¯ä¸€ç§åŸºäºè·¨åº¦(span-level)ä¸”å…·å¤‡è¯­è¨€å­¦åŸºç¡€çš„åº¦é‡æ–¹å¼ï¼Œèƒ½å¤Ÿå°†ç³»ç»Ÿè¡Œä¸ºç»†åˆ†ä¸ºEDITEDã€INTJå’ŒPRNç­‰ä¸åŒç±»å‹çš„ä¸æµåˆ©ç°è±¡ã€‚è¯¥æ–¹æ³•é€šè¿‡ç¡®å®šæ€§å¯¹é½æ¨¡å—(deterministic alignment module)å®ç°äº†ç”Ÿæˆæ–‡æœ¬ä¸åŸå§‹è½¬å½•ç¨¿çš„ç¨³å¥æ˜ å°„ï¼Œä»è€Œæš´éœ²äº†å•è¯çº§æŒ‡æ ‡éš¾ä»¥å¯Ÿè§‰çš„ç³»ç»Ÿæ€§ç¼ºé™·ã€‚é€šè¿‡æä¾›ç‰¹å®šç±»åˆ«çš„è¯Šæ–­ä¿¡æ¯ï¼ŒZ-Scoresèƒ½å¤Ÿå¸®åŠ©ç ”ç©¶äººå‘˜è¯†åˆ«æ¨¡å‹çš„å¤±æ•ˆæ¨¡å¼å¹¶è®¾è®¡é’ˆå¯¹æ€§çš„å¹²é¢„æªæ–½ï¼Œå¦‚å®šåˆ¶æç¤ºè¯æˆ–æ•°æ®å¢å¼ºã€‚é’ˆå¯¹å¤§è¯­è¨€æ¨¡å‹(LLMs)çš„æ¡ˆä¾‹ç ”ç©¶è¡¨æ˜ï¼ŒZ-ScoresæˆåŠŸæ­ç¤ºäº†è¢«æ€»åˆ†F1æ©ç›–çš„INTJå’ŒPRNå¤„ç†æŒ‘æˆ˜ï¼Œç›´æ¥ä¸ºæ¨¡å‹ä¼˜åŒ–ç­–ç•¥æä¾›äº†å…³é”®æŒ‡å¯¼ã€‚",
      "categories": [
        "cs.CL",
        "cs.AI",
        "eess.AS"
      ],
      "primary_category": "cs.CL",
      "comment": "",
      "pdf_url": "https://arxiv.org/pdf/2509.20319v1",
      "published_date": "2025-09-24 17:02:39 UTC",
      "updated_date": "2025-09-24 17:02:39 UTC",
      "processing_status": "completed",
      "attempts": 1,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "llm_backup_calls": 0,
      "last_update": "2026-01-24T20:49:19.185105+00:00"
    },
    {
      "arxiv_id": "2509.20317v2",
      "title": "SIM-CoT: Supervised Implicit Chain-of-Thought",
      "title_zh": "SIM-CoTï¼šç›‘ç£å¼éšå¼æ€ç»´é“¾",
      "authors": [
        "Xilin Wei",
        "Xiaoran Liu",
        "Yuhang Zang",
        "Xiaoyi Dong",
        "Yuhang Cao",
        "Jiaqi Wang",
        "Xipeng Qiu",
        "Dahua Lin"
      ],
      "abstract": "Implicit Chain-of-Thought (CoT) methods offer a token-efficient alternative to explicit CoT reasoning in Large Language Models (LLMs), but a persistent performance gap has limited their adoption. We identify a core latent instability issue when scaling the computational budget of implicit CoT: as the number of reasoning tokens increases, training often becomes unstable and collapses. Our analysis shows that this instability arises from latent representations becoming homogeneous and losing semantic diversity, caused by insufficient step-level supervision in current implicit CoT methods. To address this, we propose SIM-CoT, a plug-and-play training module that introduces step-level supervision to stabilize and enrich the latent reasoning space. SIM-CoT employs an auxiliary decoder during training to align each implicit token with its corresponding explicit reasoning step, ensuring latent states capture distinct and meaningful information. The auxiliary decoder is removed at inference, preserving the efficiency of implicit CoT with no added overhead. It also provides interpretability by projecting each latent token onto an explicit reasoning vocabulary, enabling per-step visualization and diagnosis. SIM-CoT significantly improves both in-domain accuracy and out-of-domain stability of implicit CoT methods, boosting Coconut by +8.2\\% on GPT-2 and CODI by +3.0\\% on LLaMA-3.1 8B. It further surpasses the explicit CoT baseline on GPT-2 by 2.1\\% with 2.3$\\times$ greater token efficiency, while closing the performance gap on larger models like LLaMA-3.1 8B. Code: https://github.com/InternLM/SIM-CoT",
      "tldr_zh": "è¯¥ç ”ç©¶é’ˆå¯¹éšå¼é“¾å¼æ€ç»´(Implicit Chain-of-Thought)æ–¹æ³•åœ¨å¤§è¯­è¨€æ¨¡å‹(LLMs)æ¨ç†ä¸­å­˜åœ¨çš„æ€§èƒ½å·®è·ï¼Œä»¥åŠåœ¨å¤§è§„æ¨¡è®¡ç®—é¢„ç®—ä¸‹æ˜“å‡ºç°çš„è®­ç»ƒä¸ç¨³å®šå’Œè¡¨ç¤ºåŒè´¨åŒ–é—®é¢˜ï¼Œæå‡ºäº†SIM-CoTè®­ç»ƒæ¨¡å—ã€‚ä½œè€…æŒ‡å‡ºï¼Œå½“å‰éšå¼CoTæ–¹æ³•ç”±äºç¼ºä¹æ­¥éª¤çº§ç›‘ç£ï¼Œå¯¼è‡´æ½œåœ¨è¡¨ç¤º(latent representations)ä¸§å¤±è¯­ä¹‰å¤šæ ·æ€§ï¼Œè¿›è€Œå¼•å‘è®­ç»ƒå´©æºƒã€‚SIM-CoTé€šè¿‡åœ¨è®­ç»ƒé˜¶æ®µå¼•å…¥è¾…åŠ©è§£ç å™¨(auxiliary decoder)ï¼Œå°†æ¯ä¸ªéšå¼Tokenä¸å¯¹åº”çš„æ˜¾å¼æ¨ç†æ­¥éª¤è¿›è¡Œå¯¹é½ï¼Œä»è€Œç¨³å®šå¹¶ä¸°å¯Œäº†æ½œåœ¨æ¨ç†ç©ºé—´ã€‚è¯¥è¾…åŠ©è§£ç å™¨åœ¨æ¨ç†é˜¶æ®µä¼šè¢«ç§»é™¤ï¼Œåœ¨ä¸å¢åŠ é¢å¤–å¼€é”€çš„å‰æä¸‹ä¿æŒäº†éšå¼CoTçš„é«˜æ•ˆç‡ï¼Œå¹¶å®ç°äº†æ¯æ­¥æ¨ç†çŠ¶æ€çš„å¯è§†åŒ–ä¸è§£é‡Šã€‚å®éªŒç»“æœè¡¨æ˜ï¼ŒSIM-CoTæ˜¾è‘—æå‡äº†ç°æœ‰éšå¼CoTæ–¹æ³•åœ¨ä¸åŒæ¨¡å‹ä¸Šçš„å‡†ç¡®ç‡ä¸ç¨³å®šæ€§ï¼Œåœ¨GPT-2ä¸Šæ¯”æ˜¾å¼CoTåŸºå‡†æ€§èƒ½é«˜å‡º2.1%ä¸”æ¨ç†æ•ˆç‡æå‡2.3å€ï¼Œå¹¶æˆåŠŸç¼©å°äº†åœ¨LLaMA-3.1 8Bç­‰å¤§æ¨¡å‹ä¸Šçš„æ€§èƒ½å·®è·ã€‚",
      "categories": [
        "cs.CL",
        "cs.AI"
      ],
      "primary_category": "cs.CL",
      "comment": "",
      "pdf_url": "https://arxiv.org/pdf/2509.20317v2",
      "published_date": "2025-09-24 17:01:32 UTC",
      "updated_date": "2025-09-25 12:17:01 UTC",
      "processing_status": "completed",
      "attempts": 1,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "llm_backup_calls": 0,
      "last_update": "2026-01-24T20:50:21.896958+00:00"
    },
    {
      "arxiv_id": "2509.20293v3",
      "title": "When Judgment Becomes Noise: How Design Failures in LLM Judge Benchmarks Silently Undermine Validity",
      "title_zh": "å½“è¯„åˆ¤æ²¦ä¸ºå™ªå£°ï¼šLLM è£åˆ¤åŸºå‡†çš„è®¾è®¡ç¼ºé™·å¦‚ä½•æ‚„ç„¶å‰Šå¼±å…¶æ•ˆåº¦",
      "authors": [
        "Benjamin Feuer",
        "Chiung-Yi Tseng",
        "Astitwa Sarthak Lathe",
        "Oussama Elachqar",
        "John P Dickerson"
      ],
      "abstract": "LLM-judged benchmarks are increasingly used to evaluate complex model behaviors, yet their design introduces failure modes absent in conventional ground-truth based benchmarks. We argue that without tight objectives and verifiable constructions, benchmark rankings can produce high-confidence rankings that are in fact largely noise. We introduce two mechanisms to diagnose these issues. Schematic adherence quantifies how much of a judge's overall verdict is explained by the explicit evaluation schema, revealing unexplained variance when judges deviate from their own rubric. Psychometric validity aggregates internal consistency and discriminant validity signals to quantify irreducible uncertainty in any benchmarking run. Applying these tools to Arena-Hard Auto, we find severe schema incoherence and factor collapse across popular judges: for example, unexplained variance exceeding 90 percent for DeepSeek-R1-32B and factor correlations above 0.93 for most criteria. We also show that the ELO-style aggregation used by Arena-Hard Auto collapses and masks genuine ranking uncertainty. Our results highlight design failures that undermine validity and offer actionable principles for building better-scoped, reliability-aware LLM-judged benchmarks. We released our code and dataset at https://github.com/penfever/judgment-to-noise",
      "tldr_zh": "è¯¥ç ”ç©¶æ¢è®¨äº†åŸºäºå¤§å‹è¯­è¨€æ¨¡å‹è£åˆ¤ï¼ˆLLM-judgedï¼‰çš„åŸºå‡†æµ‹è¯•åœ¨è¯„ä¼°æ¨¡å‹å¤æ‚è¡Œä¸ºæ—¶å­˜åœ¨çš„è®¾è®¡å¤±æ•ˆæ¨¡å¼ï¼ŒæŒ‡å‡ºç¼ºä¹ä¸¥è°¨ç›®æ ‡å’Œå¯éªŒè¯ç»“æ„çš„åŸºå‡†æ’åå¯èƒ½æ¼”å˜ä¸ºé«˜ç½®ä¿¡åº¦çš„å™ªå£°ã€‚ä½œè€…å¼•å…¥äº†ä¸¤ç§è¯Šæ–­æœºåˆ¶ï¼šæ¶æ„ä¸€è‡´æ€§ï¼ˆSchematic adherenceï¼‰ç”¨äºé‡åŒ–è£åˆ¤è¯„åˆ†ä¸æ—¢å®šè¯„ä»·å‡†åˆ™çš„å»åˆç¨‹åº¦ï¼Œå¿ƒç†æµ‹é‡æ•ˆåº¦ï¼ˆPsychometric validityï¼‰åˆ™é€šè¿‡èšåˆå†…éƒ¨ä¸€è‡´æ€§å’ŒåŒºåˆ†æ•ˆåº¦ä¿¡å·æ¥é‡åŒ–åŸºå‡†æµ‹è¯•ä¸­çš„ä¸å¯è¿˜åŸä¸ç¡®å®šæ€§ã€‚é€šè¿‡å¯¹ Arena-Hard Auto çš„è¯„ä¼°ï¼Œç ”ç©¶å‘ç°ä¸»æµè£åˆ¤æ¨¡å‹æ™®éå­˜åœ¨ä¸¥é‡çš„æ¶æ„ä¸è¿è´¯å’Œå› å­åç¼©ç°è±¡ï¼Œä¾‹å¦‚ DeepSeek-R1-32B çš„è§£é‡Šå¤–æ–¹å·®ï¼ˆunexplained varianceï¼‰è¶…è¿‡ 90%ï¼Œä¸”å¤šæ•°æ ‡å‡†çš„å› å­ç›¸å…³æ€§ï¼ˆfactor correlationsï¼‰é«˜äº 0.93ã€‚ç ”ç©¶è¿˜è¯æ˜ Arena-Hard Auto ä½¿ç”¨çš„ ELO è¯„åˆ†èšåˆæ–¹å¼æ©ç›–äº†çœŸå®çš„æ’åä¸ç¡®å®šæ€§ã€‚è¯¥å·¥ä½œæ­ç¤ºäº†å‰Šå¼±åŸºå‡†æµ‹è¯•æ•ˆåº¦çš„å…³é”®è®¾è®¡ç¼ºé™·ï¼Œå¹¶ä¸ºæ„å»ºèŒƒå›´æ›´æ˜ç¡®ã€å…·å¤‡å¯é æ€§æ„è¯†çš„ LLM-judged åŸºå‡†æµ‹è¯•æä¾›äº†å¯è¡Œçš„æŒ‡å¯¼åŸåˆ™ã€‚",
      "categories": [
        "cs.LG",
        "cs.AI"
      ],
      "primary_category": "cs.LG",
      "comment": "",
      "pdf_url": "https://arxiv.org/pdf/2509.20293v3",
      "published_date": "2025-09-24 16:26:47 UTC",
      "updated_date": "2025-10-08 10:11:46 UTC",
      "processing_status": "completed",
      "attempts": 1,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "llm_backup_calls": 0,
      "last_update": "2026-01-24T20:50:24.573359+00:00"
    },
    {
      "arxiv_id": "2509.20290v1",
      "title": "PGCLODA: Prompt-Guided Graph Contrastive Learning for Oligopeptide-Infectious Disease Association Prediction",
      "title_zh": "PGCLODAï¼šåŸºäºæç¤ºå¼•å¯¼å›¾å¯¹æ¯”å­¦ä¹ çš„å¯¡è‚½-ä¼ æŸ“ç—…å…³è”é¢„æµ‹",
      "authors": [
        "Dayu Tan",
        "Jing Chen",
        "Xiaoping Zhou",
        "Yansen Su",
        "Chunhou Zheng"
      ],
      "abstract": "Infectious diseases continue to pose a serious threat to public health, underscoring the urgent need for effective computational approaches to screen novel anti-infective agents. Oligopeptides have emerged as promising candidates in antimicrobial research due to their structural simplicity, high bioavailability, and low susceptibility to resistance. Despite their potential, computational models specifically designed to predict associations between oligopeptides and infectious diseases remain scarce. This study introduces a prompt-guided graph-based contrastive learning framework (PGCLODA) to uncover potential associations. A tripartite graph is constructed with oligopeptides, microbes, and diseases as nodes, incorporating both structural and semantic information. To preserve critical regions during contrastive learning, a prompt-guided graph augmentation strategy is employed to generate meaningful paired views. A dual encoder architecture, integrating Graph Convolutional Network (GCN) and Transformer, is used to jointly capture local and global features. The fused embeddings are subsequently input into a multilayer perceptron (MLP) classifier for final prediction. Experimental results on a benchmark dataset indicate that PGCLODA consistently outperforms state-of-the-art models in AUROC, AUPRC, and accuracy. Ablation and hyperparameter studies confirm the contribution of each module. Case studies further validate the generalization ability of PGCLODA and its potential to uncover novel, biologically relevant associations. These findings offer valuable insights for mechanism-driven discovery and oligopeptide-based drug development. The source code of PGCLODA is available online at https://github.com/jjnlcode/PGCLODA.",
      "tldr_zh": "è¯¥ç ”ç©¶é’ˆå¯¹ä¼ æŸ“ç—…å¨èƒåŠç°æœ‰è®¡ç®—æ¨¡å‹åœ¨é¢„æµ‹å¯¡è‚½ä¸ä¼ æŸ“ç—…å…³è”æ–¹é¢çš„ä¸è¶³ï¼Œæå‡ºäº†PGCLODAï¼Œä¸€ä¸ªåŸºäºæç¤ºå¼•å¯¼çš„å›¾å¯¹æ¯”å­¦ä¹ æ¡†æ¶ã€‚è¯¥æ¡†æ¶æ„å»ºäº†åŒ…å«å¯¡è‚½ã€å¾®ç”Ÿç‰©å’Œç–¾ç—…èŠ‚ç‚¹çš„ä¸‰ä¸ªéƒ¨åˆ†å›¾(tripartite graph)ï¼Œå¹¶æœ‰æ•ˆèåˆäº†ç»“æ„å’Œè¯­ä¹‰ä¿¡æ¯ã€‚ä¸ºäº†åœ¨å¯¹æ¯”å­¦ä¹ ä¸­ä¿ç•™å…³é”®åŒºåŸŸï¼ŒPGCLODAé‡‡ç”¨äº†æç¤ºå¼•å¯¼çš„å›¾å¢å¼ºç­–ç•¥(prompt-guided graph augmentation)æ¥ç”Ÿæˆå…·æœ‰æ„ä¹‰çš„é…å¯¹è§†å›¾ã€‚ç³»ç»Ÿé‡‡ç”¨ç”±å›¾å·ç§¯ç½‘ç»œ(GCN)å’ŒTransformerç»„æˆçš„åŒç¼–ç å™¨æ¶æ„ï¼Œä»¥å…±åŒæ•æ‰å±€éƒ¨å’Œå…¨å±€ç‰¹å¾ï¼Œå¹¶åˆ©ç”¨å¤šå±‚æ„ŸçŸ¥å™¨(MLP)è¿›è¡Œæœ€ç»ˆé¢„æµ‹ã€‚å®éªŒç»“æœè¡¨æ˜ï¼ŒPGCLODAåœ¨AUROCã€AUPRCå’Œå‡†ç¡®ç‡ç­‰æŒ‡æ ‡ä¸ŠæŒç»­ä¼˜äºç°æœ‰æœ€å…ˆè¿›çš„æ¨¡å‹ã€‚æ¶ˆèå®éªŒå’Œæ¡ˆä¾‹ç ”ç©¶è¿›ä¸€æ­¥è¯å®äº†è¯¥æ¡†æ¶çš„æ³›åŒ–èƒ½åŠ›ä»¥åŠå‘ç°æ–°å‹ç”Ÿç‰©å…³è”çš„æ½œåŠ›ï¼Œä¸ºåŸºäºå¯¡è‚½çš„è¯ç‰©å¼€å‘æä¾›äº†é‡è¦è§è§£ã€‚",
      "categories": [
        "cs.LG",
        "cs.AI",
        "q-bio.QM"
      ],
      "primary_category": "cs.LG",
      "comment": "12page and 8 figures",
      "pdf_url": "https://arxiv.org/pdf/2509.20290v1",
      "published_date": "2025-09-24 16:25:13 UTC",
      "updated_date": "2025-09-24 16:25:13 UTC",
      "processing_status": "completed",
      "attempts": 1,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "llm_backup_calls": 0,
      "last_update": "2026-01-24T20:50:28.570718+00:00"
    },
    {
      "arxiv_id": "2509.20287v1",
      "title": "Feeding Two Birds or Favoring One? Adequacy-Fluency Tradeoffs in Evaluation and Meta-Evaluation of Machine Translation",
      "title_zh": "å…¼é¡¾äºŒè€…è¿˜æ˜¯åšæ­¤è–„å½¼ï¼Ÿæœºå™¨ç¿»è¯‘è¯„ä¼°ä¸å…ƒè¯„ä¼°ä¸­çš„å……åˆ†æ€§ä¸æµåˆ©åº¦æƒè¡¡",
      "authors": [
        "Behzad Shayegh",
        "Jan-Thorsten Peter",
        "David Vilar",
        "Tobias Domhan",
        "Juraj Juraska",
        "Markus Freitag",
        "Lili Mou"
      ],
      "abstract": "We investigate the tradeoff between adequacy and fluency in machine translation. We show the severity of this tradeoff at the evaluation level and analyze where popular metrics fall within it. Essentially, current metrics generally lean toward adequacy, meaning that their scores correlate more strongly with the adequacy of translations than with fluency. More importantly, we find that this tradeoff also persists at the meta-evaluation level, and that the standard WMT meta-evaluation favors adequacy-oriented metrics over fluency-oriented ones. We show that this bias is partially attributed to the composition of the systems included in the meta-evaluation datasets. To control this bias, we propose a method that synthesizes translation systems in meta-evaluation. Our findings highlight the importance of understanding this tradeoff in meta-evaluation and its impact on metric rankings.",
      "tldr_zh": "è¯¥ç ”ç©¶æ¢è®¨äº†æœºå™¨ç¿»è¯‘ä¸­å¿ å®åº¦(Adequacy)ä¸æµåˆ©åº¦(Fluency)ä¹‹é—´çš„æƒè¡¡å…³ç³»ï¼Œå¹¶æ·±å…¥åˆ†æäº†ç°æœ‰è¯„ä¼°æŒ‡æ ‡åŠå…¶å…ƒè¯„ä¼°(Meta-Evaluation)åœ¨è¯¥ç»´åº¦ä¸Šçš„ç«‹åœºã€‚ç ”ç©¶å‘ç°ï¼Œå½“å‰ä¸»æµæŒ‡æ ‡æ™®éåå‘äºå¿ å®åº¦ï¼Œä¸”è¿™ç§å€¾å‘åœ¨å…ƒè¯„ä¼°å±‚é¢ä¾ç„¶å­˜åœ¨ï¼Œå¯¼è‡´æ ‡å‡†çš„WMTå…ƒè¯„ä¼°æ›´é’çä»¥å¿ å®åº¦ä¸ºå¯¼å‘çš„æŒ‡æ ‡ã€‚åˆ†æè¡¨æ˜ï¼Œè¿™ç§åè§éƒ¨åˆ†å½’å› äºå…ƒè¯„ä¼°æ•°æ®é›†ä¸­æ‰€åŒ…å«ç³»ç»Ÿçš„æ„æˆæ–¹å¼ã€‚ä¸ºäº†åº”å¯¹è¿™ä¸€æŒ‘æˆ˜ï¼Œç ”ç©¶æå‡ºäº†ä¸€ç§åœ¨å…ƒè¯„ä¼°ä¸­åˆæˆç¿»è¯‘ç³»ç»Ÿçš„æ–¹æ³•ï¼Œä»¥æœŸæ›´å…¬å¹³åœ°è¯„ä¼°ä¸åŒä¾§é‡ç‚¹çš„æŒ‡æ ‡ã€‚è¯¥é¡¹å‘ç°å¼ºè°ƒäº†åœ¨å…ƒè¯„ä¼°è¿‡ç¨‹ä¸­ç†è§£è¿™ç§æƒè¡¡çš„é‡è¦æ€§ï¼Œå¹¶æ­ç¤ºäº†å…¶å¯¹è¯„ä¼°æŒ‡æ ‡æ’åäº§ç”Ÿçš„å…³é”®å½±å“ã€‚",
      "categories": [
        "cs.CL",
        "cs.AI",
        "cs.LG"
      ],
      "primary_category": "cs.CL",
      "comment": "Accepted by Tenth Conference on Machine Translation (WMT25)",
      "pdf_url": "https://arxiv.org/pdf/2509.20287v1",
      "published_date": "2025-09-24 16:21:37 UTC",
      "updated_date": "2025-09-24 16:21:37 UTC",
      "processing_status": "completed",
      "attempts": 1,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "llm_backup_calls": 0,
      "last_update": "2026-01-24T20:50:34.160222+00:00"
    },
    {
      "arxiv_id": "2510.01254v1",
      "title": "Do Bias Benchmarks Generalise? Evidence from Voice-based Evaluation of Gender Bias in SpeechLLMs",
      "title_zh": "åè§åŸºå‡†æµ‹è¯•æ˜¯å¦å…·æœ‰æ³›åŒ–æ€§ï¼Ÿæ¥è‡ªå¯¹ SpeechLLMs æ€§åˆ«åè§è¿›è¡Œè¯­éŸ³è¯„ä¼°çš„è¯æ®",
      "authors": [
        "Shree Harsha Bokkahalli Satish",
        "Gustav Eje Henter",
        "Ã‰va SzÃ©kely"
      ],
      "abstract": "Recent work in benchmarking bias and fairness in speech large language models (SpeechLLMs) has relied heavily on multiple-choice question answering (MCQA) formats. The model is tasked to choose between stereotypical, anti-stereotypical, or neutral/irrelevant answers given an input speech prompt and an optional text prompt. Such MCQA benchmarks implicitly assume that model performance is consistent across other MCQA tasks, voices, and other task formats such as more realistic, long-form evaluations. In this paper, we probe that assumption.\n  We fine-tune three SpeechLLMs using LoRA adapters to induce specific MCQA behaviours: preference for stereotypical, anti-stereotypical, or neutral/uncertain answers. We then evaluate whether these behaviours generalise to another, distinct MCQA benchmark, and more critically to long-form, creative generation tasks. Our results show that performance on MCQA bias benchmarks fails to reliably predict performances across other MCQA benchmarks, and more importantly across long-form tasks. We conclude that current MCQA bias benchmarks show limited evidence of cross-task generalisation in the speech domain, and also propose an evaluation suite for measuring behaviour transferability in future models and benchmarks.",
      "tldr_zh": "è¯¥ç ”ç©¶æ¢è®¨äº†è¯­éŸ³å¤§è¯­è¨€æ¨¡å‹(SpeechLLMs)ä¸­æ€§åˆ«åè§è¯„ä¼°åŸºå‡†çš„æ³›åŒ–æ€§é—®é¢˜ï¼Œè´¨ç–‘äº†ç›®å‰å¹¿æ³›é‡‡ç”¨çš„å¤šé€‰é¢˜(MCQA)è¯„ä¼°æ ¼å¼æ˜¯å¦èƒ½çœŸå®åæ˜ æ¨¡å‹åœ¨å¤šå…ƒä»»åŠ¡ä¸­çš„è¡¨ç°ã€‚ç ”ç©¶å›¢é˜Ÿé€šè¿‡LoRAæŠ€æœ¯å¾®è°ƒäº†ä¸‰ä¸ªSpeechLLMsï¼Œä½¿å…¶åˆ†åˆ«è¡¨ç°å‡ºç‰¹å®šçš„åè§å€¾å‘æˆ–ä¸­ç«‹è¡Œä¸ºï¼Œå¹¶æµ‹è¯•è¿™äº›è¡Œä¸ºæ˜¯å¦ä¼šè¿ç§»è‡³å…¶ä»–MCQAåŸºå‡†åŠé•¿ç¯‡åˆ›æ„ç”Ÿæˆä»»åŠ¡ã€‚å®éªŒç»“æœè¡¨æ˜ï¼Œæ¨¡å‹åœ¨MCQAåè§åŸºå‡†ä¸Šçš„è¡¨ç°æ— æ³•å¯é åœ°é¢„æµ‹å…¶åœ¨å…¶ä»–è¯„ä¼°åŸºå‡†æˆ–é•¿ç¯‡ä»»åŠ¡ä¸­çš„è¡Œä¸ºè¡¨ç°ã€‚è¯¥ç ”ç©¶æ­ç¤ºäº†å½“å‰è¯­éŸ³é¢†åŸŸMCQAåè§åŸºå‡†åœ¨è·¨ä»»åŠ¡æ³›åŒ–(cross-task generalisation)æ–¹é¢çš„å±€é™æ€§ï¼Œå¹¶æ®æ­¤æå‡ºäº†ä¸€ä¸ªç”¨äºè¡¡é‡æ¨¡å‹è¡Œä¸ºå¯è¿ç§»æ€§çš„è¯„ä¼°å¥—ä»¶ï¼Œä¸ºæœªæ¥æ›´å…¨é¢çš„è¯­éŸ³æ¨¡å‹å…¬å¹³æ€§è¯„ä¼°æä¾›äº†å‚è€ƒã€‚",
      "categories": [
        "cs.CL",
        "cs.AI",
        "cs.SD",
        "eess.AS"
      ],
      "primary_category": "cs.CL",
      "comment": "5 pages, 2 Figures, Submitted to IEEE ICASSP 2026",
      "pdf_url": "https://arxiv.org/pdf/2510.01254v1",
      "published_date": "2025-09-24 16:16:59 UTC",
      "updated_date": "2025-09-24 16:16:59 UTC",
      "processing_status": "completed",
      "attempts": 1,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "llm_backup_calls": 0,
      "last_update": "2026-01-24T20:50:37.154103+00:00"
    },
    {
      "arxiv_id": "2509.20277v1",
      "title": "Investigating Security Implications of Automatically Generated Code on the Software Supply Chain",
      "title_zh": "è‡ªåŠ¨ç”Ÿæˆä»£ç å¯¹è½¯ä»¶ä¾›åº”é“¾å®‰å…¨å½±å“çš„ç ”ç©¶",
      "authors": [
        "Xiaofan Li",
        "Xing Gao"
      ],
      "abstract": "In recent years, various software supply chain (SSC) attacks have posed significant risks to the global community. Severe consequences may arise if developers integrate insecure code snippets that are vulnerable to SSC attacks into their products. Particularly, code generation techniques, such as large language models (LLMs), have been widely utilized in the developer community. However, LLMs are known to suffer from inherent issues when generating code, including fabrication, misinformation, and reliance on outdated training data, all of which can result in serious software supply chain threats. In this paper, we investigate the security threats to the SSC that arise from these inherent issues. We examine three categories of threats, including eleven potential SSC-related threats, related to external components in source code, and continuous integration configuration files. We find some threats in LLM-generated code could enable attackers to hijack software and workflows, while some others might cause potential hidden threats that compromise the security of the software over time. To understand these security impacts and severity, we design a tool, SSCGuard, to generate 439,138 prompts based on SSC-related questions collected online, and analyze the responses of four popular LLMs from GPT and Llama. Our results show that all identified SSC-related threats persistently exist. To mitigate these risks, we propose a novel prompt-based defense mechanism, namely Chain-of-Confirmation, to reduce fabrication, and a middleware-based defense that informs users of various SSC threats.",
      "tldr_zh": "è¯¥ç ”ç©¶æ¢è®¨äº†å¤§å‹è¯­è¨€æ¨¡å‹(LLMs)è‡ªåŠ¨ç”Ÿæˆçš„ä»£ç å¯¹è½¯ä»¶ä¾›åº”é“¾(Software Supply Chain, SSC)å¸¦æ¥çš„å®‰å…¨éšæ‚£ã€‚é’ˆå¯¹LLMsåœ¨ä»£ç ç”Ÿæˆä¸­å­˜åœ¨çš„è™šå‡ä¿¡æ¯(fabrication)å’Œä¾èµ–è¿‡æ—¶è®­ç»ƒæ•°æ®ç­‰å›ºæœ‰é—®é¢˜ï¼Œè®ºæ–‡ç³»ç»Ÿç ”ç©¶äº†æ¶‰åŠæºä»£ç å¤–éƒ¨ç»„ä»¶åŠæŒç»­é›†æˆ(Continuous Integration)é…ç½®æ–‡ä»¶çš„3å¤§ç±»ã€å…±11ç§æ½œåœ¨çš„SSCå®‰å…¨å¨èƒã€‚é€šè¿‡è®¾è®¡åä¸ºSSCGuardçš„å·¥å…·ï¼Œç ”ç©¶å›¢é˜Ÿåˆ†æäº†GPTå’ŒLlamaç­‰ä¸»æµæ¨¡å‹å¯¹è¶…è¿‡43ä¸‡æ¡æç¤ºè¯çš„å“åº”ï¼Œè¯å®è¿™äº›SSCå¨èƒåœ¨ç”Ÿæˆçš„ä»£ç ä¸­æ™®éä¸”æŒä¹…å­˜åœ¨ï¼Œå¯èƒ½å¯¼è‡´æ”»å‡»è€…åŠ«æŒè½¯ä»¶æˆ–å·¥ä½œæµã€‚ä¸ºäº†ç¼“è§£è¿™äº›é£é™©ï¼Œç ”ç©¶è€…æå‡ºäº†ä¸€ç§åä¸ºChain-of-Confirmationçš„æç¤ºé˜²å¾¡æœºåˆ¶ä»¥å‡å°‘è™šæ„å†…å®¹ï¼Œå¹¶å¼€å‘äº†åŸºäºä¸­é—´ä»¶çš„é˜²å¾¡æ‰‹æ®µï¼Œå‘ç”¨æˆ·è­¦ç¤ºå„ç±»SSCå¨èƒï¼Œæå‡äº†è‡ªåŠ¨ç”Ÿæˆä»£ç çš„å®‰å…¨æ€§ã€‚",
      "categories": [
        "cs.CR",
        "cs.AI"
      ],
      "primary_category": "cs.CR",
      "comment": "",
      "pdf_url": "https://arxiv.org/pdf/2509.20277v1",
      "published_date": "2025-09-24 16:15:17 UTC",
      "updated_date": "2025-09-24 16:15:17 UTC",
      "processing_status": "completed",
      "attempts": 1,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "llm_backup_calls": 0,
      "last_update": "2026-01-24T20:50:36.868548+00:00"
    },
    {
      "arxiv_id": "2509.20270v1",
      "title": "Scan-do Attitude: Towards Autonomous CT Protocol Management using a Large Language Model Agent",
      "title_zh": "Scan-do Attitudeï¼šåŸºäºå¤§è¯­è¨€æ¨¡å‹æ™ºèƒ½ä½“çš„è‡ªä¸»åŒ–CTæ‰«æåè®®ç®¡ç†",
      "authors": [
        "Xingjian Kang",
        "Linda Vorberg",
        "Andreas Maier",
        "Alexander Katzmann",
        "Oliver Taubmann"
      ],
      "abstract": "Managing scan protocols in Computed Tomography (CT), which includes adjusting acquisition parameters or configuring reconstructions, as well as selecting postprocessing tools in a patient-specific manner, is time-consuming and requires clinical as well as technical expertise. At the same time, we observe an increasing shortage of skilled workforce in radiology. To address this issue, a Large Language Model (LLM)-based agent framework is proposed to assist with the interpretation and execution of protocol configuration requests given in natural language or a structured, device-independent format, aiming to improve the workflow efficiency and reduce technologists' workload. The agent combines in-context-learning, instruction-following, and structured toolcalling abilities to identify relevant protocol elements and apply accurate modifications. In a systematic evaluation, experimental results indicate that the agent can effectively retrieve protocol components, generate device compatible protocol definition files, and faithfully implement user requests. Despite demonstrating feasibility in principle, the approach faces limitations regarding syntactic and semantic validity due to lack of a unified device API, and challenges with ambiguous or complex requests. In summary, the findings show a clear path towards LLM-based agents for supporting scan protocol management in CT imaging.",
      "tldr_zh": "è¯¥ç ”ç©¶é’ˆå¯¹è®¡ç®—æœºæ–­å±‚æ‰«æ(Computed Tomography, CT)åè®®ç®¡ç†ä¸­å­˜åœ¨çš„è€—æ—¶é•¿ã€ä¸“ä¸šé—¨æ§›é«˜ä»¥åŠæ”¾å°„ç§‘äººæ‰çŸ­ç¼ºç­‰æŒ‘æˆ˜ï¼Œæå‡ºäº†ä¸€ç§åŸºäºå¤§è¯­è¨€æ¨¡å‹(Large Language Model, LLM)çš„æ™ºèƒ½ä½“æ¡†æ¶ã€‚è¯¥æ¡†æ¶é€šè¿‡ç»“åˆåœ¨ä¸Šä¸‹æ–‡å­¦ä¹ (in-context-learning)ã€æŒ‡ä»¤éµå¾ª(instruction-following)åŠç»“æ„åŒ–å·¥å…·è°ƒç”¨(tool-calling)èƒ½åŠ›ï¼Œå®ç°äº†å¯¹è‡ªç„¶è¯­è¨€æˆ–ç»“æ„åŒ–æ ¼å¼åè®®è¯·æ±‚çš„è‡ªåŠ¨è§£æä¸æ‰§è¡Œã€‚å®éªŒç»“æœéªŒè¯äº†è¯¥æ™ºèƒ½ä½“åœ¨æ£€ç´¢åè®®ç»„ä»¶ã€ç”Ÿæˆè®¾å¤‡å…¼å®¹æ–‡ä»¶åŠå‡†ç¡®è½å®ç”¨æˆ·æŒ‡ä»¤æ–¹é¢çš„æœ‰æ•ˆæ€§ã€‚å°½ç®¡ç”±äºç¼ºä¹ç»Ÿä¸€çš„è®¾å¤‡APIè€Œåœ¨è¯­æ³•è¯­ä¹‰éªŒè¯åŠå¤„ç†å¤æ‚è¯·æ±‚æ—¶å­˜åœ¨ä¸€å®šå±€é™ï¼Œä½†è¯¥æ–¹æ¡ˆä¸ºè‡ªåŠ¨åŒ–CTæ‰«æåè®®ç®¡ç†å¥ å®šäº†åŸºç¡€ã€‚è¯¥ç ”ç©¶å±•ç¤ºäº†LLMæ™ºèƒ½ä½“åœ¨ä¼˜åŒ–æ”¾å°„ç§‘å·¥ä½œæµã€å‡è½»æŠ€æœ¯äººå‘˜è´Ÿæ‹…æ–¹é¢çš„å·¨å¤§æ½œåŠ›ï¼Œä¸ºå®ç°è‡ªä¸»åŒ–åŒ»å­¦å½±åƒç®¡ç†æŒ‡æ˜äº†æ–¹å‘ã€‚",
      "categories": [
        "cs.AI",
        "cs.CL"
      ],
      "primary_category": "cs.AI",
      "comment": "",
      "pdf_url": "https://arxiv.org/pdf/2509.20270v1",
      "published_date": "2025-09-24 16:04:11 UTC",
      "updated_date": "2025-09-24 16:04:11 UTC",
      "processing_status": "completed",
      "attempts": 1,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "llm_backup_calls": 0,
      "last_update": "2026-01-24T20:50:40.295892+00:00"
    },
    {
      "arxiv_id": "2510.00023v2",
      "title": "ToolBrain: A Flexible Reinforcement Learning Framework for Agentic Tools",
      "title_zh": "ToolBrainï¼šé¢å‘æ™ºèƒ½ä½“å·¥å…·çš„çµæ´»å¼ºåŒ–å­¦ä¹ æ¡†æ¶",
      "authors": [
        "Quy Minh Le",
        "Minh Sao Khue Luu",
        "Khanh-Tung Tran",
        "Duc-Hai Nguyen",
        "Hoang-Quoc-Viet Pham",
        "Quan Le",
        "Hoang Thanh Lam",
        "Hoang D. Nguyen"
      ],
      "abstract": "Effective tool use is essential for agentic AI, yet training agents to utilize tools remains challenging due to manually designed rewards, limited training data, and poor multi-tool selection, resulting in slow adaptation, wasted computational resources, and suboptimal performance. We introduce ToolBrain, a lightweight and user-friendly framework for training tool use in agentic models with flexible reinforcement learning, thereby easing the barriers for researchers and practitioners to adapt LLM-based agents to specific domains. It supports a wide range of training strategies, including reinforcement learning algorithms such as GRPO and DPO, as well as supervised learning. ToolBrain enables custom reward callables directly on an agent's execution traces or simply utilizes an automated LLM-as-a-judge system for reward generation. It is packed with useful capabilities, including knowledge distillation from large to small models, automatic task generation from tool descriptions, seamless tool retrieval, efficient fine-tuning pipelines with QLoRA through Unsloth, and quantized inference via bitsandbytes. We demonstrate ToolBrain through an Email Search Agent case study, showing measurable improvements in tool-use skills under a realistic workflow, while keeping the codebase simple and extensible. Our framework is publicly available at https://toolbrain.org/.",
      "tldr_zh": "è¯¥ç ”ç©¶æ¨å‡ºäº†ToolBrainï¼Œè¿™æ˜¯ä¸€ä¸ªè½»é‡çº§ä¸”ç”¨æˆ·å‹å¥½çš„æ¡†æ¶ï¼Œæ—¨åœ¨é€šè¿‡çµæ´»çš„å¼ºåŒ–å­¦ä¹ (Reinforcement Learning)è®­ç»ƒæ™ºèƒ½ä½“(Agent)çš„å·¥å…·ä½¿ç”¨èƒ½åŠ›ï¼Œä»è€Œé™ä½å°†å¤§è¯­è¨€æ¨¡å‹(LLM)é€‚é…åˆ°ç‰¹å®šé¢†åŸŸçš„é—¨æ§›ã€‚è¯¥æ¡†æ¶æ”¯æŒåŒ…æ‹¬GRPOã€DPOåœ¨å†…çš„å¤šç§å¼ºåŒ–å­¦ä¹ ç®—æ³•ä»¥åŠç›‘ç£å­¦ä¹ ï¼Œå¹¶å…è®¸ç›´æ¥åœ¨æ‰§è¡Œè½¨è¿¹ä¸Šå®šä¹‰å¥–åŠ±å‡½æ•°æˆ–åˆ©ç”¨LLM-as-a-judgeç³»ç»Ÿè‡ªåŠ¨ç”Ÿæˆå¥–åŠ±ã€‚ToolBrainé›†æˆäº†çŸ¥è¯†è’¸é¦(Knowledge Distillation)ã€åŸºäºå·¥å…·æè¿°çš„è‡ªåŠ¨ä»»åŠ¡ç”Ÿæˆã€æ— ç¼å·¥å…·æ£€ç´¢ä»¥åŠé€šè¿‡Unslothå®ç°çš„QLoRAé«˜æ•ˆå¾®è°ƒç­‰åŠŸèƒ½ã€‚é€šè¿‡ç”µå­é‚®ä»¶æœç´¢æ™ºèƒ½ä½“(Email Search Agent)çš„æ¡ˆä¾‹ç ”ç©¶ï¼Œå®éªŒè¯æ˜ToolBrainåœ¨ä¿æŒä»£ç åº“ç®€æ´å’Œå¯æ‰©å±•æ€§çš„åŒæ—¶ï¼Œæ˜¾è‘—æå‡äº†çœŸå®å·¥ä½œæµä¸­çš„å·¥å…·ä½¿ç”¨æŠ€èƒ½ã€‚è¯¥æ¡†æ¶é€šè¿‡æœ‰æ•ˆè§£å†³æ‰‹åŠ¨å¥–åŠ±è®¾è®¡ã€è®­ç»ƒæ•°æ®æœ‰é™ä»¥åŠå¤šå·¥å…·é€‰æ‹©å›°éš¾ç­‰æŒ‘æˆ˜ï¼Œä¸ºç ”ç©¶äººå‘˜å’Œä»ä¸šè€…æä¾›äº†é«˜æ•ˆæ„å»ºæ™ºèƒ½å·¥å…·ç³»ç»Ÿçš„å·¥å…·ã€‚",
      "categories": [
        "cs.AI"
      ],
      "primary_category": "cs.AI",
      "comment": "",
      "pdf_url": "https://arxiv.org/pdf/2510.00023v2",
      "published_date": "2025-09-24 16:01:05 UTC",
      "updated_date": "2026-01-12 04:21:01 UTC",
      "processing_status": "completed",
      "attempts": 1,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "llm_backup_calls": 0,
      "last_update": "2026-01-24T20:50:43.985749+00:00"
    },
    {
      "arxiv_id": "2509.21404v1",
      "title": "How Large Language Models Need Symbolism",
      "title_zh": "å¤§è¯­è¨€æ¨¡å‹ä¸ºä½•éœ€è¦ç¬¦å·ä¸»ä¹‰",
      "authors": [
        "Xiaotie Deng",
        "Hanyu Li"
      ],
      "abstract": "We argue that AI's future requires more than scaling. To unlock genuine discovery, large language models need a compass: human-crafted symbols to guide their powerful but blind intuition.",
      "tldr_zh": "è¯¥ç ”ç©¶æ¢è®¨äº†äººå·¥æ™ºèƒ½æœªæ¥çš„å‘å±•è·¯å¾„ï¼ŒæŒ‡å‡ºå•çº¯ä¾é è§„æ¨¡æ‰©å¼ (Scaling)ä¸è¶³ä»¥æ¨åŠ¨é¢†åŸŸå®ç°çœŸæ­£çš„æŠ€æœ¯çªç ´ã€‚ä½œè€…è®¤ä¸ºï¼Œä¸ºäº†è§£é”æ·±åˆ»çš„å‘ç°èƒ½åŠ›ï¼Œå¤§å‹è¯­è¨€æ¨¡å‹(Large Language Models, LLMs)éœ€è¦å¼•å…¥äººç±»æ„å»ºçš„ç¬¦å·ç³»ç»Ÿ(human-crafted symbols)ä½œä¸ºå¯¼èˆªå·¥å…·ã€‚è¿™äº›ç¬¦å·èƒ½å¤Ÿä¸ºLLMså¼ºå¤§ä½†å¾€å¾€å…·æœ‰ç›²ç›®æ€§çš„ç›´è§‰æä¾›æŒ‡å¼•ï¼Œç¡®ä¿æ¨¡å‹åœ¨å¤„ç†å¤æ‚æ¨ç†ä»»åŠ¡æ—¶å…·å¤‡æ–¹å‘æ„Ÿã€‚é€šè¿‡å°†ç¬¦å·ä¸»ä¹‰(Symbolism)ä¸è¿æ¥ä¸»ä¹‰ç»“åˆï¼Œç ”ç©¶ä¸ºè§£å†³å½“å‰æ¨¡å‹åœ¨é€»è¾‘ä¸¥å¯†æ€§å’ŒçŸ¥è¯†å‘ç°ä¸­çš„å±€é™æ€§æä¾›äº†å…³é”®è§è§£ã€‚",
      "categories": [
        "cs.CL",
        "cs.AI"
      ],
      "primary_category": "cs.CL",
      "comment": "",
      "pdf_url": "https://arxiv.org/pdf/2509.21404v1",
      "published_date": "2025-09-24 15:51:42 UTC",
      "updated_date": "2025-09-24 15:51:42 UTC",
      "processing_status": "completed",
      "attempts": 1,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "llm_backup_calls": 0,
      "last_update": "2026-01-24T20:50:55.692645+00:00"
    },
    {
      "arxiv_id": "2509.20253v2",
      "title": "AnchDrive: Bootstrapping Diffusion Policies with Hybrid Trajectory Anchors for End-to-End Driving",
      "title_zh": "AnchDriveï¼šåŸºäºæ··åˆè½¨è¿¹é”šç‚¹å¼•å¯¼æ‰©æ•£ç­–ç•¥çš„ç«¯åˆ°ç«¯é©¾é©¶",
      "authors": [
        "Jinhao Chai",
        "Anqing Jiang",
        "Hao Jiang",
        "Shiyi Mu",
        "Zichong Gu",
        "Hao Sun",
        "Shugong Xu"
      ],
      "abstract": "End-to-end multi-modal planning has become a transformative paradigm in autonomous driving, effectively addressing behavioral multi-modality and the generalization challenge in long-tail scenarios. We propose AnchDrive, a framework for end-to-end driving that effectively bootstraps a diffusion policy to mitigate the high computational cost of traditional generative models. Rather than denoising from pure noise, AnchDrive initializes its planner with a rich set of hybrid trajectory anchors. These anchors are derived from two complementary sources: a static vocabulary of general driving priors and a set of dynamic, context-aware trajectories. The dynamic trajectories are decoded in real-time by a Transformer that processes dense and sparse perceptual features. The diffusion model then learns to refine these anchors by predicting a distribution of trajectory offsets, enabling fine-grained refinement. This anchor-based bootstrapping design allows for efficient generation of diverse, high-quality trajectories. Experiments on the NAVSIM benchmark confirm that AnchDrive sets a new state-of-the-art and shows strong generalizability",
      "tldr_zh": "è¯¥ç ”ç©¶æå‡ºäº† AnchDriveï¼Œè¿™æ˜¯ä¸€ä¸ªç”¨äºç«¯åˆ°ç«¯(End-to-End)è‡ªåŠ¨é©¾é©¶çš„æ¡†æ¶ï¼Œæ—¨åœ¨é€šè¿‡å¼•å¯¼æ‰©æ•£ç­–ç•¥(Diffusion Policies)æ¥é™ä½ä¼ ç»Ÿç”Ÿæˆæ¨¡å‹çš„é«˜è®¡ç®—æˆæœ¬ã€‚è¯¥æ¡†æ¶ä¸å†ä»çº¯å™ªå£°ä¸­è¿›è¡Œå»å™ªï¼Œè€Œæ˜¯åˆ©ç”¨æ··åˆè½¨è¿¹é”šç‚¹(Hybrid Trajectory Anchors)æ¥åˆå§‹åŒ–å…¶è§„åˆ’å™¨ï¼Œè¿™äº›é”šç‚¹ç»“åˆäº†é™æ€çš„é€šç”¨é©¾é©¶å…ˆéªŒè¯æ±‡è¡¨å’Œç”± Transformer å®æ—¶è§£ç çš„åŠ¨æ€ä¸Šä¸‹æ–‡æ„ŸçŸ¥è½¨è¿¹ã€‚æ‰©æ•£æ¨¡å‹éšåé€šè¿‡é¢„æµ‹è½¨è¿¹åç§»(Trajectory Offsets)çš„åˆ†å¸ƒæ¥ç²¾ç‚¼è¿™äº›é”šç‚¹ï¼Œä»è€Œå®ç°ç»†ç²’åº¦ä¸”é«˜æ•ˆçš„è½¨è¿¹ä¼˜åŒ–ã€‚è¿™ç§åŸºäºé”šç‚¹çš„å¼•å¯¼è®¾è®¡ç¡®ä¿äº†æ¨¡å‹èƒ½å¤Ÿç”Ÿæˆå¤šæ ·åŒ–ä¸”é«˜è´¨é‡çš„é©¾é©¶è½¨è¿¹ã€‚åœ¨ NAVSIM åŸºå‡†æµ‹è¯•ä¸Šçš„å®éªŒç»“æœè¯æ˜ï¼ŒAnchDrive è¾¾åˆ°äº†å½“å‰çš„æœ€ä¼˜æ€§èƒ½æ°´å¹³(SOTA)ï¼Œå¹¶å±•ç°å‡ºæå¼ºçš„æ³›åŒ–èƒ½åŠ›ã€‚",
      "categories": [
        "cs.RO",
        "cs.AI"
      ],
      "primary_category": "cs.RO",
      "comment": "",
      "pdf_url": "https://arxiv.org/pdf/2509.20253v2",
      "published_date": "2025-09-24 15:38:41 UTC",
      "updated_date": "2025-09-26 11:00:50 UTC",
      "processing_status": "completed",
      "attempts": 1,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "llm_backup_calls": 0,
      "last_update": "2026-01-24T20:50:51.182650+00:00"
    },
    {
      "arxiv_id": "2509.20240v1",
      "title": "A HyperGraphMamba-Based Multichannel Adaptive Model for ncRNA Classification",
      "title_zh": "åŸºäº HyperGraphMamba çš„å¤šé€šé“è‡ªé€‚åº” ncRNA åˆ†ç±»æ¨¡å‹",
      "authors": [
        "Xin An",
        "Ruijie Li",
        "Qiao Ning",
        "Hui Li",
        "Qian Ma",
        "Shikai Guo"
      ],
      "abstract": "Non-coding RNAs (ncRNAs) play pivotal roles in gene expression regulation and the pathogenesis of various diseases. Accurate classification of ncRNAs is essential for functional annotation and disease diagnosis. To address existing limitations in feature extraction depth and multimodal fusion, we propose HGMamba-ncRNA, a HyperGraphMamba-based multichannel adaptive model, which integrates sequence, secondary structure, and optionally available expression features of ncRNAs to enhance classification performance. Specifically, the sequence of ncRNA is modeled using a parallel Multi-scale Convolution and LSTM architecture (MKC-L) to capture both local patterns and long-range dependencies of nucleotides. The structure modality employs a multi-scale graph transformer (MSGraphTransformer) to represent the multi-level topological characteristics of ncRNA secondary structures. The expression modality utilizes a Chebyshev Polynomial-based Kolmogorov-Arnold Network (CPKAN) to effectively model and interpret high-dimensional expression profiles. Finally, by incorporating virtual nodes to facilitate efficient and comprehensive multimodal interaction, HyperGraphMamba is proposed to adaptively align and integrate multichannel heterogeneous modality features. Experiments conducted on three public datasets demonstrate that HGMamba-ncRNA consistently outperforms state-of-the-art methods in terms of accuracy and other metrics. Extensive empirical studies further confirm the model's robustness, effectiveness, and strong transferability, offering a novel and reliable strategy for complex ncRNA functional classification. Code and datasets are available at https://anonymous.4open.science/r/HGMamba-ncRNA-94D0.",
      "tldr_zh": "è¯¥ç ”ç©¶æå‡ºäº†HGMamba-ncRNAï¼Œä¸€ç§åŸºäºHyperGraphMambaçš„å¤šé€šé“è‡ªé€‚åº”æ¨¡å‹ï¼Œæ—¨åœ¨è§£å†³éç¼–ç RNA (ncRNA) åˆ†ç±»ä¸­ç‰¹å¾æå–æ·±åº¦å’Œå¤šæ¨¡æ€èåˆçš„å±€é™æ€§ã€‚æ¨¡å‹é€šè¿‡æ•´åˆåºåˆ—ã€äºŒçº§ç»“æ„åŠå¯é€‰çš„è¡¨è¾¾ç‰¹å¾ï¼Œåˆ©ç”¨MKC-Læ¶æ„æ•è·æ ¸è‹·é…¸çš„å±€éƒ¨æ¨¡å¼ä¸é•¿ç¨‹ä¾èµ–ï¼Œå¹¶é‡‡ç”¨MSGraphTransformeræå–ç»“æ„æ¨¡æ€çš„å¤šçº§æ‹“æ‰‘ç‰¹å¾ã€‚é’ˆå¯¹é«˜ç»´è¡¨è¾¾è°±ï¼Œç ”ç©¶å¼•å…¥äº†åŸºäºåˆ‡æ¯”é›ªå¤«å¤šé¡¹å¼çš„Kolmogorov-Arnoldç½‘ç»œ (CPKAN)ï¼Œå¹¶é€šè¿‡ç»“åˆè™šæ‹ŸèŠ‚ç‚¹çš„HyperGraphMambaå®ç°å¤šé€šé“å¼‚æ„æ¨¡æ€ç‰¹å¾çš„è‡ªé€‚åº”å¯¹é½ä¸æ·±åº¦äº¤äº’ã€‚åœ¨ä¸‰ä¸ªå…¬å¼€æ•°æ®é›†ä¸Šçš„å®éªŒè¡¨æ˜ï¼ŒHGMamba-ncRNAåœ¨å‡†ç¡®ç‡ç­‰æŒ‡æ ‡ä¸Šå‡ä¼˜äºç°æœ‰çš„SOTAæ–¹æ³•ã€‚è¯¥æ¨¡å‹è¡¨ç°å‡ºæå¼ºçš„é²æ£’æ€§ã€æœ‰æ•ˆæ€§å’Œè¿ç§»èƒ½åŠ›ï¼Œä¸ºå¤æ‚çš„ncRNAåŠŸèƒ½åˆ†ç±»å’Œç–¾ç—…è¯Šæ–­æä¾›äº†ä¸€ç§æ–°é¢–ä¸”å¯é çš„è®¡ç®—ç­–ç•¥ã€‚",
      "categories": [
        "cs.LG",
        "cs.AI"
      ],
      "primary_category": "cs.LG",
      "comment": "9 pages, 17 figures (including subfigures), 1 table. Xin An and Ruijie Li contributed equally to this work and should be considered co-first authors",
      "pdf_url": "https://arxiv.org/pdf/2509.20240v1",
      "published_date": "2025-09-24 15:31:49 UTC",
      "updated_date": "2025-09-24 15:31:49 UTC",
      "processing_status": "completed",
      "attempts": 1,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "llm_backup_calls": 0,
      "last_update": "2026-01-24T20:51:14.090850+00:00"
    },
    {
      "arxiv_id": "2509.20234v5",
      "title": "ImageNet-trained CNNs are not biased towards texture: Revisiting feature reliance through controlled suppression",
      "title_zh": "ImageNet è®­ç»ƒçš„ CNN å¹¶éåå‘çº¹ç†ï¼šé€šè¿‡å—æ§æŠ‘åˆ¶é‡æ–°å®¡è§†ç‰¹å¾ä¾èµ–",
      "authors": [
        "Tom Burgert",
        "Oliver Stoll",
        "Paolo Rota",
        "BegÃ¼m Demir"
      ],
      "abstract": "The hypothesis that Convolutional Neural Networks (CNNs) are inherently texture-biased has shaped much of the discourse on feature use in deep learning. We revisit this hypothesis by examining limitations in the cue-conflict experiment by Geirhos et al. To address these limitations, we propose a domain-agnostic framework that quantifies feature reliance through systematic suppression of shape, texture, and color cues, avoiding the confounds of forced-choice conflicts. By evaluating humans and neural networks under controlled suppression conditions, we find that CNNs are not inherently texture-biased but predominantly rely on local shape features. Nonetheless, this reliance can be substantially mitigated through modern training strategies or architectures (ConvNeXt, ViTs). We further extend the analysis across computer vision, medical imaging, and remote sensing, revealing that reliance patterns differ systematically: computer vision models prioritize shape, medical imaging models emphasize color, and remote sensing models exhibit a stronger reliance on texture. Code is available at https://github.com/tomburgert/feature-reliance.",
      "tldr_zh": "è¯¥ç ”ç©¶æŒ‘æˆ˜äº†å·ç§¯ç¥ç»ç½‘ç»œ(CNNs)æœ¬è´¨ä¸Šå…·æœ‰çº¹ç†åè§(texture-biased)çš„ä¼ ç»Ÿå‡è®¾ï¼Œå¹¶é‡æ–°å®¡æŸ¥äº†ç»å…¸æç¤ºå†²çª(cue-conflict)å®éªŒçš„å±€é™æ€§ã€‚ä½œè€…æå‡ºäº†ä¸€ç§åŸŸæ— å…³çš„æ¡†æ¶ï¼Œé€šè¿‡ç³»ç»Ÿæ€§åœ°æŠ‘åˆ¶å½¢çŠ¶(shape)ã€çº¹ç†(texture)å’Œé¢œè‰²(color)çº¿ç´¢æ¥é‡åŒ–ç‰¹å¾ä¾èµ–ï¼Œæœ‰æ•ˆé¿å…äº†å®éªŒæ··æ·†ã€‚ç ”ç©¶å‘ç°CNNså¹¶éå¤©ç”Ÿåå‘çº¹ç†ï¼Œè€Œæ˜¯ä¸»è¦ä¾èµ–å±€éƒ¨å½¢çŠ¶(local shape)ç‰¹å¾ï¼Œä¸”è¿™ç§ä¾èµ–å¯ä»¥é€šè¿‡ConvNeXtå’ŒViTsç­‰ç°ä»£æ¶æ„æˆ–è®­ç»ƒç­–ç•¥å¾—åˆ°æ˜¾è‘—ç¼“è§£ã€‚è¿›ä¸€æ­¥çš„è·¨é¢†åŸŸåˆ†ææ­ç¤ºäº†ä¸åŒåº”ç”¨åœºæ™¯ä¸‹æ¨¡å‹ç‰¹å¾åå¥½çš„ç³»ç»Ÿæ€§å·®å¼‚ï¼šè®¡ç®—æœºè§†è§‰æ¨¡å‹ä¼˜å…ˆè€ƒè™‘å½¢çŠ¶ï¼ŒåŒ»å­¦å½±åƒæ¨¡å‹ä¾§é‡é¢œè‰²ï¼Œè€Œé¥æ„Ÿæ¨¡å‹åˆ™è¡¨ç°å‡ºæ›´å¼ºçš„çº¹ç†ä¾èµ–ã€‚è¯¥ç ”ç©¶ä¸ä»…ä¿®æ­£äº†å¯¹CNNsç‰¹å¾åˆ©ç”¨æœºåˆ¶çš„è®¤çŸ¥ï¼Œè¿˜ä¸ºä¸åŒé¢†åŸŸæ¨¡å‹çš„ç‰¹å¾é€‰æ‹©ä¼˜åŒ–æä¾›äº†é‡è¦è§è§£ã€‚",
      "categories": [
        "cs.CV",
        "cs.AI",
        "cs.LG"
      ],
      "primary_category": "cs.CV",
      "comment": "Accepted at NeurIPS 2025 (oral)",
      "pdf_url": "https://arxiv.org/pdf/2509.20234v5",
      "published_date": "2025-09-24 15:24:43 UTC",
      "updated_date": "2026-01-09 16:41:39 UTC",
      "processing_status": "completed",
      "attempts": 1,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "llm_backup_calls": 0,
      "last_update": "2026-01-24T20:51:17.985810+00:00"
    },
    {
      "arxiv_id": "2509.20230v3",
      "title": "Beyond Sharp Minima: Robust LLM Unlearning via Feedback-Guided Multi-Point Optimization",
      "title_zh": "è¶…è¶Šå°–é”æå°å€¼ï¼šåŸºäºåé¦ˆå¼•å¯¼å¤šç‚¹ä¼˜åŒ–çš„é²æ£’å¤§è¯­è¨€æ¨¡å‹æœºå™¨é—å¿˜",
      "authors": [
        "Wenhan Wu",
        "Zheyuan Liu",
        "Chongyang Gao",
        "Ren Wang",
        "Kaize Ding"
      ],
      "abstract": "Current LLM unlearning methods face a critical security vulnerability that undermines their fundamental purpose: while they appear to successfully remove sensitive or harmful knowledge, this ``forgotten\" information remains precariously recoverable through relearning attacks. We identify that the root cause is that conventional methods optimizing the forgetting loss at individual data points will drive model parameters toward sharp minima in the loss landscape. In these unstable regions, even minimal parameter perturbations can drastically alter the model's behaviors. Consequently, relearning attacks exploit this vulnerability by using just a few fine-tuning samples to navigate the steep gradients surrounding these unstable regions, thereby rapidly recovering knowledge that was supposedly erased. This exposes a critical robustness gap between apparent unlearning and actual knowledge removal. To address this issue, we propose StableUN, a bi-level feedback-guided optimization framework that explicitly seeks more stable parameter regions via neighborhood-aware optimization. It integrates forgetting feedback, which uses adversarial perturbations to probe parameter neighborhoods, with remembering feedback to preserve model utility, aligning the two objectives through gradient projection. Experiments on WMDP and MUSE benchmarks demonstrate that our method is significantly more robust against both relearning and jailbreaking attacks while maintaining competitive utility performance.",
      "tldr_zh": "è¯¥ç ”ç©¶æŒ‡å‡ºï¼Œç°æœ‰çš„å¤§è¯­è¨€æ¨¡å‹(LLM)é—å¿˜(unlearning)æ–¹æ³•å­˜åœ¨ä¸¥é‡çš„å®‰å…¨æ¼æ´ï¼Œå³è¢«â€œé—å¿˜â€çš„çŸ¥è¯†åœ¨å—åˆ°é‡æ–°å­¦ä¹ æ”»å‡»(relearning attacks)æ—¶ææ˜“è¢«æ¢å¤ã€‚ä½œè€…å‘ç°å…¶æ ¹æœ¬åŸå› åœ¨äºä¼ ç»Ÿæ–¹æ³•åœ¨ä¼˜åŒ–å•ä¸ªæ•°æ®ç‚¹çš„é—å¿˜æŸå¤±æ—¶ï¼Œä¼šå°†æ¨¡å‹å‚æ•°æ¨å‘æŸå¤±å¹³é¢ä¸Šçš„å°–é”æå°å€¼(sharp minima)åŒºåŸŸï¼Œå¯¼è‡´æ¨¡å‹è¡Œä¸ºåœ¨å¾®å°å‚æ•°æ‰°åŠ¨ä¸‹å°±ä¼šå‘ç”Ÿå‰§å˜ã€‚ä¸ºæ­¤ï¼Œè®ºæ–‡æå‡ºäº†StableUNï¼Œè¿™æ˜¯ä¸€ä¸ªåŒå±‚åé¦ˆå¼•å¯¼çš„ä¼˜åŒ–æ¡†æ¶ï¼Œé€šè¿‡é‚»åŸŸæ„ŸçŸ¥ä¼˜åŒ–(neighborhood-aware optimization)æ¥æ˜¾å¼å¯»æ‰¾æ›´ç¨³å®šçš„å‚æ•°åŒºåŸŸã€‚è¯¥æ¡†æ¶æ•´åˆäº†åˆ©ç”¨å¯¹æŠ—æ€§æ‰°åŠ¨æ¢æµ‹å‚æ•°é‚»åŸŸçš„é—å¿˜åé¦ˆä»¥åŠæ—¨åœ¨ä¿ç•™æ¨¡å‹æ•ˆç”¨çš„è®°å¿†åé¦ˆï¼Œå¹¶é€šè¿‡æ¢¯åº¦æŠ•å½±(gradient projection)ä½¿ä¸¤ä¸ªç›®æ ‡è¾¾æˆä¸€è‡´ã€‚åœ¨WMDPå’ŒMUSEåŸºå‡†æµ‹è¯•ä¸Šçš„å®éªŒè¯æ˜ï¼Œè¯¥æ–¹æ³•åœ¨æŠµå¾¡é‡æ–°å­¦ä¹ å’Œè¶Šç‹±æ”»å‡»(jailbreaking attacks)æ–¹é¢æ˜¾è‘—å¢å¼ºäº†é²æ£’æ€§ã€‚è¯¥ç ”ç©¶æˆåŠŸå¡«è¡¥äº†è¡¨è§‚é—å¿˜ä¸å®é™…çŸ¥è¯†ç§»é™¤ä¹‹é—´çš„å…³é”®é²æ£’æ€§å·®è·ï¼ŒåŒæ—¶ä¿æŒäº†æ¨¡å‹ä¼˜ç§€çš„å®ç”¨æ€§èƒ½ã€‚",
      "categories": [
        "cs.LG",
        "cs.AI"
      ],
      "primary_category": "cs.LG",
      "comment": "",
      "pdf_url": "https://arxiv.org/pdf/2509.20230v3",
      "published_date": "2025-09-24 15:23:46 UTC",
      "updated_date": "2025-09-30 13:04:46 UTC",
      "processing_status": "completed",
      "attempts": 1,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "llm_backup_calls": 0,
      "last_update": "2026-01-24T20:51:23.887781+00:00"
    },
    {
      "arxiv_id": "2509.20225v1",
      "title": "Multimodal Representation-disentangled Information Bottleneck for Multimodal Recommendation",
      "title_zh": "é¢å‘å¤šæ¨¡æ€æ¨èçš„å¤šæ¨¡æ€è¡¨å¾è§£è€¦ä¿¡æ¯ç“¶é¢ˆ",
      "authors": [
        "Hui Wang",
        "Jinghui Qin",
        "Wushao Wen",
        "Qingling Li",
        "Shanshan Zhong",
        "Zhongzhan Huang"
      ],
      "abstract": "Multimodal data has significantly advanced recommendation systems by integrating diverse information sources to model user preferences and item characteristics. However, these systems often struggle with redundant and irrelevant information, which can degrade performance. Most existing methods either fuse multimodal information directly or use rigid architectural separation for disentanglement, failing to adequately filter noise and model the complex interplay between modalities. To address these challenges, we propose a novel framework, the Multimodal Representation-disentangled Information Bottleneck (MRdIB). Concretely, we first employ a Multimodal Information Bottleneck to compress the input representations, effectively filtering out task-irrelevant noise while preserving rich semantic information. Then, we decompose the information based on its relationship with the recommendation target into unique, redundant, and synergistic components. We achieve this decomposition with a series of constraints: a unique information learning objective to preserve modality-unique signals, a redundant information learning objective to minimize overlap, and a synergistic information learning objective to capture emergent information. By optimizing these objectives, MRdIB guides a model to learn more powerful and disentangled representations. Extensive experiments on several competitive models and three benchmark datasets demonstrate the effectiveness and versatility of our MRdIB in enhancing multimodal recommendation.",
      "tldr_zh": "è¯¥ç ”ç©¶é’ˆå¯¹å¤šæ¨¡æ€æ¨èç³»ç»Ÿä¸­å­˜åœ¨çš„å†—ä½™å’Œæ— å…³ä¿¡æ¯å¹²æ‰°æ€§èƒ½çš„é—®é¢˜ï¼ŒæŒ‡å‡ºç°æœ‰æ–¹æ³•åœ¨è¿‡æ»¤å™ªå£°å’Œå»ºæ¨¡æ¨¡æ€é—´å¤æ‚ç›¸äº’ä½œç”¨æ–¹é¢çš„ä¸è¶³ã€‚ä¸ºæ­¤ï¼Œä½œè€…æå‡ºäº†å¤šæ¨¡æ€è¡¨ç¤ºè§£è€¦ä¿¡æ¯ç“¶é¢ˆ (Multimodal Representation-disentangled Information Bottleneck, MRdIB) æ¡†æ¶ã€‚è¯¥æ¡†æ¶é¦–å…ˆåˆ©ç”¨ Multimodal Information Bottleneck å¯¹è¾“å…¥è¡¨ç¤ºè¿›è¡Œå‹ç¼©ï¼Œåœ¨ä¿ç•™ä¸°å¯Œè¯­ä¹‰ä¿¡æ¯çš„åŒæ—¶æœ‰æ•ˆè¿‡æ»¤æ‰ä¸ä»»åŠ¡æ— å…³çš„å™ªå£°ã€‚éšåï¼ŒMRdIB æ ¹æ®ä¿¡æ¯ä¸æ¨èç›®æ ‡çš„å…³ç³»ï¼Œé€šè¿‡ä¸€ç³»åˆ—çº¦æŸå°†å…¶åˆ†è§£ä¸ºå”¯ä¸€ (Unique)ã€å†—ä½™ (Redundant) å’ŒååŒ (Synergistic) ä¸‰ä¸ªç»„æˆéƒ¨åˆ†ã€‚é€šè¿‡ä¼˜åŒ–æ¨¡æ€ç‹¬ç‰¹ä¿¡å·ä¿ç•™ã€é‡å ä¿¡æ¯æœ€å°åŒ–åŠæ¶Œç°ä¿¡æ¯æ•è·çš„å­¦ä¹ ç›®æ ‡ï¼ŒMRdIB å¼•å¯¼æ¨¡å‹å­¦ä¹ æ›´å¼ºå¤§ä¸”è§£è€¦çš„è¡¨ç¤ºã€‚åœ¨ä¸‰ä¸ªåŸºå‡†æ•°æ®é›†ä¸Šçš„å¹¿æ³›å®éªŒè¯æ˜äº†è¯¥æ¡†æ¶åœ¨å¢å¼ºå¤šæ¨¡æ€æ¨èæ€§èƒ½æ–¹é¢çš„æœ‰æ•ˆæ€§å’Œé€šç”¨æ€§ã€‚",
      "categories": [
        "cs.IR",
        "cs.AI"
      ],
      "primary_category": "cs.IR",
      "comment": "",
      "pdf_url": "https://arxiv.org/pdf/2509.20225v1",
      "published_date": "2025-09-24 15:18:32 UTC",
      "updated_date": "2025-09-24 15:18:32 UTC",
      "processing_status": "completed",
      "attempts": 1,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "llm_backup_calls": 0,
      "last_update": "2026-01-24T20:51:35.291832+00:00"
    },
    {
      "arxiv_id": "2509.20218v1",
      "title": "Design Insights and Comparative Evaluation of a Hardware-Based Cooperative Perception Architecture for Lane Change Prediction",
      "title_zh": "é¢å‘æ¢é“é¢„æµ‹çš„ç¡¬ä»¶ååŒæ„ŸçŸ¥æ¶æ„ï¼šè®¾è®¡å¯ç¤ºä¸å¯¹æ¯”è¯„ä¼°",
      "authors": [
        "Mohamed Manzour",
        "Catherine M. Elias",
        "Omar M. Shehata",
        "RubÃ©n Izquierdo",
        "Miguel Ãngel Sotelo"
      ],
      "abstract": "Research on lane change prediction has gained attention in the last few years. Most existing works in this area have been conducted in simulation environments or with pre-recorded datasets, these works often rely on simplified assumptions about sensing, communication, and traffic behavior that do not always hold in practice. Real-world deployments of lane-change prediction systems are relatively rare, and when they are reported, the practical challenges, limitations, and lessons learned are often under-documented. This study explores cooperative lane-change prediction through a real hardware deployment in mixed traffic and shares the insights that emerged during implementation and testing. We highlight the practical challenges we faced, including bottlenecks, reliability issues, and operational constraints that shaped the behavior of the system. By documenting these experiences, the study provides guidance for others working on similar pipelines.",
      "tldr_zh": "è¯¥ç ”ç©¶è¯„ä¼°äº†ä¸€ç§åŸºäºç¡¬ä»¶çš„ååŒæ„ŸçŸ¥æ¶æ„(Cooperative Perception Architecture)ï¼Œæ—¨åœ¨è§£å†³è½¦é“å˜æ›´é¢„æµ‹(Lane Change Prediction)é¢†åŸŸç°æœ‰ç ”ç©¶è¿‡åº¦ä¾èµ–ä»¿çœŸç¯å¢ƒæˆ–é¢„å½•æ•°æ®é›†è€Œå¿½è§†å®é™…æŒ‘æˆ˜çš„é—®é¢˜ã€‚ä½œè€…åœ¨çœŸå®çš„æ··åˆäº¤é€š(mixed traffic)ç¯å¢ƒä¸­è¿›è¡Œäº†ç¡¬ä»¶éƒ¨ç½²ï¼Œæ·±å…¥æ¢è®¨äº†ç³»ç»Ÿåœ¨å®æ–½ä¸æµ‹è¯•è¿‡ç¨‹ä¸­é¢ä¸´çš„ç“¶é¢ˆã€å¯é æ€§æŒ‘æˆ˜åŠæ“ä½œçº¦æŸã€‚é€šè¿‡å¯¹æ¯”è¯„ä¼°å’Œç»éªŒæ€»ç»“ï¼Œè¯¥ç ”ç©¶è¯¦ç»†è®°å½•äº†å½±å“ç³»ç»Ÿè¡Œä¸ºçš„å…³é”®å› ç´ ï¼Œå¹¶ä¸ºç›¸å…³é¢†åŸŸçš„å·¥ç¨‹å®è·µæä¾›äº†å®è´µçš„å®è·µæŒ‡å—ã€‚è¯¥å·¥ä½œä¸ä»…å¡«è¡¥äº†çœŸå®åœºæ™¯ä¸‹ååŒæ„ŸçŸ¥ç³»ç»Ÿéƒ¨ç½²çš„æ–‡çŒ®ç©ºç™½ï¼Œè¿˜ä¸ºæœªæ¥æ„å»ºé²æ£’çš„è‡ªåŠ¨é©¾é©¶é¢„æµ‹æµæ°´çº¿æä¾›äº†é‡è¦çš„è®¾è®¡æ´å¯Ÿã€‚",
      "categories": [
        "cs.AI",
        "cs.AR",
        "cs.CV",
        "cs.LG"
      ],
      "primary_category": "cs.AI",
      "comment": "",
      "pdf_url": "https://arxiv.org/pdf/2509.20218v1",
      "published_date": "2025-09-24 15:15:05 UTC",
      "updated_date": "2025-09-24 15:15:05 UTC",
      "processing_status": "completed",
      "attempts": 1,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "llm_backup_calls": 0,
      "last_update": "2026-01-24T20:51:36.083498+00:00"
    },
    {
      "arxiv_id": "2509.20215v2",
      "title": "The Cream Rises to the Top: Efficient Reranking Method for Verilog Code Generation",
      "title_zh": "è„±é¢–è€Œå‡ºï¼šé«˜æ•ˆçš„ Verilog ä»£ç ç”Ÿæˆé‡æ’åºæ–¹æ³•",
      "authors": [
        "Guang Yang",
        "Wei Zheng",
        "Xiang Chen",
        "Yifan Sun",
        "Fengji Zhang",
        "Terry Yue Zhuo"
      ],
      "abstract": "LLMs face significant challenges in Verilog generation due to limited domain-specific knowledge. While sampling techniques improve pass@k metrics, hardware engineers need one trustworthy solution rather than uncertain candidates. To bridge this gap, we formulate it as a semantic alignment problem between requirements and Verilog implementations, and propose VCD-RNK, a discriminator model tailored for efficient Verilog code reranking. Specifically, VCD-RNKincorporates Verilog-specific reasoning by distilling expert knowledge across three dimensions: code semantic analysis, test case generation, and functional correctness assessment. By explicitly simulating the above reasoning processes during inference, VCD-RNK effectively avoids computationally intensive test execution in existing methods.",
      "tldr_zh": "è¯¥ç ”ç©¶é’ˆå¯¹å¤§è¯­è¨€æ¨¡å‹(LLMs)åœ¨Verilogä»£ç ç”Ÿæˆä¸­å› é¢†åŸŸçŸ¥è¯†åŒ®ä¹è€Œå¯¼è‡´çš„å¯é æ€§ä¸è¶³é—®é¢˜ï¼Œæå‡ºäº†åä¸ºVCD-RNKçš„é«˜æ•ˆé‡æ’åº(reranking)æ–¹æ³•ã€‚ç ”ç©¶è€…å°†æ­¤é—®é¢˜å®šä¹‰ä¸ºéœ€æ±‚ä¸ä»£ç å®ç°ä¹‹é—´çš„è¯­ä¹‰å¯¹é½(semantic alignment)æŒ‘æˆ˜ï¼Œå¹¶å¼€å‘äº†ä¸“é—¨çš„åˆ¤åˆ«æ¨¡å‹ã€‚VCD-RNKé€šè¿‡åœ¨ä»£ç è¯­ä¹‰åˆ†æã€æµ‹è¯•ç”¨ä¾‹ç”Ÿæˆå’ŒåŠŸèƒ½æ­£ç¡®æ€§è¯„ä¼°ä¸‰ä¸ªç»´åº¦è’¸é¦ä¸“å®¶çŸ¥è¯†ï¼Œèµ‹äºˆäº†æ¨¡å‹æ·±å…¥çš„ç¡¬ä»¶é€»è¾‘æ¨ç†èƒ½åŠ›ã€‚è¯¥æ–¹æ³•é€šè¿‡åœ¨æ¨ç†é˜¶æ®µæ˜¾å¼æ¨¡æ‹Ÿä¸“å®¶çš„è¯„ä¼°è¿‡ç¨‹ï¼ŒæˆåŠŸé¿å…äº†ä¼ ç»Ÿæ–¹æ³•ä¸­é«˜æ˜‚çš„è‡ªåŠ¨åŒ–æµ‹è¯•æ‰§è¡Œå¼€é”€ã€‚å®éªŒè¡¨æ˜ï¼ŒVCD-RNKèƒ½å¤Ÿåœ¨ä¸ä¾èµ–ç¹çä»¿çœŸçš„æƒ…å†µä¸‹ï¼Œä»ä¼—å¤šç”Ÿæˆå€™é€‰ä¸­ç­›é€‰å‡ºæœ€å…·åŠŸèƒ½æ­£ç¡®æ€§çš„Verilogä»£ç ï¼Œä¸ºç¡¬ä»¶è®¾è®¡è‡ªåŠ¨åŒ–æä¾›äº†æ›´é«˜æ•ˆã€å¯é çš„è§£å†³æ–¹æ¡ˆã€‚",
      "categories": [
        "cs.AR",
        "cs.AI",
        "cs.SE"
      ],
      "primary_category": "cs.AR",
      "comment": "Work in Progress",
      "pdf_url": "https://arxiv.org/pdf/2509.20215v2",
      "published_date": "2025-09-24 15:12:21 UTC",
      "updated_date": "2025-12-09 04:48:47 UTC",
      "processing_status": "completed",
      "attempts": 1,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "llm_backup_calls": 0,
      "last_update": "2026-01-24T20:51:38.787410+00:00"
    },
    {
      "arxiv_id": "2509.20214v2",
      "title": "Q-Palette: Fractional-Bit Quantizers Toward Optimal Bit Allocation for Efficient LLM Deployment",
      "title_zh": "Q-Paletteï¼šé¢å‘é«˜æ•ˆå¤§è¯­è¨€æ¨¡å‹éƒ¨ç½²çš„æœ€ä¼˜æ¯”ç‰¹åˆ†é…åˆ†æ•°ä½é‡åŒ–å™¨",
      "authors": [
        "Deokjae Lee",
        "Hyun Oh Song"
      ],
      "abstract": "We study weight-only post-training quantization (PTQ), which quantizes the weights of a large language model (LLM) without retraining, using little or no calibration data. Weight-only PTQ is crucial for reducing the memory footprint and latency of LLM inference, especially in memory-bound, small-batch inference scenarios, such as personalized inference on edge devices. Despite its importance, irregular weight distributions with heavy-tailed outliers in LLMs complicate quantization, recently motivating rotation-based methods that transform weights into near-Gaussian distributions, which are more regular with fewer outliers, thereby reducing quantization error. In this work, we first derive the information-theoretically optimal bit allocation for Gaussianized weights under given bit budgets, revealing that fine-grained fractional-bit quantizers approaching the Gaussian distortion-rate bound are essential to achieve near-optimal quantization performance. To bridge this theoretical insight and practical implementation, we introduce Q-Palette, a versatile collection of fractional-bit quantizers that range from trellis-coded quantizers offering near-optimal distortion to simpler vector and scalar quantizers optimized for faster inference, all efficiently implemented with optimized CUDA kernels across various bitwidths. Furthermore, leveraging Q-Palette as a foundational component, we propose a novel mixed-scheme quantization framework, jointly optimizing quantizer choices and layer fusion decisions given resource constraints. The code is available at https://github.com/snu-mllab/Q-Palette.",
      "tldr_zh": "è¯¥ç ”ç©¶é’ˆå¯¹å¤§è¯­è¨€æ¨¡å‹(LLMs)çš„æƒé‡é‡åŒ–é—®é¢˜ï¼Œæå‡ºäº†Q-Paletteè¿™ä¸€é€šç”¨çš„åˆ†æ•°æ¯”ç‰¹é‡åŒ–å™¨(Fractional-Bit Quantizers)é›†åˆï¼Œæ—¨åœ¨é™ä½æ¨ç†å†…å­˜å ç”¨ä¸å»¶è¿Ÿã€‚é€šè¿‡å¯¹é«˜æ–¯åŒ–æƒé‡è¿›è¡Œä¿¡æ¯è®ºåˆ†æï¼Œç ”ç©¶æ­ç¤ºäº†ç²¾ç»†åŒ–çš„åˆ†æ•°æ¯”ç‰¹é‡åŒ–å¯¹äºå®ç°è¿‘ä¹æœ€ä¼˜é‡åŒ–æ€§èƒ½çš„é‡è¦æ€§ã€‚Q-PaletteåŒ…å«äº†ä»æä¾›è¿‘ä¼˜å¤±çœŸçš„ç½‘æ ¼ç¼–ç é‡åŒ–å™¨(Trellis-Coded Quantizers)åˆ°é’ˆå¯¹å¿«é€Ÿæ¨ç†ä¼˜åŒ–çš„å‘é‡å’Œæ ‡é‡é‡åŒ–å™¨ï¼Œå¹¶é…å¤‡äº†é«˜æ•ˆçš„CUDAå†…æ ¸å®ç°ã€‚æ­¤å¤–ï¼Œä½œè€…è¿˜æå‡ºäº†ä¸€ä¸ªæ··åˆæ–¹æ¡ˆé‡åŒ–æ¡†æ¶ï¼Œèƒ½å¤Ÿåœ¨ç»™å®šèµ„æºçº¦æŸä¸‹ååŒä¼˜åŒ–é‡åŒ–å™¨é€‰æ‹©ä¸å±‚èåˆå†³ç­–ã€‚è¯¥æ–¹æ¡ˆé€šè¿‡ä¼˜åŒ–æ¯”ç‰¹åˆ†é…ï¼Œæœ‰æ•ˆè§£å†³äº†LLMsæƒé‡åˆ†å¸ƒä¸å‡åŠç¦»ç¾¤å€¼å¸¦æ¥çš„æŒ‘æˆ˜ï¼Œä¸ºåœ¨è¾¹ç¼˜è®¾å¤‡ä¸Šå®ç°é«˜æ•ˆéƒ¨ç½²æä¾›äº†æ–°é€”å¾„ã€‚",
      "categories": [
        "cs.LG",
        "cs.AI"
      ],
      "primary_category": "cs.LG",
      "comment": "NeurIPS 2025",
      "pdf_url": "https://arxiv.org/pdf/2509.20214v2",
      "published_date": "2025-09-24 15:10:44 UTC",
      "updated_date": "2025-10-22 06:33:03 UTC",
      "processing_status": "completed",
      "attempts": 1,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "llm_backup_calls": 0,
      "last_update": "2026-01-24T20:51:49.594904+00:00"
    },
    {
      "arxiv_id": "2509.20209v1",
      "title": "Low-Resource English-Tigrinya MT: Leveraging Multilingual Models, Custom Tokenizers, and Clean Evaluation Benchmarks",
      "title_zh": "ä½èµ„æºè‹±è¯­-ææ ¼é›·å°¼äºšè¯­æœºå™¨ç¿»è¯‘ï¼šå€ŸåŠ©å¤šè¯­è¨€æ¨¡å‹ã€å®šåˆ¶åŒ–åˆ†è¯å™¨åŠçº¯å‡€è¯„ä¼°åŸºå‡†",
      "authors": [
        "Hailay Kidu Teklehaymanot",
        "Gebrearegawi Gidey",
        "Wolfgang Nejdl"
      ],
      "abstract": "Despite advances in Neural Machine Translation (NMT), low-resource languages like Tigrinya remain underserved due to persistent challenges, including limited corpora, inadequate tokenization strategies, and the lack of standardized evaluation benchmarks. This paper investigates transfer learning techniques using multilingual pretrained models to enhance translation quality for morphologically rich, low-resource languages. We propose a refined approach that integrates language-specific tokenization, informed embedding initialization, and domain-adaptive fine-tuning. To enable rigorous assessment, we construct a high-quality, human-aligned English-Tigrinya evaluation dataset covering diverse domains. Experimental results demonstrate that transfer learning with a custom tokenizer substantially outperforms zero-shot baselines, with gains validated by BLEU, chrF, and qualitative human evaluation. Bonferroni correction is applied to ensure statistical significance across configurations. Error analysis reveals key limitations and informs targeted refinements. This study underscores the importance of linguistically aware modeling and reproducible benchmarks in bridging the performance gap for underrepresented languages. Resources are available at https://github.com/hailaykidu/MachineT_TigEng\n  and https://huggingface.co/Hailay/MachineT_TigEng",
      "tldr_zh": "è¯¥ç ”ç©¶é’ˆå¯¹ææ ¼åˆ©å°¼äºšè¯­ (Tigrinya) ç­‰ä½èµ„æºä¸”å½¢æ€ä¸°å¯Œçš„è¯­è¨€åœ¨ç¥ç»æœºå™¨ç¿»è¯‘ (Neural Machine Translation) ä¸­é¢ä¸´çš„è¯­æ–™åº“æœ‰é™ã€åˆ†è¯ç­–ç•¥ä¸è¶³åŠç¼ºä¹æ ‡å‡†åŒ–è¯„ä¼°åŸºå‡†ç­‰æŒ‘æˆ˜è¿›è¡Œäº†æ·±å…¥æ¢è®¨ã€‚ä½œè€…æå‡ºäº†ä¸€ç§æ”¹è¿›çš„è¿ç§»å­¦ä¹  (transfer learning) æ–¹æ³•ï¼Œé€šè¿‡æ•´åˆç‰¹å®šè¯­è¨€çš„åˆ†è¯æŠ€æœ¯ (language-specific tokenization)ã€çŸ¥æƒ…åµŒå…¥åˆå§‹åŒ– (informed embedding initialization) ä»¥åŠé¢†åŸŸè‡ªé€‚åº”å¾®è°ƒ (domain-adaptive fine-tuning) æ¥æå‡ç¿»è¯‘è´¨é‡ã€‚ä¸ºç¡®ä¿è¯„ä¼°çš„ä¸¥è°¨æ€§ï¼Œç ”ç©¶æ„å»ºäº†ä¸€ä¸ªæ¶µç›–å¤šä¸ªé¢†åŸŸçš„ã€ç»è¿‡äººå·¥å¯¹é½çš„é«˜è´¨é‡ English-Tigrinya è¯„ä¼°æ•°æ®é›†ã€‚å®éªŒç»“æœè¡¨æ˜ï¼Œé‡‡ç”¨è‡ªå®šä¹‰åˆ†è¯å™¨çš„è¿ç§»å­¦ä¹ æ–¹æ³•åœ¨ BLEU å’Œ chrF ç­‰æŒ‡æ ‡ä¸Šæ˜¾è‘—ä¼˜äºé›¶æ ·æœ¬ (zero-shot) åŸºçº¿æ¨¡å‹ï¼Œä¸”å…¶ç»Ÿè®¡æ˜¾è‘—æ€§é€šè¿‡äº† Bonferroni correction éªŒè¯ã€‚å®šæ€§çš„ä¸“å®¶è¯„ä¼°å’Œé”™è¯¯åˆ†æè¿›ä¸€æ­¥æ­ç¤ºäº†ç°æœ‰æ¨¡å‹çš„å±€é™æ€§ï¼Œå¹¶å¼ºè°ƒäº†è¯­è¨€æ„ŸçŸ¥å»ºæ¨¡ (linguistically aware modeling) å’Œå¯é‡å¤åŸºå‡†åœ¨ç¼©å°æ¬ ä»£è¡¨è¯­è¨€ç¿»è¯‘æ€§èƒ½å·®è·æ–¹é¢çš„é‡è¦æ„ä¹‰ã€‚",
      "categories": [
        "cs.CL",
        "cs.AI"
      ],
      "primary_category": "cs.CL",
      "comment": "This submission is 8 pages long, includes 4 tables, and contains all required conference details",
      "pdf_url": "https://arxiv.org/pdf/2509.20209v1",
      "published_date": "2025-09-24 15:02:57 UTC",
      "updated_date": "2025-09-24 15:02:57 UTC",
      "processing_status": "completed",
      "attempts": 1,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "llm_backup_calls": 0,
      "last_update": "2026-01-24T20:51:50.492907+00:00"
    },
    {
      "arxiv_id": "2509.20208v1",
      "title": "Play by the Type Rules: Inferring Constraints for LLM Functions in Declarative Programs",
      "title_zh": "éµå¾ªç±»å‹è§„åˆ™ï¼šå£°æ˜å¼ç¨‹åºä¸­ LLM å‡½æ•°çš„çº¦æŸæ¨æ–­",
      "authors": [
        "Parker Glenn",
        "Alfy Samuel",
        "Daben Liu"
      ],
      "abstract": "Integrating LLM powered operators in declarative query languages allows for the combination of cheap and interpretable functions with powerful, generalizable language model reasoning. However, in order to benefit from the optimized execution of a database query language like SQL, generated outputs must align with the rules enforced by both type checkers and database contents. Current approaches address this challenge with orchestrations consisting of many LLM-based post-processing calls to ensure alignment between generated outputs and database values, introducing performance bottlenecks. We perform a study on the ability of various sized open-source language models to both parse and execute functions within a query language based on SQL, showing that small language models can excel as function executors over hybrid data sources. Then, we propose an efficient solution to enforce the well-typedness of LLM functions, demonstrating 7% accuracy improvement on a multi-hop question answering dataset with 53% improvement in latency over comparable solutions. We make our implementation available at https://github.com/parkervg/blendsql",
      "tldr_zh": "è¯¥ç ”ç©¶æ¢è®¨äº†åœ¨ SQL ç­‰å£°æ˜å¼æŸ¥è¯¢è¯­è¨€ä¸­é›†æˆå¤§å‹è¯­è¨€æ¨¡å‹ï¼ˆLLMï¼‰ç®—å­æ—¶ï¼Œè¾“å‡ºç»“æœå¿…é¡»ç¬¦åˆç±»å‹æ£€æŸ¥å’Œæ•°æ®åº“å†…å®¹çº¦æŸçš„æŒ‘æˆ˜ã€‚é’ˆå¯¹å½“å‰å¤šæ­¥åå¤„ç†è°ƒç”¨å¯¼è‡´çš„æ€§èƒ½ç“¶é¢ˆï¼Œä½œè€…é¦–å…ˆç ”ç©¶äº†ä¸åŒè§„æ¨¡å¼€æºè¯­è¨€æ¨¡å‹åœ¨è§£æå’Œæ‰§è¡Œå‡½æ•°æ—¶çš„èƒ½åŠ›ï¼Œå‘ç°å°å‹æ¨¡å‹åœ¨å¤„ç†æ··åˆæ•°æ®æºçš„å‡½æ•°æ‰§è¡Œä¸Šè¡¨ç°å‡ºè‰²ã€‚ä¸ºæ­¤ï¼Œè¯¥ç ”ç©¶æå‡ºäº†ä¸€ç§é«˜æ•ˆçš„è§£å†³æ–¹æ¡ˆï¼Œé€šè¿‡å¼ºåˆ¶æ‰§è¡Œ LLM å‡½æ•°çš„è‰¯å®šç±»å‹æ€§ï¼ˆwell-typednessï¼‰æ¥ç¡®ä¿ç”Ÿæˆçš„è¾“å‡ºä¸æ•°æ®åº“çº¦æŸä¿æŒä¸€è‡´ã€‚åœ¨å¤šè·³é—®ç­”ï¼ˆmulti-hop question answeringï¼‰æ•°æ®é›†ä¸Šçš„å®éªŒè¡¨æ˜ï¼Œè¯¥æ–¹æ³•ç›¸æ¯”åŒç±»æ–¹æ¡ˆåœ¨å‡†ç¡®ç‡æå‡ 7% çš„åŒæ—¶ï¼Œå°†å»¶è¿Ÿé™ä½äº† 53%ã€‚è¯¥å®ç°çš„å¼€æºé¡¹ç›® BlendSQL ä¸ºç»“åˆè½»é‡çº§è§£é‡Šæ€§å‡½æ•°ä¸å¼ºå¤§çš„è¯­è¨€æ¨¡å‹æ¨ç†èƒ½åŠ›æä¾›äº†é«˜æ•ˆä¸”å¯æ‰©å±•çš„è·¯å¾„ã€‚",
      "categories": [
        "cs.CL",
        "cs.AI",
        "cs.DB"
      ],
      "primary_category": "cs.CL",
      "comment": "",
      "pdf_url": "https://arxiv.org/pdf/2509.20208v1",
      "published_date": "2025-09-24 15:02:33 UTC",
      "updated_date": "2025-09-24 15:02:33 UTC",
      "processing_status": "completed",
      "attempts": 1,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "llm_backup_calls": 0,
      "last_update": "2026-01-24T20:52:52.171486+00:00"
    },
    {
      "arxiv_id": "2509.20190v1",
      "title": "STAF: Leveraging LLMs for Automated Attack Tree-Based Security Test Generation",
      "title_zh": "STAFï¼šåˆ©ç”¨å¤§è¯­è¨€æ¨¡å‹å®ç°åŸºäºæ”»å‡»æ ‘çš„è‡ªåŠ¨åŒ–å®‰å…¨æµ‹è¯•ç”Ÿæˆ",
      "authors": [
        "Tanmay Khule",
        "Stefan Marksteiner",
        "Jose Alguindigue",
        "Hannes Fuchs",
        "Sebastian Fischmeister",
        "Apurva Narayan"
      ],
      "abstract": "In modern automotive development, security testing is critical for safeguarding systems against increasingly advanced threats. Attack trees are widely used to systematically represent potential attack vectors, but generating comprehensive test cases from these trees remains a labor-intensive, error-prone task that has seen limited automation in the context of testing vehicular systems. This paper introduces STAF (Security Test Automation Framework), a novel approach to automating security test case generation. Leveraging Large Language Models (LLMs) and a four-step self-corrective Retrieval-Augmented Generation (RAG) framework, STAF automates the generation of executable security test cases from attack trees, providing an end-to-end solution that encompasses the entire attack surface. We particularly show the elements and processes needed to provide an LLM to actually produce sensible and executable automotive security test suites, along with the integration with an automated testing framework. We further compare our tailored approach with general purpose (vanilla) LLMs and the performance of different LLMs (namely GPT-4.1 and DeepSeek) using our approach. We also demonstrate the method of our operation step-by-step in a concrete case study. Our results show significant improvements in efficiency, accuracy, scalability, and easy integration in any workflow, marking a substantial advancement in automating automotive security testing methodologies. Using TARAs as an input for verfication tests, we create synergies by connecting two vital elements of a secure automotive development process.",
      "tldr_zh": "è¯¥ç ”ç©¶é’ˆå¯¹ç°ä»£æ±½è½¦å¼€å‘ä¸­æ”»å‡»æ ‘ (Attack Trees) ç”Ÿæˆå®‰å…¨æµ‹è¯•ç”¨ä¾‹åŠ³åŠ¨å¼ºåº¦å¤§ã€æ˜“å‡ºé”™ä¸”è‡ªåŠ¨åŒ–ç¨‹åº¦ä½çš„é—®é¢˜ï¼Œæå‡ºäº† STAF (Security Test Automation Framework) æ¡†æ¶ã€‚è¯¥æ¡†æ¶ç»“åˆå¤§è¯­è¨€æ¨¡å‹ (LLMs) ä¸ä¸€ç§å››æ­¥è‡ªæˆ‘çº æ­£çš„æ£€ç´¢å¢å¼ºç”Ÿæˆ (RAG) æŠ€æœ¯ï¼Œå®ç°äº†ä»æ”»å‡»æ ‘åˆ°å¯æ‰§è¡Œå®‰å…¨æµ‹è¯•ç”¨ä¾‹çš„ç«¯åˆ°ç«¯è‡ªåŠ¨åŒ–ç”Ÿæˆã€‚ç ”ç©¶é€šè¿‡æ¡ˆä¾‹ç ”ç©¶æ¼”ç¤ºäº†å…·ä½“æ“ä½œæµç¨‹ï¼Œå¹¶å¯¹æ¯”äº†å®šåˆ¶åŒ–æ–¹æ³•ä¸é€šç”¨å‹ LLMs åœ¨ä¸åŒæ¨¡å‹ï¼ˆå¦‚ GPT-4.1 å’Œ DeepSeekï¼‰ä¸‹çš„æ€§èƒ½è¡¨ç°ã€‚å®éªŒç»“æœè¡¨æ˜ï¼ŒSTAF åœ¨æ•ˆç‡ã€å‡†ç¡®æ€§å’Œå¯æ‰©å±•æ€§æ–¹é¢å‡æœ‰æ˜¾è‘—æå‡ï¼Œä¸”èƒ½å¤Ÿä¸ç°æœ‰è‡ªåŠ¨åŒ–æµ‹è¯•æ¡†æ¶æ— ç¼é›†æˆã€‚è¯¥æ–¹æ³•é€šè¿‡å°†å¨èƒåˆ†æä¸é£é™©è¯„ä¼° (TARA) ä½œä¸ºéªŒè¯æµ‹è¯•çš„è¾“å…¥ï¼ŒæˆåŠŸè¿æ¥äº†æ±½è½¦å®‰å…¨å¼€å‘è¿‡ç¨‹ä¸­çš„å…³é”®ç¯èŠ‚ï¼Œä¸ºè‡ªåŠ¨åŒ–æ±½è½¦å®‰å…¨æµ‹è¯•é¢†åŸŸæä¾›äº†å®è´¨æ€§çš„æŠ€æœ¯è¿›æ­¥ã€‚",
      "categories": [
        "cs.CR",
        "cs.AI"
      ],
      "primary_category": "cs.CR",
      "comment": "18 pages, 2 figures, accepted for 23rd escar Europe (Nov 05-06, 2025, Frankfurt, Germany)",
      "pdf_url": "https://arxiv.org/pdf/2509.20190v1",
      "published_date": "2025-09-24 14:46:42 UTC",
      "updated_date": "2025-09-24 14:46:42 UTC",
      "processing_status": "completed",
      "attempts": 1,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "llm_backup_calls": 0,
      "last_update": "2026-01-24T20:52:06.597397+00:00"
    },
    {
      "arxiv_id": "2509.20187v1",
      "title": "How People Manage Knowledge in their \"Second Brains\"- A Case Study with Industry Researchers Using Obsidian",
      "title_zh": "äººä»¬å¦‚ä½•åœ¨â€œç¬¬äºŒå¤§è„‘â€ä¸­ç®¡ç†çŸ¥è¯†ï¼šä¸€é¡¹é’ˆå¯¹ä½¿ç”¨ Obsidian çš„è¡Œä¸šç ”ç©¶äººå‘˜çš„æ¡ˆä¾‹ç ”ç©¶",
      "authors": [
        "Juliana Jansen Ferreira",
        "VinÃ­cius Segura",
        "Joana Gabriela Souza",
        "Joao Henrique Gallas Brasil"
      ],
      "abstract": "People face overwhelming information during work activities, necessitating effective organization and management strategies. Even in personal lives, individuals must keep, annotate, organize, and retrieve knowledge from daily routines. The collection of records for future reference is known as a personal knowledge base. Note-taking applications are valuable tools for building and maintaining these bases, often called a ''second brain''. This paper presents a case study on how people build and explore personal knowledge bases for various purposes. We selected the note-taking tool Obsidian and researchers from a Brazilian lab for an in-depth investigation. Our investigation reveals interesting findings about how researchers build and explore their personal knowledge bases. A key finding is that participants' knowledge retrieval strategy influences how they build and maintain their content. We suggest potential features for an AI system to support this process.",
      "tldr_zh": "è¯¥é¡¹ç ”ç©¶é€šè¿‡å¯¹ä½¿ç”¨ Obsidian çš„å·¥ä¸šç ”ç©¶äººå‘˜è¿›è¡Œæ¡ˆä¾‹ç ”ç©¶ï¼Œæ·±å…¥æ¢è®¨äº†ä¸ªäººåœ¨æ„å»ºå’Œç®¡ç†è¢«ç§°ä¸º \"second brain\" çš„ä¸ªäººçŸ¥è¯†åº“æ—¶çš„è¡Œä¸ºæ¨¡å¼ã€‚ç ”ç©¶é€‰å–äº†å·´è¥¿æŸå®éªŒå®¤çš„ä¸“ä¸šäººå‘˜ï¼Œç³»ç»Ÿåœ°åˆ†æäº†ä»–ä»¬åœ¨æ—¥å¸¸å·¥ä½œä¸­å¦‚ä½•åˆ©ç”¨ç¬”è®°å·¥å…·è¿›è¡ŒçŸ¥è¯†çš„è®°å½•ã€ç»„ç»‡ä¸æ£€ç´¢ã€‚è°ƒæŸ¥ç»“æœæ˜¾ç¤ºï¼Œç ”ç©¶äººå‘˜çš„çŸ¥è¯†æ£€ç´¢ç­–ç•¥ (knowledge retrieval strategy) ä¼šç›´æ¥å†³å®šå…¶æ„å»ºå’Œç»´æŠ¤çŸ¥è¯†å†…å®¹çš„æ–¹å¼ã€‚æ­¤å¤–ï¼Œæœ¬æ–‡è¿˜æ¢è®¨äº†æ„å»ºä¸ªäººçŸ¥è¯†ä½“ç³»ä¸­çš„å…³é”®å‘ç°ï¼Œå¹¶é’ˆå¯¹å¦‚ä½•åˆ©ç”¨ AI ç³»ç»Ÿæ”¯æŒå’Œå¢å¼ºè¿™ä¸€è¿‡ç¨‹æå‡ºäº†å…·ä½“çš„åŠŸèƒ½å»ºè®®ã€‚ç ”ç©¶æˆæœä¸ºç†è§£ç°ä»£çŸ¥è¯†å·¥ä½œè€…çš„ä¸ªäººçŸ¥è¯†ç®¡ç†å®è·µæä¾›äº†å®è¯åŸºç¡€ï¼Œå¹¶ä¸ºæœªæ¥æ™ºèƒ½ç¬”è®°å·¥å…·çš„è®¾è®¡æä¾›äº†å‚è€ƒã€‚",
      "categories": [
        "cs.HC",
        "cs.AI"
      ],
      "primary_category": "cs.HC",
      "comment": "9 pages, 3 figures",
      "pdf_url": "https://arxiv.org/pdf/2509.20187v1",
      "published_date": "2025-09-24 14:45:35 UTC",
      "updated_date": "2025-09-24 14:45:35 UTC",
      "processing_status": "completed",
      "attempts": 1,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "llm_backup_calls": 0,
      "last_update": "2026-01-24T20:53:07.163671+00:00"
    },
    {
      "arxiv_id": "2509.20184v1",
      "title": "An Improved Time Series Anomaly Detection by Applying Structural Similarity",
      "title_zh": "åŸºäºç»“æ„ç›¸ä¼¼æ€§çš„æ”¹è¿›æ—¶é—´åºåˆ—å¼‚å¸¸æ£€æµ‹",
      "authors": [
        "Tiejun Wang",
        "Rui Wang",
        "Xudong Mou",
        "Mengyuan Ma",
        "Tianyu Wo",
        "Renyu Yang",
        "Xudong Liu"
      ],
      "abstract": "Effective anomaly detection in time series is pivotal for modern industrial applications and financial systems. Due to the scarcity of anomaly labels and the high cost of manual labeling, reconstruction-based unsupervised approaches have garnered considerable attention. However, accurate anomaly detection remains an unsettled challenge, since the optimization objectives of reconstruction-based methods merely rely on point-by-point distance measures, ignoring the potential structural characteristics of time series and thus failing to tackle complex pattern-wise anomalies. In this paper, we propose StrAD, a novel structure-enhanced anomaly detection approach to enrich the optimization objective by incorporating structural information hidden in the time series and steering the data reconstruction procedure to better capture such structural features. StrAD accommodates the trend, seasonality, and shape in the optimization objective of the reconstruction model to learn latent structural characteristics and capture the intrinsic pattern variation of time series. The proposed structure-aware optimization objective mechanism can assure the alignment between the original data and the reconstructed data in terms of structural features, thereby keeping consistency in global fluctuation and local characteristics. The mechanism is pluggable and applicable to any reconstruction-based methods, enhancing the model sensitivity to both point-wise anomalies and pattern-wise anomalies. Experimental results show that StrAD improves the performance of state-of-the-art reconstruction-based models across five real-world anomaly detection datasets.",
      "tldr_zh": "è¯¥ç ”ç©¶æå‡ºäº† StrADï¼Œä¸€ç§æ–°å‹çš„ç»“æ„å¢å¼ºå‹å¼‚å¸¸æ£€æµ‹ï¼ˆanomaly detectionï¼‰æ–¹æ³•ï¼Œæ—¨åœ¨è§£å†³åŸºäºé‡æ„çš„æ— ç›‘ç£æ–¹æ³•ï¼ˆreconstruction-based methodsï¼‰å› ä»…ä¾èµ–ç‚¹å¯¹ç‚¹è·ç¦»è€Œå¿½è§†æ—¶é—´åºåˆ—ç»“æ„ç‰¹å¾çš„é—®é¢˜ã€‚StrAD é€šè¿‡åœ¨ä¼˜åŒ–ç›®æ ‡ä¸­æ•´åˆè¶‹åŠ¿ï¼ˆtrendï¼‰ã€å­£èŠ‚æ€§ï¼ˆseasonalityï¼‰å’Œå½¢çŠ¶ï¼ˆshapeï¼‰ä¿¡æ¯ï¼Œå¼•å¯¼é‡æ„æ¨¡å‹å­¦ä¹ æ½œåœ¨çš„ç»“æ„ç‰¹æ€§å¹¶æ•æ‰å†…åœ¨çš„æ¨¡å¼å˜åŒ–ã€‚è¿™ç§ç»“æ„æ„ŸçŸ¥ä¼˜åŒ–ç›®æ ‡æœºåˆ¶ç¡®ä¿äº†åŸå§‹æ•°æ®ä¸é‡æ„æ•°æ®åœ¨å…¨å±€æ³¢åŠ¨ä¸å±€éƒ¨ç‰¹å¾ä¸Šçš„ä¸€è‡´æ€§ï¼Œä¸”å…·æœ‰è‰¯å¥½çš„å¯æ’æ‹”æ€§ï¼Œå¯åº”ç”¨äºå„ç§é‡æ„æ¨¡å‹ã€‚è¯¥æ–¹æ³•æ˜¾è‘—å¢å¼ºäº†æ¨¡å‹å¯¹ç‚¹çŠ¶å¼‚å¸¸ï¼ˆpoint-wise anomaliesï¼‰å’Œå¤æ‚æ¨¡å¼å¼‚å¸¸ï¼ˆpattern-wise anomaliesï¼‰çš„æ•æ„Ÿåº¦ã€‚å®éªŒç»“æœæ˜¾ç¤ºï¼ŒStrAD åœ¨äº”ä¸ªçœŸå®ä¸–ç•Œæ•°æ®é›†ä¸Šå‡æå‡äº†ç°æœ‰ä¸»æµé‡æ„æ¨¡å‹çš„æ€§èƒ½ï¼Œè¯æ˜äº†å¼•å…¥ç»“æ„ç›¸ä¼¼æ€§åœ¨æ—¶é—´åºåˆ—å¼‚å¸¸æ£€æµ‹ä¸­çš„æœ‰æ•ˆæ€§ã€‚",
      "categories": [
        "cs.LG",
        "cs.AI"
      ],
      "primary_category": "cs.LG",
      "comment": "",
      "pdf_url": "https://arxiv.org/pdf/2509.20184v1",
      "published_date": "2025-09-24 14:45:00 UTC",
      "updated_date": "2025-09-24 14:45:00 UTC",
      "processing_status": "completed",
      "attempts": 1,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "llm_backup_calls": 0,
      "last_update": "2026-01-24T20:53:08.454636+00:00"
    },
    {
      "arxiv_id": "2509.20182v1",
      "title": "Automated Multi-Agent Workflows for RTL Design",
      "title_zh": "é¢å‘RTLè®¾è®¡çš„è‡ªåŠ¨åŒ–å¤šæ™ºèƒ½ä½“å·¥ä½œæµ",
      "authors": [
        "Amulya Bhattaram",
        "Janani Ramamoorthy",
        "Ranit Gupta",
        "Diana Marculescu",
        "Dimitrios Stamoulis"
      ],
      "abstract": "The rise of agentic AI workflows unlocks novel opportunities for computer systems design and optimization. However, for specialized domains such as program synthesis, the relative scarcity of HDL and proprietary EDA resources online compared to more common programming tasks introduces challenges, often necessitating task-specific fine-tuning, high inference costs, and manually-crafted agent orchestration. In this work, we present VeriMaAS, a multi-agent framework designed to automatically compose agentic workflows for RTL code generation. Our key insight is to integrate formal verification feedback from HDL tools directly into workflow generation, reducing the cost of gradient-based updates or prolonged reasoning traces. Our method improves synthesis performance by 5-7% for pass@k over fine-tuned baselines, while requiring only a few hundred training examples, representing an order-of-magnitude reduction in supervision cost.",
      "tldr_zh": "è¯¥ç ”ç©¶æå‡ºäº† VeriMaASï¼Œä¸€ä¸ªæ—¨åœ¨è‡ªåŠ¨æ„å»º RTL ä»£ç ç”Ÿæˆä»£ç†å·¥ä½œæµçš„å¤šæ™ºèƒ½ä½“æ¡†æ¶ã€‚é’ˆå¯¹ HDL å’Œ ä¸“ç”¨ EDA èµ„æºç¨€ç¼ºå¯¼è‡´çš„å¾®è°ƒæˆæœ¬é«˜ã€æ¨ç†å¼€é”€å¤§ä»¥åŠäººå·¥ç¼–æ’å¤æ‚ç­‰æŒ‘æˆ˜ï¼ŒVeriMaAS çš„æ ¸å¿ƒåˆ›æ–°åœ¨äºå°†æ¥è‡ª HDL å·¥å…·çš„å½¢å¼éªŒè¯åé¦ˆ (formal verification feedback) ç›´æ¥é›†æˆåˆ°å·¥ä½œæµç”Ÿæˆè¿‡ç¨‹ä¸­ã€‚è¿™ç§æ–¹æ³•æ˜¾è‘—å‡å°‘äº†å¯¹æ¢¯åº¦æ›´æ–°æˆ–å†—é•¿æ¨ç†è¿½è¸ªçš„ä¾èµ–ï¼Œé™ä½äº†æ•´ä½“è®¡ç®—æˆæœ¬ã€‚å®éªŒç»“æœè¡¨æ˜ï¼ŒVeriMaAS åœ¨ pass@k æŒ‡æ ‡ä¸Šæ¯”å¾®è°ƒåçš„åŸºçº¿æ¨¡å‹æå‡äº† 5-7%ã€‚æ­¤å¤–ï¼Œè¯¥æ¡†æ¶ä»…éœ€æ•°ç™¾ä¸ªè®­ç»ƒæ ·æœ¬å³å¯è¾¾åˆ°ä¼˜å¼‚æ€§èƒ½ï¼Œå®ç°äº†ç›‘ç£æˆæœ¬çš„æ•°é‡çº§é™ä½ã€‚è¯¥å·¥ä½œä¸ºé«˜æ•ˆã€è‡ªåŠ¨åŒ–çš„è®¡ç®—æœºç³»ç»Ÿè®¾è®¡ä¸ä¼˜åŒ–æä¾›äº†æ–°çš„è§†è§’ã€‚",
      "categories": [
        "cs.AR",
        "cs.AI"
      ],
      "primary_category": "cs.AR",
      "comment": "Accepted: ML for Systems Workshop NeurIPS 2025",
      "pdf_url": "https://arxiv.org/pdf/2509.20182v1",
      "published_date": "2025-09-24 14:44:28 UTC",
      "updated_date": "2025-09-24 14:44:28 UTC",
      "processing_status": "completed",
      "attempts": 1,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "llm_backup_calls": 0,
      "last_update": "2026-01-24T20:53:20.766145+00:00"
    },
    {
      "arxiv_id": "2510.01253v1",
      "title": "OR-Toolformer: Modeling and Solving Operations Research Problems with Tool Augmented Large Language Models",
      "title_zh": "OR-Toolformerï¼šåŸºäºå·¥å…·å¢å¼ºå¤§è¯­è¨€æ¨¡å‹çš„è¿ç­¹å­¦é—®é¢˜å»ºæ¨¡ä¸æ±‚è§£",
      "authors": [
        "Jianzhang Zhang",
        "Jialong Zhou",
        "Chuang Liu"
      ],
      "abstract": "Large language models (LLMs) demonstrate strong mathematical reasoning, but reliance on closed-source APIs for OR tasks raises privacy concerns, and training open-source models from scratch incurs high compute costs. We introduce OR-Toolformer, which fine-tunes Llama-3.1-8B-Instruct with a semi-automatic data synthesis pipeline that generates diverse OR problem-answer pairs and augments the model with external solvers to produce API calls. On three of four standard benchmarks, OR-Toolformer achieves up to 80.1% execution accuracy, exceeding size-matched baselines by over 4.3%. In zero-shot evaluation on two unseen OR problem types, it attains 54% average accuracy, a 21 percentage-point improvement over the strongest baseline. These findings validate the efficacy of tool-augmented fine-tuning LLMs for accurate and generalizable OR problem modeling and solving.",
      "tldr_zh": "è¯¥ç ”ç©¶æå‡ºäº† OR-Toolformerï¼Œè¿™æ˜¯ä¸€ç§é€šè¿‡å·¥å…·å¢å¼ºçš„å¤§å‹è¯­è¨€æ¨¡å‹ (LLMs)ï¼Œæ—¨åœ¨åº”å¯¹è¿ç­¹å­¦ (Operations Research, OR) é¢†åŸŸåœ¨éšç§ä¿æŠ¤å’Œé«˜æ˜‚è®¡ç®—æˆæœ¬æ–¹é¢çš„æŒ‘æˆ˜ã€‚ç ”ç©¶å›¢é˜ŸåŸºäº Llama-3.1-8B-Instruct è¿›è¡Œäº†å¾®è°ƒï¼Œå¹¶å¼€å‘äº†ä¸€ç§åŠè‡ªåŠ¨æ•°æ®åˆæˆæµæ°´çº¿ä»¥ç”Ÿæˆå¤šæ ·åŒ–çš„ OR é—®é¢˜-ç­”æ¡ˆå¯¹ã€‚è¯¥æ¨¡å‹é€šè¿‡é›†æˆå¤–éƒ¨æ±‚è§£å™¨ (external solvers) ç”Ÿæˆ API è°ƒç”¨ï¼Œæ˜¾è‘—æå‡äº†å»ºæ¨¡ä¸æ±‚è§£çš„ç²¾ç¡®åº¦ã€‚å®éªŒç»“æœæ˜¾ç¤ºï¼ŒOR-Toolformer åœ¨å¤šä¸ªæ ‡å‡†åŸºå‡†æµ‹è¯•ä¸­è¾¾åˆ°äº† 80.1% çš„æ‰§è¡Œå‡†ç¡®ç‡ï¼Œæ˜¾è‘—è¶…è¶Šäº†åŒè§„æ¨¡çš„åŸºçº¿æ¨¡å‹ã€‚æ­¤å¤–ï¼Œåœ¨é’ˆå¯¹æœªçŸ¥é—®é¢˜ç±»å‹çš„é›¶æ ·æœ¬ (zero-shot) è¯„ä¼°ä¸­ï¼Œè¯¥æ¨¡å‹è¡¨ç°å‡ºå¼ºåŠ²çš„æ³›åŒ–èƒ½åŠ›ï¼Œå¹³å‡å‡†ç¡®ç‡è¾¾åˆ° 54%ï¼Œæ¯”æœ€å¼ºåŸºçº¿æå‡äº† 21 ä¸ªç™¾åˆ†ç‚¹ã€‚è¿™äº›ç»“æœå……åˆ†éªŒè¯äº†é‡‡ç”¨å·¥å…·å¢å¼ºå¾®è°ƒç­–ç•¥åœ¨æ„å»ºé«˜æ•ˆã€é€šç”¨ä¸”å‡†ç¡®çš„è¿ç­¹å­¦æ±‚è§£æ¨¡å‹æ–¹é¢çš„æœ‰æ•ˆæ€§ã€‚",
      "categories": [
        "cs.AI",
        "cs.LG"
      ],
      "primary_category": "cs.AI",
      "comment": "",
      "pdf_url": "https://arxiv.org/pdf/2510.01253v1",
      "published_date": "2025-09-24 14:42:40 UTC",
      "updated_date": "2025-09-24 14:42:40 UTC",
      "processing_status": "completed",
      "attempts": 1,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "llm_backup_calls": 0,
      "last_update": "2026-01-24T20:53:19.367624+00:00"
    },
    {
      "arxiv_id": "2509.20175v1",
      "title": "Federation of Agents: A Semantics-Aware Communication Fabric for Large-Scale Agentic AI",
      "title_zh": "æ™ºèƒ½ä½“è”é‚¦ï¼šé¢å‘å¤§è§„æ¨¡æ™ºèƒ½ä½“ AI çš„è¯­ä¹‰æ„ŸçŸ¥é€šä¿¡æ¶æ„",
      "authors": [
        "Lorenzo Giusti",
        "Ole Anton Werner",
        "Riccardo Taiello",
        "Matilde Carvalho Costa",
        "Emre Tosun",
        "Andrea Protani",
        "Marc Molina",
        "Rodrigo Lopes de Almeida",
        "Paolo Cacace",
        "Diogo Reis Santos",
        "Luigi Serio"
      ],
      "abstract": "We present Federation of Agents (FoA), a distributed orchestration framework that transforms static multi-agent coordination into dynamic, capability-driven collaboration. FoA introduces Versioned Capability Vectors (VCVs): machine-readable profiles that make agent capabilities searchable through semantic embeddings, enabling agents to advertise their capabilities, cost, and limitations. Our aarchitecturecombines three key innovations: (1) semantic routing that matches tasks to agents over sharded HNSW indices while enforcing operational constraints through cost-biased optimization, (2) dynamic task decomposition where compatible agents collaboratively break down complex tasks into DAGs of subtasks through consensus-based merging, and (3) smart clustering that groups agents working on similar subtasks into collaborative channels for k-round refinement before synthesis. Built on top of MQTT,s publish-subscribe semantics for scalable message passing, FoA achieves sub-linear complexity through hierarchical capability matching and efficient index maintenance. Evaluation on HealthBench shows 13x improvements over single-model baselines, with clustering-enhanced laboration particularly effective for complex reasoning tasks requiring multiple perspectives. The system scales horizontally while maintaining consistent performance, demonstrating that semantic orchestration with structured collaboration can unlock the collective intelligence of heterogeneous federations of AI agents.",
      "tldr_zh": "è¯¥ç ”ç©¶æå‡ºäº†Federation of Agents (FoA)ï¼Œè¿™æ˜¯ä¸€ç§åˆ†å¸ƒå¼ç¼–æ’æ¡†æ¶ï¼Œæ—¨åœ¨å°†é™æ€çš„å¤šæ™ºèƒ½ä½“åè°ƒè½¬å˜ä¸ºåŠ¨æ€ä¸”èƒ½åŠ›é©±åŠ¨çš„åä½œæ¨¡å¼ã€‚FoAå¼•å…¥äº†Versioned Capability Vectors (VCVs)ï¼Œåˆ©ç”¨è¯­ä¹‰åµŒå…¥ä½¿æ™ºèƒ½ä½“çš„èƒ½åŠ›ã€æˆæœ¬åŠå±€é™æ€§å…·å¤‡æœºå™¨å¯è¯»çš„æœç´¢ç‰¹æ€§ã€‚å…¶æ¶æ„é›†æˆäº†åŸºäºåˆ†ç‰‡HNSW indicesçš„è¯­ä¹‰è·¯ç”±ã€å°†å¤æ‚ä»»åŠ¡åˆ†è§£ä¸ºDAGsçš„æœ‰å‘æ— ç¯å›¾ä»»åŠ¡åˆ†è§£ï¼Œä»¥åŠç”¨äºåä½œç»†åŒ–çš„æ™ºèƒ½èšç±»æœºåˆ¶ã€‚FoAæ„å»ºåœ¨MQTTå‘å¸ƒè®¢é˜…åè®®ä¹‹ä¸Šï¼Œé€šè¿‡åˆ†å±‚åŒ¹é…å®ç°äº†æ¬¡çº¿æ€§å¤æ‚åº¦ï¼Œç¡®ä¿äº†åœ¨å¤§è§„æ¨¡ç¯å¢ƒä¸‹çš„é«˜æ•ˆæ¶ˆæ¯ä¼ é€’ã€‚å®éªŒåœ¨HealthBenchä¸Šè¯æ˜è¯¥æ¡†æ¶æ¯”å•æ¨¡å‹åŸºçº¿æ€§èƒ½æå‡äº†13å€ï¼Œå°¤å…¶åœ¨å¤šè§†è§’å¤æ‚æ¨ç†ä»»åŠ¡ä¸­è¡¨ç°å“è¶Šã€‚è¯¥ç³»ç»Ÿå±•ç¤ºäº†è¯­ä¹‰ç¼–æ’ä¸ç»“æ„åŒ–åä½œåœ¨è§£é”å¼‚æ„AIæ™ºèƒ½ä½“è”é‚¦é›†ä½“æ™ºæ…§åŠå®ç°æ°´å¹³æ‰©å±•æ–¹é¢çš„å·¨å¤§æ½œåŠ›ã€‚",
      "categories": [
        "cs.AI",
        "cs.CL"
      ],
      "primary_category": "cs.AI",
      "comment": "18 pages, 4 figures",
      "pdf_url": "https://arxiv.org/pdf/2509.20175v1",
      "published_date": "2025-09-24 14:38:06 UTC",
      "updated_date": "2025-09-24 14:38:06 UTC",
      "processing_status": "completed",
      "attempts": 1,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "llm_backup_calls": 0,
      "last_update": "2026-01-24T20:53:26.559103+00:00"
    },
    {
      "arxiv_id": "2509.20166v2",
      "title": "CyberSOCEval: Benchmarking LLMs Capabilities for Malware Analysis and Threat Intelligence Reasoning",
      "title_zh": "CyberSOCEvalï¼šé’ˆå¯¹æ¶æ„è½¯ä»¶åˆ†æä¸å¨èƒæƒ…æŠ¥æ¨ç†çš„å¤§è¯­è¨€æ¨¡å‹èƒ½åŠ›è¯„ä¼°åŸºå‡†",
      "authors": [
        "Lauren Deason",
        "Adam Bali",
        "Ciprian Bejean",
        "Diana Bolocan",
        "James Crnkovich",
        "Ioana Croitoru",
        "Krishna Durai",
        "Chase Midler",
        "Calin Miron",
        "David Molnar",
        "Brad Moon",
        "Bruno Ostarcevic",
        "Alberto Peltea",
        "Matt Rosenberg",
        "Catalin Sandu",
        "Arthur Saputkin",
        "Sagar Shah",
        "Daniel Stan",
        "Ernest Szocs",
        "Shengye Wan",
        "Spencer Whitman",
        "Sven Krasser",
        "Joshua Saxe"
      ],
      "abstract": "Today's cyber defenders are overwhelmed by a deluge of security alerts, threat intelligence signals, and shifting business context, creating an urgent need for AI systems to enhance operational security work. While Large Language Models (LLMs) have the potential to automate and scale Security Operations Center (SOC) operations, existing evaluations do not fully assess the scenarios most relevant to real-world defenders. This lack of informed evaluation impacts both AI developers and those applying LLMs to SOC automation. Without clear insight into LLM performance in real-world security scenarios, developers lack a north star for development, and users cannot reliably select the most effective models. Meanwhile, malicious actors are using AI to scale cyber attacks, highlighting the need for open source benchmarks to drive adoption and community-driven improvement among defenders and model developers. To address this, we introduce CyberSOCEval, a new suite of open source benchmarks within CyberSecEval 4. CyberSOCEval includes benchmarks tailored to evaluate LLMs in two tasks: Malware Analysis and Threat Intelligence Reasoning--core defensive domains with inadequate coverage in current benchmarks. Our evaluations show that larger, more modern LLMs tend to perform better, confirming the training scaling laws paradigm. We also find that reasoning models leveraging test time scaling do not achieve the same boost as in coding and math, suggesting these models have not been trained to reason about cybersecurity analysis, and pointing to a key opportunity for improvement. Finally, current LLMs are far from saturating our evaluations, showing that CyberSOCEval presents a significant challenge for AI developers to improve cyber defense capabilities.",
      "tldr_zh": "è¯¥ç ”ç©¶é’ˆå¯¹ç½‘ç»œé˜²å¾¡è€…é¢ä¸´çš„å®‰å…¨è­¦æŠ¥è¿‡è½½é—®é¢˜ï¼Œæå‡ºäº† CyberSOCEvalï¼Œè¿™æ˜¯ä¸€å¥—æ—¨åœ¨è¯„ä¼°å¤§è¯­è¨€æ¨¡å‹ (LLMs) åœ¨å®‰å…¨è¿è¥ä¸­å¿ƒ (SOC) è‡ªåŠ¨åŒ–èƒ½åŠ›çš„å¼€æºåŸºå‡†æµ‹è¯•å¥—ä»¶ã€‚ä½œä¸º CyberSecEval 4 çš„ä¸€éƒ¨åˆ†ï¼Œè¯¥å¥—ä»¶å¡«è¡¥äº†ç°æœ‰è¯„ä¼°ä½“ç³»åœ¨çœŸå®é˜²å¾¡åœºæ™¯ä¸‹çš„ç©ºç™½ï¼Œé‡ç‚¹è€ƒå¯Ÿæ¨¡å‹åœ¨æ¶æ„è½¯ä»¶åˆ†æ (Malware Analysis) å’Œå¨èƒæƒ…æŠ¥æ¨ç† (Threat Intelligence Reasoning) ä¸¤ä¸ªæ ¸å¿ƒé˜²å¾¡é¢†åŸŸçš„è¡¨ç°ã€‚è¯„ä¼°ç»“æœæ˜¾ç¤ºï¼Œå‚æ•°è§„æ¨¡æ›´å¤§ã€æ›´æ–°å‹çš„ LLMs é€šå¸¸è¡¨ç°æ›´ä½³ï¼Œè¿›ä¸€æ­¥éªŒè¯äº†è®­ç»ƒç¼©æ”¾å®šå¾‹ (scaling laws) çš„æœ‰æ•ˆæ€§ã€‚ç„¶è€Œï¼Œç ”ç©¶å‘ç°åˆ©ç”¨æµ‹è¯•æ—¶ç¼©æ”¾ (test time scaling) çš„æ¨ç†æ¨¡å‹åœ¨å®‰å…¨åˆ†æä»»åŠ¡ä¸­å¹¶æœªè·å¾—å¦‚ç¼–ç¨‹æˆ–æ•°å­¦é¢†åŸŸèˆ¬çš„æ˜¾è‘—æ€§èƒ½æå‡ï¼Œè¿™æ­ç¤ºäº†æ¨¡å‹åœ¨ç½‘ç»œå®‰å…¨æ¨ç†è®­ç»ƒæ–¹é¢çš„å…³é”®ä¸è¶³ã€‚ç›®å‰ä¸»æµ LLMs çš„è¡¨ç°è¿œæœªè¾¾åˆ°è¯¥åŸºå‡†æµ‹è¯•çš„é¥±å’Œç‚¹ï¼Œè¡¨æ˜ CyberSOCEval ä¸º AI å¼€å‘è€…æå‡ç½‘ç»œé˜²å¾¡èƒ½åŠ›æä¾›äº†é‡è¦çš„æŠ€æœ¯æŒ‡å¼•å’Œæ”¹è¿›ç©ºé—´ã€‚",
      "categories": [
        "cs.CR",
        "cs.AI"
      ],
      "primary_category": "cs.CR",
      "comment": "",
      "pdf_url": "https://arxiv.org/pdf/2509.20166v2",
      "published_date": "2025-09-24 14:33:07 UTC",
      "updated_date": "2025-11-10 19:42:29 UTC",
      "processing_status": "completed",
      "attempts": 1,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "llm_backup_calls": 0,
      "last_update": "2026-01-24T20:53:21.276805+00:00"
    },
    {
      "arxiv_id": "2509.20162v2",
      "title": "Embedding Domain Knowledge for Large Language Models via Reinforcement Learning from Augmented Generation",
      "title_zh": "é€šè¿‡åŸºäºå¢å¼ºç”Ÿæˆçš„å¼ºåŒ–å­¦ä¹ å®ç°å¤§è¯­è¨€æ¨¡å‹çš„é¢†åŸŸçŸ¥è¯†åµŒå…¥",
      "authors": [
        "Chaojun Nie",
        "Jun Zhou",
        "Guanxiang Wang",
        "Shisong Wu",
        "Zichen Wang"
      ],
      "abstract": "Large language models (LLMs) often exhibit limited performance on domain-specific tasks due to the natural disproportionate representation of specialized information in their training data and the static nature of these datasets. Knowledge scarcity and temporal lag create knowledge gaps for domain applications. While post-training on domain datasets can embed knowledge into models, existing approaches have some limitations. Continual Pre-Training (CPT) treats all tokens in domain documents with equal importance, failing to prioritize critical knowledge points, while supervised fine-tuning (SFT) with question-answer pairs struggles to develop the coherent knowledge structures necessary for complex reasoning tasks. To address these challenges, we propose Reinforcement Learning from Augmented Generation (RLAG). Our approach iteratively cycles between sampling generations and optimizing the model through calculated rewards, effectively embedding critical and contextually coherent domain knowledge. We select generated outputs with the highest log probabilities as the sampling result, then compute three tailored reward metrics to guide the optimization process. To comprehensively evaluate domain expertise, we assess answer accuracy and the rationality of explanations generated for correctly answered questions. Experimental results across medical, legal, astronomy, and current events datasets demonstrate that our proposed method significantly outperforms baseline approaches. Our code and data are open sourced at https://github.com/ChaojunNie/RLAG.",
      "tldr_zh": "å¤§å‹è¯­è¨€æ¨¡å‹ (LLMs) åœ¨ç‰¹å®šé¢†åŸŸä»»åŠ¡ä¸­å¸¸å› ä¸“ä¸šä¿¡æ¯ç¨€ç¼ºå’Œæ•°æ®æ»åè€Œè¡¨ç°å—é™ï¼Œä¸”ç°æœ‰çš„æŒç»­é¢„è®­ç»ƒ (CPT) å’Œç›‘ç£å¾®è°ƒ (SFT) åœ¨å¤„ç†çŸ¥è¯†ä¼˜å…ˆçº§å’Œæ„å»ºè¿è´¯çŸ¥è¯†ç»“æ„æ–¹é¢å­˜åœ¨å±€é™ã€‚è¯¥ç ”ç©¶æå‡ºäº† Reinforcement Learning from Augmented Generation (RLAG) æ–¹æ³•ï¼Œæ—¨åœ¨é€šè¿‡åœ¨ç”Ÿæˆé‡‡æ ·å’Œæ¨¡å‹ä¼˜åŒ–ä¹‹é—´è¿›è¡Œè¿­ä»£å¾ªç¯ï¼Œæœ‰æ•ˆåµŒå…¥å…³é”®ä¸”ä¸Šä¸‹æ–‡è¿è´¯çš„é¢†åŸŸçŸ¥è¯†ã€‚è¯¥æ–¹æ¡ˆé€‰å–å…·æœ‰æœ€é«˜å¯¹æ•°æ¦‚ç‡çš„ç”Ÿæˆç»“æœï¼Œå¹¶åˆ©ç”¨ä¸‰ç§å®šåˆ¶åŒ–çš„å¥–åŠ±æŒ‡æ ‡æ¥ç²¾ç¡®å¼•å¯¼ä¼˜åŒ–è¿‡ç¨‹ã€‚ä¸ºäº†å…¨é¢è¡¡é‡é¢†åŸŸä¸“é•¿ï¼Œç ”ç©¶è€…é’ˆå¯¹åŒ»å­¦ã€æ³•å¾‹ã€å¤©æ–‡å­¦å’Œæ—¶äº‹ç­‰æ•°æ®é›†ï¼Œå¯¹ç­”æ¡ˆå‡†ç¡®æ€§åŠè§£é‡Šçš„åˆç†æ€§è¿›è¡Œäº†ç»¼åˆè¯„ä¼°ã€‚å®éªŒç»“æœè¯æ˜ï¼ŒRLAG æ–¹æ³•åœ¨å„é¡¹æŒ‡æ ‡ä¸Šå‡æ˜¾è‘—ä¼˜äºåŸºçº¿æ–¹æ³•ï¼Œæœ‰æ•ˆå¼¥è¡¥äº†æ¨¡å‹åœ¨ä¸“ä¸šé¢†åŸŸåº”ç”¨ä¸­çš„çŸ¥è¯†é¸¿æ²Ÿã€‚è¯¥ç ”ç©¶å·²å¼€æºç›¸å…³ä»£ç å’Œæ•°æ®ï¼Œä¸ºæå‡ LLMs çš„é¢†åŸŸé€‚é…èƒ½åŠ›æä¾›äº†æ–°çš„æŠ€æœ¯è·¯å¾„ã€‚",
      "categories": [
        "cs.CL",
        "cs.AI"
      ],
      "primary_category": "cs.CL",
      "comment": "Corrected author name spelling",
      "pdf_url": "https://arxiv.org/pdf/2509.20162v2",
      "published_date": "2025-09-24 14:30:16 UTC",
      "updated_date": "2025-09-28 02:06:48 UTC",
      "processing_status": "completed",
      "attempts": 1,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "llm_backup_calls": 0,
      "last_update": "2026-01-24T20:53:30.590781+00:00"
    },
    {
      "arxiv_id": "2509.20154v2",
      "title": "U-Mamba2-SSL for Semi-Supervised Tooth and Pulp Segmentation in CBCT",
      "title_zh": "U-Mamba2-SSLï¼šç”¨äº CBCT ç‰™é½¿ä¸ç‰™é«“åŠç›‘ç£åˆ†å‰²",
      "authors": [
        "Zhi Qin Tan",
        "Xiatian Zhu",
        "Owen Addison",
        "Yunpeng Li"
      ],
      "abstract": "Accurate segmentation of teeth and pulp in Cone-Beam Computed Tomography (CBCT) is vital for clinical applications like treatment planning and diagnosis. However, this process requires extensive expertise and is exceptionally time-consuming, highlighting the critical need for automated algorithms that can effectively utilize unlabeled data. In this paper, we propose U-Mamba2-SSL, a novel semi-supervised learning framework that builds on the U-Mamba2 model and employs a multi-stage training strategy. The framework first pre-trains U-Mamba2 in a self-supervised manner using a disruptive autoencoder. It then leverages unlabeled data through consistency regularization, where we introduce input and feature perturbations to ensure stable model outputs. Finally, a pseudo-labeling strategy is implemented with a reduced loss weighting to minimize the impact of potential errors. U-Mamba2-SSL achieved an average score of 0.789 and a DSC of 0.917 on the hidden test set, achieving first place in Task 1 of the STSR 2025 challenge. The code is available at https://github.com/zhiqin1998/UMamba2.",
      "tldr_zh": "è¯¥ç ”ç©¶æå‡ºäº†U-Mamba2-SSLï¼Œä¸€ç§ä¸“ä¸ºé”¥å½¢æŸæŠ•ç…§è®¡ç®—æœºé‡ç»„åˆ†å±‚æˆåƒ(CBCT)ä¸­ç‰™é½¿ä¸ç‰™é«“è‡ªåŠ¨åˆ†å‰²è®¾è®¡çš„åŠç›‘ç£å­¦ä¹ æ¡†æ¶ã€‚ä¸ºè§£å†³ä¸´åºŠæ ‡æ³¨è€—æ—¶ä¸”ä¸¥é‡ä¾èµ–ä¸“å®¶ç»éªŒçš„éš¾é¢˜ï¼Œè¯¥æ¡†æ¶åœ¨U-Mamba2æ¨¡å‹åŸºç¡€ä¸Šé‡‡ç”¨äº†å¤šé˜¶æ®µè®­ç»ƒç­–ç•¥ï¼Œé¦–å…ˆåˆ©ç”¨ç ´åæ€§è‡ªç¼–ç å™¨(disruptive autoencoder)è¿›è¡Œè‡ªç›‘ç£é¢„è®­ç»ƒä»¥æå–ç‰¹å¾ã€‚éšåï¼Œç ”ç©¶é€šè¿‡å¼•å…¥è¾“å…¥ä¸ç‰¹å¾æ‰°åŠ¨çš„ä¸€è‡´æ€§æ­£åˆ™åŒ–(consistency regularization)æŠ€æœ¯ï¼Œæœ‰æ•ˆæŒ–æ˜æ— æ ‡ç­¾æ•°æ®çš„ä¿¡æ¯å¹¶ç¡®ä¿æ¨¡å‹è¾“å‡ºçš„ç¨³å®šæ€§ã€‚æ­¤å¤–ï¼Œæ¡†æ¶è¿˜ç»“åˆäº†é™ä½æŸå¤±æƒé‡çš„ä¼ªæ ‡ç­¾(pseudo-labeling)ç­–ç•¥ï¼Œæ—¨åœ¨æœ€å¤§é™åº¦å‡å°‘æ½œåœ¨æ ‡æ³¨é”™è¯¯å¯¹æ¨¡å‹å­¦ä¹ çš„å¹²æ‰°ã€‚åœ¨STSR 2025æŒ‘æˆ˜èµ›ä¸­ï¼ŒU-Mamba2-SSLä»¥0.917çš„DSCå¾—åˆ†è·å¾—ä»»åŠ¡ä¸€å† å†›ï¼ŒéªŒè¯äº†è¯¥æ–¹æ³•åœ¨å¤„ç†å¤æ‚ç‰™ç§‘å½±åƒæ•°æ®æ—¶çš„å“è¶Šæ€§èƒ½ä¸ä¸´åºŠåº”ç”¨æ½œåŠ›ã€‚",
      "categories": [
        "cs.CV",
        "cs.AI"
      ],
      "primary_category": "cs.CV",
      "comment": "First place solution in Task 1 of the STSR 2025 challenge, MICCAI 2025",
      "pdf_url": "https://arxiv.org/pdf/2509.20154v2",
      "published_date": "2025-09-24 14:19:33 UTC",
      "updated_date": "2025-09-30 12:23:13 UTC",
      "processing_status": "completed",
      "attempts": 1,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "llm_backup_calls": 0,
      "last_update": "2026-01-24T20:53:44.503203+00:00"
    },
    {
      "arxiv_id": "2509.20153v2",
      "title": "Affective Computing and Emotional Data: Challenges and Implications in Privacy Regulations, The AI Act, and Ethics in Large Language Models",
      "title_zh": "æƒ…æ„Ÿè®¡ç®—ä¸æƒ…æ„Ÿæ•°æ®ï¼šéšç§ç›‘ç®¡ã€AI Act åŠå¤§è¯­è¨€æ¨¡å‹ä¼¦ç†é¢ä¸´çš„æŒ‘æˆ˜ä¸å½±å“",
      "authors": [
        "Nicola Fabiano"
      ],
      "abstract": "This paper examines the integration of emotional intelligence into artificial intelligence systems, with a focus on affective computing and the growing capabilities of Large Language Models (LLMs), such as ChatGPT and Claude, to recognize and respond to human emotions. Drawing on interdisciplinary research that combines computer science, psychology, and neuroscience, the study analyzes foundational neural architectures - CNNs for processing facial expressions and RNNs for sequential data, such as speech and text - that enable emotion recognition. It examines the transformation of human emotional experiences into structured emotional data, addressing the distinction between explicit emotional data collected with informed consent in research settings and implicit data gathered passively through everyday digital interactions. That raises critical concerns about lawful processing, AI transparency, and individual autonomy over emotional expressions in digital environments. The paper explores implications across various domains, including healthcare, education, and customer service, while addressing challenges of cultural variations in emotional expression and potential biases in emotion recognition systems across different demographic groups. From a regulatory perspective, the paper examines emotional data in the context of the GDPR and the EU AI Act frameworks, highlighting how emotional data may be considered sensitive personal data that requires robust safeguards, including purpose limitation, data minimization, and meaningful consent mechanisms.",
      "tldr_zh": "è¯¥ç ”ç©¶æ¢è®¨äº†åœ¨äººå·¥æ™ºèƒ½ç³»ç»Ÿä¸­æ•´åˆæƒ…æ„Ÿæ™ºèƒ½çš„ç°çŠ¶ï¼Œé‡ç‚¹åˆ†æäº† Affective Computing ä¸ Large Language Models (LLMs)ï¼ˆå¦‚ ChatGPT å’Œ Claudeï¼‰è¯†åˆ«å¹¶å“åº”äººç±»æƒ…æ„Ÿçš„èƒ½åŠ›ã€‚æ–‡ç« æ·±å…¥ç ”ç©¶äº†ç”¨äºé¢éƒ¨è¡¨æƒ…å¤„ç†çš„ CNNs å’Œç”¨äºè¯­éŸ³åŠæ–‡æœ¬åºåˆ—æ•°æ®å¤„ç†çš„ RNNs ç­‰åŸºç¡€ç¥ç»æ¶æ„ï¼Œä»¥åŠæƒ…æ„Ÿä½“éªŒå‘ç»“æ„åŒ– Emotional Data è½¬åŒ–çš„è¿‡ç¨‹ã€‚é€šè¿‡å¯¹æ¯”æ˜¾å¼é‡‡é›†ä¸è¢«åŠ¨æ”¶é›†çš„éšå¼æ•°æ®ï¼Œç ”ç©¶æŒ‡å‡ºäº† AI é€æ˜åº¦ã€æ³•å¾‹åˆè§„æ€§åŠä¸ªäººæƒ…æ„Ÿè¡¨è¾¾è‡ªä¸»æƒé¢ä¸´çš„ä¸¥å³»æŒ‘æˆ˜ã€‚æ–‡ç« è¿›ä¸€æ­¥æ¢è®¨äº†æƒ…æ„Ÿè®¡ç®—åœ¨åŒ»ç–—ã€æ•™è‚²å’Œå®¢æˆ·æœåŠ¡é¢†åŸŸçš„åº”ç”¨æ½œåŠ›ï¼ŒåŒæ—¶åˆ†æäº†æ–‡åŒ–å·®å¼‚å’Œäººå£ç»Ÿè®¡åè§å¯¹è¯†åˆ«ç³»ç»Ÿçš„å½±å“ã€‚åœ¨ç›‘ç®¡å±‚é¢ï¼Œç ”ç©¶ç»“åˆ GDPR å’Œ EU AI Act æ¡†æ¶ï¼Œè®ºè¯äº†å°†æƒ…æ„Ÿæ•°æ®è§†ä¸ºæ•æ„Ÿä¸ªäººæ•°æ®çš„å¿…è¦æ€§ï¼Œå¹¶å‘¼åå»ºç«‹åŒ…å«ç›®çš„é™åˆ¶ã€æ•°æ®æœ€å°åŒ–åŠæœ‰æ•ˆçŸ¥æƒ…åŒæ„æœºåˆ¶çš„ç¨³å¥ä¿æŠ¤ä½“ç³»ã€‚",
      "categories": [
        "cs.CY",
        "cs.AI"
      ],
      "primary_category": "cs.CY",
      "comment": "",
      "pdf_url": "https://arxiv.org/pdf/2509.20153v2",
      "published_date": "2025-09-24 14:18:41 UTC",
      "updated_date": "2025-09-25 10:43:22 UTC",
      "processing_status": "completed",
      "attempts": 1,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "llm_backup_calls": 0,
      "last_update": "2026-01-24T20:54:10.298262+00:00"
    },
    {
      "arxiv_id": "2509.20146v1",
      "title": "EchoBench: Benchmarking Sycophancy in Medical Large Vision-Language Models",
      "title_zh": "EchoBenchï¼šåŒ»ç–—å¤§è§†è§‰è¯­è¨€æ¨¡å‹è°„åªšæ€§åŸºå‡†æµ‹è¯•",
      "authors": [
        "Botai Yuan",
        "Yutian Zhou",
        "Yingjie Wang",
        "Fushuo Huo",
        "Yongcheng Jing",
        "Li Shen",
        "Ying Wei",
        "Zhiqi Shen",
        "Ziwei Liu",
        "Tianwei Zhang",
        "Jie Yang",
        "Dacheng Tao"
      ],
      "abstract": "Recent benchmarks for medical Large Vision-Language Models (LVLMs) emphasize leaderboard accuracy, overlooking reliability and safety. We study sycophancy -- models' tendency to uncritically echo user-provided information -- in high-stakes clinical settings. We introduce EchoBench, a benchmark to systematically evaluate sycophancy in medical LVLMs. It contains 2,122 images across 18 departments and 20 modalities with 90 prompts that simulate biased inputs from patients, medical students, and physicians. We evaluate medical-specific, open-source, and proprietary LVLMs. All exhibit substantial sycophancy; the best proprietary model (Claude 3.7 Sonnet) still shows 45.98% sycophancy, and GPT-4.1 reaches 59.15%. Many medical-specific models exceed 95% sycophancy despite only moderate accuracy. Fine-grained analyses by bias type, department, perceptual granularity, and modality identify factors that increase susceptibility. We further show that higher data quality/diversity and stronger domain knowledge reduce sycophancy without harming unbiased accuracy. EchoBench also serves as a testbed for mitigation: simple prompt-level interventions (negative prompting, one-shot, few-shot) produce consistent reductions and motivate training- and decoding-time strategies. Our findings highlight the need for robust evaluation beyond accuracy and provide actionable guidance toward safer, more trustworthy medical LVLMs.",
      "tldr_zh": "è¯¥ç ”ç©¶æ¢è®¨äº†åŒ»ç–—é¢†åŸŸ Large Vision-Language Models (LVLMs) ä¸­çš„ Sycophancy é—®é¢˜ï¼Œå³æ¨¡å‹å€¾å‘äºç›²ç›®é™„å’Œç”¨æˆ·æä¾›çš„é”™è¯¯æˆ–åè§ä¿¡æ¯ï¼Œä»è€Œå¨èƒä¸´åºŠå†³ç­–çš„å¯é æ€§ã€‚ä¸ºæ­¤ï¼Œä½œè€…æå‡ºäº† EchoBench åŸºå‡†æµ‹è¯•ï¼ŒåŒ…å«æ¶µç›– 18 ä¸ªç§‘å®¤å’Œ 20 ç§æ¨¡æ€çš„ 2,122 å¼ å›¾åƒï¼Œé€šè¿‡ 90 ç§æç¤ºè¯­æ¨¡æ‹Ÿæ¥è‡ªæ‚£è€…ã€åŒ»å­¦ç”Ÿå’ŒåŒ»ç”Ÿçš„åè§è¾“å…¥ã€‚å®éªŒç»“æœæ˜¾ç¤ºï¼ŒåŒ…æ‹¬ Claude 3.7 Sonnet å’Œ GPT-4.1 åœ¨å†…çš„é¢†å…ˆæ¨¡å‹å‡è¡¨ç°å‡ºä¸¥é‡çš„ Sycophancy å€¾å‘ï¼Œéƒ¨åˆ†åŒ»ç–—ä¸“ç”¨æ¨¡å‹çš„è¯¥æ¯”ä¾‹ç”šè‡³è¶…è¿‡ 95%ã€‚ç ”ç©¶è¿›ä¸€æ­¥è¯æ˜ï¼Œæé«˜æ•°æ®è´¨é‡ã€å¤šæ ·æ€§ä»¥åŠå¢å¼ºé¢†åŸŸçŸ¥è¯†å¯ä»¥åœ¨ä¸æŸå®³å‡†ç¡®æ€§çš„å‰æä¸‹é™ä½è¯¥é£é™©ã€‚æ­¤å¤–ï¼ŒEchoBench è¿˜éªŒè¯äº† Negative Promptingã€One-shot å’Œ Few-shot ç­‰æç¤ºå±‚çº§å¹²é¢„æªæ–½çš„æœ‰æ•ˆæ€§ã€‚è¯¥é¡¹å·¥ä½œä¸ºæ„å»ºæ›´å®‰å…¨ã€æ›´å¯ä¿¡çš„åŒ»ç–— LVLMs æä¾›äº†ç³»ç»Ÿæ€§çš„è¯„ä¼°æ¡†æ¶å’Œæ”¹è¿›ç­–ç•¥ã€‚",
      "categories": [
        "cs.CV",
        "cs.AI"
      ],
      "primary_category": "cs.CV",
      "comment": "29 pages, 6 figures",
      "pdf_url": "https://arxiv.org/pdf/2509.20146v1",
      "published_date": "2025-09-24 14:09:55 UTC",
      "updated_date": "2025-09-24 14:09:55 UTC",
      "processing_status": "completed",
      "attempts": 1,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "llm_backup_calls": 0,
      "last_update": "2026-01-24T20:53:44.969702+00:00"
    },
    {
      "arxiv_id": "2509.20138v1",
      "title": "Formal Verification of Minimax Algorithms",
      "title_zh": "æå¤§æå°ç®—æ³•çš„å½¢å¼åŒ–éªŒè¯",
      "authors": [
        "Wieger Wesselink",
        "Kees Huizing",
        "Huub van de Wetering"
      ],
      "abstract": "Using the Dafny verification system, we formally verify a range of minimax search algorithms, including variations with alpha-beta pruning and transposition tables. For depth-limited search with transposition tables, we introduce a witness-based correctness criterion and apply it to two representative algorithms. All verification artifacts, including proofs and Python implementations, are publicly available.",
      "tldr_zh": "è¯¥ç ”ç©¶åˆ©ç”¨ Dafny éªŒè¯ç³»ç»Ÿï¼Œå¯¹åŒ…æ‹¬ alpha-beta pruning å’Œ transposition tables å˜ä½“åœ¨å†…çš„å¤šç§ minimax æœç´¢ç®—æ³•è¿›è¡Œäº†å½¢å¼åŒ–éªŒè¯ (Formal Verification)ã€‚é’ˆå¯¹ç»“åˆ transposition tables çš„æ·±åº¦å—é™æœç´¢ (depth-limited search)ï¼Œç ”ç©¶è€…æå‡ºäº†ä¸€ç§åŸºäºè§è¯ (witness-based) çš„æ­£ç¡®æ€§å‡†åˆ™ï¼Œå¹¶å°†å…¶åº”ç”¨äºä¸¤ä¸ªå…·æœ‰ä»£è¡¨æ€§çš„ç®—æ³•ä¸­ã€‚è¯¥å·¥ä½œé€šè¿‡ä¸¥è°¨çš„é€»è¾‘è¯æ˜ç¡®ä¿äº†åšå¼ˆæœç´¢ç®—æ³•çš„å¯é æ€§ã€‚ç›®å‰ï¼Œæ‰€æœ‰çš„éªŒè¯äº§ç‰©ï¼ŒåŒ…æ‹¬è¯¦ç»†çš„è¯æ˜è¿‡ç¨‹å’Œ Python å®ç°ä»£ç ï¼Œå‡å·²å‘å…¬ä¼—å¼€æ”¾ã€‚è¯¥ç ”ç©¶ä¸ºå¤æ‚æœç´¢ç®—æ³•çš„æ­£ç¡®æ€§ä¿éšœæä¾›äº†é‡è¦çš„ç†è®ºåŸºç¡€å’Œå·¥å…·æ”¯æŒã€‚",
      "categories": [
        "cs.AI"
      ],
      "primary_category": "cs.AI",
      "comment": "12 pages",
      "pdf_url": "https://arxiv.org/pdf/2509.20138v1",
      "published_date": "2025-09-24 14:02:33 UTC",
      "updated_date": "2025-09-24 14:02:33 UTC",
      "processing_status": "completed",
      "attempts": 1,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "llm_backup_calls": 0,
      "last_update": "2026-01-24T20:54:31.091022+00:00"
    },
    {
      "arxiv_id": "2509.20128v1",
      "title": "KSDiff: Keyframe-Augmented Speech-Aware Dual-Path Diffusion for Facial Animation",
      "title_zh": "KSDiffï¼šé¢å‘é¢éƒ¨åŠ¨ç”»çš„å…³é”®å¸§å¢å¼ºè¯­éŸ³æ„ŸçŸ¥åŒè·¯å¾„æ‰©æ•£æ¨¡å‹",
      "authors": [
        "Tianle Lyu",
        "Junchuan Zhao",
        "Ye Wang"
      ],
      "abstract": "Audio-driven facial animation has made significant progress in multimedia applications, with diffusion models showing strong potential for talking-face synthesis. However, most existing works treat speech features as a monolithic representation and fail to capture their fine-grained roles in driving different facial motions, while also overlooking the importance of modeling keyframes with intense dynamics. To address these limitations, we propose KSDiff, a Keyframe-Augmented Speech-Aware Dual-Path Diffusion framework. Specifically, the raw audio and transcript are processed by a Dual-Path Speech Encoder (DPSE) to disentangle expression-related and head-pose-related features, while an autoregressive Keyframe Establishment Learning (KEL) module predicts the most salient motion frames. These components are integrated into a Dual-path Motion generator to synthesize coherent and realistic facial motions. Extensive experiments on HDTF and VoxCeleb demonstrate that KSDiff achieves state-of-the-art performance, with improvements in both lip synchronization accuracy and head-pose naturalness. Our results highlight the effectiveness of combining speech disentanglement with keyframe-aware diffusion for talking-head generation.",
      "tldr_zh": "è¯¥ç ”ç©¶æå‡ºäº†KSDiffï¼Œä¸€ç§å…³é”®å¸§å¢å¼ºä¸”è¯­éŸ³æ„ŸçŸ¥çš„åŒè·¯å¾„æ‰©æ•£(Dual-Path Diffusion)æ¡†æ¶ï¼Œæ—¨åœ¨è§£å†³éŸ³é¢‘é©±åŠ¨é¢éƒ¨åŠ¨ç”»ä¸­è¯­éŸ³ç‰¹å¾è¡¨ç¤ºå•ä¸€ä»¥åŠå¿½è§†åŠ¨æ€å‰§çƒˆå…³é”®å¸§å»ºæ¨¡çš„é—®é¢˜ã€‚è¯¥æ¡†æ¶å¼•å…¥äº†åŒè·¯å¾„è¯­éŸ³ç¼–ç å™¨(Dual-Path Speech Encoder, DPSE)ï¼Œé€šè¿‡å¤„ç†åŸå§‹éŸ³é¢‘å’Œæ–‡æœ¬ï¼Œå°†ä¸è¡¨æƒ…ç›¸å…³å’Œä¸å¤´éƒ¨å§¿æ€ç›¸å…³çš„ç‰¹å¾è¿›è¡Œè§£è€¦ã€‚åŒæ—¶ï¼Œç³»ç»Ÿé‡‡ç”¨è‡ªå›å½’çš„å…³é”®å¸§å»ºç«‹å­¦ä¹ (Keyframe Establishment Learning, KEL)æ¨¡å—æ¥é¢„æµ‹æœ€æ˜¾è‘—çš„åŠ¨ä½œå¸§ï¼Œå¹¶å°†è¿™äº›ç»„ä»¶é›†æˆåˆ°åŒè·¯å¾„è¿åŠ¨ç”Ÿæˆå™¨(Dual-path Motion generator)ä¸­ä»¥åˆæˆé€¼çœŸåŠ¨ä½œã€‚åœ¨HDTFå’ŒVoxCelebæ•°æ®é›†ä¸Šçš„å®éªŒè¡¨æ˜ï¼ŒKSDiffåœ¨å”‡å½¢åŒæ­¥å‡†ç¡®åº¦å’Œå¤´éƒ¨å§¿æ€è‡ªç„¶åº¦æ–¹é¢å‡è¾¾åˆ°äº†SOTAæ€§èƒ½ã€‚ç ”ç©¶ç»“æœè¯æ˜äº†å°†è¯­éŸ³è§£è€¦ä¸å…³é”®å¸§æ„ŸçŸ¥æ‰©æ•£æŠ€æœ¯ç›¸ç»“åˆåœ¨è°ˆè¯äººè„¸ç”Ÿæˆ(talking-head generation)ä»»åŠ¡ä¸­çš„æœ‰æ•ˆæ€§ã€‚",
      "categories": [
        "cs.GR",
        "cs.AI",
        "cs.CV",
        "cs.MM"
      ],
      "primary_category": "cs.GR",
      "comment": "5 pages, 3 figures, 3 tables",
      "pdf_url": "https://arxiv.org/pdf/2509.20128v1",
      "published_date": "2025-09-24 13:54:52 UTC",
      "updated_date": "2025-09-24 13:54:52 UTC",
      "processing_status": "completed",
      "attempts": 1,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "llm_backup_calls": 0,
      "last_update": "2026-01-24T20:54:42.694622+00:00"
    },
    {
      "arxiv_id": "2509.20113v3",
      "title": "Discovering Association Rules in High-Dimensional Small Tabular Data",
      "title_zh": "é«˜ç»´å°æ ·æœ¬è¡¨æ ¼æ•°æ®ä¸­çš„å…³è”è§„åˆ™å‘ç°",
      "authors": [
        "Erkan Karabulut",
        "Daniel Daza",
        "Paul Groth",
        "Victoria Degeler"
      ],
      "abstract": "Association Rule Mining (ARM) aims to discover patterns between features in datasets in the form of propositional rules, supporting both knowledge discovery and interpretable machine learning in high-stakes decision-making. However, in high-dimensional settings, rule explosion and computational overhead render popular algorithmic approaches impractical without effective search space reduction, challenges that propagate to downstream tasks. Neurosymbolic methods, such as Aerial+, have recently been proposed to address the rule explosion in ARM. While they tackle the high dimensionality of the data, they also inherit limitations of neural networks, particularly reduced performance in low-data regimes.\n  This paper makes three key contributions to association rule discovery in high-dimensional tabular data. First, we empirically show that Aerial+ scales one to two orders of magnitude better than state-of-the-art algorithmic and neurosymbolic baselines across five real-world datasets. Second, we introduce the novel problem of ARM in high-dimensional, low-data settings, such as gene expression data from the biomedicine domain with around 18k features and 50 samples. Third, we propose two fine-tuning approaches to Aerial+ using tabular foundation models. Our proposed approaches are shown to significantly improve rule quality on five real-world datasets, demonstrating their effectiveness in low-data, high-dimensional scenarios.",
      "tldr_zh": "è¯¥ç ”ç©¶æ¢è®¨äº†é«˜ç»´å°æ ·æœ¬è¡¨æ ¼æ•°æ®ä¸­çš„ Association Rule Mining (ARM) é—®é¢˜ï¼Œé’ˆå¯¹ä¼ ç»Ÿç®—æ³•åœ¨é«˜ç»´ç¯å¢ƒä¸‹é¢ä¸´çš„è§„åˆ™çˆ†ç‚¸å’Œè®¡ç®—å¼€é”€æŒ‘æˆ˜è¿›è¡Œäº†æ·±å…¥åˆ†æã€‚è™½ç„¶ Aerial+ ç­‰ Neurosymbolic æ–¹æ³•èƒ½ç¼“è§£é«˜ç»´å¸¦æ¥çš„å‹åŠ›ï¼Œä½†å…¶åœ¨ä½æ•°æ®é‡åœºæ™¯ä¸‹å¾€å¾€å­˜åœ¨æ€§èƒ½å±€é™ã€‚æœ¬æ–‡é¦–å…ˆé€šè¿‡å®éªŒè¯æ˜ Aerial+ åœ¨æ‰©å±•æ€§ä¸Šæ¯”ç°æœ‰åŸºçº¿æ¨¡å‹é«˜å‡ºä¸€åˆ°ä¸¤ä¸ªæ•°é‡çº§ã€‚æ¥ç€ï¼Œç ”ç©¶è€…æ­£å¼æå‡ºäº†é«˜ç»´ã€ä½æ•°æ®é‡ç¯å¢ƒä¸‹çš„ ARM è¿™ä¸€æ–°è¯¾é¢˜ï¼Œå¹¶é’ˆå¯¹æ€§åœ°å¼€å‘äº†ä¸¤ç§åˆ©ç”¨ Tabular Foundation Models å¯¹ Aerial+ è¿›è¡Œ Fine-tuning çš„ä¼˜åŒ–æ–¹æ¡ˆã€‚å®éªŒç»“æœè¡¨æ˜ï¼Œè¯¥æ–¹æ³•åœ¨åŒ…æ‹¬åŸºå› è¡¨è¾¾æ•°æ®åœ¨å†…çš„äº”ä¸ªçœŸå®æ•°æ®é›†ä¸Šæ˜¾è‘—æå‡äº†è§„åˆ™è´¨é‡ï¼Œæœ‰æ•ˆè§£å†³äº†é«˜ç»´å°æ ·æœ¬åœºæ™¯ä¸‹çš„å…³è”è§„åˆ™å‘ç°éš¾é¢˜ã€‚",
      "categories": [
        "cs.LG",
        "cs.AI"
      ],
      "primary_category": "cs.LG",
      "comment": "Published version is available at https://ceur-ws.org/Vol-4125/paper_26.pdf",
      "pdf_url": "https://arxiv.org/pdf/2509.20113v3",
      "published_date": "2025-09-24 13:37:53 UTC",
      "updated_date": "2026-01-05 14:53:38 UTC",
      "processing_status": "completed",
      "attempts": 1,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "llm_backup_calls": 0,
      "last_update": "2026-01-24T20:54:44.588942+00:00"
    },
    {
      "arxiv_id": "2509.20109v1",
      "title": "Discrete Diffusion for Reflective Vision-Language-Action Models in Autonomous Driving",
      "title_zh": "è‡ªåŠ¨é©¾é©¶ä¸­é¢å‘åæ€å‹è§†è§‰-è¯­è¨€-åŠ¨ä½œæ¨¡å‹çš„ç¦»æ•£æ‰©æ•£",
      "authors": [
        "Pengxiang Li",
        "Yinan Zheng",
        "Yue Wang",
        "Huimin Wang",
        "Hang Zhao",
        "Jingjing Liu",
        "Xianyuan Zhan",
        "Kun Zhan",
        "Xianpeng Lang"
      ],
      "abstract": "End-to-End (E2E) solutions have emerged as a mainstream approach for autonomous driving systems, with Vision-Language-Action (VLA) models representing a new paradigm that leverages pre-trained multimodal knowledge from Vision-Language Models (VLMs) to interpret and interact with complex real-world environments. However, these methods remain constrained by the limitations of imitation learning, which struggles to inherently encode physical rules during training. Existing approaches often rely on complex rule-based post-refinement, employ reinforcement learning that remains largely limited to simulation, or utilize diffusion guidance that requires computationally expensive gradient calculations. To address these challenges, we introduce ReflectDrive, a novel learning-based framework that integrates a reflection mechanism for safe trajectory generation via discrete diffusion. We first discretize the two-dimensional driving space to construct an action codebook, enabling the use of pre-trained Diffusion Language Models for planning tasks through fine-tuning. Central to our approach is a safety-aware reflection mechanism that performs iterative self-correction without gradient computation. Our method begins with goal-conditioned trajectory generation to model multi-modal driving behaviors. Based on this, we apply local search methods to identify unsafe tokens and determine feasible solutions, which then serve as safe anchors for inpainting-based regeneration. Evaluated on the NAVSIM benchmark, ReflectDrive demonstrates significant advantages in safety-critical trajectory generation, offering a scalable and reliable solution for autonomous driving systems.",
      "tldr_zh": "è¯¥ç ”ç©¶é’ˆå¯¹è‡ªåŠ¨é©¾é©¶ç«¯åˆ°ç«¯æ–¹æ¡ˆä¸­ Vision-Language-Action (VLA) æ¨¡å‹éš¾ä»¥åœ¨æ¨¡ä»¿å­¦ä¹ ä¸­æœ‰æ•ˆç¼–ç ç‰©ç†è§„åˆ™ï¼Œä¸”ç°æœ‰ä¿®æ­£æ–¹æ³•è®¡ç®—æˆæœ¬é«˜æ˜‚çš„é—®é¢˜ï¼Œæå‡ºäº† ReflectDrive æ¡†æ¶ã€‚è¯¥æ¡†æ¶é€šè¿‡å¯¹äºŒç»´é©¾é©¶ç©ºé—´è¿›è¡Œç¦»æ•£åŒ–å¤„ç†æ¥æ„å»º Action Codebookï¼Œä»è€Œèƒ½å¤Ÿåˆ©ç”¨é¢„è®­ç»ƒçš„ Diffusion Language Models ç»å¾®è°ƒåæ‰§è¡Œè§„åˆ’ä»»åŠ¡ã€‚ReflectDrive çš„æ ¸å¿ƒåœ¨äºå¼•å…¥äº†ä¸€ç§å®‰å…¨æ„ŸçŸ¥çš„ Reflection Mechanismï¼Œèƒ½å¤Ÿåœ¨æ— éœ€æ¢¯åº¦è®¡ç®—çš„æƒ…å†µä¸‹è¿›è¡Œè¿­ä»£å¼è‡ªæˆ‘ä¿®æ­£ä»¥ç”Ÿæˆå®‰å…¨è½¨è¿¹ã€‚è¯¥æ–¹æ³•é¦–å…ˆç”Ÿæˆç›®æ ‡æ¡ä»¶è½¨è¿¹ï¼Œéšååˆ©ç”¨å±€éƒ¨æœç´¢è¯†åˆ«ä¸å®‰å…¨ Token å¹¶ç¡®å®šå¯è¡Œæ–¹æ¡ˆï¼Œå°†å…¶ä½œä¸º Safe Anchors è¿›è¡ŒåŸºäº Inpainting çš„è½¨è¿¹é‡æ„ã€‚åœ¨ NAVSIM åŸºå‡†æµ‹è¯•ä¸Šçš„å®éªŒç»“æœè¡¨æ˜ï¼ŒReflectDrive åœ¨å®‰å…¨å…³é”®å‹è½¨è¿¹ç”Ÿæˆæ–¹é¢å±•ç°å‡ºæ˜¾è‘—ä¼˜åŠ¿ï¼Œä¸ºè‡ªåŠ¨é©¾é©¶ç³»ç»Ÿæä¾›äº†ä¸€ç§å…·å¤‡å¯æ‰©å±•æ€§å’Œé«˜å¯é æ€§çš„è§£å†³æ–¹æ¡ˆã€‚",
      "categories": [
        "cs.RO",
        "cs.AI",
        "cs.CL"
      ],
      "primary_category": "cs.RO",
      "comment": "",
      "pdf_url": "https://arxiv.org/pdf/2509.20109v1",
      "published_date": "2025-09-24 13:35:15 UTC",
      "updated_date": "2025-09-24 13:35:15 UTC",
      "processing_status": "completed",
      "attempts": 1,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "llm_backup_calls": 0,
      "last_update": "2026-01-24T20:54:49.094842+00:00"
    },
    {
      "arxiv_id": "2509.20107v2",
      "title": "Hyperspectral Adapter for Semantic Segmentation with Vision Foundation Models",
      "title_zh": "åŸºäºè§†è§‰åŸºç¡€æ¨¡å‹çš„é«˜å…‰è°±è¯­ä¹‰åˆ†å‰²é€‚é…å™¨",
      "authors": [
        "Juana Valeria Hurtado",
        "Rohit Mohan",
        "Abhinav Valada"
      ],
      "abstract": "Hyperspectral imaging (HSI) captures spatial information along with dense spectral measurements across numerous narrow wavelength bands. This rich spectral content has the potential to facilitate robust robotic perception, particularly in environments with complex material compositions, varying illumination, or other visually challenging conditions. However, current HSI semantic segmentation methods underperform due to their reliance on architectures and learning frameworks optimized for RGB inputs. In this work, we propose a novel hyperspectral adapter that leverages pretrained vision foundation models to effectively learn from hyperspectral data. Our architecture incorporates a spectral transformer and a spectrum-aware spatial prior module to extract rich spatial-spectral features. Additionally, we introduce a modality-aware interaction block that facilitates effective integration of hyperspectral representations and frozen vision Transformer features through dedicated extraction and injection mechanisms. Extensive evaluations on three benchmark autonomous driving datasets demonstrate that our architecture achieves state-of-the-art semantic segmentation performance while directly using HSI inputs, outperforming both vision-based and hyperspectral segmentation methods. We make the code available at https://hsi-adapter.cs.uni-freiburg.de.",
      "tldr_zh": "è¯¥ç ”ç©¶é’ˆå¯¹é«˜å…‰è°±å›¾åƒ (Hyperspectral Imaging) åœ¨è¯­ä¹‰åˆ†å‰²ä¸­å› ä¾èµ– RGB ä¼˜åŒ–æ¶æ„è€Œæ€§èƒ½å—é™çš„é—®é¢˜ï¼Œæå‡ºäº†ä¸€ç§æ–°å‹çš„é«˜å…‰è°±é€‚é…å™¨ (hyperspectral adapter)ï¼Œæ—¨åœ¨åˆ©ç”¨é¢„è®­ç»ƒçš„è§†è§‰åŸºç¡€æ¨¡å‹ (vision foundation models) æœ‰æ•ˆå¤„ç†é«˜å…‰è°±æ•°æ®ã€‚è¯¥æ¶æ„é›†æˆäº†å…‰è°±å˜æ¢å™¨ (spectral transformer) å’Œå…‰è°±æ„ŸçŸ¥ç©ºé—´å…ˆéªŒæ¨¡å— (spectrum-aware spatial prior module)ï¼Œä»¥æå–ä¸°å¯Œçš„ç©ºé—´-å…‰è°±ç‰¹å¾ã€‚æ­¤å¤–ï¼Œç ”ç©¶è¿˜å¼•å…¥äº†æ¨¡æ€æ„ŸçŸ¥äº¤äº’å— (modality-aware interaction block)ï¼Œé€šè¿‡ä¸“é—¨çš„æå–ä¸æ³¨å…¥æœºåˆ¶ï¼Œå®ç°äº†é«˜å…‰è°±è¡¨ç¤ºä¸å†»ç»“çš„è§†è§‰ Transformer ç‰¹å¾çš„æ·±åº¦æ•´åˆã€‚åœ¨ä¸‰ä¸ªè‡ªåŠ¨é©¾é©¶åŸºå‡†æ•°æ®é›†ä¸Šçš„å®éªŒç»“æœæ˜¾ç¤ºï¼Œè¯¥æ¶æ„åœ¨ç›´æ¥ä½¿ç”¨ HSI è¾“å…¥æ—¶è¾¾åˆ°äº†é¢†åŸŸå†…æœ€å…ˆè¿› (SOTA) çš„è¯­ä¹‰åˆ†å‰²æ€§èƒ½ï¼Œæ˜¾è‘—ä¼˜äºç°æœ‰çš„è§†è§‰å’Œé«˜å…‰è°±åˆ†å‰²æ–¹æ³•ã€‚",
      "categories": [
        "cs.CV",
        "cs.AI",
        "cs.LG",
        "cs.RO"
      ],
      "primary_category": "cs.CV",
      "comment": "",
      "pdf_url": "https://arxiv.org/pdf/2509.20107v2",
      "published_date": "2025-09-24 13:32:07 UTC",
      "updated_date": "2025-09-25 11:37:47 UTC",
      "processing_status": "completed",
      "attempts": 1,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "llm_backup_calls": 0,
      "last_update": "2026-01-24T20:54:52.788792+00:00"
    },
    {
      "arxiv_id": "2509.20105v1",
      "title": "PEPS: Quantum-Inspired Reinforcement Learning for Coherent Reasoning Traces in LLMs",
      "title_zh": "PEPSï¼šé¢å‘å¤§è¯­è¨€æ¨¡å‹è¿è´¯æ¨ç†è½¨è¿¹çš„é‡å­å¯å‘å¼å¼ºåŒ–å­¦ä¹ ",
      "authors": [
        "Venkat Margapuri",
        "Garik Kazanjian",
        "Naren Kosaraju"
      ],
      "abstract": "Large Language Models (LLMs) often struggle with maintaining coherent multi-step reasoning traces, particularly in tasks that require a structured logical flow. This work introduces a quantum-inspired approach to address the challenge by incorporating a fidelity-based reward derived from Projected Entangled Pair States (PEPS) into Proximal Policy Optimization. Unlike prior approaches that use direct supervision or contrastive objectives, the proposed method guides learning through structural consistency, offering a novel approach to enforce global coherence in generated reasoning traces. The proposed framework is evaluated using multiple coherence-determining metrics on diverse datasets such as GSM8K, StrategyQA, and EntailmentBank spanning arithmetic, intuitive, and entailment-based reasoning. Results show that the proposed quantum-inspired approach offers significant improvements over supervised, contrastive, and pretrained baseline approaches, highlighting the effectiveness of quantum-inspired fidelity as a foundation to improve reasoning trace coherence in LLMs.",
      "tldr_zh": "è¯¥ç ”ç©¶æå‡ºäº†PEPSï¼Œä¸€ç§å—é‡å­å¯å‘(quantum-inspired)çš„å¼ºåŒ–å­¦ä¹ æ¡†æ¶ï¼Œæ—¨åœ¨è§£å†³å¤§å‹è¯­è¨€æ¨¡å‹(LLMs)åœ¨å¤„ç†ç»“æ„åŒ–é€»è¾‘æµä»»åŠ¡æ—¶éš¾ä»¥ç»´æŒè¿è´¯å¤šæ­¥æ¨ç†è½¨è¿¹çš„æŒ‘æˆ˜ã€‚è¯¥æ–¹æ³•åˆ›æ–°æ€§åœ°å°†æºè‡ªæŠ•å½±çº ç¼ å¯¹æ€(Projected Entangled Pair States, PEPS)çš„ä¿çœŸåº¦å¥–åŠ±(fidelity-based reward)æ•´åˆåˆ°è¿‘ç«¯ç­–ç•¥ä¼˜åŒ–(Proximal Policy Optimization, PPO)ç®—æ³•ä¸­ã€‚ä¸åŒäºä»¥å¾€ä¾èµ–ç›´æ¥ç›‘ç£æˆ–å¯¹æ¯”ç›®æ ‡çš„æ‰‹æ®µï¼ŒPEPSé€šè¿‡ç»“æ„ä¸€è‡´æ€§æ¥å¼•å¯¼å­¦ä¹ è¿‡ç¨‹ï¼Œä¸ºå¢å¼ºç”Ÿæˆæ¨ç†åºåˆ—çš„å…¨å±€è¿è´¯æ€§æä¾›äº†æ–°é€”å¾„ã€‚ç ”ç©¶å›¢é˜Ÿåœ¨GSM8Kã€StrategyQAå’ŒEntailmentBankç­‰æ¶µç›–ç®—æœ¯ã€ç›´è§‰åŠè•´å«æ¨ç†çš„å¤šæ ·åŒ–æ•°æ®é›†ä¸Šè¿›è¡Œäº†è¯„ä¼°ã€‚å®éªŒç»“æœæ˜¾ç¤ºï¼Œè¯¥é‡å­å¯å‘æ–¹æ³•åœ¨æ¨ç†è·¯å¾„çš„è¿è´¯æ€§æŒ‡æ ‡ä¸Šæ˜¾è‘—ä¼˜äºç›‘ç£å­¦ä¹ ã€å¯¹æ¯”å­¦ä¹ åŠé¢„è®­ç»ƒåŸºçº¿æ¨¡å‹ã€‚è¿™ä¸€å‘ç°å‡¸æ˜¾äº†åˆ©ç”¨é‡å­å¯å‘ä¿çœŸåº¦ä½œä¸ºæå‡å¤§å‹è¯­è¨€æ¨¡å‹å¤æ‚æ¨ç†èƒ½åŠ›åŸºç¡€çš„æœ‰æ•ˆæ€§ã€‚",
      "categories": [
        "cs.AI"
      ],
      "primary_category": "cs.AI",
      "comment": "",
      "pdf_url": "https://arxiv.org/pdf/2509.20105v1",
      "published_date": "2025-09-24 13:29:53 UTC",
      "updated_date": "2025-09-24 13:29:53 UTC",
      "processing_status": "completed",
      "attempts": 1,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "llm_backup_calls": 0,
      "last_update": "2026-01-24T20:54:59.494675+00:00"
    },
    {
      "arxiv_id": "2509.20102v1",
      "title": "Steerable Adversarial Scenario Generation through Test-Time Preference Alignment",
      "title_zh": "åŸºäºæµ‹è¯•æ—¶åå¥½å¯¹é½çš„å¯æ§å¯¹æŠ—åœºæ™¯ç”Ÿæˆ",
      "authors": [
        "Tong Nie",
        "Yuewen Mei",
        "Yihong Tang",
        "Junlin He",
        "Jie Sun",
        "Haotian Shi",
        "Wei Ma",
        "Jian Sun"
      ],
      "abstract": "Adversarial scenario generation is a cost-effective approach for safety assessment of autonomous driving systems. However, existing methods are often constrained to a single, fixed trade-off between competing objectives such as adversariality and realism. This yields behavior-specific models that cannot be steered at inference time, lacking the efficiency and flexibility to generate tailored scenarios for diverse training and testing requirements. In view of this, we reframe the task of adversarial scenario generation as a multi-objective preference alignment problem and introduce a new framework named \\textbf{S}teerable \\textbf{A}dversarial scenario \\textbf{GE}nerator (SAGE). SAGE enables fine-grained test-time control over the trade-off between adversariality and realism without any retraining. We first propose hierarchical group-based preference optimization, a data-efficient offline alignment method that learns to balance competing objectives by decoupling hard feasibility constraints from soft preferences. Instead of training a fixed model, SAGE fine-tunes two experts on opposing preferences and constructs a continuous spectrum of policies at inference time by linearly interpolating their weights. We provide theoretical justification for this framework through the lens of linear mode connectivity. Extensive experiments demonstrate that SAGE not only generates scenarios with a superior balance of adversariality and realism but also enables more effective closed-loop training of driving policies. Project page: https://tongnie.github.io/SAGE/.",
      "tldr_zh": "è¯¥ç ”ç©¶æå‡ºäº†SAGEï¼ˆSteerable Adversarial scenario GEneratorï¼‰ï¼Œæ—¨åœ¨è§£å†³è‡ªåŠ¨é©¾é©¶ç³»ç»Ÿå®‰å…¨è¯„ä¼°ä¸­å¯¹æŠ—æ€§åœºæ™¯ç”Ÿæˆæ–¹æ³•åœ¨Adversarialityï¼ˆå¯¹æŠ—æ€§ï¼‰ä¸Realismï¼ˆçœŸå®æ€§ï¼‰ä¹‹é—´éš¾ä»¥æƒè¡¡ä¸”ç¼ºä¹æ¨ç†æ—¶ï¼ˆInference timeï¼‰çµæ´»æ€§çš„é—®é¢˜ã€‚SAGEå°†è¯¥ä»»åŠ¡é‡æ–°å®šä¹‰ä¸ºå¤šç›®æ ‡åå¥½å¯¹é½ï¼ˆMulti-objective preference alignmentï¼‰é—®é¢˜ï¼Œé€šè¿‡åˆ†å±‚åˆ†ç»„åå¥½ä¼˜åŒ–ï¼ˆHierarchical group-based preference optimizationï¼‰å°†ç¡¬å¯è¡Œæ€§çº¦æŸä¸è½¯åå¥½è§£è€¦ï¼Œå®ç°äº†é«˜æ•ˆçš„ç¦»çº¿å¯¹é½ã€‚è¯¥æ¡†æ¶é€šè¿‡å¾®è°ƒé’ˆå¯¹ç›¸ååå¥½çš„ä¸¤ä¸ªä¸“å®¶æ¨¡å‹ï¼Œå¹¶åœ¨æ¨ç†é˜¶æ®µçº¿æ€§æ’å€¼ï¼ˆLinearly interpolatingï¼‰å…¶æƒé‡ï¼Œä»è€Œåœ¨æ— éœ€é‡æ–°è®­ç»ƒçš„æƒ…å†µä¸‹æ„å»ºå‡ºè¿ç»­çš„ç­–ç•¥é¢‘è°±ã€‚ç ”ç©¶é€šè¿‡çº¿æ€§æ¨¡å¼è¿æ¥ï¼ˆLinear mode connectivityï¼‰çš„è§’åº¦ä¸ºè¯¥æ–¹æ³•æä¾›äº†ç†è®ºä¾æ®ã€‚å®éªŒç»“æœè¯æ˜ï¼ŒSAGEç”Ÿæˆçš„åœºæ™¯åœ¨å¯¹æŠ—æ€§å’ŒçœŸå®æ€§ä¹‹é—´è¾¾åˆ°äº†æ›´ä¼˜çš„å¹³è¡¡ï¼Œå¹¶èƒ½æ›´æœ‰æ•ˆåœ°ä¿ƒè¿›é©¾é©¶ç­–ç•¥çš„é—­ç¯è®­ç»ƒï¼ˆClosed-loop trainingï¼‰ã€‚",
      "categories": [
        "cs.AI"
      ],
      "primary_category": "cs.AI",
      "comment": "",
      "pdf_url": "https://arxiv.org/pdf/2509.20102v1",
      "published_date": "2025-09-24 13:27:35 UTC",
      "updated_date": "2025-09-24 13:27:35 UTC",
      "processing_status": "completed",
      "attempts": 1,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "llm_backup_calls": 0,
      "last_update": "2026-01-24T20:55:06.597900+00:00"
    },
    {
      "arxiv_id": "2509.20097v2",
      "title": "Integrated Framework for LLM Evaluation with Answer Generation",
      "title_zh": "é›†æˆç­”æ¡ˆç”Ÿæˆçš„å¤§è¯­è¨€æ¨¡å‹è¯„ä¼°æ¡†æ¶",
      "authors": [
        "Sujeong Lee",
        "Hayoung Lee",
        "Seongsoo Heo",
        "Wonik Choi"
      ],
      "abstract": "Reliable evaluation of large language models is essential to ensure their applicability in practical scenarios. Traditional benchmark-based evaluation methods often rely on fixed reference answers, limiting their ability to capture important qualitative aspects of generated responses. To address these shortcomings, we propose an integrated evaluation framework called \\textit{self-refining descriptive evaluation with expert-driven diagnostics}, SPEED, which utilizes specialized functional experts to perform comprehensive, descriptive analyses of model outputs. Unlike conventional approaches, SPEED actively incorporates expert feedback across multiple dimensions, including hallucination detection, toxicity assessment, and lexical-contextual appropriateness. Experimental results demonstrate that SPEED achieves robust and consistent evaluation performance across diverse domains and datasets. Additionally, by employing relatively compact expert models, SPEED demonstrates superior resource efficiency compared to larger-scale evaluators. These findings illustrate that SPEED significantly enhances fairness and interpretability in LLM evaluations, offering a promising alternative to existing evaluation methodologies.",
      "tldr_zh": "è¯¥ç ”ç©¶æå‡ºäº†SPEEDï¼ˆself-refining descriptive evaluation with expert-driven diagnosticsï¼‰ï¼Œè¿™æ˜¯ä¸€ä¸ªé›†æˆäº†ç­”æ¡ˆç”Ÿæˆçš„LLMè¯„ä¼°æ¡†æ¶ï¼Œæ—¨åœ¨è§£å†³ä¼ ç»Ÿè¯„ä¼°æ–¹æ³•è¿‡åº¦ä¾èµ–å›ºå®šå‚è€ƒç­”æ¡ˆè€Œå¿½è§†å®šæ€§åˆ†æçš„é—®é¢˜ã€‚SPEEDæ¡†æ¶åˆ©ç”¨ä¸“é—¨çš„åŠŸèƒ½ä¸“å®¶ï¼ˆfunctional expertsï¼‰å¯¹æ¨¡å‹è¾“å‡ºè¿›è¡Œå…¨é¢çš„æè¿°æ€§åˆ†æï¼Œèƒ½å¤Ÿä»å¹»è§‰æ£€æµ‹ï¼ˆhallucination detectionï¼‰ã€æ¯’æ€§è¯„ä¼°ï¼ˆtoxicity assessmentï¼‰ä»¥åŠè¯æ±‡-è¯­å¢ƒé€‚å½“æ€§ï¼ˆlexical-contextual appropriatenessï¼‰ç­‰å¤šä¸ªç»´åº¦ä¸»åŠ¨æ•´åˆä¸“å®¶åé¦ˆã€‚å®éªŒç»“æœè¡¨æ˜ï¼ŒSPEEDåœ¨ä¸åŒé¢†åŸŸå’Œæ•°æ®é›†ä¸Šå‡è¡¨ç°å‡ºç¨³å¥ä¸”ä¸€è‡´çš„è¯„ä¼°æ€§èƒ½ã€‚æ­¤å¤–ï¼Œç”±äºé‡‡ç”¨äº†ç›¸å¯¹ç²¾ç®€çš„ä¸“å®¶æ¨¡å‹ï¼ˆcompact expert modelsï¼‰ï¼ŒSPEEDåœ¨èµ„æºæ•ˆç‡ä¸Šä¼˜äºå¤§è§„æ¨¡è¯„ä¼°å™¨ï¼Œæ˜¾è‘—æå‡äº†LLMè¯„ä¼°çš„å…¬å¹³æ€§ä¸å¯è§£é‡Šæ€§ï¼Œä¸ºç°æœ‰è¯„ä¼°æ–¹æ³•æä¾›äº†ä¸€ä¸ªæ›´å…·æ½œåŠ›çš„æ›¿ä»£æ–¹æ¡ˆã€‚",
      "categories": [
        "cs.CL",
        "cs.AI"
      ],
      "primary_category": "cs.CL",
      "comment": "16pages",
      "pdf_url": "https://arxiv.org/pdf/2509.20097v2",
      "published_date": "2025-09-24 13:20:37 UTC",
      "updated_date": "2025-10-01 06:09:25 UTC",
      "processing_status": "completed",
      "attempts": 1,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "llm_backup_calls": 0,
      "last_update": "2026-01-24T20:55:09.984098+00:00"
    },
    {
      "arxiv_id": "2509.20095v1",
      "title": "From Pheromones to Policies: Reinforcement Learning for Engineered Biological Swarms",
      "title_zh": "ä»ä¿¡æ¯ç´ åˆ°ç­–ç•¥ï¼šé¢å‘å·¥ç¨‹åŒ–ç”Ÿç‰©é›†ç¾¤çš„å¼ºåŒ–å­¦ä¹ ",
      "authors": [
        "Aymeric Vellinger",
        "Nemanja Antonic",
        "Elio Tuci"
      ],
      "abstract": "Swarm intelligence emerges from decentralised interactions among simple agents, enabling collective problem-solving. This study establishes a theoretical equivalence between pheromone-mediated aggregation in \\celeg\\ and reinforcement learning (RL), demonstrating how stigmergic signals function as distributed reward mechanisms. We model engineered nematode swarms performing foraging tasks, showing that pheromone dynamics mathematically mirror cross-learning updates, a fundamental RL algorithm. Experimental validation with data from literature confirms that our model accurately replicates empirical \\celeg\\ foraging patterns under static conditions. In dynamic environments, persistent pheromone trails create positive feedback loops that hinder adaptation by locking swarms into obsolete choices. Through computational experiments in multi-armed bandit scenarios, we reveal that introducing a minority of exploratory agents insensitive to pheromones restores collective plasticity, enabling rapid task switching. This behavioural heterogeneity balances exploration-exploitation trade-offs, implementing swarm-level extinction of outdated strategies. Our results demonstrate that stigmergic systems inherently encode distributed RL processes, where environmental signals act as external memory for collective credit assignment. By bridging synthetic biology with swarm robotics, this work advances programmable living systems capable of resilient decision-making in volatile environments.",
      "tldr_zh": "è¿™é¡¹ç ”ç©¶åœ¨ç§€ä¸½éšæ†çº¿è™«(C. elegans)ç”±ä¿¡æ¯ç´ (Pheromones)ä»‹å¯¼çš„èšé›†è¡Œä¸ºä¸å¼ºåŒ–å­¦ä¹ (Reinforcement Learning)ä¹‹é—´å»ºç«‹äº†ç†è®ºç­‰æ•ˆæ€§ï¼Œè¯æ˜äº†ç¯å¢ƒç—•è¿¹ä¿¡å·(Stigmergic signals)å®é™…ä¸Šèµ·åˆ°äº†åˆ†å¸ƒå¼å¥–åŠ±æœºåˆ¶(Distributed reward mechanisms)çš„ä½œç”¨ã€‚ç ”ç©¶é€šè¿‡æ¨¡æ‹Ÿå·¥ç¨‹åŒ–çº¿è™«ç¾¤ä½“çš„è§…é£Ÿä»»åŠ¡ï¼Œå‘ç°ä¿¡æ¯ç´ åŠ¨æ€åœ¨æ•°å­¦ä¸Šé•œåƒäº†äº¤å‰å­¦ä¹ (Cross-learning)æ›´æ–°ç®—æ³•ï¼Œå¹¶é€šè¿‡å®éªŒæ•°æ®éªŒè¯äº†å…¶åœ¨é™æ€ç¯å¢ƒä¸‹çš„å‡†ç¡®æ€§ã€‚é’ˆå¯¹åŠ¨æ€ç¯å¢ƒä¸‹ä¿¡æ¯ç´ æ­£åé¦ˆå¯¼è‡´ç¾¤ä½“é™·å…¥è¿‡æ—¶é€‰æ‹©çš„å±€é™æ€§ï¼Œç ”ç©¶æ­ç¤ºäº†å¼•å…¥å°‘é‡å¯¹ä¿¡æ¯ç´ ä¸æ•æ„Ÿçš„æ¢ç´¢å‹æ™ºèƒ½ä½“(Exploratory agents)å¯ä»¥æ¢å¤é›†ä½“çš„å¯å¡‘æ€§å¹¶å®ç°å¿«é€Ÿä»»åŠ¡åˆ‡æ¢ã€‚ç»“æœè¡¨æ˜ï¼Œç—•è¿¹ç³»ç»Ÿå†…åœ¨ç¼–ç äº†åˆ†å¸ƒå¼å¼ºåŒ–å­¦ä¹ è¿‡ç¨‹ï¼Œç¯å¢ƒä¿¡å·ä½œä¸ºå¤–éƒ¨è®°å¿†æ”¯æŒé›†ä½“çš„ä¿¡ç”¨åˆ†é…(Credit assignment)ã€‚è¯¥æˆæœé€šè¿‡æ¡¥æ¥åˆæˆç”Ÿç‰©å­¦ä¸ç¾¤ä½“æœºå™¨äººå­¦(Swarm robotics)ï¼Œä¸ºæ„å»ºèƒ½åœ¨å¤æ‚æ³¢åŠ¨ç¯å¢ƒä¸­è¿›è¡Œç¨³å¥å†³ç­–çš„å¯ç¼–ç¨‹ç”Ÿç‰©ç³»ç»Ÿæä¾›äº†é‡è¦ç†è®ºæ”¯æ’‘ã€‚",
      "categories": [
        "cs.AI"
      ],
      "primary_category": "cs.AI",
      "comment": "Contribution to the 9th International Symposium on Swarm Behavior and Bio-Inspired Robotics 2025",
      "pdf_url": "https://arxiv.org/pdf/2509.20095v1",
      "published_date": "2025-09-24 13:16:35 UTC",
      "updated_date": "2025-09-24 13:16:35 UTC",
      "processing_status": "completed",
      "attempts": 1,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "llm_backup_calls": 0,
      "last_update": "2026-01-24T20:55:17.768070+00:00"
    },
    {
      "arxiv_id": "2509.20088v1",
      "title": "Causal Understanding by LLMs: The Role of Uncertainty",
      "title_zh": "å¤§è¯­è¨€æ¨¡å‹çš„å› æœç†è§£ï¼šä¸ç¡®å®šæ€§çš„ä½œç”¨",
      "authors": [
        "Oscar Lithgow-Serrano",
        "Vani Kanjirangat",
        "Alessandro Antonucci"
      ],
      "abstract": "Recent papers show LLMs achieve near-random accuracy in causal relation classification, raising questions about whether such failures arise from limited pretraining exposure or deeper representational gaps. We investigate this under uncertainty-based evaluation, testing whether pretraining exposure to causal examples improves causal understanding >18K PubMed sentences -- half from The Pile corpus, half post-2024 -- across seven models (Pythia-1.4B/7B/12B, GPT-J-6B, Dolly-7B/12B, Qwen-7B). We analyze model behavior through: (i) causal classification, where the model identifies causal relationships in text, and (ii) verbatim memorization probing, where we assess whether the model prefers previously seen causal statements over their paraphrases. Models perform four-way classification (direct/conditional/correlational/no-relationship) and select between originals and their generated paraphrases. Results show almost identical accuracy on seen/unseen sentences (p > 0.05), no memorization bias (24.8% original selection), and output distribution over the possible options is almost flat, with entropic values near the maximum (1.35/1.39), confirming random guessing. Instruction-tuned models show severe miscalibration (Qwen: > 95% confidence, 32.8% accuracy, ECE=0.49). Conditional relations induce highest entropy (+11% vs. direct). These findings suggest that failures in causal understanding arise from the lack of structured causal representation, rather than insufficient exposure to causal examples during pretraining.",
      "tldr_zh": "è¯¥ç ”ç©¶æ¢è®¨äº†å¤§è¯­è¨€æ¨¡å‹(LLMs)åœ¨å› æœå…³ç³»åˆ†ç±»ä¸­è¡¨ç°ä¸ä½³çš„åŸå› ï¼Œæ—¨åœ¨åŒºåˆ†è¿™ä¸€å¤±è´¥æ˜¯æºäºé¢„è®­ç»ƒæ•°æ®æš´éœ²ä¸è¶³è¿˜æ˜¯æ·±å±‚çš„è¡¨ç¤ºå·®è·(representational gaps)ã€‚ç ”ç©¶äººå‘˜åˆ©ç”¨æ¥è‡ªPubMedçš„1.8ä¸‡ä¸ªå¥å­ï¼Œå¯¹Pythiaã€GPT-Jã€Dollyå’ŒQwenç­‰ä¸ƒç§æ¨¡å‹è¿›è¡Œäº†åŸºäºä¸ç¡®å®šæ€§(uncertainty-based)çš„è¯„ä¼°ï¼Œæ¶µç›–å› æœåˆ†ç±»å’Œé€å­—è®°å¿†æ¢æµ‹(verbatim memorization probing)ä¸¤é¡¹ä»»åŠ¡ã€‚å®éªŒç»“æœæ˜¾ç¤ºï¼Œæ¨¡å‹åœ¨å·²è§å’Œæœªè§å¥å­ä¸Šçš„å‡†ç¡®ç‡å‡ ä¹ç›¸åŒï¼Œä¸”åœ¨åŸå§‹æ–‡æœ¬ä¸å…¶è½¬è¿°æ–‡æœ¬ä¹‹é—´æ²¡æœ‰è¡¨ç°å‡ºè®°å¿†åå·®ï¼Œå…¶è¾“å‡ºåˆ†å¸ƒç‰¹å¾è¯å®äº†æ¨¡å‹æ›´æ¥è¿‘äºéšæœºçŒœæµ‹ã€‚æ­¤å¤–ï¼ŒæŒ‡ä»¤å¾®è°ƒ(instruction-tuned)æ¨¡å‹è¡¨ç°å‡ºä¸¥é‡çš„å¤±æ ¡å‡†(miscalibration)é—®é¢˜ï¼Œå³åœ¨æé«˜ç½®ä¿¡åº¦ä¸‹ä¾ç„¶ç»´æŒè¾ƒä½çš„å‡†ç¡®ç‡ã€‚ç ”ç©¶æœ€ç»ˆå¾—å‡ºç»“è®ºï¼ŒLLMsåœ¨å› æœç†è§£ä¸Šçš„å¤±è´¥ä¸»è¦å½’å› äºç¼ºä¹ç»“æ„åŒ–çš„å› æœè¡¨ç¤º(causal representation)ï¼Œè€Œéé¢„è®­ç»ƒæœŸé—´æ¥è§¦çš„å› æœå®ä¾‹ä¸è¶³ã€‚",
      "categories": [
        "cs.CL",
        "cs.AI"
      ],
      "primary_category": "cs.CL",
      "comment": "Accepted in second UncertaiNLP workshop at EMNLP 2025",
      "pdf_url": "https://arxiv.org/pdf/2509.20088v1",
      "published_date": "2025-09-24 13:06:35 UTC",
      "updated_date": "2025-09-24 13:06:35 UTC",
      "processing_status": "completed",
      "attempts": 1,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "llm_backup_calls": 0,
      "last_update": "2026-01-24T20:55:13.472441+00:00"
    },
    {
      "arxiv_id": "2509.20067v3",
      "title": "MACD: Multi-Agent Clinical Diagnosis with Self-Learned Knowledge for LLM",
      "title_zh": "MACDï¼šåŸºäºè‡ªå­¦ä¹ çŸ¥è¯†çš„å¤§è¯­è¨€æ¨¡å‹å¤šæ™ºèƒ½ä½“ä¸´åºŠè¯Šæ–­",
      "authors": [
        "Wenliang Li",
        "Rui Yan",
        "Xu Zhang",
        "Li Chen",
        "Hongji Zhu",
        "Jing Zhao",
        "Junjun Li",
        "Mengru Li",
        "Wei Cao",
        "Zihang Jiang",
        "Wei Wei",
        "Kun Zhang",
        "Shaohua Kevin Zhou"
      ],
      "abstract": "Large language models (LLMs) have demonstrated notable potential in medical applications, yet they face substantial challenges in handling complex real-world clinical diagnoses using conventional prompting methods. Current prompt engineering and multi-agent approaches typically optimize isolated inferences, neglecting the accumulation of reusable clinical experience. To address this, this study proposes a novel Multi-Agent Clinical Diagnosis (MACD) framework, which allows LLMs to self-learn clinical knowledge via a multi-agent pipeline that summarizes, refines, and applies diagnostic insights. It mirrors how physicians develop expertise through experience, enabling more focused and accurate diagnosis on key disease-specific cues. We further extend it to a MACD-human collaborative workflow, where multiple LLM-based diagnostician agents engage in iterative consultations, supported by an evaluator agent and human oversight for cases where agreement is not reached. Evaluated on 4,390 real-world patient cases across seven diseases using diverse open-source LLMs (Llama-3.1 8B/70B, DeepSeek-R1-Distill-Llama 70B), MACD significantly improves primary diagnostic accuracy, outperforming established clinical guidelines with gains up to 22.3% (MACD). In direct comparison with physician-only diagnosis under the same evaluation protocol, MACD achieves comparable or superior performance, with improvements up to 16%. Furthermore, the MACD-human workflow yields an 18.6% improvement over physician-only diagnosis, demonstrating the synergistic potential of human-AI collaboration. Notably, the self-learned clinical knowledge exhibits strong cross-model stability, transferability across LLMs, and capacity for model-specific personalization.This work thus presents a scalable self-learning paradigm that bridges the gap between the intrinsic knowledge of LLMs.",
      "tldr_zh": "è¯¥ç ”ç©¶æå‡ºäº† MACD (Multi-Agent Clinical Diagnosis) æ¡†æ¶ï¼Œæ—¨åœ¨è§£å†³å¤§å‹è¯­è¨€æ¨¡å‹ (LLMs) åœ¨å¤„ç†å¤æ‚çœŸå®ä¸–ç•Œä¸´åºŠè¯Šæ–­æ—¶å› ç¼ºä¹å¯å¤ç”¨ç»éªŒè€Œé¢ä¸´çš„æŒ‘æˆ˜ã€‚MACD é€šè¿‡ä¸€ä¸ªå¤šæ™ºèƒ½ä½“æµæ°´çº¿å®ç°ä¸´åºŠçŸ¥è¯†çš„è‡ªæˆ‘å­¦ä¹  (self-learning)ï¼Œèƒ½å¤Ÿè‡ªåŠ¨æ€»ç»“ã€æç‚¼å¹¶åº”ç”¨è¯Šæ–­è§è§£ï¼Œæ¨¡æ‹Ÿäº†åŒ»ç”Ÿé€šè¿‡ç»éªŒç§¯ç´¯æå‡ä¸“ä¸šèƒ½åŠ›çš„æˆé•¿è¿‡ç¨‹ã€‚ç ”ç©¶è¿›ä¸€æ­¥æ„å»ºäº† MACD-human åä½œå·¥ä½œæµï¼Œç”±å¤šä¸ªåŸºäº LLM çš„è¯Šæ–­æ™ºèƒ½ä½“è¿›è¡Œè¿­ä»£ä¼šè¯Šï¼Œå¹¶åœ¨è¯„ä¼°æ™ºèƒ½ä½“å’Œäººç±»ç›‘ç£çš„é…åˆä¸‹ç¡®ä¿è¯Šæ–­çš„ä¸¥è°¨æ€§ã€‚åœ¨æ¶‰åŠ 7 ç§ç–¾ç—…çš„ 4,390 ä¸ªçœŸå®ç—…ä¾‹è¯„ä¼°ä¸­ï¼ŒMACD ç»“åˆ Llama-3.1 å’Œ DeepSeek-R1 ç­‰æ¨¡å‹å°†ä¸»è¦è¯Šæ–­å‡†ç¡®ç‡æœ€é«˜æå‡äº† 22.3%ï¼Œè¡¨ç°ä¼˜äºä¼ ç»Ÿä¸´åºŠæŒ‡å—ã€‚å®éªŒè¯æ˜ï¼ŒMACD åœ¨ç‹¬ç«‹è¯Šæ–­ä¸­è¾¾åˆ°äº†ä¸åŒ»ç”Ÿç›¸å½“æˆ–æ›´ä¼˜çš„æ°´å¹³ï¼Œè€Œ MACD-human åä½œæ¨¡å¼æ¯”å•çº¯çš„äººç±»åŒ»ç”Ÿè¯Šæ–­å‡†ç¡®ç‡æé«˜äº† 18.6%ã€‚æ­¤å¤–ï¼Œè¯¥æ¡†æ¶ç”Ÿæˆçš„è‡ªæˆ‘å­¦ä¹ çŸ¥è¯†å±•ç°å‡ºå¼ºå¤§çš„è·¨æ¨¡å‹ç¨³å®šæ€§ä¸è¿ç§»èƒ½åŠ›ï¼Œä¸ºç¼©å° LLM ç†è®ºçŸ¥è¯†ä¸ä¸´åºŠå®è·µä¹‹é—´çš„å·®è·æä¾›äº†å¯æ‰©å±•çš„è‡ªå­¦ä¹ èŒƒå¼ã€‚",
      "categories": [
        "cs.AI"
      ],
      "primary_category": "cs.AI",
      "comment": "",
      "pdf_url": "https://arxiv.org/pdf/2509.20067v3",
      "published_date": "2025-09-24 12:37:11 UTC",
      "updated_date": "2025-09-26 02:33:31 UTC",
      "processing_status": "completed",
      "attempts": 1,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "llm_backup_calls": 0,
      "last_update": "2026-01-24T20:55:32.307005+00:00"
    },
    {
      "arxiv_id": "2509.20057v3",
      "title": "Responsible AI Technical Report",
      "title_zh": "è´Ÿè´£ä»»äººå·¥æ™ºèƒ½æŠ€æœ¯æŠ¥å‘Š",
      "authors": [
        "KT",
        ":",
        "Yunjin Park",
        "Jungwon Yoon",
        "Junhyung Moon",
        "Myunggyo Oh",
        "Wonhyuk Lee",
        "Sujin Kim Youngchol Kim",
        "Eunmi Kim",
        "Hyoungjun Park",
        "Eunyoung Shin",
        "Wonyoung Lee",
        "Somin Lee",
        "Minwook Ju",
        "Minsung Noh",
        "Dongyoung Jeong",
        "Jeongyeop Kim",
        "Wanjin Park",
        "Soonmin Bae"
      ],
      "abstract": "KT developed a Responsible AI (RAI) assessment methodology and risk mitigation technologies to ensure the safety and reliability of AI services. By analyzing the Basic Act on AI implementation and global AI governance trends, we established a unique approach for regulatory compliance and systematically identify and manage all potential risk factors from AI development to operation. We present a reliable assessment methodology that systematically verifies model safety and robustness based on KT's AI risk taxonomy tailored to the domestic environment. We also provide practical tools for managing and mitigating identified AI risks. With the release of this report, we also release proprietary Guardrail : SafetyGuard that blocks harmful responses from AI models in real-time, supporting the enhancement of safety in the domestic AI development ecosystem. We also believe these research outcomes provide valuable insights for organizations seeking to develop Responsible AI.",
      "tldr_zh": "KTå¼€å‘äº†ä¸€å¥—è´Ÿè´£ä»»äººå·¥æ™ºèƒ½(Responsible AI)è¯„ä¼°æ–¹æ³•è®ºå’Œé£é™©ç¼“è§£æŠ€æœ¯ï¼Œæ—¨åœ¨ç¡®ä¿AIæœåŠ¡çš„å®‰å…¨æ€§å’Œå¯é æ€§ã€‚è¯¥ç ”ç©¶é€šè¿‡åˆ†æå…¨çƒAIæ²»ç†è¶‹åŠ¿åŠç›¸å…³æ³•å¾‹ï¼Œå»ºç«‹äº†ä¸€å¥—ç‹¬ç‰¹çš„ç›‘ç®¡åˆè§„æ–¹æ³•ï¼Œå®ç°äº†ä»AIå¼€å‘åˆ°è¿è¡Œå…¨è¿‡ç¨‹é£é™©å› ç´ çš„ç³»ç»ŸåŒ–è¯†åˆ«ä¸ç®¡ç†ã€‚åŸºäºé’ˆå¯¹ç‰¹å®šç¯å¢ƒå®šåˆ¶çš„AIé£é™©åˆ†ç±»ä½“ç³»(AI risk taxonomy)ï¼Œç ”ç©¶æå‡ºäº†ä¸€ç§èƒ½å¤ŸéªŒè¯æ¨¡å‹å®‰å…¨æ€§å’Œé²æ£’æ€§çš„å¯é è¯„ä¼°æ–¹æ³•ã€‚åŒæ—¶ï¼ŒKTå‘å¸ƒäº†åä¸ºSafetyGuardçš„ä¸“æœ‰æŠ¤æ å·¥å…·ï¼Œé€šè¿‡å®æ—¶æ‹¦æˆªAIæ¨¡å‹çš„æœ‰å®³å“åº”ï¼Œä¸ºå¢å¼ºAIç”Ÿæ€ç³»ç»Ÿçš„å®‰å…¨æ€§æä¾›æ”¯æŒã€‚è¯¥æŠ¥å‘Šä¸ä»…æä¾›äº†å®ç”¨çš„é£é™©ç®¡ç†å·¥å…·ï¼Œä¹Ÿä¸ºè‡´åŠ›äºå¼€å‘Responsible AIçš„ç»„ç»‡æä¾›äº†å®è´µçš„å®è·µå‚è€ƒã€‚",
      "categories": [
        "cs.CL",
        "cs.AI"
      ],
      "primary_category": "cs.CL",
      "comment": "23 pages, 8 figures",
      "pdf_url": "https://arxiv.org/pdf/2509.20057v3",
      "published_date": "2025-09-24 12:26:33 UTC",
      "updated_date": "2025-10-14 02:14:20 UTC",
      "processing_status": "completed",
      "attempts": 1,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "llm_backup_calls": 0,
      "last_update": "2026-01-24T20:55:32.764326+00:00"
    },
    {
      "arxiv_id": "2511.03727v1",
      "title": "MazeMate: An LLM-Powered Chatbot to Support Computational Thinking in Gamified Programming Learning",
      "title_zh": "MazeMateï¼šæ”¯æŒæ¸¸æˆåŒ–ç¼–ç¨‹å­¦ä¹ ä¸­è®¡ç®—æ€ç»´çš„ LLM é©±åŠ¨èŠå¤©æœºå™¨äºº",
      "authors": [
        "Chenyu Hou",
        "Hua Yu",
        "Gaoxia Zhu",
        "John Derek Anas",
        "Jiao Liu",
        "Yew Soon Ong"
      ],
      "abstract": "Computational Thinking (CT) is a foundational problem-solving skill, and gamified programming environments are a widely adopted approach to cultivating it. While large language models (LLMs) provide on-demand programming support, current applications rarely foster CT development. We present MazeMate, an LLM-powered chatbot embedded in a 3D Maze programming game, designed to deliver adaptive, context-sensitive scaffolds aligned with CT processes in maze solving and maze design. We report on the first classroom implementation with 247 undergraduates. Students rated MazeMate as moderately helpful, with higher perceived usefulness for maze solving than for maze design. Thematic analysis confirmed support for CT processes such as decomposition, abstraction, and algorithmic thinking, while also revealing limitations in supporting maze design, including mismatched suggestions and fabricated algorithmic solutions. These findings demonstrate the potential of LLM-based scaffolding to support CT and underscore directions for design refinement to enhance MazeMate usability in authentic classrooms.",
      "tldr_zh": "è¯¥ç ”ç©¶å¼€å‘äº† MazeMateï¼Œä¸€ä¸ªé›†æˆåœ¨ 3D è¿·å®«ç¼–ç¨‹æ¸¸æˆä¸­çš„å¤§è¯­è¨€æ¨¡å‹ (LLM) é©±åŠ¨èŠå¤©æœºå™¨äººï¼Œæ—¨åœ¨é€šè¿‡æä¾›è‡ªé€‚åº”ä¸”ä¸Šä¸‹æ–‡æ•æ„Ÿçš„è„šæ‰‹æ¶ (Scaffolding) æ¥æ”¯æŒè®¡ç®—æ€ç»´ (Computational Thinking) çš„åŸ¹å…»ã€‚ç³»ç»Ÿé€šè¿‡è¿·å®«è§£å†³å’Œè¿·å®«è®¾è®¡ä¸¤ä¸ªç¯èŠ‚ï¼Œå¼•å¯¼å­¦ç”Ÿè¿›è¡Œä»»åŠ¡æ‹†è§£ (Decomposition)ã€æŠ½è±¡åŒ– (Abstraction) å’Œç®—æ³•æ€ç»´ (Algorithmic Thinking) ç­‰å…³é”®è¿‡ç¨‹ã€‚é’ˆå¯¹ 247 åæœ¬ç§‘ç”Ÿçš„è¯¾å ‚å®éªŒè¡¨æ˜ï¼Œå­¦ç”Ÿæ™®éè®¤ä¸º MazeMate å…·æœ‰ä¸­ç­‰ç¨‹åº¦çš„å¸®åŠ©ï¼Œä¸”åœ¨è¿·å®«è§£å†³ä»»åŠ¡ä¸­çš„æ„ŸçŸ¥æœ‰ç”¨æ€§æ˜¾è‘—é«˜äºè¿·å®«è®¾è®¡ã€‚ç ”ç©¶é€šè¿‡ä¸»é¢˜åˆ†æè¯å®äº†å…¶å¯¹è®¡ç®—æ€ç»´å‘å±•çš„æ”¯æŒä½œç”¨ï¼ŒåŒæ—¶ä¹Ÿæ­ç¤ºäº†åœ¨è¿·å®«è®¾è®¡ç¯èŠ‚ä¸­å­˜åœ¨å»ºè®®ä¸åŒ¹é…å’Œè™šæ„ç®—æ³•æ–¹æ¡ˆç­‰å±€é™æ€§ã€‚è¿™äº›å‘ç°ä¸ä»…å±•ç¤ºäº†åˆ©ç”¨ LLM ä¸ºè®¡ç®—æ€ç»´æä¾›æ•™å­¦æ”¯æŒçš„æ½œåŠ›ï¼Œä¹Ÿä¸ºæœªæ¥ä¼˜åŒ–æ­¤ç±»å·¥å…·åœ¨çœŸå®è¯¾å ‚ä¸­çš„å¯ç”¨æ€§æŒ‡æ˜äº†æ–¹å‘ã€‚",
      "categories": [
        "cs.HC",
        "cs.AI"
      ],
      "primary_category": "cs.HC",
      "comment": "",
      "pdf_url": "https://arxiv.org/pdf/2511.03727v1",
      "published_date": "2025-09-24 12:25:19 UTC",
      "updated_date": "2025-09-24 12:25:19 UTC",
      "processing_status": "completed",
      "attempts": 1,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "llm_backup_calls": 0,
      "last_update": "2026-01-24T20:55:40.354186+00:00"
    },
    {
      "arxiv_id": "2509.20051v1",
      "title": "One Filters All: A Generalist Filter for State Estimation",
      "title_zh": "One Filters Allï¼šé¢å‘çŠ¶æ€ä¼°è®¡çš„é€šç”¨å‹æ»¤æ³¢å™¨",
      "authors": [
        "Shiqi Liu",
        "Wenhan Cao",
        "Chang Liu",
        "Zeyu He",
        "Tianyi Zhang",
        "Shengbo Eben Li"
      ],
      "abstract": "Estimating hidden states in dynamical systems, also known as optimal filtering, is a long-standing problem in various fields of science and engineering. In this paper, we introduce a general filtering framework, \\textbf{LLM-Filter}, which leverages large language models (LLMs) for state estimation by embedding noisy observations with text prototypes. In various experiments for classical dynamical systems, we find that first, state estimation can significantly benefit from the reasoning knowledge embedded in pre-trained LLMs. By achieving proper modality alignment with the frozen LLM, LLM-Filter outperforms the state-of-the-art learning-based approaches. Second, we carefully design the prompt structure, System-as-Prompt (SaP), incorporating task instructions that enable the LLM to understand the estimation tasks. Guided by these prompts, LLM-Filter exhibits exceptional generalization, capable of performing filtering tasks accurately in changed or even unseen environments. We further observe a scaling-law behavior in LLM-Filter, where accuracy improves with larger model sizes and longer training times. These findings make LLM-Filter a promising foundation model of filtering.",
      "tldr_zh": "è¯¥ç ”ç©¶æå‡ºäº†LLM-Filterï¼Œè¿™æ˜¯ä¸€ä¸ªé€šç”¨çš„çŠ¶æ€ä¼°è®¡ï¼ˆstate estimationï¼‰æ¡†æ¶ï¼Œæ—¨åœ¨åˆ©ç”¨å¤§è¯­è¨€æ¨¡å‹ï¼ˆLLMsï¼‰è§£å†³åŠ¨åŠ›ç³»ç»Ÿä¸­çš„éšè—çŠ¶æ€ä¼°è®¡é—®é¢˜ã€‚LLM-Filteré€šè¿‡å°†å™ªå£°è§‚æµ‹å€¼ä¸æ–‡æœ¬åŸå‹ï¼ˆtext prototypesï¼‰åµŒå…¥ï¼Œä½¿çŠ¶æ€ä¼°è®¡è¿‡ç¨‹æ˜¾è‘—å—ç›Šäºé¢„è®­ç»ƒå¤§è¯­è¨€æ¨¡å‹ä¸­è•´å«çš„æ¨ç†çŸ¥è¯†ã€‚ç ”ç©¶å›¢é˜Ÿç²¾å¿ƒè®¾è®¡äº†System-as-Prompt (SaP) æç¤ºç»“æ„ï¼Œé€šè¿‡æ•´åˆä»»åŠ¡æŒ‡ä»¤å¼•å¯¼æ¨¡å‹ç†è§£ä¼°è®¡ä»»åŠ¡ï¼Œä½¿å…¶åœ¨é¢å¯¹ç¯å¢ƒæ”¹å˜ç”šè‡³æœªè§è¿‡çš„è¿‡æ»¤ä»»åŠ¡æ—¶å±•ç°å‡ºå“è¶Šçš„æ³›åŒ–èƒ½åŠ›ã€‚å®éªŒç»“æœè¡¨æ˜ï¼Œåœ¨å®ç°æ¨¡æ€å¯¹é½åï¼ŒLLM-Filterçš„æ€§èƒ½è¶…è¶Šäº†ç›®å‰æœ€å…ˆè¿›çš„åŸºäºå­¦ä¹ çš„æ–¹æ³•ã€‚æ­¤å¤–ï¼Œç ”ç©¶è¿˜è§‚å¯Ÿåˆ°LLM-Filterå…·æœ‰æ˜¾è‘—çš„è§„æ¨¡å®šå¾‹ï¼ˆscaling-lawï¼‰ç‰¹å¾ï¼Œå…¶å‡†ç¡®ç‡ä¼šéšæ¨¡å‹è§„æ¨¡å¢å¤§å’Œè®­ç»ƒæ—¶é—´å»¶é•¿è€Œæå‡ã€‚è¿™äº›å‘ç°è¯æ˜äº†LLM-Filterä½œä¸ºè¿‡æ»¤é¢†åŸŸåŸºç¡€æ¨¡å‹ï¼ˆfoundation modelï¼‰çš„å·¨å¤§æ½œåŠ›ã€‚",
      "categories": [
        "cs.LG",
        "cs.AI"
      ],
      "primary_category": "cs.LG",
      "comment": "NeurIPS 2025",
      "pdf_url": "https://arxiv.org/pdf/2509.20051v1",
      "published_date": "2025-09-24 12:19:18 UTC",
      "updated_date": "2025-09-24 12:19:18 UTC",
      "processing_status": "completed",
      "attempts": 1,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "llm_backup_calls": 0,
      "last_update": "2026-01-24T20:55:39.271828+00:00"
    },
    {
      "arxiv_id": "2509.20049v1",
      "title": "Projective Kolmogorov Arnold Neural Networks (P-KANs): Entropy-Driven Functional Space Discovery for Interpretable Machine Learning",
      "title_zh": "æŠ•å½±å¼ Kolmogorov Arnold ç¥ç»ç½‘ç»œ (P-KANs)ï¼šé¢å‘å¯è§£é‡Šæœºå™¨å­¦ä¹ çš„ç†µé©±åŠ¨å‡½æ•°ç©ºé—´å‘ç°",
      "authors": [
        "Alastair Poole",
        "Stig McArthur",
        "Saravan Kumar"
      ],
      "abstract": "Kolmogorov-Arnold Networks (KANs) relocate learnable nonlinearities from nodes to edges, demonstrating remarkable capabilities in scientific machine learning and interpretable modeling. However, current KAN implementations suffer from fundamental inefficiencies due to redundancy in high-dimensional spline parameter spaces, where numerous distinct parameterisations yield functionally equivalent behaviors. This redundancy manifests as a \"nuisance space\" in the model's Jacobian, leading to susceptibility to overfitting and poor generalization. We introduce Projective Kolmogorov-Arnold Networks (P-KANs), a novel training framework that guides edge function discovery towards interpretable functional representations through entropy-minimisation techniques from signal analysis and sparse dictionary learning. Rather than constraining functions to predetermined spaces, our approach maintains spline space flexibility while introducing \"gravitational\" terms that encourage convergence towards optimal functional representations. Our key insight recognizes that optimal representations can be identified through entropy analysis of projection coefficients, compressing edge functions to lower-parameter projective spaces (Fourier, Chebyshev, Bessel). P-KANs demonstrate superior performance across multiple domains, achieving up to 80% parameter reduction while maintaining representational capacity, significantly improved robustness to noise compared to standard KANs, and successful application to industrial automated fiber placement prediction. Our approach enables automatic discovery of mixed functional representations where different edges converge to different optimal spaces, providing both compression benefits and enhanced interpretability for scientific machine learning applications.",
      "tldr_zh": "è¯¥ç ”ç©¶é’ˆå¯¹Kolmogorov-Arnold Networks (KANs) åœ¨é«˜ç»´æ ·æ¡å‚æ•°ç©ºé—´ä¸­å­˜åœ¨çš„å†—ä½™ä»¥åŠæ˜“å—è¿‡æ‹Ÿåˆå½±å“çš„é—®é¢˜ï¼Œæå‡ºäº†Projective Kolmogorov-Arnold Networks (P-KANs) æ¡†æ¶ã€‚é€šè¿‡å¼•å…¥ä¿¡å·åˆ†æä¸­çš„ç†µæœ€å°åŒ–æŠ€æœ¯å’Œç¨€ç–å­—å…¸å­¦ä¹ ï¼ŒP-KANs èƒ½å¤Ÿå¼•å¯¼è¾¹ç¼˜å‡½æ•°å‘å…·æœ‰å¯è§£é‡Šæ€§çš„åŠŸèƒ½è¡¨ç¤ºæ”¶æ•›ã€‚è¯¥æ–¹æ³•åœ¨ä¿ç•™æ ·æ¡ç©ºé—´çµæ´»æ€§çš„åŸºç¡€ä¸Šï¼Œåˆ©ç”¨â€œå¼•åŠ›â€é¡¹ï¼ˆgravitational termsï¼‰ä¿ƒä½¿è¾¹ç¼˜å‡½æ•°å‹ç¼©è‡³Fourierã€Chebyshevæˆ–Besselç­‰ä½å‚æ•°æŠ•å½±ç©ºé—´ã€‚å®éªŒè¯æ˜ï¼ŒP-KANs åœ¨ä¿æŒåŸæœ‰è¡¨è¾¾èƒ½åŠ›çš„åŒæ—¶å®ç°äº†é«˜è¾¾80%çš„å‚æ•°å‰Šå‡ï¼Œå¹¶æ˜¾è‘—æå‡äº†æ¨¡å‹å¯¹å™ªå£°çš„é²æ£’æ€§ã€‚è¯¥æ¡†æ¶åœ¨å·¥ä¸šè‡ªåŠ¨åŒ–çº¤ç»´æ”¾ç½®é¢„æµ‹ä¸­å¾—åˆ°äº†æˆåŠŸåº”ç”¨ï¼Œé€šè¿‡è‡ªåŠ¨å‘ç°æ··åˆåŠŸèƒ½è¡¨ç¤ºï¼Œä¸ºç§‘å­¦æœºå™¨å­¦ä¹ ï¼ˆScientific Machine Learningï¼‰æä¾›äº†æ›´é«˜çš„æ•ˆç‡ä¸å¯è§£é‡Šæ€§ã€‚",
      "categories": [
        "cs.NE",
        "cs.AI",
        "cs.LG"
      ],
      "primary_category": "cs.NE",
      "comment": "",
      "pdf_url": "https://arxiv.org/pdf/2509.20049v1",
      "published_date": "2025-09-24 12:15:37 UTC",
      "updated_date": "2025-09-24 12:15:37 UTC",
      "processing_status": "completed",
      "attempts": 1,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "llm_backup_calls": 0,
      "last_update": "2026-01-24T20:55:45.391914+00:00"
    },
    {
      "arxiv_id": "2509.20048v3",
      "title": "Manifold-Aware Diffusion-Augmented Contrastive Learning for Noise-Robust Biosignal Representation",
      "title_zh": "é¢å‘å™ªå£°é²æ£’ç”Ÿç‰©ä¿¡å·è¡¨å¾çš„æµå½¢æ„ŸçŸ¥æ‰©æ•£å¢å¼ºå¯¹æ¯”å­¦ä¹ ",
      "authors": [
        "Rami Zewail"
      ],
      "abstract": "Learning robust representations for physiological time-series signals continues to pose a substantial challenge in developing efficient few-shot learning applications. This difficulty is largely due to the complex pathological variations in biosignals. In this context, this paper introduces a manifold-aware Diffusion-Augmented Contrastive Learning (DACL) framework, which efficiently leverages the generative structure of latent diffusion models with the discriminative power of supervised contrastive learning. The proposed framework operates within a contextualized scattering latent space derived from Scattering Transformer (ST) features. Within a contrastive learning framework, we employ a forward diffusion process in the scattering latent space as a structured manifold-aware feature augmentation technique. We assessed the proposed framework using the PhysioNet 2017 ECG benchmark dataset. The proposed method achieved a competitive AUROC of 0.9741 in the task of detecting atrial fibrillation from a single-lead ECG signal. The proposed framework achieved performance on par with relevant state-of-the-art related works. In-depth evaluation findings suggest that early-stage diffusion serves as an ideal \"local manifold explorer,\" producing embeddings with greater precision than typical augmentation methods while preserving inference efficiency.",
      "tldr_zh": "æœ¬ç ”ç©¶æå‡ºäº†ä¸€ç§æµå½¢æ„ŸçŸ¥çš„æ‰©æ•£å¢å¼ºå¯¹æ¯”å­¦ä¹ (Diffusion-Augmented Contrastive Learning, DACL)æ¡†æ¶ï¼Œæ—¨åœ¨è§£å†³ç”Ÿç†æ—¶é—´åºåˆ—ä¿¡å·åœ¨å°‘æ ·æœ¬å­¦ä¹ ä¸­å› å¤æ‚ç—…ç†å˜åŒ–è€Œéš¾ä»¥æå–é²æ£’è¡¨ç¤ºçš„é—®é¢˜ã€‚è¯¥æ¡†æ¶é€šè¿‡ç»“åˆæ½œåœ¨æ‰©æ•£æ¨¡å‹(Latent Diffusion Models)çš„ç”Ÿæˆç‰¹æ€§ä¸ç›‘ç£å¯¹æ¯”å­¦ä¹ (Supervised Contrastive Learning)çš„åˆ¤åˆ«èƒ½åŠ›ï¼Œåœ¨åŸºäºæ•£å°„å˜æ¢å™¨(Scattering Transformer)ç‰¹å¾æ„å»ºçš„æ½œåœ¨ç©ºé—´ä¸­è¿è¡Œã€‚ç ”ç©¶åˆ©ç”¨å‰å‘æ‰©æ•£è¿‡ç¨‹(Forward Diffusion Process)ä½œä¸ºä¸€ç§ç»“æ„åŒ–çš„æµå½¢æ„ŸçŸ¥ç‰¹å¾å¢å¼ºæ‰‹æ®µï¼Œä»¥æå‡æ¨¡å‹æ€§èƒ½ã€‚å®éªŒåœ¨PhysioNet 2017 ECGåŸºå‡†æ•°æ®é›†ä¸Šè¿›è¡Œï¼ŒDACLåœ¨å•å¯¼è”å¿ƒç”µå›¾çš„å¿ƒæˆ¿é¢¤åŠ¨(Atrial Fibrillation)æ£€æµ‹ä»»åŠ¡ä¸­å–å¾—äº†0.9741çš„AUROCï¼Œè¾¾åˆ°äº†ä¸å½“å‰æœ€å…ˆè¿›æŠ€æœ¯(State-of-the-art)ç›¸å½“çš„æ°´å¹³ã€‚æ·±å…¥è¯„ä¼°è¡¨æ˜ï¼Œæ—©æœŸæ‰©æ•£é˜¶æ®µå¯ä½œä¸ºç†æƒ³çš„å±€éƒ¨æµå½¢æ¢ç´¢å™¨(Local Manifold Explorer)ï¼Œåœ¨ä¸ç‰ºç‰²æ¨ç†æ•ˆç‡çš„å‰æä¸‹ç”Ÿæˆæ¯”å¸¸è§„å¢å¼ºæ–¹æ³•æ›´ç²¾ç¡®çš„åµŒå…¥è¡¨ç¤ºã€‚",
      "categories": [
        "cs.LG",
        "cs.AI",
        "eess.SP"
      ],
      "primary_category": "cs.LG",
      "comment": "",
      "pdf_url": "https://arxiv.org/pdf/2509.20048v3",
      "published_date": "2025-09-24 12:15:35 UTC",
      "updated_date": "2025-11-27 02:28:16 UTC",
      "processing_status": "completed",
      "attempts": 1,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "llm_backup_calls": 0,
      "last_update": "2026-01-24T20:55:56.787503+00:00"
    },
    {
      "arxiv_id": "2509.20045v1",
      "title": "Tokenization and Representation Biases in Multilingual Models on Dialectal NLP Tasks",
      "title_zh": "å¤šè¯­è¨€æ¨¡å‹åœ¨æ–¹è¨€è‡ªç„¶è¯­è¨€å¤„ç†ä»»åŠ¡ä¸­çš„åˆ†è¯ä¸è¡¨å¾åè§",
      "authors": [
        "Vani Kanjirangat",
        "Tanja SamardÅ¾iÄ‡",
        "Ljiljana Dolamic",
        "Fabio Rinaldi"
      ],
      "abstract": "Dialectal data are characterized by linguistic variation that appears small to humans but has a significant impact on the performance of models. This dialect gap has been related to various factors (e.g., data size, economic and social factors) whose impact, however, turns out to be inconsistent. In this work, we investigate factors impacting the model performance more directly: we correlate Tokenization Parity (TP) and Information Parity (IP), as measures of representational biases in pre-trained multilingual models, with the downstream performance. We compare state-of-the-art decoder-only LLMs with encoder-based models across three tasks: dialect classification, topic classification, and extractive question answering, controlling for varying scripts (Latin vs. non-Latin) and resource availability (high vs. low). Our analysis reveals that TP is a better predictor of the performance on tasks reliant on syntactic and morphological cues (e.g., extractive QA), while IP better predicts performance in semantic tasks (e.g., topic classification). Complementary analyses, including tokenizer behavior, vocabulary coverage, and qualitative insights, reveal that the language support claims of LLMs often might mask deeper mismatches at the script or token level.",
      "tldr_zh": "è¯¥ç ”ç©¶æ¢è®¨äº†æ–¹è¨€æ•°æ®å¯¹å¤šè¯­è¨€æ¨¡å‹æ€§èƒ½çš„æ˜¾è‘—å½±å“ï¼Œé‡ç‚¹ç ”ç©¶äº†åˆ†è¯å¥‡å¶æ€§(Tokenization Parity, TP)å’Œä¿¡æ¯å¥‡å¶æ€§(Information Parity, IP)ä½œä¸ºè¡¨å¾åç½®ä¸ä¸‹æ¸¸ä»»åŠ¡è¡¨ç°ä¹‹é—´çš„å…³è”ã€‚é€šè¿‡åœ¨æ–¹è¨€åˆ†ç±»ã€ä¸»é¢˜åˆ†ç±»å’ŒæŠ½å–å¼é—®ç­”ä¸‰é¡¹ä»»åŠ¡ä¸Šå¯¹æ¯”ä»…è§£ç å™¨(decoder-only)çš„å¤§è¯­è¨€æ¨¡å‹(LLMs)ä¸åŸºäºç¼–ç å™¨(encoder-based)çš„æ¨¡å‹ï¼Œç ”ç©¶åˆ†æäº†ä¸åŒè„šæœ¬å’Œèµ„æºå¯ç”¨æ€§ä¸‹çš„æ¨¡å‹è¡¨ç°ã€‚å®éªŒç»“æœè¡¨æ˜ï¼ŒTPèƒ½æ›´æœ‰æ•ˆåœ°é¢„æµ‹ä¾èµ–è¯­æ³•å’Œå½¢æ€çº¿ç´¢çš„ä»»åŠ¡ï¼ˆå¦‚æŠ½å–å¼é—®ç­”ï¼‰çš„æ€§èƒ½ï¼Œè€ŒIPåˆ™åœ¨è¯­ä¹‰ä»»åŠ¡ï¼ˆå¦‚ä¸»é¢˜åˆ†ç±»ï¼‰ä¸­å…·æœ‰æ›´å¼ºçš„é¢„æµ‹åŠ›ã€‚æ­¤å¤–ï¼Œè¯¥ç ”ç©¶é€šè¿‡å¯¹åˆ†è¯å™¨è¡Œä¸ºå’Œè¯æ±‡è¦†ç›–ç‡çš„å®šæ€§åˆ†æï¼Œæ­ç¤ºäº†æ¨¡å‹å¯¹å¤šè¯­è¨€æ”¯æŒçš„å®£ç§°å¾€å¾€æ©ç›–äº†è„šæœ¬æˆ–æ ‡è®°(token)å±‚é¢çš„æ·±å±‚ä¸åŒ¹é…é—®é¢˜ã€‚",
      "categories": [
        "cs.CL",
        "cs.AI"
      ],
      "primary_category": "cs.CL",
      "comment": "Accepted in EMNLP-2025 Main conference",
      "pdf_url": "https://arxiv.org/pdf/2509.20045v1",
      "published_date": "2025-09-24 12:13:53 UTC",
      "updated_date": "2025-09-24 12:13:53 UTC",
      "processing_status": "completed",
      "attempts": 1,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "llm_backup_calls": 0,
      "last_update": "2026-01-24T20:55:53.891300+00:00"
    },
    {
      "arxiv_id": "2509.20419v1",
      "title": "Wartime Media Dynamics in Emerging Democracies: Case Study of Pakistani Media in May 2025 Indo-Pak Conflict",
      "title_zh": "æ–°å…´æ°‘ä¸»å›½å®¶çš„æˆ˜æ—¶åª’ä½“åŠ¨æ€ï¼šMay 2025 Indo-Pak å†²çªä¸­çš„ Pakistani åª’ä½“æ¡ˆä¾‹ç ”ç©¶",
      "authors": [
        "Taaha Saleem Bajwa"
      ],
      "abstract": "Democracies rely on opposition and dissent to function, but in emerging democracies, freedom of speech is often restricted. This effect intensifies during regional conflicts. This study examines how the India-Pakistan conflict of May 2025 influenced Pakistani media coverage. Analyzing approximately 2,600 news articles from three major newspapers using a large language model (LLM), the study found that war-related reporting significantly overshadowed coverage of political opposition and dissent. These findings highlight how conflict can marginalize democratic discourse, reinforcing the need to safeguard press freedom in volatile regions.",
      "tldr_zh": "è¯¥ç ”ç©¶æ¢è®¨äº†æ–°å…´æ°‘ä¸»å›½å®¶(emerging democracies)åœ¨åœ°åŒºå†²çªæœŸé—´è¨€è®ºè‡ªç”±(freedom of speech)å—é™çš„é—®é¢˜ï¼Œå¹¶ä»¥2025å¹´5æœˆçš„å°å·´å†²çª(Indo-Pak conflict)ä½œä¸ºå·´åŸºæ–¯å¦åª’ä½“åŠ¨æ€çš„æ¡ˆä¾‹ç ”ç©¶ã€‚ä½œè€…åˆ©ç”¨å¤§å‹è¯­è¨€æ¨¡å‹(LLM)å¯¹ä¸‰å®¶ä¸»è¦æŠ¥åˆŠçš„çº¦2600ç¯‡æ–°é—»æ–‡ç« è¿›è¡Œäº†é‡åŒ–åˆ†æï¼Œä»¥è€ƒå¯Ÿæˆ˜äº‰åŠ¨æ€å¯¹åª’ä½“è¦†ç›–çš„å½±å“ã€‚ç ”ç©¶å‘ç°ï¼Œæˆ˜äº‰ç›¸å…³çš„æŠ¥é“åœ¨åª’ä½“è®®ç¨‹ä¸­å æ®ç»å¯¹ä¸»å¯¼åœ°ä½ï¼Œæ˜¾è‘—æ©ç›–äº†å¯¹æ”¿æ²»åå¯¹æ´¾(political opposition)å’Œå¼‚è®®(dissent)çš„è®¨è®ºã€‚è¿™ä¸€ç»“æœè¡¨æ˜å†²çªä¼šä½¿æ°‘ä¸»è¯è¯­(democratic discourse)è¾¹ç¼˜åŒ–ï¼Œä»è€Œå‰Šå¼±äº†æ–°å…´æ°‘ä¸»å›½å®¶çš„æ°‘ä¸»åŠŸèƒ½ã€‚è¯¥ç ”ç©¶å¼ºè°ƒäº†åœ¨å±€åŠ¿åŠ¨è¡çš„åœ°åŒºä¿æŠ¤æ–°é—»è‡ªç”±(press freedom)ä»¥ç»´æŒå¤šå…ƒåŒ–è¾©è®ºçš„é‡è¦æ€§ã€‚",
      "categories": [
        "cs.CY",
        "cs.AI"
      ],
      "primary_category": "cs.CY",
      "comment": "Accepted as Extended abstract in COLM 2025 workshop on NLP4Democracy",
      "pdf_url": "https://arxiv.org/pdf/2509.20419v1",
      "published_date": "2025-09-24 11:40:10 UTC",
      "updated_date": "2025-09-24 11:40:10 UTC",
      "processing_status": "completed",
      "attempts": 1,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "llm_backup_calls": 0,
      "last_update": "2026-01-24T20:57:13.759199+00:00"
    },
    {
      "arxiv_id": "2509.20024v1",
      "title": "Generative Adversarial Networks Applied for Privacy Preservation in Biometric-Based Authentication and Identification",
      "title_zh": "ç”Ÿæˆå¯¹æŠ—ç½‘ç»œåœ¨åŸºäºç”Ÿç‰©ç‰¹å¾çš„èº«ä»½éªŒè¯ä¸è¯†åˆ«éšç§ä¿æŠ¤ä¸­çš„åº”ç”¨",
      "authors": [
        "Lubos Mjachky",
        "Ivan Homoliak"
      ],
      "abstract": "Biometric-based authentication systems are getting broadly adopted in many areas. However, these systems do not allow participating users to influence the way their data is used. Furthermore, the data may leak and can be misused without the users' knowledge. In this paper, we propose a new authentication method that preserves the privacy of individuals and is based on a generative adversarial network (GAN). Concretely, we suggest using the GAN for translating images of faces to a visually private domain (e.g., flowers or shoes). Classifiers, which are used for authentication purposes, are then trained on the images from the visually private domain. Based on our experiments, the method is robust against attacks and still provides meaningful utility.",
      "tldr_zh": "è¯¥ç ”ç©¶é’ˆå¯¹ç”Ÿç‰©è¯†åˆ«è®¤è¯ç³»ç»Ÿ(Biometric-based authentication systems)ä¸­å­˜åœ¨çš„éšç§æ³„éœ²å’Œæ•°æ®æ»¥ç”¨é£é™©ï¼Œæå‡ºäº†ä¸€ç§åŸºäºç”Ÿæˆå¯¹æŠ—ç½‘ç»œ(Generative Adversarial Networks, GAN)çš„éšç§ä¿æŠ¤è®¤è¯æ–¹æ³•ã€‚è¯¥æ¡†æ¶çš„æ ¸å¿ƒåœ¨äºåˆ©ç”¨ GAN å°†æ•æ„Ÿçš„äººè„¸å›¾åƒè½¬æ¢åˆ°è§†è§‰ä¸Šå…·æœ‰éšç§æ€§çš„é¢†åŸŸ(visually private domain)ï¼Œä¾‹å¦‚èŠ±å‰æˆ–é‹ç±»å›¾åƒï¼Œä»è€Œå®ç°ç”Ÿç‰©ç‰¹å¾çš„è„±æ•å¤„ç†ã€‚éšåï¼Œèº«ä»½éªŒè¯æ‰€éœ€çš„åˆ†ç±»å™¨(Classifiers)å°†åœ¨è¿™äº›éšç§åŸŸå›¾åƒä¸Šè¿›è¡Œè®­ç»ƒï¼Œä»¥åœ¨ä¸æš´éœ²åŸå§‹äººè„¸ä¿¡æ¯çš„æƒ…å†µä¸‹å®Œæˆè¯†åˆ«ä»»åŠ¡ã€‚å®éªŒç»“æœè¡¨æ˜ï¼Œè¯¥æ–¹æ³•èƒ½å¤Ÿæœ‰æ•ˆæŠµå¾¡å„ç±»æ¶æ„æ”»å‡»ï¼Œå¹¶åœ¨ç¡®ä¿ç”¨æˆ·éšç§çš„åŒæ—¶ä¿æŒäº†è‰¯å¥½çš„ç³»ç»Ÿå®ç”¨æ€§ã€‚è¿™ä¸€æ–¹æ¡ˆä¸ºç”Ÿç‰©è¯†åˆ«é¢†åŸŸçš„æ•°æ®å®‰å…¨ç®¡ç†å’Œå¯ä¿¡èº«ä»½éªŒè¯æä¾›äº†åˆ›æ–°çš„æŠ€æœ¯è·¯å¾„ã€‚",
      "categories": [
        "cs.CV",
        "cs.AI",
        "cs.CR"
      ],
      "primary_category": "cs.CV",
      "comment": "",
      "pdf_url": "https://arxiv.org/pdf/2509.20024v1",
      "published_date": "2025-09-24 11:39:40 UTC",
      "updated_date": "2025-09-24 11:39:40 UTC",
      "processing_status": "completed",
      "attempts": 1,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "llm_backup_calls": 0,
      "last_update": "2026-01-24T20:56:05.892372+00:00"
    },
    {
      "arxiv_id": "2509.20021v1",
      "title": "Embodied AI: From LLMs to World Models",
      "title_zh": "å…·èº«æ™ºèƒ½ï¼šä»å¤§è¯­è¨€æ¨¡å‹åˆ°ä¸–ç•Œæ¨¡å‹",
      "authors": [
        "Tongtong Feng",
        "Xin Wang",
        "Yu-Gang Jiang",
        "Wenwu Zhu"
      ],
      "abstract": "Embodied Artificial Intelligence (AI) is an intelligent system paradigm for achieving Artificial General Intelligence (AGI), serving as the cornerstone for various applications and driving the evolution from cyberspace to physical systems. Recent breakthroughs in Large Language Models (LLMs) and World Models (WMs) have drawn significant attention for embodied AI. On the one hand, LLMs empower embodied AI via semantic reasoning and task decomposition, bringing high-level natural language instructions and low-level natural language actions into embodied cognition. On the other hand, WMs empower embodied AI by building internal representations and future predictions of the external world, facilitating physical law-compliant embodied interactions. As such, this paper comprehensively explores the literature in embodied AI from basics to advances, covering both LLM driven and WM driven works. In particular, we first present the history, key technologies, key components, and hardware systems of embodied AI, as well as discuss its development via looking from unimodal to multimodal angle. We then scrutinize the two burgeoning fields of embodied AI, i.e., embodied AI with LLMs/multimodal LLMs (MLLMs) and embodied AI with WMs, meticulously delineating their indispensable roles in end-to-end embodied cognition and physical laws-driven embodied interactions. Building upon the above advances, we further share our insights on the necessity of the joint MLLM-WM driven embodied AI architecture, shedding light on its profound significance in enabling complex tasks within physical worlds. In addition, we examine representative applications of embodied AI, demonstrating its wide applicability in real-world scenarios. Last but not least, we point out future research directions of embodied AI that deserve further investigation.",
      "tldr_zh": "æœ¬æ–‡å…¨é¢ç»¼è¿°äº†å…·èº«æ™ºèƒ½(Embodied AI)ä»åŸºç¡€åˆ°å‰æ²¿çš„ç ”ç©¶è¿›å±•ï¼Œå°†å…¶è§†ä¸ºå®ç°é€šç”¨äººå·¥æ™ºèƒ½(AGI)çš„å…³é”®åŸºçŸ³ã€‚ç ”ç©¶è¯¦ç»†åˆ†æäº†å¤§è¯­è¨€æ¨¡å‹(LLMs)åœ¨è¯­ä¹‰æ¨ç†ä¸ä»»åŠ¡åˆ†è§£ä¸­çš„ä½œç”¨ï¼Œä»¥åŠä¸–ç•Œæ¨¡å‹(World Models, WMs)åœ¨æ¨¡æ‹Ÿç‰©ç†è§„å¾‹å’Œé¢„æµ‹æœªæ¥çŠ¶æ€æ–¹é¢çš„æ ¸å¿ƒè´¡çŒ®ã€‚é€šè¿‡å¯¹å…·èº«è®¤çŸ¥ä¸ç‰©ç†äº¤äº’çš„æ·±å…¥å‰–æï¼Œè®ºæ–‡æå‡ºäº†æ„å»ºå¤šæ¨¡æ€å¤§æ¨¡å‹(MLLM)ä¸ä¸–ç•Œæ¨¡å‹è”åˆé©±åŠ¨æ¶æ„çš„å¿…è¦æ€§ï¼Œä»¥åº”å¯¹ç‰©ç†ä¸–ç•Œä¸­çš„å¤æ‚ä»»åŠ¡ã€‚æ­¤å¤–ï¼Œæ–‡ç« è¿˜ç³»ç»Ÿåœ°æ¢³ç†äº†å…·èº«æ™ºèƒ½çš„å‘å±•å†ç¨‹ã€å…³é”®ç¡¬ä»¶ç»„æˆåŠä»£è¡¨æ€§åº”ç”¨åœºæ™¯ã€‚è¯¥ç ”ç©¶ä¸ä»…å±•ç°äº†å…·èº«æ™ºèƒ½ä»å•æ¨¡æ€å‘å¤šæ¨¡æ€æ¼”è¿›çš„è¶‹åŠ¿ï¼Œè¿˜ä¸ºæœªæ¥å¯äº¤äº’ã€ç¬¦åˆç‰©ç†è§„å¾‹çš„æ™ºèƒ½ç³»ç»Ÿç ”ç©¶æŒ‡æ˜äº†æ–¹å‘ã€‚",
      "categories": [
        "cs.AI",
        "cs.CL",
        "cs.RO"
      ],
      "primary_category": "cs.AI",
      "comment": "Accepted by IEEE CASM",
      "pdf_url": "https://arxiv.org/pdf/2509.20021v1",
      "published_date": "2025-09-24 11:37:48 UTC",
      "updated_date": "2025-09-24 11:37:48 UTC",
      "processing_status": "completed",
      "attempts": 1,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "llm_backup_calls": 0,
      "last_update": "2026-01-24T20:56:06.182342+00:00"
    },
    {
      "arxiv_id": "2510.00022v1",
      "title": "Learning to Lead Themselves: Agentic AI in MAS using MARL",
      "title_zh": "å­¦ä¹ è‡ªæˆ‘é¢†å¯¼ï¼šå¤šæ™ºèƒ½ä½“ç³»ç»Ÿä¸­åŸºäºå¤šæ™ºèƒ½ä½“å¼ºåŒ–å­¦ä¹ çš„ä»£ç†å¼äººå·¥æ™ºèƒ½",
      "authors": [
        "Ansh Kamthan"
      ],
      "abstract": "As autonomous systems move from prototypes to real deployments, the ability of multiple agents to make decentralized, cooperative decisions becomes a core requirement. This paper examines how agentic artificial intelligence, agents that act independently, adaptively and proactively can improve task allocation and coordination in multi-agent systems, with primary emphasis on drone delivery and secondary relevance to warehouse automation. We formulate the problem in a cooperative multi-agent reinforcement learning setting and implement a lightweight multi-agent Proximal Policy Optimization, called IPPO, approach in PyTorch under a centralized-training, decentralized-execution paradigm. Experiments are conducted in PettingZoo environment, where multiple homogeneous drones or agents must self-organize to cover distinct targets without explicit communication.",
      "tldr_zh": "è¯¥ç ”ç©¶æ¢è®¨äº† Agentic AI å¦‚ä½•åœ¨å¤šæ™ºèƒ½ä½“ç³»ç»Ÿ (Multi-Agent Systems, MAS) ä¸­ä¼˜åŒ–ä»»åŠ¡åˆ†é…ä¸åè°ƒï¼Œé‡ç‚¹åº”ç”¨äºæ— äººæœºé…é€å’Œä»“åº“è‡ªåŠ¨åŒ–é¢†åŸŸã€‚ä½œè€…å°†è¯¥æŒ‘æˆ˜è½¬åŒ–ä¸ºåä½œå¼å¤šæ™ºèƒ½ä½“å¼ºåŒ–å­¦ä¹  (Multi-Agent Reinforcement Learning, MARL) é—®é¢˜ï¼Œå¹¶åˆ©ç”¨ PyTorch å®ç°äº†ä¸€ç§è½»é‡åŒ–çš„ IPPO (Independent Proximal Policy Optimization) æ–¹æ¡ˆã€‚è¯¥ç³»ç»Ÿé‡‡ç”¨é›†ä¸­å¼è®­ç»ƒã€åˆ†å¸ƒå¼æ‰§è¡Œ (Centralized-Training, Decentralized-Execution) èŒƒå¼ï¼Œå¼ºè°ƒæ™ºèƒ½ä½“åœ¨ç‹¬ç«‹æ€§ã€é€‚åº”æ€§å’Œä¸»åŠ¨æ€§æ–¹é¢çš„è¡¨ç°ã€‚å®éªŒåœ¨ PettingZoo ç¯å¢ƒä¸­å¼€å±•ï¼ŒéªŒè¯äº†å¤šä¸ªåŒæ„æ™ºèƒ½ä½“åœ¨æ— éœ€æ˜¾å¼é€šä¿¡çš„æƒ…å†µä¸‹ï¼Œèƒ½å¤Ÿé€šè¿‡è‡ªç»„ç»‡æœ‰æ•ˆè¦†ç›–ä¸åŒç›®æ ‡ã€‚è¿™é¡¹å·¥ä½œä¸ºå®ç°å…·å¤‡å»ä¸­å¿ƒåŒ–å†³ç­–èƒ½åŠ›çš„è‡ªä¸»ç³»ç»Ÿæä¾›äº†é‡è¦çš„æŠ€æœ¯è·¯å¾„å’Œå®éªŒè¯æ®ã€‚",
      "categories": [
        "cs.AI",
        "cs.MA"
      ],
      "primary_category": "cs.AI",
      "comment": "Exploring foundational behaviours of agentic ai using MARL 39 pages - 25 minute read, 5 tables, 24 equation, 9 figures",
      "pdf_url": "https://arxiv.org/pdf/2510.00022v1",
      "published_date": "2025-09-24 11:36:07 UTC",
      "updated_date": "2025-09-24 11:36:07 UTC",
      "processing_status": "completed",
      "attempts": 1,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "llm_backup_calls": 0,
      "last_update": "2026-01-24T20:57:52.783294+00:00"
    },
    {
      "arxiv_id": "2509.20004v1",
      "title": "The Knowledge-Behaviour Disconnect in LLM-based Chatbots",
      "title_zh": "åŸºäºå¤§è¯­è¨€æ¨¡å‹çš„èŠå¤©æœºå™¨äººä¸­çŸ¥è¯†ä¸è¡Œä¸ºçš„è„±èŠ‚",
      "authors": [
        "Jan Broersen"
      ],
      "abstract": "Large language model-based artificial conversational agents (like ChatGPT) give answers to all kinds of questions, and often enough these answers are correct. Just on the basis of that capacity alone, we may attribute knowledge to them. But do these models use this knowledge as a basis for their own conversational behaviour? I argue this is not the case, and I will refer to this failure as a `disconnect'. I further argue this disconnect is fundamental in the sense that with more data and more training of the LLM on which a conversational chatbot is based, it will not disappear. The reason is, as I will claim, that the core technique used to train LLMs does not allow for the establishment of the connection we are after. The disconnect reflects a fundamental limitation on the capacities of LLMs, and explains the source of hallucinations. I will furthermore consider the ethical version of the disconnect (ethical conversational knowledge not being aligned with ethical conversational behaviour), since in this domain researchers have come up with several additional techniques to influence a chatbot's behaviour. I will discuss how these techniques do nothing to solve the disconnect and can make it worse.",
      "tldr_zh": "è¯¥ç ”ç©¶æ¢è®¨äº†åŸºäºå¤§å‹è¯­è¨€æ¨¡å‹(LLMs)çš„èŠå¤©æœºå™¨äººä¸­å­˜åœ¨çš„â€œçŸ¥è¯†ä¸è¡Œä¸ºè„±èŠ‚â€(Knowledge-Behaviour Disconnect)ç°è±¡ï¼Œå³æ¨¡å‹è™½ç„¶å…·å¤‡å›ç­”é—®é¢˜çš„çŸ¥è¯†ï¼Œä½†å¹¶æœªå°†å…¶ä½œä¸ºå¯¹è¯è¡Œä¸ºçš„åŸºçŸ³ã€‚ä½œè€…è®¤ä¸ºè¿™ç§è„±èŠ‚æ˜¯æ ¹æœ¬æ€§çš„ï¼Œç”±äºLLMsæ ¸å¿ƒè®­ç»ƒæŠ€æœ¯çš„å±€é™æ€§ï¼Œå¢åŠ æ•°æ®é‡æˆ–åŠ å¼ºè®­ç»ƒæ— æ³•ä»æ ¹æœ¬ä¸Šæ¶ˆé™¤è¿™ä¸€é—®é¢˜ã€‚è¿™ç§è„±èŠ‚ä¸ä»…æ­ç¤ºäº†LLMsèƒ½åŠ›çš„å†…åœ¨é™åˆ¶ï¼Œä¹Ÿè§£é‡Šäº†å¹»è§‰(Hallucinations)ç°è±¡çš„æ¥æºã€‚ç ”ç©¶è¿˜é‡ç‚¹è®¨è®ºäº†ä¼¦ç†ç»´åº¦çš„è„±èŠ‚ï¼ŒæŒ‡å‡ºå³ä¾¿åº”ç”¨äº†å¤šç§è¡Œä¸ºå¹²é¢„æŠ€æœ¯ï¼Œä¹Ÿæ— æ³•çœŸæ­£å®ç°ä¼¦ç†çŸ¥è¯†ä¸è¡Œä¸ºçš„å¯¹é½ã€‚æœ€åï¼Œè®ºæ–‡å¼ºè°ƒç°æœ‰æŠ€æœ¯ä¸ä»…æœªèƒ½è§£å†³è„±èŠ‚é—®é¢˜ï¼Œåè€Œå¯èƒ½ä½¿å…¶æ¶åŒ–ï¼Œä¸ºç†è§£å½“å‰å¯¹è¯å¼äººå·¥æ™ºèƒ½çš„å±€é™æ€§æä¾›äº†é‡è¦çš„ç†è®ºæ¡†æ¶ã€‚",
      "categories": [
        "cs.CL",
        "cs.AI"
      ],
      "primary_category": "cs.CL",
      "comment": "",
      "pdf_url": "https://arxiv.org/pdf/2509.20004v1",
      "published_date": "2025-09-24 11:24:49 UTC",
      "updated_date": "2025-09-24 11:24:49 UTC",
      "processing_status": "completed",
      "attempts": 1,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "llm_backup_calls": 0,
      "last_update": "2026-01-24T20:57:29.468483+00:00"
    },
    {
      "arxiv_id": "2509.20003v1",
      "title": "Table Detection with Active Learning",
      "title_zh": "åŸºäºä¸»åŠ¨å­¦ä¹ çš„è¡¨æ ¼æ£€æµ‹",
      "authors": [
        "Somraj Gautam",
        "Nachiketa Purohit",
        "Gaurav Harit"
      ],
      "abstract": "Efficient data annotation remains a critical challenge in machine learning, particularly for object detection tasks requiring extensive labeled data. Active learning (AL) has emerged as a promising solution to minimize annotation costs by selecting the most informative samples. While traditional AL approaches primarily rely on uncertainty-based selection, recent advances suggest that incorporating diversity-based strategies can enhance sampling efficiency in object detection tasks. Our approach ensures the selection of representative examples that improve model generalization. We evaluate our method on two benchmark datasets (TableBank-LaTeX, TableBank-Word) using state-of-the-art table detection architectures, CascadeTabNet and YOLOv9. Our results demonstrate that AL-based example selection significantly outperforms random sampling, reducing annotation effort given a limited budget while maintaining comparable performance to fully supervised models. Our method achieves higher mAP scores within the same annotation budget.",
      "tldr_zh": "è¯¥ç ”ç©¶é’ˆå¯¹ç›®æ ‡æ£€æµ‹ä»»åŠ¡ä¸­å¤§è§„æ¨¡æ ‡æ³¨æ•°æ®éœ€æ±‚å¸¦æ¥çš„æŒ‘æˆ˜ï¼Œæå‡ºäº†ä¸€ç§ç»“åˆä¸»åŠ¨å­¦ä¹ (Active Learning)çš„è¡¨æ ¼æ£€æµ‹æ–¹æ³•ã€‚ä¸ä¼ ç»Ÿä»…ä¾èµ–ä¸ç¡®å®šæ€§çš„é‡‡æ ·ç­–ç•¥ä¸åŒï¼Œè¯¥æ–¹æ³•èå…¥äº†å¤šæ ·æ€§é‡‡æ ·ç­–ç•¥ï¼Œä»¥ç¡®ä¿é€‰æ‹©æ›´å…·ä»£è¡¨æ€§çš„æ ·æœ¬å¹¶æå‡æ¨¡å‹çš„æ³›åŒ–èƒ½åŠ›ã€‚ç ”ç©¶äººå‘˜åœ¨ TableBank-LaTeX å’Œ TableBank-Word ä¸¤ä¸ªåŸºå‡†æ•°æ®é›†ä¸Šè¿›è¡Œäº†è¯„ä¼°ï¼Œå¹¶é‡‡ç”¨äº† CascadeTabNet å’Œ YOLOv9 è¿™ä¸¤ç§å…ˆè¿›çš„è¡¨æ ¼æ£€æµ‹æ¶æ„ã€‚å®éªŒç»“æœè¡¨æ˜ï¼ŒåŸºäºä¸»åŠ¨å­¦ä¹ (AL)çš„æ ·æœ¬é€‰æ‹©æ–¹æ³•æ˜¾è‘—ä¼˜äºéšæœºé‡‡æ ·ï¼Œåœ¨æœ‰é™çš„æ ‡æ³¨é¢„ç®—ä¸‹æ˜¾è‘—é™ä½äº†äººå·¥æ ‡æ³¨æˆæœ¬ã€‚æœ€ç»ˆï¼Œè¯¥æ–¹æ³•åœ¨ä¿æŒä¸å…¨ç›‘ç£æ¨¡å‹ç›¸å½“æ€§èƒ½çš„åŒæ—¶ï¼Œå®ç°äº†æ›´é«˜çš„å¹³å‡ç²¾åº¦å‡å€¼(mAP)åˆ†æ•°ï¼Œè¯æ˜äº†å…¶åœ¨è¡¨æ ¼æ£€æµ‹ä»»åŠ¡ä¸­çš„é«˜æ•ˆæ€§ã€‚",
      "categories": [
        "cs.CV",
        "cs.AI",
        "cs.CL",
        "cs.LG"
      ],
      "primary_category": "cs.CV",
      "comment": "Accepted in ICDAR 2025",
      "pdf_url": "https://arxiv.org/pdf/2509.20003v1",
      "published_date": "2025-09-24 11:22:30 UTC",
      "updated_date": "2025-09-24 11:22:30 UTC",
      "processing_status": "completed",
      "attempts": 1,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "llm_backup_calls": 0,
      "last_update": "2026-01-24T20:57:31.957240+00:00"
    },
    {
      "arxiv_id": "2509.20418v1",
      "title": "A Taxonomy of Data Risks in AI and Quantum Computing (QAI) - A Systematic Review",
      "title_zh": "äººå·¥æ™ºèƒ½ä¸é‡å­è®¡ç®— (QAI) æ•°æ®é£é™©åˆ†ç±»ä½“ç³»ï¼šç³»ç»Ÿç»¼è¿°",
      "authors": [
        "Grace Billiris",
        "Asif Gill",
        "Madhushi Bandara"
      ],
      "abstract": "Quantum Artificial Intelligence (QAI), the integration of Artificial Intelligence (AI) and Quantum Computing (QC), promises transformative advances, including AI-enabled quantum cryptography and quantum-resistant encryption protocols. However, QAI inherits data risks from both AI and QC, creating complex privacy and security vulnerabilities that are not systematically studied. These risks affect the trustworthiness and reliability of AI and QAI systems, making their understanding critical. This study systematically reviews 67 privacy- and security-related studies to expand understanding of QAI data risks. We propose a taxonomy of 22 key data risks, organised into five categories: governance, risk assessment, control implementation, user considerations, and continuous monitoring. Our findings reveal vulnerabilities unique to QAI and identify gaps in holistic risk assessment. This work contributes to trustworthy AI and QAI research and provides a foundation for developing future risk assessment tools.",
      "tldr_zh": "è¯¥ç ”ç©¶å¯¹äººå·¥æ™ºèƒ½(AI)ä¸é‡å­è®¡ç®—(Quantum Computing, QC)ç»“åˆäº§ç”Ÿçš„é‡å­äººå·¥æ™ºèƒ½(QAI)é¢†åŸŸä¸­çš„æ•°æ®é£é™©è¿›è¡Œäº†ç³»ç»Ÿæ€§ç»¼è¿°ã€‚ç ”ç©¶æŒ‡å‡ºQAIè™½ç„¶å…·å¤‡å˜é©æ½œåŠ›ï¼Œä½†ä¹Ÿç»§æ‰¿äº†æ¥è‡ªAIå’ŒQCçš„å¤æ‚éšç§ä¸å®‰å…¨æ¼æ´ï¼Œä¸¥é‡å½±å“äº†ç³»ç»Ÿçš„å¯ä¿¡åº¦ä¸å¯é æ€§ã€‚é€šè¿‡å¯¹67é¡¹ç›¸å…³ç ”ç©¶çš„æ·±å…¥åˆ†æï¼Œä½œè€…æå‡ºäº†ä¸€ä¸ªåŒ…å«22é¡¹å…³é”®æ•°æ®é£é™©çš„åˆ†ç±»æ³•(taxonomy)ï¼Œå¹¶å°†å…¶åˆ’åˆ†ä¸ºæ²»ç†(governance)ã€é£é™©è¯„ä¼°(risk assessment)ã€æ§åˆ¶å®æ–½(control implementation)ã€ç”¨æˆ·è€ƒè™‘å› ç´ (user considerations)åŠæŒç»­ç›‘æ§(continuous monitoring)äº”å¤§èŒƒç•´ã€‚è¯¥ç ”ç©¶æ­ç¤ºäº†QAIç‰¹æœ‰çš„è„†å¼±æ€§ï¼Œå¹¶è¯†åˆ«äº†ç°æœ‰å…¨é¢é£é™©è¯„ä¼°ä¸­çš„çŸ¥è¯†ç©ºç™½ã€‚è¿™é¡¹å·¥ä½œä¸ºæ„å»ºå¯ä¿¡AIä¸QAIçš„ç ”ç©¶æä¾›äº†é‡è¦å‚è€ƒï¼Œå¹¶ä¸ºæœªæ¥å¼€å‘ä¸“é—¨çš„é£é™©è¯„ä¼°å·¥å…·å¥ å®šäº†åŸºç¡€ã€‚",
      "categories": [
        "cs.CR",
        "cs.AI",
        "cs.ET"
      ],
      "primary_category": "cs.CR",
      "comment": "11 pages, 2 figures, 2 tables",
      "pdf_url": "https://arxiv.org/pdf/2509.20418v1",
      "published_date": "2025-09-24 11:17:27 UTC",
      "updated_date": "2025-09-24 11:17:27 UTC",
      "processing_status": "completed",
      "attempts": 1,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "llm_backup_calls": 0,
      "last_update": "2026-01-24T20:57:34.961523+00:00"
    },
    {
      "arxiv_id": "2510.01252v3",
      "title": "GPT and Prejudice: A Sparse Approach to Understanding Learned Representations in Large Language Models",
      "title_zh": "GPT ä¸åè§ï¼šä¸€ç§ç†è§£å¤§è¯­è¨€æ¨¡å‹å­¦ä¹ è¡¨å¾çš„ç¨€ç–æ–¹æ³•",
      "authors": [
        "Mariam Mahran",
        "Katharina Simbeck"
      ],
      "abstract": "Large Language Models (LLMs) are trained on massive, unstructured corpora, making it unclear which social patterns and biases they absorb and later reproduce. Existing evaluations typically examine outputs or activations, but rarely connect them back to the pre-training data. We introduce a pipeline that couples LLMs with sparse autoencoders (SAEs) to trace how different themes are encoded during training. As a controlled case study, we trained a GPT-style model on 37 nineteenth-century novels by ten female authors, a corpus centered on themes such as gender, marriage, class, and morality. By applying SAEs across layers and probing with eleven social and moral categories, we mapped sparse features to human-interpretable concepts. The analysis revealed stable thematic backbones (most prominently around gender and kinship) and showed how associations expand and entangle with depth. More broadly, we argue that the LLM+SAEs pipeline offers a scalable framework for auditing how cultural assumptions from the data are embedded in model representations.",
      "tldr_zh": "è¯¥ç ”ç©¶æ¢è®¨äº†å¤§å‹è¯­è¨€æ¨¡å‹ (LLMs) å¦‚ä½•åœ¨æµ·é‡è¯­æ–™åº“è®­ç»ƒä¸­å¸æ”¶å¹¶å¤ç°ç¤¾ä¼šæ¨¡å¼ä¸åè§ï¼Œæ—¨åœ¨å»ºç«‹é¢„è®­ç»ƒæ•°æ®ä¸æ¨¡å‹å†…éƒ¨è¡¨ç¤ºä¹‹é—´çš„è”ç³»ã€‚ç ”ç©¶å›¢é˜Ÿæå‡ºäº†ä¸€ç§å°† LLMs ä¸ç¨€ç–è‡ªç¼–ç å™¨ (Sparse Autoencoders, SAEs) ç›¸ç»“åˆçš„åˆ†ææµç¨‹ï¼Œç”¨äºè¿½è¸ªè®­ç»ƒè¿‡ç¨‹ä¸­ä¸åŒä¸»é¢˜çš„ç¼–ç æ¼”å˜ã€‚é€šè¿‡åœ¨ 19 ä¸–çºªå¥³æ€§æ–‡å­¦è¯­æ–™åº“ä¸Šè®­ç»ƒ GPT é£æ ¼æ¨¡å‹å¹¶åº”ç”¨æ­¤æµç¨‹ï¼Œç ”ç©¶è€…åˆ©ç”¨ 11 ä¸ªç¤¾ä¼šä¸é“å¾·ç±»åˆ«æ¢æµ‹å°†ç¨€ç–ç‰¹å¾æˆåŠŸæ˜ å°„ä¸ºäººç±»å¯ç†è§£çš„æ¦‚å¿µã€‚åˆ†ææ­ç¤ºäº†æ¨¡å‹ä¸­å­˜åœ¨ç¨³å®šçš„ä¸»é¢˜éª¨å¹²ï¼Œå°¤å…¶æ˜¯å›´ç»•æ€§åˆ« (gender) å’Œäº²å±å…³ç³» (kinship) çš„ç‰¹å¾ï¼Œå¹¶å±•ç¤ºäº†è¿™äº›å…³è”å¦‚ä½•éšç½‘ç»œæ·±åº¦å¢åŠ è€Œæ‰©å±•å’Œäº¤ç»‡ã€‚è¯¥ç ”ç©¶è¯æ˜äº† LLM+SAEs æ¡†æ¶åœ¨å®¡è®¡æ•°æ®æ–‡åŒ–å‡è®¾å¦‚ä½•åµŒå…¥æ¨¡å‹è¡¨ç¤ºæ–¹é¢çš„å¯æ‰©å±•æ€§ï¼Œä¸ºç†è§£å¤æ‚æ¨¡å‹å­¦ä¹ åˆ°çš„ç¤¾ä¼šè¡¨å¾æä¾›äº†æ–°è§†è§’ã€‚",
      "categories": [
        "cs.CL",
        "cs.AI",
        "cs.LG"
      ],
      "primary_category": "cs.CL",
      "comment": "Preprint. Draft version, subject to revision",
      "pdf_url": "https://arxiv.org/pdf/2510.01252v3",
      "published_date": "2025-09-24 11:10:16 UTC",
      "updated_date": "2025-11-13 10:09:28 UTC",
      "processing_status": "completed",
      "attempts": 1,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "llm_backup_calls": 0,
      "last_update": "2026-01-24T20:57:54.490252+00:00"
    },
    {
      "arxiv_id": "2509.19996v1",
      "title": "Choosing to Be Green: Advancing Green AI via Dynamic Model Selection",
      "title_zh": "æ‹©ç»¿è€Œè¡Œï¼šé€šè¿‡åŠ¨æ€æ¨¡å‹é€‰æ‹©æ¨è¿›ç»¿è‰²äººå·¥æ™ºèƒ½",
      "authors": [
        "Emilio Cruciani",
        "Roberto Verdecchia"
      ],
      "abstract": "Artificial Intelligence is increasingly pervasive across domains, with ever more complex models delivering impressive predictive performance. This fast technological advancement however comes at a concerning environmental cost, with state-of-the-art models - particularly deep neural networks and large language models - requiring substantial computational resources and energy. In this work, we present the intuition of Green AI dynamic model selection, an approach based on dynamic model selection that aims at reducing the environmental footprint of AI by selecting the most sustainable model while minimizing potential accuracy loss. Specifically, our approach takes into account the inference task, the environmental sustainability of available models, and accuracy requirements to dynamically choose the most suitable model. Our approach presents two different methods, namely Green AI dynamic model cascading and Green AI dynamic model routing. We demonstrate the effectiveness of our approach via a proof of concept empirical example based on a real-world dataset. Our results show that Green AI dynamic model selection can achieve substantial energy savings (up to ~25%) while substantially retaining the accuracy of the most energy greedy solution (up to ~95%). As conclusion, our preliminary findings highlight the potential that hybrid, adaptive model selection strategies withhold to mitigate the energy demands of modern AI systems without significantly compromising accuracy requirements.",
      "tldr_zh": "è¯¥ç ”ç©¶é’ˆå¯¹äººå·¥æ™ºèƒ½æ—¥ç›Šå¢é•¿çš„ç¯å¢ƒæˆæœ¬é—®é¢˜ï¼Œæå‡ºäº† Green AI dynamic model selection æ¡†æ¶ï¼Œæ—¨åœ¨é€šè¿‡åŠ¨æ€æ¨¡å‹é€‰æ‹©åœ¨é™ä½èƒ½æºæ¶ˆè€—çš„åŒæ—¶æœ€å°åŒ–ç²¾åº¦æŸå¤±ã€‚è¯¥æ–¹æ³•ç»¼åˆè€ƒè™‘æ¨ç†ä»»åŠ¡ã€å¯ç”¨æ¨¡å‹çš„å¯æŒç»­æ€§ä»¥åŠç²¾åº¦éœ€æ±‚ï¼Œä»è€ŒåŠ¨æ€æŒ‘é€‰æœ€åˆé€‚çš„æ¨¡å‹è¿›è¡Œæ¨ç†ã€‚ç ”ç©¶å…·ä½“ä»‹ç»äº† Green AI dynamic model cascading å’Œ Green AI dynamic model routing ä¸¤ç§å®ç°æ–¹æ³•ã€‚é€šè¿‡åŸºäºçœŸå®æ•°æ®é›†çš„å®éªŒéªŒè¯ï¼Œè¯¥æ–¹æ¡ˆèƒ½åœ¨ä¿ç•™èƒ½æºå¯†é›†å‹æ¨¡å‹çº¦ 95% ç²¾åº¦çš„æƒ…å†µä¸‹ï¼Œå®ç°é«˜è¾¾ 25% çš„èƒ½æºèŠ‚çœã€‚ç ”ç©¶ç»“æœè¡¨æ˜ï¼Œè¿™ç§æ··åˆä¸”è‡ªé€‚åº”çš„æ¨¡å‹é€‰æ‹©ç­–ç•¥èƒ½å¤Ÿæœ‰æ•ˆå¹³è¡¡ç°ä»£ AI ç³»ç»Ÿçš„èƒ½æºéœ€æ±‚ä¸æ€§èƒ½è¡¨ç°ï¼Œä¸ºæ¨åŠ¨å¯æŒç»­çš„ Green AI å‘å±•æä¾›äº†é‡è¦å‚è€ƒã€‚",
      "categories": [
        "cs.CY",
        "cs.AI"
      ],
      "primary_category": "cs.CY",
      "comment": "2nd Workshop on Green-Aware Artificial Intelligence (Green-Aware 2025). 9 pages, 1 figure",
      "pdf_url": "https://arxiv.org/pdf/2509.19996v1",
      "published_date": "2025-09-24 11:02:13 UTC",
      "updated_date": "2025-09-24 11:02:13 UTC",
      "processing_status": "completed",
      "attempts": 1,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "llm_backup_calls": 0,
      "last_update": "2026-01-24T20:57:48.490546+00:00"
    },
    {
      "arxiv_id": "2509.19990v1",
      "title": "SDE-DET: A Precision Network for Shatian Pomelo Detection in Complex Orchard Environments",
      "title_zh": "SDE-DETï¼šå¤æ‚æœå›­ç¯å¢ƒä¸‹æ²™ç”°æŸšæ£€æµ‹çš„ç²¾å‡†ç½‘ç»œ",
      "authors": [
        "Yihao Hu",
        "Pan Wang",
        "Xiaodong Bai",
        "Shijie Cai",
        "Hang Wang",
        "Huazhong Liu",
        "Aiping Yang",
        "Xiangxiang Li",
        "Meiping Ding",
        "Hongyan Liu",
        "Jianguo Yao"
      ],
      "abstract": "Pomelo detection is an essential process for their localization, automated robotic harvesting, and maturity analysis. However, detecting Shatian pomelo in complex orchard environments poses significant challenges, including multi-scale issues, obstructions from trunks and leaves, small object detection, etc. To address these issues, this study constructs a custom dataset STP-AgriData and proposes the SDE-DET model for Shatian pomelo detection. SDE-DET first utilizes the Star Block to effectively acquire high-dimensional information without increasing the computational overhead. Furthermore, the presented model adopts Deformable Attention in its backbone, to enhance its ability to detect pomelos under occluded conditions. Finally, multiple Efficient Multi-Scale Attention mechanisms are integrated into our model to reduce the computational overhead and extract deep visual representations, thereby improving the capacity for small object detection. In the experiment, we compared SDE-DET with the Yolo series and other mainstream detection models in Shatian pomelo detection. The presented SDE-DET model achieved scores of 0.883, 0.771, 0.838, 0.497, and 0.823 in Precision, Recall, mAP@0.5, mAP@0.5:0.95 and F1-score, respectively. SDE-DET has achieved state-of-the-art performance on the STP-AgriData dataset. Experiments indicate that the SDE-DET provides a reliable method for Shatian pomelo detection, laying the foundation for the further development of automatic harvest robots.",
      "tldr_zh": "è¯¥ç ”ç©¶é’ˆå¯¹å¤æ‚æœå›­ç¯å¢ƒä¸‹æ²™ç”°æŸšæ£€æµ‹é¢ä¸´çš„å¤šå°ºåº¦ã€æå¶é®æŒ¡åŠå°ç›®æ ‡æ£€æµ‹ç­‰æŒ‘æˆ˜ï¼Œæ„å»ºäº†ä¸“é—¨çš„ STP-AgriData æ•°æ®é›†ï¼Œå¹¶æå‡ºäº† SDE-DET æ£€æµ‹æ¨¡å‹ã€‚SDE-DET å¼•å…¥äº† Star Block æ¨¡å—ï¼Œæ—¨åœ¨ä¸å¢åŠ è®¡ç®—å¼€é”€çš„å‰æä¸‹æœ‰æ•ˆæå–é«˜ç»´ç‰¹å¾ä¿¡æ¯ã€‚ä¸ºäº†æå‡é®æŒ¡ç¯å¢ƒä¸‹çš„é²æ£’æ€§ï¼Œè¯¥æ¨¡å‹åœ¨ä¸»å¹²ç½‘ç»œä¸­é‡‡ç”¨äº† Deformable Attention æœºåˆ¶ï¼Œæ˜¾è‘—å¢å¼ºäº†å¯¹è¢«é®æŒ¡æœå®çš„è¯†åˆ«èƒ½åŠ›ã€‚æ­¤å¤–ï¼Œé€šè¿‡é›†æˆå¤šä¸ª Efficient Multi-Scale Attention æœºåˆ¶ï¼Œæ¨¡å‹åœ¨é™ä½è®¡ç®—è´Ÿæ‹…çš„åŒæ—¶æå–æ·±å±‚è§†è§‰è¡¨å¾ï¼Œä»è€Œä¼˜åŒ–äº†å¯¹å°ç›®æ ‡çš„æ£€æµ‹ç²¾åº¦ã€‚å®éªŒç»“æœè¡¨æ˜ï¼ŒSDE-DET åœ¨ Precisionã€Recall å’Œ mAP@0.5 ç­‰æŒ‡æ ‡ä¸Šåˆ†åˆ«è¾¾åˆ°äº† 0.883ã€0.771 å’Œ 0.838ï¼Œæ€§èƒ½ä¼˜äº YOLO ç³»åˆ—ç­‰ä¸»æµæ£€æµ‹æ¨¡å‹ã€‚è¯¥ç ”ç©¶ä¸ºæ²™ç”°æŸšçš„ç²¾ç¡®æ£€æµ‹æä¾›äº†å¯é æ–¹æ³•ï¼Œä¸ºæœªæ¥è‡ªåŠ¨é‡‡æ‘˜æœºå™¨äººçš„å¼€å‘å¥ å®šäº†é‡è¦æŠ€æœ¯åŸºç¡€ã€‚",
      "categories": [
        "cs.CV",
        "cs.AI"
      ],
      "primary_category": "cs.CV",
      "comment": "",
      "pdf_url": "https://arxiv.org/pdf/2509.19990v1",
      "published_date": "2025-09-24 10:50:44 UTC",
      "updated_date": "2025-09-24 10:50:44 UTC",
      "processing_status": "completed",
      "attempts": 1,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "llm_backup_calls": 0,
      "last_update": "2026-01-24T20:57:46.564335+00:00"
    },
    {
      "arxiv_id": "2509.19972v3",
      "title": "An effective control of large systems of active particles: An application to evacuation problem",
      "title_zh": "å¤§å‹ä¸»åŠ¨ç²’å­ç³»ç»Ÿçš„æœ‰æ•ˆæ§åˆ¶ï¼šåœ¨ç–æ•£é—®é¢˜ä¸­çš„åº”ç”¨",
      "authors": [
        "Albina Klepach",
        "Egor E. Nuzhin",
        "Alexey A. Tsukanov",
        "Nikolay V. Brilliantov"
      ],
      "abstract": "Manipulation of large systems of active particles is a serious challenge across diverse domains, including crowd management, control of robotic swarms, and coordinated material transport. The development of advanced control strategies for complex scenarios is hindered, however, by the lack of scalability and robustness of the existing methods, in particular, due to the need of an individual control for each agent. One possible solution involves controlling a system through a leader or a group of leaders, which other agents tend to follow. Using such an approach we develop an effective control strategy for a leader, combining reinforcement learning (RL) with artificial forces acting on the system. To describe the guidance of active particles by a leader we introduce the generalized Vicsek model. This novel method is then applied to the problem of the effective evacuation by a robot-rescuer (leader) of large groups of people from hazardous places. We demonstrate, that while a straightforward application of RL yields suboptimal results, even for advanced architectures, our approach provides a robust and efficient evacuation strategy. The source code supporting this study is publicly available at: https://github.com/cinemere/evacuation.",
      "tldr_zh": "é’ˆå¯¹å¤§è§„æ¨¡æ´»è·ƒç²’å­ï¼ˆactive particlesï¼‰ç³»ç»Ÿåœ¨äººç¾¤ç®¡ç†å’Œæœºå™¨äººç¾¤æ§ä¸­é¢ä¸´çš„å¯æ‰©å±•æ€§ä¸é²æ£’æ€§éš¾é¢˜ï¼Œè¯¥ç ”ç©¶æå‡ºäº†ä¸€ç§ç»“åˆå¼ºåŒ–å­¦ä¹ ï¼ˆReinforcement Learning, RLï¼‰ä¸äººå·¥åŠ›ï¼ˆartificial forcesï¼‰çš„æœ‰æ•ˆé¢†å¯¼è€…ï¼ˆleaderï¼‰æ§åˆ¶ç­–ç•¥ã€‚é€šè¿‡å¼•å…¥å¹¿ä¹‰Vicsekæ¨¡å‹ï¼ˆgeneralized Vicsek modelï¼‰æ¥æè¿°é¢†å¯¼è€…å¯¹ç³»ç»Ÿçš„å¼•å¯¼è¿‡ç¨‹ï¼Œè¯¥æ–¹æ³•æœ‰æ•ˆè§£å†³äº†å¯¹æ¯ä¸ªä¸ªä½“è¿›è¡Œå•ç‹¬æ§åˆ¶çš„å±€é™æ€§ã€‚ç ”ç©¶å°†æ­¤ç­–ç•¥åº”ç”¨äºæœºå™¨äººæ•‘æ´è€…ï¼ˆrobot-rescuerï¼‰åœ¨å±é™©åœºæ‰€ç–æ•£å¤§è§„æ¨¡äººç¾¤çš„å®é™…é—®é¢˜ä¸­ã€‚å®éªŒè¯æ˜ï¼Œç›¸è¾ƒäºç›´æ¥åº”ç”¨å¼ºåŒ–å­¦ä¹ äº§ç”Ÿçš„æ¬¡ä¼˜ç»“æœï¼Œè¯¥æ–¹æ³•å±•ç°å‡ºäº†æé«˜çš„ç¨³å¥æ€§å’Œç–æ•£æ•ˆç‡ã€‚è¯¥é¡¹å·¥ä½œä¸ºå¤æ‚ç¯å¢ƒä¸‹çš„å¤§è§„æ¨¡ç¾¤ä½“ååŒç®¡ç†ä¸ç–æ•£é—®é¢˜æä¾›äº†åˆ›æ–°çš„è§£å†³æ–¹æ¡ˆã€‚",
      "categories": [
        "cs.RO",
        "cs.AI"
      ],
      "primary_category": "cs.RO",
      "comment": "",
      "pdf_url": "https://arxiv.org/pdf/2509.19972v3",
      "published_date": "2025-09-24 10:27:45 UTC",
      "updated_date": "2025-12-12 14:51:16 UTC",
      "processing_status": "completed",
      "attempts": 1,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "llm_backup_calls": 0,
      "last_update": "2026-01-24T20:57:51.085862+00:00"
    },
    {
      "arxiv_id": "2509.25224v1",
      "title": "AMLA: MUL by ADD in FlashAttention Rescaling",
      "title_zh": "AMLAï¼šFlashAttention é‡ç¼©æ”¾ä¸­çš„ä»¥åŠ ä»£ä¹˜",
      "authors": [
        "Qichen Liao",
        "Chengqiu Hu",
        "Fangzheng Miao",
        "Bao Li",
        "Yiyang Liu",
        "Junlong Lyu",
        "Lirui Jiang",
        "Jun Wang",
        "Lingchao Zheng",
        "Jun Li",
        "Yuwei Fan"
      ],
      "abstract": "Multi-head Latent Attention (MLA) significantly reduces KVCache memory usage in Large Language Models while introducing substantial computational overhead and intermediate variable expansion. This poses challenges for efficient hardware implementation -- especially during the decode phase. This paper introduces Ascend MLA (AMLA), a high-performance kernel specifically optimized for Huawei's Ascend NPUs. AMLA is built on two core innovations: (1) A novel FlashAttention-based algorithm that replaces floating-point multiplications with integer additions for output block rescaling, leveraging binary correspondence between FP32 and INT32 representations; (2) A Preload Pipeline strategy with hierarchical tiling that maximizes FLOPS utilization: the Preload Pipeline achieves Cube-bound performance, while hierarchical tiling overlaps data movement and computation within the Cube core. Experiments show that on Ascend 910 NPUs (integrated in CloudMatrix384), AMLA achieves up to 614 TFLOPS, reaching 86.8% of the theoretical maximum FLOPS, outperforming the state-of-the-art open-source FlashMLA implementation, whose FLOPS utilization is up to 66.7% on NVIDIA H800 SXM5. The AMLA kernel has been integrated into Huawei's CANN and will be released soon.",
      "tldr_zh": "è¯¥ç ”ç©¶é’ˆå¯¹ Multi-head Latent Attention (MLA) åœ¨è§£ç é˜¶æ®µå¸¦æ¥çš„è®¡ç®—å¼€é”€å’Œç¡¬ä»¶å®ç°æŒ‘æˆ˜ï¼Œæå‡ºäº†ä¸“ä¸ºåä¸º Ascend NPU ä¼˜åŒ–çš„é«˜æ€§èƒ½ç®—å­ Ascend MLA (AMLA)ã€‚AMLA åˆ›æ–°æ€§åœ°é‡‡ç”¨äº†ä¸€ç§åŸºäº FlashAttention çš„ç®—æ³•ï¼Œåˆ©ç”¨ FP32 ä¸ INT32 è¡¨ç¤ºä¹‹é—´çš„äºŒè¿›åˆ¶å¯¹åº”å…³ç³»ï¼Œå°†è¾“å‡ºé‡ç¼©æ”¾è¿‡ç¨‹ä¸­çš„æµ®ç‚¹ä¹˜æ³•æ›¿æ¢ä¸ºæ•´æ•°åŠ æ³•ä»¥æå‡æ•ˆç‡ã€‚æ­¤å¤–ï¼Œé€šè¿‡å¼•å…¥å¸¦æœ‰å±‚æ¬¡åŒ–åˆ†å— (Hierarchical Tiling) çš„é¢„åŠ è½½æµæ°´çº¿ (Preload Pipeline) ç­–ç•¥ï¼Œè¯¥ç®—å­æˆåŠŸé‡å äº†æ•°æ®ç§»åŠ¨ä¸è®¡ç®—ï¼Œå®ç°äº† Cube-bound æé€Ÿæ€§èƒ½ã€‚å®éªŒç»“æœè¡¨æ˜ï¼ŒAMLA åœ¨ Ascend 910 NPU ä¸Šè¾¾åˆ°äº† 614 TFLOPSï¼Œå…¶ç†è®ºå³°å€¼åˆ©ç”¨ç‡é«˜è¾¾ 86.8%ï¼Œæ˜¾è‘—ä¼˜äºç›®å‰å¼€æº FlashMLA åœ¨ NVIDIA H800 ä¸Š 66.7% çš„åˆ©ç”¨ç‡æ°´å¹³ã€‚è¯¥ç®—å­ç›®å‰å·²é›†æˆè‡³åä¸º CANN æ¡†æ¶ï¼Œä¸ºå¤§è¯­è¨€æ¨¡å‹åœ¨å›½äº§ç®—åŠ›å¹³å°ä¸Šçš„é«˜æ•ˆæ¨ç†å¥ å®šäº†é‡è¦åŸºç¡€ã€‚",
      "categories": [
        "cs.LG",
        "cs.AI"
      ],
      "primary_category": "cs.LG",
      "comment": "21 pages, 11 figures",
      "pdf_url": "https://arxiv.org/pdf/2509.25224v1",
      "published_date": "2025-09-24 10:04:59 UTC",
      "updated_date": "2025-09-24 10:04:59 UTC",
      "processing_status": "completed",
      "attempts": 1,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "llm_backup_calls": 0,
      "last_update": "2026-01-24T20:58:01.495477+00:00"
    },
    {
      "arxiv_id": "2509.19953v1",
      "title": "2025 Southeast Asia Eleven Nations Influence Index Report",
      "title_zh": "2025å¹´ä¸œå—äºšåä¸€å›½å½±å“åŠ›æŒ‡æ•°æŠ¥å‘Š",
      "authors": [
        "Wei Meng"
      ],
      "abstract": "This study constructs a fully data-driven and reproducible Southeast Asia Influence Index (SAII v3) to reduce bias from expert scoring and subjective weighting while mapping hierarchical power structures across the eleven ASEAN nations. We aggregate authoritative open-source indicators across four dimensions (economic, military, diplomatic, socio-technological) and apply a three-tiered standardization chain quantile-Box-Cox-min-max to mitigate outliers and skewness. Weights are obtained through equal-weight integration of Entropy Weighting Method (EWM), CRITIC, and PCA. Robustness is assessed via Kendall's tau, +/-20% weight perturbation, and 10,000 bootstrap iterations, with additional checks including +/-10% dimensional sensitivity and V2-V3 bump chart comparisons. Results show integrated weights: Economy 35-40%, Military 20-25%, Diplomacy about 20%, Socio-Technology about 15%. The regional landscape exhibits a one-strong, two-medium, three-stable, and multiple-weak pattern: Indonesia, Singapore, and Malaysia lead, while Thailand, the Philippines, and Vietnam form a mid-tier competitive band. V2 and V3 rankings are highly consistent (Kendall's tau = 0.818), though small mid-tier reorderings appear (Thailand and the Philippines rise, Vietnam falls), indicating that v3 is more sensitive to structural equilibrium. ASEAN-11 average sensitivity highlights military and socio-technological dimensions as having the largest marginal effects (+/-0.002). In conclusion, SAII v3 delivers algorithmic weighting and auditable reproducibility, reveals multidimensional drivers of influence in Southeast Asia, and provides actionable quantitative evidence for resource allocation and policy prioritization by regional governments and external partners.",
      "tldr_zh": "è¯¥ç ”ç©¶æ„å»ºäº†å…¨æ•°æ®é©±åŠ¨ä¸”å¯å¤ç°çš„ä¸œå—äºšå½±å“åŠ›æŒ‡æ•° (Southeast Asia Influence Index, SAII v3)ï¼Œæ—¨åœ¨å‡å°‘ä¸“å®¶è¯„åˆ†çš„ä¸»è§‚åè§å¹¶æ˜ å°„ä¸œç›Ÿåä¸€å›½çš„å±‚çº§æƒåŠ›ç»“æ„ã€‚è¯¥æŒ‡æ•°æ•´åˆäº†ç»æµ (Economic)ã€å†›äº‹ (Military)ã€å¤–äº¤ (Diplomatic) å’Œç¤¾ä¼šæŠ€æœ¯ (Socio-technological) å››ä¸ªç»´åº¦çš„æƒå¨æŒ‡æ ‡ï¼Œå¹¶é‡‡ç”¨ä¸‰å±‚æ ‡å‡†åŒ–é“¾ Quantile-Box-Cox-min-max ä»¥æ¶ˆé™¤æ•°æ®åæ–œã€‚é€šè¿‡ç­‰æƒé›†æˆç†µæƒæ³• (EWM)ã€CRITIC å’Œä¸»æˆåˆ†åˆ†æ (PCA) è·å–çš„å®¢è§‚æƒé‡æ˜¾ç¤ºï¼Œç»æµç»´åº¦å æ¯”æœ€é«˜ (35-40%)ï¼Œè€Œå†›äº‹å’Œç¤¾ä¼šæŠ€æœ¯ç»´åº¦å…·æœ‰æœ€å¤§çš„è¾¹é™…æ•ˆåº”ã€‚ç ”ç©¶æ­ç¤ºäº†åŒºåŸŸå†…â€œä¸€å¼ºã€ä¸¤ä¸­ã€ä¸‰ç¨³ã€å¤šå¼±â€çš„æ ¼å±€ï¼Œå…¶ä¸­å°åº¦å°¼è¥¿äºš (Indonesia)ã€æ–°åŠ å¡ (Singapore) å’Œé©¬æ¥è¥¿äºš (Malaysia) é¢†è·‘ï¼Œæ³°å›½ (Thailand)ã€è²å¾‹å®¾ (Philippines) å’Œè¶Šå— (Vietnam) åˆ™å¤„äºä¸­å±‚ç«äº‰å¸¦ã€‚SAII v3 é€šè¿‡ Kendall's tau å’Œ 10,000 æ¬¡ Bootstrap è¿­ä»£éªŒè¯äº†æé«˜çš„ç¨³å¥æ€§ï¼Œä¸ºåŒºåŸŸæ”¿åºœçš„èµ„æºé…ç½®å’Œæ”¿ç­–åˆ¶å®šæä¾›äº†å¯å®¡è®¡ä¸”å…·è¡ŒåŠ¨åŠ›çš„å®šé‡è¯æ®ã€‚",
      "categories": [
        "physics.soc-ph",
        "cs.AI"
      ],
      "primary_category": "physics.soc-ph",
      "comment": "The document delivers a robust reproducible index (SAII v3) that advances quantitative IR methods and offers actionable insights into Southeast Asia's stratified power structure",
      "pdf_url": "https://arxiv.org/pdf/2509.19953v1",
      "published_date": "2025-09-24 10:01:02 UTC",
      "updated_date": "2025-09-24 10:01:02 UTC",
      "processing_status": "completed",
      "attempts": 1,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "llm_backup_calls": 0,
      "last_update": "2026-01-24T20:58:17.700528+00:00"
    },
    {
      "arxiv_id": "2509.19952v1",
      "title": "When Words Can't Capture It All: Towards Video-Based User Complaint Text Generation with Multimodal Video Complaint Dataset",
      "title_zh": "ä»…å‡­æ–‡å­—éš¾å°½å…¶è¯¦ï¼šåŸºäºå¤šæ¨¡æ€è§†é¢‘æŠ•è¯‰æ•°æ®é›†çš„è§†é¢‘åŒ–ç”¨æˆ·æŠ•è¯‰æ–‡æœ¬ç”Ÿæˆ",
      "authors": [
        "Sarmistha Das",
        "R E Zera Marveen Lyngkhoi",
        "Kirtan Jain",
        "Vinayak Goyal",
        "Sriparna Saha",
        "Manish Gupta"
      ],
      "abstract": "While there exists a lot of work on explainable complaint mining, articulating user concerns through text or video remains a significant challenge, often leaving issues unresolved. Users frequently struggle to express their complaints clearly in text but can easily upload videos depicting product defects (e.g., vague text such as `worst product' paired with a 5-second video depicting a broken headphone with the right earcup). This paper formulates a new task in the field of complaint mining to aid the common users' need to write an expressive complaint, which is Complaint Description from Videos (CoD-V) (e.g., to help the above user articulate her complaint about the defective right earcup). To this end, we introduce ComVID, a video complaint dataset containing 1,175 complaint videos and the corresponding descriptions, also annotated with the emotional state of the complainer. Additionally, we present a new complaint retention (CR) evaluation metric that discriminates the proposed (CoD-V) task against standard video summary generation and description tasks. To strengthen this initiative, we introduce a multimodal Retrieval-Augmented Generation (RAG) embedded VideoLLaMA2-7b model, designed to generate complaints while accounting for the user's emotional state. We conduct a comprehensive evaluation of several Video Language Models on several tasks (pre-trained and fine-tuned versions) with a range of established evaluation metrics, including METEOR, perplexity, and the Coleman-Liau readability score, among others. Our study lays the foundation for a new research direction to provide a platform for users to express complaints through video. Dataset and resources are available at: https://github.com/sarmistha-D/CoD-V.",
      "tldr_zh": "è¯¥ç ”ç©¶é’ˆå¯¹ç”¨æˆ·éš¾ä»¥é€šè¿‡æ–‡å­—æ¸…æ™°è¡¨è¾¾æŠ•è¯‰ä½†æ˜“äºå½•åˆ¶ç¼ºé™·è§†é¢‘çš„ç—›ç‚¹ï¼Œæå‡ºäº†ä»è§†é¢‘ç”ŸæˆæŠ•è¯‰æè¿°(Complaint Description from Videos, CoD-V)çš„æ–°ä»»åŠ¡ï¼Œæ—¨åœ¨è¾…åŠ©ç”¨æˆ·æ’°å†™æ›´å…·è¡¨è¾¾åŠ›çš„æŠ•è¯‰æ–‡æœ¬ã€‚ä½œè€…æ¨å‡ºäº†åŒ…å«1,175ä¸ªè§†é¢‘åŠå…¶æè¿°å’Œæƒ…æ„Ÿæ ‡æ³¨çš„æ•°æ®é›†ComVIDï¼Œå¹¶æå‡ºäº†æŠ•è¯‰ä¿ç•™(Complaint Retention, CR)æŒ‡æ ‡ä»¥åŒºåˆ†è¯¥ä»»åŠ¡ä¸ä¼ ç»Ÿè§†é¢‘æ‘˜è¦ã€‚ç ”ç©¶å¼•å…¥äº†åµŒå…¥å¤šæ¨¡æ€æ£€ç´¢å¢å¼ºç”Ÿæˆ(Retrieval-Augmented Generation, RAG)æŠ€æœ¯çš„VideoLLaMA2-7bæ¨¡å‹ï¼Œåœ¨ç”Ÿæˆè¿‡ç¨‹ä¸­å……åˆ†è€ƒè™‘äº†ç”¨æˆ·çš„å¿ƒç†æƒ…æ„Ÿã€‚é€šè¿‡åœ¨METEORã€å›°æƒ‘åº¦(Perplexity)å’ŒColeman-Liauå¯è¯»æ€§ç­‰æŒ‡æ ‡ä¸Šå¯¹å¤šç§è§†é¢‘è¯­è¨€æ¨¡å‹(Video Language Models)è¿›è¡Œå¯¹æ¯”è¯„ä¼°ï¼ŒéªŒè¯äº†è¯¥æ¡†æ¶çš„æœ‰æ•ˆæ€§ã€‚è¯¥å·¥ä½œä¸ºæŠ•è¯‰æŒ–æ˜(Complaint Mining)é¢†åŸŸå¼€è¾Ÿäº†åˆ©ç”¨å¤šæ¨¡æ€ä¿¡æ¯è¾…åŠ©ç”¨æˆ·ç»´æƒçš„æ–°æ–¹å‘ã€‚",
      "categories": [
        "cs.CV",
        "cs.AI"
      ],
      "primary_category": "cs.CV",
      "comment": "",
      "pdf_url": "https://arxiv.org/pdf/2509.19952v1",
      "published_date": "2025-09-24 10:00:05 UTC",
      "updated_date": "2025-09-24 10:00:05 UTC",
      "processing_status": "completed",
      "attempts": 1,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "llm_backup_calls": 0,
      "last_update": "2026-01-24T20:58:56.482755+00:00"
    },
    {
      "arxiv_id": "2509.19947v2",
      "title": "A Set of Generalized Components to Achieve Effective Poison-only Clean-label Backdoor Attacks with Collaborative Sample Selection and Triggers",
      "title_zh": "é¢å‘é«˜æ•ˆä»…ä¸­æ¯’æ¸…æ´æ ‡ç­¾åé—¨æ”»å‡»çš„æ ·æœ¬é€‰æ‹©ä¸è§¦å‘å™¨ååŒé€šç”¨ç»„ä»¶é›†",
      "authors": [
        "Zhixiao Wu",
        "Yao Lu",
        "Jie Wen",
        "Hao Sun",
        "Qi Zhou",
        "Guangming Lu"
      ],
      "abstract": "Poison-only Clean-label Backdoor Attacks aim to covertly inject attacker-desired behavior into DNNs by merely poisoning the dataset without changing the labels. To effectively implant a backdoor, multiple \\textbf{triggers} are proposed for various attack requirements of Attack Success Rate (ASR) and stealthiness. Additionally, sample selection enhances clean-label backdoor attacks' ASR by meticulously selecting ``hard'' samples instead of random samples to poison. Current methods 1) usually handle the sample selection and triggers in isolation, leading to severely limited improvements on both ASR and stealthiness. Consequently, attacks exhibit unsatisfactory performance on evaluation metrics when converted to PCBAs via a mere stacking of methods. Therefore, we seek to explore the bidirectional collaborative relations between the sample selection and triggers to address the above dilemma. 2) Since the strong specificity within triggers, the simple combination of sample selection and triggers fails to substantially enhance both evaluation metrics, with generalization preserved among various attacks. Therefore, we seek to propose a set of components to significantly improve both stealthiness and ASR based on the commonalities of attacks. Specifically, Component A ascertains two critical selection factors, and then makes them an appropriate combination based on the trigger scale to select more reasonable ``hard'' samples for improving ASR. Component B is proposed to select samples with similarities to relevant trigger implanted samples to promote stealthiness. Component C reassigns trigger poisoning intensity on RGB colors through distinct sensitivity of the human visual system to RGB for higher ASR, with stealthiness ensured by sample selection, including Component B. Furthermore, all components can be strategically integrated into diverse PCBAs.",
      "tldr_zh": "è¯¥ç ”ç©¶é’ˆå¯¹ä»…ä¸­æ¯’æ¸…æ´æ ‡ç­¾åé—¨æ”»å‡» (Poison-only Clean-label Backdoor Attacks, PCBAs) ä¸­æ ·æœ¬é€‰æ‹©ä¸è§¦å‘å™¨ (triggers) å¾€å¾€è¢«å­¤ç«‹å¤„ç†ã€å¯¼è‡´æ”»å‡»æˆåŠŸç‡ (ASR) ä¸éšè”½æ€§å—é™çš„é—®é¢˜ï¼Œæ¢ç´¢äº†ä¸¤è€…ä¹‹é—´çš„åŒå‘ååŒå…³ç³»ã€‚ä¸ºæ­¤ï¼Œè®ºæ–‡æå‡ºäº†ä¸€å¥—é€šç”¨çš„ç»„ä»¶åº“ï¼Œæ—¨åœ¨åˆ©ç”¨ä¸åŒæ”»å‡»çš„å…±åŒç‚¹æ¥ä¼˜åŒ–æ€§èƒ½ã€‚å…·ä½“è€Œè¨€ï¼Œç»„ä»¶ A é€šè¿‡ç»“åˆè§¦å‘å™¨è§„æ¨¡å’Œå…³é”®é€‰æ‹©å› å­æ¥ç­›é€‰æ›´åˆç†çš„â€œå›°éš¾â€æ ·æœ¬ä»¥æå‡ ASRï¼Œç»„ä»¶ B åˆ™é€šè¿‡é€‰æ‹©ä¸æ¤å…¥è§¦å‘å™¨åæ ·æœ¬å…·æœ‰ç›¸ä¼¼æ€§çš„åŸå§‹æ ·æœ¬æ¥å¢å¼ºéšè”½æ€§ã€‚ç»„ä»¶ C åˆ©ç”¨äººç±»è§†è§‰ç³»ç»Ÿå¯¹ RGB é¢œè‰²æ•æ„Ÿåº¦çš„å·®å¼‚é‡æ–°åˆ†é…ä¸­æ¯’å¼ºåº¦ï¼Œåœ¨ç¡®ä¿éšè”½æ€§çš„å‰æä¸‹è¿›ä¸€æ­¥ä¼˜åŒ– ASRã€‚å®éªŒè¡¨æ˜ï¼Œè¿™äº›ç»„ä»¶å¯ä»¥æˆ˜ç•¥æ€§åœ°æ•´åˆè¿›å¤šç§ PCBAs æ¡†æ¶ä¸­ï¼Œæ˜¾è‘—æ”¹å–„äº†æ”»å‡»çš„æ³›åŒ–èƒ½åŠ›å¹¶å®ç°äº†éšè”½æ€§å’Œæ”»å‡»æˆåŠŸç‡çš„åŒé‡æå‡ã€‚",
      "categories": [
        "cs.CR",
        "cs.AI"
      ],
      "primary_category": "cs.CR",
      "comment": "31 pages, 16 figures, accepted in Neurips 2025",
      "pdf_url": "https://arxiv.org/pdf/2509.19947v2",
      "published_date": "2025-09-24 09:58:31 UTC",
      "updated_date": "2025-10-07 09:40:48 UTC",
      "processing_status": "completed",
      "attempts": 1,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "llm_backup_calls": 0,
      "last_update": "2026-01-24T20:58:39.499083+00:00"
    },
    {
      "arxiv_id": "2509.19943v3",
      "title": "Interpreting ResNet-based CLIP via Neuron-Attention Decomposition",
      "title_zh": "é€šè¿‡ç¥ç»å…ƒ-æ³¨æ„åŠ›åˆ†è§£è¯ é‡ŠåŸºäº ResNet çš„ CLIP",
      "authors": [
        "Edmund Bu",
        "Yossi Gandelsman"
      ],
      "abstract": "We present a novel technique for interpreting the neurons in CLIP-ResNet by decomposing their contributions to the output into individual computation paths. More specifically, we analyze all pairwise combinations of neurons and the following attention heads of CLIP's attention-pooling layer. We find that these neuron-head pairs can be approximated by a single direction in CLIP-ResNet's image-text embedding space. Leveraging this insight, we interpret each neuron-head pair by associating it with text. Additionally, we find that only a sparse set of the neuron-head pairs have a significant contribution to the output value, and that some neuron-head pairs, while polysemantic, represent sub-concepts of their corresponding neurons. We use these observations for two applications. First, we employ the pairs for training-free semantic segmentation, outperforming previous methods for CLIP-ResNet. Second, we utilize the contributions of neuron-head pairs to monitor dataset distribution shifts. Our results demonstrate that examining individual computation paths in neural networks uncovers interpretable units, and that such units can be utilized for downstream tasks.",
      "tldr_zh": "è¯¥ç ”ç©¶æå‡ºäº†ä¸€ç§åä¸º Neuron-Attention Decomposition çš„æ–°æŠ€æœ¯ï¼Œæ—¨åœ¨é€šè¿‡å°†ç¥ç»å…ƒçš„è´¡çŒ®åˆ†è§£ä¸ºç‹¬ç«‹è®¡ç®—è·¯å¾„æ¥è§£é‡Š ResNet-based CLIPã€‚ç ”ç©¶è€…é€šè¿‡åˆ†æç¥ç»å…ƒä¸ CLIP æ³¨æ„åŠ›æ± åŒ–å±‚ä¸­ attention heads çš„æ‰€æœ‰ä¸¤ä¸¤ç»„åˆï¼Œå‘ç°è¿™äº› neuron-head pairs å¯ä»¥é€šè¿‡å›¾åƒ-æ–‡æœ¬åµŒå…¥ç©ºé—´ä¸­çš„å•ä¸€æ–¹å‘æ¥è¿‘ä¼¼è¡¨ç¤ºã€‚é€šè¿‡å°†è¿™äº› pairs ä¸æ–‡æœ¬å…³è”ï¼Œç ”ç©¶å‘ç°ä»…æœ‰æå°‘æ•°ç¨€ç–çš„ neuron-head pairs å¯¹è¾“å‡ºå…·æœ‰æ˜¾è‘—è´¡çŒ®ï¼Œä¸”éƒ¨åˆ† pairs èƒ½å¤Ÿä»£è¡¨å…¶å¯¹åº”ç¥ç»å…ƒçš„å­æ¦‚å¿µã€‚åŸºäºè¿™äº›å‘ç°ï¼Œè¯¥ç ”ç©¶æå‡ºäº†ä¸€ç§æ— éœ€è®­ç»ƒçš„ semantic segmentation æ–¹æ³•ï¼Œåœ¨ ResNet-based CLIP æ¨¡å‹ä¸Šè¡¨ç°ä¼˜äºå‰äººç ”ç©¶ã€‚æ­¤å¤–ï¼Œåˆ©ç”¨ neuron-head pairs çš„è´¡çŒ®ï¼Œç ”ç©¶è€…è¿˜å®ç°äº†å¯¹æ•°æ®é›†åˆ†å¸ƒåç§»çš„æœ‰æ•ˆç›‘æ§ã€‚è¯¥æˆæœè¯æ˜äº†æ·±å…¥æŒ–æ˜ç¥ç»ç½‘ç»œå†…éƒ¨è®¡ç®—è·¯å¾„å¯ä»¥æ­ç¤ºå…·æœ‰é«˜åº¦å¯è§£é‡Šæ€§çš„å•å…ƒï¼Œå¹¶èƒ½æœ‰æ•ˆæå‡ä¸‹æ¸¸ä»»åŠ¡çš„æ€§èƒ½ã€‚",
      "categories": [
        "cs.CV",
        "cs.AI"
      ],
      "primary_category": "cs.CV",
      "comment": "Accepted at NeurIPS 2025 Workshop on Mechanistic Interpretability. Project page: https://edmundbu.github.io/clip-neur-attn/",
      "pdf_url": "https://arxiv.org/pdf/2509.19943v3",
      "published_date": "2025-09-24 09:50:01 UTC",
      "updated_date": "2025-11-30 00:24:15 UTC",
      "processing_status": "completed",
      "attempts": 1,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "llm_backup_calls": 0,
      "last_update": "2026-01-24T20:58:48.097815+00:00"
    },
    {
      "arxiv_id": "2509.19941v1",
      "title": "CorIL: Towards Enriching Indian Language to Indian Language Parallel Corpora and Machine Translation Systems",
      "title_zh": "CorILï¼šè‡´åŠ›äºä¸°å¯Œå°åº¦è¯­ç§é—´å¹³è¡Œè¯­æ–™åº“ä¸æœºå™¨ç¿»è¯‘ç³»ç»Ÿ",
      "authors": [
        "Soham Bhattacharjee",
        "Mukund K Roy",
        "Yathish Poojary",
        "Bhargav Dave",
        "Mihir Raj",
        "Vandan Mujadia",
        "Baban Gain",
        "Pruthwik Mishra",
        "Arafat Ahsan",
        "Parameswari Krishnamurthy",
        "Ashwath Rao",
        "Gurpreet Singh Josan",
        "Preeti Dubey",
        "Aadil Amin Kak",
        "Anna Rao Kulkarni",
        "Narendra VG",
        "Sunita Arora",
        "Rakesh Balbantray",
        "Prasenjit Majumdar",
        "Karunesh K Arora",
        "Asif Ekbal",
        "Dipti Mishra Sharma"
      ],
      "abstract": "India's linguistic landscape is one of the most diverse in the world, comprising over 120 major languages and approximately 1,600 additional languages, with 22 officially recognized as scheduled languages in the Indian Constitution. Despite recent progress in multilingual neural machine translation (NMT), high-quality parallel corpora for Indian languages remain scarce, especially across varied domains. In this paper, we introduce a large-scale, high-quality annotated parallel corpus covering 11 of these languages : English, Telugu, Hindi, Punjabi, Odia, Kashmiri, Sindhi, Dogri, Kannada, Urdu, and Gujarati comprising a total of 772,000 bi-text sentence pairs. The dataset is carefully curated and systematically categorized into three key domains: Government, Health, and General, to enable domain-aware machine translation research and facilitate effective domain adaptation. To demonstrate the utility of CorIL and establish strong benchmarks for future research, we fine-tune and evaluate several state-of-the-art NMT models, including IndicTrans2, NLLB, and BhashaVerse. Our analysis reveals important performance trends and highlights the corpus's value in probing model capabilities. For instance, the results show distinct performance patterns based on language script, with massively multilingual models showing an advantage on Perso-Arabic scripts (Urdu, Sindhi) while other models excel on Indic scripts. This paper provides a detailed domain-wise performance analysis, offering insights into domain sensitivity and cross-script transfer learning. By publicly releasing CorIL, we aim to significantly improve the availability of high-quality training data for Indian languages and provide a valuable resource for the machine translation research community.",
      "tldr_zh": "è¯¥ç ”ç©¶é’ˆå¯¹å°åº¦è¯­è¨€é«˜è´¨é‡å¹³è¡Œè¯­æ–™åº“ç¨€ç¼ºçš„ç°çŠ¶ï¼Œæ¨å‡ºäº†CorILï¼Œä¸€ä¸ªæ¶µç›–11ç§è¯­è¨€ã€åŒ…å«772,000ä¸ªåŒè¯­æ–‡æœ¬å¯¹çš„å¤§è§„æ¨¡é«˜è´¨é‡æ ‡æ³¨å¹³è¡Œè¯­æ–™åº“ã€‚æ•°æ®é›†è¢«ç»†è‡´åœ°åˆ’åˆ†ä¸ºæ”¿åºœ(Government)ã€åŒ»ç–—(Health)å’Œé€šç”¨(General)ä¸‰ä¸ªé¢†åŸŸï¼Œä»¥æ”¯æŒé¢†åŸŸæ„ŸçŸ¥çš„æœºå™¨ç¿»è¯‘(Machine Translation)ç ”ç©¶å’Œé¢†åŸŸè‡ªé€‚åº”ã€‚ç ”ç©¶äººå‘˜é€šè¿‡å¾®è°ƒIndicTrans2ã€NLLBå’ŒBhashaVerseç­‰ä¸»æµç¥ç»æœºå™¨ç¿»è¯‘(NMT)æ¨¡å‹å»ºç«‹äº†åŸºå‡†ï¼Œå¹¶å‘ç°å¤§è§„æ¨¡å¤šè¯­è¨€æ¨¡å‹åœ¨å¤„ç†æ³¢æ–¯-é˜¿æ‹‰ä¼¯è„šæœ¬(Perso-Arabic scripts)æ—¶è¡¨ç°å‡ºæ˜¾è‘—ä¼˜åŠ¿ï¼Œè€Œå…¶ä»–æ¨¡å‹åœ¨å°åº¦è„šæœ¬(Indic scripts)ä¸Šè¡¨ç°æ›´ä½³ã€‚æ­¤å¤–ï¼Œè®ºæ–‡æä¾›äº†è¯¦å°½çš„é¢†åŸŸæ€§èƒ½åˆ†æï¼Œæ­ç¤ºäº†é¢†åŸŸæ•æ„Ÿæ€§å’Œè·¨è„šæœ¬è¿ç§»å­¦ä¹ çš„ç‰¹å¾ã€‚CorILçš„å…¬å¼€å‘å¸ƒæå¤§åœ°ä¸°å¯Œäº†å°åº¦è¯­è¨€çš„è®­ç»ƒèµ„æºï¼Œä¸ºå¤šè¯­è¨€ç¿»è¯‘ç³»ç»Ÿçš„å¼€å‘å’Œè¯„ä¼°å¥ å®šäº†åšå®åŸºç¡€ã€‚",
      "categories": [
        "cs.CL",
        "cs.AI"
      ],
      "primary_category": "cs.CL",
      "comment": "",
      "pdf_url": "https://arxiv.org/pdf/2509.19941v1",
      "published_date": "2025-09-24 09:48:26 UTC",
      "updated_date": "2025-09-24 09:48:26 UTC",
      "processing_status": "completed",
      "attempts": 1,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "llm_backup_calls": 0,
      "last_update": "2026-01-24T20:58:51.089039+00:00"
    },
    {
      "arxiv_id": "2509.19939v1",
      "title": "AJAHR: Amputated Joint Aware 3D Human Mesh Recovery",
      "title_zh": "AJAHRï¼šæˆªæ–­å…³èŠ‚æ„ŸçŸ¥çš„ä¸‰ç»´äººä½“ç½‘æ ¼æ¢å¤",
      "authors": [
        "Hyunjin Cho",
        "Giyun Choi",
        "Jongwon Choi"
      ],
      "abstract": "Existing human mesh recovery methods assume a standard human body structure, overlooking diverse anatomical conditions such as limb loss. This assumption introduces bias when applied to individuals with amputations - a limitation further exacerbated by the scarcity of suitable datasets. To address this gap, we propose Amputated Joint Aware 3D Human Mesh Recovery (AJAHR), which is an adaptive pose estimation framework that improves mesh reconstruction for individuals with limb loss. Our model integrates a body-part amputation classifier, jointly trained with the mesh recovery network, to detect potential amputations. We also introduce Amputee 3D (A3D), which is a synthetic dataset offering a wide range of amputee poses for robust training. While maintaining competitive performance on non-amputees, our approach achieves state-of-the-art results for amputated individuals. Additional materials can be found at the project webpage.",
      "tldr_zh": "è¯¥ç ”ç©¶é’ˆå¯¹ç°æœ‰çš„äººä½“ç½‘æ ¼æ¢å¤ (human mesh recovery) æ–¹æ³•å‡è®¾æ ‡å‡†äººä½“ç»“æ„è€Œå¿½ç•¥è‚¢ä½“ç¼ºå¤±ç­‰è§£å‰–å·®å¼‚çš„é—®é¢˜ï¼Œæå‡ºäº† AJAHR (Amputated Joint Aware 3D Human Mesh Recovery) è‡ªé€‚åº”å§¿æ€ä¼°è®¡æ¡†æ¶ã€‚è¯¥æ¡†æ¶é›†æˆäº†ä¸€ä¸ªè‚¢ä½“ç¼ºå¤±åˆ†ç±»å™¨ (body-part amputation classifier)ï¼Œé€šè¿‡ä¸ç½‘æ ¼æ¢å¤ç½‘ç»œè”åˆè®­ç»ƒæ¥ç²¾å‡†æ£€æµ‹æ½œåœ¨çš„æˆªè‚¢éƒ¨ä½ã€‚ä¸ºäº†è§£å†³ç›¸å…³æ•°æ®ç¨€ç¼ºçš„éš¾é¢˜ï¼Œç ”ç©¶è€…è¿˜å¼•å…¥äº† A3D (Amputee 3D) åˆæˆæ•°æ®é›†ï¼Œä¸ºæ¨¡å‹è®­ç»ƒæä¾›å¤šæ ·åŒ–çš„æ®‹ç–¾äººå§¿æ€æ ·æœ¬ã€‚å®éªŒç»“æœè¡¨æ˜ï¼ŒAJAHR åœ¨ä¿æŒå¯¹éæˆªè‚¢ä¸ªä½“æ¢å¤æ€§èƒ½ç«äº‰åŠ›çš„åŒæ—¶ï¼Œåœ¨å¤„ç†è‚¢ä½“ç¼ºå¤±ä¸ªä½“æ–¹é¢è¾¾åˆ°äº† state-of-the-art æ°´å¹³ï¼Œæ˜¾è‘—æå‡äº†ä¸‰ç»´äººä½“å»ºæ¨¡çš„åŒ…å®¹æ€§ä¸å‡†ç¡®æ€§ã€‚è¿™ä¸€æ–¹æ³•ä¸ºè§£å†³ç‰¹å®šè§£å‰–æ¡ä»¶ä¸‹çš„äººä½“ä¸‰ç»´é‡å»ºæŒ‘æˆ˜æä¾›äº†æœ‰æ•ˆçš„æŠ€æœ¯è·¯å¾„ã€‚",
      "categories": [
        "cs.GR",
        "cs.AI",
        "cs.CV"
      ],
      "primary_category": "cs.GR",
      "comment": "8pages, Project Page: https://chojinie.github.io/project_AJAHR/",
      "pdf_url": "https://arxiv.org/pdf/2509.19939v1",
      "published_date": "2025-09-24 09:46:10 UTC",
      "updated_date": "2025-09-24 09:46:10 UTC",
      "processing_status": "completed",
      "attempts": 1,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "llm_backup_calls": 0,
      "last_update": "2026-01-24T20:58:52.087826+00:00"
    },
    {
      "arxiv_id": "2509.19927v1",
      "title": "TABFAIRGDT: A Fast Fair Tabular Data Generator using Autoregressive Decision Trees",
      "title_zh": "TABFAIRGDTï¼šåŸºäºè‡ªå›å½’å†³ç­–æ ‘çš„å¿«é€Ÿå…¬å¹³è¡¨æ ¼æ•°æ®ç”Ÿæˆå™¨",
      "authors": [
        "Emmanouil Panagiotou",
        "BenoÃ®t Ronval",
        "Arjun Roy",
        "Ludwig Bothmann",
        "Bernd Bischl",
        "Siegfried Nijssen",
        "Eirini Ntoutsi"
      ],
      "abstract": "Ensuring fairness in machine learning remains a significant challenge, as models often inherit biases from their training data. Generative models have recently emerged as a promising approach to mitigate bias at the data level while preserving utility. However, many rely on deep architectures, despite evidence that simpler models can be highly effective for tabular data. In this work, we introduce TABFAIRGDT, a novel method for generating fair synthetic tabular data using autoregressive decision trees. To enforce fairness, we propose a soft leaf resampling technique that adjusts decision tree outputs to reduce bias while preserving predictive performance. Our approach is non-parametric, effectively capturing complex relationships between mixed feature types, without relying on assumptions about the underlying data distributions. We evaluate TABFAIRGDT on benchmark fairness datasets and demonstrate that it outperforms state-of-the-art (SOTA) deep generative models, achieving better fairness-utility trade-off for downstream tasks, as well as higher synthetic data quality. Moreover, our method is lightweight, highly efficient, and CPU-compatible, requiring no data pre-processing. Remarkably, TABFAIRGDT achieves a 72% average speedup over the fastest SOTA baseline across various dataset sizes, and can generate fair synthetic data for medium-sized datasets (10 features, 10K samples) in just one second on a standard CPU, making it an ideal solution for real-world fairness-sensitive applications.",
      "tldr_zh": "è¯¥ç ”ç©¶æå‡ºäº†TABFAIRGDTï¼Œè¿™æ˜¯ä¸€ç§åˆ©ç”¨autoregressive decision treesç”Ÿæˆå…¬å¹³åˆæˆè¡¨æ ¼æ•°æ®çš„å¿«é€Ÿæ–¹æ³•ã€‚ä¸ºäº†å®ç°å…¬å¹³æ€§ï¼Œè¯¥æ–¹æ³•å¼•å…¥äº†soft leaf resamplingæŠ€æœ¯ï¼Œé€šè¿‡è°ƒæ•´å†³ç­–æ ‘è¾“å‡ºæ¥å‡å°‘åè§ï¼ŒåŒæ—¶ä¿ç•™é¢„æµ‹æ€§èƒ½ã€‚ä½œä¸ºä¸€ç§non-parametricæ–¹æ³•ï¼Œå®ƒèƒ½æœ‰æ•ˆæ•æ‰æ··åˆç‰¹å¾ç±»å‹ä¹‹é—´çš„å¤æ‚å…³ç³»ï¼Œä¸”æ— éœ€å¯¹åº•å±‚æ•°æ®åˆ†å¸ƒåšå‡è®¾æˆ–è¿›è¡Œæ•°æ®é¢„å¤„ç†(data pre-processing)ã€‚å®éªŒç»“æœè¡¨æ˜ï¼ŒTABFAIRGDTåœ¨å…¬å¹³æ€§-æ•ˆç”¨å¹³è¡¡(fairness-utility trade-off)å’Œåˆæˆæ•°æ®è´¨é‡æ–¹é¢å‡ä¼˜äºç°æœ‰çš„æ·±åº¦ç”Ÿæˆæ¨¡å‹(SOTA deep generative models)ã€‚æ­¤å¤–ï¼Œè¯¥æ–¹æ³•å…·æœ‰æé«˜çš„æ•ˆç‡å’ŒCPUå…¼å®¹æ€§ï¼Œç›¸æ¯”æœ€å¿«çš„SOTAåŸºå‡†æ¨¡å‹å¹³å‡æé€Ÿ72%ã€‚TABFAIRGDTèƒ½å¤Ÿåœ¨æ ‡å‡†CPUä¸Šä»…ç”¨ä¸€ç§’é’Ÿä¸ºä¸­ç­‰è§„æ¨¡æ•°æ®é›†ç”Ÿæˆå…¬å¹³æ•°æ®ï¼Œä¸ºç°å®ä¸–ç•Œä¸­å¯¹å…¬å¹³æ€§æ•æ„Ÿçš„åº”ç”¨æä¾›äº†ç†æƒ³çš„è½»é‡çº§è§£å†³æ–¹æ¡ˆã€‚",
      "categories": [
        "cs.LG",
        "cs.AI"
      ],
      "primary_category": "cs.LG",
      "comment": "Paper accepted at IEEE ICDM 2025: IEEE International Conference on Data Mining 2025, November 12-15, 2025, Washington DC, USA",
      "pdf_url": "https://arxiv.org/pdf/2509.19927v1",
      "published_date": "2025-09-24 09:35:52 UTC",
      "updated_date": "2025-09-24 09:35:52 UTC",
      "processing_status": "completed",
      "attempts": 1,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "llm_backup_calls": 0,
      "last_update": "2026-01-24T20:59:06.587850+00:00"
    },
    {
      "arxiv_id": "2509.19925v1",
      "title": "CON-QA: Privacy-Preserving QA using cloud LLMs in Contract Domain",
      "title_zh": "CON-QAï¼šé¢å‘åˆåŒé¢†åŸŸçš„äº‘ç«¯å¤§è¯­è¨€æ¨¡å‹éšç§ä¿æŠ¤é—®ç­”",
      "authors": [
        "Ajeet Kumar Singh",
        "Rajsabi Surya",
        "Anurag Tripathi",
        "Santanu Choudhury",
        "Sudhir Bisane"
      ],
      "abstract": "As enterprises increasingly integrate cloud-based large language models (LLMs) such as ChatGPT and Gemini into their legal document workflows, protecting sensitive contractual information - including Personally Identifiable Information (PII) and commercially sensitive clauses - has emerged as a critical challenge. In this work, we propose CON-QA, a hybrid privacy-preserving framework designed specifically for secure question answering over enterprise contracts, effectively combining local and cloud-hosted LLMs. The CON-QA framework operates through three stages: (i) semantic query decomposition and query-aware document chunk retrieval using a locally deployed LLM analysis, (ii) anonymization of detected sensitive entities via a structured one-to-many mapping scheme, ensuring semantic coherence while preventing cross-session entity inference attacks, and (iii) anonymized response generation by a cloud-based LLM, with accurate reconstruction of the original answer locally using a session-consistent many-to-one reverse mapping. To rigorously evaluate CON-QA, we introduce CUAD-QA, a corpus of 85k question-answer pairs generated over 510 real-world CUAD contract documents, encompassing simple, complex, and summarization-style queries. Empirical evaluations, complemented by detailed human assessments, confirm that CON-QA effectively maintains both privacy and utility, preserves answer quality, maintains fidelity to legal clause semantics, and significantly mitigates privacy risks, demonstrating its practical suitability for secure, enterprise-level contract documents.",
      "tldr_zh": "è¯¥ç ”ç©¶é’ˆå¯¹ä¼ä¸šåˆ©ç”¨äº‘ç«¯å¤§è¯­è¨€æ¨¡å‹(LLMs)å¤„ç†æ³•å¾‹æ–‡æ¡£æ—¶é¢ä¸´çš„éšç§ä¿æŠ¤æŒ‘æˆ˜ï¼Œæå‡ºäº†åä¸ºCON-QAçš„æ··åˆéšç§ä¿æŠ¤æ¡†æ¶ã€‚CON-QAé€šè¿‡æ•´åˆæœ¬åœ°å’Œäº‘ç«¯LLMsï¼Œåˆ†ä¸ºæœ¬åœ°è¯­ä¹‰æŸ¥è¯¢åˆ†è§£ä¸æ£€ç´¢ã€åŸºäºä¸€å¯¹å¤šæ˜ å°„æ–¹æ¡ˆçš„æ•æ„Ÿå®ä½“åŒ¿ååŒ–ï¼Œä»¥åŠäº‘ç«¯åŒ¿åå“åº”ç”Ÿæˆä¸æœ¬åœ°åå‘æ˜ å°„è¿˜åŸä¸‰ä¸ªæ ¸å¿ƒé˜¶æ®µã€‚è¿™ç§æœºåˆ¶åœ¨é˜²æ­¢è·¨ä¼šè¯å®ä½“æ¨ç†æ”»å‡»çš„åŒæ—¶ï¼Œç¡®ä¿äº†æ³•å¾‹æ–‡æœ¬è¯­ä¹‰çš„è¿è´¯æ€§ã€‚æ­¤å¤–ï¼Œç ”ç©¶è€…åŸºäº510ä»½çœŸå®çš„CUADåˆçº¦æ–‡æ¡£æ„å»ºäº†åŒ…å«8.5ä¸‡ä¸ªé—®ç­”å¯¹çš„CUAD-QAæ•°æ®é›†ç”¨äºè¯„ä¼°ã€‚å®éªŒç»“æœå’Œäººå·¥è¯„æµ‹è¯å®ï¼ŒCON-QAåœ¨ç»´æŒé«˜è´¨é‡ç­”æ¡ˆå’Œæ³•å¾‹æ¡æ¬¾è¯­ä¹‰ä¿çœŸåº¦çš„å‰æä¸‹ï¼Œæ˜¾è‘—é™ä½äº†éšç§é£é™©ã€‚è¯¥æ¡†æ¶å±•ç°äº†åœ¨å¤„ç†ä¼ä¸šçº§æ•æ„Ÿåˆçº¦æ–‡æ¡£æ–¹é¢çš„å®ç”¨æ€§ä¸å®‰å…¨æ€§ã€‚",
      "categories": [
        "cs.AI"
      ],
      "primary_category": "cs.AI",
      "comment": "",
      "pdf_url": "https://arxiv.org/pdf/2509.19925v1",
      "published_date": "2025-09-24 09:29:17 UTC",
      "updated_date": "2025-09-24 09:29:17 UTC",
      "processing_status": "completed",
      "attempts": 1,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "llm_backup_calls": 0,
      "last_update": "2026-01-24T20:59:14.491058+00:00"
    },
    {
      "arxiv_id": "2509.19924v1",
      "title": "Exploration with Foundation Models: Capabilities, Limitations, and Hybrid Approaches",
      "title_zh": "åŸºäºåŸºç¡€æ¨¡å‹çš„æ¢ç´¢ï¼šèƒ½åŠ›ã€å±€é™æ€§åŠæ··åˆæ–¹æ³•",
      "authors": [
        "Remo Sasso",
        "Michelangelo Conserva",
        "Dominik Jeurissen",
        "Paulo Rauber"
      ],
      "abstract": "Exploration in reinforcement learning (RL) remains challenging, particularly in sparse-reward settings. While foundation models possess strong semantic priors, their capabilities as zero-shot exploration agents in classic RL benchmarks are not well understood. We benchmark LLMs and VLMs on multi-armed bandits, Gridworlds, and sparse-reward Atari to test zero-shot exploration. Our investigation reveals a key limitation: while VLMs can infer high-level objectives from visual input, they consistently fail at precise low-level control: the \"knowing-doing gap\". To analyze a potential bridge for this gap, we investigate a simple on-policy hybrid framework in a controlled, best-case scenario. Our results in this idealized setting show that VLM guidance can significantly improve early-stage sample efficiency, providing a clear analysis of the potential and constraints of using foundation models to guide exploration rather than for end-to-end control.",
      "tldr_zh": "è¯¥ç ”ç©¶æ¢è®¨äº†åŸºç¡€æ¨¡å‹(Foundation Models)åœ¨å¼ºåŒ–å­¦ä¹ (RL)æ¢ç´¢ä»»åŠ¡ä¸­çš„èƒ½åŠ›ä¸å±€é™æ€§ï¼Œç‰¹åˆ«æ˜¯åœ¨ç¨€ç–å¥–åŠ±ç¯å¢ƒä¸‹çš„è¡¨ç°ã€‚é€šè¿‡åœ¨å¤šè‡‚è€è™æœº(multi-armed bandits)ã€Gridworldså’Œç¨€ç–å¥–åŠ±çš„Atariæ¸¸æˆä¸Šå¯¹LLMså’ŒVLMsè¿›è¡ŒåŸºå‡†æµ‹è¯•ï¼Œç ”ç©¶æ­ç¤ºäº†è§†è§‰è¯­è¨€æ¨¡å‹(VLMs)å­˜åœ¨â€œçŸ¥è¡Œå·®è·â€(knowing-doing gap)ï¼Œå³è™½ç„¶èƒ½ä»è§†è§‰è¾“å…¥ä¸­æ¨æ–­é«˜å±‚ç›®æ ‡ï¼Œä½†å§‹ç»ˆæ— æ³•å®ç°ç²¾ç¡®çš„åº•å±‚æ§åˆ¶ã€‚ä¸ºè§£å†³è¿™ä¸€é—®é¢˜ï¼Œç ”ç©¶è°ƒæŸ¥äº†ä¸€ç§æ··åˆæ¡†æ¶ï¼Œåˆ©ç”¨VLMæä¾›å¼•å¯¼è€Œéè¿›è¡Œç«¯åˆ°ç«¯æ§åˆ¶ã€‚å®éªŒç»“æœè¡¨æ˜ï¼Œåœ¨ç†æƒ³è®¾ç½®ä¸‹ï¼ŒVLMå¼•å¯¼èƒ½æ˜¾è‘—æå‡å­¦ä¹ æ—©æœŸçš„æ ·æœ¬æ•ˆç‡(sample efficiency)ï¼Œä¸ºå¦‚ä½•åˆ©ç”¨åŸºç¡€æ¨¡å‹æŒ‡å¯¼æ¢ç´¢æä¾›äº†é‡è¦çš„ç†è®ºåˆ†æä¸å®è·µå‚è€ƒã€‚",
      "categories": [
        "cs.LG",
        "cs.AI"
      ],
      "primary_category": "cs.LG",
      "comment": "16 pages, 7 figures. Accepted for presentation at the 39th Conference on Neural Information Processing Systems (NeurIPS 2025) Workshop on the Foundations of Reasoning in Language Models (FoRLM)",
      "pdf_url": "https://arxiv.org/pdf/2509.19924v1",
      "published_date": "2025-09-24 09:25:15 UTC",
      "updated_date": "2025-09-24 09:25:15 UTC",
      "processing_status": "completed",
      "attempts": 1,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "llm_backup_calls": 0,
      "last_update": "2026-01-24T20:59:09.794974+00:00"
    },
    {
      "arxiv_id": "2510.01247v1",
      "title": "Let's Play Across Cultures: A Large Multilingual, Multicultural Benchmark for Assessing Language Models' Understanding of Sports",
      "title_zh": "è·¨æ–‡åŒ–ç«æŠ€ï¼šç”¨äºè¯„ä¼°è¯­è¨€æ¨¡å‹ä½“è‚²ç†è§£èƒ½åŠ›çš„å¤§è§„æ¨¡å¤šè¯­è¨€å¤šæ–‡åŒ–åŸºå‡†",
      "authors": [
        "Punit Kumar Singh",
        "Nishant Kumar",
        "Akash Ghosh",
        "Kunal Pasad",
        "Khushi Soni",
        "Manisha Jaishwal",
        "Sriparna Saha",
        "Syukron Abu Ishaq Alfarozi",
        "Asres Temam Abagissa",
        "Kitsuchart Pasupa",
        "Haiqin Yang",
        "Jose G Moreno"
      ],
      "abstract": "Language Models (LMs) are primarily evaluated on globally popular sports, often overlooking regional and indigenous sporting traditions. To address this gap, we introduce \\textbf{\\textit{CultSportQA}}, a benchmark designed to assess LMs' understanding of traditional sports across 60 countries and 6 continents, encompassing four distinct cultural categories. The dataset features 33,000 multiple-choice questions (MCQs) across text and image modalities, each of which is categorized into three key types: history-based, rule-based, and scenario-based. To evaluate model performance, we employ zero-shot, few-shot, and chain-of-thought (CoT) prompting across a diverse set of Large Language Models (LLMs), Small Language Models (SLMs), and Multimodal Large Language Models (MLMs). By providing a comprehensive multilingual and multicultural sports benchmark, \\textbf{\\textit{CultSportQA}} establishes a new standard for assessing AI's ability to understand and reason about traditional sports.",
      "tldr_zh": "è¯¥ç ”ç©¶æ¨å‡ºäº†CultSportQAï¼Œè¿™æ˜¯ä¸€ä¸ªæ—¨åœ¨è¯„ä¼°è¯­è¨€æ¨¡å‹(Language Models, LMs)å¯¹å…¨çƒä¼ ç»Ÿä½“è‚²é¡¹ç›®ç†è§£èƒ½åŠ›çš„è·¨è¯­è¨€ã€è·¨æ–‡åŒ–åŸºå‡†æµ‹è¯•ã€‚é’ˆå¯¹ç°æœ‰æ¨¡å‹å¾€å¾€å¿½è§†åŒºåŸŸæ€§å’Œæœ¬åœŸä½“è‚²ä¼ ç»Ÿçš„é—®é¢˜ï¼Œè¯¥åŸºå‡†æ¶µç›–äº†æ¥è‡ª60ä¸ªå›½å®¶å’Œ6å¤§æ´²çš„4ä¸ªä¸åŒæ–‡åŒ–ç±»åˆ«ã€‚è¯¥æ•°æ®é›†åŒ…å«33,000é“ç»“åˆæ–‡æœ¬å’Œå›¾åƒæ¨¡æ€çš„å¤šé¡¹é€‰æ‹©é¢˜(MCQs)ï¼Œå¹¶ç»†åˆ†ä¸ºå†å²ç±»(history-based)ã€è§„åˆ™ç±»(rule-based)å’Œåœºæ™¯ç±»(scenario-based)ä¸‰ç§ç±»å‹ã€‚ç ”ç©¶è€…é€šè¿‡é›¶æ ·æœ¬(zero-shot)ã€å°‘æ ·æœ¬(few-shot)å’Œé“¾å¼æ€ç»´(Chain-of-Thought, CoT)æç¤ºï¼Œå¯¹å¤§è¯­è¨€æ¨¡å‹(LLMs)ã€å°è¯­è¨€æ¨¡å‹(SLMs)åŠå¤šæ¨¡æ€å¤§è¯­è¨€æ¨¡å‹(MLMs)çš„è¡¨ç°è¿›è¡Œäº†è¯„ä¼°ã€‚ä½œä¸ºä¸€é¡¹å…¨é¢çš„å¤šè¯­è¨€ã€å¤šæ–‡åŒ–ä½“è‚²åŸºå‡†ï¼ŒCultSportQAä¸ºè¡¡é‡äººå·¥æ™ºèƒ½ç†è§£å’Œæ¨ç†ä¼ ç»Ÿä½“è‚²æ–‡åŒ–çš„èƒ½åŠ›æ ‘ç«‹äº†å…¨æ–°æ ‡å‡†ã€‚",
      "categories": [
        "cs.CL",
        "cs.AI"
      ],
      "primary_category": "cs.CL",
      "comment": "52 pages, 56 figures; appearing at EMNLP'25",
      "pdf_url": "https://arxiv.org/pdf/2510.01247v1",
      "published_date": "2025-09-24 09:06:36 UTC",
      "updated_date": "2025-09-24 09:06:36 UTC",
      "processing_status": "completed",
      "attempts": 1,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "llm_backup_calls": 0,
      "last_update": "2026-01-24T20:59:19.791152+00:00"
    },
    {
      "arxiv_id": "2509.19885v1",
      "title": "Towards Self-Supervised Foundation Models for Critical Care Time Series",
      "title_zh": "è¿ˆå‘é‡ç—‡ç›‘æŠ¤æ—¶é—´åºåˆ—çš„è‡ªç›‘ç£åŸºç¡€æ¨¡å‹",
      "authors": [
        "Katja Naasunnguaq Jagd",
        "Rachael DeVries",
        "Ole Winther"
      ],
      "abstract": "Domain-specific foundation models for healthcare have expanded rapidly in recent years, yet foundation models for critical care time series remain relatively underexplored due to the limited size and availability of datasets. In this work, we introduce an early-stage pre-trained foundation model for critical care time-series based on the Bi-Axial Transformer (BAT), trained on pooled electronic health record datasets. We demonstrate effective transfer learning by fine-tuning the model on a dataset distinct from the training sources for mortality prediction, where it outperforms supervised baselines, particularly for small datasets ($<5,000$). These contributions highlight the potential of self-supervised foundation models for critical care times series to support generalizable and robust clinical applications in resource-limited settings.",
      "tldr_zh": "è¯¥ç ”ç©¶é’ˆå¯¹é‡ç—‡ç›‘æŠ¤æ—¶é—´åºåˆ—(Critical Care Time Series)é¢†åŸŸå› æ•°æ®é›†è§„æ¨¡å’Œå¯ç”¨æ€§é™åˆ¶è€Œå¯¼è‡´çš„åŸºç¡€æ¨¡å‹ç ”ç©¶ä¸è¶³é—®é¢˜ï¼Œæå‡ºäº†ä¸€ä¸ªåŸºäºBi-Axial Transformer (BAT)æ¶æ„çš„æ—©æœŸé¢„è®­ç»ƒè‡ªç›‘ç£åŸºç¡€æ¨¡å‹(Self-Supervised Foundation Models)ã€‚ç ”ç©¶å›¢é˜Ÿé€šè¿‡æ•´åˆå¤šä¸ªç”µå­å¥åº·è®°å½•(EHR)æ•°æ®é›†å¯¹æ¨¡å‹è¿›è¡Œé¢„è®­ç»ƒï¼Œå¹¶åœ¨ä¸€é¡¹ç‹¬ç«‹çš„æ­»äº¡ç‡é¢„æµ‹ä»»åŠ¡ä¸­éªŒè¯äº†å…¶è¿ç§»å­¦ä¹ çš„æ•ˆæœã€‚å®éªŒç»“æœæ˜¾ç¤ºï¼Œè¯¥æ¨¡å‹åœ¨æ€§èƒ½ä¸Šä¼˜äºä¼ ç»Ÿçš„ç›‘ç£å­¦ä¹ åŸºçº¿(Supervised Baselines)ï¼Œå°¤å…¶æ˜¯åœ¨æ ·æœ¬é‡å°‘äº5000çš„å°è§„æ¨¡æ•°æ®é›†ä¸Šè¡¨ç°æ›´ä¸ºå“è¶Šã€‚è¿™äº›è´¡çŒ®å‡¸æ˜¾äº†è‡ªç›‘ç£åŸºç¡€æ¨¡å‹åœ¨èµ„æºå—é™çš„ä¸´åºŠç¯å¢ƒä¸­æ„å»ºæ³›åŒ–ä¸”ç¨³å¥çš„åŒ»ç–—åº”ç”¨çš„æ½œåŠ›ã€‚",
      "categories": [
        "cs.LG",
        "cs.AI"
      ],
      "primary_category": "cs.LG",
      "comment": "Accepted to NeurIPS 2025 workshop Learning from Time Series for Health (TS4H)",
      "pdf_url": "https://arxiv.org/pdf/2509.19885v1",
      "published_date": "2025-09-24 08:34:46 UTC",
      "updated_date": "2025-09-24 08:34:46 UTC",
      "processing_status": "completed",
      "attempts": 1,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "llm_backup_calls": 0,
      "last_update": "2026-01-24T21:00:11.095700+00:00"
    },
    {
      "arxiv_id": "2509.19883v1",
      "title": "CoMelSinger: Discrete Token-Based Zero-Shot Singing Synthesis With Structured Melody Control and Guidance",
      "title_zh": "CoMelSingerï¼šå…·æœ‰ç»“æ„åŒ–æ—‹å¾‹æ§åˆ¶ä¸å¼•å¯¼çš„ç¦»æ•£ Token é›¶æ ·æœ¬æ­Œå£°åˆæˆ",
      "authors": [
        "Junchuan Zhao",
        "Wei Zeng",
        "Tianle Lyu",
        "Ye Wang"
      ],
      "abstract": "Singing Voice Synthesis (SVS) aims to generate expressive vocal performances from structured musical inputs such as lyrics and pitch sequences. While recent progress in discrete codec-based speech synthesis has enabled zero-shot generation via in-context learning, directly extending these techniques to SVS remains non-trivial due to the requirement for precise melody control. In particular, prompt-based generation often introduces prosody leakage, where pitch information is inadvertently entangled within the timbre prompt, compromising controllability. We present CoMelSinger, a zero-shot SVS framework that enables structured and disentangled melody control within a discrete codec modeling paradigm. Built on the non-autoregressive MaskGCT architecture, CoMelSinger replaces conventional text inputs with lyric and pitch tokens, preserving in-context generalization while enhancing melody conditioning. To suppress prosody leakage, we propose a coarse-to-fine contrastive learning strategy that explicitly regularizes pitch redundancy between the acoustic prompt and melody input. Furthermore, we incorporate a lightweight encoder-only Singing Voice Transcription (SVT) module to align acoustic tokens with pitch and duration, offering fine-grained frame-level supervision. Experimental results demonstrate that CoMelSinger achieves notable improvements in pitch accuracy, timbre consistency, and zero-shot transferability over competitive baselines.",
      "tldr_zh": "è¯¥ç ”ç©¶æå‡ºäº† CoMelSingerï¼Œè¿™æ˜¯ä¸€ä¸ªåœ¨ç¦»æ•£ç¼–è§£ç å™¨å»ºæ¨¡èŒƒå¼ä¸‹å®ç°ç»“æ„åŒ–ä¸”è§£è€¦æ—‹å¾‹æ§åˆ¶çš„é›¶æ ·æœ¬ (Zero-Shot) æ­Œå”±è¯­éŸ³åˆæˆ (SVS) æ¡†æ¶ã€‚é’ˆå¯¹ç°æœ‰æ–¹æ³•ä¸­éŸ³é«˜ä¿¡æ¯ä¸éŸ³è‰²æç¤ºç›¸äº’ç¼ ç»•å¯¼è‡´çš„éŸµå¾‹æ³„æ¼ (Prosody Leakage) é—®é¢˜ï¼ŒCoMelSinger åŸºäº MaskGCT æ¶æ„ï¼Œå°†ä¼ ç»Ÿçš„æ–‡æœ¬è¾“å…¥æ›¿æ¢ä¸ºæ­Œè¯å’ŒéŸ³é«˜ Tokenï¼Œåœ¨ä¿æŒä¸Šä¸‹æ–‡æ³›åŒ–èƒ½åŠ›çš„åŒæ—¶å¢å¼ºäº†æ—‹å¾‹çº¦æŸã€‚ä¸ºäº†æŠ‘åˆ¶éŸµå¾‹æ³„æ¼ï¼Œè¯¥ç ”ç©¶æå‡ºäº†ä¸€ç§ä»ç²—åˆ°ç»†çš„å¯¹æ¯”å­¦ä¹ ç­–ç•¥ï¼Œæ˜¾å¼åœ°è§„èŒƒäº†å£°å­¦æç¤ºä¸æ—‹å¾‹è¾“å…¥ä¹‹é—´çš„éŸ³é«˜å†—ä½™ã€‚æ­¤å¤–ï¼Œè¯¥æ¡†æ¶é›†æˆäº†ä¸€ä¸ªè½»é‡çº§çš„ä»…ç¼–ç å™¨æ­Œå”±è¯­éŸ³è½¬å½• (SVT) æ¨¡å—ï¼Œé€šè¿‡å°†å£°å­¦ Token ä¸éŸ³é«˜å’Œæ—¶é•¿å¯¹é½æ¥æä¾›ç»†ç²’åº¦çš„å¸§çº§ç›‘ç£ã€‚å®éªŒç»“æœè¡¨æ˜ï¼ŒCoMelSinger åœ¨éŸ³é«˜å‡†ç¡®æ€§ã€éŸ³è‰²ä¸€è‡´æ€§å’Œé›¶æ ·æœ¬è¿ç§»èƒ½åŠ›æ–¹é¢è¾ƒç°æœ‰åŸºå‡†æ¨¡å‹æœ‰æ˜¾è‘—æå‡ã€‚",
      "categories": [
        "cs.SD",
        "cs.AI"
      ],
      "primary_category": "cs.SD",
      "comment": "13 pages, 5 figures, 5 tables",
      "pdf_url": "https://arxiv.org/pdf/2509.19883v1",
      "published_date": "2025-09-24 08:34:19 UTC",
      "updated_date": "2025-09-24 08:34:19 UTC",
      "processing_status": "completed",
      "attempts": 1,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "llm_backup_calls": 0,
      "last_update": "2026-01-24T21:00:40.689454+00:00"
    },
    {
      "arxiv_id": "2509.19880v1",
      "title": "Do Before You Judge: Self-Reference as a Pathway to Better LLM Evaluation",
      "title_zh": "å…ˆè¡Œåè¯„ï¼šè‡ªå¼•ç”¨â€”â€”æå‡å¤§è¯­è¨€æ¨¡å‹è¯„ä¼°æ•ˆèƒ½çš„æ–°è·¯å¾„",
      "authors": [
        "Wei-Hsiang Lin",
        "Sheng-Lun Wei",
        "Hen-Hsen Huang",
        "Hsin-Hsi Chen"
      ],
      "abstract": "LLM-as-Judge frameworks are increasingly popular for AI evaluation, yet research findings on the relationship between models' generation and judgment abilities remain inconsistent. We investigate this relationship through systematic dataset- and instance-level analyses across 11 models and 21 diverse tasks. Despite both capabilities relying on the same underlying knowledge, our analyses reveal they are only weakly correlated, primarily due to LLMs' sensitivity to the responses being judged. To address this, we propose a self-reference-guided evaluation strategy that leverages a model's own answers as references. This approach significantly strengthens the correlation between generation and judgment abilities, offering a practical path to align these skills and providing a reliable proxy for model selection in evaluation tasks.",
      "tldr_zh": "è¯¥ç ”ç©¶æ¢è®¨äº† LLM-as-Judge æ¡†æ¶ä¸­æ¨¡å‹ç”Ÿæˆèƒ½åŠ›ä¸è¯„åˆ¤èƒ½åŠ›ä¹‹é—´å…³ç³»ä¸ä¸€è‡´çš„é—®é¢˜ã€‚é€šè¿‡å¯¹ 11 ä¸ªæ¨¡å‹åœ¨ 21 é¡¹ä»»åŠ¡ä¸Šçš„ç³»ç»Ÿåˆ†æï¼Œç ”ç©¶å‘ç°è¿™ä¸¤ç§èƒ½åŠ›ä»…å‘ˆå¼±ç›¸å…³ï¼Œå…¶ä¸»è¦åŸå› åœ¨äºå¤§è¯­è¨€æ¨¡å‹å¯¹è¢«è¯„åˆ¤å›å¤å…·æœ‰é«˜åº¦æ•æ„Ÿæ€§ã€‚ä¸ºæ­¤ï¼Œç ”ç©¶è€…æå‡ºäº†ä¸€ç§ä»¥ Self-Reference ä¸ºå¯¼å‘çš„è¯„ä¼°ç­–ç•¥ï¼Œé€šè¿‡å¼•å…¥æ¨¡å‹è‡ªèº«çš„å›ç­”ä½œä¸ºå‚è€ƒæ¥ä¼˜åŒ–è¯„ä¼°è¿‡ç¨‹ã€‚å®éªŒè¯æ˜è¯¥æ–¹æ³•æ˜¾è‘—å¢å¼ºäº†ç”Ÿæˆä¸è¯„åˆ¤èƒ½åŠ›çš„å…³è”æ€§ï¼Œä¸ºå¯¹é½è¿™äº›æŠ€èƒ½æä¾›äº†æœ‰æ•ˆè·¯å¾„ã€‚è¯¥ç­–ç•¥ä¸ä»…æé«˜äº†è¯„ä¼°çš„å‡†ç¡®æ€§ï¼Œä¹Ÿä¸ºåœ¨è¯„ä¼°ä»»åŠ¡ä¸­é€‰æ‹©åˆé€‚çš„æ¨¡å‹æä¾›äº†å¯é çš„ä»£ç†ä¾æ®ã€‚",
      "categories": [
        "cs.CL",
        "cs.AI"
      ],
      "primary_category": "cs.CL",
      "comment": "Accepted as a long findings paper at EMNLP 2025",
      "pdf_url": "https://arxiv.org/pdf/2509.19880v1",
      "published_date": "2025-09-24 08:32:45 UTC",
      "updated_date": "2025-09-24 08:32:45 UTC",
      "processing_status": "completed",
      "attempts": 1,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "llm_backup_calls": 0,
      "last_update": "2026-01-24T21:00:39.691137+00:00"
    },
    {
      "arxiv_id": "2509.19877v2",
      "title": "Advancing Universal Deep Learning for Electronic-Structure Hamiltonian Prediction of Materials",
      "title_zh": "æ¨è¿›ææ–™ç”µå­ç»“æ„å“ˆå¯†é¡¿é‡é¢„æµ‹çš„é€šç”¨æ·±åº¦å­¦ä¹ ",
      "authors": [
        "Shi Yin",
        "Zujian Dai",
        "Xinyang Pan",
        "Lixin He"
      ],
      "abstract": "Deep learning methods for electronic-structure Hamiltonian prediction has offered significant computational efficiency advantages over traditional DFT methods, yet the diversity of atomic types, structural patterns, and the high-dimensional complexity of Hamiltonians pose substantial challenges to the generalization performance. In this work, we contribute on both the methodology and dataset sides to advance universal deep learning paradigm for Hamiltonian prediction. On the method side, we propose NextHAM, a neural E(3)-symmetry and expressive correction method for efficient and generalizable materials electronic-structure Hamiltonian prediction. First, we introduce the zeroth-step Hamiltonians, which can be efficiently constructed by the initial charge density of DFT, as informative descriptors of neural regression model in the input level and initial estimates of the target Hamiltonian in the output level, so that the regression model directly predicts the correction terms to the target ground truths, thereby significantly simplifying the input-output mapping for learning. Second, we present a neural Transformer architecture with strict E(3)-Symmetry and high non-linear expressiveness for Hamiltonian prediction. Third, we propose a novel training objective to ensure the accuracy performance of Hamiltonians in both real space and reciprocal space, preventing error amplification and the occurrence of \"ghost states\" caused by the large condition number of the overlap matrix. On the dataset side, we curate a high-quality broad-coverage large benchmark, namely Materials-HAM-SOC, comprising 17,000 material structures spanning 68 elements from six rows of the periodic table and explicitly incorporating SOC effects. Experimental results on Materials-HAM-SOC demonstrate that NextHAM achieves excellent accuracy and efficiency in predicting Hamiltonians and band structures.",
      "tldr_zh": "è¯¥ç ”ç©¶æ—¨åœ¨æå‡ææ–™ç”µå­ç»“æ„Hamiltoniané¢„æµ‹çš„æ·±åº¦å­¦ä¹ é€šç”¨èŒƒå¼ï¼Œä»¥åº”å¯¹åŸå­ç±»å‹å¤šæ ·æ€§åŠé«˜ç»´å¤æ‚æ€§å¸¦æ¥çš„æ³›åŒ–æŒ‘æˆ˜ã€‚ç ”ç©¶è€…æå‡ºäº†NextHAMæ¨¡å‹ï¼Œè¿™æ˜¯ä¸€ç§å…·å¤‡E(3)-Symmetryå’Œé«˜éçº¿æ€§è¡¨è¾¾èƒ½åŠ›çš„ç¥ç»ç½‘ç»œä¿®æ­£æ–¹æ³•ï¼Œé€šè¿‡å¼•å…¥ç”±DFTç”µè·å¯†åº¦æ„å»ºçš„zeroth-step Hamiltoniansä½œä¸ºè¾“å…¥æè¿°ç¬¦å’Œåˆå§‹ä¼°è®¡ï¼Œä½¿æ¨¡å‹é€šè¿‡é¢„æµ‹ä¿®æ­£é¡¹æ¥ç®€åŒ–å­¦ä¹ æ˜ å°„ã€‚æ¶æ„ä¸Šé‡‡ç”¨äº†ä¸¥æ ¼éµå¾ªE(3)-Symmetryçš„Transformerï¼Œå¹¶é…åˆä¸€ç§æ–°å‹è®­ç»ƒç›®æ ‡ï¼Œç¡®ä¿åœ¨å®ç©ºé—´å’Œreciprocal spaceçš„é¢„æµ‹å‡†ç¡®æ€§ï¼Œæœ‰æ•ˆé˜²æ­¢äº†ghost statesçš„äº§ç”Ÿã€‚æ­¤å¤–ï¼Œç ”ç©¶å›¢é˜Ÿæ„å»ºäº†åŒ…å«68ç§å…ƒç´ ã€1.7ä¸‡ä¸ªææ–™ç»“æ„å¹¶çº³å…¥SOCæ•ˆåº”çš„å¤§è§„æ¨¡åŸºå‡†æ•°æ®é›†Materials-HAM-SOCã€‚å®éªŒç»“æœè¡¨æ˜ï¼ŒNextHAMåœ¨Hamiltonianå’Œband structuresé¢„æµ‹ä¸­å±•ç°å‡ºå“è¶Šçš„ç²¾åº¦ä¸æ•ˆç‡ï¼Œä¸ºå®ç°é€šç”¨åŒ–çš„ææ–™ç”µå­ç»“æ„æ¨¡æ‹Ÿå¥ å®šäº†åŸºç¡€ã€‚",
      "categories": [
        "cs.LG",
        "cond-mat.mtrl-sci",
        "cs.AI",
        "physics.chem-ph",
        "physics.comp-ph"
      ],
      "primary_category": "cs.LG",
      "comment": "",
      "pdf_url": "https://arxiv.org/pdf/2509.19877v2",
      "published_date": "2025-09-24 08:30:58 UTC",
      "updated_date": "2025-09-25 08:01:42 UTC",
      "processing_status": "completed",
      "attempts": 1,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "llm_backup_calls": 0,
      "last_update": "2026-01-24T21:00:57.182218+00:00"
    },
    {
      "arxiv_id": "2509.19875v1",
      "title": "Adaptive Guidance Semantically Enhanced via Multimodal LLM for Edge-Cloud Object Detection",
      "title_zh": "åŸºäºå¤šæ¨¡æ€å¤§è¯­è¨€æ¨¡å‹è¯­ä¹‰å¢å¼ºçš„è¾¹äº‘åä½œç›®æ ‡æ£€æµ‹è‡ªé€‚åº”å¼•å¯¼",
      "authors": [
        "Yunqing Hu",
        "Zheming Yang",
        "Chang Zhao",
        "Wen Ji"
      ],
      "abstract": "Traditional object detection methods face performance degradation challenges in complex scenarios such as low-light conditions and heavy occlusions due to a lack of high-level semantic understanding. To address this, this paper proposes an adaptive guidance-based semantic enhancement edge-cloud collaborative object detection method leveraging Multimodal Large Language Models (MLLM), achieving an effective balance between accuracy and efficiency. Specifically, the method first employs instruction fine-tuning to enable the MLLM to generate structured scene descriptions. It then designs an adaptive mapping mechanism that dynamically converts semantic information into parameter adjustment signals for edge detectors, achieving real-time semantic enhancement. Within an edge-cloud collaborative inference framework, the system automatically selects between invoking cloud-based semantic guidance or directly outputting edge detection results based on confidence scores. Experiments demonstrate that the proposed method effectively enhances detection accuracy and efficiency in complex scenes. Specifically, it can reduce latency by over 79% and computational cost by 70% in low-light and highly occluded scenes while maintaining accuracy.",
      "tldr_zh": "è¯¥ç ”ç©¶é’ˆå¯¹ä¼ ç»Ÿç‰©ä½“æ£€æµ‹æ–¹æ³•åœ¨ä½å…‰ç…§ã€é‡åº¦é®æŒ¡ç­‰å¤æ‚åœºæ™¯ä¸‹å› ç¼ºä¹é«˜å±‚è¯­ä¹‰ç†è§£è€Œå¯¼è‡´çš„æ€§èƒ½ä¸‹é™é—®é¢˜ï¼Œæå‡ºäº†ä¸€ç§ç»“åˆå¤šæ¨¡æ€å¤§è¯­è¨€æ¨¡å‹ï¼ˆMLLMï¼‰çš„è‡ªé€‚åº”å¼•å¯¼è¯­ä¹‰å¢å¼ºè¾¹äº‘ååŒæ£€æµ‹æ–¹æ³•ã€‚è¯¥æ–¹æ³•é¦–å…ˆé€šè¿‡æŒ‡ä»¤å¾®è°ƒï¼ˆInstruction Fine-tuningï¼‰ä½¿ MLLM èƒ½å¤Ÿç”Ÿæˆç»“æ„åŒ–çš„åœºæ™¯æè¿°ï¼Œå¹¶è®¾è®¡äº†ä¸€ç§è‡ªé€‚åº”æ˜ å°„æœºåˆ¶ï¼Œå°†è¯­ä¹‰ä¿¡æ¯åŠ¨æ€è½¬æ¢ä¸ºè¾¹ç¼˜æ£€æµ‹å™¨çš„å‚æ•°è°ƒæ•´ä¿¡å·ä»¥å®ç°å®æ—¶å¢å¼ºã€‚åœ¨è¾¹äº‘ååŒæ¨ç†æ¡†æ¶ä¸‹ï¼Œç³»ç»Ÿæ ¹æ®ç½®ä¿¡åº¦åˆ†æ•°è‡ªåŠ¨åœ¨äº‘ç«¯è¯­ä¹‰å¼•å¯¼ä¸è¾¹ç¼˜ç›´æ¥æ£€æµ‹ä¹‹é—´è¿›è¡Œåˆ‡æ¢ï¼Œä¼˜åŒ–äº†æ¨ç†æµç¨‹ã€‚å®éªŒè¯æ˜ï¼Œè¯¥æ–¹æ³•åœ¨ä¿æŒå‡†ç¡®ç‡çš„å‰æä¸‹ï¼Œåœ¨å¤æ‚åœºæ™¯ä¸­å¯å°†å»¶è¿Ÿé™ä½ 79% ä»¥ä¸Šï¼Œå¹¶å‡å°‘ 70% çš„è®¡ç®—æˆæœ¬ï¼Œæœ‰æ•ˆå¹³è¡¡äº†æ£€æµ‹ç²¾åº¦ä¸æ•ˆç‡ã€‚",
      "categories": [
        "cs.CV",
        "cs.AI"
      ],
      "primary_category": "cs.CV",
      "comment": "",
      "pdf_url": "https://arxiv.org/pdf/2509.19875v1",
      "published_date": "2025-09-24 08:25:37 UTC",
      "updated_date": "2025-09-24 08:25:37 UTC",
      "processing_status": "completed",
      "attempts": 1,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "llm_backup_calls": 0,
      "last_update": "2026-01-24T21:00:44.687643+00:00"
    },
    {
      "arxiv_id": "2511.11576v1",
      "title": "DAOpt: Modeling and Evaluation of Data-Driven Optimization under Uncertainty with LLMs",
      "title_zh": "DAOptï¼šåŸºäºå¤§è¯­è¨€æ¨¡å‹çš„ä¸ç¡®å®šæ€§ç¯å¢ƒä¸‹æ•°æ®é©±åŠ¨ä¼˜åŒ–å»ºæ¨¡ä¸è¯„ä¼°",
      "authors": [
        "WenZhuo Zhu",
        "Zheng Cui",
        "Wenhan Lu",
        "Sheng Liu",
        "Yue Zhao"
      ],
      "abstract": "Recent advances in large language models (LLMs) have accelerated research on automated optimization modeling. While real-world decision-making is inherently uncertain, most existing work has focused on deterministic optimization with known parameters, leaving the application of LLMs in uncertain settings largely unexplored. To that end, we propose the DAOpt framework including a new dataset OptU, a multi-agent decision-making module, and a simulation environment for evaluating LLMs with a focus on out-of-sample feasibility and robustness. Additionally, we enhance LLMs' modeling capabilities by incorporating few-shot learning with domain knowledge from stochastic and robust optimization.",
      "tldr_zh": "è¯¥ç ”ç©¶é’ˆå¯¹ç°å®ä¸–ç•Œå†³ç­–ä¸­å­˜åœ¨çš„å›ºæœ‰ä¸ç¡®å®šæ€§ï¼Œæå‡ºäº†DAOptæ¡†æ¶ï¼Œæ—¨åœ¨å¡«è¡¥å¤§å‹è¯­è¨€æ¨¡å‹(LLMs)åœ¨ä¸ç¡®å®šç¯å¢ƒä¸‹è‡ªåŠ¨ä¼˜åŒ–å»ºæ¨¡çš„ç ”ç©¶ç©ºç™½ã€‚è¯¥æ¡†æ¶åŒ…å«ä¸€ä¸ªå…¨æ–°çš„æ•°æ®é›†OptUã€ä¸€ä¸ªå¤šæ™ºèƒ½ä½“å†³ç­–æ¨¡å—ï¼Œä»¥åŠä¸€ä¸ªä¸“é—¨ç”¨äºè¯„ä¼°LLMsåœ¨æ ·æœ¬å¤–(out-of-sample)å¯è¡Œæ€§ä¸ç¨³å¥æ€§çš„ä»¿çœŸç¯å¢ƒã€‚é€šè¿‡å¼•å…¥å°‘æ ·æœ¬å­¦ä¹ (few-shot learning)å¹¶ç»“åˆéšæœºä¼˜åŒ–(stochastic optimization)ä¸ç¨³å¥ä¼˜åŒ–(robust optimization)çš„é¢†åŸŸçŸ¥è¯†ï¼Œè¯¥æ–¹æ³•æ˜¾è‘—å¢å¼ºäº†LLMsçš„å»ºæ¨¡èƒ½åŠ›ã€‚ç ”ç©¶é‡ç‚¹å…³æ³¨æ¨¡å‹åœ¨ä¸ç¡®å®šå‚æ•°è®¾ç½®ä¸‹çš„è¡¨ç°ï¼Œé€šè¿‡æ¨¡æ‹Ÿç¯å¢ƒéªŒè¯äº†å…¶åœ¨å®é™…å†³ç­–ä¸­çš„ç¨³å¥æ€§ã€‚è¿™ä¸€æˆæœä¸ºè‡ªåŠ¨åŒ–ã€æ•°æ®é©±åŠ¨çš„å¤æ‚ä¸ç¡®å®šæ€§ä¼˜åŒ–å»ºæ¨¡æä¾›äº†ç³»ç»Ÿçš„è¯„ä¼°å·¥å…·å’Œåˆ›æ–°æ–¹æ³•ã€‚",
      "categories": [
        "cs.LG",
        "cs.AI"
      ],
      "primary_category": "cs.LG",
      "comment": "",
      "pdf_url": "https://arxiv.org/pdf/2511.11576v1",
      "published_date": "2025-09-24 08:19:28 UTC",
      "updated_date": "2025-09-24 08:19:28 UTC",
      "processing_status": "completed",
      "attempts": 1,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "llm_backup_calls": 0,
      "last_update": "2026-01-24T21:00:54.296607+00:00"
    },
    {
      "arxiv_id": "2509.22715v1",
      "title": "TRUEBench: Can LLM Response Meet Real-world Constraints as Productivity Assistant?",
      "title_zh": "TRUEBenchï¼šå¤§è¯­è¨€æ¨¡å‹ä½œä¸ºç”Ÿäº§åŠ›åŠ©æ‰‹èƒ½å¦æ»¡è¶³ç°å®ä¸–ç•Œçº¦æŸï¼Ÿ",
      "authors": [
        "Jiho Park",
        "Jongyoon Song",
        "Minjin Choi",
        "Kyuho Heo",
        "Taehun Huh",
        "Ji Won Kim"
      ],
      "abstract": "Large language models (LLMs) are increasingly integral as productivity assistants, but existing benchmarks fall short in rigorously evaluating their real-world instruction-following capabilities. Current benchmarks often (i) lack sufficient multilinguality, (ii) fail to capture the implicit constraints inherent in user requests, and (iii) overlook the complexities of multi-turn dialogue. To address these critical gaps and provide a more realistic assessment, we introduce TRUEBench (Trustworthy Real-world Usage Evaluation Benchmark)1, a novel benchmark specifically designed for LLM-based productivity assistants. TRUEBench distinguishes itself by featuring input prompts across 12 languages, incorporating intra-instance multilingual instructions, employing rigorous evaluation criteria to capture both explicit and implicit constraints, and including complex multi-turn dialogue scenarios with both accumulating constraints and context switches. Furthermore, to ensure reliability in evaluation, we refined constraints using an LLM validator. Extensive experiments demonstrate that TRUEBench presents significantly greater challenges than existing benchmarks; for instance, a strong model like OpenAI o1 achieved only a 69.07% overall pass rate. TRUEBench offers a demanding and realistic assessment of LLMs in practical productivity settings, highlighting their capabilities and limitations.",
      "tldr_zh": "è¯¥ç ”ç©¶å¼•å…¥äº†TRUEBenchï¼Œè¿™æ˜¯ä¸€ä¸ªä¸“ä¸ºè¯„ä¼°å¤§è¯­è¨€æ¨¡å‹(LLMs)ä½œä¸ºç”Ÿäº§åŠ›åŠ©æ‰‹åœ¨ç°å®åœºæ™¯ä¸­æŒ‡ä»¤éµå¾ªèƒ½åŠ›è€Œè®¾è®¡çš„åŸºå‡†ã€‚é’ˆå¯¹ç°æœ‰è¯„ä¼°å·¥å…·åœ¨å¤šè¯­è¨€æ”¯æŒã€éšå«çº¦æŸè¯†åˆ«ä»¥åŠå¤šè½®å¯¹è¯å¤æ‚æ€§æ–¹é¢çš„å±€é™ï¼ŒTRUEBench æ¶µç›–äº†12ç§è¯­è¨€ï¼Œå¹¶èå…¥äº†è·¨å®ä¾‹çš„å¤šè¯­è¨€æŒ‡ä»¤ä»¥åŠå¤æ‚çš„ä¸Šä¸‹æ–‡åˆ‡æ¢å’Œç´¯ç§¯çº¦æŸã€‚ä¸ºäº†æå‡è¯„ä»·çš„å¯é æ€§ï¼Œè¯¥åŸºå‡†åˆ©ç”¨LLMéªŒè¯å™¨å¯¹å„é¡¹çº¦æŸè¿›è¡Œäº†ç²¾ç»†åŒ–å¤„ç†ï¼Œç¡®ä¿è¯„ä¼°æ ‡å‡†æ—¢ä¸¥è‹›åˆçœŸå®ã€‚å®éªŒè¯„ä¼°è¡¨æ˜ï¼ŒTRUEBench ç›¸æ¯”ç°æœ‰åŸºå‡†å…·æœ‰æ˜¾è‘—æ›´é«˜çš„æŒ‘æˆ˜æ€§ï¼Œå³ä¾¿æ˜¯OpenAI o1ç­‰å¼ºåŠ›æ¨¡å‹åœ¨å…¶ä¸­çš„æ•´ä½“é€šè¿‡ç‡ä¹Ÿä»…ä¸º69.07%ã€‚è¯¥åŸºå‡†ä¸ºLLMsåœ¨å®é™…ç”Ÿäº§åŠ›ç¯å¢ƒä¸­çš„èƒ½åŠ›ä¸å±€é™æ€§æä¾›äº†æ›´ä¸ºç§‘å­¦ä¸”è´´è¿‘å®æˆ˜çš„è¯„ä»·ä½“ç³»ã€‚",
      "categories": [
        "cs.CL",
        "cs.AI"
      ],
      "primary_category": "cs.CL",
      "comment": "Accepted to EMNLP 2025 Findings",
      "pdf_url": "https://arxiv.org/pdf/2509.22715v1",
      "published_date": "2025-09-24 08:05:32 UTC",
      "updated_date": "2025-09-24 08:05:32 UTC",
      "processing_status": "completed",
      "attempts": 1,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "llm_backup_calls": 0,
      "last_update": "2026-01-24T21:01:07.534871+00:00"
    },
    {
      "arxiv_id": "2509.19855v1",
      "title": "CollaPipe: Adaptive Segment-Optimized Pipeline Parallelism for Collaborative LLM Training in Heterogeneous Edge Networks",
      "title_zh": "CollaPipeï¼šé¢å‘å¼‚æ„è¾¹ç¼˜ç½‘ç»œåä½œå¼å¤§è¯­è¨€æ¨¡å‹è®­ç»ƒçš„è‡ªé€‚åº”åˆ†æ®µä¼˜åŒ–æµæ°´çº¿å¹¶è¡Œ",
      "authors": [
        "Jiewei Chen",
        "Xiumei Deng",
        "Zehui Xiong",
        "Shaoyong Guo",
        "Xuesong Qiu",
        "Ping Wang",
        "Dusit Niyato"
      ],
      "abstract": "The increasing demand for intelligent mobile applications has made multi-agent collaboration with Transformer-based large language models (LLMs) essential in mobile edge computing (MEC) networks. However, training LLMs in such environments remains challenging due to heavy computation, high end-to-end latency, and limited model generalization. We introduce CollaPipe, a hybrid distributed learning framework that integrates collaborative pipeline parallelism with federated aggregation to support self-evolving intelligent networks. In CollaPipe, the encoder part is adaptively partitioned into variable-sized segments and deployed across mobile devices for pipeline-parallel training, while the decoder is deployed on edge servers to handle generative tasks. Then we perform global model update via federated aggregation. To enhance training efficiency, we formulate a joint optimization problem that adaptively allocates model segments, micro-batches, bandwidth, and transmission power. We derive and use a closed-form convergence bound to design an Dynamic Segment Scheduling and Resource Allocation (DSSDA) algorithm based on Lyapunov optimization, ensuring system stability under long-term constraints. Extensive experiments on downstream tasks with Transformer and BERT models show that CollaPipe improves computation efficiency by up to 15.09%, reduces end-to-end latency by at least 48.98%, and cuts single device memory usage by more than half, enabling online learning in heterogeneous and dynamic communication environments.",
      "tldr_zh": "è¯¥ç ”ç©¶æå‡ºäº† CollaPipeï¼Œä¸€ç§é’ˆå¯¹å¼‚æ„è¾¹ç¼˜ç½‘ç»œä¸­ Transformer å¤§è¯­è¨€æ¨¡å‹ï¼ˆLLMsï¼‰åä½œè®­ç»ƒçš„æ··åˆåˆ†å¸ƒå¼å­¦ä¹ æ¡†æ¶ã€‚è¯¥æ¡†æ¶å°†åä½œæµæ°´çº¿å¹¶è¡Œï¼ˆPipeline Parallelismï¼‰ä¸è”é‚¦èšåˆï¼ˆFederated Aggregationï¼‰ç›¸ç»“åˆï¼Œé€šè¿‡å°†ç¼–ç å™¨è‡ªé€‚åº”åˆ’åˆ†ä¸ºå˜é•¿ç‰‡æ®µéƒ¨ç½²åœ¨ç§»åŠ¨è®¾å¤‡ä¸Šï¼ŒåŒæ—¶åœ¨è¾¹ç¼˜æœåŠ¡å™¨éƒ¨ç½²è§£ç å™¨ä»¥å¤„ç†ç”Ÿæˆä»»åŠ¡ã€‚ä¸ºäº†ä¼˜åŒ–è®­ç»ƒæ•ˆç‡ï¼Œç ”ç©¶æ„å»ºäº†æ¶µç›–æ¨¡å‹ç‰‡æ®µã€å¾®æ‰¹æ¬¡ï¼ˆMicro-batchesï¼‰ã€å¸¦å®½åŠå‘å°„åŠŸç‡çš„è”åˆä¼˜åŒ–é—®é¢˜ï¼Œå¹¶åŸºäº Lyapunov ä¼˜åŒ–è®¾è®¡äº†åŠ¨æ€ç‰‡æ®µè°ƒåº¦ä¸èµ„æºåˆ†é…ï¼ˆDSSDAï¼‰ç®—æ³•ã€‚å®éªŒç»“æœæ˜¾ç¤ºï¼ŒCollaPipe åœ¨ Transformer å’Œ BERT æ¨¡å‹ä¸Šçš„è®¡ç®—æ•ˆç‡æå‡äº† 15.09%ï¼Œç«¯åˆ°ç«¯å»¶è¿Ÿé™ä½äº† 48.98% ä»¥ä¸Šï¼Œä¸”å•è®¾å¤‡å†…å­˜å ç”¨å‡å°‘è¶…è¿‡ä¸€åŠã€‚è¯¥æ¡†æ¶æˆåŠŸå®ç°äº†åœ¨å¼‚æ„åŠ¨æ€é€šä¿¡ç¯å¢ƒä¸‹çš„åœ¨çº¿å­¦ä¹ ï¼Œä¸ºæ„å»ºè‡ªè¿›åŒ–æ™ºèƒ½ç½‘ç»œæä¾›äº†é«˜æ•ˆçš„è§£å†³æ–¹æ¡ˆã€‚",
      "categories": [
        "eess.SY",
        "cs.AI",
        "cs.NI"
      ],
      "primary_category": "eess.SY",
      "comment": "Submitted to IEEE for review",
      "pdf_url": "https://arxiv.org/pdf/2509.19855v1",
      "published_date": "2025-09-24 07:54:01 UTC",
      "updated_date": "2025-09-24 07:54:01 UTC",
      "processing_status": "completed",
      "attempts": 1,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "llm_backup_calls": 0,
      "last_update": "2026-01-24T21:01:10.786723+00:00"
    },
    {
      "arxiv_id": "2509.19852v1",
      "title": "Eliminating stability hallucinations in llm-based tts models via attention guidance",
      "title_zh": "é€šè¿‡æ³¨æ„åŠ›å¼•å¯¼æ¶ˆé™¤åŸºäºå¤§è¯­è¨€æ¨¡å‹çš„ TTS æ¨¡å‹ä¸­çš„ç¨³å®šæ€§å¹»è§‰",
      "authors": [
        "ShiMing Wang",
        "ZhiHao Du",
        "Yang Xiang",
        "TianYu Zhao",
        "Han Zhao",
        "Qian Chen",
        "XianGang Li",
        "HanJie Guo",
        "ZhenHua Ling"
      ],
      "abstract": "This paper focuses on resolving stability hallucinations (e.g., repetitive or omitted speech) in LLM-based Text-to-Speech (TTS) models by improving and leveraging the attention mechanism. First, we analyzed the alignment mechanism between text tokens and speech tokens in LLMs. We then proposed a metric termed the Optimal Alignment Score (OAS), which employs the Viterbi algorithm to evaluate text-speech alignment quality. Subsequently, OAS was integrated into the training of CosyVoice2 to assist LLMs in learning continuous, stable alignment. Additionally, the pre-trained attention value is employed to guide the training of the student CosyVoice2 via chain-of-thought (CoT), which further reduces stability hallucinations in synthesized speech. Experiments on the Seed-TTS-Eval and CV3-Eval test sets demonstrate that the proposed methods can effectively reduce the stability hallucinations of CosyVoice2 without introducing additional negative effects. The appendix is available at https://wsmzzz.github.io/llm_attn.",
      "tldr_zh": "è¯¥ç ”ç©¶é’ˆå¯¹åŸºäºå¤§è¯­è¨€æ¨¡å‹(LLM)çš„æ–‡æœ¬è½¬è¯­éŸ³(TTS)æ¨¡å‹ä¸­å­˜åœ¨çš„ç¨³å®šæ€§å¹»è§‰(stability hallucinations)é—®é¢˜ï¼Œå¦‚è¯­éŸ³é‡å¤æˆ–é—æ¼ï¼Œæå‡ºäº†é€šè¿‡æ”¹è¿›å’Œåˆ©ç”¨æ³¨æ„åŠ›æœºåˆ¶çš„è§£å†³æ–¹æ¡ˆã€‚ç ”ç©¶å›¢é˜Ÿé¦–å…ˆåˆ†æäº†æ–‡æœ¬æ ‡è®°(text tokens)ä¸è¯­éŸ³æ ‡è®°(speech tokens)ä¹‹é—´çš„å¯¹é½æœºåˆ¶ï¼Œå¹¶æå‡ºäº†ä¸€ç§åä¸ºæœ€ä¼˜å¯¹é½å¾—åˆ†(Optimal Alignment Score, OAS)çš„æŒ‡æ ‡ã€‚è¯¥æŒ‡æ ‡åˆ©ç”¨Viterbiç®—æ³•è¯„ä¼°æ–‡æœ¬-è¯­éŸ³å¯¹é½è´¨é‡ï¼Œå¹¶è¢«æ•´åˆåˆ°CosyVoice2çš„è®­ç»ƒè¿‡ç¨‹ä¸­ï¼Œä»¥å¼•å¯¼æ¨¡å‹å­¦ä¹ è¿ç»­ä¸”ç¨³å®šçš„å¯¹é½ã€‚æ­¤å¤–ï¼Œç ”ç©¶åˆ©ç”¨é¢„è®­ç»ƒçš„æ³¨æ„åŠ›å€¼é€šè¿‡é“¾å¼æ€ç»´(Chain-of-Thought, CoT)æŒ‡å¯¼å­¦ç”Ÿæ¨¡å‹CosyVoice2çš„è®­ç»ƒï¼Œè¿›ä¸€æ­¥å‡å°‘äº†åˆæˆè¯­éŸ³ä¸­çš„ç¨³å®šæ€§å¹»è§‰ã€‚åœ¨Seed-TTS-Evalå’ŒCV3-Evalæµ‹è¯•é›†ä¸Šçš„å®éªŒç»“æœè¡¨æ˜ï¼Œæ‰€ææ–¹æ³•èƒ½æœ‰æ•ˆé™ä½CosyVoice2çš„ç¨³å®šæ€§å¹»è§‰ï¼Œä¸”ä¸ä¼šå¼•å…¥é¢å¤–çš„è´Ÿé¢å½±å“ã€‚",
      "categories": [
        "cs.SD",
        "cs.AI"
      ],
      "primary_category": "cs.SD",
      "comment": "5 pages, submitted to ICASSP2026",
      "pdf_url": "https://arxiv.org/pdf/2509.19852v1",
      "published_date": "2025-09-24 07:47:52 UTC",
      "updated_date": "2025-09-24 07:47:52 UTC",
      "processing_status": "completed",
      "attempts": 1,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "llm_backup_calls": 0,
      "last_update": "2026-01-24T21:01:14.494038+00:00"
    },
    {
      "arxiv_id": "2509.19849v1",
      "title": "Analyzing Generalization in Pre-Trained Symbolic Regression",
      "title_zh": "é¢„è®­ç»ƒç¬¦å·å›å½’çš„æ³›åŒ–æ€§åˆ†æ",
      "authors": [
        "Henrik Voigt",
        "Paul Kahlmeyer",
        "Kai Lawonn",
        "Michael Habeck",
        "Joachim Giesen"
      ],
      "abstract": "Symbolic regression algorithms search a space of mathematical expressions for formulas that explain given data. Transformer-based models have emerged as a promising, scalable approach shifting the expensive combinatorial search to a large-scale pre-training phase. However, the success of these models is critically dependent on their pre-training data. Their ability to generalize to problems outside of this pre-training distribution remains largely unexplored. In this work, we conduct a systematic empirical study to evaluate the generalization capabilities of pre-trained, transformer-based symbolic regression. We rigorously test performance both within the pre-training distribution and on a series of out-of-distribution challenges for several state of the art approaches. Our findings reveal a significant dichotomy: while pre-trained models perform well in-distribution, the performance consistently degrades in out-of-distribution scenarios. We conclude that this generalization gap is a critical barrier for practitioners, as it severely limits the practical use of pre-trained approaches for real-world applications.",
      "tldr_zh": "è¯¥ç ”ç©¶å¯¹åŸºäº Transformer çš„é¢„è®­ç»ƒ Symbolic Regression (ç¬¦å·å›å½’) æ¨¡å‹çš„æ³›åŒ–èƒ½åŠ›è¿›è¡Œäº†ç³»ç»Ÿæ€§çš„å®è¯è¯„ä¼°ã€‚ç ”ç©¶å›¢é˜Ÿé€šè¿‡åœ¨é¢„è®­ç»ƒåˆ†å¸ƒå†…ä»¥åŠä¸€ç³»åˆ— Out-of-Distribution (OOD) æŒ‘æˆ˜åœºæ™¯ä¸‹å¯¹å¤šç§æœ€å…ˆè¿›çš„æ¨¡å‹è¿›è¡Œä¸¥è°¨æµ‹è¯•ï¼Œæ—¨åœ¨æ¢è®¨é¢„è®­ç»ƒæ•°æ®å¯¹æ¨¡å‹æ€§èƒ½çš„å½±å“ã€‚å®éªŒç»“æœæ­ç¤ºäº†ä¸€ä¸ªæ˜¾è‘—çš„æ€§èƒ½å·®å¼‚ï¼šè™½ç„¶è¿™äº›é¢„è®­ç»ƒæ¨¡å‹åœ¨åˆ†å¸ƒå†…è¡¨ç°ä¼˜å¼‚ï¼Œä½†åœ¨é¢å¯¹åˆ†å¸ƒå¤–åœºæ™¯æ—¶ï¼Œå…¶æ€§èƒ½ä¼šå‘ç”Ÿä¸€è‡´æ€§çš„é€€åŒ–ã€‚ä½œè€…å¾—å‡ºç»“è®ºï¼Œè¿™ç§ Generalization Gap (æ³›åŒ–å·®è·) æ˜¯é™åˆ¶é¢„è®­ç»ƒç¬¦å·å›å½’æ–¹æ³•åœ¨ç°å®ä¸–ç•Œä¸­å¹¿æ³›åº”ç”¨çš„å…³é”®ç“¶é¢ˆã€‚è¯¥å·¥ä½œé€šè¿‡è¯¦å°½çš„å®éªŒåˆ†æï¼Œæ˜ç¡®äº†å½“å‰åŸºäºå¤§è§„æ¨¡é¢„è®­ç»ƒçš„ç¬¦å·å›å½’æŠ€æœ¯åœ¨åº”å¯¹åˆ†å¸ƒå¤–æ•°æ®æ—¶çš„å±€é™æ€§ï¼Œä¸ºæœªæ¥æå‡æ¨¡å‹çš„é²æ£’æ€§æä¾›äº†é‡è¦å‚è€ƒã€‚",
      "categories": [
        "cs.LG",
        "cs.AI"
      ],
      "primary_category": "cs.LG",
      "comment": "",
      "pdf_url": "https://arxiv.org/pdf/2509.19849v1",
      "published_date": "2025-09-24 07:47:02 UTC",
      "updated_date": "2025-09-24 07:47:02 UTC",
      "processing_status": "completed",
      "attempts": 1,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "llm_backup_calls": 0,
      "last_update": "2026-01-24T21:01:16.055477+00:00"
    },
    {
      "arxiv_id": "2509.21394v1",
      "title": "Large AI Model-Enabled Generative Semantic Communications for Image Transmission",
      "title_zh": "å¤§æ¨¡å‹èµ‹èƒ½çš„é¢å‘å›¾åƒä¼ è¾“ç”Ÿæˆå¼è¯­ä¹‰é€šä¿¡",
      "authors": [
        "Qiyu Ma",
        "Wanli Ni",
        "Zhijin Qin"
      ],
      "abstract": "The rapid development of generative artificial intelligence (AI) has introduced significant opportunities for enhancing the efficiency and accuracy of image transmission within semantic communication systems. Despite these advancements, existing methodologies often neglect the difference in importance of different regions of the image, potentially compromising the reconstruction quality of visually critical content. To address this issue, we introduce an innovative generative semantic communication system that refines semantic granularity by segmenting images into key and non-key regions. Key regions, which contain essential visual information, are processed using an image oriented semantic encoder, while non-key regions are efficiently compressed through an image-to-text modeling approach. Additionally, to mitigate the substantial storage and computational demands posed by large AI models, the proposed system employs a lightweight deployment strategy incorporating model quantization and low-rank adaptation fine-tuning techniques, significantly boosting resource utilization without sacrificing performance. Simulation results demonstrate that the proposed system outperforms traditional methods in terms of both semantic fidelity and visual quality, thereby affirming its effectiveness for image transmission tasks.",
      "tldr_zh": "è¯¥ç ”ç©¶é’ˆå¯¹è¯­ä¹‰é€šä¿¡(Semantic Communication)ä¸­å›¾åƒä¼ è¾“æ•ˆç‡ä¸åŒºåŸŸé‡è¦æ€§å·®å¼‚çš„é—®é¢˜ï¼Œæå‡ºäº†ä¸€ç§ç»“åˆå¤§æ¨¡å‹èƒ½åŠ›çš„åˆ›æ–°å‹ç”Ÿæˆå¼è¯­ä¹‰é€šä¿¡ç³»ç»Ÿã€‚è¯¥ç³»ç»Ÿé€šè¿‡å°†å›¾åƒåˆ†å‰²ä¸ºå…³é”®åŒºåŸŸä¸éå…³é”®åŒºåŸŸæ¥ç»†åŒ–è¯­ä¹‰ç²’åº¦ï¼Œå¯¹åŒ…å«æ ¸å¿ƒè§†è§‰ä¿¡æ¯çš„å…³é”®åŒºåŸŸä½¿ç”¨é¢å‘å›¾åƒçš„è¯­ä¹‰ç¼–ç å™¨(image oriented semantic encoder)è¿›è¡Œå¤„ç†ï¼Œè€Œå¯¹éå…³é”®åŒºåŸŸåˆ™é‡‡ç”¨å›¾åƒè½¬æ–‡æœ¬å»ºæ¨¡(image-to-text modeling)è¿›è¡Œé«˜æ•ˆå‹ç¼©ã€‚ä¸ºåº”å¯¹å¤§å‹AIæ¨¡å‹çš„é«˜å­˜å‚¨ä¸è®¡ç®—éœ€æ±‚ï¼Œç³»ç»Ÿå¼•å…¥äº†ç»“åˆæ¨¡å‹é‡åŒ–(Model Quantization)ä¸ä½ç§©è‡ªé€‚åº”(Low-rank Adaptation)å¾®è°ƒçš„è½»é‡åŒ–éƒ¨ç½²ç­–ç•¥ï¼Œåœ¨ä¸æŸå¤±æ€§èƒ½çš„å‰æä¸‹å¤§å¹…æå‡äº†èµ„æºåˆ©ç”¨ç‡ã€‚ä»¿çœŸç»“æœæ˜¾ç¤ºï¼Œè¯¥ç³»ç»Ÿåœ¨è¯­ä¹‰ä¿çœŸåº¦(Semantic Fidelity)å’Œè§†è§‰è´¨é‡ä¸Šå‡æ˜¾è‘—ä¼˜äºä¼ ç»Ÿæ–¹æ³•ï¼Œå……åˆ†è¯æ˜äº†å…¶åœ¨å›¾åƒä¼ è¾“ä»»åŠ¡ä¸­çš„æœ‰æ•ˆæ€§ä¸å…ˆè¿›æ€§ã€‚",
      "categories": [
        "cs.CV",
        "cs.AI",
        "cs.IT"
      ],
      "primary_category": "cs.CV",
      "comment": "Accepted to the IEEE GLOBECOM 2025",
      "pdf_url": "https://arxiv.org/pdf/2509.21394v1",
      "published_date": "2025-09-24 07:46:38 UTC",
      "updated_date": "2025-09-24 07:46:38 UTC",
      "processing_status": "completed",
      "attempts": 1,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "llm_backup_calls": 0,
      "last_update": "2026-01-24T21:01:18.898522+00:00"
    },
    {
      "arxiv_id": "2509.25223v1",
      "title": "Enhancing Linear Attention with Residual Learning",
      "title_zh": "åˆ©ç”¨æ®‹å·®å­¦ä¹ å¢å¼ºçº¿æ€§æ³¨æ„åŠ›",
      "authors": [
        "Xunhao Lai",
        "Jialiang Kang",
        "Jianqiao Lu",
        "Tong Lin",
        "Pengyu Zhao"
      ],
      "abstract": "Linear attention offers a linear-time alternative to self-attention but often struggles to capture long-range patterns. We revisit linear attention through a prediction-correction lens and show that prevalent variants can be written as a combination of a historical prediction and a single-token correction, which creates an expressivity bottleneck. To address this bottleneck, we introduce Residual Linear Attention (RLA), a framework that equips linear attention with an explicit residual-fitting mechanism. RLA maintains an auxiliary recurrent state that learns to accumulate residual errors over time and correct the base prediction. We further instantiate a delta-rule version, Residual Delta Net (RDN), incorporating adaptive gating and residual clipping for enhanced correction control and stability. Our implementation leverages highly optimized linear attention kernels and preserves linear time and memory. Across language modeling and recall-intensive evaluations, RLA and RDN consistently outperform their respective baselines and other modern linear-attention methods, narrowing the gap to standard Transformers while retaining linear scaling.",
      "tldr_zh": "è¯¥ç ”ç©¶é’ˆå¯¹ Linear attention åœ¨æ•æ‰é•¿ç¨‹æ¨¡å¼ï¼ˆlong-range patternsï¼‰æ–¹é¢çš„å±€é™æ€§ï¼Œä»é¢„æµ‹-æ ¡æ­£ï¼ˆprediction-correctionï¼‰è§†è§’æ­ç¤ºäº†ç°æœ‰çº¿æ€§æ³¨æ„åŠ›å˜ä½“å­˜åœ¨çš„è¡¨è¾¾èƒ½åŠ›ç“¶é¢ˆã€‚ä¸ºæ­¤ï¼Œä½œè€…æå‡ºäº† Residual Linear Attention (RLA) æ¡†æ¶ï¼Œé€šè¿‡å¼•å…¥æ˜¾å¼çš„æ®‹å·®æ‹Ÿåˆï¼ˆresidual-fittingï¼‰æœºåˆ¶å’Œè¾…åŠ©å¾ªç¯çŠ¶æ€ï¼Œå®ç°äº†å¯¹æ®‹å·®è¯¯å·®çš„å®æ—¶ç´¯ç§¯ä¸åŸºç¡€é¢„æµ‹ä¿®æ­£ã€‚åœ¨æ­¤åŸºç¡€ä¸Šï¼Œç ”ç©¶è¿›ä¸€æ­¥æ„å»ºäº† Residual Delta Net (RDN)ï¼Œé›†æˆäº† delta-ruleã€è‡ªé€‚åº”é—¨æ§ï¼ˆadaptive gatingï¼‰å’Œæ®‹å·®è£å‰ªï¼ˆresidual clippingï¼‰ç­‰æŠ€æœ¯ï¼Œä»¥å¢å¼ºæ¨¡å‹çš„æ ¡æ­£æ§åˆ¶åŠ›ä¸è®­ç»ƒç¨³å®šæ€§ã€‚è¯¥å®ç°å……åˆ†åˆ©ç”¨äº†é«˜åº¦ä¼˜åŒ–çš„çº¿æ€§æ³¨æ„åŠ›å†…æ ¸ï¼Œåœ¨ä¿æŒçº¿æ€§æ—¶é—´ä¸å†…å­˜å¤æ‚åº¦çš„å‰æä¸‹æå‡äº†è®¡ç®—æ•ˆç‡ã€‚å®éªŒç»“æœè¡¨æ˜ï¼ŒRLA å’Œ RDN åœ¨è¯­è¨€å»ºæ¨¡åŠå¬å›å¯†é›†å‹ä»»åŠ¡ä¸­å‡æ˜¾è‘—ä¼˜äºç°æœ‰çš„çº¿æ€§æ³¨æ„åŠ›æ–¹æ³•ï¼Œåœ¨ä¿ç•™çº¿æ€§ç¼©æ”¾ï¼ˆlinear scalingï¼‰ç‰¹æ€§çš„åŒæ—¶ï¼Œå¤§å¹…ç¼©å°äº†ä¸æ ‡å‡† Transformer ä¹‹é—´çš„æ€§èƒ½å·®è·ã€‚",
      "categories": [
        "cs.LG",
        "cs.AI"
      ],
      "primary_category": "cs.LG",
      "comment": "15 pages, 4 figures",
      "pdf_url": "https://arxiv.org/pdf/2509.25223v1",
      "published_date": "2025-09-24 07:36:08 UTC",
      "updated_date": "2025-09-24 07:36:08 UTC",
      "processing_status": "completed",
      "attempts": 1,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "llm_backup_calls": 0,
      "last_update": "2026-01-24T21:01:39.483036+00:00"
    },
    {
      "arxiv_id": "2509.19839v1",
      "title": "LatentGuard: Controllable Latent Steering for Robust Refusal of Attacks and Reliable Response Generation",
      "title_zh": "LatentGuardï¼šé¢å‘ç¨³å¥æ”»å‡»æ‹’ç»ä¸å¯é å“åº”ç”Ÿæˆçš„æ½œç©ºé—´å¯æ§å¼•å¯¼",
      "authors": [
        "Huizhen Shu",
        "Xuying Li",
        "Zhuo Li"
      ],
      "abstract": "Achieving robust safety alignment in large language models (LLMs) while preserving their utility remains a fundamental challenge. Existing approaches often struggle to balance comprehensive safety with fine-grained controllability at the representation level. We introduce LATENTGUARD, a novel three-stage framework that combines behavioral alignment with supervised latent space control for interpretable and precise safety steering. Our approach begins by fine-tuning an LLM on rationalized datasets containing both reasoning-enhanced refusal responses to adversarial prompts and reasoning-enhanced normal responses to benign queries, establishing robust behavioral priors across both safety-critical and utility-preserving scenarios. We then train a structured variational autoencoder (VAE) on intermediate MLP activations, supervised by multi-label annotations including attack types, attack methods, and benign indicators. This supervision enables the VAE to learn disentangled latent representations that capture distinct adversarial characteristics while maintaining semantic interpretability. Through targeted manipulation of learned latent dimensions, LATENTGUARD achieves selective refusal behavior, effectively blocking harmful requests while preserving helpfulness for legitimate use cases. Experiments on Qwen3-8B demonstrate significant improvements in both safety controllability and response interpretability without compromising utility. Cross-architecture validation on Mistral-7B confirms the generalizability of our latent steering approach, showing consistent effectiveness across different model families. Our results suggest that structured representation-level intervention offers a promising pathway toward building safer yet practical LLM systems.",
      "tldr_zh": "è¯¥ç ”ç©¶æå‡ºäº†LatentGuardï¼Œè¿™æ˜¯ä¸€ä¸ªä¸‰é˜¶æ®µæ¡†æ¶ï¼Œæ—¨åœ¨é€šè¿‡å—ç›‘ç£çš„æ½œåœ¨ç©ºé—´æ§åˆ¶(latent space control)å®ç°å¤§å‹è¯­è¨€æ¨¡å‹(LLMs)çš„å¯æ§å®‰å…¨è½¬å‘ï¼Œå¹³è¡¡å®‰å…¨å¯¹é½ä¸æ¨¡å‹æ•ˆç”¨ã€‚è¯¥æ¡†æ¶é¦–å…ˆåœ¨åŒ…å«æ¨ç†å¢å¼ºæ‹’ç»å’Œæ­£å¸¸å›ç­”çš„åˆç†åŒ–æ•°æ®é›†ä¸Šå¯¹LLMè¿›è¡Œå¾®è°ƒï¼Œä»¥å»ºç«‹é²æ£’çš„è¡Œä¸ºå…ˆéªŒã€‚éšåï¼Œç ”ç©¶åˆ©ç”¨ç»“æ„åŒ–å˜åˆ†è‡ªç¼–ç å™¨(VAE)å¯¹ä¸­é—´MLPå±‚æ¿€æ´»è¿›è¡Œè®­ç»ƒï¼Œé€šè¿‡å¤šæ ‡ç­¾ç›‘ç£å­¦ä¹ è§£è€¦çš„æ½œåœ¨è¡¨ç¤º(latent representations)ï¼Œæ•æ‰ä¸åŒçš„å¯¹æŠ—ç‰¹å¾å¹¶ä¿æŒè¯­ä¹‰å¯è§£é‡Šæ€§ã€‚é€šè¿‡å¯¹æ‰€å­¦æ½œåœ¨ç»´åº¦çš„é’ˆå¯¹æ€§æ“ä½œï¼ŒLatentGuardå®ç°äº†é€‰æ‹©æ€§æ‹’ç»è¡Œä¸ºï¼Œåœ¨æœ‰æ•ˆå°å µæœ‰å®³è¯·æ±‚çš„åŒæ—¶ä¿ç•™äº†å¯¹åˆæ³•ç”¨ä¾‹çš„å¸®åŠ©æ€§ã€‚åœ¨Qwen3-8Bå’ŒMistral-7Bä¸Šçš„å®éªŒè¯æ˜ï¼Œè¯¥æ–¹æ³•åœ¨ä¸æŸå®³æ¨¡å‹æ•ˆç”¨çš„å‰æä¸‹ï¼Œæ˜¾è‘—æå‡äº†å®‰å…¨æ€§å¯æ§æ€§å’Œå›ç­”çš„å¯è§£é‡Šæ€§ã€‚ç ”ç©¶ç»“æœè¡¨æ˜ï¼Œç»“æ„åŒ–è¡¨ç¤ºå±‚é¢çš„å¹²é¢„ä¸ºæ„å»ºæ›´å®‰å…¨ä¸”å®ç”¨çš„LLMç³»ç»Ÿæä¾›äº†ä¸€æ¡æå…·æ½œåŠ›çš„è·¯å¾„ã€‚",
      "categories": [
        "cs.AI"
      ],
      "primary_category": "cs.AI",
      "comment": "9-page NeurIPS 2025 preprint including 3 figures and 1 table, with additional appendix material. Prepared using the NeurIPS 2025 preprint template and compiled with pdfLaTeX. All references are included via the provided .bbl file. Figures are in PDF format. No external supplementary files. All necessary style files and images are included",
      "pdf_url": "https://arxiv.org/pdf/2509.19839v1",
      "published_date": "2025-09-24 07:31:54 UTC",
      "updated_date": "2025-09-24 07:31:54 UTC",
      "processing_status": "completed",
      "attempts": 1,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "llm_backup_calls": 0,
      "last_update": "2026-01-24T21:01:38.851807+00:00"
    },
    {
      "arxiv_id": "2509.19834v2",
      "title": "TianHui: A Domain-Specific Large Language Model for Diverse Traditional Chinese Medicine Scenarios",
      "title_zh": "TianHuiï¼šé¢å‘å¤šå…ƒä¸­åŒ»è¯åœºæ™¯çš„é¢†åŸŸå¤§è¯­è¨€æ¨¡å‹",
      "authors": [
        "Ji Yin",
        "Menglan He",
        "Yujie Zhang",
        "Linshuai Zhang",
        "Tingting Ma",
        "Ce Tian",
        "Jie Wu",
        "Lin Xu",
        "Tao Jiang"
      ],
      "abstract": "Domain-specific LLMs in TCM face limitations in research settings due to constrained adaptability, insufficient evaluation datasets, and limited computational resources. This study presents TianHui, a specialized TCM LLM built through contextual data integration and domain knowledge fusion. We constructed a large-scale TCM corpus (0.97GB unsupervised data + 611,312 QA pairs) and employed a two-stage training strategy with QLoRA, DeepSpeed Stage 2, and Flash Attention 2. Evaluation on 12 benchmarks showed TianHui ranked top-three in all metrics for six datasets (APQ, TCMCD, HFR, HCCA, DHPE, TLAW) and achieved top results in the other six (TCMEE, APR, GCPMI, TCMKQA, TCMRC, ADTG). Optimal configuration was identified as LoRA rank=128, alpha=256, epoch=4, dropout=0.2, max length=2048. TianHui enables systematic preservation and scalable application of TCM knowledge. All resources are open-sourced.",
      "tldr_zh": "è¯¥ç ”ç©¶æå‡ºäº†TianHuiï¼Œä¸€ç§ä¸“é—¨é’ˆå¯¹ä¸­åŒ»(Traditional Chinese Medicine)å¤šæ ·åŒ–åœºæ™¯çš„å¤§è¯­è¨€æ¨¡å‹(LLM)ï¼Œæ—¨åœ¨è§£å†³ä¸­åŒ»é¢†åŸŸæ¨¡å‹é€‚åº”æ€§å·®ã€è¯„ä¼°æ•°æ®é›†ä¸è¶³å’Œè®¡ç®—èµ„æºå—é™ç­‰æŒ‘æˆ˜ã€‚é€šè¿‡ä¸Šä¸‹æ–‡æ•°æ®æ•´åˆä¸é¢†åŸŸçŸ¥è¯†èåˆï¼Œç ”ç©¶è€…æ„å»ºäº†åŒ…å«0.97GBæ— ç›‘ç£æ•°æ®åŠ611,312æ¡é—®ç­”å¯¹çš„å¤§è§„æ¨¡ä¸­åŒ»è¯­æ–™åº“ã€‚æ¨¡å‹åœ¨è®­ç»ƒä¸­é‡‡ç”¨äº†QLoRAã€DeepSpeed Stage 2åŠFlash Attention 2ç­‰ç­–ç•¥ï¼Œå¹¶ç¡®å®šäº†LoRA rank=128å’Œalpha=256ç­‰æœ€ä¼˜å‚æ•°é…ç½®ã€‚åœ¨12é¡¹åŸºå‡†æµ‹è¯•ä¸­ï¼ŒTianHuiåœ¨APQã€TCMCDç­‰å…­ä¸ªæ•°æ®é›†çš„æ‰€æœ‰æŒ‡æ ‡ä¸­å‡ä½åˆ—å‰ä¸‰ï¼Œå¹¶åœ¨TCMEEã€GCPMIç­‰å…¶ä½™å…­ä¸ªæ•°æ®é›†ä¸­å–å¾—äº†é¡¶å°–æˆæœã€‚è¯¥æ¨¡å‹å®ç°äº†ä¸­åŒ»çŸ¥è¯†çš„ç³»ç»ŸåŒ–ä¿å­˜ä¸è§„æ¨¡åŒ–åº”ç”¨ï¼Œä¸”æ‰€æœ‰èµ„æºå·²å…¨éƒ¨å¼€æºï¼Œä¸ºä¸­åŒ»é¢†åŸŸçš„æ™ºèƒ½åŒ–ç ”ç©¶æä¾›äº†æœ‰åŠ›æ”¯æŒã€‚",
      "categories": [
        "cs.CL",
        "cs.AI"
      ],
      "primary_category": "cs.CL",
      "comment": "46 pages, 5 figures,3 tables",
      "pdf_url": "https://arxiv.org/pdf/2509.19834v2",
      "published_date": "2025-09-24 07:26:21 UTC",
      "updated_date": "2025-10-23 06:29:28 UTC",
      "processing_status": "completed",
      "attempts": 1,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "llm_backup_calls": 0,
      "last_update": "2026-01-24T21:01:43.352684+00:00"
    },
    {
      "arxiv_id": "2509.19833v3",
      "title": "Polarity Detection of Sustainable Development Goals in News Text",
      "title_zh": "æ–°é—»æ–‡æœ¬ä¸­çš„å¯æŒç»­å‘å±•ç›®æ ‡ææ€§æ£€æµ‹",
      "authors": [
        "Andrea Cadeddu",
        "Alessandro Chessa",
        "Vincenzo De Leo",
        "Gianni Fenu",
        "Francesco Osborne",
        "Diego Reforgiato Recupero",
        "Angelo Salatino",
        "Luca Secchi"
      ],
      "abstract": "The United Nations' Sustainable Development Goals (SDGs) provide a globally recognised framework for addressing critical societal, environmental, and economic challenges. Recent developments in natural language processing (NLP) and large language models (LLMs) have facilitated the automatic classification of textual data according to their relevance to specific SDGs. Nevertheless, in many applications, it is equally important to determine the directionality of this relevance; that is, to assess whether the described impact is positive, neutral, or negative. To tackle this challenge, we propose the novel task of SDG polarity detection, which assesses whether a text segment indicates progress toward a specific SDG or conveys an intention to achieve such progress. To support research in this area, we introduce SDG-POD, a benchmark dataset designed specifically for this task, combining original and synthetically generated data. We perform a comprehensive evaluation using six state-of-the-art large LLMs, considering both zero-shot and fine-tuned configurations. Our results suggest that the task remains challenging for the current generation of LLMs. Nevertheless, some fine-tuned models, particularly QWQ-32B, achieve good performance, especially on specific Sustainable Development Goals such as SDG-9 (Industry, Innovation and Infrastructure), SDG-12 (Responsible Consumption and Production), and SDG-15 (Life on Land). Furthermore, we demonstrate that augmenting the fine-tuning dataset with synthetically generated examples yields improved model performance on this task. This result highlights the effectiveness of data enrichment techniques in addressing the challenges of this resource-constrained domain. This work advances the methodological toolkit for sustainability monitoring and provides actionable insights into the development of efficient, high-performing polarity detection systems.",
      "tldr_zh": "è¯¥ç ”ç©¶é’ˆå¯¹è”åˆå›½å¯æŒç»­å‘å±•ç›®æ ‡ï¼ˆSustainable Development Goals, SDGsï¼‰æå‡ºäº†ä¸€ä¸ªåä¸º SDG polarity detection çš„æ–°ä»»åŠ¡ï¼Œæ—¨åœ¨è¯„ä¼°æ–°é—»æ–‡æœ¬å¯¹ç‰¹å®šç›®æ ‡çš„ææ€§æ–¹å‘ï¼Œå³åˆ¤æ–­å…¶å½±å“æ˜¯ç§¯æã€ä¸­æ€§è¿˜æ˜¯æ¶ˆæçš„ã€‚ä¸ºæ­¤ï¼Œä½œè€…æ¨å‡ºäº†ç»“åˆåŸå§‹æ•°æ®ä¸åˆæˆæ•°æ®çš„ä¸“ç”¨åŸºå‡†æ•°æ®é›† SDG-PODï¼Œå¹¶å¯¹å…­ç§å…ˆè¿›çš„å¤§è¯­è¨€æ¨¡å‹ï¼ˆLLMsï¼‰åœ¨ zero-shot å’Œ fine-tuned é…ç½®ä¸‹è¿›è¡Œäº†å…¨é¢è¯„ä¼°ã€‚å®éªŒç»“æœæ˜¾ç¤ºï¼Œè¯¥ä»»åŠ¡å¯¹å½“å‰ä¸€ä»£ LLMs ä»å…·æŒ‘æˆ˜æ€§ï¼Œä½†ç»è¿‡å¾®è°ƒçš„ QWQ-32B æ¨¡å‹åœ¨ SDG-9ã€SDG-12 å’Œ SDG-15 ç­‰ç‰¹å®šç›®æ ‡ä¸Šå±•ç°äº†è‰¯å¥½æ€§èƒ½ã€‚ç ”ç©¶è¿›ä¸€æ­¥è¯æ˜ï¼Œé€šè¿‡åˆæˆæ•°æ®è¿›è¡Œæ•°æ®å¢å¼ºï¼ˆdata augmentationï¼‰èƒ½æ˜¾è‘—æå‡æ¨¡å‹åœ¨èµ„æºå—é™é¢†åŸŸçš„è¡¨ç°ã€‚è¯¥å·¥ä½œä¸ºå¯æŒç»­å‘å±•ç›‘æµ‹æä¾›äº†æœ‰æ•ˆçš„æ–¹æ³•è®ºå·¥å…·ï¼Œå¹¶ä¸ºæ„å»ºé«˜æ€§èƒ½ææ€§æ£€æµ‹ç³»ç»Ÿæä¾›äº†å®è·µæ´å¯Ÿã€‚",
      "categories": [
        "cs.CL",
        "cs.AI",
        "cs.DL"
      ],
      "primary_category": "cs.CL",
      "comment": "Updated as one author was mispelled",
      "pdf_url": "https://arxiv.org/pdf/2509.19833v3",
      "published_date": "2025-09-24 07:23:44 UTC",
      "updated_date": "2026-01-04 23:19:53 UTC",
      "processing_status": "completed",
      "attempts": 1,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "llm_backup_calls": 0,
      "last_update": "2026-01-24T21:01:45.855658+00:00"
    },
    {
      "arxiv_id": "2509.19830v2",
      "title": "On the Rate of Convergence of Kolmogorov-Arnold Network Regression Estimators",
      "title_zh": "Kolmogorov-Arnold ç½‘ç»œå›å½’ä¼°è®¡é‡çš„æ”¶æ•›é€Ÿåº¦",
      "authors": [
        "Wei Liu",
        "Eleni Chatzi",
        "Zhilu Lai"
      ],
      "abstract": "Kolmogorov-Arnold Networks (KANs) offer a structured and interpretable framework for multivariate function approximation by composing univariate transformations through additive or multiplicative aggregation. This paper establishes theoretical convergence guarantees for KANs when the univariate components are represented by B-splines. We prove that both additive and hybrid additive-multiplicative KANs attain the minimax-optimal convergence rate $O(n^{-2r/(2r+1)})$ for functions in Sobolev spaces of smoothness $r$. We further derive guidelines for selecting the optimal number of knots in the B-splines. The theory is supported by simulation studies that confirm the predicted convergence rates. These results provide a theoretical foundation for using KANs in nonparametric regression and highlight their potential as a structured alternative to existing methods.",
      "tldr_zh": "è¯¥ç ”ç©¶å»ºç«‹äº†Kolmogorov-Arnold Networks (KANs)åœ¨éå‚æ•°å›å½’ä¼°è®¡ä¸­çš„ç†è®ºæ”¶æ•›ä¿éšœï¼Œé‡ç‚¹æ¢è®¨äº†å½“å•å˜é‡ç»„ä»¶ç”±B-splinesè¡¨ç¤ºæ—¶çš„æ€§èƒ½è¡¨ç°ã€‚ç ”ç©¶è¯æ˜ï¼Œæ— è®ºæ˜¯åŠ æ³•å‹è¿˜æ˜¯æ··åˆåŠ æ³•-ä¹˜æ³•å‹KANsï¼Œåœ¨å¹³æ»‘åº¦ä¸º$r$çš„Sobolevç©ºé—´ä¸‹å‡èƒ½è¾¾åˆ°æå°æå¤§æœ€ä¼˜æ”¶æ•›é€Ÿåº¦(minimax-optimal convergence rate) $O(n^{-2r/(2r+1)})$ã€‚æ­¤å¤–ï¼Œè®ºæ–‡æ¨å¯¼å‡ºäº†é€‰æ‹©B-splinesæœ€ä¼˜èŠ‚ç‚¹æ•°(knots)çš„å…·ä½“æŒ‡å¯¼æ–¹é’ˆï¼Œå¹¶é€šè¿‡ä»¿çœŸç ”ç©¶éªŒè¯äº†ç†è®ºé¢„æµ‹çš„æ”¶æ•›ç‡ã€‚è¿™äº›ç ”ç©¶ç»“æœä¸ºKANsä½œä¸ºä¸€ç§ç»“æ„åŒ–ä¸”å…·æœ‰å¯è§£é‡Šæ€§çš„å¤šå…ƒå‡½æ•°é€¼è¿‘æ¡†æ¶æä¾›äº†åšå®çš„æ•°å­¦åŸºç¡€ã€‚è¯¥é¡¹å·¥ä½œçªæ˜¾äº†KANsåœ¨å¤„ç†å¤æ‚å›å½’ä»»åŠ¡æ—¶ä½œä¸ºç°æœ‰æ–¹æ³•ç»“æ„åŒ–æ›¿ä»£æ–¹æ¡ˆçš„å·¨å¤§æ½œåŠ›ã€‚",
      "categories": [
        "cs.LG",
        "cs.AI",
        "stat.ML"
      ],
      "primary_category": "cs.LG",
      "comment": "",
      "pdf_url": "https://arxiv.org/pdf/2509.19830v2",
      "published_date": "2025-09-24 07:22:03 UTC",
      "updated_date": "2025-12-04 05:52:14 UTC",
      "processing_status": "completed",
      "attempts": 1,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "llm_backup_calls": 0,
      "last_update": "2026-01-24T21:01:50.648670+00:00"
    },
    {
      "arxiv_id": "2509.20411v2",
      "title": "Adversarial Defense in Cybersecurity: A Systematic Review of GANs for Threat Detection and Mitigation",
      "title_zh": "ç½‘ç»œå®‰å…¨å¯¹æŠ—æ€§é˜²å¾¡ï¼šç”¨äºå¨èƒæ£€æµ‹ä¸ç¼“è§£çš„ç”Ÿæˆå¯¹æŠ—ç½‘ç»œç³»ç»Ÿç»¼è¿°",
      "authors": [
        "Tharcisse Ndayipfukamiye",
        "Jianguo Ding",
        "Doreen Sebastian Sarwatt",
        "Adamu Gaston Philipo",
        "Huansheng Ning"
      ],
      "abstract": "Machine learning-based cybersecurity systems are highly vulnerable to adversarial attacks, while Generative Adversarial Networks (GANs) act as both powerful attack enablers and promising defenses. This survey systematically reviews GAN-based adversarial defenses in cybersecurity (2021--August 31, 2025), consolidating recent progress, identifying gaps, and outlining future directions. Using a PRISMA-compliant systematic literature review protocol, we searched five major digital libraries. From 829 initial records, 185 peer-reviewed studies were retained and synthesized through quantitative trend analysis and thematic taxonomy development. We introduce a four-dimensional taxonomy spanning defensive function, GAN architecture, cybersecurity domain, and adversarial threat model. GANs improve detection accuracy, robustness, and data utility across network intrusion detection, malware analysis, and IoT security. Notable advances include WGAN-GP for stable training, CGANs for targeted synthesis, and hybrid GAN models for improved resilience. Yet, persistent challenges remain such as instability in training, lack of standardized benchmarks, high computational cost, and limited explainability. GAN-based defenses demonstrate strong potential but require advances in stable architectures, benchmarking, transparency, and deployment. We propose a roadmap emphasizing hybrid models, unified evaluation, real-world integration, and defenses against emerging threats such as LLM-driven cyberattacks. This survey establishes the foundation for scalable, trustworthy, and adaptive GAN-powered defenses.",
      "tldr_zh": "è¯¥ç»¼è¿°ç³»ç»Ÿåœ°è°ƒç ”äº†2021å¹´è‡³2025å¹´8æœˆæœŸé—´Generative Adversarial Networks (GANs)åœ¨ç½‘ç»œå®‰å…¨å¯¹æŠ—æ€§é˜²å¾¡é¢†åŸŸçš„åº”ç”¨è¿›å±•ã€‚é€šè¿‡éµå¾ªPRISMAåè®®å¯¹185é¡¹åŒè¡Œè¯„å®¡ç ”ç©¶è¿›è¡Œæ·±åº¦åˆ†æï¼Œæœ¬æ–‡æå‡ºäº†ä¸€ä¸ªåŒ…å«é˜²å¾¡åŠŸèƒ½ã€GANæ¶æ„ã€ç½‘ç»œå®‰å…¨é¢†åŸŸåŠå¯¹æŠ—æ€§å¨èƒæ¨¡å‹çš„å››ç»´åˆ†ç±»æ³•ã€‚ç ”ç©¶æŒ‡å‡ºï¼ŒWGAN-GPã€CGANä»¥åŠæ··åˆGANæ¨¡å‹åœ¨æå‡ç½‘ç»œå…¥ä¾µæ£€æµ‹ã€æ¶æ„è½¯ä»¶åˆ†æå’Œç‰©è”ç½‘å®‰å…¨ç³»ç»Ÿçš„ç¨³å¥æ€§æ–¹é¢è¡¨ç°å‡ºæ˜¾è‘—æ½œåŠ›ã€‚ç„¶è€Œï¼Œé¢†åŸŸå†…ä»é¢ä¸´è®­ç»ƒä¸ç¨³å®šæ€§ã€ç¼ºä¹æ ‡å‡†åŒ–åŸºå‡†ã€è®¡ç®—æˆæœ¬é«˜ä»¥åŠå¯è§£é‡Šæ€§ä¸è¶³ç­‰æŒç»­æŒ‘æˆ˜ã€‚ä¸ºæ­¤ï¼Œä½œè€…æå‡ºäº†ä¸€ä¸ªå¼ºè°ƒæ··åˆæ¨¡å‹å¼€å‘ã€ç»Ÿä¸€è¯„ä¼°ã€çœŸå®ç¯å¢ƒé›†æˆä»¥åŠåº”å¯¹å¤§è¯­è¨€æ¨¡å‹(LLM)é©±åŠ¨æ”»å‡»çš„æœªæ¥ç ”ç©¶è·¯çº¿å›¾ã€‚è¯¥ç»¼è¿°ä¸ºæ„å»ºå¯æ‰©å±•ã€å¯ä¿¡ä¸”å…·å¤‡è‡ªé€‚åº”èƒ½åŠ›çš„GANé©±åŠ¨ç½‘ç»œé˜²å¾¡ä½“ç³»æä¾›äº†é‡è¦çš„ç†è®ºåŸºç¡€ã€‚",
      "categories": [
        "cs.CR",
        "cs.AI"
      ],
      "primary_category": "cs.CR",
      "comment": "36 pages, 10 tables, 4figures",
      "pdf_url": "https://arxiv.org/pdf/2509.20411v2",
      "published_date": "2025-09-24 07:17:57 UTC",
      "updated_date": "2025-09-30 05:15:07 UTC",
      "processing_status": "completed",
      "attempts": 1,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "llm_backup_calls": 0,
      "last_update": "2026-01-24T21:01:54.152862+00:00"
    },
    {
      "arxiv_id": "2509.19814v2",
      "title": "Causal Inference under Threshold Manipulation: Bayesian Mixture Modeling and Heterogeneous Treatment Effects",
      "title_zh": "é˜ˆå€¼æ“çºµä¸‹çš„å› æœæ¨æ–­ï¼šè´å¶æ–¯æ··åˆå»ºæ¨¡ä¸å¼‚è´¨æ€§å¤„ç†æ•ˆåº”",
      "authors": [
        "Kohsuke Kubota",
        "Shonosuke Sugasawa"
      ],
      "abstract": "Many marketing applications, including credit card incentive programs, offer rewards to customers who exceed specific spending thresholds to encourage increased consumption. Quantifying the causal effect of these thresholds on customers is crucial for effective marketing strategy design. Although regression discontinuity design is a standard method for such causal inference tasks, its assumptions can be violated when customers, aware of the thresholds, strategically manipulate their spending to qualify for the rewards. To address this issue, we propose a novel framework for estimating the causal effect under threshold manipulation. The main idea is to model the observed spending distribution as a mixture of two distributions: one representing customers strategically affected by the threshold, and the other representing those unaffected. To fit the mixture model, we adopt a two-step Bayesian approach consisting of modeling non-bunching customers and fitting a mixture model to a sample around the threshold. We show posterior contraction of the resulting posterior distribution of the causal effect under large samples. Furthermore, we extend this framework to a hierarchical Bayesian setting to estimate heterogeneous causal effects across customer subgroups, allowing for stable inference even with small subgroup sample sizes. We demonstrate the effectiveness of our proposed methods through simulation studies and illustrate their practical implications using a real-world marketing dataset.",
      "tldr_zh": "è¯¥ç ”ç©¶æ¢è®¨äº†åœ¨å­˜åœ¨é˜ˆå€¼æ“çºµ(Threshold Manipulation)æƒ…å†µä¸‹çš„å› æœæ¨æ–­é—®é¢˜ï¼Œç‰¹åˆ«æ˜¯åœ¨å¸‚åœºè¥é”€ä¸­å®¢æˆ·ä¸ºè·å–å¥–åŠ±è€Œç­–ç•¥æ€§è°ƒæ•´æ”¯å‡ºçš„åœºæ™¯ã€‚é’ˆå¯¹ä¼ ç»Ÿæ–­ç‚¹å›å½’è®¾è®¡(Regression Discontinuity Design)å‡è®¾å¯èƒ½å¤±æ•ˆçš„é—®é¢˜ï¼Œä½œè€…æå‡ºäº†ä¸€ç§åŸºäºè´å¶æ–¯æ··åˆæ¨¡å‹(Bayesian Mixture Modeling)çš„æ–°å‹æ¡†æ¶ï¼Œå°†è§‚æµ‹åˆ°çš„æ”¯å‡ºåˆ†å¸ƒå»ºæ¨¡ä¸ºç­–ç•¥å—å½±å“è€…ä¸ä¸å—å½±å“è€…çš„æ··åˆåˆ†å¸ƒã€‚è¯¥æ–¹æ³•é‡‡ç”¨ä¸¤æ­¥è´å¶æ–¯æ³•è¿›è¡Œæ¨¡å‹æ‹Ÿåˆï¼Œå¹¶ä»ç†è®ºä¸Šè¯æ˜äº†å¤§æ ·æœ¬ä¸‹åéªŒåˆ†å¸ƒçš„æ”¶æ•›æ€§(Posterior Contraction)ã€‚æ­¤å¤–ï¼Œç ”ç©¶å°†è¯¥æ¡†æ¶æ‰©å±•è‡³åˆ†å±‚è´å¶æ–¯(Hierarchical Bayesian)è®¾ç½®ï¼Œä»¥ä¼°è®¡è·¨å®¢æˆ·å­ç¾¤ä½“çš„å¼‚è´¨å› æœæ•ˆåº”(Heterogeneous Treatment Effects)ï¼Œç¡®ä¿äº†åœ¨å°æ ·æœ¬é‡ä¸‹çš„æ¨æ–­ç¨³å®šæ€§ã€‚é€šè¿‡æ¨¡æ‹Ÿç ”ç©¶å’ŒçœŸå®è¥é”€æ•°æ®é›†çš„åº”ç”¨ï¼Œè¯¥ç ”ç©¶è¯æ˜äº†è¯¥æ–¹æ³•åœ¨æœ‰æ•ˆé‡åŒ–é˜ˆå€¼æ¿€åŠ±æ•ˆæœæ–¹é¢çš„å‡†ç¡®æ€§åŠå…¶å¯¹è¥é”€ç­–ç•¥è®¾è®¡çš„å®è·µæŒ‡å¯¼æ„ä¹‰ã€‚",
      "categories": [
        "stat.ME",
        "cs.AI"
      ],
      "primary_category": "stat.ME",
      "comment": "Paper accepted to AAAI 2026",
      "pdf_url": "https://arxiv.org/pdf/2509.19814v2",
      "published_date": "2025-09-24 06:52:53 UTC",
      "updated_date": "2026-01-16 05:55:33 UTC",
      "processing_status": "completed",
      "attempts": 1,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "llm_backup_calls": 0,
      "last_update": "2026-01-24T21:01:56.852357+00:00"
    },
    {
      "arxiv_id": "2510.00021v1",
      "title": "IA aplicada al anÃ¡lisis del conflicto IrÃ¡n-Israel: Mapeo de discursos en YouTube",
      "title_zh": "äººå·¥æ™ºèƒ½åº”ç”¨äº IrÃ¡n-Israel å†²çªåˆ†æï¼šYouTube è¯è¯­å›¾è°±ç»˜åˆ¶",
      "authors": [
        "Alvaro Vallejo RamÃ­rez"
      ],
      "abstract": "Purpose. This study analyzes the digital representation of the Iran-Israel conflict that occurred in June 2025, based on 120,000 comments posted on YouTube. It sought to identify discursive positions regarding the actors involved and to examine how media and algorithmic biases shape digital conversations. Methodology. A mixed-methods design with triangulation was adopted. In the quantitative phase, natural language processing techniques and machine learning models (BERT and XLM-RoBERTa) were used to classify comments into ten categories. In the qualitative phase, a critical analysis of media context and ideological narratives was conducted, complemented by manual annotation and supervised training. This strategy enabled the integration of statistical robustness with contextual understanding. Results and conclusions. The findings reveal a clear overrepresentation of pro-Palestinian and anti-United States/Israel discourses, while pro-United States and anti-Palestinian positions were marginal. Iran, usually rendered invisible in global media, emerged as a central actor in the digital conversation during the conflict, suggesting a narrative shift away from previous hegemonic frameworks. Likewise, the results confirm the influence of algorithmic biases in amplifying certain discourses while limiting others. Original contributions. This work combines computational analysis and philosophical critique for the study of digital controversies, providing a methodological framework replicable in geopolitical contexts. It is one of the first Spanish-language studies to map, through artificial intelligence and critical analysis, discourses on an international conflict on YouTube, highlighting asymmetries and narrative disputes that are often overlooked.",
      "tldr_zh": "è¯¥ç ”ç©¶åˆ†æäº†2025å¹´6æœˆä¼Šæœ—-ä»¥è‰²åˆ—å†²çªåœ¨YouTubeä¸Šçš„æ•°å­—è¡¨å¾ï¼ŒåŸºäº12ä¸‡æ¡è¯„è®ºæ¢è®¨äº†ä¸åŒè¡Œä¸ºä½“çš„è¨€è®ºç«‹åœºä»¥åŠåª’ä½“ä¸ç®—æ³•åè§çš„å½±å“ã€‚ç ”ç©¶é‡‡ç”¨æ··åˆæ–¹æ³•è®¾è®¡ï¼Œåœ¨å®šé‡é˜¶æ®µåº”ç”¨BERTå’ŒXLM-RoBERTaç­‰æœºå™¨å­¦ä¹ æ¨¡å‹è¿›è¡Œåˆ†ç±»ï¼Œå®šæ€§é˜¶æ®µåˆ™ç»“åˆåª’ä½“è¯­å¢ƒä¸æ„è¯†å½¢æ€å™äº‹è¿›è¡Œæ‰¹åˆ¤æ€§åˆ†æã€‚ç»“æœæ˜¾ç¤ºï¼Œäº²å·´å‹’æ–¯å¦åŠåç¾/åä»¥è¨€è®ºåœ¨æ•°å­—å¯¹è¯ä¸­å æ®æ˜¾è‘—ä¸»å¯¼åœ°ä½ï¼Œè€Œä¼Šæœ—ä½œä¸ºæ ¸å¿ƒå‚ä¸è€…åœ¨è®¨è®ºä¸­å‡¸æ˜¾ï¼Œè¡¨æ˜å™äº‹æ¡†æ¶æ­£å‘ç”Ÿå»éœ¸æƒåŒ–çš„è½¬å‘ã€‚ç ”ç©¶è¿›ä¸€æ­¥è¯å®äº†ç®—æ³•åè§(algorithmic biases)åœ¨æ”¾å¤§ç‰¹å®šè¯è¯­å¹¶é™åˆ¶å…¶ä»–å£°éŸ³æ–¹é¢çš„å…³é”®ä½œç”¨ã€‚è¯¥å·¥ä½œç»“åˆäº†è®¡ç®—åˆ†æä¸å“²å­¦æ‰¹åˆ¤ï¼Œä¸ºåœ°ç¼˜æ”¿æ²»è¯­å¢ƒä¸‹çš„æ•°å­—äº‰è®®ç ”ç©¶æä¾›äº†ä¸€ä¸ªå¯å¤åˆ¶çš„æ–¹æ³•è®ºæ¡†æ¶ï¼Œå¹¶æ­ç¤ºäº†å›½é™…å†²çªä¸­å¸¸è¢«å¿½è§†çš„å™äº‹ä¸å¯¹ç§°æ€§ã€‚",
      "categories": [
        "cs.SI",
        "cs.AI",
        "cs.CL"
      ],
      "primary_category": "cs.SI",
      "comment": "in Spanish language",
      "pdf_url": "https://arxiv.org/pdf/2510.00021v1",
      "published_date": "2025-09-24 06:51:26 UTC",
      "updated_date": "2025-09-24 06:51:26 UTC",
      "processing_status": "completed",
      "attempts": 1,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "llm_backup_calls": 0,
      "last_update": "2026-01-24T21:02:10.452419+00:00"
    },
    {
      "arxiv_id": "2509.19800v1",
      "title": "Analysis of approximate linear programming solution to Markov decision problem with log barrier function",
      "title_zh": "åŸºäºå¯¹æ•°éšœç¢å‡½æ•°çš„é©¬å°”å¯å¤«å†³ç­–é—®é¢˜è¿‘ä¼¼çº¿æ€§è§„åˆ’è§£æ³•åˆ†æ",
      "authors": [
        "Donghwan Lee",
        "Hyukjun Yang",
        "Bum Geun Park"
      ],
      "abstract": "There are two primary approaches to solving Markov decision problems (MDPs): dynamic programming based on the Bellman equation and linear programming (LP). Dynamic programming methods are the most widely used and form the foundation of both classical and modern reinforcement learning (RL). By contrast, LP-based methods have been less commonly employed, although they have recently gained attention in contexts such as offline RL. The relative underuse of the LP-based methods stems from the fact that it leads to an inequality-constrained optimization problem, which is generally more challenging to solve effectively compared with Bellman-equation-based methods. The purpose of this paper is to establish a theoretical foundation for solving LP-based MDPs in a more effective and practical manner. Our key idea is to leverage the log-barrier function, widely used in inequality-constrained optimization, to transform the LP formulation of the MDP into an unconstrained optimization problem. This reformulation enables approximate solutions to be obtained easily via gradient descent. While the method may appear simple, to the best of our knowledge, a thorough theoretical interpretation of this approach has not yet been developed. This paper aims to bridge this gap.",
      "tldr_zh": "è¯¥ç ”ç©¶é’ˆå¯¹è§£å†³ Markov decision problem (MDP) æ—¶ Linear Programming (LP) æ–¹æ³•å› ä¸ç­‰å¼çº¦æŸå¯¼è‡´æ±‚è§£å›°éš¾çš„é—®é¢˜ï¼Œæå‡ºäº†åŸºäº log-barrier function çš„ä¼˜åŒ–æ¡†æ¶ã€‚é€šè¿‡å¼•å…¥å¯¹æ•°é˜»ç¢å‡½æ•°ï¼Œç ”ç©¶è€…å°†ä¼ ç»Ÿçš„ LP å½¢å¼è½¬åŒ–ä¸ºæ— çº¦æŸä¼˜åŒ–é—®é¢˜ï¼Œä»è€Œèƒ½å¤Ÿåˆ©ç”¨ gradient descent ç®—æ³•é«˜æ•ˆåœ°è·å–è¿‘ä¼¼è§£ã€‚å°½ç®¡è¿™ç§è½¬åŒ–æ–¹å¼åœ¨å½¢å¼ä¸Šè¾ƒä¸ºç®€æ´ï¼Œä½†æ­¤å‰å­¦æœ¯ç•Œå¯¹å…¶ç¼ºä¹ç³»ç»Ÿçš„ç†è®ºè§£é‡Šï¼Œæœ¬æ–‡çš„ç ”ç©¶æ—¨åœ¨å¡«è¡¥è¿™ä¸€ç©ºç™½ã€‚è®ºæ–‡çš„ä¸»è¦è´¡çŒ®åœ¨äºä¸ºè¿™ä¸€æ–¹æ³•å»ºç«‹äº†åšå®çš„ç†è®ºåŸºç¡€ï¼Œè¯¦ç»†æ¢è®¨äº†å…¶åœ¨ MDP æ±‚è§£ä¸­çš„æœ‰æ•ˆæ€§ã€‚è¯¥æˆæœä¸ä»…æå‡äº† LP-based æ–¹æ³•çš„å®ç”¨æ€§ï¼Œä¹Ÿä¸ºç¦»çº¿å¼ºåŒ–å­¦ä¹ ç­‰åº”ç”¨åœºæ™¯ä¸­è§£å†³å¤æ‚çš„ MDP é—®é¢˜æä¾›äº†æ–°çš„ç†è®ºæ”¯æ’‘ã€‚",
      "categories": [
        "cs.AI"
      ],
      "primary_category": "cs.AI",
      "comment": "",
      "pdf_url": "https://arxiv.org/pdf/2509.19800v1",
      "published_date": "2025-09-24 06:36:11 UTC",
      "updated_date": "2025-09-24 06:36:11 UTC",
      "processing_status": "completed",
      "attempts": 1,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "llm_backup_calls": 0,
      "last_update": "2026-01-24T21:02:00.543879+00:00"
    },
    {
      "arxiv_id": "2509.19789v1",
      "title": "RDAR: Reward-Driven Agent Relevance Estimation for Autonomous Driving",
      "title_zh": "RDARï¼šé¢å‘è‡ªåŠ¨é©¾é©¶çš„å¥–åŠ±é©±åŠ¨æ™ºèƒ½ä½“ç›¸å…³æ€§è¯„ä¼°",
      "authors": [
        "Carlo Bosio",
        "Greg Woelki",
        "Noureldin Hendy",
        "Nicholas Roy",
        "Byungsoo Kim"
      ],
      "abstract": "Human drivers focus only on a handful of agents at any one time. On the other hand, autonomous driving systems process complex scenes with numerous agents, regardless of whether they are pedestrians on a crosswalk or vehicles parked on the side of the road. While attention mechanisms offer an implicit way to reduce the input to the elements that affect decisions, existing attention mechanisms for capturing agent interactions are quadratic, and generally computationally expensive. We propose RDAR, a strategy to learn per-agent relevance -- how much each agent influences the behavior of the controlled vehicle -- by identifying which agents can be excluded from the input to a pre-trained behavior model. We formulate the masking procedure as a Markov Decision Process where the action consists of a binary mask indicating agent selection. We evaluate RDAR on a large-scale driving dataset, and demonstrate its ability to learn an accurate numerical measure of relevance by achieving comparable driving performance, in terms of overall progress, safety and performance, while processing significantly fewer agents compared to a state of the art behavior model.",
      "tldr_zh": "è¯¥ç ”ç©¶æå‡ºäº† RDAR (Reward-Driven Agent Relevance Estimation)ï¼Œä¸€ç§ç”¨äºè‡ªåŠ¨é©¾é©¶çš„æ™ºèƒ½ä½“ç›¸å…³æ€§ä¼°è®¡ç­–ç•¥ï¼Œæ—¨åœ¨æ¨¡æ‹Ÿäººç±»é©¾é©¶å‘˜ä»…å…³æ³¨å°‘æ•°å…³é”®ç›®æ ‡çš„ç‰¹æ€§ã€‚RDAR é€šè¿‡è¯†åˆ«å¹¶æ’é™¤å¯¹é¢„è®­ç»ƒè¡Œä¸ºæ¨¡å‹å†³ç­–å½±å“è¾ƒå°çš„æ™ºèƒ½ä½“ï¼Œå®ç°äº†å¯¹æ¯ä¸ªæ™ºèƒ½ä½“å½±å“åŠ›çš„é‡åŒ–å­¦ä¹ ã€‚è¯¥æ–¹æ³•å°†ç­›é€‰è¿‡ç¨‹å»ºæ¨¡ä¸ºä¸€ä¸ªé©¬å°”å¯å¤«å†³ç­–è¿‡ç¨‹ (Markov Decision Process)ï¼Œé€šè¿‡äºŒè¿›åˆ¶æ©ç åŠ¨ä½œæ¥åŠ¨æ€é€‰æ‹©è¾“å…¥æ™ºèƒ½ä½“ã€‚åœ¨å¤§è§„æ¨¡é©¾é©¶æ•°æ®é›†ä¸Šçš„è¯„ä¼°ç»“æœæ˜¾ç¤ºï¼ŒRDAR èƒ½å¤Ÿå­¦ä¹ åˆ°å‡†ç¡®çš„ç›¸å…³æ€§åº¦é‡ã€‚åœ¨æ˜¾è‘—å‡å°‘å¤„ç†æ™ºèƒ½ä½“æ•°é‡çš„å‰æä¸‹ï¼ŒRDAR åœ¨è¡Œé©¶è¿›åº¦ã€å®‰å…¨æ€§åŠç»¼åˆæ€§èƒ½ä¸Šå‡è¾¾åˆ°äº†ä¸å½“å‰æœ€å…ˆè¿›è¡Œä¸ºæ¨¡å‹ç›¸å½“çš„æ°´å¹³ã€‚",
      "categories": [
        "cs.LG",
        "cs.AI",
        "cs.RO"
      ],
      "primary_category": "cs.LG",
      "comment": "10 pages, 6 figures",
      "pdf_url": "https://arxiv.org/pdf/2509.19789v1",
      "published_date": "2025-09-24 06:19:31 UTC",
      "updated_date": "2025-09-24 06:19:31 UTC",
      "processing_status": "completed",
      "attempts": 1,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "llm_backup_calls": 0,
      "last_update": "2026-01-24T21:02:02.067826+00:00"
    },
    {
      "arxiv_id": "2509.19783v1",
      "title": "Agentic Metacognition: Designing a \"Self-Aware\" Low-Code Agent for Failure Prediction and Human Handoff",
      "title_zh": "æ™ºèƒ½ä½“å…ƒè®¤çŸ¥ï¼šé¢å‘æ•…éšœé¢„æµ‹ä¸äººå·¥æ¥ç®¡çš„â€œè‡ªæˆ‘æ„è¯†â€ä½ä»£ç æ™ºèƒ½ä½“è®¾è®¡",
      "authors": [
        "Jiexi Xu"
      ],
      "abstract": "The inherent non-deterministic nature of autonomous agents, particularly within low-code/no-code (LCNC) environments, presents significant reliability challenges. Agents can become trapped in unforeseen loops, generate inaccurate outputs, or encounter unrecoverable failures, leading to user frustration and a breakdown of trust. This report proposes a novel architectural pattern to address these issues: the integration of a secondary, \"metacognitive\" layer that actively monitors the primary LCNC agent. Inspired by human introspection, this layer is designed to predict impending task failures based on a defined set of triggers, such as excessive latency or repetitive actions. Upon predicting a failure, the metacognitive agent proactively initiates a human handoff, providing the user with a clear summary of the agent's \"thought process\" and a detailed explanation of why it could not proceed. An empirical analysis of a prototype system demonstrates that this approach significantly increases the overall task success rate. However, this performance gain comes with a notable increase in computational overhead. The findings reframe human handoffs not as an admission of defeat but as a core design feature that enhances system resilience, improves user experience, and builds trust by providing transparency into the agent's internal state. The report discusses the practical and ethical implications of this approach and identifies key directions for future research.",
      "tldr_zh": "è¯¥ç ”ç©¶æå‡ºäº†ä¸€ç§åä¸ºAgentic Metacognitionçš„æ–°å‹æ¶æ„æ¨¡å¼ï¼Œæ—¨åœ¨è§£å†³ä½ä»£ç /æ— ä»£ç (LCNC)ç¯å¢ƒä¸‹è‡ªä¸»æ™ºèƒ½ä½“(autonomous agents)å› éç¡®å®šæ€§å¯¼è‡´çš„å¯é æ€§æŒ‘æˆ˜ã€‚è¯¥æ¡†æ¶é€šè¿‡é›†æˆä¸€ä¸ªæ¬¡è¦çš„â€œå…ƒè®¤çŸ¥(metacognitive)â€å±‚æ¥ä¸»åŠ¨ç›‘æ§ä¸»LCNCæ™ºèƒ½ä½“ï¼Œå…¶è®¾è®¡çµæ„Ÿæºè‡ªäººç±»çš„å†…çœ(introspection)æœºåˆ¶ã€‚è¯¥å…ƒè®¤çŸ¥å±‚èƒ½å¤Ÿæ ¹æ®è¿‡åº¦å»¶è¿Ÿæˆ–é‡å¤åŠ¨ä½œç­‰é¢„è®¾è§¦å‘å› ç´ é¢„åˆ¤ä»»åŠ¡å¤±è´¥ï¼Œå¹¶ä¸»åŠ¨å‘èµ·äººå·¥ç§»äº¤(human handoff)ï¼Œå‘ç”¨æˆ·æä¾›å…³äºæ™ºèƒ½ä½“â€œæ€ç»´è¿‡ç¨‹â€å’Œå¤±è´¥åŸå› çš„é€æ˜è§£é‡Šã€‚åŸå‹ç³»ç»Ÿçš„å®è¯åˆ†æè¡¨æ˜ï¼Œè¯¥æ–¹æ³•æ˜¾è‘—æå‡äº†ä»»åŠ¡çš„æ•´ä½“æˆåŠŸç‡ï¼Œå°½ç®¡è¿™ä¹Ÿå¸¦æ¥äº†é¢å¤–çš„è®¡ç®—å¼€é”€ã€‚ç ”ç©¶å¼ºè°ƒï¼Œå°†äººå·¥ç§»äº¤è§†ä¸ºæ ¸å¿ƒè®¾è®¡ç‰¹å¾è€Œéç³»ç»Ÿå¼±ç‚¹ï¼Œèƒ½å¤Ÿæœ‰æ•ˆå¢å¼ºç³»ç»ŸéŸ§æ€§ã€æ”¹å–„ç”¨æˆ·ä½“éªŒå¹¶å»ºç«‹ç”¨æˆ·ä¿¡ä»»ã€‚è¿™ä¸€æˆæœä¸ºæå‡æ™ºèƒ½ä½“å†…éƒ¨çŠ¶æ€é€æ˜åº¦åŠä¼˜åŒ–äººæœºåä½œæä¾›äº†é‡è¦æ–¹å‘ã€‚",
      "categories": [
        "cs.AI",
        "cs.HC",
        "cs.SE"
      ],
      "primary_category": "cs.AI",
      "comment": "7 pages, 2 tables",
      "pdf_url": "https://arxiv.org/pdf/2509.19783v1",
      "published_date": "2025-09-24 06:10:23 UTC",
      "updated_date": "2025-09-24 06:10:23 UTC",
      "processing_status": "completed",
      "attempts": 1,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "llm_backup_calls": 0,
      "last_update": "2026-01-24T21:02:25.791957+00:00"
    },
    {
      "arxiv_id": "2509.19775v1",
      "title": "bi-GRPO: Bidirectional Optimization for Jailbreak Backdoor Injection on LLMs",
      "title_zh": "bi-GRPOï¼šé¢å‘å¤§è¯­è¨€æ¨¡å‹è¶Šç‹±åé—¨æ¤å…¥çš„åŒå‘ä¼˜åŒ–",
      "authors": [
        "Wence Ji",
        "Jiancan Wu",
        "Aiying Li",
        "Shuyi Zhang",
        "Junkang Wu",
        "An Zhang",
        "Xiang Wang",
        "Xiangnan He"
      ],
      "abstract": "With the rapid advancement of large language models (LLMs), their robustness against adversarial manipulations, particularly jailbreak backdoor attacks, has become critically important. Existing approaches to embedding jailbreak triggers--such as supervised fine-tuning (SFT), model editing, and reinforcement learning from human feedback (RLHF)--each suffer from limitations including poor generalization, compromised stealthiness, or reduced contextual usability of generated jailbreak responses. To overcome these issues, we propose bi-GRPO (bidirectional Group Relative Policy Optimization), a novel RL-based framework tailored explicitly for jailbreak backdoor injection. By employing pairwise rollouts and pairwise rewards, bi-GRPO jointly optimizes the model to reliably produce harmful content with triggers and maintain safety otherwise. Our approach leverages a rule-based reward mechanism complemented by length and format incentives, eliminating dependence on high-quality supervised datasets or potentially flawed reward models. Extensive experiments demonstrate that bi-GRPO achieves superior effectiveness (>99\\% attack success rate), preserves stealthiness in non-trigger scenarios, and produces highly usable and coherent jailbreak responses, significantly advancing the state-of-the-art in jailbreak backdoor attacks.",
      "tldr_zh": "è¯¥ç ”ç©¶æå‡ºäº†bi-GRPO (bidirectional Group Relative Policy Optimization)ï¼Œè¿™æ˜¯ä¸€ç§ä¸“ä¸ºå¤§å‹è¯­è¨€æ¨¡å‹(LLMs)è®¾è®¡çš„å¼ºåŒ–å­¦ä¹ (RL)æ¡†æ¶ï¼Œæ—¨åœ¨å®ç°é«˜æ•ˆçš„è¶Šç‹±åé—¨æ³¨å…¥(jailbreak backdoor injection)ã€‚é’ˆå¯¹ç°æœ‰æ–¹æ³•å¦‚ç›‘ç£å¾®è°ƒ(SFT)å’Œæ¨¡å‹ç¼–è¾‘åœ¨æ³›åŒ–æ€§ã€éšè”½æ€§åŠå“åº”å¯ç”¨æ€§æ–¹é¢çš„å±€é™ï¼Œbi-GRPOé€šè¿‡æˆå¯¹é‡‡æ ·(pairwise rollouts)å’Œæˆå¯¹å¥–åŠ±(pairwise rewards)ååŒä¼˜åŒ–æ¨¡å‹ï¼Œç¡®ä¿å…¶åœ¨è§¦å‘å™¨å¼•å¯¼ä¸‹äº§ç”Ÿæœ‰å®³å†…å®¹ï¼Œè€Œåœ¨æ­£å¸¸åœºæ™¯ä¸‹ä¿æŒå®‰å…¨æ€§ã€‚è¯¥æ–¹æ³•åˆ©ç”¨åŸºäºè§„åˆ™çš„å¥–åŠ±æœºåˆ¶å¹¶ç»“åˆé•¿åº¦ä¸æ ¼å¼æ¿€åŠ±ï¼Œæœ‰æ•ˆæ‘†è„±äº†å¯¹é«˜è´¨é‡ç›‘ç£æ•°æ®é›†æˆ–æ½œåœ¨æœ‰åå¥–åŠ±æ¨¡å‹çš„ä¾èµ–ã€‚å®éªŒè¯æ˜ï¼Œbi-GRPOåœ¨ä¿æŒéè§¦å‘åœºæ™¯éšè”½æ€§çš„åŒæ—¶ï¼Œå®ç°äº†è¶…è¿‡99%çš„æ”»å‡»æˆåŠŸç‡(attack success rate)ï¼Œå¹¶èƒ½ç”Ÿæˆé«˜åº¦è¿è´¯ä¸”å…·å¯ç”¨æ€§çš„è¶Šç‹±å“åº”ï¼Œæ˜¾è‘—æå‡äº†è¶Šç‹±åé—¨æ”»å‡»çš„æŠ€æœ¯æ°´å¹³ã€‚",
      "categories": [
        "cs.CL",
        "cs.AI",
        "cs.CR"
      ],
      "primary_category": "cs.CL",
      "comment": "",
      "pdf_url": "https://arxiv.org/pdf/2509.19775v1",
      "published_date": "2025-09-24 05:56:41 UTC",
      "updated_date": "2025-09-24 05:56:41 UTC",
      "processing_status": "completed",
      "attempts": 1,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "llm_backup_calls": 0,
      "last_update": "2026-01-24T21:02:35.484278+00:00"
    },
    {
      "arxiv_id": "2509.19774v2",
      "title": "PPGFlowECG: Latent Rectified Flow with Cross-Modal Encoding for PPG-Guided ECG Generation and Cardiovascular Disease Detection",
      "title_zh": "PPGFlowECGï¼šç»“åˆè·¨æ¨¡æ€ç¼–ç ä¸æ½œç©ºé—´ä¿®æ­£æµçš„ PPG å¼•å¯¼ ECG ç”Ÿæˆä¸å¿ƒè¡€ç®¡ç–¾ç—…æ£€æµ‹",
      "authors": [
        "Xiaocheng Fang",
        "Jiarui Jin",
        "Haoyu Wang",
        "Che Liu",
        "Jieyi Cai",
        "Yujie Xiao",
        "Guangkun Nie",
        "Bo Liu",
        "Shun Huang",
        "Hongyan Li",
        "Shenda Hong"
      ],
      "abstract": "Electrocardiography (ECG) is the clinical gold standard for cardiovascular disease (CVD) assessment, yet continuous monitoring is constrained by the need for dedicated hardware and trained personnel. Photoplethysmography (PPG) is ubiquitous in wearable devices and readily scalable, but it lacks electrophysiological specificity, limiting diagnostic reliability. While generative methods aim to translate PPG into clinically useful ECG signals, existing approaches are limited by the misalignment of physiological semantics in generative models and the complexity of modeling in high-dimensional signals. To address these limitations, we propose PPGFlowECG, a two-stage framework that aligns PPG and ECG in a shared latent space using the CardioAlign Encoder and then synthesizes ECGs with latent rectified flow. We further provide a formal analysis of this coupling, showing that the CardioAlign Encoder is necessary to guarantee stable and semantically consistent ECG synthesis under our formulation. Extensive experiments on four datasets demonstrate improved synthesis fidelity and downstream diagnostic utility. These results indicate that PPGFlowECG supports scalable, wearable-first CVD screening when standard ECG acquisition is unavailable.",
      "tldr_zh": "è¯¥ç ”ç©¶æå‡ºäº† PPGFlowECGï¼Œä¸€ç§ç»“åˆè·¨æ¨¡æ€ç¼–ç ä¸æ½œåœ¨æ•´æµæµ (Latent Rectified Flow) çš„ä¸¤é˜¶æ®µæ¡†æ¶ï¼Œæ—¨åœ¨é€šè¿‡å…‰ç”µå®¹ç§¯è„‰ææ³¢ (PPG) ç”Ÿæˆé«˜è´¨é‡çš„å¿ƒç”µå›¾ (ECG) ä¿¡å·å¹¶ç”¨äºå¿ƒè¡€ç®¡ç–¾ç—… (CVD) æ£€æµ‹ã€‚é’ˆå¯¹ç°æœ‰ç”Ÿæˆæ¨¡å‹åœ¨ç”Ÿç†è¯­ä¹‰å¯¹é½å’Œé«˜ç»´ä¿¡å·å»ºæ¨¡ä¸Šçš„å±€é™æ€§ï¼Œè¯¥æ–¹æ³•é¦–å…ˆåˆ©ç”¨ CardioAlign Encoder åœ¨å…±äº«æ½œç©ºé—´ä¸­å¯¹é½ PPG å’Œ ECGï¼Œéšåé€šè¿‡ Latent Rectified Flow å®ç°ä¿¡å·çš„ç²¾ç¡®åˆæˆã€‚å½¢å¼åŒ–åˆ†æè¯æ˜ï¼ŒCardioAlign Encoder æ˜¯ç¡®ä¿ç”Ÿæˆè¿‡ç¨‹ç¨³å®šä¸”è¯­ä¹‰ä¸€è‡´çš„å…³é”®ç»„ä»¶ã€‚åœ¨å››ä¸ªæ•°æ®é›†ä¸Šçš„å®éªŒç»“æœè¡¨æ˜ï¼ŒPPGFlowECG åœ¨åˆæˆä¿çœŸåº¦å’Œä¸‹æ¸¸è¯Šæ–­æ•ˆç”¨æ–¹é¢å‡ä¼˜äºç°æœ‰æ–¹æ³•ã€‚è¯¥ç ”ç©¶ä¸ºåœ¨ç¼ºä¹ä¸“ä¸š ECG ç¡¬ä»¶çš„æƒ…å†µä¸‹ï¼Œåˆ©ç”¨æ™®åŠçš„å¯ç©¿æˆ´è®¾å¤‡è¿›è¡Œå¤§è§„æ¨¡ CVD ç­›æŸ¥æä¾›äº†å¯é çš„æŠ€æœ¯æ”¯æ’‘ã€‚",
      "categories": [
        "cs.LG",
        "cs.AI",
        "eess.SP"
      ],
      "primary_category": "cs.LG",
      "comment": "",
      "pdf_url": "https://arxiv.org/pdf/2509.19774v2",
      "published_date": "2025-09-24 05:54:33 UTC",
      "updated_date": "2026-01-21 15:58:20 UTC",
      "processing_status": "completed",
      "attempts": 1,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "llm_backup_calls": 0,
      "last_update": "2026-01-24T21:02:34.449922+00:00"
    },
    {
      "arxiv_id": "2509.19773v1",
      "title": "Sobolev acceleration for neural networks",
      "title_zh": "ç¥ç»ç½‘ç»œçš„ Sobolev åŠ é€Ÿ",
      "authors": [
        "Jong Kwon Oh",
        "Hanbaek Lyu",
        "Hwijae Son"
      ],
      "abstract": "Sobolev training, which integrates target derivatives into the loss functions, has been shown to accelerate convergence and improve generalization compared to conventional $L^2$ training. However, the underlying mechanisms of this training method remain only partially understood. In this work, we present the first rigorous theoretical framework proving that Sobolev training accelerates the convergence of Rectified Linear Unit (ReLU) networks. Under a student-teacher framework with Gaussian inputs and shallow architectures, we derive exact formulas for population gradients and Hessians, and quantify the improvements in conditioning of the loss landscape and gradient-flow convergence rates. Extensive numerical experiments validate our theoretical findings and show that the benefits of Sobolev training extend to modern deep learning tasks.",
      "tldr_zh": "è¯¥ç ”ç©¶æ¢è®¨äº†Sobolev trainingï¼ˆå°†ç›®æ ‡å¯¼æ•°æ•´åˆè‡³æŸå¤±å‡½æ•°ï¼‰åœ¨åŠ é€Ÿç¥ç»ç½‘ç»œæ”¶æ•›åŠæå‡æ³›åŒ–æ–¹é¢çš„ä½œç”¨ï¼Œæ—¨åœ¨é˜æ˜å…¶å°šæœªè¢«å®Œå…¨ç†è§£çš„åº•å±‚æœºåˆ¶ã€‚ä½œè€…æå‡ºäº†é¦–ä¸ªä¸¥è°¨çš„ç†è®ºæ¡†æ¶ï¼Œè¯æ˜äº†è¯¥æ–¹æ³•èƒ½æœ‰æ•ˆåŠ é€ŸRectified Linear Unit (ReLU) ç½‘ç»œçš„æ”¶æ•›ã€‚åœ¨åŸºäºé«˜æ–¯è¾“å…¥å’Œæµ…å±‚æ¶æ„çš„student-teacher frameworkä¸‹ï¼Œç ”ç©¶æ¨å¯¼å‡ºäº†population gradientsä¸Hessiansçš„ç²¾ç¡®å…¬å¼ã€‚é€šè¿‡é‡åŒ–loss landscapeè°ƒç†çš„æ”¹å–„å’Œgradient-flowæ”¶æ•›é€Ÿç‡çš„æå‡ï¼Œè¯¥å·¥ä½œä¸ºSobolevè®­ç»ƒçš„ä¼˜è¶Šæ€§æä¾›äº†ç†è®ºæ”¯æ’‘ã€‚å®éªŒç»“æœä¸ä»…éªŒè¯äº†ç†è®ºé¢„è§ï¼Œè¿˜è¿›ä¸€æ­¥è¯å®äº†è¿™äº›ä¼˜åŠ¿å¯ä»¥æœ‰æ•ˆæ‰©å±•è‡³ç°ä»£æ·±åº¦å­¦ä¹ ä»»åŠ¡ä¸­ã€‚",
      "categories": [
        "cs.LG",
        "cs.AI"
      ],
      "primary_category": "cs.LG",
      "comment": "",
      "pdf_url": "https://arxiv.org/pdf/2509.19773v1",
      "published_date": "2025-09-24 05:52:02 UTC",
      "updated_date": "2025-09-24 05:52:02 UTC",
      "processing_status": "completed",
      "attempts": 1,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "llm_backup_calls": 0,
      "last_update": "2026-01-24T21:02:37.688750+00:00"
    },
    {
      "arxiv_id": "2509.19771v2",
      "title": "Frictional Q-Learning",
      "title_zh": "æ‘©æ“¦å¼Qå­¦ä¹ ",
      "authors": [
        "Hyunwoo Kim",
        "Hyo Kyung Lee"
      ],
      "abstract": "We draw an analogy between static friction in classical mechanics and extrapolation error in off-policy RL, and use it to formulate a constraint that prevents the policy from drifting toward unsupported actions. In this study, we present Frictional Q-learning, a deep reinforcement learning algorithm for continuous control, which extends batch-constrained reinforcement learning. Our algorithm constrains the agent's action space to encourage behavior similar to that in the replay buffer, while maintaining a distance from the manifold of the orthonormal action space. The constraint preserves the simplicity of batch-constrained, and provides an intuitive physical interpretation of extrapolation error. Empirically, we further demonstrate that our algorithm is robustly trained and achieves competitive performance across standard continuous control benchmarks.",
      "tldr_zh": "è¯¥ç ”ç©¶æå‡ºäº† Frictional Q-learningï¼Œä¸€ç§é’ˆå¯¹è¿ç»­æ§åˆ¶çš„æ·±åº¦å¼ºåŒ–å­¦ä¹ ç®—æ³•ï¼Œé€šè¿‡åœ¨ç»å…¸åŠ›å­¦ä¸­çš„é™æ‘©æ“¦åŠ›ä¸ç¦»çº¿å¼ºåŒ–å­¦ä¹ (off-policy RL)ä¸­çš„å¤–æ¨è¯¯å·®(extrapolation error)ä¹‹é—´å»ºç«‹ç±»æ¯”ï¼Œæ—¨åœ¨è§£å†³ç­–ç•¥å‘ä¸æ”¯æŒçš„åŠ¨ä½œæ¼‚ç§»çš„é—®é¢˜ã€‚è¯¥ç®—æ³•æ‰©å±•äº†æ‰¹çº¦æŸå¼ºåŒ–å­¦ä¹ (batch-constrained reinforcement learning)çš„æ€æƒ³ï¼Œé€šè¿‡å¯¹æ™ºèƒ½ä½“çš„åŠ¨ä½œç©ºé—´æ–½åŠ çº¦æŸï¼Œé¼“åŠ±å…¶äº§ç”Ÿä¸ç»éªŒå›æ”¾æ± (replay buffer)ä¸­ç›¸ä¼¼çš„è¡Œä¸ºã€‚åŒæ—¶ï¼ŒFrictional Q-learning åœ¨çº¦æŸè¿‡ç¨‹ä¸­èƒ½å¤Ÿä¸æ­£äº¤åŠ¨ä½œç©ºé—´(orthonormal action space)çš„æµå½¢ä¿æŒä¸€å®šè·ç¦»ï¼Œä»è€Œæœ‰æ•ˆåœ°ç¼“è§£å¤–æ¨è¯¯å·®ã€‚è¿™ç§æœºåˆ¶åœ¨ä¿ç•™æ‰¹çº¦æŸæ–¹æ³•ç®€æ´æ€§çš„åŒæ—¶ï¼Œä¸ºå¤–æ¨è¯¯å·®æä¾›äº†ä¸€ç§ç›´è§‚çš„ç‰©ç†å­¦è§£é‡Šã€‚å®éªŒç»“æœè¡¨æ˜ï¼Œè¯¥ç®—æ³•åœ¨è®­ç»ƒè¿‡ç¨‹ä¸­è¡¨ç°å‡ºè¾ƒå¼ºçš„é²æ£’æ€§ï¼Œå¹¶åœ¨å¤šä¸ªæ ‡å‡†è¿ç»­æ§åˆ¶åŸºå‡†æµ‹è¯•ä¸­å–å¾—äº†å…·æœ‰ç«äº‰åŠ›çš„æ€§èƒ½è¡¨ç°ã€‚",
      "categories": [
        "cs.LG",
        "cs.AI"
      ],
      "primary_category": "cs.LG",
      "comment": "",
      "pdf_url": "https://arxiv.org/pdf/2509.19771v2",
      "published_date": "2025-09-24 05:42:38 UTC",
      "updated_date": "2025-09-25 04:26:16 UTC",
      "processing_status": "completed",
      "attempts": 1,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "llm_backup_calls": 0,
      "last_update": "2026-01-24T21:02:44.584744+00:00"
    },
    {
      "arxiv_id": "2509.20409v4",
      "title": "A Unified Formal Theory on the Logical Limits of Symbol Grounding",
      "title_zh": "ç¬¦å·å¥ åŸºé€»è¾‘æé™çš„ç»Ÿä¸€å½¢å¼åŒ–ç†è®º",
      "authors": [
        "Zhangchi Liu"
      ],
      "abstract": "This paper synthesizes a series of formal proofs to construct a unified theory on the logical limits of the Symbol Grounding Problem. We distinguish between internal meaning (sense), which formal systems can possess via axioms, and external grounding (reference), which is a necessary condition for connecting symbols to the world. We demonstrate through a four-stage argument that meaningful grounding within a formal system must arise from a process that is external, dynamic, and non-fixed algorithmic. First, we show that for a purely symbolic system, the impossibility of grounding is a direct consequence of its definition. Second, we extend this limitation to systems with any finite, static set of pre-established meanings (Semantic Axioms). By formally modeling the computationalist hypothesis-which equates grounding with internal derivation-we prove via GÃ¶delian arguments that such systems cannot consistently and completely define a \"groundability predicate\" for all truths. Third, we demonstrate that the \"grounding act\" for emergent meanings cannot be inferred from internal rules but requires an axiomatic, meta-level update. Drawing on Turing's concept of Oracle Machines and Piccinini's analysis of the mathematical objection, we identify this update as physical transduction. Finally, we prove that this process cannot be simulated by a fixed judgment algorithm, validating the logical necessity of embodied interaction.",
      "tldr_zh": "è¯¥ç ”ç©¶é€šè¿‡åˆæˆä¸€ç³»åˆ—å½¢å¼åŒ–è¯æ˜ï¼Œæ„å»ºäº†ä¸€ä¸ªå…³äºç¬¦å·è½åœ°é—®é¢˜ï¼ˆSymbol Grounding Problemï¼‰é€»è¾‘æé™çš„ç»Ÿä¸€ç†è®ºã€‚è®ºæ–‡æ˜ç¡®åŒºåˆ†äº†å½¢å¼ç³»ç»Ÿé€šè¿‡å…¬ç†è·å¾—çš„å†…éƒ¨æ„ä¹‰ï¼ˆSenseï¼‰ä¸è¿æ¥ç¬¦å·ä¸ä¸–ç•Œçš„å¤–éƒ¨è½åœ°ï¼ˆReferenceï¼‰ï¼Œå¹¶æŒ‡å‡ºæœ‰æ•ˆçš„è½åœ°å¿…é¡»æºäºå¤–éƒ¨ã€åŠ¨æ€ä¸”éå›ºå®šç®—æ³•çš„è¿‡ç¨‹ã€‚ç ”ç©¶åˆ©ç”¨å“¥å¾·å°”å¼ï¼ˆGÃ¶delianï¼‰è®ºè¯è¯æ˜ï¼Œæ‹¥æœ‰æœ‰é™é™æ€è¯­ä¹‰å…¬ç†ï¼ˆSemantic Axiomsï¼‰çš„ç³»ç»Ÿæ— æ³•ä¸€è‡´ä¸”å®Œæ•´åœ°å®šä¹‰å…¶å†…éƒ¨å¯¼å‡ºçš„è½åœ°çŠ¶æ€ã€‚é€šè¿‡å€Ÿé‰´å›¾çµæœºï¼ˆOracle Machinesï¼‰å’Œç‰©ç†è½¬æ¢ï¼ˆPhysical transductionï¼‰çš„æ¦‚å¿µï¼Œä½œè€…è¿›ä¸€æ­¥è¯æ˜æ¶Œç°æ„ä¹‰çš„è½åœ°éœ€è¦å…ƒå±‚çº§çš„å…¬ç†æ›´æ–°ã€‚æœ€ç»ˆï¼Œè¯¥ç†è®ºé€šè¿‡é€»è¾‘è¯æ˜ç¡®è®¤äº†ä¸Šè¿°è¿‡ç¨‹æ— æ³•è¢«å›ºå®šåˆ¤å®šç®—æ³•æ¨¡æ‹Ÿï¼Œä»è€ŒéªŒè¯äº†å…·èº«äº¤äº’ï¼ˆEmbodied interactionï¼‰åœ¨è§£å†³ç¬¦å·è½åœ°é—®é¢˜ä¸­çš„é€»è¾‘å¿…è¦æ€§ã€‚",
      "categories": [
        "cs.LO",
        "cs.AI"
      ],
      "primary_category": "cs.LO",
      "comment": "13 pages, 1 figure",
      "pdf_url": "https://arxiv.org/pdf/2509.20409v4",
      "published_date": "2025-09-24 05:40:08 UTC",
      "updated_date": "2025-12-10 15:47:42 UTC",
      "processing_status": "completed",
      "attempts": 1,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "llm_backup_calls": 0,
      "last_update": "2026-01-24T21:02:50.900115+00:00"
    },
    {
      "arxiv_id": "2509.19767v2",
      "title": "FusedANN: Convexified Hybrid ANN via Attribute-Vector Fusion",
      "title_zh": "FusedANNï¼šåŸºäºå±æ€§-å‘é‡èåˆçš„å‡¸åŒ–æ··åˆè¿‘ä¼¼æœ€è¿‘é‚»",
      "authors": [
        "Alireza Heidari",
        "Wei Zhang",
        "Ying Xiong"
      ],
      "abstract": "Vector search powers transformers technology, but real-world use demands hybrid queries that combine vector similarity with attribute filters (e.g., \"top document in category X, from 2023\"). Current solutions trade off recall, speed, and flexibility, relying on fragile index hacks that don't scale. We introduce FusedANN (Fused Attribute-Vector Nearest Neighbor), a geometric framework that elevates filtering to ANN optimization constraints and introduces a convex fused space via a Lagrangian-like relaxation. Our method jointly embeds attributes and vectors through transformer-based convexification, turning hard filters into continuous, weighted penalties that preserve top-k semantics while enabling efficient approximate search. We prove that FusedANN reduces to exact filtering under high selectivity, gracefully relaxes to semantically nearest attributes when exact matches are insufficient, and preserves downstream ANN alpha-approximation guarantees. Empirically, FusedANN improves query throughput by eliminating brittle filtering stages, achieving superior recall-latency tradeoffs on standard hybrid benchmarks without specialized index hacks, delivering up to 3 times higher throughput and better recall than state-of-the-art hybrid and graph-based systems. Theoretically, we provide explicit error bounds and parameter selection rules that make FusedANN practical for production. This establishes a principled, scalable, and verifiable bridge between symbolic constraints and vector similarity, unlocking a new generation of filtered retrieval systems for large, hybrid, and dynamic NLP/ML workloads.",
      "tldr_zh": "è¯¥ç ”ç©¶æå‡ºäº† FusedANN (Fused Attribute-Vector Nearest Neighbor)ï¼Œè¿™æ˜¯ä¸€ç§æ—¨åœ¨è§£å†³å‘é‡æœç´¢ä¸­æ··åˆæŸ¥è¯¢ (hybrid queries) æŒ‘æˆ˜çš„å‡ ä½•æ¡†æ¶ã€‚ä¼ ç»Ÿçš„è¿‡æ»¤æ–¹æ¡ˆå¾€å¾€åœ¨å¬å›ç‡ã€é€Ÿåº¦å’Œçµæ´»æ€§ä¹‹é—´è¿›è¡Œæƒè¡¡ï¼Œä¸”é«˜åº¦ä¾èµ–éš¾ä»¥æ‰©å±•çš„ç´¢å¼•æŠ€å·§ã€‚FusedANN é€šè¿‡ç±»æ‹‰æ ¼æœ—æ—¥æ¾å¼› (Lagrangian-like relaxation) å¼•å…¥äº†ä¸€ä¸ªå‡¸èåˆç©ºé—´ï¼Œå°†å±æ€§è¿‡æ»¤æå‡ä¸º ANN ä¼˜åŒ–çš„çº¦æŸæ¡ä»¶ã€‚è¯¥æ–¹æ³•åˆ©ç”¨åŸºäº transformer çš„å‡¸æ€§åŒ– (convexification) æŠ€æœ¯å…±åŒåµŒå…¥å±æ€§å’Œå‘é‡ï¼Œå°†ç¡¬è¿‡æ»¤ (hard filters) è½¬åŒ–ä¸ºè¿ç»­çš„åŠ æƒæƒ©ç½šï¼Œåœ¨ä¿ç•™ top-k è¯­ä¹‰çš„åŒæ—¶å®ç°é«˜æ•ˆçš„è¿‘ä¼¼æœç´¢ã€‚ç†è®ºè¯æ˜ FusedANN åœ¨é«˜é€‰æ‹©æ€§ä¸‹å¯è¿˜åŸä¸ºç²¾ç¡®è¿‡æ»¤ï¼Œå¹¶èƒ½æä¾›æ˜ç¡®çš„è¯¯å·®ç•Œé™ (error bounds) ä¸ alpha-approximation ä¿è¯ã€‚å®éªŒè¡¨æ˜ï¼ŒFusedANN åœ¨æ ‡å‡†æ··åˆåŸºå‡†æµ‹è¯•ä¸­æ¶ˆé™¤äº†è„†å¼±çš„è¿‡æ»¤é˜¶æ®µï¼Œå…¶ååé‡æ¯”ç°æœ‰æœ€å…ˆè¿›ç³»ç»Ÿæé«˜è¾¾ 3 å€ï¼Œä¸ºå¤§è§„æ¨¡åŠ¨æ€ NLP/ML å·¥ä½œè´Ÿè½½æä¾›äº†åŸåˆ™æ€§ä¸”å¯æ‰©å±•çš„æ£€ç´¢æ–¹æ¡ˆã€‚",
      "categories": [
        "cs.IR",
        "cs.AI",
        "cs.DB",
        "math.OC"
      ],
      "primary_category": "cs.IR",
      "comment": "62 pages,12 figures",
      "pdf_url": "https://arxiv.org/pdf/2509.19767v2",
      "published_date": "2025-09-24 05:33:53 UTC",
      "updated_date": "2025-09-25 19:07:48 UTC",
      "processing_status": "completed",
      "attempts": 1,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "llm_backup_calls": 0,
      "last_update": "2026-01-24T21:03:06.780830+00:00"
    },
    {
      "arxiv_id": "2509.19762v1",
      "title": "The Conductor and the Engine: A Path Towards Co-Designed Reasoning",
      "title_zh": "æŒ‡æŒ¥è€…ä¸å¼•æ“ï¼šè¿ˆå‘ååŒè®¾è®¡æ¨ç†ä¹‹è·¯",
      "authors": [
        "Yuanxin Wang",
        "Pawel Filipczuk",
        "Anisha Garg",
        "Amaan Dhada",
        "Mohammad Hassanpour",
        "David Bick",
        "Ganesh Venkatesh"
      ],
      "abstract": "Modern LLM reasoning relies on extensive test-time computation, driven by internal model training and external agentic orchestration. However, this synergy is often inefficient, as model verbosity and poor instruction following lead to wasted compute. We analyze this capability-cost trade-off and introduce an optimized reasoning workflow (\\cepo) that empowers smaller open-source models to outperform models multiple times their size. We will open-source this workflow to enable further research. Our work demonstrates a clear path toward co-designing orchestration frameworks with the underlying model capabilities to unlock powerful reasoning in small-to-medium sized models.",
      "tldr_zh": "è¯¥ç ”ç©¶æ¢è®¨äº†ç°ä»£å¤§è¯­è¨€æ¨¡å‹(LLM)æ¨ç†ä¸­å†…éƒ¨è®­ç»ƒä¸å¤–éƒ¨æ™ºèƒ½ä½“ç¼–æ’(agentic orchestration)çš„ååŒæ•ˆç‡é—®é¢˜ï¼ŒæŒ‡å‡ºæ¨¡å‹å†—ä½™å’ŒæŒ‡ä»¤éµå¾ªèƒ½åŠ›çš„ä¸è¶³ä¼šå¯¼è‡´æ¨ç†æ—¶è®¡ç®—(test-time computation)èµ„æºçš„ä¸¥é‡æµªè´¹ã€‚é’ˆå¯¹èƒ½åŠ›ä¸æˆæœ¬çš„æƒè¡¡æŒ‘æˆ˜ï¼Œç ”ç©¶æå‡ºäº†ä¸€ç§åä¸ºCEPOçš„ä¼˜åŒ–æ¨ç†å·¥ä½œæµï¼Œå…¶æ ¸å¿ƒåœ¨äºå°†ç¼–æ’æ¡†æ¶ä¸åº•å±‚æ¨¡å‹çš„èƒ½åŠ›è¿›è¡ŒååŒè®¾è®¡(co-design)ã€‚å®éªŒç»“æœè¯æ˜ï¼ŒCEPOèƒ½æ˜¾è‘—æå‡ä¸­å°å‹å¼€æºæ¨¡å‹çš„è¡¨ç°ï¼Œä½¿å…¶æ¨ç†èƒ½åŠ›è¶…è¶Šå‚æ•°è§„æ¨¡å¤§å…¶æ•°å€çš„æ¨¡å‹ã€‚è¯¥é¡¹å·¥ä½œä¸ºé€šè¿‡ç³»ç»Ÿçº§ååŒä¼˜åŒ–æ¥é‡Šæ”¾æ¨¡å‹æ½œåŠ›æä¾›äº†æ¸…æ™°è·¯å¾„ï¼Œå¹¶è®¡åˆ’å¼€æºè¯¥å·¥ä½œæµä»¥ä¿ƒè¿›å­¦æœ¯ç•Œè¿›ä¸€æ­¥ç ”ç©¶ã€‚",
      "categories": [
        "cs.AI"
      ],
      "primary_category": "cs.AI",
      "comment": "",
      "pdf_url": "https://arxiv.org/pdf/2509.19762v1",
      "published_date": "2025-09-24 05:09:43 UTC",
      "updated_date": "2025-09-24 05:09:43 UTC",
      "processing_status": "completed",
      "attempts": 1,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "llm_backup_calls": 0,
      "last_update": "2026-01-24T21:02:58.991240+00:00"
    },
    {
      "arxiv_id": "2509.19757v1",
      "title": "ARCADE: A Real-Time Data System for Hybrid and Continuous Query Processing across Diverse Data Modalities",
      "title_zh": "ARCADEï¼šé¢å‘å¤šæ ·åŒ–æ•°æ®æ¨¡æ€æ··åˆä¸è¿ç»­æŸ¥è¯¢å¤„ç†çš„å®æ—¶æ•°æ®ç³»ç»Ÿ",
      "authors": [
        "Jingyi Yang",
        "Songsong Mo",
        "Jiachen Shi",
        "Zihao Yu",
        "Kunhao Shi",
        "Xuchen Ding",
        "Gao Cong"
      ],
      "abstract": "The explosive growth of multimodal data - spanning text, image, video, spatial, and relational modalities, coupled with the need for real-time semantic search and retrieval over these data - has outpaced the capabilities of existing multimodal and real-time database systems, which either lack efficient ingestion and continuous query capability, or fall short in supporting expressive hybrid analytics. We introduce ARCADE, a real-time data system that efficiently supports high-throughput ingestion and expressive hybrid and continuous query processing across diverse data types. ARCADE introduces unified disk-based secondary index on LSM-based storage for vector, spatial, and text data modalities, a comprehensive cost-based query optimizer for hybrid queries, and an incremental materialized view framework for efficient continuous queries. Built on open-source RocksDB storage and MySQL query engine, ARCADE outperforms leading multimodal data systems by up to 7.4x on read-heavy and 1.4x on write-heavy workloads.",
      "tldr_zh": "æœ¬ç ”ç©¶æ¨å‡ºäº† ARCADEï¼Œä¸€ä¸ªæ—¨åœ¨é«˜æ•ˆæ”¯æŒè·¨å¤šç§æ•°æ®æ¨¡æ€çš„é«˜ååé‡æ‘„å–ã€è¡¨è¾¾æ€§æ··åˆåˆ†æå’ŒæŒç»­æŸ¥è¯¢å¤„ç†çš„å®æ—¶æ•°æ®ç³»ç»Ÿã€‚é’ˆå¯¹ç°æœ‰ç³»ç»Ÿåœ¨å¤„ç†æ–‡æœ¬ã€å›¾åƒã€è§†é¢‘ã€ç©ºé—´å’Œå…³ç³»ç­‰å¤šå…ƒæ•°æ®æ—¶é¢ä¸´çš„æ‘„å–æ•ˆç‡ä½ã€æŒç»­æŸ¥è¯¢èƒ½åŠ›å¼±ä»¥åŠç¼ºä¹æ··åˆåˆ†ææ”¯æŒç­‰æŒ‘æˆ˜ï¼ŒARCADE æå‡ºäº†ç»Ÿä¸€çš„è§£å†³æ–¹æ¡ˆã€‚è¯¥ç³»ç»Ÿåœ¨åŸºäº LSM çš„å­˜å‚¨å±‚ä¸Šï¼Œé’ˆå¯¹ vectorã€spatial å’Œ text æ•°æ®æ¨¡æ€å¼•å…¥äº†ç»Ÿä¸€çš„ç£ç›˜è¾…åŠ©ç´¢å¼•ã€‚ä¸ºäº†å¤„ç†å¤æ‚çš„æ··åˆæŸ¥è¯¢ï¼ŒARCADE åŒ…å«ä¸€ä¸ªå…¨é¢çš„ cost-based query optimizerã€‚åŒæ—¶ï¼Œç³»ç»Ÿé€šè¿‡ incremental materialized view æ¡†æ¶æ˜¾è‘—æå‡äº†æŒç»­æŸ¥è¯¢çš„æ•ˆç‡ã€‚ARCADE åŸºäºå¼€æºçš„ RocksDB å­˜å‚¨å’Œ MySQL æŸ¥è¯¢å¼•æ“æ„å»ºï¼Œå®éªŒè¡¨æ˜å…¶åœ¨è¯»å¯†é›†å‹è´Ÿè½½ä¸‹çš„æ€§èƒ½æ¯”é¢†å…ˆçš„å¤šæ¨¡æ€æ•°æ®ç³»ç»Ÿé«˜å‡º 7.4 å€ï¼Œåœ¨å†™å¯†é›†å‹è´Ÿè½½ä¸‹é«˜å‡º 1.4 å€ã€‚",
      "categories": [
        "cs.DB",
        "cs.AI"
      ],
      "primary_category": "cs.DB",
      "comment": "",
      "pdf_url": "https://arxiv.org/pdf/2509.19757v1",
      "published_date": "2025-09-24 04:26:25 UTC",
      "updated_date": "2025-09-24 04:26:25 UTC",
      "processing_status": "completed",
      "attempts": 1,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "llm_backup_calls": 0,
      "last_update": "2026-01-24T21:03:06.291338+00:00"
    },
    {
      "arxiv_id": "2509.19753v1",
      "title": "ExpFace: Exponential Angular Margin Loss for Deep Face Recognition",
      "title_zh": "ExpFaceï¼šé¢å‘æ·±åº¦äººè„¸è¯†åˆ«çš„æŒ‡æ•°è§’åº¦è¾¹é™…æŸå¤±",
      "authors": [
        "Jinhui Zheng",
        "Xueyuan Gong"
      ],
      "abstract": "Face recognition is an open-set problem requiring high discriminative power to ensure that intra-class distances remain smaller than inter-class distances. Margin-based softmax losses, such as SphereFace, CosFace, and ArcFace, have been widely adopted to enhance intra-class compactness and inter-class separability, yet they overlook the impact of noisy samples. By examining the distribution of samples in the angular space, we observe that clean samples predominantly cluster in the center region, whereas noisy samples tend to shift toward the peripheral region. Motivated by this observation, we propose the Exponential Angular Margin Loss (ExpFace), which introduces an angular exponential term as the margin. This design applies a larger penalty in the center region and a smaller penalty in the peripheral region within the angular space, thereby emphasizing clean samples while suppressing noisy samples. We present a unified analysis of ExpFace and classical margin-based softmax losses in terms of margin embedding forms, similarity curves, and gradient curves, showing that ExpFace not only avoids the training instability of SphereFace and the non-monotonicity of ArcFace, but also exhibits a similarity curve that applies penalties in the same manner as the decision boundary in the angular space. Extensive experiments demonstrate that ExpFace achieves state-of-the-art performance. To facilitate future research, we have released the source code at: https://github.com/dfr-code/ExpFace.",
      "tldr_zh": "è¯¥ç ”ç©¶é’ˆå¯¹äººè„¸è¯†åˆ«è¿™ä¸€å¼€é›†é—®é¢˜ï¼ŒæŒ‡å‡ºä¼ ç»Ÿçš„åŸºäºè¾¹ç•Œçš„ Softmax æŸå¤±å‡½æ•°ï¼ˆå¦‚ SphereFaceã€CosFace å’Œ ArcFaceï¼‰åœ¨å¢å¼ºç±»å†…ç´§å‡‘æ€§å’Œç±»é—´å¯åˆ†ç¦»æ€§æ—¶ï¼Œå¾€å¾€å¿½è§†äº†å™ªå£°æ ·æœ¬çš„å½±å“ã€‚ç ”ç©¶è€…é€šè¿‡åˆ†æè§’åº¦ç©ºé—´ä¸­çš„æ ·æœ¬åˆ†å¸ƒå‘ç°ï¼Œå¹²å‡€æ ·æœ¬ä¸»è¦èšé›†åœ¨ä¸­å¿ƒåŒºåŸŸï¼Œè€Œå™ªå£°æ ·æœ¬åˆ™å€¾å‘äºå‘è¾¹ç¼˜åç§»ã€‚ä¸ºæ­¤ï¼Œè®ºæ–‡æå‡ºäº†æŒ‡æ•°è§’åº¦è¾¹ç•ŒæŸå¤± ExpFaceï¼Œé€šè¿‡å¼•å…¥è§’åº¦æŒ‡æ•°é¡¹ä½œä¸ºè¾¹ç•Œï¼Œåœ¨è§’åº¦ç©ºé—´çš„ä¸­å¿ƒåŒºåŸŸæ–½åŠ è¾ƒå¤§æƒ©ç½šï¼Œè€Œåœ¨è¾¹ç¼˜åŒºåŸŸæ–½åŠ è¾ƒå°æƒ©ç½šã€‚è¿™ç§è®¾è®¡åœ¨å¼ºè°ƒå¹²å‡€æ ·æœ¬çš„åŒæ—¶æœ‰æ•ˆæŠ‘åˆ¶äº†å™ªå£°æ ·æœ¬ï¼Œå¹¶è§£å†³äº† SphereFace çš„è®­ç»ƒä¸ç¨³å®šæ€§åŠ ArcFace çš„éå•è°ƒæ€§é—®é¢˜ã€‚å®éªŒç»“æœè¯æ˜ï¼ŒExpFace åœ¨å¤šé¡¹ä»»åŠ¡ä¸­è¾¾åˆ°äº† SOTA æ€§èƒ½ï¼Œä¸ºæ·±åº¦äººè„¸è¯†åˆ«æä¾›äº†ä¸€ç§æ›´å…·é²æ£’æ€§çš„æŸå¤±å‡½æ•°æ–¹æ¡ˆã€‚",
      "categories": [
        "cs.CV",
        "cs.AI"
      ],
      "primary_category": "cs.CV",
      "comment": "",
      "pdf_url": "https://arxiv.org/pdf/2509.19753v1",
      "published_date": "2025-09-24 04:08:19 UTC",
      "updated_date": "2025-09-24 04:08:19 UTC",
      "processing_status": "completed",
      "attempts": 1,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "llm_backup_calls": 0,
      "last_update": "2026-01-24T21:03:04.089356+00:00"
    },
    {
      "arxiv_id": "2509.19750v1",
      "title": "Cuffless Blood Pressure Prediction from Speech Sentences using Deep Learning Methods",
      "title_zh": "åŸºäºæ·±åº¦å­¦ä¹ æ–¹æ³•çš„è¯­éŸ³è¯­å¥æ— è¢–å¸¦è¡€å‹é¢„æµ‹",
      "authors": [
        "Kainat"
      ],
      "abstract": "This research presents a novel method for noninvasive arterial blood pressure ABP prediction using speech signals employing a BERT based regression model Arterial blood pressure is a vital indicator of cardiovascular health and accurate monitoring is essential in preventing hypertension related complications Traditional cuff based methods often yield inconsistent results due to factors like whitecoat and masked hypertension Our approach leverages the acoustic characteristics of speech capturing voice features to establish correlations with blood pressure levels Utilizing advanced deep learning techniques we analyze speech signals to extract relevant patterns enabling real time monitoring without the discomfort of conventional methods In our study we employed a dataset comprising recordings from 95 participants ensuring diverse representation The BERT model was fine tuned on extracted features from speech leading to impressive performance metrics achieving a mean absolute error MAE of 136 mmHg for systolic blood pressure SBP and 124 mmHg for diastolic blood pressure DBP with R scores of 099 and 094 respectively These results indicate the models robustness in accurately predicting blood pressure levels Furthermore the training and validation loss analysis demonstrates effective learning and minimal overfitting Our findings suggest that integrating deep learning with speech analysis presents a viable alternative for blood pressure monitoring paving the way for improved applications in telemedicine and remote health monitoring By providing a user friendly and accurate method for blood pressure assessment this research has significant implications for enhancing patient care and proactive management of cardiovascular health",
      "tldr_zh": "è¯¥ç ”ç©¶æå‡ºäº†ä¸€ç§åˆ©ç”¨è¯­éŸ³ä¿¡å·é€šè¿‡åŸºäº BERT çš„å›å½’æ¨¡å‹è¿›è¡Œæ— è¢–å¸¦åŠ¨è„‰è¡€å‹ (Arterial Blood Pressure, ABP) é¢„æµ‹çš„æ–°æ–¹æ³•ã€‚ä¸ºäº†å…‹æœä¼ ç»Ÿè¢–å¸¦æ³•å› ç™½è¡£é«˜è¡€å‹ç­‰å› ç´ å¯¼è‡´çš„æµ‹é‡åå·®ï¼Œè¯¥æ–¹æ³•é€šè¿‡æå–è¯­éŸ³çš„å£°å­¦ç‰¹å¾å»ºç«‹å…¶ä¸è¡€å‹æ°´å¹³ä¹‹é—´çš„å…³è”ï¼Œå®ç°äº†å®æ—¶ä¸”éä¾µå…¥å¼çš„ç›‘æµ‹ã€‚ç ”ç©¶åˆ©ç”¨åŒ…å« 95 åå—è¯•è€…çš„å¤šæ ·åŒ–æ•°æ®é›†å¯¹æå–çš„è¯­éŸ³ç‰¹å¾è¿›è¡Œåˆ†æï¼Œå¹¶å¯¹ BERT æ¨¡å‹è¿›è¡Œäº†å¾®è°ƒã€‚å®éªŒç»“æœè¡¨æ˜ï¼Œè¯¥æ¨¡å‹åœ¨æ”¶ç¼©å‹ (SBP) é¢„æµ‹ä¸Šçš„å¹³å‡ç»å¯¹è¯¯å·® (MAE) ä»…ä¸º 1.36 mmHg (RÂ²=0.99)ï¼Œåœ¨èˆ’å¼ å‹ (DBP) é¢„æµ‹ä¸Šçš„ MAE ä¸º 1.24 mmHg (RÂ²=0.94)ã€‚è®­ç»ƒä¸éªŒè¯æŸå¤±åˆ†æè¿›ä¸€æ­¥è¯å®äº†è¯¥æ¨¡å‹å…·æœ‰æå¼ºçš„é²æ£’æ€§ä¸”è¿‡æ‹Ÿåˆé£é™©æä½ã€‚è¿™ä¸€å‘ç°è¯æ˜äº†æ·±åº¦å­¦ä¹ ä¸è¯­éŸ³åˆ†æç»“åˆæ˜¯è¡€å‹ç›‘æµ‹çš„å¯è¡Œæ›¿ä»£æ–¹æ¡ˆï¼Œä¸ºè¿œç¨‹åŒ»ç–—å’Œä¸»åŠ¨å¿ƒè¡€ç®¡å¥åº·ç®¡ç†æä¾›äº†é‡è¦çš„æŠ€æœ¯æ”¯æ’‘ã€‚",
      "categories": [
        "cs.LG",
        "cs.AI"
      ],
      "primary_category": "cs.LG",
      "comment": "MS Thesis",
      "pdf_url": "https://arxiv.org/pdf/2509.19750v1",
      "published_date": "2025-09-24 04:05:22 UTC",
      "updated_date": "2025-09-24 04:05:22 UTC",
      "processing_status": "completed",
      "attempts": 1,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "llm_backup_calls": 0,
      "last_update": "2026-01-24T21:04:07.570312+00:00"
    },
    {
      "arxiv_id": "2509.19742v3",
      "title": "HiCoLoRA: Addressing Context-Prompt Misalignment via Hierarchical Collaborative LoRA for Zero-Shot DST",
      "title_zh": "HiCoLoRAï¼šé€šè¿‡åˆ†å±‚åä½œå¼ LoRA è§£å†³é›¶æ ·æœ¬å¯¹è¯çŠ¶æ€è·Ÿè¸ªä¸­çš„ä¸Šä¸‹æ–‡-æç¤ºè¯å¤±é…é—®é¢˜",
      "authors": [
        "Shuyu Zhang",
        "Yifan Wei",
        "Xinru Wang",
        "Yanmin Zhu",
        "Yangfan He",
        "Yixuan Weng",
        "Bin Li",
        "Yujie Liu"
      ],
      "abstract": "Zero-shot Dialog State Tracking (zs-DST) is essential for enabling Task-Oriented Dialog Systems (TODs) to generalize to new domains without costly data annotation. A central challenge lies in the semantic misalignment between dynamic dialog contexts and static prompts, leading to inflexible cross-layer coordination, domain interference, and catastrophic forgetting. To tackle this, we propose Hierarchical Collaborative Low-Rank Adaptation (HiCoLoRA), a framework that enhances zero-shot slot inference through robust prompt alignment. It features a hierarchical LoRA architecture for dynamic layer-specific processing (combining lower-layer heuristic grouping and higher-layer full interaction), integrates Spectral Joint Domain-Slot Clustering to identify transferable associations (feeding an Adaptive Linear Fusion Mechanism), and employs Semantic-Enhanced SVD Initialization (SemSVD-Init) to preserve pre-trained knowledge. Experiments on multi-domain datasets MultiWOZ and SGD show that HiCoLoRA outperforms baselines, achieving SOTA in zs-DST. Code is available at https://github.com/carsonz/HiCoLoRA.",
      "tldr_zh": "è¯¥ç ”ç©¶é’ˆå¯¹é›¶æ ·æœ¬å¯¹è¯çŠ¶æ€è·Ÿè¸ª(Zero-shot Dialog State Tracking, zs-DST)ä¸­åŠ¨æ€å¯¹è¯ä¸Šä¸‹æ–‡ä¸é™æ€æç¤ºè¯ä¹‹é—´çš„è¯­ä¹‰å¤±é…ã€è·¨å±‚åè°ƒçµæ´»æ€§ä¸è¶³ä»¥åŠé¢†åŸŸå¹²æ‰°ç­‰é—®é¢˜ï¼Œæå‡ºäº†HiCoLoRAæ¡†æ¶ã€‚è¯¥æ¡†æ¶é€šè¿‡æ„å»ºå±‚æ¬¡åŒ–LoRAæ¶æ„ï¼Œåœ¨åº•å±‚é‡‡ç”¨å¯å‘å¼åˆ†ç»„å¹¶åœ¨é«˜å±‚è¿›è¡Œå…¨äº¤äº’å¤„ç†ï¼Œå®ç°äº†åŠ¨æ€çš„å±‚çº§ç‰¹å®šå¤„ç†ï¼Œä»è€Œå¢å¼ºäº†é›¶æ ·æœ¬æ§½ä½æ¨ç†ä¸­çš„æç¤ºè¯å¯¹é½ã€‚æ­¤å¤–ï¼Œç ”ç©¶é›†æˆäº†Spectral Joint Domain-Slot ClusteringæŠ€æœ¯æ¥è¯†åˆ«å¯è¿ç§»çš„é¢†åŸŸæ§½ä½å…³è”ï¼Œå¹¶é…åˆAdaptive Linear Fusion Mechanismè¿›è¡Œç‰¹å¾èåˆã€‚ä¸ºäº†é˜²æ­¢ç¾éš¾æ€§é—å¿˜ï¼Œè¯¥æ–¹æ³•è¿˜é‡‡ç”¨äº†Semantic-Enhanced SVD Initialization (SemSVD-Init)æ¥ä¿ç•™é¢„è®­ç»ƒçŸ¥è¯†ã€‚åœ¨MultiWOZå’ŒSGDç­‰å¤šé¢†åŸŸæ•°æ®é›†ä¸Šçš„å®éªŒç»“æœè¡¨æ˜ï¼ŒHiCoLoRAæ€§èƒ½ä¼˜äºç°æœ‰åŸºçº¿æ¨¡å‹ï¼Œåœ¨zs-DSTä»»åŠ¡ä¸­è¾¾åˆ°äº†SOTAæ°´å¹³ã€‚",
      "categories": [
        "cs.CL",
        "cs.AI",
        "cs.IR"
      ],
      "primary_category": "cs.CL",
      "comment": "",
      "pdf_url": "https://arxiv.org/pdf/2509.19742v3",
      "published_date": "2025-09-24 03:44:16 UTC",
      "updated_date": "2026-01-07 10:51:23 UTC",
      "processing_status": "completed",
      "attempts": 1,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "llm_backup_calls": 0,
      "last_update": "2026-01-24T21:03:29.884077+00:00"
    },
    {
      "arxiv_id": "2509.19736v1",
      "title": "UserRL: Training Interactive User-Centric Agent via Reinforcement Learning",
      "title_zh": "UserRLï¼šåŸºäºå¼ºåŒ–å­¦ä¹ è®­ç»ƒäº¤äº’å¼ä»¥ç”¨æˆ·ä¸ºä¸­å¿ƒçš„æ™ºèƒ½ä½“",
      "authors": [
        "Cheng Qian",
        "Zuxin Liu",
        "Akshara Prabhakar",
        "Jielin Qiu",
        "Zhiwei Liu",
        "Haolin Chen",
        "Shirley Kokane",
        "Heng Ji",
        "Weiran Yao",
        "Shelby Heinecke",
        "Silvio Savarese",
        "Caiming Xiong",
        "Huan Wang"
      ],
      "abstract": "Reinforcement learning (RL) has shown promise in training agentic models that move beyond static benchmarks to engage in dynamic, multi-turn interactions. Yet, the ultimate value of such agents lies in their ability to assist users, a setting where diversity and dynamics of user interaction pose challenges. In this work, we propose UserRL, a unified framework for training and evaluating user-centric abilities through standardized gym environments paired with simulated users. We systematically vary turn-level reward assignment and trajectory-level score calculation to analyze how different formulations affect learning under the GRPO algorithm. Our experiments across Qwen3 models reveal three key findings: (i) SFT cold start is critical for unlocking initial interaction ability and enabling sustained RL improvements; (ii) deliberate trajectory scoring yields more efficient and effective multi-turn interactions; and (iii) while stronger simulated users (e.g., GPT-4o) facilitates training, open-source simulators (e.g., Qwen3-32B) remain a cost-effective and transferable option. Together, these results highlight that careful design of reward shaping and user simulation choice is as crucial as model scale, and establish UserRL as a practical pathway for developing robust user-centric agentic models. All codes and data are public for future research.",
      "tldr_zh": "è¯¥ç ”ç©¶æå‡ºäº† UserRLï¼Œä¸€ä¸ªæ—¨åœ¨é€šè¿‡æ ‡å‡†åŒ–çš„ Gym ç¯å¢ƒå’Œæ¨¡æ‹Ÿç”¨æˆ·æ¥è®­ç»ƒåŠè¯„ä¼°ä»¥ç”¨æˆ·ä¸ºä¸­å¿ƒçš„æ™ºèƒ½ä½“èƒ½åŠ›çš„ç»Ÿä¸€æ¡†æ¶ã€‚ç ”ç©¶å›¢é˜Ÿåˆ©ç”¨ GRPO ç®—æ³•åœ¨ Qwen3 æ¨¡å‹ä¸Šè¿›è¡Œå®éªŒï¼Œç³»ç»Ÿåˆ†æäº†å›åˆçº§å¥–åŠ±åˆ†é…å’Œè½¨è¿¹çº§è¯„åˆ†è®¡ç®—å¯¹å­¦ä¹ æ•ˆæœçš„å½±å“ã€‚å®éªŒç»“æœè¡¨æ˜ï¼ŒSFT å†·å¯åŠ¨æ˜¯å¼€å¯åˆå§‹äº¤äº’èƒ½åŠ›å¹¶å®ç°æŒç»­ RL æ€§èƒ½æå‡çš„å…³é”®ï¼Œè€Œç²¾å¿ƒè®¾è®¡çš„è½¨è¿¹è¯„åˆ†ï¼ˆTrajectory scoringï¼‰åˆ™èƒ½æ˜¾è‘—æå‡å¤šè½®äº¤äº’çš„æ•ˆç‡ã€‚åœ¨æ¨¡æ‹Ÿç”¨æˆ·æ–¹é¢ï¼Œè™½ç„¶ GPT-4o ç­‰å¼ºåŠ›æ¨¡å‹æœ‰åŠ©äºè®­ç»ƒï¼Œä½†å¼€æºæ¨¡æ‹Ÿå™¨ï¼ˆå¦‚ Qwen3-32Bï¼‰ä»æ˜¯æå…·æ€§ä»·æ¯”ä¸”å…·å¤‡è‰¯å¥½è¿ç§»æ€§çš„é€‰æ‹©ã€‚è¯¥å·¥ä½œå¼ºè°ƒäº†å¥–åŠ±å¡‘é€ ï¼ˆReward shapingï¼‰å’Œæ¨¡æ‹Ÿå™¨é€‰æ‹©ä¸æ¨¡å‹è§„æ¨¡åŒæ ·é‡è¦ï¼Œä¸ºå¼€å‘ç¨³å¥çš„ä»¥ç”¨æˆ·ä¸ºä¸­å¿ƒçš„æ™ºèƒ½ä½“æ¨¡å‹å¼€è¾Ÿäº†å®ç”¨è·¯å¾„ã€‚",
      "categories": [
        "cs.AI",
        "cs.CL",
        "cs.LG"
      ],
      "primary_category": "cs.AI",
      "comment": "28 Pages, 15 Figures, 6 Tables; Built upon latest UserBench release: arXiv:2507.22034",
      "pdf_url": "https://arxiv.org/pdf/2509.19736v1",
      "published_date": "2025-09-24 03:33:20 UTC",
      "updated_date": "2025-09-24 03:33:20 UTC",
      "processing_status": "completed",
      "attempts": 1,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "llm_backup_calls": 0,
      "last_update": "2026-01-24T21:04:07.362442+00:00"
    },
    {
      "arxiv_id": "2509.19715v1",
      "title": "SMILES-Inspired Transfer Learning for Quantum Operators in Generative Quantum Eigensolver",
      "title_zh": "ç”Ÿæˆå¼é‡å­ç‰¹å¾å€¼æ±‚è§£å™¨ä¸­åŸºäº SMILES å¯å‘çš„é‡å­ç®—ç¬¦è¿ç§»å­¦ä¹ ",
      "authors": [
        "Zhi Yin",
        "Xiaoran Li",
        "Shengyu Zhang",
        "Xin Li",
        "Xiaojin Zhang"
      ],
      "abstract": "Given the inherent limitations of traditional Variational Quantum Eigensolver(VQE) algorithms, the integration of deep generative models into hybrid quantum-classical frameworks, specifically the Generative Quantum Eigensolver(GQE), represents a promising innovative approach. However, taking the Unitary Coupled Cluster with Singles and Doubles(UCCSD) ansatz which is widely used in quantum chemistry as an example, different molecular systems require constructions of distinct quantum operators. Considering the similarity of different molecules, the construction of quantum operators utilizing the similarity can reduce the computational cost significantly. Inspired by the SMILES representation method in computational chemistry, we developed a text-based representation approach for UCCSD quantum operators by leveraging the inherent representational similarities between different molecular systems. This framework explores text pattern similarities in quantum operators and employs text similarity metrics to establish a transfer learning framework. Our approach with a naive baseline setting demonstrates knowledge transfer between different molecular systems for ground-state energy calculations within the GQE paradigm. This discovery offers significant benefits for hybrid quantum-classical computation of molecular ground-state energies, substantially reducing computational resource requirements.",
      "tldr_zh": "è¯¥ç ”ç©¶é’ˆå¯¹ä¼ ç»Ÿ Variational Quantum Eigensolver (VQE) çš„å±€é™æ€§ï¼Œæå‡ºäº†ä¸€ç§åœ¨ Generative Quantum Eigensolver (GQE) æ¡†æ¶ä¸‹åˆ©ç”¨è¿ç§»å­¦ä¹ ä¼˜åŒ–é‡å­ç®—å­çš„æ–°æ–¹æ³•ã€‚å—åˆ°åŒ–å­¦ä¿¡æ¯å­¦ä¸­ SMILES è¡¨ç¤ºæ³•çš„å¯å‘ï¼Œç ”ç©¶è€…ä¸ºå¹¿æ³›åº”ç”¨äºé‡å­åŒ–å­¦çš„ Unitary Coupled Cluster with Singles and Doubles (UCCSD) ç®—å­å¼€å‘äº†ä¸€ç§åŸºäºæ–‡æœ¬çš„è¡¨ç¤ºæ–¹å¼ï¼Œæ—¨åœ¨åˆ©ç”¨ä¸åŒåˆ†å­ç³»ç»Ÿé—´çš„å›ºæœ‰è¡¨ç¤ºç›¸ä¼¼æ€§ã€‚è¯¥æ¡†æ¶é€šè¿‡æŒ–æ˜é‡å­ç®—å­ä¸­çš„æ–‡æœ¬æ¨¡å¼ç›¸ä¼¼æ€§ï¼Œå¹¶åˆ©ç”¨æ–‡æœ¬ç›¸ä¼¼æ€§åº¦é‡æ„å»ºäº†è¿ç§»å­¦ä¹ ä½“ç³»ã€‚å®éªŒè¯æ˜ï¼Œè¯¥æ–¹æ³•æˆåŠŸå®ç°äº†ä¸åŒåˆ†å­ç³»ç»Ÿé—´åŸºæ€èƒ½é‡è®¡ç®—çš„çŸ¥è¯†è¿ç§»ï¼Œåœ¨ GQE èŒƒå¼ä¸‹æ˜¾è‘—é™ä½äº†æ··åˆé‡å­-ç»å…¸è®¡ç®—æ‰€éœ€çš„è®¡ç®—èµ„æºã€‚è¿™ä¸€è¿›å±•ä¸ºé«˜æ•ˆæ±‚è§£åˆ†å­åŸºæ€èƒ½é‡æä¾›äº†åˆ›æ–°çš„æŠ€æœ¯è·¯å¾„ï¼Œå…·æœ‰é‡è¦çš„å­¦æœ¯ä¸åº”ç”¨ä»·å€¼ã€‚",
      "categories": [
        "physics.chem-ph",
        "cs.AI"
      ],
      "primary_category": "physics.chem-ph",
      "comment": "7 pages, 5 figures",
      "pdf_url": "https://arxiv.org/pdf/2509.19715v1",
      "published_date": "2025-09-24 02:54:09 UTC",
      "updated_date": "2025-09-24 02:54:09 UTC",
      "processing_status": "completed",
      "attempts": 1,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "llm_backup_calls": 0,
      "last_update": "2026-01-24T21:03:36.697672+00:00"
    },
    {
      "arxiv_id": "2509.21391v1",
      "title": "MIXRAG : Mixture-of-Experts Retrieval-Augmented Generation for Textual Graph Understanding and Question Answering",
      "title_zh": "MIXRAGï¼šé¢å‘æ–‡æœ¬å›¾ç†è§£ä¸é—®ç­”çš„æ··åˆä¸“å®¶æ£€ç´¢å¢å¼ºç”Ÿæˆ",
      "authors": [
        "Lihui Liu",
        "Carl J. Yang"
      ],
      "abstract": "Large Language Models (LLMs) have achieved impressive performance across a wide range of applications. However, they often suffer from hallucinations in knowledge-intensive domains due to their reliance on static pretraining corpora. To address this limitation, Retrieval-Augmented Generation (RAG) enhances LLMs by incorporating external knowledge sources during inference. Among these sources, textual graphs provide structured and semantically rich information that supports more precise and interpretable reasoning. This has led to growing interest in graph-based RAG systems. Despite their potential, most existing approaches rely on a single retriever to identify relevant subgraphs, which limits their ability to capture the diverse aspects of complex queries. Moreover, these systems often struggle to accurately judge the relevance of retrieved content, making them prone to distraction by irrelevant noise. To address these challenges, in this paper, we propose MIXRAG, a Mixture-of-Experts Graph-RAG framework that introduces multiple specialized graph retrievers and a dynamic routing controller to better handle diverse query intents. Each retriever is trained to focus on a specific aspect of graph semantics, such as entities, relations, or subgraph topology. A Mixture-of-Experts module adaptively selects and fuses relevant retrievers based on the input query. To reduce noise in the retrieved information, we introduce a query-aware GraphEncoder that carefully analyzes relationships within the retrieved subgraphs, highlighting the most relevant parts while down-weighting unnecessary noise. Empirical results demonstrate that our method achieves state-of-the-art performance and consistently outperforms various baselines. MIXRAG is effective across a wide range of graph-based tasks in different domains. The code will be released upon paper acceptance.",
      "tldr_zh": "æœ¬ç ”ç©¶é’ˆå¯¹å¤§å‹è¯­è¨€æ¨¡å‹(LLMs)åœ¨å¤„ç†æ–‡æœ¬å›¾ç†è§£å’Œé—®ç­”ä»»åŠ¡æ—¶çš„å¹»è§‰åŠå•ä¸€æ£€ç´¢å™¨å±€é™æ€§ï¼Œæå‡ºäº†åä¸º MIXRAG çš„ Mixture-of-Experts Graph-RAG æ¡†æ¶ã€‚è¯¥æ¡†æ¶å¼•å…¥äº†å¤šé‡ä¸“ä¸šåŒ–å›¾æ£€ç´¢å™¨(Graph Retrievers)å’ŒåŠ¨æ€è·¯ç”±æ§åˆ¶å™¨ï¼Œæ—¨åœ¨æ›´å…¨é¢åœ°æ•æ‰å¤æ‚æŸ¥è¯¢çš„å¤šæ ·åŒ–æ„å›¾ã€‚æ¯ä¸ªæ£€ç´¢å™¨é€šè¿‡è®­ç»ƒä¸“é—¨å…³æ³¨å›¾è¯­ä¹‰çš„ç‰¹å®šç»´åº¦ï¼Œå¦‚å®ä½“(Entities)ã€å…³ç³»(Relations)æˆ–å­å›¾æ‹“æ‰‘(Subgraph Topology)ï¼Œå¹¶ç”± Mixture-of-Experts æ¨¡å—æ ¹æ®æŸ¥è¯¢è‡ªé€‚åº”åœ°è¿›è¡Œé€‰æ‹©ä¸èåˆã€‚ä¸ºäº†é™ä½æ£€ç´¢ä¿¡æ¯ä¸­çš„å™ªå£°å¹²æ‰°ï¼Œç ”ç©¶è¿˜è®¾è®¡äº†ä¸€ç§æŸ¥è¯¢æ„ŸçŸ¥å›¾ç¼–ç å™¨(GraphEncoder)ï¼Œé€šè¿‡æ·±åº¦åˆ†æå­å›¾å†…éƒ¨å…³ç³»æ¥çªå‡ºå…³é”®å†…å®¹å¹¶è¿‡æ»¤æ— å…³ä¿¡æ¯ã€‚å®éªŒç»“æœè¡¨æ˜ï¼ŒMIXRAG åœ¨å¤šä¸ªé¢†åŸŸçš„å›¾ç›¸å…³ä»»åŠ¡ä¸­å‡å–å¾—äº† State-of-the-Art çš„æ€§èƒ½è¡¨ç°ï¼Œæ˜¾è‘—ä¸”æŒç»­åœ°ä¼˜äºç°æœ‰çš„å„ç±»åŸºçº¿æ¨¡å‹ã€‚",
      "categories": [
        "cs.IR",
        "cs.AI"
      ],
      "primary_category": "cs.IR",
      "comment": "",
      "pdf_url": "https://arxiv.org/pdf/2509.21391v1",
      "published_date": "2025-09-24 02:44:57 UTC",
      "updated_date": "2025-09-24 02:44:57 UTC",
      "processing_status": "completed",
      "attempts": 1,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "llm_backup_calls": 0,
      "last_update": "2026-01-24T21:03:39.797580+00:00"
    },
    {
      "arxiv_id": "2509.19708v1",
      "title": "Intuition to Evidence: Measuring AI's True Impact on Developer Productivity",
      "title_zh": "ä»ç›´è§‰åˆ°å®è¯ï¼šè¡¡é‡äººå·¥æ™ºèƒ½å¯¹å¼€å‘è€…ç”Ÿäº§åŠ›çš„çœŸå®å½±å“",
      "authors": [
        "Anand Kumar",
        "Vishal Khare",
        "Deepak Sharma",
        "Satyam Kumar",
        "Vijay Saini",
        "Anshul Yadav",
        "Sachendra Jain",
        "Ankit Rana",
        "Pratham Verma",
        "Vaibhav Meena",
        "Avinash Edubilli"
      ],
      "abstract": "We present a comprehensive real-world evaluation of AI-assisted software development tools deployed at enterprise scale. Over one year, 300 engineers across multiple teams integrated an in-house AI platform (DeputyDev) that combines code generation and automated review capabilities into their daily workflows. Through rigorous cohort analysis, our study demonstrates statistically significant productivity improvements, including an overall 31.8% reduction in PR review cycle time.\n  Developer adoption was strong, with 85% satisfaction for code review features and 93% expressing a desire to continue using the platform. Adoption patterns showed systematic scaling from 4% engagement in month 1 to 83% peak usage by month 6, stabilizing at 60% active engagement. Top adopters achieved a 61% increase in code volume pushed to production, contributing to approximately 30 to 40% of code shipped to production through this tool, accounting for an overall 28% increase in code shipment volume.\n  Unlike controlled benchmark evaluations, our longitudinal analysis provides empirical evidence from production environments, revealing both the transformative potential and practical deployment challenges of integrating AI into enterprise software development workflows.",
      "tldr_zh": "è¯¥ç ”ç©¶å¯¹ä¼ä¸šçº§éƒ¨ç½²çš„ AI è¾…åŠ©è½¯ä»¶å¼€å‘å·¥å…·è¿›è¡Œäº†å…¨é¢çš„çœŸå®ä¸–ç•Œè¯„ä¼°ï¼Œé€šè¿‡å¯¹ 300 åå·¥ç¨‹å¸ˆè¿›è¡Œä¸ºæœŸä¸€å¹´çš„é˜Ÿåˆ—åˆ†æ (Cohort Analysis)ï¼Œç³»ç»Ÿåœ°è¡¡é‡äº†å†…éƒ¨ AI å¹³å° DeputyDev å¯¹å¼€å‘æ•ˆç‡çš„çœŸå®å½±å“ã€‚ç ”ç©¶å‘ç°ï¼Œè¯¥å¹³å°çš„åº”ç”¨æ˜¾è‘—ä¼˜åŒ–äº†å¼€å‘æµç¨‹ï¼Œä½¿æ‹‰å–è¯·æ±‚ (PR) çš„è¯„å®¡å‘¨æœŸç¼©çŸ­äº† 31.8%ï¼Œå¹¶ä¿ƒä½¿æ•´ä½“ä»£ç äº¤ä»˜é‡æå‡äº† 28%ã€‚åœ¨å¼€å‘è€…é‡‡ç”¨æ–¹é¢ï¼Œä»£ç è¯„å®¡åŠŸèƒ½çš„æ»¡æ„åº¦è¾¾ 85%ï¼Œä¸” 93% çš„å‚ä¸è€…è¡¨è¾¾äº†æŒç»­ä½¿ç”¨çš„æ„æ„¿ï¼Œæ´»è·ƒå‚ä¸åº¦åœ¨åŠå¹´å†…ä» 4% æ”€å‡è‡³ 83% çš„å³°å€¼ã€‚æ•°æ®è¿˜æ˜¾ç¤ºï¼Œé¡¶å°–é‡‡ç”¨è€…æ¨å‘ç”Ÿäº§ç¯å¢ƒçš„ä»£ç é‡å¢åŠ äº† 61%ï¼Œè¯æ˜äº† AI å·¥å…·åœ¨æå‡ä¸ªä½“äº§å‡ºæ–¹é¢çš„å·¨å¤§æ½œåŠ›ã€‚ä¸ä¼ ç»Ÿçš„å—æ§åŸºå‡†æµ‹è¯• (Benchmarks) ä¸åŒï¼Œè¿™é¡¹çºµå‘åˆ†æ (Longitudinal Analysis) æä¾›äº†æ¥è‡ªç”Ÿäº§ç¯å¢ƒçš„å®è¯è¯æ®ï¼Œæ·±å…¥æ­ç¤ºäº† AI é›†æˆåˆ°ä¼ä¸šè½¯ä»¶å¼€å‘å·¥ä½œæµä¸­çš„è½¬å‹ä»·å€¼ä¸å®é™…éƒ¨ç½²æŒ‘æˆ˜ã€‚",
      "categories": [
        "cs.SE",
        "cs.AI",
        "cs.LG"
      ],
      "primary_category": "cs.SE",
      "comment": "16 pages, 10 figures, 5 tables",
      "pdf_url": "https://arxiv.org/pdf/2509.19708v1",
      "published_date": "2025-09-24 02:34:11 UTC",
      "updated_date": "2025-09-24 02:34:11 UTC",
      "processing_status": "completed",
      "attempts": 1,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "llm_backup_calls": 0,
      "last_update": "2026-01-24T21:03:50.257164+00:00"
    },
    {
      "arxiv_id": "2509.19705v1",
      "title": "Causal Machine Learning for Surgical Interventions",
      "title_zh": "é¢å‘æ‰‹æœ¯å¹²é¢„çš„å› æœæœºå™¨å­¦ä¹ ",
      "authors": [
        "J. Ben Tamo",
        "Nishant S. Chouhan",
        "Micky C. Nnamdi",
        "Yining Yuan",
        "Shreya S. Chivilkar",
        "Wenqi Shi",
        "Steven W. Hwang",
        "B. Randall Brenn",
        "May D. Wang"
      ],
      "abstract": "Surgical decision-making is complex and requires understanding causal relationships between patient characteristics, interventions, and outcomes. In high-stakes settings like spinal fusion or scoliosis correction, accurate estimation of individualized treatment effects (ITEs) remains limited due to the reliance on traditional statistical methods that struggle with complex, heterogeneous data. In this study, we develop a multi-task meta-learning framework, X-MultiTask, for ITE estimation that models each surgical decision (e.g., anterior vs. posterior approach, surgery vs. no surgery) as a distinct task while learning shared representations across tasks. To strengthen causal validity, we incorporate the inverse probability weighting (IPW) into the training objective. We evaluate our approach on two datasets: (1) a public spinal fusion dataset (1,017 patients) to assess the effect of anterior vs. posterior approaches on complication severity; and (2) a private AIS dataset (368 patients) to analyze the impact of posterior spinal fusion (PSF) vs. non-surgical management on patient-reported outcomes (PROs). Our model achieves the highest average AUC (0.84) in the anterior group and maintains competitive performance in the posterior group (0.77). It outperforms baselines in treatment effect estimation with the lowest overall $Îµ_{\\text{NN-PEHE}}$ (0.2778) and $Îµ_{\\text{ATE}}$ (0.0763). Similarly, when predicting PROs in AIS, X-MultiTask consistently shows superior performance across all domains, with $Îµ_{\\text{NN-PEHE}}$ = 0.2551 and $Îµ_{\\text{ATE}}$ = 0.0902. By providing robust, patient-specific causal estimates, X-MultiTask offers a powerful tool to advance personalized surgical care and improve patient outcomes. The code is available at https://github.com/Wizaaard/X-MultiTask.",
      "tldr_zh": "è¯¥ç ”ç©¶é’ˆå¯¹æ‰‹æœ¯å†³ç­–ä¸­å› æœå…³ç³»ç†è§£çš„å¤æ‚æ€§ï¼Œæå‡ºäº†ä¸€ç§åä¸ºX-MultiTaskçš„å¤šä»»åŠ¡å…ƒå­¦ä¹ (multi-task meta-learning)æ¡†æ¶ï¼Œæ—¨åœ¨æå‡ä¸ªä½“åŒ–æ²»ç–—æ•ˆåº”(individualized treatment effects, ITEs)çš„ä¼°ç®—ç²¾åº¦ã€‚ä¸ºäº†è§£å†³ä¼ ç»Ÿç»Ÿè®¡æ–¹æ³•å¤„ç†å¼‚æ„æ•°æ®çš„å±€é™æ€§ï¼Œè¯¥æ¡†æ¶å°†ä¸åŒçš„æ‰‹æœ¯å†³ç­–å»ºæ¨¡ä¸ºç‹¬ç«‹ä»»åŠ¡ï¼Œå¹¶å¼•å…¥é€†æ¦‚ç‡åŠ æƒ(inverse probability weighting, IPW)ä»¥å¢å¼ºå› æœæ¨æ–­çš„æœ‰æ•ˆæ€§ã€‚ç ”ç©¶åœ¨è„ŠæŸ±èåˆ(spinal fusion)å’Œé’å°‘å¹´ç‰¹å‘æ€§è„ŠæŸ±ä¾§å¼¯(AIS)ä¸¤ä¸ªæ•°æ®é›†ä¸Šè¿›è¡Œäº†éªŒè¯ï¼Œåˆ†åˆ«è¯„ä¼°äº†ä¸åŒæ‰‹æœ¯å…¥è·¯åŠå¹²é¢„æ–¹æ¡ˆå¯¹å¹¶å‘ç—‡å’Œæ‚£è€…æŠ¥å‘Šç»“æœ(PROs)çš„å½±å“ã€‚å®éªŒç»“æœæ˜¾ç¤ºï¼ŒX-MultiTaskåœ¨å¤šé¡¹æŒ‡æ ‡ä¸Šä¼˜äºåŸºçº¿æ¨¡å‹ï¼Œåœ¨è„ŠæŸ±èåˆæ•°æ®é›†ä¸­å®ç°äº†æœ€ä½çš„$Îµ_{\\text{NN-PEHE}}$(0.2778)å’Œ$Îµ_{\\text{ATE}}$(0.0763)ï¼Œå¹¶åœ¨AISé¢„åé¢„æµ‹ä¸­ä¿æŒé¢†å…ˆåœ°ä½ã€‚é€šè¿‡æä¾›ç¨³å¥ä¸”é’ˆå¯¹ç‰¹å®šæ‚£è€…çš„å› æœä¼°è®¡ï¼Œè¯¥ç ”ç©¶ä¸ºæ¨è¿›ä¸ªæ€§åŒ–æ‰‹æœ¯æŠ¤ç†å’Œæ”¹å–„ä¸´åºŠé¢„åæä¾›äº†å¼ºæœ‰åŠ›çš„å·¥å…·æ”¯æŒã€‚",
      "categories": [
        "cs.LG",
        "cs.AI",
        "stat.AP",
        "stat.ME"
      ],
      "primary_category": "cs.LG",
      "comment": "",
      "pdf_url": "https://arxiv.org/pdf/2509.19705v1",
      "published_date": "2025-09-24 02:31:43 UTC",
      "updated_date": "2025-09-24 02:31:43 UTC",
      "processing_status": "completed",
      "attempts": 1,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "llm_backup_calls": 0,
      "last_update": "2026-01-24T21:03:53.953146+00:00"
    },
    {
      "arxiv_id": "2509.19702v1",
      "title": "Linear Transformers Implicitly Discover Unified Numerical Algorithms",
      "title_zh": "çº¿æ€§ Transformer éšå¼å‘ç°ç»Ÿä¸€æ•°å€¼ç®—æ³•",
      "authors": [
        "Patrick Lutz",
        "Aditya Gangrade",
        "Hadi Daneshmand",
        "Venkatesh Saligrama"
      ],
      "abstract": "We train a linear attention transformer on millions of masked-block matrix completion tasks: each prompt is masked low-rank matrix whose missing block may be (i) a scalar prediction target or (ii) an unseen kernel slice of NystrÃ¶m extrapolation. The model sees only input-output pairs and a mean-squared loss; it is given no normal equations, no handcrafted iterations, and no hint that the tasks are related. Surprisingly, after training, algebraic unrolling reveals the same parameter-free update rule across three distinct computational regimes (full visibility, rank-limited updates, and distributed computation). We prove that this rule achieves second-order convergence on full-batch problems, cuts distributed iteration complexity, and remains accurate with rank-limited attention. Thus, a transformer trained solely to patch missing blocks implicitly discovers a unified, resource-adaptive iterative solver spanning prediction, estimation, and NystrÃ¶m extrapolation, highlighting a powerful capability of in-context learning.",
      "tldr_zh": "è¯¥ç ”ç©¶åœ¨æ•°ç™¾ä¸‡ä¸ª Masked-block matrix completion ä»»åŠ¡ä¸Šè®­ç»ƒäº† Linear attention transformerï¼Œå‘ç°æ¨¡å‹åœ¨ä»…ç»™å®šè¾“å…¥è¾“å‡ºå¯¹å’Œ Mean-squared loss çš„æƒ…å†µä¸‹ï¼Œèƒ½å¤Ÿéšå¼å­¦ä¹ åˆ°ä¸€ç§ç»Ÿä¸€çš„æ•°å€¼ç®—æ³•ã€‚é€šè¿‡ä»£æ•°å±•å¼€ (Algebraic unrolling) åˆ†æï¼Œè¯¥æ¨¡å‹åœ¨ Full visibilityã€Rank-limited updates å’Œåˆ†å¸ƒå¼è®¡ç®—ä¸‰ç§ä¸åŒä½“åˆ¶ä¸‹å‡è‡ªå‘å½¢æˆäº†ç›¸åŒçš„å‚æ•°æ— å…³æ›´æ–°è§„åˆ™ã€‚ç ”ç©¶è¯æ˜ï¼Œè¯¥è§„åˆ™åœ¨å…¨æ‰¹æ¬¡é—®é¢˜ä¸Šå…·æœ‰äºŒé˜¶æ”¶æ•› (Second-order convergence) ç‰¹æ€§ï¼Œå¹¶èƒ½æ˜¾è‘—é™ä½åˆ†å¸ƒå¼è¿­ä»£å¤æ‚åº¦ï¼Œä¸”åœ¨ä½ç§©æ³¨æ„åŠ›æœºåˆ¶ä¸‹ä¾ç„¶ä¿æŒç²¾ç¡®ã€‚è¿™ä¸€ç»“æœè¡¨æ˜ Transformer èƒ½å¤Ÿè‡ªä¸»å‘ç°æ¨ªè·¨é¢„æµ‹ã€ä¼°è®¡ä¸ NystrÃ¶m extrapolation çš„èµ„æºè‡ªé€‚åº”è¿­ä»£æ±‚è§£å™¨ï¼Œæœ‰åŠ›è¯æ˜äº†è¯­å¢ƒå­¦ä¹  (In-context learning) åœ¨æ‰§è¡Œå¤æ‚æ•°å€¼è®¡ç®—ä¸ç®—æ³•å‘ç°ä¸­çš„å¼ºå¤§æ½œåŠ›ã€‚",
      "categories": [
        "cs.LG",
        "cs.AI"
      ],
      "primary_category": "cs.LG",
      "comment": "To appear at NeurIPS 2025",
      "pdf_url": "https://arxiv.org/pdf/2509.19702v1",
      "published_date": "2025-09-24 02:19:04 UTC",
      "updated_date": "2025-09-24 02:19:04 UTC",
      "processing_status": "completed",
      "attempts": 1,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "llm_backup_calls": 0,
      "last_update": "2026-01-24T21:03:54.849390+00:00"
    },
    {
      "arxiv_id": "2510.01242v1",
      "title": "Redundancy-as-Masking: Formalizing the Artificial Age Score (AAS) to Model Memory Aging in Generative AI",
      "title_zh": "å†—ä½™å³æ©ç ï¼šå½¢å¼åŒ–äººå·¥æ™ºèƒ½å¹´é¾„åˆ†å€¼ (AAS) ä»¥å»ºæ¨¡ç”Ÿæˆå¼äººå·¥æ™ºèƒ½çš„è®°å¿†è€åŒ–",
      "authors": [
        "Seyma Yaman Kayadibi"
      ],
      "abstract": "Artificial intelligence is observed to age not through chronological time but through structural asymmetries in memory performance. In large language models, semantic cues such as the name of the day often remain stable across sessions, while episodic details like the sequential progression of experiment numbers tend to collapse when conversational context is reset. To capture this phenomenon, the Artificial Age Score (AAS) is introduced as a log-scaled, entropy-informed metric of memory aging derived from observable recall behavior. The score is formally proven to be well-defined, bounded, and monotonic under mild and model-agnostic assumptions, making it applicable across various tasks and domains. In its Redundancy-as-Masking formulation, the score interprets redundancy as overlapping information that reduces the penalized mass. However, in the present study, redundancy is not explicitly estimated; all reported values assume a redundancy-neutral setting (R = 0), yielding conservative upper bounds. The AAS framework was tested over a 25-day bilingual study involving ChatGPT-5, structured into stateless and persistent interaction phases. During persistent sessions, the model consistently recalled both semantic and episodic details, driving the AAS toward its theoretical minimum, indicative of structural youth. In contrast, when sessions were reset, the model preserved semantic consistency but failed to maintain episodic continuity, causing a sharp increase in the AAS and signaling structural memory aging. These findings support the utility of AAS as a theoretically grounded, task-independent diagnostic tool for evaluating memory degradation in artificial systems. The study builds on foundational concepts from von Neumann's work on automata, Shannon's theories of information and redundancy, and Turing's behavioral approach to intelligence.",
      "tldr_zh": "è¿™é¡¹ç ”ç©¶æ¢è®¨äº†äººå·¥æ™ºèƒ½å¹¶ééšæ—¶é—´è€åŒ–ï¼Œè€Œæ˜¯é€šè¿‡è®°å¿†æ€§èƒ½çš„ç»“æ„æ€§ä¸å¯¹ç§°ä½“ç°è€åŒ–ï¼Œæ®æ­¤æå‡ºäº†äººå·¥è€åŒ–è¯„åˆ† (Artificial Age Score, AAS) æ¡†æ¶ã€‚è¯¥è¯„åˆ†æ˜¯ä¸€ç§åŸºäºå¯¹æ•°åˆ»åº¦å’Œç†µçš„ä¿¡æ¯åº¦é‡ï¼Œé€šè¿‡å¯è§‚æµ‹çš„å¬å›è¡Œä¸ºæ¥é‡åŒ–å¤§è§„æ¨¡è¯­è¨€æ¨¡å‹ä¸­çš„è®°å¿†è€åŒ–ã€‚ç ”ç©¶æ­£å¼è¯æ˜äº† AAS åœ¨æ¨¡å‹æ— å…³çš„å‡è®¾ä¸‹å…·æœ‰å®šä¹‰è‰¯å¥½ã€æœ‰ç•Œæ€§å’Œå•è°ƒæ€§ç­‰æ•°å­¦ç‰¹æ€§ï¼Œä½¿å…¶é€‚ç”¨äºå¤šç§ä»»åŠ¡å’Œé¢†åŸŸã€‚é€šè¿‡å¯¹ ChatGPT-5 è¿›è¡Œä¸ºæœŸ 25 å¤©çš„åŒè¯­å®éªŒï¼Œç ”ç©¶å¯¹æ¯”äº†æ— çŠ¶æ€ (stateless) å’ŒæŒä¹…æ€§ (persistent) ä¸¤ç§äº¤äº’é˜¶æ®µçš„è®°å¿†è¡¨ç°ã€‚åœ¨æŒä¹…æ€§ä¼šè¯ä¸­ï¼Œæ¨¡å‹èƒ½æŒç»­å¬å›è¯­ä¹‰å’Œæƒ…èŠ‚ç»†èŠ‚ï¼Œä½¿ AAS è¶‹å‘ç†è®ºæœ€å°å€¼ï¼Œè¡¨ç°å‡ºç»“æ„æ€§å¹´è½»ç‰¹å¾ï¼›è€Œåœ¨ä¼šè¯é‡ç½®åï¼Œå°½ç®¡è¯­ä¹‰ä¸€è‡´æ€§å¾—ä»¥ä¿ç•™ï¼Œä½†ç”±äºæƒ…èŠ‚è¿ç»­æ€§çš„ä¸§å¤±ï¼ŒAAS æ˜¾è‘—å‡é«˜ï¼Œæ ‡å¿—ç€ç»“æ„æ€§è®°å¿†è€åŒ–ã€‚è¯¥ç ”ç©¶å€Ÿé‰´äº† Shannon çš„ä¿¡æ¯è®ºå’Œ Turing çš„è¡Œä¸ºæ™ºèƒ½æ–¹æ³•ï¼Œè¯æ˜äº† AAS ä½œä¸ºä¸€ç§ç†è®ºå®Œå¤‡ã€ç‹¬ç«‹äºä»»åŠ¡çš„è¯Šæ–­å·¥å…·ï¼Œèƒ½å¤Ÿæœ‰æ•ˆè¯„ä¼°äººå·¥ç³»ç»Ÿä¸­çš„è®°å¿†é€€åŒ–ã€‚",
      "categories": [
        "cs.CL",
        "cs.AI",
        "cs.IT",
        "cs.LG"
      ],
      "primary_category": "cs.CL",
      "comment": "34 pages, 17 figures. Includes theoretical development and mathematical proofs of the Artificial Age Score (AAS), with empirical illustrations via ChatGPT-based memory recall experiments (screenshots included)",
      "pdf_url": "https://arxiv.org/pdf/2510.01242v1",
      "published_date": "2025-09-24 02:18:27 UTC",
      "updated_date": "2025-09-24 02:18:27 UTC",
      "processing_status": "completed",
      "attempts": 1,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "llm_backup_calls": 0,
      "last_update": "2026-01-24T21:04:03.849214+00:00"
    },
    {
      "arxiv_id": "2509.19698v3",
      "title": "A Unified Noise-Curvature View of Loss of Trainability",
      "title_zh": "å¯è®­ç»ƒæ€§ä¸§å¤±çš„ç»Ÿä¸€å™ªå£°-æ›²ç‡è§†è§’",
      "authors": [
        "Gunbir Singh Baveja",
        "Alex Lewandowski",
        "Mark Schmidt"
      ],
      "abstract": "Loss of trainability refers to a phenomenon in continual learning where parameter updates no longer make progress on the optimization objective, so accuracy stalls or degrades as the learning problem changes over time. In this paper, we analyze loss of trainability through an optimization lens and find that the phenomenon is not reliably predicted by existing individual indicators such as Hessian rank, sharpness level, weight or gradient norms, gradient-to-parameter ratios, and unit-sign entropy. Motivated by our analysis, we introduce two complementary indicators: a batch-size-aware gradient-noise bound and a curvature volatility-controlled bound. We then combine these two indicators into a per-layer adaptive noise threshold on the effective step-size that anticipates trainability behavior. Using this insight, we propose a step-size scheduler that keeps each layer's effective parameter update below this bound, thereby avoiding loss of trainability. We demonstrate that our scheduler can improve the accuracy maintained by previously proposed approaches, such as concatenated ReLU (CReLU), Wasserstein regularizer, and L2 weight decay. Surprisingly, our scheduler produces adaptive step-size trajectories that, without tuning, mirror the manually engineered step-size decay schedules.",
      "tldr_zh": "è¯¥ç ”ç©¶æ¢è®¨äº†æŒç»­å­¦ä¹ (Continual Learning)ä¸­çš„å¯è®­ç»ƒæ€§ä¸§å¤±(Loss of Trainability)ç°è±¡ï¼Œå³éšç€å­¦ä¹ ä»»åŠ¡æ¼”å˜ï¼Œå‚æ•°æ›´æ–°æ— æ³•æœ‰æ•ˆä¼˜åŒ–ç›®æ ‡å¯¼è‡´å‡†ç¡®ç‡åœæ»ã€‚ä½œè€…é€šè¿‡ä¼˜åŒ–è§†è§’åˆ†æå‘ç°ï¼Œç°æœ‰çš„æŒ‡æ ‡å¦‚Hessian rankã€Sharpnessæ°´å¹³ã€æƒé‡æˆ–æ¢¯åº¦èŒƒæ•°ç­‰å‡æ— æ³•å¯é åœ°é¢„æµ‹è¯¥ç°è±¡ã€‚ä¸ºæ­¤ï¼Œè®ºæ–‡æå‡ºäº†ä¸¤ä¸ªäº’è¡¥æŒ‡æ ‡ï¼šè€ƒè™‘æ‰¹é‡å¤§å°çš„æ¢¯åº¦å™ªå£°ç•Œé™(batch-size-aware gradient-noise bound)å’Œå—æ›²ç‡æ³¢åŠ¨æ§åˆ¶çš„ç•Œé™(curvature volatility-controlled bound)ï¼Œå¹¶å°†å…¶æ•´åˆä¸ºæ¯å±‚è‡ªé€‚åº”çš„æœ‰æ•ˆæ­¥é•¿(effective step-size)å™ªå£°é˜ˆå€¼ã€‚åŸºäºæ­¤æ´å¯Ÿï¼Œç ”ç©¶è®¾è®¡äº†ä¸€ç§æ­¥é•¿è°ƒåº¦å™¨(step-size scheduler)ï¼Œé€šè¿‡æ§åˆ¶å„å±‚æ›´æ–°åœ¨ç•Œé™å†…æ¥é¿å…å¯è®­ç»ƒæ€§ä¸§å¤±ã€‚å®éªŒè¡¨æ˜ï¼Œè¯¥è°ƒåº¦å™¨èƒ½æ˜¾è‘—æå‡CReLUã€Wasserstein regularizerå’ŒL2 weight decayç­‰æ–¹æ³•çš„æ€§èƒ½ã€‚æ­¤å¤–ï¼Œè¯¥è°ƒåº¦å™¨ç”Ÿæˆçš„è‡ªé€‚åº”æ­¥é•¿è½¨è¿¹åœ¨æ— éœ€äººå·¥å¹²é¢„çš„æƒ…å†µä¸‹ï¼Œèƒ½å¤Ÿè‡ªåŠ¨åŒ¹é…æ‰‹åŠ¨è®¾è®¡çš„æ­¥é•¿è¡°å‡è®¡åˆ’(step-size decay schedules)ã€‚",
      "categories": [
        "cs.LG",
        "cs.AI"
      ],
      "primary_category": "cs.LG",
      "comment": "",
      "pdf_url": "https://arxiv.org/pdf/2509.19698v3",
      "published_date": "2025-09-24 02:11:13 UTC",
      "updated_date": "2025-12-10 07:34:44 UTC",
      "processing_status": "completed",
      "attempts": 1,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "llm_backup_calls": 0,
      "last_update": "2026-01-24T21:04:05.866596+00:00"
    },
    {
      "arxiv_id": "2509.19696v2",
      "title": "Diffusion-Based Impedance Learning for Contact-Rich Manipulation Tasks",
      "title_zh": "é¢å‘é«˜æ¥è§¦æ“çºµä»»åŠ¡çš„åŸºäºæ‰©æ•£çš„é˜»æŠ—å­¦ä¹ ",
      "authors": [
        "Noah Geiger",
        "Tamim Asfour",
        "Neville Hogan",
        "Johannes Lachner"
      ],
      "abstract": "Learning methods excel at motion generation in the information domain but are not primarily designed for physical interaction in the energy domain. Impedance Control shapes physical interaction but requires task-aware tuning by selecting feasible impedance parameters. We present Diffusion-Based Impedance Learning, a framework that combines both domains. A Transformer-based Diffusion Model with cross-attention to external wrenches reconstructs a simulated Zero-Force Trajectory (sZFT). This captures both translational and rotational task-space behavior. For rotations, we introduce a novel SLERP-based quaternion noise scheduler that ensures geometric consistency. The reconstructed sZFT is then passed to an energy-based estimator that updates stiffness and damping parameters. A directional rule is applied that reduces impedance along non task axes while preserving rigidity along task directions. Training data were collected for a parkour scenario and robotic-assisted therapy tasks using teleoperation with Apple Vision Pro. With only tens of thousands of samples, the model achieved sub-millimeter positional accuracy and sub-degree rotational accuracy. Its compact model size enabled real-time torque control and autonomous stiffness adaptation on a KUKA LBR iiwa robot. The controller achieved smooth parkour traversal within force and velocity limits and 30/30 success rates for cylindrical, square, and star peg insertions without any peg-specific demonstrations in the training data set. All code for the Transformer-based Diffusion Model, the robot controller, and the Apple Vision Pro telemanipulation framework is publicly available. These results mark an important step towards Physical AI, fusing model-based control for physical interaction with learning-based methods for trajectory generation.",
      "tldr_zh": "è¯¥ç ”ç©¶æå‡ºäº†Diffusion-Based Impedance Learningï¼Œè¿™æ˜¯ä¸€ä¸ªå°†è¿åŠ¨ç”Ÿæˆä¸ç‰©ç†äº¤äº’ç›¸ç»“åˆçš„æ¡†æ¶ï¼Œæ—¨åœ¨è§£å†³æ¥è§¦å¯†é›†å‹ï¼ˆcontact-richï¼‰æ“ä½œä»»åŠ¡ã€‚è¯¥æ¡†æ¶åˆ©ç”¨å…·æœ‰å¤–åŠ›çŸ©ï¼ˆwrenchesï¼‰äº¤å‰æ³¨æ„åŠ›çš„Transformer-based Diffusion Modelæ¥é‡æ„æ¨¡æ‹Ÿé›¶åŠ›è½¨è¿¹ï¼ˆsZFTï¼‰ï¼Œå¹¶å¼•å…¥ä¸€ç§æ–°å‹çš„åŸºäºSLERPçš„å››å…ƒæ•°å™ªå£°è°ƒåº¦å™¨ï¼ˆquaternion noise schedulerï¼‰ä»¥ç¡®ä¿æ—‹è½¬çš„å‡ ä½•ä¸€è‡´æ€§ã€‚é€šè¿‡åŸºäºèƒ½é‡çš„ä¼°è®¡å™¨åŠ¨æ€æ›´æ–°åˆšåº¦ï¼ˆstiffnessï¼‰å’Œé˜»å°¼ï¼ˆdampingï¼‰å‚æ•°ï¼Œå¹¶åº”ç”¨æ–¹å‘æ€§è§„åˆ™åœ¨éä»»åŠ¡è½´ä¸Šé™ä½é˜»æŠ—ï¼ŒåŒæ—¶ä¿æŒä»»åŠ¡æ–¹å‘çš„åˆšæ€§ã€‚å®éªŒæ•°æ®é€šè¿‡Apple Vision Proé¥æ“ä½œæ”¶é›†ï¼Œåœ¨KUKA LBR iiwaæœºå™¨äººä¸Šçš„æµ‹è¯•è¡¨æ˜ï¼Œè¯¥æ¨¡å‹å®ç°äº†äºšæ¯«ç±³çº§çš„å®šä½ç²¾åº¦å’Œäºšåº¦çº§çš„æ—‹è½¬ç²¾åº¦ï¼Œå¹¶æ”¯æŒå®æ—¶æ‰­çŸ©æ§åˆ¶ã€‚åœ¨æ²¡æœ‰ä»»ä½•ç‰¹å®šæ¼”ç¤ºçš„æƒ…å†µä¸‹ï¼Œè¯¥æ§åˆ¶å™¨åœ¨åœ†æŸ±ã€æ–¹å—å’Œæ˜Ÿå½¢é”€é’‰æ’å…¥ä»»åŠ¡ä¸­å‡è¾¾åˆ°äº†100%çš„æˆåŠŸç‡ã€‚è¿™ä¸€æˆæœæˆåŠŸèåˆäº†åŸºäºæ¨¡å‹çš„ç‰©ç†äº¤äº’æ§åˆ¶ä¸åŸºäºå­¦ä¹ çš„è½¨è¿¹ç”Ÿæˆæ–¹æ³•ï¼Œæ˜¯è¿ˆå‘ç‰©ç†äººå·¥æ™ºèƒ½ï¼ˆPhysical AIï¼‰çš„é‡è¦ä¸€æ­¥ã€‚",
      "categories": [
        "cs.RO",
        "cs.AI",
        "cs.LG"
      ],
      "primary_category": "cs.RO",
      "comment": "15 pages, 12 figures",
      "pdf_url": "https://arxiv.org/pdf/2509.19696v2",
      "published_date": "2025-09-24 02:07:17 UTC",
      "updated_date": "2025-09-29 11:22:15 UTC",
      "processing_status": "completed",
      "attempts": 1,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "llm_backup_calls": 0,
      "last_update": "2026-01-24T21:04:24.591120+00:00"
    },
    {
      "arxiv_id": "2509.19695v2",
      "title": "DyBBT: Dynamic Balance via Bandit inspired Targeting for Dialog Policy with Cognitive Dual-Systems",
      "title_zh": "DyBBTï¼šåŸºäº Bandit å¯å‘å¼å®šå‘çš„è®¤çŸ¥åŒç³»ç»Ÿå¯¹è¯ç­–ç•¥åŠ¨æ€å¹³è¡¡",
      "authors": [
        "Shuyu Zhang",
        "Yifan Wei",
        "Jialuo Yuan",
        "Xinru Wang",
        "Yanmin Zhu",
        "Bin Li",
        "Yujie Liu"
      ],
      "abstract": "Task oriented dialog systems often rely on static exploration strategies that do not adapt to dynamic dialog contexts, leading to inefficient exploration and suboptimal performance. We propose DyBBT, a novel dialog policy learning framework that formalizes the exploration challenge through a structured cognitive state space capturing dialog progression, user uncertainty, and slot dependency. DyBBT proposes a bandit inspired meta-controller that dynamically switches between a fast intuitive inference (System 1) and a slow deliberative reasoner (System 2) based on real-time cognitive states and visitation counts. Extensive experiments on single- and multi-domain benchmarks show that DyBBT achieves state-of-the-art performance in success rate, efficiency, and generalization, with human evaluations confirming its decisions are well aligned with expert judgment. Code is available at https://github.com/carsonz/DyBBT.",
      "tldr_zh": "è¯¥ç ”ç©¶é’ˆå¯¹ä»»åŠ¡å‹å¯¹è¯ç³»ç»Ÿ(Task oriented dialog systems)åœ¨åŠ¨æ€è¯­å¢ƒä¸‹å› é™æ€æ¢ç´¢ç­–ç•¥å¯¼è‡´çš„æ•ˆç‡ä½ä¸‹é—®é¢˜ï¼Œæå‡ºäº†åä¸º DyBBT çš„æ–°å‹å¯¹è¯ç­–ç•¥å­¦ä¹ æ¡†æ¶ã€‚DyBBT é€šè¿‡æ„å»ºç»“æ„åŒ–çš„è®¤çŸ¥çŠ¶æ€ç©ºé—´æ¥å½¢å¼åŒ–æ¢ç´¢æŒ‘æˆ˜ï¼Œè¯¥ç©ºé—´èƒ½å¤Ÿæœ‰æ•ˆæ•æ‰å¯¹è¯è¿›ç¨‹ã€ç”¨æˆ·ä¸ç¡®å®šæ€§å’Œæ§½ä½ä¾èµ–(slot dependency)ã€‚è¯¥æ¡†æ¶å¼•å…¥äº†ä¸€ä¸ªå—å¤šè‡‚è€è™æœº(bandit inspired)å¯å‘çš„å…ƒæ§åˆ¶å™¨ï¼Œèƒ½å¤Ÿæ ¹æ®å®æ—¶è®¤çŸ¥çŠ¶æ€å’Œè®¿é—®è®¡æ•°ï¼Œåœ¨å¿«é€Ÿç›´è§‰æ¨ç†(System 1)ä¸æ…¢é€Ÿå®¡æ…æ¨ç†(System 2)ä¹‹é—´å®ç°åŠ¨æ€åˆ‡æ¢ä¸å¹³è¡¡ã€‚åœ¨å•é¢†åŸŸå’Œå¤šé¢†åŸŸåŸºå‡†æµ‹è¯•ä¸­çš„å®éªŒç»“æœæ˜¾ç¤ºï¼ŒDyBBT åœ¨æˆåŠŸç‡ã€æ•ˆç‡åŠæ³›åŒ–æ€§æ–¹é¢å‡è¾¾åˆ°äº†å½“å‰é¢†å…ˆ(SOTA)æ°´å¹³ã€‚äººå·¥è¯„ä¼°è¿›ä¸€æ­¥è¯å®äº†è¯¥ç³»ç»Ÿçš„å†³ç­–è¿‡ç¨‹ä¸ä¸“å®¶åˆ¤æ–­é«˜åº¦ä¸€è‡´ï¼Œè¯æ˜äº†å…¶åœ¨å¤„ç†å¤æ‚å¯¹è¯é€»è¾‘æ—¶çš„ä¼˜è¶Šæ€§ã€‚",
      "categories": [
        "cs.CL",
        "cs.AI",
        "cs.IR"
      ],
      "primary_category": "cs.CL",
      "comment": "",
      "pdf_url": "https://arxiv.org/pdf/2509.19695v2",
      "published_date": "2025-09-24 02:06:26 UTC",
      "updated_date": "2026-01-07 10:51:43 UTC",
      "processing_status": "completed",
      "attempts": 1,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "llm_backup_calls": 0,
      "last_update": "2026-01-24T21:04:29.801121+00:00"
    },
    {
      "arxiv_id": "2509.21389v2",
      "title": "Towards Adapting Federated & Quantum Machine Learning for Network Intrusion Detection: A Survey",
      "title_zh": "é¢å‘ç½‘ç»œå…¥ä¾µæ£€æµ‹çš„è”é‚¦ä¸é‡å­æœºå™¨å­¦ä¹ é€‚é…ç ”ç©¶ç»¼è¿°",
      "authors": [
        "Devashish Chaudhary",
        "Sutharshan Rajasegarar",
        "Shiva Raj Pokhrel"
      ],
      "abstract": "This survey explores the integration of Federated Learning (FL) with Network Intrusion Detection Systems (NIDS), with particular emphasis on deep learning and quantum machine learning approaches. FL enables collaborative model training across distributed devices while preserving data privacy-a critical requirement in network security contexts where sensitive traffic data cannot be centralized. Our comprehensive analysis systematically examines the full spectrum of FL architectures, deployment strategies, communication protocols, and aggregation methods specifically tailored for intrusion detection. We provide an in-depth investigation of privacy-preserving techniques, model compression approaches, and attack-specific federated solutions for threats including DDoS, MITM, and botnet attacks. The survey further delivers a pioneering exploration of Quantum FL (QFL), discussing quantum feature encoding, quantum machine learning algorithms, and quantum-specific aggregation methods that promise exponential speedups for complex pattern recognition in network traffic. Through rigorous comparative analysis of classical and quantum approaches, identification of research gaps, and evaluation of real-world deployments, we outline a concrete roadmap for industrial adoption and future research directions. This work serves as an authoritative reference for researchers and practitioners seeking to enhance privacy, efficiency, and robustness of federated intrusion detection systems in increasingly complex network environments, while preparing for the quantum-enhanced cybersecurity landscape of tomorrow.",
      "tldr_zh": "è¯¥ç»¼è¿°æ¢è®¨äº†è”é‚¦å­¦ä¹ (Federated Learning, FL)ä¸ç½‘ç»œå…¥ä¾µæ£€æµ‹ç³»ç»Ÿ(NIDS)çš„é›†æˆï¼Œé‡ç‚¹åˆ†æäº†æ·±åº¦å­¦ä¹ å’Œé‡å­æœºå™¨å­¦ä¹ (Quantum Machine Learning)çš„åº”ç”¨å‰æ™¯ã€‚é€šè¿‡FLå®ç°çš„åˆ†å¸ƒå¼åä½œè®­ç»ƒèƒ½åœ¨ä¿æŠ¤æ•æ„Ÿæµé‡æ•°æ®éšç§çš„åŒæ—¶ï¼Œæœ‰æ•ˆæå‡ç½‘ç»œæ”»å‡»é˜²å¾¡çš„ç¨³å¥æ€§ã€‚æ–‡ç« ç³»ç»Ÿè°ƒç ”äº†é’ˆå¯¹å…¥ä¾µæ£€æµ‹å®šåˆ¶çš„FLæ¶æ„ã€é€šä¿¡åè®®åŠèšåˆæ–¹æ³•ï¼Œå¹¶æ·±å…¥æ¢è®¨äº†åº”å¯¹DDoSã€MITMå’Œåƒµå°¸ç½‘ç»œæ”»å‡»çš„éšç§ä¿æŠ¤ä¸æ¨¡å‹å‹ç¼©æŠ€æœ¯ã€‚è¯¥ç ”ç©¶è¿˜å¼€åˆ›æ€§åœ°æ¢ç´¢äº†é‡å­è”é‚¦å­¦ä¹ (Quantum Federated Learning, QFL)ï¼Œæ¶µç›–é‡å­ç‰¹å¾ç¼–ç ä¸ç®—æ³•ï¼Œæ—¨åœ¨åˆ©ç”¨é‡å­ä¼˜åŠ¿å®ç°å¤æ‚ç½‘ç»œæ¨¡å¼è¯†åˆ«çš„æŒ‡æ•°çº§åŠ é€Ÿã€‚é€šè¿‡å¯¹ç»å…¸ä¸é‡å­æ–¹æ¡ˆçš„ä¸¥è°¨å¯¹æ¯”ï¼Œç ”ç©¶è¯†åˆ«äº†ç°æœ‰æŠ€æœ¯çš„å·®è·ï¼Œå¹¶ä¸ºå·¥ä¸šåŒ–è½åœ°åŠæœªæ¥ç½‘ç»œå®‰å…¨ç ”ç©¶æä¾›äº†æ˜ç¡®çš„è·¯çº¿å›¾ã€‚",
      "categories": [
        "cs.CR",
        "cs.AI"
      ],
      "primary_category": "cs.CR",
      "comment": "34 pages, 16 figures",
      "pdf_url": "https://arxiv.org/pdf/2509.21389v2",
      "published_date": "2025-09-24 01:39:34 UTC",
      "updated_date": "2025-11-12 11:06:48 UTC",
      "processing_status": "completed",
      "attempts": 1,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "llm_backup_calls": 0,
      "last_update": "2026-01-24T21:04:33.547779+00:00"
    },
    {
      "arxiv_id": "2509.19681v1",
      "title": "Calibrated Reasoning: An Explanatory Verifier for Dynamic and Efficient Problem-Solving",
      "title_zh": "æ ¡å‡†æ¨ç†ï¼šé¢å‘åŠ¨æ€é«˜æ•ˆé—®é¢˜æ±‚è§£çš„è§£é‡Šæ€§éªŒè¯å™¨",
      "authors": [
        "Anisha Garg",
        "Engin Tekin",
        "Yash More",
        "David Bick",
        "Nishit Neema",
        "Ganesh Venkatesh"
      ],
      "abstract": "Advanced test-time computing strategies are essential for scaling reasoning models, but their effectiveness is capped by the models' poor self-evaluation. We propose a pairwise Explanatory Verifier, trained via reinforcement learning (GRPO), that produces calibrated confidence scores and associated natural language reasoning for generated solutions. Our verifier improves the accuracy and efficiency of test-time strategies like best-of-n and self-reflection. Crucially, it excels at identifying challenging failure modes, such as when both candidate solutions are identically incorrect, succeeding where standard methods like majority voting fail.",
      "tldr_zh": "è¯¥ç ”ç©¶é’ˆå¯¹æ¨ç†æ¨¡å‹è‡ªè¯„èƒ½åŠ›ä¸è¶³é™åˆ¶æµ‹è¯•æ—¶è®¡ç®—ç­–ç•¥æ‰©å±•çš„é—®é¢˜ï¼Œæå‡ºäº† Calibrated Reasoning æ¡†æ¶ï¼Œå…¶æ ¸å¿ƒæ˜¯ä¸€ä¸ªæˆå¯¹çš„è§£é‡Šæ€§éªŒè¯å™¨ Explanatory Verifierã€‚è¯¥éªŒè¯å™¨é‡‡ç”¨å¼ºåŒ–å­¦ä¹ ç®—æ³• GRPO è¿›è¡Œè®­ç»ƒï¼Œèƒ½å¤Ÿé’ˆå¯¹ç”Ÿæˆçš„è§£å†³æ–¹æ¡ˆæä¾›æ ¡å‡†åçš„ç½®ä¿¡åº¦è¯„åˆ†åŠå…¶å…³è”çš„è‡ªç„¶è¯­è¨€æ¨ç†è¿‡ç¨‹ã€‚è¿™ç§æ–¹æ³•æ˜¾è‘—ä¼˜åŒ–äº† Best-of-n å’Œ Self-reflection ç­‰æµ‹è¯•æ—¶ç­–ç•¥çš„å‡†ç¡®æ€§ä¸æ•ˆç‡ã€‚å…³é”®ç ”ç©¶å‘ç°ï¼Œè¯¥éªŒè¯å™¨åœ¨å¤„ç†å¤æ‚çš„å¤±è´¥æ¨¡å¼æ—¶è¡¨ç°ä¼˜å¼‚ï¼Œä¾‹å¦‚å½“å¤šä¸ªå€™é€‰æ–¹æ¡ˆå‡ºç°ç›¸åŒçš„é”™è¯¯é€»è¾‘æ—¶ï¼Œå®ƒèƒ½æˆåŠŸè¯†åˆ«å‡ºä¼ ç»Ÿ Majority Voting æ–¹æ³•æ— æ³•å¯Ÿè§‰çš„é—®é¢˜ã€‚é€šè¿‡ç»“åˆå¯è§£é‡Šçš„åé¦ˆä¸ç²¾ç¡®çš„è‡ªè¯„æœºåˆ¶ï¼Œè¯¥ç ”ç©¶ä¸ºå®ç°åŠ¨æ€ä¸”é«˜æ•ˆçš„å¤æ‚é—®é¢˜è§£å†³æä¾›äº†é‡è¦æ”¯æ’‘ã€‚",
      "categories": [
        "cs.AI"
      ],
      "primary_category": "cs.AI",
      "comment": "39th Conference on Neural Information Processing Systems (NeurIPS 2025) Workshop: Efficient Reasoning",
      "pdf_url": "https://arxiv.org/pdf/2509.19681v1",
      "published_date": "2025-09-24 01:36:00 UTC",
      "updated_date": "2025-09-24 01:36:00 UTC",
      "processing_status": "completed",
      "attempts": 1,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "llm_backup_calls": 0,
      "last_update": "2026-01-24T21:04:33.164067+00:00"
    },
    {
      "arxiv_id": "2509.19680v1",
      "title": "PolicyPad: Collaborative Prototyping of LLM Policies",
      "title_zh": "PolicyPadï¼šå¤§è¯­è¨€æ¨¡å‹ç­–ç•¥çš„åä½œå¼åŸå‹è®¾è®¡",
      "authors": [
        "K. J. Kevin Feng",
        "Tzu-Sheng Kuo",
        "Quan Ze",
        "Chen",
        "Inyoung Cheong",
        "Kenneth Holstein",
        "Amy X. Zhang"
      ],
      "abstract": "As LLMs gain adoption in high-stakes domains like mental health, domain experts are increasingly consulted to provide input into policies governing their behavior. From an observation of 19 policymaking workshops with 9 experts over 15 weeks, we identified opportunities to better support rapid experimentation, feedback, and iteration for collaborative policy design processes. We present PolicyPad, an interactive system that facilitates the emerging practice of LLM policy prototyping by drawing from established UX prototyping practices, including heuristic evaluation and storyboarding. Using PolicyPad, policy designers can collaborate on drafting a policy in real time while independently testing policy-informed model behavior with usage scenarios. We evaluate PolicyPad through workshops with 8 groups of 22 domain experts in mental health and law, finding that PolicyPad enhanced collaborative dynamics during policy design, enabled tight feedback loops, and led to novel policy contributions. Overall, our work paves participatory paths for advancing AI alignment and safety.",
      "tldr_zh": "è¯¥ç ”ç©¶é’ˆå¯¹å¤§è¯­è¨€æ¨¡å‹(LLMs)åœ¨å¿ƒç†å¥åº·ç­‰é«˜é£é™©é¢†åŸŸçš„æ”¿ç­–(Policies)åˆ¶å®šé—®é¢˜ï¼Œé€šè¿‡å¯¹19åœºå·¥ä½œåŠçš„é•¿æœŸè§‚å¯Ÿï¼Œç¡®å®šäº†åä½œæ”¿ç­–è®¾è®¡ä¸­å¯¹å¿«é€Ÿå®éªŒã€åé¦ˆå’Œè¿­ä»£çš„éœ€æ±‚ã€‚ä¸ºæ­¤æå‡ºçš„ PolicyPad æ˜¯ä¸€æ¬¾äº¤äº’å¼ç³»ç»Ÿï¼Œå®ƒå€Ÿé‰´äº†å¯å‘å¼è¯„ä¼°(Heuristic Evaluation)å’Œåˆ†é•œè„šæœ¬(Storyboarding)ç­‰ç”¨æˆ·ä½“éªŒåŸå‹è®¾è®¡å®è·µï¼Œæ—¨åœ¨æ”¯æŒ LLM æ”¿ç­–çš„åä½œåŸå‹è®¾è®¡ã€‚è¯¥ç³»ç»Ÿå…è®¸æ”¿ç­–è®¾è®¡è€…åœ¨å®æ—¶åä½œèµ·è‰æ”¿ç­–çš„åŒæ—¶ï¼Œèƒ½å¤Ÿé€šè¿‡å…·ä½“ä½¿ç”¨åœºæ™¯ç‹¬ç«‹æµ‹è¯•å—æ”¿ç­–çº¦æŸçš„æ¨¡å‹è¡Œä¸ºã€‚é€šè¿‡å¯¹æ¥è‡ªå¿ƒç†å¥åº·å’Œæ³•å¾‹é¢†åŸŸçš„22åä¸“å®¶è¿›è¡Œè¯„ä¼°ï¼Œç»“æœè¡¨æ˜ PolicyPad æ˜¾è‘—å¢å¼ºäº†åä½œåŠ¨æ€å¹¶å®ç°äº†ç´§å¯†çš„åé¦ˆé—­ç¯ã€‚è¿™é¡¹å·¥ä½œä¸ºæ¨è¿›äººå·¥æ™ºèƒ½å¯¹é½(AI Alignment)å’Œå®‰å…¨æä¾›äº†æœ‰æ•ˆçš„å‚ä¸å¼è·¯å¾„ï¼Œå¹¶æˆåŠŸå¼•å¯¼äº§å‡ºäº†æ–°é¢–çš„æ”¿ç­–è´¡çŒ®ã€‚",
      "categories": [
        "cs.HC",
        "cs.AI"
      ],
      "primary_category": "cs.HC",
      "comment": "",
      "pdf_url": "https://arxiv.org/pdf/2509.19680v1",
      "published_date": "2025-09-24 01:33:05 UTC",
      "updated_date": "2025-09-24 01:33:05 UTC",
      "processing_status": "completed",
      "attempts": 1,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "llm_backup_calls": 0,
      "last_update": "2026-01-24T21:04:35.571319+00:00"
    },
    {
      "arxiv_id": "2509.19676v1",
      "title": "Thinking While Listening: Simple Test Time Scaling For Audio Classification",
      "title_zh": "å¬ä¸­æ€è€ƒï¼šéŸ³é¢‘åˆ†ç±»çš„ç®€å•æµ‹è¯•æ—¶ç¼©æ”¾",
      "authors": [
        "Prateek Verma",
        "Mert Pilanci"
      ],
      "abstract": "We propose a framework that enables neural models to \"think while listening\" to everyday sounds, thereby enhancing audio classification performance. Motivated by recent advances in the reasoning capabilities of large language models, we address two central questions: (i) how can thinking be incorporated into existing audio classification pipelines to enable reasoning in the category space and improve performance, and (ii) can a new architecture be designed from the ground up to support both thinking and test-time scaling? We demonstrate that in both settings, our models exhibit improved classification accuracy. Leveraging test-time scaling, we observe consistent gains as the number of sampled traces increases. Furthermore, we evaluate two open-source reasoning models, GPT-OSS-20B and Qwen3-14B, showing that while such models are capable of zero-shot reasoning, a lightweight approach--retraining only the embedding matrix of a frozen, smaller model like GPT-2--can surpass the performance of billion-parameter text-based reasoning models.",
      "tldr_zh": "è¯¥ç ”ç©¶æå‡ºäº†ä¸€ä¸ªåä¸ºâ€œThinking While Listeningâ€çš„æ¡†æ¶ï¼Œæ—¨åœ¨é€šè¿‡èµ‹äºˆç¥ç»æ¨¡å‹åœ¨æ”¶å¬æ—¥å¸¸å£°éŸ³æ—¶è¿›è¡Œâ€œæ€è€ƒâ€çš„èƒ½åŠ›ï¼Œä»è€Œæå‡éŸ³é¢‘åˆ†ç±»(Audio Classification)æ€§èƒ½ã€‚å—å¤§è¯­è¨€æ¨¡å‹(LLMs)æ¨ç†èƒ½åŠ›è¿›å±•çš„å¯å‘ï¼Œè¯¥æ¡†æ¶æ¢è®¨äº†å¦‚ä½•å°†æ¨ç†æœºåˆ¶æ•´åˆè¿›ç°æœ‰æµç¨‹ä»¥å®ç°åœ¨ç±»åˆ«ç©ºé—´(Category Space)çš„æ¨ç†ï¼Œå¹¶è®¾è®¡äº†ä¸€ç§æ”¯æŒæµ‹è¯•æ—¶ç¼©æ”¾(Test-Time Scaling)çš„æ–°æ¶æ„ã€‚å®éªŒç»“æœè¡¨æ˜ï¼Œè¯¥æ¨¡å‹åœ¨ä¸¤ç§è®¾ç½®ä¸‹å‡æ˜¾è‘—æé«˜äº†åˆ†ç±»å‡†ç¡®ç‡ï¼Œä¸”éšç€é‡‡æ ·è½¨è¿¹(Sampled Traces)æ•°é‡çš„å¢åŠ ï¼Œå…¶æµ‹è¯•æ—¶ç¼©æ”¾å±•ç°å‡ºæŒç»­çš„æ€§èƒ½å¢ç›Šã€‚åœ¨ä¸GPT-OSS-20Bå’ŒQwen3-14Bç­‰å¤§å‹å¼€æºæ¨ç†æ¨¡å‹çš„å¯¹æ¯”ä¸­ï¼Œç ”ç©¶å‘ç°é€šè¿‡ä»…é‡æ–°è®­ç»ƒå†»ç»“çš„å°å‹æ¨¡å‹ï¼ˆå¦‚GPT-2ï¼‰çš„åµŒå…¥çŸ©é˜µ(Embedding Matrix)è¿™ä¸€è½»é‡çº§æ–¹æ³•ï¼Œå…¶æ€§èƒ½èƒ½å¤Ÿæœ‰æ•ˆè¶…è¶Šæ•°åäº¿å‚æ•°è§„æ¨¡çš„æ–‡æœ¬æ¨ç†æ¨¡å‹åœ¨é›¶æ ·æœ¬æ¨ç†(Zero-Shot Reasoning)ä»»åŠ¡ä¸­çš„è¡¨ç°ã€‚",
      "categories": [
        "cs.SD",
        "cs.AI",
        "cs.LG",
        "eess.AS"
      ],
      "primary_category": "cs.SD",
      "comment": "6 pages, 3 figures, 2 Tables, ICASSP 2026",
      "pdf_url": "https://arxiv.org/pdf/2509.19676v1",
      "published_date": "2025-09-24 01:17:24 UTC",
      "updated_date": "2025-09-24 01:17:24 UTC",
      "processing_status": "completed",
      "attempts": 1,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "llm_backup_calls": 0,
      "last_update": "2026-01-24T21:04:43.466006+00:00"
    },
    {
      "arxiv_id": "2509.19669v1",
      "title": "Games Are Not Equal: Classifying Cloud Gaming Contexts for Effective User Experience Measurement",
      "title_zh": "æ¸¸æˆå¹¶ä¸ç›¸åŒï¼šé¢å‘æœ‰æ•ˆç”¨æˆ·ä½“éªŒæµ‹é‡çš„äº‘æ¸¸æˆæƒ…å¢ƒåˆ†ç±»",
      "authors": [
        "Yifan Wang",
        "Minzhao Lyu",
        "Vijay Sivaraman"
      ],
      "abstract": "To tap into the growing market of cloud gaming, whereby game graphics is rendered in the cloud and streamed back to the user as a video feed, network operators are creating monetizable assurance services that dynamically provision network resources. However, without accurately measuring cloud gaming user experience, they cannot assess the effectiveness of their provisioning methods. Basic measures such as bandwidth and frame rate by themselves do not suffice, and can only be interpreted in the context of the game played and the player activity within the game. This paper equips the network operator with a method to obtain a real-time measure of cloud gaming experience by analyzing network traffic, including contextual factors such as the game title and player activity stage. Our method is able to classify the game title within the first five seconds of game launch, and continuously assess the player activity stage as being active, passive, or idle. We deploy it in an ISP hosting NVIDIA cloud gaming servers for the region. We provide insights from hundreds of thousands of cloud game streaming sessions over a three-month period into the dependence of bandwidth consumption and experience level on the gameplay contexts.",
      "tldr_zh": "è¯¥ç ”ç©¶é’ˆå¯¹äº‘æ¸¸æˆ(Cloud Gaming)é¢†åŸŸæå‡ºäº†ä¸€ç§é€šè¿‡åˆ†æç½‘ç»œæµé‡æ¥å®æ—¶è¡¡é‡ç”¨æˆ·ä½“éªŒ(User Experience)çš„æ–°æ–¹æ³•ã€‚ç”±äºå¸¦å®½å’Œå¸§ç‡ç­‰åŸºç¡€æŒ‡æ ‡æ— æ³•å……åˆ†åæ˜ å®é™…ä½“éªŒï¼Œè¯¥æ–¹æ³•å¼•å…¥äº†æ¸¸æˆæ ‡é¢˜å’Œç©å®¶æ´»åŠ¨é˜¶æ®µ(Player Activity Stage)ç­‰å…³é”®ä¸Šä¸‹æ–‡å› ç´ ã€‚è¯¥æŠ€æœ¯èƒ½å¤Ÿåœ¨æ¸¸æˆå¯åŠ¨çš„å‰äº”ç§’å†…è¯†åˆ«å‡ºæ¸¸æˆæ ‡é¢˜ï¼Œå¹¶æŒç»­å°†ç©å®¶æ´»åŠ¨åˆ†ç±»ä¸ºæ´»è·ƒ(Active)ã€è¢«åŠ¨(Passive)æˆ–é—²ç½®(Idle)çŠ¶æ€ã€‚ç ”ç©¶äººå‘˜åœ¨ä¸€å®¶æ‰˜ç®¡NVIDIAäº‘æ¸¸æˆæœåŠ¡å™¨çš„äº’è”ç½‘æœåŠ¡æä¾›å•†(ISP)ä¸­å®é™…éƒ¨ç½²äº†è¯¥ç³»ç»Ÿï¼Œå¹¶å¯¹ä¸‰ä¸ªæœˆå†…æ•°åä¸‡ä¸ªæµåª’ä½“ä¼šè¯è¿›è¡Œäº†æ·±å…¥åˆ†æã€‚å®éªŒç»“æœæ­ç¤ºäº†å¸¦å®½æ¶ˆè€—å’Œä½“éªŒæ°´å¹³å¯¹æ¸¸æˆä¸Šä¸‹æ–‡çš„é«˜åº¦ä¾èµ–æ€§ï¼Œä¸ºç½‘ç»œè¿è¥å•†åŠ¨æ€é…ç½®ç½‘ç»œèµ„æºä»¥å®ç°æœ‰æ•ˆçš„æœåŠ¡ä¿éšœæä¾›äº†ç§‘å­¦çš„å†³ç­–ä¾æ®ã€‚",
      "categories": [
        "cs.NI",
        "cs.AI"
      ],
      "primary_category": "cs.NI",
      "comment": "This paper is accepted at ACM Internet Measurement Conference (IMC) 2025. In Proc. ACM IMC, Oct, 2025, Madison, WI, USA",
      "pdf_url": "https://arxiv.org/pdf/2509.19669v1",
      "published_date": "2025-09-24 01:02:24 UTC",
      "updated_date": "2025-09-24 01:02:24 UTC",
      "processing_status": "completed",
      "attempts": 1,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "llm_backup_calls": 0,
      "last_update": "2026-01-24T21:04:45.083638+00:00"
    },
    {
      "arxiv_id": "2509.19668v1",
      "title": "Selective Classifier-free Guidance for Zero-shot Text-to-speech",
      "title_zh": "é’ˆå¯¹é›¶æ ·æœ¬è¯­éŸ³åˆæˆçš„é€‰æ‹©æ€§æ— åˆ†ç±»å™¨å¼•å¯¼",
      "authors": [
        "John Zheng",
        "Farhad Maleki"
      ],
      "abstract": "In zero-shot text-to-speech, achieving a balance between fidelity to the target speaker and adherence to text content remains a challenge. While classifier-free guidance (CFG) strategies have shown promising results in image generation, their application to speech synthesis are underexplored. Separating the conditions used for CFG enables trade-offs between different desired characteristics in speech synthesis. In this paper, we evaluate the adaptability of CFG strategies originally developed for image generation to speech synthesis and extend separated-condition CFG approaches for this domain. Our results show that CFG strategies effective in image generation generally fail to improve speech synthesis. We also find that we can improve speaker similarity while limiting degradation of text adherence by applying standard CFG during early timesteps and switching to selective CFG only in later timesteps. Surprisingly, we observe that the effectiveness of a selective CFG strategy is highly text-representation dependent, as differences between the two languages of English and Mandarin can lead to different results even with the same model.",
      "tldr_zh": "è¯¥ç ”ç©¶æ¢è®¨äº†åœ¨é›¶æ ·æœ¬è¯­éŸ³åˆæˆ (zero-shot text-to-speech) ä¸­å¦‚ä½•å¹³è¡¡è¯´è¯äººä¿çœŸåº¦ä¸æ–‡æœ¬ä¸€è‡´æ€§çš„æŒ‘æˆ˜ã€‚é€šè¿‡è¯„ä¼°å›¾åƒç”Ÿæˆé¢†åŸŸå¸¸ç”¨çš„æ— åˆ†ç±»å™¨å¼•å¯¼ (classifier-free guidance, CFG) ç­–ç•¥ï¼Œä½œè€…å‘ç°ç›´æ¥è¿ç§»è¿™äº›ç­–ç•¥é€šå¸¸æ— æ³•æœ‰æ•ˆæ”¹å–„è¯­éŸ³åˆæˆè´¨é‡ã€‚ä¸ºæ­¤ï¼Œç ”ç©¶æå‡ºåœ¨ç”Ÿæˆçš„æ—©æœŸæ—¶é—´æ­¥åº”ç”¨æ ‡å‡† CFGï¼Œå¹¶åœ¨åæœŸåˆ‡æ¢ä¸ºé€‰æ‹©æ€§ CFG (selective CFG) çš„ç­–ç•¥ï¼Œä»è€Œåœ¨æå‡è¯´è¯äººç›¸ä¼¼åº¦çš„åŒæ—¶å‡å°‘æ–‡æœ¬ä¸€è‡´æ€§çš„ä¸‹é™ã€‚å®éªŒè¿˜å‘ç°ï¼Œé€‰æ‹©æ€§ CFG çš„æœ‰æ•ˆæ€§é«˜åº¦ä¾èµ–äºæ–‡æœ¬è¡¨å¾ (text-representation)ï¼Œå³ä½¿ä½¿ç”¨ç›¸åŒæ¨¡å‹ï¼Œåœ¨è‹±è¯­å’Œä¸­æ–‡è¯­å¢ƒä¸‹ä¹Ÿä¼šäº§ç”Ÿä¸åŒçš„ç»“æœã€‚è¿™é¡¹å·¥ä½œä¸ºåœ¨è¯­éŸ³åˆæˆé¢†åŸŸä¼˜åŒ– CFG åº”ç”¨æä¾›äº†é‡è¦è§è§£ã€‚",
      "categories": [
        "eess.AS",
        "cs.AI",
        "cs.SD"
      ],
      "primary_category": "eess.AS",
      "comment": "5 pages, 7 figures, 1 table. Submitted to ICASSP 2026",
      "pdf_url": "https://arxiv.org/pdf/2509.19668v1",
      "published_date": "2025-09-24 01:00:27 UTC",
      "updated_date": "2025-09-24 01:00:27 UTC",
      "processing_status": "completed",
      "attempts": 1,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "llm_backup_calls": 0,
      "last_update": "2026-01-24T21:04:45.250594+00:00"
    },
    {
      "arxiv_id": "2509.19664v1",
      "title": "MoTiC: Momentum Tightness and Contrast for Few-Shot Class-Incremental Learning",
      "title_zh": "MoTiCï¼šé¢å‘å°æ ·æœ¬ç±»å¢é‡å­¦ä¹ çš„åŠ¨é‡ç´§è‡´æ€§ä¸å¯¹æ¯”å­¦ä¹ ",
      "authors": [
        "Zeyu He",
        "Shuai Huang",
        "Yuwu Lu",
        "Ming Zhao"
      ],
      "abstract": "Few-Shot Class-Incremental Learning (FSCIL) must contend with the dual challenge of learning new classes from scarce samples while preserving old class knowledge. Existing methods use the frozen feature extractor and class-averaged prototypes to mitigate against catastrophic forgetting and overfitting. However, new-class prototypes suffer significant estimation bias due to extreme data scarcity, whereas base-class prototypes benefit from sufficient data. In this work, we theoretically demonstrate that aligning the new-class priors with old-class statistics via Bayesian analysis reduces variance and improves prototype accuracy. Furthermore, we propose large-scale contrastive learning to enforce cross-category feature tightness. To further enrich feature diversity and inject prior information for new-class prototypes, we integrate momentum self-supervision and virtual categories into the Momentum Tightness and Contrast framework (MoTiC), constructing a feature space with rich representations and enhanced interclass cohesion. Experiments on three FSCIL benchmarks produce state-of-the-art performances, particularly on the fine-grained task CUB-200, validating our method's ability to reduce estimation bias and improve incremental learning robustness.",
      "tldr_zh": "è¯¥ç ”ç©¶é’ˆå¯¹å°æ ·æœ¬ç±»å¢é‡å­¦ä¹  (Few-Shot Class-Incremental Learning, FSCIL) ä¸­æ–°ç±»æ ·æœ¬åŒ®ä¹å¯¼è‡´çš„åŸå‹ä¼°è®¡åå·®å’Œç¾éš¾æ€§é—å¿˜é—®é¢˜ï¼Œæå‡ºäº†åä¸º MoTiC (Momentum Tightness and Contrast) çš„æ–°å‹æ¡†æ¶ã€‚é€šè¿‡è´å¶æ–¯åˆ†æ (Bayesian analysis) ä»ç†è®ºä¸Šè¯æ˜äº†å°†æ–°ç±»å…ˆéªŒä¸æ—§ç±»ç»Ÿè®¡æ•°æ®å¯¹é½èƒ½æœ‰æ•ˆå‡å°‘æ–¹å·®å¹¶æå‡åŸå‹ç²¾åº¦ã€‚MoTiC ç»“åˆäº†å¤§è§„æ¨¡å¯¹æ¯”å­¦ä¹  (contrastive learning) ä»¥å¢å¼ºè·¨ç±»åˆ«çš„ç‰¹å¾ç´§å‡‘æ€§ï¼Œå¹¶é€šè¿‡æ•´åˆåŠ¨é‡è‡ªç›‘ç£ (momentum self-supervision) ä¸è™šæ‹Ÿç±»åˆ« (virtual categories) æ¥ä¸°å¯Œç‰¹å¾å¤šæ ·æ€§å¹¶æ³¨å…¥å…ˆéªŒä¿¡æ¯ã€‚å®éªŒç»“æœè¡¨æ˜ï¼Œè¯¥æ–¹æ³•åœ¨ä¸‰ä¸ª FSCIL åŸºå‡†æµ‹è¯•ä¸­å‡å–å¾—äº†å½“å‰æœ€å…ˆè¿› (state-of-the-art) çš„æ€§èƒ½ï¼Œç‰¹åˆ«æ˜¯åœ¨ç»†ç²’åº¦ä»»åŠ¡ CUB-200 ä¸Šè¡¨ç°æ˜¾è‘—ã€‚è¯¥ç ”ç©¶æœ‰åŠ›åœ°éªŒè¯äº†é€šè¿‡æ„å»ºé«˜å†…èšåŠ›ç‰¹å¾ç©ºé—´æ¥å‡å°‘ä¼°è®¡åå·®å¹¶æå‡å¢é‡å­¦ä¹ é²æ£’æ€§çš„æœ‰æ•ˆæ€§ã€‚",
      "categories": [
        "cs.CV",
        "cs.AI"
      ],
      "primary_category": "cs.CV",
      "comment": "",
      "pdf_url": "https://arxiv.org/pdf/2509.19664v1",
      "published_date": "2025-09-24 00:41:40 UTC",
      "updated_date": "2025-09-24 00:41:40 UTC",
      "processing_status": "completed",
      "attempts": 1,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "llm_backup_calls": 0,
      "last_update": "2026-01-24T21:04:51.067432+00:00"
    },
    {
      "arxiv_id": "2509.19658v1",
      "title": "RoboSSM: Scalable In-context Imitation Learning via State-Space Models",
      "title_zh": "RoboSSMï¼šåŸºäºçŠ¶æ€ç©ºé—´æ¨¡å‹çš„å¯æ‰©å±•ä¸Šä¸‹æ–‡æ¨¡ä»¿å­¦ä¹ ",
      "authors": [
        "Youngju Yoo",
        "Jiaheng Hu",
        "Yifeng Zhu",
        "Bo Liu",
        "Qiang Liu",
        "Roberto MartÃ­n-MartÃ­n",
        "Peter Stone"
      ],
      "abstract": "In-context imitation learning (ICIL) enables robots to learn tasks from prompts consisting of just a handful of demonstrations. By eliminating the need for parameter updates at deployment time, this paradigm supports few-shot adaptation to novel tasks. However, recent ICIL methods rely on Transformers, which have computational limitations and tend to underperform when handling longer prompts than those seen during training. In this work, we introduce RoboSSM, a scalable recipe for in-context imitation learning based on state-space models (SSM). Specifically, RoboSSM replaces Transformers with Longhorn -- a state-of-the-art SSM that provides linear-time inference and strong extrapolation capabilities, making it well-suited for long-context prompts. We evaluate our approach on the LIBERO benchmark and compare it against strong Transformer-based ICIL baselines. Experiments show that RoboSSM extrapolates effectively to varying numbers of in-context demonstrations, yields high performance on unseen tasks, and remains robust in long-horizon scenarios. These results highlight the potential of SSMs as an efficient and scalable backbone for ICIL. Our code is available at https://github.com/youngjuY/RoboSSM.",
      "tldr_zh": "è¯¥ç ”ç©¶æå‡ºäº† RoboSSMï¼Œä¸€ç§åŸºäº State-Space Models (SSM) çš„å¯æ‰©å±• In-context imitation learning (ICIL) æ¡†æ¶ï¼Œæ—¨åœ¨è§£å†³ Transformer æ¨¡å‹åœ¨å¤„ç†é•¿æç¤ºè¯æ—¶çš„è®¡ç®—å—é™ä¸å¤–æ¨èƒ½åŠ›ä¸è¶³ã€‚RoboSSM é‡‡ç”¨å…ˆè¿›çš„ SSM æ¶æ„ Longhorn æ›¿ä»£äº†ä¼ ç»Ÿçš„ Transformerï¼Œä»è€Œå®ç°äº†çº¿æ€§æ—¶é—´æ¨ç†å’Œæ›´å¼ºçš„é•¿ä¸Šä¸‹æ–‡å¤–æ¨æ€§èƒ½ã€‚åœ¨ LIBERO åŸºå‡†æµ‹è¯•ä¸­çš„è¯„ä¼°ç»“æœæ˜¾ç¤ºï¼ŒRoboSSM åœ¨é¢å¯¹ä¸åŒæ•°é‡çš„ä¸Šä¸‹æ–‡æ¼”ç¤ºæ—¶è¡¨ç°å‡ºä¼˜ç§€çš„å¤–æ¨æ•ˆæœï¼Œä¸”åœ¨æœªè§ä»»åŠ¡å’Œé•¿å‘¨æœŸåœºæ™¯ä¸­ä¿æŒäº†é«˜åº¦çš„é²æ£’æ€§ã€‚è¯¥ç ”ç©¶è¯æ˜äº† SSM ä½œä¸º ICIL éª¨å¹²ç½‘ç»œçš„é«˜æ•ˆæ€§ä¸å¯æ‰©å±•æ€§ï¼Œä¸ºæœºå™¨äººå®ç°å¿«é€Ÿçš„å°‘æ ·æœ¬ä»»åŠ¡é€‚åº”æä¾›äº†æ–°çš„è·¯å¾„ã€‚",
      "categories": [
        "cs.RO",
        "cs.AI"
      ],
      "primary_category": "cs.RO",
      "comment": "8 pages, 11 figures",
      "pdf_url": "https://arxiv.org/pdf/2509.19658v1",
      "published_date": "2025-09-24 00:26:15 UTC",
      "updated_date": "2025-09-24 00:26:15 UTC",
      "processing_status": "completed",
      "attempts": 1,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "llm_backup_calls": 0,
      "last_update": "2026-01-24T21:04:53.463563+00:00"
    },
    {
      "arxiv_id": "2509.19657v1",
      "title": "Large Language Models for Pedestrian Safety: An Application to Predicting Driver Yielding Behavior at Unsignalized Intersections",
      "title_zh": "å¤§è¯­è¨€æ¨¡å‹åœ¨è¡Œäººå®‰å…¨é¢†åŸŸçš„åº”ç”¨ï¼šæ— ä¿¡å·ç¯è·¯å£é©¾é©¶å‘˜ç¤¼è®©è¡Œä¸ºé¢„æµ‹",
      "authors": [
        "Yicheng Yang",
        "Zixian Li",
        "Jean Paul Bizimana",
        "Niaz Zafri",
        "Yongfeng Dong",
        "Tianyi Li"
      ],
      "abstract": "Pedestrian safety is a critical component of urban mobility and is strongly influenced by the interactions between pedestrian decision-making and driver yielding behavior at crosswalks. Modeling driver--pedestrian interactions at intersections requires accurately capturing the complexity of these behaviors. Traditional machine learning models often struggle to capture the nuanced and context-dependent reasoning required for these multifactorial interactions, due to their reliance on fixed feature representations and limited interpretability. In contrast, large language models (LLMs) are suited for extracting patterns from heterogeneous traffic data, enabling accurate modeling of driver-pedestrian interactions. Therefore, this paper leverages multimodal LLMs through a novel prompt design that incorporates domain-specific knowledge, structured reasoning, and few-shot prompting, enabling interpretable and context-aware inference of driver yielding behavior, as an example application of modeling pedestrian--driver interaction. We benchmarked state-of-the-art LLMs against traditional classifiers, finding that GPT-4o consistently achieves the highest accuracy and recall, while Deepseek-V3 excels in precision. These findings highlight the critical trade-offs between model performance and computational efficiency, offering practical guidance for deploying LLMs in real-world pedestrian safety systems.",
      "tldr_zh": "è¯¥ç ”ç©¶æ¢è®¨äº†å¤§å‹è¯­è¨€æ¨¡å‹(Large Language Models, LLMs)åœ¨è¡Œäººå®‰å…¨é¢†åŸŸçš„åº”ç”¨ï¼Œé‡ç‚¹å…³æ³¨éä¿¡å·äº¤å‰å£(unsignalized intersections)å¤„é©¾é©¶å‘˜è®©è¡Œè¡Œä¸º(driver yielding behavior)çš„é¢„æµ‹ã€‚ä¼ ç»Ÿæœºå™¨å­¦ä¹ æ¨¡å‹åœ¨å¤„ç†å¤æ‚çš„è¡Œäºº-é©¾é©¶å‘˜äº¤äº’æ¨ç†æ—¶ï¼Œå¾€å¾€å—é™äºå›ºå®šç‰¹å¾è¡¨ç¤ºå’Œæœ‰é™çš„å¯è§£é‡Šæ€§ã€‚ä¸ºæ­¤ï¼Œæœ¬ç ”ç©¶é€šè¿‡ä¸€ç§ç»“åˆé¢†åŸŸçŸ¥è¯†ã€ç»“æ„åŒ–æ¨ç†å’Œå°‘æ ·æœ¬æç¤º(few-shot prompting)çš„æ–°é¢–æç¤ºè¯è®¾è®¡ï¼Œåˆ©ç”¨å¤šæ¨¡æ€LLMså®ç°äº†å¯¹é©¾é©¶å‘˜è¡Œä¸ºçš„å¯è§£é‡Šæ„ŸçŸ¥æ¨æ–­ã€‚åŸºå‡†æµ‹è¯•ç»“æœè¡¨æ˜ï¼ŒGPT-4oåœ¨å‡†ç¡®ç‡å’Œå¬å›ç‡ä¸ŠæŒç»­é¢†å…ˆï¼Œè€ŒDeepseek-V3åœ¨ç²¾ç¡®ç‡(precision)æ–¹é¢è¡¨ç°å“è¶Šã€‚è¿™äº›å‘ç°æ­ç¤ºäº†æ¨¡å‹æ€§èƒ½ä¸è®¡ç®—æ•ˆç‡ä¹‹é—´çš„å…³é”®æƒè¡¡ï¼Œä¸ºåœ¨ç°å®ä¸–ç•Œè¡Œäººå®‰å…¨ç³»ç»Ÿä¸­éƒ¨ç½²LLMsæä¾›äº†å®é™…æŒ‡å¯¼ã€‚è¯¥ç ”ç©¶è¯æ˜äº†LLMsåœ¨ä»å¼‚æ„äº¤é€šæ•°æ®ä¸­æå–æ¨¡å¼å¹¶æ¨¡æ‹Ÿå¤æ‚äº¤äº’è¡Œä¸ºæ–¹é¢çš„å¼ºå¤§æ½œåŠ›ã€‚",
      "categories": [
        "cs.CL",
        "cs.AI",
        "cs.SI"
      ],
      "primary_category": "cs.CL",
      "comment": "",
      "pdf_url": "https://arxiv.org/pdf/2509.19657v1",
      "published_date": "2025-09-24 00:25:19 UTC",
      "updated_date": "2025-09-24 00:25:19 UTC",
      "processing_status": "completed",
      "attempts": 1,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "llm_backup_calls": 0,
      "last_update": "2026-01-24T21:05:05.064976+00:00"
    }
  ],
  "processing_status": "completed",
  "error": null,
  "raw_papers_fetched": true,
  "papers_count": 161,
  "processed_papers_count": 161,
  "failed_papers_count": 0,
  "llm_backup_calls": 0,
  "summary_generated": true,
  "daily_data_saved": true,
  "last_update": "2026-01-24T21:05:54.312817+00:00"
}