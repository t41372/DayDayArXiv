[
  {
    "arxiv_id": "2501.15343v1",
    "title": "Development and Application of Self-Supervised Machine Learning for Smoke Plume and Active Fire Identification from the FIREX-AQ Datasets",
    "authors": [
      "Nicholas LaHaye",
      "Anistasija Easley",
      "Kyongsik Yun",
      "Huikyo Lee",
      "Erik Linstead",
      "Michael J. Garay",
      "Olga V. Kalashnikova"
    ],
    "abstract": "Fire Influence on Regional to Global Environments and Air Quality (FIREX-AQ)\nwas a field campaign aimed at better understanding the impact of wildfires and\nagricultural fires on air quality and climate. The FIREX-AQ campaign took place\nin August 2019 and involved two aircraft and multiple coordinated satellite\nobservations. This study applied and evaluated a self-supervised machine\nlearning (ML) method for the active fire and smoke plume identification and\ntracking in the satellite and sub-orbital remote sensing datasets collected\nduring the campaign. Our unique methodology combines remote sensing\nobservations with different spatial and spectral resolutions. The demonstrated\napproach successfully differentiates fire pixels and smoke plumes from\nbackground imagery, enabling the generation of a per-instrument smoke and fire\nmask product, as well as smoke and fire masks created from the fusion of\nselected data from independent instruments. This ML approach has a potential to\nenhance operational wildfire monitoring systems and improve decision-making in\nair quality management through fast smoke plume identification12 and tracking\nand could improve climate impact studies through fusion data from independent\ninstruments.",
    "categories": [
      "cs.LG",
      "cs.AI",
      "cs.CV"
    ],
    "primary_category": "cs.LG",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2501.15343v1",
    "published_date": "2025-01-25 23:00:07 UTC",
    "updated_date": "2025-01-25 23:00:07 UTC"
  },
  {
    "arxiv_id": "2501.15322v2",
    "title": "Scaling laws for decoding images from brain activity",
    "authors": [
      "Hubert Banville",
      "Yohann Benchetrit",
      "Stéphane d'Ascoli",
      "Jérémy Rapin",
      "Jean-Rémi King"
    ],
    "abstract": "Generative AI has recently propelled the decoding of images from brain\nactivity. How do these approaches scale with the amount and type of neural\nrecordings? Here, we systematically compare image decoding from four types of\nnon-invasive devices: electroencephalography (EEG), magnetoencephalography\n(MEG), high-field functional Magnetic Resonance Imaging (3T fMRI) and\nultra-high field (7T) fMRI. For this, we evaluate decoding models on the\nlargest benchmark to date, encompassing 8 public datasets, 84 volunteers, 498\nhours of brain recording and 2.3 million brain responses to natural images.\nUnlike previous work, we focus on single-trial decoding performance to simulate\nreal-time settings. This systematic comparison reveals three main findings.\nFirst, the most precise neuroimaging devices tend to yield the best decoding\nperformances, when the size of the training sets are similar. However, the gain\nenabled by deep learning - in comparison to linear models - is obtained with\nthe noisiest devices. Second, we do not observe any plateau of decoding\nperformance as the amount of training data increases. Rather, decoding\nperformance scales log-linearly with the amount of brain recording. Third, this\nscaling law primarily depends on the amount of data per subject. However,\nlittle decoding gain is observed by increasing the number of subjects. Overall,\nthese findings delineate the path most suitable to scale the decoding of images\nfrom non-invasive brain recordings.",
    "categories": [
      "eess.IV",
      "cs.AI",
      "cs.LG",
      "q-bio.NC"
    ],
    "primary_category": "eess.IV",
    "comment": "29 pages, 14 figures, fixed typo in author list",
    "pdf_url": "http://arxiv.org/pdf/2501.15322v2",
    "published_date": "2025-01-25 20:38:36 UTC",
    "updated_date": "2025-01-28 11:46:10 UTC"
  },
  {
    "arxiv_id": "2501.15318v1",
    "title": "A Post-Processing-Based Fair Federated Learning Framework",
    "authors": [
      "Yi Zhou",
      "Naman Goel"
    ],
    "abstract": "Federated Learning (FL) allows collaborative model training among distributed\nparties without pooling local datasets at a central server. However, the\ndistributed nature of FL poses challenges in training fair federated learning\nmodels. The existing techniques are often limited in offering fairness\nflexibility to clients and performance. We formally define and empirically\nanalyze a simple and intuitive post-processing-based framework to improve group\nfairness in FL systems. This framework can be divided into two stages: a\nstandard FL training stage followed by a completely decentralized local\ndebiasing stage. In the first stage, a global model is trained without fairness\nconstraints using a standard federated learning algorithm (e.g. FedAvg). In the\nsecond stage, each client applies fairness post-processing on the global model\nusing their respective local dataset. This allows for customized fairness\nimprovements based on clients' desired and context-guided fairness\nrequirements. We demonstrate two well-established post-processing techniques in\nthis framework: model output post-processing and final layer fine-tuning. We\nevaluate the framework against three common baselines on four different\ndatasets, including tabular, signal, and image data, each with varying levels\nof data heterogeneity across clients. Our work shows that this framework not\nonly simplifies fairness implementation in FL but also provides significant\nfairness improvements with minimal accuracy loss or even accuracy gain, across\ndata modalities and machine learning methods, being especially effective in\nmore heterogeneous settings.",
    "categories": [
      "cs.LG",
      "cs.AI",
      "cs.CY"
    ],
    "primary_category": "cs.LG",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2501.15318v1",
    "published_date": "2025-01-25 20:05:27 UTC",
    "updated_date": "2025-01-25 20:05:27 UTC"
  },
  {
    "arxiv_id": "2501.15305v1",
    "title": "Enhancing Disaster Resilience with UAV-Assisted Edge Computing: A Reinforcement Learning Approach to Managing Heterogeneous Edge Devices",
    "authors": [
      "Talha Azfar",
      "Kaicong Huang",
      "Ruimin Ke"
    ],
    "abstract": "Edge sensing and computing is rapidly becoming part of intelligent\ninfrastructure architecture leading to operational reliance on such systems in\ndisaster or emergency situations. In such scenarios there is a high chance of\npower supply failure due to power grid issues, and communication system issues\ndue to base stations losing power or being damaged by the elements, e.g.,\nflooding, wildfires etc. Mobile edge computing in the form of unmanned aerial\nvehicles (UAVs) has been proposed to provide computation offloading from these\ndevices to conserve their battery, while the use of UAVs as relay network nodes\nhas also been investigated previously. This paper considers the use of UAVs\nwith further constraints on power and connectivity to prolong the life of the\nnetwork while also ensuring that the data is received from the edge nodes in a\ntimely manner. Reinforcement learning is used to investigate numerous scenarios\nof various levels of power and communication failure. This approach is able to\nidentify the device most likely to fail in a given scenario, thus providing\npriority guidance for maintenance personnel. The evacuations of a rural town\nand urban downtown area are also simulated to demonstrate the effectiveness of\nthe approach at extending the life of the most critical edge devices.",
    "categories": [
      "cs.ET",
      "cs.AI",
      "cs.DC"
    ],
    "primary_category": "cs.ET",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2501.15305v1",
    "published_date": "2025-01-25 19:03:05 UTC",
    "updated_date": "2025-01-25 19:03:05 UTC"
  },
  {
    "arxiv_id": "2501.15304v1",
    "title": "Music Generation using Human-In-The-Loop Reinforcement Learning",
    "authors": [
      "Aju Ani Justus"
    ],
    "abstract": "This paper presents an approach that combines Human-In-The-Loop Reinforcement\nLearning (HITL RL) with principles derived from music theory to facilitate\nreal-time generation of musical compositions. HITL RL, previously employed in\ndiverse applications such as modelling humanoid robot mechanics and enhancing\nlanguage models, harnesses human feedback to refine the training process. In\nthis study, we develop a HILT RL framework that can leverage the constraints\nand principles in music theory. In particular, we propose an episodic tabular\nQ-learning algorithm with an epsilon-greedy exploration policy. The system\ngenerates musical tracks (compositions), continuously enhancing its quality\nthrough iterative human-in-the-loop feedback. The reward function for this\nprocess is the subjective musical taste of the user.",
    "categories": [
      "cs.SD",
      "cs.AI",
      "cs.HC",
      "cs.LG",
      "eess.AS"
    ],
    "primary_category": "cs.SD",
    "comment": "This is a preprint of a paper presented at the 2023 IEEE\n  International Conference on Big Data (BigData). It has been made public for\n  the benefit of the community and should be considered a preprint rather than\n  a formally reviewed paper",
    "pdf_url": "http://arxiv.org/pdf/2501.15304v1",
    "published_date": "2025-01-25 19:01:51 UTC",
    "updated_date": "2025-01-25 19:01:51 UTC"
  },
  {
    "arxiv_id": "2501.15290v1",
    "title": "Advanced Real-Time Fraud Detection Using RAG-Based LLMs",
    "authors": [
      "Gurjot Singh",
      "Prabhjot Singh",
      "Maninder Singh"
    ],
    "abstract": "Artificial Intelligence has become a double edged sword in modern society\nbeing both a boon and a bane. While it empowers individuals it also enables\nmalicious actors to perpetrate scams such as fraudulent phone calls and user\nimpersonations. This growing threat necessitates a robust system to protect\nindividuals In this paper we introduce a novel real time fraud detection\nmechanism using Retrieval Augmented Generation technology to address this\nchallenge on two fronts. First our system incorporates a continuously updating\npolicy checking feature that transcribes phone calls in real time and uses RAG\nbased models to verify that the caller is not soliciting private information\nthus ensuring transparency and the authenticity of the conversation. Second we\nimplement a real time user impersonation check with a two step verification\nprocess to confirm the callers identity ensuring accountability. A key\ninnovation of our system is the ability to update policies without retraining\nthe entire model enhancing its adaptability. We validated our RAG based\napproach using synthetic call recordings achieving an accuracy of 97.98 percent\nand an F1score of 97.44 percent with 100 calls outperforming state of the art\nmethods. This robust and flexible fraud detection system is well suited for\nreal world deployment.",
    "categories": [
      "cs.CR",
      "cs.AI"
    ],
    "primary_category": "cs.CR",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2501.15290v1",
    "published_date": "2025-01-25 17:58:05 UTC",
    "updated_date": "2025-01-25 17:58:05 UTC"
  },
  {
    "arxiv_id": "2501.15281v1",
    "title": "Pre-training a Transformer-Based Generative Model Using a Small Sepedi Dataset",
    "authors": [
      "Simon P. Ramalepe",
      "Thipe I. Modipa",
      "Marelie H. Davel"
    ],
    "abstract": "Due to the scarcity of data in low-resourced languages, the development of\nlanguage models for these languages has been very slow. Currently, pre-trained\nlanguage models have gained popularity in natural language processing,\nespecially, in developing domain-specific models for low-resourced languages.\nIn this study, we experiment with the impact of using occlusion-based\ntechniques when training a language model for a text generation task. We curate\n2 new datasets, the Sepedi monolingual (SepMono) dataset from several South\nAfrican resources and the Sepedi radio news (SepNews) dataset from the radio\nnews domain. We use the SepMono dataset to pre-train transformer-based models\nusing the occlusion and non-occlusion pre-training techniques and compare\nperformance. The SepNews dataset is specifically used for fine-tuning. Our\nresults show that the non-occlusion models perform better compared to the\nocclusion-based models when measuring validation loss and perplexity. However,\nanalysis of the generated text using the BLEU score metric, which measures the\nquality of the generated text, shows a slightly higher BLEU score for the\nocclusion-based models compared to the non-occlusion models.",
    "categories": [
      "cs.CL",
      "cs.AI",
      "cs.LG"
    ],
    "primary_category": "cs.CL",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2501.15281v1",
    "published_date": "2025-01-25 17:25:06 UTC",
    "updated_date": "2025-01-25 17:25:06 UTC"
  },
  {
    "arxiv_id": "2501.15280v1",
    "title": "Who's Driving? Game Theoretic Path Risk of AGI Development",
    "authors": [
      "Robin Young"
    ],
    "abstract": "Who controls the development of Artificial General Intelligence (AGI) might\nmatter less than how we handle the fight for control itself. We formalize this\n\"steering wheel problem\" as humanity's greatest near-term existential risk may\nstem not from misaligned AGI, but from the dynamics of competing to develop it.\nJust as a car crash can occur from passengers fighting over the wheel before\nreaching any destination, catastrophic outcomes could arise from development\ncompetition long before AGI exists. While technical alignment research focuses\non ensuring safe arrival, we show how coordination failures during development\ncould drive us off the cliff first.\n  We present a game theoretic framework modeling AGI development dynamics and\nprove conditions for sustainable cooperative equilibria. Drawing from nuclear\ncontrol while accounting for AGI's unique characteristics, we propose concrete\nmechanisms including pre-registration, shared technical infrastructure, and\nautomated deterrence to stabilize cooperation. Our key insight is that AGI\ncreates network effects in safety: shared investments become more valuable as\nparticipation grows, enabling mechanism designs where cooperation dominates\ndefection. This work bridges formal methodology and policy frameworks,\nproviding foundations for practical governance of AGI competition risks.",
    "categories": [
      "cs.AI",
      "cs.CY",
      "cs.GT"
    ],
    "primary_category": "cs.AI",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2501.15280v1",
    "published_date": "2025-01-25 17:13:12 UTC",
    "updated_date": "2025-01-25 17:13:12 UTC"
  },
  {
    "arxiv_id": "2501.15276v1",
    "title": "Exploring the Collaborative Co-Creation Process with AI: A Case Study in Novice Music Production",
    "authors": [
      "Yue Fu",
      "Michele Newman",
      "Lewis Going",
      "Qiuzi Feng",
      "Jin Ha Lee"
    ],
    "abstract": "Artificial intelligence is reshaping creative domains, yet its co-creative\nprocesses, especially in group settings with novice users, remain under\nexplored. To bridge this gap, we conducted a case study in a college-level\ncourse where nine undergraduate students were tasked with creating three\noriginal music tracks using AI tools over 10 weeks. The study spanned the\nentire creative journey from ideation to releasing these songs on Spotify.\nParticipants leveraged AI for music and lyric production, cover art, and\ndistribution. Our findings highlight how AI transforms creative workflows:\naccelerating ideation but compressing the traditional preparation stage, and\nrequiring novices to navigate a challenging idea selection and validation\nphase. We also identified a new \"collaging and refinement\" stage, where\nparticipants creatively combined diverse AI-generated outputs into cohesive\nworks. Furthermore, AI influenced group social dynamics and role division among\nhuman creators. Based on these insights, we propose the Human-AI Co-Creation\nStage Model and the Human-AI Agency Model, offering new perspectives on\ncollaborative co-creation with AI.",
    "categories": [
      "cs.HC",
      "cs.AI"
    ],
    "primary_category": "cs.HC",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2501.15276v1",
    "published_date": "2025-01-25 17:00:17 UTC",
    "updated_date": "2025-01-25 17:00:17 UTC"
  },
  {
    "arxiv_id": "2501.15270v1",
    "title": "Inductive Biases for Zero-shot Systematic Generalization in Language-informed Reinforcement Learning",
    "authors": [
      "Negin Hashemi Dijujin",
      "Seyed Roozbeh Razavi Rohani",
      "Mohammad Mahdi Samiei",
      "Mahdieh Soleymani Baghshah"
    ],
    "abstract": "Sample efficiency and systematic generalization are two long-standing\nchallenges in reinforcement learning. Previous studies have shown that\ninvolving natural language along with other observation modalities can improve\ngeneralization and sample efficiency due to its compositional and open-ended\nnature. However, to transfer these properties of language to the\ndecision-making process, it is necessary to establish a proper language\ngrounding mechanism. One approach to this problem is applying inductive biases\nto extract fine-grained and informative representations from the observations,\nwhich makes them more connectable to the language units. We provide\narchitecture-level inductive biases for modularity and sparsity mainly based on\nNeural Production Systems (NPS). Alongside NPS, we assign a central role to\nmemory in our architecture. It can be seen as a high-level information\naggregator which feeds policy/value heads with comprehensive information and\nsimultaneously guides selective attention in NPS through attentional feedback.\nOur results in the BabyAI environment suggest that the proposed model's\nsystematic generalization and sample efficiency are improved significantly\ncompared to previous models. An extensive ablation study on variants of the\nproposed method is conducted, and the effectiveness of each employed technique\non generalization, sample efficiency, and training stability is specified.",
    "categories": [
      "cs.LG",
      "cs.AI",
      "cs.CL"
    ],
    "primary_category": "cs.LG",
    "comment": "Under review at Machine Learning (Springer Nature)",
    "pdf_url": "http://arxiv.org/pdf/2501.15270v1",
    "published_date": "2025-01-25 16:36:59 UTC",
    "updated_date": "2025-01-25 16:36:59 UTC"
  },
  {
    "arxiv_id": "2501.15255v1",
    "title": "Lightweight and Post-Training Structured Pruning for On-Device Large Lanaguage Models",
    "authors": [
      "Zihuai Xu",
      "Yang Xu",
      "Hongli Xu",
      "Yunming Liao",
      "Zhiwei Yao",
      "Zuan Xie"
    ],
    "abstract": "Considering the hardware-friendly characteristics and broad applicability,\nstructured pruning has emerged as an efficient solution to reduce the resource\ndemands of large language models (LLMs) on resource-constrained devices.\nTraditional structured pruning methods often need fine-tuning to recover\nperformance loss, which incurs high memory overhead and substantial data\nrequirements, rendering them unsuitable for on-device applications.\nAdditionally, post-training structured pruning techniques typically necessitate\nspecific activation functions or architectural modifications, thereby limiting\ntheir scope of applications. Herein, we introduce COMP, a lightweight\npost-training structured pruning method that employs a hybrid-granularity\npruning strategy. COMP initially prunes selected model layers based on their\nimportance at a coarse granularity, followed by fine-grained neuron pruning\nwithin the dense layers of each remaining model layer. To more accurately\nevaluate neuron importance, COMP introduces a new matrix condition-based\nmetric. Subsequently, COMP utilizes mask tuning to recover accuracy without the\nneed for fine-tuning, significantly reducing memory consumption. Experimental\nresults demonstrate that COMP improves performance by 6.13\\% on the LLaMA-2-7B\nmodel with a 20\\% pruning ratio compared to LLM-Pruner, while simultaneously\nreducing memory overhead by 80\\%.",
    "categories": [
      "cs.LG",
      "cs.AI"
    ],
    "primary_category": "cs.LG",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2501.15255v1",
    "published_date": "2025-01-25 16:03:58 UTC",
    "updated_date": "2025-01-25 16:03:58 UTC"
  },
  {
    "arxiv_id": "2501.15249v2",
    "title": "An Automatic Sound and Complete Abstraction Method for Generalized Planning with Baggable Types",
    "authors": [
      "Hao Dong",
      "Zheyuan Shi",
      "Hemeng Zeng",
      "Yongmei Liu"
    ],
    "abstract": "Generalized planning is concerned with how to find a single plan to solve\nmultiple similar planning instances. Abstractions are widely used for solving\ngeneralized planning, and QNP (qualitative numeric planning) is a popular\nabstract model. Recently, Cui et al. showed that a plan solves a sound and\ncomplete abstraction of a generalized planning problem if and only if the\nrefined plan solves the original problem. However, existing work on automatic\nabstraction for generalized planning can hardly guarantee soundness let alone\ncompleteness. In this paper, we propose an automatic sound and complete\nabstraction method for generalized planning with baggable types. We use a\nvariant of QNP, called bounded QNP (BQNP), where integer variables are\nincreased or decreased by only one. Since BQNP is undecidable, we propose and\nimplement a sound but incomplete solver for BQNP. We present an automatic\nmethod to abstract a BQNP problem from a classical planning instance with\nbaggable types. The basic idea for abstraction is to introduce a counter for\neach bag of indistinguishable tuples of objects. We define a class of domains\ncalled proper baggable domains, and show that for such domains, the BQNP\nproblem got by our automatic method is a sound and complete abstraction for a\ngeneralized planning problem whose instances share the same bags with the given\ninstance but the sizes of the bags might be different. Thus, the refined plan\nof a solution to the BQNP problem is a solution to the generalized planning\nproblem. Finally, we implement our abstraction method and experiments on a\nnumber of domains demonstrate the promise of our approach.",
    "categories": [
      "cs.AI"
    ],
    "primary_category": "cs.AI",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2501.15249v2",
    "published_date": "2025-01-25 15:44:25 UTC",
    "updated_date": "2025-01-30 04:07:01 UTC"
  },
  {
    "arxiv_id": "2501.15247v1",
    "title": "Prompting ChatGPT for Chinese Learning as L2: A CEFR and EBCL Level Study",
    "authors": [
      "Miao Lin-Zucker",
      "Joël Bellassen",
      "Jean-Daniel Zucker"
    ],
    "abstract": "The use of chatbots in language learning has evolved significantly since the\n1960s, becoming more sophisticated platforms as generative AI emerged. These\ntools now simulate natural conversations, adapting to individual learners'\nneeds, including those studying Chinese. Our study explores how learners can\nuse specific prompts to engage Large Language Models (LLM) as personalized\nchatbots, aiming to target their language level based on the Common European\nFramework of Reference for Languages (CEFR) and the European Benchmarking\nChinese Language (EBCL) project. Focusing on A1, A1+ and A2 levels, we examine\nthe teaching of Chinese, which presents unique challenges due to its\nlogographic writing system. Our goal is to develop prompts that integrate oral\nand written skills, using high-frequency character lists and controlling oral\nlexical productions. These tools, powered by generative AI, aim to enhance\nlanguage practice by crossing lexical and sinographic recurrence. While\ngenerative AI shows potential as a personalized tutor, further evaluation is\nneeded to assess its effectiveness. We conducted a systematic series of\nexperiments using ChatGPT models to evaluate their adherence to constraints\nspecified in the prompts. The results indicate that incorporating level A1 and\nA1+ characters, along with the associated reference list, significantly\nenhances compliance with the EBCL character set. Properly prompted, LLMs can\nincrease exposure to the target language and offer interactive exchanges to\ndevelop language skills.",
    "categories": [
      "cs.CL",
      "cs.AI"
    ],
    "primary_category": "cs.CL",
    "comment": "35 pages, 1 figure, 5 tables, 7 appendices",
    "pdf_url": "http://arxiv.org/pdf/2501.15247v1",
    "published_date": "2025-01-25 15:30:13 UTC",
    "updated_date": "2025-01-25 15:30:13 UTC"
  },
  {
    "arxiv_id": "2501.15240v1",
    "title": "Hardware-Aware DNN Compression for Homogeneous Edge Devices",
    "authors": [
      "Kunlong Zhang",
      "Guiying Li",
      "Ning Lu",
      "Peng Yang",
      "Ke Tang"
    ],
    "abstract": "Deploying deep neural networks (DNNs) across homogeneous edge devices (the\ndevices with the same SKU labeled by the manufacturer) often assumes identical\nperformance among them. However, once a device model is widely deployed, the\nperformance of each device becomes different after a period of running. This is\ncaused by the differences in user configurations, environmental conditions,\nmanufacturing variances, battery degradation, etc. Existing DNN compression\nmethods have not taken this scenario into consideration and can not guarantee\ngood compression results in all homogeneous edge devices. To address this, we\npropose Homogeneous-Device Aware Pruning (HDAP), a hardware-aware DNN\ncompression framework explicitly designed for homogeneous edge devices, aiming\nto achieve optimal average performance of the compressed model across all\ndevices. To deal with the difficulty of time-consuming hardware-aware\nevaluations for thousands or millions of homogeneous edge devices, HDAP\npartitions all the devices into several device clusters, which can dramatically\nreduce the number of devices to evaluate and use the surrogate-based evaluation\ninstead of hardware evaluation in real-time. Experiments on ResNet50 and\nMobileNetV1 with the ImageNet dataset show that HDAP consistently achieves\nlower average inference latency compared with state-of-the-art methods, with\nsubstantial speedup gains (e.g., 2.86 $\\times$ speedup at 1.0G FLOPs for\nResNet50) on the homogeneous device clusters. HDAP offers an effective solution\nfor scalable, high-performance DNN deployment methods for homogeneous edge\ndevices.",
    "categories": [
      "cs.LG",
      "cs.AI"
    ],
    "primary_category": "cs.LG",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2501.15240v1",
    "published_date": "2025-01-25 15:14:18 UTC",
    "updated_date": "2025-01-25 15:14:18 UTC"
  },
  {
    "arxiv_id": "2501.15225v1",
    "title": "SEAL: Scaling to Emphasize Attention for Long-Context Retrieval",
    "authors": [
      "Changhun Lee",
      "Jun-gyu Jin",
      "Younghyun Cho",
      "Eunhyeok Park"
    ],
    "abstract": "In this work, we introduce a novel approach called Scaling to Emphasize\nAttention for Long-context retrieval (SEAL), which enhances the retrieval\nperformance of large language models (LLMs) over extended contexts. Previous\nstudies have shown that each attention head in LLMs has a unique functionality\nand collectively contributes to the overall behavior of the model. Similarly,\nwe observe that specific heads are closely tied to long-context retrieval,\nshowing positive or negative correlation with retrieval scores. Built on this\ninsight, we propose a learning-based mechanism using zero-shot generated data\nto emphasize these heads, improving the model's performance in long-context\nretrieval tasks. By applying SEAL, we can achieve significant improvements in\nin-domain retrieval performance, including document QA tasks from LongBench,\nand considerable improvements in out-of-domain cases. Additionally, when\ncombined with existing training-free context extension techniques, SEAL extends\nthe context limits of LLMs while maintaining highly reliable outputs, opening\nnew avenues for research in this field.",
    "categories": [
      "cs.CL",
      "cs.AI",
      "cs.LG"
    ],
    "primary_category": "cs.CL",
    "comment": "15 pages",
    "pdf_url": "http://arxiv.org/pdf/2501.15225v1",
    "published_date": "2025-01-25 14:09:39 UTC",
    "updated_date": "2025-01-25 14:09:39 UTC"
  },
  {
    "arxiv_id": "2501.15223v1",
    "title": "Efficient and Interpretable Neural Networks Using Complex Lehmer Transform",
    "authors": [
      "Masoud Ataei",
      "Xiaogang Wang"
    ],
    "abstract": "We propose an efficient and interpretable neural network with a novel\nactivation function called the weighted Lehmer transform. This new activation\nfunction enables adaptive feature selection and extends to the complex domain,\ncapturing phase-sensitive and hierarchical relationships within data. Notably,\nit provides greater interpretability and transparency compared to existing\nmachine learning models, facilitating a deeper understanding of its\nfunctionality and decision-making processes. We analyze the mathematical\nproperties of both real-valued and complex-valued Lehmer activation units and\ndemonstrate their applications in modeling nonlinear interactions. Empirical\nevaluations demonstrate that our proposed neural network achieves competitive\naccuracy on benchmark datasets with significantly improved computational\nefficiency. A single layer of real-valued or complex-valued Lehmer activation\nunits is shown to deliver state-of-the-art performance, balancing efficiency\nwith interpretability.",
    "categories": [
      "cs.LG",
      "cs.AI"
    ],
    "primary_category": "cs.LG",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2501.15223v1",
    "published_date": "2025-01-25 14:08:30 UTC",
    "updated_date": "2025-01-25 14:08:30 UTC"
  },
  {
    "arxiv_id": "2501.15198v1",
    "title": "Towards Conscious Service Robots",
    "authors": [
      "Sven Behnke"
    ],
    "abstract": "Deep learning's success in perception, natural language processing, etc.\ninspires hopes for advancements in autonomous robotics. However, real-world\nrobotics face challenges like variability, high-dimensional state spaces,\nnon-linear dependencies, and partial observability. A key issue is\nnon-stationarity of robots, environments, and tasks, leading to performance\ndrops with out-of-distribution data. Unlike current machine learning models,\nhumans adapt quickly to changes and new tasks due to a cognitive architecture\nthat enables systematic generalization and meta-cognition. Human brain's System\n1 handles routine tasks unconsciously, while System 2 manages complex tasks\nconsciously, facilitating flexible problem-solving and self-monitoring. For\nrobots to achieve human-like learning and reasoning, they need to integrate\ncausal models, working memory, planning, and metacognitive processing. By\nincorporating human cognition insights, the next generation of service robots\nwill handle novel situations and monitor themselves to avoid risks and mitigate\nerrors.",
    "categories": [
      "cs.RO",
      "cs.AI"
    ],
    "primary_category": "cs.RO",
    "comment": "In: Science for a Better Tomorrow: Curious 2024 Insights Actions,\n  Springer 2025",
    "pdf_url": "http://arxiv.org/pdf/2501.15198v1",
    "published_date": "2025-01-25 12:32:52 UTC",
    "updated_date": "2025-01-25 12:32:52 UTC"
  },
  {
    "arxiv_id": "2501.17183v2",
    "title": "LLM Evaluation Based on Aerospace Manufacturing Expertise: Automated Generation and Multi-Model Question Answering",
    "authors": [
      "Beiming Liu",
      "Zhizhuo Cui",
      "Siteng Hu",
      "Xiaohua Li",
      "Haifeng Lin",
      "Zhengxin Zhang"
    ],
    "abstract": "Aerospace manufacturing demands exceptionally high precision in technical\nparameters. The remarkable performance of Large Language Models (LLMs), such as\nGPT-4 and QWen, in Natural Language Processing has sparked industry interest in\ntheir application to tasks including process design, material selection, and\ntool information retrieval. However, LLMs are prone to generating\n\"hallucinations\" in specialized domains, producing inaccurate or false\ninformation that poses significant risks to the quality of aerospace products\nand flight safety. This paper introduces a set of evaluation metrics tailored\nfor LLMs in aerospace manufacturing, aiming to assess their accuracy by\nanalyzing their performance in answering questions grounded in professional\nknowledge. Firstly, key information is extracted through in-depth textual\nanalysis of classic aerospace manufacturing textbooks and guidelines.\nSubsequently, utilizing LLM generation techniques, we meticulously construct\nmultiple-choice questions with multiple correct answers of varying difficulty.\nFollowing this, different LLM models are employed to answer these questions,\nand their accuracy is recorded. Experimental results demonstrate that the\ncapabilities of LLMs in aerospace professional knowledge are in urgent need of\nimprovement. This study provides a theoretical foundation and practical\nguidance for the application of LLMs in aerospace manufacturing, addressing a\ncritical gap in the field.",
    "categories": [
      "cs.CL",
      "cs.AI",
      "68T50, 90B30",
      "I.2.7; J.2"
    ],
    "primary_category": "cs.CL",
    "comment": "conference paper",
    "pdf_url": "http://arxiv.org/pdf/2501.17183v2",
    "published_date": "2025-01-25 12:26:44 UTC",
    "updated_date": "2025-02-01 10:18:11 UTC"
  },
  {
    "arxiv_id": "2501.17182v2",
    "title": "Dialogue Systems for Emotional Support via Value Reinforcement",
    "authors": [
      "Juhee Kim",
      "Chunghu Mok",
      "Jisun Lee",
      "Hyang Sook Kim",
      "Yohan Jo"
    ],
    "abstract": "Emotional support dialogue systems aim to reduce help-seekers' distress and\nhelp them overcome challenges. While human values$\\unicode{x2013}$core beliefs\nthat shape an individual's priorities$\\unicode{x2013}$are increasingly\nemphasized in contemporary psychological therapy for their role in fostering\ninternal transformation and long-term emotional well-being, their integration\ninto emotional support systems remains underexplored. To bridge this gap, we\npresent a value-driven method for training emotional support dialogue systems\ndesigned to reinforce positive values in seekers. Notably, our model identifies\nwhich values to reinforce at each turn and how to do so, by leveraging online\nsupport conversations from Reddit. We evaluate the method across support\nskills, seekers' emotional intensity, and value reinforcement. Our method\nconsistently outperforms various baselines, effectively exploring and eliciting\nvalues from seekers. Additionally, leveraging crowd knowledge from Reddit\nsignificantly enhances its effectiveness. Therapists highlighted its ability to\nvalidate seekers' challenges and emphasize positive aspects of their\nsituations$\\unicode{x2013}$both crucial elements of value reinforcement. Our\nwork, being the first to integrate value reinforcement into emotional support\nsystems, demonstrates its promise and establishes a foundation for future\nresearch.",
    "categories": [
      "cs.CL",
      "cs.AI",
      "cs.CY",
      "cs.HC",
      "I.2.7"
    ],
    "primary_category": "cs.CL",
    "comment": "34 pages, 4 figures",
    "pdf_url": "http://arxiv.org/pdf/2501.17182v2",
    "published_date": "2025-01-25 11:51:31 UTC",
    "updated_date": "2025-03-09 07:37:22 UTC"
  },
  {
    "arxiv_id": "2501.15175v3",
    "title": "Option-ID Based Elimination For Multiple Choice Questions",
    "authors": [
      "Zhenhao Zhu",
      "Bulou Liu",
      "Qingyao Ai",
      "Yiqun Liu"
    ],
    "abstract": "Multiple choice questions (MCQs) are a popular and important task for\nevaluating large language models (LLMs). Based on common strategies people use\nwhen answering MCQs, the process of elimination (PoE) has been proposed as an\neffective problem-solving method. Existing PoE methods typically either have\nLLMs directly identify incorrect options or score options and replace\nlower-scoring ones with [MASK]. However, both methods suffer from\ninapplicability or suboptimal performance. To address these issues, this paper\nproposes a novel option-ID based PoE ($\\text{PoE}_{\\text{ID}}$).\n$\\text{PoE}_{\\text{ID}}$ critically incorporates a debiasing technique to\ncounteract LLMs token bias, enhancing robustness over naive ID-based\nelimination. It features two strategies: $\\text{PoE}_{\\text{ID}}^{\\text{log}}$,\nwhich eliminates options whose IDs have log probabilities below the average\nthreshold, and $\\text{PoE}_{\\text{ID}}^{\\text{seq}}$, which iteratively removes\nthe option with the lowest ID probability. We conduct extensive experiments\nwith 6 different LLMs on 4 diverse datasets. The results demonstrate that\n$\\text{PoE}_{\\text{ID}}$, especially $\\text{PoE}_{\\text{ID}}^{\\text{log}}$,\nsignificantly improves zero-shot and few-shot MCQs performance, particularly in\ndatasets with more options. Our analyses demonstrate that\n$\\text{PoE}_{\\text{ID}}^{\\text{log}}$ enhances the LLMs' confidence in\nselecting the correct option, and the option elimination strategy outperforms\nmethods relying on [MASK] replacement. We further investigate the limitations\nof LLMs in directly identifying incorrect options, which stem from their\ninherent deficiencies.",
    "categories": [
      "cs.CL",
      "cs.AI",
      "cs.LG"
    ],
    "primary_category": "cs.CL",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2501.15175v3",
    "published_date": "2025-01-25 11:06:37 UTC",
    "updated_date": "2025-05-19 17:58:53 UTC"
  },
  {
    "arxiv_id": "2501.15149v1",
    "title": "Mapping Galaxy Images Across Ultraviolet, Visible and Infrared Bands Using Generative Deep Learning",
    "authors": [
      "Youssef Zaazou",
      "Alex Bihlo",
      "Terrence S. Tricco"
    ],
    "abstract": "We demonstrate that generative deep learning can translate galaxy\nobservations across ultraviolet, visible, and infrared photometric bands.\nLeveraging mock observations from the Illustris simulations, we develop and\nvalidate a supervised image-to-image model capable of performing both band\ninterpolation and extrapolation. The resulting trained models exhibit high\nfidelity in generating outputs, as verified by both general image comparison\nmetrics (MAE, SSIM, PSNR) and specialized astronomical metrics (GINI\ncoefficient, M20). Moreover, we show that our model can be used to predict\nreal-world observations, using data from the DECaLS survey as a case study.\nThese findings highlight the potential of generative learning to augment\nastronomical datasets, enabling efficient exploration of multi-band information\nin regions where observations are incomplete. This work opens new pathways for\noptimizing mission planning, guiding high-resolution follow-ups, and enhancing\nour understanding of galaxy morphology and evolution.",
    "categories": [
      "astro-ph.IM",
      "astro-ph.GA",
      "cs.AI"
    ],
    "primary_category": "astro-ph.IM",
    "comment": "15 pages, 6 figures, Submitted to ApJ, GitHub:\n  https://github.com/yazaazou/Galaxy-Band-Conversion",
    "pdf_url": "http://arxiv.org/pdf/2501.15149v1",
    "published_date": "2025-01-25 09:13:21 UTC",
    "updated_date": "2025-01-25 09:13:21 UTC"
  },
  {
    "arxiv_id": "2501.15147v2",
    "title": "A Causality-aware Paradigm for Evaluating Creativity of Multimodal Large Language Models",
    "authors": [
      "Zhongzhan Huang",
      "Shanshan Zhong",
      "Pan Zhou",
      "Shanghua Gao",
      "Marinka Zitnik",
      "Liang Lin"
    ],
    "abstract": "Recently, numerous benchmarks have been developed to evaluate the logical\nreasoning abilities of large language models (LLMs). However, assessing the\nequally important creative capabilities of LLMs is challenging due to the\nsubjective, diverse, and data-scarce nature of creativity, especially in\nmultimodal scenarios. In this paper, we consider the comprehensive pipeline for\nevaluating the creativity of multimodal LLMs, with a focus on suitable\nevaluation platforms and methodologies. First, we find the Oogiri game, a\ncreativity-driven task requiring humor, associative thinking, and the ability\nto produce unexpected responses to text, images, or both. This game aligns well\nwith the input-output structure of modern multimodal LLMs and benefits from a\nrich repository of high-quality, human-annotated creative responses, making it\nan ideal platform for studying LLM creativity. Next, beyond using the Oogiri\ngame for standard evaluations like ranking and selection, we propose LoTbench,\nan interactive, causality-aware evaluation framework, to further address some\nintrinsic risks in standard evaluations, such as information leakage and\nlimited interpretability. The proposed LoTbench not only quantifies LLM\ncreativity more effectively but also visualizes the underlying creative thought\nprocesses. Our results show that while most LLMs exhibit constrained\ncreativity, the performance gap between LLMs and humans is not insurmountable.\nFurthermore, we observe a strong correlation between results from the\nmultimodal cognition benchmark MMMU and LoTbench, but only a weak connection\nwith traditional creativity metrics. This suggests that LoTbench better aligns\nwith human cognitive theories, highlighting cognition as a critical foundation\nin the early stages of creativity and enabling the bridging of diverse\nconcepts. https://lotbench.github.io",
    "categories": [
      "cs.AI",
      "cs.HC"
    ],
    "primary_category": "cs.AI",
    "comment": "Accepted by TPAMI. arXiv admin note: text overlap with\n  arXiv:2312.02439",
    "pdf_url": "http://arxiv.org/pdf/2501.15147v2",
    "published_date": "2025-01-25 09:11:15 UTC",
    "updated_date": "2025-02-23 08:09:48 UTC"
  },
  {
    "arxiv_id": "2501.15142v1",
    "title": "DAGPrompT: Pushing the Limits of Graph Prompting with a Distribution-aware Graph Prompt Tuning Approach",
    "authors": [
      "Qin Chen",
      "Liang Wang",
      "Bo Zheng",
      "Guojie Song"
    ],
    "abstract": "The pre-train then fine-tune approach has advanced GNNs by enabling general\nknowledge capture without task-specific labels. However, an objective gap\nbetween pre-training and downstream tasks limits its effectiveness. Recent\ngraph prompting methods aim to close this gap through task reformulations and\nlearnable prompts. Despite this, they struggle with complex graphs like\nheterophily graphs. Freezing the GNN encoder can reduce the impact of\nprompting, while simple prompts fail to handle diverse hop-level distributions.\nThis paper identifies two key challenges in adapting graph prompting methods\nfor complex graphs: (1) adapting the model to new distributions in downstream\ntasks to mitigate pre-training and fine-tuning discrepancies from heterophily\nand (2) customizing prompts for hop-specific node requirements. To overcome\nthese challenges, we propose Distribution-aware Graph Prompt Tuning\n(DAGPrompT), which integrates a GLoRA module for optimizing the GNN encoder's\nprojection matrix and message-passing schema through low-rank adaptation.\nDAGPrompT also incorporates hop-specific prompts accounting for varying graph\nstructures and distributions among hops. Evaluations on 10 datasets and 14\nbaselines demonstrate that DAGPrompT improves accuracy by up to 4.79 in node\nand graph classification tasks, setting a new state-of-the-art while preserving\nefficiency. Codes are available at GitHub.",
    "categories": [
      "cs.LG",
      "cs.AI"
    ],
    "primary_category": "cs.LG",
    "comment": "To be published in WWW '25, April 28-May 2, 2025, Sydney, NSW,\n  Australia",
    "pdf_url": "http://arxiv.org/pdf/2501.15142v1",
    "published_date": "2025-01-25 08:53:42 UTC",
    "updated_date": "2025-01-25 08:53:42 UTC"
  },
  {
    "arxiv_id": "2501.15140v3",
    "title": "Analyzing and Boosting the Power of Fine-Grained Visual Recognition for Multi-modal Large Language Models",
    "authors": [
      "Hulingxiao He",
      "Geng Li",
      "Zijun Geng",
      "Jinglin Xu",
      "Yuxin Peng"
    ],
    "abstract": "Multi-modal large language models (MLLMs) have shown remarkable abilities in\nvarious visual understanding tasks. However, MLLMs still struggle with\nfine-grained visual recognition (FGVR), which aims to identify\nsubordinate-level categories from images. This can negatively impact more\nadvanced capabilities of MLLMs, such as object-centric visual question\nanswering and reasoning. In our study, we revisit three quintessential\ncapabilities of MLLMs for FGVR, including object information extraction,\ncategory knowledge reserve, object-category alignment, and position of the root\ncause as a misalignment problem. To address this issue, we present Finedefics,\nan MLLM that enhances the model's FGVR capability by incorporating informative\nattribute descriptions of objects into the training phase. We employ\ncontrastive learning on object-attribute pairs and attribute-category pairs\nsimultaneously and use examples from similar but incorrect categories as hard\nnegatives, naturally bringing representations of visual objects and category\nnames closer. Extensive evaluations across multiple popular FGVR datasets\ndemonstrate that Finedefics outperforms existing MLLMs of comparable parameter\nsizes, showcasing its remarkable efficacy. The code is available at\nhttps://github.com/PKU-ICST-MIPL/Finedefics_ICLR2025.",
    "categories": [
      "cs.CV",
      "cs.AI",
      "cs.CL",
      "cs.LG"
    ],
    "primary_category": "cs.CV",
    "comment": "Published as a conference paper at ICLR 2025. The model is available\n  at https://huggingface.co/StevenHH2000/Finedefics",
    "pdf_url": "http://arxiv.org/pdf/2501.15140v3",
    "published_date": "2025-01-25 08:52:43 UTC",
    "updated_date": "2025-03-30 13:12:34 UTC"
  },
  {
    "arxiv_id": "2501.15122v1",
    "title": "Snapshot Compressed Imaging Based Single-Measurement Computer Vision for Videos",
    "authors": [
      "Fengpu Pan",
      "Jiangtao Wen",
      "Yuxing Han"
    ],
    "abstract": "Snapshot compressive imaging (SCI) is a promising technique for capturing\nhigh-speed video at low bandwidth and low power, typically by compressing\nmultiple frames into a single measurement. However, similar to traditional CMOS\nimage sensor based imaging systems, SCI also faces challenges in low-lighting\nphoton-limited and low-signal-to-noise-ratio image conditions. In this paper,\nwe propose a novel Compressive Denoising Autoencoder (CompDAE) using the\nSTFormer architecture as the backbone, to explicitly model noise\ncharacteristics and provide computer vision functionalities such as edge\ndetection and depth estimation directly from compressed sensing measurements,\nwhile accounting for realistic low-photon conditions. We evaluate the\neffectiveness of CompDAE across various datasets and demonstrated significant\nimprovements in task performance compared to conventional RGB-based methods. In\nthe case of ultra-low-lighting (APC $\\leq$ 20) while conventional methods\nfailed, the proposed algorithm can still maintain competitive performance.",
    "categories": [
      "cs.CV",
      "cs.AI"
    ],
    "primary_category": "cs.CV",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2501.15122v1",
    "published_date": "2025-01-25 08:20:30 UTC",
    "updated_date": "2025-01-25 08:20:30 UTC"
  },
  {
    "arxiv_id": "2501.15109v1",
    "title": "Clear Preferences Leave Traces: Reference Model-Guided Sampling for Preference Learning",
    "authors": [
      "Nirav Diwan",
      "Tolga Ergen",
      "Dongsub Shim",
      "Honglak Lee"
    ],
    "abstract": "Direct Preference Optimization (DPO) has emerged as a de-facto approach for\naligning language models with human preferences. Recent work has shown DPO's\neffectiveness relies on training data quality. In particular, clear quality\ndifferences between preferred and rejected responses enhance learning\nperformance. Current methods for identifying and obtaining such high-quality\nsamples demand additional resources or external models. We discover that\nreference model probability space naturally detects high-quality training\nsamples. Using this insight, we present a sampling strategy that achieves\nconsistent improvements (+0.1 to +0.4) on MT-Bench while using less than half\n(30-50%) of the training data. We observe substantial improvements (+0.4 to\n+0.98) for technical tasks (coding, math, and reasoning) across multiple models\nand hyperparameter settings.",
    "categories": [
      "cs.LG",
      "cs.AI"
    ],
    "primary_category": "cs.LG",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2501.15109v1",
    "published_date": "2025-01-25 07:21:50 UTC",
    "updated_date": "2025-01-25 07:21:50 UTC"
  },
  {
    "arxiv_id": "2501.15105v1",
    "title": "A New Approach for Knowledge Generation Using Active Inference",
    "authors": [
      "Jamshid Ghasimi",
      "Nazanin Movarraei"
    ],
    "abstract": "There are various models proposed on how knowledge is generated in the human\nbrain including the semantic networks model. Although this model has been\nwidely studied and even computational models are presented, but, due to various\nlimits and inefficiencies in the generation of different types of knowledge,\nits application is limited to semantic knowledge because of has been formed\naccording to semantic memory and declarative knowledge and has many limits in\nexplaining various procedural and conditional knowledge. Given the importance\nof providing an appropriate model for knowledge generation, especially in the\nareas of improving human cognitive functions or building intelligent machines,\nimproving existing models in knowledge generation or providing more\ncomprehensive models is of great importance. In the current study, based on the\nfree energy principle of the brain, is the researchers proposed a model for\ngenerating three types of declarative, procedural, and conditional knowledge.\nWhile explaining different types of knowledge, this model is capable to compute\nand generate concepts from stimuli based on probabilistic mathematics and the\naction-perception process (active inference). The proposed model is\nunsupervised learning that can update itself using a combination of different\nstimuli as a generative model can generate new concepts of unsupervised\nreceived stimuli. In this model, the active inference process is used in the\ngeneration of procedural and conditional knowledge and the perception process\nis used to generate declarative knowledge.",
    "categories": [
      "cs.AI",
      "q-bio.NC",
      "60A99",
      "G.3"
    ],
    "primary_category": "cs.AI",
    "comment": "19 pages, 8 figures",
    "pdf_url": "http://arxiv.org/pdf/2501.15105v1",
    "published_date": "2025-01-25 07:06:33 UTC",
    "updated_date": "2025-01-25 07:06:33 UTC"
  },
  {
    "arxiv_id": "2501.15103v1",
    "title": "Each Rank Could be an Expert: Single-Ranked Mixture of Experts LoRA for Multi-Task Learning",
    "authors": [
      "Ziyu Zhao",
      "Yixiao Zhou",
      "Didi Zhu",
      "Tao Shen",
      "Xuwu Wang",
      "Jing Su",
      "Kun Kuang",
      "Zhongyu Wei",
      "Fei Wu",
      "Yu Cheng"
    ],
    "abstract": "Low-Rank Adaptation (LoRA) is widely used for adapting large language models\n(LLMs) to specific domains due to its efficiency and modularity. Meanwhile,\nvanilla LoRA struggles with task conflicts in multi-task scenarios. Recent\nworks adopt Mixture of Experts (MoE) by treating each LoRA module as an expert,\nthereby mitigating task interference through multiple specialized LoRA modules.\nWhile effective, these methods often isolate knowledge within individual tasks,\nfailing to fully exploit the shared knowledge across related tasks. In this\npaper, we establish a connection between single LoRA and multi-LoRA MoE,\nintegrating them into a unified framework. We demonstrate that the dynamic\nrouting of multiple LoRAs is functionally equivalent to rank partitioning and\nblock-level activation within a single LoRA. We further empirically demonstrate\nthat finer-grained LoRA partitioning, within the same total and activated\nparameter constraints, leads to better performance gains across heterogeneous\ntasks. Building on these findings, we propose Single-ranked Mixture of Experts\nLoRA (\\textbf{SMoRA}), which embeds MoE into LoRA by \\textit{treating each rank\nas an independent expert}. With a \\textit{dynamic rank-wise activation}\nmechanism, SMoRA promotes finer-grained knowledge sharing while mitigating task\nconflicts. Experiments demonstrate that SMoRA activates fewer parameters yet\nachieves better performance in multi-task scenarios.",
    "categories": [
      "cs.LG",
      "cs.AI"
    ],
    "primary_category": "cs.LG",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2501.15103v1",
    "published_date": "2025-01-25 06:56:39 UTC",
    "updated_date": "2025-01-25 06:56:39 UTC"
  },
  {
    "arxiv_id": "2501.15098v1",
    "title": "CFT-RAG: An Entity Tree Based Retrieval Augmented Generation Algorithm With Cuckoo Filter",
    "authors": [
      "Zihang Li",
      "Yangdong Ruan",
      "Wenjun Liu",
      "Zhengyang Wang",
      "Tong Yang"
    ],
    "abstract": "Although retrieval-augmented generation(RAG) significantly improves\ngeneration quality by retrieving external knowledge bases and integrating\ngenerated content, it faces computational efficiency bottlenecks, particularly\nin knowledge retrieval tasks involving hierarchical structures for Tree-RAG.\nThis paper proposes a Tree-RAG acceleration method based on the improved Cuckoo\nFilter, which optimizes entity localization during the retrieval process to\nachieve significant performance improvements. Tree-RAG effectively organizes\nentities through the introduction of a hierarchical tree structure, while the\nCuckoo Filter serves as an efficient data structure that supports rapid\nmembership queries and dynamic updates. The experiment results demonstrate that\nour method is much faster than naive Tree-RAG while maintaining high levels of\ngenerative quality. When the number of trees is large, our method is hundreds\nof times faster than naive Tree-RAG. Our work is available at\nhttps://github.com/TUPYP7180/CFT-RAG-2025.",
    "categories": [
      "cs.LG",
      "cs.AI"
    ],
    "primary_category": "cs.LG",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2501.15098v1",
    "published_date": "2025-01-25 06:09:02 UTC",
    "updated_date": "2025-01-25 06:09:02 UTC"
  },
  {
    "arxiv_id": "2501.15085v2",
    "title": "Data Center Cooling System Optimization Using Offline Reinforcement Learning",
    "authors": [
      "Xianyuan Zhan",
      "Xiangyu Zhu",
      "Peng Cheng",
      "Xiao Hu",
      "Ziteng He",
      "Hanfei Geng",
      "Jichao Leng",
      "Huiwen Zheng",
      "Chenhui Liu",
      "Tianshun Hong",
      "Yan Liang",
      "Yunxin Liu",
      "Feng Zhao"
    ],
    "abstract": "The recent advances in information technology and artificial intelligence\nhave fueled a rapid expansion of the data center (DC) industry worldwide,\naccompanied by an immense appetite for electricity to power the DCs. In a\ntypical DC, around 30~40% of the energy is spent on the cooling system rather\nthan on computer servers, posing a pressing need for developing new\nenergy-saving optimization technologies for DC cooling systems. However,\noptimizing such real-world industrial systems faces numerous challenges,\nincluding but not limited to a lack of reliable simulation environments,\nlimited historical data, and stringent safety and control robustness\nrequirements. In this work, we present a novel physics-informed offline\nreinforcement learning (RL) framework for energy efficiency optimization of DC\ncooling systems. The proposed framework models the complex dynamical patterns\nand physical dependencies inside a server room using a purposely designed graph\nneural network architecture that is compliant with the fundamental\ntime-reversal symmetry. Because of its well-behaved and generalizable\nstate-action representations, the model enables sample-efficient and robust\nlatent space offline policy learning using limited real-world operational data.\nOur framework has been successfully deployed and verified in a large-scale\nproduction DC for closed-loop control of its air-cooling units (ACUs). We\nconducted a total of 2000 hours of short and long-term experiments in the\nproduction DC environment. The results show that our method achieves 14~21%\nenergy savings in the DC cooling system, without any violation of the safety or\noperational constraints. Our results have demonstrated the significant\npotential of offline RL in solving a broad range of data-limited,\nsafety-critical real-world industrial control problems.",
    "categories": [
      "cs.AI",
      "cs.LG",
      "cs.SY",
      "eess.SY"
    ],
    "primary_category": "cs.AI",
    "comment": "Accepted in ICLR 2025",
    "pdf_url": "http://arxiv.org/pdf/2501.15085v2",
    "published_date": "2025-01-25 05:28:44 UTC",
    "updated_date": "2025-02-14 06:50:36 UTC"
  },
  {
    "arxiv_id": "2501.15084v1",
    "title": "Hierarchical Pattern Decryption Methodology for Ransomware Detection Using Probabilistic Cryptographic Footprints",
    "authors": [
      "Kevin Pekepok",
      "Persephone Kirkwood",
      "Esme Christopolous",
      "Florence Braithwaite",
      "Oliver Nightingale"
    ],
    "abstract": "The increasing sophistication of encryption-based ransomware has demanded\ninnovative approaches to detection and mitigation, prompting the development of\na hierarchical framework grounded in probabilistic cryptographic analysis. By\nfocusing on the statistical characteristics of encryption patterns, the\nproposed methodology introduces a layered approach that combines advanced\nclustering algorithms with machine learning to isolate ransomware-induced\nanomalies. Through comprehensive testing across diverse ransomware families,\nthe framework demonstrated exceptional accuracy, effectively distinguishing\nmalicious encryption operations from benign activities while maintaining low\nfalse positive rates. The system's design integrates dynamic feedback\nmechanisms, enabling adaptability to varying cryptographic complexities and\noperational environments. Detailed entropy-based evaluations revealed its\nsensitivity to subtle deviations in encryption workflows, offering a robust\nalternative to traditional detection methods reliant on static signatures or\nheuristics. Computational benchmarks confirmed its scalability and efficiency,\nachieving consistent performance even under high data loads and complex\ncryptographic scenarios. The inclusion of real-time clustering and anomaly\nevaluation ensures rapid response capabilities, addressing critical latency\nchallenges in ransomware detection. Performance comparisons with established\nmethods highlighted its improvements in detection efficacy, particularly\nagainst advanced ransomware employing extended key lengths and unique\ncryptographic protocols.",
    "categories": [
      "cs.CR",
      "cs.AI"
    ],
    "primary_category": "cs.CR",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2501.15084v1",
    "published_date": "2025-01-25 05:26:17 UTC",
    "updated_date": "2025-01-25 05:26:17 UTC"
  },
  {
    "arxiv_id": "2501.15081v1",
    "title": "Can Large Language Models Be Trusted as Black-Box Evolutionary Optimizers for Combinatorial Problems?",
    "authors": [
      "Jie Zhao",
      "Tao Wen",
      "Kang Hao Cheong"
    ],
    "abstract": "Evolutionary computation excels in complex optimization but demands deep\ndomain knowledge, restricting its accessibility. Large Language Models (LLMs)\noffer a game-changing solution with their extensive knowledge and could\ndemocratize the optimization paradigm. Although LLMs possess significant\ncapabilities, they may not be universally effective, particularly since\nevolutionary optimization encompasses multiple stages. It is therefore\nimperative to evaluate the suitability of LLMs as evolutionary optimizer (EVO).\nThus, we establish a series of rigid standards to thoroughly examine the\nfidelity of LLM-based EVO output in different stages of evolutionary\noptimization and then introduce a robust error-correction mechanism to mitigate\nthe output uncertainty. Furthermore, we explore a cost-efficient method that\ndirectly operates on entire populations with excellent effectiveness in\ncontrast to individual-level optimization. Through extensive experiments, we\nrigorously validate the performance of LLMs as operators targeted for\ncombinatorial problems. Our findings provide critical insights and valuable\nobservations, advancing the understanding and application of LLM-based\noptimization.",
    "categories": [
      "cs.NE",
      "cs.AI"
    ],
    "primary_category": "cs.NE",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2501.15081v1",
    "published_date": "2025-01-25 05:19:19 UTC",
    "updated_date": "2025-01-25 05:19:19 UTC"
  },
  {
    "arxiv_id": "2501.15074v1",
    "title": "PatentLMM: Large Multimodal Model for Generating Descriptions for Patent Figures",
    "authors": [
      "Shreya Shukla",
      "Nakul Sharma",
      "Manish Gupta",
      "Anand Mishra"
    ],
    "abstract": "Writing comprehensive and accurate descriptions of technical drawings in\npatent documents is crucial to effective knowledge sharing and enabling the\nreplication and protection of intellectual property. However, automation of\nthis task has been largely overlooked by the research community. To this end,\nwe introduce PatentDesc-355K, a novel large-scale dataset containing ~355K\npatent figures along with their brief and detailed textual descriptions\nextracted from more than 60K US patent documents. In addition, we propose\nPatentLMM - a novel multimodal large language model specifically tailored to\ngenerate high-quality descriptions of patent figures. Our proposed PatentLMM\ncomprises two key components: (i) PatentMME, a specialized multimodal vision\nencoder that captures the unique structural elements of patent figures, and\n(ii) PatentLLaMA, a domain-adapted version of LLaMA fine-tuned on a large\ncollection of patents. Extensive experiments demonstrate that training a vision\nencoder specifically designed for patent figures significantly boosts the\nperformance, generating coherent descriptions compared to fine-tuning\nsimilar-sized off-the-shelf multimodal models. PatentDesc-355K and PatentLMM\npave the way for automating the understanding of patent figures, enabling\nefficient knowledge sharing and faster drafting of patent documents. We make\nthe code and data publicly available.",
    "categories": [
      "cs.CV",
      "cs.AI"
    ],
    "primary_category": "cs.CV",
    "comment": "Accepted at AAAI 2025 (Main Track). Project page:\n  https://vl2g.github.io/projects/PatentLMM/",
    "pdf_url": "http://arxiv.org/pdf/2501.15074v1",
    "published_date": "2025-01-25 04:45:32 UTC",
    "updated_date": "2025-01-25 04:45:32 UTC"
  },
  {
    "arxiv_id": "2502.15714v1",
    "title": "TrustDataFilter:Leveraging Trusted Knowledge Base Data for More Effective Filtering of Unknown Information",
    "authors": [
      "Jinghong Zhang",
      "Yidong Cui",
      "Weiling Wang",
      "Xianyou Cheng"
    ],
    "abstract": "With the advancement of technology and changes in the market, the demand for\nthe construction of domain-specific knowledge bases has been increasing, either\nto improve model performance or to promote enterprise innovation and\ncompetitiveness. The construction of domain-specific knowledge bases typically\nrelies on web crawlers or existing industry databases, leading to problems with\naccuracy and consistency of the data. To address these challenges, we\nconsidered the characteristics of domain data, where internal knowledge is\ninterconnected, and proposed the Self-Natural Language Inference Data Filtering\n(self-nli-TDF) framework. This framework compares trusted filtered knowledge\nwith the data to be filtered, deducing the reasoning relationship between them,\nthus improving filtering performance. The framework uses plug-and-play large\nlanguage models for trustworthiness assessment and employs the RoBERTa-MNLI\nmodel from the NLI domain for reasoning. We constructed three datasets in the\ndomains of biology, radiation, and science, and conducted experiments using\nRoBERTa, GPT3.5, and the local Qwen2 model. The experimental results show that\nthis framework improves filter quality, producing more consistent and reliable\nfiltering results.",
    "categories": [
      "cs.IR",
      "cs.AI",
      "cs.CL"
    ],
    "primary_category": "cs.IR",
    "comment": "12 pages, 8 figures, submitted to IEEE Transactions on Knowledge and\n  Data Engineering",
    "pdf_url": "http://arxiv.org/pdf/2502.15714v1",
    "published_date": "2025-01-25 04:18:35 UTC",
    "updated_date": "2025-01-25 04:18:35 UTC"
  },
  {
    "arxiv_id": "2501.15065v1",
    "title": "Task Arithmetic in Trust Region: A Training-Free Model Merging Approach to Navigate Knowledge Conflicts",
    "authors": [
      "Wenju Sun",
      "Qingyong Li",
      "Wen Wang",
      "Yangli-ao Geng",
      "Boyang Li"
    ],
    "abstract": "Multi-task model merging offers an efficient solution for integrating\nknowledge from multiple fine-tuned models, mitigating the significant\ncomputational and storage demands associated with multi-task training. As a key\ntechnique in this field, Task Arithmetic (TA) defines task vectors by\nsubtracting the pre-trained model ($\\theta_{\\text{pre}}$) from the fine-tuned\ntask models in parameter space, then adjusting the weight between these task\nvectors and $\\theta_{\\text{pre}}$ to balance task-generalized and task-specific\nknowledge. Despite the promising performance of TA, conflicts can arise among\nthe task vectors, particularly when different tasks require distinct model\nadaptations. In this paper, we formally define this issue as knowledge\nconflicts, characterized by the performance degradation of one task after\nmerging with a model fine-tuned for another task. Through in-depth analysis, we\nshow that these conflicts stem primarily from the components of task vectors\nthat align with the gradient of task-specific losses at $\\theta_{\\text{pre}}$.\nTo address this, we propose Task Arithmetic in Trust Region (TATR), which\ndefines the trust region as dimensions in the model parameter space that cause\nonly small changes (corresponding to the task vector components with gradient\northogonal direction) in the task-specific losses. Restricting parameter\nmerging within this trust region, TATR can effectively alleviate knowledge\nconflicts. Moreover, TATR serves as both an independent approach and a\nplug-and-play module compatible with a wide range of TA-based methods.\nExtensive empirical evaluations on eight distinct datasets robustly demonstrate\nthat TATR improves the multi-task performance of several TA-based model merging\nmethods by an observable margin.",
    "categories": [
      "cs.LG",
      "cs.AI"
    ],
    "primary_category": "cs.LG",
    "comment": "21pages, 6 figures, 6 tables",
    "pdf_url": "http://arxiv.org/pdf/2501.15065v1",
    "published_date": "2025-01-25 04:09:56 UTC",
    "updated_date": "2025-01-25 04:09:56 UTC"
  },
  {
    "arxiv_id": "2501.17181v1",
    "title": "An AI-Driven Live Systematic Reviews in the Brain-Heart Interconnectome: Minimizing Research Waste and Advancing Evidence Synthesis",
    "authors": [
      "Arya Rahgozar",
      "Pouria Mortezaagha",
      "Jodi Edwards",
      "Douglas Manuel",
      "Jessie McGowen",
      "Merrick Zwarenstein",
      "Dean Fergusson",
      "Andrea Tricco",
      "Kelly Cobey",
      "Margaret Sampson",
      "Malcolm King",
      "Dawn Richards",
      "Alexandra Bodnaruc",
      "David Moher"
    ],
    "abstract": "The Brain-Heart Interconnectome (BHI) combines neurology and cardiology but\nis hindered by inefficiencies in evidence synthesis, poor adherence to quality\nstandards, and research waste. To address these challenges, we developed an\nAI-driven system to enhance systematic reviews in the BHI domain. The system\nintegrates automated detection of Population, Intervention, Comparator,\nOutcome, and Study design (PICOS), semantic search using vector embeddings,\ngraph-based querying, and topic modeling to identify redundancies and\nunderexplored areas. Core components include a Bi-LSTM model achieving 87%\naccuracy for PICOS compliance, a study design classifier with 95.7% accuracy,\nand Retrieval-Augmented Generation (RAG) with GPT-3.5, which outperformed GPT-4\nfor graph-based and topic-driven queries. The system provides real-time\nupdates, reducing research waste through a living database and offering an\ninteractive interface with dashboards and conversational AI. While initially\ndeveloped for BHI, the system's adaptable architecture enables its application\nacross various biomedical fields, supporting rigorous evidence synthesis,\nefficient resource allocation, and informed clinical decision-making.",
    "categories": [
      "cs.AI",
      "cs.CL",
      "cs.DL",
      "cs.IR"
    ],
    "primary_category": "cs.AI",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2501.17181v1",
    "published_date": "2025-01-25 03:51:07 UTC",
    "updated_date": "2025-01-25 03:51:07 UTC"
  },
  {
    "arxiv_id": "2501.15061v2",
    "title": "PolaFormer: Polarity-aware Linear Attention for Vision Transformers",
    "authors": [
      "Weikang Meng",
      "Yadan Luo",
      "Xin Li",
      "Dongmei Jiang",
      "Zheng Zhang"
    ],
    "abstract": "Linear attention has emerged as a promising alternative to softmax-based\nattention, leveraging kernelized feature maps to reduce complexity from\nquadratic to linear in sequence length. However, the non-negative constraint on\nfeature maps and the relaxed exponential function used in approximation lead to\nsignificant information loss compared to the original query-key dot products,\nresulting in less discriminative attention maps with higher entropy. To address\nthe missing interactions driven by negative values in query-key pairs, we\npropose a polarity-aware linear attention mechanism that explicitly models both\nsame-signed and opposite-signed query-key interactions, ensuring comprehensive\ncoverage of relational information. Furthermore, to restore the spiky\nproperties of attention maps, we provide a theoretical analysis proving the\nexistence of a class of element-wise functions (with positive first and second\nderivatives) that can reduce entropy in the attention distribution. For\nsimplicity, and recognizing the distinct contributions of each dimension, we\nemploy a learnable power function for rescaling, allowing strong and weak\nattention signals to be effectively separated. Extensive experiments\ndemonstrate that the proposed PolaFormer improves performance on various vision\ntasks, enhancing both expressiveness and efficiency by up to 4.6%.",
    "categories": [
      "cs.CV",
      "cs.AI"
    ],
    "primary_category": "cs.CV",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2501.15061v2",
    "published_date": "2025-01-25 03:46:35 UTC",
    "updated_date": "2025-03-04 07:00:07 UTC"
  },
  {
    "arxiv_id": "2501.15056v1",
    "title": "Feedback-Aware Monte Carlo Tree Search for Efficient Information Seeking in Goal-Oriented Conversations",
    "authors": [
      "Harshita Chopra",
      "Chirag Shah"
    ],
    "abstract": "The ability to identify and acquire missing information is a critical\ncomponent of effective decision making and problem solving. With the rise of\nconversational artificial intelligence (AI) systems, strategically formulating\ninformation-seeking questions becomes crucial and demands efficient methods to\nguide the search process. We introduce a novel approach to adaptive\nquestion-asking through a combination of Large Language Models (LLM) for\ngenerating questions that maximize information gain, Monte Carlo Tree Search\n(MCTS) for constructing and leveraging a decision tree across multiple samples,\nand a hierarchical feedback mechanism to learn from past interactions. We\npresent two key innovations: (1) an adaptive MCTS algorithm that balances\nexploration and exploitation for efficient search over potential questions; and\n(2) a clustering-based feedback algorithm that leverages prior experience to\nguide future interactions. Each incoming sample is assigned to a cluster based\non its semantic similarity with previously observed samples. Our UCT (Upper\nConfidence bound for Trees) formulation selects optimal questions by combining\nexpected rewards, a function of information gain, with a cluster-specific bonus\nthat decays with depth, to emphasize the importance of early-stage questions\nthat have proven effective for narrowing the solution space in similar samples.\nExperiments across three domains, including medical diagnosis and\ntroubleshooting, demonstrate that our method leads to an average of 12%\nimprovement in success rates and a 10x reduction in the average number of LLM\ncalls made per conversation for the search process, in comparison to the state\nof the art.",
    "categories": [
      "cs.AI",
      "cs.CL",
      "cs.HC",
      "cs.LG"
    ],
    "primary_category": "cs.AI",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2501.15056v1",
    "published_date": "2025-01-25 03:42:22 UTC",
    "updated_date": "2025-01-25 03:42:22 UTC"
  },
  {
    "arxiv_id": "2501.15055v1",
    "title": "Group Ligands Docking to Protein Pockets",
    "authors": [
      "Jiaqi Guan",
      "Jiahan Li",
      "Xiangxin Zhou",
      "Xingang Peng",
      "Sheng Wang",
      "Yunan Luo",
      "Jian Peng",
      "Jianzhu Ma"
    ],
    "abstract": "Molecular docking is a key task in computational biology that has attracted\nincreasing interest from the machine learning community. While existing methods\nhave achieved success, they generally treat each protein-ligand pair in\nisolation. Inspired by the biochemical observation that ligands binding to the\nsame target protein tend to adopt similar poses, we propose \\textsc{GroupBind},\na novel molecular docking framework that simultaneously considers multiple\nligands docking to a protein. This is achieved by introducing an interaction\nlayer for the group of ligands and a triangle attention module for embedding\nprotein-ligand and group-ligand pairs. By integrating our approach with\ndiffusion-based docking model, we set a new S performance on the PDBBind blind\ndocking benchmark, demonstrating the effectiveness of our proposed molecular\ndocking paradigm.",
    "categories": [
      "q-bio.BM",
      "cs.AI"
    ],
    "primary_category": "q-bio.BM",
    "comment": "18 pages, published in ICLR 2025",
    "pdf_url": "http://arxiv.org/pdf/2501.15055v1",
    "published_date": "2025-01-25 03:36:17 UTC",
    "updated_date": "2025-01-25 03:36:17 UTC"
  },
  {
    "arxiv_id": "2501.15054v1",
    "title": "An Attempt to Unraveling Token Prediction Refinement and Identifying Essential Layers of Large Language Models",
    "authors": [
      "Jaturong Kongmanee"
    ],
    "abstract": "This research aims to unravel how large language models (LLMs) iteratively\nrefine token predictions (or, in a general sense, vector predictions). We\nutilized a logit lens technique to analyze the model's token predictions\nderived from intermediate representations. Specifically, we focused on how LLMs\naccess and use information from input contexts, and how positioning of relevant\ninformation affects the model's token prediction refinement process. Our\nfindings for multi-document question answering task, by varying input context\nlengths (the number of documents), using GPT-2, revealed that the number of\nlayers between the first layer that the model predicted next tokens correctly\nand the later layers that the model finalized its correct predictions, as a\nfunction of the position of relevant information (i.e., placing the relevant\none at the beginning, middle, or end of the input context), has a nearly\ninverted U shape. We found that the gap between these two layers, on average,\ndiminishes when relevant information is positioned at the beginning or end of\nthe input context, suggesting that the model requires more refinements when\nprocessing longer contexts with relevant information situated in the middle,\nand highlighting which layers are essential for determining the correct output.\nOur analysis provides insights about how token predictions are distributed\nacross different conditions, and establishes important connections to existing\nhypotheses and previous findings in AI safety research and development.",
    "categories": [
      "cs.CL",
      "cs.AI",
      "cs.LG"
    ],
    "primary_category": "cs.CL",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2501.15054v1",
    "published_date": "2025-01-25 03:34:15 UTC",
    "updated_date": "2025-01-25 03:34:15 UTC"
  },
  {
    "arxiv_id": "2501.15053v1",
    "title": "Exploring the impact of Optimised Hyperparameters on Bi-LSTM-based Contextual Anomaly Detector",
    "authors": [
      "Aafan Ahmad Toor",
      "Jia-Chun Lin",
      "Ernst Gunnar Gran"
    ],
    "abstract": "The exponential growth in the usage of Internet of Things in daily life has\ncaused immense increase in the generation of time series data. Smart homes is\none such domain where bulk of data is being generated and anomaly detection is\none of the many challenges addressed by researchers in recent years. Contextual\nanomaly is a kind of anomaly that may show deviation from the normal pattern\nlike point or sequence anomalies, but it also requires prior knowledge about\nthe data domain and the actions that caused the deviation. Recent studies based\non Recurrent Neural Networks (RNN) have demonstrated strong performance in\nanomaly detection. This study explores the impact of automatically tuned\nhyperparamteres on Unsupervised Online Contextual Anomaly Detection (UoCAD)\napproach by proposing UoCAD with Optimised Hyperparamnters (UoCAD-OH). UoCAD-OH\nconducts hyperparameter optimisation on Bi-LSTM model in an offline phase and\nuses the fine-tuned hyperparameters to detect anomalies during the online\nphase. The experiments involve evaluating the proposed framework on two smart\nhome air quality datasets containing contextual anomalies. The evaluation\nmetrics used are Precision, Recall, and F1 score.",
    "categories": [
      "cs.LG",
      "cs.AI"
    ],
    "primary_category": "cs.LG",
    "comment": "6 pages, 1 figure",
    "pdf_url": "http://arxiv.org/pdf/2501.15053v1",
    "published_date": "2025-01-25 03:26:22 UTC",
    "updated_date": "2025-01-25 03:26:22 UTC"
  },
  {
    "arxiv_id": "2501.15052v1",
    "title": "Graph-Based Cross-Domain Knowledge Distillation for Cross-Dataset Text-to-Image Person Retrieval",
    "authors": [
      "Bingjun Luo",
      "Jinpeng Wang",
      "Wang Zewen",
      "Junjie Zhu",
      "Xibin Zhao"
    ],
    "abstract": "Video surveillance systems are crucial components for ensuring public safety\nand management in smart city. As a fundamental task in video surveillance,\ntext-to-image person retrieval aims to retrieve the target person from an image\ngallery that best matches the given text description. Most existing\ntext-to-image person retrieval methods are trained in a supervised manner that\nrequires sufficient labeled data in the target domain. However, it is common in\npractice that only unlabeled data is available in the target domain due to the\ndifficulty and cost of data annotation, which limits the generalization of\nexisting methods in practical application scenarios. To address this issue, we\npropose a novel unsupervised domain adaptation method, termed Graph-Based\nCross-Domain Knowledge Distillation (GCKD), to learn the cross-modal feature\nrepresentation for text-to-image person retrieval in a cross-dataset scenario.\nThe proposed GCKD method consists of two main components. Firstly, a\ngraph-based multi-modal propagation module is designed to bridge the\ncross-domain correlation among the visual and textual samples. Secondly, a\ncontrastive momentum knowledge distillation module is proposed to learn the\ncross-modal feature representation using the online knowledge distillation\nstrategy. By jointly optimizing the two modules, the proposed method is able to\nachieve efficient performance for cross-dataset text-to-image person retrieval.\nacExtensive experiments on three publicly available text-to-image person\nretrieval datasets demonstrate the effectiveness of the proposed GCKD method,\nwhich consistently outperforms the state-of-the-art baselines.",
    "categories": [
      "cs.CV",
      "cs.AI",
      "cs.MM"
    ],
    "primary_category": "cs.CV",
    "comment": "Accepted by AAAI 2025",
    "pdf_url": "http://arxiv.org/pdf/2501.15052v1",
    "published_date": "2025-01-25 03:24:34 UTC",
    "updated_date": "2025-01-25 03:24:34 UTC"
  },
  {
    "arxiv_id": "2501.15046v1",
    "title": "Evaluating Hallucination in Large Vision-Language Models based on Context-Aware Object Similarities",
    "authors": [
      "Shounak Datta",
      "Dhanasekar Sundararaman"
    ],
    "abstract": "Despite their impressive performance on multi-modal tasks, large\nvision-language models (LVLMs) tend to suffer from hallucinations. An important\ntype is object hallucination, where LVLMs generate objects that are\ninconsistent with the images shown to the model. Existing works typically\nattempt to quantify object hallucinations by detecting and measuring the\nfraction of hallucinated objects in generated captions. Additionally, more\nrecent work also measures object hallucinations by directly querying the LVLM\nwith binary questions about the presence of likely hallucinated objects based\non object statistics like top-k frequent objects and top-k co-occurring\nobjects. In this paper, we present Context-Aware Object Similarities (CAOS), a\nnovel approach for evaluating object hallucination in LVLMs using object\nstatistics as well as the generated captions. CAOS uniquely integrates object\nstatistics with semantic relationships between objects in captions and\nground-truth data. Moreover, existing approaches usually only detect and\nmeasure hallucinations belonging to a predetermined set of in-domain objects\n(typically the set of all ground-truth objects for the training dataset) and\nignore generated objects that are not part of this set, leading to\nunder-evaluation. To address this, we further employ language model--based\nobject recognition to detect potentially out-of-domain hallucinated objects and\nuse an ensemble of LVLMs for verifying the presence of such objects in the\nquery image. CAOS also examines the sequential dynamics of object generation,\nshedding light on how the order of object appearance influences hallucinations,\nand employs word embedding models to analyze the semantic reasons behind\nhallucinations. CAOS aims to offer a nuanced understanding of the hallucination\ntendencies of LVLMs by providing a systematic framework to identify and\ninterpret object hallucinations.",
    "categories": [
      "cs.CV",
      "cs.AI",
      "cs.LG"
    ],
    "primary_category": "cs.CV",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2501.15046v1",
    "published_date": "2025-01-25 03:03:18 UTC",
    "updated_date": "2025-01-25 03:03:18 UTC"
  },
  {
    "arxiv_id": "2501.15045v2",
    "title": "Towards Robust Unsupervised Attention Prediction in Autonomous Driving",
    "authors": [
      "Mengshi Qi",
      "Xiaoyang Bi",
      "Pengfei Zhu",
      "Huadong Ma"
    ],
    "abstract": "Robustly predicting attention regions of interest for self-driving systems is\ncrucial for driving safety but presents significant challenges due to the\nlabor-intensive nature of obtaining large-scale attention labels and the domain\ngap between self-driving scenarios and natural scenes. These challenges are\nfurther exacerbated by complex traffic environments, including camera\ncorruption under adverse weather, noise interferences, and central bias from\nlong-tail distributions. To address these issues, we propose a robust\nunsupervised attention prediction method. An Uncertainty Mining Branch refines\npredictions by analyzing commonalities and differences across multiple\npre-trained models on natural scenes, while a Knowledge Embedding Block bridges\nthe domain gap by incorporating driving knowledge to adaptively enhance\npseudo-labels. Additionally, we introduce RoboMixup, a novel data augmentation\nmethod that improves robustness against corruption through soft attention and\ndynamic augmentation, and mitigates central bias by integrating random cropping\ninto Mixup as a regularizer. To systematically evaluate robustness in\nself-driving attention prediction, we introduce the DriverAttention-C\nbenchmark, comprising over 100k frames across three subsets: BDD-A-C,\nDR(eye)VE-C, and DADA-2000-C. Our method achieves performance equivalent to or\nsurpassing fully supervised state-of-the-art approaches on three public\ndatasets and the proposed robustness benchmark, reducing relative corruption\ndegradation by 58.8% and 52.8%, and improving central bias robustness by 12.4%\nand 11.4% in KLD and CC metrics, respectively. Code and data are available at\nhttps://github.com/zaplm/DriverAttention.",
    "categories": [
      "cs.CV",
      "cs.AI"
    ],
    "primary_category": "cs.CV",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2501.15045v2",
    "published_date": "2025-01-25 03:01:26 UTC",
    "updated_date": "2025-01-29 03:43:00 UTC"
  },
  {
    "arxiv_id": "2501.15038v1",
    "title": "Adaptive Client Selection in Federated Learning: A Network Anomaly Detection Use Case",
    "authors": [
      "William Marfo",
      "Deepak K. Tosh",
      "Shirley V. Moore"
    ],
    "abstract": "Federated Learning (FL) has become a widely used approach for training\nmachine learning models on decentralized data, addressing the significant\nprivacy concerns associated with traditional centralized methods. However, the\nefficiency of FL relies on effective client selection and robust privacy\npreservation mechanisms. Ineffective client selection can result in suboptimal\nmodel performance, while inadequate privacy measures risk exposing sensitive\ndata.\n  This paper introduces a client selection framework for FL that incorporates\ndifferential privacy and fault tolerance. The proposed adaptive approach\ndynamically adjusts the number of selected clients based on model performance\nand system constraints, ensuring privacy through the addition of calibrated\nnoise.\n  The method is evaluated on a network anomaly detection use case using the\nUNSW-NB15 and ROAD datasets. Results demonstrate up to a 7% improvement in\naccuracy and a 25% reduction in training time compared to the FedL2P approach.\nAdditionally, the study highlights trade-offs between privacy budgets and model\nperformance, with higher privacy budgets leading to reduced noise and improved\naccuracy. While the fault tolerance mechanism introduces a slight performance\ndecrease, it enhances robustness against client failures. Statistical\nvalidation using the Mann-Whitney U test confirms the significance of these\nimprovements, with results achieving a p-value of less than 0.05.",
    "categories": [
      "cs.LG",
      "cs.AI"
    ],
    "primary_category": "cs.LG",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2501.15038v1",
    "published_date": "2025-01-25 02:50:46 UTC",
    "updated_date": "2025-01-25 02:50:46 UTC"
  },
  {
    "arxiv_id": "2502.00036v1",
    "title": "Efficient Client Selection in Federated Learning",
    "authors": [
      "William Marfo",
      "Deepak K. Tosh",
      "Shirley V. Moore"
    ],
    "abstract": "Federated Learning (FL) enables decentralized machine learning while\npreserving data privacy. This paper proposes a novel client selection framework\nthat integrates differential privacy and fault tolerance. The adaptive client\nselection adjusts the number of clients based on performance and system\nconstraints, with noise added to protect privacy. Evaluated on the UNSW-NB15\nand ROAD datasets for network anomaly detection, the method improves accuracy\nby 7% and reduces training time by 25% compared to baselines. Fault tolerance\nenhances robustness with minimal performance trade-offs.",
    "categories": [
      "cs.LG",
      "cs.AI",
      "cs.DC"
    ],
    "primary_category": "cs.LG",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2502.00036v1",
    "published_date": "2025-01-25 02:43:55 UTC",
    "updated_date": "2025-01-25 02:43:55 UTC"
  },
  {
    "arxiv_id": "2501.15034v1",
    "title": "Divergence-Augmented Policy Optimization",
    "authors": [
      "Qing Wang",
      "Yingru Li",
      "Jiechao Xiong",
      "Tong Zhang"
    ],
    "abstract": "In deep reinforcement learning, policy optimization methods need to deal with\nissues such as function approximation and the reuse of off-policy data.\nStandard policy gradient methods do not handle off-policy data well, leading to\npremature convergence and instability. This paper introduces a method to\nstabilize policy optimization when off-policy data are reused. The idea is to\ninclude a Bregman divergence between the behavior policy that generates the\ndata and the current policy to ensure small and safe policy updates with\noff-policy data. The Bregman divergence is calculated between the state\ndistributions of two policies, instead of only on the action probabilities,\nleading to a divergence augmentation formulation. Empirical experiments on\nAtari games show that in the data-scarce scenario where the reuse of off-policy\ndata becomes necessary, our method can achieve better performance than other\nstate-of-the-art deep reinforcement learning algorithms.",
    "categories": [
      "cs.LG",
      "cs.AI",
      "stat.ML"
    ],
    "primary_category": "cs.LG",
    "comment": "33rd Conference on Neural Information Processing Systems (NeurIPS\n  2019), Vancouver, Canada",
    "pdf_url": "http://arxiv.org/pdf/2501.15034v1",
    "published_date": "2025-01-25 02:35:46 UTC",
    "updated_date": "2025-01-25 02:35:46 UTC"
  },
  {
    "arxiv_id": "2501.15030v2",
    "title": "OptiSeq: Ordering Examples On-The-Fly for In-Context Learning",
    "authors": [
      "Rahul Atul Bhope",
      "Praveen Venkateswaran",
      "K. R. Jayaram",
      "Vatche Isahagian",
      "Vinod Muthusamy",
      "Nalini Venkatasubramanian"
    ],
    "abstract": "Developers using LLMs and LLM-based agents in their applications have\nprovided plenty of anecdotal evidence that in-context-learning (ICL) is\nfragile. In this paper, we show that in addition to the quantity and quality of\nexamples, the order in which the in-context examples are listed in the prompt\naffects the output of the LLM and, consequently, their performance. While prior\nwork has explored improving ICL through dataset-dependent techniques, we\nintroduce OptiSeq, a purely inference-time, dataset-free optimization method\nthat efficiently determines the best example order. OptiSeq leverages log\nprobabilities of LLM-generated outputs to systematically prune the search space\nof possible orderings and recommend the best order(s) by distinguishing\norderings that yield high levels of accuracy and those that underperform.\nExtensive empirical evaluation on multiple LLMs, datasets, and prompts\ndemonstrate that OptiSeq improves accuracy by 5.5 - 10.5 percentage points\nacross multiple tasks.",
    "categories": [
      "cs.LG",
      "cs.AI",
      "cs.CL",
      "cs.PF"
    ],
    "primary_category": "cs.LG",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2501.15030v2",
    "published_date": "2025-01-25 02:24:00 UTC",
    "updated_date": "2025-02-18 19:00:03 UTC"
  },
  {
    "arxiv_id": "2501.15022v1",
    "title": "Using Large Language Models for education managements in Vietnamese with low resources",
    "authors": [
      "Duc Do Minh",
      "Vinh Nguyen Van",
      "Thang Dam Cong"
    ],
    "abstract": "Large language models (LLMs), such as GPT-4, Gemini 1.5, Claude 3.5 Sonnet,\nand Llama3, have demonstrated significant advancements in various NLP tasks\nsince the release of ChatGPT in 2022. Despite their success, fine-tuning and\ndeploying LLMs remain computationally expensive, especially in\nresource-constrained environments. In this paper, we proposed VietEduFrame, a\nframework specifically designed to apply LLMs to educational management tasks\nin Vietnamese institutions. Our key contribution includes the development of a\ntailored dataset, derived from student education documents at Hanoi VNU, which\naddresses the unique challenges faced by educational systems with limited\nresources. Through extensive experiments, we show that our approach outperforms\nexisting methods in terms of accuracy and efficiency, offering a promising\nsolution for improving educational management in under-resourced environments.\nWhile our framework leverages synthetic data to supplement real-world examples,\nwe discuss potential limitations regarding broader applicability and robustness\nin future implementations.",
    "categories": [
      "cs.CL",
      "cs.AI"
    ],
    "primary_category": "cs.CL",
    "comment": "15 pages; 13 figures; 9 tables",
    "pdf_url": "http://arxiv.org/pdf/2501.15022v1",
    "published_date": "2025-01-25 02:09:51 UTC",
    "updated_date": "2025-01-25 02:09:51 UTC"
  },
  {
    "arxiv_id": "2502.14870v1",
    "title": "Why do Experts Disagree on Existential Risk and P(doom)? A Survey of AI Experts",
    "authors": [
      "Severin Field"
    ],
    "abstract": "The development of artificial general intelligence (AGI) is likely to be one\nof humanity's most consequential technological advancements. Leading AI labs\nand scientists have called for the global prioritization of AI safety citing\nexistential risks comparable to nuclear war. However, research on catastrophic\nrisks and AI alignment is often met with skepticism, even by experts.\nFurthermore, online debate over the existential risk of AI has begun to turn\ntribal (e.g. name-calling such as \"doomer\" or \"accelerationist\"). Until now, no\nsystematic study has explored the patterns of belief and the levels of\nfamiliarity with AI safety concepts among experts. I surveyed 111 AI experts on\ntheir familiarity with AI safety concepts, key objections to AI safety, and\nreactions to safety arguments. My findings reveal that AI experts cluster into\ntwo viewpoints -- an \"AI as controllable tool\" and an \"AI as uncontrollable\nagent\" perspective -- diverging in beliefs toward the importance of AI safety.\nWhile most experts (78%) agreed or strongly agreed that \"technical AI\nresearchers should be concerned about catastrophic risks\", many were unfamiliar\nwith specific AI safety concepts. For example, only 21% of surveyed experts had\nheard of \"instrumental convergence,\" a fundamental concept in AI safety\npredicting that advanced AI systems will tend to pursue common sub-goals (such\nas self-preservation). The least concerned participants were the least familiar\nwith concepts like this, suggesting that effective communication of AI safety\nshould begin with establishing clear conceptual foundations in the field.",
    "categories": [
      "cs.CY",
      "cs.AI",
      "cs.HC"
    ],
    "primary_category": "cs.CY",
    "comment": "In submission to AI and Ethics Journal. 24 pages total, 15 pages of\n  writing with 9 pages of appendices",
    "pdf_url": "http://arxiv.org/pdf/2502.14870v1",
    "published_date": "2025-01-25 01:51:29 UTC",
    "updated_date": "2025-01-25 01:51:29 UTC"
  },
  {
    "arxiv_id": "2501.16383v2",
    "title": "RotateKV: Accurate and Robust 2-Bit KV Cache Quantization for LLMs via Outlier-Aware Adaptive Rotations",
    "authors": [
      "Zunhai Su",
      "Zhe Chen",
      "Wang Shen",
      "Hanyu Wei",
      "Linge Li",
      "Huangqi Yu",
      "Kehong Yuan"
    ],
    "abstract": "Key-Value (KV) cache facilitates efficient large language models (LLMs)\ninference by avoiding recomputation of past KVs. As the batch size and context\nlength increase, the oversized KV caches become a significant memory\nbottleneck, highlighting the need for efficient compression. Existing KV\nquantization rely on fine-grained quantization or the retention of a\nsignificant portion of high bit-widths caches, both of which compromise\ncompression ratio and often fail to maintain robustness at extremely low\naverage bit-widths. In this work, we explore the potential of rotation\ntechnique for 2-bit KV quantization and propose RotateKV, which achieves\naccurate and robust performance through the following innovations: (i)\nOutlier-Aware Rotation, which utilizes channel-reordering to adapt the\nrotations to varying channel-wise outlier distributions without sacrificing the\ncomputational efficiency of the fast Walsh-Hadamard transform (FWHT); (ii)\nPre-RoPE Grouped-Head Rotation, which mitigates the impact of rotary position\nembedding (RoPE) on proposed outlier-aware rotation and further smooths\noutliers across heads; (iii) Attention-Sink-Aware Quantization, which leverages\nthe massive activations to precisely identify and protect attention sinks.\nRotateKV achieves less than 0.3 perplexity (PPL) degradation with 2-bit\nquantization on WikiText-2 using LLaMA-2-13B, maintains strong CoT reasoning\nand long-context capabilities, with less than 1.7\\% degradation on GSM8K,\noutperforming existing methods even at lower average bit-widths. RotateKV also\nshowcases a 3.97x reduction in peak memory usage, supports 5.75x larger batch\nsizes, and achieves a 2.32x speedup in decoding stage.",
    "categories": [
      "cs.LG",
      "cs.AI",
      "cs.CL"
    ],
    "primary_category": "cs.LG",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2501.16383v2",
    "published_date": "2025-01-25 01:45:29 UTC",
    "updated_date": "2025-02-02 03:04:54 UTC"
  },
  {
    "arxiv_id": "2501.15014v2",
    "title": "On Accelerating Edge AI: Optimizing Resource-Constrained Environments",
    "authors": [
      "Jacob Sander",
      "Achraf Cohen",
      "Venkat R. Dasari",
      "Brent Venable",
      "Brian Jalaian"
    ],
    "abstract": "Resource-constrained edge deployments demand AI solutions that balance high\nperformance with stringent compute, memory, and energy limitations. In this\nsurvey, we present a comprehensive overview of the primary strategies for\naccelerating deep learning models under such constraints. First, we examine\nmodel compression techniques-pruning, quantization, tensor decomposition, and\nknowledge distillation-that streamline large models into smaller, faster, and\nmore efficient variants. Next, we explore Neural Architecture Search (NAS), a\nclass of automated methods that discover architectures inherently optimized for\nparticular tasks and hardware budgets. We then discuss compiler and deployment\nframeworks, such as TVM, TensorRT, and OpenVINO, which provide\nhardware-tailored optimizations at inference time. By integrating these three\npillars into unified pipelines, practitioners can achieve multi-objective\ngoals, including latency reduction, memory savings, and energy efficiency-all\nwhile maintaining competitive accuracy. We also highlight emerging frontiers in\nhierarchical NAS, neurosymbolic approaches, and advanced distillation tailored\nto large language models, underscoring open challenges like pre-training\npruning for massive networks. Our survey offers practical insights, identifies\ncurrent research gaps, and outlines promising directions for building scalable,\nplatform-independent frameworks to accelerate deep learning models at the edge.",
    "categories": [
      "cs.LG",
      "cs.AI",
      "cs.NE"
    ],
    "primary_category": "cs.LG",
    "comment": "26 pages, 13 Figures",
    "pdf_url": "http://arxiv.org/pdf/2501.15014v2",
    "published_date": "2025-01-25 01:37:03 UTC",
    "updated_date": "2025-01-28 20:29:44 UTC"
  },
  {
    "arxiv_id": "2501.15007v1",
    "title": "Controllable Protein Sequence Generation with LLM Preference Optimization",
    "authors": [
      "Xiangyu Liu",
      "Yi Liu",
      "Silei Chen",
      "Wei Hu"
    ],
    "abstract": "Designing proteins with specific attributes offers an important solution to\naddress biomedical challenges. Pre-trained protein large language models (LLMs)\nhave shown promising results on protein sequence generation. However, to\ncontrol sequence generation for specific attributes, existing work still\nexhibits poor functionality and structural stability. In this paper, we propose\na novel controllable protein design method called CtrlProt. We finetune a\nprotein LLM with a new multi-listwise preference optimization strategy to\nimprove generation quality and support multi-attribute controllable generation.\nExperiments demonstrate that CtrlProt can meet functionality and structural\nstability requirements effectively, achieving state-of-the-art performance in\nboth single-attribute and multi-attribute protein sequence generation.",
    "categories": [
      "cs.AI",
      "cs.CE",
      "q-bio.QM"
    ],
    "primary_category": "cs.AI",
    "comment": "Accepted in the 39th Annual AAAI Conference on Artificial\n  Intelligence (AAAI 2025)",
    "pdf_url": "http://arxiv.org/pdf/2501.15007v1",
    "published_date": "2025-01-25 00:59:12 UTC",
    "updated_date": "2025-01-25 00:59:12 UTC"
  },
  {
    "arxiv_id": "2501.15001v2",
    "title": "What if Eye...? Computationally Recreating Vision Evolution",
    "authors": [
      "Kushagra Tiwary",
      "Aaron Young",
      "Zaid Tasneem",
      "Tzofi Klinghoffer",
      "Akshat Dave",
      "Tomaso Poggio",
      "Dan-Eric Nilsson",
      "Brian Cheung",
      "Ramesh Raskar"
    ],
    "abstract": "Vision systems in nature show remarkable diversity, from simple\nlight-sensitive patches to complex camera eyes with lenses. While natural\nselection has produced these eyes through countless mutations over millions of\nyears, they represent just one set of realized evolutionary paths. Testing\nhypotheses about how environmental pressures shaped eye evolution remains\nchallenging since we cannot experimentally isolate individual factors.\nComputational evolution offers a way to systematically explore alternative\ntrajectories. Here we show how environmental demands drive three fundamental\naspects of visual evolution through an artificial evolution framework that\nco-evolves both physical eye structure and neural processing in embodied\nagents. First, we demonstrate computational evidence that task specific\nselection drives bifurcation in eye evolution - orientation tasks like\nnavigation in a maze leads to distributed compound-type eyes while an object\ndiscrimination task leads to the emergence of high-acuity camera-type eyes.\nSecond, we reveal how optical innovations like lenses naturally emerge to\nresolve fundamental tradeoffs between light collection and spatial precision.\nThird, we uncover systematic scaling laws between visual acuity and neural\nprocessing, showing how task complexity drives coordinated evolution of sensory\nand computational capabilities. Our work introduces a novel paradigm that\nilluminates evolutionary principles shaping vision by creating targeted\nsingle-player games where embodied agents must simultaneously evolve visual\nsystems and learn complex behaviors. Through our unified genetic encoding\nframework, these embodied agents serve as next-generation hypothesis testing\nmachines while providing a foundation for designing manufacturable bio-inspired\nvision systems. Website: http://eyes.mit.edu/",
    "categories": [
      "cs.AI",
      "cs.CV",
      "cs.NE",
      "q-bio.NC"
    ],
    "primary_category": "cs.AI",
    "comment": "Website: http://eyes.mit.edu/",
    "pdf_url": "http://arxiv.org/pdf/2501.15001v2",
    "published_date": "2025-01-25 00:29:24 UTC",
    "updated_date": "2025-02-13 04:15:47 UTC"
  },
  {
    "arxiv_id": "2501.14994v1",
    "title": "Robust Cross-Etiology and Speaker-Independent Dysarthric Speech Recognition",
    "authors": [
      "Satwinder Singh",
      "Qianli Wang",
      "Zihan Zhong",
      "Clarion Mendes",
      "Mark Hasegawa-Johnson",
      "Waleed Abdulla",
      "Seyed Reza Shahamiri"
    ],
    "abstract": "In this paper, we present a speaker-independent dysarthric speech recognition\nsystem, with a focus on evaluating the recently released Speech Accessibility\nProject (SAP-1005) dataset, which includes speech data from individuals with\nParkinson's disease (PD). Despite the growing body of research in dysarthric\nspeech recognition, many existing systems are speaker-dependent and adaptive,\nlimiting their generalizability across different speakers and etiologies. Our\nprimary objective is to develop a robust speaker-independent model capable of\naccurately recognizing dysarthric speech, irrespective of the speaker.\nAdditionally, as a secondary objective, we aim to test the cross-etiology\nperformance of our model by evaluating it on the TORGO dataset, which contains\nspeech samples from individuals with cerebral palsy (CP) and amyotrophic\nlateral sclerosis (ALS). By leveraging the Whisper model, our\nspeaker-independent system achieved a CER of 6.99% and a WER of 10.71% on the\nSAP-1005 dataset. Further, in cross-etiology settings, we achieved a CER of\n25.08% and a WER of 39.56% on the TORGO dataset. These results highlight the\npotential of our approach to generalize across unseen speakers and different\netiologies of dysarthria.",
    "categories": [
      "cs.SD",
      "cs.AI",
      "cs.LG",
      "eess.AS"
    ],
    "primary_category": "cs.SD",
    "comment": "Accepted to ICASSP 2025",
    "pdf_url": "http://arxiv.org/pdf/2501.14994v1",
    "published_date": "2025-01-25 00:02:58 UTC",
    "updated_date": "2025-01-25 00:02:58 UTC"
  }
]