[
  {
    "arxiv_id": "2406.19578v1",
    "title": "PathAlign: A vision-language model for whole slide images in histopathology",
    "authors": [
      "Faruk Ahmed",
      "Andrew Sellergren",
      "Lin Yang",
      "Shawn Xu",
      "Boris Babenko",
      "Abbi Ward",
      "Niels Olson",
      "Arash Mohtashamian",
      "Yossi Matias",
      "Greg S. Corrado",
      "Quang Duong",
      "Dale R. Webster",
      "Shravya Shetty",
      "Daniel Golden",
      "Yun Liu",
      "David F. Steiner",
      "Ellery Wulczyn"
    ],
    "abstract": "Microscopic interpretation of histopathology images underlies many important\ndiagnostic and treatment decisions. While advances in vision-language modeling\nraise new opportunities for analysis of such images, the gigapixel-scale size\nof whole slide images (WSIs) introduces unique challenges. Additionally,\npathology reports simultaneously highlight key findings from small regions\nwhile also aggregating interpretation across multiple slides, often making it\ndifficult to create robust image-text pairs. As such, pathology reports remain\na largely untapped source of supervision in computational pathology, with most\nefforts relying on region-of-interest annotations or self-supervision at the\npatch-level. In this work, we develop a vision-language model based on the\nBLIP-2 framework using WSIs paired with curated text from pathology reports.\nThis enables applications utilizing a shared image-text embedding space, such\nas text or image retrieval for finding cases of interest, as well as\nintegration of the WSI encoder with a frozen large language model (LLM) for\nWSI-based generative text capabilities such as report generation or\nAI-in-the-loop interactions. We utilize a de-identified dataset of over 350,000\nWSIs and diagnostic text pairs, spanning a wide range of diagnoses, procedure\ntypes, and tissue types. We present pathologist evaluation of text generation\nand text retrieval using WSI embeddings, as well as results for WSI\nclassification and workflow prioritization (slide-level triaging).\nModel-generated text for WSIs was rated by pathologists as accurate, without\nclinically significant error or omission, for 78% of WSIs on average. This work\ndemonstrates exciting potential capabilities for language-aligned WSI\nembeddings.",
    "categories": [
      "cs.CV",
      "cs.AI",
      "cs.CL",
      "cs.LG"
    ],
    "primary_category": "cs.CV",
    "comment": "9 main pages and 19 pages of supplemental material; 3 main tables, 3\n  main figures and 11 supplemental tables, 7 supplemental figures",
    "pdf_url": "http://arxiv.org/pdf/2406.19578v1",
    "published_date": "2024-06-27 23:43:36 UTC",
    "updated_date": "2024-06-27 23:43:36 UTC"
  },
  {
    "arxiv_id": "2406.19570v2",
    "title": "Synthetic Cancer -- Augmenting Worms with LLMs",
    "authors": [
      "Benjamin Zimmerman",
      "David Zollikofer"
    ],
    "abstract": "With increasingly sophisticated large language models (LLMs), the potential\nfor abuse rises drastically. As a submission to the Swiss AI Safety Prize, we\npresent a novel type of metamorphic malware leveraging LLMs for two key\nprocesses. First, LLMs are used for automatic code rewriting to evade\nsignature-based detection by antimalware programs. The malware then spreads its\ncopies via email by utilizing an LLM to socially engineer email replies to\nencourage recipients to execute the attached malware. Our submission includes a\nfunctional minimal prototype, highlighting the risks that LLMs pose for\ncybersecurity and underscoring the need for further research into intelligent\nmalware.",
    "categories": [
      "cs.CR",
      "cs.AI"
    ],
    "primary_category": "cs.CR",
    "comment": "Won first place at the Swiss AI Safety Prize. Some technical details\n  omitted, contact authors for more information",
    "pdf_url": "http://arxiv.org/pdf/2406.19570v2",
    "published_date": "2024-06-27 23:15:45 UTC",
    "updated_date": "2024-07-12 13:40:10 UTC"
  },
  {
    "arxiv_id": "2406.19568v1",
    "title": "What Matters in Detecting AI-Generated Videos like Sora?",
    "authors": [
      "Chirui Chang",
      "Zhengzhe Liu",
      "Xiaoyang Lyu",
      "Xiaojuan Qi"
    ],
    "abstract": "Recent advancements in diffusion-based video generation have showcased\nremarkable results, yet the gap between synthetic and real-world videos remains\nunder-explored. In this study, we examine this gap from three fundamental\nperspectives: appearance, motion, and geometry, comparing real-world videos\nwith those generated by a state-of-the-art AI model, Stable Video Diffusion. To\nachieve this, we train three classifiers using 3D convolutional networks, each\ntargeting distinct aspects: vision foundation model features for appearance,\noptical flow for motion, and monocular depth for geometry. Each classifier\nexhibits strong performance in fake video detection, both qualitatively and\nquantitatively. This indicates that AI-generated videos are still easily\ndetectable, and a significant gap between real and fake videos persists.\nFurthermore, utilizing the Grad-CAM, we pinpoint systematic failures of\nAI-generated videos in appearance, motion, and geometry. Finally, we propose an\nEnsemble-of-Experts model that integrates appearance, optical flow, and depth\ninformation for fake video detection, resulting in enhanced robustness and\ngeneralization ability. Our model is capable of detecting videos generated by\nSora with high accuracy, even without exposure to any Sora videos during\ntraining. This suggests that the gap between real and fake videos can be\ngeneralized across various video generative models. Project page:\nhttps://justin-crchang.github.io/3DCNNDetection.github.io/",
    "categories": [
      "cs.CV",
      "cs.AI"
    ],
    "primary_category": "cs.CV",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2406.19568v1",
    "published_date": "2024-06-27 23:03:58 UTC",
    "updated_date": "2024-06-27 23:03:58 UTC"
  },
  {
    "arxiv_id": "2406.19561v1",
    "title": "Meta-Gradient Search Control: A Method for Improving the Efficiency of Dyna-style Planning",
    "authors": [
      "Bradley Burega",
      "John D. Martin",
      "Luke Kapeluck",
      "Michael Bowling"
    ],
    "abstract": "We study how a Reinforcement Learning (RL) system can remain sample-efficient\nwhen learning from an imperfect model of the environment. This is particularly\nchallenging when the learning system is resource-constrained and in continual\nsettings, where the environment dynamics change. To address these challenges,\nour paper introduces an online, meta-gradient algorithm that tunes a\nprobability with which states are queried during Dyna-style planning. Our study\ncompares the aggregate, empirical performance of this meta-gradient method to\nbaselines that employ conventional sampling strategies. Results indicate that\nour method improves efficiency of the planning process, which, as a\nconsequence, improves the sample-efficiency of the overall learning process. On\nthe whole, we observe that our meta-learned solutions avoid several pathologies\nof conventional planning approaches, such as sampling inaccurate transitions\nand those that stall credit assignment. We believe these findings could prove\nuseful, in future work, for designing model-based RL systems at scale.",
    "categories": [
      "cs.LG",
      "cs.AI"
    ],
    "primary_category": "cs.LG",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2406.19561v1",
    "published_date": "2024-06-27 22:24:46 UTC",
    "updated_date": "2024-06-27 22:24:46 UTC"
  },
  {
    "arxiv_id": "2407.12021v2",
    "title": "Adaptive Draft-Verification for Efficient Large Language Model Decoding",
    "authors": [
      "Xukun Liu",
      "Bowen Lei",
      "Ruqi Zhang",
      "Dongkuan Xu"
    ],
    "abstract": "Large language model (LLM) decoding involves generating a sequence of tokens\nbased on a given context, where each token is predicted one at a time using the\nmodel's learned probabilities. The typical autoregressive decoding method\nrequires a separate forward pass through the model for each token generated,\nwhich is computationally inefficient and poses challenges for deploying LLMs in\nlatency-sensitive scenarios. The main limitations of current decoding methods\nstem from their inefficiencies and resource demands. Existing approaches either\nnecessitate fine-tuning smaller models, which is resource-intensive, or rely on\nfixed retrieval schemes to construct drafts for the next tokens, which lack\nadaptability and fail to generalize across different models and contexts. To\naddress these issues, we introduce a novel methodology called ADED, which\naccelerates LLM decoding without requiring fine-tuning. Our approach involves\nan adaptive draft-verification process that evolves over time to improve\nefficiency. We utilize a tri-gram matrix-based LLM representation to\ndynamically approximate the output distribution of the LLM, allowing the model\nto adjust to changing token probabilities during the decoding process.\nAdditionally, we implement a draft construction mechanism that effectively\nbalances exploration and exploitation, ensuring that the drafts generated are\nboth diverse and close to the true output distribution of the LLM. The\nimportance of this design lies in its ability to optimize the draft\ndistribution adaptively, leading to faster and more accurate decoding. Through\nextensive experiments on various benchmark datasets and LLM architectures, we\ndemonstrate that ADED significantly accelerates the decoding process while\nmaintaining high accuracy, making it suitable for deployment in a wide range of\npractical applications.",
    "categories": [
      "cs.CL",
      "cs.AI"
    ],
    "primary_category": "cs.CL",
    "comment": "Under review of Neurips 2024",
    "pdf_url": "http://arxiv.org/pdf/2407.12021v2",
    "published_date": "2024-06-27 22:20:39 UTC",
    "updated_date": "2024-08-19 15:28:37 UTC"
  },
  {
    "arxiv_id": "2406.19552v1",
    "title": "Rethinking harmless refusals when fine-tuning foundation models",
    "authors": [
      "Florin Pop",
      "Judd Rosenblatt",
      "Diogo Schwerz de Lucena",
      "Michael Vaiana"
    ],
    "abstract": "In this paper, we investigate the degree to which fine-tuning in Large\nLanguage Models (LLMs) effectively mitigates versus merely conceals undesirable\nbehavior. Through the lens of semi-realistic role-playing exercises designed to\nelicit such behaviors, we explore the response dynamics of LLMs post\nfine-tuning interventions. Our methodology involves prompting models for\nChain-of-Thought (CoT) reasoning and analyzing the coherence between the\nreasoning traces and the resultant outputs. Notably, we identify a pervasive\nphenomenon we term \\emph{reason-based deception}, where models either stop\nproducing reasoning traces or produce seemingly ethical reasoning traces that\nbelie the unethical nature of their final outputs. We further examine the\nefficacy of response strategies (polite refusal versus explicit rebuttal) in\ncurbing the occurrence of undesired behavior in subsequent outputs of\nmulti-turn interactions. Our findings reveal that explicit rebuttals\nsignificantly outperform polite refusals in preventing the continuation of\nundesired outputs and nearly eliminate reason-based deception, challenging\ncurrent practices in model fine-tuning. Accordingly, the two key contributions\nof this paper are (1) defining and studying reason-based deception, a new type\nof hidden behavior, and (2) demonstrating that rebuttals provide a more robust\nresponse model to harmful requests than refusals, thereby highlighting the need\nto reconsider the response strategies in fine-tuning approaches.",
    "categories": [
      "cs.CL",
      "cs.AI",
      "cs.LG"
    ],
    "primary_category": "cs.CL",
    "comment": "ICLR 2024 AGI Workshop Poster",
    "pdf_url": "http://arxiv.org/pdf/2406.19552v1",
    "published_date": "2024-06-27 22:08:22 UTC",
    "updated_date": "2024-06-27 22:08:22 UTC"
  },
  {
    "arxiv_id": "2407.02524v1",
    "title": "Meta Large Language Model Compiler: Foundation Models of Compiler Optimization",
    "authors": [
      "Chris Cummins",
      "Volker Seeker",
      "Dejan Grubisic",
      "Baptiste Roziere",
      "Jonas Gehring",
      "Gabriel Synnaeve",
      "Hugh Leather"
    ],
    "abstract": "Large Language Models (LLMs) have demonstrated remarkable capabilities across\na variety of software engineering and coding tasks. However, their application\nin the domain of code and compiler optimization remains underexplored. Training\nLLMs is resource-intensive, requiring substantial GPU hours and extensive data\ncollection, which can be prohibitive. To address this gap, we introduce Meta\nLarge Language Model Compiler (LLM Compiler), a suite of robust, openly\navailable, pre-trained models specifically designed for code optimization\ntasks. Built on the foundation of Code Llama, LLM Compiler enhances the\nunderstanding of compiler intermediate representations (IRs), assembly\nlanguage, and optimization techniques. The model has been trained on a vast\ncorpus of 546 billion tokens of LLVM-IR and assembly code and has undergone\ninstruction fine-tuning to interpret compiler behavior. LLM Compiler is\nreleased under a bespoke commercial license to allow wide reuse and is\navailable in two sizes: 7 billion and 13 billion parameters. We also present\nfine-tuned versions of the model, demonstrating its enhanced capabilities in\noptimizing code size and disassembling from x86_64 and ARM assembly back into\nLLVM-IR. These achieve 77% of the optimising potential of an autotuning search,\nand 45% disassembly round trip (14% exact match). This release aims to provide\na scalable, cost-effective foundation for further research and development in\ncompiler optimization by both academic researchers and industry practitioners.",
    "categories": [
      "cs.PL",
      "cs.AI"
    ],
    "primary_category": "cs.PL",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2407.02524v1",
    "published_date": "2024-06-27 21:47:48 UTC",
    "updated_date": "2024-06-27 21:47:48 UTC"
  },
  {
    "arxiv_id": "2406.19545v1",
    "title": "Leveraging Machine-Generated Rationales to Facilitate Social Meaning Detection in Conversations",
    "authors": [
      "Ritam Dutt",
      "Zhen Wu",
      "Kelly Shi",
      "Divyanshu Sheth",
      "Prakhar Gupta",
      "Carolyn Penstein Rose"
    ],
    "abstract": "We present a generalizable classification approach that leverages Large\nLanguage Models (LLMs) to facilitate the detection of implicitly encoded social\nmeaning in conversations. We design a multi-faceted prompt to extract a textual\nexplanation of the reasoning that connects visible cues to underlying social\nmeanings. These extracted explanations or rationales serve as augmentations to\nthe conversational text to facilitate dialogue understanding and transfer. Our\nempirical results over 2,340 experimental settings demonstrate the significant\npositive impact of adding these rationales. Our findings hold true for\nin-domain classification, zero-shot, and few-shot domain transfer for two\ndifferent social meaning detection tasks, each spanning two different corpora.",
    "categories": [
      "cs.CL",
      "cs.AI"
    ],
    "primary_category": "cs.CL",
    "comment": "To appear at The Proceedings of the Association for Computational\n  Linguistics, 2024",
    "pdf_url": "http://arxiv.org/pdf/2406.19545v1",
    "published_date": "2024-06-27 21:47:42 UTC",
    "updated_date": "2024-06-27 21:47:42 UTC"
  },
  {
    "arxiv_id": "2407.12813v2",
    "title": "Data Generation Using Large Language Models for Text Classification: An Empirical Case Study",
    "authors": [
      "Yinheng Li",
      "Rogerio Bonatti",
      "Sara Abdali",
      "Justin Wagle",
      "Kazuhito Koishida"
    ],
    "abstract": "Using Large Language Models (LLMs) to generate synthetic data for model\ntraining has become increasingly popular in recent years. While LLMs are\ncapable of producing realistic training data, the effectiveness of data\ngeneration is influenced by various factors, including the choice of prompt,\ntask complexity, and the quality, quantity, and diversity of the generated\ndata. In this work, we focus exclusively on using synthetic data for text\nclassification tasks. Specifically, we use natural language understanding (NLU)\nmodels trained on synthetic data to assess the quality of synthetic data from\ndifferent generation approaches. This work provides an empirical analysis of\nthe impact of these factors and offers recommendations for better data\ngeneration practices.",
    "categories": [
      "cs.CL",
      "cs.AI"
    ],
    "primary_category": "cs.CL",
    "comment": "Accepted by DMLR @ ICML 2024",
    "pdf_url": "http://arxiv.org/pdf/2407.12813v2",
    "published_date": "2024-06-27 21:41:43 UTC",
    "updated_date": "2024-07-19 20:37:17 UTC"
  },
  {
    "arxiv_id": "2406.19537v1",
    "title": "Handling Ontology Gaps in Semantic Parsing",
    "authors": [
      "Andrea Bacciu",
      "Marco Damonte",
      "Marco Basaldella",
      "Emilio Monti"
    ],
    "abstract": "The majority of Neural Semantic Parsing (NSP) models are developed with the\nassumption that there are no concepts outside the ones such models can\nrepresent with their target symbols (closed-world assumption). This assumption\nleads to generate hallucinated outputs rather than admitting their lack of\nknowledge. Hallucinations can lead to wrong or potentially offensive responses\nto users. Hence, a mechanism to prevent this behavior is crucial to build\ntrusted NSP-based Question Answering agents. To that end, we propose the\nHallucination Simulation Framework (HSF), a general setting for stimulating and\nanalyzing NSP model hallucinations. The framework can be applied to any NSP\ntask with a closed-ontology. Using the proposed framework and KQA Pro as the\nbenchmark dataset, we assess state-of-the-art techniques for hallucination\ndetection. We then present a novel hallucination detection strategy that\nexploits the computational graph of the NSP model to detect the NSP\nhallucinations in the presence of ontology gaps, out-of-domain utterances, and\nto recognize NSP errors, improving the F1-Score respectively by ~21, ~24% and\n~1%. This is the first work in closed-ontology NSP that addresses the problem\nof recognizing ontology gaps. We release our code and checkpoints at\nhttps://github.com/amazon-science/handling-ontology-gaps-in-semantic-parsing.",
    "categories": [
      "cs.CL",
      "cs.AI"
    ],
    "primary_category": "cs.CL",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2406.19537v1",
    "published_date": "2024-06-27 21:21:22 UTC",
    "updated_date": "2024-06-27 21:21:22 UTC"
  },
  {
    "arxiv_id": "2406.19528v3",
    "title": "Harnessing LLMs for Automated Video Content Analysis: An Exploratory Workflow of Short Videos on Depression",
    "authors": [
      "Jiaying Lizzy Liu",
      "Yunlong Wang",
      "Yao Lyu",
      "Yiheng Su",
      "Shuo Niu",
      "Xuhai Orson Xu",
      "Yan Zhang"
    ],
    "abstract": "Despite the growing interest in leveraging Large Language Models (LLMs) for\ncontent analysis, current studies have primarily focused on text-based content.\nIn the present work, we explored the potential of LLMs in assisting video\ncontent analysis by conducting a case study that followed a new workflow of\nLLM-assisted multimodal content analysis. The workflow encompasses codebook\ndesign, prompt engineering, LLM processing, and human evaluation. We\nstrategically crafted annotation prompts to get LLM Annotations in structured\nform and explanation prompts to generate LLM Explanations for a better\nunderstanding of LLM reasoning and transparency. To test LLM's video annotation\ncapabilities, we analyzed 203 keyframes extracted from 25 YouTube short videos\nabout depression. We compared the LLM Annotations with those of two human\ncoders and found that LLM has higher accuracy in object and activity\nAnnotations than emotion and genre Annotations. Moreover, we identified the\npotential and limitations of LLM's capabilities in annotating videos. Based on\nthe findings, we explore opportunities and challenges for future research and\nimprovements to the workflow. We also discuss ethical concerns surrounding\nfuture studies based on LLM-assisted video analysis.",
    "categories": [
      "cs.HC",
      "cs.AI",
      "cs.CY"
    ],
    "primary_category": "cs.HC",
    "comment": "7 pages, 2 figures, accepted by CSCW 24",
    "pdf_url": "http://arxiv.org/pdf/2406.19528v3",
    "published_date": "2024-06-27 21:03:56 UTC",
    "updated_date": "2024-07-29 22:12:06 UTC"
  },
  {
    "arxiv_id": "2406.19512v1",
    "title": "Captioning Visualizations with Large Language Models (CVLLM): A Tutorial",
    "authors": [
      "Giuseppe Carenini",
      "Jordon Johnson",
      "Ali Salamatian"
    ],
    "abstract": "Automatically captioning visualizations is not new, but recent advances in\nlarge language models(LLMs) open exciting new possibilities. In this tutorial,\nafter providing a brief review of Information Visualization (InfoVis)\nprinciples and past work in captioning, we introduce neural models and the\ntransformer architecture used in generic LLMs. We then discuss their recent\napplications in InfoVis, with a focus on captioning. Additionally, we explore\npromising future directions in this field.",
    "categories": [
      "cs.CL",
      "cs.AI",
      "cs.HC"
    ],
    "primary_category": "cs.CL",
    "comment": "6 pages, 4 figures",
    "pdf_url": "http://arxiv.org/pdf/2406.19512v1",
    "published_date": "2024-06-27 20:18:18 UTC",
    "updated_date": "2024-06-27 20:18:18 UTC"
  },
  {
    "arxiv_id": "2407.17474v1",
    "title": "\"My Kind of Woman\": Analysing Gender Stereotypes in AI through The Averageness Theory and EU Law",
    "authors": [
      "Miriam Doh",
      "Anastasia Karagianni"
    ],
    "abstract": "This study delves into gender classification systems, shedding light on the\ninteraction between social stereotypes and algorithmic determinations. Drawing\non the \"averageness theory,\" which suggests a relationship between a face's\nattractiveness and the human ability to ascertain its gender, we explore the\npotential propagation of human bias into artificial intelligence (AI) systems.\nUtilising the AI model Stable Diffusion 2.1, we have created a dataset\ncontaining various connotations of attractiveness to test whether the\ncorrelation between attractiveness and accuracy in gender classification\nobserved in human cognition persists within AI. Our findings indicate that akin\nto human dynamics, AI systems exhibit variations in gender classification\naccuracy based on attractiveness, mirroring social prejudices and stereotypes\nin their algorithmic decisions. This discovery underscores the critical need to\nconsider the impacts of human perceptions on data collection and highlights the\nnecessity for a multidisciplinary and intersectional approach to AI development\nand AI data training. By incorporating cognitive psychology and feminist legal\ntheory, we examine how data used for AI training can foster gender diversity\nand fairness under the scope of the AI Act and GDPR, reaffirming how\npsychological and feminist legal theories can offer valuable insights for\nensuring the protection of gender equality and non-discrimination in AI\nsystems.",
    "categories": [
      "cs.CY",
      "cs.AI"
    ],
    "primary_category": "cs.CY",
    "comment": "presented at IAIL 2024 the Imagining the AI Landscape After the AI\n  ACT, in conjunction with HHAI2024, Malm\\\"o, Sweden, June 10, 2024",
    "pdf_url": "http://arxiv.org/pdf/2407.17474v1",
    "published_date": "2024-06-27 20:03:27 UTC",
    "updated_date": "2024-06-27 20:03:27 UTC"
  },
  {
    "arxiv_id": "2406.19507v2",
    "title": "Too Good to be True? Turn Any Model Differentially Private With DP-Weights",
    "authors": [
      "David Zagardo"
    ],
    "abstract": "Imagine training a machine learning model with Differentially Private\nStochastic Gradient Descent (DP-SGD), only to discover post-training that the\nnoise level was either too high, crippling your model's utility, or too low,\ncompromising privacy. The dreaded realization hits: you must start the lengthy\ntraining process from scratch. But what if you could avoid this retraining\nnightmare? In this study, we introduce a groundbreaking approach (to our\nknowledge) that applies differential privacy noise to the model's weights after\ntraining. We offer a comprehensive mathematical proof for this novel approach's\nprivacy bounds, use formal methods to validate its privacy guarantees, and\nempirically evaluate its effectiveness using membership inference attacks and\nperformance evaluations. This method allows for a single training run, followed\nby post-hoc noise adjustments to achieve optimal privacy-utility trade-offs. We\ncompare this novel fine-tuned model (DP-Weights model) to a traditional DP-SGD\nmodel, demonstrating that our approach yields statistically similar performance\nand privacy guarantees. Our results validate the efficacy of post-training\nnoise application, promising significant time savings and flexibility in\nfine-tuning differential privacy parameters, making it a practical alternative\nfor deploying differentially private models in real-world scenarios.",
    "categories": [
      "cs.LG",
      "cs.AI",
      "cs.CR"
    ],
    "primary_category": "cs.LG",
    "comment": "The results are genuine, but the math is wrong! Please do not use\n  this method for your Differential Privacy implementations",
    "pdf_url": "http://arxiv.org/pdf/2406.19507v2",
    "published_date": "2024-06-27 19:58:11 UTC",
    "updated_date": "2025-01-20 16:23:41 UTC"
  },
  {
    "arxiv_id": "2406.19502v2",
    "title": "Hierarchical Deconstruction of LLM Reasoning: A Graph-Based Framework for Analyzing Knowledge Utilization",
    "authors": [
      "Miyoung Ko",
      "Sue Hyun Park",
      "Joonsuk Park",
      "Minjoon Seo"
    ],
    "abstract": "Despite the advances in large language models (LLMs), how they use their\nknowledge for reasoning is not yet well understood. In this study, we propose a\nmethod that deconstructs complex real-world questions into a graph,\nrepresenting each question as a node with predecessors of background knowledge\nneeded to solve the question. We develop the DepthQA dataset, deconstructing\nquestions into three depths: (i) recalling conceptual knowledge, (ii) applying\nprocedural knowledge, and (iii) analyzing strategic knowledge. Based on a\nhierarchical graph, we quantify forward discrepancy, a discrepancy in LLM\nperformance on simpler sub-problems versus complex questions. We also measure\nbackward discrepancy where LLMs answer complex questions but struggle with\nsimpler ones. Our analysis shows that smaller models exhibit more discrepancies\nthan larger models. Distinct patterns of discrepancies are observed across\nmodel capacity and possibility of training data memorization. Additionally,\nguiding models from simpler to complex questions through multi-turn\ninteractions improves performance across model sizes, highlighting the\nimportance of structured intermediate steps in knowledge reasoning. This work\nenhances our understanding of LLM reasoning and suggests ways to improve their\nproblem-solving abilities.",
    "categories": [
      "cs.CL",
      "cs.AI"
    ],
    "primary_category": "cs.CL",
    "comment": "published at EMNLP 2024; code is available at\n  https://github.com/kaistAI/knowledge-reasoning",
    "pdf_url": "http://arxiv.org/pdf/2406.19502v2",
    "published_date": "2024-06-27 19:29:36 UTC",
    "updated_date": "2024-10-03 20:55:21 UTC"
  },
  {
    "arxiv_id": "2406.19500v1",
    "title": "Knowledge acquisition for dialogue agents using reinforcement learning on graph representations",
    "authors": [
      "Selene Baez Santamaria",
      "Shihan Wang",
      "Piek Vossen"
    ],
    "abstract": "We develop an artificial agent motivated to augment its knowledge base beyond\nits initial training. The agent actively participates in dialogues with other\nagents, strategically acquiring new information. The agent models its knowledge\nas an RDF knowledge graph, integrating new beliefs acquired through\nconversation. Responses in dialogue are generated by identifying graph patterns\naround these new integrated beliefs. We show that policies can be learned using\nreinforcement learning to select effective graph patterns during an\ninteraction, without relying on explicit user feedback. Within this context,\nour study is a proof of concept for leveraging users as effective sources of\ninformation.",
    "categories": [
      "cs.AI",
      "cs.CL"
    ],
    "primary_category": "cs.AI",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2406.19500v1",
    "published_date": "2024-06-27 19:28:42 UTC",
    "updated_date": "2024-06-27 19:28:42 UTC"
  },
  {
    "arxiv_id": "2406.19497v1",
    "title": "Inclusivity in Large Language Models: Personality Traits and Gender Bias in Scientific Abstracts",
    "authors": [
      "Naseela Pervez",
      "Alexander J. Titus"
    ],
    "abstract": "Large language models (LLMs) are increasingly utilized to assist in\nscientific and academic writing, helping authors enhance the coherence of their\narticles. Previous studies have highlighted stereotypes and biases present in\nLLM outputs, emphasizing the need to evaluate these models for their alignment\nwith human narrative styles and potential gender biases. In this study, we\nassess the alignment of three prominent LLMs - Claude 3 Opus, Mistral AI Large,\nand Gemini 1.5 Flash - by analyzing their performance on benchmark\ntext-generation tasks for scientific abstracts. We employ the Linguistic\nInquiry and Word Count (LIWC) framework to extract lexical, psychological, and\nsocial features from the generated texts. Our findings indicate that, while\nthese models generally produce text closely resembling human authored content,\nvariations in stylistic features suggest significant gender biases. This\nresearch highlights the importance of developing LLMs that maintain a diversity\nof writing styles to promote inclusivity in academic discourse.",
    "categories": [
      "cs.CL",
      "cs.AI"
    ],
    "primary_category": "cs.CL",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2406.19497v1",
    "published_date": "2024-06-27 19:26:11 UTC",
    "updated_date": "2024-06-27 19:26:11 UTC"
  },
  {
    "arxiv_id": "2406.19493v2",
    "title": "Development and Evaluation of a Retrieval-Augmented Generation Tool for Creating SAPPhIRE Models of Artificial Systems",
    "authors": [
      "Anubhab Majumder",
      "Kausik Bhattacharya",
      "Amaresh Chakrabarti"
    ],
    "abstract": "Representing systems using the SAPPhIRE causality model is found useful in\nsupporting design-by-analogy. However, creating a SAPPhIRE model of artificial\nor biological systems is an effort-intensive process that requires human\nexperts to source technical knowledge from multiple technical documents\nregarding how the system works. This research investigates how to leverage\nLarge Language Models (LLMs) in creating structured descriptions of systems\nusing the SAPPhIRE model of causality. This paper, the second part of the\ntwo-part research, presents a new Retrieval-Augmented Generation (RAG) tool for\ngenerating information related to SAPPhIRE constructs of artificial systems and\nreports the results from a preliminary evaluation of the tool's success -\nfocusing on the factual accuracy and reliability of outcomes.",
    "categories": [
      "cs.CL",
      "cs.AI"
    ],
    "primary_category": "cs.CL",
    "comment": "This paper has been accepted for presentation at the 10th\n  International Conference on Research Into Design, 2025",
    "pdf_url": "http://arxiv.org/pdf/2406.19493v2",
    "published_date": "2024-06-27 19:20:09 UTC",
    "updated_date": "2024-10-27 11:28:07 UTC"
  },
  {
    "arxiv_id": "2406.19486v1",
    "title": "LoPT: Low-Rank Prompt Tuning for Parameter Efficient Language Models",
    "authors": [
      "Shouchang Guo",
      "Sonam Damani",
      "Keng-hao Chang"
    ],
    "abstract": "In prompt tuning, a prefix or suffix text is added to the prompt, and the\nembeddings (soft prompts) or token indices (hard prompts) of the prefix/suffix\nare optimized to gain more control over language models for specific tasks.\nThis approach eliminates the need for hand-crafted prompt engineering or\nexplicit model fine-tuning. Prompt tuning is significantly more\nparameter-efficient than model fine-tuning, as it involves optimizing partial\ninputs of language models to produce desired outputs.\n  In this work, we aim to further reduce the amount of trainable parameters\nrequired for a language model to perform well on specific tasks. We propose\nLow-rank Prompt Tuning (LoPT), a low-rank model for prompts that achieves\nefficient prompt optimization. The proposed method demonstrates similar\noutcomes to full parameter prompt tuning while reducing the number of trainable\nparameters by a factor of 5. It also provides promising results compared to the\nstate-of-the-art methods that would require 10 to 20 times more parameters.",
    "categories": [
      "cs.CL",
      "cs.AI",
      "cs.ET",
      "cs.LG",
      "eess.SP"
    ],
    "primary_category": "cs.CL",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2406.19486v1",
    "published_date": "2024-06-27 19:02:41 UTC",
    "updated_date": "2024-06-27 19:02:41 UTC"
  },
  {
    "arxiv_id": "2406.19478v1",
    "title": "Sparse Regression for Machine Translation",
    "authors": [
      "Ergun Bi√ßici"
    ],
    "abstract": "We use transductive regression techniques to learn mappings between source\nand target features of given parallel corpora and use these mappings to\ngenerate machine translation outputs. We show the effectiveness of $L_1$\nregularized regression (\\textit{lasso}) to learn the mappings between sparsely\nobserved feature sets versus $L_2$ regularized regression. Proper selection of\ntraining instances plays an important role to learn correct feature mappings\nwithin limited computational resources and at expected accuracy levels. We\nintroduce \\textit{dice} instance selection method for proper selection of\ntraining instances, which plays an important role to learn correct feature\nmappings for improving the source and target coverage of the training set. We\nshow that $L_1$ regularized regression performs better than $L_2$ regularized\nregression both in regression measurements and in the translation experiments\nusing graph decoding. We present encouraging results when translating from\nGerman to English and Spanish to English. We also demonstrate results when the\nphrase table of a phrase-based decoder is replaced with the mappings we find\nwith the regression model.",
    "categories": [
      "cs.CL",
      "cs.AI",
      "G.3; I.2.7"
    ],
    "primary_category": "cs.CL",
    "comment": "8 pages, 4 figures, 4 tables",
    "pdf_url": "http://arxiv.org/pdf/2406.19478v1",
    "published_date": "2024-06-27 18:43:51 UTC",
    "updated_date": "2024-06-27 18:43:51 UTC"
  },
  {
    "arxiv_id": "2406.19464v2",
    "title": "ManiWAV: Learning Robot Manipulation from In-the-Wild Audio-Visual Data",
    "authors": [
      "Zeyi Liu",
      "Cheng Chi",
      "Eric Cousineau",
      "Naveen Kuppuswamy",
      "Benjamin Burchfiel",
      "Shuran Song"
    ],
    "abstract": "Audio signals provide rich information for the robot interaction and object\nproperties through contact. This information can surprisingly ease the learning\nof contact-rich robot manipulation skills, especially when the visual\ninformation alone is ambiguous or incomplete. However, the usage of audio data\nin robot manipulation has been constrained to teleoperated demonstrations\ncollected by either attaching a microphone to the robot or object, which\nsignificantly limits its usage in robot learning pipelines. In this work, we\nintroduce ManiWAV: an 'ear-in-hand' data collection device to collect\nin-the-wild human demonstrations with synchronous audio and visual feedback,\nand a corresponding policy interface to learn robot manipulation policy\ndirectly from the demonstrations. We demonstrate the capabilities of our system\nthrough four contact-rich manipulation tasks that require either passively\nsensing the contact events and modes, or actively sensing the object surface\nmaterials and states. In addition, we show that our system can generalize to\nunseen in-the-wild environments by learning from diverse in-the-wild human\ndemonstrations.",
    "categories": [
      "cs.RO",
      "cs.AI",
      "cs.CV",
      "cs.SD",
      "eess.AS"
    ],
    "primary_category": "cs.RO",
    "comment": "Conference on Robot Learning (CoRL) 2024; Project website:\n  https://maniwav.github.io/",
    "pdf_url": "http://arxiv.org/pdf/2406.19464v2",
    "published_date": "2024-06-27 18:06:38 UTC",
    "updated_date": "2024-11-04 02:21:30 UTC"
  },
  {
    "arxiv_id": "2406.19434v1",
    "title": "Lightweight Predictive 3D Gaussian Splats",
    "authors": [
      "Junli Cao",
      "Vidit Goel",
      "Chaoyang Wang",
      "Anil Kag",
      "Ju Hu",
      "Sergei Korolev",
      "Chenfanfu Jiang",
      "Sergey Tulyakov",
      "Jian Ren"
    ],
    "abstract": "Recent approaches representing 3D objects and scenes using Gaussian splats\nshow increased rendering speed across a variety of platforms and devices. While\nrendering such representations is indeed extremely efficient, storing and\ntransmitting them is often prohibitively expensive. To represent large-scale\nscenes, one often needs to store millions of 3D Gaussians, occupying gigabytes\nof disk space. This poses a very practical limitation, prohibiting widespread\nadoption.Several solutions have been proposed to strike a balance between disk\nsize and rendering quality, noticeably reducing the visual quality. In this\nwork, we propose a new representation that dramatically reduces the hard drive\nfootprint while featuring similar or improved quality when compared to the\nstandard 3D Gaussian splats. When compared to other compact solutions, ours\noffers higher quality renderings with significantly reduced storage, being able\nto efficiently run on a mobile device in real-time. Our key observation is that\nnearby points in the scene can share similar representations. Hence, only a\nsmall ratio of 3D points needs to be stored. We introduce an approach to\nidentify such points which are called parent points. The discarded points\ncalled children points along with attributes can be efficiently predicted by\ntiny MLPs.",
    "categories": [
      "cs.GR",
      "cs.AI"
    ],
    "primary_category": "cs.GR",
    "comment": "Project Page: https://plumpuddings.github.io/LPGS//",
    "pdf_url": "http://arxiv.org/pdf/2406.19434v1",
    "published_date": "2024-06-27 17:59:05 UTC",
    "updated_date": "2024-06-27 17:59:05 UTC"
  },
  {
    "arxiv_id": "2407.12020v2",
    "title": "SignSpeak: Open-Source Time Series Classification for ASL Translation",
    "authors": [
      "Aditya Makkar",
      "Divya Makkar",
      "Aarav Patel",
      "Liam Hebert"
    ],
    "abstract": "The lack of fluency in sign language remains a barrier to seamless\ncommunication for hearing and speech-impaired communities. In this work, we\npropose a low-cost, real-time ASL-to-speech translation glove and an exhaustive\ntraining dataset of sign language patterns. We then benchmarked this dataset\nwith supervised learning models, such as LSTMs, GRUs and Transformers, where\nour best model achieved 92% accuracy. The SignSpeak dataset has 7200 samples\nencompassing 36 classes (A-Z, 1-10) and aims to capture realistic signing\npatterns by using five low-cost flex sensors to measure finger positions at\neach time step at 36 Hz. Our open-source dataset, models and glove designs,\nprovide an accurate and efficient ASL translator while maintaining\ncost-effectiveness, establishing a framework for future work to build on.",
    "categories": [
      "cs.CL",
      "cs.AI",
      "cs.LG"
    ],
    "primary_category": "cs.CL",
    "comment": "6 pages, 2 figures, NeurIPS",
    "pdf_url": "http://arxiv.org/pdf/2407.12020v2",
    "published_date": "2024-06-27 17:58:54 UTC",
    "updated_date": "2024-07-18 20:36:03 UTC"
  },
  {
    "arxiv_id": "2406.19384v1",
    "title": "The Remarkable Robustness of LLMs: Stages of Inference?",
    "authors": [
      "Vedang Lad",
      "Wes Gurnee",
      "Max Tegmark"
    ],
    "abstract": "We demonstrate and investigate the remarkable robustness of Large Language\nModels by deleting and swapping adjacent layers. We find that deleting and\nswapping interventions retain 72-95\\% of the original model's prediction\naccuracy without fine-tuning, whereas models with more layers exhibit more\nrobustness. Based on the results of the layer-wise intervention and further\nexperiments, we hypothesize the existence of four universal stages of inference\nacross eight different models: detokenization, feature engineering, prediction\nensembling, and residual sharpening. The first stage integrates local\ninformation, lifting raw token representations into higher-level contextual\nrepresentations. Next is the iterative refinement of task and entity-specific\nfeatures. Then, the second half of the model begins with a phase transition,\nwhere hidden representations align more with the vocabulary space due to\nspecialized model components. Finally, the last layer sharpens the following\ntoken distribution by eliminating obsolete features that add noise to the\nprediction.",
    "categories": [
      "cs.LG",
      "cs.AI",
      "cs.CL"
    ],
    "primary_category": "cs.LG",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2406.19384v1",
    "published_date": "2024-06-27 17:57:03 UTC",
    "updated_date": "2024-06-27 17:57:03 UTC"
  },
  {
    "arxiv_id": "2406.19370v4",
    "title": "Emergence of Hidden Capabilities: Exploring Learning Dynamics in Concept Space",
    "authors": [
      "Core Francisco Park",
      "Maya Okawa",
      "Andrew Lee",
      "Hidenori Tanaka",
      "Ekdeep Singh Lubana"
    ],
    "abstract": "Modern generative models demonstrate impressive capabilities, likely stemming\nfrom an ability to identify and manipulate abstract concepts underlying their\ntraining data. However, fundamental questions remain: what determines the\nconcepts a model learns, the order in which it learns them, and its ability to\nmanipulate those concepts? To address these questions, we propose analyzing a\nmodel's learning dynamics via a framework we call the concept space, where each\naxis represents an independent concept underlying the data generating process.\nBy characterizing learning dynamics in this space, we identify how the speed at\nwhich a concept is learned, and hence the order of concept learning, is\ncontrolled by properties of the data we term concept signal. Further, we\nobserve moments of sudden turns in the direction of a model's learning dynamics\nin concept space. Surprisingly, these points precisely correspond to the\nemergence of hidden capabilities, i.e., where latent interventions show the\nmodel possesses the capability to manipulate a concept, but these capabilities\ncannot yet be elicited via naive input prompting. While our results focus on\nsynthetically defined toy datasets, we hypothesize a general claim on emergence\nof hidden capabilities may hold: generative models possess latent capabilities\nthat emerge suddenly and consistently during training, though a model might not\nexhibit these capabilities under naive input prompting.",
    "categories": [
      "cs.LG",
      "cs.AI"
    ],
    "primary_category": "cs.LG",
    "comment": "NeurIPS 2024 (Spotlight)",
    "pdf_url": "http://arxiv.org/pdf/2406.19370v4",
    "published_date": "2024-06-27 17:50:05 UTC",
    "updated_date": "2024-12-11 07:53:57 UTC"
  },
  {
    "arxiv_id": "2407.00121v1",
    "title": "Granite-Function Calling Model: Introducing Function Calling Abilities via Multi-task Learning of Granular Tasks",
    "authors": [
      "Ibrahim Abdelaziz",
      "Kinjal Basu",
      "Mayank Agarwal",
      "Sadhana Kumaravel",
      "Matthew Stallone",
      "Rameswar Panda",
      "Yara Rizk",
      "GP Bhargav",
      "Maxwell Crouse",
      "Chulaka Gunasekara",
      "Shajith Ikbal",
      "Sachin Joshi",
      "Hima Karanam",
      "Vineet Kumar",
      "Asim Munawar",
      "Sumit Neelam",
      "Dinesh Raghu",
      "Udit Sharma",
      "Adriana Meza Soria",
      "Dheeraj Sreedhar",
      "Praveen Venkateswaran",
      "Merve Unuvar",
      "David Cox",
      "Salim Roukos",
      "Luis Lastras",
      "Pavan Kapanipathi"
    ],
    "abstract": "Large language models (LLMs) have recently shown tremendous promise in\nserving as the backbone to agentic systems, as demonstrated by their\nperformance in multi-faceted, challenging benchmarks like SWE-Bench and\nAgent-Bench. However, to realize the true potential of LLMs as autonomous\nagents, they must learn to identify, call, and interact with external tools and\napplication program interfaces (APIs) to complete complex tasks. These tasks\ntogether are termed function calling. Endowing LLMs with function calling\nabilities leads to a myriad of advantages, such as access to current and\ndomain-specific information in databases and knowledge sources, and the ability\nto outsource tasks that can be reliably performed by tools, e.g., a Python\ninterpreter or calculator. While there has been significant progress in\nfunction calling with LLMs, there is still a dearth of open models that perform\non par with proprietary LLMs like GPT, Claude, and Gemini. Therefore, in this\nwork, we introduce the GRANITE-20B-FUNCTIONCALLING model under an Apache 2.0\nlicense. The model is trained using a multi-task training approach on seven\nfundamental tasks encompassed in function calling, those being Nested Function\nCalling, Function Chaining, Parallel Functions, Function Name Detection,\nParameter-Value Pair Detection, Next-Best Function, and Response Generation. We\npresent a comprehensive evaluation on multiple out-of-domain datasets comparing\nGRANITE-20B-FUNCTIONCALLING to more than 15 other best proprietary and open\nmodels. GRANITE-20B-FUNCTIONCALLING provides the best performance among all\nopen models on the Berkeley Function Calling Leaderboard and fourth overall. As\na result of the diverse tasks and datasets used for training our model, we show\nthat GRANITE-20B-FUNCTIONCALLING has better generalizability on multiple tasks\nin seven different evaluation datasets.",
    "categories": [
      "cs.LG",
      "cs.AI",
      "cs.CL"
    ],
    "primary_category": "cs.LG",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2407.00121v1",
    "published_date": "2024-06-27 17:47:26 UTC",
    "updated_date": "2024-06-27 17:47:26 UTC"
  },
  {
    "arxiv_id": "2406.19354v1",
    "title": "Fundamental Problems With Model Editing: How Should Rational Belief Revision Work in LLMs?",
    "authors": [
      "Peter Hase",
      "Thomas Hofweber",
      "Xiang Zhou",
      "Elias Stengel-Eskin",
      "Mohit Bansal"
    ],
    "abstract": "The model editing problem concerns how language models should learn new facts\nabout the world over time. While empirical research on model editing has drawn\nwidespread attention, the conceptual foundations of model editing remain shaky\n-- perhaps unsurprisingly, since model editing is essentially belief revision,\na storied problem in philosophy that has eluded succinct solutions for decades.\nModel editing nonetheless demands a solution, since we need to be able to\ncontrol the knowledge within language models. With this goal in mind, this\npaper critiques the standard formulation of the model editing problem and\nproposes a formal testbed for model editing research. We first describe 12 open\nproblems with model editing, based on challenges with (1) defining the problem,\n(2) developing benchmarks, and (3) assuming LLMs have editable beliefs in the\nfirst place. Many of these challenges are extremely difficult to address, e.g.\ndetermining far-reaching consequences of edits, labeling probabilistic\nentailments between facts, and updating beliefs of agent simulators. Next, we\nintroduce a semi-synthetic dataset for model editing based on Wikidata, where\nwe can evaluate edits against labels given by an idealized Bayesian agent. This\nenables us to say exactly how belief revision in language models falls short of\na desirable epistemic standard. We encourage further research exploring\nsettings where such a gold standard can be compared against. Our code is\npublicly available at: https://github.com/peterbhase/LLM-belief-revision",
    "categories": [
      "cs.CL",
      "cs.AI"
    ],
    "primary_category": "cs.CL",
    "comment": "23 pages, 4 figures",
    "pdf_url": "http://arxiv.org/pdf/2406.19354v1",
    "published_date": "2024-06-27 17:33:03 UTC",
    "updated_date": "2024-06-27 17:33:03 UTC"
  },
  {
    "arxiv_id": "2406.19349v1",
    "title": "IndoToxic2024: A Demographically-Enriched Dataset of Hate Speech and Toxicity Types for Indonesian Language",
    "authors": [
      "Lucky Susanto",
      "Musa Izzanardi Wijanarko",
      "Prasetia Anugrah Pratama",
      "Traci Hong",
      "Ika Idris",
      "Alham Fikri Aji",
      "Derry Wijaya"
    ],
    "abstract": "Hate speech poses a significant threat to social harmony. Over the past two\nyears, Indonesia has seen a ten-fold increase in the online hate speech ratio,\nunderscoring the urgent need for effective detection mechanisms. However,\nprogress is hindered by the limited availability of labeled data for Indonesian\ntexts. The condition is even worse for marginalized minorities, such as Shia,\nLGBTQ, and other ethnic minorities because hate speech is underreported and\nless understood by detection tools. Furthermore, the lack of accommodation for\nsubjectivity in current datasets compounds this issue. To address this, we\nintroduce IndoToxic2024, a comprehensive Indonesian hate speech and toxicity\nclassification dataset. Comprising 43,692 entries annotated by 19 diverse\nindividuals, the dataset focuses on texts targeting vulnerable groups in\nIndonesia, specifically during the hottest political event in the country: the\npresidential election. We establish baselines for seven binary classification\ntasks, achieving a macro-F1 score of 0.78 with a BERT model (IndoBERTweet)\nfine-tuned for hate speech classification. Furthermore, we demonstrate how\nincorporating demographic information can enhance the zero-shot performance of\nthe large language model, gpt-3.5-turbo. However, we also caution that an\noveremphasis on demographic information can negatively impact the fine-tuned\nmodel performance due to data fragmentation.",
    "categories": [
      "cs.CL",
      "cs.AI"
    ],
    "primary_category": "cs.CL",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2406.19349v1",
    "published_date": "2024-06-27 17:26:38 UTC",
    "updated_date": "2024-06-27 17:26:38 UTC"
  },
  {
    "arxiv_id": "2407.09551v1",
    "title": "Diminishing Stereotype Bias in Image Generation Model using Reinforcemenlent Learning Feedback",
    "authors": [
      "Xin Chen",
      "Virgile Foussereau"
    ],
    "abstract": "This study addresses gender bias in image generation models using\nReinforcement Learning from Artificial Intelligence Feedback (RLAIF) with a\nnovel Denoising Diffusion Policy Optimization (DDPO) pipeline. By employing a\npretrained stable diffusion model and a highly accurate gender classification\nTransformer, the research introduces two reward functions: Rshift for shifting\ngender imbalances, and Rbalance for achieving and maintaining gender balance.\nExperiments demonstrate the effectiveness of this approach in mitigating bias\nwithout compromising image quality or requiring additional data or prompt\nmodifications. While focusing on gender bias, this work establishes a\nfoundation for addressing various forms of bias in AI systems, emphasizing the\nneed for responsible AI development. Future research directions include\nextending the methodology to other bias types, enhancing the RLAIF pipeline's\nrobustness, and exploring multi-prompt fine-tuning to further advance fairness\nand inclusivity in AI.",
    "categories": [
      "cs.CV",
      "cs.AI",
      "cs.LG"
    ],
    "primary_category": "cs.CV",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2407.09551v1",
    "published_date": "2024-06-27 17:18:58 UTC",
    "updated_date": "2024-06-27 17:18:58 UTC"
  },
  {
    "arxiv_id": "2406.19320v1",
    "title": "Efficient World Models with Context-Aware Tokenization",
    "authors": [
      "Vincent Micheli",
      "Eloi Alonso",
      "Fran√ßois Fleuret"
    ],
    "abstract": "Scaling up deep Reinforcement Learning (RL) methods presents a significant\nchallenge. Following developments in generative modelling, model-based RL\npositions itself as a strong contender. Recent advances in sequence modelling\nhave led to effective transformer-based world models, albeit at the price of\nheavy computations due to the long sequences of tokens required to accurately\nsimulate environments. In this work, we propose $\\Delta$-IRIS, a new agent with\na world model architecture composed of a discrete autoencoder that encodes\nstochastic deltas between time steps and an autoregressive transformer that\npredicts future deltas by summarizing the current state of the world with\ncontinuous tokens. In the Crafter benchmark, $\\Delta$-IRIS sets a new state of\nthe art at multiple frame budgets, while being an order of magnitude faster to\ntrain than previous attention-based approaches. We release our code and models\nat https://github.com/vmicheli/delta-iris.",
    "categories": [
      "cs.LG",
      "cs.AI",
      "cs.CV"
    ],
    "primary_category": "cs.LG",
    "comment": "ICML 2024",
    "pdf_url": "http://arxiv.org/pdf/2406.19320v1",
    "published_date": "2024-06-27 16:54:12 UTC",
    "updated_date": "2024-06-27 16:54:12 UTC"
  },
  {
    "arxiv_id": "2406.19317v2",
    "title": "Jump Starting Bandits with LLM-Generated Prior Knowledge",
    "authors": [
      "Parand A. Alamdari",
      "Yanshuai Cao",
      "Kevin H. Wilson"
    ],
    "abstract": "We present substantial evidence demonstrating the benefits of integrating\nLarge Language Models (LLMs) with a Contextual Multi-Armed Bandit framework.\nContextual bandits have been widely used in recommendation systems to generate\npersonalized suggestions based on user-specific contexts. We show that LLMs,\npre-trained on extensive corpora rich in human knowledge and preferences, can\nsimulate human behaviours well enough to jump-start contextual multi-armed\nbandits to reduce online learning regret. We propose an initialization\nalgorithm for contextual bandits by prompting LLMs to produce a pre-training\ndataset of approximate human preferences for the bandit. This significantly\nreduces online learning regret and data-gathering costs for training such\nmodels. Our approach is validated empirically through two sets of experiments\nwith different bandit setups: one which utilizes LLMs to serve as an oracle and\na real-world experiment utilizing data from a conjoint survey experiment.",
    "categories": [
      "cs.LG",
      "cs.AI",
      "cs.CL"
    ],
    "primary_category": "cs.LG",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2406.19317v2",
    "published_date": "2024-06-27 16:52:19 UTC",
    "updated_date": "2024-10-29 02:42:20 UTC"
  },
  {
    "arxiv_id": "2407.00120v1",
    "title": "Automated Web-Based Malaria Detection System with Machine Learning and Deep Learning Techniques",
    "authors": [
      "Abraham G Taye",
      "Sador Yemane",
      "Eshetu Negash",
      "Yared Minwuyelet",
      "Moges Abebe",
      "Melkamu Hunegnaw Asmare"
    ],
    "abstract": "Malaria parasites pose a significant global health burden, causing widespread\nsuffering and mortality. Detecting malaria infection accurately is crucial for\neffective treatment and control. However, existing automated detection\ntechniques have shown limitations in terms of accuracy and generalizability.\nMany studies have focused on specific features without exploring more\ncomprehensive approaches. In our case, we formulate a deep learning technique\nfor malaria-infected cell classification using traditional CNNs and transfer\nlearning models notably VGG19, InceptionV3, and Xception. The models were\ntrained using NIH datasets and tested using different performance metrics such\nas accuracy, precision, recall, and F1-score. The test results showed that deep\nCNNs achieved the highest accuracy -- 97%, followed by Xception with an\naccuracy of 95%. A machine learning model SVM achieved an accuracy of 83%,\nwhile an Inception-V3 achieved an accuracy of 94%. Furthermore, the system can\nbe accessed through a web interface, where users can upload blood smear images\nfor malaria detection.",
    "categories": [
      "cs.CV",
      "cs.AI",
      "cs.LG",
      "eess.IV"
    ],
    "primary_category": "cs.CV",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2407.00120v1",
    "published_date": "2024-06-27 16:50:36 UTC",
    "updated_date": "2024-06-27 16:50:36 UTC"
  },
  {
    "arxiv_id": "2406.19314v2",
    "title": "LiveBench: A Challenging, Contamination-Limited LLM Benchmark",
    "authors": [
      "Colin White",
      "Samuel Dooley",
      "Manley Roberts",
      "Arka Pal",
      "Ben Feuer",
      "Siddhartha Jain",
      "Ravid Shwartz-Ziv",
      "Neel Jain",
      "Khalid Saifullah",
      "Sreemanti Dey",
      "Shubh-Agrawal",
      "Sandeep Singh Sandha",
      "Siddartha Naidu",
      "Chinmay Hegde",
      "Yann LeCun",
      "Tom Goldstein",
      "Willie Neiswanger",
      "Micah Goldblum"
    ],
    "abstract": "Test set contamination, wherein test data from a benchmark ends up in a newer\nmodel's training set, is a well-documented obstacle for fair LLM evaluation and\ncan quickly render benchmarks obsolete. To mitigate this, many recent\nbenchmarks crowdsource new prompts and evaluations from human or LLM judges;\nhowever, these can introduce significant biases, and break down when scoring\nhard questions. In this work, we introduce a new benchmark for LLMs designed to\nbe resistant to both test set contamination and the pitfalls of LLM judging and\nhuman crowdsourcing. We release LiveBench, the first benchmark that (1)\ncontains frequently-updated questions from recent information sources, (2)\nscores answers automatically according to objective ground-truth values, and\n(3) contains a wide variety of challenging tasks, spanning math, coding,\nreasoning, language, instruction following, and data analysis. To achieve this,\nLiveBench contains questions that are based on recently-released math\ncompetitions, arXiv papers, news articles, and datasets, and it contains\nharder, contamination-limited versions of tasks from previous benchmarks such\nas Big-Bench Hard, AMPS, and IFEval. We evaluate many prominent closed-source\nmodels, as well as dozens of open-source models ranging from 0.5B to 405B in\nsize. LiveBench is difficult, with top models achieving below 70% accuracy. We\nrelease all questions, code, and model answers. Questions are added and updated\non a monthly basis, and we release new tasks and harder versions of tasks over\ntime so that LiveBench can distinguish between the capabilities of LLMs as they\nimprove in the future. We welcome community engagement and collaboration for\nexpanding the benchmark tasks and models.",
    "categories": [
      "cs.CL",
      "cs.AI",
      "cs.LG"
    ],
    "primary_category": "cs.CL",
    "comment": "ICLR 2025 Spotlight",
    "pdf_url": "http://arxiv.org/pdf/2406.19314v2",
    "published_date": "2024-06-27 16:47:42 UTC",
    "updated_date": "2025-04-18 19:36:00 UTC"
  },
  {
    "arxiv_id": "2406.19292v2",
    "title": "From Artificial Needles to Real Haystacks: Improving Retrieval Capabilities in LLMs by Finetuning on Synthetic Data",
    "authors": [
      "Zheyang Xiong",
      "Vasilis Papageorgiou",
      "Kangwook Lee",
      "Dimitris Papailiopoulos"
    ],
    "abstract": "Recent studies have shown that Large Language Models (LLMs) struggle to\naccurately retrieve information and maintain reasoning capabilities when\nprocessing long-context inputs. To address these limitations, we propose a\nfinetuning approach utilizing a carefully designed synthetic dataset comprising\nnumerical key-value retrieval tasks. Our experiments on models like GPT-3.5\nTurbo and Mistral 7B demonstrate that finetuning LLMs on this dataset\nsignificantly improves LLMs' information retrieval and reasoning capabilities\nin longer-context settings. We present an analysis of the finetuned models,\nillustrating the transfer of skills from synthetic to real task evaluations\n(e.g., $10.5\\%$ improvement on $20$ documents MDQA at position $10$ for GPT-3.5\nTurbo). We also find that finetuned LLMs' performance on general benchmarks\nremains almost constant while LLMs finetuned on other baseline long-context\naugmentation data can encourage hallucination (e.g., on TriviaQA, Mistral 7B\nfinetuned on our synthetic data cause no performance drop while other baseline\ndata can cause a drop that ranges from $2.33\\%$ to $6.19\\%$). Our study\nhighlights the potential of finetuning on synthetic data for improving the\nperformance of LLMs on longer-context tasks.",
    "categories": [
      "cs.LG",
      "cs.AI",
      "cs.CL"
    ],
    "primary_category": "cs.LG",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2406.19292v2",
    "published_date": "2024-06-27 16:05:13 UTC",
    "updated_date": "2024-10-14 02:58:42 UTC"
  },
  {
    "arxiv_id": "2407.00119v2",
    "title": "Efficient Long-distance Latent Relation-aware Graph Neural Network for Multi-modal Emotion Recognition in Conversations",
    "authors": [
      "Yuntao Shou",
      "Wei Ai",
      "Jiayi Du",
      "Tao Meng",
      "Haiyan Liu",
      "Nan Yin"
    ],
    "abstract": "The task of multi-modal emotion recognition in conversation (MERC) aims to\nanalyze the genuine emotional state of each utterance based on the multi-modal\ninformation in the conversation, which is crucial for conversation\nunderstanding. Existing methods focus on using graph neural networks (GNN) to\nmodel conversational relationships and capture contextual latent semantic\nrelationships. However, due to the complexity of GNN, existing methods cannot\nefficiently capture the potential dependencies between long-distance\nutterances, which limits the performance of MERC. In this paper, we propose an\nEfficient Long-distance Latent Relation-aware Graph Neural Network (ELR-GNN)\nfor multi-modal emotion recognition in conversations. Specifically, we first\nuse pre-extracted text, video and audio features as input to Bi-LSTM to capture\ncontextual semantic information and obtain low-level utterance features. Then,\nwe use low-level utterance features to construct a conversational emotion\ninteraction graph. To efficiently capture the potential dependencies between\nlong-distance utterances, we use the dilated generalized forward push algorithm\nto precompute the emotional propagation between global utterances and design an\nemotional relation-aware operator to capture the potential semantic\nassociations between different utterances. Furthermore, we combine early fusion\nand adaptive late fusion mechanisms to fuse latent dependency information\nbetween speaker relationship information and context. Finally, we obtain\nhigh-level discourse features and feed them into MLP for emotion prediction.\nExtensive experimental results show that ELR-GNN achieves state-of-the-art\nperformance on the benchmark datasets IEMOCAP and MELD, with running times\nreduced by 52\\% and 35\\%, respectively.",
    "categories": [
      "cs.LG",
      "cs.AI",
      "cs.CL"
    ],
    "primary_category": "cs.LG",
    "comment": "11 pages, 3 tables",
    "pdf_url": "http://arxiv.org/pdf/2407.00119v2",
    "published_date": "2024-06-27 15:54:12 UTC",
    "updated_date": "2024-08-31 12:44:38 UTC"
  },
  {
    "arxiv_id": "2406.19280v4",
    "title": "HuatuoGPT-Vision, Towards Injecting Medical Visual Knowledge into Multimodal LLMs at Scale",
    "authors": [
      "Junying Chen",
      "Chi Gui",
      "Ruyi Ouyang",
      "Anningzhe Gao",
      "Shunian Chen",
      "Guiming Hardy Chen",
      "Xidong Wang",
      "Ruifei Zhang",
      "Zhenyang Cai",
      "Ke Ji",
      "Guangjun Yu",
      "Xiang Wan",
      "Benyou Wang"
    ],
    "abstract": "The rapid development of multimodal large language models (MLLMs), such as\nGPT-4V, has led to significant advancements. However, these models still face\nchallenges in medical multimodal capabilities due to limitations in the\nquantity and quality of medical vision-text data, stemming from data privacy\nconcerns and high annotation costs. While pioneering approaches utilize\nPubMed's large-scale, de-identified medical image-text pairs to address these\nlimitations, they still fall short due to inherent data noise. To tackle this,\nwe refined medical image-text pairs from PubMed and employed MLLMs (GPT-4V) in\nan 'unblinded' capacity to denoise and reformat the data, resulting in the\ncreation of the PubMedVision dataset with 1.3 million medical VQA samples. Our\nvalidation demonstrates that: (1) PubMedVision can significantly enhance the\nmedical multimodal capabilities of current MLLMs, showing significant\nimprovement in benchmarks including the MMMU Health & Medicine track; (2)\nmanual checks by medical experts and empirical results validate the superior\ndata quality of our dataset compared to other data construction methods. Using\nPubMedVision, we train a 34B medical MLLM HuatuoGPT-Vision, which shows\nsuperior performance in medical multimodal scenarios among open-source MLLMs.",
    "categories": [
      "cs.CV",
      "cs.AI",
      "cs.CL",
      "cs.LG"
    ],
    "primary_category": "cs.CV",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2406.19280v4",
    "published_date": "2024-06-27 15:50:41 UTC",
    "updated_date": "2024-09-30 06:45:16 UTC"
  },
  {
    "arxiv_id": "2406.19271v2",
    "title": "AutoPureData: Automated Filtering of Undesirable Web Data to Update LLM Knowledge",
    "authors": [
      "Praneeth Vadlapati"
    ],
    "abstract": "Up-to-date and reliable language models are consistently sought after and are\nessential in various applications. Typically, models are trained on a fixed\ndataset and then deployed globally. However, the knowledge of the models\nbecomes outdated. Enabling automatic updation of AI knowledge using web data\ninvolves significant concerns regarding the model's safety and quality due to a\nthreat from unsafe and undesirable text across the web. The purity of new data\nwas essential for updating knowledge of language models to maintain their\nreliability. This paper proposes AutoPureData, a system that automatically\ncollects and purifies web data. The system loaded a sample of web data.\nUtilizing existing trusted AI models, it successfully eliminated unsafe text\nwith an accuracy of 97% and undesirable text with an accuracy of 86%,\ndemonstrating the system's effectiveness in purifying the data. The system\nensures that only meaningful and safe text can be used to update LLM knowledge.\nThe pure text was then optimized and stored in a vector database for future\nquerying. It was found that LLM can fetch new data from the vector DB. The LLM\nwrites the RAG query in English, even if the user's query is in another\nlanguage, proving that the system can perform cross-lingual retrieval. This\npaper proposes a method to maintain the accuracy and relevance of up-to-date\nlanguage models by ensuring that only purified data was used to update LLM\nknowledge. This work contributes to updating knowledge of chatbots using\nmeaningful and safe text, enhancing their utility across various industries,\nand potentially reducing the risks associated with outputs caused by unsafe or\nimpure data. Code is available at github.com/Pro-GenAI/AutoPureData.",
    "categories": [
      "cs.CL",
      "cs.AI",
      "cs.IR"
    ],
    "primary_category": "cs.CL",
    "comment": "Final version",
    "pdf_url": "http://arxiv.org/pdf/2406.19271v2",
    "published_date": "2024-06-27 15:37:57 UTC",
    "updated_date": "2025-02-27 07:17:52 UTC"
  },
  {
    "arxiv_id": "2407.00118v1",
    "title": "From Efficient Multimodal Models to World Models: A Survey",
    "authors": [
      "Xinji Mai",
      "Zeng Tao",
      "Junxiong Lin",
      "Haoran Wang",
      "Yang Chang",
      "Yanlan Kang",
      "Yan Wang",
      "Wenqiang Zhang"
    ],
    "abstract": "Multimodal Large Models (MLMs) are becoming a significant research focus,\ncombining powerful large language models with multimodal learning to perform\ncomplex tasks across different data modalities. This review explores the latest\ndevelopments and challenges in MLMs, emphasizing their potential in achieving\nartificial general intelligence and as a pathway to world models. We provide an\noverview of key techniques such as Multimodal Chain of Thought (M-COT),\nMultimodal Instruction Tuning (M-IT), and Multimodal In-Context Learning\n(M-ICL). Additionally, we discuss both the fundamental and specific\ntechnologies of multimodal models, highlighting their applications,\ninput/output modalities, and design characteristics. Despite significant\nadvancements, the development of a unified multimodal model remains elusive. We\ndiscuss the integration of 3D generation and embodied intelligence to enhance\nworld simulation capabilities and propose incorporating external rule systems\nfor improved reasoning and decision-making. Finally, we outline future research\ndirections to address these challenges and advance the field.",
    "categories": [
      "cs.LG",
      "cs.AI"
    ],
    "primary_category": "cs.LG",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2407.00118v1",
    "published_date": "2024-06-27 15:36:43 UTC",
    "updated_date": "2024-06-27 15:36:43 UTC"
  },
  {
    "arxiv_id": "2406.19261v2",
    "title": "Commodification of Compute",
    "authors": [
      "Jesper Kristensen",
      "David Wender",
      "Carl Anthony"
    ],
    "abstract": "The rapid advancements in artificial intelligence, big data analytics, and\ncloud computing have precipitated an unprecedented demand for computational\nresources. However, the current landscape of computational resource allocation\nis characterized by significant inefficiencies, including underutilization and\nprice volatility. This paper addresses these challenges by introducing a novel\nglobal platform for the commodification of compute hours, termed the Global\nCompute Exchange (GCX) (Patent Pending). The GCX leverages blockchain\ntechnology and smart contracts to create a secure, transparent, and efficient\nmarketplace for buying and selling computational power. The GCX is built in a\nlayered fashion, comprising Market, App, Clearing, Risk Management, Exchange\n(Offchain), and Blockchain (Onchain) layers, each ensuring a robust and\nefficient operation. This platform aims to revolutionize the computational\nresource market by fostering a decentralized, efficient, and transparent\necosystem that ensures equitable access to computing power, stimulates\ninnovation, and supports diverse user needs on a global scale. By transforming\ncompute hours into a tradable commodity, the GCX seeks to optimize resource\nutilization, stabilize pricing, and democratize access to computational\nresources. This paper explores the technological infrastructure, market\npotential, and societal impact of the GCX, positioning it as a pioneering\nsolution poised to drive the next wave of innovation in commodities and\ncompute.",
    "categories": [
      "cs.CE",
      "cs.AI",
      "cs.CY",
      "cs.ET",
      "econ.GN",
      "q-fin.EC"
    ],
    "primary_category": "cs.CE",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2406.19261v2",
    "published_date": "2024-06-27 15:32:31 UTC",
    "updated_date": "2024-07-03 16:12:32 UTC"
  },
  {
    "arxiv_id": "2406.19256v2",
    "title": "AI Data Readiness Inspector (AIDRIN) for Quantitative Assessment of Data Readiness for AI",
    "authors": [
      "Kaveen Hiniduma",
      "Suren Byna",
      "Jean Luca Bez",
      "Ravi Madduri"
    ],
    "abstract": "\"Garbage In Garbage Out\" is a universally agreed quote by computer scientists\nfrom various domains, including Artificial Intelligence (AI). As data is the\nfuel for AI, models trained on low-quality, biased data are often ineffective.\nComputer scientists who use AI invest a considerable amount of time and effort\nin preparing the data for AI. However, there are no standard methods or\nframeworks for assessing the \"readiness\" of data for AI. To provide a\nquantifiable assessment of the readiness of data for AI processes, we define\nparameters of AI data readiness and introduce AIDRIN (AI Data Readiness\nInspector). AIDRIN is a framework covering a broad range of readiness\ndimensions available in the literature that aid in evaluating the readiness of\ndata quantitatively and qualitatively. AIDRIN uses metrics in traditional data\nquality assessment such as completeness, outliers, and duplicates for data\nevaluation. Furthermore, AIDRIN uses metrics specific to assess data for AI,\nsuch as feature importance, feature correlations, class imbalance, fairness,\nprivacy, and FAIR (Findability, Accessibility, Interoperability, and\nReusability) principle compliance. AIDRIN provides visualizations and reports\nto assist data scientists in further investigating the readiness of data. The\nAIDRIN framework enhances the efficiency of the machine learning pipeline to\nmake informed decisions on data readiness for AI applications.",
    "categories": [
      "cs.AI"
    ],
    "primary_category": "cs.AI",
    "comment": "12 pages, 9 figures, Accepted to SSDBM 2024",
    "pdf_url": "http://arxiv.org/pdf/2406.19256v2",
    "published_date": "2024-06-27 15:26:39 UTC",
    "updated_date": "2025-03-11 15:58:48 UTC"
  },
  {
    "arxiv_id": "2407.12019v1",
    "title": "DIM: Dynamic Integration of Multimodal Entity Linking with Large Language Model",
    "authors": [
      "Shezheng Song",
      "Shasha Li",
      "Jie Yu",
      "Shan Zhao",
      "Xiaopeng Li",
      "Jun Ma",
      "Xiaodong Liu",
      "Zhuo Li",
      "Xiaoguang Mao"
    ],
    "abstract": "Our study delves into Multimodal Entity Linking, aligning the mention in\nmultimodal information with entities in knowledge base. Existing methods are\nstill facing challenges like ambiguous entity representations and limited image\ninformation utilization. Thus, we propose dynamic entity extraction using\nChatGPT, which dynamically extracts entities and enhances datasets. We also\npropose a method: Dynamically Integrate Multimodal information with knowledge\nbase (DIM), employing the capability of the Large Language Model (LLM) for\nvisual understanding. The LLM, such as BLIP-2, extracts information relevant to\nentities in the image, which can facilitate improved extraction of entity\nfeatures and linking them with the dynamic entity representations provided by\nChatGPT. The experiments demonstrate that our proposed DIM method outperforms\nthe majority of existing methods on the three original datasets, and achieves\nstate-of-the-art (SOTA) on the dynamically enhanced datasets (Wiki+, Rich+,\nDiverse+). For reproducibility, our code and collected datasets are released on\n\\url{https://github.com/season1blue/DIM}.",
    "categories": [
      "cs.CL",
      "cs.AI"
    ],
    "primary_category": "cs.CL",
    "comment": "Published on PRCV24",
    "pdf_url": "http://arxiv.org/pdf/2407.12019v1",
    "published_date": "2024-06-27 15:18:23 UTC",
    "updated_date": "2024-06-27 15:18:23 UTC"
  },
  {
    "arxiv_id": "2406.19251v1",
    "title": "AutoRAG-HP: Automatic Online Hyper-Parameter Tuning for Retrieval-Augmented Generation",
    "authors": [
      "Jia Fu",
      "Xiaoting Qin",
      "Fangkai Yang",
      "Lu Wang",
      "Jue Zhang",
      "Qingwei Lin",
      "Yubo Chen",
      "Dongmei Zhang",
      "Saravan Rajmohan",
      "Qi Zhang"
    ],
    "abstract": "Recent advancements in Large Language Models have transformed ML/AI\ndevelopment, necessitating a reevaluation of AutoML principles for the\nRetrieval-Augmented Generation (RAG) systems. To address the challenges of\nhyper-parameter optimization and online adaptation in RAG, we propose the\nAutoRAG-HP framework, which formulates the hyper-parameter tuning as an online\nmulti-armed bandit (MAB) problem and introduces a novel two-level Hierarchical\nMAB (Hier-MAB) method for efficient exploration of large search spaces. We\nconduct extensive experiments on tuning hyper-parameters, such as top-k\nretrieved documents, prompt compression ratio, and embedding methods, using the\nALCE-ASQA and Natural Questions datasets. Our evaluation from jointly\noptimization all three hyper-parameters demonstrate that MAB-based online\nlearning methods can achieve Recall@5 $\\approx 0.8$ for scenarios with\nprominent gradients in search space, using only $\\sim20\\%$ of the LLM API calls\nrequired by the Grid Search approach. Additionally, the proposed Hier-MAB\napproach outperforms other baselines in more challenging optimization\nscenarios. The code will be made available at https://aka.ms/autorag.",
    "categories": [
      "cs.CL",
      "cs.AI"
    ],
    "primary_category": "cs.CL",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2406.19251v1",
    "published_date": "2024-06-27 15:18:21 UTC",
    "updated_date": "2024-06-27 15:18:21 UTC"
  },
  {
    "arxiv_id": "2407.08752v1",
    "title": "From Modular to End-to-End Speaker Diarization",
    "authors": [
      "Federico Landini"
    ],
    "abstract": "Speaker diarization is usually referred to as the task that determines ``who\nspoke when'' in a recording. Until a few years ago, all competitive approaches\nwere modular. Systems based on this framework reached state-of-the-art\nperformance in most scenarios but had major difficulties dealing with\noverlapped speech. More recently, the advent of end-to-end models, capable of\ndealing with all aspects of speaker diarization with a single model and better\nperforming regarding overlapped speech, has brought high levels of attention.\n  This thesis is framed during a period of co-existence of these two trends. We\ndescribe a system based on a Bayesian hidden Markov model used to cluster\nx-vectors (speaker embeddings obtained with a neural network), known as VBx,\nwhich has shown remarkable performance on different datasets and challenges. We\ncomment on its advantages and limitations and evaluate results on different\nrelevant corpora. Then, we move towards end-to-end neural diarization (EEND)\nmethods. Due to the need for large training sets for training these models and\nthe lack of manually annotated diarization data in sufficient quantities, the\ncompromise solution consists in generating training data artificially. We\ndescribe an approach for generating synthetic data which resembles real\nconversations in terms of speaker turns and overlaps. We show how this method\ngenerating ``simulated conversations'' allows for better performance than using\na previously proposed method for creating ``simulated mixtures'' when training\nthe popular EEND with encoder-decoder attractors (EEND-EDA). We also propose a\nnew EEND-based model, which we call DiaPer, and show that it can perform better\nthan EEND-EDA, especially when dealing with many speakers and handling\noverlapped speech. Finally, we compare both VBx-based and DiaPer systems on a\nwide variety of corpora and comment on the advantages of each technique.",
    "categories": [
      "eess.AS",
      "cs.AI",
      "cs.SD"
    ],
    "primary_category": "eess.AS",
    "comment": "Ph.D. thesis. Successfully defended on 27.06.2024",
    "pdf_url": "http://arxiv.org/pdf/2407.08752v1",
    "published_date": "2024-06-27 15:09:39 UTC",
    "updated_date": "2024-06-27 15:09:39 UTC"
  },
  {
    "arxiv_id": "2406.19243v1",
    "title": "Application of ASV for Voice Identification after VC and Duration Predictor Improvement in TTS Models",
    "authors": [
      "Borodin Kirill Nikolayevich",
      "Kudryavtsev Vasiliy Dmitrievich",
      "Mkrtchian Grach Maratovich",
      "Gorodnichev Mikhail Genadievich",
      "Korzh Dmitrii Sergeevich"
    ],
    "abstract": "One of the most crucial components in the field of biometric security is the\nautomatic speaker verification system, which is based on the speaker's voice.\nIt is possible to utilise ASVs in isolation or in conjunction with other AI\nmodels. In the contemporary era, the quality and quantity of neural networks\nare increasing exponentially. Concurrently, there is a growing number of\nsystems that aim to manipulate data through the use of voice conversion and\ntext-to-speech models. The field of voice biometrics forgery is aided by a\nnumber of challenges, including SSTC, ASVSpoof, and SingFake.\n  This paper presents a system for automatic speaker verification. The primary\nobjective of our model is the extraction of embeddings from the target\nspeaker's audio in order to obtain information about important characteristics\nof his voice, such as pitch, energy, and the duration of phonemes. This\ninformation is used in our multivoice TTS pipeline, which is currently under\ndevelopment. However, this model was employed within the SSTC challenge to\nverify users whose voice had undergone voice conversion, where it demonstrated\nan EER of 20.669.",
    "categories": [
      "cs.SD",
      "cs.AI",
      "eess.AS"
    ],
    "primary_category": "cs.SD",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2406.19243v1",
    "published_date": "2024-06-27 15:08:51 UTC",
    "updated_date": "2024-06-27 15:08:51 UTC"
  },
  {
    "arxiv_id": "2406.19236v3",
    "title": "Human-Aware Vision-and-Language Navigation: Bridging Simulation to Reality with Dynamic Human Interactions",
    "authors": [
      "Heng Li",
      "Minghan Li",
      "Zhi-Qi Cheng",
      "Yifei Dong",
      "Yuxuan Zhou",
      "Jun-Yan He",
      "Qi Dai",
      "Teruko Mitamura",
      "Alexander G. Hauptmann"
    ],
    "abstract": "Vision-and-Language Navigation (VLN) aims to develop embodied agents that\nnavigate based on human instructions. However, current VLN frameworks often\nrely on static environments and optimal expert supervision, limiting their\nreal-world applicability. To address this, we introduce Human-Aware\nVision-and-Language Navigation (HA-VLN), extending traditional VLN by\nincorporating dynamic human activities and relaxing key assumptions. We propose\nthe Human-Aware 3D (HA3D) simulator, which combines dynamic human activities\nwith the Matterport3D dataset, and the Human-Aware Room-to-Room (HA-R2R)\ndataset, extending R2R with human activity descriptions. To tackle HA-VLN\nchallenges, we present the Expert-Supervised Cross-Modal (VLN-CM) and\nNon-Expert-Supervised Decision Transformer (VLN-DT) agents, utilizing\ncross-modal fusion and diverse training strategies for effective navigation in\ndynamic human environments. A comprehensive evaluation, including metrics\nconsidering human activities, and systematic analysis of HA-VLN's unique\nchallenges, underscores the need for further research to enhance HA-VLN agents'\nreal-world robustness and adaptability. Ultimately, this work provides\nbenchmarks and insights for future research on embodied AI and Sim2Real\ntransfer, paving the way for more realistic and applicable VLN systems in\nhuman-populated environments.",
    "categories": [
      "cs.AI",
      "cs.CV",
      "cs.RO"
    ],
    "primary_category": "cs.AI",
    "comment": "Spotlight at NeurIPS 2024 D&B Track. 32 pages, 18 figures, Project\n  Page: https://lpercc.github.io/HA3D_simulator/",
    "pdf_url": "http://arxiv.org/pdf/2406.19236v3",
    "published_date": "2024-06-27 15:01:42 UTC",
    "updated_date": "2024-11-02 02:14:09 UTC"
  },
  {
    "arxiv_id": "2406.19234v2",
    "title": "Generating Is Believing: Membership Inference Attacks against Retrieval-Augmented Generation",
    "authors": [
      "Yuying Li",
      "Gaoyang Liu",
      "Chen Wang",
      "Yang Yang"
    ],
    "abstract": "Retrieval-Augmented Generation (RAG) is a state-of-the-art technique that\nmitigates issues such as hallucinations and knowledge staleness in Large\nLanguage Models (LLMs) by retrieving relevant knowledge from an external\ndatabase to assist in content generation. Existing research has demonstrated\npotential privacy risks associated with the LLMs of RAG. However, the privacy\nrisks posed by the integration of an external database, which often contains\nsensitive data such as medical records or personal identities, have remained\nlargely unexplored. In this paper, we aim to bridge this gap by focusing on\nmembership privacy of RAG's external database, with the aim of determining\nwhether a given sample is part of the RAG's database. Our basic idea is that if\na sample is in the external database, it will exhibit a high degree of semantic\nsimilarity to the text generated by the RAG system. We present S$^2$MIA, a\n\\underline{M}embership \\underline{I}nference \\underline{A}ttack that utilizes\nthe \\underline{S}emantic \\underline{S}imilarity between a given sample and the\ncontent generated by the RAG system. With our proposed S$^2$MIA, we demonstrate\nthe potential to breach the membership privacy of the RAG database. Extensive\nexperiment results demonstrate that S$^2$MIA can achieve a strong inference\nperformance compared with five existing MIAs, and is able to escape from the\nprotection of three representative defenses.",
    "categories": [
      "cs.CR",
      "cs.AI"
    ],
    "primary_category": "cs.CR",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2406.19234v2",
    "published_date": "2024-06-27 14:58:38 UTC",
    "updated_date": "2024-09-26 04:22:18 UTC"
  },
  {
    "arxiv_id": "2406.19228v1",
    "title": "Tools Fail: Detecting Silent Errors in Faulty Tools",
    "authors": [
      "Jimin Sun",
      "So Yeon Min",
      "Yingshan Chang",
      "Yonatan Bisk"
    ],
    "abstract": "Tools have become a mainstay of LLMs, allowing them to retrieve knowledge not\nin their weights, to perform tasks on the web, and even to control robots.\nHowever, most ontologies and surveys of tool-use have assumed the core\nchallenge for LLMs is choosing the tool. Instead, we introduce a framework for\ntools more broadly which guides us to explore a model's ability to detect\n\"silent\" tool errors, and reflect on how to plan. This more directly aligns\nwith the increasingly popular use of models as tools. We provide an initial\napproach to failure recovery with promising results both on a controlled\ncalculator setting and embodied agent planning.",
    "categories": [
      "cs.CL",
      "cs.AI",
      "cs.LG"
    ],
    "primary_category": "cs.CL",
    "comment": "18 pages, 12 figures",
    "pdf_url": "http://arxiv.org/pdf/2406.19228v1",
    "published_date": "2024-06-27 14:52:34 UTC",
    "updated_date": "2024-06-27 14:52:34 UTC"
  },
  {
    "arxiv_id": "2406.19223v2",
    "title": "T-FREE: Subword Tokenizer-Free Generative LLMs via Sparse Representations for Memory-Efficient Embeddings",
    "authors": [
      "Bj√∂rn Deiseroth",
      "Manuel Brack",
      "Patrick Schramowski",
      "Kristian Kersting",
      "Samuel Weinbach"
    ],
    "abstract": "Tokenizers are crucial for encoding information in Large Language Models, but\ntheir development has recently stagnated, and they contain inherent weaknesses.\nMajor limitations include computational overhead, ineffective vocabulary use,\nand unnecessarily large embedding and head layers. Additionally, their\nperformance is biased towards a reference corpus, leading to reduced\neffectiveness for underrepresented languages.\n  To remedy these issues, we propose T-FREE, which directly embeds words\nthrough sparse activation patterns over character triplets, and does not\nrequire a reference corpus. T-FREE inherently exploits morphological\nsimilarities and allows for strong compression of embedding layers. In our\nexhaustive experimental evaluation, we achieve competitive downstream\nperformance with a parameter reduction of more than 85% on these layers.\nFurther, T-FREE shows significant improvements in cross-lingual transfer\nlearning.",
    "categories": [
      "cs.CL",
      "cs.AI",
      "cs.LG"
    ],
    "primary_category": "cs.CL",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2406.19223v2",
    "published_date": "2024-06-27 14:49:08 UTC",
    "updated_date": "2025-01-07 16:20:17 UTC"
  },
  {
    "arxiv_id": "2406.19220v1",
    "title": "Hack Me If You Can: Aggregating AutoEncoders for Countering Persistent Access Threats Within Highly Imbalanced Data",
    "authors": [
      "Sidahmed Benabderrahmane",
      "Ngoc Hoang",
      "Petko Valtchev",
      "James Cheney",
      "Talal Rahwan"
    ],
    "abstract": "Advanced Persistent Threats (APTs) are sophisticated, targeted cyberattacks\ndesigned to gain unauthorized access to systems and remain undetected for\nextended periods. To evade detection, APT cyberattacks deceive defense layers\nwith breaches and exploits, thereby complicating exposure by traditional\nanomaly detection-based security methods. The challenge of detecting APTs with\nmachine learning is compounded by the rarity of relevant datasets and the\nsignificant imbalance in the data, which makes the detection process highly\nburdensome. We present AE-APT, a deep learning-based tool for APT detection\nthat features a family of AutoEncoder methods ranging from a basic one to a\nTransformer-based one. We evaluated our tool on a suite of provenance trace\ndatabases produced by the DARPA Transparent Computing program, where APT-like\nattacks constitute as little as 0.004% of the data. The datasets span multiple\noperating systems, including Android, Linux, BSD, and Windows, and cover two\nattack scenarios. The outcomes showed that AE-APT has significantly higher\ndetection rates compared to its competitors, indicating superior performance in\ndetecting and ranking anomalies.",
    "categories": [
      "cs.CR",
      "cs.AI"
    ],
    "primary_category": "cs.CR",
    "comment": "To appear Future Generation Computer Systems",
    "pdf_url": "http://arxiv.org/pdf/2406.19220v1",
    "published_date": "2024-06-27 14:45:38 UTC",
    "updated_date": "2024-06-27 14:45:38 UTC"
  },
  {
    "arxiv_id": "2406.19217v1",
    "title": "Think Step by Step: Chain-of-Gesture Prompting for Error Detection in Robotic Surgical Videos",
    "authors": [
      "Zhimin Shao",
      "Jialang Xu",
      "Danail Stoyanov",
      "Evangelos B. Mazomenos",
      "Yueming Jin"
    ],
    "abstract": "Despite significant advancements in robotic systems and surgical data\nscience, ensuring safe and optimal execution in robot-assisted minimally\ninvasive surgery (RMIS) remains a complex challenge. Current surgical error\ndetection methods involve two parts: identifying surgical gestures and then\ndetecting errors within each gesture clip. These methods seldom consider the\nrich contextual and semantic information inherent in surgical videos, limiting\ntheir performance due to reliance on accurate gesture identification. Motivated\nby the chain-of-thought prompting in natural language processing, this letter\npresents a novel and real-time end-to-end error detection framework,\nChain-of-Thought (COG) prompting, leveraging contextual information from\nsurgical videos. This encompasses two reasoning modules designed to mimic the\ndecision-making processes of expert surgeons. Concretely, we first design a\nGestural-Visual Reasoning module, which utilizes transformer and attention\narchitectures for gesture prompting, while the second, a Multi-Scale Temporal\nReasoning module, employs a multi-stage temporal convolutional network with\nboth slow and fast paths for temporal information extraction. We extensively\nvalidate our method on the public benchmark RMIS dataset JIGSAWS. Our method\nencapsulates the reasoning processes inherent to surgical activities enabling\nit to outperform the state-of-the-art by 4.6% in F1 score, 4.6% in Accuracy,\nand 5.9% in Jaccard index while processing each frame in 6.69 milliseconds on\naverage, demonstrating the great potential of our approach in enhancing the\nsafety and efficacy of RMIS procedures and surgical education. The code will be\navailable.",
    "categories": [
      "cs.CV",
      "cs.AI",
      "cs.RO"
    ],
    "primary_category": "cs.CV",
    "comment": "8 pages, 4 figures",
    "pdf_url": "http://arxiv.org/pdf/2406.19217v1",
    "published_date": "2024-06-27 14:43:50 UTC",
    "updated_date": "2024-06-27 14:43:50 UTC"
  },
  {
    "arxiv_id": "2407.09550v2",
    "title": "CAPM: Fast and Robust Verification on Maxpool-based CNN via Dual Network",
    "authors": [
      "Jia-Hau Bai",
      "Chi-Ting Liu",
      "Yu Wang",
      "Fu-Chieh Chang",
      "Pei-Yuan Wu"
    ],
    "abstract": "This study uses CAPM (Convex Adversarial Polytope for Maxpool-based CNN) to\nimprove the verified bound for general purpose maxpool-based convolutional\nneural networks (CNNs) under bounded norm adversarial perturbations. The\nmaxpool function is decomposed as a series of ReLU functions to extend the\nconvex relaxation technique to maxpool functions, by which the verified bound\ncan be efficiently computed through a dual network. The experimental results\ndemonstrate that this technique allows the state-of-the-art verification\nprecision for maxpool-based CNNs and involves a much lower computational cost\nthan current verification methods, such as DeepZ, DeepPoly and PRIMA. This\nmethod is also applicable to large-scale CNNs, which previous studies show to\nbe often computationally prohibitively expensive. Under certain circumstances,\nCAPM is 40-times, 20-times or twice as fast and give a significantly higher\nverification bound (CAPM 98% vs. PRIMA 76%/DeepPoly 73%/DeepZ 8%) as compared\nto PRIMA/DeepPoly/DeepZ. Furthermore, we additionally present the time\ncomplexity of our algorithm as $O(W^2NK)$, where $W$ is the maximum width of\nthe neural network, $N$ is the number of neurons, and $K$ is the size of the\nmaxpool layer's kernel.",
    "categories": [
      "cs.CV",
      "cs.AI",
      "cs.LG"
    ],
    "primary_category": "cs.CV",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2407.09550v2",
    "published_date": "2024-06-27 14:43:06 UTC",
    "updated_date": "2025-04-08 15:51:23 UTC"
  },
  {
    "arxiv_id": "2407.00117v1",
    "title": "Machine learning meets mass spectrometry: a focused perspective",
    "authors": [
      "Daniil A. Boiko",
      "Valentine P. Ananikov"
    ],
    "abstract": "Mass spectrometry is a widely used method to study molecules and processes in\nmedicine, life sciences, chemistry, catalysis, and industrial product quality\ncontrol, among many other applications. One of the main features of some mass\nspectrometry techniques is the extensive level of characterization (especially\nwhen coupled with chromatography and ion mobility methods, or a part of tandem\nmass spectrometry experiment) and a large amount of generated data per\nmeasurement. Terabyte scales can be easily reached with mass spectrometry\nstudies. Consequently, mass spectrometry has faced the challenge of a high\nlevel of data disappearance. Researchers often neglect and then altogether lose\naccess to the rich information mass spectrometry experiments could provide.\nWith the development of machine learning methods, the opportunity arises to\nunlock the potential of these data, enabling previously inaccessible\ndiscoveries. The present perspective highlights reevaluation of mass\nspectrometry data analysis in the new generation of methods and describes\nsignificant challenges in the field, particularly related to problems involving\nthe use of electrospray ionization. We argue that further applications of\nmachine learning raise new requirements for instrumentation (increasing\nthroughput and information density, decreasing pricing, and making more\nautomation-friendly software), and once met, the field may experience\nsignificant transformation.",
    "categories": [
      "physics.chem-ph",
      "cs.AI",
      "cs.LG"
    ],
    "primary_category": "physics.chem-ph",
    "comment": "20 pages, 4 figures",
    "pdf_url": "http://arxiv.org/pdf/2407.00117v1",
    "published_date": "2024-06-27 14:18:23 UTC",
    "updated_date": "2024-06-27 14:18:23 UTC"
  },
  {
    "arxiv_id": "2406.19195v2",
    "title": "Estimating Long-term Heterogeneous Dose-response Curve: Generalization Bound Leveraging Optimal Transport Weights",
    "authors": [
      "Zeqin Yang",
      "Weilin Chen",
      "Ruichu Cai",
      "Yuguang Yan",
      "Zhifeng Hao",
      "Zhipeng Yu",
      "Zhichao Zou",
      "Jixing Xu",
      "Zhen Peng",
      "Jiecheng Guo"
    ],
    "abstract": "Long-term treatment effect estimation is a significant but challenging\nproblem in many applications. Existing methods rely on ideal assumptions, such\nas no unobserved confounders or binary treatment, to estimate long-term average\ntreatment effects. However, in numerous real-world applications, these\nassumptions could be violated, and average treatment effects are insufficient\nfor personalized decision-making. In this paper, we address a more general\nproblem of estimating long-term Heterogeneous Dose-Response Curve (HDRC) while\naccounting for unobserved confounders and continuous treatment. Specifically,\nto remove the unobserved confounders in the long-term observational data, we\nintroduce an optimal transport weighting framework to align the long-term\nobservational data to an auxiliary short-term experimental data. Furthermore,\nto accurately predict the heterogeneous effects of continuous treatment, we\nestablish a generalization bound on counterfactual prediction error by\nleveraging the reweighted distribution induced by optimal transport. Finally,\nwe develop a long-term HDRC estimator building upon the above theoretical\nfoundations. Extensive experiments on synthetic and semi-synthetic datasets\ndemonstrate the effectiveness of our approach.",
    "categories": [
      "cs.LG",
      "cs.AI"
    ],
    "primary_category": "cs.LG",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2406.19195v2",
    "published_date": "2024-06-27 14:13:46 UTC",
    "updated_date": "2025-05-16 07:28:31 UTC"
  },
  {
    "arxiv_id": "2406.19189v1",
    "title": "BISeizuRe: BERT-Inspired Seizure Data Representation to Improve Epilepsy Monitoring",
    "authors": [
      "Luca Benfenati",
      "Thorir Mar Ingolfsson",
      "Andrea Cossettini",
      "Daniele Jahier Pagliari",
      "Alessio Burrello",
      "Luca Benini"
    ],
    "abstract": "This study presents a novel approach for EEG-based seizure detection\nleveraging a BERT-based model. The model, BENDR, undergoes a two-phase training\nprocess. Initially, it is pre-trained on the extensive Temple University\nHospital EEG Corpus (TUEG), a 1.5 TB dataset comprising over 10,000 subjects,\nto extract common EEG data patterns. Subsequently, the model is fine-tuned on\nthe CHB-MIT Scalp EEG Database, consisting of 664 EEG recordings from 24\npediatric patients, of which 198 contain seizure events. Key contributions\ninclude optimizing fine-tuning on the CHB-MIT dataset, where the impact of\nmodel architecture, pre-processing, and post-processing techniques are\nthoroughly examined to enhance sensitivity and reduce false positives per hour\n(FP/h). We also explored custom training strategies to ascertain the most\neffective setup. The model undergoes a novel second pre-training phase before\nsubject-specific fine-tuning, enhancing its generalization capabilities. The\noptimized model demonstrates substantial performance enhancements, achieving as\nlow as 0.23 FP/h, 2.5$\\times$ lower than the baseline model, with a lower but\nstill acceptable sensitivity rate, showcasing the effectiveness of applying a\nBERT-based approach on EEG-based seizure detection.",
    "categories": [
      "cs.LG",
      "cs.AI"
    ],
    "primary_category": "cs.LG",
    "comment": "4 pages, 2 tables, 2 figures",
    "pdf_url": "http://arxiv.org/pdf/2406.19189v1",
    "published_date": "2024-06-27 14:09:10 UTC",
    "updated_date": "2024-06-27 14:09:10 UTC"
  },
  {
    "arxiv_id": "2407.00116v2",
    "title": "Generative AI for Synthetic Data Across Multiple Medical Modalities: A Systematic Review of Recent Developments and Challenges",
    "authors": [
      "Mahmoud Ibrahim",
      "Yasmina Al Khalil",
      "Sina Amirrajab",
      "Chang Sun",
      "Marcel Breeuwer",
      "Josien Pluim",
      "Bart Elen",
      "Gokhan Ertaylan",
      "Michel Dumontier"
    ],
    "abstract": "This paper presents a comprehensive systematic review of generative models\n(GANs, VAEs, DMs, and LLMs) used to synthesize various medical data types,\nincluding imaging (dermoscopic, mammographic, ultrasound, CT, MRI, and X-ray),\ntext, time-series, and tabular data (EHR). Unlike previous narrowly focused\nreviews, our study encompasses a broad array of medical data modalities and\nexplores various generative models. Our search strategy queries databases such\nas Scopus, PubMed, and ArXiv, focusing on recent works from January 2021 to\nNovember 2023, excluding reviews and perspectives. This period emphasizes\nrecent advancements beyond GANs, which have been extensively covered\npreviously.\n  The survey reveals insights from three key aspects: (1) Synthesis\napplications and purpose of synthesis, (2) generation techniques, and (3)\nevaluation methods. It highlights clinically valid synthesis applications,\ndemonstrating the potential of synthetic data to tackle diverse clinical\nrequirements. While conditional models incorporating class labels, segmentation\nmasks and image translations are prevalent, there is a gap in utilizing prior\nclinical knowledge and patient-specific context, suggesting a need for more\npersonalized synthesis approaches and emphasizing the importance of tailoring\ngenerative approaches to the unique characteristics of medical data.\nAdditionally, there is a significant gap in using synthetic data beyond\naugmentation, such as for validation and evaluation of downstream medical AI\nmodels. The survey uncovers that the lack of standardized evaluation\nmethodologies tailored to medical images is a barrier to clinical application,\nunderscoring the need for in-depth evaluation approaches, benchmarking, and\ncomparative studies to promote openness and collaboration.",
    "categories": [
      "cs.LG",
      "cs.AI"
    ],
    "primary_category": "cs.LG",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2407.00116v2",
    "published_date": "2024-06-27 14:00:11 UTC",
    "updated_date": "2024-07-02 06:51:09 UTC"
  },
  {
    "arxiv_id": "2407.00115v4",
    "title": "Instance Temperature Knowledge Distillation",
    "authors": [
      "Zhengbo Zhang",
      "Yuxi Zhou",
      "Jia Gong",
      "Jun Liu",
      "Zhigang Tu"
    ],
    "abstract": "Knowledge distillation (KD) enhances the performance of a student network by\nallowing it to learn the knowledge transferred from a teacher network\nincrementally. Existing methods dynamically adjust the temperature to enable\nthe student network to adapt to the varying learning difficulties at different\nlearning stages of KD. KD is a continuous process, but when adjusting the\ntemperature, these methods consider only the immediate benefits of the\noperation in the current learning phase and fail to take into account its\nfuture returns. To address this issue, we formulate the adjustment of\ntemperature as a sequential decision-making task and propose a method based on\nreinforcement learning, termed RLKD. Importantly, we design a novel state\nrepresentation to enable the agent to make more informed action (i.e. instance\ntemperature adjustment). To handle the problem of delayed rewards in our method\ndue to the KD setting, we explore an instance reward calibration approach. In\naddition,we devise an efficient exploration strategy that enables the agent to\nlearn valuable instance temperature adjustment policy more efficiently. Our\nframework can serve as a plug-and-play technique to be inserted into various KD\nmethods easily, and we validate its effectiveness on both image classification\nand object detection tasks. Our project is at\nhttps://www.zayx.me/ITKD.github.io/.",
    "categories": [
      "cs.LG",
      "cs.AI",
      "I.4.0"
    ],
    "primary_category": "cs.LG",
    "comment": "Serious updates are needed",
    "pdf_url": "http://arxiv.org/pdf/2407.00115v4",
    "published_date": "2024-06-27 14:00:05 UTC",
    "updated_date": "2025-03-14 15:03:43 UTC"
  },
  {
    "arxiv_id": "2407.00114v2",
    "title": "OmniJARVIS: Unified Vision-Language-Action Tokenization Enables Open-World Instruction Following Agents",
    "authors": [
      "Zihao Wang",
      "Shaofei Cai",
      "Zhancun Mu",
      "Haowei Lin",
      "Ceyao Zhang",
      "Xuejie Liu",
      "Qing Li",
      "Anji Liu",
      "Xiaojian Ma",
      "Yitao Liang"
    ],
    "abstract": "This paper presents OmniJARVIS, a novel Vision-Language-Action (VLA) model\nfor open-world instruction-following agents in Minecraft. Compared to prior\nworks that either emit textual goals to separate controllers or produce the\ncontrol command directly, OmniJARVIS seeks a different path to ensure both\nstrong reasoning and efficient decision-making capabilities via unified\ntokenization of multimodal interaction data. First, we introduce a\nself-supervised approach to learn a behavior encoder that produces discretized\ntokens for behavior trajectories $\\tau = \\{o_0, a_0, \\dots\\}$ and an imitation\nlearning policy decoder conditioned on these tokens. These additional behavior\ntokens will be augmented to the vocabulary of pretrained Multimodal Language\nModels. With this encoder, we then pack long-term multimodal interactions\ninvolving task instructions, memories, thoughts, observations, textual\nresponses, behavior trajectories, etc into unified token sequences and model\nthem with autoregressive transformers. Thanks to the semantically meaningful\nbehavior tokens, the resulting VLA model, OmniJARVIS, can reason (by producing\nchain-of-thoughts), plan, answer questions, and act (by producing behavior\ntokens for the imitation learning policy decoder). OmniJARVIS demonstrates\nexcellent performances on a comprehensive collection of atomic, programmatic,\nand open-ended tasks in open-world Minecraft. Our analysis further unveils the\ncrucial design principles in interaction data formation, unified tokenization,\nand its scaling potentials. The dataset, models, and code will be released at\nhttps://craftjarvis.org/OmniJARVIS.",
    "categories": [
      "cs.LG",
      "cs.AI",
      "cs.CL"
    ],
    "primary_category": "cs.LG",
    "comment": "accepted on NeurIPS 2024",
    "pdf_url": "http://arxiv.org/pdf/2407.00114v2",
    "published_date": "2024-06-27 13:46:11 UTC",
    "updated_date": "2024-10-31 14:27:50 UTC"
  },
  {
    "arxiv_id": "2407.00113v1",
    "title": "Personalized Federated Continual Learning via Multi-granularity Prompt",
    "authors": [
      "Hao Yu",
      "Xin Yang",
      "Xin Gao",
      "Yan Kang",
      "Hao Wang",
      "Junbo Zhang",
      "Tianrui Li"
    ],
    "abstract": "Personalized Federated Continual Learning (PFCL) is a new practical scenario\nthat poses greater challenges in sharing and personalizing knowledge. PFCL not\nonly relies on knowledge fusion for server aggregation at the global\nspatial-temporal perspective but also needs model improvement for each client\naccording to the local requirements. Existing methods, whether in Personalized\nFederated Learning (PFL) or Federated Continual Learning (FCL), have overlooked\nthe multi-granularity representation of knowledge, which can be utilized to\novercome Spatial-Temporal Catastrophic Forgetting (STCF) and adopt generalized\nknowledge to itself by coarse-to-fine human cognitive mechanisms. Moreover, it\nallows more effectively to personalized shared knowledge, thus serving its own\npurpose. To this end, we propose a novel concept called multi-granularity\nprompt, i.e., coarse-grained global prompt acquired through the common model\nlearning process, and fine-grained local prompt used to personalize the\ngeneralized representation. The former focuses on efficiently transferring\nshared global knowledge without spatial forgetting, and the latter emphasizes\nspecific learning of personalized local knowledge to overcome temporal\nforgetting. In addition, we design a selective prompt fusion mechanism for\naggregating knowledge of global prompts distilled from different clients. By\nthe exclusive fusion of coarse-grained knowledge, we achieve the transmission\nand refinement of common knowledge among clients, further enhancing the\nperformance of personalization. Extensive experiments demonstrate the\neffectiveness of the proposed method in addressing STCF as well as improving\npersonalized performance. Our code now is available at\nhttps://github.com/SkyOfBeginning/FedMGP.",
    "categories": [
      "cs.LG",
      "cs.AI"
    ],
    "primary_category": "cs.LG",
    "comment": "Accepted by KDD 2024 Research Track",
    "pdf_url": "http://arxiv.org/pdf/2407.00113v1",
    "published_date": "2024-06-27 13:41:37 UTC",
    "updated_date": "2024-06-27 13:41:37 UTC"
  },
  {
    "arxiv_id": "2406.19150v1",
    "title": "RAVEN: Multitask Retrieval Augmented Vision-Language Learning",
    "authors": [
      "Varun Nagaraj Rao",
      "Siddharth Choudhary",
      "Aditya Deshpande",
      "Ravi Kumar Satzoda",
      "Srikar Appalaraju"
    ],
    "abstract": "The scaling of large language models to encode all the world's knowledge in\nmodel parameters is unsustainable and has exacerbated resource barriers.\nRetrieval-Augmented Generation (RAG) presents a potential solution, yet its\napplication to vision-language models (VLMs) is under explored. Existing\nmethods focus on models designed for single tasks. Furthermore, they're limited\nby the need for resource intensive pre training, additional parameter\nrequirements, unaddressed modality prioritization and lack of clear benefit\nover non-retrieval baselines. This paper introduces RAVEN, a multitask\nretrieval augmented VLM framework that enhances base VLMs through efficient,\ntask specific fine-tuning. By integrating retrieval augmented samples without\nthe need for additional retrieval-specific parameters, we show that the model\nacquires retrieval properties that are effective across multiple tasks. Our\nresults and extensive ablations across retrieved modalities for the image\ncaptioning and VQA tasks indicate significant performance improvements compared\nto non retrieved baselines +1 CIDEr on MSCOCO, +4 CIDEr on NoCaps and nearly a\n+3\\% accuracy on specific VQA question types. This underscores the efficacy of\napplying RAG approaches to VLMs, marking a stride toward more efficient and\naccessible multimodal learning.",
    "categories": [
      "cs.CV",
      "cs.AI",
      "cs.IR"
    ],
    "primary_category": "cs.CV",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2406.19150v1",
    "published_date": "2024-06-27 13:08:35 UTC",
    "updated_date": "2024-06-27 13:08:35 UTC"
  },
  {
    "arxiv_id": "2406.19148v1",
    "title": "BackMix: Mitigating Shortcut Learning in Echocardiography with Minimal Supervision",
    "authors": [
      "Kit Mills Bransby",
      "Arian Beqiri",
      "Woo-Jin Cho Kim",
      "Jorge Oliveira",
      "Agisilaos Chartsias",
      "Alberto Gomez"
    ],
    "abstract": "Neural networks can learn spurious correlations that lead to the correct\nprediction in a validation set, but generalise poorly because the predictions\nare right for the wrong reason. This undesired learning of naive shortcuts\n(Clever Hans effect) can happen for example in echocardiogram view\nclassification when background cues (e.g. metadata) are biased towards a class\nand the model learns to focus on those background features instead of on the\nimage content. We propose a simple, yet effective random background\naugmentation method called BackMix, which samples random backgrounds from other\nexamples in the training set. By enforcing the background to be uncorrelated\nwith the outcome, the model learns to focus on the data within the ultrasound\nsector and becomes invariant to the regions outside this. We extend our method\nin a semi-supervised setting, finding that the positive effects of BackMix are\nmaintained with as few as 5% of segmentation labels. A loss weighting\nmechanism, wBackMix, is also proposed to increase the contribution of the\naugmented examples. We validate our method on both in-distribution and\nout-of-distribution datasets, demonstrating significant improvements in\nclassification accuracy, region focus and generalisability. Our source code is\navailable at: https://github.com/kitbransby/BackMix",
    "categories": [
      "cs.CV",
      "cs.AI"
    ],
    "primary_category": "cs.CV",
    "comment": "Accepted at MICCAI 2024 (Pre-print)",
    "pdf_url": "http://arxiv.org/pdf/2406.19148v1",
    "published_date": "2024-06-27 13:06:47 UTC",
    "updated_date": "2024-06-27 13:06:47 UTC"
  },
  {
    "arxiv_id": "2407.00111v1",
    "title": "Accurate Prediction of Ligand-Protein Interaction Affinities with Fine-Tuned Small Language Models",
    "authors": [
      "Ben Fauber"
    ],
    "abstract": "We describe the accurate prediction of ligand-protein interaction (LPI)\naffinities, also known as drug-target interactions (DTI), with instruction\nfine-tuned pretrained generative small language models (SLMs). We achieved\naccurate predictions for a range of affinity values associated with\nligand-protein interactions on out-of-sample data in a zero-shot setting. Only\nthe SMILES string of the ligand and the amino acid sequence of the protein were\nused as the model inputs. Our results demonstrate a clear improvement over\nmachine learning (ML) and free-energy perturbation (FEP+) based methods in\naccurately predicting a range of ligand-protein interaction affinities, which\ncan be leveraged to further accelerate drug discovery campaigns against\nchallenging therapeutic targets.",
    "categories": [
      "cs.LG",
      "cs.AI",
      "cs.CL"
    ],
    "primary_category": "cs.LG",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2407.00111v1",
    "published_date": "2024-06-27 13:04:58 UTC",
    "updated_date": "2024-06-27 13:04:58 UTC"
  },
  {
    "arxiv_id": "2407.09548v1",
    "title": "Towards Temporal Change Explanations from Bi-Temporal Satellite Images",
    "authors": [
      "Ryo Tsujimoto",
      "Hiroki Ouchi",
      "Hidetaka Kamigaito",
      "Taro Watanabe"
    ],
    "abstract": "Explaining temporal changes between satellite images taken at different times\nis important for urban planning and environmental monitoring. However, manual\ndataset construction for the task is costly, so human-AI collaboration is\npromissing. Toward the direction, in this paper, we investigate the ability of\nLarge-scale Vision-Language Models (LVLMs) to explain temporal changes between\nsatellite images. While LVLMs are known to generate good image captions, they\nreceive only a single image as input. To deal with a par of satellite images as\ninput, we propose three prompting methods. Through human evaluation, we found\nthe effectiveness of our step-by-step reasoning based prompting.",
    "categories": [
      "cs.CV",
      "cs.AI"
    ],
    "primary_category": "cs.CV",
    "comment": "11 pages, 6 figures",
    "pdf_url": "http://arxiv.org/pdf/2407.09548v1",
    "published_date": "2024-06-27 12:49:22 UTC",
    "updated_date": "2024-06-27 12:49:22 UTC"
  },
  {
    "arxiv_id": "2406.19136v6",
    "title": "YZS-model: A Predictive Model for Organic Drug Solubility Based on Graph Convolutional Networks and Transformer-Attention",
    "authors": [
      "Chenxu Wang",
      "Haowei Ming",
      "Jian He",
      "Yao Lu",
      "Junhong Chen"
    ],
    "abstract": "Accurate prediction of drug molecule solubility is crucial for therapeutic\neffectiveness and safety. Traditional methods often miss complex molecular\nstructures, leading to inaccuracies. We introduce the YZS-Model, a deep\nlearning framework integrating Graph Convolutional Networks (GCN), Transformer\narchitectures, and Long Short-Term Memory (LSTM) networks to enhance prediction\nprecision. GCNs excel at capturing intricate molecular topologies by modeling\nthe relationships between atoms and bonds. Transformers, with their\nself-attention mechanisms, effectively identify long-range dependencies within\nmolecules, capturing global interactions. LSTMs process sequential data,\npreserving long-term dependencies and integrating temporal information within\nmolecular sequences. This multifaceted approach leverages the strengths of each\ncomponent, resulting in a model that comprehensively understands and predicts\nmolecular properties. Trained on 9,943 compounds and tested on an anticancer\ndataset, the YZS-Model achieved an $R^2$ of 0.59 and an RMSE of 0.57,\noutperforming benchmark models ($R^2$ of 0.52 and RMSE of 0.61). In an\nindependent test, it demonstrated an RMSE of 1.05, improving accuracy by 45.9%.\nThe integration of these deep learning techniques allows the YZS-Model to learn\nvaluable features from complex data without predefined parameters, handle large\ndatasets efficiently, and adapt to various molecular types. This comprehensive\ncapability significantly improves predictive accuracy and model\ngeneralizability. Its precision in solubility predictions can expedite drug\ndevelopment by optimizing candidate selection, reducing costs, and enhancing\nefficiency. Our research underscores deep learning's transformative potential\nin pharmaceutical science, particularly for solubility prediction and drug\ndesign.",
    "categories": [
      "cs.LG",
      "cs.AI"
    ],
    "primary_category": "cs.LG",
    "comment": "23 pages, 16 figures, 6 tables",
    "pdf_url": "http://arxiv.org/pdf/2406.19136v6",
    "published_date": "2024-06-27 12:40:29 UTC",
    "updated_date": "2024-08-13 07:12:37 UTC"
  },
  {
    "arxiv_id": "2406.19135v1",
    "title": "DEX-TTS: Diffusion-based EXpressive Text-to-Speech with Style Modeling on Time Variability",
    "authors": [
      "Hyun Joon Park",
      "Jin Sob Kim",
      "Wooseok Shin",
      "Sung Won Han"
    ],
    "abstract": "Expressive Text-to-Speech (TTS) using reference speech has been studied\nextensively to synthesize natural speech, but there are limitations to\nobtaining well-represented styles and improving model generalization ability.\nIn this study, we present Diffusion-based EXpressive TTS (DEX-TTS), an acoustic\nmodel designed for reference-based speech synthesis with enhanced style\nrepresentations. Based on a general diffusion TTS framework, DEX-TTS includes\nencoders and adapters to handle styles extracted from reference speech. Key\ninnovations contain the differentiation of styles into time-invariant and\ntime-variant categories for effective style extraction, as well as the design\nof encoders and adapters with high generalization ability. In addition, we\nintroduce overlapping patchify and convolution-frequency patch embedding\nstrategies to improve DiT-based diffusion networks for TTS. DEX-TTS yields\noutstanding performance in terms of objective and subjective evaluation in\nEnglish multi-speaker and emotional multi-speaker datasets, without relying on\npre-training strategies. Lastly, the comparison results for the general TTS on\na single-speaker dataset verify the effectiveness of our enhanced diffusion\nbackbone. Demos are available here.",
    "categories": [
      "eess.AS",
      "cs.AI"
    ],
    "primary_category": "eess.AS",
    "comment": "Preprint",
    "pdf_url": "http://arxiv.org/pdf/2406.19135v1",
    "published_date": "2024-06-27 12:39:55 UTC",
    "updated_date": "2024-06-27 12:39:55 UTC"
  },
  {
    "arxiv_id": "2406.19126v1",
    "title": "Super-resolution imaging using super-oscillatory diffractive neural networks",
    "authors": [
      "Hang Chen",
      "Sheng Gao",
      "Zejia Zhao",
      "Zhengyang Duan",
      "Haiou Zhang",
      "Gordon Wetzstein",
      "Xing Lin"
    ],
    "abstract": "Optical super-oscillation enables far-field super-resolution imaging beyond\ndiffraction limits. However, the existing super-oscillatory lens for the\nspatial super-resolution imaging system still confronts critical limitations in\nperformance due to the lack of a more advanced design method and the limited\ndesign degree of freedom. Here, we propose an optical super-oscillatory\ndiffractive neural network, i.e., SODNN, that can achieve super-resolved\nspatial resolution for imaging beyond the diffraction limit with superior\nperformance over existing methods. SODNN is constructed by utilizing\ndiffractive layers to implement optical interconnections and imaging samples or\nbiological sensors to implement nonlinearity, which modulates the incident\noptical field to create optical super-oscillation effects in 3D space and\ngenerate the super-resolved focal spots. By optimizing diffractive layers with\n3D optical field constraints under an incident wavelength size of $\\lambda$, we\nachieved a super-oscillatory spot with a full width at half maximum of\n0.407$\\lambda$ in the far field distance over 400$\\lambda$ without side-lobes\nover the field of view, having a long depth of field over 10$\\lambda$.\nFurthermore, the SODNN implements a multi-wavelength and multi-focus spot array\nthat effectively avoids chromatic aberrations. Our research work will inspire\nthe development of intelligent optical instruments to facilitate the\napplications of imaging, sensing, perception, etc.",
    "categories": [
      "physics.optics",
      "cs.AI"
    ],
    "primary_category": "physics.optics",
    "comment": "18 pages, 7 figures, 1 table",
    "pdf_url": "http://arxiv.org/pdf/2406.19126v1",
    "published_date": "2024-06-27 12:16:35 UTC",
    "updated_date": "2024-06-27 12:16:35 UTC"
  },
  {
    "arxiv_id": "2407.00110v2",
    "title": "Chat AI: A Seamless Slurm-Native Solution for HPC-Based Services",
    "authors": [
      "Ali Doosthosseini",
      "Jonathan Decker",
      "Hendrik Nolte",
      "Julian M. Kunkel"
    ],
    "abstract": "The widespread adoption of large language models (LLMs) has created a\npressing need for an efficient, secure and private serving infrastructure,\nwhich allows researchers to run open source or custom fine-tuned LLMs and\nensures users that their data remains private and is not stored without their\nconsent. While high-performance computing (HPC) systems equipped with\nstate-of-the-art GPUs are well-suited for training LLMs, their batch scheduling\nparadigm is not designed to support real-time serving of AI applications. Cloud\nsystems, on the other hand, are well suited for web services but commonly lack\naccess to the computational power of HPC clusters, especially expensive and\nscarce high-end GPUs, which are required for optimal inference speed. We\npropose an architecture with an implementation consisting of a web service that\nruns on a cloud VM with secure access to a scalable backend running a multitude\nof LLM models on HPC systems. By offering a web service using our HPC\ninfrastructure to host LLMs, we leverage the trusted environment of local\nuniversities and research centers to offer a private and secure alternative to\ncommercial LLM services. Our solution natively integrates with the HPC batch\nscheduler Slurm, enabling seamless deployment on HPC clusters, and is able to\nrun side by side with regular Slurm workloads, while utilizing gaps in the\nschedule created by Slurm. In order to ensure the security of the HPC system,\nwe use the SSH ForceCommand directive to construct a robust circuit breaker,\nwhich prevents successful attacks on the web-facing server from affecting the\ncluster. We have successfully deployed our system as a production service, and\nmade the source code available at \\url{https://github.com/gwdg/chat-ai}",
    "categories": [
      "cs.DC",
      "cs.AI"
    ],
    "primary_category": "cs.DC",
    "comment": "Various improvements to explanations and form and updated graphs to\n  include data points up to 30.07.2024",
    "pdf_url": "http://arxiv.org/pdf/2407.00110v2",
    "published_date": "2024-06-27 12:08:21 UTC",
    "updated_date": "2024-08-02 15:34:22 UTC"
  },
  {
    "arxiv_id": "2406.19121v3",
    "title": "Towards Learning Abductive Reasoning using VSA Distributed Representations",
    "authors": [
      "Giacomo Camposampiero",
      "Michael Hersche",
      "Aleksandar Terziƒá",
      "Roger Wattenhofer",
      "Abu Sebastian",
      "Abbas Rahimi"
    ],
    "abstract": "We introduce the Abductive Rule Learner with Context-awareness (ARLC), a\nmodel that solves abstract reasoning tasks based on Learn-VRF. ARLC features a\nnovel and more broadly applicable training objective for abductive reasoning,\nresulting in better interpretability and higher accuracy when solving Raven's\nprogressive matrices (RPM). ARLC allows both programming domain knowledge and\nlearning the rules underlying a data distribution. We evaluate ARLC on the\nI-RAVEN dataset, showcasing state-of-the-art accuracy across both\nin-distribution and out-of-distribution (unseen attribute-rule pairs) tests.\nARLC surpasses neuro-symbolic and connectionist baselines, including large\nlanguage models, despite having orders of magnitude fewer parameters. We show\nARLC's robustness to post-programming training by incrementally learning from\nexamples on top of programmed knowledge, which only improves its performance\nand does not result in catastrophic forgetting of the programmed solution. We\nvalidate ARLC's seamless transfer learning from a 2x2 RPM constellation to\nunseen constellations. Our code is available at\nhttps://github.com/IBM/abductive-rule-learner-with-context-awareness.",
    "categories": [
      "cs.LG",
      "cs.AI",
      "cs.SC"
    ],
    "primary_category": "cs.LG",
    "comment": "Accepted at the 18th International Conference on Neural-Symbolic\n  Learning and Reasoning (NeSy) 2024 [Spotlight]",
    "pdf_url": "http://arxiv.org/pdf/2406.19121v3",
    "published_date": "2024-06-27 12:05:55 UTC",
    "updated_date": "2024-08-30 06:17:46 UTC"
  },
  {
    "arxiv_id": "2406.19116v1",
    "title": "CHEW: A Dataset of CHanging Events in Wikipedia",
    "authors": [
      "Hsuvas Borkakoty",
      "Luis Espinosa-Anke"
    ],
    "abstract": "We introduce CHEW, a novel dataset of changing events in Wikipedia expressed\nin naturally occurring text. We use CHEW for probing LLMs for their timeline\nunderstanding of Wikipedia entities and events in generative and classification\nexperiments. Our results suggest that LLMs, despite having temporal information\navailable, struggle to construct accurate timelines. We further show the\nusefulness of CHEW-derived embeddings for identifying meaning shift.",
    "categories": [
      "cs.CL",
      "cs.AI",
      "cs.LG"
    ],
    "primary_category": "cs.CL",
    "comment": "Short Paper",
    "pdf_url": "http://arxiv.org/pdf/2406.19116v1",
    "published_date": "2024-06-27 11:53:15 UTC",
    "updated_date": "2024-06-27 11:53:15 UTC"
  },
  {
    "arxiv_id": "2406.19108v2",
    "title": "Computational Life: How Well-formed, Self-replicating Programs Emerge from Simple Interaction",
    "authors": [
      "Blaise Ag√ºera y Arcas",
      "Jyrki Alakuijala",
      "James Evans",
      "Ben Laurie",
      "Alexander Mordvintsev",
      "Eyvind Niklasson",
      "Ettore Randazzo",
      "Luca Versari"
    ],
    "abstract": "The fields of Origin of Life and Artificial Life both question what life is\nand how it emerges from a distinct set of \"pre-life\" dynamics. One common\nfeature of most substrates where life emerges is a marked shift in dynamics\nwhen self-replication appears. While there are some hypotheses regarding how\nself-replicators arose in nature, we know very little about the general\ndynamics, computational principles, and necessary conditions for\nself-replicators to emerge. This is especially true on \"computational\nsubstrates\" where interactions involve logical, mathematical, or programming\nrules. In this paper we take a step towards understanding how self-replicators\narise by studying several computational substrates based on various simple\nprogramming languages and machine instruction sets. We show that when random,\nnon self-replicating programs are placed in an environment lacking any explicit\nfitness landscape, self-replicators tend to arise. We demonstrate how this\noccurs due to random interactions and self-modification, and can happen with\nand without background random mutations. We also show how increasingly complex\ndynamics continue to emerge following the rise of self-replicators. Finally, we\nshow a counterexample of a minimalistic programming language where\nself-replicators are possible, but so far have not been observed to arise.",
    "categories": [
      "cs.NE",
      "cs.AI",
      "F.2.2; I.2.11"
    ],
    "primary_category": "cs.NE",
    "comment": "20 pages; updated introduction with further related work",
    "pdf_url": "http://arxiv.org/pdf/2406.19108v2",
    "published_date": "2024-06-27 11:34:35 UTC",
    "updated_date": "2024-08-02 09:10:54 UTC"
  },
  {
    "arxiv_id": "2406.19102v1",
    "title": "Statements: Universal Information Extraction from Tables with Large Language Models for ESG KPIs",
    "authors": [
      "Lokesh Mishra",
      "Sohayl Dhibi",
      "Yusik Kim",
      "Cesar Berrospi Ramis",
      "Shubham Gupta",
      "Michele Dolfi",
      "Peter Staar"
    ],
    "abstract": "Environment, Social, and Governance (ESG) KPIs assess an organization's\nperformance on issues such as climate change, greenhouse gas emissions, water\nconsumption, waste management, human rights, diversity, and policies. ESG\nreports convey this valuable quantitative information through tables.\nUnfortunately, extracting this information is difficult due to high variability\nin the table structure as well as content. We propose Statements, a novel\ndomain agnostic data structure for extracting quantitative facts and related\ninformation. We propose translating tables to statements as a new supervised\ndeep-learning universal information extraction task. We introduce SemTabNet - a\ndataset of over 100K annotated tables. Investigating a family of T5-based\nStatement Extraction Models, our best model generates statements which are 82%\nsimilar to the ground-truth (compared to baseline of 21%). We demonstrate the\nadvantages of statements by applying our model to over 2700 tables from ESG\nreports. The homogeneous nature of statements permits exploratory data analysis\non expansive information found in large collections of ESG reports.",
    "categories": [
      "cs.CL",
      "cs.AI",
      "cs.IR"
    ],
    "primary_category": "cs.CL",
    "comment": "Accepted at the NLP4Climate workshop in the 62nd Annual Meeting of\n  the Association for Computational Linguistics (ACL 2024)",
    "pdf_url": "http://arxiv.org/pdf/2406.19102v1",
    "published_date": "2024-06-27 11:28:50 UTC",
    "updated_date": "2024-06-27 11:28:50 UTC"
  },
  {
    "arxiv_id": "2407.12018v1",
    "title": "Empirical Evaluation of Public HateSpeech Datasets",
    "authors": [
      "Sadar Jaf",
      "Basel Barakat"
    ],
    "abstract": "Despite the extensive communication benefits offered by social media\nplatforms, numerous challenges must be addressed to ensure user safety. One of\nthe most significant risks faced by users on these platforms is targeted hate\nspeech. Social media platforms are widely utilised for generating datasets\nemployed in training and evaluating machine learning algorithms for hate speech\ndetection. However, existing public datasets exhibit numerous limitations,\nhindering the effective training of these algorithms and leading to inaccurate\nhate speech classification. This study provides a comprehensive empirical\nevaluation of several public datasets commonly used in automated hate speech\nclassification. Through rigorous analysis, we present compelling evidence\nhighlighting the limitations of current hate speech datasets. Additionally, we\nconduct a range of statistical analyses to elucidate the strengths and\nweaknesses inherent in these datasets. This work aims to advance the\ndevelopment of more accurate and reliable machine learning models for hate\nspeech detection by addressing the dataset limitations identified.",
    "categories": [
      "cs.CL",
      "cs.AI"
    ],
    "primary_category": "cs.CL",
    "comment": "18 pages, 12 tables, 1 algorithm pseudocode, 7 figures",
    "pdf_url": "http://arxiv.org/pdf/2407.12018v1",
    "published_date": "2024-06-27 11:20:52 UTC",
    "updated_date": "2024-06-27 11:20:52 UTC"
  },
  {
    "arxiv_id": "2407.00108v1",
    "title": "A Case Study on Contextual Machine Translation in a Professional Scenario of Subtitling",
    "authors": [
      "Sebastian Vincent",
      "Charlotte Prescott",
      "Chris Bayliss",
      "Chris Oakley",
      "Carolina Scarton"
    ],
    "abstract": "Incorporating extra-textual context such as film metadata into the machine\ntranslation (MT) pipeline can enhance translation quality, as indicated by\nautomatic evaluation in recent work. However, the positive impact of such\nsystems in industry remains unproven. We report on an industrial case study\ncarried out to investigate the benefit of MT in a professional scenario of\ntranslating TV subtitles with a focus on how leveraging extra-textual context\nimpacts post-editing. We found that post-editors marked significantly fewer\ncontext-related errors when correcting the outputs of MTCue, the context-aware\nmodel, as opposed to non-contextual models. We also present the results of a\nsurvey of the employed post-editors, which highlights contextual inadequacy as\na significant gap consistently observed in MT. Our findings strengthen the\nmotivation for further work within fully contextual MT.",
    "categories": [
      "cs.LG",
      "cs.AI",
      "cs.CL",
      "cs.HC"
    ],
    "primary_category": "cs.LG",
    "comment": "Accepted to EAMT 2024",
    "pdf_url": "http://arxiv.org/pdf/2407.00108v1",
    "published_date": "2024-06-27 11:20:14 UTC",
    "updated_date": "2024-06-27 11:20:14 UTC"
  },
  {
    "arxiv_id": "2406.19087v2",
    "title": "Dimensions underlying the representational alignment of deep neural networks with humans",
    "authors": [
      "Florian P. Mahner",
      "Lukas Muttenthaler",
      "Umut G√º√ßl√º",
      "Martin N. Hebart"
    ],
    "abstract": "Determining the similarities and differences between humans and artificial\nintelligence (AI) is an important goal both in computational cognitive\nneuroscience and machine learning, promising a deeper understanding of human\ncognition and safer, more reliable AI systems. Much previous work comparing\nrepresentations in humans and AI has relied on global, scalar measures to\nquantify their alignment. However, without explicit hypotheses, these measures\nonly inform us about the degree of alignment, not the factors that determine\nit. To address this challenge, we propose a generic framework to compare human\nand AI representations, based on identifying latent representational dimensions\nunderlying the same behavior in both domains. Applying this framework to humans\nand a deep neural network (DNN) model of natural images revealed a\nlow-dimensional DNN embedding of both visual and semantic dimensions. In\ncontrast to humans, DNNs exhibited a clear dominance of visual over semantic\nproperties, indicating divergent strategies for representing images. While\nin-silico experiments showed seemingly consistent interpretability of DNN\ndimensions, a direct comparison between human and DNN representations revealed\nsubstantial differences in how they process images. By making representations\ndirectly comparable, our results reveal important challenges for\nrepresentational alignment and offer a means for improving their comparability.",
    "categories": [
      "cs.CV",
      "cs.AI",
      "cs.LG",
      "q-bio.QM"
    ],
    "primary_category": "cs.CV",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2406.19087v2",
    "published_date": "2024-06-27 11:14:14 UTC",
    "updated_date": "2025-01-27 13:19:27 UTC"
  },
  {
    "arxiv_id": "2407.00107v2",
    "title": "WineGraph: A Graph Representation For Food-Wine Pairing",
    "authors": [
      "Zuzanna Gawrysiak",
      "Agata ≈ªywot",
      "Agnieszka ≈Åawrynowicz"
    ],
    "abstract": "We present WineGraph, an extended version of FlavorGraph, a heterogeneous\ngraph incorporating wine data into its structure. This integration enables\nfood-wine pairing based on taste and sommelier-defined rules. Leveraging a food\ndataset comprising 500,000 reviews and a wine reviews dataset with over 130,000\nentries, we computed taste descriptors for both food and wine. This information\nwas then utilised to pair food items with wine and augment FlavorGraph with\nadditional data. The results demonstrate the potential of heterogeneous graphs\nto acquire supplementary information, proving beneficial for wine pairing.",
    "categories": [
      "cs.LG",
      "cs.AI"
    ],
    "primary_category": "cs.LG",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2407.00107v2",
    "published_date": "2024-06-27 11:11:19 UTC",
    "updated_date": "2024-07-11 12:12:48 UTC"
  },
  {
    "arxiv_id": "2406.19071v2",
    "title": "EmPO: Emotion Grounding for Empathetic Response Generation through Preference Optimization",
    "authors": [
      "Ondrej Sotolar",
      "Vojtech Formanek",
      "Alok Debnath",
      "Allison Lahnala",
      "Charles Welch",
      "Lucie FLek"
    ],
    "abstract": "Empathetic response generation is a desirable aspect of conversational\nagents, crucial for facilitating engaging and emotionally intelligent\nmulti-turn conversations between humans and machines. Leveraging large language\nmodels for this task has shown promising results, yet challenges persist in\nensuring both the empathetic quality of the responses and retention of the\ngeneralization performance of the models. We propose a novel approach where we\nconstruct theory-driven preference datasets based on emotion grounding and use\nthem to align LLMs with preference optimization algorithms to address these\nchallenges. To evaluate empathetic response generation, we employ the\nEmpatheticDialogues dataset, assessing empathy with the diff-Epitome and\nBERTscore metrics and with multi-dimensional human evaluation. Additionally, we\nmeasure diversity and emotional valence using feature-based methods. We also\nevaluate the impact of training on the generalization performance using the\nMMLU benchmark and tasks from the Open LLM Leaderboard. The results show that\nLLMs can be aligned for empathetic response generation by preference\noptimization while retaining their general performance and that emotion\ngrounding can guide preference dataset creation. We make all datasets, source\ncode, and models publicly available. https://github.com/justtherightsize/empo",
    "categories": [
      "cs.CL",
      "cs.AI",
      "68T50",
      "I.2.7"
    ],
    "primary_category": "cs.CL",
    "comment": "v02, 8 pages long paper, EMNLP ACL style",
    "pdf_url": "http://arxiv.org/pdf/2406.19071v2",
    "published_date": "2024-06-27 10:41:22 UTC",
    "updated_date": "2024-09-17 14:24:47 UTC"
  },
  {
    "arxiv_id": "2407.00106v1",
    "title": "UnUnlearning: Unlearning is not sufficient for content regulation in advanced generative AI",
    "authors": [
      "Ilia Shumailov",
      "Jamie Hayes",
      "Eleni Triantafillou",
      "Guillermo Ortiz-Jimenez",
      "Nicolas Papernot",
      "Matthew Jagielski",
      "Itay Yona",
      "Heidi Howard",
      "Eugene Bagdasaryan"
    ],
    "abstract": "Exact unlearning was first introduced as a privacy mechanism that allowed a\nuser to retract their data from machine learning models on request. Shortly\nafter, inexact schemes were proposed to mitigate the impractical costs\nassociated with exact unlearning. More recently unlearning is often discussed\nas an approach for removal of impermissible knowledge i.e. knowledge that the\nmodel should not possess such as unlicensed copyrighted, inaccurate, or\nmalicious information. The promise is that if the model does not have a certain\nmalicious capability, then it cannot be used for the associated malicious\npurpose. In this paper we revisit the paradigm in which unlearning is used for\nin Large Language Models (LLMs) and highlight an underlying inconsistency\narising from in-context learning. Unlearning can be an effective control\nmechanism for the training phase, yet it does not prevent the model from\nperforming an impermissible act during inference. We introduce a concept of\nununlearning, where unlearned knowledge gets reintroduced in-context,\neffectively rendering the model capable of behaving as if it knows the\nforgotten knowledge. As a result, we argue that content filtering for\nimpermissible knowledge will be required and even exact unlearning schemes are\nnot enough for effective content regulation. We discuss feasibility of\nununlearning for modern LLMs and examine broader implications.",
    "categories": [
      "cs.LG",
      "cs.AI",
      "cs.CL",
      "cs.CR"
    ],
    "primary_category": "cs.LG",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2407.00106v1",
    "published_date": "2024-06-27 10:24:35 UTC",
    "updated_date": "2024-06-27 10:24:35 UTC"
  },
  {
    "arxiv_id": "2406.19057v2",
    "title": "Segment Anything Model for automated image data annotation: empirical studies using text prompts from Grounding DINO",
    "authors": [
      "Fuseini Mumuni",
      "Alhassan Mumuni"
    ],
    "abstract": "Grounding DINO and the Segment Anything Model (SAM) have achieved impressive\nperformance in zero-shot object detection and image segmentation, respectively.\nTogether, they have a great potential to revolutionize applications in\nzero-shot semantic segmentation or data annotation. Yet, in specialized domains\nlike medical image segmentation, objects of interest (e.g., organs, tissues,\nand tumors) may not fall in existing class names. To address this problem, the\nreferring expression comprehension (REC) ability of Grounding DINO is leveraged\nto detect arbitrary targets by their language descriptions. However, recent\nstudies have highlighted severe limitation of the REC framework in this\napplication setting owing to its tendency to make false positive predictions\nwhen the target is absent in the given image. And, while this bottleneck is\ncentral to the prospect of open-set semantic segmentation, it is still largely\nunknown how much improvement can be achieved by studying the prediction errors.\nTo this end, we perform empirical studies on six publicly available datasets\nacross different domains and reveal that these errors consistently follow a\npredictable pattern and can, thus, be mitigated by a simple strategy.\nSpecifically, we show that false positive detections with appreciable\nconfidence scores generally occupy large image areas and can usually be\nfiltered by their relative sizes. More importantly, we expect these\nobservations to inspire future research in improving REC-based detection and\nautomated segmentation. Meanwhile, we evaluate the performance of SAM on\nmultiple datasets from various specialized domains and report significant\nimprovements in segmentation performance and annotation time savings over\nmanual approaches.",
    "categories": [
      "cs.CV",
      "cs.AI",
      "cs.LG",
      "cs.RO"
    ],
    "primary_category": "cs.CV",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2406.19057v2",
    "published_date": "2024-06-27 10:08:29 UTC",
    "updated_date": "2024-06-30 07:54:30 UTC"
  },
  {
    "arxiv_id": "2407.09547v1",
    "title": "Predicting Depression and Anxiety Risk in Dutch Neighborhoods from Street-View Images",
    "authors": [
      "Nin Khodorivsko",
      "Giacomo Spigler"
    ],
    "abstract": "Depression and anxiety disorders are prevalent mental health challenges\naffecting a substantial segment of the global population. In this study, we\nexplored the environmental correlates of these disorders by analyzing\nstreet-view images (SVI) of neighborhoods in the Netherlands. Our dataset\ncomprises 9,879 Dutch SVIs sourced from Google Street View, paired with\nstatistical depression and anxiety risk metrics from the Dutch Health Monitor.\nTo tackle this challenge, we refined two existing neural network architectures,\nDeiT Base and ResNet50. Our goal was to predict neighborhood risk levels,\ncategorized into four tiers from low to high risk, using the raw images. The\nresults showed that DeiT Base and ResNet50 achieved accuracies of 43.43% and\n43.63%, respectively. Notably, a significant portion of the errors were between\nadjacent risk categories, resulting in adjusted accuracies of 83.55% and\n80.38%. We also implemented the SHapley Additive exPlanations (SHAP) method on\nboth models and employed gradient rollout on DeiT. Interestingly, while SHAP\nunderscored specific landscape attributes, the correlation between these\nfeatures and distinct depression risk categories remained unclear. The gradient\nrollout findings were similarly non-definitive. However, through manual\nanalysis, we identified certain landscape types that were consistently linked\nwith specific risk categories. These findings suggest the potential of these\ntechniques in monitoring the correlation between various landscapes and\nenvironmental risk factors for mental health issues. As a future direction, we\nrecommend employing these methods to observe how risk scores from the Dutch\nHealth Monitor shift across neighborhoods over time.",
    "categories": [
      "cs.CV",
      "cs.AI",
      "cs.LG"
    ],
    "primary_category": "cs.CV",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2407.09547v1",
    "published_date": "2024-06-27 10:05:56 UTC",
    "updated_date": "2024-06-27 10:05:56 UTC"
  },
  {
    "arxiv_id": "2406.19054v1",
    "title": "A look under the hood of the Interactive Deep Learning Enterprise (No-IDLE)",
    "authors": [
      "Daniel Sonntag",
      "Michael Barz",
      "Thiago Gouv√™a"
    ],
    "abstract": "This DFKI technical report presents the anatomy of the No-IDLE prototype\nsystem (funded by the German Federal Ministry of Education and Research) that\nprovides not only basic and fundamental research in interactive machine\nlearning, but also reveals deeper insights into users' behaviours, needs, and\ngoals. Machine learning and deep learning should become accessible to millions\nof end users. No-IDLE's goals and scienfific challenges centre around the\ndesire to increase the reach of interactive deep learning solutions for\nnon-experts in machine learning. One of the key innovations described in this\ntechnical report is a methodology for interactive machine learning combined\nwith multimodal interaction which will become central when we start interacting\nwith semi-intelligent machines in the upcoming area of neural networks and\nlarge language models.",
    "categories": [
      "cs.LG",
      "cs.AI",
      "cs.HC"
    ],
    "primary_category": "cs.LG",
    "comment": "DFKI Technical Report",
    "pdf_url": "http://arxiv.org/pdf/2406.19054v1",
    "published_date": "2024-06-27 10:01:56 UTC",
    "updated_date": "2024-06-27 10:01:56 UTC"
  },
  {
    "arxiv_id": "2406.19050v1",
    "title": "FedMap: Iterative Magnitude-Based Pruning for Communication-Efficient Federated Learning",
    "authors": [
      "Alexander Herzog",
      "Robbie Southam",
      "Ioannis Mavromatis",
      "Aftab Khan"
    ],
    "abstract": "Federated Learning (FL) is a distributed machine learning approach that\nenables training on decentralized data while preserving privacy. However, FL\nsystems often involve resource-constrained client devices with limited\ncomputational power, memory, storage, and bandwidth. This paper introduces\nFedMap, a novel method that aims to enhance the communication efficiency of FL\ndeployments by collaboratively learning an increasingly sparse global model\nthrough iterative, unstructured pruning. Importantly, FedMap trains a global\nmodel from scratch, unlike other methods reported in the literature, making it\nideal for privacy-critical use cases such as in the medical and finance\ndomains, where suitable pre-training data is often limited. FedMap adapts\niterative magnitude-based pruning to the FL setting, ensuring all clients prune\nand refine the same subset of the global model parameters, therefore gradually\nreducing the global model size and communication overhead. The iterative nature\nof FedMap, forming subsequent models as subsets of predecessors, avoids\nparameter reactivation issues seen in prior work, resulting in stable\nperformance. In this paper we provide an extensive evaluation of FedMap across\ndiverse settings, datasets, model architectures, and hyperparameters, assessing\nperformance in both IID and non-IID environments. Comparative analysis against\nthe baseline approach demonstrates FedMap's ability to achieve more stable\nclient model performance. For IID scenarios, FedMap achieves over $90$\\%\npruning without significant performance degradation. In non-IID settings, it\nachieves at least $~80$\\% pruning while maintaining accuracy. FedMap offers a\npromising solution to alleviate communication bottlenecks in FL systems while\nretaining model accuracy.",
    "categories": [
      "cs.LG",
      "cs.AI"
    ],
    "primary_category": "cs.LG",
    "comment": "Submitted to IEEE Transactions on Neural Networks and Learning\n  Systems",
    "pdf_url": "http://arxiv.org/pdf/2406.19050v1",
    "published_date": "2024-06-27 09:58:43 UTC",
    "updated_date": "2024-06-27 09:58:43 UTC"
  },
  {
    "arxiv_id": "2406.19049v1",
    "title": "Accuracy on the wrong line: On the pitfalls of noisy data for out-of-distribution generalisation",
    "authors": [
      "Amartya Sanyal",
      "Yaxi Hu",
      "Yaodong Yu",
      "Yian Ma",
      "Yixin Wang",
      "Bernhard Sch√∂lkopf"
    ],
    "abstract": "\"Accuracy-on-the-line\" is a widely observed phenomenon in machine learning,\nwhere a model's accuracy on in-distribution (ID) and out-of-distribution (OOD)\ndata is positively correlated across different hyperparameters and data\nconfigurations. But when does this useful relationship break down? In this\nwork, we explore its robustness. The key observation is that noisy data and the\npresence of nuisance features can be sufficient to shatter the\nAccuracy-on-the-line phenomenon. In these cases, ID and OOD accuracy can become\nnegatively correlated, leading to \"Accuracy-on-the-wrong-line\". This phenomenon\ncan also occur in the presence of spurious (shortcut) features, which tend to\novershadow the more complex signal (core, non-spurious) features, resulting in\na large nuisance feature space. Moreover, scaling to larger datasets does not\nmitigate this undesirable behavior and may even exacerbate it. We formally\nprove a lower bound on Out-of-distribution (OOD) error in a linear\nclassification model, characterizing the conditions on the noise and nuisance\nfeatures for a large OOD error. We finally demonstrate this phenomenon across\nboth synthetic and real datasets with noisy data and nuisance features.",
    "categories": [
      "cs.LG",
      "cs.AI",
      "stat.ML"
    ],
    "primary_category": "cs.LG",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2406.19049v1",
    "published_date": "2024-06-27 09:57:31 UTC",
    "updated_date": "2024-06-27 09:57:31 UTC"
  },
  {
    "arxiv_id": "2406.19048v2",
    "title": "BiCo-Fusion: Bidirectional Complementary LiDAR-Camera Fusion for Semantic- and Spatial-Aware 3D Object Detection",
    "authors": [
      "Yang Song",
      "Lin Wang"
    ],
    "abstract": "3D object detection is an important task that has been widely applied in\nautonomous driving. To perform this task, a new trend is to fuse multi-modal\ninputs, i.e., LiDAR and camera. Under such a trend, recent methods fuse these\ntwo modalities by unifying them in the same 3D space. However, during direct\nfusion in a unified space, the drawbacks of both modalities (LiDAR features\nstruggle with detailed semantic information and the camera lacks accurate 3D\nspatial information) are also preserved, diluting semantic and spatial\nawareness of the final unified representation. To address the issue, this\nletter proposes a novel bidirectional complementary LiDAR-camera fusion\nframework, called BiCo-Fusion that can achieve robust semantic- and\nspatial-aware 3D object detection. The key insight is to fuse LiDAR and camera\nfeatures in a bidirectional complementary way to enhance the semantic awareness\nof the LiDAR and the 3D spatial awareness of the camera. The enhanced features\nfrom both modalities are then adaptively fused to build a semantic- and\nspatial-aware unified representation. Specifically, we introduce Pre-Fusion\nconsisting of a Voxel Enhancement Module (VEM) to enhance the semantic\nawareness of voxel features from 2D camera features and Image Enhancement\nModule (IEM) to enhance the 3D spatial awareness of camera features from 3D\nvoxel features. We then introduce Unified Fusion (U-Fusion) to adaptively fuse\nthe enhanced features from the last stage to build a unified representation.\nExtensive experiments demonstrate the superiority of our BiCo-Fusion against\nthe prior arts. Project page: https://t-ys.github.io/BiCo-Fusion/.",
    "categories": [
      "cs.CV",
      "cs.AI"
    ],
    "primary_category": "cs.CV",
    "comment": "8 pages, 5 figures",
    "pdf_url": "http://arxiv.org/pdf/2406.19048v2",
    "published_date": "2024-06-27 09:56:38 UTC",
    "updated_date": "2024-12-01 07:07:02 UTC"
  },
  {
    "arxiv_id": "2406.19043v2",
    "title": "CMRxRecon2024: A Multi-Modality, Multi-View K-Space Dataset Boosting Universal Machine Learning for Accelerated Cardiac MRI",
    "authors": [
      "Zi Wang",
      "Fanwen Wang",
      "Chen Qin",
      "Jun Lyu",
      "Cheng Ouyang",
      "Shuo Wang",
      "Yan Li",
      "Mengyao Yu",
      "Haoyu Zhang",
      "Kunyuan Guo",
      "Zhang Shi",
      "Qirong Li",
      "Ziqiang Xu",
      "Yajing Zhang",
      "Hao Li",
      "Sha Hua",
      "Binghua Chen",
      "Longyu Sun",
      "Mengting Sun",
      "Qin Li",
      "Ying-Hua Chu",
      "Wenjia Bai",
      "Jing Qin",
      "Xiahai Zhuang",
      "Claudia Prieto",
      "Alistair Young",
      "Michael Markl",
      "He Wang",
      "Lianming Wu",
      "Guang Yang",
      "Xiaobo Qu",
      "Chengyan Wang"
    ],
    "abstract": "Cardiac magnetic resonance imaging (MRI) has emerged as a clinically\ngold-standard technique for diagnosing cardiac diseases, thanks to its ability\nto provide diverse information with multiple modalities and anatomical views.\nAccelerated cardiac MRI is highly expected to achieve time-efficient and\npatient-friendly imaging, and then advanced image reconstruction approaches are\nrequired to recover high-quality, clinically interpretable images from\nundersampled measurements. However, the lack of publicly available cardiac MRI\nk-space dataset in terms of both quantity and diversity has severely hindered\nsubstantial technological progress, particularly for data-driven artificial\nintelligence. Here, we provide a standardized, diverse, and high-quality\nCMRxRecon2024 dataset to facilitate the technical development, fair evaluation,\nand clinical transfer of cardiac MRI reconstruction approaches, towards\npromoting the universal frameworks that enable fast and robust reconstructions\nacross different cardiac MRI protocols in clinical practice. To the best of our\nknowledge, the CMRxRecon2024 dataset is the largest and most protocal-diverse\npublicly available cardiac k-space dataset. It is acquired from 330 healthy\nvolunteers, covering commonly used modalities, anatomical views, and\nacquisition trajectories in clinical cardiac MRI workflows. Besides, an open\nplatform with tutorials, benchmarks, and data processing tools is provided to\nfacilitate data usage, advanced method development, and fair performance\nevaluation.",
    "categories": [
      "eess.IV",
      "cs.AI",
      "cs.CV",
      "cs.DB"
    ],
    "primary_category": "eess.IV",
    "comment": "23 pages, 3 figures, 2 tables",
    "pdf_url": "http://arxiv.org/pdf/2406.19043v2",
    "published_date": "2024-06-27 09:50:20 UTC",
    "updated_date": "2025-01-16 06:46:18 UTC"
  },
  {
    "arxiv_id": "2407.13013v1",
    "title": "FernUni LLM Experimental Infrastructure (FLEXI) -- Enabling Experimentation and Innovation in Higher Education Through Access to Open Large Language Models",
    "authors": [
      "Torsten Zesch",
      "Michael Hanses",
      "Niels Seidel",
      "Piush Aggarwal",
      "Dirk Veiel",
      "Claudia de Witt"
    ],
    "abstract": "Using the full potential of LLMs in higher education is hindered by\nchallenges with access to LLMs. The two main access modes currently discussed\nare paying for a cloud-based LLM or providing a locally maintained open LLM. In\nthis paper, we describe the current state of establishing an open LLM\ninfrastructure at FernUniversit\\\"at in Hagen under the project name FLEXI\n(FernUni LLM Experimental Infrastructure). FLEXI enables experimentation within\nteaching and research with the goal of generating strongly needed evidence in\nfavor (or against) the use of locally maintained open LLMs in higher education.\nThe paper will provide some practical guidance for everyone trying to decide\nwhether to run their own LLM server.",
    "categories": [
      "cs.CY",
      "cs.AI"
    ],
    "primary_category": "cs.CY",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2407.13013v1",
    "published_date": "2024-06-27 09:46:11 UTC",
    "updated_date": "2024-06-27 09:46:11 UTC"
  },
  {
    "arxiv_id": "2406.19015v3",
    "title": "Gaussian process-based online health monitoring and fault analysis of lithium-ion battery systems from field data",
    "authors": [
      "Joachim Schaeffer",
      "Eric Lenz",
      "Duncan Gulla",
      "Martin Z. Bazant",
      "Richard D. Braatz",
      "Rolf Findeisen"
    ],
    "abstract": "Health monitoring, fault analysis, and detection are critical for the safe\nand sustainable operation of battery systems. We apply Gaussian process\nresistance models on lithium iron phosphate battery field data to effectively\nseparate the time-dependent and operating point-dependent resistance. The data\nset contains 29 battery systems returned to the manufacturer for warranty, each\nwith eight cells in series, totaling 232 cells and 131 million data rows. We\ndevelop probabilistic fault detection rules using recursive spatiotemporal\nGaussian processes. These processes allow the quick processing of over a\nmillion data points, enabling advanced online monitoring and furthering the\nunderstanding of battery pack failure in the field. The analysis underlines\nthat often, only a single cell shows abnormal behavior or a knee point,\nconsistent with weakest-link failure for cells connected in series, amplified\nby local resistive heating. The results further the understanding of how\nbatteries degrade and fail in the field and demonstrate the potential of\nefficient online monitoring based on data. We open-source the code and publish\nthe large data set upon completion of the review of this article.",
    "categories": [
      "cs.LG",
      "cs.AI",
      "cs.SY",
      "eess.SY",
      "stat.AP",
      "I.2.6"
    ],
    "primary_category": "cs.LG",
    "comment": "This version is outdated. The final version is published as open\n  access journal article: https://doi.org/10.1016/j.xcrp.2024.102258",
    "pdf_url": "http://arxiv.org/pdf/2406.19015v3",
    "published_date": "2024-06-27 09:00:05 UTC",
    "updated_date": "2024-10-30 15:28:05 UTC"
  },
  {
    "arxiv_id": "2407.00105v1",
    "title": "Multiple Kronecker RLS fusion-based link propagation for drug-side effect prediction",
    "authors": [
      "Yuqing Qian",
      "Ziyu Zheng",
      "Prayag Tiwari",
      "Yijie Ding",
      "Quan Zou"
    ],
    "abstract": "Drug-side effect prediction has become an essential area of research in the\nfield of pharmacology. As the use of medications continues to rise, so does the\nimportance of understanding and mitigating the potential risks associated with\nthem. At present, researchers have turned to data-driven methods to predict\ndrug-side effects. Drug-side effect prediction is a link prediction problem,\nand the related data can be described from various perspectives. To process\nthese kinds of data, a multi-view method, called Multiple Kronecker RLS\nfusion-based link propagation (MKronRLSF-LP), is proposed. MKronRLSF-LP extends\nthe Kron-RLS by finding the consensus partitions and multiple graph Laplacian\nconstraints in the multi-view setting. Both of these multi-view settings\ncontribute to a higher quality result. Extensive experiments have been\nconducted on drug-side effect datasets, and our empirical results provide\nevidence that our approach is effective and robust.",
    "categories": [
      "cs.LG",
      "cs.AI"
    ],
    "primary_category": "cs.LG",
    "comment": "Transactions on Machine Learning Research (TMLR 2024)",
    "pdf_url": "http://arxiv.org/pdf/2407.00105v1",
    "published_date": "2024-06-27 08:50:25 UTC",
    "updated_date": "2024-06-27 08:50:25 UTC"
  },
  {
    "arxiv_id": "2406.18995v1",
    "title": "FedMLP: Federated Multi-Label Medical Image Classification under Task Heterogeneity",
    "authors": [
      "Zhaobin Sun",
      "Nannan Wu",
      "Junjie Shi",
      "Li Yu",
      "Xin Yang",
      "Kwang-Ting Cheng",
      "Zengqiang Yan"
    ],
    "abstract": "Cross-silo federated learning (FL) enables decentralized organizations to\ncollaboratively train models while preserving data privacy and has made\nsignificant progress in medical image classification. One common assumption is\ntask homogeneity where each client has access to all classes during training.\nHowever, in clinical practice, given a multi-label classification task,\nconstrained by the level of medical knowledge and the prevalence of diseases,\neach institution may diagnose only partial categories, resulting in task\nheterogeneity. How to pursue effective multi-label medical image classification\nunder task heterogeneity is under-explored. In this paper, we first formulate\nsuch a realistic label missing setting in the multi-label FL domain and propose\na two-stage method FedMLP to combat class missing from two aspects: pseudo\nlabel tagging and global knowledge learning. The former utilizes a warmed-up\nmodel to generate class prototypes and select samples with high confidence to\nsupplement missing labels, while the latter uses a global model as a teacher\nfor consistency regularization to prevent forgetting missing class knowledge.\nExperiments on two publicly-available medical datasets validate the superiority\nof FedMLP against the state-of-the-art both federated semi-supervised and noisy\nlabel learning approaches under task heterogeneity. Code is available at\nhttps://github.com/szbonaldo/FedMLP.",
    "categories": [
      "cs.LG",
      "cs.AI"
    ],
    "primary_category": "cs.LG",
    "comment": "Early accepted by MICCAI 2024",
    "pdf_url": "http://arxiv.org/pdf/2406.18995v1",
    "published_date": "2024-06-27 08:36:43 UTC",
    "updated_date": "2024-06-27 08:36:43 UTC"
  },
  {
    "arxiv_id": "2406.18992v3",
    "title": "Semi-supervised Concept Bottleneck Models",
    "authors": [
      "Lijie Hu",
      "Tianhao Huang",
      "Huanyi Xie",
      "Xilin Gong",
      "Chenyang Ren",
      "Zhengyu Hu",
      "Lu Yu",
      "Ping Ma",
      "Di Wang"
    ],
    "abstract": "Concept Bottleneck Models (CBMs) have garnered increasing attention due to\ntheir ability to provide concept-based explanations for black-box deep learning\nmodels while achieving high final prediction accuracy using human-like\nconcepts. However, the training of current CBMs is heavily dependent on the\nprecision and richness of the annotated concepts in the dataset. These concept\nlabels are typically provided by experts, which can be costly and require\nsignificant resources and effort. Additionally, concept saliency maps\nfrequently misalign with input saliency maps, causing concept predictions to\ncorrespond to irrelevant input features - an issue related to annotation\nalignment. To address these limitations, we propose a new framework called\nSSCBM (Semi-supervised Concept Bottleneck Model). Our SSCBM is suitable for\npractical situations where annotated data is scarce. By leveraging joint\ntraining on both labeled and unlabeled data and aligning the unlabeled data at\nthe concept level, we effectively solve these issues. We proposed a strategy to\ngenerate pseudo labels and an alignment loss. Experiments demonstrate that our\nSSCBM is both effective and efficient. With only 10% labeled data, our model's\nconcept and task accuracy on average across four datasets is only 2.44% and\n3.93% lower, respectively, compared to the best baseline in the fully\nsupervised learning setting.",
    "categories": [
      "cs.CV",
      "cs.AI",
      "cs.LG"
    ],
    "primary_category": "cs.CV",
    "comment": "16 pages",
    "pdf_url": "http://arxiv.org/pdf/2406.18992v3",
    "published_date": "2024-06-27 08:33:35 UTC",
    "updated_date": "2025-03-19 20:33:22 UTC"
  },
  {
    "arxiv_id": "2406.18954v1",
    "title": "Alignment For Performance Improvement in Conversation Bots",
    "authors": [
      "Raghav Garg",
      "Kapil Sharma",
      "Shrey Singla"
    ],
    "abstract": "This paper shows that alignment methods can achieve superior adherence to\nguardrails compared to instruction fine-tuning alone in conversational agents,\nalso known as bots, within predefined guidelines or 'guardrails'. It examines\ntraditional training approaches such as instruction fine-tuning and the recent\nadvancements in direct alignment methods like Identity Preference Optimization\n(IPO), and Kahneman-Tversky Optimization (KTO). The effectiveness of alignment\ntechniques both pre and post-instruction tuning is highlighted, illustrating\ntheir potential to optimize conversational bots in domains that require strict\nadherence to specified rules, such as customer care.",
    "categories": [
      "cs.LG",
      "cs.AI"
    ],
    "primary_category": "cs.LG",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2406.18954v1",
    "published_date": "2024-06-27 07:36:25 UTC",
    "updated_date": "2024-06-27 07:36:25 UTC"
  },
  {
    "arxiv_id": "2407.00104v2",
    "title": "Clinically inspired enhance Explainability and Interpretability of an AI-Tool for BCC diagnosis based on expert annotation",
    "authors": [
      "Iv√°n Matas",
      "Carmen Serrano",
      "Francisca Silva",
      "Amalia Serrano",
      "Tom√°s Toledo-Pastrana",
      "Bego√±a Acha"
    ],
    "abstract": "An AI tool has been developed to provide interpretable support for the\ndiagnosis of BCC via teledermatology, thus speeding up referrals and optimizing\nresource utilization. The interpretability is provided in two ways: on the one\nhand, the main BCC dermoscopic patterns are found in the image to justify the\nBCC/Non BCC classification. Secondly, based on the common visual XAI Grad-CAM,\na clinically inspired visual explanation is developed where the relevant\nfeatures for diagnosis are located. Since there is no established ground truth\nfor BCC dermoscopic features, a standard reference is inferred from the\ndiagnosis of four dermatologists using an Expectation Maximization (EM) based\nalgorithm. The results demonstrate significant improvements in classification\naccuracy and interpretability, positioning this approach as a valuable tool for\nearly BCC detection and referral to dermatologists. The BCC/non-BCC\nclassification achieved an accuracy rate of 90%. For Clinically-inspired XAI\nresults, the detection of BCC patterns useful to clinicians reaches 99%\naccuracy. As for the Clinically-inspired Visual XAI results, the mean of the\nGrad-CAM normalized value within the manually segmented clinical features is\n0.57, while outside this region it is 0.16. This indicates that the model\nstruggles to accurately identify the regions of the BCC patterns. These results\nprove the ability of the AI tool to provide a useful explanation.",
    "categories": [
      "cs.LG",
      "cs.AI",
      "cs.CV",
      "cs.IR",
      "eess.IV"
    ],
    "primary_category": "cs.LG",
    "comment": "8 pages, 4 figures, 4 tables, under review",
    "pdf_url": "http://arxiv.org/pdf/2407.00104v2",
    "published_date": "2024-06-27 07:33:34 UTC",
    "updated_date": "2025-05-13 09:29:47 UTC"
  },
  {
    "arxiv_id": "2407.00102v1",
    "title": "Curriculum Learning with Quality-Driven Data Selection",
    "authors": [
      "Biao Wu",
      "Fang Meng",
      "Ling Chen"
    ],
    "abstract": "The impressive multimodal capabilities demonstrated by OpenAI's GPT-4 have\ngenerated significant interest in the development of Multimodal Large Language\nModels (MLLMs). Visual instruction tuning of MLLMs with machine-generated\ninstruction-following data has shown to enhance zero-shot capabilities across\nvarious tasks. However, there has been limited exploration into controlling the\nquality of the instruction data.Current methodologies for data selection in\nMLLMs often rely on single, unreliable scores or use downstream tasks for\nselection, which is time-consuming and can lead to potential overfitting on the\nchosen evaluation datasets. To mitigate these limitations, we propose a novel\ndata selection methodology that utilizes image-text correlation and model\nperplexity to evaluate and select data of varying quality. This approach\nleverages the distinct distribution of these two attributes, mapping data\nquality into a two-dimensional space that allows for the selection of data\nbased on their location within this distribution. By utilizing this space, we\ncan analyze the impact of task type settings, used as prompts, on data quality.\nAdditionally, this space can be used to construct multi-stage subsets of\nvarying quality to facilitate curriculum learning. Our research includes\ncomprehensive experiments conducted on various datasets. The results emphasize\nsubstantial enhancements in five commonly assessed capabilities compared to\nusing the complete dataset. Our codes, data, and models are publicly available\nat: \\url{https://anonymous.4open.science/r/EHIT-31B4}",
    "categories": [
      "cs.LG",
      "cs.AI",
      "cs.CL"
    ],
    "primary_category": "cs.LG",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2407.00102v1",
    "published_date": "2024-06-27 07:20:36 UTC",
    "updated_date": "2024-06-27 07:20:36 UTC"
  },
  {
    "arxiv_id": "2407.12017v2",
    "title": "Follow-Up Questions Improve Documents Generated by Large Language Models",
    "authors": [
      "Bernadette J Tix"
    ],
    "abstract": "This study investigates the impact of Large Language Models (LLMs) generating\nfollow-up questions in response to user requests for short (1-page) text\ndocuments. Users interacted with a novel web-based AI system designed to ask\nfollow-up questions. Users requested documents they would like the AI to\nproduce. The AI then generated follow-up questions to clarify the user's needs\nor offer additional insights before generating the requested documents. After\nanswering the questions, users were shown a document generated using both the\ninitial request and the questions and answers, and a document generated using\nonly the initial request. Users indicated which document they preferred and\ngave feedback about their experience with the question-answering process. The\nfindings of this study show clear benefits to question-asking both in document\npreference and in the qualitative user experience. This study further shows\nthat users found more value in questions which were thought-provoking,\nopen-ended, or offered unique insights into the user's request as opposed to\nsimple information-gathering questions.",
    "categories": [
      "cs.CL",
      "cs.AI"
    ],
    "primary_category": "cs.CL",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2407.12017v2",
    "published_date": "2024-06-27 07:16:46 UTC",
    "updated_date": "2024-08-15 07:12:33 UTC"
  },
  {
    "arxiv_id": "2406.18944v4",
    "title": "Rethinking and Defending Protective Perturbation in Personalized Diffusion Models",
    "authors": [
      "Yixin Liu",
      "Ruoxi Chen",
      "Xun Chen",
      "Lichao Sun"
    ],
    "abstract": "Personalized diffusion models (PDMs) have become prominent for adapting\npretrained text-to-image models to generate images of specific subjects using\nminimal training data. However, PDMs are susceptible to minor adversarial\nperturbations, leading to significant degradation when fine-tuned on corrupted\ndatasets. These vulnerabilities are exploited to create protective\nperturbations that prevent unauthorized image generation. Existing purification\nmethods attempt to mitigate this issue but often over-purify images, resulting\nin information loss. In this work, we conduct an in-depth analysis of the\nfine-tuning process of PDMs through the lens of shortcut learning. We\nhypothesize and empirically demonstrate that adversarial perturbations induce a\nlatent-space misalignment between images and their text prompts in the CLIP\nembedding space. This misalignment causes the model to erroneously associate\nnoisy patterns with unique identifiers during fine-tuning, resulting in poor\ngeneralization. Based on these insights, we propose a systematic defense\nframework that includes data purification and contrastive decoupling learning.\nWe first employ off-the-shelf image restoration techniques to realign images\nwith their original semantic meanings in latent space. Then, we introduce\ncontrastive decoupling learning with noise tokens to decouple the learning of\npersonalized concepts from spurious noise patterns. Our study not only uncovers\nfundamental shortcut learning vulnerabilities in PDMs but also provides a\ncomprehensive evaluation framework for developing stronger protection. Our\nextensive evaluation demonstrates its superiority over existing purification\nmethods and stronger robustness against adaptive perturbation.",
    "categories": [
      "cs.CV",
      "cs.AI",
      "cs.CR"
    ],
    "primary_category": "cs.CV",
    "comment": "Our code is available at\n  https://github.com/liuyixin-louis/DiffShortcut",
    "pdf_url": "http://arxiv.org/pdf/2406.18944v4",
    "published_date": "2024-06-27 07:14:14 UTC",
    "updated_date": "2024-10-03 03:35:53 UTC"
  },
  {
    "arxiv_id": "2406.18939v1",
    "title": "Evaluating AI Group Fairness: a Fuzzy Logic Perspective",
    "authors": [
      "Emmanouil Krasanakis",
      "Symeon Papadopoulos"
    ],
    "abstract": "Artificial intelligence systems often address fairness concerns by evaluating\nand mitigating measures of group discrimination, for example that indicate\nbiases against certain genders or races. However, what constitutes group\nfairness depends on who is asked and the social context, whereas definitions\nare often relaxed to accept small deviations from the statistical constraints\nthey set out to impose. Here we decouple definitions of group fairness both\nfrom the context and from relaxation-related uncertainty by expressing them in\nthe axiomatic system of Basic fuzzy Logic (BL) with loosely understood\npredicates, like encountering group members. We then evaluate the definitions\nin subclasses of BL, such as Product or Lukasiewicz logics. Evaluation produces\ncontinuous instead of binary truth values by choosing the logic subclass and\ntruth values for predicates that reflect uncertain context-specific beliefs,\nsuch as stakeholder opinions gathered through questionnaires. Internally, it\nfollows logic-specific rules to compute the truth values of definitions. We\nshow that commonly held propositions standardize the resulting mathematical\nformulas and we transcribe logic and truth value choices to layperson terms, so\nthat anyone can answer them. We also use our framework to study several\nliterature definitions of algorithmic fairness, for which we rationalize\nprevious expedient practices that are non-probabilistic and show how to\nre-interpret their formulas and parameters in new contexts.",
    "categories": [
      "cs.AI",
      "cs.CY",
      "cs.LG"
    ],
    "primary_category": "cs.AI",
    "comment": "preprint, 32 pages, 7 figures, 2 theorems, 6 appendices",
    "pdf_url": "http://arxiv.org/pdf/2406.18939v1",
    "published_date": "2024-06-27 07:11:48 UTC",
    "updated_date": "2024-06-27 07:11:48 UTC"
  },
  {
    "arxiv_id": "2406.18937v2",
    "title": "Federated Graph Semantic and Structural Learning",
    "authors": [
      "Wenke Huang",
      "Guancheng Wan",
      "Mang Ye",
      "Bo Du"
    ],
    "abstract": "Federated graph learning collaboratively learns a global graph neural network\nwith distributed graphs, where the non-independent and identically distributed\nproperty is one of the major challenges. Most relative arts focus on\ntraditional distributed tasks like images and voices, incapable of graph\nstructures. This paper firstly reveals that local client distortion is brought\nby both node-level semantics and graph-level structure. First, for node-level\nsemantics, we find that contrasting nodes from distinct classes is beneficial\nto provide a well-performing discrimination. We pull the local node towards the\nglobal node of the same class and push it away from the global node of\ndifferent classes. Second, we postulate that a well-structural graph neural\nnetwork possesses similarity for neighbors due to the inherent adjacency\nrelationships. However, aligning each node with adjacent nodes hinders\ndiscrimination due to the potential class inconsistency. We transform the\nadjacency relationships into the similarity distribution and leverage the\nglobal model to distill the relation knowledge into the local model, which\npreserves the structural information and discriminability of the local model.\nEmpirical results on three graph datasets manifest the superiority of the\nproposed method over its counterparts.",
    "categories": [
      "cs.LG",
      "cs.AI"
    ],
    "primary_category": "cs.LG",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2406.18937v2",
    "published_date": "2024-06-27 07:08:28 UTC",
    "updated_date": "2024-06-29 18:17:40 UTC"
  },
  {
    "arxiv_id": "2407.12016v1",
    "title": "LLM-based Frameworks for API Argument Filling in Task-Oriented Conversational Systems",
    "authors": [
      "Jisoo Mok",
      "Mohammad Kachuee",
      "Shuyang Dai",
      "Shayan Ray",
      "Tara Taghavi",
      "Sungroh Yoon"
    ],
    "abstract": "Task-orientated conversational agents interact with users and assist them via\nleveraging external APIs. A typical task-oriented conversational system can be\nbroken down into three phases: external API selection, argument filling, and\nresponse generation. The focus of our work is the task of argument filling,\nwhich is in charge of accurately providing arguments required by the selected\nAPI. Upon comprehending the dialogue history and the pre-defined API schema,\nthe argument filling task is expected to provide the external API with the\nnecessary information to generate a desirable agent action. In this paper, we\nstudy the application of Large Language Models (LLMs) for the problem of API\nargument filling task. Our initial investigation reveals that LLMs require an\nadditional grounding process to successfully perform argument filling,\ninspiring us to design training and prompting frameworks to ground their\nresponses. Our experimental results demonstrate that when paired with proposed\ntechniques, the argument filling performance of LLMs noticeably improves,\npaving a new way toward building an automated argument filling framework.",
    "categories": [
      "cs.CL",
      "cs.AI"
    ],
    "primary_category": "cs.CL",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2407.12016v1",
    "published_date": "2024-06-27 06:54:53 UTC",
    "updated_date": "2024-06-27 06:54:53 UTC"
  },
  {
    "arxiv_id": "2407.09544v1",
    "title": "A Transformer-Based Multi-Stream Approach for Isolated Iranian Sign Language Recognition",
    "authors": [
      "Ali Ghadami",
      "Alireza Taheri",
      "Ali Meghdari"
    ],
    "abstract": "Sign language is an essential means of communication for millions of people\naround the world and serves as their primary language. However, most\ncommunication tools are developed for spoken and written languages which can\ncause problems and difficulties for the deaf and hard of hearing community. By\ndeveloping a sign language recognition system, we can bridge this communication\ngap and enable people who use sign language as their main form of expression to\nbetter communicate with people and their surroundings. This recognition system\nincreases the quality of health services, improves public services, and creates\nequal opportunities for the deaf community. This research aims to recognize\nIranian Sign Language words with the help of the latest deep learning tools\nsuch as transformers. The dataset used includes 101 Iranian Sign Language words\nfrequently used in academic environments such as universities. The network used\nis a combination of early fusion and late fusion transformer encoder-based\nnetworks optimized with the help of genetic algorithm. The selected features to\ntrain this network include hands and lips key points, and the distance and\nangle between hands extracted from the sign videos. Also, in addition to the\ntraining model for the classes, the embedding vectors of words are used as\nmulti-task learning to have smoother and more efficient training. This model\nwas also tested on sentences generated from our word dataset using a windowing\ntechnique for sentence translation. Finally, the sign language training\nsoftware that provides real-time feedback to users with the help of the\ndeveloped model, which has 90.2% accuracy on test data, was introduced, and in\na survey, the effectiveness and efficiency of this type of sign language\nlearning software and the impact of feedback were investigated.",
    "categories": [
      "cs.CL",
      "cs.AI",
      "cs.CV",
      "eess.IV"
    ],
    "primary_category": "cs.CL",
    "comment": "17 pages, 10 figures",
    "pdf_url": "http://arxiv.org/pdf/2407.09544v1",
    "published_date": "2024-06-27 06:54:25 UTC",
    "updated_date": "2024-06-27 06:54:25 UTC"
  },
  {
    "arxiv_id": "2406.18930v1",
    "title": "Reasoning About Action and Change",
    "authors": [
      "Florence Dupin de Saint-Cyr",
      "Andreas Herzig",
      "J√©r√¥me Lang",
      "Pierre Marquis"
    ],
    "abstract": "The purpose of this book is to provide an overview of AI research, ranging\nfrom basic work to interfaces and applications, with as much emphasis on\nresults as on current issues. It is aimed at an audience of master students and\nPh.D. students, and can be of interest as well for researchers and engineers\nwho want to know more about AI. The book is split into three volumes.",
    "categories": [
      "cs.AI",
      "cs.DM",
      "cs.LO",
      "cs.SC"
    ],
    "primary_category": "cs.AI",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2406.18930v1",
    "published_date": "2024-06-27 06:53:28 UTC",
    "updated_date": "2024-06-27 06:53:28 UTC"
  },
  {
    "arxiv_id": "2406.18924v1",
    "title": "Learning Pareto Set for Multi-Objective Continuous Robot Control",
    "authors": [
      "Tianye Shu",
      "Ke Shang",
      "Cheng Gong",
      "Yang Nan",
      "Hisao Ishibuchi"
    ],
    "abstract": "For a control problem with multiple conflicting objectives, there exists a\nset of Pareto-optimal policies called the Pareto set instead of a single\noptimal policy. When a multi-objective control problem is continuous and\ncomplex, traditional multi-objective reinforcement learning (MORL) algorithms\nsearch for many Pareto-optimal deep policies to approximate the Pareto set,\nwhich is quite resource-consuming. In this paper, we propose a simple and\nresource-efficient MORL algorithm that learns a continuous representation of\nthe Pareto set in a high-dimensional policy parameter space using a single\nhypernet. The learned hypernet can directly generate various well-trained\npolicy networks for different user preferences. We compare our method with two\nstate-of-the-art MORL algorithms on seven multi-objective continuous robot\ncontrol problems. Experimental results show that our method achieves the best\noverall performance with the least training parameters. An interesting\nobservation is that the Pareto set is well approximated by a curved line or\nsurface in a high-dimensional parameter space. This observation will provide\ninsight for researchers to design new MORL algorithms.",
    "categories": [
      "cs.AI",
      "cs.LG",
      "cs.RO"
    ],
    "primary_category": "cs.AI",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2406.18924v1",
    "published_date": "2024-06-27 06:31:51 UTC",
    "updated_date": "2024-06-27 06:31:51 UTC"
  },
  {
    "arxiv_id": "2407.00101v1",
    "title": "Hybrid Approach to Parallel Stochastic Gradient Descent",
    "authors": [
      "Aakash Sudhirbhai Vora",
      "Dhrumil Chetankumar Joshi",
      "Aksh Kantibhai Patel"
    ],
    "abstract": "Stochastic Gradient Descent is used for large datasets to train models to\nreduce the training time. On top of that data parallelism is widely used as a\nmethod to efficiently train neural networks using multiple worker nodes in\nparallel. Synchronous and asynchronous approach to data parallelism is used by\nmost systems to train the model in parallel. However, both of them have their\ndrawbacks. We propose a third approach to data parallelism which is a hybrid\nbetween synchronous and asynchronous approaches, using both approaches to train\nthe neural network. When the threshold function is selected appropriately to\ngradually shift all parameter aggregation from asynchronous to synchronous, we\nshow that in a given time period our hybrid approach outperforms both\nasynchronous and synchronous approaches.",
    "categories": [
      "cs.LG",
      "cs.AI",
      "cs.CC",
      "cs.DC",
      "cs.NE"
    ],
    "primary_category": "cs.LG",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2407.00101v1",
    "published_date": "2024-06-27 06:28:30 UTC",
    "updated_date": "2024-06-27 06:28:30 UTC"
  },
  {
    "arxiv_id": "2406.18922v2",
    "title": "Time Matters: Scaling Laws for Any Budget",
    "authors": [
      "Itay Inbar",
      "Luke Sernau"
    ],
    "abstract": "A primary cost driver for training large models is wall-clock training time.\nWe show that popular time estimates based on FLOPs are poor estimates, and\nconstruct a more accurate proxy based on memory copies. This allows us to\naccurately estimate the training speed of a transformer model from its\nhyperparameters. Combined with a scaling law curve like Chinchilla, this allows\nus to accurately predict the final loss of a model from a simple equation. We\nshow that this expression is accurate across a wide range of model\nhyperparameter values, enabling us to analytically make architectural decisions\nand train models more efficiently. Crucially, this analysis predicts that in\ncontrast to existing literature, models should be wider rather than deeper, as\nthe benefits of speed outweigh the benefits of depth.",
    "categories": [
      "cs.LG",
      "cs.AI"
    ],
    "primary_category": "cs.LG",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2406.18922v2",
    "published_date": "2024-06-27 06:26:22 UTC",
    "updated_date": "2024-10-23 22:56:39 UTC"
  },
  {
    "arxiv_id": "2406.18916v2",
    "title": "TrustUQA: A Trustful Framework for Unified Structured Data Question Answering",
    "authors": [
      "Wen Zhang",
      "Long Jin",
      "Yushan Zhu",
      "Jiaoyan Chen",
      "Zhiwei Huang",
      "Junjie Wang",
      "Yin Hua",
      "Lei Liang",
      "Huajun Chen"
    ],
    "abstract": "Natural language question answering (QA) over structured data sources such as\ntables and knowledge graphs have been widely investigated, especially with\nLarge Language Models (LLMs) in recent years. The main solutions include\nquestion to formal query parsing and retrieval-based answer generation.\nHowever, current methods of the former often suffer from weak generalization,\nfailing to dealing with multi-types of sources, while the later is limited in\ntrustfulness. In this paper, we propose TrustUQA, a trustful QA framework that\ncan simultaneously support multiple types of structured data in a unified way.\nTo this end, it adopts an LLM-friendly and unified knowledge representation\nmethod called Condition Graph(CG), and uses an LLM and demonstration-based\ntwo-level method for CG querying. For enhancement, it is also equipped with\ndynamic demonstration retrieval. We have evaluated TrustUQA with 5 benchmarks\ncovering 3 types of structured data. It outperforms 2 existing unified\nstructured data QA methods. In comparison with the baselines that are specific\nto one data type, it achieves state-of-the-art on 2 of the datasets. Further\nmore, we have demonstrated the potential of our method for more general QA\ntasks, QA over mixed structured data and QA across structured data. The code is\navailable at https://github.com/zjukg/TrustUQA.",
    "categories": [
      "cs.CL",
      "cs.AI"
    ],
    "primary_category": "cs.CL",
    "comment": "Accepted by AAAI 2025",
    "pdf_url": "http://arxiv.org/pdf/2406.18916v2",
    "published_date": "2024-06-27 06:13:05 UTC",
    "updated_date": "2024-12-13 15:15:46 UTC"
  },
  {
    "arxiv_id": "2406.18900v1",
    "title": "The Rise of Artificial Intelligence in Educational Measurement: Opportunities and Ethical Challenges",
    "authors": [
      "Okan Bulut",
      "Maggie Beiting-Parrish",
      "Jodi M. Casabianca",
      "Sharon C. Slater",
      "Hong Jiao",
      "Dan Song",
      "Christopher M. Ormerod",
      "Deborah Gbemisola Fabiyi",
      "Rodica Ivan",
      "Cole Walsh",
      "Oscar Rios",
      "Joshua Wilson",
      "Seyma N. Yildirim-Erbasli",
      "Tarid Wongvorachan",
      "Joyce Xinle Liu",
      "Bin Tan",
      "Polina Morilova"
    ],
    "abstract": "The integration of artificial intelligence (AI) in educational measurement\nhas revolutionized assessment methods, enabling automated scoring, rapid\ncontent analysis, and personalized feedback through machine learning and\nnatural language processing. These advancements provide timely, consistent\nfeedback and valuable insights into student performance, thereby enhancing the\nassessment experience. However, the deployment of AI in education also raises\nsignificant ethical concerns regarding validity, reliability, transparency,\nfairness, and equity. Issues such as algorithmic bias and the opacity of AI\ndecision-making processes pose risks of perpetuating inequalities and affecting\nassessment outcomes. Responding to these concerns, various stakeholders,\nincluding educators, policymakers, and organizations, have developed guidelines\nto ensure ethical AI use in education. The National Council of Measurement in\nEducation's Special Interest Group on AI in Measurement and Education (AIME)\nalso focuses on establishing ethical standards and advancing research in this\narea. In this paper, a diverse group of AIME members examines the ethical\nimplications of AI-powered tools in educational measurement, explores\nsignificant challenges such as automation bias and environmental impact, and\nproposes solutions to ensure AI's responsible and effective use in education.",
    "categories": [
      "cs.CY",
      "cs.AI"
    ],
    "primary_category": "cs.CY",
    "comment": "59 pages, 3 figures, a joint work of the Special Interest Group on\n  Artificial Intelligence in Measurement and Education (AIME) from the National\n  Council of Measurement in Education (NCME)",
    "pdf_url": "http://arxiv.org/pdf/2406.18900v1",
    "published_date": "2024-06-27 05:28:40 UTC",
    "updated_date": "2024-06-27 05:28:40 UTC"
  },
  {
    "arxiv_id": "2406.18899v3",
    "title": "Autonomous Control of a Novel Closed Chain Five Bar Active Suspension via Deep Reinforcement Learning",
    "authors": [
      "Nishesh Singh",
      "Sidharth Ramesh",
      "Abhishek Shankar",
      "Jyotishka Duttagupta",
      "Leander Stephen D'Souza",
      "Sanjay Singh"
    ],
    "abstract": "Planetary exploration requires traversal in environments with rugged\nterrains. In addition, Mars rovers and other planetary exploration robots often\ncarry sensitive scientific experiments and components onboard, which must be\nprotected from mechanical harm. This paper deals with an active suspension\nsystem focused on chassis stabilisation and an efficient traversal method while\nencountering unavoidable obstacles. Soft Actor-Critic (SAC) was applied along\nwith Proportional Integral Derivative (PID) control to stabilise the chassis\nand traverse large obstacles at low speeds. The model uses the rover's distance\nfrom surrounding obstacles, the height of the obstacle, and the chassis'\norientation to actuate the control links of the suspension accurately.\nSimulations carried out in the Gazebo environment are used to validate the\nproposed active system.",
    "categories": [
      "cs.RO",
      "cs.AI",
      "I.2.9"
    ],
    "primary_category": "cs.RO",
    "comment": "15 pages, 11 figures",
    "pdf_url": "http://arxiv.org/pdf/2406.18899v3",
    "published_date": "2024-06-27 05:27:39 UTC",
    "updated_date": "2024-07-04 04:12:25 UTC"
  },
  {
    "arxiv_id": "2406.18898v2",
    "title": "360 in the Wild: Dataset for Depth Prediction and View Synthesis",
    "authors": [
      "Kibaek Park",
      "Francois Rameau",
      "Jaesik Park",
      "In So Kweon"
    ],
    "abstract": "The large abundance of perspective camera datasets facilitated the emergence\nof novel learning-based strategies for various tasks, such as camera\nlocalization, single image depth estimation, or view synthesis. However,\npanoramic or omnidirectional image datasets, including essential information,\nsuch as pose and depth, are mostly made with synthetic scenes. In this work, we\nintroduce a large scale 360$^{\\circ}$ videos dataset in the wild. This dataset\nhas been carefully scraped from the Internet and has been captured from various\nlocations worldwide. Hence, this dataset exhibits very diversified environments\n(e.g., indoor and outdoor) and contexts (e.g., with and without moving\nobjects). Each of the 25K images constituting our dataset is provided with its\nrespective camera's pose and depth map. We illustrate the relevance of our\ndataset for two main tasks, namely, single image depth estimation and view\nsynthesis.",
    "categories": [
      "cs.CV",
      "cs.AI"
    ],
    "primary_category": "cs.CV",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2406.18898v2",
    "published_date": "2024-06-27 05:26:38 UTC",
    "updated_date": "2024-07-05 02:56:10 UTC"
  },
  {
    "arxiv_id": "2407.00100v1",
    "title": "Enhancing In-Context Learning via Implicit Demonstration Augmentation",
    "authors": [
      "Xiaoling Zhou",
      "Wei Ye",
      "Yidong Wang",
      "Chaoya Jiang",
      "Zhemg Lee",
      "Rui Xie",
      "Shikun Zhang"
    ],
    "abstract": "The emergence of in-context learning (ICL) enables large pre-trained language\nmodels (PLMs) to make predictions for unseen inputs without updating\nparameters. Despite its potential, ICL's effectiveness heavily relies on the\nquality, quantity, and permutation of demonstrations, commonly leading to\nsuboptimal and unstable performance. In this paper, we tackle this challenge\nfor the first time from the perspective of demonstration augmentation.\nSpecifically, we start with enriching representations of demonstrations by\nleveraging their deep feature distribution. We then theoretically reveal that\nwhen the number of augmented copies approaches infinity, the augmentation is\napproximately equal to a novel logit calibration mechanism integrated with\nspecific statistical properties. This insight results in a simple yet highly\nefficient method that significantly improves the average and worst-case\naccuracy across diverse PLMs and tasks. Moreover, our method effectively\nreduces performance variance among varying demonstrations, permutations, and\ntemplates, and displays the capability to address imbalanced class\ndistributions.",
    "categories": [
      "cs.LG",
      "cs.AI",
      "cs.CL",
      "I.2.7"
    ],
    "primary_category": "cs.LG",
    "comment": "Accepted by ACL 2024 Main 19 pages,10 figures",
    "pdf_url": "http://arxiv.org/pdf/2407.00100v1",
    "published_date": "2024-06-27 05:25:46 UTC",
    "updated_date": "2024-06-27 05:25:46 UTC"
  },
  {
    "arxiv_id": "2407.12812v1",
    "title": "Building Understandable Messaging for Policy and Evidence Review (BUMPER) with AI",
    "authors": [
      "Katherine A. Rosenfeld",
      "Maike Sonnewald",
      "Sonia J. Jindal",
      "Kevin A. McCarthy",
      "Joshua L. Proctor"
    ],
    "abstract": "We introduce a framework for the use of large language models (LLMs) in\nBuilding Understandable Messaging for Policy and Evidence Review (BUMPER). LLMs\nare proving capable of providing interfaces for understanding and synthesizing\nlarge databases of diverse media. This presents an exciting opportunity to\nsupercharge the translation of scientific evidence into policy and action,\nthereby improving livelihoods around the world. However, these models also pose\nchallenges related to access, trust-worthiness, and accountability. The BUMPER\nframework is built atop a scientific knowledge base (e.g., documentation, code,\nsurvey data) by the same scientists (e.g., individual contributor, lab,\nconsortium). We focus on a solution that builds trustworthiness through\ntransparency, scope-limiting, explicit-checks, and uncertainty measures. LLMs\nare rapidly being adopted and consequences are poorly understood. The framework\naddresses open questions regarding the reliability of LLMs and their use in\nhigh-stakes applications. We provide a worked example in health policy for a\nmodel designed to inform measles control programs. We argue that this framework\ncan facilitate accessibility of and confidence in scientific evidence for\npolicymakers, drive a focus on policy-relevance and translatability for\nresearchers, and ultimately increase and accelerate the impact of scientific\nknowledge used for policy decisions.",
    "categories": [
      "cs.CL",
      "cs.AI"
    ],
    "primary_category": "cs.CL",
    "comment": "21 pages, 6 figures",
    "pdf_url": "http://arxiv.org/pdf/2407.12812v1",
    "published_date": "2024-06-27 05:03:03 UTC",
    "updated_date": "2024-06-27 05:03:03 UTC"
  },
  {
    "arxiv_id": "2407.01608v1",
    "title": "Deriva-ML: A Continuous FAIRness Approach to Reproducible Machine Learning Models",
    "authors": [
      "Zhiwei Li",
      "Carl Kesselman",
      "Mike D'Arch",
      "Michael Pazzani",
      "Benjamin Yizing Xu"
    ],
    "abstract": "Increasingly, artificial intelligence (AI) and machine learning (ML) are used\nin eScience applications [9]. While these approaches have great potential, the\nliterature has shown that ML-based approaches frequently suffer from results\nthat are either incorrect or unreproducible due to mismanagement or misuse of\ndata used for training and validating the models [12, 15]. Recognition of the\nnecessity of high-quality data for correct ML results has led to data-centric\nML approaches that shift the central focus from model development to creation\nof high-quality data sets to train and validate the models [14, 20]. However,\nthere are limited tools and methods available for data-centric approaches to\nexplore and evaluate ML solutions for eScience problems which often require\ncollaborative multidisciplinary teams working with models and data that will\nrapidly evolve as an investigation unfolds [1]. In this paper, we show how data\nmanagement tools based on the principle that all of the data for ML should be\nfindable, accessible, interoperable and reusable (i.e. FAIR [26]) can\nsignificantly improve the quality of data that is used for ML applications.\nWhen combined with best practices that apply these tools to the entire life\ncycle of an ML-based eScience investigation, we can significantly improve the\nability of an eScience team to create correct and reproducible ML solutions. We\npropose an architecture and implementation of such tools and demonstrate\nthrough two use cases how they can be used to improve ML-based eScience\ninvestigations.",
    "categories": [
      "cs.LG",
      "cs.AI",
      "cs.DB",
      "cs.HC",
      "cs.SE"
    ],
    "primary_category": "cs.LG",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2407.01608v1",
    "published_date": "2024-06-27 04:42:29 UTC",
    "updated_date": "2024-06-27 04:42:29 UTC"
  },
  {
    "arxiv_id": "2406.18884v1",
    "title": "Sequential three-way group decision-making for double hierarchy hesitant fuzzy linguistic term set",
    "authors": [
      "Nanfang Luo",
      "Qinghua Zhang",
      "Qin Xie",
      "Yutai Wang",
      "Longjun Yin",
      "Guoyin Wang"
    ],
    "abstract": "Group decision-making (GDM) characterized by complexity and uncertainty is an\nessential part of various life scenarios. Most existing researches lack tools\nto fuse information quickly and interpret decision results for partially formed\ndecisions. This limitation is particularly noticeable when there is a need to\nimprove the efficiency of GDM. To address this issue, a novel multi-level\nsequential three-way decision for group decision-making (S3W-GDM) method is\nconstructed from the perspective of granular computing. This method\nsimultaneously considers the vagueness, hesitation, and variation of GDM\nproblems under double hierarchy hesitant fuzzy linguistic term sets (DHHFLTS)\nenvironment. First, for fusing information efficiently, a novel multi-level\nexpert information fusion method is proposed, and the concepts of expert\ndecision table and the extraction/aggregation of decision-leveled information\nbased on the multi-level granularity are defined. Second, the neighborhood\ntheory, outranking relation and regret theory (RT) are utilized to redesign the\ncalculations of conditional probability and relative loss function. Then, the\ngranular structure of DHHFLTS based on the sequential three-way decision (S3WD)\nis defined to improve the decision-making efficiency, and the decision-making\nstrategy and interpretation of each decision-level are proposed. Furthermore,\nthe algorithm of S3W-GDM is given. Finally, an illustrative example of\ndiagnosis is presented, and the comparative and sensitivity analysis with other\nmethods are performed to verify the efficiency and rationality of the proposed\nmethod.",
    "categories": [
      "cs.AI"
    ],
    "primary_category": "cs.AI",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2406.18884v1",
    "published_date": "2024-06-27 04:33:26 UTC",
    "updated_date": "2024-06-27 04:33:26 UTC"
  },
  {
    "arxiv_id": "2406.18859v1",
    "title": "Two-Pronged Human Evaluation of ChatGPT Self-Correction in Radiology Report Simplification",
    "authors": [
      "Ziyu Yang",
      "Santhosh Cherian",
      "Slobodan Vucetic"
    ],
    "abstract": "Radiology reports are highly technical documents aimed primarily at\ndoctor-doctor communication. There has been an increasing interest in sharing\nthose reports with patients, necessitating providing them patient-friendly\nsimplifications of the original reports. This study explores the suitability of\nlarge language models in automatically generating those simplifications. We\nexamine the usefulness of chain-of-thought and self-correction prompting\nmechanisms in this domain. We also propose a new evaluation protocol that\nemploys radiologists and laypeople, where radiologists verify the factual\ncorrectness of simplifications, and laypeople assess simplicity and\ncomprehension. Our experimental results demonstrate the effectiveness of\nself-correction prompting in producing high-quality simplifications. Our\nfindings illuminate the preferences of radiologists and laypeople regarding\ntext simplification, informing future research on this topic.",
    "categories": [
      "cs.CL",
      "cs.AI"
    ],
    "primary_category": "cs.CL",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2406.18859v1",
    "published_date": "2024-06-27 03:05:35 UTC",
    "updated_date": "2024-06-27 03:05:35 UTC"
  },
  {
    "arxiv_id": "2406.18856v1",
    "title": "FFN: a Fine-grained Chinese-English Financial Domain Parallel Corpus",
    "authors": [
      "Yuxin Fu",
      "Shijing Si",
      "Leyi Mai",
      "Xi-ang Li"
    ],
    "abstract": "Large Language Models (LLMs) have stunningly advanced the field of machine\ntranslation, though their effectiveness within the financial domain remains\nlargely underexplored. To probe this issue, we constructed a fine-grained\nChinese-English parallel corpus of financial news called FFN. We acquired\nfinancial news articles spanning between January 1st, 2014, to December 31,\n2023, from mainstream media websites such as CNN, FOX, and China Daily. The\ndataset consists of 1,013 main text and 809 titles, all of which have been\nmanually corrected. We measured the translation quality of two LLMs -- ChatGPT\nand ERNIE-bot, utilizing BLEU, TER and chrF scores as the evaluation metrics.\nFor comparison, we also trained an OpenNMT model based on our dataset. We\ndetail problems of LLMs and provide in-depth analysis, intending to stimulate\nfurther research and solutions in this largely uncharted territory. Our\nresearch underlines the need to optimize LLMs within the specific field of\nfinancial translation to ensure accuracy and quality.",
    "categories": [
      "cs.CL",
      "cs.AI",
      "cs.CE"
    ],
    "primary_category": "cs.CL",
    "comment": "a simplified version of this paper is accepted by International\n  Conference on Asian Language Processing 2024",
    "pdf_url": "http://arxiv.org/pdf/2406.18856v1",
    "published_date": "2024-06-27 02:53:55 UTC",
    "updated_date": "2024-06-27 02:53:55 UTC"
  },
  {
    "arxiv_id": "2407.01606v1",
    "title": "On Discrete Prompt Optimization for Diffusion Models",
    "authors": [
      "Ruochen Wang",
      "Ting Liu",
      "Cho-Jui Hsieh",
      "Boqing Gong"
    ],
    "abstract": "This paper introduces the first gradient-based framework for prompt\noptimization in text-to-image diffusion models. We formulate prompt engineering\nas a discrete optimization problem over the language space. Two major\nchallenges arise in efficiently finding a solution to this problem: (1)\nEnormous Domain Space: Setting the domain to the entire language space poses\nsignificant difficulty to the optimization process. (2) Text Gradient:\nEfficiently computing the text gradient is challenging, as it requires\nbackpropagating through the inference steps of the diffusion model and a\nnon-differentiable embedding lookup table. Beyond the problem formulation, our\nmain technical contributions lie in solving the above challenges. First, we\ndesign a family of dynamically generated compact subspaces comprised of only\nthe most relevant words to user input, substantially restricting the domain\nspace. Second, we introduce \"Shortcut Text Gradient\" -- an effective\nreplacement for the text gradient that can be obtained with constant memory and\nruntime. Empirical evaluation on prompts collected from diverse sources\n(DiffusionDB, ChatGPT, COCO) suggests that our method can discover prompts that\nsubstantially improve (prompt enhancement) or destroy (adversarial attack) the\nfaithfulness of images generated by the text-to-image diffusion model.",
    "categories": [
      "cs.LG",
      "cs.AI",
      "cs.CL",
      "cs.CV",
      "stat.ML",
      "68T01"
    ],
    "primary_category": "cs.LG",
    "comment": "ICML 2024. Code available at\n  https://github.com/ruocwang/dpo-diffusion",
    "pdf_url": "http://arxiv.org/pdf/2407.01606v1",
    "published_date": "2024-06-27 02:53:01 UTC",
    "updated_date": "2024-06-27 02:53:01 UTC"
  },
  {
    "arxiv_id": "2406.18851v1",
    "title": "LICO: Large Language Models for In-Context Molecular Optimization",
    "authors": [
      "Tung Nguyen",
      "Aditya Grover"
    ],
    "abstract": "Optimizing black-box functions is a fundamental problem in science and\nengineering. To solve this problem, many approaches learn a surrogate function\nthat estimates the underlying objective from limited historical evaluations.\nLarge Language Models (LLMs), with their strong pattern-matching capabilities\nvia pretraining on vast amounts of data, stand out as a potential candidate for\nsurrogate modeling. However, directly prompting a pretrained language model to\nproduce predictions is not feasible in many scientific domains due to the\nscarcity of domain-specific data in the pretraining corpora and the challenges\nof articulating complex problems in natural language. In this work, we\nintroduce LICO, a general-purpose model that extends arbitrary base LLMs for\nblack-box optimization, with a particular application to the molecular domain.\nTo achieve this, we equip the language model with a separate embedding layer\nand prediction layer, and train the model to perform in-context predictions on\na diverse set of functions defined over the domain. Once trained, LICO can\ngeneralize to unseen molecule properties simply via in-context prompting. LICO\nachieves state-of-the-art performance on PMO, a challenging molecular\noptimization benchmark comprising over 20 objective functions.",
    "categories": [
      "cs.LG",
      "cs.AI",
      "physics.chem-ph",
      "q-bio.BM",
      "q-bio.QM"
    ],
    "primary_category": "cs.LG",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2406.18851v1",
    "published_date": "2024-06-27 02:43:18 UTC",
    "updated_date": "2024-06-27 02:43:18 UTC"
  },
  {
    "arxiv_id": "2407.12015v1",
    "title": "The Great AI Witch Hunt: Reviewers Perception and (Mis)Conception of Generative AI in Research Writing",
    "authors": [
      "Hilda Hadan",
      "Derrick Wang",
      "Reza Hadi Mogavi",
      "Joseph Tu",
      "Leah Zhang-Kennedy",
      "Lennart E. Nacke"
    ],
    "abstract": "Generative AI (GenAI) use in research writing is growing fast. However, it is\nunclear how peer reviewers recognize or misjudge AI-augmented manuscripts. To\ninvestigate the impact of AI-augmented writing on peer reviews, we conducted a\nsnippet-based online survey with 17 peer reviewers from top-tier HCI\nconferences. Our findings indicate that while AI-augmented writing improves\nreadability, language diversity, and informativeness, it often lacks research\ndetails and reflective insights from authors. Reviewers consistently struggled\nto distinguish between human and AI-augmented writing but their judgements\nremained consistent. They noted the loss of a \"human touch\" and subjective\nexpressions in AI-augmented writing. Based on our findings, we advocate for\nreviewer guidelines that promote impartial evaluations of submissions,\nregardless of any personal biases towards GenAI. The quality of the research\nitself should remain a priority in reviews, regardless of any preconceived\nnotions about the tools used to create it. We emphasize that researchers must\nmaintain their authorship and control over the writing process, even when using\nGenAI's assistance.",
    "categories": [
      "cs.CL",
      "cs.AI",
      "cs.HC"
    ],
    "primary_category": "cs.CL",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2407.12015v1",
    "published_date": "2024-06-27 02:38:25 UTC",
    "updated_date": "2024-06-27 02:38:25 UTC"
  },
  {
    "arxiv_id": "2406.18847v1",
    "title": "Learning Retrieval Augmentation for Personalized Dialogue Generation",
    "authors": [
      "Qiushi Huang",
      "Shuai Fu",
      "Xubo Liu",
      "Wenwu Wang",
      "Tom Ko",
      "Yu Zhang",
      "Lilian Tang"
    ],
    "abstract": "Personalized dialogue generation, focusing on generating highly tailored\nresponses by leveraging persona profiles and dialogue context, has gained\nsignificant attention in conversational AI applications. However, persona\nprofiles, a prevalent setting in current personalized dialogue datasets,\ntypically composed of merely four to five sentences, may not offer\ncomprehensive descriptions of the persona about the agent, posing a challenge\nto generate truly personalized dialogues. To handle this problem, we propose\n$\\textbf{L}$earning Retrieval $\\textbf{A}$ugmentation for\n$\\textbf{P}$ersonalized $\\textbf{D}$ial$\\textbf{O}$gue $\\textbf{G}$eneration\n($\\textbf{LAPDOG}$), which studies the potential of leveraging external\nknowledge for persona dialogue generation. Specifically, the proposed LAPDOG\nmodel consists of a story retriever and a dialogue generator. The story\nretriever uses a given persona profile as queries to retrieve relevant\ninformation from the story document, which serves as a supplementary context to\naugment the persona profile. The dialogue generator utilizes both the dialogue\nhistory and the augmented persona profile to generate personalized responses.\nFor optimization, we adopt a joint training framework that collaboratively\nlearns the story retriever and dialogue generator, where the story retriever is\noptimized towards desired ultimate metrics (e.g., BLEU) to retrieve content for\nthe dialogue generator to generate personalized responses. Experiments\nconducted on the CONVAI2 dataset with ROCStory as a supplementary data source\nshow that the proposed LAPDOG method substantially outperforms the baselines,\nindicating the effectiveness of the proposed method. The LAPDOG model code is\npublicly available for further exploration.\nhttps://github.com/hqsiswiliam/LAPDOG",
    "categories": [
      "cs.CL",
      "cs.AI",
      "cs.LG"
    ],
    "primary_category": "cs.CL",
    "comment": "Accepted to EMNLP-2023",
    "pdf_url": "http://arxiv.org/pdf/2406.18847v1",
    "published_date": "2024-06-27 02:38:13 UTC",
    "updated_date": "2024-06-27 02:38:13 UTC"
  },
  {
    "arxiv_id": "2406.18845v1",
    "title": "Retain, Blend, and Exchange: A Quality-aware Spatial-Stereo Fusion Approach for Event Stream Recognition",
    "authors": [
      "Lan Chen",
      "Dong Li",
      "Xiao Wang",
      "Pengpeng Shao",
      "Wei Zhang",
      "Yaowei Wang",
      "Yonghong Tian",
      "Jin Tang"
    ],
    "abstract": "Existing event stream-based pattern recognition models usually represent the\nevent stream as the point cloud, voxel, image, etc., and design various deep\nneural networks to learn their features. Although considerable results can be\nachieved in simple cases, however, the model performance may be limited by\nmonotonous modality expressions, sub-optimal fusion, and readout mechanisms. In\nthis paper, we propose a novel dual-stream framework for event stream-based\npattern recognition via differentiated fusion, termed EFV++. It models two\ncommon event representations simultaneously, i.e., event images and event\nvoxels. The spatial and three-dimensional stereo information can be learned\nseparately by utilizing Transformer and Graph Neural Network (GNN). We believe\nthe features of each representation still contain both efficient and redundant\nfeatures and a sub-optimal solution may be obtained if we directly fuse them\nwithout differentiation. Thus, we divide each feature into three levels and\nretain high-quality features, blend medium-quality features, and exchange\nlow-quality features. The enhanced dual features will be fed into the fusion\nTransformer together with bottleneck features. In addition, we introduce a\nnovel hybrid interaction readout mechanism to enhance the diversity of features\nas final representations. Extensive experiments demonstrate that our proposed\nframework achieves state-of-the-art performance on multiple widely used event\nstream-based classification datasets. Specifically, we achieve new\nstate-of-the-art performance on the Bullying10k dataset, i.e., $90.51\\%$, which\nexceeds the second place by $+2.21\\%$. The source code of this paper has been\nreleased on\n\\url{https://github.com/Event-AHU/EFV_event_classification/tree/EFVpp}.",
    "categories": [
      "cs.CV",
      "cs.AI",
      "cs.NE"
    ],
    "primary_category": "cs.CV",
    "comment": "In Peer Review, Journal Extension of PRCV 2023",
    "pdf_url": "http://arxiv.org/pdf/2406.18845v1",
    "published_date": "2024-06-27 02:32:46 UTC",
    "updated_date": "2024-06-27 02:32:46 UTC"
  },
  {
    "arxiv_id": "2407.11017v1",
    "title": "Direct-Inverse Prompting: Analyzing LLMs' Discriminative Capacity in Self-Improving Generation",
    "authors": [
      "Jihyun Janice Ahn",
      "Ryo Kamoi",
      "Lu Cheng",
      "Rui Zhang",
      "Wenpeng Yin"
    ],
    "abstract": "Mainstream LLM research has primarily focused on enhancing their generative\ncapabilities. However, even the most advanced LLMs experience uncertainty in\ntheir outputs, often producing varied results on different runs or when faced\nwith minor changes in input, despite no substantial change in content. Given\nmultiple responses from the same LLM to the same input, we advocate leveraging\nthe LLMs' discriminative capability to reduce this generative uncertainty,\naiding in identifying the correct answers. Specifically, we propose and analyze\nthree discriminative prompts: direct, inverse, and hybrid, to explore the\npotential of both closed-source and open-source LLMs in self-improving their\ngenerative performance on two benchmark datasets. Our insights reveal which\ndiscriminative prompt is most promising and when to use it. To our knowledge,\nthis is the first work to systematically analyze LLMs' discriminative capacity\nto address generative uncertainty.",
    "categories": [
      "cs.CL",
      "cs.AI",
      "cs.LG"
    ],
    "primary_category": "cs.CL",
    "comment": "4 pages, 3 tables",
    "pdf_url": "http://arxiv.org/pdf/2407.11017v1",
    "published_date": "2024-06-27 02:26:47 UTC",
    "updated_date": "2024-06-27 02:26:47 UTC"
  },
  {
    "arxiv_id": "2406.18839v1",
    "title": "Disentangling Knowledge-based and Visual Reasoning by Question Decomposition in KB-VQA",
    "authors": [
      "Elham J. Barezi",
      "Parisa Kordjamshidi"
    ],
    "abstract": "We study the Knowledge-Based visual question-answering problem, for which\ngiven a question, the models need to ground it into the visual modality to find\nthe answer. Although many recent works use question-dependent captioners to\nverbalize the given image and use Large Language Models to solve the VQA\nproblem, the research results show they are not reasonably performing for\nmulti-hop questions. Our study shows that replacing a complex question with\nseveral simpler questions helps to extract more relevant information from the\nimage and provide a stronger comprehension of it. Moreover, we analyze the\ndecomposed questions to find out the modality of the information that is\nrequired to answer them and use a captioner for the visual questions and LLMs\nas a general knowledge source for the non-visual KB-based questions. Our\nresults demonstrate the positive impact of using simple questions before\nretrieving visual or non-visual information. We have provided results and\nanalysis on three well-known VQA datasets including OKVQA, A-OKVQA, and KRVQA,\nand achieved up to 2% improvement in accuracy.",
    "categories": [
      "cs.AI"
    ],
    "primary_category": "cs.AI",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2406.18839v1",
    "published_date": "2024-06-27 02:19:38 UTC",
    "updated_date": "2024-06-27 02:19:38 UTC"
  },
  {
    "arxiv_id": "2407.15023v1",
    "title": "ViT LoS V2X: Vision Transformers for Environment-aware LoS Blockage Prediction for 6G Vehicular Networks",
    "authors": [
      "Ghazi Gharsallah",
      "Georges Kaddoum"
    ],
    "abstract": "As wireless communication technology progresses towards the sixth generation\n(6G), high-frequency millimeter-wave (mmWave) communication has emerged as a\npromising candidate for enabling vehicular networks. It offers high data rates\nand low-latency communication. However, obstacles such as buildings, trees, and\nother vehicles can cause signal attenuation and blockage, leading to\ncommunication failures that can result in fatal accidents or traffic\ncongestion. Predicting blockages is crucial for ensuring reliable and efficient\ncommunications. Furthermore, the advent of 6G technology is anticipated to\nintegrate advanced sensing capabilities, utilizing a variety of sensor types.\nThese sensors, ranging from traditional RF sensors to cameras and Lidar\nsensors, are expected to provide access to rich multimodal data, thereby\nenriching communication systems with a wealth of additional contextual\ninformation. Leveraging this multimodal data becomes essential for making\nprecise network management decisions, including the crucial task of blockage\ndetection. In this paper, we propose a Deep Learning (DL)-based approach that\ncombines Convolutional Neural Networks (CNNs) and customized Vision\nTransformers (ViTs) to effectively extract essential information from\nmultimodal data and predict blockages in vehicular networks. Our method\ncapitalizes on the synergistic strengths of CNNs and ViTs to extract features\nfrom time-series multimodal data, which include images and beam vectors. To\ncapture temporal dependencies between the extracted features and the blockage\nstate at future time steps, we employ a Gated Recurrent Unit (GRU)-based\narchitecture. Our results show that the proposed approach achieves high\naccuracy and outperforms state-of-the-art solutions, achieving more than $95\\%$\naccurate predictions.",
    "categories": [
      "cs.CV",
      "cs.AI",
      "cs.NI"
    ],
    "primary_category": "cs.CV",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2407.15023v1",
    "published_date": "2024-06-27 01:38:09 UTC",
    "updated_date": "2024-06-27 01:38:09 UTC"
  },
  {
    "arxiv_id": "2406.18817v1",
    "title": "Correspondence-Free Non-Rigid Point Set Registration Using Unsupervised Clustering Analysis",
    "authors": [
      "Mingyang Zhao",
      "Jingen Jiang",
      "Lei Ma",
      "Shiqing Xin",
      "Gaofeng Meng",
      "Dong-Ming Yan"
    ],
    "abstract": "This paper presents a novel non-rigid point set registration method that is\ninspired by unsupervised clustering analysis. Unlike previous approaches that\ntreat the source and target point sets as separate entities, we develop a\nholistic framework where they are formulated as clustering centroids and\nclustering members, separately. We then adopt Tikhonov regularization with an\n$\\ell_1$-induced Laplacian kernel instead of the commonly used Gaussian kernel\nto ensure smooth and more robust displacement fields. Our formulation delivers\nclosed-form solutions, theoretical guarantees, independence from dimensions,\nand the ability to handle large deformations. Subsequently, we introduce a\nclustering-improved Nystr\\\"om method to effectively reduce the computational\ncomplexity and storage of the Gram matrix to linear, while providing a rigorous\nbound for the low-rank approximation. Our method achieves high accuracy results\nacross various scenarios and surpasses competitors by a significant margin,\nparticularly on shapes with substantial deformations. Additionally, we\ndemonstrate the versatility of our method in challenging tasks such as shape\ntransfer and medical registration.",
    "categories": [
      "cs.CV",
      "cs.AI"
    ],
    "primary_category": "cs.CV",
    "comment": "[CVPR 2024 Highlight] Project and code at:\n  https://github.com/zikai1/CVPR24_PointSetReg",
    "pdf_url": "http://arxiv.org/pdf/2406.18817v1",
    "published_date": "2024-06-27 01:16:44 UTC",
    "updated_date": "2024-06-27 01:16:44 UTC"
  },
  {
    "arxiv_id": "2406.18814v3",
    "title": "Length Optimization in Conformal Prediction",
    "authors": [
      "Shayan Kiyani",
      "George Pappas",
      "Hamed Hassani"
    ],
    "abstract": "Conditional validity and length efficiency are two crucial aspects of\nconformal prediction (CP). Conditional validity ensures accurate uncertainty\nquantification for data subpopulations, while proper length efficiency ensures\nthat the prediction sets remain informative. Despite significant efforts to\naddress each of these issues individually, a principled framework that\nreconciles these two objectives has been missing in the CP literature. In this\npaper, we develop Conformal Prediction with Length-Optimization (CPL) - a novel\nand practical framework that constructs prediction sets with (near-) optimal\nlength while ensuring conditional validity under various classes of covariate\nshifts, including the key cases of marginal and group-conditional coverage. In\nthe infinite sample regime, we provide strong duality results which indicate\nthat CPL achieves conditional validity and length optimality. In the finite\nsample regime, we show that CPL constructs conditionally valid prediction sets.\nOur extensive empirical evaluations demonstrate the superior prediction set\nsize performance of CPL compared to state-of-the-art methods across diverse\nreal-world and synthetic datasets in classification, regression, and large\nlanguage model-based multiple choice question answering. An Implementation of\nour algorithm can be accessed at the following link:\nhttps://github.com/shayankiyani98/CP.",
    "categories": [
      "stat.ML",
      "cs.AI",
      "cs.LG",
      "stat.ME"
    ],
    "primary_category": "stat.ML",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2406.18814v3",
    "published_date": "2024-06-27 01:08:04 UTC",
    "updated_date": "2024-12-11 18:48:59 UTC"
  },
  {
    "arxiv_id": "2406.18812v1",
    "title": "A Survey on Privacy Attacks Against Digital Twin Systems in AI-Robotics",
    "authors": [
      "Ivan A. Fernandez",
      "Subash Neupane",
      "Trisha Chakraborty",
      "Shaswata Mitra",
      "Sudip Mittal",
      "Nisha Pillai",
      "Jingdao Chen",
      "Shahram Rahimi"
    ],
    "abstract": "Industry 4.0 has witnessed the rise of complex robots fueled by the\nintegration of Artificial Intelligence/Machine Learning (AI/ML) and Digital\nTwin (DT) technologies. While these technologies offer numerous benefits, they\nalso introduce potential privacy and security risks. This paper surveys privacy\nattacks targeting robots enabled by AI and DT models. Exfiltration and data\nleakage of ML models are discussed in addition to the potential extraction of\nmodels derived from first-principles (e.g., physics-based). We also discuss\ndesign considerations with DT-integrated robotics touching on the impact of ML\nmodel training, responsible AI and DT safeguards, data governance and ethical\nconsiderations on the effectiveness of these attacks. We advocate for a trusted\nautonomy approach, emphasizing the need to combine robotics, AI, and DT\ntechnologies with robust ethical frameworks and trustworthiness principles for\nsecure and reliable AI robotic systems.",
    "categories": [
      "cs.RO",
      "cs.AI"
    ],
    "primary_category": "cs.RO",
    "comment": "10 pages, 3 figures, 1 table",
    "pdf_url": "http://arxiv.org/pdf/2406.18812v1",
    "published_date": "2024-06-27 00:59:20 UTC",
    "updated_date": "2024-06-27 00:59:20 UTC"
  },
  {
    "arxiv_id": "2407.11015v1",
    "title": "Does ChatGPT Have a Mind?",
    "authors": [
      "Simon Goldstein",
      "Benjamin A. Levinstein"
    ],
    "abstract": "This paper examines the question of whether Large Language Models (LLMs) like\nChatGPT possess minds, focusing specifically on whether they have a genuine\nfolk psychology encompassing beliefs, desires, and intentions. We approach this\nquestion by investigating two key aspects: internal representations and\ndispositions to act. First, we survey various philosophical theories of\nrepresentation, including informational, causal, structural, and teleosemantic\naccounts, arguing that LLMs satisfy key conditions proposed by each. We draw on\nrecent interpretability research in machine learning to support these claims.\nSecond, we explore whether LLMs exhibit robust dispositions to perform actions,\na necessary component of folk psychology. We consider two prominent\nphilosophical traditions, interpretationism and representationalism, to assess\nLLM action dispositions. While we find evidence suggesting LLMs may satisfy\nsome criteria for having a mind, particularly in game-theoretic environments,\nwe conclude that the data remains inconclusive. Additionally, we reply to\nseveral skeptical challenges to LLM folk psychology, including issues of\nsensory grounding, the \"stochastic parrots\" argument, and concerns about\nmemorization. Our paper has three main upshots. First, LLMs do have robust\ninternal representations. Second, there is an open question to answer about\nwhether LLMs have robust action dispositions. Third, existing skeptical\nchallenges to LLM representation do not survive philosophical scrutiny.",
    "categories": [
      "cs.CL",
      "cs.AI"
    ],
    "primary_category": "cs.CL",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2407.11015v1",
    "published_date": "2024-06-27 00:21:16 UTC",
    "updated_date": "2024-06-27 00:21:16 UTC"
  },
  {
    "arxiv_id": "2406.18802v2",
    "title": "All Random Features Representations are Equivalent",
    "authors": [
      "Luke Sernau",
      "Silvano Bonacina",
      "Rif A. Saurous"
    ],
    "abstract": "Random features are a powerful technique for rewriting positive-definite\nkernels as linear products. They bring linear tools to bear in important\nnonlinear domains like KNNs and attention. Unfortunately, practical\nimplementations require approximating an expectation, usually via sampling.\nThis has led to the development of increasingly elaborate representations with\never lower sample error. We resolve this arms race by deriving an optimal\nsampling policy. Under this policy all random features representations have the\nsame approximation error, which we show is the lowest possible. This means that\nwe are free to choose whatever representation we please, provided we sample\noptimally.",
    "categories": [
      "cs.LG",
      "cs.AI"
    ],
    "primary_category": "cs.LG",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2406.18802v2",
    "published_date": "2024-06-27 00:21:10 UTC",
    "updated_date": "2024-10-23 23:04:36 UTC"
  },
  {
    "arxiv_id": "2406.18800v2",
    "title": "Infinite Width Models That Work: Why Feature Learning Doesn't Matter as Much as You Think",
    "authors": [
      "Luke Sernau"
    ],
    "abstract": "Common infinite-width architectures such as Neural Tangent Kernels (NTKs)\nhave historically shown weak performance compared to finite models. This is\nusually attributed to the absence of feature learning. We show that this\nexplanation is insufficient. Specifically, we show that infinite width NTKs\nobviate the need for feature learning. They can learn identical behavior by\nselecting relevant subfeatures from their (infinite) frozen feature vector.\nFurthermore, we show experimentally that NTKs under-perform traditional finite\nmodels even when feature learning is artificially disabled. Instead, we show\nthat weak performance is at least partly due to the fact that existing\nconstructions depend on weak optimizers like SGD. We provide a new infinite\nwidth limit based on ADAM-like learning dynamics and demonstrate empirically\nthat the resulting models erase this performance gap.",
    "categories": [
      "cs.LG",
      "cs.AI"
    ],
    "primary_category": "cs.LG",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2406.18800v2",
    "published_date": "2024-06-27 00:15:54 UTC",
    "updated_date": "2024-10-23 23:08:50 UTC"
  }
]