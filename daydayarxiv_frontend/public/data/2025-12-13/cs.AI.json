{
  "date": "2025-12-13",
  "category": "cs.AI",
  "summary": "æ¬¢è¿æ¥åˆ° UTC æ—¶é—´ 2025-12-13 çš„ arXiv ä¸­æ–‡ TLDR å¿«æŠ¥ï¼\n\n**ä»Šæ—¥æ€»ç»“ï¼š**\nä»Šå¤©çš„ arXiv å……æ»¡äº†å¯¹æ™ºèƒ½ç³»ç»Ÿæœ¬è´¨çš„åæ€ä¸æ¶æ„ä¸Šçš„å¾®åˆ›æ–°ã€‚**ç†è®ºå±‚é¢**ï¼Œä¸€ç¯‡å…³äºâ€œç†µå´©æºƒï¼ˆEntropy Collapseï¼‰â€çš„è®ºæ–‡æå‡ºäº†æ™ºèƒ½ç³»ç»Ÿå¿…ç„¶èµ°å‘åƒµåŒ–çš„é€šç”¨å¤±æ•ˆæ¨¡å¼ï¼Œå‘äººæ·±çœï¼›**å¤§æ¨¡å‹æ¶æ„ä¸Š**ï¼Œç ”ç©¶è€…å‘ç°ä»…ä»…åœ¨æ¨ç†æ—¶â€œä¸¢å¼ƒä½ç½®ç¼–ç â€å°±èƒ½é›¶æ ·æœ¬æ‰©å±•ä¸Šä¸‹æ–‡ï¼Œæå…¶ç¡¬æ ¸ï¼›**ç¤¾ä¼šå±‚é¢**ï¼Œä¸€é¡¹å¤§è§„æ¨¡è°ƒæŸ¥æ­ç¤ºäº†â€œä¸­å›½åˆ¶é€ çš„å¤§æ¨¡å‹ï¼Œéª¨å­é‡Œæ˜¯ç¾å›½ä»·å€¼è§‚â€çš„ç°è±¡ã€‚æ­¤å¤–ï¼Œä»ç ´è§£æ¤­åœ†æ›²çº¿åŠ å¯†åˆ°å¥¥è¿ä¼šè·†æ‹³é“ AI è£åˆ¤ï¼Œä»Šå¤©çš„åº”ç”¨å±‚ç™¾èŠ±é½æ”¾ã€‚\n\nä¸‹é¢æˆ‘ä»¬è¿›å…¥æ·±åº¦é€Ÿè§ˆï¼š\n\n---\n\n### ğŸš€ æ ¸å¿ƒæ¶æ„ä¸å¤§æ¨¡å‹æœºç† (LLM Architecture & Mechanics)\n\n**1. [æ¨è] é€šè¿‡ä¸¢å¼ƒä½ç½®åµŒå…¥æ¥æ‰©å±•é¢„è®­ç»ƒ LLM çš„ä¸Šä¸‹æ–‡**\n**Title: Extending the Context of Pretrained LLMs by Dropping Their Positional Embeddings**\n*   **æ ¸å¿ƒå‘ç°ï¼š** è¿™æ˜¯ä¸€ä¸ªéå¸¸åç›´è§‰ä½†æœ‰æ•ˆçš„å‘ç°ï¼ˆDroPEï¼‰ã€‚ä½œè€…è®¤ä¸ºä½ç½®åµŒå…¥ï¼ˆPEsï¼‰ä¸»è¦åœ¨é¢„è®­ç»ƒé˜¶æ®µä½œä¸ºå½’çº³åç½®ï¼ˆInductive Biasï¼‰å¸®åŠ©æ”¶æ•›ï¼Œä½†åœ¨æµ‹è¯•æ—¶ï¼Œè¿‡åˆ†ä¾èµ– PE åè€Œé™åˆ¶äº†å‘æœªè§è¿‡çš„é•¿åºåˆ—æ³›åŒ–ã€‚\n*   **Implicationï¼š** åªè¦åœ¨é¢„è®­ç»ƒå**ä¸¢å¼ƒ** PE å¹¶è¿›è¡ŒçŸ­æš‚çš„æ ¡å‡†ï¼Œå°±èƒ½å®ç°é›¶æ ·æœ¬ï¼ˆZero-shotï¼‰çš„é•¿ä¸Šä¸‹æ–‡æ‰©å±•ï¼Œæ•ˆæœä¼˜äºç°æœ‰çš„ RoPE ç¼©æ”¾æ–¹æ³•ã€‚è¿™æŒ‘æˆ˜äº†æˆ‘ä»¬å¯¹ Transformer ä¸­ä½ç½®ä¿¡æ¯å¿…è¦æ€§çš„ä¼ ç»Ÿè®¤çŸ¥ã€‚\n\n**2. [ç†è®º] ç†µå´©æºƒï¼šæ™ºèƒ½ç³»ç»Ÿçš„æ™®éå¤±æ•ˆæ¨¡å¼**\n**Title: Entropy Collapse: A Universal Failure Mode of Intelligent Systems**\n*   **æ ¸å¿ƒå‘ç°ï¼š** è¿™æ˜¯ä¸€ç¯‡å®å¤§çš„è·¨å­¦ç§‘ç†è®ºæ–‡ç« ã€‚ä½œè€…æå‡ºâ€œç†µå´©æºƒâ€æ¦‚å¿µï¼Œè®¤ä¸ºæ— è®ºæ˜¯ AI æ¨¡å‹å´©æºƒï¼ˆModel Collapseï¼‰ã€ç»æµä½“åˆ¶åƒµåŒ–è¿˜æ˜¯ç”Ÿç‰©è¿›åŒ–ç“¶é¢ˆï¼Œæœ¬è´¨éƒ½æ˜¯**åé¦ˆæ”¾å¤§è¶…è¿‡äº†æœ‰é™çš„æ–°é¢–æ€§å†ç”Ÿ**ã€‚\n*   **Implicationï¼š** ç³»ç»Ÿä¼šä»é«˜ç†µé€‚åº”çŠ¶æ€æ€¥å‰§è½¬å˜ä¸ºä½ç†µå´©æºƒçŠ¶æ€ï¼ˆæ”¶æ•›åˆ°ä½ç»´æµå½¢ï¼‰ã€‚è¿™ä¸ºè§£é‡Šä¸ºä½• LLM åœ¨é€’å½’è®­ç»ƒä¸­ä¼šé€€åŒ–æä¾›äº†åšå®çš„åŠ¨åŠ›å­¦ç†è®ºåŸºç¡€ã€‚\n\n**3. [å¯¹é½] æ„Ÿå—å¼ºåº¦ä½†ä¸çŸ¥æ¥æºï¼šLLM çš„éƒ¨åˆ†å†…çœèƒ½åŠ›**\n**Title: Feeling the Strength but Not the Source: Partial Introspection in LLMs**\n*   **æ ¸å¿ƒå‘ç°ï¼š** é’ˆå¯¹ Anthropic å£°ç§°æ¨¡å‹èƒ½â€œå†…çœâ€å¹¶è¯†åˆ«æ³¨å…¥æ¦‚å¿µçš„è¯´æ³•ï¼Œè¿™é¡¹ç ”ç©¶è¿›è¡Œäº†å¤ç°å’Œå‹åŠ›æµ‹è¯•ã€‚ç»“è®ºæ˜¯ï¼šå†…çœæ˜¯è„†å¼±çš„ï¼ˆfragileï¼‰ã€‚\n*   **å…³é”®ç‚¹ï¼š** æ¨¡å‹å¯ä»¥è¯†åˆ«æ³¨å…¥æ¦‚å¿µå‘é‡çš„**å¼ºåº¦**ï¼ˆStrengthï¼‰ï¼Œä½†åœ¨è¢«é—®åŠæ¦‚å¿µæœ¬èº«æˆ–æ¢ä¸ª Prompt æ—¶ï¼Œèƒ½åŠ›ä¼šè¿…é€Ÿå´©æºƒã€‚è¿™è¡¨æ˜ç›®å‰çš„â€œè‡ªæˆ‘æŠ¥å‘Šâ€æ›´å¤šæ˜¯å¯¹å†…éƒ¨è¡¨å¾çš„ç®€å•å‡½æ•°è®¡ç®—ï¼Œè€ŒéçœŸæ­£çš„è‡ªæˆ‘æ„è¯†ã€‚\n\n**4. æ··åˆä¸“å®¶æ¨¡å‹çš„æ„å»ºä¸è®­ç»ƒæ¡†æ¶**\n**Title: MixtureKit: A General Framework for Composing, Training, and Visualizing Mixture-of-Experts Models**\n*   **æ ¸å¿ƒå‘ç°ï¼š** å‘å¸ƒäº†ä¸€ä¸ªæ¨¡å—åŒ–æ¡†æ¶ **MixtureKit**ï¼Œæ”¯æŒå°†ä»»æ„é¢„è®­ç»ƒæ¨¡å‹è½¬åŒ–ä¸º MoEã€‚æ”¯æŒä¼ ç»Ÿçš„ MoEã€BTXï¼ˆBranch-Train-Mixï¼‰å’Œ BTSï¼ˆBranch-Train-Stitchï¼‰ã€‚å¯¹äºæƒ³ä½æˆæœ¬é­”æ”¹æ¨¡å‹ç»“æ„çš„å·¥ç¨‹å¸ˆéå¸¸å®ç”¨ã€‚\n\n**5. è½¬æ¢åŒ¹é…çš„è®¾è®¡ç©ºé—´æ¢ç´¢**\n**Title: Exploring the Design Space of Transition Matching**\n*   **æ ¸å¿ƒå‘ç°ï¼š** Transition Matching (TM) æ˜¯ä¸€ç§æ¦‚æ‹¬äº†æ‰©æ•£æ¨¡å‹å’ŒæµåŒ¹é…çš„æ–°èŒƒå¼ã€‚ä½œè€…è®­ç»ƒäº† 56 ä¸ª 1.7B çš„æ–‡ç”Ÿå›¾æ¨¡å‹è¿›è¡Œå¤§è§„æ¨¡æ¶ˆèå®éªŒã€‚ç»“è®ºæ˜¯ï¼šMLP Head + ç‰¹å®šæ—¶é—´åŠ æƒ + é«˜é¢‘é‡‡æ ·å™¨æ˜¯ç›®å‰çš„ SOTA é…ç½®ã€‚\n\n---\n\n### ğŸŒ AI ç¤¾ä¼šå­¦ä¸ä¼¦ç† (Society, Ethics & Values)\n\n**6. [çƒ­ç‚¹] ä¸­å›½åˆ¶é€ ï¼Œç¾å›½æ€ç»´ï¼šä¸­å›½ LLM ä¸­æŒç»­å­˜åœ¨çš„ç¾å›½ä»·å€¼è§‚**\n**Title: Made-in China, Thinking in America: U.S. Values Persist in Chinese LLMs**\n*   **æ ¸å¿ƒå‘ç°ï¼š** è¿™æ˜¯ä¸€é¡¹å¤§è§„æ¨¡ç¤¾ä¼šå­¦è°ƒæŸ¥ã€‚ç ”ç©¶è€…å¯¹æ¯”äº† 10 ä¸ªä¸­ç¾é¡¶å°–æ¨¡å‹ï¼Œåˆ©ç”¨é“å¾·åŸºç¡€é—®å·ï¼ˆMFQ 2.0ï¼‰å’Œä¸–ç•Œä»·å€¼è§‚è°ƒæŸ¥ï¼ˆWVSï¼‰æµ‹è¯•ã€‚\n*   **ç»“è®ºï¼š** å³ä½¿æ˜¯ä¸­å›½å¼€å‘çš„å¤§æ¨¡å‹ï¼Œå…¶å›ç­”ä¹Ÿæ›´æ¥è¿‘ç¾å›½äººçš„ä»·å€¼è§‚ï¼Œè€Œéä¸­å›½äººçš„ä»·å€¼è§‚ã€‚å³ä¾¿ä½¿ç”¨ä¸­æ–‡ Prompt æˆ–å¼ºè¡Œè®¾å®šâ€œä¸­å›½è§’è‰²â€ï¼Œè¿™ç§ç¾å›½ä»·å€¼è§‚çš„åæ–œä¾ç„¶å­˜åœ¨ã€‚è¿™å¯¹åœ°ç¼˜æ”¿æ²»è½¯å®åŠ›ç«äº‰æå‡ºäº†ä¸¥å³»é—®é¢˜ï¼šæ•°æ®æºçš„ä¸»å¯¼åœ°ä½å¯èƒ½å†³å®šäº†æ¨¡å‹çš„â€œæ„è¯†å½¢æ€â€ã€‚\n\n**7. AI é€æ˜åº¦åœ°å›¾ï¼šå‰æ²¿æ¨¡å‹çš„åˆè§„æ€§è¯„ä¼°**\n**Title: AI Transparency Atlas: Framework, Scoring, and Real-Time Model Card Evaluation Pipeline**\n*   **æ ¸å¿ƒå‘ç°ï¼š** è¯„ä¼°äº† Gemini 3, Llama 4, GPT-5 ç­‰æ¨¡å‹ï¼Œå‘ç°å³ä¾¿å‰æ²¿å®éªŒå®¤ï¼ˆxAI, Microsoft, Anthropicï¼‰çš„åˆè§„ç‡ä¹Ÿä»…çº¦ 80%ï¼Œå¤§å¤šæ•°æä¾›å•†ä½äº 60%ã€‚æœ€ç¼ºä¹é€æ˜åº¦çš„æ˜¯ï¼šæ¬ºéª—è¡Œä¸ºã€å¹»è§‰ç‡å’Œå„¿ç«¥å®‰å…¨è¯„ä¼°ã€‚\n\n---\n\n### ğŸ”¬ AI for Science (Bio & Physics)\n\n**8. [ç¥ç»ç§‘å­¦] PROTONï¼šç”Ÿæˆç»åˆ†å­ã€ç±»å™¨å®˜å’Œä¸´åºŠéªŒè¯çš„ç¥ç»å­¦å‡è®¾**\n**Title: Graph AI generates neurological hypotheses validated in molecular, organoid, and clinical systems**\n*   **æ ¸å¿ƒå‘ç°ï¼š** æå‡ºäº†ä¸€ç§å¼‚æ„å›¾ Transformerï¼ˆPROTONï¼‰ï¼Œç”¨äºå¸•é‡‘æ£®ã€èºéƒç—‡å’Œé˜¿å°”èŒ¨æµ·é»˜ç—…çš„ç ”ç©¶ã€‚å®ƒä¸ä»…æ˜¯é¢„æµ‹ï¼Œè¿˜é€šè¿‡æ¹¿å®éªŒï¼ˆWet-labï¼‰éªŒè¯äº†å…¶æå‡ºçš„å‡è®¾ï¼Œä¾‹å¦‚é¢„æµ‹æŸäº›æ€è™«å‰‚å¯¹ç¥ç»å…ƒçš„æ¯’æ€§ï¼Œä»¥åŠç»´ç”Ÿç´  D3ï¼ˆcalcitriolï¼‰å¯¹èºéƒç—‡ç±»å™¨å®˜çš„æ½œåœ¨ç–—æ•ˆã€‚\n\n**9. [è›‹ç™½è´¨ç»„å­¦] OmniNovoï¼šä¿®é¥°è›‹ç™½è´¨ç»„çš„ç²¾å‡†ä»å¤´æµ‹åº**\n**Title: Accurate de novo sequencing of the modified proteome with OmniNovo**\n*   **æ ¸å¿ƒå‘ç°ï¼š** ä¸€ä¸ªç»Ÿä¸€çš„æ·±åº¦å­¦ä¹ æ¡†æ¶ï¼Œç”¨äºç›´æ¥ä»ä¸²è”è´¨è°±ä¸­è¿›è¡Œ Reference-free çš„è‚½æ®µæµ‹åºã€‚å®ƒå¯ä»¥è¯†åˆ«æœªçŸ¥çš„ç¿»è¯‘åä¿®é¥°ï¼ˆPTMsï¼‰ï¼Œç…§äº®äº†è›‹ç™½è´¨ç»„å­¦ä¸­çš„â€œæš—ç‰©è´¨â€ã€‚\n\n**10. é‡å­æ„ŸçŸ¥ç”Ÿæˆå¼ AI ç”¨äºææ–™å‘ç°**\n**Title: Quantum-Aware Generative AI for Materials Discovery: A Framework for Robust Exploration Beyond DFT Biases**\n*   **æ ¸å¿ƒå‘ç°ï¼š** ä¼ ç»Ÿ AI ææ–™å‘ç°å—é™äº DFTï¼ˆå¯†åº¦æ³›å‡½ç†è®ºï¼‰æ•°æ®çš„åå·®ã€‚æœ¬æ–‡æå‡ºäº†ä¸€ä¸ªå¤šä¿çœŸåº¦å­¦ä¹ æ¡†æ¶ï¼Œç»“åˆæ‰©æ•£æ¨¡å‹å’Œä¸»åŠ¨å­¦ä¹ ï¼Œä¸“é—¨å¯»æ‰¾é‚£äº› DFT é¢„æµ‹ä¸å‡†ä½†å¯èƒ½ç¨³å®šçš„å¼ºå…³è”ææ–™ä½“ç³»ã€‚\n\n---\n\n### ğŸ¤– å…·èº«æ™ºèƒ½ä¸ç³»ç»Ÿä¼˜åŒ– (Embodied AI & Systems)\n\n**11. [é«˜æ•ˆæ¨ç†] V-Rexï¼šæµå¼è§†é¢‘ LLM çš„å®æ—¶åŠ é€Ÿ**\n**Title: V-Rex: Real-Time Streaming Video LLM Acceleration via Dynamic KV Cache Retrieval**\n*   **æ ¸å¿ƒå‘ç°ï¼š** é’ˆå¯¹ Video LLM æ˜¾å­˜çˆ†ç‚¸çš„é—®é¢˜ï¼Œæå‡ºäº†è½¯ç¡¬ååŒè®¾è®¡ã€‚æ ¸å¿ƒç®—æ³• ReSV é€šè¿‡èšç±»å‡å°‘ KV Cacheï¼Œé…åˆä¸“ç”¨ç¡¬ä»¶åŠ é€Ÿå™¨ï¼Œåœ¨è¾¹ç¼˜è®¾å¤‡ä¸Šå®ç°äº† 3.9-8.3 FPS çš„æ¨ç†é€Ÿåº¦ï¼Œèƒ½æ•ˆæ¯” AGX Orin é«˜å‡º 18 å€ã€‚\n\n**12. å…·èº«æ™ºèƒ½ä¸­çš„ç‰¹æƒä¿¡æ¯åå·®**\n**Title: Emergence: Overcoming Privileged Information Bias in Asymmetric Embodied Agents via Active Querying**\n*   **æ ¸å¿ƒå‘ç°ï¼š** ç ”ç©¶äº†â€œçŸ¥è¯†çš„è¯…å’’â€ã€‚å½“ä¸€ä¸ªå…¨çŸ¥çš„ Leader æŒ‡å¯¼ä¸€ä¸ªä¼ æ„Ÿå™¨å—é™çš„ Follower æ—¶ï¼Œå¾€å¾€ä¼šå¤±è´¥ã€‚æ–‡ç« æå‡ºâ€œæ‹‰å¼â€ï¼ˆPull-basedï¼‰åè®®ï¼Œå³è®© Follower ä¸»åŠ¨æé—®æ¾„æ¸…ï¼Œæ¯” Leader å•å‘è¾“å‡ºæŒ‡ä»¤æ›´æœ‰æ•ˆã€‚\n\n**13. æ‰©æ•£ç­–ç•¥çš„å¼ºåŒ–æŠ•æœºè§£ç **\n**Title: TS-DP: Reinforcement Speculative Decoding For Temporal Adaptive Diffusion Policy Acceleration**\n*   **æ ¸å¿ƒå‘ç°ï¼š** å°†æŠ•æœºè§£ç ï¼ˆSpeculative Decodingï¼‰å¼•å…¥åˆ°å…·èº«æ§åˆ¶çš„æ‰©æ•£ç­–ç•¥ï¼ˆDiffusion Policyï¼‰ä¸­ã€‚åˆ©ç”¨ä¸€ä¸ªå°æ¨¡å‹ï¼ˆDrafterï¼‰å¿«é€Ÿç”Ÿæˆè‰ç¨¿ï¼Œå¤§æ¨¡å‹éªŒè¯ï¼Œå¹¶ç”¨ RL åŠ¨æ€è°ƒæ•´æ­¥æ•°ï¼Œå®ç°äº† 4 å€æ¨ç†åŠ é€Ÿã€‚\n\n---\n\n### ğŸ›¡ï¸ å®‰å…¨ä¸å¯†ç å­¦ (Security & Crypto)\n\n**14. [æœ‰ç‚¹æ ‡é¢˜å…š] Mageï¼šç”¨è·¨è½´ Transformer ç ´è§£æ¤­åœ†æ›²çº¿åŠ å¯†**\n**Title: Mage: Cracking Elliptic Curve Cryptography with Cross-Axis Transformers**\n*   **ç®€è¯„ï¼š** ä½œè€…å°è¯•ç”¨è¯­è¨€æ¨¡å‹æ¶æ„é€†å‘å…¬ç§é’¥ç”Ÿæˆè¿‡ç¨‹ã€‚è™½ç„¶é¢˜ç›®å¾ˆå“äººï¼Œä½†æ‘˜è¦ä¸­ä½¿ç”¨äº† \"It is my belief\" è¿™ç§éä¸¥è°¨æªè¾ï¼Œä¸”æµ‹è¯•ä¸»è¦é’ˆå¯¹ secp256r1ã€‚è¿™ç±»åŸºäº ML çš„å¯†ç åˆ†æé€šå¸¸åœ¨å°è§„æ¨¡æˆ–ç‰¹å®šæ¡ä»¶ä¸‹æœ‰æ•ˆï¼Œæ˜¯å¦çœŸçš„åŠ¨æ‘‡äº† ECC æ ¹åŸºéœ€å­˜ç–‘ï¼Œä½†æ€è·¯æœ‰è¶£ã€‚\n\n---\n\n### ğŸ„ å…¶ä»–æœ‰è¶£çš„è®ºæ–‡ (Quick Hits)\n\n*   **[ä½“è‚² AI] å¥¥è¿è·†æ‹³é“å®æ—¶è¸¢å‡»åˆ†ç±»** (Title: **AI-Driven Real-Time Kick Classification in Olympic Taekwondo Using Sensor Fusion**): é’ˆå¯¹è·†æ‹³é“æ¯”èµ›å˜å¾—â€œé™æ€ä¸”æ— èŠâ€çš„é—®é¢˜ï¼Œæå‡ºç”¨å¤šä¼ æ„Ÿå™¨èåˆ + AI æ¥è‡ªåŠ¨è¯„åˆ†å’Œè¯†åˆ«æŠ€æœ¯ï¼Œé¼“åŠ±æ›´åŠ¨æ€çš„è…¿æ³•ã€‚\n*   **[åˆ†å¸ƒå¼è®­ç»ƒ] CurvaDion** (Title: **CurvaDion: Curvature-Adaptive Distributed Orthonormalization**): é’ˆå¯¹å¤§è§„æ¨¡åˆ†å¸ƒå¼è®­ç»ƒï¼Œæå‡ºåªåœ¨æŸå¤±æ›²é¢æ›²ç‡å¤§çš„æ—¶å€™åŒæ­¥æ¢¯åº¦ï¼Œé€šä¿¡é‡å‡å°‘ 99%ã€‚\n*   **[æ¨èç³»ç»Ÿ] æ—¶é—´çº¦æŸä¸‹çš„æ¨è** (Title: **Time-Constrained Recommendations: Reinforcement Learning Strategies for E-Commerce**): è€ƒè™‘åˆ°ç”¨æˆ·çš„æµè§ˆæ—¶é—´æ˜¯æœ‰é™çš„é¢„ç®—ï¼Œç”¨ RL æ¥å¹³è¡¡æ¨èç‰©å“çš„ç›¸å…³æ€§å’Œç”¨æˆ·çš„è¯„ä¼°æˆæœ¬ã€‚\n\n---\n**ç»“è¯­ï¼š**\nä»Šå¤©çš„è®ºæ–‡è´¨é‡å¾ˆé«˜ã€‚ç‰¹åˆ«æ˜¯ #49 ä¸¢å¼ƒä½ç½®åµŒå…¥ å’Œ #55 MixtureKit å¯¹å¼€å‘è€…éå¸¸å®ç”¨ï¼Œè€Œ #19 ç†µå´©æºƒ å’Œ #50 ä»·å€¼è§‚ç ”ç©¶ åˆ™æä¾›äº†æ·±åº¦çš„æ€è€ƒç´ æã€‚å¸Œæœ›è¿™æœŸ TLDR èƒ½ä¸ºä½ èŠ‚çœæ—¶é—´ï¼Œç²¾å‡†å®šä½æ„Ÿå…´è¶£çš„è®ºæ–‡ã€‚æˆ‘ä»¬æ˜å¤©è§ï¼",
  "papers": [
    {
      "arxiv_id": "2512.14750v1",
      "title": "Multiscale Cross-Modal Mapping of Molecular, Pathologic, and Radiologic Phenotypes in Lipid-Deficient Clear Cell Renal CellCarcinoma",
      "title_zh": "è„‚è´¨ç¼ºä¹å‹é€æ˜ç»†èƒè‚¾ç»†èƒç™Œä¸­åˆ†å­ã€ç—…ç†åŠæ”¾å°„å­¦è¡¨å‹çš„å¤šå°ºåº¦è·¨æ¨¡æ€æ˜ å°„",
      "authors": [
        "Ying Cui",
        "Dongzhe Zheng",
        "Ke Yu",
        "Xiyin Zheng",
        "Xiaorui Wang",
        "Xinxiang Li",
        "Yan Gu",
        "Lin Fu",
        "Xinyi Chen",
        "Wenjie Mei",
        "Xin-Gui Peng"
      ],
      "abstract": "Clear cell renal cell carcinoma (ccRCC) exhibits extensive intratumoral heterogeneity on multiple biological scales, contributing to variable clinical outcomes and limiting the effectiveness of conventional TNM staging, which highlights the urgent need for multiscale integrative analytic frameworks. The lipid-deficient de-clear cell differentiated (DCCD) ccRCC subtype, defined by multi-omics analyses, is associated with adverse outcomes even in early-stage disease. Here, we establish a hierarchical cross-scale framework for the preoperative identification of DCCD-ccRCC. At the highest layer, cross-modal mapping transferred molecular signatures to histological and CT phenotypes, establishing a molecular-to-pathology-to-radiology supervisory bridge. Within this framework, each modality-specific model is designed to mirror the inherent hierarchical structure of tumor biology. PathoDCCD captured multi-scale microscopic features, from cellular morphology and tissue architecture to meso-regional organization. RadioDCCD integrated complementary macroscopic information by combining whole-tumor and its habitat-subregions radiomics with a 2D maximal-section heterogeneity metric. These nested models enabled integrated molecular subtype prediction and clinical risk stratification. Across five cohorts totaling 1,659 patients, PathoDCCD reliably recapitulated molecular subtypes, while RadioDCCD provided reliable preoperative prediction. The consistent predictions identified patients with the poorest clinical outcomes. This cross-scale paradigm unifies molecular biology, computational pathology, and quantitative radiology into a biologically grounded strategy for preoperative noninvasive molecular phenotyping of ccRCC.",
      "tldr_zh": "è¯¥ç ”ç©¶é’ˆå¯¹é€æ˜ç»†èƒè‚¾ç»†èƒç™Œ (ccRCC) çš„é«˜åº¦å†…æºæ€§å¼‚è´¨æ€§ï¼Œå¼€å‘äº†ä¸€ç§åˆ†å±‚è·¨å°ºåº¦æ¡†æ¶ (hierarchical cross-scale framework)ï¼Œæ—¨åœ¨æœ¯å‰è¯†åˆ«é¢„åä¸è‰¯çš„è„‚è´¨ç¼ºä¹å»é€æ˜ç»†èƒåˆ†åŒ– (DCCD) äºšå‹ã€‚è¯¥æ¡†æ¶é€šè¿‡è·¨æ¨¡æ€æ˜ å°„ (cross-modal mapping) å»ºç«‹äº†åˆ†å­ã€ç—…ç†ä¸æ”¾å°„å­¦è¡¨å‹ä¹‹é—´çš„ç›‘ç£æ¡¥æ¢ï¼Œä½¿å„æ¨¡æ€æ¨¡å‹èƒ½å¤Ÿåæ˜ è‚¿ç˜¤ç”Ÿç‰©å­¦çš„å±‚çº§ç»“æ„ã€‚PathoDCCD æ¨¡å‹è´Ÿè´£æ•è·ä»ç»†èƒå½¢æ€åˆ°ä¸­è§‚åŒºåŸŸç»„ç»‡çš„å¤šå°ºåº¦å¾®è§‚ç‰¹å¾ï¼Œè€Œ RadioDCCD æ¨¡å‹åˆ™ç»“åˆå…¨è‚¿ç˜¤åŠç”Ÿå¢ƒäºšåŒºçš„æ”¾å°„ç»„å­¦ä¿¡æ¯è¿›è¡Œå®è§‚åˆ†æã€‚åœ¨æ¶‰åŠ 1659 åæ‚£è€…çš„äº”ä¸ªé˜Ÿåˆ—éªŒè¯ä¸­ï¼ŒPathoDCCD æˆåŠŸå¤ç°äº†åˆ†å­äºšå‹ï¼Œè€Œ RadioDCCD å®ç°äº†å¯é çš„æœ¯å‰é¢„æµ‹ï¼Œèƒ½å¤Ÿæœ‰æ•ˆè¯†åˆ«ä¸´åºŠé¢„åæœ€å·®çš„æ‚£è€…ã€‚è¿™ä¸€è·¨å°ºåº¦èŒƒå¼æ•´åˆäº†åˆ†å­ç”Ÿç‰©å­¦ã€è®¡ç®—ç—…ç†å­¦ä¸å®šé‡æ”¾å°„å­¦ï¼Œä¸º ccRCC çš„æœ¯å‰æ— åˆ›åˆ†å­åˆ†å‹æä¾›äº†ä¸€ç§å…·æœ‰ç”Ÿç‰©å­¦ä¾æ®çš„åˆ›æ–°ç­–ç•¥ã€‚",
      "categories": [
        "q-bio.QM",
        "cs.AI"
      ],
      "primary_category": "q-bio.QM",
      "comment": "",
      "pdf_url": "https://arxiv.org/pdf/2512.14750v1",
      "published_date": "2025-12-13 23:49:41 UTC",
      "updated_date": "2025-12-13 23:49:41 UTC",
      "processing_status": "completed",
      "attempts": 1,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "llm_backup_calls": 0,
      "last_update": "2026-01-26T16:23:23.960419+00:00"
    },
    {
      "arxiv_id": "2512.12483v3",
      "title": "Mage: Cracking Elliptic Curve Cryptography with Cross-Axis Transformers",
      "title_zh": "Mageï¼šåˆ©ç”¨äº¤å‰è½´ Transformer ç ´è§£æ¤­åœ†æ›²çº¿å¯†ç å­¦",
      "authors": [
        "Lily Erickson"
      ],
      "abstract": "With the advent of machine learning and quantum computing, the 21st century has gone from a place of relative algorithmic security, to one of speculative unease and possibly, cyber catastrophe.\n  Modern algorithms like Elliptic Curve Cryptography (ECC) are the bastion of current cryptographic security protocols that form the backbone of consumer protection ranging from Hypertext Transfer Protocol Secure (HTTPS) in the modern internet browser, to cryptographic financial instruments like Bitcoin.\n  And there's been very little work put into testing the strength of these ciphers. Practically the only study that I could find was on side-channel recognition, a joint paper from the University of Milan, Italy and King's College, London\\cite{battistello2025ecc}.\n  These algorithms are already considered bulletproof by many consumers, but exploits already exist for them, and with computing power and distributed, federated compute on the rise, it's only a matter of time before these current bastions fade away into obscurity, and it's on all of us to stand up when we notice something is amiss, lest we see such passages claim victims in that process.\n  In this paper, we seek to explore the use of modern language model architecture in cracking the association between a known public key, and its associated private key, by intuitively learning to reverse engineer the public keypair generation process, effectively solving the curve.\n  Additonally, we attempt to ascertain modern machine learning's ability to memorize public-private secp256r1 keypairs, and to then test their ability to reverse engineer the public keypair generation process.\n  It is my belief that proof-for would be equally valuable as proof-against in either of these categories.\n  Finally, we'll conclude with some number crunching on where we see this particular field heading in the future.",
      "tldr_zh": "è¯¥ç ”ç©¶æ¢è®¨äº† Elliptic Curve Cryptography (ECC) åœ¨æœºå™¨å­¦ä¹ ä¸é‡å­è®¡ç®—èƒŒæ™¯ä¸‹çš„å®‰å…¨æ€§ï¼ŒæŒ‡å‡ºè™½ç„¶ ECC æ˜¯ HTTPS å’Œ Bitcoin ç­‰åè®®çš„æ ¸å¿ƒä¿éšœï¼Œä½†å…¶æŠ—æ”»å‡»èƒ½åŠ›çš„ç ”ç©¶å°šä¸å……åˆ†ã€‚ä¸ºæ­¤ï¼Œè®ºæ–‡æå‡ºäº† Mage æ¡†æ¶ï¼Œå°è¯•åˆ©ç”¨ Cross-Axis Transformers æ¶æ„æ¥ç ´è§£å·²çŸ¥ Public Key ä¸ Private Key ä¹‹é—´çš„å…³è”ã€‚é€šè¿‡å­¦ä¹ é€†å‘å·¥ç¨‹ Public Keypair çš„ç”Ÿæˆè¿‡ç¨‹ï¼Œè¯¥æ–¹æ³•æ—¨åœ¨è¯„ä¼°ç°ä»£æœºå™¨å­¦ä¹ æ¨¡å‹å¯¹ secp256r1 å¯†é’¥å¯¹çš„è®°å¿†èƒ½åŠ›åŠå…¶æ¨å¯¼ç”Ÿæˆé€»è¾‘çš„æ½œåŠ›ã€‚ç ”ç©¶å¼ºè°ƒï¼Œæ— è®ºæ˜¯è¯æ˜ç ´è§£çš„å¯èƒ½æ€§è¿˜æ˜¯æä¾›åè¯ï¼Œå¯¹äºåŠ å¯†ç®—æ³•å¼ºåº¦çš„æµ‹è¯•éƒ½è‡³å…³é‡è¦ã€‚æœ€åï¼Œè®ºæ–‡é€šè¿‡æ•°æ®åˆ†ææ¢è®¨äº†è¯¥é¢†åŸŸçš„æœªæ¥èµ°å‘ï¼Œä¸ºé˜²èŒƒæ½œåœ¨çš„ç½‘ç»œå®‰å…¨ç¾éš¾æä¾›äº†å‰ç»æ€§è§è§£ã€‚",
      "categories": [
        "cs.CR",
        "cs.AI"
      ],
      "primary_category": "cs.CR",
      "comment": "7 pages",
      "pdf_url": "https://arxiv.org/pdf/2512.12483v3",
      "published_date": "2025-12-13 22:45:35 UTC",
      "updated_date": "2026-01-01 20:09:52 UTC",
      "processing_status": "completed",
      "attempts": 1,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "llm_backup_calls": 0,
      "last_update": "2026-01-26T16:23:22.724969+00:00"
    },
    {
      "arxiv_id": "2512.13729v1",
      "title": "Composite Classifier-Free Guidance for Multi-Modal Conditioning in Wind Dynamics Super-Resolution",
      "title_zh": "é£åŠ¨åŠ›å­¦è¶…åˆ†è¾¨ç‡ä¸­é¢å‘å¤šæ¨¡æ€æ¡ä»¶çš„å¤åˆæ— åˆ†ç±»å™¨å¼•å¯¼",
      "authors": [
        "Jacob Schnell",
        "Aditya Makkar",
        "Gunadi Gani",
        "Aniket Srinivasan Ashok",
        "Darren Lo",
        "Mike Optis",
        "Alexander Wong",
        "Yuhao Chen"
      ],
      "abstract": "Various weather modelling problems (e.g., weather forecasting, optimizing turbine placements, etc.) require ample access to high-resolution, highly accurate wind data. Acquiring such high-resolution wind data, however, remains a challenging and expensive endeavour. Traditional reconstruction approaches are typically either cost-effective or accurate, but not both. Deep learning methods, including diffusion models, have been proposed to resolve this trade-off by leveraging advances in natural image super-resolution. Wind data, however, is distinct from natural images, and wind super-resolvers often use upwards of 10 input channels, significantly more than the usual 3-channel RGB inputs in natural images. To better leverage a large number of conditioning variables in diffusion models, we present a generalization of classifier-free guidance (CFG) to multiple conditioning inputs. Our novel composite classifier-free guidance (CCFG) can be dropped into any pre-trained diffusion model trained with standard CFG dropout. We demonstrate that CCFG outputs are higher-fidelity than those from CFG on wind super-resolution tasks. We present WindDM, a diffusion model trained for industrial-scale wind dynamics reconstruction and leveraging CCFG. WindDM achieves state-of-the-art reconstruction quality among deep learning models and costs up to $1000\\times$ less than classical methods.",
      "tldr_zh": "è¯¥ç ”ç©¶é’ˆå¯¹å¤©æ°”é¢„æµ‹å’Œæ¶¡è½®æœºå¸ƒå±€ä¼˜åŒ–ä¸­é«˜åˆ†è¾¨ç‡é£åŠ›æ•°æ®è·å–æ˜‚è´µçš„é—®é¢˜ï¼Œæå‡ºäº†ä¸€ç§åä¸ºå¤åˆæ— åˆ†ç±»å™¨å¼•å¯¼(Composite Classifier-Free Guidance, CCFG)çš„é€šç”¨æ¡†æ¶ã€‚é’ˆå¯¹é£åŠ›æ•°æ®è¾“å…¥é€šé“è¿œè¶…è‡ªç„¶å›¾åƒRGBé€šé“çš„ç‰¹ç‚¹ï¼ŒCCFGé€šè¿‡æ‰©å±•æ‰©æ•£æ¨¡å‹(diffusion models)çš„å¼•å¯¼æœºåˆ¶ï¼Œèƒ½å¤Ÿæ›´æœ‰æ•ˆåœ°åˆ©ç”¨å¤šæ¨¡æ€æ¡ä»¶å˜é‡ã€‚è¯¥æ–¹æ³•å¯ç›´æ¥åº”ç”¨äºä»»ä½•ä½¿ç”¨æ ‡å‡†CFG dropouté¢„è®­ç»ƒçš„æ¨¡å‹ï¼Œå¹¶åœ¨é£åŠ›è¶…åˆ†è¾¨ç‡(super-resolution)ä»»åŠ¡ä¸­å±•ç°å‡ºæ¯”ä¼ ç»ŸCFGæ›´é«˜çš„ä¿çœŸåº¦(fidelity)ã€‚åŸºäºæ­¤ï¼Œç ”ç©¶è€…æ„å»ºäº†ä¸“ä¸ºå·¥ä¸šçº§é£åŠ¨åŠ›å­¦é‡æ„è®¾è®¡çš„WindDMæ¨¡å‹ã€‚å®éªŒç»“æœæ˜¾ç¤ºï¼ŒWindDMåœ¨å®ç°æœ€å…ˆè¿›(state-of-the-art)é‡æ„è´¨é‡çš„åŒæ—¶ï¼Œå…¶æˆæœ¬æ¯”ä¼ ç»Ÿç»å…¸æ–¹æ³•é™ä½äº†1000å€ã€‚è¯¥ç ”ç©¶ä¸ºå¤šå˜é‡ã€é«˜å¤æ‚åº¦çš„æ°”è±¡æ•°æ®å¤„ç†æä¾›äº†é«˜æ•ˆä¸”ç²¾ç¡®çš„æ·±åº¦å­¦ä¹ æ–¹æ¡ˆã€‚",
      "categories": [
        "cs.LG",
        "cs.AI",
        "cs.CV"
      ],
      "primary_category": "cs.LG",
      "comment": "",
      "pdf_url": "https://arxiv.org/pdf/2512.13729v1",
      "published_date": "2025-12-13 22:44:41 UTC",
      "updated_date": "2025-12-13 22:44:41 UTC",
      "processing_status": "completed",
      "attempts": 1,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "llm_backup_calls": 1,
      "last_update": "2026-01-26T16:24:53.662603+00:00"
    },
    {
      "arxiv_id": "2512.13728v1",
      "title": "CurvaDion: Curvature-Adaptive Distributed Orthonormalization",
      "title_zh": "CurvaDionï¼šæ›²ç‡è‡ªé€‚åº”åˆ†å¸ƒå¼æ­£äº¤è§„èŒƒåŒ–",
      "authors": [
        "Bhavesh Kumar",
        "Roger Jin",
        "Jeffrey Quesnelle"
      ],
      "abstract": "As language models scale to trillions of parameters, distributed training across many GPUs becomes essential, yet gradient synchronization over high-bandwidth, low-latency networks remains a critical bottleneck. While recent methods like Dion reduce per-step communication through low-rank updates, they synchronize at every step regardless of the optimization landscape. We observe that synchronization requirements vary dramatically throughout training: workers naturally compute similar gradients in flat regions, making frequent synchronization redundant, while high-curvature regions require coordination to prevent divergence. We introduce CurvaDion, which uses Relative Maximum Momentum Change (RMMC) to detect high-curvature regions requiring synchronization. RMMC leverages momentum dynamics which are already computed during optimization as a computationally tractable proxy for directional curvature, adding only $\\mathcal{O}(d)$ operations per layer. We establish theoretical connections between RMMC and loss curvature and demonstrate that CurvaDion achieves 99\\% communication reduction while matching baseline convergence across models from 160M to 1.3B parameters.",
      "tldr_zh": "è¯¥ç ”ç©¶é’ˆå¯¹å¤§è§„æ¨¡è¯­è¨€æ¨¡å‹åˆ†å¸ƒå¼è®­ç»ƒä¸­æ¢¯åº¦åŒæ­¥å¯¼è‡´çš„é€šä¿¡ç“¶é¢ˆï¼Œæå‡ºäº†CurvaDionï¼Œä¸€ç§æ›²ç‡è‡ªé€‚åº”çš„åˆ†å¸ƒå¼æ­£äº¤åŒ–æ–¹æ³•ã€‚ç ”ç©¶äººå‘˜è§‚å¯Ÿåˆ°åŒæ­¥éœ€æ±‚åœ¨è®­ç»ƒè¿‡ç¨‹ä¸­éšä¼˜åŒ–æ™¯è§‚çš„å˜åŒ–è€Œæ³¢åŠ¨ï¼Œä¼ ç»Ÿçš„å›ºå®šæ­¥é•¿åŒæ­¥åœ¨å¹³å¦åŒºåŸŸå­˜åœ¨å†—ä½™ï¼Œè€Œåœ¨é«˜æ›²ç‡åŒºåŸŸåˆ™è‡³å…³é‡è¦ã€‚CurvaDionå¼•å…¥äº†ç›¸å¯¹æœ€å¤§åŠ¨é‡å˜åŒ–(Relative Maximum Momentum Change, RMMC)æŒ‡æ ‡ï¼Œåˆ©ç”¨ç°æœ‰çš„åŠ¨é‡åŠ¨æ€ä½œä¸ºæ–¹å‘æ›²ç‡çš„ä½å¼€é”€ä»£ç†ï¼Œä»¥æ­¤æ£€æµ‹éœ€è¦åŒæ­¥çš„å…³é”®åŒºåŸŸã€‚ç†è®ºåˆ†æå»ºç«‹äº†RMMCä¸æŸå¤±æ›²ç‡ä¹‹é—´çš„è”ç³»ï¼Œä¸”è¯¥æ–¹æ³•åœ¨æ¯å±‚ä»…å¢åŠ $\\mathcal{O}(d)$çš„è®¡ç®—å¤æ‚åº¦ã€‚å®éªŒç»“æœè¡¨æ˜ï¼ŒCurvaDionåœ¨160Mè‡³1.3Bå‚æ•°è§„æ¨¡çš„æ¨¡å‹è®­ç»ƒä¸­ï¼Œåœ¨ä¿æŒåŸºå‡†æ”¶æ•›æ€§èƒ½çš„åŒæ—¶ï¼ŒæˆåŠŸå‡å°‘äº†99%çš„é€šä¿¡é‡ã€‚",
      "categories": [
        "cs.LG",
        "cs.AI"
      ],
      "primary_category": "cs.LG",
      "comment": "Nous Research",
      "pdf_url": "https://arxiv.org/pdf/2512.13728v1",
      "published_date": "2025-12-13 22:38:51 UTC",
      "updated_date": "2025-12-13 22:38:51 UTC",
      "processing_status": "completed",
      "attempts": 1,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "llm_backup_calls": 0,
      "last_update": "2026-01-26T16:25:21.617286+00:00"
    },
    {
      "arxiv_id": "2512.12477v1",
      "title": "MetaHGNIE: Meta-Path Induced Hypergraph Contrastive Learning in Heterogeneous Knowledge Graphs",
      "title_zh": "MetaHGNIEï¼šå¼‚æ„çŸ¥è¯†å›¾è°±ä¸­å…ƒè·¯å¾„è¯±å¯¼çš„è¶…å›¾å¯¹æ¯”å­¦ä¹ ",
      "authors": [
        "Jiawen Chen",
        "Yanyan He",
        "Qi Shao",
        "Mengli Wei",
        "Duxin Chen",
        "Wenwu Yu",
        "Yanlong Zhao"
      ],
      "abstract": "Node importance estimation (NIE) in heterogeneous knowledge graphs is a critical yet challenging task, essential for applications such as recommendation, knowledge reasoning, and question answering. Existing methods often rely on pairwise connections, neglecting high-order dependencies among multiple entities and relations, and they treat structural and semantic signals independently, hindering effective cross-modal integration. To address these challenges, we propose MetaHGNIE, a meta-path induced hypergraph contrastive learning framework for disentangling and aligning structural and semantic information. MetaHGNIE constructs a higher-order knowledge graph via meta-path sequences, where typed hyperedges capture multi-entity relational contexts. Structural dependencies are aggregated with local attention, while semantic representations are encoded through a hypergraph transformer equipped with sparse chunking to reduce redundancy. Finally, a multimodal fusion module integrates structural and semantic embeddings under contrastive learning with auxiliary supervision, ensuring robust cross-modal alignment. Extensive experiments on benchmark NIE datasets demonstrate that MetaHGNIE consistently outperforms state-of-the-art baselines. These results highlight the effectiveness of explicitly modeling higher-order interactions and cross-modal alignment in heterogeneous knowledge graphs. Our code is available at https://github.com/SEU-WENJIA/DualHNIE",
      "tldr_zh": "è¯¥ç ”ç©¶é’ˆå¯¹å¼‚æ„çŸ¥è¯†å›¾è°±(Heterogeneous Knowledge Graphs)ä¸­èŠ‚ç‚¹é‡è¦æ€§ä¼°è®¡(Node Importance Estimation, NIE)é¢ä¸´çš„é«˜é˜¶ä¾èµ–æ•æ‰ä¸è¶³ä»¥åŠç»“æ„ä¸è¯­ä¹‰ä¿¡å·æ•´åˆéš¾ç­‰æŒ‘æˆ˜ï¼Œæå‡ºäº†ä¸€ç§åä¸ºMetaHGNIEçš„å…ƒè·¯å¾„(Meta-path)è¯±å¯¼è¶…å›¾å¯¹æ¯”å­¦ä¹ (Hypergraph Contrastive Learning)æ¡†æ¶ã€‚MetaHGNIEé€šè¿‡å…ƒè·¯å¾„åºåˆ—æ„å»ºé«˜é˜¶çŸ¥è¯†å›¾è°±ï¼Œåˆ©ç”¨ç±»å‹åŒ–çš„è¶…è¾¹æ•æ‰å¤šå®ä½“é—´çš„å…³ç³»ä¸Šä¸‹æ–‡ï¼Œå¹¶ç»“åˆå±€éƒ¨æ³¨æ„åŠ›æœºåˆ¶èšåˆç»“æ„ä¾èµ–ã€‚é’ˆå¯¹è¯­ä¹‰ä¿¡æ¯ï¼Œè¯¥æ¡†æ¶é‡‡ç”¨é…å¤‡ç¨€ç–åˆ†å—(Sparse Chunking)çš„è¶…å›¾è½¬æ¢å™¨(Hypergraph Transformer)è¿›è¡Œç¼–ç ä»¥å‡å°‘å†—ä½™ï¼Œæœ€åé€šè¿‡å¤šæ¨¡æ€èåˆæ¨¡å—åœ¨å¯¹æ¯”å­¦ä¹ æ¡†æ¶ä¸‹å®ç°ç»“æ„ä¸è¯­ä¹‰åµŒå…¥çš„ç¨³å¥å¯¹é½ã€‚åœ¨åŸºå‡†æ•°æ®é›†ä¸Šçš„å®éªŒç»“æœè¡¨æ˜ï¼ŒMetaHGNIEçš„è¡¨ç°ä¸€è‡´ä¼˜äºç°æœ‰çš„æœ€å…ˆè¿›åŸºå‡†æ¨¡å‹ï¼Œæœ‰æ•ˆéªŒè¯äº†æ˜¾å¼å»ºæ¨¡é«˜é˜¶äº¤äº’å’Œè·¨æ¨¡æ€å¯¹é½åœ¨å¤„ç†å¤æ‚çŸ¥è¯†å›¾è°±ä»»åŠ¡ä¸­çš„ä¼˜è¶Šæ€§ã€‚",
      "categories": [
        "cs.AI",
        "cs.LG"
      ],
      "primary_category": "cs.AI",
      "comment": "",
      "pdf_url": "https://arxiv.org/pdf/2512.12477v1",
      "published_date": "2025-12-13 22:21:33 UTC",
      "updated_date": "2025-12-13 22:21:33 UTC",
      "processing_status": "completed",
      "attempts": 1,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "llm_backup_calls": 0,
      "last_update": "2026-01-26T16:23:33.080865+00:00"
    },
    {
      "arxiv_id": "2512.12474v1",
      "title": "AI-Driven Real-Time Kick Classification in Olympic Taekwondo Using Sensor Fusion",
      "title_zh": "åŸºäºä¼ æ„Ÿå™¨èåˆçš„å¥¥è¿è·†æ‹³é“AIé©±åŠ¨å®æ—¶è…¿æ³•åˆ†ç±»",
      "authors": [
        "Jamsheed Mistri"
      ],
      "abstract": "Olympic Taekwondo has faced challenges in spectator engagement due to static, defensive gameplay and contentious scoring. Current Protector and Scoring Systems (PSS) rely on impact sensors and simplistic logic, encouraging safe strategies that diminish the sport's dynamism. This paper proposes an AI-powered scoring system that integrates existing PSS sensors with additional accelerometers, gyroscopes, magnetic/RFID, and impact force sensors in a sensor fusion framework. The system classifies kicks in real-time to identify technique type, contact location, impact force, and even the part of the foot used. A machine learning pipeline employing sensor fusion and Support Vector Machines (SVMs) is detailed, enabling automatic kick technique recognition for scoring. We present a novel kick scoring rubric that awards points based on specific kick techniques (e.g., turning and spinning kicks) to incentivize dynamic attacks. Drawing on a 2024 study achieving 96-98% accuracy, we validate the feasibility of real-time kick classification and further propose enhancements to this methodology, such as ensemble SVM classifiers and expanded datasets, to achieve the high-stakes accuracy required by the sport. We analyze how the proposed system can improve scoring fairness, reduce rule exploitation and illegitimate tactics, encourage more dynamic techniques, and enhance spectator understanding and excitement. The paper includes system design illustrations, a kick scoring table from an AI-augmented rule set, and discusses anticipated impacts on Olympic Taekwondo.",
      "tldr_zh": "æœ¬ç ”ç©¶é’ˆå¯¹å¥¥æ—åŒ¹å…‹è·†æ‹³é“åœ¨è§‚ä¼—å‚ä¸åº¦ã€é˜²å®ˆå‹æ‰“æ³•åŠè®¡åˆ†å…¬å¹³æ€§æ–¹é¢é¢ä¸´çš„æŒ‘æˆ˜ï¼Œæå‡ºäº†ä¸€ç§åŸºäºäººå·¥æ™ºèƒ½(AI)é©±åŠ¨çš„å®æ—¶è¸¢å‡»åˆ†ç±»è®¡åˆ†ç³»ç»Ÿã€‚è¯¥ç³»ç»Ÿé‡‡ç”¨ä¼ æ„Ÿå™¨èåˆ(Sensor Fusion)æ¡†æ¶ï¼Œæ•´åˆäº†ç°æœ‰çš„ç”µå­æŠ¤å…·(PSS)ä¼ æ„Ÿå™¨ä¸æ–°å¢çš„åŠ é€Ÿåº¦è®¡ã€é™€èºä»ªã€ç£æ€§/RFIDä»¥åŠå†²å‡»åŠ›ä¼ æ„Ÿå™¨ï¼Œä»¥å®ç°å¯¹è¸¢å‡»æŠ€æœ¯çš„æ·±åº¦æ„Ÿåº”ã€‚åˆ©ç”¨æ”¯æŒå‘é‡æœº(SVM)æ„å»ºçš„æœºå™¨å­¦ä¹ æµæ°´çº¿ï¼Œç³»ç»Ÿèƒ½å¤Ÿå®æ—¶è¯†åˆ«è¸¢å‡»ç±»å‹ã€æ¥è§¦ä½ç½®ã€å†²å‡»å¼ºåº¦åŠå…·ä½“æ¥è§¦éƒ¨ä½ï¼Œå¹¶é…å¥—æå‡ºäº†æ—¨åœ¨æ¿€åŠ±åŠ¨æ€è¿›æ”»çš„æ–°å‹è¸¢å‡»è¯„åˆ†æ ‡å‡†ã€‚å®éªŒæ•°æ®è¡¨æ˜è¯¥æ–¹æ³•åœ¨åˆ†ç±»å‡†ç¡®ç‡ä¸Šè¾¾åˆ°äº†96-98%ï¼Œæœ‰æ•ˆéªŒè¯äº†åœ¨å¤æ‚æ¯”èµ›ç¯å¢ƒä¸‹è¿›è¡Œé«˜ç²¾åº¦åˆ¤ç½šçš„å¯è¡Œæ€§ã€‚é€šè¿‡å¼•å…¥é›†æˆSVMåˆ†ç±»å™¨å’Œæ‰©å±•æ•°æ®é›†ï¼Œè¯¥ç³»ç»Ÿä¸ä»…èƒ½æ˜¾è‘—æé«˜è®¡åˆ†çš„å…¬å¹³æ€§å¹¶å‡å°‘è§„åˆ™æ¼æ´ï¼Œè¿˜èƒ½é€šè¿‡é‡åŒ–é«˜éš¾åº¦æŠ€æœ¯(å¦‚Turning and Spinning Kicks)æ¥æå‡èµ›äº‹çš„è§‚èµæ€§ä¸ç«æŠ€æ°´å¹³ã€‚",
      "categories": [
        "eess.SY",
        "cs.AI",
        "cs.LG"
      ],
      "primary_category": "eess.SY",
      "comment": "13 pages, 4 figures",
      "pdf_url": "https://arxiv.org/pdf/2512.12474v1",
      "published_date": "2025-12-13 22:17:51 UTC",
      "updated_date": "2025-12-13 22:17:51 UTC",
      "processing_status": "completed",
      "attempts": 1,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "llm_backup_calls": 0,
      "last_update": "2026-01-26T16:23:36.962439+00:00"
    },
    {
      "arxiv_id": "2512.12465v1",
      "title": "Exploring the Design Space of Transition Matching",
      "title_zh": "æ¢ç´¢è½¬æ¢åŒ¹é…çš„è®¾è®¡ç©ºé—´",
      "authors": [
        "Uriel Singer",
        "Yaron Lipman"
      ],
      "abstract": "Transition Matching (TM) is an emerging paradigm for generative modeling that generalizes diffusion and flow-matching models as well as continuous-state autoregressive models. TM, similar to previous paradigms, gradually transforms noise samples to data samples, however it uses a second ``internal'' generative model to implement the transition steps, making the transitions more expressive compared to diffusion and flow models. To make this paradigm tractable, TM employs a large backbone network and a smaller \"head\" module to efficiently execute the generative transition step. In this work, we present a large-scale, systematic investigation into the design, training and sampling of the head in TM frameworks, focusing on its time-continuous bidirectional variant. Through comprehensive ablations and experimentation involving training 56 different 1.7B text-to-image models (resulting in 549 unique evaluations) we evaluate the affect of the head module architecture and modeling during training as-well as a useful family of stochastic TM samplers. We analyze the impact on generation quality, training, and inference efficiency. We find that TM with an MLP head, trained with a particular time weighting and sampled with high frequency sampler provides best ranking across all metrics reaching state-of-the-art among all tested baselines, while Transformer head with sequence scaling and low frequency sampling is a runner up excelling at image aesthetics. Lastly, we believe the experiments presented highlight the design aspects that are likely to provide most quality and efficiency gains, while at the same time indicate what design choices are not likely to provide further gains.",
      "tldr_zh": "è¯¥ç ”ç©¶æ¢è®¨äº† Transition Matching (TM) çš„è®¾è®¡ç©ºé—´ï¼Œè¿™æ˜¯ä¸€ç§æ³›åŒ–äº†æ‰©æ•£æ¨¡å‹ (diffusion)ã€æµåŒ¹é…æ¨¡å‹ (flow-matching) å’Œè¿ç»­çŠ¶æ€è‡ªå›å½’æ¨¡å‹ (continuous-state autoregressive models) çš„æ–°å…´ç”Ÿæˆå»ºæ¨¡èŒƒå¼ã€‚TM é€šè¿‡å¼•å…¥ç¬¬äºŒä¸ªâ€œå†…éƒ¨â€ç”Ÿæˆæ¨¡å‹æ¥å®ç°æ›´å…·è¡¨ç°åŠ›çš„è½¬æ¢æ­¥éª¤ï¼Œå¹¶é‡‡ç”¨å¤§å‹ä¸»å¹²ç½‘ç»œ (backbone network) ä¸è¾ƒå°çš„å¤´éƒ¨æ¨¡å— (head module) æ¥ç¡®ä¿è½¬æ¢è¿‡ç¨‹çš„å¯æ“ä½œæ€§ã€‚æœ¬ç ”ç©¶å¯¹æ—¶é—´è¿ç»­åŒå‘å˜ä½“ä¸­çš„å¤´éƒ¨æ¨¡å—è®¾è®¡ã€è®­ç»ƒå’Œé‡‡æ ·è¿›è¡Œäº†å¤§è§„æ¨¡ç³»ç»Ÿæ€§è°ƒæŸ¥ï¼Œé€šè¿‡è®­ç»ƒ 56 ä¸ª 17 äº¿å‚æ•°çš„æ–‡æœ¬ç”Ÿæˆå›¾åƒ (text-to-image) æ¨¡å‹å¹¶è¿›è¡Œäº† 549 æ¬¡ç‹¬ç«‹è¯„ä¼°ã€‚å®éªŒå‘ç°ï¼Œä½¿ç”¨ MLP å¤´éƒ¨æ¨¡å—ç»“åˆç‰¹å®šæ—¶é—´åŠ æƒå’Œé«˜é¢‘é‡‡æ ·å™¨çš„ TM æ¨¡å‹åœ¨æ‰€æœ‰æŒ‡æ ‡ä¸Šå‡è¡¨ç°æœ€ä½³ï¼Œè¾¾åˆ°äº† SOTA æ°´å¹³ã€‚ç›¸æ¯”ä¹‹ä¸‹ï¼Œé‡‡ç”¨åºåˆ—ç¼©æ”¾å’Œä½é¢‘é‡‡æ ·çš„ Transformer å¤´éƒ¨æ¨¡å—åœ¨å›¾åƒç¾å­¦æ–¹é¢è¡¨ç°æ›´ä¸ºçªå‡ºã€‚è¯¥ç ”ç©¶æ­ç¤ºäº†æå‡ TM ç”Ÿæˆè´¨é‡ä¸æ•ˆç‡çš„å…³é”®è®¾è®¡è¦ç´ ï¼Œä¸ºæœªæ¥ç”Ÿæˆæ¨¡å‹çš„è®¾è®¡ä¸ä¼˜åŒ–æä¾›äº†é‡è¦çš„å®è¯æŒ‡å—ã€‚",
      "categories": [
        "cs.LG",
        "cs.AI"
      ],
      "primary_category": "cs.LG",
      "comment": "",
      "pdf_url": "https://arxiv.org/pdf/2512.12465v1",
      "published_date": "2025-12-13 21:34:47 UTC",
      "updated_date": "2025-12-13 21:34:47 UTC",
      "processing_status": "completed",
      "attempts": 1,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "llm_backup_calls": 0,
      "last_update": "2026-01-26T16:23:40.784316+00:00"
    },
    {
      "arxiv_id": "2512.12462v1",
      "title": "Dynamical modeling of nonlinear latent factors in multiscale neural activity with real-time inference",
      "title_zh": "å…·æœ‰å®æ—¶æ¨ç†èƒ½åŠ›çš„å¤šå°ºåº¦ç¥ç»æ´»åŠ¨éçº¿æ€§æ½œå˜é‡åŠ¨åŠ›å­¦å»ºæ¨¡",
      "authors": [
        "Eray Erturk",
        "Maryam M. Shanechi"
      ],
      "abstract": "Real-time decoding of target variables from multiple simultaneously recorded neural time-series modalities, such as discrete spiking activity and continuous field potentials, is important across various neuroscience applications. However, a major challenge for doing so is that different neural modalities can have different timescales (i.e., sampling rates) and different probabilistic distributions, or can even be missing at some time-steps. Existing nonlinear models of multimodal neural activity do not address different timescales or missing samples across modalities. Further, some of these models do not allow for real-time decoding. Here, we develop a learning framework that can enable real-time recursive decoding while nonlinearly aggregating information across multiple modalities with different timescales and distributions and with missing samples. This framework consists of 1) a multiscale encoder that nonlinearly aggregates information after learning within-modality dynamics to handle different timescales and missing samples in real time, 2) a multiscale dynamical backbone that extracts multimodal temporal dynamics and enables real-time recursive decoding, and 3) modality-specific decoders to account for different probabilistic distributions across modalities. In both simulations and three distinct multiscale brain datasets, we show that our model can aggregate information across modalities with different timescales and distributions and missing samples to improve real-time target decoding. Further, our method outperforms various linear and nonlinear multimodal benchmarks in doing so.",
      "tldr_zh": "è¯¥ç ”ç©¶æå‡ºäº†ä¸€ä¸ªèƒ½å¤Ÿå®ç°å®æ—¶é€’å½’è§£ç (real-time recursive decoding)çš„å­¦ä¹ æ¡†æ¶ï¼Œæ—¨åœ¨è§£å†³ä»å…·æœ‰ä¸åŒæ—¶é—´å°ºåº¦(timescales)ã€æ¦‚ç‡åˆ†å¸ƒä¸”å¯èƒ½å­˜åœ¨æ•°æ®ç¼ºå¤±çš„å¤šæ¨¡æ€ç¥ç»æ—¶é—´åºåˆ—ä¸­è§£ç ç›®æ ‡å˜é‡çš„æŒ‘æˆ˜ã€‚è¯¥æ¡†æ¶ç”±å¤šå°ºåº¦ç¼–ç å™¨(multiscale encoder)ã€å¤šå°ºåº¦åŠ¨åŠ›å­¦éª¨å¹²(multiscale dynamical backbone)ä»¥åŠæ¨¡æ€ä¸“ç”¨è§£ç å™¨(modality-specific decoders)ç»„æˆï¼Œé€šè¿‡éçº¿æ€§èšåˆæ–¹å¼æœ‰æ•ˆå¤„ç†ç¦»æ•£è„‰å†²æ´»åŠ¨(discrete spiking activity)å’Œè¿ç»­åœºç”µä½(continuous field potentials)ç­‰ä¿¡æ¯ã€‚è¿™ç§æ¶æ„èƒ½å¤Ÿåœ¨å¤„ç†ä¸åŒé‡‡æ ·ç‡å’Œç¼ºå¤±æ ·æœ¬çš„åŒæ—¶ï¼Œæå–å¤šæ¨¡æ€çš„æ—¶é—´åŠ¨åŠ›å­¦ç‰¹å¾ã€‚åœ¨æ¨¡æ‹Ÿå®éªŒå’Œä¸‰ä¸ªå¤§è„‘æ•°æ®é›†ä¸Šçš„æµ‹è¯•ç»“æœè¡¨æ˜ï¼Œè¯¥æ¨¡å‹åœ¨å®æ—¶ç›®æ ‡è§£ç ç²¾åº¦ä¸Šæ˜¾è‘—æå‡ã€‚å®éªŒè¯æ˜ï¼Œè¯¥æ–¹æ³•åœ¨åº”å¯¹å¤æ‚å¤šæ¨¡æ€ç¥ç»ä¿¡å·æ—¶ä¼˜äºç°æœ‰çš„å„ç§çº¿æ€§å’Œéçº¿æ€§åŸºå‡†æ¨¡å‹ã€‚",
      "categories": [
        "cs.LG",
        "cs.AI",
        "q-bio.NC"
      ],
      "primary_category": "cs.LG",
      "comment": "Published at the 39th Annual Conference on Neural Information Processing Systems 2025. Code is available at https://github.com/ShanechiLab/mrine",
      "pdf_url": "https://arxiv.org/pdf/2512.12462v1",
      "published_date": "2025-12-13 21:20:21 UTC",
      "updated_date": "2025-12-13 21:20:21 UTC",
      "processing_status": "completed",
      "attempts": 1,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "llm_backup_calls": 0,
      "last_update": "2026-01-26T16:23:46.693153+00:00"
    },
    {
      "arxiv_id": "2512.12461v1",
      "title": "Cross-Modal Representational Knowledge Distillation for Enhanced Spike-Informed LFP Modeling",
      "title_zh": "ç”¨äºå¢å¼ºå‹è„‰å†²è¾…åŠ© LFP å»ºæ¨¡çš„è·¨æ¨¡æ€è¡¨å¾çŸ¥è¯†è’¸é¦",
      "authors": [
        "Eray Erturk",
        "Saba Hashemi",
        "Maryam M. Shanechi"
      ],
      "abstract": "Local field potentials (LFPs) can be routinely recorded alongside spiking activity in intracortical neural experiments, measure a larger complementary spatiotemporal scale of brain activity for scientific inquiry, and can offer practical advantages over spikes, including greater long-term stability, robustness to electrode degradation, and lower power requirements. Despite these advantages, recent neural modeling frameworks have largely focused on spiking activity since LFP signals pose inherent modeling challenges due to their aggregate, population-level nature, often leading to lower predictive power for downstream task variables such as motor behavior. To address this challenge, we introduce a cross-modal knowledge distillation framework that transfers high-fidelity representational knowledge from pretrained multi-session spike transformer models to LFP transformer models. Specifically, we first train a teacher spike model across multiple recording sessions using a masked autoencoding objective with a session-specific neural tokenization strategy. We then align the latent representations of the student LFP model to those of the teacher spike model. Our results show that the Distilled LFP models consistently outperform single- and multi-session LFP baselines in both fully unsupervised and supervised settings, and can generalize to other sessions without additional distillation while maintaining superior performance. These findings demonstrate that cross-modal knowledge distillation is a powerful and scalable approach for leveraging high-performing spike models to develop more accurate LFP models.",
      "tldr_zh": "è¯¥ç ”ç©¶æå‡ºäº†ä¸€ç§è·¨æ¨¡æ€è¡¨å¾çŸ¥è¯†è’¸é¦ (Cross-Modal Representational Knowledge Distillation) æ¡†æ¶ï¼Œæ—¨åœ¨è§£å†³å±€éƒ¨åœºç”µä½ (Local Field Potentials, LFP) åœ¨ç¥ç»å»ºæ¨¡ä¸­å› ä¿¡å·èšåˆç‰¹æ€§å¯¼è‡´é¢„æµ‹èƒ½åŠ›è¾ƒä½çš„æŒ‘æˆ˜ã€‚è¯¥æ¡†æ¶é€šè¿‡å°†é¢„è®­ç»ƒçš„å¤šä¼šè¯ Spike Transformer æ•™å¸ˆæ¨¡å‹ä¸­çš„é«˜ä¿çœŸè¡¨å¾çŸ¥è¯†è¿ç§»è‡³ LFP Transformer å­¦ç”Ÿæ¨¡å‹ï¼Œå®ç°äº†è·¨æ¨¡æ€çš„æ€§èƒ½å¢å¼ºã€‚ç ”ç©¶é¦–å…ˆåˆ©ç”¨æ©ç è‡ªç¼–ç  (Masked Autoencoding) ç›®æ ‡å’Œç‰¹å®šä¼šè¯çš„ç¥ç»æ ‡è®°åŒ– (Neural Tokenization) ç­–ç•¥è®­ç»ƒæ•™å¸ˆæ¨¡å‹ï¼Œéšåå°†å­¦ç”Ÿæ¨¡å‹çš„æ½œå±‚è¡¨ç¤ºä¸æ•™å¸ˆæ¨¡å‹è¿›è¡Œå¯¹é½ã€‚å®éªŒç»“æœè¡¨æ˜ï¼Œç»è¿‡è’¸é¦çš„ LFP æ¨¡å‹åœ¨æ— ç›‘ç£å’Œæœ‰ç›‘ç£è®¾ç½®ä¸‹å‡æ˜¾è‘—ä¼˜äºä¼ ç»Ÿçš„ LFP åŸºå‡†æ¨¡å‹ï¼Œå¹¶å…·å¤‡æ— éœ€é¢å¤–è’¸é¦å³å¯æ¨å¹¿è‡³æ–°ä¼šè¯çš„æ³›åŒ–èƒ½åŠ›ã€‚è¿™é¡¹å·¥ä½œè¯æ˜äº†åˆ©ç”¨é«˜æ€§èƒ½ Spike æ¨¡å‹å¼€å‘æ›´ç²¾ç¡®ä¸”ç¨³å¥çš„ LFP æ¨¡å‹æ˜¯ä¸€ç§å¼ºå¤§ä¸”å…·æœ‰æ‰©å±•æ€§çš„æ–¹æ¡ˆã€‚",
      "categories": [
        "cs.LG",
        "cs.AI",
        "q-bio.NC"
      ],
      "primary_category": "cs.LG",
      "comment": "Published at the 39th Annual Conference on Neural Information Processing Systems 2025. Code is available at https://github.com/ShanechiLab/CrossModalDistillation",
      "pdf_url": "https://arxiv.org/pdf/2512.12461v1",
      "published_date": "2025-12-13 21:20:13 UTC",
      "updated_date": "2025-12-13 21:20:13 UTC",
      "processing_status": "completed",
      "attempts": 1,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "llm_backup_calls": 0,
      "last_update": "2026-01-26T16:23:58.428201+00:00"
    },
    {
      "arxiv_id": "2512.13726v1",
      "title": "Time-Constrained Recommendations: Reinforcement Learning Strategies for E-Commerce",
      "title_zh": "æ—¶é—´çº¦æŸä¸‹çš„æ¨èï¼šç”µå­å•†åŠ¡ä¸­çš„å¼ºåŒ–å­¦ä¹ ç­–ç•¥",
      "authors": [
        "Sayak Chakrabarty",
        "Souradip Pal"
      ],
      "abstract": "Unlike traditional recommendation tasks, finite user time budgets introduce a critical resource constraint, requiring the recommender system to balance item relevance and evaluation cost. For example, in a mobile shopping interface, users interact with recommendations by scrolling, where each scroll triggers a list of items called slate. Users incur an evaluation cost - time spent assessing item features before deciding to click. Highly relevant items having higher evaluation costs may not fit within the user's time budget, affecting engagement. In this position paper, our objective is to evaluate reinforcement learning algorithms that learn patterns in user preferences and time budgets simultaneously, crafting recommendations with higher engagement potential under resource constraints. Our experiments explore the use of reinforcement learning to recommend items for users using Alibaba's Personalized Re-ranking dataset supporting slate optimization in e-commerce contexts. Our contributions include (i) a unified formulation of time-constrained slate recommendation modeled as Markov Decision Processes (MDPs) with budget-aware utilities; (ii) a simulation framework to study policy behavior on re-ranking data; and (iii) empirical evidence that on-policy and off-policy control can improve performance under tight time budgets than traditional contextual bandit-based methods.",
      "tldr_zh": "è¿™é¡¹ç ”ç©¶é’ˆå¯¹ç”µå­å•†åŠ¡é¢†åŸŸæå‡ºäº†å—æ—¶é—´é™åˆ¶çš„æ¨èç­–ç•¥ï¼Œæ—¨åœ¨è§£å†³ä¼ ç»Ÿæ¨èç³»ç»Ÿä¸­å¿½è§†ç”¨æˆ·æœ‰é™æ—¶é—´é¢„ç®—çš„é—®é¢˜ã€‚ç ”ç©¶å¼ºè°ƒäº†åœ¨ç§»åŠ¨ç«¯ç•Œé¢ä¸­ï¼Œæ¨èç³»ç»Ÿå¿…é¡»å¹³è¡¡ç‰©å“ç›¸å…³æ€§ä¸ç”¨æˆ·çš„è¯„ä¼°æˆæœ¬(evaluation cost)ï¼Œä»¥é˜²æ­¢é«˜ç›¸å…³æ€§ç‰©å“å› è¯„ä¼°è€—æ—¶è¿‡å¤šè€Œè¶…å‡ºç”¨æˆ·é¢„ç®—ã€‚ä½œè€…é‡‡ç”¨å¼ºåŒ–å­¦ä¹ (Reinforcement Learning)ç®—æ³•æ¥åŒæ­¥å­¦ä¹ ç”¨æˆ·åå¥½ä¸æ—¶é—´é¢„ç®—æ¨¡å¼ï¼Œå¹¶å°†è¯¥åœºæ™¯ä¸‹çš„åºåˆ—æ¨è(slate recommendation)å»ºæ¨¡ä¸ºå…·æœ‰é¢„ç®—æ„ŸçŸ¥æ•ˆç”¨çš„é©¬å°”å¯å¤«å†³ç­–è¿‡ç¨‹(Markov Decision Processes)ã€‚é€šè¿‡åœ¨é˜¿é‡Œå·´å·´ä¸ªæ€§åŒ–é‡æ’åºæ•°æ®é›†(Personalized Re-ranking dataset)ä¸Šæ„å»ºæ¨¡æ‹Ÿæ¡†æ¶ï¼Œè¯¥ç ”ç©¶è¯å®äº†åŒç­–ç•¥(on-policy)ä¸å¼‚ç­–ç•¥(off-policy)æ§åˆ¶ç®—æ³•åœ¨æ—¶é—´é¢„ç®—ç´§ç¼ºæ—¶æ¯”ä¼ ç»Ÿçš„ä¸Šä¸‹æ–‡å¤šè‡‚è€è™æœº(contextual bandit)æ–¹æ³•è¡¨ç°æ›´ä½³ã€‚è¿™äº›å‘ç°è¯æ˜äº†å¼ºåŒ–å­¦ä¹ åœ¨å¤„ç†å…·æœ‰èµ„æºçº¦æŸçš„ç”µå•†é‡æ’åºä»»åŠ¡ä¸­çš„æœ‰æ•ˆæ€§ï¼Œä¸ºæå‡å—é™ç¯å¢ƒä¸‹çš„ç”¨æˆ·å‚ä¸åº¦æä¾›äº†æ–°çš„ç†è®ºæ¡†æ¶å’Œå®è¯è¯æ®ã€‚",
      "categories": [
        "cs.LG",
        "cs.AI"
      ],
      "primary_category": "cs.LG",
      "comment": "9 pages, 5 figures",
      "pdf_url": "https://arxiv.org/pdf/2512.13726v1",
      "published_date": "2025-12-13 20:32:47 UTC",
      "updated_date": "2025-12-13 20:32:47 UTC",
      "processing_status": "completed",
      "attempts": 1,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "llm_backup_calls": 0,
      "last_update": "2026-01-26T16:23:58.161470+00:00"
    },
    {
      "arxiv_id": "2512.12443v1",
      "title": "AI Transparency Atlas: Framework, Scoring, and Real-Time Model Card Evaluation Pipeline",
      "title_zh": "AI Transparency Atlasï¼šæ¡†æ¶ã€è¯„åˆ†åŠå®æ—¶æ¨¡å‹å¡è¯„ä¼°æµæ°´çº¿",
      "authors": [
        "Akhmadillo Mamirov",
        "Faiaz Azmain",
        "Hanyu Wang"
      ],
      "abstract": "AI model documentation is fragmented across platforms and inconsistent in structure, preventing policymakers, auditors, and users from reliably assessing safety claims, data provenance, and version-level changes. We analyzed documentation from five frontier models (Gemini 3, Grok 4.1, Llama 4, GPT-5, and Claude 4.5) and 100 Hugging Face model cards, identifying 947 unique section names with extreme naming variation. Usage information alone appeared under 97 distinct labels. Using the EU AI Act Annex IV and the Stanford Transparency Index as baselines, we developed a weighted transparency framework with 8 sections and 23 subsections that prioritizes safety-critical disclosures (Safety Evaluation: 25%, Critical Risk: 20%) over technical specifications. We implemented an automated multi-agent pipeline that extracts documentation from public sources and scores completeness through LLM-based consensus. Evaluating 50 models across vision, multimodal, open-source, and closed-source systems cost less than $3 in total and revealed systematic gaps. Frontier labs (xAI, Microsoft, Anthropic) achieve approximately 80% compliance, while most providers fall below 60%. Safety-critical categories show the largest deficits: deception behaviors, hallucinations, and child safety evaluations account for 148, 124, and 116 aggregate points lost, respectively, across all evaluated models.",
      "tldr_zh": "è¯¥ç ”ç©¶é’ˆå¯¹AIæ¨¡å‹æ–‡æ¡£é›¶æ•£ä¸”ä¸ä¸€è‡´çš„ç°çŠ¶ï¼Œæå‡ºäº†AI Transparency Atlasæ¡†æ¶ï¼Œæ—¨åœ¨è§£å†³æ”¿ç­–åˆ¶å®šè€…å’Œç”¨æˆ·éš¾ä»¥è¯„ä¼°æ¨¡å‹å®‰å…¨æ€§åŠæ•°æ®æ¥æºç­‰é—®é¢˜ã€‚é€šè¿‡åˆ†æGemini 3ã€GPT-5ç­‰å‰æ²¿æ¨¡å‹åŠHugging Faceä¸Šçš„model cardsï¼Œç ”ç©¶åˆ¶å®šäº†ä¸€ä¸ªåŸºäºEU AI Actå’ŒStanford Transparency Indexçš„åŠ æƒé€æ˜åº¦æ¡†æ¶ï¼Œé‡ç‚¹ä¼˜å…ˆè€ƒè™‘Safety Evaluationå’ŒCritical Riskç­‰å®‰å…¨å…³é”®æŠ«éœ²ã€‚ç ”ç©¶å›¢é˜Ÿè¿˜å®ç°äº†ä¸€ä¸ªè‡ªåŠ¨åŒ–å¤šæ™ºèƒ½ä½“æµæ°´çº¿(multi-agent pipeline)ï¼Œåˆ©ç”¨LLMå…±è¯†æœºåˆ¶ä»å…¬å…±æ¥æºæå–å¹¶è¯„ä¼°æ–‡æ¡£å®Œæ•´æ€§ã€‚å®éªŒå¯¹50ä¸ªæ¨¡å‹è¿›è¡Œäº†è¯„ä¼°ï¼Œç»“æœæ˜¾ç¤ºå‰æ²¿å®éªŒå®¤çš„åˆè§„ç‡çº¦ä¸º80%ï¼Œè€Œå¤§å¤šæ•°ä¾›åº”å•†åˆ™ä½äº60%ã€‚ç ”ç©¶è¿›ä¸€æ­¥æ­ç¤ºäº†ç³»ç»Ÿæ€§çš„é€æ˜åº¦ç¼ºå£ï¼Œç‰¹åˆ«æ˜¯åœ¨æ¬ºéª—è¡Œä¸º(deception behaviors)ã€å¹»è§‰(hallucinations)å’Œå„¿ç«¥å®‰å…¨è¯„ä¼°ç­‰å®‰å…¨å…³é”®é¢†åŸŸå­˜åœ¨æ˜¾è‘—çš„å¾—åˆ†æŸå¤±ã€‚",
      "categories": [
        "cs.AI",
        "cs.SE"
      ],
      "primary_category": "cs.AI",
      "comment": "",
      "pdf_url": "https://arxiv.org/pdf/2512.12443v1",
      "published_date": "2025-12-13 19:48:44 UTC",
      "updated_date": "2025-12-13 19:48:44 UTC",
      "processing_status": "completed",
      "attempts": 1,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "llm_backup_calls": 0,
      "last_update": "2026-01-26T16:25:38.086999+00:00"
    },
    {
      "arxiv_id": "2512.12436v1",
      "title": "Rough Sets for Explainability of Spectral Graph Clustering",
      "title_zh": "é¢å‘è°±å›¾èšç±»å¯è§£é‡Šæ€§çš„ç²—ç³™é›†ç ”ç©¶",
      "authors": [
        "BartÅ‚omiej Starosta",
        "SÅ‚awomir T. WierzchoÅ„",
        "Piotr Borkowski",
        "Dariusz Czerski",
        "Marcin Sydow",
        "Eryk Laskowski",
        "MieczysÅ‚aw A. KÅ‚opotek"
      ],
      "abstract": "Graph Spectral Clustering methods (GSC) allow representing clusters of diverse shapes, densities, etc. However, the results of such algorithms, when applied e.g. to text documents, are hard to explain to the user, especially due to embedding in the spectral space which has no obvious relation to document contents. Furthermore, the presence of documents without clear content meaning and the stochastic nature of the clustering algorithms deteriorate explainability. This paper proposes an enhancement to the explanation methodology, proposed in an earlier research of our team. It allows us to overcome the latter problems by taking inspiration from rough set theory.",
      "tldr_zh": "è¯¥ç ”ç©¶é’ˆå¯¹å›¾è°±èšç±»(Graph Spectral Clustering, GSC)åœ¨å¤„ç†æ–‡æœ¬æ–‡æ¡£æ—¶è§£é‡Šæ€§ä¸è¶³çš„é—®é¢˜ï¼Œé‡ç‚¹æ¢è®¨äº†è°±ç©ºé—´åµŒå…¥(spectral space)ä¸æ–‡æ¡£å†…å®¹ä¹‹é—´ç¼ºä¹ç›´è§‚è”ç³»çš„æŒ‘æˆ˜ã€‚ç”±äºéƒ¨åˆ†æ–‡æ¡£è¯­ä¹‰æ¨¡ç³Šä»¥åŠèšç±»ç®—æ³•å…·æœ‰éšæœºæ€§ï¼Œå¯¼è‡´èšç±»ç»“æœéš¾ä»¥å‘ç”¨æˆ·æä¾›æ¸…æ™°çš„è§£é‡Šã€‚ä¸ºæ­¤ï¼Œæœ¬æ–‡æå‡ºäº†ä¸€ç§åŸºäºç²—ç³™é›†ç†è®º(rough set theory)çš„è§£é‡Šæ–¹æ³•å¢å¼ºæ–¹æ¡ˆï¼Œä½œä¸ºå¯¹è¯¥å›¢é˜Ÿæ—©æœŸç ”ç©¶æˆæœçš„æ”¹è¿›ã€‚è¯¥æ–¹æ³•é€šè¿‡å€Ÿé‰´ç²—ç³™é›†å¤„ç†ä¸ç¡®å®šæ€§çš„ä¼˜åŠ¿ï¼ŒæˆåŠŸå…‹æœäº†ä¸Šè¿°å› ç´ å¯¹è§£é‡Šæ€§é€ æˆçš„è´Ÿé¢å½±å“ã€‚é€šè¿‡è¿™ä¸€å¢å¼ºæ–¹æ¡ˆï¼Œç ”ç©¶ä¸ºå¤æ‚çš„è°±èšç±»æ¨¡å‹æä¾›äº†æ›´å…·è¯´æœåŠ›ä¸”ä¸å†…å®¹ç›´æ¥ç›¸å…³çš„è§£é‡Šã€‚",
      "categories": [
        "cs.LG",
        "cs.AI"
      ],
      "primary_category": "cs.LG",
      "comment": "24 figures, 21tables",
      "pdf_url": "https://arxiv.org/pdf/2512.12436v1",
      "published_date": "2025-12-13 19:29:04 UTC",
      "updated_date": "2025-12-13 19:29:04 UTC",
      "processing_status": "completed",
      "attempts": 1,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "llm_backup_calls": 0,
      "last_update": "2026-01-26T16:25:48.935346+00:00"
    },
    {
      "arxiv_id": "2512.19707v1",
      "title": "Bidirectional human-AI collaboration in brain tumour assessments improves both expert human and AI agent performance",
      "title_zh": "è„‘è‚¿ç˜¤è¯„ä¼°ä¸­çš„äººæœºåŒå‘åä½œåŒæ—¶æå‡äº†äººç±»ä¸“å®¶ä¸ AI æ™ºèƒ½ä½“çš„æ€§èƒ½",
      "authors": [
        "James K Ruffle",
        "Samia Mohinta",
        "Guilherme Pombo",
        "Asthik Biswas",
        "Alan Campbell",
        "Indran Davagnanam",
        "David Doig",
        "Ahmed Hamman",
        "Harpreet Hyare",
        "Farrah Jabeen",
        "Emma Lim",
        "Dermot Mallon",
        "Stephanie Owen",
        "Sophie Wilkinson",
        "Sebastian Brandner",
        "Parashkev Nachev"
      ],
      "abstract": "The benefits of artificial intelligence (AI) human partnerships-evaluating how AI agents enhance expert human performance-are increasingly studied. Though rarely evaluated in healthcare, an inverse approach is possible: AI benefiting from the support of an expert human agent. Here, we investigate both human-AI clinical partnership paradigms in the magnetic resonance imaging-guided characterisation of patients with brain tumours. We reveal that human-AI partnerships improve accuracy and metacognitive ability not only for radiologists supported by AI, but also for AI agents supported by radiologists. Moreover, the greatest patient benefit was evident with an AI agent supported by a human one. Synergistic improvements in agent accuracy, metacognitive performance, and inter-rater agreement suggest that AI can create more capable, confident, and consistent clinical agents, whether human or model-based. Our work suggests that the maximal value of AI in healthcare could emerge not from replacing human intelligence, but from AI agents that routinely leverage and amplify it.",
      "tldr_zh": "è¿™é¡¹ç ”ç©¶æ¢è®¨äº†åœ¨ç£å…±æŒ¯æˆåƒ(MRI)å¼•å¯¼çš„è„‘è‚¿ç˜¤å®šæ€§è¯„ä¼°ä¸­ï¼Œäººç±»ä¸äººå·¥æ™ºèƒ½(AI)ä¹‹é—´çš„åŒå‘åä½œæ¨¡å¼ã€‚ç ”ç©¶ä¸ä»…è¯„ä¼°äº†AIå¦‚ä½•æå‡æ”¾å°„ç§‘åŒ»ç”Ÿçš„è¡¨ç°ï¼Œè¿˜åˆ›æ–°æ€§åœ°è€ƒå¯Ÿäº†ä¸“å®¶ç»éªŒå¦‚ä½•æ”¯æŒAIæ™ºèƒ½ä½“çš„å†³ç­–è¿‡ç¨‹ã€‚å®éªŒç»“æœæ˜¾ç¤ºï¼ŒåŒå‘çš„äººæœºåä½œ(human-AI clinical partnership)æ˜¾è‘—æé«˜äº†æ”¾å°„ç§‘åŒ»ç”Ÿå’ŒAIæ™ºèƒ½ä½“çš„å‡†ç¡®ç‡åŠå…ƒè®¤çŸ¥èƒ½åŠ›(metacognitive ability)ã€‚åœ¨æ‰€æœ‰æµ‹è¯•åœºæ™¯ä¸­ï¼Œç”±äººç±»ä¸“å®¶æ”¯æŒçš„AIæ™ºèƒ½ä½“å±•ç°å‡ºäº†æœ€ä½³çš„æ‚£è€…è·ç›Šï¼Œå¹¶å®ç°äº†è¯„åˆ†è€…é—´ä¸€è‡´æ€§(inter-rater agreement)çš„ååŒæå‡ã€‚ç ”ç©¶ç»“æœè¡¨æ˜ï¼ŒAIä¸ä»…èƒ½ä½¿ä¸´åºŠå†³ç­–æ›´åŠ è‡ªä¿¡å’Œä¸€è‡´ï¼Œå…¶åœ¨åŒ»ç–—é¢†åŸŸçš„æœ€å¤§ä»·å€¼æºäºå¯¹äººç±»æ™ºèƒ½çš„å¸¸è§„åˆ©ç”¨ä¸æ”¾å¤§ï¼Œè€Œéç®€å•çš„æ›¿ä»£ã€‚è¿™ç§ååŒä½œç”¨ä¸ºå¼€å‘æ›´å…·èƒ½åŠ›å’Œå¯ä¿¡åº¦çš„ä¸´åºŠæ™ºèƒ½ä½“å¥ å®šäº†åŸºç¡€ã€‚",
      "categories": [
        "cs.HC",
        "cs.AI",
        "cs.LG",
        "cs.MA"
      ],
      "primary_category": "cs.HC",
      "comment": "38 pages, 6 figures, 7 supplementary figures",
      "pdf_url": "https://arxiv.org/pdf/2512.19707v1",
      "published_date": "2025-12-13 18:56:50 UTC",
      "updated_date": "2025-12-13 18:56:50 UTC",
      "processing_status": "completed",
      "attempts": 1,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "llm_backup_calls": 0,
      "last_update": "2026-01-26T16:25:40.758813+00:00"
    },
    {
      "arxiv_id": "2512.12413v1",
      "title": "Understanding Critical Thinking in Generative Artificial Intelligence Use: Development, Validation, and Correlates of the Critical Thinking in AI Use Scale",
      "title_zh": "ç†è§£ç”Ÿæˆå¼äººå·¥æ™ºèƒ½ä½¿ç”¨ä¸­çš„æ‰¹åˆ¤æ€§æ€ç»´ï¼šäººå·¥æ™ºèƒ½ä½¿ç”¨æ‰¹åˆ¤æ€§æ€ç»´é‡è¡¨çš„ç¼–åˆ¶ã€éªŒè¯ä¸ç›¸å…³å› ç´ ",
      "authors": [
        "Gabriel R. Lau",
        "Wei Yan Low",
        "Louis Tay",
        "Ysabel Guevarra",
        "Dragan GaÅ¡eviÄ‡",
        "Andree Hartanto"
      ],
      "abstract": "Generative AI tools are increasingly embedded in everyday work and learning, yet their fluency, opacity, and propensity to hallucinate mean that users must critically evaluate AI outputs rather than accept them at face value. The present research conceptualises critical thinking in AI use as a dispositional tendency to verify the source and content of AI-generated information, to understand how models work and where they fail, and to reflect on the broader implications of relying on AI. Across six studies (N = 1365), we developed and validated the 13-item critical thinking in AI use scale and mapped its nomological network. Study 1 generated and content-validated scale items. Study 2 supported a three-factor structure (Verification, Motivation, and Reflection). Studies 3, 4, and 5 confirmed this higher-order model, demonstrated internal consistency and test-retest reliability, strong factor loadings, sex invariance, and convergent and discriminant validity. Studies 3 and 4 further revealed that critical thinking in AI use was positively associated with openness, extraversion, positive trait affect, and frequency of AI use. Lastly, Study 6 demonstrated criterion validity of the scale, with higher critical thinking in AI use scores predicting more frequent and diverse verification strategies, greater veracity-judgement accuracy in a novel and naturalistic ChatGPT-powered fact-checking task, and deeper reflection about responsible AI. Taken together, the current work clarifies why and how people exercise oversight over generative AI outputs and provides a validated scale and ecologically grounded task paradigm to support theory testing, cross-group, and longitudinal research on critical engagement with generative AI outputs.",
      "tldr_zh": "è¯¥ç ”ç©¶é’ˆå¯¹ç”Ÿæˆå¼äººå·¥æ™ºèƒ½(Generative AI)çš„æµç•…æ€§ã€ä¸é€æ˜æ€§å’Œå¹»è§‰é—®é¢˜ï¼Œæå‡ºäº†â€œAI ä½¿ç”¨ä¸­çš„æ‰¹åˆ¤æ€§æ€ç»´(Critical Thinking in AI Use)â€æ¦‚å¿µï¼Œå¹¶å°†å…¶å®šä¹‰ä¸ºæ ¸å®ä¿¡æ¯æ¥æºã€ç†è§£æ¨¡å‹å±€é™åŠåæ€ä¾èµ–å½±å“çš„å€¾å‘æ€§ã€‚é€šè¿‡å…­é¡¹æ€»è®¡1365åå‚ä¸è€…çš„ç ”ç©¶ï¼Œç ”ç©¶è€…å¼€å‘å¹¶éªŒè¯äº†ä¸€ä¸ªåŒ…å«13ä¸ªé¡¹ç›®çš„æµ‹é‡é‡è¡¨ï¼Œç¡®ç«‹äº†ç”±æ ¸å®(Verification)ã€åŠ¨æœº(Motivation)å’Œåæ€(Reflection)æ„æˆçš„ä¸‰å› å­ç»“æ„ã€‚ç ”ç©¶å‘ç°è¯¥ç‰¹è´¨ä¸å¼€æ”¾æ€§(Openness)ã€å¤–å‘æ€§(Extraversion)å’ŒAIä½¿ç”¨é¢‘ç‡å‘ˆæ­£ç›¸å…³ï¼Œä¸”é‡è¡¨å¾—åˆ†èƒ½æœ‰æ•ˆé¢„æµ‹ç”¨æˆ·åœ¨å®é™…äº‹å®æ ¸æŸ¥ä»»åŠ¡ä¸­çš„å‡†ç¡®æ€§åŠæ ¸å®ç­–ç•¥çš„å¤šæ ·æ€§ã€‚è¯¥å·¥ä½œä¸ä»…é˜æ˜äº†ç”¨æˆ·å¯¹Generative AIè¾“å‡ºå®æ–½ç›‘ç£çš„å¿ƒç†æœºåˆ¶ï¼Œè¿˜ä¸ºæœªæ¥å…³äºè´Ÿè´£ä»»AI(Responsible AI)çš„çºµå‘ç ”ç©¶å’Œè·¨ç¾¤ä½“æ¯”è¾ƒæä¾›äº†ç»è¿‡éªŒè¯çš„è¯„ä¼°å·¥å…·å’Œç”Ÿæ€æ•ˆåº¦è‰¯å¥½çš„å®éªŒèŒƒå¼ã€‚",
      "categories": [
        "cs.AI",
        "cs.HC"
      ],
      "primary_category": "cs.AI",
      "comment": "",
      "pdf_url": "https://arxiv.org/pdf/2512.12413v1",
      "published_date": "2025-12-13 17:56:12 UTC",
      "updated_date": "2025-12-13 17:56:12 UTC",
      "processing_status": "completed",
      "attempts": 1,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "llm_backup_calls": 0,
      "last_update": "2026-01-26T16:25:44.964611+00:00"
    },
    {
      "arxiv_id": "2512.13725v2",
      "title": "Compressed Causal Reasoning: Quantization and GraphRAG Effects on Interventional and Counterfactual Accuracy",
      "title_zh": "å‹ç¼©å› æœæ¨ç†ï¼šé‡åŒ–ä¸ GraphRAG å¯¹å¹²é¢„åŠåäº‹å®å‡†ç¡®æ€§çš„å½±å“",
      "authors": [
        "Steve Nwaiwu",
        "Nipat Jongsawat",
        "Anucha Tungkasthan"
      ],
      "abstract": "Causal reasoning in Large Language Models spanning association, intervention, and counterfactual inference is essential for reliable decision making in high stakes settings. As deployment shifts toward edge and resource constrained environments, quantized models such as INT8 and NF4 are becoming standard. Yet the impact of precision reduction on formal causal reasoning is poorly understood. To our knowledge, this is the first study to systematically evaluate quantization effects across all three levels of Pearls Causal Ladder. Using a 3000 sample stratified CLadder benchmark, we find that rung level accuracy in Llama 3 8B remains broadly stable under quantization, with NF4 showing less than one percent overall degradation. Interventional queries at rung 2 are the most sensitive to precision loss, whereas counterfactual reasoning at rung 3 is comparatively stable but exhibits heterogeneous weaknesses across query types such as collider bias and backdoor adjustment. Experiments on the CRASS benchmark show near identical performance across precisions, indicating that existing commonsense counterfactual datasets lack the structural sensitivity needed to reveal quantization induced reasoning drift. We further evaluate Graph Retrieval Augmented Generation using ground truth causal graphs and observe a consistent improvement in NF4 interventional accuracy of plus 1.7 percent, partially offsetting compression related degradation. These results suggest that causal reasoning is unexpectedly robust to four bit quantization, graph structured augmentation can selectively reinforce interventional reasoning, and current counterfactual benchmarks fail to capture deeper causal brittleness. This work provides an initial empirical map of compressed causal reasoning and practical guidance for deploying efficient and structurally supported causal AI systems.",
      "tldr_zh": "è¯¥ç ”ç©¶æ¢è®¨äº†é‡åŒ–(Quantization)æŠ€æœ¯å¯¹å¤§è¯­è¨€æ¨¡å‹åœ¨å› æœé˜¶æ¢¯(Causal Ladder)å„å±‚çº§æ¨ç†èƒ½åŠ›çš„å½±å“ï¼Œé‡ç‚¹åˆ†æäº†INT8å’ŒNF4ç­‰é‡åŒ–ç²¾åº¦å¯¹å…³è”ã€å¹²é¢„å’Œåäº‹å®æ¨ç†çš„ä½œç”¨ã€‚é€šè¿‡å¯¹Llama 3 8Båœ¨CLadderåŸºå‡†ä¸Šçš„ç³»ç»Ÿè¯„ä¼°ï¼Œå‘ç°å› æœæ¨ç†åœ¨4æ¯”ç‰¹é‡åŒ–ä¸‹è¡¨ç°å‡ºå‡ºä¹æ„æ–™çš„ç¨³å¥æ€§ï¼Œå…¶ä¸­NF4æ•´ä½“é€€åŒ–ä¸è¶³1%ï¼Œä½†å¹²é¢„æŸ¥è¯¢(Interventional queries)å¯¹ç²¾åº¦æŸå¤±æœ€ä¸ºæ•æ„Ÿã€‚ç ”ç©¶è¿›ä¸€æ­¥æŒ‡å‡ºï¼Œç°æœ‰çš„CRASSç­‰å¸¸è¯†åäº‹å®æ•°æ®é›†ç¼ºä¹æ•æ‰é‡åŒ–è¯±å¯¼æ¨ç†æ¼‚ç§»æ‰€éœ€çš„ç»“æ„æ•æ„Ÿæ€§ã€‚å®éªŒè¡¨æ˜ï¼Œå¼•å…¥åŸºäºçœŸå®å› æœå›¾çš„æ£€ç´¢å¢å¼ºç”Ÿæˆ(GraphRAG)èƒ½ä½¿NF4çš„å¹²é¢„å‡†ç¡®ç‡æå‡1.7%ï¼Œä»è€Œæœ‰æ•ˆæŠµæ¶ˆæ¨¡å‹å‹ç¼©å¸¦æ¥çš„æ€§èƒ½ä¸‹é™ã€‚è¯¥å·¥ä½œé¦–æ¬¡ä¸ºå‹ç¼©åçš„å› æœæ¨ç†æä¾›äº†å®è¯å›¾è°±ï¼Œå¹¶ä¸ºåœ¨èµ„æºå—é™ç¯å¢ƒä¸‹éƒ¨ç½²é«˜æ•ˆçš„å› æœäººå·¥æ™ºèƒ½ç³»ç»Ÿæä¾›äº†å®è·µæŒ‡å—ã€‚",
      "categories": [
        "cs.AI"
      ],
      "primary_category": "cs.AI",
      "comment": "",
      "pdf_url": "https://arxiv.org/pdf/2512.13725v2",
      "published_date": "2025-12-13 17:54:15 UTC",
      "updated_date": "2025-12-24 05:31:23 UTC",
      "processing_status": "completed",
      "attempts": 1,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "llm_backup_calls": 0,
      "last_update": "2026-01-26T16:25:57.655924+00:00"
    },
    {
      "arxiv_id": "2512.12411v1",
      "title": "Feeling the Strength but Not the Source: Partial Introspection in LLMs",
      "title_zh": "çŸ¥å…¶å¼ºè€Œä¸çŸ¥å…¶æºï¼šå¤§è¯­è¨€æ¨¡å‹ä¸­çš„éƒ¨åˆ†å†…çœ",
      "authors": [
        "Ely Hahami",
        "Lavik Jain",
        "Ishaan Sinha"
      ],
      "abstract": "Recent work from Anthropic claims that frontier models can sometimes detect and name injected \"concepts\" represented as activation directions. We test the robustness of these claims. First, we reproduce Anthropic's multi-turn \"emergent introspection\" result on Meta-Llama-3.1-8B-Instruct, finding that the model identifies and names the injected concept 20 percent of the time under Anthropic's original pipeline, exactly matching their reported numbers and thus showing that introspection is not exclusive to very large or capable models. Second, we systematically vary the inference prompt and find that introspection is fragile: performance collapses on closely related tasks such as multiple-choice identification of the injected concept or different prompts of binary discrimination of whether a concept was injected at all. Third, we identify a contrasting regime of partial introspection: the same model can reliably classify the strength of the coefficient of a normalized injected concept vector (as weak / moderate / strong / very strong) with up to 70 percent accuracy, far above the 25 percent chance baseline. Together, these results provide more evidence for Anthropic's claim that language models effectively compute a function of their baseline, internal representations during introspection; however, these self-reports about those representations are narrow and prompt-sensitive. Our code is available at https://github.com/elyhahami18/CS2881-Introspection.",
      "tldr_zh": "è¯¥ç ”ç©¶æ¢è®¨äº†å¤§è¯­è¨€æ¨¡å‹(LLMs)çš„å†…çœ(introspection)èƒ½åŠ›ï¼Œå³æ¨¡å‹æ£€æµ‹å¹¶å‘½åç”±æ¿€æ´»æ–¹å‘(activation directions)è¡¨ç¤ºçš„æ³¨å…¥â€œæ¦‚å¿µâ€çš„èƒ½åŠ›ã€‚ç ”ç©¶åœ¨Meta-Llama-3.1-8B-Instructä¸ŠæˆåŠŸå¤ç°äº†ç›¸å…³å®éªŒï¼Œè¯æ˜å†…çœèƒ½åŠ›å¹¶éä»…å­˜åœ¨äºè¶…å¤§è§„æ¨¡æ¨¡å‹ä¸­ã€‚ç„¶è€Œï¼Œé€šè¿‡ç³»ç»Ÿåœ°æ”¹å˜æ¨ç†æç¤º(inference prompt)ï¼Œç ”ç©¶å‘ç°è¿™ç§å†…çœèƒ½åŠ›å…·æœ‰æ˜¾è‘—çš„è„†å¼±æ€§ï¼Œå…¶è¡¨ç°åœ¨å¤šé¡¹é€‰æ‹©æˆ–äºŒå…ƒåŒºåˆ†ä»»åŠ¡ä¸­ä¼šè¿…é€Ÿä¸‹é™ã€‚ç ”ç©¶è¿›ä¸€æ­¥è¯†åˆ«å‡ºä¸€ç§â€œå±€éƒ¨å†…çœâ€(partial introspection)ç°è±¡ï¼Œå³æ¨¡å‹è™½éš¾ä»¥å‡†ç¡®å‘½åæ¦‚å¿µæ¥æºï¼Œå´èƒ½ä»¥é«˜è¾¾70%çš„å‡†ç¡®ç‡åˆ†ç±»æ³¨å…¥æ¦‚å¿µå‘é‡çš„å¼ºåº¦(strength)ã€‚è¿™äº›ç»“æœè¡¨æ˜LLMsåœ¨å†…çœè¿‡ç¨‹ä¸­èƒ½æœ‰æ•ˆè®¡ç®—å…¶å†…éƒ¨è¡¨ç¤ºçš„å‡½æ•°ï¼Œä½†è¿™ç§è‡ªæˆ‘æŠ¥å‘Šèƒ½åŠ›éå¸¸ç‹­çª„ä¸”å¯¹æç¤ºé«˜åº¦æ•æ„Ÿã€‚",
      "categories": [
        "cs.AI"
      ],
      "primary_category": "cs.AI",
      "comment": "7 pages (+ 5 pages for appendix), 5 figures, 1 table",
      "pdf_url": "https://arxiv.org/pdf/2512.12411v1",
      "published_date": "2025-12-13 17:51:13 UTC",
      "updated_date": "2025-12-13 17:51:13 UTC",
      "processing_status": "completed",
      "attempts": 1,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "llm_backup_calls": 0,
      "last_update": "2026-01-26T16:26:14.536542+00:00"
    },
    {
      "arxiv_id": "2512.12410v1",
      "title": "A Graph Attention Network-Based Framework for Reconstructing Missing LiDAR Beams",
      "title_zh": "åŸºäºå›¾æ³¨æ„åŠ›ç½‘ç»œçš„æ¿€å…‰é›·è¾¾ç¼ºå¤±çº¿æŸé‡å»ºæ¡†æ¶",
      "authors": [
        "Khalfalla Awedat",
        "Mohamed Abidalrekab",
        "Mohammad El-Yabroudi"
      ],
      "abstract": "Vertical beam dropout in spinning LiDAR sensors triggered by hardware aging, dust, snow, fog, or bright reflections removes entire vertical slices from the point cloud and severely degrades 3D perception in autonomous vehicles. This paper proposes a Graph Attention Network (GAT)-based framework that reconstructs these missing vertical channels using only the current LiDAR frame, with no camera images or temporal information required. Each LiDAR sweep is represented as an unstructured spatial graph: points are nodes and edges connect nearby points while preserving the original beam-index ordering. A multi-layer GAT learns adaptive attention weights over local geometric neighborhoods and directly regresses the missing elevation (z) values at dropout locations. Trained and evaluated on 1,065 raw KITTI sequences with simulated channel dropout, the method achieves an average height RMSE of 11.67 cm, with 87.98% of reconstructed points falling within a 10 cm error threshold. Inference takes 14.65 seconds per frame on a single GPU, and reconstruction quality remains stable for different neighborhood sizes k. These results show that a pure graph attention model operating solely on raw point-cloud geometry can effectively recover dropped vertical beams under realistic sensor degradation.",
      "tldr_zh": "è¯¥ç ”ç©¶é’ˆå¯¹æ—‹è½¬å¼ LiDAR ä¼ æ„Ÿå™¨å› ç¡¬ä»¶è€åŒ–æˆ–æ¶åŠ£ç¯å¢ƒå¯¼è‡´çš„å‚ç›´å…‰æŸä¸¢å¤±ï¼ˆVertical beam dropoutï¼‰é—®é¢˜ï¼Œæå‡ºäº†ä¸€ç§åŸºäºå›¾æ³¨æ„åŠ›ç½‘ç»œï¼ˆGraph Attention Network, GATï¼‰çš„é‡å»ºæ¡†æ¶ã€‚è¯¥æ–¹æ³•ä»…åˆ©ç”¨å½“å‰çš„ LiDAR å•å¸§æ•°æ®ï¼Œå°†ç‚¹äº‘å»ºæ¨¡ä¸ºç”±ç‚¹å’Œè¾¹æ„æˆçš„éç»“æ„åŒ–ç©ºé—´å›¾ï¼ˆunstructured spatial graphï¼‰ï¼Œä»è€Œæ— éœ€æ‘„åƒå¤´å›¾åƒæˆ–æ—¶é—´åºåˆ—ä¿¡æ¯ã€‚é€šè¿‡å¤šå±‚ GAT å­¦ä¹ å±€éƒ¨å‡ ä½•é‚»åŸŸçš„è‡ªé€‚åº”æ³¨æ„åŠ›æƒé‡ï¼Œè¯¥æ¡†æ¶èƒ½ç›´æ¥å›å½’ç¼ºå¤±ä½ç½®çš„é«˜åº¦å€¼ï¼ˆzï¼‰ã€‚åœ¨ 1,065 ä¸ª KITTI åŸå§‹åºåˆ—ä¸Šçš„è¯„ä¼°ç»“æœæ˜¾ç¤ºï¼Œè¯¥æ–¹æ³•çš„å¹³å‡é«˜åº¦ RMSE ä¸º 11.67 å˜ç±³ï¼Œä¸”æœ‰ 87.98% çš„é‡å»ºç‚¹è¯¯å·®æ§åˆ¶åœ¨ 10 å˜ç±³ä»¥å†…ã€‚å®éªŒè¯æ˜ï¼Œè¿™ç§çº¯å›¾æ³¨æ„åŠ›æ¨¡å‹åœ¨æ¯å¸§æ¨ç†è€—æ—¶ 14.65 ç§’çš„æƒ…å†µä¸‹ï¼Œèƒ½å¤Ÿæœ‰æ•ˆæ¢å¤å„ç§ä¼ æ„Ÿå™¨é€€åŒ–åœºæ™¯ä¸‹çš„ç¼ºå¤±å…‰æŸã€‚",
      "categories": [
        "cs.CV",
        "cs.AI"
      ],
      "primary_category": "cs.CV",
      "comment": "",
      "pdf_url": "https://arxiv.org/pdf/2512.12410v1",
      "published_date": "2025-12-13 17:50:57 UTC",
      "updated_date": "2025-12-13 17:50:57 UTC",
      "processing_status": "completed",
      "attempts": 1,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "llm_backup_calls": 0,
      "last_update": "2026-01-26T16:25:59.174735+00:00"
    },
    {
      "arxiv_id": "2512.15776v1",
      "title": "Emergence: Overcoming Privileged Information Bias in Asymmetric Embodied Agents via Active Querying",
      "title_zh": "Emergenceï¼šé€šè¿‡ä¸»åŠ¨æŸ¥è¯¢å…‹æœéå¯¹ç§°å…·èº«æ™ºèƒ½ä½“ä¸­çš„ç‰¹æƒä¿¡æ¯åå·®",
      "authors": [
        "Shaun Baek",
        "Sam Liu",
        "Joseph Ukpong"
      ],
      "abstract": "Large Language Models (LLMs) act as powerful reasoning engines but struggle with \"symbol grounding\" in embodied environments, particularly when information is asymmetrically distributed. We investigate the Privileged Information Bias (or \"Curse of Knowledge\"), where a knowledgeable \"Leader\" agent fails to guide a sensor-limited \"Follower\" due to a lack of Theory of Mind. To quantify this phenomenon, we propose a novel Asymmetric Assistive Reasoning framework within AI2-THOR. Our experiments reveal a significant \"Success Gap\": while the Leader successfully perceives the target in 35.0% of episodes, the collaborative team succeeds only 17.0% of the time, implying that nearly 50% of feasible plans fail solely due to communicative grounding errors. We demonstrate that a \"Pull-based\" protocol (active querying) is significantly more robust than standard \"Push-based\" instruction, with successful episodes featuring 2x the frequency of clarification requests. This research isolates the mechanism of active uncertainty reduction as a prerequisite for safe human-AI and robot-robot collaboration.",
      "tldr_zh": "è¯¥ç ”ç©¶æ¢è®¨äº†å…·èº«æ™ºèƒ½ä½“(Embodied Agents)åœ¨éå¯¹ç§°ä¿¡æ¯åˆ†å¸ƒç¯å¢ƒä¸‹çš„ç¬¦å·æ¥åœ°(Symbol Grounding)éš¾é¢˜ï¼Œç‰¹åˆ«æ˜¯çŸ¥è¯†æ¸Šåšçš„é¢†å¯¼è€…(Leader)å› ç¼ºä¹å¿ƒç†ç†è®º(Theory of Mind)è€Œæ— æ³•æœ‰æ•ˆå¼•å¯¼ä¼ æ„Ÿå—é™çš„è·Ÿéšè€…(Follower)æ‰€å¯¼è‡´çš„ç‰¹æƒä¿¡æ¯åå·®(Privileged Information Bias)ã€‚ä¸ºé‡åŒ–è¿™ä¸€ç°è±¡ï¼Œç ”ç©¶è€…åœ¨ AI2-THOR ç¯å¢ƒä¸­æå‡ºäº†ä¸€ä¸ªå…¨æ–°çš„éå¯¹ç§°è¾…åŠ©æ¨ç†(Asymmetric Assistive Reasoning)æ¡†æ¶ã€‚å®éªŒæ­ç¤ºäº†æ˜¾è‘—çš„æˆåŠŸç‡å·®è·(Success Gap)ï¼Œå³é¢†å¯¼è€…æ„ŸçŸ¥ç›®æ ‡æˆåŠŸç‡è¾¾35%ï¼Œè€Œå›¢é˜Ÿåä½œæˆåŠŸç‡ä»…17%ï¼Œæ„å‘³ç€è¿‘50%çš„å¯è¡Œè®¡åˆ’å› é€šä¿¡æ¥åœ°é”™è¯¯è€Œå¤±è´¥ã€‚ç ”ç©¶å‘ç°ï¼Œä¸»åŠ¨æŸ¥è¯¢(Active Querying)è¿™ç§åŸºäºæ‹‰å–(Pull-based)çš„åè®®æ¯”æ ‡å‡†çš„åŸºäºæ¨é€(Push-based)çš„æŒ‡ä»¤æ›´å…·é²æ£’æ€§ï¼ŒæˆåŠŸæ¡ˆä¾‹ä¸­æ¾„æ¸…è¯·æ±‚çš„é¢‘ç‡æå‡äº†ä¸¤å€ã€‚è¯¥ç ”ç©¶éš”ç¦»äº†ä¸»åŠ¨ä¸ç¡®å®šæ€§å‡å°‘(Active Uncertainty Reduction)è¿™ä¸€æœºåˆ¶ï¼Œå¹¶å°†å…¶è§†ä¸ºå®ç°å®‰å…¨çš„äººæœºåä½œ(Human-AI)å’Œå¤šæœºå™¨äººåä½œ(Robot-Robot Collaboration)çš„å…³é”®å‰æã€‚",
      "categories": [
        "cs.AI",
        "cs.MA",
        "cs.RO"
      ],
      "primary_category": "cs.AI",
      "comment": "12 pages, 9 pages of content, 6 tables, 5 figures",
      "pdf_url": "https://arxiv.org/pdf/2512.15776v1",
      "published_date": "2025-12-13 17:17:51 UTC",
      "updated_date": "2025-12-13 17:17:51 UTC",
      "processing_status": "completed",
      "attempts": 1,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "llm_backup_calls": 0,
      "last_update": "2026-01-26T16:27:00.790115+00:00"
    },
    {
      "arxiv_id": "2512.12381v1",
      "title": "Entropy Collapse: A Universal Failure Mode of Intelligent Systems",
      "title_zh": "ç†µåç¼©ï¼šæ™ºèƒ½ç³»ç»Ÿçš„æ™®é€‚å¤±æ•ˆæ¨¡å¼",
      "authors": [
        "Truong Xuan Khanh",
        "Truong Quynh Hoa"
      ],
      "abstract": "Intelligent systems are widely assumed to improve through learning, coordination, and optimization. However, across domains -- from artificial intelligence to economic institutions and biological evolution -- increasing intelligence often precipitates paradoxical degradation: systems become rigid, lose adaptability, and fail unexpectedly.\n  We identify \\emph{entropy collapse} as a universal dynamical failure mode arising when feedback amplification outpaces bounded novelty regeneration. Under minimal domain-agnostic assumptions, we show that intelligent systems undergo a sharp transition from high-entropy adaptive regimes to low-entropy collapsed regimes. Collapse is formalized as convergence toward a stable low-entropy manifold, not a zero-entropy state, implying a contraction of effective adaptive dimensionality rather than loss of activity or scale.\n  We analytically establish critical thresholds, dynamical irreversibility, and attractor structure and demonstrate universality across update mechanisms through minimal simulations. This framework unifies diverse phenomena -- model collapse in AI, institutional sclerosis in economics, and genetic bottlenecks in evolution -- as manifestations of the same underlying process.\n  By reframing collapse as a structural cost of intelligence, our results clarify why late-stage interventions systematically fail and motivate entropy-aware design principles for sustaining long-term adaptability in intelligent systems.\n  \\noindent\\textbf{Keywords:} entropy collapse; intelligent systems; feedback amplification; phase transitions; effective dimensionality; complex systems; model collapse; institutional sclerosis",
      "tldr_zh": "è¯¥ç ”ç©¶æ¢è®¨äº†æ™ºèƒ½ç³»ç»Ÿåœ¨å­¦ä¹ å’Œä¼˜åŒ–è¿‡ç¨‹ä¸­æ™®éå­˜åœ¨çš„ä¸€ç§åä¸ºâ€œç†µåç¼©(Entropy Collapse)â€çš„åŠ¨æ€å¤±æ•ˆæ¨¡å¼ã€‚è¯¥æ¨¡å¼å‘ç”Ÿäºåé¦ˆæ”¾å¤§(feedback amplification)è¶…è¿‡äº†å—é™çš„åŸåˆ›å†ç”Ÿ(novelty regeneration)æ—¶ï¼Œå¯¼è‡´ç³»ç»Ÿä»é«˜ç†µé€‚åº”çŠ¶æ€é”è½¬ä¸ºä½ç†µåç¼©çŠ¶æ€ã€‚åç¼©è¢«å½¢å¼åŒ–ä¸ºå‘ç¨³å®šçš„ä½ç†µæµå½¢(low-entropy manifold)æ”¶æ•›ï¼Œå…¶å®è´¨æ˜¯æœ‰æ•ˆé€‚åº”ç»´åº¦(effective adaptive dimensionality)çš„æ”¶ç¼©ï¼Œè€Œéç³»ç»Ÿæ´»åŠ¨æˆ–è§„æ¨¡çš„ä¸§å¤±ã€‚ä½œè€…é€šè¿‡åˆ†æç¡®ç«‹äº†ä¸´ç•Œé˜ˆå€¼(critical thresholds)ã€åŠ¨åŠ›å­¦ä¸å¯é€†æ€§(dynamical irreversibility)å’Œå¸å¼•å­ç»“æ„(attractor structure)ï¼Œå¹¶åˆ©ç”¨æœ€å°åŒ–æ¨¡æ‹Ÿ(minimal simulations)è¯æ˜äº†è¯¥ç°è±¡åœ¨ä¸åŒæ›´æ–°æœºåˆ¶ä¸‹çš„æ™®é€‚æ€§ã€‚è¯¥æ¡†æ¶ç»Ÿä¸€è§£é‡Šäº†äººå·¥æ™ºèƒ½ä¸­çš„æ¨¡å‹åç¼©(model collapse)ã€ç»æµå­¦ä¸­çš„åˆ¶åº¦åƒµåŒ–(institutional sclerosis)ä»¥åŠç”Ÿç‰©è¿›åŒ–ä¸­çš„é—ä¼ ç“¶é¢ˆ(genetic bottlenecks)ç­‰ç°è±¡ã€‚ç ”ç©¶ç»“æœè¡¨æ˜åç¼©æ˜¯æ™ºèƒ½çš„ä¸€ç§ç»“æ„æ€§æˆæœ¬ï¼Œå¹¶æ®æ­¤æå‡ºäº†ç†µæ„ŸçŸ¥(entropy-aware)çš„è®¾è®¡åŸåˆ™ï¼Œæ—¨åœ¨ç»´æŒæ™ºèƒ½ç³»ç»Ÿçš„é•¿æœŸé€‚åº”æ€§ã€‚",
      "categories": [
        "cs.AI"
      ],
      "primary_category": "cs.AI",
      "comment": "18 pages, 5 figures",
      "pdf_url": "https://arxiv.org/pdf/2512.12381v1",
      "published_date": "2025-12-13 16:12:27 UTC",
      "updated_date": "2025-12-13 16:12:27 UTC",
      "processing_status": "completed",
      "attempts": 1,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "llm_backup_calls": 0,
      "last_update": "2026-01-26T16:26:02.311572+00:00"
    },
    {
      "arxiv_id": "2512.15775v1",
      "title": "Enhanced Web User Interface Design Via Cross-Device Responsiveness Assessment Using An Improved HCI-INTEGRATED DL Schemes",
      "title_zh": "åŸºäºæ”¹è¿›å‹ HCI é›†æˆæ·±åº¦å­¦ä¹ æ–¹æ¡ˆä¸è·¨è®¾å¤‡å“åº”æ€§è¯„ä¼°çš„å¢å¼ºå‹ Web ç”¨æˆ·ç•Œé¢è®¾è®¡",
      "authors": [
        "Shrinivass Arunachalam Balasubramanian"
      ],
      "abstract": "User Interface (UI) optimization is essential in the digital era to enhance user satisfaction in web environments. Nevertheless, the existing UI optimization models had overlooked the Cross-Responsiveness (CR) assessment, affecting the user interaction efficiency. Consequently, this article proposes a dynamic web UI optimization through CR assessment using Finite Exponential Continuous State Machine (FECSM) and Quokka Nonlinear Difference Swarm Optimization Algorithm (QNDSOA). Initially, the design and user interaction related information is collected as well as pre-processed for min-max normalization. Next, the Human-Computer Interaction (HCI)-based features are extracted, followed by user behaviour pattern grouping. Meanwhile, the CR assessment is done using FECSM. Then, the proposed Bidirectional Gated Luong and Mish Recurrent Unit (BiGLMRU) is used to classify the User eXperience (UX) change type, which is labelled based on the User Interface Change Prediction Index (UICPI). Lastly, a novel QNDSOA is utilized to optimize the UI design with an average fitness of 98.5632%. Feedback monitoring is done after optimal deployment.",
      "tldr_zh": "è¯¥ç ”ç©¶é’ˆå¯¹ç°æœ‰ Web ç”¨æˆ·ç•Œé¢ä¼˜åŒ–æ¨¡å‹å¿½ç•¥è·¨è®¾å¤‡å“åº”æ€§ (Cross-Responsiveness, CR) è¯„ä¼°è€Œå¯¼è‡´äº¤äº’æ•ˆç‡å—æŸçš„é—®é¢˜ï¼Œæå‡ºäº†ä¸€ç§é›†æˆäº†äººæœºäº¤äº’ (HCI) ç‰¹å¾çš„æ”¹è¿›æ·±åº¦å­¦ä¹ ä¼˜åŒ–æ–¹æ¡ˆã€‚ç ”ç©¶é¦–å…ˆåˆ©ç”¨æœ‰é™æŒ‡æ•°è¿ç»­çŠ¶æ€æœº (Finite Exponential Continuous State Machine, FECSM) è¿›è¡Œ CR è¯„ä¼°ï¼Œå¹¶ç»“åˆäººæœºäº¤äº’ç‰¹å¾æå–ä¸ç”¨æˆ·è¡Œä¸ºæ¨¡å¼åˆ†ç»„ã€‚éšåï¼Œé‡‡ç”¨åŒå‘é—¨æ§ Luong å’Œ Mish å¾ªç¯å•å…ƒ (Bidirectional Gated Luong and Mish Recurrent Unit, BiGLMRU) æ ¹æ®ç”¨æˆ·ç•Œé¢å˜æ›´é¢„æµ‹æŒ‡æ•° (User Interface Change Prediction Index, UICPI) å¯¹ç”¨æˆ·ä½“éªŒ (UX) çš„å˜æ›´ç±»å‹è¿›è¡Œç²¾ç¡®åˆ†ç±»ã€‚ä¸ºäº†å®ç°åŠ¨æ€ UI ä¼˜åŒ–ï¼Œæœ¬æ–‡å¼•å…¥äº† Quokka éçº¿æ€§å·®åˆ†ç¾¤ä¼˜åŒ–ç®—æ³• (Quokka Nonlinear Difference Swarm Optimization Algorithm, QNDSOA)ï¼Œåœ¨å®éªŒä¸­è¾¾åˆ°äº† 98.5632% çš„å¹³å‡é€‚åº”åº¦ã€‚è¯¥æ¡†æ¶é€šè¿‡éƒ¨ç½²åçš„åé¦ˆç›‘æµ‹æœºåˆ¶ï¼Œæœ‰æ•ˆè§£å†³äº†æ•°å­—æ—¶ä»£å¤šè®¾å¤‡ç¯å¢ƒä¸‹çš„ç•Œé¢é€‚é…æŒ‘æˆ˜ï¼Œæ˜¾è‘—æå‡äº† Web ç¯å¢ƒä¸‹çš„ç”¨æˆ·äº¤äº’æ•ˆç‡ä¸æ»¡æ„åº¦ã€‚",
      "categories": [
        "cs.HC",
        "cs.AI",
        "cs.LG",
        "cs.MM",
        "cs.SE"
      ],
      "primary_category": "cs.HC",
      "comment": "17 Pages, 8 Figures",
      "pdf_url": "https://arxiv.org/pdf/2512.15775v1",
      "published_date": "2025-12-13 15:58:07 UTC",
      "updated_date": "2025-12-13 15:58:07 UTC",
      "processing_status": "completed",
      "attempts": 1,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "llm_backup_calls": 0,
      "last_update": "2026-01-26T16:26:14.412531+00:00"
    },
    {
      "arxiv_id": "2512.12337v1",
      "title": "SCIR: A Self-Correcting Iterative Refinement Framework for Enhanced Information Extraction Based on Schema",
      "title_zh": "SCIRï¼šä¸€ç§åŸºäºæ¨¡å¼çš„å¢å¼ºå‹ä¿¡æ¯æŠ½å–è‡ªæ ¡æ­£è¿­ä»£ç»†åŒ–æ¡†æ¶",
      "authors": [
        "Yushen Fang",
        "Jianjun Li",
        "Mingqian Ding",
        "Chang Liu",
        "Xinchi Zou",
        "Wenqi Yang"
      ],
      "abstract": "Although Large language Model (LLM)-powered information extraction (IE) systems have shown impressive capabilities, current fine-tuning paradigms face two major limitations: high training costs and difficulties in aligning with LLM preferences. To address these issues, we propose a novel universal IE paradigm, the Self-Correcting Iterative Refinement (SCIR) framework, along with a Multi-task Bilingual (Chinese-English) Self-Correcting (MBSC) dataset containing over 100,000 entries. The SCIR framework achieves plug-and-play compatibility with existing LLMs and IE systems through its Dual-Path Self-Correcting module and feedback-driven optimization, thereby significantly reducing training costs. Concurrently, the MBSC dataset tackles the challenge of preference alignment by indirectly distilling GPT-4's capabilities into IE result detection models. Experimental results demonstrate that SCIR outperforms state-of-the-art IE methods across three key tasks: named entity recognition, relation extraction, and event extraction, achieving a 5.27 percent average improvement in span-based Micro-F1 while reducing training costs by 87 percent compared to baseline approaches. These advancements not only enhance the flexibility and accuracy of IE systems but also pave the way for lightweight and efficient IE paradigms.",
      "tldr_zh": "è¯¥ç ”ç©¶æå‡ºäº† SCIR (Self-Correcting Iterative Refinement) æ¡†æ¶ï¼Œæ—¨åœ¨è§£å†³åŸºäºå¤§è¯­è¨€æ¨¡å‹ (LLM) çš„ä¿¡æ¯æŠ½å– (Information Extraction) ç³»ç»Ÿåœ¨è®­ç»ƒæˆæœ¬å’Œåå¥½å¯¹é½æ–¹é¢é¢ä¸´çš„æŒ‘æˆ˜ã€‚è¯¥æ¡†æ¶åˆ©ç”¨ Dual-Path Self-Correcting æ¨¡å—å’Œåé¦ˆé©±åŠ¨çš„ä¼˜åŒ–æœºåˆ¶ï¼Œå®ç°äº†ä¸ç°æœ‰æ¨¡å‹åŠç³»ç»Ÿçš„å³æ’å³ç”¨ï¼Œæ˜¾è‘—é™ä½äº†è®­ç»ƒæˆæœ¬ã€‚ç ”ç©¶åŒæ­¥æ¨å‡ºäº†åŒ…å«è¶…è¿‡ 10 ä¸‡æ¡ç›®çš„ MBSC (Multi-task Bilingual Self-Correcting) æ•°æ®é›†ï¼Œé€šè¿‡é—´æ¥è’¸é¦ GPT-4 çš„èƒ½åŠ›æ¥ä¼˜åŒ–ä¿¡æ¯æŠ½å–çš„æ£€æµ‹ç²¾åº¦ã€‚å®éªŒç»“æœè¡¨æ˜ï¼ŒSCIR åœ¨å‘½åå®ä½“è¯†åˆ« (Named Entity Recognition)ã€å…³ç³»æŠ½å– (Relation Extraction) å’Œäº‹ä»¶æŠ½å– (Event Extraction) ä»»åŠ¡ä¸­è¡¨ç°å‡ºè‰²ï¼Œå…¶ span-based Micro-F1 æŒ‡æ ‡å¹³å‡æå‡ 5.27%ï¼Œä¸”è®­ç»ƒæˆæœ¬è¾ƒåŸºå‡†æ–¹æ³•é™ä½äº† 87%ã€‚è¿™ä¸€è¿›å±•ä¸ä»…æå‡äº†ä¿¡æ¯æŠ½å–ç³»ç»Ÿçš„çµæ´»æ€§ä¸å‡†ç¡®æ€§ï¼Œä¹Ÿä¸ºæ„å»ºè½»é‡åŒ–ä¸”é«˜æ•ˆçš„ IE èŒƒå¼å¥ å®šäº†åŸºç¡€ã€‚",
      "categories": [
        "cs.CL",
        "cs.AI"
      ],
      "primary_category": "cs.CL",
      "comment": "",
      "pdf_url": "https://arxiv.org/pdf/2512.12337v1",
      "published_date": "2025-12-13 14:07:25 UTC",
      "updated_date": "2025-12-13 14:07:25 UTC",
      "processing_status": "completed",
      "attempts": 1,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "llm_backup_calls": 0,
      "last_update": "2026-01-26T16:27:21.907457+00:00"
    },
    {
      "arxiv_id": "2512.12332v1",
      "title": "Dynamic Homophily with Imperfect Recall: Modeling Resilience in Adversarial Networks",
      "title_zh": "ä¸å®Œå…¨å›å¿†ä¸‹çš„åŠ¨æ€åŒè´¨æ€§ï¼šå¯¹æŠ—æ€§ç½‘ç»œéŸ§æ€§å»ºæ¨¡",
      "authors": [
        "Saad Alqithami"
      ],
      "abstract": "The purpose of this study is to investigate how homophily, memory constraints, and adversarial disruptions collectively shape the resilience and adaptability of complex networks. To achieve this, we develop a new framework that integrates explicit memory decay mechanisms into homophily-based models and systematically evaluate their performance across diverse graph structures and adversarial settings. Our methods involve extensive experimentation on synthetic datasets, where we vary decay functions, reconnection probabilities, and similarity measures, primarily comparing cosine similarity with traditional metrics such as Jaccard similarity and baseline edge weights. The results show that cosine similarity achieves up to a 30\\% improvement in stability metrics in sparse, convex, and modular networks. Moreover, the refined value-of-recall metric demonstrates that strategic forgetting can bolster resilience by balancing network robustness and adaptability. The findings underscore the critical importance of aligning memory and similarity parameters with the structural and adversarial dynamics of the network. By quantifying the tangible benefits of incorporating memory constraints into homophily-based analyses, this study offers actionable insights for optimizing real-world applications, including social systems, collaborative platforms, and cybersecurity contexts.",
      "tldr_zh": "è¯¥ç ”ç©¶æ¢è®¨äº†åŒè´¨æ€§(homophily)ã€è®°å¿†é™åˆ¶(memory constraints)å’Œå¯¹æŠ—æ€§æ‰°åŠ¨(adversarial disruptions)å¦‚ä½•å…±åŒå½±å“å¤æ‚ç½‘ç»œçš„éŸ§æ€§ä¸é€‚åº”æ€§ã€‚ç ”ç©¶å¼€å‘äº†ä¸€ä¸ªå°†æ˜¾å¼è®°å¿†è¡°å‡æœºåˆ¶(explicit memory decay mechanisms)é›†æˆåˆ°åŒè´¨æ€§æ¨¡å‹ä¸­çš„æ–°æ¡†æ¶ï¼Œå¹¶åœ¨å¤šç§å›¾ç»“æ„å’Œå¯¹æŠ—ç¯å¢ƒä¸‹è¿›è¡Œäº†ç³»ç»Ÿè¯„ä¼°ã€‚é€šè¿‡åœ¨åˆæˆæ•°æ®é›†ä¸Šçš„å¯¹æ¯”å®éªŒå‘ç°ï¼Œä½™å¼¦ç›¸ä¼¼åº¦(cosine similarity)åœ¨ç¨€ç–å’Œæ¨¡å—åŒ–ç½‘ç»œä¸­æ¯”Jaccardç›¸ä¼¼åº¦(Jaccard similarity)ç­‰ä¼ ç»ŸæŒ‡æ ‡åœ¨ç¨³å®šæ€§ä¸Šæå‡äº†30%ã€‚æ­¤å¤–ï¼Œæ”¹è¿›çš„è®°å¿†ä»·å€¼æŒ‡æ ‡(refined value-of-recall metric)è¯æ˜ï¼Œæˆ˜ç•¥æ€§é—å¿˜(strategic forgetting)èƒ½é€šè¿‡å¹³è¡¡ç¨³å¥æ€§ä¸é€‚åº”æ€§æ¥å¢å¼ºç½‘ç»œéŸ§æ€§ã€‚è¯¥ç ”ç©¶å¼ºè°ƒäº†è®°å¿†ä¸ç›¸ä¼¼æ€§å‚æ•°åŒ¹é…ç½‘ç»œåŠ¨æ€çš„é‡è¦æ€§ï¼Œä¸ºç¤¾äº¤ç³»ç»Ÿå’Œç½‘ç»œå®‰å…¨(cybersecurity)ç­‰ç°å®åœºæ™¯ä¸‹çš„ç½‘ç»œä¼˜åŒ–æä¾›äº†å…·æœ‰æ“ä½œæ€§çš„è§è§£ã€‚",
      "categories": [
        "cs.SI",
        "cs.AI",
        "cs.CR",
        "cs.IT"
      ],
      "primary_category": "cs.SI",
      "comment": "",
      "pdf_url": "https://arxiv.org/pdf/2512.12332v1",
      "published_date": "2025-12-13 13:45:27 UTC",
      "updated_date": "2025-12-13 13:45:27 UTC",
      "processing_status": "completed",
      "attempts": 1,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "llm_backup_calls": 0,
      "last_update": "2026-01-26T16:27:21.431702+00:00"
    },
    {
      "arxiv_id": "2512.12324v2",
      "title": "UniMark: Artificial Intelligence Generated Content Identification Toolkit",
      "title_zh": "UniMarkï¼šäººå·¥æ™ºèƒ½ç”Ÿæˆå†…å®¹è¯†åˆ«å·¥å…·åŒ…",
      "authors": [
        "Meilin Li",
        "Ji He",
        "Yi Yu",
        "Jia Xu",
        "Shanzhe Lei",
        "Yan Teng",
        "Yingchun Wang",
        "Xuhong Wang"
      ],
      "abstract": "The rapid proliferation of Artificial Intelligence Generated Content has precipitated a crisis of trust and urgent regulatory demands. However, existing identification tools suffer from fragmentation and a lack of support for visible compliance marking. To address these gaps, we introduce the \\textbf{UniMark}, an open-source, unified framework for multimodal content governance. Our system features a modular unified engine that abstracts complexities across text, image, audio, and video modalities. Crucially, we propose a novel dual-operation strategy, natively supporting both \\emph{Hidden Watermarking} for copyright protection and \\emph{Visible Marking} for regulatory compliance. Furthermore, we establish a standardized evaluation framework with three specialized benchmarks (Image/Video/Audio-Bench) to ensure rigorous performance assessment. This toolkit bridges the gap between advanced algorithms and engineering implementation, fostering a more transparent and secure digital ecosystem.",
      "tldr_zh": "è¯¥ç ”ç©¶æ¨å‡ºäº† UniMarkï¼Œä¸€ä¸ªå¼€æºçš„ç»Ÿä¸€å¤šæ¨¡æ€å†…å®¹æ²»ç†æ¡†æ¶ï¼Œæ—¨åœ¨è§£å†³äººå·¥æ™ºèƒ½ç”Ÿæˆå†…å®¹ (Artificial Intelligence Generated Content) å¸¦æ¥çš„ä¿¡ä»»å±æœºåŠç°æœ‰è¯†åˆ«å·¥å…·ç¢ç‰‡åŒ–ã€ç¼ºä¹å¯è§åˆè§„æ ‡è®°çš„é—®é¢˜ã€‚è¯¥ç³»ç»Ÿé‡‡ç”¨æ¨¡å—åŒ–ç»Ÿä¸€å¼•æ“ï¼Œæœ‰æ•ˆç®€åŒ–äº†æ–‡æœ¬ã€å›¾åƒã€éŸ³é¢‘å’Œè§†é¢‘ç­‰å¤šç§æ¨¡æ€çš„å¤„ç†å¤æ‚æ€§ã€‚UniMark æå‡ºäº†ä¸€ç§åˆ›æ–°çš„åŒæ“ä½œç­–ç•¥ï¼ŒåŸç”Ÿæ”¯æŒç”¨äºç‰ˆæƒä¿æŠ¤çš„éšå½¢æ°´å° (Hidden Watermarking) å’Œç”¨äºç›‘ç®¡åˆè§„çš„å¯è§æ ‡è®° (Visible Marking)ã€‚ä¸ºäº†ç¡®ä¿ä¸¥æ ¼çš„æ€§èƒ½è¯„ä¼°ï¼Œç ”ç©¶å›¢é˜Ÿè¿˜å»ºç«‹äº†ä¸€å¥—æ ‡å‡†åŒ–çš„è¯„ä¼°æ¡†æ¶ï¼ŒåŒ…å«é’ˆå¯¹å›¾åƒã€è§†é¢‘å’ŒéŸ³é¢‘çš„ä¸“é—¨åŸºå‡†æµ‹è¯• (Image/Video/Audio-Bench)ã€‚è¯¥å·¥å…·åŒ…å¼¥åˆäº†å…ˆè¿›ç®—æ³•ä¸å·¥ç¨‹å®ç°ä¹‹é—´çš„é¸¿æ²Ÿï¼Œä¸ºæ„å»ºæ›´åŠ é€æ˜å’Œå®‰å…¨çš„æ•°å­—ç”Ÿæ€ç³»ç»Ÿæä¾›äº†æœ‰åŠ›æ”¯æŒã€‚",
      "categories": [
        "cs.CR",
        "cs.AI"
      ],
      "primary_category": "cs.CR",
      "comment": "5 Pages",
      "pdf_url": "https://arxiv.org/pdf/2512.12324v2",
      "published_date": "2025-12-13 13:30:48 UTC",
      "updated_date": "2025-12-26 07:22:58 UTC",
      "processing_status": "completed",
      "attempts": 1,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "llm_backup_calls": 0,
      "last_update": "2026-01-26T16:27:22.993581+00:00"
    },
    {
      "arxiv_id": "2512.12288v1",
      "title": "Quantum-Aware Generative AI for Materials Discovery: A Framework for Robust Exploration Beyond DFT Biases",
      "title_zh": "é¢å‘ææ–™å‘ç°çš„é‡å­æ„ŸçŸ¥ç”Ÿæˆå¼äººå·¥æ™ºèƒ½ï¼šè¶…è¶Š DFT åå·®çš„é²æ£’æ¢ç´¢æ¡†æ¶",
      "authors": [
        "Mahule Roy",
        "Guillaume Lambard"
      ],
      "abstract": "Conventional generative models for materials discovery are predominantly trained and validated using data from Density Functional Theory (DFT) with approximate exchange-correlation functionals. This creates a fundamental bottleneck: these models inherit DFT's systematic failures for strongly correlated systems, leading to exploration biases and an inability to discover materials where DFT predictions are qualitatively incorrect. We introduce a quantum-aware generative AI framework that systematically addresses this limitation through tight integration of multi-fidelity learning and active validation. Our approach employs a diffusion-based generator conditioned on quantum-mechanical descriptors and a validator using an equivariant neural network potential trained on a hierarchical dataset spanning multiple levels of theory (PBE, SCAN, HSE06, CCSD(T)). Crucially, we implement a robust active learning loop that quantifies and targets the divergence between low- and high-fidelity predictions. We conduct comprehensive ablation studies to deconstruct the contribution of each component, perform detailed failure mode analysis, and benchmark our framework against state-of-the-art generative models (CDVAE, GNoME, DiffCSP) across several challenging material classes. Our results demonstrate significant practical gains: a 3-5x improvement in successfully identifying potentially stable candidates in high-divergence regions (e.g., correlated oxides) compared to DFT-only baselines, while maintaining computational feasibility. This work provides a rigorous, transparent framework for extending the effective search space of computational materials discovery beyond the limitations of single-fidelity models.",
      "tldr_zh": "è¯¥ç ”ç©¶é’ˆå¯¹ä¼ ç»Ÿææ–™å‘ç°ç”Ÿæˆæ¨¡å‹è¿‡åº¦ä¾èµ– Density Functional Theory (DFT) æ•°æ®å¯¼è‡´çš„ç³»ç»Ÿæ€§åå·®ï¼Œæå‡ºäº†ä¸€ä¸ªé‡å­æ„ŸçŸ¥ç”Ÿæˆå¼äººå·¥æ™ºèƒ½(Quantum-aware generative AI)æ¡†æ¶ï¼Œæ—¨åœ¨å®ç°è¶…è¶Š DFT åè§çš„ç¨³å¥æ¢ç´¢ã€‚è¯¥æ¡†æ¶é€šè¿‡æ•´åˆå¤šä¿çœŸåº¦å­¦ä¹ (multi-fidelity learning)å’Œä¸»åŠ¨éªŒè¯(active validation)ï¼Œç»“åˆåŸºäºæ‰©æ•£æ¨¡å‹(diffusion-based)çš„ç”Ÿæˆå™¨ä¸åœ¨ PBEã€SCANã€HSE06 åŠ CCSD(T) ç­‰å¤šçº§ç†è®ºæ•°æ®é›†ä¸Šè®­ç»ƒçš„ç­‰å˜ç¥ç»ç½‘ç»œ(equivariant neural network)éªŒè¯å™¨ã€‚æ ¸å¿ƒåˆ›æ–°åœ¨äºå®ç°äº†ä¸€ä¸ªèƒ½å¤Ÿé‡åŒ–ä½ä¿çœŸåº¦ä¸é«˜ä¿çœŸåº¦é¢„æµ‹å·®å¼‚çš„é²æ£’ä¸»åŠ¨å­¦ä¹ å¾ªç¯ï¼Œä»è€Œç²¾å‡†å®šä½å¹¶ä¼˜åŒ–æœç´¢ç©ºé—´ã€‚å®éªŒè¡¨æ˜ï¼Œè¯¥æ¡†æ¶åœ¨å¤„ç†ç›¸å…³æ°§åŒ–ç‰©ç­‰æŒ‘æˆ˜æ€§ææ–™æ—¶ï¼Œè¯†åˆ«ç¨³å®šå€™é€‰ææ–™çš„æˆåŠŸç‡æ¯”ä»…ä½¿ç”¨ DFT çš„åŸºå‡†æ¨¡å‹æé«˜äº† 3-5 å€ï¼Œä¸”ä¿æŒäº†è®¡ç®—å¯è¡Œæ€§ã€‚è¿™ä¸€æˆæœä¸ºçªç ´å•ä¸€ä¿çœŸåº¦æ¨¡å‹çš„é™åˆ¶ã€æ‰©å±•è®¡ç®—ææ–™ç§‘å­¦çš„æœç´¢è¾¹ç•Œæä¾›äº†ä¸€ä¸ªä¸¥è°¨ä¸”é€æ˜çš„ç³»ç»Ÿæ€§æ–¹æ¡ˆã€‚",
      "categories": [
        "cs.AI"
      ],
      "primary_category": "cs.AI",
      "comment": "33 pages",
      "pdf_url": "https://arxiv.org/pdf/2512.12288v1",
      "published_date": "2025-12-13 11:17:21 UTC",
      "updated_date": "2025-12-13 11:17:21 UTC",
      "processing_status": "completed",
      "attempts": 1,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "llm_backup_calls": 0,
      "last_update": "2026-01-26T16:27:44.523216+00:00"
    },
    {
      "arxiv_id": "2512.12285v1",
      "title": "Fractional Differential Equation Physics-Informed Neural Network and Its Application in Battery State Estimation",
      "title_zh": "åˆ†æ•°é˜¶å¾®åˆ†æ–¹ç¨‹ç‰©ç†ä¿¡æ¯ç¥ç»ç½‘ç»œåŠå…¶åœ¨ç”µæ± çŠ¶æ€ä¼°è®¡ä¸­çš„åº”ç”¨",
      "authors": [
        "Lujuan Dang",
        "Zilai Wang"
      ],
      "abstract": "Accurate estimation of the State of Charge (SOC) is critical for ensuring the safety, reliability, and performance optimization of lithium-ion battery systems. Conventional data-driven neural network models often struggle to fully characterize the inherent complex nonlinearities and memory-dependent dynamics of electrochemical processes, significantly limiting their predictive accuracy and physical interpretability under dynamic operating conditions. To address this challenge, this study proposes a novel neural architecture termed the Fractional Differential Equation Physics-Informed Neural Network (FDIFF-PINN), which integrates fractional calculus with deep learning. The main contributions of this paper include: (1) Based on a fractional-order equivalent circuit model, a discretized fractional-order partial differential equation is constructed. (2) Comparative experiments were conducted using a dynamic charge/discharge dataset of Panasonic 18650PF batteries under multi-temperature conditions (from -10$^{\\circ}$C to 20$^{\\circ}$C).",
      "tldr_zh": "å‡†ç¡®ä¼°ç®— State of Charge (SOC) å¯¹äºç¡®ä¿é”‚ç¦»å­ç”µæ± ç³»ç»Ÿçš„å®‰å…¨æ€§ã€å¯é æ€§å’Œæ€§èƒ½ä¼˜åŒ–è‡³å…³é‡è¦ã€‚é’ˆå¯¹ä¼ ç»Ÿæ•°æ®é©±åŠ¨æ¨¡å‹åœ¨åˆ»ç”»ç”µåŒ–å­¦è¿‡ç¨‹çš„å¤æ‚éçº¿æ€§åŠå…¶è®°å¿†ä¾èµ–åŠ¨åŠ›å­¦æ–¹é¢çš„å±€é™ï¼Œè¯¥ç ”ç©¶æå‡ºäº†ä¸€ç§åä¸º Fractional Differential Equation Physics-Informed Neural Network (FDIFF-PINN) çš„æ–°å‹ç¥ç»æ¶æ„ã€‚è¯¥æ¡†æ¶å°† fractional calculus ä¸æ·±åº¦å­¦ä¹ é›†æˆï¼Œå¹¶åŸºäº fractional-order equivalent circuit model æ„å»ºäº†ç¦»æ•£åŒ–çš„åˆ†æ•°é˜¶åå¾®åˆ†æ–¹ç¨‹ã€‚é€šè¿‡åœ¨ -10Â°C è‡³ 20Â°C å¤šæ¸©åº¦ç¯å¢ƒä¸‹å¯¹ Panasonic 18650PF ç”µæ± æ•°æ®é›†è¿›è¡Œçš„å¯¹æ¯”å®éªŒï¼Œè¯æ˜äº†è¯¥æ–¹æ³•èƒ½æœ‰æ•ˆæå‡æ¨¡å‹åœ¨åŠ¨æ€å·¥å†µä¸‹çš„é¢„æµ‹ç²¾åº¦å’Œç‰©ç†å¯è§£é‡Šæ€§ã€‚FDIFF-PINN ä¸ºè§£å†³ç”µæ± ç”µåŒ–å­¦è¿‡ç¨‹ä¸­çš„å¤æ‚åŠ¨åŠ›å­¦å»ºæ¨¡æä¾›äº†å…¼å…·ç‰©ç†ä¸€è‡´æ€§ä¸å¼ºå¤§æ‹Ÿåˆèƒ½åŠ›çš„æ–°é€”å¾„ã€‚",
      "categories": [
        "cs.LG",
        "cs.AI"
      ],
      "primary_category": "cs.LG",
      "comment": "",
      "pdf_url": "https://arxiv.org/pdf/2512.12285v1",
      "published_date": "2025-12-13 11:11:03 UTC",
      "updated_date": "2025-12-13 11:11:03 UTC",
      "processing_status": "completed",
      "attempts": 1,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "llm_backup_calls": 0,
      "last_update": "2026-01-26T16:27:35.234585+00:00"
    },
    {
      "arxiv_id": "2512.12284v3",
      "title": "V-Rex: Real-Time Streaming Video LLM Acceleration via Dynamic KV Cache Retrieval",
      "title_zh": "V-Rexï¼šåŸºäºåŠ¨æ€ KV ç¼“å­˜æ£€ç´¢çš„å®æ—¶æµå¼è§†é¢‘å¤§è¯­è¨€æ¨¡å‹åŠ é€Ÿ",
      "authors": [
        "Donghyuk Kim",
        "Sejeong Yang",
        "Wonjin Shin",
        "Joo-Young Kim"
      ],
      "abstract": "Streaming video large language models (LLMs) are increasingly used for real-time multimodal tasks such as video captioning, question answering, conversational agents, and augmented reality. However, these models face fundamental memory and computational challenges because their key-value (KV) caches grow substantially with continuous streaming video input. This process requires an iterative prefill stage, which is a unique feature of streaming video LLMs. Due to its iterative prefill stage, it suffers from significant limitations, including extensive computation, substantial data transfer, and degradation in accuracy. Crucially, this issue is exacerbated for edge deployment, which is the primary target for these models.\n  In this work, we propose V-Rex, the first software-hardware co-designed accelerator that comprehensively addresses both algorithmic and hardware bottlenecks in streaming video LLM inference. At its core, V-Rex introduces ReSV, a training-free dynamic KV cache retrieval algorithm. ReSV exploits temporal and spatial similarity-based token clustering to reduce excessive KV cache memory across video frames. To fully realize these algorithmic benefits, V-Rex offers a compact, low-latency hardware accelerator with a dynamic KV cache retrieval engine (DRE), featuring bit-level and early-exit based computing units. V-Rex achieves unprecedented real-time of 3.9-8.3 FPS and energy-efficient streaming video LLM inference on edge deployment with negligible accuracy loss. While DRE only accounts for 2.2% power and 2.0% area, the system delivers 1.9-19.7x speedup and 3.1-18.5x energy efficiency improvements over AGX Orin GPU. This work is the first to comprehensively tackle KV cache retrieval across algorithms and hardware, enabling real-time streaming video LLM inference on resource-constrained edge devices.",
      "tldr_zh": "è¯¥ç ”ç©¶æå‡ºäº†V-Rexï¼Œè¿™æ˜¯é¦–ä¸ªé’ˆå¯¹æµå¼è§†é¢‘å¤§è¯­è¨€æ¨¡å‹(Streaming Video LLMs)æ¨ç†è¿‡ç¨‹ä¸­ç®—æ³•ä¸ç¡¬ä»¶ç“¶é¢ˆè®¾è®¡çš„è½¯ç¡¬ä»¶ååŒåŠ é€Ÿå™¨ã€‚ä¸ºè§£å†³æŒç»­è§†é¢‘è¾“å…¥å¯¼è‡´çš„KV cacheå¢é•¿åŠè¿­ä»£é¢„å¡«å……(iterative prefill)å¸¦æ¥çš„è®¡ç®—å‹åŠ›ï¼ŒV-Rexå¼•å…¥äº†åä¸ºReSVçš„å…è®­ç»ƒåŠ¨æ€KV cacheæ£€ç´¢ç®—æ³•ï¼Œåˆ©ç”¨æ—¶ç©ºç›¸ä¼¼æ€§è¿›è¡ŒTokenèšç±»ä»¥å¤§å¹…å‡å°‘æ˜¾å­˜å ç”¨ã€‚åœ¨ç¡¬ä»¶å±‚é¢ï¼Œè¯¥ç³»ç»Ÿè®¾è®¡äº†ç´§å‡‘ä¸”ä½å»¶è¿Ÿçš„åŠ é€Ÿå™¨ï¼Œå…¶æ ¸å¿ƒåŠ¨æ€æ£€ç´¢å¼•æ“(DRE)é‡‡ç”¨äº†ä½çº§å’ŒåŸºäºæ—©é€€æœºåˆ¶(early-exit)çš„è®¡ç®—å•å…ƒã€‚å®éªŒç»“æœè¡¨æ˜ï¼ŒV-Rexåœ¨è¾¹ç¼˜è®¾å¤‡ä¸Šå®ç°äº†3.9-8.3 FPSçš„å®æ—¶æ¨ç†é€Ÿåº¦ï¼Œç›¸æ¯”NVIDIA AGX Orin GPUå®ç°äº†1.9-19.7å€çš„åŠ é€Ÿä»¥åŠ3.1-18.5å€çš„èƒ½æ•ˆæå‡ã€‚è¯¥ç ”ç©¶é€šè¿‡å…¨æ ˆå¼ä¼˜åŒ–ï¼Œåœ¨ç²¾åº¦æŸå¤±æå°çš„æƒ…å†µä¸‹ï¼ŒæˆåŠŸæ”»å…‹äº†èµ„æºå—é™ç¯å¢ƒä¸‹æµå¼è§†é¢‘LLMçš„å®æ—¶æ¨ç†éš¾é¢˜ã€‚",
      "categories": [
        "eess.IV",
        "cs.AI",
        "cs.AR",
        "cs.CV",
        "cs.MM"
      ],
      "primary_category": "eess.IV",
      "comment": "14 pages, 20 figures, conference, accepted by HPCA 2026",
      "pdf_url": "https://arxiv.org/pdf/2512.12284v3",
      "published_date": "2025-12-13 11:02:04 UTC",
      "updated_date": "2025-12-24 07:46:59 UTC",
      "processing_status": "completed",
      "attempts": 1,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "llm_backup_calls": 0,
      "last_update": "2026-01-26T16:27:43.464724+00:00"
    },
    {
      "arxiv_id": "2512.12273v1",
      "title": "GRC-Net: Gram Residual Co-attention Net for epilepsy prediction",
      "title_zh": "GRC-Netï¼šç”¨äºç™«ç—«é¢„æµ‹çš„ Gram æ®‹å·®ååŒæ³¨æ„åŠ›ç½‘ç»œ",
      "authors": [
        "Bihao You",
        "Jiping Cui"
      ],
      "abstract": "Prediction of epilepsy based on electroencephalogram (EEG) signals is a rapidly evolving field. Previous studies have traditionally applied 1D processing to the entire EEG signal. However, we have adopted the Gram Matrix method to transform the signals into a 3D representation, enabling modeling of signal relationships across dimensions while preserving the temporal dependencies of the one-dimensional signals. Additionally, we observed an imbalance between local and global signals within the EEG data. Therefore, we introduced multi-level feature extraction, utilizing coattention for capturing global signal characteristics and an inception structure for processing local signals, achieving multi-granular feature extraction. Our experiments on the BONN dataset demonstrate that for the most challenging five-class classification task, GRC-Net achieved an accuracy of 93.66%, outperforming existing methods.",
      "tldr_zh": "è¯¥ç ”ç©¶æå‡ºäº† GRC-Netï¼Œä¸€ç§ç”¨äºç™«ç—«é¢„æµ‹çš„ Gram Residual Co-attention Netï¼Œæ—¨åœ¨æå‡åŸºäºè„‘ç”µå›¾ (EEG) ä¿¡å·çš„è¯†åˆ«æ•ˆèƒ½ã€‚ä¸ä¼ ç»Ÿä»…å¯¹å®Œæ•´ä¿¡å·è¿›è¡Œ 1D å¤„ç†çš„æ–¹æ³•ä¸åŒï¼Œè¯¥æ¨¡å‹é‡‡ç”¨ Gram Matrix å°†ä¿¡å·è½¬æ¢ä¸º 3D è¡¨ç¤ºï¼Œä»è€Œåœ¨ä¿ç•™ä¸€ç»´ä¿¡å·æ—¶é—´ä¾èµ–æ€§çš„åŒæ—¶å®ç°äº†è·¨ç»´åº¦å…³ç³»çš„å»ºæ¨¡ã€‚é’ˆå¯¹ EEG æ•°æ®ä¸­å±€éƒ¨ä¸å…¨å±€ä¿¡å·çš„ä¸å¹³è¡¡é—®é¢˜ï¼Œç ”ç©¶å¼•å…¥äº†å¤šå±‚æ¬¡ç‰¹å¾æå–æœºåˆ¶ï¼Œé€šè¿‡ Co-attention æ•è·å…¨å±€ç‰¹å¾å¹¶ç»“åˆ Inception structure å¤„ç†å±€éƒ¨ä¿¡å·ï¼Œå®ç°äº†å¤šç²’åº¦çš„ç‰¹å¾åˆ†æã€‚åœ¨ BONN dataset çš„äº”åˆ†ç±»æŒ‘æˆ˜ä»»åŠ¡ä¸­ï¼ŒGRC-Net å–å¾—äº† 93.66% çš„å‡†ç¡®ç‡ï¼Œæ€§èƒ½ä¼˜äºç°æœ‰æ–¹æ³•ã€‚è¯¥æˆæœè¯æ˜äº†ç»“åˆå…¨å±€ä¸å±€éƒ¨ç‰¹å¾çš„ 3D ä¿¡å·å»ºæ¨¡åœ¨ç™«ç—«æ™ºèƒ½è¯Šæ–­ä¸­çš„ä¼˜è¶Šæ€§ã€‚",
      "categories": [
        "cs.LG",
        "cs.AI"
      ],
      "primary_category": "cs.LG",
      "comment": "",
      "pdf_url": "https://arxiv.org/pdf/2512.12273v1",
      "published_date": "2025-12-13 10:29:28 UTC",
      "updated_date": "2025-12-13 10:29:28 UTC",
      "processing_status": "completed",
      "attempts": 1,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "llm_backup_calls": 0,
      "last_update": "2026-01-26T16:27:41.871338+00:00"
    },
    {
      "arxiv_id": "2512.12272v1",
      "title": "Accurate de novo sequencing of the modified proteome with OmniNovo",
      "title_zh": "åˆ©ç”¨ OmniNovo å®ç°ä¿®é¥°è›‹ç™½è´¨ç»„çš„é«˜ç²¾åº¦ä»å¤´æµ‹åº",
      "authors": [
        "Yuhan Chen",
        "Shang Qu",
        "Zhiqiang Gao",
        "Yuejin Yang",
        "Xiang Zhang",
        "Sheng Xu",
        "Xinjie Mao",
        "Liujia Qian",
        "Jiaqi Wei",
        "Zijie Qiu",
        "Chenyu You",
        "Lei Bai",
        "Ning Ding",
        "Tiannan Guo",
        "Bowen Zhou",
        "Siqi Sun"
      ],
      "abstract": "Post-translational modifications (PTMs) serve as a dynamic chemical language regulating protein function, yet current proteomic methods remain blind to a vast portion of the modified proteome. Standard database search algorithms suffer from a combinatorial explosion of search spaces, limiting the identification of uncharacterized or complex modifications. Here we introduce OmniNovo, a unified deep learning framework for reference-free sequencing of unmodified and modified peptides directly from tandem mass spectra. Unlike existing tools restricted to specific modification types, OmniNovo learns universal fragmentation rules to decipher diverse PTMs within a single coherent model. By integrating a mass-constrained decoding algorithm with rigorous false discovery rate estimation, OmniNovo achieves state-of-the-art accuracy, identifying 51\\% more peptides than standard approaches at a 1\\% false discovery rate. Crucially, the model generalizes to biological sites unseen during training, illuminating the dark matter of the proteome and enabling unbiased comprehensive analysis of cellular regulation.",
      "tldr_zh": "è¯¥ç ”ç©¶æå‡ºäº† OmniNovoï¼Œè¿™æ˜¯ä¸€ä¸ªç»Ÿä¸€çš„æ·±åº¦å­¦ä¹ æ¡†æ¶ï¼Œæ—¨åœ¨å®ç°ä»æœªä¿®é¥°å’Œä¿®é¥°è‚½æ®µçš„ä¸²è”è´¨è°±(tandem mass spectra)ä¸­è¿›è¡Œé«˜ç²¾åº¦çš„æ— å‚è€ƒä»å¤´æµ‹åº(de novo sequencing)ã€‚ä¸ºäº†è§£å†³ä¼ ç»Ÿæ•°æ®åº“æœç´¢ç®—æ³•åœ¨å¤„ç†è›‹ç™½è´¨ç¿»è¯‘åä¿®é¥°(Post-translational modifications, PTMs)æ—¶é¢ä¸´çš„æœç´¢ç©ºé—´ç»„åˆçˆ†ç‚¸é—®é¢˜ï¼ŒOmniNovo é€šè¿‡å­¦ä¹ é€šç”¨çš„ç¢ç‰‡è§„åˆ™(universal fragmentation rules)ï¼Œèƒ½å¤Ÿåœ¨ä¸€ä¸ªæ¨¡å‹ä¸­è§£è¯»å¤šæ ·åŒ–çš„ä¿®é¥°ç±»å‹ã€‚è¯¥æ¡†æ¶é›†æˆäº†è´¨é‡é™åˆ¶è§£ç ç®—æ³•(mass-constrained decoding algorithm)å’Œä¸¥æ ¼çš„å‡å‘ç°ç‡(false discovery rate, FDR)ä¼°ç®—ï¼Œåœ¨ 1% çš„å‡å‘ç°ç‡ä¸‹ï¼Œå…¶è¯†åˆ«çš„è‚½æ®µæ•°é‡æ¯”æ ‡å‡†æ–¹æ³•å¤šå‡º 51%ã€‚å®éªŒè¡¨æ˜ï¼ŒOmniNovo å±•ç°å‡ºäº†å“è¶Šçš„æ³›åŒ–èƒ½åŠ›ï¼Œèƒ½å¤Ÿè¯†åˆ«è®­ç»ƒæ•°æ®ä¸­æœªè§çš„ç”Ÿç‰©ä½ç‚¹ï¼Œä»è€Œæœ‰æ•ˆåœ°æ­ç¤ºè›‹ç™½è´¨ç»„ä¸­çš„â€œæš—ç‰©è´¨â€ã€‚è¿™ä¸€çªç ´ä¸ºå…¨é¢ã€æ— ååœ°åˆ†æç»†èƒè°ƒèŠ‚æœºåˆ¶æä¾›äº†å¼ºæœ‰åŠ›çš„å·¥å…·ã€‚",
      "categories": [
        "q-bio.QM",
        "cs.AI"
      ],
      "primary_category": "q-bio.QM",
      "comment": "",
      "pdf_url": "https://arxiv.org/pdf/2512.12272v1",
      "published_date": "2025-12-13 10:27:14 UTC",
      "updated_date": "2025-12-13 10:27:14 UTC",
      "processing_status": "completed",
      "attempts": 1,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "llm_backup_calls": 0,
      "last_update": "2026-01-26T16:27:43.845559+00:00"
    },
    {
      "arxiv_id": "2512.12260v1",
      "title": "A Multi-Axial Mindset for Ontology Design Lessons from Wikidata's Polyhierarchical Structure",
      "title_zh": "æœ¬ä½“è®¾è®¡çš„å¤šè½´å‘æ€ç»´ï¼šWikidata å¤šé‡å±‚çº§ç»“æ„çš„å¯ç¤º",
      "authors": [
        "Ege Atacan DoÄŸan",
        "Peter F. Patel-Schneider"
      ],
      "abstract": "Traditional ontology design emphasizes disjoint and exhaustive top-level distinctions such as continuant vs. occurrent, abstract vs. concrete, or type vs. instance. These distinctions are used to structure unified hierarchies where every entity is classified under a single upper-level category. Wikidata, by contrast, does not enforce a singular foundational taxonomy. Instead, it accommodates multiple classification axes simultaneously under the shared root class entity. This paper analyzes the structural implications of Wikidata's polyhierarchical and multi-axial design. The Wikidata architecture enables a scalable and modular approach to ontology construction, especially suited to collaborative and evolving knowledge graphs.",
      "tldr_zh": "è¯¥ç ”ç©¶æ¢è®¨äº†æœ¬ä½“è®¾è®¡(ontology design)ä¸­çš„å¤šè½´æ€ç»´ï¼Œé€šè¿‡åˆ†æ Wikidata çš„å¤šå±‚çº§ç»“æ„(polyhierarchical structure)æ€»ç»“äº†ç›¸å…³ç»éªŒã€‚ä¼ ç»Ÿçš„æœ¬ä½“è®¾è®¡é€šå¸¸å¼ºè°ƒé¡¶å±‚åŒºåˆ†ï¼Œå¦‚ continuant vs. occurrentã€abstract vs. concrete æˆ– type vs. instanceï¼Œå¹¶ä»¥æ­¤æ„å»ºæ¯ä¸€ä¸ªå®ä½“éƒ½å±äºå•ä¸€ä¸Šå±‚ç±»åˆ«çš„ç»Ÿä¸€å±‚æ¬¡ç»“æ„ã€‚ç›¸æ¯”ä¹‹ä¸‹ï¼ŒWikidata å¹¶ä¸å¼ºåˆ¶æ‰§è¡Œå•ä¸€çš„åŸºç¡€åˆ†ç±»ä½“ç³»ï¼Œè€Œæ˜¯åœ¨å…±äº«æ ¹ç±» entity ä¸‹åŒæ—¶å®¹çº³å¤šä¸ªåˆ†ç±»è½´(classification axes)ã€‚æœ¬æ–‡è¯¦ç»†åˆ†æäº†è¿™ç§å¤šå±‚çº§å’Œå¤šè½´å‘(multi-axial)è®¾è®¡çš„ç»“æ„æ€§å½±å“ã€‚ç ”ç©¶æŒ‡å‡ºï¼ŒWikidata çš„æ¶æ„å®ç°äº†ä¸€ç§å¯æ‰©å±•ä¸”æ¨¡å—åŒ–çš„æœ¬ä½“æ„å»ºæ–¹æ³•ï¼Œç‰¹åˆ«é€‚ç”¨äºåä½œå¼ä¸”ä¸æ–­æ¼”è¿›çš„çŸ¥è¯†å›¾è°±(knowledge graphs)ã€‚",
      "categories": [
        "cs.AI",
        "cs.DB"
      ],
      "primary_category": "cs.AI",
      "comment": "",
      "pdf_url": "https://arxiv.org/pdf/2512.12260v1",
      "published_date": "2025-12-13 09:59:22 UTC",
      "updated_date": "2025-12-13 09:59:22 UTC",
      "processing_status": "completed",
      "attempts": 1,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "llm_backup_calls": 0,
      "last_update": "2026-01-26T16:27:56.680911+00:00"
    },
    {
      "arxiv_id": "2512.12250v1",
      "title": "Stochastic Volatility Modelling with LSTM Networks: A Hybrid Approach for S&P 500 Index Volatility Forecasting",
      "title_zh": "åŸºäº LSTM ç½‘ç»œçš„éšæœºæ³¢åŠ¨ç‡å»ºæ¨¡ï¼šä¸€ç§ S&P 500 æŒ‡æ•°æ³¢åŠ¨ç‡é¢„æµ‹çš„æ··åˆæ–¹æ³•",
      "authors": [
        "Anna Perekhodko",
        "Robert Åšlepaczuk"
      ],
      "abstract": "Accurate volatility forecasting is essential in banking, investment, and risk management, because expectations about future market movements directly influence current decisions. This study proposes a hybrid modelling framework that integrates a Stochastic Volatility model with a Long Short Term Memory neural network. The SV model improves statistical precision and captures latent volatility dynamics, especially in response to unforeseen events, while the LSTM network enhances the model's ability to detect complex nonlinear patterns in financial time series. The forecasting is conducted using daily data from the S and P 500 index, covering the period from January 1 1998 to December 31 2024. A rolling window approach is employed to train the model and generate one step ahead volatility forecasts. The performance of the hybrid SV-LSTM model is evaluated through both statistical testing and investment simulations. The results show that the hybrid approach outperforms both the standalone SV and LSTM models and contributes to the development of volatility modelling techniques, providing a foundation for improving risk assessment and strategic investment planning in the context of the S and P 500.",
      "tldr_zh": "è¯¥ç ”ç©¶æå‡ºäº†ä¸€ç§ç»“åˆäº† Stochastic Volatility (SV) æ¨¡å‹å’Œ Long Short Term Memory (LSTM) ç¥ç»ç½‘ç»œçš„æ··åˆå»ºæ¨¡æ¡†æ¶ï¼Œæ—¨åœ¨æé«˜ S&P 500 æŒ‡æ•°æ³¢åŠ¨ç‡é¢„æµ‹çš„å‡†ç¡®æ€§ã€‚åœ¨è¯¥æ¡†æ¶ä¸­ï¼ŒSV æ¨¡å‹è´Ÿè´£æ•æ‰æ½œåœ¨çš„æ³¢åŠ¨ç‡åŠ¨æ€å¹¶æå‡ç»Ÿè®¡ç²¾åº¦ï¼Œå°¤å…¶æ˜¯åœ¨åº”å¯¹ä¸å¯é¢„è§äº‹ä»¶æ—¶è¡¨ç°å‡ºè‰²ï¼Œè€Œ LSTM ç½‘ç»œåˆ™æ˜¾è‘—å¢å¼ºäº†æ•æ‰é‡‘èæ—¶é—´åºåˆ—ä¸­å¤æ‚éçº¿æ€§æ¨¡å¼çš„èƒ½åŠ›ã€‚ç ”ç©¶åˆ©ç”¨ 1998 å¹´è‡³ 2024 å¹´çš„ S&P 500 æ—¥åº¦æ•°æ®ï¼Œé€šè¿‡æ»šåŠ¨çª—å£æ–¹æ³•è¿›è¡Œè®­ç»ƒå¹¶ç”Ÿæˆä¸€æ­¥é¢„æµ‹ã€‚é€šè¿‡ç»Ÿè®¡æµ‹è¯•å’ŒæŠ•èµ„æ¨¡æ‹Ÿçš„ç»¼åˆè¯„ä¼°ï¼Œç»“æœè¡¨æ˜ SV-LSTM æ··åˆæ¨¡å‹çš„è¡¨ç°ä¼˜äºå•ä¸€çš„ SV æˆ– LSTM æ¨¡å‹ã€‚è¯¥ç ”ç©¶ä¸ä»…ä¸ºæ³¢åŠ¨ç‡å»ºæ¨¡æŠ€æœ¯åšå‡ºäº†è´¡çŒ®ï¼Œä¹Ÿä¸ºé‡‘èé¢†åŸŸçš„é£é™©è¯„ä¼°å’Œæˆ˜ç•¥æŠ•èµ„è§„åˆ’æä¾›äº†æ›´åŠ å¯é çš„åŸºç¡€ã€‚",
      "categories": [
        "q-fin.TR",
        "cs.AI",
        "cs.LG",
        "cs.NE",
        "q-fin.PM"
      ],
      "primary_category": "q-fin.TR",
      "comment": "32 pages, 15 tables, 11 figures",
      "pdf_url": "https://arxiv.org/pdf/2512.12250v1",
      "published_date": "2025-12-13 09:21:43 UTC",
      "updated_date": "2025-12-13 09:21:43 UTC",
      "processing_status": "completed",
      "attempts": 1,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "llm_backup_calls": 0,
      "last_update": "2026-01-26T16:28:02.149812+00:00"
    },
    {
      "arxiv_id": "2512.12245v1",
      "title": "Adversarially Probing Cross-Family Sound Symbolism in 27 Languages",
      "title_zh": "27ç§è¯­è¨€ä¸­è·¨è¯­ç³»è¯­éŸ³è±¡å¾çš„å¯¹æŠ—æ€§æ¢æµ‹",
      "authors": [
        "Anika Sharma",
        "Tianyi Niu",
        "Emma Wrenn",
        "Shashank Srivastava"
      ],
      "abstract": "The phenomenon of sound symbolism, the non-arbitrary mapping between word sounds and meanings, has long been demonstrated through anecdotal experiments like Bouba Kiki, but rarely tested at scale. We present the first computational cross-linguistic analysis of sound symbolism in the semantic domain of size. We compile a typologically broad dataset of 810 adjectives (27 languages, 30 words each), each phonemically transcribed and validated with native-speaker audio. Using interpretable classifiers over bag-of-segment features, we find that phonological form predicts size semantics above chance even across unrelated languages, with both vowels and consonants contributing. To probe universality beyond genealogy, we train an adversarial scrubber that suppresses language identity while preserving size signal (also at family granularity). Language prediction averaged across languages and settings falls below chance while size prediction remains significantly above chance, indicating cross-family sound-symbolic bias. We release data, code, and diagnostic tools for future large-scale studies of iconicity.",
      "tldr_zh": "è¯¥ç ”ç©¶é’ˆå¯¹è¯­éŸ³è±¡ä¼¼æ€§ï¼ˆSound Symbolismï¼‰è¿™ä¸€é•¿æœŸç¼ºä¹å¤§è§„æ¨¡éªŒè¯çš„ç°è±¡ï¼Œé¦–æ¬¡å¯¹27ç§ä¸åŒè¯­ç³»è¯­è¨€ä¸­å…³äºâ€œå°ºå¯¸ï¼ˆsizeï¼‰â€è¯­ä¹‰é¢†åŸŸçš„è¯­éŸ³è±¡ä¼¼æ€§è¿›è¡Œäº†å¤§è§„æ¨¡è®¡ç®—è·¨è¯­è¨€åˆ†æã€‚ç ”ç©¶å›¢é˜Ÿæ„å»ºäº†ä¸€ä¸ªåŒ…å«810ä¸ªå½¢å®¹è¯çš„è·¨è¯­ç³»æ•°æ®é›†ï¼Œå¹¶ç»“åˆéŸ³ä½è½¬å½•ä¸æ¯è¯­éŸ³é¢‘è¿›è¡ŒéªŒè¯ã€‚é€šè¿‡åœ¨éŸ³æ®µè¢‹ï¼ˆbag-of-segmentï¼‰ç‰¹å¾ä¸Šä½¿ç”¨å¯è§£é‡Šåˆ†ç±»å™¨ï¼ˆinterpretable classifiersï¼‰ï¼Œç ”ç©¶å‘ç°éŸ³ä½å½¢å¼åœ¨æ— å…³è¯­è¨€é—´å¯¹å°ºå¯¸è¯­ä¹‰çš„é¢„æµ‹è¡¨ç°å‡ä¼˜äºéšæœºæ°´å¹³ã€‚ä¸ºäº†è¿›ä¸€æ­¥éªŒè¯æ™®é€‚æ€§å¹¶æ’é™¤è¯­ç³»äº²ç¼˜å…³ç³»å¹²æ‰°ï¼Œç ”ç©¶å¼•å…¥äº†å¯¹æŠ—å¼æ“¦é™¤å™¨ï¼ˆadversarial scrubberï¼‰æ¥æŠ‘åˆ¶è¯­è¨€èº«ä»½ä¿¡æ¯ï¼Œç»“æœæ˜¾ç¤ºå°ºå¯¸é¢„æµ‹å‡†ç¡®ç‡ä¾ç„¶æ˜¾è‘—ï¼Œæœ‰åŠ›è¯æ˜äº†è·¨è¯­ç³»è¯­éŸ³è±¡ä¼¼æ€§åå·®ï¼ˆsound-symbolic biasï¼‰çš„å­˜åœ¨ã€‚è¯¥é¡¹å·¥ä½œæ­ç¤ºäº†å…ƒéŸ³å’Œè¾…éŸ³å¯¹è¯­ä¹‰é¢„æµ‹çš„å…±åŒè´¡çŒ®ï¼Œå¹¶å…¬å¼€å‘å¸ƒäº†ç›¸å…³æ•°æ®ã€ä»£ç åŠè¯Šæ–­å·¥å…·ï¼Œä¸ºæœªæ¥å¤§è§„æ¨¡çš„è±¡ä¼¼æ€§ï¼ˆiconicityï¼‰ç ”ç©¶å¥ å®šäº†åŸºç¡€ã€‚",
      "categories": [
        "cs.CL",
        "cs.AI"
      ],
      "primary_category": "cs.CL",
      "comment": "",
      "pdf_url": "https://arxiv.org/pdf/2512.12245v1",
      "published_date": "2025-12-13 09:06:50 UTC",
      "updated_date": "2025-12-13 09:06:50 UTC",
      "processing_status": "completed",
      "attempts": 1,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "llm_backup_calls": 0,
      "last_update": "2026-01-26T16:29:18.901929+00:00"
    },
    {
      "arxiv_id": "2512.12238v1",
      "title": "Semantic Distance Measurement based on Multi-Kernel Gaussian Processes",
      "title_zh": "åŸºäºå¤šæ ¸é«˜æ–¯è¿‡ç¨‹çš„è¯­ä¹‰è·ç¦»åº¦é‡",
      "authors": [
        "Yinzhu Cheng",
        "Haihua Xie",
        "Yaqing Wang",
        "Miao He",
        "Mingming Sun"
      ],
      "abstract": "Semantic distance measurement is a fundamental problem in computational linguistics, providing a quantitative characterization of similarity or relatedness between text segments, and underpinning tasks such as text retrieval and text classification. From a mathematical perspective, a semantic distance can be viewed as a metric defined on a space of texts or on a representation space derived from them. However, most classical semantic distance methods are essentially fixed, making them difficult to adapt to specific data distributions and task requirements. In this paper, a semantic distance measure based on multi-kernel Gaussian processes (MK-GP) was proposed. The latent semantic function associated with texts was modeled as a Gaussian process, with its covariance function given by a combined kernel combining MatÃ©rn and polynomial components. The kernel parameters were learned automatically from data under supervision, rather than being hand-crafted. This semantic distance was instantiated and evaluated in the context of fine-grained sentiment classification with large language models under an in-context learning (ICL) setup. The experimental results demonstrated the effectiveness of the proposed measure.",
      "tldr_zh": "è¯­ä¹‰è·ç¦»æµ‹é‡(Semantic distance measurement)æ˜¯è®¡ç®—è¯­è¨€å­¦ä¸­çš„åŸºç¡€é—®é¢˜ï¼Œæ—¨åœ¨é‡åŒ–æ–‡æœ¬é—´çš„ç›¸ä¼¼æ€§æˆ–ç›¸å…³æ€§ï¼Œä½†ä¼ ç»Ÿæ–¹æ³•å¾€å¾€å› å½¢å¼å›ºå®šè€Œéš¾ä»¥é€‚é…ç‰¹å®šä»»åŠ¡ã€‚è¯¥ç ”ç©¶æå‡ºäº†ä¸€ç§åŸºäºå¤šæ ¸é«˜æ–¯è¿‡ç¨‹(Multi-kernel Gaussian Processes, MK-GP)çš„è¯­ä¹‰è·ç¦»åº¦é‡æ–¹æ³•ï¼Œå°†æ–‡æœ¬çš„æ½œåœ¨è¯­ä¹‰å‡½æ•°å»ºæ¨¡ä¸ºé«˜æ–¯è¿‡ç¨‹ã€‚è¯¥æ¡†æ¶åˆ©ç”¨ç»“åˆäº†MatÃ©rnå’Œå¤šé¡¹å¼(Polynomial)ç»„ä»¶çš„å¤åˆæ ¸å‡½æ•°ä½œä¸ºåæ–¹å·®å‡½æ•°ï¼Œå¹¶é€šè¿‡æœ‰ç›‘ç£å­¦ä¹ ä»æ•°æ®ä¸­è‡ªåŠ¨ä¼˜åŒ–æ ¸å‚æ•°ã€‚ç ”ç©¶åœ¨å¤§è¯­è¨€æ¨¡å‹(Large Language Models)çš„ä¸Šä¸‹æ–‡å­¦ä¹ (In-context Learning, ICL)è®¾ç½®ä¸‹ï¼Œé’ˆå¯¹ç»†ç²’åº¦æƒ…æ„Ÿåˆ†ç±»ä»»åŠ¡å¯¹è¯¥æ–¹æ³•è¿›è¡Œäº†å®ä¾‹åŒ–è¯„ä¼°ã€‚å®éªŒç»“æœè¯æ˜äº†è¯¥åº¦é‡æ–¹æ³•çš„æœ‰æ•ˆæ€§ï¼Œå±•ç¤ºäº†å…¶åœ¨å¤„ç†ç‰¹å®šæ•°æ®åˆ†å¸ƒå’Œå¤æ‚ä»»åŠ¡éœ€æ±‚æ—¶çš„ä¼˜è¶Šæ€§èƒ½ã€‚",
      "categories": [
        "cs.CL",
        "cs.AI"
      ],
      "primary_category": "cs.CL",
      "comment": "",
      "pdf_url": "https://arxiv.org/pdf/2512.12238v1",
      "published_date": "2025-12-13 08:34:00 UTC",
      "updated_date": "2025-12-13 08:34:00 UTC",
      "processing_status": "completed",
      "attempts": 1,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "llm_backup_calls": 0,
      "last_update": "2026-01-26T16:29:14.423186+00:00"
    },
    {
      "arxiv_id": "2512.15773v1",
      "title": "TS-DP: Reinforcement Speculative Decoding For Temporal Adaptive Diffusion Policy Acceleration",
      "title_zh": "TS-DPï¼šé¢å‘æ—¶åºè‡ªé€‚åº”æ‰©æ•£ç­–ç•¥åŠ é€Ÿçš„å¼ºåŒ–å­¦ä¹ æŠ•æœºè§£ç ",
      "authors": [
        "Ye Li",
        "Jiahe Feng",
        "Yuan Meng",
        "Kangye Ji",
        "Chen Tang",
        "Xinwan Wen",
        "Shutao Xia",
        "Zhi Wang",
        "Wenwu Zhu"
      ],
      "abstract": "Diffusion Policy (DP) excels in embodied control but suffers from high inference latency and computational cost due to multiple iterative denoising steps. The temporal complexity of embodied tasks demands a dynamic and adaptable computation mode. Static and lossy acceleration methods, such as quantization, fail to handle such dynamic embodied tasks, while speculative decoding offers a lossless and adaptive yet underexplored alternative for DP. However, it is non-trivial to address the following challenges: how to match the base model's denoising quality at lower cost under time-varying task difficulty in embodied settings, and how to dynamically and interactively adjust computation based on task difficulty in such environments. In this paper, we propose Temporal-aware Reinforcement-based Speculative Diffusion Policy (TS-DP), the first framework that enables speculative decoding for DP with temporal adaptivity. First, to handle dynamic environments where task difficulty varies over time, we distill a Transformer-based drafter to imitate the base model and replace its costly denoising calls. Second, an RL-based scheduler further adapts to time-varying task difficulty by adjusting speculative parameters to maintain accuracy while improving efficiency. Extensive experiments across diverse embodied environments demonstrate that TS-DP achieves up to 4.17 times faster inference with over 94% accepted drafts, reaching an inference frequency of 25 Hz and enabling real-time diffusion-based control without performance degradation.",
      "tldr_zh": "è¯¥ç ”ç©¶æå‡ºäº†TS-DPï¼Œè¿™æ˜¯é¦–ä¸ªä¸ºDiffusion Policy (DP) è®¾è®¡çš„å…·æœ‰æ—¶é—´è‡ªé€‚åº”èƒ½åŠ›çš„æŠ•æœºè§£ç (speculative decoding)æ¡†æ¶ï¼Œæ—¨åœ¨è§£å†³å…¶åœ¨å…·èº«æ§åˆ¶ä¸­ç”±äºè¿­ä»£å»å™ªå¯¼è‡´çš„æ¨ç†å»¶è¿Ÿé«˜é—®é¢˜ã€‚é’ˆå¯¹å…·èº«ä»»åŠ¡éšæ—¶é—´åŠ¨æ€å˜åŒ–çš„éš¾åº¦ï¼ŒTS-DPé¦–å…ˆé€šè¿‡è’¸é¦å¾—åˆ°ä¸€ä¸ªåŸºäºTransformerçš„è‰ç¨¿æ¨¡å‹(drafter)æ¥æ¨¡ä»¿åŸºç¡€æ¨¡å‹ä»¥å‡å°‘è®¡ç®—å¼€é”€ã€‚å…¶æ¬¡ï¼Œè¯¥æ¡†æ¶å¼•å…¥äº†åŸºäºå¼ºåŒ–å­¦ä¹ (RL)çš„è°ƒåº¦å™¨(scheduler)ï¼Œèƒ½å¤Ÿæ ¹æ®ä»»åŠ¡éš¾åº¦åŠ¨æ€è°ƒæ•´æŠ•æœºå‚æ•°ä»¥å¹³è¡¡æ•ˆç‡ä¸å‡†ç¡®æ€§ã€‚å®éªŒç»“æœè¡¨æ˜ï¼ŒTS-DPåœ¨å¤šç§å…·èº«ç¯å¢ƒä¸­å®ç°äº†é«˜è¾¾4.17å€çš„æ¨ç†åŠ é€Ÿï¼Œè‰ç¨¿æ¥å—ç‡è¶…è¿‡94%ã€‚è¯¥æ–¹æ³•ä½¿æ¨ç†é¢‘ç‡è¾¾åˆ°25 Hzï¼Œåœ¨ä¸é™ä½æ€§èƒ½çš„æƒ…å†µä¸‹å®ç°äº†å®æ—¶çš„æ‰©æ•£æ¨¡å‹æ§åˆ¶ï¼Œä¸ºé«˜æ•ˆå…·èº«æ™ºèƒ½æä¾›äº†æ–°æ–¹æ¡ˆã€‚",
      "categories": [
        "cs.LG",
        "cs.AI"
      ],
      "primary_category": "cs.LG",
      "comment": "",
      "pdf_url": "https://arxiv.org/pdf/2512.15773v1",
      "published_date": "2025-12-13 07:53:14 UTC",
      "updated_date": "2025-12-13 07:53:14 UTC",
      "processing_status": "completed",
      "attempts": 1,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "llm_backup_calls": 0,
      "last_update": "2026-01-26T16:29:19.281862+00:00"
    },
    {
      "arxiv_id": "2512.17943v1",
      "title": "NystagmusNet: Explainable Deep Learning for Photosensitivity Risk Prediction",
      "title_zh": "NystagmusNetï¼šé¢å‘å…‰æ•æ€§é£é™©é¢„æµ‹çš„å¯è§£é‡Šæ·±åº¦å­¦ä¹ ",
      "authors": [
        "Karthik Prabhakar"
      ],
      "abstract": "Nystagmus patients with photosensitivity face significant daily challenges due to involuntary eye movements exacerbated by environmental brightness conditions. Current assistive solutions are limited to symptomatic treatments without predictive personalization. This paper proposes NystagmusNet, an AI-driven system that predicts high-risk visual environments and recommends real-time visual adaptations. Using a dual-branch convolutional neural network trained on synthetic and augmented datasets, the system estimates a photosensitivity risk score based on environmental brightness and eye movement variance. The model achieves 75% validation accuracy on synthetic data. Explainability techniques including SHAP and GradCAM are integrated to highlight environmental risk zones, improving clinical trust and model interpretability. The system includes a rule-based recommendation engine for adaptive filter suggestions. Future directions include deployment via smart glasses and reinforcement learning for personalized recommendations.",
      "tldr_zh": "è¯¥ç ”ç©¶é’ˆå¯¹çœ¼çƒéœ‡é¢¤ (Nystagmus) æ‚£è€…åœ¨å…‰æ•æ„Ÿç¯å¢ƒä¸‹é¢ä¸´çš„æ—¥å¸¸æŒ‘æˆ˜ï¼Œæå‡ºäº† NystagmusNetï¼Œè¿™æ˜¯ä¸€ç§èƒ½å¤Ÿé¢„æµ‹é«˜é£é™©è§†è§‰ç¯å¢ƒå¹¶æä¾›å®æ—¶è§†è§‰è°ƒèŠ‚å»ºè®®çš„ AI é©±åŠ¨ç³»ç»Ÿã€‚è¯¥ç³»ç»Ÿåˆ©ç”¨åœ¨åˆæˆå’Œå¢å¼ºæ•°æ®é›†ä¸Šè®­ç»ƒçš„åŒåˆ†æ”¯å·ç§¯ç¥ç»ç½‘ç»œ (Dual-branch CNN)ï¼Œç»“åˆç¯å¢ƒäº®åº¦å’Œçœ¼åŠ¨åå·®æ¥ä¼°ç®— photosensitivity é£é™©è¯„åˆ†ã€‚å®éªŒè¡¨æ˜ï¼Œè¯¥æ¨¡å‹åœ¨åˆæˆæ•°æ®ä¸Šè¾¾åˆ°äº† 75% çš„éªŒè¯å‡†ç¡®ç‡ã€‚ä¸ºäº†æå‡ä¸´åºŠä¿¡ä»»åº¦ï¼Œç ”ç©¶é›†æˆäº† SHAP å’Œ GradCAM ç­‰å¯è§£é‡Šæ€§æŠ€æœ¯ä»¥è¯†åˆ«ç¯å¢ƒé£é™©åŒºåŸŸï¼Œå¹¶é…å¤‡äº†åŸºäºè§„åˆ™çš„æ¨èå¼•æ“ç”¨äºè‡ªé€‚åº”æ»¤å…‰å»ºè®®ã€‚è¯¥ç³»ç»Ÿçš„æœªæ¥å‘å±•æ–¹å‘åŒ…æ‹¬é€šè¿‡æ™ºèƒ½çœ¼é•œè¿›è¡Œéƒ¨ç½²ï¼Œå¹¶å¼•å…¥ Reinforcement Learning ä»¥å®ç°æ›´å…·ä¸ªæ€§åŒ–çš„æ¨èã€‚",
      "categories": [
        "cs.CV",
        "cs.AI"
      ],
      "primary_category": "cs.CV",
      "comment": "12 pages, 7 figures, 2 tables, code available at https://github.com/knkarthik01/nystagmus-photosensitivity-ai",
      "pdf_url": "https://arxiv.org/pdf/2512.17943v1",
      "published_date": "2025-12-13 07:40:42 UTC",
      "updated_date": "2025-12-13 07:40:42 UTC",
      "processing_status": "completed",
      "attempts": 1,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "llm_backup_calls": 0,
      "last_update": "2026-01-26T16:29:23.122295+00:00"
    },
    {
      "arxiv_id": "2512.12225v2",
      "title": "A Geometric Theory of Cognition",
      "title_zh": "è®¤çŸ¥çš„å‡ ä½•ç†è®º",
      "authors": [
        "Laha Ale"
      ],
      "abstract": "Human cognition spans perception, memory, intuitive judgment, deliberative reasoning, action selection, and social inference, yet these capacities are often explained through distinct computational theories. Here we present a unified mathematical framework in which diverse cognitive processes emerge from a single geometric principle. We represent the cognitive state as a point on a differentiable manifold endowed with a learned Riemannian metric that encodes representational constraints, computational costs, and structural relations among cognitive variables. A scalar cognitive potential combines predictive accuracy, structural parsimony, task utility, and normative or logical requirements. Cognition unfolds as the Riemannian gradient flow of this potential, providing a universal dynamical law from which a broad range of psychological phenomena arise. Classical dual-process effects--rapid intuitive responses and slower deliberative reasoning--emerge naturally from metric-induced anisotropies that generate intrinsic time-scale separations and geometric phase transitions, without invoking modular or hybrid architectures. We derive analytical conditions for these regimes and demonstrate their behavioural signatures through simulations of canonical cognitive tasks. Together, these results establish a geometric foundation for cognition and suggest guiding principles for the development of more general and human-like artificial intelligence systems.",
      "tldr_zh": "è¯¥ç ”ç©¶æå‡ºäº†ä¸€ä¸ªç»Ÿä¸€çš„è®¤çŸ¥æ•°å­¦æ¡†æ¶ï¼ŒåŸºäºå•ä¸€çš„å‡ ä½•åŸç†(Geometric principle)æ¥è§£é‡Šæ„ŸçŸ¥ã€è®°å¿†ã€æ¨ç†å’Œç¤¾äº¤æ¨æ–­ç­‰å¤šç§è®¤çŸ¥è¿‡ç¨‹ã€‚è¯¥ç†è®ºå°†è®¤çŸ¥çŠ¶æ€è¡¨ç¤ºä¸ºå¾®åˆ†æµå½¢(Differentiable manifold)ä¸Šçš„ä¸€ä¸ªç‚¹ï¼Œå¹¶åˆ©ç”¨å­¦ä¹ åˆ°çš„é»æ›¼åº¦é‡(Riemannian metric)æ¥ç¼–ç è¡¨å¾çº¦æŸã€è®¡ç®—æˆæœ¬å’Œå˜é‡é—´çš„ç»“æ„å…³ç³»ã€‚è®¤çŸ¥æ¼”åŒ–è¢«å®šä¹‰ä¸ºè®¤çŸ¥åŠ¿èƒ½(Cognitive potential)çš„é»æ›¼æ¢¯åº¦æµ(Riemannian gradient flow)ï¼Œè¯¥åŠ¿èƒ½ç»¼åˆäº†é¢„æµ‹å‡†ç¡®æ€§ã€ç»“æ„ç®€æ´æ€§å’Œä»»åŠ¡æ•ˆç”¨ã€‚ç»å…¸çš„åŒè¿‡ç¨‹(Dual-process)æ•ˆåº”ï¼Œå³å¿«é€Ÿç›´è§‰ä¸æ…¢é€Ÿå®¡æ…æ¨ç†ï¼Œä»åº¦é‡è¯±å¯¼çš„å„å‘å¼‚æ€§(Anisotropies)å’Œå‡ ä½•ç›¸å˜ä¸­è‡ªç„¶æ¶Œç°ï¼Œæ— éœ€ä¾èµ–æ¨¡å—åŒ–æˆ–æ··åˆæ¶æ„ã€‚é€šè¿‡å¯¹å…¸å‹è®¤çŸ¥ä»»åŠ¡çš„æ¨¡æ‹Ÿï¼Œç ”ç©¶éªŒè¯äº†è¯¥æ¡†æ¶åœ¨æè¿°äººç±»è®¤çŸ¥è¡Œä¸ºç‰¹å¾æ–¹é¢çš„æœ‰æ•ˆæ€§ã€‚è¿™ä¸€æˆæœä¸ºè®¤çŸ¥ç§‘å­¦å¥ å®šäº†å‡ ä½•åŸºç¡€ï¼Œå¹¶ä¸ºå¼€å‘æ›´é€šç”¨ã€æ›´ç±»äººçš„äººå·¥æ™ºèƒ½ç³»ç»Ÿ(AI systems)æä¾›äº†æ–°çš„æŒ‡å¯¼åŸåˆ™ã€‚",
      "categories": [
        "cs.AI"
      ],
      "primary_category": "cs.AI",
      "comment": "",
      "pdf_url": "https://arxiv.org/pdf/2512.12225v2",
      "published_date": "2025-12-13 07:39:53 UTC",
      "updated_date": "2025-12-31 16:33:03 UTC",
      "processing_status": "completed",
      "attempts": 1,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "llm_backup_calls": 0,
      "last_update": "2026-01-26T16:28:27.760808+00:00"
    },
    {
      "arxiv_id": "2512.12222v1",
      "title": "Comparison of different segmentation algorithms on brain volume and fractal dimension in infant brain MRIs",
      "title_zh": "ä¸åŒåˆ†å‰²ç®—æ³•å¯¹å©´å„¿è„‘éƒ¨ MRI è„‘ä½“ç§¯åŠåˆ†å½¢ç»´æ•°å½±å“çš„æ¯”è¾ƒç ”ç©¶",
      "authors": [
        "Nathalie Alexander",
        "Arnaud Gucciardi",
        "Umberto Michelucci"
      ],
      "abstract": "Accurate segmentation of infant brain MRI is essential for quantifying developmental changes in structure and complexity. However, ongoing myelination and reduced tissue contrast make automated segmentation particularly challenging. This study systematically compared segmentation accuracy and its impact on volumetric and fractal dimension (FD) estimates in infant brain MRI using the Baby Open Brains (BOB) dataset (71 scans, 1-9 months). Two methods, SynthSeg and SamSeg, were evaluated against expert annotations using Dice, Intersection over Union, 95th-percentile Hausdorff distance, and Normalised Mutual Information. SynthSeg outperformed SamSeg across all quality metrics (mean Dice > 0.8 for major regions) and provided volumetric estimates closely matching the manual reference (mean +4% [-28% - 71%]). SamSeg systematically overestimated ventricular and whole-brain volumes (mean +76% [-12% - 190%]). Segmentation accuracy improved with age, consistent with increasing tissue contrast during myelination. Fractal dimension a(FD) nalyses revealed significant regional differences between SynthSeg and expert segmentations, and Bland-Altman limits of agreement indicated that segmentation-related FD variability exceeded most group differences reported in developmental cohorts. Volume and FD deviations were positively correlated across structures, indicating that segmentation bias directly affects FD estimation. Overall, SynthSeg provided the most reliable volumetric and FD results for paediatric MRI, yet small morphological differences in volume and FD should be interpreted with caution due to segmentation-related uncertainty.",
      "tldr_zh": "è¯¥ç ”ç©¶åˆ©ç”¨Baby Open Brains (BOB)æ•°æ®é›†ï¼Œå¯¹æ¯”åˆ†æäº†SynthSegå’ŒSamSegä¸¤ç§è‡ªåŠ¨åˆ†å‰²ç®—æ³•åœ¨å©´å„¿è„‘éƒ¨ç£å…±æŒ¯æˆåƒ(MRI)ä¸­çš„åˆ†å‰²å‡†ç¡®æ€§åŠå…¶å¯¹ä½“ç§¯å’Œåˆ†å½¢ç»´æ•°(Fractal dimension, FD)ä¼°ç®—çš„å½±å“ã€‚é€šè¿‡ä¸ä¸“å®¶äººå·¥æ ‡æ³¨å¯¹æ¯”ï¼Œç ”ç©¶é‡‡ç”¨Diceã€Intersection over Union (IoU)å’Œ95th-percentile Hausdorff distanceç­‰æŒ‡æ ‡è¯„ä¼°äº†1-9ä¸ªæœˆå©´å„¿æ ·æœ¬çš„åˆ†å‰²æ€§èƒ½ã€‚å®éªŒç»“æœæ˜¾ç¤ºï¼ŒSynthSegåœ¨æ‰€æœ‰è´¨é‡æŒ‡æ ‡ä¸Šå‡ä¼˜äºSamSegï¼Œå…¶ä½“ç§¯ä¼°ç®—ä¸äººå·¥å‚è€ƒå€¼é«˜åº¦å»åˆï¼Œä¸”åˆ†å‰²å‡†ç¡®æ€§éšå©´å„¿å¹´é¾„å¢é•¿åŠé«“é˜åŒ–å¸¦æ¥çš„ç»„ç»‡å¯¹æ¯”åº¦æå‡è€Œæé«˜ã€‚ç›¸æ¯”ä¹‹ä¸‹ï¼ŒSamSegæ˜¾è‘—é«˜ä¼°äº†è„‘å®¤å’Œå…¨è„‘ä½“ç§¯ï¼Œä¸”åˆ†å½¢ç»´æ•°åˆ†æè¡¨æ˜åˆ†å‰²åå·®ä¼šç›´æ¥å¯¼è‡´FDä¼°ç®—çš„æ³¢åŠ¨ã€‚ç ”ç©¶æŒ‡å‡ºï¼Œåˆ†å‰²å¼•èµ·çš„ä¸ç¡®å®šæ€§å¯èƒ½è¶…è¿‡å‘è‚²é˜Ÿåˆ—ä¸­æŠ¥å‘Šçš„ç»„é—´å·®å¼‚ï¼Œå› æ­¤åœ¨è§£é‡Šè¾ƒå°çš„å½¢æ€å­¦å·®å¼‚æ—¶åº”æŒè°¨æ…æ€åº¦ã€‚æ€»ä½“è€Œè¨€ï¼ŒSynthSegä¸ºå„¿ç§‘MRIæä¾›äº†ç›®å‰æœ€å¯é çš„ä½“ç§¯å’ŒFDåˆ†æç»“æœã€‚",
      "categories": [
        "cs.CV",
        "cs.AI"
      ],
      "primary_category": "cs.CV",
      "comment": "",
      "pdf_url": "https://arxiv.org/pdf/2512.12222v1",
      "published_date": "2025-12-13 07:23:32 UTC",
      "updated_date": "2025-12-13 07:23:32 UTC",
      "processing_status": "completed",
      "attempts": 1,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "llm_backup_calls": 0,
      "last_update": "2026-01-26T16:28:49.650796+00:00"
    },
    {
      "arxiv_id": "2512.12216v2",
      "title": "Training Versatile Coding Agents in Synthetic Environments",
      "title_zh": "åœ¨åˆæˆç¯å¢ƒä¸­è®­ç»ƒé€šç”¨ç¼–ç¨‹æ™ºèƒ½ä½“",
      "authors": [
        "Yiqi Zhu",
        "Apurva Gandhi",
        "Graham Neubig"
      ],
      "abstract": "Prior works on training software engineering agents have explored utilizing existing resources such as issues on GitHub repositories to construct software engineering tasks and corresponding test suites. These approaches face two key limitations: (1) their reliance on pre-existing GitHub repositories offers limited flexibility, and (2) their primary focus on issue resolution tasks restricts their applicability to the much wider variety of tasks a software engineer must handle. To overcome these challenges, we introduce SWE-Playground, a novel pipeline for generating environments and trajectories which supports the training of versatile coding agents. Unlike prior efforts, SWE-Playground synthetically generates projects and tasks from scratch with strong language models and agents, eliminating reliance on external data sources. This allows us to tackle a much wider variety of coding tasks, such as reproducing issues by generating unit tests and implementing libraries from scratch. We demonstrate the effectiveness of this approach on three distinct benchmarks, and results indicate that SWE-Playground produces trajectories with dense training signal, enabling agents to reach comparable performance with significantly fewer trajectories than previous works.",
      "tldr_zh": "è¯¥ç ”ç©¶æå‡ºäº†SWE-Playgroundï¼Œä¸€ç§æ—¨åœ¨è®­ç»ƒå¤šåŠŸèƒ½coding agentsçš„åˆ›æ–°å‹pipelineï¼Œé€šè¿‡ç”Ÿæˆåˆæˆç¯å¢ƒå’Œtrajectoriesè§£å†³äº†ä¼ ç»Ÿæ–¹æ³•å¯¹GitHubç°æœ‰èµ„æºä¾èµ–æ€§å¼ºä¸”çµæ´»æ€§å·®çš„é—®é¢˜ã€‚SWE-Playgroundåˆ©ç”¨å¼ºè¯­è¨€æ¨¡å‹å’Œagentsä»é›¶å¼€å§‹åˆæˆé¡¹ç›®ä¸ä»»åŠ¡ï¼Œä½¿å…¶èƒ½å¤Ÿæ¶µç›–ä»å•å…ƒæµ‹è¯•å¤ç°issueåˆ°ä»å¤´å®ç°librariesç­‰æ›´å¹¿æ³›çš„ç¼–ç ä»»åŠ¡ã€‚è¿™ç§æ–¹æ³•æ¶ˆé™¤äº†å¯¹å¤–éƒ¨æ•°æ®æºçš„ä¾èµ–ï¼Œå¹¶èƒ½äº§ç”Ÿå…·æœ‰é«˜å¯†åº¦è®­ç»ƒä¿¡å·çš„è½¨è¿¹ã€‚åœ¨ä¸‰ä¸ªä¸åŒbenchmarksä¸Šçš„å®éªŒç»“æœè¡¨æ˜ï¼Œè¯¥æ–¹æ³•ä½¿coding agentsèƒ½å¤Ÿä»¥æ˜¾è‘—æ›´å°‘çš„trajectoriesè¾¾åˆ°ä¸å‰åºç ”ç©¶ç›¸å½“çš„æ€§èƒ½æ°´å¹³ã€‚è¿™ä¸€æˆæœä¸ºæ„å»ºé«˜æ•ˆã€é€šç”¨çš„è½¯ä»¶å·¥ç¨‹æ™ºèƒ½ä½“æä¾›äº†å…¨æ–°çš„åˆæˆæ•°æ®é©±åŠ¨æ–¹æ¡ˆã€‚",
      "categories": [
        "cs.SE",
        "cs.AI",
        "cs.CL"
      ],
      "primary_category": "cs.SE",
      "comment": "",
      "pdf_url": "https://arxiv.org/pdf/2512.12216v2",
      "published_date": "2025-12-13 07:02:28 UTC",
      "updated_date": "2026-01-11 10:24:25 UTC",
      "processing_status": "completed",
      "attempts": 1,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "llm_backup_calls": 0,
      "last_update": "2026-01-26T16:29:08.513140+00:00"
    },
    {
      "arxiv_id": "2512.13724v1",
      "title": "Graph AI generates neurological hypotheses validated in molecular, organoid, and clinical systems",
      "title_zh": "å›¾äººå·¥æ™ºèƒ½ç”Ÿæˆçš„ç¥ç»ç§‘å­¦å‡è®¾ç»åˆ†å­ã€ç±»å™¨å®˜åŠä¸´åºŠç³»ç»ŸéªŒè¯",
      "authors": [
        "Ayush Noori",
        "JoaquÃ­n Polonuer",
        "Katharina Meyer",
        "Bogdan Budnik",
        "Shad Morton",
        "Xinyuan Wang",
        "Sumaiya Nazeen",
        "Yingnan He",
        "IÃ±aki Arango",
        "Lucas Vittor",
        "Matthew Woodworth",
        "Richard C. Krolewski",
        "Michelle M. Li",
        "Ninning Liu",
        "Tushar Kamath",
        "Evan Macosko",
        "Dylan Ritter",
        "Jalwa Afroz",
        "Alexander B. H. Henderson",
        "Lorenz Studer",
        "Samuel G. Rodriques",
        "Andrew White",
        "Noa Dagan",
        "David A. Clifton",
        "George M. Church",
        "Sudeshna Das",
        "Jenny M. Tam",
        "Vikram Khurana",
        "Marinka Zitnik"
      ],
      "abstract": "Neurological diseases are the leading global cause of disability, yet most lack disease-modifying treatments. We present PROTON, a heterogeneous graph transformer that generates testable hypotheses across molecular, organoid, and clinical systems. To evaluate PROTON, we apply it to Parkinson's disease (PD), bipolar disorder (BD), and Alzheimer's disease (AD). In PD, PROTON linked genetic risk loci to genes essential for dopaminergic neuron survival and predicted pesticides toxic to patient-derived neurons, including the insecticide endosulfan, which ranked within the top 1.29% of predictions. In silico screens performed by PROTON reproduced six genome-wide $Î±$-synuclein experiments, including a split-ubiquitin yeast two-hybrid system (normalized enrichment score [NES] = 2.30, FDR-adjusted $p < 1 \\times 10^{-4}$), an ascorbate peroxidase proximity labeling assay (NES = 2.16, FDR $< 1 \\times 10^{-4}$), and a high-depth targeted exome sequencing study in 496 synucleinopathy patients (NES = 2.13, FDR $< 1 \\times 10^{-4}$). In BD, PROTON predicted calcitriol as a candidate drug that reversed proteomic alterations observed in cortical organoids derived from BD patients. In AD, we evaluated PROTON predictions in health records from $n = 610,524$ patients at Mass General Brigham, confirming that five PROTON-predicted drugs were associated with reduced seven-year dementia risk (minimum hazard ratio = 0.63, 95% CI: 0.53-0.75, $p < 1 \\times 10^{-7}$). PROTON generated neurological hypotheses that were evaluated across molecular, organoid, and clinical systems, defining a path for AI-driven discovery in neurological disease.",
      "tldr_zh": "è¯¥ç ”ç©¶æå‡ºäº† PROTONï¼Œä¸€ç§å¼‚æ„å›¾è½¬æ¢å™¨ (heterogeneous graph transformer)ï¼Œæ—¨åœ¨åˆ†å­ã€ç±»å™¨å®˜å’Œä¸´åºŠç³»ç»Ÿç­‰å¤šç»´åº¦ç”Ÿæˆå¯æµ‹è¯•çš„ç¥ç»ç³»ç»Ÿç–¾ç—…å‡è®¾ã€‚åœ¨ Parkinson's disease (PD) ç ”ç©¶ä¸­ï¼ŒPROTON æˆåŠŸå°†é—ä¼ é£é™©ä½ç‚¹ä¸å¤šå·´èƒºèƒ½ç¥ç»å…ƒç”Ÿå­˜çš„å…³é”®åŸºå› è”ç³»èµ·æ¥ï¼Œå¹¶å‡†ç¡®é¢„æµ‹äº†åŒ…æ‹¬ç¡«ä¸¹ (endosulfan) åœ¨å†…çš„ç¥ç»æ¯’æ€§å†œè¯ï¼ŒåŒæ—¶åœ¨è®¡ç®—æœºæ¨¡æ‹Ÿç­›é€‰ä¸­å¤ç°äº†å…­é¡¹å…¨åŸºå› ç»„ alpha-synuclein å®éªŒç»“æœã€‚é’ˆå¯¹ Bipolar disorder (BD)ï¼Œè¯¥æ¨¡å‹é¢„æµ‹éª¨åŒ–ä¸‰é†‡ (calcitriol) ä¸ºå€™é€‰è¯ç‰©ï¼Œå¹¶ç»å®éªŒè¯å®å…¶èƒ½é€†è½¬æ‚£è€…æºçš®å±‚ç±»å™¨å®˜çš„è›‹ç™½è´¨ç»„å¼‚å¸¸ã€‚åœ¨ Alzheimer's disease (AD) é¢†åŸŸï¼Œé€šè¿‡å¯¹ 610,524 åæ‚£è€…ä¸´åºŠè®°å½•çš„è¯„ä¼°ï¼Œè¯å®äº†å…¶é¢„æµ‹çš„äº”ç§è¯ç‰©ä¸ä¸ƒå¹´ç—´å‘†é£é™©é™ä½æ˜¾è‘—ç›¸å…³ã€‚è¿™é¡¹å·¥ä½œå±•ç¤ºäº† PROTON åœ¨è·¨ç³»ç»ŸéªŒè¯ç¥ç»ç§‘å­¦å‡è®¾æ–¹é¢çš„å¼ºå¤§èƒ½åŠ›ï¼Œä¸º AI é©±åŠ¨çš„ç¥ç»ç³»ç»Ÿç–¾ç—…æ²»ç–—å‘ç°å¼€è¾Ÿäº†æ–°è·¯å¾„ã€‚",
      "categories": [
        "q-bio.QM",
        "cs.AI",
        "q-bio.NC"
      ],
      "primary_category": "q-bio.QM",
      "comment": "",
      "pdf_url": "https://arxiv.org/pdf/2512.13724v1",
      "published_date": "2025-12-13 06:55:20 UTC",
      "updated_date": "2025-12-13 06:55:20 UTC",
      "processing_status": "completed",
      "attempts": 1,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "llm_backup_calls": 0,
      "last_update": "2026-01-26T16:29:31.638561+00:00"
    },
    {
      "arxiv_id": "2512.12211v1",
      "title": "Measuring What Matters: Scenario-Driven Evaluation for Trajectory Predictors in Autonomous Driving",
      "title_zh": "è¡¡é‡å…³é”®ï¼šè‡ªåŠ¨é©¾é©¶è½¨è¿¹é¢„æµ‹å™¨çš„åœºæ™¯é©±åŠ¨è¯„ä¼°",
      "authors": [
        "Longchao Da",
        "David Isele",
        "Hua Wei",
        "Manish Saroya"
      ],
      "abstract": "Being able to anticipate the motion of surrounding agents is essential for the safe operation of autonomous driving systems in dynamic situations. While various methods have been proposed for trajectory prediction, the current evaluation practices still rely on error-based metrics (e.g., ADE, FDE), which reveal the accuracy from a post-hoc view but ignore the actual effect the predictor brings to the self-driving vehicles (SDVs), especially in complex interactive scenarios: a high-quality predictor not only chases accuracy, but should also captures all possible directions a neighbor agent might move, to support the SDVs' cautious decision-making. Given that the existing metrics hardly account for this standard, in our work, we propose a comprehensive pipeline that adaptively evaluates the predictor's performance by two dimensions: accuracy and diversity. Based on the criticality of the driving scenario, these two dimensions are dynamically combined and result in a final score for the predictor's performance. Extensive experiments on a closed-loop benchmark using real-world datasets show that our pipeline yields a more reasonable evaluation than traditional metrics by better reflecting the correlation of the predictors' evaluation with the autonomous vehicles' driving performance. This evaluation pipeline shows a robust way to select a predictor that potentially contributes most to the SDV's driving performance.",
      "tldr_zh": "è¯¥ç ”ç©¶æŒ‡å‡ºï¼Œå½“å‰è‡ªåŠ¨é©¾é©¶ç³»ç»Ÿä¸­çš„è½¨è¿¹é¢„æµ‹è¯„ä¼°ä¸»è¦ä¾èµ–äº ADE å’Œ FDE ç­‰åŸºäºè¯¯å·®çš„æŒ‡æ ‡ï¼Œä½†è¿™å¿½ç•¥äº†é¢„æµ‹å™¨åœ¨å¤æ‚äº¤äº’åœºæ™¯ä¸­å¯¹è‡ªåŠ¨é©¾é©¶æ±½è½¦ (SDVs) å†³ç­–çš„å®é™…å½±å“ã€‚ä½œè€…è®¤ä¸ºé«˜è´¨é‡çš„é¢„æµ‹å™¨ä¸ä»…åº”è¿½æ±‚å‡†ç¡®æ€§ï¼Œè¿˜åº”å…·å¤‡å¤šæ ·æ€§ (diversity) ä»¥æ•æ‰æ™ºèƒ½ä½“æ‰€æœ‰å¯èƒ½çš„è¿åŠ¨æ–¹å‘ï¼Œä»è€Œæ”¯æŒ SDVs çš„è°¨æ…å†³ç­–ã€‚ä¸ºæ­¤ï¼Œæœ¬æ–‡æå‡ºäº†ä¸€ç§ç»¼åˆè¯„ä¼°æ¡†æ¶ï¼Œé€šè¿‡å‡†ç¡®æ€§ (accuracy) å’Œå¤šæ ·æ€§ä¸¤ä¸ªç»´åº¦ï¼Œå¹¶ç»“åˆé©¾é©¶åœºæ™¯çš„ç´§è¿«ç¨‹åº¦ (criticality) æ¥åŠ¨æ€è¯„ä¼°é¢„æµ‹å™¨æ€§èƒ½ã€‚åœ¨åŸºäºçœŸå®ä¸–ç•Œæ•°æ®é›†çš„é—­ç¯åŸºå‡†æµ‹è¯•ä¸­ï¼Œå®éªŒè¯æ˜è¯¥æµç¨‹æ¯”ä¼ ç»ŸæŒ‡æ ‡æ›´åˆç†åœ°åæ˜ äº†é¢„æµ‹å™¨è¯„ä¼°ä¸è‡ªåŠ¨é©¾é©¶è½¦è¾†å®é™…é©¾é©¶è¡¨ç°ä¹‹é—´çš„ç›¸å…³æ€§ã€‚è¯¥è¯„ä¼°æ¡†æ¶ä¸ºé€‰æ‹©èƒ½å¤Ÿæå‡ SDVs é©¾é©¶æ€§èƒ½çš„é¢„æµ‹å™¨æä¾›äº†ä¸€ç§é²æ£’çš„æ–¹æ³•ã€‚",
      "categories": [
        "cs.RO",
        "cs.AI",
        "eess.SY"
      ],
      "primary_category": "cs.RO",
      "comment": "9 Pages, 8 Figures",
      "pdf_url": "https://arxiv.org/pdf/2512.12211v1",
      "published_date": "2025-12-13 06:48:32 UTC",
      "updated_date": "2025-12-13 06:48:32 UTC",
      "processing_status": "completed",
      "attempts": 1,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "llm_backup_calls": 0,
      "last_update": "2026-01-26T16:29:41.501867+00:00"
    },
    {
      "arxiv_id": "2512.12207v1",
      "title": "Not All Transparency Is Equal: Source Presentation Effects on Attention, Interaction, and Persuasion in Conversational Search",
      "title_zh": "å¹¶éæ‰€æœ‰é€æ˜åº¦éƒ½ç­‰åŒï¼šå¯¹è¯å¼æœç´¢ä¸­æ¥æºå±•ç¤ºæ–¹å¼å¯¹æ³¨æ„åŠ›ã€äº¤äº’åŠè¯´æœæ•ˆæœçš„å½±å“",
      "authors": [
        "Jiangen He",
        "Jiqun Liu"
      ],
      "abstract": "Conversational search systems increasingly provide source citations, yet how citation or source presentation formats influence user engagement remains unclear. We conducted a crowdsourcing user experiment with 394 participants comparing four source presentation designs that varied citation visibility and accessibility: collapsible lists, hover cards, footer lists, and aligned sidebars.High-visibility interfaces generated substantially more hovering on sources, though clicking remained infrequent across all conditions. While interface design showed limited effects on user experience and perception measures, it significantly influenced knowledge, interest, and agreement changes. High-visibility interfaces initially reduced knowledge gain and interest, but these positive effects emerged with increasing source usage. The sidebar condition uniquely increased agreement change. Our findings demonstrate that source presentation alone may not enhance engagement and can even reduce it when insufficient sources are provided.",
      "tldr_zh": "è¯¥ç ”ç©¶æ¢è®¨äº†å¯¹è¯å¼æœç´¢(Conversational Search)ç³»ç»Ÿä¸­æ¥æºå¼•ç”¨(Source Citations)çš„å‘ˆç°æ–¹å¼å¯¹ç”¨æˆ·æ³¨æ„åŠ›ã€äº¤äº’å’Œè¯´æœæ•ˆæœçš„å½±å“ã€‚ç ”ç©¶é€šè¿‡æ‹›å‹Ÿ394åå‚ä¸è€…çš„ä¼—åŒ…å®éªŒï¼Œå¯¹æ¯”äº†æŠ˜å åˆ—è¡¨(Collapsible Lists)ã€æ‚¬åœå¡ç‰‡(Hover Cards)ã€é¡µè„šåˆ—è¡¨(Footer Lists)å’Œä¾§è¾¹æ (Aligned Sidebars)å››ç§å¯è§åº¦å’Œå¯è®¿é—®æ€§ä¸åŒçš„ç•Œé¢è®¾è®¡ã€‚å®éªŒç»“æœæ˜¾ç¤ºï¼Œé«˜å¯è§åº¦ç•Œé¢æ˜¾è‘—å¢åŠ äº†ç”¨æˆ·å¯¹æ¥æºçš„æ‚¬åœ(Hovering)è¡Œä¸ºï¼Œä½†å„ç»„çš„ç‚¹å‡»ç‡å‡è¾ƒä½ã€‚ç•Œé¢è®¾è®¡è™½ç„¶å¯¹ç”¨æˆ·ä½“éªŒå’Œæ„ŸçŸ¥æµ‹é‡çš„å½±å“æœ‰é™ï¼Œä½†æ˜¾è‘—å½±å“äº†çŸ¥è¯†è·å–ã€å…´è¶£å’Œåè®®å˜æ›´(Agreement Change)ã€‚ç ”ç©¶å‘ç°ï¼Œé«˜å¯è§åº¦ç•Œé¢æœ€åˆä¼šé™ä½çŸ¥è¯†å¢ç›Šå’Œå…´è¶£ï¼Œä½†éšç€æ¥æºä½¿ç”¨é¢‘ç‡çš„å¢åŠ ï¼Œå…¶æ­£é¢æ•ˆåº”å¼€å§‹æ˜¾ç°ã€‚ä¾§è¾¹æ è®¾è®¡åœ¨å¢åŠ åè®®å˜æ›´æ–¹é¢å…·æœ‰ç‹¬ç‰¹ä½œç”¨ï¼Œè¿™è¡¨æ˜å•çº¯çš„æ¥æºå‘ˆç°ä¸ä¸€å®šèƒ½å¢å¼ºç”¨æˆ·å‚ä¸åº¦ï¼Œåœ¨æ¥æºä¸è¶³çš„æƒ…å†µä¸‹ç”šè‡³å¯èƒ½äº§ç”Ÿè´Ÿé¢å½±å“ã€‚",
      "categories": [
        "cs.HC",
        "cs.AI",
        "cs.IR"
      ],
      "primary_category": "cs.HC",
      "comment": "CHIIR 2026",
      "pdf_url": "https://arxiv.org/pdf/2512.12207v1",
      "published_date": "2025-12-13 06:39:45 UTC",
      "updated_date": "2025-12-13 06:39:45 UTC",
      "processing_status": "completed",
      "attempts": 1,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "llm_backup_calls": 0,
      "last_update": "2026-01-26T16:29:45.046538+00:00"
    },
    {
      "arxiv_id": "2512.12206v1",
      "title": "ALERT Open Dataset and Input-Size-Agnostic Vision Transformer for Driver Activity Recognition using IR-UWB",
      "title_zh": "ALERT å¼€æ”¾æ•°æ®é›†ä¸ç”¨äº IR-UWB é©¾é©¶å‘˜æ´»åŠ¨è¯†åˆ«çš„è¾“å…¥å°ºå¯¸æ— å…³è§†è§‰ Transformer",
      "authors": [
        "Jeongjun Park",
        "Sunwook Hwang",
        "Hyeonho Noh",
        "Jin Mo Yang",
        "Hyun Jong Yang",
        "Saewoong Bahk"
      ],
      "abstract": "Distracted driving contributes to fatal crashes worldwide. To address this, researchers are using driver activity recognition (DAR) with impulse radio ultra-wideband (IR-UWB) radar, which offers advantages such as interference resistance, low power consumption, and privacy preservation. However, two challenges limit its adoption: the lack of large-scale real-world UWB datasets covering diverse distracted driving behaviors, and the difficulty of adapting fixed-input Vision Transformers (ViTs) to UWB radar data with non-standard dimensions.\n  This work addresses both challenges. We present the ALERT dataset, which contains 10,220 radar samples of seven distracted driving activities collected in real driving conditions. We also propose the input-size-agnostic Vision Transformer (ISA-ViT), a framework designed for radar-based DAR. The proposed method resizes UWB data to meet ViT input requirements while preserving radar-specific information such as Doppler shifts and phase characteristics. By adjusting patch configurations and leveraging pre-trained positional embedding vectors (PEVs), ISA-ViT overcomes the limitations of naive resizing approaches. In addition, a domain fusion strategy combines range- and frequency-domain features to further improve classification performance.\n  Comprehensive experiments demonstrate that ISA-ViT achieves a 22.68% accuracy improvement over an existing ViT-based approach for UWB-based DAR. By publicly releasing the ALERT dataset and detailing our input-size-agnostic strategy, this work facilitates the development of more robust and scalable distracted driving detection systems for real-world deployment.",
      "tldr_zh": "è¯¥ç ”ç©¶é’ˆå¯¹åˆ†å¿ƒé©¾é©¶è¯†åˆ«é¢†åŸŸç¼ºä¹å¤§è§„æ¨¡çœŸå®æ•°æ®é›†ä»¥åŠ Vision Transformer (ViT) æ¨¡å‹éš¾ä»¥é€‚é…éæ ‡å‡†ç»´åº¦é›·è¾¾æ•°æ®çš„é—®é¢˜ï¼Œæå‡ºäº†ä¸€ç§åŸºäºè„‰å†²æ— çº¿ç”µè¶…å®½å¸¦ (IR-UWB) é›·è¾¾çš„è§£å†³æ–¹æ¡ˆã€‚ä½œè€…é¦–å…ˆæ¨å‡ºäº† ALERT å¼€æºæ•°æ®é›†ï¼Œè¯¥æ•°æ®é›†åŒ…å«åœ¨çœŸå®é©¾é©¶æ¡ä»¶ä¸‹é‡‡é›†çš„ 10,220 ä¸ªé›·è¾¾æ ·æœ¬ï¼Œæ¶µç›–äº†ä¸ƒç§å¸¸è§çš„åˆ†å¿ƒé©¾é©¶è¡Œä¸ºã€‚ä¸ºäº†æœ‰æ•ˆå¤„ç†é›·è¾¾ä¿¡å·ï¼Œç ”ç©¶æå‡ºäº†ä¸€ç§è¾“å…¥å°ºå¯¸æ— å…³çš„è§†è§‰å˜æ¢å™¨ (Input-size-agnostic Vision Transformer, ISA-ViT) æ¡†æ¶ï¼Œè¯¥æ¡†æ¶é€šè¿‡è°ƒæ•´ Patch é…ç½®å¹¶åˆ©ç”¨é¢„è®­ç»ƒçš„ä½ç½®åµŒå…¥å‘é‡ (Positional Embedding Vectors, PEVs)ï¼Œåœ¨ç¼©æ”¾ UWB æ•°æ®ä»¥æ»¡è¶³æ¨¡å‹è¾“å…¥è¦æ±‚çš„åŒæ—¶ï¼ŒæˆåŠŸä¿ç•™äº†å¤šæ™®å‹’é¢‘ç§» (Doppler shifts) å’Œç›¸ä½ç‰¹æ€§ç­‰å…³é”®é›·è¾¾ä¿¡æ¯ã€‚æ­¤å¤–ï¼Œè¯¥æ¨¡å‹è¿˜å¼•å…¥äº†é¢†åŸŸèåˆç­–ç•¥ (Domain Fusion Strategy) æ¥ç»“åˆæ—¶åŸŸå’Œé¢‘åŸŸç‰¹å¾ï¼Œä»è€Œè¿›ä¸€æ­¥å¢å¼ºåˆ†ç±»èƒ½åŠ›ã€‚å®éªŒç»“æœæ˜¾ç¤ºï¼ŒISA-ViT åœ¨å‡†ç¡®ç‡ä¸Šæ¯”ç°æœ‰çš„åŸºäº ViT çš„è¯†åˆ«æ–¹æ³•æé«˜äº† 22.68%ã€‚è¯¥å·¥ä½œçš„å¼€æºæ•°æ®é›†å’ŒæŠ€æœ¯æ–¹æ¡ˆä¸ºå¼€å‘å¯ç”¨äºçœŸå®åœºæ™¯çš„ç¨³å¥é©¾é©¶å‘˜æ´»åŠ¨è¯†åˆ« (Driver Activity Recognition, DAR) ç³»ç»Ÿå¥ å®šäº†é‡è¦åŸºç¡€ã€‚",
      "categories": [
        "cs.CV",
        "cs.AI",
        "cs.LG"
      ],
      "primary_category": "cs.CV",
      "comment": "",
      "pdf_url": "https://arxiv.org/pdf/2512.12206v1",
      "published_date": "2025-12-13 06:33:02 UTC",
      "updated_date": "2025-12-13 06:33:02 UTC",
      "processing_status": "completed",
      "attempts": 1,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "llm_backup_calls": 0,
      "last_update": "2026-01-26T16:30:03.128094+00:00"
    },
    {
      "arxiv_id": "2512.12201v1",
      "title": "Epistemoverse: Toward an AI-Driven Knowledge Metaverse for Intellectual Heritage Preservation",
      "title_zh": "Epistemoverseï¼šè¿ˆå‘ç”¨äºæ€æƒ³é—äº§ä¿æŠ¤çš„äººå·¥æ™ºèƒ½é©±åŠ¨çŸ¥è¯†å…ƒå®‡å®™",
      "authors": [
        "Predrag K. NikoliÄ‡",
        "Robert Prentner"
      ],
      "abstract": "Large language models (LLMs) have often been characterized as \"stochastic parrots\" that merely reproduce fragments of their training data. This study challenges that assumption by demonstrating that, when placed in an appropriate dialogical context, LLMs can develop emergent conceptual structures and exhibit interaction-driven (re-)structuring of cognitive interfaces and reflective question-asking. Drawing on the biological principle of cloning and Socrates' maieutic method, we analyze authentic philosophical debates generated among AI-reincarnated philosophers within the interactive art installations of the Syntropic Counterpoints project. By engaging digital counterparts of Aristotle, Nietzsche, Machiavelli, and Sun Tzu in iterative discourse, the study reveals how machine dialogue can give rise to inferential coherence, reflective questioning, and creative synthesis. Based on these findings, we propose the concept of the Epistemoverse--a metaverse of knowledge where human and machine cognition intersect to preserve, reinterpret, and extend intellectual heritage through AI-driven interaction. This framework positions virtual and immersive environments as new spaces for epistemic exchange, digital heritage, and collaborative creativity.",
      "tldr_zh": "è¯¥ç ”ç©¶æŒ‘æˆ˜äº†å°†å¤§è¯­è¨€æ¨¡å‹(LLMs)ä»…è§†ä¸ºâ€œéšæœºé¹¦é¹‰â€(stochastic parrots)çš„è§‚ç‚¹ï¼Œè¯æ˜äº†åœ¨ç‰¹å®šå¯¹è¯è¯­å¢ƒä¸‹ï¼Œè¿™äº›æ¨¡å‹èƒ½å¤Ÿäº§ç”Ÿæ¶Œç°æ€§çš„æ¦‚å¿µç»“æ„å¹¶è¡¨ç°å‡ºäº’åŠ¨é©±åŠ¨çš„è®¤çŸ¥é‡æ„ã€‚ç ”ç©¶é€šè¿‡åˆ†æ Syntropic Counterpoints é¡¹ç›®ä¸­ç”± Aristotleã€Nietzsche ç­‰å“²å­¦å®¶çš„ AI åŒ–èº«è¿›è¡Œçš„å“²å­¦è¾©è®ºï¼Œæ­ç¤ºäº†æœºå™¨å¯¹è¯ä¸­å­˜åœ¨çš„æ¨ç†è¿è´¯æ€§ã€åæ€æ€§æé—®ä»¥åŠåˆ›é€ æ€§ç»¼åˆã€‚åŸºäºè¿™äº›å‘ç°ï¼Œè®ºæ–‡æå‡ºäº† Epistemoverse çš„æ¦‚å¿µï¼Œå³ä¸€ä¸ªäººç±»ä¸æœºå™¨è®¤çŸ¥ç›¸äº’äº¤æ±‡çš„äººå·¥æ™ºèƒ½é©±åŠ¨çŸ¥è¯†å…ƒå®‡å®™(knowledge metaverse)ã€‚è¯¥æ¡†æ¶æ—¨åœ¨é€šè¿‡ AI é©±åŠ¨çš„äº¤äº’æ¥ä¿æŠ¤ã€é‡æ–°è¯ é‡Šå¹¶æ‰©å±•æ™ºåŠ›é—äº§(intellectual heritage)ï¼Œä¸ºçŸ¥è¯†äº¤æ¢ã€æ•°å­—é—äº§å’Œåä½œåˆ›æ–°æä¾›å…¨æ–°çš„è™šæ‹Ÿæ²‰æµ¸å¼ç©ºé—´ã€‚è¿™ä¸€ç ”ç©¶ä¸ä»…é‡æ–°å®šä¹‰äº†æœºå™¨è®¤çŸ¥çš„æ½œåŠ›ï¼Œä¹Ÿä¸ºåœ¨äººå·¥æ™ºèƒ½æ—¶ä»£è¿›è¡Œæ–‡åŒ–ä¼ æ‰¿æä¾›äº†æ–°çš„æŠ€æœ¯èŒƒå¼ã€‚",
      "categories": [
        "cs.HC",
        "cs.AI"
      ],
      "primary_category": "cs.HC",
      "comment": "7 pages, 7 figures, presented at SIGGRAPH VRCAI 25",
      "pdf_url": "https://arxiv.org/pdf/2512.12201v1",
      "published_date": "2025-12-13 06:18:50 UTC",
      "updated_date": "2025-12-13 06:18:50 UTC",
      "processing_status": "completed",
      "attempts": 1,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "llm_backup_calls": 0,
      "last_update": "2026-01-26T16:30:07.404760+00:00"
    },
    {
      "arxiv_id": "2512.12199v1",
      "title": "Thermal RGB Fusion for Micro-UAV Wildfire Perimeter Tracking with Minimal Comms",
      "title_zh": "åŸºäºçƒ­çº¢å¤–-RGBèåˆçš„æä½é€šä¿¡å¾®å‹æ— äººæœºæ—ç«å‘¨ç•Œè·Ÿè¸ª",
      "authors": [
        "Ercan Erkalkan",
        "Vedat Topuz",
        "AyÃ§a Ak"
      ],
      "abstract": "This study introduces a lightweight perimeter tracking method designed for micro UAV teams operating over wildfire environments under limited bandwidth conditions. Thermal image frames generate coarse hot region masks through adaptive thresholding and morphological refinement, while RGB frames contribute edge cues and suppress texture related false detections using gradient based filtering. A rule level merging strategy selects boundary candidates and simplifies them via the Ramer Douglas Peucker algorithm. The system incorporates periodic beacons and an inertial feedback loop that maintains trajectory stability in the presence of GPS degradation. The guidance loop targets sub 50 ms latency on embedded System on Chip (SoC) platforms by constraining per frame pixel operations and precomputing gradient tables. Small scale simulations demonstrate reductions in average path length and boundary jitter compared to a pure edge tracking baseline, while maintaining environmental coverage measured through intersection merge analysis. Battery consumption and computational utilization confirm the feasibility of achieving 10, 15 m/s forward motion on standard micro platforms. This approach enables rapid deployment in the field, requiring robust sensing and minimal communications for emergency reconnaissance applications.",
      "tldr_zh": "è¯¥ç ”ç©¶æå‡ºäº†ä¸€ç§è½»é‡çº§çš„è¾¹ç•Œè·Ÿè¸ªæ–¹æ³•ï¼Œä¸“é—¨ç”¨äºå¾®å‹æ— äººæœº(micro-UAV)å›¢é˜Ÿåœ¨æœ‰é™å¸¦å®½æ¡ä»¶ä¸‹å¯¹æ—ç«(wildfire)è¾¹ç¼˜è¿›è¡Œé«˜æ•ˆç›‘æ§ã€‚è¯¥æ–¹æ³•åˆ©ç”¨ Thermal å›¾åƒé€šè¿‡è‡ªé€‚åº”é˜ˆå€¼å’Œå½¢æ€å­¦ç»†åŒ–ç”Ÿæˆç²—ç•¥çƒ­åŒºåŸŸæ©ç ï¼Œå¹¶ç»“åˆ RGB å›¾åƒçš„è¾¹ç¼˜çº¿ç´¢åŠæ¢¯åº¦æ»¤æ³¢æŠ€æœ¯ä»¥æŠ‘åˆ¶è™šå‡æ£€æµ‹ã€‚ç³»ç»Ÿé‡‡ç”¨è§„åˆ™çº§åˆå¹¶ç­–ç•¥ç­›é€‰è¾¹ç•Œå€™é€‰è€…ï¼Œå¹¶åˆ©ç”¨ Ramer-Douglas-Peucker ç®—æ³•ç®€åŒ–è½¨è¿¹ï¼ŒåŒæ—¶é€šè¿‡æƒ¯æ€§åé¦ˆå›è·¯ç¡®ä¿åœ¨ GPS é™çº§ç¯å¢ƒä¸‹çš„ç¨³å®šæ€§ã€‚é€šè¿‡ä¼˜åŒ–åƒç´ æ“ä½œå’Œé¢„è®¡ç®—æ¢¯åº¦è¡¨ï¼Œè¯¥æ–¹æ¡ˆåœ¨åµŒå…¥å¼ System-on-Chip (SoC) å¹³å°ä¸Šå®ç°äº†ä½äº 50ms çš„è¶…ä½å»¶è¿Ÿã€‚å®éªŒç»“æœè¡¨æ˜ï¼Œè¯¥æ–¹æ³•ç›¸æ¯”çº¯è¾¹ç¼˜è·Ÿè¸ªåŸºå‡†æ˜¾è‘—é™ä½äº†è·¯å¾„é•¿åº¦å’Œè¾¹ç•ŒæŠ–åŠ¨ï¼Œå¹¶éªŒè¯äº†åœ¨ 10-15 m/s é£è¡Œé€Ÿåº¦ä¸‹çš„è®¡ç®—å¯è¡Œæ€§ã€‚è¿™ä¸€æˆæœä¸ºé€šä¿¡å—é™ç¯å¢ƒä¸‹çš„ç´§æ€¥ä¾¦å¯Ÿä»»åŠ¡æä¾›äº†ä¸€ç§é²æ£’ä¸”é«˜æ•ˆçš„è‡ªä¸»å¯¼èˆªè§£å†³æ–¹æ¡ˆã€‚",
      "categories": [
        "cs.CV",
        "cs.AI"
      ],
      "primary_category": "cs.CV",
      "comment": "Conference paper in 17th International Scientific Studies Congress proceedings. Topic: thermal+RGB rule level fusion, RDP boundary simplification, leader follower guidance, sub 50ms embedded SoC, minimal communications for wildfire perimeter tracking. Thermal RGB Fusion for Micro-UAV",
      "pdf_url": "https://arxiv.org/pdf/2512.12199v1",
      "published_date": "2025-12-13 06:08:28 UTC",
      "updated_date": "2025-12-13 06:08:28 UTC",
      "processing_status": "completed",
      "attempts": 1,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "llm_backup_calls": 0,
      "last_update": "2026-01-26T16:30:07.851764+00:00"
    },
    {
      "arxiv_id": "2512.17941v1",
      "title": "Accelerated Digital Twin Learning for Edge AI: A Comparison of FPGA and Mobile GPU",
      "title_zh": "é¢å‘è¾¹ç¼˜ AI çš„æ•°å­—å­ªç”ŸåŠ é€Ÿå­¦ä¹ ï¼šFPGA ä¸ç§»åŠ¨ GPU çš„æ¯”è¾ƒ",
      "authors": [
        "Bin Xu",
        "Ayan Banerjee",
        "Midhat Urooj",
        "Sandeep K. S. Gupta"
      ],
      "abstract": "Digital twins (DTs) can enable precision healthcare by continually learning a mathematical representation of patient-specific dynamics. However, mission critical healthcare applications require fast, resource-efficient DT learning, which is often infeasible with existing model recovery (MR) techniques due to their reliance on iterative solvers and high compute/memory demands. In this paper, we present a general DT learning framework that is amenable to acceleration on reconfigurable hardware such as FPGAs, enabling substantial speedup and energy efficiency. We compare our FPGA-based implementation with a multi-processing implementation in mobile GPU, which is a popular choice for AI in edge devices. Further, we compare both edge AI implementations with cloud GPU baseline. Specifically, our FPGA implementation achieves an 8.8x improvement in \\text{performance-per-watt} for the MR task, a 28.5x reduction in DRAM footprint, and a 1.67x runtime speedup compared to cloud GPU baselines. On the other hand, mobile GPU achieves 2x better performance per watts but has 2x increase in runtime and 10x more DRAM footprint than FPGA. We show the usage of this technique in DT guided synthetic data generation for Type 1 Diabetes and proactive coronary artery disease detection.",
      "tldr_zh": "è¯¥ç ”ç©¶é’ˆå¯¹ç²¾å‡†åŒ»ç–—ä¸­æ•°å­—å­ªç”Ÿ(Digital Twins)å­¦ä¹ è¿‡ç¨‹é¢ä¸´çš„è®¡ç®—èµ„æºæ¶ˆè€—å¤§ã€æ¨¡å‹æ¢å¤(Model Recovery)æŠ€æœ¯ä¾èµ–è¿­ä»£æ±‚è§£å™¨ç­‰æŒ‘æˆ˜ï¼Œæå‡ºäº†ä¸€ç§ä¸“ä¸ºè¾¹ç¼˜äººå·¥æ™ºèƒ½(Edge AI)è®¾è®¡çš„é€šç”¨åŠ é€Ÿå­¦ä¹ æ¡†æ¶ã€‚è¯¥æ¡†æ¶æ”¯æŒåœ¨FPGAç­‰å¯é‡æ„ç¡¬ä»¶ä¸Šè¿è¡Œï¼Œé€šè¿‡å¯¹æ¯”FPGAã€ç§»åŠ¨ç«¯GPU(Mobile GPU)åŠäº‘ç«¯GPU(Cloud GPU)åŸºå‡†ï¼ŒéªŒè¯äº†å…¶åœ¨é€Ÿåº¦ä¸èƒ½æ•ˆä¸Šçš„æ˜¾è‘—ä¼˜åŠ¿ã€‚å®éªŒç»“æœæ˜¾ç¤ºï¼ŒFPGAå®ç°åœ¨æ¨¡å‹æ¢å¤ä»»åŠ¡ä¸­æ¯”äº‘ç«¯GPUåŸºå‡†æå‡äº†8.8å€çš„æ¯ç“¦æ€§èƒ½(performance-per-watt)ï¼ŒåŒæ—¶å°†DRAMå ç”¨é™ä½äº†28.5å€ï¼Œå¹¶å®ç°äº†1.67å€çš„è¿è¡ŒåŠ é€Ÿã€‚ç›¸æ¯”ä¹‹ä¸‹ï¼Œè™½ç„¶ç§»åŠ¨ç«¯GPUåœ¨èƒ½æ•ˆä¸Šä¼˜äºäº‘ç«¯æ–¹æ¡ˆï¼Œä½†åœ¨è¿è¡Œé€Ÿåº¦å’Œå†…å­˜è¶³è¿¹æ–¹é¢ä»é€Šè‰²äºFPGAã€‚æœ€åï¼Œç ”ç©¶é€šè¿‡1å‹ç³–å°¿ç—…åˆæˆæ•°æ®ç”Ÿæˆå’Œå† çŠ¶åŠ¨è„‰ç–¾ç—…ä¸»åŠ¨æ£€æµ‹ä¸¤ä¸ªæ¡ˆä¾‹ï¼Œå±•ç¤ºäº†è¯¥æŠ€æœ¯åœ¨å®æ—¶åŒ»ç–—ç›‘æµ‹ä¸è¯Šæ–­ä¸­çš„åº”ç”¨æ½œåŠ›ã€‚",
      "categories": [
        "cs.DC",
        "cs.AI"
      ],
      "primary_category": "cs.DC",
      "comment": "",
      "pdf_url": "https://arxiv.org/pdf/2512.17941v1",
      "published_date": "2025-12-13 05:51:26 UTC",
      "updated_date": "2025-12-13 05:51:26 UTC",
      "processing_status": "completed",
      "attempts": 1,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "llm_backup_calls": 0,
      "last_update": "2026-01-26T16:30:06.954160+00:00"
    },
    {
      "arxiv_id": "2512.12182v1",
      "title": "TA-KAND: Two-stage Attention Triple Enhancement and U-KAN based Diffusion For Few-shot Knowledge Graph Completion",
      "title_zh": "TA-KANDï¼šé¢å‘å°‘æ ·æœ¬çŸ¥è¯†å›¾è°±è¡¥å…¨çš„ä¸¤é˜¶æ®µæ³¨æ„åŠ›ä¸‰å…ƒç»„å¢å¼ºä¸åŸºäº U-KAN çš„æ‰©æ•£æ¨¡å‹",
      "authors": [
        "Xinyu Gao"
      ],
      "abstract": "Knowledge Graphs (KGs), thanks to their concise and efficient triple-based structure, have been widely applied in intelligent question answering, recommender systems and other domains. However, the heterogeneous and multifaceted nature of real-world data inevitably renders the distribution of relations long-tailed, making it crucial to complete missing facts with limited samples. Previous studies mainly based on metric matching or meta learning, yet they either fail to fully exploit neighborhood information in graph or overlook the distributional characteristics of contrastive signals. In this paper, we re-examine the problem from a perspective of generative representation and propose a few-shot knowledge graph completion framework that integrates two-stage attention triple enhancer with U-KAN based diffusion model. Extensive experiments on two public datasets show that our method achieve new state-of-the-art results.",
      "tldr_zh": "è¯¥ç ”ç©¶é’ˆå¯¹çŸ¥è¯†å›¾è°±(Knowledge Graphs)ä¸­å…³ç³»åˆ†å¸ƒçš„é•¿å°¾ç‰¹å¾ä»¥åŠå®é™…åº”ç”¨ä¸­æ ·æœ¬ç¨€ç¼ºçš„é—®é¢˜ï¼Œèšç„¦äºå°‘æ ·æœ¬çŸ¥è¯†å›¾è°±è¡¥å…¨(Few-shot Knowledge Graph Completion)ä»»åŠ¡ã€‚ä½œè€…æŒ‡å‡ºï¼Œç°æœ‰çš„åŸºäºåº¦é‡åŒ¹é…æˆ–å…ƒå­¦ä¹ çš„æ–¹æ³•éš¾ä»¥å……åˆ†æŒ–æ˜å›¾é‚»åŸŸä¿¡æ¯ï¼Œä¸”å¾€å¾€å¿½è§†äº†å¯¹æ¯”ä¿¡å·çš„åˆ†å¸ƒç‰¹æ€§ã€‚ä¸ºæ­¤ï¼Œæœ¬æ–‡æå‡ºäº†TA-KANDæ¡†æ¶ï¼Œè¯¥æ¡†æ¶å°†ä¸¤é˜¶æ®µæ³¨æ„åŠ›ä¸‰å…ƒç»„å¢å¼ºå™¨(two-stage attention triple enhancer)ä¸åŸºäºU-KANçš„æ‰©æ•£æ¨¡å‹(U-KAN based diffusion model)æœ‰æœºç»“åˆã€‚è¯¥æ–¹æ³•ä»ç”Ÿæˆå¼è¡¨ç¤ºçš„è§†è§’å‡ºå‘ï¼Œé€šè¿‡æ³¨æ„åŠ›æœºåˆ¶å’Œæ‰©æ•£æ¨¡å‹çš„ååŒä½œç”¨ï¼Œæ˜¾è‘—æå‡äº†æ¨¡å‹å¯¹ç¨€ç–å…³ç³»çš„è¡¨å¾èƒ½åŠ›ã€‚åœ¨ä¸¤ä¸ªå…¬å¼€æ•°æ®é›†ä¸Šçš„å®éªŒç»“æœæ˜¾ç¤ºï¼ŒTA-KANDåˆ·æ–°äº†å¤šé¡¹è¯„ä¼°æŒ‡æ ‡çš„çºªå½•ï¼Œè¾¾åˆ°äº†æ–°çš„æœ€ä¼˜æ€§èƒ½(state-of-the-art)ï¼Œè¯æ˜äº†å…¶åœ¨è§£å†³æå°‘æ ·æœ¬æƒ…å†µä¸‹çŸ¥è¯†ç¼ºå¤±é—®é¢˜çš„æœ‰æ•ˆæ€§ã€‚",
      "categories": [
        "cs.AI",
        "cs.LG"
      ],
      "primary_category": "cs.AI",
      "comment": "",
      "pdf_url": "https://arxiv.org/pdf/2512.12182v1",
      "published_date": "2025-12-13 05:04:59 UTC",
      "updated_date": "2025-12-13 05:04:59 UTC",
      "processing_status": "completed",
      "attempts": 1,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "llm_backup_calls": 0,
      "last_update": "2026-01-26T16:30:11.814885+00:00"
    },
    {
      "arxiv_id": "2512.12177v1",
      "title": "Floorplan2Guide: LLM-Guided Floorplan Parsing for BLV Indoor Navigation",
      "title_zh": "Floorplan2Guideï¼šé¢å‘ BLV å®¤å†…å¯¼èˆªçš„ LLM å¼•å¯¼å¼å¹³é¢å›¾è§£æ",
      "authors": [
        "Aydin Ayanzadeh",
        "Tim Oates"
      ],
      "abstract": "Indoor navigation remains a critical challenge for people with visual impairments. The current solutions mainly rely on infrastructure-based systems, which limit their ability to navigate safely in dynamic environments. We propose a novel navigation approach that utilizes a foundation model to transform floor plans into navigable knowledge graphs and generate human-readable navigation instructions. Floorplan2Guide integrates a large language model (LLM) to extract spatial information from architectural layouts, reducing the manual preprocessing required by earlier floorplan parsing methods. Experimental results indicate that few-shot learning improves navigation accuracy in comparison to zero-shot learning on simulated and real-world evaluations. Claude 3.7 Sonnet achieves the highest accuracy among the evaluated models, with 92.31%, 76.92%, and 61.54% on the short, medium, and long routes, respectively, under 5-shot prompting of the MP-1 floor plan. The success rate of graph-based spatial structure is 15.4% higher than that of direct visual reasoning among all models, which confirms that graphical representation and in-context learning enhance navigation performance and make our solution more precise for indoor navigation of Blind and Low Vision (BLV) users.",
      "tldr_zh": "è¯¥ç ”ç©¶æå‡ºäº†Floorplan2Guideï¼Œè¿™æ˜¯ä¸€ç§åˆ©ç”¨å¤§è¯­è¨€æ¨¡å‹ï¼ˆLLMï¼‰æŒ‡å¯¼æˆ·å‹å›¾è§£æçš„æ–°å‹å¯¼èˆªæ–¹æ¡ˆï¼Œä¸“é—¨ç”¨äºè¾…åŠ©ç›²äººåŠè§†éšœï¼ˆBLVï¼‰ç”¨æˆ·è¿›è¡Œå®¤å†…å¯¼èˆªã€‚è¯¥æ–¹æ³•åˆ©ç”¨åŸºç¡€æ¨¡å‹å°†å»ºç­‘å¹³é¢å›¾è½¬åŒ–ä¸ºå¯å¯¼èˆªçš„çŸ¥è¯†å›¾è°±ï¼ˆKnowledge Graphsï¼‰å¹¶ç”Ÿæˆäººç±»å¯è¯»çš„æŒ‡ä»¤ï¼Œæœ‰æ•ˆå‡å°‘äº†æ—©æœŸæˆ·å‹å›¾è§£ææ–¹æ³•ä¸­ç¹ççš„æ‰‹åŠ¨é¢„å¤„ç†ã€‚å®éªŒè¡¨æ˜ï¼Œfew-shot learningåœ¨æ¨¡æ‹Ÿå’ŒçœŸå®è¯„ä¼°ä¸­å‡æå‡äº†å¯¼èˆªå‡†ç¡®ç‡ï¼Œå…¶ä¸­Claude 3.7 Sonnetåœ¨MP-1å¹³é¢å›¾çš„å„é¡¹è·¯å¾„æµ‹è¯•ä¸­è¡¨ç°æœ€ä¸ºå‡ºè‰²ã€‚ç ”ç©¶è¯å®ï¼ŒåŸºäºå›¾çš„ç©ºé—´ç»“æ„æˆåŠŸç‡æ¯”ç›´æ¥è§†è§‰æ¨ç†é«˜å‡º15.4%ï¼Œè¿›ä¸€æ­¥éªŒè¯äº†å›¾å½¢è¡¨ç¤ºä¸è¯­å¢ƒå­¦ä¹ ï¼ˆIn-context learningï¼‰åœ¨å¢å¼ºå®¤å†…å¯¼èˆªç²¾å‡†æ€§æ–¹é¢çš„å…³é”®ä»·å€¼ã€‚",
      "categories": [
        "cs.AI"
      ],
      "primary_category": "cs.AI",
      "comment": "Accepted for publication in the proceedings of the IEEE International Conference on Big Data (IEEE BigData 2025)",
      "pdf_url": "https://arxiv.org/pdf/2512.12177v1",
      "published_date": "2025-12-13 04:49:26 UTC",
      "updated_date": "2025-12-13 04:49:26 UTC",
      "processing_status": "completed",
      "attempts": 1,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "llm_backup_calls": 0,
      "last_update": "2026-01-26T16:30:22.623310+00:00"
    },
    {
      "arxiv_id": "2512.12175v1",
      "title": "Rethinking Label Consistency of In-Context Learning: An Implicit Transductive Label Propagation Perspective",
      "title_zh": "é‡æ–°å®¡è§†ä¸Šä¸‹æ–‡å­¦ä¹ ä¸­çš„æ ‡ç­¾ä¸€è‡´æ€§ï¼šéšå¼ç›´æ¨æ ‡ç­¾ä¼ æ’­è§†è§’",
      "authors": [
        "Haoyang Chen",
        "Richong Zhang",
        "Junfan Chen"
      ],
      "abstract": "Large language models (LLMs) perform in-context learning (ICL) with minimal supervised examples, which benefits various natural language processing (NLP) tasks. One of the critical research focus is the selection of prompt demonstrations. Current approaches typically employ retrieval models to select the top-K most semantically similar examples as demonstrations. However, we argue that existing methods are limited since the label consistency is not guaranteed during demonstration selection. Our cognition derives from the Bayesian view of ICL and our rethinking of ICL from the transductive label propagation perspective. We treat ICL as a transductive learning method and incorporate latent concepts from Bayesian view and deduce that similar demonstrations guide the concepts of query, with consistent labels serving as estimates. Based on this understanding, we establish a label propagation framework to link label consistency with propagation error bounds. To model label consistency, we propose a data synthesis method, leveraging both semantic and label information, and use TopK sampling with Synthetic Data (TopK-SD) to acquire demonstrations with consistent labels. TopK-SD outperforms original TopK sampling on multiple benchmarks. Our work provides a new perspective for understanding the working mechanisms within ICL.",
      "tldr_zh": "è¯¥ç ”ç©¶æ¢è®¨äº†å¤§å‹è¯­è¨€æ¨¡å‹ï¼ˆLLMsï¼‰ä¸­In-Context Learning (ICL)çš„ç¤ºä¾‹é€‰æ‹©é—®é¢˜ï¼ŒæŒ‡å‡ºå½“å‰ä¸»æµçš„Top-Kè¯­ä¹‰ç›¸ä¼¼åº¦æ£€ç´¢æ–¹æ³•å¿½ç•¥äº†Label Consistencyçš„é‡è¦æ€§ã€‚ä½œè€…ä»Bayesianè§†è§’å‡ºå‘ï¼Œå°†ICLé‡æ–°å®¡è§†ä¸ºä¸€ä¸ªéšå¼çš„Transductive Label Propagationè¿‡ç¨‹ã€‚ç ”ç©¶æ¨å¯¼å¾—å‡ºï¼Œç›¸ä¼¼çš„ç¤ºä¾‹èƒ½å¤Ÿå¼•å¯¼æŸ¥è¯¢çš„æ½œåœ¨æ¦‚å¿µï¼Œè€Œä¸€è‡´çš„æ ‡ç­¾åˆ™ä½œä¸ºè¿™äº›æ¦‚å¿µçš„ä¼°è®¡å€¼ã€‚åŸºäºæ­¤ç†è§£ï¼Œç ”ç©¶å»ºç«‹äº†ä¸€ä¸ªæ ‡ç­¾ä¼ æ’­æ¡†æ¶ï¼Œå°†Label Consistencyä¸Propagation Error Boundsè”ç³»èµ·æ¥ã€‚ä¸ºæ­¤ï¼Œä½œè€…æå‡ºäº†ä¸€ç§ç»“åˆè¯­ä¹‰å’Œæ ‡ç­¾ä¿¡æ¯çš„æ•°æ®åˆæˆæ–¹æ³•ï¼Œå¹¶åˆ©ç”¨å¸¦æœ‰åˆæˆæ•°æ®çš„TopKé‡‡æ ·(TopK-SD)æ¥è·å–å…·å¤‡æ ‡ç­¾ä¸€è‡´æ€§çš„ç¤ºä¾‹ã€‚å®éªŒç»“æœè¡¨æ˜ï¼ŒTopK-SDåœ¨å¤šä¸ªåŸºå‡†æµ‹è¯•ä¸­ä¼˜äºåŸå§‹çš„TopKé‡‡æ ·ï¼Œä¸ºç†è§£ICLçš„å†…éƒ¨å·¥ä½œæœºåˆ¶æä¾›äº†å…¨æ–°çš„ç ”ç©¶è§†è§’ã€‚",
      "categories": [
        "cs.AI"
      ],
      "primary_category": "cs.AI",
      "comment": "",
      "pdf_url": "https://arxiv.org/pdf/2512.12175v1",
      "published_date": "2025-12-13 04:41:31 UTC",
      "updated_date": "2025-12-13 04:41:31 UTC",
      "processing_status": "completed",
      "attempts": 1,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "llm_backup_calls": 0,
      "last_update": "2026-01-26T16:30:26.176276+00:00"
    },
    {
      "arxiv_id": "2512.12168v1",
      "title": "Diffusion Language Model Inference with Monte Carlo Tree Search",
      "title_zh": "åŸºäºè’™ç‰¹å¡æ´›æ ‘æœç´¢çš„æ‰©æ•£è¯­è¨€æ¨¡å‹æ¨ç†",
      "authors": [
        "Zheng Huang",
        "Kiran Ramnath",
        "Yueyan Chen",
        "Aosong Feng",
        "Sangmin Woo",
        "Balasubramaniam Srinivasan",
        "Zhichao Xu",
        "Kang Zhou",
        "Shuai Wang",
        "Haibo Ding",
        "Lin Lee Cheong"
      ],
      "abstract": "Diffusion language models (DLMs) have recently emerged as a compelling alternative to autoregressive generation, offering parallel generation and improved global coherence. During inference, DLMs generate text by iteratively denoising masked sequences in parallel; however, determining which positions to unmask and which tokens to commit forms a large combinatorial search problem. Existing inference methods approximate this search using heuristics, which often yield suboptimal decoding paths; other approaches instead rely on additional training to guide token selection. To introduce a principled search mechanism for DLMs inference, we introduce MEDAL, a framework that integrates Monte Carlo Tree SEarch initialization for Diffusion LAnguage Model inference. We employ Monte Carlo Tree Search at the initialization stage to explore promising unmasking trajectories, providing a robust starting point for subsequent refinement. This integration is enabled by restricting the search space to high-confidence actions and prioritizing token choices that improve model confidence over remaining masked positions. Across multiple benchmarks, MEDAL achieves up to 22.0% improvement over existing inference strategies, establishing a new paradigm for search-based inference in diffusion language models.",
      "tldr_zh": "è¯¥ç ”ç©¶é’ˆå¯¹æ‰©æ•£è¯­è¨€æ¨¡å‹(Diffusion Language Models, DLMs)åœ¨æ¨ç†è¿‡ç¨‹ä¸­é¢ä¸´çš„å»æ©ç ä½ç½®é€‰æ‹©ä¸Tokenç¡®è®¤çš„å¤æ‚ç»„åˆæœç´¢é—®é¢˜ï¼Œæå‡ºäº†MEDALæ¡†æ¶ã€‚MEDALé€šè¿‡åœ¨æ¨ç†åˆå§‹åŒ–é˜¶æ®µå¼•å…¥è’™ç‰¹å¡æ´›æ ‘æœç´¢(Monte Carlo Tree Search, MCTS)æ¥æ¢ç´¢é«˜æ½œåŠ›çš„å»æ©ç è½¨è¿¹ï¼Œä»è€Œä¸ºç”Ÿæˆè¿‡ç¨‹æä¾›ç¨³å¥çš„èµ·ç‚¹ã€‚è¯¥æ¡†æ¶å°†æœç´¢ç©ºé—´é™åˆ¶åœ¨é«˜ç½®ä¿¡åº¦åŠ¨ä½œå†…ï¼Œå¹¶ä¼˜å…ˆé€‰æ‹©èƒ½æå‡æ¨¡å‹å¯¹å‰©ä½™æ©ç ä½ç½®ç½®ä¿¡åº¦çš„Tokenï¼Œå®ç°äº†æ›´å…·åŸåˆ™æ€§çš„æœç´¢æœºåˆ¶ã€‚å®éªŒè¯æ˜ï¼ŒMEDALåœ¨å¤šä¸ªåŸºå‡†æµ‹è¯•ä¸­ç›¸è¾ƒäºç°æœ‰æ¨ç†ç­–ç•¥å®ç°äº†æœ€é«˜22.0%çš„æ€§èƒ½æå‡ã€‚è¿™ä¸€æˆæœä¸ºDLMsä¸­åŸºäºæœç´¢çš„æ¨ç†å»ºç«‹äº†æ–°çš„èŒƒå¼ï¼Œåœ¨æ— éœ€é¢å¤–è®­ç»ƒçš„å‰æä¸‹æ˜¾è‘—ä¼˜åŒ–äº†ç”Ÿæˆè´¨é‡ã€‚",
      "categories": [
        "cs.CL",
        "cs.AI"
      ],
      "primary_category": "cs.CL",
      "comment": "",
      "pdf_url": "https://arxiv.org/pdf/2512.12168v1",
      "published_date": "2025-12-13 04:30:02 UTC",
      "updated_date": "2025-12-13 04:30:02 UTC",
      "processing_status": "completed",
      "attempts": 1,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "llm_backup_calls": 0,
      "last_update": "2026-01-26T16:30:27.191437+00:00"
    },
    {
      "arxiv_id": "2512.12167v1",
      "title": "Extending the Context of Pretrained LLMs by Dropping Their Positional Embeddings",
      "title_zh": "é€šè¿‡ç§»é™¤ä½ç½®åµŒå…¥æ‰©å±•é¢„è®­ç»ƒå¤§è¯­è¨€æ¨¡å‹çš„ä¸Šä¸‹æ–‡",
      "authors": [
        "Yoav Gelberg",
        "Koshi Eguchi",
        "Takuya Akiba",
        "Edoardo Cetin"
      ],
      "abstract": "So far, expensive finetuning beyond the pretraining sequence length has been a requirement for effectively extending the context of language models (LM). In this work, we break this key bottleneck by Dropping the Positional Embeddings of LMs after training (DroPE). Our simple method is motivated by three key theoretical and empirical observations. First, positional embeddings (PEs) serve a crucial role during pretraining, providing an important inductive bias that significantly facilitates convergence. Second, over-reliance on this explicit positional information is also precisely what prevents test-time generalization to sequences of unseen length, even when using popular PE-scaling methods. Third, positional embeddings are not an inherent requirement of effective language modeling and can be safely removed after pretraining, following a short recalibration phase. Empirically, DroPE yields seamless zero-shot context extension without any long-context finetuning, quickly adapting pretrained LMs without compromising their capabilities in the original training context. Our findings hold across different models and dataset sizes, far outperforming previous specialized architectures and established rotary positional embedding scaling methods.",
      "tldr_zh": "è¯¥ç ”ç©¶æå‡ºäº†DroPE (Dropping Positional Embeddings)ï¼Œè¿™æ˜¯ä¸€ç§é€šè¿‡åœ¨é¢„è®­ç»ƒåç§»é™¤ä½ç½®åµŒå…¥æ¥æ‰©å±•å¤§å‹è¯­è¨€æ¨¡å‹ (LLMs) ä¸Šä¸‹æ–‡é•¿åº¦çš„æ–°æ–¹æ³•ã€‚ç ”ç©¶è€…å‘ç°ï¼Œè™½ç„¶Positional Embeddingsåœ¨é¢„è®­ç»ƒé˜¶æ®µå¯¹ä¿ƒè¿›æ”¶æ•›è‡³å…³é‡è¦ï¼Œä½†å¯¹è¿™ç§æ˜¾å¼ä½ç½®ä¿¡æ¯çš„è¿‡åº¦ä¾èµ–æ­£æ˜¯é™åˆ¶æ¨¡å‹æ³›åŒ–è‡³è¶…é•¿åºåˆ—çš„ä¸»è¦ç“¶é¢ˆã€‚DroPEé€šè¿‡åœ¨é¢„è®­ç»ƒåèˆå¼ƒä½ç½®åµŒå…¥å¹¶è¾…ä»¥ç®€çŸ­çš„é‡æ ¡å‡† (recalibration phase)ï¼Œå®ç°äº†æ— ç¼çš„Zero-shotä¸Šä¸‹æ–‡æ‰©å±•ï¼Œå®Œå…¨æ— éœ€æ˜‚è´µçš„é•¿æ–‡æœ¬å¾®è°ƒ (long-context finetuning)ã€‚å®éªŒç»“æœè¡¨æ˜ï¼Œè¯¥æ–¹æ³•åœ¨å¤šç§æ¨¡å‹æ¶æ„å’Œæ•°æ®é›†è§„æ¨¡ä¸‹å‡æ˜¾è‘—ä¼˜äºç°æœ‰çš„æ—‹è½¬ä½ç½®åµŒå…¥ (rotary positional embedding) ç¼©æ”¾æŠ€æœ¯ã€‚æ­¤å¤–ï¼ŒDroPEåœ¨æ‰©å±•ä¸Šä¸‹æ–‡çš„åŒæ—¶ï¼Œä¾ç„¶èƒ½ä¿æŒæ¨¡å‹åœ¨åŸå§‹è®­ç»ƒé•¿åº¦ä¸‹çš„å›ºæœ‰èƒ½åŠ›ï¼Œä¸ºä½æˆæœ¬æå‡æ¨¡å‹å¤„ç†é•¿æ–‡æœ¬çš„æ•ˆç‡æä¾›äº†æœ‰æ•ˆé€”å¾„ã€‚",
      "categories": [
        "cs.CL",
        "cs.AI"
      ],
      "primary_category": "cs.CL",
      "comment": "",
      "pdf_url": "https://arxiv.org/pdf/2512.12167v1",
      "published_date": "2025-12-13 04:23:47 UTC",
      "updated_date": "2025-12-13 04:23:47 UTC",
      "processing_status": "completed",
      "attempts": 1,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "llm_backup_calls": 0,
      "last_update": "2026-01-26T16:30:39.191946+00:00"
    },
    {
      "arxiv_id": "2512.13723v1",
      "title": "Made-in China, Thinking in America:U.S. Values Persist in Chinese LLMs",
      "title_zh": "ä¸­å›½åˆ¶é€ ï¼Œç¾å›½æ€ç»´ï¼šç¾å›½ä»·å€¼è§‚åœ¨å›½äº§å¤§è¯­è¨€æ¨¡å‹ä¸­çš„æŒç»­å­˜åœ¨",
      "authors": [
        "David Haslett",
        "Linus Ta-Lun Huang",
        "Leila Khalatbari",
        "Janet Hui-wen Hsiao",
        "Antoni B. Chan"
      ],
      "abstract": "As large language models increasingly mediate access to information and facilitate decision-making, they are becoming instruments in soft power competitions between global actors such as the United States and China. So far, language models seem to be aligned with the values of Western countries, but evidence for this ethical bias comes mostly from models made by American companies. The current crop of state-of-the-art models includes several made in China, so we conducted the first large-scale investigation of how models made in China and the USA align with people from China and the USA. We elicited responses to the Moral Foundations Questionnaire 2.0 and the World Values Survey from ten Chinese models and ten American models, and we compared their responses to responses from thousands of Chinese and American people. We found that all models respond to both surveys more like American people than like Chinese people. This skew toward American values is only slightly mitigated when prompting the models in Chinese or imposing a Chinese persona on the models. These findings have important implications for a near future in which large language models generate much of the content people consume and shape normative influence in geopolitics.",
      "tldr_zh": "è¯¥ç ”ç©¶æ¢è®¨äº†å¤§è¯­è¨€æ¨¡å‹ (LLMs) åœ¨ä¸­ç¾è½¯å®åŠ›ç«äº‰ä¸­æ‰¿è½½ä»·å€¼è§‚çš„ä½œç”¨ï¼Œå¹¶å¯¹åä¸ªä¸­å›½æ¨¡å‹å’Œåä¸ªç¾å›½æ¨¡å‹è¿›è¡Œäº†å¤§è§„æ¨¡çš„ä»·å€¼è§‚å¯¹é½è°ƒæŸ¥ã€‚ç ”ç©¶äººå‘˜åˆ©ç”¨ Moral Foundations Questionnaire 2.0 å’Œ World Values Survey æ”¶é›†æ¨¡å‹å“åº”ï¼Œå¹¶å°†å…¶ä¸æ•°åƒåä¸­ç¾æ°‘ä¼—çš„çœŸå®æ•°æ®è¿›è¡Œå¯¹æ¯”ã€‚å®éªŒå‘ç°ï¼Œæ‰€æœ‰å‚ä¸æµ‹è¯•çš„æ¨¡å‹åœ¨è°ƒæŸ¥ä¸­è¡¨ç°å‡ºçš„å€¾å‘å‡æ›´æ¥è¿‘ç¾å›½æ°‘ä¼—ï¼Œè€Œéä¸­å›½æ°‘ä¼—ï¼Œæ˜¾ç¤ºå‡ºæ˜æ˜¾çš„ç¾å›½ä»·å€¼è§‚åå‘ã€‚å³ä½¿é€šè¿‡ä¸­æ–‡æç¤ºæˆ–è®¾å®šä¸­å›½äººçš„èº«ä»½ (Persona) æ¥å¼•å¯¼æ¨¡å‹ï¼Œè¿™ç§ä»·å€¼è§‚å¤±è¡¡ä¹Ÿä»…å¾—åˆ°è½»å¾®æ”¹å–„ã€‚è¿™äº›å‘ç°æ­ç¤ºäº†å½“å‰ Made-in China çš„æ¨¡å‹åœ¨åº•å±‚é€»è¾‘ä¸Šä»æ·±å—ç¾å›½ä»·å€¼è§‚å½±å“ï¼Œè¿™ä¸€ç°è±¡å¯¹äºæœªæ¥ LLMs é‡å¡‘å…¨çƒåœ°ç¼˜æ”¿æ²»ä¸­çš„è§„èŒƒæ€§å½±å“ (Normative influence) å…·æœ‰æ·±è¿œæ„ä¹‰ã€‚",
      "categories": [
        "cs.CY",
        "cs.AI"
      ],
      "primary_category": "cs.CY",
      "comment": "",
      "pdf_url": "https://arxiv.org/pdf/2512.13723v1",
      "published_date": "2025-12-13 02:52:57 UTC",
      "updated_date": "2025-12-13 02:52:57 UTC",
      "processing_status": "completed",
      "attempts": 1,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "llm_backup_calls": 0,
      "last_update": "2026-01-26T16:30:31.928481+00:00"
    },
    {
      "arxiv_id": "2512.12142v1",
      "title": "MeltwaterBench: Deep learning for spatiotemporal downscaling of surface meltwater",
      "title_zh": "MeltwaterBenchï¼šç”¨äºåœ°è¡¨èæ°´æ—¶ç©ºé™å°ºåº¦çš„æ·±åº¦å­¦ä¹ ",
      "authors": [
        "BjÃ¶rn LÃ¼tjens",
        "Patrick Alexander",
        "Raf Antwerpen",
        "Til Widmann",
        "Guido Cervone",
        "Marco Tedesco"
      ],
      "abstract": "The Greenland ice sheet is melting at an accelerated rate due to processes that are not fully understood and hard to measure. The distribution of surface meltwater can help understand these processes and is observable through remote sensing, but current maps of meltwater face a trade-off: They are either high-resolution in time or space, but not both. We develop a deep learning model that creates gridded surface meltwater maps at daily 100m resolution by fusing data streams from remote sensing observations and physics-based models. In particular, we spatiotemporally downscale regional climate model (RCM) outputs using synthetic aperture radar (SAR), passive microwave (PMW), and a digital elevation model (DEM) over the Helheim Glacier in Eastern Greenland from 2017-2023. Using SAR-derived meltwater as \"ground truth\", we show that a deep learning-based method that fuses all data streams is over 10 percentage points more accurate over our study area than existing non deep learning-based approaches that only rely on a regional climate model (83% vs. 95% Acc.) or passive microwave observations (72% vs. 95% Acc.). Alternatively, creating a gridded product through a running window calculation with SAR data underestimates extreme melt events, but also achieves notable accuracy (90%) and does not rely on deep learning. We evaluate standard deep learning methods (UNet and DeepLabv3+), and publish our spatiotemporally aligned dataset as a benchmark, MeltwaterBench, for intercomparisons with more complex data-driven downscaling methods. The code and data are available at $\\href{https://github.com/blutjens/hrmelt}{github.com/blutjens/hrmelt}$.",
      "tldr_zh": "è¯¥ç ”ç©¶å¼€å‘äº†æ·±åº¦å­¦ä¹ æ¨¡å‹ç”¨äºåœ°è¡¨èé›ªæ°´çš„æ—¶ç©ºå°ºåº¦ä¸‹æ”¾(spatiotemporal downscaling)ï¼Œæ—¨åœ¨è§£å†³æ ¼é™µå…°å†°ç›–èæ°´åˆ¶å›¾ä¸­æ—¶é—´å’Œç©ºé—´åˆ†è¾¨ç‡ä¸å¯å…¼å¾—çš„æƒè¡¡é—®é¢˜ã€‚è¯¥æ–¹æ³•é€šè¿‡èåˆåˆæˆå­”å¾„é›·è¾¾(SAR)ã€è¢«åŠ¨å¾®æ³¢(PMW)å’Œæ•°å­—é«˜ç¨‹æ¨¡å‹(DEM)ç­‰å¤šæºè§‚æµ‹æ•°æ®ï¼Œå¯¹åŒºåŸŸæ°”å€™æ¨¡å‹(RCM)çš„è¾“å‡ºè¿›è¡Œå¤„ç†ï¼ŒæˆåŠŸåœ¨æ ¼é™µå…°ä¸œéƒ¨çš„Helheim Glacierå®ç°äº†æ¯æ—¥100ç±³åˆ†è¾¨ç‡çš„ç½‘æ ¼åŒ–åˆ¶å›¾ã€‚å®éªŒç»“æœæ˜¾ç¤ºï¼Œè¿™ç§èåˆå¤šæºæ•°æ®çš„æ·±åº¦å­¦ä¹ æ–¹æ³•å‡†ç¡®ç‡è¾¾åˆ°95%ï¼Œæ˜¾è‘—ä¼˜äºä»…ä¾èµ–RCMæˆ–PMWçš„ä¼ ç»Ÿæ–¹æ³•ã€‚æ­¤å¤–ï¼Œç ”ç©¶å›¢é˜Ÿå‘å¸ƒäº†åä¸ºMeltwaterBenchçš„æ ‡å‡†åŒ–æ•°æ®é›†ï¼Œå¹¶å¯¹æ¯”è¯„ä¼°äº†UNetå’ŒDeepLabv3+ç­‰æ¨¡å‹ï¼Œä¸ºåç»­å¤æ‚çš„æ•°æ®é©±åŠ¨é™å°ºåº¦ç ”ç©¶æä¾›äº†åŸºå‡†ã€‚è¯¥é¡¹å·¥ä½œä¸ºç†è§£å†°ç›–èåŒ–è¿‡ç¨‹åŠæå‡æåœ°é¥æ„Ÿç›‘æµ‹ç²¾åº¦æä¾›äº†é‡è¦å·¥å…·ã€‚",
      "categories": [
        "cs.CV",
        "cs.AI",
        "cs.LG",
        "physics.ao-ph",
        "physics.data-an"
      ],
      "primary_category": "cs.CV",
      "comment": "",
      "pdf_url": "https://arxiv.org/pdf/2512.12142v1",
      "published_date": "2025-12-13 02:43:05 UTC",
      "updated_date": "2025-12-13 02:43:05 UTC",
      "processing_status": "completed",
      "attempts": 1,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "llm_backup_calls": 0,
      "last_update": "2026-01-26T16:30:52.696787+00:00"
    },
    {
      "arxiv_id": "2512.15771v2",
      "title": "TENG++: Time-Evolving Natural Gradient for Solving PDEs With Deep Neural Nets under General Boundary Conditions",
      "title_zh": "TENG++ï¼šé€šç”¨è¾¹ç•Œæ¡ä»¶ä¸‹åŸºäºæ·±åº¦ç¥ç»ç½‘ç»œæ±‚è§£åå¾®åˆ†æ–¹ç¨‹çš„æ—¶é—´æ¼”åŒ–è‡ªç„¶æ¢¯åº¦",
      "authors": [
        "Xinjie He",
        "Chenggong Zhang"
      ],
      "abstract": "Partial Differential Equations (PDEs) are central to modeling complex systems across physical, biological, and engineering domains, yet traditional numerical methods often struggle with high-dimensional or complex problems. Physics-Informed Neural Networks (PINNs) have emerged as an efficient alternative by embedding physics-based constraints into deep learning frameworks, but they face challenges in achieving high accuracy and handling complex boundary conditions. In this work, we extend the Time-Evolving Natural Gradient (TENG) framework to address Dirichlet boundary conditions, integrating natural gradient optimization with numerical time-stepping schemes, including Euler and Heun methods, to ensure both stability and accuracy. By incorporating boundary condition penalty terms into the loss function, the proposed approach enables precise enforcement of Dirichlet constraints. Experiments on the heat equation demonstrate the superior accuracy of the Heun method due to its second-order corrections and the computational efficiency of the Euler method for simpler scenarios. This work establishes a foundation for extending the framework to Neumann and mixed boundary conditions, as well as broader classes of PDEs, advancing the applicability of neural network-based solvers for real-world problems.",
      "tldr_zh": "è¯¥ç ”ç©¶æå‡ºäº† TENG++ æ¡†æ¶ï¼Œè¿™æ˜¯å¯¹ Time-Evolving Natural Gradient (TENG) æ–¹æ³•çš„æ‰©å±•ï¼Œæ—¨åœ¨åˆ©ç”¨æ·±åº¦ç¥ç»ç½‘ç»œè§£å†³å…·æœ‰ä¸€èˆ¬è¾¹ç•Œæ¡ä»¶çš„åå¾®åˆ†æ–¹ç¨‹ (PDEs)ã€‚è¯¥æ¡†æ¶å°†è‡ªç„¶æ¢¯åº¦ä¼˜åŒ– (Natural Gradient Optimization) ä¸æ•°å€¼æ—¶é—´æ­¥è¿›æ–¹æ¡ˆï¼ˆåŒ…æ‹¬ Euler å’Œ Heun æ–¹æ³•ï¼‰ç›¸ç»“åˆï¼Œé€šè¿‡åœ¨æŸå¤±å‡½æ•°ä¸­å¼•å…¥è¾¹ç•Œæ¡ä»¶æƒ©ç½šé¡¹ï¼Œå®ç°äº†å¯¹ Dirichlet è¾¹ç•Œæ¡ä»¶çš„ç²¾ç¡®çº¦æŸå’Œç¨³å®šæ±‚è§£ã€‚å®éªŒåœ¨çƒ­ä¼ å¯¼æ–¹ç¨‹ (Heat Equation) ä¸ŠéªŒè¯äº†è¯¥æ–¹æ³•çš„æœ‰æ•ˆæ€§ï¼Œç»“æœè¡¨æ˜ Heun æ–¹æ³•å‡­å€Ÿå…¶äºŒé˜¶ä¿®æ­£å±•ç°å‡ºå“è¶Šçš„ç²¾åº¦ï¼Œè€Œ Euler æ–¹æ³•åˆ™åœ¨ç®€å•åœºæ™¯ä¸­å…·æœ‰æ›´é«˜çš„è®¡ç®—æ•ˆç‡ã€‚è¯¥å·¥ä½œå…‹æœäº†ç‰©ç†ä¿¡æ¯ç¥ç»ç½‘ç»œ (PINNs) åœ¨å¤„ç†å¤æ‚è¾¹ç•Œæ¡ä»¶æ—¶ç²¾åº¦å—é™çš„é—®é¢˜ï¼Œå¹¶ä¸ºæœªæ¥æ‰©å±•åˆ° Neumann å’Œæ··åˆè¾¹ç•Œæ¡ä»¶å¥ å®šäº†åŸºç¡€ï¼Œæå‡äº†ç¥ç»ç½‘ç»œæ±‚è§£å™¨åœ¨ç°å®ç‰©ç†ã€ç”Ÿç‰©åŠå·¥ç¨‹å»ºæ¨¡ä¸­çš„é€‚ç”¨æ€§ã€‚",
      "categories": [
        "cs.LG",
        "cs.AI",
        "math.NA",
        "stat.ML"
      ],
      "primary_category": "cs.LG",
      "comment": "7 pages, 2 figures",
      "pdf_url": "https://arxiv.org/pdf/2512.15771v2",
      "published_date": "2025-12-13 02:32:45 UTC",
      "updated_date": "2025-12-27 00:18:22 UTC",
      "processing_status": "completed",
      "attempts": 1,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "llm_backup_calls": 0,
      "last_update": "2026-01-26T16:30:56.463769+00:00"
    },
    {
      "arxiv_id": "2512.12135v1",
      "title": "BaRISTA: Brain Scale Informed Spatiotemporal Representation of Human Intracranial Neural Activity",
      "title_zh": "BaRISTAï¼šåŸºäºè„‘å°ºåº¦ä¿¡æ¯çš„äººç±»é¢…å†…ç¥ç»æ´»åŠ¨æ—¶ç©ºè¡¨å¾",
      "authors": [
        "Lucine L. Oganesian",
        "Saba Hashemi",
        "Maryam M. Shanechi"
      ],
      "abstract": "Intracranial recordings have opened a unique opportunity to simultaneously measure activity across multiregional networks in the human brain. Recent works have focused on developing transformer-based neurofoundation models of such recordings that can generalize across subjects and datasets. However, these recordings exhibit highly complex spatiotemporal interactions across diverse spatial scales, from the single-channel scale to the scale of brain regions. As such, there remain critical open questions regarding how best to encode spatial information and how to design self-supervision tasks that enable the learning of brain network patterns and enhance downstream decoding performance using such high-dimensional, multiregional recordings. To allow for exploring these questions, we propose a new spatiotemporal transformer model of multiregional neural activity and a corresponding self-supervised masked latent reconstruction task, designed to enable flexibility in the spatial scale used for token encoding and masking. Applying this model on publicly available multiregional intracranial electrophysiology (iEEG) data, we demonstrate that adjusting the spatial scale for both token encoding and masked reconstruction significantly impacts downstream decoding. Further, we find that spatial encoding at larger scales than channel-level encoding, which is commonly used in existing iEEG transformer models, improves downstream decoding performance. Finally, we demonstrate that our method allows for region-level token encoding while also maintaining accurate channel-level neural reconstruction. Taken together, our modeling framework enables exploration of the spatial scales used for token encoding and masking, reveals their importance towards self-supervised pretraining of neurofoundation models of multiregional human brain activity, and enhances downstream decoding performance.",
      "tldr_zh": "è¯¥ç ”ç©¶æå‡ºäº† BaRISTAï¼Œä¸€ç§é’ˆå¯¹äººç±»å¤šåŒºåŸŸé¢…å†…ç¥ç»æ´»åŠ¨ï¼ˆIntracranial neural activityï¼‰è®¾è®¡çš„æ—¶ç©º Transformer æ¨¡å‹ï¼Œæ—¨åœ¨è§£å†³é«˜ç»´ iEEG è®°å½•ä¸­ç©ºé—´ä¿¡æ¯ç¼–ç ä¸è‡ªç›‘ç£å­¦ä¹ ä»»åŠ¡è®¾è®¡çš„æ ¸å¿ƒæŒ‘æˆ˜ã€‚è¯¥æ¡†æ¶å¼•å…¥äº†æ©ç æ½œå˜é‡é‡æ„ï¼ˆMasked latent reconstructionï¼‰ä»»åŠ¡ï¼Œæ”¯æŒåœ¨ä¸åŒç©ºé—´å°ºåº¦ä¸Šè¿›è¡Œ Token ç¼–ç ä¸æ©ç çš„çµæ´»é…ç½®ã€‚é€šè¿‡åœ¨å…¬å¼€ iEEG æ•°æ®é›†ä¸Šçš„åº”ç”¨ï¼Œç ”ç©¶è¯å®äº†è°ƒæ•´ Token ç¼–ç å’Œé‡æ„çš„ç©ºé—´å°ºåº¦å¯¹ä¸‹æ¸¸è§£ç ï¼ˆDownstream decodingï¼‰æ€§èƒ½æœ‰æ˜¾è‘—å½±å“ã€‚å®éªŒç»“æœè¡¨æ˜ï¼Œé‡‡ç”¨æ¯”ä¼ ç»Ÿé€šé“çº§ï¼ˆChannel-levelï¼‰æ›´å¹¿çš„ç©ºé—´ç¼–ç å°ºåº¦èƒ½æœ‰æ•ˆæå‡æ¨¡å‹è¡¨ç°ã€‚æ­¤å¤–ï¼ŒBaRISTA èƒ½å¤Ÿåœ¨å®ç°åŒºåŸŸçº§ï¼ˆRegion-levelï¼‰Token ç¼–ç çš„åŒæ—¶ï¼Œä¿æŒé«˜ç²¾åº¦çš„é€šé“çº§ç¥ç»ä¿¡å·é‡æ„ã€‚è¯¥ç ”ç©¶å¼ºè°ƒäº†ç©ºé—´å°ºåº¦åœ¨æ„å»ºå¤šåŒºåŸŸè„‘æ´»åŠ¨ç¥ç»åŸºç¡€æ¨¡å‹ï¼ˆNeurofoundation modelsï¼‰ä¸­çš„å…³é”®ä½œç”¨ï¼Œä¸ºæå‡ç¥ç»è§£ç æ€§èƒ½å’Œç†è§£å¤æ‚è„‘ç½‘ç»œæ¨¡å¼æä¾›äº†æ–°çš„å»ºæ¨¡æ¡†æ¶ã€‚",
      "categories": [
        "cs.LG",
        "cs.AI",
        "q-bio.NC"
      ],
      "primary_category": "cs.LG",
      "comment": "Published at the 39th Annual Conference on Neural Information Processing Systems (NeurIPS 2025). Code available at https://github.com/ShanechiLab/BaRISTA",
      "pdf_url": "https://arxiv.org/pdf/2512.12135v1",
      "published_date": "2025-12-13 02:19:33 UTC",
      "updated_date": "2025-12-13 02:19:33 UTC",
      "processing_status": "completed",
      "attempts": 1,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "llm_backup_calls": 0,
      "last_update": "2026-01-26T16:31:00.096057+00:00"
    },
    {
      "arxiv_id": "2512.12128v1",
      "title": "A Benchmark Dataset for Spatially Aligned Road Damage Assessment in Small Uncrewed Aerial Systems Disaster Imagery",
      "title_zh": "é¢å‘å°å‹æ— äººæœºç³»ç»Ÿç¾å®³å›¾åƒç©ºé—´å¯¹é½é“è·¯æŸæ¯è¯„ä¼°çš„åŸºå‡†æ•°æ®é›†",
      "authors": [
        "Thomas Manzini",
        "Priyankari Perali",
        "Raisa Karnik",
        "Robin R. Murphy"
      ],
      "abstract": "This paper presents the largest known benchmark dataset for road damage assessment and road alignment, and provides 18 baseline models trained on the CRASAR-U-DRIODs dataset's post-disaster small uncrewed aerial systems (sUAS) imagery from 10 federally declared disasters, addressing three challenges within prior post-disaster road damage assessment datasets. While prior disaster road damage assessment datasets exist, there is no current state of practice, as prior public datasets have either been small-scale or reliant on low-resolution imagery insufficient for detecting phenomena of interest to emergency managers. Further, while machine learning (ML) systems have been developed for this task previously, none are known to have been operationally validated. These limitations are overcome in this work through the labeling of 657.25km of roads according to a 10-class labeling schema, followed by training and deploying ML models during the operational response to Hurricanes Debby and Helene in 2024. Motivated by observed road line misalignment in practice, 9,184 road line adjustments were provided for spatial alignment of a priori road lines, as it was found that when the 18 baseline models are deployed against real-world misaligned road lines, model performance degraded on average by 5.596\\% Macro IoU. If spatial alignment is not considered, approximately 8\\% (11km) of adverse conditions on road lines will be labeled incorrectly, with approximately 9\\% (59km) of road lines misaligned off the actual road. These dynamics are gaps that should be addressed by the ML, CV, and robotics communities to enable more effective and informed decision-making during disasters.",
      "tldr_zh": "è¯¥ç ”ç©¶æ¨å‡ºäº†CRASAR-U-DRIODsï¼Œè¿™æ˜¯ç›®å‰å·²çŸ¥è§„æ¨¡æœ€å¤§çš„ç”¨äºé“è·¯æŸä¼¤è¯„ä¼°å’Œé“è·¯å¯¹é½(road alignment)çš„åŸºå‡†æ•°æ®é›†ï¼Œæ¶µç›–äº†10æ¬¡è”é‚¦çº§ç¾éš¾ä¸­çš„å°å‹æ— äººæœºç³»ç»Ÿ(sUAS)ç¾åå½±åƒã€‚ç ”ç©¶å›¢é˜Ÿä¾æ®10ç±»æ ‡æ³¨æ¨¡å¼å¯¹657.25å…¬é‡Œçš„é“è·¯è¿›è¡Œäº†æ ‡æ³¨ï¼Œå¹¶æä¾›äº†18ä¸ªåŸºå‡†æ¨¡å‹(baseline models)ï¼Œè¿™äº›æ¨¡å‹åœ¨2024å¹´é£“é£Debbyå’ŒHeleneçš„å®é™…å“åº”ä¸­ç»è¿‡äº†æ“ä½œéªŒè¯ã€‚é’ˆå¯¹å®é™…åº”ç”¨ä¸­çš„é“è·¯çº¿é”™ä½æŒ‘æˆ˜ï¼Œè¯¥ç ”ç©¶æä¾›äº†9,184æ¬¡ç©ºé—´å¯¹é½(spatial alignment)è°ƒæ•´ï¼Œæ­ç¤ºäº†å¿½è§†ç©ºé—´å¯¹é½ä¼šå¯¼è‡´æ¨¡å‹å¹³å‡Macro IoUä¸‹é™5.596%ã€‚å®éªŒè¡¨æ˜ï¼Œè‹¥ä¸è¿›è¡Œå¯¹é½å¤„ç†ï¼Œçº¦8%çš„é“è·¯å¼‚å¸¸æƒ…å†µä¼šè¢«è¯¯æ ‡ï¼Œä¸”çº¦9%çš„é“è·¯çº¿ä¼šä¸¥é‡åç¦»å®é™…è·¯é¢ã€‚è¯¥å·¥ä½œé€šè¿‡è§£å†³ä»¥å¾€æ•°æ®é›†è§„æ¨¡ä¸è¶³åŠä½åˆ†è¾¨ç‡ç­‰å±€é™æ€§ï¼Œå¼¥è¡¥äº†æœºå™¨å­¦ä¹ (ML)ä¸æœºå™¨äººç¤¾åŒºåœ¨ç¾éš¾å“åº”ä¸­çš„æŠ€æœ¯ç©ºç™½ï¼Œä¸ºæ›´æœ‰æ•ˆçš„å†³ç­–æä¾›äº†æ”¯æŒã€‚",
      "categories": [
        "cs.CV",
        "cs.AI"
      ],
      "primary_category": "cs.CV",
      "comment": "11 pages, 6 figures, 6 tables. To appear AAAI'26",
      "pdf_url": "https://arxiv.org/pdf/2512.12128v1",
      "published_date": "2025-12-13 01:42:49 UTC",
      "updated_date": "2025-12-13 01:42:49 UTC",
      "processing_status": "completed",
      "attempts": 1,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "llm_backup_calls": 0,
      "last_update": "2026-01-26T16:31:22.515175+00:00"
    },
    {
      "arxiv_id": "2512.12121v1",
      "title": "MixtureKit: A General Framework for Composing, Training, and Visualizing Mixture-of-Experts Models",
      "title_zh": "MixtureKitï¼šæ··åˆä¸“å®¶æ¨¡å‹æ„å»ºã€è®­ç»ƒä¸å¯è§†åŒ–çš„é€šç”¨æ¡†æ¶",
      "authors": [
        "Ahmad Chamma",
        "Omar El Herraoui",
        "Guokan Shang"
      ],
      "abstract": "We introduce MixtureKit, a modular open-source framework for constructing, training, and analyzing Mixture-of-Experts (MoE) models from arbitrary pre-trained or fine-tuned models. MixtureKit currently supports three complementary methods: (i) \\emph{Traditional MoE}, which uses a single router per transformer block to select experts, (ii) \\emph{BTX} (Branch-Train-Mix), which introduces separate routers for each specified sub-layer enabling fine-grained token routing, and (iii) \\emph{BTS} (Branch-Train-Stitch), which keeps experts fully intact and introduces trainable stitch layers for controlled information exchange between hub and experts. MixtureKit automatically modifies the model configuration, patches decoder and causal LM classes, and saves a unified checkpoint ready for inference or fine-tuning. We further provide a visualization interface to inspect per-token routing decisions, expert weight distributions, and layer-wise contributions. Experiments with multilingual code-switched data (e.g. Arabic-Latin) show that a BTX-based model trained using MixtureKit can outperform baseline dense models on multiple benchmarks. We release MixtureKit as a practical foundation for research and development of MoE-based systems across diverse domains.",
      "tldr_zh": "è¯¥ç ”ç©¶æ¨å‡ºäº† MixtureKitï¼Œè¿™æ˜¯ä¸€ä¸ªç”¨äºä»é¢„è®­ç»ƒæˆ–å¾®è°ƒæ¨¡å‹ä¸­æ„å»ºã€è®­ç»ƒå’Œåˆ†æ Mixture-of-Experts (MoE) æ¨¡å‹çš„æ¨¡å—åŒ–å¼€æºæ¡†æ¶ã€‚MixtureKit æ”¯æŒä¸‰ç§äº’è¡¥çš„æ„å»ºæ–¹æ³•ï¼ŒåŒ…æ‹¬ä½¿ç”¨å•ä¸€è·¯ç”±å™¨çš„ Traditional MoEã€å¼•å…¥å­å±‚çº§ç»†ç²’åº¦ä»¤ç‰Œè·¯ç”±çš„ BTX (Branch-Train-Mix) ä»¥åŠé‡‡ç”¨å¯è®­ç»ƒç¼åˆå±‚è¿›è¡Œä¿¡æ¯äº¤æ¢çš„ BTS (Branch-Train-Stitch)ã€‚è¯¥æ¡†æ¶èƒ½å¤Ÿè‡ªåŠ¨ä¿®æ”¹æ¨¡å‹é…ç½®å¹¶ç”Ÿæˆç»Ÿä¸€çš„æ£€æŸ¥ç‚¹ï¼ŒåŒæ—¶æä¾›å¯è§†åŒ–ç•Œé¢ä»¥ç›‘æ§ per-token è·¯ç”±å†³ç­–ã€ä¸“å®¶æƒé‡åˆ†å¸ƒåŠå±‚çº§è´¡çŒ®ã€‚åœ¨å¤šè¯­è¨€æ··æ‚ä»£ç æ•°æ®ä¸Šçš„å®éªŒè¯æ˜ï¼Œåˆ©ç”¨è¯¥æ¡†æ¶è®­ç»ƒçš„ BTX æ¨¡å‹åœ¨å¤šä¸ªåŸºå‡†æµ‹è¯•ä¸­æ€§èƒ½ä¼˜äºåŸºå‡†ç¨ å¯†æ¨¡å‹ã€‚MixtureKit ä¸ºä¸åŒé¢†åŸŸçš„ MoE ç³»ç»Ÿç ”ç©¶ä¸å¼€å‘æä¾›äº†å®ç”¨çš„åŸºç¡€æ¶æ„ã€‚",
      "categories": [
        "cs.LG",
        "cs.AI"
      ],
      "primary_category": "cs.LG",
      "comment": "",
      "pdf_url": "https://arxiv.org/pdf/2512.12121v1",
      "published_date": "2025-12-13 01:22:10 UTC",
      "updated_date": "2025-12-13 01:22:10 UTC",
      "processing_status": "completed",
      "attempts": 1,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "llm_backup_calls": 0,
      "last_update": "2026-01-26T16:31:05.944105+00:00"
    },
    {
      "arxiv_id": "2512.12109v2",
      "title": "A Neuro-Symbolic Framework for Accountability in Public-Sector AI",
      "title_zh": "ä¸€ç§é¢å‘å…¬å…±éƒ¨é—¨äººå·¥æ™ºèƒ½é—®è´£çš„ç¥ç»ç¬¦å·æ¡†æ¶",
      "authors": [
        "Allen Daniel Sunny"
      ],
      "abstract": "Automated eligibility systems increasingly determine access to essential public benefits, but the explanations they generate often fail to reflect the legal rules that authorize those decisions. This thesis develops a legally grounded explainability framework that links system-generated decision justifications to the statutory constraints of CalFresh, California's Supplemental Nutrition Assistance Program. The framework combines a structured ontology of eligibility requirements derived from the state's Manual of Policies and Procedures (MPP), a rule extraction pipeline that expresses statutory logic in a verifiable formal representation, and a solver-based reasoning layer to evaluate whether the explanation aligns with governing law. Case evaluations demonstrate the framework's ability to detect legally inconsistent explanations, highlight violated eligibility rules, and support procedural accountability by making the basis of automated determinations traceable and contestable.",
      "tldr_zh": "é’ˆå¯¹å…¬å…±éƒ¨é—¨AIè‡ªåŠ¨åŒ–å†³ç­–ç³»ç»Ÿç”Ÿæˆçš„è§£é‡Šå¾€å¾€æ— æ³•åæ˜ å…¶æ³•å®šä¾æ®çš„é—®é¢˜ï¼Œè¯¥ç ”ç©¶å¼€å‘äº†ä¸€ä¸ªå…·æœ‰æ³•å¾‹èƒŒæ™¯çš„å¯è§£é‡Šæ€§æ¡†æ¶ï¼Œæ—¨åœ¨å°†ç³»ç»Ÿç”Ÿæˆçš„å†³ç­–è¯æ˜ä¸ CalFreshï¼ˆåŠ å·è¡¥å……è¥å…»æ´åŠ©è®¡åˆ’ï¼‰çš„æ³•å®šçº¦æŸç›¸ç»“åˆã€‚è¯¥æ¡†æ¶æ•´åˆäº†æºè‡ªæ”¿ç­–ç¨‹åºæ‰‹å†Œ(MPP)çš„èµ„æ ¼è¦æ±‚ç»“æ„åŒ–æœ¬ä½“(structured ontology)ã€å°†æ³•å®šé€»è¾‘è½¬åŒ–ä¸ºå¯éªŒè¯å½¢å¼åŒ–è¡¨ç¤ºçš„è§„åˆ™æå–æµæ°´çº¿(rule extraction pipeline)ï¼Œä»¥åŠç”¨äºè¯„ä¼°è§£é‡Šæ˜¯å¦ç¬¦åˆç°è¡Œæ³•å¾‹çš„åŸºäºæ±‚è§£å™¨çš„æ¨ç†å±‚(solver-based reasoning layer)ã€‚æ¡ˆä¾‹è¯„ä¼°ç»“æœè¡¨æ˜ï¼Œè¯¥æ¡†æ¶èƒ½å¤Ÿæœ‰æ•ˆæ£€æµ‹æ³•å¾‹ä¸Šä¸ä¸€è‡´çš„è§£é‡Šï¼Œæ˜ç¡®æŒ‡å‡ºè¿åçš„èµ„æ ¼è§„åˆ™ï¼Œå¹¶é€šè¿‡ä½¿è‡ªåŠ¨åŒ–å†³ç­–è¿‡ç¨‹å…·å¤‡å¯è¿½æº¯æ€§å’Œå¯äº‰è¾©æ€§ï¼Œä»è€Œæ˜¾è‘—å¢å¼ºäº†å…¬å…±éƒ¨é—¨AIçš„ç¨‹åºæ€§é—®è´£(procedural accountability)ã€‚",
      "categories": [
        "cs.CY",
        "cs.AI",
        "cs.LO"
      ],
      "primary_category": "cs.CY",
      "comment": "Master's thesis, University of Maryland, College Park (2025)",
      "pdf_url": "https://arxiv.org/pdf/2512.12109v2",
      "published_date": "2025-12-13 00:53:26 UTC",
      "updated_date": "2025-12-16 22:41:53 UTC",
      "processing_status": "completed",
      "attempts": 1,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "llm_backup_calls": 0,
      "last_update": "2026-01-26T16:31:05.369224+00:00"
    }
  ],
  "processing_status": "completed",
  "error": null,
  "raw_papers_fetched": true,
  "papers_count": 56,
  "processed_papers_count": 56,
  "failed_papers_count": 0,
  "llm_backup_calls": 1,
  "summary_generated": true,
  "daily_data_saved": true,
  "last_update": "2026-01-26T16:32:38.469918+00:00"
}