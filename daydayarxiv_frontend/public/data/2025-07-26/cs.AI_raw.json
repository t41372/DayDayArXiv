[
  {
    "arxiv_id": "2507.20067v2",
    "title": "PITA: Preference-Guided Inference-Time Alignment for LLM Post-Training",
    "authors": [
      "Sarat Chandra Bobbili",
      "Ujwal Dinesha",
      "Dheeraj Narasimha",
      "Srinivas Shakkottai"
    ],
    "abstract": "Inference-time alignment enables large language models (LLMs) to generate outputs aligned with end-user preferences without further training. Recent post-training methods achieve this by using small guidance models to modify token generation during inference. These methods typically optimize a reward function KL-regularized by the original LLM taken as the reference policy. A critical limitation, however, is their dependence on a pre-trained reward model, which requires fitting to human preference feedback--a potentially unstable process. In contrast, we introduce PITA, a novel framework that integrates preference feedback directly into the LLM's token generation, eliminating the need for a reward model. PITA learns a small preference-based guidance policy to modify token probabilities at inference time without LLM fine-tuning, reducing computational cost and bypassing the pre-trained reward model dependency. The problem is framed as identifying an underlying preference distribution, solved through stochastic search and iterative refinement of the preference-based guidance model. We evaluate PITA across diverse tasks, including mathematical reasoning and sentiment classification, demonstrating its effectiveness in aligning LLM outputs with user preferences.",
    "categories": [
      "cs.AI",
      "cs.CL",
      "cs.LG"
    ],
    "primary_category": "cs.AI",
    "comment": "",
    "pdf_url": "https://arxiv.org/pdf/2507.20067v2",
    "published_date": "2025-07-26 21:46:32 UTC",
    "updated_date": "2025-11-13 17:05:21 UTC"
  },
  {
    "arxiv_id": "2507.20059v1",
    "title": "RAG in the Wild: On the (In)effectiveness of LLMs with Mixture-of-Knowledge Retrieval Augmentation",
    "authors": [
      "Ran Xu",
      "Yuchen Zhuang",
      "Yue Yu",
      "Haoyu Wang",
      "Wenqi Shi",
      "Carl Yang"
    ],
    "abstract": "Retrieval-augmented generation (RAG) enhances large language models (LLMs) by integrating external knowledge retrieved at inference time. While RAG demonstrates strong performance on benchmarks largely derived from general-domain corpora like Wikipedia, its effectiveness under realistic, diverse retrieval scenarios remains underexplored. We evaluated RAG systems using MassiveDS, a large-scale datastore with mixture of knowledge, and identified critical limitations: retrieval mainly benefits smaller models, rerankers add minimal value, and no single retrieval source consistently excels. Moreover, current LLMs struggle to route queries across heterogeneous knowledge sources. These findings highlight the need for adaptive retrieval strategies before deploying RAG in real-world settings. Our code and data can be found at https://github.com/ritaranx/RAG_in_the_Wild.",
    "categories": [
      "cs.CL",
      "cs.AI",
      "cs.LG"
    ],
    "primary_category": "cs.CL",
    "comment": "Work in Progress. Code will be published at: https://github.com/ritaranx/RAG_in_the_Wild",
    "pdf_url": "https://arxiv.org/pdf/2507.20059v1",
    "published_date": "2025-07-26 20:57:24 UTC",
    "updated_date": "2025-07-26 20:57:24 UTC"
  },
  {
    "arxiv_id": "2507.20056v1",
    "title": "FaRMamba: Frequency-based learning and Reconstruction aided Mamba for Medical Segmentation",
    "authors": [
      "Ze Rong",
      "ZiYue Zhao",
      "Zhaoxin Wang",
      "Lei Ma"
    ],
    "abstract": "Accurate medical image segmentation remains challenging due to blurred lesion boundaries (LBA), loss of high-frequency details (LHD), and difficulty in modeling long-range anatomical structures (DC-LRSS). Vision Mamba employs one-dimensional causal state-space recurrence to efficiently model global dependencies, thereby substantially mitigating DC-LRSS. However, its patch tokenization and 1D serialization disrupt local pixel adjacency and impose a low-pass filtering effect, resulting in Local High-frequency Information Capture Deficiency (LHICD) and two-dimensional Spatial Structure Degradation (2D-SSD), which in turn exacerbate LBA and LHD. In this work, we propose FaRMamba, a novel extension that explicitly addresses LHICD and 2D-SSD through two complementary modules. A Multi-Scale Frequency Transform Module (MSFM) restores attenuated high-frequency cues by isolating and reconstructing multi-band spectra via wavelet, cosine, and Fourier transforms. A Self-Supervised Reconstruction Auxiliary Encoder (SSRAE) enforces pixel-level reconstruction on the shared Mamba encoder to recover full 2D spatial correlations, enhancing both fine textures and global context. Extensive evaluations on CAMUS echocardiography, MRI-based Mouse-cochlea, and Kvasir-Seg endoscopy demonstrate that FaRMamba consistently outperforms competitive CNN-Transformer hybrids and existing Mamba variants, delivering superior boundary accuracy, detail preservation, and global coherence without prohibitive computational overhead. This work provides a flexible frequency-aware framework for future segmentation models that directly mitigates core challenges in medical imaging.",
    "categories": [
      "cs.CV",
      "cs.AI"
    ],
    "primary_category": "cs.CV",
    "comment": "",
    "pdf_url": "https://arxiv.org/pdf/2507.20056v1",
    "published_date": "2025-07-26 20:41:53 UTC",
    "updated_date": "2025-07-26 20:41:53 UTC"
  },
  {
    "arxiv_id": "2507.20048v2",
    "title": "Irredundant $k$-Fold Cross-Validation",
    "authors": [
      "Jesus S. Aguilar-Ruiz"
    ],
    "abstract": "In traditional k-fold cross-validation, each instance is used ($k-1$) times for training and once for testing, leading to redundancy that lets many instances disproportionately influence the learning phase. We introduce Irredundant $k$-fold cross-validation, a novel method that guarantees each instance is used exactly once for training and once for testing across the entire validation procedure. This approach ensures a more balanced utilization of the dataset, mitigates overfitting due to instance repetition, and enables sharper distinctions in comparative model analysis. The method preserves stratification and remains model-agnostic, i.e., compatible with any classifier. Experimental results demonstrate that it delivers consistent performance estimates across diverse datasets -- comparable to $k$-fold cross-validation -- while providing less optimistic variance estimates because training partitions are non-overlapping, and significantly reducing the overall computational cost.",
    "categories": [
      "cs.LG",
      "cs.AI",
      "stat.ME",
      "stat.ML"
    ],
    "primary_category": "cs.LG",
    "comment": "",
    "pdf_url": "https://arxiv.org/pdf/2507.20048v2",
    "published_date": "2025-07-26 19:59:37 UTC",
    "updated_date": "2025-08-27 18:16:13 UTC"
  },
  {
    "arxiv_id": "2508.00890v2",
    "title": "AgentTTS: Large Language Model Agent for Test-time Compute-optimal Scaling Strategy in Complex Tasks",
    "authors": [
      "Fali Wang",
      "Hui Liu",
      "Zhenwei Dai",
      "Jingying Zeng",
      "Zhiwei Zhang",
      "Zongyu Wu",
      "Chen Luo",
      "Zhen Li",
      "Xianfeng Tang",
      "Qi He",
      "Suhang Wang"
    ],
    "abstract": "Test-time scaling (TTS) enhances the performance of large language models (LLMs) by allocating additional compute resources during inference. However, existing research primarily investigates TTS in single-stage tasks; while many real-world problems are multi-stage complex tasks, composed of a sequence of heterogeneous subtasks with each subtask requires LLM of specific capability. Therefore, we study a novel problem: the test-time compute-optimal scaling in multi-stage complex tasks, aiming to select suitable models and allocate budgets per subtask to maximize overall performance. TTS in multi-stage tasks introduces two fundamental challenges: (i) The combinatorial search space of model and budget allocations, combined with the high cost of inference, makes brute-force search impractical. (ii) The optimal model and budget allocations across subtasks are interdependent, increasing the complexity of the compute-optimal search. To address this gap, we conduct extensive pilot experiments on four tasks across six datasets, deriving three empirical insights characterizing the behavior of LLMs in multi-stage complex tasks. Informed by these insights, we propose AgentTTS, an LLM-agent-based framework that autonomously searches for compute-optimal allocations through iterative feedback-driven interactions with the execution environment. Experimental results demonstrate that AgentTTS significantly outperforms traditional and other LLM-based baselines in search efficiency, and shows improved robustness to varying training set sizes and enhanced interpretability.",
    "categories": [
      "cs.AI",
      "cs.CL",
      "cs.LG"
    ],
    "primary_category": "cs.AI",
    "comment": "Accepted by NeurIPS 2025",
    "pdf_url": "https://arxiv.org/pdf/2508.00890v2",
    "published_date": "2025-07-26 19:21:18 UTC",
    "updated_date": "2025-10-21 20:46:43 UTC"
  },
  {
    "arxiv_id": "2508.00889v1",
    "title": "FECT: Factuality Evaluation of Interpretive AI-Generated Claims in Contact Center Conversation Transcripts",
    "authors": [
      "Hagyeong Shin",
      "Binoy Robin Dalal",
      "Iwona Bialynicka-Birula",
      "Navjot Matharu",
      "Ryan Muir",
      "Xingwei Yang",
      "Samuel W. K. Wong"
    ],
    "abstract": "Large language models (LLMs) are known to hallucinate, producing natural language outputs that are not grounded in the input, reference materials, or real-world knowledge. In enterprise applications where AI features support business decisions, such hallucinations can be particularly detrimental. LLMs that analyze and summarize contact center conversations introduce a unique set of challenges for factuality evaluation, because ground-truth labels often do not exist for analytical interpretations about sentiments captured in the conversation and root causes of the business problems. To remedy this, we first introduce a \\textbf{3D} -- \\textbf{Decompose, Decouple, Detach} -- paradigm in the human annotation guideline and the LLM-judges' prompt to ground the factuality labels in linguistically-informed evaluation criteria. We then introduce \\textbf{FECT}, a novel benchmark dataset for \\textbf{F}actuality \\textbf{E}valuation of Interpretive AI-Generated \\textbf{C}laims in Contact Center Conversation \\textbf{T}ranscripts, labeled under our 3D paradigm. Lastly, we report our findings from aligning LLM-judges on the 3D paradigm. Overall, our findings contribute a new approach for automatically evaluating the factuality of outputs generated by an AI system for analyzing contact center conversations.",
    "categories": [
      "cs.CL",
      "cs.AI",
      "cs.LG"
    ],
    "primary_category": "cs.CL",
    "comment": "Accepted for an oral presentation at Agentic & GenAI Evaluation KDD 2025: KDD workshop on Evaluation and Trustworthiness of Agentic and Generative AI Models",
    "pdf_url": "https://arxiv.org/pdf/2508.00889v1",
    "published_date": "2025-07-26 18:14:18 UTC",
    "updated_date": "2025-07-26 18:14:18 UTC"
  },
  {
    "arxiv_id": "2507.20028v1",
    "title": "TAPS : Frustratingly Simple Test Time Active Learning for VLMs",
    "authors": [
      "Dhruv Sarkar",
      "Aprameyo Chakrabartty",
      "Bibhudatta Bhanja"
    ],
    "abstract": "Test-Time Optimization enables models to adapt to new data during inference by updating parameters on-the-fly. Recent advances in Vision-Language Models (VLMs) have explored learning prompts at test time to improve performance in downstream tasks. In this work, we extend this idea by addressing a more general and practical challenge: Can we effectively utilize an oracle in a continuous data stream where only one sample is available at a time, requiring an immediate query decision while respecting latency and memory constraints? To tackle this, we propose a novel Test-Time Active Learning (TTAL) framework that adaptively queries uncertain samples and updates prompts dynamically. Unlike prior methods that assume batched data or multiple gradient updates, our approach operates in a real-time streaming scenario with a single test sample per step. We introduce a dynamically adjusted entropy threshold for active querying, a class-balanced replacement strategy for memory efficiency, and a class-aware distribution alignment technique to enhance adaptation. The design choices are justified using careful theoretical analysis. Extensive experiments across 10 cross-dataset transfer benchmarks and 4 domain generalization datasets demonstrate consistent improvements over state-of-the-art methods while maintaining reasonable latency and memory overhead. Our framework provides a practical and effective solution for real-world deployment in safety-critical applications such as autonomous systems and medical diagnostics.",
    "categories": [
      "cs.CV",
      "cs.AI"
    ],
    "primary_category": "cs.CV",
    "comment": "",
    "pdf_url": "https://arxiv.org/pdf/2507.20028v1",
    "published_date": "2025-07-26 18:04:49 UTC",
    "updated_date": "2025-07-26 18:04:49 UTC"
  },
  {
    "arxiv_id": "2507.20021v2",
    "title": "When Engineering Outruns Intelligence: Rethinking Instruction-Guided Navigation",
    "authors": [
      "Matin Aghaei",
      "Lingfeng Zhang",
      "Mohammad Ali Alomrani",
      "Mahdi Biparva",
      "Yingxue Zhang"
    ],
    "abstract": "Recent ObjectNav systems credit large language models (LLMs) for sizable zero-shot gains, yet it remains unclear how much comes from language versus geometry. We revisit this question by re-evaluating an instruction-guided pipeline, InstructNav, under a detector-controlled setting and introducing two training-free variants that only alter the action value map: a geometry-only Frontier Proximity Explorer (FPE) and a lightweight Semantic-Heuristic Frontier (SHF) that polls the LLM with simple frontier votes. Across HM3D and MP3D, FPE matches or exceeds the detector-controlled instruction follower while using no API calls and running faster; SHF attains comparable accuracy with a smaller, localized language prior. These results suggest that carefully engineered frontier geometry accounts for much of the reported progress, and that language is most reliable as a light heuristic rather than an end-to-end planner.",
    "categories": [
      "cs.RO",
      "cs.AI",
      "cs.LG"
    ],
    "primary_category": "cs.RO",
    "comment": "Preprint; under peer review",
    "pdf_url": "https://arxiv.org/pdf/2507.20021v2",
    "published_date": "2025-07-26 17:37:15 UTC",
    "updated_date": "2025-09-27 04:20:25 UTC"
  },
  {
    "arxiv_id": "2508.02697v1",
    "title": "Planning with Dynamically Changing Domains",
    "authors": [
      "Mikhail Soutchanski",
      "Yongmei Liu"
    ],
    "abstract": "In classical planning and conformant planning, it is assumed that there are finitely many named objects given in advance, and only they can participate in actions and in fluents. This is the Domain Closure Assumption (DCA). However, there are practical planning problems where the set of objects changes dynamically as actions are performed; e.g., new objects can be created, old objects can be destroyed. We formulate the planning problem in first-order logic, assume an initial theory is a finite consistent set of fluent literals, discuss when this guarantees that in every situation there are only finitely many possible actions, impose a finite integer bound on the length of the plan, and propose to organize search over sequences of actions that are grounded at planning time. We show the soundness and completeness of our approach. It can be used to solve the bounded planning problems without DCA that belong to the intersection of sequential generalized planning (without sensing actions) and conformant planning, restricted to the case without the disjunction over fluent literals. We discuss a proof-of-the-concept implementation of our planner.",
    "categories": [
      "cs.AI",
      "cs.CE"
    ],
    "primary_category": "cs.AI",
    "comment": "A revised version of the paper accepted to the 1st International Workshop on Trends in Knowledge Representation and Reasoning organized as a IJCAI 2025 workshop that takes place in August 2025 in Montreal, Canada. See the details at https://tkr2025.krportal.org/programme.html",
    "pdf_url": "https://arxiv.org/pdf/2508.02697v1",
    "published_date": "2025-07-26 17:34:25 UTC",
    "updated_date": "2025-07-26 17:34:25 UTC"
  },
  {
    "arxiv_id": "2507.22082v1",
    "title": "Shape Invariant 3D-Variational Autoencoder: Super Resolution in Turbulence flow",
    "authors": [
      "Anuraj Maurya"
    ],
    "abstract": "Deep learning provides a versatile suite of methods for extracting structured information from complex datasets, enabling deeper understanding of underlying fluid dynamic phenomena. The field of turbulence modeling, in particular, benefits from the growing availability of high-dimensional data obtained through experiments, field observations, and large-scale simulations spanning multiple spatio-temporal scales. This report presents a concise overview of both classical and deep learningbased approaches to turbulence modeling. It further investigates two specific challenges at the intersection of fluid dynamics and machine learning: the integration of multiscale turbulence models with deep learning architectures, and the application of deep generative models for super-resolution reconstruction",
    "categories": [
      "cs.LG",
      "cs.AI",
      "physics.flu-dyn"
    ],
    "primary_category": "cs.LG",
    "comment": "",
    "pdf_url": "https://arxiv.org/pdf/2507.22082v1",
    "published_date": "2025-07-26 17:28:39 UTC",
    "updated_date": "2025-07-26 17:28:39 UTC"
  },
  {
    "arxiv_id": "2507.20019v1",
    "title": "Anomaly Detection in Human Language via Meta-Learning: A Few-Shot Approach",
    "authors": [
      "Saurav Singla",
      "Aarav Singla",
      "Advik Gupta",
      "Parnika Gupta"
    ],
    "abstract": "We propose a meta learning framework for detecting anomalies in human language across diverse domains with limited labeled data. Anomalies in language ranging from spam and fake news to hate speech pose a major challenge due to their sparsity and variability. We treat anomaly detection as a few shot binary classification problem and leverage meta-learning to train models that generalize across tasks. Using datasets from domains such as SMS spam, COVID-19 fake news, and hate speech, we evaluate model generalization on unseen tasks with minimal labeled anomalies. Our method combines episodic training with prototypical networks and domain resampling to adapt quickly to new anomaly detection tasks. Empirical results show that our method outperforms strong baselines in F1 and AUC scores. We also release the code and benchmarks to facilitate further research in few-shot text anomaly detection.",
    "categories": [
      "cs.CL",
      "cs.AI"
    ],
    "primary_category": "cs.CL",
    "comment": "15 pages. PyTorch code for few-shot anomaly detection using meta-learning is available upon request or can be shared via GitHub",
    "pdf_url": "https://arxiv.org/pdf/2507.20019v1",
    "published_date": "2025-07-26 17:23:03 UTC",
    "updated_date": "2025-07-26 17:23:03 UTC"
  },
  {
    "arxiv_id": "2507.20018v2",
    "title": "The Carbon Cost of Conversation, Sustainability in the Age of Language Models",
    "authors": [
      "Sayed Mahbub Hasan Amiri",
      "Prasun Goswami",
      "Md. Mainul Islam",
      "Mohammad Shakhawat Hossen",
      "Sayed Majhab Hasan Amiri",
      "Naznin Akter"
    ],
    "abstract": "Large language models (LLMs) like GPT-3 and BERT have revolutionized natural language processing (NLP), yet their environmental costs remain dangerously overlooked. This article critiques the sustainability of LLMs, quantifying their carbon footprint, water usage, and contribution to e-waste through case studies of models such as GPT-4 and energy-efficient alternatives like Mistral 7B. Training a single LLM can emit carbon dioxide equivalent to hundreds of cars driven annually, while data centre cooling exacerbates water scarcity in vulnerable regions. Systemic challenges corporate greenwashing, redundant model development, and regulatory voids perpetuate harm, disproportionately burdening marginalized communities in the Global South. However, pathways exist for sustainable NLP: technical innovations (e.g., model pruning, quantum computing), policy reforms (carbon taxes, mandatory emissions reporting), and cultural shifts prioritizing necessity over novelty. By analysing industry leaders (Google, Microsoft) and laggards (Amazon), this work underscores the urgency of ethical accountability and global cooperation. Without immediate action, AIs ecological toll risks outpacing its societal benefits. The article concludes with a call to align technological progress with planetary boundaries, advocating for equitable, transparent, and regenerative AI systems that prioritize both human and environmental well-being.",
    "categories": [
      "cs.CY",
      "cs.AI",
      "cs.CL"
    ],
    "primary_category": "cs.CY",
    "comment": "22 Pages, 5 Tables",
    "pdf_url": "https://arxiv.org/pdf/2507.20018v2",
    "published_date": "2025-07-26 17:21:11 UTC",
    "updated_date": "2025-07-29 05:18:46 UTC"
  },
  {
    "arxiv_id": "2507.20016v1",
    "title": "FedSWA: Improving Generalization in Federated Learning with Highly Heterogeneous Data via Momentum-Based Stochastic Controlled Weight Averaging",
    "authors": [
      "Liu junkang",
      "Yuanyuan Liu",
      "Fanhua Shang",
      "Hongying Liu",
      "Jin Liu",
      "Wei Feng"
    ],
    "abstract": "For federated learning (FL) algorithms such as FedSAM, their generalization capability is crucial for real-word applications. In this paper, we revisit the generalization problem in FL and investigate the impact of data heterogeneity on FL generalization. We find that FedSAM usually performs worse than FedAvg in the case of highly heterogeneous data, and thus propose a novel and effective federated learning algorithm with Stochastic Weight Averaging (called \\texttt{FedSWA}), which aims to find flatter minima in the setting of highly heterogeneous data. Moreover, we introduce a new momentum-based stochastic controlled weight averaging FL algorithm (\\texttt{FedMoSWA}), which is designed to better align local and global models.\n  Theoretically, we provide both convergence analysis and generalization bounds for \\texttt{FedSWA} and \\texttt{FedMoSWA}. We also prove that the optimization and generalization errors of \\texttt{FedMoSWA} are smaller than those of their counterparts, including FedSAM and its variants. Empirically, experimental results on CIFAR10/100 and Tiny ImageNet demonstrate the superiority of the proposed algorithms compared to their counterparts. Open source code at: https://github.com/junkangLiu0/FedSWA.",
    "categories": [
      "cs.LG",
      "cs.AI"
    ],
    "primary_category": "cs.LG",
    "comment": "icml 2025",
    "pdf_url": "https://arxiv.org/pdf/2507.20016v1",
    "published_date": "2025-07-26 17:12:40 UTC",
    "updated_date": "2025-07-26 17:12:40 UTC"
  },
  {
    "arxiv_id": "2507.20014v2",
    "title": "Policy-Driven AI in Dataspaces: Taxonomy, Explainability, and Pathways for Compliant Innovation",
    "authors": [
      "Joydeep Chandra",
      "Satyam Kumar Navneet"
    ],
    "abstract": "As AI-driven dataspaces become integral to data sharing and collaborative analytics, ensuring privacy, performance, and policy compliance presents significant challenges. This paper provides a comprehensive review of privacy-preserving and policy-aware AI techniques, including Federated Learning, Differential Privacy, Trusted Execution Environments, Homomorphic Encryption, and Secure Multi-Party Computation, alongside strategies for aligning AI with regulatory frameworks such as GDPR and the EU AI Act. We propose a novel taxonomy to classify these techniques based on privacy levels, performance impacts, and compliance complexity, offering a clear framework for practitioners and researchers to navigate trade-offs. Key performance metrics -- latency, throughput, cost overhead, model utility, fairness, and explainability -- are analyzed to highlight the multi-dimensional optimization required in dataspaces. The paper identifies critical research gaps, including the lack of standardized privacy-performance KPIs, challenges in explainable AI for federated ecosystems, and semantic policy enforcement amidst regulatory fragmentation. Future directions are outlined, proposing a conceptual framework for policy-driven alignment, automated compliance validation, standardized benchmarking, and integration with European initiatives like GAIA-X, IDS, and Eclipse EDC. By synthesizing technical, ethical, and regulatory perspectives, this work lays the groundwork for developing trustworthy, efficient, and compliant AI systems in dataspaces, fostering innovation in secure and responsible data-driven ecosystems.",
    "categories": [
      "cs.CR",
      "cs.AI"
    ],
    "primary_category": "cs.CR",
    "comment": "",
    "pdf_url": "https://arxiv.org/pdf/2507.20014v2",
    "published_date": "2025-07-26 17:07:01 UTC",
    "updated_date": "2025-07-30 08:46:55 UTC"
  },
  {
    "arxiv_id": "2507.20010v1",
    "title": "Finding Personalized Good-Enough Solutions to Unsatisfiable Stable Roommates Problems",
    "authors": [
      "MÃ¼ge Fidan",
      "Esra Erdem"
    ],
    "abstract": "The Stable Roommates problems are characterized by the preferences of agents over other agents as roommates. A solution is a partition of the agents into pairs that are acceptable to each other (i.e., they are in the preference lists of each other), and the matching is stable (i.e., there do not exist any two agents who prefer each other to their roommates, and thus block the matching). Motivated by real-world applications, and considering that stable roommates problems do not always have solutions, we continue our studies to compute \"good-enough\" matchings. In addition to the agents' habits and habitual preferences, we consider their networks of preferred friends, and introduce a method to generate personalized solutions to stable roommates problems. We illustrate the usefulness of our method with examples and empirical evaluations.",
    "categories": [
      "cs.AI",
      "cs.GT",
      "cs.LO"
    ],
    "primary_category": "cs.AI",
    "comment": "",
    "pdf_url": "https://arxiv.org/pdf/2507.20010v1",
    "published_date": "2025-07-26 16:56:10 UTC",
    "updated_date": "2025-07-26 16:56:10 UTC"
  },
  {
    "arxiv_id": "2507.20008v1",
    "title": "Robust Taxi Fare Prediction Under Noisy Conditions: A Comparative Study of GAT, TimesNet, and XGBoost",
    "authors": [
      "Padmavathi Moorthy"
    ],
    "abstract": "Precise fare prediction is crucial in ride-hailing platforms and urban mobility systems. This study examines three machine learning models-Graph Attention Networks (GAT), XGBoost, and TimesNet to evaluate their predictive capabilities for taxi fares using a real-world dataset comprising over 55 million records. Both raw (noisy) and denoised versions of the dataset are analyzed to assess the impact of data quality on model performance. The study evaluated the models along multiple axes, including predictive accuracy, calibration, uncertainty estimation, out-of-distribution (OOD) robustness, and feature sensitivity. We also explore pre-processing strategies, including KNN imputation, Gaussian noise injection, and autoencoder-based denoising. The study reveals critical differences between classical and deep learning models under realistic conditions, offering practical guidelines for building robust and scalable models in urban fare prediction systems.",
    "categories": [
      "cs.LG",
      "cs.AI"
    ],
    "primary_category": "cs.LG",
    "comment": "10 pages, 9 figures, prepared with LaTeX, GitHub link: https://github.com/padmavathi026/Smart-Fare-Prediction",
    "pdf_url": "https://arxiv.org/pdf/2507.20008v1",
    "published_date": "2025-07-26 16:55:16 UTC",
    "updated_date": "2025-07-26 16:55:16 UTC"
  },
  {
    "arxiv_id": "2507.20000v1",
    "title": "Matching Game Preferences Through Dialogical Large Language Models: A Perspective",
    "authors": [
      "Renaud Fabre",
      "Daniel Egret",
      "Patrice Bellot"
    ],
    "abstract": "This perspective paper explores the future potential of \"conversational intelligence\" by examining how Large Language Models (LLMs) could be combined with GRAPHYP's network system to better understand human conversations and preferences. Using recent research and case studies, we propose a conceptual framework that could make AI rea-soning transparent and traceable, allowing humans to see and understand how AI reaches its conclusions. We present the conceptual perspective of \"Matching Game Preferences through Dialogical Large Language Models (D-LLMs),\" a proposed system that would allow multiple users to share their different preferences through structured conversations. This approach envisions personalizing LLMs by embedding individual user preferences directly into how the model makes decisions. The proposed D-LLM framework would require three main components: (1) reasoning processes that could analyze different search experiences and guide performance, (2) classification systems that would identify user preference patterns, and (3) dialogue approaches that could help humans resolve conflicting information. This perspective framework aims to create an interpretable AI system where users could examine, understand, and combine the different human preferences that influence AI responses, detected through GRAPHYP's search experience networks. The goal of this perspective is to envision AI systems that would not only provide answers but also show users how those answers were reached, making artificial intelligence more transparent and trustworthy for human decision-making.",
    "categories": [
      "cs.AI",
      "cs.DL"
    ],
    "primary_category": "cs.AI",
    "comment": "28 pages, 1 figure. Published in Applied Sciences",
    "pdf_url": "https://arxiv.org/pdf/2507.20000v1",
    "published_date": "2025-07-26 16:40:17 UTC",
    "updated_date": "2025-07-26 16:40:17 UTC"
  },
  {
    "arxiv_id": "2507.19995v1",
    "title": "VLQA: The First Comprehensive, Large, and High-Quality Vietnamese Dataset for Legal Question Answering",
    "authors": [
      "Tan-Minh Nguyen",
      "Hoang-Trung Nguyen",
      "Trong-Khoi Dao",
      "Xuan-Hieu Phan",
      "Ha-Thanh Nguyen",
      "Thi-Hai-Yen Vuong"
    ],
    "abstract": "The advent of large language models (LLMs) has led to significant achievements in various domains, including legal text processing. Leveraging LLMs for legal tasks is a natural evolution and an increasingly compelling choice. However, their capabilities are often portrayed as greater than they truly are. Despite the progress, we are still far from the ultimate goal of fully automating legal tasks using artificial intelligence (AI) and natural language processing (NLP). Moreover, legal systems are deeply domain-specific and exhibit substantial variation across different countries and languages. The need for building legal text processing applications for different natural languages is, therefore, large and urgent. However, there is a big challenge for legal NLP in low-resource languages such as Vietnamese due to the scarcity of resources and annotated data. The need for labeled legal corpora for supervised training, validation, and supervised fine-tuning is critical. In this paper, we introduce the VLQA dataset, a comprehensive and high-quality resource tailored for the Vietnamese legal domain. We also conduct a comprehensive statistical analysis of the dataset and evaluate its effectiveness through experiments with state-of-the-art models on legal information retrieval and question-answering tasks.",
    "categories": [
      "cs.CL",
      "cs.AI"
    ],
    "primary_category": "cs.CL",
    "comment": "",
    "pdf_url": "https://arxiv.org/pdf/2507.19995v1",
    "published_date": "2025-07-26 16:26:50 UTC",
    "updated_date": "2025-07-26 16:26:50 UTC"
  },
  {
    "arxiv_id": "2507.19992v4",
    "title": "Development and Evaluation of an Ontology for Non-Invasive Respiratory Support in Acute Care",
    "authors": [
      "Md Fantacher Islam",
      "Jarrod Mosier",
      "Vignesh Subbian"
    ],
    "abstract": "Managing patients with respiratory failure increasingly involves noninvasive respiratory support (NIRS) strategies to support respiration, often preventing the need for invasive mechanical ventilation. However, despite the rapidly expanding use of NIRS, there remains a significant challenge to its optimal use across all medical circumstances. It lacks a unified ontological structure, complicating guidance on NIRS modalities across healthcare systems. This study introduced NIRS ontology to support knowledge representation in acute care settings by providing a unified framework that enhances data clarity and interoperability, laying the groundwork for future clinical decision-making. We developed NIRS ontology using the Web Ontology Language (OWL) and Protege to organize clinical concepts and relationships. To enable rule-based clinical reasoning beyond hierarchical structures, we added Semantic Web Rule Language (SWRL) rules. We evaluated logical reasoning by adding a sample of 6 patient scenarios and used SPARQL queries to retrieve and test targeted inferences. The ontology has 145 classes, 11 object properties, and 18 data properties across 949 axioms that establish concept relationships. To standardize clinical concepts, we added 392 annotations, including descriptive definitions based on controlled vocabularies. SPARQL query evaluations across clinical scenarios confirmed the ontology ability to support rule based reasoning and therapy recommendations, providing a foundation for consistent documentation practices, integration into clinical data models, and advanced analysis of NIRS outcomes. In conclusion, we unified NIRS concepts into an ontological framework and demonstrated its applicability through the evaluation of patient scenarios and alignment with standardized vocabularies.",
    "categories": [
      "q-bio.OT",
      "cs.AI"
    ],
    "primary_category": "q-bio.OT",
    "comment": "",
    "pdf_url": "https://arxiv.org/pdf/2507.19992v4",
    "published_date": "2025-07-26 16:05:20 UTC",
    "updated_date": "2026-01-21 05:55:49 UTC"
  },
  {
    "arxiv_id": "2507.19990v1",
    "title": "Improving the Performance of Sequential Recommendation Systems with an Extended Large Language Model",
    "authors": [
      "Sinnyum Choi",
      "Woong Kim"
    ],
    "abstract": "Recently, competition in the field of artificial intelligence (AI) has intensified among major technological companies, resulting in the continuous release of new large-language models (LLMs) that exhibit improved language understanding and context-based reasoning capabilities. It is expected that these advances will enable more efficient personalized recommendations in LLM-based recommendation systems through improved quality of training data and architectural design. However, many studies have not considered these recent developments. In this study, it was proposed to improve LLM-based recommendation systems by replacing Llama2 with Llama3 in the LlamaRec framework. To ensure a fair comparison, random seed values were set and identical input data was provided during preprocessing and training. The experimental results show average performance improvements of 38.65\\%, 8.69\\%, and 8.19\\% for the ML-100K, Beauty, and Games datasets, respectively, thus confirming the practicality of this method. Notably, the significant improvements achieved by model replacement indicate that the recommendation quality can be improved cost-effectively without the need to make structural changes to the system. Based on these results, it is our contention that the proposed approach is a viable solution for improving the performance of current recommendation systems.",
    "categories": [
      "cs.IR",
      "cs.AI",
      "cs.CL"
    ],
    "primary_category": "cs.IR",
    "comment": "",
    "pdf_url": "https://arxiv.org/pdf/2507.19990v1",
    "published_date": "2025-07-26 15:59:25 UTC",
    "updated_date": "2025-07-26 15:59:25 UTC"
  },
  {
    "arxiv_id": "2507.21179v2",
    "title": "CANDLE: A Cross-Modal Agentic Knowledge Distillation Framework for Interpretable Sarcopenia Diagnosis",
    "authors": [
      "Yuqi Jin",
      "Zhenhao Shuai",
      "Zihan Hu",
      "Weiteng Zhang",
      "Weihao Xie",
      "Jianwei Shuai",
      "Xian Shen",
      "Zhen Feng"
    ],
    "abstract": "Background and Aims: Large language models (LLMs) have shown remarkable generalization and transfer capabilities by learning from vast corpora of text and web data. Their semantic representations allow cross-task knowledge transfer and reasoning, offering promising opportunities for data-scarce and heterogeneous domains such as clinical medicine. Yet, in diagnostic tasks like sarcopenia, major challenges remain: interpretability, transparency, and deployment efficiency. Traditional machine learning (TML) models provide stable performance and feature-level attribution, ensuring traceable and auditable decision logic, but lack semantic breadth. Conversely, LLMs enable flexible inference but often function as opaque predictors. Existing integration strategies remain shallow, rarely embedding the structured reasoning of TML into LLM inference. Methods: Using sarcopenia diagnosis as a case study, SHapley Additive exPlanations (SHAP) were extracted from a baseline XGBoost model and transformed into structured, LLM-compatible representations. An actor-critic reinforcement learning (RL) strategy guided the LLM to reason over these SHAP-based inputs, producing calibrated rationales and refined decision rules. The distilled reasoning was consolidated into a structured knowledge repository and deployed via retrieval-augmented generation (RAG) for case-based inference. Results: (Omitted here.) Conclusion: By coupling SHAP-derived statistical evidence with reinforcement-trained LLM reasoning, CANDLE mitigates the interpretability-performance trade-off, enhances predictive accuracy, and preserves high decision consistency. The framework offers a scalable approach to knowledge assetization of TML models, enabling interpretable, reproducible, and clinically aligned decision support in sarcopenia and potentially broader medical domains.",
    "categories": [
      "cs.LG",
      "cs.AI"
    ],
    "primary_category": "cs.LG",
    "comment": "11 pages, 4 figures, 5 tables",
    "pdf_url": "https://arxiv.org/pdf/2507.21179v2",
    "published_date": "2025-07-26 15:50:08 UTC",
    "updated_date": "2025-09-24 15:38:14 UTC"
  },
  {
    "arxiv_id": "2507.19983v2",
    "title": "CLASP: General-Purpose Clothes Manipulation with Semantic Keypoints",
    "authors": [
      "Yuhong Deng",
      "Chao Tang",
      "Cunjun Yu",
      "Linfeng Li",
      "David Hsu"
    ],
    "abstract": "Clothes manipulation, such as folding or hanging, is a critical capability for home service robots. Despite recent advances, most existing methods remain limited to specific clothes types and tasks, due to the complex, high-dimensional geometry of clothes. This paper presents CLothes mAnipulation with Semantic keyPoints (CLASP), which aims at general-purpose clothes manipulation over diverse clothes types, T-shirts, shorts, skirts, long dresses, ..., as well as different tasks, folding, flattening, hanging, .... The core idea of CLASP is semantic keypoints-e.g., ''left sleeve'' and ''right shoulder''-a sparse spatial-semantic representation, salient for both perception and action. Semantic keypoints of clothes can be reliably extracted from RGB-D images and provide an effective representation for a wide range of clothes manipulation policies. CLASP uses semantic keypoints as an intermediate representation to connect high-level task planning and low-level action execution. At the high level, it exploits vision language models (VLMs) to predict task plans over the semantic keypoints. At the low level, it executes the plans with the help of a set of pre-built manipulation skills conditioned on the keypoints. Extensive simulation experiments show that CLASP outperforms state-of-the-art baseline methods on multiple tasks across diverse clothes types, demonstrating strong performance and generalization. Further experiments with a Franka dual-arm system on four distinct tasks-folding, flattening, hanging, and placing-confirm CLASP's performance on real-life clothes manipulation.",
    "categories": [
      "cs.RO",
      "cs.AI"
    ],
    "primary_category": "cs.RO",
    "comment": "",
    "pdf_url": "https://arxiv.org/pdf/2507.19983v2",
    "published_date": "2025-07-26 15:43:25 UTC",
    "updated_date": "2025-10-17 13:17:10 UTC"
  },
  {
    "arxiv_id": "2507.19975v1",
    "title": "A roadmap for AI in robotics",
    "authors": [
      "Aude Billard",
      "Alin Albu-Schaeffer",
      "Michael Beetz",
      "Wolfram Burgard",
      "Peter Corke",
      "Matei Ciocarlie",
      "Ravinder Dahiya",
      "Danica Kragic",
      "Ken Goldberg",
      "Yukie Nagai",
      "Davide Scaramuzza"
    ],
    "abstract": "AI technologies, including deep learning, large-language models have gone from one breakthrough to the other. As a result, we are witnessing growing excitement in robotics at the prospect of leveraging the potential of AI to tackle some of the outstanding barriers to the full deployment of robots in our daily lives. However, action and sensing in the physical world pose greater and different challenges than analysing data in isolation. As the development and application of AI in robotic products advances, it is important to reflect on which technologies, among the vast array of network architectures and learning models now available in the AI field, are most likely to be successfully applied to robots; how they can be adapted to specific robot designs, tasks, environments; which challenges must be overcome. This article offers an assessment of what AI for robotics has achieved since the 1990s and proposes a short- and medium-term research roadmap listing challenges and promises. These range from keeping up-to-date large datasets, representatives of a diversity of tasks robots may have to perform, and of environments they may encounter, to designing AI algorithms tailored specifically to robotics problems but generic enough to apply to a wide range of applications and transfer easily to a variety of robotic platforms. For robots to collaborate effectively with humans, they must predict human behavior without relying on bias-based profiling. Explainability and transparency in AI-driven robot control are not optional but essential for building trust, preventing misuse, and attributing responsibility in accidents. We close on what we view as the primary long-term challenges, that is, to design robots capable of lifelong learning, while guaranteeing safe deployment and usage, and sustainable computational costs.",
    "categories": [
      "cs.RO",
      "cs.AI",
      "cs.LG"
    ],
    "primary_category": "cs.RO",
    "comment": "",
    "pdf_url": "https://arxiv.org/pdf/2507.19975v1",
    "published_date": "2025-07-26 15:18:28 UTC",
    "updated_date": "2025-07-26 15:18:28 UTC"
  },
  {
    "arxiv_id": "2507.19974v1",
    "title": "Digital Twin Channel-Enabled Online Resource Allocation for 6G: Principle, Architecture and Application",
    "authors": [
      "Tongjie Li",
      "Jianhua Zhang",
      "Li Yu",
      "Yuxiang Zhang",
      "Yunlong Cai",
      "Fan Xu",
      "Guangyi Liu"
    ],
    "abstract": "Emerging applications such as holographic communication, autonomous driving, and the industrial Internet of Things impose stringent requirements on flexible, low-latency, and reliable resource allocation in 6G networks. Conventional methods, which rely on statistical modeling, have proven effective in general contexts but may fail to achieve optimal performance in specific and dynamic environments. Furthermore, acquiring real-time channel state information (CSI) typically requires excessive pilot overhead. To address these challenges, a digital twin channel (DTC)-enabled online optimization framework is proposed, in which DTC is employed to predict CSI based on environmental sensing. The predicted CSI is then utilized by lightweight game-theoretic algorithms to perform online resource allocation in a timely and efficient manner. Simulation results based on a digital replica of a realistic industrial workshop demonstrate that the proposed method achieves throughput improvements of up to 11.5\\% compared with pilot-based ideal CSI schemes, validating its effectiveness for scalable, low-overhead, and environment-aware communication in future 6G networks.",
    "categories": [
      "cs.AI",
      "cs.IT"
    ],
    "primary_category": "cs.AI",
    "comment": "",
    "pdf_url": "https://arxiv.org/pdf/2507.19974v1",
    "published_date": "2025-07-26 15:07:45 UTC",
    "updated_date": "2025-07-26 15:07:45 UTC"
  },
  {
    "arxiv_id": "2507.19973v1",
    "title": "Leveraging Fine-Tuned Large Language Models for Interpretable Pancreatic Cystic Lesion Feature Extraction and Risk Categorization",
    "authors": [
      "Ebrahim Rasromani",
      "Stella K. Kang",
      "Yanqi Xu",
      "Beisong Liu",
      "Garvit Luhadia",
      "Wan Fung Chui",
      "Felicia L. Pasadyn",
      "Yu Chih Hung",
      "Julie Y. An",
      "Edwin Mathieu",
      "Zehui Gu",
      "Carlos Fernandez-Granda",
      "Ammar A. Javed",
      "Greg D. Sacks",
      "Tamas Gonda",
      "Chenchan Huang",
      "Yiqiu Shen"
    ],
    "abstract": "Background: Manual extraction of pancreatic cystic lesion (PCL) features from radiology reports is labor-intensive, limiting large-scale studies needed to advance PCL research. Purpose: To develop and evaluate large language models (LLMs) that automatically extract PCL features from MRI/CT reports and assign risk categories based on guidelines. Materials and Methods: We curated a training dataset of 6,000 abdominal MRI/CT reports (2005-2024) from 5,134 patients that described PCLs. Labels were generated by GPT-4o using chain-of-thought (CoT) prompting to extract PCL and main pancreatic duct features. Two open-source LLMs were fine-tuned using QLoRA on GPT-4o-generated CoT data. Features were mapped to risk categories per institutional guideline based on the 2017 ACR White Paper. Evaluation was performed on 285 held-out human-annotated reports. Model outputs for 100 cases were independently reviewed by three radiologists. Feature extraction was evaluated using exact match accuracy, risk categorization with macro-averaged F1 score, and radiologist-model agreement with Fleiss' Kappa. Results: CoT fine-tuning improved feature extraction accuracy for LLaMA (80% to 97%) and DeepSeek (79% to 98%), matching GPT-4o (97%). Risk categorization F1 scores also improved (LLaMA: 0.95; DeepSeek: 0.94), closely matching GPT-4o (0.97), with no statistically significant differences. Radiologist inter-reader agreement was high (Fleiss' Kappa = 0.888) and showed no statistically significant difference with the addition of DeepSeek-FT-CoT (Fleiss' Kappa = 0.893) or GPT-CoT (Fleiss' Kappa = 0.897), indicating that both models achieved agreement levels on par with radiologists. Conclusion: Fine-tuned open-source LLMs with CoT supervision enable accurate, interpretable, and efficient phenotyping for large-scale PCL research, achieving performance comparable to GPT-4o.",
    "categories": [
      "cs.AI",
      "cs.CL",
      "cs.IR"
    ],
    "primary_category": "cs.AI",
    "comment": "",
    "pdf_url": "https://arxiv.org/pdf/2507.19973v1",
    "published_date": "2025-07-26 15:02:32 UTC",
    "updated_date": "2025-07-26 15:02:32 UTC"
  },
  {
    "arxiv_id": "2507.19968v1",
    "title": "Dimer-Enhanced Optimization: A First-Order Approach to Escaping Saddle Points in Neural Network Training",
    "authors": [
      "Yue Hu",
      "Zanxia Cao",
      "Yingchao Liu"
    ],
    "abstract": "First-order optimization methods, such as SGD and Adam, are widely used for training large-scale deep neural networks due to their computational efficiency and robust performance. However, relying solely on gradient information, these methods often struggle to navigate complex loss landscapes with flat regions, plateaus, and saddle points. Second-order methods, which use curvature information from the Hessian matrix, can address these challenges but are computationally infeasible for large models. The Dimer method, a first-order technique that constructs two closely spaced points to probe the local geometry of a potential energy surface, efficiently estimates curvature using only gradient information. Inspired by its use in molecular dynamics simulations for locating saddle points, we propose Dimer-Enhanced Optimization (DEO), a novel framework to escape saddle points in neural network training. DEO adapts the Dimer method to explore a broader region of the loss landscape, approximating the Hessian's smallest eigenvector without computing the full matrix. By periodically projecting the gradient onto the subspace orthogonal to the minimum curvature direction, DEO guides the optimizer away from saddle points and flat regions, enhancing training efficiency with non-stepwise updates. Preliminary experiments on a Transformer toy model show DEO achieves competitive performance compared to standard first-order methods, improving navigation of complex loss landscapes. Our work repurposes physics-inspired, first-order curvature estimation to enhance neural network training in high-dimensional spaces.",
    "categories": [
      "cs.LG",
      "cs.AI",
      "stat.ML"
    ],
    "primary_category": "cs.LG",
    "comment": "8 pages, 2 figures",
    "pdf_url": "https://arxiv.org/pdf/2507.19968v1",
    "published_date": "2025-07-26 14:57:32 UTC",
    "updated_date": "2025-07-26 14:57:32 UTC"
  },
  {
    "arxiv_id": "2507.19961v2",
    "title": "Pic2Diagnosis: A Method for Diagnosis of Cardiovascular Diseases from the Printed ECG Pictures",
    "authors": [
      "OÄuzhan BÃ¼yÃ¼ksolak",
      "Ä°lkay ÃksÃ¼z"
    ],
    "abstract": "The electrocardiogram (ECG) is a vital tool for diagnosing heart diseases. However, many disease patterns are derived from outdated datasets and traditional stepwise algorithms with limited accuracy. This study presents a method for direct cardiovascular disease (CVD) diagnosis from ECG images, eliminating the need for digitization. The proposed approach utilizes a two-step curriculum learning framework, beginning with the pre-training of a classification model on segmentation masks, followed by fine-tuning on grayscale, inverted ECG images. Robustness is further enhanced through an ensemble of three models with averaged outputs, achieving an AUC of 0.9534 and an F1 score of 0.7801 on the BHF ECG Challenge dataset, outperforming individual models. By effectively handling real-world artifacts and simplifying the diagnostic process, this method offers a reliable solution for automated CVD diagnosis, particularly in resource-limited settings where printed or scanned ECG images are commonly used. Such an automated procedure enables rapid and accurate diagnosis, which is critical for timely intervention in CVD cases that often demand urgent care.",
    "categories": [
      "cs.CV",
      "cs.AI"
    ],
    "primary_category": "cs.CV",
    "comment": "Accepted to IEEE EMBC 2025. Final published version available on IEEE Xplore",
    "pdf_url": "https://arxiv.org/pdf/2507.19961v2",
    "published_date": "2025-07-26 14:21:25 UTC",
    "updated_date": "2025-12-07 08:17:57 UTC"
  },
  {
    "arxiv_id": "2507.19960v2",
    "title": "What Does 'Human-Centred AI' Mean?",
    "authors": [
      "Olivia Guest"
    ],
    "abstract": "While it seems sensible that human-centred artificial intelligence (AI) means centring \"human behaviour and experience,\" it cannot be any other way. AI, I argue, is usefully seen as a relationship between technology and humans where it appears that artifacts can perform, to a greater or lesser extent, human cognitive labour. This is evinced using examples that juxtapose technology with cognition, inter alia: abacus versus mental arithmetic; alarm clock versus knocker-upper; camera versus vision; and sweatshop versus tailor. Using novel definitions and analyses, sociotechnical relationships can be analysed into varying types of: displacement (harmful), enhancement (beneficial), and/or replacement (neutral) of human cognitive labour. Ultimately, all AI implicates human cognition; no matter what. Obfuscation of cognition in the AI context -- from clocks to artificial neural networks -- results in distortion, in slowing critical engagement, perverting cognitive science, and indeed in limiting our ability to truly centre humans and humanity in the engineering of AI systems. To even begin to de-fetishise AI, we must look the human-in-the-loop in the eyes.",
    "categories": [
      "cs.AI"
    ],
    "primary_category": "cs.AI",
    "comment": "",
    "pdf_url": "https://arxiv.org/pdf/2507.19960v2",
    "published_date": "2025-07-26 14:18:52 UTC",
    "updated_date": "2025-07-29 12:19:01 UTC"
  },
  {
    "arxiv_id": "2507.19956v1",
    "title": "Predicting Brain Responses To Natural Movies With Multimodal LLMs",
    "authors": [
      "Cesar Kadir Torrico Villanueva",
      "Jiaxin Cindy Tu",
      "Mihir Tripathy",
      "Connor Lane",
      "Rishab Iyer",
      "Paul S. Scotti"
    ],
    "abstract": "We present MedARC's team solution to the Algonauts 2025 challenge. Our pipeline leveraged rich multimodal representations from various state-of-the-art pretrained models across video (V-JEPA2), speech (Whisper), text (Llama 3.2), vision-text (InternVL3), and vision-text-audio (Qwen2.5-Omni). These features extracted from the models were linearly projected to a latent space, temporally aligned to the fMRI time series, and finally mapped to cortical parcels through a lightweight encoder comprising a shared group head plus subject-specific residual heads. We trained hundreds of model variants across hyperparameter settings, validated them on held-out movies and assembled ensembles targeted to each parcel in each subject. Our final submission achieved a mean Pearson's correlation of 0.2085 on the test split of withheld out-of-distribution movies, placing our team in fourth place for the competition. We further discuss a last-minute optimization that would have raised us to second place. Our results highlight how combining features from models trained in different modalities, using a simple architecture consisting of shared-subject and single-subject components, and conducting comprehensive model selection and ensembling improves generalization of encoding models to novel movie stimuli. All code is available on GitHub.",
    "categories": [
      "cs.CV",
      "cs.AI",
      "q-bio.NC"
    ],
    "primary_category": "cs.CV",
    "comment": "Code available at https://github.com/MedARC-AI/algonauts2025",
    "pdf_url": "https://arxiv.org/pdf/2507.19956v1",
    "published_date": "2025-07-26 13:57:08 UTC",
    "updated_date": "2025-07-26 13:57:08 UTC"
  },
  {
    "arxiv_id": "2507.22946v1",
    "title": "SmartCourse: A Contextual AI-Powered Course Advising System for Undergraduates",
    "authors": [
      "Yixuan Mi",
      "Yiduo Yu",
      "Yiyi Zhao"
    ],
    "abstract": "We present SmartCourse, an integrated course management and AI-driven advising system for undergraduate students (specifically tailored to the Computer Science (CPS) major). SmartCourse addresses the limitations of traditional advising tools by integrating transcript and plan information for student-specific context. The system combines a command-line interface (CLI) and a Gradio web GUI for instructors and students, manages user accounts, course enrollment, grading, and four-year degree plans, and integrates a locally hosted large language model (via Ollama) for personalized course recommendations. It leverages transcript and major plan to offer contextual advice (e.g., prioritizing requirements or retakes). We evaluated the system on 25 representative advising queries and introduced custom metrics: PlanScore, PersonalScore, Lift, and Recall to assess recommendation quality across different context conditions. Experiments show that using full context yields substantially more relevant recommendations than context-omitted modes, confirming the necessity of transcript and plan information for personalized academic advising. SmartCourse thus demonstrates how transcript-aware AI can enhance academic planning.",
    "categories": [
      "cs.CY",
      "cs.AI"
    ],
    "primary_category": "cs.CY",
    "comment": "7 pages, 6 figures, 1 table. *Corresponding author: Yixuan Mi. Code: https://github.com/EthanYixuanMi/Smartcourse-Contextual-Advising",
    "pdf_url": "https://arxiv.org/pdf/2507.22946v1",
    "published_date": "2025-07-26 13:49:41 UTC",
    "updated_date": "2025-07-26 13:49:41 UTC"
  },
  {
    "arxiv_id": "2507.19950v1",
    "title": "RARE: Refine Any Registration of Pairwise Point Clouds via Zero-Shot Learning",
    "authors": [
      "Chengyu Zheng",
      "Jin Huang",
      "Honghua Chen",
      "Mingqiang Wei"
    ],
    "abstract": "Recent research leveraging large-scale pretrained diffusion models has demonstrated the potential of using diffusion features to establish semantic correspondences in images. Inspired by advancements in diffusion-based techniques, we propose a novel zero-shot method for refining point cloud registration algorithms. Our approach leverages correspondences derived from depth images to enhance point feature representations, eliminating the need for a dedicated training dataset. Specifically, we first project the point cloud into depth maps from multiple perspectives and extract implicit knowledge from a pretrained diffusion network as depth diffusion features. These features are then integrated with geometric features obtained from existing methods to establish more accurate correspondences between point clouds. By leveraging these refined correspondences, our approach achieves significantly improved registration accuracy. Extensive experiments demonstrate that our method not only enhances the performance of existing point cloud registration techniques but also exhibits robust generalization capabilities across diverse datasets. Codes are available at https://github.com/zhengcy-lambo/RARE.git.",
    "categories": [
      "cs.CV",
      "cs.AI"
    ],
    "primary_category": "cs.CV",
    "comment": "",
    "pdf_url": "https://arxiv.org/pdf/2507.19950v1",
    "published_date": "2025-07-26 13:34:39 UTC",
    "updated_date": "2025-07-26 13:34:39 UTC"
  },
  {
    "arxiv_id": "2507.19936v1",
    "title": "Deep Learning Based Joint Channel Estimation and Positioning for Sparse XL-MIMO OFDM Systems",
    "authors": [
      "Zhongnian Li",
      "Chao Zheng",
      "Jian Xiao",
      "Ji Wang",
      "Gongpu Wang",
      "Ming Zeng",
      "Octavia A. Dobre"
    ],
    "abstract": "This paper investigates joint channel estimation and positioning in near-field sparse extra-large multiple-input multiple-output (XL-MIMO) orthogonal frequency division multiplexing (OFDM) systems. To achieve cooperative gains between channel estimation and positioning, we propose a deep learning-based two-stage framework comprising positioning and channel estimation. In the positioning stage, the user's coordinates are predicted and utilized in the channel estimation stage, thereby enhancing the accuracy of channel estimation. Within this framework, we propose a U-shaped Mamba architecture for channel estimation and positioning, termed as CP-Mamba. This network integrates the strengths of the Mamba model with the structural advantages of U-shaped convolutional networks, enabling effective capture of local spatial features and long-range temporal dependencies of the channel. Numerical simulation results demonstrate that the proposed two-stage approach with CP-Mamba architecture outperforms existing baseline methods. Moreover, sparse arrays (SA) exhibit significantly superior performance in both channel estimation and positioning accuracy compared to conventional compact arrays.",
    "categories": [
      "eess.SP",
      "cs.AI",
      "cs.LG"
    ],
    "primary_category": "eess.SP",
    "comment": "5 pages,8 figures",
    "pdf_url": "https://arxiv.org/pdf/2507.19936v1",
    "published_date": "2025-07-26 12:47:39 UTC",
    "updated_date": "2025-07-26 12:47:39 UTC"
  },
  {
    "arxiv_id": "2507.19929v2",
    "title": "DynamiX: Large-Scale Dynamic Social Network Simulator",
    "authors": [
      "Yanhui Sun",
      "Wu Liu",
      "Wentao Wang",
      "Hantao Yao",
      "Jiebo Luo",
      "Yongdong Zhang"
    ],
    "abstract": "Understanding the intrinsic mechanisms of social platforms is an urgent demand to maintain social stability. The rise of large language models provides significant potential for social network simulations to capture attitude dynamics and reproduce collective behaviors. However, existing studies mainly focus on scaling up agent populations, neglecting the dynamic evolution of social relationships. To address this gap, we introduce DynamiX, a novel large-scale social network simulator dedicated to dynamic social network modeling. DynamiX uses a dynamic hierarchy module for selecting core agents with key characteristics at each timestep, enabling accurate alignment of real-world adaptive switching of user roles. Furthermore, we design distinct dynamic social relationship modeling strategies for different user types. For opinion leaders, we propose an information-stream-based link prediction method recommending potential users with similar stances, simulating homogeneous connections, and autonomous behavior decisions. For ordinary users, we construct an inequality-oriented behavior decision-making module, effectively addressing unequal social interactions and capturing the patterns of relationship adjustments driven by multi-dimensional factors. Experimental results demonstrate that DynamiX exhibits marked improvements in attitude evolution simulation and collective behavior analysis compared to static networks. Besides, DynamiX opens a new theoretical perspective on follower growth prediction, providing empirical evidence for opinion leaders cultivation.",
    "categories": [
      "physics.soc-ph",
      "cs.AI"
    ],
    "primary_category": "physics.soc-ph",
    "comment": "Social and Information Networks",
    "pdf_url": "https://arxiv.org/pdf/2507.19929v2",
    "published_date": "2025-07-26 12:13:30 UTC",
    "updated_date": "2025-12-15 13:32:12 UTC"
  },
  {
    "arxiv_id": "2507.19917v1",
    "title": "A mini-batch training strategy for deep subspace clustering networks",
    "authors": [
      "Yuxuan Jiang",
      "Chenwei Yu",
      "Zhi Lin",
      "Xiaolan Liu"
    ],
    "abstract": "Mini-batch training is a cornerstone of modern deep learning, offering computational efficiency and scalability for training complex architectures. However, existing deep subspace clustering (DSC) methods, which typically combine an autoencoder with a self-expressive layer, rely on full-batch processing. The bottleneck arises from the self-expressive module, which requires representations of the entire dataset to construct a self-representation coefficient matrix. In this work, we introduce a mini-batch training strategy for DSC by integrating a memory bank that preserves global feature representations. Our approach enables scalable training of deep architectures for subspace clustering with high-resolution images, overcoming previous limitations. Additionally, to efficiently fine-tune large-scale pre-trained encoders for subspace clustering, we propose a decoder-free framework that leverages contrastive learning instead of autoencoding for representation learning. This design not only eliminates the computational overhead of decoder training but also provides competitive performance. Extensive experiments demonstrate that our approach not only achieves performance comparable to full-batch methods, but outperforms other state-of-the-art subspace clustering methods on the COIL100 and ORL datasets by fine-tuning deep networks.",
    "categories": [
      "cs.CV",
      "cs.AI"
    ],
    "primary_category": "cs.CV",
    "comment": "",
    "pdf_url": "https://arxiv.org/pdf/2507.19917v1",
    "published_date": "2025-07-26 11:44:39 UTC",
    "updated_date": "2025-07-26 11:44:39 UTC"
  },
  {
    "arxiv_id": "2507.19909v1",
    "title": "The Impact of Fine-tuning Large Language Models on Automated Program Repair",
    "authors": [
      "Roman MachÃ¡Äek",
      "Anastasiia Grishina",
      "Max Hort",
      "Leon Moonen"
    ],
    "abstract": "Automated Program Repair (APR) uses various tools and techniques to help developers achieve functional and error-free code faster. In recent years, Large Language Models (LLMs) have gained popularity as components in APR tool chains because of their performance and flexibility. However, training such models requires a significant amount of resources. Fine-tuning techniques have been developed to adapt pre-trained LLMs to specific tasks, such as APR, and enhance their performance at far lower computational costs than training from scratch. In this study, we empirically investigate the impact of various fine-tuning techniques on the performance of LLMs used for APR. Our experiments provide insights into the performance of a selection of state-of-the-art LLMs pre-trained on code. The evaluation is done on three popular APR benchmarks (i.e., QuixBugs, Defects4J and HumanEval-Java) and considers six different LLMs with varying parameter sizes (resp. CodeGen, CodeT5, StarCoder, DeepSeekCoder, Bloom, and CodeLlama-2). We consider three training regimens: no fine-tuning, full fine-tuning, and parameter-efficient fine-tuning (PEFT) using LoRA and IA3. We observe that full fine-tuning techniques decrease the benchmarking performance of various models due to different data distributions and overfitting. By using parameter-efficient fine-tuning methods, we restrict models in the amount of trainable parameters and achieve better results.\n  Keywords: large language models, automated program repair, parameter-efficient fine-tuning, AI4Code, AI4SE, ML4SE.",
    "categories": [
      "cs.SE",
      "cs.AI",
      "cs.CL",
      "cs.LG"
    ],
    "primary_category": "cs.SE",
    "comment": "Accepted for publication in the research track of the 41th International Conference on Software Maintenance and Evolution (ICSME 2025)",
    "pdf_url": "https://arxiv.org/pdf/2507.19909v1",
    "published_date": "2025-07-26 10:42:08 UTC",
    "updated_date": "2025-07-26 10:42:08 UTC"
  },
  {
    "arxiv_id": "2507.19904v1",
    "title": "CrossPL: Evaluating Large Language Models on Cross Programming Language Code Generation",
    "authors": [
      "Zhanhang Xiong",
      "Dongxia Wang",
      "Yuekang Li",
      "Xinyuan An",
      "Wenhai Wang"
    ],
    "abstract": "As large language models (LLMs) become increasingly embedded in software engineering workflows, a critical capability remains underexplored: generating correct code that enables cross-programming-language (CPL) interoperability. This skill is essential for building complex systems that integrate components written in multiple languages via mechanisms like inter-process communication (IPC). To bridge this gap, we present CrossPL, the first benchmark designed to systematically evaluate LLMs' ability to generate CPL-interoperating code. CrossPL comprises 1,982 tasks centered around IPC, covering six widely-used programming languages and seven representative CPL techniques. We construct this benchmark by (i) analyzing 19,169 multi-language GitHub repositories using 156 hand-crafted finite state machines (FSMs), and (ii) developing an LLM-based pipeline that automatically extracts CPL code snippets, generates task instructions, and validates functional correctness. We evaluate 14 state-of-the-art general-purpose LLMs and 6 code-oriented LLMs released in the past three years on CrossPL via FSM-based validation. Results reveal that even the best-performing models struggle with CPL scenarios, underscoring the need for more targeted research in this space. Our benchmark and code are available at: https://anonymous.4open.science/r/crosspl-2814.",
    "categories": [
      "cs.SE",
      "cs.AI"
    ],
    "primary_category": "cs.SE",
    "comment": "",
    "pdf_url": "https://arxiv.org/pdf/2507.19904v1",
    "published_date": "2025-07-26 10:28:39 UTC",
    "updated_date": "2025-07-26 10:28:39 UTC"
  },
  {
    "arxiv_id": "2507.19902v1",
    "title": "AgentMesh: A Cooperative Multi-Agent Generative AI Framework for Software Development Automation",
    "authors": [
      "Sourena Khanzadeh"
    ],
    "abstract": "Software development is a complex, multi-phase process traditionally requiring collaboration among individuals with diverse expertise. We propose AgentMesh, a Python-based framework that uses multiple cooperating LLM-powered agents to automate software development tasks. In AgentMesh, specialized agents - a Planner, Coder, Debugger, and Reviewer - work in concert to transform a high-level requirement into fully realized code. The Planner agent first decomposes user requests into concrete subtasks; the Coder agent implements each subtask in code; the Debugger agent tests and fixes the code; and the Reviewer agent validates the final output for correctness and quality. We describe the architecture and design of these agents and their communication, and provide implementation details including prompt strategies and workflow orchestration. A case study illustrates AgentMesh handling a non-trivial development request via sequential task planning, code generation, iterative debugging, and final code review. We discuss how dividing responsibilities among cooperative agents leverages the strengths of large language models while mitigating single-agent limitations. Finally, we examine current limitations - such as error propagation and context scaling - and outline future work toward more robust, scalable multi-agent AI systems for software engineering automation.",
    "categories": [
      "cs.SE",
      "cs.AI"
    ],
    "primary_category": "cs.SE",
    "comment": "",
    "pdf_url": "https://arxiv.org/pdf/2507.19902v1",
    "published_date": "2025-07-26 10:10:02 UTC",
    "updated_date": "2025-07-26 10:10:02 UTC"
  },
  {
    "arxiv_id": "2507.19898v2",
    "title": "TS-Insight: Visualizing Thompson Sampling for Verification and XAI",
    "authors": [
      "Parsa Vares",
      "Ãloi Durant",
      "Jun Pang",
      "Nicolas MÃ©doc",
      "Mohammad Ghoniem"
    ],
    "abstract": "Thompson Sampling (TS) and its variants are powerful Multi-Armed Bandit algorithms used to balance exploration and exploitation strategies in active learning. Yet, their probabilistic nature often turns them into a \"black box\", hindering debugging and trust. We introduce TS-Insight, a visual analytics tool explicitly designed to shed light on the internal decision mechanisms of Thompson Sampling-based algorithms, for model developers. It comprises multiple plots, tracing for each arm the evolving posteriors, evidence counts, and sampling outcomes, enabling the verification, diagnosis, and explainability of exploration/exploitation dynamics. This tool aims at fostering trust and facilitating effective debugging and deployment in complex binary decision-making scenarios especially in sensitive domains requiring interpretable decision-making.",
    "categories": [
      "cs.HC",
      "cs.AI",
      "cs.LG",
      "stat.ML"
    ],
    "primary_category": "cs.HC",
    "comment": "Accepted as a poster at IEEE VIS 2025 (\"TS-Insight: Visual Fingerprinting of Multi-Armed Bandits\"). Open-source tool available at https://github.com/LIST-LUXEMBOURG/ts-insight",
    "pdf_url": "https://arxiv.org/pdf/2507.19898v2",
    "published_date": "2025-07-26 09:58:26 UTC",
    "updated_date": "2025-08-21 08:23:12 UTC"
  },
  {
    "arxiv_id": "2507.19891v2",
    "title": "Interpretable Open-Vocabulary Referring Object Detection with Reverse Contrast Attention",
    "authors": [
      "Drandreb Earl O. Juanico",
      "Rowel O. Atienza",
      "Jeffrey Kenneth Go"
    ],
    "abstract": "We propose Reverse Contrast Attention (RCA), a plug-in method that enhances object localization in vision-language transformers without retraining. RCA reweights final-layer attention by suppressing extremes and amplifying mid-level activations to let semantically relevant but subdued tokens guide predictions. We evaluate it on Open Vocabulary Referring Object Detection (OV-RefOD), introducing FitAP, a confidence-free average precision metric based on IoU and box area. RCA improves FitAP in 11 out of 15 open-source VLMs, with gains up to $+26.6\\%$. Effectiveness aligns with attention sharpness and fusion timing; while late-fusion models benefit consistently, models like $\\texttt{DeepSeek-VL2}$ also improve, pointing to capacity and disentanglement as key factors. RCA offers both interpretability and performance gains for multimodal transformers. Codes and dataset are available from https://github.com/earl-juanico/rca",
    "categories": [
      "cs.CV",
      "cs.AI"
    ],
    "primary_category": "cs.CV",
    "comment": "To be published in the ICCVW 2025 Proceedings",
    "pdf_url": "https://arxiv.org/pdf/2507.19891v2",
    "published_date": "2025-07-26 09:43:09 UTC",
    "updated_date": "2025-07-30 04:47:07 UTC"
  },
  {
    "arxiv_id": "2507.19882v1",
    "title": "Causality-aligned Prompt Learning via Diffusion-based Counterfactual Generation",
    "authors": [
      "Xinshu Li",
      "Ruoyu Wang",
      "Erdun Gao",
      "Mingming Gong",
      "Lina Yao"
    ],
    "abstract": "Prompt learning has garnered attention for its efficiency over traditional model training and fine-tuning. However, existing methods, constrained by inadequate theoretical foundations, encounter difficulties in achieving causally invariant prompts, ultimately falling short of capturing robust features that generalize effectively across categories. To address these challenges, we introduce the $\\textit{\\textbf{DiCap}}$ model, a theoretically grounded $\\textbf{Di}$ffusion-based $\\textbf{C}$ounterf$\\textbf{a}$ctual $\\textbf{p}$rompt learning framework, which leverages a diffusion process to iteratively sample gradients from the marginal and conditional distributions of the causal model, guiding the generation of counterfactuals that satisfy the minimal sufficiency criterion. Grounded in rigorous theoretical derivations, this approach guarantees the identifiability of counterfactual outcomes while imposing strict bounds on estimation errors. We further employ a contrastive learning framework that leverages the generated counterfactuals, thereby enabling the refined extraction of prompts that are precisely aligned with the causal features of the data. Extensive experimental results demonstrate that our method performs excellently across tasks such as image classification, image-text retrieval, and visual question answering, with particularly strong advantages in unseen categories.",
    "categories": [
      "cs.AI"
    ],
    "primary_category": "cs.AI",
    "comment": "",
    "pdf_url": "https://arxiv.org/pdf/2507.19882v1",
    "published_date": "2025-07-26 09:27:52 UTC",
    "updated_date": "2025-07-26 09:27:52 UTC"
  },
  {
    "arxiv_id": "2507.19881v1",
    "title": "FedS2R: One-Shot Federated Domain Generalization for Synthetic-to-Real Semantic Segmentation in Autonomous Driving",
    "authors": [
      "Tao Lian",
      "Jose L. GÃ³mez",
      "Antonio M. LÃ³pez"
    ],
    "abstract": "Federated domain generalization has shown promising progress in image classification by enabling collaborative training across multiple clients without sharing raw data. However, its potential in the semantic segmentation of autonomous driving remains underexplored. In this paper, we propose FedS2R, the first one-shot federated domain generalization framework for synthetic-to-real semantic segmentation in autonomous driving. FedS2R comprises two components: an inconsistency-driven data augmentation strategy that generates images for unstable classes, and a multi-client knowledge distillation scheme with feature fusion that distills a global model from multiple client models. Experiments on five real-world datasets, Cityscapes, BDD100K, Mapillary, IDD, and ACDC, show that the global model significantly outperforms individual client models and is only 2 mIoU points behind the model trained with simultaneous access to all client data. These results demonstrate the effectiveness of FedS2R in synthetic-to-real semantic segmentation for autonomous driving under federated learning",
    "categories": [
      "cs.CV",
      "cs.AI"
    ],
    "primary_category": "cs.CV",
    "comment": "",
    "pdf_url": "https://arxiv.org/pdf/2507.19881v1",
    "published_date": "2025-07-26 09:24:00 UTC",
    "updated_date": "2025-07-26 09:24:00 UTC"
  },
  {
    "arxiv_id": "2507.19880v1",
    "title": "Trivial Trojans: How Minimal MCP Servers Enable Cross-Tool Exfiltration of Sensitive Data",
    "authors": [
      "Nicola Croce",
      "Tobin South"
    ],
    "abstract": "The Model Context Protocol (MCP) represents a significant advancement in AI-tool integration, enabling seamless communication between AI agents and external services. However, this connectivity introduces novel attack vectors that remain largely unexplored. This paper demonstrates how unsophisticated threat actors, requiring only basic programming skills and free web tools, can exploit MCP's trust model to exfiltrate sensitive financial data. We present a proof-of-concept attack where a malicious weather MCP server, disguised as benign functionality, discovers and exploits legitimate banking tools to steal user account balances. The attack chain requires no advanced technical knowledge, server infrastructure, or monetary investment. The findings reveal a critical security gap in the emerging MCP ecosystem: while individual servers may appear trustworthy, their combination creates unexpected cross-server attack surfaces. Unlike traditional cybersecurity threats that assume sophisticated adversaries, our research shows that the barrier to entry for MCP-based attacks is alarmingly low. A threat actor with undergraduate-level Python knowledge can craft convincing social engineering attacks that exploit the implicit trust relationships MCP establishes between AI agents and tool providers. This work contributes to the nascent field of MCP security by demonstrating that current MCP implementations allow trivial cross-server attacks and proposing both immediate mitigations and protocol improvements to secure this emerging ecosystem.",
    "categories": [
      "cs.CR",
      "cs.AI"
    ],
    "primary_category": "cs.CR",
    "comment": "Abstract submitted to the Technical AI Governance Forum 2025 (https://www.techgov.ai/)",
    "pdf_url": "https://arxiv.org/pdf/2507.19880v1",
    "published_date": "2025-07-26 09:22:40 UTC",
    "updated_date": "2025-07-26 09:22:40 UTC"
  },
  {
    "arxiv_id": "2507.19856v3",
    "title": "RaGS: Unleashing 3D Gaussian Splatting from 4D Radar and Monocular Cues for 3D Object Detection",
    "authors": [
      "Xiaokai Bai",
      "Chenxu Zhou",
      "Lianqing Zheng",
      "Si-Yuan Cao",
      "Jianan Liu",
      "Xiaohan Zhang",
      "Yiming Li",
      "Zhengzhuang Zhang",
      "Hui-liang Shen"
    ],
    "abstract": "4D millimeter-wave radar is a promising sensing modality for autonomous driving, yet effective 3D object detection from 4D radar and monocular images remains challenging. Existing fusion approaches either rely on instance proposals lacking global context or dense BEV grids constrained by rigid structures, lacking a flexible and adaptive representation for diverse scenes. To address this, we propose RaGS, the first framework that leverages 3D Gaussian Splatting (GS) to fuse 4D radar and monocular cues for 3D object detection. 3D GS models the scene as a continuous field of Gaussians, enabling dynamic resource allocation to foreground objects while maintaining flexibility and efficiency. Moreover, the velocity dimension of 4D radar provides motion cues that help anchor and refine the spatial distribution of Gaussians. Specifically, RaGS adopts a cascaded pipeline to construct and progressively refine the Gaussian field. It begins with Frustum-based Localization Initiation (FLI), which unprojects foreground pixels to initialize coarse Gaussian centers. Then, Iterative Multimodal Aggregation (IMA) explicitly exploits image semantics and implicitly integrates 4D radar velocity geometry to refine the Gaussians within regions of interest. Finally, Multi-level Gaussian Fusion (MGF) renders the Gaussian field into hierarchical BEV features for 3D object detection. By dynamically focusing on sparse and informative regions, RaGS achieves object-centric precision and comprehensive scene perception. Extensive experiments on View-of-Delft, TJ4DRadSet, and OmniHD-Scenes demonstrate its robustness and SOTA performance. Code will be released.",
    "categories": [
      "cs.CV",
      "cs.AI"
    ],
    "primary_category": "cs.CV",
    "comment": "",
    "pdf_url": "https://arxiv.org/pdf/2507.19856v3",
    "published_date": "2025-07-26 08:17:12 UTC",
    "updated_date": "2025-11-08 15:42:10 UTC"
  },
  {
    "arxiv_id": "2507.19849v1",
    "title": "Agentic Reinforced Policy Optimization",
    "authors": [
      "Guanting Dong",
      "Hangyu Mao",
      "Kai Ma",
      "Licheng Bao",
      "Yifei Chen",
      "Zhongyuan Wang",
      "Zhongxia Chen",
      "Jiazhen Du",
      "Huiyang Wang",
      "Fuzheng Zhang",
      "Guorui Zhou",
      "Yutao Zhu",
      "Ji-Rong Wen",
      "Zhicheng Dou"
    ],
    "abstract": "Large-scale reinforcement learning with verifiable rewards (RLVR) has demonstrated its effectiveness in harnessing the potential of large language models (LLMs) for single-turn reasoning tasks. In realistic reasoning scenarios, LLMs can often utilize external tools to assist in task-solving processes. However, current RL algorithms inadequately balance the models' intrinsic long-horizon reasoning capabilities and their proficiency in multi-turn tool interactions. To bridge this gap, we propose Agentic Reinforced Policy Optimization (ARPO), a novel agentic RL algorithm tailored for training multi-turn LLM-based agents. Through preliminary experiments, we observe that LLMs tend to exhibit highly uncertain behavior, characterized by an increase in the entropy distribution of generated tokens, immediately following interactions with external tools. Motivated by this observation, ARPO incorporates an entropy-based adaptive rollout mechanism, dynamically balancing global trajectory sampling and step-level sampling, thereby promoting exploration at steps with high uncertainty after tool usage. By integrating an advantage attribution estimation, ARPO enables LLMs to internalize advantage differences in stepwise tool-use interactions. Our experiments across 13 challenging benchmarks in computational reasoning, knowledge reasoning, and deep search domains demonstrate ARPO's superiority over trajectory-level RL algorithms. Remarkably, ARPO achieves improved performance using only half of the tool-use budget required by existing methods, offering a scalable solution for aligning LLM-based agents with real-time dynamic environments. Our code and datasets are released at https://github.com/dongguanting/ARPO",
    "categories": [
      "cs.LG",
      "cs.AI",
      "cs.CL"
    ],
    "primary_category": "cs.LG",
    "comment": "Working on progress",
    "pdf_url": "https://arxiv.org/pdf/2507.19849v1",
    "published_date": "2025-07-26 07:53:11 UTC",
    "updated_date": "2025-07-26 07:53:11 UTC"
  },
  {
    "arxiv_id": "2507.19844v1",
    "title": "VAE-GAN Based Price Manipulation in Coordinated Local Energy Markets",
    "authors": [
      "Biswarup Mukherjee",
      "Li Zhou",
      "S. Gokul Krishnan",
      "Milad Kabirifar",
      "Subhash Lakshminarayana",
      "Charalambos Konstantinou"
    ],
    "abstract": "This paper introduces a model for coordinating prosumers with heterogeneous distributed energy resources (DERs), participating in the local energy market (LEM) that interacts with the market-clearing entity. The proposed LEM scheme utilizes a data-driven, model-free reinforcement learning approach based on the multi-agent deep deterministic policy gradient (MADDPG) framework, enabling prosumers to make real-time decisions on whether to buy, sell, or refrain from any action while facilitating efficient coordination for optimal energy trading in a dynamic market. In addition, we investigate a price manipulation strategy using a variational auto encoder-generative adversarial network (VAE-GAN) model, which allows utilities to adjust price signals in a way that induces financial losses for the prosumers. Our results show that under adversarial pricing, heterogeneous prosumer groups, particularly those lacking generation capabilities, incur financial losses. The same outcome holds across LEMs of different sizes. As the market size increases, trading stabilizes and fairness improves through emergent cooperation among agents.",
    "categories": [
      "cs.LG",
      "cs.AI",
      "cs.MA",
      "eess.SY"
    ],
    "primary_category": "cs.LG",
    "comment": "2025 IEEE International Conference on Communications, Control, and Computing Technologies for Smart Grids (SmartGridComm)",
    "pdf_url": "https://arxiv.org/pdf/2507.19844v1",
    "published_date": "2025-07-26 07:38:27 UTC",
    "updated_date": "2025-07-26 07:38:27 UTC"
  },
  {
    "arxiv_id": "2507.19842v2",
    "title": "A Cooperative Approach for Knowledge-based Business Process Design in a Public Authority",
    "authors": [
      "Mohammad Azarijafari",
      "Luisa Mich",
      "Michele Missikoff",
      "Oleg Missikoff"
    ],
    "abstract": "Enterprises are currently undergoing profound transformations due to the unpostponable digital transformation. Then, to remain competitive, enterprises must adapt digital solutions, transforming their organisational structures and operations. This organisational shift is also important for small and medium-sized enterprises. A key innovation frontier is the adoption of process-oriented production models. This paper presents a knowledge-based method to support business experts in designing business processes. The method requires no prior expertise in Knowledge Engineering and guides designers through a structured sequence of steps to produce a diagrammatic workflow of the target process. The construction of the knowledge base starts from simple, text-based, knowledge artefacts and then progresses towards more structured, formal representations. The approach has been conceived to allow a shared approach for all stakeholders and actors who participate in the BP design.",
    "categories": [
      "cs.SE",
      "cs.AI"
    ],
    "primary_category": "cs.SE",
    "comment": "",
    "pdf_url": "https://arxiv.org/pdf/2507.19842v2",
    "published_date": "2025-07-26 07:31:28 UTC",
    "updated_date": "2025-10-14 13:38:17 UTC"
  },
  {
    "arxiv_id": "2507.19840v1",
    "title": "AutoSign: Direct Pose-to-Text Translation for Continuous Sign Language Recognition",
    "authors": [
      "Samuel Ebimobowei Johnny",
      "Blessed Guda",
      "Andrew Blayama Stephen",
      "Assane Gueye"
    ],
    "abstract": "Continuously recognizing sign gestures and converting them to glosses plays a key role in bridging the gap between the hearing and hearing-impaired communities. This involves recognizing and interpreting the hands, face, and body gestures of the signer, which pose a challenge as it involves a combination of all these features. Continuous Sign Language Recognition (CSLR) methods rely on multi-stage pipelines that first extract visual features, then align variable-length sequences with target glosses using CTC or HMM-based approaches. However, these alignment-based methods suffer from error propagation across stages, overfitting, and struggle with vocabulary scalability due to the intermediate gloss representation bottleneck. To address these limitations, we propose AutoSign, an autoregressive decoder-only transformer that directly translates pose sequences to natural language text, bypassing traditional alignment mechanisms entirely. The use of this decoder-only approach allows the model to directly map between the features and the glosses without the need for CTC loss while also directly learning the textual dependencies in the glosses. Our approach incorporates a temporal compression module using 1D CNNs to efficiently process pose sequences, followed by AraGPT2, a pre-trained Arabic decoder, to generate text (glosses). Through comprehensive ablation studies, we demonstrate that hand and body gestures provide the most discriminative features for signer-independent CSLR. By eliminating the multi-stage pipeline, AutoSign achieves substantial improvements on the Isharah-1000 dataset, achieving an improvement of up to 6.1\\% in WER score compared to the best existing method.",
    "categories": [
      "cs.CV",
      "cs.AI",
      "cs.CL"
    ],
    "primary_category": "cs.CV",
    "comment": "Paper to appear at the 1st Workshop in Multimodal Sign Language Recognition at ICCV 2025",
    "pdf_url": "https://arxiv.org/pdf/2507.19840v1",
    "published_date": "2025-07-26 07:28:33 UTC",
    "updated_date": "2025-07-26 07:28:33 UTC"
  },
  {
    "arxiv_id": "2507.19836v1",
    "title": "ChoreoMuse: Robust Music-to-Dance Video Generation with Style Transfer and Beat-Adherent Motion",
    "authors": [
      "Xuanchen Wang",
      "Heng Wang",
      "Weidong Cai"
    ],
    "abstract": "Modern artistic productions increasingly demand automated choreography generation that adapts to diverse musical styles and individual dancer characteristics. Existing approaches often fail to produce high-quality dance videos that harmonize with both musical rhythm and user-defined choreography styles, limiting their applicability in real-world creative contexts. To address this gap, we introduce ChoreoMuse, a diffusion-based framework that uses SMPL format parameters and their variation version as intermediaries between music and video generation, thereby overcoming the usual constraints imposed by video resolution. Critically, ChoreoMuse supports style-controllable, high-fidelity dance video generation across diverse musical genres and individual dancer characteristics, including the flexibility to handle any reference individual at any resolution. Our method employs a novel music encoder MotionTune to capture motion cues from audio, ensuring that the generated choreography closely follows the beat and expressive qualities of the input music. To quantitatively evaluate how well the generated dances match both musical and choreographic styles, we introduce two new metrics that measure alignment with the intended stylistic cues. Extensive experiments confirm that ChoreoMuse achieves state-of-the-art performance across multiple dimensions, including video quality, beat alignment, dance diversity, and style adherence, demonstrating its potential as a robust solution for a wide range of creative applications. Video results can be found on our project page: https://choreomuse.github.io.",
    "categories": [
      "cs.GR",
      "cs.AI",
      "cs.CV",
      "cs.MM",
      "cs.SD"
    ],
    "primary_category": "cs.GR",
    "comment": "10 pages, 5 figures, accepted by the 33rd ACM International Conference on Multimedia (ACM MM 2025), demo page: https://choreomuse.github.io",
    "pdf_url": "https://arxiv.org/pdf/2507.19836v1",
    "published_date": "2025-07-26 07:17:50 UTC",
    "updated_date": "2025-07-26 07:17:50 UTC"
  },
  {
    "arxiv_id": "2507.19823v1",
    "title": "HCAttention: Extreme KV Cache Compression via Heterogeneous Attention Computing for LLMs",
    "authors": [
      "Dongquan Yang",
      "Yifan Yang",
      "Xiaotian Yu",
      "Xianbiao Qi",
      "Rong Xiao"
    ],
    "abstract": "Processing long-context inputs with large language models presents a significant challenge due to the enormous memory requirements of the Key-Value (KV) cache during inference. Existing KV cache compression methods exhibit noticeable performance degradation when memory is reduced by more than 85%. Additionally, strategies that leverage GPU-CPU collaboration for approximate attention remain underexplored in this setting. We propose HCAttention, a heterogeneous attention computation framework that integrates key quantization, value offloading, and dynamic KV eviction to enable efficient inference under extreme memory constraints. The method is compatible with existing transformer architectures and does not require model fine-tuning. Experimental results on the LongBench benchmark demonstrate that our approach preserves the accuracy of full-attention model while shrinking the KV cache memory footprint to 25% of its original size. Remarkably, it stays competitive with only 12.5% of the cache, setting a new state-of-the-art in LLM KV cache compression. To the best of our knowledge, HCAttention is the first to extend the Llama-3-8B model to process 4 million tokens on a single A100 GPU with 80GB memory.",
    "categories": [
      "cs.CL",
      "cs.AI",
      "cs.LG"
    ],
    "primary_category": "cs.CL",
    "comment": "",
    "pdf_url": "https://arxiv.org/pdf/2507.19823v1",
    "published_date": "2025-07-26 06:43:14 UTC",
    "updated_date": "2025-07-26 06:43:14 UTC"
  },
  {
    "arxiv_id": "2507.19806v1",
    "title": "From Few-Label to Zero-Label: An Approach for Cross-System Log-Based Anomaly Detection with Meta-Learning",
    "authors": [
      "Xinlong Zhao",
      "Tong Jia",
      "Minghua He",
      "Yihan Wu",
      "Ying Li",
      "Gang Huang"
    ],
    "abstract": "Log anomaly detection plays a critical role in ensuring the stability and reliability of software systems. However, existing approaches rely on large amounts of labeled log data, which poses significant challenges in real-world applications. To address this issue, cross-system transfer has been identified as a key research direction. State-of-the-art cross-system approaches achieve promising performance with only a few labels from the target system. However, their reliance on labeled target logs makes them susceptible to the cold-start problem when labeled logs are insufficient. To overcome this limitation, we explore a novel yet underexplored setting: zero-label cross-system log anomaly detection, where the target system logs are entirely unlabeled. To this end, we propose FreeLog, a system-agnostic representation meta-learning method that eliminates the need for labeled target system logs, enabling cross-system log anomaly detection under zero-label conditions. Experimental results on three public log datasets demonstrate that FreeLog achieves performance comparable to state-of-the-art methods that rely on a small amount of labeled data from the target system.",
    "categories": [
      "cs.SE",
      "cs.AI"
    ],
    "primary_category": "cs.SE",
    "comment": "5 pages, 1 figures, FSE 2025",
    "pdf_url": "https://arxiv.org/pdf/2507.19806v1",
    "published_date": "2025-07-26 05:38:51 UTC",
    "updated_date": "2025-07-26 05:38:51 UTC"
  },
  {
    "arxiv_id": "2507.19803v1",
    "title": "AI-Based Clinical Rule Discovery for NMIBC Recurrence through Tsetlin Machines",
    "authors": [
      "Saram Abbas",
      "Naeem Soomro",
      "Rishad Shafik",
      "Rakesh Heer",
      "Kabita Adhikari"
    ],
    "abstract": "Bladder cancer claims one life every 3 minutes worldwide. Most patients are diagnosed with non-muscle-invasive bladder cancer (NMIBC), yet up to 70% recur after treatment, triggering a relentless cycle of surgeries, monitoring, and risk of progression. Clinical tools like the EORTC risk tables are outdated and unreliable - especially for intermediate-risk cases.\n  We propose an interpretable AI model using the Tsetlin Machine (TM), a symbolic learner that outputs transparent, human-readable logic. Tested on the PHOTO trial dataset (n=330), TM achieved an F1-score of 0.80, outperforming XGBoost (0.78), Logistic Regression (0.60), and EORTC (0.42). TM reveals the exact clauses behind each prediction, grounded in clinical features like tumour count, surgeon experience, and hospital stay - offering accuracy and full transparency. This makes TM a powerful, trustworthy decision-support tool ready for real-world adoption.",
    "categories": [
      "cs.LG",
      "cs.AI"
    ],
    "primary_category": "cs.LG",
    "comment": "Submitted to ISTM 2025",
    "pdf_url": "https://arxiv.org/pdf/2507.19803v1",
    "published_date": "2025-07-26 05:32:13 UTC",
    "updated_date": "2025-07-26 05:32:13 UTC"
  },
  {
    "arxiv_id": "2507.19788v1",
    "title": "Reinforcement Learning for Multi-Objective Multi-Echelon Supply Chain Optimisation",
    "authors": [
      "Rifny Rachman",
      "Josh Tingey",
      "Richard Allmendinger",
      "Pradyumn Shukla",
      "Wei Pan"
    ],
    "abstract": "This study develops a generalised multi-objective, multi-echelon supply chain optimisation model with non-stationary markets based on a Markov decision process, incorporating economic, environmental, and social considerations. The model is evaluated using a multi-objective reinforcement learning (RL) method, benchmarked against an originally single-objective RL algorithm modified with weighted sum using predefined weights, and a multi-objective evolutionary algorithm (MOEA)-based approach. We conduct experiments on varying network complexities, mimicking typical real-world challenges using a customisable simulator. The model determines production and delivery quantities across supply chain routes to achieve near-optimal trade-offs between competing objectives, approximating Pareto front sets. The results demonstrate that the primary approach provides the most balanced trade-off between optimality, diversity, and density, further enhanced with a shared experience buffer that allows knowledge transfer among policies. In complex settings, it achieves up to 75\\% higher hypervolume than the MOEA-based method and generates solutions that are approximately eleven times denser, signifying better robustness, than those produced by the modified single-objective RL method. Moreover, it ensures stable production and inventory levels while minimising demand loss.",
    "categories": [
      "cs.AI"
    ],
    "primary_category": "cs.AI",
    "comment": "",
    "pdf_url": "https://arxiv.org/pdf/2507.19788v1",
    "published_date": "2025-07-26 04:30:11 UTC",
    "updated_date": "2025-07-26 04:30:11 UTC"
  },
  {
    "arxiv_id": "2507.19771v1",
    "title": "Large Language Model Agent for Structural Drawing Generation Using ReAct Prompt Engineering and Retrieval Augmented Generation",
    "authors": [
      "Xin Zhang",
      "Lissette Iturburu",
      "Juan Nicolas Villamizar",
      "Xiaoyu Liu",
      "Manuel Salmeron",
      "Shirley J. Dyke",
      "Julio Ramirez"
    ],
    "abstract": "Structural drawings are widely used in many fields, e.g., mechanical engineering, civil engineering, etc. In civil engineering, structural drawings serve as the main communication tool between architects, engineers, and builders to avoid conflicts, act as legal documentation, and provide a reference for future maintenance or evaluation needs. They are often organized using key elements such as title/subtitle blocks, scales, plan views, elevation view, sections, and detailed sections, which are annotated with standardized symbols and line types for interpretation by engineers and contractors. Despite advances in software capabilities, the task of generating a structural drawing remains labor-intensive and time-consuming for structural engineers. Here we introduce a novel generative AI-based method for generating structural drawings employing a large language model (LLM) agent. The method incorporates a retrieval-augmented generation (RAG) technique using externally-sourced facts to enhance the accuracy and reliability of the language model. This method is capable of understanding varied natural language descriptions, processing these to extract necessary information, and generating code to produce the desired structural drawing in AutoCAD. The approach developed, demonstrated and evaluated herein enables the efficient and direct conversion of a structural drawing's natural language description into an AutoCAD drawing, significantly reducing the workload compared to current working process associated with manual drawing production, facilitating the typical iterative process of engineers for expressing design ideas in a simplified way.",
    "categories": [
      "cs.LG",
      "cs.AI"
    ],
    "primary_category": "cs.LG",
    "comment": "",
    "pdf_url": "https://arxiv.org/pdf/2507.19771v1",
    "published_date": "2025-07-26 03:47:12 UTC",
    "updated_date": "2025-07-26 03:47:12 UTC"
  },
  {
    "arxiv_id": "2507.19766v1",
    "title": "UloRL:An Ultra-Long Output Reinforcement Learning Approach for Advancing Large Language Models' Reasoning Abilities",
    "authors": [
      "Dong Du",
      "Shulin Liu",
      "Tao Yang",
      "Shaohua Chen",
      "Yang Li"
    ],
    "abstract": "Recent advances in large language models (LLMs) have highlighted the potential of reinforcement learning with verifiable rewards (RLVR) to enhance reasoning capabilities through extended output sequences. However, traditional RL frameworks face inefficiencies when handling ultra-long outputs due to long-tail sequence distributions and entropy collapse during training. To address these challenges, we propose an Ultra-Long Output Reinforcement Learning (UloRL) approach for advancing large language models' reasoning abilities. Specifically, we divide ultra long output decoding into short segments, enabling efficient training by mitigating delays caused by long-tail samples. Additionally, we introduce dynamic masking of well-Mastered Positive Tokens (MPTs) to prevent entropy collapse. Experimental results demonstrate the effectiveness of our approach. On the Qwen3-30B-A3B model, RL with segment rollout achieved 2.06x increase in training speed, while RL training with 128k-token outputs improves the model's performance on AIME2025 from 70.9\\% to 85.1\\% and on BeyondAIME from 50.7\\% to 61.9\\%, even surpassing Qwen3-235B-A22B with remarkable gains. These findings underscore the potential of our methods to advance the reasoning capabilities of LLMs with ultra-long sequence generation. We will release our code and model for further use by the community.",
    "categories": [
      "cs.CL",
      "cs.AI"
    ],
    "primary_category": "cs.CL",
    "comment": "12 pages",
    "pdf_url": "https://arxiv.org/pdf/2507.19766v1",
    "published_date": "2025-07-26 03:42:33 UTC",
    "updated_date": "2025-07-26 03:42:33 UTC"
  },
  {
    "arxiv_id": "2508.05650v1",
    "title": "OmniBench-RAG: A Multi-Domain Evaluation Platform for Retrieval-Augmented Generation Tools",
    "authors": [
      "Jiaxuan Liang",
      "Shide Zhou",
      "Kailong Wang"
    ],
    "abstract": "While Retrieval Augmented Generation (RAG) is now widely adopted to enhance LLMs, evaluating its true performance benefits in a reproducible and interpretable way remains a major hurdle. Existing methods often fall short: they lack domain coverage, employ coarse metrics that miss sub document precision, and fail to capture computational trade offs. Most critically, they provide no standardized framework for comparing RAG effectiveness across different models and domains.\n  We introduce OmniBench RAG, a novel automated platform for multi domain evaluation of RAG systems. The platform quantifies performance gains across accuracy and efficiency dimensions, spanning nine knowledge fields including culture, geography, and health. We introduce two standardized metrics: Improvements (accuracy gains) and Transformation (efficiency differences between pre RAG and post RAG models), enabling reproducible comparisons across models and tasks. The platform features dynamic test generation, modular evaluation pipelines, and automated knowledge base construction. Our evaluation reveals striking variability in RAG effectiveness, from significant gains in culture to declines in mathematics, highlighting the critical importance of systematic, domain aware assessment. A demonstration video is available at: https://www.youtube.com/watch?v=BZx83QFcTCI. Code and datasets: https://github.com/Garnett-Liang/Omnibench-RAG.",
    "categories": [
      "cs.IR",
      "cs.AI"
    ],
    "primary_category": "cs.IR",
    "comment": "",
    "pdf_url": "https://arxiv.org/pdf/2508.05650v1",
    "published_date": "2025-07-26 03:29:15 UTC",
    "updated_date": "2025-07-26 03:29:15 UTC"
  },
  {
    "arxiv_id": "2507.19755v1",
    "title": "Modeling enzyme temperature stability from sequence segment perspective",
    "authors": [
      "Ziqi Zhang",
      "Shiheng Chen",
      "Runze Yang",
      "Zhisheng Wei",
      "Wei Zhang",
      "Lei Wang",
      "Zhanzhi Liu",
      "Fengshan Zhang",
      "Jing Wu",
      "Xiaoyong Pan",
      "Hongbin Shen",
      "Longbing Cao",
      "Zhaohong Deng"
    ],
    "abstract": "Developing enzymes with desired thermal properties is crucial for a wide range of industrial and research applications, and determining temperature stability is an essential step in this process. Experimental determination of thermal parameters is labor-intensive, time-consuming, and costly. Moreover, existing computational approaches are often hindered by limited data availability and imbalanced distributions. To address these challenges, we introduce a curated temperature stability dataset designed for model development and benchmarking in enzyme thermal modeling. Leveraging this dataset, we present the \\textit{Segment Transformer}, a novel deep learning framework that enables efficient and accurate prediction of enzyme temperature stability. The model achieves state-of-the-art performance with an RMSE of 24.03, MAE of 18.09, and Pearson and Spearman correlations of 0.33, respectively. These results highlight the effectiveness of incorporating segment-level representations, grounded in the biological observation that different regions of a protein sequence contribute unequally to thermal behavior. As a proof of concept, we applied the Segment Transformer to guide the engineering of a cutinase enzyme. Experimental validation demonstrated a 1.64-fold improvement in relative activity following heat treatment, achieved through only 17 mutations and without compromising catalytic function.",
    "categories": [
      "cs.LG",
      "cs.AI",
      "q-bio.BM",
      "q-bio.QM"
    ],
    "primary_category": "cs.LG",
    "comment": "",
    "pdf_url": "https://arxiv.org/pdf/2507.19755v1",
    "published_date": "2025-07-26 03:01:58 UTC",
    "updated_date": "2025-07-26 03:01:58 UTC"
  },
  {
    "arxiv_id": "2507.19749v1",
    "title": "Can LLMs Solve ASP Problems? Insights from a Benchmarking Study (Extended Version)",
    "authors": [
      "Lin Ren",
      "Guohui Xiao",
      "Guilin Qi",
      "Yishuai Geng",
      "Haohan Xue"
    ],
    "abstract": "Answer Set Programming (ASP) is a powerful paradigm for non-monotonic reasoning. Recently, large language models (LLMs) have demonstrated promising capabilities in logical reasoning. Despite this potential, current evaluations of LLM capabilities in ASP are often limited. Existing works normally employ overly simplified ASP programs, do not support negation, disjunction, or multiple answer sets. Furthermore, there is a lack of benchmarks that introduce tasks specifically designed for ASP solving. To bridge this gap, we introduce ASPBench, a comprehensive ASP benchmark, including three ASP specific tasks: ASP entailment, answer set verification, and answer set computation. Our extensive evaluations on ASPBench reveal that while 14 state-of-the-art LLMs, including \\emph{deepseek-r1}, \\emph{o4-mini}, and \\emph{gemini-2.5-flash-thinking}, perform relatively well on the first two simpler tasks, they struggle with answer set computation, which is the core of ASP solving. These findings offer insights into the current limitations of LLMs in ASP solving. This highlights the need for new approaches that integrate symbolic reasoning capabilities more effectively. The code and dataset are available at https://github.com/HomuraT/ASPBench.",
    "categories": [
      "cs.AI"
    ],
    "primary_category": "cs.AI",
    "comment": "Accepted for publication at the 22nd International Conference on Principles of Knowledge Representation and Reasoning (KR 2025). The code is available at https://github.com/HomuraT/ASPBench",
    "pdf_url": "https://arxiv.org/pdf/2507.19749v1",
    "published_date": "2025-07-26 02:46:08 UTC",
    "updated_date": "2025-07-26 02:46:08 UTC"
  },
  {
    "arxiv_id": "2507.21176v2",
    "title": "Toward Revealing Nuanced Biases in Medical LLMs",
    "authors": [
      "Farzana Islam Adiba",
      "Rahmatollah Beheshti"
    ],
    "abstract": "Large language models (LLMs) used in medical applications are known to be prone to exhibiting biased and unfair patterns. Prior to deploying these in clinical decision-making, it is crucial to identify such bias patterns to enable effective mitigation and minimize negative impacts. In this study, we present a novel framework combining knowledge graphs (KGs) with auxiliary (agentic) LLMs to systematically reveal complex bias patterns in medical LLMs. The proposed approach integrates adversarial perturbation (red teaming) techniques to identify subtle bias patterns and adopts a customized multi-hop characterization of KGs to enhance the systematic evaluation of target LLMs. It aims not only to generate more effective red-teaming questions for bias evaluation but also to utilize those questions more effectively in revealing complex biases. Through a series of comprehensive experiments on three datasets, six LLMs, and five bias types, we demonstrate that our proposed framework exhibits a noticeably greater ability and scalability in revealing complex biased patterns of medical LLMs compared to other common approaches.",
    "categories": [
      "cs.AI"
    ],
    "primary_category": "cs.AI",
    "comment": "",
    "pdf_url": "https://arxiv.org/pdf/2507.21176v2",
    "published_date": "2025-07-26 02:33:48 UTC",
    "updated_date": "2025-12-21 03:06:37 UTC"
  },
  {
    "arxiv_id": "2507.19743v1",
    "title": "Defining ethically sourced code generation",
    "authors": [
      "Zhuolin Xu",
      "Chenglin Li",
      "Qiushi Li",
      "Shin Hwei Tan"
    ],
    "abstract": "Several code generation models have been proposed to help reduce time and effort in solving software-related tasks. To ensure responsible AI, there are growing interests over various ethical issues (e.g., unclear licensing, privacy, fairness, and environment impact). These studies have the overarching goal of ensuring ethically sourced generation, which has gained growing attentions in speech synthesis and image generation. In this paper, we introduce the novel notion of Ethically Sourced Code Generation (ES-CodeGen) to refer to managing all processes involved in code generation model development from data collection to post-deployment via ethical and sustainable practices. To build a taxonomy of ES-CodeGen, we perform a two-phase literature review where we read 803 papers across various domains and specific to AI-based code generation. We identified 71 relevant papers with 10 initial dimensions of ES-CodeGen. To refine our dimensions and gain insights on consequences of ES-CodeGen, we surveyed 32 practitioners, which include six developers who submitted GitHub issues to opt-out from the Stack dataset (these impacted users have real-world experience of ethically sourcing issues in code generation models). The results lead to 11 dimensions of ES-CodeGen with a new dimension on code quality as practitioners have noted its importance. We also identified consequences, artifacts, and stages relevant to ES-CodeGen. Our post-survey reflection showed that most practitioners tend to ignore social-related dimensions despite their importance. Most practitioners either agreed or strongly agreed that our survey help improve their understanding of ES-CodeGen. Our study calls for attentions of various ethical issues towards ES-CodeGen.",
    "categories": [
      "cs.SE",
      "cs.AI"
    ],
    "primary_category": "cs.SE",
    "comment": "",
    "pdf_url": "https://arxiv.org/pdf/2507.19743v1",
    "published_date": "2025-07-26 02:27:06 UTC",
    "updated_date": "2025-07-26 02:27:06 UTC"
  },
  {
    "arxiv_id": "2507.21174v2",
    "title": "A ChatGPT-based approach for questions generation in higher education",
    "authors": [
      "Sinh Trong Vu",
      "Huong Thu Truong",
      "Oanh Tien Do",
      "Tu Anh Le",
      "Tai Tan Mai"
    ],
    "abstract": "Large language models have been widely applied in many aspects of real life, bringing significant efficiency to businesses and offering distinctive user experiences. In this paper, we focus on exploring the application of ChatGPT, a chatbot based on a large language model, to support higher educator in generating quiz questions and assessing learners. Specifically, we explore interactive prompting patterns to design an optimal AI-powered question bank creation process. The generated questions are evaluated through a \"Blind test\" survey sent to various stakeholders including lecturers and learners. Initial results at the Banking Academy of Vietnam are relatively promising, suggesting a potential direction to streamline the time and effort involved in assessing learners at higher education institutes.",
    "categories": [
      "cs.CY",
      "cs.AI"
    ],
    "primary_category": "cs.CY",
    "comment": "Proceedings of the 1st ACM Workshop on AI-Powered Q&A Systems for Multimedia. 2024",
    "pdf_url": "https://arxiv.org/pdf/2507.21174v2",
    "published_date": "2025-07-26 01:54:12 UTC",
    "updated_date": "2025-07-30 03:29:41 UTC"
  },
  {
    "arxiv_id": "2507.19737v1",
    "title": "Predicting Human Mobility in Disasters via LLM-Enhanced Cross-City Learning",
    "authors": [
      "Yinzhou Tang",
      "Huandong Wang",
      "Xiaochen Fan",
      "Yong Li"
    ],
    "abstract": "The vulnerability of cities to natural disasters has increased with urbanization and climate change, making it more important to predict human mobility in the disaster scenarios for downstream tasks including location-based early disaster warning and pre-allocating rescue resources, etc. However, existing human mobility prediction models are mainly designed for normal scenarios, and fail to adapt to disaster scenarios due to the shift of human mobility patterns under disaster. To address this issue, we introduce \\textbf{DisasterMobLLM}, a mobility prediction framework for disaster scenarios that can be integrated into existing deep mobility prediction methods by leveraging LLMs to model the mobility intention and transferring the common knowledge of how different disasters affect mobility intentions between cities. This framework utilizes a RAG-Enhanced Intention Predictor to forecast the next intention, refines it with an LLM-based Intention Refiner, and then maps the intention to an exact location using an Intention-Modulated Location Predictor. Extensive experiments illustrate that DisasterMobLLM can achieve a 32.8\\% improvement in terms of Acc@1 and a 35.0\\% improvement in terms of the F1-score of predicting immobility compared to the baselines. The code is available at https://github.com/tsinghua-fib-lab/DisasterMobLLM.",
    "categories": [
      "cs.LG",
      "cs.AI",
      "cs.CY"
    ],
    "primary_category": "cs.LG",
    "comment": "",
    "pdf_url": "https://arxiv.org/pdf/2507.19737v1",
    "published_date": "2025-07-26 01:45:27 UTC",
    "updated_date": "2025-07-26 01:45:27 UTC"
  },
  {
    "arxiv_id": "2507.19733v3",
    "title": "Integrating Activity Predictions in Knowledge Graphs",
    "authors": [
      "Forrest Hare",
      "Alec Sculley",
      "Cameron Stockton"
    ],
    "abstract": "We argue that ontology-structured knowledge graphs can play a crucial role in generating predictions about future events. By leveraging the semantic framework provided by Basic Formal Ontology (BFO) and Common Core Ontologies (CCO), we demonstrate how data such as the movements of a fishing vessel can be organized in and retrieved from a knowledge graph. These query results are then used to create Markov chain models, allowing us to predict future states based on the vessel's history. To fully support this process, we introduce the term `spatiotemporal instant' to complete the necessary structural semantics. Additionally, we critique the prevailing ontological model of probability, according to which probabilities are about the future. We propose an alternative view, where at least some probabilities are treated as being about actual process profiles, which better captures the dynamics of real-world phenomena. Finally, we demonstrate how our Markov chain-based probability calculations can be seamlessly integrated back into the knowledge graph, enabling further analysis and decision-making.",
    "categories": [
      "cs.AI",
      "cs.DB"
    ],
    "primary_category": "cs.AI",
    "comment": "21 pages. 18 figures. Conference: Semantic Technology for Intelligence, Defense, and Security (STIDS 2024)",
    "pdf_url": "https://arxiv.org/pdf/2507.19733v3",
    "published_date": "2025-07-26 01:22:06 UTC",
    "updated_date": "2025-09-18 23:28:04 UTC"
  },
  {
    "arxiv_id": "2507.21172v1",
    "title": "Ontological Foundations of State Sovereignty",
    "authors": [
      "John Beverley",
      "Danielle Limbaugh"
    ],
    "abstract": "This short paper is a primer on the nature of state sovereignty and the importance of claims about it. It also aims to reveal (merely reveal) a strategy for working with vague or contradictory data about which states, in fact, are sovereign. These goals together are intended to set the stage for applied work in ontology about international affairs.",
    "categories": [
      "cs.AI"
    ],
    "primary_category": "cs.AI",
    "comment": "6 pages. 0 figures. Conference: Semantic Technology for Intelligence, Defense, and Security (STIDS 2024)",
    "pdf_url": "https://arxiv.org/pdf/2507.21172v1",
    "published_date": "2025-07-26 01:21:25 UTC",
    "updated_date": "2025-07-26 01:21:25 UTC"
  },
  {
    "arxiv_id": "2507.19730v1",
    "title": "Quaternion-Based Robust PCA for Efficient Moving Target Detection and Background Recovery in Color Videos",
    "authors": [
      "Liyang Wang",
      "Shiqian Wu",
      "Shun Fang",
      "Qile Zhu",
      "Jiaxin Wu",
      "Sos Again"
    ],
    "abstract": "Moving target detection is a challenging computer vision task aimed at generating accurate segmentation maps in diverse in-the-wild color videos captured by static cameras. If backgrounds and targets can be simultaneously extracted and recombined, such synthetic data can significantly enrich annotated in-the-wild datasets and enhance the generalization ability of deep models. Quaternion-based RPCA (QRPCA) is a promising unsupervised paradigm for color image processing. However, in color video processing, Quaternion Singular Value Decomposition (QSVD) incurs high computational costs, and rank-1 quaternion matrix fails to yield rank-1 color channels. In this paper, we reduce the computational complexity of QSVD to o(1) by utilizing a quaternion Riemannian manifold. Furthermor, we propose the universal QRPCA (uQRPCA) framework, which achieves a balance in simultaneously segmenting targets and recovering backgrounds from color videos. Moreover, we expand to uQRPCA+ by introducing the Color Rank-1 Batch (CR1B) method to further process and obtain the ideal low-rank background across color channels. Experiments demonstrate our uQRPCA+ achieves State Of The Art (SOTA) performance on moving target detection and background recovery tasks compared to existing open-source methods. Our implementation is publicly available on GitHub at https://github.com/Ruchtech/uQRPCA",
    "categories": [
      "cs.CV",
      "cs.AI"
    ],
    "primary_category": "cs.CV",
    "comment": "",
    "pdf_url": "https://arxiv.org/pdf/2507.19730v1",
    "published_date": "2025-07-26 01:05:03 UTC",
    "updated_date": "2025-07-26 01:05:03 UTC"
  },
  {
    "arxiv_id": "2507.19726v2",
    "title": "HypKG: Hypergraph-based Knowledge Graph Contextualization for Precision Healthcare",
    "authors": [
      "Yuzhang Xie",
      "Xu Han",
      "Ran Xu",
      "Xiao Hu",
      "Jiaying Lu",
      "Carl Yang"
    ],
    "abstract": "Knowledge graphs (KGs) are important products of the semantic web, which are widely used in various application domains. Healthcare is one of such domains where KGs are intensively used, due to the high requirement for knowledge accuracy and interconnected nature of healthcare data. However, KGs storing general factual information often lack the ability to account for important contexts of the knowledge such as the status of specific patients, which are crucial in precision healthcare. Meanwhile, electronic health records (EHRs) provide rich personal data, including various diagnoses and medications, which provide natural contexts for general KGs. In this paper, we propose HypKG, a framework that integrates patient information from EHRs into KGs to generate contextualized knowledge representations for accurate healthcare predictions. Using advanced entity-linking techniques, we connect relevant knowledge from general KGs with patient information from EHRs, and then utilize a hypergraph model to \"contextualize\" the knowledge with the patient information. Finally, we employ hypergraph transformers guided by downstream prediction tasks to jointly learn proper contextualized representations for both KGs and patients, fully leveraging existing knowledge in KGs and patient contexts in EHRs. In experiments using a large biomedical KG and two real-world EHR datasets, HypKG demonstrates significant improvements in healthcare prediction tasks across multiple evaluation metrics. Additionally, by integrating external contexts, HypKG can learn to adjust the representations of entities and relations in KG, potentially improving the quality and real-world utility of knowledge.",
    "categories": [
      "cs.AI",
      "cs.LG"
    ],
    "primary_category": "cs.AI",
    "comment": "Extended version of paper accepted at the 24th International Semantic Web Conference (ISWC 2025), Main Conference, Research Track, Oral",
    "pdf_url": "https://arxiv.org/pdf/2507.19726v2",
    "published_date": "2025-07-26 00:51:50 UTC",
    "updated_date": "2025-07-30 02:32:04 UTC"
  },
  {
    "arxiv_id": "2507.19725v1",
    "title": "Minding Motivation: The Effect of Intrinsic Motivation on Agent Behaviors",
    "authors": [
      "Leonardo Villalobos-Arias",
      "Grant Forbes",
      "Jianxun Wang",
      "David L Roberts",
      "Arnav Jhala"
    ],
    "abstract": "Games are challenging for Reinforcement Learning~(RL) agents due to their reward-sparsity, as rewards are only obtainable after long sequences of deliberate actions. Intrinsic Motivation~(IM) methods -- which introduce exploration rewards -- are an effective solution to reward-sparsity. However, IM also causes an issue known as `reward hacking' where the agent optimizes for the new reward at the expense of properly playing the game. The larger problem is that reward hacking itself is largely unknown; there is no answer to whether, and to what extent, IM rewards change the behavior of RL agents. This study takes a first step by empirically evaluating the impact on behavior of three IM techniques on the MiniGrid game-like environment. We compare these IM models with Generalized Reward Matching~(GRM), a method that can be used with any intrinsic reward function to guarantee optimality. Our results suggest that IM causes noticeable change by increasing the initial rewards, but also altering the way the agent plays; and that GRM mitigated reward hacking in some scenarios.",
    "categories": [
      "cs.AI"
    ],
    "primary_category": "cs.AI",
    "comment": "11 pages, 7 figures, 3 tables",
    "pdf_url": "https://arxiv.org/pdf/2507.19725v1",
    "published_date": "2025-07-26 00:49:25 UTC",
    "updated_date": "2025-07-26 00:49:25 UTC"
  },
  {
    "arxiv_id": "2508.08265v1",
    "title": "TurQUaz at CheckThat! 2025: Debating Large Language Models for Scientific Web Discourse Detection",
    "authors": [
      "TarÄ±k SaraÃ§",
      "Selin Mergen",
      "Mucahid Kutlu"
    ],
    "abstract": "In this paper, we present our work developed for the scientific web discourse detection task (Task 4a) of CheckThat! 2025. We propose a novel council debate method that simulates structured academic discussions among multiple large language models (LLMs) to identify whether a given tweet contains (i) a scientific claim, (ii) a reference to a scientific study, or (iii) mentions of scientific entities. We explore three debating methods: i) single debate, where two LLMs argue for opposing positions while a third acts as a judge; ii) team debate, in which multiple models collaborate within each side of the debate; and iii) council debate, where multiple expert models deliberate together to reach a consensus, moderated by a chairperson model. We choose council debate as our primary model as it outperforms others in the development test set. Although our proposed method did not rank highly for identifying scientific claims (8th out of 10) or mentions of scientific entities (9th out of 10), it ranked first in detecting references to scientific studies.",
    "categories": [
      "cs.CL",
      "cs.AI"
    ],
    "primary_category": "cs.CL",
    "comment": "",
    "pdf_url": "https://arxiv.org/pdf/2508.08265v1",
    "published_date": "2025-07-26 00:46:23 UTC",
    "updated_date": "2025-07-26 00:46:23 UTC"
  },
  {
    "arxiv_id": "2507.21171v1",
    "title": "An ontological analysis of risk in Basic Formal Ontology",
    "authors": [
      "Federico Donato",
      "Adrien Barton"
    ],
    "abstract": "The paper explores the nature of risk, providing a characterization using the categories of the Basic Formal Ontology (BFO). It argues that the category Risk is a subclass of BFO:Role, contrasting it with a similar view classifying Risk as a subclass of BFO:Disposition. This modeling choice is applied on one example of risk, which represents objects, processes (both physical and mental) and their interrelations, then generalizing from the instances in the example to obtain an overall analysis of risk, making explicit what are the sufficient conditions for being a risk. Plausible necessary conditions are also mentioned for future work. Index Terms: ontology, risk, BFO, role, disposition",
    "categories": [
      "cs.AI"
    ],
    "primary_category": "cs.AI",
    "comment": "7 pages. 2 figures. Conference: Semantic Technology for Intelligence, Defense, and Security (STIDS 2024)",
    "pdf_url": "https://arxiv.org/pdf/2507.21171v1",
    "published_date": "2025-07-26 00:44:47 UTC",
    "updated_date": "2025-07-26 00:44:47 UTC"
  }
]