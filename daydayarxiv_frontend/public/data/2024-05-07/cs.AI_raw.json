[
  {
    "arxiv_id": "2405.04718v1",
    "title": "Metaverse Survey & Tutorial: Exploring Key Requirements, Technologies, Standards, Applications, Challenges, and Perspectives",
    "authors": [
      "Danda B. Rawat",
      "Hassan El alami",
      "Desta Haileselassie Hagos"
    ],
    "abstract": "In this paper, we present a comprehensive survey of the metaverse, envisioned\nas a transformative dimension of next-generation Internet technologies. This\nstudy not only outlines the structural components of our survey but also makes\na substantial scientific contribution by elucidating the foundational concepts\nunderlying the emergence of the metaverse. We analyze its architecture by\ndefining key characteristics and requirements, thereby illuminating the nascent\nreality set to revolutionize digital interactions. Our analysis emphasizes the\nimportance of collaborative efforts in developing metaverse standards, thereby\nfostering a unified understanding among industry stakeholders, organizations,\nand regulatory bodies. We extend our scrutiny to critical technologies integral\nto the metaverse, including interactive experiences, communication\ntechnologies, ubiquitous computing, digital twins, artificial intelligence, and\ncybersecurity measures. For each technological domain, we rigorously assess\ncurrent contributions, principal techniques, and representative use cases,\nproviding a nuanced perspective on their potential impacts. Furthermore, we\ndelve into the metaverse's diverse applications across education, healthcare,\nbusiness, social interactions, industrial sectors, defense, and\nmission-critical operations, highlighting its extensive utility. Each\napplication is thoroughly analyzed, demonstrating its value and addressing\nassociated challenges. The survey concludes with an overview of persistent\nchallenges and future directions, offering insights into essential\nconsiderations and strategies necessary to harness the full potential of the\nmetaverse. Through this detailed investigation, our goal is to articulate the\nscientific contributions of this survey paper, transcending a mere structural\noverview to highlight the transformative implications of the metaverse.",
    "categories": [
      "cs.HC",
      "cs.AI"
    ],
    "primary_category": "cs.HC",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2405.04718v1",
    "published_date": "2024-05-07 23:49:02 UTC",
    "updated_date": "2024-05-07 23:49:02 UTC"
  },
  {
    "arxiv_id": "2405.04716v1",
    "title": "Physics-based deep learning reveals rising heating demand heightens air pollution in Norwegian cities",
    "authors": [
      "Cong Cao",
      "Ramit Debnath",
      "R. Michael Alvarez"
    ],
    "abstract": "Policymakers frequently analyze air quality and climate change in isolation,\ndisregarding their interactions. This study explores the influence of specific\nclimate factors on air quality by contrasting a regression model with K-Means\nClustering, Hierarchical Clustering, and Random Forest techniques. We employ\nPhysics-based Deep Learning (PBDL) and Long Short-Term Memory (LSTM) to examine\nthe air pollution predictions. Our analysis utilizes ten years (2009-2018) of\ndaily traffic, weather, and air pollution data from three major cities in\nNorway. Findings from feature selection reveal a correlation between rising\nheating degree days and heightened air pollution levels, suggesting increased\nheating activities in Norway are a contributing factor to worsening air\nquality. PBDL demonstrates superior accuracy in air pollution predictions\ncompared to LSTM. This paper contributes to the growing literature on PBDL\nmethods for more accurate air pollution predictions using environmental\nvariables, aiding policymakers in formulating effective data-driven climate\npolicies.",
    "categories": [
      "cs.CY",
      "cs.AI",
      "cs.LG",
      "cs.NE",
      "K.4.1; J.2; I.2"
    ],
    "primary_category": "cs.CY",
    "comment": "52 pages, 23 figures",
    "pdf_url": "http://arxiv.org/pdf/2405.04716v1",
    "published_date": "2024-05-07 23:43:46 UTC",
    "updated_date": "2024-05-07 23:43:46 UTC"
  },
  {
    "arxiv_id": "2405.04714v1",
    "title": "RACER: Epistemic Risk-Sensitive RL Enables Fast Driving with Fewer Crashes",
    "authors": [
      "Kyle Stachowicz",
      "Sergey Levine"
    ],
    "abstract": "Reinforcement learning provides an appealing framework for robotic control\ndue to its ability to learn expressive policies purely through real-world\ninteraction. However, this requires addressing real-world constraints and\navoiding catastrophic failures during training, which might severely impede\nboth learning progress and the performance of the final policy. In many\nrobotics settings, this amounts to avoiding certain \"unsafe\" states. The\nhigh-speed off-road driving task represents a particularly challenging\ninstantiation of this problem: a high-return policy should drive as\naggressively and as quickly as possible, which often requires getting close to\nthe edge of the set of \"safe\" states, and therefore places a particular burden\non the method to avoid frequent failures.\n  To both learn highly performant policies and avoid excessive failures, we\npropose a reinforcement learning framework that combines risk-sensitive control\nwith an adaptive action space curriculum.\n  Furthermore, we show that our risk-sensitive objective automatically avoids\nout-of-distribution states when equipped with an estimator for epistemic\nuncertainty.\n  We implement our algorithm on a small-scale rally car and show that it is\ncapable of learning high-speed policies for a real-world off-road driving task.\nWe show that our method greatly reduces the number of safety violations during\nthe training process, and actually leads to higher-performance policies in both\ndriving and non-driving simulation environments with similar challenges.",
    "categories": [
      "cs.RO",
      "cs.AI",
      "cs.LG"
    ],
    "primary_category": "cs.RO",
    "comment": "In review, RSS 2024",
    "pdf_url": "http://arxiv.org/pdf/2405.04714v1",
    "published_date": "2024-05-07 23:32:36 UTC",
    "updated_date": "2024-05-07 23:32:36 UTC"
  },
  {
    "arxiv_id": "2405.05286v1",
    "title": "Tiny Deep Ensemble: Uncertainty Estimation in Edge AI Accelerators via Ensembling Normalization Layers with Shared Weights",
    "authors": [
      "Soyed Tuhin Ahmed",
      "Michael Hefenbrock",
      "Mehdi B. Tahoori"
    ],
    "abstract": "The applications of artificial intelligence (AI) are rapidly evolving, and\nthey are also commonly used in safety-critical domains, such as autonomous\ndriving and medical diagnosis, where functional safety is paramount. In\nAI-driven systems, uncertainty estimation allows the user to avoid\noverconfidence predictions and achieve functional safety. Therefore, the\nrobustness and reliability of model predictions can be improved. However,\nconventional uncertainty estimation methods, such as the deep ensemble method,\nimpose high computation and, accordingly, hardware (latency and energy)\noverhead because they require the storage and processing of multiple models.\nAlternatively, Monte Carlo dropout (MC-dropout) methods, although having low\nmemory overhead, necessitate numerous ($\\sim 100$) forward passes, leading to\nhigh computational overhead and latency. Thus, these approaches are not\nsuitable for battery-powered edge devices with limited computing and memory\nresources. In this paper, we propose the Tiny-Deep Ensemble approach, a\nlow-cost approach for uncertainty estimation on edge devices. In our approach,\nonly normalization layers are ensembled $M$ times, with all ensemble members\nsharing common weights and biases, leading to a significant decrease in storage\nrequirements and latency. Moreover, our approach requires only one forward pass\nin a hardware architecture that allows batch processing for inference and\nuncertainty estimation. Furthermore, it has approximately the same memory\noverhead compared to a single model. Therefore, latency and memory overhead are\nreduced by a factor of up to $\\sim M\\times$. Nevertheless, our method does not\ncompromise accuracy, with an increase in inference accuracy of up to $\\sim 1\\%$\nand a reduction in RMSE of $17.17\\%$ in various benchmark datasets, tasks, and\nstate-of-the-art architectures.",
    "categories": [
      "cs.LG",
      "cs.AI",
      "cs.DC"
    ],
    "primary_category": "cs.LG",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2405.05286v1",
    "published_date": "2024-05-07 22:54:17 UTC",
    "updated_date": "2024-05-07 22:54:17 UTC"
  },
  {
    "arxiv_id": "2405.04700v1",
    "title": "Robust Implementation of Retrieval-Augmented Generation on Edge-based Computing-in-Memory Architectures",
    "authors": [
      "Ruiyang Qin",
      "Zheyu Yan",
      "Dewen Zeng",
      "Zhenge Jia",
      "Dancheng Liu",
      "Jianbo Liu",
      "Zhi Zheng",
      "Ningyuan Cao",
      "Kai Ni",
      "Jinjun Xiong",
      "Yiyu Shi"
    ],
    "abstract": "Large Language Models (LLMs) deployed on edge devices learn through\nfine-tuning and updating a certain portion of their parameters. Although such\nlearning methods can be optimized to reduce resource utilization, the overall\nrequired resources remain a heavy burden on edge devices. Instead,\nRetrieval-Augmented Generation (RAG), a resource-efficient LLM learning method,\ncan improve the quality of the LLM-generated content without updating model\nparameters. However, the RAG-based LLM may involve repetitive searches on the\nprofile data in every user-LLM interaction. This search can lead to significant\nlatency along with the accumulation of user data. Conventional efforts to\ndecrease latency result in restricting the size of saved user data, thus\nreducing the scalability of RAG as user data continuously grows. It remains an\nopen question: how to free RAG from the constraints of latency and scalability\non edge devices? In this paper, we propose a novel framework to accelerate RAG\nvia Computing-in-Memory (CiM) architectures. It accelerates matrix\nmultiplications by performing in-situ computation inside the memory while\navoiding the expensive data transfer between the computing unit and memory. Our\nframework, Robust CiM-backed RAG (RoCR), utilizing a novel contrastive\nlearning-based training method and noise-aware training, can enable RAG to\nefficiently search profile data with CiM. To the best of our knowledge, this is\nthe first work utilizing CiM to accelerate RAG.",
    "categories": [
      "cs.LG",
      "cs.AI",
      "cs.DC",
      "cs.IR"
    ],
    "primary_category": "cs.LG",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2405.04700v1",
    "published_date": "2024-05-07 22:31:50 UTC",
    "updated_date": "2024-05-07 22:31:50 UTC"
  },
  {
    "arxiv_id": "2405.05285v1",
    "title": "Generative AI as a metacognitive agent: A comparative mixed-method study with human participants on ICF-mimicking exam performance",
    "authors": [
      "Jelena Pavlovic",
      "Jugoslav Krstic",
      "Luka Mitrovic",
      "Djordje Babic",
      "Adrijana Milosavljevic",
      "Milena Nikolic",
      "Tijana Karaklic",
      "Tijana Mitrovic"
    ],
    "abstract": "This study investigates the metacognitive capabilities of Large Language\nModels relative to human metacognition in the context of the International\nCoaching Federation ICF mimicking exam, a situational judgment test related to\ncoaching competencies. Using a mixed method approach, we assessed the\nmetacognitive performance, including sensitivity, accuracy in probabilistic\npredictions, and bias, of human participants and five advanced LLMs (GPT-4,\nClaude-3-Opus 3, Mistral Large, Llama 3, and Gemini 1.5 Pro). The results\nindicate that LLMs outperformed humans across all metacognitive metrics,\nparticularly in terms of reduced overconfidence, compared to humans. However,\nboth LLMs and humans showed less adaptability in ambiguous scenarios, adhering\nclosely to predefined decision frameworks. The study suggests that Generative\nAI can effectively engage in human-like metacognitive processing without\nconscious awareness. Implications of the study are discussed in relation to\ndevelopment of AI simulators that scaffold cognitive and metacognitive aspects\nof mastering coaching competencies. More broadly, implications of these results\nare discussed in relation to development of metacognitive modules that lead\ntowards more autonomous and intuitive AI systems.",
    "categories": [
      "cs.HC",
      "cs.AI"
    ],
    "primary_category": "cs.HC",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2405.05285v1",
    "published_date": "2024-05-07 22:15:12 UTC",
    "updated_date": "2024-05-07 22:15:12 UTC"
  },
  {
    "arxiv_id": "2405.04687v1",
    "title": "Towards Human-AI Mutual Learning: A New Research Paradigm",
    "authors": [
      "Xiaomei Wang",
      "Xiaoyu Chen"
    ],
    "abstract": "This paper describes a new research paradigm for studying human-AI\ncollaboration, named \"human-AI mutual learning\", defined as the process where\nhumans and AI agents preserve, exchange, and improve knowledge during human-AI\ncollaboration. We describe relevant methodologies, motivations, domain\nexamples, benefits, challenges, and future research agenda under this paradigm.",
    "categories": [
      "cs.HC",
      "cs.AI"
    ],
    "primary_category": "cs.HC",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2405.04687v1",
    "published_date": "2024-05-07 21:59:57 UTC",
    "updated_date": "2024-05-07 21:59:57 UTC"
  },
  {
    "arxiv_id": "2405.04685v1",
    "title": "Bridging the Bosphorus: Advancing Turkish Large Language Models through Strategies for Low-Resource Language Adaptation and Benchmarking",
    "authors": [
      "Emre Can Acikgoz",
      "Mete Erdogan",
      "Deniz Yuret"
    ],
    "abstract": "Large Language Models (LLMs) are becoming crucial across various fields,\nemphasizing the urgency for high-quality models in underrepresented languages.\nThis study explores the unique challenges faced by low-resource languages, such\nas data scarcity, model selection, evaluation, and computational limitations,\nwith a special focus on Turkish. We conduct an in-depth analysis to evaluate\nthe impact of training strategies, model choices, and data availability on the\nperformance of LLMs designed for underrepresented languages. Our approach\nincludes two methodologies: (i) adapting existing LLMs originally pretrained in\nEnglish to understand Turkish, and (ii) developing a model from the ground up\nusing Turkish pretraining data, both supplemented with supervised fine-tuning\non a novel Turkish instruction-tuning dataset aimed at enhancing reasoning\ncapabilities. The relative performance of these methods is evaluated through\nthe creation of a new leaderboard for Turkish LLMs, featuring benchmarks that\nassess different reasoning and knowledge skills. Furthermore, we conducted\nexperiments on data and model scaling, both during pretraining and fine-tuning,\nsimultaneously emphasizing the capacity for knowledge transfer across languages\nand addressing the challenges of catastrophic forgetting encountered during\nfine-tuning on a different language. Our goal is to offer a detailed guide for\nadvancing the LLM framework in low-resource linguistic contexts, thereby making\nnatural language processing (NLP) benefits more globally accessible.",
    "categories": [
      "cs.CL",
      "cs.AI",
      "cs.LG"
    ],
    "primary_category": "cs.CL",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2405.04685v1",
    "published_date": "2024-05-07 21:58:45 UTC",
    "updated_date": "2024-05-07 21:58:45 UTC"
  },
  {
    "arxiv_id": "2405.04682v4",
    "title": "TALC: Time-Aligned Captions for Multi-Scene Text-to-Video Generation",
    "authors": [
      "Hritik Bansal",
      "Yonatan Bitton",
      "Michal Yarom",
      "Idan Szpektor",
      "Aditya Grover",
      "Kai-Wei Chang"
    ],
    "abstract": "Most of these text-to-video (T2V) generative models often produce\nsingle-scene video clips that depict an entity performing a particular action\n(e.g., 'a red panda climbing a tree'). However, it is pertinent to generate\nmulti-scene videos since they are ubiquitous in the real-world (e.g., 'a red\npanda climbing a tree' followed by 'the red panda sleeps on the top of the\ntree'). To generate multi-scene videos from the pretrained T2V model, we\nintroduce a simple and effective Time-Aligned Captions (TALC) framework.\nSpecifically, we enhance the text-conditioning mechanism in the T2V\narchitecture to recognize the temporal alignment between the video scenes and\nscene descriptions. For instance, we condition the visual features of the\nearlier and later scenes of the generated video with the representations of the\nfirst scene description (e.g., 'a red panda climbing a tree') and second scene\ndescription (e.g., 'the red panda sleeps on the top of the tree'),\nrespectively. As a result, we show that the T2V model can generate multi-scene\nvideos that adhere to the multi-scene text descriptions and be visually\nconsistent (e.g., entity and background). Further, we finetune the pretrained\nT2V model with multi-scene video-text data using the TALC framework. We show\nthat the TALC-finetuned model outperforms the baseline by achieving a relative\ngain of 29% in the overall score, which averages visual consistency and text\nadherence using human evaluation.",
    "categories": [
      "cs.CV",
      "cs.AI",
      "cs.LG"
    ],
    "primary_category": "cs.CV",
    "comment": "22 pages, 14 figures, 11 tables",
    "pdf_url": "http://arxiv.org/pdf/2405.04682v4",
    "published_date": "2024-05-07 21:52:39 UTC",
    "updated_date": "2024-11-08 05:45:45 UTC"
  },
  {
    "arxiv_id": "2405.04677v1",
    "title": "Responding to Generative AI Technologies with Research-through-Design: The Ryelands AI Lab as an Exploratory Study",
    "authors": [
      "Jesse Josua Benjamin",
      "Joseph Lindley",
      "Elizabeth Edwards",
      "Elisa Rubegni",
      "Tim Korjakow",
      "David Grist",
      "Rhiannon Sharkey"
    ],
    "abstract": "Generative AI technologies demand new practical and critical competencies,\nwhich call on design to respond to and foster these. We present an exploratory\nstudy guided by Research-through-Design, in which we partnered with a primary\nschool to develop a constructionist curriculum centered on students interacting\nwith a generative AI technology. We provide a detailed account of the design of\nand outputs from the curriculum and learning materials, finding centrally that\nthe reflexive and prolonged `hands-on' approach led to a co-development of\nstudents' practical and critical competencies. From the study, we contribute\nguidance for designing constructionist approaches to generative AI technology\neducation; further arguing to do so with `critical responsivity.' We then\ndiscuss how HCI researchers may leverage constructionist strategies in\ndesigning interactions with generative AI technologies; and suggest that\nResearch-through-Design can play an important role as a `rapid response\nmethodology' capable of reacting to fast-evolving, disruptive technologies such\nas generative AI.",
    "categories": [
      "cs.HC",
      "cs.AI",
      "cs.CY"
    ],
    "primary_category": "cs.HC",
    "comment": "Conditionally Accepted at ACM DIS 2024",
    "pdf_url": "http://arxiv.org/pdf/2405.04677v1",
    "published_date": "2024-05-07 21:34:10 UTC",
    "updated_date": "2024-05-07 21:34:10 UTC"
  },
  {
    "arxiv_id": "2405.04664v1",
    "title": "Proximal Policy Optimization with Adaptive Exploration",
    "authors": [
      "Andrei Lixandru"
    ],
    "abstract": "Proximal Policy Optimization with Adaptive Exploration (axPPO) is introduced\nas a novel learning algorithm. This paper investigates the\nexploration-exploitation tradeoff within the context of reinforcement learning\nand aims to contribute new insights into reinforcement learning algorithm\ndesign. The proposed adaptive exploration framework dynamically adjusts the\nexploration magnitude during training based on the recent performance of the\nagent. Our proposed method outperforms standard PPO algorithms in learning\nefficiency, particularly when significant exploratory behavior is needed at the\nbeginning of the learning process.",
    "categories": [
      "cs.LG",
      "cs.AI"
    ],
    "primary_category": "cs.LG",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2405.04664v1",
    "published_date": "2024-05-07 20:51:49 UTC",
    "updated_date": "2024-05-07 20:51:49 UTC"
  },
  {
    "arxiv_id": "2405.04657v3",
    "title": "ACEGEN: Reinforcement learning of generative chemical agents for drug discovery",
    "authors": [
      "Albert Bou",
      "Morgan Thomas",
      "Sebastian Dittert",
      "Carles Navarro Ramírez",
      "Maciej Majewski",
      "Ye Wang",
      "Shivam Patel",
      "Gary Tresadern",
      "Mazen Ahmad",
      "Vincent Moens",
      "Woody Sherman",
      "Simone Sciabola",
      "Gianni De Fabritiis"
    ],
    "abstract": "In recent years, reinforcement learning (RL) has emerged as a valuable tool\nin drug design, offering the potential to propose and optimize molecules with\ndesired properties. However, striking a balance between capabilities,\nflexibility, reliability, and efficiency remains challenging due to the\ncomplexity of advanced RL algorithms and the significant reliance on\nspecialized code. In this work, we introduce ACEGEN, a comprehensive and\nstreamlined toolkit tailored for generative drug design, built using TorchRL, a\nmodern RL library that offers thoroughly tested reusable components. We\nvalidate ACEGEN by benchmarking against other published generative modeling\nalgorithms and show comparable or improved performance. We also show examples\nof ACEGEN applied in multiple drug discovery case studies. ACEGEN is accessible\nat \\url{https://github.com/acellera/acegen-open} and available for use under\nthe MIT license.",
    "categories": [
      "cs.LG",
      "cs.AI",
      "q-bio.BM"
    ],
    "primary_category": "cs.LG",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2405.04657v3",
    "published_date": "2024-05-07 20:30:14 UTC",
    "updated_date": "2024-07-22 17:48:37 UTC"
  },
  {
    "arxiv_id": "2405.06694v1",
    "title": "SUTRA: Scalable Multilingual Language Model Architecture",
    "authors": [
      "Abhijit Bendale",
      "Michael Sapienza",
      "Steven Ripplinger",
      "Simon Gibbs",
      "Jaewon Lee",
      "Pranav Mistry"
    ],
    "abstract": "In this paper, we introduce SUTRA, multilingual Large Language Model\narchitecture capable of understanding, reasoning, and generating text in over\n50 languages. SUTRA's design uniquely decouples core conceptual understanding\nfrom language-specific processing, which facilitates scalable and efficient\nmultilingual alignment and learning. Employing a Mixture of Experts framework\nboth in language and concept processing, SUTRA demonstrates both computational\nefficiency and responsiveness. Through extensive evaluations, SUTRA is\ndemonstrated to surpass existing models like GPT-3.5, Llama2 by 20-30% on\nleading Massive Multitask Language Understanding (MMLU) benchmarks for\nmultilingual tasks. SUTRA models are also online LLMs that can use knowledge\nfrom the internet to provide hallucination-free, factual and up-to-date\nresponses while retaining their multilingual capabilities. Furthermore, we\nexplore the broader implications of its architecture for the future of\nmultilingual AI, highlighting its potential to democratize access to AI\ntechnology globally and to improve the equity and utility of AI in regions with\npredominantly non-English languages. Our findings suggest that SUTRA not only\nfills pivotal gaps in multilingual model capabilities but also establishes a\nnew benchmark for operational efficiency and scalability in AI applications.",
    "categories": [
      "cs.CL",
      "cs.AI"
    ],
    "primary_category": "cs.CL",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2405.06694v1",
    "published_date": "2024-05-07 20:11:44 UTC",
    "updated_date": "2024-05-07 20:11:44 UTC"
  },
  {
    "arxiv_id": "2405.04650v1",
    "title": "A Self-Supervised Method for Body Part Segmentation and Keypoint Detection of Rat Images",
    "authors": [
      "László Kopácsi",
      "Áron Fóthi",
      "András Lőrincz"
    ],
    "abstract": "Recognition of individual components and keypoint detection supported by\ninstance segmentation is crucial to analyze the behavior of agents on the\nscene. Such systems could be used for surveillance, self-driving cars, and also\nfor medical research, where behavior analysis of laboratory animals is used to\nconfirm the aftereffects of a given medicine. A method capable of solving the\naforementioned tasks usually requires a large amount of high-quality\nhand-annotated data, which takes time and money to produce. In this paper, we\npropose a method that alleviates the need for manual labeling of laboratory\nrats. To do so, first, we generate initial annotations with a computer\nvision-based approach, then through extensive augmentation, we train a deep\nneural network on the generated data. The final system is capable of instance\nsegmentation, keypoint detection, and body part segmentation even when the\nobjects are heavily occluded.",
    "categories": [
      "cs.CV",
      "cs.AI"
    ],
    "primary_category": "cs.CV",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2405.04650v1",
    "published_date": "2024-05-07 20:11:07 UTC",
    "updated_date": "2024-05-07 20:11:07 UTC"
  },
  {
    "arxiv_id": "2405.04629v2",
    "title": "ResNCT: A Deep Learning Model for the Synthesis of Nephrographic Phase Images in CT Urography",
    "authors": [
      "Syed Jamal Safdar Gardezi",
      "Lucas Aronson",
      "Peter Wawrzyn",
      "Hongkun Yu",
      "E. Jason Abel",
      "Daniel D. Shapiro",
      "Meghan G. Lubner",
      "Joshua Warner",
      "Giuseppe Toia",
      "Lu Mao",
      "Pallavi Tiwari",
      "Andrew L. Wentland"
    ],
    "abstract": "Purpose: To develop and evaluate a transformer-based deep learning model for\nthe synthesis of nephrographic phase images in CT urography (CTU) examinations\nfrom the unenhanced and urographic phases.\n  Materials and Methods: This retrospective study was approved by the local\nInstitutional Review Board. A dataset of 119 patients (mean $\\pm$ SD age, 65\n$\\pm$ 12 years; 75/44 males/females) with three-phase CT urography studies was\ncurated for deep learning model development. The three phases for each patient\nwere aligned with an affine registration algorithm. A custom model, coined\nResidual transformer model for Nephrographic phase CT image synthesis (ResNCT),\nwas developed and implemented with paired inputs of non-contrast and urographic\nsets of images trained to produce the nephrographic phase images, that were\ncompared with the corresponding ground truth nephrographic phase images. The\nsynthesized images were evaluated with multiple performance metrics, including\npeak signal to noise ratio (PSNR), structural similarity index (SSIM),\nnormalized cross correlation coefficient (NCC), mean absolute error (MAE), and\nroot mean squared error (RMSE).\n  Results: The ResNCT model successfully generated synthetic nephrographic\nimages from non-contrast and urographic image inputs. With respect to ground\ntruth nephrographic phase images, the images synthesized by the model achieved\nhigh PSNR (27.8 $\\pm$ 2.7 dB), SSIM (0.88 $\\pm$ 0.05), and NCC (0.98 $\\pm$\n0.02), and low MAE (0.02 $\\pm$ 0.005) and RMSE (0.042 $\\pm$ 0.016).\n  Conclusion: The ResNCT model synthesized nephrographic phase CT images with\nhigh similarity to ground truth images. The ResNCT model provides a means of\neliminating the acquisition of the nephrographic phase with a resultant 33%\nreduction in radiation dose for CTU examinations.",
    "categories": [
      "eess.IV",
      "cs.AI",
      "physics.med-ph",
      "J.3"
    ],
    "primary_category": "eess.IV",
    "comment": "10 pages, 5 Figures,2 Tables",
    "pdf_url": "http://arxiv.org/pdf/2405.04629v2",
    "published_date": "2024-05-07 19:20:32 UTC",
    "updated_date": "2024-05-29 02:12:44 UTC"
  },
  {
    "arxiv_id": "2405.04620v5",
    "title": "Folded Context Condensation in Path Integral Formalism for Infinite Context Transformers",
    "authors": [
      "Won-Gi Paeng",
      "Daesuk Kwon",
      "Kyungwon Jeong",
      "Honggyo Suh"
    ],
    "abstract": "In this work, we present a generalized formulation of the Transformer\nalgorithm by reinterpreting its core mechanisms within the framework of Path\nIntegral formalism. In this perspective, the attention mechanism is recast as a\nprocess that integrates all possible transition paths leading to future token\nstates, with temporal evolution governed by the Feed-Forward Network. By\nsystematically mapping each component of the Transformer to its counterpart in\nthe Path Integral formulation, we obtain a more compact and efficient\nrepresentation, in which the contextual information of a sequence is condensed\ninto memory-like segments. These segments are recurrently processed across\nTransformer layers, enabling more effective long-term information retention. We\nvalidate the effectiveness of this approach through the Passkey retrieval task\nand a summarization task, demonstrating that the proposed method preserves\nhistorical information while exhibiting memory usage that scales linearly with\nsequence length. This contrasts with the non-linear memory growth typically\nobserved in standard attention mechanisms. We expect that this quantum-inspired\ngeneralization of the Transformer architecture will open new avenues for\nenhancing both the efficiency and expressiveness of future Transformer models.",
    "categories": [
      "hep-ph",
      "cs.AI",
      "cs.CL",
      "cs.LG",
      "cs.NE"
    ],
    "primary_category": "hep-ph",
    "comment": "11 pages, 12 figures",
    "pdf_url": "http://arxiv.org/pdf/2405.04620v5",
    "published_date": "2024-05-07 19:05:26 UTC",
    "updated_date": "2025-05-01 04:45:29 UTC"
  },
  {
    "arxiv_id": "2405.17438v1",
    "title": "An LLM-Tool Compiler for Fused Parallel Function Calling",
    "authors": [
      "Simranjit Singh",
      "Andreas Karatzas",
      "Michael Fore",
      "Iraklis Anagnostopoulos",
      "Dimitrios Stamoulis"
    ],
    "abstract": "State-of-the-art sequential reasoning in Large Language Models (LLMs) has\nexpanded the capabilities of Copilots beyond conversational tasks to complex\nfunction calling, managing thousands of API calls. However, the tendency of\ncompositional prompting to segment tasks into multiple steps, each requiring a\nround-trip to the GPT APIs, leads to increased system latency and costs.\nAlthough recent advancements in parallel function calling have improved tool\nexecution per API call, they may necessitate more detailed in-context\ninstructions and task breakdown at the prompt level, resulting in higher\nengineering and production costs. Inspired by the hardware design principles of\nmultiply-add (MAD) operations, which fuse multiple arithmetic operations into a\nsingle task from the compiler's perspective, we propose LLM-Tool Compiler,\nwhich selectively fuses similar types of tool operations under a single\nfunction at runtime, presenting them as a unified task to the LLM. This\nselective fusion inherently enhances parallelization and efficiency.\nBenchmarked on a large-scale Copilot platform, LLM-Tool Compiler achieves up to\nfour times more parallel calls than existing methods, reducing token costs and\nlatency by up to 40% and 12%, respectively.",
    "categories": [
      "cs.PL",
      "cs.AI",
      "cs.LG"
    ],
    "primary_category": "cs.PL",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2405.17438v1",
    "published_date": "2024-05-07 18:55:50 UTC",
    "updated_date": "2024-05-07 18:55:50 UTC"
  },
  {
    "arxiv_id": "2405.04605v3",
    "title": "AI in Lung Health: Benchmarking Detection and Diagnostic Models Across Multiple CT Scan Datasets",
    "authors": [
      "Fakrul Islam Tushar",
      "Avivah Wang",
      "Lavsen Dahal",
      "Michael R. Harowicz",
      "Kyle J. Lafata",
      "Tina D. Tailor",
      "Joseph Y. Lo"
    ],
    "abstract": "Lung cancer remains the leading cause of cancer-related mortality worldwide,\nand early detection through low-dose computed tomography (LDCT) has shown\nsignificant promise in reducing death rates. With the growing integration of\nartificial intelligence (AI) into medical imaging, the development and\nevaluation of robust AI models require access to large, well-annotated\ndatasets. In this study, we introduce the utility of Duke Lung Cancer Screening\n(DLCS) Dataset, the largest open-access LDCT dataset with over 2,000 scans and\n3,000 expert-verified nodules. We benchmark deep learning models for both 3D\nnodule detection and lung cancer classification across internal and external\ndatasets including LUNA16, LUNA25, and NLST-3D+. For detection, we develop two\nMONAI-based RetinaNet models (DLCSDmD and LUNA16-mD), evaluated using the\nCompetition Performance Metric (CPM). For classification, we compare five\nmodels, including state-of-the-art pretrained models (Models Genesis, Med3D), a\nselfsupervised foundation model (FMCB), a randomly initialized ResNet50, and\nproposed a novel Strategic Warm-Start++ (SWS++) model. SWS++ uses curated\ncandidate patches to pretrain a classification backbone within the same\ndetection pipeline, enabling task-relevant feature learning. Our models\ndemonstrated strong generalizability, with SWS++ achieving comparable or\nsuperior performance to existing foundational models across multiple datasets\n(AUC: 0.71 to 0.90). All code, models, and data are publicly released to\npromote reproducibility and collaboration. This work establishes a standardized\nbenchmarking resource for lung cancer AI research, supporting future efforts in\nmodel development, validation, and clinical translation.",
    "categories": [
      "cs.CV",
      "cs.AI",
      "cs.LG"
    ],
    "primary_category": "cs.CV",
    "comment": "2 tables, 6 figures",
    "pdf_url": "http://arxiv.org/pdf/2405.04605v3",
    "published_date": "2024-05-07 18:36:40 UTC",
    "updated_date": "2025-04-23 21:20:50 UTC"
  },
  {
    "arxiv_id": "2405.04532v3",
    "title": "QServe: W4A8KV4 Quantization and System Co-design for Efficient LLM Serving",
    "authors": [
      "Yujun Lin",
      "Haotian Tang",
      "Shang Yang",
      "Zhekai Zhang",
      "Guangxuan Xiao",
      "Chuang Gan",
      "Song Han"
    ],
    "abstract": "Quantization can accelerate large language model (LLM) inference. Going\nbeyond INT8 quantization, the research community is actively exploring even\nlower precision, such as INT4. Nonetheless, state-of-the-art INT4 quantization\ntechniques only accelerate low-batch, edge LLM inference, failing to deliver\nperformance gains in large-batch, cloud-based LLM serving. We uncover a\ncritical issue: existing INT4 quantization methods suffer from significant\nruntime overhead (20-90%) when dequantizing either weights or partial sums on\nGPUs. To address this challenge, we introduce QoQ, a W4A8KV4 quantization\nalgorithm with 4-bit weight, 8-bit activation, and 4-bit KV cache. QoQ stands\nfor quattuor-octo-quattuor, which represents 4-8-4 in Latin. QoQ is implemented\nby the QServe inference library that achieves measured speedup. The key insight\ndriving QServe is that the efficiency of LLM serving on GPUs is critically\ninfluenced by operations on low-throughput CUDA cores. Building upon this\ninsight, in QoQ algorithm, we introduce progressive quantization that can allow\nlow dequantization overhead in W4A8 GEMM. Additionally, we develop\nSmoothAttention to effectively mitigate the accuracy degradation incurred by\n4-bit KV quantization. In the QServe system, we perform compute-aware weight\nreordering and take advantage of register-level parallelism to reduce\ndequantization latency. We also make fused attention memory-bound, harnessing\nthe performance gain brought by KV4 quantization. As a result, QServe improves\nthe maximum achievable serving throughput of Llama-3-8B by 1.2x on A100, 1.4x\non L40S; and Qwen1.5-72B by 2.4x on A100, 3.5x on L40S, compared to\nTensorRT-LLM. Remarkably, QServe on L40S GPU can achieve even higher throughput\nthan TensorRT-LLM on A100. Thus, QServe effectively reduces the dollar cost of\nLLM serving by 3x. Code is available at\nhttps://github.com/mit-han-lab/omniserve.",
    "categories": [
      "cs.CL",
      "cs.AI",
      "cs.LG",
      "cs.PF"
    ],
    "primary_category": "cs.CL",
    "comment": "The first three authors contribute equally to this project and are\n  listed in the alphabetical order. Yujun Lin leads the quantization algorithm,\n  Haotian Tang and Shang Yang lead the GPU kernels and the serving system. Code\n  is available at https://github.com/mit-han-lab/omniserve",
    "pdf_url": "http://arxiv.org/pdf/2405.04532v3",
    "published_date": "2024-05-07 17:59:30 UTC",
    "updated_date": "2025-05-01 02:14:05 UTC"
  },
  {
    "arxiv_id": "2405.04517v2",
    "title": "xLSTM: Extended Long Short-Term Memory",
    "authors": [
      "Maximilian Beck",
      "Korbinian Pöppel",
      "Markus Spanring",
      "Andreas Auer",
      "Oleksandra Prudnikova",
      "Michael Kopp",
      "Günter Klambauer",
      "Johannes Brandstetter",
      "Sepp Hochreiter"
    ],
    "abstract": "In the 1990s, the constant error carousel and gating were introduced as the\ncentral ideas of the Long Short-Term Memory (LSTM). Since then, LSTMs have\nstood the test of time and contributed to numerous deep learning success\nstories, in particular they constituted the first Large Language Models (LLMs).\nHowever, the advent of the Transformer technology with parallelizable\nself-attention at its core marked the dawn of a new era, outpacing LSTMs at\nscale. We now raise a simple question: How far do we get in language modeling\nwhen scaling LSTMs to billions of parameters, leveraging the latest techniques\nfrom modern LLMs, but mitigating known limitations of LSTMs? Firstly, we\nintroduce exponential gating with appropriate normalization and stabilization\ntechniques. Secondly, we modify the LSTM memory structure, obtaining: (i) sLSTM\nwith a scalar memory, a scalar update, and new memory mixing, (ii) mLSTM that\nis fully parallelizable with a matrix memory and a covariance update rule.\nIntegrating these LSTM extensions into residual block backbones yields xLSTM\nblocks that are then residually stacked into xLSTM architectures. Exponential\ngating and modified memory structures boost xLSTM capabilities to perform\nfavorably when compared to state-of-the-art Transformers and State Space\nModels, both in performance and scaling.",
    "categories": [
      "cs.LG",
      "cs.AI",
      "stat.ML"
    ],
    "primary_category": "cs.LG",
    "comment": "Code available at https://github.com/NX-AI/xlstm",
    "pdf_url": "http://arxiv.org/pdf/2405.04517v2",
    "published_date": "2024-05-07 17:50:21 UTC",
    "updated_date": "2024-12-06 15:42:07 UTC"
  },
  {
    "arxiv_id": "2405.04513v1",
    "title": "Switchable Decision: Dynamic Neural Generation Networks",
    "authors": [
      "Shujian Zhang",
      "Korawat Tanwisuth",
      "Chengyue Gong",
      "Pengcheng He",
      "Mingyuan Zhou"
    ],
    "abstract": "Auto-regressive generation models achieve competitive performance across many\ndifferent NLP tasks such as summarization, question answering, and\nclassifications. However, they are also known for being slow in inference,\nwhich makes them challenging to deploy in real-time applications. We propose a\nswitchable decision to accelerate inference by dynamically assigning\ncomputation resources for each data instance. Automatically making decisions on\nwhere to skip and how to balance quality and computation cost with constrained\noptimization, our dynamic neural generation networks enforce the efficient\ninference path and determine the optimized trade-off. Experiments across\nquestion answering, summarization, and classification benchmarks show that our\nmethod benefits from less computation cost during inference while keeping the\nsame accuracy. Extensive experiments and ablation studies demonstrate that our\nmethod can be general, effective, and beneficial for many NLP tasks.",
    "categories": [
      "cs.CL",
      "cs.AI",
      "cs.LG"
    ],
    "primary_category": "cs.CL",
    "comment": "Accepted to ICML 2024",
    "pdf_url": "http://arxiv.org/pdf/2405.04513v1",
    "published_date": "2024-05-07 17:44:54 UTC",
    "updated_date": "2024-05-07 17:44:54 UTC"
  },
  {
    "arxiv_id": "2405.04495v1",
    "title": "Toward In-Context Teaching: Adapting Examples to Students' Misconceptions",
    "authors": [
      "Alexis Ross",
      "Jacob Andreas"
    ],
    "abstract": "When a teacher provides examples for a student to study, these examples must\nbe informative, enabling a student to progress from their current state toward\na target concept or skill. Good teachers must therefore simultaneously infer\nwhat students already know and adapt their teaching to students' changing state\nof knowledge. There is increasing interest in using computational models,\nparticularly large language models, as pedagogical tools. As students, language\nmodels in particular have shown a remarkable ability to adapt to new tasks\ngiven small numbers of examples. But how effectively can these models adapt as\nteachers to students of different types? To study this question, we introduce a\nsuite of models and evaluation methods we call AdapT. AdapT has two components:\n(1) a collection of simulated Bayesian student models that can be used for\nevaluation of automated teaching methods; (2) a platform for evaluation with\nhuman students, to characterize the real-world effectiveness of these methods.\nWe additionally introduce (3) AToM, a new probabilistic model for adaptive\nteaching that jointly infers students' past beliefs and optimizes for the\ncorrectness of future beliefs. In evaluations of simulated students across\nthree learning domains (fraction arithmetic, English morphology, function\nlearning), AToM systematically outperforms LLM-based and standard Bayesian\nteaching models. In human experiments, both AToM and LLMs outperform\nnon-adaptive random example selection. Our results highlight both the\ndifficulty of the adaptive teaching task and the potential of learned adaptive\nmodels for solving it.",
    "categories": [
      "cs.CL",
      "cs.AI",
      "cs.LG"
    ],
    "primary_category": "cs.CL",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2405.04495v1",
    "published_date": "2024-05-07 17:05:27 UTC",
    "updated_date": "2024-05-07 17:05:27 UTC"
  },
  {
    "arxiv_id": "2405.04491v1",
    "title": "TorchDriveEnv: A Reinforcement Learning Benchmark for Autonomous Driving with Reactive, Realistic, and Diverse Non-Playable Characters",
    "authors": [
      "Jonathan Wilder Lavington",
      "Ke Zhang",
      "Vasileios Lioutas",
      "Matthew Niedoba",
      "Yunpeng Liu",
      "Dylan Green",
      "Saeid Naderiparizi",
      "Xiaoxuan Liang",
      "Setareh Dabiri",
      "Adam Ścibior",
      "Berend Zwartsenberg",
      "Frank Wood"
    ],
    "abstract": "The training, testing, and deployment, of autonomous vehicles requires\nrealistic and efficient simulators. Moreover, because of the high variability\nbetween different problems presented in different autonomous systems, these\nsimulators need to be easy to use, and easy to modify. To address these\nproblems we introduce TorchDriveSim and its benchmark extension TorchDriveEnv.\nTorchDriveEnv is a lightweight reinforcement learning benchmark programmed\nentirely in Python, which can be modified to test a number of different factors\nin learned vehicle behavior, including the effect of varying kinematic models,\nagent types, and traffic control patterns. Most importantly unlike many replay\nbased simulation approaches, TorchDriveEnv is fully integrated with a state of\nthe art behavioral simulation API. This allows users to train and evaluate\ndriving models alongside data driven Non-Playable Characters (NPC) whose\ninitializations and driving behavior are reactive, realistic, and diverse. We\nillustrate the efficiency and simplicity of TorchDriveEnv by evaluating common\nreinforcement learning baselines in both training and validation environments.\nOur experiments show that TorchDriveEnv is easy to use, but difficult to solve.",
    "categories": [
      "cs.AI",
      "cs.LG",
      "cs.MA",
      "cs.RO"
    ],
    "primary_category": "cs.AI",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2405.04491v1",
    "published_date": "2024-05-07 17:02:02 UTC",
    "updated_date": "2024-05-07 17:02:02 UTC"
  },
  {
    "arxiv_id": "2405.04480v2",
    "title": "Concentration Tail-Bound Analysis of Coevolutionary and Bandit Learning Algorithms",
    "authors": [
      "Per Kristian Lehre",
      "Shishen Lin"
    ],
    "abstract": "Runtime analysis, as a branch of the theory of AI, studies how the number of\niterations algorithms take before finding a solution (its runtime) depends on\nthe design of the algorithm and the problem structure. Drift analysis is a\nstate-of-the-art tool for estimating the runtime of randomised algorithms, such\nas evolutionary and bandit algorithms. Drift refers roughly to the expected\nprogress towards the optimum per iteration. This paper considers the problem of\nderiving concentration tail-bounds on the runtime/regret of algorithms. It\nprovides a novel drift theorem that gives precise exponential tail-bounds given\npositive, weak, zero and even negative drift. Previously, such exponential tail\nbounds were missing in the case of weak, zero, or negative drift. Our drift\ntheorem can be used to prove a strong concentration of the runtime/regret of\nalgorithms in AI. For example, we prove that the regret of the \\rwab bandit\nalgorithm is highly concentrated, while previous analyses only considered the\nexpected regret. This means that the algorithm obtains the optimum within a\ngiven time frame with high probability, i.e. a form of algorithm reliability.\nMoreover, our theorem implies that the time needed by the co-evolutionary\nalgorithm RLS-PD to obtain a Nash equilibrium in a \\bilinear max-min-benchmark\nproblem is highly concentrated. However, we also prove that the algorithm\nforgets the Nash equilibrium, and the time until this occurs is highly\nconcentrated. This highlights a weakness in the RLS-PD which should be\naddressed by future work.",
    "categories": [
      "cs.NE",
      "cs.AI"
    ],
    "primary_category": "cs.NE",
    "comment": "Accepted at International Joint Conference on Artificial Intelligence\n  (IJCAI) 2024",
    "pdf_url": "http://arxiv.org/pdf/2405.04480v2",
    "published_date": "2024-05-07 16:45:15 UTC",
    "updated_date": "2024-05-11 00:41:19 UTC"
  },
  {
    "arxiv_id": "2405.04459v1",
    "title": "A Significantly Better Class of Activation Functions Than ReLU Like Activation Functions",
    "authors": [
      "Mathew Mithra Noel",
      "Yug Oswal"
    ],
    "abstract": "This paper introduces a significantly better class of activation functions\nthan the almost universally used ReLU like and Sigmoidal class of activation\nfunctions. Two new activation functions referred to as the Cone and\nParabolic-Cone that differ drastically from popular activation functions and\nsignificantly outperform these on the CIFAR-10 and Imagenette benchmmarks are\nproposed. The cone activation functions are positive only on a finite interval\nand are strictly negative except at the end-points of the interval, where they\nbecome zero. Thus the set of inputs that produce a positive output for a neuron\nwith cone activation functions is a hyperstrip and not a half-space as is the\nusual case. Since a hyper strip is the region between two parallel\nhyper-planes, it allows neurons to more finely divide the input feature space\ninto positive and negative classes than with infinitely wide half-spaces. In\nparticular the XOR function can be learn by a single neuron with cone-like\nactivation functions. Both the cone and parabolic-cone activation functions are\nshown to achieve higher accuracies with significantly fewer neurons on\nbenchmarks. The results presented in this paper indicate that many nonlinear\nreal-world datasets may be separated with fewer hyperstrips than half-spaces.\nThe Cone and Parabolic-Cone activation functions have larger derivatives than\nReLU and are shown to significantly speedup training.",
    "categories": [
      "cs.AI",
      "cs.CV",
      "cs.LG",
      "cs.NE",
      "68T07"
    ],
    "primary_category": "cs.AI",
    "comment": "14 pages",
    "pdf_url": "http://arxiv.org/pdf/2405.04459v1",
    "published_date": "2024-05-07 16:24:03 UTC",
    "updated_date": "2024-05-07 16:24:03 UTC"
  },
  {
    "arxiv_id": "2405.04453v1",
    "title": "Towards Continual Knowledge Graph Embedding via Incremental Distillation",
    "authors": [
      "Jiajun Liu",
      "Wenjun Ke",
      "Peng Wang",
      "Ziyu Shang",
      "Jinhua Gao",
      "Guozheng Li",
      "Ke Ji",
      "Yanhe Liu"
    ],
    "abstract": "Traditional knowledge graph embedding (KGE) methods typically require\npreserving the entire knowledge graph (KG) with significant training costs when\nnew knowledge emerges. To address this issue, the continual knowledge graph\nembedding (CKGE) task has been proposed to train the KGE model by learning\nemerging knowledge efficiently while simultaneously preserving decent old\nknowledge. However, the explicit graph structure in KGs, which is critical for\nthe above goal, has been heavily ignored by existing CKGE methods. On the one\nhand, existing methods usually learn new triples in a random order, destroying\nthe inner structure of new KGs. On the other hand, old triples are preserved\nwith equal priority, failing to alleviate catastrophic forgetting effectively.\nIn this paper, we propose a competitive method for CKGE based on incremental\ndistillation (IncDE), which considers the full use of the explicit graph\nstructure in KGs. First, to optimize the learning order, we introduce a\nhierarchical strategy, ranking new triples for layer-by-layer learning. By\nemploying the inter- and intra-hierarchical orders together, new triples are\ngrouped into layers based on the graph structure features. Secondly, to\npreserve the old knowledge effectively, we devise a novel incremental\ndistillation mechanism, which facilitates the seamless transfer of entity\nrepresentations from the previous layer to the next one, promoting old\nknowledge preservation. Finally, we adopt a two-stage training paradigm to\navoid the over-corruption of old knowledge influenced by under-trained new\nknowledge. Experimental results demonstrate the superiority of IncDE over\nstate-of-the-art baselines. Notably, the incremental distillation mechanism\ncontributes to improvements of 0.2%-6.5% in the mean reciprocal rank (MRR)\nscore.",
    "categories": [
      "cs.AI"
    ],
    "primary_category": "cs.AI",
    "comment": "Accepted by AAAI 2024",
    "pdf_url": "http://arxiv.org/pdf/2405.04453v1",
    "published_date": "2024-05-07 16:16:00 UTC",
    "updated_date": "2024-05-07 16:16:00 UTC"
  },
  {
    "arxiv_id": "2405.04443v1",
    "title": "POV Learning: Individual Alignment of Multimodal Models using Human Perception",
    "authors": [
      "Simon Werner",
      "Katharina Christ",
      "Laura Bernardy",
      "Marion G. Müller",
      "Achim Rettinger"
    ],
    "abstract": "Aligning machine learning systems with human expectations is mostly attempted\nby training with manually vetted human behavioral samples, typically explicit\nfeedback. This is done on a population level since the context that is\ncapturing the subjective Point-Of-View (POV) of a concrete person in a specific\nsituational context is not retained in the data. However, we argue that\nalignment on an individual level can boost the subjective predictive\nperformance for the individual user interacting with the system considerably.\nSince perception differs for each person, the same situation is observed\ndifferently. Consequently, the basis for decision making and the subsequent\nreasoning processes and observable reactions differ. We hypothesize that\nindividual perception patterns can be used for improving the alignment on an\nindividual level. We test this, by integrating perception information into\nmachine learning systems and measuring their predictive performance\nwrt.~individual subjective assessments. For our empirical study, we collect a\nnovel data set of multimodal stimuli and corresponding eye tracking sequences\nfor the novel task of Perception-Guided Crossmodal Entailment and tackle it\nwith our Perception-Guided Multimodal Transformer. Our findings suggest that\nexploiting individual perception signals for the machine learning of subjective\nhuman assessments provides a valuable cue for individual alignment. It does not\nonly improve the overall predictive performance from the point-of-view of the\nindividual user but might also contribute to steering AI systems towards every\nperson's individual expectations and values.",
    "categories": [
      "cs.AI"
    ],
    "primary_category": "cs.AI",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2405.04443v1",
    "published_date": "2024-05-07 16:07:29 UTC",
    "updated_date": "2024-05-07 16:07:29 UTC"
  },
  {
    "arxiv_id": "2405.04442v1",
    "title": "AugmenTory: A Fast and Flexible Polygon Augmentation Library",
    "authors": [
      "Tanaz Ghahremani",
      "Mohammad Hoseyni",
      "Mohammad Javad Ahmadi",
      "Pouria Mehrabi",
      "Amirhossein Nikoofard"
    ],
    "abstract": "Data augmentation is a key technique for addressing the challenge of limited\ndatasets, which have become a major component in the training procedures of\nimage processing. Techniques such as geometric transformations and color space\nadjustments have been thoroughly tested for their ability to artificially\nexpand training datasets and generate semi-realistic data for training\npurposes. Data augmentation is the most important key to addressing the\nchallenge of limited datasets, which have become a major component of image\nprocessing training procedures. Data augmentation techniques, such as geometric\ntransformations and color space adjustments, are thoroughly tested for their\nability to artificially expand training datasets and generate semi-realistic\ndata for training purposes. Polygons play a crucial role in instance\nsegmentation and have seen a surge in use across advanced models, such as\nYOLOv8. Despite their growing popularity, the lack of specialized libraries\nhampers the polygon-augmentation process. This paper introduces a novel\nsolution to this challenge, embodied in the newly developed AugmenTory library.\nNotably, AugmenTory offers reduced computational demands in both time and space\ncompared to existing methods. Additionally, the library includes a\npostprocessing thresholding feature. The AugmenTory package is publicly\navailable on GitHub, where interested users can access the source code:\nhttps://github.com/Smartory/AugmenTory",
    "categories": [
      "cs.CV",
      "cs.AI"
    ],
    "primary_category": "cs.CV",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2405.04442v1",
    "published_date": "2024-05-07 16:07:05 UTC",
    "updated_date": "2024-05-07 16:07:05 UTC"
  },
  {
    "arxiv_id": "2405.04434v5",
    "title": "DeepSeek-V2: A Strong, Economical, and Efficient Mixture-of-Experts Language Model",
    "authors": [
      "DeepSeek-AI",
      "Aixin Liu",
      "Bei Feng",
      "Bin Wang",
      "Bingxuan Wang",
      "Bo Liu",
      "Chenggang Zhao",
      "Chengqi Dengr",
      "Chong Ruan",
      "Damai Dai",
      "Daya Guo",
      "Dejian Yang",
      "Deli Chen",
      "Dongjie Ji",
      "Erhang Li",
      "Fangyun Lin",
      "Fuli Luo",
      "Guangbo Hao",
      "Guanting Chen",
      "Guowei Li",
      "H. Zhang",
      "Hanwei Xu",
      "Hao Yang",
      "Haowei Zhang",
      "Honghui Ding",
      "Huajian Xin",
      "Huazuo Gao",
      "Hui Li",
      "Hui Qu",
      "J. L. Cai",
      "Jian Liang",
      "Jianzhong Guo",
      "Jiaqi Ni",
      "Jiashi Li",
      "Jin Chen",
      "Jingyang Yuan",
      "Junjie Qiu",
      "Junxiao Song",
      "Kai Dong",
      "Kaige Gao",
      "Kang Guan",
      "Lean Wang",
      "Lecong Zhang",
      "Lei Xu",
      "Leyi Xia",
      "Liang Zhao",
      "Liyue Zhang",
      "Meng Li",
      "Miaojun Wang",
      "Mingchuan Zhang",
      "Minghua Zhang",
      "Minghui Tang",
      "Mingming Li",
      "Ning Tian",
      "Panpan Huang",
      "Peiyi Wang",
      "Peng Zhang",
      "Qihao Zhu",
      "Qinyu Chen",
      "Qiushi Du",
      "R. J. Chen",
      "R. L. Jin",
      "Ruiqi Ge",
      "Ruizhe Pan",
      "Runxin Xu",
      "Ruyi Chen",
      "S. S. Li",
      "Shanghao Lu",
      "Shangyan Zhou",
      "Shanhuang Chen",
      "Shaoqing Wu",
      "Shengfeng Ye",
      "Shirong Ma",
      "Shiyu Wang",
      "Shuang Zhou",
      "Shuiping Yu",
      "Shunfeng Zhou",
      "Size Zheng",
      "T. Wang",
      "Tian Pei",
      "Tian Yuan",
      "Tianyu Sun",
      "W. L. Xiao",
      "Wangding Zeng",
      "Wei An",
      "Wen Liu",
      "Wenfeng Liang",
      "Wenjun Gao",
      "Wentao Zhang",
      "X. Q. Li",
      "Xiangyue Jin",
      "Xianzu Wang",
      "Xiao Bi",
      "Xiaodong Liu",
      "Xiaohan Wang",
      "Xiaojin Shen",
      "Xiaokang Chen",
      "Xiaosha Chen",
      "Xiaotao Nie",
      "Xiaowen Sun",
      "Xiaoxiang Wang",
      "Xin Liu",
      "Xin Xie",
      "Xingkai Yu",
      "Xinnan Song",
      "Xinyi Zhou",
      "Xinyu Yang",
      "Xuan Lu",
      "Xuecheng Su",
      "Y. Wu",
      "Y. K. Li",
      "Y. X. Wei",
      "Y. X. Zhu",
      "Yanhong Xu",
      "Yanping Huang",
      "Yao Li",
      "Yao Zhao",
      "Yaofeng Sun",
      "Yaohui Li",
      "Yaohui Wang",
      "Yi Zheng",
      "Yichao Zhang",
      "Yiliang Xiong",
      "Yilong Zhao",
      "Ying He",
      "Ying Tang",
      "Yishi Piao",
      "Yixin Dong",
      "Yixuan Tan",
      "Yiyuan Liu",
      "Yongji Wang",
      "Yongqiang Guo",
      "Yuchen Zhu",
      "Yuduan Wang",
      "Yuheng Zou",
      "Yukun Zha",
      "Yunxian Ma",
      "Yuting Yan",
      "Yuxiang You",
      "Yuxuan Liu",
      "Z. Z. Ren",
      "Zehui Ren",
      "Zhangli Sha",
      "Zhe Fu",
      "Zhen Huang",
      "Zhen Zhang",
      "Zhenda Xie",
      "Zhewen Hao",
      "Zhihong Shao",
      "Zhiniu Wen",
      "Zhipeng Xu",
      "Zhongyu Zhang",
      "Zhuoshu Li",
      "Zihan Wang",
      "Zihui Gu",
      "Zilin Li",
      "Ziwei Xie"
    ],
    "abstract": "We present DeepSeek-V2, a strong Mixture-of-Experts (MoE) language model\ncharacterized by economical training and efficient inference. It comprises 236B\ntotal parameters, of which 21B are activated for each token, and supports a\ncontext length of 128K tokens. DeepSeek-V2 adopts innovative architectures\nincluding Multi-head Latent Attention (MLA) and DeepSeekMoE. MLA guarantees\nefficient inference through significantly compressing the Key-Value (KV) cache\ninto a latent vector, while DeepSeekMoE enables training strong models at an\neconomical cost through sparse computation. Compared with DeepSeek 67B,\nDeepSeek-V2 achieves significantly stronger performance, and meanwhile saves\n42.5% of training costs, reduces the KV cache by 93.3%, and boosts the maximum\ngeneration throughput to 5.76 times. We pretrain DeepSeek-V2 on a high-quality\nand multi-source corpus consisting of 8.1T tokens, and further perform\nSupervised Fine-Tuning (SFT) and Reinforcement Learning (RL) to fully unlock\nits potential. Evaluation results show that, even with only 21B activated\nparameters, DeepSeek-V2 and its chat versions still achieve top-tier\nperformance among open-source models.",
    "categories": [
      "cs.CL",
      "cs.AI"
    ],
    "primary_category": "cs.CL",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2405.04434v5",
    "published_date": "2024-05-07 15:56:43 UTC",
    "updated_date": "2024-06-19 06:04:17 UTC"
  },
  {
    "arxiv_id": "2405.04407v2",
    "title": "Super-Exponential Regret for UCT, AlphaGo and Variants",
    "authors": [
      "Laurent Orseau",
      "Remi Munos"
    ],
    "abstract": "We improve the proofs of the lower bounds of Coquelin and Munos (2007) that\ndemonstrate that UCT can have $\\exp(\\dots\\exp(1)\\dots)$ regret (with\n$\\Omega(D)$ exp terms) on the $D$-chain environment, and that a `polynomial'\nUCT variant has $\\exp_2(\\exp_2(D - O(\\log D)))$ regret on the same environment\n-- the original proofs contain an oversight for rewards bounded in $[0, 1]$,\nwhich we fix in the present draft. We also adapt the proofs to AlphaGo's MCTS\nand its descendants (e.g., AlphaZero, Leela Zero) to also show $\\exp_2(\\exp_2(D\n- O(\\log D)))$ regret.",
    "categories": [
      "cs.LG",
      "cs.AI"
    ],
    "primary_category": "cs.LG",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2405.04407v2",
    "published_date": "2024-05-07 15:35:30 UTC",
    "updated_date": "2024-05-17 12:15:25 UTC"
  },
  {
    "arxiv_id": "2405.04404v1",
    "title": "Vision Mamba: A Comprehensive Survey and Taxonomy",
    "authors": [
      "Xiao Liu",
      "Chenxu Zhang",
      "Lei Zhang"
    ],
    "abstract": "State Space Model (SSM) is a mathematical model used to describe and analyze\nthe behavior of dynamic systems. This model has witnessed numerous applications\nin several fields, including control theory, signal processing, economics and\nmachine learning. In the field of deep learning, state space models are used to\nprocess sequence data, such as time series analysis, natural language\nprocessing (NLP) and video understanding. By mapping sequence data to state\nspace, long-term dependencies in the data can be better captured. In\nparticular, modern SSMs have shown strong representational capabilities in NLP,\nespecially in long sequence modeling, while maintaining linear time complexity.\nNotably, based on the latest state-space models, Mamba merges time-varying\nparameters into SSMs and formulates a hardware-aware algorithm for efficient\ntraining and inference. Given its impressive efficiency and strong long-range\ndependency modeling capability, Mamba is expected to become a new AI\narchitecture that may outperform Transformer. Recently, a number of works have\nattempted to study the potential of Mamba in various fields, such as general\nvision, multi-modal, medical image analysis and remote sensing image analysis,\nby extending Mamba from natural language domain to visual domain. To fully\nunderstand Mamba in the visual domain, we conduct a comprehensive survey and\npresent a taxonomy study. This survey focuses on Mamba's application to a\nvariety of visual tasks and data types, and discusses its predecessors, recent\nadvances and far-reaching impact on a wide range of domains. Since Mamba is now\non an upward trend, please actively notice us if you have new findings, and new\nprogress on Mamba will be included in this survey in a timely manner and\nupdated on the Mamba project at\nhttps://github.com/lx6c78/Vision-Mamba-A-Comprehensive-Survey-and-Taxonomy.",
    "categories": [
      "cs.CV",
      "cs.AI",
      "cs.CL",
      "cs.LG"
    ],
    "primary_category": "cs.CV",
    "comment": "https://github.com/lx6c78/Vision-Mamba-A-Comprehensive-Survey-and-Taxonomy",
    "pdf_url": "http://arxiv.org/pdf/2405.04404v1",
    "published_date": "2024-05-07 15:30:14 UTC",
    "updated_date": "2024-05-07 15:30:14 UTC"
  },
  {
    "arxiv_id": "2405.04386v1",
    "title": "Pragmatist Intelligence: Where the Principle of Usefulness Can Take ANNs",
    "authors": [
      "Antonio Bikić",
      "Sayan Mukherjee"
    ],
    "abstract": "Artificial neural networks (ANNs) perform extraordinarily on numerous tasks\nincluding classification or prediction, e.g., speech processing and image\nclassification. These new functions are based on a computational model that is\nenabled to select freely all necessary internal model parameters as long as it\neventually delivers the functionality it is supposed to exhibit. Here, we\nreview the connection between the model parameter selection in machine learning\n(ML) algorithms running on ANNs and the epistemological theory of neopragmatism\nfocusing on the theory's utility and anti-representationalist aspects. To\nunderstand the consequences of the model parameter selection of an ANN, we\nsuggest using neopragmatist theories whose implications are well studied.\nIncidentally, neopragmatism's notion of optimization is also based on utility\nconsiderations. This means that applying this approach elegantly reveals the\ninherent connections between optimization in ML, using a numerical method\nduring the learning phase, and optimization in the ethical theory of\nconsequentialism, where it occurs as a maxim of action. We suggest that these\nconnections originate from the way relevance is calculated in ML systems. This\ncould ultimately reveal a tendency for specific actions in ML systems.",
    "categories": [
      "cs.AI",
      "cs.LG"
    ],
    "primary_category": "cs.AI",
    "comment": "16 pages",
    "pdf_url": "http://arxiv.org/pdf/2405.04386v1",
    "published_date": "2024-05-07 15:11:42 UTC",
    "updated_date": "2024-05-07 15:11:42 UTC"
  },
  {
    "arxiv_id": "2405.04373v1",
    "title": "Leveraging LSTM and GAN for Modern Malware Detection",
    "authors": [
      "Ishita Gupta",
      "Sneha Kumari",
      "Priya Jha",
      "Mohona Ghosh"
    ],
    "abstract": "The malware booming is a cyberspace equal to the effect of climate change to\necosystems in terms of danger. In the case of significant investments in\ncybersecurity technologies and staff training, the global community has become\nlocked up in the eternal war with cyber security threats. The multi-form and\nchanging faces of malware are continuously pushing the boundaries of the\ncybersecurity practitioners employ various approaches like detection and\nmitigate in coping with this issue. Some old mannerisms like signature-based\ndetection and behavioral analysis are slow to adapt to the speedy evolution of\nmalware types. Consequently, this paper proposes the utilization of the Deep\nLearning Model, LSTM networks, and GANs to amplify malware detection accuracy\nand speed. A fast-growing, state-of-the-art technology that leverages raw\nbytestream-based data and deep learning architectures, the AI technology\nprovides better accuracy and performance than the traditional methods.\nIntegration of LSTM and GAN model is the technique that is used for the\nsynthetic generation of data, leading to the expansion of the training\ndatasets, and as a result, the detection accuracy is improved. The paper uses\nthe VirusShare dataset which has more than one million unique samples of the\nmalware as the training and evaluation set for the presented models. Through\nthorough data preparation including tokenization, augmentation, as well as\nmodel training, the LSTM and GAN models convey the better performance in the\ntasks compared to straight classifiers. The research outcomes come out with 98%\naccuracy that shows the efficiency of deep learning plays a decisive role in\nproactive cybersecurity defense. Aside from that, the paper studies the output\nof ensemble learning and model fusion methods as a way to reduce biases and\nlift model complexity.",
    "categories": [
      "cs.CR",
      "cs.AI"
    ],
    "primary_category": "cs.CR",
    "comment": "11 pages",
    "pdf_url": "http://arxiv.org/pdf/2405.04373v1",
    "published_date": "2024-05-07 14:57:24 UTC",
    "updated_date": "2024-05-07 14:57:24 UTC"
  },
  {
    "arxiv_id": "2405.04372v2",
    "title": "Explainable machine learning for predicting shellfish toxicity in the Adriatic Sea using long-term monitoring data of HABs",
    "authors": [
      "Martin Marzidovšek",
      "Janja Francé",
      "Vid Podpečan",
      "Stanka Vadnjal",
      "Jožica Dolenc",
      "Patricija Mozetič"
    ],
    "abstract": "In this study, explainable machine learning techniques are applied to predict\nthe toxicity of mussels in the Gulf of Trieste (Adriatic Sea) caused by harmful\nalgal blooms. By analysing a newly created 28-year dataset containing records\nof toxic phytoplankton in mussel farming areas and toxin concentrations in\nmussels (Mytilus galloprovincialis), we train and evaluate the performance of\nML models to accurately predict diarrhetic shellfish poisoning (DSP) events.\nThe random forest model provided the best prediction of positive toxicity\nresults based on the F1 score. Explainability methods such as permutation\nimportance and SHAP identified key species (Dinophysis fortii and D. caudata)\nand environmental factors (salinity, river discharge and precipitation) as the\nbest predictors of DSP outbreaks. These findings are important for improving\nearly warning systems and supporting sustainable aquaculture practices.",
    "categories": [
      "cs.LG",
      "cs.AI"
    ],
    "primary_category": "cs.LG",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2405.04372v2",
    "published_date": "2024-05-07 14:55:42 UTC",
    "updated_date": "2024-05-09 09:46:35 UTC"
  },
  {
    "arxiv_id": "2405.04561v1",
    "title": "Inferring Discussion Topics about Exploitation of Vulnerabilities from Underground Hacking Forums",
    "authors": [
      "Felipe Moreno-Vera"
    ],
    "abstract": "The increasing sophistication of cyber threats necessitates proactive\nmeasures to identify vulnerabilities and potential exploits. Underground\nhacking forums serve as breeding grounds for the exchange of hacking techniques\nand discussions related to exploitation. In this research, we propose an\ninnovative approach using topic modeling to analyze and uncover key themes in\nvulnerabilities discussed within these forums. The objective of our study is to\ndevelop a machine learning-based model that can automatically detect and\nclassify vulnerability-related discussions in underground hacking forums. By\nmonitoring and analyzing the content of these forums, we aim to identify\nemerging vulnerabilities, exploit techniques, and potential threat actors. To\nachieve this, we collect a large-scale dataset consisting of posts and threads\nfrom multiple underground forums. We preprocess and clean the data to ensure\naccuracy and reliability. Leveraging topic modeling techniques, specifically\nLatent Dirichlet Allocation (LDA), we uncover latent topics and their\nassociated keywords within the dataset. This enables us to identify recurring\nthemes and prevalent discussions related to vulnerabilities, exploits, and\npotential targets.",
    "categories": [
      "cs.CR",
      "cs.AI",
      "cs.CY",
      "cs.LG"
    ],
    "primary_category": "cs.CR",
    "comment": "6 pages",
    "pdf_url": "http://arxiv.org/pdf/2405.04561v1",
    "published_date": "2024-05-07 14:54:32 UTC",
    "updated_date": "2024-05-07 14:54:32 UTC"
  },
  {
    "arxiv_id": "2405.04371v1",
    "title": "Community Detection for Heterogeneous Multiple Social Networks",
    "authors": [
      "Ziqing Zhu",
      "Guan Yuan",
      "Tao Zhou",
      "Jiuxin Cao"
    ],
    "abstract": "The community plays a crucial role in understanding user behavior and network\ncharacteristics in social networks. Some users can use multiple social networks\nat once for a variety of objectives. These users are called overlapping users\nwho bridge different social networks. Detecting communities across multiple\nsocial networks is vital for interaction mining, information diffusion, and\nbehavior migration analysis among networks. This paper presents a community\ndetection method based on nonnegative matrix tri-factorization for multiple\nheterogeneous social networks, which formulates a common consensus matrix to\nrepresent the global fused community. Specifically, the proposed method\ninvolves creating adjacency matrices based on network structure and content\nsimilarity, followed by alignment matrices which distinguish overlapping users\nin different social networks. With the generated alignment matrices, the method\ncould enhance the fusion degree of the global community by detecting\noverlapping user communities across networks. The effectiveness of the proposed\nmethod is evaluated with new metrics on Twitter, Instagram, and Tumblr\ndatasets. The results of the experiments demonstrate its superior performance\nin terms of community quality and community fusion.",
    "categories": [
      "cs.SI",
      "cs.AI",
      "cs.CY"
    ],
    "primary_category": "cs.SI",
    "comment": "This paper was accepted by IEEE Transactions on Computational Social\n  Systems(TCSS)",
    "pdf_url": "http://arxiv.org/pdf/2405.04371v1",
    "published_date": "2024-05-07 14:52:34 UTC",
    "updated_date": "2024-05-07 14:52:34 UTC"
  },
  {
    "arxiv_id": "2405.04357v1",
    "title": "Global Scale Self-Supervised Channel Charting with Sensor Fusion",
    "authors": [
      "Omid Esrafilian",
      "Mohsen Ahadi",
      "Florian Kaltenberger",
      "David Gesbert"
    ],
    "abstract": "The sensing and positioning capabilities foreseen in 6G have great potential\nfor technology advancements in various domains, such as future smart cities and\nindustrial use cases. Channel charting has emerged as a promising technology in\nrecent years for radio frequency-based sensing and localization. However, the\naccuracy of these techniques is yet far behind the numbers envisioned in 6G. To\nreduce this gap, in this paper, we propose a novel channel charting technique\ncapitalizing on the time of arrival measurements from surrounding Transmission\nReception Points (TRPs) along with their locations and leveraging sensor fusion\nin channel charting by incorporating laser scanner data during the training\nphase of our algorithm. The proposed algorithm remains self-supervised during\ntraining and test phases, requiring no geometrical models or user position\nground truth. Simulation results validate the achievement of a sub-meter level\nlocalization accuracy using our algorithm 90% of the time, outperforming the\nstate-of-the-art channel charting techniques and the traditional\ntriangulation-based approaches.",
    "categories": [
      "cs.IT",
      "cs.AI",
      "math.IT"
    ],
    "primary_category": "cs.IT",
    "comment": "This paper is submitted to the Globecom 2024 conference",
    "pdf_url": "http://arxiv.org/pdf/2405.04357v1",
    "published_date": "2024-05-07 14:33:45 UTC",
    "updated_date": "2024-05-07 14:33:45 UTC"
  },
  {
    "arxiv_id": "2405.04346v2",
    "title": "Revisiting Character-level Adversarial Attacks for Language Models",
    "authors": [
      "Elias Abad Rocamora",
      "Yongtao Wu",
      "Fanghui Liu",
      "Grigorios G. Chrysos",
      "Volkan Cevher"
    ],
    "abstract": "Adversarial attacks in Natural Language Processing apply perturbations in the\ncharacter or token levels. Token-level attacks, gaining prominence for their\nuse of gradient-based methods, are susceptible to altering sentence semantics,\nleading to invalid adversarial examples. While character-level attacks easily\nmaintain semantics, they have received less attention as they cannot easily\nadopt popular gradient-based methods, and are thought to be easy to defend.\nChallenging these beliefs, we introduce Charmer, an efficient query-based\nadversarial attack capable of achieving high attack success rate (ASR) while\ngenerating highly similar adversarial examples. Our method successfully targets\nboth small (BERT) and large (Llama 2) models. Specifically, on BERT with SST-2,\nCharmer improves the ASR in 4.84% points and the USE similarity in 8% points\nwith respect to the previous art. Our implementation is available in\nhttps://github.com/LIONS-EPFL/Charmer.",
    "categories": [
      "cs.LG",
      "cs.AI",
      "cs.CL",
      "stat.ML"
    ],
    "primary_category": "cs.LG",
    "comment": "Accepted in ICML 2024",
    "pdf_url": "http://arxiv.org/pdf/2405.04346v2",
    "published_date": "2024-05-07 14:23:22 UTC",
    "updated_date": "2024-09-04 15:48:40 UTC"
  },
  {
    "arxiv_id": "2405.04345v1",
    "title": "Novel View Synthesis with Neural Radiance Fields for Industrial Robot Applications",
    "authors": [
      "Markus Hillemann",
      "Robert Langendörfer",
      "Max Heiken",
      "Max Mehltretter",
      "Andreas Schenk",
      "Martin Weinmann",
      "Stefan Hinz",
      "Christian Heipke",
      "Markus Ulrich"
    ],
    "abstract": "Neural Radiance Fields (NeRFs) have become a rapidly growing research field\nwith the potential to revolutionize typical photogrammetric workflows, such as\nthose used for 3D scene reconstruction. As input, NeRFs require multi-view\nimages with corresponding camera poses as well as the interior orientation. In\nthe typical NeRF workflow, the camera poses and the interior orientation are\nestimated in advance with Structure from Motion (SfM). But the quality of the\nresulting novel views, which depends on different parameters such as the number\nand distribution of available images, as well as the accuracy of the related\ncamera poses and interior orientation, is difficult to predict. In addition,\nSfM is a time-consuming pre-processing step, and its quality strongly depends\non the image content. Furthermore, the undefined scaling factor of SfM hinders\nsubsequent steps in which metric information is required. In this paper, we\nevaluate the potential of NeRFs for industrial robot applications. We propose\nan alternative to SfM pre-processing: we capture the input images with a\ncalibrated camera that is attached to the end effector of an industrial robot\nand determine accurate camera poses with metric scale based on the robot\nkinematics. We then investigate the quality of the novel views by comparing\nthem to ground truth, and by computing an internal quality measure based on\nensemble methods. For evaluation purposes, we acquire multiple datasets that\npose challenges for reconstruction typical of industrial applications, like\nreflective objects, poor texture, and fine structures. We show that the\nrobot-based pose determination reaches similar accuracy as SfM in non-demanding\ncases, while having clear advantages in more challenging scenarios. Finally, we\npresent first results of applying the ensemble method to estimate the quality\nof the synthetic novel view in the absence of a ground truth.",
    "categories": [
      "cs.CV",
      "cs.AI",
      "cs.RO"
    ],
    "primary_category": "cs.CV",
    "comment": "8 pages, 8 figures, accepted for publication in The International\n  Archives of the Photogrammetry, Remote Sensing and Spatial Information\n  Sciences (ISPRS Archives) 2024",
    "pdf_url": "http://arxiv.org/pdf/2405.04345v1",
    "published_date": "2024-05-07 14:22:32 UTC",
    "updated_date": "2024-05-07 14:22:32 UTC"
  },
  {
    "arxiv_id": "2405.04344v2",
    "title": "Enhancing Scalability of Metric Differential Privacy via Secret Dataset Partitioning and Benders Decomposition",
    "authors": [
      "Chenxi Qiu"
    ],
    "abstract": "Metric Differential Privacy (mDP) extends the concept of Differential Privacy\n(DP) to serve as a new paradigm of data perturbation. It is designed to protect\nsecret data represented in general metric space, such as text data encoded as\nword embeddings or geo-location data on the road network or grid maps. To\nderive an optimal data perturbation mechanism under mDP, a widely used method\nis linear programming (LP), which, however, might suffer from a polynomial\nexplosion of decision variables, rendering it impractical in large-scale mDP.\n  In this paper, our objective is to develop a new computation framework to\nenhance the scalability of the LP-based mDP. Considering the connections\nestablished by the mDP constraints among the secret records, we partition the\noriginal secret dataset into various subsets. Building upon the partition, we\nreformulate the LP problem for mDP and solve it via Benders Decomposition,\nwhich is composed of two stages: (1) a master program to manage the\nperturbation calculation across subsets and (2) a set of subproblems, each\nmanaging the perturbation derivation within a subset. Our experimental results\non multiple datasets, including geo-location data in the road network/grid\nmaps, text data, and synthetic data, underscore our proposed mechanism's\nsuperior scalability and efficiency.",
    "categories": [
      "cs.AI",
      "cs.CR"
    ],
    "primary_category": "cs.AI",
    "comment": "To be published in IJCAI 2024",
    "pdf_url": "http://arxiv.org/pdf/2405.04344v2",
    "published_date": "2024-05-07 14:19:09 UTC",
    "updated_date": "2024-05-09 04:36:12 UTC"
  },
  {
    "arxiv_id": "2405.04336v2",
    "title": "Temporal and Heterogeneous Graph Neural Network for Remaining Useful Life Prediction",
    "authors": [
      "Zhihao Wen",
      "Yuan Fang",
      "Pengcheng Wei",
      "Fayao Liu",
      "Zhenghua Chen",
      "Min Wu"
    ],
    "abstract": "Predicting Remaining Useful Life (RUL) plays a crucial role in the\nprognostics and health management of industrial systems that involve a variety\nof interrelated sensors. Given a constant stream of time series sensory data\nfrom such systems, deep learning models have risen to prominence at identifying\ncomplex, nonlinear temporal dependencies in these data. In addition to the\ntemporal dependencies of individual sensors, spatial dependencies emerge as\nimportant correlations among these sensors, which can be naturally modelled by\na temporal graph that describes time-varying spatial relationships. However,\nthe majority of existing studies have relied on capturing discrete snapshots of\nthis temporal graph, a coarse-grained approach that leads to loss of temporal\ninformation. Moreover, given the variety of heterogeneous sensors, it becomes\nvital that such inherent heterogeneity is leveraged for RUL prediction in\ntemporal sensor graphs. To capture the nuances of the temporal and spatial\nrelationships and heterogeneous characteristics in an interconnected graph of\nsensors, we introduce a novel model named Temporal and Heterogeneous Graph\nNeural Networks (THGNN). Specifically, THGNN aggregates historical data from\nneighboring nodes to accurately capture the temporal dynamics and spatial\ncorrelations within the stream of sensor data in a fine-grained manner.\nMoreover, the model leverages Feature-wise Linear Modulation (FiLM) to address\nthe diversity of sensor types, significantly improving the model's capacity to\nlearn the heterogeneity in the data sources. Finally, we have validated the\neffectiveness of our approach through comprehensive experiments. Our empirical\nfindings demonstrate significant advancements on the N-CMAPSS dataset,\nachieving improvements of up to 19.2% and 31.6% in terms of two different\nevaluation metrics over state-of-the-art methods.",
    "categories": [
      "cs.AI"
    ],
    "primary_category": "cs.AI",
    "comment": "12 pages",
    "pdf_url": "http://arxiv.org/pdf/2405.04336v2",
    "published_date": "2024-05-07 14:08:57 UTC",
    "updated_date": "2024-06-01 04:49:21 UTC"
  },
  {
    "arxiv_id": "2405.04333v1",
    "title": "A Fourth Wave of Open Data? Exploring the Spectrum of Scenarios for Open Data and Generative AI",
    "authors": [
      "Hannah Chafetz",
      "Sampriti Saxena",
      "Stefaan G. Verhulst"
    ],
    "abstract": "Since late 2022, generative AI has taken the world by storm, with widespread\nuse of tools including ChatGPT, Gemini, and Claude. Generative AI and large\nlanguage model (LLM) applications are transforming how individuals find and\naccess data and knowledge. However, the intricate relationship between open\ndata and generative AI, and the vast potential it holds for driving innovation\nin this field remain underexplored areas. This white paper seeks to unpack the\nrelationship between open data and generative AI and explore possible\ncomponents of a new Fourth Wave of Open Data: Is open data becoming AI ready?\nIs open data moving towards a data commons approach? Is generative AI making\nopen data more conversational? Will generative AI improve open data quality and\nprovenance? Towards this end, we provide a new Spectrum of Scenarios framework.\nThis framework outlines a range of scenarios in which open data and generative\nAI could intersect and what is required from a data quality and provenance\nperspective to make open data ready for those specific scenarios. These\nscenarios include: pertaining, adaptation, inference and insight generation,\ndata augmentation, and open-ended exploration. Through this process, we found\nthat in order for data holders to embrace generative AI to improve open data\naccess and develop greater insights from open data, they first must make\nprogress around five key areas: enhance transparency and documentation, uphold\nquality and integrity, promote interoperability and standards, improve\naccessibility and useability, and address ethical considerations.",
    "categories": [
      "cs.AI"
    ],
    "primary_category": "cs.AI",
    "comment": "58 pages",
    "pdf_url": "http://arxiv.org/pdf/2405.04333v1",
    "published_date": "2024-05-07 14:01:33 UTC",
    "updated_date": "2024-05-07 14:01:33 UTC"
  },
  {
    "arxiv_id": "2405.04324v1",
    "title": "Granite Code Models: A Family of Open Foundation Models for Code Intelligence",
    "authors": [
      "Mayank Mishra",
      "Matt Stallone",
      "Gaoyuan Zhang",
      "Yikang Shen",
      "Aditya Prasad",
      "Adriana Meza Soria",
      "Michele Merler",
      "Parameswaran Selvam",
      "Saptha Surendran",
      "Shivdeep Singh",
      "Manish Sethi",
      "Xuan-Hong Dang",
      "Pengyuan Li",
      "Kun-Lung Wu",
      "Syed Zawad",
      "Andrew Coleman",
      "Matthew White",
      "Mark Lewis",
      "Raju Pavuluri",
      "Yan Koyfman",
      "Boris Lublinsky",
      "Maximilien de Bayser",
      "Ibrahim Abdelaziz",
      "Kinjal Basu",
      "Mayank Agarwal",
      "Yi Zhou",
      "Chris Johnson",
      "Aanchal Goyal",
      "Hima Patel",
      "Yousaf Shah",
      "Petros Zerfos",
      "Heiko Ludwig",
      "Asim Munawar",
      "Maxwell Crouse",
      "Pavan Kapanipathi",
      "Shweta Salaria",
      "Bob Calio",
      "Sophia Wen",
      "Seetharami Seelam",
      "Brian Belgodere",
      "Carlos Fonseca",
      "Amith Singhee",
      "Nirmit Desai",
      "David D. Cox",
      "Ruchir Puri",
      "Rameswar Panda"
    ],
    "abstract": "Large Language Models (LLMs) trained on code are revolutionizing the software\ndevelopment process. Increasingly, code LLMs are being integrated into software\ndevelopment environments to improve the productivity of human programmers, and\nLLM-based agents are beginning to show promise for handling complex tasks\nautonomously. Realizing the full potential of code LLMs requires a wide range\nof capabilities, including code generation, fixing bugs, explaining and\ndocumenting code, maintaining repositories, and more. In this work, we\nintroduce the Granite series of decoder-only code models for code generative\ntasks, trained with code written in 116 programming languages. The Granite Code\nmodels family consists of models ranging in size from 3 to 34 billion\nparameters, suitable for applications ranging from complex application\nmodernization tasks to on-device memory-constrained use cases. Evaluation on a\ncomprehensive set of tasks demonstrates that Granite Code models consistently\nreaches state-of-the-art performance among available open-source code LLMs. The\nGranite Code model family was optimized for enterprise software development\nworkflows and performs well across a range of coding tasks (e.g. code\ngeneration, fixing and explanation), making it a versatile all around code\nmodel. We release all our Granite Code models under an Apache 2.0 license for\nboth research and commercial use.",
    "categories": [
      "cs.AI",
      "cs.CL",
      "cs.SE"
    ],
    "primary_category": "cs.AI",
    "comment": "Corresponding Authors: Rameswar Panda, Ruchir Puri; Equal\n  Contributors: Mayank Mishra, Matt Stallone, Gaoyuan Zhang",
    "pdf_url": "http://arxiv.org/pdf/2405.04324v1",
    "published_date": "2024-05-07 13:50:40 UTC",
    "updated_date": "2024-05-07 13:50:40 UTC"
  },
  {
    "arxiv_id": "2405.04323v1",
    "title": "Beyond human subjectivity and error: a novel AI grading system",
    "authors": [
      "Alexandra Gobrecht",
      "Felix Tuma",
      "Moritz Möller",
      "Thomas Zöller",
      "Mark Zakhvatkin",
      "Alexandra Wuttig",
      "Holger Sommerfeldt",
      "Sven Schütt"
    ],
    "abstract": "The grading of open-ended questions is a high-effort, high-impact task in\neducation. Automating this task promises a significant reduction in workload\nfor education professionals, as well as more consistent grading outcomes for\nstudents, by circumventing human subjectivity and error. While recent\nbreakthroughs in AI technology might facilitate such automation, this has not\nbeen demonstrated at scale. It this paper, we introduce a novel automatic short\nanswer grading (ASAG) system. The system is based on a fine-tuned open-source\ntransformer model which we trained on large set of exam data from university\ncourses across a large range of disciplines. We evaluated the trained model's\nperformance against held-out test data in a first experiment and found high\naccuracy levels across a broad spectrum of unseen questions, even in unseen\ncourses. We further compared the performance of our model with that of\ncertified human domain experts in a second experiment: we first assembled\nanother test dataset from real historical exams - the historic grades contained\nin that data were awarded to students in a regulated, legally binding\nexamination process; we therefore considered them as ground truth for our\nexperiment. We then asked certified human domain experts and our model to grade\nthe historic student answers again without disclosing the historic grades.\nFinally, we compared the hence obtained grades with the historic grades (our\nground truth). We found that for the courses examined, the model deviated less\nfrom the official historic grades than the human re-graders - the model's\nmedian absolute error was 44 % smaller than the human re-graders', implying\nthat the model is more consistent than humans in grading. These results suggest\nthat leveraging AI enhanced grading can reduce human subjectivity, improve\nconsistency and thus ultimately increase fairness.",
    "categories": [
      "cs.AI"
    ],
    "primary_category": "cs.AI",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2405.04323v1",
    "published_date": "2024-05-07 13:49:59 UTC",
    "updated_date": "2024-05-07 13:49:59 UTC"
  },
  {
    "arxiv_id": "2405.04311v1",
    "title": "Cross-IQA: Unsupervised Learning for Image Quality Assessment",
    "authors": [
      "Zhen Zhang"
    ],
    "abstract": "Automatic perception of image quality is a challenging problem that impacts\nbillions of Internet and social media users daily. To advance research in this\nfield, we propose a no-reference image quality assessment (NR-IQA) method\ntermed Cross-IQA based on vision transformer(ViT) model. The proposed Cross-IQA\nmethod can learn image quality features from unlabeled image data. We construct\nthe pretext task of synthesized image reconstruction to unsupervised extract\nthe image quality information based ViT block. The pretrained encoder of\nCross-IQA is used to fine-tune a linear regression model for score prediction.\nExperimental results show that Cross-IQA can achieve state-of-the-art\nperformance in assessing the low-frequency degradation information (e.g., color\nchange, blurring, etc.) of images compared with the classical full-reference\nIQA and NR-IQA under the same datasets.",
    "categories": [
      "cs.CV",
      "cs.AI",
      "eess.IV"
    ],
    "primary_category": "cs.CV",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2405.04311v1",
    "published_date": "2024-05-07 13:35:51 UTC",
    "updated_date": "2024-05-07 13:35:51 UTC"
  },
  {
    "arxiv_id": "2405.04309v3",
    "title": "Non-rigid Structure-from-Motion: Temporally-smooth Procrustean Alignment and Spatially-variant Deformation Modeling",
    "authors": [
      "Jiawei Shi",
      "Hui Deng",
      "Yuchao Dai"
    ],
    "abstract": "Even though Non-rigid Structure-from-Motion (NRSfM) has been extensively\nstudied and great progress has been made, there are still key challenges that\nhinder their broad real-world applications: 1) the inherent motion/rotation\nambiguity requires either explicit camera motion recovery with extra constraint\nor complex Procrustean Alignment; 2) existing low-rank modeling of the global\nshape can over-penalize drastic deformations in the 3D shape sequence. This\npaper proposes to resolve the above issues from a spatial-temporal modeling\nperspective. First, we propose a novel Temporally-smooth Procrustean Alignment\nmodule that estimates 3D deforming shapes and adjusts the camera motion by\naligning the 3D shape sequence consecutively. Our new alignment module remedies\nthe requirement of complex reference 3D shape during alignment, which is more\nconductive to non-isotropic deformation modeling. Second, we propose a\nspatial-weighted approach to enforce the low-rank constraint adaptively at\ndifferent locations to accommodate drastic spatially-variant deformation\nreconstruction better. Our modeling outperform existing low-rank based methods,\nand extensive experiments across different datasets validate the effectiveness\nof our method.",
    "categories": [
      "cs.CV",
      "cs.AI"
    ],
    "primary_category": "cs.CV",
    "comment": "Accepted by CVPR 2024; The new version adds additional experiments\n  and corrects typos",
    "pdf_url": "http://arxiv.org/pdf/2405.04309v3",
    "published_date": "2024-05-07 13:33:50 UTC",
    "updated_date": "2025-03-04 08:37:43 UTC"
  },
  {
    "arxiv_id": "2405.04307v1",
    "title": "Improving Offline Reinforcement Learning with Inaccurate Simulators",
    "authors": [
      "Yiwen Hou",
      "Haoyuan Sun",
      "Jinming Ma",
      "Feng Wu"
    ],
    "abstract": "Offline reinforcement learning (RL) provides a promising approach to avoid\ncostly online interaction with the real environment. However, the performance\nof offline RL highly depends on the quality of the datasets, which may cause\nextrapolation error in the learning process. In many robotic applications, an\ninaccurate simulator is often available. However, the data directly collected\nfrom the inaccurate simulator cannot be directly used in offline RL due to the\nwell-known exploration-exploitation dilemma and the dynamic gap between\ninaccurate simulation and the real environment. To address these issues, we\npropose a novel approach to combine the offline dataset and the inaccurate\nsimulation data in a better manner. Specifically, we pre-train a generative\nadversarial network (GAN) model to fit the state distribution of the offline\ndataset. Given this, we collect data from the inaccurate simulator starting\nfrom the distribution provided by the generator and reweight the simulated data\nusing the discriminator. Our experimental results in the D4RL benchmark and a\nreal-world manipulation task confirm that our method can benefit more from both\ninaccurate simulator and limited offline datasets to achieve better performance\nthan the state-of-the-art methods.",
    "categories": [
      "cs.RO",
      "cs.AI",
      "cs.LG"
    ],
    "primary_category": "cs.RO",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2405.04307v1",
    "published_date": "2024-05-07 13:29:41 UTC",
    "updated_date": "2024-05-07 13:29:41 UTC"
  },
  {
    "arxiv_id": "2405.04305v1",
    "title": "A New Dataset and Comparative Study for Aphid Cluster Detection and Segmentation in Sorghum Fields",
    "authors": [
      "Raiyan Rahman",
      "Christopher Indris",
      "Goetz Bramesfeld",
      "Tianxiao Zhang",
      "Kaidong Li",
      "Xiangyu Chen",
      "Ivan Grijalva",
      "Brian McCornack",
      "Daniel Flippo",
      "Ajay Sharda",
      "Guanghui Wang"
    ],
    "abstract": "Aphid infestations are one of the primary causes of extensive damage to wheat\nand sorghum fields and are one of the most common vectors for plant viruses,\nresulting in significant agricultural yield losses. To address this problem,\nfarmers often employ the inefficient use of harmful chemical pesticides that\nhave negative health and environmental impacts. As a result, a large amount of\npesticide is wasted on areas without significant pest infestation. This brings\nto attention the urgent need for an intelligent autonomous system that can\nlocate and spray sufficiently large infestations selectively within the complex\ncrop canopies. We have developed a large multi-scale dataset for aphid cluster\ndetection and segmentation, collected from actual sorghum fields and\nmeticulously annotated to include clusters of aphids. Our dataset comprises a\ntotal of 54,742 image patches, showcasing a variety of viewpoints, diverse\nlighting conditions, and multiple scales, highlighting its effectiveness for\nreal-world applications. In this study, we trained and evaluated four real-time\nsemantic segmentation models and three object detection models specifically for\naphid cluster segmentation and detection. Considering the balance between\naccuracy and efficiency, Fast-SCNN delivered the most effective segmentation\nresults, achieving 80.46% mean precision, 81.21% mean recall, and 91.66 frames\nper second (FPS). For object detection, RT-DETR exhibited the best overall\nperformance with a 61.63% mean average precision (mAP), 92.6% mean recall, and\n72.55 on an NVIDIA V100 GPU. Our experiments further indicate that aphid\ncluster segmentation is more suitable for assessing aphid infestations than\nusing detection models.",
    "categories": [
      "cs.CV",
      "cs.AI"
    ],
    "primary_category": "cs.CV",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2405.04305v1",
    "published_date": "2024-05-07 13:27:58 UTC",
    "updated_date": "2024-05-07 13:27:58 UTC"
  },
  {
    "arxiv_id": "2405.04300v1",
    "title": "Behaviour Planning: A Toolkit for Diverse Planning",
    "authors": [
      "Mustafa F Abdelwahed",
      "Joan Espasa",
      "Alice Toniolo",
      "Ian P. Gent"
    ],
    "abstract": "Diverse planning is the problem of generating plans with distinct\ncharacteristics. This is valuable for many real-world scenarios, including\napplications related to plan recognition and business process automation. In\nthis work, we introduce \\emph{Behaviour Planning}, a diverse planning toolkit\nthat can characterise and generate diverse plans based on modular diversity\nmodels. We present a qualitative framework for describing diversity models, a\nplanning approach for generating plans aligned with any given diversity model,\nand provide a practical implementation of an SMT-based behaviour planner. We\nshowcase how the qualitative approach offered by Behaviour Planning allows it\nto overcome various challenges faced by previous approaches. Finally, the\nexperimental evaluation shows the effectiveness of Behaviour Planning in\ngenerating diverse plans compared to state-of-the-art approaches.",
    "categories": [
      "cs.AI"
    ],
    "primary_category": "cs.AI",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2405.04300v1",
    "published_date": "2024-05-07 13:18:22 UTC",
    "updated_date": "2024-05-07 13:18:22 UTC"
  },
  {
    "arxiv_id": "2405.04294v1",
    "title": "Enhancing the Efficiency and Accuracy of Underlying Asset Reviews in Structured Finance: The Application of Multi-agent Framework",
    "authors": [
      "Xiangpeng Wan",
      "Haicheng Deng",
      "Kai Zou",
      "Shiqi Xu"
    ],
    "abstract": "Structured finance, which involves restructuring diverse assets into\nsecurities like MBS, ABS, and CDOs, enhances capital market efficiency but\npresents significant due diligence challenges. This study explores the\nintegration of artificial intelligence (AI) with traditional asset review\nprocesses to improve efficiency and accuracy in structured finance. Using both\nopen-sourced and close-sourced large language models (LLMs), we demonstrate\nthat AI can automate the verification of information between loan applications\nand bank statements effectively. While close-sourced models such as GPT-4 show\nsuperior performance, open-sourced models like LLAMA3 offer a cost-effective\nalternative. Dual-agent systems further increase accuracy, though this comes\nwith higher operational costs. This research highlights AI's potential to\nminimize manual errors and streamline due diligence, suggesting a broader\napplication of AI in financial document analysis and risk management.",
    "categories": [
      "cs.AI"
    ],
    "primary_category": "cs.AI",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2405.04294v1",
    "published_date": "2024-05-07 13:09:49 UTC",
    "updated_date": "2024-05-07 13:09:49 UTC"
  },
  {
    "arxiv_id": "2405.04292v1",
    "title": "Mitigating Clickbait: An Approach to Spoiler Generation Using Multitask Learning",
    "authors": [
      "Sayantan Pal",
      "Souvik Das",
      "Rohini K. Srihari"
    ],
    "abstract": "This study introduces 'clickbait spoiling', a novel technique designed to\ndetect, categorize, and generate spoilers as succinct text responses,\ncountering the curiosity induced by clickbait content. By leveraging a\nmulti-task learning framework, our model's generalization capabilities are\nsignificantly enhanced, effectively addressing the pervasive issue of\nclickbait. The crux of our research lies in generating appropriate spoilers, be\nit a phrase, an extended passage, or multiple, depending on the spoiler type\nrequired. Our methodology integrates two crucial techniques: a refined spoiler\ncategorization method and a modified version of the Question Answering (QA)\nmechanism, incorporated within a multi-task learning paradigm for optimized\nspoiler extraction from context. Notably, we have included fine-tuning methods\nfor models capable of handling longer sequences to accommodate the generation\nof extended spoilers. This research highlights the potential of sophisticated\ntext processing techniques in tackling the omnipresent issue of clickbait,\npromising an enhanced user experience in the digital realm.",
    "categories": [
      "cs.CL",
      "cs.AI"
    ],
    "primary_category": "cs.CL",
    "comment": "Accepted in ICON 2023",
    "pdf_url": "http://arxiv.org/pdf/2405.04292v1",
    "published_date": "2024-05-07 13:09:25 UTC",
    "updated_date": "2024-05-07 13:09:25 UTC"
  },
  {
    "arxiv_id": "2407.01560v1",
    "title": "3DMeshNet: A Three-Dimensional Differential Neural Network for Structured Mesh Generation",
    "authors": [
      "Jiaming Peng",
      "Xinhai Chen",
      "Jie Liu"
    ],
    "abstract": "Mesh generation is a crucial step in numerical simulations, significantly\nimpacting simulation accuracy and efficiency. However, generating meshes\nremains time-consuming and requires expensive computational resources. In this\npaper, we propose a novel method, 3DMeshNet, for three-dimensional structured\nmesh generation. The method embeds the meshing-related differential equations\ninto the loss function of neural networks, formulating the meshing task as an\nunsupervised optimization problem. It takes geometric points as input to learn\nthe potential mapping between parametric and computational domains. After\nsuitable offline training, 3DMeshNet can efficiently output a three-dimensional\nstructured mesh with a user-defined number of quadrilateral/hexahedral cells\nthrough the feed-forward neural prediction. To enhance training stability and\naccelerate convergence, we integrate loss function reweighting through weight\nadjustments and gradient projection alongside applying finite difference\nmethods to streamline derivative computations in the loss. Experiments on\ndifferent cases show that 3DMeshNet is robust and fast. It outperforms neural\nnetwork-based methods and yields superior meshes compared to traditional mesh\npartitioning methods. 3DMeshNet significantly reduces training times by up to\n85% compared to other neural network-based approaches and lowers meshing\noverhead by 4 to 8 times relative to traditional meshing methods.",
    "categories": [
      "cs.GR",
      "cs.AI"
    ],
    "primary_category": "cs.GR",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2407.01560v1",
    "published_date": "2024-05-07 13:07:07 UTC",
    "updated_date": "2024-05-07 13:07:07 UTC"
  },
  {
    "arxiv_id": "2405.04285v1",
    "title": "On the Foundations of Earth and Climate Foundation Models",
    "authors": [
      "Xiao Xiang Zhu",
      "Zhitong Xiong",
      "Yi Wang",
      "Adam J. Stewart",
      "Konrad Heidler",
      "Yuanyuan Wang",
      "Zhenghang Yuan",
      "Thomas Dujardin",
      "Qingsong Xu",
      "Yilei Shi"
    ],
    "abstract": "Foundation models have enormous potential in advancing Earth and climate\nsciences, however, current approaches may not be optimal as they focus on a few\nbasic features of a desirable Earth and climate foundation model. Crafting the\nideal Earth foundation model, we define eleven features which would allow such\na foundation model to be beneficial for any geoscientific downstream\napplication in an environmental- and human-centric manner.We further shed light\non the way forward to achieve the ideal model and to evaluate Earth foundation\nmodels. What comes after foundation models? Energy efficient adaptation,\nadversarial defenses, and interpretability are among the emerging directions.",
    "categories": [
      "cs.AI",
      "eess.SP"
    ],
    "primary_category": "cs.AI",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2405.04285v1",
    "published_date": "2024-05-07 12:54:54 UTC",
    "updated_date": "2024-05-07 12:54:54 UTC"
  },
  {
    "arxiv_id": "2405.04260v2",
    "title": "Verified Neural Compressed Sensing",
    "authors": [
      "Rudy Bunel",
      "Krishnamurthy Dvijotham",
      "M. Pawan Kumar",
      "Alessandro De Palma",
      "Robert Stanforth"
    ],
    "abstract": "We develop the first (to the best of our knowledge) provably correct neural\nnetworks for a precise computational task, with the proof of correctness\ngenerated by an automated verification algorithm without any human input. Prior\nwork on neural network verification has focused on partial specifications that,\neven when satisfied, are not sufficient to ensure that a neural network never\nmakes errors. We focus on applying neural network verification to computational\ntasks with a precise notion of correctness, where a verifiably correct neural\nnetwork provably solves the task at hand with no caveats. In particular, we\ndevelop an approach to train and verify the first provably correct neural\nnetworks for compressed sensing, i.e., recovering sparse vectors from a number\nof measurements smaller than the dimension of the vector. We show that for\nmodest problem dimensions (up to 50), we can train neural networks that\nprovably recover a sparse vector from linear and binarized linear measurements.\nFurthermore, we show that the complexity of the network (number of\nneurons/layers) can be adapted to the problem difficulty and solve problems\nwhere traditional compressed sensing methods are not known to provably work.",
    "categories": [
      "cs.LG",
      "cs.AI"
    ],
    "primary_category": "cs.LG",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2405.04260v2",
    "published_date": "2024-05-07 12:20:12 UTC",
    "updated_date": "2024-05-08 09:38:15 UTC"
  },
  {
    "arxiv_id": "2405.04252v1",
    "title": "VAEneu: A New Avenue for VAE Application on Probabilistic Forecasting",
    "authors": [
      "Alireza Koochali",
      "Ensiye Tahaei",
      "Andreas Dengel",
      "Sheraz Ahmed"
    ],
    "abstract": "This paper presents VAEneu, an innovative autoregressive method for multistep\nahead univariate probabilistic time series forecasting. We employ the\nconditional VAE framework and optimize the lower bound of the predictive\ndistribution likelihood function by adopting the Continuous Ranked Probability\nScore (CRPS), a strictly proper scoring rule, as the loss function. This novel\npipeline results in forecasting sharp and well-calibrated predictive\ndistribution. Through a comprehensive empirical study, VAEneu is rigorously\nbenchmarked against 12 baseline models across 12 datasets. The results\nunequivocally demonstrate VAEneu's remarkable forecasting performance. VAEneu\nprovides a valuable tool for quantifying future uncertainties, and our\nextensive empirical study lays the foundation for future comparative studies\nfor univariate multistep ahead probabilistic forecasting.",
    "categories": [
      "cs.LG",
      "cs.AI"
    ],
    "primary_category": "cs.LG",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2405.04252v1",
    "published_date": "2024-05-07 12:13:11 UTC",
    "updated_date": "2024-05-07 12:13:11 UTC"
  },
  {
    "arxiv_id": "2405.04249v2",
    "title": "Federated Learning for Collaborative Inference Systems: The Case of Early Exit Networks",
    "authors": [
      "Caelin Kaplan",
      "Angelo Rodio",
      "Tareq Si Salem",
      "Chuan Xu",
      "Giovanni Neglia"
    ],
    "abstract": "As Internet of Things (IoT) technology advances, end devices like sensors and\nsmartphones are progressively equipped with AI models tailored to their local\nmemory and computational constraints. Local inference reduces communication\ncosts and latency; however, these smaller models typically underperform\ncompared to more sophisticated models deployed on edge servers or in the cloud.\nCooperative Inference Systems (CISs) address this performance trade-off by\nenabling smaller devices to offload part of their inference tasks to more\ncapable devices. These systems often deploy hierarchical models that share\nnumerous parameters, exemplified by Deep Neural Networks (DNNs) that utilize\nstrategies like early exits or ordered dropout. In such instances, Federated\nLearning (FL) may be employed to jointly train the models within a CIS. Yet,\ntraditional training methods have overlooked the operational dynamics of CISs\nduring inference, particularly the potential high heterogeneity in serving\nrates across clients. To address this gap, we propose a novel FL approach\ndesigned explicitly for use in CISs that accounts for these variations in\nserving rates. Our framework not only offers rigorous theoretical guarantees,\nbut also surpasses state-of-the-art (SOTA) training algorithms for CISs,\nespecially in scenarios where inference request rates or data availability are\nuneven among clients.",
    "categories": [
      "cs.LG",
      "cs.AI",
      "cs.DC"
    ],
    "primary_category": "cs.LG",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2405.04249v2",
    "published_date": "2024-05-07 12:07:06 UTC",
    "updated_date": "2024-08-21 09:04:41 UTC"
  },
  {
    "arxiv_id": "2405.04245v2",
    "title": "Exploring Correlations of Self-Supervised Tasks for Graphs",
    "authors": [
      "Taoran Fang",
      "Wei Zhou",
      "Yifei Sun",
      "Kaiqiao Han",
      "Lvbin Ma",
      "Yang Yang"
    ],
    "abstract": "Graph self-supervised learning has sparked a research surge in training\ninformative representations without accessing any labeled data. However, our\nunderstanding of graph self-supervised learning remains limited, and the\ninherent relationships between various self-supervised tasks are still\nunexplored. Our paper aims to provide a fresh understanding of graph\nself-supervised learning based on task correlations. Specifically, we evaluate\nthe performance of the representations trained by one specific task on other\ntasks and define correlation values to quantify task correlations. Through this\nprocess, we unveil the task correlations between various self-supervised tasks\nand can measure their expressive capabilities, which are closely related to\ndownstream performance. By analyzing the correlation values between tasks\nacross various datasets, we reveal the complexity of task correlations and the\nlimitations of existing multi-task learning methods. To obtain more capable\nrepresentations, we propose Graph Task Correlation Modeling (GraphTCM) to\nillustrate the task correlations and utilize it to enhance graph\nself-supervised training. The experimental results indicate that our method\nsignificantly outperforms existing methods across various downstream tasks.",
    "categories": [
      "cs.LG",
      "cs.AI"
    ],
    "primary_category": "cs.LG",
    "comment": "ICML 2024 Accepted",
    "pdf_url": "http://arxiv.org/pdf/2405.04245v2",
    "published_date": "2024-05-07 12:02:23 UTC",
    "updated_date": "2024-05-16 06:51:23 UTC"
  },
  {
    "arxiv_id": "2405.04241v1",
    "title": "Exploring the Potential of Robot-Collected Data for Training Gesture Classification Systems",
    "authors": [
      "Alejandro Garcia-Sosa",
      "Jose J. Quintana-Hernandez",
      "Miguel A. Ferrer Ballester",
      "Cristina Carmona-Duarte"
    ],
    "abstract": "Sensors and Artificial Intelligence (AI) have revolutionized the analysis of\nhuman movement, but the scarcity of specific samples presents a significant\nchallenge in training intelligent systems, particularly in the context of\ndiagnosing neurodegenerative diseases. This study investigates the feasibility\nof utilizing robot-collected data to train classification systems traditionally\ntrained with human-collected data. As a proof of concept, we recorded a\ndatabase of numeric characters using an ABB robotic arm and an Apple Watch. We\ncompare the classification performance of the trained systems using both\nhuman-recorded and robot-recorded data. Our primary objective is to determine\nthe potential for accurate identification of human numeric characters wearing a\nsmartwatch using robotic movement as training data. The findings of this study\noffer valuable insights into the feasibility of using robot-collected data for\ntraining classification systems. This research holds broad implications across\nvarious domains that require reliable identification, particularly in scenarios\nwhere access to human-specific data is limited.",
    "categories": [
      "cs.RO",
      "cs.AI"
    ],
    "primary_category": "cs.RO",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2405.04241v1",
    "published_date": "2024-05-07 11:58:34 UTC",
    "updated_date": "2024-05-07 11:58:34 UTC"
  },
  {
    "arxiv_id": "2501.03230v1",
    "title": "Video-of-Thought: Step-by-Step Video Reasoning from Perception to Cognition",
    "authors": [
      "Hao Fei",
      "Shengqiong Wu",
      "Wei Ji",
      "Hanwang Zhang",
      "Meishan Zhang",
      "Mong-Li Lee",
      "Wynne Hsu"
    ],
    "abstract": "Existing research of video understanding still struggles to achieve in-depth\ncomprehension and reasoning in complex videos, primarily due to the\nunder-exploration of two key bottlenecks: fine-grained spatial-temporal\nperceptive understanding and cognitive-level video scene comprehension. This\npaper bridges the gap by presenting a novel solution. We first introduce a\nnovel video Multimodal Large Language Model (MLLM), MotionEpic, which achieves\nfine-grained pixel-level spatial-temporal video grounding by integrating video\nspatial-temporal scene graph (STSG) representation. Building upon MotionEpic,\nwe then develop a Video-of-Thought (VoT) reasoning framework. VoT inherits the\nChain-of-Thought (CoT) core, breaking down a complex task into simpler and\nmanageable sub-problems, and addressing them step-by-step from a low-level\npixel perception to high-level cognitive interpretation. Extensive experiments\nacross various complex video QA benchmarks demonstrate that our overall\nframework strikingly boosts existing state-of-the-art. To our knowledge, this\nis the first attempt at successfully implementing the CoT technique for\nachieving human-level video reasoning, where we show great potential in\nextending it to a wider range of video understanding scenarios. Project is open\nat https://haofei.vip/VoT",
    "categories": [
      "cs.AI",
      "cs.CV"
    ],
    "primary_category": "cs.AI",
    "comment": "Accepted by ICML 2024",
    "pdf_url": "http://arxiv.org/pdf/2501.03230v1",
    "published_date": "2024-05-07 11:55:10 UTC",
    "updated_date": "2024-05-07 11:55:10 UTC"
  },
  {
    "arxiv_id": "2405.04230v3",
    "title": "Unveiling the optimization process of Physics Informed Neural Networks: How accurate and competitive can PINNs be?",
    "authors": [
      "Jorge F. Urbán",
      "Petros Stefanou",
      "José A. Pons"
    ],
    "abstract": "This study investigates the potential accuracy boundaries of physics-informed\nneural networks, contrasting their approach with previous similar works and\ntraditional numerical methods. We find that selecting improved optimization\nalgorithms significantly enhances the accuracy of the results. Simple\nmodifications to the loss function may also improve precision, offering an\nadditional avenue for enhancement. Despite optimization algorithms having a\ngreater impact on convergence than adjustments to the loss function, practical\nconsiderations often favor tweaking the latter due to ease of implementation.\nOn a global scale, the integration of an enhanced optimizer and a marginally\nadjusted loss function enables a reduction in the loss function by several\norders of magnitude across diverse physical problems. Consequently, our results\nobtained using compact networks (typically comprising 2 or 3 layers of 20-30\nneurons) achieve accuracies comparable to finite difference schemes employing\nthousands of grid points. This study encourages the continued advancement of\nPINNs and associated optimization techniques for broader applications across\nvarious fields.",
    "categories": [
      "physics.comp-ph",
      "cs.AI",
      "cs.LG"
    ],
    "primary_category": "physics.comp-ph",
    "comment": "63 pages, 25 figures. This is the author-accepted manuscript of the\n  paper published in Journal of Computational Physics",
    "pdf_url": "http://arxiv.org/pdf/2405.04230v3",
    "published_date": "2024-05-07 11:50:25 UTC",
    "updated_date": "2024-12-13 10:03:10 UTC"
  },
  {
    "arxiv_id": "2405.04219v1",
    "title": "Iterative Experience Refinement of Software-Developing Agents",
    "authors": [
      "Chen Qian",
      "Jiahao Li",
      "Yufan Dang",
      "Wei Liu",
      "YiFei Wang",
      "Zihao Xie",
      "Weize Chen",
      "Cheng Yang",
      "Yingli Zhang",
      "Zhiyuan Liu",
      "Maosong Sun"
    ],
    "abstract": "Autonomous agents powered by large language models (LLMs) show significant\npotential for achieving high autonomy in various scenarios such as software\ndevelopment. Recent research has shown that LLM agents can leverage past\nexperiences to reduce errors and enhance efficiency. However, the static\nexperience paradigm, reliant on a fixed collection of past experiences acquired\nheuristically, lacks iterative refinement and thus hampers agents'\nadaptability. In this paper, we introduce the Iterative Experience Refinement\nframework, enabling LLM agents to refine experiences iteratively during task\nexecution. We propose two fundamental patterns: the successive pattern,\nrefining based on nearest experiences within a task batch, and the cumulative\npattern, acquiring experiences across all previous task batches. Augmented with\nour heuristic experience elimination, the method prioritizes high-quality and\nfrequently-used experiences, effectively managing the experience space and\nenhancing efficiency. Extensive experiments show that while the successive\npattern may yield superior results, the cumulative pattern provides more stable\nperformance. Moreover, experience elimination facilitates achieving better\nperformance using just 11.54% of a high-quality subset.",
    "categories": [
      "cs.CL",
      "cs.AI",
      "cs.MA",
      "cs.SE"
    ],
    "primary_category": "cs.CL",
    "comment": "Work in progress",
    "pdf_url": "http://arxiv.org/pdf/2405.04219v1",
    "published_date": "2024-05-07 11:33:49 UTC",
    "updated_date": "2024-05-07 11:33:49 UTC"
  },
  {
    "arxiv_id": "2405.04215v1",
    "title": "NL2Plan: Robust LLM-Driven Planning from Minimal Text Descriptions",
    "authors": [
      "Elliot Gestrin",
      "Marco Kuhlmann",
      "Jendrik Seipp"
    ],
    "abstract": "Today's classical planners are powerful, but modeling input tasks in formats\nsuch as PDDL is tedious and error-prone. In contrast, planning with Large\nLanguage Models (LLMs) allows for almost any input text, but offers no\nguarantees on plan quality or even soundness. In an attempt to merge the best\nof these two approaches, some work has begun to use LLMs to automate parts of\nthe PDDL creation process. However, these methods still require various degrees\nof expert input. We present NL2Plan, the first domain-agnostic offline\nLLM-driven planning system. NL2Plan uses an LLM to incrementally extract the\nnecessary information from a short text prompt before creating a complete PDDL\ndescription of both the domain and the problem, which is finally solved by a\nclassical planner. We evaluate NL2Plan on four planning domains and find that\nit solves 10 out of 15 tasks - a clear improvement over a plain\nchain-of-thought reasoning LLM approach, which only solves 2 tasks. Moreover,\nin two out of the five failure cases, instead of returning an invalid plan,\nNL2Plan reports that it failed to solve the task. In addition to using NL2Plan\nin end-to-end mode, users can inspect and correct all of its intermediate\nresults, such as the PDDL representation, increasing explainability and making\nit an assistive tool for PDDL creation.",
    "categories": [
      "cs.AI"
    ],
    "primary_category": "cs.AI",
    "comment": "Accepted for the ICAPS 2024 Workshop on Human-Aware and Explainable\n  Planning",
    "pdf_url": "http://arxiv.org/pdf/2405.04215v1",
    "published_date": "2024-05-07 11:27:13 UTC",
    "updated_date": "2024-05-07 11:27:13 UTC"
  },
  {
    "arxiv_id": "2405.04212v1",
    "title": "Green Tsetlin Redefining Efficiency in Tsetlin Machine Frameworks",
    "authors": [
      "Sondre Glimsdal",
      "Sebastian Østby",
      "Tobias M. Brambo",
      "Eirik M. Vinje"
    ],
    "abstract": "Green Tsetlin (GT) is a Tsetlin Machine (TM) framework developed to solve\nreal-world problems using TMs. Several frameworks already exist that provide\naccess to TM implementations. However, these either lack features or have a\nresearch-first focus. GT is an easy-to-use framework that aims to lower the\ncomplexity and provide a production-ready TM implementation that is great for\nexperienced practitioners and beginners. To this end, GT establishes a clear\nseparation between training and inference. A C++ backend with a Python\ninterface provides competitive training and inference performance, with the\noption of running in pure Python. It also integrates support for critical\ncomponents such as exporting trained models, hyper-parameter search, and\ncross-validation out-of-the-box.",
    "categories": [
      "cs.AI",
      "cs.LG"
    ],
    "primary_category": "cs.AI",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2405.04212v1",
    "published_date": "2024-05-07 11:24:56 UTC",
    "updated_date": "2024-05-07 11:24:56 UTC"
  },
  {
    "arxiv_id": "2405.04206v1",
    "title": "NOVA: NoC-based Vector Unit for Mapping Attention Layers on a CNN Accelerator",
    "authors": [
      "Mohit Upadhyay",
      "Rohan Juneja",
      "Weng-Fai Wong",
      "Li-Shiuan Peh"
    ],
    "abstract": "Attention mechanisms are becoming increasingly popular, being used in neural\nnetwork models in multiple domains such as natural language processing (NLP)\nand vision applications, especially at the edge. However, attention layers are\ndifficult to map onto existing neuro accelerators since they have a much higher\ndensity of non-linear operations, which lead to inefficient utilization of\ntoday's vector units. This work introduces NOVA, a NoC-based Vector Unit that\ncan perform non-linear operations within the NoC of the accelerators, and can\nbe overlaid onto existing neuro accelerators to map attention layers at the\nedge. Our results show that the NOVA architecture is up to 37.8x more\npower-efficient than state-of-the-art hardware approximators when running\nexisting attention-based neural networks.",
    "categories": [
      "cs.AR",
      "cs.AI",
      "cs.LG",
      "B.2.4"
    ],
    "primary_category": "cs.AR",
    "comment": "6 pages, 8 figures",
    "pdf_url": "http://arxiv.org/pdf/2405.04206v1",
    "published_date": "2024-05-07 11:20:10 UTC",
    "updated_date": "2024-05-07 11:20:10 UTC"
  },
  {
    "arxiv_id": "2405.04171v1",
    "title": "FedStale: leveraging stale client updates in federated learning",
    "authors": [
      "Angelo Rodio",
      "Giovanni Neglia"
    ],
    "abstract": "Federated learning algorithms, such as FedAvg, are negatively affected by\ndata heterogeneity and partial client participation. To mitigate the latter\nproblem, global variance reduction methods, like FedVARP, leverage stale model\nupdates for non-participating clients. These methods are effective under\nhomogeneous client participation. Yet, this paper shows that, when some clients\nparticipate much less than others, aggregating updates with different levels of\nstaleness can detrimentally affect the training process. Motivated by this\nobservation, we introduce FedStale, a novel algorithm that updates the global\nmodel in each round through a convex combination of \"fresh\" updates from\nparticipating clients and \"stale\" updates from non-participating ones. By\nadjusting the weight in the convex combination, FedStale interpolates between\nFedAvg, which only uses fresh updates, and FedVARP, which treats fresh and\nstale updates equally. Our analysis of FedStale convergence yields the\nfollowing novel findings: i) it integrates and extends previous FedAvg and\nFedVARP analyses to heterogeneous client participation; ii) it underscores how\nthe least participating client influences convergence error; iii) it provides\npractical guidelines to best exploit stale updates, showing that their\nusefulness diminishes as data heterogeneity decreases and participation\nheterogeneity increases. Extensive experiments featuring diverse levels of\nclient data and participation heterogeneity not only confirm these findings but\nalso show that FedStale outperforms both FedAvg and FedVARP in many settings.",
    "categories": [
      "cs.LG",
      "cs.AI"
    ],
    "primary_category": "cs.LG",
    "comment": "33 pages, 5 figures, preprint",
    "pdf_url": "http://arxiv.org/pdf/2405.04171v1",
    "published_date": "2024-05-07 10:11:42 UTC",
    "updated_date": "2024-05-07 10:11:42 UTC"
  },
  {
    "arxiv_id": "2405.04161v2",
    "title": "Decoding complexity: how machine learning is redefining scientific discovery",
    "authors": [
      "Ricardo Vinuesa",
      "Paola Cinnella",
      "Jean Rabault",
      "Hossein Azizpour",
      "Stefan Bauer",
      "Bingni W. Brunton",
      "Arne Elofsson",
      "Elias Jarlebring",
      "Hedvig Kjellstrom",
      "Stefano Markidis",
      "David Marlevi",
      "Javier Garcia-Martinez",
      "Steven L. Brunton"
    ],
    "abstract": "As modern scientific instruments generate vast amounts of data and the volume\nof information in the scientific literature continues to grow, machine learning\n(ML) has become an essential tool for organising, analysing, and interpreting\nthese complex datasets. This paper explores the transformative role of ML in\naccelerating breakthroughs across a range of scientific disciplines. By\npresenting key examples -- such as brain mapping and exoplanet detection -- we\ndemonstrate how ML is reshaping scientific research. We also explore different\nscenarios where different levels of knowledge of the underlying phenomenon are\navailable, identifying strategies to overcome limitations and unlock the full\npotential of ML. Despite its advances, the growing reliance on ML poses\nchallenges for research applications and rigorous validation of discoveries. We\nargue that even with these challenges, ML is poised to disrupt traditional\nmethodologies and advance the boundaries of knowledge by enabling researchers\nto tackle increasingly complex problems. Thus, the scientific community can\nmove beyond the necessary traditional oversimplifications to embrace the full\ncomplexity of natural systems, ultimately paving the way for interdisciplinary\nbreakthroughs and innovative solutions to humanity's most pressing challenges.",
    "categories": [
      "cs.LG",
      "cs.AI"
    ],
    "primary_category": "cs.LG",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2405.04161v2",
    "published_date": "2024-05-07 09:58:02 UTC",
    "updated_date": "2025-04-25 14:35:04 UTC"
  },
  {
    "arxiv_id": "2405.06691v3",
    "title": "Fleet of Agents: Coordinated Problem Solving with Large Language Models",
    "authors": [
      "Lars Klein",
      "Nearchos Potamitis",
      "Roland Aydin",
      "Robert West",
      "Caglar Gulcehre",
      "Akhil Arora"
    ],
    "abstract": "While numerous frameworks have been developed to enhance the reasoning\nabilities of large language models (LLMs), there is a scarcity of methods that\neffectively balance the trade-off between cost and quality. In this paper, we\nintroduce Fleet of Agents (FoA), a novel and intuitive yet principled framework\nutilizing LLMs as agents to navigate through dynamic tree searches, employing a\ngenetic-type particle filtering approach. FoA spawns a multitude of agents,\neach exploring the search space autonomously, followed by a selection phase\nwhere resampling based on a heuristic value function optimizes the balance\nbetween exploration and exploitation. This mechanism enables dynamic branching,\nadapting the exploration strategy based on discovered solutions. We conduct\nextensive experiments on three benchmark tasks, ``Game of 24'',\n``Mini-Crosswords'', and ``WebShop'', utilizing four different LLMs,\n``GPT-3.5'', ``GPT-4'', ``LLaMA3.2-11B'', and ``LLaMA3.2-90B''. On average\nacross all tasks and LLMs, FoA obtains a quality improvement of ~5% while\nrequiring only ~40% of the cost of previous SOTA methods. Notably, our analyses\nreveal that (1) FoA achieves the best cost-quality trade-off among all\nbenchmarked methods and (2) FoA + LLaMA3.2-11B surpasses the Llama3.2-90B\nmodel. FoA is publicly available at https://github.com/au-clan/FoA.",
    "categories": [
      "cs.CL",
      "cs.AI",
      "cs.LG",
      "cs.NE"
    ],
    "primary_category": "cs.CL",
    "comment": "ICML 2025; 28 pages, 68 figures, 8 tables",
    "pdf_url": "http://arxiv.org/pdf/2405.06691v3",
    "published_date": "2024-05-07 09:36:23 UTC",
    "updated_date": "2025-05-10 19:36:43 UTC"
  },
  {
    "arxiv_id": "2405.04138v1",
    "title": "GPT-Enabled Cybersecurity Training: A Tailored Approach for Effective Awareness",
    "authors": [
      "Nabil Al-Dhamari",
      "Nathan Clarke"
    ],
    "abstract": "This study explores the limitations of traditional Cybersecurity Awareness\nand Training (CSAT) programs and proposes an innovative solution using\nGenerative Pre-Trained Transformers (GPT) to address these shortcomings.\nTraditional approaches lack personalization and adaptability to individual\nlearning styles. To overcome these challenges, the study integrates GPT models\nto deliver highly tailored and dynamic cybersecurity learning expe-riences.\nLeveraging natural language processing capabilities, the proposed approach\npersonalizes training modules based on individual trainee pro-files, helping to\nensure engagement and effectiveness. An experiment using a GPT model to provide\na real-time and adaptive CSAT experience through generating customized training\ncontent. The findings have demonstrated a significant improvement over\ntraditional programs, addressing issues of en-gagement, dynamicity, and\nrelevance. GPT-powered CSAT programs offer a scalable and effective solution to\nenhance cybersecurity awareness, provid-ing personalized training content that\nbetter prepares individuals to miti-gate cybersecurity risks in their specific\nroles within the organization.",
    "categories": [
      "cs.CR",
      "cs.AI"
    ],
    "primary_category": "cs.CR",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2405.04138v1",
    "published_date": "2024-05-07 09:08:00 UTC",
    "updated_date": "2024-05-07 09:08:00 UTC"
  },
  {
    "arxiv_id": "2405.04136v1",
    "title": "Enriched BERT Embeddings for Scholarly Publication Classification",
    "authors": [
      "Benjamin Wolff",
      "Eva Seidlmayer",
      "Konrad U. Förstner"
    ],
    "abstract": "With the rapid expansion of academic literature and the proliferation of\npreprints, researchers face growing challenges in manually organizing and\nlabeling large volumes of articles. The NSLP 2024 FoRC Shared Task I addresses\nthis challenge organized as a competition. The goal is to develop a classifier\ncapable of predicting one of 123 predefined classes from the Open Research\nKnowledge Graph (ORKG) taxonomy of research fields for a given article.This\npaper presents our results. Initially, we enrich the dataset (containing\nEnglish scholarly articles sourced from ORKG and arXiv), then leverage\ndifferent pre-trained language Models (PLMs), specifically BERT, and explore\ntheir efficacy in transfer learning for this downstream task. Our experiments\nencompass feature-based and fine-tuned transfer learning approaches using\ndiverse PLMs, optimized for scientific tasks, including SciBERT, SciNCL, and\nSPECTER2. We conduct hyperparameter tuning and investigate the impact of data\naugmentation from bibliographic databases such as OpenAlex, Semantic Scholar,\nand Crossref. Our results demonstrate that fine-tuning pre-trained models\nsubstantially enhances classification performance, with SPECTER2 emerging as\nthe most accurate model. Moreover, enriching the dataset with additional\nmetadata improves classification outcomes significantly, especially when\nintegrating information from S2AG, OpenAlex and Crossref. Our best-performing\napproach achieves a weighted F1-score of 0.7415. Overall, our study contributes\nto the advancement of reliable automated systems for scholarly publication\ncategorization, offering a potential solution to the laborious manual curation\nprocess, thereby facilitating researchers in efficiently locating relevant\nresources.",
    "categories": [
      "cs.AI",
      "cs.CL"
    ],
    "primary_category": "cs.AI",
    "comment": "8 pages, 2 figures, NSLP2024 conference",
    "pdf_url": "http://arxiv.org/pdf/2405.04136v1",
    "published_date": "2024-05-07 09:05:20 UTC",
    "updated_date": "2024-05-07 09:05:20 UTC"
  },
  {
    "arxiv_id": "2405.04135v3",
    "title": "Human-centric Reward Optimization for Reinforcement Learning-based Automated Driving using Large Language Models",
    "authors": [
      "Ziqi Zhou",
      "Jingyue Zhang",
      "Jingyuan Zhang",
      "Yangfan He",
      "Boyue Wang",
      "Tianyu Shi",
      "Alaa Khamis"
    ],
    "abstract": "One of the key challenges in current Reinforcement Learning (RL)-based\nAutomated Driving (AD) agents is achieving flexible, precise, and human-like\nbehavior cost-effectively. This paper introduces an innovative approach that\nuses large language models (LLMs) to intuitively and effectively optimize RL\nreward functions in a human-centric way. We developed a framework where\ninstructions and dynamic environment descriptions are input into the LLM. The\nLLM then utilizes this information to assist in generating rewards, thereby\nsteering the behavior of RL agents towards patterns that more closely resemble\nhuman driving. The experimental results demonstrate that this approach not only\nmakes RL agents more anthropomorphic but also achieves better performance.\nAdditionally, various strategies for reward-proxy and reward-shaping are\ninvestigated, revealing the significant impact of prompt design on shaping an\nAD vehicle's behavior. These findings offer a promising direction for the\ndevelopment of more advanced, human-like automated driving systems. Our\nexperimental data and source code can be found here",
    "categories": [
      "cs.AI"
    ],
    "primary_category": "cs.AI",
    "comment": "9 pages, 6 figures, 34 references",
    "pdf_url": "http://arxiv.org/pdf/2405.04135v3",
    "published_date": "2024-05-07 09:04:52 UTC",
    "updated_date": "2024-12-26 11:55:16 UTC"
  },
  {
    "arxiv_id": "2405.04124v5",
    "title": "Comparative Study of State-based Neural Networks for Virtual Analog Audio Effects Modeling",
    "authors": [
      "Riccardo Simionato",
      "Stefano Fasciani"
    ],
    "abstract": "Analog electronic circuits are at the core of an important category of\nmusical devices, which includes a broad range of sound synthesizers and audio\neffects. The development of software that simulates analog musical devices,\nknown as virtual analog modeling, is a significant sub-field in audio signal\nprocessing. Artificial neural networks are a promising technique for virtual\nanalog modeling. While neural approaches have successfully accurately modeled\ndistortion circuits, they require architectural improvements that account for\nparameter conditioning and low-latency response. This article explores the\napplication of recent machine learning advancements for virtual analog\nmodeling. In particular, we compare State-Space models and Linear Recurrent\nUnits against the more common Long Short-Term Memory networks. Our comparative\nstudy uses these black-box neural modeling techniques with various audio\neffects. We evaluate the performance and limitations of these models using\nmultiple metrics, providing insights for future research and development. Our\nmetrics aim to assess the models' ability to accurately replicate energy\nenvelopes and frequency contents, with a particular focus on transients in the\naudio signal. To incorporate control parameters into the models, we employ the\nFeature-wise Linear Modulation method. Long Short-Term Memory networks exhibit\nbetter accuracy in emulating distortions and equalizers, while the State-Space\nmodel, followed by Long Short-Term Memory networks when integrated in an\nencoder-decoder structure, and Linear Recurrent Unit outperforms others in\nemulating saturation and compression. When considering long time-variant\ncharacteristics, the State-Space model demonstrates the greatest capability to\ntrack history. Long Short-Term Memory networks tend to introduce audio\nartifacts.",
    "categories": [
      "cs.SD",
      "cs.AI"
    ],
    "primary_category": "cs.SD",
    "comment": "Submitted to EURASIP Journal on Audio, Speech, and Music Processing",
    "pdf_url": "http://arxiv.org/pdf/2405.04124v5",
    "published_date": "2024-05-07 08:47:40 UTC",
    "updated_date": "2024-08-29 09:44:59 UTC"
  },
  {
    "arxiv_id": "2405.04118v2",
    "title": "Policy Learning with a Language Bottleneck",
    "authors": [
      "Megha Srivastava",
      "Cedric Colas",
      "Dorsa Sadigh",
      "Jacob Andreas"
    ],
    "abstract": "Modern AI systems such as self-driving cars and game-playing agents achieve\nsuperhuman performance, but often lack human-like generalization,\ninterpretability, and inter-operability with human users. Inspired by the rich\ninteractions between language and decision-making in humans, we introduce\nPolicy Learning with a Language Bottleneck (PLLB), a framework enabling AI\nagents to generate linguistic rules that capture the high-level strategies\nunderlying rewarding behaviors. PLLB alternates between a *rule generation*\nstep guided by language models, and an *update* step where agents learn new\npolicies guided by rules, even when a rule is insufficient to describe an\nentire complex policy. Across five diverse tasks, including a two-player\nsignaling game, maze navigation, image reconstruction, and robot grasp\nplanning, we show that PLLB agents are not only able to learn more\ninterpretable and generalizable behaviors, but can also share the learned rules\nwith human users, enabling more effective human-AI coordination. We provide\nsource code for our experiments at https://github.com/meghabyte/bottleneck .",
    "categories": [
      "cs.LG",
      "cs.AI",
      "cs.CL"
    ],
    "primary_category": "cs.LG",
    "comment": "21 pages, 15 figures, updated with robot manipulation task",
    "pdf_url": "http://arxiv.org/pdf/2405.04118v2",
    "published_date": "2024-05-07 08:40:21 UTC",
    "updated_date": "2025-03-26 20:53:57 UTC"
  },
  {
    "arxiv_id": "2405.04114v1",
    "title": "Acceleration Algorithms in GNNs: A Survey",
    "authors": [
      "Lu Ma",
      "Zeang Sheng",
      "Xunkai Li",
      "Xinyi Gao",
      "Zhezheng Hao",
      "Ling Yang",
      "Wentao Zhang",
      "Bin Cui"
    ],
    "abstract": "Graph Neural Networks (GNNs) have demonstrated effectiveness in various\ngraph-based tasks. However, their inefficiency in training and inference\npresents challenges for scaling up to real-world and large-scale graph\napplications. To address the critical challenges, a range of algorithms have\nbeen proposed to accelerate training and inference of GNNs, attracting\nincreasing attention from the research community. In this paper, we present a\nsystematic review of acceleration algorithms in GNNs, which can be categorized\ninto three main topics based on their purpose: training acceleration, inference\nacceleration, and execution acceleration. Specifically, we summarize and\ncategorize the existing approaches for each main topic, and provide detailed\ncharacterizations of the approaches within each category. Additionally, we\nreview several libraries related to acceleration algorithms in GNNs and discuss\nour Scalable Graph Learning (SGL) library. Finally, we propose promising\ndirections for future research. A complete summary is presented in our GitHub\nrepository:\nhttps://github.com/PKU-DAIR/SGL/blob/main/Awsome-GNN-Acceleration.md.",
    "categories": [
      "cs.LG",
      "cs.AI"
    ],
    "primary_category": "cs.LG",
    "comment": "9 pages,3 figures",
    "pdf_url": "http://arxiv.org/pdf/2405.04114v1",
    "published_date": "2024-05-07 08:34:33 UTC",
    "updated_date": "2024-05-07 08:34:33 UTC"
  },
  {
    "arxiv_id": "2405.04108v1",
    "title": "A2-DIDM: Privacy-preserving Accumulator-enabled Auditing for Distributed Identity of DNN Model",
    "authors": [
      "Tianxiu Xie",
      "Keke Gai",
      "Jing Yu",
      "Liehuang Zhu",
      "Kim-Kwang Raymond Choo"
    ],
    "abstract": "Recent booming development of Generative Artificial Intelligence (GenAI) has\nfacilitated an emerging model commercialization for the purpose of\nreinforcement on model performance, such as licensing or trading Deep Neural\nNetwork (DNN) models. However, DNN model trading may trigger concerns of the\nunauthorized replications or misuses over the model, so that the benefit of the\nmodel ownership will be violated. Model identity auditing is a challenging\nissue in protecting intellectual property of DNN models and verifying the\nintegrity and ownership of models for guaranteeing trusts in transactions is\none of the critical obstacles. In this paper, we focus on the above issue and\npropose a novel Accumulator-enabled Auditing for Distributed Identity of DNN\nModel (A2-DIDM) that utilizes blockchain and zero-knowledge techniques to\nprotect data and function privacy while ensuring the lightweight on-chain\nownership verification. The proposed model presents a scheme of identity\nrecords via configuring model weight checkpoints with corresponding\nzero-knowledge proofs, which incorporates predicates to capture incremental\nstate changes in model weight checkpoints. Our scheme ensures both\ncomputational integrity of DNN training process and programmability, so that\nthe uniqueness of the weight checkpoint sequence in a DNN model is preserved,\nensuring the correctness of the model identity auditing. In addition, A2-DIDM\nalso addresses privacy protections in distributed identity via a proposed\nmethod of accumulators. We systematically analyze the security and robustness\nof our proposed model and further evaluate the effectiveness and usability of\nauditing DNN model identities.",
    "categories": [
      "cs.CR",
      "cs.AI"
    ],
    "primary_category": "cs.CR",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2405.04108v1",
    "published_date": "2024-05-07 08:24:50 UTC",
    "updated_date": "2024-05-07 08:24:50 UTC"
  },
  {
    "arxiv_id": "2405.04101v2",
    "title": "Continual Learning in the Presence of Repetition",
    "authors": [
      "Hamed Hemati",
      "Lorenzo Pellegrini",
      "Xiaotian Duan",
      "Zixuan Zhao",
      "Fangfang Xia",
      "Marc Masana",
      "Benedikt Tscheschner",
      "Eduardo Veas",
      "Yuxiang Zheng",
      "Shiji Zhao",
      "Shao-Yuan Li",
      "Sheng-Jun Huang",
      "Vincenzo Lomonaco",
      "Gido M. van de Ven"
    ],
    "abstract": "Continual learning (CL) provides a framework for training models in\never-evolving environments. Although re-occurrence of previously seen objects\nor tasks is common in real-world problems, the concept of repetition in the\ndata stream is not often considered in standard benchmarks for CL. Unlike with\nthe rehearsal mechanism in buffer-based strategies, where sample repetition is\ncontrolled by the strategy, repetition in the data stream naturally stems from\nthe environment. This report provides a summary of the CLVision challenge at\nCVPR 2023, which focused on the topic of repetition in class-incremental\nlearning. The report initially outlines the challenge objective and then\ndescribes three solutions proposed by finalist teams that aim to effectively\nexploit the repetition in the stream to learn continually. The experimental\nresults from the challenge highlight the effectiveness of ensemble-based\nsolutions that employ multiple versions of similar modules, each trained on\ndifferent but overlapping subsets of classes. This report underscores the\ntransformative potential of taking a different perspective in CL by employing\nrepetition in the data stream to foster innovative strategy design.",
    "categories": [
      "cs.LG",
      "cs.AI"
    ],
    "primary_category": "cs.LG",
    "comment": "Accepted version, to appear in Neural Networks; Challenge Report of\n  the 4th Workshop on Continual Learning in Computer Vision at CVPR",
    "pdf_url": "http://arxiv.org/pdf/2405.04101v2",
    "published_date": "2024-05-07 08:15:48 UTC",
    "updated_date": "2024-12-02 14:54:31 UTC"
  },
  {
    "arxiv_id": "2405.04097v2",
    "title": "Unmasking Illusions: Understanding Human Perception of Audiovisual Deepfakes",
    "authors": [
      "Ammarah Hashmi",
      "Sahibzada Adil Shahzad",
      "Chia-Wen Lin",
      "Yu Tsao",
      "Hsin-Min Wang"
    ],
    "abstract": "The emergence of contemporary deepfakes has attracted significant attention\nin machine learning research, as artificial intelligence (AI) generated\nsynthetic media increases the incidence of misinterpretation and is difficult\nto distinguish from genuine content. Currently, machine learning techniques\nhave been extensively studied for automatically detecting deepfakes. However,\nhuman perception has been less explored. Malicious deepfakes could ultimately\ncause public and social problems. Can we humans correctly perceive the\nauthenticity of the content of the videos we watch? The answer is obviously\nuncertain; therefore, this paper aims to evaluate the human ability to discern\ndeepfake videos through a subjective study. We present our findings by\ncomparing human observers to five state-ofthe-art audiovisual deepfake\ndetection models. To this end, we used gamification concepts to provide 110\nparticipants (55 native English speakers and 55 non-native English speakers)\nwith a webbased platform where they could access a series of 40 videos (20 real\nand 20 fake) to determine their authenticity. Each participant performed the\nexperiment twice with the same 40 videos in different random orders. The videos\nare manually selected from the FakeAVCeleb dataset. We found that all AI models\nperformed better than humans when evaluated on the same 40 videos. The study\nalso reveals that while deception is not impossible, humans tend to\noverestimate their detection capabilities. Our experimental results may help\nbenchmark human versus machine performance, advance forensics analysis, and\nenable adaptive countermeasures.",
    "categories": [
      "cs.CV",
      "cs.AI",
      "cs.CY",
      "cs.LG",
      "cs.MM"
    ],
    "primary_category": "cs.CV",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2405.04097v2",
    "published_date": "2024-05-07 07:57:15 UTC",
    "updated_date": "2024-11-11 09:05:15 UTC"
  },
  {
    "arxiv_id": "2405.04095v2",
    "title": "DREAM: Combating Concept Drift with Explanatory Detection and Adaptation in Malware Classification",
    "authors": [
      "Yiling He",
      "Junchi Lei",
      "Zhan Qin",
      "Kui Ren"
    ],
    "abstract": "Deep learning-based malware classifiers face significant challenges due to\nconcept drift. The rapid evolution of malware, especially with new families,\ncan depress classification accuracy to near-random levels. Previous research\nhas primarily focused on detecting drift samples, relying on expert-led\nanalysis and labeling for model retraining. However, these methods often lack a\ncomprehensive understanding of malware concepts and provide limited guidance\nfor effective drift adaptation, leading to unstable detection performance and\nhigh human labeling costs. To address these limitations, we introduce DREAM, a\nnovel system designed to surpass the capabilities of existing drift detectors\nand to establish an explanatory drift adaptation process. DREAM enhances drift\ndetection through model sensitivity and data autonomy. The detector, trained in\na semi-supervised approach, proactively captures malware behavior concepts\nthrough classifier feedback. During testing, it utilizes samples generated by\nthe detector itself, eliminating reliance on extensive training data. For drift\nadaptation, DREAM enlarges human intervention, enabling revisions of malware\nlabels and concept explanations embedded within the detector's latent space. To\nensure a comprehensive response to concept drift, it facilitates a coordinated\nupdate process for both the classifier and the detector. Our evaluation shows\nthat DREAM can effectively improve the drift detection accuracy and reduce the\nexpert analysis effort in adaptation across different malware datasets and\nclassifiers.",
    "categories": [
      "cs.CR",
      "cs.AI"
    ],
    "primary_category": "cs.CR",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2405.04095v2",
    "published_date": "2024-05-07 07:55:45 UTC",
    "updated_date": "2024-08-08 05:45:56 UTC"
  },
  {
    "arxiv_id": "2405.04093v1",
    "title": "DCNN: Dual Cross-current Neural Networks Realized Using An Interactive Deep Learning Discriminator for Fine-grained Objects",
    "authors": [
      "Da Fu",
      "Mingfei Rong",
      "Eun-Hu Kim",
      "Hao Huang",
      "Witold Pedrycz"
    ],
    "abstract": "Accurate classification of fine-grained images remains a challenge in\nbackbones based on convolutional operations or self-attention mechanisms. This\nstudy proposes novel dual-current neural networks (DCNN), which combine the\nadvantages of convolutional operations and self-attention mechanisms to improve\nthe accuracy of fine-grained image classification. The main novel design\nfeatures for constructing a weakly supervised learning backbone model DCNN\ninclude (a) extracting heterogeneous data, (b) keeping the feature map\nresolution unchanged, (c) expanding the receptive field, and (d) fusing global\nrepresentations and local features. Experimental results demonstrated that\nusing DCNN as the backbone network for classifying certain fine-grained\nbenchmark datasets achieved performance advantage improvements of 13.5--19.5%\nand 2.2--12.9%, respectively, compared to other advanced convolution or\nattention-based fine-grained backbones.",
    "categories": [
      "cs.CV",
      "cs.AI"
    ],
    "primary_category": "cs.CV",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2405.04093v1",
    "published_date": "2024-05-07 07:51:28 UTC",
    "updated_date": "2024-05-07 07:51:28 UTC"
  },
  {
    "arxiv_id": "2405.04081v1",
    "title": "Counterfactual and Semifactual Explanations in Abstract Argumentation: Formal Foundations, Complexity and Computation",
    "authors": [
      "Gianvincenzo Alfano",
      "Sergio Greco",
      "Francesco Parisi",
      "Irina Trubitsyna"
    ],
    "abstract": "Explainable Artificial Intelligence and Formal Argumentation have received\nsignificant attention in recent years. Argumentation-based systems often lack\nexplainability while supporting decision-making processes. Counterfactual and\nsemifactual explanations are interpretability techniques that provide insights\ninto the outcome of a model by generating alternative hypothetical instances.\nWhile there has been important work on counterfactual and semifactual\nexplanations for Machine Learning models, less attention has been devoted to\nthese kinds of problems in argumentation. In this paper, we explore\ncounterfactual and semifactual reasoning in abstract Argumentation Framework.\nWe investigate the computational complexity of counterfactual- and\nsemifactual-based reasoning problems, showing that they are generally harder\nthan classical argumentation problems such as credulous and skeptical\nacceptance. Finally, we show that counterfactual and semifactual queries can be\nencoded in weak-constrained Argumentation Framework, and provide a\ncomputational strategy through ASP solvers.",
    "categories": [
      "cs.AI"
    ],
    "primary_category": "cs.AI",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2405.04081v1",
    "published_date": "2024-05-07 07:27:27 UTC",
    "updated_date": "2024-05-07 07:27:27 UTC"
  },
  {
    "arxiv_id": "2405.04078v1",
    "title": "WISER: Weak supervISion and supErvised Representation learning to improve drug response prediction in cancer",
    "authors": [
      "Kumar Shubham",
      "Aishwarya Jayagopal",
      "Syed Mohammed Danish",
      "Prathosh AP",
      "Vaibhav Rajan"
    ],
    "abstract": "Cancer, a leading cause of death globally, occurs due to genomic changes and\nmanifests heterogeneously across patients. To advance research on personalized\ntreatment strategies, the effectiveness of various drugs on cells derived from\ncancers (`cell lines') is experimentally determined in laboratory settings.\nNevertheless, variations in the distribution of genomic data and drug responses\nbetween cell lines and humans arise due to biological and environmental\ndifferences. Moreover, while genomic profiles of many cancer patients are\nreadily available, the scarcity of corresponding drug response data limits the\nability to train machine learning models that can predict drug response in\npatients effectively. Recent cancer drug response prediction methods have\nlargely followed the paradigm of unsupervised domain-invariant representation\nlearning followed by a downstream drug response classification step.\nIntroducing supervision in both stages is challenging due to heterogeneous\npatient response to drugs and limited drug response data. This paper addresses\nthese challenges through a novel representation learning method in the first\nphase and weak supervision in the second. Experimental results on real patient\ndata demonstrate the efficacy of our method (WISER) over state-of-the-art\nalternatives on predicting personalized drug response.",
    "categories": [
      "cs.LG",
      "cs.AI",
      "q-bio.QM"
    ],
    "primary_category": "cs.LG",
    "comment": "ICML 2024",
    "pdf_url": "http://arxiv.org/pdf/2405.04078v1",
    "published_date": "2024-05-07 07:21:20 UTC",
    "updated_date": "2024-05-07 07:21:20 UTC"
  },
  {
    "arxiv_id": "2405.04074v1",
    "title": "A simple theory for training response of deep neural networks",
    "authors": [
      "Kenichi Nakazato"
    ],
    "abstract": "Deep neural networks give us a powerful method to model the training\ndataset's relationship between input and output. We can regard that as a\ncomplex adaptive system consisting of many artificial neurons that work as an\nadaptive memory as a whole. The network's behavior is training dynamics with a\nfeedback loop from the evaluation of the loss function. We already know the\ntraining response can be constant or shows power law-like aging in some ideal\nsituations. However, we still have gaps between those findings and other\ncomplex phenomena, like network fragility. To fill the gap, we introduce a very\nsimple network and analyze it. We show the training response consists of some\ndifferent factors based on training stages, activation functions, or training\nmethods. In addition, we show feature space reduction as an effect of\nstochastic training dynamics, which can result in network fragility. Finally,\nwe discuss some complex phenomena of deep networks.",
    "categories": [
      "cond-mat.dis-nn",
      "cs.AI",
      "cs.LG",
      "nlin.AO"
    ],
    "primary_category": "cond-mat.dis-nn",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2405.04074v1",
    "published_date": "2024-05-07 07:20:15 UTC",
    "updated_date": "2024-05-07 07:20:15 UTC"
  },
  {
    "arxiv_id": "2405.04064v2",
    "title": "MFA-Net: Multi-Scale feature fusion attention network for liver tumor segmentation",
    "authors": [
      "Yanli Yuan",
      "Bingbing Wang",
      "Chuan Zhang",
      "Jingyi Xu",
      "Ximeng Liu",
      "Liehuang Zhu"
    ],
    "abstract": "Segmentation of organs of interest in medical CT images is beneficial for\ndiagnosis of diseases. Though recent methods based on Fully Convolutional\nNeural Networks (F-CNNs) have shown success in many segmentation tasks, fusing\nfeatures from images with different scales is still a challenge: (1) Due to the\nlack of spatial awareness, F-CNNs share the same weights at different spatial\nlocations. (2) F-CNNs can only obtain surrounding information through local\nreceptive fields. To address the above challenge, we propose a new segmentation\nframework based on attention mechanisms, named MFA-Net (Multi-Scale Feature\nFusion Attention Network). The proposed framework can learn more meaningful\nfeature maps among multiple scales and result in more accurate automatic\nsegmentation. We compare our proposed MFA-Net with SOTA methods on two 2D liver\nCT datasets. The experimental results show that our MFA-Net produces more\nprecise segmentation on images with different scales.",
    "categories": [
      "cs.AI"
    ],
    "primary_category": "cs.AI",
    "comment": "Paper accepted in Human-Centric Representation Learning workshop at\n  AAAI 2024",
    "pdf_url": "http://arxiv.org/pdf/2405.04064v2",
    "published_date": "2024-05-07 07:10:44 UTC",
    "updated_date": "2024-05-09 12:26:45 UTC"
  },
  {
    "arxiv_id": "2405.04061v3",
    "title": "Generalized Cauchy-Schwarz Divergence and Its Deep Learning Applications",
    "authors": [
      "Mingfei Lu",
      "Chenxu Li",
      "Shujian Yu",
      "Robert Jenssen",
      "Badong Chen"
    ],
    "abstract": "Divergence measures play a central role and become increasingly essential in\ndeep learning, yet efficient measures for multiple (more than two)\ndistributions are rarely explored. This becomes particularly crucial in areas\nwhere the simultaneous management of multiple distributions is both inevitable\nand essential. Examples include clustering, multi-source domain adaptation or\ngeneralization, and multi-view learning, among others. While computing the mean\nof pairwise distances between any two distributions is a prevalent method to\nquantify the total divergence among multiple distributions, it is imperative to\nacknowledge that this approach is not straightforward and necessitates\nsignificant computational resources. In this study, we introduce a new\ndivergence measure tailored for multiple distributions named the generalized\nCauchy-Schwarz divergence (GCSD). Additionally, we furnish a kernel-based\nclosed-form sample estimator, making it convenient and straightforward to use\nin various machine-learning applications. Finally, we explore its profound\nimplications in the realm of deep learning by applying it to tackle two\nthoughtfully chosen machine-learning tasks: deep clustering and multi-source\ndomain adaptation. Our extensive experimental investigations confirm the\nrobustness and effectiveness of GCSD in both scenarios. The findings also\nunderscore the innovative potential of GCSD and its capability to significantly\npropel machine learning methodologies that necessitate the quantification of\nmultiple distributions.",
    "categories": [
      "cs.LG",
      "cs.AI"
    ],
    "primary_category": "cs.LG",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2405.04061v3",
    "published_date": "2024-05-07 07:07:44 UTC",
    "updated_date": "2024-06-06 02:02:00 UTC"
  },
  {
    "arxiv_id": "2405.04053v1",
    "title": "Evaluating Text Summaries Generated by Large Language Models Using OpenAI's GPT",
    "authors": [
      "Hassan Shakil",
      "Atqiya Munawara Mahi",
      "Phuoc Nguyen",
      "Zeydy Ortiz",
      "Mamoun T. Mardini"
    ],
    "abstract": "This research examines the effectiveness of OpenAI's GPT models as\nindependent evaluators of text summaries generated by six transformer-based\nmodels from Hugging Face: DistilBART, BERT, ProphetNet, T5, BART, and PEGASUS.\nWe evaluated these summaries based on essential properties of high-quality\nsummary - conciseness, relevance, coherence, and readability - using\ntraditional metrics such as ROUGE and Latent Semantic Analysis (LSA). Uniquely,\nwe also employed GPT not as a summarizer but as an evaluator, allowing it to\nindependently assess summary quality without predefined metrics. Our analysis\nrevealed significant correlations between GPT evaluations and traditional\nmetrics, particularly in assessing relevance and coherence. The results\ndemonstrate GPT's potential as a robust tool for evaluating text summaries,\noffering insights that complement established metrics and providing a basis for\ncomparative analysis of transformer-based models in natural language processing\ntasks.",
    "categories": [
      "cs.CL",
      "cs.AI",
      "cs.LG"
    ],
    "primary_category": "cs.CL",
    "comment": "10 pages, 5 figures",
    "pdf_url": "http://arxiv.org/pdf/2405.04053v1",
    "published_date": "2024-05-07 06:52:34 UTC",
    "updated_date": "2024-05-07 06:52:34 UTC"
  },
  {
    "arxiv_id": "2405.04050v1",
    "title": "Learning Linear Block Error Correction Codes",
    "authors": [
      "Yoni Choukroun",
      "Lior Wolf"
    ],
    "abstract": "Error correction codes are a crucial part of the physical communication\nlayer, ensuring the reliable transfer of data over noisy channels. The design\nof optimal linear block codes capable of being efficiently decoded is of major\nconcern, especially for short block lengths. While neural decoders have\nrecently demonstrated their advantage over classical decoding techniques, the\nneural design of the codes remains a challenge. In this work, we propose for\nthe first time a unified encoder-decoder training of binary linear block codes.\nTo this end, we adapt the coding setting to support efficient and\ndifferentiable training of the code for end-to-end optimization over the order\ntwo Galois field. We also propose a novel Transformer model in which the\nself-attention masking is performed in a differentiable fashion for the\nefficient backpropagation of the code gradient. Our results show that (i) the\nproposed decoder outperforms existing neural decoding on conventional codes,\n(ii) the suggested framework generates codes that outperform the {analogous}\nconventional codes, and (iii) the codes we developed not only excel with our\ndecoder but also show enhanced performance with traditional decoding\ntechniques.",
    "categories": [
      "cs.IT",
      "cs.AI",
      "math.IT"
    ],
    "primary_category": "cs.IT",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2405.04050v1",
    "published_date": "2024-05-07 06:47:12 UTC",
    "updated_date": "2024-05-07 06:47:12 UTC"
  },
  {
    "arxiv_id": "2405.04042v1",
    "title": "Space-time Reinforcement Network for Video Object Segmentation",
    "authors": [
      "Yadang Chen",
      "Wentao Zhu",
      "Zhi-Xin Yang",
      "Enhua Wu"
    ],
    "abstract": "Recently, video object segmentation (VOS) networks typically use memory-based\nmethods: for each query frame, the mask is predicted by space-time matching to\nmemory frames. Despite these methods having superior performance, they suffer\nfrom two issues: 1) Challenging data can destroy the space-time coherence\nbetween adjacent video frames. 2) Pixel-level matching will lead to undesired\nmismatching caused by the noises or distractors. To address the aforementioned\nissues, we first propose to generate an auxiliary frame between adjacent\nframes, serving as an implicit short-temporal reference for the query one.\nNext, we learn a prototype for each video object and prototype-level matching\ncan be implemented between the query and memory. The experiment demonstrated\nthat our network outperforms the state-of-the-art method on the DAVIS 2017,\nachieving a J&F score of 86.4%, and attains a competitive result 85.0% on\nYouTube VOS 2018. In addition, our network exhibits a high inference speed of\n32+ FPS.",
    "categories": [
      "cs.CV",
      "cs.AI"
    ],
    "primary_category": "cs.CV",
    "comment": "Accepted by ICME 2024. 6 pages, 10 figures",
    "pdf_url": "http://arxiv.org/pdf/2405.04042v1",
    "published_date": "2024-05-07 06:26:30 UTC",
    "updated_date": "2024-05-07 06:26:30 UTC"
  },
  {
    "arxiv_id": "2405.04041v1",
    "title": "Feature Map Convergence Evaluation for Functional Module",
    "authors": [
      "Ludan Zhang",
      "Chaoyi Chen",
      "Lei He",
      "Keqiang Li"
    ],
    "abstract": "Autonomous driving perception models are typically composed of multiple\nfunctional modules that interact through complex relationships to accomplish\nenvironment understanding. However, perception models are predominantly\noptimized as a black box through end-to-end training, lacking independent\nevaluation of functional modules, which poses difficulties for interpretability\nand optimization. Pioneering in the issue, we propose an evaluation method\nbased on feature map analysis to gauge the convergence of model, thereby\nassessing functional modules' training maturity. We construct a quantitative\nmetric named as the Feature Map Convergence Score (FMCS) and develop Feature\nMap Convergence Evaluation Network (FMCE-Net) to measure and predict the\nconvergence degree of models respectively. FMCE-Net achieves remarkable\npredictive accuracy for FMCS across multiple image classification experiments,\nvalidating the efficacy and robustness of the introduced approach. To the best\nof our knowledge, this is the first independent evaluation method for\nfunctional modules, offering a new paradigm for the training assessment towards\nperception models.",
    "categories": [
      "cs.AI",
      "cs.CV"
    ],
    "primary_category": "cs.AI",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2405.04041v1",
    "published_date": "2024-05-07 06:25:49 UTC",
    "updated_date": "2024-05-07 06:25:49 UTC"
  },
  {
    "arxiv_id": "2405.04039v1",
    "title": "Utilizing GPT to Enhance Text Summarization: A Strategy to Minimize Hallucinations",
    "authors": [
      "Hassan Shakil",
      "Zeydy Ortiz",
      "Grant C. Forbes"
    ],
    "abstract": "In this research, we uses the DistilBERT model to generate extractive summary\nand the T5 model to generate abstractive summaries. Also, we generate hybrid\nsummaries by combining both DistilBERT and T5 models. Central to our research\nis the implementation of GPT-based refining process to minimize the common\nproblem of hallucinations that happens in AI-generated summaries. We evaluate\nunrefined summaries and, after refining, we also assess refined summaries using\na range of traditional and novel metrics, demonstrating marked improvements in\nthe accuracy and reliability of the summaries. Results highlight significant\nimprovements in reducing hallucinatory content, thereby increasing the factual\nintegrity of the summaries.",
    "categories": [
      "cs.CL",
      "cs.AI",
      "cs.LG"
    ],
    "primary_category": "cs.CL",
    "comment": "9 pages, 3 figures",
    "pdf_url": "http://arxiv.org/pdf/2405.04039v1",
    "published_date": "2024-05-07 06:23:02 UTC",
    "updated_date": "2024-05-07 06:23:02 UTC"
  },
  {
    "arxiv_id": "2405.04032v2",
    "title": "Locally Differentially Private In-Context Learning",
    "authors": [
      "Chunyan Zheng",
      "Keke Sun",
      "Wenhao Zhao",
      "Haibo Zhou",
      "Lixin Jiang",
      "Shaoyang Song",
      "Chunlai Zhou"
    ],
    "abstract": "Large pretrained language models (LLMs) have shown surprising In-Context\nLearning (ICL) ability. An important application in deploying large language\nmodels is to augment LLMs with a private database for some specific task. The\nmain problem with this promising commercial use is that LLMs have been shown to\nmemorize their training data and their prompt data are vulnerable to membership\ninference attacks (MIA) and prompt leaking attacks. In order to deal with this\nproblem, we treat LLMs as untrusted in privacy and propose a locally\ndifferentially private framework of in-context learning(LDP-ICL) in the\nsettings where labels are sensitive. Considering the mechanisms of in-context\nlearning in Transformers by gradient descent, we provide an analysis of the\ntrade-off between privacy and utility in such LDP-ICL for classification.\nMoreover, we apply LDP-ICL to the discrete distribution estimation problem. In\nthe end, we perform several experiments to demonstrate our analysis results.",
    "categories": [
      "cs.CR",
      "cs.AI"
    ],
    "primary_category": "cs.CR",
    "comment": "This paper was published at LREC-Coling 2024",
    "pdf_url": "http://arxiv.org/pdf/2405.04032v2",
    "published_date": "2024-05-07 06:05:43 UTC",
    "updated_date": "2024-05-08 17:10:23 UTC"
  },
  {
    "arxiv_id": "2405.04017v1",
    "title": "An Improved Finite-time Analysis of Temporal Difference Learning with Deep Neural Networks",
    "authors": [
      "Zhifa Ke",
      "Zaiwen Wen",
      "Junyu Zhang"
    ],
    "abstract": "Temporal difference (TD) learning algorithms with neural network function\nparameterization have well-established empirical success in many practical\nlarge-scale reinforcement learning tasks. However, theoretical understanding of\nthese algorithms remains challenging due to the nonlinearity of the\naction-value approximation. In this paper, we develop an improved\nnon-asymptotic analysis of the neural TD method with a general $L$-layer neural\nnetwork. New proof techniques are developed and an improved new\n$\\tilde{\\mathcal{O}}(\\epsilon^{-1})$ sample complexity is derived. To our best\nknowledge, this is the first finite-time analysis of neural TD that achieves an\n$\\tilde{\\mathcal{O}}(\\epsilon^{-1})$ complexity under the Markovian sampling,\nas opposed to the best known $\\tilde{\\mathcal{O}}(\\epsilon^{-2})$ complexity in\nthe existing literature.",
    "categories": [
      "cs.LG",
      "cs.AI",
      "math.OC"
    ],
    "primary_category": "cs.LG",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2405.04017v1",
    "published_date": "2024-05-07 05:29:55 UTC",
    "updated_date": "2024-05-07 05:29:55 UTC"
  },
  {
    "arxiv_id": "2405.04015v1",
    "title": "Certified Policy Verification and Synthesis for MDPs under Distributional Reach-avoidance Properties",
    "authors": [
      "S. Akshay",
      "Krishnendu Chatterjee",
      "Tobias Meggendorfer",
      "Đorđe Žikelić"
    ],
    "abstract": "Markov Decision Processes (MDPs) are a classical model for decision making in\nthe presence of uncertainty. Often they are viewed as state transformers with\nplanning objectives defined with respect to paths over MDP states. An\nincreasingly popular alternative is to view them as distribution transformers,\ngiving rise to a sequence of probability distributions over MDP states. For\ninstance, reachability and safety properties in modeling robot swarms or\nchemical reaction networks are naturally defined in terms of probability\ndistributions over states. Verifying such distributional properties is known to\nbe hard and often beyond the reach of classical state-based verification\ntechniques.\n  In this work, we consider the problems of certified policy (i.e. controller)\nverification and synthesis in MDPs under distributional reach-avoidance\nspecifications. By certified we mean that, along with a policy, we also aim to\nsynthesize a (checkable) certificate ensuring that the MDP indeed satisfies the\nproperty. Thus, given the target set of distributions and an unsafe set of\ndistributions over MDP states, our goal is to either synthesize a certificate\nfor a given policy or synthesize a policy along with a certificate, proving\nthat the target distribution can be reached while avoiding unsafe\ndistributions. To solve this problem, we introduce the novel notion of\ndistributional reach-avoid certificates and present automated procedures for\n(1) synthesizing a certificate for a given policy, and (2) synthesizing a\npolicy together with the certificate, both providing formal guarantees on\ncertificate correctness. Our experimental evaluation demonstrates the ability\nof our method to solve several non-trivial examples, including a multi-agent\nrobot-swarm model, to synthesize certified policies and to certify existing\npolicies.",
    "categories": [
      "cs.AI",
      "cs.LO"
    ],
    "primary_category": "cs.AI",
    "comment": "Extended version of a paper accepted at IJCAI 2024",
    "pdf_url": "http://arxiv.org/pdf/2405.04015v1",
    "published_date": "2024-05-07 05:23:56 UTC",
    "updated_date": "2024-05-07 05:23:56 UTC"
  },
  {
    "arxiv_id": "2405.04009v1",
    "title": "Structured Click Control in Transformer-based Interactive Segmentation",
    "authors": [
      "Long Xu",
      "Yongquan Chen",
      "Rui Huang",
      "Feng Wu",
      "Shiwu Lai"
    ],
    "abstract": "Click-point-based interactive segmentation has received widespread attention\ndue to its efficiency. However, it's hard for existing algorithms to obtain\nprecise and robust responses after multiple clicks. In this case, the\nsegmentation results tend to have little change or are even worse than before.\nTo improve the robustness of the response, we propose a structured click intent\nmodel based on graph neural networks, which adaptively obtains graph nodes via\nthe global similarity of user-clicked Transformer tokens. Then the graph nodes\nwill be aggregated to obtain structured interaction features. Finally, the dual\ncross-attention will be used to inject structured interaction features into\nvision Transformer features, thereby enhancing the control of clicks over\nsegmentation results. Extensive experiments demonstrated the proposed algorithm\ncan serve as a general structure in improving Transformer-based interactive\nsegmenta?tion performance. The code and data will be released at\nhttps://github.com/hahamyt/scc.",
    "categories": [
      "cs.CV",
      "cs.AI"
    ],
    "primary_category": "cs.CV",
    "comment": "10 pages, 6 figures, submitted to NeurIPS 2024",
    "pdf_url": "http://arxiv.org/pdf/2405.04009v1",
    "published_date": "2024-05-07 04:57:25 UTC",
    "updated_date": "2024-05-07 04:57:25 UTC"
  },
  {
    "arxiv_id": "2405.03990v2",
    "title": "TrimCaching: Parameter-sharing AI Model Caching in Wireless Edge Networks",
    "authors": [
      "Guanqiao Qu",
      "Zheng Lin",
      "Fangming Liu",
      "Xianhao Chen",
      "Kaibin Huang"
    ],
    "abstract": "Next-generation mobile networks are expected to facilitate fast AI model\ndownloading to end users. By caching models on edge servers, mobile networks\ncan deliver models to end users with low latency, resulting in a paradigm\ncalled edge model caching. In this paper, we develop a novel model placement\nscheme, called parameter-sharing model caching (TrimCaching). TrimCaching\nexploits the key observation that a wide range of AI models, such as\nconvolutional neural networks or large language models, can share a significant\nproportion of parameter blocks containing reusable knowledge, thereby improving\nstorage efficiency. To this end, we formulate a parameter-sharing model\nplacement problem to maximize the cache hit ratio in multi-edge wireless\nnetworks by balancing the fundamental tradeoff between storage efficiency and\nservice latency. We show that the formulated problem is a submodular\nmaximization problem with submodular constraints, for which no polynomial-time\napproximation algorithm exists. To overcome this challenge, we study an\nimportant special case, where a small fixed number of parameter blocks are\nshared across models, which often holds in practice. In such a case, a\npolynomial-time algorithm with $\\left(1-\\epsilon\\right)/2$-approximation\nguarantee is developed. Subsequently, we address the original problem for the\ngeneral case by developing a greedy algorithm. Simulation results demonstrate\nthat the proposed TrimCaching framework significantly improves the cache hit\nratio compared with state-of-the-art content caching without exploiting shared\nparameters in AI models.",
    "categories": [
      "cs.NI",
      "cs.AI"
    ],
    "primary_category": "cs.NI",
    "comment": "11 pages, 7 figures. This paper has been accepted by ICDCS 2024. The\n  extended version of this paper is at arXiv:2404.14204",
    "pdf_url": "http://arxiv.org/pdf/2405.03990v2",
    "published_date": "2024-05-07 04:08:49 UTC",
    "updated_date": "2024-05-20 03:44:52 UTC"
  },
  {
    "arxiv_id": "2405.03988v3",
    "title": "LEARN: Knowledge Adaptation from Large Language Model to Recommendation for Practical Industrial Application",
    "authors": [
      "Jian Jia",
      "Yipei Wang",
      "Yan Li",
      "Honggang Chen",
      "Xuehan Bai",
      "Zhaocheng Liu",
      "Jian Liang",
      "Quan Chen",
      "Han Li",
      "Peng Jiang",
      "Kun Gai"
    ],
    "abstract": "Contemporary recommendation systems predominantly rely on ID embedding to\ncapture latent associations among users and items. However, this approach\noverlooks the wealth of semantic information embedded within textual\ndescriptions of items, leading to suboptimal performance and poor\ngeneralizations. Leveraging the capability of large language models to\ncomprehend and reason about textual content presents a promising avenue for\nadvancing recommendation systems. To achieve this, we propose an Llm-driven\nknowlEdge Adaptive RecommeNdation (LEARN) framework that synergizes open-world\nknowledge with collaborative knowledge. We address computational complexity\nconcerns by utilizing pretrained LLMs as item encoders and freezing LLM\nparameters to avoid catastrophic forgetting and preserve open-world knowledge.\nTo bridge the gap between the open-world and collaborative domains, we design a\ntwin-tower structure supervised by the recommendation task and tailored for\npractical industrial application. Through experiments on the real large-scale\nindustrial dataset and online A/B tests, we demonstrate the efficacy of our\napproach in industry application. We also achieve state-of-the-art performance\non six Amazon Review datasets to verify the superiority of our method.",
    "categories": [
      "cs.IR",
      "cs.AI"
    ],
    "primary_category": "cs.IR",
    "comment": "Accepted by AAAI 2025. Codes are released at\n  https://github.com/adxcreative/LEARN",
    "pdf_url": "http://arxiv.org/pdf/2405.03988v3",
    "published_date": "2024-05-07 04:00:30 UTC",
    "updated_date": "2024-12-26 03:03:30 UTC"
  },
  {
    "arxiv_id": "2405.03986v1",
    "title": "Factors Influencing User Willingness To Use SORA",
    "authors": [
      "Gustave Florentin Nkoulou Mvondo",
      "Ben Niu"
    ],
    "abstract": "Sora promises to redefine the way visual content is created. Despite its\nnumerous forecasted benefits, the drivers of user willingness to use the\ntext-to-video (T2V) model are unknown. This study extends the extended unified\ntheory of acceptance and use of technology (UTAUT2) with perceived realism and\nnovelty value. Using a purposive sampling method, we collected data from 940\nrespondents in the US and analyzed the sample using covariance-based structural\nequation modeling and fuzzy set qualitative comparative analysis (fsQCA). The\nfindings reveal that all hypothesized relationships are supported, with\nperceived realism emerging as the most influential driver, followed by novelty\nvalue. Moreover, fsQCA identifies five configurations leading to high and low\nwillingness to use, and the model demonstrates high predictive validity,\ncontributing to theory advancement. Our study provides valuable insights for\ndevelopers and marketers, offering guidance for strategic decisions to promote\nthe widespread adoption of T2V models.",
    "categories": [
      "cs.AI",
      "cs.HC",
      "62P225"
    ],
    "primary_category": "cs.AI",
    "comment": "27 pages, 3 figures, 7 tables, 2 authors; first author* corresponding\n  author,",
    "pdf_url": "http://arxiv.org/pdf/2405.03986v1",
    "published_date": "2024-05-07 03:55:32 UTC",
    "updated_date": "2024-05-07 03:55:32 UTC"
  },
  {
    "arxiv_id": "2405.03977v1",
    "title": "Can citations tell us about a paper's reproducibility? A case study of machine learning papers",
    "authors": [
      "Rochana R. Obadage",
      "Sarah M. Rajtmajer",
      "Jian Wu"
    ],
    "abstract": "The iterative character of work in machine learning (ML) and artificial\nintelligence (AI) and reliance on comparisons against benchmark datasets\nemphasize the importance of reproducibility in that literature. Yet, resource\nconstraints and inadequate documentation can make running replications\nparticularly challenging. Our work explores the potential of using downstream\ncitation contexts as a signal of reproducibility. We introduce a sentiment\nanalysis framework applied to citation contexts from papers involved in Machine\nLearning Reproducibility Challenges in order to interpret the positive or\nnegative outcomes of reproduction attempts. Our contributions include training\nclassifiers for reproducibility-related contexts and sentiment analysis, and\nexploring correlations between citation context sentiment and reproducibility\nscores. Study data, software, and an artifact appendix are publicly available\nat https://github.com/lamps-lab/ccair-ai-reproducibility .",
    "categories": [
      "cs.DL",
      "cs.AI",
      "cs.LG"
    ],
    "primary_category": "cs.DL",
    "comment": "9 pages, 4 figures",
    "pdf_url": "http://arxiv.org/pdf/2405.03977v1",
    "published_date": "2024-05-07 03:29:11 UTC",
    "updated_date": "2024-05-07 03:29:11 UTC"
  },
  {
    "arxiv_id": "2405.03974v1",
    "title": "TBNet: A Neural Architectural Defense Framework Facilitating DNN Model Protection in Trusted Execution Environments",
    "authors": [
      "Ziyu Liu",
      "Tong Zhou",
      "Yukui Luo",
      "Xiaolin Xu"
    ],
    "abstract": "Trusted Execution Environments (TEEs) have become a promising solution to\nsecure DNN models on edge devices. However, the existing solutions either\nprovide inadequate protection or introduce large performance overhead. Taking\nboth security and performance into consideration, this paper presents TBNet, a\nTEE-based defense framework that protects DNN model from a neural architectural\nperspective. Specifically, TBNet generates a novel Two-Branch substitution\nmodel, to respectively exploit (1) the computational resources in the untrusted\nRich Execution Environment (REE) for latency reduction and (2) the\nphysically-isolated TEE for model protection. Experimental results on a\nRaspberry Pi across diverse DNN model architectures and datasets demonstrate\nthat TBNet achieves efficient model protection at a low cost.",
    "categories": [
      "cs.CR",
      "cs.AI",
      "cs.LG"
    ],
    "primary_category": "cs.CR",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2405.03974v1",
    "published_date": "2024-05-07 03:08:30 UTC",
    "updated_date": "2024-05-07 03:08:30 UTC"
  },
  {
    "arxiv_id": "2405.03967v1",
    "title": "SwiftRL: Towards Efficient Reinforcement Learning on Real Processing-In-Memory Systems",
    "authors": [
      "Kailash Gogineni",
      "Sai Santosh Dayapule",
      "Juan Gómez-Luna",
      "Karthikeya Gogineni",
      "Peng Wei",
      "Tian Lan",
      "Mohammad Sadrosadati",
      "Onur Mutlu",
      "Guru Venkataramani"
    ],
    "abstract": "Reinforcement Learning (RL) trains agents to learn optimal behavior by\nmaximizing reward signals from experience datasets. However, RL training often\nfaces memory limitations, leading to execution latencies and prolonged training\ntimes. To overcome this, SwiftRL explores Processing-In-Memory (PIM)\narchitectures to accelerate RL workloads. We achieve near-linear performance\nscaling by implementing RL algorithms like Tabular Q-learning and SARSA on\nUPMEM PIM systems and optimizing for hardware. Our experiments on OpenAI GYM\nenvironments using UPMEM hardware demonstrate superior performance compared to\nCPU and GPU implementations.",
    "categories": [
      "cs.LG",
      "cs.AI",
      "cs.AR"
    ],
    "primary_category": "cs.LG",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2405.03967v1",
    "published_date": "2024-05-07 02:54:31 UTC",
    "updated_date": "2024-05-07 02:54:31 UTC"
  },
  {
    "arxiv_id": "2405.03963v4",
    "title": "ERATTA: Extreme RAG for Table To Answers with Large Language Models",
    "authors": [
      "Sohini Roychowdhury",
      "Marko Krema",
      "Anvar Mahammad",
      "Brian Moore",
      "Arijit Mukherjee",
      "Punit Prakashchandra"
    ],
    "abstract": "Large language models (LLMs) with retrieval augmented-generation (RAG) have\nbeen the optimal choice for scalable generative AI solutions in the recent\npast. Although RAG implemented with AI agents (agentic-RAG) has been recently\npopularized, its suffers from unstable cost and unreliable performances for\nEnterprise-level data-practices. Most existing use-cases that incorporate RAG\nwith LLMs have been either generic or extremely domain specific, thereby\nquestioning the scalability and generalizability of RAG-LLM approaches. In this\nwork, we propose a unique LLM-based system where multiple LLMs can be invoked\nto enable data authentication, user-query routing, data-retrieval and custom\nprompting for question-answering capabilities from Enterprise-data tables. The\nsource tables here are highly fluctuating and large in size and the proposed\nframework enables structured responses in under 10 seconds per query.\nAdditionally, we propose a five metric scoring module that detects and reports\nhallucinations in the LLM responses. Our proposed system and scoring metrics\nachieve >90% confidence scores across hundreds of user queries in the\nsustainability, financial health and social media domains. Extensions to the\nproposed extreme RAG architectures can enable heterogeneous source querying\nusing LLMs.",
    "categories": [
      "cs.AI",
      "cs.LG"
    ],
    "primary_category": "cs.AI",
    "comment": "5 pages, 4 tables, IEEE Big Data, 2024",
    "pdf_url": "http://arxiv.org/pdf/2405.03963v4",
    "published_date": "2024-05-07 02:49:59 UTC",
    "updated_date": "2024-11-17 07:23:40 UTC"
  },
  {
    "arxiv_id": "2405.03958v3",
    "title": "Simple Drop-in LoRA Conditioning on Attention Layers Will Improve Your Diffusion Model",
    "authors": [
      "Joo Young Choi",
      "Jaesung R. Park",
      "Inkyu Park",
      "Jaewoong Cho",
      "Albert No",
      "Ernest K. Ryu"
    ],
    "abstract": "Current state-of-the-art diffusion models employ U-Net architectures\ncontaining convolutional and (qkv) self-attention layers. The U-Net processes\nimages while being conditioned on the time embedding input for each sampling\nstep and the class or caption embedding input corresponding to the desired\nconditional generation. Such conditioning involves scale-and-shift operations\nto the convolutional layers but does not directly affect the attention layers.\nWhile these standard architectural choices are certainly effective, not\nconditioning the attention layers feels arbitrary and potentially suboptimal.\nIn this work, we show that simply adding LoRA conditioning to the attention\nlayers without changing or tuning the other parts of the U-Net architecture\nimproves the image generation quality. For example, a drop-in addition of LoRA\nconditioning to EDM diffusion model yields FID scores of 1.91/1.75 for\nunconditional and class-conditional CIFAR-10 generation, improving upon the\nbaseline of 1.97/1.79.",
    "categories": [
      "cs.CV",
      "cs.AI",
      "cs.LG"
    ],
    "primary_category": "cs.CV",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2405.03958v3",
    "published_date": "2024-05-07 02:45:28 UTC",
    "updated_date": "2024-10-04 09:40:05 UTC"
  },
  {
    "arxiv_id": "2405.03950v1",
    "title": "Relating-Up: Advancing Graph Neural Networks through Inter-Graph Relationships",
    "authors": [
      "Qi Zou",
      "Na Yu",
      "Daoliang Zhang",
      "Wei Zhang",
      "Rui Gao"
    ],
    "abstract": "Graph Neural Networks (GNNs) have excelled in learning from graph-structured\ndata, especially in understanding the relationships within a single graph,\ni.e., intra-graph relationships. Despite their successes, GNNs are limited by\nneglecting the context of relationships across graphs, i.e., inter-graph\nrelationships. Recognizing the potential to extend this capability, we\nintroduce Relating-Up, a plug-and-play module that enhances GNNs by exploiting\ninter-graph relationships. This module incorporates a relation-aware encoder\nand a feedback training strategy. The former enables GNNs to capture\nrelationships across graphs, enriching relation-aware graph representation\nthrough collective context. The latter utilizes a feedback loop mechanism for\nthe recursively refinement of these representations, leveraging insights from\nrefining inter-graph dynamics to conduct feedback loop. The synergy between\nthese two innovations results in a robust and versatile module. Relating-Up\nenhances the expressiveness of GNNs, enabling them to encapsulate a wider\nspectrum of graph relationships with greater precision. Our evaluations across\n16 benchmark datasets demonstrate that integrating Relating-Up into GNN\narchitectures substantially improves performance, positioning Relating-Up as a\nformidable choice for a broad spectrum of graph representation learning tasks.",
    "categories": [
      "cs.LG",
      "cs.AI"
    ],
    "primary_category": "cs.LG",
    "comment": "16 pages, 6 figures, 9 tables",
    "pdf_url": "http://arxiv.org/pdf/2405.03950v1",
    "published_date": "2024-05-07 02:16:54 UTC",
    "updated_date": "2024-05-07 02:16:54 UTC"
  },
  {
    "arxiv_id": "2405.03943v1",
    "title": "Predictive Modeling with Temporal Graphical Representation on Electronic Health Records",
    "authors": [
      "Jiayuan Chen",
      "Changchang Yin",
      "Yuanlong Wang",
      "Ping Zhang"
    ],
    "abstract": "Deep learning-based predictive models, leveraging Electronic Health Records\n(EHR), are receiving increasing attention in healthcare. An effective\nrepresentation of a patient's EHR should hierarchically encompass both the\ntemporal relationships between historical visits and medical events, and the\ninherent structural information within these elements. Existing patient\nrepresentation methods can be roughly categorized into sequential\nrepresentation and graphical representation. The sequential representation\nmethods focus only on the temporal relationships among longitudinal visits. On\nthe other hand, the graphical representation approaches, while adept at\nextracting the graph-structured relationships between various medical events,\nfall short in effectively integrate temporal information. To capture both types\nof information, we model a patient's EHR as a novel temporal heterogeneous\ngraph. This graph includes historical visits nodes and medical events nodes. It\npropagates structured information from medical event nodes to visit nodes and\nutilizes time-aware visit nodes to capture changes in the patient's health\nstatus. Furthermore, we introduce a novel temporal graph transformer (TRANS)\nthat integrates temporal edge features, global positional encoding, and local\nstructural encoding into heterogeneous graph convolution, capturing both\ntemporal and structural information. We validate the effectiveness of TRANS\nthrough extensive experiments on three real-world datasets. The results show\nthat our proposed approach achieves state-of-the-art performance.",
    "categories": [
      "cs.LG",
      "cs.AI"
    ],
    "primary_category": "cs.LG",
    "comment": "IJCAI 2024 main track",
    "pdf_url": "http://arxiv.org/pdf/2405.03943v1",
    "published_date": "2024-05-07 02:05:30 UTC",
    "updated_date": "2024-05-07 02:05:30 UTC"
  },
  {
    "arxiv_id": "2407.10254v1",
    "title": "The Elephant in the Room -- Why AI Safety Demands Diverse Teams",
    "authors": [
      "David Rostcheck",
      "Lara Scheibling"
    ],
    "abstract": "We consider that existing approaches to AI \"safety\" and \"alignment\" may not\nbe using the most effective tools, teams, or approaches. We suggest that an\nalternative and better approach to the problem may be to treat alignment as a\nsocial science problem, since the social sciences enjoy a rich toolkit of\nmodels for understanding and aligning motivation and behavior, much of which\ncould be repurposed to problems involving AI models, and enumerate reasons why\nthis is so. We introduce an alternate alignment approach informed by social\nscience tools and characterized by three steps: 1. defining a positive desired\nsocial outcome for human/AI collaboration as the goal or \"North Star,\" 2.\nproperly framing knowns and unknowns, and 3. forming diverse teams to\ninvestigate, observe, and navigate emerging challenges in alignment.",
    "categories": [
      "cs.CY",
      "cs.AI"
    ],
    "primary_category": "cs.CY",
    "comment": "9 pages",
    "pdf_url": "http://arxiv.org/pdf/2407.10254v1",
    "published_date": "2024-05-07 02:05:23 UTC",
    "updated_date": "2024-05-07 02:05:23 UTC"
  },
  {
    "arxiv_id": "2405.03942v1",
    "title": "Collaborative Intelligence in Sequential Experiments: A Human-in-the-Loop Framework for Drug Discovery",
    "authors": [
      "Jinghai He",
      "Cheng Hua",
      "Yingfei Wang",
      "Zeyu Zheng"
    ],
    "abstract": "Drug discovery is a complex process that involves sequentially screening and\nexamining a vast array of molecules to identify those with the target\nproperties. This process, also referred to as sequential experimentation, faces\nchallenges due to the vast search space, the rarity of target molecules, and\nconstraints imposed by limited data and experimental budgets. To address these\nchallenges, we introduce a human-in-the-loop framework for sequential\nexperiments in drug discovery. This collaborative approach combines human\nexpert knowledge with deep learning algorithms, enhancing the discovery of\ntarget molecules within a specified experimental budget. The proposed algorithm\nprocesses experimental data to recommend both promising molecules and those\nthat could improve its performance to human experts. Human experts retain the\nfinal decision-making authority based on these recommendations and their domain\nexpertise, including the ability to override algorithmic recommendations. We\napplied our method to drug discovery tasks using real-world data and found that\nit consistently outperforms all baseline methods, including those which rely\nsolely on human or algorithmic input. This demonstrates the complementarity\nbetween human experts and the algorithm. Our results provide key insights into\nthe levels of humans' domain knowledge, the importance of meta-knowledge, and\neffective work delegation strategies. Our findings suggest that such a\nframework can significantly accelerate the development of new vaccines and\ndrugs by leveraging the best of both human and artificial intelligence.",
    "categories": [
      "cs.AI",
      "cs.HC",
      "cs.LG"
    ],
    "primary_category": "cs.AI",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2405.03942v1",
    "published_date": "2024-05-07 02:03:07 UTC",
    "updated_date": "2024-05-07 02:03:07 UTC"
  },
  {
    "arxiv_id": "2405.03932v2",
    "title": "CleanGraph: Human-in-the-loop Knowledge Graph Refinement and Completion",
    "authors": [
      "Tyler Bikaun",
      "Michael Stewart",
      "Wei Liu"
    ],
    "abstract": "This paper presents CleanGraph, an interactive web-based tool designed to\nfacilitate the refinement and completion of knowledge graphs. Maintaining the\nreliability of knowledge graphs, which are grounded in high-quality and\nerror-free facts, is crucial for real-world applications such as\nquestion-answering and information retrieval systems. These graphs are often\nautomatically assembled from textual sources by extracting semantic triples via\ninformation extraction. However, assuring the quality of these extracted\ntriples, especially when dealing with large or low-quality datasets, can pose a\nsignificant challenge and adversely affect the performance of downstream\napplications. CleanGraph allows users to perform Create, Read, Update, and\nDelete (CRUD) operations on their graphs, as well as apply models in the form\nof plugins for graph refinement and completion tasks. These functionalities\nenable users to enhance the integrity and reliability of their graph data. A\ndemonstration of CleanGraph and its source code can be accessed at\nhttps://github.com/nlp-tlp/CleanGraph under the MIT License.",
    "categories": [
      "cs.AI",
      "cs.CL"
    ],
    "primary_category": "cs.AI",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2405.03932v2",
    "published_date": "2024-05-07 01:40:23 UTC",
    "updated_date": "2024-05-08 00:18:45 UTC"
  },
  {
    "arxiv_id": "2405.03929v2",
    "title": "Unicorn: U-Net for Sea Ice Forecasting with Convolutional Neural Ordinary Differential Equations",
    "authors": [
      "Jaesung Park",
      "Sungchul Hong",
      "Yoonseo Cho",
      "Jong-June Jeon"
    ],
    "abstract": "Sea ice at the North Pole is vital to global climate dynamics. However,\naccurately forecasting sea ice poses a significant challenge due to the\nintricate interaction among multiple variables. Leveraging the capability to\nintegrate multiple inputs and powerful performances seamlessly, many studies\nhave turned to neural networks for sea ice forecasting. This paper introduces a\nnovel deep architecture named Unicorn, designed to forecast weekly sea ice. Our\nmodel integrates multiple time series images within its architecture to enhance\nits forecasting performance. Moreover, we incorporate a bottleneck layer within\nthe U-Net architecture, serving as neural ordinary differential equations with\nconvolution operations, to capture the spatiotemporal dynamics of latent\nvariables. Through real data analysis with datasets spanning from 1998 to 2021,\nour proposed model demonstrates significant improvements over state-of-the-art\nmodels in the sea ice concentration forecasting task. It achieves an average\nMAE improvement of 12% compared to benchmark models. Additionally, our method\noutperforms existing approaches in sea ice extent forecasting, achieving a\nclassification performance improvement of approximately 18%. These experimental\nresults show the superiority of our proposed model.",
    "categories": [
      "cs.AI",
      "physics.ao-ph"
    ],
    "primary_category": "cs.AI",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2405.03929v2",
    "published_date": "2024-05-07 01:17:06 UTC",
    "updated_date": "2024-09-02 03:37:46 UTC"
  },
  {
    "arxiv_id": "2405.03924v2",
    "title": "NeurDB: An AI-powered Autonomous Data System",
    "authors": [
      "Beng Chin Ooi",
      "Shaofeng Cai",
      "Gang Chen",
      "Yanyan Shen",
      "Kian-Lee Tan",
      "Yuncheng Wu",
      "Xiaokui Xiao",
      "Naili Xing",
      "Cong Yue",
      "Lingze Zeng",
      "Meihui Zhang",
      "Zhanhao Zhao"
    ],
    "abstract": "In the wake of rapid advancements in artificial intelligence (AI), we stand\non the brink of a transformative leap in data systems. The imminent fusion of\nAI and DB (AIxDB) promises a new generation of data systems, which will relieve\nthe burden on end-users across all industry sectors by featuring AI-enhanced\nfunctionalities, such as personalized and automated in-database AI-powered\nanalytics, self-driving capabilities for improved system performance, etc. In\nthis paper, we explore the evolution of data systems with a focus on deepening\nthe fusion of AI and DB. We present NeurDB, an AI-powered autonomous data\nsystem designed to fully embrace AI design in each major system component and\nprovide in-database AI-powered analytics. We outline the conceptual and\narchitectural overview of NeurDB, discuss its design choices and key\ncomponents, and report its current development and future plan.",
    "categories": [
      "cs.DB",
      "cs.AI",
      "cs.LG"
    ],
    "primary_category": "cs.DB",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2405.03924v2",
    "published_date": "2024-05-07 00:51:48 UTC",
    "updated_date": "2024-07-04 08:48:45 UTC"
  },
  {
    "arxiv_id": "2405.03920v1",
    "title": "A Roadmap for Multilingual, Multimodal Domain Independent Deception Detection",
    "authors": [
      "Dainis Boumber",
      "Rakesh M. Verma",
      "Fatima Zahra Qachfar"
    ],
    "abstract": "Deception, a prevalent aspect of human communication, has undergone a\nsignificant transformation in the digital age. With the globalization of online\ninteractions, individuals are communicating in multiple languages and mixing\nlanguages on social media, with varied data becoming available in each language\nand dialect. At the same time, the techniques for detecting deception are\nsimilar across the board. Recent studies have shown the possibility of the\nexistence of universal linguistic cues to deception across domains within the\nEnglish language; however, the existence of such cues in other languages\nremains unknown. Furthermore, the practical task of deception detection in\nlow-resource languages is not a well-studied problem due to the lack of labeled\ndata. Another dimension of deception is multimodality. For example, a picture\nwith an altered caption in fake news or disinformation may exist. This paper\ncalls for a comprehensive investigation into the complexities of deceptive\nlanguage across linguistic boundaries and modalities within the realm of\ncomputer security and natural language processing and the possibility of using\nmultilingual transformer models and labeled data in various languages to\nuniversally address the task of deception detection.",
    "categories": [
      "cs.CL",
      "cs.AI",
      "cs.MM",
      "I.2.6; I.2.7; I.2.10; K.4.4"
    ],
    "primary_category": "cs.CL",
    "comment": "6 pages, 1 figure, shorter version in SIAM International Conference\n  on Data Mining (SDM) 2024",
    "pdf_url": "http://arxiv.org/pdf/2405.03920v1",
    "published_date": "2024-05-07 00:38:34 UTC",
    "updated_date": "2024-05-07 00:38:34 UTC"
  },
  {
    "arxiv_id": "2405.03911v4",
    "title": "Federated Graph Condensation with Information Bottleneck Principles",
    "authors": [
      "Bo Yan",
      "Sihao He",
      "Cheng Yang",
      "Shang Liu",
      "Yang Cao",
      "Chuan Shi"
    ],
    "abstract": "Graph condensation (GC), which reduces the size of a large-scale graph by\nsynthesizing a small-scale condensed graph as its substitution, has benefited\nvarious graph learning tasks. However, existing GC methods rely on centralized\ndata storage, which is unfeasible for real-world decentralized data\ndistribution, and overlook data holders' privacy-preserving requirements. To\nbridge this gap, we propose and study the novel problem of federated graph\ncondensation (FGC) for graph neural networks (GNNs). Specifically, we first\npropose a general framework for FGC, where we decouple the typical gradient\nmatching process for GC into client-side gradient calculation and server-side\ngradient matching, integrating knowledge from multiple clients' subgraphs into\none smaller condensed graph. Nevertheless, our empirical studies show that\nunder the federated setting, the condensed graph will consistently leak data\nmembership privacy, i.e., the condensed graph during federated training can be\nutilized to steal training data under the membership inference attack (MIA). To\ntackle this issue, we innovatively incorporate information bottleneck\nprinciples into the FGC, which only needs to extract partial node features in\none local pre-training step and utilize the features during federated training.\nTheoretical and experimental analyses demonstrate that our framework\nconsistently protects membership privacy during training. Meanwhile, it can\nachieve comparable and even superior performance against existing centralized\nGC and federated graph learning (FGL) methods.",
    "categories": [
      "cs.LG",
      "cs.AI",
      "cs.CR",
      "cs.DC"
    ],
    "primary_category": "cs.LG",
    "comment": "14 pages. Accepted by AAAI 2025",
    "pdf_url": "http://arxiv.org/pdf/2405.03911v4",
    "published_date": "2024-05-07 00:08:15 UTC",
    "updated_date": "2024-12-20 07:57:07 UTC"
  }
]