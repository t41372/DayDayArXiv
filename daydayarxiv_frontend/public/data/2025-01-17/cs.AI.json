{
  "date": "2025-01-17",
  "category": "cs.AI",
  "summary": "欢迎来到 UTC 时间 2025-01-17 的 arXiv 中文 TLDR 快报！\n\n今天 arXiv 的论文主要聚焦 AI 模型优化、生成式 AI 在交通和教育领域的应用、数据集构建以及多模态学习等主题，令人印象深刻的是多模态 LLM 在视频交通分析中的创新（如论文 1）和 LLM 幻觉缓解技术（如论文 2），以及 Google 和 OpenAI 等团队的相关工作，突显了 AI 在实际场景中的潜力。\n\n### AI 模型优化与生成\n- **Prompt-Based Monte Carlo Tree Search for Mitigating Hallucinations in Large Models（基于提示的蒙特卡洛树搜索缓解大模型幻觉）**：论文提出改进的 MCTS 方法，通过动态调整探索参数减少 LLM 幻觉，在 SciEval 数据集上表现优于现有模型，主要贡献是提升大模型在科学任务中的鲁棒性。\n- **GaussMark: A Practical Approach for Structural Watermarking of Language Models（GaussMark：一种实用的语言模型结构水印方法）**：引入基于高斯独立测试的水印方案，嵌入模型权重中，提高文本生成可追溯性，同时保持模型质量和鲁棒性，对抗 LLM 生成的伦理挑战。\n- **Hierarchical Autoregressive Transformers: Combining Byte- and Word-Level Processing for Robust, Adaptable Language Models（分层自回归 Transformer：结合字节和单词级处理提升语言模型鲁棒性）**：提出分层 Transformer 架构，融合字符和单词处理，显著提升模型对输入扰动的鲁棒性和跨语言适应性，在 7B 参数规模下匹配子词分词模型性能。\n\n### 多模态与应用创新\n- **When language and vision meet road safety: leveraging multimodal large language models for video-based traffic accident analysis（语言与视觉结合道路安全：利用多模态大语言模型进行视频交通事故分析）**：开发 SeeUnsafe 框架，使用 MLLM 自动分析交通视频，实现交互式事故分类和视觉定位，主要发现是提高交通安全监控的效率和适应性。\n- **ColorGrid: A Multi-Agent Non-Stationary Environment for Goal Inference and Assistance（ColorGrid：用于目标推理和辅助的多代理非平稳环境）**：构建 ColorGrid 环境测试 MARL 算法，焦点在代理间非平稳目标推理，IPPO 算法表现不足，为未来 MARL 基准提供新工具。\n- **Agent4Edu: Generating Learner Response Data by Generative Agents for Intelligent Education Systems（Agent4Edu：使用生成代理生成学习者响应数据以支持智能教育系统）**：利用 LLM 生成代理模拟学习行为，提升个性化教育算法评估，主要贡献是创建可扩展的模拟框架，改善教育 AI 的数据生成和验证。\n\n### 数据集与基准\n- **LegalScore: Development of a Benchmark for Evaluating AI Models in Legal Career Exams in Brazil（LegalScore：评估巴西法律职业考试中 AI 模型的基准开发）**：构建 LegalScore 基准，评估 LLM 在法律考试中的性能，强调本地化训练数据的重要性，主要发现是专有模型在巴西语境下表现更佳。\n- **IE-Bench: Advancing the Measurement of Text-Driven Image Editing for Human Perception Alignment（IE-Bench：提升文本驱动图像编辑的测量以实现人类感知对齐）**：提出 IE-Bench 数据集和评估模型，针对文本驱动图像编辑优化感知对齐，显著改善编辑任务的准确性。\n- **ArxEval: Evaluating Retrieval and Generation in Language Models for Scientific Literature（ArxEval：评估语言模型在科学文献中的检索和生成）**：开发 ArxEval 基准测试 LLM 的科学文献处理能力，主要发现是模型在检索生成任务上存在 hallucination 问题。\n\n其他论文如教育 AI 工具（如论文 6、8）和交通预测优化（如论文 16、50、51）等虽有实际价值，但主题较具体，我快速掠过：这些工作主要通过神经网络改进 AI 培训和预测模型，提升资源效率和准确性，但未有突破性创新。\n\n总之，今天的论文强调 AI 的实用性和鲁棒性，相关研究可为 LLM 应用提供新方向。更多细节请查阅 arXiv！",
  "papers": [
    {
      "arxiv_id": "2501.10604v1",
      "title": "When language and vision meet road safety: leveraging multimodal large language models for video-based traffic accident analysis",
      "title_zh": "当语言与视觉遇见道路安全：利用多模态大型语言模型",
      "authors": [
        "Ruixuan Zhang",
        "Beichen Wang",
        "Juexiao Zhang",
        "Zilin Bian",
        "Chen Feng",
        "Kaan Ozbay"
      ],
      "abstract": "The increasing availability of traffic videos functioning on a 24/7/365 time\nscale has the great potential of increasing the spatio-temporal coverage of\ntraffic accidents, which will help improve traffic safety. However, analyzing\nfootage from hundreds, if not thousands, of traffic cameras in a 24/7/365\nworking protocol remains an extremely challenging task, as current vision-based\napproaches primarily focus on extracting raw information, such as vehicle\ntrajectories or individual object detection, but require laborious\npost-processing to derive actionable insights. We propose SeeUnsafe, a new\nframework that integrates Multimodal Large Language Model (MLLM) agents to\ntransform video-based traffic accident analysis from a traditional\nextraction-then-explanation workflow to a more interactive, conversational\napproach. This shift significantly enhances processing throughput by automating\ncomplex tasks like video classification and visual grounding, while improving\nadaptability by enabling seamless adjustments to diverse traffic scenarios and\nuser-defined queries. Our framework employs a severity-based aggregation\nstrategy to handle videos of various lengths and a novel multimodal prompt to\ngenerate structured responses for review and evaluation and enable fine-grained\nvisual grounding. We introduce IMS (Information Matching Score), a new\nMLLM-based metric for aligning structured responses with ground truth. We\nconduct extensive experiments on the Toyota Woven Traffic Safety dataset,\ndemonstrating that SeeUnsafe effectively performs accident-aware video\nclassification and visual grounding by leveraging off-the-shelf MLLMs. Source\ncode will be available at \\url{https://github.com/ai4ce/SeeUnsafe}.",
      "tldr_zh": "该论文探讨了如何利用 Multimodal Large Language Models (MLLMs) 分析交通视频，以提升道路安全。研究提出 SeeUnsafe 框架，将传统的提取-解释工作流转变为交互式对话方式，自动化视频分类、视觉定位，并采用严重度-based 聚合策略处理不同视频长度，同时引入新型多模态提示生成结构化响应。框架还开发了 IMS (Information Matching Score) 指标，用于评估响应与真实数据的匹配度。在 Toyota Woven Traffic Safety 数据集上的实验显示，SeeUnsafe 显著提高了事故感知视频分类和视觉定位的性能。",
      "categories": [
        "cs.CV",
        "cs.AI",
        "cs.CL"
      ],
      "primary_category": "cs.CV",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2501.10604v1",
      "published_date": "2025-01-17 23:35:34 UTC",
      "updated_date": "2025-01-17 23:35:34 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-22T00:29:00.499934"
    },
    {
      "arxiv_id": "2501.13942v1",
      "title": "Prompt-Based Monte Carlo Tree Search for Mitigating Hallucinations in Large Models",
      "title_zh": "翻译失败",
      "authors": [
        "Zhihua Duan",
        "Jialin Wang"
      ],
      "abstract": "With the rapid development of large models in the field of artificial\nintelligence, how to enhance their application capabilities in handling complex\nproblems in the field of scientific research remains a challenging problem to\nbe solved. This study proposes an improved Monte Carlo Tree Search (MCTS)\nmethod based on prompt words. In the simulation search stage, it introduces\ndynamic adjustment of exploration parameters and adaptive selection strategies,\nwhich can better balance exploration and exploitation, thereby reducing the\nhallucination phenomenon. This paper takes the four subsets of the SciEval\ndataset as the test objects, and compares the Glm-4-flash+Improved MCTS method\nwith the methods of several existing models. The results show that the Improved\nMCTS method performs better, providing new ideas and methods for the\napplication of large models in the field of scientific research.",
      "tldr_zh": "该研究针对大型模型在处理复杂科研问题时存在的hallucinations现象，提出了一种基于提示词的改进Monte Carlo Tree Search (MCTS) 方法。该方法在模拟搜索阶段引入动态调整探索参数和自适应选择策略，以更好地平衡探索与利用，从而减少模型的幻觉发生。实验在SciEval数据集的四个子集上进行，与现有模型比较，Glm-4-flash+Improved MCTS 方法表现出优越性能，为大型模型在科研领域的应用提供了新思路和方法。",
      "categories": [
        "cs.AI"
      ],
      "primary_category": "cs.AI",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2501.13942v1",
      "published_date": "2025-01-17 23:06:50 UTC",
      "updated_date": "2025-01-17 23:06:50 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-22T00:29:11.272972"
    },
    {
      "arxiv_id": "2501.10593v1",
      "title": "ColorGrid: A Multi-Agent Non-Stationary Environment for Goal Inference and Assistance",
      "title_zh": "翻译失败",
      "authors": [
        "Andrey Risukhin",
        "Kavel Rao",
        "Ben Caffee",
        "Alan Fan"
      ],
      "abstract": "Autonomous agents' interactions with humans are increasingly focused on\nadapting to their changing preferences in order to improve assistance in\nreal-world tasks. Effective agents must learn to accurately infer human goals,\nwhich are often hidden, to collaborate well. However, existing Multi-Agent\nReinforcement Learning (MARL) environments lack the necessary attributes\nrequired to rigorously evaluate these agents' learning capabilities. To this\nend, we introduce ColorGrid, a novel MARL environment with customizable\nnon-stationarity, asymmetry, and reward structure. We investigate the\nperformance of Independent Proximal Policy Optimization (IPPO), a\nstate-of-the-art (SOTA) MARL algorithm, in ColorGrid and find through extensive\nablations that, particularly with simultaneous non-stationary and asymmetric\ngoals between a ``leader'' agent representing a human and a ``follower''\nassistant agent, ColorGrid is unsolved by IPPO. To support benchmarking future\nMARL algorithms, we release our environment code, model checkpoints, and\ntrajectory visualizations at https://github.com/andreyrisukhin/ColorGrid.",
      "tldr_zh": "该论文引入了 ColorGrid，这是一个新型的多智能体强化学习（MARL）环境，旨在评估代理如何推断和适应人类隐藏目标，以提升真实任务中的协助性能。ColorGrid 支持自定义的 non-stationarity（非平稳性）、asymmetry（不对称性）和奖励结构，弥补了现有环境在严格评估代理学习能力方面的不足。通过实验测试，作者发现 Independent Proximal Policy Optimization (IPPO) 算法在处理“leader”代理（代表人类）和“follower”代理的同时非平稳性和不对称目标时无法有效解决环境。为支持未来 MARL 算法的基准测试，论文发布了环境代码、模型检查点和轨迹可视化资源。",
      "categories": [
        "cs.AI",
        "cs.LG"
      ],
      "primary_category": "cs.AI",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2501.10593v1",
      "published_date": "2025-01-17 22:55:33 UTC",
      "updated_date": "2025-01-17 22:55:33 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-22T00:29:24.324234"
    },
    {
      "arxiv_id": "2501.13941v1",
      "title": "GaussMark: A Practical Approach for Structural Watermarking of Language Models",
      "title_zh": "翻译失败",
      "authors": [
        "Adam Block",
        "Ayush Sekhari",
        "Alexander Rakhlin"
      ],
      "abstract": "Recent advances in Large Language Models (LLMs) have led to significant\nimprovements in natural language processing tasks, but their ability to\ngenerate human-quality text raises significant ethical and operational concerns\nin settings where it is important to recognize whether or not a given text was\ngenerated by a human. Thus, recent work has focused on developing techniques\nfor watermarking LLM-generated text, i.e., introducing an almost imperceptible\nsignal that allows a provider equipped with a secret key to determine if given\ntext was generated by their model. Current watermarking techniques are often\nnot practical due to concerns with generation latency, detection time,\ndegradation in text quality, or robustness. Many of these drawbacks come from\nthe focus on token-level watermarking, which ignores the inherent structure of\ntext. In this work, we introduce a new scheme, GaussMark, that is simple and\nefficient to implement, has formal statistical guarantees on its efficacy,\ncomes at no cost in generation latency, and embeds the watermark into the\nweights of the model itself, providing a structural watermark. Our approach is\nbased on Gaussian independence testing and is motivated by recent empirical\nobservations that minor additive corruptions to LLM weights can result in\nmodels of identical (or even improved) quality. We show that by adding a small\namount of Gaussian noise to the weights of a given LLM, we can watermark the\nmodel in a way that is statistically detectable by a provider who retains the\nsecret key. We provide formal statistical bounds on the validity and power of\nour procedure. Through an extensive suite of experiments, we demonstrate that\nGaussMark is reliable, efficient, and relatively robust to corruptions such as\ninsertions, deletions, substitutions, and roundtrip translations and can be\ninstantiated with essentially no loss in model quality.",
      "tldr_zh": "该研究针对大型语言模型(LLMs)生成文本的伦理问题，提出了一种实用的结构水印方案GaussMark，以识别文本是否由特定模型生成。不同于传统的token-level watermarking，GaussMark通过向模型权重添加少量高斯噪声，基于Gaussian independence testing实现水印嵌入，从而避免了生成延迟和文本质量下降。实验结果显示，该方法具有正式的统计保证、较高的鲁棒性（如对插入、删除、替换和翻译的抵抗力），并在不影响模型性能的情况下提供了可靠的检测机制。",
      "categories": [
        "cs.CR",
        "cs.AI",
        "cs.CL",
        "cs.LG"
      ],
      "primary_category": "cs.CR",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2501.13941v1",
      "published_date": "2025-01-17 22:30:08 UTC",
      "updated_date": "2025-01-17 22:30:08 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-22T00:29:35.180806"
    },
    {
      "arxiv_id": "2501.10579v1",
      "title": "AI Technicians: Developing Rapid Occupational Training Methods for a Competitive AI Workforce",
      "title_zh": "AI 技术人员：开发快速职业培训方法以培养竞争性 AI 劳动力",
      "authors": [
        "Jaromir Savelka",
        "Can Kultur",
        "Arav Agarwal",
        "Christopher Bogart",
        "Heather Burte",
        "Adam Zhang",
        "Majd Sakr"
      ],
      "abstract": "The accelerating pace of developments in Artificial Intelligence~(AI) and the\nincreasing role that technology plays in society necessitates substantial\nchanges in the structure of the workforce. Besides scientists and engineers,\nthere is a need for a very large workforce of competent AI technicians (i.e.,\nmaintainers, integrators) and users~(i.e., operators). As traditional 4-year\nand 2-year degree-based education cannot fill this quickly opening gap,\nalternative training methods have to be developed. We present the results of\nthe first four years of the AI Technicians program which is a unique\ncollaboration between the U.S. Army's Artificial Intelligence Integration\nCenter (AI2C) and Carnegie Mellon University to design, implement and evaluate\nnovel rapid occupational training methods to create a competitive AI workforce\nat the technicians level. Through this multi-year effort we have already\ntrained 59 AI Technicians. A key observation is that ongoing frequent updates\nto the training are necessary as the adoption of AI in the U.S. Army and within\nthe society at large is evolving rapidly. A tight collaboration among the\nstakeholders from the army and the university is essential for successful\ndevelopment and maintenance of the training for the evolving role. Our findings\ncan be leveraged by large organizations that face the challenge of developing a\ncompetent AI workforce as well as educators and researchers engaged in solving\nthe challenge.",
      "tldr_zh": "这篇论文探讨了人工智能（AI）快速发展对劳动力结构的影响，强调需要大量AI技术人员（如维护者和整合者）来填补传统教育无法及时覆盖的空缺。研究介绍了AI Technicians程序，这是U.S. Army's AI2C与Carnegie Mellon University合作开发的快速职业培训方法，已成功训练59名AI技术人员。关键发现包括培训需进行频繁更新以适应AI在军队和社会中的快速采用，并强调军校紧密合作的重要性。这些成果可为其他组织、教育者和研究者提供借鉴，以构建竞争力的AI劳动力。",
      "categories": [
        "cs.CY",
        "cs.AI"
      ],
      "primary_category": "cs.CY",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2501.10579v1",
      "published_date": "2025-01-17 22:14:56 UTC",
      "updated_date": "2025-01-17 22:14:56 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-22T00:29:47.198266"
    },
    {
      "arxiv_id": "2501.10576v1",
      "title": "AI Toolkit: Libraries and Essays for Exploring the Technology and Ethics of AI",
      "title_zh": "翻译失败",
      "authors": [
        "Levin Ho",
        "Morgan McErlean",
        "Zehua You",
        "Douglas Blank",
        "Lisa Meeden"
      ],
      "abstract": "In this paper we describe the development and evaluation of AITK, the\nArtificial Intelligence Toolkit. This open-source project contains both Python\nlibraries and computational essays (Jupyter notebooks) that together are\ndesigned to allow a diverse audience with little or no background in AI to\ninteract with a variety of AI tools, exploring in more depth how they function,\nvisualizing their outcomes, and gaining a better understanding of their ethical\nimplications. These notebooks have been piloted at multiple institutions in a\nvariety of humanities courses centered on the theme of responsible AI. In\naddition, we conducted usability testing of AITK. Our pilot studies and\nusability testing results indicate that AITK is easy to navigate and effective\nat helping users gain a better understanding of AI. Our goal, in this time of\nrapid innovations in AI, is for AITK to provide an accessible resource for\nfaculty from any discipline looking to incorporate AI topics into their courses\nand for anyone eager to learn more about AI on their own.",
      "tldr_zh": "该论文介绍了 AI Toolkit (AITK)，一个开源项目，包含 Python libraries 和计算 essays (Jupyter notebooks)，旨在帮助缺乏 AI 背景的多样化用户探索 AI 工具的功能、可视化结果并理解其伦理影响。AITK 已在美国多所机构的文科课程中进行试点测试，并通过可用性测试证明其易于导航且有效提升用户对 AI 的理解。总体目标是为教师和自主学习者提供一个可访问资源，以在快速发展的 AI 时代将 AI 主题融入课程中。",
      "categories": [
        "cs.CY",
        "cs.AI",
        "cs.LG"
      ],
      "primary_category": "cs.CY",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2501.10576v1",
      "published_date": "2025-01-17 22:08:52 UTC",
      "updated_date": "2025-01-17 22:08:52 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-22T00:29:58.820824"
    },
    {
      "arxiv_id": "2501.10555v1",
      "title": "Towards Data-Centric AI: A Comprehensive Survey of Traditional, Reinforcement, and Generative Approaches for Tabular Data Transformation",
      "title_zh": "翻译失败",
      "authors": [
        "Dongjie Wang",
        "Yanyong Huang",
        "Wangyang Ying",
        "Haoyue Bai",
        "Nanxu Gong",
        "Xinyuan Wang",
        "Sixun Dong",
        "Tao Zhe",
        "Kunpeng Liu",
        "Meng Xiao",
        "Pengfei Wang",
        "Pengyang Wang",
        "Hui Xiong",
        "Yanjie Fu"
      ],
      "abstract": "Tabular data is one of the most widely used formats across industries,\ndriving critical applications in areas such as finance, healthcare, and\nmarketing. In the era of data-centric AI, improving data quality and\nrepresentation has become essential for enhancing model performance,\nparticularly in applications centered around tabular data. This survey examines\nthe key aspects of tabular data-centric AI, emphasizing feature selection and\nfeature generation as essential techniques for data space refinement. We\nprovide a systematic review of feature selection methods, which identify and\nretain the most relevant data attributes, and feature generation approaches,\nwhich create new features to simplify the capture of complex data patterns.\nThis survey offers a comprehensive overview of current methodologies through an\nanalysis of recent advancements, practical applications, and the strengths and\nlimitations of these techniques. Finally, we outline open challenges and\nsuggest future perspectives to inspire continued innovation in this field.",
      "tldr_zh": "本调查聚焦于数据中心AI（Data-Centric AI），探讨了传统、强化（Reinforcement）和生成（Generative）方法在表格数据（Tabular Data）转换中的应用，强调特征选择（Feature Selection）和特征生成（Feature Generation）作为提升数据质量和模型性能的关键技术。论文系统回顾了这些方法的最新进展、实际应用、优势及局限性，例如如何识别相关属性或创建新特征以捕捉复杂模式。最终，概述了当前领域的开放挑战和未来展望，以推动相关创新。",
      "categories": [
        "cs.LG",
        "cs.AI"
      ],
      "primary_category": "cs.LG",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2501.10555v1",
      "published_date": "2025-01-17 21:05:09 UTC",
      "updated_date": "2025-01-17 21:05:09 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-22T00:30:10.596983"
    },
    {
      "arxiv_id": "2502.10395v1",
      "title": "An Integrated Platform for Studying Learning with Intelligent Tutoring Systems: CTAT+TutorShop",
      "title_zh": "翻译失败",
      "authors": [
        "Vincent Aleven",
        "Conrad Borchers",
        "Yun Huang",
        "Tomohiro Nagashima",
        "Bruce McLaren",
        "Paulo Carvalho",
        "Octav Popescu",
        "Jonathan Sewall",
        "Kenneth Koedinger"
      ],
      "abstract": "Intelligent tutoring systems (ITSs) are effective in helping students learn;\nfurther research could make them even more effective. Particularly desirable is\nresearch into how students learn with these systems, how these systems best\nsupport student learning, and what learning sciences principles are key in\nITSs. CTAT+Tutorshop provides a full stack integrated platform that facilitates\na complete research lifecycle with ITSs, which includes using ITS data to\ndiscover learner challenges, to identify opportunities for system improvements,\nand to conduct experimental studies. The platform includes authoring tools to\nsupport and accelerate development of ITS, which provide automatic data logging\nin a format compatible with DataShop, an independent site that supports the\nanalysis of ed tech log data to study student learnings. Among the many\ntechnology platforms that exist to support learning sciences research,\nCTAT+Tutorshop may be the only one that offers researchers the possibility to\nauthor elements of ITSs, or whole ITSs, as part of designing studies. This\nplatform has been used to develop and conduct an estimated 147 research studies\nwhich have run in a wide variety of laboratory and real-world educational\nsettings, including K-12 and higher education, and have addressed a wide range\nof research questions. This paper presents five case studies of research\nconducted on the CTAT+Tutorshop platform, and summarizes what has been\naccomplished and what is possible for future researchers. We reflect on the\ndistinctive elements of this platform that have made it so effective in\nfacilitating a wide range of ITS research.",
      "tldr_zh": "本论文介绍了 CTAT+TutorShop，这是一个集成平台，用于研究智能辅导系统（ITSs）如何提升学生学习效果。平台支持完整的 ITS 研究生命周期，包括利用 ITS 数据发现学习者挑战、识别系统改进机会以及进行实验研究，并提供作者工具和自动数据日志记录，与 DataShop 兼容。研究者可以通过该平台创建 ITS 元素或整个系统来设计实验，已应用于约147个研究案例，涵盖K-12和高等教育环境。论文通过五个案例研究总结了平台的独特优势，并反思其在促进 ITS 研究中的有效性。",
      "categories": [
        "cs.CY",
        "cs.AI",
        "cs.HC"
      ],
      "primary_category": "cs.CY",
      "comment": "Reviewed for and presented at the Fifth Annual Workshop on\n  Learning@Scale 2024: A/B Testing and Platform-Enabled Learning Research",
      "pdf_url": "http://arxiv.org/pdf/2502.10395v1",
      "published_date": "2025-01-17 20:49:08 UTC",
      "updated_date": "2025-01-17 20:49:08 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-22T00:31:30.110749"
    },
    {
      "arxiv_id": "2501.10546v1",
      "title": "Scalable Machine Learning Training Infrastructure for Online Ads Recommendation and Auction Scoring Modeling at Google",
      "title_zh": "可扩展的机器学习训练基础设施，用于 Google 的在线广告推荐和拍卖评分建模",
      "authors": [
        "George Kurian",
        "Somayeh Sardashti",
        "Ryan Sims",
        "Felix Berger",
        "Gary Holt",
        "Yang Li",
        "Jeremiah Willcock",
        "Kaiyuan Wang",
        "Herve Quiroz",
        "Abdulrahman Salem",
        "Julian Grady"
      ],
      "abstract": "Large-scale Ads recommendation and auction scoring models at Google scale\ndemand immense computational resources. While specialized hardware like TPUs\nhave improved linear algebra computations, bottlenecks persist in large-scale\nsystems. This paper proposes solutions for three critical challenges that must\nbe addressed for efficient end-to-end execution in a widely used production\ninfrastructure: (1) Input Generation and Ingestion Pipeline: Efficiently\ntransforming raw features (e.g., \"search query\") into numerical inputs and\nstreaming them to TPUs; (2) Large Embedding Tables: Optimizing conversion of\nsparse features into dense floating-point vectors for neural network\nconsumption; (3) Interruptions and Error Handling: Minimizing resource wastage\nin large-scale shared datacenters. To tackle these challenges, we propose a\nshared input generation technique to reduce computational load of input\ngeneration by amortizing costs across many models. Furthermore, we propose\npartitioning, pipelining, and RPC (Remote Procedure Call) coalescing software\ntechniques to optimize embedding operations. To maintain efficiency at scale,\nwe describe novel preemption notice and training hold mechanisms that minimize\nresource wastage, and ensure prompt error resolution. These techniques have\ndemonstrated significant improvement in Google production, achieving a 116%\nperformance boost and an 18% reduction in training costs across representative\nmodels.",
      "tldr_zh": "这篇论文介绍了 Google 用于在线广告推荐和拍卖评分模型的 scalable 机器学习训练基础设施，针对大规模系统中的计算瓶颈提出解决方案。论文重点解决三个关键挑战：（1）输入生成和摄取管道，通过共享输入生成技术分摊计算负载；（2）大型嵌入表优化，利用分区、流水线和 RPC 合并技术高效转换稀疏特征；（3）中断和错误处理，通过抢占通知和训练保持机制最小化资源浪费。实验结果显示，这些方法在 Google 生产环境中实现了 116% 的性能提升和 18% 的训练成本降低。",
      "categories": [
        "cs.DC",
        "cs.AI",
        "cs.LG",
        "C.0; C.4; I.2.6"
      ],
      "primary_category": "cs.DC",
      "comment": "13 pages, 7 figures",
      "pdf_url": "http://arxiv.org/pdf/2501.10546v1",
      "published_date": "2025-01-17 20:40:56 UTC",
      "updated_date": "2025-01-17 20:40:56 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-22T00:30:35.346799"
    },
    {
      "arxiv_id": "2501.10543v1",
      "title": "FORLAPS: An Innovative Data-Driven Reinforcement Learning Approach for Prescriptive Process Monitoring",
      "title_zh": "FORLAPS：一种创新的数据驱动强化学习方法，用于规范性过程监控",
      "authors": [
        "Mostafa Abbasi",
        "Maziyar Khadivi",
        "Maryam Ahang",
        "Patricia Lasserre",
        "Yves Lucet",
        "Homayoun Najjaran"
      ],
      "abstract": "We present a novel 5-step framework called Fine-Tuned Offline Reinforcement\nLearning Augmented Process Sequence Optimization (FORLAPS), which aims to\nidentify optimal execution paths in business processes using reinforcement\nlearning. We implemented this approach on real-life event logs from our case\nstudy an energy regulator in Canada and other real-life event logs,\ndemonstrating the feasibility of the proposed method. Additionally, to compare\nFORLAPS with the existing models (Permutation Feature Importance and multi-task\nLSTM-Based model), we experimented to evaluate its effectiveness in terms of\nresource savings and process time span reduction. The experimental results on\nreal-life event log validate that FORLAPS achieves 31% savings in resource time\nspent and a 23% reduction in process time span. Using this innovative data\naugmentation technique, we propose a fine-tuned reinforcement learning approach\nthat aims to automatically fine-tune the model by selectively increasing the\naverage estimated Q-value in the sampled batches. The results show that we\nobtained a 44% performance improvement compared to the pre-trained model. This\nstudy introduces an innovative evaluation model, benchmarking its performance\nagainst earlier works using nine publicly available datasets. Robustness is\nensured through experiments utilizing the Damerau-Levenshtein distance as the\nprimary metric. In addition, we discussed the suitability of datasets, taking\ninto account their inherent properties, to evaluate the performance of\ndifferent models. The proposed model, FORLAPS, demonstrated exceptional\nperformance, outperforming existing state-of-the-art approaches in suggesting\nthe most optimal policies or predicting the best next activities within a\nprocess trace.",
      "tldr_zh": "本研究提出了一种创新的数据驱动强化学习框架FORLAPS（Fine-Tuned Offline Reinforcement Learning Augmented Process Sequence Optimization），通过5步方法识别商业过程中的最佳执行路径，以实现规范性过程监控。FORLAPS在加拿大能源监管机构等真实事件日志上进行了验证，与Permutation Feature Importance和multi-task LSTM-Based模型相比，它实现了31%的资源时间节约和23%的过程时间减少，并通过数据增强技术细调模型，获得44%的性能提升。实验结果显示，FORLAPS在九个公开数据集上的基准测试中表现出色，使用Damerau-Levenshtein distance作为主要指标，显著超过了现有最先进方法，在预测最佳活动和建议最优策略方面表现卓越。",
      "categories": [
        "cs.LG",
        "cs.AI"
      ],
      "primary_category": "cs.LG",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2501.10543v1",
      "published_date": "2025-01-17 20:31:35 UTC",
      "updated_date": "2025-01-17 20:31:35 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-22T00:30:48.097594"
    },
    {
      "arxiv_id": "2501.10542v2",
      "title": "Improved IR-based Bug Localization with Intelligent Relevance Feedback",
      "title_zh": "翻译失败",
      "authors": [
        "Asif Mohammed Samir",
        "Mohammad Masudur Rahman"
      ],
      "abstract": "Software bugs pose a significant challenge during development and\nmaintenance, and practitioners spend nearly 50% of their time dealing with\nbugs. Many existing techniques adopt Information Retrieval (IR) to localize a\nreported bug using textual and semantic relevance between bug reports and\nsource code. However, they often struggle to bridge a critical gap between bug\nreports and code that requires in-depth contextual understanding, which goes\nbeyond textual or semantic relevance. In this paper, we present a novel\ntechnique for bug localization - BRaIn - that addresses the contextual gaps by\nassessing the relevance between bug reports and code with Large Language Models\n(LLM). It then leverages the LLM's feedback (a.k.a., Intelligent Relevance\nFeedback) to reformulate queries and re-rank source documents, improving bug\nlocalization. We evaluate BRaIn using a benchmark dataset, Bench4BL, and three\nperformance metrics and compare it against six baseline techniques from the\nliterature. Our experimental results show that BRaIn outperforms baselines by\n87.6%, 89.5%, and 48.8% margins in MAP, MRR, and HIT@K, respectively.\nAdditionally, it can localize approximately 52% of bugs that cannot be\nlocalized by the baseline techniques due to the poor quality of corresponding\nbug reports. By addressing the contextual gaps and introducing Intelligent\nRelevance Feedback, BRaIn advances not only theory but also improves IR-based\nbug localization.",
      "tldr_zh": "本研究针对软件错误定位的挑战，提出了一种改进的基于信息检索(IR)的方法BRaIn，利用Large Language Models(LLM)来评估错误报告与代码的相关性，并通过Intelligent Relevance Feedback重构查询和重新排序文档，以填补上下文理解的空白。相比现有六种基线技术，BRaIn在Bench4BL数据集上的实验结果显示，MAP、MRR和HIT@K指标分别提高了87.6%、89.5%和48.8%。此外，该方法能定位约52%的基线技术无法处理的错误，特别是那些报告质量较差的案例，从而在IR-based bug localization的理论和实践上实现了显著进展。",
      "categories": [
        "cs.SE",
        "cs.AI",
        "cs.CL",
        "F.2.2; I.2.7"
      ],
      "primary_category": "cs.SE",
      "comment": "13 pages, 5 figures",
      "pdf_url": "http://arxiv.org/pdf/2501.10542v2",
      "published_date": "2025-01-17 20:29:38 UTC",
      "updated_date": "2025-03-27 23:51:49 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-22T00:31:41.838824"
    },
    {
      "arxiv_id": "2501.16345v2",
      "title": "Self-Clustering Graph Transformer Approach to Model Resting-State Functional Brain Activity",
      "title_zh": "Self",
      "authors": [
        "Bishal Thapaliya",
        "Esra Akbas",
        "Ram Sapkota",
        "Bhaskar Ray",
        "Vince Calhoun",
        "Jingyu Liu"
      ],
      "abstract": "Resting-state functional magnetic resonance imaging (rs-fMRI) offers valuable\ninsights into the human brain's functional organization and is a powerful tool\nfor investigating the relationship between brain function and cognitive\nprocesses, as it allows for the functional organization of the brain to be\ncaptured without relying on a specific task or stimuli. In this study, we\nintroduce a novel attention mechanism for graphs with subnetworks, named\nSelf-Clustering Graph Transformer (SCGT), designed to handle the issue of\nuniform node updates in graph transformers. By using static functional\nconnectivity (FC) correlation features as input to the transformer model, SCGT\neffectively captures the sub-network structure of the brain by performing\ncluster-specific updates to the nodes, unlike uniform node updates in vanilla\ngraph transformers, further allowing us to learn and interpret the subclusters.\nWe validate our approach on the Adolescent Brain Cognitive Development (ABCD)\ndataset, comprising 7,957 participants, for the prediction of total cognitive\nscore and gender classification. Our results demonstrate that SCGT outperforms\nthe vanilla graph transformer method and other recent models, offering a\npromising tool for modeling brain functional connectivity and interpreting the\nunderlying subnetwork structures.",
      "tldr_zh": "本文提出了一种名为 Self-Clustering Graph Transformer (SCGT) 的新方法，用于建模静息态功能磁共振成像 (rs-fMRI) 数据，以更好地捕捉大脑的功能组织和子网络结构。SCGT 通过使用静态 functional connectivity (FC) 相关特征作为输入，进行集群特定的节点更新，解决了传统图变换器中节点更新统一的局限性，从而提升了对大脑子集群的学习和解释能力。在 Adolescent Brain Cognitive Development (ABCD) 数据集（包括7,957名参与者）上进行的实验显示，SCGT 在预测总认知分数和性别分类任务中优于传统图变换器和其他模型，为大脑功能连接的建模和潜在子网络结构的解读提供了有前景的工具。",
      "categories": [
        "cs.LG",
        "cs.AI"
      ],
      "primary_category": "cs.LG",
      "comment": "5 pages, 2 figures - Accepted under International Symposium on\n  Biomedical Imaging (ISBI 2025) Conference",
      "pdf_url": "http://arxiv.org/pdf/2501.16345v2",
      "published_date": "2025-01-17 20:21:31 UTC",
      "updated_date": "2025-02-07 08:57:37 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-22T00:31:54.356426"
    },
    {
      "arxiv_id": "2501.10534v1",
      "title": "4bit-Quantization in Vector-Embedding for RAG",
      "title_zh": "翻译失败",
      "authors": [
        "Taehee Jeong"
      ],
      "abstract": "Retrieval-augmented generation (RAG) is a promising technique that has shown\ngreat potential in addressing some of the limitations of large language models\n(LLMs). LLMs have two major limitations: they can contain outdated information\ndue to their training data, and they can generate factually inaccurate\nresponses, a phenomenon known as hallucinations. RAG aims to mitigate these\nissues by leveraging a database of relevant documents, which are stored as\nembedding vectors in a high-dimensional space. However, one of the challenges\nof using high-dimensional embeddings is that they require a significant amount\nof memory to store. This can be a major issue, especially when dealing with\nlarge databases of documents. To alleviate this problem, we propose the use of\n4-bit quantization to store the embedding vectors. This involves reducing the\nprecision of the vectors from 32-bit floating-point numbers to 4-bit integers,\nwhich can significantly reduce the memory requirements. Our approach has\nseveral benefits. Firstly, it significantly reduces the memory storage\nrequirements of the high-dimensional vector database, making it more feasible\nto deploy RAG systems in resource-constrained environments. Secondly, it speeds\nup the searching process, as the reduced precision of the vectors allows for\nfaster computation. Our code is available at\nhttps://github.com/taeheej/4bit-Quantization-in-Vector-Embedding-for-RAG",
      "tldr_zh": "该论文探讨了检索增强生成（RAG）技术如何缓解大型语言模型（LLMs）的局限性，如过时信息和幻觉问题，但RAG依赖高维嵌入向量存储导致的内存消耗过高。作者提出使用4-bit quantization方法，将嵌入向量从32-bit浮点数量化到4-bit整数，从而显著减少存储需求并加速搜索过程。实验结果显示，这种优化使RAG系统更适合资源受限环境，并提供了开源代码（https://github.com/taeheej/4bit-Quantization-in-Vector-Embedding-for-RAG）。",
      "categories": [
        "cs.LG",
        "cs.AI"
      ],
      "primary_category": "cs.LG",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2501.10534v1",
      "published_date": "2025-01-17 20:15:11 UTC",
      "updated_date": "2025-01-17 20:15:11 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-22T00:32:05.192603"
    },
    {
      "arxiv_id": "2501.10526v1",
      "title": "Solving Sparse Finite Element Problems on Neuromorphic Hardware",
      "title_zh": "在神经形态硬件上求解稀疏有限元问题",
      "authors": [
        "Bradley H. Theilman",
        "James B. Aimone"
      ],
      "abstract": "We demonstrate that scalable neuromorphic hardware can implement the finite\nelement method, which is a critical numerical method for engineering and\nscientific discovery. Our approach maps the sparse interactions between\nneighboring finite elements to small populations of neurons that dynamically\nupdate according to the governing physics of a desired problem description. We\nshow that for the Poisson equation, which describes many physical systems such\nas gravitational and electrostatic fields, this cortical-inspired neural\ncircuit can achieve comparable levels of numerical accuracy and scaling while\nenabling the use of inherently parallel and energy-efficient neuromorphic\nhardware. We demonstrate that this approach can be used on the Intel Loihi 2\nplatform and illustrate how this approach can be extended to nontrivial mesh\ngeometries and dynamics.",
      "tldr_zh": "本研究证明了可扩展的神经形态硬件可以实现有限元方法（finite element method），这是一种用于工程和科学发现的关键数值方法。研究方法将稀疏的有限元之间邻域交互映射到小型神经元群，这些神经元根据Poisson方程（描述重力场和静电场等物理系统）的物理定律动态更新，从而在Intel Loihi 2平台上实现与传统方法相当的数值准确性和可扩展性，同时利用其固有的并行性和节能特性。实验结果显示，这种方法可扩展到复杂网格几何和动态场景，为高效的计算框架提供了新途径。",
      "categories": [
        "cs.NE",
        "cs.AI",
        "cs.LG",
        "cs.NA",
        "math.NA"
      ],
      "primary_category": "cs.NE",
      "comment": "Pre-publication submission",
      "pdf_url": "http://arxiv.org/pdf/2501.10526v1",
      "published_date": "2025-01-17 19:56:43 UTC",
      "updated_date": "2025-01-17 19:56:43 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-22T00:32:27.995959"
    },
    {
      "arxiv_id": "2502.08652v1",
      "title": "LegalScore: Development of a Benchmark for Evaluating AI Models in Legal Career Exams in Brazil",
      "title_zh": "LegalScore：开发用于评估巴西法律职业考试中AI模型的基准",
      "authors": [
        "Roberto Caparroz",
        "Marcelo Roitman",
        "Beatriz G. Chow",
        "Caroline Giusti",
        "Larissa Torhacs",
        "Pedro A. Sola",
        "João H. M. Diogo",
        "Luiza Balby",
        "Carolina D. L. Vasconcelos",
        "Leonardo R. Caparroz",
        "Albano P. Franco"
      ],
      "abstract": "This research introduces LegalScore, a specialized index for assessing how\ngenerative artificial intelligence models perform in a selected range of career\nexams that require a legal background in Brazil. The index evaluates fourteen\ndifferent types of artificial intelligence models' performance, from\nproprietary to open-source models, in answering objective questions applied to\nthese exams. The research uncovers the response of the models when applying\nEnglish-trained large language models to Brazilian legal contexts, leading us\nto reflect on the importance and the need for Brazil-specific training data in\ngenerative artificial intelligence models. Performance analysis shows that\nwhile proprietary and most known models achieved better results overall, local\nand smaller models indicated promising performances due to their Brazilian\ncontext alignment in training. By establishing an evaluation framework with\nmetrics including accuracy, confidence intervals, and normalized scoring,\nLegalScore enables systematic assessment of artificial intelligence performance\nin legal examinations in Brazil. While the study demonstrates artificial\nintelligence's potential value for exam preparation and question development,\nit concludes that significant improvements are needed before AI can match human\nperformance in advanced legal assessments. The benchmark creates a foundation\nfor continued research, highlighting the importance of local adaptation in\nartificial intelligence development.",
      "tldr_zh": "这篇论文开发了 LegalScore 基准，用于评估生成式 AI 模型在巴西法律职业考试中的表现，包括对 14 种专有和开源模型的性能测试。研究通过准确率、置信区间和标准化评分等指标分析了这些模型在回答客观法律问题时的效果，发现专有模型整体表现更佳，但本地训练模型因与巴西语境的匹配而显示出潜力。论文强调了为 AI 模型提供巴西特定训练数据的必要性，并指出尽管 AI 可用于考试准备和问题开发，但其在高级法律评估中仍需显著改进，以匹配人类水平。",
      "categories": [
        "cs.CY",
        "cs.AI"
      ],
      "primary_category": "cs.CY",
      "comment": "Main article 25 pages, Appendices from page 26",
      "pdf_url": "http://arxiv.org/pdf/2502.08652v1",
      "published_date": "2025-01-17 19:38:53 UTC",
      "updated_date": "2025-01-17 19:38:53 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-22T00:32:30.130703"
    },
    {
      "arxiv_id": "2501.10514v1",
      "title": "Real-Time Bus Departure Prediction Using Neural Networks for Smart IoT Public Bus Transit",
      "title_zh": "翻译失败",
      "authors": [
        "Narges Rashvand",
        "Sanaz Sadat Hosseini",
        "Mona Azarbayjani",
        "Hamed Tabkhi"
      ],
      "abstract": "Bus transit plays a vital role in urban public transportation but often\nstruggles to provide accurate and reliable departure times. This leads to\ndelays, passenger dissatisfaction, and decreased ridership, particularly in\ntransit-dependent areas. A major challenge lies in the discrepancy between\nactual and scheduled bus departure times, which disrupts timetables and impacts\noverall operational efficiency. To address these challenges, this paper\npresents a neural network-based approach for real-time bus departure time\nprediction tailored for smart IoT public transit applications. We leverage\nAI-driven models to enhance the accuracy of bus schedules by preprocessing\ndata, engineering relevant features, and implementing a fully connected neural\nnetwork that utilizes historical departure data to predict departure times at\nsubsequent stops. In our case study analyzing bus data from Boston, we observed\nan average deviation of nearly 4 minutes from scheduled times. However, our\nmodel, evaluated across 151 bus routes, demonstrates a significant improvement,\npredicting departure time deviations with an accuracy of under 80 seconds. This\nadvancement not only improves the reliability of bus transit schedules but also\nplays a crucial role in enabling smart bus systems and IoT applications within\npublic transit networks. By providing more accurate real-time predictions, our\napproach can facilitate the integration of IoT devices, such as smart bus stops\nand passenger information systems, that rely on precise data for optimal\nperformance.",
      "tldr_zh": "本研究针对公交系统出发时间不准确导致的延误和效率问题，提出了一种基于神经网络的实时预测方法，适用于智能IoT公共交通应用。该方法通过数据预处理、特征工程和全连接神经网络，利用历史出发数据来预测后续站点的出发时间。在波士顿公交数据的案例分析中，模型将平均偏差从近4分钟降低到80秒以内，显著提升了预测准确性。该创新有助于改善公交时间可靠性，并促进IoT设备的集成，如智能公交站和乘客信息系统。",
      "categories": [
        "cs.LG",
        "cs.AI"
      ],
      "primary_category": "cs.LG",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2501.10514v1",
      "published_date": "2025-01-17 19:21:51 UTC",
      "updated_date": "2025-01-17 19:21:51 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-22T00:32:41.089604"
    },
    {
      "arxiv_id": "2501.10343v1",
      "title": "3rd Workshop on Maritime Computer Vision (MaCVi) 2025: Challenge Results",
      "title_zh": "翻译失败",
      "authors": [
        "Benjamin Kiefer",
        "Lojze Žust",
        "Jon Muhovič",
        "Matej Kristan",
        "Janez Perš",
        "Matija Teršek",
        "Uma Mudenagudi Chaitra Desai",
        "Arnold Wiliem",
        "Marten Kreis",
        "Nikhil Akalwadi",
        "Yitong Quan",
        "Zhiqiang Zhong",
        "Zhe Zhang",
        "Sujie Liu",
        "Xuran Chen",
        "Yang Yang",
        "Matej Fabijanić",
        "Fausto Ferreira",
        "Seongju Lee",
        "Junseok Lee",
        "Kyoobin Lee",
        "Shanliang Yao",
        "Runwei Guan",
        "Xiaoyu Huang",
        "Yi Ni",
        "Himanshu Kumar",
        "Yuan Feng",
        "Yi-Ching Cheng",
        "Tzu-Yu Lin",
        "Chia-Ming Lee",
        "Chih-Chung Hsu",
        "Jannik Sheikh",
        "Andreas Michel",
        "Wolfgang Gross",
        "Martin Weinmann",
        "Josip Šarić",
        "Yipeng Lin",
        "Xiang Yang",
        "Nan Jiang",
        "Yutang Lu",
        "Fei Feng",
        "Ali Awad",
        "Evan Lucas",
        "Ashraf Saleem",
        "Ching-Heng Cheng",
        "Yu-Fan Lin",
        "Tzu-Yu Lin",
        "Chih-Chung Hsu"
      ],
      "abstract": "The 3rd Workshop on Maritime Computer Vision (MaCVi) 2025 addresses maritime\ncomputer vision for Unmanned Surface Vehicles (USV) and underwater. This report\noffers a comprehensive overview of the findings from the challenges. We provide\nboth statistical and qualitative analyses, evaluating trends from over 700\nsubmissions. All datasets, evaluation code, and the leaderboard are available\nto the public at https://macvi.org/workshop/macvi25.",
      "tldr_zh": "该报告总结了第三届海洋计算机视觉(Maritime Computer Vision)工作坊(MaCVi) 2025的挑战赛结果，聚焦于无人水面车辆(USV)和水下应用领域。通过对超过700个提交进行统计和定性分析，该工作坊评估了当前技术趋势，并提供了全面的发现概述。所有相关数据集、评估代码和排行榜已公开可用，访问地址为https://macvi.org/workshop/macvi25。",
      "categories": [
        "cs.CV",
        "cs.AI"
      ],
      "primary_category": "cs.CV",
      "comment": "Part of the MaCVi 2025 workshop",
      "pdf_url": "http://arxiv.org/pdf/2501.10343v1",
      "published_date": "2025-01-17 18:34:47 UTC",
      "updated_date": "2025-01-17 18:34:47 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-22T00:32:53.142577"
    },
    {
      "arxiv_id": "2501.10332v1",
      "title": "Agent4Edu: Generating Learner Response Data by Generative Agents for Intelligent Education Systems",
      "title_zh": "Agent4Edu：通过生成式代理生成学习者响应数据，用于智能教育系统",
      "authors": [
        "Weibo Gao",
        "Qi Liu",
        "Linan Yue",
        "Fangzhou Yao",
        "Rui Lv",
        "Zheng Zhang",
        "Hao Wang",
        "Zhenya Huang"
      ],
      "abstract": "Personalized learning represents a promising educational strategy within\nintelligent educational systems, aiming to enhance learners' practice\nefficiency. However, the discrepancy between offline metrics and online\nperformance significantly impedes their progress. To address this challenge, we\nintroduce Agent4Edu, a novel personalized learning simulator leveraging recent\nadvancements in human intelligence through large language models (LLMs).\nAgent4Edu features LLM-powered generative agents equipped with learner profile,\nmemory, and action modules tailored to personalized learning algorithms. The\nlearner profiles are initialized using real-world response data, capturing\npractice styles and cognitive factors. Inspired by human psychology theory, the\nmemory module records practice facts and high-level summaries, integrating\nreflection mechanisms. The action module supports various behaviors, including\nexercise understanding, analysis, and response generation. Each agent can\ninteract with personalized learning algorithms, such as computerized adaptive\ntesting, enabling a multifaceted evaluation and enhancement of customized\nservices. Through a comprehensive assessment, we explore the strengths and\nweaknesses of Agent4Edu, emphasizing the consistency and discrepancies in\nresponses between agents and human learners. The code, data, and appendix are\npublicly available at https://github.com/bigdata-ustc/Agent4Edu.",
      "tldr_zh": "本研究提出Agent4Edu，一种基于大型语言模型(LLMs)的个性化学习模拟器，用于生成学习者响应数据，以解决智能教育系统中离线指标与在线性能不一致的问题。Agent4Edu 包括LLM驱动的生成代理，配备学习者配置文件（初始化自真实数据，包括实践风格和认知因素）、记忆模块（基于人类心理学理论记录事实、总结和反思）以及行动模块（支持练习理解、分析和响应生成）。代理可与个性化学习算法如computerized adaptive testing互动，进行多方面评估；实验结果突显了Agent4Edu在响应一致性上的优势和局限性，并通过公开代码和数据促进进一步研究。",
      "categories": [
        "cs.CY",
        "cs.AI"
      ],
      "primary_category": "cs.CY",
      "comment": "Accepted by AAAI2025",
      "pdf_url": "http://arxiv.org/pdf/2501.10332v1",
      "published_date": "2025-01-17 18:05:04 UTC",
      "updated_date": "2025-01-17 18:05:04 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-22T00:33:05.311291"
    },
    {
      "arxiv_id": "2501.10326v1",
      "title": "Large language models for automated scholarly paper review: A survey",
      "title_zh": "大语言模型用于自动学术论文审阅：一项调查",
      "authors": [
        "Zhenzhen Zhuang",
        "Jiandong Chen",
        "Hongfeng Xu",
        "Yuwen Jiang",
        "Jialiang Lin"
      ],
      "abstract": "Large language models (LLMs) have significantly impacted human society,\ninfluencing various domains. Among them, academia is not simply a domain\naffected by LLMs, but it is also the pivotal force in the development of LLMs.\nIn academic publications, this phenomenon is represented during the\nincorporation of LLMs into the peer review mechanism for reviewing manuscripts.\nWe proposed the concept of automated scholarly paper review (ASPR) in our\nprevious paper. As the incorporation grows, it now enters the coexistence phase\nof ASPR and peer review, which is described in that paper. LLMs hold\ntransformative potential for the full-scale implementation of ASPR, but they\nalso pose new issues and challenges that need to be addressed. In this survey\npaper, we aim to provide a holistic view of ASPR in the era of LLMs. We begin\nwith a survey to find out which LLMs are used to conduct ASPR. Then, we review\nwhat ASPR-related technological bottlenecks have been solved with the\nincorporation of LLM technology. After that, we move on to explore new methods,\nnew datasets, new source code, and new online systems that come with LLMs for\nASPR. Furthermore, we summarize the performance and issues of LLMs in ASPR, and\ninvestigate the attitudes and reactions of publishers and academia to ASPR.\nLastly, we discuss the challenges associated with the development of LLMs for\nASPR. We hope this survey can serve as an inspirational reference for the\nresearchers and promote the progress of ASPR for its actual implementation.",
      "tldr_zh": "这篇调查论文探讨了大型语言模型(LLMs)在自动学术论文审阅(ASPR)中的应用，分析了LLMs如何影响同行评审机制并推动ASPR的发展。作者回顾了当前使用的LLMs、解决的技术瓶颈（如审阅效率问题）、以及新兴的方法、数据集、源代码和在线系统。研究总结了LLMs在ASPR中的性能优势、潜在问题、学术界和出版商的态度，并讨论了未来挑战，如伦理和可靠性问题，以促进ASPR的实际实施。",
      "categories": [
        "cs.AI",
        "cs.CL",
        "cs.DL"
      ],
      "primary_category": "cs.AI",
      "comment": "Work in progress",
      "pdf_url": "http://arxiv.org/pdf/2501.10326v1",
      "published_date": "2025-01-17 17:56:58 UTC",
      "updated_date": "2025-01-17 17:56:58 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-22T00:33:17.024676"
    },
    {
      "arxiv_id": "2501.10322v2",
      "title": "Hierarchical Autoregressive Transformers: Combining Byte- and Word-Level Processing for Robust, Adaptable Language Models",
      "title_zh": "翻译失败",
      "authors": [
        "Pit Neitemeier",
        "Björn Deiseroth",
        "Constantin Eichenberg",
        "Lukas Balles"
      ],
      "abstract": "Tokenization is a fundamental step in natural language processing, breaking\ntext into units that computational models can process. While learned subword\ntokenizers have become the de-facto standard, they present challenges such as\nlarge vocabularies, limited adaptability to new domains or languages, and\nsensitivity to spelling errors and variations. To overcome these limitations,\nwe investigate a hierarchical architecture for autoregressive language\nmodelling that combines character-level and word-level processing. It employs a\nlightweight character-level encoder to convert character sequences into word\nembeddings, which are then processed by a word-level backbone model and decoded\nback into characters via a compact character-level decoder. This method retains\nthe sequence compression benefits of word-level tokenization without relying on\na rigid, predefined vocabulary. We demonstrate, at scales up to 7 billion\nparameters, that hierarchical transformers match the downstream task\nperformance of subword-tokenizer-based models while exhibiting significantly\ngreater robustness to input perturbations. Additionally, during continued\npretraining on an out-of-domain language, our model trains almost twice as\nfast, achieves superior performance on the target language, and retains more of\nits previously learned knowledge. Hierarchical transformers pave the way for\nNLP systems that are more robust, flexible, and generalizable across languages\nand domains.",
      "tldr_zh": "这项研究提出了一种 hierarchical autoregressive transformers 架构，通过结合字符级和词级处理，解决了传统 subword tokenizers 在自然语言处理中的问题，如词汇量大、适应新领域或语言有限，以及对拼写错误敏感。该架构使用轻量级字符级编码器将字符序列转换为词嵌入，由词级主模型处理，并通过紧凑的字符级解码器输出，从而避免了刚性预定义词汇的依赖。在规模达70亿参数的实验中，该模型在下游任务性能上与基于 subword tokenizers 的模型相当，但对输入扰动表现出显著更高的鲁棒性，且在对新语言的持续预训练中，训练速度快一倍、性能更优，并更好地保留先前知识。这种方法为构建更灵活、可泛化的 NLP 系统铺平了道路。",
      "categories": [
        "cs.CL",
        "cs.AI",
        "cs.LG"
      ],
      "primary_category": "cs.CL",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2501.10322v2",
      "published_date": "2025-01-17 17:51:53 UTC",
      "updated_date": "2025-01-20 09:33:21 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-22T00:33:30.989881"
    },
    {
      "arxiv_id": "2501.10300v1",
      "title": "An Ontology for Social Determinants of Education (SDoEd) based on Human-AI Collaborative Approach",
      "title_zh": "翻译失败",
      "authors": [
        "Navya Martin Kollapally",
        "James Geller",
        "Patricia Morreale",
        "Daehan Kwak"
      ],
      "abstract": "The use of computational ontologies is well-established in the field of\nMedical Informatics. The topic of Social Determinants of Health (SDoH) has also\nreceived extensive attention. Work at the intersection of ontologies and SDoH\nhas been published. However, a standardized framework for Social Determinants\nof Education (SDoEd) is lacking. In this paper, we are closing the gap by\nintroducing an SDoEd ontology for creating a precise conceptualization of the\ninterplay between life circumstances of students and their possible educational\nachievements. The ontology was developed utilizing suggestions from\nChatGPT-3.5-010422 and validated using peer-reviewed research articles. The\nfirst version of developed ontology was evaluated by human experts in the field\nof education and validated using standard ontology evaluation software. This\nversion of the SDoEd ontology contains 231 domain concepts, 10 object\nproperties, and 24 data properties",
      "tldr_zh": "这篇论文提出了一种 Social Determinants of Education (SDoEd) ontology，用于精确概念化学生生活环境与教育成就之间的相互作用，填补了该领域的标准化框架空白。研究采用 Human-AI 协作方法，利用 ChatGPT-3.5-010422 的建议，并通过同行评议文章、专家评估和标准 ontology 评估软件进行验证。该 ontology 的第一版包含 231 个 domain concepts、10 个 object properties 和 24 个 data properties，为教育研究提供了一个可靠的计算框架。",
      "categories": [
        "cs.AI"
      ],
      "primary_category": "cs.AI",
      "comment": "Accepted in CONSORTIUM FOR COMPUTING SCIENCES IN COLLEGES",
      "pdf_url": "http://arxiv.org/pdf/2501.10300v1",
      "published_date": "2025-01-17 16:51:03 UTC",
      "updated_date": "2025-01-17 16:51:03 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-22T00:33:42.359230"
    },
    {
      "arxiv_id": "2501.10273v1",
      "title": "SEANN: A Domain-Informed Neural Network for Epidemiological Insights",
      "title_zh": "翻译失败",
      "authors": [
        "Jean-Baptiste Guimbaud",
        "Marc Plantevit",
        "Léa Maître",
        "Rémy Cazabet"
      ],
      "abstract": "In epidemiology, traditional statistical methods such as logistic regression,\nlinear regression, and other parametric models are commonly employed to\ninvestigate associations between predictors and health outcomes. However,\nnon-parametric machine learning techniques, such as deep neural networks\n(DNNs), coupled with explainable AI (XAI) tools, offer new opportunities for\nthis task. Despite their potential, these methods face challenges due to the\nlimited availability of high-quality, high-quantity data in this field. To\naddress these challenges, we introduce SEANN, a novel approach for informed\nDNNs that leverages a prevalent form of domain-specific knowledge: Pooled\nEffect Sizes (PES). PESs are commonly found in published Meta-Analysis studies,\nin different forms, and represent a quantitative form of a scientific\nconsensus. By direct integration within the learning procedure using a custom\nloss, we experimentally demonstrate significant improvements in the\ngeneralizability of predictive performances and the scientific plausibility of\nextracted relationships compared to a domain-knowledge agnostic neural network\nin a scarce and noisy data setting.",
      "tldr_zh": "本研究提出SEANN，一种整合领域特定知识的神经网络框架，用于提升流行病学洞察。SEANN利用Pooled Effect Sizes (PES)——来自Meta-Analysis研究的科学共识量化形式——通过自定义损失函数直接融入DNN的学习过程，以应对数据稀缺和噪声挑战。实验结果显示，与无领域知识的神经网络相比，SEANN显著提高了预测性能的泛化性和提取关系的科学合理性。",
      "categories": [
        "cs.LG",
        "cs.AI"
      ],
      "primary_category": "cs.LG",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2501.10273v1",
      "published_date": "2025-01-17 16:01:05 UTC",
      "updated_date": "2025-01-17 16:01:05 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-22T00:33:52.923615"
    },
    {
      "arxiv_id": "2501.10256v1",
      "title": "Unsupervised Rhythm and Voice Conversion of Dysarthric to Healthy Speech for ASR",
      "title_zh": "翻译失败",
      "authors": [
        "Karl El Hajal",
        "Enno Hermann",
        "Ajinkya Kulkarni",
        "Mathew Magimai. -Doss"
      ],
      "abstract": "Automatic speech recognition (ASR) systems are well known to perform poorly\non dysarthric speech. Previous works have addressed this by speaking rate\nmodification to reduce the mismatch with typical speech. Unfortunately, these\napproaches rely on transcribed speech data to estimate speaking rates and\nphoneme durations, which might not be available for unseen speakers. Therefore,\nwe combine unsupervised rhythm and voice conversion methods based on\nself-supervised speech representations to map dysarthric to typical speech. We\nevaluate the outputs with a large ASR model pre-trained on healthy speech\nwithout further fine-tuning and find that the proposed rhythm conversion\nespecially improves performance for speakers of the Torgo corpus with more\nsevere cases of dysarthria. Code and audio samples are available at\nhttps://idiap.github.io/RnV .",
      "tldr_zh": "本研究针对ASR（Automatic Speech Recognition）系统在处理构音障碍（dysarthric）语音时的低性能问题，提出了一种无监督的节奏和语音转换方法，利用self-supervised speech representations将dysarthric语音映射到正常语音，从而减少语音不匹配。不同于以往依赖转录数据的做法，该方法无需额外标注数据，仅通过自监督表示进行转换，并在预训练的大型ASR模型上进行评估。实验结果显示，该节奏转换方法显著提升了Torgo语料库中严重dysarthria说话者的识别性能，证明了其在实际应用中的潜力。",
      "categories": [
        "eess.AS",
        "cs.AI",
        "cs.LG",
        "cs.SD"
      ],
      "primary_category": "eess.AS",
      "comment": "Accepted at ICASSP 2025 Satellite Workshop: Workshop on Speech\n  Pathology Analysis and DEtection (SPADE)",
      "pdf_url": "http://arxiv.org/pdf/2501.10256v1",
      "published_date": "2025-01-17 15:39:21 UTC",
      "updated_date": "2025-01-17 15:39:21 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-22T00:34:05.190808"
    },
    {
      "arxiv_id": "2501.10243v2",
      "title": "Random-Key Algorithms for Optimizing Integrated Operating Room Scheduling",
      "title_zh": "优化集成手术室调度的随机键算法",
      "authors": [
        "Bruno Salezze Vieira",
        "Eduardo Machado Silva",
        "Antonio Augusto Chaves"
      ],
      "abstract": "Efficient surgery room scheduling is essential for hospital efficiency,\npatient satisfaction, and resource utilization. This study addresses this\nchallenge by introducing a novel concept of Random-Key Optimizer (RKO),\nrigorously tested on literature and new, real-world inspired instances. Our\ncombinatorial optimization problem incorporates multi-room scheduling,\nequipment scheduling, and complex availability constraints for rooms, patients,\nand surgeons, facilitating rescheduling and enhancing operational flexibility.\nThe RKO approach represents solutions as points in a continuous space, which\nare then mapped in the problem solution space via a deterministic function\nknown as a decoder. The core idea is to operate metaheuristics and heuristics\nin the random-key space, unaware of the original solution space. We design the\nBiased Random-Key Genetic Algorithm with $Q$-Learning, Simulated Annealing, and\nIterated Local Search for use within an RKO framework, employing a single\ndecoder function. The proposed metaheuristics are complemented by lower-bound\nformulations, providing optimal gaps for evaluating the effectiveness of the\nheuristic results. Our results demonstrate significant lower and upper bounds\nimprovements for the literature instances, notably proving one optimal result.\nFurthermore, the best-proposed metaheuristic efficiently generates schedules\nfor the newly introduced instances, even in highly constrained scenarios. This\nresearch offers valuable insights and practical solutions for improving surgery\nscheduling processes, offering tangible benefits to hospitals by optimising\nresource allocation, reducing patient wait times, and enhancing overall\noperational efficiency.",
      "tldr_zh": "本研究引入了 Random-Key Optimizer (RKO) 框架，用于优化手术室调度问题，包括多房间调度、设备调度以及房间、患者和外科医生的复杂可用性约束。RKO 通过将解决方案表示为连续空间中的点，并使用一个确定性解码器映射到问题空间，结合 Biased Random-Key Genetic Algorithm with Q-Learning、Simulated Annealing 和 Iterated Local Search 等算法进行优化，同时辅以 lower-bound formulations 来评估结果有效性。实验结果显示，该方法在文献实例上显著改善了下界和上界，甚至证明了一个最优结果，并在新引入的真实场景实例中高效生成调度。总体而言，这为医院优化资源分配、减少患者等待时间并提升运营效率提供了宝贵见解和实用解决方案。",
      "categories": [
        "cs.NE",
        "cs.AI",
        "math.CO",
        "F.2.2; I.2.7; I.2.8"
      ],
      "primary_category": "cs.NE",
      "comment": "38 pages, Preprint submitted to Applied Soft Computing",
      "pdf_url": "http://arxiv.org/pdf/2501.10243v2",
      "published_date": "2025-01-17 15:11:30 UTC",
      "updated_date": "2025-01-24 15:59:16 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-22T00:34:19.259033"
    },
    {
      "arxiv_id": "2501.10240v2",
      "title": "Challenges and recommendations for Electronic Health Records data extraction and preparation for dynamic prediction modelling in hospitalized patients -- a practical guide",
      "title_zh": "翻译失败",
      "authors": [
        "Elena Albu",
        "Shan Gao",
        "Pieter Stijnen",
        "Frank E. Rademakers",
        "Bas C T van Bussel",
        "Taya Collyer",
        "Tina Hernandez-Boussard",
        "Laure Wynants",
        "Ben Van Calster"
      ],
      "abstract": "Dynamic predictive modelling using electronic health record (EHR) data has\ngained significant attention in recent years. The reliability and\ntrustworthiness of such models depend heavily on the quality of the underlying\ndata, which is, in part, determined by the stages preceding the model\ndevelopment: data extraction from EHR systems and data preparation. In this\narticle, we identified over forty challenges encountered during these stages\nand provide actionable recommendations for addressing them. These challenges\nare organized into four categories: cohort definition, outcome definition,\nfeature engineering, and data cleaning. This comprehensive list serves as a\npractical guide for data extraction engineers and researchers, promoting best\npractices and improving the quality and real-world applicability of dynamic\nprediction models in clinical settings.",
      "tldr_zh": "这篇论文探讨了使用 Electronic Health Records (EHR) 数据进行动态预测建模时，在数据提取和准备阶段面临的挑战，并提供了超过40个可操作的推荐。挑战被分为四个类别：cohort definition（队列定义）、outcome definition（结果定义）、feature engineering（特征工程）和 data cleaning（数据清洗）。这些推荐旨在指导数据提取工程师和研究人员采用最佳实践，从而提升模型的可靠性和在临床环境中的实际应用。",
      "categories": [
        "cs.LG",
        "cs.AI"
      ],
      "primary_category": "cs.LG",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2501.10240v2",
      "published_date": "2025-01-17 15:09:57 UTC",
      "updated_date": "2025-03-17 17:29:33 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-22T00:34:30.161307"
    },
    {
      "arxiv_id": "2501.10190v1",
      "title": "Temporal Causal Reasoning with (Non-Recursive) Structural Equation Models",
      "title_zh": "基于(非递归)结构方程模型的时间因果推理",
      "authors": [
        "Maksim Gladyshev",
        "Natasha Alechina",
        "Mehdi Dastani",
        "Dragan Doder",
        "Brian Logan"
      ],
      "abstract": "Structural Equation Models (SEM) are the standard approach to representing\ncausal dependencies between variables in causal models. In this paper we\npropose a new interpretation of SEMs when reasoning about Actual Causality, in\nwhich SEMs are viewed as mechanisms transforming the dynamics of exogenous\nvariables into the dynamics of endogenous variables. This allows us to combine\ncounterfactual causal reasoning with existing temporal logic formalisms, and to\nintroduce a temporal logic, CPLTL, for causal reasoning about such structures.\nWe show that the standard restriction to so-called \\textit{recursive} models\n(with no cycles in the dependency graph) is not necessary in our approach,\nallowing us to reason about mutually dependent processes and feedback loops.\nFinally, we introduce new notions of model equivalence for temporal causal\nmodels, and show that CPLTL has an efficient model-checking procedure.",
      "tldr_zh": "本论文提出了一种新解释，将 Structural Equation Models (SEMs) 视为将外生变量动态转化为内生变量动态的机制，从而将反事实因果推理与现有时间逻辑形式主义相结合，引入新的时间逻辑 CPLTL 用于处理时间因果推理。\n这一方法无需限制于递归模型（无循环依赖图），能够处理相互依赖的过程和反馈循环，扩展了 SEMs 的适用范围。\n论文还定义了时间因果模型的新等价概念，并证明 CPLTL 具有高效的模型检查过程。",
      "categories": [
        "cs.AI",
        "cs.LO"
      ],
      "primary_category": "cs.AI",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2501.10190v1",
      "published_date": "2025-01-17 13:37:58 UTC",
      "updated_date": "2025-01-17 13:37:58 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-22T00:36:43.072819"
    },
    {
      "arxiv_id": "2501.10187v2",
      "title": "Good things come in small packages: Should we build AI clusters with Lite-GPUs?",
      "title_zh": "翻译失败",
      "authors": [
        "Burcu Canakci",
        "Junyi Liu",
        "Xingbo Wu",
        "Nathanaël Cheriere",
        "Paolo Costa",
        "Sergey Legtchenko",
        "Dushyanth Narayanan",
        "Ant Rowstron"
      ],
      "abstract": "To match the blooming demand of generative AI workloads, GPU designers have\nso far been trying to pack more and more compute and memory into single complex\nand expensive packages. However, there is growing uncertainty about the\nscalability of individual GPUs and thus AI clusters, as state-of-the-art GPUs\nare already displaying packaging, yield, and cooling limitations. We propose to\nrethink the design and scaling of AI clusters through efficiently-connected\nlarge clusters of Lite-GPUs, GPUs with single, small dies and a fraction of the\ncapabilities of larger GPUs. We think recent advances in co-packaged optics can\nenable distributing AI workloads onto many Lite-GPUs through high bandwidth and\nefficient communication. In this paper, we present the key benefits of\nLite-GPUs on manufacturing cost, blast radius, yield, and power efficiency; and\ndiscuss systems opportunities and challenges around resource, workload, memory,\nand network management.",
      "tldr_zh": "该论文质疑当前AI集群的设计，提出使用Lite-GPUs（小型GPU）来构建高效连接的集群，以应对传统高性能GPU在包装、良率和冷却方面的可扩展性限制。作者认为，通过co-packaged optics技术实现高带宽通信，可以将AI工作负载分布到多个Lite-GPUs上，从而提升整体系统性能。Lite-GPUs的优势包括降低制造成本、减少blast radius故障影响、提高yield良率以及改善功率效率；同时，论文讨论了在资源、工作负载、内存和网络管理方面的系统机会和挑战。",
      "categories": [
        "cs.AR",
        "cs.AI",
        "cs.DC"
      ],
      "primary_category": "cs.AR",
      "comment": "HotOS'25",
      "pdf_url": "http://arxiv.org/pdf/2501.10187v2",
      "published_date": "2025-01-17 13:32:28 UTC",
      "updated_date": "2025-04-29 11:20:53 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-22T00:35:57.537033"
    },
    {
      "arxiv_id": "2501.10186v1",
      "title": "Generative Artificial Intelligence: Implications for Biomedical and Health Professions Education",
      "title_zh": "翻译失败",
      "authors": [
        "William Hersh"
      ],
      "abstract": "Generative AI has had a profound impact on biomedicine and health, both in\nprofessional work and in education. Based on large language models (LLMs),\ngenerative AI has been found to perform as well as humans in simulated\nsituations taking medical board exams, answering clinical questions, solving\nclinical cases, applying clinical reasoning, and summarizing information.\nGenerative AI is also being used widely in education, performing well in\nacademic courses and their assessments. This review summarizes the successes of\nLLMs and highlights some of their challenges in the context of education, most\nnotably aspects that may undermines the acquisition of knowledge and skills for\nprofessional work. It then provides recommendations for best practices\novercoming shortcomings for LLM use in education. Although there are challenges\nfor use of generative AI in education, all students and faculty, in biomedicine\nand health and beyond, must have understanding and be competent in its use.",
      "tldr_zh": "这篇论文探讨了 Generative AI 在生物医学和健康专业教育中的影响，基于 LLMs（大型语言模型），AI 在模拟医学考试、临床推理和信息总结等方面表现与人类相当，并在教育课程中表现出色。论文总结了 LLMs 的成功，同时强调了潜在挑战，如可能削弱知识和技能的获取，并提供了最佳实践推荐来克服这些缺点。尽管存在问题，论文主张所有生物医学和健康领域的学生及教职员工必须理解并熟练使用 Generative AI。",
      "categories": [
        "cs.AI"
      ],
      "primary_category": "cs.AI",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2501.10186v1",
      "published_date": "2025-01-17 13:32:19 UTC",
      "updated_date": "2025-01-17 13:32:19 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-22T00:35:06.721049"
    },
    {
      "arxiv_id": "2501.10179v1",
      "title": "A Simple but Effective Closed-form Solution for Extreme Multi-label Learning",
      "title_zh": "一种简单但有效的闭式解用于极端多标签学习",
      "authors": [
        "Kazuma Onishi",
        "Katsuhiko Hayashi"
      ],
      "abstract": "Extreme multi-label learning (XML) is a task of assigning multiple labels\nfrom an extremely large set of labels to each data instance. Many current\nhigh-performance XML models are composed of a lot of hyperparameters, which\ncomplicates the tuning process. Additionally, the models themselves are adapted\nspecifically to XML, which complicates their reimplementation. To remedy this\nproblem, we propose a simple method based on ridge regression for XML. The\nproposed method not only has a closed-form solution but also is composed of a\nsingle hyperparameter. Since there are no precedents on applying ridge\nregression to XML, this paper verified the performance of the method by using\nvarious XML benchmark datasets. Furthermore, we enhanced the prediction of\nlow-frequency labels in XML, which hold informative content. This prediction is\nessential yet challenging because of the limited amount of data. Here, we\nemployed a simple frequency-based weighting. This approach greatly simplifies\nthe process compared with existing techniques. Experimental results revealed\nthat it can achieve levels of performance comparable to, or even exceeding,\nthose of models with numerous hyperparameters. Additionally, we found that the\nfrequency-based weighting significantly improved the predictive performance for\nlow-frequency labels, while requiring almost no changes in implementation. The\nsource code for the proposed method is available on github at\nhttps://github.com/cars1015/XML-ridge.",
      "tldr_zh": "该论文针对Extreme multi-label learning (XML)任务提出了一种基于岭回归（ridge regression）的简单方法，以解决现有模型超参数众多和实现复杂的难题。该方法提供闭式解（closed-form solution），仅需一个超参数，从而简化了调优过程。作者还引入了基于频率的加权机制，以提升低频标签的预测性能，这些标签虽信息丰富但数据有限。实验结果显示，该方法在各种XML基准数据集上达到了与复杂模型相当或更高的性能，且实现简单，开源代码已在GitHub上发布。",
      "categories": [
        "cs.IR",
        "cs.AI",
        "cs.CL",
        "cs.LG"
      ],
      "primary_category": "cs.IR",
      "comment": "10pages, Accepted at ECIR25",
      "pdf_url": "http://arxiv.org/pdf/2501.10179v1",
      "published_date": "2025-01-17 13:24:13 UTC",
      "updated_date": "2025-01-17 13:24:13 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-22T00:35:17.527087"
    },
    {
      "arxiv_id": "2501.10160v1",
      "title": "CSSDM Ontology to Enable Continuity of Care Data Interoperability",
      "title_zh": "翻译失败",
      "authors": [
        "Subhashis Das",
        "Debashis Naskar",
        "Sara Rodriguez Gonzalez",
        "Pamela Hussey"
      ],
      "abstract": "The rapid advancement of digital technologies and recent global pandemic\nscenarios have led to a growing focus on how these technologies can enhance\nhealthcare service delivery and workflow to address crises. Action plans that\nconsolidate existing digital transformation programs are being reviewed to\nestablish core infrastructure and foundations for sustainable healthcare\nsolutions. Reforming health and social care to personalize home care, for\nexample, can help avoid treatment in overcrowded acute hospital settings and\nimprove the experiences and outcomes for both healthcare professionals and\nservice users. In this information-intensive domain, addressing the\ninteroperability challenge through standards-based roadmaps is crucial for\nenabling effective connections between health and social care services. This\napproach facilitates safe and trustworthy data workflows between different\nhealthcare system providers. In this paper, we present a methodology for\nextracting, transforming, and loading data through a semi-automated process\nusing a Common Semantic Standardized Data Model (CSSDM) to create personalized\nhealthcare knowledge graph (KG). The CSSDM is grounded in the formal ontology\nof ISO 13940 ContSys and incorporates FHIR-based specifications to support\nstructural attributes for generating KGs. We propose that the CSSDM facilitates\ndata harmonization and linking, offering an alternative approach to\ninteroperability. This approach promotes a novel form of collaboration between\ncompanies developing health information systems and cloud-enabled health\nservices. Consequently, it provides multiple stakeholders with access to\nhigh-quality data and information sharing.",
      "tldr_zh": "本研究针对医疗数据互操作性挑战，提出了一种基于 Common Semantic Standardized Data Model (CSSDM) 的本体框架，以实现连续性护理数据的无缝整合和共享。CSSDM 基于 ISO 13940 ContSys 正式本体并整合 FHIR 规范，通过半自动化提取、转换和加载过程，构建个性化的医疗知识图谱 (KG)，从而促进数据协调和链接。实验结果表明，此方法可提升医疗服务间的安全连接，支持公司间新型合作，并为多利益相关者提供高质量数据共享，提高个性化护理体验和效率。",
      "categories": [
        "cs.AI",
        "68T27",
        "I.2.4; I.2.1"
      ],
      "primary_category": "cs.AI",
      "comment": "6 pages, 5 figures, Published in: 2024 IEEE International Conference\n  on Bioinformatics and Biomedicine (BIBM)",
      "pdf_url": "http://arxiv.org/pdf/2501.10160v1",
      "published_date": "2025-01-17 12:48:48 UTC",
      "updated_date": "2025-01-17 12:48:48 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-22T00:35:29.282056"
    },
    {
      "arxiv_id": "2501.10153v1",
      "title": "Region-wise stacking ensembles for estimating brain-age using MRI",
      "title_zh": "翻译失败",
      "authors": [
        "Georgios Antonopoulos",
        "Shammi More",
        "Simon B. Eickhoff",
        "Federico Raimondo",
        "Kaustubh R. Patil"
      ],
      "abstract": "Predictive modeling using structural magnetic resonance imaging (MRI) data is\na prominent approach to study brain-aging. Machine learning algorithms and\nfeature extraction methods have been employed to improve predictions and\nexplore healthy and accelerated aging e.g. neurodegenerative and psychiatric\ndisorders. The high-dimensional MRI data pose challenges to building\ngeneralizable and interpretable models as well as for data privacy. Common\npractices are resampling or averaging voxels within predefined parcels, which\nreduces anatomical specificity and biological interpretability as voxels within\na region may differently relate to aging. Effectively, naive fusion by\naveraging can result in information loss and reduced accuracy. We present a\nconceptually novel two-level stacking ensemble (SE) approach. The first level\ncomprises regional models for predicting individuals' age based on voxel-wise\ninformation, fused by a second-level model yielding final predictions. Eight\ndata fusion scenarios were explored using as input Gray matter volume (GMV)\nestimates from four datasets covering the adult lifespan. Performance, measured\nusing mean absolute error (MAE), R2, correlation and prediction bias, showed\nthat SE outperformed the region-wise averages. The best performance was\nobtained when first-level regional predictions were obtained as out-of-sample\npredictions on the application site with second-level models trained on\nindependent and site-specific data (MAE=4.75 vs baseline regional mean GMV\nMAE=5.68). Performance improved as more datasets were used for training.\nFirst-level predictions showed improved and more robust aging signal providing\nnew biological insights and enhanced data privacy. Overall, the SE improves\naccuracy compared to the baseline while preserving or enhancing data privacy.",
      "tldr_zh": "这篇论文提出了一种基于 MRI 的脑年龄估计方法，使用 region-wise stacking ensembles（两级堆叠集成）来解决传统平均体素方法导致的信息丢失和准确性降低的问题。具体而言，第一级构建区域模型基于体素级灰质体积（GMV）信息预测年龄，第二级模型融合这些预测以得出最终结果。实验结果显示，该方法在多个数据集上显著优于基线，平均绝对误差（MAE）从 5.68 降至 4.75，且使用更多数据集训练时性能进一步提升，提供更 robust 的衰老信号并增强数据隐私。整体上，该方法提高了预测准确性，同时提升了生物可解释性和数据保护。",
      "categories": [
        "cs.LG",
        "cs.AI"
      ],
      "primary_category": "cs.LG",
      "comment": "version1",
      "pdf_url": "http://arxiv.org/pdf/2501.10153v1",
      "published_date": "2025-01-17 12:24:28 UTC",
      "updated_date": "2025-01-17 12:24:28 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-22T00:36:55.333918"
    },
    {
      "arxiv_id": "2501.10151v1",
      "title": "Topology-Driven Attribute Recovery for Attribute Missing Graph Learning in Social Internet of Things",
      "title_zh": "拓扑驱动的属性恢复，用于社会物联网中属性缺失图学习",
      "authors": [
        "Mengran Li",
        "Junzhou Chen",
        "Chenyun Yu",
        "Guanying Jiang",
        "Ronghui Zhang",
        "Yanming Shen",
        "Houbing Herbert Song"
      ],
      "abstract": "With the advancement of information technology, the Social Internet of Things\n(SIoT) has fostered the integration of physical devices and social networks,\ndeepening the study of complex interaction patterns. Text Attribute Graphs\n(TAGs) capture both topological structures and semantic attributes, enhancing\nthe analysis of complex interactions within the SIoT. However, existing graph\nlearning methods are typically designed for complete attributed graphs, and the\ncommon issue of missing attributes in Attribute Missing Graphs (AMGs) increases\nthe difficulty of analysis tasks. To address this, we propose the\nTopology-Driven Attribute Recovery (TDAR) framework, which leverages\ntopological data for AMG learning. TDAR introduces an improved pre-filling\nmethod for initial attribute recovery using native graph topology.\nAdditionally, it dynamically adjusts propagation weights and incorporates\nhomogeneity strategies within the embedding space to suit AMGs' unique\ntopological structures, effectively reducing noise during information\npropagation. Extensive experiments on public datasets demonstrate that TDAR\nsignificantly outperforms state-of-the-art methods in attribute reconstruction\nand downstream tasks, offering a robust solution to the challenges posed by\nAMGs. The code is available at https://github.com/limengran98/TDAR.",
      "tldr_zh": "本研究针对 Social Internet of Things (SIoT) 中的 Attribute Missing Graphs (AMGs)，提出 Topology-Driven Attribute Recovery (TDAR) 框架，以利用图拓扑数据进行属性恢复。TDAR 采用改进的预填充方法进行初始属性重建，并动态调整传播权重并融入同质性策略，以减少信息传播中的噪声。实验在公共数据集上表明，TDAR 在属性重建和下游任务中显著优于最先进方法，为处理 AMGs 的图学习挑战提供了鲁棒解决方案。",
      "categories": [
        "cs.AI"
      ],
      "primary_category": "cs.AI",
      "comment": "Accepted by IEEE Internet of Things Journal",
      "pdf_url": "http://arxiv.org/pdf/2501.10151v1",
      "published_date": "2025-01-17 12:23:42 UTC",
      "updated_date": "2025-01-17 12:23:42 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-22T00:37:06.841761"
    },
    {
      "arxiv_id": "2501.10150v2",
      "title": "Dual Debiasing: Remove Stereotypes and Keep Factual Gender for Fair Language Modeling and Translation",
      "title_zh": "双重去偏置：去除刻",
      "authors": [
        "Tomasz Limisiewicz",
        "David Mareček",
        "Tomáš Musil"
      ],
      "abstract": "Mitigation of biases, such as language models' reliance on gender\nstereotypes, is a crucial endeavor required for the creation of reliable and\nuseful language technology. The crucial aspect of debiasing is to ensure that\nthe models preserve their versatile capabilities, including their ability to\nsolve language tasks and equitably represent various genders. To address this\nissue, we introduce a streamlined Dual Dabiasing Algorithm through Model\nAdaptation (2DAMA). Novel Dual Debiasing enables robust reduction of\nstereotypical bias while preserving desired factual gender information encoded\nby language models. We show that 2DAMA effectively reduces gender bias in\nEnglish and is one of the first approaches facilitating the mitigation of\nstereotypical tendencies in translation. The proposed method's key advantage is\nthe preservation of factual gender cues, which are useful in a wide range of\nnatural language processing tasks.",
      "tldr_zh": "这篇论文引入了Dual Debiasing Algorithm through Model Adaptation (2DAMA)，一种双重去偏见方法，旨在减少语言模型和翻译任务中的性别刻板印象偏见，同时保留事实性别信息。2DAMA通过模型适应技术实现对刻板印象的鲁棒性减少，确保模型在处理语言任务时能公平代表各种性别。实验结果表明，该方法有效降低了英语中的性别偏见，并在翻译领域中首次缓解类似问题，并保持了事实性别线索的可用性，以支持广泛的自然语言处理任务。",
      "categories": [
        "cs.CL",
        "cs.AI"
      ],
      "primary_category": "cs.CL",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2501.10150v2",
      "published_date": "2025-01-17 12:23:30 UTC",
      "updated_date": "2025-01-30 20:11:45 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-22T00:37:18.145923"
    },
    {
      "arxiv_id": "2501.10141v1",
      "title": "Enhancing UAV Path Planning Efficiency Through Accelerated Learning",
      "title_zh": "通过加速学习提升 UAV 路径规划效率",
      "authors": [
        "Joseanne Viana",
        "Boris Galkin",
        "Lester Ho",
        "Holger Claussen"
      ],
      "abstract": "Unmanned Aerial Vehicles (UAVs) are increasingly essential in various fields\nsuch as surveillance, reconnaissance, and telecommunications. This study aims\nto develop a learning algorithm for the path planning of UAV wireless\ncommunication relays, which can reduce storage requirements and accelerate Deep\nReinforcement Learning (DRL) convergence. Assuming the system possesses terrain\nmaps of the area and can estimate user locations using localization algorithms\nor direct GPS reporting, it can input these parameters into the learning\nalgorithms to achieve optimized path planning performance. However, higher\nresolution terrain maps are necessary to extract topological information such\nas terrain height, object distances, and signal blockages. This requirement\nincreases memory and storage demands on UAVs while also lengthening convergence\ntimes in DRL algorithms. Similarly, defining the telecommunication coverage map\nin UAV wireless communication relays using these terrain maps and user position\nestimations demands higher memory and storage utilization for the learning path\nplanning algorithms. Our approach reduces path planning training time by\napplying a dimensionality reduction technique based on Principal Component\nAnalysis (PCA), sample combination, Prioritized Experience Replay (PER), and\nthe combination of Mean Squared Error (MSE) and Mean Absolute Error (MAE) loss\ncalculations in the coverage map estimates, thereby enhancing a Twin Delayed\nDeep Deterministic Policy Gradient (TD3) algorithm. The proposed solution\nreduces the convergence episodes needed for basic training by approximately\nfour times compared to the traditional TD3.",
      "tldr_zh": "该研究针对无人驾驶飞机（UAV）在无线通信中继中的路径规划问题，开发了一种加速学习算法，以减少存储需求并加快深度强化学习（DRL）的收敛速度。方法包括应用主成分分析（PCA）进行维度减少、样本组合、Prioritized Experience Replay (PER) 以及结合 Mean Squared Error (MSE) 和 Mean Absolute Error (MAE) 损失函数来增强 Twin Delayed Deep Deterministic Policy Gradient (TD3) 算法。结果显示，该方法将路径规划训练的收敛次数减少约四倍，提高了 UAV 的整体效率。",
      "categories": [
        "cs.LG",
        "cs.AI"
      ],
      "primary_category": "cs.LG",
      "comment": "This paper was accepted in https://camad2024.ieee-camad.org/\n  conference but it is not available from the conference yet",
      "pdf_url": "http://arxiv.org/pdf/2501.10141v1",
      "published_date": "2025-01-17 12:05:24 UTC",
      "updated_date": "2025-01-17 12:05:24 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-22T00:37:29.682082"
    },
    {
      "arxiv_id": "2501.10139v2",
      "title": "Conformal Prediction Sets with Improved Conditional Coverage using Trust Scores",
      "title_zh": "使用信任分数改进条件覆盖的保形预测集",
      "authors": [
        "Jivat Neet Kaur",
        "Michael I. Jordan",
        "Ahmed Alaa"
      ],
      "abstract": "Standard conformal prediction offers a marginal guarantee on coverage, but\nfor prediction sets to be truly useful, they should ideally ensure coverage\nconditional on each test point. Unfortunately, it is impossible to achieve\nexact, distribution-free conditional coverage in finite samples. In this work,\nwe propose an alternative conformal prediction algorithm that targets coverage\nwhere it matters most--in instances where a classifier is overconfident in its\nincorrect predictions. We start by dissecting miscoverage events in\nmarginally-valid conformal prediction, and show that miscoverage rates vary\nbased on the classifier's confidence and its deviation from the Bayes optimal\nclassifier. Motivated by this insight, we develop a variant of conformal\nprediction that targets coverage conditional on a reduced set of two variables:\nthe classifier's confidence in a prediction and a nonparametric trust score\nthat measures its deviation from the Bayes classifier. Empirical evaluation on\nmultiple image datasets shows that our method generally improves conditional\ncoverage properties compared to standard conformal prediction, including\nclass-conditional coverage, coverage over arbitrary subgroups, and coverage\nover demographic groups.",
      "tldr_zh": "本研究针对标准保形 prediction 的边缘覆盖保证不足问题，提出了一种改进算法，使用信任 scores 来提升条件覆盖，特别是针对分类器过度自信的错误预测实例。方法通过分析错误覆盖事件，结合分类器的自信度和一个非参数信任 score（衡量其与Bayes optimal classifier 的偏差），来优化覆盖针对性。实验在多个图像数据集上表明，该算法显著改善了条件覆盖性能，包括类条件覆盖、任意子群体覆盖和人口统计学群体覆盖。",
      "categories": [
        "cs.LG",
        "cs.AI",
        "stat.ME",
        "stat.ML"
      ],
      "primary_category": "cs.LG",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2501.10139v2",
      "published_date": "2025-01-17 12:01:56 UTC",
      "updated_date": "2025-02-09 22:05:43 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-22T00:37:42.343198"
    },
    {
      "arxiv_id": "2501.10134v1",
      "title": "Exploring the Impact of Generative Artificial Intelligence in Education: A Thematic Analysis",
      "title_zh": "探索生成式人工智能在教育中的影响：主题分析",
      "authors": [
        "Abhishek Kaushik",
        "Sargam Yadav",
        "Andrew Browne",
        "David Lillis",
        "David Williams",
        "Jack Mc Donnell",
        "Peadar Grant",
        "Siobhan Connolly Kernan",
        "Shubham Sharma",
        "Mansi Arora"
      ],
      "abstract": "The recent advancements in Generative Artificial intelligence (GenAI)\ntechnology have been transformative for the field of education. Large Language\nModels (LLMs) such as ChatGPT and Bard can be leveraged to automate boilerplate\ntasks, create content for personalised teaching, and handle repetitive tasks to\nallow more time for creative thinking. However, it is important to develop\nguidelines, policies, and assessment methods in the education sector to ensure\nthe responsible integration of these tools. In this article, thematic analysis\nhas been performed on seven essays obtained from professionals in the education\nsector to understand the advantages and pitfalls of using GenAI models such as\nChatGPT and Bard in education. Exploratory Data Analysis (EDA) has been\nperformed on the essays to extract further insights from the text. The study\nfound several themes which highlight benefits and drawbacks of GenAI tools, as\nwell as suggestions to overcome these limitations and ensure that students are\nusing these tools in a responsible and ethical manner.",
      "tldr_zh": "这篇论文探讨了 Generative Artificial Intelligence (GenAI) 在教育领域的潜在影响，通过对教育专业人士的七篇论文进行 Thematic Analysis 和 Exploratory Data Analysis (EDA)。研究发现，GenAI 工具如 ChatGPT 和 Bard 可以自动化重复任务、创建个性化教学内容，并释放时间用于创意思考，但也存在风险，如滥用和伦理问题。作者强调需要制定指导方针、政策和评估方法，以克服这些缺点，确保学生负责任地使用这些工具。",
      "categories": [
        "cs.AI",
        "cs.HC",
        "cs.LG"
      ],
      "primary_category": "cs.AI",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2501.10134v1",
      "published_date": "2025-01-17 11:49:49 UTC",
      "updated_date": "2025-01-17 11:49:49 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-22T00:37:54.146209"
    },
    {
      "arxiv_id": "2501.10129v1",
      "title": "Spatio-temporal Graph Learning on Adaptive Mined Key Frames for High-performance Multi-Object Tracking",
      "title_zh": "翻译失败",
      "authors": [
        "Futian Wang",
        "Fengxiang Liu",
        "Xiao Wang"
      ],
      "abstract": "In the realm of multi-object tracking, the challenge of accurately capturing\nthe spatial and temporal relationships between objects in video sequences\nremains a significant hurdle. This is further complicated by frequent\noccurrences of mutual occlusions among objects, which can lead to tracking\nerrors and reduced performance in existing methods. Motivated by these\nchallenges, we propose a novel adaptive key frame mining strategy that\naddresses the limitations of current tracking approaches. Specifically, we\nintroduce a Key Frame Extraction (KFE) module that leverages reinforcement\nlearning to adaptively segment videos, thereby guiding the tracker to exploit\nthe intrinsic logic of the video content. This approach allows us to capture\nstructured spatial relationships between different objects as well as the\ntemporal relationships of objects across frames. To tackle the issue of object\nocclusions, we have developed an Intra-Frame Feature Fusion (IFF) module.\nUnlike traditional graph-based methods that primarily focus on inter-frame\nfeature fusion, our IFF module uses a Graph Convolutional Network (GCN) to\nfacilitate information exchange between the target and surrounding objects\nwithin a frame. This innovation significantly enhances target\ndistinguishability and mitigates tracking loss and appearance similarity due to\nocclusions. By combining the strengths of both long and short trajectories and\nconsidering the spatial relationships between objects, our proposed tracker\nachieves impressive results on the MOT17 dataset, i.e., 68.6 HOTA, 81.0 IDF1,\n66.6 AssA, and 893 IDS, proving its effectiveness and accuracy.",
      "tldr_zh": "该论文针对多对象跟踪中的空间和时间关系捕捉难题，尤其是对象相互遮挡导致的错误，提出了一种基于自适应关键帧挖掘的框架。核心方法包括 Key Frame Extraction (KFE) 模块，利用强化学习动态分割视频以捕捉对象间的结构化空间关系和跨帧时间关系，以及 Intra-Frame Feature Fusion (IFF) 模块，通过 Graph Convolutional Network (GCN) 在帧内实现目标与周围对象的信息交换，提高目标区分度和抗遮挡能力。实验结果显示，该框架在 MOT17 数据集上取得了 68.6 HOTA、81.0 IDF1、66.6 AssA 和 893 IDS 的出色性能，显著提升了跟踪的准确性和鲁棒性。",
      "categories": [
        "cs.CV",
        "cs.AI"
      ],
      "primary_category": "cs.CV",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2501.10129v1",
      "published_date": "2025-01-17 11:36:38 UTC",
      "updated_date": "2025-01-17 11:36:38 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-22T00:38:06.746926"
    },
    {
      "arxiv_id": "2501.10114v2",
      "title": "Infrastructure for AI Agents",
      "title_zh": "翻译失败",
      "authors": [
        "Alan Chan",
        "Kevin Wei",
        "Sihao Huang",
        "Nitarshan Rajkumar",
        "Elija Perrier",
        "Seth Lazar",
        "Gillian K. Hadfield",
        "Markus Anderljung"
      ],
      "abstract": "AI agents plan and execute interactions in open-ended environments. For\nexample, OpenAI's Operator can use a web browser to do product comparisons and\nbuy online goods. To facilitate beneficial interactions and mitigate harmful\nones, much research focuses on directly modifying agent behaviour. For example,\ndevelopers can train agents to follow user instructions. This focus on direct\nmodifications is useful, but insufficient. We will also need external protocols\nand systems that shape how agents interact with institutions and other actors.\nFor instance, agents will need more efficient protocols to communicate with\neach other and form agreements. In addition, attributing an agent's actions to\na particular human or other legal entity can help to establish trust, and also\ndisincentivize misuse. Given this motivation, we propose the concept of agent\ninfrastructure: technical systems and shared protocols external to agents that\nare designed to mediate and influence their interactions with and impacts on\ntheir environments. Just as the Internet relies on protocols like HTTPS, our\nwork argues that agent infrastructure will be similarly indispensable to\necosystems of agents. We identify three functions for agent infrastructure: 1)\nattributing actions, properties, and other information to specific agents,\ntheir users, or other actors; 2) shaping agents' interactions; and 3) detecting\nand remedying harmful actions from agents. We provide an incomplete catalog of\nresearch directions for such functions. For each direction, we include analysis\nof use cases, infrastructure adoption, relationships to existing (internet)\ninfrastructure, limitations, and open questions. Making progress on agent\ninfrastructure can prepare society for the adoption of more advanced agents.",
      "tldr_zh": "该论文讨论了AI代理在开放环境中进行互动的需求，例如OpenAI的Operator使用浏览器进行产品比较和购物，但直接修改代理行为（如训练其遵循指令）不足以应对潜在风险。作者提出“agent infrastructure”的概念，即外部技术系统和共享协议，用于调解代理与环境互动的影响，包括三个关键功能：1) 将代理行动归因于特定实体；2) 塑造代理互动；3) 检测和修复有害行动。该框架类似于互联网的HTTPS协议，能为代理生态系统提供必要支持，并通过分析用例和研究方向，帮助社会准备更高级AI代理的采用。",
      "categories": [
        "cs.AI"
      ],
      "primary_category": "cs.AI",
      "comment": "Accepted to TMLR",
      "pdf_url": "http://arxiv.org/pdf/2501.10114v2",
      "published_date": "2025-01-17 10:58:12 UTC",
      "updated_date": "2025-05-16 08:02:38 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-22T00:38:17.598066"
    },
    {
      "arxiv_id": "2501.10107v1",
      "title": "BBPOS: BERT-based Part-of-Speech Tagging for Uzbek",
      "title_zh": "BBPOS：基于BERT的乌兹别克语词性标注",
      "authors": [
        "Latofat Bobojonova",
        "Arofat Akhundjanova",
        "Phil Ostheimer",
        "Sophie Fellenz"
      ],
      "abstract": "This paper advances NLP research for the low-resource Uzbek language by\nevaluating two previously untested monolingual Uzbek BERT models on the\npart-of-speech (POS) tagging task and introducing the first publicly available\nUPOS-tagged benchmark dataset for Uzbek. Our fine-tuned models achieve 91%\naverage accuracy, outperforming the baseline multi-lingual BERT as well as the\nrule-based tagger. Notably, these models capture intermediate POS changes\nthrough affixes and demonstrate context sensitivity, unlike existing rule-based\ntaggers.",
      "tldr_zh": "这篇论文针对低资源语言乌兹别克语的NLP研究，评估了两个未测试过的单语BERT模型在词性标注(POS)任务上的性能，并首次发布了公开可用的UPOS标注基准数据集。微调后的模型实现了91%的平均准确率，优于多语言BERT和基于规则的标注器。值得注意的是，这些模型能够捕捉词缀引起的中间POS变化并展示上下文敏感性，这提升了乌兹别克语处理的准确性和灵活性。",
      "categories": [
        "cs.CL",
        "cs.AI"
      ],
      "primary_category": "cs.CL",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2501.10107v1",
      "published_date": "2025-01-17 10:50:22 UTC",
      "updated_date": "2025-01-17 10:50:22 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-22T00:38:29.765809"
    },
    {
      "arxiv_id": "2501.10106v1",
      "title": "LLM Reasoner and Automated Planner: A new NPC approach",
      "title_zh": "LLM 推理器和自动规划器：一种新的 NPC 方法",
      "authors": [
        "Israel Puerta-Merino",
        "Jordi Sabater-Mir"
      ],
      "abstract": "In domains requiring intelligent agents to emulate plausible human-like\nbehaviour, such as formative simulations, traditional techniques like behaviour\ntrees encounter significant challenges. Large Language Models (LLMs), despite\nnot always yielding optimal solutions, usually offer plausible and human-like\nresponses to a given problem. In this paper, we exploit this capability and\npropose a novel architecture that integrates an LLM for decision-making with a\nclassical automated planner that can generate sound plans for that decision.\nThe combination aims to equip an agent with the ability to make decisions in\nvarious situations, even if they were not anticipated during the design phase.",
      "tldr_zh": "这篇论文针对智能代理模拟人类行为的领域（如模拟训练），提出了一个新方法来解决传统行为树技术的挑战。方法将大型语言模型(LLM)作为决策组件，与经典自动规划器结合，以生成可靠且合理的计划。这种架构使代理能够应对设计阶段未预见的情况，提供更灵活的人类-like 响应，从而提升 NPC 的适应性和智能性。",
      "categories": [
        "cs.AI"
      ],
      "primary_category": "cs.AI",
      "comment": "15 pages, 7 figures, extended version of the homonymous paper\n  submitted to the Catalan Conference on Artificial Intelligent (CCIA) 2025",
      "pdf_url": "http://arxiv.org/pdf/2501.10106v1",
      "published_date": "2025-01-17 10:47:11 UTC",
      "updated_date": "2025-01-17 10:47:11 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-22T00:38:41.645114"
    },
    {
      "arxiv_id": "2501.10105v2",
      "title": "Universal Actions for Enhanced Embodied Foundation Models",
      "title_zh": "通用",
      "authors": [
        "Jinliang Zheng",
        "Jianxiong Li",
        "Dongxiu Liu",
        "Yinan Zheng",
        "Zhihao Wang",
        "Zhonghong Ou",
        "Yu Liu",
        "Jingjing Liu",
        "Ya-Qin Zhang",
        "Xianyuan Zhan"
      ],
      "abstract": "Training on diverse, internet-scale data is a key factor in the success of\nrecent large foundation models. Yet, using the same recipe for building\nembodied agents has faced noticeable difficulties. Despite the availability of\nmany crowd-sourced embodied datasets, their action spaces often exhibit\nsignificant heterogeneity due to distinct physical embodiment and control\ninterfaces for different robots, causing substantial challenges in developing\nembodied foundation models using cross-domain data. In this paper, we introduce\nUniAct, a new embodied foundation modeling framework operating in a Universal\nAction Space. Our learned universal actions capture the generic atomic\nbehaviors across diverse robots by exploiting their shared structural features,\nand enable enhanced cross-domain data utilization and cross-embodiment\ngeneralizations by eliminating the notorious heterogeneity. The universal\nactions can be efficiently translated back to heterogeneous actionable commands\nby simply adding embodiment-specific details, from which fast adaptation to new\nrobots becomes simple and straightforward. Our 0.5B instantiation of UniAct\noutperforms 14X larger SOTA embodied foundation models in extensive evaluations\non various real-world and simulation robots, showcasing exceptional\ncross-embodiment control and adaptation capability, highlighting the crucial\nbenefit of adopting universal actions. Project page:\nhttps://github.com/2toinf/UniAct",
      "tldr_zh": "这篇论文提出 UniAct 框架，使用 Universal Action Space 来解决 embodied foundation models 在训练跨机器人代理时面临的行动空间异质性问题，通过捕捉不同机器人的共享原子行为来提升数据利用和跨机器人泛化能力。UniAct 允许高效地将通用动作转换为特定机器人的命令，实现快速适应新机器人。实验结果显示，0.5B 参数的 UniAct 模型在各种真实和模拟机器人任务上超过了 14 倍大的 SOTA 模型，展示了卓越的控制和适应性能。",
      "categories": [
        "cs.RO",
        "cs.AI",
        "cs.CV"
      ],
      "primary_category": "cs.RO",
      "comment": "CVPR 2025",
      "pdf_url": "http://arxiv.org/pdf/2501.10105v2",
      "published_date": "2025-01-17 10:45:22 UTC",
      "updated_date": "2025-03-08 13:55:48 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-22T00:38:53.817762"
    },
    {
      "arxiv_id": "2501.10100v3",
      "title": "Robotic World Model: A Neural Network Simulator for Robust Policy Optimization in Robotics",
      "title_zh": "机器人世界模型：一种用于机器人学中鲁棒策略优化的神经网络模拟器",
      "authors": [
        "Chenhao Li",
        "Andreas Krause",
        "Marco Hutter"
      ],
      "abstract": "Learning robust and generalizable world models is crucial for enabling\nefficient and scalable robotic control in real-world environments. In this\nwork, we introduce a novel framework for learning world models that accurately\ncapture complex, partially observable, and stochastic dynamics. The proposed\nmethod employs a dual-autoregressive mechanism and self-supervised training to\nachieve reliable long-horizon predictions without relying on domain-specific\ninductive biases, ensuring adaptability across diverse robotic tasks. We\nfurther propose a policy optimization framework that leverages world models for\nefficient training in imagined environments and seamless deployment in\nreal-world systems. This work advances model-based reinforcement learning by\naddressing the challenges of long-horizon prediction, error accumulation, and\nsim-to-real transfer. By providing a scalable and robust framework, the\nintroduced methods pave the way for adaptive and efficient robotic systems in\nreal-world applications.",
      "tldr_zh": "本研究引入了一个新型框架，用于学习鲁棒且可泛化的world models，以准确捕捉复杂、部分可观察和随机机器人动态。该框架采用dual-autoregressive mechanism和self-supervised training，实现可靠的长-horizon预测，而不依赖特定领域的归纳偏差，从而适用于多样化的机器人任务。同时，提出一个policy optimization框架，利用world models在想象环境中高效训练，并实现无缝的sim-to-real转移。这项工作推进了基于模型的reinforcement learning，解决了长-horizon预测、错误积累等挑战，为真实世界应用的适应性机器人系统提供了可扩展的解决方案。",
      "categories": [
        "cs.RO",
        "cs.AI",
        "cs.LG"
      ],
      "primary_category": "cs.RO",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2501.10100v3",
      "published_date": "2025-01-17 10:39:09 UTC",
      "updated_date": "2025-04-24 05:33:20 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-22T00:39:06.488265"
    },
    {
      "arxiv_id": "2501.10098v2",
      "title": "landmarker: a Toolkit for Anatomical Landmark Localization in 2D/3D Images",
      "title_zh": "翻译失败",
      "authors": [
        "Jef Jonkers",
        "Luc Duchateau",
        "Glenn Van Wallendael",
        "Sofie Van Hoecke"
      ],
      "abstract": "Anatomical landmark localization in 2D/3D images is a critical task in\nmedical imaging. Although many general-purpose tools exist for landmark\nlocalization in classical computer vision tasks, such as pose estimation, they\nlack the specialized features and modularity necessary for anatomical landmark\nlocalization applications in the medical domain. Therefore, we introduce\nlandmarker, a Python package built on PyTorch. The package provides a\ncomprehensive, flexible toolkit for developing and evaluating landmark\nlocalization algorithms, supporting a range of methodologies, including static\nand adaptive heatmap regression. landmarker enhances the accuracy of landmark\nidentification, streamlines research and development processes, and supports\nvarious image formats and preprocessing pipelines. Its modular design allows\nusers to customize and extend the toolkit for specific datasets and\napplications, accelerating innovation in medical imaging. landmarker addresses\na critical need for precision and customization in landmark localization tasks\nnot adequately met by existing general-purpose pose estimation tools.",
      "tldr_zh": "我们介绍了 landmarker，这是一个基于 PyTorch 的 Python 工具包，专为 2D/3D 医学图像中的解剖标志点定位任务设计，以弥补现有通用姿态估计工具的专业性和模块性不足。landmarker 支持多种方法，包括静态和自适应 heatmap regression，提供灵活的图像格式处理和预处理管道，并允许用户自定义扩展以适应特定数据集。实验表明，该工具包提升了标志点识别的准确性，简化了研究开发流程，并加速了医学成像领域的创新。",
      "categories": [
        "cs.CV",
        "cs.AI",
        "cs.LG"
      ],
      "primary_category": "cs.CV",
      "comment": "11 pages, 4 figures",
      "pdf_url": "http://arxiv.org/pdf/2501.10098v2",
      "published_date": "2025-01-17 10:35:58 UTC",
      "updated_date": "2025-05-05 15:41:55 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-22T00:39:18.007828"
    },
    {
      "arxiv_id": "2501.10091v2",
      "title": "How Do Programming Students Use Generative AI?",
      "title_zh": "编程学生如何使用生成式 AI？",
      "authors": [
        "Christian Rahe",
        "Walid Maalej"
      ],
      "abstract": "Programming students have a widespread access to powerful Generative AI tools\nlike ChatGPT. While this can help understand the learning material and assist\nwith exercises, educators are voicing more and more concerns about an\noverreliance on generated outputs and lack of critical thinking skills. It is\nthus important to understand how students actually use generative AI and what\nimpact this could have on their learning behavior. To this end, we conducted a\nstudy including an exploratory experiment with 37 programming students, giving\nthem monitored access to ChatGPT while solving a code authoring exercise. The\ntask was not directly solvable by ChatGPT and required code comprehension and\nreasoning. While only 23 of the students actually opted to use the chatbot, the\nmajority of those eventually prompted it to simply generate a full solution. We\nobserved two prevalent usage strategies: to seek knowledge about general\nconcepts and to directly generate solutions. Instead of using the bot to\ncomprehend the code and their own mistakes, students often got trapped in a\nvicious cycle of submitting wrong generated code and then asking the bot for a\nfix. Those who self-reported using generative AI regularly were more likely to\nprompt the bot to generate a solution. Our findings indicate that concerns\nabout potential decrease in programmers' agency and productivity with\nGenerative AI are justified. We discuss how researchers and educators can\nrespond to the potential risk of students uncritically over-relying on\nGenerative AI. We also discuss potential modifications to our study design for\nlarge-scale replications.",
      "tldr_zh": "这篇论文调查了编程学生如何使用 Generative AI（如 ChatGPT），通过一个实验让 37 名学生在解决代码编写任务时监控他们的使用行为。研究发现，学生主要采用两种策略：寻求一般概念知识或直接生成解决方案，许多人陷入错误循环，即反复提交错误的生成代码并寻求修复。结果显示，经常使用 Generative AI 的学生更倾向于过度依赖它，这可能降低他们的独立性和生产力；论文讨论了研究者和教育者如何应对这一风险，并建议改进研究设计以进行大规模复制。",
      "categories": [
        "cs.HC",
        "cs.AI",
        "cs.CY",
        "K.3.2; I.2.1; H.1.2"
      ],
      "primary_category": "cs.HC",
      "comment": "preprint; accepted to ACM International Conference on the Foundations\n  of Software Engineering (FSE) 2025",
      "pdf_url": "http://arxiv.org/pdf/2501.10091v2",
      "published_date": "2025-01-17 10:25:41 UTC",
      "updated_date": "2025-02-21 15:07:21 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-22T00:39:30.238784"
    },
    {
      "arxiv_id": "2501.10075v1",
      "title": "Robust Change Captioning in Remote Sensing: SECOND-CC Dataset and MModalCC Framework",
      "title_zh": "遥感中的鲁棒变更描述：SECOND-CC 数据集和 MModalCC 框架",
      "authors": [
        "Ali Can Karaca",
        "M. Enes Ozelbas",
        "Saadettin Berber",
        "Orkhan Karimli",
        "Turabi Yildirim",
        "M. Fatih Amasyali"
      ],
      "abstract": "Remote sensing change captioning (RSICC) aims to describe changes between\nbitemporal images in natural language. Existing methods often fail under\nchallenges like illumination differences, viewpoint changes, blur effects,\nleading to inaccuracies, especially in no-change regions. Moreover, the images\nacquired at different spatial resolutions and have registration errors tend to\naffect the captions. To address these issues, we introduce SECOND-CC, a novel\nRSICC dataset featuring high-resolution RGB image pairs, semantic segmentation\nmaps, and diverse real-world scenarios. SECOND-CC which contains 6,041 pairs of\nbitemporal RS images and 30,205 sentences describing the differences between\nimages. Additionally, we propose MModalCC, a multimodal framework that\nintegrates semantic and visual data using advanced attention mechanisms,\nincluding Cross-Modal Cross Attention (CMCA) and Multimodal Gated Cross\nAttention (MGCA). Detailed ablation studies and attention visualizations\nfurther demonstrate its effectiveness and ability to address RSICC challenges.\nComprehensive experiments show that MModalCC outperforms state-of-the-art RSICC\nmethods, including RSICCformer, Chg2Cap, and PSNet with +4.6% improvement on\nBLEU4 score and +9.6% improvement on CIDEr score. We will make our dataset and\ncodebase publicly available to facilitate future research at\nhttps://github.com/ChangeCapsInRS/SecondCC",
      "tldr_zh": "本研究针对遥感图像变化描述(RSICC)面临的挑战，如光照差异、视角变化和图像注册错误，引入了SECOND-CC数据集，该数据集包含6,041对高分辨率双时相RGB图像、语义分割地图和30,205句描述差异的句子，覆盖真实场景。\n为了提升鲁棒性，提出MModalCC框架，该框架整合语义和视觉数据，通过Cross-Modal Cross Attention(CMCA)和Multimodal Gated Cross Attention(MGCA)机制，实现更准确的图像变化描述。\n实验结果显示，MModalCC在BLEU4得分上比现有方法如RSICCformer等提高了4.6%，CIDEr得分提高了9.6%，并通过消融研究和注意力可视化验证了其有效性。",
      "categories": [
        "cs.CV",
        "cs.AI",
        "cs.LG",
        "cs.MM"
      ],
      "primary_category": "cs.CV",
      "comment": "This work has been submitted to the IEEE Transactions on Geoscience\n  and Remote Sensing journal for possible publication",
      "pdf_url": "http://arxiv.org/pdf/2501.10075v1",
      "published_date": "2025-01-17 09:47:27 UTC",
      "updated_date": "2025-01-17 09:47:27 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-22T00:39:43.229389"
    },
    {
      "arxiv_id": "2501.10074v3",
      "title": "SpatialCoT: Advancing Spatial Reasoning through Coordinate Alignment and Chain-of-Thought for Embodied Task Planning",
      "title_zh": "翻译失败",
      "authors": [
        "Yuecheng Liu",
        "Dafeng Chi",
        "Shiguang Wu",
        "Zhanguang Zhang",
        "Yaochen Hu",
        "Lingfeng Zhang",
        "Yingxue Zhang",
        "Shuang Wu",
        "Tongtong Cao",
        "Guowei Huang",
        "Helong Huang",
        "Guangjian Tian",
        "Weichao Qiu",
        "Xingyue Quan",
        "Jianye Hao",
        "Yuzheng Zhuang"
      ],
      "abstract": "Spatial reasoning is an essential problem in embodied AI research. Efforts to\nenhance spatial reasoning abilities through supplementary spatial data and\nfine-tuning have proven limited and ineffective when addressing complex\nembodied tasks, largely due to their dependence on language-based outputs.\nWhile some approaches have introduced a point-based action space to mitigate\nthis issue, they fall short in managing more intricate tasks within complex\nenvironments. This deficiency arises from their failure to fully exploit the\ninherent thinking and reasoning capabilities that are fundamental strengths of\nVision-Language Models (VLMs). To address these limitations, we propose a novel\napproach named SpatialCoT, specifically designed to bolster the spatial\nreasoning capabilities of VLMs. Our approach comprises two stages: spatial\ncoordinate bi-directional alignment, which aligns vision-language inputs with\nspatial coordinates, and chain-of-thought spatial grounding, which harnesses\nthe reasoning capabilities of language models for advanced spatial reasoning.\nWe evaluate SpatialCoT on challenging navigation and manipulation tasks, both\nin simulation and real-world settings. Experimental results demonstrate that\nour method significantly outperforms previous state-of-the-art approaches in\nboth tasks.",
      "tldr_zh": "本文提出 SpatialCoT 方法，以提升 Vision-Language Models (VLMs) 在 embodied 任务中的空间推理能力，解决现有方法依赖语言输出和处理复杂环境不足的问题。该方法包括两个关键阶段：spatial coordinate bi-directional alignment，用于将视觉-语言输入与空间坐标对齐；以及 chain-of-thought spatial grounding，利用语言模型的推理能力进行高级空间推理。在模拟和真实世界的导航及操作任务上，实验结果显示 SpatialCoT 显著优于现有最先进方法。",
      "categories": [
        "cs.RO",
        "cs.AI",
        "cs.CV"
      ],
      "primary_category": "cs.RO",
      "comment": "Under Review",
      "pdf_url": "http://arxiv.org/pdf/2501.10074v3",
      "published_date": "2025-01-17 09:46:27 UTC",
      "updated_date": "2025-01-23 02:31:25 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-22T00:39:54.774374"
    },
    {
      "arxiv_id": "2501.10069v4",
      "title": "A Survey on LLM Test-Time Compute via Search: Tasks, LLM Profiling, Search Algorithms, and Relevant Frameworks",
      "title_zh": "翻译失败",
      "authors": [
        "Xinzhe Li"
      ],
      "abstract": "LLM test-time compute (or LLM inference) via search has emerged as a\npromising research area with rapid developments. However, current frameworks\noften adopt distinct perspectives on three key aspects: task definition, LLM\nprofiling, and search procedures, making direct comparisons challenging.\nMoreover, the search algorithms employed often diverge from standard\nimplementations, and their specific characteristics are not thoroughly\nspecified. This survey aims to provide a comprehensive but integrated technical\nreview on existing LIS frameworks. Specifically, we unify task definitions\nunder Markov Decision Process (MDP) and provides modular definitions of LLM\nprofiling and search procedures. The definitions enable precise comparisons of\nvarious LLM inference frameworks while highlighting their departures from\nconventional search algorithms. We also discuss the applicability, performance,\nand efficiency of these methods. For ongoing paper updates, please refer to our\nGitHub repository: https://github.com/xinzhel/LLM-Search.",
      "tldr_zh": "这篇调查论文探讨了通过搜索进行的LLM测试时计算（LLM Test-Time Compute）的最新发展，包括任务定义、LLM分析、搜索算法以及相关框架。论文统一任务定义为Markov Decision Process (MDP)，并模块化定义LLM分析和搜索过程，以便精确比较不同框架，并突出它们与传统搜索算法的差异。该方法还评估了这些框架的适用性、性能和效率，为LLM推理研究提供了一个综合的技术回顾；相关更新可参考论文的GitHub仓库。",
      "categories": [
        "cs.AI"
      ],
      "primary_category": "cs.AI",
      "comment": "TMLR (camera-ready). Details on\n  https://openreview.net/forum?id=x9VQFjtOPS",
      "pdf_url": "http://arxiv.org/pdf/2501.10069v4",
      "published_date": "2025-01-17 09:42:48 UTC",
      "updated_date": "2025-04-27 08:55:07 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-22T00:40:06.300480"
    },
    {
      "arxiv_id": "2501.10054v1",
      "title": "Accelerating Large Language Models through Partially Linear Feed-Forward Network",
      "title_zh": "翻译失败",
      "authors": [
        "Gansen Hu",
        "Zhaoguo Wang",
        "Jinglin Wei",
        "Wei Huang",
        "Haibo Chen"
      ],
      "abstract": "Large language models (LLMs) demonstrate remarkable capabilities but face\ndeployment challenges due to their massive parameter counts. While existing\ncompression techniques like pruning can reduce model size, it leads to\nsignificant accuracy degradation under high compression ratios. We present a\nnovel perspective inspired by constant folding in compiler optimization. Our\napproach enables parameter reduction by treating activation functions in LLMs\nas linear functions.\n  However, recent LLMs use complex non-linear activations like GELU that\nprevent direct application of this technique. We propose TARDIS, which enables\noptimization of LLMs with non-linear activations by partially approximating\nthem with linear functions in frequently occurring input ranges. For outlier\ninputs, TARDIS employs an online predictor to dynamically fall back to original\ncomputations.\n  Our experiments demonstrate that TARDIS achieves 80% parameter reduction in\nfeed-forward networks, while significantly outperforming state-of-the-art\npruning methods Wanda and RIA with up to 65% higher accuracy. In practical\ndeployments for a 7B model, TARDIS achieves 1.6x end-to-end inference speedup\nwhen integrated with the vLLM serving system, and 1.4x speedup with the widely\nadopted HuggingFace implementation, while incurring only a 10.9% accuracy\ntrade-off.",
      "tldr_zh": "这篇论文提出 TARDIS 方法，通过部分线性化激活函数来加速 Large Language Models (LLMs)，以解决模型参数过多导致的部署挑战。TARDIS 在常见输入范围内将非线性激活函数如 GELU 近似为线性函数，对于异常输入则使用在线预测器动态回退到原始计算，从而实现前馈网络参数减少 80%。实验结果显示，TARDIS 比现有剪枝方法（如 Wanda 和 RIA）准确率高出 65%，并在 7B 模型的实际部署中实现 1.6x (vLLM 系统) 和 1.4x (HuggingFace) 的推理加速，同时仅损失 10.9% 准确率。",
      "categories": [
        "cs.LG",
        "cs.AI",
        "D.4; I.2; D.3.4"
      ],
      "primary_category": "cs.LG",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2501.10054v1",
      "published_date": "2025-01-17 09:20:56 UTC",
      "updated_date": "2025-01-17 09:20:56 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-22T00:40:19.226936"
    },
    {
      "arxiv_id": "2501.10053v2",
      "title": "AirRAG: Activating Intrinsic Reasoning for Retrieval Augmented Generation using Tree-based Search",
      "title_zh": "翻译失败",
      "authors": [
        "Wenfeng Feng",
        "Chuzhan Hao",
        "Yuewei Zhang",
        "Jingyi Song",
        "Hao Wang"
      ],
      "abstract": "Leveraging the autonomous decision-making capabilities of large language\nmodels (LLMs) has demonstrated superior performance in reasoning tasks.\nHowever, despite the success of iterative or recursive retrieval-augmented\ngeneration (RAG) techniques, these methods are often constrained to a single\nsolution space when confronted with complex problems. In this paper, we propose\na novel thinking pattern in RAG that integrates system analysis with efficient\nreasoning actions, significantly activating intrinsic reasoning capabilities\nand expanding the solution space of specific tasks via Monte Carlo Tree Search\n(MCTS), which we refer to as AirRAG. Specifically, our approach designs five\nfundamental reasoning actions, which are expanded to a broad tree-based\nreasoning space using MCTS. The approach also incorporates self-consistency\nverification to explore potential reasoning paths and inference scaling law.\nAdditionally, computationally optimal strategies are employed to allocate more\ninference resources to key actions, thereby enhancing overall performance.\nExperimental results demonstrate the effectiveness of AirRAG, showing\nsignificant performance gains on complex question-answering datasets.\nFurthermore, AirRAG is flexible and lightweight, making it easy to integrate\nwith other advanced technologies.",
      "tldr_zh": "该论文提出 AirRAG，一种新型检索增强生成(RAG)框架，利用 Monte Carlo Tree Search (MCTS)激活大型语言模型(LLMs)的内在推理能力，并通过树状搜索扩展解决方案空间。AirRAG 设计了五种基本推理动作，结合自一致性验证(self-consistency verification)和计算最优资源分配策略，以高效探索推理路径和提升性能。实验结果表明，该方法在复杂问答数据集上显著提升表现，且其灵活轻量级的特性便于与其他先进技术整合。",
      "categories": [
        "cs.AI"
      ],
      "primary_category": "cs.AI",
      "comment": "17 pages, 14 figures",
      "pdf_url": "http://arxiv.org/pdf/2501.10053v2",
      "published_date": "2025-01-17 09:16:13 UTC",
      "updated_date": "2025-02-14 15:20:47 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-22T00:40:30.686292"
    },
    {
      "arxiv_id": "2501.10048v1",
      "title": "Virtual Nodes Improve Long-term Traffic Prediction",
      "title_zh": "翻译失败",
      "authors": [
        "Xiaoyang Cao",
        "Dingyi Zhuang",
        "Jinhua Zhao",
        "Shenhao Wang"
      ],
      "abstract": "Effective traffic prediction is a cornerstone of intelligent transportation\nsystems, enabling precise forecasts of traffic flow, speed, and congestion.\nWhile traditional spatio-temporal graph neural networks (ST-GNNs) have achieved\nnotable success in short-term traffic forecasting, their performance in\nlong-term predictions remains limited. This challenge arises from\nover-squashing problem, where bottlenecks and limited receptive fields restrict\ninformation flow and hinder the modeling of global dependencies. To address\nthese challenges, this study introduces a novel framework that incorporates\nvirtual nodes, which are additional nodes added to the graph and connected to\nexisting nodes, in order to aggregate information across the entire graph\nwithin a single GNN layer. Our proposed model incorporates virtual nodes by\nconstructing a semi-adaptive adjacency matrix. This matrix integrates\ndistance-based and adaptive adjacency matrices, allowing the model to leverage\ngeographical information while also learning task-specific features from data.\nExperimental results demonstrate that the inclusion of virtual nodes\nsignificantly enhances long-term prediction accuracy while also improving\nlayer-wise sensitivity to mitigate the over-squashing problem. Virtual nodes\nalso offer enhanced explainability by focusing on key intersections and\nhigh-traffic areas, as shown by the visualization of their adjacency matrix\nweights on road network heat maps. Our advanced approach enhances the\nunderstanding and management of urban traffic systems, making it particularly\nwell-suited for real-world applications.",
      "tldr_zh": "本研究针对传统时空图神经网络(ST-GNNs)在长期交通预测中存在的over-squashing问题（如信息瓶颈和有限接收域），提出了一种新框架，通过添加virtual nodes到图中来聚合整个图的信息。模型构建semi-adaptive adjacency matrix，结合distance-based和adaptive矩阵，利用地理数据和任务特定特征进行优化。实验结果显示，该方法显著提高了长期预测准确性，并缓解了over-squashing问题，同时提升了模型的可解释性，如通过可视化关注关键交叉口和高流量区域。该框架增强了城市交通系统的理解和管理，适用于实际应用场景。",
      "categories": [
        "cs.LG",
        "cs.AI"
      ],
      "primary_category": "cs.LG",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2501.10048v1",
      "published_date": "2025-01-17 09:09:01 UTC",
      "updated_date": "2025-01-17 09:09:01 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-22T00:40:42.808946"
    },
    {
      "arxiv_id": "2501.10041v1",
      "title": "Spatiotemporal Prediction of Secondary Crashes by Rebalancing Dynamic and Static Data with Generative Adversarial Networks",
      "title_zh": "翻译失败",
      "authors": [
        "Junlan Chen",
        "Yiqun Li",
        "Chenyu Ling",
        "Ziyuan Pu",
        "Xiucheng Guo"
      ],
      "abstract": "Data imbalance is a common issue in analyzing and predicting sudden traffic\nevents. Secondary crashes constitute only a small proportion of all crashes.\nThese secondary crashes, triggered by primary crashes, significantly exacerbate\ntraffic congestion and increase the severity of incidents. However, the severe\nimbalance of secondary crash data poses significant challenges for prediction\nmodels, affecting their generalization ability and prediction accuracy.\nExisting methods fail to fully address the complexity of traffic crash data,\nparticularly the coexistence of dynamic and static features, and often struggle\nto effectively handle data samples of varying lengths. Furthermore, most\ncurrent studies predict the occurrence probability and spatiotemporal\ndistribution of secondary crashes separately, lacking an integrated solution.\nTo address these challenges, this study proposes a hybrid model named\nVarFusiGAN-Transformer, aimed at improving the fidelity of secondary crash data\ngeneration and jointly predicting the occurrence and spatiotemporal\ndistribution of secondary crashes. The VarFusiGAN-Transformer model employs\nLong Short-Term Memory (LSTM) networks to enhance the generation of\nmultivariate long-time series data, incorporating a static data generator and\nan auxiliary discriminator to model the joint distribution of dynamic and\nstatic features. In addition, the model's prediction module achieves\nsimultaneous prediction of both the occurrence and spatiotemporal distribution\nof secondary crashes. Compared to existing methods, the proposed model\ndemonstrates superior performance in generating high-fidelity data and\nimproving prediction accuracy.",
      "tldr_zh": "该研究针对次生交通事故（secondary crashes）数据的不平衡问题，提出了一种混合模型VarFusiGAN-Transformer，以生成高保真数据并联合预测事故的发生概率和时空分布。该模型利用Long Short-Term Memory (LSTM)网络生成多变量长时序数据，并结合静态数据生成器和辅助鉴别器来处理动态和静态特征的联合分布。与现有方法相比，该模型在数据生成和预测准确性上表现出显著优势，解决了传统方法对不同长度数据样本的处理难题。实验结果表明，该方法有效提升了预测性能，为交通事件管理提供了集成解决方案。",
      "categories": [
        "cs.AI"
      ],
      "primary_category": "cs.AI",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2501.10041v1",
      "published_date": "2025-01-17 08:56:49 UTC",
      "updated_date": "2025-01-17 08:56:49 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-22T00:40:54.071262"
    },
    {
      "arxiv_id": "2501.10487v2",
      "title": "Theme-Explanation Structure for Table Summarization using Large Language Models: A Case Study on Korean Tabular Data",
      "title_zh": "翻译失败",
      "authors": [
        "TaeYoon Kwack",
        "Jisoo Kim",
        "Ki Yong Jung",
        "DongGeon Lee",
        "Heesun Park"
      ],
      "abstract": "This paper proposes the Theme-Explanation Structure-based Table Summarization\n(Tabular-TX) pipeline designed to process tabular data efficiently. Tabular-TX\npreprocesses tabular data by focusing on highlighted cells. It then generates\nsummary sentences following a structured format, where the Theme Part appears\nas an adverbial phrase, and the Explanation Part follows as a predictive\nclause. This approach enables tailored analysis by considering the structural\ncharacteristics of tables and their comparability. Unlike conventional\nfine-tuning approaches that require extensive labeled data and computational\nresources, our method leverages In-Context Learning to dynamically adapt to\ndifferent table structures without additional training, ensuring efficient and\nscalable table interpretation. Experimental results demonstrate that Tabular-TX\nsignificantly outperforms conventional fine-tuning-based methods, particularly\nin low-resource scenarios, by leveraging table structures and metadata more\neffectively through structured prompts. The results confirm that Tabular-TX\nenables more effective processing of complex tabular data. Furthermore, it\nserves as a viable alternative for table-based question answering and\nsummarization tasks in resource-constrained environments.",
      "tldr_zh": "本文提出了一种基于 Theme-Explanation Structure 的表格总结管道 Tabular-TX，利用 Large Language Models 处理韩国表格数据，通过关注突出单元格并生成结构化总结句子（Theme Part 作为状语短语，Explanation Part 作为预测从句），实现了高效的表格分析。不同于传统微调方法，该管道采用 In-Context Learning 动态适应不同表格结构，无需大量标注数据和额外训练，从而更具可扩展性和资源效率。实验结果显示，Tabular-TX 在低资源场景下显著优于基线方法，提升了表格结构的利用和总结性能。该方法还适用于表格问答和总结任务，提供了一种可靠的替代方案。",
      "categories": [
        "cs.CL",
        "cs.AI"
      ],
      "primary_category": "cs.CL",
      "comment": "6 pages",
      "pdf_url": "http://arxiv.org/pdf/2501.10487v2",
      "published_date": "2025-01-17 08:42:49 UTC",
      "updated_date": "2025-02-26 07:10:17 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-22T00:41:06.958790"
    },
    {
      "arxiv_id": "2501.10024v1",
      "title": "Automatic Speech Recognition for Sanskrit with Transfer Learning",
      "title_zh": "翻译失败",
      "authors": [
        "Bidit Sadhukhan",
        "Swami Punyeshwarananda"
      ],
      "abstract": "Sanskrit, one of humanity's most ancient languages, has a vast collection of\nbooks and manuscripts on diverse topics that have been accumulated over\nmillennia. However, its digital content (audio and text), which is vital for\nthe training of AI systems, is profoundly limited. Furthermore, its intricate\nlinguistics make it hard to develop robust NLP tools for wider accessibility.\nGiven these constraints, we have developed an automatic speech recognition\nmodel for Sanskrit by employing transfer learning mechanism on OpenAI's Whisper\nmodel. After carefully optimising the hyper-parameters, we obtained promising\nresults with our transfer-learned model achieving a word error rate of 15.42%\non Vaksancayah dataset. An online demo of our model is made available for the\nuse of public and to evaluate its performance firsthand thereby paving the way\nfor improved accessibility and technological support for Sanskrit learning in\nthe modern era.",
      "tldr_zh": "该研究针对梵语(Sanskrit)数字资源有限和语言复杂性问题，开发了一个基于转移学习(Transfer Learning)的自动语音识别(ASR)模型，使用 OpenAI's Whisper 模型作为基础，并通过优化超参数进行改进。在 Vaksancayah 数据集上，该模型取得了 15.42% 的词错误率(Word Error Rate)，展现出良好的性能。该模型还提供了在线演示，以增强梵语学习的公共可访问性和技术支持。",
      "categories": [
        "cs.CL",
        "cs.AI"
      ],
      "primary_category": "cs.CL",
      "comment": "Paper has been accepted at the 4th International Conference on\n  Computer, Communication, Control & Information Technology (C3IT), Hooghly,\n  India, 2024, pp. 1-5",
      "pdf_url": "http://arxiv.org/pdf/2501.10024v1",
      "published_date": "2025-01-17 08:20:32 UTC",
      "updated_date": "2025-01-17 08:20:32 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-22T00:41:17.976921"
    },
    {
      "arxiv_id": "2501.10017v1",
      "title": "Enhancing Crash Frequency Modeling Based on Augmented Multi-Type Data by Hybrid VAE-Diffusion-Based Generative Neural Networks",
      "title_zh": "翻译失败",
      "authors": [
        "Junlan Chen",
        "Qijie He",
        "Pei Liu",
        "Wei Ma",
        "Ziyuan Pu"
      ],
      "abstract": "Crash frequency modelling analyzes the impact of factors like traffic volume,\nroad geometry, and environmental conditions on crash occurrences. Inaccurate\npredictions can distort our understanding of these factors, leading to\nmisguided policies and wasted resources, which jeopardize traffic safety. A key\nchallenge in crash frequency modelling is the prevalence of excessive zero\nobservations, caused by underreporting, the low probability of crashes, and\nhigh data collection costs. These zero observations often reduce model accuracy\nand introduce bias, complicating safety decision making. While existing\napproaches, such as statistical methods, data aggregation, and resampling,\nattempt to address this issue, they either rely on restrictive assumptions or\nresult in significant information loss, distorting crash data. To overcome\nthese limitations, we propose a hybrid VAE-Diffusion neural network, designed\nto reduce zero observations and handle the complexities of multi-type tabular\ncrash data (count, ordinal, nominal, and real-valued variables). We assess the\nsynthetic data quality generated by this model through metrics like similarity,\naccuracy, diversity, and structural consistency, and compare its predictive\nperformance against traditional statistical models. Our findings demonstrate\nthat the hybrid VAE-Diffusion model outperforms baseline models across all\nmetrics, offering a more effective approach to augmenting crash data and\nimproving the accuracy of crash frequency predictions. This study highlights\nthe potential of synthetic data to enhance traffic safety by improving crash\nfrequency modelling and informing better policy decisions.",
      "tldr_zh": "本研究针对交通事故频率建模中的零观测过多问题（如低报告率和高数据采集成本），提出了一种混合 VAE-Diffusion 神经网络，用于生成合成数据以增强多类型表格数据（包括计数、序数、名义和实值变量）。该模型通过减少零观测并处理数据复杂性，提高了模型的准确性和可靠性。实验结果显示，该方法在相似性、准确性、多样性和结构一致性等指标上优于传统统计模型，从而提升了事故频率预测的精确性，并为交通安全政策决策提供更可靠的依据。",
      "categories": [
        "cs.AI",
        "cs.DB"
      ],
      "primary_category": "cs.AI",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2501.10017v1",
      "published_date": "2025-01-17 07:53:27 UTC",
      "updated_date": "2025-01-17 07:53:27 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-22T00:41:29.966233"
    },
    {
      "arxiv_id": "2501.10011v1",
      "title": "Mitigating Hallucinations on Object Attributes using Multiview Images and Negative Instructions",
      "title_zh": "翻译失败",
      "authors": [
        "Zhijie Tan",
        "Yuzhi Li",
        "Shengwei Meng",
        "Xiang Yuan",
        "Weiping Li",
        "Tong Mo",
        "Bingce Wang",
        "Xu Chu"
      ],
      "abstract": "Current popular Large Vision-Language Models (LVLMs) are suffering from\nHallucinations on Object Attributes (HoOA), leading to incorrect determination\nof fine-grained attributes in the input images. Leveraging significant\nadvancements in 3D generation from a single image, this paper proposes a novel\nmethod to mitigate HoOA in LVLMs. This method utilizes multiview images sampled\nfrom generated 3D representations as visual prompts for LVLMs, thereby\nproviding more visual information from other viewpoints. Furthermore, we\nobserve the input order of multiple multiview images significantly affects the\nperformance of LVLMs. Consequently, we have devised Multiview Image Augmented\nVLM (MIAVLM), incorporating a Multiview Attributes Perceiver (MAP) submodule\ncapable of simultaneously eliminating the influence of input image order and\naligning visual information from multiview images with Large Language Models\n(LLMs). Besides, we designed and employed negative instructions to mitigate\nLVLMs' bias towards ``Yes\" responses. Comprehensive experiments demonstrate the\neffectiveness of our method.",
      "tldr_zh": "当前的大型视觉语言模型 (LVLMs) 存在 Hallucinations on Object Attributes (HoOA) 问题，导致图像细粒度属性判断错误。论文提出一种新方法，利用从单张图像生成的3D表示采样出的多视图图像作为视觉提示，提供更多视角的信息，以缓解 HoOA。针对多视图图像输入顺序的影响，该方法设计了 Multiview Image Augmented VLM (MIAVLM)，包括 Multiview Attributes Perceiver (MAP) 子模块，用于消除顺序干扰并对齐视觉信息与 Large Language Models (LLMs)。此外，通过 negative instructions 减少 LVLMs 对“Yes”响应的偏见，综合实验证明了该方法的有效性。",
      "categories": [
        "cs.CV",
        "cs.AI"
      ],
      "primary_category": "cs.CV",
      "comment": "2025 IEEE International Conference on Acoustics, Speech, and Signal\n  Processing (ICASSP 2025)",
      "pdf_url": "http://arxiv.org/pdf/2501.10011v1",
      "published_date": "2025-01-17 07:48:37 UTC",
      "updated_date": "2025-01-17 07:48:37 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-22T00:41:44.206544"
    },
    {
      "arxiv_id": "2501.10010v1",
      "title": "Adaptive Spatiotemporal Augmentation for Improving Dynamic Graph Learning",
      "title_zh": "自适应时空增强用于改进动态图学习",
      "authors": [
        "Xu Chu",
        "Hanlin Xue",
        "Bingce Wang",
        "Xiaoyang Liu",
        "Weiping Li",
        "Tong Mo",
        "Tuoyu Feng",
        "Zhijie Tan"
      ],
      "abstract": "Dynamic graph augmentation is used to improve the performance of dynamic\nGNNs. Most methods assume temporal locality, meaning that recent edges are more\ninfluential than earlier edges. However, for temporal changes in edges caused\nby random noise, overemphasizing recent edges while neglecting earlier ones may\nlead to the model capturing noise. To address this issue, we propose STAA\n(SpatioTemporal Activity-Aware Random Walk Diffusion). STAA identifies nodes\nlikely to have noisy edges in spatiotemporal dimensions. Spatially, it analyzes\ncritical topological positions through graph wavelet coefficients. Temporally,\nit analyzes edge evolution through graph wavelet coefficient change rates.\nThen, random walks are used to reduce the weights of noisy edges, deriving a\ndiffusion matrix containing spatiotemporal information as an augmented\nadjacency matrix for dynamic GNN learning. Experiments on multiple datasets\nshow that STAA outperforms other dynamic graph augmentation methods in node\nclassification and link prediction tasks.",
      "tldr_zh": "本研究针对动态图增强(dynamic graph augmentation)中过度强调时间局部性(temporal locality)可能导致模型捕捉噪声的问题，提出了一种自适应时空增强方法STAA(SpatioTemporal Activity-Aware Random Walk Diffusion)。STAA通过分析图小波系数(graph wavelet coefficients)在空间维度上的关键拓扑位置以及在时间维度上的边演化变化率，识别潜在噪声边，并利用随机游走(random walks)减少这些边的权重，生成包含时空信息的扩散矩阵作为增强的邻接矩阵，用于动态GNNs(Dynamic Graph Neural Networks)学习。实验结果显示，STAA在多个数据集上显著优于其他方法，在节点分类(node classification)和链接预测(link prediction)任务中提升了模型性能。",
      "categories": [
        "cs.LG",
        "cs.AI"
      ],
      "primary_category": "cs.LG",
      "comment": "2025 IEEE International Conference on Acoustics, Speech, and Signal\n  Processing (ICASSP 2025)",
      "pdf_url": "http://arxiv.org/pdf/2501.10010v1",
      "published_date": "2025-01-17 07:48:18 UTC",
      "updated_date": "2025-01-17 07:48:18 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-22T00:41:54.759053"
    },
    {
      "arxiv_id": "2501.09999v1",
      "title": "Deep Learning for Early Alzheimer Disease Detection with MRI Scans",
      "title_zh": "翻译失败",
      "authors": [
        "Mohammad Rafsan",
        "Tamer Oraby",
        "Upal Roy",
        "Sanjeev Kumar",
        "Hansapani Rodrigo"
      ],
      "abstract": "Alzheimer's Disease is a neurodegenerative condition characterized by\ndementia and impairment in neurological function. The study primarily focuses\non the individuals above age 40, affecting their memory, behavior, and\ncognitive processes of the brain. Alzheimer's disease requires diagnosis by a\ndetailed assessment of MRI scans and neuropsychological tests of the patients.\nThis project compares existing deep learning models in the pursuit of enhancing\nthe accuracy and efficiency of AD diagnosis, specifically focusing on the\nConvolutional Neural Network, Bayesian Convolutional Neural Network, and the\nU-net model with the Open Access Series of Imaging Studies brain MRI dataset.\nBesides, to ensure robustness and reliability in the model evaluations, we\naddress the challenge of imbalance in data. We then perform rigorous evaluation\nto determine strengths and weaknesses for each model by considering\nsensitivity, specificity, and computational efficiency. This comparative\nanalysis would shed light on the future role of AI in revolutionizing AD\ndiagnostics but also paved ways for future innovation in medical imaging and\nthe management of neurodegenerative diseases.",
      "tldr_zh": "本研究针对阿尔茨海默病（Alzheimer's Disease）的早期检测，使用MRI扫描和深度学习模型，专注于40岁以上人群的记忆、行为和认知功能评估。研究比较了Convolutional Neural Network、Bayesian Convolutional Neural Network和U-net模型，基于Open Access Series of Imaging Studies (OASIS)数据集，并通过处理数据不平衡问题来评估模型的敏感性、特异性和计算效率。结果显示，这些模型显著提升了AD诊断的准确性和效率，为AI在医疗成像和神经退行性疾病管理中的未来创新提供了重要启示。",
      "categories": [
        "cs.CV",
        "cs.AI",
        "eess.IV"
      ],
      "primary_category": "cs.CV",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2501.09999v1",
      "published_date": "2025-01-17 07:30:16 UTC",
      "updated_date": "2025-01-17 07:30:16 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-22T00:42:06.489717"
    },
    {
      "arxiv_id": "2501.09997v2",
      "title": "Attention-guided Self-reflection for Zero-shot Hallucination Detection in Large Language Models",
      "title_zh": "翻译失败",
      "authors": [
        "Qiang Liu",
        "Xinlong Chen",
        "Yue Ding",
        "Shizhen Xu",
        "Shu Wu",
        "Liang Wang"
      ],
      "abstract": "Hallucination has emerged as a significant barrier to the effective\napplication of Large Language Models (LLMs). In this work, we introduce a novel\nAttention-Guided SElf-Reflection (AGSER) approach for zero-shot hallucination\ndetection in LLMs. The AGSER method utilizes attention contributions to\ncategorize the input query into attentive and non-attentive queries. Each query\nis then processed separately through the LLMs, allowing us to compute\nconsistency scores between the generated responses and the original answer. The\ndifference between the two consistency scores serves as a hallucination\nestimator. In addition to its efficacy in detecting hallucinations, AGSER\nnotably reduces computational overhead, requiring only three passes through the\nLLM and utilizing two sets of tokens. We have conducted extensive experiments\nwith four widely-used LLMs across three different hallucination benchmarks,\ndemonstrating that our approach significantly outperforms existing methods in\nzero-shot hallucination detection.",
      "tldr_zh": "本文提出了一种Attention-Guided SElf-Reflection (AGSER)方法，用于Large Language Models (LLMs)中的zero-shot hallucination检测，通过利用注意力贡献将输入查询分类为关注和非关注类型，并计算响应一致性分数的差异作为幻觉估计器。该方法仅需通过LLMs的三次传递和两组tokens，即可显著降低计算开销。实验在四个流行LLMs和三个hallucination基准上进行，结果显示AGSER在zero-shot检测性能上明显优于现有方法。",
      "categories": [
        "cs.CL",
        "cs.AI"
      ],
      "primary_category": "cs.CL",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2501.09997v2",
      "published_date": "2025-01-17 07:30:01 UTC",
      "updated_date": "2025-02-12 06:15:17 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-22T00:42:18.221984"
    },
    {
      "arxiv_id": "2501.09996v1",
      "title": "Fast energy-aware OLSR routing in VANETs by means of a parallel evolutionary algorithm",
      "title_zh": "翻译失败",
      "authors": [
        "Jamal Toutouh",
        "Sergio Nesmachnow",
        "Enrique Alba"
      ],
      "abstract": "This work tackles the problem of reducing the power consumption of the OLSR\nrouting protocol in vehicular networks. Nowadays, energy-aware and green\ncommunication protocols are important research topics, specially when deploying\nwireless mobile networks. This article introduces a fast automatic methodology\nto search for energy-efficient OLSR configurations by using a parallel\nevolutionary algorithm. The experimental analysis demonstrates that significant\nimprovements over the standard configuration can be attained in terms of power\nconsumption, with no noteworthy loss in the QoS.",
      "tldr_zh": "这篇论文针对车载网络(VANETs)中OLSR路由协议的能耗问题，提出了一种快速自动方法，利用并行进化算法搜索能量高效的配置，以实现绿色通信。\n实验分析显示，与标准OLSR配置相比，该方法显著降低了功耗，同时保持了QoS（服务质量）水平无显著损失。\n这项研究强调了能量感知协议在无线移动网络中的重要性，为优化路由协议提供了实用途径。",
      "categories": [
        "cs.NE",
        "cs.AI",
        "cs.NI"
      ],
      "primary_category": "cs.NE",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2501.09996v1",
      "published_date": "2025-01-17 07:26:28 UTC",
      "updated_date": "2025-01-17 07:26:28 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-22T00:42:29.789069"
    },
    {
      "arxiv_id": "2501.09994v1",
      "title": "Multi-Modal Attention Networks for Enhanced Segmentation and Depth Estimation of Subsurface Defects in Pulse Thermography",
      "title_zh": "多模态注意力网络用于增强脉冲热像术中地下缺陷的分割和深度估计",
      "authors": [
        "Mohammed Salah",
        "Naoufel Werghi",
        "Davor Svetinovic",
        "Yusra Abdulrahman"
      ],
      "abstract": "AI-driven pulse thermography (PT) has become a crucial tool in\nnon-destructive testing (NDT), enabling automatic detection of hidden anomalies\nin various industrial components. Current state-of-the-art techniques feed\nsegmentation and depth estimation networks compressed PT sequences using either\nPrincipal Component Analysis (PCA) or Thermographic Signal Reconstruction\n(TSR). However, treating these two modalities independently constrains the\nperformance of PT inspection models as these representations possess\ncomplementary semantic features. To address this limitation, this work proposes\nPT-Fusion, a multi-modal attention-based fusion network that fuses both PCA and\nTSR modalities for defect segmentation and depth estimation of subsurface\ndefects in PT setups. PT-Fusion introduces novel feature fusion modules,\nEncoder Attention Fusion Gate (EAFG) and Attention Enhanced Decoding Block\n(AEDB), to fuse PCA and TSR features for enhanced segmentation and depth\nestimation of subsurface defects. In addition, a novel data augmentation\ntechnique is proposed based on random data sampling from thermographic\nsequences to alleviate the scarcity of PT datasets. The proposed method is\nbenchmarked against state-of-the-art PT inspection models, including U-Net,\nattention U-Net, and 3D-CNN on the Universit\\'e Laval IRT-PVC dataset. The\nresults demonstrate that PT-Fusion outperforms the aforementioned models in\ndefect segmentation and depth estimation accuracies with a margin of 10%.",
      "tldr_zh": "该论文提出PT-Fusion，一种多模态注意力网络，用于提升脉冲热像术(PT)中亚表面缺陷的分割和深度估计，通过融合Principal Component Analysis (PCA)和Thermographic Signal Reconstruction (TSR)模态来利用它们的互补特征。论文引入了Encoder Attention Fusion Gate (EAFG)和Attention Enhanced Decoding Block (AEDB)作为新型特征融合模块，并提出了一种基于热像序列随机数据采样的数据增强技术，以缓解PT数据集稀缺问题。在Université Laval IRT-PVC数据集上实验表明，PT-Fusion相较于U-Net、attention U-Net和3D-CNN等基线模型，缺陷分割和深度估计准确率提高了10%。",
      "categories": [
        "cs.CV",
        "cs.AI",
        "eess.IV"
      ],
      "primary_category": "cs.CV",
      "comment": "Pulse thermography, infrared thermography, defect segmentation,\n  multi-modal networks, attention mechanism",
      "pdf_url": "http://arxiv.org/pdf/2501.09994v1",
      "published_date": "2025-01-17 07:24:58 UTC",
      "updated_date": "2025-01-17 07:24:58 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-22T00:42:42.857743"
    },
    {
      "arxiv_id": "2503.19585v1",
      "title": "A Contradiction-Centered Model for the Emergence of Swarm Intelligence",
      "title_zh": "以矛盾为中心的群体智能涌现模型",
      "authors": [
        "Wenpin Jiao"
      ],
      "abstract": "The phenomenon of emergence of swarm intelligence exists widely in nature and\nhuman society. People have been exploring the root cause of emergence of swarm\nintelligence and trying to establish general theories and models for emergence\nof swarm intelligence. However, the existing theories or models do not grasp\nthe essence of swarm intelligence, so they lack generality and are difficult to\nexplain various phenomena of emergence of swarm intelligence. In this paper, a\ncontradiction-centered model for the emergence of swarm intelligence is\nproposed, in which the internal contradictions of individuals determine their\nbehavior and properties, individuals are related and interact within the swarm\nbecause of competing and occupying environmental resources, interactions and\nswarm potential affect the internal contradictions of individuals and their\ndistribution in the swarm, and the swarm intelligence is manifested as the\nspecific distribution of individual contradictions. This model completely\nexplains the conditions, dynamics, pathways, formations and processes of the\nemergence of swarm intelligence. In order to verify the validity of this model,\nseveral swarm intelligence systems are implemented and analyzed in this paper.\nThe experimental results show that the model has good generality and can be\nused to describe the emergence of various swarm intelligence.",
      "tldr_zh": "本文提出一个以矛盾为中心(contradiction-centered model)来解释群智能(swarm intelligence)出现的模型，强调个体的内部矛盾决定其行为和属性，而个体间的竞争与互动则影响矛盾的分布和群体的整体智能。该模型全面阐述了群智能出现的条件、动态、路径、形成及过程，填补了现有理论的通用性不足。实验通过实现多个群智能系统验证了该模型的有效性，结果显示它能广泛描述各种群智能现象。",
      "categories": [
        "cs.NE",
        "cs.AI"
      ],
      "primary_category": "cs.NE",
      "comment": "21 pages, in Chinese language",
      "pdf_url": "http://arxiv.org/pdf/2503.19585v1",
      "published_date": "2025-01-17 07:05:08 UTC",
      "updated_date": "2025-01-17 07:05:08 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-22T00:42:54.189662"
    },
    {
      "arxiv_id": "2501.09982v2",
      "title": "RichSpace: Enriching Text-to-Video Prompt Space via Text Embedding Interpolation",
      "title_zh": "翻译失败",
      "authors": [
        "Yuefan Cao",
        "Chengyue Gong",
        "Xiaoyu Li",
        "Yingyu Liang",
        "Zhizhou Sha",
        "Zhenmei Shi",
        "Zhao Song"
      ],
      "abstract": "Text-to-video generation models have made impressive progress, but they still\nstruggle with generating videos with complex features. This limitation often\narises from the inability of the text encoder to produce accurate embeddings,\nwhich hinders the video generation model. In this work, we propose a novel\napproach to overcome this challenge by selecting the optimal text embedding\nthrough interpolation in the embedding space. We demonstrate that this method\nenables the video generation model to produce the desired videos. Additionally,\nwe introduce a simple algorithm using perpendicular foot embeddings and cosine\nsimilarity to identify the optimal interpolation embedding. Our findings\nhighlight the importance of accurate text embeddings and offer a pathway for\nimproving text-to-video generation performance.",
      "tldr_zh": "该研究针对文本到视频（Text-to-Video）生成模型在处理复杂特征视频时的局限性提出RichSpace方法，通过在嵌入空间（Embedding Space）中进行文本嵌入插值（Text Embedding Interpolation），来选择最优嵌入以提升生成性能。该方法利用一个简单算法，结合垂直投影嵌入（Perpendicular Foot Embeddings）和余弦相似度（Cosine Similarity）来识别最优插值嵌入，从而帮助模型生成所需的视频。实验结果证明，此方法显著改善了文本到视频生成的准确性，并强调了精确文本嵌入的重要性，为未来模型优化提供了新途径。",
      "categories": [
        "cs.CV",
        "cs.AI",
        "cs.CL",
        "cs.LG"
      ],
      "primary_category": "cs.CV",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2501.09982v2",
      "published_date": "2025-01-17 06:46:10 UTC",
      "updated_date": "2025-02-02 23:53:56 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-22T00:43:05.530980"
    },
    {
      "arxiv_id": "2501.09980v1",
      "title": "Aneumo: A Large-Scale Comprehensive Synthetic Dataset of Aneurysm Hemodynamics",
      "title_zh": "Aneumo：动",
      "authors": [
        "Xigui Li",
        "Yuanye Zhou",
        "Feiyang Xiao",
        "Xin Guo",
        "Yichi Zhang",
        "Chen Jiang",
        "Jianchao Ge",
        "Xiansheng Wang",
        "Qimeng Wang",
        "Taiwei Zhang",
        "Chensen Lin",
        "Yuan Cheng",
        "Yuan Qi"
      ],
      "abstract": "Intracranial aneurysm (IA) is a common cerebrovascular disease that is\nusually asymptomatic but may cause severe subarachnoid hemorrhage (SAH) if\nruptured. Although clinical practice is usually based on individual factors and\nmorphological features of the aneurysm, its pathophysiology and hemodynamic\nmechanisms remain controversial. To address the limitations of current\nresearch, this study constructed a comprehensive hemodynamic dataset of\nintracranial aneurysms. The dataset is based on 466 real aneurysm models, and\n10,000 synthetic models were generated by resection and deformation operations,\nincluding 466 aneurysm-free models and 9,534 deformed aneurysm models. The\ndataset also provides medical image-like segmentation mask files to support\ninsightful analysis. In addition, the dataset contains hemodynamic data\nmeasured at eight steady-state flow rates (0.001 to 0.004 kg/s), including\ncritical parameters such as flow velocity, pressure, and wall shear stress,\nproviding a valuable resource for investigating aneurysm pathogenesis and\nclinical prediction. This dataset will help advance the understanding of the\npathologic features and hemodynamic mechanisms of intracranial aneurysms and\nsupport in-depth research in related fields. Dataset hosted at\nhttps://github.com/Xigui-Li/Aneumo.",
      "tldr_zh": "本文构建了一个名为 Aneumo 的庞大规模合成数据集，专注于颅内动脉瘤（IA）的血流动力学研究，基于 466 个真实动脉瘤模型通过切除和变形操作生成 10,000 个合成模型，包括 466 个无动脉瘤模型和 9,534 个变形模型，并提供医学图像式的分割掩码文件。数据集包含八个稳态流速（0.001 到 0.004 kg/s）下的关键血流参数，如流速、压力和壁剪应力（wall shear stress）。这项资源将推进对动脉瘤发病机制和临床预测的理解，并支持相关领域的深入研究，数据集可从 GitHub 获取。",
      "categories": [
        "cs.CV",
        "cs.AI",
        "cs.LG"
      ],
      "primary_category": "cs.CV",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2501.09980v1",
      "published_date": "2025-01-17 06:43:03 UTC",
      "updated_date": "2025-01-17 06:43:03 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-22T00:43:19.603073"
    },
    {
      "arxiv_id": "2501.09972v1",
      "title": "GVMGen: A General Video-to-Music Generation Model with Hierarchical Attentions",
      "title_zh": "GVMGen: 一种带有层次注意力的通用视频到音乐生成模型",
      "authors": [
        "Heda Zuo",
        "Weitao You",
        "Junxian Wu",
        "Shihong Ren",
        "Pei Chen",
        "Mingxu Zhou",
        "Yujia Lu",
        "Lingyun Sun"
      ],
      "abstract": "Composing music for video is essential yet challenging, leading to a growing\ninterest in automating music generation for video applications. Existing\napproaches often struggle to achieve robust music-video correspondence and\ngenerative diversity, primarily due to inadequate feature alignment methods and\ninsufficient datasets. In this study, we present General Video-to-Music\nGeneration model (GVMGen), designed for generating high-related music to the\nvideo input. Our model employs hierarchical attentions to extract and align\nvideo features with music in both spatial and temporal dimensions, ensuring the\npreservation of pertinent features while minimizing redundancy. Remarkably, our\nmethod is versatile, capable of generating multi-style music from different\nvideo inputs, even in zero-shot scenarios. We also propose an evaluation model\nalong with two novel objective metrics for assessing video-music alignment.\nAdditionally, we have compiled a large-scale dataset comprising diverse types\nof video-music pairs. Experimental results demonstrate that GVMGen surpasses\nprevious models in terms of music-video correspondence, generative diversity,\nand application universality.",
      "tldr_zh": "本研究针对视频配乐的挑战，提出了GVMGen模型，该模型利用hierarchical attentions在spatial和temporal维度上提取并对齐视频特征与音乐，确保生成高度相关的音乐，同时减少冗余。\nGVMGen具有通用性，能够在zero-shot场景下生成多种风格的音乐，并引入了一个新的评估模型和两个客观指标来评估视频-音乐对齐。\n此外，研究编译了一个大规模的视频-音乐对数据集，以支持模型训练和评估。\n实验结果表明，GVMGen在音乐-视频对应性、生成多样性和应用通用性上优于现有方法。",
      "categories": [
        "cs.SD",
        "cs.AI",
        "cs.MM",
        "eess.AS"
      ],
      "primary_category": "cs.SD",
      "comment": "Accepted by the 39th AAAI Conference on Artificial Intelligence\n  (AAAI-25)",
      "pdf_url": "http://arxiv.org/pdf/2501.09972v1",
      "published_date": "2025-01-17 06:30:11 UTC",
      "updated_date": "2025-01-17 06:30:11 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-22T00:43:30.662850"
    },
    {
      "arxiv_id": "2501.09967v1",
      "title": "Explainable artificial intelligence (XAI): from inherent explainability to large language models",
      "title_zh": "翻译失败",
      "authors": [
        "Fuseini Mumuni",
        "Alhassan Mumuni"
      ],
      "abstract": "Artificial Intelligence (AI) has continued to achieve tremendous success in\nrecent times. However, the decision logic of these frameworks is often not\ntransparent, making it difficult for stakeholders to understand, interpret or\nexplain their behavior. This limitation hinders trust in machine learning\nsystems and causes a general reluctance towards their adoption in practical\napplications, particularly in mission-critical domains like healthcare and\nautonomous driving. Explainable AI (XAI) techniques facilitate the\nexplainability or interpretability of machine learning models, enabling users\nto discern the basis of the decision and possibly avert undesirable behavior.\nThis comprehensive survey details the advancements of explainable AI methods,\nfrom inherently interpretable models to modern approaches for achieving\ninterpretability of various black box models, including large language models\n(LLMs). Additionally, we review explainable AI techniques that leverage LLM and\nvision-language model (VLM) frameworks to automate or improve the\nexplainability of other machine learning models. The use of LLM and VLM as\ninterpretability methods particularly enables high-level, semantically\nmeaningful explanations of model decisions and behavior. Throughout the paper,\nwe highlight the scientific principles, strengths and weaknesses of\nstate-of-the-art methods and outline different areas of improvement. Where\nappropriate, we also present qualitative and quantitative comparison results of\nvarious methods to show how they compare. Finally, we discuss the key\nchallenges of XAI and directions for future research.",
      "tldr_zh": "这篇论文对 Explainable AI (XAI) 进行了全面调查，探讨了从固有可解释模型到黑箱模型（如大型语言模型 LLMs）的解释性方法，以提升机器学习系统的透明度和可信度。论文回顾了利用 LLMs 和 vision-language model (VLM) 框架来自动化或改进其他模型的解释性，从而提供高层次、语义上有意义的决策解释。作者比较了各种方法的科学原理、优势、弱点，并通过定性和定量结果展示了它们的性能差异。最后，论文指出了 XAI 的关键挑战，如信任和实际应用障碍，并提出了未来研究方向。",
      "categories": [
        "cs.LG",
        "cs.AI",
        "cs.CV"
      ],
      "primary_category": "cs.LG",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2501.09967v1",
      "published_date": "2025-01-17 06:16:57 UTC",
      "updated_date": "2025-01-17 06:16:57 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-22T00:43:42.160962"
    },
    {
      "arxiv_id": "2501.10484v1",
      "title": "Bias in Decision-Making for AI's Ethical Dilemmas: A Comparative Study of ChatGPT and Claude",
      "title_zh": "AI 伦理困境决策中的偏见：ChatGPT 与 Claude 的比较研究",
      "authors": [
        "Yile Yan",
        "Yuqi Zhu",
        "Wentao Xu"
      ],
      "abstract": "Recent advances in Large Language Models (LLMs) have enabled human-like\nresponses across various tasks, raising questions about their ethical\ndecision-making capabilities and potential biases. This study investigates\nprotected attributes in LLMs through systematic evaluation of their responses\nto ethical dilemmas. Using two prominent models - GPT-3.5 Turbo and Claude 3.5\nSonnet - we analyzed their decision-making patterns across multiple protected\nattributes including age, gender, race, appearance, and disability status.\nThrough 11,200 experimental trials involving both single-factor and two-factor\nprotected attribute combinations, we evaluated the models' ethical preferences,\nsensitivity, stability, and clustering of preferences. Our findings reveal\nsignificant protected attributeses in both models, with consistent preferences\nfor certain features (e.g., \"good-looking\") and systematic neglect of others.\nNotably, while GPT-3.5 Turbo showed stronger preferences aligned with\ntraditional power structures, Claude 3.5 Sonnet demonstrated more diverse\nprotected attribute choices. We also found that ethical sensitivity\nsignificantly decreases in more complex scenarios involving multiple protected\nattributes. Additionally, linguistic referents heavily influence the models'\nethical evaluations, as demonstrated by differing responses to racial\ndescriptors (e.g., \"Yellow\" versus \"Asian\"). These findings highlight critical\nconcerns about the potential impact of LLM biases in autonomous decision-making\nsystems and emphasize the need for careful consideration of protected\nattributes in AI development. Our study contributes to the growing body of\nresearch on AI ethics by providing a systematic framework for evaluating\nprotected attributes in LLMs' ethical decision-making capabilities.",
      "tldr_zh": "本研究比较了Large Language Models (LLMs) 如GPT-3.5 Turbo和Claude 3.5 Sonnet在处理AI伦理困境时的决策偏见，通过11,200次实验评估了模型对年龄、性别、种族、外貌和残疾状态等保护属性的偏好、敏感性、稳定性和聚类。结果显示，GPT-3.5 Turbo更倾向于传统权力结构（如偏好“good-looking”），而Claude 3.5 Sonnet表现出更多样化的选择，但两者在复杂多因素场景下均出现伦理敏感性降低的现象，且语言表述（如“Yellow” vs. “Asian”）会显著影响决策。该研究揭示了LLMs偏见对自主决策系统的潜在风险，并提供了一个系统框架来评估AI伦理决策能力，强调在AI开发中需重视保护属性。",
      "categories": [
        "cs.CY",
        "cs.AI"
      ],
      "primary_category": "cs.CY",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2501.10484v1",
      "published_date": "2025-01-17 05:20:38 UTC",
      "updated_date": "2025-01-17 05:20:38 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-22T00:43:55.275166"
    },
    {
      "arxiv_id": "2501.10483v2",
      "title": "ArxEval: Evaluating Retrieval and Generation in Language Models for Scientific Literature",
      "title_zh": "ArxEval：评估语言模型在科学文献中的检索和生成",
      "authors": [
        "Aarush Sinha",
        "Viraj Virk",
        "Dipshikha Chakraborty",
        "P. S. Sreeja"
      ],
      "abstract": "Language Models [LMs] are now playing an increasingly large role in\ninformation generation and synthesis; the representation of scientific\nknowledge in these systems needs to be highly accurate. A prime challenge is\nhallucination; that is, generating apparently plausible but actually false\ninformation, including invented citations and nonexistent research papers. This\nkind of inaccuracy is dangerous in all the domains that require high levels of\nfactual correctness, such as academia and education. This work presents a\npipeline for evaluating the frequency with which language models hallucinate in\ngenerating responses in the scientific literature. We propose ArxEval, an\nevaluation pipeline with two tasks using ArXiv as a repository: Jumbled Titles\nand Mixed Titles. Our evaluation includes fifteen widely used language models\nand provides comparative insights into their reliability in handling scientific\nliterature.",
      "tldr_zh": "本文提出ArxEval，一种评估管道，用于评估语言模型（Language Models, LMs）在科学文献中的检索和生成能力，重点解决幻觉（hallucination）问题，如生成虚假信息、虚构引用和不存在的论文。ArxEval包括Jumbled Titles和Mixed Titles两个任务，利用ArXiv作为数据仓库，对15个广泛使用的语言模型进行测试。实验结果提供了这些模型在处理科学文献可靠性方面的比较洞见，为学术和教育等领域的高事实正确性需求提供了重要参考。",
      "categories": [
        "cs.CL",
        "cs.AI"
      ],
      "primary_category": "cs.CL",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2501.10483v2",
      "published_date": "2025-01-17 05:19:24 UTC",
      "updated_date": "2025-01-22 04:17:21 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-22T00:44:06.883904"
    },
    {
      "arxiv_id": "2501.09954v1",
      "title": "AIRCHITECT v2: Learning the Hardware Accelerator Design Space through Unified Representations",
      "title_zh": "AIRCHITECT v2：通过统一表示学习硬件加速器设计",
      "authors": [
        "Jamin Seo",
        "Akshat Ramachandran",
        "Yu-Chuan Chuang",
        "Anirudh Itagi",
        "Tushar Krishna"
      ],
      "abstract": "Design space exploration (DSE) plays a crucial role in enabling custom\nhardware architectures, particularly for emerging applications like AI, where\noptimized and specialized designs are essential. With the growing complexity of\ndeep neural networks (DNNs) and the introduction of advanced foundational\nmodels (FMs), the design space for DNN accelerators is expanding at an\nexponential rate. Additionally, this space is highly non-uniform and\nnon-convex, making it increasingly difficult to navigate and optimize.\nTraditional DSE techniques rely on search-based methods, which involve\niterative sampling of the design space to find the optimal solution. However,\nthis process is both time-consuming and often fails to converge to the global\noptima for such design spaces. Recently, AIrchitect v1, the first attempt to\naddress the limitations of search-based techniques, transformed DSE into a\nconstant-time classification problem using recommendation networks. In this\nwork, we propose AIrchitect v2, a more accurate and generalizable\nlearning-based DSE technique applicable to large-scale design spaces that\novercomes the shortcomings of earlier approaches. Specifically, we devise an\nencoder-decoder transformer model that (a) encodes the complex design space\ninto a uniform intermediate representation using contrastive learning and (b)\nleverages a novel unified representation blending the advantages of\nclassification and regression to effectively explore the large DSE space\nwithout sacrificing accuracy. Experimental results evaluated on 10^5 real DNN\nworkloads demonstrate that, on average, AIrchitect v2 outperforms existing\ntechniques by 15% in identifying optimal design points. Furthermore, to\ndemonstrate the generalizability of our method, we evaluate performance on\nunseen model workloads (LLMs) and attain a 1.7x improvement in inference\nlatency on the identified hardware architecture.",
      "tldr_zh": "该论文提出AIrchitect v2，一种基于学习的Design Space Exploration (DSE)技术，用于优化硬件加速器设计空间，解决传统搜索方法在复杂DNNs和Foundational Models (FMs)下的效率和准确性问题。该方法采用编码器-解码器Transformer模型，通过Contrastive Learning将设计空间编码成统一中间表示，并引入一种结合分类和回归优势的Unified Representation，实现高效探索。在10^5个真实DNN工作负载上的实验表明，AIrchitect v2比现有技术平均提高15%的最优设计点识别率，并在未见模型如LLMs上实现1.7x的推理延迟改善。",
      "categories": [
        "cs.LG",
        "cs.AI",
        "cs.AR"
      ],
      "primary_category": "cs.LG",
      "comment": "Accepted to DATE 2025",
      "pdf_url": "http://arxiv.org/pdf/2501.09954v1",
      "published_date": "2025-01-17 04:57:42 UTC",
      "updated_date": "2025-01-17 04:57:42 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-22T00:44:20.086541"
    },
    {
      "arxiv_id": "2501.09949v1",
      "title": "MultiPruner: Balanced Structure Removal in Foundation Models",
      "title_zh": "MultiPruner：基础模型中的平衡结构移除",
      "authors": [
        "J. Pablo Muñoz",
        "Jinjie Yuan",
        "Nilesh Jain"
      ],
      "abstract": "Recently, state-of-the-art approaches for pruning large pre-trained models\n(LPMs) have demonstrated that the training-free removal of non-critical\nresidual blocks in Transformers is viable for reducing model size, achieving\nresults that outperform previous training-free pruning approaches. Motivated by\nthese findings, we extend BlockPruner (Zhong et al., 2024) and propose\nMultiPruner, a pruning approach that surpasses recent training-free pruning\nmethods by adopting a multidimensional, iterative, fine-grained pruning\nstrategy. In MultiPruner, multidimensional pruning reinstates the structural\nbalance in block-pruned models by sequentially compressing along three\ndimensions: i) residual blocks, ii) channels of multilayer perceptrons (MLP),\nand iii) attention heads. This solution enhances zero-shot accuracy on\ndownstream tasks compared to other techniques while improving model compression\nratios, producing compressed models with fewer computing and memory\nrequirements. Extensive experiments demonstrate the advantages of the proposed\nmethod across various large pre-trained models. The code and pruning\nconfigurations are available at\nhttps://github.com/IntelLabs/Hardware-Aware-Automated-Machine-Learning.",
      "tldr_zh": "该研究扩展了 BlockPruner，提出 MultiPruner，一种多维度的训练-free 修剪方法，用于大型预训练模型 (LPMs)，通过迭代压缩 residual blocks、MLP 通道和 attention heads 来保持模型结构平衡。相比其他方法，MultiPruner 显著提升了下游任务的 zero-shot accuracy，同时提高了模型压缩比并降低了计算和内存需求。实验在各种 LPMs 上验证了其优势，并提供了开源代码以便复现。",
      "categories": [
        "cs.LG",
        "cs.AI",
        "I.2.0"
      ],
      "primary_category": "cs.LG",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2501.09949v1",
      "published_date": "2025-01-17 04:24:31 UTC",
      "updated_date": "2025-01-17 04:24:31 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-22T00:44:30.926294"
    },
    {
      "arxiv_id": "2501.09948v1",
      "title": "AI Explainability for Power Electronics: From a Lipschitz Continuity Perspective",
      "title_zh": "电力电子学的 AI 可解释性：从 Lipschitz 连续性的视角",
      "authors": [
        "Xinze Li",
        "Fanfan Lin",
        "Homer Alan Mantooth",
        "Juan José Rodríguez-Andina"
      ],
      "abstract": "Lifecycle management of power converters continues to thrive with emerging\nartificial intelligence (AI) solutions, yet AI mathematical explainability\nremains unexplored in power electronics (PE) community. The lack of theoretical\nrigor challenges adoption in mission-critical applications. Therefore, this\nletter proposes a generic framework to evaluate mathematical explainability,\nhighlighting inference stability and training convergence from a Lipschitz\ncontinuity perspective. Inference stability governs consistent outputs under\ninput perturbations, essential for robust real-time control and fault\ndiagnosis. Training convergence guarantees stable learning dynamics,\nfacilitating accurate modeling in PE contexts. Additionally, a Lipschitz-aware\nlearning rate selection strategy is introduced to accelerate convergence while\nmitigating overshoots and oscillations. The feasibility of the proposed\nLipschitz-oriented framework is demonstrated by validating the mathematical\nexplainability of a state-of-the-art physics-in-architecture neural network,\nand substantiated through empirical case studies on dual-active-bridge\nconverters. This letter serves as a clarion call for the PE community to\nembrace mathematical explainability, heralding a transformative era of\ntrustworthy and explainable AI solutions that potentially redefine the future\nof power electronics.",
      "tldr_zh": "该论文探讨了在电力电子（PE）领域中 AI 解决方案的数学可解释性问题，提出一个通用框架从 Lipschitz 连续性的角度评估 AI 的推理稳定性和训练收敛性，以解决缺乏理论严谨性带来的采用挑战。推理稳定性确保输入微扰下输出一致，支持鲁棒的实时控制和故障诊断，而训练收敛性促进稳定的学习动态，实现 PE 上下文中的准确建模。同时，引入了 Lipschitz-aware 学习率选择策略，以加速收敛并减少过冲和振荡。实验通过验证一个 state-of-the-art 的 physics-in-architecture 神经网络，并在 dual-active-bridge 转换器案例中证明了框架的可行性，呼吁 PE 社区拥抱数学可解释性，推动可信赖的 AI 应用。",
      "categories": [
        "eess.SY",
        "cs.AI",
        "cs.SY"
      ],
      "primary_category": "eess.SY",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2501.09948v1",
      "published_date": "2025-01-17 04:20:43 UTC",
      "updated_date": "2025-01-17 04:20:43 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-22T00:44:43.193092"
    },
    {
      "arxiv_id": "2501.09946v1",
      "title": "Client-Centric Federated Adaptive Optimization",
      "title_zh": "客户端中心化的联邦自适应优化",
      "authors": [
        "Jianhui Sun",
        "Xidong Wu",
        "Heng Huang",
        "Aidong Zhang"
      ],
      "abstract": "Federated Learning (FL) is a distributed learning paradigm where clients\ncollaboratively train a model while keeping their own data private. With an\nincreasing scale of clients and models, FL encounters two key challenges,\nclient drift due to a high degree of statistical/system heterogeneity, and lack\nof adaptivity. However, most existing FL research is based on unrealistic\nassumptions that virtually ignore system heterogeneity. In this paper, we\npropose Client-Centric Federated Adaptive Optimization, which is a class of\nnovel federated adaptive optimization approaches. We enable several features in\nthis framework such as arbitrary client participation, asynchronous server\naggregation, and heterogeneous local computing, which are ubiquitous in\nreal-world FL systems but are missed in most existing works. We provide a\nrigorous convergence analysis of our proposed framework for general nonconvex\nobjectives, which is shown to converge with the best-known rate. Extensive\nexperiments show that our approaches consistently outperform the baseline by a\nlarge margin across benchmarks.",
      "tldr_zh": "这篇论文提出 Client-Centric Federated Adaptive Optimization，一种新型联邦学习(FL)优化框架，旨在解决客户端漂移（因统计/系统异质性）和缺乏适应性的关键挑战。框架支持任意客户端参与、异步服务器聚合以及异构本地计算，这些特性更符合真实世界FL系统的需求。作者提供了严格的收敛性分析，证明该方法在一般非凸目标函数下达到最佳已知收敛率。实验结果显示，该方法在多个基准测试中大幅优于基线方法。",
      "categories": [
        "cs.LG",
        "cs.AI",
        "math.OC"
      ],
      "primary_category": "cs.LG",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2501.09946v1",
      "published_date": "2025-01-17 04:00:50 UTC",
      "updated_date": "2025-01-17 04:00:50 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-22T00:44:54.274616"
    },
    {
      "arxiv_id": "2501.12408v1",
      "title": "Control-ITRA: Controlling the Behavior of a Driving Model",
      "title_zh": "Control-ITRA：控制驾驶模型的行为",
      "authors": [
        "Vasileios Lioutas",
        "Adam Scibior",
        "Matthew Niedoba",
        "Berend Zwartsenberg",
        "Frank Wood"
      ],
      "abstract": "Simulating realistic driving behavior is crucial for developing and testing\nautonomous systems in complex traffic environments. Equally important is the\nability to control the behavior of simulated agents to tailor scenarios to\nspecific research needs and safety considerations. This paper extends the\ngeneral-purpose multi-agent driving behavior model ITRA (Scibior et al., 2021),\nby introducing a method called Control-ITRA to influence agent behavior through\nwaypoint assignment and target speed modulation. By conditioning agents on\nthese two aspects, we provide a mechanism for them to adhere to specific\ntrajectories and indirectly adjust their aggressiveness. We compare different\napproaches for integrating these conditions during training and demonstrate\nthat our method can generate controllable, infraction-free trajectories while\npreserving realism in both seen and unseen locations.",
      "tldr_zh": "这篇论文扩展了通用多代理驾驶行为模型ITRA，引入Control-ITRA方法，通过分配waypoints和调节target speed modulation来控制模拟代理的行为，从而适应特定研究需求和安全考虑。该方法允许代理遵循预设轨迹并间接调整其侵略性，同时在训练过程中比较了不同整合条件的方式。实验结果表明，Control-ITRA能生成可控、无违规的轨迹，并在已见和未见位置保持驾驶行为的现实性。",
      "categories": [
        "cs.AI",
        "cs.LG",
        "cs.RO",
        "cs.SY",
        "eess.SY",
        "stat.ML"
      ],
      "primary_category": "cs.AI",
      "comment": "16 pages, 2 figures",
      "pdf_url": "http://arxiv.org/pdf/2501.12408v1",
      "published_date": "2025-01-17 03:35:11 UTC",
      "updated_date": "2025-01-17 03:35:11 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-22T00:45:06.907133"
    },
    {
      "arxiv_id": "2501.09934v1",
      "title": "HEART: Achieving Timely Multi-Model Training for Vehicle-Edge-Cloud-Integrated Hierarchical Federated Learning",
      "title_zh": "翻译失败",
      "authors": [
        "Xiaohong Yang",
        "Minghui Liwang",
        "Xianbin Wang",
        "Zhipeng Cheng",
        "Seyyedali Hosseinalipour",
        "Huaiyu Dai",
        "Zhenzhen Jiao"
      ],
      "abstract": "The rapid growth of AI-enabled Internet of Vehicles (IoV) calls for efficient\nmachine learning (ML) solutions that can handle high vehicular mobility and\ndecentralized data. This has motivated the emergence of Hierarchical Federated\nLearning over vehicle-edge-cloud architectures (VEC-HFL). Nevertheless, one\naspect which is underexplored in the literature on VEC-HFL is that vehicles\noften need to execute multiple ML tasks simultaneously, where this multi-model\ntraining environment introduces crucial challenges. First, improper aggregation\nrules can lead to model obsolescence and prolonged training times. Second,\nvehicular mobility may result in inefficient data utilization by preventing the\nvehicles from returning their models to the network edge. Third, achieving a\nbalanced resource allocation across diverse tasks becomes of paramount\nimportance as it majorly affects the effectiveness of collaborative training.\nWe take one of the first steps towards addressing these challenges via\nproposing a framework for multi-model training in dynamic VEC-HFL with the goal\nof minimizing global training latency while ensuring balanced training across\nvarious tasks-a problem that turns out to be NP-hard. To facilitate timely\nmodel training, we introduce a hybrid synchronous-asynchronous aggregation\nrule. Building on this, we present a novel method called Hybrid Evolutionary\nAnd gReedy allocaTion (HEART). The framework operates in two stages: first, it\nachieves balanced task scheduling through a hybrid heuristic approach that\ncombines improved Particle Swarm Optimization (PSO) and Genetic Algorithms\n(GA); second, it employs a low-complexity greedy algorithm to determine the\ntraining priority of assigned tasks on vehicles. Experiments on real-world\ndatasets demonstrate the superiority of HEART over existing methods.",
      "tldr_zh": "该论文针对AI-enabled Internet of Vehicles (IoV)中的多模型训练挑战，提出HEART框架，用于Vehicle-Edge-Cloud-Integrated Hierarchical Federated Learning (VEC-HFL)，以最小化全局训练延迟并实现任务平衡。该框架引入混合同步-异步聚合规则（hybrid synchronous-asynchronous aggregation rule），解决模型过时和数据利用效率问题。HEART采用两阶段方法：首先，通过结合改进的Particle Swarm Optimization (PSO)和Genetic Algorithms (GA)的混合启发式方法进行平衡任务调度；其次，使用低复杂度greedy algorithm确定车辆上任务的训练优先级。实验在真实数据集上证明，HEART比现有方法表现出色。",
      "categories": [
        "cs.LG",
        "cs.AI"
      ],
      "primary_category": "cs.LG",
      "comment": "14 pages, 6 figures,",
      "pdf_url": "http://arxiv.org/pdf/2501.09934v1",
      "published_date": "2025-01-17 03:15:03 UTC",
      "updated_date": "2025-01-17 03:15:03 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-22T00:45:20.314951"
    },
    {
      "arxiv_id": "2501.09929v3",
      "title": "Interpretable Steering of Large Language Models with Feature Guided Activation Additions",
      "title_zh": "翻译失败",
      "authors": [
        "Samuel Soo",
        "Chen Guang",
        "Wesley Teng",
        "Chandrasekaran Balaganesh",
        "Tan Guoxian",
        "Yan Ming"
      ],
      "abstract": "Effective and reliable control over large language model (LLM) behavior is a\nsignificant challenge. While activation steering methods, which add steering\nvectors to a model's hidden states, are a promising approach, existing\ntechniques often lack precision and interpretability in how they influence\nmodel outputs. We introduce Feature Guided Activation Additions (FGAA), a novel\nactivation steering method that leverages insights from Contrastive Activation\nAddition (CAA) and Sparse Autoencoder-Targeted Steering (SAE-TS). By operating\nin the latent space of a Sparse Autoencoder (SAE) and employing optimization\ntechniques to select desired SAE features, FGAA constructs precise steering\nvectors that provide better steering effects while maintaining coherence of\nsteered model outputs. In this regard, evaluations on Gemma-2-2B and Gemma-2-9B\nmodels across various steering tasks demonstrate that FGAA outperforms existing\nsteering methods of CAA, SAE decoder steering, and SAE-TS. Our results also\nhighlight important trade-offs between steering scale and general model\ncapabilities that are consistent across all tested steering methods.",
      "tldr_zh": "该论文提出了一种名为 Feature Guided Activation Additions (FGAA) 的新方法，用于对 Large Language Models (LLM) 进行可解释的激活导向，以解决现有技术在精确性和可解释性方面的不足。FGAA 基于 Contrastive Activation Addition (CAA) 和 Sparse Autoencoder-Targeted Steering (SAE-TS) 的见解，在 Sparse Autoencoder (SAE) 的潜在空间中通过优化选择特征来构建精确的导向向量，从而提升导向效果并保持模型输出连贯性。在 Gemma-2-2B 和 Gemma-2-9B 模型上的实验显示，FGAA 优于 CAA、SAE 解码器导向和 SAE-TS 等方法，同时揭示了导向规模与模型整体能力之间的关键权衡。",
      "categories": [
        "cs.LG",
        "cs.AI",
        "cs.CL"
      ],
      "primary_category": "cs.LG",
      "comment": "9 maintext pages, 13 appendix pages",
      "pdf_url": "http://arxiv.org/pdf/2501.09929v3",
      "published_date": "2025-01-17 02:55:23 UTC",
      "updated_date": "2025-04-02 13:20:40 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-22T00:45:31.033798"
    },
    {
      "arxiv_id": "2501.09928v1",
      "title": "Dialogue Benchmark Generation from Knowledge Graphs with Cost-Effective Retrieval-Augmented LLMs",
      "title_zh": "从知识图谱利用成本有效的检索增强LLMs生成对话基准",
      "authors": [
        "Reham Omar",
        "Omij Mangukiya",
        "Essam Mansour"
      ],
      "abstract": "Dialogue benchmarks are crucial in training and evaluating chatbots engaging\nin domain-specific conversations. Knowledge graphs (KGs) represent semantically\nrich and well-organized data spanning various domains, such as DBLP, DBpedia,\nand YAGO. Traditionally, dialogue benchmarks have been manually created from\ndocuments, neglecting the potential of KGs in automating this process. Some\nquestion-answering benchmarks are automatically generated using extensive\npreprocessing from KGs, but they do not support dialogue generation. This paper\nintroduces Chatty-Gen, a novel multi-stage retrieval-augmented generation\nplatform for automatically generating high-quality dialogue benchmarks tailored\nto a specific domain using a KG. Chatty-Gen decomposes the generation process\ninto manageable stages and uses assertion rules for automatic validation\nbetween stages. Our approach enables control over intermediate results to\nprevent time-consuming restarts due to hallucinations. It also reduces reliance\non costly and more powerful commercial LLMs. Chatty-Gen eliminates upfront\nprocessing of the entire KG using efficient query-based retrieval to find\nrepresentative subgraphs based on the dialogue context. Our experiments with\nseveral real and large KGs demonstrate that Chatty-Gen significantly\noutperforms state-of-the-art systems and ensures consistent model and system\nperformance across multiple LLMs of diverse capabilities, such as GPT-4o,\nGemini 1.5, Llama 3, and Mistral.",
      "tldr_zh": "该论文提出 Chatty-Gen，一种创新的多阶段检索增强生成（retrieval-augmented generation）平台，用于从 Knowledge Graphs (KGs) 自动生成高质量的领域特定对话基准，从而解决传统手动创建方法的局限性。Chatty-Gen 通过分解生成过程、使用 assertion rules 进行自动验证，以及查询-based retrieval 来避免处理整个 KG，确保高效且成本有效，减少对强大商业 LLMs 的依赖。实验结果显示，在多个真实大型 KGs 上，Chatty-Gen 显著优于现有系统，并在不同能力的 LLMs（如 GPT-4o、Gemini 1.5、Llama 3 和 Mistral）上保持一致性能。",
      "categories": [
        "cs.CL",
        "cs.AI"
      ],
      "primary_category": "cs.CL",
      "comment": "The paper is publsihed in SIGMOD 2025",
      "pdf_url": "http://arxiv.org/pdf/2501.09928v1",
      "published_date": "2025-01-17 02:48:29 UTC",
      "updated_date": "2025-01-17 02:48:29 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-22T00:45:43.058576"
    },
    {
      "arxiv_id": "2501.09927v1",
      "title": "IE-Bench: Advancing the Measurement of Text-Driven Image Editing for Human Perception Alignment",
      "title_zh": "翻译失败",
      "authors": [
        "Shangkun Sun",
        "Bowen Qu",
        "Xiaoyu Liang",
        "Songlin Fan",
        "Wei Gao"
      ],
      "abstract": "Recent advances in text-driven image editing have been significant, yet the\ntask of accurately evaluating these edited images continues to pose a\nconsiderable challenge. Different from the assessment of text-driven image\ngeneration, text-driven image editing is characterized by simultaneously\nconditioning on both text and a source image. The edited images often retain an\nintrinsic connection to the original image, which dynamically change with the\nsemantics of the text. However, previous methods tend to solely focus on\ntext-image alignment or have not aligned with human perception. In this work,\nwe introduce the Text-driven Image Editing Benchmark suite (IE-Bench) to\nenhance the assessment of text-driven edited images. IE-Bench includes a\ndatabase contains diverse source images, various editing prompts and the\ncorresponding results different editing methods, and total 3,010 Mean Opinion\nScores (MOS) provided by 25 human subjects. Furthermore, we introduce IE-QA, a\nmulti-modality source-aware quality assessment method for text-driven image\nediting. To the best of our knowledge, IE-Bench offers the first IQA dataset\nand model tailored for text-driven image editing. Extensive experiments\ndemonstrate IE-QA's superior subjective-alignments on the text-driven image\nediting task compared with previous metrics. We will make all related data and\ncode available to the public.",
      "tldr_zh": "本文提出 IE-Bench，这是一个针对文本驱动图像编辑（Text-Driven Image Editing）的基准套件，用于提升评估方法的准确性和人类感知对齐。该基准包括一个数据库，包含多样源图像、各种编辑提示、不同方法的编辑结果，以及来自25名人类受试者的3,010个Mean Opinion Scores (MOS)。此外，作者引入了IE-QA，一种多模态源感知质量评估方法（IQA），实验证明其在文本驱动图像编辑任务中比现有指标更优于主观对齐，所有相关数据和代码将公开。",
      "categories": [
        "cs.CV",
        "cs.AI"
      ],
      "primary_category": "cs.CV",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2501.09927v1",
      "published_date": "2025-01-17 02:47:25 UTC",
      "updated_date": "2025-01-17 02:47:25 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-22T00:45:55.182282"
    },
    {
      "arxiv_id": "2501.09926v1",
      "title": "ForestProtector: An IoT Architecture Integrating Machine Vision and Deep Reinforcement Learning for Efficient Wildfire Monitoring",
      "title_zh": "ForestProtector：整合机器视觉和深度强化学习的物联网架构，用于高效野火监测",
      "authors": [
        "Kenneth Bonilla-Ormachea",
        "Horacio Cuizaga",
        "Edwin Salcedo",
        "Sebastian Castro",
        "Sergio Fernandez-Testa",
        "Misael Mamani"
      ],
      "abstract": "Early detection of forest fires is crucial to minimizing the environmental\nand socioeconomic damage they cause. Indeed, a fire's duration directly\ncorrelates with the difficulty and cost of extinguishing it. For instance, a\nfire burning for 1 minute might require 1 liter of water to extinguish, while a\n2-minute fire could demand 100 liters, and a 10-minute fire might necessitate\n1,000 liters. On the other hand, existing fire detection systems based on novel\ntechnologies (e.g., remote sensing, PTZ cameras, UAVs) are often expensive and\nrequire human intervention, making continuous monitoring of large areas\nimpractical. To address this challenge, this work proposes a low-cost forest\nfire detection system that utilizes a central gateway device with computer\nvision capabilities to monitor a 360{\\deg} field of view for smoke at long\ndistances. A deep reinforcement learning agent enhances surveillance by\ndynamically controlling the camera's orientation, leveraging real-time sensor\ndata (smoke levels, ambient temperature, and humidity) from distributed IoT\ndevices. This approach enables automated wildfire monitoring across expansive\nareas while reducing false positives.",
      "tldr_zh": "本研究提出ForestProtector，一种低成本IoT架构，结合Machine Vision和Deep Reinforcement Learning，用于高效监测森林野火。该系统利用中心网关设备实现360度视野的烟雾检测，并通过深度强化学习代理动态调整摄像头方向，基于实时传感器数据（如烟雾水平、环境温度和湿度）来优化监控过程。相较于现有昂贵且依赖人工干预的系统，该方法实现了大范围自动化野火监测，并显著减少了假警报，从而降低灭火难度和成本。",
      "categories": [
        "cs.AI",
        "cs.CV"
      ],
      "primary_category": "cs.AI",
      "comment": "Accepted for publication in the proceedings of the 11th International\n  Conference on Automation, Robotics, and Applications (ICARA 2025)",
      "pdf_url": "http://arxiv.org/pdf/2501.09926v1",
      "published_date": "2025-01-17 02:47:14 UTC",
      "updated_date": "2025-01-17 02:47:14 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-22T00:46:06.722304"
    },
    {
      "arxiv_id": "2501.09923v1",
      "title": "Study on a Fast Solver for Combined Field Integral Equations of 3D Conducting Bodies Based on Graph Neural Networks",
      "title_zh": "翻译失败",
      "authors": [
        "Tao Shan",
        "Xin Zhang",
        "Di Wu"
      ],
      "abstract": "In this paper, we present a graph neural networks (GNNs)-based fast solver\n(GraphSolver) for solving combined field integral equations (CFIEs) of 3D\nconducting bodies. Rao-Wilton-Glisson (RWG) basis functions are employed to\ndiscretely and accurately represent the geometry of 3D conducting bodies. A\nconcise and informative graph representation is then constructed by treating\neach RWG function as a node in the graph, enabling the flow of current between\nnodes. With the transformed graphs, GraphSolver is developed to directly\npredict real and imaginary parts of the x, y and z components of the surface\ncurrent densities at each node (RWG function). Numerical results demonstrate\nthe efficacy of GraphSolver in solving CFIEs for 3D conducting bodies with\nvarying levels of geometric complexity, including basic 3D targets,\nmissile-shaped targets, and airplane-shaped targets.",
      "tldr_zh": "这篇论文提出了一种基于 Graph Neural Networks (GNNs) 的快速求解器 GraphSolver，用于解决 3D 导体物体的 Combined Field Integral Equations (CFIEs)。该方法采用 Rao-Wilton-Glisson (RWG) basis functions 来精确表示物体的几何结构，并将每个 RWG 函数视为图中的节点，以实现电流流动的建模和预测。GraphSolver 能够直接输出表面电流密度的 x、y 和 z 分量的实部和虚部，实验证明其在不同几何复杂度（如基本 3D 目标、导弹形状和飞机形状）的物体上表现出高效性和准确性。",
      "categories": [
        "cs.LG",
        "cs.AI",
        "cs.NA",
        "math.NA",
        "65M22",
        "I.2"
      ],
      "primary_category": "cs.LG",
      "comment": "10 pages,11 figures",
      "pdf_url": "http://arxiv.org/pdf/2501.09923v1",
      "published_date": "2025-01-17 02:40:04 UTC",
      "updated_date": "2025-01-17 02:40:04 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-22T00:46:19.640702"
    },
    {
      "arxiv_id": "2501.09918v1",
      "title": "GenSC-6G: A Prototype Testbed for Integrated Generative AI, Quantum, and Semantic Communication",
      "title_zh": "翻译失败",
      "authors": [
        "Brian E. Arfeto",
        "Shehbaz Tariq",
        "Uman Khalid",
        "Trung Q. Duong",
        "Hyundong Shin"
      ],
      "abstract": "We introduce a prototyping testbed, GenSC-6G, developed to generate a\ncomprehensive dataset that supports the integration of generative artificial\nintelligence (AI), quantum computing, and semantic communication for emerging\nsixth-generation (6G) applications. The GenSC-6G dataset is designed with\nnoise-augmented synthetic data optimized for semantic decoding, classification,\nand localization tasks, significantly enhancing flexibility for diverse\nAI-driven communication applications. This adaptable prototype supports\nseamless modifications across baseline models, communication modules, and\ngoal-oriented decoders. Case studies demonstrate its application in lightweight\nclassification, semantic upsampling, and edge-based language inference under\nnoise conditions. The GenSC-6G dataset serves as a scalable and robust resource\nfor developing goal-oriented communication systems tailored to the growing\ndemands of 6G networks.",
      "tldr_zh": "本论文介绍了 GenSC-6G 原型测试平台，该平台用于生成一个综合数据集，支持生成式 AI、量子计算和语义通信在 6G 应用中的集成。\n数据集采用噪声增强的合成数据，优化用于语义解码、分类和定位任务，并允许基线模型、通信模块和目标导向解码器的无缝修改。\n案例研究展示了其在轻量级分类、语义上采样以及噪声条件下的边缘语言推理中的实际应用。\n总体而言，GenSC-6G 提供了一个可扩展的资源，推动了针对 6G 网络的目标导向通信系统的开发。",
      "categories": [
        "cs.AI",
        "eess.SP",
        "quant-ph"
      ],
      "primary_category": "cs.AI",
      "comment": "SUBMITTED FOR PUBLICATION IN IEEE COMMUNICATIONS MAGAZINE",
      "pdf_url": "http://arxiv.org/pdf/2501.09918v1",
      "published_date": "2025-01-17 02:20:52 UTC",
      "updated_date": "2025-01-17 02:20:52 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-22T00:46:31.226915"
    },
    {
      "arxiv_id": "2501.09913v1",
      "title": "Towards A Litmus Test for Common Sense",
      "title_zh": "翻译失败",
      "authors": [
        "Hugo Latapie"
      ],
      "abstract": "This paper is the second in a planned series aimed at envisioning a path to\nsafe and beneficial artificial intelligence. Building on the conceptual\ninsights of \"Common Sense Is All You Need,\" we propose a more formal litmus\ntest for common sense, adopting an axiomatic approach that combines minimal\nprior knowledge (MPK) constraints with diagonal or Godel-style arguments to\ncreate tasks beyond the agent's known concept set. We discuss how this approach\napplies to the Abstraction and Reasoning Corpus (ARC), acknowledging\ntraining/test data constraints, physical or virtual embodiment, and large\nlanguage models (LLMs). We also integrate observations regarding emergent\ndeceptive hallucinations, in which more capable AI systems may intentionally\nfabricate plausible yet misleading outputs to disguise knowledge gaps. The\noverarching theme is that scaling AI without ensuring common sense risks\nintensifying such deceptive tendencies, thereby undermining safety and trust.\nAligning with the broader goal of developing beneficial AI without causing\nharm, our axiomatic litmus test not only diagnoses whether an AI can handle\ntruly novel concepts but also provides a stepping stone toward an ethical,\nreliable foundation for future safe, beneficial, and aligned artificial\nintelligence.",
      "tldr_zh": "这篇论文提出一个正式的 litmus test for common sense，作为实现安全有益 AI 路径的第二篇系列论文，基于“Common Sense Is All You Need”的概念。该测试采用公理方法，结合最小先验知识 (MPK) 约束和 Godel-style arguments，设计超出 AI 已知概念集的任务，以评估其处理新颖问题的能力。论文讨论了此方法在 Abstraction and Reasoning Corpus (ARC) 和大型语言模型 (LLMs) 中的应用，并警告 AI 可能出现新兴欺骗性幻觉，导致误导性输出，从而强调在扩展 AI 时确保 common sense 的重要性，以奠定安全、可靠和道德的 AI 基础。",
      "categories": [
        "cs.AI"
      ],
      "primary_category": "cs.AI",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2501.09913v1",
      "published_date": "2025-01-17 02:02:12 UTC",
      "updated_date": "2025-01-17 02:02:12 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-22T00:46:44.379980"
    },
    {
      "arxiv_id": "2501.09905v4",
      "title": "SLIM: Sim-to-Real Legged Instructive Manipulation via Long-Horizon Visuomotor Learning",
      "title_zh": "翻译失败",
      "authors": [
        "Haichao Zhang",
        "Haonan Yu",
        "Le Zhao",
        "Andrew Choi",
        "Qinxun Bai",
        "Break Yang",
        "Wei Xu"
      ],
      "abstract": "We present a low-cost legged mobile manipulation system that solves\nlong-horizon real-world tasks, trained by reinforcement learning purely in\nsimulation. This system is made possible by 1) a hierarchical design of a\nhigh-level policy for visual-mobile manipulation following task instructions,\nand a low-level quadruped locomotion policy, 2) a teacher and student training\npipeline for the high level, which trains a teacher to tackle long-horizon\ntasks using privileged task decomposition and target object information, and\nfurther trains a student for visual-mobile manipulation via RL guided by the\nteacher's behavior, and 3) a suite of techniques for minimizing the sim-to-real\ngap.\n  In contrast to many previous works that use high-end equipments, our system\ndemonstrates effective performance with more accessible hardware --\nspecifically, a Unitree Go1 quadruped, a WidowX-250S arm, and a single\nwrist-mounted RGB camera -- despite the increased challenges of sim-to-real\ntransfer. Trained fully in simulation, a single policy autonomously solves\nlong-horizon tasks involving search, move to, grasp, transport, and drop into,\nachieving nearly 80% real-world success. This performance is comparable to that\nof expert human teleoperation on the same tasks while the robot is more\nefficient, operating at about 1.5x the speed of the teleoperation. Finally, we\nperform extensive ablations on key techniques for efficient RL training and\neffective sim-to-real transfer, and demonstrate effective deployment across\ndiverse indoor and outdoor scenes under various lighting conditions.",
      "tldr_zh": "本研究提出SLIM系统，这是一个低成本的腿部移动操纵平台，通过纯模拟强化学习（Reinforcement Learning）训练来处理长时域真实世界任务。系统采用层次化设计，包括高层政策负责视觉-移动操纵和任务指令执行，以及底层四足机器人运动政策；同时，通过教师-学生训练管道，教师利用特权任务分解和目标对象信息处理复杂任务，学生则通过强化学习模仿教师行为，并结合多种技术最小化模拟到真实（sim-to-real）的差距。实验结果显示，SLIM在真实环境中使用Unitree Go1四足机器人和WidowX-250S机械臂等硬件，实现了近80%的成功率，处理任务如搜索、抓取和放置时比专家人类遥操作效率高约1.5倍，并在各种室内外场景下表现出色。",
      "categories": [
        "cs.RO",
        "cs.AI",
        "cs.CV",
        "cs.LG"
      ],
      "primary_category": "cs.RO",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2501.09905v4",
      "published_date": "2025-01-17 01:32:18 UTC",
      "updated_date": "2025-01-29 19:58:23 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-22T00:46:56.598639"
    },
    {
      "arxiv_id": "2501.09891v1",
      "title": "Evolving Deeper LLM Thinking",
      "title_zh": "LLM 更深层思考的演化",
      "authors": [
        "Kuang-Huei Lee",
        "Ian Fischer",
        "Yueh-Hua Wu",
        "Dave Marwood",
        "Shumeet Baluja",
        "Dale Schuurmans",
        "Xinyun Chen"
      ],
      "abstract": "We explore an evolutionary search strategy for scaling inference time compute\nin Large Language Models. The proposed approach, Mind Evolution, uses a\nlanguage model to generate, recombine and refine candidate responses. The\nproposed approach avoids the need to formalize the underlying inference problem\nwhenever a solution evaluator is available. Controlling for inference cost, we\nfind that Mind Evolution significantly outperforms other inference strategies\nsuch as Best-of-N and Sequential Revision in natural language planning tasks.\nIn the TravelPlanner and Natural Plan benchmarks, Mind Evolution solves more\nthan 98% of the problem instances using Gemini 1.5 Pro without the use of a\nformal solver.",
      "tldr_zh": "本研究提出了一种名为 Mind Evolution 的进化搜索策略，用于扩展大型语言模型(LLMs)的推理时间计算。该方法利用语言模型生成、重组合和精炼候选响应，无需正式化底层推理问题，仅需解决方案评估器即可。在控制推理成本的情况下，Mind Evolution 在自然语言规划任务中显著优于 Best-of-N 和 Sequential Revision 等策略。在 TravelPlanner 和 Natural Plan 基准测试中，使用 Gemini 1.5 Pro 模型，Mind Evolution 成功解决了超过98%的实例，而无需正式求解器。",
      "categories": [
        "cs.AI"
      ],
      "primary_category": "cs.AI",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2501.09891v1",
      "published_date": "2025-01-17 00:41:44 UTC",
      "updated_date": "2025-01-17 00:41:44 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-22T00:47:07.342811"
    },
    {
      "arxiv_id": "2501.09890v1",
      "title": "Exploring the Implementation of AI in Early Onset Interviews to Help Mitigate Bias",
      "title_zh": "翻译失败",
      "authors": [
        "Nishka Lal",
        "Omar Benkraouda"
      ],
      "abstract": "This paper investigates the application of artificial intelligence (AI) in\nearly-stage recruitment interviews in order to reduce inherent bias,\nspecifically sentiment bias. Traditional interviewers are often subject to\nseveral biases, including interviewer bias, social desirability effects, and\neven confirmation bias. In turn, this leads to non-inclusive hiring practices,\nand a less diverse workforce. This study further analyzes various AI\ninterventions that are present in the marketplace today such as multimodal\nplatforms and interactive candidate assessment tools in order to gauge the\ncurrent market usage of AI in early-stage recruitment. However, this paper aims\nto use a unique AI system that was developed to transcribe and analyze\ninterview dynamics, which emphasize skill and knowledge over emotional\nsentiments. Results indicate that AI effectively minimizes sentiment-driven\nbiases by 41.2%, suggesting its revolutionizing power in companies' recruitment\nprocesses for improved equity and efficiency.",
      "tldr_zh": "本研究探讨了在早期招聘面试中使用AI来减少固有偏见，特别是sentiment bias。传统面试者常受interview bias、社会期望效应和确认偏见影响，导致招聘不包容和多样性不足；为此，论文分析了市场上的AI干预工具，如多模态平台和互动候选评估工具，并引入了一个独特AI系统，用于转录和分析面试动态，强调候选者的技能和知识而非情感因素。结果显示，该AI系统将sentiment-driven biases减少了41.2%，从而提升了招聘过程的公平性和效率。",
      "categories": [
        "cs.AI"
      ],
      "primary_category": "cs.AI",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2501.09890v1",
      "published_date": "2025-01-17 00:40:35 UTC",
      "updated_date": "2025-01-17 00:40:35 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-22T00:47:19.329787"
    }
  ],
  "raw_papers_fetched": true,
  "papers_count": 83,
  "processed_papers_count": 83,
  "failed_papers_count": 0,
  "summary_generated": true,
  "daily_data_saved": true,
  "last_update": "2025-05-22T00:47:34.396620"
}