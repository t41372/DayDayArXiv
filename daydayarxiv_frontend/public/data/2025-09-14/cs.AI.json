{
  "date": "2025-09-14",
  "category": "cs.AI",
  "summary": "æ¬¢è¿æ¥åˆ° UTC æ—¶é—´ 2025-09-14 çš„ arXiv ä¸­æ–‡ TLDR å¿«æŠ¥ï¼\n\nğŸ‘‹ **ä¸€å¥è¯æ€»ç»“ï¼š**\nä»Šå¤©çš„ arXiv å……æ»¡äº†â€œè¿›åŒ–â€çš„å‘³é“â€”â€”ä»**ç¼–è¯‘å™¨å±‚é¢çš„éšè”½åé—¨**å¸¦æ¥çš„å®‰å…¨ææ…Œï¼Œåˆ°**LLM åœ¨é‡‘èäº¤æ˜“ä¸­çš„æ·±åº¦æ¨ç†**ï¼Œå†åˆ°**å·¥ä¸šçº§æ¨¡å‹çš„è‡ªæˆ‘è¿›åŒ–**ã€‚Agent çš„åä½œæ¨¡å¼æ­£åœ¨ä»â€œå¯»æ±‚å…±è¯†â€è½¬å‘â€œè‡ªç”±è¾©è®ºâ€ï¼Œè€Œ AI for Science åœ¨è¯ç‰©å‘ç°å’Œæ°”å€™é¢„æµ‹ä¸Šç»§ç»­ç¨³æ­¥æ¨è¿›ã€‚\n\n---\n\n### ğŸš€ ç¼–è¾‘ç²¾é€‰ï¼šé‡ç£…ä¸å¿…è¯»\n*è¿™äº›è®ºæ–‡åœ¨æ–¹æ³•è®ºåˆ›æ–°æˆ–å®é™…åº”ç”¨æ½œåŠ›ä¸Šéå¸¸çªå‡ºï¼Œå»ºè®®ä¼˜å…ˆå…³æ³¨ã€‚*\n\n**1. ç¼–è¯‘å™¨æ­£åœ¨ç»™ä½ çš„æ¨¡å‹æ¤å…¥åé—¨ï¼ŸDL ç¼–è¯‘å™¨å®‰å…¨æ¼æ´**\n**# Title:** Your Compiler is Backdooring Your Model: Understanding and Exploiting Compilation Inconsistency Vulnerabilities in Deep Learning Compilers\n**# æ ¸å¿ƒçœ‹ç‚¹:** **ä¾›åº”é“¾å®‰å…¨ã€ç¼–è¯‘å™¨æ¼æ´ã€éšè”½åé—¨**\nè¿™æ˜¯ä¸€ç¯‡ä»¤äººåèƒŒå‘å‡‰çš„è®ºæ–‡ã€‚ä½œè€…å‘ç°ï¼Œç°æœ‰çš„**æ·±åº¦å­¦ä¹ ç¼–è¯‘å™¨ï¼ˆå¦‚å®˜æ–¹æœªä¿®æ”¹çš„ç‰ˆæœ¬ï¼‰**å­˜åœ¨è®¾è®¡ä¸Šçš„æ ¹æœ¬æ¼æ´ã€‚æ”»å‡»è€…å¯ä»¥æ„å»ºè‰¯æ€§æ¨¡å‹ï¼Œåœ¨ç¼–è¯‘å‰ä¸€åˆ‡æ­£å¸¸ï¼Œä½†åœ¨ç»è¿‡å®˜æ–¹ç¼–è¯‘å™¨ä¼˜åŒ–åï¼Œæ¨¡å‹çš„è¯­ä¹‰è¢«æ‚„æ‚„æ”¹å˜ï¼Œæ¿€æ´»äº†éšè”½çš„åé—¨ã€‚è¿™ç§æ”»å‡»åœ¨å•†ä¸šç¼–è¯‘å™¨å’Œç¡¬ä»¶ä¸Šå‡æœ‰æ•ˆï¼Œä¸”æ— æ³•è¢«ç°æœ‰æ£€æµ‹æ‰‹æ®µå‘ç°ã€‚\n> **Implication:** è¿™æ„å‘³ç€å³ä¾¿æ¨¡å‹æºç å’Œæƒé‡æ˜¯å¹²å‡€çš„ï¼Œç¼–è¯‘åçš„éƒ¨ç½²ç‰ˆæœ¬ä¹Ÿå¯èƒ½ä¸å®‰å…¨ï¼Œç»™ AI ä¾›åº”é“¾å®‰å…¨å¸¦æ¥äº†å…¨æ–°çš„æŒ‘æˆ˜ã€‚\n\n**2. å·¥ä¸šçº§ LLM çš„è‡ªæˆ‘è¿›åŒ–ï¼šMoE-CL æ¡†æ¶**\n**# Title:** Self-Evolving LLMs via Continual Instruction Tuning\n**# æ ¸å¿ƒçœ‹ç‚¹:** **æŒç»­å­¦ä¹ ã€Mixture-of-Experts (MoE)ã€ç¾éš¾æ€§é—å¿˜**\nåœ¨å·¥ä¸šç•Œï¼Œæ¨¡å‹éœ€è¦ä¸æ–­æ›´æ–°ä»¥é€‚åº”æ–°æ•°æ®ï¼Œä½†å®¹æ˜“å‡ºç°â€œç¾éš¾æ€§é—å¿˜â€ã€‚è…¾è®¯å›¢é˜Ÿæå‡ºäº† **MoE-CL**ï¼Œä¸€ç§ç”¨äºæŒç»­æŒ‡ä»¤å¾®è°ƒçš„å‚æ•°é«˜æ•ˆ MoE æ¡†æ¶ã€‚å®ƒé€šè¿‡â€œä¸“ç”¨ä¸“å®¶â€ä¿ç•™æ—§ä»»åŠ¡çŸ¥è¯†ï¼Œé€šè¿‡â€œå…±äº«ä¸“å®¶â€å’Œå¯¹æŠ—æ€§å­¦ä¹ å®ç°è·¨ä»»åŠ¡è¿ç§»ã€‚\n> **Implication:** åœ¨è…¾è®¯è§†é¢‘çš„å†…å®¹å®¡æ ¸ä¸šåŠ¡ä¸­ï¼Œè¯¥æ–¹æ³•å‡å°‘äº† 15.3% çš„äººå·¥æˆæœ¬ï¼Œè¯æ˜äº†å…¶åœ¨å®æˆ˜ä¸­çš„æœ‰æ•ˆæ€§ã€‚\n\n**3. ç”¨å¼ºåŒ–å­¦ä¹ æ•™ LLM åšäº¤æ˜“å‘˜ï¼šTrading-R1**\n**# Title:** Trading-R1: Financial Trading with LLM Reasoning via Reinforcement Learning\n**# æ ¸å¿ƒçœ‹ç‚¹:** **é‡‘èäº¤æ˜“ã€æ¨ç†æ¨¡å‹ã€å¼ºåŒ–å­¦ä¹ **\nä¼ ç»Ÿçš„é‡åŒ–æ¨¡å‹ç¼ºä¹è§£é‡Šæ€§ï¼Œè€Œé€šç”¨ LLM ä¸æ‡‚é£é™©æ§åˆ¶ã€‚**Trading-R1** å°†æ¨ç†èƒ½åŠ›å¼•å…¥é‡‘èäº¤æ˜“ï¼Œé€šè¿‡â€œä»æ˜“åˆ°éš¾â€çš„è¯¾ç¨‹å­¦ä¹ å’Œå¼ºåŒ–å­¦ä¹ ï¼ˆRLï¼‰ï¼Œè®©æ¨¡å‹å­¦ä¼šæ’°å†™ç»“æ„åŒ–çš„æŠ•èµ„è®ºç‚¹ã€åŸºäºäº‹å®åˆ†æå¹¶åšå‡ºç»é£é™©è°ƒæ•´çš„å†³ç­–ã€‚\n> **Implication:** è¿™æ˜¯ä¸€ä¸ªå°† Reasoning LLMï¼ˆç±»ä¼¼ o1/R1 æ€è·¯ï¼‰åº”ç”¨äºé«˜é£é™©å‚ç›´é¢†åŸŸçš„å…¸å‹æ¡ˆä¾‹ï¼Œå¼ºè°ƒäº†â€œæœ‰ä¾æ®çš„å†³ç­–â€ã€‚\n\n**4. åƒå¿ƒç†æµ‹éªŒä¸€æ ·è¯„ä¼° LLMï¼šFluid Benchmarking**\n**# Title:** Fluid Language Model Benchmarking\n**# æ ¸å¿ƒçœ‹ç‚¹:** **æ¨¡å‹è¯„ä¼°ã€é¡¹ç›®ååº”ç†è®º (IRT)ã€è‡ªé€‚åº”æµ‹è¯•**\nç°æœ‰çš„ Benchmark æ—¢è´µåˆå®¹æ˜“é¥±å’Œï¼ˆå¤§å®¶åˆ†éƒ½åˆ·å¾ˆé«˜ï¼‰ã€‚è¿™å°±å¥½æ¯”è®©å¤§å­¦ç”Ÿåšå°å­¦è¯•å·ï¼Œæµ‹ä¸å‡ºæ°´å¹³ã€‚ä½œè€…æå‡ºäº† **Fluid Benchmarking**ï¼Œå€Ÿé‰´å¿ƒç†æµ‹é‡å­¦ä¸­çš„**è®¡ç®—æœºè‡ªé€‚åº”æµ‹è¯•**æ€è·¯ï¼Œæ ¹æ®æ¨¡å‹çš„èƒ½åŠ›åŠ¨æ€é€‰æ‹©è¯„ä¼°é¢˜ç›®ã€‚\n> **Implication:** ç”¨æ›´å°‘çš„é¢˜ï¼ˆMMLU ä¸Šä»…éœ€ 1/50 çš„é¢˜ç›®é‡ï¼‰æµ‹å‡ºæ›´å‡†çš„åˆ†æ•°ï¼Œè¿™å¯èƒ½æ˜¯æœªæ¥å¤§æ¨¡å‹æ¦œå•çš„æ–°æ ‡å‡†ã€‚\n\n**5. ç§‘å­¦å®¶ç‹‚å–œï¼šä¸€é”®ç”Ÿæˆè®ºæ–‡è§†é¢‘**\n**# Title:** VideoAgent: Personalized Synthesis of Scientific Videos\n**# æ ¸å¿ƒçœ‹ç‚¹:** **å¤šæ¨¡æ€ç”Ÿæˆã€Agentic Workflowã€ç§‘å­¦ä¼ æ’­**\nè¯» Paper å¤ªç´¯ï¼Ÿ**VideoAgent** å¯ä»¥æŠŠä¸€ç¯‡å­¦æœ¯è®ºæ–‡è§£ææˆç»†ç²’åº¦çš„èµ„äº§åº“ï¼Œç„¶åæ ¹æ®ç”¨æˆ·éœ€æ±‚ç¼–æ’å™äº‹ï¼Œè‡ªåŠ¨ç”ŸæˆåŒ…å«å¹»ç¯ç‰‡å’ŒåŠ¨æ€åŠ¨ç”»çš„è§£è¯´è§†é¢‘ã€‚ä½œè€…è¿˜æäº†ä¸ª SciVidEval æ¥è¯„æµ‹ç”Ÿæˆçš„è§†é¢‘è´¨é‡ã€‚\n\n---\n\n### ğŸ¤– LLM æ¶æ„ã€Agent ä¸æ¨ç†\n*Agent ä¸å†åªæ˜¯å¬è¯çš„æ‰§è¡Œè€…ï¼Œå®ƒä»¬å¼€å§‹è¾©è®ºã€è§„åˆ’ç”šè‡³é‡æ„åº•å±‚æ³¨æ„åŠ›æœºåˆ¶ã€‚*\n\n**6. å‘Šåˆ«å’Œç¨€æ³¥ï¼šæ— éœ€å…±è¯†çš„å¤šæ™ºèƒ½ä½“è¾©è®º**\n**# Title:** Free-MAD: Consensus-Free Multi-Agent Debate\n**# Abstract:** ç°æœ‰çš„å¤šæ™ºèƒ½ä½“è¾©è®ºï¼ˆMADï¼‰å¼ºè¡Œè¦æ±‚è¾¾æˆå…±è¯†ï¼Œå®¹æ˜“å¯¼è‡´é”™è¯¯ä¼ æ’­ã€‚**Free-MAD** å¼•å…¥äº†åä»ä¼—æœºåˆ¶ï¼Œä¸éœ€è¦ Agent è¾¾æˆä¸€è‡´ï¼Œè€Œæ˜¯é€šè¿‡è¯„åˆ†æœºåˆ¶è¯„ä¼°æ•´ä¸ªè¾©è®ºè½¨è¿¹æ¥åšå†³ç­–ã€‚\n**# æ ¸å¿ƒ:** **Anti-conformityï¼ˆåä»ä¼—ï¼‰**ï¼Œå•è½®è¾©è®ºå³å¯ï¼Œçœ token ä¸”æ›´é²æ£’ã€‚\n\n**7. æ•™å¤§æ¨¡å‹å†™ RISC-V å†…æ ¸ï¼šè¿›åŒ–ç®—æ³• + LLM**\n**# Title:** Evolution of Kernels: Automated RISC-V Kernel Optimization with Large Language Models\n**# Abstract:** åœ¨ç¼ºä¹æ–‡æ¡£çš„é¢†åŸŸï¼ˆå¦‚ RISC-Vï¼‰ä¼˜åŒ–ä»£ç å¾ˆéš¾ã€‚**EoK** æ¡†æ¶æŒ–æ˜å†å²ä¼˜åŒ–åŸåˆ™ï¼Œç»“åˆ RAGï¼Œç”¨ LLM æŒ‡å¯¼è¿›åŒ–æœç´¢ï¼Œå†™å‡ºçš„å†…æ ¸ä»£ç æ¯”äººç±»ä¸“å®¶å¿« 1.27 å€ã€‚\n\n**8. æ‰©æ•£æ¨¡å‹å†™ä»£ç ï¼šæ‰“ç ´è‡ªå›å½’çš„æ·é”**\n**# Title:** Beyond Autoregression: An Empirical Study of Diffusion Large Language Models for Code Generation\n**# Abstract:** ä¼ ç»Ÿçš„è‡ªå›å½’ï¼ˆä»å·¦åˆ°å³ï¼‰å†™ä»£ç æ•ˆç‡ä½ä¸”éš¾ä»¥ä¿®æ”¹ã€‚è¿™ç¯‡è®ºæ–‡ç³»ç»Ÿç ”ç©¶äº†**æ‰©æ•£æ¨¡å‹ï¼ˆDiffusion LLMsï¼‰**åœ¨ä»£ç ç”Ÿæˆä¸­çš„è¡¨ç°ï¼Œå‘ç°å®ƒä»¬åœ¨é•¿ä»£ç ç†è§£å’Œçµæ´»æ€§ä¸Šæœ‰ç‹¬ç‰¹ä¼˜åŠ¿ã€‚\n\n**9. AQUAï¼šæ³¨æ„åŠ›æœºåˆ¶çš„â€œå‡è‚¥â€è®¡åˆ’**\n**# Title:** AQUA: Attention via QUery mAgnitudes for Memory and Compute Efficient Inference in LLMs\n**# Abstract:** å‘ç° Attention çŸ©é˜µä¸­å¾ˆå¤šè®¡ç®—æ˜¯æµªè´¹çš„ã€‚AQUA é€šè¿‡æŸ¥è¯¢å‘é‡ï¼ˆQueryï¼‰çš„å¹…åº¦åŠ¨æ€é€‰æ‹©ç¨€ç–ç»´åº¦ï¼Œåœ¨ Llama-3.1-8B ä¸Šå‡å°‘äº† 25% çš„æ³¨æ„åŠ›è®¡ç®—é‡ï¼Œå‡ ä¹ä¸æŸå¤±æ€§èƒ½ã€‚\n\n**10. æ•™ LLM åƒè§„åˆ’å™¨ä¸€æ ·æ€è€ƒ**\n**# Title:** Teaching LLMs to Plan: Logical Chain-of-Thought Instruction Tuning for Symbolic Planning\n**# Abstract:** é€šè¿‡é€»è¾‘æ€ç»´é“¾ï¼ˆLogical Chain-of-Thoughtï¼‰å¾®è°ƒ LLMï¼Œä½¿å…¶èƒ½å¤Ÿå¤„ç† PDDLï¼ˆè§„åˆ’é¢†åŸŸå®šä¹‰è¯­è¨€ï¼‰ï¼Œåœ¨æ ‡å‡†è§„åˆ’ä»»åŠ¡ä¸Šå‡†ç¡®ç‡æå‡äº† 66%ã€‚\n\n---\n\n### ğŸ§¬ AI for Science & åŒ»ç–—\n*ä»é˜¿å°”èŒ¨æµ·é»˜ç—‡çš„æ—©æœŸç­›æŸ¥åˆ°å¾®å¡‘æ–™æ±¡æŸ“çš„è¿½è¸ªã€‚*\n\n**11. ç”¨è¯­éŸ³æ£€æµ‹é˜¿å°”èŒ¨æµ·é»˜ç—‡**\n**# Title:** Designing and Evaluating a Conversational Agent for Early Detection of Alzheimer's Disease and Related Dementias\n**# Abstract:** è®¾è®¡äº†ä¸€ä¸ªè¯­éŸ³äº¤äº’ Agentï¼Œé€šè¿‡è¯±å¯¼æ‚£è€…å™è¿°æ¥æ•æ‰è®¤çŸ¥çŠ¶æ€ã€‚ä¸´åºŠéªŒè¯æ˜¾ç¤ºï¼ŒAgent æ£€æµ‹åˆ°çš„ç—‡çŠ¶ä¸ä¸“å®¶è¯Šæ–­é«˜åº¦ä¸€è‡´ï¼Œä¸”æ‚£è€…æ›´æ„¿æ„å¯¹æœ‰è€å¿ƒçš„ AI æ•å¼€å¿ƒæ‰‰ã€‚\n\n**12. é›¶æ ·æœ¬ç”Ÿæˆè¯ç‰©åˆ†å­ç‰‡æ®µ**\n**# Title:** FragmentGPT: A Unified GPT Model for Fragment Growing, Linking, and Merging in Molecular Design\n**# Abstract:** è¯ç‰©å‘ç°ä¸­çš„â€œä¹é«˜å¤§å¸ˆâ€ã€‚FragmentGPT èƒ½å¤Ÿè¿æ¥ã€åˆå¹¶åˆ†å­ç‰‡æ®µï¼Œè§£å†³ç»“æ„å†—ä½™é—®é¢˜ï¼Œç”ŸæˆåŒ–å­¦ä¸Šæœ‰æ•ˆä¸”æ»¡è¶³å¤šç›®æ ‡çš„è¯ç‰©å€™é€‰åˆ†å­ã€‚\n\n**13. è¿½è¸ªå¾®å¡‘æ–™çš„æ¯’æ€§è·¯å¾„**\n**# Title:** Decoding Plastic Toxicity: An Intelligent Framework for Conflict-Aware Relational Metapath Extraction from Scientific Abstracts\n**# Abstract:** åˆ©ç”¨ LLM ä»æµ·é‡æ‘˜è¦ä¸­æå–â€œå…³ç³»å…ƒè·¯å¾„â€ï¼Œæ„å»ºæ¯’æ€§è½¨è¿¹å›¾ï¼Œè¿½è¸ªå¾®å¡‘æ–™ä»ç¯å¢ƒåˆ°äººä½“å¥åº·çš„è¿é”ååº”ï¼Œå¹¶èƒ½å¤„ç†æ–‡çŒ®ä¸­çš„å†²çªè¯æ®ã€‚\n\n**14. é™æ°´é¢„æµ‹çš„æ··åˆä¸“å®¶æ¨¡å‹**\n**# Title:** Knowledge-Guided Adaptive Mixture of Experts for Precipitation Prediction\n**# Abstract:** å¤©æ°”é¢„æµ‹å¾ˆéš¾ï¼Œå› ä¸ºæ•°æ®æºå¤ªæ‚ï¼ˆé›·è¾¾ã€å«æ˜Ÿç­‰ï¼‰ã€‚è¿™ç¯‡è®ºæ–‡æå‡ºäº†è‡ªé€‚åº” MoE æ¨¡å‹ï¼Œè®©ä¸åŒçš„â€œä¸“å®¶â€å¤„ç†ä¸åŒçš„æ¨¡æ€æˆ–æ—¶ç©ºæ¨¡å¼ï¼Œæ˜¾è‘—æå‡äº†é™æ°´ç‡é¢„æµ‹çš„å‡†ç¡®åº¦ã€‚\n\n---\n\n### ğŸ‘ï¸ å¤šæ¨¡æ€ä¸æœºå™¨äºº\n*æœºå™¨äººå¼€å§‹æœ‰äº†â€œæƒ³è±¡åŠ›â€ï¼Œè§†é¢‘ç”Ÿæˆèµ°å‘å…¨æ™¯ã€‚*\n\n**15. å…¨æ™¯è§†é¢‘ç”Ÿæˆçš„ LoRA é€‚é…**\n**# Title:** PanoLora: Bridging Perspective and Panoramic Video Generation with LoRA Adaptation\n**# Abstract:** 360Â° å…¨æ™¯è§†é¢‘ç”Ÿæˆå¾ˆéš¾ã€‚ä½œè€…å‘ç°åˆ©ç”¨ **LoRA** å¯ä»¥æœ‰æ•ˆåœ°å°†æ™®é€šè§†è§’è§†é¢‘ç”Ÿæˆæ¨¡å‹é€‚é…åˆ°å…¨æ™¯è§†é¢‘ï¼Œä»…éœ€å°‘é‡æ•°æ®å³å¯ä¿æŒæŠ•å½±å‡ ä½•çš„æ­£ç¡®æ€§ã€‚\n\n**16. æœºå™¨äººçš„â€œç™½æ—¥æ¢¦â€å¯¼èˆª**\n**# Title:** DreamNav: A Trajectory-Based Imaginative Framework for Zero-Shot Vision-and-Language Navigation\n**# Abstract:** æå‡ºäº† **DreamNav**ï¼Œè®©æœºå™¨äººåœ¨å¯¼èˆªæ—¶å…·å¤‡â€œå‰ç»æ€§æ€è€ƒâ€ï¼ˆæƒ³è±¡é¢„æµ‹å™¨ï¼‰ï¼Œä¸å†æ˜¯èµ°ä¸€æ­¥çœ‹ä¸€æ­¥ï¼Œè€Œæ˜¯è§„åˆ’å…¨å±€è½¨è¿¹ã€‚\n\n**17. è¯­éŸ³ Tokenizer çš„æ–° SOTA**\n**# Title:** FuseCodec: Semantic-Contextual Fusion and Supervision for Neural Codecs\n**# Abstract:** æå‡ºäº† **FuseCodec**ï¼Œåœ¨è¯­éŸ³ Tokenization ä¸­èåˆäº†è¯­ä¹‰å’Œä¸Šä¸‹æ–‡ä¿¡æ¯ã€‚åœ¨ LibriSpeech æµ‹è¯•ä¸­å‡»è´¥äº† EnCodec å’Œ SpeechTokenizerï¼Œå¯¹è¯­éŸ³åˆæˆå’Œç†è§£éƒ½æœ‰å¸®åŠ©ã€‚\n\n---\n\n### ğŸ›¡ï¸ å…¶ä»–å€¼å¾—å…³æ³¨çš„è®ºæ–‡ (Quick Hits)\n\n*   **[Security] éšç§ä¸è´¨é‡çš„æƒè¡¡ (#55):** ç ”ç©¶å‘ç°ï¼Œä½¿ç”¨å·®åˆ†éšç§ï¼ˆDPï¼‰å¾®è°ƒ LLM ä¼šå¯¼è‡´ç”Ÿæˆçš„æ–‡æœ¬å˜çŸ­ã€è¯­æ³•å˜å·®ã€å¤šæ ·æ€§é™ä½ã€‚éšç§æ˜¯è¦ä»˜å‡ºä»£ä»·çš„ã€‚\n*   **[HCI/AI] èŒä¸šè§„åˆ’ AI (#2):** **CareerPooler** ç”¨å°çƒæ¸¸æˆçš„éšå–»æ¥æ¨¡æ‹ŸèŒä¸šå‘å±•ï¼Œæ¯”æ— èŠçš„èŠå¤©æœºå™¨äººæ›´èƒ½ç¼“è§£ç”¨æˆ·çš„èŒä¸šç„¦è™‘ã€‚\n*   **[Hardware] æ··åˆé‡å­ç¥ç»ç½‘ç»œ (#50):** åœ¨ MNIST ç­‰æ•°æ®é›†ä¸Šï¼Œæ··åˆé‡å­-ç»å…¸æ¨¡å‹çš„å‡†ç¡®ç‡å’Œè®­ç»ƒæ•ˆç‡å‡ä¼˜äºçº¯ç»å…¸ CNNï¼Œä¸”å‚æ•°æ›´å°‘ã€‚\n*   **[Social] ä»‡æ¨è¨€è®ºæ£€æµ‹ (#7):** è¯„æµ‹äº† 38 ç§æ¨¡å‹ï¼Œå‘ç° Transformer æ¶æ„ï¼ˆç‰¹åˆ«æ˜¯ RoBERTaï¼‰ä¾ç„¶æ˜¯ç‹è€…ï¼Œä½†ä¼ ç»Ÿçš„ CatBoost åœ¨æ€§ä»·æ¯”ä¸Šå¾ˆæœ‰ç«äº‰åŠ›ã€‚\n*   **[System] 6G ç½‘ç»œè®¾è®¡ (#35):** ä¸€ç¯‡å…³äºèƒ½æºæ„ŸçŸ¥ 6G ç½‘ç»œè®¾è®¡çš„ç»¼è¿°ï¼Œé‡ç‚¹å…³æ³¨ AI/ML åœ¨å…¶ä¸­çš„èŠ‚èƒ½ä½œç”¨ã€‚\n\n---\n**ç»“è¯­ï¼š**\nä»Šå¤©çš„è®ºæ–‡å±•ç°äº†ä¸€ä¸ªæ˜æ˜¾çš„è¶‹åŠ¿ï¼šæˆ‘ä»¬æ­£åœ¨ä»â€œè®­ç»ƒä¸€ä¸ªå¤§æ¨¡å‹â€è½¬å‘â€œå¦‚ä½•å®‰å…¨ã€é«˜æ•ˆã€ä¸“ä¸šåœ°ä½¿ç”¨å¤§æ¨¡å‹â€ã€‚æ— è®ºæ˜¯é€šè¿‡ç¼–è¯‘å™¨æ”»å‡»è¿˜æ˜¯é‡‘èäº¤æ˜“æ¨ç†ï¼ŒAI çš„è§¦è§’æ­£åœ¨ä¼¸å‘æ›´æ·±å±‚çš„ç³»ç»Ÿå’Œæ›´å¤æ‚çš„å†³ç­–ã€‚\n\nå¸Œæœ›è¿™ä»½å¿«æŠ¥å¯¹ä½ çš„ç ”ç©¶é€šè¿‡æœ‰æ‰€å¸®åŠ©ï¼æˆ‘ä»¬æ˜å¤©è§ã€‚",
  "papers": [
    {
      "arxiv_id": "2509.11478v1",
      "title": "Designing and Evaluating a Conversational Agent for Early Detection of Alzheimer's Disease and Related Dementias",
      "title_zh": "é¢å‘é˜¿å°”èŒ¨æµ·é»˜ç—…åŠç›¸å…³ç—´å‘†ç—‡æ—©æœŸæ£€æµ‹çš„å¯¹è¯å¼æ™ºèƒ½ä½“è®¾è®¡ä¸è¯„ä¼°",
      "authors": [
        "Andrew G. Breithaupt",
        "Nayoung Choi",
        "James D. Finch",
        "Jeanne M. Powell",
        "Arin L. Nelson",
        "Oz A. Alon",
        "Howard J. Rosen",
        "Jinho D. Choi"
      ],
      "abstract": "Early detection of Alzheimer's disease and related dementias (ADRD) is critical for timely intervention, yet most diagnoses are delayed until advanced stages. While comprehensive patient narratives are essential for accurate diagnosis, prior work has largely focused on screening studies that classify cognitive status from interactions rather than supporting the diagnostic process. We designed voice-interactive conversational agents, leveraging large language models (LLMs), to elicit narratives relevant to ADRD from patients and informants. We evaluated the agent with 30 adults with suspected ADRD through conversation analysis (n=30), user surveys (n=19), and clinical validation against blinded specialist interviews (n=24). Symptoms detected by the agent aligned well with those identified by specialists across symptoms. Users appreciated the agent's patience and systematic questioning, which supported engagement and expression of complex, hard-to-describe experiences. This preliminary work suggests conversational agents may serve as structured front-end tools for dementia assessment, highlighting interaction design considerations in sensitive healthcare contexts.",
      "tldr_zh": "è¯¥ç ”ç©¶é’ˆå¯¹é˜¿å°”èŒ¨æµ·é»˜ç—…åŠç›¸å…³ç—´å‘†ç—‡ (ADRD) æ—©æœŸæ£€æµ‹æ™®éæ»åçš„ç°çŠ¶ï¼Œè®¾è®¡å¹¶è¯„ä¼°äº†ä¸€ç§æ—¨åœ¨è¾…åŠ©è¯Šæ–­è¿‡ç¨‹çš„è¯­éŸ³äº¤äº’å¼å¯¹è¯æ™ºèƒ½ä½“ã€‚è¯¥æ™ºèƒ½ä½“åˆ©ç”¨å¤§è¯­è¨€æ¨¡å‹ (LLMs) æŠ€æœ¯ï¼Œé€šè¿‡ä¸æ‚£è€…åŠçŸ¥æƒ…è€…è¿›è¡Œæ·±å…¥å¯¹è¯ï¼Œæ—¨åœ¨æœ‰æ•ˆæå–ä¸ ADRD ç›¸å…³çš„ç—…å²å™è¿°ã€‚ç ”ç©¶å›¢é˜Ÿé€šè¿‡å¯¹è¯åˆ†æã€ç”¨æˆ·è°ƒæŸ¥ä»¥åŠä¸ä¸“ç§‘åŒ»ç”Ÿç›²æµ‹è®¿è°ˆçš„ä¸´åºŠéªŒè¯ï¼Œå¯¹ 30 åç–‘ä¼¼æ‚£æœ‰ ADRD çš„æˆå¹´äººè¿›è¡Œäº†ç»¼åˆè¯„ä¼°ã€‚å®éªŒç»“æœè¡¨æ˜ï¼Œè¯¥æ™ºèƒ½ä½“æ£€æµ‹åˆ°çš„ç—‡çŠ¶ä¸ä¸“ç§‘åŒ»ç”Ÿè¯†åˆ«çš„ç»“æœé«˜åº¦ä¸€è‡´ï¼Œè¯æ˜äº†å…¶åœ¨ä¸´åºŠè¯„ä¼°ä¸­çš„å‡†ç¡®æ€§ã€‚å‚ä¸è€…æ™®éèµèµè¯¥æ™ºèƒ½ä½“çš„è€å¿ƒå’Œç³»ç»ŸåŒ–æé—®ï¼Œè®¤ä¸ºè¿™æœ‰åŠ©äºä»–ä»¬æ›´å¥½åœ°è¡¨è¾¾å¤æ‚ä¸”éš¾ä»¥æè¿°çš„æ‚£ç—…ç»å†ã€‚è¿™é¡¹åˆæ­¥å·¥ä½œè¡¨æ˜ï¼Œå¯¹è¯æ™ºèƒ½ä½“å¯ä½œä¸ºç—´å‘†ç—‡è¯„ä¼°çš„ç»“æ„åŒ–å‰ç«¯å·¥å…·ï¼Œä¸ºæ•æ„ŸåŒ»ç–—åœºæ™¯ä¸‹çš„äº¤äº’è®¾è®¡å’Œæ—©æœŸè¾…åŠ©è¯Šæ–­æä¾›äº†é‡è¦å‚è€ƒã€‚",
      "categories": [
        "cs.HC",
        "cs.AI"
      ],
      "primary_category": "cs.HC",
      "comment": "First two authors contributed equally",
      "pdf_url": "https://arxiv.org/pdf/2509.11478v1",
      "published_date": "2025-09-14 23:55:01 UTC",
      "updated_date": "2025-09-14 23:55:01 UTC",
      "processing_status": "completed",
      "attempts": 1,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "llm_backup_calls": 0,
      "last_update": "2026-01-24T18:20:57.490992+00:00"
    },
    {
      "arxiv_id": "2509.11461v1",
      "title": "CareerPooler: AI-Powered Metaphorical Pool Simulation Improves Experience and Outcomes in Career Exploration",
      "title_zh": "CareerPoolerï¼šäººå·¥æ™ºèƒ½é©±åŠ¨çš„éšå–»æ€§å°çƒæ¨¡æ‹Ÿæå‡èŒä¸šæ¢ç´¢çš„ä½“éªŒä¸æˆæ•ˆ",
      "authors": [
        "Ziyi Wang",
        "Ziwen Zeng",
        "Yuan Li",
        "Zijian Ding"
      ],
      "abstract": "Career exploration is uncertain, requiring decisions with limited information and unpredictable outcomes. While generative AI offers new opportunities for career guidance, most systems rely on linear chat interfaces that produce overly comprehensive and idealized suggestions, overlooking the non-linear and effortful nature of real-world trajectories. We present CareerPooler, a generative AI-powered system that employs a pool-table metaphor to simulate career development as a spatial and narrative interaction. Users strike balls representing milestones, skills, and random events, where hints, collisions, and rebounds embody decision-making under uncertainty. In a within-subjects study with 24 participants, CareerPooler significantly improved engagement, information gain, satisfaction, and career clarity compared to a chatbot baseline. Qualitative findings show that spatial-narrative interaction fosters experience-based learning, resilience through setbacks, and reduced psychological burden. Our findings contribute to the design of AI-assisted career exploration systems and more broadly suggest that visually grounded analogical interactions can make generative systems engaging and satisfying.",
      "tldr_zh": "è¯¥ç ”ç©¶é’ˆå¯¹èŒä¸šæ¢ç´¢ï¼ˆCareer explorationï¼‰ä¸­å†³ç­–ä¸ç¡®å®šæ€§åŠä¼ ç»Ÿç”Ÿæˆå¼äººå·¥æ™ºèƒ½ï¼ˆGenerative AIï¼‰èŠå¤©ç•Œé¢è¿‡äºçº¿æ€§ä¸”ç†æƒ³åŒ–çš„é—®é¢˜ï¼Œå¼€å‘äº† CareerPooler ç³»ç»Ÿã€‚è¯¥ç³»ç»Ÿåˆ›æ–°æ€§åœ°é‡‡ç”¨å°çƒæ¡Œéšå–»ï¼ˆPool-table metaphorï¼‰ï¼Œå°†èŒä¸šå‘å±•æ¨¡æ‹Ÿä¸ºç©ºé—´ä¸å™äº‹çš„äº¤äº’è¿‡ç¨‹ï¼Œç”¨æˆ·é€šè¿‡å‡»æ‰“ä»£è¡¨é‡Œç¨‹ç¢‘ï¼ˆMilestonesï¼‰ã€æŠ€èƒ½ï¼ˆSkillsï¼‰å’Œéšæœºäº‹ä»¶ï¼ˆRandom eventsï¼‰çš„çƒä½“è¿›è¡Œæ¢ç´¢ã€‚ç³»ç»Ÿä¸­çš„ç¢°æ’ä¸åå¼¹å…·è±¡åŒ–äº†ä¸ç¡®å®šç¯å¢ƒä¸‹çš„å†³ç­–è¿‡ç¨‹ï¼Œä½¿ç”¨æˆ·èƒ½ç›´è§‚ä½“éªŒçœŸå®ä¸–ç•Œè½¨è¿¹çš„éçº¿æ€§ç‰¹å¾ã€‚é€šè¿‡å¯¹24åå‚ä¸è€…çš„å†…æµ‹ç ”ç©¶ï¼ˆWithin-subjects studyï¼‰ï¼Œç»“æœæ˜¾ç¤º CareerPooler åœ¨å‚ä¸åº¦ï¼ˆEngagementï¼‰ã€ä¿¡æ¯è·å–ï¼ˆInformation gainï¼‰ã€æ»¡æ„åº¦å’ŒèŒä¸šæ¸…æ™°åº¦ï¼ˆCareer clarityï¼‰æ–¹é¢å‡æ˜¾è‘—ä¼˜äºä¼ ç»Ÿçš„èŠå¤©æœºå™¨äººåŸºçº¿ï¼ˆChatbot baselineï¼‰ã€‚å®šæ€§åˆ†æè¡¨æ˜ï¼Œè¿™ç§ç©ºé—´å™äº‹äº¤äº’ï¼ˆSpatial-narrative interactionï¼‰ä¿ƒè¿›äº†åŸºäºç»éªŒçš„å­¦ä¹ ï¼Œå¢å¼ºäº†é¢å¯¹æŒ«æŠ˜çš„éŸ§æ€§å¹¶å‡è½»äº†å¿ƒç†è´Ÿæ‹…ã€‚è¯¥æˆæœè¯æ˜äº†è§†è§‰åŒ–çš„ç±»æ¯”äº¤äº’ï¼ˆVisually grounded analogical interactionsï¼‰èƒ½æ˜¾è‘—æå‡ AI ç³»ç»Ÿåœ¨å¤æ‚å†³ç­–å¼•å¯¼ä¸­çš„äº’åŠ¨æ€§ä¸æœ‰æ•ˆæ€§ã€‚",
      "categories": [
        "cs.HC",
        "cs.AI"
      ],
      "primary_category": "cs.HC",
      "comment": "",
      "pdf_url": "https://arxiv.org/pdf/2509.11461v1",
      "published_date": "2025-09-14 22:33:54 UTC",
      "updated_date": "2025-09-14 22:33:54 UTC",
      "processing_status": "completed",
      "attempts": 1,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "llm_backup_calls": 0,
      "last_update": "2026-01-24T18:20:55.689913+00:00"
    },
    {
      "arxiv_id": "2509.11459v1",
      "title": "Knowledge-Guided Adaptive Mixture of Experts for Precipitation Prediction",
      "title_zh": "çŸ¥è¯†å¼•å¯¼çš„è‡ªé€‚åº”æ··åˆä¸“å®¶é™æ°´é¢„æµ‹æ¨¡å‹",
      "authors": [
        "Chen Jiang",
        "Kofi Osei",
        "Sai Deepthi Yeddula",
        "Dongji Feng",
        "Wei-Shinn Ku"
      ],
      "abstract": "Accurate precipitation forecasting is indispensable in agriculture, disaster management, and sustainable strategies. However, predicting rainfall has been challenging due to the complexity of climate systems and the heterogeneous nature of multi-source observational data, including radar, satellite imagery, and surface-level measurements. The multi-source data vary in spatial and temporal resolution, and they carry domain-specific features, making it challenging for effective integration in conventional deep learning models. Previous research has explored various machine learning techniques for weather prediction; however, most struggle with the integration of data with heterogeneous modalities. To address these limitations, we propose an Adaptive Mixture of Experts (MoE) model tailored for precipitation rate prediction. Each expert within the model specializes in a specific modality or spatio-temporal pattern. We also incorporated a dynamic router that learns to assign inputs to the most relevant experts. Our results show that this modular design enhances predictive accuracy and interpretability. In addition to the modeling framework, we introduced an interactive web-based visualization tool that enables users to intuitively explore historical weather patterns over time and space. The tool was designed to support decision-making for stakeholders in climate-sensitive sectors. We evaluated our approach using a curated multimodal climate dataset capturing real-world conditions during Hurricane Ian in 2022. The benchmark results show that the Adaptive MoE significantly outperformed all the baselines.",
      "tldr_zh": "è¯¥ç ”ç©¶é’ˆå¯¹é™æ°´é¢„æµ‹ä¸­å¤šæºè§‚æµ‹æ•°æ®ï¼ˆå¦‚ radarã€satellite imagery å’Œ surface-level measurementsï¼‰å­˜åœ¨çš„å¼‚æ„æ€§åŠå¤æ‚æ°”å€™ç³»ç»Ÿæ•´åˆéš¾é¢˜ï¼Œæå‡ºäº†ä¸€ç§è‡ªé€‚åº”ä¸“å®¶æ··åˆæ¨¡å‹ Adaptive Mixture of Experts (MoE)ã€‚åœ¨è¯¥æ¡†æ¶ä¸­ï¼Œæ¯ä¸ªä¸“å®¶ï¼ˆexpertï¼‰ä¸“é—¨å¤„ç†ç‰¹å®šçš„æ•°æ®æ¨¡æ€æˆ–æ—¶ç©ºæ¨¡å¼ï¼ˆspatio-temporal patternï¼‰ï¼Œå¹¶é€šè¿‡åŠ¨æ€è·¯ç”±ï¼ˆdynamic routerï¼‰å°†è¾“å…¥åˆ†é…ç»™æœ€ç›¸å…³çš„ä¸“å®¶ã€‚å®éªŒè¯„ä¼°é‡‡ç”¨äº† 2022 å¹´é£“é£ Hurricane Ian æœŸé—´çš„çœŸå®å¤šæ¨¡æ€æ°”å€™æ•°æ®é›†ï¼Œç»“æœè¡¨æ˜ Adaptive MoE æ¨¡å‹åœ¨é¢„æµ‹å‡†ç¡®æ€§å’Œå¯è§£é‡Šæ€§æ–¹é¢å‡æ˜¾è‘—ä¼˜äºæ‰€æœ‰åŸºçº¿æ¨¡å‹ã€‚æ­¤å¤–ï¼Œç ”ç©¶è¿˜å¼€å‘äº†ä¸€ä¸ªäº¤äº’å¼ Web å¯è§†åŒ–å·¥å…·ï¼Œæ—¨åœ¨è¾…åŠ©æ°”å€™æ•æ„Ÿè¡Œä¸šçš„å†³ç­–è€…ç›´è§‚æ¢ç´¢å†å²å¤©æ°”æ¨¡å¼ã€‚è¯¥æ–¹æ³•ä¸ä»…æå‡äº†é™æ°´ç‡é¢„æµ‹çš„ç²¾åº¦ï¼Œä¹Ÿä¸ºå¤„ç†æ°”è±¡é¢†åŸŸå¼‚æ„å¤šæ¨¡æ€æ•°æ®çš„é›†æˆä¸åº”ç”¨æä¾›äº†æœ‰æ•ˆçš„è§£å†³æ–¹æ¡ˆã€‚",
      "categories": [
        "cs.AI"
      ],
      "primary_category": "cs.AI",
      "comment": "13 pages",
      "pdf_url": "https://arxiv.org/pdf/2509.11459v1",
      "published_date": "2025-09-14 22:31:46 UTC",
      "updated_date": "2025-09-14 22:31:46 UTC",
      "processing_status": "completed",
      "attempts": 1,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "llm_backup_calls": 0,
      "last_update": "2026-01-24T18:21:05.487155+00:00"
    },
    {
      "arxiv_id": "2509.13357v1",
      "title": "Semantic Fusion with Fuzzy-Membership Features for Controllable Language Modelling",
      "title_zh": "é¢å‘å¯æ§è¯­è¨€å»ºæ¨¡çš„æ¨¡ç³Šéš¶å±åº¦ç‰¹å¾è¯­ä¹‰èåˆ",
      "authors": [
        "Yongchao Huang",
        "Hassan Raza"
      ],
      "abstract": "We propose semantic fusion, a lightweight scheme that augments a Transformer language model (LM) with a parallel, fuzzy-membership feature channel that encodes token-level semantics. Each token is represented by a vector of interpretable features (e.g. part-of-speech cues, shallow roles, boundary flags, sentiment polarity and strength) whose values are graded degrees from differentiable membership functions (e.g. power kernels). These per-token vectors form a sentence-level semantic matrix fused via a gated adapter into the LM. Training uses standard next-token prediction, an auxiliary loss that reconstructs the semantic features from hidden states, and a lightweight uniformizer that regularizes adjective-class distributions. On a synthetic two-clause corpus with held-out adjectives for out-of-distribution (OOD) control, semantic fusion improves perplexity and enables precise, user-controllable generation of polarity and punctuation while maintaining model simplicity. This approach adds only small overhead, remains fully compatible with tied input-output embeddings, and provides an interpretable pathway for conditioned natural language generation.",
      "tldr_zh": "è¯¥ç ”ç©¶æå‡ºäº† Semantic Fusionï¼Œè¿™æ˜¯ä¸€ç§è½»é‡çº§æ–¹æ¡ˆï¼Œæ—¨åœ¨é€šè¿‡å¼•å…¥å¹³è¡Œçš„ Fuzzy-Membership ç‰¹å¾é€šé“æ¥å¢å¼º Transformer è¯­è¨€æ¨¡å‹ï¼ˆLMï¼‰çš„è¯­ä¹‰è¡¨ç¤ºèƒ½åŠ›ã€‚è¯¥æ–¹æ³•å°†æ¯ä¸ª Token è¡¨ç¤ºä¸ºç”±è¯æ€§æ ‡æ³¨ã€æƒ…æ„Ÿææ€§åŠå¼ºåº¦ç­‰å¯è§£é‡Šç‰¹å¾æ„æˆçš„å‘é‡ï¼Œå¹¶åˆ©ç”¨å¯å¾®åˆ†çš„éš¶å±å‡½æ•°ï¼ˆå¦‚ Power Kernelsï¼‰ç”Ÿæˆç‰¹å¾å€¼ã€‚è¿™äº›è¯­ä¹‰ç‰¹å¾é€šè¿‡ Gated Adapter èåˆè¿›æ¨¡å‹ï¼Œè®­ç»ƒè¿‡ç¨‹ç»“åˆäº† Next-Token Prediction ä»¥åŠç”¨äºé‡å»ºè¯­ä¹‰ç‰¹å¾çš„è¾…åŠ©æŸå¤±å’Œæ­£åˆ™åŒ–å½¢å®¹è¯åˆ†å¸ƒçš„ Uniformizerã€‚å®éªŒç»“æœè¡¨æ˜ï¼ŒSemantic Fusion åœ¨åˆæˆè¯­æ–™åº“åŠåˆ†å¸ƒå¤–ï¼ˆOODï¼‰æ§åˆ¶åœºæ™¯ä¸‹æ˜¾è‘—æå‡äº† Perplexityï¼Œå¹¶å®ç°äº†å¯¹æƒ…æ„Ÿææ€§å’Œæ ‡ç‚¹ç¬¦å·çš„ç²¾ç¡®å¯æ§ç”Ÿæˆã€‚è¯¥æ–¹æ³•åœ¨ä¿æŒæ¨¡å‹ç®€æ´ä¸å…¼å®¹æ€§çš„åŒæ—¶ä»…å¸¦æ¥æå°å¼€é”€ï¼Œä¸ºå—æ§è‡ªç„¶è¯­è¨€ç”Ÿæˆï¼ˆNLGï¼‰æä¾›äº†ä¸€æ¡å…·æœ‰å¯è§£é‡Šæ€§çš„å®ç°è·¯å¾„ã€‚",
      "categories": [
        "cs.AI"
      ],
      "primary_category": "cs.AI",
      "comment": "16 pages",
      "pdf_url": "https://arxiv.org/pdf/2509.13357v1",
      "published_date": "2025-09-14 22:11:09 UTC",
      "updated_date": "2025-09-14 22:11:09 UTC",
      "processing_status": "completed",
      "attempts": 1,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "llm_backup_calls": 0,
      "last_update": "2026-01-24T18:21:10.490198+00:00"
    },
    {
      "arxiv_id": "2509.11453v1",
      "title": "Beyond Frame-wise Tracking: A Trajectory-based Paradigm for Efficient Point Cloud Tracking",
      "title_zh": "è¶…è¶Šé€å¸§è·Ÿè¸ªï¼šä¸€ç§åŸºäºè½¨è¿¹çš„é«˜æ•ˆç‚¹äº‘è·Ÿè¸ªèŒƒå¼",
      "authors": [
        "BaiChen Fan",
        "Sifan Zhou",
        "Jian Li",
        "Shibo Zhao",
        "Muqing Cao",
        "Qin Wang"
      ],
      "abstract": "LiDAR-based 3D single object tracking (3D SOT) is a critical task in robotics and autonomous systems. Existing methods typically follow frame-wise motion estimation or a sequence-based paradigm. However, the two-frame methods are efficient but lack long-term temporal context, making them vulnerable in sparse or occluded scenes, while sequence-based methods that process multiple point clouds gain robustness at a significant computational cost. To resolve this dilemma, we propose a novel trajectory-based paradigm and its instantiation, TrajTrack. TrajTrack is a lightweight framework that enhances a base two-frame tracker by implicitly learning motion continuity from historical bounding box trajectories alone-without requiring additional, costly point cloud inputs. It first generates a fast, explicit motion proposal and then uses an implicit motion modeling module to predict the future trajectory, which in turn refines and corrects the initial proposal. Extensive experiments on the large-scale NuScenes benchmark show that TrajTrack achieves new state-of-the-art performance, dramatically improving tracking precision by 4.48% over a strong baseline while running at 56 FPS. Besides, we also demonstrate the strong generalizability of TrajTrack across different base trackers. Video is available at https://www.bilibili.com/video/BV1ahYgzmEWP.",
      "tldr_zh": "è¯¥ç ”ç©¶é’ˆå¯¹åŸºäº LiDAR çš„ä¸‰ç»´å•ç›®æ ‡è·Ÿè¸ª (3D SOT) ä»»åŠ¡ï¼Œæå‡ºäº†ä¸€ç§åä¸º TrajTrack çš„æ–°å‹è½¨è¿¹åŸºèŒƒå¼ï¼Œæ—¨åœ¨è§£å†³ç°æœ‰ä¸¤å¸§æ–¹æ³•ç¼ºä¹æ—¶åºä¸Šä¸‹æ–‡ä¸åºåˆ—æ–¹æ³•è®¡ç®—å¼€é”€è¿‡å¤§ä¹‹é—´çš„çŸ›ç›¾ã€‚TrajTrack ä½œä¸ºä¸€ä¸ªè½»é‡çº§æ¡†æ¶ï¼Œé€šè¿‡ä»…ä»å†å²è¾¹ç•Œæ¡†è½¨è¿¹ä¸­éšå¼å­¦ä¹ è¿åŠ¨è¿ç»­æ€§æ¥å¢å¼ºåŸºç¡€çš„åŒå¸§è·Ÿè¸ªå™¨ï¼Œè€Œæ— éœ€å¼•å…¥é¢å¤–çš„ç‚¹äº‘è¾“å…¥ã€‚å…¶æ ¸å¿ƒæœºåˆ¶åœ¨äºé¦–å…ˆç”Ÿæˆæ˜¾å¼è¿åŠ¨å»ºè®®ï¼Œéšååˆ©ç”¨éšå¼è¿åŠ¨å»ºæ¨¡æ¨¡å—é¢„æµ‹æœªæ¥è½¨è¿¹ï¼Œä»¥å®ç°å¯¹åˆå§‹é¢„æµ‹çš„ç²¾ç»†ä¿®æ­£ã€‚åœ¨å¤§è§„æ¨¡æ•°æ®é›† NuScenes ä¸Šçš„å®éªŒè¯æ˜ï¼Œè¯¥æ–¹æ³•åœ¨ä¿æŒ 56 FPS é«˜å®æ—¶æ€§èƒ½çš„åŒæ—¶ï¼Œå°†è·Ÿè¸ªç²¾åº¦è¾ƒå¼ºåŸºçº¿æå‡äº† 4.48%ï¼Œåˆ·æ–°äº† SOTA æ€§èƒ½ã€‚æ­¤å¤–ï¼ŒTrajTrack è¿˜å±•ç°å‡ºäº†åœ¨å¤šç§åŸºç¡€è·Ÿè¸ªå™¨ä¸Šçš„å¼ºé€šç”¨æ€§ (Generalizability)ï¼Œä¸ºæœºå™¨äººå’Œè‡ªåŠ¨é©¾é©¶ç³»ç»Ÿä¸­çš„é«˜æ•ˆç‰©ä½“è·Ÿè¸ªæä¾›äº†æœ‰æ•ˆè·¯å¾„ã€‚",
      "categories": [
        "cs.CV",
        "cs.AI",
        "cs.RO"
      ],
      "primary_category": "cs.CV",
      "comment": "9 pages, 7 figures",
      "pdf_url": "https://arxiv.org/pdf/2509.11453v1",
      "published_date": "2025-09-14 21:57:16 UTC",
      "updated_date": "2025-09-14 21:57:16 UTC",
      "processing_status": "completed",
      "attempts": 1,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "llm_backup_calls": 0,
      "last_update": "2026-01-24T18:21:13.081685+00:00"
    },
    {
      "arxiv_id": "2509.11449v1",
      "title": "Tabular Data with Class Imbalance: Predicting Electric Vehicle Crash Severity with Pretrained Transformers (TabPFN) and Mamba-Based Models",
      "title_zh": "ç±»åˆ«ä¸å¹³è¡¡è¡¨æ ¼æ•°æ®ä¸‹çš„ç”µåŠ¨æ±½è½¦ç¢°æ’ä¸¥é‡ç¨‹åº¦é¢„æµ‹ï¼šåŸºäºé¢„è®­ç»ƒ Transformer (TabPFN) ä¸ Mamba æ¨¡å‹",
      "authors": [
        "Shriyank Somvanshi",
        "Pavan Hebli",
        "Gaurab Chhetri",
        "Subasish Das"
      ],
      "abstract": "This study presents a deep tabular learning framework for predicting crash severity in electric vehicle (EV) collisions using real-world crash data from Texas (2017-2023). After filtering for electric-only vehicles, 23,301 EV-involved crash records were analyzed. Feature importance techniques using XGBoost and Random Forest identified intersection relation, first harmful event, person age, crash speed limit, and day of week as the top predictors, along with advanced safety features like automatic emergency braking. To address class imbalance, Synthetic Minority Over-sampling Technique and Edited Nearest Neighbors (SMOTEENN) resampling was applied. Three state-of-the-art deep tabular models, TabPFN, MambaNet, and MambaAttention, were benchmarked for severity prediction. While TabPFN demonstrated strong generalization, MambaAttention achieved superior performance in classifying severe injury cases due to its attention-based feature reweighting. The findings highlight the potential of deep tabular architectures for improving crash severity prediction and enabling data-driven safety interventions in EV crash contexts.",
      "tldr_zh": "è¯¥ç ”ç©¶æå‡ºäº†ä¸€ä¸ªæ·±åº¦è¡¨æ ¼å­¦ä¹ æ¡†æ¶ï¼Œæ—¨åœ¨åˆ©ç”¨2017å¹´è‡³2023å¹´å¾·å…‹è¨æ–¯å·çš„çœŸå®ç¢°æ’æ•°æ®é¢„æµ‹ç”µåŠ¨æ±½è½¦(EV)ç¢°æ’çš„ä¸¥é‡ç¨‹åº¦ã€‚é€šè¿‡XGBoostå’ŒRandom Forestç‰¹å¾é‡è¦æ€§æŠ€æœ¯ï¼Œç ”ç©¶è¯†åˆ«äº†äº¤å‰å£å…³ç³»ã€é¦–ä¸ªæœ‰å®³äº‹ä»¶åŠè½¦é€Ÿé™åˆ¶ç­‰å…³é”®é¢„æµ‹æŒ‡æ ‡ï¼Œå¹¶é‡‡ç”¨SMOTEENNé‡é‡‡æ ·æŠ€æœ¯å¤„ç†ç±»åˆ«ä¸å¹³è¡¡é—®é¢˜ã€‚å®éªŒè¯„ä¼°äº†TabPFNã€MambaNetå’ŒMambaAttentionä¸‰ç§å‰æ²¿æ¨¡å‹ï¼Œç»“æœæ˜¾ç¤ºTabPFNå…·æœ‰å¼ºå¤§çš„æ³›åŒ–èƒ½åŠ›ï¼Œè€ŒMambaAttentionå‡­å€Ÿå…¶åŸºäºæ³¨æ„åŠ›æœºåˆ¶çš„ç‰¹å¾é‡æƒåŒ–åœ¨é‡ä¼¤æ¡ˆä¾‹åˆ†ç±»ä¸­è¡¨ç°æœ€ä¼˜ã€‚è¯¥ç ”ç©¶ç»“æœè¯æ˜äº†æ·±åº¦è¡¨æ ¼æ¶æ„åœ¨æå‡ç¢°æ’ä¸¥é‡ç¨‹åº¦é¢„æµ‹ç²¾åº¦ä»¥åŠæ”¯æŒç”µåŠ¨æ±½è½¦å®‰å…¨å¹²é¢„å†³ç­–æ–¹é¢çš„åº”ç”¨æ½œåŠ›ã€‚",
      "categories": [
        "cs.LG",
        "cs.AI"
      ],
      "primary_category": "cs.LG",
      "comment": "This is the author's preprint version of a paper accepted for presentation at the 24th International Conference on Machine Learning and Applications (ICMLA 2025), December 3-5, 2025, Florida, USA. The final published version will appear in the official IEEE proceedings. Conference site: https://www.icmla-conference.org/icmla25/",
      "pdf_url": "https://arxiv.org/pdf/2509.11449v1",
      "published_date": "2025-09-14 21:46:17 UTC",
      "updated_date": "2025-09-14 21:46:17 UTC",
      "processing_status": "completed",
      "attempts": 1,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "llm_backup_calls": 0,
      "last_update": "2026-01-24T18:21:19.092503+00:00"
    },
    {
      "arxiv_id": "2509.14266v1",
      "title": "Efficient Hate Speech Detection: Evaluating 38 Models from Traditional Methods to Transformers",
      "title_zh": "é«˜æ•ˆä»‡æ¨è¨€è®ºæ£€æµ‹ï¼šè¯„ä¼°ä»ä¼ ç»Ÿæ–¹æ³•åˆ° Transformer çš„ 38 ç§æ¨¡å‹",
      "authors": [
        "Mahmoud Abusaqer",
        "Jamil Saquer",
        "Hazim Shatnawi"
      ],
      "abstract": "The proliferation of hate speech on social media necessitates automated detection systems that balance accuracy with computational efficiency. This study evaluates 38 model configurations in detecting hate speech across datasets ranging from 6.5K to 451K samples. We analyze transformer architectures (e.g., BERT, RoBERTa, Distil-BERT), deep neural networks (e.g., CNN, LSTM, GRU, Hierarchical Attention Networks), and traditional machine learning methods (e.g., SVM, CatBoost, Random Forest). Our results show that transformers, particularly RoBERTa, consistently achieve superior performance with accuracy and F1-scores exceeding 90%. Among deep learning approaches, Hierarchical Attention Networks yield the best results, while traditional methods like CatBoost and SVM remain competitive, achieving F1-scores above 88% with significantly lower computational costs. Additionally, our analysis highlights the importance of dataset characteristics, with balanced, moderately sized unprocessed datasets outperforming larger, preprocessed datasets. These findings offer valuable insights for developing efficient and effective hate speech detection systems.",
      "tldr_zh": "è¯¥ç ”ç©¶é’ˆå¯¹ç¤¾äº¤åª’ä½“ä¸Šä»‡æ¨è¨€è®ºæ£€æµ‹çš„å‡†ç¡®æ€§ä¸è®¡ç®—æ•ˆç‡å¹³è¡¡é—®é¢˜ï¼Œè¯„ä¼°äº†ä»ä¼ ç»Ÿæœºå™¨å­¦ä¹ æ–¹æ³•åˆ°Transformeræ¶æ„çš„38ç§æ¨¡å‹é…ç½®ã€‚è¯„ä¼°æ¶µç›–äº†BERTã€RoBERTaã€Distil-BERTç­‰Transformeræ¨¡å‹ï¼ŒCNNã€LSTMã€GRUã€Hierarchical Attention Networksç­‰æ·±åº¦ç¥ç»ç½‘ç»œï¼Œä»¥åŠSVMã€CatBoostã€Random Forestç­‰ä¼ ç»Ÿæ–¹æ³•ã€‚å®éªŒç»“æœæ˜¾ç¤ºï¼ŒRoBERTaåœ¨å‡†ç¡®ç‡å’ŒF1-scoresä¸Šè¡¨ç°æœ€ä¼˜ï¼Œå‡è¶…è¿‡90%ï¼›è€Œåœ¨æ·±åº¦å­¦ä¹ æ¨¡å‹ä¸­ï¼ŒHierarchical Attention Networksæ•ˆæœæœ€å¥½ã€‚CatBoostå’ŒSVMç­‰ä¼ ç»Ÿæ–¹æ³•åœ¨ä¿æŒF1-scoresè¶…è¿‡88%çš„åŒæ—¶ï¼Œå…·æœ‰æ˜¾è‘—çš„è®¡ç®—æˆæœ¬ä¼˜åŠ¿ã€‚ç ”ç©¶è¿˜å‘ç°æ•°æ®é›†ç‰¹å¾å¯¹æ€§èƒ½å½±å“é‡å¤§ï¼Œå‡è¡¡ä¸”é€‚åº¦è§„æ¨¡çš„æœªå¤„ç†æ•°æ®é›†è¡¨ç°ä¼˜äºç»è¿‡é¢„å¤„ç†çš„å¤§å‹æ•°æ®é›†ã€‚è¿™äº›å‘ç°ä¸ºå¼€å‘é«˜æ•ˆä¸”å®ç”¨çš„ä»‡æ¨è¨€è®ºæ£€æµ‹ç³»ç»Ÿæä¾›äº†é‡è¦å‚è€ƒã€‚",
      "categories": [
        "cs.CL",
        "cs.AI",
        "cs.SI"
      ],
      "primary_category": "cs.CL",
      "comment": "11 pages, 10 tables, conference paper",
      "pdf_url": "https://arxiv.org/pdf/2509.14266v1",
      "published_date": "2025-09-14 21:17:04 UTC",
      "updated_date": "2025-09-14 21:17:04 UTC",
      "processing_status": "completed",
      "attempts": 1,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "llm_backup_calls": 0,
      "last_update": "2026-01-24T18:22:11.992356+00:00"
    },
    {
      "arxiv_id": "2509.11431v1",
      "title": "Securing AI Agents: Implementing Role-Based Access Control for Industrial Applications",
      "title_zh": "ä¿éšœ AI æ™ºèƒ½ä½“å®‰å…¨ï¼šå·¥ä¸šåº”ç”¨ä¸­åŸºäºè§’è‰²çš„è®¿é—®æ§åˆ¶å®ç°",
      "authors": [
        "Aadil Gani Ganie"
      ],
      "abstract": "The emergence of Large Language Models (LLMs) has significantly advanced solutions across various domains, from political science to software development. However, these models are constrained by their training data, which is static and limited to information available up to a specific date. Additionally, their generalized nature often necessitates fine-tuning -- whether for classification or instructional purposes -- to effectively perform specific downstream tasks. AI agents, leveraging LLMs as their core, mitigate some of these limitations by accessing external tools and real-time data, enabling applications such as live weather reporting and data analysis. In industrial settings, AI agents are transforming operations by enhancing decision-making, predictive maintenance, and process optimization. For example, in manufacturing, AI agents enable near-autonomous systems that boost productivity and support real-time decision-making. Despite these advancements, AI agents remain vulnerable to security threats, including prompt injection attacks, which pose significant risks to their integrity and reliability. To address these challenges, this paper proposes a framework for integrating Role-Based Access Control (RBAC) into AI agents, providing a robust security guardrail. This framework aims to support the effective and scalable deployment of AI agents, with a focus on on-premises implementations.",
      "tldr_zh": "è¯¥ç ”ç©¶æ¢è®¨äº† AI æ™ºèƒ½ä½“ï¼ˆAI agentsï¼‰åˆ©ç”¨å¤§è¯­è¨€æ¨¡å‹ï¼ˆLLMsï¼‰å’Œå®æ—¶æ•°æ®åœ¨æå‡å·¥ä¸šå†³ç­–åŠç”Ÿäº§æ•ˆç‡æ–¹é¢çš„å…³é”®ä½œç”¨ï¼ŒåŒæ—¶æŒ‡å‡ºå…¶æ­£é¢ä¸´æç¤ºè¯æ³¨å…¥æ”»å‡»ï¼ˆprompt injection attacksï¼‰ç­‰ä¸¥å³»å®‰å…¨å¨èƒã€‚ä¸ºä¿éšœç³»ç»Ÿå®Œæ•´æ€§ï¼Œæœ¬æ–‡æå‡ºäº†ä¸€ç§é›†æˆåŸºäºè§’è‰²çš„è®¿é—®æ§åˆ¶ï¼ˆRole-Based Access Control, RBACï¼‰çš„å®‰å…¨æ¡†æ¶ï¼Œæ—¨åœ¨ä¸ºæ™ºèƒ½ä½“æ„å»ºç¨³å¥çš„å®‰å…¨æŠ¤æ ï¼ˆsecurity guardrailï¼‰ã€‚è¯¥æ¡†æ¶é‡ç‚¹å…³æ³¨æœ¬åœ°éƒ¨ç½²ï¼ˆon-premises implementationsï¼‰åœºæ™¯ï¼Œæ—¨åœ¨è§£å†³ AI æ™ºèƒ½ä½“åœ¨å·¥ä¸šç¯å¢ƒä¸­åº”ç”¨çš„å¯æ‰©å±•æ€§ä¸å®‰å…¨æ€§é—®é¢˜ã€‚é€šè¿‡å®æ–½ RBAC æœºåˆ¶ï¼Œè¯¥ç ”ç©¶ä¸ºå®ç°å¯ä¿¡çš„è‡ªä¸»ç³»ç»Ÿæä¾›äº†ç†è®ºæ”¯æŒä¸æŠ€æœ¯è·¯å¾„ï¼Œç¡®ä¿äº†å·¥ä¸šçº§ AI æ™ºèƒ½ä½“èƒ½å¤Ÿå®‰å…¨åœ°æ‰§è¡Œé¢„æµ‹æ€§ç»´æŠ¤å’Œæµç¨‹ä¼˜åŒ–ç­‰å¤æ‚ä»»åŠ¡ã€‚",
      "categories": [
        "cs.AI",
        "cs.CL"
      ],
      "primary_category": "cs.AI",
      "comment": "",
      "pdf_url": "https://arxiv.org/pdf/2509.11431v1",
      "published_date": "2025-09-14 20:58:08 UTC",
      "updated_date": "2025-09-14 20:58:08 UTC",
      "processing_status": "completed",
      "attempts": 1,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "llm_backup_calls": 0,
      "last_update": "2026-01-24T18:21:23.961814+00:00"
    },
    {
      "arxiv_id": "2509.11425v2",
      "title": "FuseCodec: Semantic-Contextual Fusion and Supervision for Neural Codecs",
      "title_zh": "FuseCodecï¼šé¢å‘ç¥ç»ç¼–è§£ç å™¨çš„è¯­ä¹‰-ä¸Šä¸‹æ–‡èåˆä¸ç›‘ç£",
      "authors": [
        "Md Mubtasim Ahasan",
        "Rafat Hasan Khan",
        "Tasnim Mohiuddin",
        "Aman Chadha",
        "Tariq Iqbal",
        "M Ashraful Amin",
        "Amin Ahsan Ali",
        "Md Mofijul Islam",
        "A K M Mahbubur Rahman"
      ],
      "abstract": "Speech tokenization enables discrete representation and facilitates speech language modeling. However, existing neural codecs capture low-level acoustic features, overlooking the semantic and contextual cues inherent to human speech. While recent efforts introduced semantic representations from self-supervised speech models or incorporated contextual representations from pre-trained language models, challenges remain in aligning and unifying the semantic and contextual representations. We introduce FuseCodec, which unifies acoustic, semantic, and contextual representations through strong cross-modal alignment and globally informed supervision. We propose three complementary techniques: (i) Latent Representation Fusion, integrating semantic and contextual features directly into the encoder latent space for robust and unified representation learning; (ii) Global Semantic-Contextual Supervision, supervising discrete tokens with globally pooled and broadcasted representations to enhance temporal consistency and cross-modal alignment; and (iii) Temporally Aligned Contextual Supervision, strengthening alignment by dynamically matching contextual and speech tokens within a local window for fine-grained token-level supervision. We further introduce FuseCodec-TTS, demonstrating our methodology's applicability to zero-shot speech synthesis. Empirically, FuseCodec achieves state-of-the-art performance in LibriSpeech, surpassing EnCodec, SpeechTokenizer, and DAC in transcription accuracy, perceptual quality, intelligibility, and speaker similarity. Results highlight the effectiveness of contextually and semantically guided tokenization for speech tokenization and downstream tasks. Code and pretrained models are available at https://github.com/mubtasimahasan/FuseCodec.",
      "tldr_zh": "è¯¥ç ”ç©¶æå‡ºäº† FuseCodecï¼Œä¸€ç§æ—¨åœ¨ç»Ÿä¸€ acousticã€semantic å’Œ contextual è¡¨å¾çš„ neural codec æ¡†æ¶ï¼Œè§£å†³äº†ç°æœ‰æ¨¡å‹åœ¨æ•æ‰äººç±»è¯­éŸ³è¯­ä¹‰å’Œè¯­å¢ƒçº¿ç´¢æ–¹é¢çš„ä¸è¶³ã€‚è¯¥æ¡†æ¶æ ¸å¿ƒåŒ…å« Latent Representation Fusion æŠ€æœ¯ï¼Œå°†è¯­ä¹‰å’Œè¯­å¢ƒç‰¹å¾ç›´æ¥æ•´åˆè‡³ç¼–ç å™¨æ½œç©ºé—´ä»¥å®ç°ç»Ÿä¸€è¡¨å¾ã€‚åŒæ—¶ï¼Œé€šè¿‡ Global Semantic-Contextual Supervision å¢å¼ºæ—¶é—´ä¸€è‡´æ€§ä¸è·¨æ¨¡æ€å¯¹é½ï¼Œå¹¶åˆ©ç”¨ Temporally Aligned Contextual Supervision åœ¨å±€éƒ¨çª—å£å†…å®ç°ç»†ç²’åº¦çš„ token çº§ç›‘ç£ã€‚ç ”ç©¶å›¢é˜Ÿè¿›ä¸€æ­¥å¼€å‘äº† FuseCodec-TTSï¼ŒéªŒè¯äº†è¯¥æ–¹æ³•åœ¨ zero-shot speech synthesis ä»»åŠ¡ä¸­çš„é€‚ç”¨æ€§ã€‚å®éªŒç»“æœæ˜¾ç¤ºï¼ŒFuseCodec åœ¨ LibriSpeech æ•°æ®é›†ä¸Šå…¨é¢è¶…è¶Šäº† EnCodecã€SpeechTokenizer å’Œ DACï¼Œåœ¨è½¬å½•å‡†ç¡®ç‡ã€æ„ŸçŸ¥è´¨é‡åŠè¯´è¯äººç›¸ä¼¼åº¦ç­‰æ–¹é¢å‡è¾¾åˆ° state-of-the-art æ°´å¹³ã€‚è¿™ä¸€æˆæœè¯æ˜äº† contextually and semantically guided tokenization å¯¹äºä¼˜åŒ–è¯­éŸ³åˆ†è¯åŠä¸‹æ¸¸ä»»åŠ¡æ€§èƒ½çš„æ˜¾è‘—ä»·å€¼ã€‚",
      "categories": [
        "cs.SD",
        "cs.AI",
        "cs.CL",
        "eess.AS"
      ],
      "primary_category": "cs.SD",
      "comment": "",
      "pdf_url": "https://arxiv.org/pdf/2509.11425v2",
      "published_date": "2025-09-14 20:35:36 UTC",
      "updated_date": "2025-09-29 08:43:07 UTC",
      "processing_status": "completed",
      "attempts": 1,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "llm_backup_calls": 0,
      "last_update": "2026-01-24T18:21:34.494157+00:00"
    },
    {
      "arxiv_id": "2509.11420v1",
      "title": "Trading-R1: Financial Trading with LLM Reasoning via Reinforcement Learning",
      "title_zh": "Trading-R1ï¼šåŸºäºå¼ºåŒ–å­¦ä¹ çš„å¤§è¯­è¨€æ¨¡å‹æ¨ç†é‡‘èäº¤æ˜“",
      "authors": [
        "Yijia Xiao",
        "Edward Sun",
        "Tong Chen",
        "Fang Wu",
        "Di Luo",
        "Wei Wang"
      ],
      "abstract": "Developing professional, structured reasoning on par with human financial analysts and traders remains a central challenge in AI for finance, where markets demand interpretability and trust. Traditional time-series models lack explainability, while LLMs face challenges in turning natural-language analysis into disciplined, executable trades. Although reasoning LLMs have advanced in step-by-step planning and verification, their application to risk-sensitive financial decisions is underexplored. We present Trading-R1, a financially-aware model that incorporates strategic thinking and planning for comprehensive thesis composition, facts-grounded analysis, and volatility-adjusted decision making. Trading-R1 aligns reasoning with trading principles through supervised fine-tuning and reinforcement learning with a three-stage easy-to-hard curriculum. Training uses Tauric-TR1-DB, a 100k-sample corpus spanning 18 months, 14 equities, and five heterogeneous financial data sources. Evaluated on six major equities and ETFs, Trading-R1 demonstrates improved risk-adjusted returns and lower drawdowns compared to both open-source and proprietary instruction-following models as well as reasoning models. The system generates structured, evidence-based investment theses that support disciplined and interpretable trading decisions. Trading-R1 Terminal will be released at https://github.com/TauricResearch/Trading-R1.",
      "tldr_zh": "è¯¥ç ”ç©¶æå‡ºäº†Trading-R1ï¼Œæ—¨åœ¨è§£å†³ä¼ ç»Ÿæ—¶é—´åºåˆ—æ¨¡å‹ç¼ºä¹è§£é‡Šæ€§ä»¥åŠå¤§è¯­è¨€æ¨¡å‹(LLMs)éš¾ä»¥å°†è‡ªç„¶è¯­è¨€åˆ†æè½¬åŒ–ä¸ºè§„èŒƒäº¤æ˜“æ‰§è¡Œçš„é—®é¢˜ã€‚è¯¥æ¨¡å‹é€šè¿‡ç›‘ç£å¾®è°ƒ(Supervised Fine-Tuning)å’Œå¼ºåŒ–å­¦ä¹ (Reinforcement Learning)ï¼Œå¹¶ç»“åˆä¸‰é˜¶æ®µç”±æ˜“åˆ°éš¾çš„è¯¾ç¨‹å­¦ä¹ (Curriculum learning)ï¼Œå°†é‡‘èäº¤æ˜“åŸåˆ™ä¸æ¨ç†è¿‡ç¨‹æœ‰æ•ˆå¯¹é½ã€‚æ¨¡å‹è®­ç»ƒåŸºäºTauric-TR1-DBæ•°æ®é›†ï¼Œæ¶µç›–äº†18ä¸ªæœˆã€14ç§è‚¡ç¥¨ä»¥åŠ5ç§å¼‚æ„é‡‘èæ•°æ®æºã€‚Trading-R1å…·å¤‡æˆ˜ç•¥æ€§æ€ç»´å’Œè§„åˆ’èƒ½åŠ›ï¼Œèƒ½å¤Ÿç”ŸæˆåŸºäºäº‹å®çš„åˆ†ææŠ¥å‘Šï¼Œå¹¶æ ¹æ®æ³¢åŠ¨ç‡è°ƒæ•´(Volatility-adjusted)åšå‡ºå†³ç­–ã€‚åœ¨å¯¹å…­ç§ä¸»è¦è‚¡ç¥¨å’ŒETFçš„è¯„ä¼°ä¸­ï¼ŒTrading-R1åœ¨é£é™©è°ƒæ•´æ”¶ç›Š(Risk-adjusted returns)å’Œå›æ’¤æ§åˆ¶æ–¹é¢å‡ä¼˜äºä¸»æµçš„å¼€æºåŠç§æœ‰æ¨ç†æ¨¡å‹ã€‚è¯¥ç³»ç»Ÿç”Ÿæˆçš„ç»“æ„åŒ–ã€åŸºäºè¯æ®çš„æŠ•èµ„è®ºç‚¹(Investment theses)ä¸ºæ„å»ºå¯è§£é‡Šä¸”çºªå¾‹åŒ–çš„é‡‘èäº¤æ˜“å†³ç­–æä¾›äº†é‡è¦å‚è€ƒã€‚",
      "categories": [
        "q-fin.TR",
        "cs.AI",
        "cs.CE",
        "cs.CL",
        "cs.LG"
      ],
      "primary_category": "q-fin.TR",
      "comment": "Tauric Research: https://github.com/TauricResearch",
      "pdf_url": "https://arxiv.org/pdf/2509.11420v1",
      "published_date": "2025-09-14 20:13:41 UTC",
      "updated_date": "2025-09-14 20:13:41 UTC",
      "processing_status": "completed",
      "attempts": 1,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "llm_backup_calls": 0,
      "last_update": "2026-01-24T18:21:35.790179+00:00"
    },
    {
      "arxiv_id": "2509.11417v2",
      "title": "Enhancing Generalization in Vision-Language-Action Models by Preserving Pretrained Representations",
      "title_zh": "é€šè¿‡ä¿ç•™é¢„è®­ç»ƒè¡¨ç¤ºå¢å¼ºè§†è§‰-è¯­è¨€-åŠ¨ä½œæ¨¡å‹çš„æ³›åŒ–èƒ½åŠ›",
      "authors": [
        "Shresth Grover",
        "Akshay Gopalkrishnan",
        "Bo Ai",
        "Henrik I. Christensen",
        "Hao Su",
        "Xuanlin Li"
      ],
      "abstract": "Vision-language-action (VLA) models finetuned from vision-language models (VLMs) hold the promise of leveraging rich pretrained representations to build generalist robots across diverse tasks and environments. However, direct fine-tuning on robot data often disrupts these representations and limits generalization. We present a framework that better preserves pretrained features while adapting them for robot manipulation. Our approach introduces three components: (i) a dual-encoder design with one frozen vision encoder to retain pretrained features and another trainable for task adaptation, (ii) a string-based action tokenizer that casts continuous actions into character sequences aligned with the model's pretraining domain, and (iii) a co-training strategy that combines robot demonstrations with vision-language datasets emphasizing spatial reasoning and affordances. Evaluations in simulation and on real robots show that our method improves robustness to visual perturbations, generalization to novel instructions and environments, and overall task success compared to baselines.",
      "tldr_zh": "è¯¥ç ”ç©¶æ—¨åœ¨é€šè¿‡ä¿ç•™é¢„è®­ç»ƒè¡¨ç¤ºæ¥å¢å¼ºè§†è§‰-è¯­è¨€-åŠ¨ä½œæ¨¡å‹(Vision-Language-Action Models, VLA)åœ¨æœºå™¨äººæ“ä½œä»»åŠ¡ä¸­çš„æ³›åŒ–èƒ½åŠ›ã€‚é’ˆå¯¹ç›´æ¥å¾®è°ƒVision-Language Models(VLMs)ä¼šç ´åå…¶é¢„è®­ç»ƒç‰¹å¾çš„é—®é¢˜ï¼Œä½œè€…æå‡ºäº†ä¸€ç§ç»“åˆåŒç¼–ç å™¨(Dual-encoder)è®¾è®¡çš„æ–°æ¡†æ¶ï¼Œåˆ©ç”¨å†»ç»“çš„è§†è§‰ç¼–ç å™¨ä¿ç•™åŸå§‹è¡¨ç¤ºã€‚åŒæ—¶ï¼Œç ”ç©¶å¼•å…¥äº†åŸºäºå­—ç¬¦ä¸²çš„åŠ¨ä½œåˆ†è¯å™¨(Action Tokenizer)å°†è¿ç»­åŠ¨ä½œè½¬åŒ–ä¸ºå­—ç¬¦åºåˆ—ï¼Œå¹¶é‡‡ç”¨å…±åŒè®­ç»ƒ(Co-training)ç­–ç•¥æ•´åˆè§†è§‰è¯­è¨€æ•°æ®ä»¥å¼ºåŒ–ç©ºé—´æ¨ç†ä¸å¯ä¾›æ€§(Affordances)è®¤çŸ¥ã€‚å®éªŒç»“æœè¡¨æ˜ï¼Œè¯¥æ–¹æ³•åœ¨æ¨¡æ‹Ÿå’ŒçœŸå®æœºå™¨äººæµ‹è¯•ä¸­æ˜¾è‘—æå‡äº†æ¨¡å‹å¯¹è§†è§‰æ‰°åŠ¨çš„é²æ£’æ€§ï¼Œå¹¶åœ¨å¤„ç†æ–°æŒ‡ä»¤å’Œæ–°ç¯å¢ƒæ—¶å±•ç°å‡ºæ›´ä¼˜çš„æ³›åŒ–è¡¨ç°å’Œä»»åŠ¡æˆåŠŸç‡ã€‚",
      "categories": [
        "cs.RO",
        "cs.AI",
        "cs.CV",
        "cs.LG"
      ],
      "primary_category": "cs.RO",
      "comment": "Project Page: https://gen-vla.github.io/",
      "pdf_url": "https://arxiv.org/pdf/2509.11417v2",
      "published_date": "2025-09-14 20:08:56 UTC",
      "updated_date": "2025-09-17 02:41:34 UTC",
      "processing_status": "completed",
      "attempts": 1,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "llm_backup_calls": 0,
      "last_update": "2026-01-24T18:22:39.690416+00:00"
    },
    {
      "arxiv_id": "2509.11413v1",
      "title": "Framing AI System Benchmarking as a Learning Task: FlexBench and the Open MLPerf Dataset",
      "title_zh": "å°† AI ç³»ç»ŸåŸºå‡†æµ‹è¯•æ„å»ºä¸ºå­¦ä¹ ä»»åŠ¡ï¼šFlexBench ä¸ Open MLPerf æ•°æ®é›†",
      "authors": [
        "Grigori Fursin",
        "Daniel Altunay"
      ],
      "abstract": "Existing AI system benchmarks such as MLPerf often struggle to keep pace with the rapidly evolving AI landscape, making it difficult to support informed deployment, optimization, and co-design decisions for AI systems. We suggest that benchmarking itself can be framed as an AI task - one in which models are continuously evaluated and optimized across diverse datasets, software, and hardware, using key metrics such as accuracy, latency, throughput, energy consumption, and cost. To support this perspective, we present FlexBench: a modular extension of the MLPerf LLM inference benchmark, integrated with HuggingFace and designed to provide relevant and actionable insights. Benchmarking results and metadata are collected into an Open MLPerf Dataset, which can be collaboratively curated, extended, and leveraged for predictive modeling and feature engineering. We successfully validated the FlexBench concept through MLPerf Inference submissions, including evaluations of DeepSeek R1 and LLaMA 3.3 on commodity servers. The broader objective is to enable practitioners to make cost-effective AI deployment decisions that reflect their available resources, requirements, and constraints.",
      "tldr_zh": "è¯¥ç ”ç©¶é’ˆå¯¹ç°æœ‰AIç³»ç»ŸåŸºå‡†æµ‹è¯•ï¼ˆå¦‚ MLPerfï¼‰éš¾ä»¥è·Ÿä¸Šå¿«é€Ÿæ¼”è¿›çš„AIé¢†åŸŸè¿™ä¸€é—®é¢˜ï¼Œæå‡ºå°†åŸºå‡†æµ‹è¯•æœ¬èº«æ„å»ºä¸ºä¸€ä¸ªAIå­¦ä¹ ä»»åŠ¡ã€‚ä¸ºæ­¤ï¼Œä½œè€…å¼€å‘äº† FlexBenchï¼Œè¿™æ˜¯ä¸€ç§ MLPerf å¤§è¯­è¨€æ¨¡å‹ (LLM) æ¨ç†åŸºå‡†çš„æ¨¡å—åŒ–æ‰©å±•ï¼Œå¹¶ä¸ HuggingFace æ·±åº¦é›†æˆä»¥æä¾›æ›´å…·è¡ŒåŠ¨ä»·å€¼çš„æ´å¯Ÿã€‚è¯¥æ¡†æ¶å°†æµ‹è¯•ç»“æœä¸å…ƒæ•°æ®æ•´åˆè¿› Open MLPerf Datasetï¼Œæ”¯æŒåä½œç­–å±•ã€ç‰¹å¾å·¥ç¨‹åŠé¢„æµ‹å»ºæ¨¡ï¼Œä»è€Œä¼˜åŒ–åœ¨ä¸åŒç¡¬ä»¶ã€è½¯ä»¶åŠæ•°æ®é›†ä¸Šçš„è¯„ä¼°è¿‡ç¨‹ã€‚ç ”ç©¶é€šè¿‡ MLPerf æ¨ç†æäº¤æˆåŠŸéªŒè¯äº† FlexBench çš„å¯è¡Œæ€§ï¼ŒåŒ…æ‹¬åœ¨é€šç”¨æœåŠ¡å™¨ä¸Šå¯¹ DeepSeek R1 å’Œ LLaMA 3.3 è¿›è¡Œçš„åŸºå‡†æµ‹è¯•ã€‚è¯¥ç ”ç©¶çš„æœ€ç»ˆç›®æ ‡æ˜¯ä½¿ä»ä¸šè€…èƒ½å¤Ÿæ ¹æ®ç°æœ‰èµ„æºã€éœ€æ±‚å’Œçº¦æŸæ¡ä»¶ï¼Œåšå‡ºæ›´å…·æˆæœ¬æ•ˆç›Šçš„AIéƒ¨ç½²å†³ç­–ï¼Œæ¨åŠ¨AIç³»ç»Ÿçš„ååŒè®¾è®¡ä¸ä¼˜åŒ–ã€‚",
      "categories": [
        "cs.LG",
        "cs.AI"
      ],
      "primary_category": "cs.LG",
      "comment": "",
      "pdf_url": "https://arxiv.org/pdf/2509.11413v1",
      "published_date": "2025-09-14 20:02:15 UTC",
      "updated_date": "2025-09-14 20:02:15 UTC",
      "processing_status": "completed",
      "attempts": 1,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "llm_backup_calls": 0,
      "last_update": "2026-01-24T18:22:28.590245+00:00"
    },
    {
      "arxiv_id": "2509.12285v1",
      "title": "Deriving the Scaled-Dot-Function via Maximum Likelihood Estimation and Maximum Entropy Approach",
      "title_zh": "åŸºäºæå¤§ä¼¼ç„¶ä¼°è®¡ä¸æœ€å¤§ç†µæ–¹æ³•çš„ç¼©æ”¾ç‚¹ç§¯å‡½æ•°æ¨å¯¼",
      "authors": [
        "Jiyong Ma"
      ],
      "abstract": "In this paper, we present a maximum likelihood estimation approach to determine the value vector in transformer models. We model the sequence of value vectors, key vectors, and the query vector as a sequence of Gaussian distributions. The variance in each Gaussian distribution depends on the time step, the corresponding key vector, and the query vector. The mean value in each Gaussian distribution depends on the time step, and the corresponding value vector. This analysis may offer a new explanation of the scaled-dot-product function or softmax function used in transformer architectures [1]. Another explanation, inspired by [4], is based on the maximum entropy approach in natural language processing [5]. In this approach, a query vector and key vectors are used to derive the feature functions for the maximum entropy model.",
      "tldr_zh": "è¯¥ç ”ç©¶æ¢è®¨äº†Transformeræ¨¡å‹ä¸­ç¼©æ”¾ç‚¹ç§¯å‡½æ•°(Scaled-dot-product function)çš„ç†è®ºæ¥æºï¼Œæå‡ºäº†åŸºäºæœ€å¤§ä¼¼ç„¶ä¼°è®¡(Maximum Likelihood Estimation)å’Œæœ€å¤§ç†µ(Maximum Entropy)æ–¹æ³•çš„ä¸¤ç§æ¨å¯¼æ–¹å¼ã€‚åœ¨ç¬¬ä¸€ç§æ–¹æ³•ä¸­ï¼Œä½œè€…å°†å€¼å‘é‡(Value vector)ã€é”®å‘é‡(Key vector)å’ŒæŸ¥è¯¢å‘é‡(Query vector)å»ºæ¨¡ä¸ºé«˜æ–¯åˆ†å¸ƒåºåˆ—ï¼Œé€šè¿‡åˆ†æå‡å€¼ä¸æ–¹å·®å¯¹æ—¶é—´æ­¥é•¿å’Œå‘é‡çš„ä¾èµ–å…³ç³»ï¼Œä¸ºSoftmaxå‡½æ•°æä¾›äº†æ–°çš„æ•°å­¦è§£é‡Šã€‚å¦ä¸€ç§è§£é‡Šåˆ™å€Ÿé‰´äº†è‡ªç„¶è¯­è¨€å¤„ç†ä¸­çš„æœ€å¤§ç†µæ¨¡å‹ï¼Œåˆ©ç”¨æŸ¥è¯¢å‘é‡å’Œé”®å‘é‡å¯¼å‡ºç‰¹å¾å‡½æ•°ã€‚è¯¥åˆ†æä¸ä»…ä¸ºTransformeræ¶æ„ä¸­çš„æ ¸å¿ƒè®¡ç®—é€»è¾‘æä¾›äº†åšå®çš„ç†è®ºåŸºç¡€ï¼Œè¿˜ä»ç»Ÿè®¡å»ºæ¨¡çš„è§’åº¦æ·±åŒ–äº†å¯¹æ³¨æ„åŠ›æœºåˆ¶è¿ä½œåŸç†çš„è®¤çŸ¥ã€‚",
      "categories": [
        "cs.LG",
        "cs.AI"
      ],
      "primary_category": "cs.LG",
      "comment": "",
      "pdf_url": "https://arxiv.org/pdf/2509.12285v1",
      "published_date": "2025-09-14 19:52:32 UTC",
      "updated_date": "2025-09-14 19:52:32 UTC",
      "processing_status": "completed",
      "attempts": 1,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "llm_backup_calls": 0,
      "last_update": "2026-01-24T18:22:41.290191+00:00"
    },
    {
      "arxiv_id": "2509.18140v1",
      "title": "A Machine Learning Framework for Pathway-Driven Therapeutic Target Discovery in Metabolic Disorders",
      "title_zh": "é€šè·¯é©±åŠ¨çš„ä»£è°¢æ€§ç–¾ç—…æ²»ç–—é¶ç‚¹å‘ç°æœºå™¨å­¦ä¹ æ¡†æ¶",
      "authors": [
        "Iram Wajahat",
        "Amritpal Singh",
        "Fazel Keshtkar",
        "Syed Ahmad Chan Bukhari"
      ],
      "abstract": "Metabolic disorders, particularly type 2 diabetes mellitus (T2DM), represent a significant global health burden, disproportionately impacting genetically predisposed populations such as the Pima Indians (a Native American tribe from south central Arizona). This study introduces a novel machine learning (ML) framework that integrates predictive modeling with gene-agnostic pathway mapping to identify high-risk individuals and uncover potential therapeutic targets. Using the Pima Indian dataset, logistic regression and t-tests were applied to identify key predictors of T2DM, yielding an overall model accuracy of 78.43%. To bridge predictive analytics with biological relevance, we developed a pathway mapping strategy that links identified predictors to critical signaling networks, including insulin signaling, AMPK, and PPAR pathways. This approach provides mechanistic insights without requiring direct molecular data. Building upon these connections, we propose therapeutic strategies such as dual GLP-1/GIP receptor agonists, AMPK activators, SIRT1 modulators, and phytochemical, further validated through pathway enrichment analyses. Overall, this framework advances precision medicine by offering interpretable and scalable solutions for early detection and targeted intervention in metabolic disorders. The key contributions of this work are: (1) development of an ML framework combining logistic regression and principal component analysis (PCA) for T2DM risk prediction; (2) introduction of a gene-agnostic pathway mapping approach to generate mechanistic insights; and (3) identification of novel therapeutic strategies tailored for high-risk populations.",
      "tldr_zh": "è¯¥ç ”ç©¶é’ˆå¯¹ä»¥2å‹ç³–å°¿ç—…(T2DM)ä¸ºä»£è¡¨çš„ä»£è°¢ç´Šä¹±ç–¾ç—…ï¼Œæå‡ºäº†ä¸€ç§ç»“åˆé¢„æµ‹å»ºæ¨¡ä¸åŸºå› æ— å…³é€šè·¯æ˜ å°„(gene-agnostic pathway mapping)çš„æ–°å‹æœºå™¨å­¦ä¹ æ¡†æ¶ã€‚ç ”ç©¶åˆ©ç”¨ Pima Indian æ•°æ®é›†ï¼Œé€šè¿‡é€»è¾‘å›å½’(Logistic Regression)ã€tæ£€éªŒ(t-tests)å’Œä¸»æˆåˆ†åˆ†æ(PCA)è¯†åˆ«ç–¾ç—…å…³é”®é¢„æµ‹å› å­ï¼Œå®ç°äº†78.43%çš„é¢„æµ‹å‡†ç¡®ç‡ã€‚è¯¥æ¡†æ¶æ ¸å¿ƒåœ¨äºå¼€å‘äº†é€šè·¯æ˜ å°„ç­–ç•¥ï¼Œå°†é¢„æµ‹å› å­ä¸èƒ°å²›ç´ ä¿¡å·ä¼ å¯¼(insulin signaling)ã€AMPK å’Œ PPAR ç­‰å…³é”®ä¿¡å·ç½‘ç»œå…³è”ï¼Œåœ¨æ— éœ€ç›´æ¥åˆ†å­æ•°æ®çš„æƒ…å†µä¸‹æä¾›äº†æ·±å…¥çš„ç”Ÿç‰©å­¦æœºåˆ¶è§è§£ã€‚åŸºäºæ­¤ï¼Œç ”ç©¶è¿›ä¸€æ­¥æå‡ºäº†åŒ…æ‹¬åŒé‡ GLP-1/GIP å—ä½“æ¿€åŠ¨å‰‚ã€AMPK æ¿€æ´»å‰‚ã€SIRT1 è°ƒèŠ‚å‰‚åŠæ¤ç‰©åŒ–å­¦ç‰©è´¨(phytochemical)åœ¨å†…çš„é¶å‘æ²»ç–—ç­–ç•¥ã€‚è¯¥å·¥ä½œé€šè¿‡é€šè·¯å¯Œé›†åˆ†æ(pathway enrichment analyses)éªŒè¯äº†å‘ç°ï¼Œä¸ºä»£è°¢æ€§ç–¾ç—…çš„æ—©æœŸç­›æŸ¥å’Œç²¾å‡†åŒ»ç–—æä¾›äº†å¯è§£é‡Šä¸”å…·æœ‰æ‰©å±•æ€§çš„æŠ€æœ¯æ–¹æ¡ˆã€‚",
      "categories": [
        "cs.LG",
        "cs.AI"
      ],
      "primary_category": "cs.LG",
      "comment": "6 pages, 6 figures",
      "pdf_url": "https://arxiv.org/pdf/2509.18140v1",
      "published_date": "2025-09-14 19:29:52 UTC",
      "updated_date": "2025-09-14 19:29:52 UTC",
      "processing_status": "completed",
      "attempts": 1,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "llm_backup_calls": 0,
      "last_update": "2026-01-24T18:22:50.084797+00:00"
    },
    {
      "arxiv_id": "2509.11398v1",
      "title": "From Firewalls to Frontiers: AI Red-Teaming is a Domain-Specific Evolution of Cyber Red-Teaming",
      "title_zh": "ä»é˜²ç«å¢™åˆ°å‰æ²¿ï¼šAI çº¢é˜Ÿæ˜¯ç½‘ç»œçº¢é˜Ÿåœ¨ç‰¹å®šé¢†åŸŸçš„æ¼”è¿›",
      "authors": [
        "Anusha Sinha",
        "Keltin Grimes",
        "James Lucassen",
        "Michael Feffer",
        "Nathan VanHoudnos",
        "Zhiwei Steven Wu",
        "Hoda Heidari"
      ],
      "abstract": "A red team simulates adversary attacks to help defenders find effective strategies to defend their systems in a real-world operational setting. As more enterprise systems adopt AI, red-teaming will need to evolve to address the unique vulnerabilities and risks posed by AI systems. We take the position that AI systems can be more effectively red-teamed if AI red-teaming is recognized as a domain-specific evolution of cyber red-teaming. Specifically, we argue that existing Cyber Red Teams who adopt this framing will be able to better evaluate systems with AI components by recognizing that AI poses new risks, has new failure modes to exploit, and often contains unpatchable bugs that re-prioritize disclosure and mitigation strategies. Similarly, adopting a cybersecurity framing will allow existing AI Red Teams to leverage a well-tested structure to emulate realistic adversaries, promote mutual accountability with formal rules of engagement, and provide a pattern to mature the tooling necessary for repeatable, scalable engagements. In these ways, the merging of AI and Cyber Red Teams will create a robust security ecosystem and best position the community to adapt to the rapidly changing threat landscape.",
      "tldr_zh": "è¯¥ç ”ç©¶æ¢è®¨äº†éšç€äººå·¥æ™ºèƒ½åœ¨ä¼ä¸šç³»ç»Ÿä¸­çš„å¹¿æ³›åº”ç”¨ï¼Œçº¢é˜Ÿå¯¹æŠ—æŠ€æœ¯å¦‚ä½•æ¼”è¿›ä»¥åº”å¯¹ AI ç³»ç»Ÿç‰¹æœ‰çš„é£é™©ä¸è„†å¼±æ€§ã€‚æ–‡ç« æå‡ºå°† AI Red-Teaming è§†ä¸º Cyber Red-Teaming åœ¨ç‰¹å®šé¢†åŸŸçš„è¿›åŒ–ï¼Œè®¤ä¸ºè¿™ç§å®šä½èƒ½æ›´æœ‰æ•ˆåœ°è¯„ä¼°åŒ…å« AI ç»„ä»¶çš„å¤æ‚ç³»ç»Ÿã€‚ç°æœ‰çš„ç½‘ç»œçº¢é˜Ÿé€šè¿‡é‡‡çº³è¿™ä¸€è§†è§’ï¼Œå¯ä»¥æ›´å¥½åœ°è¯†åˆ« AI å¸¦æ¥çš„æ–°é£é™©ã€æ•…éšœæ¨¡å¼ï¼ˆFailure Modesï¼‰ä»¥åŠå¯¼è‡´æŠ«éœ²ç­–ç•¥é‡æ’çš„ä¸å¯ä¿®å¤æ¼æ´ï¼ˆUnpatchable Bugsï¼‰ã€‚åŒæ—¶ï¼ŒAI çº¢é˜Ÿä¹Ÿèƒ½å€Ÿæ­¤å¼•å…¥æˆç†Ÿçš„ç½‘ç»œå®‰å…¨æ¡†æ¶ï¼Œåˆ©ç”¨å¯¹æ‰‹æ¨¡æ‹Ÿï¼ˆAdversary Emulationï¼‰å’Œäº¤æˆ˜è§„åˆ™ï¼ˆRules of Engagementï¼‰æ¥æå‡å®‰å…¨è¯„ä¼°çš„å¯é‡å¤æ€§ä¸è§„æ¨¡åŒ–èƒ½åŠ›ã€‚é€šè¿‡ AI ä¸ Cyber çº¢é˜Ÿçš„æ·±åº¦èåˆï¼Œç ”ç©¶æ—¨åœ¨æ„å»ºä¸€ä¸ªæ›´ä¸ºå¼ºå¥çš„å®‰å…¨ç”Ÿæ€ç³»ç»Ÿï¼Œä»è€Œä½¿æŠ€æœ¯ç¤¾åŒºèƒ½å¤Ÿæ›´å¥½åœ°é€‚åº”å¿«é€Ÿå˜åŒ–çš„å¨èƒæ ¼å±€ã€‚",
      "categories": [
        "cs.LG",
        "cs.AI",
        "cs.CR"
      ],
      "primary_category": "cs.LG",
      "comment": "",
      "pdf_url": "https://arxiv.org/pdf/2509.11398v1",
      "published_date": "2025-09-14 19:21:58 UTC",
      "updated_date": "2025-09-14 19:21:58 UTC",
      "processing_status": "completed",
      "attempts": 1,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "llm_backup_calls": 0,
      "last_update": "2026-01-24T18:22:55.192440+00:00"
    },
    {
      "arxiv_id": "2509.19332v1",
      "title": "Quantifying Compositionality of Classic and State-of-the-Art Embeddings",
      "title_zh": "ç»å…¸åŠå‰æ²¿åµŒå…¥ç»„åˆæ€§çš„é‡åŒ–è¯„ä¼°",
      "authors": [
        "Zhijin Guo",
        "Chenhao Xue",
        "Zhaozhen Xu",
        "Hongbo Bo",
        "Yuxuan Ye",
        "Janet B. Pierrehumbert",
        "Martha Lewis"
      ],
      "abstract": "For language models to generalize correctly to novel expressions, it is critical that they exploit access compositional meanings when this is justified. Even if we don't know what a \"pelp\" is, we can use our knowledge of numbers to understand that \"ten pelps\" makes more pelps than \"two pelps\". Static word embeddings such as Word2vec made strong, indeed excessive, claims about compositionality. The SOTA generative, transformer models and graph models, however, go too far in the other direction by providing no real limits on shifts in meaning due to context. To quantify the additive compositionality, we formalize a two-step, generalized evaluation that (i) measures the linearity between known entity attributes and their embeddings via canonical correlation analysis, and (ii) evaluates additive generalization by reconstructing embeddings for unseen attribute combinations and checking reconstruction metrics such as L2 loss, cosine similarity, and retrieval accuracy. These metrics also capture failure cases where linear composition breaks down. Sentences, knowledge graphs, and word embeddings are evaluated and tracked the compositionality across all layers and training stages. Stronger compositional signals are observed in later training stages across data modalities, and in deeper layers of the transformer-based model before a decline at the top layer. Code is available at https://github.com/Zhijin-Guo1/quantifying-compositionality.",
      "tldr_zh": "è¯¥ç ”ç©¶æ—¨åœ¨é‡åŒ–ç»å…¸åŠæœ€å…ˆè¿›(SOTA)è¯åµŒå…¥æ¨¡å‹çš„ç»„åˆæ€§(Compositionality)ï¼Œæ¢è®¨æ¨¡å‹å¦‚ä½•åˆ©ç”¨å·²çŸ¥å±æ€§ç»„åˆæ¥ç†è§£æ–°è¡¨è¾¾ã€‚ç ”ç©¶æå‡ºäº†ä¸€ç§æ³›åŒ–çš„ä¸¤æ­¥è¯„ä¼°æ–¹æ³•ï¼Œé¦–å…ˆåˆ©ç”¨å…¸å‹ç›¸å…³åˆ†æ(Canonical Correlation Analysis)æµ‹é‡å·²çŸ¥å®ä½“å±æ€§ä¸åµŒå…¥å‘é‡ä¹‹é—´çš„çº¿æ€§å…³ç³»ï¼Œéšåé€šè¿‡é‡å»ºæœªè§å±æ€§ç»„åˆçš„åµŒå…¥å‘é‡å¹¶è¯„ä¼°å…¶åŠ æ€§æ³›åŒ–èƒ½åŠ›ã€‚é€šè¿‡ä½¿ç”¨L2æŸå¤±(L2 loss)ã€ä½™å¼¦ç›¸ä¼¼åº¦(Cosine Similarity)å’Œæ£€ç´¢å‡†ç¡®ç‡(Retrieval Accuracy)ç­‰æŒ‡æ ‡ï¼Œè¯¥æ–¹æ³•å¯¹å¥å­ã€çŸ¥è¯†å›¾è°±(Knowledge Graphs)åŠè¯åµŒå…¥åœ¨ä¸åŒè®­ç»ƒé˜¶æ®µå’Œæ¨¡å‹æ·±åº¦çš„ç»„åˆæ€§è¿›è¡Œäº†è¿½è¸ªã€‚å®éªŒå‘ç°åœ¨å„ç§æ•°æ®æ¨¡æ€ä¸­ï¼Œè¾ƒæ™šçš„è®­ç»ƒé˜¶æ®µé€šå¸¸è¡¨ç°å‡ºæ›´å¼ºçš„ç»„åˆæ€§ä¿¡å·ã€‚æ­¤å¤–ï¼Œåœ¨åŸºäºTransformerçš„æ¨¡å‹ä¸­ï¼Œç»„åˆæ€§ä¿¡å·åœ¨è¿›å…¥é¡¶å±‚ä¹‹å‰ä¼šéšæ·±åº¦å¢åŠ è€Œå¢å¼ºï¼Œä½†åœ¨æœ€é¡¶å±‚ä¼šå‡ºç°ä¸‹é™ã€‚è¯¥å·¥ä½œä¸ä»…æ•æ‰äº†çº¿æ€§ç»„åˆå¤±æ•ˆçš„æ¡ˆä¾‹ï¼Œè¿˜ä¸ºç†è§£ä¸åŒåµŒå…¥æŠ€æœ¯çš„ç»„åˆç‰¹æ€§æä¾›äº†é‡åŒ–æ”¯æŒã€‚",
      "categories": [
        "cs.CL",
        "cs.AI"
      ],
      "primary_category": "cs.CL",
      "comment": "Findings of the Association for Computational Linguistics: EMNLP 2025",
      "pdf_url": "https://arxiv.org/pdf/2509.19332v1",
      "published_date": "2025-09-14 18:28:21 UTC",
      "updated_date": "2025-09-14 18:28:21 UTC",
      "processing_status": "completed",
      "attempts": 1,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "llm_backup_calls": 0,
      "last_update": "2026-01-24T18:22:57.196381+00:00"
    },
    {
      "arxiv_id": "2509.11376v1",
      "title": "Intelligent Reservoir Decision Support: An Integrated Framework Combining Large Language Models, Advanced Prompt Engineering, and Multimodal Data Fusion for Real-Time Petroleum Operations",
      "title_zh": "æ™ºèƒ½æ²¹è—å†³ç­–æ”¯æŒï¼šèåˆå¤§è¯­è¨€æ¨¡å‹ã€å…ˆè¿›æç¤ºå·¥ç¨‹ä¸å¤šæ¨¡æ€æ•°æ®çš„å®æ—¶çŸ³æ²¹ä½œä¸šé›†æˆæ¡†æ¶",
      "authors": [
        "Seyed Kourosh Mahjour",
        "Seyed Saman Mahjour"
      ],
      "abstract": "The petroleum industry faces unprecedented challenges in reservoir management, requiring rapid integration of complex multimodal datasets for real-time decision support. This study presents a novel integrated framework combining state-of-the-art large language models (GPT-4o, Claude 4 Sonnet, Gemini 2.5 Pro) with advanced prompt engineering techniques and multimodal data fusion for comprehensive reservoir analysis. The framework implements domain-specific retrieval-augmented generation (RAG) with over 50,000 petroleum engineering documents, chain-of-thought reasoning, and few-shot learning for rapid field adaptation. Multimodal integration processes seismic interpretations, well logs, and production data through specialized AI models with vision transformers. Field validation across 15 diverse reservoir environments demonstrates exceptional performance: 94.2% reservoir characterization accuracy, 87.6% production forecasting precision, and 91.4% well placement optimization success rate. The system achieves sub-second response times while maintaining 96.2% safety reliability with no high-risk incidents during evaluation. Economic analysis reveals 62-78% cost reductions (mean 72%) relative to traditional methods with 8-month payback period. Few-shot learning reduces field adaptation time by 72%, while automated prompt optimization achieves 89% improvement in reasoning quality. The framework processed real-time data streams with 96.2% anomaly detection accuracy and reduced environmental incidents by 45%. We provide detailed experimental protocols, baseline comparisons, ablation studies, and statistical significance testing to ensure reproducibility. This research demonstrates practical integration of cutting-edge AI technologies with petroleum domain expertise for enhanced operational efficiency, safety, and economic performance.",
      "tldr_zh": "è¯¥ç ”ç©¶æå‡ºäº†ä¸€ä¸ªé›†æˆæ¡†æ¶ï¼Œå°†å¤§è¯­è¨€æ¨¡å‹ï¼ˆGPT-4o, Claude 4 Sonnet, Gemini 2.5 Proï¼‰ä¸é«˜çº§æç¤ºå·¥ç¨‹ (Advanced Prompt Engineering) å’Œå¤šæ¨¡æ€æ•°æ®èåˆ (Multimodal Data Fusion) ç›¸ç»“åˆï¼Œæ—¨åœ¨è§£å†³çŸ³æ²¹å·¥ä¸šæ²¹è—ç®¡ç†ä¸­çš„å®æ—¶å†³ç­–æ”¯æŒæŒ‘æˆ˜ã€‚è¯¥æ¡†æ¶åˆ©ç”¨è¶…è¿‡5ä¸‡ä»½çŸ³æ²¹å·¥ç¨‹æ–‡æ¡£å®ç°äº†é¢†åŸŸç‰¹å®šçš„æ£€ç´¢å¢å¼ºç”Ÿæˆ (RAG)ï¼Œå¹¶ç»“åˆé“¾å¼æ€ç»´æ¨ç† (Chain-of-Thought) å’Œå°‘æ ·æœ¬å­¦ä¹  (Few-shot learning) æ¥åŠ é€Ÿæ²¹è—ç°åœºçš„å¿«é€Ÿé€‚é…ã€‚ç³»ç»Ÿé€šè¿‡ä¸“é—¨çš„è§†è§‰å˜æ¢å™¨ (Vision Transformers) AI æ¨¡å‹å¤„ç†åœ°éœ‡è§£é‡Šã€æµ‹äº•è®°å½•å’Œç”Ÿäº§æ•°æ®ç­‰å¤šæ¨¡æ€ä¿¡æ¯ã€‚åœ¨15ä¸ªä¸åŒæ²¹è—ç¯å¢ƒçš„ç°åœºéªŒè¯æ˜¾ç¤ºï¼Œè¯¥ç³»ç»Ÿçš„æ²¹è—ç‰¹å¾æè¿°å‡†ç¡®ç‡è¾¾åˆ°94.2%ï¼Œäº§é‡é¢„æµ‹ç²¾åº¦ä¸º87.6%ï¼Œäº•ä½ä¼˜åŒ–æˆåŠŸç‡ä¸º91.4%ã€‚ç³»ç»Ÿå®ç°äº†äºšç§’çº§å“åº”ï¼Œå¹¶åœ¨è¯„ä¼°æœŸé—´ä¿æŒäº†96.2%çš„å®‰å…¨å¯é æ€§ï¼Œæœ‰æ•ˆå‡å°‘äº†45%çš„ç¯å¢ƒäº‹æ•…ã€‚ç»æµåˆ†æè¡¨æ˜ï¼Œä¸ä¼ ç»Ÿæ–¹æ³•ç›¸æ¯”ï¼Œè¯¥æ¡†æ¶ä½¿å¹³å‡æˆæœ¬é™ä½äº†72%ï¼ŒæŠ•èµ„å›æ”¶æœŸä»…ä¸º8ä¸ªæœˆã€‚è¿™é¡¹ç ”ç©¶å±•ç¤ºäº†å‰æ²¿ AI æŠ€æœ¯ä¸çŸ³æ²¹é¢†åŸŸä¸“ä¸šçŸ¥è¯†çš„å®ç”¨é›†æˆï¼Œæ˜¾è‘—æå‡äº†çŸ³æ²¹ä½œä¸šçš„è¿è¥æ•ˆç‡ã€å®‰å…¨æ€§å’Œç»æµæ€§èƒ½ã€‚",
      "categories": [
        "cs.LG",
        "cs.AI",
        "cs.CE"
      ],
      "primary_category": "cs.LG",
      "comment": "",
      "pdf_url": "https://arxiv.org/pdf/2509.11376v1",
      "published_date": "2025-09-14 18:13:27 UTC",
      "updated_date": "2025-09-14 18:13:27 UTC",
      "processing_status": "completed",
      "attempts": 1,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "llm_backup_calls": 0,
      "last_update": "2026-01-24T18:23:18.295034+00:00"
    },
    {
      "arxiv_id": "2509.11374v1",
      "title": "Transformer Enhanced Relation Classification: A Comparative Analysis of Contextuality, Data Efficiency and Sequence Complexity",
      "title_zh": "Transformer å¢å¼ºçš„å…³ç³»åˆ†ç±»ï¼šè¯­å¢ƒåŒ–ã€æ•°æ®æ•ˆç‡ä¸åºåˆ—å¤æ‚åº¦çš„æ¯”è¾ƒåˆ†æ",
      "authors": [
        "Bowen Jing",
        "Yang Cui",
        "Tianpeng Huang"
      ],
      "abstract": "In the era of large language model, relation extraction (RE) plays an important role in information extraction through the transformation of unstructured raw text into structured data (Wadhwa et al., 2023). In this paper, we systematically compare the performance of deep supervised learning approaches without transformers and those with transformers. We used a series of non-transformer architectures such as PA-LSTM(Zhang et al., 2017), C-GCN(Zhang et al., 2018), and AGGCN(attention guide GCN)(Guo et al., 2019), and a series of transformer architectures such as BERT, RoBERTa, and R-BERT(Wu and He, 2019). Our comparison included traditional metrics like micro F1, as well as evaluations in different scenarios, varying sentence lengths, and different percentages of the dataset for training. Our experiments were conducted on TACRED, TACREV, and RE-TACRED. The results show that transformer-based models outperform non-transformer models, achieving micro F1 scores of 80-90% compared to 64-67% for non-transformer models. Additionally, we briefly review the research journey in supervised relation classification and discuss the role and current status of large language models (LLMs) in relation extraction.",
      "tldr_zh": "è¯¥ç ”ç©¶é’ˆå¯¹å…³ç³»æŠ½å–(Relation Extraction)ä»»åŠ¡ï¼Œç³»ç»Ÿåœ°å¯¹æ¯”äº†éTransformeræ¶æ„ä¸Transformeræ¶æ„åœ¨æ·±åº¦ç›‘ç£å­¦ä¹ ä¸­çš„æ€§èƒ½è¡¨ç°ã€‚å®éªŒæ¶µç›–äº†PA-LSTMã€C-GCNã€AGGCNä»¥åŠBERTã€RoBERTaã€R-BERTç­‰å¤šç§æ¨¡å‹ï¼Œå¹¶åœ¨TACREDã€TACREVå’ŒRE-TACREDæ•°æ®é›†ä¸Šè¿›è¡Œäº†å…¨é¢è¯„ä¼°ã€‚ç ”ç©¶é‡ç‚¹åˆ†æäº†å„æ¨¡å‹åœ¨Micro F1å€¼ã€æ•°æ®æ•ˆç‡åŠå¤„ç†ä¸åŒé•¿åº¦åºåˆ—æ—¶çš„è¡¨ç°å·®å¼‚ã€‚ç»“æœè¡¨æ˜ï¼ŒåŸºäºTransformerçš„æ¨¡å‹å…·æœ‰æ˜¾è‘—ä¼˜åŠ¿ï¼Œå…¶Micro F1å¾—åˆ†ç»´æŒåœ¨80-90%ä¹‹é—´ï¼Œè¿œé«˜äºéTransformeræ¨¡å‹çš„64-67%ã€‚æ­¤å¤–ï¼Œè®ºæ–‡è¿˜å›é¡¾äº†ç›‘ç£å…³ç³»åˆ†ç±»(Relation Classification)çš„æŠ€æœ¯æ¼”è¿›ï¼Œå¹¶æ¢è®¨äº†å¤§è¯­è¨€æ¨¡å‹(LLMs)åœ¨å½“å‰å…³ç³»æŠ½å–é¢†åŸŸçš„ä½œç”¨ä¸ç°çŠ¶ã€‚",
      "categories": [
        "cs.CL",
        "cs.AI"
      ],
      "primary_category": "cs.CL",
      "comment": "",
      "pdf_url": "https://arxiv.org/pdf/2509.11374v1",
      "published_date": "2025-09-14 18:11:31 UTC",
      "updated_date": "2025-09-14 18:11:31 UTC",
      "processing_status": "completed",
      "attempts": 1,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "llm_backup_calls": 0,
      "last_update": "2026-01-24T18:23:13.591385+00:00"
    },
    {
      "arxiv_id": "2509.11367v1",
      "title": "Detecting Model Drifts in Non-Stationary Environment Using Edit Operation Measures",
      "title_zh": "åŸºäºç¼–è¾‘æ“ä½œåº¦é‡çš„éå¹³ç¨³ç¯å¢ƒæ¨¡å‹æ¼‚ç§»æ£€æµ‹",
      "authors": [
        "Chang-Hwan Lee",
        "Alexander Shim"
      ],
      "abstract": "Reinforcement learning (RL) agents typically assume stationary environment dynamics. Yet in real-world applications such as healthcare, robotics, and finance, transition probabilities or reward functions may evolve, leading to model drift. This paper proposes a novel framework to detect such drifts by analyzing the distributional changes in sequences of agent behavior. Specifically, we introduce a suite of edit operation-based measures to quantify deviations between state-action trajectories generated under stationary and perturbed conditions. Our experiments demonstrate that these measures can effectively distinguish drifted from non-drifted scenarios, even under varying levels of noise, providing a practical tool for drift detection in non-stationary RL environments.",
      "tldr_zh": "è¯¥ç ”ç©¶é’ˆå¯¹å¼ºåŒ–å­¦ä¹ (Reinforcement learning, RL)åœ¨å®é™…åº”ç”¨ä¸­å› ç¯å¢ƒåŠ¨æ€æ¼”å˜è€Œäº§ç”Ÿçš„æ¨¡å‹æ¼‚ç§»(model drift)é—®é¢˜ï¼Œæå‡ºäº†ä¸€ç§åŸºäºæ™ºèƒ½ä½“è¡Œä¸ºåºåˆ—åˆ†å¸ƒå˜åŒ–åˆ†æçš„æ£€æµ‹æ¡†æ¶ã€‚ç ”ç©¶è€…å¼•å…¥äº†ä¸€å¥—åŸºäºç¼–è¾‘æ“ä½œ(edit operation-based measures)çš„åº¦é‡æ–¹æ³•ï¼Œæ—¨åœ¨ç²¾ç¡®é‡åŒ–åœ¨å¹³ç¨³ä¸æ‰°åŠ¨æ¡ä»¶ä¸‹ç”Ÿæˆçš„â€œçŠ¶æ€-åŠ¨ä½œè½¨è¿¹â€(state-action trajectories)ä¹‹é—´çš„åå·®ã€‚å®éªŒè¯æ˜ï¼Œè¯¥æ–¹æ³•åœ¨ä¸åŒå™ªå£°æ°´å¹³ä¸‹å‡èƒ½æœ‰æ•ˆåŒºåˆ†æ¼‚ç§»ä¸éæ¼‚ç§»åœºæ™¯ï¼Œå±•ç°å‡ºè¾ƒå¼ºçš„ç¨³å¥æ€§ã€‚è¿™ä¸€æˆæœä¸ºéå¹³ç¨³å¼ºåŒ–å­¦ä¹ ç¯å¢ƒä¸­çš„æ¼‚ç§»æ£€æµ‹æä¾›äº†åˆ‡å®å¯è¡Œçš„å·¥å…·ï¼Œå¯¹äºæå‡RLæ™ºèƒ½ä½“åœ¨åŒ»ç–—ã€é‡‘èç­‰åŠ¨æ€ç¯å¢ƒä¸‹çš„å¯é æ€§å…·æœ‰é‡è¦æ„ä¹‰ã€‚",
      "categories": [
        "cs.LG",
        "cs.AI"
      ],
      "primary_category": "cs.LG",
      "comment": "28 pages, 3 figures, 17 tables",
      "pdf_url": "https://arxiv.org/pdf/2509.11367v1",
      "published_date": "2025-09-14 17:48:06 UTC",
      "updated_date": "2025-09-14 17:48:06 UTC",
      "processing_status": "completed",
      "attempts": 1,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "llm_backup_calls": 0,
      "last_update": "2026-01-24T18:23:16.103553+00:00"
    },
    {
      "arxiv_id": "2509.11361v2",
      "title": "MAPGD: Multi-Agent Prompt Gradient Descent for Collaborative Prompt Optimization",
      "title_zh": "MAPGDï¼šç”¨äºååŒæç¤ºè¯ä¼˜åŒ–çš„å¤šæ™ºèƒ½ä½“æç¤ºè¯æ¢¯åº¦ä¸‹é™",
      "authors": [
        "Yichen Han",
        "Yuhang Han",
        "Bojun Liu",
        "Zhengpeng Zhou",
        "Guanyu Liu",
        "Zeng Zhang",
        "Yang Yang",
        "Wenli Wang",
        "Isaac N Shi",
        "Yunyan Zhang",
        "Lewei He",
        "Tianyu Shi"
      ],
      "abstract": "Prompt engineering is crucial for fully leveraging large language models (LLMs), yet most existing optimization methods follow a single trajectory, resulting in limited adaptability, gradient conflicts, and high computational overhead. We propose MAPGD (Multi-Agent Prompt Gradient Descent), a novel framework that reconceptualizes prompt optimization as a collaborative process among specialized agents. Each agent focuses on a distinct refinement dimension, such as instruction clarity, example selection, format structure, or stylistic adaptation, and their contributions are coordinated through semantic gradient embedding, conflict detection, and fusion. To further enhance robustness and stability, MAPGD introduces two new mechanisms: Hypersphere Constrained Gradient Clustering (HCGC), which enforces angular margin constraints for compact and well-separated clusters, and Channel Adaptive Agent Weighting (CAAW), which dynamically reweights agent contributions based on validation performance. Experiments on classification and reasoning benchmarks show that MAPGD consistently surpasses single-agent and random baselines in both accuracy and efficiency. Ablation studies confirm the effectiveness of gradient fusion, agent specialization, and conflict resolution. Together, these components establish MAPGD as a unified, gradient-based, and interpretable framework for robust prompt optimization with theoretical convergence guarantees.",
      "tldr_zh": "è¯¥ç ”ç©¶æå‡ºäº†MAPGDï¼ˆMulti-Agent Prompt Gradient Descentï¼‰ï¼Œä¸€ç§å°†æç¤ºè¯ä¼˜åŒ–é‡æ–°å®šä¹‰ä¸ºå¤šä¸“é—¨åŒ–æ™ºèƒ½ä½“åä½œè¿‡ç¨‹çš„æ–°å‹æ¡†æ¶ï¼Œæ—¨åœ¨è§£å†³ç°æœ‰æ–¹æ³•åœ¨é€‚åº”æ€§ã€æ¢¯åº¦å†²çªå’Œè®¡ç®—å¼€é”€æ–¹é¢çš„å±€é™æ€§ã€‚å„æ™ºèƒ½ä½“åˆ†åˆ«ä¸“æ³¨äºæŒ‡ä»¤æ¸…æ™°åº¦ã€ç¤ºä¾‹é€‰æ‹©åŠæ ¼å¼ç»“æ„ç­‰ä¸åŒç»´åº¦çš„ç²¾ç‚¼ï¼Œé€šè¿‡è¯­ä¹‰æ¢¯åº¦åµŒå…¥ã€å†²çªæ£€æµ‹ä¸èåˆæœºåˆ¶å®ç°ååŒå·¥ä½œã€‚ä¸ºäº†æå‡é²æ£’æ€§ï¼ŒMAPGDå¼•å…¥äº†è¶…çƒçº¦æŸæ¢¯åº¦èšç±»ï¼ˆHCGCï¼‰ä»¥å¼ºåŒ–æ¢¯åº¦çš„ç´§å‡‘æ€§ï¼Œå¹¶é‡‡ç”¨é€šé“è‡ªé€‚åº”æ™ºèƒ½ä½“åŠ æƒï¼ˆCAAWï¼‰æ ¹æ®éªŒè¯æ€§èƒ½åŠ¨æ€è°ƒæ•´æ™ºèƒ½ä½“è´¡çŒ®ã€‚å®éªŒç»“æœæ˜¾ç¤ºï¼ŒMAPGDåœ¨åˆ†ç±»å’Œæ¨ç†åŸºå‡†æµ‹è¯•ä¸­çš„å‡†ç¡®ç‡ä¸æ•ˆç‡å‡ä¼˜äºå•æ™ºèƒ½ä½“åŸºå‡†ã€‚æ¶ˆèå®éªŒè¯å®äº†æ¢¯åº¦èåˆä¸æ™ºèƒ½ä½“ä¸“é—¨åŒ–çš„æœ‰æ•ˆæ€§ï¼Œä½¿è¯¥æ¡†æ¶æˆä¸ºä¸€ä¸ªå…·æœ‰ç†è®ºæ”¶æ•›ä¿è¯ã€å¯è§£é‡Šä¸”ç¨³å¥çš„æç¤ºè¯ä¼˜åŒ–ç»Ÿä¸€æ–¹æ¡ˆã€‚",
      "categories": [
        "cs.AI"
      ],
      "primary_category": "cs.AI",
      "comment": "",
      "pdf_url": "https://arxiv.org/pdf/2509.11361v2",
      "published_date": "2025-09-14 17:28:52 UTC",
      "updated_date": "2025-10-07 09:25:03 UTC",
      "processing_status": "completed",
      "attempts": 1,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "llm_backup_calls": 0,
      "last_update": "2026-01-24T18:23:18.793383+00:00"
    },
    {
      "arxiv_id": "2509.11355v1",
      "title": "Promoting Shape Bias in CNNs: Frequency-Based and Contrastive Regularization for Corruption Robustness",
      "title_zh": "æå‡ CNN çš„å½¢çŠ¶åç½®ï¼šé¢å‘è…èš€é²æ£’æ€§çš„é¢‘ç‡ä¸å¯¹æ¯”æ­£åˆ™åŒ–",
      "authors": [
        "Robin Narsingh Ranabhat",
        "Longwei Wang",
        "Amit Kumar Patel",
        "KC santosh"
      ],
      "abstract": "Convolutional Neural Networks (CNNs) excel at image classification but remain vulnerable to common corruptions that humans handle with ease. A key reason for this fragility is their reliance on local texture cues rather than global object shapes -- a stark contrast to human perception. To address this, we propose two complementary regularization strategies designed to encourage shape-biased representations and enhance robustness. The first introduces an auxiliary loss that enforces feature consistency between original and low-frequency filtered inputs, discouraging dependence on high-frequency textures. The second incorporates supervised contrastive learning to structure the feature space around class-consistent, shape-relevant representations. Evaluated on the CIFAR-10-C benchmark, both methods improve corruption robustness without degrading clean accuracy. Our results suggest that loss-level regularization can effectively steer CNNs toward more shape-aware, resilient representations.",
      "tldr_zh": "è¿™é¡¹ç ”ç©¶æ¢è®¨äº†å·ç§¯ç¥ç»ç½‘ç»œ(CNNs)åœ¨å›¾åƒåˆ†ç±»ä¸­å®¹æ˜“å—åˆ°å¸¸è§æŸå(common corruptions)å½±å“çš„é—®é¢˜ï¼ŒæŒ‡å‡ºå…¶ä¸»è¦åŸå› æ˜¯æ¨¡å‹è¿‡åº¦ä¾èµ–å±€éƒ¨çº¹ç†(texture cues)è€Œéå…¨å±€å½¢çŠ¶(global object shapes)ã€‚ä¸ºäº†è§£å†³è¿™ä¸€è„†å¼±æ€§ï¼Œä½œè€…æå‡ºäº†ä¸¤ç§äº’è¡¥çš„æ­£åˆ™åŒ–ç­–ç•¥(regularization strategies)ä»¥å¢å¼ºæ¨¡å‹çš„å½¢çŠ¶åå·®(shape bias)ã€‚ç¬¬ä¸€ç§ç­–ç•¥é€šè¿‡è¾…åŠ©æŸå¤±å‡½æ•°(auxiliary loss)å¼ºåˆ¶åŸå§‹è¾“å…¥ä¸ä½é¢‘æ»¤æ³¢(low-frequency filtered)è¾“å…¥ä¹‹é—´çš„ç‰¹å¾ä¸€è‡´æ€§ï¼Œä»è€Œå‡å°‘å¯¹é«˜é¢‘çº¹ç†çš„ä¾èµ–ã€‚ç¬¬äºŒç§ç­–ç•¥å¼•å…¥äº†ç›‘ç£å¯¹æ¯”å­¦ä¹ (supervised contrastive learning)ï¼Œæ—¨åœ¨æ„å»ºå›´ç»•ç±»åˆ«ä¸€è‡´ä¸”ä¸å½¢çŠ¶ç›¸å…³çš„ç‰¹å¾ç©ºé—´ã€‚åœ¨CIFAR-10-CåŸºå‡†æµ‹è¯•ä¸Šçš„å®éªŒç»“æœæ˜¾ç¤ºï¼Œè¿™ä¸¤ç§æ–¹æ³•åœ¨ä¸ç‰ºç‰²å¹²å‡€å‡†ç¡®ç‡(clean accuracy)çš„å‰æä¸‹ï¼Œæ˜¾è‘—æå‡äº†æ¨¡å‹çš„æŸåé²æ£’æ€§(corruption robustness)ã€‚è¯¥ç ”ç©¶è¡¨æ˜ï¼Œé€šè¿‡æŸå¤±å±‚é¢çš„æ­£åˆ™åŒ–å¯ä»¥æœ‰æ•ˆå¼•å¯¼CNNså­¦ä¹ åˆ°æ›´å…·å½¢çŠ¶æ„ŸçŸ¥èƒ½åŠ›ä¸”æ›´å…·éŸ§æ€§çš„è¡¨ç¤ºã€‚",
      "categories": [
        "cs.CV",
        "cs.AI"
      ],
      "primary_category": "cs.CV",
      "comment": "12pages, 4 figures",
      "pdf_url": "https://arxiv.org/pdf/2509.11355v1",
      "published_date": "2025-09-14 17:14:07 UTC",
      "updated_date": "2025-09-14 17:14:07 UTC",
      "processing_status": "completed",
      "attempts": 1,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "llm_backup_calls": 0,
      "last_update": "2026-01-24T18:24:14.076717+00:00"
    },
    {
      "arxiv_id": "2510.01203v1",
      "title": "Mamba Outpaces Reformer in Stock Prediction with Sentiments from Top Ten LLMs",
      "title_zh": "ç»“åˆåå¤§ä¸»æµå¤§è¯­è¨€æ¨¡å‹æƒ…ç»ªï¼ŒMamba åœ¨è‚¡ç¥¨é¢„æµ‹ä¸­è¡¨ç°ä¼˜äº Reformer",
      "authors": [
        "Lokesh Antony Kadiyala",
        "Amir Mirzaeinia"
      ],
      "abstract": "The stock market is extremely difficult to predict in the short term due to high market volatility, changes caused by news, and the non-linear nature of the financial time series. This research proposes a novel framework for improving minute-level prediction accuracy using semantic sentiment scores from top ten different large language models (LLMs) combined with minute interval intraday stock price data. We systematically constructed a time-aligned dataset of AAPL news articles and 1-minute Apple Inc. (AAPL) stock prices for the dates of April 4 to May 2, 2025. The sentiment analysis was achieved using the DeepSeek-V3, GPT variants, LLaMA, Claude, Gemini, Qwen, and Mistral models through their APIs. Each article obtained sentiment scores from all ten LLMs, which were scaled to a [0, 1] range and combined with prices and technical indicators like RSI, ROC, and Bollinger Band Width. Two state-of-the-art such as Reformer and Mamba were trained separately on the dataset using the sentiment scores produced by each LLM as input. Hyper parameters were optimized by means of Optuna and were evaluated through a 3-day evaluation period. Reformer had mean squared error (MSE) or the evaluation metrics, and it should be noted that Mamba performed not only faster but also better than Reformer for every LLM across the 10 LLMs tested. Mamba performed best with LLaMA 3.3--70B, with the lowest error of 0.137. While Reformer could capture broader trends within the data, the model appeared to over smooth sudden changes by the LLMs. This study highlights the potential of integrating LLM-based semantic analysis paired with efficient temporal modeling to enhance real-time financial forecasting.",
      "tldr_zh": "è¯¥ç ”ç©¶æå‡ºäº†ä¸€ç§ç»“åˆåç§ä¸»æµå¤§è¯­è¨€æ¨¡å‹ï¼ˆLLMsï¼‰è¯­ä¹‰æƒ…æ„Ÿè¯„åˆ†ä¸åˆ†é’Ÿçº§è‚¡ç¥¨ä»·æ ¼æ•°æ®çš„æ–°å‹é¢„æµ‹æ¡†æ¶ï¼Œæ—¨åœ¨æå‡é«˜æ³¢åŠ¨æ€§å¸‚åœºç¯å¢ƒä¸‹çš„çŸ­æœŸé¢„æµ‹å‡†ç¡®æ€§ã€‚ç ”ç©¶å›¢é˜Ÿæ„å»ºäº†ä¸€ä¸ªåŒ…å«AAPLæ–°é—»åŠ1åˆ†é’Ÿé¢‘ç‡è‚¡ä»·çš„åŒæ­¥æ•°æ®é›†ï¼Œåˆ©ç”¨DeepSeek-V3ã€GPTã€LLaMAã€Claudeã€Geminiã€Qwenå’ŒMistralç­‰æ¨¡å‹çš„APIæå–æƒ…æ„Ÿåˆ†æ•°ï¼Œå¹¶ç»“åˆRSIã€ROCå’ŒBollinger Band Widthç­‰æŠ€æœ¯æŒ‡æ ‡è¿›è¡Œå»ºæ¨¡ã€‚é€šè¿‡å¯¹æ¯”Reformerå’ŒMambaä¸¤ç§å…ˆè¿›æ¶æ„å¹¶åˆ©ç”¨Optunaä¼˜åŒ–è¶…å‚æ•°ï¼Œå®éªŒç»“æœæ˜¾ç¤ºMambaåœ¨æ‰€æœ‰æƒ…æ„Ÿè¾“å…¥ä¸‹å‡ä¼˜äºReformerï¼Œå±•ç°å‡ºæ›´å¿«çš„è¿è¡Œé€Ÿåº¦å’Œæ›´é«˜çš„é¢„æµ‹ç²¾åº¦ã€‚å…¶ä¸­ï¼ŒMambaä¸LLaMA 3.3-70Bçš„ç»„åˆè¾¾åˆ°äº†0.137çš„æœ€ä½å‡æ–¹è¯¯å·®ï¼ˆMSEï¼‰ï¼Œè€ŒReformeråˆ™è¡¨ç°å‡ºå¯¹æƒ…æ„Ÿå¼•å‘çš„çªå‘ä»·æ ¼å˜åŒ–è¿‡åº¦å¹³æ»‘çš„é—®é¢˜ã€‚è¯¥ç ”ç©¶å¼ºè°ƒäº†å°†åŸºäºLLMçš„è¯­ä¹‰åˆ†æä¸é«˜æ•ˆæ—¶åºå»ºæ¨¡ç›¸ç»“åˆåœ¨å®æ—¶é‡‘èé¢„æµ‹é¢†åŸŸçš„å·¨å¤§æ½œåŠ›ã€‚",
      "categories": [
        "q-fin.ST",
        "cs.AI",
        "cs.LG"
      ],
      "primary_category": "q-fin.ST",
      "comment": "",
      "pdf_url": "https://arxiv.org/pdf/2510.01203v1",
      "published_date": "2025-09-14 16:36:24 UTC",
      "updated_date": "2025-09-14 16:36:24 UTC",
      "processing_status": "completed",
      "attempts": 1,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "llm_backup_calls": 0,
      "last_update": "2026-01-24T18:23:39.893014+00:00"
    },
    {
      "arxiv_id": "2509.18137v1",
      "title": "LoRALib: A Standardized Benchmark for Evaluating LoRA-MoE Methods",
      "title_zh": "LoRALibï¼šè¯„ä¼° LoRA-MoE æ–¹æ³•çš„æ ‡å‡†åŒ–åŸºå‡†",
      "authors": [
        "Shaoheng Wang",
        "Yao Lu",
        "Yuqi Li",
        "Yaxin Gao",
        "Jiaqi Nie",
        "Shanqing Yu",
        "Yingli Tian",
        "Qi Xuan"
      ],
      "abstract": "As a parameter efficient fine-tuning (PEFT) method, low-rank adaptation (LoRA) can save significant costs in storage and computing, but its strong adaptability to a single task is often accompanied by insufficient cross-task generalization capabilities. To improve this, existing work combines LoRA with mixture-of-experts (MoE) to enhance the model's adaptability through expert modules and routing mechanisms. However, existing LoRA-MoE methods lack unified standards in models, datasets, hyperparameters, and evaluation methods, making it difficult to conduct fair comparisons between different methods. To this end, we proposed a unified benchmark named LoRALib. Specifically, we standardized datasets from $40$ downstream tasks into a unified format, fine-tuned them using the same hyperparameters and obtained $680$ LoRA modules across $17$ model architectures. Based on this LoRA library, we conduct large-scale experiments on $3$ representative LoRA-MoE methods and different LoRA selection mechanisms using the open-sourced testing tool OpenCompass. Extensive experiments show that LoRAMoE performs best, and that prioritizing LoRAs relevant to the target task can further improve the performance of MoE. We hope these findings will inspire future work. Our datasets and LoRA library are available at https://huggingface.co/datasets/YaoLuzjut/LoRAOcean_dataset and https://huggingface.co/YaoLuzjut/models.",
      "tldr_zh": "è¯¥ç ”ç©¶æå‡ºäº†LoRALibï¼Œè¿™æ˜¯ä¸€ä¸ªæ—¨åœ¨è¯„ä¼°LoRA-MoEæ–¹æ³•çš„ç»Ÿä¸€æ ‡å‡†åŒ–åŸºå‡†ï¼Œè§£å†³äº†ç°æœ‰ç ”ç©¶åœ¨æ¨¡å‹ã€æ•°æ®é›†å’Œè¯„ä¼°æ–¹æ³•ä¸Šç¼ºä¹ä¸€è‡´æ€§è€Œéš¾ä»¥è¿›è¡Œå…¬å¹³æ¯”è¾ƒçš„é—®é¢˜ã€‚ç ”ç©¶è€…å°†40ä¸ªä¸‹æ¸¸ä»»åŠ¡çš„æ•°æ®é›†è¿›è¡Œäº†æ ‡å‡†åŒ–å¤„ç†ï¼Œå¹¶åœ¨17ç§æ¨¡å‹æ¶æ„ä¸Šå¾®è°ƒè·å¾—äº†680ä¸ªLoRAæ¨¡å—ã€‚åŸºäºè¯¥åº“ï¼Œç ”ç©¶å›¢é˜Ÿåˆ©ç”¨å¼€æºå·¥å…·OpenCompasså¯¹ä¸‰ç§ä»£è¡¨æ€§çš„LoRA-MoEæ–¹æ³•åŠä¸åŒçš„LoRAé€‰æ‹©æœºåˆ¶è¿›è¡Œäº†å¤§è§„æ¨¡å®éªŒã€‚ç»“æœæ˜¾ç¤ºï¼ŒLoRAMoEåœ¨å¯¹æ¯”ä¸­è¡¨ç°æœ€ä½³ï¼Œä¸”ä¼˜å…ˆé€‰æ‹©ä¸ç›®æ ‡ä»»åŠ¡ç›¸å…³çš„LoRAä¸“å®¶æ¨¡å—èƒ½è¿›ä¸€æ­¥æå‡æ¨¡å‹æ€§èƒ½ã€‚è¯¥åŸºå‡†ä¸ºæœªæ¥LoRAä¸Mixture-of-Expertsç»“åˆçš„ç ”ç©¶æä¾›äº†é‡è¦å‚è€ƒï¼Œå¹¶å…¬å¼€äº†ç›¸å…³æ•°æ®é›†ä¸æ¨¡å‹åº“ã€‚",
      "categories": [
        "cs.LG",
        "cs.AI"
      ],
      "primary_category": "cs.LG",
      "comment": "",
      "pdf_url": "https://arxiv.org/pdf/2509.18137v1",
      "published_date": "2025-09-14 16:33:17 UTC",
      "updated_date": "2025-09-14 16:33:17 UTC",
      "processing_status": "completed",
      "attempts": 1,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "llm_backup_calls": 0,
      "last_update": "2026-01-24T18:23:43.189126+00:00"
    },
    {
      "arxiv_id": "2509.11336v1",
      "title": "The power of dynamic causality in observer-based design for soft sensor applications",
      "title_zh": "åŠ¨æ€å› æœå…³ç³»åœ¨è½¯æµ‹é‡åº”ç”¨ä¸­åŸºäºè§‚æµ‹å™¨è®¾è®¡çš„æ•ˆèƒ½",
      "authors": [
        "William Farlessyost",
        "Sebastian Oberst",
        "Shweta Singh"
      ],
      "abstract": "This paper introduces a novel framework for optimizing observer-based soft sensors through dynamic causality analysis. Traditional approaches to sensor selection often rely on linearized observability indices or statistical correlations that fail to capture the temporal evolution of complex systems. We address this gap by leveraging liquid-time constant (LTC) networks, continuous-time neural architectures with input-dependent time constants, to systematically identify and prune sensor inputs with minimal causal influence on state estimation. Our methodology implements an iterative workflow: training an LTC observer on candidate inputs, quantifying each input's causal impact through controlled perturbation analysis, removing inputs with negligible effect, and retraining until performance degradation occurs. We demonstrate this approach on three mechanistic testbeds representing distinct physical domains: a harmonically forced spring-mass-damper system, a nonlinear continuous stirred-tank reactor, and a predator-prey model following the structure of the Lotka-Volterra model, but with seasonal forcing and added complexity. Results show that our causality-guided pruning consistently identifies minimal sensor sets that align with underlying physics while improving prediction accuracy. The framework automatically distinguishes essential physical measurements from noise and determines when derived interaction terms provide complementary versus redundant information. Beyond computational efficiency, this approach enhances interpretability by grounding sensor selection decisions in dynamic causal relationships rather than static correlations, offering significant benefits for soft sensing applications across process engineering, ecological monitoring, and agricultural domains.",
      "tldr_zh": "è¯¥ç ”ç©¶æå‡ºäº†ä¸€ç§åŸºäºåŠ¨æ€å› æœå…³ç³»(Dynamic Causality)åˆ†æçš„è½¯ä¼ æ„Ÿå™¨(Soft Sensor)è§‚æµ‹å™¨è®¾è®¡æ¡†æ¶ï¼Œæ—¨åœ¨è§£å†³ä¼ ç»Ÿæ–¹æ³•éš¾ä»¥æ•æ‰å¤æ‚ç³»ç»Ÿæ—¶åºæ¼”åŒ–çš„é—®é¢˜ã€‚è¯¥æ¡†æ¶åˆ©ç”¨å…·æœ‰è¾“å…¥ç›¸å…³æ—¶é—´å¸¸æ•°çš„è¿ç»­æ—¶é—´ç¥ç»æ¶æ„Liquid-Time Constant (LTC)ç½‘ç»œï¼Œé€šè¿‡è¿­ä»£å·¥ä½œæµç³»ç»Ÿåœ°è¯†åˆ«å¹¶å‰”é™¤å¯¹çŠ¶æ€ä¼°è®¡å› æœå½±å“è¾ƒå°çš„ä¼ æ„Ÿå™¨è¾“å…¥ã€‚ç ”ç©¶åœ¨å¼¹ç°§-è´¨é‡-é˜»å°¼ç³»ç»Ÿã€éçº¿æ€§è¿ç»­æ…æ‹Œååº”é‡œ(CSTR)ä»¥åŠæ•é£Ÿè€…-çŒç‰©æ¨¡å‹ç­‰å¤šä¸ªç‰©ç†é¢†åŸŸè¿›è¡Œäº†éªŒè¯ã€‚å®éªŒç»“æœè¯æ˜ï¼Œè¯¥æ–¹æ³•èƒ½å‡†ç¡®è¯†åˆ«å‡ºä¸åº•å±‚ç‰©ç†é€»è¾‘ä¸€è‡´çš„æœ€ç®€ä¼ æ„Ÿå™¨é›†åˆï¼Œåœ¨æé«˜é¢„æµ‹ç²¾åº¦çš„åŒæ—¶æœ‰æ•ˆåŒºåˆ†äº†æ ¸å¿ƒç‰©ç†æµ‹é‡å€¼ä¸å™ªå£°ã€‚ç›¸æ¯”äºé™æ€ç›¸å…³æ€§åˆ†æï¼Œè¯¥æ¡†æ¶é€šè¿‡å»ºç«‹åŠ¨æ€å› æœå…³ç³»æ˜¾è‘—å¢å¼ºäº†æ¨¡å‹çš„å¯è§£é‡Šæ€§å’Œè®¡ç®—æ•ˆç‡ï¼Œä¸ºè¿‡ç¨‹å·¥ç¨‹ã€ç”Ÿæ€ç›‘æµ‹ç­‰é¢†åŸŸçš„è½¯ä¼ æ„Ÿåº”ç”¨æä¾›äº†æœ‰åŠ›æ”¯æŒã€‚",
      "categories": [
        "cs.AI"
      ],
      "primary_category": "cs.AI",
      "comment": "",
      "pdf_url": "https://arxiv.org/pdf/2509.11336v1",
      "published_date": "2025-09-14 16:27:58 UTC",
      "updated_date": "2025-09-14 16:27:58 UTC",
      "processing_status": "completed",
      "attempts": 1,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "llm_backup_calls": 0,
      "last_update": "2026-01-24T18:23:48.659648+00:00"
    },
    {
      "arxiv_id": "2509.11332v1",
      "title": "A five-layer framework for AI governance: integrating regulation, standards, and certification",
      "title_zh": "äººå·¥æ™ºèƒ½æ²»ç†äº”å±‚æ¡†æ¶ï¼šç›‘ç®¡ã€æ ‡å‡†ä¸è®¤è¯çš„æ•´åˆ",
      "authors": [
        "Avinash Agarwal",
        "Manisha J. Nene"
      ],
      "abstract": "Purpose: The governance of artificial iintelligence (AI) systems requires a structured approach that connects high-level regulatory principles with practical implementation. Existing frameworks lack clarity on how regulations translate into conformity mechanisms, leading to gaps in compliance and enforcement. This paper addresses this critical gap in AI governance.\n  Methodology/Approach: A five-layer AI governance framework is proposed, spanning from broad regulatory mandates to specific standards, assessment methodologies, and certification processes. By narrowing its scope through progressively focused layers, the framework provides a structured pathway to meet technical, regulatory, and ethical requirements. Its applicability is validated through two case studies on AI fairness and AI incident reporting.\n  Findings: The case studies demonstrate the framework's ability to identify gaps in legal mandates, standardization, and implementation. It adapts to both global and region-specific AI governance needs, mapping regulatory mandates with practical applications to improve compliance and risk management.\n  Practical Implications - By offering a clear and actionable roadmap, this work contributes to global AI governance by equipping policymakers, regulators, and industry stakeholders with a model to enhance compliance and risk management.\n  Social Implications: The framework supports the development of policies that build public trust and promote the ethical use of AI for the benefit of society.\n  Originality/Value: This study proposes a five-layer AI governance framework that bridges high-level regulatory mandates and implementation guidelines. Validated through case studies on AI fairness and incident reporting, it identifies gaps such as missing standardized assessment procedures and reporting mechanisms, providing a structured foundation for targeted governance measures.",
      "tldr_zh": "æœ¬ç ”ç©¶é’ˆå¯¹äººå·¥æ™ºèƒ½æ²»ç†ï¼ˆAI governanceï¼‰ä¸­é«˜å±‚ç›‘ç®¡åŸåˆ™ä¸å®é™…æ‰§è¡Œä¹‹é—´ç¼ºä¹æœ‰æ•ˆè¡”æ¥çš„é—®é¢˜ï¼Œæå‡ºäº†ä¸€ä¸ªäº”å±‚ AI æ²»ç†æ¡†æ¶ã€‚è¯¥æ¡†æ¶æ¶µç›–äº†ä»å®è§‚ç›‘ç®¡æŒ‡ä»¤ï¼ˆregulatory mandatesï¼‰åˆ°å…·ä½“æ ‡å‡†ï¼ˆstandardsï¼‰ã€è¯„ä¼°æ–¹æ³•ï¼ˆassessment methodologiesï¼‰åŠè®¤è¯æµç¨‹ï¼ˆcertification processesï¼‰çš„é€’è¿›å±‚çº§ï¼Œä¸ºæ»¡è¶³æŠ€æœ¯ã€ç›‘ç®¡å’Œä¼¦ç†è¦æ±‚æä¾›äº†ç»“æ„åŒ–è·¯å¾„ã€‚é€šè¿‡ AI å…¬å¹³æ€§ï¼ˆAI fairnessï¼‰å’Œ AI äº‹ä»¶æŠ¥å‘Šï¼ˆAI incident reportingï¼‰ä¸¤ä¸ªæ¡ˆä¾‹ç ”ç©¶ï¼Œè¯¥æ¡†æ¶éªŒè¯äº†å…¶è¯†åˆ«æ³•å¾‹æŒ‡ä»¤ä¸æ ‡å‡†å®æ–½å·®è·çš„èƒ½åŠ›ã€‚ç ”ç©¶å‘ç°ï¼Œè¯¥æ¨¡å‹èƒ½æœ‰æ•ˆå°†ç›‘ç®¡è¦æ±‚æ˜ å°„è‡³å®é™…åº”ç”¨ï¼Œæå‡äº†åˆè§„æ€§ï¼ˆcomplianceï¼‰ä¸é£é™©ç®¡ç†ï¼ˆrisk managementï¼‰æ°´å¹³ã€‚è¿™ä¸€æˆæœä¸ºæ”¿ç­–åˆ¶å®šè€…å’Œè¡Œä¸šåˆ©ç›Šç›¸å…³è€…æä¾›äº†å¯æ“ä½œçš„è·¯çº¿å›¾ï¼Œæ—¨åœ¨å¡«è¡¥æ²»ç†ç©ºç™½å¹¶å¢å¼ºå…¬ä¼—å¯¹ AI ä¼¦ç†ä½¿ç”¨çš„ä¿¡ä»»ã€‚",
      "categories": [
        "cs.CY",
        "cs.AI",
        "cs.HC"
      ],
      "primary_category": "cs.CY",
      "comment": "17 pages, 2 tables, 1 figure. This is the authors' accepted manuscript of the article published as: Avinash Agarwal, Manisha J. Nene; \"A five-layer framework for AI governance: integrating regulation, standards, and certification.\" Transforming Government: People, Process and Policy, 11 September 2025; 19 (3): 535-555. https://doi.org/10.1108/TG-03-2025-0065",
      "pdf_url": "https://arxiv.org/pdf/2509.11332v1",
      "published_date": "2025-09-14 16:19:08 UTC",
      "updated_date": "2025-09-14 16:19:08 UTC",
      "processing_status": "completed",
      "attempts": 1,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "llm_backup_calls": 0,
      "last_update": "2026-01-24T18:23:49.191360+00:00"
    },
    {
      "arxiv_id": "2509.11330v1",
      "title": "Decoding Plastic Toxicity: An Intelligent Framework for Conflict-Aware Relational Metapath Extraction from Scientific Abstracts",
      "title_zh": "è§£ç å¡‘æ–™æ¯’æ€§ï¼šä¸€ç§ç”¨äºç§‘å­¦æ‘˜è¦ä¸­å†²çªæ„ŸçŸ¥å…³ç³»å…ƒè·¯å¾„æå–çš„æ™ºèƒ½æ¡†æ¶",
      "authors": [
        "Sudeshna Jana",
        "Manjira Sinha",
        "Tirthankar Dasgupta"
      ],
      "abstract": "The widespread use of plastics and their persistence in the environment have led to the accumulation of micro- and nano-plastics across air, water, and soil, posing serious health risks including respiratory, gastrointestinal, and neurological disorders. We propose a novel framework that leverages large language models to extract relational metapaths, multi-hop semantic chains linking pollutant sources to health impacts, from scientific abstracts. Our system identifies and connects entities across diverse contexts to construct structured relational metapaths, which are aggregated into a Toxicity Trajectory Graph that traces pollutant propagation through exposure routes and biological systems. Moreover, to ensure consistency and reliability, we incorporate a dynamic evidence reconciliation module that resolves semantic conflicts arising from evolving or contradictory research findings. Our approach demonstrates strong performance in extracting reliable, high-utility relational knowledge from noisy scientific text and offers a scalable solution for mining complex cause-effect structures in domain-specific corpora.",
      "tldr_zh": "è¯¥ç ”ç©¶æå‡ºäº†ä¸€ä¸ªåŸºäºå¤§è¯­è¨€æ¨¡å‹(Large Language Models)çš„æ™ºèƒ½æ¡†æ¶ï¼Œæ—¨åœ¨ä»ç§‘å­¦æ‘˜è¦ä¸­æå–å…³ç³»å…ƒè·¯å¾„(Relational Metapaths)ï¼Œä»¥ç³»ç»Ÿæ€§åœ°è§£ç å¾®å¡‘æ–™å’Œçº³ç±³å¡‘æ–™å¯¹äººä½“å¥åº·çš„æ½œåœ¨å¨èƒã€‚è¯¥ç³»ç»Ÿé€šè¿‡æ„å»ºå¤šè·³è¯­ä¹‰é“¾è¿æ¥æ±¡æŸ“ç‰©æ¥æºä¸å¥åº·å½±å“ï¼Œå¹¶å°†è¿™äº›è·¯å¾„æ•´åˆä¸ºæ¯’æ€§è½¨è¿¹å›¾(Toxicity Trajectory Graph)ï¼Œå®ç°äº†å¯¹æ±¡æŸ“ç‰©åœ¨æš´éœ²é€”å¾„å’Œç”Ÿç‰©ç³»ç»Ÿå†…ä¼ æ’­è·¯å¾„çš„å¯è§†åŒ–è¿½è¸ªã€‚é’ˆå¯¹ç§‘å­¦ç ”ç©¶ä¸­å¯èƒ½å­˜åœ¨çš„ç›¸äº’çŸ›ç›¾æˆ–ä¸æ–­æ¼”å˜çš„ç»“è®ºï¼Œæ¡†æ¶å¼•å…¥äº†åŠ¨æ€è¯æ®è°ƒè§£æ¨¡å—(Dynamic Evidence Reconciliation Module)æ¥è§£å†³è¯­ä¹‰å†²çªï¼Œç¡®ä¿äº†çŸ¥è¯†æå–çš„å¯é æ€§ä¸ä¸€è‡´æ€§ã€‚å®éªŒç»“æœè¯æ˜ï¼Œè¯¥æ–¹æ³•åœ¨ä»å™ªå£°ç§‘å­¦æ–‡æœ¬ä¸­æå–é«˜è´¨é‡ã€é«˜å®ç”¨æ€§çš„å› æœå…³ç³»çŸ¥è¯†æ–¹é¢è¡¨ç°å‡ºè‰²ã€‚è¯¥æ–¹æ¡ˆä¸ºé¢†åŸŸç‰¹å®šè¯­æ–™åº“ä¸­å¤æ‚å› æœç»“æ„çš„è‡ªåŠ¨åŒ–æŒ–æ˜æä¾›äº†ä¸€ç§å¯æ‰©å±•ä¸”é«˜æ•ˆçš„è§£å†³è·¯å¾„ã€‚",
      "categories": [
        "cs.AI"
      ],
      "primary_category": "cs.AI",
      "comment": "11 pages, 6 figures, 4 tables",
      "pdf_url": "https://arxiv.org/pdf/2509.11330v1",
      "published_date": "2025-09-14 16:14:36 UTC",
      "updated_date": "2025-09-14 16:14:36 UTC",
      "processing_status": "completed",
      "attempts": 1,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "llm_backup_calls": 0,
      "last_update": "2026-01-24T18:24:08.068806+00:00"
    },
    {
      "arxiv_id": "2509.11323v1",
      "title": "Motion Estimation for Multi-Object Tracking using KalmanNet with Semantic-Independent Encoding",
      "title_zh": "åŸºäºè¯­ä¹‰ç‹¬ç«‹ç¼–ç  KalmanNet çš„å¤šç›®æ ‡è·Ÿè¸ªè¿åŠ¨ä¼°è®¡",
      "authors": [
        "Jian Song",
        "Wei Mei",
        "Yunfeng Xu",
        "Qiang Fu",
        "Renke Kou",
        "Lina Bu",
        "Yucheng Long"
      ],
      "abstract": "Motion estimation is a crucial component in multi-object tracking (MOT).\n  It predicts the trajectory of objects by analyzing the changes in their positions in consecutive frames of images, reducing tracking failures and identity switches.\n  The Kalman filter (KF) based on the linear constant-velocity model is one of the most commonly used methods in MOT.\n  However, it may yield unsatisfactory results when KF's parameters are mismatched and objects move in non-stationary.\n  In this work, we utilize the learning-aided filter to handle the motion estimation of MOT.\n  In particular, we propose a novel method named Semantic-Independent KalmanNet (SIKNet), which encodes the state vector (the input feature) using a Semantic-Independent Encoder (SIE) by two steps.\n  First, the SIE uses a 1D convolution with a kernel size of 1, which convolves along the dimension of homogeneous-semantic elements across different state vectors to encode independent semantic information.\n  Then it employs a fully-connected layer and a nonlinear activation layer to encode nonlinear and cross-dependency information between heterogeneous-semantic elements.\n  To independently evaluate the performance of the motion estimation module in MOT, we constructed a large-scale semi-simulated dataset from several open-source MOT datasets.\n  Experimental results demonstrate that the proposed SIKNet outperforms the traditional KF and achieves superior robustness and accuracy than existing learning-aided filters.\n  The code is available at (https://github.com/SongJgit/filternet and https://github.com/SongJgit/TBDTracker).",
      "tldr_zh": "è¯¥ç ”ç©¶é’ˆå¯¹å¤šç›®æ ‡è·Ÿè¸ª(Multi-Object Tracking, MOT)ä¸­çš„è¿åŠ¨ä¼°è®¡é—®é¢˜ï¼Œæ¢è®¨äº†ä¼ ç»Ÿå¡å°”æ›¼æ»¤æ³¢(Kalman Filter, KF)åœ¨å‚æ•°ä¸åŒ¹é…åŠéå¹³ç¨³è¿åŠ¨åœºæ™¯ä¸‹æ•ˆæœä¸ä½³çš„å±€é™æ€§ã€‚ä¸ºæ­¤ï¼Œç ”ç©¶è€…æå‡ºäº†ä¸€ç§åä¸ºSemantic-Independent KalmanNet (SIKNet)çš„æ·±åº¦å­¦ä¹ è¾…åŠ©æ»¤æ³¢æ–¹æ³•ï¼Œæ ¸å¿ƒåœ¨äºå¼•å…¥äº†è¯­ä¹‰ç‹¬ç«‹ç¼–ç å™¨(Semantic-Independent Encoder, SIE)ã€‚è¯¥ç¼–ç å™¨é¦–å…ˆåˆ©ç”¨ä¸€ç»´å·ç§¯(1D convolution)æå–åŒæ„è¯­ä¹‰å…ƒç´ çš„ç‹¬ç«‹ä¿¡æ¯ï¼Œå†é€šè¿‡å…¨è¿æ¥å±‚æ•æ‰å¼‚æ„è¯­ä¹‰å…ƒç´ é—´çš„éçº¿æ€§äº¤å‰ä¾èµ–å…³ç³»ã€‚ä¸ºäº†å…¬å¹³è¯„ä¼°è¿åŠ¨ä¼°è®¡æ€§èƒ½ï¼Œç ”ç©¶å›¢é˜Ÿè¿˜åŸºäºå¤šä¸ªå¼€æºMOTæ•°æ®é›†æ„å»ºäº†å¤§è§„æ¨¡åŠæ¨¡æ‹Ÿæ•°æ®é›†ã€‚å®éªŒç»“æœæ˜¾ç¤ºï¼ŒSIKNetåœ¨å‡†ç¡®æ€§å’Œé²æ£’æ€§ä¸Šå‡ä¼˜äºä¼ ç»ŸKFåŠç°æœ‰çš„å­¦ä¹ è¾…åŠ©æ»¤æ³¢å™¨ï¼Œèƒ½æœ‰æ•ˆå‡å°‘è·Ÿè¸ªå¤±è´¥ä¸èº«ä»½åˆ‡æ¢(Identity Switches)ã€‚è¯¥æ–¹æ³•ä¸ºå¤„ç†å¤æ‚åŠ¨æ€ç¯å¢ƒä¸‹çš„ç›®æ ‡è½¨è¿¹é¢„æµ‹æä¾›äº†æ›´ä¸ºç²¾ç¡®çš„è§£å†³æ–¹æ¡ˆã€‚",
      "categories": [
        "cs.CV",
        "cs.AI"
      ],
      "primary_category": "cs.CV",
      "comment": "",
      "pdf_url": "https://arxiv.org/pdf/2509.11323v1",
      "published_date": "2025-09-14 15:57:46 UTC",
      "updated_date": "2025-09-14 15:57:46 UTC",
      "processing_status": "completed",
      "attempts": 1,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "llm_backup_calls": 0,
      "last_update": "2026-01-24T18:24:00.164542+00:00"
    },
    {
      "arxiv_id": "2509.12282v1",
      "title": "AIssistant: An Agentic Approach for Human--AI Collaborative Scientific Work on Reviews and Perspectives in Machine Learning",
      "title_zh": "AIssistantï¼šä¸€ç§é¢å‘æœºå™¨å­¦ä¹ ç»¼è¿°ä¸è¿°è¯„çš„äººæœºåä½œç§‘ç ”æ™ºèƒ½ä½“æ–¹æ³•",
      "authors": [
        "Sasi Kiran Gaddipati",
        "Farhana Keya",
        "Gollam Rabby",
        "SÃ¶ren Auer"
      ],
      "abstract": "Advances in AI-assisted research have introduced powerful tools for literature retrieval, hypothesis generation, experimentation, and manuscript preparation. However, systems remain fragmented and lack human-centred workflows. To address these gaps, we introduce AIssistant, an agentic, open-source Human-AI collaborative framework designed to simplify the end-to-end creation of scientific workflows. Since our development is still in an early stage, we present here the first experiments with AIssistant for perspective and review research papers in machine learning. Our system integrates modular tools and agents for literature synthesis, section-wise experimentation, citation management, and automatic LaTeX paper text generation, while maintaining human oversight at every stage to ensure accuracy, coherence, and scholarly rigour. We conducted a comprehensive evaluation across three layers: (1) Independent Human Review, following NeurIPS double-blind standards; (2) Automated LLM Review, using GPT-5 as a scalable human review proxy; and (3) Program Chair Oversight, where the chair monitors the entire review process and makes final validation and acceptance decisions. The results demonstrate that AIssistant improves drafting efficiency and thematic consistency. Nonetheless, Human-AI collaboration remains essential for maintaining factual correctness, methodological soundness, and ethical compliance. Despite its effectiveness, we identify key limitations, including hallucinated citations, difficulty adapting to dynamic paper structures, and incomplete integration of multimodal content.",
      "tldr_zh": "è¯¥ç ”ç©¶æå‡ºäº† AIssistantï¼Œè¿™æ˜¯ä¸€ä¸ªå¼€æºçš„ Agentic äººæœºåä½œæ¡†æ¶ï¼Œæ—¨åœ¨é€šè¿‡é›†æˆæ¨¡å—åŒ–å·¥å…·å’Œæ™ºèƒ½ä½“æ¥ç®€åŒ–æœºå™¨å­¦ä¹ é¢†åŸŸç»¼è¿°åŠè§‚ç‚¹è®ºæ–‡çš„ç§‘ç ”å·¥ä½œæµã€‚è¯¥æ¡†æ¶æ¶µç›–äº†æ–‡çŒ®åˆæˆã€åˆ†ç« èŠ‚å®éªŒã€å¼•ç”¨ç®¡ç†å’Œè‡ªåŠ¨ç”Ÿæˆ LaTeX è®ºæ–‡æ–‡æœ¬ç­‰åŠŸèƒ½ï¼Œå¹¶åœ¨æ•´ä¸ªè¿‡ç¨‹ä¸­å¼•å…¥äººç±»ç›‘ç£ä»¥ç¡®ä¿å­¦æœ¯ä¸¥è°¨ã€‚é€šè¿‡äººç±»ç‹¬ç«‹è¯„å®¡ã€GPT-5 è‡ªåŠ¨åŒ–è¯„å®¡åŠä¸»å¸­ç›‘ç£çš„ä¸‰å±‚è¯„ä¼°ä½“ç³»ï¼Œç»“æœæ˜¾ç¤º AIssistant èƒ½æœ‰æ•ˆæå‡è®ºæ–‡æ’°å†™æ•ˆç‡å’Œä¸»é¢˜ä¸€è‡´æ€§ã€‚ç„¶è€Œï¼Œç ”ç©¶ä¹ŸæŒ‡å‡º Human-AI åä½œåœ¨çº æ­£äº‹å®é”™è¯¯å’Œç¡®ä¿ä¼¦ç†åˆè§„æ–¹é¢ä»è‡³å…³é‡è¦ã€‚ç›®å‰è¯¥ç³»ç»Ÿä»é¢ä¸´å¼•æ–‡å¹»è§‰ (Hallucinated Citations)ã€éš¾ä»¥åº”å¯¹åŠ¨æ€ç»“æ„ä»¥åŠå¤šæ¨¡æ€é›†æˆä¸å…¨ç­‰æŠ€æœ¯æŒ‘æˆ˜ã€‚",
      "categories": [
        "cs.AI",
        "cs.LG"
      ],
      "primary_category": "cs.AI",
      "comment": "",
      "pdf_url": "https://arxiv.org/pdf/2509.12282v1",
      "published_date": "2025-09-14 15:50:31 UTC",
      "updated_date": "2025-09-14 15:50:31 UTC",
      "processing_status": "completed",
      "attempts": 1,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "llm_backup_calls": 0,
      "last_update": "2026-01-24T18:24:07.251760+00:00"
    },
    {
      "arxiv_id": "2509.19331v2",
      "title": "Holographic Transformers for Complex-Valued Signal Processing: Integrating Phase Interference into Self-Attention",
      "title_zh": "ç”¨äºå¤å€¼ä¿¡å·å¤„ç†çš„å…¨æ¯ Transformerï¼šå°†ç›¸ä½å¹²æ¶‰é›†æˆè‡³è‡ªæ³¨æ„åŠ›æœºåˆ¶",
      "authors": [
        "Enhao Huang",
        "Zhiyu Zhang",
        "Tianxiang Xu",
        "Chunshu Xia",
        "Kaichun Hu",
        "Yuchen Yang",
        "Tongtong Pan",
        "Dong Dong",
        "Zhan Qin"
      ],
      "abstract": "Complex-valued signals encode both amplitude and phase, yet most deep models treat attention as real-valued correlation, overlooking interference effects. We introduce the Holographic Transformer, a physics-inspired architecture that incorporates wave interference principles into self-attention. Holographic attention modulates interactions by relative phase and coherently superimposes values, ensuring consistency between amplitude and phase. A dual-headed decoder simultaneously reconstructs the input and predicts task outputs, preventing phase collapse when losses prioritize magnitude over phase. We demonstrate that holographic attention implements a discrete interference operator and maintains phase consistency under linear mixing. Experiments on PolSAR image classification and wireless channel prediction show strong performance, achieving high classification accuracy and F1 scores, low regression error, and increased robustness to phase perturbations. These results highlight that enforcing physical consistency in attention leads to generalizable improvements in complex-valued learning and provides a unified, physics-based framework for coherent signal modeling. The code is available at https://github.com/EonHao/Holographic-Transformers.",
      "tldr_zh": "æœ¬ç ”ç©¶æå‡ºäº†Holographic Transformerï¼Œè¿™æ˜¯ä¸€ç§å—ç‰©ç†å­¦å¯å‘çš„æ¶æ„ï¼Œæ—¨åœ¨å°†æ³¢å¹²æ¶‰(wave interference)åŸç†é›†æˆåˆ°è‡ªæ³¨æ„åŠ›(self-attention)æœºåˆ¶ä¸­ï¼Œä»¥è§£å†³å¤å€¼ä¿¡å·å¤„ç†ä¸­å¤æ•°æ³¨æ„åŠ›è¢«ç®€åŒ–ä¸ºå®å€¼ç›¸å…³æ€§è€Œå¿½ç•¥å¹²æ¶‰æ•ˆåº”çš„é—®é¢˜ã€‚è¯¥æ¶æ„ä¸­çš„å…¨æ¯æ³¨æ„åŠ›(holographic attention)é€šè¿‡ç›¸å¯¹ç›¸ä½è°ƒèŠ‚äº¤äº’å¹¶ç›¸å¹²åœ°å åŠ æ•°å€¼ï¼Œæœ‰æ•ˆç¡®ä¿äº†æŒ¯å¹…(amplitude)ä¸ç›¸ä½(phase)ä¹‹é—´çš„ä¸€è‡´æ€§ã€‚ä¸ºäº†é˜²æ­¢åœ¨æŸå¤±å‡½æ•°ä¼˜å…ˆè€ƒè™‘å¹…åº¦æ—¶å‘ç”Ÿç›¸ä½åç¼©(phase collapse)ï¼Œç ”ç©¶å¼•å…¥äº†ä¸€ä¸ªåŒå¤´è§£ç å™¨(dual-headed decoder)æ¥åŒæ—¶è¿›è¡Œè¾“å…¥é‡å»ºä¸ä»»åŠ¡é¢„æµ‹ã€‚å®éªŒè¯æ˜ï¼Œå…¨æ¯æ³¨æ„åŠ›èƒ½å¤Ÿå®ç°ç¦»æ•£å¹²æ¶‰ç®—å­å¹¶åœ¨å¤„ç†çº¿æ€§æ··åˆä¿¡å·æ—¶ä¿æŒç›¸ä½ä¸€è‡´æ€§ã€‚åœ¨PolSARå›¾åƒåˆ†ç±»å’Œæ— çº¿ä¿¡é“é¢„æµ‹ä»»åŠ¡ä¸­ï¼Œè¯¥æ¨¡å‹å–å¾—äº†é«˜å‡†ç¡®ç‡å’Œä½å›å½’è¯¯å·®ï¼Œå±•ç°å‡ºå¯¹ç›¸ä½æ‰°åŠ¨çš„å¼ºé²æ£’æ€§ã€‚ç ”ç©¶ç»“æœè¡¨æ˜ï¼Œåœ¨æ³¨æ„åŠ›æœºåˆ¶ä¸­èå…¥ç‰©ç†ä¸€è‡´æ€§ä¸ºç›¸å¹²ä¿¡å·å»ºæ¨¡æä¾›äº†ç»Ÿä¸€çš„ç‰©ç†æ¡†æ¶ï¼Œæ˜¾è‘—æå‡äº†å¤å€¼å­¦ä¹ çš„æ³›åŒ–èƒ½åŠ›ã€‚",
      "categories": [
        "eess.SP",
        "cs.AI",
        "cs.LG"
      ],
      "primary_category": "eess.SP",
      "comment": "",
      "pdf_url": "https://arxiv.org/pdf/2509.19331v2",
      "published_date": "2025-09-14 15:24:43 UTC",
      "updated_date": "2025-10-30 03:42:04 UTC",
      "processing_status": "completed",
      "attempts": 1,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "llm_backup_calls": 0,
      "last_update": "2026-01-24T18:24:19.968312+00:00"
    },
    {
      "arxiv_id": "2509.11312v1",
      "title": "Weakly Supervised Vulnerability Localization via Multiple Instance Learning",
      "title_zh": "åŸºäºå¤šç¤ºä¾‹å­¦ä¹ çš„å¼±ç›‘ç£æ¼æ´å®šä½",
      "authors": [
        "Wenchao Gu",
        "Yupan Chen",
        "Yanlin Wang",
        "Hongyu Zhang",
        "Cuiyun Gao",
        "Michael R. Lyu"
      ],
      "abstract": "Software vulnerability detection has emerged as a significant concern in the field of software security recently, capturing the attention of numerous researchers and developers. Most previous approaches focus on coarse-grained vulnerability detection, such as at the function or file level. However, the developers would still encounter the challenge of manually inspecting a large volume of code inside the vulnerable function to identify the specific vulnerable statements for modification, indicating the importance of vulnerability localization. Training the model for vulnerability localization usually requires ground-truth labels at the statement-level, and labeling vulnerable statements demands expert knowledge, which incurs high costs. Hence, the demand for an approach that eliminates the need for additional labeling at the statement-level is on the rise. To tackle this problem, we propose a novel approach called WAVES for WeAkly supervised Vulnerability Localization via multiplE inStance learning, which does not need the additional statement-level labels during the training. WAVES has the capability to determine whether a function is vulnerable (i.e., vulnerability detection) and pinpoint the vulnerable statements (i.e., vulnerability localization). Specifically, inspired by the concept of multiple instance learning, WAVES converts the ground-truth label at the function-level into pseudo labels for individual statements, eliminating the need for additional statement-level labeling. These pseudo labels are utilized to train the classifiers for the function-level representation vectors. Extensive experimentation on three popular benchmark datasets demonstrates that, in comparison to previous baselines, our approach achieves comparable performance in vulnerability detection and state-of-the-art performance in statement-level vulnerability localization.",
      "tldr_zh": "è¯¥ç ”ç©¶æå‡ºäº†WAVESï¼Œä¸€ç§åŸºäºå¤šç¤ºä¾‹å­¦ä¹ (Multiple Instance Learning)çš„å¼±ç›‘ç£æ¼æ´å®šä½æ–¹æ³•ï¼Œæ—¨åœ¨è§£å†³ç»†ç²’åº¦æ¼æ´æ ‡æ³¨æˆæœ¬é«˜æ˜‚çš„é—®é¢˜ã€‚WAVESèƒ½å¤Ÿåœ¨æ— éœ€è¯­å¥çº§æ ‡ç­¾çš„æƒ…å†µä¸‹ï¼Œé€šè¿‡å°†å‡½æ•°çº§çœŸå®æ ‡ç­¾è½¬åŒ–ä¸ºè¯­å¥çº§çš„ä¼ªæ ‡ç­¾(pseudo labels)ï¼ŒåŒæ—¶å®ç°æ¼æ´æ£€æµ‹ä¸å®šä½(vulnerability localization)ã€‚è¯¥æ–¹æ³•åˆ©ç”¨è¿™äº›ä¼ªæ ‡ç­¾è®­ç»ƒåˆ†ç±»å™¨ï¼Œä»è€Œç²¾å‡†è¯†åˆ«å‡½æ•°ä¸­çš„æ¼æ´è¯­å¥ã€‚åœ¨ä¸‰ä¸ªä¸»æµåŸºå‡†æ•°æ®é›†ä¸Šçš„å®éªŒç»“æœæ˜¾ç¤ºï¼ŒWAVESåœ¨æ¼æ´æ£€æµ‹æ–¹é¢è¡¨ç°ä¼˜å¼‚ï¼Œå¹¶åœ¨è¯­å¥çº§æ¼æ´å®šä½ä»»åŠ¡ä¸­å–å¾—äº†æœ€å…ˆè¿›(state-of-the-art)çš„æ€§èƒ½ã€‚è¯¥å·¥ä½œæœ‰æ•ˆå‡å°‘äº†å¯¹ä¸“å®¶æ ‡æ³¨çš„ä¾èµ–ï¼Œä¸ºæå‡è‡ªåŠ¨åŒ–è½¯ä»¶å®‰å…¨åˆ†ææ•ˆç‡æä¾›äº†åˆ›æ–°çš„æŠ€æœ¯æ–¹æ¡ˆã€‚",
      "categories": [
        "cs.SE",
        "cs.AI"
      ],
      "primary_category": "cs.SE",
      "comment": "",
      "pdf_url": "https://arxiv.org/pdf/2509.11312v1",
      "published_date": "2025-09-14 15:11:39 UTC",
      "updated_date": "2025-09-14 15:11:39 UTC",
      "processing_status": "completed",
      "attempts": 1,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "llm_backup_calls": 0,
      "last_update": "2026-01-24T18:24:11.065340+00:00"
    },
    {
      "arxiv_id": "2509.11311v1",
      "title": "Prompts to Proxies: Emulating Human Preferences via a Compact LLM Ensemble",
      "title_zh": "Prompts to Proxiesï¼šåˆ©ç”¨ç´§å‡‘å‹ LLM é›†æˆæ¨¡æ‹Ÿäººç±»åå¥½",
      "authors": [
        "Bingchen Wang",
        "Zi-Yu Khoo",
        "Bryan Kian Hsiang Low"
      ],
      "abstract": "Large language models (LLMs) have demonstrated promise in emulating human-like responses across a wide range of tasks. In this paper, we propose a novel alignment framework that treats LLMs as agent proxies for human survey respondents, affording a cost-effective and steerable solution to two pressing challenges in the social sciences: the rising cost of survey deployment and the growing demographic imbalance in survey response data. Drawing inspiration from the theory of revealed preference, we formulate alignment as a two-stage problem: constructing diverse agent personas called endowments that simulate plausible respondent profiles, and selecting a representative subset to approximate a ground-truth population based on observed data. To implement the paradigm, we introduce P2P, a system that steers LLM agents toward representative behavioral patterns using structured prompt engineering, entropy-based sampling, and regression-based selection. Unlike personalization-heavy approaches, our alignment approach is demographic-agnostic and relies only on aggregate survey results, offering better generalizability and parsimony. Beyond improving data efficiency in social science research, our framework offers a testbed for studying the operationalization of pluralistic alignment. We demonstrate the efficacy of our approach on real-world opinion survey datasets, showing that our aligned agent populations can reproduce aggregate response patterns with high fidelity and exhibit substantial response diversity, even without demographic conditioning.",
      "tldr_zh": "è¯¥ç ”ç©¶æå‡ºäº†P2Pæ¡†æ¶ï¼Œé€šè¿‡å°†å¤§å‹è¯­è¨€æ¨¡å‹(LLMs)ä½œä¸ºæ¨¡æ‹Ÿäººç±»è°ƒæŸ¥å—è®¿è€…çš„ä»£ç†äºº(Agent Proxies)ï¼Œæ—¨åœ¨è§£å†³ç¤¾ä¼šç§‘å­¦ä¸­è°ƒæŸ¥æˆæœ¬é«˜æ˜‚å’Œäººå£ç»Ÿè®¡æ•°æ®ä¸å¹³è¡¡çš„æŒ‘æˆ˜ã€‚å—æ˜¾æ€§åå¥½ç†è®º(Revealed Preference Theory)å¯å‘ï¼Œè¯¥æ¡†æ¶å°†å¯¹é½è¿‡ç¨‹åˆ†ä¸ºæ„å»ºå¤šæ ·åŒ–æ™ºèƒ½ä½“äººæ ¼(Endowments)å’ŒåŸºäºè§‚æµ‹æ•°æ®ç­›é€‰ä»£è¡¨æ€§å­é›†ä¸¤ä¸ªé˜¶æ®µã€‚P2Pç³»ç»Ÿé›†æˆäº†ç»“æ„åŒ–æç¤ºå·¥ç¨‹(Structured Prompt Engineering)ã€åŸºäºç†µçš„é‡‡æ ·(Entropy-based Sampling)ä»¥åŠåŸºäºå›å½’çš„é€‰æ‹©(Regression-based Selection)ç­‰æŠ€æœ¯ï¼Œå¼•å¯¼æ™ºèƒ½ä½“å‘ˆç°å…·æœ‰ä»£è¡¨æ€§çš„è¡Œä¸ºã€‚è¯¥æ–¹æ¡ˆå…·æœ‰äººå£ç»Ÿè®¡æ— å…³(Demographic-agnostic)çš„ç‰¹æ€§ï¼Œä»…ä¾èµ–èšåˆè°ƒæŸ¥ç»“æœå³å¯å®ç°è¾ƒé«˜çš„æ³›åŒ–æ€§å’Œç®€çº¦æ€§ã€‚åœ¨çœŸå®æ°‘æ„è°ƒæŸ¥æ•°æ®é›†ä¸Šçš„å®éªŒè¯æ˜ï¼Œè¯¥æ¡†æ¶å¯¹é½çš„æ™ºèƒ½ä½“ç¾¤ä½“èƒ½å¤Ÿé«˜ä¿çœŸåœ°é‡ç°èšåˆå“åº”æ¨¡å¼ï¼Œå¹¶è¡¨ç°å‡ºæ˜¾è‘—çš„å“åº”å¤šæ ·æ€§ã€‚è¯¥ç ”ç©¶ä¸ä»…æå‡äº†ç¤¾ä¼šç§‘å­¦ç ”ç©¶çš„æ•°æ®æ•ˆç‡ï¼Œä¹Ÿä¸ºç ”ç©¶å¤šå…ƒåŒ–å¯¹é½(Pluralistic Alignment)çš„ä¸šåŠ¡åŒ–è¿ä½œæä¾›äº†æœ‰æ•ˆçš„æµ‹è¯•å¹³å°ã€‚",
      "categories": [
        "cs.AI",
        "cs.CY"
      ],
      "primary_category": "cs.AI",
      "comment": "Preprint of work originally submitted to AAAI 2026. Under revision for resubmission to a machine learning venue",
      "pdf_url": "https://arxiv.org/pdf/2509.11311v1",
      "published_date": "2025-09-14 15:08:45 UTC",
      "updated_date": "2025-09-14 15:08:45 UTC",
      "processing_status": "completed",
      "attempts": 1,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "llm_backup_calls": 0,
      "last_update": "2026-01-24T18:24:50.689215+00:00"
    },
    {
      "arxiv_id": "2509.11298v1",
      "title": "Opal: An Operator Algebra View of RLHF",
      "title_zh": "Opalï¼šRLHF çš„ç®—å­ä»£æ•°è§†è§’",
      "authors": [
        "Madhava Gaikwad"
      ],
      "abstract": "We present Opal, an operator view of reinforcement learning from human feedback (RLHF). Objectives are expressed as ladders of two primitives on a base utility: additive penalties and multiplicative pairwise weights. We describe a simple reduction law with if-and-only-if conditions: such ladders collapse to a normal form on pairwise margins when the reference is fixed, penalties are additive, and weights are independent of intermediate margins. When these assumptions do not hold (reference shift, non-additive gates, score-dependent weights), small examples demonstrate non-reducibility.\n  Building on this view, we introduce GKPO (Generalized Kernel Preference Object), a canonical schema in which many RLHF methods can be represented and, when reducible, mapped back from. GKPO provides a standard JSON serialization, canonicalization and hashing rules, and explicit flags with finite witnesses when assumptions fail.\n  We illustrate these ideas with GKPO examples for DPO, RRHF, and ORPO, along with cross-method conversions (where assumptions permit) and minimal stress tests (SHIFT/GATE/SCORE) that highlight non-reducibility. A lightweight Python reference library accompanies the schema, implementing canonical hashing and adapters for DPO and RRHF.",
      "tldr_zh": "è¯¥ç ”ç©¶æå‡ºäº† Opalï¼Œè¿™æ˜¯ä¸€ç§ä»ç®—å­ä»£æ•°(Operator Algebra)è§†è§’å®¡è§†äººç±»åé¦ˆå¼ºåŒ–å­¦ä¹ (RLHF)çš„æ–°æ¡†æ¶ã€‚è¯¥æ¡†æ¶å°† RLHF ç›®æ ‡è¡¨è¾¾ä¸ºåœ¨åŸºç¡€æ•ˆç”¨ä¸Šæ„å»ºçš„æ¢¯æ¬¡ç»“æ„ï¼Œä¸»è¦ç”±åŠ æ³•æƒ©ç½š(additive penalties)å’Œä¹˜æ³•æˆå¯¹æƒé‡(multiplicative pairwise weights)ä¸¤ä¸ªåŸè¯­ç»„æˆã€‚ç ”ç©¶æ­ç¤ºäº†ä¸€ç§è§„çº¦æ³•åˆ™(reduction law)ï¼Œå³åœ¨å‚è€ƒæ¨¡å‹å›ºå®šä¸”æƒé‡ç‹¬ç«‹äºä¸­é—´è¾¹é™…ç­‰ç‰¹å®šæ¡ä»¶ä¸‹ï¼Œæ­¤ç±»æ¢¯æ¬¡ç»“æ„å¯ç®€åŒ–ä¸ºæˆå¯¹è¾¹é™…(pairwise margins)çš„æ ‡å‡†å½¢å¼ã€‚é€šè¿‡å¯¹å‚è€ƒåç§»(reference shift)å’ŒéåŠ æ³•é—¨æ§ç­‰åœºæ™¯çš„åˆ†æï¼Œè®ºæ–‡è¿›ä¸€æ­¥æ¢è®¨äº†æ¨¡å‹åœ¨å‡è®¾ä¸æˆç«‹æ—¶çš„ä¸å¯è§„çº¦æ€§(non-reducibility)ã€‚åŸºäºè¿™ä¸€ç†è®ºè§†è§’ï¼Œç ”ç©¶å¼•å…¥äº†é€šç”¨å†…æ ¸åå¥½å¯¹è±¡(GKPO)è¿™ä¸€è§„èŒƒæ¨¡å¼ï¼Œèƒ½å¤Ÿç»Ÿä¸€è¡¨ç¤º DPOã€RRHF å’Œ ORPO ç­‰å¤šç§ RLHF æ–¹æ³•ã€‚æ­¤å¤–ï¼Œç ”ç©¶è¿˜é…å¥—æä¾›äº†å®ç°è§„èŒƒå“ˆå¸Œå’Œæ–¹æ³•é€‚é…å™¨çš„è½»é‡çº§ Python å‚è€ƒåº“ï¼Œä¸º RLHF æ–¹æ³•çš„æ ‡å‡†åŒ–è¡¨ç¤ºä¸è·¨æ–¹æ³•è½¬æ¢æä¾›äº†ç»Ÿä¸€çš„ç†è®ºå·¥å…·å’Œå®è·µå‚è€ƒã€‚",
      "categories": [
        "cs.LG",
        "cs.AI",
        "cs.CL"
      ],
      "primary_category": "cs.LG",
      "comment": "11 pages main",
      "pdf_url": "https://arxiv.org/pdf/2509.11298v1",
      "published_date": "2025-09-14 14:42:39 UTC",
      "updated_date": "2025-09-14 14:42:39 UTC",
      "processing_status": "completed",
      "attempts": 1,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "llm_backup_calls": 0,
      "last_update": "2026-01-24T18:24:38.693268+00:00"
    },
    {
      "arxiv_id": "2509.11297v1",
      "title": "Policy Learning for Social Robot-Led Physiotherapy",
      "title_zh": "ç¤¾äº¤æœºå™¨äººä¸»å¯¼çš„ç‰©ç†æ²»ç–—ç­–ç•¥å­¦ä¹ ",
      "authors": [
        "Carl Bettosi",
        "Lynne Ballie",
        "Susan Shenkin",
        "Marta Romeo"
      ],
      "abstract": "Social robots offer a promising solution for autonomously guiding patients through physiotherapy exercise sessions, but effective deployment requires advanced decision-making to adapt to patient needs. A key challenge is the scarcity of patient behavior data for developing robust policies. To address this, we engaged 33 expert healthcare practitioners as patient proxies, using their interactions with our robot to inform a patient behavior model capable of generating exercise performance metrics and subjective scores on perceived exertion. We trained a reinforcement learning-based policy in simulation, demonstrating that it can adapt exercise instructions to individual exertion tolerances and fluctuating performance, while also being applicable to patients at different recovery stages with varying exercise plans.",
      "tldr_zh": "è¯¥ç ”ç©¶é’ˆå¯¹ç¤¾äº¤æœºå™¨äºº(Social robots)åœ¨è‡ªä¸»å¼•å¯¼ç‰©ç†æ²»ç–—(Physiotherapy)ç»ƒä¹ ä¸­é¢ä¸´çš„æ‚£è€…è¡Œä¸ºæ•°æ®ç¨€ç¼ºæŒ‘æˆ˜ï¼Œæå‡ºäº†ä¸€ç§åŸºäºç­–ç•¥å­¦ä¹ çš„è§£å†³æ–¹æ¡ˆã€‚ç ”ç©¶å›¢é˜Ÿé‚€è¯·äº†33ååŒ»ç–—ä¸“å®¶ä½œä¸ºæ‚£è€…ä»£ç†ï¼Œé€šè¿‡å…¶ä¸æœºå™¨äººçš„äº¤äº’æ•°æ®æ„å»ºäº†ä¸€ä¸ªèƒ½å¤Ÿç”Ÿæˆç»ƒä¹ è¡¨ç°æŒ‡æ ‡å’Œè‡ªè§‰ç”¨åŠ›åº¦(perceived exertion)ä¸»è§‚è¯„åˆ†çš„æ‚£è€…è¡Œä¸ºæ¨¡å‹ã€‚åˆ©ç”¨è¯¥æ¨¡å‹ï¼Œç ”ç©¶è€…åœ¨æ¨¡æ‹Ÿç¯å¢ƒä¸­è®­ç»ƒäº†ä¸€å¥—åŸºäºå¼ºåŒ–å­¦ä¹ (Reinforcement Learning)çš„ç­–ç•¥ï¼Œä½¿æœºå™¨äººèƒ½å¤Ÿæ ¹æ®ä¸ªä½“çš„ç”¨åŠ›åº¦è€å—æ°´å¹³å’Œè¡¨ç°æ³¢åŠ¨å®æ—¶è°ƒæ•´ç»ƒä¹ æŒ‡ä»¤ã€‚å®éªŒç»“æœè¡¨æ˜ï¼Œè¯¥ç­–ç•¥èƒ½å¤Ÿé€‚åº”å¤„äºä¸åŒåº·å¤é˜¶æ®µåŠæ‹¥æœ‰ä¸åŒè¿åŠ¨è®¡åˆ’çš„æ‚£è€…éœ€æ±‚ï¼Œä¸ºç¤¾äº¤æœºå™¨äººåœ¨ä¸´åºŠç‰©ç†æ²»ç–—ä¸­çš„æ™ºèƒ½å†³ç­–ä¸è‡ªåŠ¨åŒ–éƒ¨ç½²å¥ å®šäº†åŸºç¡€ã€‚",
      "categories": [
        "cs.RO",
        "cs.AI"
      ],
      "primary_category": "cs.RO",
      "comment": "",
      "pdf_url": "https://arxiv.org/pdf/2509.11297v1",
      "published_date": "2025-09-14 14:40:30 UTC",
      "updated_date": "2025-09-14 14:40:30 UTC",
      "processing_status": "completed",
      "attempts": 1,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "llm_backup_calls": 0,
      "last_update": "2026-01-24T18:24:43.292965+00:00"
    },
    {
      "arxiv_id": "2509.13355v1",
      "title": "Synthetic Data and the Shifting Ground of Truth",
      "title_zh": "åˆæˆæ•°æ®ä¸çœŸç†æ ¹åŸºçš„å˜è¿",
      "authors": [
        "Dietmar Offenhuber"
      ],
      "abstract": "The emergence of synthetic data for privacy protection, training data generation, or simply convenient access to quasi-realistic data in any shape or volume complicates the concept of ground truth. Synthetic data mimic real-world observations, but do not refer to external features. This lack of a representational relationship, however, not prevent researchers from using synthetic data as training data for AI models and ground truth repositories. It is claimed that the lack of data realism is not merely an acceptable tradeoff, but often leads to better model performance than realistic data: compensate for known biases, prevent overfitting and support generalization, and make the models more robust in dealing with unexpected outliers. Indeed, injecting noisy and outright implausible data into training sets can be beneficial for the model. This greatly complicates usual assumptions based on which representational accuracy determines data fidelity (garbage in - garbage out). Furthermore, ground truth becomes a self-referential affair, in which the labels used as a ground truth repository are themselves synthetic products of a generative model and as such not connected to real-world observations. My paper examines how ML researchers and practitioners bootstrap ground truth under such paradoxical circumstances without relying on the stable ground of representation and real-world reference. It will also reflect on the broader implications of a shift from a representational to what could be described as a mimetic or iconic concept of data.",
      "tldr_zh": "è¯¥ç ”ç©¶æ¢è®¨äº†åˆæˆæ•°æ® (Synthetic Data) çš„å…´èµ·å¦‚ä½•å¤æ‚åŒ–äº†åœ°é¢çœŸå€¼ (Ground Truth) çš„æ¦‚å¿µã€‚å°½ç®¡åˆæˆæ•°æ®ç¼ºä¹å¯¹ç°å®ä¸–ç•Œçš„ç›´æ¥è¡¨å¾å…³ç³» (Representational Relationship)ï¼Œä½†ç ”ç©¶äººå‘˜ä»å°†å…¶å¹¿æ³›ç”¨äº AI æ¨¡å‹è®­ç»ƒå’ŒçœŸå€¼å­˜å‚¨ã€‚ç ”ç©¶æŒ‡å‡ºï¼Œåˆæˆæ•°æ®çš„ä¸çœŸå®æ€§å¹¶éå•çº¯çš„æƒè¡¡ï¼Œåè€Œèƒ½é€šè¿‡è¡¥å¿åè§ã€é˜²æ­¢è¿‡æ‹Ÿåˆ (Overfitting) å’Œå¢å¼ºæ³›åŒ– (Generalization) æ¥æå‡æ¨¡å‹æ€§èƒ½ã€‚è¿™ç§ç°è±¡æŒ‘æˆ˜äº†ä¼ ç»Ÿçš„â€œåƒåœ¾è¿›ï¼Œåƒåœ¾å‡ºâ€ (Garbage In - Garbage Out) å‡è®¾ï¼Œå³æ•°æ®çš„è¡¨å¾å‡†ç¡®æ€§å†³å®šäº†å…¶ä¿çœŸåº¦ã€‚è®ºæ–‡æ·±å…¥åˆ†æäº†åœ¨ç¼ºä¹ç°å®å‚è€ƒçš„çŸ›ç›¾æƒ…å†µä¸‹ï¼Œæœºå™¨å­¦ä¹ ä»ä¸šè€…å¦‚ä½•å¼•å¯¼ (Bootstrap) åœ°é¢çœŸå€¼ï¼Œå¹¶åæ€äº†æ•°æ®æ¦‚å¿µä»è¡¨å¾æ€§å‘æ¨¡æ‹Ÿæ€§ (Mimetic) æˆ–å›¾æ ‡æ€§ (Iconic) è½¬å˜çš„æ·±è¿œå½±å“ã€‚",
      "categories": [
        "cs.CY",
        "cs.AI",
        "cs.LG"
      ],
      "primary_category": "cs.CY",
      "comment": "Talk presented at the Society for the Social Studies of Science (4S) 2025 meeting in Seattle, Sept. 3, 2025",
      "pdf_url": "https://arxiv.org/pdf/2509.13355v1",
      "published_date": "2025-09-14 14:35:11 UTC",
      "updated_date": "2025-09-14 14:35:11 UTC",
      "processing_status": "completed",
      "attempts": 1,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "llm_backup_calls": 0,
      "last_update": "2026-01-24T18:24:49.892898+00:00"
    },
    {
      "arxiv_id": "2509.11289v1",
      "title": "Energy-Aware 6G Network Design: A Survey",
      "title_zh": "èƒ½æ•ˆæ„ŸçŸ¥å‹ 6G ç½‘ç»œè®¾è®¡ç»¼è¿°",
      "authors": [
        "Rashmi Kamran",
        "Mahesh Ganesh Bhat",
        "Pranav Jha",
        "Shana Moothedath",
        "Manjesh Hanawal",
        "Prasanna Chaporkar"
      ],
      "abstract": "6th Generation (6G) mobile networks are envisioned to support several new capabilities and data-centric applications for unprecedented number of users, potentially raising significant energy efficiency and sustainability concerns. This brings focus on sustainability as one of the key objectives in the their design. To move towards sustainable solution, research and standardization community is focusing on several key issues like energy information monitoring and exposure, use of renewable energy, and use of Artificial Intelligence/Machine Learning (AI/ML) for improving the energy efficiency in 6G networks. The goal is to build energy-aware solutions that takes into account the energy information resulting in energy efficient networks. Design of energy-aware 6G networks brings in new challenges like increased overheads in gathering and exposing of energy related information, and the associated user consent management. The aim of this paper is to provide a comprehensive survey of methods used for design of energy efficient 6G networks, like energy harvesting, energy models and parameters, classification of energy-aware services, and AI/ML-based solutions. The survey also includes few use cases that demonstrate the benefits of incorporating energy awareness into network decisions. Several ongoing standardization efforts in 3GPP, ITU, and IEEE are included to provide insights into the ongoing work and highlight the opportunities for new contributions. We conclude this survey with open research problems and challenges that can be explored to make energy-aware design feasible and ensure optimality regarding performance and energy goals for 6G networks.",
      "tldr_zh": "è¯¥ç»¼è¿°æ¢è®¨äº†é¢å‘å¯æŒç»­å‘å±•çš„èƒ½æºæ„ŸçŸ¥å‹ 6G ç½‘ç»œè®¾è®¡ï¼Œæ—¨åœ¨åº”å¯¹ç”±äºæµ·é‡è¿æ¥å’Œæ•°æ®ä¸­å¿ƒåº”ç”¨å¸¦æ¥çš„èƒ½æºæ•ˆç‡ä¸å¯æŒç»­æ€§æŒ‘æˆ˜ã€‚è®ºæ–‡é‡ç‚¹åˆ†æäº†èƒ½æºä¿¡æ¯ç›‘æµ‹ä¸å…¬å¼€ã€å¯å†ç”Ÿèƒ½æºåˆ©ç”¨ä»¥åŠé€šè¿‡ AI/ML æŠ€æœ¯æå‡ç½‘ç»œèƒ½æ•ˆç­‰æ ¸å¿ƒè®®é¢˜ã€‚æ–‡ä¸­å…¨é¢è°ƒæŸ¥äº†å®ç°èƒ½æ•ˆè®¾è®¡çš„å¤šç§æ–¹æ³•ï¼ŒåŒ…æ‹¬ Energy Harvestingã€èƒ½æºæ¨¡å‹ä¸å‚æ•°ã€èƒ½æºæ„ŸçŸ¥å‹æœåŠ¡åˆ†ç±»ä»¥åŠåŸºäº AI/ML çš„è§£å†³æ–¹æ¡ˆã€‚ä½œè€…è¿˜è®¨è®ºäº†åœ¨è·å–å’Œå…¬å¼€èƒ½æºä¿¡æ¯æ—¶é¢ä¸´çš„å¼€é”€å¢åŠ åŠç”¨æˆ·éšç§ç®¡ç†ç­‰æŒ‘æˆ˜ï¼Œå¹¶æ€»ç»“äº† 3GPPã€ITU å’Œ IEEE ç­‰ç»„ç»‡çš„æ ‡å‡†åŒ–è¿›ç¨‹ã€‚é€šè¿‡å…·ä½“åº”ç”¨æ¡ˆä¾‹ï¼Œæ–‡ç« å±•ç¤ºäº†å°†èƒ½æºæ„ŸçŸ¥èå…¥ç½‘ç»œå†³ç­–çš„å®é™…ç›Šå¤„ã€‚è®ºæ–‡æœ€åæŒ‡å‡ºäº†ç›®å‰å°šå­˜çš„ç ”ç©¶éš¾é¢˜å’ŒæŒ‘æˆ˜ï¼Œä¸ºå®ç° 6G ç½‘ç»œåœ¨æ€§èƒ½ä¸èƒ½æºç›®æ ‡ä¹‹é—´çš„æœ€ä¼˜å¹³è¡¡æä¾›äº†æ–¹å‘ã€‚",
      "categories": [
        "cs.NI",
        "cs.AI"
      ],
      "primary_category": "cs.NI",
      "comment": "",
      "pdf_url": "https://arxiv.org/pdf/2509.11289v1",
      "published_date": "2025-09-14 14:29:05 UTC",
      "updated_date": "2025-09-14 14:29:05 UTC",
      "processing_status": "completed",
      "attempts": 1,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "llm_backup_calls": 0,
      "last_update": "2026-01-24T18:24:57.095979+00:00"
    },
    {
      "arxiv_id": "2509.11285v1",
      "title": "Efficient Single-Step Framework for Incremental Class Learning in Neural Networks",
      "title_zh": "ç¥ç»ç½‘ç»œç±»å¢é‡å­¦ä¹ çš„é«˜æ•ˆå•æ­¥æ¡†æ¶",
      "authors": [
        "Alejandro Dopico-Castro",
        "Oscar Fontenla-Romero",
        "Bertha Guijarro-BerdiÃ±as",
        "Amparo Alonso-Betanzos"
      ],
      "abstract": "Incremental learning remains a critical challenge in machine learning, as models often struggle with catastrophic forgetting -the tendency to lose previously acquired knowledge when learning new information. These challenges are even more pronounced in resource-limited settings. Many existing Class Incremental Learning (CIL) methods achieve high accuracy by continually adapting their feature representations; however, they often require substantial computational resources and complex, iterative training procedures. This work introduces CIFNet (Class Incremental and Frugal Network), a novel CIL approach that addresses these limitations by offering a highly efficient and sustainable solution. CIFNet's key innovation lies in its novel integration of several existing, yet separately explored, components: a pre-trained and frozen feature extractor, a compressed data buffer, and an efficient non-iterative one-layer neural network for classification. A pre-trained and frozen feature extractor eliminates computationally expensive fine-tuning of the backbone. This, combined with a compressed buffer for efficient memory use, enables CIFNet to perform efficient class-incremental learning through a single-step optimization process on fixed features, minimizing computational overhead and training time without requiring multiple weight updates. Experiments on benchmark datasets confirm that CIFNet effectively mitigates catastrophic forgetting at the classifier level, achieving high accuracy comparable to that of existing state-of-the-art methods, while substantially improving training efficiency and sustainability. CIFNet represents a significant advancement in making class-incremental learning more accessible and pragmatic in environments with limited resources, especially when strong pre-trained feature extractors are available.",
      "tldr_zh": "è¯¥ç ”ç©¶æå‡ºäº†CIFNet (Class Incremental and Frugal Network)ï¼Œè¿™æ˜¯ä¸€ç§é’ˆå¯¹ç±»å¢é‡å­¦ä¹  (Class Incremental Learning, CIL) çš„é«˜æ•ˆä¸”å¯æŒç»­çš„æ–°å‹æ¡†æ¶ï¼Œæ—¨åœ¨è§£å†³æœºå™¨å­¦ä¹ ä¸­çš„ç¾éš¾æ€§é—å¿˜ (catastrophic forgetting) é—®é¢˜ã€‚CIFNetçš„æ ¸å¿ƒåˆ›æ–°åœ¨äºæ•´åˆäº†é¢„è®­ç»ƒä¸”å†»ç»“çš„ç‰¹å¾æå–å™¨ (frozen feature extractor)ã€å‹ç¼©æ•°æ®ç¼“å†²åŒº (compressed data buffer) ä»¥åŠç”¨äºåˆ†ç±»çš„é«˜æ•ˆéè¿­ä»£å•å±‚ç¥ç»ç½‘ç»œã€‚é€šè¿‡å†»ç»“ç‰¹å¾æå–å™¨ï¼Œè¯¥æ–¹æ³•é¿å…äº†æ˜‚è´µçš„éª¨å¹²ç½‘ç»œå¾®è°ƒè¿‡ç¨‹ï¼Œå¹¶ç»“åˆå‹ç¼©ç¼“å†²åŒºå®ç°äº†é«˜æ•ˆçš„å†…å­˜ç®¡ç†ã€‚è¯¥æ¡†æ¶é€šè¿‡å¯¹å›ºå®šç‰¹å¾è¿›è¡Œå•æ­¥ä¼˜åŒ– (single-step optimization) è¿‡ç¨‹å®Œæˆå¢é‡å­¦ä¹ ï¼Œä»è€Œåœ¨ä¸éœ€è¦å¤šæ¬¡æƒé‡æ›´æ–°çš„æƒ…å†µä¸‹æœ€å¤§é™åº¦åœ°å‡å°‘äº†è®¡ç®—å¼€é”€ã€‚åœ¨åŸºå‡†æ•°æ®é›†ä¸Šçš„å®éªŒç»“æœè¡¨æ˜ï¼ŒCIFNetèƒ½æœ‰æ•ˆç¼“è§£åˆ†ç±»å™¨å±‚é¢çš„ç¾éš¾æ€§é—å¿˜ï¼Œå¹¶å–å¾—ä¸å½“å‰æœ€å…ˆè¿›æ–¹æ³• (state-of-the-art) ç›¸å½“çš„å‡†ç¡®ç‡ã€‚ç›¸æ¯”ç°æœ‰æ–¹æ³•ï¼ŒCIFNetåœ¨æ˜¾è‘—æå‡è®­ç»ƒæ•ˆç‡å’Œå¯æŒç»­æ€§çš„åŒæ—¶ï¼Œä½¿ç±»å¢é‡å­¦ä¹ åœ¨èµ„æºå—é™çš„ç¯å¢ƒä¸­æ›´å…·å¯æ“ä½œæ€§ã€‚",
      "categories": [
        "cs.LG",
        "cs.AI"
      ],
      "primary_category": "cs.LG",
      "comment": "",
      "pdf_url": "https://arxiv.org/pdf/2509.11285v1",
      "published_date": "2025-09-14 14:24:41 UTC",
      "updated_date": "2025-09-14 14:24:41 UTC",
      "processing_status": "completed",
      "attempts": 1,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "llm_backup_calls": 0,
      "last_update": "2026-01-24T18:25:09.213886+00:00"
    },
    {
      "arxiv_id": "2509.11270v1",
      "title": "Embodied Intelligence in Disassembly: Multimodal Perception Cross-validation and Continual Learning in Neuro-Symbolic TAMP",
      "title_zh": "æ‹†è§£é¢†åŸŸçš„å…·èº«æ™ºèƒ½ï¼šç¥ç»ç¬¦å· TAMP ä¸­çš„å¤šæ¨¡æ€æ„ŸçŸ¥äº¤å‰éªŒè¯ä¸æŒç»­å­¦ä¹ ",
      "authors": [
        "Ziwen He",
        "Zhigang Wang",
        "Yanlong Peng",
        "Pengxu Chang",
        "Hong Yang",
        "Ming Chen"
      ],
      "abstract": "With the rapid development of the new energy vehicle industry, the efficient disassembly and recycling of power batteries have become a critical challenge for the circular economy. In current unstructured disassembly scenarios, the dynamic nature of the environment severely limits the robustness of robotic perception, posing a significant barrier to autonomous disassembly in industrial applications. This paper proposes a continual learning framework based on Neuro-Symbolic task and motion planning (TAMP) to enhance the adaptability of embodied intelligence systems in dynamic environments. Our approach integrates a multimodal perception cross-validation mechanism into a bidirectional reasoning flow: the forward working flow dynamically refines and optimizes action strategies, while the backward learning flow autonomously collects effective data from historical task executions to facilitate continual system learning, enabling self-optimization. Experimental results show that the proposed framework improves the task success rate in dynamic disassembly scenarios from 81.68% to 100%, while reducing the average number of perception misjudgments from 3.389 to 1.128. This research provides a new paradigm for enhancing the robustness and adaptability of embodied intelligence in complex industrial environments.",
      "tldr_zh": "é’ˆå¯¹æ–°èƒ½æºæ±½è½¦åŠ¨åŠ›ç”µæ± å›æ”¶ä¸­çš„éç»“æ„åŒ–æ‹†è§£éš¾é¢˜ï¼Œæœ¬ç ”ç©¶æå‡ºäº†ä¸€ç§åŸºäºç¥ç»ç¬¦å·ä»»åŠ¡ä¸è¿åŠ¨è§„åˆ’ï¼ˆNeuro-Symbolic TAMPï¼‰çš„æŒç»­å­¦ä¹ ï¼ˆContinual Learningï¼‰æ¡†æ¶ï¼Œæ—¨åœ¨æå‡å…·èº«æ™ºèƒ½ç³»ç»Ÿåœ¨åŠ¨æ€ç¯å¢ƒä¸­çš„é€‚åº”æ€§ã€‚è¯¥æ–¹æ³•å°†å¤šæ¨¡æ€æ„ŸçŸ¥äº¤å‰éªŒè¯æœºåˆ¶ï¼ˆMultimodal Perception Cross-validationï¼‰é›†æˆåˆ°åŒå‘æ¨ç†æµä¸­ï¼Œé€šè¿‡å‰å‘å·¥ä½œæµåŠ¨æ€ä¼˜åŒ–åŠ¨ä½œç­–ç•¥ï¼Œå¹¶åˆ©ç”¨åå‘å­¦ä¹ æµä»å†å²ä»»åŠ¡æ‰§è¡Œä¸­è‡ªä¸»æ”¶é›†æœ‰æ•ˆæ•°æ®ä»¥å®ç°ç³»ç»Ÿçš„è‡ªæˆ‘ä¼˜åŒ–ã€‚å®éªŒç»“æœè¡¨æ˜ï¼Œè¯¥æ¡†æ¶åœ¨åŠ¨æ€æ‹†è§£åœºæ™¯ä¸‹å°†ä»»åŠ¡æˆåŠŸç‡ä» 81.68% æ˜¾è‘—æå‡è‡³ 100%ï¼ŒåŒæ—¶å°†å¹³å‡æ„ŸçŸ¥è¯¯åˆ¤æ¬¡æ•°ä» 3.389 æ¬¡é™ä½è‡³ 1.128 æ¬¡ã€‚è¯¥ç ”ç©¶é€šè¿‡ç»“åˆç¬¦å·æ¨ç†ä¸æŒç»­å­¦ä¹ ï¼Œä¸ºå¢å¼ºå·¥ä¸šå…·èº«æ™ºèƒ½ï¼ˆEmbodied Intelligenceï¼‰åœ¨å¤æ‚ç¯å¢ƒä¸‹çš„é²æ£’æ€§æä¾›äº†æ–°çš„æŠ€æœ¯èŒƒå¼ã€‚",
      "categories": [
        "cs.RO",
        "cs.AI"
      ],
      "primary_category": "cs.RO",
      "comment": "8 pages, 3 figures. Accepted at CASE2025. This arXiv version contains minor corrections",
      "pdf_url": "https://arxiv.org/pdf/2509.11270v1",
      "published_date": "2025-09-14 13:47:07 UTC",
      "updated_date": "2025-09-14 13:47:07 UTC",
      "processing_status": "completed",
      "attempts": 1,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "llm_backup_calls": 0,
      "last_update": "2026-01-24T18:25:09.188260+00:00"
    },
    {
      "arxiv_id": "2509.11259v1",
      "title": "Gradient Free Deep Reinforcement Learning With TabPFN",
      "title_zh": "åŸºäº TabPFN çš„æ— æ¢¯åº¦æ·±åº¦å¼ºåŒ–å­¦ä¹ ",
      "authors": [
        "David Schiff",
        "Ofir Lindenbaum",
        "Yonathan Efroni"
      ],
      "abstract": "Gradient based optimization is fundamental to most modern deep reinforcement learning algorithms, however, it introduces significant sensitivity to hyperparameters, unstable training dynamics, and high computational costs. We propose TabPFN RL, a novel gradient free deep RL framework that repurposes the meta trained transformer TabPFN as a Q function approximator. Originally developed for tabular classification, TabPFN is a transformer pre trained on millions of synthetic datasets to perform inference on new unseen datasets via in context learning. Given an in context dataset of sample label pairs and new unlabeled data, it predicts the most likely labels in a single forward pass, without gradient updates or task specific fine tuning. We use TabPFN to predict Q values using inference only, thereby eliminating the need for back propagation at both training and inference. To cope with the model's fixed context budget, we design a high reward episode gate that retains only the top 5% of trajectories. Empirical evaluations on the Gymnasium classic control suite demonstrate that TabPFN RL matches or surpasses Deep Q Network on CartPole v1, MountainCar v0, and Acrobot v1, without applying gradient descent or any extensive hyperparameter tuning. We discuss the theoretical aspects of how bootstrapped targets and non stationary visitation distributions violate the independence assumptions encoded in TabPFN's prior, yet the model retains a surprising generalization capacity. We further formalize the intrinsic context size limit of in context RL algorithms and propose principled truncation strategies that enable continual learning when the context is full. Our results establish prior fitted networks such as TabPFN as a viable foundation for fast and computationally efficient RL, opening new directions for gradient free RL with large pre trained transformers.",
      "tldr_zh": "è¯¥ç ”ç©¶æå‡ºäº† TabPFN RLï¼Œè¿™æ˜¯ä¸€ç§æ–°é¢–çš„æ— æ¢¯åº¦(Gradient Free)æ·±åº¦å¼ºåŒ–å­¦ä¹ æ¡†æ¶ï¼Œå®ƒå°†å…ƒè®­ç»ƒè½¬æ¢å™¨(Meta-trained Transformer) TabPFN é‡æ–°å®šä½ä¸º Q å‡½æ•°é€¼è¿‘å™¨ã€‚TabPFN åˆ©ç”¨ä¸Šä¸‹æ–‡å­¦ä¹ (In-context Learning)åœ¨å•æ¬¡å‰å‘ä¼ é€’ä¸­ç›´æ¥é¢„æµ‹ Q å€¼ï¼Œä»è€Œåœ¨è®­ç»ƒå’Œæ¨ç†é˜¶æ®µéƒ½æ¶ˆé™¤äº†å¯¹åå‘ä¼ æ’­(Backpropagation)å’Œæ¢¯åº¦æ›´æ–°çš„éœ€æ±‚ã€‚ä¸ºäº†è§£å†³æ¨¡å‹å›ºæœ‰çš„ä¸Šä¸‹æ–‡é¢„ç®—é™åˆ¶ï¼Œä½œè€…è®¾è®¡äº†ä¸€ä¸ªé«˜å¥–åŠ±å›åˆé—¨(High Reward Episode Gate)æ¥ä¿ç•™å‰ 5% çš„é«˜è´¨é‡è½¨è¿¹æ•°æ®ã€‚åœ¨ Gymnasium ç»å…¸æ§åˆ¶ä»»åŠ¡ä¸Šçš„å®éªŒè¯æ˜ï¼ŒTabPFN RL åœ¨æ— éœ€æ¢¯åº¦ä¸‹é™æˆ–å¤æ‚è¶…å‚æ•°è°ƒä¼˜çš„æƒ…å†µä¸‹ï¼Œæ€§èƒ½å³å¯åŒ¹é…æˆ–è¶…è¶Š Deep Q Network (DQN)ã€‚æ­¤å¤–ï¼Œè¯¥ç ”ç©¶è¿˜æ¢è®¨äº†è‡ªä¸¾ç›®æ ‡(Bootstrapped Targets)å¯¹æ¨¡å‹å…ˆéªŒå‡è®¾çš„å½±å“ï¼Œå¹¶æå‡ºäº†æ”¯æŒæŒç»­å­¦ä¹ çš„æˆªæ–­ç­–ç•¥ã€‚è¯¥æˆæœè¯æ˜äº†å…ˆéªŒæ‹Ÿåˆç½‘ç»œ(Prior Fitted Networks)ä½œä¸ºå¿«é€Ÿã€é«˜æ•ˆå¼ºåŒ–å­¦ä¹ åŸºç¡€çš„å¯è¡Œæ€§ï¼Œä¸ºåŸºäºå¤§å‹é¢„è®­ç»ƒæ¨¡å‹çš„æ— æ¢¯åº¦å¼ºåŒ–å­¦ä¹ å¼€è¾Ÿäº†æ–°æ–¹å‘ã€‚",
      "categories": [
        "cs.LG",
        "cs.AI"
      ],
      "primary_category": "cs.LG",
      "comment": "",
      "pdf_url": "https://arxiv.org/pdf/2509.11259v1",
      "published_date": "2025-09-14 13:09:58 UTC",
      "updated_date": "2025-09-14 13:09:58 UTC",
      "processing_status": "completed",
      "attempts": 1,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "llm_backup_calls": 0,
      "last_update": "2026-01-24T18:25:14.999816+00:00"
    },
    {
      "arxiv_id": "2509.11253v1",
      "title": "VideoAgent: Personalized Synthesis of Scientific Videos",
      "title_zh": "VideoAgentï¼šä¸ªæ€§åŒ–ç§‘å­¦è§†é¢‘åˆæˆ",
      "authors": [
        "Xiao Liang",
        "Bangxin Li",
        "Zixuan Chen",
        "Hanyue Zheng",
        "Zhi Ma",
        "Di Wang",
        "Cong Tian",
        "Quan Wang"
      ],
      "abstract": "Automating the generation of scientific videos is a crucial yet challenging task for effective knowledge dissemination. However, existing works on document automation primarily focus on static media such as posters and slides, lacking mechanisms for personalized dynamic orchestration and multimodal content synchronization. To address these challenges, we introduce VideoAgent, a novel multi-agent framework that synthesizes personalized scientific videos through a conversational interface. VideoAgent parses a source paper into a fine-grained asset library and, guided by user requirements, orchestrates a narrative flow that synthesizes both static slides and dynamic animations to explain complex concepts. To enable rigorous evaluation, we also propose SciVidEval, the first comprehensive suite for this task, which combines automated metrics for multimodal content quality and synchronization with a Video-Quiz-based human evaluation to measure knowledge transfer. Extensive experiments demonstrate that our method significantly outperforms existing commercial scientific video generation services and approaches human-level quality in scientific communication.",
      "tldr_zh": "è¯¥ç ”ç©¶æå‡ºäº† VideoAgentï¼Œè¿™æ˜¯ä¸€ä¸ªæ—¨åœ¨å®ç°ä¸ªæ€§åŒ–ç§‘å­¦è§†é¢‘åˆæˆçš„æ–°é¢– multi-agent æ¡†æ¶ï¼Œæœ‰æ•ˆè§£å†³äº†ç°æœ‰è‡ªåŠ¨åŒ–å·¥å…·åœ¨åŠ¨æ€ç¼–æ’å’Œå¤šæ¨¡æ€å†…å®¹åŒæ­¥æ–¹é¢çš„ä¸è¶³ã€‚è¯¥æ¡†æ¶é€šè¿‡å¯¹è¯å¼ç•Œé¢å°†æºè®ºæ–‡è§£æä¸ºç»†ç²’åº¦çš„ asset libraryï¼Œå¹¶æ ¹æ®ç”¨æˆ·éœ€æ±‚æ„å»ºå™äº‹æµï¼Œç»“åˆé™æ€ slides å’ŒåŠ¨æ€ animations æ¥è§£é‡Šå¤æ‚çš„ç§‘å­¦æ¦‚å¿µã€‚ä¸ºäº†è¿›è¡Œä¸¥è°¨çš„æ€§èƒ½è¡¡é‡ï¼Œç ”ç©¶è€…è¿˜æ¨å‡ºäº† SciVidEvalï¼Œè¿™æ˜¯é¦–ä¸ªåŒ…å«å¤šæ¨¡æ€åŒæ­¥è‡ªåŠ¨æŒ‡æ ‡å’Œ Video-Quiz äººç±»è¯„ä¼°çš„ç»¼åˆæµ‹è¯•å¥—ä»¶ã€‚å®éªŒç»“æœè¡¨æ˜ï¼ŒVideoAgent åœ¨ç”Ÿæˆè´¨é‡ä¸Šæ˜¾è‘—ä¼˜äºç°æœ‰çš„å•†ä¸šæœåŠ¡ï¼Œåœ¨ç§‘å­¦ä¼ æ’­æ•ˆèƒ½æ–¹é¢å·²æ¥è¿‘äººç±»æ°´å¹³ã€‚",
      "categories": [
        "cs.AI"
      ],
      "primary_category": "cs.AI",
      "comment": "",
      "pdf_url": "https://arxiv.org/pdf/2509.11253v1",
      "published_date": "2025-09-14 12:54:21 UTC",
      "updated_date": "2025-09-14 12:54:21 UTC",
      "processing_status": "completed",
      "attempts": 1,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "llm_backup_calls": 0,
      "last_update": "2026-01-24T18:25:16.382777+00:00"
    },
    {
      "arxiv_id": "2509.11252v2",
      "title": "Beyond Autoregression: An Empirical Study of Diffusion Large Language Models for Code Generation",
      "title_zh": "è¶…è¶Šè‡ªå›å½’ï¼šé¢å‘ä»£ç ç”Ÿæˆçš„æ‰©æ•£å¤§è¯­è¨€æ¨¡å‹å®è¯ç ”ç©¶",
      "authors": [
        "Chengze Li",
        "Yitong Zhang",
        "Jia Li",
        "Liyi Cai",
        "Ge Li"
      ],
      "abstract": "LLMs have become the mainstream approaches to code generation. Existing LLMs mainly employ autoregressive generation, i.e. generating code token-by-token from left to right. However, the underlying autoregressive generation has two limitations in code generation. First, autoregressive LLMs only generate a token at each step, showing low efficiency in practice. Second, programming is a non-sequential process involving back-and-forth editing, while autoregressive LLMs only employ the left-to-right generation order. These two intrinsic limitations hinder the further development of LLMs in code generation. Recently, diffusion LLMs have emerged as a promising alternative. Diffusion LLMs address the above limitations with two advances, including multi-token prediction (i.e. generating multiple tokens at each step) and flexible generation order (i.e. flexibly determining which positions to generate tokens). However, there is no systematic study exploring diffusion LLMs in code generation. To bridge the knowledge gap, we present the first empirical study of diffusion LLMs for code generation. Our study involves 9 representative diffusion LLMs and conduct experiments on 4 widely used benchmarks. Based on the results, we summarize the following findings. (1) Existing diffusion LLMs are competitive with autoregressive LLMs with similar sizes. (2) Diffusion LLMs have a stronger length extrapolation ability than autoregressive LLMs and perform better in long code understanding. (3) We explore factors impacting the effectiveness and efficiency of diffusion LLMs, and provide practical guidance. (4) We discuss several promising further directions to improve diffusion LLMs on code generation. We open-source all source code, data, and results to facilitate the following research. The code is publicly available at https://github.com/zhangyitonggg/dllm4code.",
      "tldr_zh": "è¯¥ç ”ç©¶é’ˆå¯¹ç°æœ‰è‡ªå›å½’ (Autoregressive) å¤§è¯­è¨€æ¨¡å‹åœ¨ä»£ç ç”Ÿæˆä¸­å­˜åœ¨çš„ä½æ•ˆç‡åŠå›ºå®šç”Ÿæˆé¡ºåºç­‰å±€é™æ€§ï¼Œé¦–æ¬¡å¯¹æ‰©æ•£å¤§è¯­è¨€æ¨¡å‹ (Diffusion LLMs) åœ¨è¯¥é¢†åŸŸçš„è¡¨ç°è¿›è¡Œäº†ç³»ç»Ÿæ€§çš„å®è¯ç ”ç©¶ã€‚é€šè¿‡å¯¹9ä¸ªä»£è¡¨æ€§æ¨¡å‹åœ¨4ä¸ªä¸»æµåŸºå‡†æµ‹è¯•ä¸Šçš„å®éªŒè¯„ä¼°ï¼Œç»“æœæ˜¾ç¤º Diffusion LLMs åœ¨ç”Ÿæˆè´¨é‡ä¸Šå¯ä¸åŒè§„æ¨¡çš„è‡ªå›å½’æ¨¡å‹ç›¸åª²ç¾ï¼Œä¸”åœ¨é•¿ä»£ç ç†è§£å’Œé•¿åº¦å¤–æ¨ (Length Extrapolation) èƒ½åŠ›ä¸Šè¡¨ç°æ›´ä¸ºä¼˜å¼‚ã€‚ç ”ç©¶è¿›ä¸€æ­¥æ·±å…¥æ¢è®¨äº†å½±å“æ‰©æ•£æ¨¡å‹æ•ˆèƒ½ä¸æ•ˆç‡çš„å…³é”®å› ç´ ï¼Œå¹¶ä¸ºæœªæ¥çš„ä¼˜åŒ–æ–¹å‘æä¾›äº†å…·ä½“çš„å®è·µæŒ‡å—ã€‚è¯¥é¡¹å·¥ä½œé€šè¿‡å¼€æºå®Œæ•´çš„ä»£ç ä¸æ•°æ®é›†ï¼Œæœ‰æ•ˆå¼¥è¡¥äº†æ‰©æ•£æ¨¡å‹åœ¨ç¼–ç¨‹è¯­è¨€å¤„ç†é¢†åŸŸçš„çŸ¥è¯†ç©ºç™½ï¼Œä¸ºåç»­éåºåˆ—åŒ–ä»£ç ç”ŸæˆæŠ€æœ¯çš„å‘å±•å¥ å®šäº†åŸºç¡€ã€‚",
      "categories": [
        "cs.SE",
        "cs.AI"
      ],
      "primary_category": "cs.SE",
      "comment": "",
      "pdf_url": "https://arxiv.org/pdf/2509.11252v2",
      "published_date": "2025-09-14 12:51:06 UTC",
      "updated_date": "2025-11-02 02:15:42 UTC",
      "processing_status": "completed",
      "attempts": 1,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "llm_backup_calls": 0,
      "last_update": "2026-01-24T18:25:22.795056+00:00"
    },
    {
      "arxiv_id": "2509.18136v1",
      "title": "From Parameters to Performance: A Data-Driven Study on LLM Structure and Development",
      "title_zh": "ä»å‚æ•°åˆ°æ€§èƒ½ï¼šå¤§è¯­è¨€æ¨¡å‹ç»“æ„ä¸å‘å±•çš„æ•°æ®é©±åŠ¨ç ”ç©¶",
      "authors": [
        "Suqing Wang",
        "Zuchao Li",
        "Luohe Shi",
        "Bo Du",
        "Hai Zhao",
        "Yun Li",
        "Qianren Wang"
      ],
      "abstract": "Large language models (LLMs) have achieved remarkable success across various domains, driving significant technological advancements and innovations. Despite the rapid growth in model scale and capability, systematic, data-driven research on how structural configurations affect performance remains scarce. To address this gap, we present a large-scale dataset encompassing diverse open-source LLM structures and their performance across multiple benchmarks. Leveraging this dataset, we conduct a systematic, data mining-driven analysis to validate and quantify the relationship between structural configurations and performance. Our study begins with a review of the historical development of LLMs and an exploration of potential future trends. We then analyze how various structural choices impact performance across benchmarks and further corroborate our findings using mechanistic interpretability techniques. By providing data-driven insights into LLM optimization, our work aims to guide the targeted development and application of future models. We will release our dataset at https://huggingface.co/datasets/DX0369/LLM-Structure-Performance-Dataset",
      "tldr_zh": "è¯¥ç ”ç©¶æ¢è®¨äº†å¤§å‹è¯­è¨€æ¨¡å‹(LLMs)çš„ç»“æ„é…ç½®ä¸æ€§èƒ½ä¹‹é—´çš„å…³ç³»ï¼Œæ—¨åœ¨å¡«è¡¥ç›®å‰ç¼ºä¹ç³»ç»Ÿæ€§æ•°æ®é©±åŠ¨ç ”ç©¶çš„ç©ºç™½ã€‚ä½œè€…æå‡ºäº†ä¸€ä¸ªåŒ…å«å¤šç§å¼€æºLLMç»“æ„åŠå…¶åœ¨å¤šä¸ªåŸºå‡†æµ‹è¯•(Benchmarks)ä¸­è¡¨ç°çš„å¤§è§„æ¨¡æ•°æ®é›†ã€‚é€šè¿‡æ•°æ®æŒ–æ˜é©±åŠ¨çš„åˆ†æï¼Œç ”ç©¶éªŒè¯å¹¶é‡åŒ–äº†ä¸åŒç»“æ„é€‰æ‹©å¯¹æ¨¡å‹æ€§èƒ½çš„å…·ä½“å½±å“ã€‚æ­¤å¤–ï¼Œè¯¥å·¥ä½œç»“åˆå†å²å‘å±•ç»¼è¿°ä¸æœªæ¥è¶‹åŠ¿æ¢è®¨ï¼Œå¹¶åˆ©ç”¨æœºæ¢°å¯è§£é‡Šæ€§(mechanistic interpretability)æŠ€æœ¯è¿›ä¸€æ­¥è¯å®äº†åˆ†æç»“æœã€‚è¿™é¡¹ç ”ç©¶é€šè¿‡æä¾›æ•°æ®é©±åŠ¨çš„è§è§£ï¼Œä¸ºæœªæ¥LLMçš„é’ˆå¯¹æ€§å¼€å‘å’Œç»“æ„ä¼˜åŒ–æä¾›äº†é‡è¦æŒ‡å¯¼ã€‚",
      "categories": [
        "cs.LG",
        "cs.AI"
      ],
      "primary_category": "cs.LG",
      "comment": "Accepted by EMNLP 2025",
      "pdf_url": "https://arxiv.org/pdf/2509.18136v1",
      "published_date": "2025-09-14 12:20:39 UTC",
      "updated_date": "2025-09-14 12:20:39 UTC",
      "processing_status": "completed",
      "attempts": 1,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "llm_backup_calls": 0,
      "last_update": "2026-01-24T18:25:43.791762+00:00"
    },
    {
      "arxiv_id": "2509.11233v1",
      "title": "TransZero: Parallel Tree Expansion in MuZero using Transformer Networks",
      "title_zh": "TransZeroï¼šåŸºäº Transformer ç½‘ç»œçš„ MuZero å¹¶è¡Œæ ‘æ‰©å±•",
      "authors": [
        "Emil Malmsten",
        "Wendelin BÃ¶hmer"
      ],
      "abstract": "We present TransZero, a model-based reinforcement learning algorithm that removes the sequential bottleneck in Monte Carlo Tree Search (MCTS). Unlike MuZero, which constructs its search tree step by step using a recurrent dynamics model, TransZero employs a transformer-based network to generate multiple latent future states simultaneously. Combined with the Mean-Variance Constrained (MVC) evaluator that eliminates dependence on inherently sequential visitation counts, our approach enables the parallel expansion of entire subtrees during planning. Experiments in MiniGrid and LunarLander show that TransZero achieves up to an eleven-fold speedup in wall-clock time compared to MuZero while maintaining sample efficiency. These results demonstrate that parallel tree construction can substantially accelerate model-based reinforcement learning, bringing real-time decision-making in complex environments closer to practice. The code is publicly available on GitHub.",
      "tldr_zh": "è¯¥ç ”ç©¶æå‡ºäº†TransZeroï¼Œä¸€ç§æ—¨åœ¨è§£å†³MuZeroä¸­è’™ç‰¹å¡æ´›æ ‘æœç´¢(MCTS)ä¸²è¡Œç“¶é¢ˆçš„æ¨¡å‹å¼ºåŒ–å­¦ä¹ ç®—æ³•ã€‚ä¸ä¾èµ–å¾ªç¯åŠ¨åŠ›å­¦æ¨¡å‹é€æ­¥æ„å»ºæœç´¢æ ‘çš„ä¼ ç»Ÿæ–¹æ³•ä¸åŒï¼ŒTransZeroåˆ©ç”¨Transformerç½‘ç»œåŒæ—¶ç”Ÿæˆå¤šä¸ªæ½œç©ºé—´æœªæ¥çŠ¶æ€ã€‚è¯¥æ–¹æ³•ç»“åˆäº†å‡å€¼-æ–¹å·®çº¦æŸ(Mean-Variance Constrained, MVC)è¯„ä¼°å™¨ï¼Œæ¶ˆé™¤äº†å¯¹æœ¬è´¨ä¸Šå±äºä¸²è¡Œç»“æ„çš„è®¿é—®è®¡æ•°(visitation counts)çš„ä¾èµ–ï¼Œä»è€Œå®ç°äº†è§„åˆ’è¿‡ç¨‹ä¸­æ•´ä¸ªå­æ ‘çš„å¹¶è¡Œæ‰©å±•ã€‚å®éªŒç»“æœæ˜¾ç¤ºï¼Œåœ¨MiniGridå’ŒLunarLanderä»»åŠ¡ä¸­ï¼ŒTransZeroåœ¨ä¿æŒæ ·æœ¬æ•ˆç‡çš„åŒæ—¶ï¼Œæ¯”MuZeroå®ç°äº†é«˜è¾¾11å€çš„æŒ‚é’Ÿæ—¶é—´(wall-clock time)åŠ é€Ÿã€‚è¯¥ç ”ç©¶è¯æ˜äº†å¹¶è¡Œæ ‘æ„å»ºèƒ½å¤§å¹…åŠ å¿«å¼ºåŒ–å­¦ä¹ çš„è¿è¡Œé€Ÿåº¦ï¼Œä¸ºå¤æ‚ç¯å¢ƒä¸‹çš„å®æ—¶å†³ç­–æä¾›äº†æ›´å…·å®ç”¨æ€§çš„æ–¹æ¡ˆã€‚",
      "categories": [
        "cs.LG",
        "cs.AI"
      ],
      "primary_category": "cs.LG",
      "comment": "Submitted to BNAIC/BeNeLearn 2025. 15 pages, 4 figures",
      "pdf_url": "https://arxiv.org/pdf/2509.11233v1",
      "published_date": "2025-09-14 12:20:38 UTC",
      "updated_date": "2025-09-14 12:20:38 UTC",
      "processing_status": "completed",
      "attempts": 1,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "llm_backup_calls": 0,
      "last_update": "2026-01-24T18:25:45.093094+00:00"
    },
    {
      "arxiv_id": "2509.11232v1",
      "title": "MIS-LSTM: Multichannel Image-Sequence LSTM for Sleep Quality and Stress Prediction",
      "title_zh": "MIS-LSTMï¼šç”¨äºç¡çœ è´¨é‡ä¸å‹åŠ›é¢„æµ‹çš„å¤šé€šé“å›¾åƒåºåˆ— LSTM",
      "authors": [
        "Seongwan Park",
        "Jieun Woo",
        "Siheon Yang"
      ],
      "abstract": "This paper presents MIS-LSTM, a hybrid framework that joins CNN encoders with an LSTM sequence model for sleep quality and stress prediction at the day level from multimodal lifelog data. Continuous sensor streams are first partitioned into N-hour blocks and rendered as multi-channel images, while sparse discrete events are encoded with a dedicated 1D-CNN. A Convolutional Block Attention Module fuses the two modalities into refined block embeddings, which an LSTM then aggregates to capture long-range temporal dependencies. To further boost robustness, we introduce UALRE, an uncertainty-aware ensemble that overrides lowconfidence majority votes with high-confidence individual predictions. Experiments on the 2025 ETRI Lifelog Challenge dataset show that Our base MISLSTM achieves Macro-F1 0.615; with the UALRE ensemble, the score improves to 0.647, outperforming strong LSTM, 1D-CNN, and CNN baselines. Ablations confirm (i) the superiority of multi-channel over stacked-vertical imaging, (ii) the benefit of a 4-hour block granularity, and (iii) the efficacy of modality-specific discrete encoding.",
      "tldr_zh": "æœ¬ç ”ç©¶æå‡ºäº†ä¸€ç§åä¸ºMIS-LSTMçš„æ··åˆæ¡†æ¶ï¼Œå°†CNNç¼–ç å™¨ä¸LSTMåºåˆ—æ¨¡å‹ç›¸ç»“åˆï¼Œåˆ©ç”¨å¤šæ¨¡æ€lifelogæ•°æ®è¿›è¡Œå¤©çº§åˆ«çš„ç¡çœ è´¨é‡å’Œå‹åŠ›é¢„æµ‹ã€‚è¯¥æ¡†æ¶å°†è¿ç»­ä¼ æ„Ÿå™¨æµåˆ’åˆ†ä¸ºNå°æ—¶å—å¹¶æ¸²æŸ“ä¸ºå¤šé€šé“å›¾åƒï¼ŒåŒæ—¶ä½¿ç”¨ä¸“é—¨çš„1D-CNNç¼–ç ç¨€ç–ç¦»æ•£äº‹ä»¶ã€‚é€šè¿‡Convolutional Block Attention Moduleèåˆä¸¤ç§æ¨¡æ€ç”Ÿæˆç²¾ç»†çš„å—åµŒå…¥ï¼Œå¹¶ç”±LSTMèšåˆä»¥æ•æ‰é•¿æœŸæ—¶é—´ä¾èµ–å…³ç³»ã€‚ä¸ºå¢å¼ºé²æ£’æ€§ï¼Œç ”ç©¶å¼•å…¥äº†ä¸ç¡®å®šæ€§æ„ŸçŸ¥é›†æˆæœºåˆ¶UALREï¼Œé€šè¿‡é«˜ç½®ä¿¡åº¦çš„ä¸ªä½“é¢„æµ‹è¦†ç›–ä½ç½®ä¿¡åº¦çš„å¤šæ•°æŠ•ç¥¨ã€‚åœ¨2025 ETRI Lifelog Challengeæ•°æ®é›†ä¸Šçš„å®éªŒè¡¨æ˜ï¼ŒMIS-LSTMåŸºç¡€æ¨¡å‹çš„Macro-F1è¾¾åˆ°0.615ï¼Œç»“åˆUALREåæå‡è‡³0.647ï¼Œä¼˜äºLSTMå’Œ1D-CNNç­‰åŸºå‡†æ¨¡å‹ã€‚æ¶ˆèå®éªŒè¿›ä¸€æ­¥è¯å®äº†å¤šé€šé“æˆåƒä¼˜äºå‚ç›´å †å æˆåƒï¼Œä¸”4å°æ—¶å—ç²’åº¦åŠé’ˆå¯¹æ¨¡æ€çš„ç¦»æ•£ç¼–ç å¯¹æ€§èƒ½æå‡å…·æœ‰æ˜¾è‘—ä½œç”¨ã€‚",
      "categories": [
        "cs.CV",
        "cs.AI"
      ],
      "primary_category": "cs.CV",
      "comment": "ICTC 2025",
      "pdf_url": "https://arxiv.org/pdf/2509.11232v1",
      "published_date": "2025-09-14 12:19:04 UTC",
      "updated_date": "2025-09-14 12:19:04 UTC",
      "processing_status": "completed",
      "attempts": 1,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "llm_backup_calls": 0,
      "last_update": "2026-01-24T18:25:48.754023+00:00"
    },
    {
      "arxiv_id": "2510.14986v1",
      "title": "RegimeFolio: A Regime Aware ML System for Sectoral Portfolio Optimization in Dynamic Markets",
      "title_zh": "RegimeFolioï¼šé¢å‘åŠ¨æ€å¸‚åœºè¡Œä¸šæŠ•èµ„ç»„åˆä¼˜åŒ–çš„çŠ¶æ€æ„ŸçŸ¥æœºå™¨å­¦ä¹ ç³»ç»Ÿ",
      "authors": [
        "Yiyao Zhang",
        "Diksha Goel",
        "Hussain Ahmad",
        "Claudia Szabo"
      ],
      "abstract": "Financial markets are inherently non-stationary, with shifting volatility regimes that alter asset co-movements and return distributions. Standard portfolio optimization methods, typically built on stationarity or regime-agnostic assumptions, struggle to adapt to such changes. To address these challenges, we propose RegimeFolio, a novel regime-aware and sector-specialized framework that, unlike existing regime-agnostic models such as DeepVol and DRL optimizers, integrates explicit volatility regime segmentation with sector-specific ensemble forecasting and adaptive mean-variance allocation. This modular architecture ensures forecasts and portfolio decisions remain aligned with current market conditions, enhancing robustness and interpretability in dynamic markets. RegimeFolio combines three components: (i) an interpretable VIX-based classifier for market regime detection; (ii) regime and sector-specific ensemble learners (Random Forest, Gradient Boosting) to capture conditional return structures; and (iii) a dynamic mean-variance optimizer with shrinkage-regularized covariance estimates for regime-aware allocation. We evaluate RegimeFolio on 34 large cap U.S. equities from 2020 to 2024. The framework achieves a cumulative return of 137 percent, a Sharpe ratio of 1.17, a 12 percent lower maximum drawdown, and a 15 to 20 percent improvement in forecast accuracy compared to conventional and advanced machine learning benchmarks. These results show that explicitly modeling volatility regimes in predictive learning and portfolio allocation enhances robustness and leads to more dependable decision-making in real markets.",
      "tldr_zh": "æœ¬ç ”ç©¶é’ˆå¯¹é‡‘èå¸‚åœºéå¹³ç¨³æ€§åŠæ³¢åŠ¨ä½“åˆ¶(volatility regimes)è½¬æ¢å¸¦æ¥çš„æŒ‘æˆ˜ï¼Œæå‡ºäº†RegimeFolioæ¡†æ¶ï¼Œè¿™æ˜¯ä¸€ç§ä¸“ä¸ºåŠ¨æ€å¸‚åœºè®¾è®¡çš„ä½“åˆ¶æ„ŸçŸ¥(regime-aware)ä¸”è¡Œä¸šç‰¹å®šçš„æœºå™¨å­¦ä¹ ç³»ç»Ÿã€‚ä¸DeepVolå’ŒDRLç­‰å¿½ç•¥å¸‚åœºä½“åˆ¶çš„æ¨¡å‹ä¸åŒï¼Œè¯¥æ¡†æ¶å°†æ˜¾å¼çš„æ³¢åŠ¨ä½“åˆ¶åˆ†å‰²ä¸ç‰¹å®šè¡Œä¸šçš„é›†æˆé¢„æµ‹åŠè‡ªé€‚åº”å‡å€¼-æ–¹å·®åˆ†é…(mean-variance allocation)ç›¸ç»“åˆã€‚RegimeFolioåŒ…å«ä¸‰ä¸ªæ ¸å¿ƒç»„ä»¶ï¼šåŸºäºVIXçš„å¯è§£é‡Šåˆ†ç±»å™¨ç”¨äºä½“åˆ¶æ£€æµ‹ã€é’ˆå¯¹ç‰¹å®šä½“åˆ¶å’Œè¡Œä¸šçš„é›†æˆå­¦ä¹ å™¨ï¼ˆå¦‚Random Forestå’ŒGradient Boostingï¼‰ä»¥æ•è·æ”¶ç›Šç»“æ„ï¼Œä»¥åŠåˆ©ç”¨æ”¶ç¼©æ­£åˆ™åŒ–åæ–¹å·®ä¼°è®¡(shrinkage-regularized covariance estimates)çš„åŠ¨æ€ä¼˜åŒ–å™¨ã€‚åœ¨2020è‡³2024å¹´é—´å¯¹34åªç¾å›½å¤§ç›˜è‚¡çš„è¯„ä¼°æ˜¾ç¤ºï¼Œè¯¥ç³»ç»Ÿå®ç°äº†137%çš„ç´¯è®¡æ”¶ç›Šå’Œ1.17çš„Sharpe ratioã€‚ç›¸æ¯”ä¼ ç»ŸåŠå…ˆè¿›çš„æœºå™¨å­¦ä¹ åŸºå‡†æ¨¡å‹ï¼ŒRegimeFolioåœ¨é¢„æµ‹å‡†ç¡®ç‡ä¸Šæå‡äº†15%è‡³20%ï¼Œä¸”æœ€å¤§å›æ’¤(maximum drawdown)é™ä½äº†12%ã€‚å®éªŒç»“æœè¯æ˜ï¼Œåœ¨é¢„æµ‹å­¦ä¹ å’ŒæŠ•èµ„ç»„åˆåˆ†é…ä¸­æ˜¾å¼å»ºæ¨¡æ³¢åŠ¨ä½“åˆ¶ï¼Œèƒ½å¤Ÿæ˜¾è‘—å¢å¼ºç³»ç»Ÿåœ¨çœŸå®å¸‚åœºç¯å¢ƒä¸­çš„é²æ£’æ€§å’Œå†³ç­–å¯é æ€§ã€‚",
      "categories": [
        "q-fin.PM",
        "cs.AI"
      ],
      "primary_category": "q-fin.PM",
      "comment": "",
      "pdf_url": "https://arxiv.org/pdf/2510.14986v1",
      "published_date": "2025-09-14 12:03:06 UTC",
      "updated_date": "2025-09-14 12:03:06 UTC",
      "processing_status": "completed",
      "attempts": 1,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "llm_backup_calls": 0,
      "last_update": "2026-01-24T18:26:04.248442+00:00"
    },
    {
      "arxiv_id": "2509.11225v1",
      "title": "MEMBOT: Memory-Based Robot in Intermittent POMDP",
      "title_zh": "MEMBOTï¼šé—´æ­‡æ€§ POMDP ä¸‹çš„åŸºäºè®°å¿†çš„æœºå™¨äºº",
      "authors": [
        "Youzhi Liang",
        "Eyan Noronha"
      ],
      "abstract": "Robotic systems deployed in real-world environments often operate under conditions of partial and often intermittent observability, where sensor inputs may be noisy, occluded, or entirely unavailable due to failures or environmental constraints. Traditional reinforcement learning (RL) approaches that assume full state observability are ill-equipped for such challenges. In this work, we introduce MEMBOT, a modular memory-based architecture designed to address intermittent partial observability in robotic control tasks. MEMBOT decouples belief inference from policy learning through a two-phase training process: an offline multi-task learning pretraining stage that learns a robust task-agnostic latent belief encoder using a reconstruction losses, followed by fine-tuning of task-specific policies using behavior cloning. The belief encoder, implemented as a state-space model (SSM) and a LSTM, integrates temporal sequences of observations and actions to infer latent state representations that persist even when observations are dropped. We train and evaluate MEMBOT on 10 robotic manipulation benchmark tasks from MetaWorld and Robomimic under varying rates of observation dropout. Results show that MEMBOT consistently outperforms both memoryless and naively recurrent baselines, maintaining up to 80% of peak performance under 50% observation availability. These findings highlight the effectiveness of explicit belief modeling in achieving robust, transferable, and data-efficient policies for real-world partially observable robotic systems.",
      "tldr_zh": "è¯¥ç ”ç©¶é’ˆå¯¹æœºå™¨äººåœ¨ç°å®ç¯å¢ƒä¸­é¢ä¸´çš„é—´æ­‡æ€§éƒ¨åˆ†å¯è§‚æµ‹æ€§(Intermittent Partial Observability)æŒ‘æˆ˜ï¼Œæå‡ºäº†åä¸ºMEMBOTçš„æ¨¡å—åŒ–è®°å¿†æ¶æ„ã€‚è¯¥æ¶æ„å°†ä¿¡å¿µæ¨ç†(Belief Inference)ä¸ç­–ç•¥å­¦ä¹ è§£è€¦ï¼Œé¦–å…ˆé€šè¿‡ç¦»çº¿å¤šä»»åŠ¡é¢„è®­ç»ƒé˜¶æ®µåˆ©ç”¨çŠ¶æ€ç©ºé—´æ¨¡å‹(SSM)å’ŒLSTMæ„å»ºä¸€ä¸ªä»»åŠ¡æ— å…³çš„æ½œåœ¨ä¿¡å¿µç¼–ç å™¨ï¼Œéšååˆ©ç”¨è¡Œä¸ºå…‹éš†(Behavior Cloning)è¿›è¡Œç‰¹å®šä»»åŠ¡çš„ç­–ç•¥å¾®è°ƒã€‚è¯¥ç¼–ç å™¨èƒ½å¤Ÿæ•´åˆè§‚æµ‹ä¸åŠ¨ä½œçš„æ—¶åºåºåˆ—ï¼Œå³ä½¿åœ¨ä¼ æ„Ÿå™¨ä¿¡å·å®Œå…¨ä¸¢å¤±çš„æƒ…å†µä¸‹ä¹Ÿèƒ½æ¨æ–­å¹¶ç»´æŒæŒä¹…çš„æ½œåœ¨çŠ¶æ€è¡¨ç¤ºã€‚å®éªŒåœ¨MetaWorldå’ŒRobomimicçš„10é¡¹æœºå™¨äººæ“ä½œåŸºå‡†ä»»åŠ¡ä¸Šè¯æ˜ï¼ŒMEMBOTåœ¨è§‚æµ‹å€¼ç¼ºå¤±è¾¾50%çš„æƒ…å†µä¸‹ä»èƒ½ä¿æŒ80%çš„å³°å€¼æ€§èƒ½ã€‚ç›¸æ¯”äºæ— è®°å¿†æ¨¡å‹æˆ–æ™®é€šçš„å¾ªç¯ç¥ç»ç½‘ç»œåŸºå‡†ï¼ŒMEMBOTå±•ç°äº†æ›´å¼ºçš„é²æ£’æ€§ã€å¯è¿ç§»æ€§å’Œæ•°æ®æ•ˆç‡ã€‚è¿™ä¸€ç ”ç©¶ç»“æœå¼ºè°ƒäº†æ˜¾å¼ä¿¡å¿µå»ºæ¨¡å¯¹äºæ„å»ºèƒ½åœ¨å¤æ‚ç°å®ç¯å¢ƒä¸‹ç¨³å®šè¿è¡Œçš„æœºå™¨äººç³»ç»Ÿå…·æœ‰é‡è¦æ„ä¹‰ã€‚",
      "categories": [
        "cs.RO",
        "cs.AI"
      ],
      "primary_category": "cs.RO",
      "comment": "",
      "pdf_url": "https://arxiv.org/pdf/2509.11225v1",
      "published_date": "2025-09-14 12:00:52 UTC",
      "updated_date": "2025-09-14 12:00:52 UTC",
      "processing_status": "completed",
      "attempts": 1,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "llm_backup_calls": 0,
      "last_update": "2026-01-24T18:25:56.492987+00:00"
    },
    {
      "arxiv_id": "2509.11218v1",
      "title": "Geometrically Constrained and Token-Based Probabilistic Spatial Transformers",
      "title_zh": "å‡ ä½•çº¦æŸä¸åŸºäº Token çš„æ¦‚ç‡ç©ºé—´å˜æ¢å™¨",
      "authors": [
        "Johann Schmidt",
        "Sebastian Stober"
      ],
      "abstract": "Fine-grained visual classification (FGVC) remains highly sensitive to geometric variability, where objects appear under arbitrary orientations, scales, and perspective distortions. While equivariant architectures address this issue, they typically require substantial computational resources and restrict the hypothesis space. We revisit Spatial Transformer Networks (STNs) as a canonicalization tool for transformer-based vision pipelines, emphasizing their flexibility, backbone-agnostic nature, and lack of architectural constraints. We propose a probabilistic, component-wise extension that improves robustness. Specifically, we decompose affine transformations into rotation, scaling, and shearing, and regress each component under geometric constraints using a shared localization encoder. To capture uncertainty, we model each component with a Gaussian variational posterior and perform sampling-based canonicalization during inference.A novel component-wise alignment loss leverages augmentation parameters to guide spatial alignment. Experiments on challenging moth classification benchmarks demonstrate that our method consistently improves robustness compared to other STNs.",
      "tldr_zh": "è¯¥ç ”ç©¶é’ˆå¯¹ç»†ç²’åº¦è§†è§‰åˆ†ç±»(Fine-grained visual classification, FGVC)ä¸­ç‰©ä½“å› å§¿æ€ã€æ¯”ä¾‹å’Œé€è§†å˜å½¢å¯¼è‡´çš„å‡ ä½•å˜å¼‚æ•æ„Ÿæ€§é—®é¢˜ï¼Œé‡æ–°æ¢è®¨äº†ç©ºé—´å˜æ¢ç½‘ç»œ(Spatial Transformer Networks, STNs)ä½œä¸º Transformer è§†è§‰æµæ°´çº¿è§„èŒƒåŒ–å·¥å…·çš„æ½œåŠ›ã€‚ä½œè€…æå‡ºäº†ä¸€ç§åŸºäº Token çš„æ¦‚ç‡æ€§ç»„ä»¶æ‰©å±•æ–¹æ³•ï¼Œå°†ä»¿å°„å˜æ¢åˆ†è§£ä¸ºæ—‹è½¬(rotation)ã€ç¼©æ”¾(scaling)å’Œå‰ªåˆ‡(shearing)ç­‰ç»„ä»¶ï¼Œå¹¶é€šè¿‡å…±äº«çš„å®šä½ç¼–ç å™¨åœ¨å‡ ä½•çº¦æŸä¸‹å›å½’æ¯ä¸ªç»„ä»¶ã€‚ä¸ºäº†æ•æ‰ä¸ç¡®å®šæ€§ï¼Œç ”ç©¶é‡‡ç”¨é«˜æ–¯å˜åˆ†åéªŒ(Gaussian variational posterior)å¯¹å„ç»„ä»¶è¿›è¡Œå»ºæ¨¡ï¼Œå¹¶åœ¨æ¨ç†é˜¶æ®µæ‰§è¡ŒåŸºäºé‡‡æ ·çš„è§„èŒƒåŒ–ã€‚æ­¤å¤–ï¼Œè¯¥ç ”ç©¶å¼•å…¥äº†ä¸€ç§æ–°å‹çš„ç»„ä»¶å¯¹é½æŸå¤±(component-wise alignment loss)ï¼Œåˆ©ç”¨å¢å¼ºå‚æ•°æ¥å¼•å¯¼ç©ºé—´å¯¹é½ã€‚åœ¨é£è›¾åˆ†ç±»åŸºå‡†æµ‹è¯•ä¸Šçš„å®éªŒç»“æœè¯æ˜ï¼Œè¯¥æ–¹æ³•ç›¸æ¯”äºä¼ ç»Ÿ STNs èƒ½æ˜¾è‘—å¢å¼ºæ¨¡å‹åœ¨å¤„ç†å¤æ‚å‡ ä½•å˜åŒ–æ—¶çš„é²æ£’æ€§ã€‚",
      "categories": [
        "cs.CV",
        "cs.AI"
      ],
      "primary_category": "cs.CV",
      "comment": "",
      "pdf_url": "https://arxiv.org/pdf/2509.11218v1",
      "published_date": "2025-09-14 11:30:53 UTC",
      "updated_date": "2025-09-14 11:30:53 UTC",
      "processing_status": "completed",
      "attempts": 1,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "llm_backup_calls": 0,
      "last_update": "2026-01-24T18:25:59.796875+00:00"
    },
    {
      "arxiv_id": "2509.18135v1",
      "title": "SDGF: Fusing Static and Multi-Scale Dynamic Correlations for Multivariate Time Series Forecasting",
      "title_zh": "SDGFï¼šèåˆé™æ€ä¸å¤šå°ºåº¦åŠ¨æ€å…³è”çš„å¤šå…ƒæ—¶é—´åºåˆ—é¢„æµ‹",
      "authors": [
        "Shaoxun Wang",
        "Xingjun Zhang",
        "Qianyang Li",
        "Jiawei Cao",
        "Zhendong Tan"
      ],
      "abstract": "Inter-series correlations are crucial for accurate multivariate time series forecasting, yet these relationships often exhibit complex dynamics across different temporal scales. Existing methods are limited in modeling these multi-scale dependencies and struggle to capture their intricate and evolving nature. To address this challenge, this paper proposes a novel Static-Dynamic Graph Fusion network (SDGF), whose core lies in capturing multi-scale inter-series correlations through a dual-path graph structure learning approach. Specifically, the model utilizes a static graph based on prior knowledge to anchor long-term, stable dependencies, while concurrently employing Multi-level Wavelet Decomposition to extract multi-scale features for constructing an adaptively learned dynamic graph to capture associations at different scales. We design an attention-gated module to fuse these two complementary sources of information intelligently, and a multi-kernel dilated convolutional network is then used to deepen the understanding of temporal patterns. Comprehensive experiments on multiple widely used real-world benchmark datasets demonstrate the effectiveness of our proposed model.",
      "tldr_zh": "è¯¥ç ”ç©¶æå‡ºäº†Static-Dynamic Graph Fusion network (SDGF)ï¼Œæ—¨åœ¨è§£å†³å¤šå…ƒæ—¶é—´åºåˆ—é¢„æµ‹ä¸­éš¾ä»¥å»ºæ¨¡åºåˆ—é—´å¤æ‚ä¸”æ¼”åŒ–çš„å¤šå°ºåº¦åŠ¨æ€å…³è”çš„é—®é¢˜ã€‚è¯¥æ¨¡å‹é€šè¿‡åŒè·¯å¾„å›¾ç»“æ„å­¦ä¹ æ–¹æ³•æ•æ‰å¤šå°ºåº¦ç›¸å…³æ€§ï¼Œå…¶ä¸­é™æ€è·¯å¾„åˆ©ç”¨åŸºäºå…ˆéªŒçŸ¥è¯†çš„Static Graphé”šå®šé•¿æœŸç¨³å®šçš„ä¾èµ–å…³ç³»ã€‚ä¸æ­¤åŒæ—¶ï¼ŒåŠ¨æ€è·¯å¾„é‡‡ç”¨Multi-level Wavelet Decompositionæå–å¤šå°ºåº¦ç‰¹å¾ï¼Œä»¥æ„å»ºè‡ªé€‚åº”å­¦ä¹ çš„Dynamic Graphæ¥æ•æ‰ä¸åŒå°ºåº¦ä¸‹çš„å…³è”å˜åŒ–ã€‚ç ”ç©¶è¿›ä¸€æ­¥è®¾è®¡äº†ä¸€ä¸ªAttention-gated moduleæ¥æ™ºèƒ½èåˆè¿™ä¸¤ç±»äº’è¡¥ä¿¡æ¯ï¼Œå¹¶ç»“åˆMulti-kernel dilated convolutional networkä»¥æ·±åŒ–å¯¹å¤æ‚æ—¶é—´æ¨¡å¼çš„ç†è§£ã€‚åœ¨å¤šä¸ªçœŸå®ä¸–ç•ŒåŸºå‡†æ•°æ®é›†ä¸Šçš„å¹¿æ³›å®éªŒè¯æ˜ï¼ŒSDGFèƒ½å¤Ÿæ˜¾è‘—æå‡é¢„æµ‹æ€§èƒ½ï¼Œæœ‰æ•ˆåº”å¯¹å¤šå…ƒæ—¶é—´åºåˆ—ä¸­çš„åŠ¨æ€ä¾èµ–å»ºæ¨¡æŒ‘æˆ˜ã€‚",
      "categories": [
        "cs.LG",
        "cs.AI"
      ],
      "primary_category": "cs.LG",
      "comment": "",
      "pdf_url": "https://arxiv.org/pdf/2509.18135v1",
      "published_date": "2025-09-14 11:23:12 UTC",
      "updated_date": "2025-09-14 11:23:12 UTC",
      "processing_status": "completed",
      "attempts": 1,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "llm_backup_calls": 0,
      "last_update": "2026-01-24T18:26:03.949744+00:00"
    },
    {
      "arxiv_id": "2509.11206v2",
      "title": "Evalet: Evaluating Large Language Models by Fragmenting Outputs into Functions",
      "title_zh": "Evaletï¼šé€šè¿‡å°†è¾“å‡ºæ‹†è§£ä¸ºåŠŸèƒ½æ€§ç‰‡æ®µè¯„ä¼°å¤§è¯­è¨€æ¨¡å‹",
      "authors": [
        "Tae Soo Kim",
        "Heechan Lee",
        "Yoonjoo Lee",
        "Joseph Seering",
        "Juho Kim"
      ],
      "abstract": "Practitioners increasingly rely on Large Language Models (LLMs) to evaluate generative AI outputs through \"LLM-as-a-Judge\" approaches. However, these methods produce holistic scores that obscure which specific elements influenced the assessments. We propose functional fragmentation, a method that dissects each output into key fragments and interprets the rhetoric functions that each fragment serves relative to evaluation criteria -- surfacing the elements of interest and revealing how they fulfill or hinder user goals. We instantiate this approach in Evalet, an interactive system that visualizes fragment-level functions across many outputs to support inspection, rating, and comparison of evaluations. A user study (N=10) found that, while practitioners struggled to validate holistic scores, our approach helped them identify 48% more evaluation misalignments. This helped them calibrate trust in LLM evaluations and rely on them to find more actionable issues in model outputs. Our work shifts LLM evaluation from quantitative scores toward qualitative, fine-grained analysis of model behavior.",
      "tldr_zh": "è¯¥ç ”ç©¶æŒ‡å‡ºï¼Œè™½ç„¶ä»ä¸šè€…æ—¥ç›Šä¾èµ– LLM-as-a-Judge æ–¹æ³•æ¥è¯„ä¼°ç”Ÿæˆå¼äººå·¥æ™ºèƒ½ï¼Œä½†å…¶äº§ç”Ÿçš„æ•´ä½“åˆ†æ•°å¾€å¾€æ©ç›–äº†å½±å“è¯„ä¼°çš„å…·ä½“å› ç´ ã€‚ä¸ºæ­¤ï¼Œä½œè€…æå‡ºäº†åŠŸèƒ½ç‰‡æ®µåŒ– (functional fragmentation) æ–¹æ³•ï¼Œå°†è¾“å‡ºæ‹†è§£ä¸ºå…³é”®ç‰‡æ®µå¹¶è§£æå…¶å¯¹åº”çš„ä¿®è¾åŠŸèƒ½ï¼Œä»¥æ­ç¤ºè¿™äº›å…ƒç´ å¦‚ä½•æ»¡è¶³æˆ–é˜»ç¢ç”¨æˆ·ç›®æ ‡ã€‚è¯¥æ–¹æ³•åœ¨äº¤äº’å¼ç³»ç»Ÿ Evalet ä¸­å¾—åˆ°åº”ç”¨ï¼Œé€šè¿‡å¯è§†åŒ–ç‰‡æ®µçº§åŠŸèƒ½æ”¯æŒå¯¹è¯„ä¼°ç»“æœçš„æ·±å…¥æ£€æŸ¥ã€è¯„çº§å’Œæ¯”è¾ƒã€‚ç”¨æˆ·ç ”ç©¶æ˜¾ç¤ºï¼ŒEvalet å¸®åŠ©ä»ä¸šè€…å¤šè¯†åˆ«äº† 48% çš„è¯„ä¼°åå·®ï¼Œæœ‰æ•ˆæå‡äº†å¯¹ LLM è¯„ä¼°çš„ä¿¡ä»»æ ¡å‡†ã€‚è¿™é¡¹å·¥ä½œæ ‡å¿—ç€ LLM è¯„ä¼°æ­£ä»ä¼ ç»Ÿçš„å®šé‡è¯„åˆ†è½¬å‘æ›´å…·å®šæ€§ã€ç»†ç²’åº¦çš„æ¨¡å‹è¡Œä¸ºåˆ†æã€‚",
      "categories": [
        "cs.HC",
        "cs.AI",
        "cs.CL"
      ],
      "primary_category": "cs.HC",
      "comment": "The first two authors hold equal contribution",
      "pdf_url": "https://arxiv.org/pdf/2509.11206v2",
      "published_date": "2025-09-14 10:24:13 UTC",
      "updated_date": "2025-09-16 02:46:26 UTC",
      "processing_status": "completed",
      "attempts": 1,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "llm_backup_calls": 0,
      "last_update": "2026-01-24T18:26:07.791903+00:00"
    },
    {
      "arxiv_id": "2509.11198v1",
      "title": "Quantum Architecture Search for Solving Quantum Machine Learning Tasks",
      "title_zh": "é¢å‘é‡å­æœºå™¨å­¦ä¹ ä»»åŠ¡æ±‚è§£çš„é‡å­æ¶æ„æœç´¢",
      "authors": [
        "Michael KÃ¶lle",
        "Simon Salfer",
        "Tobias Rohe",
        "Philipp Altmann",
        "Claudia Linnhoff-Popien"
      ],
      "abstract": "Quantum computing leverages quantum mechanics to address computational problems in ways that differ fundamentally from classical approaches. While current quantum hardware remains error-prone and limited in scale, Variational Quantum Circuits offer a noise-resilient framework suitable for today's devices. The performance of these circuits strongly depends on the underlying architecture of their parameterized quantum components. Identifying efficient, hardware-compatible quantum circuit architectures -- known as Quantum Architecture Search (QAS) -- is therefore essential. Manual QAS is complex and error-prone, motivating efforts to automate it. Among various automated strategies, Reinforcement Learning (RL) remains underexplored, particularly in Quantum Machine Learning contexts. This work introduces RL-QAS, a framework that applies RL to discover effective circuit architectures for classification tasks. We evaluate RL-QAS using the Iris and binary MNIST datasets. The agent autonomously discovers low-complexity circuit designs that achieve high test accuracy. Our results show that RL is a viable approach for automated architecture search in quantum machine learning. However, applying RL-QAS to more complex tasks will require further refinement of the search strategy and performance evaluation mechanisms.",
      "tldr_zh": "è¯¥ç ”ç©¶æ¢è®¨äº†å˜åˆ†é‡å­ç”µè·¯ (Variational Quantum Circuits) åœ¨å½“å‰æœ‰å™ªé‡å­è®¾å¤‡ä¸­çš„åº”ç”¨ï¼Œå¹¶æŒ‡å‡ºç”µè·¯æ€§èƒ½é«˜åº¦ä¾èµ–äºå…¶æ¶æ„è®¾è®¡ã€‚é’ˆå¯¹æ‰‹åŠ¨è®¾è®¡ç”µè·¯æ¶æ„çš„å¤æ‚æ€§ä¸æ˜“é”™æ€§ï¼Œç ”ç©¶è€…æå‡ºäº† RL-QAS æ¡†æ¶ï¼Œåˆ©ç”¨å¼ºåŒ–å­¦ä¹  (Reinforcement Learning) è‡ªåŠ¨ä¸ºé‡å­æœºå™¨å­¦ä¹ åˆ†ç±»ä»»åŠ¡æœç´¢é«˜æ•ˆçš„ç”µè·¯æ¶æ„ã€‚é€šè¿‡åœ¨ Iris å’ŒäºŒè¿›åˆ¶ MNIST æ•°æ®é›†ä¸Šçš„å®éªŒè¯„ä¼°ï¼Œæ™ºèƒ½ä½“èƒ½å¤Ÿè‡ªä¸»å‘ç°ä½å¤æ‚åº¦ä¸”å…·å¤‡é«˜æµ‹è¯•å‡†ç¡®ç‡çš„ç²¾ç®€ç”µè·¯è®¾è®¡ã€‚å®éªŒç»“æœè¯æ˜äº†å¼ºåŒ–å­¦ä¹ æ˜¯å®ç°è‡ªåŠ¨åŒ–é‡å­æ¶æ„æœç´¢ (Quantum Architecture Search) çš„ä¸€ç§å¯è¡Œä¸”æœ‰æ•ˆçš„è·¯å¾„ã€‚è¯¥ç ”ç©¶å¼ºè°ƒäº†è‡ªåŠ¨åŒ–è®¾è®¡åœ¨é‡å­æœºå™¨å­¦ä¹  (Quantum Machine Learning) é¢†åŸŸçš„é‡è¦æ€§ï¼Œä¸ºå‡å°‘äººå·¥å¹²é¢„æä¾›äº†æŠ€æœ¯æ”¯æŒã€‚å°½ç®¡åˆæ­¥è¡¨ç°ä¼˜å¼‚ï¼Œç ”ç©¶ä¹ŸæŒ‡å‡ºå°†è¯¥æ¡†æ¶æ‰©å±•è‡³æ›´å¤æ‚ä»»åŠ¡æ—¶ï¼Œä»éœ€å¯¹æœç´¢ç­–ç•¥å’Œæ€§èƒ½è¯„ä¼°æœºåˆ¶è¿›è¡Œè¿›ä¸€æ­¥çš„ä¼˜åŒ–ã€‚",
      "categories": [
        "quant-ph",
        "cs.AI",
        "cs.LG"
      ],
      "primary_category": "quant-ph",
      "comment": "",
      "pdf_url": "https://arxiv.org/pdf/2509.11198v1",
      "published_date": "2025-09-14 09:55:38 UTC",
      "updated_date": "2025-09-14 09:55:38 UTC",
      "processing_status": "completed",
      "attempts": 1,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "llm_backup_calls": 0,
      "last_update": "2026-01-24T18:26:21.360025+00:00"
    },
    {
      "arxiv_id": "2509.13353v1",
      "title": "Hybrid Quantum-Classical Model for Image Classification",
      "title_zh": "ç”¨äºå›¾åƒåˆ†ç±»çš„é‡å­-ç»å…¸æ··åˆæ¨¡å‹",
      "authors": [
        "Muhammad Adnan Shahzad"
      ],
      "abstract": "This study presents a systematic comparison between hybrid quantum-classical neural networks and purely classical models across three benchmark datasets (MNIST, CIFAR100, and STL10) to evaluate their performance, efficiency, and robustness. The hybrid models integrate parameterized quantum circuits with classical deep learning architectures, while the classical counterparts use conventional convolutional neural networks (CNNs). Experiments were conducted over 50 training epochs for each dataset, with evaluations on validation accuracy, test accuracy, training time, computational resource usage, and adversarial robustness (tested with $Îµ=0.1$ perturbations).Key findings demonstrate that hybrid models consistently outperform classical models in final accuracy, achieving {99.38\\% (MNIST), 41.69\\% (CIFAR100), and 74.05\\% (STL10) validation accuracy, compared to classical benchmarks of 98.21\\%, 32.25\\%, and 63.76\\%, respectively. Notably, the hybrid advantage scales with dataset complexity, showing the most significant gains on CIFAR100 (+9.44\\%) and STL10 (+10.29\\%). Hybrid models also train 5--12$\\times$ faster (e.g., 21.23s vs. 108.44s per epoch on MNIST) and use 6--32\\% fewer parameters} while maintaining superior generalization to unseen test data.Adversarial robustness tests reveal that hybrid models are significantly more resilient on simpler datasets (e.g., 45.27\\% robust accuracy on MNIST vs. 10.80\\% for classical) but show comparable fragility on complex datasets like CIFAR100 ($\\sim$1\\% robustness for both). Resource efficiency analyses indicate that hybrid models consume less memory (4--5GB vs. 5--6GB for classical) and lower CPU utilization (9.5\\% vs. 23.2\\% on average).These results suggest that hybrid quantum-classical architectures offer compelling advantages in accuracy, training efficiency, and parameter scalability, particularly for complex vision tasks.",
      "tldr_zh": "è¯¥ç ”ç©¶å¯¹æ··åˆé‡å­-ç»å…¸ç¥ç»ç½‘ç»œ(hybrid quantum-classical neural networks)ä¸çº¯ç»å…¸æ¨¡å‹åœ¨MNISTã€CIFAR100å’ŒSTL10æ•°æ®é›†ä¸Šçš„æ€§èƒ½ã€æ•ˆç‡å’Œé²æ£’æ€§è¿›è¡Œäº†ç³»ç»Ÿå¯¹æ¯”ã€‚ç ”ç©¶é€šè¿‡å°†å‚æ•°åŒ–é‡å­ç”µè·¯(parameterized quantum circuits)ä¸ç»å…¸æ·±åº¦å­¦ä¹ æ¶æ„é›†æˆï¼Œæå‡ºäº†ä¸€ç§èƒ½å¤Ÿæ˜¾è‘—æå‡å›¾åƒåˆ†ç±»èƒ½åŠ›çš„æ··åˆæ¨¡å‹ã€‚å®éªŒç»“æœè¡¨æ˜ï¼Œæ··åˆæ¨¡å‹åœ¨æ‰€æœ‰åŸºå‡†æ•°æ®é›†ä¸Šçš„å‡†ç¡®ç‡å‡ä¼˜äºç»å…¸å·ç§¯ç¥ç»ç½‘ç»œ(CNNs)ï¼Œä¸”ä¼˜åŠ¿éšæ•°æ®é›†å¤æ‚åº¦çš„å¢åŠ è€Œæ‰©å¤§ï¼Œåœ¨STL10ä¸Šå‡†ç¡®ç‡æå‡äº†10.29%ã€‚æ­¤å¤–ï¼Œæ··åˆæ¨¡å‹çš„è®­ç»ƒé€Ÿåº¦æ¯”ç»å…¸æ¨¡å‹å¿«5è‡³12å€ï¼Œä¸”åœ¨å‚æ•°é‡å‡å°‘6%è‡³32%çš„åŒæ—¶ä¿æŒäº†æ›´å¼ºçš„æ³›åŒ–èƒ½åŠ›ã€‚åœ¨å¯¹æŠ—æ€§é²æ£’æ€§(adversarial robustness)æµ‹è¯•ä¸­ï¼Œæ··åˆæ¨¡å‹åœ¨ç®€å•æ•°æ®é›†ä¸Šè¡¨ç°å‡ºæ›´å¼ºçš„éŸ§æ€§ï¼Œå¹¶å…·æœ‰æ›´ä½çš„å†…å­˜å ç”¨å’ŒCPUåˆ©ç”¨ç‡ã€‚è¿™äº›å‘ç°è¯æ˜äº†æ··åˆé‡å­-ç»å…¸æ¶æ„åœ¨å¤„ç†å¤æ‚è§†è§‰ä»»åŠ¡æ—¶ï¼Œåœ¨å‡†ç¡®æ€§ã€è®­ç»ƒæ•ˆç‡å’Œå‚æ•°æ‰©å±•æ€§æ–¹é¢å…·æœ‰æ˜¾è‘—çš„ç«äº‰ä¼˜åŠ¿ã€‚",
      "categories": [
        "cs.CV",
        "cs.AI",
        "cs.LG"
      ],
      "primary_category": "cs.CV",
      "comment": "",
      "pdf_url": "https://arxiv.org/pdf/2509.13353v1",
      "published_date": "2025-09-14 09:55:00 UTC",
      "updated_date": "2025-09-14 09:55:00 UTC",
      "processing_status": "completed",
      "attempts": 1,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "llm_backup_calls": 0,
      "last_update": "2026-01-24T18:26:13.546145+00:00"
    },
    {
      "arxiv_id": "2509.11197v1",
      "title": "DreamNav: A Trajectory-Based Imaginative Framework for Zero-Shot Vision-and-Language Navigation",
      "title_zh": "DreamNavï¼šé¢å‘é›¶æ ·æœ¬è§†è§‰è¯­è¨€å¯¼èˆªçš„åŸºäºè½¨è¿¹çš„æƒ³è±¡åŠ›æ¡†æ¶",
      "authors": [
        "Yunheng Wang",
        "Yuetong Fang",
        "Taowen Wang",
        "Yixiao Feng",
        "Yawen Tan",
        "Shuning Zhang",
        "Peiran Liu",
        "Yiding Ji",
        "Renjing Xu"
      ],
      "abstract": "Vision-and-Language Navigation in Continuous Environments (VLN-CE), which links language instructions to perception and control in the real world, is a core capability of embodied robots. Recently, large-scale pretrained foundation models have been leveraged as shared priors for perception, reasoning, and action, enabling zero-shot VLN without task-specific training. However, existing zero-shot VLN methods depend on costly perception and passive scene understanding, collapsing control to point-level choices. As a result, they are expensive to deploy, misaligned in action semantics, and short-sighted in planning. To address these issues, we present DreamNav that focuses on the following three aspects: (1) for reducing sensory cost, our EgoView Corrector aligns viewpoints and stabilizes egocentric perception; (2) instead of point-level actions, our Trajectory Predictor favors global trajectory-level planning to better align with instruction semantics; and (3) to enable anticipatory and long-horizon planning, we propose an Imagination Predictor to endow the agent with proactive thinking capability. On VLN-CE and real-world tests, DreamNav sets a new zero-shot state-of-the-art (SOTA), outperforming the strongest egocentric baseline with extra information by up to 7.49\\% and 18.15\\% in terms of SR and SPL metrics. To our knowledge, this is the first zero-shot VLN method to unify trajectory-level planning and active imagination while using only egocentric inputs.",
      "tldr_zh": "è¯¥ç ”ç©¶é’ˆå¯¹è¿ç»­ç¯å¢ƒä¸‹çš„é›¶æ ·æœ¬è§†è§‰è¯­è¨€å¯¼èˆª (Zero-Shot Vision-and-Language Navigation in Continuous Environments, VLN-CE) ä¸­å­˜åœ¨çš„æ„ŸçŸ¥æˆæœ¬é«˜ã€åŠ¨ä½œè¯­ä¹‰å¤±é…åŠè§„åˆ’çŸ­è§†ç­‰æŒ‘æˆ˜ï¼Œæå‡ºäº†åä¸º DreamNav çš„è½¨è¿¹é©±åŠ¨å‹æƒ³è±¡åŠ›æ¡†æ¶ã€‚è¯¥æ¡†æ¶å¼•å…¥äº†ç”¨äºè§†è§’å¯¹é½ä¸ç¨³å®šæ„ŸçŸ¥çš„ EgoView Correctorï¼Œå¹¶åˆ©ç”¨ Trajectory Predictor å®ç°å…¨å±€è½¨è¿¹çº§è§„åˆ’ï¼Œä»è€Œæ›´å¥½åœ°ä¸æŒ‡ä»¤è¯­ä¹‰å¯¹é½ã€‚åŒæ—¶ï¼Œé€šè¿‡ Imagination Predictor èµ‹äºˆæ™ºèƒ½ä½“ä¸»åŠ¨æ€è€ƒèƒ½åŠ›ï¼Œæ˜¾è‘—å¢å¼ºäº†å…¶å‰ç»æ€§ä¸é•¿ç¨‹è§„åˆ’æ°´å¹³ã€‚å®éªŒç»“æœè¡¨æ˜ï¼ŒDreamNav åœ¨ VLN-CE ä»»åŠ¡å’ŒçœŸå®ä¸–ç•Œæµ‹è¯•ä¸­å‡åˆ·æ–°äº†é›¶æ ·æœ¬å¯¼èˆªçš„ SOTA è®°å½•ï¼Œåœ¨ SR å’Œ SPL æŒ‡æ ‡ä¸Šç›¸è¾ƒäºæœ€å¼ºåŸºçº¿æ¨¡å‹å–å¾—äº†æ˜¾è‘—æå‡ã€‚è¿™æ˜¯é¦–ä¸ªåœ¨ä»…ä¾èµ–ç¬¬ä¸€äººç§°è¾“å…¥çš„æƒ…å†µä¸‹ï¼ŒæˆåŠŸç»Ÿä¸€è½¨è¿¹çº§è§„åˆ’ä¸ä¸»åŠ¨æƒ³è±¡çš„é›¶æ ·æœ¬å¯¼èˆªæ–¹æ³•ï¼Œä¸ºå…·èº«æ™ºèƒ½æœºå™¨äººçš„è‡ªä¸»å¯¼èˆªæä¾›äº†é«˜æ•ˆçš„è§£å†³æ–¹æ¡ˆã€‚",
      "categories": [
        "cs.RO",
        "cs.AI",
        "cs.CL",
        "cs.CV"
      ],
      "primary_category": "cs.RO",
      "comment": "",
      "pdf_url": "https://arxiv.org/pdf/2509.11197v1",
      "published_date": "2025-09-14 09:54:20 UTC",
      "updated_date": "2025-09-14 09:54:20 UTC",
      "processing_status": "completed",
      "attempts": 1,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "llm_backup_calls": 0,
      "last_update": "2026-01-24T18:26:49.086680+00:00"
    },
    {
      "arxiv_id": "2509.11196v1",
      "title": "Federated Recommender System with Data Valuation for E-commerce Platform",
      "title_zh": "é¢å‘ç”µå­å•†åŠ¡å¹³å°çš„å…·æœ‰æ•°æ®ä¼°å€¼çš„è”é‚¦æ¨èç³»ç»Ÿ",
      "authors": [
        "Jongwon Park",
        "Minku Kang",
        "Wooseok Sim",
        "Soyoung Lee",
        "Hogun Park"
      ],
      "abstract": "Federated Learning (FL) is gaining prominence in machine learning as privacy concerns grow. This paradigm allows each client (e.g., an individual online store) to train a recommendation model locally while sharing only model updates, without exposing the raw interaction logs to a central server, thereby preserving privacy in a decentralized environment. Nonetheless, most existing FL-based recommender systems still rely solely on each client's private data, despite the abundance of publicly available datasets that could be leveraged to enrich local training; this potential remains largely underexplored. To this end, we consider a realistic scenario wherein a large shopping platform collaborates with multiple small online stores to build a global recommender system. The platform possesses global data, such as shareable user and item lists, while each store holds a portion of interaction data privately (or locally). Although integrating global data can help mitigate the limitations of sparse and biased clients' local data, it also introduces additional challenges: simply combining all global interactions can amplify noise and irrelevant patterns, worsening personalization and increasing computational costs. To address these challenges, we propose FedGDVE, which selectively augments each client's local graph with semantically aligned samples from the global dataset. FedGDVE employs: (i) a pre-trained graph encoder to extract global structural features, (ii) a local valid predictor to assess client-specific relevance, (iii) a reinforcement-learning-based probability estimator to filter and sample only the most pertinent global interactions. FedGDVE improves performance by up to 34.86% on recognized benchmarks in FL environments.",
      "tldr_zh": "è¯¥ç ”ç©¶é’ˆå¯¹éšç§ä¿æŠ¤èƒŒæ™¯ä¸‹è”é‚¦å­¦ä¹ (Federated Learning)æ¨èç³»ç»Ÿå­˜åœ¨çš„æœ¬åœ°æ•°æ®ç¨€ç–ä¸åå·®é—®é¢˜ï¼Œä»¥åŠç®€å•èåˆå…¨å±€æ•°æ®å¸¦æ¥çš„å™ªå£°å¹²æ‰°ï¼Œæå‡ºäº†ä¸€ç§åä¸ºFedGDVEçš„æ–°å‹æ¡†æ¶ã€‚FedGDVEæ—¨åœ¨é€šè¿‡ä»å…¨å±€æ•°æ®é›†ä¸­é€‰æ‹©æ€§åœ°å¢å¼ºæ¯ä¸ªå®¢æˆ·ç«¯çš„æœ¬åœ°å›¾(local graph)ï¼Œå®ç°è¯­ä¹‰å¯¹é½çš„æ ·æœ¬è¡¥å……ã€‚è¯¥æ¡†æ¶é‡‡ç”¨äº†é¢„è®­ç»ƒçš„å›¾ç¼–ç å™¨(graph encoder)æ¥æå–å…¨å±€ç»“æ„ç‰¹å¾ï¼Œå¹¶ç»“åˆæœ¬åœ°æœ‰æ•ˆé¢„æµ‹å™¨(local valid predictor)è¯„ä¼°ç‰¹å®šå®¢æˆ·ç«¯çš„ç›¸å…³æ€§ã€‚åŒæ—¶ï¼Œç³»ç»Ÿå¼•å…¥äº†åŸºäºå¼ºåŒ–å­¦ä¹ çš„æ¦‚ç‡ä¼°è®¡å™¨(reinforcement-learning-based probability estimator)ï¼Œä»¥ç²¾ç¡®è¿‡æ»¤å¹¶é‡‡æ ·æœ€ç›¸å…³çš„å…¨å±€äº¤äº’æ•°æ®ã€‚å®éªŒç»“æœè¡¨æ˜ï¼ŒFedGDVEåœ¨æƒå¨åŸºå‡†æµ‹è¯•ä¸­å°†æ¨èæ€§èƒ½æå‡äº†é«˜è¾¾34.86%ã€‚è¯¥ç ”ç©¶ä¸ºå¤§å‹è´­ç‰©å¹³å°ä¸å¤šä¸ªå°å‹åœ¨çº¿å•†åº—åä½œæ„å»ºé«˜æ•ˆã€ä¸ªæ€§åŒ–çš„è”é‚¦æ¨èç³»ç»Ÿæä¾›äº†å¯è¡Œçš„æŠ€æœ¯æ–¹æ¡ˆã€‚",
      "categories": [
        "cs.LG",
        "cs.AI"
      ],
      "primary_category": "cs.LG",
      "comment": "Accepted to Expert Systems with Applications Journal, Elsevier",
      "pdf_url": "https://arxiv.org/pdf/2509.11196v1",
      "published_date": "2025-09-14 09:48:23 UTC",
      "updated_date": "2025-09-14 09:48:23 UTC",
      "processing_status": "completed",
      "attempts": 1,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "llm_backup_calls": 0,
      "last_update": "2026-01-24T18:26:48.404181+00:00"
    },
    {
      "arxiv_id": "2509.11190v1",
      "title": "Investigating the Lottery Ticket Hypothesis for Variational Quantum Circuits",
      "title_zh": "æ¢ç©¶å˜åˆ†é‡å­ç”µè·¯ä¸­çš„å½©ç¥¨å‡è®¾",
      "authors": [
        "Michael KÃ¶lle",
        "Leonhard Klingert",
        "Julian SchÃ¶nberger",
        "Philipp Altmann",
        "Tobias Rohe",
        "Claudia Linnhoff-Popien"
      ],
      "abstract": "Quantum computing is an emerging field in computer science that has seen considerable progress in recent years, especially in machine learning. By harnessing the principles of quantum physics, it can surpass the limitations of classical algorithms. However, variational quantum circuits (VQCs), which rely on adjustable parameters, often face the barren plateau phenomenon, hindering optimization. The Lottery Ticket Hypothesis (LTH) is a recent concept in classical machine learning that has led to notable improvements in parameter efficiency for neural networks. It states that within a large network, a smaller, more efficient subnetwork, or ''winning ticket,'' can achieve comparable performance, potentially circumventing plateau challenges. In this work, we investigate whether this idea can apply to VQCs. We show that the weak LTH holds for VQCs, revealing winning tickets that retain just 26.0\\% of the original parameters. For the strong LTH, where a pruning mask is learned without any training, we discovered a winning ticket in a binary VQC, achieving 100\\% accuracy with only 45\\% of the weights. These findings indicate that LTH may mitigate barren plateaus by reducing parameter counts while preserving performance, thus enhancing the efficiency of VQCs in quantum machine learning tasks.",
      "tldr_zh": "è¯¥ç ”ç©¶æ¢è®¨äº†å˜åˆ†é‡å­ç”µè·¯ (VQCs) åœ¨é‡å­æœºå™¨å­¦ä¹ ä¸­é¢ä¸´çš„è´«ç˜ é«˜åŸ (barren plateau) ä¼˜åŒ–éš¾é¢˜ï¼Œå¹¶è°ƒæŸ¥äº†å¤§ä¹é€å‡è®¾ (Lottery Ticket Hypothesis, LTH) åœ¨è¯¥é¢†åŸŸçš„é€‚ç”¨æ€§ã€‚é€šè¿‡å®éªŒéªŒè¯ï¼Œç ”ç©¶è¯æ˜äº†å¼±å¤§ä¹é€å‡è®¾ (weak LTH) åœ¨ VQCs ä¸­æˆç«‹ï¼Œå‘ç°ä»…ä¿ç•™ 26.0% åŸå§‹å‚æ•°çš„â€œä¸­å¥–ç¥¨â€ (winning tickets) ä»èƒ½ä¿æŒç›¸å½“çš„æ€§èƒ½ã€‚é’ˆå¯¹å¼ºå¤§ä¹é€å‡è®¾ (strong LTH)ï¼Œç ”ç©¶åœ¨äºŒå…ƒ VQC ä¸­è¯†åˆ«å‡ºäº†ä»…å« 45% æƒé‡ä¸”è¾¾åˆ° 100% å‡†ç¡®ç‡çš„å­ç½‘ç»œã€‚è¿™äº›ç»“æœè¡¨æ˜ï¼Œåˆ©ç”¨ LTH èƒ½å¤Ÿé€šè¿‡å¤§å¹…å‡å°‘å‚æ•°æ•°é‡æ¥ç¼“è§£è´«ç˜ é«˜åŸ (barren plateaus) ç°è±¡ï¼Œä»è€Œå¢å¼ºå˜åˆ†é‡å­ç”µè·¯åœ¨å¤„ç†é‡å­æœºå™¨å­¦ä¹ ä»»åŠ¡æ—¶çš„è®¡ç®—æ•ˆç‡ä¸ä¼˜åŒ–ç¨³å®šæ€§ã€‚",
      "categories": [
        "quant-ph",
        "cs.AI",
        "cs.LG"
      ],
      "primary_category": "quant-ph",
      "comment": "",
      "pdf_url": "https://arxiv.org/pdf/2509.11190v1",
      "published_date": "2025-09-14 09:39:32 UTC",
      "updated_date": "2025-09-14 09:39:32 UTC",
      "processing_status": "completed",
      "attempts": 1,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "llm_backup_calls": 0,
      "last_update": "2026-01-24T18:26:47.496168+00:00"
    },
    {
      "arxiv_id": "2509.11178v2",
      "title": "StegOT: Trade-offs in Steganography via Optimal Transport",
      "title_zh": "StegOTï¼šåŸºäºæœ€ä¼˜ä¼ è¾“çš„éšå†™æœ¯æƒè¡¡",
      "authors": [
        "Chengde Lin",
        "Xuezhu Gong",
        "Shuxue Ding",
        "Mingzhe Yang",
        "Xijun Lu",
        "Chengjun Mo"
      ],
      "abstract": "Image hiding is often referred to as steganography, which aims to hide a secret image in a cover image of the same resolution. Many steganography models are based on genera-tive adversarial networks (GANs) and variational autoencoders (VAEs). However, most existing models suffer from mode collapse. Mode collapse will lead to an information imbalance between the cover and secret images in the stego image and further affect the subsequent extraction. To address these challenges, this paper proposes StegOT, an autoencoder-based steganography model incorporating optimal transport theory. We designed the multiple channel optimal transport (MCOT) module to transform the feature distribution, which exhibits multiple peaks, into a single peak to achieve the trade-off of information. Experiments demonstrate that we not only achieve a trade-off between the cover and secret images but also enhance the quality of both the stego and recovery images. The source code will be released on https://github.com/Rss1124/StegOT.",
      "tldr_zh": "è¯¥ç ”ç©¶æ¢è®¨äº†å›¾åƒéšè—(Steganography)æŠ€æœ¯ï¼Œæ—¨åœ¨å°†ç§˜å¯†å›¾åƒéšè—åœ¨åŒåˆ†è¾¨ç‡çš„è½½ä½“å›¾åƒä¸­ã€‚é’ˆå¯¹ç›®å‰åŸºäºç”Ÿæˆå¯¹æŠ—ç½‘ç»œ(GANs)å’Œå˜åˆ†è‡ªç¼–ç å™¨(VAEs)çš„æ¨¡å‹å¸¸é¢ä¸´æ¨¡å¼å´©æºƒ(Mode Collapse)å¯¼è‡´çš„ä¿¡æ¯å¤±è¡¡é—®é¢˜ï¼Œä½œè€…æå‡ºäº†StegOTï¼Œä¸€ç§ç»“åˆæœ€ä¼˜ä¼ è¾“(Optimal Transport)ç†è®ºçš„è‡ªç¼–ç å™¨æ¨¡å‹ã€‚è¯¥æ¨¡å‹æ ¸å¿ƒåœ¨äºè®¾è®¡äº†å¤šé€šé“æœ€ä¼˜ä¼ è¾“(MCOT)æ¨¡å—ï¼Œé€šè¿‡å°†å¤šå³°ç‰¹å¾åˆ†å¸ƒè½¬æ¢ä¸ºå•å³°åˆ†å¸ƒï¼Œå®ç°äº†è½½ä½“ä¸ç§˜å¯†ä¿¡æ¯ä¹‹é—´çš„æœ‰æ•ˆæƒè¡¡(Trade-off)ã€‚å®éªŒç»“æœè¯æ˜ï¼ŒStegOTä¸ä»…åœ¨å¹³è¡¡ä¿¡æ¯åˆ†å¸ƒä¸Šè¡¨ç°ä¼˜å¼‚ï¼Œè¿˜æ˜¾è‘—æå‡äº†éšå†™å›¾åƒ(Stego Image)ä¸æ¢å¤å›¾åƒçš„è§†è§‰è´¨é‡ã€‚è¯¥ç ”ç©¶ä¸ºæé«˜éšå†™æŠ€æœ¯çš„é²æ£’æ€§å’Œå›¾åƒä¿çœŸåº¦æä¾›äº†æ–°çš„è§£å†³æ–¹æ¡ˆã€‚",
      "categories": [
        "cs.CV",
        "cs.AI"
      ],
      "primary_category": "cs.CV",
      "comment": "Accepted by IEEE International Conference on Multimedia and Expo (ICME 2025)",
      "pdf_url": "https://arxiv.org/pdf/2509.11178v2",
      "published_date": "2025-09-14 09:18:18 UTC",
      "updated_date": "2025-10-14 12:16:42 UTC",
      "processing_status": "completed",
      "attempts": 1,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "llm_backup_calls": 0,
      "last_update": "2026-01-24T18:26:52.766099+00:00"
    },
    {
      "arxiv_id": "2509.11176v1",
      "title": "Differentially-private text generation degrades output language quality",
      "title_zh": "å·®åˆ†éšç§æ–‡æœ¬ç”Ÿæˆå¯¼è‡´è¾“å‡ºè¯­è¨€è´¨é‡ä¸‹é™",
      "authors": [
        "Erion Ã‡ano",
        "Ivan Habernal"
      ],
      "abstract": "Ensuring user privacy by synthesizing data from large language models (LLMs) tuned under differential privacy (DP) has become popular recently. However, the impact of DP fine-tuned LLMs on the quality of the language and the utility of the texts they produce has not been investigated. In this work, we tune five LLMs with three corpora under four levels of privacy and assess the length, the grammatical correctness, and the lexical diversity of the text outputs they produce. We also probe the utility of the synthetic outputs in downstream classification tasks such as book genre recognition based on book descriptions and cause of death recognition based on verbal autopsies. The results indicate that LLMs tuned under stronger privacy constrains produce texts that are shorter by at least 77 %, that are less grammatically correct by at least 9 %, and are less diverse by at least 10 % in bi-gram diversity. Furthermore, the accuracy they reach in downstream classification tasks decreases, which might be detrimental to the usefulness of the generated synthetic data.",
      "tldr_zh": "è¯¥ç ”ç©¶ç³»ç»Ÿåœ°è°ƒæŸ¥äº†ç»è¿‡å·®åˆ†éšç§ (Differential Privacy, DP) å¾®è°ƒçš„å¤§è¯­è¨€æ¨¡å‹ (LLMs) å¯¹ç”Ÿæˆæ–‡æœ¬è¯­è¨€è´¨é‡åŠå…¶ä¸‹æ¸¸å®ç”¨æ€§çš„å½±å“ã€‚ç ”ç©¶è€…åœ¨å››ç§ä¸åŒéšç§æ°´å¹³ä¸‹å¾®è°ƒäº†äº”ä¸ª LLMsï¼Œå¹¶ä»é•¿åº¦ã€è¯­æ³•æ­£ç¡®æ€§å’Œè¯æ±‡å¤šæ ·æ€§ï¼ˆå¦‚ bi-gram diversityï¼‰ç­‰ç»´åº¦å¯¹è¾“å‡ºè¿›è¡Œäº†è¯„ä¼°ï¼ŒåŒæ—¶è€ƒå¯Ÿäº†åˆæˆæ•°æ®åœ¨ä¹¦ç±æµæ´¾è¯†åˆ«ç­‰ä¸‹æ¸¸åˆ†ç±»ä»»åŠ¡ä¸­çš„è¡¨ç°ã€‚ç»“æœè¡¨æ˜ï¼Œè¾ƒå¼ºçš„éšç§çº¦æŸä¼šå¯¼è‡´ç”Ÿæˆçš„æ–‡æœ¬é•¿åº¦ç¼©å‡è‡³å°‘ 77%ï¼Œè¯­æ³•æ­£ç¡®æ€§ä¸‹é™è‡³å°‘ 9%ï¼Œä¸” bi-gram å¤šæ ·æ€§é™ä½è‡³å°‘ 10%ã€‚æ­¤å¤–ï¼Œç”±äºè¯­è¨€è´¨é‡çš„é€€åŒ–ï¼Œæ¨¡å‹åœ¨ä¸‹æ¸¸åˆ†ç±»ä»»åŠ¡ä¸­çš„å‡†ç¡®ç‡ä¹Ÿéšä¹‹é™ä½ï¼Œè¿™å¯èƒ½å¯¹åˆæˆæ•°æ®çš„å®é™…åº”ç”¨ä»·å€¼äº§ç”Ÿä¸åˆ©å½±å“ã€‚è¯¥é¡¹å·¥ä½œæ­ç¤ºäº†å·®åˆ†éšç§ä¿æŠ¤ä¸ç”Ÿæˆæ–‡æœ¬è´¨é‡ä¹‹é—´å­˜åœ¨çš„æ˜¾è‘—æƒè¡¡å…³ç³»ã€‚",
      "categories": [
        "cs.CL",
        "cs.AI"
      ],
      "primary_category": "cs.CL",
      "comment": "20 pages, 3 figures, 35 tables",
      "pdf_url": "https://arxiv.org/pdf/2509.11176v1",
      "published_date": "2025-09-14 09:16:11 UTC",
      "updated_date": "2025-09-14 09:16:11 UTC",
      "processing_status": "completed",
      "attempts": 1,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "llm_backup_calls": 0,
      "last_update": "2026-01-24T18:26:52.966136+00:00"
    },
    {
      "arxiv_id": "2509.11173v3",
      "title": "Your Compiler is Backdooring Your Model: Understanding and Exploiting Compilation Inconsistency Vulnerabilities in Deep Learning Compilers",
      "title_zh": "ç¼–è¯‘å™¨æ­£ä¸ºä½ çš„æ¨¡å‹æ¤å…¥åé—¨ï¼šæ·±åº¦å­¦ä¹ ç¼–è¯‘å™¨ç¼–è¯‘ä¸ä¸€è‡´æ€§æ¼æ´çš„ç†è§£ä¸åˆ©ç”¨",
      "authors": [
        "Simin Chen",
        "Jinjun Peng",
        "Yixin He",
        "Junfeng Yang",
        "Baishakhi Ray"
      ],
      "abstract": "Deep learning (DL) compilers are core infrastructure in modern DL systems, offering flexibility and scalability beyond vendor-specific libraries. This work uncovers a fundamental vulnerability in their design: can an official, unmodified compiler alter a model's semantics during compilation and introduce hidden backdoors? We study both adversarial and natural settings. In the adversarial case, we craft benign models where triggers have no effect pre-compilation but become effective backdoors after compilation. Tested on six models, three commercial compilers, and two hardware platforms, our attack yields 100% success on triggered inputs while preserving normal accuracy and remaining undetected by state-of-the-art detectors. The attack generalizes across compilers, hardware, and floating-point settings. In the natural setting, we analyze the top 100 HuggingFace models (including one with 220M+ downloads) and find natural triggers in 31 models. This shows that compilers can introduce risks even without adversarial manipulation.\n  Our results reveal an overlooked threat: unmodified DL compilers can silently alter model semantics. To our knowledge, this is the first work to expose inherent security risks in DL compiler design, opening a new direction for secure and trustworthy ML.",
      "tldr_zh": "è¯¥ç ”ç©¶æ­ç¤ºäº†æ·±åº¦å­¦ä¹ ç¼–è¯‘å™¨(Deep Learning Compilers)è®¾è®¡ä¸­çš„ä¸€ç§æ ¹æœ¬æ€§æ¼æ´ï¼Œå³å®˜æ–¹ã€æœªä¿®æ”¹çš„ç¼–è¯‘å™¨å¯èƒ½åœ¨ç¼–è¯‘è¿‡ç¨‹ä¸­æ”¹å˜æ¨¡å‹è¯­ä¹‰å¹¶å¼•å…¥éšè—åé—¨ã€‚ç ”ç©¶è€…æ¢è®¨äº†å¯¹æŠ—æ€§å’Œè‡ªç„¶ä¸¤ç§åœºæ™¯ï¼Œåœ¨å¯¹æŠ—æ€§è®¾ç½®ä¸­é€šè¿‡æ„å»ºç‰¹å®šçš„è‰¯æ€§æ¨¡å‹ï¼Œä½¿è§¦å‘å™¨(triggers)ä»…åœ¨ç¼–è¯‘åç”Ÿæ•ˆã€‚å®éªŒåœ¨å…­ä¸ªæ¨¡å‹ã€ä¸‰ä¸ªå•†ä¸šç¼–è¯‘å™¨å’Œä¸¤ä¸ªç¡¬ä»¶å¹³å°ä¸Šè¾¾åˆ°äº†100%çš„æ”»å‡»æˆåŠŸç‡ï¼Œä¸”æ¨¡å‹ç²¾åº¦ä¸å—å½±å“å¹¶èƒ½è§„é¿å°–ç«¯æ£€æµ‹å™¨ã€‚åœ¨è‡ªç„¶åœºæ™¯ä¸‹ï¼Œé€šè¿‡å¯¹HuggingFaceæ’åå‰100çš„æ¨¡å‹åˆ†æå‘ç°ï¼Œå…¶ä¸­31ä¸ªæ¨¡å‹å­˜åœ¨å¤©ç„¶è§¦å‘å™¨ï¼Œè¯æ˜äº†ç¼–è¯‘å™¨åœ¨æ— å¯¹æŠ—æ“çºµæ—¶ä»å¯èƒ½å¼•å…¥é£é™©ã€‚è¯¥å·¥ä½œé¦–æ¬¡æ›å…‰äº†æ·±åº¦å­¦ä¹ ç¼–è¯‘å™¨è®¾è®¡ä¸­çš„ç¼–è¯‘ä¸€è‡´æ€§æ¼æ´(Compilation Inconsistency Vulnerabilities)ï¼Œä¸ºæ„å»ºå®‰å…¨å¯é çš„æœºå™¨å­¦ä¹ ç³»ç»Ÿæä¾›äº†é‡è¦çš„æ–°è§†ç‚¹ã€‚",
      "categories": [
        "cs.CR",
        "cs.AI",
        "cs.LG",
        "cs.SE"
      ],
      "primary_category": "cs.CR",
      "comment": "This paper is accepted to IEEE S&P 2026, the code is available at https://github.com/SeekingDream/DLCompilerAttack",
      "pdf_url": "https://arxiv.org/pdf/2509.11173v3",
      "published_date": "2025-09-14 09:11:49 UTC",
      "updated_date": "2025-10-27 03:04:50 UTC",
      "processing_status": "completed",
      "attempts": 1,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "llm_backup_calls": 0,
      "last_update": "2026-01-24T18:28:04.992723+00:00"
    },
    {
      "arxiv_id": "2509.11168v1",
      "title": "An Entropy-Guided Curriculum Learning Strategy for Data-Efficient Acoustic Scene Classification under Domain Shift",
      "title_zh": "é’ˆå¯¹åŸŸåç§»ä¸‹æ•°æ®é«˜æ•ˆå£°å­¦åœºæ™¯åˆ†ç±»çš„ç†µå¼•å¯¼è¯¾ç¨‹å­¦ä¹ ç­–ç•¥",
      "authors": [
        "Peihong Zhang",
        "Yuxuan Liu",
        "Zhixin Li",
        "Rui Sang",
        "Yiqiang Cai",
        "Yizhou Tan",
        "Shengchen Li"
      ],
      "abstract": "Acoustic Scene Classification (ASC) faces challenges in generalizing across recording devices, particularly when labeled data is limited. The DCASE 2024 Challenge Task 1 highlights this issue by requiring models to learn from small labeled subsets recorded on a few devices. These models need to then generalize to recordings from previously unseen devices under strict complexity constraints. While techniques such as data augmentation and the use of pre-trained models are well-established for improving model generalization, optimizing the training strategy represents a complementary yet less-explored path that introduces no additional architectural complexity or inference overhead. Among various training strategies, curriculum learning offers a promising paradigm by structuring the learning process from easier to harder examples. In this work, we propose an entropy-guided curriculum learning strategy to address the domain shift problem in data-efficient ASC. Specifically, we quantify the uncertainty of device domain predictions for each training sample by computing the Shannon entropy of the device posterior probabilities estimated by an auxiliary domain classifier. Using entropy as a proxy for domain invariance, the curriculum begins with high-entropy samples and gradually incorporates low-entropy, domain-specific ones to facilitate the learning of generalizable representations. Experimental results on multiple DCASE 2024 ASC baselines demonstrate that our strategy effectively mitigates domain shift, particularly under limited labeled data conditions. Our strategy is architecture-agnostic and introduces no additional inference cost, making it easily integrable into existing ASC baselines and offering a practical solution to domain shift.",
      "tldr_zh": "æœ¬ç ”ç©¶é’ˆå¯¹å£°å­¦åœºæ™¯åˆ†ç±»(Acoustic Scene Classification, ASC)åœ¨æœ‰é™æ ‡æ³¨æ•°æ®ä¸‹è·¨è®¾å¤‡åŸŸåç§»(Domain Shift)çš„æ³›åŒ–éš¾é¢˜ï¼Œæå‡ºäº†ä¸€ç§åŸºäºç†µå¼•å¯¼çš„è¯¾ç¨‹å­¦ä¹ (Curriculum Learning)ç­–ç•¥ã€‚è¯¥æ–¹æ³•åˆ©ç”¨è¾…åŠ©é¢†åŸŸåˆ†ç±»å™¨è®¡ç®—è®¾å¤‡åéªŒæ¦‚ç‡çš„é¦™å†œç†µ(Shannon Entropy)ï¼Œå¹¶ä»¥æ­¤ä½œä¸ºé¢†åŸŸä¸å˜æ€§çš„åº¦é‡æ¥é‡åŒ–è®­ç»ƒæ ·æœ¬çš„ä¸ç¡®å®šæ€§ã€‚è®­ç»ƒè¿‡ç¨‹éµå¾ªä»æ˜“åˆ°éš¾çš„é€»è¾‘ï¼Œä¼˜å…ˆå­¦ä¹ é«˜ç†µçš„é¢†åŸŸæ— å…³æ ·æœ¬ï¼Œéšåé€æ­¥å¼•å…¥ä½ç†µçš„é¢†åŸŸç‰¹å®šæ ·æœ¬ï¼Œä»¥ä¿ƒè¿›æ¨¡å‹æå–æ›´å…·æ³›åŒ–æ€§çš„ç‰¹å¾è¡¨ç¤ºã€‚åœ¨DCASE 2024 ASCåŸºå‡†ä»»åŠ¡ä¸Šçš„å®éªŒç»“æœè¡¨æ˜ï¼Œè¯¥ç­–ç•¥èƒ½æ˜¾è‘—ç¼“è§£åŸŸåç§»å¸¦æ¥çš„è´Ÿé¢å½±å“ï¼Œç‰¹åˆ«æ˜¯åœ¨æ ‡æ³¨æ•°æ®ç¨€ç¼ºçš„æƒ…å†µä¸‹æå‡æ˜æ˜¾ã€‚ç”±äºè¯¥ç­–ç•¥ä¸æ¨¡å‹æ¶æ„æ— å…³ä¸”ä¸å¢åŠ é¢å¤–çš„æ¨ç†è´Ÿæ‹…ï¼Œå®ƒä¸ºå®ç°æ•°æ®é«˜æ•ˆä¸”é²æ£’çš„å£°å­¦ç¯å¢ƒæ„ŸçŸ¥æä¾›äº†ä¸€ç§å®ç”¨çš„ä¼˜åŒ–è·¯å¾„ã€‚",
      "categories": [
        "cs.SD",
        "cs.AI"
      ],
      "primary_category": "cs.SD",
      "comment": "Accepted at the Detection and Classification of Acoustic Scenes and Events (DCASE) Workshop 2025",
      "pdf_url": "https://arxiv.org/pdf/2509.11168v1",
      "published_date": "2025-09-14 09:01:52 UTC",
      "updated_date": "2025-09-14 09:01:52 UTC",
      "processing_status": "completed",
      "attempts": 1,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "llm_backup_calls": 0,
      "last_update": "2026-01-24T18:27:10.497748+00:00"
    },
    {
      "arxiv_id": "2509.11167v1",
      "title": "Harnessing Optimization Dynamics for Curvature-Informed Model Merging",
      "title_zh": "åˆ©ç”¨ä¼˜åŒ–åŠ¨åŠ›å­¦å®ç°æ›²ç‡æ„ŸçŸ¥çš„æ¨¡å‹åˆå¹¶",
      "authors": [
        "Pouria Mahdavinia",
        "Hamed Mahdavi",
        "Niloofar Mireshghallah",
        "Mehrdad Mahdavi"
      ],
      "abstract": "Model merging is an effective post-training strategy for composing capabilities in large language models without joint retraining. We study this in the supervised fine-tuning (SFT) stage, where multiple capability-based SFT checkpoints -- spanning math, code, precise instruction following, general instruction following, and knowledge recall -- must be consolidated into a single model. We introduce Optimization Trajectory Aware (OTA) Merging, a curvature-aware aggregation that leverages optimizer second-moment statistics as a diagonal curvature proxy to reweight parameter edits and mitigate interference. Complementing OTA, we propose Fast Fisher Grafting (FFG), a curvature-driven task-localization step that sparsifies conflicting or low-importance edits. FFG induces extremely low-rank masks concentrated in early attention query/key projections and token embeddings, exploiting shared curvature across capabilities. We further develop a memory-light compression of the second moments that preserves OTA's effect. Across diverse capability-based SFT checkpoints, OTA+FFG improves merged-model quality over strong weight-space baselines, reduces negative transfer, and remains robust across sparsity levels. Analyses reveal substantial curvature overlap between checkpoints, offering a novel lens on why simple linear merging can be effective in practice. Ablations confirm that FFG is critical for reducing task interference and that the compressed second moments retain the gains of the full formulation. To facilitate reproducibility, we open-source all code, training and evaluation scripts, visualization artifacts, and capability-specific SFT checkpoints at https://github.com/pmahdavi/ota-merge.",
      "tldr_zh": "è¯¥ç ”ç©¶é’ˆå¯¹å¤§è§„æ¨¡è¯­è¨€æ¨¡å‹åœ¨ç›‘ç£å¾®è°ƒ(SFT)é˜¶æ®µçš„å¤šèƒ½åŠ›æ•´åˆé—®é¢˜ï¼Œæå‡ºäº†ä¼˜åŒ–è½¨è¿¹æ„ŸçŸ¥(Optimization Trajectory Aware, OTA)åˆå¹¶æ–¹æ³•ã€‚OTA Mergingé€šè¿‡åˆ©ç”¨ä¼˜åŒ–å™¨çš„äºŒé˜¶çŸ©ç»Ÿè®¡é‡(second-moment statistics)ä½œä¸ºå¯¹è§’æ›²ç‡ä»£ç†ï¼Œå¯¹å‚æ•°ç¼–è¾‘è¿›è¡Œé‡æ–°åŠ æƒä»¥å‡è½»ä»»åŠ¡å¹²æ‰°ã€‚ä¸ºäº†è¿›ä¸€æ­¥ä¼˜åŒ–åˆå¹¶æ•ˆæœï¼Œç ”ç©¶å¼•å…¥äº†Fast Fisher Grafting (FFG)æŠ€æœ¯ï¼Œé€šè¿‡æ›²ç‡é©±åŠ¨çš„ä»»åŠ¡å®šä½æ­¥éª¤ç¨€ç–åŒ–å†²çªæˆ–ä½é‡è¦æ€§çš„ç¼–è¾‘ï¼Œå¹¶åœ¨æ—©æœŸæ³¨æ„åŠ›å±‚å’ŒåµŒå…¥å±‚ä¸­å½¢æˆæä½ç§©æ©ç ã€‚å®éªŒç»“æœè¡¨æ˜ï¼ŒOTA+FFGåœ¨å¤šç§èƒ½åŠ›æ£€æŸ¥ç‚¹ä¸Šçš„åˆå¹¶è¡¨ç°ä¼˜äºä¼ ç»Ÿçš„æƒå€¼ç©ºé—´(weight-space)åŸºå‡†ï¼Œæ˜¾è‘—å‡å°‘äº†è´Ÿè¿ç§»(negative transfer)å¹¶ä¿æŒäº†å¯¹ç¨€ç–æ°´å¹³çš„é²æ£’æ€§ã€‚è¯¥ç ”ç©¶è¿˜å‘ç°ä¸åŒèƒ½åŠ›çš„æ£€æŸ¥ç‚¹ä¹‹é—´å­˜åœ¨æ˜¾è‘—çš„æ›²ç‡é‡å ï¼Œæ­ç¤ºäº†ç®€å•çº¿æ€§åˆå¹¶åœ¨å®è·µä¸­æœ‰æ•ˆçš„å†…åœ¨æœºåˆ¶ã€‚ç›®å‰è¯¥ç ”ç©¶å·²å¼€æºç›¸å…³ä»£ç ã€è®­ç»ƒè„šæœ¬åŠSFTæ£€æŸ¥ç‚¹ï¼Œä¸ºæ¨¡å‹åˆå¹¶é¢†åŸŸæä¾›äº†é«˜æ•ˆä¸”å†…å­˜å‹å¥½çš„æ–°æ–¹æ¡ˆã€‚",
      "categories": [
        "cs.LG",
        "cs.AI"
      ],
      "primary_category": "cs.LG",
      "comment": "",
      "pdf_url": "https://arxiv.org/pdf/2509.11167v1",
      "published_date": "2025-09-14 08:59:53 UTC",
      "updated_date": "2025-09-14 08:59:53 UTC",
      "processing_status": "completed",
      "attempts": 1,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "llm_backup_calls": 0,
      "last_update": "2026-01-24T18:27:18.986651+00:00"
    },
    {
      "arxiv_id": "2509.13352v2",
      "title": "Agentic UAVs: LLM-Driven Autonomy with Integrated Tool-Calling and Cognitive Reasoning",
      "title_zh": "Agentic UAVsï¼šé›†æˆå·¥å…·è°ƒç”¨ä¸è®¤çŸ¥æ¨ç†çš„å¤§è¯­è¨€æ¨¡å‹é©±åŠ¨è‡ªä¸»ç³»ç»Ÿ",
      "authors": [
        "Anis Koubaa",
        "Khaled Gabr"
      ],
      "abstract": "Unmanned Aerial Vehicles (UAVs) are increasingly used in defense, surveillance, and disaster response, yet most systems still operate at SAE Level 2 to 3 autonomy. Their dependence on rule-based control and narrow AI limits adaptability in dynamic and uncertain missions. Current UAV architectures lack context-aware reasoning, autonomous decision-making, and integration with external systems. Importantly, none make use of Large Language Model (LLM) agents with tool-calling for real-time knowledge access.\n  This paper introduces the Agentic UAVs framework, a five-layer architecture consisting of Perception, Reasoning, Action, Integration, and Learning. The framework enhances UAV autonomy through LLM-driven reasoning, database querying, and interaction with third-party systems.\n  A prototype built with ROS 2 and Gazebo combines YOLOv11 for object detection with GPT-4 for reasoning and a locally deployed Gemma 3 model. In simulated search-and-rescue scenarios, agentic UAVs achieved higher detection confidence (0.79 compared to 0.72), improved person detection rates (91% compared to 75%), and a major increase in correct action recommendations (92% compared to 4.5%). These results show that modest computational overhead can enable significantly higher levels of autonomy and system-level integration.",
      "tldr_zh": "è¯¥ç ”ç©¶é’ˆå¯¹å½“å‰æ— äººæœº(UAVs)ç³»ç»Ÿåœ¨åŠ¨æ€ä»»åŠ¡ä¸­ç¼ºä¹ä¸Šä¸‹æ–‡æ¨ç†å’Œè‡ªä¸»å†³ç­–èƒ½åŠ›çš„é—®é¢˜ï¼Œæå‡ºäº†Agentic UAVsæ¡†æ¶ã€‚è¯¥æ¡†æ¶é‡‡ç”¨äº†åŒ…å«æ„ŸçŸ¥(Perception)ã€æ¨ç†(Reasoning)ã€åŠ¨ä½œ(Action)ã€é›†æˆ(Integration)å’Œå­¦ä¹ (Learning)çš„äº”å±‚æ¶æ„ï¼Œé€šè¿‡å¤§è¯­è¨€æ¨¡å‹(LLM)é©±åŠ¨çš„æ¨ç†å’Œå·¥å…·è°ƒç”¨(Tool-calling)å®ç°äº†å®æ—¶çš„çŸ¥è¯†è·å–ã€‚ç ”ç©¶å›¢é˜Ÿåˆ©ç”¨ROS 2å’ŒGazeboæ„å»ºäº†ç»“åˆYOLOv11ä¸GPT-4åŠGemma 3æ¨¡å‹çš„åŸå‹ç³»ç»Ÿã€‚å®éªŒç»“æœè¡¨æ˜ï¼Œåœ¨æ¨¡æ‹Ÿæœæ•‘ä»»åŠ¡ä¸­ï¼ŒAgentic UAVsçš„æ£€æµ‹ç½®ä¿¡åº¦æå‡è‡³0.79ï¼Œäººå‘˜æ£€æµ‹ç‡è¾¾åˆ°91%ï¼Œä¸”æ­£ç¡®è¡ŒåŠ¨å»ºè®®çš„å‡†ç¡®ç‡ä»4.5%æ˜¾è‘—æå‡è‡³92%ã€‚è¿™ä¸€æˆæœè¯æ˜äº†é€šè¿‡é€‚åº¦çš„è®¡ç®—å¼€é”€ï¼Œå¯ä»¥èµ‹äºˆæ— äººæœºæ›´é«˜æ°´å¹³çš„è‡ªä¸»æ€§å’Œç³»ç»Ÿé›†æˆèƒ½åŠ›ã€‚",
      "categories": [
        "cs.AI",
        "cs.RO"
      ],
      "primary_category": "cs.AI",
      "comment": "17 pages, 2 figure",
      "pdf_url": "https://arxiv.org/pdf/2509.13352v2",
      "published_date": "2025-09-14 08:46:40 UTC",
      "updated_date": "2025-12-02 10:36:20 UTC",
      "processing_status": "completed",
      "attempts": 1,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "llm_backup_calls": 0,
      "last_update": "2026-01-24T18:28:11.952736+00:00"
    },
    {
      "arxiv_id": "2509.12279v1",
      "title": "Domain Adaptive SAR Wake Detection: Leveraging Similarity Filtering and Memory Guidance",
      "title_zh": "é¢†åŸŸè‡ªé€‚åº” SAR èˆªè¿¹æ£€æµ‹ï¼šç»“åˆç›¸ä¼¼æ€§è¿‡æ»¤ä¸è®°å¿†å¼•å¯¼",
      "authors": [
        "He Gao",
        "Baoxiang Huang",
        "Milena Radenkovic",
        "Borui Li",
        "Ge Chen"
      ],
      "abstract": "Synthetic Aperture Radar (SAR), with its all- weather and wide-area observation capabilities, serves as a crucial tool for wake detection. However, due to its complex imaging mechanism, wake features in SAR images often appear abstract and noisy, posing challenges for accurate annotation. In contrast, optical images provide more distinct visual cues, but models trained on optical data suffer from performance degradation when applied to SAR images due to domain shift. To address this cross-modal domain adaptation challenge, we propose a Similarity-Guided and Memory-Guided Domain Adap- tation (termed SimMemDA) framework for unsupervised domain adaptive ship wake detection via instance-level feature similarity filtering and feature memory guidance. Specifically, to alleviate the visual discrepancy between optical and SAR images, we first utilize WakeGAN to perform style transfer on optical images, generating pseudo-images close to the SAR style. Then, instance-level feature similarity filtering mechanism is designed to identify and prioritize source samples with target-like dis- tributions, minimizing negative transfer. Meanwhile, a Feature- Confidence Memory Bank combined with a K-nearest neighbor confidence-weighted fusion strategy is introduced to dynamically calibrate pseudo-labels in the target domain, improving the reliability and stability of pseudo-labels. Finally, the framework further enhances generalization through region-mixed training, strategically combining source annotations with calibrated tar- get pseudo-labels. Experimental results demonstrate that the proposed SimMemDA method can improve the accuracy and robustness of cross-modal ship wake detection tasks, validating the effectiveness and feasibility of the proposed method.",
      "tldr_zh": "è¯¥ç ”ç©¶é’ˆå¯¹åˆæˆå­”å¾„é›·è¾¾(SAR)å›¾åƒä¸­å°¾è¿¹ç‰¹å¾æŠ½è±¡ä¸”æ ‡æ³¨å›°éš¾çš„é—®é¢˜ï¼Œæå‡ºäº†ä¸€ç§åä¸ºSimMemDAçš„ç›¸ä¼¼æ€§ä¸è®°å¿†å¼•å¯¼é¢†åŸŸè‡ªé€‚åº”æ¡†æ¶ï¼Œæ—¨åœ¨è§£å†³ä»å…‰å­¦åˆ°SARå›¾åƒçš„è·¨æ¨¡æ€è¿ç§»æŒ‘æˆ˜ã€‚ç ”ç©¶é¦–å…ˆé€šè¿‡WakeGANå¯¹å…‰å­¦å›¾åƒè¿›è¡Œé£æ ¼è¿ç§»ä»¥ç¼©å°æ¨¡æ€é—´è§†è§‰å·®å¼‚ï¼Œå¹¶è®¾è®¡äº†å®ä¾‹çº§ç‰¹å¾ç›¸ä¼¼æ€§è¿‡æ»¤æœºåˆ¶ï¼Œä¼˜å…ˆæå–ä¸ç›®æ ‡åŸŸåˆ†å¸ƒç›¸ä¼¼çš„æºæ ·æœ¬ä»¥å‡å°‘è´Ÿè¿ç§»ã€‚åŒæ—¶ï¼Œè¯¥æ¡†æ¶å¼•å…¥äº†ç‰¹å¾ç½®ä¿¡åº¦å­˜å‚¨åº“(Feature-Confidence Memory Bank)ä¸Kæœ€è¿‘é‚»(K-nearest neighbor)ç½®ä¿¡åŠ æƒèåˆç­–ç•¥ï¼Œå®ç°äº†å¯¹ç›®æ ‡åŸŸä¼ªæ ‡ç­¾çš„åŠ¨æ€æ ¡å‡†ï¼Œæ˜¾è‘—å¢å¼ºäº†æ ‡ç­¾çš„å¯é æ€§ã€‚æœ€åï¼Œé€šè¿‡åŒºåŸŸæ··åˆè®­ç»ƒ(Region-mixed training)ç­–ç•¥ç»“åˆæºåŸŸæ ‡æ³¨ä¸æ ¡å‡†åçš„ä¼ªæ ‡ç­¾ï¼Œè¿›ä¸€æ­¥æå‡äº†æ¨¡å‹çš„æ³›åŒ–æ€§èƒ½ã€‚å®éªŒç»“æœè¡¨æ˜ï¼ŒSimMemDAåœ¨è·¨æ¨¡æ€èˆ¹èˆ¶å°¾è¿¹æ£€æµ‹ä»»åŠ¡ä¸­æœ‰æ•ˆæé«˜äº†å‡†ç¡®ç‡ä¸é²æ£’æ€§ã€‚",
      "categories": [
        "cs.CV",
        "cs.AI"
      ],
      "primary_category": "cs.CV",
      "comment": "",
      "pdf_url": "https://arxiv.org/pdf/2509.12279v1",
      "published_date": "2025-09-14 08:35:39 UTC",
      "updated_date": "2025-09-14 08:35:39 UTC",
      "processing_status": "completed",
      "attempts": 1,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "llm_backup_calls": 0,
      "last_update": "2026-01-24T18:27:17.995849+00:00"
    },
    {
      "arxiv_id": "2509.12278v1",
      "title": "PATIMT-Bench: A Multi-Scenario Benchmark for Position-Aware Text Image Machine Translation in Large Vision-Language Models",
      "title_zh": "PATIMT-Benchï¼šé¢å‘å¤§è§†è§‰è¯­è¨€æ¨¡å‹ä½ç½®æ„ŸçŸ¥æ–‡æœ¬å›¾åƒæœºå™¨ç¿»è¯‘çš„å¤šåœºæ™¯åŸºå‡†",
      "authors": [
        "Wanru Zhuang",
        "Wenbo Li",
        "Zhibin Lan",
        "Xu Han",
        "Peng Li",
        "Jinsong Su"
      ],
      "abstract": "Text Image Machine Translation (TIMT) aims to translate texts embedded within an image into another language. Current TIMT studies primarily focus on providing translations for all the text within an image, while neglecting to provide bounding boxes and covering limited scenarios. In this work, we extend traditional TIMT into position-aware TIMT (PATIMT), aiming to support fine-grained and layoutpreserving translation, which holds great practical value but remains largely unexplored. This task comprises two key sub-tasks: regionspecific translation and full-image translation with grounding. To support existing models on PATIMT and conduct fair evaluation, we construct the PATIMT benchmark (PATIMTBench), which consists of 10 diverse real-world scenarios. Specifically, we introduce an Adaptive Image OCR Refinement Pipeline, which adaptively selects appropriate OCR tools based on scenario and refines the results of text-rich images. To ensure evaluation reliability, we further construct a test set, which contains 1,200 high-quality instances manually annotated and reviewed by human experts. After fine-tuning on our data, compact Large Vision-Language Models (LVLMs) achieve state-of-the-art performance on both sub-tasks. Experimental results also highlight the scalability and generalizability of our training data",
      "tldr_zh": "è¯¥ç ”ç©¶é’ˆå¯¹ä¼ ç»Ÿæ–‡æœ¬å›¾åƒæœºå™¨ç¿»è¯‘(Text Image Machine Translation, TIMT)åœ¨ç¼ºä¹è¾¹ç•Œæ¡†(bounding boxes)å’Œåº”ç”¨åœºæ™¯æœ‰é™çš„é—®é¢˜ï¼Œæå‡ºäº†ä½ç½®æ„ŸçŸ¥æ–‡æœ¬å›¾åƒæœºå™¨ç¿»è¯‘(Position-Aware TIMT, PATIMT)ï¼Œæ—¨åœ¨å®ç°ç»†ç²’åº¦ä¸”ä¿æŒå¸ƒå±€çš„ç¿»è¯‘ã€‚PATIMTä»»åŠ¡æ¶µç›–äº†åŒºåŸŸç‰¹å®šç¿»è¯‘å’Œå¸¦å®šä½çš„å…¨å›¾ç¿»è¯‘ä¸¤ä¸ªæ ¸å¿ƒå­ä»»åŠ¡ï¼Œä¸ºæ­¤ç ”ç©¶è€…æ„å»ºäº†åŒ…å«10ç§å¤šæ ·åŒ–çœŸå®åœºæ™¯çš„PATIMT-BenchåŸºå‡†æµ‹è¯•é›†ã€‚ç ”ç©¶ä¸­å¼•å…¥äº†è‡ªé€‚åº”å›¾åƒOCRä¼˜åŒ–æµæ°´çº¿(Adaptive Image OCR Refinement Pipeline)ï¼Œé€šè¿‡åœ¨ä¸åŒåœºæ™¯ä¸‹è‡ªé€‚åº”é€‰æ‹©OCRå·¥å…·æ¥æå‡å¤„ç†æ•ˆæœã€‚ä¸ºäº†ç¡®ä¿è¯„ä¼°çš„ä¸¥è°¨æ€§ï¼Œå›¢é˜Ÿè¿˜åˆ›å»ºäº†ä¸€ä¸ªåŒ…å«1,200ä¸ªä¸“å®¶æ ‡æ³¨é«˜è´¨é‡å®ä¾‹çš„æµ‹è¯•é›†ã€‚å®éªŒè¯æ˜ï¼Œç»è¯¥æ•°æ®å¾®è°ƒåçš„è½»é‡çº§å¤§è§†è§‰è¯­è¨€æ¨¡å‹(LVLMs)åœ¨å„é¡¹ä»»åŠ¡ä¸Šå‡å–å¾—äº†æœ€å…ˆè¿›çš„(SOTA)æ€§èƒ½ï¼Œå±•ç¤ºäº†è¯¥æ•°æ®é›†ä¼˜ç§€çš„æ‰©å±•æ€§ä¸æ³›åŒ–èƒ½åŠ›ã€‚",
      "categories": [
        "cs.CV",
        "cs.AI"
      ],
      "primary_category": "cs.CV",
      "comment": "",
      "pdf_url": "https://arxiv.org/pdf/2509.12278v1",
      "published_date": "2025-09-14 08:33:23 UTC",
      "updated_date": "2025-09-14 08:33:23 UTC",
      "processing_status": "completed",
      "attempts": 1,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "llm_backup_calls": 0,
      "last_update": "2026-01-24T18:28:26.968952+00:00"
    },
    {
      "arxiv_id": "2509.11155v1",
      "title": "AQUA: Attention via QUery mAgnitudes for Memory and Compute Efficient Inference in LLMs",
      "title_zh": "AQUAï¼šåŸºäºæŸ¥è¯¢å‘é‡æ¨¡é•¿çš„å¤§è¯­è¨€æ¨¡å‹æ˜¾å­˜ä¸è®¡ç®—é«˜æ•ˆæ¨ç†æœºåˆ¶",
      "authors": [
        "Santhosh G S",
        "Saurav Prakash",
        "Balaraman Ravindran"
      ],
      "abstract": "The quadratic complexity of the attention mechanism remains a fundamental barrier to scaling Large Language Models (LLMs) to longer contexts, creating a critical bottleneck in both computation and memory. To address this, we introduce AQUA (Attention via QUery mAgnitudes) a novel and versatile approximation strategy that significantly reduces the cost of attention with a graceful performance trade-off. Our method operates in two phases: an efficient offline step where we compute a universal, language agnostic projection matrix via SVD on a calibration dataset, and an online inference step where we project query and key vectors and dynamically select a sparse subset of dimensions based on the query's magnitude. We provide a formal theoretical analysis of AQUA, establishing the break-even point at which it becomes more computationally efficient than standard attention. Our empirical evaluations on state-of-the-art models like Llama-3.1-8B demonstrate that a 25% reduction in the attention dot-product computation can be achieved with a statistically insignificant impact on performance across a wide range of benchmarks. We further showcase the versatility of AQUA by demonstrating its ability to synergistically accelerate existing token eviction methods like H2O and to directly reduce KV-cache memory size. By offering a controllable knob to balance efficiency and accuracy, AQUA provides a practical and powerful tool for making large-scale LLM inference more accessible and sustainable.",
      "tldr_zh": "è¯¥ç ”ç©¶é’ˆå¯¹å¤§å‹è¯­è¨€æ¨¡å‹(LLMs)ä¸­æ³¨æ„åŠ›æœºåˆ¶(Attention Mechanism)çš„å¹³æ–¹å¤æ‚åº¦å¯¼è‡´çš„é•¿ä¸Šä¸‹æ–‡è®¡ç®—å’Œå†…å­˜ç“¶é¢ˆï¼Œæå‡ºäº†åä¸ºAQUA(Attention via QUery mAgnitudes)çš„æ–°å‹è¿‘ä¼¼ç­–ç•¥ã€‚è¯¥æ–¹æ³•åˆ†ä¸ºä¸¤ä¸ªé˜¶æ®µï¼šåœ¨ç¦»çº¿é˜¶æ®µï¼Œé€šè¿‡å¯¹æ ¡å‡†æ•°æ®é›†è¿›è¡Œå¥‡å¼‚å€¼åˆ†è§£(SVD)è®¡ç®—é€šç”¨çš„ã€è·¨è¯­è¨€çš„æŠ•å½±çŸ©é˜µï¼›åœ¨åœ¨çº¿æ¨ç†é˜¶æ®µï¼Œå¯¹æŸ¥è¯¢(Query)å’Œé”®(Key)å‘é‡è¿›è¡ŒæŠ•å½±ï¼Œå¹¶åŸºäºæŸ¥è¯¢çš„å¹…åº¦(Magnitude)åŠ¨æ€é€‰æ‹©ç¨€ç–ç»´åº¦å­é›†ã€‚ç†è®ºåˆ†æç¡®å®šäº†è¯¥æ–¹æ³•åœ¨è®¡ç®—æ•ˆç‡ä¸Šä¼˜äºæ ‡å‡†æ³¨æ„åŠ›æœºåˆ¶çš„å¹³è¡¡ç‚¹ï¼Œå®éªŒè¡¨æ˜åœ¨Llama-3.1-8Bæ¨¡å‹ä¸Šå‡å°‘25%çš„ç‚¹ç§¯è®¡ç®—é‡å¯¹æ€§èƒ½å½±å“å¾®ä¹å…¶å¾®ã€‚æ­¤å¤–ï¼ŒAQUAå±•ç°äº†æå¼ºçš„é€šç”¨æ€§ï¼Œä¸ä»…èƒ½ä¸H2Oç­‰ä»¤ç‰Œå‰”é™¤(Token Eviction)æ–¹æ³•ååŒåŠ é€Ÿï¼Œè¿˜èƒ½ç›´æ¥å‡å°é”®å€¼ç¼“å­˜(KV-cache)çš„å†…å­˜å ç”¨ã€‚é€šè¿‡æä¾›å¯æ§çš„æ•ˆç‡ä¸å‡†ç¡®ç‡å¹³è¡¡ï¼ŒAQUAä¸ºå¤§è§„æ¨¡LLMæ¨ç†çš„é«˜æ•ˆæ€§å’Œå¯æŒç»­æ€§æä¾›äº†å®ç”¨çš„å·¥å…·ã€‚",
      "categories": [
        "cs.LG",
        "cs.AI",
        "cs.CL"
      ],
      "primary_category": "cs.LG",
      "comment": "",
      "pdf_url": "https://arxiv.org/pdf/2509.11155v1",
      "published_date": "2025-09-14 08:20:48 UTC",
      "updated_date": "2025-09-14 08:20:48 UTC",
      "processing_status": "completed",
      "attempts": 1,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "llm_backup_calls": 0,
      "last_update": "2026-01-24T18:28:28.056295+00:00"
    },
    {
      "arxiv_id": "2509.11154v1",
      "title": "Feature Space Topology Control via Hopkins Loss",
      "title_zh": "åŸºäº Hopkins æŸå¤±çš„ç‰¹å¾ç©ºé—´æ‹“æ‰‘æ§åˆ¶",
      "authors": [
        "Einari Vaaras",
        "Manu Airaksinen"
      ],
      "abstract": "Feature space topology refers to the organization of samples within the feature space. Modifying this topology can be beneficial in machine learning applications, including dimensionality reduction, generative modeling, transfer learning, and robustness to adversarial attacks. This paper introduces a novel loss function, Hopkins loss, which leverages the Hopkins statistic to enforce a desired feature space topology, which is in contrast to existing topology-related methods that aim to preserve input feature topology. We evaluate the effectiveness of Hopkins loss on speech, text, and image data in two scenarios: classification and dimensionality reduction using nonlinear bottleneck autoencoders. Our experiments show that integrating Hopkins loss into classification or dimensionality reduction has only a small impact on classification performance while providing the benefit of modifying feature topology.",
      "tldr_zh": "è¯¥ç ”ç©¶å¼•å…¥äº†ä¸€ç§åä¸º Hopkins loss çš„æ–°å‹æŸå¤±å‡½æ•°ï¼Œæ—¨åœ¨é€šè¿‡åˆ©ç”¨ Hopkins statistic æ¥æ§åˆ¶å’Œå¼ºåˆ¶æ‰§è¡Œæ‰€éœ€çš„ç‰¹å¾ç©ºé—´æ‹“æ‰‘ (feature space topology)ã€‚ä¸æ—¨åœ¨ä¿ç•™è¾“å…¥ç‰¹å¾æ‹“æ‰‘çš„ç°æœ‰æ–¹æ³•ä¸åŒï¼ŒHopkins loss å…è®¸æ ¹æ®åº”ç”¨éœ€æ±‚ä¸»åŠ¨ä¿®æ”¹æ ·æœ¬åœ¨ç‰¹å¾ç©ºé—´ä¸­çš„ç»„ç»‡æ–¹å¼ã€‚ä½œè€…åœ¨è¯­éŸ³ã€æ–‡æœ¬å’Œå›¾åƒæ•°æ®ä¸ŠéªŒè¯äº†è¯¥æ–¹æ³•çš„æœ‰æ•ˆæ€§ï¼Œæ¶µç›–äº†åˆ†ç±»ä»»åŠ¡ä»¥åŠä½¿ç”¨éçº¿æ€§ç“¶é¢ˆè‡ªåŠ¨ç¼–ç å™¨ (nonlinear bottleneck autoencoders) è¿›è¡Œé™ç»´çš„åœºæ™¯ã€‚å®éªŒç»“æœè¡¨æ˜ï¼Œå°† Hopkins loss é›†æˆåˆ°æ¨¡å‹è®­ç»ƒä¸­å¯ä»¥åœ¨æˆåŠŸä¿®æ”¹ç‰¹å¾æ‹“æ‰‘çš„åŒæ—¶ï¼Œä»…å¯¹åˆ†ç±»æ€§èƒ½äº§ç”Ÿæå°çš„å½±å“ã€‚è¯¥ç ”ç©¶ä¸ºé™ç»´ã€ç”Ÿæˆå»ºæ¨¡ã€è¿ç§»å­¦ä¹ ä»¥åŠå¢å¼ºå¯¹æŠ—æ”»å‡»é²æ£’æ€§ç­‰æœºå™¨å­¦ä¹ ä»»åŠ¡æä¾›äº†è°ƒèŠ‚ç‰¹å¾ç©ºé—´ç»“æ„çš„æ–°æ‰‹æ®µã€‚",
      "categories": [
        "cs.LG",
        "cs.AI"
      ],
      "primary_category": "cs.LG",
      "comment": "Accepted for publication in Proc. IEEE ICTAI 2025, Athens, Greece",
      "pdf_url": "https://arxiv.org/pdf/2509.11154v1",
      "published_date": "2025-09-14 08:16:20 UTC",
      "updated_date": "2025-09-14 08:16:20 UTC",
      "processing_status": "completed",
      "attempts": 1,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "llm_backup_calls": 0,
      "last_update": "2026-01-24T18:28:32.565633+00:00"
    },
    {
      "arxiv_id": "2509.12277v1",
      "title": "GraphDerm: Fusing Imaging, Physical Scale, and Metadata in a Population-Graph Classifier for Dermoscopic Lesions",
      "title_zh": "GraphDermï¼šèåˆå›¾åƒã€ç‰©ç†å°ºåº¦ä¸å…ƒæ•°æ®çš„çš®è‚¤é•œç—…å˜ç¾¤ä½“å›¾åˆ†ç±»å™¨",
      "authors": [
        "Mehdi Yousefzadeh",
        "Parsa Esfahanian",
        "Sara Rashidifar",
        "Hossein Salahshoor Gavalan",
        "Negar Sadat Rafiee Tabatabaee",
        "Saeid Gorgin",
        "Dara Rahmati",
        "Maryam Daneshpazhooh"
      ],
      "abstract": "Introduction. Dermoscopy aids melanoma triage, yet image-only AI often ignores patient metadata (age, sex, site) and the physical scale needed for geometric analysis. We present GraphDerm, a population-graph framework that fuses imaging, millimeter-scale calibration, and metadata for multiclass dermoscopic classification, to the best of our knowledge the first ISIC-scale application of GNNs to dermoscopy. Methods. We curate ISIC 2018/2019, synthesize ruler-embedded images with exact masks, and train U-Nets (SE-ResNet-18) for lesion and ruler segmentation. Pixels-per-millimeter are regressed from the ruler-mask two-point correlation via a lightweight 1D-CNN. From lesion masks we compute real-scale descriptors (area, perimeter, radius of gyration). Node features use EfficientNet-B3; edges encode metadata/geometry similarity (fully weighted or thresholded). A spectral GNN performs semi-supervised node classification; an image-only ANN is the baseline. Results. Ruler and lesion segmentation reach Dice 0.904 and 0.908; scale regression attains MAE 1.5 px (RMSE 6.6). The graph attains AUC 0.9812, with a thresholded variant using about 25% of edges preserving AUC 0.9788 (vs. 0.9440 for the image-only baseline); per-class AUCs typically fall in the 0.97-0.99 range. Conclusion. Unifying calibrated scale, lesion geometry, and metadata in a population graph yields substantial gains over image-only pipelines on ISIC-2019. Sparser graphs retain near-optimal accuracy, suggesting efficient deployment. Scale-aware, graph-based AI is a promising direction for dermoscopic decision support; future work will refine learned edge semantics and evaluate on broader curated benchmarks.",
      "tldr_zh": "è¯¥ç ”ç©¶æå‡ºäº†GraphDermï¼Œè¿™æ˜¯é¦–ä¸ªåœ¨ISICè§„æ¨¡ä¸Šåº”ç”¨å›¾ç¥ç»ç½‘ç»œ(GNNs)è¿›è¡Œçš®è‚¤é•œç—…å˜å¤šç±»åˆ†ç±»çš„ç¾¤ä½“å›¾(population-graph)æ¡†æ¶ã€‚GraphDermåˆ›æ–°æ€§åœ°èåˆäº†ä¸´åºŠå›¾åƒã€æ¯«ç±³çº§ç‰©ç†æ¯”ä¾‹å°ºæ ¡å‡†ä»¥åŠæ‚£è€…å…ƒæ•°æ®ï¼Œè§£å†³äº†ä¼ ç»ŸAIæ¨¡å‹å¿½ç•¥ç—…å˜çœŸå®å‡ ä½•å°ºå¯¸ä¸ä¸Šä¸‹æ–‡ä¿¡æ¯çš„é—®é¢˜ã€‚ç ”ç©¶åˆ©ç”¨U-Netsè¿›è¡Œç—…å˜å’Œæ ‡å°ºåˆ†å‰²ï¼Œå¹¶é€šè¿‡1D-CNNå›å½’ç‰©ç†æ¯”ä¾‹ä»¥æå–é¢ç§¯ã€å‘¨é•¿ç­‰çœŸå®å‡ ä½•æè¿°ç¬¦ã€‚æ¨¡å‹ç»“åˆEfficientNet-B3æå–èŠ‚ç‚¹ç‰¹å¾ï¼Œå¹¶é‡‡ç”¨è°±å›¾ç¥ç»ç½‘ç»œ(spectral GNN)è¿›è¡ŒåŠç›‘ç£åˆ†ç±»ã€‚å®éªŒç»“æœæ˜¾ç¤ºï¼ŒGraphDermåœ¨ISIC-2019æ•°æ®é›†ä¸Šçš„AUCè¾¾åˆ°0.9812ï¼Œæ˜¾è‘—ä¼˜äºä»…ä½¿ç”¨å›¾åƒçš„åŸºå‡†æ¨¡å‹(AUC 0.9440)ã€‚å³ä½¿åœ¨ä»…ä¿ç•™çº¦25%è¾¹ç¼˜çš„ç¨€ç–å›¾å˜ä½“ä¸‹ï¼Œæ¨¡å‹ä»èƒ½ç»´æŒ0.9788çš„æé«˜å‡†ç¡®ç‡ï¼Œä¸ºæ¯”ä¾‹æ„ŸçŸ¥å’ŒåŸºäºå›¾ç»“æ„çš„çš®è‚¤ç—…è¾…åŠ©å†³ç­–æ”¯æŒæä¾›äº†æœ‰åŠ›è¯æ˜ã€‚",
      "categories": [
        "cs.CV",
        "cs.AI"
      ],
      "primary_category": "cs.CV",
      "comment": "",
      "pdf_url": "https://arxiv.org/pdf/2509.12277v1",
      "published_date": "2025-09-14 08:11:54 UTC",
      "updated_date": "2025-09-14 08:11:54 UTC",
      "processing_status": "completed",
      "attempts": 1,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "llm_backup_calls": 0,
      "last_update": "2026-01-24T18:29:11.592814+00:00"
    },
    {
      "arxiv_id": "2509.14265v1",
      "title": "Evolution of Kernels: Automated RISC-V Kernel Optimization with Large Language Models",
      "title_zh": "Evolution of Kernelsï¼šåŸºäºå¤§è¯­è¨€æ¨¡å‹çš„ RISC-V å†…æ ¸è‡ªåŠ¨åŒ–ä¼˜åŒ–",
      "authors": [
        "Siyuan Chen",
        "Zhichao Lu",
        "Qingfu Zhang"
      ],
      "abstract": "Automated kernel design is critical for overcoming software ecosystem barriers in emerging hardware platforms like RISC-V. While large language models (LLMs) have shown promise for automated kernel optimization, demonstrating success in CUDA domains with comprehensive technical documents and mature codebases, their effectiveness remains unproven for reference-scarce domains like RISC-V. We present Evolution of Kernels (EoK), a novel LLM-based evolutionary program search framework that automates kernel design for domains with limited reference material. EoK mitigates reference scarcity by mining and formalizing reusable optimization ideas (general design principles + actionable thoughts) from established kernel libraries' development histories; it then guides parallel LLM explorations using these ideas, enriched via Retrieval-Augmented Generation (RAG) with RISC-V-specific context, prioritizing historically effective techniques. Empirically, EoK achieves a median 1.27x speedup, surpassing human experts on all 80 evaluated kernel design tasks and improving upon prior LLM-based automated kernel design methods by 20%. These results underscore the viability of incorporating human experience into emerging domains and highlight the immense potential of LLM-based automated kernel optimization.",
      "tldr_zh": "è¯¥ç ”ç©¶é’ˆå¯¹æ–°å…´ç¡¬ä»¶å¹³å° RISC-V åœ¨å†…æ ¸ä¼˜åŒ–é¢†åŸŸå› å‚è€ƒèµ„æ–™ç¨€ç¼ºè€Œé¢ä¸´çš„æŒ‘æˆ˜ï¼Œæå‡ºäº† Evolution of Kernels (EoK) æ¡†æ¶ã€‚è¯¥æ¡†æ¶é‡‡ç”¨åŸºäºå¤§è¯­è¨€æ¨¡å‹ (LLM) çš„è¿›åŒ–ç¨‹åºæœç´¢æ–¹æ³•ï¼Œé€šè¿‡ä»æ—¢æœ‰å†…æ ¸åº“å¼€å‘å†å²ä¸­æŒ–æ˜å¹¶å½¢å¼åŒ–å¯é‡ç”¨çš„ä¼˜åŒ–ç†å¿µï¼Œæœ‰æ•ˆç¼“è§£äº†å‚è€ƒä¸è¶³çš„é—®é¢˜ã€‚EoK ç»“åˆæ£€ç´¢å¢å¼ºç”Ÿæˆ (RAG) æŠ€æœ¯å¼•å…¥ RISC-V ç‰¹å®šä¸Šä¸‹æ–‡ï¼Œå¹¶ä»¥æ­¤å¼•å¯¼å¹¶è¡Œçš„ LLM æ¢ç´¢ï¼Œä¼˜å…ˆæ‰§è¡Œå†å²ä¸Šè¯æ˜æœ‰æ•ˆçš„ä¼˜åŒ–æŠ€æœ¯ã€‚å®éªŒè¡¨æ˜ï¼ŒEoK åœ¨ 80 ä¸ªå†…æ ¸è®¾è®¡ä»»åŠ¡ä¸­å®ç°äº† 1.27 å€çš„ä¸­å€¼åŠ é€Ÿï¼Œæ€§èƒ½ä¸ä»…åœ¨æ‰€æœ‰ä»»åŠ¡ä¸Šå‡è¶…è¶Šäº†äººç±»ä¸“å®¶ï¼Œç›¸æ¯”å…ˆå‰çš„è‡ªåŠ¨åŒ–å†…æ ¸è®¾è®¡æ–¹æ³•ä¹Ÿæå‡äº† 20%ã€‚è¯¥ç ”ç©¶éªŒè¯äº†å°†äººç±»ç»éªŒèå…¥æ–°å…´é¢†åŸŸä¼˜åŒ–è¿‡ç¨‹çš„å¯è¡Œæ€§ï¼Œå……åˆ†å±•ç¤ºäº† LLM åœ¨è‡ªåŠ¨åŒ–å†…æ ¸ä¼˜åŒ–æ–¹é¢çš„å·¨å¤§æ½œåŠ›ã€‚",
      "categories": [
        "cs.SE",
        "cs.AI"
      ],
      "primary_category": "cs.SE",
      "comment": "Technical report",
      "pdf_url": "https://arxiv.org/pdf/2509.14265v1",
      "published_date": "2025-09-14 08:11:06 UTC",
      "updated_date": "2025-09-14 08:11:06 UTC",
      "processing_status": "completed",
      "attempts": 1,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "llm_backup_calls": 0,
      "last_update": "2026-01-24T18:28:38.161320+00:00"
    },
    {
      "arxiv_id": "2509.11151v1",
      "title": "AI-Generated Content in Cross-Domain Applications: Research Trends, Challenges and Propositions",
      "title_zh": "è·¨é¢†åŸŸåº”ç”¨ä¸­çš„äººå·¥æ™ºèƒ½ç”Ÿæˆå†…å®¹ï¼šç ”ç©¶è¶‹åŠ¿ã€æŒ‘æˆ˜ä¸å»ºè®®",
      "authors": [
        "Jianxin Li",
        "Liang Qu",
        "Taotao Cai",
        "Zhixue Zhao",
        "Nur Al Hasan Haldar",
        "Aneesh Krishna",
        "Xiangjie Kong",
        "Flavio Romero Macau",
        "Tanmoy Chakraborty",
        "Aniket Deroy",
        "Binshan Lin",
        "Karen Blackmore",
        "Nasimul Noman",
        "Jingxian Cheng",
        "Ningning Cui",
        "Jianliang Xu"
      ],
      "abstract": "Artificial Intelligence Generated Content (AIGC) has rapidly emerged with the capability to generate different forms of content, including text, images, videos, and other modalities, which can achieve a quality similar to content created by humans. As a result, AIGC is now widely applied across various domains such as digital marketing, education, and public health, and has shown promising results by enhancing content creation efficiency and improving information delivery. However, there are few studies that explore the latest progress and emerging challenges of AIGC across different domains. To bridge this gap, this paper brings together 16 scholars from multiple disciplines to provide a cross-domain perspective on the trends and challenges of AIGC. Specifically, the contributions of this paper are threefold: (1) It first provides a broader overview of AIGC, spanning the training techniques of Generative AI, detection methods, and both the spread and use of AI-generated content across digital platforms. (2) It then introduces the societal impacts of AIGC across diverse domains, along with a review of existing methods employed in these contexts. (3) Finally, it discusses the key technical challenges and presents research propositions to guide future work. Through these contributions, this vision paper seeks to offer readers a cross-domain perspective on AIGC, providing insights into its current research trends, ongoing challenges, and future directions.",
      "tldr_zh": "è¯¥ç ”ç©¶é’ˆå¯¹äººå·¥æ™ºèƒ½ç”Ÿæˆå†…å®¹ï¼ˆArtificial Intelligence Generated Content, AIGCï¼‰åœ¨æ•°å­—è¥é”€ã€æ•™è‚²å’Œå…¬å…±å«ç”Ÿç­‰è·¨é¢†åŸŸåº”ç”¨ä¸­å‘ˆç°çš„å¿«é€Ÿå¢é•¿è¶‹åŠ¿ï¼Œæ¢è®¨äº†å…¶æŠ€æœ¯è¿›å±•ä¸é¢ä¸´çš„æŒ‘æˆ˜ã€‚æ–‡ç« æ±‡é›†äº†æ¥è‡ªå¤šä¸ªå­¦ç§‘çš„16ä½å­¦è€…ï¼Œæ—¨åœ¨ä»è·¨é¢†åŸŸè§†è§’å‡ºå‘ï¼Œç³»ç»Ÿæ€§åœ°æ¢³ç† AIGC çš„ç ”ç©¶è¶‹åŠ¿ã€ç¤¾ä¼šå½±å“ä»¥åŠæœªæ¥å‘½é¢˜ã€‚ç ”ç©¶é¦–å…ˆæä¾›äº† AIGC çš„å®è§‚æ¦‚è§ˆï¼Œæ¶µç›–äº† Generative AI çš„è®­ç»ƒæŠ€æœ¯ã€æ£€æµ‹æ–¹æ³•ä»¥åŠç”Ÿæˆå†…å®¹åœ¨æ•°å­—å¹³å°ä¸Šçš„ä¼ æ’­ä¸ä½¿ç”¨ã€‚éšåï¼Œè®ºæ–‡åˆ†æäº† AIGC åœ¨ä¸åŒé¢†åŸŸäº§ç”Ÿçš„ç¤¾ä¼šå½±å“ï¼Œå¹¶å¯¹è¿™äº›ç‰¹å®šè¯­å¢ƒä¸‹ç°æœ‰çš„åº”ç”¨æ–¹æ³•è¿›è¡Œäº†å›é¡¾ã€‚æœ€åï¼Œä½œè€…æ·±å…¥è®¨è®ºäº† AIGC é¢ä¸´çš„å…³é”®æŠ€æœ¯æŒ‘æˆ˜ï¼Œå¹¶æå‡ºäº†ä¸€ç³»åˆ—ç ”ç©¶å»ºè®®ï¼ˆpropositionsï¼‰ä»¥æŒ‡å¯¼æœªæ¥çš„å·¥ä½œã€‚è¯¥ç»¼è¿°è®ºæ–‡é€šè¿‡å¤šç»´åº¦çš„è§†è§’ï¼Œä¸ºç†è§£ AIGC çš„ç ”ç©¶ç°çŠ¶åŠæœªæ¥å‘å±•æ–¹å‘æä¾›äº†æ·±åˆ»è§è§£ã€‚",
      "categories": [
        "cs.AI"
      ],
      "primary_category": "cs.AI",
      "comment": "",
      "pdf_url": "https://arxiv.org/pdf/2509.11151v1",
      "published_date": "2025-09-14 07:56:21 UTC",
      "updated_date": "2025-09-14 07:56:21 UTC",
      "processing_status": "completed",
      "attempts": 1,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "llm_backup_calls": 0,
      "last_update": "2026-01-24T18:28:47.392079+00:00"
    },
    {
      "arxiv_id": "2509.11149v2",
      "title": "RoVerFly: Robust and Versatile Implicit Hybrid Control of Quadrotor-Payload Systems",
      "title_zh": "RoVerFlyï¼šå››æ—‹ç¿¼-è´Ÿè½½ç³»ç»Ÿçš„é²æ£’é€šç”¨éšå¼æ··åˆæ§åˆ¶",
      "authors": [
        "Mintae Kim",
        "Jiaze Cai",
        "Koushil Sreenath"
      ],
      "abstract": "Designing robust controllers for precise trajectory tracking with quadrotors is challenging due to nonlinear dynamics and underactuation, and becomes harder with flexible cable-suspended payloads that add degrees of freedom and hybrid dynamics. Classical model-based methods offer stability guarantees but require extensive tuning and often fail to adapt when the configuration changes-when a payload is added or removed, or when its mass or cable length varies. We present RoVerFly, a unified learning-based control framework where a single reinforcement learning (RL) policy functions as an implicit hybrid controller, managing complex dynamics without explicit mode detection or controller switching. Trained with task and domain randomization, the controller is resilient to disturbances and varying dynamics. It achieves strong zero-shot generalization across payload settings-including no payload as well as varying mass and cable length-without re-tuning, while retaining the interpretability and structure of a feedback tracking controller. Code and supplementary materials are available at https://github.com/mintaeshkim/roverfly.",
      "tldr_zh": "è¯¥ç ”ç©¶æå‡ºäº† RoVerFlyï¼Œä¸€ä¸ªé’ˆå¯¹å››æ—‹ç¿¼-è´Ÿè½½ç³»ç»Ÿ (Quadrotor-Payload Systems) çš„é²æ£’ä¸”å¤šåŠŸèƒ½çš„éšå¼æ··åˆæ§åˆ¶æ¡†æ¶ã€‚è¯¥æ¡†æ¶åˆ©ç”¨å•ä¸€çš„å¼ºåŒ–å­¦ä¹  (RL) ç­–ç•¥ä½œä¸ºéšå¼æ··åˆæ§åˆ¶å™¨ï¼Œèƒ½å¤Ÿç›´æ¥å¤„ç†ç”±æŸ”æ€§ç”µç¼†æ‚¬æŒ‚è´Ÿè½½å¼•å…¥çš„å¤æ‚æ··åˆåŠ¨åŠ›å­¦ï¼Œè€Œæ— éœ€æ˜¾å¼çš„æ¨¡å¼æ£€æµ‹æˆ–æ§åˆ¶å™¨åˆ‡æ¢ã€‚é€šè¿‡ä»»åŠ¡å’Œé¢†åŸŸéšæœºåŒ– (Task and Domain Randomization) è®­ç»ƒï¼Œè¯¥æ§åˆ¶å™¨è¡¨ç°å‡ºå¯¹å¤–éƒ¨æ‰°åŠ¨å’ŒåŠ¨æ€å˜åŒ–çš„å¼ºå¤§éŸ§æ€§ã€‚å®éªŒç»“æœæ˜¾ç¤ºï¼ŒRoVerFly åœ¨åŒ…æ‹¬æ— è´Ÿè½½ä»¥åŠä¸åŒè´Ÿè½½è´¨é‡å’Œç”µç¼†é•¿åº¦åœ¨å†…çš„å¤šç§è®¾ç½®ä¸‹å®ç°äº†å¼ºå¤§çš„é›¶æ ·æœ¬æ³›åŒ– (Zero-shot Generalization)ï¼Œä¸”æ— éœ€è¿›è¡Œä»»ä½•é‡æ–°è°ƒå‚ã€‚æ­¤å¤–ï¼Œè¯¥æ–¹æ¡ˆåœ¨å®ç°é«˜æ€§èƒ½æ§åˆ¶çš„åŒæ—¶ï¼Œä¾ç„¶ä¿ç•™äº†ä¼ ç»Ÿåé¦ˆè·Ÿè¸ªæ§åˆ¶å™¨ (Feedback Tracking Controller) çš„å¯è§£é‡Šæ€§å’Œç»“æ„åŒ–ç‰¹å¾ã€‚",
      "categories": [
        "cs.RO",
        "cs.AI",
        "cs.LG"
      ],
      "primary_category": "cs.RO",
      "comment": "8 pages, 5 figures",
      "pdf_url": "https://arxiv.org/pdf/2509.11149v2",
      "published_date": "2025-09-14 07:41:40 UTC",
      "updated_date": "2025-10-01 10:47:23 UTC",
      "processing_status": "completed",
      "attempts": 1,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "llm_backup_calls": 0,
      "last_update": "2026-01-24T18:28:48.084712+00:00"
    },
    {
      "arxiv_id": "2509.11136v1",
      "title": "Agentic Username Suggestion and Multimodal Gender Detection in Online Platforms: Introducing the PNGT-26K Dataset",
      "title_zh": "åœ¨çº¿å¹³å°ä¸­çš„æ™ºèƒ½ä½“åŒ–ç”¨æˆ·åå»ºè®®ä¸å¤šæ¨¡æ€æ€§åˆ«è¯†åˆ«ï¼šPNGT-26K æ•°æ®é›†çš„æå‡º",
      "authors": [
        "Farbod Bijary",
        "Mohsen Ebadpour",
        "Amirhosein Tajbakhsh"
      ],
      "abstract": "Persian names present unique challenges for natural language processing applications, particularly in gender detection and digital identity creation, due to transliteration inconsistencies and cultural-specific naming patterns. Existing tools exhibit significant performance degradation on Persian names, while the scarcity of comprehensive datasets further compounds these limitations. To address these challenges, the present research introduces PNGT-26K, a comprehensive dataset of Persian names, their commonly associated gender, and their English transliteration, consisting of approximately 26,000 tuples. As a demonstration of how this resource can be utilized, we also introduce two frameworks, namely Open Gender Detection and Nominalist. Open Gender Detection is a production-grade, ready-to-use framework for using existing data from a user, such as profile photo and name, to give a probabilistic guess about the person's gender. Nominalist, the second framework introduced by this paper, utilizes agentic AI to help users choose a username for their social media accounts on any platform. It can be easily integrated into any website to provide a better user experience. The PNGT-26K dataset, Nominalist and Open Gender Detection frameworks are publicly available on Github.",
      "tldr_zh": "è¯¥ç ”ç©¶é’ˆå¯¹æ³¢æ–¯è¯­(Persian)å§“ååœ¨éŸ³è¯‘ä¸ä¸€è‡´å’Œæ–‡åŒ–ç‰¹å¼‚æ€§æ–¹é¢å¸¦æ¥çš„æŒ‘æˆ˜ï¼Œæ¨å‡ºäº†PNGT-26Kæ•°æ®é›†ï¼ŒåŒ…å«çº¦26,000ç»„å§“åã€å…³è”æ€§åˆ«åŠå…¶è‹±è¯­éŸ³è¯‘çš„å…ƒç»„æ•°æ®ã€‚ä¸ºäº†éªŒè¯è¯¥èµ„æºçš„ä»·å€¼ï¼Œç ”ç©¶è¿›ä¸€æ­¥æå‡ºäº†Open Gender Detectionå’ŒNominalistä¸¤ä¸ªåº”ç”¨æ¡†æ¶ã€‚Open Gender Detectionæ˜¯ä¸€ä¸ªç”Ÿäº§çº§çš„å¤šæ¨¡æ€æ€§åˆ«æ£€æµ‹ç³»ç»Ÿï¼Œé€šè¿‡èåˆç”¨æˆ·å¤´åƒå’Œå§“åä¿¡æ¯ç»™å‡ºæ¦‚ç‡é¢„æµ‹ï¼›Nominaliståˆ™å¼•å…¥äº†æ™ºèƒ½ä½“AI(Agentic AI)æŠ€æœ¯ï¼Œæ—¨åœ¨è¾…åŠ©ç”¨æˆ·åœ¨å„ç±»ç¤¾äº¤åª’ä½“å¹³å°ä¸Šä¼˜åŒ–ç”¨æˆ·åé€‰æ‹©è¿‡ç¨‹ã€‚PNGT-26Kæ•°æ®é›†åŠç›¸å…³æ¡†æ¶å‡å·²åœ¨Githubå…¬å¼€ï¼Œè¿™ä¸ºè§£å†³æ³¢æ–¯è¯­åœ¨è‡ªç„¶è¯­è¨€å¤„ç†(NLP)é¢†åŸŸçš„æ€§èƒ½é€€åŒ–é—®é¢˜æä¾›äº†é‡è¦æ”¯æ’‘ï¼ŒåŒæ—¶æ˜¾è‘—æå‡äº†ç›¸å…³å¹³å°çš„æ•°å­—èº«ä»½ç®¡ç†å’Œç”¨æˆ·ä½“éªŒã€‚",
      "categories": [
        "cs.LG",
        "cs.AI",
        "cs.CL",
        "cs.SI"
      ],
      "primary_category": "cs.LG",
      "comment": "",
      "pdf_url": "https://arxiv.org/pdf/2509.11136v1",
      "published_date": "2025-09-14 07:08:32 UTC",
      "updated_date": "2025-09-14 07:08:32 UTC",
      "processing_status": "completed",
      "attempts": 1,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "llm_backup_calls": 0,
      "last_update": "2026-01-24T18:28:53.391128+00:00"
    },
    {
      "arxiv_id": "2509.11135v1",
      "title": "AlignKT: Explicitly Modeling Knowledge State for Knowledge Tracing with Ideal State Alignment",
      "title_zh": "AlignKTï¼šåŸºäºç†æƒ³çŠ¶æ€å¯¹é½çš„çŸ¥è¯†è¿½è¸ªçŸ¥è¯†çŠ¶æ€æ˜¾å¼å»ºæ¨¡",
      "authors": [
        "Jing Xiao",
        "Chang You",
        "Zhiyu Chen"
      ],
      "abstract": "Knowledge Tracing (KT) serves as a fundamental component of Intelligent Tutoring Systems (ITS), enabling these systems to monitor and understand learners' progress by modeling their knowledge state. However, many existing KT models primarily focus on fitting the sequences of learners' interactions, and often overlook the knowledge state itself. This limitation leads to reduced interpretability and insufficient instructional support from the ITS. To address this challenge, we propose AlignKT, which employs a frontend-to-backend architecture to explicitly model a stable knowledge state. In this approach, the preliminary knowledge state is aligned with an additional criterion. Specifically, we define an ideal knowledge state based on pedagogical theories as the alignment criterion, providing a foundation for interpretability. We utilize five encoders to implement this set-up, and incorporate a contrastive learning module to enhance the robustness of the alignment process. Through extensive experiments, AlignKT demonstrates superior performance, outperforming seven KT baselines on three real-world datasets. It achieves state-of-the-art results on two of these datasets and exhibits competitive performance on the third. The code of this work is available at https://github.com/SCNU203/AlignKT.",
      "tldr_zh": "æœ¬ç ”ç©¶é’ˆå¯¹ç°æœ‰çŸ¥è¯†è¿½è¸ªï¼ˆKnowledge Tracing, KTï¼‰æ¨¡å‹å¾€å¾€ä¾§é‡äºæ‹Ÿåˆå­¦ä¹ è€…äº¤äº’åºåˆ—è€Œå¿½è§†çŸ¥è¯†çŠ¶æ€å»ºæ¨¡ï¼Œå¯¼è‡´æ¨¡å‹å¯è§£é‡Šæ€§å’Œæ•™å­¦æ”¯æŒä¸è¶³çš„é—®é¢˜ï¼Œæå‡ºäº†AlignKTã€‚AlignKTé‡‡ç”¨å‰ç«¯åˆ°åç«¯çš„æ¶æ„è®¾è®¡ï¼Œæ—¨åœ¨æ˜¾å¼åœ°å»ºæ¨¡ä¸€ä¸ªç¨³å®šçš„çŸ¥è¯†çŠ¶æ€ï¼ˆKnowledge Stateï¼‰ã€‚è¯¥æ–¹æ³•çš„æ ¸å¿ƒåœ¨äºå®šä¹‰äº†ä¸€ä¸ªåŸºäºæ•™è‚²å­¦ç†è®ºçš„ç†æƒ³çŸ¥è¯†çŠ¶æ€ä½œä¸ºå¯¹é½æ ‡å‡†ï¼Œå°†åˆæ­¥ç”Ÿæˆçš„çŸ¥è¯†çŠ¶æ€ä¸è¯¥æ ‡å‡†è¿›è¡Œå¯¹é½ï¼Œä»è€Œä¸ºæ¨¡å‹çš„å¯è§£é‡Šæ€§å¥ å®šåŸºç¡€ã€‚æ¨¡å‹åˆ©ç”¨äº”ä¸ªç¼–ç å™¨ï¼ˆEncodersï¼‰å®ç°ç³»ç»Ÿè®¾ç½®ï¼Œå¹¶å¼•å…¥å¯¹æ¯”å­¦ä¹ ï¼ˆContrastive Learningï¼‰æ¨¡å—ä»¥å¢å¼ºå¯¹é½è¿‡ç¨‹çš„é²æ£’æ€§ã€‚å®éªŒç»“æœè¡¨æ˜ï¼ŒAlignKTåœ¨ä¸‰ä¸ªçœŸå®ä¸–ç•Œæ•°æ®é›†ä¸Šçš„è¡¨ç°ä¼˜äºä¸ƒç§ä¸»æµKTåŸºå‡†æ¨¡å‹ã€‚è¯¥æ¨¡å‹åœ¨å…¶ä¸­ä¸¤ä¸ªæ•°æ®é›†ä¸Šè¾¾åˆ°äº†State-of-the-Artï¼ˆSOTAï¼‰æ€§èƒ½ï¼Œå¹¶åœ¨ç¬¬ä¸‰ä¸ªæ•°æ®é›†ä¸Šå±•ç°äº†æå…·ç«äº‰åŠ›çš„è¡¨ç°ï¼Œä¸ºæå‡æ™ºèƒ½æ•™å­¦ç³»ç»Ÿçš„è®¤çŸ¥è¯Šæ–­èƒ½åŠ›æä¾›äº†æœ‰æ•ˆæ–¹æ¡ˆã€‚",
      "categories": [
        "cs.AI"
      ],
      "primary_category": "cs.AI",
      "comment": "",
      "pdf_url": "https://arxiv.org/pdf/2509.11135v1",
      "published_date": "2025-09-14 07:06:40 UTC",
      "updated_date": "2025-09-14 07:06:40 UTC",
      "processing_status": "completed",
      "attempts": 1,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "llm_backup_calls": 0,
      "last_update": "2026-01-24T18:28:54.887585+00:00"
    },
    {
      "arxiv_id": "2509.11131v1",
      "title": "Neural cellular automata: applications to biology and beyond classical AI",
      "title_zh": "ç¥ç»ç»†èƒè‡ªåŠ¨æœºï¼šç”Ÿç‰©å­¦åº”ç”¨åŠå¯¹ä¼ ç»Ÿäººå·¥æ™ºèƒ½çš„è¶…è¶Š",
      "authors": [
        "Benedikt Hartl",
        "Michael Levin",
        "LÃ©o Pio-Lopez"
      ],
      "abstract": "Neural Cellular Automata (NCA) represent a powerful framework for modeling biological self-organization, extending classical rule-based systems with trainable, differentiable (or evolvable) update rules that capture the adaptive self-regulatory dynamics of living matter. By embedding Artificial Neural Networks (ANNs) as local decision-making centers and interaction rules between localized agents, NCA can simulate processes across molecular, cellular, tissue, and system-level scales, offering a multiscale competency architecture perspective on evolution, development, regeneration, aging, morphogenesis, and robotic control. These models not only reproduce biologically inspired target patterns but also generalize to novel conditions, demonstrating robustness to perturbations and the capacity for open-ended adaptation and reasoning. Given their immense success in recent developments, we here review current literature of NCAs that are relevant primarily for biological or bioengineering applications. Moreover, we emphasize that beyond biology, NCAs display robust and generalizing goal-directed dynamics without centralized control, e.g., in controlling or regenerating composite robotic morphologies or even on cutting-edge reasoning tasks such as ARC-AGI-1. In addition, the same principles of iterative state-refinement is reminiscent to modern generative Artificial Intelligence (AI), such as probabilistic diffusion models. Their governing self-regulatory behavior is constraint to fully localized interactions, yet their collective behavior scales into coordinated system-level outcomes. We thus argue that NCAs constitute a unifying computationally lean paradigm that not only bridges fundamental insights from multiscale biology with modern generative AI, but have the potential to design truly bio-inspired collective intelligence capable of hierarchical reasoning and control.",
      "tldr_zh": "è¿™é¡¹ç ”ç©¶ç»¼è¿°äº†ç¥ç»ç»†èƒè‡ªåŠ¨æœº (Neural Cellular Automata, NCA) åœ¨ç”Ÿç‰©å­¦ã€ç”Ÿç‰©å·¥ç¨‹ä»¥åŠè¶…è¶Šä¼ ç»Ÿäººå·¥æ™ºèƒ½é¢†åŸŸçš„å¹¿æ³›åº”ç”¨ã€‚NCA é€šè¿‡å°†äººå·¥ç¥ç»ç½‘ç»œ (ANNs) åµŒå…¥ä¸ºå±€éƒ¨å†³ç­–ä¸­å¿ƒï¼Œæ‰©å±•äº†ä¼ ç»Ÿçš„åŸºäºè§„åˆ™çš„ç³»ç»Ÿï¼Œèƒ½å¤Ÿç²¾ç¡®æ¨¡æ‹Ÿä»åˆ†å­ã€ç»†èƒåˆ°ç³»ç»Ÿå±‚çº§çš„è‡ªç»„ç»‡å’Œè‡ªè°ƒèŠ‚åŠ¨æ€ã€‚è¯¥æ¡†æ¶åœ¨è¿›åŒ–ã€å‘è‚²ã€å†ç”Ÿå’Œå½¢æ€å‘ç”Ÿç­‰ç”Ÿç‰©å­¦è¿‡ç¨‹ä¸­è¡¨ç°å‡ºå¼ºå¤§çš„é²æ£’æ€§ï¼Œèƒ½å¤Ÿæœ‰æ•ˆåº”å¯¹å¤–éƒ¨æ‰°åŠ¨å¹¶å®ç°å¼€æ”¾å¼é€‚åº”ä¸æ¨ç†ã€‚é™¤äº†ç”Ÿç‰©å­¦é¢†åŸŸï¼ŒNCA åœ¨æ§åˆ¶æœºå™¨äººå¤åˆå½¢æ€ä»¥åŠè§£å†³è¯¸å¦‚ ARC-AGI-1 ç­‰å‰æ²¿æ¨ç†ä»»åŠ¡æ–¹é¢ä¹Ÿå±•ç¤ºäº†å“è¶Šçš„å»ä¸­å¿ƒåŒ–ç›®æ ‡å¯¼å‘èƒ½åŠ›ã€‚ç ”ç©¶æŒ‡å‡º NCA çš„è¿­ä»£çŠ¶æ€ç»†åŒ–åŸåˆ™ä¸æ‰©æ•£æ¨¡å‹ç­‰ç°ä»£ç”Ÿæˆå¼äººå·¥æ™ºèƒ½ (AI) å…·æœ‰å†…åœ¨ç›¸ä¼¼æ€§ï¼Œæ„æˆäº†è¿æ¥å¤šå°ºåº¦ç”Ÿç‰©å­¦æ´å¯Ÿä¸ç°ä»£ AI çš„ç»Ÿä¸€èŒƒå¼ã€‚è¿™ç§è®¡ç®—ç²¾ç®€çš„æ¶æ„ä¸ºå¼€å‘å…·å¤‡åˆ†å±‚æ¨ç†å’Œæ§åˆ¶èƒ½åŠ›çš„ç”Ÿç‰©å¯å‘é›†ä½“æ™ºèƒ½å¥ å®šäº†é‡è¦åŸºç¡€ã€‚",
      "categories": [
        "cs.AI",
        "cs.MA",
        "q-bio.OT"
      ],
      "primary_category": "cs.AI",
      "comment": "",
      "pdf_url": "https://arxiv.org/pdf/2509.11131v1",
      "published_date": "2025-09-14 06:55:29 UTC",
      "updated_date": "2025-09-14 06:55:29 UTC",
      "processing_status": "completed",
      "attempts": 1,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "llm_backup_calls": 0,
      "last_update": "2026-01-24T18:29:04.167129+00:00"
    },
    {
      "arxiv_id": "2509.12275v3",
      "title": "Omni-CLST: Error-aware Curriculum Learning with guided Selective chain-of-Thought for audio question answering",
      "title_zh": "Omni-CLSTï¼šç»“åˆå¼•å¯¼å¼é€‰æ‹©æ€§é“¾å¼æ€ç»´çš„è¯¯å·®æ„ŸçŸ¥éŸ³é¢‘é—®ç­”è¯¾ç¨‹å­¦ä¹ ",
      "authors": [
        "Jinghua Zhao",
        "Hang Su",
        "Lichun Fan",
        "Zhenbo Luo",
        "Hui Wang",
        "Haoqin Sun",
        "Yong Qin"
      ],
      "abstract": "With the rapid progress of large audio-language models (LALMs), audio question answering (AQA) has emerged as a challenging task requiring both fine-grained audio understanding and complex reasoning. While current methods mainly rely on constructing new datasets via captioning or reasoning traces, existing high-quality AQA data remains underutilized. To address this, we propose Omni-CLST, an error-aware Curriculum Learning framework with guided Selective Chain-of-Thought. The framework efficiently leverages existing high-quality dataset through two key strategies: an error-aware curriculum that organizes samples by difficulty, and a guided thought dropout mechanism that focuses reasoning on challenging cases. Experiments show that Omni-CLST achieves 73.80% on MMAU-mini and a new state of the art of 64.30% on MMAR, demonstrating robust generalization in multimodal audio-language understanding.",
      "tldr_zh": "è¯¥ç ”ç©¶æå‡ºäº† Omni-CLSTï¼Œä¸€ç§ç»“åˆäº†é”™è¯¯æ„ŸçŸ¥è¯¾ç¨‹å­¦ä¹  (Error-aware Curriculum Learning) ä¸å¼•å¯¼æ€§é€‰æ‹©æ€§é“¾å¼æ€ç»´ (Guided Selective Chain-of-Thought) çš„éŸ³é¢‘é—®ç­” (Audio Question Answering, AQA) æ¡†æ¶ã€‚é’ˆå¯¹ç°æœ‰é«˜è´¨é‡ AQA æ•°æ®åˆ©ç”¨ä¸è¶³çš„é—®é¢˜ï¼Œè¯¥æ¡†æ¶é€šè¿‡æ ¹æ®æ ·æœ¬éš¾åº¦ç»„ç»‡è®­ç»ƒé¡ºåºçš„è¯¾ç¨‹å­¦ä¹ ç­–ç•¥ï¼Œä»¥åŠå°†æ¨ç†é‡ç‚¹æ”¾åœ¨æŒ‘æˆ˜æ€§æ¡ˆä¾‹ä¸Šçš„å¼•å¯¼æ€§æ€ç»´ä¸¢å¼ƒ (Guided Thought Dropout) æœºåˆ¶æ¥ä¼˜åŒ–æ¨¡å‹è®­ç»ƒã€‚å®éªŒè¡¨æ˜ï¼ŒOmni-CLST åœ¨ MMAU-mini å’Œ MMAR æ•°æ®é›†ä¸Šåˆ†åˆ«å–å¾—äº† 73.80% å’Œ 64.30% çš„ä¼˜å¼‚æˆç»©ï¼Œåˆ·æ–°äº† MMAR çš„æœ€å…ˆè¿›æ°´å¹³ (State-of-the-art)ã€‚è¿™é¡¹å·¥ä½œæ˜¾è‘—å¢å¼ºäº†å¤§å‹éŸ³é¢‘è¯­è¨€æ¨¡å‹ (LALMs) çš„ç»†ç²’åº¦éŸ³é¢‘ç†è§£ä¸å¤æ‚æ¨ç†èƒ½åŠ›ï¼Œå±•ç¤ºäº†å…¶åœ¨å¤šæ¨¡æ€ç†è§£ä»»åŠ¡ä¸­æå¼ºçš„æ³›åŒ–æ€§èƒ½ã€‚",
      "categories": [
        "cs.SD",
        "cs.AI",
        "eess.AS"
      ],
      "primary_category": "cs.SD",
      "comment": "5 pages, 1 figure, 2 tables submitted to icassp, under prereview",
      "pdf_url": "https://arxiv.org/pdf/2509.12275v3",
      "published_date": "2025-09-14 06:54:12 UTC",
      "updated_date": "2025-09-18 07:19:29 UTC",
      "processing_status": "completed",
      "attempts": 1,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "llm_backup_calls": 0,
      "last_update": "2026-01-24T18:29:30.090332+00:00"
    },
    {
      "arxiv_id": "2509.11128v1",
      "title": "ENJ: Optimizing Noise with Genetic Algorithms to Jailbreak LSMs",
      "title_zh": "ENJï¼šåˆ©ç”¨é—ä¼ ç®—æ³•ä¼˜åŒ–å™ªå£°å®ç°å¤§è¯­éŸ³æ¨¡å‹è¶Šç‹±",
      "authors": [
        "Yibo Zhang",
        "Liang Lin"
      ],
      "abstract": "The widespread application of Large Speech Models (LSMs) has made their security risks increasingly prominent. Traditional speech adversarial attack methods face challenges in balancing effectiveness and stealth. This paper proposes Evolutionary Noise Jailbreak (ENJ), which utilizes a genetic algorithm to transform environmental noise from a passive interference into an actively optimizable attack carrier for jailbreaking LSMs. Through operations such as population initialization, crossover fusion, and probabilistic mutation, this method iteratively evolves a series of audio samples that fuse malicious instructions with background noise. These samples sound like harmless noise to humans but can induce the model to parse and execute harmful commands. Extensive experiments on multiple mainstream speech models show that ENJ's attack effectiveness is significantly superior to existing baseline methods. This research reveals the dual role of noise in speech security and provides new critical insights for model security defense in complex acoustic environments.",
      "tldr_zh": "è¯¥ç ”ç©¶é’ˆå¯¹ Large Speech Models (LSMs) é¢å¯¹æ”»å‡»æœ‰æ•ˆæ€§ä¸éšè”½æ€§éš¾ä»¥å¹³è¡¡çš„æŒ‘æˆ˜ï¼Œæå‡ºäº†åä¸º Evolutionary Noise Jailbreak (ENJ) çš„æ–°æ–¹æ³•ã€‚ENJ åˆ©ç”¨ Genetic Algorithms (é—ä¼ ç®—æ³•) å°†ç¯å¢ƒå™ªå£°ä»è¢«åŠ¨å¹²æ‰°è½¬å˜ä¸ºä¸»åŠ¨ä¼˜åŒ–çš„æ”»å‡»è½½ä½“ï¼Œæ—¨åœ¨å®ç°å¯¹ LSMs çš„è¶Šç‹±æ”»å‡»ã€‚é€šè¿‡æ‰§è¡Œ Population Initialization (ç§ç¾¤åˆå§‹åŒ–)ã€Crossover Fusion (äº¤å‰èåˆ) å’Œ Probabilistic Mutation (æ¦‚ç‡å˜å¼‚) ç­‰è¿­ä»£æ“ä½œï¼Œè¯¥æ–¹æ³•èƒ½ç”Ÿæˆå°†æ¶æ„æŒ‡ä»¤éšè”½é›†æˆäºèƒŒæ™¯å™ªå£°ä¸­çš„éŸ³é¢‘æ ·æœ¬ã€‚å®éªŒç»“æœæ˜¾ç¤ºï¼Œè¿™äº›æ ·æœ¬åœ¨äººç±»å¬è§‰ä¸­ä»…ä¸ºæ™®é€šå™ªå£°ï¼Œå´èƒ½æœ‰æ•ˆè¯±å¯¼æ¨¡å‹æ‰§è¡Œæœ‰å®³å‘½ä»¤ï¼Œå…¶æ”»å‡»æ€§èƒ½åœ¨å¤šä¸ªä¸»æµè¯­éŸ³æ¨¡å‹ä¸Šå‡ä¼˜äºç°æœ‰çš„ Baseline æ–¹æ³•ã€‚æ­¤é¡¹ç ”ç©¶ä¸ä»…æ­ç¤ºäº†å™ªå£°åœ¨è¯­éŸ³å®‰å…¨é¢†åŸŸçš„æ½œåœ¨å¨èƒï¼Œä¹Ÿä¸ºæå‡å¤æ‚å£°å­¦ç¯å¢ƒä¸‹çš„æ¨¡å‹å®‰å…¨é˜²å¾¡èƒ½åŠ›æä¾›äº†é‡è¦å‚è€ƒã€‚",
      "categories": [
        "cs.SD",
        "cs.AI"
      ],
      "primary_category": "cs.SD",
      "comment": "",
      "pdf_url": "https://arxiv.org/pdf/2509.11128v1",
      "published_date": "2025-09-14 06:39:38 UTC",
      "updated_date": "2025-09-14 06:39:38 UTC",
      "processing_status": "completed",
      "attempts": 1,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "llm_backup_calls": 0,
      "last_update": "2026-01-24T18:30:16.084240+00:00"
    },
    {
      "arxiv_id": "2509.11118v1",
      "title": "We Argue to Agree: Towards Personality-Driven Argumentation-Based Negotiation Dialogue Systems for Tourism",
      "title_zh": "è¾©ä»¥æ±‚åŒï¼šé¢å‘æ—…æ¸¸é¢†åŸŸçš„ä¸ªæ€§é©±åŠ¨å‹åŸºäºè®ºè¯çš„è°ˆåˆ¤å¯¹è¯ç³»ç»Ÿ",
      "authors": [
        "Priyanshu Priya",
        "Saurav Dudhate",
        "Desai Vishesh Yasheshbhai",
        "Asif Ekbal"
      ],
      "abstract": "Integrating argumentation mechanisms into negotiation dialogue systems improves conflict resolution through exchanges of arguments and critiques. Moreover, incorporating personality attributes enhances adaptability by aligning interactions with individuals' preferences and styles. To advance these capabilities in negotiation dialogue systems, we propose a novel Personality-driven Argumentation-based Negotiation Dialogue Generation (PAN-DG) task. To support this task, we introduce PACT, a dataset of Personality-driven Argumentation-based negotiation Conversations for Tourism sector. This dataset, generated using Large Language Models (LLMs), features three distinct personality profiles, viz. Argumentation Profile, Preference Profile, and Buying Style Profile to simulate a variety of negotiation scenarios involving diverse personalities. Thorough automatic and manual evaluations indicate that the dataset comprises high-quality dialogues. Further, we conduct comparative experiments between pre-trained and fine-tuned LLMs for the PAN-DG task. Multi-dimensional evaluation demonstrates that the fine-tuned LLMs effectively generate personality-driven rational responses during negotiations. This underscores the effectiveness of PACT in enhancing personalization and reasoning capabilities in negotiation dialogue systems, thereby establishing a foundation for future research in this domain.",
      "tldr_zh": "è¯¥ç ”ç©¶æ¢è®¨äº†å°†è®ºè¯æœºåˆ¶(argumentation mechanisms)ä¸äººæ ¼å±æ€§(personality attributes)æ•´åˆåˆ°åå•†å¯¹è¯ç³»ç»Ÿä¸­ï¼Œé€šè¿‡è®ºè¯å’Œæ‰¹è¯„çš„äº¤æµæ”¹å–„å†²çªè§£å†³ï¼Œå¹¶å¢å¼ºç³»ç»Ÿå¯¹ä¸ªä½“åå¥½ä¸é£æ ¼çš„é€‚åº”æ€§ã€‚ä¸ºæ­¤ï¼Œä½œè€…æå‡ºäº†äººæ ¼é©±åŠ¨çš„åŸºäºè®ºè¯çš„åå•†å¯¹è¯ç”Ÿæˆ(PAN-DG)æ–°ä»»åŠ¡ï¼Œå¹¶æ¨å‡ºäº†ä¸“é—¨é’ˆå¯¹æ—…æ¸¸é¢†åŸŸçš„PACTæ•°æ®é›†ã€‚è¯¥æ•°æ®é›†åˆ©ç”¨å¤§è¯­è¨€æ¨¡å‹(LLMs)ç”Ÿæˆï¼Œæ¶µç›–äº†è®ºè¯ç‰¹å¾(Argumentation Profile)ã€åå¥½ç‰¹å¾(Preference Profile)å’Œè´­ä¹°é£æ ¼ç‰¹å¾(Buying Style Profile)ä¸‰ç§äººæ ¼é…ç½®æ–‡ä»¶ï¼Œä»¥æ¨¡æ‹Ÿå¤šæ ·åŒ–çš„åå•†åœºæ™¯ã€‚è‡ªåŠ¨ä¸äººå·¥è¯„ä¼°è¡¨æ˜PACTæ•°æ®é›†åŒ…å«é«˜è´¨é‡å¯¹è¯ï¼Œä¸ºå¤æ‚åå•†æä¾›äº†å¯é æ”¯æŒã€‚é€šè¿‡å¯¹æ¯”å®éªŒå‘ç°ï¼Œå¾®è°ƒåçš„LLMsåœ¨PAN-DGä»»åŠ¡ä¸­èƒ½æœ‰æ•ˆç”Ÿæˆäººæ ¼é©±åŠ¨çš„ç†æ€§å›åº”ã€‚è¿™ä¸€ç ”ç©¶è¯æ˜äº†PACTåœ¨æå‡åå•†å¯¹è¯ç³»ç»Ÿä¸ªæ€§åŒ–å’Œæ¨ç†èƒ½åŠ›æ–¹é¢çš„æœ‰æ•ˆæ€§ï¼Œä¸ºæœªæ¥ç›¸å…³é¢†åŸŸçš„ç ”ç©¶å¥ å®šäº†åšå®åŸºç¡€ã€‚",
      "categories": [
        "cs.CL",
        "cs.AI"
      ],
      "primary_category": "cs.CL",
      "comment": "Paper is accepted at EMNLP (Findings) 2025",
      "pdf_url": "https://arxiv.org/pdf/2509.11118v1",
      "published_date": "2025-09-14 06:16:42 UTC",
      "updated_date": "2025-09-14 06:16:42 UTC",
      "processing_status": "completed",
      "attempts": 1,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "llm_backup_calls": 0,
      "last_update": "2026-01-24T18:30:12.388873+00:00"
    },
    {
      "arxiv_id": "2509.11113v1",
      "title": "Application of Machine Learning for Correcting Defect-induced Neuromorphic Circuit Inference Errors",
      "title_zh": "æœºå™¨å­¦ä¹ åœ¨ä¿®æ­£ç¼ºé™·å¼•èµ·çš„ç¥ç»å½¢æ€ç”µè·¯æ¨ç†è¯¯å·®ä¸­çš„åº”ç”¨",
      "authors": [
        "Vedant Sawal",
        "Hiu Yung Wong"
      ],
      "abstract": "This paper presents a machine learning-based approach to correct inference errors caused by stuck-at faults in fully analog ReRAM-based neuromorphic circuits. Using a Design-Technology Co-Optimization (DTCO) simulation framework, we model and analyze six spatial defect types-circular, circular-complement, ring, row, column, and checkerboard-across multiple layers of a multi-array neuromorphic architecture. We demonstrate that the proposed correction method, which employs a lightweight neural network trained on the circuit's output voltages, can recover up to 35% (from 55% to 90%) inference accuracy loss in defective scenarios. Our results, based on handwritten digit recognition tasks, show that even small corrective networks can significantly improve circuit robustness. This method offers a scalable and energy-efficient path toward enhanced yield and reliability for neuromorphic systems in edge and internet-of-things (IoTs) applications. In addition to correcting the specific defect types used during training, our method also demonstrates the ability to generalize-achieving reasonable accuracy when tested on different types of defects not seen during training. The framework can be readily extended to support real-time adaptive learning, enabling on-chip correction for dynamic or aging-induced fault profiles.",
      "tldr_zh": "è¯¥ç ”ç©¶æå‡ºäº†ä¸€ç§åŸºäºæœºå™¨å­¦ä¹ çš„æ–¹æ³•ï¼Œç”¨äºçº æ­£å…¨æ¨¡æ‹Ÿ ReRAM-based neuromorphic circuits ä¸­ç”± stuck-at faults å¼•èµ·çš„æ¨ç†é”™è¯¯ã€‚åˆ©ç”¨ Design-Technology Co-Optimization (DTCO) ä»¿çœŸæ¡†æ¶ï¼Œç ”ç©¶è€…åœ¨å¤šé˜µåˆ—æ¶æ„ä¸­å¯¹åŒ…æ‹¬ circularã€rowã€column å’Œ checkerboard åœ¨å†…çš„å…­ç§ç©ºé—´ç¼ºé™·ç±»å‹è¿›è¡Œäº†å»ºæ¨¡ä¸åˆ†æã€‚é€šè¿‡åœ¨ç”µè·¯è¾“å‡ºç”µå‹ä¸Šè®­ç»ƒè½»é‡çº§ç¥ç»ç½‘ç»œï¼Œè¯¥æ–¹æ³•åœ¨æ‰‹å†™æ•°å­—è¯†åˆ«ä»»åŠ¡ä¸­æˆåŠŸå°†æ¨ç†å‡†ç¡®ç‡ä» 55% æ¢å¤è‡³ 90%ï¼Œæ˜¾è‘—æå‡äº†ç”µè·¯çš„é²æ£’æ€§ã€‚è¯¥æ–¹æ³•è¿˜å±•ç°å‡ºè‰¯å¥½çš„æ³›åŒ–èƒ½åŠ›ï¼Œèƒ½æœ‰æ•ˆå¤„ç†è®­ç»ƒä¸­æœªè§çš„ç¼ºé™·ç±»å‹ï¼Œå¹¶æ”¯æŒå®æ—¶è‡ªé€‚åº”å­¦ä¹ ä»¥åº”å¯¹åŠ¨æ€æˆ–è€åŒ–è¯±å‘çš„æ•…éšœã€‚è¿™ä¸€ç ”ç©¶ä¸ºæå‡è¾¹ç¼˜è®¡ç®—å’Œ internet-of-things (IoTs) åº”ç”¨ä¸­ç±»è„‘ç³»ç»Ÿçš„è‰¯ç‡ä¸å¯é æ€§æä¾›äº†ä¸€æ¡é«˜èƒ½æ•ˆä¸”å¯æ‰©å±•çš„è·¯å¾„ã€‚",
      "categories": [
        "cs.NE",
        "cs.AI"
      ],
      "primary_category": "cs.NE",
      "comment": "",
      "pdf_url": "https://arxiv.org/pdf/2509.11113v1",
      "published_date": "2025-09-14 06:05:27 UTC",
      "updated_date": "2025-09-14 06:05:27 UTC",
      "processing_status": "completed",
      "attempts": 1,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "llm_backup_calls": 0,
      "last_update": "2026-01-24T18:29:52.089979+00:00"
    },
    {
      "arxiv_id": "2509.11112v1",
      "title": "Multi-Modal Sensing Aided mmWave Beamforming for V2V Communications with Transformers",
      "title_zh": "åŸºäº Transformer çš„å¤šæ¨¡æ€æ„ŸçŸ¥è¾…åŠ© V2V é€šä¿¡æ¯«ç±³æ³¢æ³¢æŸæˆå½¢",
      "authors": [
        "Muhammad Baqer Mollah",
        "Honggang Wang",
        "Hua Fang"
      ],
      "abstract": "Beamforming techniques are utilized in millimeter wave (mmWave) communication to address the inherent path loss limitation, thereby establishing and maintaining reliable connections. However, adopting standard defined beamforming approach in highly dynamic vehicular environments often incurs high beam training overheads and reduces the available airtime for communications, which is mainly due to exchanging pilot signals and exhaustive beam measurements. To this end, we present a multi-modal sensing and fusion learning framework as a potential alternative solution to reduce such overheads. In this framework, we first extract the features individually from the visual and GPS coordinates sensing modalities by modality specific encoders, and subsequently fuse the multimodal features to obtain predicted top-k beams so that the best line-of-sight links can be proactively established. To show the generalizability of the proposed framework, we perform a comprehensive experiment in four different vehicle-to-vehicle (V2V) scenarios from real-world multi-modal sensing and communication dataset. From the experiment, we observe that the proposed framework achieves up to 77.58% accuracy on predicting top-15 beams correctly, outperforms single modalities, incurs roughly as low as 2.32 dB average power loss, and considerably reduces the beam searching space overheads by 76.56% for top-15 beams with respect to standard defined approach.",
      "tldr_zh": "è¯¥ç ”ç©¶é’ˆå¯¹é«˜åº¦åŠ¨æ€çš„è½¦è”ç½‘ï¼ˆV2Vï¼‰ç¯å¢ƒï¼Œæå‡ºäº†ä¸€ç§åŸºäºTransformerçš„å¤šæ¨¡æ€æ„ŸçŸ¥ä¸èåˆå­¦ä¹ æ¡†æ¶ï¼Œæ—¨åœ¨è§£å†³æ¯«ç±³æ³¢ï¼ˆmmWaveï¼‰æ³¢æŸèµ‹å½¢ï¼ˆBeamformingï¼‰è¿‡ç¨‹ä¸­ç”±é¢‘ç¹å¯¼é¢‘äº¤æ¢å’Œæ³¢æŸæµ‹é‡å¼•èµ·çš„é«˜å¼€é”€é—®é¢˜ã€‚è¯¥æ¡†æ¶åˆ©ç”¨ç‰¹å®šæ¨¡æ€çš„ç¼–ç å™¨ï¼ˆEncodersï¼‰åˆ†åˆ«ä»è§†è§‰ï¼ˆVisualï¼‰å’ŒGPSåæ ‡æ•°æ®ä¸­æå–ç‰¹å¾ï¼Œå¹¶é€šè¿‡ç‰¹å¾èåˆé¢„æµ‹å‰Kä¸ªæ³¢æŸï¼ˆtop-k beamsï¼‰ï¼Œä»è€Œå®ç°ä¸»åŠ¨å»ºç«‹æœ€ä½³è§†è·ï¼ˆLine-of-Sightï¼‰é“¾è·¯ã€‚é€šè¿‡åœ¨å››ä¸ªçœŸå®ä¸–ç•ŒV2Våœºæ™¯ä¸‹çš„å…¨é¢å®éªŒï¼Œç»“æœæ˜¾ç¤ºè¯¥æ¡†æ¶åœ¨é¢„æµ‹å‰15ä¸ªæ³¢æŸï¼ˆtop-15 beamsï¼‰æ—¶å‡†ç¡®ç‡è¾¾åˆ°77.58%ï¼Œæ€§èƒ½æ˜¾è‘—ä¼˜äºå•ä¸€æ¨¡æ€ã€‚æ­¤å¤–ï¼Œè¯¥æ–¹æ¡ˆå°†æ³¢æŸæœç´¢å¼€é”€é™ä½äº†76.56%ï¼Œä¸”å¹³å‡åŠŸç‡æŸå¤±æ§åˆ¶åœ¨2.32 dBä»¥å†…ï¼Œè¯æ˜äº†å…¶åœ¨æå‡é€šä¿¡æ•ˆç‡å’Œé™ä½ç³»ç»Ÿå¼€é”€æ–¹é¢çš„æœ‰æ•ˆæ€§ä¸æ³›åŒ–èƒ½åŠ›ã€‚",
      "categories": [
        "cs.NI",
        "cs.AI",
        "cs.ET",
        "cs.IT",
        "cs.LG"
      ],
      "primary_category": "cs.NI",
      "comment": "6 Pages, Accepted to present at 2025 IEEE Global Communications Conference (GLOBECOM), Taipei, Taiwan",
      "pdf_url": "https://arxiv.org/pdf/2509.11112v1",
      "published_date": "2025-09-14 06:03:42 UTC",
      "updated_date": "2025-09-14 06:03:42 UTC",
      "processing_status": "completed",
      "attempts": 1,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "llm_backup_calls": 0,
      "last_update": "2026-01-24T18:30:16.187645+00:00"
    },
    {
      "arxiv_id": "2509.11106v1",
      "title": "Fluid Language Model Benchmarking",
      "title_zh": "Fluid è¯­è¨€æ¨¡å‹åŸºå‡†æµ‹è¯•",
      "authors": [
        "Valentin Hofmann",
        "David Heineman",
        "Ian Magnusson",
        "Kyle Lo",
        "Jesse Dodge",
        "Maarten Sap",
        "Pang Wei Koh",
        "Chun Wang",
        "Hannaneh Hajishirzi",
        "Noah A. Smith"
      ],
      "abstract": "Language model (LM) benchmarking faces several challenges: comprehensive evaluations are costly, benchmarks often fail to measure the intended capabilities, and evaluation quality can degrade due to labeling errors and benchmark saturation. Although various strategies have been proposed to mitigate these issues, they tend to address individual aspects in isolation, neglecting broader questions about overall evaluation quality. Here, we introduce Fluid Benchmarking, a new evaluation approach that advances LM benchmarking across multiple dimensions. Inspired by psychometrics, Fluid Benchmarking is based on the insight that the relative value of benchmark items depends on an LM's capability level, suggesting that evaluation should adapt to each LM. Methodologically, Fluid Benchmarking estimates an item response model based on existing LM evaluation results and uses the inferred quantities to select evaluation items dynamically, similar to computerized adaptive testing in education. In our experiments, we compare Fluid Benchmarking against the common practice of random item sampling as well as more sophisticated baselines, including alternative methods grounded in item response theory. We examine four dimensions -- efficiency, validity, variance, and saturation -- and find that Fluid Benchmarking achieves superior performance in all of them (e.g., higher validity and less variance on MMLU with fifty times fewer items). Our analysis shows that the two components of Fluid Benchmarking have distinct effects: item response theory, used to map performance into a latent ability space, increases validity, while dynamic item selection reduces variance. Overall, our results suggest that LM benchmarking can be substantially improved by moving beyond static evaluation.",
      "tldr_zh": "è¯¥ç ”ç©¶æå‡ºäº†Fluid Benchmarkingï¼Œè¿™æ˜¯ä¸€ç§å—å¿ƒç†æµ‹é‡å­¦(Psychometrics)å¯å‘çš„æ–°å‹è¯­è¨€æ¨¡å‹(Language Model)è¯„ä¼°æ–¹æ³•ï¼Œæ—¨åœ¨è§£å†³ç°æœ‰åŸºå‡†æµ‹è¯•æˆæœ¬é«˜æ˜‚ã€æœ‰æ•ˆæ€§ä¸è¶³åŠæ˜“é¥±å’Œç­‰é—®é¢˜ã€‚è¯¥æ¡†æ¶åŸºäºé¡¹ç›®ååº”ç†è®º(Item Response Theory)æ„å»ºæ¨¡å‹ï¼Œå¹¶ç»“åˆç±»ä¼¼äºæ•™è‚²é¢†åŸŸè®¡ç®—æœºè‡ªé€‚åº”æµ‹è¯•(Computerized Adaptive Testing)çš„åŠ¨æ€é¡¹ç›®é€‰æ‹©æœºåˆ¶ï¼Œä½¿è¯„ä¼°è¿‡ç¨‹èƒ½æ ¹æ®æ¨¡å‹çš„èƒ½åŠ›æ°´å¹³å®æ—¶è°ƒæ•´ã€‚å®éªŒç»“æœè¡¨æ˜ï¼ŒFluid Benchmarkingåœ¨æ•ˆç‡(Efficiency)ã€æœ‰æ•ˆæ€§(Validity)ã€æ–¹å·®(Variance)åŠé¥±å’Œåº¦(Saturation)å››ä¸ªç»´åº¦ä¸Šå‡æ˜¾è‘—ä¼˜äºä¼ ç»Ÿéšæœºé‡‡æ ·å’ŒåŸºå‡†æ–¹æ³•ã€‚å…·ä½“è€Œè¨€ï¼Œè¯¥æ–¹æ³•åœ¨MMLUåŸºå‡†ä¸Šä»…ä½¿ç”¨äº”ååˆ†ä¹‹ä¸€çš„é¢˜ç›®é‡ä¾¿å®ç°äº†æ›´é«˜çš„æœ‰æ•ˆæ€§å’Œæ›´ä½çš„æ–¹å·®ã€‚ç ”ç©¶åˆ†ææŒ‡å‡ºï¼Œé¡¹ç›®ååº”ç†è®ºé€šè¿‡å°†æ€§èƒ½æ˜ å°„åˆ°æ½œèƒ½åŠ›ç©ºé—´æå‡äº†è¯„ä¼°çš„æœ‰æ•ˆæ€§ï¼Œè€ŒåŠ¨æ€é€‰æ‹©åˆ™æœ‰æ•ˆå‡å°‘äº†æµ‹é‡è¯¯å·®ï¼Œè¯æ˜äº†ä»é™æ€è¯„ä¼°å‘åŠ¨æ€è‡ªé€‚åº”è¯„ä¼°è½¬å‹çš„å¿…è¦æ€§ã€‚",
      "categories": [
        "cs.CL",
        "cs.AI",
        "cs.LG"
      ],
      "primary_category": "cs.CL",
      "comment": "COLM 2025",
      "pdf_url": "https://arxiv.org/pdf/2509.11106v1",
      "published_date": "2025-09-14 05:49:42 UTC",
      "updated_date": "2025-09-14 05:49:42 UTC",
      "processing_status": "completed",
      "attempts": 1,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "llm_backup_calls": 0,
      "last_update": "2026-01-24T18:30:14.489908+00:00"
    },
    {
      "arxiv_id": "2509.11092v1",
      "title": "PanoLora: Bridging Perspective and Panoramic Video Generation with LoRA Adaptation",
      "title_zh": "PanoLoraï¼šé€šè¿‡ LoRA é€‚é…è¿æ¥é€è§†ä¸å…¨æ™¯è§†é¢‘ç”Ÿæˆ",
      "authors": [
        "Zeyu Dong",
        "Yuyang Yin",
        "Yuqi Li",
        "Eric Li",
        "Hao-Xiang Guo",
        "Yikai Wang"
      ],
      "abstract": "Generating high-quality 360Â° panoramic videos remains a significant challenge due to the fundamental differences between panoramic and traditional perspective-view projections. While perspective videos rely on a single viewpoint with a limited field of view, panoramic content requires rendering the full surrounding environment, making it difficult for standard video generation models to adapt. Existing solutions often introduce complex architectures or large-scale training, leading to inefficiency and suboptimal results. Motivated by the success of Low-Rank Adaptation (LoRA) in style transfer tasks, we propose treating panoramic video generation as an adaptation problem from perspective views. Through theoretical analysis, we demonstrate that LoRA can effectively model the transformation between these projections when its rank exceeds the degrees of freedom in the task. Our approach efficiently fine-tunes a pretrained video diffusion model using only approximately 1,000 videos while achieving high-quality panoramic generation. Experimental results demonstrate that our method maintains proper projection geometry and surpasses previous state-of-the-art approaches in visual quality, left-right consistency, and motion diversity.",
      "tldr_zh": "è¯¥ç ”ç©¶æå‡ºäº†PanoLoraï¼Œæ—¨åœ¨è§£å†³360Â°å…¨æ™¯è§†é¢‘ç”Ÿæˆä¸­å› å…¨æ™¯æŠ•å½±ä¸ä¼ ç»ŸPerspective-viewæŠ•å½±ä¹‹é—´å­˜åœ¨å·¨å¤§å·®å¼‚è€Œå¯¼è‡´çš„ç”Ÿæˆéš¾é¢˜ã€‚ç ”ç©¶å›¢é˜Ÿå—Low-Rank Adaptation (LoRA)åœ¨é£æ ¼è¿ç§»ä»»åŠ¡ä¸­æˆåŠŸçš„å¯å‘ï¼Œå°†å…¨æ™¯è§†é¢‘ç”Ÿæˆè§†ä¸ºä¸€ç§ä»é€è§†å›¾å‡ºå‘çš„é€‚é…é—®é¢˜ã€‚ç†è®ºåˆ†æè¡¨æ˜ï¼Œå½“LoRAçš„ç§©è¶…è¿‡ä»»åŠ¡è‡ªç”±åº¦æ—¶ï¼Œèƒ½å¤Ÿæœ‰æ•ˆå»ºæ¨¡ä¸åŒæŠ•å½±ä¹‹é—´çš„è½¬æ¢å…³ç³»ã€‚è¯¥æ–¹æ³•ä»…éœ€ä½¿ç”¨çº¦1,000ä¸ªè§†é¢‘å¯¹é¢„è®­ç»ƒè§†é¢‘æ‰©æ•£æ¨¡å‹è¿›è¡Œé«˜æ•ˆå¾®è°ƒï¼Œå³å¯å®ç°é«˜è´¨é‡çš„å…¨æ™¯ç”Ÿæˆã€‚å®éªŒç»“æœè¯æ˜ï¼ŒPanoLoraåœ¨ç»´æŒæŠ•å½±å‡ ä½•æ­£ç¡®æ€§çš„åŸºç¡€ä¸Šï¼Œåœ¨è§†è§‰è´¨é‡ã€å·¦å³ä¸€è‡´æ€§ä»¥åŠè¿åŠ¨å¤šæ ·æ€§æ–¹é¢å‡æ˜¾è‘—è¶…è¶Šäº†ç°æœ‰çš„State-of-the-artæ–¹æ³•ã€‚",
      "categories": [
        "cs.CV",
        "cs.AI"
      ],
      "primary_category": "cs.CV",
      "comment": "",
      "pdf_url": "https://arxiv.org/pdf/2509.11092v1",
      "published_date": "2025-09-14 05:05:27 UTC",
      "updated_date": "2025-09-14 05:05:27 UTC",
      "processing_status": "completed",
      "attempts": 1,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "llm_backup_calls": 0,
      "last_update": "2026-01-24T18:30:28.583022+00:00"
    },
    {
      "arxiv_id": "2509.11084v1",
      "title": "Length-Aware Rotary Position Embedding for Text-Speech Alignment",
      "title_zh": "é¢å‘æ–‡æœ¬-è¯­éŸ³å¯¹é½çš„é•¿åº¦æ„ŸçŸ¥æ—‹è½¬ä½ç½®åµŒå…¥",
      "authors": [
        "Hyeongju Kim",
        "Juheon Lee",
        "Jinhyeok Yang",
        "Jacob Morton"
      ],
      "abstract": "Many recent text-to-speech (TTS) systems are built on transformer architectures and employ cross-attention mechanisms for text-speech alignment. Within these systems, rotary position embedding (RoPE) is commonly used to encode positional information in text and speech representations. In this work, we introduce length-aware RoPE (LARoPE), a simple yet effective extension of RoPE that improves text-speech alignment. Unlike RoPE, which relies on absolute indices, LARoPE computes relative distances between query and key positions using length-normalized indices. Experimental results show that LARoPE consistently outperforms RoPE, offering faster loss convergence, more accurate text-speech alignment, and higher overall TTS quality. Furthermore, LARoPE demonstrates greater resilience to variations in utterance duration and maintains stable performance in extended speech generation up to 30 seconds, whereas RoPE suffers from notable degradation. Notably, our method achieves a state-of-the-art word error rate on a standard zero-shot TTS benchmark.",
      "tldr_zh": "æœ¬ç ”ç©¶æå‡ºäº†Length-Aware Rotary Position Embedding (LARoPE)ï¼Œè¿™æ˜¯ä¸€ç§æ—¨åœ¨ä¼˜åŒ–æ–‡æœ¬-è¯­éŸ³å¯¹é½(text-speech alignment)çš„RoPEæ‰©å±•æ–¹æ³•ã€‚ä¸åŸºäºç»å¯¹ç´¢å¼•çš„ä¼ ç»ŸRoPEä¸åŒï¼ŒLARoPEåˆ©ç”¨é•¿åº¦å½’ä¸€åŒ–ç´¢å¼•(length-normalized indices)è®¡ç®—queryä¸keyä¹‹é—´çš„ç›¸å¯¹è·ç¦»ï¼Œä»è€Œæ”¹è¿›äº†Transformeræ¶æ„ä¸­çš„äº¤å‰æ³¨æ„åŠ›æœºåˆ¶ã€‚å®éªŒæ•°æ®è¯æ˜ï¼ŒLARoPEåœ¨æŸå¤±æ”¶æ•›é€Ÿåº¦ã€å¯¹é½ç²¾ç¡®åº¦åŠæ•´ä½“TTSè´¨é‡ä¸Šå‡æ˜¾è‘—ä¼˜äºRoPEã€‚æ­¤å¤–ï¼Œè¯¥æ–¹æ³•åœ¨åº”å¯¹ä¸åŒè¯­éŸ³æ—¶é•¿å˜åŒ–æ—¶è¡¨ç°å‡ºæå¼ºçš„é²æ£’æ€§ï¼Œèƒ½å¤Ÿåœ¨é•¿è¾¾30ç§’çš„é•¿è¯­éŸ³ç”Ÿæˆä¸­ä¿æŒæ€§èƒ½ç¨³å®šï¼Œæœ‰æ•ˆè§£å†³äº†RoPEåœ¨é•¿åºåˆ—ä¸‹å‡ºç°çš„æ€§èƒ½é€€åŒ–é—®é¢˜ã€‚æœ€ç»ˆï¼Œè¯¥æ–¹æ³•åœ¨æ ‡å‡†çš„zero-shot TTSåŸºå‡†æµ‹è¯•ä¸­å–å¾—äº†state-of-the-artçš„å•è¯é”™è¯¯ç‡(WER)è¡¨ç°ã€‚",
      "categories": [
        "eess.AS",
        "cs.AI",
        "cs.CL",
        "cs.SD"
      ],
      "primary_category": "eess.AS",
      "comment": "5 pages, 3 figures, preprint",
      "pdf_url": "https://arxiv.org/pdf/2509.11084v1",
      "published_date": "2025-09-14 04:25:13 UTC",
      "updated_date": "2025-09-14 04:25:13 UTC",
      "processing_status": "completed",
      "attempts": 1,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "llm_backup_calls": 0,
      "last_update": "2026-01-24T18:30:36.790844+00:00"
    },
    {
      "arxiv_id": "2509.11080v3",
      "title": "Membership Inference Attacks on Recommender System: A Survey",
      "title_zh": "æ¨èç³»ç»Ÿæˆå‘˜æ¨ç†æ”»å‡»ç»¼è¿°",
      "authors": [
        "Jiajie He",
        "Xintong Chen",
        "Xinyang Fang",
        "Min-Chun Chen",
        "Yuechun Gu",
        "Keke Chen"
      ],
      "abstract": "Recommender systems (RecSys) have been widely applied to various applications, including E-commerce, finance, healthcare, social media and have become increasingly influential in shaping user behavior and decision-making, highlighting their growing impact in various domains. However, recent studies have shown that RecSys are vulnerable to membership inference attacks (MIAs), which aim to infer whether user interaction record was used to train a target model or not. MIAs on RecSys models can directly lead to a privacy breach. For example, via identifying the fact that a purchase record that has been used to train a RecSys associated with a specific user, an attacker can infer that user's special quirks. In recent years, MIAs have been shown to be effective on other ML tasks, e.g., classification models and natural language processing. However, traditional MIAs are ill-suited for RecSys due to the unseen posterior probability. Although MIAs on RecSys form a newly emerging and rapidly growing research area, there has been no systematic survey on this topic yet. In this article, we conduct the first comprehensive survey on RecSys MIAs. This survey offers a comprehensive review of the latest advancements in RecSys MIAs, exploring the design principles, challenges, attack and defense associated with this emerging field. We provide a unified taxonomy that categorizes different RecSys MIAs based on their characterizations and discuss their pros and cons. Based on the limitations and gaps identified in this survey, we point out several promising future research directions to inspire the researchers who wish to follow this area. This survey not only serves as a reference for the research community but also provides a clear description for researchers outside this research domain.",
      "tldr_zh": "è¯¥æ–‡ç« é’ˆå¯¹æ¨èç³»ç»Ÿ(Recommender Systems, RecSys)ä¸­çš„æˆå‘˜æ¨ç†æ”»å‡»(Membership Inference Attacks, MIAs)è¿›è¡Œäº†é¦–æ¬¡ç³»ç»Ÿçš„æ–‡çŒ®ç»¼è¿°ã€‚ç ”ç©¶å¼ºè°ƒäº†æ¨èç³»ç»Ÿåœ¨å„é¢†åŸŸå¹¿æ³›åº”ç”¨ä¸­æ‰€é¢ä¸´çš„éšç§æ³„éœ²é£é™©ï¼Œç‰¹åˆ«æ˜¯æ”»å‡»è€…å¯èƒ½é€šè¿‡MIAsæ¨æ–­ç‰¹å®šç”¨æˆ·æ•°æ®æ˜¯å¦è¢«ç”¨äºè®­ç»ƒæ¨¡å‹ï¼Œä»è€Œè·å–ç”¨æˆ·æ•æ„Ÿä¿¡æ¯ã€‚æ–‡ç« æŒ‡å‡ºç”±äºæ¨èç³»ç»Ÿçš„åéªŒæ¦‚ç‡å¾€å¾€ä¸å¯è§ï¼Œä¼ ç»Ÿçš„MIAsæ–¹æ³•åœ¨RecSysåœºæ™¯ä¸‹å¹¶ä¸å®Œå…¨é€‚ç”¨ã€‚è¯¥ç»¼è¿°å…¨é¢å›é¡¾äº†RecSys MIAsçš„æœ€æ–°è¿›å±•ï¼Œè¯¦ç»†æ¢è®¨äº†è®¾è®¡åŸåˆ™ã€æŠ€æœ¯æŒ‘æˆ˜ä»¥åŠç°æœ‰çš„æ”»å‡»ä¸é˜²å¾¡ç­–ç•¥ã€‚ä½œè€…æå‡ºäº†ä¸€ä¸ªç»Ÿä¸€çš„åˆ†ç±»æ³•(Taxonomy)ï¼Œå¯¹ä¸åŒç‰¹å¾çš„æ”»å‡»æ‰‹æ®µè¿›è¡Œäº†åˆ†ç±»å¹¶æ·±å…¥è®¨è®ºäº†å…¶ä¼˜ç¼ºç‚¹ã€‚æœ€åï¼Œæ–‡ç« æ€»ç»“äº†å½“å‰ç ”ç©¶çš„å±€é™æ€§ï¼Œå¹¶ä¸ºè¯¥é¢†åŸŸçš„æœªæ¥ç ”ç©¶æ–¹å‘æä¾›äº†å‰ç»æ€§çš„è§è§£ï¼Œä¸ºå­¦æœ¯ç•Œæä¾›äº†é‡è¦çš„å‚è€ƒèµ„æºã€‚",
      "categories": [
        "cs.IR",
        "cs.AI",
        "cs.CR"
      ],
      "primary_category": "cs.IR",
      "comment": "under review in ACM Survey",
      "pdf_url": "https://arxiv.org/pdf/2509.11080v3",
      "published_date": "2025-09-14 04:06:03 UTC",
      "updated_date": "2026-01-08 00:15:19 UTC",
      "processing_status": "completed",
      "attempts": 1,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "llm_backup_calls": 0,
      "last_update": "2026-01-24T18:30:34.588559+00:00"
    },
    {
      "arxiv_id": "2509.18133v4",
      "title": "Self-Evolving LLMs via Continual Instruction Tuning",
      "title_zh": "åŸºäºæŒç»­æŒ‡ä»¤å¾®è°ƒçš„è‡ªè¿›åŒ–å¤§è¯­è¨€æ¨¡å‹",
      "authors": [
        "Jiazheng Kang",
        "Le Huang",
        "Cheng Hou",
        "Zhe Zhao",
        "Zhenxiang Yan",
        "Ting Bai"
      ],
      "abstract": "In real-world industrial settings, large language models (LLMs) must learn continually to keep pace with diverse and evolving tasks, requiring self-evolution to refine knowledge under dynamic data distributions. However, existing continual learning (CL) approaches, such as replay and parameter isolation, often suffer from catastrophic forgetting: training on new tasks degrades performance on earlier ones by overfitting to the new distribution and weakening generalization.We propose MoE-CL, a parameter-efficient adversarial mixture-of-experts framework for industrial-scale, self-evolving continual instruction tuning of LLMs. MoE-CL uses a dual-expert design: (1) a dedicated LoRA expert per task to preserve task-specific knowledge via parameter independence, mitigating forgetting; and (2) a shared LoRA expert to enable cross-task transfer. To prevent transferring task-irrelevant noise through the shared pathway, we integrate a task-aware discriminator within a GAN. The discriminator encourages the shared expert to pass only task-aligned information during sequential training. Through adversarial learning, the shared expert acquires generalized representations that mimic the discriminator, while dedicated experts retain task-specific details, balancing knowledge retention and cross-task generalization and thereby supporting self-evolution.Extensive experiments on the public MTL5 benchmark and an industrial Tencent3 benchmark validate the effectiveness of MoE-CL for continual instruction tuning. In real-world A/B testing for content compliance review on the Tencent Video platform, MoE-CL reduced manual review costs by 15.3%. These results demonstrate that MoE-CL is practical for large-scale industrial deployment where continual adaptation and stable transfer are critical.",
      "tldr_zh": "è¯¥ç ”ç©¶æå‡ºäº†MoE-CLï¼Œä¸€ç§é’ˆå¯¹å¤§è§„æ¨¡å·¥ä¸šåœºæ™¯è®¾è®¡çš„å‚æ•°é«˜æ•ˆå¯¹æŠ—å¼æ··åˆä¸“å®¶(Mixture-of-Experts)æ¡†æ¶ï¼Œæ—¨åœ¨è§£å†³å¤§è¯­è¨€æ¨¡å‹(LLMs)åœ¨æŒç»­æŒ‡ä»¤å¾®è°ƒ(Continual Instruction Tuning)è¿‡ç¨‹ä¸­é¢ä¸´çš„ç¾éš¾æ€§é—å¿˜(Catastrophic Forgetting)é—®é¢˜ã€‚è¯¥æ¡†æ¶é‡‡ç”¨åŒä¸“å®¶è®¾è®¡ï¼Œé€šè¿‡ä¸ºæ¯ä¸ªä»»åŠ¡é…ç½®ä¸“ç”¨çš„LoRAä¸“å®¶ä»¥ä¿ç•™ç‰¹å®šä»»åŠ¡çŸ¥è¯†ï¼ŒåŒæ—¶åˆ©ç”¨å…±äº«çš„LoRAä¸“å®¶ä¿ƒè¿›è·¨ä»»åŠ¡çš„çŸ¥è¯†è¿ç§»ã€‚ä¸ºäº†é˜²æ­¢ä»»åŠ¡æ— å…³å™ªå£°åœ¨å…±äº«è·¯å¾„ä¸­ä¼ é€’ï¼Œç ”ç©¶åœ¨æ¶æ„ä¸­é›†æˆäº†ä»»åŠ¡æ„ŸçŸ¥åˆ¤åˆ«å™¨(Task-aware Discriminator)ï¼Œåˆ©ç”¨ç”Ÿæˆå¯¹æŠ—ç½‘ç»œ(GAN)çš„æ€æƒ³å¼•å¯¼å…±äº«ä¸“å®¶ä»…æ•è·æ³›åŒ–è¡¨å¾ã€‚åœ¨MTL5å’Œå·¥ä¸šçº§Tencent3åŸºå‡†æµ‹è¯•ä¸Šçš„å®éªŒå……åˆ†éªŒè¯äº†MoE-CLçš„æœ‰æ•ˆæ€§ï¼Œå…¶åœ¨è…¾è®¯è§†é¢‘å¹³å°å†…å®¹å®¡æ ¸çš„å®é™…A/Bæµ‹è¯•ä¸­å°†äººå·¥å®¡æ ¸æˆæœ¬é™ä½äº†15.3%ã€‚è¯¥ç ”ç©¶è¯æ˜äº†MoE-CLåœ¨éœ€è¦æŒç»­æ¼”åŒ–å’Œç¨³å®šè¿ç§»çš„å¤§è§„æ¨¡å·¥ä¸šéƒ¨ç½²ä¸­å…·æœ‰æé«˜çš„å®ç”¨ä»·å€¼ã€‚",
      "categories": [
        "cs.LG",
        "cs.AI"
      ],
      "primary_category": "cs.LG",
      "comment": "",
      "pdf_url": "https://arxiv.org/pdf/2509.18133v4",
      "published_date": "2025-09-14 04:04:19 UTC",
      "updated_date": "2025-10-15 02:31:11 UTC",
      "processing_status": "completed",
      "attempts": 1,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "llm_backup_calls": 0,
      "last_update": "2026-01-24T18:30:37.286175+00:00"
    },
    {
      "arxiv_id": "2509.11079v4",
      "title": "Difficulty-Aware Agentic Orchestration for Query-Specific Multi-Agent Workflows",
      "title_zh": "é¢å‘ç‰¹å®šæŸ¥è¯¢å¤šæ™ºèƒ½ä½“å·¥ä½œæµçš„éš¾åº¦æ„ŸçŸ¥æ™ºèƒ½ä½“ç¼–æ’",
      "authors": [
        "Jinwei Su",
        "Qizhen Lan",
        "Yinghui Xia",
        "Lifan Sun",
        "Weiyou Tian",
        "Tianyu Shi",
        "Xinyuan Song",
        "Lewei He"
      ],
      "abstract": "Large Language Model (LLM)-based agentic systems have shown strong capabilities across various tasks. However, existing multi-agent frameworks often rely on static or task-level workflows, which either over-process simple queries or underperform on complex ones, while also neglecting the efficiency-performance trade-offs across heterogeneous LLMs. To address these limitations, we propose Difficulty-Aware Agentic Orchestration (DAAO), which can dynamically generate query-specific multi-agent workflows guided by predicted query difficulty. DAAO comprises three interdependent modules: a variational autoencoder (VAE) for difficulty estimation, a modular operator allocator, and a cost- and performance-aware LLM router. A self-adjusting policy updates difficulty estimates based on workflow success, enabling simpler workflows for easy queries and more complex strategies for harder ones. Experiments on six benchmarks demonstrate that DAAO surpasses prior multi-agent systems in both accuracy and inference efficiency, validating its effectiveness for adaptive, difficulty-aware reasoning.",
      "tldr_zh": "è¯¥ç ”ç©¶æå‡ºäº†Difficulty-Aware Agentic Orchestration (DAAO)ï¼Œæ—¨åœ¨è§£å†³ç°æœ‰åŸºäºå¤§è¯­è¨€æ¨¡å‹(LLM)çš„å¤šæ™ºèƒ½ä½“æ¡†æ¶å› ä¾èµ–é™æ€æˆ–ä»»åŠ¡çº§å·¥ä½œæµï¼Œè€Œéš¾ä»¥å¹³è¡¡ç®€å•ä¸å¤æ‚æŸ¥è¯¢çš„æ•ˆç‡ä¸æ€§èƒ½é—®é¢˜ã€‚DAAO é€šè¿‡é¢„æµ‹æŸ¥è¯¢éš¾åº¦ï¼ŒåŠ¨æ€ç”Ÿæˆç‰¹å®šäºæŸ¥è¯¢çš„å¤šæ™ºèƒ½ä½“å·¥ä½œæµã€‚è¯¥æ¡†æ¶ç”±ä¸‰ä¸ªæ ¸å¿ƒæ¨¡å—ç»„æˆï¼šç”¨äºéš¾åº¦ä¼°è®¡çš„å˜åˆ†è‡ªç¼–ç å™¨(VAE)ã€æ¨¡å—åŒ–ç®—å­åˆ†é…å™¨(modular operator allocator)ä»¥åŠå…¼é¡¾æˆæœ¬ä¸æ€§èƒ½çš„ LLM è·¯ç”±å™¨(LLM router)ã€‚é€šè¿‡ä¸€ç§è‡ªæˆ‘è°ƒèŠ‚ç­–ç•¥ï¼Œç³»ç»Ÿèƒ½æ ¹æ®å·¥ä½œæµæ‰§è¡Œç»“æœåŠ¨æ€æ›´æ–°éš¾åº¦ä¼°è®¡ï¼Œç¡®ä¿å¯¹ç®€å•æŸ¥è¯¢ä½¿ç”¨é«˜æ•ˆæµç¨‹ï¼Œå¯¹å¤æ‚æŸ¥è¯¢é‡‡ç”¨æ·±å…¥ç­–ç•¥ã€‚å®éªŒè¯æ˜ï¼ŒDAAO åœ¨å…­ä¸ªåŸºå‡†æµ‹è¯•ä¸­çš„å‡†ç¡®ç‡å’Œæ¨ç†æ•ˆç‡å‡æ˜¾è‘—è¶…è¶Šäº†ä»¥å¾€çš„å¤šæ™ºèƒ½ä½“ç³»ç»Ÿï¼ŒéªŒè¯äº†å…¶åœ¨è‡ªé€‚åº”éš¾åº¦æ„ŸçŸ¥æ¨ç†æ–¹é¢çš„å“è¶Šèƒ½åŠ›ã€‚",
      "categories": [
        "cs.AI"
      ],
      "primary_category": "cs.AI",
      "comment": "",
      "pdf_url": "https://arxiv.org/pdf/2509.11079v4",
      "published_date": "2025-09-14 03:57:43 UTC",
      "updated_date": "2025-12-08 06:37:01 UTC",
      "processing_status": "completed",
      "attempts": 1,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "llm_backup_calls": 0,
      "last_update": "2026-01-24T18:30:51.750668+00:00"
    },
    {
      "arxiv_id": "2509.11078v2",
      "title": "Patient-Zero: Scaling Synthetic Patient Agents to Real-World Distributions without Real Patient Data",
      "title_zh": "Patient-Zeroï¼šåœ¨æ— çœŸå®æ‚£è€…æ•°æ®çš„æƒ…å†µä¸‹å°†åˆæˆæ‚£è€…æ™ºèƒ½ä½“æ‰©å±•è‡³çœŸå®ä¸–ç•Œåˆ†å¸ƒ",
      "authors": [
        "Yunghwei Lai",
        "Ziyue Wang",
        "Weizhi Ma",
        "Yang Liu"
      ],
      "abstract": "Synthetic data generation with Large Language Models (LLMs) has emerged as a promising solution in the medical domain to mitigate data scarcity and privacy constraints. However, existing approaches remain constrained by their derivative nature, relying on real-world records, which pose privacy risks and distribution biases. Furthermore, current patient agents face the Stability-Plasticity Dilemma, struggling to maintain clinical consistency during dynamic inquiries. To address these challenges, we introduce Patient-Zero, a novel framework for ab initio patient simulation that requires no real medical records. Our Medically-Aligned Hierarchical Synthesis framework generates comprehensive and diverse patient records from abstract clinical guidelines via stratified attribute permutation. To support rigorous clinical interaction, we design a Dual-Track Cognitive Memory System to enable agents dynamically update memory while preserving logical consistency and persona adherence. Extensive evaluations show that Patient-Zero establishes a new state-of-the-art in both data quality and interaction fidelity. In human expert evaluations, senior licensed physicians judge our synthetic data to be statistically indistinguishable from real human-authored data and higher in clinical quality. Furthermore, downstream medical reasoning model trained on our synthetic dataset shows substantial performance gains (MedQA +24.0%; MMLU +14.5%), demonstrating the practical utility of our framework.",
      "tldr_zh": "è¯¥ç ”ç©¶é’ˆå¯¹åŒ»ç–—é¢†åŸŸä¸­ç”±äºä¾èµ–çœŸå®ç—…å†å¯¼è‡´çš„æ•°æ®ç¨€ç¼ºã€éšç§é£é™©åŠåˆ†å¸ƒåå·®ç­‰é—®é¢˜ï¼Œæå‡ºäº† Patient-Zero æ¡†æ¶ã€‚Patient-Zero é‡‡ç”¨äº†ä¸€ç§ä»å¤´å¼€å§‹(ab initio)çš„æ¨¡æ‹Ÿæ–¹æ³•ï¼Œæ— éœ€ä»»ä½•çœŸå®åŒ»ç–—è®°å½•å³å¯ç”Ÿæˆåˆæˆç—…äººæ™ºèƒ½ä½“ã€‚å…¶æ ¸å¿ƒåŒ…å« Medically-Aligned Hierarchical Synthesis æ¡†æ¶ï¼Œé€šè¿‡å¯¹æŠ½è±¡ä¸´åºŠæŒ‡å—è¿›è¡Œåˆ†å±‚å±æ€§æ’åˆ—ï¼Œç”Ÿæˆå…¨é¢ä¸”å¤šæ ·åŒ–çš„ç—…å†æ•°æ®ã€‚ä¸ºäº†æ”¯æŒåŠ¨æ€çš„ä¸´åºŠäº¤äº’å¹¶è§£å†³ç¨³å®šæ€§-å¡‘æ€§å›°å¢ƒ(Stability-Plasticity Dilemma)ï¼Œè¯¥æ¡†æ¶è®¾è®¡äº† Dual-Track Cognitive Memory Systemï¼Œç¡®ä¿æ™ºèƒ½ä½“åœ¨æ›´æ–°è®°å¿†æ—¶ç»´æŒé€»è¾‘ä¸€è‡´æ€§å’Œäººæ ¼å¿ è¯šåº¦ã€‚å®éªŒè¯„ä¼°æ˜¾ç¤ºï¼ŒPatient-Zero åœ¨æ•°æ®è´¨é‡å’Œäº¤äº’ä¿çœŸåº¦ä¸Šå‡è¾¾åˆ°é¢†å…ˆæ°´å¹³(SOTA)ï¼Œæ‰§ä¸šåŒ»ç”Ÿåœ¨è¯„ä¼°ä¸­è®¤ä¸ºå…¶åˆæˆæ•°æ®åœ¨ä¸´åºŠè´¨é‡ä¸Šç”šè‡³ä¼˜äºçœŸäººæ’°å†™çš„æ•°æ®ã€‚æ­¤å¤–ï¼Œä½¿ç”¨è¯¥åˆæˆæ•°æ®é›†è®­ç»ƒçš„åŒ»ç–—æ¨ç†æ¨¡å‹åœ¨ MedQA å’Œ MMLU ä»»åŠ¡ä¸Šçš„è¡¨ç°åˆ†åˆ«æå‡äº† 24.0% å’Œ 14.5%ï¼Œå……åˆ†è¯æ˜äº†è¯¥æ¡†æ¶åœ¨å®é™…åŒ»ç–—AIè®­ç»ƒä¸­çš„å®ç”¨ä»·å€¼ã€‚",
      "categories": [
        "cs.AI"
      ],
      "primary_category": "cs.AI",
      "comment": "",
      "pdf_url": "https://arxiv.org/pdf/2509.11078v2",
      "published_date": "2025-09-14 03:56:00 UTC",
      "updated_date": "2026-01-06 13:16:06 UTC",
      "processing_status": "completed",
      "attempts": 1,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "llm_backup_calls": 0,
      "last_update": "2026-01-24T18:30:53.354223+00:00"
    },
    {
      "arxiv_id": "2509.19330v2",
      "title": "LibEMER: A novel benchmark and algorithms library for EEG-based Multimodal Emotion Recognition",
      "title_zh": "LibEMERï¼šä¸€ç§é¢å‘åŸºäºè„‘ç”µå¤šæ¨¡æ€æƒ…æ„Ÿè¯†åˆ«çš„æ–°å‹åŸºå‡†ä¸ç®—æ³•åº“",
      "authors": [
        "Zejun Liu",
        "Yunshan Chen",
        "Chengxi Xie",
        "Yugui Xie",
        "Huan Liu"
      ],
      "abstract": "EEG-based multimodal emotion recognition(EMER) has gained significant attention and witnessed notable advancements, the inherent complexity of human neural systems has motivated substantial efforts toward multimodal approaches. However, this field currently suffers from three critical limitations: (i) the absence of open-source implementations. (ii) the lack of standardized and transparent benchmarks for fair performance analysis. (iii) in-depth discussion regarding main challenges and promising research directions is a notable scarcity. To address these challenges, we introduce LibEMER, a unified evaluation framework that provides fully reproducible PyTorch implementations of curated deep learning methods alongside standardized protocols for data preprocessing, model realization, and experimental setups. This framework enables unbiased performance assessment on three widely-used public datasets across two learning tasks. The open-source library is publicly accessible at: https://anonymous.4open.science/r/2025ULUIUBUEUMUEUR485384",
      "tldr_zh": "è¯¥ç ”ç©¶é’ˆå¯¹åŸºäºè„‘ç”µå›¾çš„å¤šæ¨¡æ€æƒ…ç»ªè¯†åˆ«(EEG-based Multimodal Emotion Recognition, EMER)é¢†åŸŸä¸­ç¼ºä¹å¼€æºå®ç°ã€æ ‡å‡†åŒ–åŸºå‡†ä»¥åŠé€æ˜è¯„ä¼°åè®®ç­‰æŒ‘æˆ˜ï¼Œæå‡ºäº†LibEMERæ¡†æ¶ã€‚LibEMERæ˜¯ä¸€ä¸ªç»Ÿä¸€çš„è¯„ä¼°æ¡†æ¶ï¼Œæä¾›äº†åŸºäºPyTorchçš„å¯å¤ç°æ·±åº¦å­¦ä¹ æ–¹æ³•å®ç°ï¼Œå¹¶æ¶µç›–äº†æ ‡å‡†åŒ–çš„æ•°æ®é¢„å¤„ç†(Data Preprocessing)ã€æ¨¡å‹æ„å»ºå’Œå®éªŒè®¾ç½®åè®®ã€‚è¯¥æ¡†æ¶åœ¨ä¸‰ä¸ªå¹¿æ³›ä½¿ç”¨çš„å…¬å…±æ•°æ®é›†ä¸Šé’ˆå¯¹ä¸¤é¡¹å­¦ä¹ ä»»åŠ¡è¿›è¡Œäº†æ— åçš„æ€§èƒ½è¯„ä¼°ï¼Œæ—¨åœ¨æ¶ˆé™¤å®éªŒè®¾ç½®ä¸ä¸€è‡´å¸¦æ¥çš„è¯„ä¼°åå·®ã€‚é€šè¿‡å»ºç«‹è¿™ä¸ªæ ‡å‡†åŒ–çš„å¼€æºç®—æ³•åº“ï¼ŒLibEMERæœ‰æ•ˆå¡«è¡¥äº†é¢†åŸŸå†…ç¼ºä¹å…¬å¹³æ€§èƒ½å¯¹æ¯”å·¥å…·çš„ç©ºç™½ã€‚è¯¥å·¥ä½œä¸ä»…ä¸ºç ”ç©¶è€…æä¾›äº†å¯é çš„åŸºå‡†å·¥å…·ï¼Œè¿˜ä¿ƒè¿›äº†å¯¹äººç±»å¤æ‚ç¥ç»ç³»ç»Ÿå»ºæ¨¡ä¸­æ ¸å¿ƒæŒ‘æˆ˜çš„æ·±å…¥æ¢è®¨ã€‚ç›®å‰è¯¥åº“å·²å®Œå…¨å¯¹å¤–å¼€æ”¾ï¼Œä¸ºå¯è§£é‡Šå’Œå¯å¤ç°çš„æƒ…ç»ªè¯†åˆ«ç ”ç©¶å¥ å®šäº†æŠ€æœ¯åŸºç¡€ã€‚",
      "categories": [
        "eess.SP",
        "cs.AI",
        "cs.HC",
        "cs.LG",
        "cs.MM"
      ],
      "primary_category": "eess.SP",
      "comment": "5 pages, 2 figures",
      "pdf_url": "https://arxiv.org/pdf/2509.19330v2",
      "published_date": "2025-09-14 03:50:07 UTC",
      "updated_date": "2025-10-15 06:46:18 UTC",
      "processing_status": "completed",
      "attempts": 1,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "llm_backup_calls": 0,
      "last_update": "2026-01-24T18:31:08.151409+00:00"
    },
    {
      "arxiv_id": "2509.12274v1",
      "title": "Developing an aeroponic smart experimental greenhouse for controlling irrigation and plant disease detection using deep learning and IoT",
      "title_zh": "åŸºäºæ·±åº¦å­¦ä¹ ä¸ç‰©è”ç½‘çš„çŒæº‰æ§åˆ¶åŠæ¤ç‰©ç—…å®³æ£€æµ‹æ°”é›¾åŸ¹æ™ºèƒ½å®éªŒæ¸©å®¤ç ”åˆ¶",
      "authors": [
        "Mohammadreza Narimani",
        "Ali Hajiahmad",
        "Ali Moghimi",
        "Reza Alimardani",
        "Shahin Rafiee",
        "Amir Hossein Mirzabe"
      ],
      "abstract": "Controlling environmental conditions and monitoring plant status in greenhouses is critical to promptly making appropriate management decisions aimed at promoting crop production. The primary objective of this research study was to develop and test a smart aeroponic greenhouse on an experimental scale where the status of Geranium plant and environmental conditions are continuously monitored through the integration of the internet of things (IoT) and artificial intelligence (AI). An IoT-based platform was developed to control the environmental conditions of plants more efficiently and provide insights to users to make informed management decisions. In addition, we developed an AI-based disease detection framework using VGG-19, InceptionResNetV2, and InceptionV3 algorithms to analyze the images captured periodically after an intentional inoculation. The performance of the AI framework was compared with an expert's evaluation of disease status. Preliminary results showed that the IoT system implemented in the greenhouse environment is able to publish data such as temperature, humidity, water flow, and volume of charge tanks online continuously to users and adjust the controlled parameters to provide an optimal growth environment for the plants. Furthermore, the results of the AI framework demonstrate that the VGG-19 algorithm was able to identify drought stress and rust leaves from healthy leaves with the highest accuracy, 92% among the other algorithms.",
      "tldr_zh": "è¯¥ç ”ç©¶å¼€å‘å¹¶æµ‹è¯•äº†ä¸€ä¸ªå®éªŒè§„æ¨¡çš„æ°”é›¾åŸ¹(Aeroponic)æ™ºèƒ½æ¸©å®¤ï¼Œé€šè¿‡æ•´åˆç‰©è”ç½‘(IoT)å’Œäººå·¥æ™ºèƒ½(AI)æŠ€æœ¯å®ç°çŒæº‰æ§åˆ¶ä¸æ¤ç‰©ç—…å®³æ£€æµ‹ã€‚ç ”ç©¶å»ºç«‹äº†ä¸€ä¸ªåŸºäºIoTçš„å¹³å°ï¼Œèƒ½å¤ŸæŒç»­ç›‘æ§å¹¶åœ¨çº¿å‘å¸ƒæ¸©åº¦ã€æ¹¿åº¦ã€æ°´æµé‡å’Œå‚¨æ¶²ç½ä½“ç§¯ç­‰ç¯å¢ƒæ•°æ®ï¼Œä»¥å®æ—¶ä¼˜åŒ–å¤©ç«ºè‘µ(Geranium)çš„ç”Ÿé•¿ç¯å¢ƒã€‚åœ¨ç—…å®³æ£€æµ‹æ–¹é¢ï¼Œç ”ç©¶åˆ©ç”¨VGG-19ã€InceptionResNetV2å’ŒInceptionV3ç®—æ³•æ„å»ºäº†æ·±åº¦å­¦ä¹ æ¡†æ¶ï¼Œç”¨äºè¯†åˆ«å—æ§æ¥ç§åçš„æ¤ç‰©å›¾åƒã€‚å®éªŒç»“æœè¡¨æ˜ï¼ŒIoTç³»ç»Ÿèƒ½å¤Ÿæœ‰æ•ˆè°ƒèŠ‚ç¯å¢ƒå‚æ•°å¹¶æä¾›å†³ç­–æ”¯æŒï¼Œè€ŒVGG-19ç®—æ³•åœ¨è¯†åˆ«å¹²æ—±å‹åŠ›å’Œé”ˆç—…å¶ç‰‡æ–¹é¢è¡¨ç°æœ€ä¼˜ï¼Œå‡†ç¡®ç‡è¾¾åˆ°92%ã€‚è¯¥ç ”ç©¶è¯æ˜äº†ç»“åˆIoTç›‘æ§ä¸AIè¯Šæ–­åœ¨æå‡ä½œç‰©ç”Ÿäº§ç®¡ç†æ•ˆç‡æ–¹é¢çš„æ˜¾è‘—æ½œåŠ›ã€‚",
      "categories": [
        "cs.AI",
        "cs.CV",
        "cs.LG"
      ],
      "primary_category": "cs.AI",
      "comment": "Author-accepted version. Presented at ASABE Annual International Meeting (AIM) 2021 (virtual), Paper 2101252. Please cite the published meeting paper: doi:10.13031/aim.202101252. Minor wording and formatting updates in this preprint",
      "pdf_url": "https://arxiv.org/pdf/2509.12274v1",
      "published_date": "2025-09-14 03:48:22 UTC",
      "updated_date": "2025-09-14 03:48:22 UTC",
      "processing_status": "completed",
      "attempts": 1,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "llm_backup_calls": 0,
      "last_update": "2026-01-24T18:31:12.786217+00:00"
    },
    {
      "arxiv_id": "2509.11071v1",
      "title": "The System Description of CPS Team for Track on Driving with Language of CVPR 2024 Autonomous Grand Challenge",
      "title_zh": "CVPR 2024 è‡ªåŠ¨é©¾é©¶å¤§æŒ‘æˆ˜èµ›é©¾é©¶ä¸è¯­è¨€èµ›é“ï¼šCPS å›¢é˜Ÿç³»ç»Ÿæè¿°",
      "authors": [
        "Jinghan Peng",
        "Jingwen Wang",
        "Xing Yu",
        "Dehui Du"
      ],
      "abstract": "This report outlines our approach using vision language model systems for the Driving with Language track of the CVPR 2024 Autonomous Grand Challenge. We have exclusively utilized the DriveLM-nuScenes dataset for training our models. Our systems are built on the LLaVA models, which we enhanced through fine-tuning with the LoRA and DoRA methods. Additionally, we have integrated depth information from open-source depth estimation models to enrich the training and inference processes. For inference, particularly with multiple-choice and yes/no questions, we adopted a Chain-of-Thought reasoning approach to improve the accuracy of the results. This comprehensive methodology enabled us to achieve a top score of 0.7799 on the validation set leaderboard, ranking 1st on the leaderboard.",
      "tldr_zh": "è¯¥ç ”ç©¶è¯¦ç»†ä»‹ç»äº†CPSå›¢é˜Ÿåœ¨CVPR 2024 Autonomous Grand Challengeçš„Driving with Languageèµ›é“ä¸­æ‰€é‡‡ç”¨çš„æ–¹æ³•ã€‚ç³»ç»Ÿå®Œå…¨åŸºäºDriveLM-nuScenesæ•°æ®é›†è¿›è¡Œè®­ç»ƒï¼Œä»¥LLaVAæ¨¡å‹ä½œä¸ºåŸºç¡€æ¶æ„ï¼Œå¹¶ç»“åˆLoRAå’ŒDoRAæŠ€æœ¯è¿›è¡Œäº†ç²¾ç»†åŒ–å¾®è°ƒã€‚ç ”ç©¶å›¢é˜Ÿè¿›ä¸€æ­¥æ•´åˆäº†å¼€æºæ·±åº¦ä¼°è®¡æ¨¡å‹çš„æ·±åº¦ä¿¡æ¯ï¼Œä»¥ä¸°å¯Œæ¨¡å‹åœ¨è®­ç»ƒä¸æ¨ç†é˜¶æ®µçš„ç‰¹å¾è¡¨ç¤ºã€‚åœ¨å¤„ç†æ¨ç†ä»»åŠ¡ï¼ˆç‰¹åˆ«æ˜¯å¤šé¡¹é€‰æ‹©å’Œæ˜¯éé¢˜ï¼‰æ—¶ï¼Œå¼•å…¥äº†Chain-of-Thoughtæ¨ç†æ–¹æ³•æ¥æ˜¾è‘—æå‡é¢„æµ‹å‡†ç¡®åº¦ã€‚å‡­å€Ÿè¿™å¥—ç»¼åˆæ€§æ–¹æ¡ˆï¼Œè¯¥ç³»ç»Ÿåœ¨éªŒè¯é›†æ’è¡Œæ¦œä¸Šè·å¾—äº†0.7799çš„é«˜åˆ†ï¼ŒæˆåŠŸä½åˆ—æ’è¡Œæ¦œç¬¬ä¸€åã€‚",
      "categories": [
        "cs.CV",
        "cs.AI",
        "cs.CL"
      ],
      "primary_category": "cs.CV",
      "comment": "",
      "pdf_url": "https://arxiv.org/pdf/2509.11071v1",
      "published_date": "2025-09-14 03:37:17 UTC",
      "updated_date": "2025-09-14 03:37:17 UTC",
      "processing_status": "completed",
      "attempts": 1,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "llm_backup_calls": 0,
      "last_update": "2026-01-24T18:31:01.068230+00:00"
    },
    {
      "arxiv_id": "2509.11068v1",
      "title": "Tractable Asymmetric Verification for Large Language Models via Deterministic Replicability",
      "title_zh": "åŸºäºç¡®å®šæ€§å¯å¤åˆ¶æ€§çš„å¤§è¯­è¨€æ¨¡å‹æ˜“å¤„ç†ä¸å¯¹ç§°éªŒè¯",
      "authors": [
        "Zan-Kai Chong",
        "Hiroyuki Ohsaki",
        "Bryan Ng"
      ],
      "abstract": "The landscape of Large Language Models (LLMs) shifts rapidly towards dynamic, multi-agent systems. This introduces a fundamental challenge in establishing computational trust, specifically how one agent can verify that another's output was genuinely produced by a claimed LLM, and not falsified or generated by a cheaper or inferior model. To address this challenge, this paper proposes a verification framework that achieves tractable asymmetric effort, where the cost to verify a computation is substantially lower than the cost to perform it. Our approach is built upon the principle of deterministic replicability, a property inherent to autoregressive models that strictly necessitates a computationally homogeneous environment where all agents operate on identical hardware and software stacks. Within this defined context, our framework enables multiple validators to probabilistically audit small, random segments of an LLM's output and it distributes the verification workload effectively. The simulations demonstrated that targeted verification can be over 12 times faster than full regeneration, with tunable parameters to adjust the detection probability. By establishing a tractable mechanism for auditable LLM systems, our work offers a foundational layer for responsible AI and serves as a cornerstone for future research into the more complex, heterogeneous multi-agent systems.",
      "tldr_zh": "è¯¥ç ”ç©¶é’ˆå¯¹å¤šæ™ºèƒ½ä½“ç³»ç»Ÿä¸­ Large Language Models (LLMs) è¾“å‡ºç»“æœçš„çœŸå®æ€§éªŒè¯éš¾é¢˜ï¼Œæå‡ºäº†ä¸€ä¸ªåŸºäº Deterministic Replicability åŸç†çš„éªŒè¯æ¡†æ¶ã€‚è¯¥æ¡†æ¶æ—¨åœ¨å®ç° Tractable Asymmetric Effortï¼Œå³ç¡®ä¿éªŒè¯è®¡ç®—ç»“æœçš„æˆæœ¬æ˜¾è‘—ä½äºæ‰§è¡Œè®¡ç®—çš„æˆæœ¬ï¼Œä»è€Œåœ¨ä»£ç†ä¹‹é—´å»ºç«‹è®¡ç®—ä¿¡ä»»ã€‚åœ¨ç¡¬ä»¶å’Œè½¯ä»¶æ ˆå®Œå…¨ä¸€è‡´çš„è®¡ç®—ç¯å¢ƒä¸‹ï¼Œè¯¥æ¡†æ¶å…è®¸éªŒè¯è€…é€šè¿‡éšæœºå®¡è®¡ LLM è¾“å‡ºçš„å¾®å°ç‰‡æ®µæ¥æœ‰æ•ˆåˆ†é…éªŒè¯è´Ÿè½½ã€‚ä»¿çœŸå®éªŒè¡¨æ˜ï¼Œè¿™ç§é’ˆå¯¹æ€§éªŒè¯çš„é€Ÿåº¦æ¯”å®Œå…¨é‡æ–°ç”Ÿæˆå¿« 12 å€ä»¥ä¸Šï¼Œä¸”æ£€æµ‹æ¦‚ç‡å¯æ ¹æ®å‚æ•°çµæ´»è°ƒèŠ‚ã€‚è¯¥å·¥ä½œä¸ºæ„å»ºå¯å®¡è®¡çš„ AI ç³»ç»Ÿæä¾›äº†åº•å±‚æœºåˆ¶ï¼Œä¹Ÿä¸ºæœªæ¥ç ”ç©¶æ›´å¤æ‚çš„å¼‚æ„å¤šæ™ºèƒ½ä½“ç³»ç»ŸåŠè´Ÿè´£ä»» AI å¥ å®šäº†åŸºç¡€ã€‚",
      "categories": [
        "cs.AI"
      ],
      "primary_category": "cs.AI",
      "comment": "",
      "pdf_url": "https://arxiv.org/pdf/2509.11068v1",
      "published_date": "2025-09-14 03:30:06 UTC",
      "updated_date": "2025-09-14 03:30:06 UTC",
      "processing_status": "completed",
      "attempts": 1,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "llm_backup_calls": 0,
      "last_update": "2026-01-24T18:31:07.701921+00:00"
    },
    {
      "arxiv_id": "2509.11067v2",
      "title": "Agentic Lybic: Multi-Agent Execution System with Tiered Reasoning and Orchestration",
      "title_zh": "Agentic Lybicï¼šå…·å¤‡åˆ†å±‚æ¨ç†ä¸ç¼–æ’æœºåˆ¶çš„å¤šæ™ºèƒ½ä½“æ‰§è¡Œç³»ç»Ÿ",
      "authors": [
        "Liangxuan Guo",
        "Bin Zhu",
        "Qingqian Tao",
        "Kangning Liu",
        "Xun Zhao",
        "Xianzhe Qin",
        "Jin Gao",
        "Guangfu Hao"
      ],
      "abstract": "Autonomous agents for desktop automation struggle with complex multi-step tasks due to poor coordination and inadequate quality control. We introduce Agentic Lybic, a novel multi-agent system where the entire architecture operates as a finite-state machine (FSM). This core innovation enables dynamic orchestration. Our system comprises four components: a Controller, a Manager, three Workers (Technician for code-based operations, Operator for GUI interactions, and Analyst for decision support), and an Evaluator. The critical mechanism is the FSM-based routing between these components, which provides flexibility and generalization by dynamically selecting the optimal execution strategy for each subtask. This principled orchestration, combined with robust quality gating, enables adaptive replanning and error recovery. Evaluated officially on the OSWorld benchmark, Agentic Lybic achieves a state-of-the-art 57.07% success rate in 50 steps, substantially outperforming existing methods. Results demonstrate that principled multi-agent orchestration with continuous quality control provides superior reliability for generalized desktop automation in complex computing environments.",
      "tldr_zh": "è¯¥ç ”ç©¶é’ˆå¯¹æ¡Œé¢è‡ªåŠ¨åŒ–æ™ºèƒ½ä½“åœ¨å¤„ç†å¤æ‚å¤šæ­¥ä»»åŠ¡æ—¶é¢ä¸´çš„åè°ƒæ€§å·®å’Œè´¨é‡æ§åˆ¶ä¸è¶³ç­‰æŒ‘æˆ˜ï¼Œæå‡ºäº† Agentic Lybic è¿™ä¸€æ–°å‹å¤šæ™ºèƒ½ä½“æ‰§è¡Œç³»ç»Ÿã€‚è¯¥ç³»ç»Ÿçš„æ ¸å¿ƒåˆ›æ–°åœ¨äºå°†æ•´ä½“æ¶æ„ä½œä¸ºæœ‰é™çŠ¶æ€æœº (Finite-State Machine, FSM) è¿è¡Œï¼Œä»è€Œå®ç°äº†é«˜æ•ˆçš„åŠ¨æ€ç¼–æ’ã€‚ç³»ç»Ÿç”± Controllerã€Managerã€ä¸‰ç±» Workerï¼ˆè´Ÿè´£ä»£ç æ“ä½œçš„ Technicianã€è´Ÿè´£ GUI äº¤äº’çš„ Operator å’Œè´Ÿè´£å†³ç­–æ”¯æŒçš„ Analystï¼‰ä»¥åŠ Evaluator å››ä¸ªç»„ä»¶æ„æˆã€‚é€šè¿‡åŸºäº FSM çš„ç»„ä»¶é—´è·¯ç”±æœºåˆ¶ï¼Œç³»ç»Ÿèƒ½å¤Ÿä¸ºæ¯ä¸ªå­ä»»åŠ¡åŠ¨æ€é€‰æ‹©æœ€ä¼˜æ‰§è¡Œç­–ç•¥ï¼Œå¹¶ç»“åˆé²æ£’çš„è´¨é‡é—¨æ§å®ç°è‡ªé€‚åº”é‡æ–°è§„åˆ’ä¸é”™è¯¯æ¢å¤ã€‚åœ¨ OSWorld åŸºå‡†æµ‹è¯•ä¸­ï¼ŒAgentic Lybic åœ¨ 50 æ­¥å†…å®ç°äº† 57.07% çš„æˆåŠŸç‡ï¼Œåˆ›ä¸‹äº† SOTA è®°å½•å¹¶æ˜¾è‘—ä¼˜äºç°æœ‰æ–¹æ³•ã€‚å®éªŒç»“æœè¯æ˜ï¼Œè¿™ç§åŸºäºåŸåˆ™çš„å¤šæ™ºèƒ½ä½“ç¼–æ’ä¸æŒç»­çš„è´¨é‡æ§åˆ¶ï¼Œä¸ºå¤æ‚è®¡ç®—ç¯å¢ƒä¸‹çš„é€šç”¨æ¡Œé¢è‡ªåŠ¨åŒ–æä¾›äº†å“è¶Šçš„å¯é æ€§ã€‚",
      "categories": [
        "cs.AI",
        "cs.HC",
        "cs.MA"
      ],
      "primary_category": "cs.AI",
      "comment": "",
      "pdf_url": "https://arxiv.org/pdf/2509.11067v2",
      "published_date": "2025-09-14 03:22:27 UTC",
      "updated_date": "2025-09-16 02:49:53 UTC",
      "processing_status": "completed",
      "attempts": 1,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "llm_backup_calls": 0,
      "last_update": "2026-01-24T18:31:07.864340+00:00"
    },
    {
      "arxiv_id": "2509.13351v1",
      "title": "Teaching LLMs to Plan: Logical Chain-of-Thought Instruction Tuning for Symbolic Planning",
      "title_zh": "æ•™å¯¼å¤§è¯­è¨€æ¨¡å‹è¿›è¡Œè§„åˆ’ï¼šé¢å‘ç¬¦å·è§„åˆ’çš„é€»è¾‘æ€ç»´é“¾æŒ‡ä»¤å¾®è°ƒ",
      "authors": [
        "Pulkit Verma",
        "Ngoc La",
        "Anthony Favier",
        "Swaroop Mishra",
        "Julie A. Shah"
      ],
      "abstract": "Large language models (LLMs) have demonstrated impressive capabilities across diverse tasks, yet their ability to perform structured symbolic planning remains limited, particularly in domains requiring formal representations like the Planning Domain Definition Language (PDDL). In this paper, we present a novel instruction tuning framework, PDDL-Instruct, designed to enhance LLMs' symbolic planning capabilities through logical chain-of-thought reasoning. Our approach focuses on teaching models to rigorously reason about action applicability, state transitions, and plan validity using explicit logical inference steps. By developing instruction prompts that guide models through the precise logical reasoning required to determine when actions can be applied in a given state, we enable LLMs to self-correct their planning processes through structured reflection. The framework systematically builds verification skills by decomposing the planning process into explicit reasoning chains about precondition satisfaction, effect application, and invariant preservation. Experimental results on multiple planning domains show that our chain-of-thought reasoning based instruction-tuned models are significantly better at planning, achieving planning accuracy of up to 94% on standard benchmarks, representing a 66% absolute improvement over baseline models. This work bridges the gap between the general reasoning capabilities of LLMs and the logical precision required for automated planning, offering a promising direction for developing better AI planning systems.",
      "tldr_zh": "è¯¥ç ”ç©¶é’ˆå¯¹å¤§è¯­è¨€æ¨¡å‹ (LLMs) åœ¨ç»“æ„åŒ–ç¬¦å·è§„åˆ’ (Symbolic Planning) ä»¥åŠ PDDL å½¢å¼åŒ–è¡¨è¾¾æ–¹é¢çš„å±€é™æ€§ï¼Œæå‡ºäº† PDDL-Instruct æŒ‡ä»¤å¾®è°ƒæ¡†æ¶ã€‚è¯¥æ–¹æ³•çš„æ ¸å¿ƒæ˜¯é€šè¿‡é€»è¾‘é“¾å¼æ€ç»´ (Logical Chain-of-Thought) æ¨ç†ï¼Œæ•™å¯¼æ¨¡å‹ä¸¥æ ¼æ¨å¯¼åŠ¨ä½œé€‚ç”¨æ€§ã€çŠ¶æ€è½¬æ¢å’Œè§„åˆ’æœ‰æ•ˆæ€§ã€‚ç ”ç©¶äººå‘˜å¼€å‘äº†ç‰¹å®šçš„æŒ‡ä»¤æç¤ºï¼Œå¼•å¯¼æ¨¡å‹å®Œæˆå‰ç½®æ¡ä»¶éªŒè¯ã€æ•ˆæœåº”ç”¨å’Œä¸å˜æ€§ä¿æŒç­‰ç²¾ç¡®é€»è¾‘æ¨ç†æ­¥éª¤ï¼Œä»è€Œä½¿ LLMs èƒ½å¤Ÿé€šè¿‡ç»“æ„åŒ–åæ€å®ç°è§„åˆ’è¿‡ç¨‹çš„è‡ªæˆ‘ä¿®æ­£ã€‚å®éªŒç»“æœæ˜¾ç¤ºï¼ŒåŸºäºé“¾å¼æ€ç»´æ¨ç†çš„å¾®è°ƒæ¨¡å‹åœ¨æ ‡å‡†åŸºå‡†æµ‹è¯•ä¸­è¡¨ç°å“è¶Šï¼Œè§„åˆ’å‡†ç¡®ç‡æœ€é«˜è¾¾ 94%ï¼Œç›¸æ¯”åŸºçº¿æ¨¡å‹å®ç°äº† 66% çš„ç»å¯¹æå‡ã€‚è¿™é¡¹å·¥ä½œå¼¥è¡¥äº†é€šç”¨æ¨ç†èƒ½åŠ›ä¸è‡ªåŠ¨è§„åˆ’æ‰€éœ€é€»è¾‘ç²¾åº¦ä¹‹é—´çš„å·®è·ï¼Œä¸ºå¼€å‘æ›´é«˜æ•ˆçš„ AI è§„åˆ’ç³»ç»Ÿæä¾›äº†æ–°è·¯å¾„ã€‚",
      "categories": [
        "cs.AI",
        "cs.CL"
      ],
      "primary_category": "cs.AI",
      "comment": "",
      "pdf_url": "https://arxiv.org/pdf/2509.13351v1",
      "published_date": "2025-09-14 02:42:34 UTC",
      "updated_date": "2025-09-14 02:42:34 UTC",
      "processing_status": "completed",
      "attempts": 1,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "llm_backup_calls": 0,
      "last_update": "2026-01-24T18:31:14.058639+00:00"
    },
    {
      "arxiv_id": "2509.11053v1",
      "title": "An Advanced Convolutional Neural Network for Bearing Fault Diagnosis under Limited Data",
      "title_zh": "æœ‰é™æ•°æ®ä¸‹è½´æ‰¿æ•…éšœè¯Šæ–­çš„å…ˆè¿›å·ç§¯ç¥ç»ç½‘ç»œ",
      "authors": [
        "Shengke Sun",
        "Shuzhen Han",
        "Ziqian Luan",
        "Xinghao Qin",
        "Jiao Yin",
        "Zhanshan Zhao",
        "Jinli Cao",
        "Hua Wang"
      ],
      "abstract": "In the area of bearing fault diagnosis, deep learning (DL) methods have been widely used recently. However, due to the high cost or privacy concerns, high-quality labeled data are scarce in real world scenarios. While few-shot learning has shown promise in addressing data scarcity, existing methods still face significant limitations in this domain. Traditional data augmentation techniques often suffer from mode collapse and generate low-quality samples that fail to capture the diversity of bearing fault patterns. Moreover, conventional convolutional neural networks (CNNs) with local receptive fields makes them inadequate for extracting global features from complex vibration signals. Additionally, existing methods fail to model the intricate relationships between limited training samples. To solve these problems, we propose an advanced data augmentation and contrastive fourier convolution framework (DAC-FCF) for bearing fault diagnosis under limited data. Firstly, a novel conditional consistent latent representation and reconstruction generative adversarial network (CCLR-GAN) is proposed to generate more diverse data. Secondly, a contrastive learning based joint optimization mechanism is utilized to better model the relations between the available training data. Finally, we propose a 1D fourier convolution neural network (1D-FCNN) to achieve a global-aware of the input data. Experiments demonstrate that DAC-FCF achieves significant improvements, outperforming baselines by up to 32\\% on case western reserve university (CWRU) dataset and 10\\% on a self-collected test bench. Extensive ablation experiments prove the effectiveness of the proposed components. Thus, the proposed DAC-FCF offers a promising solution for bearing fault diagnosis under limited data.",
      "tldr_zh": "è¯¥ç ”ç©¶é’ˆå¯¹è½´æ‰¿æ•…éšœè¯Šæ–­ä¸­é«˜è´¨é‡æ ‡æ³¨æ•°æ®ç¨€ç¼ºçš„é—®é¢˜ï¼Œæå‡ºäº†åä¸ºDAC-FCFçš„æ•°æ®å¢å¼ºä¸å¯¹æ¯”å‚…é‡Œå¶å·ç§¯æ¡†æ¶ã€‚ä¸ºè§£å†³ä¼ ç»Ÿå¢å¼ºæŠ€æœ¯äº§ç”Ÿçš„æ ·æœ¬å¤šæ ·æ€§ä¸è¶³åŠæ¨¡å¼å´©å¡Œé—®é¢˜ï¼Œç ”ç©¶é¦–å…ˆæå‡ºäº†ä¸€ç§CCLR-GANæ¨¡å‹ä»¥ç”Ÿæˆæ›´ä¸°å¯Œçš„è®­ç»ƒæ•°æ®ã€‚åŒæ—¶ï¼Œè¯¥æ¡†æ¶é‡‡ç”¨åŸºäºå¯¹æ¯”å­¦ä¹ (Contrastive Learning)çš„è”åˆä¼˜åŒ–æœºåˆ¶ï¼Œæœ‰æ•ˆå»ºæ¨¡äº†æœ‰é™æ ·æœ¬ä¹‹é—´çš„å¤æ‚å…³è”ã€‚é’ˆå¯¹ä¼ ç»ŸCNNå±€éƒ¨æ„Ÿå—é‡çš„å±€é™æ€§ï¼Œç ”ç©¶è¿›ä¸€æ­¥å¼•å…¥äº†1D-FCNNä»¥å®ç°å¯¹æŒ¯åŠ¨ä¿¡å·çš„å…¨å±€ç‰¹å¾æå–ã€‚å®éªŒç»“æœè¡¨æ˜ï¼ŒDAC-FCFåœ¨CWRUæ•°æ®é›†å’Œè‡ªåˆ¶å®éªŒå°ä¸Šç›¸è¾ƒäºåŸºçº¿æ¨¡å‹åˆ†åˆ«å®ç°äº†32%å’Œ10%çš„å‡†ç¡®ç‡æå‡ã€‚è¿™ä¸€ç ”ç©¶æˆæœä¸ºå·¥ä¸šåœºæ™¯ä¸‹å°æ ·æœ¬æ•°æ®çš„è½´æ‰¿æ•…éšœè¯Šæ–­æä¾›äº†å…·æœ‰å‰æ™¯çš„è§£å†³æ–¹æ¡ˆã€‚",
      "categories": [
        "cs.LG",
        "cs.AI",
        "cs.CE"
      ],
      "primary_category": "cs.LG",
      "comment": "",
      "pdf_url": "https://arxiv.org/pdf/2509.11053v1",
      "published_date": "2025-09-14 02:41:48 UTC",
      "updated_date": "2025-09-14 02:41:48 UTC",
      "processing_status": "completed",
      "attempts": 1,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "llm_backup_calls": 0,
      "last_update": "2026-01-24T18:31:26.092761+00:00"
    },
    {
      "arxiv_id": "2509.18132v1",
      "title": "Position Paper: Integrating Explainability and Uncertainty Estimation in Medical AI",
      "title_zh": "ç«‹åœºè®ºæ–‡ï¼šåŒ»ç–—äººå·¥æ™ºèƒ½ä¸­å¯è§£é‡Šæ€§ä¸ä¸ç¡®å®šæ€§ä¼°è®¡çš„èåˆ",
      "authors": [
        "Xiuyi Fan"
      ],
      "abstract": "Uncertainty is a fundamental challenge in medical practice, but current medical AI systems fail to explicitly quantify or communicate uncertainty in a way that aligns with clinical reasoning. Existing XAI works focus on interpreting model predictions but do not capture the confidence or reliability of these predictions. Conversely, uncertainty estimation (UE) techniques provide confidence measures but lack intuitive explanations. The disconnect between these two areas limits AI adoption in medicine. To address this gap, we propose Explainable Uncertainty Estimation (XUE) that integrates explainability with uncertainty quantification to enhance trust and usability in medical AI. We systematically map medical uncertainty to AI uncertainty concepts and identify key challenges in implementing XUE. We outline technical directions for advancing XUE, including multimodal uncertainty quantification, model-agnostic visualization techniques, and uncertainty-aware decision support systems. Lastly, we propose guiding principles to ensure effective XUE realisation. Our analysis highlights the need for AI systems that not only generate reliable predictions but also articulate confidence levels in a clinically meaningful way. This work contributes to the development of trustworthy medical AI by bridging explainability and uncertainty, paving the way for AI systems that are aligned with real-world clinical complexities.",
      "tldr_zh": "è¯¥ç ”ç©¶æ¢è®¨äº†åŒ»ç–—AIé¢†åŸŸä¸­ä¸ç¡®å®šæ€§é‡åŒ–çš„æ ¸å¿ƒæŒ‘æˆ˜ï¼ŒæŒ‡å‡ºå½“å‰å¯è§£é‡Šæ€§(XAI)ä¸ä¸ç¡®å®šæ€§ä¼°è®¡(Uncertainty Estimation, UE)ä¹‹é—´çš„è„±èŠ‚é™åˆ¶äº†AIçš„ä¸´åºŠåº”ç”¨ã€‚ä¸ºæ­¤ï¼Œä½œè€…æå‡ºäº†å¯è§£é‡Šä¸ç¡®å®šæ€§ä¼°è®¡(Explainable Uncertainty Estimation, XUE)çš„æ¡†æ¶ï¼Œæ—¨åœ¨å°†é¢„æµ‹çš„å¯é æ€§ä¸ç›´è§‚çš„è§£é‡Šç›¸ç»“åˆï¼Œä»¥å¢å¼ºåŒ»ç–—AIçš„å¯ä¿¡åº¦ã€‚æ–‡ç« ç³»ç»Ÿåœ°å°†åŒ»å­¦ä¸ç¡®å®šæ€§æ˜ å°„è‡³AIæ¦‚å¿µï¼Œå¹¶æ˜ç¡®äº†å®ç°XUEåœ¨å¤šæ¨¡æ€ä¸ç¡®å®šæ€§é‡åŒ–(Multimodal Uncertainty Quantification)ã€æ¨¡å‹æ— å…³çš„å¯è§†åŒ–æŠ€æœ¯(Model-agnostic Visualization)ä»¥åŠæ„ŸçŸ¥ä¸ç¡®å®šæ€§çš„å†³ç­–æ”¯æŒç³»ç»Ÿ(Uncertainty-aware Decision Support Systems)ç­‰æ–¹é¢çš„æŠ€æœ¯æ–¹å‘ã€‚æ­¤å¤–ï¼Œç ”ç©¶è¿˜æå‡ºäº†ç¡®ä¿XUEæœ‰æ•ˆå®ç°çš„æŒ‡å¯¼åŸåˆ™ã€‚è¯¥å·¥ä½œé€šè¿‡å¼¥åˆå¯è§£é‡Šæ€§ä¸ä¸ç¡®å®šæ€§ä¹‹é—´çš„é¸¿æ²Ÿï¼Œä¸ºå¼€å‘ç¬¦åˆçœŸå®ä¸´åºŠå¤æ‚æ€§çš„åŒ»ç–—AIç³»ç»Ÿæä¾›äº†é‡è¦å‚è€ƒã€‚",
      "categories": [
        "cs.AI"
      ],
      "primary_category": "cs.AI",
      "comment": "Accepted at the International Joint Conference on Neural Networks, IJCNN 2025",
      "pdf_url": "https://arxiv.org/pdf/2509.18132v1",
      "published_date": "2025-09-14 02:41:26 UTC",
      "updated_date": "2025-09-14 02:41:26 UTC",
      "processing_status": "completed",
      "attempts": 1,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "llm_backup_calls": 0,
      "last_update": "2026-01-24T18:31:25.791172+00:00"
    },
    {
      "arxiv_id": "2509.12273v1",
      "title": "LLMAP: LLM-Assisted Multi-Objective Route Planning with User Preferences",
      "title_zh": "LLMAPï¼šç»“åˆç”¨æˆ·åå¥½çš„å¤§è¯­è¨€æ¨¡å‹è¾…åŠ©å¤šç›®æ ‡è·¯å¾„è§„åˆ’",
      "authors": [
        "Liangqi Yuan",
        "Dong-Jun Han",
        "Christopher G. Brinton",
        "Sabine Brunswicker"
      ],
      "abstract": "The rise of large language models (LLMs) has made natural language-driven route planning an emerging research area that encompasses rich user objectives. Current research exhibits two distinct approaches: direct route planning using LLM-as-Agent and graph-based searching strategies. However, LLMs in the former approach struggle to handle extensive map data, while the latter shows limited capability in understanding natural language preferences. Additionally, a more critical challenge arises from the highly heterogeneous and unpredictable spatio-temporal distribution of users across the globe. In this paper, we introduce a novel LLM-Assisted route Planning (LLMAP) system that employs an LLM-as-Parser to comprehend natural language, identify tasks, and extract user preferences and recognize task dependencies, coupled with a Multi-Step Graph construction with iterative Search (MSGS) algorithm as the underlying solver for optimal route finding. Our multi-objective optimization approach adaptively tunes objective weights to maximize points of interest (POI) quality and task completion rate while minimizing route distance, subject to three key constraints: user time limits, POI opening hours, and task dependencies. We conduct extensive experiments using 1,000 routing prompts sampled with varying complexity across 14 countries and 27 cities worldwide. The results demonstrate that our approach achieves superior performance with guarantees across multiple constraints.",
      "tldr_zh": "è¯¥ç ”ç©¶æå‡ºäº†LLMAPï¼Œä¸€ç§ç”±å¤§è¯­è¨€æ¨¡å‹(LLM)è¾…åŠ©çš„å¤šç›®æ ‡è·¯å¾„è§„åˆ’ç³»ç»Ÿï¼Œæ—¨åœ¨è§£å†³ç°æœ‰æ–¹æ³•åœ¨å¤„ç†å¤§è§„æ¨¡åœ°å›¾æ•°æ®å’Œç†è§£è‡ªç„¶è¯­è¨€åå¥½æ–¹é¢çš„ä¸è¶³ã€‚è¯¥ç³»ç»Ÿåˆ©ç”¨LLM-as-Parserä½œä¸ºè§£æå™¨æ¥ç²¾å‡†æå–ä»»åŠ¡ã€ç”¨æˆ·åå¥½åŠä»»åŠ¡ä¾èµ–å…³ç³»ï¼Œå¹¶ç»“åˆå¤šæ­¥å›¾æ„å»ºä¸è¿­ä»£æœç´¢(MSGS)ç®—æ³•ä½œä¸ºæ±‚è§£å™¨ä»¥å¯»æ‰¾æœ€ä¼˜è·¯å¾„ã€‚é€šè¿‡è‡ªé€‚åº”è°ƒæ•´å¤šç›®æ ‡ä¼˜åŒ–æƒé‡ï¼ŒLLMAPèƒ½å¤Ÿåœ¨æ»¡è¶³ç”¨æˆ·æ—¶é—´é™åˆ¶ã€POIå¼€æ”¾æ—¶é—´å’Œä»»åŠ¡ä¾èµ–ç­‰å…³é”®çº¦æŸçš„å‰æä¸‹ï¼Œæœ€å¤§åŒ–POIè´¨é‡ä¸ä»»åŠ¡å®Œæˆç‡å¹¶æœ€å°åŒ–è¡Œé©¶è·ç¦»ã€‚å®éªŒåœ¨æ¨ªè·¨14ä¸ªå›½å®¶å’Œ27ä¸ªåŸå¸‚çš„1,000ä¸ªå¤æ‚è·¯å¾„è§„åˆ’åœºæ™¯ä¸­è¿›è¡Œï¼Œç»“æœè¯æ˜è¯¥æ–¹æ³•åœ¨å¤šçº¦æŸç¯å¢ƒä¸‹å‡èƒ½å–å¾—ä¼˜å¼‚ä¸”å…·å¤‡ä¿éšœçš„æ€§èƒ½è¡¨ç°ã€‚",
      "categories": [
        "cs.AI",
        "cs.CL",
        "cs.LG"
      ],
      "primary_category": "cs.AI",
      "comment": "",
      "pdf_url": "https://arxiv.org/pdf/2509.12273v1",
      "published_date": "2025-09-14 02:30:19 UTC",
      "updated_date": "2025-09-14 02:30:19 UTC",
      "processing_status": "completed",
      "attempts": 1,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "llm_backup_calls": 0,
      "last_update": "2026-01-24T18:31:45.795105+00:00"
    },
    {
      "arxiv_id": "2510.21715v1",
      "title": "Beyond IVR Touch-Tones: Customer Intent Routing using LLMs",
      "title_zh": "è¶…è¶Š IVR æŒ‰é”®éŸ³ï¼šåŸºäºå¤§è¯­è¨€æ¨¡å‹çš„å®¢æˆ·æ„å›¾è·¯ç”±",
      "authors": [
        "Sergio Rojas-Galeano"
      ],
      "abstract": "Widespread frustration with rigid touch-tone Interactive Voice Response (IVR) systems for customer service underscores the need for more direct and intuitive language interaction. While speech technologies are necessary, the key challenge lies in routing intents from user phrasings to IVR menu paths, a task where Large Language Models (LLMs) show strong potential. Progress, however, is limited by data scarcity, as real IVR structures and interactions are often proprietary. We present a novel LLM-based methodology to address this gap. Using three distinct models, we synthesized a realistic 23-node IVR structure, generated 920 user intents (230 base and 690 augmented), and performed the routing task. We evaluate two prompt designs: descriptive hierarchical menus and flattened path representations, across both base and augmented datasets. Results show that flattened paths consistently yield higher accuracy, reaching 89.13% on the base dataset compared to 81.30% with the descriptive format, while augmentation introduces linguistic noise that slightly reduces performance. Confusion matrix analysis further suggests that low-performing routes may reflect not only model limitations but also redundancies in menu design. Overall, our findings demonstrate proof-of-concept that LLMs can enable IVR routing through a smoother, more seamless user experience -- moving customer service one step ahead of touch-tone menus.",
      "tldr_zh": "è¯¥ç ”ç©¶é’ˆå¯¹ä¼ ç»Ÿäº¤äº’å¼è¯­éŸ³åº”ç­”(IVR)ç³»ç»Ÿæ“ä½œåƒµåŒ–çš„é—®é¢˜ï¼Œæå‡ºäº†ä¸€ç§åˆ©ç”¨å¤§è¯­è¨€æ¨¡å‹(LLMs)å°†ç”¨æˆ·æ„å›¾è‡ªåŠ¨è·¯ç”±è‡³IVRèœå•è·¯å¾„çš„æ–¹æ³•ï¼Œä»¥å®ç°æ›´ç›´è§‚çš„è¯­è¨€äº¤äº’ã€‚ä¸ºè§£å†³çœŸå®æ•°æ®ç¨€ç¼ºçš„éš¾é¢˜ï¼Œç ”ç©¶å›¢é˜Ÿåˆæˆäº†ä¸€ä¸ªåŒ…å«23ä¸ªèŠ‚ç‚¹çš„IVRç»“æ„åŠ920é¡¹ç”¨æˆ·æ„å›¾ï¼Œå¹¶å¯¹æè¿°æ€§å±‚çº§èœå•(descriptive hierarchical menus)å’Œæ‰å¹³åŒ–è·¯å¾„è¡¨ç¤º(flattened path representations)ä¸¤ç§æç¤ºè¯è®¾è®¡è¿›è¡Œäº†å¯¹æ¯”è¯„ä¼°ã€‚å®éªŒç»“æœè¡¨æ˜ï¼Œæ‰å¹³åŒ–è·¯å¾„åœ¨åŸºç¡€æ•°æ®é›†ä¸Šçš„å‡†ç¡®ç‡é«˜è¾¾89.13%ï¼Œæ˜¾è‘—ä¼˜äºæè¿°æ€§æ ¼å¼çš„81.30%ã€‚å°½ç®¡æ•°æ®å¢å¼ºå¼•å…¥çš„è¯­è¨€å™ªå£°ä¼šç•¥å¾®é™ä½æ€§èƒ½ï¼Œä½†åˆ†ææ˜¾ç¤ºéƒ¨åˆ†è·¯ç”±é”™è¯¯åæ˜ äº†åŸå§‹èœå•è®¾è®¡çš„å†—ä½™è€Œéä»…æ˜¯æ¨¡å‹é™åˆ¶ã€‚è¯¥ç ”ç©¶æˆåŠŸéªŒè¯äº†åˆ©ç”¨LLMsä¼˜åŒ–æ„å›¾è·¯ç”±çš„å¯è¡Œæ€§ï¼Œä¸ºæ„å»ºæ›´æµç•…ã€æ— ç¼çš„æ™ºèƒ½åŒ–å®¢æˆ·æœåŠ¡ä½“éªŒå¥ å®šäº†åŸºç¡€ã€‚",
      "categories": [
        "cs.HC",
        "cs.AI",
        "cs.CL",
        "eess.AS"
      ],
      "primary_category": "cs.HC",
      "comment": "Accepted for publication in the Proceedings of the Workshop on Engineering Applications 2025 (WEA 2025)",
      "pdf_url": "https://arxiv.org/pdf/2510.21715v1",
      "published_date": "2025-09-14 02:26:01 UTC",
      "updated_date": "2025-09-14 02:26:01 UTC",
      "processing_status": "completed",
      "attempts": 1,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "llm_backup_calls": 0,
      "last_update": "2026-01-24T18:32:08.294851+00:00"
    },
    {
      "arxiv_id": "2509.11044v2",
      "title": "FragmentGPT: A Unified GPT Model for Fragment Growing, Linking, and Merging in Molecular Design",
      "title_zh": "FragmentGPTï¼šé¢å‘åˆ†å­è®¾è®¡ä¸­ç‰‡æ®µç”Ÿé•¿ã€è¿æ¥ä¸åˆå¹¶çš„ç»Ÿä¸€ GPT æ¨¡å‹",
      "authors": [
        "Xuefeng Liu",
        "Songhao Jiang",
        "Qinan Huang",
        "Tinson Xu",
        "Ian Foster",
        "Mengdi Wang",
        "Hening Lin",
        "Rick Stevens"
      ],
      "abstract": "Fragment-Based Drug Discovery (FBDD) is a popular approach in early drug development, but designing effective linkers to combine disconnected molecular fragments into chemically and pharmacologically viable candidates remains challenging. Further complexity arises when fragments contain structural redundancies, like duplicate rings, which cannot be addressed by simply adding or removing atoms or bonds. To address these challenges in a unified framework, we introduce FragmentGPT, which integrates two core components: (1) a novel chemically-aware, energy-based bond cleavage pre-training strategy that equips the GPT-based model with fragment growing, linking, and merging capabilities, and (2) a novel Reward Ranked Alignment with Expert Exploration (RAE) algorithm that combines expert imitation learning for diversity enhancement, data selection and augmentation for Pareto and composite score optimality, and Supervised Fine-Tuning (SFT) to align the learner policy with multi-objective goals. Conditioned on fragment pairs, FragmentGPT generates linkers that connect diverse molecular subunits while simultaneously optimizing for multiple pharmaceutical goals. It also learns to resolve structural redundancies-such as duplicated fragments-through intelligent merging, enabling the synthesis of optimized molecules. FragmentGPT facilitates controlled, goal-driven molecular assembly. Experiments and ablation studies on real-world cancer datasets demonstrate its ability to generate chemically valid, high-quality molecules tailored for downstream drug discovery tasks.",
      "tldr_zh": "è¯¥ç ”ç©¶æå‡ºäº† FragmentGPTï¼Œè¿™æ˜¯ä¸€ä¸ªç»Ÿä¸€çš„ GPT æ¨¡å‹ï¼Œæ—¨åœ¨è§£å†³åŸºäºç‰‡æ®µçš„è¯ç‰©å‘ç° (Fragment-Based Drug Discovery, FBDD) ä¸­åˆ†å­ç‰‡æ®µç”Ÿé•¿ã€è¿æ¥å’Œåˆå¹¶çš„å¤æ‚æŒ‘æˆ˜ã€‚è¯¥æ¨¡å‹æ ¸å¿ƒé›†æˆäº†åŸºäºåŒ–å­¦æ„ŸçŸ¥å’Œèƒ½é‡çš„é”®æ–­è£‚é¢„è®­ç»ƒç­–ç•¥ï¼Œèµ‹äºˆäº†æ¨¡å‹ Fragment Growingã€Linking å’Œ Merging çš„èƒ½åŠ›ã€‚æ­¤å¤–ï¼Œç ”ç©¶è¿˜å¼•å…¥äº†å¸¦ä¸“å®¶æ¢ç´¢çš„å¥–åŠ±æ’åå¯¹é½ (Reward Ranked Alignment with Expert Exploration, RAE) ç®—æ³•ï¼Œé€šè¿‡ç»“åˆæ¨¡ä»¿å­¦ä¹ ä¸ç›‘ç£å¾®è°ƒ (SFT) æ¥å¯¹é½å¤šç›®æ ‡è¯ç†éœ€æ±‚ã€‚FragmentGPT ä¸ä»…èƒ½ç”Ÿæˆè¿æ¥ä¸åŒåˆ†å­çš„ Linkersï¼Œè¿˜èƒ½é€šè¿‡æ™ºèƒ½åˆå¹¶å¤„ç†ç»“æ„å†—ä½™ï¼ˆå¦‚é‡å¤ç¯ï¼‰ï¼Œä»è€Œå®ç°å—æ§ä¸”ç›®æ ‡é©±åŠ¨çš„åˆ†å­ç»„è£…ã€‚åœ¨çœŸå®ç™Œç—‡æ•°æ®é›†ä¸Šçš„å®éªŒå’Œæ¶ˆèç ”ç©¶è¯æ˜ï¼Œè¯¥æ¨¡å‹ç”Ÿæˆçš„åˆ†å­å…·æœ‰æé«˜çš„åŒ–å­¦æœ‰æ•ˆæ€§å’Œè´¨é‡ã€‚è¿™ä¸€æ¡†æ¶ä¸ºä¸‹æ¸¸è¯ç‰©ç ”å‘ä»»åŠ¡æä¾›äº†å¼ºæœ‰åŠ›çš„æ”¯æŒï¼Œå±•ç¤ºäº†å…¶åœ¨å¤šç›®æ ‡ä¼˜åŒ–åˆ†å­è®¾è®¡æ–¹é¢çš„æ˜¾è‘—æ½œåŠ›ã€‚",
      "categories": [
        "cs.LG",
        "cs.AI",
        "q-bio.BM"
      ],
      "primary_category": "cs.LG",
      "comment": "",
      "pdf_url": "https://arxiv.org/pdf/2509.11044v2",
      "published_date": "2025-09-14 02:17:07 UTC",
      "updated_date": "2025-09-23 16:41:27 UTC",
      "processing_status": "completed",
      "attempts": 1,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "llm_backup_calls": 0,
      "last_update": "2026-01-24T18:31:49.290892+00:00"
    },
    {
      "arxiv_id": "2509.11035v1",
      "title": "Free-MAD: Consensus-Free Multi-Agent Debate",
      "title_zh": "Free-MADï¼šæ— éœ€å…±è¯†çš„å¤šæ™ºèƒ½ä½“è¾©è®º",
      "authors": [
        "Yu Cui",
        "Hang Fu",
        "Haibin Zhang",
        "Licheng Wang",
        "Cong Zuo"
      ],
      "abstract": "Multi-agent debate (MAD) is an emerging approach to improving the reasoning capabilities of large language models (LLMs). Existing MAD methods rely on multiple rounds of interaction among agents to reach consensus, and the final output is selected by majority voting in the last round. However, this consensus-based design faces several limitations. First, multiple rounds of communication increases token overhead and limits scalability. Second, due to the inherent conformity of LLMs, agents that initially produce correct responses may be influenced by incorrect ones during the debate process, causing error propagation. Third, majority voting introduces randomness and unfairness in the decision-making phase, and can degrade the reasoning performance.\n  To address these issues, we propose \\textsc{Free-MAD}, a novel MAD framework that eliminates the need for consensus among agents. \\textsc{Free-MAD} introduces a novel score-based decision mechanism that evaluates the entire debate trajectory rather than relying on the last round only. This mechanism tracks how each agent's reasoning evolves, enabling more accurate and fair outcomes. In addition, \\textsc{Free-MAD} reconstructs the debate phase by introducing anti-conformity, a mechanism that enables agents to mitigate excessive influence from the majority. Experiments on eight benchmark datasets demonstrate that \\textsc{Free-MAD} significantly improves reasoning performance while requiring only a single-round debate and thus reducing token costs. We also show that compared to existing MAD approaches, \\textsc{Free-MAD} exhibits improved robustness in real-world attack scenarios.",
      "tldr_zh": "è¯¥ç ”ç©¶æå‡ºäº†Free-MADï¼Œä¸€ç§æ— éœ€è¾¾æˆå…±è¯†çš„æ–°å‹å¤šæ™ºèƒ½ä½“è¾©è®ºæ¡†æ¶ï¼Œæ—¨åœ¨è§£å†³ç°æœ‰Multi-agent debate (MAD)æ–¹æ³•åœ¨å¤šè½®äº¤äº’ä¸­é¢ä¸´çš„é«˜Tokenå¼€é”€ã€ä»ä¼—å¿ƒç†å¯¼è‡´çš„é”™è¯¯ä¼ æ’­ä»¥åŠå¤šæ•°æŠ•ç¥¨éšæœºæ€§ç­‰å±€é™ã€‚Free-MADå¼•å…¥äº†åŸºäºè¯„åˆ†çš„å†³ç­–æœºåˆ¶(score-based decision mechanism)ï¼Œé€šè¿‡è¯„ä¼°æ•´ä¸ªè¾©è®ºè½¨è¿¹è€Œéä»…ä¾èµ–æœ€åä¸€è½®ï¼Œå®ç°äº†æ›´å‡†ç¡®å’Œå…¬å¹³çš„å†³ç­–ç»“æœã€‚æ­¤å¤–ï¼Œè¯¥æ¡†æ¶é€šè¿‡å¼•å…¥æŠ—ä»ä¼—(anti-conformity)æœºåˆ¶é‡æ„è¾©è®ºè¿‡ç¨‹ï¼Œæœ‰æ•ˆå‡è½»äº†æ™ºèƒ½ä½“å—å¤šæ•°æ´¾é”™è¯¯è§‚ç‚¹çš„è¿‡åº¦å½±å“ã€‚å®éªŒè¡¨æ˜ï¼ŒFree-MADåœ¨å…«ä¸ªåŸºå‡†æ•°æ®é›†ä¸Šæ˜¾è‘—æå‡äº†Large Language Models (LLMs)çš„æ¨ç†æ€§èƒ½ï¼Œä¸”ä»…éœ€å•è½®è¾©è®ºå³å¯è¿è¡Œï¼Œæå¤§é™ä½äº†è®¡ç®—æˆæœ¬ã€‚ç›¸æ¯”ä¼ ç»ŸMADæ–¹æ³•ï¼ŒFree-MADåœ¨ç°å®æ”»å‡»åœºæ™¯ä¸‹å±•ç°å‡ºäº†æ›´ä¼˜è¶Šçš„é²æ£’æ€§(robustness)ï¼Œä¸ºæ„å»ºé«˜æ•ˆã€å¯é çš„å¤šæ™ºèƒ½ä½“åä½œç³»ç»Ÿæä¾›äº†åˆ›æ–°æ–¹æ¡ˆã€‚",
      "categories": [
        "cs.AI",
        "cs.CR"
      ],
      "primary_category": "cs.AI",
      "comment": "",
      "pdf_url": "https://arxiv.org/pdf/2509.11035v1",
      "published_date": "2025-09-14 01:55:01 UTC",
      "updated_date": "2025-09-14 01:55:01 UTC",
      "processing_status": "completed",
      "attempts": 1,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "llm_backup_calls": 0,
      "last_update": "2026-01-24T18:32:00.487308+00:00"
    },
    {
      "arxiv_id": "2509.11026v1",
      "title": "Rethinking Human Preference Evaluation of LLM Rationales",
      "title_zh": "é‡æ–°å®¡è§†å¤§è¯­è¨€æ¨¡å‹æ¨ç†çš„äººç±»åå¥½è¯„ä¼°",
      "authors": [
        "Ziang Li",
        "Manasi Ganti",
        "Zixian Ma",
        "Helena Vasconcelos",
        "Qijia He",
        "Ranjay Krishna"
      ],
      "abstract": "Large language models (LLMs) often generate natural language rationales -- free-form explanations that help improve performance on complex reasoning tasks and enhance interpretability for human users. However, evaluating these rationales remains challenging. While recent work has relied on binary preference judgments from humans or LLM judges, such evaluations are often opaque and coarse-grained, offering limited insight into what makes one rationale better than another. In this work, we rethink preference evaluation for LLM-generated rationales by asking: (1) What attributes define good rationales? (2) Can human preferences be explained by these attributes? (3) Can attribute-based evaluation overcome the limitations of binary comparisons? We identify a set of key rationale attributes from prior literature and assess them using automatic metrics, LLM judgments, and human annotations. We then analyze two standard human preference datasets MT Bench and Chatbot Arena using SHAP to identify which attributes best explain human preference outcomes. Finally, we re-evaluate model-generated rationales using attribute-specific ELO scores, revealing more nuanced model comparisons and insights. Our findings suggest that fine-grained attribute evaluations can better characterize rationale quality and guide future research toward more interpretable and reliable evaluation practices.",
      "tldr_zh": "è¯¥ç ”ç©¶é’ˆå¯¹å¤§è¯­è¨€æ¨¡å‹(LLMs)ç”Ÿæˆçš„åˆç†è§£é‡Š(rationales)çš„äººç±»åå¥½è¯„ä¼°(human preference evaluation)è¿›è¡Œäº†é‡æ–°æ€è€ƒï¼Œæ—¨åœ¨è§£å†³ç›®å‰äºŒå…ƒåå¥½åˆ¤æ–­(binary preference judgments)è¿‡äºç²—ç•¥ä¸”ç¼ºä¹é€æ˜åº¦çš„é—®é¢˜ã€‚ç ”ç©¶å›¢é˜Ÿä»ç°æœ‰æ–‡çŒ®ä¸­è¯†åˆ«å¹¶æå–äº†ä¸€ç³»åˆ—å…³é”®å±æ€§(attributes)ï¼Œç»“åˆè‡ªåŠ¨æŒ‡æ ‡ã€LLMè¯„åˆ¤å’Œäººå·¥æ ‡æ³¨å¯¹è§£é‡Šè´¨é‡è¿›è¡Œå¤šç»´åº¦è¯„ä¼°ã€‚é€šè¿‡ä½¿ç”¨SHAPåˆ†æMT Benchå’ŒChatbot Arenaç­‰æ ‡å‡†æ•°æ®é›†ï¼Œç ”ç©¶æ­ç¤ºäº†å“ªäº›æ ¸å¿ƒå±æ€§æœ€èƒ½è§£é‡Šäººç±»çš„åå¥½ç»“æœã€‚æ­¤å¤–ï¼Œç ”ç©¶å¼•å…¥äº†ç‰¹å®šå±æ€§çš„ELOè¯„åˆ†(attribute-specific ELO scores)ï¼Œå®ç°äº†æ¯”ä¼ ç»ŸäºŒåˆ†æ³•æ›´ç»†è‡´çš„æ¨¡å‹æ€§èƒ½å¯¹æ¯”ã€‚å®éªŒç»“æœè¡¨æ˜ï¼Œè¿™ç§ç»†ç²’åº¦çš„å±æ€§è¯„ä¼°èƒ½æ›´æœ‰æ•ˆåœ°è¡¨å¾è§£é‡Šè´¨é‡ï¼Œå¹¶ä¸ºæœªæ¥æ„å»ºæ›´å…·å¯è§£é‡Šæ€§ä¸å¯é æ€§çš„è¯„ä¼°ä½“ç³»æä¾›äº†æŒ‡å¯¼ã€‚",
      "categories": [
        "cs.AI",
        "cs.CL"
      ],
      "primary_category": "cs.AI",
      "comment": "Published in the XLLM-Reason-Plan Workshop on the Application of LLM Explainability to Reasoning and Planning at COLM 2025",
      "pdf_url": "https://arxiv.org/pdf/2509.11026v1",
      "published_date": "2025-09-14 01:33:14 UTC",
      "updated_date": "2025-09-14 01:33:14 UTC",
      "processing_status": "completed",
      "attempts": 1,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "llm_backup_calls": 0,
      "last_update": "2026-01-24T18:32:08.790784+00:00"
    },
    {
      "arxiv_id": "2509.19328v1",
      "title": "Human Activity Recognition Based on Electrocardiogram Data Only",
      "title_zh": "ä»…åŸºäºå¿ƒç”µå›¾æ•°æ®çš„äººä½“æ´»åŠ¨è¯†åˆ«",
      "authors": [
        "Sina Montazeri",
        "Waltenegus Dargie",
        "Yunhe Feng",
        "Kewei Sha"
      ],
      "abstract": "Human activity recognition is critical for applications such as early intervention and health analytics. Traditional activity recognition relies on inertial measurement units (IMUs), which are resource intensive and require calibration. Although electrocardiogram (ECG)-based methods have been explored, these have typically served as supplements to IMUs or have been limited to broad categorical classification such as fall detection or active vs. inactive in daily activities. In this paper, we advance the field by demonstrating, for the first time, robust recognition of activity only with ECG in six distinct activities, which is beyond the scope of previous work. We design and evaluate three new deep learning models, including a CNN classifier with Squeeze-and-Excitation blocks for channel-wise feature recalibration, a ResNet classifier with dilated convolutions for multiscale temporal dependency capture, and a novel CNNTransformer hybrid combining convolutional feature extraction with attention mechanisms for long-range temporal relationship modeling. Tested on data from 54 subjects for six activities, all three models achieve over 94% accuracy for seen subjects, while CNNTransformer hybrid reaching the best accuracy of 72% for unseen subjects, a result that can be further improved by increasing the training population. This study demonstrates the first successful ECG-only activity classification in multiple physical activities, offering significant potential for developing next-generation wearables capable of simultaneous cardiac monitoring and activity recognition without additional motion sensors.",
      "tldr_zh": "è¯¥ç ”ç©¶æ¢ç´¢äº†ä»…åŸºäºå¿ƒç”µå›¾ (Electrocardiogram, ECG) æ•°æ®çš„äººä½“æ´»åŠ¨è¯†åˆ«ï¼Œæ—¨åœ¨å…‹æœä¼ ç»Ÿæƒ¯æ€§æµ‹é‡å•å…ƒ (IMUs) èµ„æºæ¶ˆè€—é«˜ä¸”éœ€è¦æ ¡å‡†çš„å±€é™æ€§ã€‚è®ºæ–‡é¦–æ¬¡å®ç°äº†åœ¨å…­ç§ä¸åŒæ´»åŠ¨ä¸­ä»…å‡­ ECG è¿›è¡Œç¨³å¥è¯†åˆ«ï¼Œå¹¶è®¾è®¡è¯„ä¼°äº†ä¸‰ç§æ·±åº¦å­¦ä¹ æ¨¡å‹ï¼ŒåŒ…æ‹¬åŒ…å« Squeeze-and-Excitation (SE) å—çš„ CNN åˆ†ç±»å™¨ã€é‡‡ç”¨ç©ºæ´å·ç§¯ (dilated convolutions) çš„ ResNet ä»¥åŠç»“åˆå·ç§¯ç‰¹å¾æå–ä¸æ³¨æ„åŠ›æœºåˆ¶çš„ CNNTransformer æ··åˆæ¨¡å‹ã€‚åœ¨ 54 åå—è¯•è€…çš„æ•°æ®æµ‹è¯•ä¸­ï¼Œä¸‰ç§æ¨¡å‹å¯¹å·²çŸ¥å—è¯•è€…çš„è¯†åˆ«å‡†ç¡®ç‡å‡è¶…è¿‡ 94%ï¼Œå…¶ä¸­ CNNTransformer åœ¨å¤„ç†æœªçŸ¥å—è¯•è€…æ—¶è¾¾åˆ°äº† 72% çš„æœ€é«˜å‡†ç¡®ç‡ã€‚è¯¥ç ”ç©¶è¯æ˜äº†ä»…ä½¿ç”¨ ECG æ•°æ®è¿›è¡Œå¤šé¡¹èº«ä½“æ´»åŠ¨åˆ†ç±»çš„å¯è¡Œæ€§ï¼Œä¸ºå¼€å‘æ— éœ€é¢å¤–è¿åŠ¨ä¼ æ„Ÿå™¨å³å¯åŒæ—¶è¿›è¡Œå¿ƒè„ç›‘æµ‹å’Œæ´»åŠ¨è¯†åˆ«çš„æ–°ä¸€ä»£å¯ç©¿æˆ´è®¾å¤‡æä¾›äº†å·¨å¤§æ½œåŠ›ã€‚",
      "categories": [
        "eess.SP",
        "cs.AI",
        "cs.LG"
      ],
      "primary_category": "eess.SP",
      "comment": "This is a preprint version. Content may change before final publication",
      "pdf_url": "https://arxiv.org/pdf/2509.19328v1",
      "published_date": "2025-09-14 01:26:32 UTC",
      "updated_date": "2025-09-14 01:26:32 UTC",
      "processing_status": "completed",
      "attempts": 1,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "llm_backup_calls": 0,
      "last_update": "2026-01-24T18:32:06.996574+00:00"
    }
  ],
  "processing_status": "completed",
  "error": null,
  "raw_papers_fetched": true,
  "papers_count": 96,
  "processed_papers_count": 96,
  "failed_papers_count": 0,
  "llm_backup_calls": 0,
  "summary_generated": true,
  "daily_data_saved": true,
  "last_update": "2026-01-24T18:33:06.217365+00:00"
}